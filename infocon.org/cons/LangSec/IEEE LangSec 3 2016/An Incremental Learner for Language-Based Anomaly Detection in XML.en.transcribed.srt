1
00:00:00,000 --> 00:00:04,290
today<font color="#E5E5E5"> I will talk</font><font color="#CCCCCC"> about an incremental</font>

2
00:00:02,399 --> 00:00:07,049
learner for language based anomaly

3
00:00:04,290 --> 00:00:10,530
detection in XML so you have heard

4
00:00:07,049 --> 00:00:14,580
<font color="#E5E5E5">already that the XML has some pretty</font>

5
00:00:10,530 --> 00:00:17,270
nasty screw-ups to make<font color="#E5E5E5"> it short</font><font color="#CCCCCC"> it's a</font>

6
00:00:14,580 --> 00:00:19,619
text based data serialization format and

7
00:00:17,270 --> 00:00:21,720
it's used<font color="#E5E5E5"> in many communication</font>

8
00:00:19,619 --> 00:00:24,630
protocols that you already<font color="#E5E5E5"> find in cloud</font>

9
00:00:21,720 --> 00:00:27,840
computing it<font color="#CCCCCC"> text-based so they like it</font>

10
00:00:24,630 --> 00:00:29,490
for the<font color="#E5E5E5"> heterogeneous environments so so</font>

11
00:00:27,840 --> 00:00:32,369
this<font color="#E5E5E5"> is classic protocol for web</font>

12
00:00:29,490 --> 00:00:34,910
services XMPP is in the new standard for

13
00:00:32,369 --> 00:00:39,350
inter Cloud messaging sam'l is a

14
00:00:34,910 --> 00:00:42,839
protocol for single sign-on XHTML is the

15
00:00:39,350 --> 00:00:45,809
XML variant of HTML and so on<font color="#CCCCCC"> so you</font>

16
00:00:42,840 --> 00:00:48,149
find XML basically everywhere and in the

17
00:00:45,809 --> 00:00:50,328
lungs accents you can think<font color="#E5E5E5"> about</font><font color="#CCCCCC"> giba</font>

18
00:00:48,149 --> 00:00:54,600
validation as a first-line defense a

19
00:00:50,329 --> 00:00:57,449
schema is like a dreamer it specifies

20
00:00:54,600 --> 00:01:00,210
types of elements and production rules

21
00:00:57,449 --> 00:01:03,930
how these types are allowed to<font color="#CCCCCC"> expand in</font>

22
00:01:00,210 --> 00:01:05,790
<font color="#CCCCCC">a document in validation is then to</font>

23
00:01:03,930 --> 00:01:08,610
check whether a document conforms to a

24
00:01:05,790 --> 00:01:11,340
schema and it should reject unacceptable

25
00:01:08,610 --> 00:01:13,369
inputs but it's not that<font color="#E5E5E5"> easy because</font>

26
00:01:11,340 --> 00:01:17,340
there are two language theoretic flaws

27
00:01:13,369 --> 00:01:19,560
first the industry standard XML schema

28
00:01:17,340 --> 00:01:21,869
has so-called<font color="#E5E5E5"> extension points for</font>

29
00:01:19,560 --> 00:01:23,280
achieving composability and the

30
00:01:21,869 --> 00:01:27,270
extension points are basically<font color="#CCCCCC"> wife</font>

31
00:01:23,280 --> 00:01:30,840
buyouts second we have references in XML

32
00:01:27,270 --> 00:01:33,658
so I debased references are self

33
00:01:30,840 --> 00:01:36,270
references in the<font color="#E5E5E5"> document empty</font><font color="#CCCCCC"> raise</font>

34
00:01:33,659 --> 00:01:41,549
the expressiveness beyond context-free

35
00:01:36,270 --> 00:01:44,310
which makes it very<font color="#CCCCCC"> hard to validate so</font>

36
00:01:41,549 --> 00:01:46,530
how can I spot an extension point this

37
00:01:44,310 --> 00:01:50,490
<font color="#E5E5E5">is a fragment talking directly from the</font>

38
00:01:46,530 --> 00:01:53,070
soap specification it's it<font color="#E5E5E5"> specifies the</font>

39
00:01:50,490 --> 00:01:55,079
type for header the soap protocol

40
00:01:53,070 --> 00:01:57,898
specifies a massive message format the

41
00:01:55,079 --> 00:02:00,839
envelope has header in the body and in

42
00:01:57,899 --> 00:02:04,229
the header it just specifies an any

43
00:02:00,840 --> 00:02:06,060
element can appear and the namespace

44
00:02:04,229 --> 00:02:09,209
just has to be<font color="#E5E5E5"> different from the soap</font>

45
00:02:06,060 --> 00:02:11,129
namespace and the last argument process

46
00:02:09,209 --> 00:02:13,360
content<font color="#E5E5E5"> like this makes it really bad</font>

47
00:02:11,129 --> 00:02:16,420
process contact legs

48
00:02:13,360 --> 00:02:19,270
<font color="#CCCCCC">I tells the</font><font color="#E5E5E5"> parser when when you</font>

49
00:02:16,420 --> 00:02:21,489
<font color="#E5E5E5">validate such a document try to find the</font>

50
00:02:19,270 --> 00:02:23,200
schema for this<font color="#E5E5E5"> element at this place if</font>

51
00:02:21,490 --> 00:02:26,230
there is<font color="#CCCCCC"> no</font><font color="#E5E5E5"> schema in the scope of the</font>

52
00:02:23,200 --> 00:02:29,079
pawza just skip validation so what can

53
00:02:26,230 --> 00:02:31,410
<font color="#CCCCCC">you place there now so you can</font><font color="#E5E5E5"> easily</font>

54
00:02:29,080 --> 00:02:35,290
make some denial<font color="#E5E5E5"> of service attacks like</font>

55
00:02:31,410 --> 00:02:37,600
many nested elements many elements in

56
00:02:35,290 --> 00:02:41,200
general but you can also place more

57
00:02:37,600 --> 00:02:44,400
involve the text so the signature

58
00:02:41,200 --> 00:02:46,660
wrapping attack combines this problem of

59
00:02:44,400 --> 00:02:50,709
extension points and I debased

60
00:02:46,660 --> 00:02:53,620
references XML digital signatures are

61
00:02:50,709 --> 00:02:56,590
used in many protocols like ws-security

62
00:02:53,620 --> 00:03:00,190
for soap or in summary singer some

63
00:02:56,590 --> 00:03:02,350
<font color="#CCCCCC">Samuelson sign on to to digitally sign a</font>

64
00:03:00,190 --> 00:03:06,970
part of the document and stored the

65
00:03:02,350 --> 00:03:09,100
signature at some other place so the

66
00:03:06,970 --> 00:03:12,340
group of summer<font color="#CCCCCC"> oski have looked at</font>

67
00:03:09,100 --> 00:03:14,140
<font color="#CCCCCC">samuel implementations and they</font><font color="#E5E5E5"> found in</font>

68
00:03:12,340 --> 00:03:16,840
2012 that most of them were vulnerable

69
00:03:14,140 --> 00:03:19,000
to this kind of attack and to make it

70
00:03:16,840 --> 00:03:22,420
<font color="#E5E5E5">more</font><font color="#CCCCCC"> understandable I've a small example</font>

71
00:03:19,000 --> 00:03:24,670
on the slide this is the information<font color="#E5E5E5"> set</font>

72
00:03:22,420 --> 00:03:28,480
of a soap message it has an envelope and

73
00:03:24,670 --> 00:03:31,268
header and in ws-security the signature

74
00:03:28,480 --> 00:03:34,060
resides in the header and the sign part

75
00:03:31,269 --> 00:03:36,040
is the body and the reference<font color="#E5E5E5"> of the</font>

76
00:03:34,060 --> 00:03:39,160
<font color="#E5E5E5">signature points to the body and when</font>

77
00:03:36,040 --> 00:03:41,709
this file is consumed by<font color="#CCCCCC"> a service or by</font>

78
00:03:39,160 --> 00:03:43,810
client it goes typically through a

79
00:03:41,709 --> 00:03:46,269
processing pipeline the first check

80
00:03:43,810 --> 00:03:49,780
whether the signatures are<font color="#E5E5E5"> all valid the</font>

81
00:03:46,269 --> 00:03:52,600
boolean decision if yes then process the

82
00:03:49,780 --> 00:03:54,670
part so the<font color="#E5E5E5"> problem arises</font><font color="#CCCCCC"> when the</font>

83
00:03:52,600 --> 00:03:57,980
digital design part is not necessarily

84
00:03:54,670 --> 00:04:00,109
the<font color="#E5E5E5"> process part</font>

85
00:03:57,980 --> 00:04:02,359
because there are extension points then

86
00:04:00,110 --> 00:04:05,209
attacker can move the original content

87
00:04:02,360 --> 00:04:10,569
into some random<font color="#E5E5E5"> wrapper in the header</font>

88
00:04:05,209 --> 00:04:13,670
and place its own instructions there and

89
00:04:10,569 --> 00:04:15,798
the business logic selects the body for

90
00:04:13,670 --> 00:04:18,858
the<font color="#E5E5E5"> instructions and the signature is</font>

91
00:04:15,799 --> 00:04:22,669
still valid so this is<font color="#CCCCCC"> actually an</font>

92
00:04:18,858 --> 00:04:24,770
example from 2009 for ms on AC to this

93
00:04:22,669 --> 00:04:27,680
using this attack it was able to create

94
00:04:24,770 --> 00:04:33,409
arbitrary<font color="#E5E5E5"> ssh keys for other hosts in</font>

95
00:04:27,680 --> 00:04:36,289
the cloud and the attacker only needs a

96
00:04:33,410 --> 00:04:38,900
signed message the one<font color="#E5E5E5"> to the left and</font>

97
00:04:36,289 --> 00:04:40,969
in this attack it was<font color="#E5E5E5"> easily possible</font>

98
00:04:38,900 --> 00:04:43,549
back then it was possible to get<font color="#E5E5E5"> them</font>

99
00:04:40,970 --> 00:04:45,740
from<font color="#CCCCCC"> network sniffing or users even</font>

100
00:04:43,550 --> 00:04:48,860
<font color="#E5E5E5">posted them on the Amazon support forums</font>

101
00:04:45,740 --> 00:04:51,139
for debugging purposes so if once the

102
00:04:48,860 --> 00:04:54,470
attacker got the valid message a valid

103
00:04:51,139 --> 00:04:57,020
signature he could utilize it so how can

104
00:04:54,470 --> 00:04:59,690
<font color="#E5E5E5">we encounter this attack there have</font><font color="#CCCCCC"> been</font>

105
00:04:57,020 --> 00:05:04,280
several attempts to close this loophole

106
00:04:59,690 --> 00:05:06,200
in my opinion the<font color="#CCCCCC"> most are the one that</font>

107
00:05:04,280 --> 00:05:08,960
makes most sense is the one by the<font color="#E5E5E5"> group</font>

108
00:05:06,200 --> 00:05:12,620
of yinz it's just removing the extension

109
00:05:08,960 --> 00:05:14,659
points but<font color="#E5E5E5"> this turns out to be hard the</font>

110
00:05:12,620 --> 00:05:17,810
extension points are basically all the

111
00:05:14,660 --> 00:05:19,610
composable protocols<font color="#CCCCCC"> i listed before so</font>

112
00:05:17,810 --> 00:05:22,250
we have a combinatorial problem if you

113
00:05:19,610 --> 00:05:24,590
want to<font color="#E5E5E5"> create the unified schema so if</font>

114
00:05:22,250 --> 00:05:25,880
<font color="#E5E5E5">i have</font><font color="#CCCCCC"> 10 schemas with</font><font color="#E5E5E5"> 10 extension</font>

115
00:05:24,590 --> 00:05:28,909
points i can<font color="#CCCCCC"> combine them arbitrarily</font>

116
00:05:25,880 --> 00:05:31,909
and the result grows exponentially so

117
00:05:28,910 --> 00:05:33,590
removing them is hard and this motivates

118
00:05:31,910 --> 00:05:35,720
my research of which i call

119
00:05:33,590 --> 00:05:38,030
language-based anomaly detection the

120
00:05:35,720 --> 00:05:40,190
idea is<font color="#CCCCCC"> to</font><font color="#E5E5E5"> learn the acceptable language</font>

121
00:05:38,030 --> 00:05:43,969
at the<font color="#CCCCCC"> particular interface of an</font>

122
00:05:40,190 --> 00:05:46,669
xml-based system what do<font color="#E5E5E5"> we need for</font>

123
00:05:43,970 --> 00:05:49,280
this first we need some representation

124
00:05:46,669 --> 00:05:52,400
of the language<font color="#E5E5E5"> I chose an automaton</font>

125
00:05:49,280 --> 00:05:55,460
based representation I call<font color="#CCCCCC"> it data type</font>

126
00:05:52,400 --> 00:05:59,448
XML visibly pushdown automata very long

127
00:05:55,460 --> 00:06:03,320
name the idea is it accepts mixed

128
00:05:59,449 --> 00:06:05,150
content.xml in a streaming scenario why

129
00:06:03,320 --> 00:06:09,770
mixed content because we have it in the

130
00:06:05,150 --> 00:06:11,128
HTML scenario by streaming the XMPP

131
00:06:09,770 --> 00:06:13,529
protocol

132
00:06:11,129 --> 00:06:15,479
is an XML stream protocol so this<font color="#CCCCCC"> is</font><font color="#E5E5E5"> the</font>

133
00:06:13,529 --> 00:06:19,050
<font color="#E5E5E5">most generalized form of language</font>

134
00:06:15,479 --> 00:06:21,599
representation in XML we can have

135
00:06:19,050 --> 00:06:25,699
character data and the automaton

136
00:06:21,599 --> 00:06:29,159
generalizes data using data types and

137
00:06:25,699 --> 00:06:31,559
from this automaton another form can be

138
00:06:29,159 --> 00:06:34,229
created it's called character data<font color="#CCCCCC"> XV PA</font>

139
00:06:31,559 --> 00:06:36,330
it's basically the same<font color="#E5E5E5"> just as some</font>

140
00:06:34,229 --> 00:06:38,248
optimization for stream<font color="#CCCCCC"> policy for</font>

141
00:06:36,330 --> 00:06:42,389
stream validation so you can check in

142
00:06:38,249 --> 00:06:45,479
linear time second we need some learning

143
00:06:42,389 --> 00:06:47,939
algorithm and I specify an incremental

144
00:06:45,479 --> 00:06:50,758
learner using the ideas from

145
00:06:47,939 --> 00:06:53,129
dramatically<font color="#CCCCCC"> invariance the learner</font>

146
00:06:50,759 --> 00:06:57,599
constructs such an automaton from

147
00:06:53,129 --> 00:06:59,459
examples and it also provides<font color="#E5E5E5"> a two</font>

148
00:06:57,599 --> 00:07:02,099
operations for unlearning<font color="#E5E5E5"> and</font>

149
00:06:59,459 --> 00:07:03,990
sanitization of the automaton so we can

150
00:07:02,099 --> 00:07:08,669
<font color="#CCCCCC">handle poisoning attacks during the</font>

151
00:07:03,990 --> 00:07:12,149
learning process and third learning is

152
00:07:08,669 --> 00:07:14,789
of course<font color="#E5E5E5"> some form of induction it can</font>

153
00:07:12,149 --> 00:07:18,209
never<font color="#CCCCCC"> be completely valid it can only be</font>

154
00:07:14,789 --> 00:07:20,579
very<font color="#E5E5E5"> strong so we need experiments how</font>

155
00:07:18,209 --> 00:07:23,849
it works in practice and now you have<font color="#CCCCCC"> a</font>

156
00:07:20,579 --> 00:07:26,610
train and test approach and in<font color="#E5E5E5"> total for</font>

157
00:07:23,849 --> 00:07:30,110
data sets two of them were<font color="#E5E5E5"> generated</font>

158
00:07:26,610 --> 00:07:33,990
using a stochastic<font color="#CCCCCC"> XML generator just do</font>

159
00:07:30,110 --> 00:07:36,929
<font color="#CCCCCC">to do the tests and</font><font color="#E5E5E5"> two more advanced</font>

160
00:07:33,990 --> 00:07:38,849
scenarios using the<font color="#CCCCCC"> apache access to web</font>

161
00:07:36,929 --> 00:07:41,219
service<font color="#CCCCCC"> i implemented</font><font color="#E5E5E5"> that my own web</font>

162
00:07:38,849 --> 00:07:42,959
service like the tutorials tell me to

163
00:07:41,219 --> 00:07:47,248
implement it was of course born a rebel

164
00:07:42,959 --> 00:07:49,709
against all day at<font color="#E5E5E5"> X and I used to</font>

165
00:07:47,249 --> 00:07:55,319
support and manually<font color="#E5E5E5"> text to to make</font>

166
00:07:49,709 --> 00:07:58,099
some examples for testing so<font color="#CCCCCC"> how does an</font>

167
00:07:55,319 --> 00:08:01,829
automaton look like in<font color="#E5E5E5"> this class of</font>

168
00:07:58,099 --> 00:08:05,300
quality states and transitions what

169
00:08:01,829 --> 00:08:07,829
makes it very special it's a it has a

170
00:08:05,300 --> 00:08:12,929
alphabet it has actually three alphabets

171
00:08:07,829 --> 00:08:14,939
a cola return in a internal alphabet<font color="#E5E5E5"> the</font>

172
00:08:12,929 --> 00:08:17,549
call alpha betas for the start element

173
00:08:14,939 --> 00:08:20,430
events the open text in the document the

174
00:08:17,550 --> 00:08:22,889
return<font color="#CCCCCC"> alpha betas for the end element</font>

175
00:08:20,430 --> 00:08:24,580
events for the glowsticks into the

176
00:08:22,889 --> 00:08:26,590
internal alpha betas for data

177
00:08:24,580 --> 00:08:31,300
something that happens between<font color="#E5E5E5"> an</font>

178
00:08:26,590 --> 00:08:33,098
Augmented<font color="#CCCCCC"> closed tech of course it tests</font>

179
00:08:31,300 --> 00:08:34,899
this<font color="#E5E5E5"> is a pushdown automaton so</font><font color="#CCCCCC"> Cory of</font>

180
00:08:33,099 --> 00:08:38,190
course<font color="#E5E5E5"> it need to stack and it utilizes</font>

181
00:08:34,899 --> 00:08:40,779
the states for<font color="#E5E5E5"> the stack alphabet the</font>

182
00:08:38,190 --> 00:08:42,820
<font color="#CCCCCC">names of these alphabets might indicate</font>

183
00:08:40,779 --> 00:08:46,209
where the<font color="#E5E5E5"> Optima the class originates</font>

184
00:08:42,820 --> 00:08:48,339
from it's from program analysis the call

185
00:08:46,209 --> 00:08:50,260
and return were used to model function

186
00:08:48,339 --> 00:08:52,269
calls and returns and<font color="#CCCCCC"> the internal</font>

187
00:08:50,260 --> 00:08:57,100
alphabet is used to model what happens

188
00:08:52,269 --> 00:08:59,290
in a function so the states are then

189
00:08:57,100 --> 00:09:03,760
partitioned into so-called modules<font color="#CCCCCC"> shown</font>

190
00:08:59,290 --> 00:09:06,790
<font color="#CCCCCC">s-boxes the modules have an entry state</font>

191
00:09:03,760 --> 00:09:10,480
and exit states and the module is

192
00:09:06,790 --> 00:09:13,329
exactly a schema type what you have in a

193
00:09:10,480 --> 00:09:16,899
gramma we have<font color="#E5E5E5"> done transitions within</font>

194
00:09:13,329 --> 00:09:19,719
modules and between modules transition

195
00:09:16,899 --> 00:09:22,920
between modules are<font color="#E5E5E5"> for open</font><font color="#CCCCCC"> closed tech</font>

196
00:09:19,720 --> 00:09:25,480
<font color="#E5E5E5">events and the push</font><font color="#CCCCCC"> and pop the stack</font>

197
00:09:22,920 --> 00:09:27,370
transitions within a module if the

198
00:09:25,480 --> 00:09:29,350
second changed so this gives the

199
00:09:27,370 --> 00:09:34,480
automotive very nice decidability

200
00:09:29,350 --> 00:09:38,170
properties and the<font color="#E5E5E5"> CX vpa is a special</font>

201
00:09:34,480 --> 00:09:41,820
form it just optimizes how internal

202
00:09:38,170 --> 00:09:41,819
checks are done in linear time

203
00:09:44,379 --> 00:09:48,079
this is now the incremental learning

204
00:09:46,639 --> 00:09:52,819
step there are several algorithms

205
00:09:48,079 --> 00:09:54,920
involved there is a learner component in

206
00:09:52,819 --> 00:09:57,709
a valid<font color="#E5E5E5"> data component the learner</font>

207
00:09:54,920 --> 00:10:00,139
computes an updated automata and the

208
00:09:57,709 --> 00:10:04,189
bolita validator uses the fast

209
00:10:00,139 --> 00:10:06,170
representation for checking and the

210
00:10:04,189 --> 00:10:08,899
learner receives a data type the event

211
00:10:06,170 --> 00:10:10,550
stream this means is that event stream

212
00:10:08,899 --> 00:10:13,309
where the character data is already

213
00:10:10,550 --> 00:10:18,920
replaced by minimally required data

214
00:10:13,309 --> 00:10:21,319
types to model these texts there are two

215
00:10:18,920 --> 00:10:23,689
internal representations there a and the

216
00:10:21,319 --> 00:10:25,729
Omega the a is an incremented

217
00:10:23,689 --> 00:10:27,860
incrementally<font color="#CCCCCC"> updateable pushdown</font>

218
00:10:25,730 --> 00:10:29,959
automaton and the<font color="#E5E5E5"> Omega is a our</font>

219
00:10:27,860 --> 00:10:32,149
frequencies of states and transitions

220
00:10:29,959 --> 00:10:36,079
learn from data so they are like<font color="#E5E5E5"> wait</font>

221
00:10:32,149 --> 00:10:38,949
for the HSN T States<font color="#E5E5E5"> and the ink</font><font color="#CCCCCC"> waited</font>

222
00:10:36,079 --> 00:10:41,719
algorithm updates these internal

223
00:10:38,949 --> 00:10:44,329
representations<font color="#E5E5E5"> drem removes the</font><font color="#CCCCCC"> 0</font>

224
00:10:41,720 --> 00:10:46,910
waited<font color="#CCCCCC"> states and transitions again xvii</font>

225
00:10:44,329 --> 00:10:50,479
<font color="#CCCCCC">PA generates the modules and does some</font>

226
00:10:46,910 --> 00:10:55,339
minimization and then a learning step in

227
00:10:50,480 --> 00:10:57,079
incremental learning<font color="#E5E5E5"> step is done so to</font>

228
00:10:55,339 --> 00:10:59,990
give you<font color="#E5E5E5"> an idea how incremental</font>

229
00:10:57,079 --> 00:11:02,269
learning works the<font color="#E5E5E5"> fundamental idea</font><font color="#CCCCCC"> is</font>

230
00:10:59,990 --> 00:11:04,160
that every event stream prefix of a

231
00:11:02,269 --> 00:11:09,490
training document gets a unique<font color="#E5E5E5"> state</font>

232
00:11:04,160 --> 00:11:13,339
and we do this by naming the<font color="#E5E5E5"> states</font>

233
00:11:09,490 --> 00:11:15,679
using you<font color="#E5E5E5"> and why you and be you is a</font>

234
00:11:13,339 --> 00:11:19,069
typing context and we are the left

235
00:11:15,679 --> 00:11:21,529
siblings and we then merge two states if

236
00:11:19,069 --> 00:11:23,360
they<font color="#E5E5E5"> are locally the same and the</font>

237
00:11:21,529 --> 00:11:25,910
locality is specified by<font color="#E5E5E5"> two parameters</font>

238
00:11:23,360 --> 00:11:31,730
<font color="#E5E5E5">K and L so let's look at this example</font>

239
00:11:25,910 --> 00:11:34,069
this is a xml<font color="#E5E5E5"> info set it is a document</font>

240
00:11:31,730 --> 00:11:37,879
where a dealer has used cars new cars

241
00:11:34,069 --> 00:11:39,618
and advertisements for them what makes

242
00:11:37,879 --> 00:11:42,069
this example interesting is that the

243
00:11:39,619 --> 00:11:44,569
advertisements for used cars are

244
00:11:42,069 --> 00:11:47,089
different type than the advertisement

245
00:11:44,569 --> 00:11:49,128
for a new car because<font color="#E5E5E5"> because a new car</font>

246
00:11:47,089 --> 00:11:51,860
does<font color="#CCCCCC"> not need a year</font><font color="#E5E5E5"> because it's new</font>

247
00:11:49,129 --> 00:11:56,110
and the learner should of course be able

248
00:11:51,860 --> 00:11:56,110
to distinguish these cases

249
00:11:56,290 --> 00:12:02,360
so the red part and the blue part

250
00:11:59,689 --> 00:12:04,429
together are all the typing information

251
00:12:02,360 --> 00:12:06,860
a deterministic parcel needs to decide

252
00:12:04,429 --> 00:12:12,529
the type of the<font color="#E5E5E5"> add element of the right</font>

253
00:12:06,860 --> 00:12:16,600
most adamant we use the typing context

254
00:12:12,529 --> 00:12:22,220
and disciplines to derive a unique state

255
00:12:16,600 --> 00:12:25,879
and from this unique state we can create

256
00:12:22,220 --> 00:12:28,790
<font color="#CCCCCC">the localized state and this is the</font>

257
00:12:25,879 --> 00:12:32,299
whole magic of the learning the question

258
00:12:28,790 --> 00:12:34,309
is<font color="#E5E5E5"> is it sound yes in many cases because</font>

259
00:12:32,299 --> 00:12:36,920
there were studies on complexities of

260
00:12:34,309 --> 00:12:38,988
schemas in practice people tend<font color="#E5E5E5"> to use</font>

261
00:12:36,920 --> 00:12:42,110
very simple production rules where

262
00:12:38,989 --> 00:12:45,799
locality works and people also tend to

263
00:12:42,110 --> 00:12:48,199
use very limited typing contexts local

264
00:12:45,799 --> 00:12:50,660
typing context so there are I can

265
00:12:48,199 --> 00:12:54,170
usually find small parameters K and L to

266
00:12:50,660 --> 00:12:57,139
do a very good<font color="#E5E5E5"> generalization so what</font>

267
00:12:54,170 --> 00:12:59,269
about poisoning attacks I mentioned we

268
00:12:57,139 --> 00:13:00,980
have these omegas the Countess of

269
00:12:59,269 --> 00:13:03,920
frequencies how often states and

270
00:13:00,980 --> 00:13:06,350
transitions have been learned unlearning

271
00:13:03,920 --> 00:13:08,299
is for the case where I have where I

272
00:13:06,350 --> 00:13:11,179
discover oh my god I have learned an

273
00:13:08,299 --> 00:13:14,170
attack unintentionally then I can remove

274
00:13:11,179 --> 00:13:16,369
this attack by simulating this

275
00:13:14,170 --> 00:13:18,559
corresponding attack and decrementing

276
00:13:16,369 --> 00:13:23,110
the edges and the trim function then

277
00:13:18,559 --> 00:13:25,519
drops these edges if the turn 20 and

278
00:13:23,110 --> 00:13:28,100
sanitization is for the case where<font color="#E5E5E5"> I</font>

279
00:13:25,519 --> 00:13:31,759
have hidden poisoning attacks in my

280
00:13:28,100 --> 00:13:33,769
model the assumption is there are only

281
00:13:31,759 --> 00:13:36,589
few of those<font color="#CCCCCC"> the statistically</font>

282
00:13:33,769 --> 00:13:38,839
assumption and I can get rid of them if

283
00:13:36,589 --> 00:13:41,629
I decrement all the counters by one or

284
00:13:38,839 --> 00:13:44,419
by two and all that the edges that drop

285
00:13:41,629 --> 00:13:49,579
below zero are then removed so that the

286
00:13:44,419 --> 00:13:52,579
low frequent events so as i<font color="#CCCCCC"> mentioned i</font>

287
00:13:49,579 --> 00:13:56,089
tested<font color="#E5E5E5"> it in total four scenarios for a</font>

288
00:13:52,579 --> 00:14:00,469
text i use<font color="#CCCCCC"> both manual skills and also</font>

289
00:13:56,089 --> 00:14:03,649
to support and for evaluating<font color="#E5E5E5"> i measured</font>

290
00:14:00,470 --> 00:14:05,929
the learning progress I have a train set

291
00:14:03,649 --> 00:14:07,970
and a test set I randomly<font color="#E5E5E5"> pick a</font>

292
00:14:05,929 --> 00:14:10,519
training example

293
00:14:07,970 --> 00:14:13,939
the incremental learning step evaluate

294
00:14:10,519 --> 00:14:16,459
the whole test set measure<font color="#E5E5E5"> the binary</font>

295
00:14:13,939 --> 00:14:18,889
classification performance and<font color="#E5E5E5"> I also</font>

296
00:14:16,459 --> 00:14:20,599
count the mind changes the mind changes

297
00:14:18,889 --> 00:14:22,819
are the number of states and transitions

298
00:14:20,600 --> 00:14:24,860
that have been<font color="#E5E5E5"> added from an incremental</font>

299
00:14:22,819 --> 00:14:27,680
learning step so if the model is

300
00:14:24,860 --> 00:14:29,509
complete they are zero mind changes when

301
00:14:27,680 --> 00:14:31,250
learning and if it's if it learns a lot

302
00:14:29,509 --> 00:14:33,589
there of course many mind changes and

303
00:14:31,250 --> 00:14:36,259
<font color="#CCCCCC">these mind changes they are useful</font>

304
00:14:33,589 --> 00:14:38,990
heuristic in practice to see if my model

305
00:14:36,259 --> 00:14:42,560
has already converged<font color="#CCCCCC"> so but still as a</font>

306
00:14:38,990 --> 00:14:45,259
heuristic these are two examples the

307
00:14:42,560 --> 00:14:50,420
lower access<font color="#E5E5E5"> are the training iterations</font>

308
00:14:45,259 --> 00:14:52,160
and the dots represent the mind changes

309
00:14:50,420 --> 00:14:53,839
in the first training step there of

310
00:14:52,160 --> 00:14:55,610
course many mind changes because many

311
00:14:53,839 --> 00:14:59,449
new states and transitions are<font color="#CCCCCC"> allocated</font>

312
00:14:55,610 --> 00:15:03,889
and they get less<font color="#E5E5E5"> and less the error</font>

313
00:14:59,449 --> 00:15:06,199
bars in the above graph they they

314
00:15:03,889 --> 00:15:08,329
correspond to the randomness because I

315
00:15:06,199 --> 00:15:10,910
<font color="#E5E5E5">randomly choose an example so I did</font>

316
00:15:08,329 --> 00:15:12,500
these runs several times and measure the

317
00:15:10,910 --> 00:15:15,969
best and the<font color="#CCCCCC"> worst performance this is</font>

318
00:15:12,500 --> 00:15:19,480
why I have error bars in the graphs and

319
00:15:15,970 --> 00:15:22,250
in all<font color="#E5E5E5"> cases that there were only few</font>

320
00:15:19,480 --> 00:15:25,639
examples necessary to converge to a

321
00:15:22,250 --> 00:15:28,850
stable representation the f1's go up is

322
00:15:25,639 --> 00:15:30,829
the overall classification performance f

323
00:15:28,850 --> 00:15:34,160
one hundred percent means that it did

324
00:15:30,829 --> 00:15:37,519
everything right in the<font color="#E5E5E5"> catalog data set</font>

325
00:15:34,160 --> 00:15:39,110
it was about ninety-one percent and then

326
00:15:37,519 --> 00:15:42,970
the other data set the wound shop out

327
00:15:39,110 --> 00:15:45,529
order this<font color="#E5E5E5"> is the the exes to example</font>

328
00:15:42,970 --> 00:15:47,809
where I use the signature wrapping

329
00:15:45,529 --> 00:15:49,399
attack or many signature wrapping

330
00:15:47,809 --> 00:15:53,779
attacks many different combinations<font color="#CCCCCC"> of</font>

331
00:15:49,399 --> 00:15:55,730
them and in this data set usually after

332
00:15:53,779 --> 00:15:58,220
two or three examples they learn<font color="#E5E5E5"> I had</font>

333
00:15:55,730 --> 00:16:01,069
already a representation that was good

334
00:15:58,220 --> 00:16:06,350
enough<font color="#CCCCCC"> to identify hundred percent of</font>

335
00:16:01,069 --> 00:16:10,009
the attacks this was because the Apache

336
00:16:06,350 --> 00:16:11,509
<font color="#E5E5E5">X is 2 is a plug-in where I for form a</font>

337
00:16:10,009 --> 00:16:14,300
chava development where<font color="#CCCCCC"> I right</font>

338
00:16:11,509 --> 00:16:17,449
javabeans and it generates all the<font color="#E5E5E5"> XML</font>

339
00:16:14,300 --> 00:16:19,969
<font color="#E5E5E5">metric behind automatically and because</font>

340
00:16:17,449 --> 00:16:21,729
of this automatic generation the grammar

341
00:16:19,970 --> 00:16:24,459
structures are very rare

342
00:16:21,730 --> 00:16:29,350
stricted so<font color="#E5E5E5"> the learning can be done</font>

343
00:16:24,459 --> 00:16:30,550
very quickly so to sum up in<font color="#E5E5E5"> all the</font>

344
00:16:29,350 --> 00:16:32,139
experiments that the<font color="#E5E5E5"> learned</font>

345
00:16:30,550 --> 00:16:33,910
representation outperformed the

346
00:16:32,139 --> 00:16:36,670
traditional schema validation approach

347
00:16:33,910 --> 00:16:39,069
our signature<font color="#E5E5E5"> wrapping attacks were</font>

348
00:16:36,670 --> 00:16:41,290
detected using this method the classic

349
00:16:39,070 --> 00:16:44,290
schema validation detects none of them

350
00:16:41,290 --> 00:16:46,389
because of<font color="#E5E5E5"> the extension points there</font>

351
00:16:44,290 --> 00:16:48,670
were also<font color="#CCCCCC"> no false positives however</font>

352
00:16:46,389 --> 00:16:51,339
there were some false negatives they

353
00:16:48,670 --> 00:16:53,589
were related to<font color="#E5E5E5"> the data types the data</font>

354
00:16:51,339 --> 00:16:56,459
type extraction of content and<font color="#E5E5E5"> if the</font>

355
00:16:53,589 --> 00:17:00,399
data type gets<font color="#E5E5E5"> too general it accepts</font>

356
00:16:56,459 --> 00:17:02,229
might accept an attack there and there

357
00:17:00,399 --> 00:17:06,309
was also very fast convergence in all

358
00:17:02,230 --> 00:17:08,410
the experiments this was basically<font color="#E5E5E5"> a</font>

359
00:17:06,309 --> 00:17:09,790
rough overview what<font color="#CCCCCC"> I did in the paper</font>

360
00:17:08,410 --> 00:17:12,160
there's of course more they<font color="#CCCCCC"> are the</font>

361
00:17:09,790 --> 00:17:14,649
specifications<font color="#E5E5E5"> for the automata models</font>

362
00:17:12,160 --> 00:17:16,660
there is also the lexical data type

363
00:17:14,650 --> 00:17:19,959
system for in varying data types from

364
00:17:16,660 --> 00:17:23,260
<font color="#CCCCCC">texts used for a data type event stream</font>

365
00:17:19,959 --> 00:17:24,939
and there are also the specifications

366
00:17:23,260 --> 00:17:27,069
<font color="#CCCCCC">for the algorithms for the incremental</font>

367
00:17:24,939 --> 00:17:29,919
learner and also more details in the

368
00:17:27,069 --> 00:17:32,440
experiments how I put<font color="#E5E5E5"> them together so</font>

369
00:17:29,919 --> 00:17:35,290
what<font color="#E5E5E5"> are the use cases of this of course</font>

370
00:17:32,440 --> 00:17:38,230
<font color="#E5E5E5">a security mechanism for XML based into</font>

371
00:17:35,290 --> 00:17:41,530
action<font color="#E5E5E5"> especially when systems use</font>

372
00:17:38,230 --> 00:17:43,690
composed schemas one example the

373
00:17:41,530 --> 00:17:47,350
discount in development is an xml-based

374
00:17:43,690 --> 00:17:49,720
firewall for web services but i<font color="#E5E5E5"> think</font>

375
00:17:47,350 --> 00:17:53,590
this this this method could have more

376
00:17:49,720 --> 00:17:56,760
applications so thank you so much<font color="#CCCCCC"> i'm</font>

377
00:17:53,590 --> 00:17:56,760
ready<font color="#CCCCCC"> for fish</font>

