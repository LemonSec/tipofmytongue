1
00:00:02,480 --> 00:00:08,670
all right so this is gonna be like a

2
00:00:06,200 --> 00:00:10,139
humorous kind of light-hearted talk you

3
00:00:08,670 --> 00:00:13,139
know talking about you know how you can

4
00:00:10,139 --> 00:00:16,289
hack into a computer with an AI but to

5
00:00:13,139 --> 00:00:18,990
begin I kind of wanted to just take a

6
00:00:16,289 --> 00:00:22,710
moment and say thank you to these

7
00:00:18,990 --> 00:00:35,340
individuals here who all of us are here

8
00:00:22,710 --> 00:00:37,140
because of them so this is a ethics free

9
00:00:35,340 --> 00:00:42,809
guide to exploiting deep learning for

10
00:00:37,140 --> 00:00:44,280
fun and profit and you know I signed up

11
00:00:42,809 --> 00:00:47,280
for this talk and like I've never done a

12
00:00:44,280 --> 00:00:48,960
big talk and they told me I was gonna be

13
00:00:47,280 --> 00:00:52,700
speaking in a booth so I was like

14
00:00:48,960 --> 00:00:52,700
alright sweet cuz I'm not qualified to

15
00:00:53,570 --> 00:00:59,370
so this is me at age 11 at MIT I

16
00:00:57,660 --> 00:01:04,709
actually got in trouble for messing with

17
00:00:59,370 --> 00:01:07,950
that computer I've been reading 2600

18
00:01:04,709 --> 00:01:11,189
since I was 11 and I've been dreaming of

19
00:01:07,950 --> 00:01:14,820
coming to hope the entire time so this

20
00:01:11,189 --> 00:01:16,710
is big for me and you know if you're a

21
00:01:14,820 --> 00:01:18,689
parent out there and you catch your kid

22
00:01:16,710 --> 00:01:21,360
you know playing with computers or like

23
00:01:18,689 --> 00:01:22,770
reading 2600 you know it's gonna go one

24
00:01:21,360 --> 00:01:24,659
of two ways right either they're gonna

25
00:01:22,770 --> 00:01:27,479
have like an awesome career and you know

26
00:01:24,659 --> 00:01:28,890
get like amazing experience out of it

27
00:01:27,479 --> 00:01:30,420
you know or they're gonna be like on

28
00:01:28,890 --> 00:01:36,420
stage talking about how they pissed the

29
00:01:30,420 --> 00:01:38,790
government off by making AI so also my

30
00:01:36,420 --> 00:01:41,790
company wants nothing to do with this so

31
00:01:38,790 --> 00:01:45,390
I work for a cyber security company

32
00:01:41,790 --> 00:01:47,990
doing AI for defense and there's a lot

33
00:01:45,390 --> 00:01:50,970
of really cool stuff out there for that

34
00:01:47,990 --> 00:01:52,979
but you know for some reason they didn't

35
00:01:50,970 --> 00:01:56,070
necessarily want me associating their

36
00:01:52,979 --> 00:01:58,350
name with this so in lieu of that I

37
00:01:56,070 --> 00:02:02,570
reached out to threat but so now I'm a

38
00:01:58,350 --> 00:02:06,199
threat but employee threat but is hiring

39
00:02:02,570 --> 00:02:08,940
check out our careers page and see

40
00:02:06,200 --> 00:02:12,650
shouts to all these people over here

41
00:02:08,940 --> 00:02:14,750
they've all been immensely helpful

42
00:02:12,650 --> 00:02:18,980
and not affiliated if I get in trouble

43
00:02:14,750 --> 00:02:21,799
for this I've worked on a number of ML

44
00:02:18,980 --> 00:02:24,440
projects endgame has a really cool

45
00:02:21,799 --> 00:02:27,530
project that I've contributed to just a

46
00:02:24,440 --> 00:02:31,069
handful of other things and this is my

47
00:02:27,530 --> 00:02:34,190
site dot SH is totally a TLD and you can

48
00:02:31,069 --> 00:02:35,510
have one and if you curl that in to bash

49
00:02:34,190 --> 00:02:38,019
there's that there's a special surprise

50
00:02:35,510 --> 00:02:38,018
for you

51
00:02:39,129 --> 00:02:44,268
my twitter is really not safe for work

52
00:02:42,049 --> 00:02:49,640
and my github is like really really not

53
00:02:44,269 --> 00:02:53,329
safe for work so these are some of the

54
00:02:49,640 --> 00:02:56,358
contributors to the project and so there

55
00:02:53,329 --> 00:03:01,159
was a sort of a sort of a think tank out

56
00:02:56,359 --> 00:03:04,159
there for adversary ml called the war

57
00:03:01,159 --> 00:03:07,310
mind which comes from destiny - or

58
00:03:04,159 --> 00:03:10,489
something but either way so they are a

59
00:03:07,310 --> 00:03:12,170
group of InfoSec experts and researchers

60
00:03:10,489 --> 00:03:14,840
you may recognize some of those names up

61
00:03:12,170 --> 00:03:18,950
there for you know other other projects

62
00:03:14,840 --> 00:03:22,630
and so they've kind of been looking into

63
00:03:18,950 --> 00:03:24,589
this and so I have as well and then uh

64
00:03:22,630 --> 00:03:26,540
shouts to Molly

65
00:03:24,590 --> 00:03:28,970
that's not the FSF Molly that's that's

66
00:03:26,540 --> 00:03:32,209
like that Molly she's awesome and then

67
00:03:28,970 --> 00:03:34,579
shouts 2x9 security comm he actually

68
00:03:32,209 --> 00:03:36,500
launched his page early so I could like

69
00:03:34,579 --> 00:03:41,239
say something about it but check that

70
00:03:36,500 --> 00:03:42,739
out okay so disclaimers here I'm not a

71
00:03:41,239 --> 00:03:47,090
real data scientist I learned this

72
00:03:42,739 --> 00:03:48,859
on YouTube also this is the most hope

73
00:03:47,090 --> 00:03:50,660
thing ever because there's like a PhD

74
00:03:48,859 --> 00:03:52,129
electrical engineer over there and you

75
00:03:50,660 --> 00:03:55,569
guys are talking to the guy with a GED

76
00:03:52,129 --> 00:03:55,569
that learned this on YouTube

77
00:03:56,090 --> 00:04:03,269
[Applause]

78
00:03:59,450 --> 00:04:04,950
I'm also not a red teamer can't do CTS

79
00:04:03,269 --> 00:04:07,620
or anything like that so this is this is

80
00:04:04,950 --> 00:04:10,109
gonna be painful for both parties and

81
00:04:07,620 --> 00:04:11,730
you know of course we're InfoSec

82
00:04:10,110 --> 00:04:14,400
professionals this is purely a research

83
00:04:11,730 --> 00:04:15,810
project based on like what's this going

84
00:04:14,400 --> 00:04:20,340
to look like in the future is this

85
00:04:15,810 --> 00:04:22,560
possible now and kind of just both sort

86
00:04:20,339 --> 00:04:24,299
of go into that and then you know don't

87
00:04:22,560 --> 00:04:36,660
don't do anything illegal because of

88
00:04:24,300 --> 00:04:38,160
this talk so you know so you know every

89
00:04:36,660 --> 00:04:39,539
every talk kind of has an agenda I

90
00:04:38,160 --> 00:04:40,770
wanted to throw mine out there this is

91
00:04:39,539 --> 00:04:44,430
the stuff you have to get through before

92
00:04:40,770 --> 00:04:46,590
you watch an AI pop a box I'm gonna do

93
00:04:44,430 --> 00:04:49,560
some like software freedom talks related

94
00:04:46,590 --> 00:04:50,549
to AI the current future state stuff

95
00:04:49,560 --> 00:04:52,650
like that

96
00:04:50,550 --> 00:04:54,539
and then there's gonna be like 20

97
00:04:52,650 --> 00:05:01,138
minutes me being like whoa tensorflow is

98
00:04:54,539 --> 00:05:03,539
cool ai liberation so this is a neural

99
00:05:01,139 --> 00:05:06,270
network no I'm sorry this is a printing

100
00:05:03,539 --> 00:05:08,849
press and kind of you know hopefully

101
00:05:06,270 --> 00:05:14,099
everyone here hold on let me scroll down

102
00:05:08,849 --> 00:05:15,240
on Emacs real quick okay so everyone

103
00:05:14,099 --> 00:05:18,180
kind of knows the story here right where

104
00:05:15,240 --> 00:05:21,960
there's this person named Guttenberg in

105
00:05:18,180 --> 00:05:24,840
like the 1400s who designed this thing

106
00:05:21,960 --> 00:05:27,680
and before then only like six people in

107
00:05:24,840 --> 00:05:27,679
Europe knew how to read

108
00:05:28,319 --> 00:05:36,009
and then you know they started releasing

109
00:05:31,990 --> 00:05:37,389
books and that rate skyrocketed and and

110
00:05:36,009 --> 00:05:39,069
because of that you know people could

111
00:05:37,389 --> 00:05:41,169
read the Bible whereas before that

112
00:05:39,069 --> 00:05:42,219
they're their priests or whatever we're

113
00:05:41,169 --> 00:05:45,430
the only ones that could and you know

114
00:05:42,219 --> 00:05:47,620
Protestantism happened but what they

115
00:05:45,430 --> 00:05:49,449
don't tell you there at least I didn't

116
00:05:47,620 --> 00:05:50,979
know I so I was I was looking at but

117
00:05:49,449 --> 00:05:52,449
what a printing press costs because I

118
00:05:50,979 --> 00:05:54,609
was gonna make this really lame point of

119
00:05:52,449 --> 00:05:56,889
like oh it wasn't free so normal people

120
00:05:54,610 --> 00:05:59,650
couldn't have a printing press so fun

121
00:05:56,889 --> 00:06:00,639
facts like $5,000 today money but that's

122
00:05:59,650 --> 00:06:01,539
not the interesting thing the

123
00:06:00,639 --> 00:06:03,699
interesting thing is that Gutenberg

124
00:06:01,539 --> 00:06:05,770
never sold the printing press he kept it

125
00:06:03,699 --> 00:06:08,020
a secret so if you wanted a printing

126
00:06:05,770 --> 00:06:10,090
press you had to take five thousand

127
00:06:08,020 --> 00:06:11,710
dollars just of material and then spend

128
00:06:10,090 --> 00:06:13,590
like your entire life apprentices and

129
00:06:11,710 --> 00:06:15,789
mastering this thing working in a shop

130
00:06:13,590 --> 00:06:17,739
memorizing every single component and

131
00:06:15,789 --> 00:06:20,680
how they worked start your own shop and

132
00:06:17,740 --> 00:06:22,719
build one from memory and for 200 years

133
00:06:20,680 --> 00:06:27,819
that's how we did printing it was it was

134
00:06:22,719 --> 00:06:31,060
it was a secret so then that's such a

135
00:06:27,819 --> 00:06:33,819
good picture so this guy came along and

136
00:06:31,060 --> 00:06:37,349
I hadn't heard of this individual Josef

137
00:06:33,819 --> 00:06:39,969
Moxon so it turns out Joseph Moxon in

138
00:06:37,349 --> 00:06:42,069
1683 was the first person to published

139
00:06:39,969 --> 00:06:44,379
plans and instructions on how to do

140
00:06:42,069 --> 00:06:47,439
printing on a printing press so it took

141
00:06:44,379 --> 00:06:49,089
us 200 years so like think about that

142
00:06:47,439 --> 00:06:50,649
rate so Gutenberg whose name is

143
00:06:49,089 --> 00:06:53,740
literally synonymous with information

144
00:06:50,649 --> 00:06:55,919
freedom was like Microsoft in like the

145
00:06:53,740 --> 00:06:58,949
mid 80s right

146
00:06:55,919 --> 00:07:03,599
and then this guy of course is like the

147
00:06:58,949 --> 00:07:06,150
RMS of like the 1600s shell star man

148
00:07:03,599 --> 00:07:07,919
so but the really cool thing about

149
00:07:06,150 --> 00:07:10,198
Joseph Moxon like I went down this crazy

150
00:07:07,919 --> 00:07:12,029
Wikipedia rabbit hole one night doing

151
00:07:10,199 --> 00:07:13,379
this he did he didn't just do the

152
00:07:12,029 --> 00:07:16,710
printing press that this guy was self

153
00:07:13,379 --> 00:07:17,969
educated his father was a tradesman he

154
00:07:16,710 --> 00:07:20,460
was a tradesman but he just liked

155
00:07:17,969 --> 00:07:23,039
messing with stuff and he wrote like our

156
00:07:20,460 --> 00:07:26,219
first guy did the print press obviously

157
00:07:23,039 --> 00:07:28,830
but also some of our first books on like

158
00:07:26,219 --> 00:07:31,949
woodworking and like weird like abstract

159
00:07:28,830 --> 00:07:34,469
old-timey math these titles are great

160
00:07:31,949 --> 00:07:39,960
like mathematics made easy spelled all

161
00:07:34,469 --> 00:07:43,289
all old timey but I guess so my point is

162
00:07:39,960 --> 00:07:45,840
right is that Joseph Moxon was was an OG

163
00:07:43,289 --> 00:07:49,039
hacker he took this thing that he had

164
00:07:45,840 --> 00:07:51,119
the foresight to see is going to be

165
00:07:49,039 --> 00:07:52,860
artists all right was incredibly

166
00:07:51,120 --> 00:07:57,960
important to to our culture and how he

167
00:07:52,860 --> 00:08:00,949
grew and he knew that that needed to be

168
00:07:57,960 --> 00:08:04,919
free that needed to be a public resource

169
00:08:00,949 --> 00:08:07,500
fortunately nowadays you know free and

170
00:08:04,919 --> 00:08:10,169
open source software is is kind of the

171
00:08:07,500 --> 00:08:11,899
way we do things and so with artificial

172
00:08:10,169 --> 00:08:15,089
intelligence this technology that's

173
00:08:11,899 --> 00:08:16,919
affecting everything in our lives we

174
00:08:15,089 --> 00:08:18,449
have the bleeding edge like you can go

175
00:08:16,919 --> 00:08:20,399
download tensorflow right now and they

176
00:08:18,449 --> 00:08:25,550
use that in the drones they're in

177
00:08:20,399 --> 00:08:28,830
drone research I'm sorry so like the

178
00:08:25,550 --> 00:08:31,830
that's kind of what this kind of rant is

179
00:08:28,830 --> 00:08:33,750
about right is is that we we have this

180
00:08:31,830 --> 00:08:35,909
right now we can learn this I learned

181
00:08:33,750 --> 00:08:37,380
this on YouTube and I have a GED like a

182
00:08:35,909 --> 00:08:39,750
lot of you are really really smart

183
00:08:37,380 --> 00:08:41,698
people all of you are and like we need

184
00:08:39,750 --> 00:08:46,519
to start hacking on this stuff so why

185
00:08:41,698 --> 00:08:46,519
don't we well there's

186
00:08:47,240 --> 00:08:51,660
there there's a lot of uncertainty right

187
00:08:49,560 --> 00:08:52,888
now it's it's um you know the the

188
00:08:51,660 --> 00:08:55,589
current narrative of artificial

189
00:08:52,889 --> 00:08:57,600
intelligence or you know whatever word

190
00:08:55,589 --> 00:08:59,399
we want to call it is that it's really

191
00:08:57,600 --> 00:09:01,529
scary and that people can do really bad

192
00:08:59,399 --> 00:09:05,420
things with it like make AI that can pop

193
00:09:01,529 --> 00:09:12,269
boxes and so we get a lot of crazy news

194
00:09:05,420 --> 00:09:16,229
like this and and this and and this and

195
00:09:12,269 --> 00:09:20,399
it's honestly like I'm not trained in

196
00:09:16,230 --> 00:09:21,930
this type of thing but like if you know

197
00:09:20,399 --> 00:09:24,480
like the first thing about a computer

198
00:09:21,930 --> 00:09:26,670
you know that this is ridiculous

199
00:09:24,480 --> 00:09:28,410
it's it's it's not even part of the

200
00:09:26,670 --> 00:09:31,680
story and it's not even boiled down to

201
00:09:28,410 --> 00:09:33,269
something that non tech people can

202
00:09:31,680 --> 00:09:35,609
understand it's just absolute garbage

203
00:09:33,269 --> 00:09:37,550
and it's not the truth and then you get

204
00:09:35,610 --> 00:09:40,050
stuff like this this article came out

205
00:09:37,550 --> 00:09:41,790
like a week ago and it's my favorite

206
00:09:40,050 --> 00:09:44,279
thing ever so top line right Microsoft

207
00:09:41,790 --> 00:09:50,790
calls for AI regulation bottom line were

208
00:09:44,279 --> 00:09:53,670
totally buying into it and then this guy

209
00:09:50,790 --> 00:09:56,599
right mister like AI Fudd himself is

210
00:09:53,670 --> 00:10:03,689
saying it's more dangerous than nukes

211
00:09:56,600 --> 00:10:06,269
it's an existential threat and then he

212
00:10:03,689 --> 00:10:12,000
goes and does this and that's the

213
00:10:06,269 --> 00:10:13,589
story all over is you know we as normal

214
00:10:12,000 --> 00:10:15,720
people who have access to this shouldn't

215
00:10:13,589 --> 00:10:17,880
have access to it but they totally

216
00:10:15,720 --> 00:10:20,639
should and let's buy in and regulate the

217
00:10:17,880 --> 00:10:23,519
hell out of it and then the marketing to

218
00:10:20,639 --> 00:10:25,199
make AI less scary you know they're not

219
00:10:23,519 --> 00:10:28,920
argue or they're not advertising like

220
00:10:25,199 --> 00:10:31,050
mass anomaly detection or you know crazy

221
00:10:28,920 --> 00:10:33,329
Bayesian networks to track you there

222
00:10:31,050 --> 00:10:36,689
they're doing stuff like this they're

223
00:10:33,329 --> 00:10:38,189
teaching them to play dota which is

224
00:10:36,689 --> 00:10:43,680
impressive because because I'm an lol

225
00:10:38,189 --> 00:10:45,809
player DotA's real hard and then they do

226
00:10:43,680 --> 00:10:47,489
stuff like this right this AI chat bot

227
00:10:45,809 --> 00:10:49,920
that talks to your kids and oh that's

228
00:10:47,490 --> 00:10:51,410
super cute and then this even cooler AI

229
00:10:49,920 --> 00:10:55,170
chat BOTS that talks to your kids

230
00:10:51,410 --> 00:10:55,170
[Laughter]

231
00:10:55,850 --> 00:11:03,959
so this is kind of summing up the point

232
00:10:58,529 --> 00:11:09,630
here right is is that is that the this

233
00:11:03,959 --> 00:11:10,800
is like my first talk so so those who

234
00:11:09,630 --> 00:11:13,500
would profit off of making this

235
00:11:10,800 --> 00:11:15,270
inaccessible are benefiting from us not

236
00:11:13,500 --> 00:11:17,910
knowing anything about it and at the

237
00:11:15,270 --> 00:11:23,449
very least benefiting at in some cases

238
00:11:17,910 --> 00:11:26,219
like contributing to it come on

239
00:11:23,450 --> 00:11:28,890
so once kind of cut through some of the

240
00:11:26,220 --> 00:11:29,339
uncertainty in doubt and things like

241
00:11:28,890 --> 00:11:32,580
that

242
00:11:29,339 --> 00:11:35,250
what is AI now I if you talk to like any

243
00:11:32,580 --> 00:11:37,709
grown up data scientist they'll probably

244
00:11:35,250 --> 00:11:39,779
not call it AI I call it AI because I

245
00:11:37,709 --> 00:11:41,880
really love cyberpunk and and it's it

246
00:11:39,779 --> 00:11:45,209
sounds much cooler than deep learning

247
00:11:41,880 --> 00:11:47,430
I think but so the general gist of this

248
00:11:45,209 --> 00:11:50,609
thing right is that AI is is a really

249
00:11:47,430 --> 00:11:53,729
old term and it's any computer that can

250
00:11:50,610 --> 00:11:54,930
kind of emulate tasks so like something

251
00:11:53,730 --> 00:11:56,339
that can play pong against you as

252
00:11:54,930 --> 00:11:58,859
artificial intelligence it's something

253
00:11:56,339 --> 00:12:01,290
that emulates human intelligence machine

254
00:11:58,860 --> 00:12:04,529
learning is is when an algorithm adjusts

255
00:12:01,290 --> 00:12:06,240
itself based on previous knowledge or

256
00:12:04,529 --> 00:12:09,660
trained knowledge and then deep learning

257
00:12:06,240 --> 00:12:12,209
is when you use these like deep neural

258
00:12:09,660 --> 00:12:14,250
networks to do these wild convolutions

259
00:12:12,209 --> 00:12:16,500
and things like that so that's kind of

260
00:12:14,250 --> 00:12:19,410
the gist of it you'll hear them all used

261
00:12:16,500 --> 00:12:21,000
kind of interchangeably and that's kind

262
00:12:19,410 --> 00:12:23,670
of how it is right now so what can they

263
00:12:21,000 --> 00:12:24,360
do was like what can that cannot do so

264
00:12:23,670 --> 00:12:26,219
they're very good at things like

265
00:12:24,360 --> 00:12:27,360
classification right hot dog or not hot

266
00:12:26,220 --> 00:12:30,899
dog

267
00:12:27,360 --> 00:12:32,520
things like regression predicting if a

268
00:12:30,899 --> 00:12:34,529
customer is going to churn or not or

269
00:12:32,520 --> 00:12:40,230
predicting like the price of a house

270
00:12:34,529 --> 00:12:41,970
based on certain data clustering so your

271
00:12:40,230 --> 00:12:43,110
social network is a cluster you know

272
00:12:41,970 --> 00:12:44,970
someone who knows someone who knows

273
00:12:43,110 --> 00:12:47,940
someone you all happen to share a

274
00:12:44,970 --> 00:12:51,779
certain hashtag and then learning

275
00:12:47,940 --> 00:12:54,270
inductive bias which is a a big academic

276
00:12:51,779 --> 00:12:56,910
word that I can kind of sum up as it

277
00:12:54,270 --> 00:13:00,089
tries things and then figures out why it

278
00:12:56,910 --> 00:13:01,980
is succeeds and why it doesn't what is

279
00:13:00,089 --> 00:13:03,510
it not good at it's not good at decision

280
00:13:01,980 --> 00:13:05,040
making without rules so you you need to

281
00:13:03,510 --> 00:13:07,740
write the code

282
00:13:05,040 --> 00:13:12,089
if you saw the code for for the upcoming

283
00:13:07,740 --> 00:13:14,550
demo it's like mostly alright go here

284
00:13:12,090 --> 00:13:17,070
now go here go here now do this

285
00:13:14,550 --> 00:13:18,390
algorithm that you figured out they're

286
00:13:17,070 --> 00:13:20,550
not good at unstructured thought we

287
00:13:18,390 --> 00:13:22,740
don't have general AI they can't broadly

288
00:13:20,550 --> 00:13:24,660
infer things and data is really really

289
00:13:22,740 --> 00:13:28,200
messy and it's a real pain to kind of

290
00:13:24,660 --> 00:13:31,469
hurt in to encapsulate and scale it so

291
00:13:28,200 --> 00:13:32,730
that you can train models with it so

292
00:13:31,470 --> 00:13:34,800
defense of AI is really big business

293
00:13:32,730 --> 00:13:36,480
it's it's a big buzzword and everyone's

294
00:13:34,800 --> 00:13:38,339
doing it I've like a Splunk sticker on

295
00:13:36,480 --> 00:13:40,650
my laptop shots to Splunk but like

296
00:13:38,340 --> 00:13:42,570
everyone's doing it to some degree and

297
00:13:40,650 --> 00:13:44,870
some of these I'm not like pointing

298
00:13:42,570 --> 00:13:48,540
fingers but some of these are very

299
00:13:44,870 --> 00:13:50,070
loosely what we would consider AI

300
00:13:48,540 --> 00:13:52,469
they're like very good statistics

301
00:13:50,070 --> 00:13:55,500
algorithms and then some of them shell

302
00:13:52,470 --> 00:13:59,460
so the Canadian government are seriously

303
00:13:55,500 --> 00:14:02,010
are doing very deep interesting studies

304
00:13:59,460 --> 00:14:04,890
into it but who's looking at offensive

305
00:14:02,010 --> 00:14:09,689
AI who's looking at things that can can

306
00:14:04,890 --> 00:14:12,510
attack and make decisions adversarially

307
00:14:09,690 --> 00:14:14,220
well and this is real dramatic I'm sorry

308
00:14:12,510 --> 00:14:15,930
anyone that anyone in this room

309
00:14:14,220 --> 00:14:19,610
considers evil is probably doing it

310
00:14:15,930 --> 00:14:19,609
depending on who that is

311
00:14:24,020 --> 00:14:33,199
so let's make one oh wait I was supposed

312
00:14:27,649 --> 00:14:36,380
to say it say that yet so so what so

313
00:14:33,200 --> 00:14:38,270
what's going on in in in today's world

314
00:14:36,380 --> 00:14:40,610
right well there's some existing

315
00:14:38,270 --> 00:14:42,050
projects some of these are deep learning

316
00:14:40,610 --> 00:14:43,279
some of these are artificial

317
00:14:42,050 --> 00:14:46,310
intelligence some of these are really

318
00:14:43,279 --> 00:14:47,630
cool graph algorithms endgame is doing a

319
00:14:46,310 --> 00:14:50,209
lot of studies into this they've

320
00:14:47,630 --> 00:14:52,160
contributed a whole lot to both sides of

321
00:14:50,209 --> 00:14:53,829
the artificial intelligence in

322
00:14:52,160 --> 00:14:56,810
cybersecurity communities

323
00:14:53,830 --> 00:14:58,040
bloodhound is not traditional deep

324
00:14:56,810 --> 00:14:59,479
artificial intelligence but I would

325
00:14:58,040 --> 00:15:01,939
argue that bloodhound and even things

326
00:14:59,480 --> 00:15:04,930
like multigo that can do deep graph

327
00:15:01,940 --> 00:15:07,250
related correlations are to some degree

328
00:15:04,930 --> 00:15:11,599
artificial intelligence and then there's

329
00:15:07,250 --> 00:15:13,430
deep exploit so deep exploit there are

330
00:15:11,600 --> 00:15:15,880
very similar projects to this project

331
00:15:13,430 --> 00:15:17,510
and they're presenting at blackhat and

332
00:15:15,880 --> 00:15:20,200
hey guys

333
00:15:17,510 --> 00:15:28,670
deep exploit if you're watching this I

334
00:15:20,200 --> 00:15:32,480
challenge you to in AI fight they have

335
00:15:28,670 --> 00:15:35,839
cooler ASCII art than me so let's talk

336
00:15:32,480 --> 00:15:37,250
about really scary things now so what

337
00:15:35,839 --> 00:15:39,230
are some scenarios that we kind of have

338
00:15:37,250 --> 00:15:44,480
to actually be worried about and it's

339
00:15:39,230 --> 00:15:46,070
it's not Skynet OS Inc correlations ml

340
00:15:44,480 --> 00:15:48,260
right now is very good at correlating

341
00:15:46,070 --> 00:15:50,959
things and it's just going to get better

342
00:15:48,260 --> 00:15:54,160
we don't need as large of datasets to

343
00:15:50,959 --> 00:15:58,160
train on as we did before and we can

344
00:15:54,160 --> 00:16:00,860
scale and handle more and more powerful

345
00:15:58,160 --> 00:16:03,890
pieces of software on our normal

346
00:16:00,860 --> 00:16:05,839
computers and so adversaries and bad

347
00:16:03,890 --> 00:16:10,579
guys and you know the government are

348
00:16:05,839 --> 00:16:13,190
going to be using this to correlate all

349
00:16:10,579 --> 00:16:14,540
kinds of things what times do you

350
00:16:13,190 --> 00:16:17,089
normally tweet well that gives away

351
00:16:14,540 --> 00:16:18,920
where you live what dialect do you use

352
00:16:17,089 --> 00:16:20,360
that gives away specifically where you

353
00:16:18,920 --> 00:16:23,479
live and what community you're involved

354
00:16:20,360 --> 00:16:26,000
with things like that

355
00:16:23,480 --> 00:16:28,250
OS ant crawling stole Emma Tree is

356
00:16:26,000 --> 00:16:30,529
really interesting so you can train a

357
00:16:28,250 --> 00:16:32,390
network on someone's speech patterns and

358
00:16:30,529 --> 00:16:35,510
then D anonymize them so if you have

359
00:16:32,390 --> 00:16:37,279
like say someone posting hate speech and

360
00:16:35,510 --> 00:16:38,930
you know their Twitter

361
00:16:37,279 --> 00:16:40,579
all of a sudden now you can find them on

362
00:16:38,930 --> 00:16:43,040
the things that they don't want you to

363
00:16:40,579 --> 00:16:45,498
know the traffic analysis pattern

364
00:16:43,040 --> 00:16:48,709
recognition things like that deep social

365
00:16:45,499 --> 00:16:50,959
engineering also shout outs to Chelsea

366
00:16:48,709 --> 00:16:54,290
Manning I'm really stoked to hear that

367
00:16:50,959 --> 00:16:56,300
she's playing with tensor flow and

368
00:16:54,290 --> 00:16:58,099
things like that it's very exciting but

369
00:16:56,300 --> 00:17:01,089
she brought up deep social engineering

370
00:16:58,100 --> 00:17:03,980
in a way that I hadn't even thought of

371
00:17:01,089 --> 00:17:05,120
so sentiment analysis is and you take

372
00:17:03,980 --> 00:17:06,319
all the tweets about your company and

373
00:17:05,119 --> 00:17:09,889
figure out if people like you or not is

374
00:17:06,319 --> 00:17:12,139
a real common use case right now but we

375
00:17:09,890 --> 00:17:16,100
can is arguably potentially use this in

376
00:17:12,140 --> 00:17:18,740
Reverse to figure out who is saying

377
00:17:16,099 --> 00:17:20,629
negative things and give that an impact

378
00:17:18,740 --> 00:17:22,959
and figure out why that has more of an

379
00:17:20,630 --> 00:17:25,850
impact than other things figure out

380
00:17:22,959 --> 00:17:27,049
certain terminology certain phrases in

381
00:17:25,849 --> 00:17:31,059
certain communities where you can have

382
00:17:27,049 --> 00:17:35,150
the most impact to essentially socially

383
00:17:31,059 --> 00:17:39,490
drop these things to spread and reduce

384
00:17:35,150 --> 00:17:39,490
the sentiment of an organization

385
00:17:39,520 --> 00:17:43,789
psychological factors we're already

386
00:17:41,600 --> 00:17:46,370
doing this but we can determine an

387
00:17:43,789 --> 00:17:48,799
individual's needs fears and vices just

388
00:17:46,370 --> 00:17:51,229
from like your Twitter feed and

389
00:17:48,799 --> 00:17:53,120
mass-scale psyops and and mimetic

390
00:17:51,230 --> 00:17:54,440
manipulation with which she also brought

391
00:17:53,120 --> 00:17:59,570
up which I thought was very interesting

392
00:17:54,440 --> 00:18:01,809
so take that times 10 it's what

393
00:17:59,570 --> 00:18:04,879
Twitter's doing they're manipulating

394
00:18:01,809 --> 00:18:08,899
your feed for better or worse to get you

395
00:18:04,880 --> 00:18:10,640
to respond more and in doing that is has

396
00:18:08,899 --> 00:18:14,750
been proven to make people depressed and

397
00:18:10,640 --> 00:18:18,159
anxious and things like this automated

398
00:18:14,750 --> 00:18:23,299
phishing that's also cool and

399
00:18:18,159 --> 00:18:25,340
intelligent persistent threats so the

400
00:18:23,299 --> 00:18:26,600
deep queue algorithm and I'm probably

401
00:18:25,340 --> 00:18:29,360
totally wrong in this but that's what

402
00:18:26,600 --> 00:18:30,620
alphago uses but we can actually gamify

403
00:18:29,360 --> 00:18:32,620
network penetration which is kind of

404
00:18:30,620 --> 00:18:38,178
what this project is is attempting to do

405
00:18:32,620 --> 00:18:40,428
we can analyze targets attempt to avoid

406
00:18:38,179 --> 00:18:42,740
being detected and blend in and the

407
00:18:40,429 --> 00:18:45,169
really interesting thing is that in AI

408
00:18:42,740 --> 00:18:46,669
apt which sounds like something that

409
00:18:45,169 --> 00:18:48,800
threat but would come up with as far as

410
00:18:46,669 --> 00:18:51,059
a term

411
00:18:48,800 --> 00:18:52,980
would be extremely difficult to

412
00:18:51,059 --> 00:18:55,800
attribute if one of those things gets

413
00:18:52,980 --> 00:18:59,720
loose you're dealing with like a model

414
00:18:55,800 --> 00:19:03,659
and some Python code that's branched out

415
00:18:59,720 --> 00:19:06,450
so anonymous actor is statistical attack

416
00:19:03,660 --> 00:19:22,070
modeling behavior emulation and that's

417
00:19:06,450 --> 00:19:24,690
really scary and let's build one okay so

418
00:19:22,070 --> 00:19:26,100
I'm gonna explain how deep learning

419
00:19:24,690 --> 00:19:28,500
works real quick so it's it's actually

420
00:19:26,100 --> 00:19:29,490
really simple you start with the neural

421
00:19:28,500 --> 00:19:31,620
network this is actually a neural

422
00:19:29,490 --> 00:19:33,450
network you do some back propagation

423
00:19:31,620 --> 00:19:36,899
once you push the data through you have

424
00:19:33,450 --> 00:19:41,400
some stochastic gradient descent and

425
00:19:36,900 --> 00:19:43,679
some goal reduction phase and then this

426
00:19:41,400 --> 00:19:47,760
is a tensor this is a tensor and you put

427
00:19:43,679 --> 00:19:51,030
this into a tensor flow and then you get

428
00:19:47,760 --> 00:19:54,210
some deep learning and then you do some

429
00:19:51,030 --> 00:19:59,010
science and some physics and then you do

430
00:19:54,210 --> 00:20:01,500
some code I actually wrote that and you

431
00:19:59,010 --> 00:20:08,400
get some more memes and now you have

432
00:20:01,500 --> 00:20:11,340
artificial intelligence so I'm obviously

433
00:20:08,400 --> 00:20:13,110
a real big William Gibson fan please

434
00:20:11,340 --> 00:20:17,100
don't sue me William Gibson cuz I used a

435
00:20:13,110 --> 00:20:18,870
bunch of your like names in this but the

436
00:20:17,100 --> 00:20:20,428
idea of this book and if you haven't

437
00:20:18,870 --> 00:20:22,110
read this book like don't take anything

438
00:20:20,429 --> 00:20:25,380
else away from this talk leave now go

439
00:20:22,110 --> 00:20:27,300
buy Neuromancer because it's amazing and

440
00:20:25,380 --> 00:20:29,940
I'm gonna really grossly sum up

441
00:20:27,300 --> 00:20:33,649
Neuromancer to offend any sci-fi nerd

442
00:20:29,940 --> 00:20:33,650
it's to a eyes fighting

443
00:20:34,730 --> 00:20:40,760
uh-huh and so you know being someone

444
00:20:38,360 --> 00:20:43,729
that works on defensive AI we started

445
00:20:40,760 --> 00:20:45,640
thinking well that's kind of neat we

446
00:20:43,730 --> 00:20:47,840
have something that's defensive and

447
00:20:45,640 --> 00:20:49,760
training data is very hard to get

448
00:20:47,840 --> 00:20:51,830
especially for defensive AI like we're

449
00:20:49,760 --> 00:20:53,960
dealing with like I'm probably not

450
00:20:51,830 --> 00:20:55,520
allowed to talk about that dealing with

451
00:20:53,960 --> 00:20:58,370
datasets and you have limited datasets

452
00:20:55,520 --> 00:21:00,650
so we were using automated scripting and

453
00:20:58,370 --> 00:21:02,149
other things to generate data trying to

454
00:21:00,650 --> 00:21:05,120
pull from different repositories shouts

455
00:21:02,150 --> 00:21:06,410
to the Canadian government and trying to

456
00:21:05,120 --> 00:21:08,389
label this data so we can build

457
00:21:06,410 --> 00:21:13,070
correlation engines and things like that

458
00:21:08,390 --> 00:21:14,990
to categorize attack data so I said hey

459
00:21:13,070 --> 00:21:17,210
you know I was I was I was in the office

460
00:21:14,990 --> 00:21:19,160
super late coding and I just read

461
00:21:17,210 --> 00:21:21,080
Neuromancer and I said hey let's just

462
00:21:19,160 --> 00:21:22,880
make an AI that can do a tax and then we

463
00:21:21,080 --> 00:21:25,220
have two things to train against each

464
00:21:22,880 --> 00:21:29,240
other it's a generative adversarial

465
00:21:25,220 --> 00:21:32,180
network with such a buzzword plus it's

466
00:21:29,240 --> 00:21:33,950
awesome Neuromancer so it turns out when

467
00:21:32,180 --> 00:21:37,390
you go to your boss actually my boss is

468
00:21:33,950 --> 00:21:39,740
really cool I'm not gonna name his name

469
00:21:37,390 --> 00:21:42,140
but he was stoked on it but everyone

470
00:21:39,740 --> 00:21:44,240
else was like really not stoked on it

471
00:21:42,140 --> 00:21:46,610
apparently you know you tell individuals

472
00:21:44,240 --> 00:21:48,320
that you want to put a hacker AI in

473
00:21:46,610 --> 00:21:53,179
their network and they get all oh don't

474
00:21:48,320 --> 00:21:54,290
don't don't start Skynet and so this

475
00:21:53,180 --> 00:21:57,440
thing's open source and I'm not allowed

476
00:21:54,290 --> 00:22:01,070
to name my company anymore so you start

477
00:21:57,440 --> 00:22:02,990
by saying what you want right so we

478
00:22:01,070 --> 00:22:05,629
wanted it to behave like an actual actor

479
00:22:02,990 --> 00:22:08,360
analyze the network environment and use

480
00:22:05,630 --> 00:22:12,470
deep learning to determine which are the

481
00:22:08,360 --> 00:22:15,139
best points to attack what would a bad

482
00:22:12,470 --> 00:22:18,080
guy do so this is kind of what the thing

483
00:22:15,140 --> 00:22:19,700
looked like initially you have nmap

484
00:22:18,080 --> 00:22:22,939
hopefully everyone knows and Matt if not

485
00:22:19,700 --> 00:22:25,520
it's a support scanner thing you scan

486
00:22:22,940 --> 00:22:27,290
the parts of a machine and then you get

487
00:22:25,520 --> 00:22:29,000
all this data and you have a trained

488
00:22:27,290 --> 00:22:32,090
model that's what that is that's a

489
00:22:29,000 --> 00:22:33,500
neural network to take that data and

490
00:22:32,090 --> 00:22:37,340
make a prediction on what the best

491
00:22:33,500 --> 00:22:37,970
attack in MSF would be so that's really

492
00:22:37,340 --> 00:22:39,889
cool

493
00:22:37,970 --> 00:22:42,830
but it turns out someone already made it

494
00:22:39,890 --> 00:22:44,150
oh wait and it's called a von scanner

495
00:22:42,830 --> 00:22:50,560
and

496
00:22:44,150 --> 00:22:52,640
so I made a shitty Voland scanner so I

497
00:22:50,560 --> 00:22:57,010
actually came up with this incredible

498
00:22:52,640 --> 00:23:01,010
algorithm to determine the math words of

499
00:22:57,010 --> 00:23:04,610
that to replace this entire project here

500
00:23:01,010 --> 00:23:14,080
with like one line of code and it's a

501
00:23:04,610 --> 00:23:17,659
sequel join so I took so the NIS T

502
00:23:14,080 --> 00:23:21,730
provided everyone with the CVE database

503
00:23:17,660 --> 00:23:24,830
which is sweet and rapid7

504
00:23:21,730 --> 00:23:26,390
provided all of us with Metasploit so

505
00:23:24,830 --> 00:23:28,310
you parse through Metasploit pull the

506
00:23:26,390 --> 00:23:30,370
CVS out of Metasploit do a join and now

507
00:23:28,310 --> 00:23:32,659
you have a table that tells you

508
00:23:30,370 --> 00:23:34,399
essentially what CVE is tied to what

509
00:23:32,660 --> 00:23:37,840
Metasploit module the platform the

510
00:23:34,400 --> 00:23:37,840
version all the other data about it I

511
00:23:37,930 --> 00:23:45,290
think I missed one no oh yeah Eris so uh

512
00:23:42,460 --> 00:23:49,820
Wintermute is kind of what we call this

513
00:23:45,290 --> 00:23:51,940
project and here's the questions we're

514
00:23:49,820 --> 00:23:54,500
asking so from historical experience

515
00:23:51,940 --> 00:23:58,060
what's the best thing to do from

516
00:23:54,500 --> 00:24:00,980
environmental data what effects that and

517
00:23:58,060 --> 00:24:04,040
network architecture knowledge what lies

518
00:24:00,980 --> 00:24:05,560
behind the port if it's a Maya you know

519
00:24:04,040 --> 00:24:08,210
if it's a my sequel well there might be

520
00:24:05,560 --> 00:24:09,860
some other things behind it if it looks

521
00:24:08,210 --> 00:24:13,160
like an ad there's definitely ad behind

522
00:24:09,860 --> 00:24:15,290
it things like that so let's talk about

523
00:24:13,160 --> 00:24:18,680
the tech stack I'm a coder so I really

524
00:24:15,290 --> 00:24:22,450
you know this is my jam here so I use

525
00:24:18,680 --> 00:24:26,360
Python with tensorflow and caris and

526
00:24:22,450 --> 00:24:30,860
pandas those are all ml or big data

527
00:24:26,360 --> 00:24:32,840
related my very tensorflow is used for

528
00:24:30,860 --> 00:24:34,340
machine learning and working with

529
00:24:32,840 --> 00:24:36,560
tensors that's that's a math thing I

530
00:24:34,340 --> 00:24:37,909
can't explain to you guys and Karis is a

531
00:24:36,560 --> 00:24:39,679
deep learning library that wraps

532
00:24:37,910 --> 00:24:44,390
tensorflow and makes it easy for people

533
00:24:39,680 --> 00:24:50,000
like me to do those math things and that

534
00:24:44,390 --> 00:24:51,800
is come on SCAP ii which which is a

535
00:24:50,000 --> 00:24:53,120
security python library you can craft

536
00:24:51,800 --> 00:24:56,120
packets and things like that it's very

537
00:24:53,120 --> 00:24:57,719
cool and then we docker eyes that that's

538
00:24:56,120 --> 00:25:02,580
the best Kali logo

539
00:24:57,720 --> 00:25:05,280
by the way and we threw in a graph

540
00:25:02,580 --> 00:25:06,629
database which we'll be talking about in

541
00:25:05,280 --> 00:25:10,110
a minute as well to do these

542
00:25:06,630 --> 00:25:12,600
correlations so here's kind of the

543
00:25:10,110 --> 00:25:15,449
architecture of the thing we have a

544
00:25:12,600 --> 00:25:19,860
reconnaissance mode it's given an

545
00:25:15,450 --> 00:25:23,220
initial state ie ping scan it's scaled

546
00:25:19,860 --> 00:25:25,409
analyzed and all the useful data is

547
00:25:23,220 --> 00:25:27,540
tokenized so you take the data you

548
00:25:25,410 --> 00:25:30,090
encode it a hash it and I have a token

549
00:25:27,540 --> 00:25:35,070
and then it looks it up in this graph

550
00:25:30,090 --> 00:25:36,840
database ie the join table and it

551
00:25:35,070 --> 00:25:38,760
decides on a subsection of the targets

552
00:25:36,840 --> 00:25:44,790
as in what's the most interesting once

553
00:25:38,760 --> 00:25:48,510
they're scored and it moves in so does

554
00:25:44,790 --> 00:25:50,220
this a couple times and it might find

555
00:25:48,510 --> 00:25:52,410
that a target is less interesting than

556
00:25:50,220 --> 00:25:53,880
the larger picture and it might back off

557
00:25:52,410 --> 00:25:57,600
and look at other things and it attempts

558
00:25:53,880 --> 00:26:01,140
to maximize the interest rating of a

559
00:25:57,600 --> 00:26:03,719
target once it's zeroed in on it's given

560
00:26:01,140 --> 00:26:06,870
a score to say how likely it is to be

561
00:26:03,720 --> 00:26:09,270
vulnerable yeah we went through this

562
00:26:06,870 --> 00:26:10,469
target selected I'm like reading off of

563
00:26:09,270 --> 00:26:12,990
my thing now it's added to a graph

564
00:26:10,470 --> 00:26:16,770
graphs graphs are cool and then the

565
00:26:12,990 --> 00:26:18,930
exploitation phase they're sorted by how

566
00:26:16,770 --> 00:26:23,100
useful or how likely the exploit is to

567
00:26:18,930 --> 00:26:24,990
be but happening it's executed it

568
00:26:23,100 --> 00:26:27,480
attempts for a success it's a reverse

569
00:26:24,990 --> 00:26:30,120
shell right now once it's found it'll

570
00:26:27,480 --> 00:26:32,760
open a sub process and connect it in the

571
00:26:30,120 --> 00:26:37,199
post exploit we have a data gathering

572
00:26:32,760 --> 00:26:39,180
script the logs are parsed by an automat

573
00:26:37,200 --> 00:26:41,430
an automatic log scrubber which we're

574
00:26:39,180 --> 00:26:43,560
adding machine learning into that can

575
00:26:41,430 --> 00:26:49,770
find anything that looks sketchy in the

576
00:26:43,560 --> 00:26:53,990
log and remove it and profit so here's

577
00:26:49,770 --> 00:26:59,300
some fake stuff this is called Quine

578
00:26:53,990 --> 00:27:05,220
we're attempting to copy the ml over to

579
00:26:59,300 --> 00:27:07,800
the hacked machine so that it can escape

580
00:27:05,220 --> 00:27:10,800
and become anonymous or autonomous and I

581
00:27:07,800 --> 00:27:13,740
have an autonomous AI bought

582
00:27:10,800 --> 00:27:16,200
I had a reporter today or a couple weeks

583
00:27:13,740 --> 00:27:20,900
ago use the word that is scary when

584
00:27:16,200 --> 00:27:24,180
describing that which which I loved and

585
00:27:20,900 --> 00:27:27,500
sci-fi nerds and then we have a

586
00:27:24,180 --> 00:27:29,670
simulation piece which is it's a

587
00:27:27,500 --> 00:27:30,240
currently in production that's that's

588
00:27:29,670 --> 00:27:33,120
incorrect

589
00:27:30,240 --> 00:27:35,240
but the simulation piece we can design a

590
00:27:33,120 --> 00:27:38,790
simulated Network and run through

591
00:27:35,240 --> 00:27:40,200
hundreds and hundreds of tests just

592
00:27:38,790 --> 00:27:42,230
through simulation and not actually

593
00:27:40,200 --> 00:27:45,270
having to like spin up VMs to do this

594
00:27:42,230 --> 00:27:47,040
because the state and the environment

595
00:27:45,270 --> 00:27:50,550
and the agent are all separate pieces so

596
00:27:47,040 --> 00:27:59,940
it's kind of like Ender's Game where he

597
00:27:50,550 --> 00:28:01,710
didn't know he was in a simple so here's

598
00:27:59,940 --> 00:28:04,170
kind of how the reinforcement learning

599
00:28:01,710 --> 00:28:07,710
piece is going so you have your agent

600
00:28:04,170 --> 00:28:10,140
that's awesome jpg and you have your

601
00:28:07,710 --> 00:28:14,430
correlation engine and your network

602
00:28:10,140 --> 00:28:18,780
interface and it finds things that can

603
00:28:14,430 --> 00:28:20,340
see and it correlates them and then it's

604
00:28:18,780 --> 00:28:23,490
given a number of decisions on a graph

605
00:28:20,340 --> 00:28:25,320
and it'll say which action to take

606
00:28:23,490 --> 00:28:27,270
attack and scan which towards the

607
00:28:25,320 --> 00:28:29,820
likeliest to work and which will lead

608
00:28:27,270 --> 00:28:31,500
somewhere how do you ask those questions

609
00:28:29,820 --> 00:28:32,850
how do you tell a computer to ask those

610
00:28:31,500 --> 00:28:35,490
questions that's that's a tough thing

611
00:28:32,850 --> 00:28:37,469
and computer science actually has has a

612
00:28:35,490 --> 00:28:42,180
really interesting answer for that and

613
00:28:37,470 --> 00:28:48,780
it's just try some stuff AI so that's

614
00:28:42,180 --> 00:28:51,270
the talk does anyone ever so uh Sosa's

615
00:28:48,780 --> 00:28:55,200
try some stuff so hey let's try struts

616
00:28:51,270 --> 00:28:56,550
oh no they patched let's try nginx oh no

617
00:28:55,200 --> 00:28:58,950
I got Cod they have a good sim or

618
00:28:56,550 --> 00:29:04,260
something so it gets reinforced that's

619
00:28:58,950 --> 00:29:06,150
the squirt bottle so it says all right

620
00:29:04,260 --> 00:29:07,770
like let's try eternal blue which uni

621
00:29:06,150 --> 00:29:13,020
should totes try first if you're doing

622
00:29:07,770 --> 00:29:14,910
this and it gets a cookie so the next

623
00:29:13,020 --> 00:29:23,900
time it goes to ask these questions it

624
00:29:14,910 --> 00:29:29,450
stores these in a math and stick

625
00:29:23,900 --> 00:29:33,690
stochastic matrix is that right okay so

626
00:29:29,450 --> 00:29:35,940
and now it has correlations and it can

627
00:29:33,690 --> 00:29:37,830
remember what these things are and so

628
00:29:35,940 --> 00:29:39,480
hey eternal blue works really well last

629
00:29:37,830 --> 00:29:43,470
time so this is kind of how the

630
00:29:39,480 --> 00:29:47,580
architecture works for from a high-level

631
00:29:43,470 --> 00:29:49,770
view we have an environment which then

632
00:29:47,580 --> 00:29:52,770
gives out a state and a reward here's

633
00:29:49,770 --> 00:29:56,730
the math for you state is s and reward

634
00:29:52,770 --> 00:30:01,080
is R and in in machine learning policy

635
00:29:56,730 --> 00:30:03,870
is natural EQ the policy is is the state

636
00:30:01,080 --> 00:30:08,970
and the reward maths and comes up with

637
00:30:03,870 --> 00:30:11,209
an answer and hacks the computer so demo

638
00:30:08,970 --> 00:30:11,210
time

639
00:30:12,390 --> 00:30:23,700
oh yeah heads up I'm like real big into

640
00:30:17,730 --> 00:30:27,840
curses so this is uh oops this is almost

641
00:30:23,700 --> 00:30:30,200
like ridiculous amounts of ASCII art and

642
00:30:27,840 --> 00:30:30,199
curses

643
00:30:31,450 --> 00:30:48,930
oh wait hold on this thing is a computer

644
00:30:45,550 --> 00:30:48,930
is they're they're they're hard

645
00:30:53,250 --> 00:30:56,690
there we go article

646
00:30:58,210 --> 00:31:11,580
that's cool so Paris's I wish the text

647
00:31:09,249 --> 00:31:11,580
was bigger

648
00:31:14,100 --> 00:31:21,580
so we're executing our initial and map

649
00:31:17,679 --> 00:31:25,059
skin it pulled my adapter information by

650
00:31:21,580 --> 00:31:28,029
the way I have a capture the flag box so

651
00:31:25,059 --> 00:31:30,668
pulled the ports on the CTF box and now

652
00:31:28,029 --> 00:31:32,409
it's doing a it's it's decided on which

653
00:31:30,669 --> 00:31:34,330
scan it needs to do based on what it's

654
00:31:32,409 --> 00:31:36,460
pulled already and so it's doing a more

655
00:31:34,330 --> 00:31:38,080
intensive skin probably like an SUV to

656
00:31:36,460 --> 00:31:39,850
get the version and things like that and

657
00:31:38,080 --> 00:31:42,549
now it's doing version detection

658
00:31:39,850 --> 00:31:48,879
matching and checking correlations and

659
00:31:42,549 --> 00:31:51,999
exploit mode and we open Metasploit this

660
00:31:48,879 --> 00:31:55,029
sometimes doesn't work exploit completed

661
00:31:51,999 --> 00:31:58,119
no session was created so the first one

662
00:31:55,029 --> 00:31:59,980
failed so it's going to probably try the

663
00:31:58,119 --> 00:32:06,658
next best thing or maybe go back to

664
00:31:59,980 --> 00:32:06,659
recon at this point there's a timer so

665
00:32:07,740 --> 00:32:11,970
any minute bud there we go

666
00:32:12,880 --> 00:32:24,080
okay so it's so we're trying it again it

667
00:32:17,780 --> 00:32:25,670
normally gets it within like - I need

668
00:32:24,080 --> 00:32:37,070
some like synth wave music or something

669
00:32:25,670 --> 00:32:39,530
this is okay so pop the exploit it's got

670
00:32:37,070 --> 00:32:48,159
the connection it's trying to open a

671
00:32:39,530 --> 00:32:59,270
reverse shell this is very intense and

672
00:32:48,160 --> 00:33:01,190
we have a show so there's an open Wi-Fi

673
00:32:59,270 --> 00:33:04,440
network called pineapple if anyone wants

674
00:33:01,190 --> 00:33:08,840
to uh jump on and have a free pen test

675
00:33:04,440 --> 00:33:08,840
[Laughter]

676
00:33:10,750 --> 00:33:14,140
so what did we learn

677
00:33:15,040 --> 00:33:19,520
machine learning is hard

678
00:33:17,690 --> 00:33:24,500
specifically handling messy data is very

679
00:33:19,520 --> 00:33:29,570
hard the libraries for talking to the

680
00:33:24,500 --> 00:33:32,000
MSF RPC are dated to say that the least

681
00:33:29,570 --> 00:33:34,129
so we've kind of been contributing back

682
00:33:32,000 --> 00:33:36,200
to them so hopefully they should be like

683
00:33:34,130 --> 00:33:41,299
Python three point whatever compatible

684
00:33:36,200 --> 00:33:43,549
now old solutions are oftentimes better

685
00:33:41,299 --> 00:33:45,918
than new solutions and I was I was just

686
00:33:43,549 --> 00:33:47,809
saying to someone if I didn't want to do

687
00:33:45,919 --> 00:33:49,820
ridiculous sci-fi crap and I wanted to

688
00:33:47,809 --> 00:33:50,928
build this for real well there's so many

689
00:33:49,820 --> 00:33:52,159
better solutions out there right now

690
00:33:50,929 --> 00:33:54,580
that don't involve artificial

691
00:33:52,160 --> 00:33:54,580
intelligence

692
00:33:55,010 --> 00:34:02,120
Johnny Christmas is talking about was it

693
00:33:57,830 --> 00:34:09,830
a Empire Death Star auto sploit is

694
00:34:02,120 --> 00:34:12,199
ridiculous shouts - vector and but

695
00:34:09,830 --> 00:34:14,679
actually doing this clustering thing was

696
00:34:12,199 --> 00:34:17,529
was actually really really fast our

697
00:34:14,679 --> 00:34:21,379
vulnerability scanners like crazy fast

698
00:34:17,530 --> 00:34:24,530
and reinforcement based techniques

699
00:34:21,379 --> 00:34:25,250
provides some interesting responses that

700
00:34:24,530 --> 00:34:26,929
are kind of

701
00:34:25,250 --> 00:34:31,668
more general solutions right now than

702
00:34:26,929 --> 00:34:35,629
tailored solutions developing or

703
00:34:31,668 --> 00:34:37,969
teaching ml to hack a network to use

704
00:34:35,629 --> 00:34:40,310
these tools is almost kind of like

705
00:34:37,969 --> 00:34:42,949
teaching a toddler to drive a car like

706
00:34:40,310 --> 00:34:46,879
Eve even if you get them to drive the

707
00:34:42,949 --> 00:34:48,469
car which is incredibly dangerous you're

708
00:34:46,879 --> 00:34:51,348
basically just you know you're pushing

709
00:34:48,469 --> 00:34:54,949
them along every step of the way

710
00:34:51,349 --> 00:34:56,090
and it turns out that you know when you

711
00:34:54,949 --> 00:34:57,649
go to the bar and you're talking to

712
00:34:56,090 --> 00:35:02,240
someone and they ask you how you're

713
00:34:57,650 --> 00:35:05,210
doing and you say oh yeah I'm just I'm

714
00:35:02,240 --> 00:35:11,660
just teaching AI to hack a network they

715
00:35:05,210 --> 00:35:13,480
they leave there's some spin-offs some

716
00:35:11,660 --> 00:35:17,270
side projects that have come out of this

717
00:35:13,480 --> 00:35:20,150
so be echo tech developed this it's a

718
00:35:17,270 --> 00:35:23,960
pretty cool Python scrubber that can

719
00:35:20,150 --> 00:35:25,760
scrub all kinds of system logs these two

720
00:35:23,960 --> 00:35:28,310
things I made are actually are like

721
00:35:25,760 --> 00:35:30,710
empty github repos but I promise they're

722
00:35:28,310 --> 00:35:33,140
gonna be happening soon so demosthenes

723
00:35:30,710 --> 00:35:36,500
is that graph database related

724
00:35:33,140 --> 00:35:39,470
correlation engine for vulcanic and then

725
00:35:36,500 --> 00:35:42,020
i'm dropping like soon like add this on

726
00:35:39,470 --> 00:35:45,649
your github now the ml sec notebook

727
00:35:42,020 --> 00:35:48,440
which is kind of just again to reiterate

728
00:35:45,650 --> 00:35:50,330
to the point here this stuff is easy you

729
00:35:48,440 --> 00:35:53,330
can literally learn on youtube or like

730
00:35:50,330 --> 00:35:55,098
$10 on udemy Coursera things like that

731
00:35:53,330 --> 00:35:56,480
and this is stuff we need to be playing

732
00:35:55,099 --> 00:36:01,460
with because this is affecting our lives

733
00:35:56,480 --> 00:36:04,550
and they the powers-that-be want this to

734
00:36:01,460 --> 00:36:08,359
not be in our hands and we need to start

735
00:36:04,550 --> 00:36:10,010
messing with this stuff more and more to

736
00:36:08,359 --> 00:36:11,660
kind of get a glimpse to figure out what

737
00:36:10,010 --> 00:36:13,099
to protect against because you know all

738
00:36:11,660 --> 00:36:17,540
of us are totally law-abiding here and

739
00:36:13,099 --> 00:36:20,680
everything so again site curl that into

740
00:36:17,540 --> 00:36:20,680
bash Twitter

741
00:36:24,480 --> 00:36:35,730
[Applause]

742
00:36:36,800 --> 00:36:40,579
certainly appreciate it thank you

743
00:36:40,730 --> 00:36:48,809
does anyone have any questions I don't

744
00:36:43,230 --> 00:36:54,030
see I can't see please only easy ones

745
00:36:48,809 --> 00:36:56,190
I'm not a data scientist so my question

746
00:36:54,030 --> 00:36:57,270
is do you want help with Quine because

747
00:36:56,190 --> 00:36:59,700
that sounds like a lot of fun

748
00:36:57,270 --> 00:37:02,880
yeah totally that's so I'm I'm

749
00:36:59,700 --> 00:37:04,379
truthfully I'm at the point now where

750
00:37:02,880 --> 00:37:07,200
I've kind of done my research I've kind

751
00:37:04,380 --> 00:37:08,490
of done the thing and I'm not currently

752
00:37:07,200 --> 00:37:10,319
going to be working on this for a little

753
00:37:08,490 --> 00:37:13,020
bit but Quine is something that I want

754
00:37:10,319 --> 00:37:15,150
to develop in a more sort of broad

755
00:37:13,020 --> 00:37:16,920
distributed computing sense so yeah hit

756
00:37:15,150 --> 00:37:19,790
me up on github or Twitter or we'll chat

757
00:37:16,920 --> 00:37:19,790
cool

758
00:37:20,210 --> 00:37:26,490
so imagining a future in 5-10 years when

759
00:37:24,210 --> 00:37:30,480
neural networks are so much better and

760
00:37:26,490 --> 00:37:34,308
amazing what do you imagine doing what

761
00:37:30,480 --> 00:37:38,670
do you want other people to be doing

762
00:37:34,309 --> 00:37:40,559
that's a good question and actually and

763
00:37:38,670 --> 00:37:43,230
I'm probably grossly wrong in this but

764
00:37:40,559 --> 00:37:46,559
from my understanding the neural network

765
00:37:43,230 --> 00:37:48,510
by the way we're in a room named after

766
00:37:46,559 --> 00:37:51,420
the one of the people that developed the

767
00:37:48,510 --> 00:37:53,579
neural network Cathleen booth it's an

768
00:37:51,420 --> 00:37:54,930
old idea and it's just the hardware

769
00:37:53,579 --> 00:37:57,089
that's improving and so we're dealing

770
00:37:54,930 --> 00:37:59,279
with a lot of problems in security based

771
00:37:57,089 --> 00:38:01,558
on we have really good hardware and like

772
00:37:59,280 --> 00:38:05,549
you can get like 9 Q 2 cores for like

773
00:38:01,559 --> 00:38:07,650
10k or something now so as far as the

774
00:38:05,549 --> 00:38:08,970
next step and what to kind of be doing

775
00:38:07,650 --> 00:38:10,950
with these things I don't think we have

776
00:38:08,970 --> 00:38:12,270
the answers yet I think just playing

777
00:38:10,950 --> 00:38:16,460
around with it and figuring out things

778
00:38:12,270 --> 00:38:20,640
like this you know there's ml news and

779
00:38:16,460 --> 00:38:22,140
arc archive arxiv I think is that so

780
00:38:20,640 --> 00:38:24,270
it's pronounced like those papers that

781
00:38:22,140 --> 00:38:27,180
come out we're doing stuff that's

782
00:38:24,270 --> 00:38:30,799
mind-blowing every single day so it it I

783
00:38:27,180 --> 00:38:30,799
can't either one to tell you that

784
00:38:31,090 --> 00:38:35,050
hello thank you very much for a really

785
00:38:32,920 --> 00:38:37,750
amazing talk I'm glad you mentioned

786
00:38:35,050 --> 00:38:39,190
about the sort of emotional and social

787
00:38:37,750 --> 00:38:41,020
manipulation bit they brought up have

788
00:38:39,190 --> 00:38:43,570
you thought about any and have you had

789
00:38:41,020 --> 00:38:48,340
any thoughts about AI defenses against

790
00:38:43,570 --> 00:38:51,300
that at all defensive against the social

791
00:38:48,340 --> 00:38:55,140
piece yeah yeah no that's that's a

792
00:38:51,300 --> 00:38:57,970
that's an interesting idea what did you

793
00:38:55,140 --> 00:39:00,359
have any ideas based on that like what

794
00:38:57,970 --> 00:39:00,359
would that look like

795
00:39:00,910 --> 00:39:04,390
not personally no I know it's a bit sort

796
00:39:03,220 --> 00:39:05,919
of off-topic I just wondered if you

797
00:39:04,390 --> 00:39:09,750
thought about it at all that was all

798
00:39:05,920 --> 00:39:09,750
I haven't that's super interesting now I

799
00:39:10,650 --> 00:39:15,190
just want to also say thank you for

800
00:39:13,510 --> 00:39:18,760
bringing back some of that old-school

801
00:39:15,190 --> 00:39:23,740
hacker enthusiasm into your talk thank

802
00:39:18,760 --> 00:39:26,050
you thank you I don't want to go all

803
00:39:23,740 --> 00:39:29,700
debbie downer on you what I do have to

804
00:39:26,050 --> 00:39:32,650
say that some of what you're showing

805
00:39:29,700 --> 00:39:35,049
ultimately if you can extrapolate 5 to

806
00:39:32,650 --> 00:39:36,700
10 years out the percentage of people

807
00:39:35,050 --> 00:39:38,830
that are really gonna know how to

808
00:39:36,700 --> 00:39:42,279
manipulate this stuff is gonna remain

809
00:39:38,830 --> 00:39:44,470
super low and the companies with the

810
00:39:42,280 --> 00:39:47,560
billions of dollars are gonna be the

811
00:39:44,470 --> 00:39:50,259
ones developing it do you have in your

812
00:39:47,560 --> 00:39:53,350
mind any thoughts about how to keep

813
00:39:50,260 --> 00:39:55,480
something that's fun when it's like the

814
00:39:53,350 --> 00:39:57,850
cool kids that are using it returning

815
00:39:55,480 --> 00:40:04,570
into some sort of authoritarian

816
00:39:57,850 --> 00:40:07,120
nightmare specific action wise I don't

817
00:40:04,570 --> 00:40:08,500
have any specific thoughts other than we

818
00:40:07,120 --> 00:40:10,830
need to keep on playing with this stuff

819
00:40:08,500 --> 00:40:14,500
we need to teach people that it's not

820
00:40:10,830 --> 00:40:16,930
some sci-fi algorithm word thing that

821
00:40:14,500 --> 00:40:20,680
someone needs to have like a high school

822
00:40:16,930 --> 00:40:22,690
degree for education is important it's

823
00:40:20,680 --> 00:40:24,940
really fun to play with and I think that

824
00:40:22,690 --> 00:40:26,890
if we encourage the hacker community to

825
00:40:24,940 --> 00:40:32,100
start messing with this stuff I think

826
00:40:26,890 --> 00:40:35,819
people will i-i've confidence in that ok

827
00:40:32,100 --> 00:40:39,880
it's reading the doomsday machine by

828
00:40:35,820 --> 00:40:43,270
Daniel Ellsberg and one of the biggest

829
00:40:39,880 --> 00:40:45,350
motivations for developing the atomic

830
00:40:43,270 --> 00:40:48,470
bomb

831
00:40:45,350 --> 00:40:51,370
the fear that the Nazis were already

832
00:40:48,470 --> 00:40:58,939
pretty far ahead in developing it and

833
00:40:51,370 --> 00:41:02,359
even though and chances are it probably

834
00:40:58,940 --> 00:41:07,730
wouldn't have developed if we hadn't had

835
00:41:02,360 --> 00:41:08,390
thought that but the truth was what do

836
00:41:07,730 --> 00:41:11,570
you see

837
00:41:08,390 --> 00:41:13,759
bring us possibly bringing something

838
00:41:11,570 --> 00:41:20,870
into manifestation that wouldn't have

839
00:41:13,760 --> 00:41:25,160
otherwise existed interesting so I

840
00:41:20,870 --> 00:41:28,009
personally believe that you can't stop

841
00:41:25,160 --> 00:41:30,770
technology you can slow it down someone

842
00:41:28,010 --> 00:41:34,760
would have had that someone would have

843
00:41:30,770 --> 00:41:36,770
figured it out even if we weren't I

844
00:41:34,760 --> 00:41:39,590
think it's important to research this

845
00:41:36,770 --> 00:41:42,950
and I think it's important to do so with

846
00:41:39,590 --> 00:41:44,750
a very level head and I think it's

847
00:41:42,950 --> 00:41:52,250
important to keep technology in the

848
00:41:44,750 --> 00:41:54,140
hands of the people I say that but

849
00:41:52,250 --> 00:41:59,240
please don't go home and make any

850
00:41:54,140 --> 00:42:03,770
explosives please please hello

851
00:41:59,240 --> 00:42:05,779
why neo4j because he's a parson to other

852
00:42:03,770 --> 00:42:07,130
engraft other bases because I didn't

853
00:42:05,780 --> 00:42:12,290
know how to use it on my job wanted me

854
00:42:07,130 --> 00:42:15,170
to learn it so okay but specifically the

855
00:42:12,290 --> 00:42:18,590
neo4j piece actually that was

856
00:42:15,170 --> 00:42:20,150
legitimately the reason I just found it

857
00:42:18,590 --> 00:42:21,800
very interesting I like the

858
00:42:20,150 --> 00:42:23,600
visualizations they're all animated and

859
00:42:21,800 --> 00:42:26,030
stuff I could have probably done the

860
00:42:23,600 --> 00:42:28,009
same in like a dictionary in Python or

861
00:42:26,030 --> 00:42:34,720
something to be to be completely honest

862
00:42:28,010 --> 00:42:39,310
with you getting from GED to ml

863
00:42:34,720 --> 00:42:43,100
researcher what were the most helpful

864
00:42:39,310 --> 00:42:47,540
online resources or courses that that

865
00:42:43,100 --> 00:42:51,500
you found to get there so oh man I get

866
00:42:47,540 --> 00:42:54,920
to plug people all right so there's a

867
00:42:51,500 --> 00:42:57,319
course called deep learning and computer

868
00:42:54,920 --> 00:43:00,269
vision with Python by

869
00:42:57,319 --> 00:43:01,769
Adrian Rose Brock it's very interesting

870
00:43:00,269 --> 00:43:05,508
specifically related to deep learning

871
00:43:01,769 --> 00:43:05,508
with computer vision with Python

872
00:43:06,900 --> 00:43:13,859
there is a youtuber who he's he's a bit

873
00:43:11,519 --> 00:43:16,470
high-energy for some people but Suraj

874
00:43:13,859 --> 00:43:18,749
Raval explains things very very well in

875
00:43:16,470 --> 00:43:21,868
like something that I was able to

876
00:43:18,749 --> 00:43:25,470
understand from there there's there's a

877
00:43:21,869 --> 00:43:32,039
lot of great intermediate to entry-level

878
00:43:25,470 --> 00:43:35,759
authors Francois Sciales deep learning

879
00:43:32,039 --> 00:43:37,470
with Python is like it's the best and

880
00:43:35,759 --> 00:43:39,089
you can just kind of continue on from

881
00:43:37,470 --> 00:43:41,490
there but it's it's all very accessible

882
00:43:39,089 --> 00:43:44,249
it's just hard to go from what is this

883
00:43:41,490 --> 00:43:51,749
to reading like academic papers but you

884
00:43:44,249 --> 00:43:53,660
can kind of bridge the gap absolutely

885
00:43:51,749 --> 00:43:57,828
yes

886
00:43:53,660 --> 00:44:04,529
or Sarah yes absolutely

887
00:43:57,829 --> 00:44:07,589
Stanford thank you he did not ask a

888
00:44:04,529 --> 00:44:09,660
question but just an indent him the

889
00:44:07,589 --> 00:44:16,589
Nazis didn't developed a nuclear bomb

890
00:44:09,660 --> 00:44:20,970
because they thought it was too risky of

891
00:44:16,589 --> 00:44:24,150
an endeavor in the sense that it was not

892
00:44:20,970 --> 00:44:26,879
likely to succeed by the time the

893
00:44:24,150 --> 00:44:29,880
because the war would come to an end

894
00:44:26,880 --> 00:44:32,249
so they they abandoned the project

895
00:44:29,880 --> 00:44:33,989
because they didn't see the chance of it

896
00:44:32,249 --> 00:44:36,930
succeeding but we didn't ever knew that

897
00:44:33,989 --> 00:44:40,609
so and the same circumstance isn't the

898
00:44:36,930 --> 00:44:43,410
case here with machine learning I mean

899
00:44:40,609 --> 00:44:46,410
it's not being developed in the

900
00:44:43,410 --> 00:44:50,160
circumstance of a war so you're probably

901
00:44:46,410 --> 00:44:54,390
right about the someone else would

902
00:44:50,160 --> 00:44:56,910
probably develop it I appreciate that

903
00:44:54,390 --> 00:44:59,339
that's that's interesting and scary and

904
00:44:56,910 --> 00:45:04,609
that kind of thing is you know nightmare

905
00:44:59,339 --> 00:45:04,609
Mad Science and you know

906
00:45:04,980 --> 00:45:11,609
hopefully we don't get evil autonomous

907
00:45:08,430 --> 00:45:14,460
AI botnets but you know if we do it's

908
00:45:11,609 --> 00:45:24,479
going to be cyberpunk as thank you

909
00:45:14,460 --> 00:45:24,479
[Applause]

