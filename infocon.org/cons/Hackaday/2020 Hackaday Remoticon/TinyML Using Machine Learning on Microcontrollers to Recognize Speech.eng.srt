1
00:00:01,250 --> 00:00:06,240
[Music]

2
00:00:06,240 --> 00:00:07,200
welcome everyone

3
00:00:07,200 --> 00:00:10,080
to remote icon 2020 my name is bruce

4
00:00:10,080 --> 00:00:10,800
dominguez

5
00:00:10,800 --> 00:00:14,160
i'm one of your room moderators here and

6
00:00:14,160 --> 00:00:16,239
uh depending on your time zone good

7
00:00:16,239 --> 00:00:17,600
morning good afternoon

8
00:00:17,600 --> 00:00:20,880
and good evening today

9
00:00:20,880 --> 00:00:23,920
sean himmel will be hosting a discussion

10
00:00:23,920 --> 00:00:27,279
on tiny machine learning and

11
00:00:27,279 --> 00:00:30,320
uh if you have any questions or comments

12
00:00:30,320 --> 00:00:31,359
please post them

13
00:00:31,359 --> 00:00:34,480
in the chat to the room

14
00:00:34,480 --> 00:00:37,840
and uh you know it's a community so

15
00:00:37,840 --> 00:00:39,200
definitely be involved

16
00:00:39,200 --> 00:00:42,840
uh respond to each other and with that

17
00:00:42,840 --> 00:00:46,239
uh sean is an electrical

18
00:00:46,239 --> 00:00:48,559
and embedded engineer a freelance

19
00:00:48,559 --> 00:00:49,840
content creator

20
00:00:49,840 --> 00:00:53,600
and he and harris kenny host a podcast

21
00:00:53,600 --> 00:00:56,239
the hello blink show where they discuss

22
00:00:56,239 --> 00:00:57,120
various

23
00:00:57,120 --> 00:00:59,760
various aspects of starting a business

24
00:00:59,760 --> 00:01:02,079
from sales to hiring

25
00:01:02,079 --> 00:01:04,479
and sean has created his own company

26
00:01:04,479 --> 00:01:06,400
scowrisa

27
00:01:06,400 --> 00:01:08,479
that helps companies create compelling

28
00:01:08,479 --> 00:01:10,080
technical content

29
00:01:10,080 --> 00:01:12,960
in electronics and embedded systems and

30
00:01:12,960 --> 00:01:14,560
sean is an advocate for

31
00:01:14,560 --> 00:01:17,600
enriching education uh through stem and

32
00:01:17,600 --> 00:01:18,880
he believes that the

33
00:01:18,880 --> 00:01:21,920
best marketing comes from teaching uh he

34
00:01:21,920 --> 00:01:23,600
can be found giving talks

35
00:01:23,600 --> 00:01:26,240
running workshops and swing dancing in

36
00:01:26,240 --> 00:01:27,759
his free time and with that i'd like to

37
00:01:27,759 --> 00:01:28,960
introduce you to

38
00:01:28,960 --> 00:01:32,479
sean himal awesome thank you bruce and

39
00:01:32,479 --> 00:01:34,159
welcome everyone i know that we still

40
00:01:34,159 --> 00:01:35,759
have people kind of trickling into their

41
00:01:35,759 --> 00:01:36,880
waiting room here

42
00:01:36,880 --> 00:01:40,159
um as bruce mentioned uh i have been

43
00:01:40,159 --> 00:01:41,600
doing a bunch of machine learning

44
00:01:41,600 --> 00:01:43,600
recently mostly in the embedded world i

45
00:01:43,600 --> 00:01:45,360
used to work for spark phone electronics

46
00:01:45,360 --> 00:01:46,640
um if anybody

47
00:01:46,640 --> 00:01:49,040
ever watched that channel i i wear my

48
00:01:49,040 --> 00:01:50,560
bow tie and i'm doing it today so

49
00:01:50,560 --> 00:01:52,720
uh nice recognition there i got to keep

50
00:01:52,720 --> 00:01:54,079
the brand going

51
00:01:54,079 --> 00:01:55,759
and uh one of the things i've been doing

52
00:01:55,759 --> 00:01:57,360
for the last year or so

53
00:01:57,360 --> 00:01:59,600
is learning machine learning um i'm

54
00:01:59,600 --> 00:02:00,960
gonna take off my glasses you'll have to

55
00:02:00,960 --> 00:02:02,399
forgive me as

56
00:02:02,399 --> 00:02:04,399
my room gets a little toasty here my

57
00:02:04,399 --> 00:02:06,000
glasses are gonna fog up so normally i

58
00:02:06,000 --> 00:02:06,399
do

59
00:02:06,399 --> 00:02:07,920
actually wear glasses they're not fake

60
00:02:07,920 --> 00:02:09,679
but since i'm nearsighted i'm going to

61
00:02:09,679 --> 00:02:10,639
take them off so i can look at the

62
00:02:10,639 --> 00:02:11,440
computer

63
00:02:11,440 --> 00:02:13,440
so we're going to be doing machine

64
00:02:13,440 --> 00:02:14,480
learning and

65
00:02:14,480 --> 00:02:16,080
machine learning specifically for

66
00:02:16,080 --> 00:02:18,640
embedded systems and i've asked people

67
00:02:18,640 --> 00:02:20,400
to pick up some hardware if you want to

68
00:02:20,400 --> 00:02:21,440
follow along

69
00:02:21,440 --> 00:02:23,360
if not i believe these are going to be

70
00:02:23,360 --> 00:02:24,800
recorded so that you can come back to

71
00:02:24,800 --> 00:02:26,160
them later and

72
00:02:26,160 --> 00:02:27,840
i will continue to produce content out

73
00:02:27,840 --> 00:02:29,520
there on the internet about how to

74
00:02:29,520 --> 00:02:31,280
you know say get some type of machine

75
00:02:31,280 --> 00:02:33,280
learning thing running on an arduino or

76
00:02:33,280 --> 00:02:35,040
running on an stm32

77
00:02:35,040 --> 00:02:38,879
i've asked people to grab an stm32l476rg

78
00:02:38,879 --> 00:02:40,319
nucleo board um

79
00:02:40,319 --> 00:02:42,560
mostly because that is what i'm familiar

80
00:02:42,560 --> 00:02:43,519
with

81
00:02:43,519 --> 00:02:46,000
uh i have recently learned how to get

82
00:02:46,000 --> 00:02:48,160
this running on an arduino board that's

83
00:02:48,160 --> 00:02:49,519
a little easier but

84
00:02:49,519 --> 00:02:50,800
when i made this when i made this

85
00:02:50,800 --> 00:02:52,640
workshop i'm going with what i know

86
00:02:52,640 --> 00:02:55,360
so let's jump in because i know that um

87
00:02:55,360 --> 00:02:58,560
there's a lot to cover here um

88
00:02:58,560 --> 00:03:00,640
and it looks like bruce just dropped in

89
00:03:00,640 --> 00:03:02,159
the hackaday project

90
00:03:02,159 --> 00:03:03,920
link so if anybody wants to take a look

91
00:03:03,920 --> 00:03:05,280
at that

92
00:03:05,280 --> 00:03:09,200
and i'm going to go ahead and share this

93
00:03:09,200 --> 00:03:10,319
all right hopefully everyone can see

94
00:03:10,319 --> 00:03:12,239
this if you have not

95
00:03:12,239 --> 00:03:14,879
done so already please solder the

96
00:03:14,879 --> 00:03:16,319
headers to your microphone breakout

97
00:03:16,319 --> 00:03:17,280
board

98
00:03:17,280 --> 00:03:19,519
do that while we're talking please

99
00:03:19,519 --> 00:03:22,400
install stm32 cube ide

100
00:03:22,400 --> 00:03:24,560
just google search that term download it

101
00:03:24,560 --> 00:03:25,440
install it

102
00:03:25,440 --> 00:03:27,680
i think you're gonna have to sign up for

103
00:03:27,680 --> 00:03:29,200
a account on

104
00:03:29,200 --> 00:03:32,400
stms or st's site so heads up on that

105
00:03:32,400 --> 00:03:33,840
accept all the defaults it's a pretty

106
00:03:33,840 --> 00:03:35,440
large download so please do that if you

107
00:03:35,440 --> 00:03:36,879
have not done so already

108
00:03:36,879 --> 00:03:38,879
you will also need some kind of serial

109
00:03:38,879 --> 00:03:39,920
terminal program

110
00:03:39,920 --> 00:03:42,959
like i'm on windows so putty it is um

111
00:03:42,959 --> 00:03:44,879
forget what the big one on mac is but

112
00:03:44,879 --> 00:03:46,000
you've got like serial

113
00:03:46,000 --> 00:03:49,040
or um or or a couple of others on

114
00:03:49,040 --> 00:03:52,319
um on linux uh the other thing is you

115
00:03:52,319 --> 00:03:54,159
will need to create a gmail account if

116
00:03:54,159 --> 00:03:55,760
you don't have it already and you will

117
00:03:55,760 --> 00:03:57,439
need to create an edge impulse account

118
00:03:57,439 --> 00:03:59,360
we will be using um not gmail

119
00:03:59,360 --> 00:04:01,040
necessarily but we're using

120
00:04:01,040 --> 00:04:03,840
google colab which will let us run a

121
00:04:03,840 --> 00:04:05,760
script that i wrote to help us curate

122
00:04:05,760 --> 00:04:06,560
the data

123
00:04:06,560 --> 00:04:08,319
and we're going to be sending that

124
00:04:08,319 --> 00:04:10,640
curated data up to edge impulse to help

125
00:04:10,640 --> 00:04:12,000
us do the training

126
00:04:12,000 --> 00:04:14,159
i chose edge impulse because it's a tool

127
00:04:14,159 --> 00:04:15,519
it's a graphical tool

128
00:04:15,519 --> 00:04:17,600
and honestly if i just gave you python

129
00:04:17,600 --> 00:04:19,120
scripts to run the training

130
00:04:19,120 --> 00:04:21,440
it would be doing the same thing anyway

131
00:04:21,440 --> 00:04:22,800
that you're just running through this

132
00:04:22,800 --> 00:04:23,440
script

133
00:04:23,440 --> 00:04:25,520
um that i've provided to you um the

134
00:04:25,520 --> 00:04:27,120
advantage of edge impulse is that they

135
00:04:27,120 --> 00:04:28,960
manage all of the packaging up in

136
00:04:28,960 --> 00:04:30,960
libraries for us so that it runs

137
00:04:30,960 --> 00:04:32,639
i'm going to do my best to make this not

138
00:04:32,639 --> 00:04:34,320
a canned demo so that when you get this

139
00:04:34,320 --> 00:04:35,120
library i'll

140
00:04:35,120 --> 00:04:37,199
show you what you need to use in that

141
00:04:37,199 --> 00:04:39,520
library for your embedded system

142
00:04:39,520 --> 00:04:43,120
um so yeah the worksheet is on this

143
00:04:43,120 --> 00:04:45,040
github link

144
00:04:45,040 --> 00:04:47,520
and there we go the worksheet is on this

145
00:04:47,520 --> 00:04:48,560
github link

146
00:04:48,560 --> 00:04:50,720
um please go there we're going to be

147
00:04:50,720 --> 00:04:52,560
working out of that

148
00:04:52,560 --> 00:04:54,479
please feel free to work ahead i really

149
00:04:54,479 --> 00:04:56,479
don't mind in fact i can't see a lot of

150
00:04:56,479 --> 00:04:57,680
you right now so

151
00:04:57,680 --> 00:05:00,080
um if you if you're like you know

152
00:05:00,080 --> 00:05:00,960
chomping at the bit

153
00:05:00,960 --> 00:05:03,120
go for it start working ahead um i will

154
00:05:03,120 --> 00:05:04,720
say if you run into problems

155
00:05:04,720 --> 00:05:06,639
um wait until i get to that point where

156
00:05:06,639 --> 00:05:08,000
i'm also working through it and then

157
00:05:08,000 --> 00:05:10,240
i'll try to catch up in the chat however

158
00:05:10,240 --> 00:05:11,919
please use the chat please ask us

159
00:05:11,919 --> 00:05:14,160
questions in chat um

160
00:05:14,160 --> 00:05:15,600
and if you see somebody else asking

161
00:05:15,600 --> 00:05:17,199
questions please try to help out if

162
00:05:17,199 --> 00:05:18,720
you've run across this problem i know

163
00:05:18,720 --> 00:05:20,160
on twitter a few people running into

164
00:05:20,160 --> 00:05:21,840
problems uploading code um

165
00:05:21,840 --> 00:05:23,759
if you use the demo program that we're

166
00:05:23,759 --> 00:05:26,080
going to go through in my github repo

167
00:05:26,080 --> 00:05:28,400
then it should work all the settings are

168
00:05:28,400 --> 00:05:30,320
there so that it uploads to the nucleo

169
00:05:30,320 --> 00:05:31,600
with no problem

170
00:05:31,600 --> 00:05:33,759
i have released these slides as creative

171
00:05:33,759 --> 00:05:36,080
commons so if you want to

172
00:05:36,080 --> 00:05:37,759
pick and choose some of them and talk

173
00:05:37,759 --> 00:05:39,680
about tiny machine learning in your own

174
00:05:39,680 --> 00:05:41,440
company or with your own community

175
00:05:41,440 --> 00:05:43,520
please do so i really don't mind

176
00:05:43,520 --> 00:05:47,039
all i ask is for a little bit of credit

177
00:05:47,120 --> 00:05:49,520
so what is embedded machine learning um

178
00:05:49,520 --> 00:05:51,520
something i have learned fairly recently

179
00:05:51,520 --> 00:05:53,440
so the class was called tinyml

180
00:05:53,440 --> 00:05:54,800
and what's the difference between tinyml

181
00:05:54,800 --> 00:05:56,319
and embedded machine learning well what

182
00:05:56,319 --> 00:05:57,680
i've learned is that

183
00:05:57,680 --> 00:06:00,400
tinyaml is developing as this community

184
00:06:00,400 --> 00:06:02,560
you can go to tinyml.org

185
00:06:02,560 --> 00:06:04,240
and sign up for their talks they do them

186
00:06:04,240 --> 00:06:05,520
like once a week or once every other

187
00:06:05,520 --> 00:06:06,000
week there's

188
00:06:06,000 --> 00:06:07,919
a forum where people are discussing

189
00:06:07,919 --> 00:06:10,319
running machine learning algorithms

190
00:06:10,319 --> 00:06:12,400
on an embedded system so things like

191
00:06:12,400 --> 00:06:13,680
single board computers

192
00:06:13,680 --> 00:06:15,360
and more specifically microcontrollers

193
00:06:15,360 --> 00:06:17,039
so tinyml is the community

194
00:06:17,039 --> 00:06:18,560
embedded machine learning is kind of

195
00:06:18,560 --> 00:06:21,039
considered the general broad concept of

196
00:06:21,039 --> 00:06:22,800
let's run machine learning on

197
00:06:22,800 --> 00:06:26,080
embedded systems so why do we care to do

198
00:06:26,080 --> 00:06:27,600
this right we've got these giant

199
00:06:27,600 --> 00:06:29,600
computers and servers out there

200
00:06:29,600 --> 00:06:31,600
that already do machine learning for us

201
00:06:31,600 --> 00:06:32,960
in fact they do it really well

202
00:06:32,960 --> 00:06:35,199
um you you know any number of amazon and

203
00:06:35,199 --> 00:06:36,479
google services

204
00:06:36,479 --> 00:06:39,120
um netflix recommending to you what

205
00:06:39,120 --> 00:06:40,080
movies you

206
00:06:40,080 --> 00:06:42,639
should watch that's machine learning so

207
00:06:42,639 --> 00:06:43,680
why do we care to

208
00:06:43,680 --> 00:06:45,680
run it on an embedded system well let's

209
00:06:45,680 --> 00:06:46,800
take an example here

210
00:06:46,800 --> 00:06:49,039
you are probably most familiar uh many

211
00:06:49,039 --> 00:06:50,080
of you probably have one of these

212
00:06:50,080 --> 00:06:51,520
devices sitting in your home

213
00:06:51,520 --> 00:06:53,280
right now and that is the echo the

214
00:06:53,280 --> 00:06:54,560
amazon echo or

215
00:06:54,560 --> 00:06:56,720
google home or whatever or even your

216
00:06:56,720 --> 00:06:57,680
smartphone for like

217
00:06:57,680 --> 00:07:01,120
hey siri that kind of thing most of the

218
00:07:01,120 --> 00:07:01,759
time

219
00:07:01,759 --> 00:07:03,120
when this thing is interacting with you

220
00:07:03,120 --> 00:07:04,400
or you're interacting with it it is

221
00:07:04,400 --> 00:07:06,000
streaming audio data

222
00:07:06,000 --> 00:07:07,759
to a server so we'll go with the echo

223
00:07:07,759 --> 00:07:09,840
here that's streaming audio data to

224
00:07:09,840 --> 00:07:13,919
an amazon server however it's not always

225
00:07:13,919 --> 00:07:16,880
listening it's not always streaming data

226
00:07:16,880 --> 00:07:17,199
it's

227
00:07:17,199 --> 00:07:20,160
listening in tiny little chunks up front

228
00:07:20,160 --> 00:07:21,919
for a specific key but here's that

229
00:07:21,919 --> 00:07:22,880
keyword

230
00:07:22,880 --> 00:07:25,520
then it opens up a stream to the amazon

231
00:07:25,520 --> 00:07:27,039
servers and just starts piping anything

232
00:07:27,039 --> 00:07:28,000
it hears after that

233
00:07:28,000 --> 00:07:30,800
where more complicated and more

234
00:07:30,800 --> 00:07:31,599
complicated

235
00:07:31,599 --> 00:07:33,599
machine learning algorithms take place

236
00:07:33,599 --> 00:07:35,039
that do things like natural language

237
00:07:35,039 --> 00:07:35,759
processing

238
00:07:35,759 --> 00:07:39,120
in order to determine yes i'm

239
00:07:39,120 --> 00:07:41,440
so sorry to everyone that just heard

240
00:07:41,440 --> 00:07:42,400
that word and

241
00:07:42,400 --> 00:07:44,080
all of their echo devices started

242
00:07:44,080 --> 00:07:45,599
beeping at them i apologize

243
00:07:45,599 --> 00:07:47,440
i will refrain from using that word as

244
00:07:47,440 --> 00:07:48,879
much as possible in this day and age

245
00:07:48,879 --> 00:07:50,400
it's almost like a curse word if you're

246
00:07:50,400 --> 00:07:51,599
streaming stuff

247
00:07:51,599 --> 00:07:54,160
so once you once it opens up that socket

248
00:07:54,160 --> 00:07:54,800
to

249
00:07:54,800 --> 00:07:57,599
um a server an amazon server out there

250
00:07:57,599 --> 00:07:58,800
that's where all the natural language

251
00:07:58,800 --> 00:07:59,440
processing

252
00:07:59,440 --> 00:08:01,280
comes from to determine what you're

253
00:08:01,280 --> 00:08:02,960
trying to ask it to do

254
00:08:02,960 --> 00:08:04,960
that's an example of embedded machine

255
00:08:04,960 --> 00:08:07,440
learning other kind of things you'll see

256
00:08:07,440 --> 00:08:09,199
um are things like video object

257
00:08:09,199 --> 00:08:11,599
detection on a very very low level like

258
00:08:11,599 --> 00:08:14,000
like a person detection this is not

259
00:08:14,000 --> 00:08:14,960
trying to do

260
00:08:14,960 --> 00:08:17,520
like you know um self-driving cars we're

261
00:08:17,520 --> 00:08:19,280
trying to identify every object and

262
00:08:19,280 --> 00:08:20,240
roads and what

263
00:08:20,240 --> 00:08:22,080
what have you this is more like oh i

264
00:08:22,080 --> 00:08:23,360
just want to see if a person's in the

265
00:08:23,360 --> 00:08:23,919
frame

266
00:08:23,919 --> 00:08:26,080
and in fact i've got a security camera

267
00:08:26,080 --> 00:08:27,199
that can do exactly that

268
00:08:27,199 --> 00:08:30,319
and it's a microcontroller doing this um

269
00:08:30,319 --> 00:08:31,919
something else that i've seen is anomaly

270
00:08:31,919 --> 00:08:32,559
detection

271
00:08:32,559 --> 00:08:35,039
you take sensors like accelerometer

272
00:08:35,039 --> 00:08:36,159
accelerometers

273
00:08:36,159 --> 00:08:38,320
and you put them on like i don't know a

274
00:08:38,320 --> 00:08:41,039
um a servo or a motor or something

275
00:08:41,039 --> 00:08:42,159
that's gonna give you some type of

276
00:08:42,159 --> 00:08:43,279
vibration data

277
00:08:43,279 --> 00:08:44,800
and you watch that over time and then

278
00:08:44,800 --> 00:08:47,200
you say okay is there an anomaly is this

279
00:08:47,200 --> 00:08:48,880
thing about to break

280
00:08:48,880 --> 00:08:51,040
that can be very very helpful for things

281
00:08:51,040 --> 00:08:52,080
like um

282
00:08:52,080 --> 00:08:53,920
yeah washing machine washing machine is

283
00:08:53,920 --> 00:08:55,920
another good one is this about to break

284
00:08:55,920 --> 00:08:56,320
um

285
00:08:56,320 --> 00:08:59,040
things like um like satellites right

286
00:08:59,040 --> 00:09:00,399
where things you can't get to you need

287
00:09:00,399 --> 00:09:01,519
to know beforehand

288
00:09:01,519 --> 00:09:03,200
so that you can take actions to prevent

289
00:09:03,200 --> 00:09:04,800
that prevent the break from happening in

290
00:09:04,800 --> 00:09:05,760
the future and you can be a little

291
00:09:05,760 --> 00:09:07,360
predictive with this which is where

292
00:09:07,360 --> 00:09:08,640
machine learning comes in and that's why

293
00:09:08,640 --> 00:09:09,760
we want to run this on

294
00:09:09,760 --> 00:09:11,839
embedded systems because it allows us to

295
00:09:11,839 --> 00:09:13,839
do these kinds of things

296
00:09:13,839 --> 00:09:16,720
so uh if you didn't get the link already

297
00:09:16,720 --> 00:09:18,080
here is the github link

298
00:09:18,080 --> 00:09:20,399
to my keyword spotting that is going to

299
00:09:20,399 --> 00:09:21,680
be our worksheet

300
00:09:21,680 --> 00:09:23,760
start working through that um i will

301
00:09:23,760 --> 00:09:24,959
work through it with you

302
00:09:24,959 --> 00:09:26,720
um as we go through this but i will also

303
00:09:26,720 --> 00:09:29,440
stop and explain things um bruce linked

304
00:09:29,440 --> 00:09:29,920
it so

305
00:09:29,920 --> 00:09:31,519
please click on that um thank you for

306
00:09:31,519 --> 00:09:33,440
that i will

307
00:09:33,440 --> 00:09:35,600
i will continue to talk about concepts

308
00:09:35,600 --> 00:09:36,480
as

309
00:09:36,480 --> 00:09:37,839
people are working through this when we

310
00:09:37,839 --> 00:09:39,440
get to a stopping point that's a good

311
00:09:39,440 --> 00:09:40,160
place to

312
00:09:40,160 --> 00:09:42,320
for me to blab some more and answer some

313
00:09:42,320 --> 00:09:43,600
questions and they'll be like specific

314
00:09:43,600 --> 00:09:46,720
slides for that kind of thing

315
00:09:46,720 --> 00:09:48,160
uh once again i mentioned that this is

316
00:09:48,160 --> 00:09:49,600
i'm gonna do my best to not make it a

317
00:09:49,600 --> 00:09:51,040
canned demo because that's annoying i

318
00:09:51,040 --> 00:09:52,720
want to give people the tools they can

319
00:09:52,720 --> 00:09:54,560
they can use to create their own say

320
00:09:54,560 --> 00:09:56,480
keyword spotting system and introduce

321
00:09:56,480 --> 00:09:57,519
them into

322
00:09:57,519 --> 00:10:00,800
the world of embedded machine learning

323
00:10:00,800 --> 00:10:02,320
data collection the first thing we need

324
00:10:02,320 --> 00:10:04,240
to do is data collection so we're going

325
00:10:04,240 --> 00:10:05,920
to head to this script i'm going to exit

326
00:10:05,920 --> 00:10:07,200
out of these slides

327
00:10:07,200 --> 00:10:10,480
here is the worksheet and we're going to

328
00:10:10,480 --> 00:10:12,560
scroll down this worksheet feel free to

329
00:10:12,560 --> 00:10:14,079
read this at some point

330
00:10:14,079 --> 00:10:16,720
there are two ways to do data collection

331
00:10:16,720 --> 00:10:17,600
for this script that

332
00:10:17,600 --> 00:10:19,680
this data this curation script that i

333
00:10:19,680 --> 00:10:20,959
made the first

334
00:10:20,959 --> 00:10:23,519
is to do it locally um you'd have to

335
00:10:23,519 --> 00:10:25,279
install a whole bunch of python and

336
00:10:25,279 --> 00:10:26,160
packages and

337
00:10:26,160 --> 00:10:27,600
stuff to make that happen so we're not

338
00:10:27,600 --> 00:10:29,200
going to do that i created a

339
00:10:29,200 --> 00:10:31,360
collab script for you so if you could

340
00:10:31,360 --> 00:10:34,160
just click on this opening collab button

341
00:10:34,160 --> 00:10:37,600
in fact let me make that a new tab

342
00:10:39,120 --> 00:10:40,640
so we've got this collapse script if

343
00:10:40,640 --> 00:10:42,399
you've never run collab before

344
00:10:42,399 --> 00:10:44,399
it is basically a jupiter notebook

345
00:10:44,399 --> 00:10:45,839
that's all it is it's running it's

346
00:10:45,839 --> 00:10:47,519
jupiter notebook running on a google

347
00:10:47,519 --> 00:10:48,560
server somewhere

348
00:10:48,560 --> 00:10:51,360
this is we have access basically to a

349
00:10:51,360 --> 00:10:53,040
full linux box here um

350
00:10:53,040 --> 00:10:54,320
obviously they restrict you in what you

351
00:10:54,320 --> 00:10:56,240
can do but the idea is we can actually

352
00:10:56,240 --> 00:10:56,560
like

353
00:10:56,560 --> 00:10:58,640
upload files look at the file system and

354
00:10:58,640 --> 00:11:00,000
run python scripts

355
00:11:00,000 --> 00:11:01,760
and it's giving us a jupyter notebook

356
00:11:01,760 --> 00:11:04,640
interface to do it to run a cell so

357
00:11:04,640 --> 00:11:06,880
each of these oops each of these is

358
00:11:06,880 --> 00:11:08,399
considered a cell and they can run

359
00:11:08,399 --> 00:11:09,440
individually

360
00:11:09,440 --> 00:11:11,839
to do that we hold shift and press enter

361
00:11:11,839 --> 00:11:13,040
i'm sure there's a button somewhere to

362
00:11:13,040 --> 00:11:14,079
do this but this is how we've been doing

363
00:11:14,079 --> 00:11:14,800
it jupiter

364
00:11:14,800 --> 00:11:17,839
and jupiter notebook feel free to read

365
00:11:17,839 --> 00:11:19,360
through this however we are not going to

366
00:11:19,360 --> 00:11:21,040
be uploading our own keyword samples

367
00:11:21,040 --> 00:11:21,519
today

368
00:11:21,519 --> 00:11:23,680
this script does allow you to upload

369
00:11:23,680 --> 00:11:25,440
your own keyword samples

370
00:11:25,440 --> 00:11:27,519
something you can do is take your cell

371
00:11:27,519 --> 00:11:29,839
phone any recording device your computer

372
00:11:29,839 --> 00:11:33,040
and record yourself saying some keyword

373
00:11:33,040 --> 00:11:34,560
if you were at the bring a hack last

374
00:11:34,560 --> 00:11:35,200
night i

375
00:11:35,200 --> 00:11:36,560
showed one where i recorded myself

376
00:11:36,560 --> 00:11:38,240
saying trick or treat a whole bunch of

377
00:11:38,240 --> 00:11:39,839
times right that could be a keyword a

378
00:11:39,839 --> 00:11:41,120
keyword doesn't have to be one word it

379
00:11:41,120 --> 00:11:42,640
can be a phrase but in our case as long

380
00:11:42,640 --> 00:11:44,079
as it's less than a second

381
00:11:44,079 --> 00:11:46,560
that will act as a keyword for us um you

382
00:11:46,560 --> 00:11:48,560
need probably about 50 samples

383
00:11:48,560 --> 00:11:50,639
hundreds better thousands is even better

384
00:11:50,639 --> 00:11:52,399
than that and you want them to be a

385
00:11:52,399 --> 00:11:54,240
variety of pronunciations

386
00:11:54,240 --> 00:11:57,200
accents genders voices types anything

387
00:11:57,200 --> 00:11:57,839
you can think of

388
00:11:57,839 --> 00:12:00,880
the the more variety you have the more

389
00:12:00,880 --> 00:12:02,800
robust model you're going to be able to

390
00:12:02,800 --> 00:12:04,079
create that it will recognize

391
00:12:04,079 --> 00:12:05,760
other people's voices in fact i've got a

392
00:12:05,760 --> 00:12:07,440
good story about this i went to my

393
00:12:07,440 --> 00:12:09,440
parents house to hand out candy to kids

394
00:12:09,440 --> 00:12:09,920
on tr

395
00:12:09,920 --> 00:12:12,160
on trick-or-treat night right halloween

396
00:12:12,160 --> 00:12:13,360
um because it's something fun to do and

397
00:12:13,360 --> 00:12:13,600
i

398
00:12:13,600 --> 00:12:15,040
like giving out candy to kids and i

399
00:12:15,040 --> 00:12:17,120
brought this pumpkin hack with me

400
00:12:17,120 --> 00:12:18,800
and because i only trained it on an

401
00:12:18,800 --> 00:12:21,440
adult male and an adult female voice

402
00:12:21,440 --> 00:12:23,360
it did not pick up the little kids

403
00:12:23,360 --> 00:12:24,560
saying it because they have very

404
00:12:24,560 --> 00:12:26,720
different voices so keep that in mind

405
00:12:26,720 --> 00:12:28,880
when you're creating this type of system

406
00:12:28,880 --> 00:12:30,800
for a demonstration purpose yeah your

407
00:12:30,800 --> 00:12:32,480
own voice is fine but remember if you're

408
00:12:32,480 --> 00:12:33,680
going to deploy this

409
00:12:33,680 --> 00:12:36,000
think about people might have different

410
00:12:36,000 --> 00:12:37,920
accents who are going to talk to this

411
00:12:37,920 --> 00:12:39,360
and that's going to be a problem if they

412
00:12:39,360 --> 00:12:40,320
can't interact with

413
00:12:40,320 --> 00:12:42,720
your device and in fact amazon used

414
00:12:42,720 --> 00:12:44,560
thousands and thousands and thousands of

415
00:12:44,560 --> 00:12:45,200
samples

416
00:12:45,200 --> 00:12:49,200
um to get that alexa keyword going

417
00:12:49,200 --> 00:12:51,120
all right so let's execute this next

418
00:12:51,120 --> 00:12:52,320
script this is all

419
00:12:52,320 --> 00:12:54,000
this is all text so not much is going to

420
00:12:54,000 --> 00:12:55,440
happen here's where

421
00:12:55,440 --> 00:12:56,800
here's where the magic starts to happen

422
00:12:56,800 --> 00:12:58,880
let's shift enter on

423
00:12:58,880 --> 00:13:00,880
node.js uh oh the notebook was not

424
00:13:00,880 --> 00:13:02,399
authored by google we're going to run

425
00:13:02,399 --> 00:13:02,959
anyway

426
00:13:02,959 --> 00:13:04,320
because it's part of my account and i'm

427
00:13:04,320 --> 00:13:06,160
going to tell colab to run it this is

428
00:13:06,160 --> 00:13:06,560
going to

429
00:13:06,560 --> 00:13:09,120
take just a moment we need to install

430
00:13:09,120 --> 00:13:10,800
the latest version of

431
00:13:10,800 --> 00:13:13,360
npm which is the javascript package

432
00:13:13,360 --> 00:13:15,600
managed or node package manager

433
00:13:15,600 --> 00:13:18,000
um in order to run the edge impulse

434
00:13:18,000 --> 00:13:18,959
uploader tool

435
00:13:18,959 --> 00:13:20,800
it's a command line tool we'll install

436
00:13:20,800 --> 00:13:22,160
it and that's going to allow us to just

437
00:13:22,160 --> 00:13:24,480
send our data to the edge impulse

438
00:13:24,480 --> 00:13:26,959
servers

439
00:13:27,200 --> 00:13:29,200
so the next thing we're going to do here

440
00:13:29,200 --> 00:13:31,279
is we're going to install these packages

441
00:13:31,279 --> 00:13:33,360
so we're going to install sound file

442
00:13:33,360 --> 00:13:34,880
which lets us

443
00:13:34,880 --> 00:13:37,600
read and write wav files that's going to

444
00:13:37,600 --> 00:13:39,120
be needed by the curation script

445
00:13:39,120 --> 00:13:41,279
and we're also going to install the edge

446
00:13:41,279 --> 00:13:43,040
impulse command line tool

447
00:13:43,040 --> 00:13:44,959
once again that will allow us to we're

448
00:13:44,959 --> 00:13:46,720
going to curate a bunch of data when i

449
00:13:46,720 --> 00:13:48,639
say curate we're going to take a data

450
00:13:48,639 --> 00:13:50,320
set from google we're going to mix in

451
00:13:50,320 --> 00:13:51,440
some background noise

452
00:13:51,440 --> 00:13:53,760
pick the samples pick the classes of the

453
00:13:53,760 --> 00:13:55,839
words that we want as keywords

454
00:13:55,839 --> 00:13:57,279
one or two of those and we're going to

455
00:13:57,279 --> 00:13:59,199
create a new data set that's a subset of

456
00:13:59,199 --> 00:13:59,519
that

457
00:13:59,519 --> 00:14:01,920
of that that's been mixed in without all

458
00:14:01,920 --> 00:14:03,600
of the without uh with the background

459
00:14:03,600 --> 00:14:04,720
noise and we're going to send all that

460
00:14:04,720 --> 00:14:05,920
to edge impulse

461
00:14:05,920 --> 00:14:08,959
um question about python whatever's

462
00:14:08,959 --> 00:14:10,560
default in colab right now

463
00:14:10,560 --> 00:14:12,399
i believe it is pi i believe it is

464
00:14:12,399 --> 00:14:13,760
python 3.

465
00:14:13,760 --> 00:14:15,440
um i thought i printed that out but you

466
00:14:15,440 --> 00:14:16,800
should be good with python

467
00:14:16,800 --> 00:14:18,560
three um and that should be what's

468
00:14:18,560 --> 00:14:19,839
running in colab

469
00:14:19,839 --> 00:14:22,959
um if you have not just for me i forgot

470
00:14:22,959 --> 00:14:24,160
to check this

471
00:14:24,160 --> 00:14:27,519
um change runtime ah here we go

472
00:14:27,519 --> 00:14:28,959
um we're not doing machine learning so

473
00:14:28,959 --> 00:14:30,399
we don't i don't think we particularly

474
00:14:30,399 --> 00:14:31,920
need a gpu

475
00:14:31,920 --> 00:14:33,040
runtime since we're not doing any

476
00:14:33,040 --> 00:14:34,480
machine learning on this collab right

477
00:14:34,480 --> 00:14:36,399
now so we're just using this as a

478
00:14:36,399 --> 00:14:37,760
curation script so we don't need to

479
00:14:37,760 --> 00:14:38,959
worry about a runtime we're just going

480
00:14:38,959 --> 00:14:39,600
to uh

481
00:14:39,600 --> 00:14:42,000
do the cpu runtime these are some

482
00:14:42,000 --> 00:14:43,040
settings

483
00:14:43,040 --> 00:14:45,040
that you can you can modify if you wish

484
00:14:45,040 --> 00:14:46,399
but i recommend leaving them

485
00:14:46,399 --> 00:14:48,240
alone for right now for this particular

486
00:14:48,240 --> 00:14:50,000
demonstration um feel free to look

487
00:14:50,000 --> 00:14:51,279
through here we're going to download the

488
00:14:51,279 --> 00:14:52,959
google speech commands data set which is

489
00:14:52,959 --> 00:14:53,519
just a

490
00:14:53,519 --> 00:14:57,040
pre-made data set for us um there is

491
00:14:57,040 --> 00:14:58,639
a verbiage in here if you go up to show

492
00:14:58,639 --> 00:15:00,480
you how to you can modify your own

493
00:15:00,480 --> 00:15:02,560
or add your own keywords to modify that

494
00:15:02,560 --> 00:15:03,680
data set

495
00:15:03,680 --> 00:15:05,199
um you will want to use the google

496
00:15:05,199 --> 00:15:06,480
speech commands data set and then add

497
00:15:06,480 --> 00:15:07,839
your own on top of that and i'll show

498
00:15:07,839 --> 00:15:09,040
you why in a minute

499
00:15:09,040 --> 00:15:10,959
um this also allows you to pick the

500
00:15:10,959 --> 00:15:12,800
output number of samples your word

501
00:15:12,800 --> 00:15:14,720
volume your background volume

502
00:15:14,720 --> 00:15:16,880
your sample time we're gonna be using a

503
00:15:16,880 --> 00:15:19,279
second and your sample rate of 16

504
00:15:19,279 --> 00:15:20,160
kilohertz

505
00:15:20,160 --> 00:15:22,399
um also your bit depth all these things

506
00:15:22,399 --> 00:15:23,839
which are you know juicy good

507
00:15:23,839 --> 00:15:26,959
stuff that we're gonna need to train uh

508
00:15:26,959 --> 00:15:28,399
our machine learning model with the

509
00:15:28,399 --> 00:15:30,320
reason we set them this way

510
00:15:30,320 --> 00:15:32,079
is because we want to look at the

511
00:15:32,079 --> 00:15:33,519
microphone so

512
00:15:33,519 --> 00:15:35,680
we've got our i know i'm probably small

513
00:15:35,680 --> 00:15:36,639
we got the microphone

514
00:15:36,639 --> 00:15:38,079
in the new cl on the attached to our

515
00:15:38,079 --> 00:15:41,199
nucleo board and that microphone

516
00:15:41,199 --> 00:15:44,399
samples at 16 kilohertz and it gives us

517
00:15:44,399 --> 00:15:45,839
actually that microphone gives us

518
00:15:45,839 --> 00:15:48,480
24 bits i believe but we're going to

519
00:15:48,480 --> 00:15:50,560
truncate that to 16. so with 16

520
00:15:50,560 --> 00:15:53,120
kilohertz sampling at 16 bit

521
00:15:53,120 --> 00:15:54,959
at 16 bits pcm knowing what our

522
00:15:54,959 --> 00:15:57,360
microphone is that's what we want to

523
00:15:57,360 --> 00:16:00,000
um have all of our samples be when we go

524
00:16:00,000 --> 00:16:01,120
to train it otherwise there's going to

525
00:16:01,120 --> 00:16:01,440
be

526
00:16:01,440 --> 00:16:03,839
a mismatch when we go to deploy our

527
00:16:03,839 --> 00:16:05,440
neural network

528
00:16:05,440 --> 00:16:08,399
all right let's run this which doesn't

529
00:16:08,399 --> 00:16:09,600
do a whole lot it just sets a bunch of

530
00:16:09,600 --> 00:16:10,880
variables and then we're going to say

531
00:16:10,880 --> 00:16:11,920
hey

532
00:16:11,920 --> 00:16:13,839
go ahead and download the google speech

533
00:16:13,839 --> 00:16:15,199
commands data set and this is going to

534
00:16:15,199 --> 00:16:16,560
take a minute or two

535
00:16:16,560 --> 00:16:18,480
um what we're doing here is we're

536
00:16:18,480 --> 00:16:19,600
downloading

537
00:16:19,600 --> 00:16:22,959
the google speech commands data set from

538
00:16:22,959 --> 00:16:26,000
this link here http uh download

539
00:16:26,000 --> 00:16:27,199
tensorflow.org

540
00:16:27,199 --> 00:16:28,720
and it's going to be downloaded not to

541
00:16:28,720 --> 00:16:30,480
our computer but to this

542
00:16:30,480 --> 00:16:33,199
server right here um this is attached

543
00:16:33,199 --> 00:16:35,040
you know somewhere across the internet

544
00:16:35,040 --> 00:16:39,199
and let's go take a look here

545
00:16:39,199 --> 00:16:40,399
ah when we go to start running the

546
00:16:40,399 --> 00:16:42,000
curation we're going to talk about how

547
00:16:42,000 --> 00:16:42,399
this

548
00:16:42,399 --> 00:16:44,399
curation actually works so i'm going to

549
00:16:44,399 --> 00:16:47,279
give you an a preview here

550
00:16:47,279 --> 00:16:48,399
because we're going to need to make an

551
00:16:48,399 --> 00:16:51,759
account on edge impulse first so

552
00:16:51,759 --> 00:16:54,720
let's yep so we actually have to do that

553
00:16:54,720 --> 00:16:56,240
next so while this is downloading for

554
00:16:56,240 --> 00:16:58,240
everybody

555
00:16:58,240 --> 00:16:59,279
so yeah i'm going to jump in back and

556
00:16:59,279 --> 00:17:00,480
forth between my slides because my

557
00:17:00,480 --> 00:17:01,279
slides are

558
00:17:01,279 --> 00:17:03,279
for you also for me to remember what i

559
00:17:03,279 --> 00:17:04,400
need to do next

560
00:17:04,400 --> 00:17:07,119
so if everybody has the stm32 cube ide

561
00:17:07,119 --> 00:17:08,319
make sure you're

562
00:17:08,319 --> 00:17:10,400
installing that or have it installed we

563
00:17:10,400 --> 00:17:12,880
need to create an edge impulse account

564
00:17:12,880 --> 00:17:15,919
so go to edgeimpulse.com

565
00:17:15,919 --> 00:17:19,039
sign in create your account and we're

566
00:17:19,039 --> 00:17:22,400
going to click login here

567
00:17:22,400 --> 00:17:26,240
and we're going to create a new project

568
00:17:26,240 --> 00:17:28,400
i'm going to call it speech recognition

569
00:17:28,400 --> 00:17:30,160
or keyword spotted

570
00:17:30,160 --> 00:17:32,080
whatever you want to call it and i'm

571
00:17:32,080 --> 00:17:34,480
going to call mine i don't know one

572
00:17:34,480 --> 00:17:38,160
uh oh i already have one named one

573
00:17:39,919 --> 00:17:42,160
called o2 good version control right

574
00:17:42,160 --> 00:17:43,440
there

575
00:17:43,440 --> 00:17:45,120
all right so we're going to go to speech

576
00:17:45,120 --> 00:17:46,960
recognition o2

577
00:17:46,960 --> 00:17:48,880
we're going to click on that and then up

578
00:17:48,880 --> 00:17:50,320
at the top we want to find

579
00:17:50,320 --> 00:17:52,640
keys that little tab that's just on your

580
00:17:52,640 --> 00:17:53,840
dashboard

581
00:17:53,840 --> 00:17:57,039
and keys this is our api key so double

582
00:17:57,039 --> 00:17:57,919
click on that

583
00:17:57,919 --> 00:17:59,039
and we're going to copy that don't worry

584
00:17:59,039 --> 00:18:00,080
if you double click and you don't see

585
00:18:00,080 --> 00:18:01,120
the rest of it

586
00:18:01,120 --> 00:18:03,760
it does copy the whole thing we're going

587
00:18:03,760 --> 00:18:05,760
to go back to our script

588
00:18:05,760 --> 00:18:10,879
it looks like it is done so extracting

589
00:18:12,840 --> 00:18:14,000
done

590
00:18:14,000 --> 00:18:17,679
and actually one second so we just ran

591
00:18:17,679 --> 00:18:18,640
that

592
00:18:18,640 --> 00:18:22,080
all right so if you click on the folder

593
00:18:22,080 --> 00:18:23,919
icon on the left side of colab

594
00:18:23,919 --> 00:18:26,640
you actually get the uh file system in

595
00:18:26,640 --> 00:18:28,080
fact you can go up a folder

596
00:18:28,080 --> 00:18:29,679
and if you've ever used linux this

597
00:18:29,679 --> 00:18:31,679
should look very very familiar

598
00:18:31,679 --> 00:18:33,760
our essentially home directory where

599
00:18:33,760 --> 00:18:35,520
we're going to be working in is this

600
00:18:35,520 --> 00:18:36,720
content directory

601
00:18:36,720 --> 00:18:38,720
so i recommend taking a peek in there

602
00:18:38,720 --> 00:18:40,080
and these are the files so we just

603
00:18:40,080 --> 00:18:41,919
downloaded the speech commands data set

604
00:18:41,919 --> 00:18:44,559
and we extracted it or untard it

605
00:18:44,559 --> 00:18:47,280
rather and what you see is all of these

606
00:18:47,280 --> 00:18:48,000
files

607
00:18:48,000 --> 00:18:51,440
which contains a whole bunch of wav

608
00:18:51,440 --> 00:18:55,360
files the first thing we need to do

609
00:18:55,360 --> 00:18:57,360
is extract the background noise out

610
00:18:57,360 --> 00:18:59,360
because my script that i wrote for the

611
00:18:59,360 --> 00:19:00,559
curation

612
00:19:00,559 --> 00:19:02,799
does not take kindly to background noise

613
00:19:02,799 --> 00:19:04,720
being in one of these input directories

614
00:19:04,720 --> 00:19:05,919
so that needs to be its own separate

615
00:19:05,919 --> 00:19:07,280
directory outside of that

616
00:19:07,280 --> 00:19:09,360
that's all this cell does so let's go

617
00:19:09,360 --> 00:19:11,760
ahead and run this cell

618
00:19:11,760 --> 00:19:14,000
and then we're going to refresh this

619
00:19:14,000 --> 00:19:15,039
refresh

620
00:19:15,039 --> 00:19:17,440
your file system and you'll see that it

621
00:19:17,440 --> 00:19:18,960
pulled the background noise

622
00:19:18,960 --> 00:19:20,880
category out so google speech command

623
00:19:20,880 --> 00:19:22,640
data set gave us samples of the

624
00:19:22,640 --> 00:19:25,200
background noise great we can use that

625
00:19:25,200 --> 00:19:27,520
feel free to also add your add your own

626
00:19:27,520 --> 00:19:28,400
um your

627
00:19:28,400 --> 00:19:29,600
air conditioning running like because

628
00:19:29,600 --> 00:19:31,120
mine's very loud you're in a crowded

629
00:19:31,120 --> 00:19:31,840
room

630
00:19:31,840 --> 00:19:33,840
take a minute of recording make it a wav

631
00:19:33,840 --> 00:19:35,360
file drop it in there

632
00:19:35,360 --> 00:19:38,240
and my script will automatically extract

633
00:19:38,240 --> 00:19:39,600
background pieces of that background

634
00:19:39,600 --> 00:19:42,799
noise to mix into your keywords later

635
00:19:42,799 --> 00:19:45,919
so let's go back into this real quick

636
00:19:45,919 --> 00:19:47,360
i'm going to open up the background

637
00:19:47,360 --> 00:19:49,520
noise or excuse me the back

638
00:19:49,520 --> 00:19:53,120
wow not the background noise the

639
00:19:53,120 --> 00:19:54,960
the backward keyword and i'm going to

640
00:19:54,960 --> 00:19:57,679
say download

641
00:19:57,679 --> 00:19:59,520
so feel free to download and check it so

642
00:19:59,520 --> 00:20:01,120
we're pulling in this file from this

643
00:20:01,120 --> 00:20:06,960
from colab

644
00:20:06,960 --> 00:20:10,080
i've got when amp not wanting to play

645
00:20:10,080 --> 00:20:11,360
nicely because it really whips

646
00:20:11,360 --> 00:20:15,200
something so i don't know if

647
00:20:15,200 --> 00:20:16,400
people can hear that because it's my

648
00:20:16,400 --> 00:20:18,320
system audio but feel free to play one

649
00:20:18,320 --> 00:20:20,240
of these and you should hear

650
00:20:20,240 --> 00:20:23,440
the sound being played somebody a

651
00:20:23,440 --> 00:20:25,679
somebody providing a sample of back or

652
00:20:25,679 --> 00:20:27,679
backward or whatever the keyword is and

653
00:20:27,679 --> 00:20:29,200
feel free to try any of these and it's

654
00:20:29,200 --> 00:20:30,559
just people saying this word and there's

655
00:20:30,559 --> 00:20:30,960
like

656
00:20:30,960 --> 00:20:32,799
2 000 samples in each of these it's a

657
00:20:32,799 --> 00:20:35,600
pretty big data set

658
00:20:35,600 --> 00:20:37,440
um once again you can add your own if

659
00:20:37,440 --> 00:20:38,799
you wish if you want to say

660
00:20:38,799 --> 00:20:39,919
you know record yourself adding these

661
00:20:39,919 --> 00:20:42,080
and add it to it so um

662
00:20:42,080 --> 00:20:43,919
this allows you to download my personal

663
00:20:43,919 --> 00:20:45,200
custom data set that i've been working

664
00:20:45,200 --> 00:20:45,520
on

665
00:20:45,520 --> 00:20:47,039
um it's mostly a bunch of garbage in

666
00:20:47,039 --> 00:20:48,480
there of like you know trick or treat

667
00:20:48,480 --> 00:20:49,360
hadouken

668
00:20:49,360 --> 00:20:51,200
drakeris just me playing around and just

669
00:20:51,200 --> 00:20:52,720
adding to this it's somewhere on github

670
00:20:52,720 --> 00:20:54,080
so it pulls it in but we're not going to

671
00:20:54,080 --> 00:20:55,280
do that today we're just going to stick

672
00:20:55,280 --> 00:20:57,440
with the google speech commands data set

673
00:20:57,440 --> 00:20:59,200
this is where you want to change some

674
00:20:59,200 --> 00:21:00,960
stuff so we've got the custom data set

675
00:21:00,960 --> 00:21:02,080
path we're going to leave this

676
00:21:02,080 --> 00:21:04,400
empty because we did not create our own

677
00:21:04,400 --> 00:21:06,240
custom keywords as part of this

678
00:21:06,240 --> 00:21:09,120
next where it says the ei api key we're

679
00:21:09,120 --> 00:21:10,880
going to go ahead and paste that right

680
00:21:10,880 --> 00:21:13,360
in that we copied from edge impulse

681
00:21:13,360 --> 00:21:16,640
now let's pick some words

682
00:21:16,640 --> 00:21:18,320
we want to look at the available words

683
00:21:18,320 --> 00:21:21,280
for us um initially as a demo i said

684
00:21:21,280 --> 00:21:23,200
stop and go that's pretty simple but

685
00:21:23,200 --> 00:21:24,720
let's go with

686
00:21:24,720 --> 00:21:30,720
let's try house

687
00:21:30,720 --> 00:21:34,080
and let's go with zero that's just

688
00:21:34,080 --> 00:21:37,679
two words here uh where's the api key

689
00:21:37,679 --> 00:21:39,440
very good question so you have to log

690
00:21:39,440 --> 00:21:41,360
into edge impulse

691
00:21:41,360 --> 00:21:43,520
uh create a project or or go into an

692
00:21:43,520 --> 00:21:45,360
existing project that you have

693
00:21:45,360 --> 00:21:48,159
you want to go to dashboard and you go

694
00:21:48,159 --> 00:21:49,520
to keys

695
00:21:49,520 --> 00:21:50,880
and then it should be right here so you

696
00:21:50,880 --> 00:21:53,039
can just double click that and copy it

697
00:21:53,039 --> 00:21:54,320
that's where you find your

698
00:21:54,320 --> 00:21:57,520
api key good question thanks for um the

699
00:21:57,520 --> 00:21:58,880
reminder to go back and

700
00:21:58,880 --> 00:22:01,919
show where to get that from

701
00:22:03,120 --> 00:22:07,039
maximize window it's truncating um

702
00:22:07,039 --> 00:22:09,679
so it is truncating this i can't make

703
00:22:09,679 --> 00:22:10,080
this

704
00:22:10,080 --> 00:22:11,919
my window is maximized i'm i'm

705
00:22:11,919 --> 00:22:13,200
broadcasting at like

706
00:22:13,200 --> 00:22:16,159
um 1920 by 1080 so that everyone you

707
00:22:16,159 --> 00:22:17,520
know it's a 1080p

708
00:22:17,520 --> 00:22:20,240
stream um it does copy the whole key so

709
00:22:20,240 --> 00:22:20,960
even though it looks like it's

710
00:22:20,960 --> 00:22:21,760
truncating here

711
00:22:21,760 --> 00:22:23,280
when you paste it in you get the whole

712
00:22:23,280 --> 00:22:25,440
key um it's just a

713
00:22:25,440 --> 00:22:28,559
a weird thing um so anyway

714
00:22:28,559 --> 00:22:32,000
we've got house and zero

715
00:22:32,000 --> 00:22:34,880
um as our keywords for you pick house or

716
00:22:34,880 --> 00:22:35,360
zero

717
00:22:35,360 --> 00:22:37,919
pick one word pick two what i have found

718
00:22:37,919 --> 00:22:40,799
is that picking three or more um

719
00:22:40,799 --> 00:22:42,640
the machine learning model is not able

720
00:22:42,640 --> 00:22:44,000
to quite keep up when we start getting

721
00:22:44,000 --> 00:22:46,159
bad classifications beyond like three or

722
00:22:46,159 --> 00:22:47,280
four keywords

723
00:22:47,280 --> 00:22:49,520
um you can make it 10 and see if it

724
00:22:49,520 --> 00:22:51,280
works i can't promise the model is going

725
00:22:51,280 --> 00:22:53,039
to fit on your microcontroller or that

726
00:22:53,039 --> 00:22:54,000
it's going to be very

727
00:22:54,000 --> 00:22:57,919
accurate um the other thing that i

728
00:22:57,919 --> 00:22:59,520
found is that keywords work better when

729
00:22:59,520 --> 00:23:02,320
you have multiple syllables

730
00:23:02,320 --> 00:23:05,280
and you've got um various sounds like

731
00:23:05,280 --> 00:23:06,480
consonants and

732
00:23:06,480 --> 00:23:08,720
vowels all mixed in there which is why

733
00:23:08,720 --> 00:23:10,799
amazon went with alexa

734
00:23:10,799 --> 00:23:12,559
um you have okay google it's it's

735
00:23:12,559 --> 00:23:13,919
multiple syllables

736
00:23:13,919 --> 00:23:16,080
rather than just like hey um because

737
00:23:16,080 --> 00:23:17,600
that sounds like a lot of other things

738
00:23:17,600 --> 00:23:18,960
humans can say

739
00:23:18,960 --> 00:23:20,480
so what i have done is picked house

740
00:23:20,480 --> 00:23:22,080
which is a single syllable

741
00:23:22,080 --> 00:23:24,000
we'll see how that works and zero which

742
00:23:24,000 --> 00:23:25,760
is two syllables the more syllables you

743
00:23:25,760 --> 00:23:26,400
add

744
00:23:26,400 --> 00:23:28,640
the better accuracy you're gonna get for

745
00:23:28,640 --> 00:23:29,760
that keyword so pick

746
00:23:29,760 --> 00:23:32,480
one or two from the list over here um if

747
00:23:32,480 --> 00:23:33,760
you have time on your own if you're

748
00:23:33,760 --> 00:23:34,799
going through this

749
00:23:34,799 --> 00:23:36,400
feel free to try creating your own and

750
00:23:36,400 --> 00:23:38,559
create a custom keywords uh set that you

751
00:23:38,559 --> 00:23:40,320
add into this

752
00:23:40,320 --> 00:23:44,320
and then so we're gonna run that one

753
00:23:45,039 --> 00:23:48,080
and then we are going to download the

754
00:23:48,080 --> 00:23:49,200
curation scripts

755
00:23:49,200 --> 00:23:51,279
which is just on that it's in that

756
00:23:51,279 --> 00:23:52,400
github

757
00:23:52,400 --> 00:23:55,600
repo that we're using as the worksheet

758
00:23:55,600 --> 00:23:56,720
so i'm going to go ahead and refresh

759
00:23:56,720 --> 00:23:59,440
this data set curation you can double

760
00:23:59,440 --> 00:24:00,480
click to take a look

761
00:24:00,480 --> 00:24:03,520
um i mit license this so feel free to

762
00:24:03,520 --> 00:24:05,360
use it and it's just

763
00:24:05,360 --> 00:24:08,480
pulling in wav files mixing them with

764
00:24:08,480 --> 00:24:10,080
background

765
00:24:10,080 --> 00:24:13,120
um yeah and then spitting them out in a

766
00:24:13,120 --> 00:24:14,480
data set that's going to be useful for

767
00:24:14,480 --> 00:24:15,520
us so

768
00:24:15,520 --> 00:24:17,120
you should have gotten to this point and

769
00:24:17,120 --> 00:24:19,440
now we're ready to run the

770
00:24:19,440 --> 00:24:22,880
actual curation so we're going to shift

771
00:24:22,880 --> 00:24:25,919
enter to run this and this is going to

772
00:24:25,919 --> 00:24:26,320
take

773
00:24:26,320 --> 00:24:30,320
about 20 minutes um 15 to 20 minutes so

774
00:24:30,320 --> 00:24:31,679
i'll come back and continue to check on

775
00:24:31,679 --> 00:24:32,720
this

776
00:24:32,720 --> 00:24:33,840
as we're going through and i'm going to

777
00:24:33,840 --> 00:24:35,600
talk about kind of what's going on why

778
00:24:35,600 --> 00:24:36,320
we need to do

779
00:24:36,320 --> 00:24:39,440
data curation here

780
00:24:39,440 --> 00:24:41,760
uh when it says mixing unknown it is

781
00:24:41,760 --> 00:24:43,039
just putting random other

782
00:24:43,039 --> 00:24:44,720
non-keywords yes that is absolutely

783
00:24:44,720 --> 00:24:47,039
correct and i've got a graphic for that

784
00:24:47,039 --> 00:24:48,480
so while that's going so i wanted to get

785
00:24:48,480 --> 00:24:50,080
to that point of having people run this

786
00:24:50,080 --> 00:24:51,520
part run this script because it's going

787
00:24:51,520 --> 00:24:52,720
to take a while

788
00:24:52,720 --> 00:24:54,080
i'm going to go back to my slides here

789
00:24:54,080 --> 00:24:56,159
and talk about exactly what's going oops

790
00:24:56,159 --> 00:25:00,880
that is definitely the wrong button

791
00:25:00,880 --> 00:25:02,640
i don't know why control f5 doesn't work

792
00:25:02,640 --> 00:25:04,720
for me but it does not

793
00:25:04,720 --> 00:25:06,720
all right so what we've got going on

794
00:25:06,720 --> 00:25:08,320
here with this script and that is a

795
00:25:08,320 --> 00:25:11,919
a very good very good question oh no

796
00:25:11,919 --> 00:25:13,440
such file

797
00:25:13,440 --> 00:25:16,559
or directory

798
00:25:16,960 --> 00:25:18,640
uh let me make sure was i supposed to

799
00:25:18,640 --> 00:25:21,279
add a link higher up in the

800
00:25:21,279 --> 00:25:24,960
like yeah um

801
00:25:24,960 --> 00:25:28,640
so if you go up

802
00:25:28,640 --> 00:25:31,360
uh the custom data set path is blank

803
00:25:31,360 --> 00:25:32,320
correct

804
00:25:32,320 --> 00:25:33,840
custom yes that is correct custom data

805
00:25:33,840 --> 00:25:35,600
set path should be blank

806
00:25:35,600 --> 00:25:40,840
um i'm trying to remember where i put

807
00:25:40,840 --> 00:25:42,080
this

808
00:25:42,080 --> 00:25:44,080
uh there should be something uh here it

809
00:25:44,080 --> 00:25:45,840
is uh make sure you've run this

810
00:25:45,840 --> 00:25:49,200
cell um it in the

811
00:25:49,200 --> 00:25:51,760
google speech commands data set got it

812
00:25:51,760 --> 00:25:53,279
if you see background noise it should be

813
00:25:53,279 --> 00:25:55,039
pulled out of the google speech

814
00:25:55,039 --> 00:25:56,880
data set it should be on the same level

815
00:25:56,880 --> 00:25:57,919
uh the folder should be on the same

816
00:25:57,919 --> 00:25:58,480
level

817
00:25:58,480 --> 00:26:00,960
um otherwise it's considered a keyword

818
00:26:00,960 --> 00:26:03,440
and that's not what we want

819
00:26:03,440 --> 00:26:06,480
got it thank you sure

820
00:26:06,480 --> 00:26:08,080
target word cheese is not found in the

821
00:26:08,080 --> 00:26:10,240
subdirectory um that is because you need

822
00:26:10,240 --> 00:26:11,360
to pick

823
00:26:11,360 --> 00:26:13,200
from the available keywords in the

824
00:26:13,200 --> 00:26:14,799
google speech commands data set so if

825
00:26:14,799 --> 00:26:16,080
you on the left here if you

826
00:26:16,080 --> 00:26:18,000
drop that down these are the available

827
00:26:18,000 --> 00:26:19,760
keywords you have

828
00:26:19,760 --> 00:26:22,159
yeah so um i don't have the time to show

829
00:26:22,159 --> 00:26:23,200
people how to

830
00:26:23,200 --> 00:26:25,760
create their own keywords but if you sit

831
00:26:25,760 --> 00:26:27,520
there and record yourself saying cheese

832
00:26:27,520 --> 00:26:29,520
like 50 times on your cell phone

833
00:26:29,520 --> 00:26:30,880
and then take something like audacity

834
00:26:30,880 --> 00:26:32,720
and create one second snippets out of

835
00:26:32,720 --> 00:26:34,240
that

836
00:26:34,240 --> 00:26:36,880
um you can then create your own keyword

837
00:26:36,880 --> 00:26:38,640
it's it's not that hard to do it's just

838
00:26:38,640 --> 00:26:40,000
time consuming and i didn't have time

839
00:26:40,000 --> 00:26:41,440
for this workshop but that

840
00:26:41,440 --> 00:26:43,279
in the github repo there is the

841
00:26:43,279 --> 00:26:44,640
walkthrough that shows you how to do

842
00:26:44,640 --> 00:26:46,080
that you need to go into audacity

843
00:26:46,080 --> 00:26:47,919
create these one-second snippets and

844
00:26:47,919 --> 00:26:50,559
then you add it in as a custom keyword

845
00:26:50,559 --> 00:26:50,960
here

846
00:26:50,960 --> 00:26:52,159
and you can create your own custom

847
00:26:52,159 --> 00:26:54,080
keywords so yes you can definitely get

848
00:26:54,080 --> 00:26:55,520
cheese in there but for now for this

849
00:26:55,520 --> 00:26:56,320
workshop

850
00:26:56,320 --> 00:26:59,039
please select one or two of the keywords

851
00:26:59,039 --> 00:27:00,640
available in the google speech commands

852
00:27:00,640 --> 00:27:02,799
data set

853
00:27:02,799 --> 00:27:04,799
uh missed the api key from edge so if

854
00:27:04,799 --> 00:27:06,240
you go to edge impulse

855
00:27:06,240 --> 00:27:08,640
um log in create a project go to

856
00:27:08,640 --> 00:27:09,679
dashboard

857
00:27:09,679 --> 00:27:12,080
go to keys and it should be right there

858
00:27:12,080 --> 00:27:14,080
um it's okay if it's truncated it will

859
00:27:14,080 --> 00:27:15,120
copy

860
00:27:15,120 --> 00:27:17,679
um it will absolutely copy the uh the q

861
00:27:17,679 --> 00:27:19,520
the api key for you

862
00:27:19,520 --> 00:27:23,440
you're welcome all right so we've got

863
00:27:23,440 --> 00:27:24,080
this

864
00:27:24,080 --> 00:27:25,919
what's going on here this script is just

865
00:27:25,919 --> 00:27:27,360
a simple python script

866
00:27:27,360 --> 00:27:29,120
and it is going through each of the

867
00:27:29,120 --> 00:27:30,559
google speech commands data set

868
00:27:30,559 --> 00:27:33,919
it is pulling in each of the files or

869
00:27:33,919 --> 00:27:35,200
it's actually randomly going through and

870
00:27:35,200 --> 00:27:36,159
looking for

871
00:27:36,159 --> 00:27:38,000
um a number of files in there so like

872
00:27:38,000 --> 00:27:40,240
remember we said 1500 we want

873
00:27:40,240 --> 00:27:43,440
so we've got so say down right

874
00:27:43,440 --> 00:27:45,039
down is a category in the google speech

875
00:27:45,039 --> 00:27:46,799
commands data set it will randomly pull

876
00:27:46,799 --> 00:27:49,919
1500 files from that and then put

877
00:27:49,919 --> 00:27:52,240
them in the down category on the output

878
00:27:52,240 --> 00:27:54,399
during that process it's also mixing in

879
00:27:54,399 --> 00:27:56,559
random snippets of background noise to

880
00:27:56,559 --> 00:27:58,880
help let us create a more robust model

881
00:27:58,880 --> 00:28:01,679
it does so for the up directory unknown

882
00:28:01,679 --> 00:28:02,399
is

883
00:28:02,399 --> 00:28:04,240
random samplings from all the other

884
00:28:04,240 --> 00:28:05,520
directories and

885
00:28:05,520 --> 00:28:08,960
noise is just random random snippets of

886
00:28:08,960 --> 00:28:10,080
background noise

887
00:28:10,080 --> 00:28:11,840
these are going to be the four

888
00:28:11,840 --> 00:28:14,320
categories that we will

889
00:28:14,320 --> 00:28:16,960
train a model to recognize the output

890
00:28:16,960 --> 00:28:18,240
does not recognize

891
00:28:18,240 --> 00:28:20,640
any of the google speech commands data

892
00:28:20,640 --> 00:28:21,279
set just

893
00:28:21,279 --> 00:28:23,039
the four categories that we've provided

894
00:28:23,039 --> 00:28:24,559
here um so in this

895
00:28:24,559 --> 00:28:27,360
example it's up down unknown in noise

896
00:28:27,360 --> 00:28:28,880
for the one that i'm training going to

897
00:28:28,880 --> 00:28:29,760
be training now

898
00:28:29,760 --> 00:28:32,720
is going to be house zero unknown and

899
00:28:32,720 --> 00:28:33,360
noise

900
00:28:33,360 --> 00:28:35,039
um and for you it's whatever keywords

901
00:28:35,039 --> 00:28:39,039
you you pick unknown and noise

902
00:28:40,640 --> 00:28:42,640
malfunctioning heap of scrap of the

903
00:28:42,640 --> 00:28:44,559
available data said yeah i know

904
00:28:44,559 --> 00:28:46,640
uh that would that would be quite

905
00:28:46,640 --> 00:28:48,080
amusing uh maybe long

906
00:28:48,080 --> 00:28:49,919
longer than a second but that would be

907
00:28:49,919 --> 00:28:51,679
pretty good i'm hoping somebody puts

908
00:28:51,679 --> 00:28:53,679
other like great quotes in there and uh

909
00:28:53,679 --> 00:28:55,840
train some models to recognize them

910
00:28:55,840 --> 00:28:57,279
um i really want to see like makers go

911
00:28:57,279 --> 00:28:58,880
nuts with this and like have like light

912
00:28:58,880 --> 00:29:00,399
up crazy stuff whenever somebody says

913
00:29:00,399 --> 00:29:02,000
like the keyword of the day

914
00:29:02,000 --> 00:29:05,039
um yeah that would be that would be like

915
00:29:05,039 --> 00:29:06,559
peewee's playhouse style right i want

916
00:29:06,559 --> 00:29:08,000
somebody to say a word and like they're

917
00:29:08,000 --> 00:29:09,600
like their house just like starts

918
00:29:09,600 --> 00:29:13,760
going crazy all right

919
00:29:13,760 --> 00:29:16,159
so uh data augmentation why do we do

920
00:29:16,159 --> 00:29:17,520
data augmentation

921
00:29:17,520 --> 00:29:21,120
um data augmentation is a extremely

922
00:29:21,120 --> 00:29:22,000
useful

923
00:29:22,000 --> 00:29:24,320
um technique we can do in machine

924
00:29:24,320 --> 00:29:25,760
learning that allows us to take a

925
00:29:25,760 --> 00:29:27,840
smaller data set and expand it out to a

926
00:29:27,840 --> 00:29:28,880
larger data set

927
00:29:28,880 --> 00:29:30,240
and it also helps us create a more

928
00:29:30,240 --> 00:29:31,919
robust model so for like image

929
00:29:31,919 --> 00:29:32,960
processing

930
00:29:32,960 --> 00:29:34,240
what we can do is you know say we're

931
00:29:34,240 --> 00:29:36,159
trying to identify pictures of cats

932
00:29:36,159 --> 00:29:37,760
well let's say we start with 30 pictures

933
00:29:37,760 --> 00:29:39,039
of cats that's going to make for a

934
00:29:39,039 --> 00:29:41,039
pretty terrible model what we can do is

935
00:29:41,039 --> 00:29:42,799
we can balloon that into like a thousand

936
00:29:42,799 --> 00:29:44,080
pictures of cats

937
00:29:44,080 --> 00:29:45,679
by doing things like shifting the cat

938
00:29:45,679 --> 00:29:47,360
over rotating the cat a little bit it

939
00:29:47,360 --> 00:29:49,360
helps create a little more robust model

940
00:29:49,360 --> 00:29:51,440
to be perfectly honest 30 pictures is

941
00:29:51,440 --> 00:29:52,799
not going to nearly be enough because

942
00:29:52,799 --> 00:29:54,960
you're going to identify like

943
00:29:54,960 --> 00:29:56,640
one type of cat or your model is going

944
00:29:56,640 --> 00:29:58,240
to overfit that and just identify

945
00:29:58,240 --> 00:30:00,159
specifically those pictures and no

946
00:30:00,159 --> 00:30:03,279
general cats um the trick in machine

947
00:30:03,279 --> 00:30:04,000
learning is just

948
00:30:04,000 --> 00:30:07,039
you shove more data at it um not always

949
00:30:07,039 --> 00:30:08,720
that's not always the fix for things but

950
00:30:08,720 --> 00:30:09,919
usually it's like

951
00:30:09,919 --> 00:30:11,520
why isn't my model working and the first

952
00:30:11,520 --> 00:30:14,000
question is did you give it enough data

953
00:30:14,000 --> 00:30:17,520
so data augmentation helps us um

954
00:30:17,520 --> 00:30:19,840
helps us create more data from that and

955
00:30:19,840 --> 00:30:21,279
for our case what we're going to be

956
00:30:21,279 --> 00:30:21,760
doing

957
00:30:21,760 --> 00:30:25,279
is taking up and putting in background

958
00:30:25,279 --> 00:30:26,080
noise

959
00:30:26,080 --> 00:30:28,240
because we have a lot of starting data

960
00:30:28,240 --> 00:30:30,000
we have over 1500 and we're gonna be

961
00:30:30,000 --> 00:30:32,480
creating 1500 samples for each category

962
00:30:32,480 --> 00:30:35,679
we can actually take a unique keyword

963
00:30:35,679 --> 00:30:38,080
or sample of a keyword and mix in random

964
00:30:38,080 --> 00:30:39,279
background noise and that just helps

965
00:30:39,279 --> 00:30:40,799
create a more robust model if we were to

966
00:30:40,799 --> 00:30:42,480
do real data augmentation we take

967
00:30:42,480 --> 00:30:45,679
each keyword mix each keyword

968
00:30:45,679 --> 00:30:48,080
with a random sample of background data

969
00:30:48,080 --> 00:30:49,679
so each one becomes like

970
00:30:49,679 --> 00:30:51,679
eight or nine samples so we start with

971
00:30:51,679 --> 00:30:53,120
you know 2000

972
00:30:53,120 --> 00:30:55,760
and we end up with like 10 000 samples

973
00:30:55,760 --> 00:30:57,679
because we've each keyword now has

974
00:30:57,679 --> 00:30:58,720
different samples with different

975
00:30:58,720 --> 00:31:00,720
background that's even better we just

976
00:31:00,720 --> 00:31:01,840
don't have the time because people would

977
00:31:01,840 --> 00:31:03,519
be waiting forever to upload all of that

978
00:31:03,519 --> 00:31:05,120
data to edge impulse and the data

979
00:31:05,120 --> 00:31:06,640
curation script would take like three

980
00:31:06,640 --> 00:31:08,320
hours

981
00:31:08,320 --> 00:31:10,080
i did this so i actually know on my

982
00:31:10,080 --> 00:31:12,000
local machine it takes like three hours

983
00:31:12,000 --> 00:31:13,279
if you do this method to end up with

984
00:31:13,279 --> 00:31:16,320
like 20 000 samples

985
00:31:16,320 --> 00:31:18,720
let's check on the script how is it

986
00:31:18,720 --> 00:31:21,120
going

987
00:31:21,360 --> 00:31:23,440
all right so for whatever bizarre reason

988
00:31:23,440 --> 00:31:25,279
collab does not like to show my progress

989
00:31:25,279 --> 00:31:25,840
bars

990
00:31:25,840 --> 00:31:28,000
so once it's done mixing the progress

991
00:31:28,000 --> 00:31:30,320
bar will just appear at 100

992
00:31:30,320 --> 00:31:32,399
the progress bars do work at on your

993
00:31:32,399 --> 00:31:34,000
local machine if you run it locally i

994
00:31:34,000 --> 00:31:34,320
just

995
00:31:34,320 --> 00:31:36,080
never bothered to fix it on co-lab so

996
00:31:36,080 --> 00:31:37,279
that's why you're seeing a weird

997
00:31:37,279 --> 00:31:38,159
progress bar

998
00:31:38,159 --> 00:31:39,120
all right so it's finished with

999
00:31:39,120 --> 00:31:40,399
background noise and it's currently

1000
00:31:40,399 --> 00:31:41,360
mixing house

1001
00:31:41,360 --> 00:31:44,840
great we have time to do some more

1002
00:31:44,840 --> 00:31:46,559
talking

1003
00:31:46,559 --> 00:31:48,960
all right while that's going a little

1004
00:31:48,960 --> 00:31:50,640
bit of history of artificial

1005
00:31:50,640 --> 00:31:51,679
intelligence

1006
00:31:51,679 --> 00:31:53,519
ah you hear it artificial intelligence

1007
00:31:53,519 --> 00:31:56,320
ai ml machine learning deep learning all

1008
00:31:56,320 --> 00:31:58,000
these terms are thrown around and a lot

1009
00:31:58,000 --> 00:31:58,600
of times

1010
00:31:58,600 --> 00:32:00,720
interchangeably um and the machine

1011
00:32:00,720 --> 00:32:02,320
learning community has kind of come up

1012
00:32:02,320 --> 00:32:04,480
with this concentric model of what

1013
00:32:04,480 --> 00:32:07,360
ai versus ml means so if anybody here is

1014
00:32:07,360 --> 00:32:08,960
familiar and works with ml

1015
00:32:08,960 --> 00:32:10,720
i apologize because you've probably

1016
00:32:10,720 --> 00:32:12,880
already heard this but for anybody who's

1017
00:32:12,880 --> 00:32:13,840
new to it

1018
00:32:13,840 --> 00:32:15,919
this could be an interesting take and

1019
00:32:15,919 --> 00:32:17,200
hopefully give you some

1020
00:32:17,200 --> 00:32:19,360
vocabulary when you're talking about ai

1021
00:32:19,360 --> 00:32:21,600
or ml so what is artificial intelligence

1022
00:32:21,600 --> 00:32:22,240
it was

1023
00:32:22,240 --> 00:32:25,440
coined in 1956 by john mccarthy um as

1024
00:32:25,440 --> 00:32:27,519
part of this conference he wanted to

1025
00:32:27,519 --> 00:32:29,760
bring people together to discuss can we

1026
00:32:29,760 --> 00:32:31,200
make computers

1027
00:32:31,200 --> 00:32:33,840
behave like humans um can we give them

1028
00:32:33,840 --> 00:32:35,440
intelligence and it was it was very

1029
00:32:35,440 --> 00:32:36,960
conceptual a very small group of

1030
00:32:36,960 --> 00:32:39,279
researchers doing this kind of work

1031
00:32:39,279 --> 00:32:42,720
later he came later he comes back um

1032
00:32:42,720 --> 00:32:46,080
in in in an interview and

1033
00:32:46,080 --> 00:32:48,320
gives a much better definition ai is the

1034
00:32:48,320 --> 00:32:49,679
science and engineering of making

1035
00:32:49,679 --> 00:32:51,360
intelligent machines especially the

1036
00:32:51,360 --> 00:32:53,440
intelligent computer programs okay

1037
00:32:53,440 --> 00:32:55,600
john what is intelligence intelligence

1038
00:32:55,600 --> 00:32:57,120
is the computational part

1039
00:32:57,120 --> 00:32:58,640
of the ability to achieve goals in the

1040
00:32:58,640 --> 00:33:00,880
world so according to john mccarthy here

1041
00:33:00,880 --> 00:33:04,000
anything that tries to achieve a goal is

1042
00:33:04,000 --> 00:33:05,840
considered intelligent and if we have a

1043
00:33:05,840 --> 00:33:07,360
computer do that it's considered

1044
00:33:07,360 --> 00:33:09,519
artificial intelligence

1045
00:33:09,519 --> 00:33:12,880
that is hugely broad um from what i

1046
00:33:12,880 --> 00:33:14,480
could tell

1047
00:33:14,480 --> 00:33:17,679
if i program my thermostat to say

1048
00:33:17,679 --> 00:33:20,799
keep the room around 72 degrees

1049
00:33:20,799 --> 00:33:22,640
fahrenheit

1050
00:33:22,640 --> 00:33:24,640
and it does so with like a few if

1051
00:33:24,640 --> 00:33:26,399
statements that's

1052
00:33:26,399 --> 00:33:30,559
a i okay so ai can be very

1053
00:33:30,559 --> 00:33:34,480
very broad so what about machine

1054
00:33:34,480 --> 00:33:35,360
learning so this

1055
00:33:35,360 --> 00:33:38,159
comes about not much later after john

1056
00:33:38,159 --> 00:33:39,120
mccarthy

1057
00:33:39,120 --> 00:33:41,360
a guy named arthur samuel coined the

1058
00:33:41,360 --> 00:33:43,039
term um if you're familiar with

1059
00:33:43,039 --> 00:33:45,360
his work he was famous for making a

1060
00:33:45,360 --> 00:33:46,159
computer

1061
00:33:46,159 --> 00:33:48,640
uh play checkers and that checkers

1062
00:33:48,640 --> 00:33:50,159
experiment i think it took him years to

1063
00:33:50,159 --> 00:33:51,279
finally get it

1064
00:33:51,279 --> 00:33:52,799
working and he wrote a paper about it

1065
00:33:52,799 --> 00:33:54,240
where he coined this term machine

1066
00:33:54,240 --> 00:33:55,360
learning

1067
00:33:55,360 --> 00:33:58,399
this has more to do with can a computer

1068
00:33:58,399 --> 00:34:00,640
learn from experience and apply that

1069
00:34:00,640 --> 00:34:02,080
experience to

1070
00:34:02,080 --> 00:34:04,320
data or situations it's never seen

1071
00:34:04,320 --> 00:34:05,760
before so that's why he chose

1072
00:34:05,760 --> 00:34:07,440
checkers because checkers has a fairly

1073
00:34:07,440 --> 00:34:09,440
strict rule set

1074
00:34:09,440 --> 00:34:11,359
and can you teach it to learn from prior

1075
00:34:11,359 --> 00:34:13,359
experience to eventually beat you

1076
00:34:13,359 --> 00:34:16,639
in checkers tom mitchell in his textbook

1077
00:34:16,639 --> 00:34:21,119
in 97 gave a much more sciencey

1078
00:34:21,119 --> 00:34:22,719
like much more science-y specific

1079
00:34:22,719 --> 00:34:24,480
definition a computer program is said to

1080
00:34:24,480 --> 00:34:25,599
learn from experience e

1081
00:34:25,599 --> 00:34:28,560
with respect to a class of class of

1082
00:34:28,560 --> 00:34:29,359
tasks t

1083
00:34:29,359 --> 00:34:30,879
and performance measure p if it's

1084
00:34:30,879 --> 00:34:32,800
performance in tasks t

1085
00:34:32,800 --> 00:34:34,320
as measured by p improves with

1086
00:34:34,320 --> 00:34:36,239
experience vader basically d

1087
00:34:36,239 --> 00:34:38,719
does a computer program get better at

1088
00:34:38,719 --> 00:34:39,679
some task

1089
00:34:39,679 --> 00:34:41,599
as it's learned from prior experience so

1090
00:34:41,599 --> 00:34:42,879
that is machine learning and we can

1091
00:34:42,879 --> 00:34:44,399
apply that to things like we can

1092
00:34:44,399 --> 00:34:45,839
show it a bunch of pictures of cats and

1093
00:34:45,839 --> 00:34:48,480
have it learn what a cat looks like

1094
00:34:48,480 --> 00:34:50,480
finally we get to what is this deep

1095
00:34:50,480 --> 00:34:52,079
learning so rina dector

1096
00:34:52,079 --> 00:34:54,639
wrote this paper um somebody's gonna

1097
00:34:54,639 --> 00:34:56,320
correct me here i think she was doing

1098
00:34:56,320 --> 00:34:58,960
biology research um when she wrote this

1099
00:34:58,960 --> 00:34:59,440
paper

1100
00:34:59,440 --> 00:35:02,480
around in 1986 and she defined it as a

1101
00:35:02,480 --> 00:35:03,920
class of machine learning algorithms

1102
00:35:03,920 --> 00:35:04,480
that use

1103
00:35:04,480 --> 00:35:06,720
multiple layers to progressively extract

1104
00:35:06,720 --> 00:35:07,760
higher level features

1105
00:35:07,760 --> 00:35:10,000
from the raw input funny enough

1106
00:35:10,000 --> 00:35:12,160
wikipedia of all places gives the best

1107
00:35:12,160 --> 00:35:13,760
definition that i have found for

1108
00:35:13,760 --> 00:35:16,240
deep learning basically it's machine

1109
00:35:16,240 --> 00:35:17,440
learning

1110
00:35:17,440 --> 00:35:19,680
but more complex so like okay what are

1111
00:35:19,680 --> 00:35:21,119
we talking about complex

1112
00:35:21,119 --> 00:35:23,040
the idea is that we start to run

1113
00:35:23,040 --> 00:35:24,240
multiple layers

1114
00:35:24,240 --> 00:35:27,599
of learning algorithms where the first

1115
00:35:27,599 --> 00:35:29,280
one says does things like extract

1116
00:35:29,280 --> 00:35:30,240
features and says

1117
00:35:30,240 --> 00:35:32,480
what am i interested in and that feeds

1118
00:35:32,480 --> 00:35:33,839
it to the next layer where it may say

1119
00:35:33,839 --> 00:35:34,160
like

1120
00:35:34,160 --> 00:35:36,000
try to classify those features that have

1121
00:35:36,000 --> 00:35:37,440
been fed to it from the first layer

1122
00:35:37,440 --> 00:35:39,359
the reason that's machine learning is

1123
00:35:39,359 --> 00:35:41,280
because we're not directly adjusting

1124
00:35:41,280 --> 00:35:42,800
these parameters we're not directly

1125
00:35:42,800 --> 00:35:43,599
feeding it

1126
00:35:43,599 --> 00:35:45,520
these features we're saying go ahead and

1127
00:35:45,520 --> 00:35:47,200
learn here's a picture

1128
00:35:47,200 --> 00:35:49,359
you tell me what features you want to

1129
00:35:49,359 --> 00:35:51,280
learn right this might be it picks out

1130
00:35:51,280 --> 00:35:54,000
you know for for facial recognition we

1131
00:35:54,000 --> 00:35:54,640
might have

1132
00:35:54,640 --> 00:35:56,160
fed machine learning algorithms

1133
00:35:56,160 --> 00:35:58,000
originally like oh look at

1134
00:35:58,000 --> 00:36:00,240
where your eyes are or your nose are and

1135
00:36:00,240 --> 00:36:01,200
then we you know

1136
00:36:01,200 --> 00:36:02,640
and then we feed that to some type of

1137
00:36:02,640 --> 00:36:04,640
classification to do facial recognition

1138
00:36:04,640 --> 00:36:05,040
but

1139
00:36:05,040 --> 00:36:06,400
this deep learning says you know what

1140
00:36:06,400 --> 00:36:08,320
here's an image of a face

1141
00:36:08,320 --> 00:36:10,000
learn it actually here's a thousand

1142
00:36:10,000 --> 00:36:12,000
feature or here's a thousand images

1143
00:36:12,000 --> 00:36:15,760
of faces learn what those are and so

1144
00:36:15,760 --> 00:36:17,920
um it goes through and it might take out

1145
00:36:17,920 --> 00:36:19,359
like ears and

1146
00:36:19,359 --> 00:36:21,520
your hairline you're like i never

1147
00:36:21,520 --> 00:36:22,880
thought to do that so the machine's

1148
00:36:22,880 --> 00:36:23,920
doing stuff that

1149
00:36:23,920 --> 00:36:25,440
we don't know about it's outside of our

1150
00:36:25,440 --> 00:36:27,440
control at this point or

1151
00:36:27,440 --> 00:36:29,119
uh even sometimes under understanding

1152
00:36:29,119 --> 00:36:30,160
and that's kind of what makes it this

1153
00:36:30,160 --> 00:36:31,040
deep learning

1154
00:36:31,040 --> 00:36:32,880
we don't know they become these black

1155
00:36:32,880 --> 00:36:34,480
boxes now there are ways to dig in and

1156
00:36:34,480 --> 00:36:35,920
figure out what the machine's looking at

1157
00:36:35,920 --> 00:36:37,280
with these like heat maps which is

1158
00:36:37,280 --> 00:36:38,160
really cool

1159
00:36:38,160 --> 00:36:40,000
but we're not telling it look at these

1160
00:36:40,000 --> 00:36:42,000
features the machine's learning to do it

1161
00:36:42,000 --> 00:36:44,240
so you end up with this concentric view

1162
00:36:44,240 --> 00:36:45,200
of ai

1163
00:36:45,200 --> 00:36:48,079
ml and deep learning where um machine

1164
00:36:48,079 --> 00:36:48,880
learning is a

1165
00:36:48,880 --> 00:36:52,240
part of intel ai and deep learning

1166
00:36:52,240 --> 00:36:54,720
is a part of machine learning we're

1167
00:36:54,720 --> 00:36:56,560
using more complex models so

1168
00:36:56,560 --> 00:37:00,079
i hope that gives people a broad idea of

1169
00:37:00,079 --> 00:37:01,520
what we're talking about here are there

1170
00:37:01,520 --> 00:37:02,880
any questions while we're going to go

1171
00:37:02,880 --> 00:37:04,079
back

1172
00:37:04,079 --> 00:37:07,119
and we are going to take a look at our

1173
00:37:07,119 --> 00:37:08,720
script that's running

1174
00:37:08,720 --> 00:37:11,200
excellent i'm still on zero so i've got

1175
00:37:11,200 --> 00:37:11,839
some ways

1176
00:37:11,839 --> 00:37:13,760
to go i think everybody in this class

1177
00:37:13,760 --> 00:37:15,440
when i ran this last night it took about

1178
00:37:15,440 --> 00:37:16,640
20 minutes

1179
00:37:16,640 --> 00:37:18,400
and i'm curious if i'm if i'm just

1180
00:37:18,400 --> 00:37:19,680
talking quickly

1181
00:37:19,680 --> 00:37:23,200
or if i am

1182
00:37:23,200 --> 00:37:25,359
no i just talked quickly for that i have

1183
00:37:25,359 --> 00:37:26,880
no voice uh

1184
00:37:26,880 --> 00:37:28,160
i guess people are trying to ask

1185
00:37:28,160 --> 00:37:30,640
questions

1186
00:37:34,480 --> 00:37:36,480
yes i do i talk quickly i'm trying to

1187
00:37:36,480 --> 00:37:37,599
burn through this because i know i only

1188
00:37:37,599 --> 00:37:38,640
have two hours

1189
00:37:38,640 --> 00:37:40,079
uh when i'm when i'm making a

1190
00:37:40,079 --> 00:37:41,760
pre-recorded video i go a little more

1191
00:37:41,760 --> 00:37:42,960
slowly and stuff

1192
00:37:42,960 --> 00:37:44,560
um but for this whenever i give

1193
00:37:44,560 --> 00:37:46,000
presentations like oh we gotta get to

1194
00:37:46,000 --> 00:37:46,720
all these

1195
00:37:46,720 --> 00:37:50,079
things so we're going through these here

1196
00:37:50,079 --> 00:37:50,480
so

1197
00:37:50,480 --> 00:37:52,160
hopefully everybody's on this is every

1198
00:37:52,160 --> 00:37:54,720
anybody stuck i want to ask is everybody

1199
00:37:54,720 --> 00:37:56,960
up to here if you're following along

1200
00:37:56,960 --> 00:37:58,960
oh we've got some some comments rolling

1201
00:37:58,960 --> 00:38:00,720
in from anybody interested in other data

1202
00:38:00,720 --> 00:38:01,680
sets

1203
00:38:01,680 --> 00:38:03,760
uh here is a list actually let's go

1204
00:38:03,760 --> 00:38:05,680
explore that let looks really cool

1205
00:38:05,680 --> 00:38:07,440
good everybody's everybody who wants to

1206
00:38:07,440 --> 00:38:09,119
follow along is following along and up

1207
00:38:09,119 --> 00:38:09,920
to this point

1208
00:38:09,920 --> 00:38:19,599
where they are um doing the curation

1209
00:38:19,599 --> 00:38:21,599
uh sean will be helping the first time

1210
00:38:21,599 --> 00:38:23,680
users of stm ide

1211
00:38:23,680 --> 00:38:25,920
kind of i'm gonna show you what you need

1212
00:38:25,920 --> 00:38:28,480
to do in order to run this demo

1213
00:38:28,480 --> 00:38:30,079
um that is unfortunately one of those

1214
00:38:30,079 --> 00:38:32,079
things that is a little bit canned

1215
00:38:32,079 --> 00:38:34,880
at this point um because i don't have

1216
00:38:34,880 --> 00:38:36,640
time to go into all the features of stm

1217
00:38:36,640 --> 00:38:37,359
ide

1218
00:38:37,359 --> 00:38:40,160
um i've got videos out there that show

1219
00:38:40,160 --> 00:38:41,520
you like what you need to do to like get

1220
00:38:41,520 --> 00:38:42,800
to blinky

1221
00:38:42,800 --> 00:38:46,800
and all of this speak faster yeah

1222
00:38:46,800 --> 00:38:48,320
okay so everybody's saying that the uh

1223
00:38:48,320 --> 00:38:50,320
curation script is going about the same

1224
00:38:50,320 --> 00:38:52,000
so everybody's right about here with the

1225
00:38:52,000 --> 00:38:53,119
curation

1226
00:38:53,119 --> 00:38:55,040
um and it has once it's done with zero

1227
00:38:55,040 --> 00:38:56,800
it's got one more

1228
00:38:56,800 --> 00:38:58,720
could you give us kind of a if we have a

1229
00:38:58,720 --> 00:39:00,480
minute an overview of the tool chain

1230
00:39:00,480 --> 00:39:01,680
that we're using

1231
00:39:01,680 --> 00:39:04,480
like clicking a lot but i want to have a

1232
00:39:04,480 --> 00:39:06,000
better understanding of how everything's

1233
00:39:06,000 --> 00:39:08,560
linked together yeah very good question

1234
00:39:08,560 --> 00:39:09,760
thank you

1235
00:39:09,760 --> 00:39:11,680
so the tool chain that we're using here

1236
00:39:11,680 --> 00:39:13,280
is um

1237
00:39:13,280 --> 00:39:14,800
so we're running i wish i had a slide

1238
00:39:14,800 --> 00:39:16,079
for this that's a good question i didn't

1239
00:39:16,079 --> 00:39:17,599
think about that beforehand

1240
00:39:17,599 --> 00:39:20,560
we have um jupiter notebooks or on a

1241
00:39:20,560 --> 00:39:22,240
google server we have a jupyter notebook

1242
00:39:22,240 --> 00:39:23,680
that's basically running python right

1243
00:39:23,680 --> 00:39:25,680
this is all this is is just a python

1244
00:39:25,680 --> 00:39:26,480
script

1245
00:39:26,480 --> 00:39:28,160
more or less and jupiter notebook just

1246
00:39:28,160 --> 00:39:29,520
lets us run that in

1247
00:39:29,520 --> 00:39:31,200
you know chunks at a time it's very good

1248
00:39:31,200 --> 00:39:32,480
for learning if you haven't played with

1249
00:39:32,480 --> 00:39:32,960
it um

1250
00:39:32,960 --> 00:39:36,240
i really like it and so we've got we've

1251
00:39:36,240 --> 00:39:38,000
got python running here

1252
00:39:38,000 --> 00:39:39,599
what we're doing with this python is

1253
00:39:39,599 --> 00:39:41,760
calling this is the silly part with the

1254
00:39:41,760 --> 00:39:42,320
co-lab

1255
00:39:42,320 --> 00:39:43,520
which is why i recommend if you have

1256
00:39:43,520 --> 00:39:45,839
time run it locally um because we're

1257
00:39:45,839 --> 00:39:47,040
running it in co-lab we're actually

1258
00:39:47,040 --> 00:39:48,400
using colab here

1259
00:39:48,400 --> 00:39:51,280
to run system calls more or less so like

1260
00:39:51,280 --> 00:39:51,839
this

1261
00:39:51,839 --> 00:39:54,560
um exclamation point python we're

1262
00:39:54,560 --> 00:39:55,520
actually telling

1263
00:39:55,520 --> 00:39:58,320
linux to run python and do pip to

1264
00:39:58,320 --> 00:39:58,960
install

1265
00:39:58,960 --> 00:40:01,280
use pip to install the sound file

1266
00:40:01,280 --> 00:40:02,240
package

1267
00:40:02,240 --> 00:40:04,560
um so sound files like one library that

1268
00:40:04,560 --> 00:40:05,920
we're using to read and write

1269
00:40:05,920 --> 00:40:08,720
wav files later we'll be using the edge

1270
00:40:08,720 --> 00:40:10,319
impulse cli so right now

1271
00:40:10,319 --> 00:40:13,520
the best way to think about this this is

1272
00:40:13,520 --> 00:40:16,960
um is as a

1273
00:40:16,960 --> 00:40:18,560
linux box right i don't really have a

1274
00:40:18,560 --> 00:40:20,160
command line into it so

1275
00:40:20,160 --> 00:40:24,880
we're using colab to be a command line

1276
00:40:24,880 --> 00:40:29,440
uh ml ops i must have missed something

1277
00:40:29,440 --> 00:40:31,520
um yeah i'll get through this question

1278
00:40:31,520 --> 00:40:33,119
first we got a few about audio

1279
00:40:33,119 --> 00:40:35,920
so that's the first part and we're using

1280
00:40:35,920 --> 00:40:39,200
basically strict python

1281
00:40:39,200 --> 00:40:41,280
in this curation set um let's see what

1282
00:40:41,280 --> 00:40:43,200
does it install what does it need

1283
00:40:43,200 --> 00:40:46,319
uh sh util librosa sound file numpy it's

1284
00:40:46,319 --> 00:40:47,520
some basic like

1285
00:40:47,520 --> 00:40:50,079
audio manipulation and numpy for doing

1286
00:40:50,079 --> 00:40:50,880
matrix type

1287
00:40:50,880 --> 00:40:53,200
operations um this python script all

1288
00:40:53,200 --> 00:40:54,720
it's doing is just curation right we

1289
00:40:54,720 --> 00:40:56,720
went through that we've got curation so

1290
00:40:56,720 --> 00:40:59,599
the the pipeline from there is once

1291
00:40:59,599 --> 00:41:00,960
we've curated this data set

1292
00:41:00,960 --> 00:41:02,800
we're going to send all of these to edge

1293
00:41:02,800 --> 00:41:04,000
impulse which which is

1294
00:41:04,000 --> 00:41:07,040
this online tool that does the training

1295
00:41:07,040 --> 00:41:07,680
for us

1296
00:41:07,680 --> 00:41:10,160
and once we get to here i'll show you

1297
00:41:10,160 --> 00:41:11,359
what's going on where we're going to do

1298
00:41:11,359 --> 00:41:12,800
feature extraction to

1299
00:41:12,800 --> 00:41:14,960
to generate uh mel frequency sexual

1300
00:41:14,960 --> 00:41:16,319
coefficients

1301
00:41:16,319 --> 00:41:18,960
those get fed as features into a

1302
00:41:18,960 --> 00:41:20,560
convolutional neural network

1303
00:41:20,560 --> 00:41:22,720
that's going to be trained using keras

1304
00:41:22,720 --> 00:41:24,640
on top of tensorflow

1305
00:41:24,640 --> 00:41:26,800
once that's done we're going to download

1306
00:41:26,800 --> 00:41:27,839
a text like

1307
00:41:27,839 --> 00:41:29,280
it's going to be converted the model

1308
00:41:29,280 --> 00:41:30,960
itself will be converted to a tensorflow

1309
00:41:30,960 --> 00:41:31,680
lite model

1310
00:41:31,680 --> 00:41:33,280
we're going to download that and include

1311
00:41:33,280 --> 00:41:35,839
it in our um

1312
00:41:35,839 --> 00:41:38,880
in our ide our um

1313
00:41:38,880 --> 00:41:42,240
our oh good lord

1314
00:41:42,480 --> 00:41:46,160
our entire set for um stm

1315
00:41:46,160 --> 00:41:48,160
for the stm code um that's going to be a

1316
00:41:48,160 --> 00:41:49,520
library first just like a c

1317
00:41:49,520 --> 00:41:51,520
plus library so i hope that helps does

1318
00:41:51,520 --> 00:41:53,200
that kind of give you an idea of like

1319
00:41:53,200 --> 00:41:55,359
the technology pipeline we're using here

1320
00:41:55,359 --> 00:41:57,119
yeah that was great thank you

1321
00:41:57,119 --> 00:41:58,560
cool all right i've got a few other

1322
00:41:58,560 --> 00:42:02,960
questions here

1323
00:42:02,960 --> 00:42:05,839
i got to blinky last night in stm30 and

1324
00:42:05,839 --> 00:42:08,240
stm32 and it was a lot yeah stm32 is

1325
00:42:08,240 --> 00:42:08,800
like

1326
00:42:08,800 --> 00:42:10,480
i now know how to do this in arduino and

1327
00:42:10,480 --> 00:42:14,319
i would have definitely done an arduino

1328
00:42:14,319 --> 00:42:18,079
stm32 stm32 cube id is is is a lot it's

1329
00:42:18,079 --> 00:42:18,560
it's a

1330
00:42:18,560 --> 00:42:20,400
professional ide it's built on top of

1331
00:42:20,400 --> 00:42:22,160
eclipse um

1332
00:42:22,160 --> 00:42:24,079
i am not a big fan of eclipse but

1333
00:42:24,079 --> 00:42:26,880
generally stm32 cube

1334
00:42:26,880 --> 00:42:28,640
uh ide works out of the box when we

1335
00:42:28,640 --> 00:42:30,319
gather audio data with hardware should

1336
00:42:30,319 --> 00:42:31,760
we use the device or mobile phone so

1337
00:42:31,760 --> 00:42:33,040
that is a very good question

1338
00:42:33,040 --> 00:42:36,319
um the method we're doing

1339
00:42:36,319 --> 00:42:39,920
with this with the mel frequency steps

1340
00:42:39,920 --> 00:42:41,359
coefficients

1341
00:42:41,359 --> 00:42:44,160
actually works from just about any

1342
00:42:44,160 --> 00:42:45,839
hardware recording device

1343
00:42:45,839 --> 00:42:47,520
especially considering we've resampled

1344
00:42:47,520 --> 00:42:49,760
it and we're going to be

1345
00:42:49,760 --> 00:42:51,359
doing the discrete cosine transform

1346
00:42:51,359 --> 00:42:52,640
which then gives us an idea of the

1347
00:42:52,640 --> 00:42:53,359
overall

1348
00:42:53,359 --> 00:42:55,760
shape of this this spectrogram is kind

1349
00:42:55,760 --> 00:42:56,880
of what's going on

1350
00:42:56,880 --> 00:42:58,560
which means that we can record it with

1351
00:42:58,560 --> 00:43:00,079
any device um

1352
00:43:00,079 --> 00:43:01,440
depending on your machine learning

1353
00:43:01,440 --> 00:43:02,800
application so initially when i was

1354
00:43:02,800 --> 00:43:04,480
trying this i was trying it without the

1355
00:43:04,480 --> 00:43:06,480
mfcc's i was doing it with just the

1356
00:43:06,480 --> 00:43:07,359
spectrogram

1357
00:43:07,359 --> 00:43:09,359
gram when you do it that way the

1358
00:43:09,359 --> 00:43:11,200
microphone definitely

1359
00:43:11,200 --> 00:43:14,240
um plays a much bigger factor into

1360
00:43:14,240 --> 00:43:16,800
um what your sound signature looks like

1361
00:43:16,800 --> 00:43:17,680
and you should use

1362
00:43:17,680 --> 00:43:20,000
just that microphone um so my

1363
00:43:20,000 --> 00:43:21,599
recommendation is if you were recording

1364
00:43:21,599 --> 00:43:22,720
data yourself

1365
00:43:22,720 --> 00:43:25,040
um i would always try to use the same

1366
00:43:25,040 --> 00:43:26,400
sensor if you can

1367
00:43:26,400 --> 00:43:28,319
there are mathematical things you can do

1368
00:43:28,319 --> 00:43:29,680
to extract features that where it

1369
00:43:29,680 --> 00:43:30,720
doesn't matter which

1370
00:43:30,720 --> 00:43:33,359
sensor you're using um to a degree so i

1371
00:43:33,359 --> 00:43:35,839
hope that answers that question

1372
00:43:35,839 --> 00:43:37,760
i programmed a base program didn't do

1373
00:43:37,760 --> 00:43:39,280
anything just look into the download

1374
00:43:39,280 --> 00:43:40,079
verified

1375
00:43:40,079 --> 00:43:43,599
cool um we're using collab as ml ops

1376
00:43:43,599 --> 00:43:45,359
machine so uh yeah i guess that was the

1377
00:43:45,359 --> 00:43:47,040
question we're not this is not

1378
00:43:47,040 --> 00:43:48,640
the collab is not the ml ops in this

1379
00:43:48,640 --> 00:43:50,400
case which is hilarious it's just a way

1380
00:43:50,400 --> 00:43:50,880
so that

1381
00:43:50,880 --> 00:43:51,920
people didn't have to install a whole

1382
00:43:51,920 --> 00:43:53,359
bunch of python stuff on their own

1383
00:43:53,359 --> 00:43:54,160
computer

1384
00:43:54,160 --> 00:43:57,359
um yes a collab is a decent way to do

1385
00:43:57,359 --> 00:44:01,040
tinkering with ml ops um however

1386
00:44:01,040 --> 00:44:04,240
please note that uh collab disconnects

1387
00:44:04,240 --> 00:44:05,359
you from the runtime at

1388
00:44:05,359 --> 00:44:07,200
90 minutes um if you're if you're not

1389
00:44:07,200 --> 00:44:09,280
using the mouse or interacting with it

1390
00:44:09,280 --> 00:44:10,960
in fact we may see that happen at some

1391
00:44:10,960 --> 00:44:12,400
point

1392
00:44:12,400 --> 00:44:14,319
um you could that in that case you just

1393
00:44:14,319 --> 00:44:15,599
click in and get to it

1394
00:44:15,599 --> 00:44:18,400
um if you've been using it for 12 hours

1395
00:44:18,400 --> 00:44:19,920
it will completely shut you down and

1396
00:44:19,920 --> 00:44:21,680
reset the whole

1397
00:44:21,680 --> 00:44:23,760
file system linux server and everything

1398
00:44:23,760 --> 00:44:24,720
for you so you

1399
00:44:24,720 --> 00:44:27,920
cannot use colab to do um end and ml

1400
00:44:27,920 --> 00:44:29,599
ops especially if you're training like

1401
00:44:29,599 --> 00:44:31,520
large networks that take a day

1402
00:44:31,520 --> 00:44:33,440
to train um it's really meant for

1403
00:44:33,440 --> 00:44:35,280
research colab is a great

1404
00:44:35,280 --> 00:44:36,880
um interface for for research and

1405
00:44:36,880 --> 00:44:38,720
training small models um

1406
00:44:38,720 --> 00:44:40,960
but not for big models um and like not

1407
00:44:40,960 --> 00:44:42,319
for like setting up a full pipeline it

1408
00:44:42,319 --> 00:44:44,880
will just disconnect you

1409
00:44:44,880 --> 00:44:47,200
uh

1410
00:44:48,079 --> 00:44:49,599
can we do the edge impulse training

1411
00:44:49,599 --> 00:44:50,800
locally so we don't have to give our

1412
00:44:50,800 --> 00:44:51,680
data to somebody

1413
00:44:51,680 --> 00:44:54,800
else um i do not believe you can

1414
00:44:54,800 --> 00:44:58,480
at this point um because they're doing

1415
00:44:58,480 --> 00:44:59,280
all the server

1416
00:44:59,280 --> 00:45:00,800
all the all the training on their side

1417
00:45:00,800 --> 00:45:03,040
um that would be a question for edge

1418
00:45:03,040 --> 00:45:04,160
impulse

1419
00:45:04,160 --> 00:45:06,880
um if if any of the edge impulse people

1420
00:45:06,880 --> 00:45:07,599
are here

1421
00:45:07,599 --> 00:45:09,599
um they can answer answer that one i

1422
00:45:09,599 --> 00:45:11,200
know you can set up like programmatic

1423
00:45:11,200 --> 00:45:12,319
there's an api where you can set up

1424
00:45:12,319 --> 00:45:14,000
programmatic stuff so you can do

1425
00:45:14,000 --> 00:45:16,079
um you can feed it data programmatically

1426
00:45:16,079 --> 00:45:17,280
but i still think it has to go through

1427
00:45:17,280 --> 00:45:18,160
their server

1428
00:45:18,160 --> 00:45:21,440
um for running locally uh that's where i

1429
00:45:21,440 --> 00:45:24,880
like i i do have model i do have

1430
00:45:24,880 --> 00:45:26,400
training algorithms out there um

1431
00:45:26,400 --> 00:45:28,560
on my github for training stuff locally

1432
00:45:28,560 --> 00:45:30,720
but it's not doing the full mfcc

1433
00:45:30,720 --> 00:45:32,400
thing where you get a better model from

1434
00:45:32,400 --> 00:45:34,000
edge impulse which is why i'm using edge

1435
00:45:34,000 --> 00:45:35,119
impulse and it just makes it easier and

1436
00:45:35,119 --> 00:45:38,319
you can see the graphical flow

1437
00:45:39,359 --> 00:45:41,040
uh anybody got oh here we go ain't got

1438
00:45:41,040 --> 00:45:43,520
blinky working with os x

1439
00:45:43,520 --> 00:45:46,240
um i've seen some issues with osx

1440
00:45:46,240 --> 00:45:47,200
whatever you're running

1441
00:45:47,200 --> 00:45:49,520
i don't have a mac so i'm unable to

1442
00:45:49,520 --> 00:45:50,800
verify what's going on

1443
00:45:50,800 --> 00:45:54,640
with um with mac stuff with stm32

1444
00:45:54,640 --> 00:45:58,160
um yeah the debugging connection loss

1445
00:45:58,160 --> 00:45:58,800
shuts down

1446
00:45:58,800 --> 00:46:00,319
other people have run into this try

1447
00:46:00,319 --> 00:46:02,000
using the program for my github to see

1448
00:46:02,000 --> 00:46:02,960
if that works

1449
00:46:02,960 --> 00:46:05,119
um there have been other issues with

1450
00:46:05,119 --> 00:46:06,560
just trying blinky

1451
00:46:06,560 --> 00:46:09,119
um and the deep where the debugger just

1452
00:46:09,119 --> 00:46:14,800
shuts down

1453
00:46:14,800 --> 00:46:17,520
can you log multiple channels at audio

1454
00:46:17,520 --> 00:46:19,839
speeds that are synced can you log

1455
00:46:19,839 --> 00:46:23,200
multiple this is on youtube i not quite

1456
00:46:23,200 --> 00:46:26,160
sure um any if you have multiple

1457
00:46:26,160 --> 00:46:28,160
channels coming in

1458
00:46:28,160 --> 00:46:30,079
yeah right now we're doing mono so like

1459
00:46:30,079 --> 00:46:32,000
16 kilohertz mono if you've got

1460
00:46:32,000 --> 00:46:35,359
two channels that creates another uh

1461
00:46:35,359 --> 00:46:36,640
that creates something else that you

1462
00:46:36,640 --> 00:46:38,400
would need to train the model with so

1463
00:46:38,400 --> 00:46:39,200
you would have to

1464
00:46:39,200 --> 00:46:41,119
create the entire data set from scratch

1465
00:46:41,119 --> 00:46:42,480
because now you have twice the data

1466
00:46:42,480 --> 00:46:45,760
being fed to the machine learning model

1467
00:46:45,760 --> 00:46:46,880
okay some people are saying if you're

1468
00:46:46,880 --> 00:46:48,640
running into problems with the uh

1469
00:46:48,640 --> 00:46:49,920
debugger not working in

1470
00:46:49,920 --> 00:46:53,359
stm32 cube ide go ahead and either try

1471
00:46:53,359 --> 00:46:54,960
restarting the ide

1472
00:46:54,960 --> 00:46:56,560
restarting your computer unplugging it

1473
00:46:56,560 --> 00:46:58,079
replugging it back in

1474
00:46:58,079 --> 00:47:00,160
all the good it stuff seems to work here

1475
00:47:00,160 --> 00:47:03,920
and magically fix it sometimes

1476
00:47:05,680 --> 00:47:08,800
and done good timing all right

1477
00:47:08,800 --> 00:47:10,400
let's continue running this script so

1478
00:47:10,400 --> 00:47:12,640
we've got the edge impulse tool done

1479
00:47:12,640 --> 00:47:14,240
all this is going to do actually let's

1480
00:47:14,240 --> 00:47:16,880
take a look at this first

1481
00:47:16,880 --> 00:47:18,240
so on the left side you should see

1482
00:47:18,240 --> 00:47:20,319
keywords curated

1483
00:47:20,319 --> 00:47:21,680
let's go into there and you should see

1484
00:47:21,680 --> 00:47:23,280
the four categories that you picked or

1485
00:47:23,280 --> 00:47:25,119
excuse me the two keywords you picked

1486
00:47:25,119 --> 00:47:27,440
plus unknown which is other keywords and

1487
00:47:27,440 --> 00:47:28,960
random background noise

1488
00:47:28,960 --> 00:47:30,400
feel free to try downloading one of

1489
00:47:30,400 --> 00:47:32,079
these so i'm gonna try house

1490
00:47:32,079 --> 00:47:33,680
and once again i don't think my system

1491
00:47:33,680 --> 00:47:39,839
audio is saved

1492
00:47:40,240 --> 00:47:43,279
i'm going to bring this up

1493
00:47:43,680 --> 00:47:45,760
so try running a couple of these what

1494
00:47:45,760 --> 00:47:47,280
you should hear is somebody saying a

1495
00:47:47,280 --> 00:47:49,280
keyword from that original data set

1496
00:47:49,280 --> 00:47:51,760
and mixed in background noise so give

1497
00:47:51,760 --> 00:47:52,720
that a shot if you want on your own

1498
00:47:52,720 --> 00:47:53,280
machine

1499
00:47:53,280 --> 00:47:54,800
i don't think you can hear my system

1500
00:47:54,800 --> 00:47:56,480
audio so um

1501
00:47:56,480 --> 00:47:59,359
i'll let you guys try that finally run

1502
00:47:59,359 --> 00:48:00,000
this last

1503
00:48:00,000 --> 00:48:03,200
cell and that is going to upload stuff

1504
00:48:03,200 --> 00:48:04,559
to edge impulse

1505
00:48:04,559 --> 00:48:07,119
um using that using that api key that we

1506
00:48:07,119 --> 00:48:08,400
gave it so i'm going to sit here and let

1507
00:48:08,400 --> 00:48:10,000
it start going

1508
00:48:10,000 --> 00:48:12,319
yay it's uploading everything if i come

1509
00:48:12,319 --> 00:48:14,559
into here in edge impulse

1510
00:48:14,559 --> 00:48:17,599
i go over to data acquisition um

1511
00:48:17,599 --> 00:48:19,119
and you'll start seeing some of the data

1512
00:48:19,119 --> 00:48:21,440
roll in um it may not be in real time

1513
00:48:21,440 --> 00:48:23,280
you might have to refresh some stuff but

1514
00:48:23,280 --> 00:48:25,040
it should happen in fact i think it does

1515
00:48:25,040 --> 00:48:27,440
test first yes it does test data first

1516
00:48:27,440 --> 00:48:30,720
which brings up a good point why are we

1517
00:48:30,720 --> 00:48:32,839
splitting stuff into

1518
00:48:32,839 --> 00:48:37,599
test and training sets

1519
00:48:37,599 --> 00:48:39,119
so we're running that script while it's

1520
00:48:39,119 --> 00:48:41,200
uploading for everybody

1521
00:48:41,200 --> 00:48:42,720
what we're doing here and let me get rid

1522
00:48:42,720 --> 00:48:45,919
of my my downloads

1523
00:48:47,440 --> 00:48:48,720
what we're doing here is we're splitting

1524
00:48:48,720 --> 00:48:51,119
the data set so we've got you know 1500

1525
00:48:51,119 --> 00:48:51,920
samples

1526
00:48:51,920 --> 00:48:53,920
and 20 of those are going off to this

1527
00:48:53,920 --> 00:48:56,000
test set which exists

1528
00:48:56,000 --> 00:48:58,640
separately from this training set um the

1529
00:48:58,640 --> 00:49:00,240
the samples were random

1530
00:49:00,240 --> 00:49:01,599
the samples were randomized when they

1531
00:49:01,599 --> 00:49:02,880
were chosen from the google speech

1532
00:49:02,880 --> 00:49:03,760
commands data set

1533
00:49:03,760 --> 00:49:05,920
so when they were given those file names

1534
00:49:05,920 --> 00:49:07,440
of like point zero zero zero zero point

1535
00:49:07,440 --> 00:49:08,880
zero zero zero one point zero zero

1536
00:49:08,880 --> 00:49:11,359
two those have been randomized anyway um

1537
00:49:11,359 --> 00:49:12,720
that's why i didn't use like a hash or

1538
00:49:12,720 --> 00:49:14,800
anything they've already been randomized

1539
00:49:14,800 --> 00:49:16,720
um and that so that that's why the

1540
00:49:16,720 --> 00:49:18,960
naming doesn't particularly matter

1541
00:49:18,960 --> 00:49:21,760
um for those individual keywords so we

1542
00:49:21,760 --> 00:49:22,880
set aside 20

1543
00:49:22,880 --> 00:49:24,559
for testing and the rest of it's going

1544
00:49:24,559 --> 00:49:26,000
to be used for training our neural

1545
00:49:26,000 --> 00:49:26,640
network

1546
00:49:26,640 --> 00:49:28,400
so why do we set aside stuff for testing

1547
00:49:28,400 --> 00:49:30,400
well we set aside these keywords for

1548
00:49:30,400 --> 00:49:32,160
testing because we need a way to verify

1549
00:49:32,160 --> 00:49:33,680
that the model worked okay that seems

1550
00:49:33,680 --> 00:49:34,800
simple enough but

1551
00:49:34,800 --> 00:49:37,680
we absolutely do not want to test with

1552
00:49:37,680 --> 00:49:39,119
any of the data that we used for

1553
00:49:39,119 --> 00:49:40,640
training and the reason for that

1554
00:49:40,640 --> 00:49:42,800
is because what you'll find often is

1555
00:49:42,800 --> 00:49:45,200
that your model if

1556
00:49:45,200 --> 00:49:47,520
usually when you start the model itself

1557
00:49:47,520 --> 00:49:49,280
will overfit the data and that just

1558
00:49:49,280 --> 00:49:50,000
means that

1559
00:49:50,000 --> 00:49:51,760
the model is very very good at picking

1560
00:49:51,760 --> 00:49:53,119
out the specific

1561
00:49:53,119 --> 00:49:56,240
instances and samples that you've

1562
00:49:56,240 --> 00:49:58,319
given it and it knows how i how to

1563
00:49:58,319 --> 00:50:00,319
identify those and it's very

1564
00:50:00,319 --> 00:50:03,040
bad at generalizing to data it's never

1565
00:50:03,040 --> 00:50:03,920
seen before

1566
00:50:03,920 --> 00:50:05,440
um so when you go to deploy it if all

1567
00:50:05,440 --> 00:50:06,880
you've ever done is done is looked at

1568
00:50:06,880 --> 00:50:07,760
training data

1569
00:50:07,760 --> 00:50:09,040
and you go to deploy this you're like

1570
00:50:09,040 --> 00:50:10,559
why isn't it working like well you

1571
00:50:10,559 --> 00:50:12,000
probably overfit or you probably

1572
00:50:12,000 --> 00:50:14,319
had the model overfit the data and so

1573
00:50:14,319 --> 00:50:15,040
the test

1574
00:50:15,040 --> 00:50:17,520
the test set helps us determine if

1575
00:50:17,520 --> 00:50:19,359
that's been over fit because it's

1576
00:50:19,359 --> 00:50:21,359
data that's never been seen by this

1577
00:50:21,359 --> 00:50:22,480
model before

1578
00:50:22,480 --> 00:50:25,280
so it's very very useful um i would say

1579
00:50:25,280 --> 00:50:26,160
you almost all

1580
00:50:26,160 --> 00:50:27,920
the way you always want to have a test

1581
00:50:27,920 --> 00:50:30,000
set um

1582
00:50:30,000 --> 00:50:32,480
is it 20 is it 10 that can be up to you

1583
00:50:32,480 --> 00:50:33,599
whatever your needs are but in the

1584
00:50:33,599 --> 00:50:34,480
machine learning world

1585
00:50:34,480 --> 00:50:36,800
20 set aside for testing is kind of your

1586
00:50:36,800 --> 00:50:39,200
normal

1587
00:50:39,520 --> 00:50:44,160
and let's see how that's going

1588
00:50:44,319 --> 00:50:46,960
this is still rolling so let's talk

1589
00:50:46,960 --> 00:50:48,240
about features and what's going to be

1590
00:50:48,240 --> 00:50:51,280
going on here with features

1591
00:50:51,280 --> 00:50:53,200
so the first step once we've uploaded

1592
00:50:53,200 --> 00:50:54,800
all of the data to

1593
00:50:54,800 --> 00:50:56,000
edge impulse we're going to be

1594
00:50:56,000 --> 00:50:58,400
extracting features features for us

1595
00:50:58,400 --> 00:51:00,000
are going to be the mel frequency

1596
00:51:00,000 --> 00:51:01,760
ceptual coefficients

1597
00:51:01,760 --> 00:51:04,720
yay whatever the heck those are i'm

1598
00:51:04,720 --> 00:51:06,240
going to briefly run through this and

1599
00:51:06,240 --> 00:51:07,920
then give you a link to a site to go

1600
00:51:07,920 --> 00:51:09,280
read on your own if you really want to

1601
00:51:09,280 --> 00:51:11,359
scramble your brain for what these are

1602
00:51:11,359 --> 00:51:14,160
um so here we go mel frequency ceptual

1603
00:51:14,160 --> 00:51:15,520
coefficients what we're doing

1604
00:51:15,520 --> 00:51:17,920
is here's our sample here's an audio

1605
00:51:17,920 --> 00:51:18,960
sample of saying somebody somebody's

1606
00:51:18,960 --> 00:51:20,960
saying like zero or something right

1607
00:51:20,960 --> 00:51:22,079
we're going to take a window we're going

1608
00:51:22,079 --> 00:51:23,520
to take a slice of this and we're going

1609
00:51:23,520 --> 00:51:24,240
to compute

1610
00:51:24,240 --> 00:51:27,440
the fast 48 transform which gives us

1611
00:51:27,440 --> 00:51:31,520
uh basically our power over our um

1612
00:51:31,520 --> 00:51:33,200
frequency so we've got these bins right

1613
00:51:33,200 --> 00:51:34,880
so like at zero hertz there's this much

1614
00:51:34,880 --> 00:51:35,599
power

1615
00:51:35,599 --> 00:51:38,319
in this spectrum and at 4 000 hertz

1616
00:51:38,319 --> 00:51:39,839
we've got this much power in the

1617
00:51:39,839 --> 00:51:41,680
spectrum and it kind of looks like that

1618
00:51:41,680 --> 00:51:44,880
and it's no longer a time series we're

1619
00:51:44,880 --> 00:51:46,000
not working in the time

1620
00:51:46,000 --> 00:51:47,359
domain anymore we're looking at it from

1621
00:51:47,359 --> 00:51:49,200
a frequency um

1622
00:51:49,200 --> 00:51:50,960
i wish i had time to get into how

1623
00:51:50,960 --> 00:51:52,559
fourier transforms work but

1624
00:51:52,559 --> 00:51:55,440
uh one i forgot most of my signals in

1625
00:51:55,440 --> 00:51:56,480
systems class

1626
00:51:56,480 --> 00:51:58,160
and two we don't have that kind of time

1627
00:51:58,160 --> 00:51:59,599
um that is a fun class if you ever want

1628
00:51:59,599 --> 00:52:01,200
to get into how fourier transforms work

1629
00:52:01,200 --> 00:52:02,079
and doing them by hand

1630
00:52:02,079 --> 00:52:04,720
anyway the next step we're going to be

1631
00:52:04,720 --> 00:52:05,200
doing

1632
00:52:05,200 --> 00:52:06,720
is we're going to be taking the

1633
00:52:06,720 --> 00:52:08,559
mel-spaced filter bank

1634
00:52:08,559 --> 00:52:11,920
mel spacing is basically

1635
00:52:11,920 --> 00:52:15,200
taking a linear set of of

1636
00:52:15,200 --> 00:52:18,319
filters um for lower frequencies and

1637
00:52:18,319 --> 00:52:20,960
logarithmic filters for higher

1638
00:52:20,960 --> 00:52:22,000
frequencies

1639
00:52:22,000 --> 00:52:23,839
and then combining the energy that it

1640
00:52:23,839 --> 00:52:25,440
sees in each of those

1641
00:52:25,440 --> 00:52:26,720
in each of those frequencies and

1642
00:52:26,720 --> 00:52:28,960
basically adding it up to create

1643
00:52:28,960 --> 00:52:31,520
a set of numbers an array so this point

1644
00:52:31,520 --> 00:52:32,000
zero zero

1645
00:52:32,000 --> 00:52:35,119
two comes from this first filter where

1646
00:52:35,119 --> 00:52:36,559
it just takes the energy that it sees

1647
00:52:36,559 --> 00:52:36,880
here

1648
00:52:36,880 --> 00:52:38,800
sums it up that's the first number the

1649
00:52:38,800 --> 00:52:40,240
second one is the second filter you

1650
00:52:40,240 --> 00:52:41,760
notice they overlap a little bit so it

1651
00:52:41,760 --> 00:52:43,920
adds up all the little blue line

1652
00:52:43,920 --> 00:52:45,920
all this power all these power numbers

1653
00:52:45,920 --> 00:52:47,520
you get an energy and it ends up in the

1654
00:52:47,520 --> 00:52:49,359
second one and it continues on

1655
00:52:49,359 --> 00:52:51,359
the reason they're specific in mel space

1656
00:52:51,359 --> 00:52:53,280
is because mel spacing has to do with

1657
00:52:53,280 --> 00:52:54,640
how humans perceive

1658
00:52:54,640 --> 00:52:57,040
sound we don't perceive sound in a

1659
00:52:57,040 --> 00:52:58,559
linear fashion in fact

1660
00:52:58,559 --> 00:53:00,960
humans don't actually perceive sound in

1661
00:53:00,960 --> 00:53:02,480
a time sequence like this either we

1662
00:53:02,480 --> 00:53:03,520
don't process

1663
00:53:03,520 --> 00:53:05,920
you know individual little samples here

1664
00:53:05,920 --> 00:53:06,559
over

1665
00:53:06,559 --> 00:53:08,800
over a series of time our ears have

1666
00:53:08,800 --> 00:53:10,000
these hairs that

1667
00:53:10,000 --> 00:53:12,559
resonate with various frequencies so how

1668
00:53:12,559 --> 00:53:14,240
we hear is actually closer to something

1669
00:53:14,240 --> 00:53:15,760
like a spectrogram

1670
00:53:15,760 --> 00:53:18,240
and how those and how those individual

1671
00:53:18,240 --> 00:53:20,640
hairs are vibrating has to do with

1672
00:53:20,640 --> 00:53:23,040
um the frequency that they're they're

1673
00:53:23,040 --> 00:53:25,359
basically tuned for essentially

1674
00:53:25,359 --> 00:53:28,079
but uh though that tuning happens to be

1675
00:53:28,079 --> 00:53:30,800
more linear in lower frequencies and

1676
00:53:30,800 --> 00:53:32,960
more logarithmic and higher frequencies

1677
00:53:32,960 --> 00:53:35,599
um so this replicates

1678
00:53:35,599 --> 00:53:38,319
how humans hear um obviously if you're

1679
00:53:38,319 --> 00:53:39,839
gonna do another animal this would look

1680
00:53:39,839 --> 00:53:41,040
a little different but we're

1681
00:53:41,040 --> 00:53:42,240
trying to go for humans here right we're

1682
00:53:42,240 --> 00:53:45,040
using human speech once we have this set

1683
00:53:45,040 --> 00:53:46,960
this array that remember comes from this

1684
00:53:46,960 --> 00:53:48,960
little window slice we then compute

1685
00:53:48,960 --> 00:53:52,079
the logarithm i think it's base 10 for

1686
00:53:52,079 --> 00:53:52,720
this

1687
00:53:52,720 --> 00:53:55,760
of each of these numbers and then so we

1688
00:53:55,760 --> 00:53:58,079
got this array and it's just

1689
00:53:58,079 --> 00:54:02,640
oops so we've got this array

1690
00:54:02,640 --> 00:54:05,119
and it's just you know the log logarithm

1691
00:54:05,119 --> 00:54:06,319
of each of these numbers

1692
00:54:06,319 --> 00:54:08,240
from there we compute the discrete

1693
00:54:08,240 --> 00:54:10,960
cosine transform um

1694
00:54:10,960 --> 00:54:12,960
and what that's doing is it's basically

1695
00:54:12,960 --> 00:54:15,280
like another fourier transform more or

1696
00:54:15,280 --> 00:54:15,680
less

1697
00:54:15,680 --> 00:54:18,400
but i i believe you're using real values

1698
00:54:18,400 --> 00:54:19,040
instead of

1699
00:54:19,040 --> 00:54:21,040
complex values if i remember how the dct

1700
00:54:21,040 --> 00:54:22,160
works um

1701
00:54:22,160 --> 00:54:24,559
and this helps us give an idea of what

1702
00:54:24,559 --> 00:54:25,440
the shape

1703
00:54:25,440 --> 00:54:29,040
of the original um fourier transform

1704
00:54:29,040 --> 00:54:29,920
looked like

1705
00:54:29,920 --> 00:54:33,760
or the fft rather um and by shape i mean

1706
00:54:33,760 --> 00:54:35,680
how many like what frequency of things

1707
00:54:35,680 --> 00:54:37,280
you're going going to see

1708
00:54:37,280 --> 00:54:39,920
um so it's kind of like taking the fft

1709
00:54:39,920 --> 00:54:41,200
of the fft

1710
00:54:41,200 --> 00:54:43,280
in a bizarre world like think about it

1711
00:54:43,280 --> 00:54:44,640
that way and that's kind of where that's

1712
00:54:44,640 --> 00:54:45,760
kind of where i gave up on

1713
00:54:45,760 --> 00:54:47,680
really trying to understand what's going

1714
00:54:47,680 --> 00:54:48,960
on with mfcc's

1715
00:54:48,960 --> 00:54:52,400
but my my basic understanding is that

1716
00:54:52,400 --> 00:54:55,040
you've got um the lower values kind of

1717
00:54:55,040 --> 00:54:56,799
give you an overall shape

1718
00:54:56,799 --> 00:54:58,480
of your fourier transform and then the

1719
00:54:58,480 --> 00:55:00,160
uh the higher values

1720
00:55:00,160 --> 00:55:03,119
give you um information about what some

1721
00:55:03,119 --> 00:55:05,839
of those peaks look

1722
00:55:05,839 --> 00:55:08,160
and then so we just move that window

1723
00:55:08,160 --> 00:55:10,720
over our entire audio sample

1724
00:55:10,720 --> 00:55:12,720
and we drop in each of these arrays the

1725
00:55:12,720 --> 00:55:14,240
mfcc's over this

1726
00:55:14,240 --> 00:55:15,599
over this whole sequence so we take the

1727
00:55:15,599 --> 00:55:17,119
first one that becomes this first set of

1728
00:55:17,119 --> 00:55:17,680
arrays

1729
00:55:17,680 --> 00:55:19,599
we slide the window over we compute the

1730
00:55:19,599 --> 00:55:21,680
mfcc's that becomes the second one and

1731
00:55:21,680 --> 00:55:23,440
so forth until the entire and we get to

1732
00:55:23,440 --> 00:55:24,319
the end

1733
00:55:24,319 --> 00:55:26,880
of the audio sample another way to think

1734
00:55:26,880 --> 00:55:28,400
about this is this is how we're doing

1735
00:55:28,400 --> 00:55:29,599
training

1736
00:55:29,599 --> 00:55:31,280
when we get to actually computing this

1737
00:55:31,280 --> 00:55:33,839
in real time these are being performed

1738
00:55:33,839 --> 00:55:34,480
basically

1739
00:55:34,480 --> 00:55:37,440
in real time so it as the audio streams

1740
00:55:37,440 --> 00:55:39,440
in it's taking these mfcc's and every

1741
00:55:39,440 --> 00:55:40,480
time it computes

1742
00:55:40,480 --> 00:55:42,640
a full section of mfcc's it then tries

1743
00:55:42,640 --> 00:55:43,920
to classify that

1744
00:55:43,920 --> 00:55:46,480
um and just sending that off to the

1745
00:55:46,480 --> 00:55:48,640
neural network for inference

1746
00:55:48,640 --> 00:55:50,640
so we've got the mfcc's it's just a

1747
00:55:50,640 --> 00:55:52,000
two-dimensional array

1748
00:55:52,000 --> 00:55:53,200
that's all it is so we get this

1749
00:55:53,200 --> 00:55:55,200
two-dimensional array and it looks like

1750
00:55:55,200 --> 00:55:55,520
an

1751
00:55:55,520 --> 00:55:57,520
image which means we can actually use

1752
00:55:57,520 --> 00:55:58,640
neural networks

1753
00:55:58,640 --> 00:56:01,520
that are better at image classification

1754
00:56:01,520 --> 00:56:02,240
um

1755
00:56:02,240 --> 00:56:04,160
or meant for image classification to

1756
00:56:04,160 --> 00:56:06,240
classify audio because these look like

1757
00:56:06,240 --> 00:56:06,799
images

1758
00:56:06,799 --> 00:56:08,720
and here's an example of stop here's an

1759
00:56:08,720 --> 00:56:09,920
example of zero

1760
00:56:09,920 --> 00:56:11,119
even though they happen at different

1761
00:56:11,119 --> 00:56:13,359
times you can kind of see that the bands

1762
00:56:13,359 --> 00:56:17,599
of the mfcc's look a little different

1763
00:56:17,599 --> 00:56:18,880
and that's what we're training this

1764
00:56:18,880 --> 00:56:21,119
neural network to do okay

1765
00:56:21,119 --> 00:56:22,720
so you got through all this you're like

1766
00:56:22,720 --> 00:56:25,599
what was he just talking about

1767
00:56:25,599 --> 00:56:28,799
oh my goodness um don't think about it

1768
00:56:28,799 --> 00:56:30,240
too hard like i said i i

1769
00:56:30,240 --> 00:56:32,000
might my brain started to hurt after

1770
00:56:32,000 --> 00:56:33,680
getting to that like dct step and going

1771
00:56:33,680 --> 00:56:34,640
okay i kind of understand what's going

1772
00:56:34,640 --> 00:56:36,079
on in the dct but i don't understand

1773
00:56:36,079 --> 00:56:37,680
why we're doing the dct of this like

1774
00:56:37,680 --> 00:56:39,200
logarithmic stuff there's a great

1775
00:56:39,200 --> 00:56:40,319
article on practical

1776
00:56:40,319 --> 00:56:41,760
cryptography if you want to go read more

1777
00:56:41,760 --> 00:56:43,760
about it just know that mfcc's for

1778
00:56:43,760 --> 00:56:45,520
features are very popular in things like

1779
00:56:45,520 --> 00:56:47,440
automatic speech recognition which is

1780
00:56:47,440 --> 00:56:50,160
what we're doing all right i hope that

1781
00:56:50,160 --> 00:56:53,520
helps let's go check on our uploads

1782
00:56:53,520 --> 00:56:55,839
they are still going but we are let's

1783
00:56:55,839 --> 00:56:59,680
see zero

1784
00:56:59,680 --> 00:57:02,720
so many noise zero

1785
00:57:02,720 --> 00:57:04,880
i think it still needs to do house so

1786
00:57:04,880 --> 00:57:07,920
this is still going

1787
00:57:09,680 --> 00:57:11,520
and we can stop here and see if anybody

1788
00:57:11,520 --> 00:57:12,799
has questions i'm gonna have to scroll

1789
00:57:12,799 --> 00:57:14,160
all the way down so i apologize if i've

1790
00:57:14,160 --> 00:57:14,880
missed stuff

1791
00:57:14,880 --> 00:57:16,240
so we're image classifying the

1792
00:57:16,240 --> 00:57:18,559
spectrograms or the numerical values of

1793
00:57:18,559 --> 00:57:19,599
the arrays um

1794
00:57:19,599 --> 00:57:21,839
very good question we're basically

1795
00:57:21,839 --> 00:57:23,520
classifying the spectrograms but instead

1796
00:57:23,520 --> 00:57:25,599
of spectrograms they're the mfcc's

1797
00:57:25,599 --> 00:57:28,559
um i originally played with i originally

1798
00:57:28,559 --> 00:57:30,240
played with this by classifying

1799
00:57:30,240 --> 00:57:31,839
spectrograms it works

1800
00:57:31,839 --> 00:57:34,240
it saves you from having to do that dct

1801
00:57:34,240 --> 00:57:36,400
that discrete cosine transform step

1802
00:57:36,400 --> 00:57:38,720
um which requires a lot of in fact that

1803
00:57:38,720 --> 00:57:40,319
requires more computational power than

1804
00:57:40,319 --> 00:57:42,079
the actual neural network

1805
00:57:42,079 --> 00:57:43,839
um which you will see in a minute which

1806
00:57:43,839 --> 00:57:45,440
is kind of crazy but

1807
00:57:45,440 --> 00:57:47,760
you can classify the spectrograms as

1808
00:57:47,760 --> 00:57:48,480
images

1809
00:57:48,480 --> 00:57:49,599
and those images are just

1810
00:57:49,599 --> 00:57:51,119
two-dimensional arrays they're grayscale

1811
00:57:51,119 --> 00:57:52,480
images is all they are i know i showed

1812
00:57:52,480 --> 00:57:53,359
you ones with color

1813
00:57:53,359 --> 00:57:56,720
they're grayscale images

1814
00:57:56,720 --> 00:57:59,200
uh is the input assumed to be exactly

1815
00:57:59,200 --> 00:58:00,640
one second long yes

1816
00:58:00,640 --> 00:58:05,440
the the mfcc's are going to create a

1817
00:58:07,119 --> 00:58:08,880
basically something that looks like this

1818
00:58:08,880 --> 00:58:10,319
and in order to get exactly i think it's

1819
00:58:10,319 --> 00:58:11,040
like 16

1820
00:58:11,040 --> 00:58:14,079
mfcc's at least in this example um i

1821
00:58:14,079 --> 00:58:15,119
don't remember what it's going to be an

1822
00:58:15,119 --> 00:58:16,880
edge impulse but in order to get that

1823
00:58:16,880 --> 00:58:17,520
exact

1824
00:58:17,520 --> 00:58:19,359
number it needs to be exactly a second

1825
00:58:19,359 --> 00:58:21,119
long so yes

1826
00:58:21,119 --> 00:58:22,799
how do we figure out when to start the

1827
00:58:22,799 --> 00:58:25,359
sample for classification

1828
00:58:25,359 --> 00:58:27,359
um if you're if we're talking about

1829
00:58:27,359 --> 00:58:29,440
deployment what it's doing is it's doing

1830
00:58:29,440 --> 00:58:29,839
this

1831
00:58:29,839 --> 00:58:33,599
um in real time so every time a new

1832
00:58:33,599 --> 00:58:35,520
chunk of audio so like let's say this

1833
00:58:35,520 --> 00:58:37,280
window of audio is

1834
00:58:37,280 --> 00:58:39,280
100 milliseconds i forget exactly what

1835
00:58:39,280 --> 00:58:40,559
that number is but let's say this

1836
00:58:40,559 --> 00:58:42,720
this window is 100 milliseconds every

1837
00:58:42,720 --> 00:58:44,559
time a buffer fills up with exactly 100

1838
00:58:44,559 --> 00:58:45,359
milliseconds

1839
00:58:45,359 --> 00:58:48,160
it takes that performs the mfcc's or

1840
00:58:48,160 --> 00:58:50,000
calculates the mfcc so you

1841
00:58:50,000 --> 00:58:52,720
get this array and then you you

1842
00:58:52,720 --> 00:58:54,400
fill up another buffer

1843
00:58:54,400 --> 00:58:56,960
that looks like this and it's you just

1844
00:58:56,960 --> 00:58:58,079
start cueing these

1845
00:58:58,079 --> 00:58:59,520
so it just like continues to cue these

1846
00:58:59,520 --> 00:59:01,359
and as you get past a second it starts

1847
00:59:01,359 --> 00:59:02,720
dropping the first ones off so you've

1848
00:59:02,720 --> 00:59:03,280
got this

1849
00:59:03,280 --> 00:59:06,400
moving buffer of mfcc's and then

1850
00:59:06,400 --> 00:59:09,680
every time you get uh let's say what do

1851
00:59:09,680 --> 00:59:12,880
we say 16. so every time you get to like

1852
00:59:12,880 --> 00:59:14,720
six or set like let every time you add

1853
00:59:14,720 --> 00:59:17,040
six or seven new mfcc's to the front of

1854
00:59:17,040 --> 00:59:17,760
this

1855
00:59:17,760 --> 00:59:20,640
that gets sent to the inference engine

1856
00:59:20,640 --> 00:59:21,200
um

1857
00:59:21,200 --> 00:59:23,520
that gets sent to the inference engine

1858
00:59:23,520 --> 00:59:24,960
which then performs the classification

1859
00:59:24,960 --> 00:59:26,559
so the moving buffer over lap

1860
00:59:26,559 --> 00:59:29,839
yes the moving buffer overlaps so um new

1861
00:59:29,839 --> 00:59:31,040
samples will come into this

1862
00:59:31,040 --> 00:59:33,280
every time you add six new here and drop

1863
00:59:33,280 --> 00:59:35,280
six even though it contained ones from

1864
00:59:35,280 --> 00:59:36,160
the previous

1865
00:59:36,160 --> 00:59:39,520
uh um sample that or the the previous

1866
00:59:39,520 --> 00:59:40,559
buffer that we tried to perform

1867
00:59:40,559 --> 00:59:41,760
inference with

1868
00:59:41,760 --> 00:59:44,240
uh we send that to the inference engine

1869
00:59:44,240 --> 00:59:44,799
um

1870
00:59:44,799 --> 00:59:48,400
so in the on the uh arduino that's like

1871
00:59:48,400 --> 00:59:51,119
every 333 milliseconds on the stm32 we

1872
00:59:51,119 --> 00:59:51,680
can actually do

1873
00:59:51,680 --> 00:59:54,880
that every 250 milliseconds uh yes it is

1874
00:59:54,880 --> 00:59:55,680
exactly a slide

1875
00:59:55,680 --> 00:59:58,240
it's it actually ends up becoming like

1876
00:59:58,240 --> 00:59:59,599
uh it's not a sliding window sliding

1877
00:59:59,599 --> 01:00:00,880
it's a sliding window it's

1878
01:00:00,880 --> 01:00:04,319
it's yeah um the sliding window

1879
01:00:04,319 --> 01:00:05,839
analogy or the sliding window works

1880
01:00:05,839 --> 01:00:07,119
better when you think about it taking

1881
01:00:07,119 --> 01:00:08,480
samples and training

1882
01:00:08,480 --> 01:00:11,359
um when you when we're doing inference

1883
01:00:11,359 --> 01:00:12,559
on the

1884
01:00:12,559 --> 01:00:14,000
microcontroller it's easier to think

1885
01:00:14,000 --> 01:00:15,680
about it as it's just

1886
01:00:15,680 --> 01:00:18,000
reading constantly reading audio in and

1887
01:00:18,000 --> 01:00:19,760
then updating a buffer kind of like a

1888
01:00:19,760 --> 01:00:21,359
queue and then every time that q gets to

1889
01:00:21,359 --> 01:00:23,040
a certain point or you've added x

1890
01:00:23,040 --> 01:00:26,079
new q l x new q chunks to it that

1891
01:00:26,079 --> 01:00:28,799
goes to the inference engine um but yeah

1892
01:00:28,799 --> 01:00:31,759
like a sliding window

1893
01:00:32,720 --> 01:00:36,400
and this thing is still going

1894
01:00:36,400 --> 01:00:40,799
all right uh yeah you're welcome

1895
01:00:40,799 --> 01:00:43,200
is the input assumed to be exactly one

1896
01:00:43,200 --> 01:00:45,119
second long yes we answered that uh

1897
01:00:45,119 --> 01:00:46,319
sorry i just answered that one

1898
01:00:46,319 --> 01:00:49,119
so we're image classifying yep i got

1899
01:00:49,119 --> 01:00:50,400
that one sorry i'm going backwards

1900
01:00:50,400 --> 01:00:51,680
through the questions here to see if i

1901
01:00:51,680 --> 01:00:52,960
can get to any because we're almost done

1902
01:00:52,960 --> 01:00:53,680
with this

1903
01:00:53,680 --> 01:00:54,960
coming from music background i would

1904
01:00:54,960 --> 01:00:57,599
highly recommend julia smith's work on

1905
01:00:57,599 --> 01:01:01,040
the dft uh awesome thank you for that

1906
01:01:01,040 --> 01:01:02,480
link

1907
01:01:02,480 --> 01:01:04,799
is the process is this process run on

1908
01:01:04,799 --> 01:01:06,319
each sample or on a collection of

1909
01:01:06,319 --> 01:01:06,960
samples where

1910
01:01:06,960 --> 01:01:09,680
a sample refers to a single audio file

1911
01:01:09,680 --> 01:01:10,960
thank you that is a good question

1912
01:01:10,960 --> 01:01:13,280
um because i often get confused when we

1913
01:01:13,280 --> 01:01:14,400
start talking about

1914
01:01:14,400 --> 01:01:16,640
sampling audio where you're taking an

1915
01:01:16,640 --> 01:01:19,440
individual value at like 16 kilohertz

1916
01:01:19,440 --> 01:01:22,000
or a sample for machine learning sense

1917
01:01:22,000 --> 01:01:23,520
in a sample when we start talking about

1918
01:01:23,520 --> 01:01:24,559
machine learning

1919
01:01:24,559 --> 01:01:27,599
is a one second audio clip um

1920
01:01:27,599 --> 01:01:29,680
and we're we're going to be sending

1921
01:01:29,680 --> 01:01:31,040
those samples

1922
01:01:31,040 --> 01:01:33,839
to uh for training i hope that helps and

1923
01:01:33,839 --> 01:01:36,640
answers that question

1924
01:01:37,760 --> 01:01:39,839
that's the one class i failed you must

1925
01:01:39,839 --> 01:01:41,119
be talking about signals and systems

1926
01:01:41,119 --> 01:01:41,839
yeah

1927
01:01:41,839 --> 01:01:43,599
that was i enjoyed it because i actually

1928
01:01:43,599 --> 01:01:45,040
enjoyed doing i like had this weird

1929
01:01:45,040 --> 01:01:46,240
thing where i enjoyed doing the

1930
01:01:46,240 --> 01:01:48,559
fourier transform by hand um it's like

1931
01:01:48,559 --> 01:01:50,000
oh i just performed these steps i was

1932
01:01:50,000 --> 01:01:51,680
way better at that stuff than like

1933
01:01:51,680 --> 01:01:53,200
the math class where you're like oh

1934
01:01:53,200 --> 01:01:54,960
figure out the permutations of people

1935
01:01:54,960 --> 01:01:56,319
sitting around a table like i was

1936
01:01:56,319 --> 01:01:58,000
terrible at that math class but i could

1937
01:01:58,000 --> 01:01:58,400
do

1938
01:01:58,400 --> 01:02:00,640
the fourier transform by hand i just i

1939
01:02:00,640 --> 01:02:01,920
always thought that was uh

1940
01:02:01,920 --> 01:02:04,240
really weird and i enjoyed signals and

1941
01:02:04,240 --> 01:02:06,000
systems it's just like over time i just

1942
01:02:06,000 --> 01:02:07,760
forget some of the nitty gritty details

1943
01:02:07,760 --> 01:02:09,920
of it

1944
01:02:09,920 --> 01:02:12,640
uh another recommendation for zach starr

1945
01:02:12,640 --> 01:02:13,200
and

1946
01:02:13,200 --> 01:02:16,160
uh 3b1b i guess that's is that the three

1947
01:02:16,160 --> 01:02:17,839
blue one brown or three brown one blue

1948
01:02:17,839 --> 01:02:18,319
uh

1949
01:02:18,319 --> 01:02:20,240
that that i always mix those two up

1950
01:02:20,240 --> 01:02:21,680
that's a great youtube

1951
01:02:21,680 --> 01:02:23,839
um they have really good stuff about

1952
01:02:23,839 --> 01:02:25,599
like 48 transforms

1953
01:02:25,599 --> 01:02:27,599
convolutional neural networks um their

1954
01:02:27,599 --> 01:02:29,920
stuff's really good definitely recommend

1955
01:02:29,920 --> 01:02:34,000
uh checking them out

1956
01:02:34,000 --> 01:02:35,039
i failed that when it became an

1957
01:02:35,039 --> 01:02:36,480
electrical and an industrial engineer

1958
01:02:36,480 --> 01:02:37,680
instead of electrical yeah

1959
01:02:37,680 --> 01:02:39,520
that is unfortunately singles and

1960
01:02:39,520 --> 01:02:41,119
systems ends up kind of being the weed

1961
01:02:41,119 --> 01:02:42,720
out class for a lot of people for me it

1962
01:02:42,720 --> 01:02:44,720
was junior year

1963
01:02:44,720 --> 01:02:46,559
uh somebody linked in the practical

1964
01:02:46,559 --> 01:02:48,880
cryptography for mfcc's

1965
01:02:48,880 --> 01:02:51,839
uh yes that is that is the one thank you

1966
01:02:51,839 --> 01:02:54,319
for posting that in the chat

1967
01:02:54,319 --> 01:02:56,640
um that article really helped me get an

1968
01:02:56,640 --> 01:02:58,240
understanding of what's going on

1969
01:02:58,240 --> 01:03:03,119
it's still um quite confusing um

1970
01:03:03,119 --> 01:03:04,799
and thankfully there's a number of tools

1971
01:03:04,799 --> 01:03:06,799
out there that that just kind of do them

1972
01:03:06,799 --> 01:03:08,400
for you

1973
01:03:08,400 --> 01:03:11,359
all right while this is still going

1974
01:03:11,359 --> 01:03:12,319
let's

1975
01:03:12,319 --> 01:03:14,240
start talking about i'm gonna jump aft

1976
01:03:14,240 --> 01:03:16,000
i'm gonna go check on this after we look

1977
01:03:16,000 --> 01:03:18,240
at

1978
01:03:19,520 --> 01:03:22,640
training a neural network so the fun

1979
01:03:22,640 --> 01:03:23,680
part is once we get to the

1980
01:03:23,680 --> 01:03:25,280
actual training step it goes a lot

1981
01:03:25,280 --> 01:03:27,440
faster than this

1982
01:03:27,440 --> 01:03:29,520
um the joke in the in the joke in the

1983
01:03:29,520 --> 01:03:31,039
machine learning world is that

1984
01:03:31,039 --> 01:03:33,280
you will spend eighty percent of your

1985
01:03:33,280 --> 01:03:34,079
time

1986
01:03:34,079 --> 01:03:36,720
um manipulating and massaging data and

1987
01:03:36,720 --> 01:03:38,319
twenty percent of your time

1988
01:03:38,319 --> 01:03:39,839
on actual machine learning brack

1989
01:03:39,839 --> 01:03:42,240
propagation yes uh more or less you're

1990
01:03:42,240 --> 01:03:43,599
doing back propagation

1991
01:03:43,599 --> 01:03:45,599
i don't remember the exact algorithm

1992
01:03:45,599 --> 01:03:47,119
we're gonna be doing for training

1993
01:03:47,119 --> 01:03:48,480
um but yeah it's essentially back

1994
01:03:48,480 --> 01:03:50,960
propagation um edge impulse it's like

1995
01:03:50,960 --> 01:03:52,480
click button magic things happen but

1996
01:03:52,480 --> 01:03:53,119
i'll show you where

1997
01:03:53,119 --> 01:03:55,200
you can manipulate uh keras code um if

1998
01:03:55,200 --> 01:03:56,799
you wanna create your own neural network

1999
01:03:56,799 --> 01:03:58,799
um but we won't be going into like you

2000
01:03:58,799 --> 01:04:00,480
know uh picking out your you're learning

2001
01:04:00,480 --> 01:04:01,839
uh you can pick out your learning rates

2002
01:04:01,839 --> 01:04:04,319
um but picking out like um

2003
01:04:04,319 --> 01:04:05,680
uh like measurement values and things

2004
01:04:05,680 --> 01:04:08,240
like that so

2005
01:04:08,240 --> 01:04:10,640
training a neural network so we're gonna

2006
01:04:10,640 --> 01:04:12,319
be using a convolutional neural network

2007
01:04:12,319 --> 01:04:12,640
in

2008
01:04:12,640 --> 01:04:13,839
edge impulse they recommend a

2009
01:04:13,839 --> 01:04:15,920
one-dimensional one um which essentially

2010
01:04:15,920 --> 01:04:17,599
just takes so we've got that image right

2011
01:04:17,599 --> 01:04:19,039
we're thinking about the spectrogram or

2012
01:04:19,039 --> 01:04:20,640
the collection of mfcc's as

2013
01:04:20,640 --> 01:04:22,400
an image and essentially what that's

2014
01:04:22,400 --> 01:04:23,920
going to do is it's going to take

2015
01:04:23,920 --> 01:04:27,119
um a filter and just slide it across and

2016
01:04:27,119 --> 01:04:28,240
you'll have to forgive me i don't

2017
01:04:28,240 --> 01:04:29,839
remember if it's time wise

2018
01:04:29,839 --> 01:04:32,960
or if it's um over the values um

2019
01:04:32,960 --> 01:04:34,319
i will have to look at that one later

2020
01:04:34,319 --> 01:04:35,839
but it's gonna slide this

2021
01:04:35,839 --> 01:04:36,720
one-dimensional

2022
01:04:36,720 --> 01:04:38,960
filter across it um that's the first

2023
01:04:38,960 --> 01:04:40,960
layer then we get to max pooling

2024
01:04:40,960 --> 01:04:42,880
all that does is just looks an

2025
01:04:42,880 --> 01:04:44,640
individual in this filter it says okay

2026
01:04:44,640 --> 01:04:46,240
what are my max values

2027
01:04:46,240 --> 01:04:48,160
um after this filter has happened and

2028
01:04:48,160 --> 01:04:50,960
then just gives us those

2029
01:04:50,960 --> 01:04:53,839
um i'm in nlp and interestingly enough

2030
01:04:53,839 --> 01:04:55,599
are using filters and other convolutions

2031
01:04:55,599 --> 01:04:57,359
to parse tokens and recognize grammar

2032
01:04:57,359 --> 01:04:58,559
oh interesting yeah i don't know much

2033
01:04:58,559 --> 01:05:00,559
about nlp um so that's fascinating i'm

2034
01:05:00,559 --> 01:05:00,960
not

2035
01:05:00,960 --> 01:05:03,359
surprised that it's very similar of this

2036
01:05:03,359 --> 01:05:04,000
idea of

2037
01:05:04,000 --> 01:05:06,480
like filtering and convolutions and um

2038
01:05:06,480 --> 01:05:08,640
like those things definitely overlap

2039
01:05:08,640 --> 01:05:10,319
um and a lot of this convolution stuff

2040
01:05:10,319 --> 01:05:11,839
came from um

2041
01:05:11,839 --> 01:05:15,039
vision processing of filtering images um

2042
01:05:15,039 --> 01:05:16,799
prior to machine learning and that and

2043
01:05:16,799 --> 01:05:17,280
that

2044
01:05:17,280 --> 01:05:19,440
and by by basically saying we're gonna

2045
01:05:19,440 --> 01:05:20,480
make these filters

2046
01:05:20,480 --> 01:05:23,119
work and have the machine just figure

2047
01:05:23,119 --> 01:05:25,119
out what filters it needs what values in

2048
01:05:25,119 --> 01:05:26,480
these filters so that's just the machine

2049
01:05:26,480 --> 01:05:27,039
learning

2050
01:05:27,039 --> 01:05:29,039
part of this um we're going to actually

2051
01:05:29,039 --> 01:05:30,720
do that filter and pick out the max

2052
01:05:30,720 --> 01:05:32,319
values twice so that kind of like takes

2053
01:05:32,319 --> 01:05:34,240
this image and squishes it down

2054
01:05:34,240 --> 01:05:35,920
to its raw values and the idea is we're

2055
01:05:35,920 --> 01:05:37,839
trying to get um our features

2056
01:05:37,839 --> 01:05:39,359
from that image right we've already

2057
01:05:39,359 --> 01:05:41,039
extracted the mfcc features and now we

2058
01:05:41,039 --> 01:05:42,319
want to have this convolutional neural

2059
01:05:42,319 --> 01:05:42,880
network

2060
01:05:42,880 --> 01:05:45,200
say what are the features in this image

2061
01:05:45,200 --> 01:05:46,880
that i care about

2062
01:05:46,880 --> 01:05:48,559
and so we're gonna take those we're

2063
01:05:48,559 --> 01:05:50,000
gonna like process

2064
01:05:50,000 --> 01:05:51,839
this down to like the individual like

2065
01:05:51,839 --> 01:05:53,119
pixels that it cares about and by

2066
01:05:53,119 --> 01:05:54,480
individual i mean you know there's still

2067
01:05:54,480 --> 01:05:55,920
gonna be a few dozen pixels that it's

2068
01:05:55,920 --> 01:05:57,039
gonna care about and

2069
01:05:57,039 --> 01:05:59,359
maybe a hundred um it's gonna flatten

2070
01:05:59,359 --> 01:06:01,119
that all to a one-dimensional array

2071
01:06:01,119 --> 01:06:02,400
and then it's gonna send each of these

2072
01:06:02,400 --> 01:06:04,160
to a node in what's called a dense

2073
01:06:04,160 --> 01:06:05,119
neural network

2074
01:06:05,119 --> 01:06:06,720
it's just one layer in fact it's just

2075
01:06:06,720 --> 01:06:08,960
four nodes that correspond

2076
01:06:08,960 --> 01:06:12,640
to each of our classes and the softmax

2077
01:06:12,640 --> 01:06:13,920
the output of each of those feeds into

2078
01:06:13,920 --> 01:06:16,160
the softmax function where softmax gives

2079
01:06:16,160 --> 01:06:16,720
us

2080
01:06:16,720 --> 01:06:18,400
basically a set of probabilities that it

2081
01:06:18,400 --> 01:06:19,920
thinks the neural network

2082
01:06:19,920 --> 01:06:22,799
heard one of the classes and these

2083
01:06:22,799 --> 01:06:24,799
probabilities after the soft max layer

2084
01:06:24,799 --> 01:06:28,400
should add up to one so

2085
01:06:28,400 --> 01:06:31,920
if you if it thinks and heard the word

2086
01:06:31,920 --> 01:06:32,799
up

2087
01:06:32,799 --> 01:06:34,400
it comes through this neural network and

2088
01:06:34,400 --> 01:06:36,319
it spits out up like point nine

2089
01:06:36,319 --> 01:06:37,760
and then the rest of these like less

2090
01:06:37,760 --> 01:06:39,359
than point nine but they should all add

2091
01:06:39,359 --> 01:06:40,240
up to

2092
01:06:40,240 --> 01:06:42,400
uh one and then all we need to do in our

2093
01:06:42,400 --> 01:06:43,520
code is say

2094
01:06:43,520 --> 01:06:46,160
which of these outputs is the greatest

2095
01:06:46,160 --> 01:06:48,559
in order to determine

2096
01:06:48,559 --> 01:06:50,960
what it thinks the neural network picked

2097
01:06:50,960 --> 01:06:51,839
as the class

2098
01:06:51,839 --> 01:06:54,319
so that's what's going on here um and

2099
01:06:54,319 --> 01:06:55,839
yes we are going to be using essentially

2100
01:06:55,839 --> 01:06:57,359
backprop um and we're going to be

2101
01:06:57,359 --> 01:06:59,520
using a tool that you just click it and

2102
01:06:59,520 --> 01:07:00,720
i'll show you where you can modify some

2103
01:07:00,720 --> 01:07:02,079
of the hyper parameters if you wish if

2104
01:07:02,079 --> 01:07:03,680
you're into machine learning

2105
01:07:03,680 --> 01:07:05,280
and give you some recommendations as to

2106
01:07:05,280 --> 01:07:08,960
where you go to learn more about that

2107
01:07:09,440 --> 01:07:12,640
um haha look at this what

2108
01:07:12,640 --> 01:07:15,039
what is he talking about if this is all

2109
01:07:15,039 --> 01:07:16,400
new to you

2110
01:07:16,400 --> 01:07:19,920
um i highly highly recommend andrew

2111
01:07:19,920 --> 01:07:20,880
eng's class

2112
01:07:20,880 --> 01:07:24,640
on corsair i took that about a year ago

2113
01:07:24,640 --> 01:07:26,559
and it was by far the best introduction

2114
01:07:26,559 --> 01:07:28,000
to machine learning it takes

2115
01:07:28,000 --> 01:07:29,359
i think a couple of months to get

2116
01:07:29,359 --> 01:07:30,319
through where you're doing about five

2117
01:07:30,319 --> 01:07:31,039
hours of work

2118
01:07:31,039 --> 01:07:34,720
each week um and you start with like

2119
01:07:34,720 --> 01:07:36,799
matrix algebra and by the end of it you

2120
01:07:36,799 --> 01:07:38,160
have an understanding of what machine

2121
01:07:38,160 --> 01:07:38,960
learning is

2122
01:07:38,960 --> 01:07:40,880
and you basically design your own very

2123
01:07:40,880 --> 01:07:42,000
simple neural network

2124
01:07:42,000 --> 01:07:46,160
um in uh matlab is what you're doing um

2125
01:07:46,160 --> 01:07:47,760
and that helped tremendously and then

2126
01:07:47,760 --> 01:07:49,599
from there it's like a bunch of books

2127
01:07:49,599 --> 01:07:50,880
and things you can just like how do i

2128
01:07:50,880 --> 01:07:52,480
learn karaos how do i make bigger neural

2129
01:07:52,480 --> 01:07:53,200
networks

2130
01:07:53,200 --> 01:07:55,119
what's what's new in industry with this

2131
01:07:55,119 --> 01:07:56,480
and um right

2132
01:07:56,480 --> 01:07:57,680
we're playing with things right here

2133
01:07:57,680 --> 01:07:59,839
that are like what like a dozen or

2134
01:07:59,839 --> 01:08:01,760
less layers and you get to industry and

2135
01:08:01,760 --> 01:08:02,880
you start looking like oh how are they

2136
01:08:02,880 --> 01:08:04,240
doing object detection

2137
01:08:04,240 --> 01:08:05,760
for vision and you're like oh my god

2138
01:08:05,760 --> 01:08:07,920
that's like 300 layers

2139
01:08:07,920 --> 01:08:09,119
how do people come up with this and

2140
01:08:09,119 --> 01:08:10,319
you're like oh this is how people get

2141
01:08:10,319 --> 01:08:11,520
phds

2142
01:08:11,520 --> 01:08:14,319
so or this is how microsoft makes money

2143
01:08:14,319 --> 01:08:17,279
by developing these uh neural networks

2144
01:08:17,279 --> 01:08:19,279
all right this is still going cool i

2145
01:08:19,279 --> 01:08:22,560
want to keep checking on this but

2146
01:08:22,719 --> 01:08:24,719
um once we get there we're going to

2147
01:08:24,719 --> 01:08:26,000
evaluate on

2148
01:08:26,000 --> 01:08:29,520
the test set and i want to wait to get

2149
01:08:29,520 --> 01:08:30,640
there to do that

2150
01:08:30,640 --> 01:08:33,198
um but in the meantime if everybody

2151
01:08:33,198 --> 01:08:34,880
wants to go ahead

2152
01:08:34,880 --> 01:08:38,080
and start putting this together make

2153
01:08:38,080 --> 01:08:39,359
sure you've got your

2154
01:08:39,359 --> 01:08:43,040
headers soldered on your microphone

2155
01:08:43,040 --> 01:08:47,040
um connect it to your uh nucleo board

2156
01:08:47,040 --> 01:08:50,238
we've got the left right clock so that's

2157
01:08:50,238 --> 01:08:50,560
just

2158
01:08:50,560 --> 01:08:52,000
that's just a clock signal that toggles

2159
01:08:52,000 --> 01:08:53,279
back and forth that's how you get two

2160
01:08:53,279 --> 01:08:54,238
channels out of these

2161
01:08:54,238 --> 01:08:57,439
um that goes to a2 you've got your data

2162
01:08:57,439 --> 01:08:59,359
out that goes to d4

2163
01:08:59,359 --> 01:09:01,279
your bit clock that's the really fast

2164
01:09:01,279 --> 01:09:02,960
clock that goes to d3

2165
01:09:02,960 --> 01:09:04,640
um and you've got power ground make sure

2166
01:09:04,640 --> 01:09:06,479
it's three volts not five volts

2167
01:09:06,479 --> 01:09:08,880
um select line that determines if it's

2168
01:09:08,880 --> 01:09:10,238
left if that determines if this

2169
01:09:10,238 --> 01:09:10,960
microphone is

2170
01:09:10,960 --> 01:09:14,238
left or right channel um i think it

2171
01:09:14,238 --> 01:09:16,880
defaults left this board has this line

2172
01:09:16,880 --> 01:09:19,120
pulled down to ground so you don't need

2173
01:09:19,120 --> 01:09:20,000
to

2174
01:09:20,000 --> 01:09:23,120
put anything on this line

2175
01:09:23,120 --> 01:09:24,880
um and i think it defaults to the left

2176
01:09:24,880 --> 01:09:26,158
and um

2177
01:09:26,158 --> 01:09:28,560
my code just handles that like the demo

2178
01:09:28,560 --> 01:09:29,679
code that we're gonna use

2179
01:09:29,679 --> 01:09:33,439
um just handles that for us

2180
01:09:33,439 --> 01:09:36,158
are we done ah we're done good timing

2181
01:09:36,158 --> 01:09:37,520
okay this took a little longer than when

2182
01:09:37,520 --> 01:09:38,479
i tried this yesterday i think it's

2183
01:09:38,479 --> 01:09:39,520
because everybody's trying to upload

2184
01:09:39,520 --> 01:09:42,080
data to uh edge impulse right now

2185
01:09:42,080 --> 01:09:46,880
um where is

2186
01:09:46,960 --> 01:09:48,960
well i had a chat i had a chat bar up so

2187
01:09:48,960 --> 01:09:50,000
i'll be able to watch

2188
01:09:50,000 --> 01:09:53,120
some of that so we should have data all

2189
01:09:53,120 --> 01:09:55,280
in edge impulse right now hopefully

2190
01:09:55,280 --> 01:09:56,880
everybody's about up to here

2191
01:09:56,880 --> 01:10:00,080
um check it make sure you've got uh

2192
01:10:00,080 --> 01:10:03,199
am i in test data yeah here we go so so

2193
01:10:03,199 --> 01:10:04,400
your training data you should have about

2194
01:10:04,400 --> 01:10:06,239
20 minutes of samples in each of your

2195
01:10:06,239 --> 01:10:07,040
categories

2196
01:10:07,040 --> 01:10:09,920
zero house noise unknown and if you go

2197
01:10:09,920 --> 01:10:11,120
to test data you should have about you

2198
01:10:11,120 --> 01:10:11,760
know 20

2199
01:10:11,760 --> 01:10:13,280
of your total data so that's about five

2200
01:10:13,280 --> 01:10:14,800
minutes of each that's like

2201
01:10:14,800 --> 01:10:18,239
25 minutes of uh of each one

2202
01:10:18,239 --> 01:10:22,239
of each class let's go to

2203
01:10:22,239 --> 01:10:25,920
our impulse design this is the pipeline

2204
01:10:25,920 --> 01:10:26,800
this is your ml

2205
01:10:26,800 --> 01:10:28,719
ops basically um from a graphical

2206
01:10:28,719 --> 01:10:30,080
perspective um this

2207
01:10:30,080 --> 01:10:31,920
is where you can adjust your window size

2208
01:10:31,920 --> 01:10:33,199
you know how much they hop

2209
01:10:33,199 --> 01:10:34,719
um we're gonna keep everything at a

2210
01:10:34,719 --> 01:10:36,640
second there's no really windowing going

2211
01:10:36,640 --> 01:10:37,920
on here because it's just

2212
01:10:37,920 --> 01:10:40,159
one one second chunk of data click to

2213
01:10:40,159 --> 01:10:41,600
add a processing block

2214
01:10:41,600 --> 01:10:43,360
um edge impulse recommends that we use

2215
01:10:43,360 --> 01:10:45,440
mfcc's which we just talked about

2216
01:10:45,440 --> 01:10:47,280
let's add that this is just feature

2217
01:10:47,280 --> 01:10:48,640
extraction um

2218
01:10:48,640 --> 01:10:50,640
this this block converts those audio

2219
01:10:50,640 --> 01:10:52,640
files to the mfcc's add the learning

2220
01:10:52,640 --> 01:10:53,440
block

2221
01:10:53,440 --> 01:10:56,239
they recommend keras great or basic

2222
01:10:56,239 --> 01:10:57,520
neural network that's been developed in

2223
01:10:57,520 --> 01:10:58,400
keras

2224
01:10:58,400 --> 01:11:01,600
great and what i can't see because i've

2225
01:11:01,600 --> 01:11:02,640
got that window over there

2226
01:11:02,640 --> 01:11:04,880
is save impulse so make sure you click

2227
01:11:04,880 --> 01:11:07,520
that that is hugely important

2228
01:11:07,520 --> 01:11:09,600
and then you should see uh these blocks

2229
01:11:09,600 --> 01:11:11,440
appear on your left side so underneath

2230
01:11:11,440 --> 01:11:15,120
in impulse design you should see mfcc's

2231
01:11:15,120 --> 01:11:18,480
um feel free to play these um you can

2232
01:11:18,480 --> 01:11:20,080
actually go through and view

2233
01:11:20,080 --> 01:11:23,520
your different samples and you can play

2234
01:11:23,520 --> 01:11:24,400
those

2235
01:11:24,400 --> 01:11:26,880
uh and you can actually see what your uh

2236
01:11:26,880 --> 01:11:28,480
coefficients look like what these images

2237
01:11:28,480 --> 01:11:29,520
are gonna look like that are gonna be

2238
01:11:29,520 --> 01:11:30,080
features

2239
01:11:30,080 --> 01:11:31,760
what we need to do is actually convert

2240
01:11:31,760 --> 01:11:33,199
all of them to features so click on

2241
01:11:33,199 --> 01:11:34,880
generate features

2242
01:11:34,880 --> 01:11:36,719
and then click generate features and

2243
01:11:36,719 --> 01:11:38,000
once again we wait for

2244
01:11:38,000 --> 01:11:39,920
a couple of minutes welcome to the world

2245
01:11:39,920 --> 01:11:41,360
of machine learning um

2246
01:11:41,360 --> 01:11:44,640
you know the joke the xkcd joke about uh

2247
01:11:44,640 --> 01:11:46,159
the you know the programmers fighting on

2248
01:11:46,159 --> 01:11:47,679
the chairs it's like get back to work oh

2249
01:11:47,679 --> 01:11:49,120
we're compiling that kind of thing in

2250
01:11:49,120 --> 01:11:49,840
the machine learning

2251
01:11:49,840 --> 01:11:51,440
world it's oh i'm training or i'm you

2252
01:11:51,440 --> 01:11:53,360
know extracting features like you sit

2253
01:11:53,360 --> 01:11:54,640
around and you wait for this stuff to

2254
01:11:54,640 --> 01:11:55,199
happen

2255
01:11:55,199 --> 01:11:56,719
and what i've noticed a lot of times

2256
01:11:56,719 --> 01:11:58,080
with machine learning um with the

2257
01:11:58,080 --> 01:11:59,760
exception of diving really deep

2258
01:11:59,760 --> 01:12:01,360
into the math of what's going on into

2259
01:12:01,360 --> 01:12:03,760
each one it's often considered very

2260
01:12:03,760 --> 01:12:04,719
black boxy

2261
01:12:04,719 --> 01:12:06,960
um if you've ever done any like rf work

2262
01:12:06,960 --> 01:12:08,400
um where you have these tools and you're

2263
01:12:08,400 --> 01:12:10,159
like oh i wanna you know design a dipole

2264
01:12:10,159 --> 01:12:11,520
or whatever it is you're like i'm gonna

2265
01:12:11,520 --> 01:12:12,719
tweak it in this kind of way and you

2266
01:12:12,719 --> 01:12:14,000
just run the simulation

2267
01:12:14,000 --> 01:12:15,280
you come back in three hours and you're

2268
01:12:15,280 --> 01:12:16,480
like oh well that didn't work and you're

2269
01:12:16,480 --> 01:12:18,159
like bend it a little bit in the in the

2270
01:12:18,159 --> 01:12:18,960
simulator

2271
01:12:18,960 --> 01:12:20,400
run it again and come back so that's

2272
01:12:20,400 --> 01:12:22,159
kind of what happens in the machine

2273
01:12:22,159 --> 01:12:22,880
learning world

2274
01:12:22,880 --> 01:12:24,480
um you start with an idea maybe you look

2275
01:12:24,480 --> 01:12:26,000
at a research paper you're like oh this

2276
01:12:26,000 --> 01:12:27,679
model performed well for this task i'm

2277
01:12:27,679 --> 01:12:28,880
gonna start with that model

2278
01:12:28,880 --> 01:12:30,400
and then you start tweaking some of the

2279
01:12:30,400 --> 01:12:31,920
um maybe you like

2280
01:12:31,920 --> 01:12:35,199
add an extra layer or you uh you insert

2281
01:12:35,199 --> 01:12:36,320
some nodes you're like you know what you

2282
01:12:36,320 --> 01:12:38,239
know let's let's try a one-dimensional

2283
01:12:38,239 --> 01:12:40,560
uh cnn instead of a two-dimensional cnn

2284
01:12:40,560 --> 01:12:42,000
and see how that performs and you just

2285
01:12:42,000 --> 01:12:43,679
kind of like test it and go and iterate

2286
01:12:43,679 --> 01:12:44,640
and iterate and iterate

2287
01:12:44,640 --> 01:12:46,800
you get to something that works best for

2288
01:12:46,800 --> 01:12:47,920
your needs um

2289
01:12:47,920 --> 01:12:49,120
because a lot of times what you'll find

2290
01:12:49,120 --> 01:12:51,040
in machine learning is that it's not

2291
01:12:51,040 --> 01:12:51,520
about

2292
01:12:51,520 --> 01:12:53,199
it works a hundred percent of the time

2293
01:12:53,199 --> 01:12:55,520
um it's it's one of those you know 60

2294
01:12:55,520 --> 01:12:57,440
of the time it works 100 of the time

2295
01:12:57,440 --> 01:12:58,960
right um

2296
01:12:58,960 --> 01:13:01,360
you'll find that it misses data or or it

2297
01:13:01,360 --> 01:13:02,560
triggers on the wrong thing so if

2298
01:13:02,560 --> 01:13:03,520
anybody was

2299
01:13:03,520 --> 01:13:06,080
um there last night for the bring a hack

2300
01:13:06,080 --> 01:13:07,760
um my trick or treat thing

2301
01:13:07,760 --> 01:13:10,719
definitely picks up chicken feet um

2302
01:13:10,719 --> 01:13:12,800
that's that's mr jp over at adafruit

2303
01:13:12,800 --> 01:13:14,159
gave me that that one it's like chicken

2304
01:13:14,159 --> 01:13:14,960
feet oh it picks

2305
01:13:14,960 --> 01:13:16,640
up that's a false positive so what that

2306
01:13:16,640 --> 01:13:18,080
means is like i need to go collect a

2307
01:13:18,080 --> 01:13:19,199
bunch of data

2308
01:13:19,199 --> 01:13:20,800
if somebody's going to be commonly

2309
01:13:20,800 --> 01:13:23,199
saying chicken feet around me

2310
01:13:23,199 --> 01:13:24,880
then or around the device then i need to

2311
01:13:24,880 --> 01:13:26,800
make sure it's trained to not respond to

2312
01:13:26,800 --> 01:13:27,440
that so one

2313
01:13:27,440 --> 01:13:29,120
one thing you might need to do is then

2314
01:13:29,120 --> 01:13:30,480
collect a bunch of data that says

2315
01:13:30,480 --> 01:13:31,920
people saying chicken feet and either

2316
01:13:31,920 --> 01:13:34,320
that as a separate category

2317
01:13:34,320 --> 01:13:36,560
or it's part of the unknowns now and a

2318
01:13:36,560 --> 01:13:38,400
lot of the unknowns so that it's close

2319
01:13:38,400 --> 01:13:39,760
enough but it knows that

2320
01:13:39,760 --> 01:13:41,440
that is not the correct word and it

2321
01:13:41,440 --> 01:13:42,880
starts to pick up features

2322
01:13:42,880 --> 01:13:45,280
in that um utterance that it knows is

2323
01:13:45,280 --> 01:13:46,400
not uh

2324
01:13:46,400 --> 01:13:49,360
trick or treat feel free to look at the

2325
01:13:49,360 --> 01:13:50,719
feature explorer

2326
01:13:50,719 --> 01:13:52,719
um i'm honestly not sure what's being

2327
01:13:52,719 --> 01:13:53,840
combined here because

2328
01:13:53,840 --> 01:13:56,880
each sample should be

2329
01:13:56,880 --> 01:14:00,320
a full image um

2330
01:14:00,320 --> 01:14:01,760
trying to see where that is and i can

2331
01:14:01,760 --> 01:14:05,280
get you the exact number of

2332
01:14:05,360 --> 01:14:07,679
uh i can't i don't i don't have a number

2333
01:14:07,679 --> 01:14:08,960
number of coefficients so there should

2334
01:14:08,960 --> 01:14:10,719
be 32

2335
01:14:10,719 --> 01:14:14,000
in each time slice

2336
01:14:14,000 --> 01:14:18,000
number of filters in the filter bank

2337
01:14:18,560 --> 01:14:19,840
yeah i'm not quite seeing it so it's

2338
01:14:19,840 --> 01:14:22,560
like 13 by like 40 something i think

2339
01:14:22,560 --> 01:14:25,199
um so actually when we consider

2340
01:14:25,199 --> 01:14:26,640
dimensions

2341
01:14:26,640 --> 01:14:29,840
going into the neural network this is

2342
01:14:29,840 --> 01:14:31,040
actually like a

2343
01:14:31,040 --> 01:14:34,480
thousand dimension um

2344
01:14:34,480 --> 01:14:37,520
input which which makes it a little

2345
01:14:37,520 --> 01:14:38,880
conceptually hard

2346
01:14:38,880 --> 01:14:41,520
um another easy like another way to

2347
01:14:41,520 --> 01:14:42,880
visualize this or another way to think

2348
01:14:42,880 --> 01:14:43,920
about this is when you start looking at

2349
01:14:43,920 --> 01:14:45,440
things like this

2350
01:14:45,440 --> 01:14:47,199
when you see your dots pointed out to

2351
01:14:47,199 --> 01:14:48,800
like oh machine learning is all about

2352
01:14:48,800 --> 01:14:50,400
finding the boundary and grouping these

2353
01:14:50,400 --> 01:14:52,320
together like oh is this one class is

2354
01:14:52,320 --> 01:14:53,840
the orange one class can we define a

2355
01:14:53,840 --> 01:14:55,679
boundary a mathematical boundary

2356
01:14:55,679 --> 01:14:58,239
that separates these classes for us um

2357
01:14:58,239 --> 01:15:00,239
that's what's going on it's just that

2358
01:15:00,239 --> 01:15:02,400
humans we stop being able to really

2359
01:15:02,400 --> 01:15:03,920
comprehend stuff after about three

2360
01:15:03,920 --> 01:15:04,960
dimensions

2361
01:15:04,960 --> 01:15:06,480
um it becomes difficult and we start

2362
01:15:06,480 --> 01:15:08,640
talking like a thousand dimensions like

2363
01:15:08,640 --> 01:15:09,840
it's really tough for humans to

2364
01:15:09,840 --> 01:15:11,760
visualize that um

2365
01:15:11,760 --> 01:15:12,640
so things like if you think

2366
01:15:12,640 --> 01:15:14,320
accelerometer data right i'm gonna

2367
01:15:14,320 --> 01:15:15,920
capture accelerometer data

2368
01:15:15,920 --> 01:15:19,440
and like xyz and maybe uh those get

2369
01:15:19,440 --> 01:15:20,640
clustered together

2370
01:15:20,640 --> 01:15:22,239
and we can create a machine learning

2371
01:15:22,239 --> 01:15:24,320
algorithm that you know identifies

2372
01:15:24,320 --> 01:15:26,480
different types of positions or

2373
01:15:26,480 --> 01:15:27,760
different types of

2374
01:15:27,760 --> 01:15:29,679
um vibration and it's a little easier to

2375
01:15:29,679 --> 01:15:31,120
deal with something like that but since

2376
01:15:31,120 --> 01:15:32,560
we're dealing with audio we've got

2377
01:15:32,560 --> 01:15:35,440
many more dimensions going into our

2378
01:15:35,440 --> 01:15:37,120
neural network here

2379
01:15:37,120 --> 01:15:38,640
so we're done with generating features

2380
01:15:38,640 --> 01:15:40,719
let's go to neural network classifier

2381
01:15:40,719 --> 01:15:43,040
um you know all this talk we spent like

2382
01:15:43,040 --> 01:15:44,560
what like an hour almost an hour and a

2383
01:15:44,560 --> 01:15:46,159
half talking about extracting features

2384
01:15:46,159 --> 01:15:46,719
and

2385
01:15:46,719 --> 01:15:47,840
training the neural network's gonna be

2386
01:15:47,840 --> 01:15:49,760
like the easiest thing in this entire

2387
01:15:49,760 --> 01:15:50,480
demo

2388
01:15:50,480 --> 01:15:51,840
that's the funny part of this whole

2389
01:15:51,840 --> 01:15:52,880
thing but i want to get to the

2390
01:15:52,880 --> 01:15:54,159
deployment side of

2391
01:15:54,159 --> 01:15:57,280
running it on our microcontroller

2392
01:15:57,280 --> 01:15:58,880
keep all of the defaults i'm going to

2393
01:15:58,880 --> 01:16:00,239
tell you that right now and click start

2394
01:16:00,239 --> 01:16:01,920
training so while it's going i can kind

2395
01:16:01,920 --> 01:16:02,800
of show you

2396
01:16:02,800 --> 01:16:04,320
what's going on here number of training

2397
01:16:04,320 --> 01:16:06,480
cycles um somebody mentioned

2398
01:16:06,480 --> 01:16:09,440
the back propagation and you'll have to

2399
01:16:09,440 --> 01:16:10,560
forgive me because i

2400
01:16:10,560 --> 01:16:14,080
lost my chat window i was able to keep

2401
01:16:14,080 --> 01:16:14,640
up with

2402
01:16:14,640 --> 01:16:17,679
chat aha here it is uh

2403
01:16:17,679 --> 01:16:20,159
okay go to impulse design after upload

2404
01:16:20,159 --> 01:16:21,040
go to oh

2405
01:16:21,040 --> 01:16:23,760
okay somebody's asked

2406
01:16:24,640 --> 01:16:27,360
can we go over the impulse steps again

2407
01:16:27,360 --> 01:16:28,400
mine just finished

2408
01:16:28,400 --> 01:16:30,000
yeah let me let me briefly do that while

2409
01:16:30,000 --> 01:16:32,159
this is training so we go to impulse

2410
01:16:32,159 --> 01:16:33,360
design

2411
01:16:33,360 --> 01:16:35,199
you want to add the blocks here you want

2412
01:16:35,199 --> 01:16:36,719
to add it's going to recommend them for

2413
01:16:36,719 --> 01:16:38,159
you because it knows it's audio data

2414
01:16:38,159 --> 01:16:41,520
so add the audio mfcc one add the keras

2415
01:16:41,520 --> 01:16:43,360
block the neural network

2416
01:16:43,360 --> 01:16:45,360
that's been done in keras and then you

2417
01:16:45,360 --> 01:16:46,880
want to click

2418
01:16:46,880 --> 01:16:49,840
save impulse over here

2419
01:16:49,920 --> 01:16:52,159
that will give us uh new blocks on the

2420
01:16:52,159 --> 01:16:54,880
left side click on mfcc's

2421
01:16:54,880 --> 01:16:58,080
or mfcc click generate features click

2422
01:16:58,080 --> 01:16:59,360
generate features and wait for those

2423
01:16:59,360 --> 01:17:01,040
features to be done generating so now we

2424
01:17:01,040 --> 01:17:01,520
have

2425
01:17:01,520 --> 01:17:05,280
a big array of mfcc's on the server

2426
01:17:05,280 --> 01:17:06,640
that's what's going to be used to train

2427
01:17:06,640 --> 01:17:08,400
the neural network not the actual audio

2428
01:17:08,400 --> 01:17:10,719
data

2429
01:17:10,880 --> 01:17:13,440
and then go to your neural network

2430
01:17:13,440 --> 01:17:14,239
classifier

2431
01:17:14,239 --> 01:17:16,239
and click the train button uh or start

2432
01:17:16,239 --> 01:17:18,400
training that's where we are

2433
01:17:18,400 --> 01:17:21,120
all right uh that was a good question um

2434
01:17:21,120 --> 01:17:21,760
since as

2435
01:17:21,760 --> 01:17:23,120
people are finishing up there but that

2436
01:17:23,120 --> 01:17:24,960
way um mine can stay a little head here

2437
01:17:24,960 --> 01:17:26,400
as i'm as i'm blabbing

2438
01:17:26,400 --> 01:17:28,719
so number of training cycles so each

2439
01:17:28,719 --> 01:17:30,000
epic is what we're calling

2440
01:17:30,000 --> 01:17:32,560
it here um takes some of the training

2441
01:17:32,560 --> 01:17:33,040
data

2442
01:17:33,040 --> 01:17:36,480
um remember this collection of mfcc's it

2443
01:17:36,480 --> 01:17:38,159
sends it through the neural network so

2444
01:17:38,159 --> 01:17:39,679
that would be your forward pass

2445
01:17:39,679 --> 01:17:41,280
it comes out with basically your

2446
01:17:41,280 --> 01:17:43,040
probabilities of

2447
01:17:43,040 --> 01:17:45,840
um which class it thinks it is and it's

2448
01:17:45,840 --> 01:17:47,280
going to be all over the place when it

2449
01:17:47,280 --> 01:17:48,560
first starts because all these all these

2450
01:17:48,560 --> 01:17:50,000
parameters these numbers inside this

2451
01:17:50,000 --> 01:17:51,840
model are randomized

2452
01:17:51,840 --> 01:17:54,480
and then it's going to say hey how close

2453
01:17:54,480 --> 01:17:57,199
were these probabilities to the actual

2454
01:17:57,199 --> 01:18:00,400
label if we sent it up or or

2455
01:18:00,400 --> 01:18:03,920
uh house or zero is that what was

2456
01:18:03,920 --> 01:18:04,880
predicted

2457
01:18:04,880 --> 01:18:07,440
and there's a loss um that's and there's

2458
01:18:07,440 --> 01:18:09,440
a loss function that happens that says

2459
01:18:09,440 --> 01:18:12,480
um how it kind of measures the distance

2460
01:18:12,480 --> 01:18:14,239
mathematically between how close it

2461
01:18:14,239 --> 01:18:16,880
thinks it was to the original label

2462
01:18:16,880 --> 01:18:18,880
and then the whole idea of this back

2463
01:18:18,880 --> 01:18:20,640
propagation and this training is it

2464
01:18:20,640 --> 01:18:21,920
tries to minimize that

2465
01:18:21,920 --> 01:18:24,400
loss so it updates it goes backwards

2466
01:18:24,400 --> 01:18:25,120
through

2467
01:18:25,120 --> 01:18:27,520
the neural network and it updates these

2468
01:18:27,520 --> 01:18:28,800
parameters based on this back

2469
01:18:28,800 --> 01:18:30,320
propagation algorithm

2470
01:18:30,320 --> 01:18:33,360
to try to make that loss smaller or more

2471
01:18:33,360 --> 01:18:34,640
or less

2472
01:18:34,640 --> 01:18:37,679
the output predictions closer to the

2473
01:18:37,679 --> 01:18:38,840
original label

2474
01:18:38,840 --> 01:18:41,440
um if it thinks it's zero then it should

2475
01:18:41,440 --> 01:18:43,280
be it should be like

2476
01:18:43,280 --> 01:18:45,760
one point zero percent like probability

2477
01:18:45,760 --> 01:18:46,880
of being zero

2478
01:18:46,880 --> 01:18:48,719
and zero for all the rest and if it's

2479
01:18:48,719 --> 01:18:50,719
not that it goes back through

2480
01:18:50,719 --> 01:18:53,120
and updates these um update these

2481
01:18:53,120 --> 01:18:54,640
parameters these numbers inside this

2482
01:18:54,640 --> 01:18:55,679
neural network it's an

2483
01:18:55,679 --> 01:18:57,920
iterative process um for a neural

2484
01:18:57,920 --> 01:18:58,719
network like

2485
01:18:58,719 --> 01:19:01,760
like this this can this is this can take

2486
01:19:01,760 --> 01:19:02,640
a little bit of uh

2487
01:19:02,640 --> 01:19:04,960
time um for some larger networks this

2488
01:19:04,960 --> 01:19:05,760
can take

2489
01:19:05,760 --> 01:19:09,760
hours or days

2490
01:19:09,760 --> 01:19:12,880
uh the github says we need to add data

2491
01:19:12,880 --> 01:19:13,920
acquisition

2492
01:19:13,920 --> 01:19:17,360
upload data in ei

2493
01:19:17,360 --> 01:19:19,600
so if there's there's two there's two

2494
01:19:19,600 --> 01:19:21,040
tracks in that if you're looking at the

2495
01:19:21,040 --> 01:19:22,000
github

2496
01:19:22,000 --> 01:19:25,440
uh write-up there's two tracks one track

2497
01:19:25,440 --> 01:19:26,960
is you're doing everything locally

2498
01:19:26,960 --> 01:19:28,640
where you're doing curation locally and

2499
01:19:28,640 --> 01:19:30,080
then what you do is you go to edge

2500
01:19:30,080 --> 01:19:31,520
impulse

2501
01:19:31,520 --> 01:19:33,040
if you've done it all locally you need

2502
01:19:33,040 --> 01:19:34,719
to go to edge impulse and there's a

2503
01:19:34,719 --> 01:19:36,159
button here that says upload existing

2504
01:19:36,159 --> 01:19:37,120
data and it will just

2505
01:19:37,120 --> 01:19:39,199
it basically just gives you a computer

2506
01:19:39,199 --> 01:19:40,960
interface that just uploads away

2507
01:19:40,960 --> 01:19:44,159
all the wav files from your uh computer

2508
01:19:44,159 --> 01:19:45,280
if you did it locally if you're doing

2509
01:19:45,280 --> 01:19:46,400
everything in colab

2510
01:19:46,400 --> 01:19:48,239
it's using the command line tool to just

2511
01:19:48,239 --> 01:19:52,159
automatically send stuff to edge impulse

2512
01:19:52,560 --> 01:19:55,440
waiting for the job to be scheduled i'm

2513
01:19:55,440 --> 01:19:56,880
i wonder if the edge impulse guys are

2514
01:19:56,880 --> 01:19:57,920
sitting there going

2515
01:19:57,920 --> 01:20:00,960
oh what's going on right now yeah

2516
01:20:00,960 --> 01:20:05,280
i think we're ddosing ei

2517
01:20:05,280 --> 01:20:06,639
i'm gonna have to chat with them and be

2518
01:20:06,639 --> 01:20:08,320
like hey did you guys notice an uptick

2519
01:20:08,320 --> 01:20:09,760
of all your uh your servers

2520
01:20:09,760 --> 01:20:11,810
how did how did you what went on

2521
01:20:11,810 --> 01:20:15,040
[Laughter]

2522
01:20:15,040 --> 01:20:18,719
oh no that's good all right so

2523
01:20:18,719 --> 01:20:21,679
hopefully we are done

2524
01:20:21,920 --> 01:20:24,080
i really hope we're done okay so it

2525
01:20:24,080 --> 01:20:26,400
looks like i lost my output here

2526
01:20:26,400 --> 01:20:28,400
um and i don't want to retrain because i

2527
01:20:28,400 --> 01:20:31,600
actually have everything going on here

2528
01:20:31,600 --> 01:20:33,520
so in yours you should see something

2529
01:20:33,520 --> 01:20:35,600
that says uh

2530
01:20:35,600 --> 01:20:39,120
loss accuracy validation loss

2531
01:20:39,120 --> 01:20:42,400
validation accuracy and um

2532
01:20:42,400 --> 01:20:45,520
during the training sets during the

2533
01:20:45,520 --> 01:20:46,320
training sets

2534
01:20:46,320 --> 01:20:49,840
um they they pull out a small test set

2535
01:20:49,840 --> 01:20:50,960
that get integrated back into the

2536
01:20:50,960 --> 01:20:52,159
training set and they hold those aside

2537
01:20:52,159 --> 01:20:52,960
for a second

2538
01:20:52,960 --> 01:20:55,120
you know do one pass basically of your

2539
01:20:55,120 --> 01:20:57,600
of your uh forward and back propagation

2540
01:20:57,600 --> 01:20:59,600
and then they test the model with that

2541
01:20:59,600 --> 01:21:01,360
validation set and then those get mixed

2542
01:21:01,360 --> 01:21:02,480
in randomized

2543
01:21:02,480 --> 01:21:04,719
um for the next epic basically is my

2544
01:21:04,719 --> 01:21:05,760
understanding how they're doing it for

2545
01:21:05,760 --> 01:21:06,880
this validation set because normally

2546
01:21:06,880 --> 01:21:08,159
when i've done it i've pulled aside a

2547
01:21:08,159 --> 01:21:09,600
validation set to use

2548
01:21:09,600 --> 01:21:12,880
uh separately uh do we leave the

2549
01:21:12,880 --> 01:21:13,920
neural network settings as their

2550
01:21:13,920 --> 01:21:15,280
defaults before we click start training

2551
01:21:15,280 --> 01:21:17,280
yes please leave them as their defaults

2552
01:21:17,280 --> 01:21:19,440
um give me just a second i'll go through

2553
01:21:19,440 --> 01:21:20,320
a couple of those

2554
01:21:20,320 --> 01:21:22,560
um but this is where it's like go learn

2555
01:21:22,560 --> 01:21:23,840
a bunch about machine learning take

2556
01:21:23,840 --> 01:21:25,199
andrew wang's class you'll understand

2557
01:21:25,199 --> 01:21:26,080
more about what these

2558
01:21:26,080 --> 01:21:27,199
these are usually called hyper

2559
01:21:27,199 --> 01:21:28,719
parameters you'll understand more about

2560
01:21:28,719 --> 01:21:30,320
what these hyper parameters do

2561
01:21:30,320 --> 01:21:33,280
um uh and you can feel more confident in

2562
01:21:33,280 --> 01:21:34,719
manipulating these to serve your

2563
01:21:34,719 --> 01:21:36,000
purposes

2564
01:21:36,000 --> 01:21:38,320
um but for now just keep it as default

2565
01:21:38,320 --> 01:21:40,239
um so

2566
01:21:40,239 --> 01:21:41,920
the what you should see if you scroll

2567
01:21:41,920 --> 01:21:43,840
all the way up to your original first

2568
01:21:43,840 --> 01:21:44,639
epic of it

2569
01:21:44,639 --> 01:21:46,320
of that training pass you should

2570
01:21:46,320 --> 01:21:48,000
actually see um

2571
01:21:48,000 --> 01:21:50,639
that loss start to go down and you

2572
01:21:50,639 --> 01:21:52,560
should see your accuracy go up

2573
01:21:52,560 --> 01:21:55,520
both for the regular your training set

2574
01:21:55,520 --> 01:21:56,000
as well

2575
01:21:56,000 --> 01:21:58,639
as of the validation set um if your

2576
01:21:58,639 --> 01:21:59,600
validation set

2577
01:21:59,600 --> 01:22:01,520
starts to if your training set starts to

2578
01:22:01,520 --> 01:22:03,600
split and become more accurate than your

2579
01:22:03,600 --> 01:22:05,440
validation set it usually means your

2580
01:22:05,440 --> 01:22:06,639
model's overfitting that means it's

2581
01:22:06,639 --> 01:22:08,800
better predicting just things it sees in

2582
01:22:08,800 --> 01:22:09,360
the

2583
01:22:09,360 --> 01:22:11,840
training set and cannot generalize to

2584
01:22:11,840 --> 01:22:13,199
things it has not seen before and we're

2585
01:22:13,199 --> 01:22:14,080
going to test that

2586
01:22:14,080 --> 01:22:17,440
um with the testing data so for these

2587
01:22:17,440 --> 01:22:19,199
um quick question about these this says

2588
01:22:19,199 --> 01:22:20,960
how many steps does it do um anything

2589
01:22:20,960 --> 01:22:22,639
between 30 and 100 seems to work for

2590
01:22:22,639 --> 01:22:23,840
this but you can actually manipulate

2591
01:22:23,840 --> 01:22:25,360
this and do what's called early stopping

2592
01:22:25,360 --> 01:22:26,960
you can change this to 30 if you see a

2593
01:22:26,960 --> 01:22:28,000
lot of overfitting

2594
01:22:28,000 --> 01:22:29,760
and have the model stop a little earlier

2595
01:22:29,760 --> 01:22:31,679
to kind of like like like don't try to

2596
01:22:31,679 --> 01:22:32,639
learn more

2597
01:22:32,639 --> 01:22:33,760
um because and then you're going to

2598
01:22:33,760 --> 01:22:35,920
start over fitting to that data learning

2599
01:22:35,920 --> 01:22:37,040
rate um

2600
01:22:37,040 --> 01:22:38,719
there's you know pros and cons to higher

2601
01:22:38,719 --> 01:22:40,560
and lower learning rate and minimum

2602
01:22:40,560 --> 01:22:41,600
confidence rating

2603
01:22:41,600 --> 01:22:44,239
doesn't really apply to us um it only

2604
01:22:44,239 --> 01:22:46,320
applies to when it gives us testing here

2605
01:22:46,320 --> 01:22:47,280
but we're going to get the raw

2606
01:22:47,280 --> 01:22:48,960
probability scores out anyway when we go

2607
01:22:48,960 --> 01:22:50,880
to the microcontroller

2608
01:22:50,880 --> 01:22:53,199
do the data set duration of clips should

2609
01:22:53,199 --> 01:22:54,159
they be the same yes

2610
01:22:54,159 --> 01:22:57,040
your all of your the data you send to

2611
01:22:57,040 --> 01:22:58,960
edge impulse i believe

2612
01:22:58,960 --> 01:23:00,480
and the ei people can correct me if i'm

2613
01:23:00,480 --> 01:23:01,600
wrong here but i believe they all need

2614
01:23:01,600 --> 01:23:03,360
to be a second or

2615
01:23:03,360 --> 01:23:04,560
at least what like they could be one

2616
01:23:04,560 --> 01:23:05,679
second two seconds they all need to be

2617
01:23:05,679 --> 01:23:06,639
the same um

2618
01:23:06,639 --> 01:23:09,600
my script actually truncates anything

2619
01:23:09,600 --> 01:23:10,400
over a second

2620
01:23:10,400 --> 01:23:12,639
or it pads zeros to make it a second so

2621
01:23:12,639 --> 01:23:14,400
if you're using my curation script it

2622
01:23:14,400 --> 01:23:16,000
accounts for that just make sure where

2623
01:23:16,000 --> 01:23:18,840
the utterance is isn't going to be

2624
01:23:18,840 --> 01:23:21,840
truncated

2625
01:23:24,000 --> 01:23:25,360
uh yeah start training if you've not

2626
01:23:25,360 --> 01:23:28,560
done so um this output refreshed for me

2627
01:23:28,560 --> 01:23:30,239
so what you should see is like a bunch

2628
01:23:30,239 --> 01:23:32,840
of output here

2629
01:23:32,840 --> 01:23:35,840
and

2630
01:23:37,280 --> 01:23:38,639
and you should see a confusion matrix

2631
01:23:38,639 --> 01:23:40,320
when it's done down here uh save for

2632
01:23:40,320 --> 01:23:41,679
machine data i'm not quite sure what you

2633
01:23:41,679 --> 01:23:43,280
mean by machine data

2634
01:23:43,280 --> 01:23:45,360
do the same do the data set duration of

2635
01:23:45,360 --> 01:23:46,480
clips should be the same

2636
01:23:46,480 --> 01:23:48,000
um so they generally should otherwise

2637
01:23:48,000 --> 01:23:49,760
you're gonna end up with

2638
01:23:49,760 --> 01:23:53,040
different lengths of mfcc's machine

2639
01:23:53,040 --> 01:23:55,280
sound data so like sounds from a machine

2640
01:23:55,280 --> 01:23:56,719
or like when you record

2641
01:23:56,719 --> 01:23:58,000
sorry i'm not quite following that

2642
01:23:58,000 --> 01:24:00,080
question okay

2643
01:24:00,080 --> 01:24:01,679
so sounds from a machine yeah i guess

2644
01:24:01,679 --> 01:24:03,040
they should all be the same they should

2645
01:24:03,040 --> 01:24:04,480
be the same duration

2646
01:24:04,480 --> 01:24:06,480
um because otherwise like the you have

2647
01:24:06,480 --> 01:24:07,600
to remember that your

2648
01:24:07,600 --> 01:24:10,639
neural network expects exactly

2649
01:24:10,639 --> 01:24:14,000
um a number of input

2650
01:24:14,000 --> 01:24:17,120
uh um a number of inputs so like like

2651
01:24:17,120 --> 01:24:17,520
that

2652
01:24:17,520 --> 01:24:20,000
that image that is a like 13 by 40

2653
01:24:20,000 --> 01:24:21,440
whatever image

2654
01:24:21,440 --> 01:24:24,400
it expects like exactly that array as an

2655
01:24:24,400 --> 01:24:25,760
input if you don't feed it exactly that

2656
01:24:25,760 --> 01:24:26,880
you start throwing a whole bunch of

2657
01:24:26,880 --> 01:24:28,800
errors

2658
01:24:28,800 --> 01:24:31,199
um okay so confusion matrix you have

2659
01:24:31,199 --> 01:24:32,080
your

2660
01:24:32,080 --> 01:24:34,960
uh let's see actual label unknown so

2661
01:24:34,960 --> 01:24:36,320
you've got your actual labels on this

2662
01:24:36,320 --> 01:24:36,960
side

2663
01:24:36,960 --> 01:24:39,040
and your predicted labels on this side

2664
01:24:39,040 --> 01:24:40,320
which you should see is the numbers in

2665
01:24:40,320 --> 01:24:42,719
the diagonal

2666
01:24:42,719 --> 01:24:44,880
um should be the highest and that means

2667
01:24:44,880 --> 01:24:46,320
it's doing a decent job of predicting

2668
01:24:46,320 --> 01:24:47,360
and it's got an 80

2669
01:24:47,360 --> 01:24:49,360
accuracy i don't see any neural network

2670
01:24:49,360 --> 01:24:51,040
classifier on my ei

2671
01:24:51,040 --> 01:24:53,600
um it should be on the left side um i've

2672
01:24:53,600 --> 01:24:54,880
done this before

2673
01:24:54,880 --> 01:24:56,719
don't forget to click save impulse after

2674
01:24:56,719 --> 01:24:58,000
you've added them over here and that

2675
01:24:58,000 --> 01:24:59,360
should cause them to appear

2676
01:24:59,360 --> 01:25:01,280
over here um yeah if you don't click

2677
01:25:01,280 --> 01:25:02,880
save impulse they don't show up over

2678
01:25:02,880 --> 01:25:05,040
here

2679
01:25:05,199 --> 01:25:08,159
say 15 second clip to 15 clips of one

2680
01:25:08,159 --> 01:25:08,719
second

2681
01:25:08,719 --> 01:25:10,719
yes if you're if you're creating your

2682
01:25:10,719 --> 01:25:12,000
own

2683
01:25:12,000 --> 01:25:14,080
samples they need to be 15 clips of one

2684
01:25:14,080 --> 01:25:15,360
second each each of those is what we're

2685
01:25:15,360 --> 01:25:17,600
feeding into edge impulse

2686
01:25:17,600 --> 01:25:19,679
all right so you can do live you can do

2687
01:25:19,679 --> 01:25:22,960
live classification

2688
01:25:24,840 --> 01:25:26,239
uh

2689
01:25:26,239 --> 01:25:28,080
no not live sorry that is if you

2690
01:25:28,080 --> 01:25:29,600
actually have a microphone connected and

2691
01:25:29,600 --> 01:25:31,040
it can read it we want to do model

2692
01:25:31,040 --> 01:25:32,080
testing

2693
01:25:32,080 --> 01:25:33,520
that's actually going to take our this

2694
01:25:33,520 --> 01:25:35,840
is our test set the 20 we set aside

2695
01:25:35,840 --> 01:25:37,760
so click the top to highlight all of

2696
01:25:37,760 --> 01:25:39,679
those click classify selected

2697
01:25:39,679 --> 01:25:41,520
you'll see what it's going to do here is

2698
01:25:41,520 --> 01:25:43,679
it's going to take each of these

2699
01:25:43,679 --> 01:25:46,719
um samples that we set aside a while ago

2700
01:25:46,719 --> 01:25:48,320
and it's going to send all of those

2701
01:25:48,320 --> 01:25:51,120
through the neural network to classify

2702
01:25:51,120 --> 01:25:53,440
us that for us i don't see anything that

2703
01:25:53,440 --> 01:25:54,800
says save impulse so if you go to

2704
01:25:54,800 --> 01:25:57,600
impulse design

2705
01:25:58,239 --> 01:26:01,440
and you should see audio mfcc so if i

2706
01:26:01,440 --> 01:26:02,320
modify this

2707
01:26:02,320 --> 01:26:03,360
actually i can't modify because it's

2708
01:26:03,360 --> 01:26:05,120
going to wreck everything past it so if

2709
01:26:05,120 --> 01:26:07,280
you see this here like i don't see it

2710
01:26:07,280 --> 01:26:08,880
it should be over here on the right side

2711
01:26:08,880 --> 01:26:12,159
underneath output features

2712
01:26:13,120 --> 01:26:15,040
uh what tool do i recommend cutting the

2713
01:26:15,040 --> 01:26:17,679
clip audacity

2714
01:26:17,679 --> 01:26:20,719
uh no worries audacity is definitely the

2715
01:26:20,719 --> 01:26:22,880
the tool you should use to cut the clips

2716
01:26:22,880 --> 01:26:25,520
um if you find a way to automate them

2717
01:26:25,520 --> 01:26:28,560
great but um because you can't be quite

2718
01:26:28,560 --> 01:26:29,840
sure where that utterance is like you

2719
01:26:29,840 --> 01:26:31,280
can create something that says oh

2720
01:26:31,280 --> 01:26:33,120
i see the utterance starting and then

2721
01:26:33,120 --> 01:26:34,639
you can try to like center it or move it

2722
01:26:34,639 --> 01:26:35,520
around and then

2723
01:26:35,520 --> 01:26:37,120
you can come up with some automated tool

2724
01:26:37,120 --> 01:26:39,600
to truncate exactly a second or

2725
01:26:39,600 --> 01:26:41,920
crop out exactly a second for you um but

2726
01:26:41,920 --> 01:26:42,880
because i was working with

2727
01:26:42,880 --> 01:26:44,560
at most 100 samples i was just doing

2728
01:26:44,560 --> 01:26:46,159
everything on audacity for the custom

2729
01:26:46,159 --> 01:26:48,400
stuff

2730
01:26:48,719 --> 01:26:52,320
all right testing should be done

2731
01:26:53,120 --> 01:26:56,400
we can come back to here and

2732
01:26:56,400 --> 01:27:01,199
it did not work for me let's try that

2733
01:27:02,840 --> 01:27:05,840
again

2734
01:27:07,520 --> 01:27:09,679
testing is at 65 awesome some other

2735
01:27:09,679 --> 01:27:11,679
people's testing is rolled in

2736
01:27:11,679 --> 01:27:14,000
uh what is mine at 73 oh my was better

2737
01:27:14,000 --> 01:27:14,800
than last night

2738
01:27:14,800 --> 01:27:18,080
so this is a case of overfitting um most

2739
01:27:18,080 --> 01:27:19,760
of the time you will find that it that

2740
01:27:19,760 --> 01:27:20,639
it overfits

2741
01:27:20,639 --> 01:27:22,560
um might actually like perform

2742
01:27:22,560 --> 01:27:24,320
surprisingly well i got like 65

2743
01:27:24,320 --> 01:27:27,440
last night this is a general case

2744
01:27:27,440 --> 01:27:28,400
because we train

2745
01:27:28,400 --> 01:27:30,800
too long the model's not quite right um

2746
01:27:30,800 --> 01:27:32,080
for whatever reason

2747
01:27:32,080 --> 01:27:34,480
it overfit that data and now it's not as

2748
01:27:34,480 --> 01:27:36,239
good as classifying unseen data

2749
01:27:36,239 --> 01:27:38,080
there are a number of techniques you can

2750
01:27:38,080 --> 01:27:39,360
do to combat this

2751
01:27:39,360 --> 01:27:41,920
um one of them is to stop it early um if

2752
01:27:41,920 --> 01:27:43,280
you want to i recommend going back and

2753
01:27:43,280 --> 01:27:44,080
try training with

2754
01:27:44,080 --> 01:27:47,840
30 epics instead of 100

2755
01:27:48,320 --> 01:27:49,679
the other thing is getting more data you

2756
01:27:49,679 --> 01:27:51,600
can always get more data

2757
01:27:51,600 --> 01:27:54,320
you can try um adding in different

2758
01:27:54,320 --> 01:27:55,920
layers in the neural network so if we go

2759
01:27:55,920 --> 01:27:58,960
to the neural network classifier

2760
01:27:58,960 --> 01:28:01,120
you can actually add new layers you can

2761
01:28:01,120 --> 01:28:02,080
try uh

2762
01:28:02,080 --> 01:28:03,600
you know do if you know what you're

2763
01:28:03,600 --> 01:28:04,800
doing with neural networks you can try

2764
01:28:04,800 --> 01:28:05,760
adding different layers

2765
01:28:05,760 --> 01:28:08,239
you can try modifying um like your

2766
01:28:08,239 --> 01:28:10,239
dropout rates you know maybe try 0.5

2767
01:28:10,239 --> 01:28:11,920
dropout rate right like dropout is great

2768
01:28:11,920 --> 01:28:14,400
for preventing over 50 over uh

2769
01:28:14,400 --> 01:28:15,840
oh 15 minute warning oh shoot i thought

2770
01:28:15,840 --> 01:28:17,360
we were going to 6 15. we're going to do

2771
01:28:17,360 --> 01:28:19,520
this faster all right

2772
01:28:19,520 --> 01:28:22,639
let's go to deployment

2773
01:28:22,639 --> 01:28:25,040
uh can you add chaos early i don't think

2774
01:28:25,040 --> 01:28:26,480
you can

2775
01:28:26,480 --> 01:28:29,679
um so in deployment we're going to go to

2776
01:28:29,679 --> 01:28:32,960
uh actually c plus library um feel free

2777
01:28:32,960 --> 01:28:34,239
to analyze if you want but i'm just

2778
01:28:34,239 --> 01:28:36,159
going to say go ahead and build

2779
01:28:36,159 --> 01:28:39,440
um this will tell you um this will give

2780
01:28:39,440 --> 01:28:42,960
you an idea of uh

2781
01:28:42,960 --> 01:28:44,000
how much time it's going to take and

2782
01:28:44,000 --> 01:28:45,600
what kind of processing you'll need no

2783
01:28:45,600 --> 01:28:46,719
it's not giving you the

2784
01:28:46,719 --> 01:28:50,080
mfcc calculation time so with that and i

2785
01:28:50,080 --> 01:28:51,120
apologize i'm gonna have to go

2786
01:28:51,120 --> 01:28:52,719
a little more quickly here go back to

2787
01:28:52,719 --> 01:28:54,480
the github repo

2788
01:28:54,480 --> 01:28:57,839
download the code

2789
01:29:02,080 --> 01:29:04,400
so we should have so once you've clicked

2790
01:29:04,400 --> 01:29:06,080
build for edge impulse

2791
01:29:06,080 --> 01:29:08,840
you've clicked build go to the github

2792
01:29:08,840 --> 01:29:12,080
repo um where the worksheet is

2793
01:29:12,080 --> 01:29:14,800
and download that zip so you should have

2794
01:29:14,800 --> 01:29:17,040
two

2795
01:29:17,600 --> 01:29:20,320
and of course windows is showing me that

2796
01:29:20,320 --> 01:29:22,159
so speech recognition

2797
01:29:22,159 --> 01:29:25,520
um unzip both of these uh note that if

2798
01:29:25,520 --> 01:29:26,480
you are on windows

2799
01:29:26,480 --> 01:29:28,800
you will want um 7-zip you will probably

2800
01:29:28,800 --> 01:29:30,560
run into windows running out of

2801
01:29:30,560 --> 01:29:32,960
um space to print out its um file names

2802
01:29:32,960 --> 01:29:35,760
or its file paths

2803
01:29:35,920 --> 01:29:38,960
so yes i'm going to use 7-zip to extract

2804
01:29:38,960 --> 01:29:42,080
this i'm going to use 7-zip to extract

2805
01:29:42,080 --> 01:29:44,719
both of these

2806
01:29:46,880 --> 01:29:50,159
uh intrinsics for single instruction

2807
01:29:50,159 --> 01:29:51,840
multiple data

2808
01:29:51,840 --> 01:29:54,800
i don't believe it does um because i

2809
01:29:54,800 --> 01:29:55,600
don't believe

2810
01:29:55,600 --> 01:29:57,440
these these are microcontrollers are set

2811
01:29:57,440 --> 01:29:59,919
up for that

2812
01:30:00,480 --> 01:30:03,760
so we you should have so this is our

2813
01:30:03,760 --> 01:30:04,960
model that we downloaded from edge

2814
01:30:04,960 --> 01:30:06,800
impulse um this is what the library

2815
01:30:06,800 --> 01:30:08,400
looks like our model is actually in tf

2816
01:30:08,400 --> 01:30:10,159
lite model

2817
01:30:10,159 --> 01:30:12,000
uh uh you need to click the build button

2818
01:30:12,000 --> 01:30:13,360
at the very bottom for edge impulse to

2819
01:30:13,360 --> 01:30:15,199
get it to build and download for you

2820
01:30:15,199 --> 01:30:16,639
and that just takes the model that we

2821
01:30:16,639 --> 01:30:18,320
created we just trained

2822
01:30:18,320 --> 01:30:19,760
this it basically compresses it into a

2823
01:30:19,760 --> 01:30:21,760
tensorflow lite model um builds a

2824
01:30:21,760 --> 01:30:22,880
library around it

2825
01:30:22,880 --> 01:30:26,800
and downloads it for us um

2826
01:30:26,800 --> 01:30:29,040
so what we need to do is go into the ei

2827
01:30:29,040 --> 01:30:30,719
keyword spotting master

2828
01:30:30,719 --> 01:30:32,960
or not go into there yet that's what

2829
01:30:32,960 --> 01:30:34,320
we're going to bring in as our demo

2830
01:30:34,320 --> 01:30:35,120
project

2831
01:30:35,120 --> 01:30:38,560
so open up stm32 cube ide

2832
01:30:38,560 --> 01:30:42,159
launch that oh end time is 6 15 minutes

2833
01:30:42,159 --> 01:30:43,840
okay so just to confirm we've got uh

2834
01:30:43,840 --> 01:30:46,960
like 25 minutes right

2835
01:30:47,199 --> 01:30:49,760
awesome thank you i'm gonna like start

2836
01:30:49,760 --> 01:30:50,239
burning

2837
01:30:50,239 --> 01:30:53,920
really fast here okay so

2838
01:30:53,920 --> 01:30:57,199
stm32 cube ide bring that up what we

2839
01:30:57,199 --> 01:30:59,679
want to do is file

2840
01:30:59,679 --> 01:31:04,320
import and we are going to

2841
01:31:04,320 --> 01:31:07,280
import uh this is where actually i

2842
01:31:07,280 --> 01:31:08,560
forget

2843
01:31:08,560 --> 01:31:12,080
so this is why i wrote this all down

2844
01:31:12,080 --> 01:31:15,120
so in this github go check out the

2845
01:31:15,120 --> 01:31:17,600
embedded demos

2846
01:31:17,600 --> 01:31:21,040
go to the l464761

2847
01:31:21,040 --> 01:31:23,040
there is a walkthrough this is where we

2848
01:31:23,040 --> 01:31:24,239
are now is in this

2849
01:31:24,239 --> 01:31:25,760
second walkthrough because it's gonna

2850
01:31:25,760 --> 01:31:28,080
when i give more examples into this when

2851
01:31:28,080 --> 01:31:29,679
i put more examples in this github repo

2852
01:31:29,679 --> 01:31:31,120
i'm hoping to flesh out each one like

2853
01:31:31,120 --> 01:31:32,880
how do you make this example work

2854
01:31:32,880 --> 01:31:35,840
um this shows you your connections um

2855
01:31:35,840 --> 01:31:37,920
and what looks like we need to do is

2856
01:31:37,920 --> 01:31:41,120
file import existing projects into

2857
01:31:41,120 --> 01:31:44,080
workspace this is the step that i always

2858
01:31:44,080 --> 01:31:48,239
mess up so click on existing projects

2859
01:31:48,239 --> 01:31:50,239
into workspace

2860
01:31:50,239 --> 01:31:52,000
and this is where eclipse does it's i

2861
01:31:52,000 --> 01:31:55,120
try to make everything a gui

2862
01:31:55,120 --> 01:31:57,199
uh copy projects into workspace make

2863
01:31:57,199 --> 01:31:58,159
sure that's all

2864
01:31:58,159 --> 01:32:00,000
selected copy projects into workspace we

2865
01:32:00,000 --> 01:32:02,480
want that

2866
01:32:02,480 --> 01:32:13,839
uh yeah that looks good finish

2867
01:32:14,080 --> 01:32:16,639
um okay so for anybody who missed it

2868
01:32:16,639 --> 01:32:18,080
download

2869
01:32:18,080 --> 01:32:19,679
my github repo the one where the

2870
01:32:19,679 --> 01:32:22,000
worksheet is download the whole thing

2871
01:32:22,000 --> 01:32:24,840
um and you'll also want to download the

2872
01:32:24,840 --> 01:32:27,120
um

2873
01:32:27,120 --> 01:32:28,560
uh the edge impulse model that we

2874
01:32:28,560 --> 01:32:32,159
created so if you go to deployment

2875
01:32:32,639 --> 01:32:34,159
there's a build button at the bottom

2876
01:32:34,159 --> 01:32:35,679
that's what downloads everything so you

2877
01:32:35,679 --> 01:32:36,800
want to select

2878
01:32:36,800 --> 01:32:39,360
c plus library is what we're using and

2879
01:32:39,360 --> 01:32:42,080
then click build

2880
01:32:43,440 --> 01:32:45,920
so back in stm32 so we've got the

2881
01:32:45,920 --> 01:32:48,239
project so this is from my github repo

2882
01:32:48,239 --> 01:32:50,480
um

2883
01:32:51,600 --> 01:32:52,960
once again i have to go to the worksheet

2884
01:32:52,960 --> 01:32:55,120
now because i don't remember these exact

2885
01:32:55,120 --> 01:32:56,320
steps

2886
01:32:56,320 --> 01:32:58,159
projects explorer so we need to delete

2887
01:32:58,159 --> 01:33:00,000
the model parameters in tf lite

2888
01:33:00,000 --> 01:33:03,040
directories so this demo comes with

2889
01:33:03,040 --> 01:33:05,679
a pre-trained model and that pre-trained

2890
01:33:05,679 --> 01:33:06,159
model

2891
01:33:06,159 --> 01:33:09,120
exists in the tf model as well as some

2892
01:33:09,120 --> 01:33:10,480
information about it in the parameters

2893
01:33:10,480 --> 01:33:11,120
folders

2894
01:33:11,120 --> 01:33:13,840
so in ei keyword spotting delete that

2895
01:33:13,840 --> 01:33:14,480
one

2896
01:33:14,480 --> 01:33:17,199
uh yeah you deleted that from the from

2897
01:33:17,199 --> 01:33:19,040
the whole file system and delete

2898
01:33:19,040 --> 01:33:24,080
tf model tf like there we go

2899
01:33:24,080 --> 01:33:27,920
uh file import general file system

2900
01:33:27,920 --> 01:33:30,960
so here is one of the weird eclipse

2901
01:33:30,960 --> 01:33:31,360
things

2902
01:33:31,360 --> 01:33:33,679
when you're working in eclipse you've

2903
01:33:33,679 --> 01:33:35,280
got the projects over here

2904
01:33:35,280 --> 01:33:37,199
so i've got a few projects going on make

2905
01:33:37,199 --> 01:33:38,800
sure you click on that project when

2906
01:33:38,800 --> 01:33:39,920
you're working in it

2907
01:33:39,920 --> 01:33:43,000
or bring up something like core source

2908
01:33:43,000 --> 01:33:44,320
main.cpp

2909
01:33:44,320 --> 01:33:45,679
to make sure you're working in there

2910
01:33:45,679 --> 01:33:47,440
otherwise if you accidentally click one

2911
01:33:47,440 --> 01:33:48,159
of these and you

2912
01:33:48,159 --> 01:33:49,520
go to import a file it's going to import

2913
01:33:49,520 --> 01:33:51,440
it into another project so

2914
01:33:51,440 --> 01:33:52,639
always make sure you've got the project

2915
01:33:52,639 --> 01:33:54,639
you're working on selected or feel free

2916
01:33:54,639 --> 01:33:55,440
to

2917
01:33:55,440 --> 01:33:57,679
close these wherever the close is there

2918
01:33:57,679 --> 01:33:58,639
close project

2919
01:33:58,639 --> 01:34:00,800
feel free to do that and it makes it a

2920
01:34:00,800 --> 01:34:04,800
little neater

2921
01:34:04,800 --> 01:34:07,040
and it's a little harder to mess up some

2922
01:34:07,040 --> 01:34:07,840
of these steps so

2923
01:34:07,840 --> 01:34:12,800
click on that file import

2924
01:34:12,800 --> 01:34:16,159
uh general file system so general

2925
01:34:16,159 --> 01:34:19,920
file system next uh we want to select

2926
01:34:19,920 --> 01:34:21,920
the model parameters directory

2927
01:34:21,920 --> 01:34:23,440
uh how do we open the project in cube

2928
01:34:23,440 --> 01:34:26,239
ide um so we're on this walkthrough

2929
01:34:26,239 --> 01:34:26,880
right now

2930
01:34:26,880 --> 01:34:30,000
in where the github

2931
01:34:30,000 --> 01:34:31,679
repo where my original worksheet was if

2932
01:34:31,679 --> 01:34:34,560
you go to embedded demos stm32q ide

2933
01:34:34,560 --> 01:34:37,600
keyword spotting the nuclio l476 keyword

2934
01:34:37,600 --> 01:34:39,440
spotting the walkthrough continues for

2935
01:34:39,440 --> 01:34:41,040
this specific microcontroller

2936
01:34:41,040 --> 01:34:42,800
and this gives you the exact steps you

2937
01:34:42,800 --> 01:34:44,840
need to perform to get the stuff to

2938
01:34:44,840 --> 01:34:46,080
import

2939
01:34:46,080 --> 01:34:48,800
i i hope that helps um because i can't

2940
01:34:48,800 --> 01:34:49,679
go back and like

2941
01:34:49,679 --> 01:34:52,719
show you this step again

2942
01:34:53,920 --> 01:34:57,199
so we need to import uh where was i

2943
01:34:57,199 --> 01:35:01,839
the model parameters directory

2944
01:35:02,400 --> 01:35:04,880
from the model we downloaded because

2945
01:35:04,880 --> 01:35:06,320
we're replacing the model that was in

2946
01:35:06,320 --> 01:35:07,119
there

2947
01:35:07,119 --> 01:35:10,320
that is the speech recognition o2

2948
01:35:10,320 --> 01:35:12,840
so the model parameters select that

2949
01:35:12,840 --> 01:35:14,719
folder it should look something like

2950
01:35:14,719 --> 01:35:15,440
this we gotta

2951
01:35:15,440 --> 01:35:18,560
we gotta select them get a

2952
01:35:18,560 --> 01:35:22,480
create top level directory yep

2953
01:35:22,480 --> 01:35:24,960
that looks good finish okay so that

2954
01:35:24,960 --> 01:35:28,320
should have dropped

2955
01:35:28,320 --> 01:35:30,800
oh i messed that one up so i put it in

2956
01:35:30,800 --> 01:35:33,040
here

2957
01:35:33,280 --> 01:35:36,159
that's where i messed up

2958
01:35:36,400 --> 01:35:39,760
so delete that uh

2959
01:35:39,760 --> 01:35:42,800
the id is putting my cpu i don't know

2960
01:35:42,800 --> 01:35:44,239
sometimes it can do that if it's the

2961
01:35:44,239 --> 01:35:45,360
first time you're doing if your first

2962
01:35:45,360 --> 01:35:46,639
time you're running the ide it might

2963
01:35:46,639 --> 01:35:47,920
hose your machine for a while

2964
01:35:47,920 --> 01:35:49,040
we do not record data using the

2965
01:35:49,040 --> 01:35:52,000
microphone how will the model work um

2966
01:35:52,000 --> 01:35:53,199
it's all because of how we did it with

2967
01:35:53,199 --> 01:35:55,280
the m because the mfcc's

2968
01:35:55,280 --> 01:35:58,080
um the mfccs are what the key here is it

2969
01:35:58,080 --> 01:35:59,199
allows us to record with different

2970
01:35:59,199 --> 01:36:00,800
microphones create a model and then it

2971
01:36:00,800 --> 01:36:04,159
listens from whatever microphone we want

2972
01:36:04,159 --> 01:36:08,880
so let's try this again file import

2973
01:36:08,880 --> 01:36:12,320
my love of eclipse is showing

2974
01:36:13,760 --> 01:36:16,639
uh download model parameters select

2975
01:36:16,639 --> 01:36:19,040
folder

2976
01:36:21,600 --> 01:36:24,639
uh here we go so into folder

2977
01:36:24,639 --> 01:36:27,199
it needs to go into ei keyword spotting

2978
01:36:27,199 --> 01:36:27,679
so

2979
01:36:27,679 --> 01:36:29,119
if you've selected this it should go in

2980
01:36:29,119 --> 01:36:30,719
here otherwise you can click browse

2981
01:36:30,719 --> 01:36:32,639
make sure it goes into eli keyword

2982
01:36:32,639 --> 01:36:34,719
spotting it's very important that

2983
01:36:34,719 --> 01:36:37,280
um our model exists in this directory

2984
01:36:37,280 --> 01:36:38,800
because of how i have the includes set

2985
01:36:38,800 --> 01:36:39,360
up

2986
01:36:39,360 --> 01:36:41,920
so there we go model parameters is now

2987
01:36:41,920 --> 01:36:42,800
inside of there

2988
01:36:42,800 --> 01:36:44,800
we need to do the same thing with the tf

2989
01:36:44,800 --> 01:36:47,600
lite model directory

2990
01:36:47,600 --> 01:36:49,440
so we actually want to if you select

2991
01:36:49,440 --> 01:36:51,119
this it helps i'll try it from here

2992
01:36:51,119 --> 01:36:55,760
file import file system

2993
01:36:55,760 --> 01:37:00,159
so let's do the tflight model

2994
01:37:00,159 --> 01:37:01,920
select those so you see it tries to put

2995
01:37:01,920 --> 01:37:03,280
in the base project directory so i'm

2996
01:37:03,280 --> 01:37:04,880
gonna go browse

2997
01:37:04,880 --> 01:37:07,679
here's my project ei keyword spotting

2998
01:37:07,679 --> 01:37:08,320
select

2999
01:37:08,320 --> 01:37:11,199
create top level directory selected and

3000
01:37:11,199 --> 01:37:13,280
finish

3001
01:37:13,280 --> 01:37:15,199
okay so the three directories so we've

3002
01:37:15,199 --> 01:37:17,119
now started with my

3003
01:37:17,119 --> 01:37:19,360
my basically my template demo project

3004
01:37:19,360 --> 01:37:21,280
we've replaced the model

3005
01:37:21,280 --> 01:37:23,600
with the one that we trained from edge

3006
01:37:23,600 --> 01:37:26,080
impulse

3007
01:37:27,760 --> 01:37:30,560
all right project build configurations

3008
01:37:30,560 --> 01:37:31,840
set active releases

3009
01:37:31,840 --> 01:37:34,480
oh here we go project build

3010
01:37:34,480 --> 01:37:35,440
configurations

3011
01:37:35,440 --> 01:37:37,920
set active it wants to default to debug

3012
01:37:37,920 --> 01:37:39,040
we actually need to go to release the

3013
01:37:39,040 --> 01:37:40,480
reason for that is because there is a

3014
01:37:40,480 --> 01:37:42,239
compiler flag that gets set if we use

3015
01:37:42,239 --> 01:37:44,000
debug that makes everything run

3016
01:37:44,000 --> 01:37:46,639
really slowly um with tensorflow lite so

3017
01:37:46,639 --> 01:37:48,000
we want to make sure we're doing release

3018
01:37:48,000 --> 01:37:50,480
here um if you want to debug stuff go

3019
01:37:50,480 --> 01:37:52,159
for it i don't recommend using this

3020
01:37:52,159 --> 01:37:54,080
program to debug tensorflow lite

3021
01:37:54,080 --> 01:37:55,760
um because you'll overflow your audio

3022
01:37:55,760 --> 01:37:58,000
buffer it's like it's very very narrow

3023
01:37:58,000 --> 01:37:59,199
margins when it's trying to fill up an

3024
01:37:59,199 --> 01:37:59,920
audio buffer

3025
01:37:59,920 --> 01:38:03,840
and then run um your inference

3026
01:38:04,639 --> 01:38:07,679
uh okay so now we want to

3027
01:38:07,679 --> 01:38:10,639
new configuration and then build the

3028
01:38:10,639 --> 01:38:11,280
project

3029
01:38:11,280 --> 01:38:17,520
project build project

3030
01:38:17,520 --> 01:38:18,560
and then this is going to take a little

3031
01:38:18,560 --> 01:38:19,840
bit because not only does this have to

3032
01:38:19,840 --> 01:38:20,880
compile

3033
01:38:20,880 --> 01:38:22,400
what we have going on this has to

3034
01:38:22,400 --> 01:38:24,480
compile um the model

3035
01:38:24,480 --> 01:38:26,400
and all the uh edge impulse stuff as

3036
01:38:26,400 --> 01:38:28,960
well while that's going on

3037
01:38:28,960 --> 01:38:31,440
i can show you a little bit in maine so

3038
01:38:31,440 --> 01:38:33,199
unfortunately if you've never done stm32

3039
01:38:33,199 --> 01:38:34,000
cube stuff

3040
01:38:34,000 --> 01:38:36,080
with their hal and in this ide this is

3041
01:38:36,080 --> 01:38:37,920
going to be a little confusing

3042
01:38:37,920 --> 01:38:39,360
like i said next time i do this workshop

3043
01:38:39,360 --> 01:38:40,560
i'm going to do an arduino because i

3044
01:38:40,560 --> 01:38:41,679
think most people

3045
01:38:41,679 --> 01:38:44,639
um taking this workshop have had some

3046
01:38:44,639 --> 01:38:45,920
hopefully experience with arduino it

3047
01:38:45,920 --> 01:38:47,119
would be a lot easier

3048
01:38:47,119 --> 01:38:49,280
um lesson learned i mean i would i would

3049
01:38:49,280 --> 01:38:50,800
do this in arduino in the future

3050
01:38:50,800 --> 01:38:54,000
um that being said i like stm32 i i can

3051
01:38:54,000 --> 01:38:55,280
do a lot of stuff with it

3052
01:38:55,280 --> 01:38:57,119
um on a low low level even though i'm

3053
01:38:57,119 --> 01:38:58,400
using hal which is

3054
01:38:58,400 --> 01:39:00,639
um like somewhere between like reading

3055
01:39:00,639 --> 01:39:02,159
and writing registers

3056
01:39:02,159 --> 01:39:05,760
in your arduino framework so what's

3057
01:39:05,760 --> 01:39:07,440
the the big stuff that we need to care

3058
01:39:07,440 --> 01:39:08,800
about is here's main here's your entry

3059
01:39:08,800 --> 01:39:09,679
point

3060
01:39:09,679 --> 01:39:12,239
and there's stuff here that sets up hal

3061
01:39:12,239 --> 01:39:14,480
is stm32 stuff that's setting up all of

3062
01:39:14,480 --> 01:39:17,679
your peripherals your clocks your timers

3063
01:39:17,679 --> 01:39:20,320
uh even if you re yes that is yes kai

3064
01:39:20,320 --> 01:39:21,760
you're correct if even if you use hal

3065
01:39:21,760 --> 01:39:22,880
you still need to read the reference

3066
01:39:22,880 --> 01:39:24,960
manual that is so very true

3067
01:39:24,960 --> 01:39:27,520
um it just does some stuff that makes it

3068
01:39:27,520 --> 01:39:29,040
a little easier but then eventually you

3069
01:39:29,040 --> 01:39:29,920
get to the point where you're like wait

3070
01:39:29,920 --> 01:39:31,600
hal doesn't do this exact thing i want

3071
01:39:31,600 --> 01:39:32,719
then you have to go like to a lower

3072
01:39:32,719 --> 01:39:34,480
level library or doing manual

3073
01:39:34,480 --> 01:39:37,760
register reads and writes from there um

3074
01:39:37,760 --> 01:39:41,119
ei printf they have us implement ei

3075
01:39:41,119 --> 01:39:42,400
printf

3076
01:39:42,400 --> 01:39:43,840
if you scroll down you'll find that

3077
01:39:43,840 --> 01:39:46,239
function

3078
01:39:46,400 --> 01:39:49,360
i have ctrl f

3079
01:39:49,840 --> 01:39:52,320
so here it is all it's really doing is

3080
01:39:52,320 --> 01:39:53,920
calling this which just uses hal

3081
01:39:53,920 --> 01:39:55,520
transmit so that's coming out over the

3082
01:39:55,520 --> 01:39:55,840
uh

3083
01:39:55,840 --> 01:39:59,360
second uart port um that allows some of

3084
01:39:59,360 --> 01:40:01,119
the edge impulse stuff

3085
01:40:01,119 --> 01:40:04,000
to uh spit out over uart that helps us

3086
01:40:04,000 --> 01:40:04,560
debug

3087
01:40:04,560 --> 01:40:08,000
that's all that's going on so back

3088
01:40:08,000 --> 01:40:10,159
in loop oh sorry yeah loop right we're

3089
01:40:10,159 --> 01:40:13,119
in arduino i'm already thinking arduino

3090
01:40:13,119 --> 01:40:14,800
um that'll print out some stuff it's uh

3091
01:40:14,800 --> 01:40:16,639
then edge impulse sets up all of our

3092
01:40:16,639 --> 01:40:17,440
buffers

3093
01:40:17,440 --> 01:40:20,159
and sets up the tensorflow lite stuff

3094
01:40:20,159 --> 01:40:22,320
and then in here this is where the juicy

3095
01:40:22,320 --> 01:40:23,199
bits happen

3096
01:40:23,199 --> 01:40:26,880
um it this waits for

3097
01:40:26,880 --> 01:40:29,360
this waits for the audio buffer that

3098
01:40:29,360 --> 01:40:31,440
records exactly 250

3099
01:40:31,440 --> 01:40:33,520
milliseconds of audio data to fill up

3100
01:40:33,520 --> 01:40:36,480
before returning control

3101
01:40:36,480 --> 01:40:39,600
if you let that overflow

3102
01:40:39,600 --> 01:40:41,840
it kind of breaks this whole process so

3103
01:40:41,840 --> 01:40:44,239
if you put a bunch of code here

3104
01:40:44,239 --> 01:40:46,480
that then prevents it from um that

3105
01:40:46,480 --> 01:40:48,080
overflows that buffer because that you

3106
01:40:48,080 --> 01:40:50,159
waited too long at 250 milliseconds

3107
01:40:50,159 --> 01:40:52,320
um you'll break the whole process so

3108
01:40:52,320 --> 01:40:53,679
that's why i have to be really careful

3109
01:40:53,679 --> 01:40:54,320
here

3110
01:40:54,320 --> 01:40:56,159
um it will do classification the magical

3111
01:40:56,159 --> 01:40:58,159
thing is we take that raw signal that

3112
01:40:58,159 --> 01:40:59,440
raw audio data

3113
01:40:59,440 --> 01:41:01,280
and then we send it we call run

3114
01:41:01,280 --> 01:41:03,280
classifier continuous with it

3115
01:41:03,280 --> 01:41:05,760
and that performs the mfcc extraction

3116
01:41:05,760 --> 01:41:06,320
from that

3117
01:41:06,320 --> 01:41:08,320
and then does uh inference with the

3118
01:41:08,320 --> 01:41:11,040
neural network that we trained

3119
01:41:11,040 --> 01:41:14,560
uh we then print the output

3120
01:41:14,560 --> 01:41:16,480
oh i thought i updated this from last

3121
01:41:16,480 --> 01:41:18,800
night i thought i pushed this

3122
01:41:18,800 --> 01:41:20,719
oh well this will still work i'm gonna

3123
01:41:20,719 --> 01:41:21,920
have to go check that i thought i pushed

3124
01:41:21,920 --> 01:41:22,480
it so

3125
01:41:22,480 --> 01:41:24,080
it when you're putting your code here it

3126
01:41:24,080 --> 01:41:25,600
should actually be outside of this print

3127
01:41:25,600 --> 01:41:26,159
statement

3128
01:41:26,159 --> 01:41:27,600
i'll make sure to update the github repo

3129
01:41:27,600 --> 01:41:29,760
i thought i updated that last night

3130
01:41:29,760 --> 01:41:31,760
anyway it should still work so we need

3131
01:41:31,760 --> 01:41:34,000
to go to

3132
01:41:34,000 --> 01:41:38,000
run run configurations

3133
01:41:41,119 --> 01:41:42,639
run run configurations select

3134
01:41:42,639 --> 01:41:44,800
application okay run

3135
01:41:44,800 --> 01:41:46,239
run configurations you should see

3136
01:41:46,239 --> 01:41:49,199
something like this

3137
01:41:49,679 --> 01:41:52,560
and why are you not giving me a new

3138
01:41:52,560 --> 01:41:54,560
configuration

3139
01:41:54,560 --> 01:41:56,400
press the new configuration button oh

3140
01:41:56,400 --> 01:41:58,239
that is awesome

3141
01:41:58,239 --> 01:42:01,600
do we have an elf file releases yes we

3142
01:42:01,600 --> 01:42:03,600
have an elf file

3143
01:42:03,600 --> 01:42:15,760
why is this not working for me right now

3144
01:42:15,760 --> 01:42:17,199
okay yeah if you if this is the first

3145
01:42:17,199 --> 01:42:18,800
time you're using l476

3146
01:42:18,800 --> 01:42:21,280
um the only thing that helped was

3147
01:42:21,280 --> 01:42:21,840
connected

3148
01:42:21,840 --> 01:42:24,560
arduino program blinky yeah there's some

3149
01:42:24,560 --> 01:42:26,159
weird stuff that happens with that

3150
01:42:26,159 --> 01:42:27,199
debugger connection

3151
01:42:27,199 --> 01:42:30,400
so somebody's getting stuff yay

3152
01:42:30,400 --> 01:42:32,879
awesome

3153
01:42:33,600 --> 01:42:35,679
um and funny enough this this debug

3154
01:42:35,679 --> 01:42:37,440
connection thing is is not working for

3155
01:42:37,440 --> 01:42:40,320
me right now

3156
01:42:41,440 --> 01:42:42,880
i wonder if i open these projects will

3157
01:42:42,880 --> 01:42:45,360
give me something this is this is more

3158
01:42:45,360 --> 01:42:48,639
eclipse not doing what i want

3159
01:42:54,000 --> 01:42:55,760
i need to click on oh there we go i need

3160
01:42:55,760 --> 01:42:58,400
to click on the c plus plus application

3161
01:42:58,400 --> 01:43:00,000
in order to create a new configuration

3162
01:43:00,000 --> 01:43:03,679
of course why didn't i think of that

3163
01:43:04,000 --> 01:43:06,719
so we create a new configuration here it

3164
01:43:06,719 --> 01:43:07,040
should

3165
01:43:07,040 --> 01:43:09,199
point to the elf file we just compiled

3166
01:43:09,199 --> 01:43:10,480
which is what we're gonna send to the

3167
01:43:10,480 --> 01:43:11,199
board

3168
01:43:11,199 --> 01:43:13,199
um make sure it's release that should be

3169
01:43:13,199 --> 01:43:14,639
our configuration otherwise debugger

3170
01:43:14,639 --> 01:43:16,719
doesn't really work

3171
01:43:16,719 --> 01:43:18,560
and that should be it so we're gonna

3172
01:43:18,560 --> 01:43:21,040
click run

3173
01:43:22,400 --> 01:43:25,440
this should it should be it should have

3174
01:43:25,440 --> 01:43:27,760
been built

3175
01:43:27,760 --> 01:43:30,560
uh you shouldn't see compile errors with

3176
01:43:30,560 --> 01:43:31,679
this you'll see a bunch of

3177
01:43:31,679 --> 01:43:35,119
warnings um if you can post the compile

3178
01:43:35,119 --> 01:43:36,800
errors in the chat what you're seeing

3179
01:43:36,800 --> 01:43:38,000
that might help we can

3180
01:43:38,000 --> 01:43:40,639
probably help with some of this um

3181
01:43:40,639 --> 01:43:43,040
hopefully at this point you didn't

3182
01:43:43,040 --> 01:43:45,130
modify any code

3183
01:43:45,130 --> 01:43:47,600
[Laughter]

3184
01:43:47,600 --> 01:43:49,679
oh somebody got the audio buffer overrun

3185
01:43:49,679 --> 01:43:51,360
so that can happen if you didn't if

3186
01:43:51,360 --> 01:43:52,719
you're using a debug configuration

3187
01:43:52,719 --> 01:43:53,679
instead of release

3188
01:43:53,679 --> 01:43:55,280
um you'll probably see that if you've

3189
01:43:55,280 --> 01:43:57,520
tried to train um

3190
01:43:57,520 --> 01:43:59,199
if you try to classify more than two

3191
01:43:59,199 --> 01:44:01,199
models or sorry two two

3192
01:44:01,199 --> 01:44:04,000
keywords you'll probably see that um so

3193
01:44:04,000 --> 01:44:05,600
try maybe going back and training just

3194
01:44:05,600 --> 01:44:07,840
one

3195
01:44:08,239 --> 01:44:09,679
um yeah if you're running into problems

3196
01:44:09,679 --> 01:44:11,920
with this

3197
01:44:11,920 --> 01:44:14,960
before trying to build um if you go so

3198
01:44:14,960 --> 01:44:18,239
go back to this uh

3199
01:44:18,239 --> 01:44:19,760
my github repo here if you go into

3200
01:44:19,760 --> 01:44:21,520
embedded demos stm32q

3201
01:44:21,520 --> 01:44:24,000
ide the nucleo l476 this gives you the

3202
01:44:24,000 --> 01:44:27,199
exact steps you need to perform

3203
01:44:27,199 --> 01:44:28,639
yes yeah make sure you're not doing a

3204
01:44:28,639 --> 01:44:30,239
debug build that will definitely

3205
01:44:30,239 --> 01:44:31,280
it'll run but it will definitely

3206
01:44:31,280 --> 01:44:33,360
overflow your uh buffer

3207
01:44:33,360 --> 01:44:34,960
so once you've gotten this where it says

3208
01:44:34,960 --> 01:44:36,719
debugger connection lost shutting down

3209
01:44:36,719 --> 01:44:38,000
remember we did

3210
01:44:38,000 --> 01:44:41,199
release here we're not doing debug we're

3211
01:44:41,199 --> 01:44:43,600
specifically saying do not do uh

3212
01:44:43,600 --> 01:44:45,520
debugging for us so it's okay that it

3213
01:44:45,520 --> 01:44:46,639
does this you're not we're not doing

3214
01:44:46,639 --> 01:44:48,320
blinky we're not going to press

3215
01:44:48,320 --> 01:44:51,840
run here or anything like this um

3216
01:44:51,840 --> 01:44:53,600
so you cannot do more than two my

3217
01:44:53,600 --> 01:44:55,280
experience um this is what i

3218
01:44:55,280 --> 01:44:56,480
i think i mentioned earlier that when

3219
01:44:56,480 --> 01:44:58,480
you were picking keywords try three

3220
01:44:58,480 --> 01:45:00,000
i don't i can't promise they're gonna

3221
01:45:00,000 --> 01:45:02,400
work um because the model may become too

3222
01:45:02,400 --> 01:45:02,880
big

3223
01:45:02,880 --> 01:45:04,560
and it might take too long to process

3224
01:45:04,560 --> 01:45:06,159
that you start over over running your

3225
01:45:06,159 --> 01:45:06,800
buffer

3226
01:45:06,800 --> 01:45:08,880
um this is one of those cases like oh

3227
01:45:08,880 --> 01:45:10,239
you want to do three well you need a

3228
01:45:10,239 --> 01:45:11,840
bigger processor so that's why i stick

3229
01:45:11,840 --> 01:45:17,840
to one or two during this

3230
01:45:18,719 --> 01:45:21,040
um

3231
01:45:22,239 --> 01:45:26,239
so open up a serial connection

3232
01:45:26,239 --> 01:45:28,840
because windows i need to go to device

3233
01:45:28,840 --> 01:45:31,440
manager

3234
01:45:31,440 --> 01:45:34,400
com ports i'm on comm7 serial connect

3235
01:45:34,400 --> 01:45:35,679
with your serial

3236
01:45:35,679 --> 01:45:39,600
of choice use of 115 200

3237
01:45:39,600 --> 01:45:41,119
and you should see all of that being

3238
01:45:41,119 --> 01:45:43,040
being spit out um this is your

3239
01:45:43,040 --> 01:45:44,480
probability remember i mentioned earlier

3240
01:45:44,480 --> 01:45:46,239
you have the probabilities of each class

3241
01:45:46,239 --> 01:45:48,320
um noises noise your background noise

3242
01:45:48,320 --> 01:45:49,440
unknown as it doesn't know what you're

3243
01:45:49,440 --> 01:45:51,119
saying and then the two classes that you

3244
01:45:51,119 --> 01:45:51,760
picked

3245
01:45:51,760 --> 01:45:54,800
so i'm going to try saying house and

3246
01:45:54,800 --> 01:45:56,080
that should go up you saw that briefly

3247
01:45:56,080 --> 01:45:57,119
flash to like

3248
01:45:57,119 --> 01:46:00,320
98 percent zero

3249
01:46:00,320 --> 01:46:03,360
so you'll see that yes flashed here and

3250
01:46:03,360 --> 01:46:07,040
that's because of the demo code

3251
01:46:08,560 --> 01:46:11,199
that is because of the demo code that i

3252
01:46:11,199 --> 01:46:12,639
totally thought i checked into github

3253
01:46:12,639 --> 01:46:13,280
last night

3254
01:46:13,280 --> 01:46:16,320
and did not check in still works

3255
01:46:16,320 --> 01:46:18,480
um but what's going on here is if it

3256
01:46:18,480 --> 01:46:19,360
sees

3257
01:46:19,360 --> 01:46:21,360
classification label number three or

3258
01:46:21,360 --> 01:46:23,520
index three it's going to print this

3259
01:46:23,520 --> 01:46:26,000
which corresponds to whatever your thing

3260
01:46:26,000 --> 01:46:27,520
was and i'll show you how to find those

3261
01:46:27,520 --> 01:46:29,520
so if you go to model parameters

3262
01:46:29,520 --> 01:46:34,560
model metadata here is where your

3263
01:46:34,719 --> 01:46:36,960
here is where your uh classes are listed

3264
01:46:36,960 --> 01:46:38,880
in this order so noises 0

3265
01:46:38,880 --> 01:46:41,199
1 two and three so if i want to print

3266
01:46:41,199 --> 01:46:43,679
zero i need to do three

3267
01:46:43,679 --> 01:46:47,199
and actually in fact i recommend

3268
01:46:47,199 --> 01:46:51,679
pulling out this and going

3269
01:46:51,679 --> 01:46:54,320
above here because this only this where

3270
01:46:54,320 --> 01:46:55,600
it prints out the results only happens

3271
01:46:55,600 --> 01:46:57,280
once every four classifications every

3272
01:46:57,280 --> 01:46:57,679
second

3273
01:46:57,679 --> 01:47:01,440
we want it to do it faster so

3274
01:47:01,440 --> 01:47:05,600
what did i say three was i forget zero

3275
01:47:05,600 --> 01:47:09,840
so i'm actually going to change this to

3276
01:47:09,920 --> 01:47:13,440
zero this is your onboard led i'm going

3277
01:47:13,440 --> 01:47:16,080
to pull this out

3278
01:47:16,800 --> 01:47:18,960
and drop this right here so let's have

3279
01:47:18,960 --> 01:47:20,560
it flash the onboard led for house

3280
01:47:20,560 --> 01:47:22,560
that's zero one two

3281
01:47:22,560 --> 01:47:26,239
so i'm gonna change my index to two

3282
01:47:26,239 --> 01:47:28,400
so any time that value the output

3283
01:47:28,400 --> 01:47:30,159
probability is above point five which is

3284
01:47:30,159 --> 01:47:31,679
my threshold and i can i can adjust that

3285
01:47:31,679 --> 01:47:32,080
right

3286
01:47:32,080 --> 01:47:34,719
um i can make it eighty percent to be a

3287
01:47:34,719 --> 01:47:35,440
little higher

3288
01:47:35,440 --> 01:47:38,879
and then so every time it hears

3289
01:47:39,040 --> 01:47:44,000
house and so every time it hears zero

3290
01:47:44,000 --> 01:47:47,520
i'm gonna build project

3291
01:47:48,639 --> 01:47:50,000
so every time it hits zero then it

3292
01:47:50,000 --> 01:47:51,600
should print zero to the console every

3293
01:47:51,600 --> 01:47:53,280
time it hears house

3294
01:47:53,280 --> 01:47:55,600
it should then flash the onboard led so

3295
01:47:55,600 --> 01:47:57,360
everybody can give that a shot

3296
01:47:57,360 --> 01:48:00,639
um remember uh indexes zero and one

3297
01:48:00,639 --> 01:48:02,000
correspond to noise

3298
01:48:02,000 --> 01:48:04,080
and unknown so you really probably want

3299
01:48:04,080 --> 01:48:07,760
to play with indexes two and three

3300
01:48:08,159 --> 01:48:11,920
um and i'm going to project

3301
01:48:11,920 --> 01:48:14,560
run run that should upload it to my

3302
01:48:14,560 --> 01:48:16,880
board

3303
01:48:17,760 --> 01:48:19,440
serial body weight is one one five two

3304
01:48:19,440 --> 01:48:20,800
hundred um

3305
01:48:20,800 --> 01:48:22,239
i don't know if it matters i think

3306
01:48:22,239 --> 01:48:23,760
there's some autobot thing going on

3307
01:48:23,760 --> 01:48:24,400
there

3308
01:48:24,400 --> 01:48:25,679
uh but one one five two hundred should

3309
01:48:25,679 --> 01:48:27,520
work

3310
01:48:27,520 --> 01:48:29,119
um it's using that and that it's got

3311
01:48:29,119 --> 01:48:32,000
that embed um

3312
01:48:32,000 --> 01:48:33,840
it's got that embed programmer chip on

3313
01:48:33,840 --> 01:48:35,520
the nuclio board um which i

3314
01:48:35,520 --> 01:48:40,159
think auto bonds so but 11500 works

3315
01:48:40,159 --> 01:48:42,159
and i've absolutely lost my clock and

3316
01:48:42,159 --> 01:48:44,239
i've got eight minutes left

3317
01:48:44,239 --> 01:48:45,920
so this is the end i'm gonna bring up

3318
01:48:45,920 --> 01:48:47,520
this last side while oh here we go here

3319
01:48:47,520 --> 01:48:49,679
we go i can give this demo

3320
01:48:49,679 --> 01:48:52,639
all right here we go so we've gotta go

3321
01:48:52,639 --> 01:48:53,440
in here i'm gonna

3322
01:48:53,440 --> 01:48:56,719
say something

3323
01:48:56,719 --> 01:49:00,159
house you probably can't see it but here

3324
01:49:00,159 --> 01:49:00,480
we go

3325
01:49:00,480 --> 01:49:03,199
house see how it's lighting up the

3326
01:49:03,199 --> 01:49:05,920
little led right here whenever i say it

3327
01:49:05,920 --> 01:49:10,000
i'll make my screen bigger for that zero

3328
01:49:10,639 --> 01:49:15,280
zero there it goes zero

3329
01:49:15,280 --> 01:49:18,960
zero but doesn't like that one

3330
01:49:18,960 --> 01:49:22,000
zero ah there we go

3331
01:49:22,000 --> 01:49:23,679
so you can see those flying by i'm gonna

3332
01:49:23,679 --> 01:49:26,639
stop sharing for a second here

3333
01:49:26,639 --> 01:49:30,480
so that everyone can hopefully see me

3334
01:49:32,239 --> 01:49:36,638
and i can bring this up and house

3335
01:49:36,800 --> 01:49:40,480
zero which won't do anything house

3336
01:49:40,480 --> 01:49:44,000
yeah there we go so we got to blinky in

3337
01:49:44,000 --> 01:49:44,560
the most

3338
01:49:44,560 --> 01:49:47,599
roundabout hardest most obnoxious way

3339
01:49:47,599 --> 01:49:50,159
possible

3340
01:49:51,040 --> 01:49:52,480
let's share my screen again and i'm

3341
01:49:52,480 --> 01:49:53,760
going to come back to this final slide

3342
01:49:53,760 --> 01:49:55,199
where we have

3343
01:49:55,199 --> 01:49:57,679
seven minutes you're triggering mine

3344
01:49:57,679 --> 01:50:01,760
with zero fairly reliably

3345
01:50:01,760 --> 01:50:04,800
awesome uh

3346
01:50:04,800 --> 01:50:06,320
so people were asking about this sliding

3347
01:50:06,320 --> 01:50:07,760
window i skipped a bunch of these slides

3348
01:50:07,760 --> 01:50:08,719
because i thought we were like really

3349
01:50:08,719 --> 01:50:10,159
limited on time but yes that's

3350
01:50:10,159 --> 01:50:11,199
essentially what's going on is the

3351
01:50:11,199 --> 01:50:12,000
sliding window

3352
01:50:12,000 --> 01:50:13,599
and we're comparing the probabilities

3353
01:50:13,599 --> 01:50:15,199
here so this was just

3354
01:50:15,199 --> 01:50:16,480
what was going on with that sliding

3355
01:50:16,480 --> 01:50:18,080
window and i can burn through this real

3356
01:50:18,080 --> 01:50:18,960
quickly

3357
01:50:18,960 --> 01:50:21,119
boop boop right and then once it sees

3358
01:50:21,119 --> 01:50:22,000
that keyword

3359
01:50:22,000 --> 01:50:24,000
it compares that probability and we do

3360
01:50:24,000 --> 01:50:25,199
something with that

3361
01:50:25,199 --> 01:50:28,080
so we've already run it here is the end

3362
01:50:28,080 --> 01:50:28,960
slide

3363
01:50:28,960 --> 01:50:30,320
so i have like two minutes to go through

3364
01:50:30,320 --> 01:50:32,000
this feel free to modify that code and

3365
01:50:32,000 --> 01:50:32,800
play around with it if you're

3366
01:50:32,800 --> 01:50:34,719
comfortable with stm32 stuff i gave

3367
01:50:34,719 --> 01:50:36,159
you a couple of examples for like how do

3368
01:50:36,159 --> 01:50:38,960
you blink the onboard led um

3369
01:50:38,960 --> 01:50:40,719
this was this is what it should have

3370
01:50:40,719 --> 01:50:42,400
looked like um

3371
01:50:42,400 --> 01:50:44,719
i once again i thought i committed and

3372
01:50:44,719 --> 01:50:46,400
this is why i should always check my

3373
01:50:46,400 --> 01:50:48,080
repo to make sure i did commit those

3374
01:50:48,080 --> 01:50:48,880
changes

3375
01:50:48,880 --> 01:50:50,719
um some resources to play around with

3376
01:50:50,719 --> 01:50:52,800
here's the data sheet and the hal api if

3377
01:50:52,800 --> 01:50:54,400
you want to take a look at those

3378
01:50:54,400 --> 01:50:57,920
and um yeah there's the there's the

3379
01:50:57,920 --> 01:50:59,599
hangout bit i think that is on my

3380
01:50:59,599 --> 01:51:00,719
project link

3381
01:51:00,719 --> 01:51:03,199
as well as twitter handle linkedin if

3382
01:51:03,199 --> 01:51:04,400
you want to chat with me

3383
01:51:04,400 --> 01:51:07,760
um i do try to uh answer tweets

3384
01:51:07,760 --> 01:51:10,400
so that is all i have i'll leave this up

3385
01:51:10,400 --> 01:51:10,800
for a

3386
01:51:10,800 --> 01:51:12,639
bit are there any questions do you

3387
01:51:12,639 --> 01:51:14,719
recommend any more powerful boards for

3388
01:51:14,719 --> 01:51:17,679
edge inference um honestly i it depends

3389
01:51:17,679 --> 01:51:19,040
on your application because that's

3390
01:51:19,040 --> 01:51:21,440
always the answer right um for audio i

3391
01:51:21,440 --> 01:51:22,800
wouldn't do anything less than like

3392
01:51:22,800 --> 01:51:24,800
these uh arm cortex m4s

3393
01:51:24,800 --> 01:51:26,400
um which i think is what we've had what

3394
01:51:26,400 --> 01:51:28,239
we've got these are m4s or m4 pluses i

3395
01:51:28,239 --> 01:51:28,800
don't remember

3396
01:51:28,800 --> 01:51:30,800
but m4 i wouldn't go anything less than

3397
01:51:30,800 --> 01:51:32,400
like an m4

3398
01:51:32,400 --> 01:51:34,800
um when you start getting into uh like

3399
01:51:34,800 --> 01:51:36,400
more hardcore audio processing

3400
01:51:36,400 --> 01:51:38,480
video or video processing or image

3401
01:51:38,480 --> 01:51:40,560
processing i'd move up to like the uh

3402
01:51:40,560 --> 01:51:42,159
what are they the m7s

3403
01:51:42,159 --> 01:51:43,840
i'd go a little more powerful so these

3404
01:51:43,840 --> 01:51:45,280
are running at like

3405
01:51:45,280 --> 01:51:48,239
80-ish megahertz if i remember something

3406
01:51:48,239 --> 01:51:49,920
that like 80 100 megahertz so that's

3407
01:51:49,920 --> 01:51:51,199
kind of where you start with audio

3408
01:51:51,199 --> 01:51:53,119
you can do less for that so i've gotten

3409
01:51:53,119 --> 01:51:55,119
stuff you can do like some really basic

3410
01:51:55,119 --> 01:51:56,320
anomaly detection

3411
01:51:56,320 --> 01:51:59,360
in things like um like m0s like

3412
01:51:59,360 --> 01:52:01,040
really really basic for like like

3413
01:52:01,040 --> 01:52:02,880
accelerometer like you don't read a ton

3414
01:52:02,880 --> 01:52:05,360
you do like basic fourier transform if

3415
01:52:05,360 --> 01:52:06,639
you're not need to be really fast you

3416
01:52:06,639 --> 01:52:09,920
can get it done with like an m0

3417
01:52:10,400 --> 01:52:12,000
i think you did push it i pulled it from

3418
01:52:12,000 --> 01:52:13,199
github and got it that way maybe i

3419
01:52:13,199 --> 01:52:14,239
opened the wrong one

3420
01:52:14,239 --> 01:52:16,320
when i downloaded it so okay i'm glad

3421
01:52:16,320 --> 01:52:17,920
that worked for people

3422
01:52:17,920 --> 01:52:19,440
okay good i did and so that must have

3423
01:52:19,440 --> 01:52:20,719
been i pulled the wrong one for my

3424
01:52:20,719 --> 01:52:22,239
download and didn't clear my downloads

3425
01:52:22,239 --> 01:52:23,360
last night

3426
01:52:23,360 --> 01:52:25,360
uh would the teens what would the teensy

3427
01:52:25,360 --> 01:52:26,400
four be able to do

3428
01:52:26,400 --> 01:52:27,920
i forget the specs on that but if i

3429
01:52:27,920 --> 01:52:29,440
remember that thing is a beast

3430
01:52:29,440 --> 01:52:31,520
it was like 400 megahertz or something

3431
01:52:31,520 --> 01:52:32,719
um you probably started doing video

3432
01:52:32,719 --> 01:52:33,440
stuff on that

3433
01:52:33,440 --> 01:52:34,800
very very basic kind of like the uh

3434
01:52:34,800 --> 01:52:37,280
check out the openmv um

3435
01:52:37,280 --> 01:52:38,800
uh tensorflow lite they've got

3436
01:52:38,800 --> 01:52:40,560
tensorflow lite running on the openmv

3437
01:52:40,560 --> 01:52:42,840
with like um

3438
01:52:42,840 --> 01:52:45,920
micropython will you add arduino side on

3439
01:52:45,920 --> 01:52:46,480
the github

3440
01:52:46,480 --> 01:52:49,119
yes i'm i'm that is that is like the

3441
01:52:49,119 --> 01:52:51,040
next plan once i get um it's going to be

3442
01:52:51,040 --> 01:52:52,159
the arduino

3443
01:52:52,159 --> 01:52:54,239
uh sense the ble sense but honestly if

3444
01:52:54,239 --> 01:52:55,760
you if you like download the like

3445
01:52:55,760 --> 01:52:57,520
arduino package for the ble sense from

3446
01:52:57,520 --> 01:52:59,280
like everything we did up until that

3447
01:52:59,280 --> 01:53:00,239
point where we clicked the c

3448
01:53:00,239 --> 01:53:02,239
plus plus if you just click the arduino

3449
01:53:02,239 --> 01:53:04,239
one and then go read how you import that

3450
01:53:04,239 --> 01:53:07,280
into your um arduino that will totally

3451
01:53:07,280 --> 01:53:08,159
work

3452
01:53:08,159 --> 01:53:10,560
for everything we just did um go read

3453
01:53:10,560 --> 01:53:12,560
how it works for edge impulse to import

3454
01:53:12,560 --> 01:53:12,960
a

3455
01:53:12,960 --> 01:53:15,199
uh arduino library so it everything we

3456
01:53:15,199 --> 01:53:17,040
did applies to arduino but yeah i should

3457
01:53:17,040 --> 01:53:18,560
hopefully include that

3458
01:53:18,560 --> 01:53:20,719
i managed to get tf light running on the

3459
01:53:20,719 --> 01:53:21,760
oh that's awesome

3460
01:53:21,760 --> 01:53:23,280
yeah the team i haven't played with it i

3461
01:53:23,280 --> 01:53:24,560
think i've got a team c4 but that thing

3462
01:53:24,560 --> 01:53:26,880
is blazingly fast

3463
01:53:26,880 --> 01:53:28,719
what if i don't have sm32 this should

3464
01:53:28,719 --> 01:53:30,960
still work like this supports most arm

3465
01:53:30,960 --> 01:53:32,480
the c plus plus libraries is supported

3466
01:53:32,480 --> 01:53:34,560
on most arm processors

3467
01:53:34,560 --> 01:53:36,000
it's just a question of like how well do

3468
01:53:36,000 --> 01:53:37,520
you know the the whole tool chain in the

3469
01:53:37,520 --> 01:53:38,960
build process like i happen to know

3470
01:53:38,960 --> 01:53:41,520
stm32 decently well which is why i chose

3471
01:53:41,520 --> 01:53:43,280
it that or arduino

3472
01:53:43,280 --> 01:53:46,159
uh run configuration was debug yeah

3473
01:53:46,159 --> 01:53:47,520
sometimes that messes up which is why i

3474
01:53:47,520 --> 01:53:49,040
always check that so yeah make sure it's

3475
01:53:49,040 --> 01:53:51,440
release

3476
01:53:52,400 --> 01:53:55,840
yay people are getting it to work 600

3477
01:53:55,840 --> 01:53:59,199
megahertz for the teensy

3478
01:54:02,800 --> 01:54:05,760
that's awesome can we use uh yes once

3479
01:54:05,760 --> 01:54:06,400
again the c

3480
01:54:06,400 --> 01:54:09,119
c c plus plus library should compile it

3481
01:54:09,119 --> 01:54:10,560
doesn't so

3482
01:54:10,560 --> 01:54:13,360
it's not it's that um i can't remember

3483
01:54:13,360 --> 01:54:15,040
the name of the processor inside of the

3484
01:54:15,040 --> 01:54:16,800
uh the esp32

3485
01:54:16,800 --> 01:54:19,760
um but it's not an arm um the cc plus

3486
01:54:19,760 --> 01:54:21,199
library should work

3487
01:54:21,199 --> 01:54:22,639
um however note that when you download

3488
01:54:22,639 --> 01:54:24,880
it from edge impulse it enables some of

3489
01:54:24,880 --> 01:54:25,199
the

3490
01:54:25,199 --> 01:54:28,080
arm specific cmsis stuff for doing dsp

3491
01:54:28,080 --> 01:54:29,599
the extensor thank you 10 silica that's

3492
01:54:29,599 --> 01:54:31,360
the one couldn't remember that name

3493
01:54:31,360 --> 01:54:34,400
um it's enabling the uh arm cm system

3494
01:54:34,400 --> 01:54:36,080
for dsp to allow those to go faster and

3495
01:54:36,080 --> 01:54:38,000
it's using the built-in hardware for dsp

3496
01:54:38,000 --> 01:54:39,520
functions so if you as long as those are

3497
01:54:39,520 --> 01:54:40,960
disabled that cc

3498
01:54:40,960 --> 01:54:42,880
plus library you download from ng pulse

3499
01:54:42,880 --> 01:54:44,480
should run on any it should compile for

3500
01:54:44,480 --> 01:54:45,440
any microcontroller

3501
01:54:45,440 --> 01:54:47,040
it's just a question of is it going to

3502
01:54:47,040 --> 01:54:48,840
be fast enough without those hardware

3503
01:54:48,840 --> 01:54:51,840
accelerators

3504
01:54:54,239 --> 01:54:57,440
uh briefest explanation of how to

3505
01:54:57,440 --> 01:54:59,920
retrain the model for better accuracy so

3506
01:54:59,920 --> 01:55:01,599
um in edge impulse all you

3507
01:55:01,599 --> 01:55:04,320
need to do go back to assuming you've

3508
01:55:04,320 --> 01:55:05,679
assuming you have the data you don't

3509
01:55:05,679 --> 01:55:07,119
want to add more data

3510
01:55:07,119 --> 01:55:10,239
um which you want to go back to uh

3511
01:55:10,239 --> 01:55:11,599
assuming you have the data you don't

3512
01:55:11,599 --> 01:55:13,199
need to add more data um and you've got

3513
01:55:13,199 --> 01:55:14,639
all the features extraction just go back

3514
01:55:14,639 --> 01:55:16,560
to your neural network classifier

3515
01:55:16,560 --> 01:55:17,920
um and just start playing with these

3516
01:55:17,920 --> 01:55:20,239
parameters um so once again how do you

3517
01:55:20,239 --> 01:55:21,520
get better accuracy

3518
01:55:21,520 --> 01:55:23,360
uh you just play with stuff you tweak

3519
01:55:23,360 --> 01:55:25,040
stuff you read a bunch of documents and

3520
01:55:25,040 --> 01:55:25,920
say like oh

3521
01:55:25,920 --> 01:55:27,040
i kind of have an understanding that

3522
01:55:27,040 --> 01:55:29,119
maybe i need less neurons here but more

3523
01:55:29,119 --> 01:55:29,920
layers

3524
01:55:29,920 --> 01:55:31,599
sometimes that works better so really

3525
01:55:31,599 --> 01:55:32,880
it's just starting to play with some of

3526
01:55:32,880 --> 01:55:33,199
these

3527
01:55:33,199 --> 01:55:34,480
maybe try a two-dimensional

3528
01:55:34,480 --> 01:55:36,480
convolutional neural network

3529
01:55:36,480 --> 01:55:38,239
and by the way before i forget if you're

3530
01:55:38,239 --> 01:55:40,159
familiar with keras you can click this

3531
01:55:40,159 --> 01:55:42,480
and you can go to the keras mode so you

3532
01:55:42,480 --> 01:55:43,840
can look at how they're building this

3533
01:55:43,840 --> 01:55:45,280
model programmatically

3534
01:55:45,280 --> 01:55:47,520
um they i don't believe they give you

3535
01:55:47,520 --> 01:55:49,440
ways to

3536
01:55:49,440 --> 01:55:52,400
oh you can use you can select the like

3537
01:55:52,400 --> 01:55:53,360
uh

3538
01:55:53,360 --> 01:55:55,119
learning rate loss functions and all of

3539
01:55:55,119 --> 01:55:57,040
that here okay so yeah you can if you

3540
01:55:57,040 --> 01:55:58,639
know keras you can adjust all of this

3541
01:55:58,639 --> 01:56:01,840
programmatically here

3542
01:56:02,800 --> 01:56:04,480
um but yeah feel free to and then once

3543
01:56:04,480 --> 01:56:05,760
you've like changed this just click

3544
01:56:05,760 --> 01:56:06,960
start training again it'll just train

3545
01:56:06,960 --> 01:56:08,719
the model and give you an output so just

3546
01:56:08,719 --> 01:56:10,000
you know write down what your accuracy

3547
01:56:10,000 --> 01:56:12,239
was and then um keep in mind if you

3548
01:56:12,239 --> 01:56:13,920
start using the model testing or the

3549
01:56:13,920 --> 01:56:15,360
model testing your test data

3550
01:56:15,360 --> 01:56:18,960
to update your um to like look at and be

3551
01:56:18,960 --> 01:56:20,480
like oh and overfit and come back you

3552
01:56:20,480 --> 01:56:22,719
start introducing bias into your data so

3553
01:56:22,719 --> 01:56:24,159
there's there's like papers out there

3554
01:56:24,159 --> 01:56:25,040
like how do you

3555
01:56:25,040 --> 01:56:27,920
um prevent that but it's that's a good

3556
01:56:27,920 --> 01:56:29,280
way to start like go to your model

3557
01:56:29,280 --> 01:56:31,040
testing use the unseen data

3558
01:56:31,040 --> 01:56:32,800
make sure it's working decently well

3559
01:56:32,800 --> 01:56:35,040
come back and do your uh

3560
01:56:35,040 --> 01:56:36,480
update your parameters just know that

3561
01:56:36,480 --> 01:56:38,080
you're introducing bias into your model

3562
01:56:38,080 --> 01:56:40,560
every time you're doing that

3563
01:56:40,560 --> 01:56:42,880
reduce training cycles from 100 to 30

3564
01:56:42,880 --> 01:56:44,719
decreased from 50.

3565
01:56:44,719 --> 01:56:46,159
sometimes it made it better for me and

3566
01:56:46,159 --> 01:56:48,239
sometimes it makes it worse

3567
01:56:48,239 --> 01:56:49,679
like i wish i knew exactly what was

3568
01:56:49,679 --> 01:56:52,480
going on in the neural networks for that

3569
01:56:52,480 --> 01:56:53,920
awesome yeah go have fun play around

3570
01:56:53,920 --> 01:56:55,360
with it i hope this has given you

3571
01:56:55,360 --> 01:56:56,239
everybody um

3572
01:56:56,239 --> 01:56:57,840
a start for this kind of stuff it's a

3573
01:56:57,840 --> 01:56:59,599
lot to take in if you really want to get

3574
01:56:59,599 --> 01:57:00,880
down to the nitty-gritty and do some

3575
01:57:00,880 --> 01:57:01,440
math um

3576
01:57:01,440 --> 01:57:03,920
andrew aang's course highly recommend on

3577
01:57:03,920 --> 01:57:05,360
coursera that's what i started with and

3578
01:57:05,360 --> 01:57:06,560
then there's like a bunch of books out

3579
01:57:06,560 --> 01:57:08,080
there that you can start going through

3580
01:57:08,080 --> 01:57:10,560
um and then the the i would make sure

3581
01:57:10,560 --> 01:57:11,119
you do that

3582
01:57:11,119 --> 01:57:13,360
i would learn keras um once you're

3583
01:57:13,360 --> 01:57:14,639
familiar with that and then once you're

3584
01:57:14,639 --> 01:57:15,920
kind of comfortable training your own

3585
01:57:15,920 --> 01:57:17,280
networks and like you know building them

3586
01:57:17,280 --> 01:57:18,159
or at least pulling them off the

3587
01:57:18,159 --> 01:57:19,360
internet and tweaking them

3588
01:57:19,360 --> 01:57:22,400
then i would jump into like um uh pete

3589
01:57:22,400 --> 01:57:25,119
warden and daniel tanayaki's tiny ml

3590
01:57:25,119 --> 01:57:27,199
book because that jumps into how to use

3591
01:57:27,199 --> 01:57:29,920
um uh the tensorflow lite library

3592
01:57:29,920 --> 01:57:31,360
directly on a microcontroller

3593
01:57:31,360 --> 01:57:33,520
and edge impulses basically take that

3594
01:57:33,520 --> 01:57:35,280
and wrapped it up into a library for us

3595
01:57:35,280 --> 01:57:36,800
that like works off the shelf which is

3596
01:57:36,800 --> 01:57:38,080
why i chose that for this where we only

3597
01:57:38,080 --> 01:57:40,400
had two hours

3598
01:57:40,400 --> 01:57:42,960
uh well uh sorry i don't mean to

3599
01:57:42,960 --> 01:57:44,000
interrupt but

3600
01:57:44,000 --> 01:57:47,040
sean uh thank you for sharing with us uh

3601
01:57:47,040 --> 01:57:48,239
this really enlightening

3602
01:57:48,239 --> 01:57:51,599
and helpful presentation uh

3603
01:57:51,599 --> 01:57:54,159
it was very technical but uh you

3604
01:57:54,159 --> 01:57:55,119
presented a

3605
01:57:55,119 --> 01:57:58,400
pretty uncomplicated way so uh

3606
01:57:58,400 --> 01:58:00,800
and it was also very entertaining and uh

3607
01:58:00,800 --> 01:58:02,000
thank you for making it

3608
01:58:02,000 --> 01:58:05,360
a very down to earth and personable

3609
01:58:05,360 --> 01:58:08,800
talk so i'd like to invite everyone to

3610
01:58:08,800 --> 01:58:11,599
continue with the conversation for

3611
01:58:11,599 --> 01:58:12,880
comments and questions

3612
01:58:12,880 --> 01:58:17,360
at your hackaday.io page

3613
01:58:17,360 --> 01:58:20,560
you can go use the public chat for more

3614
01:58:20,560 --> 01:58:22,480
talks

3615
01:58:22,480 --> 01:58:25,679
and i posted the link in the

3616
01:58:25,679 --> 01:58:28,560
conversation or in the chat sidebar and

3617
01:58:28,560 --> 01:58:29,679
with that

3618
01:58:29,679 --> 01:58:31,840
thank all of you for being a part of

3619
01:58:31,840 --> 01:58:34,400
this amazing community and

3620
01:58:34,400 --> 01:58:37,040
uh joining us for emoticon so i look

3621
01:58:37,040 --> 01:58:38,400
forward to seeing

3622
01:58:38,400 --> 01:58:42,239
uh more of you at other talks and

3623
01:58:42,239 --> 01:58:44,800
uh yeah so appreciate it thank you again

3624
01:58:44,800 --> 01:58:45,520
sean

3625
01:58:45,520 --> 01:58:49,840
thank you thanks everybody

