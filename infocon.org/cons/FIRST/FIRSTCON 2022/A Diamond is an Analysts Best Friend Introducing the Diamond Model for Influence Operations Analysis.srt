1
00:00:05,870 --> 00:00:08,929
[Music]

2
00:00:09,440 --> 00:00:11,280
hello everyone

3
00:00:11,280 --> 00:00:13,280
thank you to be here today

4
00:00:13,280 --> 00:00:14,240
and

5
00:00:14,240 --> 00:00:15,920
i want to remember you that the current

6
00:00:15,920 --> 00:00:18,720
session will be tlp wide

7
00:00:18,720 --> 00:00:21,119
and to present the session named uh

8
00:00:21,119 --> 00:00:23,039
diamond is analysis best brand

9
00:00:23,039 --> 00:00:24,960
introducing the diamond model for

10
00:00:24,960 --> 00:00:27,039
influence operation analysis

11
00:00:27,039 --> 00:00:28,880
let me to introduce charity write from

12
00:00:28,880 --> 00:00:32,159
record the future thank you

13
00:00:32,159 --> 00:00:34,959
thank you so much

14
00:00:37,120 --> 00:00:39,120
can you hear me okay

15
00:00:39,120 --> 00:00:41,120
all right

16
00:00:41,120 --> 00:00:42,879
i want to start with a quote that i

17
00:00:42,879 --> 00:00:46,160
really like from dr ajit ma'an

18
00:00:46,160 --> 00:00:48,800
she wrote a book on narrative warfare

19
00:00:48,800 --> 00:00:51,440
and she says battles are one with

20
00:00:51,440 --> 00:00:55,360
kinetics but wars are one with influence

21
00:00:55,360 --> 00:00:57,280
and today we're going to talk about very

22
00:00:57,280 --> 00:01:00,000
complex issue of disinformation

23
00:01:00,000 --> 00:01:01,920
but i want to simplify the way we

24
00:01:01,920 --> 00:01:03,680
analyze it

25
00:01:03,680 --> 00:01:05,280
so first of all my name is charity

26
00:01:05,280 --> 00:01:06,240
wright

27
00:01:06,240 --> 00:01:08,000
i'm a threat intelligence analyst at

28
00:01:08,000 --> 00:01:09,920
recorded future

29
00:01:09,920 --> 00:01:12,799
in the past i worked at u.s army and

30
00:01:12,799 --> 00:01:14,880
national security agency

31
00:01:14,880 --> 00:01:17,280
i'm from dallas texas by the way so

32
00:01:17,280 --> 00:01:19,680
sorry if i don't have enough of a texas

33
00:01:19,680 --> 00:01:21,840
accent for you all but i'll throw in a

34
00:01:21,840 --> 00:01:24,320
y'all once in a while

35
00:01:24,320 --> 00:01:27,439
i currently analyze influence operations

36
00:01:27,439 --> 00:01:30,000
geopolitical intelligence and strategic

37
00:01:30,000 --> 00:01:32,880
intelligence for recorded future

38
00:01:32,880 --> 00:01:35,040
so let's jump in

39
00:01:35,040 --> 00:01:37,600
like i said disinformation is very

40
00:01:37,600 --> 00:01:41,200
complex but in my opinion analyzing it

41
00:01:41,200 --> 00:01:42,640
should not be

42
00:01:42,640 --> 00:01:43,840
so today i'm going to tell you about the

43
00:01:43,840 --> 00:01:46,560
diamond model for influence operations

44
00:01:46,560 --> 00:01:49,360
and why we use this particular framework

45
00:01:49,360 --> 00:01:51,840
and how to use it every day while you

46
00:01:51,840 --> 00:01:55,520
are also analyzing complex psychosocial

47
00:01:55,520 --> 00:01:57,200
threats

48
00:01:57,200 --> 00:01:58,640
so brief

49
00:01:58,640 --> 00:01:59,680
oh

50
00:01:59,680 --> 00:02:03,360
slides yeah sides are important right

51
00:02:03,360 --> 00:02:04,479
there we go

52
00:02:04,479 --> 00:02:06,320
that's me

53
00:02:06,320 --> 00:02:08,000
there's me on twitter if you want to

54
00:02:08,000 --> 00:02:10,720
connect with me there i do a lot of

55
00:02:10,720 --> 00:02:13,200
amplifying of the work that we're doing

56
00:02:13,200 --> 00:02:15,200
and also just keeping everybody up to

57
00:02:15,200 --> 00:02:16,480
date on

58
00:02:16,480 --> 00:02:19,599
disinformation intelligence

59
00:02:19,599 --> 00:02:21,440
so this is the agenda for today i'm

60
00:02:21,440 --> 00:02:22,800
going to try to go through it rather

61
00:02:22,800 --> 00:02:27,120
quickly we have a limited amount of time

62
00:02:28,080 --> 00:02:29,920
and first i want to start off by

63
00:02:29,920 --> 00:02:32,640
clarifying some terminology now in this

64
00:02:32,640 --> 00:02:34,840
industry as we explore

65
00:02:34,840 --> 00:02:37,040
disinformation campaigns sometimes that

66
00:02:37,040 --> 00:02:39,920
word is used synonymously so i want to

67
00:02:39,920 --> 00:02:43,840
clarify that misinformation mis

68
00:02:43,840 --> 00:02:45,920
is false information

69
00:02:45,920 --> 00:02:48,160
that is spread regardless of whether

70
00:02:48,160 --> 00:02:51,200
there is intent to mislead

71
00:02:51,200 --> 00:02:53,920
as opposed to disinformation which is

72
00:02:53,920 --> 00:02:56,720
deliberately misleading or biased

73
00:02:56,720 --> 00:02:59,680
information manipulated narrative or

74
00:02:59,680 --> 00:03:02,000
facts and propaganda

75
00:03:02,000 --> 00:03:03,760
now the the clarification there is

76
00:03:03,760 --> 00:03:05,840
disinformation is usually done with a

77
00:03:05,840 --> 00:03:08,319
malicious purpose

78
00:03:08,319 --> 00:03:10,400
and then we all know about fake news

79
00:03:10,400 --> 00:03:12,560
unfortunately throughout covet and

80
00:03:12,560 --> 00:03:14,080
various political issues that we're

81
00:03:14,080 --> 00:03:16,239
dealing with today uh we deal with

82
00:03:16,239 --> 00:03:18,720
purposefully crafted sensational

83
00:03:18,720 --> 00:03:21,200
emotionally charged misleading or

84
00:03:21,200 --> 00:03:23,840
totally fabricated information that

85
00:03:23,840 --> 00:03:28,400
mimics the form of mainstream news

86
00:03:30,319 --> 00:03:33,519
now on that note

87
00:03:33,519 --> 00:03:35,840
it can be pretty frustrating to see fake

88
00:03:35,840 --> 00:03:38,400
news spread on social media and it's

89
00:03:38,400 --> 00:03:40,560
even more frustrating to try to change

90
00:03:40,560 --> 00:03:42,959
people's minds once they see that fake

91
00:03:42,959 --> 00:03:45,440
news and the reason is

92
00:03:45,440 --> 00:03:48,159
studies prove that people believe what

93
00:03:48,159 --> 00:03:50,239
they see the most often

94
00:03:50,239 --> 00:03:52,799
and what they see first

95
00:03:52,799 --> 00:03:54,959
so in order to break that cycle and

96
00:03:54,959 --> 00:03:58,000
disrupt malign influencers we must

97
00:03:58,000 --> 00:04:01,840
understand how they work

98
00:04:02,159 --> 00:04:04,959
so what is influence operations

99
00:04:04,959 --> 00:04:07,840
this is basically an umbrella term for

100
00:04:07,840 --> 00:04:09,760
many different types of information

101
00:04:09,760 --> 00:04:10,879
warfare

102
00:04:10,879 --> 00:04:13,040
so we're talking about disinformation

103
00:04:13,040 --> 00:04:14,480
propaganda

104
00:04:14,480 --> 00:04:17,358
mass manipulation etc

105
00:04:17,358 --> 00:04:19,680
influence operations is an organized

106
00:04:19,680 --> 00:04:22,720
attempt to achieve a specific effect

107
00:04:22,720 --> 00:04:24,800
among a target audience

108
00:04:24,800 --> 00:04:27,280
so keep that in mind we're talking about

109
00:04:27,280 --> 00:04:29,919
influencers and audiences that will play

110
00:04:29,919 --> 00:04:32,000
into our diamond model

111
00:04:32,000 --> 00:04:34,639
and influence operations attempts to

112
00:04:34,639 --> 00:04:37,600
affect the decision-making beliefs and

113
00:04:37,600 --> 00:04:41,960
opinions of a target audience

114
00:04:43,040 --> 00:04:45,120
now before we dig into the diamond model

115
00:04:45,120 --> 00:04:47,040
i want to kind of go over

116
00:04:47,040 --> 00:04:48,639
some of the ways that we've been doing

117
00:04:48,639 --> 00:04:51,680
it in the years past and basically how i

118
00:04:51,680 --> 00:04:52,800
looked through these things and

119
00:04:52,800 --> 00:04:55,360
determined we need something better

120
00:04:55,360 --> 00:04:57,520
malign influence operations are one of

121
00:04:57,520 --> 00:04:59,919
the top threats we face today these

122
00:04:59,919 --> 00:05:02,880
operations can start wars can disrupt

123
00:05:02,880 --> 00:05:04,160
democracies

124
00:05:04,160 --> 00:05:08,000
create and inflame extremism and destroy

125
00:05:08,000 --> 00:05:10,800
companies actually so we've been working

126
00:05:10,800 --> 00:05:12,880
hard on identifying collecting and

127
00:05:12,880 --> 00:05:15,280
analyzing foreign and domestic influence

128
00:05:15,280 --> 00:05:18,000
campaigns that pose a threat to various

129
00:05:18,000 --> 00:05:20,320
organizations around the world both

130
00:05:20,320 --> 00:05:23,039
private sector and public

131
00:05:23,039 --> 00:05:24,560
and as we've been developing our

132
00:05:24,560 --> 00:05:26,320
tradecraft around analyzing these

133
00:05:26,320 --> 00:05:27,600
campaigns

134
00:05:27,600 --> 00:05:29,280
we have found that the existing

135
00:05:29,280 --> 00:05:32,240
frameworks are lacking in several areas

136
00:05:32,240 --> 00:05:34,320
and in order to remedy this we've

137
00:05:34,320 --> 00:05:36,240
developed a diamond model for influence

138
00:05:36,240 --> 00:05:39,520
campaign analysis now previously as you

139
00:05:39,520 --> 00:05:42,160
see on the side here only three parts of

140
00:05:42,160 --> 00:05:43,919
an influence campaign were being

141
00:05:43,919 --> 00:05:47,039
analyzed there was the content which is

142
00:05:47,039 --> 00:05:50,000
the media that's being produced

143
00:05:50,000 --> 00:05:52,080
there was also the voice which is the

144
00:05:52,080 --> 00:05:54,400
accounts that are involved the tone that

145
00:05:54,400 --> 00:05:57,280
they use the language and the wording

146
00:05:57,280 --> 00:06:00,800
and even the narrative which is a story

147
00:06:00,800 --> 00:06:03,199
and then third there's dissemination

148
00:06:03,199 --> 00:06:05,199
and that's the technical ways in which

149
00:06:05,199 --> 00:06:07,360
the information is spread across

150
00:06:07,360 --> 00:06:09,199
platforms and media

151
00:06:09,199 --> 00:06:12,000
now this is all a great starting point

152
00:06:12,000 --> 00:06:14,080
as i mentioned is very complex when you

153
00:06:14,080 --> 00:06:16,080
start digging in social media it's just

154
00:06:16,080 --> 00:06:18,479
a mess so this was a great starting

155
00:06:18,479 --> 00:06:20,800
point but we find this to be too

156
00:06:20,800 --> 00:06:22,000
simplistic

157
00:06:22,000 --> 00:06:24,560
and it doesn't address the relationships

158
00:06:24,560 --> 00:06:27,520
between the narratives the threat actors

159
00:06:27,520 --> 00:06:30,919
and the infrastructure

160
00:06:34,639 --> 00:06:37,520
okay we'll start here

161
00:06:38,160 --> 00:06:41,039
some existing frameworks correlate to

162
00:06:41,039 --> 00:06:43,280
attack chains that we're probably

163
00:06:43,280 --> 00:06:46,319
familiar with from cyber intrusions

164
00:06:46,319 --> 00:06:48,560
now on the left side is a very simple

165
00:06:48,560 --> 00:06:50,800
attack chain model

166
00:06:50,800 --> 00:06:52,960
this one explains the process which

167
00:06:52,960 --> 00:06:54,880
threat actors conduct

168
00:06:54,880 --> 00:06:56,800
information warfare

169
00:06:56,800 --> 00:06:58,639
the disinformation kill chain on the

170
00:06:58,639 --> 00:07:01,440
right is created by mitre which many of

171
00:07:01,440 --> 00:07:03,280
you are probably familiar with

172
00:07:03,280 --> 00:07:06,000
and it also follows the process which

173
00:07:06,000 --> 00:07:08,639
the threat actors take also starting

174
00:07:08,639 --> 00:07:10,639
with a recon phase

175
00:07:10,639 --> 00:07:12,479
now this is really important as we know

176
00:07:12,479 --> 00:07:14,319
with kill chain models

177
00:07:14,319 --> 00:07:16,000
it helps us identify certain

178
00:07:16,000 --> 00:07:19,360
vulnerabilities in our own systems in

179
00:07:19,360 --> 00:07:22,080
our own processes so we can disrupt the

180
00:07:22,080 --> 00:07:24,800
adversary at certain phases

181
00:07:24,800 --> 00:07:27,280
now while these kill chains help us

182
00:07:27,280 --> 00:07:30,080
understand the threat actors process and

183
00:07:30,080 --> 00:07:32,400
can help us identify

184
00:07:32,400 --> 00:07:34,000
areas of vulnerabilities that need to be

185
00:07:34,000 --> 00:07:37,120
remediated it lacks the nuance that we

186
00:07:37,120 --> 00:07:40,319
need to address the psychosocial and

187
00:07:40,319 --> 00:07:43,680
geopolitical aspects of influence and

188
00:07:43,680 --> 00:07:47,120
information operations

189
00:07:49,520 --> 00:07:51,759
this might look familiar if it looks

190
00:07:51,759 --> 00:07:54,479
like the miter framework or miter ttps

191
00:07:54,479 --> 00:07:56,639
you're you're right about that this is a

192
00:07:56,639 --> 00:07:59,280
screenshot of the omit framework it's

193
00:07:59,280 --> 00:08:00,199
spelled

194
00:08:00,199 --> 00:08:02,000
a-m-i-t-t

195
00:08:02,000 --> 00:08:04,879
emit is similar to the mitre framework

196
00:08:04,879 --> 00:08:08,479
because it breaks out very specific ttps

197
00:08:08,479 --> 00:08:12,080
used in i o campaigns as well as counter

198
00:08:12,080 --> 00:08:13,599
measures

199
00:08:13,599 --> 00:08:16,000
now these are just two samples of the

200
00:08:16,000 --> 00:08:18,639
full list which can be found on their

201
00:08:18,639 --> 00:08:20,720
github page actually

202
00:08:20,720 --> 00:08:23,440
and it's very very helpful

203
00:08:23,440 --> 00:08:26,160
for you to identify the exact tactics

204
00:08:26,160 --> 00:08:28,080
techniques and procedures that the

205
00:08:28,080 --> 00:08:31,520
influencer is using

206
00:08:31,680 --> 00:08:34,559
now as we explored the full list i had

207
00:08:34,559 --> 00:08:36,719
two thoughts one

208
00:08:36,719 --> 00:08:38,559
breaking out specific tactics and

209
00:08:38,559 --> 00:08:41,599
methods is helpful especially to layer

210
00:08:41,599 --> 00:08:44,000
on top of kill chain or diamond model

211
00:08:44,000 --> 00:08:45,600
frameworks

212
00:08:45,600 --> 00:08:48,000
this model does address ttps in ways

213
00:08:48,000 --> 00:08:50,240
that the other kill chain frameworks do

214
00:08:50,240 --> 00:08:51,279
not

215
00:08:51,279 --> 00:08:52,160
but

216
00:08:52,160 --> 00:08:53,680
on the other hand

217
00:08:53,680 --> 00:08:56,800
influence operators evolve very quickly

218
00:08:56,800 --> 00:08:59,360
and new tactics are being developed and

219
00:08:59,360 --> 00:09:01,920
used by threat actors every day

220
00:09:01,920 --> 00:09:04,160
so the current emit framework doesn't

221
00:09:04,160 --> 00:09:05,120
address

222
00:09:05,120 --> 00:09:07,519
the use of some of the newer social

223
00:09:07,519 --> 00:09:10,320
media platforms and mobile applications

224
00:09:10,320 --> 00:09:12,880
that are being used by certain influence

225
00:09:12,880 --> 00:09:16,320
actors as they pivot to avoid censorship

226
00:09:16,320 --> 00:09:18,560
and de-platforming

227
00:09:18,560 --> 00:09:19,600
however

228
00:09:19,600 --> 00:09:22,160
this list can be updated accordingly and

229
00:09:22,160 --> 00:09:23,760
used in conjunction with other

230
00:09:23,760 --> 00:09:25,120
frameworks

231
00:09:25,120 --> 00:09:27,360
so this framework although useful for

232
00:09:27,360 --> 00:09:29,920
ttps doesn't really address the

233
00:09:29,920 --> 00:09:33,440
operational process or the geopolitical

234
00:09:33,440 --> 00:09:36,640
psychosocial aspects of these campaigns

235
00:09:36,640 --> 00:09:40,720
so let's talk about that for a second

236
00:09:41,120 --> 00:09:43,360
now before i show you the diamond model

237
00:09:43,360 --> 00:09:45,360
i want to address a really important

238
00:09:45,360 --> 00:09:48,080
element that sets influence operations

239
00:09:48,080 --> 00:09:51,080
apart

240
00:09:51,120 --> 00:09:52,800
narrative

241
00:09:52,800 --> 00:09:55,519
the core element of every influence

242
00:09:55,519 --> 00:09:59,040
operation is a story or narrative i want

243
00:09:59,040 --> 00:10:00,640
to drive that home because that's very

244
00:10:00,640 --> 00:10:02,000
important

245
00:10:02,000 --> 00:10:05,200
narrative is vital to understanding and

246
00:10:05,200 --> 00:10:08,079
identifying the influencers intentions

247
00:10:08,079 --> 00:10:10,640
or objectives

248
00:10:10,640 --> 00:10:13,120
humans are innately

249
00:10:13,120 --> 00:10:15,680
predisposed to understand information

250
00:10:15,680 --> 00:10:19,600
with assigned meaning and storytelling

251
00:10:19,600 --> 00:10:22,000
really is the most effective way

252
00:10:22,000 --> 00:10:25,600
uh to assign meaning to information

253
00:10:25,600 --> 00:10:27,440
and the most successful influence

254
00:10:27,440 --> 00:10:30,480
campaigns use narratives with components

255
00:10:30,480 --> 00:10:33,279
of shared identity the us

256
00:10:33,279 --> 00:10:36,959
the we aspect of the story

257
00:10:36,959 --> 00:10:39,040
with identity and meaning

258
00:10:39,040 --> 00:10:41,920
a story can change how people think and

259
00:10:41,920 --> 00:10:43,040
behave

260
00:10:43,040 --> 00:10:45,279
which is likely the end goal or

261
00:10:45,279 --> 00:10:48,959
objective of an influence operation

262
00:10:48,959 --> 00:10:51,040
now narrative warfare

263
00:10:51,040 --> 00:10:52,000
is the

264
00:10:52,000 --> 00:10:54,720
weaponization of a narrative

265
00:10:54,720 --> 00:10:57,519
and the battle over that meaning

266
00:10:57,519 --> 00:11:00,399
and identity of information

267
00:11:00,399 --> 00:11:02,079
now this plays a central part in the

268
00:11:02,079 --> 00:11:04,000
diamond model and it's part of the

269
00:11:04,000 --> 00:11:05,680
reason we created the diamond models we

270
00:11:05,680 --> 00:11:07,519
want to incorporate that aspect of

271
00:11:07,519 --> 00:11:11,120
narrative which oftentimes gets lost

272
00:11:11,120 --> 00:11:13,440
in our very very technical industry

273
00:11:13,440 --> 00:11:15,519
where we're dealing with ttp's

274
00:11:15,519 --> 00:11:18,000
capabilities infrastructure threat

275
00:11:18,000 --> 00:11:22,480
actors this is a really important aspect

276
00:11:22,880 --> 00:11:25,120
now the diamond model for influence

277
00:11:25,120 --> 00:11:27,279
operations or i'm sorry the diamond

278
00:11:27,279 --> 00:11:29,600
model for intrusion operations is a

279
00:11:29,600 --> 00:11:32,000
framework ins uh is a framework that was

280
00:11:32,000 --> 00:11:34,399
developed by three department of defense

281
00:11:34,399 --> 00:11:35,519
analysts

282
00:11:35,519 --> 00:11:38,160
in 2013. looks like my text got a little

283
00:11:38,160 --> 00:11:39,519
messed up there

284
00:11:39,519 --> 00:11:42,720
um and so we based the diamond model for

285
00:11:42,720 --> 00:11:45,040
influence ops on the intrusion diamond

286
00:11:45,040 --> 00:11:46,079
model

287
00:11:46,079 --> 00:11:48,720
loosely because it was intended to be

288
00:11:48,720 --> 00:11:52,320
very flexible and uh to be adaptable to

289
00:11:52,320 --> 00:11:54,000
future threats

290
00:11:54,000 --> 00:11:56,320
so of course the original diamond model

291
00:11:56,320 --> 00:11:58,800
has four elements capabilities and

292
00:11:58,800 --> 00:12:01,600
infrastructure on the technical axis

293
00:12:01,600 --> 00:12:03,440
adversary and victim on the

294
00:12:03,440 --> 00:12:05,680
socio-political axis

295
00:12:05,680 --> 00:12:07,600
now taking into consideration the

296
00:12:07,600 --> 00:12:10,560
differences between intrusion campaigns

297
00:12:10,560 --> 00:12:13,040
and influence campaigns we made some

298
00:12:13,040 --> 00:12:15,519
changes

299
00:12:17,760 --> 00:12:19,760
this is the diamond model for influence

300
00:12:19,760 --> 00:12:22,079
operations

301
00:12:22,079 --> 00:12:25,360
the aim of this adapted diamond model

302
00:12:25,360 --> 00:12:27,360
is to fuse together the essential

303
00:12:27,360 --> 00:12:30,160
components of an influence campaign

304
00:12:30,160 --> 00:12:32,160
with the focus on the core of the

305
00:12:32,160 --> 00:12:35,040
diamond the narrative element that aims

306
00:12:35,040 --> 00:12:37,279
to change the behaviors of the target

307
00:12:37,279 --> 00:12:38,720
audience

308
00:12:38,720 --> 00:12:41,120
now these elements tied together all of

309
00:12:41,120 --> 00:12:43,279
the other elements of a campaign

310
00:12:43,279 --> 00:12:45,279
and some labels were changed to more

311
00:12:45,279 --> 00:12:47,839
accurately reflect the nuances of

312
00:12:47,839 --> 00:12:49,920
influence campaigns

313
00:12:49,920 --> 00:12:52,079
on the socio-political axis the term

314
00:12:52,079 --> 00:12:54,800
adversary is replaced with influencer

315
00:12:54,800 --> 00:12:57,920
and victim is replaced with audience

316
00:12:57,920 --> 00:13:00,480
but the technical axis remains the same

317
00:13:00,480 --> 00:13:02,480
it's unchanged with capabilities

318
00:13:02,480 --> 00:13:05,360
addressing the ttps and infrastructure

319
00:13:05,360 --> 00:13:07,680
addressing the various technical

320
00:13:07,680 --> 00:13:10,240
and physical infrastructure used for

321
00:13:10,240 --> 00:13:12,560
production and dissemination

322
00:13:12,560 --> 00:13:15,760
of influence materials

323
00:13:15,760 --> 00:13:18,000
the key change in this diamond model for

324
00:13:18,000 --> 00:13:20,320
influence operations is the addition of

325
00:13:20,320 --> 00:13:23,120
the core element of narrative which is

326
00:13:23,120 --> 00:13:25,800
vital but often overlooked

327
00:13:25,800 --> 00:13:28,720
socio-psychological aspect of successful

328
00:13:28,720 --> 00:13:30,399
influence operations

329
00:13:30,399 --> 00:13:34,839
so let's dig into this a little more

330
00:13:34,880 --> 00:13:37,120
on the capability side

331
00:13:37,120 --> 00:13:39,040
you could assess what kind of

332
00:13:39,040 --> 00:13:41,680
capabilities this influence actor has

333
00:13:41,680 --> 00:13:44,240
are they large scale or small do they

334
00:13:44,240 --> 00:13:46,480
use bots do they use trolls or

335
00:13:46,480 --> 00:13:48,079
automation

336
00:13:48,079 --> 00:13:51,279
do they use deep fake videos and photos

337
00:13:51,279 --> 00:13:52,720
forgeries

338
00:13:52,720 --> 00:13:53,519
or

339
00:13:53,519 --> 00:13:55,440
what is their budget that could even be

340
00:13:55,440 --> 00:13:58,720
on the capability side

341
00:13:59,519 --> 00:14:01,839
on the infrastructure side we're looking

342
00:14:01,839 --> 00:14:04,240
at what kind of technical infrastructure

343
00:14:04,240 --> 00:14:05,519
are they using

344
00:14:05,519 --> 00:14:07,360
this could be similar to an intrusion

345
00:14:07,360 --> 00:14:09,760
campaign you can tie infrastructure back

346
00:14:09,760 --> 00:14:12,160
to ip addresses and domains

347
00:14:12,160 --> 00:14:14,880
you can also look at what fringe news

348
00:14:14,880 --> 00:14:17,360
websites are they setting up what social

349
00:14:17,360 --> 00:14:19,519
media platforms and applications are

350
00:14:19,519 --> 00:14:20,959
they using

351
00:14:20,959 --> 00:14:23,519
what specific social media accounts do

352
00:14:23,519 --> 00:14:24,720
they have

353
00:14:24,720 --> 00:14:27,680
are they using news agencies

354
00:14:27,680 --> 00:14:29,600
so there's all types of infrastructure

355
00:14:29,600 --> 00:14:31,600
that influence campaigns happen on and

356
00:14:31,600 --> 00:14:32,720
that's where that would go on the

357
00:14:32,720 --> 00:14:34,880
diamond

358
00:14:34,880 --> 00:14:36,639
i like to start at the bottom with the

359
00:14:36,639 --> 00:14:38,560
audience because this is usually the

360
00:14:38,560 --> 00:14:41,199
easiest to identify the audience could

361
00:14:41,199 --> 00:14:44,399
be a global scale national scale it

362
00:14:44,399 --> 00:14:45,760
could be local

363
00:14:45,760 --> 00:14:48,160
maybe small groups maybe a political

364
00:14:48,160 --> 00:14:50,720
party or constituency

365
00:14:50,720 --> 00:14:53,040
it could also be consumers

366
00:14:53,040 --> 00:14:54,800
let's talk about your company for a

367
00:14:54,800 --> 00:14:57,360
second your company could be targeted in

368
00:14:57,360 --> 00:15:00,959
a disinformation as a service campaign

369
00:15:00,959 --> 00:15:03,360
it could be a competitor across the

370
00:15:03,360 --> 00:15:04,880
world hiring

371
00:15:04,880 --> 00:15:07,120
cyber criminals in the dark web to

372
00:15:07,120 --> 00:15:08,959
conduct a disinformation campaign on

373
00:15:08,959 --> 00:15:10,800
your company so it's important to

374
00:15:10,800 --> 00:15:12,480
understand that your audience could also

375
00:15:12,480 --> 00:15:16,079
be your consumers or your customers

376
00:15:16,079 --> 00:15:17,680
and then of course at the top is the

377
00:15:17,680 --> 00:15:18,880
influencer

378
00:15:18,880 --> 00:15:20,959
now quite often you hear about nation

379
00:15:20,959 --> 00:15:24,320
state influencers if one country

380
00:15:24,320 --> 00:15:26,320
conducts a propaganda campaign against

381
00:15:26,320 --> 00:15:27,519
another

382
00:15:27,519 --> 00:15:29,680
it can also be criminal it could be

383
00:15:29,680 --> 00:15:31,279
political

384
00:15:31,279 --> 00:15:33,759
proxy companies are also used and they

385
00:15:33,759 --> 00:15:36,320
would also go under the influencer side

386
00:15:36,320 --> 00:15:37,839
let's say

387
00:15:37,839 --> 00:15:40,079
if a nation state hires a proxy

388
00:15:40,079 --> 00:15:42,720
marketing company or a pr company that

389
00:15:42,720 --> 00:15:46,480
would go under the influencer part

390
00:15:49,920 --> 00:15:51,680
now let's take a look

391
00:15:51,680 --> 00:15:55,120
a little more in depth at the technical

392
00:15:55,120 --> 00:15:57,440
axis here

393
00:15:57,440 --> 00:15:58,880
let me get my

394
00:15:58,880 --> 00:16:00,240
slides up here

395
00:16:00,240 --> 00:16:02,240
the technical axis consists of

396
00:16:02,240 --> 00:16:04,160
capabilities on the left side of the

397
00:16:04,160 --> 00:16:05,839
diamond and infrastructure on the right

398
00:16:05,839 --> 00:16:06,880
side

399
00:16:06,880 --> 00:16:08,880
now by identifying the capabilities and

400
00:16:08,880 --> 00:16:10,959
the infrastructure used by the

401
00:16:10,959 --> 00:16:12,160
influencer

402
00:16:12,160 --> 00:16:14,880
and potential methods of defense

403
00:16:14,880 --> 00:16:17,120
decision makers are empowered to take

404
00:16:17,120 --> 00:16:19,440
action against malign influence

405
00:16:19,440 --> 00:16:20,959
operations

406
00:16:20,959 --> 00:16:23,279
the capabilities and infrastructure

407
00:16:23,279 --> 00:16:25,040
corners of the diamond can be some of

408
00:16:25,040 --> 00:16:28,240
the most revealing intelligence gathered

409
00:16:28,240 --> 00:16:30,000
on the influencer

410
00:16:30,000 --> 00:16:32,079
so both of these elements are likely to

411
00:16:32,079 --> 00:16:34,639
evolve over time especially

412
00:16:34,639 --> 00:16:36,560
if target audiences

413
00:16:36,560 --> 00:16:39,120
platform administrators or regulators

414
00:16:39,120 --> 00:16:41,920
crack down on the activity resulting in

415
00:16:41,920 --> 00:16:44,399
the influencer pivoting to new or

416
00:16:44,399 --> 00:16:46,800
unregulated infrastructure and

417
00:16:46,800 --> 00:16:49,839
undetected tactics

418
00:16:49,839 --> 00:16:52,800
now well-resourced influencers will

419
00:16:52,800 --> 00:16:55,839
usually stand out their capabilities are

420
00:16:55,839 --> 00:16:57,759
are much better funded

421
00:16:57,759 --> 00:17:00,240
and much more noticeable well-resourced

422
00:17:00,240 --> 00:17:02,800
influencers will be persistent when they

423
00:17:02,800 --> 00:17:05,199
encounter obstacles

424
00:17:05,199 --> 00:17:08,240
much like intrusion campaigns too

425
00:17:08,240 --> 00:17:10,480
and the smaller less resourced

426
00:17:10,480 --> 00:17:13,280
influencers will be easier to identify

427
00:17:13,280 --> 00:17:15,520
will make mistakes more often

428
00:17:15,520 --> 00:17:17,919
and will take significantly longer to

429
00:17:17,919 --> 00:17:20,160
overcome obstacles and set up new

430
00:17:20,160 --> 00:17:22,959
infrastructure

431
00:17:25,119 --> 00:17:26,880
so let's take a look at the

432
00:17:26,880 --> 00:17:29,440
socio-political axis

433
00:17:29,440 --> 00:17:32,640
influence operations are highly

434
00:17:32,640 --> 00:17:35,039
psychological i bring that up because

435
00:17:35,039 --> 00:17:37,200
that's an element that we don't often

436
00:17:37,200 --> 00:17:39,919
confront in our industry we don't often

437
00:17:39,919 --> 00:17:41,679
dig into the psychological and the

438
00:17:41,679 --> 00:17:44,080
political aspects but influence

439
00:17:44,080 --> 00:17:46,240
operations are highly psychological and

440
00:17:46,240 --> 00:17:47,760
political

441
00:17:47,760 --> 00:17:49,919
and i believe that the most important

442
00:17:49,919 --> 00:17:52,080
aspect in understanding an influence

443
00:17:52,080 --> 00:17:55,120
campaign is right here on the screen

444
00:17:55,120 --> 00:17:57,280
the socio-political access allows you to

445
00:17:57,280 --> 00:17:59,280
examine the relationship

446
00:17:59,280 --> 00:18:02,480
between the influencer and the audience

447
00:18:02,480 --> 00:18:04,480
there's always a relationship between

448
00:18:04,480 --> 00:18:07,280
them and it's often the influencer is

449
00:18:07,280 --> 00:18:10,240
trying to coerce the audience

450
00:18:10,240 --> 00:18:12,720
sometimes convince them of something

451
00:18:12,720 --> 00:18:15,039
maybe make the audience feel vulnerable

452
00:18:15,039 --> 00:18:16,320
or scared

453
00:18:16,320 --> 00:18:19,120
or over emotional

454
00:18:19,120 --> 00:18:20,640
that's when they can effectively

455
00:18:20,640 --> 00:18:24,080
influence the audience to take action

456
00:18:24,080 --> 00:18:27,200
now whether that's voting a certain way

457
00:18:27,200 --> 00:18:30,559
rioting starting a war or something as

458
00:18:30,559 --> 00:18:32,640
simple as influencing what someone

459
00:18:32,640 --> 00:18:34,000
purchases

460
00:18:34,000 --> 00:18:36,799
the influencer wants control over the

461
00:18:36,799 --> 00:18:37,840
audience

462
00:18:37,840 --> 00:18:39,679
and they work to build trust with the

463
00:18:39,679 --> 00:18:42,559
audience they appeal to their morals

464
00:18:42,559 --> 00:18:44,640
beliefs and ethics

465
00:18:44,640 --> 00:18:48,160
or lack thereof

466
00:18:50,080 --> 00:18:53,360
so this is uh a couple of notes on how

467
00:18:53,360 --> 00:18:55,520
the relationship between the influencer

468
00:18:55,520 --> 00:18:57,600
and audience works

469
00:18:57,600 --> 00:19:00,000
you can see here that

470
00:19:00,000 --> 00:19:03,039
they range from overt agents to

471
00:19:03,039 --> 00:19:05,679
outspoken politicians on the influencer

472
00:19:05,679 --> 00:19:08,080
side sometimes they're just low quality

473
00:19:08,080 --> 00:19:10,799
inauthentic accounts

474
00:19:10,799 --> 00:19:12,559
and then the narrative notice the

475
00:19:12,559 --> 00:19:14,559
narrative is right in between and it

476
00:19:14,559 --> 00:19:16,400
creates a story it creates a bond

477
00:19:16,400 --> 00:19:18,720
between the influencer and the audience

478
00:19:18,720 --> 00:19:20,880
the audience is obviously the intended

479
00:19:20,880 --> 00:19:23,440
target of the influence operations and

480
00:19:23,440 --> 00:19:25,520
and they can range in various sites like

481
00:19:25,520 --> 00:19:26,320
we

482
00:19:26,320 --> 00:19:28,559
already discussed and

483
00:19:28,559 --> 00:19:30,640
like i said the most resourced

484
00:19:30,640 --> 00:19:33,120
influencers are often the most obvious

485
00:19:33,120 --> 00:19:35,200
you'll see them either overtly or

486
00:19:35,200 --> 00:19:37,200
covertly using pretty large

487
00:19:37,200 --> 00:19:39,840
infrastructure

488
00:19:44,000 --> 00:19:46,559
now let's dig into some examples i think

489
00:19:46,559 --> 00:19:48,559
i have about 10 minutes left so

490
00:19:48,559 --> 00:19:50,799
hopefully we'll have time for both this

491
00:19:50,799 --> 00:19:53,679
one is actually a private sector example

492
00:19:53,679 --> 00:19:55,679
let's use an example from a fictional

493
00:19:55,679 --> 00:19:58,799
auto manufacturer called vera

494
00:19:58,799 --> 00:20:02,240
now vera develops self-driving cars

495
00:20:02,240 --> 00:20:04,880
and one day someone uploaded a video of

496
00:20:04,880 --> 00:20:07,919
a vera car driving itself around when

497
00:20:07,919 --> 00:20:10,960
suddenly it crashes into pedestrians

498
00:20:10,960 --> 00:20:13,360
causing a horrific scene

499
00:20:13,360 --> 00:20:16,000
now the video uploaded to a streaming

500
00:20:16,000 --> 00:20:17,840
video application

501
00:20:17,840 --> 00:20:20,559
instantly went viral racking up millions

502
00:20:20,559 --> 00:20:22,400
of views around the world

503
00:20:22,400 --> 00:20:24,880
social media accounts shared the video

504
00:20:24,880 --> 00:20:27,039
and also made hundreds of comments

505
00:20:27,039 --> 00:20:30,159
criticizing the vera company

506
00:20:30,159 --> 00:20:32,960
the video was later determined to be a

507
00:20:32,960 --> 00:20:34,720
deep fake video

508
00:20:34,720 --> 00:20:37,520
created to make the vera automobile look

509
00:20:37,520 --> 00:20:38,640
dangerous

510
00:20:38,640 --> 00:20:42,000
reckless and unreliable

511
00:20:42,000 --> 00:20:43,840
by the time the video was proven to be

512
00:20:43,840 --> 00:20:46,960
fake though fringe news sites like not

513
00:20:46,960 --> 00:20:48,799
mainstream news but all the little news

514
00:20:48,799 --> 00:20:50,960
sites that look very suspicious

515
00:20:50,960 --> 00:20:54,640
those ones had spread the news story

516
00:20:54,640 --> 00:20:56,400
and they had picked up the story and ran

517
00:20:56,400 --> 00:20:59,760
it in europe and the us

518
00:20:59,760 --> 00:21:01,039
but by then

519
00:21:01,039 --> 00:21:03,520
the company's stocks were tanked

520
00:21:03,520 --> 00:21:05,360
causing grave damage to the company's

521
00:21:05,360 --> 00:21:07,039
reputation

522
00:21:07,039 --> 00:21:09,280
now millions of people

523
00:21:09,280 --> 00:21:11,760
especially in u.s and europe believed

524
00:21:11,760 --> 00:21:14,320
what they saw that self-driving cars

525
00:21:14,320 --> 00:21:15,200
were

526
00:21:15,200 --> 00:21:17,039
dangerous killing machines that cannot

527
00:21:17,039 --> 00:21:18,240
be trusted

528
00:21:18,240 --> 00:21:20,240
that was the narrative

529
00:21:20,240 --> 00:21:23,200
during the investigation vera cti team

530
00:21:23,200 --> 00:21:25,520
discovered the following

531
00:21:25,520 --> 00:21:27,039
capabilities

532
00:21:27,039 --> 00:21:29,440
there was the use of deep fake video and

533
00:21:29,440 --> 00:21:30,640
photos

534
00:21:30,640 --> 00:21:32,799
altered photos from the

535
00:21:32,799 --> 00:21:36,400
supposed scene of the incident

536
00:21:36,400 --> 00:21:38,640
they used inauthentic social media

537
00:21:38,640 --> 00:21:43,679
profiles and they had fake news coverage

538
00:21:43,679 --> 00:21:46,159
on the infrastructure side there was a

539
00:21:46,159 --> 00:21:49,280
streaming media platform used mainstream

540
00:21:49,280 --> 00:21:50,720
social media

541
00:21:50,720 --> 00:21:53,280
fringe news websites hosted on foreign

542
00:21:53,280 --> 00:21:56,080
ips and domains

543
00:21:56,080 --> 00:21:57,360
that's the

544
00:21:57,360 --> 00:21:59,360
technical infrastructure that the cti

545
00:21:59,360 --> 00:22:01,600
team discovered

546
00:22:01,600 --> 00:22:04,080
and so the audience was u.s and european

547
00:22:04,080 --> 00:22:06,720
audiences where competitors

548
00:22:06,720 --> 00:22:08,640
launched a new vehicle

549
00:22:08,640 --> 00:22:13,120
adults ages 25 to 55 were targeted

550
00:22:13,120 --> 00:22:16,159
and the influencer was determined to be

551
00:22:16,159 --> 00:22:18,640
a criminal disinformation as a service

552
00:22:18,640 --> 00:22:21,200
organization hired by a foreign

553
00:22:21,200 --> 00:22:23,039
competitor

554
00:22:23,039 --> 00:22:25,520
now this is a fictional scenario but

555
00:22:25,520 --> 00:22:27,760
things like this happen every day

556
00:22:27,760 --> 00:22:29,919
and so we see disinformation as a

557
00:22:29,919 --> 00:22:32,799
service being sold in the dark web

558
00:22:32,799 --> 00:22:35,039
recorded future my organization actually

559
00:22:35,039 --> 00:22:38,240
did an experiment in 2016 where we hired

560
00:22:38,240 --> 00:22:40,080
two criminal disinformation

561
00:22:40,080 --> 00:22:43,360
organizations we hired one to conduct a

562
00:22:43,360 --> 00:22:45,919
positive sentiment campaign and we hired

563
00:22:45,919 --> 00:22:48,320
another to conduct a negative sentiment

564
00:22:48,320 --> 00:22:49,520
campaign

565
00:22:49,520 --> 00:22:52,640
we asked them prices we determined what

566
00:22:52,640 --> 00:22:54,640
scope we wanted to do and they went to

567
00:22:54,640 --> 00:22:56,400
work both

568
00:22:56,400 --> 00:22:59,360
working towards either supporting or

569
00:22:59,360 --> 00:23:01,520
degrading a fictional company that we

570
00:23:01,520 --> 00:23:02,640
created

571
00:23:02,640 --> 00:23:05,360
it was a phenomenal study and it really

572
00:23:05,360 --> 00:23:07,200
showed us how they work how they operate

573
00:23:07,200 --> 00:23:09,039
and what they're really capable of and

574
00:23:09,039 --> 00:23:10,559
you know what their first thing was that

575
00:23:10,559 --> 00:23:12,720
they went to was advertising on social

576
00:23:12,720 --> 00:23:13,760
media

577
00:23:13,760 --> 00:23:17,120
so it's a it's interesting how they work

578
00:23:17,120 --> 00:23:18,960
interesting how you can break it out

579
00:23:18,960 --> 00:23:21,200
into the diamond model here and in the

580
00:23:21,200 --> 00:23:23,200
middle for the narrative

581
00:23:23,200 --> 00:23:25,360
would be that narrative about

582
00:23:25,360 --> 00:23:27,039
self-driving cars are reckless and

583
00:23:27,039 --> 00:23:29,520
dangerous

584
00:23:29,600 --> 00:23:31,919
so let's go to the next one i have a few

585
00:23:31,919 --> 00:23:33,919
more minutes

586
00:23:33,919 --> 00:23:37,600
this next one is a fictional

587
00:23:37,600 --> 00:23:39,600
state-sponsored campaign

588
00:23:39,600 --> 00:23:42,640
let me get my slides caught up here

589
00:23:42,640 --> 00:23:44,320
now

590
00:23:44,320 --> 00:23:47,200
for this fictional state nation state

591
00:23:47,200 --> 00:23:50,159
we're going to call them country h so

592
00:23:50,159 --> 00:23:52,880
you can follow along with me country h

593
00:23:52,880 --> 00:23:56,400
is not fond of its neighbor country g

594
00:23:56,400 --> 00:23:58,559
they often fight over territory and

595
00:23:58,559 --> 00:24:01,520
scarce resources in their area

596
00:24:01,520 --> 00:24:04,159
country h was discovered conducting

597
00:24:04,159 --> 00:24:06,640
political influence operations targeting

598
00:24:06,640 --> 00:24:09,279
a group of cultural minorities on the

599
00:24:09,279 --> 00:24:11,679
border of country g

600
00:24:11,679 --> 00:24:13,760
the cultural minority lives inside the

601
00:24:13,760 --> 00:24:16,159
border of country g

602
00:24:16,159 --> 00:24:18,559
so in this campaign they attempted to

603
00:24:18,559 --> 00:24:20,960
convince the minority group that if they

604
00:24:20,960 --> 00:24:23,760
didn't vote for the pro-country h

605
00:24:23,760 --> 00:24:26,080
candidate in the next election

606
00:24:26,080 --> 00:24:29,679
the people would face grave consequences

607
00:24:29,679 --> 00:24:33,760
intimidation and coercion now country h

608
00:24:33,760 --> 00:24:36,240
they hope that if the right candidate is

609
00:24:36,240 --> 00:24:37,360
selected

610
00:24:37,360 --> 00:24:39,760
that candidate will influence country

611
00:24:39,760 --> 00:24:43,039
g's legislative body in a way that gives

612
00:24:43,039 --> 00:24:46,720
up territory to country h

613
00:24:46,720 --> 00:24:48,240
now when the threat intelligence

614
00:24:48,240 --> 00:24:50,720
analysts discovered this campaign they

615
00:24:50,720 --> 00:24:53,679
started digging in

616
00:24:53,919 --> 00:24:56,640
on the capabilities side and notice that

617
00:24:56,640 --> 00:24:59,279
i'm using the emit framework here to

618
00:24:59,279 --> 00:25:01,840
list out the ttps that's an example of

619
00:25:01,840 --> 00:25:03,760
how you can layer one framework on top

620
00:25:03,760 --> 00:25:05,200
of the diamond model

621
00:25:05,200 --> 00:25:07,440
these are three tactics that they

622
00:25:07,440 --> 00:25:10,000
discovered country h using

623
00:25:10,000 --> 00:25:12,400
they use trolls to amplify and

624
00:25:12,400 --> 00:25:15,679
manipulate on social media they also

625
00:25:15,679 --> 00:25:18,559
used a particular hashtag that appealed

626
00:25:18,559 --> 00:25:20,960
to that cultural minority

627
00:25:20,960 --> 00:25:24,400
and they organized rallies and events in

628
00:25:24,400 --> 00:25:25,360
person

629
00:25:25,360 --> 00:25:26,799
so keep this in mind that the

630
00:25:26,799 --> 00:25:28,880
infrastructure and the capabilities are

631
00:25:28,880 --> 00:25:31,200
not always technical sometimes they're

632
00:25:31,200 --> 00:25:34,000
also physical

633
00:25:35,600 --> 00:25:37,919
on the infrastructure side they used

634
00:25:37,919 --> 00:25:40,559
inauthentic social media accounts

635
00:25:40,559 --> 00:25:43,440
fringe social media that was used by the

636
00:25:43,440 --> 00:25:44,880
target audience

637
00:25:44,880 --> 00:25:46,960
so we're not talking about facebook

638
00:25:46,960 --> 00:25:49,360
twitter all the big ones even in your

639
00:25:49,360 --> 00:25:51,120
own country whatever the most popular

640
00:25:51,120 --> 00:25:53,279
platform is we're talking about a very

641
00:25:53,279 --> 00:25:55,679
specific fringe social media platform

642
00:25:55,679 --> 00:25:58,240
that was used by that cultural minority

643
00:25:58,240 --> 00:26:00,720
a safe space let's say that's where they

644
00:26:00,720 --> 00:26:02,400
were targeted

645
00:26:02,400 --> 00:26:05,120
and they also used a local town hall

646
00:26:05,120 --> 00:26:07,120
building to stage protests and

647
00:26:07,120 --> 00:26:10,000
demonstrations and to reach that target

648
00:26:10,000 --> 00:26:12,480
audience

649
00:26:13,279 --> 00:26:15,360
now we know that the audience was

650
00:26:15,360 --> 00:26:17,919
country g's cultural minority

651
00:26:17,919 --> 00:26:20,559
and we determined that the influencer

652
00:26:20,559 --> 00:26:21,360
was

653
00:26:21,360 --> 00:26:22,799
country h

654
00:26:22,799 --> 00:26:25,039
and their intelligence agency as well as

655
00:26:25,039 --> 00:26:26,799
their police department that worked on

656
00:26:26,799 --> 00:26:28,320
the border

657
00:26:28,320 --> 00:26:31,120
this right here is just an example a

658
00:26:31,120 --> 00:26:34,400
fictional example of a political um

659
00:26:34,400 --> 00:26:36,120
maybe politically motivated

660
00:26:36,120 --> 00:26:38,400
nation-state-sponsored campaign but you

661
00:26:38,400 --> 00:26:40,400
can think about a million scenarios in

662
00:26:40,400 --> 00:26:42,480
your head about politics in your own

663
00:26:42,480 --> 00:26:45,760
country or perhaps internationally how

664
00:26:45,760 --> 00:26:47,679
nation-states are launching campaigns

665
00:26:47,679 --> 00:26:49,200
against each other

666
00:26:49,200 --> 00:26:50,480
of which

667
00:26:50,480 --> 00:26:52,400
our organization has a lot of great

668
00:26:52,400 --> 00:26:54,080
reports on our website if you ever want

669
00:26:54,080 --> 00:26:56,400
to check that out now these are just two

670
00:26:56,400 --> 00:26:58,799
examples of both private and public

671
00:26:58,799 --> 00:27:00,960
sector and how you might be able to use

672
00:27:00,960 --> 00:27:03,120
the diamond model to analyze influence

673
00:27:03,120 --> 00:27:06,720
operations so as i wrap this up um just

674
00:27:06,720 --> 00:27:07,919
wanted to

675
00:27:07,919 --> 00:27:09,840
let's see here

676
00:27:09,840 --> 00:27:12,080
uh give you a qr code to the full white

677
00:27:12,080 --> 00:27:14,240
paper on the diamond model for influence

678
00:27:14,240 --> 00:27:16,640
operations analysis i promise i'm not

679
00:27:16,640 --> 00:27:18,000
fishing you

680
00:27:18,000 --> 00:27:20,480
it'll take you straight to a free white

681
00:27:20,480 --> 00:27:22,080
paper you don't have to enter any

682
00:27:22,080 --> 00:27:24,720
information

683
00:27:24,960 --> 00:27:26,240
also

684
00:27:26,240 --> 00:27:28,559
my contact information is here and i

685
00:27:28,559 --> 00:27:30,480
post quite often on twitter about new

686
00:27:30,480 --> 00:27:33,200
disinformation campaigns and malign

687
00:27:33,200 --> 00:27:35,279
influence that we discover

688
00:27:35,279 --> 00:27:36,720
with that i want to say thank you for

689
00:27:36,720 --> 00:27:40,240
your time thank you for being here

690
00:27:43,760 --> 00:27:46,000
thank you again charity there is some

691
00:27:46,000 --> 00:27:49,799
question for charity

692
00:27:49,840 --> 00:27:52,240
i remember the microphone allocated one

693
00:27:52,240 --> 00:27:54,480
in left and one right side

694
00:27:54,480 --> 00:27:58,240
yeah look it like don't be shy

695
00:27:58,960 --> 00:28:00,399
quiet group

696
00:28:00,399 --> 00:28:02,480
very good awesome so i want to thank you

697
00:28:02,480 --> 00:28:04,320
again very much

698
00:28:04,320 --> 00:28:06,320
and applause for her please yes thank

699
00:28:06,320 --> 00:28:08,559
you

700
00:28:10,720 --> 00:28:13,600
so uh we have a 10 minute break right

701
00:28:13,600 --> 00:28:16,159
now next session will become in 10

702
00:28:16,159 --> 00:28:19,960
minutes thank you

