1
00:01:06,400 --> 00:01:08,560
hello everyone welcome to day two of the

2
00:01:08,560 --> 00:01:10,720
33rd annual first conference

3
00:01:10,720 --> 00:01:12,479
i'm josh crandall from the first events

4
00:01:12,479 --> 00:01:13,920
team and i'll be helping out with host

5
00:01:13,920 --> 00:01:16,159
responsibilities on the webinar today

6
00:01:16,159 --> 00:01:18,000
before we get started i'd like to remind

7
00:01:18,000 --> 00:01:19,439
everyone that speaker q

8
00:01:19,439 --> 00:01:21,680
a will take place in our conference work

9
00:01:21,680 --> 00:01:23,119
adventure platform

10
00:01:23,119 --> 00:01:25,280
if you are just joining the stream and

11
00:01:25,280 --> 00:01:27,200
are not pre-registered please send an

12
00:01:27,200 --> 00:01:28,479
email to events

13
00:01:28,479 --> 00:01:30,960
at first.org again it's events at

14
00:01:30,960 --> 00:01:32,159
first.org

15
00:01:32,159 --> 00:01:34,640
to get set up on the system work event

16
00:01:34,640 --> 00:01:36,640
work adventure is hosting all of our

17
00:01:36,640 --> 00:01:38,640
conference networking activities as well

18
00:01:38,640 --> 00:01:40,799
as the conference exhibit hall

19
00:01:40,799 --> 00:01:42,240
and with that let's go ahead and get

20
00:01:42,240 --> 00:01:44,799
started i'll pass the mic over to adley

21
00:01:44,799 --> 00:01:47,759
our session moderator

22
00:01:47,759 --> 00:01:50,640
thank you josh welcome everyone welcome

23
00:01:50,640 --> 00:01:51,119
back

24
00:01:51,119 --> 00:01:53,759
to the 33rd first annual conference

25
00:01:53,759 --> 00:01:54,640
virtual edition

26
00:01:54,640 --> 00:01:56,560
uh this is day number two and i'm sure

27
00:01:56,560 --> 00:01:57,920
all of you are excited to

28
00:01:57,920 --> 00:02:00,960
be part of this event just as i am

29
00:02:00,960 --> 00:02:04,320
now um the next session

30
00:02:04,320 --> 00:02:07,280
or this session that we're having now we

31
00:02:07,280 --> 00:02:09,440
have two presentations

32
00:02:09,440 --> 00:02:11,360
the first one will be on root cause

33
00:02:11,360 --> 00:02:13,760
analysis in dell's pcert

34
00:02:13,760 --> 00:02:16,400
and to do that we have david spencer

35
00:02:16,400 --> 00:02:17,599
senior manager

36
00:02:17,599 --> 00:02:21,120
p search engineering who'll be

37
00:02:21,120 --> 00:02:23,360
delivering the presentation so dave

38
00:02:23,360 --> 00:02:24,560
whenever you're ready

39
00:02:24,560 --> 00:02:27,599
the floor is yours all right thank you

40
00:02:27,599 --> 00:02:29,200
very much

41
00:02:29,200 --> 00:02:32,400
my name is david spencer uh i lead the

42
00:02:32,400 --> 00:02:34,640
pcert engineering function within dell

43
00:02:34,640 --> 00:02:35,519
technologies

44
00:02:35,519 --> 00:02:37,599
and i want to thank you for taking some

45
00:02:37,599 --> 00:02:40,080
time out of your day today to listen in

46
00:02:40,080 --> 00:02:42,800
this presentation about how we within

47
00:02:42,800 --> 00:02:43,440
dell's

48
00:02:43,440 --> 00:02:46,800
pcert group handle root cause analysis

49
00:02:46,800 --> 00:02:48,640
uh just a little bit of background about

50
00:02:48,640 --> 00:02:50,000
myself i won't spend much time

51
00:02:50,000 --> 00:02:52,959
here uh i've been in this role leading

52
00:02:52,959 --> 00:02:53,440
the p

53
00:02:53,440 --> 00:02:54,640
engineering team for about two and a

54
00:02:54,640 --> 00:02:56,720
half years and prior to that

55
00:02:56,720 --> 00:02:59,599
i was doing software development for a

56
00:02:59,599 --> 00:03:01,680
variety of product teams within dell and

57
00:03:01,680 --> 00:03:03,120
emc

58
00:03:03,120 --> 00:03:05,200
most of those product development roles

59
00:03:05,200 --> 00:03:06,560
had some amount of

60
00:03:06,560 --> 00:03:09,519
security embedded in them and then i

61
00:03:09,519 --> 00:03:10,800
made the jump over to the product

62
00:03:10,800 --> 00:03:12,239
security organization

63
00:03:12,239 --> 00:03:15,760
within the last few years

64
00:03:16,800 --> 00:03:18,319
so i don't think i need to explain to

65
00:03:18,319 --> 00:03:19,440
people that are attending this

66
00:03:19,440 --> 00:03:20,159
conference

67
00:03:20,159 --> 00:03:23,280
how important root cause analysis is in

68
00:03:23,280 --> 00:03:26,159
a secure development life cycle uh it's

69
00:03:26,159 --> 00:03:27,040
built into

70
00:03:27,040 --> 00:03:28,560
all the frameworks that we follow

71
00:03:28,560 --> 00:03:30,159
whether it's ssdf

72
00:03:30,159 --> 00:03:33,280
or iso 27001 even

73
00:03:33,280 --> 00:03:35,599
first's own pcert maturity model all

74
00:03:35,599 --> 00:03:38,000
require the use of root cause analysis

75
00:03:38,000 --> 00:03:39,920
to learn from the incidents that happen

76
00:03:39,920 --> 00:03:41,920
to our products and applications

77
00:03:41,920 --> 00:03:43,680
but i will just spend a moment on this

78
00:03:43,680 --> 00:03:46,080
slide just to refresh

79
00:03:46,080 --> 00:03:48,799
for everybody why it's so important so

80
00:03:48,799 --> 00:03:49,840
obviously

81
00:03:49,840 --> 00:03:51,680
when you're developing software in a

82
00:03:51,680 --> 00:03:54,239
secure way you do have various security

83
00:03:54,239 --> 00:03:55,599
controls that you're hoping that your

84
00:03:55,599 --> 00:03:56,640
development teams

85
00:03:56,640 --> 00:03:58,239
are utilizing when they write their

86
00:03:58,239 --> 00:04:00,879
software you have security education

87
00:04:00,879 --> 00:04:02,799
programs which you're hoping they will

88
00:04:02,799 --> 00:04:05,280
attend and learn from and then you're

89
00:04:05,280 --> 00:04:06,879
hoping that those security

90
00:04:06,879 --> 00:04:09,280
things take hold and when the product

91
00:04:09,280 --> 00:04:10,959
teams do their development and testing

92
00:04:10,959 --> 00:04:13,040
they're doing it in a secure fashion

93
00:04:13,040 --> 00:04:14,959
but no matter what happens you know

94
00:04:14,959 --> 00:04:16,238
there's always going to be

95
00:04:16,238 --> 00:04:18,320
vulnerabilities that somehow escape this

96
00:04:18,320 --> 00:04:19,440
process

97
00:04:19,440 --> 00:04:20,478
and if you can learn from those

98
00:04:20,478 --> 00:04:22,400
vulnerabilities and take those learnings

99
00:04:22,400 --> 00:04:22,800
back

100
00:04:22,800 --> 00:04:25,040
in to your security controls back into

101
00:04:25,040 --> 00:04:27,199
security education back into how

102
00:04:27,199 --> 00:04:28,560
the teams are doing their development

103
00:04:28,560 --> 00:04:30,960
and testing hopefully that process

104
00:04:30,960 --> 00:04:33,199
improves your stance overall and so

105
00:04:33,199 --> 00:04:34,479
every vulnerability that

106
00:04:34,479 --> 00:04:37,680
escapes your development environment is

107
00:04:37,680 --> 00:04:38,880
a chance to learn

108
00:04:38,880 --> 00:04:40,240
something about something that went

109
00:04:40,240 --> 00:04:42,400
wrong and prevent that specific thing

110
00:04:42,400 --> 00:04:43,919
from happening again

111
00:04:43,919 --> 00:04:45,360
maybe prevent things like it from

112
00:04:45,360 --> 00:04:47,040
happening again to other

113
00:04:47,040 --> 00:04:50,880
product teams throughout your company

114
00:04:51,680 --> 00:04:54,000
so before we dig into how we are

115
00:04:54,000 --> 00:04:55,360
approaching root cause analysis

116
00:04:55,360 --> 00:04:56,960
currently i think it's important just to

117
00:04:56,960 --> 00:04:58,240
give a little bit of background

118
00:04:58,240 --> 00:05:00,479
of how the security stakeholders work

119
00:05:00,479 --> 00:05:02,320
within dell technologies

120
00:05:02,320 --> 00:05:04,320
this model is certainly not unique and

121
00:05:04,320 --> 00:05:07,199
i've vastly simplified it for this slide

122
00:05:07,199 --> 00:05:09,280
but of course we have a product security

123
00:05:09,280 --> 00:05:10,960
organization here in the middle

124
00:05:10,960 --> 00:05:12,479
and that product security organization

125
00:05:12,479 --> 00:05:14,400
has a number of teams in it the two that

126
00:05:14,400 --> 00:05:15,919
i've shown here are the ones that are of

127
00:05:15,919 --> 00:05:18,080
interest to this conversation

128
00:05:18,080 --> 00:05:19,680
we have a team that's responsible for

129
00:05:19,680 --> 00:05:21,360
our secure development life cycle which

130
00:05:21,360 --> 00:05:23,120
we term sdl

131
00:05:23,120 --> 00:05:24,479
and we have a team that's responsible

132
00:05:24,479 --> 00:05:27,039
for vulnerability response specifically

133
00:05:27,039 --> 00:05:29,120
we'll be talking about pcert product

134
00:05:29,120 --> 00:05:31,039
security incident response

135
00:05:31,039 --> 00:05:34,800
teams so these two teams

136
00:05:34,800 --> 00:05:37,039
handle all the security incidents in a

137
00:05:37,039 --> 00:05:38,160
centralized

138
00:05:38,160 --> 00:05:40,240
fashion right all the security practices

139
00:05:40,240 --> 00:05:41,840
and incidents within the

140
00:05:41,840 --> 00:05:44,080
product security organization but within

141
00:05:44,080 --> 00:05:45,840
a company like dell there are

142
00:05:45,840 --> 00:05:47,440
hundreds of different product and

143
00:05:47,440 --> 00:05:49,280
application teams scattered throughout

144
00:05:49,280 --> 00:05:50,639
many different business units in the

145
00:05:50,639 --> 00:05:51,600
company

146
00:05:51,600 --> 00:05:53,680
each of which having people of varying

147
00:05:53,680 --> 00:05:55,440
skill when it comes to security and

148
00:05:55,440 --> 00:05:56,319
varying

149
00:05:56,319 --> 00:05:58,080
uh expertise and knowledge about

150
00:05:58,080 --> 00:05:59,520
security practices

151
00:05:59,520 --> 00:06:01,919
and so we have a program like many of

152
00:06:01,919 --> 00:06:02,560
you do

153
00:06:02,560 --> 00:06:04,080
where we have security champions

154
00:06:04,080 --> 00:06:05,680
embedded in those teams

155
00:06:05,680 --> 00:06:07,520
and the security champions are

156
00:06:07,520 --> 00:06:08,800
developers or

157
00:06:08,800 --> 00:06:11,039
testers or product managers or all of

158
00:06:11,039 --> 00:06:12,000
the above

159
00:06:12,000 --> 00:06:14,080
who have some level of security

160
00:06:14,080 --> 00:06:15,440
expertise and are

161
00:06:15,440 --> 00:06:17,199
considered in their team the subject

162
00:06:17,199 --> 00:06:19,199
matter experts on security

163
00:06:19,199 --> 00:06:21,039
and they are the ones who interact most

164
00:06:21,039 --> 00:06:22,880
closely with us whether it's during

165
00:06:22,880 --> 00:06:24,479
development when they are looking

166
00:06:24,479 --> 00:06:25,280
through

167
00:06:25,280 --> 00:06:27,199
the sdl practices that they're supposed

168
00:06:27,199 --> 00:06:29,440
to be enforcing on their teams or

169
00:06:29,440 --> 00:06:30,960
whether it's during the vulnerability

170
00:06:30,960 --> 00:06:32,400
response

171
00:06:32,400 --> 00:06:34,880
cycle when they are helping make sure

172
00:06:34,880 --> 00:06:36,319
that the process is handled

173
00:06:36,319 --> 00:06:38,240
properly and that the issues are

174
00:06:38,240 --> 00:06:40,080
remediated properly

175
00:06:40,080 --> 00:06:42,880
so that's sort of the picture just as a

176
00:06:42,880 --> 00:06:44,000
background

177
00:06:44,000 --> 00:06:45,199
the conversation that we're going to

178
00:06:45,199 --> 00:06:47,280
have assumes that that

179
00:06:47,280 --> 00:06:50,960
is in place so when we look at

180
00:06:50,960 --> 00:06:53,039
root cause analysis in a company like

181
00:06:53,039 --> 00:06:54,160
dell

182
00:06:54,160 --> 00:06:56,639
the immediate concern you have is around

183
00:06:56,639 --> 00:06:57,599
scalability

184
00:06:57,599 --> 00:07:00,240
um every you know root cause analysis

185
00:07:00,240 --> 00:07:02,560
was always a part of our

186
00:07:02,560 --> 00:07:04,560
secure development life cycle whether it

187
00:07:04,560 --> 00:07:06,960
was done in a centralized fashion or in

188
00:07:06,960 --> 00:07:08,160
a distributed fashion

189
00:07:08,160 --> 00:07:10,080
it was always there but over the last

190
00:07:10,080 --> 00:07:11,680
few years we decided to take

191
00:07:11,680 --> 00:07:14,560
a look at it and try to make a process

192
00:07:14,560 --> 00:07:15,840
which was going to be driven through our

193
00:07:15,840 --> 00:07:17,919
pcert organization to formalize it a

194
00:07:17,919 --> 00:07:19,120
little bit and we'll talk

195
00:07:19,120 --> 00:07:20,560
throughout this presentation about why

196
00:07:20,560 --> 00:07:22,479
that is and how we did it

197
00:07:22,479 --> 00:07:23,840
but when you try to do that you

198
00:07:23,840 --> 00:07:25,599
immediately run into a little bit of a

199
00:07:25,599 --> 00:07:26,720
scalability issue

200
00:07:26,720 --> 00:07:28,080
you have the vulnerabilities that are

201
00:07:28,080 --> 00:07:30,479
coming into our organization discovered

202
00:07:30,479 --> 00:07:30,800
by

203
00:07:30,800 --> 00:07:32,800
in many cases external finders outside

204
00:07:32,800 --> 00:07:35,360
the company whether it's researchers

205
00:07:35,360 --> 00:07:37,599
or customers or folks that are signing

206
00:07:37,599 --> 00:07:39,759
up for a bug bounty program

207
00:07:39,759 --> 00:07:40,960
you've got hundreds of different

208
00:07:40,960 --> 00:07:42,960
products and applications all of them in

209
00:07:42,960 --> 00:07:44,080
varying stages

210
00:07:44,080 --> 00:07:46,479
of maturity in their security journey

211
00:07:46,479 --> 00:07:48,879
and you have a pcert team which is

212
00:07:48,879 --> 00:07:51,919
lean and sometimes maybe you might

213
00:07:51,919 --> 00:07:53,280
talk to some of the engineers they might

214
00:07:53,280 --> 00:07:54,240
tell you that they're a little over

215
00:07:54,240 --> 00:07:56,160
subscribed that the work

216
00:07:56,160 --> 00:07:57,919
they were already busy before we decided

217
00:07:57,919 --> 00:07:59,199
that we wanted to

218
00:07:59,199 --> 00:08:00,879
to sort of centralize this root cause

219
00:08:00,879 --> 00:08:02,639
analysis procedure

220
00:08:02,639 --> 00:08:05,199
so given that scenario we have a lot of

221
00:08:05,199 --> 00:08:07,039
interesting questions to ask about how

222
00:08:07,039 --> 00:08:08,319
are we going to approach

223
00:08:08,319 --> 00:08:11,120
the problem of root cause analysis what

224
00:08:11,120 --> 00:08:12,000
sort of quality

225
00:08:12,000 --> 00:08:14,879
information do we want to get about this

226
00:08:14,879 --> 00:08:15,280
uh

227
00:08:15,280 --> 00:08:16,560
certainly one approach to root cause

228
00:08:16,560 --> 00:08:18,800
analysis would be to say let's pick

229
00:08:18,800 --> 00:08:21,440
a small number of very interesting

230
00:08:21,440 --> 00:08:23,199
security issues and dive

231
00:08:23,199 --> 00:08:24,960
deep into them sit down with the product

232
00:08:24,960 --> 00:08:26,479
teams and dig into it

233
00:08:26,479 --> 00:08:28,319
another one might be to say let's get a

234
00:08:28,319 --> 00:08:30,000
little bit of information about every

235
00:08:30,000 --> 00:08:32,399
single issue we have

236
00:08:32,399 --> 00:08:34,000
there's there's trade-offs on both

237
00:08:34,000 --> 00:08:35,679
approaches you want to be able to come

238
00:08:35,679 --> 00:08:37,599
up with a solution that we can automate

239
00:08:37,599 --> 00:08:39,120
and fits into our existing automation

240
00:08:39,120 --> 00:08:41,519
capabilities so that as the product

241
00:08:41,519 --> 00:08:42,719
problem scales

242
00:08:42,719 --> 00:08:45,680
our solution scales and we sort of have

243
00:08:45,680 --> 00:08:47,519
to make decisions about what types of

244
00:08:47,519 --> 00:08:48,959
work we're going to prioritize when it

245
00:08:48,959 --> 00:08:50,959
comes to root cause analysis

246
00:08:50,959 --> 00:08:53,200
so we had a lot of questions to ask and

247
00:08:53,200 --> 00:08:55,120
in the end we decided to focus

248
00:08:55,120 --> 00:08:58,640
on kind of the primary question about

249
00:08:58,640 --> 00:09:00,720
root cause analysis which is answering

250
00:09:00,720 --> 00:09:02,959
what happened what was it that happened

251
00:09:02,959 --> 00:09:04,320
in this situation

252
00:09:04,320 --> 00:09:07,360
that led to us

253
00:09:07,680 --> 00:09:11,760
needing to have the this vulnerability

254
00:09:12,000 --> 00:09:14,240
sorry

255
00:09:20,080 --> 00:09:21,680
so some of the things that could have

256
00:09:21,680 --> 00:09:23,600
happened there could have been gaps in

257
00:09:23,600 --> 00:09:24,000
how

258
00:09:24,000 --> 00:09:26,959
the sdl procedures applied across the

259
00:09:26,959 --> 00:09:27,839
company

260
00:09:27,839 --> 00:09:30,399
we call that a gap in the sel coverage

261
00:09:30,399 --> 00:09:31,839
different organizations are at different

262
00:09:31,839 --> 00:09:35,279
levels of maturity and gaps in how those

263
00:09:35,279 --> 00:09:36,959
those procedures are applied to those

264
00:09:36,959 --> 00:09:39,519
organizations might have led to an issue

265
00:09:39,519 --> 00:09:42,240
there could be a situation where the sdl

266
00:09:42,240 --> 00:09:44,080
procedures didn't focus on a particular

267
00:09:44,080 --> 00:09:46,240
issue or that that team didn't focus on

268
00:09:46,240 --> 00:09:48,640
a particular sdl procedure

269
00:09:48,640 --> 00:09:52,320
it could be that there was uh an error

270
00:09:52,320 --> 00:09:54,399
quite common right where a team is

271
00:09:54,399 --> 00:09:55,920
trying to do the right thing but fall

272
00:09:55,920 --> 00:09:57,920
short

273
00:09:57,920 --> 00:09:59,680
there's this interesting scenario here

274
00:09:59,680 --> 00:10:02,160
which is a team might have acknowledged

275
00:10:02,160 --> 00:10:03,760
that there was a risk here

276
00:10:03,760 --> 00:10:05,600
didn't think that it was going to

277
00:10:05,600 --> 00:10:07,120
actually result in a vulnerability but

278
00:10:07,120 --> 00:10:09,920
it did result in a vulnerability

279
00:10:09,920 --> 00:10:11,600
and then there's this last scenario

280
00:10:11,600 --> 00:10:13,519
which would be a truly

281
00:10:13,519 --> 00:10:15,200
novel vulnerability something new that

282
00:10:15,200 --> 00:10:16,560
has happened that we were totally

283
00:10:16,560 --> 00:10:17,519
unprepared for

284
00:10:17,519 --> 00:10:20,240
and this is a chance to learn from that

285
00:10:20,240 --> 00:10:20,640
so

286
00:10:20,640 --> 00:10:22,399
with that in mind that was our initial

287
00:10:22,399 --> 00:10:24,000
focus these you know we want to be able

288
00:10:24,000 --> 00:10:25,360
to take every issue and sort of

289
00:10:25,360 --> 00:10:27,200
categorize it into one of these

290
00:10:27,200 --> 00:10:29,920
buckets the question became how do we

291
00:10:29,920 --> 00:10:31,440
approach the problem in a way that lets

292
00:10:31,440 --> 00:10:32,000
us answer

293
00:10:32,000 --> 00:10:34,720
those questions for the highest number

294
00:10:34,720 --> 00:10:35,920
of

295
00:10:35,920 --> 00:10:38,079
vulnerabilities possible and so that

296
00:10:38,079 --> 00:10:39,680
sort of drove us to focus

297
00:10:39,680 --> 00:10:41,440
more on the quantity side of the

298
00:10:41,440 --> 00:10:43,600
equation as opposed to doing a deep

299
00:10:43,600 --> 00:10:44,480
analysis

300
00:10:44,480 --> 00:10:48,560
on the quality side of the equation

301
00:10:49,360 --> 00:10:51,600
what that gives us a chance to do is to

302
00:10:51,600 --> 00:10:53,760
turn our scalability problem

303
00:10:53,760 --> 00:10:56,240
into a solution into a feature so

304
00:10:56,240 --> 00:10:57,839
instead of being a problem it now

305
00:10:57,839 --> 00:11:00,560
becomes a selling point to say we have a

306
00:11:00,560 --> 00:11:01,839
lot of data

307
00:11:01,839 --> 00:11:03,440
coming out of this root cause analysis

308
00:11:03,440 --> 00:11:05,519
because we've decided specifically to

309
00:11:05,519 --> 00:11:08,880
gather it about so many issues

310
00:11:08,880 --> 00:11:10,800
so with that approach we really faced

311
00:11:10,800 --> 00:11:12,160
some early struggles and i wanted to

312
00:11:12,160 --> 00:11:13,839
document some of them here for you and

313
00:11:13,839 --> 00:11:15,120
every single one of these bullet points

314
00:11:15,120 --> 00:11:17,040
could be a hallway conversation or a

315
00:11:17,040 --> 00:11:18,399
whole slide on its own

316
00:11:18,399 --> 00:11:20,079
but i just want to run through them and

317
00:11:20,079 --> 00:11:21,600
give you a chance to see a little bit

318
00:11:21,600 --> 00:11:22,640
into how

319
00:11:22,640 --> 00:11:24,240
how this decision to do root cause

320
00:11:24,240 --> 00:11:25,920
analysis in this way

321
00:11:25,920 --> 00:11:27,360
led to led to some interesting

322
00:11:27,360 --> 00:11:29,360
conversations so the first one that i

323
00:11:29,360 --> 00:11:30,240
want to call out is

324
00:11:30,240 --> 00:11:32,959
messaging you use the word root cause

325
00:11:32,959 --> 00:11:33,839
analysis

326
00:11:33,839 --> 00:11:35,200
and people who have engineering

327
00:11:35,200 --> 00:11:36,880
backgrounds immediately think of

328
00:11:36,880 --> 00:11:38,480
a bunch of engineers huddled in a room

329
00:11:38,480 --> 00:11:40,560
with a door closed for a few days

330
00:11:40,560 --> 00:11:42,079
until they come back with a specific

331
00:11:42,079 --> 00:11:44,399
recommendation of exactly what procedure

332
00:11:44,399 --> 00:11:45,760
needs to change so that this

333
00:11:45,760 --> 00:11:47,680
never happens again and while that's

334
00:11:47,680 --> 00:11:49,519
certainly appropriate for some types of

335
00:11:49,519 --> 00:11:50,639
root cause analysis

336
00:11:50,639 --> 00:11:52,639
we were deliberately not targeting that

337
00:11:52,639 --> 00:11:54,639
type of situation here

338
00:11:54,639 --> 00:11:56,560
and so one of the things we did was

339
00:11:56,560 --> 00:11:58,639
start modifying the vocabulary when we

340
00:11:58,639 --> 00:12:00,480
talked about this we sort of drew this

341
00:12:00,480 --> 00:12:02,480
picture for people of multiple levels of

342
00:12:02,480 --> 00:12:04,079
root cause analysis where

343
00:12:04,079 --> 00:12:06,079
at you know the very top level is this

344
00:12:06,079 --> 00:12:07,519
level zero that gives you enough

345
00:12:07,519 --> 00:12:08,560
information

346
00:12:08,560 --> 00:12:11,360
to do to make some changes without

347
00:12:11,360 --> 00:12:13,360
needing to do that deep dive that we're

348
00:12:13,360 --> 00:12:14,399
talking about

349
00:12:14,399 --> 00:12:16,160
and once we started using that messaging

350
00:12:16,160 --> 00:12:17,519
it started becoming a little more clear

351
00:12:17,519 --> 00:12:20,720
what problem we're trying to solve

352
00:12:20,720 --> 00:12:22,560
another problem that we faced

353
00:12:22,560 --> 00:12:24,560
specifically at dell had to do with our

354
00:12:24,560 --> 00:12:26,160
asset categorization

355
00:12:26,160 --> 00:12:28,560
so when we started talking to different

356
00:12:28,560 --> 00:12:29,519
stakeholders

357
00:12:29,519 --> 00:12:31,519
it became immediately clear that there

358
00:12:31,519 --> 00:12:33,600
was different groups that cared about

359
00:12:33,600 --> 00:12:35,120
different types of assets when it came

360
00:12:35,120 --> 00:12:37,040
to doing root cause analysis

361
00:12:37,040 --> 00:12:40,720
so our initial focus as engineers was

362
00:12:40,720 --> 00:12:42,800
proprietary code we want to know what

363
00:12:42,800 --> 00:12:44,560
you know here's a chance where you guys

364
00:12:44,560 --> 00:12:46,320
were writing code and something went

365
00:12:46,320 --> 00:12:48,000
wrong and we want to help you fix it

366
00:12:48,000 --> 00:12:49,440
but it turns out though a lot of our

367
00:12:49,440 --> 00:12:51,519
application teams are doing some level

368
00:12:51,519 --> 00:12:52,639
of customization

369
00:12:52,639 --> 00:12:54,800
of off-the-shelf applications and

370
00:12:54,800 --> 00:12:56,639
there's just as many opportunities for

371
00:12:56,639 --> 00:12:58,000
things to go wrong there

372
00:12:58,000 --> 00:12:59,600
and those teams really want to learn

373
00:12:59,600 --> 00:13:01,120
from from the vulnerabilities that they

374
00:13:01,120 --> 00:13:02,160
face as well

375
00:13:02,160 --> 00:13:03,519
and so figuring out how to make that

376
00:13:03,519 --> 00:13:05,519
mixture and how to prioritize those

377
00:13:05,519 --> 00:13:08,320
issues is pretty important to us

378
00:13:08,320 --> 00:13:09,839
another problem we ran into once we

379
00:13:09,839 --> 00:13:11,360
started to scale this up

380
00:13:11,360 --> 00:13:13,040
was in normalizing the outcomes that

381
00:13:13,040 --> 00:13:15,360
come out of it so the initial impression

382
00:13:15,360 --> 00:13:16,560
to sort of get this

383
00:13:16,560 --> 00:13:18,639
process off the ground quickly was to

384
00:13:18,639 --> 00:13:21,200
sort of do this in a free-form way

385
00:13:21,200 --> 00:13:23,040
and let the engineers provide as much

386
00:13:23,040 --> 00:13:24,560
data as they wanted to but it became

387
00:13:24,560 --> 00:13:25,440
pretty important

388
00:13:25,440 --> 00:13:27,680
early on to sort of force people to put

389
00:13:27,680 --> 00:13:30,000
their answers into very specific buckets

390
00:13:30,000 --> 00:13:31,279
it was the only way we could deal with

391
00:13:31,279 --> 00:13:33,279
the scale that was going to come up

392
00:13:33,279 --> 00:13:36,240
one example of that would be we made a

393
00:13:36,240 --> 00:13:37,279
decision to sort of

394
00:13:37,279 --> 00:13:39,839
map every vulnerability as we already

395
00:13:39,839 --> 00:13:41,839
did for for normal procedures

396
00:13:41,839 --> 00:13:44,240
into a cwe and then once you have that

397
00:13:44,240 --> 00:13:45,120
cwe

398
00:13:45,120 --> 00:13:46,880
we can do some further automation and

399
00:13:46,880 --> 00:13:50,000
mapping based on that so take the cwe

400
00:13:50,000 --> 00:13:52,160
and map that to the specific security

401
00:13:52,160 --> 00:13:53,920
control that should have in theory

402
00:13:53,920 --> 00:13:54,800
prevented

403
00:13:54,800 --> 00:13:56,800
that common weakness enumeration that

404
00:13:56,800 --> 00:13:58,079
that error

405
00:13:58,079 --> 00:14:00,399
so if you say this particular

406
00:14:00,399 --> 00:14:01,760
vulnerability could have been prevented

407
00:14:01,760 --> 00:14:02,000
by

408
00:14:02,000 --> 00:14:03,920
these three different security practices

409
00:14:03,920 --> 00:14:06,000
and could have been tested for with this

410
00:14:06,000 --> 00:14:08,320
specific type of security testing that

411
00:14:08,320 --> 00:14:10,160
gives us a great place to start

412
00:14:10,160 --> 00:14:11,680
in having a deeper conversation with

413
00:14:11,680 --> 00:14:13,839
that product team even if we don't know

414
00:14:13,839 --> 00:14:14,480
for sure

415
00:14:14,480 --> 00:14:16,399
that that particular vulnerability could

416
00:14:16,399 --> 00:14:17,760
have been prevented by

417
00:14:17,760 --> 00:14:20,079
in that specific instance that specific

418
00:14:20,079 --> 00:14:22,639
sdl control

419
00:14:22,639 --> 00:14:24,160
another challenge that we had to face

420
00:14:24,160 --> 00:14:27,440
early on was building a starting point

421
00:14:27,440 --> 00:14:28,880
you take a procedure like this and

422
00:14:28,880 --> 00:14:30,959
describe it and people can start to

423
00:14:30,959 --> 00:14:32,880
understand what you're talking about

424
00:14:32,880 --> 00:14:35,920
but it doesn't give you data on day one

425
00:14:35,920 --> 00:14:37,680
this is a process that's going to take

426
00:14:37,680 --> 00:14:39,600
some time to build up over time

427
00:14:39,600 --> 00:14:41,680
and is interested in sort of historical

428
00:14:41,680 --> 00:14:44,720
trends and large scale

429
00:14:44,720 --> 00:14:46,079
you know what you're seeing on a larger

430
00:14:46,079 --> 00:14:47,839
scale and it's a little harder to sell

431
00:14:47,839 --> 00:14:49,519
that to somebody and explain that you're

432
00:14:49,519 --> 00:14:51,199
starting this up and that they might see

433
00:14:51,199 --> 00:14:53,199
some interesting data in three months

434
00:14:53,199 --> 00:14:55,040
so what we had to do was sort of go back

435
00:14:55,040 --> 00:14:57,440
in time and sort of do a what if what if

436
00:14:57,440 --> 00:14:58,959
we had been doing this procedure for the

437
00:14:58,959 --> 00:15:00,079
last six months

438
00:15:00,079 --> 00:15:02,079
what sort of data would we have gathered

439
00:15:02,079 --> 00:15:04,399
so we started collecting that data and

440
00:15:04,399 --> 00:15:06,560
you know took the engineers off offline

441
00:15:06,560 --> 00:15:08,079
a little bit and said go pretend that

442
00:15:08,079 --> 00:15:09,440
you're doing this root cause analysis

443
00:15:09,440 --> 00:15:09,839
you know

444
00:15:09,839 --> 00:15:12,240
go do it for these last six months worth

445
00:15:12,240 --> 00:15:13,600
of data so that we have some place to

446
00:15:13,600 --> 00:15:17,120
start when we have these conversations

447
00:15:17,120 --> 00:15:19,120
then once we actually had this rolling

448
00:15:19,120 --> 00:15:20,480
we started running into some different

449
00:15:20,480 --> 00:15:21,519
types of problems

450
00:15:21,519 --> 00:15:24,000
right so formalizing the handoff of of

451
00:15:24,000 --> 00:15:24,880
the data

452
00:15:24,880 --> 00:15:27,040
became immediately important so now we

453
00:15:27,040 --> 00:15:28,800
had all this data and immediately we had

454
00:15:28,800 --> 00:15:31,199
stakeholders lining up to ask for it

455
00:15:31,199 --> 00:15:32,720
and we had to figure out all kinds of

456
00:15:32,720 --> 00:15:34,079
interesting questions about who's going

457
00:15:34,079 --> 00:15:35,120
to consume

458
00:15:35,120 --> 00:15:38,160
this data and how this is where it

459
00:15:38,160 --> 00:15:39,440
becomes really important to sort of

460
00:15:39,440 --> 00:15:40,079
understand

461
00:15:40,079 --> 00:15:42,880
your own organization and where

462
00:15:42,880 --> 00:15:43,519
information

463
00:15:43,519 --> 00:15:44,880
how information flows through the

464
00:15:44,880 --> 00:15:47,360
organization who influences whom

465
00:15:47,360 --> 00:15:49,120
to figure out if i give this data to the

466
00:15:49,120 --> 00:15:50,399
governance organization

467
00:15:50,399 --> 00:15:51,920
are they going to make sure that it gets

468
00:15:51,920 --> 00:15:53,600
to the

469
00:15:53,600 --> 00:15:55,839
product teams in the right way if i give

470
00:15:55,839 --> 00:15:57,360
it to the

471
00:15:57,360 --> 00:15:59,920
sdl team that we talked about earlier

472
00:15:59,920 --> 00:16:01,040
are they going to share it

473
00:16:01,040 --> 00:16:04,160
with the team that handles education on

474
00:16:04,160 --> 00:16:06,079
the sdl practices or do we need to

475
00:16:06,079 --> 00:16:08,480
directly share it with that organization

476
00:16:08,480 --> 00:16:10,560
figuring all that out and coming up with

477
00:16:10,560 --> 00:16:12,720
good ways to formalize those handoffs is

478
00:16:12,720 --> 00:16:13,040
uh

479
00:16:13,040 --> 00:16:14,639
it's a continuing challenge to make sure

480
00:16:14,639 --> 00:16:16,480
that we we properly navigate the

481
00:16:16,480 --> 00:16:19,120
organization

482
00:16:19,360 --> 00:16:21,040
a good problem to have is everybody

483
00:16:21,040 --> 00:16:23,519
wants more so once we started providing

484
00:16:23,519 --> 00:16:24,399
this data

485
00:16:24,399 --> 00:16:26,240
people immediately started asking for

486
00:16:26,240 --> 00:16:28,959
more things so our initial focus was on

487
00:16:28,959 --> 00:16:32,160
externally found issues that arised from

488
00:16:32,160 --> 00:16:33,920
proprietary code and immediately people

489
00:16:33,920 --> 00:16:35,040
said well what about third-party

490
00:16:35,040 --> 00:16:36,079
components what about

491
00:16:36,079 --> 00:16:38,480
issues that are found internally and

492
00:16:38,480 --> 00:16:39,920
what about issues that are very

493
00:16:39,920 --> 00:16:41,360
interesting and deserve a deeper

494
00:16:41,360 --> 00:16:42,880
analysis how are you going to make sure

495
00:16:42,880 --> 00:16:44,160
that that happens

496
00:16:44,160 --> 00:16:46,079
so right away we had to start balancing

497
00:16:46,079 --> 00:16:47,519
expectations for how do you

498
00:16:47,519 --> 00:16:49,360
scale this operation up while we were

499
00:16:49,360 --> 00:16:50,800
still sort of

500
00:16:50,800 --> 00:16:52,320
getting it off the ground formalizing

501
00:16:52,320 --> 00:16:53,519
the handoff all the things that we just

502
00:16:53,519 --> 00:16:55,199
talked about

503
00:16:55,199 --> 00:16:56,639
and the last example which is a little

504
00:16:56,639 --> 00:16:58,800
amusing everybody wants

505
00:16:58,800 --> 00:17:01,920
examples of root cause analysis and

506
00:17:01,920 --> 00:17:03,199
i ran into that even while putting this

507
00:17:03,199 --> 00:17:05,119
presentation together

508
00:17:05,119 --> 00:17:06,959
so it's easy to sort of describe this

509
00:17:06,959 --> 00:17:08,400
process and then

510
00:17:08,400 --> 00:17:09,839
sort of explain that this is something

511
00:17:09,839 --> 00:17:12,640
that's meant to to show results over

512
00:17:12,640 --> 00:17:14,799
a large scale of data but immediately

513
00:17:14,799 --> 00:17:16,319
someone says well give me an example of

514
00:17:16,319 --> 00:17:17,679
an issue that you did a root cause

515
00:17:17,679 --> 00:17:19,679
analysis on and what you learned

516
00:17:19,679 --> 00:17:21,599
and sometimes it's hard to do that

517
00:17:21,599 --> 00:17:23,359
because the the

518
00:17:23,359 --> 00:17:25,599
pitch here is really about giving you a

519
00:17:25,599 --> 00:17:27,359
large set of data about all the issues

520
00:17:27,359 --> 00:17:28,720
that you faced over the last three

521
00:17:28,720 --> 00:17:29,520
months

522
00:17:29,520 --> 00:17:31,360
not about one specific issue that

523
00:17:31,360 --> 00:17:34,320
happened to be interesting

524
00:17:36,799 --> 00:17:38,880
so i apologize this is not my favorite

525
00:17:38,880 --> 00:17:39,919
slide

526
00:17:39,919 --> 00:17:41,679
but it does get the point across about

527
00:17:41,679 --> 00:17:43,760
how we sort of decided to add root cause

528
00:17:43,760 --> 00:17:44,480
analysis

529
00:17:44,480 --> 00:17:47,760
into our pcert workflow

530
00:17:47,760 --> 00:17:50,400
so anyone who's involved in pcr sort of

531
00:17:50,400 --> 00:17:52,559
recognizes this overall workflow i've

532
00:17:52,559 --> 00:17:54,080
described at the top here

533
00:17:54,080 --> 00:17:56,000
where you you take the issue in there's

534
00:17:56,000 --> 00:17:58,160
some triage and analysis

535
00:17:58,160 --> 00:17:59,919
the engineering team the product team

536
00:17:59,919 --> 00:18:01,840
does some remediation on the issue

537
00:18:01,840 --> 00:18:04,320
uh you have to release and disclose and

538
00:18:04,320 --> 00:18:05,919
then if there's some post remediation

539
00:18:05,919 --> 00:18:08,320
activities that have to take place

540
00:18:08,320 --> 00:18:10,080
what we wanted to do here with root

541
00:18:10,080 --> 00:18:12,240
cause analysis was instead of adding

542
00:18:12,240 --> 00:18:14,880
a whole new procedure into our world we

543
00:18:14,880 --> 00:18:16,240
wanted to sort of

544
00:18:16,240 --> 00:18:17,760
take some existing and some new

545
00:18:17,760 --> 00:18:19,919
stakeholders and sort of add some new

546
00:18:19,919 --> 00:18:20,559
actions

547
00:18:20,559 --> 00:18:23,600
into this process all along so that we

548
00:18:23,600 --> 00:18:24,400
could

549
00:18:24,400 --> 00:18:26,640
show value just by adding a little bit

550
00:18:26,640 --> 00:18:28,799
of incremental cost onto an existing

551
00:18:28,799 --> 00:18:30,080
workflow that was already pretty

552
00:18:30,080 --> 00:18:31,600
complicated

553
00:18:31,600 --> 00:18:34,080
so during the triage analysis phase for

554
00:18:34,080 --> 00:18:36,400
example we ask our pcert team

555
00:18:36,400 --> 00:18:38,320
to gather a little more information and

556
00:18:38,320 --> 00:18:39,840
provide a little more information do

557
00:18:39,840 --> 00:18:40,720
some digging

558
00:18:40,720 --> 00:18:42,240
what's the real world impact what are

559
00:18:42,240 --> 00:18:43,760
the weakness details those things they

560
00:18:43,760 --> 00:18:45,200
were already getting but now we're

561
00:18:45,200 --> 00:18:46,320
specifically

562
00:18:46,320 --> 00:18:48,080
asking to make sure that they have

563
00:18:48,080 --> 00:18:50,000
enough data to really feed the root

564
00:18:50,000 --> 00:18:51,840
cause analysis process

565
00:18:51,840 --> 00:18:53,120
we also ask for a little bit of

566
00:18:53,120 --> 00:18:54,640
historical data do a little bit of

567
00:18:54,640 --> 00:18:55,200
research

568
00:18:55,200 --> 00:18:56,960
based on what you know from this product

569
00:18:56,960 --> 00:18:58,400
team have they run into this type of

570
00:18:58,400 --> 00:18:59,600
problem before

571
00:18:59,600 --> 00:19:02,160
that might change how we think about the

572
00:19:02,160 --> 00:19:03,039
rest of the

573
00:19:03,039 --> 00:19:06,000
root cause analysis

574
00:19:06,240 --> 00:19:08,799
once the problem has been triaged once

575
00:19:08,799 --> 00:19:10,559
the development team is remediating it

576
00:19:10,559 --> 00:19:11,919
there's a whole bunch of new things that

577
00:19:11,919 --> 00:19:12,960
might happen

578
00:19:12,960 --> 00:19:14,720
we start pulling in and working more

579
00:19:14,720 --> 00:19:16,320
closely with our counterparts

580
00:19:16,320 --> 00:19:18,960
inside the sdl organization we start

581
00:19:18,960 --> 00:19:19,520
asking them

582
00:19:19,520 --> 00:19:21,840
questions about their engagements with

583
00:19:21,840 --> 00:19:22,720
this team

584
00:19:22,720 --> 00:19:24,960
what's happened in the past how this

585
00:19:24,960 --> 00:19:27,760
team is complying with the sdl controls

586
00:19:27,760 --> 00:19:29,440
they might have this information because

587
00:19:29,440 --> 00:19:31,360
they've worked with them as individuals

588
00:19:31,360 --> 00:19:32,960
they might have it because they have

589
00:19:32,960 --> 00:19:35,440
automated tools that track these things

590
00:19:35,440 --> 00:19:37,200
however they're doing it they have some

591
00:19:37,200 --> 00:19:38,160
level of information

592
00:19:38,160 --> 00:19:39,440
that they're willing to share with us

593
00:19:39,440 --> 00:19:40,960
and we work with them to try and figure

594
00:19:40,960 --> 00:19:42,320
that out

595
00:19:42,320 --> 00:19:45,039
we asked the development team earlier on

596
00:19:45,039 --> 00:19:46,559
how are you planning to fix this because

597
00:19:46,559 --> 00:19:47,919
that gives us a chance to provide

598
00:19:47,919 --> 00:19:48,559
feedback

599
00:19:48,559 --> 00:19:50,960
earlier we try to dig a little bit into

600
00:19:50,960 --> 00:19:52,320
based on all the things we've just

601
00:19:52,320 --> 00:19:54,080
learned what we think the technical root

602
00:19:54,080 --> 00:19:55,280
cause of the issue is

603
00:19:55,280 --> 00:19:57,280
and sort of confirm that with the dev

604
00:19:57,280 --> 00:19:58,880
team

605
00:19:58,880 --> 00:20:00,559
what this gives us a chance to do is

606
00:20:00,559 --> 00:20:02,320
sort of provide some just-in-time

607
00:20:02,320 --> 00:20:03,520
education

608
00:20:03,520 --> 00:20:05,679
we get a suggestion fixed perhaps we

609
00:20:05,679 --> 00:20:07,679
might offer that to the dev team

610
00:20:07,679 --> 00:20:09,200
but we also might be able to provide

611
00:20:09,200 --> 00:20:11,280
some just-in-time education to others in

612
00:20:11,280 --> 00:20:13,840
in there as well um they may be saying i

613
00:20:13,840 --> 00:20:15,360
plan to fix this by

614
00:20:15,360 --> 00:20:17,600
adding this filter or you know doing

615
00:20:17,600 --> 00:20:18,720
this deny list

616
00:20:18,720 --> 00:20:20,159
and we turn around and explain why it

617
00:20:20,159 --> 00:20:22,159
might be safer to use an allow list

618
00:20:22,159 --> 00:20:25,679
or to to not rely on on something or to

619
00:20:25,679 --> 00:20:27,120
build in some defense in depth whatever

620
00:20:27,120 --> 00:20:30,000
the example happens to be

621
00:20:30,000 --> 00:20:32,159
based on all that we then into the post

622
00:20:32,159 --> 00:20:34,000
remediation phase add a little more data

623
00:20:34,000 --> 00:20:36,640
gathering so we pull the actual details

624
00:20:36,640 --> 00:20:38,240
of what the fix was we're not talking

625
00:20:38,240 --> 00:20:40,000
about lines of code here but

626
00:20:40,000 --> 00:20:42,080
what did you actually do and then we

627
00:20:42,080 --> 00:20:43,840
make an assessment based on our

628
00:20:43,840 --> 00:20:46,320
expert knowledge of what we think this

629
00:20:46,320 --> 00:20:47,600
was supposed to do

630
00:20:47,600 --> 00:20:49,520
and that may give us some additional

631
00:20:49,520 --> 00:20:51,520
actions it may be that the team did

632
00:20:51,520 --> 00:20:53,039
something that we didn't recommend but

633
00:20:53,039 --> 00:20:54,640
they had their own business reasons for

634
00:20:54,640 --> 00:20:55,440
doing it

635
00:20:55,440 --> 00:20:58,480
in which case we may need to open up new

636
00:20:58,480 --> 00:21:00,159
vulnerabilities we may need to track

637
00:21:00,159 --> 00:21:02,000
things with the sdl team and explain

638
00:21:02,000 --> 00:21:03,520
that there are some changes that this

639
00:21:03,520 --> 00:21:05,039
team might need to make in the future

640
00:21:05,039 --> 00:21:06,559
because they made a decision

641
00:21:06,559 --> 00:21:10,399
that led to some residual risk

642
00:21:11,600 --> 00:21:14,240
so i know i mentioned examples as a

643
00:21:14,240 --> 00:21:15,520
problem earlier

644
00:21:15,520 --> 00:21:16,960
but i couldn't let this presentation go

645
00:21:16,960 --> 00:21:19,039
by without providing one example

646
00:21:19,039 --> 00:21:20,960
so here's an example of the sort of work

647
00:21:20,960 --> 00:21:22,640
that we might do with a specific

648
00:21:22,640 --> 00:21:24,320
vulnerability and this is a real

649
00:21:24,320 --> 00:21:27,840
real world example there was a

650
00:21:27,840 --> 00:21:31,919
specific storage product that we

651
00:21:31,919 --> 00:21:34,000
ran into an issue that was disclosed to

652
00:21:34,000 --> 00:21:35,840
us by researcher or customer

653
00:21:35,840 --> 00:21:37,679
actually don't remember which one it was

654
00:21:37,679 --> 00:21:39,200
that there was a port

655
00:21:39,200 --> 00:21:41,200
on that storage product that didn't

656
00:21:41,200 --> 00:21:43,200
require authentication

657
00:21:43,200 --> 00:21:45,120
and turns out it was uh it was meant to

658
00:21:45,120 --> 00:21:47,679
be on a management land and it was on

659
00:21:47,679 --> 00:21:50,080
a front-end land or something something

660
00:21:50,080 --> 00:21:51,200
similar to that

661
00:21:51,200 --> 00:21:52,559
and uh that was reported to us

662
00:21:52,559 --> 00:21:55,120
externally and we had to fix that issue

663
00:21:55,120 --> 00:21:58,480
and then disclose it via cve

664
00:21:58,480 --> 00:22:01,520
um so as we talked about sort of we have

665
00:22:01,520 --> 00:22:03,679
to bucketize that issue what did we

666
00:22:03,679 --> 00:22:06,480
what did we actually do wrong here and

667
00:22:06,480 --> 00:22:07,120
here

668
00:22:07,120 --> 00:22:09,600
as an effort to do that we looked at the

669
00:22:09,600 --> 00:22:11,840
cwe so we assigned it a common weakness

670
00:22:11,840 --> 00:22:13,039
enumeration

671
00:22:13,039 --> 00:22:15,840
668 exposure of resource to the wrong

672
00:22:15,840 --> 00:22:16,960
sphere

673
00:22:16,960 --> 00:22:18,480
and from that we could look up in our

674
00:22:18,480 --> 00:22:20,000
mapping table and say hey

675
00:22:20,000 --> 00:22:22,400
this team there was a design objective

676
00:22:22,400 --> 00:22:23,520
in our sdl

677
00:22:23,520 --> 00:22:25,360
standards that says you're supposed to

678
00:22:25,360 --> 00:22:27,039
be applying least privilege

679
00:22:27,039 --> 00:22:28,799
and then there are some verification

680
00:22:28,799 --> 00:22:30,960
activities that we recommend you do

681
00:22:30,960 --> 00:22:33,440
some tests that we recommend you run to

682
00:22:33,440 --> 00:22:35,120
verify that you have actually applied

683
00:22:35,120 --> 00:22:36,000
least privilege

684
00:22:36,000 --> 00:22:38,559
and some of those things might be manual

685
00:22:38,559 --> 00:22:40,720
or external security testing

686
00:22:40,720 --> 00:22:42,400
there might be some network scanning

687
00:22:42,400 --> 00:22:43,760
that you could do

688
00:22:43,760 --> 00:22:45,440
threat modeling is almost always an

689
00:22:45,440 --> 00:22:47,120
example of something you could do

690
00:22:47,120 --> 00:22:50,240
to detect that sort of problem so we

691
00:22:50,240 --> 00:22:50,720
want to

692
00:22:50,720 --> 00:22:53,600
did that assign those know that's in an

693
00:22:53,600 --> 00:22:54,080
automated

694
00:22:54,080 --> 00:22:55,760
fashion that just happens because once

695
00:22:55,760 --> 00:22:58,159
you know the cwe you can apply those

696
00:22:58,159 --> 00:23:00,799
those specific boxes so then we worked

697
00:23:00,799 --> 00:23:02,320
with our sdl team

698
00:23:02,320 --> 00:23:04,000
and asked them to take a look at the

699
00:23:04,000 --> 00:23:05,760
artifacts of their prior engagements

700
00:23:05,760 --> 00:23:07,440
with this organization and found that

701
00:23:07,440 --> 00:23:09,360
there was a threat model produced for

702
00:23:09,360 --> 00:23:10,799
this storage product

703
00:23:10,799 --> 00:23:13,760
but in this particular release that port

704
00:23:13,760 --> 00:23:15,200
somehow didn't make it into the threat

705
00:23:15,200 --> 00:23:16,640
model and it didn't show up during the

706
00:23:16,640 --> 00:23:18,640
review of the threat model and so

707
00:23:18,640 --> 00:23:21,440
looks like it was a manual error of some

708
00:23:21,440 --> 00:23:22,720
kind

709
00:23:22,720 --> 00:23:24,400
so once we got the fixed details

710
00:23:24,400 --> 00:23:26,400
provided and reviewed them and said yep

711
00:23:26,400 --> 00:23:27,919
that sounds like the right fix

712
00:23:27,919 --> 00:23:29,440
it seemed like then at that point we

713
00:23:29,440 --> 00:23:31,200
could make our conclusion

714
00:23:31,200 --> 00:23:33,200
so our root cause analysis conclusion we

715
00:23:33,200 --> 00:23:34,320
take that issue and put it in one of

716
00:23:34,320 --> 00:23:34,960
those

717
00:23:34,960 --> 00:23:36,880
sort of what happened buckets we talked

718
00:23:36,880 --> 00:23:38,080
about at the beginning

719
00:23:38,080 --> 00:23:40,400
and in this situation the team basically

720
00:23:40,400 --> 00:23:41,120
did the right

721
00:23:41,120 --> 00:23:43,760
things but there was a mistake made so

722
00:23:43,760 --> 00:23:45,200
there was an activity that was supposed

723
00:23:45,200 --> 00:23:47,039
to detect this threat modeling

724
00:23:47,039 --> 00:23:48,880
and there was an error made during the

725
00:23:48,880 --> 00:23:50,080
threat modeling exercise

726
00:23:50,080 --> 00:23:53,520
that led to this so this was a port that

727
00:23:53,520 --> 00:23:53,760
was

728
00:23:53,760 --> 00:23:56,240
missed and then we made a recommendation

729
00:23:56,240 --> 00:23:58,000
back to the dev team and to the

730
00:23:58,000 --> 00:23:59,919
the sdl organization that in the future

731
00:23:59,919 --> 00:24:01,679
with this team let you know double check

732
00:24:01,679 --> 00:24:03,200
and make sure when you're doing a threat

733
00:24:03,200 --> 00:24:04,400
model review

734
00:24:04,400 --> 00:24:05,840
make sure that there's a current network

735
00:24:05,840 --> 00:24:07,440
scan involved to make sure that nothing

736
00:24:07,440 --> 00:24:08,240
was missed

737
00:24:08,240 --> 00:24:10,000
and maybe that recommendation would also

738
00:24:10,000 --> 00:24:11,760
apply to other organizations

739
00:24:11,760 --> 00:24:13,120
and other times that you're doing threat

740
00:24:13,120 --> 00:24:18,960
model reviews

741
00:24:18,960 --> 00:24:21,520
so this is a bit of an eye chart but uh

742
00:24:21,520 --> 00:24:22,799
basically

743
00:24:22,799 --> 00:24:25,360
trying to sort of explain here now that

744
00:24:25,360 --> 00:24:26,799
we have all this data

745
00:24:26,799 --> 00:24:28,400
who's consuming it and who are the

746
00:24:28,400 --> 00:24:30,320
different stakeholders that we involve

747
00:24:30,320 --> 00:24:32,720
and what data do they need from us and

748
00:24:32,720 --> 00:24:34,559
what value are we trying to add

749
00:24:34,559 --> 00:24:37,279
to the security posture of dell by doing

750
00:24:37,279 --> 00:24:39,279
this root cause analysis

751
00:24:39,279 --> 00:24:41,840
so whether it's you know the team that

752
00:24:41,840 --> 00:24:43,600
does the secure development life cycle

753
00:24:43,600 --> 00:24:44,240
standards

754
00:24:44,240 --> 00:24:45,840
whether it's the team that manages

755
00:24:45,840 --> 00:24:48,000
educating teams on our security

756
00:24:48,000 --> 00:24:49,440
practices

757
00:24:49,440 --> 00:24:51,440
we also have the governance organization

758
00:24:51,440 --> 00:24:53,039
that interacts directly with the product

759
00:24:53,039 --> 00:24:54,000
teams

760
00:24:54,000 --> 00:24:57,760
at sort of a senior stakeholder level

761
00:24:57,760 --> 00:24:59,360
and executive level to say

762
00:24:59,360 --> 00:25:01,200
hey these these product teams aren't

763
00:25:01,200 --> 00:25:02,880
doing x y or z

764
00:25:02,880 --> 00:25:04,640
uh and you need to to sort of apply that

765
00:25:04,640 --> 00:25:06,799
pressure and of course our own pcert

766
00:25:06,799 --> 00:25:07,679
organization

767
00:25:07,679 --> 00:25:09,919
is a stakeholder as well we want data

768
00:25:09,919 --> 00:25:11,200
out of this process

769
00:25:11,200 --> 00:25:13,200
uh as well we want to learn from it and

770
00:25:13,200 --> 00:25:15,200
get some value from it

771
00:25:15,200 --> 00:25:17,200
so just going through some of the things

772
00:25:17,200 --> 00:25:18,480
that come out of it

773
00:25:18,480 --> 00:25:19,919
right we we know that there's some

774
00:25:19,919 --> 00:25:22,000
correlation to the different assessments

775
00:25:22,000 --> 00:25:23,520
that teams do

776
00:25:23,520 --> 00:25:26,640
with our sdl process we know that there

777
00:25:26,640 --> 00:25:28,400
might be novel vulnerabilities those are

778
00:25:28,400 --> 00:25:30,159
things the sdl team cares about

779
00:25:30,159 --> 00:25:31,840
quite a bit those are things that they

780
00:25:31,840 --> 00:25:33,279
would want to learn from and we share

781
00:25:33,279 --> 00:25:34,559
that information with them on a regular

782
00:25:34,559 --> 00:25:35,679
basis

783
00:25:35,679 --> 00:25:37,440
our folks who are responsible for our

784
00:25:37,440 --> 00:25:39,760
education want to know about gaps in our

785
00:25:39,760 --> 00:25:40,880
training

786
00:25:40,880 --> 00:25:42,159
is there things that we should be

787
00:25:42,159 --> 00:25:44,080
teaching people about better or things

788
00:25:44,080 --> 00:25:45,840
that we're just not teaching them about

789
00:25:45,840 --> 00:25:49,200
at all uh our product teams

790
00:25:49,200 --> 00:25:50,720
our governance teams and our peace

791
00:25:50,720 --> 00:25:53,679
organization they care a lot about risk

792
00:25:53,679 --> 00:25:56,400
right so whether these are risks that

793
00:25:56,400 --> 00:25:56,720
were

794
00:25:56,720 --> 00:25:58,320
acknowledged in the past that

795
00:25:58,320 --> 00:25:59,840
materialized and turned into a

796
00:25:59,840 --> 00:26:01,279
vulnerability that's an important piece

797
00:26:01,279 --> 00:26:02,799
of information for them

798
00:26:02,799 --> 00:26:05,200
it might be meaningful to go back to an

799
00:26:05,200 --> 00:26:07,200
executive who previously signed off on a

800
00:26:07,200 --> 00:26:07,919
risk

801
00:26:07,919 --> 00:26:10,320
and explained to them this risk that you

802
00:26:10,320 --> 00:26:11,679
acknowledged in the past

803
00:26:11,679 --> 00:26:13,440
actually materialized turned into a

804
00:26:13,440 --> 00:26:15,520
vulnerability was reported to us by a

805
00:26:15,520 --> 00:26:16,559
researcher

806
00:26:16,559 --> 00:26:18,720
was blogged about you know in the

807
00:26:18,720 --> 00:26:20,000
security blog

808
00:26:20,000 --> 00:26:21,919
and and gave us a black eye for a couple

809
00:26:21,919 --> 00:26:23,919
weeks in the press and you maybe could

810
00:26:23,919 --> 00:26:25,279
have prevented that by making a

811
00:26:25,279 --> 00:26:26,080
different decision

812
00:26:26,080 --> 00:26:28,320
now maybe that executive made the right

813
00:26:28,320 --> 00:26:29,840
decision maybe

814
00:26:29,840 --> 00:26:31,440
acknowledging that risk was the right

815
00:26:31,440 --> 00:26:33,360
chance to get that product out the door

816
00:26:33,360 --> 00:26:34,880
and that's you know that's their

817
00:26:34,880 --> 00:26:35,919
decision to make

818
00:26:35,919 --> 00:26:37,600
but i think there's some value to

819
00:26:37,600 --> 00:26:39,120
demonstrating what happened

820
00:26:39,120 --> 00:26:40,480
afterwards and giving them a chance to

821
00:26:40,480 --> 00:26:42,640
look back at it those

822
00:26:42,640 --> 00:26:44,559
same stakeholders obviously also care

823
00:26:44,559 --> 00:26:45,760
about new risks

824
00:26:45,760 --> 00:26:48,080
that are residual after making a fix so

825
00:26:48,080 --> 00:26:49,679
if part of our root cause analysis

826
00:26:49,679 --> 00:26:50,799
determines

827
00:26:50,799 --> 00:26:53,120
that this fix that was implemented

828
00:26:53,120 --> 00:26:54,400
wasn't complete

829
00:26:54,400 --> 00:26:55,600
we want to make sure that the right

830
00:26:55,600 --> 00:26:58,080
people are aware of that

831
00:26:58,080 --> 00:27:00,640
everybody follows this next piece of

832
00:27:00,640 --> 00:27:02,240
data right so we want to track what are

833
00:27:02,240 --> 00:27:03,440
the most common

834
00:27:03,440 --> 00:27:06,559
cwes that we run into the most common

835
00:27:06,559 --> 00:27:09,039
weaknesses that we we might see in the

836
00:27:09,039 --> 00:27:10,000
field

837
00:27:10,000 --> 00:27:12,799
and we make sure that we we track that

838
00:27:12,799 --> 00:27:16,080
information of what we run into

839
00:27:17,440 --> 00:27:20,159
from the sdl and education side also we

840
00:27:20,159 --> 00:27:22,080
want to keep track of which

841
00:27:22,080 --> 00:27:25,120
sdl controls and which activities

842
00:27:25,120 --> 00:27:28,480
fell short so in mass this data gives

843
00:27:28,480 --> 00:27:30,480
our sdl team and our education team a

844
00:27:30,480 --> 00:27:33,039
lot of places to poke and prod

845
00:27:33,039 --> 00:27:34,880
and make fine-tuned adjustments to what

846
00:27:34,880 --> 00:27:36,720
they're doing with our security

847
00:27:36,720 --> 00:27:37,600
education

848
00:27:37,600 --> 00:27:38,880
and with our secure development

849
00:27:38,880 --> 00:27:40,880
lifecycle standards it gives them a

850
00:27:40,880 --> 00:27:41,600
chance to

851
00:27:41,600 --> 00:27:43,520
to decide if there's some shifts that

852
00:27:43,520 --> 00:27:45,440
they want to make in how we're focusing

853
00:27:45,440 --> 00:27:46,880
those activities

854
00:27:46,880 --> 00:27:48,880
meanwhile along the same lines our

855
00:27:48,880 --> 00:27:50,799
product teams and our peace organization

856
00:27:50,799 --> 00:27:52,399
probably care a lot about similar

857
00:27:52,399 --> 00:27:54,559
vulnerabilities that our analysis might

858
00:27:54,559 --> 00:27:56,320
find by product line

859
00:27:56,320 --> 00:27:58,080
so if a particular product line a

860
00:27:58,080 --> 00:28:00,000
particular group of related products and

861
00:28:00,000 --> 00:28:01,600
applications is running into the same

862
00:28:01,600 --> 00:28:02,000
problem

863
00:28:02,000 --> 00:28:04,080
repeatedly that's something interesting

864
00:28:04,080 --> 00:28:05,840
that might drive a future conversation

865
00:28:05,840 --> 00:28:08,399
with that team

866
00:28:09,039 --> 00:28:11,039
this uh next item is something again

867
00:28:11,039 --> 00:28:12,559
everybody cares about

868
00:28:12,559 --> 00:28:14,159
right so we take all of the data that

869
00:28:14,159 --> 00:28:16,240
comes out of this process and pump it

870
00:28:16,240 --> 00:28:18,399
into a business intelligence application

871
00:28:18,399 --> 00:28:19,520
and then we can present

872
00:28:19,520 --> 00:28:21,919
sort of live sliced and diced data

873
00:28:21,919 --> 00:28:23,520
across a variety of

874
00:28:23,520 --> 00:28:26,799
axes so whether it's by date

875
00:28:26,799 --> 00:28:29,440
or by business unit by criticality by

876
00:28:29,440 --> 00:28:31,440
what type of reporter it was

877
00:28:31,440 --> 00:28:34,240
by cwe whatever it is we can sort of

878
00:28:34,240 --> 00:28:35,279
present that data

879
00:28:35,279 --> 00:28:37,520
and do custom dashboards for different

880
00:28:37,520 --> 00:28:38,559
stakeholders

881
00:28:38,559 --> 00:28:40,799
and everybody really is excited about

882
00:28:40,799 --> 00:28:42,480
the ability to sort of see that data and

883
00:28:42,480 --> 00:28:43,840
see it live

884
00:28:43,840 --> 00:28:47,520
being able to go into a business review

885
00:28:47,520 --> 00:28:49,440
with a product team and show them

886
00:28:49,440 --> 00:28:51,039
you know what's happened over the last

887
00:28:51,039 --> 00:28:52,960
six months with the vulnerabilities that

888
00:28:52,960 --> 00:28:54,240
have come in on the different products

889
00:28:54,240 --> 00:28:55,520
that they're responsible for

890
00:28:55,520 --> 00:28:58,559
it's a pretty compelling story and the

891
00:28:58,559 --> 00:28:59,919
last one is the one that i'm the most

892
00:28:59,919 --> 00:29:00,960
excited about

893
00:29:00,960 --> 00:29:02,399
is the ability to sort of provide

894
00:29:02,399 --> 00:29:04,799
just-in-time information based on the

895
00:29:04,799 --> 00:29:08,159
outcomes of these analyses so uh

896
00:29:08,159 --> 00:29:11,360
there's obviously in any group that you

897
00:29:11,360 --> 00:29:12,799
know the size of dell there's sort of a

898
00:29:12,799 --> 00:29:14,399
procedure for making sure how do we

899
00:29:14,399 --> 00:29:16,240
update our education how do we update

900
00:29:16,240 --> 00:29:17,679
our secure development lifecycle

901
00:29:17,679 --> 00:29:18,720
standards

902
00:29:18,720 --> 00:29:20,320
but there's also a chance to produce

903
00:29:20,320 --> 00:29:22,320
these you know bursts of information

904
00:29:22,320 --> 00:29:24,000
that are highly targeted and have to do

905
00:29:24,000 --> 00:29:25,520
with real world vulnerabilities that are

906
00:29:25,520 --> 00:29:26,399
coming in

907
00:29:26,399 --> 00:29:28,559
and we always had this capability before

908
00:29:28,559 --> 00:29:30,559
right if an engineer came to

909
00:29:30,559 --> 00:29:32,960
us and said hey i noticed this problem

910
00:29:32,960 --> 00:29:35,360
came up three times in the last year

911
00:29:35,360 --> 00:29:37,360
it would be nice to educate people about

912
00:29:37,360 --> 00:29:38,720
it but here

913
00:29:38,720 --> 00:29:40,480
it's more formalized we can hopefully

914
00:29:40,480 --> 00:29:41,840
see these things by

915
00:29:41,840 --> 00:29:43,919
finding patterns in the data and then we

916
00:29:43,919 --> 00:29:45,919
can look each quarter and say maybe it's

917
00:29:45,919 --> 00:29:47,279
a good time for us to

918
00:29:47,279 --> 00:29:49,440
to put together a short webinar about

919
00:29:49,440 --> 00:29:50,720
cross-site scripting because we're

920
00:29:50,720 --> 00:29:51,600
seeing it grow

921
00:29:51,600 --> 00:29:53,600
in these particular business units or

922
00:29:53,600 --> 00:29:55,120
maybe it's a good chance for us to put

923
00:29:55,120 --> 00:29:56,640
together a blog post

924
00:29:56,640 --> 00:29:58,480
about code signing and how important it

925
00:29:58,480 --> 00:30:00,480
is or about least privilege or

926
00:30:00,480 --> 00:30:01,919
whatever that the problem that we're

927
00:30:01,919 --> 00:30:03,840
seeing crop up more frequently happens

928
00:30:03,840 --> 00:30:04,799
to be

929
00:30:04,799 --> 00:30:07,039
so that is one of uh and the fact that

930
00:30:07,039 --> 00:30:08,000
that decision is not

931
00:30:08,000 --> 00:30:10,080
just based on one piece or an engineer

932
00:30:10,080 --> 00:30:11,120
catching something

933
00:30:11,120 --> 00:30:12,960
but rather by the relationship between

934
00:30:12,960 --> 00:30:14,240
our peacert organization

935
00:30:14,240 --> 00:30:16,000
and our sdl organization and the other

936
00:30:16,000 --> 00:30:17,440
stakeholders that we've talked about in

937
00:30:17,440 --> 00:30:18,320
this process

938
00:30:18,320 --> 00:30:23,600
i think it adds a lot of value

939
00:30:23,600 --> 00:30:25,679
so where are we and where are we going

940
00:30:25,679 --> 00:30:27,279
with this with this process as i

941
00:30:27,279 --> 00:30:28,080
mentioned

942
00:30:28,080 --> 00:30:29,360
this process is something we've been

943
00:30:29,360 --> 00:30:31,760
maturing over the last couple of years

944
00:30:31,760 --> 00:30:34,080
and uh it's it's really starting to uh

945
00:30:34,080 --> 00:30:35,520
to show some promise and people are

946
00:30:35,520 --> 00:30:36,960
really paying attention and interested

947
00:30:36,960 --> 00:30:37,760
in it

948
00:30:37,760 --> 00:30:39,520
so we are maturing this process as i

949
00:30:39,520 --> 00:30:41,120
mentioned we're getting it incorporated

950
00:30:41,120 --> 00:30:41,520
into

951
00:30:41,520 --> 00:30:44,159
every aspect of our piece workflow we're

952
00:30:44,159 --> 00:30:45,440
producing these live

953
00:30:45,440 --> 00:30:49,279
yeah we just have two okay

954
00:30:49,279 --> 00:30:51,440
thank you very much we're putting

955
00:30:51,440 --> 00:30:52,799
together these dashboards that i talked

956
00:30:52,799 --> 00:30:54,960
about in our business intelligence tools

957
00:30:54,960 --> 00:30:56,880
and we're really starting to evangelize

958
00:30:56,880 --> 00:30:58,080
that data and get it out to the

959
00:30:58,080 --> 00:30:59,519
different stakeholders who might care

960
00:30:59,519 --> 00:31:00,320
about it

961
00:31:00,320 --> 00:31:02,880
and part of that process is accepting

962
00:31:02,880 --> 00:31:05,120
feedback on on the data

963
00:31:05,120 --> 00:31:07,360
and uh learning from what different

964
00:31:07,360 --> 00:31:09,039
people need like i mentioned

965
00:31:09,039 --> 00:31:10,320
in even some of our earliest

966
00:31:10,320 --> 00:31:11,840
conversations we figured out that we

967
00:31:11,840 --> 00:31:13,200
were targeting some information that

968
00:31:13,200 --> 00:31:15,360
wasn't helpful to some business units

969
00:31:15,360 --> 00:31:17,279
and that we needed to sort of widen what

970
00:31:17,279 --> 00:31:19,279
we're looking for

971
00:31:19,279 --> 00:31:21,200
so that leads to the next step really

972
00:31:21,200 --> 00:31:23,279
sort of working with our stakeholders

973
00:31:23,279 --> 00:31:25,600
we have regular reviews set up to make

974
00:31:25,600 --> 00:31:27,600
sure that we're talking with our sdl

975
00:31:27,600 --> 00:31:28,080
team

976
00:31:28,080 --> 00:31:29,679
with our education folks with the

977
00:31:29,679 --> 00:31:31,120
governance organization

978
00:31:31,120 --> 00:31:32,480
we're making sure that the data is

979
00:31:32,480 --> 00:31:34,080
getting shared during regular business

980
00:31:34,080 --> 00:31:35,600
reviews

981
00:31:35,600 --> 00:31:38,159
and then what's next well we do know

982
00:31:38,159 --> 00:31:39,840
that we want to

983
00:31:39,840 --> 00:31:41,600
do these sort of deep dives that i

984
00:31:41,600 --> 00:31:42,880
talked about we want to identify

985
00:31:42,880 --> 00:31:44,320
candidates for really interesting

986
00:31:44,320 --> 00:31:46,159
problems and do those deeper dives

987
00:31:46,159 --> 00:31:47,679
so we've got to figure out how to modify

988
00:31:47,679 --> 00:31:49,360
the process to enable that and make sure

989
00:31:49,360 --> 00:31:50,720
that happens

990
00:31:50,720 --> 00:31:53,039
we want to widen the net and figure out

991
00:31:53,039 --> 00:31:54,640
what sort of problems we might want to

992
00:31:54,640 --> 00:31:55,200
try

993
00:31:55,200 --> 00:31:57,440
and attack that we're not looking at

994
00:31:57,440 --> 00:31:58,640
right now

995
00:31:58,640 --> 00:32:00,720
and we want to build up experts within

996
00:32:00,720 --> 00:32:02,320
our development teams who are capable of

997
00:32:02,320 --> 00:32:04,320
doing this sort of analysis on their own

998
00:32:04,320 --> 00:32:06,720
and driving it themselves so that we are

999
00:32:06,720 --> 00:32:08,240
not the only ones responsible for

1000
00:32:08,240 --> 00:32:09,360
driving the process

1001
00:32:09,360 --> 00:32:11,919
so maybe we do this top-level process

1002
00:32:11,919 --> 00:32:13,679
and we help our dev teams sort of do

1003
00:32:13,679 --> 00:32:14,880
those deeper level

1004
00:32:14,880 --> 00:32:17,200
analyses and then work out some way to

1005
00:32:17,200 --> 00:32:18,640
share the information back and forth

1006
00:32:18,640 --> 00:32:19,919
because

1007
00:32:19,919 --> 00:32:21,600
the data really has to be both within

1008
00:32:21,600 --> 00:32:23,279
the dev team and within the security

1009
00:32:23,279 --> 00:32:25,120
organization for us to really amplify

1010
00:32:25,120 --> 00:32:25,760
its value

1011
00:32:25,760 --> 00:32:29,120
throughout the whole company so

1012
00:32:29,120 --> 00:32:30,720
last slide really quickly what is the

1013
00:32:30,720 --> 00:32:33,039
data telling us so far there's not a lot

1014
00:32:33,039 --> 00:32:34,720
here that should be surprising

1015
00:32:34,720 --> 00:32:36,000
this sort of information that we're

1016
00:32:36,000 --> 00:32:37,279
seeing and stuff that the teams are

1017
00:32:37,279 --> 00:32:38,720
already pretty aware of

1018
00:32:38,720 --> 00:32:40,159
we know that the critical issues that

1019
00:32:40,159 --> 00:32:41,440
we're facing tend to come from

1020
00:32:41,440 --> 00:32:42,000
application

1021
00:32:42,000 --> 00:32:44,159
teams that don't have as formal

1022
00:32:44,159 --> 00:32:46,240
engagements with our sdl procedures as

1023
00:32:46,240 --> 00:32:47,440
some others do

1024
00:32:47,440 --> 00:32:49,279
we know that for teams that are already

1025
00:32:49,279 --> 00:32:50,720
pretty mature and and

1026
00:32:50,720 --> 00:32:52,640
following all the right practices they

1027
00:32:52,640 --> 00:32:54,080
probably are at a point where they need

1028
00:32:54,080 --> 00:32:56,080
to optimize that and do more security

1029
00:32:56,080 --> 00:32:58,399
testing and more fuzz testing

1030
00:32:58,399 --> 00:33:00,320
we know that researchers are pretty good

1031
00:33:00,320 --> 00:33:01,600
at finding issues that relate to

1032
00:33:01,600 --> 00:33:03,200
authentication and authorization again

1033
00:33:03,200 --> 00:33:05,360
no big surprise there

1034
00:33:05,360 --> 00:33:06,640
the sorts of environments that

1035
00:33:06,640 --> 00:33:08,080
researchers are attacking are slightly

1036
00:33:08,080 --> 00:33:09,440
different than the ones that developers

1037
00:33:09,440 --> 00:33:10,000
are testing

1038
00:33:10,000 --> 00:33:12,799
in and we have found a very small number

1039
00:33:12,799 --> 00:33:14,080
of issues that have

1040
00:33:14,080 --> 00:33:16,000
some newly residual risks so something

1041
00:33:16,000 --> 00:33:17,279
new that was discovered during root

1042
00:33:17,279 --> 00:33:19,200
cause analysis that we need to document

1043
00:33:19,200 --> 00:33:20,399
going forward

1044
00:33:20,399 --> 00:33:22,000
very small number but they are there so

1045
00:33:22,000 --> 00:33:23,679
it's good to see

1046
00:33:23,679 --> 00:33:25,279
but i think the real message is you know

1047
00:33:25,279 --> 00:33:26,720
ask us again in a year

1048
00:33:26,720 --> 00:33:28,080
we'll be maturing this process and

1049
00:33:28,080 --> 00:33:29,840
hopefully i'll have a chance to speak

1050
00:33:29,840 --> 00:33:32,959
again about this another time

1051
00:33:33,519 --> 00:33:36,080
thank you very much and i will be in the

1052
00:33:36,080 --> 00:33:37,679
work adventure platform answering

1053
00:33:37,679 --> 00:33:38,320
questions

1054
00:33:38,320 --> 00:33:41,360
after the session sounds good thank you

1055
00:33:41,360 --> 00:33:43,039
very much dave for sharing with us and

1056
00:33:43,039 --> 00:33:44,399
how the pc

1057
00:33:44,399 --> 00:33:46,240
at dell technologies does root cause

1058
00:33:46,240 --> 00:33:48,480
analysis i'm sure

1059
00:33:48,480 --> 00:33:51,039
our audience truly appreciates the

1060
00:33:51,039 --> 00:33:52,240
insights and

1061
00:33:52,240 --> 00:33:54,320
have learned a thing or two tonight so

1062
00:33:54,320 --> 00:33:55,760
or today um

1063
00:33:55,760 --> 00:33:57,440
and for the audience who is interested

1064
00:33:57,440 --> 00:33:59,200
to engage with today with david uh

1065
00:33:59,200 --> 00:34:00,960
please head to work adventure he'll be

1066
00:34:00,960 --> 00:34:01,279
there

1067
00:34:01,279 --> 00:34:03,360
to answer questions or have a discussion

1068
00:34:03,360 --> 00:34:04,480
with all of you

1069
00:34:04,480 --> 00:34:06,240
so thank you once again let's give him a

1070
00:34:06,240 --> 00:34:07,919
virtual round of applause thank you

1071
00:34:07,919 --> 00:34:08,639
david

1072
00:34:08,639 --> 00:34:11,679
thank you very much all right everybody

1073
00:34:11,679 --> 00:34:14,639
the program uh will continue uh with the

1074
00:34:14,639 --> 00:34:15,918
next presentation

1075
00:34:15,918 --> 00:34:19,359
uh we have um uh

1076
00:34:19,359 --> 00:34:22,719
now uh cleberson silva and nicole

1077
00:34:22,719 --> 00:34:26,320
rickman and they are both

1078
00:34:26,320 --> 00:34:29,359
um will be speaking on the

1079
00:34:29,359 --> 00:34:33,040
uh case rnp

1080
00:34:33,040 --> 00:34:35,359
experience in brazilian general data

1081
00:34:35,359 --> 00:34:36,560
protection law

1082
00:34:36,560 --> 00:34:40,639
uh lgpd compliance so

1083
00:34:40,639 --> 00:34:43,599
without further ado i would like to

1084
00:34:43,599 --> 00:34:44,159
invite

1085
00:34:44,159 --> 00:34:46,639
both of them to share their presentation

1086
00:34:46,639 --> 00:34:48,399
and and and start

1087
00:34:48,399 --> 00:35:03,839
sharing with us

1088
00:35:23,040 --> 00:35:31,839
we're seeing your your notes

1089
00:35:40,640 --> 00:35:44,560
hello hello everyone

1090
00:35:44,560 --> 00:35:48,000
hello yup we can hear you okay and

1091
00:35:48,000 --> 00:35:51,040
can you can you see my presentation here

1092
00:35:51,040 --> 00:35:52,640
i can see your presentation but we can

1093
00:35:52,640 --> 00:35:55,599
also see your notes maybe you can

1094
00:35:55,599 --> 00:36:13,839
share a different screen okay let me try

1095
00:37:03,040 --> 00:37:06,240
okay can you hear my presentation huh

1096
00:37:06,240 --> 00:37:09,839
yeah you know can you yeah

1097
00:37:09,920 --> 00:37:14,560
is that your slides yes

1098
00:37:18,160 --> 00:37:20,560
it's okay i think we're seeing something

1099
00:37:20,560 --> 00:37:22,560
as i'm not sure exactly but it's not i

1100
00:37:22,560 --> 00:37:24,240
don't think it's your slides that we're

1101
00:37:24,240 --> 00:37:26,399
seeing

1102
00:37:26,590 --> 00:37:29,679
[Music]

1103
00:37:30,800 --> 00:37:36,370
all these slides

1104
00:37:36,370 --> 00:37:39,529
[Music]

1105
00:37:49,200 --> 00:37:51,839
perfect go ahead

1106
00:38:02,839 --> 00:38:05,839
sauce

1107
00:38:30,839 --> 00:38:33,839
hmm

1108
00:38:51,760 --> 00:38:55,280
he can see the slides but he cannot see

1109
00:38:55,280 --> 00:38:58,079
the comments so he cannot

1110
00:38:58,079 --> 00:39:02,000
present all the slides

1111
00:39:02,000 --> 00:39:05,280
without his comments

1112
00:39:06,320 --> 00:39:06,690
um

1113
00:39:06,690 --> 00:39:09,809
[Music]

1114
00:40:39,599 --> 00:40:41,520
just a second everyone we're just

1115
00:40:41,520 --> 00:40:44,240
adjusting here some

1116
00:40:44,240 --> 00:40:49,359
screens will start in

1117
00:40:50,839 --> 00:40:53,839
nagorno

1118
00:41:04,839 --> 00:41:07,839
hotel

1119
00:41:18,839 --> 00:41:22,079
foreign see

1120
00:41:22,079 --> 00:41:24,319
okay

1121
00:41:26,960 --> 00:41:30,960
so let's start okay

1122
00:41:30,960 --> 00:41:34,400
sorry for then hello everyone

1123
00:41:34,400 --> 00:41:37,920
good morning and first it's a pleasure

1124
00:41:37,920 --> 00:41:38,240
to

1125
00:41:38,240 --> 00:41:41,599
to be here in my first

1126
00:41:41,599 --> 00:41:44,160
my first time on first conference i hope

1127
00:41:44,160 --> 00:41:46,079
you are

1128
00:41:46,079 --> 00:41:48,720
doing well and staying safe my name is

1129
00:41:48,720 --> 00:41:49,680
cleverson

1130
00:41:49,680 --> 00:41:53,119
i'm a information security analyst uh

1131
00:41:53,119 --> 00:41:56,640
on kaiser from rnp

1132
00:41:56,640 --> 00:42:00,000
and here today with me is my colleague

1133
00:42:00,000 --> 00:42:02,319
nicole hi nicole

1134
00:42:02,319 --> 00:42:04,720
hello everyone i'm a cyber security

1135
00:42:04,720 --> 00:42:05,359
analyst

1136
00:42:05,359 --> 00:42:09,119
at kaiser rnp brazil

1137
00:42:09,119 --> 00:42:12,160
and i'm sorry for the delay but we hope

1138
00:42:12,160 --> 00:42:13,119
you enjoy

1139
00:42:13,119 --> 00:42:16,160
our presentation

1140
00:42:16,160 --> 00:42:18,560
well together we are going to talk about

1141
00:42:18,560 --> 00:42:20,400
brazilian gdpr law

1142
00:42:20,400 --> 00:42:24,400
or lgbt as pronounced in brazil

1143
00:42:24,400 --> 00:42:28,839
and the the experience of kais and rnp

1144
00:42:28,839 --> 00:42:31,760
okay so

1145
00:42:31,760 --> 00:42:35,760
rnp or enep is the brazilian national

1146
00:42:35,760 --> 00:42:38,800
research and education network

1147
00:42:38,800 --> 00:42:41,520
and is the organization that plans

1148
00:42:41,520 --> 00:42:44,079
designs deploys and operates

1149
00:42:44,079 --> 00:42:47,520
the academic backbone that provides

1150
00:42:47,520 --> 00:42:51,599
access to federal and public university

1151
00:42:51,599 --> 00:42:54,400
universities and federal research

1152
00:42:54,400 --> 00:42:55,119
instituted

1153
00:42:55,119 --> 00:42:58,160
some private universities totalizing

1154
00:42:58,160 --> 00:43:02,000
almost 20 2500 units

1155
00:43:02,000 --> 00:43:05,839
as academic campus in the entire country

1156
00:43:05,839 --> 00:43:09,119
our backbone reaches all the 27

1157
00:43:09,119 --> 00:43:12,160
states of brazilian federation some with

1158
00:43:12,160 --> 00:43:14,000
more capacity than others

1159
00:43:14,000 --> 00:43:17,599
but always in constant expansion

1160
00:43:17,599 --> 00:43:20,640
as part of our backbone already has

1161
00:43:20,640 --> 00:43:26,240
traffic at 100 gbps

1162
00:43:26,240 --> 00:43:29,200
i'll tell you about kais kais is the

1163
00:43:29,200 --> 00:43:30,800
incident his boss team

1164
00:43:30,800 --> 00:43:33,440
of brazil his certain educational

1165
00:43:33,440 --> 00:43:34,640
network

1166
00:43:34,640 --> 00:43:37,680
we are on the road for 25 years

1167
00:43:37,680 --> 00:43:40,480
and we manage the information security

1168
00:43:40,480 --> 00:43:41,520
incidents

1169
00:43:41,520 --> 00:43:44,720
and also offer technical support

1170
00:43:44,720 --> 00:43:48,319
security awareness to users and

1171
00:43:48,319 --> 00:43:51,359
security vulnerability handling

1172
00:43:51,359 --> 00:43:54,960
then i invite you to visit our page and

1173
00:43:54,960 --> 00:43:58,560
learn more about guys okay

1174
00:44:05,839 --> 00:44:10,079
the eligibility is inspired

1175
00:44:10,079 --> 00:44:13,119
by the european regulation

1176
00:44:13,119 --> 00:44:17,359
and gdpr as already we told you

1177
00:44:17,359 --> 00:44:21,520
the lgbt was approved in august 2018

1178
00:44:21,520 --> 00:44:24,480
it applies to any business organization

1179
00:44:24,480 --> 00:44:24,800
that

1180
00:44:24,800 --> 00:44:28,400
processes personal data data in brazil

1181
00:44:28,400 --> 00:44:31,680
in other words it regulates the

1182
00:44:31,680 --> 00:44:33,680
the activities of personal data

1183
00:44:33,680 --> 00:44:34,960
treatment in brazil

1184
00:44:34,960 --> 00:44:38,240
so if the company has any customers

1185
00:44:38,240 --> 00:44:41,599
or clients in brazil or offers services

1186
00:44:41,599 --> 00:44:42,160
or have

1187
00:44:42,160 --> 00:44:45,440
operations involving data it should

1188
00:44:45,440 --> 00:44:48,839
begin preparing for

1189
00:44:48,839 --> 00:44:51,839
lgbt

1190
00:44:53,280 --> 00:44:56,560
lgpd lgpd defines

1191
00:44:56,560 --> 00:44:59,280
authorized legal basis principle of

1192
00:44:59,280 --> 00:45:01,160
personal data processing

1193
00:45:01,160 --> 00:45:04,480
activities rights of personal data

1194
00:45:04,480 --> 00:45:07,520
subjects and guarantee of risk handling

1195
00:45:07,520 --> 00:45:10,000
and security controls in personal data

1196
00:45:10,000 --> 00:45:12,640
processing

1197
00:45:13,839 --> 00:45:17,119
what is the punishment applied by the

1198
00:45:17,119 --> 00:45:19,920
the law companies that violate the

1199
00:45:19,920 --> 00:45:20,960
elisha pda

1200
00:45:20,960 --> 00:45:24,079
will be subjected to the applications of

1201
00:45:24,079 --> 00:45:25,119
warnings

1202
00:45:25,119 --> 00:45:28,880
fines suspensions and partial

1203
00:45:28,880 --> 00:45:32,400
total bans to perform their activities

1204
00:45:32,400 --> 00:45:35,599
findings can reach a picture

1205
00:45:35,599 --> 00:45:39,040
of the organization's heavenly with a

1206
00:45:39,040 --> 00:45:39,599
limit

1207
00:45:39,599 --> 00:45:47,839
of 50 million per violation

1208
00:45:48,480 --> 00:45:51,680
uh the academic network

1209
00:45:51,680 --> 00:45:55,359
every enep

1210
00:45:55,359 --> 00:45:59,119
or rnp handles personal data in internal

1211
00:45:59,119 --> 00:46:02,880
processes and provides advanced i.t

1212
00:46:02,880 --> 00:46:03,680
services

1213
00:46:03,680 --> 00:46:06,800
to brazilian academic community that

1214
00:46:06,800 --> 00:46:09,359
handles some personal data

1215
00:46:09,359 --> 00:46:12,400
and the academic institutions can handle

1216
00:46:12,400 --> 00:46:14,640
students teachers researchers and

1217
00:46:14,640 --> 00:46:15,280
employees

1218
00:46:15,280 --> 00:46:18,640
personal data in its administrative

1219
00:46:18,640 --> 00:46:22,000
groups administrative processes

1220
00:46:22,000 --> 00:46:24,240
and can collect and handle personal data

1221
00:46:24,240 --> 00:46:25,040
of research

1222
00:46:25,040 --> 00:46:29,680
activities or public health context

1223
00:46:31,280 --> 00:46:34,319
we address the challenge of support

1224
00:46:34,319 --> 00:46:34,880
challenges

1225
00:46:34,880 --> 00:46:37,760
the compliance actions through foreign

1226
00:46:37,760 --> 00:46:39,359
fronts

1227
00:46:39,359 --> 00:46:42,720
rmp internal adequacy

1228
00:46:42,720 --> 00:46:45,760
rnp consulting as a services

1229
00:46:45,760 --> 00:46:48,960
this front has specialists on the topic

1230
00:46:48,960 --> 00:46:51,599
to support research and education

1231
00:46:51,599 --> 00:46:52,640
organizations

1232
00:46:52,640 --> 00:46:57,359
and the work of the adequacy

1233
00:46:57,359 --> 00:47:00,800
privacy training and the last one

1234
00:47:00,800 --> 00:47:03,839
development of lgbt implementation

1235
00:47:03,839 --> 00:47:04,800
method

1236
00:47:04,800 --> 00:47:08,400
for customers use this front helps

1237
00:47:08,400 --> 00:47:11,920
to share knowledge and provide inputs

1238
00:47:11,920 --> 00:47:15,200
workshops study groups and training

1239
00:47:15,200 --> 00:47:15,599
about

1240
00:47:15,599 --> 00:47:19,440
privacy and data protection to prepare

1241
00:47:19,440 --> 00:47:22,839
the institutions to adequate to

1242
00:47:22,839 --> 00:47:25,839
themselves

1243
00:47:26,079 --> 00:47:29,520
beginning the data map

1244
00:47:31,200 --> 00:47:34,559
the data mapping is very important to

1245
00:47:34,559 --> 00:47:37,839
to view and identify how the personal

1246
00:47:37,839 --> 00:47:40,558
data flows

1247
00:47:41,440 --> 00:47:45,440
inside the rnp works the company works

1248
00:47:45,440 --> 00:47:48,160
once you have this understanding you can

1249
00:47:48,160 --> 00:47:50,079
make a strategic plan

1250
00:47:50,079 --> 00:47:53,440
to answer some questions like

1251
00:47:53,440 --> 00:47:56,559
how much effort do you need to adequate

1252
00:47:56,559 --> 00:48:00,000
your environment how many resources

1253
00:48:00,000 --> 00:48:04,079
do you need to elicit the adequacy

1254
00:48:04,079 --> 00:48:08,400
how to begin living adequacy

1255
00:48:13,280 --> 00:48:16,480
well here in this illustration

1256
00:48:16,480 --> 00:48:19,599
uh shows we did some steps

1257
00:48:19,599 --> 00:48:23,520
to perform the data mapping

1258
00:48:23,839 --> 00:48:26,960
here we have the first step uh

1259
00:48:26,960 --> 00:48:29,520
identify the focal points inside the

1260
00:48:29,520 --> 00:48:30,160
company

1261
00:48:30,160 --> 00:48:32,839
and answer some questions about the

1262
00:48:32,839 --> 00:48:35,200
workflow

1263
00:48:35,200 --> 00:48:38,240
second step

1264
00:48:38,240 --> 00:48:42,000
sending sending the the data mapping

1265
00:48:42,000 --> 00:48:44,559
spreadsheet

1266
00:48:44,559 --> 00:48:47,920
show them third

1267
00:48:47,920 --> 00:48:52,079
stepping schedule an interview to

1268
00:48:52,079 --> 00:48:54,079
validate the understanding

1269
00:48:54,079 --> 00:48:57,760
and consolidate the data map

1270
00:48:57,760 --> 00:49:00,880
and perform and the last one perform the

1271
00:49:00,880 --> 00:49:03,839
risk analysis

1272
00:49:04,559 --> 00:49:07,680
so as you can see in this

1273
00:49:07,680 --> 00:49:11,280
illustration here of data map

1274
00:49:11,280 --> 00:49:14,319
can show you the method the methodology

1275
00:49:14,319 --> 00:49:15,200
used

1276
00:49:15,200 --> 00:49:18,480
according to the the label

1277
00:49:18,480 --> 00:49:21,520
in the right side here we have the blue

1278
00:49:21,520 --> 00:49:22,720
circles

1279
00:49:22,720 --> 00:49:26,079
representing the software yellow cycles

1280
00:49:26,079 --> 00:49:29,520
representing the hardware

1281
00:49:29,520 --> 00:49:32,880
light orange representing the area

1282
00:49:32,880 --> 00:49:36,800
or departments so

1283
00:49:36,800 --> 00:49:40,000
you can also see the small in small

1284
00:49:40,000 --> 00:49:41,680
green circles here

1285
00:49:41,680 --> 00:49:45,680
the d1 d2 d3

1286
00:49:45,680 --> 00:49:49,359
and representing the type of data

1287
00:49:49,359 --> 00:49:52,960
as d1 and for

1288
00:49:52,960 --> 00:49:56,640
as d1 represents employees d2

1289
00:49:56,640 --> 00:50:01,920
for partners d3 for external users

1290
00:50:01,920 --> 00:50:04,160
in this example we have three internal

1291
00:50:04,160 --> 00:50:05,280
systems

1292
00:50:05,280 --> 00:50:08,880
uh inside the the data center system

1293
00:50:08,880 --> 00:50:12,559
system a system b system

1294
00:50:12,559 --> 00:50:16,319
b and the corporate email

1295
00:50:16,319 --> 00:50:19,440
starring in the public cloud corporation

1296
00:50:19,440 --> 00:50:20,800
may here

1297
00:50:20,800 --> 00:50:24,160
is starring in the public cloud and also

1298
00:50:24,160 --> 00:50:27,520
on a external agent

1299
00:50:27,520 --> 00:50:31,359
and here you have it obsolete

1300
00:50:31,359 --> 00:50:34,400
we also can see you can see the

1301
00:50:34,400 --> 00:50:37,280
arrows pointing the data flows

1302
00:50:37,280 --> 00:50:38,720
directions

1303
00:50:38,720 --> 00:50:42,960
the area point uh using the

1304
00:50:42,960 --> 00:50:46,800
system system b

1305
00:50:46,800 --> 00:50:50,160
the area using the

1306
00:50:50,160 --> 00:50:54,000
corporate email and receiving the mail

1307
00:50:54,000 --> 00:50:57,680
to for another areas

1308
00:50:57,680 --> 00:51:01,839
or external urgencies

1309
00:51:04,559 --> 00:51:08,640
so after the data mapping consolidated

1310
00:51:08,640 --> 00:51:11,839
the risk analysis

1311
00:51:13,119 --> 00:51:15,280
the risk analysis was performed

1312
00:51:15,280 --> 00:51:16,400
considering

1313
00:51:16,400 --> 00:51:19,760
the probability to

1314
00:51:19,760 --> 00:51:24,880
possible data leak of personal data

1315
00:51:25,119 --> 00:51:27,760
this this possible data leak of personal

1316
00:51:27,760 --> 00:51:28,480
data

1317
00:51:28,480 --> 00:51:32,079
includes all all circles

1318
00:51:32,079 --> 00:51:35,760
all points here

1319
00:51:35,760 --> 00:51:38,960
in the data mapping number of

1320
00:51:38,960 --> 00:51:42,160
iq systems not approved used

1321
00:51:42,160 --> 00:51:45,440
to data choice or data

1322
00:51:45,440 --> 00:51:48,480
data leak points in a external

1323
00:51:48,480 --> 00:51:49,599
environment

1324
00:51:49,599 --> 00:51:52,000
here in this example we have the office

1325
00:51:52,000 --> 00:51:54,240
law

1326
00:51:54,880 --> 00:51:57,680
and data leak points outside the

1327
00:51:57,680 --> 00:51:58,880
vulnerability

1328
00:51:58,880 --> 00:52:02,240
management process and the

1329
00:52:02,240 --> 00:52:07,680
percentage of lgpd adequacy planned rom

1330
00:52:10,880 --> 00:52:13,920
the impact impact consists

1331
00:52:13,920 --> 00:52:17,200
in personal sensitive data

1332
00:52:17,200 --> 00:52:20,400
where sensitive data values

1333
00:52:20,400 --> 00:52:23,599
10 and no sensitive data valued

1334
00:52:23,599 --> 00:52:28,319
one quantity of personal data

1335
00:52:28,319 --> 00:52:31,200
number of different types of personal

1336
00:52:31,200 --> 00:52:31,920
data

1337
00:52:31,920 --> 00:52:35,440
in this example we have a three employee

1338
00:52:35,440 --> 00:52:39,839
partners and external agents

1339
00:52:42,640 --> 00:52:46,480
and as you as hazut the probability

1340
00:52:46,480 --> 00:52:49,839
verse versus impact gave us the

1341
00:52:49,839 --> 00:52:52,960
understanding to putting harding

1342
00:52:52,960 --> 00:52:56,400
supporting order and classify the most

1343
00:52:56,400 --> 00:52:59,920
critical areas and the most critical

1344
00:52:59,920 --> 00:53:00,720
systems

1345
00:53:00,720 --> 00:53:05,279
to prioritize its adequacy

1346
00:53:12,640 --> 00:53:16,240
until now uh all data mapping was done

1347
00:53:16,240 --> 00:53:19,440
inside the rnp along six

1348
00:53:19,440 --> 00:53:22,480
months and we got some some

1349
00:53:22,480 --> 00:53:25,760
numbers inside uh some numbers inside

1350
00:53:25,760 --> 00:53:27,040
rnp

1351
00:53:27,040 --> 00:53:30,640
76 spreadsheets fulfilled

1352
00:53:30,640 --> 00:53:34,480
36 interviewed areas

1353
00:53:34,480 --> 00:53:37,520
processing of five types of personal

1354
00:53:37,520 --> 00:53:39,839
data identified

1355
00:53:39,839 --> 00:53:43,040
processing of three types of sensitivity

1356
00:53:43,040 --> 00:53:46,079
personal data identified

1357
00:53:46,079 --> 00:53:50,559
86 iq systems mapped

1358
00:53:50,559 --> 00:53:54,319
58 ic systems that process

1359
00:53:54,319 --> 00:53:56,960
that process a personal dating identify

1360
00:53:56,960 --> 00:53:59,119
it

1361
00:53:59,440 --> 00:54:03,119
and the as the result we got

1362
00:54:03,119 --> 00:54:06,319
10 um 10 mos

1363
00:54:06,319 --> 00:54:09,359
10 most critical areas and 10 most

1364
00:54:09,359 --> 00:54:10,000
critical

1365
00:54:10,000 --> 00:54:13,040
systems to prioritize to prioritize

1366
00:54:13,040 --> 00:54:16,480
to eligibility adequates also i'll tell

1367
00:54:16,480 --> 00:54:17,839
you

1368
00:54:17,839 --> 00:54:20,960
i'll tell you some benefits obtained

1369
00:54:20,960 --> 00:54:24,720
with data mapping good understanding

1370
00:54:24,720 --> 00:54:27,839
uh of how data moves in

1371
00:54:27,839 --> 00:54:31,040
and out inside the company view

1372
00:54:31,040 --> 00:54:34,079
and documentation of data life cycle

1373
00:54:34,079 --> 00:54:37,680
from collection use it

1374
00:54:37,680 --> 00:54:41,359
starting and the

1375
00:54:41,359 --> 00:54:44,480
understanding of relationships

1376
00:54:44,480 --> 00:54:47,680
of our companies processes

1377
00:54:47,680 --> 00:54:53,839
systems and areas

1378
00:54:59,599 --> 00:55:02,720
beside all that we

1379
00:55:02,720 --> 00:55:06,160
have the training the network academic

1380
00:55:06,160 --> 00:55:06,720
school

1381
00:55:06,720 --> 00:55:10,160
esr as a unit from rnp

1382
00:55:10,160 --> 00:55:12,960
provides to academic community training

1383
00:55:12,960 --> 00:55:13,520
about

1384
00:55:13,520 --> 00:55:17,280
privacy and data protection for managers

1385
00:55:17,280 --> 00:55:20,880
data protection officers or dpos

1386
00:55:20,880 --> 00:55:24,559
and other public or private stakeholders

1387
00:55:24,559 --> 00:55:27,760
more than 150 professionals were trained

1388
00:55:27,760 --> 00:55:35,839
until now

1389
00:55:40,400 --> 00:55:43,839
um our goal support brazilian academic

1390
00:55:43,839 --> 00:55:45,200
community to be

1391
00:55:45,200 --> 00:55:48,559
compliance with lgbt and more

1392
00:55:48,559 --> 00:55:51,680
help create a privacy future

1393
00:55:51,680 --> 00:55:54,960
in their entire activities

1394
00:55:54,960 --> 00:55:58,640
sure sure uh practical experience

1395
00:55:58,640 --> 00:56:03,520
acquired in the adequacy process

1396
00:56:03,520 --> 00:56:06,160
and work work together with the other

1397
00:56:06,160 --> 00:56:07,839
organizations to

1398
00:56:07,839 --> 00:56:17,839
improve the privacy governance

1399
00:56:23,119 --> 00:56:26,650
and that's all thank you very much

1400
00:56:26,650 --> 00:56:28,079
[Music]

1401
00:56:28,079 --> 00:56:31,359
everybody have any questions

1402
00:56:31,359 --> 00:56:34,400
thank you claberson and nicole um

1403
00:56:34,400 --> 00:56:38,079
for sharing um yeah for sharing uh some

1404
00:56:38,079 --> 00:56:39,200
insights on how

1405
00:56:39,200 --> 00:56:42,000
um you guys are dealing with the uh the

1406
00:56:42,000 --> 00:56:43,920
laws there

1407
00:56:43,920 --> 00:56:46,799
for qna if people would like to ask

1408
00:56:46,799 --> 00:56:47,839
questions

1409
00:56:47,839 --> 00:56:51,040
all the q a is done in work adventure or

1410
00:56:51,040 --> 00:56:52,319
social

1411
00:56:52,319 --> 00:56:54,880
engagement platform so if you can all

1412
00:56:54,880 --> 00:56:56,400
head there

1413
00:56:56,400 --> 00:56:58,000
i guess the participants will be there

1414
00:56:58,000 --> 00:56:59,599
to ask questions

1415
00:56:59,599 --> 00:57:02,160
uh once again we'd like to thank you uh

1416
00:57:02,160 --> 00:57:02,960
for your

1417
00:57:02,960 --> 00:57:06,559
um your time and um and spending

1418
00:57:06,559 --> 00:57:09,599
the time to prepare and give um give the

1419
00:57:09,599 --> 00:57:10,799
presentation to

1420
00:57:10,799 --> 00:57:13,839
the first audience tonight thank you

1421
00:57:13,839 --> 00:57:15,359
once again

1422
00:57:15,359 --> 00:57:18,640
thank you thank you very much all right

1423
00:57:18,640 --> 00:57:21,440
over to you josh

1424
00:57:24,079 --> 00:57:25,599
all right we're going to take about a 20

1425
00:57:25,599 --> 00:57:27,520
minute break and then we have our

1426
00:57:27,520 --> 00:57:29,280
panel session that will start in

1427
00:57:29,280 --> 00:57:30,640
breakout room one

1428
00:57:30,640 --> 00:57:31,520
and that's going to be the only one

1429
00:57:31,520 --> 00:57:32,960
that's going to happen over the next

1430
00:57:32,960 --> 00:57:34,160
hour

1431
00:57:34,160 --> 00:57:38,839
we'll see you there thank you thank you

1432
00:57:38,839 --> 00:57:41,839
everyone

1433
00:57:44,880 --> 00:57:46,960
you

