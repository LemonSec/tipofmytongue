1
00:00:00,000 --> 00:00:03,529
on Sunday at the Icebreaker I was

2
00:00:03,529 --> 00:00:05,670
particularly thanked for having got

3
00:00:05,670 --> 00:00:08,220
today's keynote speaker along because

4
00:00:08,220 --> 00:00:13,400
for the last few years she has been a

5
00:00:13,400 --> 00:00:16,890
interested observer and commentator on

6
00:00:16,890 --> 00:00:19,680
this community hope is a reasonable

7
00:00:19,680 --> 00:00:22,550
description wrote a really good paper

8
00:00:22,550 --> 00:00:26,960
just published last year I think yeah on

9
00:00:26,960 --> 00:00:31,410
how this community can do stuff that

10
00:00:31,410 --> 00:00:34,170
other more formal entities may not be

11
00:00:34,170 --> 00:00:38,149
able to do so highly recommended very

12
00:00:38,149 --> 00:00:41,030
interesting to have insights from

13
00:00:41,030 --> 00:00:44,670
outside sort of the core first community

14
00:00:44,670 --> 00:00:46,469
and it struck me that's actually a theme

15
00:00:46,469 --> 00:00:49,260
to all of our keynotes this week but

16
00:00:49,260 --> 00:00:53,280
they are all people from outside are on

17
00:00:53,280 --> 00:00:56,340
the edge of the incident response

18
00:00:56,340 --> 00:00:59,579
community telling us what we look like

19
00:00:59,579 --> 00:01:01,739
from the outside or what issues might be

20
00:01:01,739 --> 00:01:05,820
coming along to that we need to take a

21
00:01:05,820 --> 00:01:09,900
look at so delighted to welcome their

22
00:01:09,900 --> 00:01:13,170
innate answer from the fascinatingly

23
00:01:13,170 --> 00:01:15,380
named once you get to the end of it

24
00:01:15,380 --> 00:01:18,030
center of excellence foresight science

25
00:01:18,030 --> 00:01:21,390
technology so far so normal and a public

26
00:01:21,390 --> 00:01:24,360
policy which is the twist that makes it

27
00:01:24,360 --> 00:01:26,130
a really interesting place to keep an

28
00:01:26,130 --> 00:01:28,049
eye on at the University College of

29
00:01:28,049 --> 00:01:30,430
London Leonie

30
00:01:30,430 --> 00:01:37,330
[Applause]

31
00:01:37,330 --> 00:01:40,700
brilliant well that was nerve-wracking

32
00:01:40,700 --> 00:01:44,000
for so many admin stuff before I was

33
00:01:44,000 --> 00:01:46,130
able to speak to you

34
00:01:46,130 --> 00:01:48,320
so thank you very much Indra for the

35
00:01:48,320 --> 00:01:50,180
introduction as Andrew said my name is

36
00:01:50,180 --> 00:01:54,430
Leonie tan sir I'm lecture at UCL and

37
00:01:54,430 --> 00:01:57,050
yeah I'm really delighted to be here

38
00:01:57,050 --> 00:01:59,570
extremely intimidated as well certainly

39
00:01:59,570 --> 00:02:02,150
my lecture halls are not as big and the

40
00:02:02,150 --> 00:02:05,270
CCT see talking that I did once was in

41
00:02:05,270 --> 00:02:06,650
the morning at the 11:00 a.m. and there

42
00:02:06,650 --> 00:02:09,949
was nobody there so this is a kind of

43
00:02:09,949 --> 00:02:13,190
new experience for me I know that the

44
00:02:13,190 --> 00:02:16,750
yesterday's keynote was outstanding so I

45
00:02:16,750 --> 00:02:19,730
was pretty much working all night to

46
00:02:19,730 --> 00:02:21,680
improve my slides to make them just as

47
00:02:21,680 --> 00:02:23,930
fun as they can be considering the topic

48
00:02:23,930 --> 00:02:26,810
of my talk as you can imagine governance

49
00:02:26,810 --> 00:02:29,240
is not the most sexy topic you can

50
00:02:29,240 --> 00:02:31,940
envision so please bear that in mind and

51
00:02:31,940 --> 00:02:36,770
just laugh anyway thank you very much so

52
00:02:36,770 --> 00:02:39,740
um so I'm gonna be talking about IOT

53
00:02:39,740 --> 00:02:43,430
governance so that I want to start where

54
00:02:43,430 --> 00:02:46,120
basically yesterday's keynote ended and

55
00:02:46,120 --> 00:02:49,010
actually I want to first say some of you

56
00:02:49,010 --> 00:02:51,110
might know me or have seen my name in

57
00:02:51,110 --> 00:02:53,930
your inbox I feel like I've literally

58
00:02:53,930 --> 00:02:56,360
emailed all of si shirts in the world at

59
00:02:56,360 --> 00:02:58,220
least like that's how my weekend when I

60
00:02:58,220 --> 00:03:00,410
emailed a copy pasted all those messages

61
00:03:00,410 --> 00:03:02,720
to you felt for those of you who replied

62
00:03:02,720 --> 00:03:04,730
thank you very much for those of you who

63
00:03:04,730 --> 00:03:08,510
didn't not good so the reason for that

64
00:03:08,510 --> 00:03:10,250
as Andrew mentioned was because we

65
00:03:10,250 --> 00:03:12,500
conducted a study and still conduct a

66
00:03:12,500 --> 00:03:14,000
study about the sea search community

67
00:03:14,000 --> 00:03:15,430
which I'm not going to be talking about

68
00:03:15,430 --> 00:03:18,200
but if you're interested in that work

69
00:03:18,200 --> 00:03:20,120
please have a look at our publication

70
00:03:20,120 --> 00:03:22,160
now the other reason why I think I was

71
00:03:22,160 --> 00:03:23,690
invited is not just because I bothered

72
00:03:23,690 --> 00:03:25,220
the board so much over the last two and

73
00:03:25,220 --> 00:03:28,130
a half years but also because I'm part

74
00:03:28,130 --> 00:03:29,510
of the so called Petra's

75
00:03:29,510 --> 00:03:31,880
internet-of-things research hub or as

76
00:03:31,880 --> 00:03:34,250
it's now called the Petra's National

77
00:03:34,250 --> 00:03:37,160
Center of Excellence now what that is

78
00:03:37,160 --> 00:03:41,420
it's a very UK focused network of by now

79
00:03:41,420 --> 00:03:45,620
11 universities who all research IOT

80
00:03:45,620 --> 00:03:47,480
aspects from technical

81
00:03:47,480 --> 00:03:49,310
aspects such as computer scientists

82
00:03:49,310 --> 00:03:51,530
electrical engineers to psychologists

83
00:03:51,530 --> 00:03:54,170
and social scientists like myself

84
00:03:54,170 --> 00:03:56,360
so now that I've disclaimed that I'm not

85
00:03:56,360 --> 00:03:58,299
a techie I hope you're still gonna be

86
00:03:58,299 --> 00:04:01,430
nice and not judge me too much but you

87
00:04:01,430 --> 00:04:03,230
might be wondering why have I been

88
00:04:03,230 --> 00:04:05,150
invited and what will I be talking about

89
00:04:05,150 --> 00:04:07,760
so there's gonna be four issues that I

90
00:04:07,760 --> 00:04:09,860
hope by the end of the talk when you

91
00:04:09,860 --> 00:04:12,650
leave are thinking about and that's one

92
00:04:12,650 --> 00:04:14,959
policy in governance of course the other

93
00:04:14,959 --> 00:04:17,449
one is the aspect of the human in this

94
00:04:17,449 --> 00:04:19,789
whole dimension then also the

95
00:04:19,789 --> 00:04:22,970
difficulties of a actually governing and

96
00:04:22,970 --> 00:04:25,789
making policies around IOT and then some

97
00:04:25,789 --> 00:04:27,350
approaches and initiatives that are on

98
00:04:27,350 --> 00:04:30,260
the way so if I achieve that that would

99
00:04:30,260 --> 00:04:32,150
be amazing and I do want to say I have

100
00:04:32,150 --> 00:04:34,250
been told not to lecture which is really

101
00:04:34,250 --> 00:04:36,169
difficult because lecturing is in the

102
00:04:36,169 --> 00:04:39,440
title of my job so if it's getting too

103
00:04:39,440 --> 00:04:41,449
boring I will see it in your faces I'm

104
00:04:41,449 --> 00:04:43,550
used to those faces for my students so I

105
00:04:43,550 --> 00:04:46,250
will try to adopt very kind thank you

106
00:04:46,250 --> 00:04:49,760
very much for the loud laughter so let's

107
00:04:49,760 --> 00:04:51,080
start with the foundations because

108
00:04:51,080 --> 00:04:53,330
that's what academics do so the internet

109
00:04:53,330 --> 00:04:56,120
of what I mean it's not a big you know

110
00:04:56,120 --> 00:04:57,770
issue for you guys I'm sure you'll

111
00:04:57,770 --> 00:05:00,050
either wear it have it at home or

112
00:05:00,050 --> 00:05:03,500
despise it nevertheless it's actually an

113
00:05:03,500 --> 00:05:05,210
umbrella term that annoys us all I

114
00:05:05,210 --> 00:05:08,690
assume it was actually probably a better

115
00:05:08,690 --> 00:05:10,010
term to call it this topic it is

116
00:05:10,010 --> 00:05:11,510
computing which was actually coming back

117
00:05:11,510 --> 00:05:14,090
in the 90s so the principle in itself is

118
00:05:14,090 --> 00:05:16,190
not that new and actually will show you

119
00:05:16,190 --> 00:05:18,169
that the whole thing is not that new

120
00:05:18,169 --> 00:05:19,729
also when it comes to regulation despite

121
00:05:19,729 --> 00:05:22,010
the fact that's I don't want to name

122
00:05:22,010 --> 00:05:24,680
names but like some reports want to tell

123
00:05:24,680 --> 00:05:28,099
you what I really want to stress is so

124
00:05:28,099 --> 00:05:29,570
despite the fact it's a very technical

125
00:05:29,570 --> 00:05:31,520
aspect I really want to emphasize that

126
00:05:31,520 --> 00:05:33,710
there is a relationship aspect not just

127
00:05:33,710 --> 00:05:35,599
between the different systems from like

128
00:05:35,599 --> 00:05:37,400
the device the communication network the

129
00:05:37,400 --> 00:05:39,229
platform but also to the human because

130
00:05:39,229 --> 00:05:41,360
we wear it we have it in our households

131
00:05:41,360 --> 00:05:45,590
and our dear Godfather Bruce Schneier

132
00:05:45,590 --> 00:05:47,930
who will do a signal sign signing

133
00:05:47,930 --> 00:05:50,930
tomorrow basically calls it a new word

134
00:05:50,930 --> 00:05:52,520
instead of Internet of Things he calls

135
00:05:52,520 --> 00:05:55,190
an Internet of plus I actually think

136
00:05:55,190 --> 00:05:56,719
it's kind of interesting to basically

137
00:05:56,719 --> 00:05:59,060
emphasize that it's not just computers

138
00:05:59,060 --> 00:06:00,889
but it's computers blast

139
00:06:00,889 --> 00:06:03,020
services that are on top of that plus

140
00:06:03,020 --> 00:06:05,300
kind of the companies many of which are

141
00:06:05,300 --> 00:06:07,550
you defending and trying to protect Plus

142
00:06:07,550 --> 00:06:10,460
us the people who are using it now

143
00:06:10,460 --> 00:06:12,949
there's a lot of risks uncertainties and

144
00:06:12,949 --> 00:06:15,349
opportunities and actually the ones who

145
00:06:15,349 --> 00:06:17,509
have encountered me by now over the last

146
00:06:17,509 --> 00:06:19,550
days will have realized that you know

147
00:06:19,550 --> 00:06:21,259
I'm all about facts and that's why you

148
00:06:21,259 --> 00:06:22,729
have a lot of citations across the

149
00:06:22,729 --> 00:06:26,449
slides in a very long reference list so

150
00:06:26,449 --> 00:06:28,759
you will realize that we don't really

151
00:06:28,759 --> 00:06:30,740
have a clarity of like the percentage of

152
00:06:30,740 --> 00:06:32,900
like how much risk is there actually and

153
00:06:32,900 --> 00:06:34,520
that's really hard to quantify where we

154
00:06:34,520 --> 00:06:36,319
are now but still there's also a lot of

155
00:06:36,319 --> 00:06:38,389
opportunities with some people try to

156
00:06:38,389 --> 00:06:40,819
emphasize but really we don't know

157
00:06:40,819 --> 00:06:43,250
really what's you know what we are

158
00:06:43,250 --> 00:06:45,529
facing in the future and that's why we

159
00:06:45,529 --> 00:06:48,020
have the wonderful Internet of if

160
00:06:48,020 --> 00:06:49,939
you have never seen it before I really

161
00:06:49,939 --> 00:06:51,759
encourage you to have a look at this

162
00:06:51,759 --> 00:06:53,810
it's kind of what the talk yesterday

163
00:06:53,810 --> 00:06:56,120
ended with which was basically we tried

164
00:06:56,120 --> 00:06:58,550
to connect everything and sometimes it

165
00:06:58,550 --> 00:07:00,759
works out most of the times it doesn't

166
00:07:00,759 --> 00:07:04,939
but it still brings us sometimes joy now

167
00:07:04,939 --> 00:07:06,680
I do want to bring one aspect and that's

168
00:07:06,680 --> 00:07:08,419
what I entered entered this slide

169
00:07:08,419 --> 00:07:12,139
entered yesterday because when can I

170
00:07:12,139 --> 00:07:15,620
finish he was basically saying why do we

171
00:07:15,620 --> 00:07:17,870
want to connect everything and I thought

172
00:07:17,870 --> 00:07:23,149
like well do we who is we we like as you

173
00:07:23,149 --> 00:07:26,060
the technical community we as users who

174
00:07:26,060 --> 00:07:28,969
is we now I really want to say don't

175
00:07:28,969 --> 00:07:31,610
blame the user because actually it's the

176
00:07:31,610 --> 00:07:33,560
industry's fault if you connect it then

177
00:07:33,560 --> 00:07:36,439
we have to purchase it so that's an

178
00:07:36,439 --> 00:07:38,719
approach I would take and if you say but

179
00:07:38,719 --> 00:07:42,710
Leonie why well there's enough research

180
00:07:42,710 --> 00:07:47,029
that shows us that the one the user is

181
00:07:47,029 --> 00:07:48,830
not the enemy it's actually if you think

182
00:07:48,830 --> 00:07:50,870
about just the way we are structuring

183
00:07:50,870 --> 00:07:51,729
society

184
00:07:51,729 --> 00:07:55,129
nobody is expected to check a packet of

185
00:07:55,129 --> 00:07:56,870
crisps when you purchase it if it

186
00:07:56,870 --> 00:07:58,789
actually is gonna harm you or danger you

187
00:07:58,789 --> 00:08:00,349
you just assume the Food Standards

188
00:08:00,349 --> 00:08:03,229
Agency will solve that right nobody is

189
00:08:03,229 --> 00:08:06,169
expecting to be electrical engineer in

190
00:08:06,169 --> 00:08:08,689
order for these lamps not to burst and

191
00:08:08,689 --> 00:08:11,599
like completely destroy this room so

192
00:08:11,599 --> 00:08:13,620
there's certain expectations we

193
00:08:13,620 --> 00:08:16,230
as an individual tower it's a covenant

194
00:08:16,230 --> 00:08:19,190
tardes industry that we have but somehow

195
00:08:19,190 --> 00:08:22,620
currently and I'm sure there will be a

196
00:08:22,620 --> 00:08:24,270
lot of booing there but somehow the

197
00:08:24,270 --> 00:08:25,950
cybersecurity industry often gets an

198
00:08:25,950 --> 00:08:29,430
easy ride on that and I have a folder

199
00:08:29,430 --> 00:08:33,080
that i religiously kind of update with

200
00:08:33,080 --> 00:08:37,110
slides sites with papers and my folder

201
00:08:37,110 --> 00:08:38,460
on culture of security which is

202
00:08:38,460 --> 00:08:40,830
something around like why users don't do

203
00:08:40,830 --> 00:08:43,440
things or why users or why even like

204
00:08:43,440 --> 00:08:46,320
companies fail to do certain things is

205
00:08:46,320 --> 00:08:49,380
growing and it evidently highlights that

206
00:08:49,380 --> 00:08:51,720
you know it's not about like shifting

207
00:08:51,720 --> 00:08:53,460
the responsibility to the individuals

208
00:08:53,460 --> 00:08:55,050
but also its structural issues that we

209
00:08:55,050 --> 00:08:57,650
need to address and to showcase this

210
00:08:57,650 --> 00:09:00,390
there is something called a privacy

211
00:09:00,390 --> 00:09:03,690
paradox now don't get me wrong it's very

212
00:09:03,690 --> 00:09:05,940
controversial a lot of debates a lot of

213
00:09:05,940 --> 00:09:07,410
publications but I still want to

214
00:09:07,410 --> 00:09:09,480
highlight this because a it's something

215
00:09:09,480 --> 00:09:11,340
that next pop quiz you can answer a

216
00:09:11,340 --> 00:09:13,230
question on it and be because it's

217
00:09:13,230 --> 00:09:14,730
actually quite interesting because you

218
00:09:14,730 --> 00:09:16,860
will you know encounter it quite often

219
00:09:16,860 --> 00:09:19,350
and what the privacy paradox means is

220
00:09:19,350 --> 00:09:23,400
that people often say they you know they

221
00:09:23,400 --> 00:09:25,220
care about privacy but what they do

222
00:09:25,220 --> 00:09:28,710
doesn't really go together so for

223
00:09:28,710 --> 00:09:30,570
example these are some studies that I

224
00:09:30,570 --> 00:09:32,670
think are worth highlighting so one is

225
00:09:32,670 --> 00:09:35,870
if you basically tells you tell

226
00:09:35,870 --> 00:09:37,890
participants that there is one store

227
00:09:37,890 --> 00:09:39,270
that values our privacy

228
00:09:39,270 --> 00:09:40,920
others who don't and there's just a

229
00:09:40,920 --> 00:09:43,410
one-year of difference people still go

230
00:09:43,410 --> 00:09:45,960
for the cheaper version the other one is

231
00:09:45,960 --> 00:09:47,880
for example participants would easily

232
00:09:47,880 --> 00:09:49,410
sell their browser that I'm sure that

233
00:09:49,410 --> 00:09:51,120
makes some of you get quite happy in his

234
00:09:51,120 --> 00:09:53,820
room which is like four seven pounds for

235
00:09:53,820 --> 00:09:55,530
seven years they would sell their

236
00:09:55,530 --> 00:09:57,450
browser data and most recently a

237
00:09:57,450 --> 00:10:01,350
colleague of mine William and and all

238
00:10:01,350 --> 00:10:03,060
have basically showed that this is also

239
00:10:03,060 --> 00:10:05,250
applicable disability paradox for the

240
00:10:05,250 --> 00:10:06,630
IOT environment it's a really

241
00:10:06,630 --> 00:10:08,160
interesting paper if you have to chance

242
00:10:08,160 --> 00:10:09,720
to read it so they did a survey in an

243
00:10:09,720 --> 00:10:12,150
interview and they showed basically you

244
00:10:12,150 --> 00:10:15,750
know that a IOT devices are perceived to

245
00:10:15,750 --> 00:10:18,150
have like significant less privacy but

246
00:10:18,150 --> 00:10:20,430
still people purchase them despite the

247
00:10:20,430 --> 00:10:23,580
fact they know that it's not secure or

248
00:10:23,580 --> 00:10:26,580
less private and IOT owners also cared

249
00:10:26,580 --> 00:10:28,650
less about their privacy it's like you

250
00:10:28,650 --> 00:10:30,540
know I purchased this and I just know

251
00:10:30,540 --> 00:10:32,550
that the companies will not care about

252
00:10:32,550 --> 00:10:35,010
my privacy which is really an awful idea

253
00:10:35,010 --> 00:10:37,650
to think about but that's how it is

254
00:10:37,650 --> 00:10:40,410
but I do want to stress one thing that

255
00:10:40,410 --> 00:10:44,280
does not mean that people do not value

256
00:10:44,280 --> 00:10:46,890
privacy and that's a really false claim

257
00:10:46,890 --> 00:10:49,320
that I will you know disregard in all

258
00:10:49,320 --> 00:10:51,360
discussions you have with me because

259
00:10:51,360 --> 00:10:53,940
there is severe cognitive problems with

260
00:10:53,940 --> 00:10:55,680
people and there's enough research to

261
00:10:55,680 --> 00:10:58,170
show that that they simply can't you

262
00:10:58,170 --> 00:11:00,150
know make that judgment often and it

263
00:11:00,150 --> 00:11:02,280
shouldn't be about industry exploiting

264
00:11:02,280 --> 00:11:05,100
this cognitive impairment okay so I

265
00:11:05,100 --> 00:11:07,380
think that's the premise that I would

266
00:11:07,380 --> 00:11:10,500
like to start with okay then you're

267
00:11:10,500 --> 00:11:12,540
gonna say well okay we can't blame it on

268
00:11:12,540 --> 00:11:14,370
the user whatever the governance issues

269
00:11:14,370 --> 00:11:17,190
then well I don't even know where to

270
00:11:17,190 --> 00:11:19,920
start there's so many papers out there

271
00:11:19,920 --> 00:11:22,890
it's ranging for privacy mm safety and

272
00:11:22,890 --> 00:11:25,530
security like you name it and in fact

273
00:11:25,530 --> 00:11:27,930
because you know I thought for a keynote

274
00:11:27,930 --> 00:11:29,880
like this I'm gonna make nice graphics I

275
00:11:29,880 --> 00:11:32,460
just outlined some of the issues that we

276
00:11:32,460 --> 00:11:36,480
you probably me I don't know have to

277
00:11:36,480 --> 00:11:39,390
ensure but certainly someone when it

278
00:11:39,390 --> 00:11:41,300
comes to for example reliability

279
00:11:41,300 --> 00:11:44,160
liability access control consent

280
00:11:44,160 --> 00:11:46,440
security and safety by design so these

281
00:11:46,440 --> 00:11:48,810
are aspects that in the long run

282
00:11:48,810 --> 00:11:50,910
IOT needs to guarantee and currently

283
00:11:50,910 --> 00:11:54,780
often does not now this is a really nice

284
00:11:54,780 --> 00:11:59,160
graph by from 2018 which highlights what

285
00:11:59,160 --> 00:12:01,830
are actually the IOT security privacy

286
00:12:01,830 --> 00:12:03,960
and safety risks and you really can

287
00:12:03,960 --> 00:12:06,180
nicely see how you go for example from

288
00:12:06,180 --> 00:12:07,710
the increased complexity which is

289
00:12:07,710 --> 00:12:09,750
yesterday really nicely highlighted from

290
00:12:09,750 --> 00:12:12,660
like the Barbie doll and all the other

291
00:12:12,660 --> 00:12:15,570
devices that were carried out of the

292
00:12:15,570 --> 00:12:17,730
suitcase to down to the lack of

293
00:12:17,730 --> 00:12:20,190
knowledge but I want to quantify qualify

294
00:12:20,190 --> 00:12:21,870
here lack of knowledge of whom lack of

295
00:12:21,870 --> 00:12:23,580
knowledge of the industry actors lack of

296
00:12:23,580 --> 00:12:25,560
knowledge of the users so this is a

297
00:12:25,560 --> 00:12:28,680
widespread issue right also to the kind

298
00:12:28,680 --> 00:12:31,860
of lack of incentives and of course as

299
00:12:31,860 --> 00:12:33,540
industry actors you would be saying well

300
00:12:33,540 --> 00:12:35,310
any just joke mister study that users

301
00:12:35,310 --> 00:12:36,690
vote really and willing to purchase

302
00:12:36,690 --> 00:12:38,520
secured devices

303
00:12:38,520 --> 00:12:41,430
why should we then invest into that and

304
00:12:41,430 --> 00:12:43,200
then also a lack of monitoring

305
00:12:43,200 --> 00:12:44,820
enforcement which is then basically

306
00:12:44,820 --> 00:12:46,920
we're government and policymakers come

307
00:12:46,920 --> 00:12:49,140
in and basically say well if we can't

308
00:12:49,140 --> 00:12:51,899
incentivize that like industry is really

309
00:12:51,899 --> 00:12:54,089
like insuring or not exploiting that

310
00:12:54,089 --> 00:12:56,899
cognitive bias perhaps we should make

311
00:12:56,899 --> 00:12:59,730
baseline security framework and priestly

312
00:12:59,730 --> 00:13:03,410
framework that will help users not to be

313
00:13:03,410 --> 00:13:08,190
used in this environment now I really

314
00:13:08,190 --> 00:13:11,220
think IOT is a lifecycle problem and I'm

315
00:13:11,220 --> 00:13:13,890
sure others do as well so it starts from

316
00:13:13,890 --> 00:13:16,980
the design the purchase the set-up the

317
00:13:16,980 --> 00:13:19,980
maintenance and the disposal now over

318
00:13:19,980 --> 00:13:21,630
the course of the two days I had a lot

319
00:13:21,630 --> 00:13:23,370
of discussion and I realized I can't

320
00:13:23,370 --> 00:13:26,399
fill them in all but there's a couple of

321
00:13:26,399 --> 00:13:28,589
issues that connect to that so for

322
00:13:28,589 --> 00:13:31,050
example how do we ensure SMEs are

323
00:13:31,050 --> 00:13:33,420
supported what are we doing with open

324
00:13:33,420 --> 00:13:35,490
source project in this round okay how

325
00:13:35,490 --> 00:13:38,070
are we gonna ensure like that they will

326
00:13:38,070 --> 00:13:40,440
be supported that this will be supported

327
00:13:40,440 --> 00:13:42,690
what are doing about counterfeit product

328
00:13:42,690 --> 00:13:44,640
will Windish in the future be releasing

329
00:13:44,640 --> 00:13:47,070
product and instead of purchasing what

330
00:13:47,070 --> 00:13:49,230
about insurance in this space and also

331
00:13:49,230 --> 00:13:50,760
the right of return that was yesterday

332
00:13:50,760 --> 00:13:53,130
mentioned so while I can't address them

333
00:13:53,130 --> 00:13:55,170
they're food for thought food for

334
00:13:55,170 --> 00:13:57,750
discussions over coffee and there's I'm

335
00:13:57,750 --> 00:14:00,000
happily like able to answer some of

336
00:14:00,000 --> 00:14:02,220
those questions around these in the Q&A

337
00:14:02,220 --> 00:14:04,380
but I think they're part of the life

338
00:14:04,380 --> 00:14:06,170
cycle problem that we have not addressed

339
00:14:06,170 --> 00:14:09,029
now a really important aspect that I see

340
00:14:09,029 --> 00:14:11,970
in our research is in the current state

341
00:14:11,970 --> 00:14:14,220
of governance but also in the current

342
00:14:14,220 --> 00:14:16,290
state of like policy development the

343
00:14:16,290 --> 00:14:19,470
majority of processes actually only look

344
00:14:19,470 --> 00:14:21,390
at the first three stages of design

345
00:14:21,390 --> 00:14:24,810
purchase and setup so they ignore the

346
00:14:24,810 --> 00:14:27,060
fact that what are we doing when users

347
00:14:27,060 --> 00:14:29,040
actually have implemented these systems

348
00:14:29,040 --> 00:14:31,110
for example in the built environment but

349
00:14:31,110 --> 00:14:33,510
also what are we doing in the long run

350
00:14:33,510 --> 00:14:35,490
when they are basically purchased and

351
00:14:35,490 --> 00:14:39,750
you know built in and then they keep

352
00:14:39,750 --> 00:14:41,610
them for like 17 years because people

353
00:14:41,610 --> 00:14:44,850
don't change them so currently a lot of

354
00:14:44,850 --> 00:14:47,250
the best practices a lot of the current

355
00:14:47,250 --> 00:14:49,650
like policy discussions do not from my

356
00:14:49,650 --> 00:14:51,270
perspective focus on the last three

357
00:14:51,270 --> 00:14:52,380
areas at

358
00:14:52,380 --> 00:14:53,550
want to mention to a colleague of mine

359
00:14:53,550 --> 00:14:55,860
jump life and others have highlighted

360
00:14:55,860 --> 00:14:58,170
again that was a responsibility for the

361
00:14:58,170 --> 00:15:00,750
user what users can do but still I think

362
00:15:00,750 --> 00:15:03,420
there's a lot of questions around these

363
00:15:03,420 --> 00:15:05,970
two areas where current regulation or

364
00:15:05,970 --> 00:15:07,590
not even regulation I don't say that

365
00:15:07,590 --> 00:15:10,770
word yet but governance and policy

366
00:15:10,770 --> 00:15:13,290
measures are not going to get a thing

367
00:15:13,290 --> 00:15:15,330
that I really want to answer is IOT is

368
00:15:15,330 --> 00:15:17,190
unique in so far it's not just like

369
00:15:17,190 --> 00:15:20,130
software it's actually a thing so we

370
00:15:20,130 --> 00:15:23,070
also have to consider product safety and

371
00:15:23,070 --> 00:15:26,520
you know everything that like engineers

372
00:15:26,520 --> 00:15:28,590
have for the last like hundreds of years

373
00:15:28,590 --> 00:15:31,500
learned around safety the standards that

374
00:15:31,500 --> 00:15:33,300
we have set up you don't really have

375
00:15:33,300 --> 00:15:34,920
that for security and that's the

376
00:15:34,920 --> 00:15:36,690
question where we are always asking

377
00:15:36,690 --> 00:15:38,700
yourself is there clash between safety

378
00:15:38,700 --> 00:15:40,530
and security standards I always give the

379
00:15:40,530 --> 00:15:41,940
example to my students if you think

380
00:15:41,940 --> 00:15:43,200
about a door right

381
00:15:43,200 --> 00:15:44,940
if you're an engineer from a safety

382
00:15:44,940 --> 00:15:46,830
perspective that door should always be

383
00:15:46,830 --> 00:15:49,110
open but from a security perspective you

384
00:15:49,110 --> 00:15:51,480
want that to be closed so how can it be

385
00:15:51,480 --> 00:15:53,730
are you going to be able to unify these

386
00:15:53,730 --> 00:15:55,380
different principles in the long run and

387
00:15:55,380 --> 00:15:57,510
ensure that their standards that

388
00:15:57,510 --> 00:16:01,110
combined both a big worry of mine and

389
00:16:01,110 --> 00:16:03,180
I'm sure we have colleagues from Amazon

390
00:16:03,180 --> 00:16:06,960
and Google in the room is I personally

391
00:16:06,960 --> 00:16:08,370
see a lot of issues around

392
00:16:08,370 --> 00:16:10,680
centralization with technical standards

393
00:16:10,680 --> 00:16:12,660
so if you think about it if your owner

394
00:16:12,660 --> 00:16:15,900
of Amazon echo or Google home you want

395
00:16:15,900 --> 00:16:17,520
to connect all your devices to that

396
00:16:17,520 --> 00:16:21,810
right so one big problem or issue that I

397
00:16:21,810 --> 00:16:23,910
can see emerge and will be a governance

398
00:16:23,910 --> 00:16:25,350
issue in the future is how are we gonna

399
00:16:25,350 --> 00:16:27,210
ensure that like these hubs these

400
00:16:27,210 --> 00:16:29,430
central nodes that IOT will create

401
00:16:29,430 --> 00:16:31,560
ensure that there's actually an open

402
00:16:31,560 --> 00:16:33,660
flow of market that like are not

403
00:16:33,660 --> 00:16:35,580
dominated by a couple of few people that

404
00:16:35,580 --> 00:16:37,200
set the standards the technical

405
00:16:37,200 --> 00:16:39,210
standards but also who allow who can

406
00:16:39,210 --> 00:16:42,660
connect to what and again something that

407
00:16:42,660 --> 00:16:45,450
like I feel policymakers currently don't

408
00:16:45,450 --> 00:16:47,250
really think about because there's so

409
00:16:47,250 --> 00:16:48,870
much other things like burning in the

410
00:16:48,870 --> 00:16:51,060
back of their mind I'm thinking of that

411
00:16:51,060 --> 00:16:52,680
image I should have put that here with

412
00:16:52,680 --> 00:16:55,080
like the dog and the burning image yeah

413
00:16:55,080 --> 00:16:58,110
should have done that there can't we

414
00:16:58,110 --> 00:16:59,670
regulate this is probably the question

415
00:16:59,670 --> 00:17:01,560
and it's something that you probably

416
00:17:01,560 --> 00:17:05,650
don't want to hear but let's be honest

417
00:17:05,650 --> 00:17:08,410
national legislation will not solve this

418
00:17:08,410 --> 00:17:12,069
no way why not because you know the

419
00:17:12,069 --> 00:17:15,520
market is not working like this even I'm

420
00:17:15,520 --> 00:17:17,709
from Austria even if Austria decides

421
00:17:17,709 --> 00:17:19,359
tomorrow that we're gonna regulate

422
00:17:19,359 --> 00:17:21,849
certain aspects around IOT we will have

423
00:17:21,849 --> 00:17:24,030
a bit of a problem like enforcing that

424
00:17:24,030 --> 00:17:28,480
and also the big big bull words is like

425
00:17:28,480 --> 00:17:32,410
we don't want to stifle innovation so in

426
00:17:32,410 --> 00:17:34,500
that ecosystem that we're now actually

427
00:17:34,500 --> 00:17:37,350
this is not something that like is

428
00:17:37,350 --> 00:17:41,860
current a debate think back 2006 I

429
00:17:41,860 --> 00:17:46,030
wasn't even at uni at that stage they

430
00:17:46,030 --> 00:17:48,640
were the European Union already had

431
00:17:48,640 --> 00:17:52,840
discussed should we regulate IOT and by

432
00:17:52,840 --> 00:17:55,059
2006 they basically you know because

433
00:17:55,059 --> 00:17:56,620
they really wanted to be the at the

434
00:17:56,620 --> 00:17:59,590
forefront of like governance issues

435
00:17:59,590 --> 00:18:01,570
around emerging technologies so it's not

436
00:18:01,570 --> 00:18:03,130
something really I really want to

437
00:18:03,130 --> 00:18:04,870
emphasize this this is not something you

438
00:18:04,870 --> 00:18:07,210
know everybody says oh I ot so new but

439
00:18:07,210 --> 00:18:10,090
since 2006 this is actually on the radar

440
00:18:10,090 --> 00:18:12,460
of the European Union but the thing is

441
00:18:12,460 --> 00:18:13,929
so these are true regulations are

442
00:18:13,929 --> 00:18:17,080
actually communications that I want to

443
00:18:17,080 --> 00:18:20,350
point out this is from 2008 so in 2008

444
00:18:20,350 --> 00:18:22,179
after you know the first one the first

445
00:18:22,179 --> 00:18:24,190
meeting the workshop in 2006 the

446
00:18:24,190 --> 00:18:25,510
European Commission basically realized

447
00:18:25,510 --> 00:18:27,550
well we rather do self regulation

448
00:18:27,550 --> 00:18:29,800
because this seems to be a bit you know

449
00:18:29,800 --> 00:18:32,860
too early stage which we still say and

450
00:18:32,860 --> 00:18:36,340
we don't want to intervene by 2009 just

451
00:18:36,340 --> 00:18:37,960
one year later the European Commission

452
00:18:37,960 --> 00:18:39,730
basically said well perhaps this is

453
00:18:39,730 --> 00:18:41,710
something we can't just leave with the

454
00:18:41,710 --> 00:18:45,429
private sector and now you know 20 years

455
00:18:45,429 --> 00:18:49,570
no ten years Jesus 10 years poof

456
00:18:49,570 --> 00:18:51,700
ten years later we're still having the

457
00:18:51,700 --> 00:18:53,559
same discussion which I think is really

458
00:18:53,559 --> 00:18:56,580
interesting when you see how slow this

459
00:18:56,580 --> 00:19:00,670
progresses and in 2009 the European

460
00:19:00,670 --> 00:19:02,559
Commission also published like 14 lines

461
00:19:02,559 --> 00:19:04,630
of action I reread them for the keynote

462
00:19:04,630 --> 00:19:06,370
and I felt like they could be published

463
00:19:06,370 --> 00:19:08,710
yesterday you know in those forth like

464
00:19:08,710 --> 00:19:10,420
in those 10 years we haven't really done

465
00:19:10,420 --> 00:19:12,490
much around the things that we like said

466
00:19:12,490 --> 00:19:13,900
we would do for example international

467
00:19:13,900 --> 00:19:16,510
dialogue of course we have chats but

468
00:19:16,510 --> 00:19:18,790
that hasn't gone anywhere

469
00:19:18,790 --> 00:19:21,190
so just a bit of a critique there of

470
00:19:21,190 --> 00:19:24,550
like of just like kind of conversation

471
00:19:24,550 --> 00:19:26,790
at one recitation of like the same

472
00:19:26,790 --> 00:19:29,080
dynamics over and over again and I just

473
00:19:29,080 --> 00:19:30,820
wonder what needs to happen to actually

474
00:19:30,820 --> 00:19:34,360
then lead to something more concrete so

475
00:19:34,360 --> 00:19:36,790
and that's where I want to go on with

476
00:19:36,790 --> 00:19:39,480
will we are we still set up for

477
00:19:39,480 --> 00:19:43,480
self-regulation well again our Bruce

478
00:19:43,480 --> 00:19:46,150
Schneier is of the opinion you know

479
00:19:46,150 --> 00:19:48,430
there's no industry that's ever improved

480
00:19:48,430 --> 00:19:49,960
safety and security without governance

481
00:19:49,960 --> 00:19:52,030
enforcing it and I kind of agree with

482
00:19:52,030 --> 00:19:54,690
him of course because I'm a policy

483
00:19:54,690 --> 00:19:57,790
person so I strongly believe that we

484
00:19:57,790 --> 00:20:00,670
need carrots and sticks I don't know if

485
00:20:00,670 --> 00:20:02,140
you've ever heard of this carrot is

486
00:20:02,140 --> 00:20:04,080
something you learn someone and say come

487
00:20:04,080 --> 00:20:06,340
do a bit of better security and privacy

488
00:20:06,340 --> 00:20:09,850
and if not we come with your stick and I

489
00:20:09,850 --> 00:20:11,440
think that's what's currently needed a

490
00:20:11,440 --> 00:20:15,160
bit so I think the European Union in

491
00:20:15,160 --> 00:20:16,960
this regard currently works on a bit of

492
00:20:16,960 --> 00:20:19,300
a stick or actually the carrots but

493
00:20:19,300 --> 00:20:20,950
perhaps they're gonna soon roll out the

494
00:20:20,950 --> 00:20:24,880
stick so colleagues of venice' here

495
00:20:24,880 --> 00:20:28,080
probably they do incredible great work

496
00:20:28,080 --> 00:20:30,790
this for example based on security

497
00:20:30,790 --> 00:20:33,490
recommendation their annex is amazing

498
00:20:33,490 --> 00:20:34,960
when I saw it that was nearly crying

499
00:20:34,960 --> 00:20:36,640
because we do it the same work and then

500
00:20:36,640 --> 00:20:37,870
we realized we don't need to do it

501
00:20:37,870 --> 00:20:40,750
anymore but like it is a really good

502
00:20:40,750 --> 00:20:43,120
summary of what's happening in the IOT

503
00:20:43,120 --> 00:20:45,520
space and what could be important for

504
00:20:45,520 --> 00:20:47,620
critical infrastructure providers and it

505
00:20:47,620 --> 00:20:49,390
really goes nicely with of course what

506
00:20:49,390 --> 00:20:50,740
the European Commission is working on

507
00:20:50,740 --> 00:20:52,930
with the cybersecurity act so if you

508
00:20:52,930 --> 00:20:54,430
have not heard about the cybersecurity

509
00:20:54,430 --> 00:20:57,510
Act proposed in 2016

510
00:20:57,510 --> 00:20:59,940
basically sets out a framework

511
00:20:59,940 --> 00:21:02,170
especially which I'm talking I'm sick

512
00:21:02,170 --> 00:21:04,540
and certification framework around how

513
00:21:04,540 --> 00:21:07,450
we could ensure that ICT products are

514
00:21:07,450 --> 00:21:10,330
becoming more secure so I think the

515
00:21:10,330 --> 00:21:11,530
European Union is really at the

516
00:21:11,530 --> 00:21:13,510
forefront but considering that they

517
00:21:13,510 --> 00:21:15,190
talked about it since 2006

518
00:21:15,190 --> 00:21:20,260
I don't know some actor that really

519
00:21:20,260 --> 00:21:23,080
tries to dominate that field now the

520
00:21:23,080 --> 00:21:24,880
other thing of course I'm biased and

521
00:21:24,880 --> 00:21:27,130
based in UCL in the United Kingdom and

522
00:21:27,130 --> 00:21:29,260
we actually worked very closely with the

523
00:21:29,260 --> 00:21:31,060
Department for Culture Digital Culture

524
00:21:31,060 --> 00:21:32,020
Media and Sport DC

525
00:21:32,020 --> 00:21:34,420
so we for example help them to write a

526
00:21:34,420 --> 00:21:36,220
literature review of the current like

527
00:21:36,220 --> 00:21:38,230
international developments around IOT

528
00:21:38,230 --> 00:21:40,510
which ultimately fed into this nice

529
00:21:40,510 --> 00:21:42,040
publication called the code of practice

530
00:21:42,040 --> 00:21:44,920
for cost consumer IOT products which

531
00:21:44,920 --> 00:21:47,080
recently has become an Etsy standard so

532
00:21:47,080 --> 00:21:49,270
any IOT vendors in this room could now

533
00:21:49,270 --> 00:21:52,050
certify your products along those lines

534
00:21:52,050 --> 00:21:54,910
and what yesterday was not discussed is

535
00:21:54,910 --> 00:21:57,880
what this code actually encompasses and

536
00:21:57,880 --> 00:22:03,340
it's 13 principles and it's from my

537
00:22:03,340 --> 00:22:05,070
perspective the low-hanging fruit

538
00:22:05,070 --> 00:22:08,020
someone work might say but still it is

539
00:22:08,020 --> 00:22:10,780
some starts to basically talk about like

540
00:22:10,780 --> 00:22:14,100
how could we ensure a more entry-level

541
00:22:14,100 --> 00:22:18,460
for IOT security and the first three are

542
00:22:18,460 --> 00:22:21,220
currently actually being discussed to be

543
00:22:21,220 --> 00:22:23,980
become mandatory but all the other

544
00:22:23,980 --> 00:22:26,620
principle will if the government decides

545
00:22:26,620 --> 00:22:29,140
still remain completely voluntary and

546
00:22:29,140 --> 00:22:31,450
that's also something that I need to

547
00:22:31,450 --> 00:22:33,220
stress with regards to the cybersecurity

548
00:22:33,220 --> 00:22:37,090
act this is all still purely voluntary

549
00:22:37,090 --> 00:22:43,180
so there will be no stick yet now what

550
00:22:43,180 --> 00:22:45,490
happens with the rest of the world now

551
00:22:45,490 --> 00:22:47,740
yesterday was mentioned the IOT

552
00:22:47,740 --> 00:22:50,770
cybersecurity Improvement Act which is a

553
00:22:50,770 --> 00:22:54,070
u.s. legislation that's purely

554
00:22:54,070 --> 00:22:55,540
government procurement that wouldn't

555
00:22:55,540 --> 00:22:57,520
affect like the average human being in

556
00:22:57,520 --> 00:22:59,890
the US but still it's a step forward

557
00:22:59,890 --> 00:23:02,800
it's something where you could see okay

558
00:23:02,800 --> 00:23:05,170
some people in the government in the

559
00:23:05,170 --> 00:23:07,480
u.s. actually realized perhaps you

560
00:23:07,480 --> 00:23:08,620
shouldn't implement it at least in our

561
00:23:08,620 --> 00:23:11,590
critical infrastructure and as always

562
00:23:11,590 --> 00:23:13,540
Bruce Schneier realized quite early that

563
00:23:13,540 --> 00:23:16,690
was in 2007 that when this was published

564
00:23:16,690 --> 00:23:20,170
that this will go nowhere and in fact he

565
00:23:20,170 --> 00:23:23,140
was right because we had so far every

566
00:23:23,140 --> 00:23:26,170
year a new senator submitting the same

567
00:23:26,170 --> 00:23:28,630
bill over and over again so we have now

568
00:23:28,630 --> 00:23:31,060
the third draft in the center in the

569
00:23:31,060 --> 00:23:34,360
Senate we shall see if it goes anywhere

570
00:23:34,360 --> 00:23:36,580
but it's still government procurement

571
00:23:36,580 --> 00:23:39,070
but it is very interesting and something

572
00:23:39,070 --> 00:23:41,920
you know worth checking out if you are

573
00:23:41,920 --> 00:23:45,340
based in the US similarly California

574
00:23:45,340 --> 00:23:46,000
tries to press

575
00:23:46,000 --> 00:23:49,240
forward and yesterday can actually said

576
00:23:49,240 --> 00:23:50,860
you know this is something very positive

577
00:23:50,860 --> 00:23:54,100
I'm you know I'm neutral towards it but

578
00:23:54,100 --> 00:23:56,890
there's a blog post by Graham Roberts

579
00:23:56,890 --> 00:23:59,860
and he's very against it basically he

580
00:23:59,860 --> 00:24:01,540
says and it's the same thing that like

581
00:24:01,540 --> 00:24:03,460
yesterday was discussed it's not about

582
00:24:03,460 --> 00:24:05,650
like that the claim in this free page

583
00:24:05,650 --> 00:24:07,690
document is basically there should be

584
00:24:07,690 --> 00:24:09,370
security features but it doesn't really

585
00:24:09,370 --> 00:24:13,150
specify what are security features which

586
00:24:13,150 --> 00:24:15,400
makes it relatively difficult if you are

587
00:24:15,400 --> 00:24:17,890
a company and you don't really know what

588
00:24:17,890 --> 00:24:21,040
you should implement right so certainly

589
00:24:21,040 --> 00:24:23,260
something worth discussing but it goes

590
00:24:23,260 --> 00:24:25,540
along with a very thorough well I assume

591
00:24:25,540 --> 00:24:28,450
very fair review by NIST so it will be

592
00:24:28,450 --> 00:24:30,160
interesting what publication they will

593
00:24:30,160 --> 00:24:32,200
come up with in order to support this

594
00:24:32,200 --> 00:24:35,230
bill so these I think are kind of the

595
00:24:35,230 --> 00:24:37,240
current like three major developments

596
00:24:37,240 --> 00:24:39,490
that are four major developments that

597
00:24:39,490 --> 00:24:42,820
are happening now interestingly you

598
00:24:42,820 --> 00:24:45,150
might as the Caesar community asked wait

599
00:24:45,150 --> 00:24:48,070
nobody's really in charge of this are we

600
00:24:48,070 --> 00:24:50,350
gonna be responsible to fix that mess

601
00:24:50,350 --> 00:24:54,730
well unfortunately for you so you

602
00:24:54,730 --> 00:24:56,410
definitely gonna have to deal with the

603
00:24:56,410 --> 00:24:58,150
critical infrastructure if you are in

604
00:24:58,150 --> 00:25:00,130
the European Union because the NIS

605
00:25:00,130 --> 00:25:03,880
directive as you know is saying that you

606
00:25:03,880 --> 00:25:06,150
know certs are very important and

607
00:25:06,150 --> 00:25:08,650
there's also a lot of discussion saying

608
00:25:08,650 --> 00:25:10,540
that you know training exercises

609
00:25:10,540 --> 00:25:11,830
issuing guidance and shooting

610
00:25:11,830 --> 00:25:13,480
cooperation across borders raising

611
00:25:13,480 --> 00:25:15,850
awareness and just like dealing with

612
00:25:15,850 --> 00:25:16,990
these nasty

613
00:25:16,990 --> 00:25:19,180
IOT risk will fall onto your heads

614
00:25:19,180 --> 00:25:21,910
unfortunately and as part of the

615
00:25:21,910 --> 00:25:23,800
interviews that are conducted last year

616
00:25:23,800 --> 00:25:26,320
I also asked like my interviews always

617
00:25:26,320 --> 00:25:28,750
around IOT as well and I felt there was

618
00:25:28,750 --> 00:25:30,520
two dynamics one was that the majority

619
00:25:30,520 --> 00:25:32,350
of interviews always said okay we're

620
00:25:32,350 --> 00:25:33,520
just gonna have to deal with the

621
00:25:33,520 --> 00:25:35,770
magnitude of IOT risks or risk in

622
00:25:35,770 --> 00:25:37,690
general it's no longer just tablets

623
00:25:37,690 --> 00:25:39,610
phones or whatever actually it's gonna

624
00:25:39,610 --> 00:25:44,200
be our connected hairbrushes and fridges

625
00:25:44,200 --> 00:25:46,570
and whatever so our constituency will

626
00:25:46,570 --> 00:25:50,800
probably come bigger but a general sense

627
00:25:50,800 --> 00:25:53,470
I received was that it isn't really or

628
00:25:53,470 --> 00:25:55,480
wasn't video topic that I ot was very

629
00:25:55,480 --> 00:25:56,890
big in the community and perhaps that's

630
00:25:56,890 --> 00:25:58,750
also why Andrew invited so many IOT

631
00:25:58,750 --> 00:25:59,350
speakers

632
00:25:59,350 --> 00:26:01,480
in order to make it a topic the other

633
00:26:01,480 --> 00:26:03,580
thing is that a lot of the interview is

634
00:26:03,580 --> 00:26:06,010
highlighted that P certs will become

635
00:26:06,010 --> 00:26:07,660
increasingly more important because of

636
00:26:07,660 --> 00:26:09,250
the IOT environment which is why I was

637
00:26:09,250 --> 00:26:11,110
really interested that like this year

638
00:26:11,110 --> 00:26:12,340
there's the first piece of meeting

639
00:26:12,340 --> 00:26:14,770
happening so I think that is something

640
00:26:14,770 --> 00:26:17,470
were perhaps like future meetups

641
00:26:17,470 --> 00:26:19,419
meetings of the piece of community could

642
00:26:19,419 --> 00:26:22,360
go but often unfortunately that often

643
00:26:22,360 --> 00:26:25,480
requires a vendor buy-in that was not

644
00:26:25,480 --> 00:26:28,539
often very present so this was kind of

645
00:26:28,539 --> 00:26:32,110
like the findings that I have seen when

646
00:26:32,110 --> 00:26:35,130
talking to Ceaser community around IOT

647
00:26:35,130 --> 00:26:38,980
okay now you might say that's all fine

648
00:26:38,980 --> 00:26:41,530
Leone okay we see what's happening the

649
00:26:41,530 --> 00:26:43,990
users not their fault what else is there

650
00:26:43,990 --> 00:26:47,620
well in addition to you kind of actually

651
00:26:47,620 --> 00:26:49,299
should be volunteering of mandatory

652
00:26:49,299 --> 00:26:51,309
baseline requirements that was a wishful

653
00:26:51,309 --> 00:26:55,240
thinking and best practices there's

654
00:26:55,240 --> 00:26:56,890
three important things I want to

655
00:26:56,890 --> 00:27:00,340
highlight one is certified there's a lot

656
00:27:00,340 --> 00:27:03,159
of discussion around certification now

657
00:27:03,159 --> 00:27:04,990
some of you might shrug and feel like oh

658
00:27:04,990 --> 00:27:08,770
my god that's awful but others perhaps

659
00:27:08,770 --> 00:27:11,080
are feeling it more in a positive sense

660
00:27:11,080 --> 00:27:13,630
so by now the discussion is purely

661
00:27:13,630 --> 00:27:16,510
around voluntary certification so no

662
00:27:16,510 --> 00:27:19,450
need to freak out but the question that

663
00:27:19,450 --> 00:27:22,799
remains is how are we going to ensure

664
00:27:22,799 --> 00:27:26,080
dynamic certification because you can

665
00:27:26,080 --> 00:27:28,840
think about like a toaster you can test

666
00:27:28,840 --> 00:27:30,580
that when it breaks how can you do the

667
00:27:30,580 --> 00:27:32,860
same thing with a smart toaster how are

668
00:27:32,860 --> 00:27:34,120
you gonna ensure that by the next

669
00:27:34,120 --> 00:27:35,980
software update it doesn't you know fall

670
00:27:35,980 --> 00:27:39,039
apart and there's four publications that

671
00:27:39,039 --> 00:27:40,600
I want to highlight one is the overview

672
00:27:40,600 --> 00:27:42,760
of ICT certification laboratories I

673
00:27:42,760 --> 00:27:44,440
think that was an attempt by Nesta to

674
00:27:44,440 --> 00:27:45,870
map out who could do those

675
00:27:45,870 --> 00:27:48,580
certifications probably the other one is

676
00:27:48,580 --> 00:27:51,880
a really nice paper on solid studies

677
00:27:51,880 --> 00:27:54,929
sorry standardization and certification

678
00:27:54,929 --> 00:27:58,690
by colleagues from Cambridge I think

679
00:27:58,690 --> 00:28:00,640
they were all based and also of course

680
00:28:00,640 --> 00:28:02,710
and we have an own publication with

681
00:28:02,710 --> 00:28:04,990
Lloyds of London and insurer who are

682
00:28:04,990 --> 00:28:06,850
very interested in this space but have

683
00:28:06,850 --> 00:28:09,549
the same problem if there's no standards

684
00:28:09,549 --> 00:28:12,580
or ways of baseline requirements and

685
00:28:12,580 --> 00:28:15,100
sure would never ever cover that risk so

686
00:28:15,100 --> 00:28:16,630
we actually did some kind of

687
00:28:16,630 --> 00:28:19,779
forward-thinking scenarios that you're

688
00:28:19,779 --> 00:28:23,169
open to have a look at what we also

689
00:28:23,169 --> 00:28:25,090
talked about how certification could

690
00:28:25,090 --> 00:28:27,010
look like in the future of a fully

691
00:28:27,010 --> 00:28:30,610
interconnected environment so that's

692
00:28:30,610 --> 00:28:32,830
around certification the other big topic

693
00:28:32,830 --> 00:28:34,809
in addition when you think about okay

694
00:28:34,809 --> 00:28:37,320
we've certified it couldn't we also

695
00:28:37,320 --> 00:28:41,620
label it so there's a lot of research in

696
00:28:41,620 --> 00:28:44,230
this space very exciting very current

697
00:28:44,230 --> 00:28:46,659
and again this goes back to my argument

698
00:28:46,659 --> 00:28:49,240
that I said earlier you don't you don't

699
00:28:49,240 --> 00:28:51,760
purchase a packet of crisp thinking okay

700
00:28:51,760 --> 00:28:54,909
I might die from that but you know it's

701
00:28:54,909 --> 00:28:57,190
gonna be okay so the same idea should be

702
00:28:57,190 --> 00:28:58,659
happening if you purchase this smart

703
00:28:58,659 --> 00:29:01,210
Barbie doll that it tells you well it's

704
00:29:01,210 --> 00:29:03,580
internet connected and there's these

705
00:29:03,580 --> 00:29:06,220
kind of you know problems with it

706
00:29:06,220 --> 00:29:09,159
because we have tested it this way so

707
00:29:09,159 --> 00:29:10,840
for example there's three studies that I

708
00:29:10,840 --> 00:29:13,720
want to highlight one is a very recent

709
00:29:13,720 --> 00:29:15,399
study I think only a couple of months

710
00:29:15,399 --> 00:29:17,590
ago which basically had it that users

711
00:29:17,590 --> 00:29:21,309
highly approve of labeling they would

712
00:29:21,309 --> 00:29:23,679
really much value this especially if

713
00:29:23,679 --> 00:29:25,539
it's done by a third party like

714
00:29:25,539 --> 00:29:27,970
independent organizations like which in

715
00:29:27,970 --> 00:29:30,100
the UK because that would allow them to

716
00:29:30,100 --> 00:29:32,110
know when they purchase something that

717
00:29:32,110 --> 00:29:34,899
product you know I can trust the other

718
00:29:34,899 --> 00:29:36,789
thing is Paul Dini at all highlight for

719
00:29:36,789 --> 00:29:38,950
example which dimension users would want

720
00:29:38,950 --> 00:29:41,350
to see when it comes to labeling and it

721
00:29:41,350 --> 00:29:44,649
is a a level of assurance so what system

722
00:29:44,649 --> 00:29:46,809
it was tested on but also kind of the

723
00:29:46,809 --> 00:29:48,820
domain it relates to and then what

724
00:29:48,820 --> 00:29:50,320
certification type was itself

725
00:29:50,320 --> 00:29:52,360
certification third-party certification

726
00:29:52,360 --> 00:29:54,220
which is all going to be important for

727
00:29:54,220 --> 00:29:57,700
the forthcoming aspects in in the

728
00:29:57,700 --> 00:29:59,710
European Union and last but not least

729
00:29:59,710 --> 00:30:01,750
Johnson at all from UCL they were also

730
00:30:01,750 --> 00:30:03,340
doing a lot of research around like our

731
00:30:03,340 --> 00:30:06,159
users willing to pay and they are but

732
00:30:06,159 --> 00:30:08,110
they also highlighted some of the

733
00:30:08,110 --> 00:30:10,929
weaknesses associated with these schemes

734
00:30:10,929 --> 00:30:13,240
because of course you know what are you

735
00:30:13,240 --> 00:30:16,240
gonna do if people are unvoluntary not

736
00:30:16,240 --> 00:30:18,519
able to you know purchase smart devices

737
00:30:18,519 --> 00:30:20,110
and I think that's a discussion around

738
00:30:20,110 --> 00:30:22,000
social inequality and equality that we

739
00:30:22,000 --> 00:30:25,210
need to have as well so the second part

740
00:30:25,210 --> 00:30:26,530
in addition to certification

741
00:30:26,530 --> 00:30:29,110
labeling and last but not least the

742
00:30:29,110 --> 00:30:36,330
really really bad word of liability no

743
00:30:36,330 --> 00:30:40,000
nobody wants to hear it I know but it is

744
00:30:40,000 --> 00:30:41,970
being discussed so I just tell you that

745
00:30:41,970 --> 00:30:44,290
policymakers are discussing it that

746
00:30:44,290 --> 00:30:45,700
doesn't mean it's gonna happen but

747
00:30:45,700 --> 00:30:47,350
certainly people are thinking about it

748
00:30:47,350 --> 00:30:49,960
and I could take out of the shape of

749
00:30:49,960 --> 00:30:51,760
like software liability so that

750
00:30:51,760 --> 00:30:54,490
Microsoft is at fault when it comes to

751
00:30:54,490 --> 00:30:58,180
issues around updates or actually that

752
00:30:58,180 --> 00:30:59,740
perhaps that makes you more happy it

753
00:30:59,740 --> 00:31:01,960
would be distributor liability so it

754
00:31:01,960 --> 00:31:05,740
would be in the UK for example John

755
00:31:05,740 --> 00:31:08,320
Lewis that they have a responsibility to

756
00:31:08,320 --> 00:31:10,390
take back if they have anything in store

757
00:31:10,390 --> 00:31:13,300
and that is no longer secure which would

758
00:31:13,300 --> 00:31:15,370
be if you think about Amazon a really

759
00:31:15,370 --> 00:31:20,440
big issue so I'm not saying yes or no

760
00:31:20,440 --> 00:31:22,600
I'm just saying because this was a talk

761
00:31:22,600 --> 00:31:24,580
about IOT governance this is being

762
00:31:24,580 --> 00:31:29,560
discussed and you make so I also want to

763
00:31:29,560 --> 00:31:32,410
end on so these are all regulatory

764
00:31:32,410 --> 00:31:35,350
aspects or policy issues but I do want

765
00:31:35,350 --> 00:31:37,540
to also say I think we haven't fully

766
00:31:37,540 --> 00:31:39,910
explored the full scale of technical

767
00:31:39,910 --> 00:31:41,620
aspects so I want to highlight two

768
00:31:41,620 --> 00:31:44,020
projects that I am really interested in

769
00:31:44,020 --> 00:31:46,690
and not part of but I think probably

770
00:31:46,690 --> 00:31:49,540
interests the search community a lot so

771
00:31:49,540 --> 00:31:52,450
one is a project by actually Carnegie

772
00:31:52,450 --> 00:31:54,220
Mellon University it's called personal

773
00:31:54,220 --> 00:31:56,530
privacy assistant and I really like the

774
00:31:56,530 --> 00:31:59,080
idea it sounds super sci-fi and as a

775
00:31:59,080 --> 00:32:00,790
social scientist I read those papers and

776
00:32:00,790 --> 00:32:02,680
how I envision it is basically you have

777
00:32:02,680 --> 00:32:04,000
probably a smartphone and you walk

778
00:32:04,000 --> 00:32:06,700
around and this previous the

779
00:32:06,700 --> 00:32:08,590
semi-automated configurate system

780
00:32:08,590 --> 00:32:10,780
basically talks to all the IOT system

781
00:32:10,780 --> 00:32:12,640
and says I don't like to share data with

782
00:32:12,640 --> 00:32:15,880
third-party vendors and I don't like my

783
00:32:15,880 --> 00:32:17,650
pictures being taken and they basically

784
00:32:17,650 --> 00:32:19,750
switch those features off which allows

785
00:32:19,750 --> 00:32:22,390
personalized ability for everyone to

786
00:32:22,390 --> 00:32:24,190
basically set the privacy standards that

787
00:32:24,190 --> 00:32:25,990
they want so I think that's a really

788
00:32:25,990 --> 00:32:28,210
interesting paper highly recommended and

789
00:32:28,210 --> 00:32:30,850
something were you know finally we see a

790
00:32:30,850 --> 00:32:32,770
development if like how could we

791
00:32:32,770 --> 00:32:34,720
actually in this environment this

792
00:32:34,720 --> 00:32:36,400
interconnected environment allow for

793
00:32:36,400 --> 00:32:40,029
personalized individualized security

794
00:32:40,029 --> 00:32:42,309
primarily privacy features the other one

795
00:32:42,309 --> 00:32:44,440
is a uk-based project called data box

796
00:32:44,440 --> 00:32:46,929
and instead of having it in more kind of

797
00:32:46,929 --> 00:32:50,529
a dynamic way this would basically be

798
00:32:50,529 --> 00:32:53,169
next to your router and protect whatever

799
00:32:53,169 --> 00:32:56,259
leaves your household how data is being

800
00:32:56,259 --> 00:32:58,599
distributed again a super amazing

801
00:32:58,599 --> 00:33:01,989
project funded by EPSRC done by

802
00:33:01,989 --> 00:33:04,149
colleagues in Imperial in Newcastle

803
00:33:04,149 --> 00:33:07,119
highly recommended I think that's again

804
00:33:07,119 --> 00:33:09,700
like a move forward to think about it

805
00:33:09,700 --> 00:33:11,259
not just in regulation terms but

806
00:33:11,259 --> 00:33:12,639
actually finding technical solution to

807
00:33:12,639 --> 00:33:14,379
ensure that like the market can fix it

808
00:33:14,379 --> 00:33:19,769
itself so I do want to say though um

809
00:33:19,769 --> 00:33:24,099
someone will have to be responsible so I

810
00:33:24,099 --> 00:33:26,649
don't know who or we at this amount of

811
00:33:26,649 --> 00:33:29,259
time don't know who but it certainly

812
00:33:29,259 --> 00:33:31,299
will be a mix between industry politics

813
00:33:31,299 --> 00:33:33,479
and society and that requires us all

814
00:33:33,479 --> 00:33:37,059
having a proper conversation a lot of

815
00:33:37,059 --> 00:33:38,679
arguments are being brought forward in

816
00:33:38,679 --> 00:33:40,239
literature that you know the World Trade

817
00:33:40,239 --> 00:33:42,279
Organization will deal with it the OECD

818
00:33:42,279 --> 00:33:45,190
or the web I personally have seen that

819
00:33:45,190 --> 00:33:48,249
in publications since 2005 I haven't

820
00:33:48,249 --> 00:33:50,519
seen anyone step up very much about it

821
00:33:50,519 --> 00:33:53,679
so I have more trust currently in what

822
00:33:53,679 --> 00:33:56,440
the US and the European Union does but I

823
00:33:56,440 --> 00:33:57,639
do want to say one thing

824
00:33:57,639 --> 00:34:00,070
I think the Caesar community has to join

825
00:34:00,070 --> 00:34:02,320
the debate or fight however you want to

826
00:34:02,320 --> 00:34:04,869
call it because a as I said you're gonna

827
00:34:04,869 --> 00:34:06,489
be probably the group that will have to

828
00:34:06,489 --> 00:34:08,679
fix it or deal with the mess that is

829
00:34:08,679 --> 00:34:12,520
being created and that's why I also want

830
00:34:12,520 --> 00:34:14,440
to say if you have because I'm a policy

831
00:34:14,440 --> 00:34:17,020
person if you've never ever heard of

832
00:34:17,020 --> 00:34:19,539
submitting evidence to policy processes

833
00:34:19,539 --> 00:34:21,190
it might be something you want to

834
00:34:21,190 --> 00:34:23,409
consider so for example there's

835
00:34:23,409 --> 00:34:26,409
constantly here as consultations open in

836
00:34:26,409 --> 00:34:28,299
the European Union but also in the UK

837
00:34:28,299 --> 00:34:31,059
and in other countries a lot of your big

838
00:34:31,059 --> 00:34:32,409
corporation in this room I'm sure have

839
00:34:32,409 --> 00:34:34,629
policy teams that do that but if you're

840
00:34:34,629 --> 00:34:38,319
smart part of a smart sorry for it in

841
00:34:38,319 --> 00:34:41,980
slip of a small company but have

842
00:34:41,980 --> 00:34:43,869
evidence that would be helpful and you

843
00:34:43,869 --> 00:34:46,119
want to contribute it is very contested

844
00:34:46,119 --> 00:34:48,279
but important debate you know you should

845
00:34:48,279 --> 00:34:51,879
really use your voice to influence the

846
00:34:51,879 --> 00:34:53,290
discussions around that

847
00:34:53,290 --> 00:34:57,400
so now this was as I said more of a

848
00:34:57,400 --> 00:34:57,940
lecture

849
00:34:57,940 --> 00:35:02,110
I'm sorry search but I promise we're

850
00:35:02,110 --> 00:35:05,650
close to the end so I hope I could

851
00:35:05,650 --> 00:35:11,940
basically highlight a that IOT matters

852
00:35:11,940 --> 00:35:15,220
especially it doesn't seem to go away it

853
00:35:15,220 --> 00:35:16,960
has haunted us since quite some time

854
00:35:16,960 --> 00:35:19,660
since the 1990s as a Picard is computing

855
00:35:19,660 --> 00:35:21,700
2006 when it starts to talk about

856
00:35:21,700 --> 00:35:24,130
regulation until this point where we

857
00:35:24,130 --> 00:35:25,630
haven't really moved further in our

858
00:35:25,630 --> 00:35:29,200
debates but ultimately still have to

859
00:35:29,200 --> 00:35:31,350
seem to come to grasp with some form of

860
00:35:31,350 --> 00:35:35,260
policy measures some policy and

861
00:35:35,260 --> 00:35:37,480
governance developments are underway and

862
00:35:37,480 --> 00:35:40,570
happening and they are for quite some

863
00:35:40,570 --> 00:35:43,060
time and I also want to say how won't

864
00:35:43,060 --> 00:35:44,710
hope to have emphasized how the user

865
00:35:44,710 --> 00:35:47,670
fits in I don't feel any of these

866
00:35:47,670 --> 00:35:51,430
governance measures really should push

867
00:35:51,430 --> 00:35:55,090
responsibility to the user insofar as we

868
00:35:55,090 --> 00:35:57,490
have evidence that they will not take it

869
00:35:57,490 --> 00:36:00,610
up so I think it is more important to

870
00:36:00,610 --> 00:36:02,800
look at like ways of ensuring that there

871
00:36:02,800 --> 00:36:04,930
that the public is protected and our

872
00:36:04,930 --> 00:36:07,240
critical infrastructure is protected in

873
00:36:07,240 --> 00:36:10,120
a systematic way then shifting the idea

874
00:36:10,120 --> 00:36:12,640
to education measures which cost a lot

875
00:36:12,640 --> 00:36:14,380
of money and take a lot of time and

876
00:36:14,380 --> 00:36:17,290
rather implement something now often

877
00:36:17,290 --> 00:36:20,080
technical partially also voluntary

878
00:36:20,080 --> 00:36:22,570
mandatory regulation etc to basically

879
00:36:22,570 --> 00:36:25,020
protect the user in this environment I

880
00:36:25,020 --> 00:36:26,950
think the seasonal in peace our

881
00:36:26,950 --> 00:36:29,590
community will definitely have a big

882
00:36:29,590 --> 00:36:31,660
role to play and that's I think where

883
00:36:31,660 --> 00:36:34,120
it's great to have a conversation around

884
00:36:34,120 --> 00:36:38,170
IOT and I really hope that you know this

885
00:36:38,170 --> 00:36:40,900
gave you at least food for thought some

886
00:36:40,900 --> 00:36:44,200
offense with when I said liability but

887
00:36:44,200 --> 00:36:46,000
at least like you know that this is

888
00:36:46,000 --> 00:36:47,260
happening and I'm sure you did before

889
00:36:47,260 --> 00:36:49,960
but you know hopefully also know where

890
00:36:49,960 --> 00:36:51,820
it is happening and that you have the

891
00:36:51,820 --> 00:36:53,800
ability to intervene through submitting

892
00:36:53,800 --> 00:36:57,970
evidence and while I feel can LA

893
00:36:57,970 --> 00:37:01,360
yesterday ended on a very negative note

894
00:37:01,360 --> 00:37:05,100
I for once and I never do that and

895
00:37:05,100 --> 00:37:06,970
positively

896
00:37:06,970 --> 00:37:10,569
I don't think all hope is lost I do

897
00:37:10,569 --> 00:37:12,520
think there is a lot of development

898
00:37:12,520 --> 00:37:15,280
happening again for years but still

899
00:37:15,280 --> 00:37:17,710
there seems to be momentum and I do

900
00:37:17,710 --> 00:37:20,440
think the time is right now before we

901
00:37:20,440 --> 00:37:23,109
really have these IOT systems in all of

902
00:37:23,109 --> 00:37:25,900
our houses if we have those legacy

903
00:37:25,900 --> 00:37:28,150
systems they will not go away now we can

904
00:37:28,150 --> 00:37:29,440
still intervene and make sure that

905
00:37:29,440 --> 00:37:31,750
they're not as horrible as they were

906
00:37:31,750 --> 00:37:34,359
just presented yesterday so I think

907
00:37:34,359 --> 00:37:37,510
there is some hope to ensure that they

908
00:37:37,510 --> 00:37:41,829
are secure ok I want to end by saying if

909
00:37:41,829 --> 00:37:43,750
this all somehow is interesting

910
00:37:43,750 --> 00:37:45,700
I highly recommend having a look at the

911
00:37:45,700 --> 00:37:47,289
Petrus Internet of Things research hub

912
00:37:47,289 --> 00:37:48,780
and the work that we're doing and

913
00:37:48,780 --> 00:37:51,150
there's a lot of industry stakeholders

914
00:37:51,150 --> 00:37:54,490
part of it I have to say I don't even

915
00:37:54,490 --> 00:37:58,180
know how many already I also want to end

916
00:37:58,180 --> 00:38:01,599
on a personal note as well I'm talking

917
00:38:01,599 --> 00:38:03,910
here about like privacy and security in

918
00:38:03,910 --> 00:38:06,010
very general terms and mixing up like

919
00:38:06,010 --> 00:38:08,289
home usage and critical infrastructure

920
00:38:08,289 --> 00:38:11,289
but one thing that personally keeps me

921
00:38:11,289 --> 00:38:14,619
rather awake at night is the evidence

922
00:38:14,619 --> 00:38:16,900
that these systems are actually abused

923
00:38:16,900 --> 00:38:22,270
in domestic violence cases so I do think

924
00:38:22,270 --> 00:38:24,880
that there's an important discussion to

925
00:38:24,880 --> 00:38:26,589
have behalf around like the effect these

926
00:38:26,589 --> 00:38:27,789
systems have for some of the most

927
00:38:27,789 --> 00:38:30,730
vulnerable groups in society and I think

928
00:38:30,730 --> 00:38:32,799
it's not happening now so it's great to

929
00:38:32,799 --> 00:38:35,529
have the opportunity to make this public

930
00:38:35,529 --> 00:38:37,900
here so I think if we don't secure them

931
00:38:37,900 --> 00:38:40,779
for the sake of like for example you

932
00:38:40,779 --> 00:38:44,380
know the average community at least

933
00:38:44,380 --> 00:38:45,670
think about some of the most vulnerable

934
00:38:45,670 --> 00:38:47,589
groups that negative we are affected by

935
00:38:47,589 --> 00:38:49,720
the vulnerabilities that we put into

936
00:38:49,720 --> 00:38:54,220
those system and I also want to say I'm

937
00:38:54,220 --> 00:38:56,260
really interested in what's happening in

938
00:38:56,260 --> 00:38:57,849
everyone's countries so please speak to

939
00:38:57,849 --> 00:39:00,640
me if you have evidence that in Japan or

940
00:39:00,640 --> 00:39:02,349
in career there's more developments

941
00:39:02,349 --> 00:39:04,960
around that and as I said if you haven't

942
00:39:04,960 --> 00:39:06,579
replied to my email and have not spoken

943
00:39:06,579 --> 00:39:08,380
to us about the c-cert research before

944
00:39:08,380 --> 00:39:11,950
it love to talk to you on that note um I

945
00:39:11,950 --> 00:39:14,440
think I'm in time actually ahead of it

946
00:39:14,440 --> 00:39:17,319
which is unusual thank you very very

947
00:39:17,319 --> 00:39:19,510
much I hope this was interesting and I

948
00:39:19,510 --> 00:39:20,020
hope you have a

949
00:39:20,020 --> 00:39:23,190
great conference thank you

950
00:39:29,080 --> 00:39:32,090
Wow I didn't know I was recruiting a

951
00:39:32,090 --> 00:39:35,060
motivational speaker I think that really

952
00:39:35,060 --> 00:39:38,090
was a call to action we do have a bit of

953
00:39:38,090 --> 00:39:40,070
time for questions if anybody has any

954
00:39:40,070 --> 00:39:43,400
there are microphones two at the front

955
00:39:43,400 --> 00:39:47,330
and I think I can just see two there I

956
00:39:47,330 --> 00:39:48,680
think we have a question we have a

957
00:39:48,680 --> 00:39:52,190
couple of questions so learning okay

958
00:39:52,190 --> 00:39:54,770
thank you that was amazing now I don't

959
00:39:54,770 --> 00:39:56,540
know if everyone else saw this morning

960
00:39:56,540 --> 00:39:58,970
that a certain smart television had put

961
00:39:58,970 --> 00:40:01,250
out a warning to its customers that they

962
00:40:01,250 --> 00:40:02,930
should be checking for virus updates on

963
00:40:02,930 --> 00:40:05,390
a regular basis and apparently it took

964
00:40:05,390 --> 00:40:08,390
like 12 steps to get to that chest to

965
00:40:08,390 --> 00:40:10,730
see and you're like who's actually going

966
00:40:10,730 --> 00:40:12,140
to do this one of the things I'm

967
00:40:12,140 --> 00:40:13,400
wondering you were talking about whether

968
00:40:13,400 --> 00:40:14,900
people were willing or not willing to

969
00:40:14,900 --> 00:40:16,550
pay for certain aspects of security and

970
00:40:16,550 --> 00:40:19,340
privacy the balance as security people

971
00:40:19,340 --> 00:40:20,960
we've always fought against what the

972
00:40:20,960 --> 00:40:23,510
product people is usability and how easy

973
00:40:23,510 --> 00:40:25,520
something is versus how secure and

974
00:40:25,520 --> 00:40:27,050
private it is and just wondering what

975
00:40:27,050 --> 00:40:28,610
kinds of aspects of that are you looking

976
00:40:28,610 --> 00:40:32,540
into and what are you finding yep so HCI

977
00:40:32,540 --> 00:40:35,210
research is where I would point to um I

978
00:40:35,210 --> 00:40:37,910
feel like there's a lot of research

979
00:40:37,910 --> 00:40:39,440
showing that people are actually you

980
00:40:39,440 --> 00:40:41,450
know not really willing to pay for it or

981
00:40:41,450 --> 00:40:43,700
they have a very low barrier to you know

982
00:40:43,700 --> 00:40:45,610
being convinced that they should sell it

983
00:40:45,610 --> 00:40:48,350
but that's where the privacy paradox is

984
00:40:48,350 --> 00:40:51,920
there with regards to usability I think

985
00:40:51,920 --> 00:40:56,330
in our research we have a group and that

986
00:40:56,330 --> 00:40:59,570
is in Lancaster and which are amazing

987
00:40:59,570 --> 00:41:01,910
they're thinking what they're doing is

988
00:41:01,910 --> 00:41:03,470
they think about the product and map

989
00:41:03,470 --> 00:41:07,120
back that's what they called Jesus

990
00:41:07,120 --> 00:41:10,040
design vision where future and so for

991
00:41:10,040 --> 00:41:12,080
example they have a smart kettle I know

992
00:41:12,080 --> 00:41:13,580
yesterday everybody was like really bad

993
00:41:13,580 --> 00:41:15,380
about that but they have a smart kettle

994
00:41:15,380 --> 00:41:17,240
called Polly and they're thinking about

995
00:41:17,240 --> 00:41:19,970
like how you know how expensive would

996
00:41:19,970 --> 00:41:22,160
that be how would it look like and then

997
00:41:22,160 --> 00:41:23,900
they met back what security features

998
00:41:23,900 --> 00:41:25,130
would we need to implement to ensure

999
00:41:25,130 --> 00:41:27,050
that so I mean I don't know how your

1000
00:41:27,050 --> 00:41:28,790
product cycles in your companies look

1001
00:41:28,790 --> 00:41:31,100
like but thinking about like what should

1002
00:41:31,100 --> 00:41:33,170
be the endpoint and mapping back what

1003
00:41:33,170 --> 00:41:34,850
could we achieve within the costs and

1004
00:41:34,850 --> 00:41:35,300
everything

1005
00:41:35,300 --> 00:41:37,130
perhaps that is something and there is

1006
00:41:37,130 --> 00:41:38,720
research around that and I can point you

1007
00:41:38,720 --> 00:41:40,160
to a publication from Petrus that I

1008
00:41:40,160 --> 00:41:40,780
would

1009
00:41:40,780 --> 00:41:44,740
comment thank you thank you very much

1010
00:41:44,740 --> 00:41:46,510
for the wonderful talk you mentioned

1011
00:41:46,510 --> 00:41:48,760
food safety ratings earlier and I

1012
00:41:48,760 --> 00:41:49,540
thought that was really interesting

1013
00:41:49,540 --> 00:41:52,270
because it addresses one part of the

1014
00:41:52,270 --> 00:41:54,100
problem for instance the doll that came

1015
00:41:54,100 --> 00:41:56,410
up yesterday but there's another part we

1016
00:41:56,410 --> 00:41:58,360
see shirts often have to deal with which

1017
00:41:58,360 --> 00:42:01,240
is how vulnerable IOT device can

1018
00:42:01,240 --> 00:42:03,010
actually expose the Internet to greater

1019
00:42:03,010 --> 00:42:05,050
harm because there's so many of them a

1020
00:42:05,050 --> 00:42:06,580
little bit like what we saw with Mirai

1021
00:42:06,580 --> 00:42:08,650
and I was wondering if you had any look

1022
00:42:08,650 --> 00:42:11,440
at ratings related to the environment

1023
00:42:11,440 --> 00:42:13,330
that we sometimes see on products and

1024
00:42:13,330 --> 00:42:14,800
where they work and whether there might

1025
00:42:14,800 --> 00:42:16,870
be a solid implementation of the was

1026
00:42:16,870 --> 00:42:20,320
possible in IOT yes definitely

1027
00:42:20,320 --> 00:42:23,110
so the publication so the UK government

1028
00:42:23,110 --> 00:42:25,090
in one of the slides I showed they had

1029
00:42:25,090 --> 00:42:27,220
recently a console or I think it's still

1030
00:42:27,220 --> 00:42:29,530
ongoing so it's still ongoing a

1031
00:42:29,530 --> 00:42:33,580
consultation around labeling and you can

1032
00:42:33,580 --> 00:42:37,270
still submit evidence and we actually so

1033
00:42:37,270 --> 00:42:39,730
the the Johnson paper I referred to

1034
00:42:39,730 --> 00:42:42,310
that's from 2019 they looked at a food

1035
00:42:42,310 --> 00:42:44,530
like all the labeling scheme John had a

1036
00:42:44,530 --> 00:42:47,860
really horrible time and so John

1037
00:42:47,860 --> 00:42:50,170
actually looked at like food labeling

1038
00:42:50,170 --> 00:42:51,940
environment labelings and he did a very

1039
00:42:51,940 --> 00:42:54,790
fair analysis of the pros and cons I

1040
00:42:54,790 --> 00:42:57,550
can't remember from the report whether

1041
00:42:57,550 --> 00:42:59,260
they were it was better than food

1042
00:42:59,260 --> 00:43:01,600
standard ratings but it certainly in

1043
00:43:01,600 --> 00:43:04,390
that report okay thank you very much I'm

1044
00:43:04,390 --> 00:43:06,040
getting a head shake from the front of

1045
00:43:06,040 --> 00:43:07,510
front roads suggest that the

1046
00:43:07,510 --> 00:43:08,890
consultation is now closed

1047
00:43:08,890 --> 00:43:14,370
I am careless with certain Latvian

1048
00:43:14,370 --> 00:43:17,050
basically I have two questions short

1049
00:43:17,050 --> 00:43:20,200
ones so first of all like those papers

1050
00:43:20,200 --> 00:43:22,480
about how people value their privacy in

1051
00:43:22,480 --> 00:43:23,530
2013

1052
00:43:23,530 --> 00:43:26,050
wasn't privacy's and like unchartered

1053
00:43:26,050 --> 00:43:29,350
territory like you know if we ask people

1054
00:43:29,350 --> 00:43:30,670
on the street today like what do they

1055
00:43:30,670 --> 00:43:32,940
think about quantum computing yeah

1056
00:43:32,940 --> 00:43:36,160
nothing and the second one and I like

1057
00:43:36,160 --> 00:43:38,710
now now since people feel how they are

1058
00:43:38,710 --> 00:43:41,110
productized they might that might change

1059
00:43:41,110 --> 00:43:43,240
gradually now and the second one is

1060
00:43:43,240 --> 00:43:46,960
about like the Internet of and I

1061
00:43:46,960 --> 00:43:48,790
mean like soon will have internet of all

1062
00:43:48,790 --> 00:43:52,300
 like I don't expect to change my

1063
00:43:52,300 --> 00:43:53,100
washing machine

1064
00:43:53,100 --> 00:43:55,230
three years as I do with my computers

1065
00:43:55,230 --> 00:43:58,860
and I don't know like we'll have huge

1066
00:43:58,860 --> 00:44:01,800
problems that we don't envision yet

1067
00:44:01,800 --> 00:44:03,960
can you stay because I probably forget

1068
00:44:03,960 --> 00:44:05,640
all your three questions the first one

1069
00:44:05,640 --> 00:44:09,930
was around privacy so you're absolutely

1070
00:44:09,930 --> 00:44:12,650
right I normally never tend to use old

1071
00:44:12,650 --> 00:44:15,360
studies and that's why there was free

1072
00:44:15,360 --> 00:44:18,180
studies so actually the 2013 study that

1073
00:44:18,180 --> 00:44:22,200
was study around a DVD store and a

1074
00:44:22,200 --> 00:44:24,450
privacy setting but still it was about

1075
00:44:24,450 --> 00:44:26,160
like whether they valued like if they

1076
00:44:26,160 --> 00:44:27,750
took notes of it but you still see the

1077
00:44:27,750 --> 00:44:29,190
same dynamic I think it's about the

1078
00:44:29,190 --> 00:44:32,100
dynamic and there are more inertial term

1079
00:44:32,100 --> 00:44:33,480
current studies that have had it the

1080
00:44:33,480 --> 00:44:35,910
same thing so the IOT study is like

1081
00:44:35,910 --> 00:44:38,280
published 2019 if they hide it the same

1082
00:44:38,280 --> 00:44:41,100
problem so while I accept outdated

1083
00:44:41,100 --> 00:44:44,730
probably in 2019 they're still studies

1084
00:44:44,730 --> 00:44:46,710
showing the same problem second question

1085
00:44:46,710 --> 00:44:51,590
was around that was tech pressure moving

1086
00:44:51,590 --> 00:44:54,660
okay okay

1087
00:44:54,660 --> 00:44:57,360
so question with another function so

1088
00:44:57,360 --> 00:44:59,640
that's why I said leasing you know I

1089
00:44:59,640 --> 00:45:02,790
think we're thinking still in terms of

1090
00:45:02,790 --> 00:45:05,610
ownership now if I'm talking and we have

1091
00:45:05,610 --> 00:45:06,870
a lot of industry stakeholders and

1092
00:45:06,870 --> 00:45:08,100
industry circles are sitting here

1093
00:45:08,100 --> 00:45:10,650
there's an increasing shift at least I'm

1094
00:45:10,650 --> 00:45:12,450
in London so I'm writing a lot of tube

1095
00:45:12,450 --> 00:45:13,980
and there's an increasing shift arts

1096
00:45:13,980 --> 00:45:18,360
leasing laptops phones so while I'm not

1097
00:45:18,360 --> 00:45:20,040
saying that the capitalist market

1098
00:45:20,040 --> 00:45:23,070
structure changes very soon I do think

1099
00:45:23,070 --> 00:45:26,300
it could be I have no it like I have

1100
00:45:26,300 --> 00:45:28,560
arguments and papers around that but no

1101
00:45:28,560 --> 00:45:30,750
proper evidence that it might be that

1102
00:45:30,750 --> 00:45:32,430
like you're smarter a washing machine

1103
00:45:32,430 --> 00:45:35,490
might be you lease it and once it's

1104
00:45:35,490 --> 00:45:38,370
outdated meal a or Siemens will replace

1105
00:45:38,370 --> 00:45:40,200
it for you and that's part of the cost

1106
00:45:40,200 --> 00:45:43,080
structure that you're in so I'm not

1107
00:45:43,080 --> 00:45:44,700
saying this is gonna be the fact but

1108
00:45:44,700 --> 00:45:46,200
this is one option that is being

1109
00:45:46,200 --> 00:45:48,740
considered to deal with the out of

1110
00:45:48,740 --> 00:45:52,980
related the the legacy aspects are on

1111
00:45:52,980 --> 00:45:54,660
products that could be deal proof and

1112
00:45:54,660 --> 00:45:57,720
other issues there's a paper by client

1113
00:45:57,720 --> 00:45:58,050
hands

1114
00:45:58,050 --> 00:46:00,240
he's also cited they show different

1115
00:46:00,240 --> 00:46:02,790
options how we could deal with the

1116
00:46:02,790 --> 00:46:05,130
outdated products we could which could

1117
00:46:05,130 --> 00:46:06,840
be for example and I'm not sure that

1118
00:46:06,840 --> 00:46:07,500
you're going to

1119
00:46:07,500 --> 00:46:09,300
happy with that but that certain

1120
00:46:09,300 --> 00:46:10,980
products could be made open source and

1121
00:46:10,980 --> 00:46:12,900
you could maintain it yourself but I'm

1122
00:46:12,900 --> 00:46:14,400
not sure that the industry would go that

1123
00:46:14,400 --> 00:46:16,410
way but it's a hot doesn't sound like a

1124
00:46:16,410 --> 00:46:17,040
great idea

1125
00:46:17,040 --> 00:46:24,180
yeah I wonderful talk enjoy it a locking

1126
00:46:24,180 --> 00:46:26,940
for full disclosure I am a vendor I am

1127
00:46:26,940 --> 00:46:30,810
making lots of stuff so when you are

1128
00:46:30,810 --> 00:46:33,090
saying about and on a safety and making

1129
00:46:33,090 --> 00:46:35,280
parallel with security it is good but

1130
00:46:35,280 --> 00:46:37,110
you are making it sound like security is

1131
00:46:37,110 --> 00:46:40,080
the one thing for safety slightly easier

1132
00:46:40,080 --> 00:46:41,550
just because we know I don't know it

1133
00:46:41,550 --> 00:46:43,950
will burn it will not burn for security

1134
00:46:43,950 --> 00:46:45,390
slightly different and also your

1135
00:46:45,390 --> 00:46:47,730
parallel with the food safety again the

1136
00:46:47,730 --> 00:46:49,950
same thing will make us feel equally

1137
00:46:49,950 --> 00:46:53,040
more or less everybody all humans the

1138
00:46:53,040 --> 00:46:55,410
same thing in security will not affect

1139
00:46:55,410 --> 00:46:57,420
everybody equally because we have

1140
00:46:57,420 --> 00:47:01,430
different perceptions so do you have any

1141
00:47:01,430 --> 00:47:05,490
research on what is I don't know

1142
00:47:05,490 --> 00:47:07,320
acceptable levels of security for

1143
00:47:07,320 --> 00:47:09,120
individuals how they are rating it and

1144
00:47:09,120 --> 00:47:12,900
why so there is certainly so you know

1145
00:47:12,900 --> 00:47:14,790
when you said there's different ways of

1146
00:47:14,790 --> 00:47:16,530
affecting it you know technically you

1147
00:47:16,530 --> 00:47:18,480
could say the same thing if you have a

1148
00:47:18,480 --> 00:47:20,670
food allergy it's gonna affect you worse

1149
00:47:20,670 --> 00:47:22,410
than me so I think like you know we

1150
00:47:22,410 --> 00:47:23,760
could argue we could have a good

1151
00:47:23,760 --> 00:47:25,350
discussion about risk you or that I hope

1152
00:47:25,350 --> 00:47:29,580
so um so I also I'm gonna be a bit

1153
00:47:29,580 --> 00:47:31,950
controversial in this audience I also

1154
00:47:31,950 --> 00:47:35,430
feel like and that like you know the

1155
00:47:35,430 --> 00:47:37,500
security sector often has an easy way

1156
00:47:37,500 --> 00:47:39,750
out of it by saying you know we're new

1157
00:47:39,750 --> 00:47:42,210
it's different but if you think about

1158
00:47:42,210 --> 00:47:45,090
all the engineering that over like how

1159
00:47:45,090 --> 00:47:46,950
long it took to come up with standards

1160
00:47:46,950 --> 00:47:49,200
in the engineering sector on safety

1161
00:47:49,200 --> 00:47:51,420
perhaps it will you know be something

1162
00:47:51,420 --> 00:47:53,580
that in 50 years times we look back and

1163
00:47:53,580 --> 00:47:56,130
be like well you know we're refusing to

1164
00:47:56,130 --> 00:47:58,350
go down a similar path now you you know

1165
00:47:58,350 --> 00:48:02,340
you yeah we can discuss that but I just

1166
00:48:02,340 --> 00:48:04,950
want to say you know of course it's like

1167
00:48:04,950 --> 00:48:07,140
earth-like it's younger its security is

1168
00:48:07,140 --> 00:48:08,400
not something the community is not

1169
00:48:08,400 --> 00:48:09,810
something that like is as long as

1170
00:48:09,810 --> 00:48:11,970
engineering issues building bridges or

1171
00:48:11,970 --> 00:48:15,090
whatever so that would be one response

1172
00:48:15,090 --> 00:48:17,220
but there is certainly studies that look

1173
00:48:17,220 --> 00:48:21,210
in like how security features

1174
00:48:21,210 --> 00:48:24,839
could be you know combined with safety

1175
00:48:24,839 --> 00:48:27,059
but the real problem is I still feel

1176
00:48:27,059 --> 00:48:29,309
like there's not a lot of standards that

1177
00:48:29,309 --> 00:48:33,030
combine them together okay and that's

1178
00:48:33,030 --> 00:48:35,010
where I hope like there will be more

1179
00:48:35,010 --> 00:48:37,530
developments around that I hope Thanks

1180
00:48:37,530 --> 00:48:41,339
okay thank you my name is Samir from

1181
00:48:41,339 --> 00:48:44,579
Egyptians earth and from electrical and

1182
00:48:44,579 --> 00:48:48,559
electrical engineering yoshiya first

1183
00:48:48,559 --> 00:48:51,660
thank you very much for this literature

1184
00:48:51,660 --> 00:48:54,030
in review from academic point of view is

1185
00:48:54,030 --> 00:48:56,369
very very good but you speak you spoke

1186
00:48:56,369 --> 00:48:59,849
about the slowly deregulation is going

1187
00:48:59,849 --> 00:49:02,220
but from my point of view I'm asking you

1188
00:49:02,220 --> 00:49:05,190
about this when the integration coming

1189
00:49:05,190 --> 00:49:08,130
between 5g and IOT and you know the big

1190
00:49:08,130 --> 00:49:11,309
debate coming these days about the 5zi

1191
00:49:11,309 --> 00:49:14,609
I'm afraid to say that we have I think

1192
00:49:14,609 --> 00:49:17,819
we have to have a big research about the

1193
00:49:17,819 --> 00:49:19,920
integration between IOT and 5g and the

1194
00:49:19,920 --> 00:49:21,809
security issues facing that I'm afraid

1195
00:49:21,809 --> 00:49:24,329
to say that maybe we face big issues

1196
00:49:24,329 --> 00:49:27,359
before getting regulations about IOT on

1197
00:49:27,359 --> 00:49:30,809
five days so do you have any ideas I'm

1198
00:49:30,809 --> 00:49:33,270
not talking technical as you said but

1199
00:49:33,270 --> 00:49:34,290
I'm talking about the research

1200
00:49:34,290 --> 00:49:36,660
directions because totally different to

1201
00:49:36,660 --> 00:49:40,530
talk about IOT independently from 5g but

1202
00:49:40,530 --> 00:49:43,619
the divergence will be very very big

1203
00:49:43,619 --> 00:49:47,640
yeah so I have not much research into

1204
00:49:47,640 --> 00:49:51,030
like I haven't looked into 5g but like

1205
00:49:51,030 --> 00:49:52,890
if you think about it just as a policy

1206
00:49:52,890 --> 00:49:55,530
issues a policy issue when increasingly

1207
00:49:55,530 --> 00:49:57,119
government's like for example the UK

1208
00:49:57,119 --> 00:49:58,680
government but also the European Union

1209
00:49:58,680 --> 00:50:00,809
doing is like adaptive regulation

1210
00:50:00,809 --> 00:50:03,540
adaptive policymaking which is the idea

1211
00:50:03,540 --> 00:50:06,510
that like you you slowly implement

1212
00:50:06,510 --> 00:50:08,250
certain measures and then see how it

1213
00:50:08,250 --> 00:50:10,349
turns out and then you adjust it

1214
00:50:10,349 --> 00:50:11,700
slightly and that's why this is more

1215
00:50:11,700 --> 00:50:13,740
tiptoe we have more carrots than sticks

1216
00:50:13,740 --> 00:50:16,049
at the moment not all governments like

1217
00:50:16,049 --> 00:50:18,480
go that way I do think that sometimes

1218
00:50:18,480 --> 00:50:22,049
it's better to do a bit of like slowly

1219
00:50:22,049 --> 00:50:24,329
tip tapping around it so adaptive gab

1220
00:50:24,329 --> 00:50:26,880
governance would be in 5g would be a

1221
00:50:26,880 --> 00:50:28,829
investment in research to see how it

1222
00:50:28,829 --> 00:50:32,670
turns out small scale implementations to

1223
00:50:32,670 --> 00:50:34,630
test it in the real world environment

1224
00:50:34,630 --> 00:50:37,509
and then adopting around that if that's

1225
00:50:37,509 --> 00:50:41,109
if I were the UK government then or any

1226
00:50:41,109 --> 00:50:43,269
government and then see okay they worked

1227
00:50:43,269 --> 00:50:45,309
there how would it extrapolate into all

1228
00:50:45,309 --> 00:50:47,339
this area so I have full control over

1229
00:50:47,339 --> 00:50:49,869
how this is being rolled out that's I

1230
00:50:49,869 --> 00:50:51,249
would treat it like an experiment okay

1231
00:50:51,249 --> 00:50:56,829
thank you thank you thank you very much

1232
00:50:56,829 --> 00:50:59,400
again Leonie

1233
00:51:04,180 --> 00:51:08,140
though I am intrigued to see what the

1234
00:51:08,140 --> 00:51:11,250
author's view of the peer reviewer is

1235
00:51:11,250 --> 00:51:13,720
I'm a little older than the shown in the

1236
00:51:13,720 --> 00:51:16,150
picture but I did enjoy reviewing the

1237
00:51:16,150 --> 00:51:20,890
paper so we start again at 11 o'clock so

1238
00:51:20,890 --> 00:51:25,480
35 minutes with a full program of

1239
00:51:25,480 --> 00:51:28,510
parallel sessions the auditorium will do

1240
00:51:28,510 --> 00:51:30,870
its special stuff while we're out and

1241
00:51:30,870 --> 00:51:34,529
enjoy the rest of the day

