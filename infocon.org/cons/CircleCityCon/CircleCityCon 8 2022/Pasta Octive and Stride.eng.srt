1
00:00:00,930 --> 00:00:08,160
[Music]

2
00:00:08,240 --> 00:00:10,960
hey everybody how are you

3
00:00:10,960 --> 00:00:12,400
you made it

4
00:00:12,400 --> 00:00:14,639
first day of circle city con we're

5
00:00:14,639 --> 00:00:16,239
wrapping it up we're getting right down

6
00:00:16,239 --> 00:00:18,240
to the end of the day we got plenty more

7
00:00:18,240 --> 00:00:19,680
coming tomorrow i hope you all have had

8
00:00:19,680 --> 00:00:21,039
a good time

9
00:00:21,039 --> 00:00:23,600
uh really excited to be here i'm alison

10
00:00:23,600 --> 00:00:25,920
miller and i

11
00:00:25,920 --> 00:00:27,439
can't thank you enough for being a part

12
00:00:27,439 --> 00:00:28,960
of this event

13
00:00:28,960 --> 00:00:31,039
and hopefully we got some more stuff to

14
00:00:31,039 --> 00:00:33,280
just uh keep those juices flowing and

15
00:00:33,280 --> 00:00:35,760
keep you excited and coming back for

16
00:00:35,760 --> 00:00:36,559
more

17
00:00:36,559 --> 00:00:39,680
so let's pop right into this and i'll

18
00:00:39,680 --> 00:00:42,079
start with just simply a little

19
00:00:42,079 --> 00:00:43,760
introduction to myself for those of you

20
00:00:43,760 --> 00:00:46,559
who maybe don't know me uh again my name

21
00:00:46,559 --> 00:00:48,399
is alyssa miller first and foremost i'm

22
00:00:48,399 --> 00:00:50,239
a hacker and a researcher i've been a

23
00:00:50,239 --> 00:00:51,840
hacker all my life

24
00:00:51,840 --> 00:00:53,600
bought my first computer os 12 broke

25
00:00:53,600 --> 00:00:55,520
into some stuff i probably shouldn't

26
00:00:55,520 --> 00:00:56,480
have

27
00:00:56,480 --> 00:00:58,399
but you know that's kind of how a lot of

28
00:00:58,399 --> 00:01:00,160
us got started right

29
00:01:00,160 --> 00:01:02,480
and i do a lot of research so i like to

30
00:01:02,480 --> 00:01:05,199
get out and just dig into technology

31
00:01:05,199 --> 00:01:06,720
i've always had a passion for it i

32
00:01:06,720 --> 00:01:09,439
really really love it and so i like to

33
00:01:09,439 --> 00:01:11,680
dig into it figure out how things work

34
00:01:11,680 --> 00:01:13,760
tell other people about the stuff i find

35
00:01:13,760 --> 00:01:14,799
and

36
00:01:14,799 --> 00:01:17,200
just yeah make it uh

37
00:01:17,200 --> 00:01:18,960
make technology something that we can

38
00:01:18,960 --> 00:01:21,839
all learn from

39
00:01:23,200 --> 00:01:27,520
professionally however i am a be so a

40
00:01:27,520 --> 00:01:29,600
business information security officer

41
00:01:29,600 --> 00:01:33,119
for an organization called s p global

42
00:01:33,119 --> 00:01:35,600
and i am the visa for their ratings

43
00:01:35,600 --> 00:01:37,600
division so if you want to ask me

44
00:01:37,600 --> 00:01:40,400
another time i can tell you all about uh

45
00:01:40,400 --> 00:01:42,159
what a be so is

46
00:01:42,159 --> 00:01:44,720
but just look at it as kind of like a

47
00:01:44,720 --> 00:01:47,200
cso but just for a particular division

48
00:01:47,200 --> 00:01:49,520
and with more of a business focus

49
00:01:49,520 --> 00:01:51,520
than just strictly security like you

50
00:01:51,520 --> 00:01:53,280
would see with the cso how's that sound

51
00:01:53,280 --> 00:01:56,240
easy enough i'm an author and a blogger

52
00:01:56,240 --> 00:01:57,040
my

53
00:01:57,040 --> 00:01:58,799
first book is actually in electronic

54
00:01:58,799 --> 00:02:00,560
preview right now you can buy it in

55
00:02:00,560 --> 00:02:01,840
advance and actually start reading it

56
00:02:01,840 --> 00:02:03,520
before it's even done

57
00:02:03,520 --> 00:02:04,479
um

58
00:02:04,479 --> 00:02:07,200
i also am a blogger i do blog to my

59
00:02:07,200 --> 00:02:09,440
website and also on behalf of different

60
00:02:09,440 --> 00:02:11,599
organizations and so forth

61
00:02:11,599 --> 00:02:14,000
and then finally i'm a former software

62
00:02:14,000 --> 00:02:16,000
developer that's how i got my start in

63
00:02:16,000 --> 00:02:19,200
tech i my first full-time job was as a

64
00:02:19,200 --> 00:02:20,720
programmer for a large financial

65
00:02:20,720 --> 00:02:22,480
technologies company

66
00:02:22,480 --> 00:02:25,599
and that sort of pivoted into a security

67
00:02:25,599 --> 00:02:27,680
uh role where now i've been in security

68
00:02:27,680 --> 00:02:30,239
the last 16 years

69
00:02:30,239 --> 00:02:31,120
so

70
00:02:31,120 --> 00:02:33,920
we're talking threat modeling today

71
00:02:33,920 --> 00:02:35,680
oh i bet a lot of people cringe when

72
00:02:35,680 --> 00:02:38,720
they hear those words threat modeling

73
00:02:38,720 --> 00:02:42,000
oh you know devs hear that word

74
00:02:42,000 --> 00:02:44,239
security people hear that that phrase

75
00:02:44,239 --> 00:02:45,840
what do we think about well we think

76
00:02:45,840 --> 00:02:48,400
about this this big heavyweight process

77
00:02:48,400 --> 00:02:50,959
right we have to create these diagrams

78
00:02:50,959 --> 00:02:53,920
these data flow diagrams that map out

79
00:02:53,920 --> 00:02:56,000
our entire system where data comes in

80
00:02:56,000 --> 00:02:58,000
where it crosses trust boundaries where

81
00:02:58,000 --> 00:03:00,640
it gets stored how it's transmitted what

82
00:03:00,640 --> 00:03:02,560
systems process it

83
00:03:02,560 --> 00:03:05,519
and we're gonna we build this whole big

84
00:03:05,519 --> 00:03:07,760
map and then we're gonna use that to

85
00:03:07,760 --> 00:03:09,599
figure out our threats

86
00:03:09,599 --> 00:03:11,360
and as we start to look at the threats

87
00:03:11,360 --> 00:03:13,360
to that system well we gotta categorize

88
00:03:13,360 --> 00:03:15,200
them so we're gonna use a framework like

89
00:03:15,200 --> 00:03:16,400
stride

90
00:03:16,400 --> 00:03:18,400
and stride has all these really

91
00:03:18,400 --> 00:03:20,959
interesting technical terms like

92
00:03:20,959 --> 00:03:23,360
spoofing and tampering repudiation

93
00:03:23,360 --> 00:03:25,120
information disclosure yada yada yada

94
00:03:25,120 --> 00:03:27,360
yada yada and if you're like me and

95
00:03:27,360 --> 00:03:29,120
you've ever been in threat modeling you

96
00:03:29,120 --> 00:03:31,840
know that those categories can sometimes

97
00:03:31,840 --> 00:03:34,480
be problematic

98
00:03:34,480 --> 00:03:36,879
but we categorize them we we get all our

99
00:03:36,879 --> 00:03:38,480
threats identified we put them in these

100
00:03:38,480 --> 00:03:40,959
categories but now we're going to bring

101
00:03:40,959 --> 00:03:43,360
in this other idea of this pasta

102
00:03:43,360 --> 00:03:45,120
methodology so how are we going to lay

103
00:03:45,120 --> 00:03:46,560
this all out how are we going to do this

104
00:03:46,560 --> 00:03:49,280
over and over make it repeatable and so

105
00:03:49,280 --> 00:03:51,280
you see we've got you know this pasta

106
00:03:51,280 --> 00:03:53,120
methodology it just lays this all out

107
00:03:53,120 --> 00:03:56,080
and oh my goodness you know define

108
00:03:56,080 --> 00:03:58,080
objectives define technical scope

109
00:03:58,080 --> 00:04:00,720
application decomposition thread

110
00:04:00,720 --> 00:04:03,439
analysis vulnerability and weakness

111
00:04:03,439 --> 00:04:06,400
analysis attack modeling risk and impact

112
00:04:06,400 --> 00:04:08,000
analysis oh my god this sounds like a

113
00:04:08,000 --> 00:04:09,439
lot of stuff

114
00:04:09,439 --> 00:04:10,319
and

115
00:04:10,319 --> 00:04:12,159
yeah it ends up being and so now we've

116
00:04:12,159 --> 00:04:13,920
got all our vulnerability or all our

117
00:04:13,920 --> 00:04:15,920
threats figured out and we've gone

118
00:04:15,920 --> 00:04:17,279
through all these different processes

119
00:04:17,279 --> 00:04:18,959
and now we need to start to prioritize

120
00:04:18,959 --> 00:04:20,720
them so we have this thing called dread

121
00:04:20,720 --> 00:04:22,320
and this is how we're going to

122
00:04:22,320 --> 00:04:24,880
categorize the overall risk of these

123
00:04:24,880 --> 00:04:27,520
threats and you know then we've got this

124
00:04:27,520 --> 00:04:29,360
octave process which maybe we want to

125
00:04:29,360 --> 00:04:31,040
try to we want to throw away all this

126
00:04:31,040 --> 00:04:32,160
and we want to approach it just a little

127
00:04:32,160 --> 00:04:33,360
bit differently so we're going to go

128
00:04:33,360 --> 00:04:34,800
with octave

129
00:04:34,800 --> 00:04:35,840
and

130
00:04:35,840 --> 00:04:37,840
what does all this have in common well

131
00:04:37,840 --> 00:04:40,400
it's just it's so complex

132
00:04:40,400 --> 00:04:42,320
so we're going to make it easier we're

133
00:04:42,320 --> 00:04:43,520
gonna come up with this thing called a

134
00:04:43,520 --> 00:04:45,840
capex taxonomy and we're gonna use that

135
00:04:45,840 --> 00:04:47,919
to identify threats that'll help us out

136
00:04:47,919 --> 00:04:48,720
right

137
00:04:48,720 --> 00:04:50,639
all the common threats that we might

138
00:04:50,639 --> 00:04:52,720
face or find in various systems we'll

139
00:04:52,720 --> 00:04:55,120
put them all in a big fat database to

140
00:04:55,120 --> 00:04:58,720
make everybody's life easier

141
00:04:59,120 --> 00:05:01,280
how's that working for you

142
00:05:01,280 --> 00:05:04,639
probably not so well

143
00:05:04,639 --> 00:05:06,320
this is why people hear the term threat

144
00:05:06,320 --> 00:05:07,759
modeling they start to freak out right

145
00:05:07,759 --> 00:05:09,520
like i mean oh my god who's gonna do

146
00:05:09,520 --> 00:05:11,600
this so

147
00:05:11,600 --> 00:05:12,960
there's a lot of people out there who

148
00:05:12,960 --> 00:05:16,160
are really into threat modeling

149
00:05:16,160 --> 00:05:18,800
i am that's why i'm here adam shostak

150
00:05:18,800 --> 00:05:21,199
wrote this book years ago

151
00:05:21,199 --> 00:05:22,800
on threat modeling

152
00:05:22,800 --> 00:05:24,960
what most myself included

153
00:05:24,960 --> 00:05:27,039
have considered the gold standard for

154
00:05:27,039 --> 00:05:29,600
threat modeling and it defines a lot of

155
00:05:29,600 --> 00:05:31,759
processes and it references things like

156
00:05:31,759 --> 00:05:33,840
stride and pasta and how we can use

157
00:05:33,840 --> 00:05:35,840
those in our methodology and how we move

158
00:05:35,840 --> 00:05:37,360
this forward

159
00:05:37,360 --> 00:05:39,759
but there's one thing that still comes

160
00:05:39,759 --> 00:05:41,520
into play

161
00:05:41,520 --> 00:05:43,440
it's always in common it seems when we

162
00:05:43,440 --> 00:05:45,280
talk about modeling and that's this need

163
00:05:45,280 --> 00:05:48,160
for a big design cycle where we start

164
00:05:48,160 --> 00:05:50,080
our threat modeling we look at the

165
00:05:50,080 --> 00:05:52,479
design of our system we figure it out

166
00:05:52,479 --> 00:05:54,000
and then we're gonna figure out where

167
00:05:54,000 --> 00:05:55,759
the threats are

168
00:05:55,759 --> 00:05:59,039
but that's really 2008 thinking

169
00:05:59,039 --> 00:06:01,520
anybody know why i picked 2008 as the

170
00:06:01,520 --> 00:06:02,960
date

171
00:06:02,960 --> 00:06:04,960
well because it was in 2008 that this

172
00:06:04,960 --> 00:06:08,880
cool thing devops showed up on the scene

173
00:06:08,880 --> 00:06:10,720
patrick dubois andrew schafer they got

174
00:06:10,720 --> 00:06:12,880
together and they had this idea of how

175
00:06:12,880 --> 00:06:14,479
they were going to improve software

176
00:06:14,479 --> 00:06:16,400
development and software deployment by

177
00:06:16,400 --> 00:06:18,639
bringing dev and ops together and oh we

178
00:06:18,639 --> 00:06:22,240
kind of left security out in the cold

179
00:06:22,240 --> 00:06:23,680
and we deserve to be left out in the

180
00:06:23,680 --> 00:06:25,759
cold quite honestly for those of my

181
00:06:25,759 --> 00:06:27,680
security practitioners out there because

182
00:06:27,680 --> 00:06:29,520
we didn't move we didn't react to this

183
00:06:29,520 --> 00:06:32,880
this started up in 2008 2009 devops days

184
00:06:32,880 --> 00:06:35,840
first was held by 2012 the first time

185
00:06:35,840 --> 00:06:37,680
security really spoke up about it when

186
00:06:37,680 --> 00:06:40,080
gene kim and josh corman presented on it

187
00:06:40,080 --> 00:06:41,280
at

188
00:06:41,280 --> 00:06:42,880
rsa

189
00:06:42,880 --> 00:06:45,120
we were like years down the road already

190
00:06:45,120 --> 00:06:46,880
and organizations were already doing

191
00:06:46,880 --> 00:06:49,840
their what they considered to be devops

192
00:06:49,840 --> 00:06:50,720
so

193
00:06:50,720 --> 00:06:52,319
with devops we start seeing things like

194
00:06:52,319 --> 00:06:55,680
ci cd and we see these fast paced

195
00:06:55,680 --> 00:06:57,280
development cycles where we probably

196
00:06:57,280 --> 00:07:00,639
don't have those big design cycles so

197
00:07:00,639 --> 00:07:02,400
threat modeling just kind of gets left

198
00:07:02,400 --> 00:07:04,960
out in the cold

199
00:07:04,960 --> 00:07:07,360
but threat modeling is important in fact

200
00:07:07,360 --> 00:07:10,639
in 2019 puppet and circle ci released

201
00:07:10,639 --> 00:07:12,960
their state of devops report and one of

202
00:07:12,960 --> 00:07:15,440
the things that they looked at were

203
00:07:15,440 --> 00:07:17,280
security practices

204
00:07:17,280 --> 00:07:19,599
and how they impacted security posture

205
00:07:19,599 --> 00:07:22,080
versus how frequently we do them

206
00:07:22,080 --> 00:07:23,520
and what you see in the upper left there

207
00:07:23,520 --> 00:07:25,039
are a lot of the security practices we

208
00:07:25,039 --> 00:07:27,840
all know and love penetration testing

209
00:07:27,840 --> 00:07:30,560
and static code analysis

210
00:07:30,560 --> 00:07:33,680
and security requirements oh secure by

211
00:07:33,680 --> 00:07:35,199
design we've heard that phrase before

212
00:07:35,199 --> 00:07:36,160
right

213
00:07:36,160 --> 00:07:37,440
all those things are in the upper left

214
00:07:37,440 --> 00:07:39,599
we do them a lot but they don't improve

215
00:07:39,599 --> 00:07:42,319
our security posture a whole lot

216
00:07:42,319 --> 00:07:43,599
but what happens when i go down to the

217
00:07:43,599 --> 00:07:45,199
lower right here the things we don't do

218
00:07:45,199 --> 00:07:47,120
is often

219
00:07:47,120 --> 00:07:48,960
but they really have a strong impact on

220
00:07:48,960 --> 00:07:50,479
our security posture well that's where i

221
00:07:50,479 --> 00:07:52,560
see collaborative efforts like threat

222
00:07:52,560 --> 00:07:54,240
modeling

223
00:07:54,240 --> 00:07:56,240
this is why threat modeling is important

224
00:07:56,240 --> 00:07:58,080
but again it gets left out in the cold

225
00:07:58,080 --> 00:07:59,680
people forget about it we don't do it

226
00:07:59,680 --> 00:08:01,039
often

227
00:08:01,039 --> 00:08:02,879
so

228
00:08:02,879 --> 00:08:04,000
you know this is something that

229
00:08:04,000 --> 00:08:05,360
frustrates me as somebody who's always

230
00:08:05,360 --> 00:08:06,960
seen the value and really enjoyed threat

231
00:08:06,960 --> 00:08:08,080
modeling and thought it was an

232
00:08:08,080 --> 00:08:10,160
invaluable thing

233
00:08:10,160 --> 00:08:11,759
and so i decided to try to figure out

234
00:08:11,759 --> 00:08:13,840
what we could do about this

235
00:08:13,840 --> 00:08:15,919
how do we how do we make threat modeling

236
00:08:15,919 --> 00:08:17,680
work in a devops world where our

237
00:08:17,680 --> 00:08:19,840
developers and our sres and our

238
00:08:19,840 --> 00:08:23,680
engineers and and our ops folks they all

239
00:08:23,680 --> 00:08:25,919
feel a part of it and they if they don't

240
00:08:25,919 --> 00:08:27,599
feel like it's incompatible with this

241
00:08:27,599 --> 00:08:30,000
processes and so to do that i i figured

242
00:08:30,000 --> 00:08:32,000
okay we got to just get back to basics i

243
00:08:32,000 --> 00:08:33,440
got to think about what is actually

244
00:08:33,440 --> 00:08:35,120
threat modeling at its core and how can

245
00:08:35,120 --> 00:08:37,200
we look at it differently so i have two

246
00:08:37,200 --> 00:08:40,240
questions one let's just define it what

247
00:08:40,240 --> 00:08:42,479
is threat modeling

248
00:08:42,479 --> 00:08:43,760
and then

249
00:08:43,760 --> 00:08:46,480
why why do we threat model

250
00:08:46,480 --> 00:08:48,080
i mean i threw it up there for you that

251
00:08:48,080 --> 00:08:50,640
okay it's got this huge impact on you

252
00:08:50,640 --> 00:08:53,920
know our our security posture but why

253
00:08:53,920 --> 00:08:57,279
why is it so impactful why is this one

254
00:08:57,279 --> 00:08:58,320
process

255
00:08:58,320 --> 00:09:00,800
so important to us

256
00:09:00,800 --> 00:09:03,120
so i set out on a mission a couple years

257
00:09:03,120 --> 00:09:04,560
ago i decided

258
00:09:04,560 --> 00:09:06,000
i'm going to figure this out i want to

259
00:09:06,000 --> 00:09:08,000
know why is how are we going to do

260
00:09:08,000 --> 00:09:09,200
threat modeling and how i'm going to

261
00:09:09,200 --> 00:09:11,120
bring threat modeling into the devsecops

262
00:09:11,120 --> 00:09:12,480
world

263
00:09:12,480 --> 00:09:14,800
so i went looking for

264
00:09:14,800 --> 00:09:16,080
just the definition of what is threat

265
00:09:16,080 --> 00:09:18,320
modeling let's see if i can start there

266
00:09:18,320 --> 00:09:20,399
and i started with every application

267
00:09:20,399 --> 00:09:22,720
security person's favorite place i went

268
00:09:22,720 --> 00:09:24,480
to oas

269
00:09:24,480 --> 00:09:25,920
oasp will have the answers they have the

270
00:09:25,920 --> 00:09:28,320
answers to everything i love owasp

271
00:09:28,320 --> 00:09:29,920
they've got the top ten they have all

272
00:09:29,920 --> 00:09:32,480
their various projects i love the crap

273
00:09:32,480 --> 00:09:34,320
out of owasp let's go ask they they'll

274
00:09:34,320 --> 00:09:36,640
help us out

275
00:09:36,640 --> 00:09:38,000
this was

276
00:09:38,000 --> 00:09:39,920
what i found

277
00:09:39,920 --> 00:09:41,279
i'm not even gonna read this to you it's

278
00:09:41,279 --> 00:09:42,640
so long

279
00:09:42,640 --> 00:09:44,959
this is not getting back to basics this

280
00:09:44,959 --> 00:09:46,640
wasn't helpful to me

281
00:09:46,640 --> 00:09:48,720
i read this i looked at this i i can't

282
00:09:48,720 --> 00:09:51,760
take this to my engineers and say here

283
00:09:51,760 --> 00:09:53,519
this is what you need to do we need to

284
00:09:53,519 --> 00:09:55,040
do threat modeling threat modeling is

285
00:09:55,040 --> 00:09:57,440
this this doesn't help

286
00:09:57,440 --> 00:09:59,360
no this wasn't going to get me anywhere

287
00:09:59,360 --> 00:10:00,880
i mean you see how

288
00:10:00,880 --> 00:10:03,120
lengthy this is and how focused it is on

289
00:10:03,120 --> 00:10:05,680
technical security terms that

290
00:10:05,680 --> 00:10:07,279
those people that i want to collaborate

291
00:10:07,279 --> 00:10:09,120
with in my threat modeling process they

292
00:10:09,120 --> 00:10:10,160
aren't even necessarily going to

293
00:10:10,160 --> 00:10:12,880
understand what these words mean

294
00:10:12,880 --> 00:10:13,680
so

295
00:10:13,680 --> 00:10:15,360
all right oh

296
00:10:15,360 --> 00:10:17,360
you kind of let me down here

297
00:10:17,360 --> 00:10:19,760
let's try another one

298
00:10:19,760 --> 00:10:22,399
if wasp isn't going to help me well then

299
00:10:22,399 --> 00:10:25,200
i'm going to check out wikipedia because

300
00:10:25,200 --> 00:10:27,680
wikipedia if it's there it's it's the

301
00:10:27,680 --> 00:10:29,680
truth right i mean wikipedia everything

302
00:10:29,680 --> 00:10:32,480
in wikipedia is true we know that

303
00:10:32,480 --> 00:10:33,920
okay maybe not

304
00:10:33,920 --> 00:10:35,839
but i thought it was worth a shot

305
00:10:35,839 --> 00:10:38,480
so wikipedia has a definition of threat

306
00:10:38,480 --> 00:10:40,000
modeling as you would expect and this

307
00:10:40,000 --> 00:10:42,079
one was clearly written by more security

308
00:10:42,079 --> 00:10:44,399
people

309
00:10:45,360 --> 00:10:48,800
again lengthy focus on really complex

310
00:10:48,800 --> 00:10:50,160
concepts and

311
00:10:50,160 --> 00:10:51,120
and just

312
00:10:51,120 --> 00:10:52,640
putting things in terms that aren't

313
00:10:52,640 --> 00:10:55,519
easily understood why i need a simpler

314
00:10:55,519 --> 00:10:58,079
definition than this this is so long and

315
00:10:58,079 --> 00:11:00,640
involved how am i going to take this and

316
00:11:00,640 --> 00:11:02,959
use a definition like this to credibly

317
00:11:02,959 --> 00:11:04,000
drive

318
00:11:04,000 --> 00:11:06,399
change in how we bring threat modeling

319
00:11:06,399 --> 00:11:08,720
to a devsecops culture

320
00:11:08,720 --> 00:11:11,040
it's just not going to happen i put this

321
00:11:11,040 --> 00:11:12,480
out in front of people and their minds

322
00:11:12,480 --> 00:11:13,600
go blank

323
00:11:13,600 --> 00:11:15,600
their eyes glaze over they look down at

324
00:11:15,600 --> 00:11:17,200
their cell phones they want

325
00:11:17,200 --> 00:11:20,079
to do nothing with this

326
00:11:20,079 --> 00:11:22,560
this doesn't encourage people

327
00:11:22,560 --> 00:11:24,160
okay

328
00:11:24,160 --> 00:11:25,279
well

329
00:11:25,279 --> 00:11:28,320
i mentioned adam shostak before adam

330
00:11:28,320 --> 00:11:30,560
showstack you saw it was microsoft press

331
00:11:30,560 --> 00:11:32,079
book

332
00:11:32,079 --> 00:11:34,160
what about microsoft microsoft has the

333
00:11:34,160 --> 00:11:35,200
sdl

334
00:11:35,200 --> 00:11:38,160
surely they have a perfect definition

335
00:11:38,160 --> 00:11:39,600
for threat modeling because threat

336
00:11:39,600 --> 00:11:44,399
modeling is a part of microsoft's sdl

337
00:11:44,480 --> 00:11:46,320
that's better

338
00:11:46,320 --> 00:11:47,920
but it's still not what i was looking

339
00:11:47,920 --> 00:11:50,560
for at least here we start to get into

340
00:11:50,560 --> 00:11:52,000
things that are

341
00:11:52,000 --> 00:11:54,800
maybe not quite as technical sounding

342
00:11:54,800 --> 00:11:57,040
it's not as lengthy

343
00:11:57,040 --> 00:11:59,440
okay so it's an engineering technique i

344
00:11:59,440 --> 00:12:01,600
i know engineering techniques i'm going

345
00:12:01,600 --> 00:12:03,360
to identify threats

346
00:12:03,360 --> 00:12:05,120
okay i think i know what a threat is i

347
00:12:05,120 --> 00:12:06,480
know what attacks are i know what

348
00:12:06,480 --> 00:12:08,639
vulnerabilities are

349
00:12:08,639 --> 00:12:10,639
if i'm an engineer do i know what we

350
00:12:10,639 --> 00:12:12,720
mean by counter measures probably okay

351
00:12:12,720 --> 00:12:14,079
we're doing good that could affect my

352
00:12:14,079 --> 00:12:16,000
application well that's bad so i want to

353
00:12:16,000 --> 00:12:18,480
make sure i do something about that

354
00:12:18,480 --> 00:12:21,040
but then oh i can use threat modeling to

355
00:12:21,040 --> 00:12:23,440
shape my applications designed to meet

356
00:12:23,440 --> 00:12:26,160
my company's security objectives and

357
00:12:26,160 --> 00:12:28,480
reduce risk

358
00:12:28,480 --> 00:12:31,120
oh well okay so this is just another one

359
00:12:31,120 --> 00:12:32,320
of those security things you're telling

360
00:12:32,320 --> 00:12:33,839
me i have to do

361
00:12:33,839 --> 00:12:37,040
all right yeah maybe not so still not

362
00:12:37,040 --> 00:12:39,120
the definition i'm looking for

363
00:12:39,120 --> 00:12:40,800
and that's what it comes down to

364
00:12:40,800 --> 00:12:43,120
i just couldn't find the definition that

365
00:12:43,120 --> 00:12:44,720
i wanted

366
00:12:44,720 --> 00:12:45,519
so

367
00:12:45,519 --> 00:12:47,760
i really just i kind of took a step back

368
00:12:47,760 --> 00:12:50,480
and said all right i need to get to the

369
00:12:50,480 --> 00:12:53,200
very most basic definition of what

370
00:12:53,200 --> 00:12:54,800
threat modeling is

371
00:12:54,800 --> 00:12:57,279
because before i can reshape this and

372
00:12:57,279 --> 00:12:59,440
start to say hey this is how we do it in

373
00:12:59,440 --> 00:13:03,040
devsecops or start to bring any change i

374
00:13:03,040 --> 00:13:05,200
need to be able to articulate in words

375
00:13:05,200 --> 00:13:08,079
that anybody can understand whether

376
00:13:08,079 --> 00:13:09,839
they're engineers whether they're my

377
00:13:09,839 --> 00:13:12,000
project managers whether they're my

378
00:13:12,000 --> 00:13:14,480
product managers

379
00:13:14,480 --> 00:13:16,480
i don't care i want them to understand

380
00:13:16,480 --> 00:13:18,720
what threat modeling is so how do i

381
00:13:18,720 --> 00:13:21,200
explain it to them so

382
00:13:21,200 --> 00:13:24,160
it finally hit me

383
00:13:24,160 --> 00:13:25,839
threat modeling

384
00:13:25,839 --> 00:13:29,360
is asking one simple question

385
00:13:29,360 --> 00:13:31,680
what could possibly go wrong

386
00:13:31,680 --> 00:13:34,320
i'm designing a system i'm making

387
00:13:34,320 --> 00:13:37,120
modifications to a system i'm adding new

388
00:13:37,120 --> 00:13:39,600
functionality to an application

389
00:13:39,600 --> 00:13:42,639
based on that what could possibly go

390
00:13:42,639 --> 00:13:44,639
wrong

391
00:13:44,639 --> 00:13:46,639
that's all i want to know

392
00:13:46,639 --> 00:13:49,440
that's what threat modeling is

393
00:13:49,440 --> 00:13:52,000
now think about this for a minute

394
00:13:52,000 --> 00:13:54,320
everybody threat models

395
00:13:54,320 --> 00:13:56,880
we threat model every single day

396
00:13:56,880 --> 00:13:59,199
think about it if you like me you live

397
00:13:59,199 --> 00:14:01,120
out in the suburbs and you're going to

398
00:14:01,120 --> 00:14:03,040
go down to the city

399
00:14:03,040 --> 00:14:05,839
for some event or something and

400
00:14:05,839 --> 00:14:06,959
you want to make sure you're going to be

401
00:14:06,959 --> 00:14:08,399
safe maybe you're worried about the

402
00:14:08,399 --> 00:14:09,760
crime i don't know it depends on which

403
00:14:09,760 --> 00:14:11,040
city you're going to i guess in which

404
00:14:11,040 --> 00:14:12,560
part of the city but those are things

405
00:14:12,560 --> 00:14:14,000
you're going to start to think about

406
00:14:14,000 --> 00:14:15,040
you're going to start to think about am

407
00:14:15,040 --> 00:14:16,880
i gonna be safe what could possibly

408
00:14:16,880 --> 00:14:19,040
happen could i get in a car wreck could

409
00:14:19,040 --> 00:14:20,959
i have car trouble could i have a

410
00:14:20,959 --> 00:14:23,120
problem finding parking these are all

411
00:14:23,120 --> 00:14:25,040
threats to my enjoyment of the evening

412
00:14:25,040 --> 00:14:27,040
if i'm going to say a show in the city

413
00:14:27,040 --> 00:14:28,480
somewhere

414
00:14:28,480 --> 00:14:30,959
that's threat modeling at its core those

415
00:14:30,959 --> 00:14:32,240
are all the things i'm thinking about

416
00:14:32,240 --> 00:14:34,320
that could possibly go wrong and why do

417
00:14:34,320 --> 00:14:35,360
i think about those things that could

418
00:14:35,360 --> 00:14:38,240
possibly go wrong

419
00:14:38,320 --> 00:14:41,279
so i can do something about it

420
00:14:41,279 --> 00:14:44,720
so finally finally a definition that i

421
00:14:44,720 --> 00:14:46,800
was comfortable with a definition that i

422
00:14:46,800 --> 00:14:50,639
felt i could defend i threat modeling is

423
00:14:50,639 --> 00:14:52,720
identifying the likely threats to a

424
00:14:52,720 --> 00:14:54,880
system to inform the design of security

425
00:14:54,880 --> 00:14:56,240
countermeasures

426
00:14:56,240 --> 00:14:58,000
okay it still kind of i got that

427
00:14:58,000 --> 00:14:59,760
security thing in there but

428
00:14:59,760 --> 00:15:01,680
that's necessary

429
00:15:01,680 --> 00:15:02,720
but okay

430
00:15:02,720 --> 00:15:05,680
so it's i'm just identifying threats

431
00:15:05,680 --> 00:15:07,040
so that i can

432
00:15:07,040 --> 00:15:08,800
inform the design that i'm gonna use who

433
00:15:08,800 --> 00:15:10,800
came up with this while i did and you

434
00:15:10,800 --> 00:15:12,560
know what i'm not super thrilled with it

435
00:15:12,560 --> 00:15:15,040
it wasn't the best definition after all

436
00:15:15,040 --> 00:15:16,160
after i started to put this into

437
00:15:16,160 --> 00:15:18,720
practice i still didn't like it

438
00:15:18,720 --> 00:15:21,120
but it was helpful because it was short

439
00:15:21,120 --> 00:15:24,079
and sweet and easy to explain and

440
00:15:24,079 --> 00:15:28,240
anybody can understand this language

441
00:15:28,240 --> 00:15:29,920
now you might ask what our security

442
00:15:29,920 --> 00:15:31,360
counter measures i mean you know what a

443
00:15:31,360 --> 00:15:32,880
counter measure is you know it has to do

444
00:15:32,880 --> 00:15:34,000
with security but what does that really

445
00:15:34,000 --> 00:15:35,920
mean and what do you mean by inform the

446
00:15:35,920 --> 00:15:39,360
design alyssa what does that mean

447
00:15:39,360 --> 00:15:40,800
well

448
00:15:40,800 --> 00:15:42,880
this is the struggle with trying to come

449
00:15:42,880 --> 00:15:43,839
up with

450
00:15:43,839 --> 00:15:46,320
a definition for threat modeling

451
00:15:46,320 --> 00:15:47,120
so

452
00:15:47,120 --> 00:15:48,320
last year

453
00:15:48,320 --> 00:15:51,199
in the heart of the pandemic

454
00:15:51,199 --> 00:15:54,560
myself and 14 other

455
00:15:54,560 --> 00:15:57,440
security practitioners

456
00:15:57,440 --> 00:16:00,240
individuals who had just a passion for

457
00:16:00,240 --> 00:16:03,279
threat modeling we got together

458
00:16:03,279 --> 00:16:06,839
and we wrote the threat modeling

459
00:16:06,839 --> 00:16:08,800
manifesto the goal of the threat

460
00:16:08,800 --> 00:16:11,199
modeling manifesto was to help the world

461
00:16:11,199 --> 00:16:12,959
understand what threat modeling is and

462
00:16:12,959 --> 00:16:15,920
why it is so crucial so we came up with

463
00:16:15,920 --> 00:16:18,800
a new definition

464
00:16:18,800 --> 00:16:20,399
foot modeling is analyzing

465
00:16:20,399 --> 00:16:22,880
representations of a system to highlight

466
00:16:22,880 --> 00:16:24,959
concerns about security and privacy

467
00:16:24,959 --> 00:16:26,720
characteristics

468
00:16:26,720 --> 00:16:29,040
that's what threat modeling is

469
00:16:29,040 --> 00:16:30,320
we're just going to look at

470
00:16:30,320 --> 00:16:31,759
representations now what do

471
00:16:31,759 --> 00:16:33,199
representations mean they could be

472
00:16:33,199 --> 00:16:35,279
diagrams they could be verbal

473
00:16:35,279 --> 00:16:37,519
explanations it could be anything that

474
00:16:37,519 --> 00:16:40,560
tells us about a system

475
00:16:40,560 --> 00:16:43,040
and we're going to use that information

476
00:16:43,040 --> 00:16:45,600
then to highlight the concerns that we

477
00:16:45,600 --> 00:16:46,959
have from a security or privacy

478
00:16:46,959 --> 00:16:49,440
perspective okay

479
00:16:49,440 --> 00:16:52,720
we can use this this is exciting

480
00:16:52,720 --> 00:16:53,440
so

481
00:16:53,440 --> 00:16:57,440
we put together this manifesto

482
00:16:57,440 --> 00:17:01,279
but great so we've got a definition

483
00:17:01,279 --> 00:17:02,800
the next step was we had to answer the

484
00:17:02,800 --> 00:17:04,799
next question the question everybody

485
00:17:04,799 --> 00:17:06,880
asked why

486
00:17:06,880 --> 00:17:09,520
why should we threaten model sure circle

487
00:17:09,520 --> 00:17:12,079
ci and puppet said that it it you know

488
00:17:12,079 --> 00:17:13,520
it's going to make us more secure it's

489
00:17:13,520 --> 00:17:15,919
going to have this huge impact on our

490
00:17:15,919 --> 00:17:18,959
security posture but why

491
00:17:18,959 --> 00:17:22,160
what does it do for us

492
00:17:23,280 --> 00:17:24,799
the output

493
00:17:24,799 --> 00:17:26,319
of a threat model

494
00:17:26,319 --> 00:17:28,480
in forms there's that word again

495
00:17:28,480 --> 00:17:31,200
decisions that you might make in

496
00:17:31,200 --> 00:17:33,760
subsequent design development testing

497
00:17:33,760 --> 00:17:34,720
and

498
00:17:34,720 --> 00:17:37,360
deployment phases so think about this

499
00:17:37,360 --> 00:17:39,679
for a minute if you do threat modeling

500
00:17:39,679 --> 00:17:41,600
very early on

501
00:17:41,600 --> 00:17:43,840
and now let's forget about design for a

502
00:17:43,840 --> 00:17:46,559
minute let's think even earlier

503
00:17:46,559 --> 00:17:48,000
if i'm going to do threat modeling

504
00:17:48,000 --> 00:17:49,760
what's what is the best place i can fit

505
00:17:49,760 --> 00:17:51,679
threat modeling into

506
00:17:51,679 --> 00:17:53,919
my devsecops

507
00:17:53,919 --> 00:17:57,039
development lifecycle

508
00:17:57,280 --> 00:18:00,480
everything starts at the user story you

509
00:18:00,480 --> 00:18:02,000
want to push left we've been talking

510
00:18:02,000 --> 00:18:04,720
push left and security how long

511
00:18:04,720 --> 00:18:06,400
couple decades

512
00:18:06,400 --> 00:18:08,320
how much further left can you go than

513
00:18:08,320 --> 00:18:10,240
the user story

514
00:18:10,240 --> 00:18:12,720
so imagine for a minute we build in

515
00:18:12,720 --> 00:18:14,720
threat modeling information into the

516
00:18:14,720 --> 00:18:16,720
user story well first of all it means we

517
00:18:16,720 --> 00:18:19,360
need our business people involved right

518
00:18:19,360 --> 00:18:20,799
because the business people are the ones

519
00:18:20,799 --> 00:18:22,080
they're going to write those user

520
00:18:22,080 --> 00:18:24,160
stories

521
00:18:24,160 --> 00:18:24,960
so

522
00:18:24,960 --> 00:18:26,400
i need to think about threat modeling

523
00:18:26,400 --> 00:18:27,840
differently

524
00:18:27,840 --> 00:18:29,360
i can't think about it in terms of

525
00:18:29,360 --> 00:18:31,280
stride anymore because i don't want to

526
00:18:31,280 --> 00:18:32,960
train business people to understand

527
00:18:32,960 --> 00:18:35,520
stride

528
00:18:36,400 --> 00:18:38,000
but now i've got that information in my

529
00:18:38,000 --> 00:18:40,480
user story so when my developer goes and

530
00:18:40,480 --> 00:18:43,360
takes a user story off the backlog

531
00:18:43,360 --> 00:18:45,200
maybe in sprint planning if i'm doing

532
00:18:45,200 --> 00:18:47,679
sprint planning or maybe i'm truly ci cd

533
00:18:47,679 --> 00:18:48,960
and they're just going and grabbing the

534
00:18:48,960 --> 00:18:50,960
next highest priority item

535
00:18:50,960 --> 00:18:53,039
either way that information is in that

536
00:18:53,039 --> 00:18:55,919
user story now do i write an entire

537
00:18:55,919 --> 00:18:57,600
threat model for the whole system in

538
00:18:57,600 --> 00:18:59,679
that user story no

539
00:18:59,679 --> 00:19:01,360
all i need my business people to do is

540
00:19:01,360 --> 00:19:03,440
to analyze that user story

541
00:19:03,440 --> 00:19:05,679
and say all right here's the critical

542
00:19:05,679 --> 00:19:06,799
assets

543
00:19:06,799 --> 00:19:09,039
that are part of this user story

544
00:19:09,039 --> 00:19:12,320
maybe it's personal information

545
00:19:12,320 --> 00:19:14,160
things that i have to defend

546
00:19:14,160 --> 00:19:15,200
maybe

547
00:19:15,200 --> 00:19:17,440
that user story represents some critical

548
00:19:17,440 --> 00:19:19,440
functionality and just the availability

549
00:19:19,440 --> 00:19:21,520
of that critical functionality

550
00:19:21,520 --> 00:19:22,840
is an

551
00:19:22,840 --> 00:19:25,600
asset maybe there's financial assets

552
00:19:25,600 --> 00:19:28,240
involved maybe there's trade secrets

553
00:19:28,240 --> 00:19:30,559
involved those are all assets that i

554
00:19:30,559 --> 00:19:31,679
have to defend and once they can

555
00:19:31,679 --> 00:19:33,440
identify the assets that are associated

556
00:19:33,440 --> 00:19:35,679
with that particular user story now they

557
00:19:35,679 --> 00:19:38,559
can sit down and in just very

558
00:19:38,559 --> 00:19:41,520
simple plain language terms describe the

559
00:19:41,520 --> 00:19:43,200
threats i don't need to know if it's

560
00:19:43,200 --> 00:19:45,520
spoofing or tampering or repudiation

561
00:19:45,520 --> 00:19:47,280
that's meaningless to anyone outside of

562
00:19:47,280 --> 00:19:48,720
security

563
00:19:48,720 --> 00:19:50,240
and we're not writing threat models for

564
00:19:50,240 --> 00:19:51,679
security we'll talk more about that a

565
00:19:51,679 --> 00:19:54,240
little bit later

566
00:19:54,559 --> 00:19:56,559
all i need to understand is is there a

567
00:19:56,559 --> 00:19:58,640
risk of theft

568
00:19:58,640 --> 00:20:01,760
is there a risk of you know system

569
00:20:01,760 --> 00:20:03,520
unavailability or the inability to

570
00:20:03,520 --> 00:20:06,400
deliver critical function is there a

571
00:20:06,400 --> 00:20:08,320
risk of fraud

572
00:20:08,320 --> 00:20:09,760
these are the kinds of things this is

573
00:20:09,760 --> 00:20:11,600
the kind of information i want in the

574
00:20:11,600 --> 00:20:13,840
back in that user story because now my

575
00:20:13,840 --> 00:20:15,120
developer takes that they get that

576
00:20:15,120 --> 00:20:16,880
information they can read it they can

577
00:20:16,880 --> 00:20:18,880
see immediately what it is that they

578
00:20:18,880 --> 00:20:20,960
need to prioritize in terms of security

579
00:20:20,960 --> 00:20:22,320
controls

580
00:20:22,320 --> 00:20:23,440
now if you're really good and you're

581
00:20:23,440 --> 00:20:24,720
really immature hopefully you've got

582
00:20:24,720 --> 00:20:26,240
engineering standards maybe reference

583
00:20:26,240 --> 00:20:28,400
architectures that they can pull from in

584
00:20:28,400 --> 00:20:30,559
order to implement security controls but

585
00:20:30,559 --> 00:20:32,880
one way or the nut or another that

586
00:20:32,880 --> 00:20:34,960
engineer that developer is able to sit

587
00:20:34,960 --> 00:20:36,320
down with that threat modeling

588
00:20:36,320 --> 00:20:38,159
information when they're getting ready

589
00:20:38,159 --> 00:20:39,919
to start coding

590
00:20:39,919 --> 00:20:42,960
and they can now start to decide

591
00:20:42,960 --> 00:20:44,880
how am i going to design my

592
00:20:44,880 --> 00:20:48,320
implementation of this user story

593
00:20:48,320 --> 00:20:52,400
this is the informing of those decisions

594
00:20:52,400 --> 00:20:56,080
but it goes further think about this

595
00:20:56,080 --> 00:20:58,240
not only

596
00:20:58,240 --> 00:21:00,559
does it inform my developers

597
00:21:00,559 --> 00:21:02,960
but my developers are now creating

598
00:21:02,960 --> 00:21:04,159
designs

599
00:21:04,159 --> 00:21:05,840
whether they're documenting them whether

600
00:21:05,840 --> 00:21:07,520
it's just implementation as part of ci

601
00:21:07,520 --> 00:21:09,520
cd however they do it they're creating

602
00:21:09,520 --> 00:21:12,240
this code i have this information now i

603
00:21:12,240 --> 00:21:13,120
know

604
00:21:13,120 --> 00:21:14,240
what the threats are i know the

605
00:21:14,240 --> 00:21:16,880
countermeasures that they've implemented

606
00:21:16,880 --> 00:21:19,760
that feeds my test cases so suddenly now

607
00:21:19,760 --> 00:21:22,080
my qa teams can leverage this like oh my

608
00:21:22,080 --> 00:21:23,760
gosh we have threat modeling information

609
00:21:23,760 --> 00:21:25,679
so now we know how to prioritize test

610
00:21:25,679 --> 00:21:27,520
cases maybe if we get really good at

611
00:21:27,520 --> 00:21:29,200
this down the road we can automate the

612
00:21:29,200 --> 00:21:31,840
creation of those test cases

613
00:21:31,840 --> 00:21:33,520
that would be awesome

614
00:21:33,520 --> 00:21:35,520
but we're not done yet what about my

615
00:21:35,520 --> 00:21:38,000
sres this is devops after all what about

616
00:21:38,000 --> 00:21:40,320
that upside what do they what do they

617
00:21:40,320 --> 00:21:43,039
get out of this

618
00:21:43,520 --> 00:21:45,280
oh boy don't they have kind of a good

619
00:21:45,280 --> 00:21:46,559
understanding of what's coming their way

620
00:21:46,559 --> 00:21:48,720
in the first place which ask any of your

621
00:21:48,720 --> 00:21:50,799
sres or your ops teams how often they

622
00:21:50,799 --> 00:21:52,559
get stuck with a new technology that

623
00:21:52,559 --> 00:21:54,240
gets thrown at them in the 11th hour and

624
00:21:54,240 --> 00:21:55,520
they've got to figure out how to support

625
00:21:55,520 --> 00:21:56,559
it

626
00:21:56,559 --> 00:21:58,320
but more importantly because they

627
00:21:58,320 --> 00:22:01,360
understand from what was tested

628
00:22:01,360 --> 00:22:03,360
and what was prioritized and what was

629
00:22:03,360 --> 00:22:05,039
laid out in terms of threats and what

630
00:22:05,039 --> 00:22:07,039
was prior what was laid out in terms of

631
00:22:07,039 --> 00:22:08,880
countermeasures that the

632
00:22:08,880 --> 00:22:10,720
developer created in that particular

633
00:22:10,720 --> 00:22:13,440
user story that now informs how they

634
00:22:13,440 --> 00:22:14,720
design

635
00:22:14,720 --> 00:22:16,320
and implement

636
00:22:16,320 --> 00:22:18,480
monitoring and countermeasures in the

637
00:22:18,480 --> 00:22:21,200
operational environment

638
00:22:21,200 --> 00:22:22,240
this

639
00:22:22,240 --> 00:22:26,720
is the value of threat modeling

640
00:22:26,720 --> 00:22:28,799
this is why threat modeling this

641
00:22:28,799 --> 00:22:30,720
collaboration where we bring all these

642
00:22:30,720 --> 00:22:32,159
people together

643
00:22:32,159 --> 00:22:34,159
either physically like traditional

644
00:22:34,159 --> 00:22:35,520
threat modeling we all get together in a

645
00:22:35,520 --> 00:22:36,640
big meeting

646
00:22:36,640 --> 00:22:37,440
or

647
00:22:37,440 --> 00:22:40,880
through a vehicle like the user story

648
00:22:40,880 --> 00:22:43,679
this is where we start to derive value

649
00:22:43,679 --> 00:22:45,679
so how do we do it

650
00:22:45,679 --> 00:22:48,400
how do we go about building our

651
00:22:48,400 --> 00:22:50,159
methodology

652
00:22:50,159 --> 00:22:52,640
now just like any sports team

653
00:22:52,640 --> 00:22:55,440
every organization

654
00:22:55,440 --> 00:22:56,880
is going to have

655
00:22:56,880 --> 00:22:59,200
their own methodology for doing threat

656
00:22:59,200 --> 00:23:01,600
modeling

657
00:23:02,640 --> 00:23:04,320
we all have different development

658
00:23:04,320 --> 00:23:06,880
pipelines we all look at this thing just

659
00:23:06,880 --> 00:23:08,240
a little bit differently we have our own

660
00:23:08,240 --> 00:23:10,480
needs our own requirements our own

661
00:23:10,480 --> 00:23:13,520
concerns our own risk profiles

662
00:23:13,520 --> 00:23:15,919
so when it comes to threat modeling

663
00:23:15,919 --> 00:23:17,679
and when it comes to the threat modeling

664
00:23:17,679 --> 00:23:20,240
manifesto the last thing we wanted to do

665
00:23:20,240 --> 00:23:23,039
was build a methodology

666
00:23:23,039 --> 00:23:24,880
that was prescriptive

667
00:23:24,880 --> 00:23:27,600
so we didn't build a methodology at all

668
00:23:27,600 --> 00:23:31,360
instead what we did was we documented

669
00:23:31,360 --> 00:23:32,960
values

670
00:23:32,960 --> 00:23:34,840
practices

671
00:23:34,840 --> 00:23:39,679
patterns and anti-patterns that describe

672
00:23:39,679 --> 00:23:42,880
what is at the core of threat modeling

673
00:23:42,880 --> 00:23:44,480
so that people could read through these

674
00:23:44,480 --> 00:23:46,240
and they could take them and they could

675
00:23:46,240 --> 00:23:48,640
begin to build a methodology that was

676
00:23:48,640 --> 00:23:52,400
tailored to their organization

677
00:23:52,400 --> 00:23:54,159
and this is what threat modeling is all

678
00:23:54,159 --> 00:23:55,039
about

679
00:23:55,039 --> 00:23:57,120
if we're talking collaboration it needs

680
00:23:57,120 --> 00:23:59,039
to be something that fits into the way

681
00:23:59,039 --> 00:24:01,760
we work whether it's automation whether

682
00:24:01,760 --> 00:24:04,480
it's processes how will we do this you

683
00:24:04,480 --> 00:24:06,320
you can't make this assumption that

684
00:24:06,320 --> 00:24:07,679
there's going to be some cool threat

685
00:24:07,679 --> 00:24:08,960
modeling tool that you're going to plug

686
00:24:08,960 --> 00:24:10,640
into your pipeline and that's going to

687
00:24:10,640 --> 00:24:13,120
do all this for you

688
00:24:13,120 --> 00:24:14,880
thread modeling doesn't work that way

689
00:24:14,880 --> 00:24:17,279
threat modeling works on the idea of

690
00:24:17,279 --> 00:24:19,520
collaboration

691
00:24:19,520 --> 00:24:23,039
you saw the circle ci and puppet report

692
00:24:23,039 --> 00:24:24,799
so

693
00:24:24,799 --> 00:24:27,600
when we set out to build this

694
00:24:27,600 --> 00:24:30,240
this manifesto this thing that was going

695
00:24:30,240 --> 00:24:32,640
to bring threat modeling to the masses

696
00:24:32,640 --> 00:24:34,640
to encourage and excite people to do

697
00:24:34,640 --> 00:24:37,440
threat modeling in their organizations

698
00:24:37,440 --> 00:24:39,520
we did not

699
00:24:39,520 --> 00:24:42,799
want to create a methodology another

700
00:24:42,799 --> 00:24:45,279
framework another thing to throw at the

701
00:24:45,279 --> 00:24:47,919
problem that might be helpful for some

702
00:24:47,919 --> 00:24:49,440
but for others would be instantly

703
00:24:49,440 --> 00:24:51,360
rejected as not fitting their

704
00:24:51,360 --> 00:24:54,320
environment as too complex as not

705
00:24:54,320 --> 00:24:56,880
compatible with their high-speed dynamic

706
00:24:56,880 --> 00:25:00,720
development and deployment phases

707
00:25:00,720 --> 00:25:03,600
so like i said we created values

708
00:25:03,600 --> 00:25:06,159
principles patterns and anti-patterns we

709
00:25:06,159 --> 00:25:07,760
described what was most important to

710
00:25:07,760 --> 00:25:09,760
threat modeling what's most important in

711
00:25:09,760 --> 00:25:11,279
the methodology

712
00:25:11,279 --> 00:25:14,000
what are things that represent good

713
00:25:14,000 --> 00:25:15,440
threat modeling and what are

714
00:25:15,440 --> 00:25:17,679
anti-patterns that threaten to destroy

715
00:25:17,679 --> 00:25:19,279
threat modeling

716
00:25:19,279 --> 00:25:20,400
and that's what you'll find in the

717
00:25:20,400 --> 00:25:22,400
manifesto

718
00:25:22,400 --> 00:25:24,880
so we started with values

719
00:25:24,880 --> 00:25:26,880
so a value in threat modeling is

720
00:25:26,880 --> 00:25:29,840
something that has relative worth merit

721
00:25:29,840 --> 00:25:32,159
or importance okay these are the things

722
00:25:32,159 --> 00:25:34,000
that are crucial

723
00:25:34,000 --> 00:25:36,159
to the threat modeling process

724
00:25:36,159 --> 00:25:39,679
you know this is the core of it

725
00:25:39,679 --> 00:25:40,480
so

726
00:25:40,480 --> 00:25:43,600
while there is value in the items on the

727
00:25:43,600 --> 00:25:46,000
right as you're going to see in a moment

728
00:25:46,000 --> 00:25:50,480
we value the items on the left more

729
00:25:50,480 --> 00:25:51,840
so what you're going to see in just a

730
00:25:51,840 --> 00:25:54,320
moment is i will go through the values

731
00:25:54,320 --> 00:25:57,919
that we described in the manifesto

732
00:25:57,919 --> 00:25:59,840
you're going to see

733
00:25:59,840 --> 00:26:01,760
on the left

734
00:26:01,760 --> 00:26:04,720
that thing that is of greatest value

735
00:26:04,720 --> 00:26:06,240
that thing that

736
00:26:06,240 --> 00:26:08,320
brings

737
00:26:08,320 --> 00:26:09,600
the oomph

738
00:26:09,600 --> 00:26:11,200
to threat modeling the thing that makes

739
00:26:11,200 --> 00:26:12,880
threat modeling

740
00:26:12,880 --> 00:26:13,840
so

741
00:26:13,840 --> 00:26:15,840
powerful for our organizations and on

742
00:26:15,840 --> 00:26:18,159
the right those things that while they

743
00:26:18,159 --> 00:26:20,400
might have some value

744
00:26:20,400 --> 00:26:22,159
they also tend to be the things that

745
00:26:22,159 --> 00:26:23,120
aren't

746
00:26:23,120 --> 00:26:25,279
as helpful when we're talking threat

747
00:26:25,279 --> 00:26:27,520
modeling

748
00:26:27,520 --> 00:26:29,760
so let's dive in because as you're

749
00:26:29,760 --> 00:26:30,720
thinking about how you're going to

750
00:26:30,720 --> 00:26:33,760
launch a methodology it is so crucial

751
00:26:33,760 --> 00:26:36,400
that these values are at the core of

752
00:26:36,400 --> 00:26:39,120
what you do

753
00:26:39,120 --> 00:26:41,360
so our first value

754
00:26:41,360 --> 00:26:44,640
a culture of finding and fixing design

755
00:26:44,640 --> 00:26:47,919
issues well that sounds like duh right

756
00:26:47,919 --> 00:26:51,440
over checkbox compliance

757
00:26:51,440 --> 00:26:52,960
how about this for an example of

758
00:26:52,960 --> 00:26:56,080
checkbox compliance

759
00:26:56,080 --> 00:26:58,559
hey you gotta have a parking space

760
00:26:58,559 --> 00:27:01,520
that's marked with a handicapped sign

761
00:27:01,520 --> 00:27:03,840
and only allows handicap parking

762
00:27:03,840 --> 00:27:05,679
great we did it

763
00:27:05,679 --> 00:27:08,159
we marked a space

764
00:27:08,159 --> 00:27:10,159
nobody can park there

765
00:27:10,159 --> 00:27:12,880
completely useless but by god we're

766
00:27:12,880 --> 00:27:14,559
compliant

767
00:27:14,559 --> 00:27:16,640
and isn't that a frustration that so

768
00:27:16,640 --> 00:27:20,159
many of us have in our organizations we

769
00:27:20,159 --> 00:27:22,000
do the security thing not because it

770
00:27:22,000 --> 00:27:23,760
makes us more secure we do the security

771
00:27:23,760 --> 00:27:26,000
thing to check a box

772
00:27:26,000 --> 00:27:27,360
maybe we sit down with something like

773
00:27:27,360 --> 00:27:29,679
pci and we look at this laundry list of

774
00:27:29,679 --> 00:27:31,520
things we say all right i'm gonna check

775
00:27:31,520 --> 00:27:33,440
off all these boxes but none of the

776
00:27:33,440 --> 00:27:34,720
things that we actually implement work

777
00:27:34,720 --> 00:27:37,279
together none of them actually are

778
00:27:37,279 --> 00:27:39,919
effective counter measures they just are

779
00:27:39,919 --> 00:27:41,679
a way for us to say yeah we did this

780
00:27:41,679 --> 00:27:43,360
thing

781
00:27:43,360 --> 00:27:45,919
or maybe it's nist maybe it's the 800

782
00:27:45,919 --> 00:27:47,120
that 50

783
00:27:47,120 --> 00:27:51,279
excuse me 800-53 controls

784
00:27:51,279 --> 00:27:53,039
all of those controls that are specified

785
00:27:53,039 --> 00:27:56,600
in nist 853.

786
00:27:57,600 --> 00:27:59,360
why do we do them

787
00:27:59,360 --> 00:28:03,200
do they even apply to our organization

788
00:28:03,200 --> 00:28:04,480
that's what we're talking about with

789
00:28:04,480 --> 00:28:07,039
checkbox compliance now when it comes to

790
00:28:07,039 --> 00:28:09,679
threat modeling so often threat modeling

791
00:28:09,679 --> 00:28:12,240
is just done because security said this

792
00:28:12,240 --> 00:28:16,159
is required so dow must do it

793
00:28:16,159 --> 00:28:17,520
that's not

794
00:28:17,520 --> 00:28:20,000
it's not creating a culture

795
00:28:20,000 --> 00:28:22,559
that's not making the focus finding and

796
00:28:22,559 --> 00:28:25,039
fixing design issues that's making a

797
00:28:25,039 --> 00:28:27,679
culture of creating a bunch of drawings

798
00:28:27,679 --> 00:28:29,360
that describe our system and sitting

799
00:28:29,360 --> 00:28:31,200
down and having meetings and doing it

800
00:28:31,200 --> 00:28:34,080
all because infosec said we had to

801
00:28:34,080 --> 00:28:35,520
that's not what threat modeling should

802
00:28:35,520 --> 00:28:37,440
be about but modeling needs to be about

803
00:28:37,440 --> 00:28:40,240
that culture that collaboration

804
00:28:40,240 --> 00:28:41,919
bringing people together in a way that

805
00:28:41,919 --> 00:28:43,919
they all understand it okay this is

806
00:28:43,919 --> 00:28:45,840
going to help us highlight where we

807
00:28:45,840 --> 00:28:48,399
might have challenges in our design

808
00:28:48,399 --> 00:28:50,480
maybe they're flaws maybe it's just we

809
00:28:50,480 --> 00:28:52,640
have questions about the design but we

810
00:28:52,640 --> 00:28:55,120
understand them in the light of threats

811
00:28:55,120 --> 00:28:56,880
that we are likely to face with this

812
00:28:56,880 --> 00:29:00,399
system and so now we can react to them

813
00:29:00,399 --> 00:29:02,399
we want to build that culture with

814
00:29:02,399 --> 00:29:04,720
threat modeling so it's not just an

815
00:29:04,720 --> 00:29:06,159
activity

816
00:29:06,159 --> 00:29:08,000
or a requirement

817
00:29:08,000 --> 00:29:09,679
but it's something that we constantly

818
00:29:09,679 --> 00:29:11,440
think about our engineers are thinking

819
00:29:11,440 --> 00:29:14,480
about it our sres are

820
00:29:14,480 --> 00:29:17,440
our operations support analysts our

821
00:29:17,440 --> 00:29:20,080
product managers our project teams our

822
00:29:20,080 --> 00:29:23,039
business everybody needs to be a part of

823
00:29:23,039 --> 00:29:24,399
that

824
00:29:24,399 --> 00:29:26,720
that's where threat modeling gains value

825
00:29:26,720 --> 00:29:28,399
for us

826
00:29:28,399 --> 00:29:29,600
so

827
00:29:29,600 --> 00:29:31,440
yeah maybe checkbox compliance is

828
00:29:31,440 --> 00:29:33,360
helpful maybe those requirements get us

829
00:29:33,360 --> 00:29:35,039
somewhere

830
00:29:35,039 --> 00:29:37,200
they make sure we're at least doing it

831
00:29:37,200 --> 00:29:38,720
but if we're not fixing and finding the

832
00:29:38,720 --> 00:29:41,120
design issues

833
00:29:41,120 --> 00:29:43,440
what what's the point

834
00:29:43,440 --> 00:29:45,520
so the culture of finding and fixing

835
00:29:45,520 --> 00:29:49,600
design issues that's the value here

836
00:29:49,840 --> 00:29:51,440
moving on

837
00:29:51,440 --> 00:29:53,279
our next value

838
00:29:53,279 --> 00:29:54,799
the next thing that we thought was

839
00:29:54,799 --> 00:29:55,919
crucial

840
00:29:55,919 --> 00:29:58,320
you've heard me say this now probably

841
00:29:58,320 --> 00:29:59,840
i don't know at least eight or nine

842
00:29:59,840 --> 00:30:02,000
times i've used the c word not that c

843
00:30:02,000 --> 00:30:04,080
word come on stay with me folks i know

844
00:30:04,080 --> 00:30:05,600
it's late in the day

845
00:30:05,600 --> 00:30:07,919
but i'm talking about collaboration

846
00:30:07,919 --> 00:30:10,880
people and collaboration

847
00:30:10,880 --> 00:30:12,960
those things that puppet and circle ci

848
00:30:12,960 --> 00:30:14,159
highlighted

849
00:30:14,159 --> 00:30:16,399
in that report

850
00:30:16,399 --> 00:30:18,720
people in collaboration over processes

851
00:30:18,720 --> 00:30:22,080
methodologies and tools we're not going

852
00:30:22,080 --> 00:30:24,960
to get there with tools

853
00:30:24,960 --> 00:30:27,840
i can't count on my hands and feet

854
00:30:27,840 --> 00:30:30,159
combined the number of people who i've

855
00:30:30,159 --> 00:30:31,840
seen suggest well we just need an

856
00:30:31,840 --> 00:30:34,880
automated tool to do threat modeling

857
00:30:34,880 --> 00:30:37,919
there's no value in that

858
00:30:37,919 --> 00:30:40,000
if i just have this tool it runs it does

859
00:30:40,000 --> 00:30:42,320
this thing yeah it might highlight some

860
00:30:42,320 --> 00:30:44,000
design concerns

861
00:30:44,000 --> 00:30:46,080
it might show me where this design is

862
00:30:46,080 --> 00:30:48,480
off or maybe i need to implement an

863
00:30:48,480 --> 00:30:50,399
additional configuration it might be

864
00:30:50,399 --> 00:30:52,480
able to suggest certain things

865
00:30:52,480 --> 00:30:54,720
but that's not the heart of the value of

866
00:30:54,720 --> 00:30:56,960
threat modeling threat modeling again

867
00:30:56,960 --> 00:30:58,960
going back to that culture it's

868
00:30:58,960 --> 00:31:01,519
bringing everybody together the exchange

869
00:31:01,519 --> 00:31:03,919
of ideas getting perspectives on these

870
00:31:03,919 --> 00:31:06,000
things from people who come from the

871
00:31:06,000 --> 00:31:08,399
engineering org who come from our

872
00:31:08,399 --> 00:31:11,600
business lines who are supporting our

873
00:31:11,600 --> 00:31:15,279
operations environments on a day-to-day

874
00:31:15,279 --> 00:31:16,880
that's what we're looking for in terms

875
00:31:16,880 --> 00:31:19,039
of threat modeling so

876
00:31:19,039 --> 00:31:21,600
in a classic environment yeah oftentimes

877
00:31:21,600 --> 00:31:24,559
they were these large meetings

878
00:31:24,559 --> 00:31:26,320
now i went to the other extreme with my

879
00:31:26,320 --> 00:31:27,840
example before about the user story

880
00:31:27,840 --> 00:31:28,880
where i said you're going to have one

881
00:31:28,880 --> 00:31:30,240
you know business person maybe it's a

882
00:31:30,240 --> 00:31:31,679
business analyst maybe it's a product

883
00:31:31,679 --> 00:31:34,480
manager whomever that's writing that

884
00:31:34,480 --> 00:31:36,399
particular user story and you're just

885
00:31:36,399 --> 00:31:38,080
going to have them do it

886
00:31:38,080 --> 00:31:41,120
maybe we go somewhere in between

887
00:31:41,120 --> 00:31:42,720
is there a way that we can bring

888
00:31:42,720 --> 00:31:45,440
multiple people into that process of

889
00:31:45,440 --> 00:31:47,039
putting that information in the user

890
00:31:47,039 --> 00:31:48,640
story how do your users stories get

891
00:31:48,640 --> 00:31:50,640
created is it just one person that

892
00:31:50,640 --> 00:31:52,880
creates them or do you have people who

893
00:31:52,880 --> 00:31:54,399
are sitting together and writing these

894
00:31:54,399 --> 00:31:57,679
things who have different perspectives

895
00:31:57,679 --> 00:31:59,519
do you have committees that get together

896
00:31:59,519 --> 00:32:01,760
and talk about what user stories are

897
00:32:01,760 --> 00:32:03,039
going to be most important that they

898
00:32:03,039 --> 00:32:05,360
want to put on the backlog

899
00:32:05,360 --> 00:32:07,679
leverage that same process

900
00:32:07,679 --> 00:32:09,919
get those diverse ideas get people

901
00:32:09,919 --> 00:32:12,240
talking get that threat information out

902
00:32:12,240 --> 00:32:13,760
there now if you put that threat

903
00:32:13,760 --> 00:32:17,039
information into your user story i

904
00:32:17,039 --> 00:32:18,720
covered that in that example how that

905
00:32:18,720 --> 00:32:21,200
creates collaboration and it pushes the

906
00:32:21,200 --> 00:32:22,960
information all the way through to your

907
00:32:22,960 --> 00:32:25,039
devs to your apps

908
00:32:25,039 --> 00:32:27,600
you can give security the heads up

909
00:32:27,600 --> 00:32:29,840
so now suddenly we can leverage that and

910
00:32:29,840 --> 00:32:32,000
that's so much more important than the

911
00:32:32,000 --> 00:32:34,480
process methodologies and tools yes we

912
00:32:34,480 --> 00:32:36,240
need to have processes for doing this we

913
00:32:36,240 --> 00:32:38,000
need to have the methodologies for doing

914
00:32:38,000 --> 00:32:38,960
this

915
00:32:38,960 --> 00:32:41,360
and whatever tools we do use

916
00:32:41,360 --> 00:32:44,000
whether you know it's templates reports

917
00:32:44,000 --> 00:32:46,640
whatever maybe it is even some automated

918
00:32:46,640 --> 00:32:48,559
tooling that can help us

919
00:32:48,559 --> 00:32:50,240
that's not where the value is coming

920
00:32:50,240 --> 00:32:52,080
from though the value is coming from

921
00:32:52,080 --> 00:32:53,919
bringing people together so they can all

922
00:32:53,919 --> 00:32:56,480
understand share their ideas and really

923
00:32:56,480 --> 00:32:58,559
talk about what this user story

924
00:32:58,559 --> 00:33:00,799
represents in terms of the overall

925
00:33:00,799 --> 00:33:02,640
system

926
00:33:02,640 --> 00:33:03,760
so

927
00:33:03,760 --> 00:33:05,840
valuing people and collaboration over

928
00:33:05,840 --> 00:33:09,200
processes methodologies and tools

929
00:33:09,200 --> 00:33:10,559
build this

930
00:33:10,559 --> 00:33:12,480
make this one of your focal points as

931
00:33:12,480 --> 00:33:14,399
you're building out your threat modeling

932
00:33:14,399 --> 00:33:17,199
methodology

933
00:33:17,679 --> 00:33:20,159
next

934
00:33:21,600 --> 00:33:23,120
credit modeling is a journey of

935
00:33:23,120 --> 00:33:25,840
understanding

936
00:33:26,559 --> 00:33:31,200
over a security and privacy snapshot

937
00:33:31,600 --> 00:33:33,360
we're really used to snapshots and

938
00:33:33,360 --> 00:33:35,360
security aren't we

939
00:33:35,360 --> 00:33:36,880
we run vulnerability scans what do we

940
00:33:36,880 --> 00:33:38,480
say about it well this is a snapshot of

941
00:33:38,480 --> 00:33:39,919
the environment as of when we ran that

942
00:33:39,919 --> 00:33:43,120
scan here's the vulnerabilities

943
00:33:43,120 --> 00:33:44,960
we pen test the web application same

944
00:33:44,960 --> 00:33:46,799
thing

945
00:33:46,799 --> 00:33:48,480
heck i was a consultant for eight years

946
00:33:48,480 --> 00:33:51,360
we actually wrote that in our contracts

947
00:33:51,360 --> 00:33:55,199
this is a point in time assessment

948
00:33:57,360 --> 00:33:59,679
what does that do for us

949
00:33:59,679 --> 00:34:02,640
that means that once a year

950
00:34:02,640 --> 00:34:04,159
maybe

951
00:34:04,159 --> 00:34:07,840
maybe less maybe more probably less

952
00:34:07,840 --> 00:34:10,239
but let's say our we test our apps once

953
00:34:10,239 --> 00:34:11,679
a year

954
00:34:11,679 --> 00:34:13,040
once a year i'm going to have to go

955
00:34:13,040 --> 00:34:14,159
through a pen test and i'm going to get

956
00:34:14,159 --> 00:34:17,040
a bunch of new work to do

957
00:34:17,040 --> 00:34:19,760
and now for the you're following i'm

958
00:34:19,760 --> 00:34:20,800
going to have to work through all those

959
00:34:20,800 --> 00:34:22,399
vulnerabilities that someone gave me on

960
00:34:22,399 --> 00:34:23,440
a report

961
00:34:23,440 --> 00:34:27,040
that's what i'm seeing as an engineer

962
00:34:27,918 --> 00:34:30,480
and so then i get through all those okay

963
00:34:30,480 --> 00:34:32,560
oh i closed all those out and what

964
00:34:32,560 --> 00:34:34,079
happens next well we run the next pen

965
00:34:34,079 --> 00:34:36,800
test hey there's all new vulnerabilities

966
00:34:36,800 --> 00:34:38,560
and what happens our engineering teams

967
00:34:38,560 --> 00:34:40,159
get frustrated

968
00:34:40,159 --> 00:34:42,480
our risk organization

969
00:34:42,480 --> 00:34:44,079
gets frustrated

970
00:34:44,079 --> 00:34:47,119
our executives get frustrated why are we

971
00:34:47,119 --> 00:34:49,440
spending all this time

972
00:34:49,440 --> 00:34:50,960
remedying vulnerabilities and we just

973
00:34:50,960 --> 00:34:52,320
keep coming back and having more and

974
00:34:52,320 --> 00:34:54,960
more and more

975
00:34:55,440 --> 00:34:56,800
that's what happens and in threat

976
00:34:56,800 --> 00:34:58,720
modeling we do the same thing

977
00:34:58,720 --> 00:35:00,400
think about that we go and we do a

978
00:35:00,400 --> 00:35:02,960
threat modeling say we have some type of

979
00:35:02,960 --> 00:35:05,520
you know threshold in which you know a

980
00:35:05,520 --> 00:35:08,320
change that's so x large has to go

981
00:35:08,320 --> 00:35:10,400
through a threat modeling process so we

982
00:35:10,400 --> 00:35:12,720
go through we drop those big data flow

983
00:35:12,720 --> 00:35:14,400
diagrams we go through stride we

984
00:35:14,400 --> 00:35:16,079
categorize out all these threads and

985
00:35:16,079 --> 00:35:17,599
then we say oh we're going to build in

986
00:35:17,599 --> 00:35:19,680
all these counter measures we put that

987
00:35:19,680 --> 00:35:21,119
all out there

988
00:35:21,119 --> 00:35:23,520
and now we're done

989
00:35:23,520 --> 00:35:25,680
right we did our threat model

990
00:35:25,680 --> 00:35:27,280
well what happens

991
00:35:27,280 --> 00:35:28,720
with all those subsequent smaller

992
00:35:28,720 --> 00:35:31,720
changes

993
00:35:33,200 --> 00:35:34,880
the point of threat modeling is to make

994
00:35:34,880 --> 00:35:36,640
this a journey of understanding what do

995
00:35:36,640 --> 00:35:38,880
i mean by that what did

996
00:35:38,880 --> 00:35:40,880
these 15 goofy individuals who wrote

997
00:35:40,880 --> 00:35:42,320
this manifesto mean when they said a

998
00:35:42,320 --> 00:35:45,280
journey of understanding

999
00:35:45,280 --> 00:35:47,680
it means that we're constantly growing

1000
00:35:47,680 --> 00:35:50,000
and learning and

1001
00:35:50,000 --> 00:35:54,320
getting new perspectives on the system

1002
00:35:54,320 --> 00:35:55,280
so

1003
00:35:55,280 --> 00:35:56,960
it's not just we take this one-time

1004
00:35:56,960 --> 00:35:58,480
snapshot okay this is the way the system

1005
00:35:58,480 --> 00:36:01,520
looks today good i'm happy no

1006
00:36:01,520 --> 00:36:02,960
we're constantly trying to grow and

1007
00:36:02,960 --> 00:36:05,119
learn more so as i start to shift this

1008
00:36:05,119 --> 00:36:07,680
into say a user story again those are

1009
00:36:07,680 --> 00:36:09,520
happening all the time

1010
00:36:09,520 --> 00:36:11,760
we're getting new insights into the

1011
00:36:11,760 --> 00:36:15,280
threat posture of our application of our

1012
00:36:15,280 --> 00:36:18,079
system of our product

1013
00:36:18,079 --> 00:36:19,760
that's what we want threat modeling to

1014
00:36:19,760 --> 00:36:21,520
be for us it's that journey of

1015
00:36:21,520 --> 00:36:24,320
understanding

1016
00:36:24,480 --> 00:36:27,119
security snapshots don't help us

1017
00:36:27,119 --> 00:36:28,960
they give us that point in time and

1018
00:36:28,960 --> 00:36:30,480
they're irrelevant

1019
00:36:30,480 --> 00:36:32,960
right after the next change happens

1020
00:36:32,960 --> 00:36:35,839
that's not where we want to be

1021
00:36:35,839 --> 00:36:38,800
so we can do more here we can be better

1022
00:36:38,800 --> 00:36:40,640
at this

1023
00:36:40,640 --> 00:36:43,520
we just need to focus on this idea of

1024
00:36:43,520 --> 00:36:45,920
continuous improvement

1025
00:36:45,920 --> 00:36:47,839
get away from this idea that we're going

1026
00:36:47,839 --> 00:36:50,720
to secure the world

1027
00:36:50,720 --> 00:36:52,480
security for far too long has thought

1028
00:36:52,480 --> 00:36:53,920
that well we're just gonna just we're

1029
00:36:53,920 --> 00:36:55,040
gonna find all the problems we're gonna

1030
00:36:55,040 --> 00:36:56,160
fix all the problems and then we're

1031
00:36:56,160 --> 00:36:57,760
secure

1032
00:36:57,760 --> 00:36:59,280
whether we say it or not that's been the

1033
00:36:59,280 --> 00:37:01,920
thinking because our actions show it get

1034
00:37:01,920 --> 00:37:03,680
out of that mindset start to build this

1035
00:37:03,680 --> 00:37:05,680
mindset that security is a constant

1036
00:37:05,680 --> 00:37:07,359
journey we're just trying to get better

1037
00:37:07,359 --> 00:37:10,560
tomorrow than we are today

1038
00:37:11,760 --> 00:37:13,599
this next one might seem kind of obvious

1039
00:37:13,599 --> 00:37:15,920
to you

1040
00:37:16,320 --> 00:37:18,560
threat modeling values doing threat

1041
00:37:18,560 --> 00:37:23,480
modeling versus talking about it

1042
00:37:23,839 --> 00:37:25,680
how does that sit with you pretty

1043
00:37:25,680 --> 00:37:27,119
obvious

1044
00:37:27,119 --> 00:37:29,680
but believe it or not this is a crucial

1045
00:37:29,680 --> 00:37:32,960
thing that oftentimes we lose sight of

1046
00:37:32,960 --> 00:37:35,280
now think about it how many of you have

1047
00:37:35,280 --> 00:37:37,200
talked about skydiving how many have

1048
00:37:37,200 --> 00:37:38,640
talked about how neat it would be how

1049
00:37:38,640 --> 00:37:40,000
cool it would be how scary it would be

1050
00:37:40,000 --> 00:37:41,440
how you would how you wanted to do it

1051
00:37:41,440 --> 00:37:43,359
how you would never do it how many of

1052
00:37:43,359 --> 00:37:45,040
you have actually gotten in a plane and

1053
00:37:45,040 --> 00:37:47,040
done it

1054
00:37:47,040 --> 00:37:48,079
not me

1055
00:37:48,079 --> 00:37:51,040
i've talked about it i've never done it

1056
00:37:51,040 --> 00:37:53,280
so where's the value in that

1057
00:37:53,280 --> 00:37:55,119
if i talk about it

1058
00:37:55,119 --> 00:37:56,720
sure i can i can talk about all the

1059
00:37:56,720 --> 00:37:58,320
greatness of threat modeling i can sit

1060
00:37:58,320 --> 00:38:00,240
here and do a 50-minute talk at circle

1061
00:38:00,240 --> 00:38:02,240
city con telling everybody how great

1062
00:38:02,240 --> 00:38:04,560
threat modeling is

1063
00:38:04,560 --> 00:38:06,480
but if i'm not doing it if i'm not out

1064
00:38:06,480 --> 00:38:07,440
there

1065
00:38:07,440 --> 00:38:09,200
making it happen

1066
00:38:09,200 --> 00:38:11,760
where's the value in that there isn't

1067
00:38:11,760 --> 00:38:14,160
and it's the same for any organization

1068
00:38:14,160 --> 00:38:16,160
as we look to implement threat modeling

1069
00:38:16,160 --> 00:38:18,000
we need to make sure that we get to

1070
00:38:18,000 --> 00:38:19,520
doing it so if i'm building out a

1071
00:38:19,520 --> 00:38:22,079
methodology

1072
00:38:22,079 --> 00:38:24,240
i've got to avoid the paralysis by

1073
00:38:24,240 --> 00:38:26,400
analysis

1074
00:38:26,400 --> 00:38:29,359
i've got to avoid that situation where

1075
00:38:29,359 --> 00:38:30,160
i

1076
00:38:30,160 --> 00:38:32,000
spend so much time trying to develop a

1077
00:38:32,000 --> 00:38:34,160
methodology and make it perfect and make

1078
00:38:34,160 --> 00:38:36,079
it wonderful that i never get to the

1079
00:38:36,079 --> 00:38:40,720
point of actually doing threat modeling

1080
00:38:41,280 --> 00:38:44,160
find the value by actually doing it

1081
00:38:44,160 --> 00:38:47,440
even if it's imperfect get to doing it

1082
00:38:47,440 --> 00:38:49,760
your first jump out of a skydive or your

1083
00:38:49,760 --> 00:38:51,440
first skydive out of a plane probably

1084
00:38:51,440 --> 00:38:53,119
isn't going to go exactly the way you

1085
00:38:53,119 --> 00:38:54,560
want

1086
00:38:54,560 --> 00:38:55,440
because you're not going to be able to

1087
00:38:55,440 --> 00:38:56,800
do it by yourself

1088
00:38:56,800 --> 00:38:58,480
you're going to have to

1089
00:38:58,480 --> 00:39:00,079
you know you get certified by doing

1090
00:39:00,079 --> 00:39:02,960
tandem jumps

1091
00:39:02,960 --> 00:39:04,320
so

1092
00:39:04,320 --> 00:39:05,359
how do we

1093
00:39:05,359 --> 00:39:07,680
how do we leverage this i you know we

1094
00:39:07,680 --> 00:39:09,440
can't within our organizations expect

1095
00:39:09,440 --> 00:39:10,880
our threat modeling methodology to be

1096
00:39:10,880 --> 00:39:13,119
perfect out of the gates we can ask for

1097
00:39:13,119 --> 00:39:15,520
help we can bring in people who

1098
00:39:15,520 --> 00:39:17,280
understand this

1099
00:39:17,280 --> 00:39:21,760
but the key is to get something started

1100
00:39:21,760 --> 00:39:23,760
even if it's small even if it's simple

1101
00:39:23,760 --> 00:39:26,800
even if it it you know we know there's

1102
00:39:26,800 --> 00:39:28,960
issues with it

1103
00:39:28,960 --> 00:39:30,880
get to the point that you're actually

1104
00:39:30,880 --> 00:39:32,400
doing something because that's what's

1105
00:39:32,400 --> 00:39:33,920
going to enable that continuous

1106
00:39:33,920 --> 00:39:35,040
improvement

1107
00:39:35,040 --> 00:39:37,520
and get you out of that whole mindset of

1108
00:39:37,520 --> 00:39:40,160
snapshots it's going to help you just

1109
00:39:40,160 --> 00:39:42,240
start getting better and as you

1110
00:39:42,240 --> 00:39:44,880
continuously improve your products or

1111
00:39:44,880 --> 00:39:47,520
your systems you're also continuously

1112
00:39:47,520 --> 00:39:50,000
improving your methodology you started

1113
00:39:50,000 --> 00:39:51,599
with something simple but you're doing

1114
00:39:51,599 --> 00:39:53,680
it as you do it you learn how to make it

1115
00:39:53,680 --> 00:39:55,119
better and you keep making your

1116
00:39:55,119 --> 00:39:57,359
methodology better

1117
00:39:57,359 --> 00:39:59,280
so don't sit there and talk about it

1118
00:39:59,280 --> 00:40:00,640
don't talk about how you're going to do

1119
00:40:00,640 --> 00:40:03,200
it just start doing it

1120
00:40:03,200 --> 00:40:05,920
from a security perspective how can you

1121
00:40:05,920 --> 00:40:07,200
just

1122
00:40:07,200 --> 00:40:09,440
start doing it

1123
00:40:09,440 --> 00:40:11,200
do you have to sit down and talk to 40

1124
00:40:11,200 --> 00:40:12,319
people get them all in a room and say

1125
00:40:12,319 --> 00:40:13,520
hey we want to start doing the threat

1126
00:40:13,520 --> 00:40:15,359
modeling methodology

1127
00:40:15,359 --> 00:40:17,520
at some point you probably have to get

1128
00:40:17,520 --> 00:40:19,920
buy in an adoption for it but how can

1129
00:40:19,920 --> 00:40:22,079
you start bringing threat modeling these

1130
00:40:22,079 --> 00:40:24,240
core concepts how can you bring that to

1131
00:40:24,240 --> 00:40:26,079
your organization sooner how can you

1132
00:40:26,079 --> 00:40:28,240
make that happen without sitting down to

1133
00:40:28,240 --> 00:40:30,880
talk about it and just do it

1134
00:40:30,880 --> 00:40:32,480
that's where you can find extra value

1135
00:40:32,480 --> 00:40:35,359
and threat modeling

1136
00:40:35,440 --> 00:40:36,800
now you've heard me say continuous

1137
00:40:36,800 --> 00:40:39,760
improvement how many times

1138
00:40:39,760 --> 00:40:41,839
i don't know i lost count and i wasn't

1139
00:40:41,839 --> 00:40:44,319
really actually counting anyway

1140
00:40:44,319 --> 00:40:46,319
continuous refinement sound familiar

1141
00:40:46,319 --> 00:40:49,359
kind of synonymous right our last value

1142
00:40:49,359 --> 00:40:52,079
continuous refinement over a single

1143
00:40:52,079 --> 00:40:54,720
delivery

1144
00:40:54,960 --> 00:40:56,640
this is where i'm talking about how do

1145
00:40:56,640 --> 00:40:58,079
we make our threat models better and

1146
00:40:58,079 --> 00:41:00,240
better over time we're not going to just

1147
00:41:00,240 --> 00:41:03,839
deliver a perfect threat model ever

1148
00:41:03,839 --> 00:41:05,920
nobody i've ever met has sat down and

1149
00:41:05,920 --> 00:41:08,640
just built a threat model with all the

1150
00:41:08,640 --> 00:41:10,079
diagrams everything else turning and

1151
00:41:10,079 --> 00:41:11,359
everybody said wow this is perfect

1152
00:41:11,359 --> 00:41:12,400
there's nothing we could have done

1153
00:41:12,400 --> 00:41:14,800
differently here it's wonderful we are

1154
00:41:14,800 --> 00:41:18,160
now secure yay

1155
00:41:18,400 --> 00:41:19,200
no

1156
00:41:19,200 --> 00:41:21,040
you're not

1157
00:41:21,040 --> 00:41:23,359
nobody has a perfect threat model

1158
00:41:23,359 --> 00:41:25,119
artists don't sit down and in one night

1159
00:41:25,119 --> 00:41:26,640
create a sculpture and sell it the next

1160
00:41:26,640 --> 00:41:28,160
day

1161
00:41:28,160 --> 00:41:30,720
artists can spend years

1162
00:41:30,720 --> 00:41:32,560
sculpting something

1163
00:41:32,560 --> 00:41:33,599
and at the end of it they might even

1164
00:41:33,599 --> 00:41:34,800
decide they don't like it they throw it

1165
00:41:34,800 --> 00:41:35,599
out

1166
00:41:35,599 --> 00:41:37,280
but they're always trying to refine it

1167
00:41:37,280 --> 00:41:39,760
they're always coming back to it making

1168
00:41:39,760 --> 00:41:42,880
little changes here and there

1169
00:41:42,880 --> 00:41:44,000
tweaking

1170
00:41:44,000 --> 00:41:47,359
making it look better

1171
00:41:47,359 --> 00:41:49,760
making it match their vision

1172
00:41:49,760 --> 00:41:52,160
adjusting it maybe maybe they realize

1173
00:41:52,160 --> 00:41:53,839
that they got the eyes just slightly off

1174
00:41:53,839 --> 00:41:55,280
so i'm going to adjust the eyes and make

1175
00:41:55,280 --> 00:41:58,000
them look like they're happier eyes or

1176
00:41:58,000 --> 00:41:59,280
they're looking in a particular

1177
00:41:59,280 --> 00:42:01,760
direction

1178
00:42:01,760 --> 00:42:03,680
we want that to be the same when it

1179
00:42:03,680 --> 00:42:06,079
comes to threat modeling just trying to

1180
00:42:06,079 --> 00:42:09,119
deliver a standardly formatted threat

1181
00:42:09,119 --> 00:42:10,960
model document

1182
00:42:10,960 --> 00:42:13,760
or series of documents

1183
00:42:13,760 --> 00:42:15,599
that doesn't get us as much value as

1184
00:42:15,599 --> 00:42:18,079
continually improving and refining that

1185
00:42:18,079 --> 00:42:19,760
process by which we create the threat

1186
00:42:19,760 --> 00:42:22,000
model in the first place

1187
00:42:22,000 --> 00:42:23,520
because remember we're getting all the

1188
00:42:23,520 --> 00:42:25,839
value out of the collaboration

1189
00:42:25,839 --> 00:42:27,599
the process of threat modeling is where

1190
00:42:27,599 --> 00:42:30,160
the value is coming from so as we refine

1191
00:42:30,160 --> 00:42:31,920
that process and get better and better

1192
00:42:31,920 --> 00:42:35,040
at it we gain more value from it if all

1193
00:42:35,040 --> 00:42:37,200
we care about is the end product that we

1194
00:42:37,200 --> 00:42:39,040
deliver at the end of our threat

1195
00:42:39,040 --> 00:42:41,520
modeling process well then

1196
00:42:41,520 --> 00:42:44,560
we're not really getting the value that

1197
00:42:44,560 --> 00:42:45,920
we could be

1198
00:42:45,920 --> 00:42:48,240
from threat modeling

1199
00:42:48,240 --> 00:42:50,960
so that's the last of our values those

1200
00:42:50,960 --> 00:42:53,200
values are meant to define here is the

1201
00:42:53,200 --> 00:42:55,280
core of what is important when we talk

1202
00:42:55,280 --> 00:42:58,680
threat modeling

1203
00:42:59,920 --> 00:43:02,000
but now we're going to talk about

1204
00:43:02,000 --> 00:43:05,200
the next piece which are the principles

1205
00:43:05,200 --> 00:43:07,119
so within the threat modeling manifesto

1206
00:43:07,119 --> 00:43:09,040
we defined our values and then we broke

1207
00:43:09,040 --> 00:43:10,960
it down into principles and what do i

1208
00:43:10,960 --> 00:43:13,040
mean by principles well the principles

1209
00:43:13,040 --> 00:43:14,480
just describe

1210
00:43:14,480 --> 00:43:16,800
fundamental truths

1211
00:43:16,800 --> 00:43:18,880
about threat modeling

1212
00:43:18,880 --> 00:43:20,800
so this is just taking it to a new layer

1213
00:43:20,800 --> 00:43:22,720
of granularity

1214
00:43:22,720 --> 00:43:24,319
and so when i think about the principles

1215
00:43:24,319 --> 00:43:26,240
there's four principles that we focused

1216
00:43:26,240 --> 00:43:28,399
on

1217
00:43:28,480 --> 00:43:31,599
the first principle reads the best use

1218
00:43:31,599 --> 00:43:33,760
of threat modeling is to improve the

1219
00:43:33,760 --> 00:43:36,560
security and privacy of a system through

1220
00:43:36,560 --> 00:43:38,839
early and frequent

1221
00:43:38,839 --> 00:43:41,119
analysis that early and frequent

1222
00:43:41,119 --> 00:43:42,960
analysis

1223
00:43:42,960 --> 00:43:44,800
this is that push left

1224
00:43:44,800 --> 00:43:46,319
right

1225
00:43:46,319 --> 00:43:48,640
think about that okay

1226
00:43:48,640 --> 00:43:50,400
back once again to our user story

1227
00:43:50,400 --> 00:43:51,520
example

1228
00:43:51,520 --> 00:43:53,440
if i'm doing it at the user story how

1229
00:43:53,440 --> 00:43:55,359
could i possibly get any earlier with my

1230
00:43:55,359 --> 00:43:57,760
threat model

1231
00:43:57,760 --> 00:43:59,680
if i'm doing it in the user story it's

1232
00:43:59,680 --> 00:44:02,079
happening frequently that analysis is

1233
00:44:02,079 --> 00:44:03,760
happening every time a new user story

1234
00:44:03,760 --> 00:44:06,079
drops on my backlog

1235
00:44:06,079 --> 00:44:08,400
that's pretty frequent

1236
00:44:08,400 --> 00:44:11,040
that's going to help me to ensure that

1237
00:44:11,040 --> 00:44:13,760
we are consistently and continuously

1238
00:44:13,760 --> 00:44:15,680
improving the security and privacy of

1239
00:44:15,680 --> 00:44:18,319
that system

1240
00:44:18,800 --> 00:44:21,280
so this is a critical piece this is an

1241
00:44:21,280 --> 00:44:23,200
absolute truth when it comes to threat

1242
00:44:23,200 --> 00:44:24,720
modeling

1243
00:44:24,720 --> 00:44:28,319
that it's best use is when

1244
00:44:28,319 --> 00:44:30,319
we're using it early and we're doing it

1245
00:44:30,319 --> 00:44:32,880
frequently

1246
00:44:33,440 --> 00:44:35,280
second principle of threat modeling is

1247
00:44:35,280 --> 00:44:38,079
that threat modeling must align with an

1248
00:44:38,079 --> 00:44:40,480
organization's development practices and

1249
00:44:40,480 --> 00:44:43,599
follow design changes in iterations that

1250
00:44:43,599 --> 00:44:46,319
are scoped to manageable portions of the

1251
00:44:46,319 --> 00:44:48,480
system

1252
00:44:48,480 --> 00:44:50,880
doing it in iterations

1253
00:44:50,880 --> 00:44:53,839
making them manageable portions

1254
00:44:53,839 --> 00:44:54,960
how many more times are you going to

1255
00:44:54,960 --> 00:44:57,520
hear me use the term user story put

1256
00:44:57,520 --> 00:45:02,000
threat modeling in your user story hello

1257
00:45:02,000 --> 00:45:04,480
that makes it iterative that makes them

1258
00:45:04,480 --> 00:45:06,319
manageable portions when we try to boil

1259
00:45:06,319 --> 00:45:07,839
the ocean that's what created all that

1260
00:45:07,839 --> 00:45:09,440
frustration with threat modeling that's

1261
00:45:09,440 --> 00:45:10,160
why

1262
00:45:10,160 --> 00:45:11,920
i had developers telling me when i was a

1263
00:45:11,920 --> 00:45:13,839
consultant that threat modeling simply

1264
00:45:13,839 --> 00:45:18,400
could not be done in a devsecops culture

1265
00:45:18,400 --> 00:45:20,079
it can

1266
00:45:20,079 --> 00:45:21,839
we just need to make it manageable it

1267
00:45:21,839 --> 00:45:25,440
can't be this huge heavy lifting thing

1268
00:45:25,440 --> 00:45:27,920
so break your threat modeling down into

1269
00:45:27,920 --> 00:45:30,720
those manageable scopes how can you do

1270
00:45:30,720 --> 00:45:33,520
it if you don't use a user story

1271
00:45:33,520 --> 00:45:36,240
find another way to focus on just

1272
00:45:36,240 --> 00:45:38,800
a single logical area of that system

1273
00:45:38,800 --> 00:45:40,319
that application whatever it is that

1274
00:45:40,319 --> 00:45:41,920
you're working on

1275
00:45:41,920 --> 00:45:44,839
and get your value there that is a

1276
00:45:44,839 --> 00:45:47,440
true absolute principle of threat

1277
00:45:47,440 --> 00:45:50,079
modeling is that that's where it must

1278
00:45:50,079 --> 00:45:51,839
align with your organization in that way

1279
00:45:51,839 --> 00:45:53,200
or people are not going to adopt it and

1280
00:45:53,200 --> 00:45:56,078
they're going to throw it away

1281
00:45:56,319 --> 00:45:57,359
next

1282
00:45:57,359 --> 00:45:59,440
the outcomes of threat modeling are only

1283
00:45:59,440 --> 00:46:01,520
meaningful when they are of value to the

1284
00:46:01,520 --> 00:46:03,920
stakeholders

1285
00:46:03,920 --> 00:46:06,880
this again should be duh but so often we

1286
00:46:06,880 --> 00:46:08,560
write threat models as i said before we

1287
00:46:08,560 --> 00:46:10,000
write threat models for the security

1288
00:46:10,000 --> 00:46:11,599
people it's security people writing

1289
00:46:11,599 --> 00:46:13,119
threat models for security people that's

1290
00:46:13,119 --> 00:46:15,520
pointless remember our goal here is to

1291
00:46:15,520 --> 00:46:17,280
inform the design and development of

1292
00:46:17,280 --> 00:46:18,720
that system

1293
00:46:18,720 --> 00:46:20,640
the testing and monitoring of that

1294
00:46:20,640 --> 00:46:22,400
system

1295
00:46:22,400 --> 00:46:23,200
so

1296
00:46:23,200 --> 00:46:24,800
threat modeling it's a principle of

1297
00:46:24,800 --> 00:46:26,720
threat modeling that's only a value if

1298
00:46:26,720 --> 00:46:28,160
it or it's

1299
00:46:28,160 --> 00:46:30,160
only useful and meaningful if it's a

1300
00:46:30,160 --> 00:46:32,640
value to our stakeholders

1301
00:46:32,640 --> 00:46:35,359
and then finally dialogue is key the

1302
00:46:35,359 --> 00:46:38,000
documents just record our discoveries

1303
00:46:38,000 --> 00:46:39,680
the dialogue the collaboration that

1304
00:46:39,680 --> 00:46:41,680
you've heard me ramble on about over and

1305
00:46:41,680 --> 00:46:43,920
over again that's where we find the

1306
00:46:43,920 --> 00:46:46,640
value in threat modeling

1307
00:46:46,640 --> 00:46:48,560
that is a principle of threat modeling

1308
00:46:48,560 --> 00:46:52,319
that the dialogue is the key

1309
00:46:52,319 --> 00:46:53,839
that dialogue doesn't have to be a bunch

1310
00:46:53,839 --> 00:46:56,240
of people sitting in a room talking it

1311
00:46:56,240 --> 00:46:58,960
can be slack channels it can be

1312
00:46:58,960 --> 00:47:01,280
documentation in the user story

1313
00:47:01,280 --> 00:47:03,440
it can be conversations in a committee

1314
00:47:03,440 --> 00:47:05,920
as a user story is being written

1315
00:47:05,920 --> 00:47:08,079
however it occurs though that dialogue

1316
00:47:08,079 --> 00:47:08,839
should

1317
00:47:08,839 --> 00:47:11,119
happen and then you can document the

1318
00:47:11,119 --> 00:47:14,880
threats and and record that elsewhere

1319
00:47:14,880 --> 00:47:16,400
but that is a principle of threat

1320
00:47:16,400 --> 00:47:17,680
modeling

1321
00:47:17,680 --> 00:47:19,200
so it's just about time for me to wrap

1322
00:47:19,200 --> 00:47:19,920
up

1323
00:47:19,920 --> 00:47:22,480
but i always like to leave folks with a

1324
00:47:22,480 --> 00:47:24,400
quote before i go

1325
00:47:24,400 --> 00:47:27,200
and this one from albert einstein i i

1326
00:47:27,200 --> 00:47:29,200
don't think it'd be any more perfect for

1327
00:47:29,200 --> 00:47:30,480
what we've just been talking about for

1328
00:47:30,480 --> 00:47:32,720
the last 45 minutes

1329
00:47:32,720 --> 00:47:35,440
genius is making complex ideas simple

1330
00:47:35,440 --> 00:47:39,440
not making simple ideas complex

1331
00:47:39,440 --> 00:47:41,920
all of these frameworks pasta octave

1332
00:47:41,920 --> 00:47:43,599
stride

1333
00:47:43,599 --> 00:47:45,359
they made threat modeling so much more

1334
00:47:45,359 --> 00:47:47,599
complex than it ever needed to be we

1335
00:47:47,599 --> 00:47:49,760
just need to be asking the question of

1336
00:47:49,760 --> 00:47:50,880
ourselves

1337
00:47:50,880 --> 00:47:53,680
what could possibly go wrong

1338
00:47:53,680 --> 00:47:54,720
and then we just need to think about

1339
00:47:54,720 --> 00:47:56,559
what are we going to do about it

1340
00:47:56,559 --> 00:47:58,319
that's threat

1341
00:47:58,319 --> 00:48:00,079
modeling

1342
00:48:00,079 --> 00:48:02,000
make it happen

1343
00:48:02,000 --> 00:48:04,000
make it a part of your organization gain

1344
00:48:04,000 --> 00:48:06,160
that value and if you want to talk about

1345
00:48:06,160 --> 00:48:08,160
it more please reach out to me here's my

1346
00:48:08,160 --> 00:48:09,599
twitter handle if you don't follow me i

1347
00:48:09,599 --> 00:48:11,520
would love to have you follow me i would

1348
00:48:11,520 --> 00:48:13,680
love to talk to you more about it i love

1349
00:48:13,680 --> 00:48:16,559
sharing ideas i love to hear what other

1350
00:48:16,559 --> 00:48:17,760
people think i love to have them

1351
00:48:17,760 --> 00:48:19,760
challenge me if if i said something you

1352
00:48:19,760 --> 00:48:21,200
think is completely off the wall and

1353
00:48:21,200 --> 00:48:24,079
wrong let me know let's talk about it

1354
00:48:24,079 --> 00:48:26,319
do it respectfully please but yeah let's

1355
00:48:26,319 --> 00:48:28,480
have some fun let's chat you just follow

1356
00:48:28,480 --> 00:48:30,319
me on linkedin connect with me there if

1357
00:48:30,319 --> 00:48:32,240
that's your preference my website where

1358
00:48:32,240 --> 00:48:33,839
you'll find my blog future speaking

1359
00:48:33,839 --> 00:48:35,839
engagements all that happy stuff a

1360
00:48:35,839 --> 00:48:37,200
contact form if you want to get in touch

1361
00:48:37,200 --> 00:48:38,400
with me

1362
00:48:38,400 --> 00:48:40,000
that works too

1363
00:48:40,000 --> 00:48:43,359
so finally thank you so much to circle

1364
00:48:43,359 --> 00:48:45,520
citycon for having me today

1365
00:48:45,520 --> 00:48:46,720
i'm going to be back with you tomorrow

1366
00:48:46,720 --> 00:48:48,480
we're going to talk more about devsecops

1367
00:48:48,480 --> 00:48:49,920
but

1368
00:48:49,920 --> 00:48:51,280
i'm just thrilled to have been here and

1369
00:48:51,280 --> 00:48:53,040
be able to share this with you

1370
00:48:53,040 --> 00:48:55,280
thank you to my organization s p global

1371
00:48:55,280 --> 00:48:57,440
ratings for making it possible for me to

1372
00:48:57,440 --> 00:48:58,800
be here today

1373
00:48:58,800 --> 00:49:01,440
but most importantly thank you to all of

1374
00:49:01,440 --> 00:49:03,280
you for being here i really hope you

1375
00:49:03,280 --> 00:49:05,440
enjoyed i hope you got something useful

1376
00:49:05,440 --> 00:49:07,440
from this check out the threat modeling

1377
00:49:07,440 --> 00:49:09,440
manifesto hopefully you saw the link up

1378
00:49:09,440 --> 00:49:11,440
there multiple times if not it's

1379
00:49:11,440 --> 00:49:13,760
threatmodelingmanifesto.org

1380
00:49:13,760 --> 00:49:15,680
go check it out

1381
00:49:15,680 --> 00:49:17,760
check out the patterns and anti-patterns

1382
00:49:17,760 --> 00:49:19,440
we didn't talk about today i think

1383
00:49:19,440 --> 00:49:21,520
you'll find the value you'll find how

1384
00:49:21,520 --> 00:49:24,640
that will make things easier for you

1385
00:49:24,640 --> 00:49:26,559
so with that

1386
00:49:26,559 --> 00:49:28,240
i'm going to say goodbye but thank you

1387
00:49:28,240 --> 00:49:31,359
again so much i really appreciate it

1388
00:49:31,359 --> 00:49:34,920
take care everybody

