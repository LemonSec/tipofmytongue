1
00:00:05,680 --> 00:00:07,759
thank you kevin uh it's great to be here

2
00:00:07,759 --> 00:00:09,120
with you all

3
00:00:09,120 --> 00:00:11,440
even if it is virtually i'm so happy to

4
00:00:11,440 --> 00:00:13,920
be joining you from lockdownland here in

5
00:00:13,920 --> 00:00:16,560
beautiful downtown auckland

6
00:00:16,560 --> 00:00:18,080
and as kevin mentioned today i'll be

7
00:00:18,080 --> 00:00:19,520
talking about

8
00:00:19,520 --> 00:00:21,760
baking security in

9
00:00:21,760 --> 00:00:24,400
and talking specifically about an app

10
00:00:24,400 --> 00:00:27,599
set critical path for development teams

11
00:00:27,599 --> 00:00:29,519
and if there's a little bit of time left

12
00:00:29,519 --> 00:00:30,960
we might talk about some of the things

13
00:00:30,960 --> 00:00:32,880
that aren't directly on that critical

14
00:00:32,880 --> 00:00:34,480
path

15
00:00:34,480 --> 00:00:37,680
so the classic about me slide

16
00:00:37,680 --> 00:00:39,920
i've had a number of past lives i

17
00:00:39,920 --> 00:00:41,920
started out doing simulation development

18
00:00:41,920 --> 00:00:44,879
for a u.s government agency i spent some

19
00:00:44,879 --> 00:00:46,960
time as a university lecturer did a

20
00:00:46,960 --> 00:00:49,120
bunch of java development

21
00:00:49,120 --> 00:00:51,600
and i moved into application security in

22
00:00:51,600 --> 00:00:53,120
2014.

23
00:00:53,120 --> 00:00:55,680
i've been here in auckland since late

24
00:00:55,680 --> 00:00:59,760
2017 and these days

25
00:00:59,760 --> 00:01:02,879
i'm working for a little company called

26
00:01:02,879 --> 00:01:04,799
datacom new zealand

27
00:01:04,799 --> 00:01:07,680
and i'm in the fairly new application

28
00:01:07,680 --> 00:01:10,400
security services team where i work as

29
00:01:10,400 --> 00:01:12,400
the software assurance lead

30
00:01:12,400 --> 00:01:16,320
well what does that mean

31
00:01:16,479 --> 00:01:19,439
external facing for our customers

32
00:01:19,439 --> 00:01:22,400
i advise on software assurance

33
00:01:22,400 --> 00:01:24,320
we do some sam based maturity

34
00:01:24,320 --> 00:01:25,600
assessments

35
00:01:25,600 --> 00:01:28,320
we provide guidance on how teams can

36
00:01:28,320 --> 00:01:30,320
improve their maturity

37
00:01:30,320 --> 00:01:32,479
and of course we give advisory and

38
00:01:32,479 --> 00:01:34,960
implementation services on grc

39
00:01:34,960 --> 00:01:38,640
activities i present a lot of training

40
00:01:38,640 --> 00:01:40,560
we sell tooling including a number of

41
00:01:40,560 --> 00:01:42,320
the tools that francesco was talking

42
00:01:42,320 --> 00:01:46,000
about in his talk just before the break

43
00:01:46,000 --> 00:01:49,280
and we also do a lot of devsecops

44
00:01:49,280 --> 00:01:51,360
adoption advisory

45
00:01:51,360 --> 00:01:53,680
internal facing we're trying to get all

46
00:01:53,680 --> 00:01:56,159
of the development teams doing project

47
00:01:56,159 --> 00:01:59,040
work at datacom to eat our own dog food

48
00:01:59,040 --> 00:02:01,200
and have the same level of maturity in

49
00:02:01,200 --> 00:02:03,280
the same set of practices

50
00:02:03,280 --> 00:02:05,520
in the things that we do for others

51
00:02:05,520 --> 00:02:07,600
under contract

52
00:02:07,600 --> 00:02:10,479
and of course the usual plug our team is

53
00:02:10,479 --> 00:02:11,680
growing

54
00:02:11,680 --> 00:02:14,000
not very quickly

55
00:02:14,000 --> 00:02:16,720
actually a quick welcome to kevin who

56
00:02:16,720 --> 00:02:19,040
joined our team just a couple months ago

57
00:02:19,040 --> 00:02:21,360
and we had another member joined just

58
00:02:21,360 --> 00:02:23,440
two weeks ago so we are still growing

59
00:02:23,440 --> 00:02:27,040
and we are looking for those right fits

60
00:02:27,040 --> 00:02:29,040
if you're interested give us a shout i

61
00:02:29,040 --> 00:02:31,519
should also mention that at datacom a

62
00:02:31,519 --> 00:02:34,160
number of other teams are growing even

63
00:02:34,160 --> 00:02:35,920
faster than we are so there are

64
00:02:35,920 --> 00:02:39,040
development roles and cyber security

65
00:02:39,040 --> 00:02:41,840
seams kind of roles available if you

66
00:02:41,840 --> 00:02:43,280
have interested in that you can also

67
00:02:43,280 --> 00:02:45,440
give one of us a shout and we can get

68
00:02:45,440 --> 00:02:48,239
you in touch with the right people

69
00:02:48,239 --> 00:02:50,480
in my other job

70
00:02:50,480 --> 00:02:53,680
i do a few things for owasp

71
00:02:53,680 --> 00:02:56,480
within the oash new zealand chapter

72
00:02:56,480 --> 00:02:58,640
i run the auckland meetup

73
00:02:58,640 --> 00:03:01,440
if you're interested our next session is

74
00:03:01,440 --> 00:03:03,200
next tuesday evening

75
00:03:03,200 --> 00:03:05,120
and of course since we're still in

76
00:03:05,120 --> 00:03:08,640
lockdown it will be online via zoom so

77
00:03:08,640 --> 00:03:10,239
you can go ahead and sign up for the

78
00:03:10,239 --> 00:03:15,040
meetup and join us for the zoom meeting

79
00:03:15,360 --> 00:03:18,400
a couple years ago i started the

80
00:03:18,400 --> 00:03:20,159
oauth new zealand chapters training day

81
00:03:20,159 --> 00:03:23,280
events we've had a couple of those

82
00:03:23,280 --> 00:03:25,680
last year we managed to squeeze a

83
00:03:25,680 --> 00:03:27,599
training day in auckland as well as

84
00:03:27,599 --> 00:03:30,239
wellington in between lockdowns

85
00:03:30,239 --> 00:03:32,799
hopefully we'll be back and even bigger

86
00:03:32,799 --> 00:03:35,120
in 2022

87
00:03:35,120 --> 00:03:36,879
event i ended up giving up this year

88
00:03:36,879 --> 00:03:38,239
that we just couldn't find a date that

89
00:03:38,239 --> 00:03:40,640
we weren't locked down

90
00:03:40,640 --> 00:03:41,400
the

91
00:03:41,400 --> 00:03:43,120
security.ac.nz

92
00:03:43,120 --> 00:03:45,840
student conference which was originated

93
00:03:45,840 --> 00:03:47,680
by kirk jackson

94
00:03:47,680 --> 00:03:49,840
hopefully again we'll come back from our

95
00:03:49,840 --> 00:03:51,280
break next year

96
00:03:51,280 --> 00:03:54,319
we have dates in august in auckland and

97
00:03:54,319 --> 00:03:55,680
kirk will be working on dates in

98
00:03:55,680 --> 00:03:57,120
wellington

99
00:03:57,120 --> 00:03:59,439
so keep those things on your calendar

100
00:03:59,439 --> 00:04:01,280
hope to see you there

101
00:04:01,280 --> 00:04:02,640
and then of course

102
00:04:02,640 --> 00:04:04,720
i have to promote the awash new zealand

103
00:04:04,720 --> 00:04:07,519
day conference

104
00:04:07,519 --> 00:04:09,599
i've been here as i mentioned since the

105
00:04:09,599 --> 00:04:11,680
very end of 2017

106
00:04:11,680 --> 00:04:13,760
i attended my first new zealand day in

107
00:04:13,760 --> 00:04:15,840
february of 2018

108
00:04:15,840 --> 00:04:18,478
where i was a casual volunteer

109
00:04:18,478 --> 00:04:20,720
that at which at that event i said you

110
00:04:20,720 --> 00:04:23,360
know i'd be happy to help out i'm happy

111
00:04:23,360 --> 00:04:25,680
to take a a slightly more active role in

112
00:04:25,680 --> 00:04:27,680
next year's conference

113
00:04:27,680 --> 00:04:29,840
so i became the conference chair and

114
00:04:29,840 --> 00:04:30,720
i've been

115
00:04:30,720 --> 00:04:32,960
chairing the event since then

116
00:04:32,960 --> 00:04:35,120
we are scheduled to hold

117
00:04:35,120 --> 00:04:36,960
the next oauth new zealand day during

118
00:04:36,960 --> 00:04:38,400
our regular

119
00:04:38,400 --> 00:04:40,479
mid-february dates

120
00:04:40,479 --> 00:04:42,720
with a covid contingency of bumping to

121
00:04:42,720 --> 00:04:44,080
july

122
00:04:44,080 --> 00:04:45,680
this year we're going to be at the

123
00:04:45,680 --> 00:04:47,600
auckland university of technology the

124
00:04:47,600 --> 00:04:49,840
city campus just up the road from our

125
00:04:49,840 --> 00:04:53,440
usual haunt at the owen glen building

126
00:04:53,440 --> 00:04:54,960
i want to point out that both the call

127
00:04:54,960 --> 00:04:57,040
for presenters and call for training are

128
00:04:57,040 --> 00:04:59,120
currently open and we've still got some

129
00:04:59,120 --> 00:05:02,160
sponsorships available

130
00:05:02,400 --> 00:05:04,320
so now

131
00:05:04,320 --> 00:05:06,080
the reason i'm here and what i want to

132
00:05:06,080 --> 00:05:07,520
talk to you about

133
00:05:07,520 --> 00:05:11,280
it's all about software assurance

134
00:05:11,280 --> 00:05:13,199
let's start with a lovely dictionary

135
00:05:13,199 --> 00:05:17,280
definition what is software assurance

136
00:05:17,280 --> 00:05:19,039
it's around

137
00:05:19,039 --> 00:05:21,680
the level of confidence that

138
00:05:21,680 --> 00:05:24,560
all of the stakeholders have that

139
00:05:24,560 --> 00:05:27,680
software being delivered and used

140
00:05:27,680 --> 00:05:29,680
is free from vulnerabilities

141
00:05:29,680 --> 00:05:31,360
whether they're

142
00:05:31,360 --> 00:05:35,840
built in or they came about accidentally

143
00:05:35,840 --> 00:05:38,400
and that the software functions the way

144
00:05:38,400 --> 00:05:40,400
we intend it to

145
00:05:40,400 --> 00:05:42,000
now to parse that definition a little

146
00:05:42,000 --> 00:05:42,880
bit

147
00:05:42,880 --> 00:05:45,199
it's really about these three things

148
00:05:45,199 --> 00:05:46,720
we want to have that stakeholder

149
00:05:46,720 --> 00:05:49,759
confidence that what we're delivering

150
00:05:49,759 --> 00:05:51,759
are the features that we intended to

151
00:05:51,759 --> 00:05:55,600
deliver and nothing else

152
00:05:55,600 --> 00:05:57,680
we want to prevent detect and remove

153
00:05:57,680 --> 00:06:00,160
vulnerabilities in the applications and

154
00:06:00,160 --> 00:06:02,400
in their supporting infrastructure

155
00:06:02,400 --> 00:06:05,039
and we want to improve the reliability

156
00:06:05,039 --> 00:06:08,000
and resilience of our production systems

157
00:06:08,000 --> 00:06:10,000
a key thing here is that software

158
00:06:10,000 --> 00:06:11,520
assurance

159
00:06:11,520 --> 00:06:12,319
is

160
00:06:12,319 --> 00:06:14,720
so much more than doing a penetration

161
00:06:14,720 --> 00:06:17,199
test at the 11th hour

162
00:06:17,199 --> 00:06:19,360
as many of you have experienced if you

163
00:06:19,360 --> 00:06:21,680
do a penetration test

164
00:06:21,680 --> 00:06:24,000
as your security check

165
00:06:24,000 --> 00:06:26,720
it's very often scheduled for a one or

166
00:06:26,720 --> 00:06:28,160
two week window

167
00:06:28,160 --> 00:06:30,400
just a couple weeks before the go live

168
00:06:30,400 --> 00:06:33,440
that marketing has already promised

169
00:06:33,440 --> 00:06:35,199
it doesn't really matter what you find

170
00:06:35,199 --> 00:06:39,360
because go live isn't being rescheduled

171
00:06:39,360 --> 00:06:41,280
we want to get out of that mindset we

172
00:06:41,280 --> 00:06:42,639
want to get to the point where we're

173
00:06:42,639 --> 00:06:44,080
producing

174
00:06:44,080 --> 00:06:47,360
reliable resilient secure software

175
00:06:47,360 --> 00:06:50,160
from the beginning that shift left

176
00:06:50,160 --> 00:06:51,680
mentality

177
00:06:51,680 --> 00:06:52,960
and

178
00:06:52,960 --> 00:06:55,840
when we do those penetration tests

179
00:06:55,840 --> 00:06:59,120
as was mentioned in an earlier talk

180
00:06:59,120 --> 00:07:01,039
we've addressed all of the low-hanging

181
00:07:01,039 --> 00:07:03,759
fruit and then if we do have the

182
00:07:03,759 --> 00:07:06,400
penetration testers find something

183
00:07:06,400 --> 00:07:09,039
interesting and difficult to find that

184
00:07:09,039 --> 00:07:10,720
challenging

185
00:07:10,720 --> 00:07:12,240
vulnerabilities

186
00:07:12,240 --> 00:07:14,800
then we can have some real conversations

187
00:07:14,800 --> 00:07:16,720
about whether or not there's sufficient

188
00:07:16,720 --> 00:07:20,400
risk to delay go life

189
00:07:21,199 --> 00:07:25,199
now a framework for talking about this

190
00:07:25,759 --> 00:07:28,319
the owasp sam software assurance

191
00:07:28,319 --> 00:07:29,680
maturity model

192
00:07:29,680 --> 00:07:31,520
this is an open framework and it

193
00:07:31,520 --> 00:07:34,080
provides an effective way for

194
00:07:34,080 --> 00:07:37,039
organizations to think about

195
00:07:37,039 --> 00:07:38,800
whether or not

196
00:07:38,800 --> 00:07:42,240
they're doing the right sorts of things

197
00:07:42,240 --> 00:07:45,039
around application security

198
00:07:45,039 --> 00:07:47,440
so this is a model for the

199
00:07:47,440 --> 00:07:50,960
organization's practices it's not about

200
00:07:50,960 --> 00:07:52,560
going and testing an individual

201
00:07:52,560 --> 00:07:55,919
application to see if it has

202
00:07:55,919 --> 00:07:59,039
xss or csrf vulnerabilities

203
00:07:59,039 --> 00:08:01,039
it's about those overall

204
00:08:01,039 --> 00:08:03,039
practices and the

205
00:08:03,039 --> 00:08:05,199
environment in which software is being

206
00:08:05,199 --> 00:08:08,319
produced in order to produce that clean

207
00:08:08,319 --> 00:08:11,199
secure software

208
00:08:11,199 --> 00:08:13,280
i glossed over this a little bit

209
00:08:13,280 --> 00:08:15,680
i've been a little involved in sam i

210
00:08:15,680 --> 00:08:18,160
started working as a core team member in

211
00:08:18,160 --> 00:08:20,080
2018

212
00:08:20,080 --> 00:08:22,000
i am a co-author of the current version

213
00:08:22,000 --> 00:08:23,120
of the model

214
00:08:23,120 --> 00:08:25,280
and as i mentioned on

215
00:08:25,280 --> 00:08:27,199
the about my work slide

216
00:08:27,199 --> 00:08:31,440
i'm also out doing sam assessments for

217
00:08:31,440 --> 00:08:32,719
customers

218
00:08:32,719 --> 00:08:34,000
and

219
00:08:34,000 --> 00:08:35,279
you might

220
00:08:35,279 --> 00:08:36,880
corr you would correctly conclude from

221
00:08:36,880 --> 00:08:38,799
all of that that

222
00:08:38,799 --> 00:08:40,640
i think this is pretty important stuff

223
00:08:40,640 --> 00:08:44,399
and there's really a lot there for us

224
00:08:44,560 --> 00:08:46,560
the sam model

225
00:08:46,560 --> 00:08:50,000
has 15 practice areas across five

226
00:08:50,000 --> 00:08:53,440
business functions or domains

227
00:08:53,600 --> 00:08:56,480
now all of these are important

228
00:08:56,480 --> 00:08:58,959
it's important that we have

229
00:08:58,959 --> 00:09:01,360
an application security strategy

230
00:09:01,360 --> 00:09:03,279
that we're collecting

231
00:09:03,279 --> 00:09:05,519
metrics in order to understand how well

232
00:09:05,519 --> 00:09:07,839
things are working and where we need to

233
00:09:07,839 --> 00:09:09,040
improve

234
00:09:09,040 --> 00:09:11,360
it's important that we have policies for

235
00:09:11,360 --> 00:09:12,399
teams to

236
00:09:12,399 --> 00:09:14,959
follow and that we understand all of our

237
00:09:14,959 --> 00:09:18,160
compliance requirements such as nzism

238
00:09:18,160 --> 00:09:22,000
and privacy 2020 gdpr if it's applicable

239
00:09:22,000 --> 00:09:23,279
australian

240
00:09:23,279 --> 00:09:24,640
rules if we're

241
00:09:24,640 --> 00:09:28,160
also working across the ditch

242
00:09:28,160 --> 00:09:30,080
it's important that we have training in

243
00:09:30,080 --> 00:09:31,120
place

244
00:09:31,120 --> 00:09:33,839
it's important that we think about

245
00:09:33,839 --> 00:09:35,360
architectures

246
00:09:35,360 --> 00:09:37,440
but many of these if you really look at

247
00:09:37,440 --> 00:09:40,800
them they're kind of enterprise level

248
00:09:40,800 --> 00:09:43,680
as a development team trying to get code

249
00:09:43,680 --> 00:09:44,640
written

250
00:09:44,640 --> 00:09:46,399
we don't spend time writing the

251
00:09:46,399 --> 00:09:48,720
company's appsec policy

252
00:09:48,720 --> 00:09:52,399
we just need to understand and follow it

253
00:09:52,399 --> 00:09:54,720
so that leads to the fact that for

254
00:09:54,720 --> 00:09:56,800
development teams there are really six

255
00:09:56,800 --> 00:09:58,560
of these practices

256
00:09:58,560 --> 00:10:01,680
that form the core of what they can

257
00:10:01,680 --> 00:10:02,959
impact

258
00:10:02,959 --> 00:10:07,440
and how a development team even without

259
00:10:07,440 --> 00:10:09,680
the senior level buy-in and all of the

260
00:10:09,680 --> 00:10:12,000
funding that you need for a lot of these

261
00:10:12,000 --> 00:10:13,440
other practices

262
00:10:13,440 --> 00:10:15,519
you can start doing things

263
00:10:15,519 --> 00:10:19,839
next sprint to make your security better

264
00:10:20,320 --> 00:10:22,640
and if you look they form

265
00:10:22,640 --> 00:10:23,920
something of a

266
00:10:23,920 --> 00:10:25,040
path

267
00:10:25,040 --> 00:10:25,920
that

268
00:10:25,920 --> 00:10:27,680
you could look at these activities more

269
00:10:27,680 --> 00:10:30,320
or less as following from one another

270
00:10:30,320 --> 00:10:32,240
and this is what i consider the critical

271
00:10:32,240 --> 00:10:34,240
path for developers

272
00:10:34,240 --> 00:10:36,560
in application security now i'm going to

273
00:10:36,560 --> 00:10:39,040
talk about each of these

274
00:10:39,040 --> 00:10:40,320
activities

275
00:10:40,320 --> 00:10:42,160
the activities within each of these

276
00:10:42,160 --> 00:10:43,519
practices

277
00:10:43,519 --> 00:10:45,680
for a couple minutes each focusing on a

278
00:10:45,680 --> 00:10:47,760
couple of them a little bit more

279
00:10:47,760 --> 00:10:49,839
and

280
00:10:49,839 --> 00:10:51,920
and then how this

281
00:10:51,920 --> 00:10:55,279
reaches the end of your process with

282
00:10:55,279 --> 00:10:57,760
some new artifacts and new information

283
00:10:57,760 --> 00:11:01,279
that can be used by decision makers

284
00:11:01,279 --> 00:11:04,800
so first threat assessment

285
00:11:04,959 --> 00:11:06,800
i should have mentioned

286
00:11:06,800 --> 00:11:08,240
running ahead of myself a little bit

287
00:11:08,240 --> 00:11:10,959
that in each of the sam practices

288
00:11:10,959 --> 00:11:13,120
there are two activity streams and then

289
00:11:13,120 --> 00:11:14,480
there are

290
00:11:14,480 --> 00:11:17,360
three broad categories of activities

291
00:11:17,360 --> 00:11:20,399
called out in each stream

292
00:11:20,399 --> 00:11:23,360
so within the threat assessment practice

293
00:11:23,360 --> 00:11:25,279
the two streams are application risk

294
00:11:25,279 --> 00:11:28,399
profiles and threat modeling

295
00:11:28,399 --> 00:11:30,320
now application risk profiles is the

296
00:11:30,320 --> 00:11:31,920
idea

297
00:11:31,920 --> 00:11:35,200
that we have looked at

298
00:11:35,200 --> 00:11:37,040
the risk

299
00:11:37,040 --> 00:11:39,040
to the business

300
00:11:39,040 --> 00:11:41,120
of an application

301
00:11:41,120 --> 00:11:43,600
and in particular it's the impacts so we

302
00:11:43,600 --> 00:11:46,000
look at the confidentiality integrity

303
00:11:46,000 --> 00:11:48,399
and availability impacts

304
00:11:48,399 --> 00:11:50,480
of a breach or

305
00:11:50,480 --> 00:11:53,279
disablement of the application

306
00:11:53,279 --> 00:11:55,519
in order to understand

307
00:11:55,519 --> 00:11:57,519
how important

308
00:11:57,519 --> 00:12:00,480
that application is to keeping the

309
00:12:00,480 --> 00:12:03,839
lights on in the business

310
00:12:04,800 --> 00:12:06,480
in order to understand that and to be

311
00:12:06,480 --> 00:12:08,880
able to look at applications

312
00:12:08,880 --> 00:12:10,720
relative to one another we use a

313
00:12:10,720 --> 00:12:12,160
standard instrument

314
00:12:12,160 --> 00:12:13,920
the most common form of this is an

315
00:12:13,920 --> 00:12:16,399
application risk profile questionnaire

316
00:12:16,399 --> 00:12:18,560
which can be anywhere from just a few

317
00:12:18,560 --> 00:12:20,720
questions to

318
00:12:20,720 --> 00:12:22,480
i think the longest i had to fill out

319
00:12:22,480 --> 00:12:24,399
was about 100 where they wanted

320
00:12:24,399 --> 00:12:26,560
supporting artifacts and and other

321
00:12:26,560 --> 00:12:28,639
documentation as well

322
00:12:28,639 --> 00:12:29,680
but

323
00:12:29,680 --> 00:12:31,200
whatever the right number of questions

324
00:12:31,200 --> 00:12:33,360
is in order for you to understand things

325
00:12:33,360 --> 00:12:34,480
like

326
00:12:34,480 --> 00:12:36,959
how big is the user community is this a

327
00:12:36,959 --> 00:12:39,279
public-facing or completely internal

328
00:12:39,279 --> 00:12:40,560
application

329
00:12:40,560 --> 00:12:43,040
what sort of personal data are you

330
00:12:43,040 --> 00:12:46,240
collecting or managing

331
00:12:46,240 --> 00:12:48,800
what regulatory requirements do you have

332
00:12:48,800 --> 00:12:50,399
around

333
00:12:50,399 --> 00:12:52,880
protection of data within the system or

334
00:12:52,880 --> 00:12:55,680
auditability of transactions

335
00:12:55,680 --> 00:12:59,360
to understand all of those things

336
00:12:59,360 --> 00:13:01,760
in order to figure out well how

337
00:13:01,760 --> 00:13:03,680
important is this system and what sort

338
00:13:03,680 --> 00:13:05,360
of risk does it pose that we're

339
00:13:05,360 --> 00:13:07,920
deploying it

340
00:13:08,160 --> 00:13:09,680
these things

341
00:13:09,680 --> 00:13:11,920
in isolation looking at one application

342
00:13:11,920 --> 00:13:14,560
and giving it a number say it's 88 out

343
00:13:14,560 --> 00:13:17,200
of 100 that's not nearly as useful as

344
00:13:17,200 --> 00:13:19,120
being able to say

345
00:13:19,120 --> 00:13:22,079
for the 60 applications that we manage

346
00:13:22,079 --> 00:13:23,920
within our portfolio

347
00:13:23,920 --> 00:13:27,519
we've got three that are 85 to 100

348
00:13:27,519 --> 00:13:29,600
and then the bulk bulk of our

349
00:13:29,600 --> 00:13:32,639
applications are really around a 70 risk

350
00:13:32,639 --> 00:13:34,880
and then we've got some that basically

351
00:13:34,880 --> 00:13:37,200
brochure where that are down in the 30s

352
00:13:37,200 --> 00:13:39,360
or 40s and when you look at things that

353
00:13:39,360 --> 00:13:41,440
way you can sort of

354
00:13:41,440 --> 00:13:43,760
easily pick out well here are our crown

355
00:13:43,760 --> 00:13:45,040
jewels these are the things that we want

356
00:13:45,040 --> 00:13:47,360
to spend a lot of time protecting

357
00:13:47,360 --> 00:13:49,680
these other ones the risk is much more

358
00:13:49,680 --> 00:13:50,720
moderate

359
00:13:50,720 --> 00:13:52,480
so we're going to invest in those but

360
00:13:52,480 --> 00:13:54,480
not as much as in those high impact

361
00:13:54,480 --> 00:13:56,880
systems

362
00:13:57,680 --> 00:14:00,000
in threat modeling

363
00:14:00,000 --> 00:14:01,440
the key thing

364
00:14:01,440 --> 00:14:02,880
is to make sure that we have a

365
00:14:02,880 --> 00:14:06,000
consistent repeatable technique

366
00:14:06,000 --> 00:14:09,120
and it needs to be

367
00:14:09,360 --> 00:14:11,760
self-service

368
00:14:11,760 --> 00:14:13,279
development teams need to be able to do

369
00:14:13,279 --> 00:14:15,040
their own threat modeling

370
00:14:15,040 --> 00:14:17,440
because organizations

371
00:14:17,440 --> 00:14:20,240
are never going to hire enough appsec

372
00:14:20,240 --> 00:14:22,800
specialists to have the appsec team do

373
00:14:22,800 --> 00:14:24,639
it for them

374
00:14:24,639 --> 00:14:27,040
i also don't believe that's a great idea

375
00:14:27,040 --> 00:14:29,199
but it's important to realize

376
00:14:29,199 --> 00:14:32,160
you need to select a methodology that

377
00:14:32,160 --> 00:14:34,240
the teams can do themselves

378
00:14:34,240 --> 00:14:36,240
with some instructions some guidance and

379
00:14:36,240 --> 00:14:38,000
some facilitation

380
00:14:38,000 --> 00:14:39,199
from those

381
00:14:39,199 --> 00:14:42,399
experts like me

382
00:14:43,040 --> 00:14:45,600
so the methodology that i recommend is

383
00:14:45,600 --> 00:14:47,279
one you've

384
00:14:47,279 --> 00:14:49,519
seen before of course with my own

385
00:14:49,519 --> 00:14:51,360
personal twist

386
00:14:51,360 --> 00:14:54,959
which i call delay oh seven questions

387
00:14:54,959 --> 00:14:57,120
now this is adapted from the four

388
00:14:57,120 --> 00:14:58,959
questions approach that adam shostak

389
00:14:58,959 --> 00:15:00,480
talks about

390
00:15:00,480 --> 00:15:02,480
where really all i've done is expand

391
00:15:02,480 --> 00:15:04,320
some of the questions into multiple

392
00:15:04,320 --> 00:15:06,160
parts because i think that they're

393
00:15:06,160 --> 00:15:09,279
important enough to address separately

394
00:15:09,279 --> 00:15:11,120
so the first question is

395
00:15:11,120 --> 00:15:13,120
what are we building

396
00:15:13,120 --> 00:15:15,199
most commonly the way that we represent

397
00:15:15,199 --> 00:15:16,959
what we're building is to draw a data

398
00:15:16,959 --> 00:15:18,720
flow diagram

399
00:15:18,720 --> 00:15:21,440
because threats most often follow the

400
00:15:21,440 --> 00:15:23,920
data we want to know what are the data

401
00:15:23,920 --> 00:15:26,639
being processed where they get stored

402
00:15:26,639 --> 00:15:28,720
how are they passed from one process to

403
00:15:28,720 --> 00:15:29,839
another

404
00:15:29,839 --> 00:15:32,320
what users interact with them

405
00:15:32,320 --> 00:15:34,160
and what are our sources and sinks for

406
00:15:34,160 --> 00:15:36,880
the information

407
00:15:37,120 --> 00:15:38,959
then we ask the question what can go

408
00:15:38,959 --> 00:15:41,680
wrong now you can use just about any

409
00:15:41,680 --> 00:15:44,399
method you want to identify threats

410
00:15:44,399 --> 00:15:47,120
but the one that i tend to favor is to

411
00:15:47,120 --> 00:15:48,880
use stride

412
00:15:48,880 --> 00:15:52,800
as a prompt to help teams understand and

413
00:15:52,800 --> 00:15:54,560
identify what

414
00:15:54,560 --> 00:15:55,920
the things they need to be concerned

415
00:15:55,920 --> 00:15:57,120
about are

416
00:15:57,120 --> 00:15:58,800
and of course

417
00:15:58,800 --> 00:16:00,560
i think it was mentioned in an earlier

418
00:16:00,560 --> 00:16:02,800
talk stride is

419
00:16:02,800 --> 00:16:04,880
it's a mnemonic to help you think about

420
00:16:04,880 --> 00:16:07,199
some general categories of threats

421
00:16:07,199 --> 00:16:10,000
spoofing tampering repudiation

422
00:16:10,000 --> 00:16:12,240
information disclosure denial of service

423
00:16:12,240 --> 00:16:14,480
and escalation of privilege

424
00:16:14,480 --> 00:16:16,399
so you go through the stride analysis

425
00:16:16,399 --> 00:16:18,320
looking at the elements of your system

426
00:16:18,320 --> 00:16:20,560
to say what could go wrong here what

427
00:16:20,560 --> 00:16:22,240
could go wrong here what could go wrong

428
00:16:22,240 --> 00:16:24,240
here and you do that until everyone's

429
00:16:24,240 --> 00:16:25,839
tired of it

430
00:16:25,839 --> 00:16:28,079
and or you've done a fairly thorough job

431
00:16:28,079 --> 00:16:30,240
of identifying those threats

432
00:16:30,240 --> 00:16:31,839
so these would be things like

433
00:16:31,839 --> 00:16:34,720
impersonating an administrator or

434
00:16:34,720 --> 00:16:37,440
modifying a request in transit

435
00:16:37,440 --> 00:16:39,440
man-in-the-middle kind of attacks

436
00:16:39,440 --> 00:16:41,920
as you capture those then you ask the

437
00:16:41,920 --> 00:16:43,519
question

438
00:16:43,519 --> 00:16:46,320
what could we do about it

439
00:16:46,320 --> 00:16:47,680
now this is the point where i've split

440
00:16:47,680 --> 00:16:49,680
the question out a little because i'd

441
00:16:49,680 --> 00:16:51,680
first i would like for teams to think

442
00:16:51,680 --> 00:16:52,959
about

443
00:16:52,959 --> 00:16:54,480
all of the different ways they could

444
00:16:54,480 --> 00:16:57,120
mitigate the problem

445
00:16:57,120 --> 00:16:59,120
a particular one that comes up a lot is

446
00:16:59,120 --> 00:17:01,279
as we start talking about

447
00:17:01,279 --> 00:17:03,360
authorization abuses

448
00:17:03,360 --> 00:17:05,199
development teams might come to their

449
00:17:05,199 --> 00:17:07,039
own realization

450
00:17:07,039 --> 00:17:08,000
that

451
00:17:08,000 --> 00:17:10,480
this existing system

452
00:17:10,480 --> 00:17:13,039
doesn't have a great authorization model

453
00:17:13,039 --> 00:17:15,760
and we really should re-engineer that

454
00:17:15,760 --> 00:17:17,280
so they'll bring it up and they say well

455
00:17:17,280 --> 00:17:19,119
we could fix the authorization model

456
00:17:19,119 --> 00:17:20,799
centralize this make sure things are

457
00:17:20,799 --> 00:17:23,280
fully mediated

458
00:17:23,280 --> 00:17:25,520
but then reality sets in

459
00:17:25,520 --> 00:17:27,199
when you ask the question

460
00:17:27,199 --> 00:17:30,000
what are we going to do about it

461
00:17:30,000 --> 00:17:31,760
then this is where budgets and

462
00:17:31,760 --> 00:17:34,559
priorities and timelines come into play

463
00:17:34,559 --> 00:17:36,080
and very often

464
00:17:36,080 --> 00:17:38,480
the one best thing that everyone agrees

465
00:17:38,480 --> 00:17:40,240
they should do

466
00:17:40,240 --> 00:17:42,240
is just not going to happen this fiscal

467
00:17:42,240 --> 00:17:43,280
year

468
00:17:43,280 --> 00:17:45,360
at which point you then talk about what

469
00:17:45,360 --> 00:17:48,160
else could we do compensating controls

470
00:17:48,160 --> 00:17:49,679
additional safeguards we could put in

471
00:17:49,679 --> 00:17:50,720
place

472
00:17:50,720 --> 00:17:53,200
once you decide what you are going to do

473
00:17:53,200 --> 00:17:54,640
about it

474
00:17:54,640 --> 00:17:57,600
then you look at risk and you ask the

475
00:17:57,600 --> 00:18:00,000
question

476
00:18:00,000 --> 00:18:02,240
now that we've selected these particular

477
00:18:02,240 --> 00:18:04,640
mitigations to do

478
00:18:04,640 --> 00:18:07,440
are we leaving any risk on the table

479
00:18:07,440 --> 00:18:08,880
and if we are

480
00:18:08,880 --> 00:18:10,720
then we need to ask

481
00:18:10,720 --> 00:18:12,240
the business owner

482
00:18:12,240 --> 00:18:14,720
if they're willing to accept that

483
00:18:14,720 --> 00:18:16,960
residual risk

484
00:18:16,960 --> 00:18:19,039
and if the answer is no

485
00:18:19,039 --> 00:18:21,280
then we go back to step four

486
00:18:21,280 --> 00:18:23,200
and change our decisions

487
00:18:23,200 --> 00:18:24,559
if they're not willing to accept the

488
00:18:24,559 --> 00:18:26,400
residual risk

489
00:18:26,400 --> 00:18:28,640
that's left after we've selected some

490
00:18:28,640 --> 00:18:31,280
mitigations that means they want more so

491
00:18:31,280 --> 00:18:34,320
let's figure out what else to do

492
00:18:34,320 --> 00:18:35,679
after you finish through

493
00:18:35,679 --> 00:18:37,280
finish going through that cycle as many

494
00:18:37,280 --> 00:18:39,440
times as you need to you've now got a

495
00:18:39,440 --> 00:18:41,440
set of mitigations

496
00:18:41,440 --> 00:18:44,960
and these are things you're going to do

497
00:18:45,200 --> 00:18:48,559
which we generally think of as

498
00:18:48,559 --> 00:18:50,400
requirements

499
00:18:50,400 --> 00:18:52,480
which then means

500
00:18:52,480 --> 00:18:54,320
we can test them

501
00:18:54,320 --> 00:18:56,160
so coming out as a consequence of this

502
00:18:56,160 --> 00:18:58,240
we've identified some threats

503
00:18:58,240 --> 00:18:59,840
we've realized some places where we need

504
00:18:59,840 --> 00:19:02,000
to change what we're doing

505
00:19:02,000 --> 00:19:05,200
we capture those as requirements for the

506
00:19:05,200 --> 00:19:06,559
software

507
00:19:06,559 --> 00:19:08,480
and then we figure out what our test

508
00:19:08,480 --> 00:19:10,880
plan will be to show that we've

509
00:19:10,880 --> 00:19:12,320
successfully implemented those new

510
00:19:12,320 --> 00:19:14,080
requirements

511
00:19:14,080 --> 00:19:15,919
see nothing to it

512
00:19:15,919 --> 00:19:17,919
and then the last question is is our

513
00:19:17,919 --> 00:19:19,520
model correct

514
00:19:19,520 --> 00:19:21,440
when you get to the end of all of this

515
00:19:21,440 --> 00:19:23,360
and you've been working off in model

516
00:19:23,360 --> 00:19:24,960
land

517
00:19:24,960 --> 00:19:26,640
representing the system and making all

518
00:19:26,640 --> 00:19:28,320
of these decisions

519
00:19:28,320 --> 00:19:30,400
is that actually what the developers

520
00:19:30,400 --> 00:19:31,760
built

521
00:19:31,760 --> 00:19:34,080
or does your model represent

522
00:19:34,080 --> 00:19:35,520
what they thought they were going to

523
00:19:35,520 --> 00:19:36,559
build

524
00:19:36,559 --> 00:19:37,919
and now you need to account for that

525
00:19:37,919 --> 00:19:40,080
diversion by going back and updating the

526
00:19:40,080 --> 00:19:42,399
model

527
00:19:42,720 --> 00:19:45,280
representing the same idea

528
00:19:45,280 --> 00:19:47,919
in a lovely animated flow chart

529
00:19:47,919 --> 00:19:49,360
you think about the fact that you have

530
00:19:49,360 --> 00:19:51,120
an existing system

531
00:19:51,120 --> 00:19:53,120
where you've been doing things without

532
00:19:53,120 --> 00:19:55,520
specifically threat modeling

533
00:19:55,520 --> 00:19:57,600
now all we're going to do

534
00:19:57,600 --> 00:19:59,440
all we're going to do

535
00:19:59,440 --> 00:20:01,280
is impose

536
00:20:01,280 --> 00:20:04,840
interpose a threat model into this

537
00:20:04,840 --> 00:20:06,799
process by saying we're going to take

538
00:20:06,799 --> 00:20:08,720
our existing architecture

539
00:20:08,720 --> 00:20:10,400
what we know the functional requirements

540
00:20:10,400 --> 00:20:12,400
are both for the existing system and for

541
00:20:12,400 --> 00:20:15,600
the new things we're planning to do

542
00:20:15,600 --> 00:20:18,720
and we're going to model that

543
00:20:18,720 --> 00:20:21,280
so we build our 2b design

544
00:20:21,280 --> 00:20:23,520
as a dfd

545
00:20:23,520 --> 00:20:25,520
we then go through that process of what

546
00:20:25,520 --> 00:20:28,559
can go wrong identifying the threats

547
00:20:28,559 --> 00:20:30,400
we then have that brainstorming session

548
00:20:30,400 --> 00:20:33,440
to say well what could we do

549
00:20:33,440 --> 00:20:35,919
then we allow our drivers

550
00:20:35,919 --> 00:20:37,760
these might be compliance drivers

551
00:20:37,760 --> 00:20:39,760
policies we have to meet

552
00:20:39,760 --> 00:20:42,320
budgetary and time constraints and so on

553
00:20:42,320 --> 00:20:44,799
in order to neck down those things we

554
00:20:44,799 --> 00:20:45,919
could do

555
00:20:45,919 --> 00:20:48,480
to the mitigations we selected

556
00:20:48,480 --> 00:20:50,320
and then we capture any risk-based

557
00:20:50,320 --> 00:20:53,120
decisions around things we're not going

558
00:20:53,120 --> 00:20:55,440
to do

559
00:20:55,440 --> 00:20:58,400
we take from those selected mitigations

560
00:20:58,400 --> 00:21:00,720
consequential requirements

561
00:21:00,720 --> 00:21:02,640
and then we feed those into our test

562
00:21:02,640 --> 00:21:05,679
cases and our post deployment checklist

563
00:21:05,679 --> 00:21:07,919
see simple

564
00:21:07,919 --> 00:21:09,440
as far as

565
00:21:09,440 --> 00:21:13,120
how much work that is to do

566
00:21:13,919 --> 00:21:16,720
your mileage will vary but this can end

567
00:21:16,720 --> 00:21:18,000
up adding

568
00:21:18,000 --> 00:21:20,480
a few story points to every sprint if

569
00:21:20,480 --> 00:21:24,559
you're doing it in an agile environment

570
00:21:24,720 --> 00:21:25,919
now looking at some of the other

571
00:21:25,919 --> 00:21:27,039
activities

572
00:21:27,039 --> 00:21:29,120
the other practices that i

573
00:21:29,120 --> 00:21:31,440
brought up there so we've got security

574
00:21:31,440 --> 00:21:32,799
requirements

575
00:21:32,799 --> 00:21:34,320
we want to incorporate those

576
00:21:34,320 --> 00:21:37,919
consequential requirements those yes and

577
00:21:37,919 --> 00:21:39,919
into our backlog

578
00:21:39,919 --> 00:21:41,760
link those to the features that depend

579
00:21:41,760 --> 00:21:44,159
on them to make sure that the definition

580
00:21:44,159 --> 00:21:46,480
of done for the feature

581
00:21:46,480 --> 00:21:49,440
includes these consequential things are

582
00:21:49,440 --> 00:21:52,320
also done

583
00:21:52,720 --> 00:21:54,640
a classic example of this one which

584
00:21:54,640 --> 00:21:58,640
comes up way too often is file upload

585
00:21:58,640 --> 00:22:00,720
when the business owner says we need to

586
00:22:00,720 --> 00:22:03,280
let customers upload files

587
00:22:03,280 --> 00:22:04,880
instead of having security be the

588
00:22:04,880 --> 00:22:06,880
department of no and saying you are

589
00:22:06,880 --> 00:22:10,080
absolutely not turning on file upload

590
00:22:10,080 --> 00:22:12,720
instead we say okay

591
00:22:12,720 --> 00:22:15,280
what exactly do you need to let them

592
00:22:15,280 --> 00:22:16,640
upload

593
00:22:16,640 --> 00:22:18,320
and we can start adding on some

594
00:22:18,320 --> 00:22:20,640
requirements to make

595
00:22:20,640 --> 00:22:23,120
file uploads less insecure like

596
00:22:23,120 --> 00:22:25,840
restricting file types and adding

597
00:22:25,840 --> 00:22:28,240
virus checks and adding

598
00:22:28,240 --> 00:22:30,559
signature checks looking at active

599
00:22:30,559 --> 00:22:32,240
monitoring in the

600
00:22:32,240 --> 00:22:34,799
data stores

601
00:22:34,799 --> 00:22:37,039
in order to make that as secure as

602
00:22:37,039 --> 00:22:39,200
possible while meeting the actual

603
00:22:39,200 --> 00:22:41,120
business need

604
00:22:41,120 --> 00:22:42,960
on the supplier side the other stream

605
00:22:42,960 --> 00:22:44,640
and security requirements

606
00:22:44,640 --> 00:22:46,880
this is where we make sure that we're

607
00:22:46,880 --> 00:22:49,520
requiring our vendors who are doing

608
00:22:49,520 --> 00:22:51,679
bespoke software for us

609
00:22:51,679 --> 00:22:53,600
to follow the same standards that we

610
00:22:53,600 --> 00:22:55,520
expect of ourselves

611
00:22:55,520 --> 00:22:57,679
that that is captured in our contracts

612
00:22:57,679 --> 00:22:59,840
through s plays

613
00:22:59,840 --> 00:23:02,960
especially slas on

614
00:23:02,960 --> 00:23:05,360
remediating vulnerabilities in their

615
00:23:05,360 --> 00:23:06,559
software

616
00:23:06,559 --> 00:23:11,520
so that we can meet our requirements

617
00:23:12,000 --> 00:23:14,159
the next practice requirements driven

618
00:23:14,159 --> 00:23:15,440
testing

619
00:23:15,440 --> 00:23:16,720
well this goes back to what i was

620
00:23:16,720 --> 00:23:18,400
talking about before of well let's make

621
00:23:18,400 --> 00:23:20,320
sure we test things

622
00:23:20,320 --> 00:23:22,720
that our qa and regression test cases

623
00:23:22,720 --> 00:23:24,480
should include tests for functional

624
00:23:24,480 --> 00:23:26,240
security requirements

625
00:23:26,240 --> 00:23:27,520
that we should have verification

626
00:23:27,520 --> 00:23:29,120
checklists or scripts for those

627
00:23:29,120 --> 00:23:31,760
non-functional requirements like

628
00:23:31,760 --> 00:23:33,039
having

629
00:23:33,039 --> 00:23:35,120
making sure that we've disabled

630
00:23:35,120 --> 00:23:38,159
weak cipher suites in all on all of our

631
00:23:38,159 --> 00:23:40,559
internet facing endpoints making sure

632
00:23:40,559 --> 00:23:41,840
that

633
00:23:41,840 --> 00:23:45,120
the identity provider that we're using

634
00:23:45,120 --> 00:23:47,840
is using a no is not using a known

635
00:23:47,840 --> 00:23:49,360
insecure hash

636
00:23:49,360 --> 00:23:51,760
checking those things off

637
00:23:51,760 --> 00:23:53,919
to make sure that what we're delivering

638
00:23:53,919 --> 00:23:56,320
and ready to put into production

639
00:23:56,320 --> 00:24:00,159
is doing all the things right

640
00:24:00,159 --> 00:24:02,159
in the second stream this is where we

641
00:24:02,159 --> 00:24:05,120
get more active in our testing

642
00:24:05,120 --> 00:24:06,799
using fuzz testing to look for

643
00:24:06,799 --> 00:24:10,159
susceptibilities to input corruption

644
00:24:10,159 --> 00:24:13,360
adding specific abuse cases to our qa

645
00:24:13,360 --> 00:24:15,600
and regression testing and then also

646
00:24:15,600 --> 00:24:17,760
looking at security stress testing or

647
00:24:17,760 --> 00:24:20,799
denial of service

648
00:24:21,120 --> 00:24:24,479
resilience testing

649
00:24:24,720 --> 00:24:27,360
in the secure build practice

650
00:24:27,360 --> 00:24:30,080
the biggest one is automated repeatable

651
00:24:30,080 --> 00:24:32,960
builds that can't be tampered with

652
00:24:32,960 --> 00:24:34,240
so we're trying to make sure the build

653
00:24:34,240 --> 00:24:37,200
process itself is secured

654
00:24:37,200 --> 00:24:39,760
and then we want to add security testing

655
00:24:39,760 --> 00:24:41,919
into the build pipelines

656
00:24:41,919 --> 00:24:44,320
on technology management the key element

657
00:24:44,320 --> 00:24:47,279
there is software composition analysis

658
00:24:47,279 --> 00:24:49,679
looking out for outdated or vulnerable

659
00:24:49,679 --> 00:24:51,279
component libraries that are being

660
00:24:51,279 --> 00:24:54,240
brought into our applications so we want

661
00:24:54,240 --> 00:24:57,760
to have an sca tool in place

662
00:24:57,760 --> 00:25:00,559
a wasp dependency check or one of the

663
00:25:00,559 --> 00:25:01,520
many

664
00:25:01,520 --> 00:25:03,600
paid tools that datacom would be happy

665
00:25:03,600 --> 00:25:06,158
to sell you

666
00:25:07,360 --> 00:25:09,760
on the secure deployment practice same

667
00:25:09,760 --> 00:25:11,600
thing we're looking for automation and

668
00:25:11,600 --> 00:25:14,000
repeatable deployments we want

669
00:25:14,000 --> 00:25:15,840
deployment processes that cannot be

670
00:25:15,840 --> 00:25:17,200
tampered with

671
00:25:17,200 --> 00:25:18,799
and we want to look at managing

672
00:25:18,799 --> 00:25:21,279
environment promotions so that we've got

673
00:25:21,279 --> 00:25:24,880
some separation of duties around

674
00:25:24,880 --> 00:25:26,720
preventing someone who

675
00:25:26,720 --> 00:25:28,880
tampered with code from being able to

676
00:25:28,880 --> 00:25:30,559
put that directly into production

677
00:25:30,559 --> 00:25:32,799
without some review and a second party

678
00:25:32,799 --> 00:25:33,919
approval

679
00:25:33,919 --> 00:25:35,919
on secret management we want to protect

680
00:25:35,919 --> 00:25:37,919
our production secrets

681
00:25:37,919 --> 00:25:39,520
make sure that we're refreshing them

682
00:25:39,520 --> 00:25:42,400
with an appropriate life cycle and that

683
00:25:42,400 --> 00:25:44,000
we're not

684
00:25:44,000 --> 00:25:45,440
ever

685
00:25:45,440 --> 00:25:48,960
storing secrets in source code or

686
00:25:48,960 --> 00:25:50,799
committing them somewhere that they can

687
00:25:50,799 --> 00:25:52,720
be captured

688
00:25:52,720 --> 00:25:54,480
making sure that developers don't have

689
00:25:54,480 --> 00:25:56,559
access to production

690
00:25:56,559 --> 00:25:58,799
secrets and

691
00:25:58,799 --> 00:26:00,880
in general we're doing what we can to

692
00:26:00,880 --> 00:26:03,760
protect access

693
00:26:03,840 --> 00:26:05,520
security testing this is where our

694
00:26:05,520 --> 00:26:08,000
automated tooling comes into play

695
00:26:08,000 --> 00:26:10,320
so static application security testing

696
00:26:10,320 --> 00:26:12,320
dynamic application security testing and

697
00:26:12,320 --> 00:26:14,480
again dependency analysis

698
00:26:14,480 --> 00:26:16,480
all of which as i mentioned datacom

699
00:26:16,480 --> 00:26:18,400
would be happy to sell to you

700
00:26:18,400 --> 00:26:21,120
as well as the fact that there are some

701
00:26:21,120 --> 00:26:23,600
other useful free tools out there

702
00:26:23,600 --> 00:26:26,159
including several from oas projects

703
00:26:26,159 --> 00:26:28,080
on penetration testing i know a number

704
00:26:28,080 --> 00:26:30,400
of the other sponsors here are very much

705
00:26:30,400 --> 00:26:32,559
in the penetration testing arena we've

706
00:26:32,559 --> 00:26:34,159
heard a couple of talks today about how

707
00:26:34,159 --> 00:26:36,320
to make that better

708
00:26:36,320 --> 00:26:38,240
and in fact as part of our advisory

709
00:26:38,240 --> 00:26:41,120
services we will talk to people

710
00:26:41,120 --> 00:26:43,200
including datacom development teams

711
00:26:43,200 --> 00:26:44,159
about

712
00:26:44,159 --> 00:26:45,760
getting rid of those low-hanging fruit

713
00:26:45,760 --> 00:26:48,000
before we turn it over to the real pros

714
00:26:48,000 --> 00:26:52,360
and have that serious test done

715
00:26:53,039 --> 00:26:54,400
on the

716
00:26:54,400 --> 00:26:56,240
artifact side what does this actually

717
00:26:56,240 --> 00:26:59,679
produce as additional stuff

718
00:26:59,679 --> 00:27:01,760
well the application risk profiles

719
00:27:01,760 --> 00:27:04,240
activities you're going to get these

720
00:27:04,240 --> 00:27:07,279
application risk impact ratings you're

721
00:27:07,279 --> 00:27:08,960
going to put those into a dashboard

722
00:27:08,960 --> 00:27:10,559
somewhere so that people can be looking

723
00:27:10,559 --> 00:27:11,440
at it

724
00:27:11,440 --> 00:27:13,840
and making sure that the senior managers

725
00:27:13,840 --> 00:27:14,640
can

726
00:27:14,640 --> 00:27:16,480
use that information when they're

727
00:27:16,480 --> 00:27:18,720
prioritizing what activities are we

728
00:27:18,720 --> 00:27:20,399
going to do for each of our major

729
00:27:20,399 --> 00:27:21,840
systems

730
00:27:21,840 --> 00:27:23,200
obviously you're going to be creating

731
00:27:23,200 --> 00:27:24,720
threat models

732
00:27:24,720 --> 00:27:26,240
now these threat models can start out

733
00:27:26,240 --> 00:27:27,760
pretty small

734
00:27:27,760 --> 00:27:29,840
you can use a free tool like owasp

735
00:27:29,840 --> 00:27:31,120
threat dragon

736
00:27:31,120 --> 00:27:32,799
or you could just do stuff in confluence

737
00:27:32,799 --> 00:27:36,080
pages i've done that in previous jobs

738
00:27:36,080 --> 00:27:39,200
there are also some very very very not

739
00:27:39,200 --> 00:27:41,039
free commercial tools

740
00:27:41,039 --> 00:27:42,240
that do

741
00:27:42,240 --> 00:27:44,559
as good a job as threat dragon or the

742
00:27:44,559 --> 00:27:46,480
microsoft threat modeling tool but you

743
00:27:46,480 --> 00:27:48,960
get in there you build those models

744
00:27:48,960 --> 00:27:51,120
a key element about this is that this is

745
00:27:51,120 --> 00:27:53,200
not a one and done activity

746
00:27:53,200 --> 00:27:56,000
so threat models are going to grow and

747
00:27:56,000 --> 00:27:58,960
change as the system does

748
00:27:58,960 --> 00:28:00,960
you're going to have these new security

749
00:28:00,960 --> 00:28:02,799
test cases each of your consequential

750
00:28:02,799 --> 00:28:04,799
requirements and your non-functional

751
00:28:04,799 --> 00:28:07,679
requirements is going to give you

752
00:28:07,679 --> 00:28:10,720
test cases for qa to complete

753
00:28:10,720 --> 00:28:12,640
as well as some post-deployment

754
00:28:12,640 --> 00:28:13,840
checklists

755
00:28:13,840 --> 00:28:15,919
to follow and make sure that your

756
00:28:15,919 --> 00:28:17,760
deployed system is meeting all of those

757
00:28:17,760 --> 00:28:20,480
expectations

758
00:28:21,279 --> 00:28:22,320
and then

759
00:28:22,320 --> 00:28:23,919
finally

760
00:28:23,919 --> 00:28:25,840
in those cases where you've decided that

761
00:28:25,840 --> 00:28:28,720
you're not going to do everything you

762
00:28:28,720 --> 00:28:30,960
might do

763
00:28:30,960 --> 00:28:32,240
well you're going to have some risk

764
00:28:32,240 --> 00:28:34,159
acceptances you want to make sure that

765
00:28:34,159 --> 00:28:36,240
you've gotten a formal

766
00:28:36,240 --> 00:28:38,480
it could be as simple as an email

767
00:28:38,480 --> 00:28:40,799
but a real affirmative acceptance from

768
00:28:40,799 --> 00:28:42,480
the business owner that they're happy

769
00:28:42,480 --> 00:28:45,200
with the choices you made

770
00:28:45,200 --> 00:28:46,960
one of the things that i harp on a lot

771
00:28:46,960 --> 00:28:49,360
and this goes back to my first days in a

772
00:28:49,360 --> 00:28:51,600
security office

773
00:28:51,600 --> 00:28:53,600
is that you

774
00:28:53,600 --> 00:28:56,480
want to get out of a situation and

775
00:28:56,480 --> 00:28:57,760
prevent

776
00:28:57,760 --> 00:28:59,840
those situations where the development

777
00:28:59,840 --> 00:29:02,880
team is implicitly accepting risk

778
00:29:02,880 --> 00:29:06,000
on behalf of the system owner

779
00:29:06,000 --> 00:29:08,000
whenever you make a decision

780
00:29:08,000 --> 00:29:09,600
not to patch

781
00:29:09,600 --> 00:29:12,960
or not to implement a security feature

782
00:29:12,960 --> 00:29:15,120
you are accepting risk

783
00:29:15,120 --> 00:29:17,840
but it's not your risk it's the owner's

784
00:29:17,840 --> 00:29:18,799
risk

785
00:29:18,799 --> 00:29:20,640
so talk to them about it make sure they

786
00:29:20,640 --> 00:29:22,000
understand it and make sure they're

787
00:29:22,000 --> 00:29:24,640
happy with it

788
00:29:25,279 --> 00:29:26,720
i understand i've got about three

789
00:29:26,720 --> 00:29:28,960
minutes left so that means i can talk

790
00:29:28,960 --> 00:29:30,559
about one or two

791
00:29:30,559 --> 00:29:32,399
practices that aren't on the critical

792
00:29:32,399 --> 00:29:33,600
path

793
00:29:33,600 --> 00:29:37,039
and i've got these ordered roughly in

794
00:29:37,039 --> 00:29:40,480
order of increasing distance from the

795
00:29:40,480 --> 00:29:42,799
teams that are have hands on keyboard so

796
00:29:42,799 --> 00:29:46,720
the first one is education

797
00:29:46,799 --> 00:29:49,039
as a trainer i love for people to get

798
00:29:49,039 --> 00:29:51,360
lots of training it gives me something

799
00:29:51,360 --> 00:29:54,480
to do it keeps my bills paid but the key

800
00:29:54,480 --> 00:29:56,240
thing here is to make sure that people

801
00:29:56,240 --> 00:29:58,320
are getting the right training at the

802
00:29:58,320 --> 00:30:00,080
right times

803
00:30:00,080 --> 00:30:02,240
and then giving them an ability to do

804
00:30:02,240 --> 00:30:04,000
some continual learning

805
00:30:04,000 --> 00:30:06,320
giving them access to things like ctf

806
00:30:06,320 --> 00:30:07,600
platforms

807
00:30:07,600 --> 00:30:08,720
or

808
00:30:08,720 --> 00:30:10,559
online training

809
00:30:10,559 --> 00:30:14,320
resources such as

810
00:30:14,960 --> 00:30:16,720
secure stack

811
00:30:16,720 --> 00:30:19,440
secure stack academy or

812
00:30:19,440 --> 00:30:22,159
secure flag or

813
00:30:22,159 --> 00:30:24,159
secure code warrior or

814
00:30:24,159 --> 00:30:26,559
any of the training modules that come

815
00:30:26,559 --> 00:30:27,840
with some of the

816
00:30:27,840 --> 00:30:30,159
the static analysis tools having that

817
00:30:30,159 --> 00:30:32,320
available to them so that

818
00:30:32,320 --> 00:30:34,480
when they're running into an issue or

819
00:30:34,480 --> 00:30:36,880
they get a warning about something

820
00:30:36,880 --> 00:30:39,200
not being a best practice they can go

821
00:30:39,200 --> 00:30:41,840
and watch a three-minute video and try a

822
00:30:41,840 --> 00:30:43,600
lab exercise so that they then

823
00:30:43,600 --> 00:30:45,600
understand it and i meant safe stack

824
00:30:45,600 --> 00:30:48,799
academy not secure stack

825
00:30:48,799 --> 00:30:50,640
on the security culture

826
00:30:50,640 --> 00:30:53,279
you have a security champions program

827
00:30:53,279 --> 00:30:55,440
whatever you might call it security

828
00:30:55,440 --> 00:30:57,279
champions as a name is sort of falling

829
00:30:57,279 --> 00:30:59,600
out of favor but it's the idea of having

830
00:30:59,600 --> 00:31:01,440
someone in every development team that

831
00:31:01,440 --> 00:31:04,240
everyone knows they can turn to and then

832
00:31:04,240 --> 00:31:05,919
that person knows that they can then

833
00:31:05,919 --> 00:31:07,840
reach back to your software security

834
00:31:07,840 --> 00:31:10,559
group to answer the hard questions

835
00:31:10,559 --> 00:31:12,000
you want to have that

836
00:31:12,000 --> 00:31:14,159
security culture where the things we

837
00:31:14,159 --> 00:31:16,640
build are secure by design secure by

838
00:31:16,640 --> 00:31:20,480
default and secure in deployment

839
00:31:21,519 --> 00:31:23,279
and the last one i'll talk about today

840
00:31:23,279 --> 00:31:24,399
is

841
00:31:24,399 --> 00:31:26,640
in the operational management practice

842
00:31:26,640 --> 00:31:28,080
data protection

843
00:31:28,080 --> 00:31:29,679
the key one of the key things around

844
00:31:29,679 --> 00:31:32,159
this is to understand what data you have

845
00:31:32,159 --> 00:31:34,000
where they live

846
00:31:34,000 --> 00:31:36,159
what's your authoritative system where

847
00:31:36,159 --> 00:31:37,840
do you have replicas that need to be

848
00:31:37,840 --> 00:31:39,279
synced

849
00:31:39,279 --> 00:31:41,200
to have a data protection policy that

850
00:31:41,200 --> 00:31:43,679
talks about classification levels and

851
00:31:43,679 --> 00:31:46,320
mandatory protections on storage and

852
00:31:46,320 --> 00:31:48,240
handling

853
00:31:48,240 --> 00:31:50,080
have some compliance monitoring to make

854
00:31:50,080 --> 00:31:53,120
sure that things like

855
00:31:53,120 --> 00:31:54,880
spreadsheets that contain all of your

856
00:31:54,880 --> 00:31:58,240
production secrets are not leaving

857
00:31:58,240 --> 00:32:00,399
the business through email

858
00:32:00,399 --> 00:32:02,320
so data loss protection

859
00:32:02,320 --> 00:32:04,399
policies and possibly some technical

860
00:32:04,399 --> 00:32:06,000
controls around that

861
00:32:06,000 --> 00:32:07,919
on system decommissioning

862
00:32:07,919 --> 00:32:09,760
the main thing is if you're not using it

863
00:32:09,760 --> 00:32:12,000
anymore turn it off

864
00:32:12,000 --> 00:32:13,600
if you're using

865
00:32:13,600 --> 00:32:15,360
third-party software like operating

866
00:32:15,360 --> 00:32:17,200
systems and platforms

867
00:32:17,200 --> 00:32:19,519
keep up to date pay attention to when

868
00:32:19,519 --> 00:32:21,120
they're end of lifeing

869
00:32:21,120 --> 00:32:23,120
and think about what you're going to do

870
00:32:23,120 --> 00:32:24,880
next

871
00:32:24,880 --> 00:32:26,799
if you're delivering software do the

872
00:32:26,799 --> 00:32:29,200
same thing manage your customers to keep

873
00:32:29,200 --> 00:32:31,760
them from living on long out of date

874
00:32:31,760 --> 00:32:34,559
versions get them off of the n minus

875
00:32:34,559 --> 00:32:36,799
four version so you can stop supporting

876
00:32:36,799 --> 00:32:38,880
it

877
00:32:38,880 --> 00:32:41,279
now i have i could talk about all of the

878
00:32:41,279 --> 00:32:43,519
other practices if only there were time

879
00:32:43,519 --> 00:32:45,600
but i'm going to stop there now

880
00:32:45,600 --> 00:32:47,039
and thank you all for your time and

881
00:32:47,039 --> 00:32:50,039
attention

