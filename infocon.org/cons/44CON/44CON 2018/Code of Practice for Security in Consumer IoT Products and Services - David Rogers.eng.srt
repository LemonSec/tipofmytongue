1
00:00:00,030 --> 00:00:07,379
hi everyone my name is David Rogers and

2
00:00:04,500 --> 00:00:11,759
I just want to say thanks to Steve for

3
00:00:07,379 --> 00:00:14,969
accepting my proposal to to talk this

4
00:00:11,759 --> 00:00:17,369
came about after a discussion on Twitter

5
00:00:14,969 --> 00:00:18,990
about you know how much security

6
00:00:17,369 --> 00:00:21,359
researchers have contributed to this

7
00:00:18,990 --> 00:00:24,959
work and whether security researchers

8
00:00:21,359 --> 00:00:29,130
were being listened to and the answer

9
00:00:24,960 --> 00:00:30,869
was a resounding yes but I thought come

10
00:00:29,130 --> 00:00:34,680
on I explained you know the whole

11
00:00:30,869 --> 00:00:36,630
rationale to the work that led up to the

12
00:00:34,680 --> 00:00:39,500
publication of what's called the code of

13
00:00:36,630 --> 00:00:42,000
practice for consumer IOT security and

14
00:00:39,500 --> 00:00:44,629
also kind of talk about some of the

15
00:00:42,000 --> 00:00:48,329
implications and hopefully further

16
00:00:44,629 --> 00:00:49,349
discussion with you guys so as far as

17
00:00:48,329 --> 00:00:53,010
I'm concerned if you've got any

18
00:00:49,350 --> 00:00:56,670
questions feel free to interrupt me it's

19
00:00:53,010 --> 00:00:57,899
a two-way street so just stop me I'm

20
00:00:56,670 --> 00:01:01,920
sure somebody else has got the same

21
00:00:57,899 --> 00:01:06,299
questions here the background well my

22
00:01:01,920 --> 00:01:07,920
background is left school at 16 worked

23
00:01:06,299 --> 00:01:11,520
in a semiconductor fab doing an

24
00:01:07,920 --> 00:01:14,900
apprenticeship got laid off and ended up

25
00:01:11,520 --> 00:01:22,048
working for a mobile phone company

26
00:01:14,900 --> 00:01:23,700
Panasonic Mobile our IP and we had a big

27
00:01:22,049 --> 00:01:25,979
security incident at the time I was

28
00:01:23,700 --> 00:01:31,500
designing equipment and software for the

29
00:01:25,979 --> 00:01:34,530
factory line and the the question was

30
00:01:31,500 --> 00:01:38,280
you know that there was a pirate in in

31
00:01:34,530 --> 00:01:40,979
Lisbon in Portugal who was apparently

32
00:01:38,280 --> 00:01:44,250
using my software and they sent me out

33
00:01:40,979 --> 00:01:46,320
to Lisbon to go and see this guy and

34
00:01:44,250 --> 00:01:50,579
when I gets a listen it turned out

35
00:01:46,320 --> 00:01:52,189
scizor undercover operation I'm 21 as I

36
00:01:50,579 --> 00:01:55,500
scanned of good I want to do this stuff

37
00:01:52,189 --> 00:01:57,570
so I ended up doing falling into

38
00:01:55,500 --> 00:01:59,280
security and we didn't you wouldn't

39
00:01:57,570 --> 00:02:01,350
believe it but you know around that time

40
00:01:59,280 --> 00:02:04,649
so about 2000 we didn't have any kind of

41
00:02:01,350 --> 00:02:06,899
product security function whatsoever and

42
00:02:04,649 --> 00:02:11,340
this was an alien to us as a Japanese

43
00:02:06,899 --> 00:02:13,140
company it's just a reality of how

44
00:02:11,340 --> 00:02:16,110
consumer products were built

45
00:02:13,140 --> 00:02:18,929
and it's kind of interesting to me

46
00:02:16,110 --> 00:02:20,580
looking back about you know when I

47
00:02:18,930 --> 00:02:23,760
talked to the design engineers in the

48
00:02:20,580 --> 00:02:26,160
Design Center that whilst there were all

49
00:02:23,760 --> 00:02:28,519
these hacking tools available and we're

50
00:02:26,160 --> 00:02:31,079
talking about embedded systems hacking

51
00:02:28,520 --> 00:02:35,100
nobody even bothered to kind of go and

52
00:02:31,080 --> 00:02:38,130
do that search because mentally that was

53
00:02:35,100 --> 00:02:39,660
a different world even though it's

54
00:02:38,130 --> 00:02:44,660
probably just an internet search away

55
00:02:39,660 --> 00:02:47,790
and so so we learned over time you know

56
00:02:44,660 --> 00:02:49,770
how to how to deal with these people

57
00:02:47,790 --> 00:02:52,769
crack in our products and how to design

58
00:02:49,770 --> 00:02:56,010
our products more securely and so a lot

59
00:02:52,769 --> 00:02:59,580
of that work led to massive improvements

60
00:02:56,010 --> 00:03:02,700
in the mobile phone industry and so

61
00:02:59,580 --> 00:03:07,110
there was some work that that led out

62
00:03:02,700 --> 00:03:09,420
with that called tr1 which was from an

63
00:03:07,110 --> 00:03:10,950
organization called MTP which led to the

64
00:03:09,420 --> 00:03:13,109
standardization of something called the

65
00:03:10,950 --> 00:03:15,299
te e trusted execution environments in

66
00:03:13,110 --> 00:03:17,850
every mobile phone now and actually

67
00:03:15,300 --> 00:03:22,200
mobile phones are a very very hard

68
00:03:17,850 --> 00:03:25,320
target we kind of had our our moments as

69
00:03:22,200 --> 00:03:29,880
it were but the mobile phone industry is

70
00:03:25,320 --> 00:03:33,170
certainly much more mature than than

71
00:03:29,880 --> 00:03:37,530
most other connected products industries

72
00:03:33,170 --> 00:03:40,018
sadly the same can't be said for IOT IOT

73
00:03:37,530 --> 00:03:43,079
is generally an easy target so as we

74
00:03:40,019 --> 00:03:45,900
have we grown historically in the mobile

75
00:03:43,079 --> 00:03:47,370
phone industry with the attackers so our

76
00:03:45,900 --> 00:03:49,320
defenses got better and the attackers

77
00:03:47,370 --> 00:03:52,049
get better and we get better so kind of

78
00:03:49,320 --> 00:03:55,109
we're up there together and then you've

79
00:03:52,049 --> 00:03:58,680
got say a washing machine company over

80
00:03:55,110 --> 00:04:00,870
here he goes I don't really want to go

81
00:03:58,680 --> 00:04:03,030
the way of the dodo you know boardrooms

82
00:04:00,870 --> 00:04:04,500
are bit scared you know you hear the

83
00:04:03,030 --> 00:04:06,810
word Kodak kind of thrown around

84
00:04:04,500 --> 00:04:09,840
boardrooms all right they're desperate

85
00:04:06,810 --> 00:04:14,220
to not be ops obsolete by some new

86
00:04:09,840 --> 00:04:16,380
company so their answer to that is to

87
00:04:14,220 --> 00:04:19,950
connect it to the internet because

88
00:04:16,380 --> 00:04:22,108
that's what people want and it doesn't

89
00:04:19,950 --> 00:04:25,740
matter that whether the use case is

90
00:04:22,108 --> 00:04:26,460
valid or not it's all about digitization

91
00:04:25,740 --> 00:04:28,889
so you

92
00:04:26,460 --> 00:04:32,370
a lot about that in in the connected

93
00:04:28,889 --> 00:04:34,620
industry world digitization of non

94
00:04:32,370 --> 00:04:37,889
digital companies but the problem you've

95
00:04:34,620 --> 00:04:38,880
got is this company and not just

96
00:04:37,889 --> 00:04:40,349
highlighting washing machine

97
00:04:38,880 --> 00:04:43,020
manufacturers there's a ton of other

98
00:04:40,349 --> 00:04:44,819
consumer products out there but they

99
00:04:43,020 --> 00:04:47,639
don't have a clue how to do anything

100
00:04:44,819 --> 00:04:49,259
securely they don't have a clue what to

101
00:04:47,639 --> 00:04:51,319
do when this thing goes on the Internet

102
00:04:49,259 --> 00:04:53,699
they're buying in third-party hardware

103
00:04:51,319 --> 00:04:56,009
they're probably having it integrated by

104
00:04:53,699 --> 00:05:00,470
some kind of third party they're getting

105
00:04:56,009 --> 00:05:00,470
the app developed by a third party and

106
00:05:00,710 --> 00:05:11,638
all of that creates what essentially has

107
00:05:03,780 --> 00:05:14,159
been a perfect storm so how this work of

108
00:05:11,639 --> 00:05:18,120
rigid aid so I do some work for 4d CMS

109
00:05:14,160 --> 00:05:21,900
is equivalent Department and they have a

110
00:05:18,120 --> 00:05:24,449
role here on cybersecurity I do some

111
00:05:21,900 --> 00:05:26,849
work on standards and so on and I was

112
00:05:24,449 --> 00:05:29,639
tasked with creating this code of

113
00:05:26,849 --> 00:05:32,849
practice for IOT security along with a

114
00:05:29,639 --> 00:05:33,449
lot of very very clever people from the

115
00:05:32,849 --> 00:05:36,000
NCSC

116
00:05:33,449 --> 00:05:42,060
and the ICO and another parts of

117
00:05:36,000 --> 00:05:46,020
government I was going to go through a

118
00:05:42,060 --> 00:05:49,919
bunch of slides with examples of things

119
00:05:46,020 --> 00:05:51,919
like cloud pets and connected fish tanks

120
00:05:49,919 --> 00:05:54,990
in casinos and stuff like that

121
00:05:51,919 --> 00:05:57,508
and to be honest of you couldn't be

122
00:05:54,990 --> 00:06:01,770
bothered so you got a picture of my cat

123
00:05:57,509 --> 00:06:03,199
instead this is pumpkin if you play neko

124
00:06:01,770 --> 00:06:07,109
atsume this is pumpkin two pumpkins

125
00:06:03,199 --> 00:06:08,699
named after pumpkin but i thought this

126
00:06:07,110 --> 00:06:12,289
is kind of looking through four pictures

127
00:06:08,699 --> 00:06:14,250
of my cat this morning this morning and

128
00:06:12,289 --> 00:06:17,669
this is actually quite a good one

129
00:06:14,250 --> 00:06:21,659
actually so this is I guess we can say

130
00:06:17,669 --> 00:06:25,109
well this is this is bit Phi this is

131
00:06:21,659 --> 00:06:27,979
cyber guidance now um this is Ken Monroe

132
00:06:25,110 --> 00:06:27,979
this is IOT

133
00:06:28,490 --> 00:06:33,150
but there are so many examples out there

134
00:06:31,710 --> 00:06:35,219
we all know them that's why I didn't

135
00:06:33,150 --> 00:06:37,440
want to kind of you know teach my

136
00:06:35,220 --> 00:06:39,930
grandmother to suck eggs we all know

137
00:06:37,440 --> 00:06:42,360
where these issues are we see all of

138
00:06:39,930 --> 00:06:45,680
these products and we're not actually

139
00:06:42,360 --> 00:06:50,060
surprised when we see that yet another

140
00:06:45,680 --> 00:06:50,060
crappy piece of IOT has been hacked

141
00:06:50,990 --> 00:06:56,700
those companies that are hacked seem to

142
00:06:54,360 --> 00:07:00,930
be surprised obviously we've got it by a

143
00:06:56,700 --> 00:07:03,120
sample here but in my experience and

144
00:07:00,930 --> 00:07:06,090
I've run a company when we get people

145
00:07:03,120 --> 00:07:09,180
ringing us up saying my products been

146
00:07:06,090 --> 00:07:10,799
hacked and what do we do and so on give

147
00:07:09,180 --> 00:07:14,940
you a couple of examples so one was a

148
00:07:10,800 --> 00:07:17,640
very large webcam vendor I think was

149
00:07:14,940 --> 00:07:21,930
context had actually done a free public

150
00:07:17,640 --> 00:07:25,729
pen test and published the results scott

151
00:07:21,930 --> 00:07:25,730
lester and did a great job on that

152
00:07:25,790 --> 00:07:34,020
company rings up and says we want a pen

153
00:07:29,790 --> 00:07:37,560
test all right well here's the pen test

154
00:07:34,020 --> 00:07:40,229
you've already got the results no no we

155
00:07:37,560 --> 00:07:42,570
want a pen test all right well you need

156
00:07:40,230 --> 00:07:43,890
to redesign your product right you need

157
00:07:42,570 --> 00:07:45,750
to all right first of all you need to

158
00:07:43,890 --> 00:07:48,360
fix the problems you've got but you do

159
00:07:45,750 --> 00:07:50,910
need to redesign your product no no we

160
00:07:48,360 --> 00:07:53,520
want a pen test and this conversation

161
00:07:50,910 --> 00:07:57,720
went on for about 20 minutes and then

162
00:07:53,520 --> 00:07:59,520
the company eventually went away and and

163
00:07:57,720 --> 00:08:03,360
this is not an uncommon conversation is

164
00:07:59,520 --> 00:08:05,460
that most of these companies that get

165
00:08:03,360 --> 00:08:06,270
hit all they want to do is make the

166
00:08:05,460 --> 00:08:10,260
problem go away

167
00:08:06,270 --> 00:08:13,620
I had another company which created kids

168
00:08:10,260 --> 00:08:20,820
kids smartwatches and the founder rang

169
00:08:13,620 --> 00:08:23,460
me up in tears we need some help okay

170
00:08:20,820 --> 00:08:27,630
here's what you need to do to redesign

171
00:08:23,460 --> 00:08:31,650
your product but these this one's quite

172
00:08:27,630 --> 00:08:33,780
interesting because what you see a lot

173
00:08:31,650 --> 00:08:36,630
of these products are kind of badged

174
00:08:33,780 --> 00:08:39,150
or DM product so outside design

175
00:08:36,630 --> 00:08:40,390
manufacturer and they're coming from

176
00:08:39,150 --> 00:08:44,560
Shenzhen some

177
00:08:40,390 --> 00:08:46,660
in China and then the job of the

178
00:08:44,560 --> 00:08:48,310
entrepreneur in Europe is basically to

179
00:08:46,660 --> 00:08:51,939
get into the sales channels of big

180
00:08:48,310 --> 00:08:53,829
retailers right so the entrepreneur

181
00:08:51,940 --> 00:08:56,650
doesn't actually care what that product

182
00:08:53,830 --> 00:09:00,550
contains nor do they know a lot about it

183
00:08:56,650 --> 00:09:02,680
at all but the problem is is that that

184
00:09:00,550 --> 00:09:05,589
reference platform that's been used for

185
00:09:02,680 --> 00:09:09,599
say that watch is the same across all of

186
00:09:05,590 --> 00:09:12,670
those different watches that sold and I

187
00:09:09,600 --> 00:09:15,970
kind of you know people throw around the

188
00:09:12,670 --> 00:09:18,219
word backdoor quite a lot but I can't

189
00:09:15,970 --> 00:09:21,460
quite work out in a lot of cases whether

190
00:09:18,220 --> 00:09:24,490
it's just a cultural issue that there's

191
00:09:21,460 --> 00:09:28,180
a lack of understanding that you can't

192
00:09:24,490 --> 00:09:31,000
just have you know an open remote

193
00:09:28,180 --> 00:09:35,020
diagnostics function with all of the

194
00:09:31,000 --> 00:09:37,300
development commands over SMS you know

195
00:09:35,020 --> 00:09:40,449
that seems to be like a massive

196
00:09:37,300 --> 00:09:41,740
mentality issue here and then surprise

197
00:09:40,450 --> 00:09:43,240
surprise you know the companies getting

198
00:09:41,740 --> 00:09:45,520
really upset because somebody's

199
00:09:43,240 --> 00:09:48,550
published the list of commands on the

200
00:09:45,520 --> 00:09:50,520
internet and it's like well you're kind

201
00:09:48,550 --> 00:09:54,490
of focusing on the wrong problem here

202
00:09:50,520 --> 00:09:56,290
you know so and this is stuff that we

203
00:09:54,490 --> 00:09:59,290
see over and over again actually coming

204
00:09:56,290 --> 00:10:01,209
back to mobile phones for those of you

205
00:09:59,290 --> 00:10:05,349
at Def Con I'm sorry it wasn't DEFCON

206
00:10:01,210 --> 00:10:07,660
actually this was a use Nick's the the

207
00:10:05,350 --> 00:10:11,260
sort of expose of how many people had

208
00:10:07,660 --> 00:10:15,310
left hundreds in some cases thousands of

209
00:10:11,260 --> 00:10:18,730
80 commands left wide open on mobile

210
00:10:15,310 --> 00:10:21,339
devices still just sat there and so it

211
00:10:18,730 --> 00:10:25,630
isn't you know it's not unique to it to

212
00:10:21,340 --> 00:10:28,480
IOT but we just see the same problems

213
00:10:25,630 --> 00:10:30,420
time and time again and this is stuff

214
00:10:28,480 --> 00:10:36,510
that we've all been talking about for

215
00:10:30,420 --> 00:10:36,510
20-25 years and it's still going on so

216
00:10:37,650 --> 00:10:41,590
when we had these meetings we had an

217
00:10:40,030 --> 00:10:43,180
expert committee that was put together

218
00:10:41,590 --> 00:10:45,880
there was loads and loads of different

219
00:10:43,180 --> 00:10:49,760
companies consulted people myself were

220
00:10:45,880 --> 00:10:52,020
talking to researchers around the world

221
00:10:49,760 --> 00:10:53,490
regularly going to security conferences

222
00:10:52,020 --> 00:10:58,680
and so on talks a lot of security

223
00:10:53,490 --> 00:11:01,350
researchers but it was interesting at

224
00:10:58,680 --> 00:11:03,449
the table because then you get that the

225
00:11:01,350 --> 00:11:09,360
same old things trotted out what we've

226
00:11:03,450 --> 00:11:12,540
got to do is educate the users or you

227
00:11:09,360 --> 00:11:15,000
know some fanciful thing about quantum

228
00:11:12,540 --> 00:11:16,740
computing and you know maybe we should

229
00:11:15,000 --> 00:11:18,930
make these things quantum resistant and

230
00:11:16,740 --> 00:11:21,720
I'm kind of banging my head off the

231
00:11:18,930 --> 00:11:23,310
table at this point because actually the

232
00:11:21,720 --> 00:11:27,210
broad problem that we've got and this is

233
00:11:23,310 --> 00:11:28,650
highlighted by Mirai is that we're not

234
00:11:27,210 --> 00:11:30,390
even bothering with looking at the

235
00:11:28,650 --> 00:11:32,160
basics because actually the basics

236
00:11:30,390 --> 00:11:34,860
aren't that sexy anymore

237
00:11:32,160 --> 00:11:37,709
but there are still manufacturers a huge

238
00:11:34,860 --> 00:11:39,690
amount of manufacturers who are doing

239
00:11:37,710 --> 00:11:42,450
really really insecure things and

240
00:11:39,690 --> 00:11:44,820
actually we've probably reached a point

241
00:11:42,450 --> 00:11:47,520
where we just need to say no it's not

242
00:11:44,820 --> 00:11:50,910
acceptable we want to eliminate this

243
00:11:47,520 --> 00:11:55,530
stuff and we're gonna say that we will

244
00:11:50,910 --> 00:12:00,600
not tolerate it anymore and we kind of

245
00:11:55,530 --> 00:12:04,530
got some consensus on that the cut

246
00:12:00,600 --> 00:12:06,930
picture here so I guess yeah the reason

247
00:12:04,530 --> 00:12:11,459
for this is we all know what's going to

248
00:12:06,930 --> 00:12:16,859
happen to these IOT products right and

249
00:12:11,460 --> 00:12:19,770
it did so the background to the secured

250
00:12:16,860 --> 00:12:21,800
by design work is sin so in the UK were

251
00:12:19,770 --> 00:12:24,780
had the national cyber security strategy

252
00:12:21,800 --> 00:12:29,699
so that the first iteration that was

253
00:12:24,780 --> 00:12:33,180
worked on 2010-2011 and the core of that

254
00:12:29,700 --> 00:12:35,550
was really to say we want our aspiration

255
00:12:33,180 --> 00:12:37,800
as we want the UK to be one of the most

256
00:12:35,550 --> 00:12:44,219
safe places in the world to do business

257
00:12:37,800 --> 00:12:48,089
to work in we want the UK to be an

258
00:12:44,220 --> 00:12:50,010
exporter of you know security goods and

259
00:12:48,090 --> 00:12:53,670
services we're already pretty good at

260
00:12:50,010 --> 00:12:56,640
that and also we want to build the

261
00:12:53,670 --> 00:12:58,860
skills base so one I encourage

262
00:12:56,640 --> 00:13:00,810
universities and so on so I teach a

263
00:12:58,860 --> 00:13:01,740
couple universities and we've now got

264
00:13:00,810 --> 00:13:05,819
the

265
00:13:01,740 --> 00:13:11,580
I use certified degrees in system

266
00:13:05,820 --> 00:13:14,490
security we've got various cohorts of

267
00:13:11,580 --> 00:13:18,690
PhD students around that are already

268
00:13:14,490 --> 00:13:21,420
coming out funded by DCMS so we're

269
00:13:18,690 --> 00:13:23,190
starting to see the results of some of

270
00:13:21,420 --> 00:13:25,439
that investment but as a second

271
00:13:23,190 --> 00:13:28,590
iteration of the cybersecurity strategy

272
00:13:25,440 --> 00:13:33,480
which start in 2016 and within that we

273
00:13:28,590 --> 00:13:34,890
also said that the UK's more secure as a

274
00:13:33,480 --> 00:13:36,600
result of technology products and

275
00:13:34,890 --> 00:13:43,020
services having cyber security designed

276
00:13:36,600 --> 00:13:46,230
into them by default so what we're

277
00:13:43,020 --> 00:13:48,000
saying is you know U is an

278
00:13:46,230 --> 00:13:49,770
acknowledgment that you can't just add

279
00:13:48,000 --> 00:13:52,490
security isn't afterthought that

280
00:13:49,770 --> 00:13:55,650
actually we new do need that design

281
00:13:52,490 --> 00:13:58,290
mentality shift to say this thing is

282
00:13:55,650 --> 00:14:00,540
going to be properly secured and we're

283
00:13:58,290 --> 00:14:01,860
going to invest in secure software the

284
00:14:00,540 --> 00:14:04,110
lifecycle

285
00:14:01,860 --> 00:14:07,260
we're going to actually think about

286
00:14:04,110 --> 00:14:14,160
security as we build these products so

287
00:14:07,260 --> 00:14:16,290
by implication we need to define define

288
00:14:14,160 --> 00:14:22,949
how we're going to actually do that what

289
00:14:16,290 --> 00:14:24,689
the tactics to actually achieve that so

290
00:14:22,950 --> 00:14:26,700
a review was conducted the secured by

291
00:14:24,690 --> 00:14:31,260
design review and it looked at two key

292
00:14:26,700 --> 00:14:33,300
risks risks related to consumer IOT so

293
00:14:31,260 --> 00:14:35,750
the first one was that the poorly

294
00:14:33,300 --> 00:14:38,430
secured IOT devices and services

295
00:14:35,750 --> 00:14:41,160
increasingly threatened consumers online

296
00:14:38,430 --> 00:14:43,459
security and privacy and even safety

297
00:14:41,160 --> 00:14:46,740
don't think anyone will argue with that

298
00:14:43,460 --> 00:14:49,880
the second point addresses a slightly

299
00:14:46,740 --> 00:14:54,450
different slant in this problem which is

300
00:14:49,880 --> 00:14:57,780
the poorly secured devices in homes

301
00:14:54,450 --> 00:15:01,230
across the UK can end up being hijacked

302
00:14:57,780 --> 00:15:02,689
and be used as part of an attack on

303
00:15:01,230 --> 00:15:05,870
something else

304
00:15:02,690 --> 00:15:09,870
so actually the user may see no effect

305
00:15:05,870 --> 00:15:13,820
and that is a greater problem for the

306
00:15:09,870 --> 00:15:13,820
country in some respects

307
00:15:14,089 --> 00:15:20,029
and so you know we saw with Mirai there

308
00:15:17,660 --> 00:15:22,850
have been other IOT botnets like Reaper

309
00:15:20,029 --> 00:15:26,990
and so on but Mirai office Li had the

310
00:15:22,850 --> 00:15:28,550
biggest impact 1.2 terabytes per second

311
00:15:26,990 --> 00:15:32,509
at one point again it's Brian Krebs I

312
00:15:28,550 --> 00:15:34,069
think it was just show the resilience of

313
00:15:32,509 --> 00:15:37,129
the internet actually though I mean ok

314
00:15:34,069 --> 00:15:40,009
you know 24 hours of pain but kind of

315
00:15:37,129 --> 00:15:42,850
bounce back you know Internet still

316
00:15:40,009 --> 00:15:42,850
running wasn't broken

317
00:15:48,019 --> 00:15:54,170
and so the back end of this was that on

318
00:15:51,399 --> 00:15:56,929
March the 7th we launched a report at

319
00:15:54,170 --> 00:16:00,110
which which kind of contained all of our

320
00:15:56,929 --> 00:16:03,529
efforts on this and at the heart of this

321
00:16:00,110 --> 00:16:06,799
was this code of practice on IOT

322
00:16:03,529 --> 00:16:09,439
security there was a public feedback

323
00:16:06,799 --> 00:16:12,799
phase so that went on until the end of

324
00:16:09,439 --> 00:16:16,219
April I think Steve said he was gonna

325
00:16:12,799 --> 00:16:19,579
feedback to it had lots and lots of

326
00:16:16,220 --> 00:16:23,420
interesting input from from companies

327
00:16:19,579 --> 00:16:25,670
and individuals from associations

328
00:16:23,420 --> 00:16:28,759
representing different types of

329
00:16:25,670 --> 00:16:30,829
industries because even within consumer

330
00:16:28,759 --> 00:16:33,049
IOT you've got kind of individual what

331
00:16:30,829 --> 00:16:36,649
they would call verticals of things like

332
00:16:33,049 --> 00:16:38,689
children's toys and there are certain

333
00:16:36,649 --> 00:16:41,749
sectors that you know children's toys

334
00:16:38,689 --> 00:16:43,368
it's a classic example so the good work

335
00:16:41,749 --> 00:16:45,379
that Ken Monroe's been doing to

336
00:16:43,369 --> 00:16:48,790
highlight issues with the Kayla doll and

337
00:16:45,379 --> 00:16:53,629
so on Oh Troy hunt we count cloud pets

338
00:16:48,790 --> 00:16:55,219
all really focuses attention and I think

339
00:16:53,629 --> 00:16:57,579
the toys and games industries have

340
00:16:55,220 --> 00:17:00,199
actually woken up to the fact that maybe

341
00:16:57,579 --> 00:17:03,019
maybe putting kids toys on the Internet

342
00:17:00,199 --> 00:17:09,319
might be about they could have told them

343
00:17:03,019 --> 00:17:12,109
that but anyway but so within this

344
00:17:09,319 --> 00:17:15,470
report also there are other aspects so

345
00:17:12,109 --> 00:17:17,479
about education and so on about things

346
00:17:15,470 --> 00:17:23,899
like labeling how do you communicates

347
00:17:17,480 --> 00:17:26,089
the user things like skills how do we

348
00:17:23,898 --> 00:17:30,590
scale up an SME to understand how to

349
00:17:26,089 --> 00:17:31,879
implement security for example that's

350
00:17:30,590 --> 00:17:34,939
available to download you can have a

351
00:17:31,880 --> 00:17:36,679
look at it that called a practice quite

352
00:17:34,940 --> 00:17:39,230
detailed and I'm gonna show you some

353
00:17:36,679 --> 00:17:40,520
detail here it's quite nice to be in

354
00:17:39,230 --> 00:17:46,700
front of an audience that understand the

355
00:17:40,520 --> 00:17:49,610
detail and the final version based on

356
00:17:46,700 --> 00:17:53,179
that public feedback will be published

357
00:17:49,610 --> 00:17:56,149
later in the autumn and I'm kind of

358
00:17:53,179 --> 00:17:57,620
pleased to say actually the the the

359
00:17:56,149 --> 00:17:58,280
feedback that we received was amazing by

360
00:17:57,620 --> 00:18:00,469
the way but

361
00:17:58,280 --> 00:18:02,360
substantially the code of practice

362
00:18:00,470 --> 00:18:03,890
hasn't changed there seems to be broad

363
00:18:02,360 --> 00:18:06,409
consensus that we kind of hit the right

364
00:18:03,890 --> 00:18:08,330
areas there were a few things that

365
00:18:06,410 --> 00:18:10,030
cropped up as I yeah didn't think about

366
00:18:08,330 --> 00:18:12,860
on one

367
00:18:10,030 --> 00:18:15,500
there's misinterpretations or things so

368
00:18:12,860 --> 00:18:17,840
for example if I say outage in my head

369
00:18:15,500 --> 00:18:19,250
I'm thinking network outage but to a

370
00:18:17,840 --> 00:18:22,399
different set of people they're thinking

371
00:18:19,250 --> 00:18:25,880
power outage so just kind of cleaning up

372
00:18:22,400 --> 00:18:32,630
languages to fight that but I think it's

373
00:18:25,880 --> 00:18:34,520
all made it more robust and so we

374
00:18:32,630 --> 00:18:36,410
concentrated on three main areas and

375
00:18:34,520 --> 00:18:41,360
this is really important to know that

376
00:18:36,410 --> 00:18:48,500
you know these these top three of what

377
00:18:41,360 --> 00:18:50,360
we are really concerned about and so how

378
00:18:48,500 --> 00:18:54,490
this how this originated with the code

379
00:18:50,360 --> 00:18:56,870
of practice so I was at a meeting in

380
00:18:54,490 --> 00:18:59,000
Etsy in the South of France and there

381
00:18:56,870 --> 00:19:01,459
was a guy from the NCSC with me and we

382
00:18:59,000 --> 00:19:03,200
sat down outside and literally a

383
00:19:01,460 --> 00:19:05,810
conversation was how would we have

384
00:19:03,200 --> 00:19:07,310
stopped me right so that's how we

385
00:19:05,810 --> 00:19:14,780
started off for building up the code of

386
00:19:07,310 --> 00:19:18,250
practice so the devices that were part

387
00:19:14,780 --> 00:19:23,560
of the mirai botnet were accessed

388
00:19:18,250 --> 00:19:25,760
through port 23 telnet using 61

389
00:19:23,560 --> 00:19:29,389
combinations of default usernames and

390
00:19:25,760 --> 00:19:33,170
passwords right so can anyone guess what

391
00:19:29,390 --> 00:19:36,650
the first one in the list was admin

392
00:19:33,170 --> 00:19:38,180
admin right so okay it's bits do you

393
00:19:36,650 --> 00:19:41,030
guys to get this right but actually if

394
00:19:38,180 --> 00:19:43,400
you speak to any I say normal person

395
00:19:41,030 --> 00:19:45,920
okay hey you know person that's not us

396
00:19:43,400 --> 00:19:47,720
and they'll also give you that answer

397
00:19:45,920 --> 00:19:51,620
everybody knows the problem the problem

398
00:19:47,720 --> 00:19:54,020
is staring itself in our faces right we

399
00:19:51,620 --> 00:19:57,199
know everybody knows so why have we

400
00:19:54,020 --> 00:19:59,830
still got this situation it I can tell

401
00:19:57,200 --> 00:20:03,080
you now that there is a manufacturer

402
00:19:59,830 --> 00:20:06,020
producing product today with the default

403
00:20:03,080 --> 00:20:08,240
password of admin admin guarantee though

404
00:20:06,020 --> 00:20:09,950
and the rest of all of those passwords

405
00:20:08,240 --> 00:20:13,140
available

406
00:20:09,950 --> 00:20:15,270
this is not confined to just consumer

407
00:20:13,140 --> 00:20:17,370
devices we've got Reuters got industrial

408
00:20:15,270 --> 00:20:21,629
equipment and so on so why are we

409
00:20:17,370 --> 00:20:24,540
tolerating it we don't need to so let's

410
00:20:21,630 --> 00:20:27,210
get rid of it let's stamp it out there

411
00:20:24,540 --> 00:20:29,420
are other methods for authenticating to

412
00:20:27,210 --> 00:20:32,100
devices we've established what those are

413
00:20:29,420 --> 00:20:34,980
there's guidance available the standards

414
00:20:32,100 --> 00:20:37,379
available already so let's you know it's

415
00:20:34,980 --> 00:20:39,060
not like there's no solution to this the

416
00:20:37,380 --> 00:20:43,410
reason that people do this is because

417
00:20:39,060 --> 00:20:45,570
they're lazy and it's easy and because

418
00:20:43,410 --> 00:20:49,440
everyone else is doing it so if we make

419
00:20:45,570 --> 00:20:51,600
it unacceptable to do that maybe even if

420
00:20:49,440 --> 00:20:53,550
we regulate in the future to prevent

421
00:20:51,600 --> 00:20:57,360
that happening we can stamp this out

422
00:20:53,550 --> 00:20:59,010
once and for all and you know there are

423
00:20:57,360 --> 00:21:01,740
campaigns I mean if you look at people

424
00:20:59,010 --> 00:21:03,960
like the phyto Alliance they're quite

425
00:21:01,740 --> 00:21:07,140
keen to eliminate the password

426
00:21:03,960 --> 00:21:09,000
I don't think practically we're gonna

427
00:21:07,140 --> 00:21:13,080
eliminate passwords they're kind of

428
00:21:09,000 --> 00:21:15,900
useful in certain circumstances but this

429
00:21:13,080 --> 00:21:19,260
is a actual problem that is actually

430
00:21:15,900 --> 00:21:22,500
causing harm right now so if we have the

431
00:21:19,260 --> 00:21:25,920
power to deal with it then we should so

432
00:21:22,500 --> 00:21:29,430
that's why it's number one number two

433
00:21:25,920 --> 00:21:36,090
and to be honest review this is quite

434
00:21:29,430 --> 00:21:39,060
hard for was to ask any company that's

435
00:21:36,090 --> 00:21:40,649
producing an IOT product or service to

436
00:21:39,060 --> 00:21:43,169
actually implement of an ability

437
00:21:40,650 --> 00:21:45,240
disclosure policy preferably cvd

438
00:21:43,170 --> 00:21:48,960
coordinator and release and disclosure

439
00:21:45,240 --> 00:21:53,700
and actually act on it and we do say and

440
00:21:48,960 --> 00:21:58,280
act on it so we have the beauty of the

441
00:21:53,700 --> 00:22:00,960
fact that people like Katy Missouri who

442
00:21:58,280 --> 00:22:03,389
set up cvd in the first place at

443
00:22:00,960 --> 00:22:06,690
Microsoft has really pushed this forward

444
00:22:03,390 --> 00:22:08,760
and is even standardized internationally

445
00:22:06,690 --> 00:22:12,570
it standardized in an ISO standard which

446
00:22:08,760 --> 00:22:15,150
is freely available and downloadable but

447
00:22:12,570 --> 00:22:17,730
it's also a recommendation that's been

448
00:22:15,150 --> 00:22:21,330
taken up by the mobile in mobile phone

449
00:22:17,730 --> 00:22:21,970
industry through GSMA the IOT security

450
00:22:21,330 --> 00:22:27,090
foundation

451
00:22:21,970 --> 00:22:30,030
recommend that you have mint CVD so

452
00:22:27,090 --> 00:22:33,040
again it's within our power to say to

453
00:22:30,030 --> 00:22:39,340
companies that we expect you to

454
00:22:33,040 --> 00:22:41,560
implement a CVD policy because actually

455
00:22:39,340 --> 00:22:43,750
that if you have no point for anybody to

456
00:22:41,560 --> 00:22:45,820
report for an abilities to you then

457
00:22:43,750 --> 00:22:50,890
you're probably not going to start to

458
00:22:45,820 --> 00:22:54,580
fix them but as Katie also makes a very

459
00:22:50,890 --> 00:22:56,920
good point repeatedly you know it's

460
00:22:54,580 --> 00:23:01,030
not-it's no good just implementing a

461
00:22:56,920 --> 00:23:03,430
policy or implementing a bug parity

462
00:23:01,030 --> 00:23:05,500
scheme for example if you don't actually

463
00:23:03,430 --> 00:23:08,530
clean your own house off if you're not

464
00:23:05,500 --> 00:23:10,500
actually actively implementing process

465
00:23:08,530 --> 00:23:13,120
measures internally in your business to

466
00:23:10,500 --> 00:23:15,100
clean bugs clean up your code and

467
00:23:13,120 --> 00:23:18,340
actually close down security

468
00:23:15,100 --> 00:23:20,679
vulnerabilities but it is a big step

469
00:23:18,340 --> 00:23:22,959
forward and it actually forces these

470
00:23:20,680 --> 00:23:26,200
companies to take security researchers

471
00:23:22,960 --> 00:23:28,720
seriously so many of you in the audience

472
00:23:26,200 --> 00:23:30,760
and I'll include myself in this have

473
00:23:28,720 --> 00:23:33,840
been stonewalled by vendors when we've

474
00:23:30,760 --> 00:23:35,620
reported disclosures actually that's

475
00:23:33,840 --> 00:23:38,620
unfortunately quite a successful

476
00:23:35,620 --> 00:23:40,479
strategy for them unless you know I if I

477
00:23:38,620 --> 00:23:42,159
disclose something I'm probably not

478
00:23:40,480 --> 00:23:46,510
going to go full disclosure if I'm

479
00:23:42,160 --> 00:23:48,400
honest so I do sit on things and that's

480
00:23:46,510 --> 00:23:49,720
usually mainly just a personal thing

481
00:23:48,400 --> 00:23:54,760
because I don't want to kind of come

482
00:23:49,720 --> 00:23:56,770
cause loads of consumer harm but it is a

483
00:23:54,760 --> 00:23:58,540
reality that actually most research is

484
00:23:56,770 --> 00:24:00,190
our force to full disclosure just

485
00:23:58,540 --> 00:24:03,159
because that's the only point at which a

486
00:24:00,190 --> 00:24:06,880
vendor will do something once they're

487
00:24:03,160 --> 00:24:08,290
shamed into it and but actually also I

488
00:24:06,880 --> 00:24:13,800
would say that some vendors are getting

489
00:24:08,290 --> 00:24:16,300
quite adept with their PR machinery so

490
00:24:13,800 --> 00:24:19,710
whilst there's been some good work in

491
00:24:16,300 --> 00:24:19,710
the community in terms of like

492
00:24:20,100 --> 00:24:24,070
highlighting companies where they

493
00:24:21,970 --> 00:24:27,850
threaten researchers for example which

494
00:24:24,070 --> 00:24:30,159
is very common that usually will

495
00:24:27,850 --> 00:24:33,780
backfire on a company from a PR point of

496
00:24:30,160 --> 00:24:33,780
view now thankfully deuter's

497
00:24:33,929 --> 00:24:42,299
but sometimes you know you see security

498
00:24:38,909 --> 00:24:45,809
researchers being smeared or the other

499
00:24:42,299 --> 00:24:48,330
one is there people getting no fixes and

500
00:24:45,809 --> 00:24:50,009
then the company quietly fixes it puts

501
00:24:48,330 --> 00:24:52,499
out an update doesn't acknowledge the

502
00:24:50,009 --> 00:24:54,809
researcher I mean real bad practice so

503
00:24:52,499 --> 00:24:56,549
you know that term of responsible

504
00:24:54,809 --> 00:24:59,668
disclosure that we kind of want to get

505
00:24:56,549 --> 00:25:02,970
rid of what I see is more broad practice

506
00:24:59,669 --> 00:25:04,970
on the corporate side then on the

507
00:25:02,970 --> 00:25:08,789
researcher side if I'm honest and

508
00:25:04,970 --> 00:25:11,460
there's still a lot of Education to tell

509
00:25:08,789 --> 00:25:13,139
these vendors that actually if somebody

510
00:25:11,460 --> 00:25:15,090
discloses something to you that's a good

511
00:25:13,139 --> 00:25:16,649
thing and you're probably dealing with a

512
00:25:15,090 --> 00:25:17,999
nice guy because the bad guys aren't

513
00:25:16,649 --> 00:25:24,330
going to disclose it to you they're just

514
00:25:17,999 --> 00:25:27,960
going to use it so we just some research

515
00:25:24,330 --> 00:25:31,139
recently didn't surprise us that there's

516
00:25:27,960 --> 00:25:36,240
probably around about 90% in the market

517
00:25:31,139 --> 00:25:38,189
has no form of variability disclosure

518
00:25:36,240 --> 00:25:43,399
policy and no way to contact those

519
00:25:38,190 --> 00:25:43,399
companies we need to clean that up I

520
00:25:43,759 --> 00:25:50,279
heard some interesting comments on

521
00:25:48,419 --> 00:25:52,379
Twitter about people talking about well

522
00:25:50,279 --> 00:25:55,259
what if a company doesn't respond to me

523
00:25:52,379 --> 00:25:57,748
maybe the next step should be that I can

524
00:25:55,259 --> 00:26:00,869
report that company to the government

525
00:25:57,749 --> 00:26:02,480
and the government can actually do

526
00:26:00,869 --> 00:26:07,259
something about it

527
00:26:02,480 --> 00:26:09,690
and I think some of those really really

528
00:26:07,259 --> 00:26:11,580
interesting ideas and I think the people

529
00:26:09,690 --> 00:26:15,450
like the NCSC are very well aware of

530
00:26:11,580 --> 00:26:17,820
this and they're also working with Katy

531
00:26:15,450 --> 00:26:22,289
Missouri on their on the government

532
00:26:17,820 --> 00:26:23,789
disclosure scheme but you know we'll

533
00:26:22,289 --> 00:26:29,009
continue to develop this as we go

534
00:26:23,789 --> 00:26:31,679
forward the third point is about keep

535
00:26:29,009 --> 00:26:36,389
software updated so this is by no means

536
00:26:31,679 --> 00:26:39,629
trivial but I would say that I I think

537
00:26:36,389 --> 00:26:41,850
this is like the sort of single greatest

538
00:26:39,629 --> 00:26:45,359
thing we can do in terms of cyber

539
00:26:41,850 --> 00:26:47,869
security hygiene you know we shouldn't

540
00:26:45,359 --> 00:26:50,908
leave these vulnerabilities open

541
00:26:47,869 --> 00:26:54,689
you know if if you look at what happens

542
00:26:50,909 --> 00:26:57,200
when you do keep your devices updated in

543
00:26:54,690 --> 00:27:00,210
the field what you do is basically you

544
00:26:57,200 --> 00:27:02,999
don't allow that kind of incubation time

545
00:27:00,210 --> 00:27:05,489
that allows the sort of commoditization

546
00:27:02,999 --> 00:27:07,019
of tools to be created for

547
00:27:05,489 --> 00:27:08,909
vulnerabilities that are left open for

548
00:27:07,019 --> 00:27:11,009
years so if you shut it down very very

549
00:27:08,909 --> 00:27:14,519
quickly you shot shut off the

550
00:27:11,009 --> 00:27:16,080
exploitation roots if you fixing

551
00:27:14,519 --> 00:27:18,840
vulnerabilities before they're found

552
00:27:16,080 --> 00:27:21,869
publicly wherever it is in the stack it

553
00:27:18,840 --> 00:27:23,609
might not be exploitable now but you're

554
00:27:21,869 --> 00:27:27,840
just keeping a clean ecosystem for

555
00:27:23,609 --> 00:27:30,320
everybody and so I've done a lot of

556
00:27:27,840 --> 00:27:33,779
working a mobile phone industry on that

557
00:27:30,320 --> 00:27:36,389
Google have done huge amounts of work to

558
00:27:33,779 --> 00:27:41,669
drag vendors kicking and screaming if

559
00:27:36,389 --> 00:27:44,939
I'm honest too a better situation is

560
00:27:41,669 --> 00:27:48,899
better but we can't say the same for IOT

561
00:27:44,940 --> 00:27:50,789
and IOT does carry its own challenges so

562
00:27:48,899 --> 00:27:53,369
you know there are super constrained

563
00:27:50,789 --> 00:27:55,080
devices out there that you may never be

564
00:27:53,369 --> 00:27:58,590
able to update so we had to consider

565
00:27:55,080 --> 00:28:01,590
things like that but I would say for the

566
00:27:58,590 --> 00:28:03,499
vast majority of devices they can be

567
00:28:01,590 --> 00:28:05,849
updated and probably should be updated

568
00:28:03,499 --> 00:28:07,320
but we have other challenges things like

569
00:28:05,849 --> 00:28:10,080
you know these devices don't have user

570
00:28:07,320 --> 00:28:13,859
interfaces the headless so how do you

571
00:28:10,080 --> 00:28:16,529
communicate that to the user how do you

572
00:28:13,859 --> 00:28:18,239
manage all of these devices in a

573
00:28:16,529 --> 00:28:20,759
household where you know you end up with

574
00:28:18,239 --> 00:28:24,599
say sixty devices that all need updating

575
00:28:20,759 --> 00:28:26,729
at various times when to update right if

576
00:28:24,599 --> 00:28:29,070
you look at the Internet of Twitter

577
00:28:26,729 --> 00:28:30,869
account which is by the way the greatest

578
00:28:29,070 --> 00:28:35,158
public service to the Internet of Things

579
00:28:30,869 --> 00:28:38,369
that I know and the latest tweet was

580
00:28:35,159 --> 00:28:40,559
about watch updates so one of the things

581
00:28:38,369 --> 00:28:43,139
we say about updates in the code of

582
00:28:40,559 --> 00:28:45,059
practice is that the core functionality

583
00:28:43,139 --> 00:28:47,428
of a product so watch is a classic

584
00:28:45,059 --> 00:28:49,320
example there's a user expectation that

585
00:28:47,429 --> 00:28:53,129
a watch should at least be able to tell

586
00:28:49,320 --> 00:28:55,049
the time and that's a very very basic

587
00:28:53,129 --> 00:28:56,668
example right but when it comes to

588
00:28:55,049 --> 00:28:59,970
safety critical it gets a bit more

589
00:28:56,669 --> 00:29:01,400
interesting so the story that I often

590
00:28:59,970 --> 00:29:04,410
tell people is

591
00:29:01,400 --> 00:29:08,760
just before nest was acquired by Google

592
00:29:04,410 --> 00:29:13,470
like two days before it was a tweet to

593
00:29:08,760 --> 00:29:17,070
nest saying thanks guys your latest

594
00:29:13,470 --> 00:29:20,730
software update turned off my nest and

595
00:29:17,070 --> 00:29:23,070
froze all my pipes it was in January the

596
00:29:20,730 --> 00:29:28,320
thing shut down stopped keeping the

597
00:29:23,070 --> 00:29:31,590
house warm and you're like how does it

598
00:29:28,320 --> 00:29:33,750
even happen i but the reason it happens

599
00:29:31,590 --> 00:29:34,949
is people design things on a bench and

600
00:29:33,750 --> 00:29:37,799
they don't actually think about the

601
00:29:34,950 --> 00:29:41,909
real-world usage but you know when it

602
00:29:37,799 --> 00:29:43,799
comes to IOT we can't accept this kind

603
00:29:41,909 --> 00:29:45,750
of failure now because actually the

604
00:29:43,799 --> 00:29:48,539
failure modes end up being safety

605
00:29:45,750 --> 00:29:51,120
critical a lot of the time in fact a lot

606
00:29:48,539 --> 00:29:53,340
of IOT devices you might not even

607
00:29:51,120 --> 00:29:56,219
consider your IOT device to be safety

608
00:29:53,340 --> 00:29:58,949
critical but somehow it links into some

609
00:29:56,220 --> 00:30:02,520
other system and suddenly you get safety

610
00:29:58,950 --> 00:30:06,539
critical scenarios so there is a concern

611
00:30:02,520 --> 00:30:09,270
by a great many people that will end up

612
00:30:06,539 --> 00:30:15,690
with the first directly attributable

613
00:30:09,270 --> 00:30:21,690
death to IOT so it's incumbent upon us

614
00:30:15,690 --> 00:30:23,309
all to try to avoid that you know we

615
00:30:21,690 --> 00:30:26,870
don't want a victim blame right we don't

616
00:30:23,309 --> 00:30:29,820
want victim blame vendors who are hacked

617
00:30:26,870 --> 00:30:29,969
because of no fault of their own you

618
00:30:29,820 --> 00:30:33,120
know

619
00:30:29,970 --> 00:30:36,000
no major negligence but what we do see

620
00:30:33,120 --> 00:30:39,110
is a lot of negligence now and a lot of

621
00:30:36,000 --> 00:30:41,760
things that will be safety critical so

622
00:30:39,110 --> 00:30:43,678
the good thing about these is also there

623
00:30:41,760 --> 00:30:46,620
they're kind of measurable so we wanted

624
00:30:43,679 --> 00:30:51,929
them to be outcome based so to a certain

625
00:30:46,620 --> 00:30:56,520
extent all of these three things even by

626
00:30:51,929 --> 00:31:00,390
a user could be checked and I think it's

627
00:30:56,520 --> 00:31:02,309
reasonable to say that if a vendor

628
00:31:00,390 --> 00:31:04,409
doesn't have those things then you

629
00:31:02,309 --> 00:31:06,658
probably well within your rights to say

630
00:31:04,409 --> 00:31:08,940
I don't want to buy it because that's

631
00:31:06,659 --> 00:31:09,690
the tip of the iceberg the rest of the

632
00:31:08,940 --> 00:31:13,620
things are probably going to be

633
00:31:09,690 --> 00:31:15,580
unsecured but we still got a long way to

634
00:31:13,620 --> 00:31:18,620
go

635
00:31:15,580 --> 00:31:21,050
about 10% at the top that I mentioned

636
00:31:18,620 --> 00:31:23,689
that the 10% of the market that is doing

637
00:31:21,050 --> 00:31:28,159
well are doing a responsible job and I

638
00:31:23,690 --> 00:31:32,090
would say that probably they meet all of

639
00:31:28,160 --> 00:31:34,670
the different elements of the of the

640
00:31:32,090 --> 00:31:37,000
code of practice and if they don't

641
00:31:34,670 --> 00:31:41,800
they're probably very close to doing it

642
00:31:37,000 --> 00:31:41,800
so then the rest of the code of practice

643
00:31:42,100 --> 00:31:49,399
tries to be pragmatic say sirs it's

644
00:31:47,000 --> 00:31:50,840
aspirational in some cases but it's a

645
00:31:49,400 --> 00:31:54,740
recognition of stuff that we probably

646
00:31:50,840 --> 00:31:56,959
already know things like you can't build

647
00:31:54,740 --> 00:32:01,580
a secure IOT product unless you have

648
00:31:56,960 --> 00:32:03,320
secure hardware right there's no you

649
00:32:01,580 --> 00:32:06,350
know we can't just randomly build these

650
00:32:03,320 --> 00:32:13,330
things and expect it to be okay when it

651
00:32:06,350 --> 00:32:13,330
reaches and routinely write something so

652
00:32:14,500 --> 00:32:23,600
again we've all seen these examples of

653
00:32:17,150 --> 00:32:25,460
people obfuscate in passwords the hard

654
00:32:23,600 --> 00:32:29,510
coded and expecting nobody to

655
00:32:25,460 --> 00:32:31,730
reverse-engineer it so if you don't have

656
00:32:29,510 --> 00:32:33,110
somewhere if you don't have secure

657
00:32:31,730 --> 00:32:35,120
storage on the device you don't have

658
00:32:33,110 --> 00:32:36,979
hardware security then that's what

659
00:32:35,120 --> 00:32:38,409
you're gonna get is developers got

660
00:32:36,980 --> 00:32:40,610
nowhere else to go

661
00:32:38,410 --> 00:32:43,220
so they're gonna have to try and do

662
00:32:40,610 --> 00:32:45,169
something that they think is clever but

663
00:32:43,220 --> 00:32:50,360
clearly isn't to an advanced level

664
00:32:45,170 --> 00:32:52,220
attacker so I'm pleased to say actually

665
00:32:50,360 --> 00:32:53,929
that there's quite a few platforms that

666
00:32:52,220 --> 00:32:56,300
are starting to come to market now that

667
00:32:53,930 --> 00:32:59,000
are including things like T's and secure

668
00:32:56,300 --> 00:33:00,980
storage and also making abstracting away

669
00:32:59,000 --> 00:33:04,460
some of the difficulties for developers

670
00:33:00,980 --> 00:33:10,760
you might seem recently as well that

671
00:33:04,460 --> 00:33:14,080
Google released a more simplified crypto

672
00:33:10,760 --> 00:33:17,720
library basically trying to avoid

673
00:33:14,080 --> 00:33:19,490
obvious pitfalls for developers that's

674
00:33:17,720 --> 00:33:23,450
the kind of thing that we need to see

675
00:33:19,490 --> 00:33:25,820
and you know cryptography is hard to

676
00:33:23,450 --> 00:33:28,420
implement and there are many ways that

677
00:33:25,820 --> 00:33:28,419
can go wrong

678
00:33:30,100 --> 00:33:38,000
we talked about communicating securely

679
00:33:33,910 --> 00:33:41,590
what was actually mean well in a lot of

680
00:33:38,000 --> 00:33:45,280
cases if you ask Ken Monroe for example

681
00:33:41,590 --> 00:33:48,649
lack of certificate validation is

682
00:33:45,280 --> 00:33:52,010
probably the one the easiest ways past a

683
00:33:48,650 --> 00:33:54,920
seemingly secure connection but if you

684
00:33:52,010 --> 00:33:57,170
if you go to stack overflow you'll see

685
00:33:54,920 --> 00:33:58,850
lots of nice comments that say you know

686
00:33:57,170 --> 00:34:00,890
how to disable certificate validation

687
00:33:58,850 --> 00:34:03,678
and HTTP connection and there's a

688
00:34:00,890 --> 00:34:06,290
comment that says thanks you solved my

689
00:34:03,679 --> 00:34:08,960
biggest problem in the project because

690
00:34:06,290 --> 00:34:10,790
this is a kind of thing that this is

691
00:34:08,960 --> 00:34:12,619
hard the developers up against the

692
00:34:10,790 --> 00:34:15,259
deadline but what you've done is make

693
00:34:12,619 --> 00:34:16,790
the errors go away and it's also hidden

694
00:34:15,260 --> 00:34:19,369
stick if it's in a mobile app right

695
00:34:16,790 --> 00:34:26,239
because the user can't see there's no

696
00:34:19,369 --> 00:34:28,790
visible warning or anything so you know

697
00:34:26,239 --> 00:34:30,500
we need to we need to ensure that these

698
00:34:28,790 --> 00:34:32,509
things have been fermented properly and

699
00:34:30,500 --> 00:34:38,330
I was pleased to see that Google

700
00:34:32,510 --> 00:34:40,190
announcement minimizing exposed attack

701
00:34:38,330 --> 00:34:42,679
surfaces you know these things are

702
00:34:40,190 --> 00:34:46,730
things that we've said before but these

703
00:34:42,679 --> 00:34:49,490
things that recoup reality so you know

704
00:34:46,730 --> 00:34:51,500
you shouldn't have remote diagnostic

705
00:34:49,489 --> 00:34:55,908
functionality now we need to wean people

706
00:34:51,500 --> 00:34:57,619
off the fact that they wanted to see

707
00:34:55,909 --> 00:35:00,020
this thing again once it goes into the

708
00:34:57,619 --> 00:35:01,340
field just in case they screwed up and

709
00:35:00,020 --> 00:35:03,680
they need to kind of mess around with it

710
00:35:01,340 --> 00:35:05,300
a little bit actually companies need to

711
00:35:03,680 --> 00:35:07,310
think about that from the start do you

712
00:35:05,300 --> 00:35:09,830
really really really need that remote

713
00:35:07,310 --> 00:35:13,700
maintenance function or is it just going

714
00:35:09,830 --> 00:35:15,440
to become effective for hijacking but

715
00:35:13,700 --> 00:35:18,560
that applies also to hardware right it's

716
00:35:15,440 --> 00:35:21,650
the amount of devices that you see with

717
00:35:18,560 --> 00:35:25,670
things like hidden serial ports so I saw

718
00:35:21,650 --> 00:35:30,200
on a femtocell an HDMI port on a

719
00:35:25,670 --> 00:35:35,740
femtocell though yeah why well clearly

720
00:35:30,200 --> 00:35:38,720
it's just a hidden serial interface now

721
00:35:35,740 --> 00:35:41,509
the company has thought

722
00:35:38,720 --> 00:35:46,910
we're clever yeah nobody will ever guess

723
00:35:41,510 --> 00:35:48,380
this clearly it's just stupid it's a

724
00:35:46,910 --> 00:35:50,118
waste of time it's a waste of time

725
00:35:48,380 --> 00:35:51,319
putting that adapter on there but

726
00:35:50,119 --> 00:35:53,420
they're putting it on there basically

727
00:35:51,319 --> 00:35:58,609
for maintenance in the field at some

728
00:35:53,420 --> 00:36:00,050
point but do the economics really work

729
00:35:58,609 --> 00:36:01,279
out companies aren't really thinking

730
00:36:00,050 --> 00:36:03,020
about this they're just thinking for

731
00:36:01,280 --> 00:36:05,180
some future point we maybe need

732
00:36:03,020 --> 00:36:07,060
maintenance but actually what they have

733
00:36:05,180 --> 00:36:10,609
done is just created an easier way for

734
00:36:07,060 --> 00:36:14,089
for somebody to get in there and an

735
00:36:10,609 --> 00:36:17,509
attack the device the same with jtech

736
00:36:14,089 --> 00:36:20,480
pots right so again companies don't

737
00:36:17,510 --> 00:36:22,190
realize that you know security

738
00:36:20,480 --> 00:36:24,319
researchers are well-versed and there's

739
00:36:22,190 --> 00:36:28,940
loads of tools like jtagulator out there

740
00:36:24,319 --> 00:36:32,960
and so on so you know why are companies

741
00:36:28,940 --> 00:36:35,420
leaving JTAG ports on PCBs they could

742
00:36:32,960 --> 00:36:38,270
they could actually remove those they

743
00:36:35,420 --> 00:36:41,930
could have it in manufacturing just on

744
00:36:38,270 --> 00:36:43,310
the biskits and that's an broken-off why

745
00:36:41,930 --> 00:36:47,270
are these things not properly

746
00:36:43,310 --> 00:36:49,609
authenticated the same with open ports

747
00:36:47,270 --> 00:36:51,500
right nobody why the hell have we still

748
00:36:49,609 --> 00:36:57,619
got devices out there with telnet open

749
00:36:51,500 --> 00:36:59,390
right it's just utterly ridiculous so

750
00:36:57,619 --> 00:37:00,859
ensuring software integrity so well

751
00:36:59,390 --> 00:37:03,200
we've got a hardware root of trust in

752
00:37:00,859 --> 00:37:04,940
there so that means that we can do

753
00:37:03,200 --> 00:37:07,730
secure boot and our secure boot is

754
00:37:04,940 --> 00:37:10,490
really hard to implement but at the end

755
00:37:07,730 --> 00:37:12,980
of the day if I turn my device on and I

756
00:37:10,490 --> 00:37:17,270
can't be actually certain that nobody's

757
00:37:12,980 --> 00:37:19,430
tampered with it since has been off then

758
00:37:17,270 --> 00:37:21,200
I kind of leave myself down the

759
00:37:19,430 --> 00:37:24,049
inevitable road that actually I do need

760
00:37:21,200 --> 00:37:27,529
secure boot I need to be able to have a

761
00:37:24,050 --> 00:37:29,930
point which I can trust and then I can

762
00:37:27,530 --> 00:37:32,240
build up more trust as I load up code

763
00:37:29,930 --> 00:37:33,589
blocks the tools are out there to do it

764
00:37:32,240 --> 00:37:35,959
this software is out there to do it

765
00:37:33,589 --> 00:37:38,480
right but people don't implement it

766
00:37:35,960 --> 00:37:41,420
because it's not you know they just

767
00:37:38,480 --> 00:37:44,230
don't think about it but we could

768
00:37:41,420 --> 00:37:46,550
eliminate a lot of cold boot attacks

769
00:37:44,230 --> 00:37:49,430
just by ensuring that people actually

770
00:37:46,550 --> 00:37:50,720
use secure boot but again we need to

771
00:37:49,430 --> 00:37:51,830
make sure that the chipsets are

772
00:37:50,720 --> 00:37:57,589
available that provide

773
00:37:51,830 --> 00:37:59,060
that functionality then woven within

774
00:37:57,590 --> 00:38:01,190
this so there's a number of requirements

775
00:37:59,060 --> 00:38:03,290
that allude to privacy and data

776
00:38:01,190 --> 00:38:06,740
protection so when we launched this in

777
00:38:03,290 --> 00:38:12,290
March we had you know we were pre gdpr

778
00:38:06,740 --> 00:38:14,240
and pre DPA turn 18 but the text is

779
00:38:12,290 --> 00:38:15,980
essentially aligned to GE PR and what

780
00:38:14,240 --> 00:38:18,950
you'll see in the autumn version is that

781
00:38:15,980 --> 00:38:20,720
we do directly refer to GD P R and

782
00:38:18,950 --> 00:38:23,720
actually that makes it very powerful and

783
00:38:20,720 --> 00:38:26,450
I'll come back to that in a second I

784
00:38:23,720 --> 00:38:29,169
talked about outages but this is again

785
00:38:26,450 --> 00:38:31,370
something I've seen out in the market is

786
00:38:29,170 --> 00:38:33,200
that actually designers don't

787
00:38:31,370 --> 00:38:35,540
necessarily think about the fact about

788
00:38:33,200 --> 00:38:38,000
when this device goes off or when

789
00:38:35,540 --> 00:38:41,029
there's a thousand of these devices and

790
00:38:38,000 --> 00:38:43,190
they all turn back on after some kind of

791
00:38:41,030 --> 00:38:44,660
big weather event so there's something

792
00:38:43,190 --> 00:38:47,840
that happens repeatedly on mobile

793
00:38:44,660 --> 00:38:49,490
networks called signaling storms so

794
00:38:47,840 --> 00:38:53,660
actually being able to deal with that

795
00:38:49,490 --> 00:38:56,209
situation how to deal with devices when

796
00:38:53,660 --> 00:38:59,120
they're offline so it amazes me how many

797
00:38:56,210 --> 00:39:02,780
devices that just think that they have

798
00:38:59,120 --> 00:39:05,089
sorry the designers think that they've

799
00:39:02,780 --> 00:39:06,410
got continually robust internet

800
00:39:05,090 --> 00:39:09,920
connection that's just absolutely

801
00:39:06,410 --> 00:39:12,230
ludicrous so particularly from a safety

802
00:39:09,920 --> 00:39:14,540
perspective the core functions of that

803
00:39:12,230 --> 00:39:17,810
device should continue to operate even

804
00:39:14,540 --> 00:39:19,160
if there is no network we should also

805
00:39:17,810 --> 00:39:24,940
consider that you're probably going to

806
00:39:19,160 --> 00:39:28,009
lose power at some point as well and

807
00:39:24,940 --> 00:39:29,660
this seems like a no-brainer but if you

808
00:39:28,010 --> 00:39:32,390
get into lebra to date or offer device

809
00:39:29,660 --> 00:39:33,649
now there's a gbbr point to this as well

810
00:39:32,390 --> 00:39:36,529
that you probably shouldn't be

811
00:39:33,650 --> 00:39:38,570
collecting unnecessarily data so if you

812
00:39:36,530 --> 00:39:41,180
if you don't need it but if you are

813
00:39:38,570 --> 00:39:42,590
monitoring system celebrity data then

814
00:39:41,180 --> 00:39:44,930
it's kind of a no-brainer

815
00:39:42,590 --> 00:39:48,350
they'd actually also monitor that for

816
00:39:44,930 --> 00:39:52,609
security anomalies so we want companies

817
00:39:48,350 --> 00:39:55,730
to think about that this one comes from

818
00:39:52,610 --> 00:39:58,630
GD P r2 which is about making it easy

819
00:39:55,730 --> 00:40:01,610
for consumers to delete personal data

820
00:39:58,630 --> 00:40:03,440
and that's about the consideration of

821
00:40:01,610 --> 00:40:05,910
you know somebody sells a device or if

822
00:40:03,440 --> 00:40:08,369
they give it to their friend or even

823
00:40:05,910 --> 00:40:10,348
know that the easiest one is a is a hire

824
00:40:08,369 --> 00:40:13,260
car or if you're selling your car right

825
00:40:10,349 --> 00:40:16,410
need to be able to satisfy the consumer

826
00:40:13,260 --> 00:40:20,359
that that their stuff is not on there

827
00:40:16,410 --> 00:40:20,359
anymore and it's been securely removed

828
00:40:23,150 --> 00:40:28,140
security usability so something that

829
00:40:25,829 --> 00:40:30,210
people don't think about a lot we want

830
00:40:28,140 --> 00:40:33,480
to encourage designers now unfortunately

831
00:40:30,210 --> 00:40:37,140
there's not you know the best book back

832
00:40:33,480 --> 00:40:40,140
and find is from 2004 maybe somebody

833
00:40:37,140 --> 00:40:42,288
needs to write the the great design

834
00:40:40,140 --> 00:40:45,058
patterns book for usability for security

835
00:40:42,289 --> 00:40:47,280
because actually we can eliminate a lot

836
00:40:45,059 --> 00:40:51,299
of security issues through cleverly

837
00:40:47,280 --> 00:40:56,010
designed interfaces and not leading the

838
00:40:51,299 --> 00:40:58,589
user down a track of insecurity and if

839
00:40:56,010 --> 00:40:59,819
you if you buy devices now just think

840
00:40:58,589 --> 00:41:01,740
about it when you're in the setup

841
00:40:59,819 --> 00:41:04,200
process you know is this actually easy

842
00:41:01,740 --> 00:41:06,450
is there somewhere that we can go wrong

843
00:41:04,200 --> 00:41:08,279
does it deliberately lead me down a path

844
00:41:06,450 --> 00:41:13,098
of insecurity and in a lot of cases it

845
00:41:08,280 --> 00:41:15,599
does the even the user manuals are just

846
00:41:13,099 --> 00:41:17,579
unreadable they don't tell the user

847
00:41:15,599 --> 00:41:23,000
anything about what they need to do in

848
00:41:17,579 --> 00:41:29,279
terms of security and then the last one

849
00:41:23,000 --> 00:41:30,930
this is about ensuring that data is not

850
00:41:29,279 --> 00:41:33,480
being manipulated across interfaces

851
00:41:30,930 --> 00:41:36,538
right so we've all seen it but this is

852
00:41:33,480 --> 00:41:39,150
everything from user interfaces through

853
00:41:36,539 --> 00:41:44,400
to interfaces between different types of

854
00:41:39,150 --> 00:41:46,170
systems right so again this is consumer

855
00:41:44,400 --> 00:41:48,299
focus good example from the automotive

856
00:41:46,170 --> 00:41:52,200
world where data is transferred from

857
00:41:48,299 --> 00:41:55,440
from most to the canvas you know and

858
00:41:52,200 --> 00:41:57,930
nobody was checking what data can and

859
00:41:55,440 --> 00:41:59,910
can't go across those interfaces well

860
00:41:57,930 --> 00:42:03,089
even to extend in things like you know

861
00:41:59,910 --> 00:42:05,098
is a temperature sensor sending data

862
00:42:03,089 --> 00:42:07,470
that's out of the possible physical

863
00:42:05,099 --> 00:42:08,940
range of that device then maybe the

864
00:42:07,470 --> 00:42:11,730
subject should be some checks in there

865
00:42:08,940 --> 00:42:14,160
to make sure that no data can be sent or

866
00:42:11,730 --> 00:42:15,369
isn't that it's in numeric integer

867
00:42:14,160 --> 00:42:19,240
between

868
00:42:15,369 --> 00:42:23,099
you know minus 30 and plus 32 and

869
00:42:19,240 --> 00:42:27,430
whatever it is and so so together

870
00:42:23,099 --> 00:42:32,829
hopefully this will create a more secure

871
00:42:27,430 --> 00:42:34,629
world for all of us so the government

872
00:42:32,829 --> 00:42:37,660
clearly said as well that we're looking

873
00:42:34,630 --> 00:42:40,569
at regulatory options so we've said what

874
00:42:37,660 --> 00:42:42,160
we want but then we have to think about

875
00:42:40,569 --> 00:42:44,529
well how are we going to regulate that

876
00:42:42,160 --> 00:42:47,618
and actually there's some regulatory

877
00:42:44,529 --> 00:42:50,289
tools that are available to us gdpr is

878
00:42:47,619 --> 00:42:54,549
actually quite a good one now in many of

879
00:42:50,289 --> 00:42:56,619
those scenarios there's probably a case

880
00:42:54,549 --> 00:42:59,410
to say that that product shouldn't be on

881
00:42:56,619 --> 00:43:01,299
the market but we need to keep exploring

882
00:42:59,410 --> 00:43:03,759
those in the areas of things like

883
00:43:01,299 --> 00:43:06,609
product safety and the consumer rights

884
00:43:03,759 --> 00:43:09,099
act there possibly some levers that we

885
00:43:06,609 --> 00:43:14,230
can pull that could really be the big

886
00:43:09,099 --> 00:43:15,700
stick so you know some people have had

887
00:43:14,230 --> 00:43:19,960
this conversation we came and rode quite

888
00:43:15,700 --> 00:43:22,029
a lot talk about enforcement yes I think

889
00:43:19,960 --> 00:43:23,799
everybody agrees this but we kind of

890
00:43:22,029 --> 00:43:25,630
need to explain to you know you can't

891
00:43:23,799 --> 00:43:27,519
expect if you haven't said what you want

892
00:43:25,630 --> 00:43:31,029
you can't expect people to be doing that

893
00:43:27,519 --> 00:43:36,308
already right so we have said what we

894
00:43:31,029 --> 00:43:37,989
want and and I mentioned about the

895
00:43:36,309 --> 00:43:40,059
disclosures thing as well perhaps that's

896
00:43:37,989 --> 00:43:43,089
future work you know if companies don't

897
00:43:40,059 --> 00:43:45,009
respond how could the government help so

898
00:43:43,089 --> 00:43:47,828
our ultimate aim is to stop this stuff

899
00:43:45,009 --> 00:43:49,749
getting into the market you know there

900
00:43:47,829 --> 00:43:51,519
is a huge amount of good you know some

901
00:43:49,749 --> 00:43:53,769
companies doing very very good but bad

902
00:43:51,519 --> 00:43:55,959
companies are actually creating fear in

903
00:43:53,769 --> 00:43:57,578
consumers about buying that stuff so the

904
00:43:55,960 --> 00:43:59,950
big companies who are doing good should

905
00:43:57,579 --> 00:44:03,630
be actually promoting this and saying

906
00:43:59,950 --> 00:44:03,629
well this is this is what we want to do

907
00:44:03,690 --> 00:44:09,609
communicating that to customers is very

908
00:44:05,710 --> 00:44:12,009
difficult but actually saying to people

909
00:44:09,609 --> 00:44:13,359
being transparent about what you do and

910
00:44:12,009 --> 00:44:15,670
how long you're going to support

911
00:44:13,359 --> 00:44:18,400
software updates for and so on that's a

912
00:44:15,670 --> 00:44:21,369
good thing you know giving people more

913
00:44:18,400 --> 00:44:23,309
information that they can understand may

914
00:44:21,369 --> 00:44:26,289
influence their purchasing decision and

915
00:44:23,309 --> 00:44:28,539
yes it may be difficult for a company to

916
00:44:26,289 --> 00:44:28,930
say what the end of life of their

917
00:44:28,539 --> 00:44:30,400
product

918
00:44:28,930 --> 00:44:32,440
but they could make some kind of

919
00:44:30,400 --> 00:44:34,210
meaningful statement they can make some

920
00:44:32,440 --> 00:44:37,000
meaningful statement about this product

921
00:44:34,210 --> 00:44:38,760
was designed with security in mind we're

922
00:44:37,000 --> 00:44:41,530
not saying you know we don't want to say

923
00:44:38,760 --> 00:44:42,760
this point this this product is secure

924
00:44:41,530 --> 00:44:45,130
because it was certified at this

925
00:44:42,760 --> 00:44:47,859
particular date that's not gonna work

926
00:44:45,130 --> 00:44:49,660
right because devices are continually

927
00:44:47,859 --> 00:44:51,250
updated new vulnerabilities come along

928
00:44:49,660 --> 00:44:53,020
new things are discovered new attacks a

929
00:44:51,250 --> 00:44:55,540
disk of it so we need to move away from

930
00:44:53,020 --> 00:44:56,920
that kind of static model but actually

931
00:44:55,540 --> 00:44:59,529
think about you know is this a

932
00:44:56,920 --> 00:45:05,020
continually responsibly designed product

933
00:44:59,530 --> 00:45:08,050
and is it well maintained just briefly

934
00:45:05,020 --> 00:45:11,140
on the last point so we're also working

935
00:45:08,050 --> 00:45:14,500
on some mapping and so the idea of that

936
00:45:11,140 --> 00:45:19,029
is to you know we conducted this work

937
00:45:14,500 --> 00:45:20,500
during August but is to map existing

938
00:45:19,030 --> 00:45:23,500
standards you know DCMS is not a

939
00:45:20,500 --> 00:45:25,210
standards body but there's lots of good

940
00:45:23,500 --> 00:45:26,680
standards out there and lots of good

941
00:45:25,210 --> 00:45:29,109
recommendations the problem is there are

942
00:45:26,680 --> 00:45:31,390
a lot of them so we've been doing a

943
00:45:29,109 --> 00:45:33,790
process of mapping those and it's been a

944
00:45:31,390 --> 00:45:35,140
huge piece of works about 4,000 pages we

945
00:45:33,790 --> 00:45:36,579
had to go through various different

946
00:45:35,140 --> 00:45:38,348
things but the good thing is there's a

947
00:45:36,579 --> 00:45:40,540
lot of alignment it's just people say

948
00:45:38,349 --> 00:45:44,380
things in different ways but that will

949
00:45:40,540 --> 00:45:45,880
enable us to kind of sort of remove that

950
00:45:44,380 --> 00:45:47,710
from the equation because we've done

951
00:45:45,880 --> 00:45:49,569
that work and we're hopefully gonna make

952
00:45:47,710 --> 00:45:52,390
that available as open data as well for

953
00:45:49,569 --> 00:45:54,430
people to work on this just shows the

954
00:45:52,390 --> 00:45:57,160
sort of level of complexity in the

955
00:45:54,430 --> 00:45:58,598
ecosystem and again we're hoping to make

956
00:45:57,160 --> 00:46:01,839
this available as open data for people

957
00:45:58,599 --> 00:46:03,940
to use and we're just using a tool here

958
00:46:01,839 --> 00:46:10,119
called Kumu I'll probably continue to

959
00:46:03,940 --> 00:46:14,890
host this so people can use it so

960
00:46:10,119 --> 00:46:16,270
hopefully maybe maybe I'm putting recent

961
00:46:14,890 --> 00:46:18,910
security researches out of a job as

962
00:46:16,270 --> 00:46:21,849
alone but maybe we can just relax a

963
00:46:18,910 --> 00:46:23,618
little bit but you know hopefully it's

964
00:46:21,849 --> 00:46:26,650
gonna succeed in the market we're also

965
00:46:23,619 --> 00:46:31,720
looking at changing government

966
00:46:26,650 --> 00:46:34,690
purchasing to come to request products

967
00:46:31,720 --> 00:46:37,509
that comply with the code of practice so

968
00:46:34,690 --> 00:46:39,280
that's hopefully can be a big leg up but

969
00:46:37,510 --> 00:46:41,109
we have to also think about what our

970
00:46:39,280 --> 00:46:42,339
attackers gonna respond to this

971
00:46:41,109 --> 00:46:45,038
how are those the

972
00:46:42,339 --> 00:46:47,109
vendors that are not invested in

973
00:46:45,039 --> 00:46:48,609
actually doing this how are they going

974
00:46:47,109 --> 00:46:50,380
to react how are they going to try and

975
00:46:48,609 --> 00:46:52,029
get around this and so we're going to

976
00:46:50,380 --> 00:46:54,209
continually be watching this week and

977
00:46:52,029 --> 00:46:57,369
it's going to be under continual review

978
00:46:54,209 --> 00:47:00,098
but the good thing is for being British

979
00:46:57,369 --> 00:47:01,719
that actually Britain is kind of

980
00:47:00,099 --> 00:47:03,819
standing tall and this we're really

981
00:47:01,719 --> 00:47:04,749
really taking leadership on this you

982
00:47:03,819 --> 00:47:06,849
know there are a lot of countries

983
00:47:04,749 --> 00:47:09,399
looking at this book Britain is way far

984
00:47:06,849 --> 00:47:11,739
and ahead of a lot of countries so

985
00:47:09,400 --> 00:47:14,319
hopefully we can take the lead and show

986
00:47:11,739 --> 00:47:16,329
others the way and hopefully other

987
00:47:14,319 --> 00:47:18,519
countries will will align to this work

988
00:47:16,329 --> 00:47:22,449
as well and then we result in the

989
00:47:18,519 --> 00:47:25,808
defragmentation of this space as well so

990
00:47:22,449 --> 00:47:28,010
thanks for listening and I hope that was

991
00:47:25,809 --> 00:47:31,890
useful

992
00:47:28,010 --> 00:47:54,179
[Applause]

993
00:47:31,890 --> 00:47:54,179
[Music]

