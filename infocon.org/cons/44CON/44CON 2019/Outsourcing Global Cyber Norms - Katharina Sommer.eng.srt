1
00:00:00,000 --> 00:00:05,870
Oh

2
00:00:01,690 --> 00:00:09,530
um I was talking to someone yesterday

3
00:00:05,870 --> 00:00:13,700
and told them that I'd be talking about

4
00:00:09,530 --> 00:00:15,919
outsourcing global cyber norms and they

5
00:00:13,700 --> 00:00:19,279
said really so what do garden gnomes

6
00:00:15,920 --> 00:00:20,600
have to do with cyber and at that point

7
00:00:19,279 --> 00:00:23,090
I thought damn that would have been a

8
00:00:20,600 --> 00:00:25,330
really good topic to talk about but as

9
00:00:23,090 --> 00:00:30,710
it is we're stuck with talking about

10
00:00:25,330 --> 00:00:34,070
norms and say can I just check who's

11
00:00:30,710 --> 00:00:37,870
here to kind of look at a very academic

12
00:00:34,070 --> 00:00:40,370
very in-depth hard-hitting talk

13
00:00:37,870 --> 00:00:41,419
brilliant kids that means I don't really

14
00:00:40,370 --> 00:00:44,930
have to disappoint anyone

15
00:00:41,420 --> 00:00:47,840
and so I'm not saying that it'll all be

16
00:00:44,930 --> 00:00:51,019
unicorns and rainbows but at least part

17
00:00:47,840 --> 00:00:53,840
of the next 45 minutes will be about

18
00:00:51,020 --> 00:00:57,200
setting out a slightly utopian vision

19
00:00:53,840 --> 00:00:59,990
for the future and I know there's a

20
00:00:57,200 --> 00:01:03,710
certain bit of irony in asking a roomful

21
00:00:59,990 --> 00:01:06,170
of info SEC professionals to do this but

22
00:01:03,710 --> 00:01:08,150
I would very much like you to kind of

23
00:01:06,170 --> 00:01:11,000
dispense with the cynicism and the

24
00:01:08,150 --> 00:01:15,280
skepticism for the next 45 minutes keep

25
00:01:11,000 --> 00:01:18,830
an open mind and embrace a level of

26
00:01:15,280 --> 00:01:22,370
radical creativity I think let's let's

27
00:01:18,830 --> 00:01:26,090
call it um if you're still with me

28
00:01:22,370 --> 00:01:27,920
awesome if you're turned off now and the

29
00:01:26,090 --> 00:01:30,260
doors over there and but let me just

30
00:01:27,920 --> 00:01:32,060
manage expectations a bit further and

31
00:01:30,260 --> 00:01:35,630
just introduce you to the central

32
00:01:32,060 --> 00:01:39,890
premise of what I hope to cover in the

33
00:01:35,630 --> 00:01:43,220
next 45 minutes and it all starts with

34
00:01:39,890 --> 00:01:46,520
the basic belief that if we want to

35
00:01:43,220 --> 00:01:48,979
ensure political stability and economic

36
00:01:46,520 --> 00:01:53,780
prosperity we need international

37
00:01:48,979 --> 00:01:56,600
agreements on cyber norms and not only

38
00:01:53,780 --> 00:02:00,530
need we do we need that agreement on the

39
00:01:56,600 --> 00:02:02,630
norms we need those norms to drive

40
00:02:00,530 --> 00:02:06,409
action and drive a change in behavior

41
00:02:02,630 --> 00:02:09,829
and practices to see it on the ground in

42
00:02:06,409 --> 00:02:12,080
reality and the premise is that States

43
00:02:09,830 --> 00:02:14,200
through their international institutions

44
00:02:12,080 --> 00:02:17,500
and international fora

45
00:02:14,200 --> 00:02:21,488
not be able to deliver that for a

46
00:02:17,500 --> 00:02:24,489
variety of reasons but that corporate

47
00:02:21,489 --> 00:02:27,819
action and the corporate world are an

48
00:02:24,489 --> 00:02:30,459
appropriate alternative to be driving

49
00:02:27,819 --> 00:02:33,310
that forward so what we'll see or what

50
00:02:30,459 --> 00:02:35,890
we want to see is really a turning round

51
00:02:33,310 --> 00:02:38,040
of that traditional model of how norms

52
00:02:35,890 --> 00:02:40,839
are developed and rules are made so

53
00:02:38,040 --> 00:02:43,510
traditionally you have government's

54
00:02:40,840 --> 00:02:45,069
deciding on certain norms and setting

55
00:02:43,510 --> 00:02:47,739
our rules and requirements and

56
00:02:45,069 --> 00:02:52,208
regulations corporates have to comply

57
00:02:47,739 --> 00:02:54,700
with serve top-down model what we will

58
00:02:52,209 --> 00:02:57,519
see I would like to see in this space is

59
00:02:54,700 --> 00:03:00,179
that corporates through voluntary

60
00:02:57,519 --> 00:03:02,680
agreements with each other will drive

61
00:03:00,180 --> 00:03:04,890
practices and behaviors that will

62
00:03:02,680 --> 00:03:12,040
subsequently be codified and formalized

63
00:03:04,890 --> 00:03:15,099
by States and the rest of the talk we'll

64
00:03:12,040 --> 00:03:18,730
look at that in more detail so what I'll

65
00:03:15,099 --> 00:03:20,709
do is just talk about by international

66
00:03:18,730 --> 00:03:24,190
state action and developing cyber norms

67
00:03:20,709 --> 00:03:25,810
is a failed endeavor and I look at the

68
00:03:24,190 --> 00:03:27,280
the current state of fly and run through

69
00:03:25,810 --> 00:03:30,389
some of the challenges that states are

70
00:03:27,280 --> 00:03:33,850
facing I'll then explain why corporate

71
00:03:30,389 --> 00:03:35,709
action is the way forward primarily by

72
00:03:33,850 --> 00:03:38,049
looking at two examples the

73
00:03:35,709 --> 00:03:41,049
cybersecurity tech Accord and the

74
00:03:38,049 --> 00:03:42,819
charter of trust and I'll then draw some

75
00:03:41,049 --> 00:03:44,230
conclusions and run through some of the

76
00:03:42,819 --> 00:03:47,530
practical implications of what that

77
00:03:44,230 --> 00:03:49,840
means and but what I would really like

78
00:03:47,530 --> 00:03:52,389
to get to is leave some space for a

79
00:03:49,840 --> 00:03:55,239
discussion at the end and leave some

80
00:03:52,389 --> 00:03:57,430
space for challenge from all of you at

81
00:03:55,239 --> 00:04:00,750
the end so let's see how my time

82
00:03:57,430 --> 00:04:06,160
management goes for the rest of this and

83
00:04:00,750 --> 00:04:09,459
final few caveats and I started looking

84
00:04:06,160 --> 00:04:10,630
at this I became really intrigued by

85
00:04:09,459 --> 00:04:13,870
this whole discussion about

86
00:04:10,630 --> 00:04:16,570
international cyber norms how they get

87
00:04:13,870 --> 00:04:18,608
derived at and but pretty soon realized

88
00:04:16,570 --> 00:04:20,978
that is pretty mind-bending and pretty

89
00:04:18,608 --> 00:04:23,859
mind-boggling to make sense of it all so

90
00:04:20,978 --> 00:04:25,930
I have taken some mental shortcuts

91
00:04:23,860 --> 00:04:30,250
primarily to keep my head from exploding

92
00:04:25,930 --> 00:04:33,159
and I've also tried and dispensed with

93
00:04:30,250 --> 00:04:36,099
this usual approach of Social Sciences

94
00:04:33,159 --> 00:04:41,729
to kind of be a bit wishy-washy

95
00:04:36,099 --> 00:04:44,380
so I've done made a few more

96
00:04:41,729 --> 00:04:45,609
simplifications and absolute statements

97
00:04:44,380 --> 00:04:48,099
to kind of keep it interesting

98
00:04:45,610 --> 00:04:50,200
and then the final bit is that a lot of

99
00:04:48,099 --> 00:04:53,680
the challenges that I'll talk about

100
00:04:50,200 --> 00:04:56,979
aren't necessarily unique to cyber and

101
00:04:53,680 --> 00:04:59,289
the cyber world and they are challenges

102
00:04:56,979 --> 00:05:03,010
that agreement internationally faces in

103
00:04:59,289 --> 00:05:04,780
other areas as well and but the beauty

104
00:05:03,010 --> 00:05:06,610
of the uniqueness of cyber is that there

105
00:05:04,780 --> 00:05:08,590
is pretty widespread agreement that

106
00:05:06,610 --> 00:05:10,930
something needs to be done at a global

107
00:05:08,590 --> 00:05:13,210
level and due to the fact that it is a

108
00:05:10,930 --> 00:05:16,960
relatively new discipline that's still

109
00:05:13,210 --> 00:05:18,719
evolving we do have flexibility to do

110
00:05:16,960 --> 00:05:22,630
things differently and you know to be

111
00:05:18,719 --> 00:05:25,080
radically creative and to not be bound

112
00:05:22,630 --> 00:05:30,159
and boxed down by legacy systems and

113
00:05:25,080 --> 00:05:37,419
institutions and with that we are ready

114
00:05:30,159 --> 00:05:40,770
to go so and brief spoiler alert at the

115
00:05:37,419 --> 00:05:43,180
very start and the assumption is that

116
00:05:40,770 --> 00:05:45,460
international side action fails because

117
00:05:43,180 --> 00:05:47,530
there is a lack of mutual trust between

118
00:05:45,460 --> 00:05:50,289
actors and because enforcement

119
00:05:47,530 --> 00:05:53,200
mechanisms and effective at an

120
00:05:50,289 --> 00:05:54,909
international level therefore any norms

121
00:05:53,200 --> 00:05:58,360
that can actually we agree cannot be

122
00:05:54,909 --> 00:06:01,030
turned into effective action and but

123
00:05:58,360 --> 00:06:04,330
let's take a look at what all these

124
00:06:01,030 --> 00:06:08,650
norms and cyber norms are actually about

125
00:06:04,330 --> 00:06:11,620
and in very simple terms there is a

126
00:06:08,650 --> 00:06:14,320
general understanding that the future

127
00:06:11,620 --> 00:06:17,889
evolution of digital technologies can be

128
00:06:14,320 --> 00:06:20,500
very very good for mankind but it also

129
00:06:17,889 --> 00:06:23,650
comes with a number of risks so if we

130
00:06:20,500 --> 00:06:27,729
want to capitalize on the benefits we

131
00:06:23,650 --> 00:06:29,710
need an agreement of how to do this as

132
00:06:27,729 --> 00:06:34,180
in cyber as in digital technology

133
00:06:29,710 --> 00:06:34,599
responsibly and we need an agreement of

134
00:06:34,180 --> 00:06:37,060
how

135
00:06:34,600 --> 00:06:40,060
to keep the internet open and peaceful

136
00:06:37,060 --> 00:06:42,490
and secure and accessible for everyone

137
00:06:40,060 --> 00:06:44,710
and we do need that agreement to be

138
00:06:42,490 --> 00:06:46,480
international because don't have to tell

139
00:06:44,710 --> 00:06:48,489
you that cyber transcends borders it

140
00:06:46,480 --> 00:06:52,050
doesn't necessarily respect national

141
00:06:48,490 --> 00:06:55,090
national sovereignty so we need

142
00:06:52,050 --> 00:06:58,360
cross-border agreement on what can and

143
00:06:55,090 --> 00:07:00,510
cannot be done and shared via shared

144
00:06:58,360 --> 00:07:04,600
understanding of what is and what isn't

145
00:07:00,510 --> 00:07:08,950
acceptable in cyberspace and that does

146
00:07:04,600 --> 00:07:12,550
cover a number of things it covers

147
00:07:08,950 --> 00:07:14,740
things like state behaviors agreement on

148
00:07:12,550 --> 00:07:17,980
you know whether stays are able to

149
00:07:14,740 --> 00:07:20,020
develop offensive capabilities when

150
00:07:17,980 --> 00:07:22,270
they're able to deploy them and against

151
00:07:20,020 --> 00:07:24,789
whom under what circumstances can they

152
00:07:22,270 --> 00:07:26,919
spy on each other can they spy on the

153
00:07:24,790 --> 00:07:29,550
respective domestic national champions

154
00:07:26,920 --> 00:07:32,200
you know what are the rules around that

155
00:07:29,550 --> 00:07:34,930
it covers things like intelligence

156
00:07:32,200 --> 00:07:37,120
sharing so how when under what

157
00:07:34,930 --> 00:07:40,140
circumstances do states and

158
00:07:37,120 --> 00:07:42,790
organizations within countries cooperate

159
00:07:40,140 --> 00:07:46,060
it covers things like rules and

160
00:07:42,790 --> 00:07:48,070
regulations so where is their agreement

161
00:07:46,060 --> 00:07:50,230
on what corporis and what citizens are

162
00:07:48,070 --> 00:07:52,450
expected and required to do to

163
00:07:50,230 --> 00:07:55,690
contribute to tackling cyber threats and

164
00:07:52,450 --> 00:07:57,670
it covers things like cybercrime so

165
00:07:55,690 --> 00:07:59,710
whether or not there is agreement on

166
00:07:57,670 --> 00:08:02,500
what cybercrime is in the first place

167
00:07:59,710 --> 00:08:08,049
and how a cyber criminals are deterred

168
00:08:02,500 --> 00:08:11,370
and punished from doing bad things and

169
00:08:08,050 --> 00:08:14,010
there have been numerous attempts of

170
00:08:11,370 --> 00:08:17,590
tackling those questions of finding

171
00:08:14,010 --> 00:08:20,260
agreements and giving you a full list

172
00:08:17,590 --> 00:08:23,080
and a rundown of what's already out

173
00:08:20,260 --> 00:08:25,060
there and would take a very long time

174
00:08:23,080 --> 00:08:26,500
and you would probably fall asleep at

175
00:08:25,060 --> 00:08:29,710
some point which is definitely not what

176
00:08:26,500 --> 00:08:30,850
we want but there are you know take my

177
00:08:29,710 --> 00:08:32,880
word for it there's lots of

178
00:08:30,850 --> 00:08:36,820
international super national or regional

179
00:08:32,880 --> 00:08:39,120
bilateral agreements to tacular and just

180
00:08:36,820 --> 00:08:44,410
to give you a brief illustration of that

181
00:08:39,120 --> 00:08:46,500
and I've stolen a charge from NATO thank

182
00:08:44,410 --> 00:08:50,010
you very much to them for that

183
00:08:46,500 --> 00:08:52,800
they call it the let me just check the

184
00:08:50,010 --> 00:08:55,410
notes the Venn diagram of international

185
00:08:52,800 --> 00:08:58,949
organizations working together for peace

186
00:08:55,410 --> 00:09:01,829
and security sounds pretty good see that

187
00:08:58,950 --> 00:09:04,440
on the left-hand side of the slide and

188
00:09:01,830 --> 00:09:07,200
that's already pretty complex and the

189
00:09:04,440 --> 00:09:09,840
overlapping memberships and the

190
00:09:07,200 --> 00:09:11,820
different but sort of similar objectives

191
00:09:09,840 --> 00:09:13,830
that all those organizations have set

192
00:09:11,820 --> 00:09:18,390
for themselves on the right-hand side

193
00:09:13,830 --> 00:09:21,030
you then have in the colored boxes the

194
00:09:18,390 --> 00:09:23,699
cyber related agreements that those

195
00:09:21,030 --> 00:09:27,480
international organizations have come up

196
00:09:23,700 --> 00:09:31,620
with and then in the gray boxes you have

197
00:09:27,480 --> 00:09:33,750
the overlaying other additional treaties

198
00:09:31,620 --> 00:09:37,070
and declarations and commitments what

199
00:09:33,750 --> 00:09:39,660
have you that all purport to cover

200
00:09:37,070 --> 00:09:42,200
global cyber norms and agreement on

201
00:09:39,660 --> 00:09:47,069
what's what's what and what needs doing

202
00:09:42,200 --> 00:09:50,250
and now the UN have been looking at this

203
00:09:47,070 --> 00:09:54,210
for the past 20 years that's just one

204
00:09:50,250 --> 00:09:59,040
body that's considered this for two

205
00:09:54,210 --> 00:10:02,360
decades and we are presented with this

206
00:09:59,040 --> 00:10:05,400
rather jungle madness thing of

207
00:10:02,360 --> 00:10:08,340
overlaying and complex agreements

208
00:10:05,400 --> 00:10:11,310
because no one's ever bothered today to

209
00:10:08,340 --> 00:10:13,650
look at whether they are working both

210
00:10:11,310 --> 00:10:16,319
effects reiative to date because you

211
00:10:13,650 --> 00:10:18,569
know cyber is a really tricky complex

212
00:10:16,320 --> 00:10:21,120
global thing that needs tackling so the

213
00:10:18,570 --> 00:10:23,790
easiest thing to do is for people to sit

214
00:10:21,120 --> 00:10:26,130
down write high-level commitments and

215
00:10:23,790 --> 00:10:29,069
just you know build that cake layer of

216
00:10:26,130 --> 00:10:32,839
one thing after the other wishes you

217
00:10:29,070 --> 00:10:35,790
know what we see at the moment um but

218
00:10:32,839 --> 00:10:37,140
let's pause for a moment and look at

219
00:10:35,790 --> 00:10:40,170
what they've actually committed to doing

220
00:10:37,140 --> 00:10:41,880
and so of reading through the various

221
00:10:40,170 --> 00:10:43,829
agreements I was actually quite

222
00:10:41,880 --> 00:10:46,980
surprised to see that there is a level

223
00:10:43,830 --> 00:10:48,960
of consensus across all of them as to

224
00:10:46,980 --> 00:10:53,430
what the high level principles of

225
00:10:48,960 --> 00:10:56,940
agreement should be so what they have

226
00:10:53,430 --> 00:10:59,189
arrived at after 20 years of discussion

227
00:10:56,940 --> 00:11:03,810
and very painful leg

228
00:10:59,190 --> 00:11:08,120
the ways is that for one international

229
00:11:03,810 --> 00:11:12,709
law should be applied in cyberspace

230
00:11:08,120 --> 00:11:15,480
states should not necessarily support

231
00:11:12,710 --> 00:11:17,370
intentional damage to systems and

232
00:11:15,480 --> 00:11:20,910
infrastructure and should prevent harm

233
00:11:17,370 --> 00:11:24,570
to people pretty easy to sign up to on

234
00:11:20,910 --> 00:11:27,420
paper there is a level of agreement that

235
00:11:24,570 --> 00:11:30,210
states should have the right to develop

236
00:11:27,420 --> 00:11:32,670
operational cyber capabilities could

237
00:11:30,210 --> 00:11:36,120
argue is a bit similar to the mutually

238
00:11:32,670 --> 00:11:39,439
assured destruction principle there is

239
00:11:36,120 --> 00:11:42,300
commitment to organizations states

240
00:11:39,440 --> 00:11:44,360
institutions working together to share

241
00:11:42,300 --> 00:11:47,069
information and work in partnership

242
00:11:44,360 --> 00:11:49,200
there is lots of support for this

243
00:11:47,070 --> 00:11:51,150
fantastic concept of cyber

244
00:11:49,200 --> 00:11:53,190
capacity-building particularly for those

245
00:11:51,150 --> 00:11:56,189
countries that are currently lagging

246
00:11:53,190 --> 00:11:57,960
behind a bit there is lots of support

247
00:11:56,190 --> 00:12:01,020
for this relatively new phenomenon of

248
00:11:57,960 --> 00:12:04,590
secured by design and there's lots of

249
00:12:01,020 --> 00:12:07,470
support and agreement on the principle

250
00:12:04,590 --> 00:12:10,440
of you know coordinated vulnerability

251
00:12:07,470 --> 00:12:11,970
disclosure I mean any sort of thing well

252
00:12:10,440 --> 00:12:14,100
that's that's you know pretty good

253
00:12:11,970 --> 00:12:17,580
there's consensus happy days what's the

254
00:12:14,100 --> 00:12:21,150
problem the problem is that a lot of

255
00:12:17,580 --> 00:12:24,600
these principles are just that there are

256
00:12:21,150 --> 00:12:27,660
principles they are very high level and

257
00:12:24,600 --> 00:12:30,420
there aren't really any detailed

258
00:12:27,660 --> 00:12:33,300
implementation plans of how those

259
00:12:30,420 --> 00:12:36,420
principles are applied and implemented

260
00:12:33,300 --> 00:12:40,229
and turned into concrete action on the

261
00:12:36,420 --> 00:12:42,810
ground and I was of trying to find a

262
00:12:40,230 --> 00:12:46,350
good analogy and kind of come up with

263
00:12:42,810 --> 00:12:48,719
this so bear with me it's a bit like

264
00:12:46,350 --> 00:12:51,960
sitting down with a group of friends and

265
00:12:48,720 --> 00:12:53,930
you go all a bit hungry should we should

266
00:12:51,960 --> 00:12:57,210
we go for dinner and people go yeah

267
00:12:53,930 --> 00:13:00,060
awesome really Nadia let's do that when

268
00:12:57,210 --> 00:13:02,370
you go cool consensus should we go now

269
00:13:00,060 --> 00:13:03,420
and someone will go would give me that

270
00:13:02,370 --> 00:13:05,670
it's 12:30

271
00:13:03,420 --> 00:13:08,370
surely dinner isn't until 7:00 and

272
00:13:05,670 --> 00:13:10,510
someone else will go no no that's tea

273
00:13:08,370 --> 00:13:13,840
dinner is at lunchtime

274
00:13:10,510 --> 00:13:15,100
and you know the interpretation or the

275
00:13:13,840 --> 00:13:16,300
lack of agreement or what's the

276
00:13:15,100 --> 00:13:18,760
interpretation of what you've actually

277
00:13:16,300 --> 00:13:20,829
just agreed to and is a good example and

278
00:13:18,760 --> 00:13:23,290
that's before you even start going into

279
00:13:20,830 --> 00:13:27,070
the whole okay let's have dinner I want

280
00:13:23,290 --> 00:13:30,250
pizza I want I I am vegan I don't really

281
00:13:27,070 --> 00:13:33,040
eat fish and also going over there as a

282
00:13:30,250 --> 00:13:37,690
way too far to walk so you know that

283
00:13:33,040 --> 00:13:42,000
really brings us to the core of the

284
00:13:37,690 --> 00:13:46,000
challenges that are being faced so I

285
00:13:42,000 --> 00:13:48,640
would argue that for cyber norms to be

286
00:13:46,000 --> 00:13:53,140
agreed and then subsequently turned into

287
00:13:48,640 --> 00:13:55,980
concrete action there are two success

288
00:13:53,140 --> 00:13:59,680
factors that need to be fulfilled one is

289
00:13:55,980 --> 00:14:02,050
Ken States find international agreement

290
00:13:59,680 --> 00:14:05,709
on what those norms should actually be

291
00:14:02,050 --> 00:14:11,170
and the answer to that question is a bit

292
00:14:05,710 --> 00:14:14,710
ish so you know there is high-level

293
00:14:11,170 --> 00:14:16,420
agreement on what spot but that only

294
00:14:14,710 --> 00:14:19,030
really holds up so long as you don't

295
00:14:16,420 --> 00:14:23,459
look under the bonnet in a lot of detail

296
00:14:19,030 --> 00:14:26,439
we do know that things like the 2017 UN

297
00:14:23,460 --> 00:14:28,450
group of governmental experts failed to

298
00:14:26,440 --> 00:14:31,450
reach consensus and what the norm should

299
00:14:28,450 --> 00:14:34,000
be we know that the process is starting

300
00:14:31,450 --> 00:14:36,820
up again except it's not a single

301
00:14:34,000 --> 00:14:39,460
process but it's two processes running

302
00:14:36,820 --> 00:14:41,650
concurrently one proposed by Russia one

303
00:14:39,460 --> 00:14:44,170
proposed by the u.s. because they aren't

304
00:14:41,650 --> 00:14:46,180
even able to agree at UN level how they

305
00:14:44,170 --> 00:14:47,890
should structure their discussion about

306
00:14:46,180 --> 00:14:51,250
what the norm should be never mind the

307
00:14:47,890 --> 00:14:54,880
outcome of the actual discussions so you

308
00:14:51,250 --> 00:14:59,080
know that's that the second question is

309
00:14:54,880 --> 00:15:02,260
whether where there is agreement on

310
00:14:59,080 --> 00:15:03,970
norms that can be turned into reality

311
00:15:02,260 --> 00:15:08,410
can be turn into action on the ground

312
00:15:03,970 --> 00:15:11,440
and and I'd argue that the answer to

313
00:15:08,410 --> 00:15:13,780
that is not really at the moment because

314
00:15:11,440 --> 00:15:18,370
that depends on two factors one is

315
00:15:13,780 --> 00:15:21,730
either a shared willingness of states to

316
00:15:18,370 --> 00:15:24,370
agree what to do in their implementation

317
00:15:21,730 --> 00:15:28,720
plans that ultimately depends

318
00:15:24,370 --> 00:15:30,279
on mutual trust between them which is a

319
00:15:28,720 --> 00:15:32,350
sort of we all agree this is the right

320
00:15:30,279 --> 00:15:34,390
thing to do let's just get on with it or

321
00:15:32,350 --> 00:15:37,810
it depends on effective enforcement

322
00:15:34,390 --> 00:15:39,370
mechanisms which is the sort of let's

323
00:15:37,810 --> 00:15:40,989
all just do it because we really don't

324
00:15:39,370 --> 00:15:46,210
like the consequences or what will

325
00:15:40,990 --> 00:15:50,230
happen if we don't do politics instances

326
00:15:46,210 --> 00:15:52,900
of technological protectionism really

327
00:15:50,230 --> 00:15:54,910
hamper that mutual trust element so

328
00:15:52,900 --> 00:15:58,930
states have very diverse and very

329
00:15:54,910 --> 00:16:01,930
diverging interests in cyberspace and

330
00:15:58,930 --> 00:16:03,819
that really does make it very difficult

331
00:16:01,930 --> 00:16:05,290
for them to develop that shared

332
00:16:03,820 --> 00:16:07,270
willingness in that shared basis of

333
00:16:05,290 --> 00:16:09,000
trust and so they might agree on the

334
00:16:07,270 --> 00:16:11,589
high level principle of say

335
00:16:09,000 --> 00:16:13,660
vulnerability disclosure until they

336
00:16:11,589 --> 00:16:15,430
realize so they can actually use some of

337
00:16:13,660 --> 00:16:20,260
these against each other or until they

338
00:16:15,430 --> 00:16:23,439
realize that not disclosing something

339
00:16:20,260 --> 00:16:25,689
might you know make a neighbor ever so

340
00:16:23,440 --> 00:16:29,529
slightly more vulnerable to attack than

341
00:16:25,690 --> 00:16:30,910
themselves they might agree on the high

342
00:16:29,529 --> 00:16:33,360
level principle of international

343
00:16:30,910 --> 00:16:36,279
cooperation and sharing information

344
00:16:33,360 --> 00:16:39,220
until they read around the table and

345
00:16:36,279 --> 00:16:41,050
there is a bit of the I show you mine if

346
00:16:39,220 --> 00:16:46,300
you show me yours and no one really

347
00:16:41,050 --> 00:16:47,949
agrees um enforcement mechanisms and

348
00:16:46,300 --> 00:16:50,859
international relations and

349
00:16:47,950 --> 00:16:55,060
international law are notoriously tricky

350
00:16:50,860 --> 00:16:57,790
because there is no single law

351
00:16:55,060 --> 00:17:00,849
enforcement power no single judiciary to

352
00:16:57,790 --> 00:17:03,699
take on that role of enforcement which

353
00:17:00,850 --> 00:17:07,120
means that ultimately depends on States

354
00:17:03,700 --> 00:17:09,329
receptiveness to the alternative

355
00:17:07,119 --> 00:17:12,579
enforcement mechanism so sanctions

356
00:17:09,329 --> 00:17:15,099
international condemnation any other

357
00:17:12,579 --> 00:17:17,678
diplomatic tools and that doesn't really

358
00:17:15,099 --> 00:17:20,948
work when you have countries like China

359
00:17:17,679 --> 00:17:25,420
and Russia who quite frankly speaking

360
00:17:20,949 --> 00:17:28,929
don't give a and so neither of

361
00:17:25,420 --> 00:17:31,679
those two ways of having clear actions

362
00:17:28,929 --> 00:17:34,090
derived from norms are really working

363
00:17:31,679 --> 00:17:35,540
where nation-states in their

364
00:17:34,090 --> 00:17:39,679
international

365
00:17:35,540 --> 00:17:43,370
channels are in the driving seat so in

366
00:17:39,680 --> 00:17:46,790
turn let's look why cross-border

367
00:17:43,370 --> 00:17:50,870
corporate action offers a way forward

368
00:17:46,790 --> 00:17:53,480
and the main rationale there is that

369
00:17:50,870 --> 00:17:56,449
corporates are driven by very different

370
00:17:53,480 --> 00:18:00,110
incentives and that those incentives

371
00:17:56,450 --> 00:18:04,340
work to encourage them to use their

372
00:18:00,110 --> 00:18:06,409
power and their capabilities to actually

373
00:18:04,340 --> 00:18:08,629
do things rather than just talk about

374
00:18:06,410 --> 00:18:12,230
them and I know at this point you're

375
00:18:08,630 --> 00:18:14,030
going really corporate we can't even get

376
00:18:12,230 --> 00:18:16,070
them to do patching properly that alone

377
00:18:14,030 --> 00:18:20,060
developed international cyber norms and

378
00:18:16,070 --> 00:18:22,370
action implementation plans but there

379
00:18:20,060 --> 00:18:24,649
are three different motivations for

380
00:18:22,370 --> 00:18:29,959
corporates to do this that kind of come

381
00:18:24,650 --> 00:18:34,640
together in that space and one is pure

382
00:18:29,960 --> 00:18:36,860
self-interest commercial interest above

383
00:18:34,640 --> 00:18:38,720
anything else and that's to do with the

384
00:18:36,860 --> 00:18:41,360
fact that a lot of the technologies and

385
00:18:38,720 --> 00:18:44,570
systems that are persistently under

386
00:18:41,360 --> 00:18:47,810
cyberattack are owned and operated and

387
00:18:44,570 --> 00:18:50,899
want to be sold by the private sector

388
00:18:47,810 --> 00:18:52,870
so securing them and making them more

389
00:18:50,900 --> 00:18:55,640
secure is good for the bottom line

390
00:18:52,870 --> 00:18:58,280
because you know damage is costly and

391
00:18:55,640 --> 00:19:03,190
damage consumer trust means people won't

392
00:18:58,280 --> 00:19:07,370
buy stuff so we really get to a point

393
00:19:03,190 --> 00:19:09,170
where a more secure cyberspace offers a

394
00:19:07,370 --> 00:19:12,679
better operating environment for

395
00:19:09,170 --> 00:19:15,920
corporates and corporates also often

396
00:19:12,680 --> 00:19:18,530
operate across borders which means

397
00:19:15,920 --> 00:19:21,890
having fifteen different regulatory

398
00:19:18,530 --> 00:19:24,889
regimes to comply with is pretty costly

399
00:19:21,890 --> 00:19:26,660
so having a harmonized approach which

400
00:19:24,890 --> 00:19:29,780
means they can do one thing and that's

401
00:19:26,660 --> 00:19:33,170
globally applicable is a lot cheaper so

402
00:19:29,780 --> 00:19:34,910
agreement on what a more cyber more

403
00:19:33,170 --> 00:19:37,240
secure cyberspace entails and practice

404
00:19:34,910 --> 00:19:41,000
is also a cheaper operating environment

405
00:19:37,240 --> 00:19:46,060
the second motivation a second element

406
00:19:41,000 --> 00:19:48,050
is this small but growing trend of a

407
00:19:46,060 --> 00:19:51,379
moral purpose

408
00:19:48,050 --> 00:19:54,139
so global corporates are increasingly

409
00:19:51,380 --> 00:19:56,240
waking up to the fact that a pure focus

410
00:19:54,140 --> 00:20:00,470
on shareholder interest is not

411
00:19:56,240 --> 00:20:04,430
necessarily the right thing to do and so

412
00:20:00,470 --> 00:20:06,590
they are embracing slowly but are

413
00:20:04,430 --> 00:20:09,680
embracing their responsibility in

414
00:20:06,590 --> 00:20:11,199
helping to tackle global challenges and

415
00:20:09,680 --> 00:20:13,730
there's normally focus on social

416
00:20:11,200 --> 00:20:16,160
injustice and inequality and climate

417
00:20:13,730 --> 00:20:18,800
change in the environment but you know

418
00:20:16,160 --> 00:20:22,970
that's not to say that a secure

419
00:20:18,800 --> 00:20:25,040
cyberspace can't be part of that and so

420
00:20:22,970 --> 00:20:29,120
corporates are embracing or want to

421
00:20:25,040 --> 00:20:30,379
embrace the sort of aligning their

422
00:20:29,120 --> 00:20:34,070
corporate mission and using their

423
00:20:30,380 --> 00:20:37,190
resources and skills with what the world

424
00:20:34,070 --> 00:20:40,189
needs and linked to that is the third

425
00:20:37,190 --> 00:20:43,100
element wishes opportunity which is the

426
00:20:40,190 --> 00:20:46,640
current vacuum left by States and

427
00:20:43,100 --> 00:20:48,860
ability to do things and the recognition

428
00:20:46,640 --> 00:20:50,510
that cyber is a shared space the

429
00:20:48,860 --> 00:20:51,979
increasing recognition by governments

430
00:20:50,510 --> 00:20:54,920
said there is a role for corporates to

431
00:20:51,980 --> 00:20:57,200
play so there is really is an open

432
00:20:54,920 --> 00:21:02,320
invitation for the corporate world to

433
00:20:57,200 --> 00:21:07,280
step in and do the right thing and so

434
00:21:02,320 --> 00:21:10,280
that said we know that there are at

435
00:21:07,280 --> 00:21:12,920
least two corporates that sort of have

436
00:21:10,280 --> 00:21:14,540
taken up that invitation and thought

437
00:21:12,920 --> 00:21:18,470
yeah let's do what we can do in that

438
00:21:14,540 --> 00:21:23,240
space and we've got the cybersecurity

439
00:21:18,470 --> 00:21:25,790
tech accord and that is initiated and

440
00:21:23,240 --> 00:21:27,920
led by Microsoft and we've got the

441
00:21:25,790 --> 00:21:33,440
charter of trust that's been initiated

442
00:21:27,920 --> 00:21:38,570
it's being led by Siemens and what I've

443
00:21:33,440 --> 00:21:45,020
done is looked at the how the why the

444
00:21:38,570 --> 00:21:47,960
what of those initiatives and they were

445
00:21:45,020 --> 00:21:51,830
both announced in the early months of

446
00:21:47,960 --> 00:21:55,550
2018 so they've been in operation for

447
00:21:51,830 --> 00:21:58,250
just a little over a year and the

448
00:21:55,550 --> 00:22:00,960
corporates that are leading them are you

449
00:21:58,250 --> 00:22:05,019
know global conglomerate

450
00:22:00,960 --> 00:22:07,330
arguably with a clear interest in the

451
00:22:05,019 --> 00:22:11,590
technology space in the future evolution

452
00:22:07,330 --> 00:22:14,559
of digital technology and they both used

453
00:22:11,590 --> 00:22:17,559
pretty well-known security for to

454
00:22:14,559 --> 00:22:19,570
announce what they were doing and so

455
00:22:17,559 --> 00:22:22,690
increasing the visibility and the reach

456
00:22:19,570 --> 00:22:25,090
of their action and yes you know wanting

457
00:22:22,690 --> 00:22:30,779
a bit of kudos for for what they were up

458
00:22:25,090 --> 00:22:33,820
to but they both very keenly emphasized

459
00:22:30,779 --> 00:22:35,739
the broader industry involvement of what

460
00:22:33,820 --> 00:22:37,840
they're trying to do so you know you've

461
00:22:35,739 --> 00:22:39,659
got standalone logos you've got a

462
00:22:37,840 --> 00:22:42,609
standalone websites you can stand alone

463
00:22:39,659 --> 00:22:47,369
documentation so very keen that these

464
00:22:42,609 --> 00:22:52,090
are initiatives in their own right and

465
00:22:47,369 --> 00:22:54,639
they both have a level of public

466
00:22:52,090 --> 00:22:57,129
accountability to an extent and that

467
00:22:54,639 --> 00:23:02,049
they publish publicly available reports

468
00:22:57,129 --> 00:23:03,639
readable by anyone to demonstrate what

469
00:23:02,049 --> 00:23:05,369
they've been up to what they have

470
00:23:03,639 --> 00:23:08,109
achieved what outcomes they have

471
00:23:05,369 --> 00:23:11,529
delivered and they both follow this

472
00:23:08,109 --> 00:23:13,869
model of having high-level values or

473
00:23:11,529 --> 00:23:17,109
high-level principles that the

474
00:23:13,869 --> 00:23:19,238
signatories commit to but then contrary

475
00:23:17,109 --> 00:23:21,220
perhaps to what's happening on the

476
00:23:19,239 --> 00:23:25,090
international state level there is

477
00:23:21,220 --> 00:23:28,239
ongoing dialogue and meetings and action

478
00:23:25,090 --> 00:23:29,799
plans and agreements that try and take

479
00:23:28,239 --> 00:23:33,159
those principles and turn them into

480
00:23:29,799 --> 00:23:36,609
action and so far they have delivered

481
00:23:33,159 --> 00:23:39,999
outcomes and that the the tech accord

482
00:23:36,609 --> 00:23:41,379
have committed their secretaries to

483
00:23:39,999 --> 00:23:44,230
publish vulnerability disclosure

484
00:23:41,379 --> 00:23:47,259
policies by the end of the year and the

485
00:23:44,230 --> 00:23:51,279
charter of trust have developed a set of

486
00:23:47,259 --> 00:23:52,840
17 supply chain security requirements

487
00:23:51,279 --> 00:23:55,480
that all the signatories have committed

488
00:23:52,840 --> 00:23:57,939
to forcing on they're requiring their

489
00:23:55,480 --> 00:24:00,460
supply chain to adhere to so there are

490
00:23:57,940 --> 00:24:03,700
tangible outcomes that those initiatives

491
00:24:00,460 --> 00:24:06,879
have delivered to date and the

492
00:24:03,700 --> 00:24:11,559
difference between the tech Accord and

493
00:24:06,879 --> 00:24:14,110
the Tartar of trust is predominantly in

494
00:24:11,559 --> 00:24:16,360
there there

495
00:24:14,110 --> 00:24:18,729
shanell for being and the ultimate end

496
00:24:16,360 --> 00:24:23,439
state that they're working towards so

497
00:24:18,730 --> 00:24:26,049
the tech account tech a quart rather in

498
00:24:23,440 --> 00:24:28,540
the face of it aims to create a secure

499
00:24:26,049 --> 00:24:30,790
online environment because all the

500
00:24:28,540 --> 00:24:32,678
secretaries recognize that they have a

501
00:24:30,790 --> 00:24:35,530
responsibility to make that happens a

502
00:24:32,679 --> 00:24:39,490
very much plays into the the altruistic

503
00:24:35,530 --> 00:24:41,889
the moral purpose motivation that I

504
00:24:39,490 --> 00:24:45,790
talked about previously the charter of

505
00:24:41,890 --> 00:24:48,160
trust on the other hand focuses on

506
00:24:45,790 --> 00:24:50,320
creating the right conditions for

507
00:24:48,160 --> 00:24:53,049
broader adoption of digital technologies

508
00:24:50,320 --> 00:24:56,139
that's predominantly a commercially

509
00:24:53,049 --> 00:25:02,470
driven rationale which plays into the

510
00:24:56,140 --> 00:25:05,290
self-interest motivation the tech accord

511
00:25:02,470 --> 00:25:08,260
in their principles and their actions

512
00:25:05,290 --> 00:25:12,159
are focused on what the secretaries

513
00:25:08,260 --> 00:25:15,280
themselves as corporates can do and they

514
00:25:12,160 --> 00:25:17,890
position themselves very clearly visa

515
00:25:15,280 --> 00:25:20,559
vie government's and sort of saying we

516
00:25:17,890 --> 00:25:23,559
as corporates will not support offensive

517
00:25:20,559 --> 00:25:27,960
operations led by States and they have

518
00:25:23,559 --> 00:25:31,629
remained an exclusively corporate forum

519
00:25:27,960 --> 00:25:34,690
the charter of trust while initially

520
00:25:31,630 --> 00:25:38,160
focused on the corporate measures that

521
00:25:34,690 --> 00:25:41,080
they can do have as their ultimate aim

522
00:25:38,160 --> 00:25:44,650
the achievement of binding rules and

523
00:25:41,080 --> 00:25:47,470
regulations set by States which also

524
00:25:44,650 --> 00:25:49,090
explains why their membership structure

525
00:25:47,470 --> 00:25:50,710
is slightly different and that they have

526
00:25:49,090 --> 00:25:55,080
this associate membership model which

527
00:25:50,710 --> 00:25:59,830
allows them to work very closely with

528
00:25:55,080 --> 00:26:02,678
state and regulatory authorities and so

529
00:25:59,830 --> 00:26:04,330
what we can see is that you know we have

530
00:26:02,679 --> 00:26:08,320
similar approaches across those

531
00:26:04,330 --> 00:26:10,149
corporate initiatives but they do offer

532
00:26:08,320 --> 00:26:13,270
a slightly different model slightly

533
00:26:10,150 --> 00:26:16,260
different ways of going about things on

534
00:26:13,270 --> 00:26:19,360
the whole though what we see is that

535
00:26:16,260 --> 00:26:22,120
corporate and corporate initiatives

536
00:26:19,360 --> 00:26:24,649
arguably are better at doing things that

537
00:26:22,120 --> 00:26:28,540
stage struggle to do

538
00:26:24,650 --> 00:26:31,310
so their endeavor or their motivation to

539
00:26:28,540 --> 00:26:33,740
tackle security risks of digital

540
00:26:31,310 --> 00:26:36,500
technology offers a shared driver and

541
00:26:33,740 --> 00:26:38,690
the fact that their collaboration their

542
00:26:36,500 --> 00:26:41,570
ability to agree is completely voluntary

543
00:26:38,690 --> 00:26:44,890
no one's forcing them so they've come

544
00:26:41,570 --> 00:26:48,139
together and with a shared purpose which

545
00:26:44,890 --> 00:26:50,480
provides pretty fertile ground for

546
00:26:48,140 --> 00:26:52,820
outcome driven discussion an outcome

547
00:26:50,480 --> 00:26:55,010
driven objectives because at the end of

548
00:26:52,820 --> 00:26:57,649
the day you know they're all busy people

549
00:26:55,010 --> 00:26:59,450
so they don't really like wasting time

550
00:26:57,650 --> 00:27:02,630
and talking shelves without anything

551
00:26:59,450 --> 00:27:05,270
coming out of this and they have shown

552
00:27:02,630 --> 00:27:07,400
that they can deliver outcomes in a

553
00:27:05,270 --> 00:27:09,740
relatively short time friends who think

554
00:27:07,400 --> 00:27:12,080
that the UN process as currently

555
00:27:09,740 --> 00:27:14,270
starting is taking between two and three

556
00:27:12,080 --> 00:27:17,120
years to just arrive at a high-level

557
00:27:14,270 --> 00:27:19,280
declaration they've come up with action

558
00:27:17,120 --> 00:27:20,840
plans in just a little over a year so

559
00:27:19,280 --> 00:27:26,750
the timeframes are a lot quicker

560
00:27:20,840 --> 00:27:29,300
um but don't want to stand here and you

561
00:27:26,750 --> 00:27:33,860
know hail the corporate there are risks

562
00:27:29,300 --> 00:27:36,860
and shortcomings still and one of them

563
00:27:33,860 --> 00:27:39,459
is that well

564
00:27:36,860 --> 00:27:42,229
the signatories to both initiatives are

565
00:27:39,460 --> 00:27:46,000
globally active and globally operating

566
00:27:42,230 --> 00:27:49,730
they are still pretty Western dominated

567
00:27:46,000 --> 00:27:52,790
Microsoft is a US company Siemens is a

568
00:27:49,730 --> 00:27:55,580
German company European footprint

569
00:27:52,790 --> 00:27:58,639
European heritage you don't see many

570
00:27:55,580 --> 00:28:02,030
Russian or Chinese companies so in that

571
00:27:58,640 --> 00:28:04,520
sense it's not really that massive step

572
00:28:02,030 --> 00:28:06,590
up from what states are able to do in

573
00:28:04,520 --> 00:28:08,570
terms of in their regional groupings

574
00:28:06,590 --> 00:28:11,120
with like-minded people they're able to

575
00:28:08,570 --> 00:28:14,810
arrive at conclusions arrival agreement

576
00:28:11,120 --> 00:28:17,169
and much more quickly but I would say

577
00:28:14,810 --> 00:28:19,909
that market drivers and market

578
00:28:17,170 --> 00:28:24,200
independencies make it easier for those

579
00:28:19,910 --> 00:28:29,000
global corporates to attack or tackle

580
00:28:24,200 --> 00:28:30,860
those regional dominance issues in an

581
00:28:29,000 --> 00:28:33,650
easier way than it is for geopolitical

582
00:28:30,860 --> 00:28:39,050
entrenchments to be overcome by national

583
00:28:33,650 --> 00:28:41,030
governments discuss and then the second

584
00:28:39,050 --> 00:28:45,260
shortcoming the second limitation is

585
00:28:41,030 --> 00:28:48,950
that of democratic legitimacy so at no

586
00:28:45,260 --> 00:28:53,330
point I think do we want to get to a

587
00:28:48,950 --> 00:28:55,610
situation where unelected effectively

588
00:28:53,330 --> 00:28:57,590
unaccountable corporates are writing

589
00:28:55,610 --> 00:29:01,189
rules that everyone else has to agree

590
00:28:57,590 --> 00:29:03,260
with and in fairness the initiatives

591
00:29:01,190 --> 00:29:05,690
themselves recognize that in their

592
00:29:03,260 --> 00:29:07,340
working with governments in they're

593
00:29:05,690 --> 00:29:09,710
trying to sit together and work out

594
00:29:07,340 --> 00:29:12,439
where governments need to step in to do

595
00:29:09,710 --> 00:29:14,330
certain things and that will ultimately

596
00:29:12,440 --> 00:29:17,630
also be required because there is a

597
00:29:14,330 --> 00:29:22,370
subset of cyber norms aspects that

598
00:29:17,630 --> 00:29:24,110
corporates can tackle they can set the

599
00:29:22,370 --> 00:29:26,449
rules for what responsible state

600
00:29:24,110 --> 00:29:30,050
behavior looks like in cyberspace but

601
00:29:26,450 --> 00:29:31,700
their implementation of corporate

602
00:29:30,050 --> 00:29:33,590
practices and actions can set the

603
00:29:31,700 --> 00:29:36,980
framework and can set the parameters

604
00:29:33,590 --> 00:29:38,780
that ultimately facilitate the level of

605
00:29:36,980 --> 00:29:45,440
state discussions happening around that

606
00:29:38,780 --> 00:29:47,210
um so in order for us to you know have

607
00:29:45,440 --> 00:29:49,610
the possibility and the ability to have

608
00:29:47,210 --> 00:29:52,490
a discussion about all this I'll sort of

609
00:29:49,610 --> 00:29:55,120
swiftly move on draw some conclusions

610
00:29:52,490 --> 00:30:00,679
talk about some of the practical

611
00:29:55,120 --> 00:30:03,260
implementations so as we've seen States

612
00:30:00,679 --> 00:30:06,470
will struggle to green arms and will

613
00:30:03,260 --> 00:30:09,980
struggle to turn those norms into

614
00:30:06,470 --> 00:30:14,090
actions and the corporate world is much

615
00:30:09,980 --> 00:30:17,030
better at that for a variety of reasons

616
00:30:14,090 --> 00:30:21,110
but corporate action in and of itself

617
00:30:17,030 --> 00:30:23,149
isn't sufficient either to tackle the

618
00:30:21,110 --> 00:30:28,550
big issue of developing global cyber

619
00:30:23,150 --> 00:30:31,370
norms turning them into action so what

620
00:30:28,550 --> 00:30:34,399
we need really is a model of true

621
00:30:31,370 --> 00:30:37,550
collaboration between States and

622
00:30:34,400 --> 00:30:44,420
governments and the private sector and

623
00:30:37,550 --> 00:30:48,290
the corporate world what does that mean

624
00:30:44,420 --> 00:30:52,200
practically and what we need to make

625
00:30:48,290 --> 00:30:55,049
this true collaborative model work

626
00:30:52,200 --> 00:30:58,139
is a rethink of the traditional roles

627
00:30:55,049 --> 00:31:00,960
and responsibilities and I'll just pick

628
00:30:58,139 --> 00:31:05,370
up this theme of radical creativity that

629
00:31:00,960 --> 00:31:08,279
I talked about at the start there are

630
00:31:05,370 --> 00:31:11,399
three groups of actors the three groups

631
00:31:08,279 --> 00:31:14,000
of stakeholders that in a way need to

632
00:31:11,399 --> 00:31:17,330
have a good hard look at themselves and

633
00:31:14,000 --> 00:31:19,710
do things differently and that's

634
00:31:17,330 --> 00:31:23,850
governments themselves that's corporate

635
00:31:19,710 --> 00:31:28,139
actors and that's you and me and people

636
00:31:23,850 --> 00:31:31,408
like us and so what governments really

637
00:31:28,139 --> 00:31:33,928
need to do is to accept the private

638
00:31:31,409 --> 00:31:37,889
sector and accept the corporate world as

639
00:31:33,929 --> 00:31:40,710
a true collaborative partner not an

640
00:31:37,889 --> 00:31:42,629
adversary not exclusively regulated

641
00:31:40,710 --> 00:31:45,210
entities but they need to create

642
00:31:42,630 --> 00:31:47,940
institutional mechanisms to give

643
00:31:45,210 --> 00:31:52,769
corporate actors a seat at the table as

644
00:31:47,940 --> 00:31:56,970
those discussions are being had and how

645
00:31:52,769 --> 00:32:00,059
they do that can vary so there is an

646
00:31:56,970 --> 00:32:06,299
option for governments to create a legal

647
00:32:00,059 --> 00:32:08,639
duty to force corporations force the

648
00:32:06,299 --> 00:32:10,080
corporate world to embrace their moral

649
00:32:08,639 --> 00:32:11,959
purpose and embrace their moral

650
00:32:10,080 --> 00:32:15,269
obligations there is a way of

651
00:32:11,960 --> 00:32:17,429
incentivizing that in other words of

652
00:32:15,269 --> 00:32:21,049
rewarding corporations to do that

653
00:32:17,429 --> 00:32:25,440
voluntarily either through tax breaks or

654
00:32:21,049 --> 00:32:30,539
investment support or grace periods for

655
00:32:25,440 --> 00:32:33,080
compliance or something there is an

656
00:32:30,539 --> 00:32:36,629
argument to be made that in regular

657
00:32:33,080 --> 00:32:39,720
instances states and governments should

658
00:32:36,630 --> 00:32:42,480
look at where corporate practice has got

659
00:32:39,720 --> 00:32:45,029
to and almost do a gap analysis and see

660
00:32:42,480 --> 00:32:47,279
where corporate action is ahead of where

661
00:32:45,029 --> 00:32:49,320
the norms discussion are at and there

662
00:32:47,279 --> 00:32:51,240
might even be a political commitment to

663
00:32:49,320 --> 00:32:53,668
then sit down and codify and formalize

664
00:32:51,240 --> 00:32:59,490
was already out there in terms of the

665
00:32:53,669 --> 00:33:01,679
norms development and there could be a

666
00:32:59,490 --> 00:33:03,810
mechanism of having you know formal

667
00:33:01,679 --> 00:33:07,400
memorandum of understanding

668
00:33:03,810 --> 00:33:10,040
or partnership frameworks but it's all

669
00:33:07,400 --> 00:33:13,080
sort of predisposing and the fact that

670
00:33:10,040 --> 00:33:15,389
corporates have a legitimate and

671
00:33:13,080 --> 00:33:18,780
accepted place at the table

672
00:33:15,390 --> 00:33:21,090
in turn the corporate world needs to

673
00:33:18,780 --> 00:33:26,580
show that they are actually deserving of

674
00:33:21,090 --> 00:33:29,730
that well and that means embracing their

675
00:33:26,580 --> 00:33:32,939
moral responsibility that means

676
00:33:29,730 --> 00:33:35,550
committing the resources to act in that

677
00:33:32,940 --> 00:33:39,480
space that means overcoming competitive

678
00:33:35,550 --> 00:33:41,639
pressures overcoming market rather berry

679
00:33:39,480 --> 00:33:43,260
and really sitting down and finding that

680
00:33:41,640 --> 00:33:49,130
that common ground and those shared

681
00:33:43,260 --> 00:33:52,110
drivers and to commit as for all of us

682
00:33:49,130 --> 00:33:56,010
we really need to use the power that we

683
00:33:52,110 --> 00:33:58,409
hold to use to hold the actors to

684
00:33:56,010 --> 00:34:01,290
account so if you look at the corporate

685
00:33:58,410 --> 00:34:05,190
world we are highly skilled highly

686
00:34:01,290 --> 00:34:07,830
desirable employees and we are customers

687
00:34:05,190 --> 00:34:09,720
with significant purchasing power so we

688
00:34:07,830 --> 00:34:12,360
really need to be adding to the

689
00:34:09,719 --> 00:34:14,879
motivation for corporate actors to play

690
00:34:12,360 --> 00:34:19,440
in that field to do the right thing and

691
00:34:14,879 --> 00:34:21,509
we need to be there to continuously hold

692
00:34:19,440 --> 00:34:24,210
them to account to act as checks and

693
00:34:21,510 --> 00:34:27,629
balances to ensure that what corporates

694
00:34:24,210 --> 00:34:30,270
commit to doing remains in the global

695
00:34:27,629 --> 00:34:34,918
interest in the interest of the global

696
00:34:30,270 --> 00:34:38,580
community and so you know I did say it's

697
00:34:34,918 --> 00:34:42,540
not all unicorns and rainbows but there

698
00:34:38,580 --> 00:34:46,799
is a certain degree of utopianism in

699
00:34:42,540 --> 00:34:49,679
this discussion and those arguments but

700
00:34:46,800 --> 00:34:52,110
I do genuine you believe that everything

701
00:34:49,679 --> 00:34:54,870
of roles and responsibilities is needed

702
00:34:52,110 --> 00:34:57,300
because you know we've had 20 years of

703
00:34:54,870 --> 00:35:01,109
doing and trying to do the same thing

704
00:34:57,300 --> 00:35:02,790
over and over and over again and it's

705
00:35:01,110 --> 00:35:07,950
not really deliver the outcomes that

706
00:35:02,790 --> 00:35:12,150
we're looking for we have to accept that

707
00:35:07,950 --> 00:35:13,560
the cyberspace is a complex ecosystem of

708
00:35:12,150 --> 00:35:16,170
different actors that have different

709
00:35:13,560 --> 00:35:17,490
strengths and weaknesses and the way in

710
00:35:16,170 --> 00:35:20,550
which they currently

711
00:35:17,490 --> 00:35:23,669
fulfill their roles doesn't really work

712
00:35:20,550 --> 00:35:25,080
to maximum effect in terms of using the

713
00:35:23,670 --> 00:35:26,369
strengths and capabilities and

714
00:35:25,080 --> 00:35:31,339
mitigating the weaknesses and

715
00:35:26,369 --> 00:35:35,640
shortcomings and so if you agree that

716
00:35:31,339 --> 00:35:37,619
madness is defined of doing as doing the

717
00:35:35,640 --> 00:35:38,580
same thing and expecting different

718
00:35:37,619 --> 00:35:41,490
outcomes

719
00:35:38,580 --> 00:35:43,589
you know perhaps trying to do things

720
00:35:41,490 --> 00:35:46,709
differently with the view to expecting

721
00:35:43,589 --> 00:35:50,430
different outcomes is the same thing to

722
00:35:46,710 --> 00:35:54,390
do at this point and with that I will

723
00:35:50,430 --> 00:36:06,750
close and really hand things over to you

724
00:35:54,390 --> 00:36:15,359
thank you very much are there any

725
00:36:06,750 --> 00:36:17,460
questions at all Thank You Gabe it's a

726
00:36:15,359 --> 00:36:20,299
really interesting discussion I just

727
00:36:17,460 --> 00:36:25,290
wondered have you considered some of the

728
00:36:20,300 --> 00:36:29,160
cultural aspects of this and how some of

729
00:36:25,290 --> 00:36:31,200
our overseas somewhere versus countries

730
00:36:29,160 --> 00:36:36,000
view the problem very differently yeah

731
00:36:31,200 --> 00:36:38,520
and yes it's interestingly but one of

732
00:36:36,000 --> 00:36:40,160
the initial caveats I wanted to put in

733
00:36:38,520 --> 00:36:42,390
is that I'm obviously looking at this

734
00:36:40,160 --> 00:36:46,410
consciously and subconsciously from a

735
00:36:42,390 --> 00:36:48,029
very Western perspective and then part

736
00:36:46,410 --> 00:36:49,500
of me was thinking this opens a whole

737
00:36:48,030 --> 00:36:52,349
other rabbit hole that I don't have time

738
00:36:49,500 --> 00:36:55,140
to go into in much detail and just sort

739
00:36:52,349 --> 00:36:57,570
of discarded it but so I thought about

740
00:36:55,140 --> 00:37:01,589
it didn't think about it in a lot of

741
00:36:57,570 --> 00:37:08,940
detail but it's a yeah it's a very valid

742
00:37:01,589 --> 00:37:11,700
point first of all thank you for this

743
00:37:08,940 --> 00:37:16,859
informative and a very thorough

744
00:37:11,700 --> 00:37:18,689
presentation in a sentence or less and I

745
00:37:16,859 --> 00:37:20,509
find myself in complete agreement with

746
00:37:18,690 --> 00:37:25,170
you regarding your assertion regarding

747
00:37:20,510 --> 00:37:28,230
the efficiency of the corporate world as

748
00:37:25,170 --> 00:37:30,600
the most effective venue to advance the

749
00:37:28,230 --> 00:37:34,680
cause I wonder

750
00:37:30,600 --> 00:37:38,100
if in fact the profit motive supersedes

751
00:37:34,680 --> 00:37:44,850
any other value or ethic thus

752
00:37:38,100 --> 00:37:48,140
invalidating the entire argument yeah I

753
00:37:44,850 --> 00:37:55,640
find it very hard to disagree with you I

754
00:37:48,140 --> 00:37:58,379
think this concept of moral purpose is

755
00:37:55,640 --> 00:38:00,359
relatively new and does require a lot

756
00:37:58,380 --> 00:38:08,190
more investigation and a lot more

757
00:38:00,360 --> 00:38:10,680
thought given to it and it will to

758
00:38:08,190 --> 00:38:14,130
counter your argument we I think we need

759
00:38:10,680 --> 00:38:16,379
a restructuring of the system in that

760
00:38:14,130 --> 00:38:20,060
profit motive is no longer the the pure

761
00:38:16,380 --> 00:38:22,410
motivator and but for the time being

762
00:38:20,060 --> 00:38:27,029
yeah you're probably you're probably

763
00:38:22,410 --> 00:38:30,299
right but that's not to say that money

764
00:38:27,030 --> 00:38:37,170
can't drive the right behaviors of

765
00:38:30,300 --> 00:38:38,940
channels in the appropriate ways you had

766
00:38:37,170 --> 00:38:42,120
a slide about the motivation of

767
00:38:38,940 --> 00:38:45,540
corporations and the three points you

768
00:38:42,120 --> 00:38:48,600
had did you double-check if initiatives

769
00:38:45,540 --> 00:38:51,390
he had which emerged last year if some

770
00:38:48,600 --> 00:38:54,810
participants and affiliates and so it's

771
00:38:51,390 --> 00:38:59,400
a similar motivation lining of see three

772
00:38:54,810 --> 00:39:01,020
or more or less so he said again yet a

773
00:38:59,400 --> 00:39:04,440
slightly of three motivations yeah and

774
00:39:01,020 --> 00:39:08,160
last year two initiatives emerged and a

775
00:39:04,440 --> 00:39:10,740
lot of petitions join these affiliates

776
00:39:08,160 --> 00:39:13,910
and Microsoft and Siemens yeah companies

777
00:39:10,740 --> 00:39:17,129
around it and did say match with your

778
00:39:13,910 --> 00:39:21,390
proposed motivations yeah more or less

779
00:39:17,130 --> 00:39:24,870
and say my interpretation is that the

780
00:39:21,390 --> 00:39:29,310
the Microsoft initiative matches more

781
00:39:24,870 --> 00:39:31,710
with the the moral purpose one in that

782
00:39:29,310 --> 00:39:34,529
at least their public rationale for

783
00:39:31,710 --> 00:39:37,080
doing what they're doing is this heroic

784
00:39:34,530 --> 00:39:40,170
ambition to make the online space more

785
00:39:37,080 --> 00:39:42,509
secure for everyone with the explanation

786
00:39:40,170 --> 00:39:44,190
that everyone has a responsibility to do

787
00:39:42,510 --> 00:39:47,099
that so there is a very

788
00:39:44,190 --> 00:39:50,500
and the rhetoric they use there's a very

789
00:39:47,099 --> 00:39:52,900
business our responsibility sort of

790
00:39:50,500 --> 00:39:55,300
thing which matches the the altruistic

791
00:39:52,900 --> 00:40:01,510
moral purpose side of things that

792
00:39:55,300 --> 00:40:04,750
charter is pretty clear that the failure

793
00:40:01,510 --> 00:40:08,320
to address security industry technology

794
00:40:04,750 --> 00:40:10,960
will reduce customers trust of the

795
00:40:08,320 --> 00:40:12,160
products and services which means a hit

796
00:40:10,960 --> 00:40:14,849
on their bottom line because they're

797
00:40:12,160 --> 00:40:20,080
less able to sell things that make sense

798
00:40:14,849 --> 00:40:22,030
and for that reason I would argue that

799
00:40:20,080 --> 00:40:26,859
that fits the the self-interest

800
00:40:22,030 --> 00:40:29,290
commercial motivation more though there

801
00:40:26,859 --> 00:40:33,910
is overlap and they all come to play

802
00:40:29,290 --> 00:40:36,550
just a matter of a shade of difference

803
00:40:33,910 --> 00:40:41,560
as to which dominates the primary

804
00:40:36,550 --> 00:40:43,839
motivation I would say we'll have time

805
00:40:41,560 --> 00:40:46,380
for one more question and after I speak

806
00:40:43,839 --> 00:40:48,820
for a second I would wonder adjust if

807
00:40:46,380 --> 00:40:50,200
you look if we look at the tech framing

808
00:40:48,820 --> 00:40:53,080
of both the moral purpose on the

809
00:40:50,200 --> 00:40:54,339
Microsoft side and the sort of more

810
00:40:53,080 --> 00:40:56,170
commercial interests we are talking

811
00:40:54,339 --> 00:40:58,210
about in the supply chain thing I'm

812
00:40:56,170 --> 00:40:59,349
wondering if we'll see that any sort of

813
00:40:58,210 --> 00:41:00,880
that vested frame that we're getting

814
00:40:59,349 --> 00:41:02,020
from those when we're taking industries

815
00:41:00,880 --> 00:41:03,609
where we don't have something with it

816
00:41:02,020 --> 00:41:05,050
directly affecting it like it seems like

817
00:41:03,609 --> 00:41:07,089
the tech industry I can see them well

818
00:41:05,050 --> 00:41:08,710
relative you have the developers now

819
00:41:07,089 --> 00:41:10,119
we're all saying you should refuse work

820
00:41:08,710 --> 00:41:11,410
that's going to hurt people and so on

821
00:41:10,119 --> 00:41:14,260
and ignoring the fact that they're lucky

822
00:41:11,410 --> 00:41:15,670
to say that different story but outside

823
00:41:14,260 --> 00:41:19,570
of the tech industry I'm still seeing

824
00:41:15,670 --> 00:41:22,810
very much the old-school Bava mode of

825
00:41:19,570 --> 00:41:25,060
being huge and I'm not sure if the frame

826
00:41:22,810 --> 00:41:26,950
of supply chain interests will encompass

827
00:41:25,060 --> 00:41:28,720
the moral eventually I'll be really

828
00:41:26,950 --> 00:41:30,250
antsy if that frame can be watched and

829
00:41:28,720 --> 00:41:32,859
pushed out of the tech sector yeah I

830
00:41:30,250 --> 00:41:33,190
don't know of anyone looking at it ya

831
00:41:32,859 --> 00:41:34,630
know

832
00:41:33,190 --> 00:41:37,200
again it's a really interesting question

833
00:41:34,630 --> 00:41:41,260
and it is it is probably another

834
00:41:37,200 --> 00:41:43,060
shortcoming of that argument is the tech

835
00:41:41,260 --> 00:41:46,900
industry of the industry with interests

836
00:41:43,060 --> 00:41:48,910
in technology that are the primary

837
00:41:46,900 --> 00:41:51,550
drivers behind I guess talking to

838
00:41:48,910 --> 00:41:52,899
someone last night they worked a

839
00:41:51,550 --> 00:41:54,130
completely different sector and they

840
00:41:52,900 --> 00:41:56,320
basically say yeah we're never going to

841
00:41:54,130 --> 00:41:59,890
cooperate across competitors

842
00:41:56,320 --> 00:42:02,170
gonna happen you know give it ten years

843
00:41:59,890 --> 00:42:04,359
of everything becomes technology maybe

844
00:42:02,170 --> 00:42:07,780
there is a difference again in in

845
00:42:04,360 --> 00:42:08,800
argument but so the question is you said

846
00:42:07,780 --> 00:42:10,330
in the beginning of this you're throwing

847
00:42:08,800 --> 00:42:11,560
out the social science view is to take a

848
00:42:10,330 --> 00:42:13,330
little bit more of an ambitious approach

849
00:42:11,560 --> 00:42:15,610
are you aware of anyone doing that type

850
00:42:13,330 --> 00:42:17,080
of review of a program like the tech

851
00:42:15,610 --> 00:42:19,270
sector or where they're framing that

852
00:42:17,080 --> 00:42:22,029
leads to the moral imperative at a

853
00:42:19,270 --> 00:42:24,490
social science of research level and I'm

854
00:42:22,030 --> 00:42:26,470
not but that's not to say it isn't

855
00:42:24,490 --> 00:42:28,600
happening because I'm not really

856
00:42:26,470 --> 00:42:30,279
embedded in academia so it might well be

857
00:42:28,600 --> 00:42:32,259
that things are happening if anyone's

858
00:42:30,280 --> 00:42:34,870
aware of anything please let me know

859
00:42:32,260 --> 00:42:38,730
kiss I am quite fascinated by this whole

860
00:42:34,870 --> 00:42:41,440
discussion are there any more questions

861
00:42:38,730 --> 00:42:43,770
right thank you very much everyone Thank

862
00:42:41,440 --> 00:42:43,770
You Kath

