1
00:00:02,780 --> 00:00:11,069
good morning how are you do and I can

2
00:00:06,330 --> 00:00:13,290
join it is it all fun first of all I

3
00:00:11,070 --> 00:00:18,869
would like to thank in ca for their kind

4
00:00:13,290 --> 00:00:21,240
invitation and I hope you're enjoying it

5
00:00:18,869 --> 00:00:22,820
but from the point of view of industry

6
00:00:21,240 --> 00:00:26,759
we think this kind of events are

7
00:00:22,820 --> 00:00:28,920
paramount for sensitizing citizens as

8
00:00:26,760 --> 00:00:31,830
we've all seen in the presentation the

9
00:00:28,920 --> 00:00:35,010
human factor is one of the main entry

10
00:00:31,830 --> 00:00:38,519
point wait in an attempt to compromise a

11
00:00:35,010 --> 00:00:41,339
network and so the task of in CB amongst

12
00:00:38,520 --> 00:00:45,829
other organizations is a critical to

13
00:00:41,340 --> 00:00:45,829
help the industry protect our users

14
00:00:45,890 --> 00:00:54,059
about myself I'm Jaime Blasco chief

15
00:00:49,260 --> 00:00:55,530
scientist at alienvault a dino me I was

16
00:00:54,059 --> 00:00:58,108
do you know ellenville sorry do you know

17
00:00:55,530 --> 00:01:01,260
any involved a few people and as you

18
00:00:58,109 --> 00:01:03,329
might know it was started here in Spain

19
00:01:01,260 --> 00:01:06,090
and a few years we had a chance to move

20
00:01:03,329 --> 00:01:10,650
to the US and we've grown

21
00:01:06,090 --> 00:01:13,530
internationally and we still have a lot

22
00:01:10,650 --> 00:01:16,500
team of engineers based in Spain but

23
00:01:13,530 --> 00:01:18,780
we've expanded internationally and now

24
00:01:16,500 --> 00:01:20,880
we have our headquarters in Silicon

25
00:01:18,780 --> 00:01:24,090
Valley I live in San Francisco for some

26
00:01:20,880 --> 00:01:26,339
years now and I have this anecdote how

27
00:01:24,090 --> 00:01:29,090
many in the room how have you lived

28
00:01:26,340 --> 00:01:31,680
abroad for a couple of years hands up

29
00:01:29,090 --> 00:01:34,530
maybe this happened to you too when I

30
00:01:31,680 --> 00:01:37,079
had a chance to move to the US I was

31
00:01:34,530 --> 00:01:40,979
thinking how great finally I will get

32
00:01:37,079 --> 00:01:45,089
better English and I moved there and

33
00:01:40,979 --> 00:01:47,640
it's true it did get bit better but 23

34
00:01:45,090 --> 00:01:51,329
years into it I realized that much fun

35
00:01:47,640 --> 00:01:53,040
is what got worse and 34 years later

36
00:01:51,329 --> 00:01:55,048
what happens is that I don't speak

37
00:01:53,040 --> 00:02:00,509
Spanish or English I it's kind of a

38
00:01:55,049 --> 00:02:03,329
mixture of both languages so if I say an

39
00:02:00,509 --> 00:02:08,210
English word or some Spanglish term

40
00:02:03,329 --> 00:02:08,209
sorry about that that's my main problem

41
00:02:09,949 --> 00:02:19,179
how many of you work in these a giftie

42
00:02:13,810 --> 00:02:21,010
industry hands up so you might get this

43
00:02:19,180 --> 00:02:25,900
question over and over again your

44
00:02:21,010 --> 00:02:27,760
friends your family I get phipps also so

45
00:02:25,900 --> 00:02:29,880
much fun you work on cybersecurity

46
00:02:27,760 --> 00:02:33,220
hackers what's your daily activity

47
00:02:29,880 --> 00:02:40,720
problem is people have been watched this

48
00:02:33,220 --> 00:02:44,200
film it we've been worse and war games

49
00:02:40,720 --> 00:02:46,569
was quite realistic then knickers is my

50
00:02:44,200 --> 00:02:51,160
favorite one I think they are great at

51
00:02:46,569 --> 00:02:53,589
explaining what the security is like and

52
00:02:51,160 --> 00:02:57,310
how it works and it all got complicated

53
00:02:53,590 --> 00:03:00,790
hackers 1995 that they were skating or

54
00:02:57,310 --> 00:03:04,120
everywhere then 2001 terrible because

55
00:03:00,790 --> 00:03:07,780
they mixed up hackers and sex and we all

56
00:03:04,120 --> 00:03:11,440
know that sci-fi so y'all got very

57
00:03:07,780 --> 00:03:13,360
complicated so your family people don't

58
00:03:11,440 --> 00:03:15,549
think that you've been to prison such as

59
00:03:13,360 --> 00:03:19,000
in black hard and you help every

60
00:03:15,549 --> 00:03:22,239
government Hargitay and nuclear plants

61
00:03:19,000 --> 00:03:24,579
that that's the main problem but if

62
00:03:22,239 --> 00:03:29,170
you're working on cybersecurity you know

63
00:03:24,579 --> 00:03:31,000
that's not like anything like it for the

64
00:03:29,170 --> 00:03:34,119
last 10 12 years that I've been in the

65
00:03:31,000 --> 00:03:36,880
industry I've just realized and it's

66
00:03:34,120 --> 00:03:39,730
been just recently that I realized

67
00:03:36,880 --> 00:03:41,440
because my favorite film is too fast too

68
00:03:39,730 --> 00:03:44,230
furious in that spurted from the

69
00:03:41,440 --> 00:03:46,690
industry I guess eat all of this island

70
00:03:44,230 --> 00:03:50,470
fine now they're thousands of companies

71
00:03:46,690 --> 00:03:52,630
offering security solutions for each

72
00:03:50,470 --> 00:03:55,180
security control you want to set up

73
00:03:52,630 --> 00:03:57,790
there's at least 20 to 20 companies that

74
00:03:55,180 --> 00:04:00,790
have a product that it that are just

75
00:03:57,790 --> 00:04:09,010
identical to each other and just the

76
00:04:00,790 --> 00:04:12,160
same 1400 vendors 1400 companies in the

77
00:04:09,010 --> 00:04:16,478
world from the point of view for user of

78
00:04:12,160 --> 00:04:21,909
a company when you're going to buy a

79
00:04:16,478 --> 00:04:23,979
security product no yellow and and and

80
00:04:21,909 --> 00:04:26,940
and why doesn't work very very well as

81
00:04:23,979 --> 00:04:29,710
you can see but

82
00:04:26,940 --> 00:04:31,930
1400 vendors how can I user know what

83
00:04:29,710 --> 00:04:39,549
the best product is and what's the

84
00:04:31,930 --> 00:04:41,080
product that will help them what I

85
00:04:39,550 --> 00:04:44,080
wanted to discuss here was a bit of

86
00:04:41,080 --> 00:04:46,240
self-criticism I'm used to given those

87
00:04:44,080 --> 00:04:48,490
presentations where I explain how the

88
00:04:46,240 --> 00:04:51,130
security industry will help solve your

89
00:04:48,490 --> 00:04:53,800
problems and you will buy my product

90
00:04:51,130 --> 00:04:56,469
here at this time for self criticism and

91
00:04:53,800 --> 00:04:58,389
I guess it's time to discuss some of the

92
00:04:56,470 --> 00:05:03,220
problems that we are facing as an

93
00:04:58,389 --> 00:05:08,440
industry first that we sell you magic

94
00:05:03,220 --> 00:05:10,780
boxes we sell you a product and our

95
00:05:08,440 --> 00:05:13,300
sales reps when they visit you they

96
00:05:10,780 --> 00:05:15,429
promise a product will solve all your

97
00:05:13,300 --> 00:05:18,789
problems you will plot your box through

98
00:05:15,430 --> 00:05:21,039
your data center and no haku will

99
00:05:18,789 --> 00:05:25,599
compromise your network that's a lie a

100
00:05:21,039 --> 00:05:28,840
blunt line and part of the blame falls

101
00:05:25,600 --> 00:05:32,580
with us with industry because we are

102
00:05:28,840 --> 00:05:35,409
terrible at marketing next-generation

103
00:05:32,580 --> 00:05:37,930
firewalls next-generation next-gen it's

104
00:05:35,410 --> 00:05:40,690
just the same product but we've just

105
00:05:37,930 --> 00:05:42,789
changed the name so we've been selling

106
00:05:40,690 --> 00:05:45,610
firewalls for 20 years and the one you

107
00:05:42,789 --> 00:05:50,169
get sold now is next-generation firewall

108
00:05:45,610 --> 00:05:52,870
but it's just the same one problem is

109
00:05:50,169 --> 00:05:57,849
the firewall concept networks have

110
00:05:52,870 --> 00:06:01,120
changed in the last 10 to 20 years these

111
00:05:57,849 --> 00:06:04,599
setting up barrier after barrier doesn't

112
00:06:01,120 --> 00:06:08,229
work cloud technology and much of your

113
00:06:04,599 --> 00:06:10,539
servers I'm not even on your network

114
00:06:08,229 --> 00:06:14,590
anymore they are in amazon's or

115
00:06:10,539 --> 00:06:17,700
microsoft's a firewall it's not as

116
00:06:14,590 --> 00:06:17,700
useful as it used to be

117
00:06:19,180 --> 00:06:25,220
these are the problem between that out

118
00:06:21,740 --> 00:06:28,070
of 1300 vendor security vendors that I

119
00:06:25,220 --> 00:06:31,700
mentioned before I can assure you that

120
00:06:28,070 --> 00:06:38,780
eighty to ninety percent just sell to

121
00:06:31,700 --> 00:06:42,770
the 1400 top companies in the world so

122
00:06:38,780 --> 00:06:46,369
the rest of the market does not have the

123
00:06:42,770 --> 00:06:49,370
right solutions to face threats I cannot

124
00:06:46,370 --> 00:06:50,660
sell you the same product to you or Bank

125
00:06:49,370 --> 00:06:54,380
of America with a thousand employees

126
00:06:50,660 --> 00:06:56,480
working on security same contrary to and

127
00:06:54,380 --> 00:06:58,490
stirred up or an SME where there is

128
00:06:56,480 --> 00:07:02,000
someone from Haiti there is also charge

129
00:06:58,490 --> 00:07:05,690
of security both products will not work

130
00:07:02,000 --> 00:07:07,880
for all companies we need many more

131
00:07:05,690 --> 00:07:12,920
vendors that do not only target large

132
00:07:07,880 --> 00:07:28,040
companies but working on user protection

133
00:07:12,920 --> 00:07:32,990
and SMEs and the smallest companies so

134
00:07:28,040 --> 00:07:38,500
it is estimated that for the next a few

135
00:07:32,990 --> 00:07:38,500
years they will spend 1 billion dollars

136
00:07:39,160 --> 00:07:47,240
one quick sorry quintillion dollars and

137
00:07:44,500 --> 00:07:49,940
go into mouse it cost you 500 million

138
00:07:47,240 --> 00:07:52,550
dollars so it costs you half the billion

139
00:07:49,940 --> 00:07:55,160
dollar so it's building it it is

140
00:07:52,550 --> 00:08:01,990
training it it is sending them to Mars

141
00:07:55,160 --> 00:08:06,310
that all costs have the world expense on

142
00:08:01,990 --> 00:08:06,310
cybersecurity for the next five years

143
00:08:06,750 --> 00:08:11,970
as a society I think we are doing

144
00:08:09,240 --> 00:08:15,150
something wrong I hope because I weren't

145
00:08:11,970 --> 00:08:16,980
I worked in the security world but I

146
00:08:15,150 --> 00:08:18,570
hope that I would go out of where

147
00:08:16,980 --> 00:08:20,280
because everything was so severe and

148
00:08:18,570 --> 00:08:22,770
safe and I could give my time on

149
00:08:20,280 --> 00:08:25,200
something more important such as sending

150
00:08:22,770 --> 00:08:28,020
humans to Mars and we could spend the

151
00:08:25,200 --> 00:08:29,700
same amount of money actually have a bit

152
00:08:28,020 --> 00:08:34,620
of what they are going to spend on

153
00:08:29,700 --> 00:08:37,740
cybersecurity up the other problem would

154
00:08:34,620 --> 00:08:43,770
be that complexity is the enemy of

155
00:08:37,740 --> 00:08:46,320
security these are very complicated

156
00:08:43,770 --> 00:08:49,110
networks that where we have several

157
00:08:46,320 --> 00:08:52,380
segments this is a fire one and then I

158
00:08:49,110 --> 00:08:54,720
feel Brett Gardner and they say when I

159
00:08:52,380 --> 00:08:58,290
need to buy 20 products i need being

160
00:08:54,720 --> 00:09:03,860
stalled and had to be integrated are we

161
00:08:58,290 --> 00:09:06,360
not that level of complexity in the end

162
00:09:03,860 --> 00:09:08,550
means that we are not so safe anymore

163
00:09:06,360 --> 00:09:10,560
and I can share thousands and millions

164
00:09:08,550 --> 00:09:16,050
of cases sony used to spend millions

165
00:09:10,560 --> 00:09:18,750
millions on cybersecurity target for

166
00:09:16,050 --> 00:09:20,490
example they took all the credit cards I

167
00:09:18,750 --> 00:09:24,290
can assure you that we're spending

168
00:09:20,490 --> 00:09:27,720
around million dollars and security and

169
00:09:24,290 --> 00:09:30,060
hot those of people checking out alerts

170
00:09:27,720 --> 00:09:33,600
and alerts and warnings but they had so

171
00:09:30,060 --> 00:09:36,479
many security devices so many warnings

172
00:09:33,600 --> 00:09:39,150
that the complexity took the best of

173
00:09:36,480 --> 00:09:42,030
them and hackers got the old information

174
00:09:39,150 --> 00:09:43,680
from from their credit cards problem is

175
00:09:42,030 --> 00:09:45,990
not that they didn't have the technology

176
00:09:43,680 --> 00:09:48,719
to find out that it was a hacker inside

177
00:09:45,990 --> 00:09:51,120
it but it was so complex so complicated

178
00:09:48,720 --> 00:09:57,600
that they could not focus on the

179
00:09:51,120 --> 00:10:00,680
information that it was important so we

180
00:09:57,600 --> 00:10:00,680
need to learn from attackers

181
00:10:03,900 --> 00:10:08,680
massillon didn't need complex techniques

182
00:10:06,550 --> 00:10:11,770
they don't need them they use very

183
00:10:08,680 --> 00:10:14,079
simple technique that still work I guess

184
00:10:11,770 --> 00:10:17,230
that is an industry as a society we need

185
00:10:14,080 --> 00:10:19,210
to redefine it from the beginning we

186
00:10:17,230 --> 00:10:22,360
need to learn from them and go back to

187
00:10:19,210 --> 00:10:24,310
the basics and what's the basics ok so

188
00:10:22,360 --> 00:10:27,780
this is an example attackers use for

189
00:10:24,310 --> 00:10:30,699
sure and you all know what a macro is

190
00:10:27,780 --> 00:10:36,910
it's a piece of code that you can embed

191
00:10:30,700 --> 00:10:39,220
into an office file and when you open it

192
00:10:36,910 --> 00:10:40,660
it can get you infected with malware and

193
00:10:39,220 --> 00:10:42,670
this is something that ransomware has

194
00:10:40,660 --> 00:10:46,630
been years in of light do you think this

195
00:10:42,670 --> 00:10:49,569
is new first proof of concept was back

196
00:10:46,630 --> 00:10:52,660
in nineteen ninety five then 1999 if you

197
00:10:49,570 --> 00:10:56,950
remember melissa is one of the most best

198
00:10:52,660 --> 00:11:00,280
known viruses bent on macro and 2016 is

199
00:10:56,950 --> 00:11:02,680
still there lockheed riddick's and lots

200
00:11:00,280 --> 00:11:07,180
of ransomware up options you said and

201
00:11:02,680 --> 00:11:09,760
it's been 21 years and the attackers

202
00:11:07,180 --> 00:11:12,280
just just the same techniques even

203
00:11:09,760 --> 00:11:15,610
though we're going to spend one trillion

204
00:11:12,280 --> 00:11:19,270
dollars in protecting networks what

205
00:11:15,610 --> 00:11:22,930
about spearfishing are fish in 2033 the

206
00:11:19,270 --> 00:11:27,329
pentagon had an attack from China 2009

207
00:11:22,930 --> 00:11:30,489
or Roura compromised Google Microsoft

208
00:11:27,330 --> 00:11:35,260
most of the larger companies in Silicon

209
00:11:30,490 --> 00:11:37,750
Valley 2016 same technique dnc yahoo i

210
00:11:35,260 --> 00:11:39,360
could give you millions of companies

211
00:11:37,750 --> 00:11:42,310
that found themselves compromised

212
00:11:39,360 --> 00:11:49,270
biosphere fishing or efficient 13 years

213
00:11:42,310 --> 00:11:52,660
just the same what the hell do you

214
00:11:49,270 --> 00:11:54,410
follow the degree GRIK up on twitter if

215
00:11:52,660 --> 00:11:56,990
you don't

216
00:11:54,410 --> 00:12:02,779
now go to your twitter twitter account

217
00:11:56,990 --> 00:12:06,230
and start following them often what they

218
00:12:02,779 --> 00:12:10,160
say is is true this is one of the quotes

219
00:12:06,230 --> 00:12:12,500
I'd like the most you can give them an

220
00:12:10,160 --> 00:12:15,589
asteroid and he'll have access for a day

221
00:12:12,500 --> 00:12:21,019
teach a man to fish and he'll have

222
00:12:15,589 --> 00:12:23,930
access for life and it's been seen 21

223
00:12:21,019 --> 00:12:27,939
years and they have the same vision

224
00:12:23,930 --> 00:12:32,149
technique and finally denial of service

225
00:12:27,939 --> 00:12:36,610
1998 there was a famous hacker group lot

226
00:12:32,149 --> 00:12:39,709
in the US visiting the Congress and

227
00:12:36,610 --> 00:12:42,199
explaining Congress people how they

228
00:12:39,709 --> 00:12:44,388
thought they could crash down the

229
00:12:42,199 --> 00:12:48,410
internet within five minutes and this

230
00:12:44,389 --> 00:12:51,769
was the government 2007 Stonier hot are

231
00:12:48,410 --> 00:12:54,019
distributed service at hack which

232
00:12:51,769 --> 00:12:57,319
basically took down the whole come

233
00:12:54,019 --> 00:13:00,470
country and then 2016 you probably

234
00:12:57,319 --> 00:13:04,069
remember a few weeks back the problem

235
00:13:00,470 --> 00:13:08,449
with me I and the Dean DNS attack that

236
00:13:04,069 --> 00:13:10,839
almost brings out the whole internet the

237
00:13:08,449 --> 00:13:16,209
person who started this mere I attack

238
00:13:10,839 --> 00:13:19,790
was a kid at home was not even a state

239
00:13:16,209 --> 00:13:24,170
it was a kid at home who thought of

240
00:13:19,790 --> 00:13:27,529
using these me right but would you

241
00:13:24,170 --> 00:13:30,410
probably remember was made up of IOT

242
00:13:27,529 --> 00:13:34,279
devices mainly a camera is connected to

243
00:13:30,410 --> 00:13:37,850
the internet and also recorders on the

244
00:13:34,279 --> 00:13:41,149
internet as well and he almost managed

245
00:13:37,850 --> 00:13:43,579
to crash at all problem is we still use

246
00:13:41,149 --> 00:13:46,550
on the internet the same protocols that

247
00:13:43,579 --> 00:13:49,370
were invented 30 years ago that we're

248
00:13:46,550 --> 00:13:53,378
not conceived from a security point of

249
00:13:49,370 --> 00:13:57,470
view vasilios DNS with changes h https

250
00:13:53,379 --> 00:14:01,490
HTTP sorry and we have version number 2

251
00:13:57,470 --> 00:14:03,680
version c 6 13 s3 we need to implement

252
00:14:01,490 --> 00:14:05,360
them we cannot still use the same

253
00:14:03,680 --> 00:14:06,160
protocols as before because a kid from

254
00:14:05,360 --> 00:14:10,209
home

255
00:14:06,160 --> 00:14:11,980
can destabilize it Oh cans that disabled

256
00:14:10,209 --> 00:14:15,430
eyes the whole internet we cannot go on

257
00:14:11,980 --> 00:14:17,769
like that and if they're journalists in

258
00:14:15,430 --> 00:14:20,430
the room please stop saying that our

259
00:14:17,769 --> 00:14:22,660
toasters can bring the internet down

260
00:14:20,430 --> 00:14:25,750
because usually they are not connected

261
00:14:22,660 --> 00:14:29,560
to the Internet and the few that are are

262
00:14:25,750 --> 00:14:36,689
in your own network they were not part

263
00:14:29,560 --> 00:14:36,689
of the botnet for mere I what now we do

264
00:14:38,220 --> 00:14:43,600
if i could start from scratch and throw

265
00:14:41,740 --> 00:14:46,449
away all the money i have spent on

266
00:14:43,600 --> 00:14:51,759
security devices what i would do is

267
00:14:46,449 --> 00:14:53,889
think in today think of details focus on

268
00:14:51,759 --> 00:14:56,019
the details just change a few of those

269
00:14:53,889 --> 00:15:00,339
one of the examples i wanted to share

270
00:14:56,019 --> 00:15:02,350
and i would recommend you to look for

271
00:15:00,339 --> 00:15:07,360
this on the internet this is google

272
00:15:02,350 --> 00:15:09,639
chrome security teams presentation here

273
00:15:07,360 --> 00:15:12,279
there was no one there was no security

274
00:15:09,639 --> 00:15:14,829
engineer working in the project they

275
00:15:12,279 --> 00:15:17,560
were all graph design graphic designers

276
00:15:14,829 --> 00:15:20,019
and yet they managed the following they

277
00:15:17,560 --> 00:15:22,899
narrow down the amount of mal word used

278
00:15:20,019 --> 00:15:25,839
by people with google chrome with

279
00:15:22,899 --> 00:15:28,029
something as simple as changing the

280
00:15:25,839 --> 00:15:31,420
messages that google chrome uses to

281
00:15:28,029 --> 00:15:33,939
warned you that you might be downloading

282
00:15:31,420 --> 00:15:37,300
a file with malware something as simple

283
00:15:33,939 --> 00:15:42,759
as saying we've warned you do not

284
00:15:37,300 --> 00:15:46,300
download it and say by the way this

285
00:15:42,759 --> 00:15:49,509
might be malicious by default it will

286
00:15:46,300 --> 00:15:55,540
not be executed but if you want I can't

287
00:15:49,509 --> 00:15:58,209
unload it and so the click-through rate

288
00:15:55,540 --> 00:16:00,370
out of a hundred message there were 30

289
00:15:58,209 --> 00:16:03,638
people who said I don't care i would get

290
00:16:00,370 --> 00:16:05,500
infected just by changing the contents

291
00:16:03,639 --> 00:16:08,500
of the message it went down to four

292
00:16:05,500 --> 00:16:12,189
percent how much eating this cost is

293
00:16:08,500 --> 00:16:15,250
this change in my message and they

294
00:16:12,189 --> 00:16:17,639
reduce a rate of infection by a large

295
00:16:15,250 --> 00:16:17,639
amount

296
00:16:17,850 --> 00:16:24,900
but let's blame the user that's way

297
00:16:22,060 --> 00:16:31,119
easier the user got an email clicked and

298
00:16:24,900 --> 00:16:35,380
got infected so the attacker managed to

299
00:16:31,120 --> 00:16:41,890
steal their database and it is the users

300
00:16:35,380 --> 00:16:44,860
blame for sure it's easier this way LEDs

301
00:16:41,890 --> 00:16:47,650
year I had a chance to attend a

302
00:16:44,860 --> 00:16:56,860
conference by drop Joyce who is the

303
00:16:47,650 --> 00:17:00,100
tower director have you heard Tom o is

304
00:16:56,860 --> 00:17:02,880
the hacking group at the NSA they are

305
00:17:00,100 --> 00:17:06,430
the world cracks that NSA has

306
00:17:02,880 --> 00:17:08,920
underground and out the ones hacking

307
00:17:06,430 --> 00:17:14,230
networks in China Russia or North Korea

308
00:17:08,920 --> 00:17:16,780
what he says is that the worst nightmare

309
00:17:14,230 --> 00:17:19,720
for anything is someone who pays

310
00:17:16,780 --> 00:17:23,500
attention and uses basic techniques and

311
00:17:19,720 --> 00:17:25,360
paying attention I check blogs I make

312
00:17:23,500 --> 00:17:27,190
sure there are no local users I pay

313
00:17:25,359 --> 00:17:30,939
attention and I check out all systems

314
00:17:27,190 --> 00:17:34,390
are up to date it's not about spending

315
00:17:30,940 --> 00:17:37,690
billions into complex security systems

316
00:17:34,390 --> 00:17:41,410
so simple as paying attention naturally

317
00:17:37,690 --> 00:17:43,780
this is no silver bullet will not

318
00:17:41,410 --> 00:17:46,150
protect you from every attacker will not

319
00:17:43,780 --> 00:17:47,860
protect you from the NSA but it will

320
00:17:46,150 --> 00:17:55,210
protect you from many other attackers

321
00:17:47,860 --> 00:17:57,610
but if you've ever spoken to a security

322
00:17:55,210 --> 00:17:59,920
vendor fashion is that they have a new

323
00:17:57,610 --> 00:18:03,520
private that is in the cloud using AI

324
00:17:59,920 --> 00:18:09,340
and that will spare you from all evil

325
00:18:03,520 --> 00:18:11,400
but let's think it through before we say

326
00:18:09,340 --> 00:18:11,399
so

327
00:18:14,590 --> 00:18:19,730
unfortunately I had a few slides where I

328
00:18:16,850 --> 00:18:22,100
would introduce you into artificial

329
00:18:19,730 --> 00:18:23,809
intelligence on machine learning but I

330
00:18:22,100 --> 00:18:26,748
realized yesterday there was another

331
00:18:23,809 --> 00:18:31,668
colleague gave a presentation on machine

332
00:18:26,749 --> 00:18:37,519
learning were you here hands up so I say

333
00:18:31,669 --> 00:18:42,279
that a few basic elements then I'll skip

334
00:18:37,519 --> 00:18:44,629
those by the way thank you because you

335
00:18:42,279 --> 00:18:52,369
suspect me five sixes likes your work

336
00:18:44,629 --> 00:18:54,918
it's amazing who could describe just ten

337
00:18:52,369 --> 00:19:00,740
words to explain what machine learning

338
00:18:54,919 --> 00:19:11,169
is who willing no one you said you were

339
00:19:00,740 --> 00:19:13,220
here yes are you right to summarize it

340
00:19:11,169 --> 00:19:15,080
basically if you were not at the

341
00:19:13,220 --> 00:19:18,049
presentation they vidya is instead of

342
00:19:15,080 --> 00:19:21,379
defining new standards or rules we would

343
00:19:18,049 --> 00:19:24,220
produce a example data set examples

344
00:19:21,379 --> 00:19:27,110
transferred into a model and then

345
00:19:24,220 --> 00:19:28,610
explained the result we expect so you

346
00:19:27,110 --> 00:19:33,590
might have 1 million pictures of cats

347
00:19:28,610 --> 00:19:37,100
and dogs classified as cut or duck you

348
00:19:33,590 --> 00:19:38,959
produce a model you fit in all the

349
00:19:37,100 --> 00:19:41,379
training data and the model in the end

350
00:19:38,960 --> 00:19:46,190
through different techniques will now

351
00:19:41,379 --> 00:19:48,469
will tell apart a cut from a dark with

352
00:19:46,190 --> 00:19:53,629
an error percentage that is quite quite

353
00:19:48,470 --> 00:19:58,369
small what's changed because we've

354
00:19:53,629 --> 00:20:02,689
discussed neural networks for 10 20 30

355
00:19:58,369 --> 00:20:05,360
40 years I recall these papers we're

356
00:20:02,690 --> 00:20:07,850
back in the 80s the neural networks were

357
00:20:05,360 --> 00:20:09,799
already fashionable if and if you pay

358
00:20:07,850 --> 00:20:12,289
attention to algorithms the main

359
00:20:09,799 --> 00:20:15,350
algorithms but they haven't changed much

360
00:20:12,289 --> 00:20:18,259
we found new techniques to build new

361
00:20:15,350 --> 00:20:21,649
layers to protect data in the right way

362
00:20:18,259 --> 00:20:23,990
but then the main idea underlying a

363
00:20:21,649 --> 00:20:26,570
neural edwards just the same so was

364
00:20:23,990 --> 00:20:30,080
changed basically

365
00:20:26,570 --> 00:20:32,860
we have now access to many more data

366
00:20:30,080 --> 00:20:35,509
sets thanks to the internet basically

367
00:20:32,860 --> 00:20:39,529
companies now have access to many more

368
00:20:35,509 --> 00:20:41,600
data Google Facebook specially so

369
00:20:39,529 --> 00:20:43,070
picture the amount of days time and not

370
00:20:41,600 --> 00:20:46,009
just days or but classified information

371
00:20:43,070 --> 00:20:47,779
that they have control of Google can

372
00:20:46,009 --> 00:20:50,000
have access to billions of pictures that

373
00:20:47,779 --> 00:20:53,059
being classified into different classes

374
00:20:50,000 --> 00:20:56,210
and they can use it to train large

375
00:20:53,059 --> 00:21:01,129
neural networks second force cloud

376
00:20:56,210 --> 00:21:03,950
computing not everyone can spend

377
00:21:01,129 --> 00:21:06,740
millions of euros or dollars keeping a

378
00:21:03,950 --> 00:21:09,049
data center with so many machines that

379
00:21:06,740 --> 00:21:12,019
are to be used for neural networks and

380
00:21:09,049 --> 00:21:17,230
now you can go to Amazon or Microsoft

381
00:21:12,019 --> 00:21:17,230
and just crank your neural network by

382
00:21:18,250 --> 00:21:23,899
using systems that only charge you per

383
00:21:21,620 --> 00:21:26,689
the time for time of use no need to

384
00:21:23,899 --> 00:21:29,000
invest into the whole heart word that

385
00:21:26,690 --> 00:21:32,389
you would used for for for days or weeks

386
00:21:29,000 --> 00:21:37,419
but you don't need to own it and then

387
00:21:32,389 --> 00:21:42,379
gamers GPUs so graphic units and cards

388
00:21:37,419 --> 00:21:46,190
boards rather that gamers use they found

389
00:21:42,379 --> 00:21:48,259
out that they would perform similar

390
00:21:46,190 --> 00:21:54,009
operations to machine learning

391
00:21:48,259 --> 00:21:54,009
algorithms and with GPUs they can be

392
00:21:54,190 --> 00:22:02,659
beat up by five or ten times so this

393
00:21:59,240 --> 00:22:07,759
video's up five or ten times main

394
00:22:02,659 --> 00:22:10,279
problems for deep learning and machine

395
00:22:07,759 --> 00:22:14,570
learning specifically have helped us and

396
00:22:10,279 --> 00:22:17,720
I have fully changed in recent years has

397
00:22:14,570 --> 00:22:21,500
been voice rec speech recognition image

398
00:22:17,720 --> 00:22:23,679
and video recognition machine Trek

399
00:22:21,500 --> 00:22:23,679
nation

400
00:22:24,750 --> 00:22:32,460
and the natural language recognition or

401
00:22:28,560 --> 00:22:34,290
processing now we have boats on facebook

402
00:22:32,460 --> 00:22:36,840
and other systems you can talk to a bar

403
00:22:34,290 --> 00:22:41,070
and they understand what you're saying

404
00:22:36,840 --> 00:22:43,439
or a lexan as well for Amazon other wats

405
00:22:41,070 --> 00:22:49,050
such as Google that has already released

406
00:22:43,440 --> 00:22:52,740
one so that you understand to what

407
00:22:49,050 --> 00:22:55,919
extent this has felt imagenet we do now

408
00:22:52,740 --> 00:22:57,810
add it imagenet would be a hard test

409
00:22:55,920 --> 00:23:00,870
international comfort contester

410
00:22:57,810 --> 00:23:03,090
tournament that is held every year you

411
00:23:00,870 --> 00:23:06,209
get a hundred thousand pictures you can

412
00:23:03,090 --> 00:23:07,860
use australian a hundred thousand

413
00:23:06,210 --> 00:23:11,340
pictures that have been classified into

414
00:23:07,860 --> 00:23:14,669
20 30 groups a thousand for a cheap or

415
00:23:11,340 --> 00:23:18,209
two thousand for a card have four

416
00:23:14,670 --> 00:23:21,090
thousand pictures of a car and you need

417
00:23:18,210 --> 00:23:27,900
to build up an algorithm that uses set

418
00:23:21,090 --> 00:23:31,770
examples can multiply by twenty percent

419
00:23:27,900 --> 00:23:34,530
to know your your model mistake or to

420
00:23:31,770 --> 00:23:38,940
what extent your model is good or how

421
00:23:34,530 --> 00:23:40,980
good your modern is 2010 the error

422
00:23:38,940 --> 00:23:43,590
percentage was a trade was thirty

423
00:23:40,980 --> 00:23:45,540
percent so it was not used and they were

424
00:23:43,590 --> 00:23:51,270
using features that were produced

425
00:23:45,540 --> 00:23:53,210
manually axis recognition shape

426
00:23:51,270 --> 00:23:55,770
recognition and this would be

427
00:23:53,210 --> 00:23:58,800
transferred into a quite basic modern

428
00:23:55,770 --> 00:24:02,490
then 2012 someone came up with the idea

429
00:23:58,800 --> 00:24:05,430
of using neural networks that was they

430
00:24:02,490 --> 00:24:07,230
they went to the Alex net and it went

431
00:24:05,430 --> 00:24:09,870
down from 30 to fifteen percent that's

432
00:24:07,230 --> 00:24:14,010
error rate and as you seem by using

433
00:24:09,870 --> 00:24:16,800
neural networks even last year at the

434
00:24:14,010 --> 00:24:20,370
tournament the error of the month the

435
00:24:16,800 --> 00:24:24,269
winning model was below a human's rate

436
00:24:20,370 --> 00:24:28,678
so the mathematic method

437
00:24:24,269 --> 00:24:32,789
had lower error in the classification of

438
00:24:28,679 --> 00:24:34,649
images compared to a human so this is

439
00:24:32,789 --> 00:24:43,919
the progression shift within four years

440
00:24:34,649 --> 00:24:46,889
it's been huge and we see that all large

441
00:24:43,919 --> 00:24:48,869
companies have come to realize that it

442
00:24:46,889 --> 00:24:50,609
is a good idea to share frameworks and

443
00:24:48,869 --> 00:24:54,289
why is that because if you spend little

444
00:24:50,609 --> 00:24:57,089
money what it was difficult to build

445
00:24:54,289 --> 00:25:00,839
noodle networks especially because you

446
00:24:57,089 --> 00:25:05,489
have to program your own software you

447
00:25:00,839 --> 00:25:06,958
have to have quite a math background but

448
00:25:05,489 --> 00:25:12,859
then recently other companies such as

449
00:25:06,959 --> 00:25:17,609
Google has published a desert flow and

450
00:25:12,859 --> 00:25:20,249
others such as I said gender cetera

451
00:25:17,609 --> 00:25:22,559
they've helped but do not be mistaken

452
00:25:20,249 --> 00:25:24,929
they do not release their frameworks

453
00:25:22,559 --> 00:25:29,639
because they wanna contribute to society

454
00:25:24,929 --> 00:25:31,739
the main reason why they do it is well I

455
00:25:29,639 --> 00:25:35,519
guess is a pretty good description of

456
00:25:31,739 --> 00:25:39,479
what we are experiencing this is 20 or

457
00:25:35,519 --> 00:25:41,789
12 2016 and you see the company's the

458
00:25:39,479 --> 00:25:43,789
largest companies in the world from the

459
00:25:41,789 --> 00:25:47,099
point of the financial point of view

460
00:25:43,789 --> 00:25:49,799
2001 only Microsoft was there as a

461
00:25:47,099 --> 00:25:51,239
software company that was one of the

462
00:25:49,799 --> 00:25:56,899
most important companies in the world

463
00:25:51,239 --> 00:26:00,089
then 2016 all all five top companies

464
00:25:56,899 --> 00:26:03,178
world companies are so we're a hardware

465
00:26:00,089 --> 00:26:04,950
companies which means this companies

466
00:26:03,179 --> 00:26:07,559
that are just the same that published

467
00:26:04,950 --> 00:26:09,959
the frame words are spending billions

468
00:26:07,559 --> 00:26:15,779
billions in thing machine learning and

469
00:26:09,959 --> 00:26:18,719
deep learning specifically they realize

470
00:26:15,779 --> 00:26:21,179
that to keep their place as a prevalent

471
00:26:18,719 --> 00:26:23,399
company a leading company you need to

472
00:26:21,179 --> 00:26:27,749
spend a lot or invest a lot I to do this

473
00:26:23,399 --> 00:26:30,869
resources then second reason were to be

474
00:26:27,749 --> 00:26:32,909
that not even intellectual property

475
00:26:30,869 --> 00:26:35,320
algorithms are so important for Deb

476
00:26:32,909 --> 00:26:38,110
Lennon

477
00:26:35,320 --> 00:26:39,760
not even the ideas they have what

478
00:26:38,110 --> 00:26:42,850
matters most is that you need to have

479
00:26:39,760 --> 00:26:45,070
data you need to have people on the

480
00:26:42,850 --> 00:26:48,689
other hand people who are experts every

481
00:26:45,070 --> 00:26:48,689
dis article the other day this paper sir

482
00:26:49,200 --> 00:26:56,280
Google Microsoft Twitter all together

483
00:26:53,440 --> 00:26:58,720
for the last two years they got the main

484
00:26:56,280 --> 00:27:00,840
professors that were teaching and

485
00:26:58,720 --> 00:27:04,440
lecturing in different US universities

486
00:27:00,840 --> 00:27:07,810
MIT and Stanford they are all working

487
00:27:04,440 --> 00:27:11,140
for private companies such as Google or

488
00:27:07,810 --> 00:27:16,240
Facebook so this is a problem the

489
00:27:11,140 --> 00:27:18,970
pioneers oh pioneers for leap deep

490
00:27:16,240 --> 00:27:21,310
learning all those professors that hold

491
00:27:18,970 --> 00:27:22,840
a chair work in the private sector and I

492
00:27:21,310 --> 00:27:25,960
guess this will be a problem because we

493
00:27:22,840 --> 00:27:29,740
will find some scarcity of people with

494
00:27:25,960 --> 00:27:37,060
the skills to understand the basis of

495
00:27:29,740 --> 00:27:39,370
deep learning one of the solutions and

496
00:27:37,060 --> 00:27:42,010
well when they realize this problem

497
00:27:39,370 --> 00:27:43,989
assisted and built open artifice

498
00:27:42,010 --> 00:27:51,010
intelligence which is an nonprofit

499
00:27:43,990 --> 00:27:53,920
organization trying to release as much

500
00:27:51,010 --> 00:27:55,870
as they can so Google Facebook do not

501
00:27:53,920 --> 00:28:02,620
have such a competitive edge ahead of

502
00:27:55,870 --> 00:28:06,159
others especially because well I don't

503
00:28:02,620 --> 00:28:09,070
agree with I love maths but it is said

504
00:28:06,160 --> 00:28:12,210
that for the at some point for the next

505
00:28:09,070 --> 00:28:16,480
ten years they will be able to create an

506
00:28:12,210 --> 00:28:17,890
artificial intelligence and what is not

507
00:28:16,480 --> 00:28:21,000
want it is to have it just one single

508
00:28:17,890 --> 00:28:24,030
company controlling what they say I

509
00:28:21,000 --> 00:28:27,160
think we're far away from that problem

510
00:28:24,030 --> 00:28:29,530
this might bring about from the point of

511
00:28:27,160 --> 00:28:32,590
view of cybersecurity the main problems

512
00:28:29,530 --> 00:28:35,710
we come across are that we don't have

513
00:28:32,590 --> 00:28:37,899
enough people who are skilled to work in

514
00:28:35,710 --> 00:28:39,940
cyber security this is one of the

515
00:28:37,900 --> 00:28:42,160
features or characteristics that we

516
00:28:39,940 --> 00:28:43,930
share with machine machine learning as

517
00:28:42,160 --> 00:28:46,090
we've just seen there are only a few

518
00:28:43,930 --> 00:28:47,850
people who are fully trained in machine

519
00:28:46,090 --> 00:28:52,049
learning and deep learning us

520
00:28:47,850 --> 00:28:54,570
to claim so what about those people who

521
00:28:52,049 --> 00:28:56,549
have training both in cyber security and

522
00:28:54,570 --> 00:28:58,649
machine learning that would be a unicorn

523
00:28:56,549 --> 00:29:02,490
actually if you have a chance when you

524
00:28:58,650 --> 00:29:04,799
go back home just go and study machine

525
00:29:02,490 --> 00:29:06,750
learning because you already have these

526
00:29:04,799 --> 00:29:09,120
aside like cyber security concepts

527
00:29:06,750 --> 00:29:11,549
clears because I promise you you if

528
00:29:09,120 --> 00:29:15,570
you've got both skill sets you will not

529
00:29:11,549 --> 00:29:22,350
be missing your job within interview in

530
00:29:15,570 --> 00:29:25,020
the next few years this is great we have

531
00:29:22,350 --> 00:29:26,459
neural networks that will solve all the

532
00:29:25,020 --> 00:29:29,039
problems in the world and it all sounds

533
00:29:26,460 --> 00:29:31,140
nice and MBA tip for but from the point

534
00:29:29,039 --> 00:29:32,908
of view of cyber security when we follow

535
00:29:31,140 --> 00:29:35,549
this kind of algorithms we need to be

536
00:29:32,909 --> 00:29:37,679
very careful there is a series of

537
00:29:35,549 --> 00:29:45,240
challenges that we need to overcome

538
00:29:37,679 --> 00:29:46,530
before we move into production the main

539
00:29:45,240 --> 00:29:48,570
problem from the point of view of

540
00:29:46,530 --> 00:29:50,610
cybersecurity that we don't have so many

541
00:29:48,570 --> 00:29:55,080
data sets available to train this kind

542
00:29:50,610 --> 00:29:57,178
of algorithms we don't have a data set

543
00:29:55,080 --> 00:29:59,908
saying this is all the tags and this is

544
00:29:57,179 --> 00:30:03,559
all non attacks it is very difficult to

545
00:29:59,909 --> 00:30:07,320
have access to that kind of information

546
00:30:03,559 --> 00:30:09,570
secondly they don't have the proper

547
00:30:07,320 --> 00:30:11,158
balance those those incidents from the

548
00:30:09,570 --> 00:30:13,740
point of view of data set if you're

549
00:30:11,159 --> 00:30:16,830
classifying you're comparing cut and

550
00:30:13,740 --> 00:30:18,390
dark you can have a hundred thousand

551
00:30:16,830 --> 00:30:21,030
pictures of dogs a hundred pictures of

552
00:30:18,390 --> 00:30:24,539
cards problem is for cybersecurity you

553
00:30:21,030 --> 00:30:28,379
get an attack out of a a hundred million

554
00:30:24,539 --> 00:30:30,960
valid queries so it is very unbalanced

555
00:30:28,380 --> 00:30:33,750
and it tends not to be the intends to be

556
00:30:30,960 --> 00:30:35,760
a problem for algorithm training you

557
00:30:33,750 --> 00:30:39,720
need to use much more time to make sure

558
00:30:35,760 --> 00:30:45,210
that there will not be false positives

559
00:30:39,720 --> 00:30:48,120
or false negatives the post- false

560
00:30:45,210 --> 00:30:52,140
positive ratio you need for its security

561
00:30:48,120 --> 00:30:58,290
product needs to be very loved if not as

562
00:30:52,140 --> 00:30:59,580
we said with target they had a over the

563
00:30:58,290 --> 00:31:01,049
dashboard with a hundred thousand

564
00:30:59,580 --> 00:31:03,059
warnings but they did

565
00:31:01,049 --> 00:31:06,210
no which ones were the significant ones

566
00:31:03,059 --> 00:31:11,450
because of false positives the other

567
00:31:06,210 --> 00:31:11,450
problem would be what we said these

568
00:31:11,989 --> 00:31:18,600
learning this one short learning when we

569
00:31:14,759 --> 00:31:20,639
are kids we see that next time we see a

570
00:31:18,600 --> 00:31:22,080
dark when we see a dog the next time we

571
00:31:20,639 --> 00:31:23,969
see a dog we know it is a dump there's

572
00:31:22,080 --> 00:31:25,799
no need for us to watch a hundred

573
00:31:23,970 --> 00:31:27,090
thousand darks to realize that the next

574
00:31:25,799 --> 00:31:30,749
one is that a problem with Karen

575
00:31:27,090 --> 00:31:34,980
algorithms is they need more than an

576
00:31:30,749 --> 00:31:36,690
example to learn and as we set for

577
00:31:34,980 --> 00:31:39,989
cybersecurity is very difficult to have

578
00:31:36,690 --> 00:31:45,210
access to that amount of data this is

579
00:31:39,989 --> 00:31:48,809
massive the other problem is that for

580
00:31:45,210 --> 00:31:51,539
deep learning is that these are black

581
00:31:48,809 --> 00:31:54,389
boxes you feed it an input and the

582
00:31:51,539 --> 00:31:58,259
arbitrary yes and no or dark her can't

583
00:31:54,389 --> 00:32:02,820
but everything going inside the model

584
00:31:58,259 --> 00:32:06,179
for did blending is a black balls but

585
00:32:02,820 --> 00:32:10,769
you displaying wine why the products

586
00:32:06,179 --> 00:32:13,679
made this decision why is like that it

587
00:32:10,769 --> 00:32:17,100
is difficult by using deep learning to

588
00:32:13,679 --> 00:32:19,769
explain why why the algorithm made a

589
00:32:17,100 --> 00:32:22,980
decision if you use this isn't making

590
00:32:19,769 --> 00:32:25,470
trees or other traditional algorithms it

591
00:32:22,980 --> 00:32:31,470
will be easier more simple because you

592
00:32:25,470 --> 00:32:35,429
will explain why and then adversarial

593
00:32:31,470 --> 00:32:41,419
examples for some models it's very

594
00:32:35,429 --> 00:32:41,419
difficulty trick to cheat the model

595
00:32:41,610 --> 00:32:50,129
I guess this will be quite

596
00:32:47,880 --> 00:32:54,480
self-explanatory you can't you tell a

597
00:32:50,130 --> 00:32:57,240
puddle of al a Labrador and fried

598
00:32:54,480 --> 00:33:02,040
chicken same without chihuahua or a

599
00:32:57,240 --> 00:33:04,980
muffin from the point of view of a

600
00:33:02,040 --> 00:33:07,678
mathematic model you know a muffin can

601
00:33:04,980 --> 00:33:09,900
look very much like a chihuahua and

602
00:33:07,679 --> 00:33:13,290
that's what it is from the point of view

603
00:33:09,900 --> 00:33:18,000
cybersecurity and malware can look a lot

604
00:33:13,290 --> 00:33:20,760
like our windows dll especially if the

605
00:33:18,000 --> 00:33:22,770
attack it does so on purpose problem

606
00:33:20,760 --> 00:33:25,230
with matching machine learning and dip

607
00:33:22,770 --> 00:33:27,090
learn and specifically is the fact that

608
00:33:25,230 --> 00:33:31,080
there are some properties where if the

609
00:33:27,090 --> 00:33:33,959
attacker is smart enough and can reverse

610
00:33:31,080 --> 00:33:39,299
the features yes by the model and built

611
00:33:33,960 --> 00:33:42,330
a similar model can littie and build

612
00:33:39,299 --> 00:33:45,570
adversarial examples to trick the model

613
00:33:42,330 --> 00:33:47,428
so when designing it you need to take it

614
00:33:45,570 --> 00:33:49,559
into account and there this very funny

615
00:33:47,429 --> 00:33:52,049
techniques where you would train a

616
00:33:49,559 --> 00:33:55,200
neural network to detect malware you

617
00:33:52,049 --> 00:33:58,620
train the network to try and trick and

618
00:33:55,200 --> 00:34:00,870
treat the other neural network so to

619
00:33:58,620 --> 00:34:03,239
each other they fight through each other

620
00:34:00,870 --> 00:34:06,000
with each other and the neural network

621
00:34:03,240 --> 00:34:09,000
learns to the extent we can't know

622
00:34:06,000 --> 00:34:12,480
whether it's been tricked or not but for

623
00:34:09,000 --> 00:34:16,109
that it takes lots of work and computing

624
00:34:12,480 --> 00:34:19,040
capability and it is complicated las

625
00:34:16,109 --> 00:34:21,299
ventajas we oportunidad que tener

626
00:34:19,040 --> 00:34:24,690
advantages and opportunities that we

627
00:34:21,300 --> 00:34:27,149
have in terms of deep learning machine

628
00:34:24,690 --> 00:34:30,240
learning machine learning and cyber

629
00:34:27,149 --> 00:34:34,368
security many of today's security

630
00:34:30,239 --> 00:34:37,469
products are based on rules and

631
00:34:34,369 --> 00:34:41,450
signatures we know what is bad and

632
00:34:37,469 --> 00:34:45,719
that's it if there is a new technique

633
00:34:41,449 --> 00:34:48,089
either automatically or manually someone

634
00:34:45,719 --> 00:34:50,819
has to tell the system that that

635
00:34:48,090 --> 00:34:53,100
technique is a bad technique but that

636
00:34:50,820 --> 00:34:54,909
will not happen anymore with machine

637
00:34:53,100 --> 00:34:59,500
learning in theory

638
00:34:54,909 --> 00:35:01,809
learning algorithm may can generate its

639
00:34:59,500 --> 00:35:04,450
own conclusions as we've seen before

640
00:35:01,809 --> 00:35:06,369
based on the number of examples so there

641
00:35:04,450 --> 00:35:10,450
will be other issues such as anti virus

642
00:35:06,369 --> 00:35:14,289
detection or anomaly detection or what

643
00:35:10,450 --> 00:35:16,990
we refer to as user behavior analysis

644
00:35:14,289 --> 00:35:19,450
user behavior analysis how do you know

645
00:35:16,990 --> 00:35:22,689
whether an employee is uploading

646
00:35:19,450 --> 00:35:25,450
photographs on to google or whether he

647
00:35:22,690 --> 00:35:27,910
is exfiltrating a database client

648
00:35:25,450 --> 00:35:31,589
database machine learning I believe can

649
00:35:27,910 --> 00:35:36,000
help out with that problem because the

650
00:35:31,589 --> 00:35:40,589
examples as well as the user behavior

651
00:35:36,000 --> 00:35:43,930
will tell us to tell what a person is

652
00:35:40,589 --> 00:35:48,549
exfiltrating data or is doing or whether

653
00:35:43,930 --> 00:35:52,240
there is any anomaly there any of the

654
00:35:48,549 --> 00:35:54,250
products or things that can be improved

655
00:35:52,240 --> 00:35:56,799
a lot is its Martha honey pot so

656
00:35:54,250 --> 00:36:00,520
deception that is to say a deception

657
00:35:56,799 --> 00:36:03,130
system it's about tramps that you put in

658
00:36:00,520 --> 00:36:05,440
your net so therefore if an attacker

659
00:36:03,130 --> 00:36:09,069
compromises your network and then if

660
00:36:05,440 --> 00:36:11,859
they connect to it to your trap is that

661
00:36:09,069 --> 00:36:14,109
because it is an attacker because usable

662
00:36:11,859 --> 00:36:15,970
not access to a suburb which is not

663
00:36:14,109 --> 00:36:18,279
accessible so we are talking about an

664
00:36:15,970 --> 00:36:21,129
attacker scanning the system and finding

665
00:36:18,279 --> 00:36:24,609
that server the same goes for files you

666
00:36:21,130 --> 00:36:26,770
may upload a fake at the client database

667
00:36:24,609 --> 00:36:29,950
do you know that if someone access it

668
00:36:26,770 --> 00:36:32,109
means that it is matthew's a month well

669
00:36:29,950 --> 00:36:34,990
because no one should be accessing that

670
00:36:32,109 --> 00:36:37,660
deep learning can improve those systems

671
00:36:34,990 --> 00:36:41,470
make them as martha and to customize

672
00:36:37,660 --> 00:36:43,868
them to the activity that is taking

673
00:36:41,470 --> 00:36:47,980
place in the network marble detection of

674
00:36:43,869 --> 00:36:50,970
course if you manage to train and

675
00:36:47,980 --> 00:36:55,390
algorithm giving it lots of examples of

676
00:36:50,970 --> 00:36:57,629
malwa and but it and no malware you will

677
00:36:55,390 --> 00:37:01,180
surely end up having a model which is

678
00:36:57,630 --> 00:37:03,640
highly predictive of malware from the

679
00:37:01,180 --> 00:37:05,529
viewpoint of attackers well we have

680
00:37:03,640 --> 00:37:08,819
talked about these from the viewpoints

681
00:37:05,529 --> 00:37:12,010
of defense for the festive viewpoints

682
00:37:08,820 --> 00:37:14,290
what happens the thing is that attackers

683
00:37:12,010 --> 00:37:16,780
can use these very same techniques and

684
00:37:14,290 --> 00:37:19,750
actually they are doing it imagine that

685
00:37:16,780 --> 00:37:21,400
an attacker built the model were the

686
00:37:19,750 --> 00:37:23,920
phishing emails that you get are

687
00:37:21,400 --> 00:37:26,980
customized for your specific because the

688
00:37:23,920 --> 00:37:28,780
model have learned information has

689
00:37:26,980 --> 00:37:31,480
learned things about you imagine that

690
00:37:28,780 --> 00:37:33,280
you're interested in photographs of a

691
00:37:31,480 --> 00:37:36,760
celebrity or because you are interested

692
00:37:33,280 --> 00:37:39,760
in cyber camp conference so if that

693
00:37:36,760 --> 00:37:43,090
algorithm gathers details information

694
00:37:39,760 --> 00:37:47,050
about you and then it generates a

695
00:37:43,090 --> 00:37:49,330
customized fishing campaign for you I

696
00:37:47,050 --> 00:37:51,070
can assure you that the percentage of

697
00:37:49,330 --> 00:37:53,620
people that we click that would open

698
00:37:51,070 --> 00:37:57,550
that email it is much much higher than

699
00:37:53,620 --> 00:38:01,740
if you sent out here general and non

700
00:37:57,550 --> 00:38:05,140
customized email and seconds

701
00:38:01,740 --> 00:38:12,970
vulnerability discover and fuzzing so

702
00:38:05,140 --> 00:38:16,089
how many of you followed the indefinite

703
00:38:12,970 --> 00:38:21,490
the challenge how many of you followed

704
00:38:16,090 --> 00:38:24,160
dark bar is government's us US

705
00:38:21,490 --> 00:38:26,080
government agency every year they did

706
00:38:24,160 --> 00:38:28,450
find a problem which is difficult to

707
00:38:26,080 --> 00:38:32,830
resolve in 2008 they launched a

708
00:38:28,450 --> 00:38:35,220
competition to build self-driving cars

709
00:38:32,830 --> 00:38:37,990
what they do is to invite the

710
00:38:35,220 --> 00:38:40,569
universities and companies to the

711
00:38:37,990 --> 00:38:44,290
compared to that competition competition

712
00:38:40,570 --> 00:38:50,140
that is held at that event so the team

713
00:38:44,290 --> 00:38:53,320
that won in two hundred 2008 were the

714
00:38:50,140 --> 00:38:56,589
ones that two or three years later build

715
00:38:53,320 --> 00:38:59,500
Google self-driving car this year they

716
00:38:56,590 --> 00:39:01,090
had a competition to create an FTF like

717
00:38:59,500 --> 00:39:02,830
the one that is being played here but

718
00:39:01,090 --> 00:39:05,680
the difference is that those who were

719
00:39:02,830 --> 00:39:08,620
competing were no humans but were but

720
00:39:05,680 --> 00:39:10,870
machines machines and models that people

721
00:39:08,620 --> 00:39:14,500
had programmed to play that CTF

722
00:39:10,870 --> 00:39:19,180
automatically what will happen Thapa is

723
00:39:14,500 --> 00:39:21,910
quite good at forecasting significant

724
00:39:19,180 --> 00:39:22,509
change in the industry they gave lots of

725
00:39:21,910 --> 00:39:24,730
importance

726
00:39:22,510 --> 00:39:27,130
of self-driving to self driving car and

727
00:39:24,730 --> 00:39:30,280
now we are seeing cars such as Tesla

728
00:39:27,130 --> 00:39:32,020
using duck technology if that part is

729
00:39:30,280 --> 00:39:34,780
saying that the use of machine learning

730
00:39:32,020 --> 00:39:37,960
and artificial intelligence in cyber

731
00:39:34,780 --> 00:39:41,650
security we are at the point where the

732
00:39:37,960 --> 00:39:44,070
self autonomous system that can play a

733
00:39:41,650 --> 00:39:48,610
CTF find vulnerabilities and patch

734
00:39:44,070 --> 00:39:50,320
vulnerabilities automatically so the

735
00:39:48,610 --> 00:39:52,390
that's not reality they created a mini

736
00:39:50,320 --> 00:39:55,450
version of an operating system obviously

737
00:39:52,390 --> 00:40:00,069
they were not competing in the same

738
00:39:55,450 --> 00:40:05,049
conditions then real attacker does but

739
00:40:00,070 --> 00:40:07,480
it's still people playing a taking part

740
00:40:05,050 --> 00:40:09,730
in the competition managed to resolve

741
00:40:07,480 --> 00:40:12,760
many of the problems people are very

742
00:40:09,730 --> 00:40:15,190
happy to say anti viruses are dead

743
00:40:12,760 --> 00:40:17,470
because we have artificial intelligence

744
00:40:15,190 --> 00:40:19,330
and that will fix everything no we

745
00:40:17,470 --> 00:40:24,040
should not cheat ourselves this is not

746
00:40:19,330 --> 00:40:27,009
the case not yet and terms of signatures

747
00:40:24,040 --> 00:40:30,670
heuristics and machine learning AV

748
00:40:27,010 --> 00:40:33,790
companies are not stupid it is not that

749
00:40:30,670 --> 00:40:36,850
new companies have arrived to use

750
00:40:33,790 --> 00:40:40,029
machine learning and to resolve a fixed

751
00:40:36,850 --> 00:40:42,130
cybersecurity many anti viruses have

752
00:40:40,030 --> 00:40:44,140
been using machine learning for a long

753
00:40:42,130 --> 00:40:45,760
time to generate heuristics and

754
00:40:44,140 --> 00:40:48,089
sometimes they use a combination of

755
00:40:45,760 --> 00:40:51,040
machine learning heuristics and

756
00:40:48,090 --> 00:40:56,260
signatures and another reason is that

757
00:40:51,040 --> 00:40:58,420
the use of neuronal neuronal networks is

758
00:40:56,260 --> 00:41:00,880
not adequate because you need lots of

759
00:40:58,420 --> 00:41:05,140
performance imagine that you have to the

760
00:41:00,880 --> 00:41:08,410
text attack seeing the net and analyze a

761
00:41:05,140 --> 00:41:10,390
hundred gigas per second and using a

762
00:41:08,410 --> 00:41:13,629
neural network is very complex because

763
00:41:10,390 --> 00:41:16,480
it will and it will be high performance

764
00:41:13,630 --> 00:41:19,240
it would be it will consume lots of

765
00:41:16,480 --> 00:41:23,080
resources so if you know which are the

766
00:41:19,240 --> 00:41:25,120
resources which are bad use signature

767
00:41:23,080 --> 00:41:28,150
signatures and do not go into neural

768
00:41:25,120 --> 00:41:30,460
networks just because it is trendy so

769
00:41:28,150 --> 00:41:33,430
this is what I want to save first focus

770
00:41:30,460 --> 00:41:35,970
on the problem not on technology there

771
00:41:33,430 --> 00:41:38,879
are many startups and we see them

772
00:41:35,970 --> 00:41:41,609
day on silicon valley is like oh we know

773
00:41:38,880 --> 00:41:44,070
a lot about machine learning and we have

774
00:41:41,609 --> 00:41:46,109
created this startup and we're going to

775
00:41:44,070 --> 00:41:49,080
resolve of the problems of the world and

776
00:41:46,109 --> 00:41:50,609
then I asked well what is the problem

777
00:41:49,080 --> 00:41:52,560
that you resolve for the user and say oh

778
00:41:50,609 --> 00:41:54,119
no no it's a neural network and then we

779
00:41:52,560 --> 00:41:55,529
will focus on the problem and I said

780
00:41:54,119 --> 00:41:58,109
don't you think it should be the other

781
00:41:55,530 --> 00:42:00,480
way round first you find a problem to

782
00:41:58,109 --> 00:42:02,940
detect the problem that uses half and

783
00:42:00,480 --> 00:42:05,609
then you choose the right technology to

784
00:42:02,940 --> 00:42:10,310
resolve that problem do not put

785
00:42:05,609 --> 00:42:10,310
technology first put the problem fast

786
00:42:19,690 --> 00:42:28,930
and the last point that I want to refer

787
00:42:24,590 --> 00:42:32,240
to stunt Hawking we as an industry are

788
00:42:28,930 --> 00:42:36,140
doing it very badly in terms of

789
00:42:32,240 --> 00:42:39,740
marketing so you know that every time

790
00:42:36,140 --> 00:42:44,060
there is a nude vulnerability we built

791
00:42:39,740 --> 00:42:46,459
the logo we create a website this is my

792
00:42:44,060 --> 00:42:48,830
favorite vulnerability I found it on the

793
00:42:46,460 --> 00:42:51,950
Internet is the first toilets with the

794
00:42:48,830 --> 00:42:57,410
vulnerability with se ve have you ever

795
00:42:51,950 --> 00:43:00,319
found that your Bluetooth key by default

796
00:42:57,410 --> 00:43:03,080
but 000 if someone is using the toilet I

797
00:43:00,320 --> 00:43:05,000
don't know why the toilet has bluetooth

798
00:43:03,080 --> 00:43:07,700
do not ask me that I just don't know

799
00:43:05,000 --> 00:43:10,730
someone found a vulnerability and what

800
00:43:07,700 --> 00:43:12,919
is most important that lots of hot was

801
00:43:10,730 --> 00:43:15,980
given to it and they said the attack

802
00:43:12,920 --> 00:43:18,290
vector both Bluetooth and have someone

803
00:43:15,980 --> 00:43:20,000
is using the toilet I can cause

804
00:43:18,290 --> 00:43:24,529
discomfort because I flushed the toilet

805
00:43:20,000 --> 00:43:28,550
or I may open and close the toilet lid

806
00:43:24,530 --> 00:43:32,540
and I said my calls and this is what I

807
00:43:28,550 --> 00:43:35,090
wanted to explain in last two years it

808
00:43:32,540 --> 00:43:37,610
has become really trendy to discover and

809
00:43:35,090 --> 00:43:40,370
vulnerability to build a logo free to

810
00:43:37,610 --> 00:43:42,260
publish it and to say well all promise

811
00:43:40,370 --> 00:43:45,049
of the world and over and they have

812
00:43:42,260 --> 00:43:47,860
vulnerabilities every single day and

813
00:43:45,050 --> 00:43:50,480
this is just an example of the

814
00:43:47,860 --> 00:43:56,150
advertising that is made to some of our

815
00:43:50,480 --> 00:43:58,130
abilities had a heart bleed it was one

816
00:43:56,150 --> 00:44:01,700
of the first ones it will had a huge

817
00:43:58,130 --> 00:44:06,050
impact lots of hype and the saying went

818
00:44:01,700 --> 00:44:09,350
for shell shock and for ghosts then bad

819
00:44:06,050 --> 00:44:11,210
luck it logo was created a website and

820
00:44:09,350 --> 00:44:12,920
then they said well the world we be over

821
00:44:11,210 --> 00:44:14,420
then the end of awesome and in the

822
00:44:12,920 --> 00:44:16,910
middle you really need to have a highly

823
00:44:14,420 --> 00:44:20,120
sophisticated attack vector not

824
00:44:16,910 --> 00:44:22,910
effective very many organizations the

825
00:44:20,120 --> 00:44:27,859
same goes for poodle or for others of

826
00:44:22,910 --> 00:44:30,980
freak when you see on the media and that

827
00:44:27,860 --> 00:44:33,440
read the small letter sometimes it seems

828
00:44:30,980 --> 00:44:36,050
the world is about to be over but

829
00:44:33,440 --> 00:44:39,800
actually doesn't have the impact it

830
00:44:36,050 --> 00:44:42,830
looks to the house so the same goes for

831
00:44:39,800 --> 00:44:46,940
malware mar y campaigns there have been

832
00:44:42,830 --> 00:44:50,420
a very much present on the media they

833
00:44:46,940 --> 00:44:54,140
have a real impact such as claimed media

834
00:44:50,420 --> 00:44:56,630
and for instances nut Stuxnet had lots

835
00:44:54,140 --> 00:44:59,509
of impact because of the uranium

836
00:44:56,630 --> 00:45:01,070
enrichment facilities in Iran but we

837
00:44:59,510 --> 00:45:03,560
have other things that I from somewhere

838
00:45:01,070 --> 00:45:05,060
lots of hype given to run somewhere but

839
00:45:03,560 --> 00:45:07,850
the level of complexity and

840
00:45:05,060 --> 00:45:10,850
sophistication is null the same goes for

841
00:45:07,850 --> 00:45:13,040
me I the botnet that was about to bring

842
00:45:10,850 --> 00:45:15,980
down the internet the other day this

843
00:45:13,040 --> 00:45:19,250
level of sophistication well it is non

844
00:45:15,980 --> 00:45:21,290
existence I kidding at home did it some

845
00:45:19,250 --> 00:45:24,410
more actually it was in the news

846
00:45:21,290 --> 00:45:27,080
yesterday this is a campaign apparently

847
00:45:24,410 --> 00:45:29,899
coming from Eden and then it attacked

848
00:45:27,080 --> 00:45:33,109
Saudi Arabia and they think that it did

849
00:45:29,900 --> 00:45:35,390
was deleting the heart raced disk no

850
00:45:33,109 --> 00:45:37,220
other complexity and the ones that are

851
00:45:35,390 --> 00:45:41,150
most important are the ones that show

852
00:45:37,220 --> 00:45:44,750
bottom right that is to say attackers or

853
00:45:41,150 --> 00:45:48,680
techniques very complex with the high

854
00:45:44,750 --> 00:45:52,100
impact however they are no very much

855
00:45:48,680 --> 00:45:54,049
discussed and you may notice that all

856
00:45:52,100 --> 00:45:56,420
those threats our intelligence services

857
00:45:54,050 --> 00:45:58,869
that their job if I am an intelligent

858
00:45:56,420 --> 00:46:01,310
service i'm going to use highly

859
00:45:58,869 --> 00:46:02,930
sophisticated techniques and I'm going

860
00:46:01,310 --> 00:46:05,750
to make everything possible so that the

861
00:46:02,930 --> 00:46:07,940
media doesn't talk about it so Francis

862
00:46:05,750 --> 00:46:11,030
if I'm a spy and if I am the media I'm

863
00:46:07,940 --> 00:46:13,430
not doing a good job so these are these

864
00:46:11,030 --> 00:46:19,910
ones are the most complicated the most

865
00:46:13,430 --> 00:46:22,430
dangerous so as I say to finish off I'd

866
00:46:19,910 --> 00:46:25,460
like to ask you a favor from you I know

867
00:46:22,430 --> 00:46:30,669
that many of you are students you are

868
00:46:25,460 --> 00:46:33,980
the new generation those of you who are

869
00:46:30,670 --> 00:46:37,609
you have the chance the opportunity to

870
00:46:33,980 --> 00:46:38,960
start from scratch and to fix all the

871
00:46:37,609 --> 00:46:43,610
problems that we have we as a society

872
00:46:38,960 --> 00:46:48,530
will be seeing the use of drones Bravo's

873
00:46:43,610 --> 00:46:52,490
in general in genetic engineering so

874
00:46:48,530 --> 00:46:55,520
very very many advances here we have to

875
00:46:52,490 --> 00:46:59,509
help protect all these systems and we

876
00:46:55,520 --> 00:47:02,509
have to help so that they are designed

877
00:46:59,510 --> 00:47:05,120
with security in mind and I ask you a

878
00:47:02,510 --> 00:47:08,000
favor if I would if I am to see you in

879
00:47:05,120 --> 00:47:11,270
10 days and i hope that machines have

880
00:47:08,000 --> 00:47:13,310
not stolen the work you work from you

881
00:47:11,270 --> 00:47:16,160
your job from you but the only thing

882
00:47:13,310 --> 00:47:18,830
that I just don't want to happen is that

883
00:47:16,160 --> 00:47:20,420
i want to adjust don't want to go back

884
00:47:18,830 --> 00:47:23,390
from the beach because my drobo is

885
00:47:20,420 --> 00:47:26,840
asking me to update it when you program

886
00:47:23,390 --> 00:47:29,480
robots please bear security in mind

887
00:47:26,840 --> 00:47:31,760
right from the start in the design thank

888
00:47:29,480 --> 00:47:35,059
you very much for your attention

889
00:47:31,760 --> 00:47:35,059
[Applause]

