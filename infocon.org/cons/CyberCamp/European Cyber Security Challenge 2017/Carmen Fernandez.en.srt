1
00:00:14,270 --> 00:00:20,730
because they mean all girls will be

2
00:00:17,630 --> 00:00:23,310
listening to us in this language so

3
00:00:20,730 --> 00:00:25,439
thank you for the introduction so I must

4
00:00:23,310 --> 00:00:28,080
say before the I start with the contents

5
00:00:25,439 --> 00:00:31,948
of my presentation that is true we are

6
00:00:28,080 --> 00:00:35,970
not many women in computer science in

7
00:00:31,949 --> 00:00:39,510
Cohen cybersecurity but we are quite a

8
00:00:35,970 --> 00:00:53,280
lot and specially in Spain it's not such

9
00:00:39,510 --> 00:00:55,440
a small number so so let's start you

10
00:00:53,280 --> 00:01:02,879
have I'm sure you have been seeing all

11
00:00:55,440 --> 00:01:06,600
during the day all the presentations

12
00:01:02,879 --> 00:01:09,330
about cybersecurity hacking source

13
00:01:06,600 --> 00:01:14,539
malicious code oh whatever

14
00:01:09,330 --> 00:01:17,700
and I'm going to talk to you about very

15
00:01:14,540 --> 00:01:20,460
related a very concept very related to

16
00:01:17,700 --> 00:01:22,829
cyber security which is inside cyber

17
00:01:20,460 --> 00:01:26,809
security as well but we could say it's

18
00:01:22,829 --> 00:01:29,669
like top-level concept that involves

19
00:01:26,810 --> 00:01:38,359
most of the security in assisting which

20
00:01:29,670 --> 00:01:38,359
is trust and how we can build trust so

21
00:01:38,780 --> 00:01:44,640
what we are going to see we are going to

22
00:01:42,329 --> 00:01:48,508
send telling you that most of the work

23
00:01:44,640 --> 00:01:52,979
is done in the context of European

24
00:01:48,509 --> 00:01:58,109
training Network on cyber security then

25
00:01:52,979 --> 00:02:00,719
I will tell you why we need trust how we

26
00:01:58,109 --> 00:02:04,640
can build trust into the software

27
00:02:00,719 --> 00:02:11,420
development lifecycle of services

28
00:02:04,640 --> 00:02:14,040
finally the conclusions so I think

29
00:02:11,420 --> 00:02:16,530
having seen all of them but I will say

30
00:02:14,040 --> 00:02:19,230
most of the presentations had been from

31
00:02:16,530 --> 00:02:22,920
the industry side so they are all

32
00:02:19,230 --> 00:02:24,840
telling you that what they want what how

33
00:02:22,920 --> 00:02:27,390
they do their things what is the

34
00:02:24,840 --> 00:02:29,160
interesting for them but

35
00:02:27,390 --> 00:02:33,299
cybersecurity is also done at the

36
00:02:29,160 --> 00:02:35,520
academic level so it is very good it is

37
00:02:33,300 --> 00:02:39,990
the practical sight of cybersecurity but

38
00:02:35,520 --> 00:02:44,250
you need the academic level at least to

39
00:02:39,990 --> 00:02:46,860
start with a Tsang career so you had to

40
00:02:44,250 --> 00:02:49,560
have your degree easy it is important to

41
00:02:46,860 --> 00:02:56,040
have some cybersecurity background and

42
00:02:49,560 --> 00:02:59,520
in some cases is good to have a PhD so

43
00:02:56,040 --> 00:03:02,850
and this could give you some specific

44
00:02:59,520 --> 00:03:05,850
training on some specific topic so the

45
00:03:02,850 --> 00:03:10,140
project next is about fostering

46
00:03:05,850 --> 00:03:12,030
cybersecurity research in three

47
00:03:10,140 --> 00:03:15,238
different blocks so we talked about risk

48
00:03:12,030 --> 00:03:20,390
management information exchange that is

49
00:03:15,239 --> 00:03:23,850
were what my talk will fall today and so

50
00:03:20,390 --> 00:03:27,299
cyber security operations systems and

51
00:03:23,850 --> 00:03:31,410
management so what we do is we train

52
00:03:27,300 --> 00:03:35,970
some early stage researchers to attain a

53
00:03:31,410 --> 00:03:40,290
PhD and as I said industry is very

54
00:03:35,970 --> 00:03:43,140
important so we don't only consider the

55
00:03:40,290 --> 00:03:45,690
academic aspect but we tried that this

56
00:03:43,140 --> 00:03:50,548
the training is also done at the

57
00:03:45,690 --> 00:03:53,190
academic the industry level so dance the

58
00:03:50,549 --> 00:03:57,420
introduction of what is important in

59
00:03:53,190 --> 00:04:02,400
cyber security at academic level let's

60
00:03:57,420 --> 00:04:05,839
say why do we need trust so Trust is a

61
00:04:02,400 --> 00:04:07,230
concept that you use in your everyday

62
00:04:05,840 --> 00:04:12,120
life

63
00:04:07,230 --> 00:04:16,310
I suppose this example that you this the

64
00:04:12,120 --> 00:04:21,478
case that there is someone who is

65
00:04:16,310 --> 00:04:26,220
jumping back he is sure and let's see

66
00:04:21,478 --> 00:04:28,530
you know they were in there before he's

67
00:04:26,220 --> 00:04:32,970
sure that someone is going to pick him

68
00:04:28,530 --> 00:04:36,090
up so he trusts and he makes a statement

69
00:04:32,970 --> 00:04:40,610
on andris on his mind saying well I

70
00:04:36,090 --> 00:04:40,609
trust these people is going to hold me

71
00:04:40,990 --> 00:04:49,000
but what happens if we don't know what

72
00:04:45,789 --> 00:04:50,889
is the other side is or the guy has to

73
00:04:49,000 --> 00:04:53,320
jump on the other one is sailing here

74
00:04:50,889 --> 00:04:56,530
yes jump on will guide you but he

75
00:04:53,320 --> 00:05:00,849
doesn't know what is what is on the

76
00:04:56,530 --> 00:05:04,419
ground where he is going to fall so in

77
00:05:00,850 --> 00:05:10,270
this case he places a lot of trust in

78
00:05:04,419 --> 00:05:12,639
this other guy and that's what you

79
00:05:10,270 --> 00:05:17,590
really do when you use your social

80
00:05:12,639 --> 00:05:22,800
networks we all use all most of us use

81
00:05:17,590 --> 00:05:27,698
whatsapp Twitter snapchat whatever we

82
00:05:22,800 --> 00:05:32,889
already fault trust on the others on the

83
00:05:27,699 --> 00:05:39,009
others way that we interact with but are

84
00:05:32,889 --> 00:05:44,979
we show who we are talking to we never

85
00:05:39,009 --> 00:05:48,880
know who is on the other side so to make

86
00:05:44,979 --> 00:05:52,060
a parallelism with real life we need to

87
00:05:48,880 --> 00:05:55,210
have another extra services on the top

88
00:05:52,060 --> 00:05:58,270
of cyber security to to protect

89
00:05:55,210 --> 00:06:01,270
ourselves for interactions with on the

90
00:05:58,270 --> 00:06:06,909
other side for who is on the other side

91
00:06:01,270 --> 00:06:11,320
in any system so as following the social

92
00:06:06,909 --> 00:06:15,610
life or the normal everyday life will

93
00:06:11,320 --> 00:06:18,130
say that Trust is personally unique and

94
00:06:15,610 --> 00:06:21,220
temporal because it depends on on time

95
00:06:18,130 --> 00:06:22,990
sometimes you can trust someone and then

96
00:06:21,220 --> 00:06:24,400
the next moment this person is not

97
00:06:22,990 --> 00:06:27,220
trusted any longer

98
00:06:24,400 --> 00:06:30,008
so it is a unique and temporal

99
00:06:27,220 --> 00:06:34,720
expectation that the trustor place is on

100
00:06:30,009 --> 00:06:40,800
a trustee regarding some interaction

101
00:06:34,720 --> 00:06:44,740
that has to happen between them so for

102
00:06:40,800 --> 00:06:52,479
doing this at the any system we need

103
00:06:44,740 --> 00:06:54,260
what we call trust model that

104
00:06:52,479 --> 00:06:57,909
establishes our relationship

105
00:06:54,260 --> 00:07:01,900
in between a truster and a trustee and

106
00:06:57,910 --> 00:07:05,630
sources of this model how you can

107
00:07:01,900 --> 00:07:09,739
calculate or computed this Transvaal use

108
00:07:05,630 --> 00:07:13,310
could be with some claims are done about

109
00:07:09,740 --> 00:07:17,900
the trustee like how it has behaved in

110
00:07:13,310 --> 00:07:21,770
the past how you feel is going to behave

111
00:07:17,900 --> 00:07:25,400
some kind of predictability or security

112
00:07:21,770 --> 00:07:28,419
itself with all this information we kind

113
00:07:25,400 --> 00:07:37,010
of put them together and come up with a

114
00:07:28,420 --> 00:07:42,020
value of trust or reputation so what we

115
00:07:37,010 --> 00:07:48,969
do is well most of the times if you want

116
00:07:42,020 --> 00:07:51,680
to have trust model what we do is we

117
00:07:48,970 --> 00:07:55,400
have thing in a patch resolution this

118
00:07:51,680 --> 00:07:58,790
means that you you have an application

119
00:07:55,400 --> 00:08:01,520
and then you say well it would be very

120
00:07:58,790 --> 00:08:04,820
interested so for these applications for

121
00:08:01,520 --> 00:08:08,840
to have a trust model address or a

122
00:08:04,820 --> 00:08:12,050
reputation model for instance this they

123
00:08:08,840 --> 00:08:16,789
are not available in most cases for

124
00:08:12,050 --> 00:08:20,300
instance like a very popular case of a

125
00:08:16,790 --> 00:08:25,760
reputation model is avais or Amazon

126
00:08:20,300 --> 00:08:28,790
ranking range of of interactions among

127
00:08:25,760 --> 00:08:34,939
the users so but this is built-in that

128
00:08:28,790 --> 00:08:37,909
errors in the at hot model but the ideal

129
00:08:34,940 --> 00:08:40,250
thing that would be the other way around

130
00:08:37,909 --> 00:08:42,110
because in this kind of scenario if you

131
00:08:40,250 --> 00:08:44,300
have the application and then once

132
00:08:42,110 --> 00:08:48,190
application is running you are trying to

133
00:08:44,300 --> 00:08:53,300
insert their attribute Asian model it

134
00:08:48,190 --> 00:08:57,560
will probably not work so it is better

135
00:08:53,300 --> 00:09:01,819
if we insert the trust and reputation

136
00:08:57,560 --> 00:09:05,378
model since the beginning of of the

137
00:09:01,820 --> 00:09:09,389
design of the application but

138
00:09:05,379 --> 00:09:12,639
then whoever is going to develop this

139
00:09:09,389 --> 00:09:16,419
service this trust service has a problem

140
00:09:12,639 --> 00:09:21,899
that he doesn't know how how to do it so

141
00:09:16,419 --> 00:09:27,659
there are many interactions in many many

142
00:09:21,899 --> 00:09:30,579
relationships but the the person who is

143
00:09:27,659 --> 00:09:33,059
gathering the the requirements for this

144
00:09:30,579 --> 00:09:38,758
application the requirements engineering

145
00:09:33,059 --> 00:09:45,669
doesn't have a guide of how to to do it

146
00:09:38,759 --> 00:09:48,639
so we do research and telling you this

147
00:09:45,669 --> 00:09:51,609
is at the academic level we haven't done

148
00:09:48,639 --> 00:09:58,209
any industrial testing so everything is

149
00:09:51,609 --> 00:10:01,720
academic but it works we want to have

150
00:09:58,209 --> 00:10:03,819
our research in India in between

151
00:10:01,720 --> 00:10:07,439
security in engineering and trust

152
00:10:03,819 --> 00:10:13,799
management and doing a new research

153
00:10:07,439 --> 00:10:18,179
field that we call trust engineering so

154
00:10:13,799 --> 00:10:20,589
the motivation is that we elicit the

155
00:10:18,179 --> 00:10:25,569
requirements of our trash her reputation

156
00:10:20,589 --> 00:10:30,659
framework and we develop component-based

157
00:10:25,569 --> 00:10:34,569
architecture that allows developers to

158
00:10:30,659 --> 00:10:39,479
build trust and reputation in since the

159
00:10:34,569 --> 00:10:39,478
beginning of the design of any service

160
00:10:41,159 --> 00:10:48,579
so for doing that we had to follow what

161
00:10:46,089 --> 00:10:50,589
we the security engineers do is to

162
00:10:48,579 --> 00:10:54,329
follow the software development

163
00:10:50,589 --> 00:10:56,949
lifecycle this is a composed of first

164
00:10:54,329 --> 00:10:58,959
planning of visualization what is your

165
00:10:56,949 --> 00:11:02,978
problem what is the context of all of

166
00:10:58,959 --> 00:11:05,529
your problem what you want to solve you

167
00:11:02,979 --> 00:11:09,039
know sure well you can see is then is a

168
00:11:05,529 --> 00:11:12,339
security analysis where you have all the

169
00:11:09,039 --> 00:11:15,789
requirements of your system then there

170
00:11:12,339 --> 00:11:16,769
is the face of design implementation

171
00:11:15,789 --> 00:11:20,459
phase

172
00:11:16,769 --> 00:11:24,420
then you had to test that everything

173
00:11:20,459 --> 00:11:27,089
grants had a rotten time means meaning

174
00:11:24,420 --> 00:11:29,488
that if change is secure in the system

175
00:11:27,089 --> 00:11:33,059
they they see there your framework for

176
00:11:29,489 --> 00:11:35,910
trust should be able to to attach itself

177
00:11:33,059 --> 00:11:38,279
to these changes and then in the

178
00:11:35,910 --> 00:11:43,410
software development lifecycle there are

179
00:11:38,279 --> 00:11:46,439
also two extra phases which are they

180
00:11:43,410 --> 00:11:49,230
controlling the risk management and the

181
00:11:46,439 --> 00:11:52,439
assurance of the systems but these are

182
00:11:49,230 --> 00:11:59,519
phases that we are not considering ELISA

183
00:11:52,439 --> 00:12:02,579
at at the moment so they just as a

184
00:11:59,519 --> 00:12:05,519
reminder we want to integrate trust into

185
00:12:02,579 --> 00:12:08,939
the software development lifecycle this

186
00:12:05,519 --> 00:12:10,619
will help us to make early decisions

187
00:12:08,939 --> 00:12:14,730
about how Trust has to be integrated

188
00:12:10,619 --> 00:12:19,110
without any surprise at the end of the

189
00:12:14,730 --> 00:12:23,129
design of the systems that they are

190
00:12:19,110 --> 00:12:26,670
specific to the system and allows us for

191
00:12:23,129 --> 00:12:32,519
some runtime reconfiguration decisions

192
00:12:26,670 --> 00:12:35,160
and this is this is very useful for

193
00:12:32,519 --> 00:12:41,089
developers so we I had to remind that

194
00:12:35,160 --> 00:12:43,920
this system is designed for developers

195
00:12:41,089 --> 00:12:48,029
what we are doing is to provide them

196
00:12:43,920 --> 00:12:53,459
with methodologies and tools how to to

197
00:12:48,029 --> 00:12:57,179
do this task of trust so let's start for

198
00:12:53,459 --> 00:13:04,199
the beginning from the beginning of the

199
00:12:57,179 --> 00:13:06,660
timings not raining what so in the

200
00:13:04,199 --> 00:13:09,569
planning of this first of all we had one

201
00:13:06,660 --> 00:13:13,679
we had to analyze what recei so then

202
00:13:09,569 --> 00:13:16,759
then this will give us all the the ideas

203
00:13:13,679 --> 00:13:20,500
of what is involved in trust

204
00:13:16,759 --> 00:13:23,720
usually in constants of

205
00:13:20,500 --> 00:13:27,130
of a trust or an atrocity some person

206
00:13:23,720 --> 00:13:32,450
who trusts and someone who is trusted

207
00:13:27,130 --> 00:13:36,110
then for the an example of how we can do

208
00:13:32,450 --> 00:13:40,190
the planning is how to use the vest the

209
00:13:36,110 --> 00:13:44,149
vest cloud provider for the design there

210
00:13:40,190 --> 00:13:47,570
are several techniques I'm going to run

211
00:13:44,149 --> 00:13:51,140
on them but they are based on threat

212
00:13:47,570 --> 00:13:54,910
analysis so how to elicit trust

213
00:13:51,140 --> 00:13:58,760
requirements for the design we can use

214
00:13:54,910 --> 00:14:00,850
UML profiles I'm not sure whether you

215
00:13:58,760 --> 00:14:04,819
are familiar for this is a very

216
00:14:00,850 --> 00:14:09,190
well-known language for the design of

217
00:14:04,820 --> 00:14:16,700
services then the development for our

218
00:14:09,190 --> 00:14:23,630
framework how we do the how we do the

219
00:14:16,700 --> 00:14:27,350
runtime verification so let's go quickly

220
00:14:23,630 --> 00:14:29,600
so let's imagine that we have some cloud

221
00:14:27,350 --> 00:14:32,180
providers and we want to choose which is

222
00:14:29,600 --> 00:14:35,870
the best one so this will be the best

223
00:14:32,180 --> 00:14:37,870
the first phase will be how to elicit

224
00:14:35,870 --> 00:14:40,820
the knowledge that we want to achieve

225
00:14:37,870 --> 00:14:44,180
then there are Sandra's factors we

226
00:14:40,820 --> 00:14:47,839
define some trust thresholds so it says

227
00:14:44,180 --> 00:14:51,579
well below these trees this threshold we

228
00:14:47,839 --> 00:14:54,019
consider this cloud provider is not

229
00:14:51,579 --> 00:14:59,029
trusted or it is not good enough for us

230
00:14:54,019 --> 00:15:02,540
below above a certain threshold is good

231
00:14:59,029 --> 00:15:08,050
enough for us then we had to perform

232
00:15:02,540 --> 00:15:13,550
some kind of calculations and

233
00:15:08,050 --> 00:15:17,089
considering some threats that are cool

234
00:15:13,550 --> 00:15:20,359
we do this analysis with comparing with

235
00:15:17,089 --> 00:15:26,949
some threats are given in clouds we can

236
00:15:20,360 --> 00:15:29,449
have some information so how the

237
00:15:26,949 --> 00:15:31,189
knowledge that we have at the beginning

238
00:15:29,449 --> 00:15:33,229
is the information that the cloud

239
00:15:31,190 --> 00:15:37,370
providers can give a sudden if this you

240
00:15:33,230 --> 00:15:39,290
Meishan comes from the SLA service level

241
00:15:37,370 --> 00:15:44,500
agreements and all these things that you

242
00:15:39,290 --> 00:15:47,329
always when you contract provider or

243
00:15:44,500 --> 00:15:54,170
telecom from provider you always say

244
00:15:47,330 --> 00:15:55,790
just saying or when you just download

245
00:15:54,170 --> 00:15:58,699
the what's up or whatever application

246
00:15:55,790 --> 00:16:01,420
you say yes as I assets so this all this

247
00:15:58,700 --> 00:16:05,090
information is giving in this essay lays

248
00:16:01,420 --> 00:16:11,750
how easy is to use the information that

249
00:16:05,090 --> 00:16:14,210
these providers give to you also what

250
00:16:11,750 --> 00:16:17,880
the information orders give a double T's

251
00:16:14,210 --> 00:16:20,500
provider so having all this information

252
00:16:17,880 --> 00:16:22,640
[Music]

253
00:16:20,500 --> 00:16:24,920
having all this information that is

254
00:16:22,640 --> 00:16:27,410
sometimes available from capillaries

255
00:16:24,920 --> 00:16:32,180
wasn't easy to get but we kind of

256
00:16:27,410 --> 00:16:35,959
achieve it we have developed work we

257
00:16:32,180 --> 00:16:38,989
have group all this information in the

258
00:16:35,960 --> 00:16:42,110
different trust what we call trust

259
00:16:38,990 --> 00:16:44,570
intervals and it depends if they the

260
00:16:42,110 --> 00:16:46,730
results from these providers fall or in

261
00:16:44,570 --> 00:16:50,090
or out these intervals their providers

262
00:16:46,730 --> 00:16:54,950
are not trusted and we have compared

263
00:16:50,090 --> 00:17:00,620
this with some we have records going to

264
00:16:54,950 --> 00:17:05,600
be quick and not I think is not easy to

265
00:17:00,620 --> 00:17:08,510
read but the the results we have

266
00:17:05,599 --> 00:17:12,169
compared a results from providers like

267
00:17:08,510 --> 00:17:14,629
Google Microsoft Apple and Amazon and

268
00:17:12,170 --> 00:17:18,800
the threats that we are considering us

269
00:17:14,630 --> 00:17:21,980
are them famous the CSI a the Cloud

270
00:17:18,800 --> 00:17:29,000
Security Alliance threats which are data

271
00:17:21,980 --> 00:17:33,200
leakage insecurity is there is a list of

272
00:17:29,000 --> 00:17:35,810
nine threats given by by them actually I

273
00:17:33,200 --> 00:17:40,400
think they are now 12 but we haven't

274
00:17:35,810 --> 00:17:45,370
analyzed the latest version so compared

275
00:17:40,400 --> 00:17:47,080
to these we say that the ones

276
00:17:45,370 --> 00:17:52,100
[Music]

277
00:17:47,080 --> 00:17:54,289
the ones that go below above the

278
00:17:52,100 --> 00:17:57,918
threshold the threshold are the blue

279
00:17:54,289 --> 00:17:59,899
lines are more addressable so if you

280
00:17:57,919 --> 00:18:01,960
compare these it might seem surprising

281
00:17:59,899 --> 00:18:06,639
but in some cases in since that

282
00:18:01,960 --> 00:18:08,740
Microsoft cloud providers have more

283
00:18:06,640 --> 00:18:12,669
[Music]

284
00:18:08,740 --> 00:18:20,389
threats about the threshold that we are

285
00:18:12,669 --> 00:18:24,019
that we are considering so a some other

286
00:18:20,389 --> 00:18:29,889
time say you have it's untrusted it's

287
00:18:24,019 --> 00:18:35,690
down in between some two entities but

288
00:18:29,889 --> 00:18:39,340
you want to calculate this final track

289
00:18:35,690 --> 00:18:45,649
so see if that's what we call some and

290
00:18:39,340 --> 00:18:47,870
transitivity so in this case we need

291
00:18:45,649 --> 00:18:51,100
kind of a transformation function that

292
00:18:47,870 --> 00:18:56,330
allows us to calculate R as in between

293
00:18:51,100 --> 00:19:00,289
Alice and Bob and it is important that

294
00:18:56,330 --> 00:19:03,668
if we consider a threat model model that

295
00:19:00,289 --> 00:19:05,929
gives us the threat level that is us

296
00:19:03,669 --> 00:19:09,309
associated with the interactions that

297
00:19:05,929 --> 00:19:15,019
they were wrong in between them

298
00:19:09,309 --> 00:19:17,389
so as a way of gathering their

299
00:19:15,019 --> 00:19:20,659
requirements we can consider a

300
00:19:17,389 --> 00:19:25,029
relationship in between trust levels and

301
00:19:20,659 --> 00:19:28,789
sensitivity levels so if this is a very

302
00:19:25,029 --> 00:19:33,620
lot of common sense so if the trust

303
00:19:28,789 --> 00:19:35,720
level is very bad and the sensitivity

304
00:19:33,620 --> 00:19:38,029
level of the information that you want

305
00:19:35,720 --> 00:19:44,120
to exchange for instance if it's a

306
00:19:38,029 --> 00:19:47,179
medical record that is very sensitive

307
00:19:44,120 --> 00:19:54,689
for the for the patient then the

308
00:19:47,179 --> 00:19:57,240
this the risk will be extreme if is in

309
00:19:54,690 --> 00:20:01,669
the contrary if the trust level is

310
00:19:57,240 --> 00:20:06,330
giving us very good but and the

311
00:20:01,669 --> 00:20:11,190
sensitivity level is very low then this

312
00:20:06,330 --> 00:20:13,049
the the threat is it's very low as well

313
00:20:11,190 --> 00:20:18,090
because it really doesn't matter if it

314
00:20:13,049 --> 00:20:21,320
is an exchange so and in an important

315
00:20:18,090 --> 00:20:26,658
thing when we exchange this kind of

316
00:20:21,320 --> 00:20:29,939
information is the privacy the privacy

317
00:20:26,659 --> 00:20:32,909
levels so imagine that you are

318
00:20:29,940 --> 00:20:36,740
exchanging information with someone in

319
00:20:32,909 --> 00:20:40,769
order to establish some trust in between

320
00:20:36,740 --> 00:20:43,950
the two entities and at some point you

321
00:20:40,769 --> 00:20:45,600
have to you are exchanging a lot of

322
00:20:43,950 --> 00:20:51,210
information and sometimes this

323
00:20:45,600 --> 00:20:54,360
information can be very private so for

324
00:20:51,210 --> 00:21:00,450
instance if you are giving if you you

325
00:20:54,360 --> 00:21:04,639
are you are just the person but at some

326
00:21:00,450 --> 00:21:07,440
points you are someone from you I am

327
00:21:04,639 --> 00:21:09,090
myself but if I want to give more

328
00:21:07,440 --> 00:21:11,519
information and can be Carmen from

329
00:21:09,090 --> 00:21:14,100
Malaga but I can be coming from Malaga

330
00:21:11,519 --> 00:21:16,879
living in such and such building that

331
00:21:14,100 --> 00:21:18,899
Street with the phone number so you

332
00:21:16,879 --> 00:21:21,449
sometimes you are giving a lot of

333
00:21:18,899 --> 00:21:23,489
information so this is a kind of

334
00:21:21,450 --> 00:21:27,710
information that you also have to

335
00:21:23,490 --> 00:21:32,120
consider when you when you do these

336
00:21:27,710 --> 00:21:40,350
trust requirements I can't do this

337
00:21:32,120 --> 00:21:47,639
because we are going to be very quick so

338
00:21:40,350 --> 00:21:49,918
a so for the design so that it was the

339
00:21:47,639 --> 00:21:51,979
previous ratio we have passed to the

340
00:21:49,919 --> 00:21:56,720
design

341
00:21:51,980 --> 00:22:05,190
to the design phase so we had to

342
00:21:56,720 --> 00:22:08,880
consider how the devices are seeing had

343
00:22:05,190 --> 00:22:10,770
a kind of what is the reputation manager

344
00:22:08,880 --> 00:22:15,510
or the reputation server that we are

345
00:22:10,770 --> 00:22:18,740
going to use how this is going to this

346
00:22:15,510 --> 00:22:25,470
is done to make that a final decision

347
00:22:18,740 --> 00:22:28,880
into the back end server so buddy and

348
00:22:25,470 --> 00:22:31,800
this the way you use is it is imagine

349
00:22:28,880 --> 00:22:34,770
that you have a lists of patients and

350
00:22:31,800 --> 00:22:37,669
they have a list of physicians and they

351
00:22:34,770 --> 00:22:42,660
had to choose the most tested one

352
00:22:37,670 --> 00:22:45,240
according to the today to their

353
00:22:42,660 --> 00:22:49,800
requirements so if these lists of

354
00:22:45,240 --> 00:22:52,590
physicians is order using this design

355
00:22:49,800 --> 00:22:56,610
that we did we introduced in the

356
00:22:52,590 --> 00:23:03,240
previous slide they these physicians are

357
00:22:56,610 --> 00:23:06,419
ordered in in order to turn a reputation

358
00:23:03,240 --> 00:23:15,840
values then the decision made by the

359
00:23:06,420 --> 00:23:20,310
patient is more informed so if we've for

360
00:23:15,840 --> 00:23:23,970
if we follow the life cycle we now

361
00:23:20,310 --> 00:23:28,139
consider I'm being a bit quick word we

362
00:23:23,970 --> 00:23:30,570
get to the implementation phase so we

363
00:23:28,140 --> 00:23:33,710
have already the developer has already

364
00:23:30,570 --> 00:23:37,590
gather all the all the requirements

365
00:23:33,710 --> 00:23:41,910
there is a designed done for the

366
00:23:37,590 --> 00:23:46,110
application and now they had to do

367
00:23:41,910 --> 00:23:51,510
through the framework the implementation

368
00:23:46,110 --> 00:23:53,280
so the implementation has to take into

369
00:23:51,510 --> 00:23:56,640
account as I said all the previous

370
00:23:53,280 --> 00:24:00,350
requirements that we have gathered a

371
00:23:56,640 --> 00:24:02,740
pass thing into the main components of

372
00:24:00,350 --> 00:24:04,719
any trust level any

373
00:24:02,740 --> 00:24:07,029
Trane's model which are they the

374
00:24:04,720 --> 00:24:09,039
entities and I think you cannot see the

375
00:24:07,029 --> 00:24:11,279
world but is the entities their

376
00:24:09,039 --> 00:24:15,940
relationships that having established

377
00:24:11,279 --> 00:24:17,970
the kind of model of operation that you

378
00:24:15,940 --> 00:24:21,929
are going to use for for instance doing

379
00:24:17,970 --> 00:24:29,980
calculating the reputation the kind of

380
00:24:21,929 --> 00:24:33,520
very variables etc so and and I know

381
00:24:29,980 --> 00:24:38,210
that this is not readable but I don't

382
00:24:33,520 --> 00:24:40,918
need to read what is inside so our

383
00:24:38,210 --> 00:24:43,899
[Music]

384
00:24:40,919 --> 00:24:47,289
implementation framework has different

385
00:24:43,899 --> 00:24:50,049
legends in a first layer we decide what

386
00:24:47,289 --> 00:24:54,279
type of model we are going to use then

387
00:24:50,049 --> 00:24:57,490
how these relationships in between the

388
00:24:54,279 --> 00:25:00,399
entities are done what are the

389
00:24:57,490 --> 00:25:03,549
interfaces variables that we use and

390
00:25:00,399 --> 00:25:11,428
then at the end the final values of the

391
00:25:03,549 --> 00:25:17,139
of the interactions so that will be a

392
00:25:11,429 --> 00:25:22,240
general key teacher of how the framework

393
00:25:17,140 --> 00:25:29,409
is used there will be translated store

394
00:25:22,240 --> 00:25:33,640
how the application is the the engine

395
00:25:29,409 --> 00:25:36,549
dispatcher which is where they formula

396
00:25:33,640 --> 00:25:40,600
that calculates the reputation is and

397
00:25:36,549 --> 00:25:42,220
all this framework goes into the

398
00:25:40,600 --> 00:25:44,320
developer who adapts the

399
00:25:42,220 --> 00:25:47,500
Assisting according to the needs of the

400
00:25:44,320 --> 00:25:50,340
requirements of the application and gets

401
00:25:47,500 --> 00:25:53,770
a final decision what is they were the

402
00:25:50,340 --> 00:26:03,689
final client see through the API

403
00:25:53,770 --> 00:26:12,549
designed for the for the client so a

404
00:26:03,690 --> 00:26:13,960
very nice example that we calculate so

405
00:26:12,549 --> 00:26:17,769
here so

406
00:26:13,960 --> 00:26:22,149
this is the the instantiation of the the

407
00:26:17,769 --> 00:26:29,590
framework that I showed you that I

408
00:26:22,149 --> 00:26:35,008
showed you before let's go a bit quickly

409
00:26:29,590 --> 00:26:38,908
so and this got to the last phase of the

410
00:26:35,009 --> 00:26:41,909
earthly life cycle which is run tank

411
00:26:38,909 --> 00:26:46,059
reconfiguration so for doing that we had

412
00:26:41,909 --> 00:26:47,950
used well-known and also true it's

413
00:26:46,059 --> 00:26:51,629
well-known but it's known by the

414
00:26:47,950 --> 00:26:57,539
research community models at one time

415
00:26:51,629 --> 00:27:00,998
meter war that is useful resign

416
00:26:57,539 --> 00:27:06,460
designing the system at real time using

417
00:27:00,999 --> 00:27:12,190
SSL fantastic system so what we did with

418
00:27:06,460 --> 00:27:14,679
this cavalry if was to insert our

419
00:27:12,190 --> 00:27:16,869
transferring work inside this one that

420
00:27:14,679 --> 00:27:21,869
allows us to change so for example

421
00:27:16,869 --> 00:27:26,709
unless I imagine that we have two

422
00:27:21,869 --> 00:27:33,039
consoles that exchange messages and we

423
00:27:26,710 --> 00:27:36,100
set up a a black list of bad words that

424
00:27:33,039 --> 00:27:38,619
are not allowed in our trust in our chat

425
00:27:36,100 --> 00:27:42,539
so in order to do that we set up our

426
00:27:38,619 --> 00:27:49,559
trans values and the system recognize

427
00:27:42,539 --> 00:27:52,509
the bad words in in real-time and if

428
00:27:49,559 --> 00:27:56,740
someone in the chat it produces this

429
00:27:52,509 --> 00:28:01,659
real this bugged words then the message

430
00:27:56,740 --> 00:28:07,559
is is rejected so this is the code we

431
00:28:01,659 --> 00:28:07,559
use or you see this code of how these

432
00:28:07,980 --> 00:28:15,399
these consoles are implemented but we

433
00:28:11,679 --> 00:28:20,710
have to try and you are this last at the

434
00:28:15,399 --> 00:28:25,510
last row so let's keep it so with this

435
00:28:20,710 --> 00:28:28,570
we have completed the life cycle of

436
00:28:25,510 --> 00:28:32,679
the design of services including trans

437
00:28:28,570 --> 00:28:34,629
into the services and not including the

438
00:28:32,679 --> 00:28:39,070
examples here but we are using for

439
00:28:34,630 --> 00:28:41,610
Internet of Things scenarios where we

440
00:28:39,070 --> 00:28:45,279
are designing then taking into account

441
00:28:41,610 --> 00:28:49,870
trans is the very beginning of their

442
00:28:45,279 --> 00:28:55,539
design and we believe it can be used it

443
00:28:49,870 --> 00:28:58,059
can be used for any kind of scenario so

444
00:28:55,539 --> 00:29:00,879
if you want to know more about what we

445
00:28:58,059 --> 00:29:04,269
do at the research level this is our

446
00:29:00,880 --> 00:29:07,120
webpage of the NYX lab the university of

447
00:29:04,269 --> 00:29:12,539
málaga we are offering four positions if

448
00:29:07,120 --> 00:29:12,539
you are interested in working with us

449
00:29:22,680 --> 00:29:24,740
you

