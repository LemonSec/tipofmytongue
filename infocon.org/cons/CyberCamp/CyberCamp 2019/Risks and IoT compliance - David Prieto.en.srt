1
00:00:01,900 --> 00:00:04,949
[Music]

2
00:00:10,010 --> 00:00:15,000
good afternoon everyone

3
00:00:12,179 --> 00:00:17,130
thank you very much for coming here and

4
00:00:15,000 --> 00:00:19,910
thank you

5
00:00:17,130 --> 00:00:23,099
in Siva for this wonderful organization

6
00:00:19,910 --> 00:00:26,279
and I would like to say hello to all

7
00:00:23,100 --> 00:00:28,400
those who are listening to us first of

8
00:00:26,279 --> 00:00:34,739
all I would like to ask a question

9
00:00:28,400 --> 00:00:40,920
honestly was in the database who read

10
00:00:34,739 --> 00:00:45,030
the terms of in Sivas website only one

11
00:00:40,920 --> 00:00:48,140
person on streaming you can also raise

12
00:00:45,030 --> 00:00:51,930
your hands because I can see you okay

13
00:00:48,140 --> 00:00:56,190
for those who didn't read it there is a

14
00:00:51,930 --> 00:00:59,100
segment of personal data protection you

15
00:00:56,190 --> 00:01:02,640
have given personal data in order to

16
00:00:59,100 --> 00:01:05,430
register to see become cyber camp and

17
00:01:02,640 --> 00:01:09,869
then you can read the rights that you

18
00:01:05,430 --> 00:01:13,830
have that you have regarding your

19
00:01:09,869 --> 00:01:16,290
personal data access limitation of

20
00:01:13,830 --> 00:01:19,080
treatment and so on so you need to be

21
00:01:16,290 --> 00:01:22,650
aware of your rights that's what we are

22
00:01:19,080 --> 00:01:26,729
going to talk about the IOT environments

23
00:01:22,650 --> 00:01:29,490
sometimes we we give data without even

24
00:01:26,729 --> 00:01:32,009
knowing it digital transformation I'm

25
00:01:29,490 --> 00:01:33,839
sure I'm not I'm not going to say

26
00:01:32,009 --> 00:01:36,540
anything new because this morning there

27
00:01:33,840 --> 00:01:39,119
were very interesting conferences on

28
00:01:36,540 --> 00:01:43,079
this topic I'm just going to say that

29
00:01:39,119 --> 00:01:45,540
according to some analysts their digital

30
00:01:43,079 --> 00:01:48,809
changes in default in the next few years

31
00:01:45,540 --> 00:01:51,750
are going to be key these changes will

32
00:01:48,810 --> 00:01:54,810
involve new business opportunities and

33
00:01:51,750 --> 00:01:57,719
of course also risks that we need to

34
00:01:54,810 --> 00:02:00,030
manage I'm going to mention only two of

35
00:01:57,719 --> 00:02:04,949
them such as artificial intelligence

36
00:02:00,030 --> 00:02:06,600
which recently is moving from a business

37
00:02:04,950 --> 00:02:09,598
environment to a home environment

38
00:02:06,600 --> 00:02:10,649
because we already have local interfaces

39
00:02:09,598 --> 00:02:13,679
with AI

40
00:02:10,649 --> 00:02:15,720
that we can use to change the TV channel

41
00:02:13,680 --> 00:02:20,400
or to make a phone call

42
00:02:15,720 --> 00:02:25,769
and the Internet of Things is a new

43
00:02:20,400 --> 00:02:31,560
paradigm enables some devices to have

44
00:02:25,769 --> 00:02:35,640
access to Internet this is going to

45
00:02:31,560 --> 00:02:39,269
generate a huge amount of data

46
00:02:35,640 --> 00:02:42,958
especially from the digitalization

47
00:02:39,269 --> 00:02:46,590
of analogical realities such as cars

48
00:02:42,959 --> 00:02:50,220
which are generating a lot of data also

49
00:02:46,590 --> 00:02:53,790
all TV platforms and human interfaces

50
00:02:50,220 --> 00:02:56,730
with technologies with which we are

51
00:02:53,790 --> 00:02:59,129
interacting everyday up to now we

52
00:02:56,730 --> 00:03:01,230
already had a huge amount of data and

53
00:02:59,129 --> 00:03:05,700
now we're going to have a tsunami of

54
00:03:01,230 --> 00:03:11,159
data thanks to the 5g which will enable

55
00:03:05,700 --> 00:03:14,220
us to have a wider bandwidth in 4G we

56
00:03:11,159 --> 00:03:19,078
could download a film in matter of

57
00:03:14,220 --> 00:03:21,359
minutes but with 5g it is going to be a

58
00:03:19,079 --> 00:03:24,989
matter of seconds another important

59
00:03:21,359 --> 00:03:27,840
feature regarding IOT is the latency for

60
00:03:24,989 --> 00:03:30,720
example we're speaking of latency

61
00:03:27,840 --> 00:03:34,500
between one and five milliseconds which

62
00:03:30,720 --> 00:03:37,700
is practically instantaneous and in the

63
00:03:34,500 --> 00:03:40,859
case of connected cars where you need

64
00:03:37,700 --> 00:03:42,720
instantanium it is very relevant or in

65
00:03:40,859 --> 00:03:47,519
the warm of I Congress there was a

66
00:03:42,720 --> 00:03:52,410
surgery operation carried out remotely

67
00:03:47,519 --> 00:03:57,019
through 5g and these leads us to this

68
00:03:52,410 --> 00:04:02,400
virtuous triangle you have a coyote as a

69
00:03:57,019 --> 00:04:05,099
big generator of data then you on the

70
00:04:02,400 --> 00:04:07,590
other hand you have a big data which is

71
00:04:05,099 --> 00:04:10,530
the element which will enable us to

72
00:04:07,590 --> 00:04:13,099
capture and analyze analyze that

73
00:04:10,530 --> 00:04:15,329
information and will help us in our

74
00:04:13,099 --> 00:04:18,089
decision making and we have the

75
00:04:15,329 --> 00:04:21,150
artificial layer which will enable us to

76
00:04:18,089 --> 00:04:24,000
make decisions regarding those data

77
00:04:21,149 --> 00:04:26,340
in other words we will be able to

78
00:04:24,000 --> 00:04:29,520
include the information that we have

79
00:04:26,340 --> 00:04:35,330
captured in the decision maker making

80
00:04:29,520 --> 00:04:39,060
process of companies as for i/o team I

81
00:04:35,330 --> 00:04:42,599
wanted to show you case of views in

82
00:04:39,060 --> 00:04:45,419
Valencia it is very appropriate to speak

83
00:04:42,600 --> 00:04:48,810
about connected cities because it is a

84
00:04:45,419 --> 00:04:52,020
point of reference in this regard it has

85
00:04:48,810 --> 00:04:55,500
a huge sensor ization regarding

86
00:04:52,020 --> 00:04:57,900
treatment of water or traffic lights you

87
00:04:55,500 --> 00:04:59,669
will have a layer of connectivity and

88
00:04:57,900 --> 00:05:02,760
you will have an aggregator where you

89
00:04:59,669 --> 00:05:06,419
can find the information and this is the

90
00:05:02,760 --> 00:05:10,320
part which is connected in our city then

91
00:05:06,419 --> 00:05:13,229
we could speak about advanced processing

92
00:05:10,320 --> 00:05:18,719
of that information where we can include

93
00:05:13,229 --> 00:05:22,229
AI into a decision making process before

94
00:05:18,720 --> 00:05:25,680
men before moving on to risks let's talk

95
00:05:22,229 --> 00:05:29,030
about the beneficial part of the of

96
00:05:25,680 --> 00:05:34,320
these because we need to mention

97
00:05:29,030 --> 00:05:38,820
technologies with a positive note in

98
00:05:34,320 --> 00:05:43,620
cities obviously with it is very easy to

99
00:05:38,820 --> 00:05:48,360
find beneficial aspects through our

100
00:05:43,620 --> 00:05:50,780
smartphones for example the tea the

101
00:05:48,360 --> 00:05:54,150
waste management water management

102
00:05:50,780 --> 00:05:59,369
lighting depending on the user's you

103
00:05:54,150 --> 00:06:02,698
read you can find up to 30 to 50 percent

104
00:05:59,370 --> 00:06:05,340
of savings and I am sure you are all

105
00:06:02,699 --> 00:06:09,840
thinking about the traffic this

106
00:06:05,340 --> 00:06:12,179
insulation will enable us to have more

107
00:06:09,840 --> 00:06:16,219
intelligent management of traffic and

108
00:06:12,180 --> 00:06:21,150
even parking obviously everything

109
00:06:16,220 --> 00:06:24,300
involves some risks we are not being

110
00:06:21,150 --> 00:06:26,989
considered as negative but just to be

111
00:06:24,300 --> 00:06:26,990
managed

112
00:06:27,289 --> 00:06:35,659
in the World Economic Forum you can see

113
00:06:29,449 --> 00:06:38,090
the likelihood of those risks the

114
00:06:35,660 --> 00:06:43,970
technological risks are those who are

115
00:06:38,090 --> 00:06:46,099
presenting a wider a greater increase so

116
00:06:43,970 --> 00:06:55,280
it seems that we need to take them

117
00:06:46,100 --> 00:07:02,720
seriously so that you see that these

118
00:06:55,280 --> 00:07:05,650
risks are real as for connected cities I

119
00:07:02,720 --> 00:07:11,419
wanted to show you some real examples

120
00:07:05,650 --> 00:07:14,599
these are from in Sivas newsletter in

121
00:07:11,419 --> 00:07:17,299
Atlanta a third of the applications used

122
00:07:14,599 --> 00:07:21,560
in the city were attacked by ransomware

123
00:07:17,300 --> 00:07:25,720
and all of that 30% 30% of them were

124
00:07:21,560 --> 00:07:29,720
critical infrastructure such as police

125
00:07:25,720 --> 00:07:34,010
police forces the ransom was not paid

126
00:07:29,720 --> 00:07:36,979
and in that case the information of from

127
00:07:34,010 --> 00:07:39,740
the police was lost another one related

128
00:07:36,979 --> 00:07:42,460
to privacy is the typical case where you

129
00:07:39,740 --> 00:07:48,560
have an endpoint with an availability

130
00:07:42,460 --> 00:07:52,820
cyber crime then the results have a

131
00:07:48,560 --> 00:07:58,220
crime that access the database with

132
00:07:52,820 --> 00:08:00,139
medical track records of 1.5 million of

133
00:07:58,220 --> 00:08:03,710
people including the prime minister of

134
00:08:00,139 --> 00:08:08,889
Singapore finally which is similar to

135
00:08:03,710 --> 00:08:18,070
the first one this is some days before

136
00:08:08,889 --> 00:08:22,699
Donald Trump's Donald Trump's

137
00:08:18,070 --> 00:08:26,360
presidential day the loss of information

138
00:08:22,699 --> 00:08:28,970
because ransomware attacked was carried

139
00:08:26,360 --> 00:08:32,630
out against Diaz video surveillance

140
00:08:28,970 --> 00:08:35,180
system of Washington DC so obviously we

141
00:08:32,630 --> 00:08:38,549
need to manage these risks but how can

142
00:08:35,179 --> 00:08:43,319
we do it in the end

143
00:08:38,549 --> 00:08:45,569
risk is consists of threat that exploits

144
00:08:43,320 --> 00:08:48,839
a vulnerability and has a consequence

145
00:08:45,570 --> 00:08:51,540
that would be the sequence and if you

146
00:08:48,839 --> 00:08:54,209
add the impact to this vulnerability

147
00:08:51,540 --> 00:08:56,969
there to this likelihood then you have

148
00:08:54,209 --> 00:08:59,550
the probability the likelihood of that

149
00:08:56,970 --> 00:09:02,029
place and then we need to take a

150
00:08:59,550 --> 00:09:08,099
decision to analyze risk and treat them

151
00:09:02,029 --> 00:09:10,800
in terms of risks these can be they are

152
00:09:08,100 --> 00:09:13,709
not only technology risks because you

153
00:09:10,800 --> 00:09:17,550
can have a reputational financial

154
00:09:13,709 --> 00:09:21,989
economic and economic risks and there

155
00:09:17,550 --> 00:09:24,479
are based different best practices or

156
00:09:21,990 --> 00:09:31,579
frameworks in order to manage different

157
00:09:24,480 --> 00:09:34,829
kinds of risks for information systems

158
00:09:31,579 --> 00:09:37,439
risk can be divided into service

159
00:09:34,829 --> 00:09:41,099
security and privacy risks sometimes

160
00:09:37,440 --> 00:09:44,990
they can be combined because cyber

161
00:09:41,100 --> 00:09:49,649
security risks are in line with

162
00:09:44,990 --> 00:09:54,690
confidentiality and integrality of

163
00:09:49,649 --> 00:09:59,100
systems however privacy is more devoted

164
00:09:54,690 --> 00:10:02,399
to the lifecycle of data sometimes they

165
00:09:59,100 --> 00:10:05,850
can be combined because it can touch

166
00:10:02,399 --> 00:10:09,180
upon the confident confidentiality of

167
00:10:05,850 --> 00:10:13,520
the data which is similar to privacy we

168
00:10:09,180 --> 00:10:19,199
could say that cyber security is based

169
00:10:13,520 --> 00:10:23,120
on compiling information that we can use

170
00:10:19,200 --> 00:10:29,550
in intelligence and sometimes these can

171
00:10:23,120 --> 00:10:33,360
involve a conflict with privacy okay so

172
00:10:29,550 --> 00:10:37,949
we have seen our scenario what is ahead

173
00:10:33,360 --> 00:10:40,860
of us we have realized we need to manage

174
00:10:37,949 --> 00:10:43,979
risks and the kind of risks and now

175
00:10:40,860 --> 00:10:49,140
we're going to talk about the cyber

176
00:10:43,980 --> 00:10:50,240
security risk in depth I wanted to show

177
00:10:49,140 --> 00:10:53,149
you an example

178
00:10:50,240 --> 00:10:55,790
of the IOT environment here on the left

179
00:10:53,149 --> 00:10:59,470
side you have the sensor ization the

180
00:10:55,790 --> 00:11:03,399
part were these scenarios virtual

181
00:10:59,470 --> 00:11:08,690
security together with physical safety

182
00:11:03,399 --> 00:11:12,680
such as smart cities lighting water

183
00:11:08,690 --> 00:11:15,380
management waste management then we have

184
00:11:12,680 --> 00:11:18,649
the communication part which links these

185
00:11:15,380 --> 00:11:20,510
devices with information collectors and

186
00:11:18,649 --> 00:11:22,149
then we would have the part of

187
00:11:20,510 --> 00:11:24,850
information processing and

188
00:11:22,149 --> 00:11:28,760
decision-making the part on the left

189
00:11:24,850 --> 00:11:34,160
part is more linked to the inner

190
00:11:28,760 --> 00:11:38,990
problems of IOT this diagram is not I

191
00:11:34,160 --> 00:11:46,399
know it is is it is not offering new new

192
00:11:38,990 --> 00:11:49,760
insights it is easy for these devices to

193
00:11:46,399 --> 00:11:53,899
be vulnerable and on the right part you

194
00:11:49,760 --> 00:11:56,300
find the IT traditional security so on

195
00:11:53,899 --> 00:11:58,640
the left part we have the security of

196
00:11:56,300 --> 00:12:01,670
the connectivity and device and on the

197
00:11:58,640 --> 00:12:05,689
right part we have the security of the

198
00:12:01,670 --> 00:12:10,300
data and threats and for both of them we

199
00:12:05,690 --> 00:12:10,300
have the risk management and compliance

200
00:12:10,390 --> 00:12:19,610
these risks were originated on the

201
00:12:16,970 --> 00:12:23,240
Internet and now we find them also on

202
00:12:19,610 --> 00:12:29,600
the Internet of thing for example the

203
00:12:23,240 --> 00:12:34,940
way that devices are being interacted in

204
00:12:29,600 --> 00:12:37,970
the IOT scenario you might notice how

205
00:12:34,940 --> 00:12:40,430
important it is to identify the devices

206
00:12:37,970 --> 00:12:42,380
which are connected the second axis is

207
00:12:40,430 --> 00:12:49,000
the visibility and the monitoring of

208
00:12:42,380 --> 00:12:53,420
security if we are talking about video I

209
00:12:49,000 --> 00:12:59,810
IT let's imagine what it is to have a

210
00:12:53,420 --> 00:13:01,130
pseudo IOT we need to monitor all the

211
00:12:59,810 --> 00:13:04,219
devices

212
00:13:01,130 --> 00:13:08,080
and finally we have the interior and

213
00:13:04,220 --> 00:13:11,360
security T we need to warranty that

214
00:13:08,080 --> 00:13:17,780
security we need to be able to measure

215
00:13:11,360 --> 00:13:21,380
how the platform works and so on as for

216
00:13:17,780 --> 00:13:25,160
the data as for beta we have

217
00:13:21,380 --> 00:13:28,880
confidentiality it must be accessible by

218
00:13:25,160 --> 00:13:33,560
the users that were given permission to

219
00:13:28,880 --> 00:13:36,020
it integrity and availability these were

220
00:13:33,560 --> 00:13:39,020
the risks according to us have a

221
00:13:36,020 --> 00:13:42,260
security if we and now we're going to

222
00:13:39,020 --> 00:13:45,199
move on to privacy and compliance and I

223
00:13:42,260 --> 00:13:47,090
wanted to tell you about regulation I am

224
00:13:45,200 --> 00:13:49,880
sure that you're thinking oh my god

225
00:13:47,090 --> 00:13:53,060
regulation that's boring but I wanted

226
00:13:49,880 --> 00:13:56,380
I'm going to show you a good example so

227
00:13:53,060 --> 00:13:59,119
that you can perfectly understand it

228
00:13:56,380 --> 00:14:02,180
some of you may look at this picture and

229
00:13:59,120 --> 00:14:04,460
think that this car was manufactured 100

230
00:14:02,180 --> 00:14:06,680
of years ago but maybe it was only 50

231
00:14:04,460 --> 00:14:09,850
years ago and this is the way we were

232
00:14:06,680 --> 00:14:12,979
traveling there were not safety belts

233
00:14:09,850 --> 00:14:16,310
children were seated were they wanted

234
00:14:12,980 --> 00:14:21,460
and so on from that point the industry

235
00:14:16,310 --> 00:14:27,560
the car industry started to manufacture

236
00:14:21,460 --> 00:14:31,670
much faster safer cars and the car

237
00:14:27,560 --> 00:14:34,250
industry realized they needed to carry

238
00:14:31,670 --> 00:14:36,290
out a risk analysis because if the power

239
00:14:34,250 --> 00:14:40,670
of the car and the speed of the car was

240
00:14:36,290 --> 00:14:44,089
going to be increased then the risks

241
00:14:40,670 --> 00:14:50,140
needed to be analyzed in order to reduce

242
00:14:44,090 --> 00:14:53,660
them that's when seatbelts appear when

243
00:14:50,140 --> 00:14:57,680
tools to help drive-in appeared and so

244
00:14:53,660 --> 00:15:01,610
on in order to reduce risk as to are

245
00:14:57,680 --> 00:15:06,280
with to reasonable levels and then the

246
00:15:01,610 --> 00:15:10,130
concept of default security appeared

247
00:15:06,280 --> 00:15:13,770
there were some brands which were using

248
00:15:10,130 --> 00:15:18,420
safety and security as an advantage

249
00:15:13,770 --> 00:15:21,680
when selling their vehicles another

250
00:15:18,420 --> 00:15:26,599
important point is the privacy products

251
00:15:21,680 --> 00:15:29,489
these refers these data come from the

252
00:15:26,600 --> 00:15:32,280
telephony edge from fundación telefónica

253
00:15:29,490 --> 00:15:35,760
and I am sure if I ask you are you

254
00:15:32,280 --> 00:15:38,250
worried of your pictures being stolen

255
00:15:35,760 --> 00:15:40,830
and everyone will raise their hands

256
00:15:38,250 --> 00:15:43,410
actually in the end we are not that

257
00:15:40,830 --> 00:15:46,440
worried I mean this is the privacy

258
00:15:43,410 --> 00:15:48,870
paradox if we are asked

259
00:15:46,440 --> 00:15:51,030
we're worried and we would say we're

260
00:15:48,870 --> 00:15:52,980
worried but in the end we're sharing

261
00:15:51,030 --> 00:15:55,439
pictures all the time in social networks

262
00:15:52,980 --> 00:15:59,370
and it is important to have that in mind

263
00:15:55,440 --> 00:16:01,830
I wanted to mention five basic

264
00:15:59,370 --> 00:16:04,650
considerations in terms of privacy in

265
00:16:01,830 --> 00:16:08,270
IOT environments first one is the flux

266
00:16:04,650 --> 00:16:12,449
of information let's imagine an IOT

267
00:16:08,270 --> 00:16:16,500
environment the information generated by

268
00:16:12,450 --> 00:16:23,390
the by sensors waste sensor a traffic

269
00:16:16,500 --> 00:16:27,030
sensor a water sensor these information

270
00:16:23,390 --> 00:16:30,390
travels through different devices so we

271
00:16:27,030 --> 00:16:33,420
need to have these end-to-end security

272
00:16:30,390 --> 00:16:37,110
who is going to manage that information

273
00:16:33,420 --> 00:16:40,920
and in which way so we need to assess

274
00:16:37,110 --> 00:16:43,670
the impact of that information you know

275
00:16:40,920 --> 00:16:50,510
that you know who can manage or not

276
00:16:43,670 --> 00:16:53,939
those data secondly we have the

277
00:16:50,510 --> 00:16:56,850
permission of precision which means only

278
00:16:53,940 --> 00:16:58,950
the person that has been been given

279
00:16:56,850 --> 00:17:03,720
permission by the owner of data can

280
00:16:58,950 --> 00:17:06,540
access that information if you are if

281
00:17:03,720 --> 00:17:08,400
you have given some data as you have

282
00:17:06,540 --> 00:17:10,889
given your personal data here in Saavik

283
00:17:08,400 --> 00:17:13,740
um you are the owner of data and only

284
00:17:10,890 --> 00:17:17,210
those whom you have given permission to

285
00:17:13,740 --> 00:17:21,150
should be able to access those data

286
00:17:17,210 --> 00:17:25,860
thirdly we need to have different

287
00:17:21,150 --> 00:17:26,510
interfaces so that owners of the attack

288
00:17:25,859 --> 00:17:29,629
can

289
00:17:26,510 --> 00:17:33,559
access that information and can exert

290
00:17:29,630 --> 00:17:37,179
their rights over those data firstly we

291
00:17:33,559 --> 00:17:46,240
need to implement different technical

292
00:17:37,179 --> 00:17:49,669
measures in data protection or from the

293
00:17:46,240 --> 00:17:55,299
elimination of personal data that's deep

294
00:17:49,669 --> 00:17:58,040
Syria anonymization finally we have

295
00:17:55,299 --> 00:18:03,260
audits and compliance you know that you

296
00:17:58,040 --> 00:18:06,980
see if we meet all the regulations there

297
00:18:03,260 --> 00:18:12,280
is a huge increase in IOT environments

298
00:18:06,980 --> 00:18:15,799
so IOT so regulation in these things is

299
00:18:12,280 --> 00:18:19,280
increasing there are two blocks one

300
00:18:15,799 --> 00:18:21,950
would be the best practices these are

301
00:18:19,280 --> 00:18:24,590
very light documents to read they do not

302
00:18:21,950 --> 00:18:27,440
have 1,000 pages do not worry the first

303
00:18:24,590 --> 00:18:29,780
one comes from NIS and it is quite

304
00:18:27,440 --> 00:18:32,350
relevant in terms of security and

305
00:18:29,780 --> 00:18:36,280
privacy the second one comes from the

306
00:18:32,350 --> 00:18:40,299
national security center of UK which

307
00:18:36,280 --> 00:18:43,370
considers risks in AI in home IOT

308
00:18:40,299 --> 00:18:47,299
environments and the third one comes

309
00:18:43,370 --> 00:18:54,860
from Anisa which has published some good

310
00:18:47,299 --> 00:18:59,540
practices in recently and i have also

311
00:18:54,860 --> 00:19:05,330
included one according to security of

312
00:18:59,540 --> 00:19:07,070
IOT these very vertical guidelines which

313
00:19:05,330 --> 00:19:09,889
are very interesting but then we are

314
00:19:07,070 --> 00:19:12,260
moving on to a compliance regulations

315
00:19:09,890 --> 00:19:15,590
that could be applied to IOT

316
00:19:12,260 --> 00:19:21,320
environments we have some general ones

317
00:19:15,590 --> 00:19:26,510
which we will touch upon and I wanted to

318
00:19:21,320 --> 00:19:34,399
highlight technical specification from

319
00:19:26,510 --> 00:19:36,879
Etsy the 103 6-4 45 which is quite

320
00:19:34,400 --> 00:19:39,450
relevant because these

321
00:19:36,880 --> 00:19:42,550
lays the foundations on future

322
00:19:39,450 --> 00:19:46,480
certification processes there is a lot

323
00:19:42,550 --> 00:19:49,570
of activity going on in regulation and

324
00:19:46,480 --> 00:19:53,050
in certification so that we know that

325
00:19:49,570 --> 00:19:57,610
those devices have been certified and do

326
00:19:53,050 --> 00:20:01,720
what they were manufactured to the for

327
00:19:57,610 --> 00:20:11,080
example device is not having default

328
00:20:01,720 --> 00:20:14,190
passwords and so on I reviewed briefly

329
00:20:11,080 --> 00:20:16,929
some of these regulations and as for

330
00:20:14,190 --> 00:20:21,610
smart cities for example there is a

331
00:20:16,930 --> 00:20:25,540
guideline from the Spanish National

332
00:20:21,610 --> 00:20:27,969
Association for data protection which

333
00:20:25,540 --> 00:20:30,820
says that previously we need to carry

334
00:20:27,970 --> 00:20:33,090
out an analysis with all the information

335
00:20:30,820 --> 00:20:37,110
fluxes the second step would be to

336
00:20:33,090 --> 00:20:42,480
assess the impact in data protection and

337
00:20:37,110 --> 00:20:45,550
finally after that analysis and impact

338
00:20:42,480 --> 00:20:48,790
evaluation we have the minimization of

339
00:20:45,550 --> 00:20:51,399
data the limitation of the conservation

340
00:20:48,790 --> 00:20:58,050
delay and the treatment of the

341
00:20:51,400 --> 00:21:01,890
information in almost anonymized way

342
00:20:58,050 --> 00:21:07,330
also we have the C e marking from the

343
00:21:01,890 --> 00:21:11,100
European Commission which certifies that

344
00:21:07,330 --> 00:21:13,659
the device or product is secure

345
00:21:11,100 --> 00:21:22,419
environmentally friendly it has several

346
00:21:13,660 --> 00:21:25,960
categories if in your IOT environment

347
00:21:22,420 --> 00:21:28,420
you you are using these kind of devices

348
00:21:25,960 --> 00:21:32,620
you need to have the C e marking

349
00:21:28,420 --> 00:21:35,680
associated to them I know the regulation

350
00:21:32,620 --> 00:21:40,439
that can be applied to the two systems

351
00:21:35,680 --> 00:21:44,910
is called in is which is you European

352
00:21:40,440 --> 00:21:50,410
regulation which can be applied in

353
00:21:44,910 --> 00:21:53,320
according to your categorization

354
00:21:50,410 --> 00:21:57,310
for example in smart cities as I was

355
00:21:53,320 --> 00:22:00,550
saying waste-treatment a water treatment

356
00:21:57,310 --> 00:22:05,379
and so on but you can also be considered

357
00:22:00,550 --> 00:22:10,419
as cloud service marketplace is dead so

358
00:22:05,380 --> 00:22:14,680
depending of your status as service

359
00:22:10,420 --> 00:22:17,710
provider you can be applied a different

360
00:22:14,680 --> 00:22:21,460
part of this regulation and its criteria

361
00:22:17,710 --> 00:22:23,320
are quite strict as for privacy I just

362
00:22:21,460 --> 00:22:27,490
wanted to mention that if there is a lot

363
00:22:23,320 --> 00:22:31,090
of regulatory even if there is a lot of

364
00:22:27,490 --> 00:22:34,900
regulatory activity in IOT we find the

365
00:22:31,090 --> 00:22:39,220
same amount of activity in privacy

366
00:22:34,900 --> 00:22:44,310
for example the iOS iOS o twenty seven

367
00:22:39,220 --> 00:22:46,630
and five five zero or the is o 2755 to

368
00:22:44,310 --> 00:22:52,210
regarding privacy management at

369
00:22:46,630 --> 00:22:56,110
companies I have also included two which

370
00:22:52,210 --> 00:22:59,190
can be applied to smart cities one of

371
00:22:56,110 --> 00:23:06,490
them is the 27th

372
00:22:59,190 --> 00:23:10,780
0:34 IOT and 27 574 smart cities finally

373
00:23:06,490 --> 00:23:13,870
this is the national regulatory system

374
00:23:10,780 --> 00:23:18,480
which can be applied to all the

375
00:23:13,870 --> 00:23:23,830
administration local regional national

376
00:23:18,480 --> 00:23:26,050
administrations here you have the

377
00:23:23,830 --> 00:23:32,230
regulation and different guidelines so

378
00:23:26,050 --> 00:23:34,960
that you can check them in order to

379
00:23:32,230 --> 00:23:37,840
conclude I would like to review what we

380
00:23:34,960 --> 00:23:40,300
have seen and I would like to draw some

381
00:23:37,840 --> 00:23:46,780
conclusions from you to think about them

382
00:23:40,300 --> 00:23:50,200
at home the first one is that they the

383
00:23:46,780 --> 00:23:53,170
risk analysis and complain analysis have

384
00:23:50,200 --> 00:23:54,470
to be seen as a positive thing because

385
00:23:53,170 --> 00:23:56,960
we

386
00:23:54,470 --> 00:24:00,830
to think about cars which are connected

387
00:23:56,960 --> 00:24:03,830
smart cities smart cars everything all

388
00:24:00,830 --> 00:24:08,870
the data that you have big given is

389
00:24:03,830 --> 00:24:13,639
going to be automated and if we comply

390
00:24:08,870 --> 00:24:17,000
these guidelines we will be more secure

391
00:24:13,639 --> 00:24:21,199
of course if risks are increasing we

392
00:24:17,000 --> 00:24:25,309
also need to increase our perspective if

393
00:24:21,200 --> 00:24:28,190
we we are adding connectivity to

394
00:24:25,309 --> 00:24:31,639
environments which were not connected

395
00:24:28,190 --> 00:24:34,519
before we need to take into account the

396
00:24:31,639 --> 00:24:39,439
interdependency between the physical and

397
00:24:34,519 --> 00:24:41,929
the virtual world so we need to be in

398
00:24:39,440 --> 00:24:48,019
connection with different elements it

399
00:24:41,929 --> 00:24:51,289
also involves to update procedures risk

400
00:24:48,019 --> 00:24:55,450
management communication policies and we

401
00:24:51,289 --> 00:24:59,269
need to incorporate all the risks

402
00:24:55,450 --> 00:25:02,000
assisting in the supply change as for

403
00:24:59,269 --> 00:25:05,059
compliance we need to understand the

404
00:25:02,000 --> 00:25:09,139
technology dimension of the elements

405
00:25:05,059 --> 00:25:11,620
with which we were working because we're

406
00:25:09,139 --> 00:25:16,580
already starting to work in IOT

407
00:25:11,620 --> 00:25:23,289
environments which are very dynamic such

408
00:25:16,580 --> 00:25:26,240
as a waste water or traffic management

409
00:25:23,289 --> 00:25:30,559
depending on the data you're processing

410
00:25:26,240 --> 00:25:35,840
you need to comply with all the

411
00:25:30,559 --> 00:25:39,590
regulation regarding it when treating

412
00:25:35,840 --> 00:25:42,289
those risks you can take different

413
00:25:39,590 --> 00:25:48,189
measures one of them which is not very

414
00:25:42,289 --> 00:25:54,950
frequent is the transfer of those risks

415
00:25:48,190 --> 00:25:57,830
and finally in to carry out those

416
00:25:54,950 --> 00:26:00,549
analysis you need to be in connection

417
00:25:57,830 --> 00:26:04,928
with different teams within

418
00:26:00,549 --> 00:26:06,540
organizations such as engineers lawyers

419
00:26:04,929 --> 00:26:09,480
protection theta

420
00:26:06,540 --> 00:26:12,870
experts and so on this is all for me I

421
00:26:09,480 --> 00:26:15,030
hope it was brief and intense and I hope

422
00:26:12,870 --> 00:26:17,879
I have given you some useful information

423
00:26:15,030 --> 00:26:19,560
feel free to ask any question I will be

424
00:26:17,880 --> 00:26:31,130
glad to answer them all thank you very

425
00:26:19,560 --> 00:26:33,629
much hello can you hear me

426
00:26:31,130 --> 00:26:39,120
congratulation for your presentation I

427
00:26:33,630 --> 00:26:41,220
Fernando the CEO of project for Q 360

428
00:26:39,120 --> 00:26:44,429
and I came here with my lawyer in order

429
00:26:41,220 --> 00:26:47,370
to see the risks we will face you have

430
00:26:44,430 --> 00:26:49,620
mentioned the Internet of Things or the

431
00:26:47,370 --> 00:26:56,850
objects which are sensor eyes and

432
00:26:49,620 --> 00:27:01,050
connected we thinking about assets which

433
00:26:56,850 --> 00:27:06,469
are not still sensor rised like a tree

434
00:27:01,050 --> 00:27:10,770
or a cat so it is evident how regulation

435
00:27:06,470 --> 00:27:13,290
is going to affect us which everything

436
00:27:10,770 --> 00:27:17,910
which is connected however what is

437
00:27:13,290 --> 00:27:26,220
connected is a only 1% of all the assets

438
00:27:17,910 --> 00:27:28,200
of smart cities yeah indeed thank you

439
00:27:26,220 --> 00:27:31,670
for your question first of all I think

440
00:27:28,200 --> 00:27:38,160
it shows how many things which are

441
00:27:31,670 --> 00:27:41,760
connected in this morning's presentation

442
00:27:38,160 --> 00:27:45,150
I think by in maths it is expected that

443
00:27:41,760 --> 00:27:49,560
in 10 years we will no longer have any

444
00:27:45,150 --> 00:27:53,070
traffic lights in line with that the

445
00:27:49,560 --> 00:27:55,500
analysis that we have carried out we are

446
00:27:53,070 --> 00:27:58,169
seeing an increase in regulatory

447
00:27:55,500 --> 00:28:02,490
activity is it a very general

448
00:27:58,170 --> 00:28:05,190
information such as the GDP are that in

449
00:28:02,490 --> 00:28:08,610
the end our general rules which are

450
00:28:05,190 --> 00:28:11,670
being applied to this field nowadays

451
00:28:08,610 --> 00:28:14,219
there is a lot of activity going on on

452
00:28:11,670 --> 00:28:18,750
connected devices

453
00:28:14,220 --> 00:28:24,539
so we need to review the regulations on

454
00:28:18,750 --> 00:28:31,110
non connected assets I think people are

455
00:28:24,539 --> 00:28:35,460
now being aware of how to apply the NIS

456
00:28:31,110 --> 00:28:38,870
regulation or the gdpr regulation any

457
00:28:35,460 --> 00:28:42,610
other question or comments or thoughts

458
00:28:38,870 --> 00:28:46,520
no then that's all thank you very much

459
00:28:42,610 --> 00:28:46,520
[Applause]

460
00:28:48,990 --> 00:28:56,339
[Music]

461
00:28:53,210 --> 00:28:56,339
[Applause]

