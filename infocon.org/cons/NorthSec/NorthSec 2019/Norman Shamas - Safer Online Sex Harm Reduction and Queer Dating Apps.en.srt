1
00:00:03,200 --> 00:00:08,580
alrights y'all you are in room 2 and you

2
00:00:06,839 --> 00:00:10,740
are about to hear a talk on say free

3
00:00:08,580 --> 00:00:13,590
online sex arm reduction in queer dating

4
00:00:10,740 --> 00:00:15,990
tips so if this was not our expectation

5
00:00:13,590 --> 00:00:18,450
now's a good time to change rooms and

6
00:00:15,990 --> 00:00:20,759
the talk will be led by norman Sherman's

7
00:00:18,450 --> 00:00:23,099
Norma Seamus is a security and privacy

8
00:00:20,759 --> 00:00:25,410
RM reduction specialist they work with

9
00:00:23,099 --> 00:00:27,840
activists globally and they have a focus

10
00:00:25,410 --> 00:00:29,059
particular focus on sex workers queer

11
00:00:27,840 --> 00:00:31,919
trans and gender non-conforming

12
00:00:29,059 --> 00:00:34,079
communities norman works as an

13
00:00:31,919 --> 00:00:36,210
independent consultant and they are a

14
00:00:34,079 --> 00:00:40,590
member of open privacy's board of

15
00:00:36,210 --> 00:00:43,470
directors so yeah before it's really

16
00:00:40,590 --> 00:00:45,150
great to be here at North sac and to

17
00:00:43,470 --> 00:00:46,920
have actually a day where we had a

18
00:00:45,150 --> 00:00:48,960
keynote that was talking about some of

19
00:00:46,920 --> 00:00:50,760
these issues of users and the talk right

20
00:00:48,960 --> 00:00:54,030
before with Alyssa talking about some of

21
00:00:50,760 --> 00:00:56,190
the ethics that are involved so I really

22
00:00:54,030 --> 00:01:00,690
appreciate that this is I'm here at this

23
00:00:56,190 --> 00:01:05,880
track in that sense and before I

24
00:01:00,690 --> 00:01:08,190
actually dive into the topics I wanted

25
00:01:05,880 --> 00:01:10,080
to start with a Content Advisory and I

26
00:01:08,190 --> 00:01:12,360
know we have the code of conduct but I

27
00:01:10,080 --> 00:01:15,120
want to just make make sure it's clear

28
00:01:12,360 --> 00:01:17,820
that this is a sex positive talk that

29
00:01:15,120 --> 00:01:19,530
focuses on marginalized communities so

30
00:01:17,820 --> 00:01:21,630
my intention is to have this be an

31
00:01:19,530 --> 00:01:25,159
inclusive space that's free from stigmas

32
00:01:21,630 --> 00:01:27,990
around the use of tech for sexuality and

33
00:01:25,159 --> 00:01:31,700
with this since I'm talking about harm

34
00:01:27,990 --> 00:01:34,740
reduction my work draws on examples of

35
00:01:31,700 --> 00:01:37,110
sex work sex education and drug use

36
00:01:34,740 --> 00:01:39,419
homelessness in sort of a broad big

37
00:01:37,110 --> 00:01:41,400
picture sense and it's there's nothing

38
00:01:39,420 --> 00:01:43,950
explicit or graphic in terms of

39
00:01:41,400 --> 00:01:45,900
discussions of sex acts or drug use but

40
00:01:43,950 --> 00:01:47,310
I want just to give people a heads up

41
00:01:45,900 --> 00:01:53,490
that that's part of what we're gonna be

42
00:01:47,310 --> 00:01:56,549
talking about so actually as Elissa

43
00:01:53,490 --> 00:01:58,439
hopefully sort of frame things I want to

44
00:01:56,549 --> 00:02:00,270
have an idea of who's thinking about the

45
00:01:58,439 --> 00:02:01,919
users in tech right now is there anyone

46
00:02:00,270 --> 00:02:05,119
in the room that's actually working or

47
00:02:01,920 --> 00:02:07,590
aimed at users so I see a couple people

48
00:02:05,119 --> 00:02:09,000
let's have like maybe one or two people

49
00:02:07,590 --> 00:02:11,479
just do a quick shout out of what

50
00:02:09,000 --> 00:02:11,479
they're doing

51
00:02:13,800 --> 00:02:19,440
here please raise your hands cuz my

52
00:02:17,370 --> 00:02:26,100
visual memory is not the best oh okay

53
00:02:19,440 --> 00:02:28,710
well I'm Florence I'm working with query

54
00:02:26,100 --> 00:02:31,829
't were basically were building website

55
00:02:28,710 --> 00:02:35,400
for queries in a feminist aching of way

56
00:02:31,830 --> 00:02:45,660
to give them at work I was online is

57
00:02:35,400 --> 00:02:47,760
pretty awesome I'm Harlan I work for the

58
00:02:45,660 --> 00:02:50,430
United States digital services and we're

59
00:02:47,760 --> 00:02:52,170
helping remember people who live in the

60
00:02:50,430 --> 00:03:00,570
u.s. better access government services

61
00:02:52,170 --> 00:03:02,310
of all kinds hi I'm Maggie I'm a Mozilla

62
00:03:00,570 --> 00:03:04,829
fellow this year and I'm also Tori's

63
00:03:02,310 --> 00:03:08,730
user advocate and I'm also working on

64
00:03:04,830 --> 00:03:10,770
anti harassment initiatives awesome yeah

65
00:03:08,730 --> 00:03:13,859
thanks everyone for who sort of shoutout

66
00:03:10,770 --> 00:03:15,390
for sharing and in part when I was

67
00:03:13,860 --> 00:03:17,550
thinking about this is that we have also

68
00:03:15,390 --> 00:03:19,500
be sorta like large categories and I'm

69
00:03:17,550 --> 00:03:21,750
not certain if everyone who sort of

70
00:03:19,500 --> 00:03:24,600
spoke up what their exact role is but we

71
00:03:21,750 --> 00:03:26,489
tend to have like UI UX designers we

72
00:03:24,600 --> 00:03:28,079
have people on the product teams that

73
00:03:26,489 --> 00:03:30,209
are thinking about features we have

74
00:03:28,080 --> 00:03:31,980
policy folks that are thinking about for

75
00:03:30,209 --> 00:03:34,830
example anti-harassment policies what

76
00:03:31,980 --> 00:03:36,840
they look like but the security team is

77
00:03:34,830 --> 00:03:39,120
generally not thinking about the user or

78
00:03:36,840 --> 00:03:41,400
if they are their thing about the user

79
00:03:39,120 --> 00:03:43,140
in a way that might not be the most

80
00:03:41,400 --> 00:03:47,280
positive you might be thinking about the

81
00:03:43,140 --> 00:03:49,470
user as a potentially malicious actor on

82
00:03:47,280 --> 00:03:53,100
a trusted network using language like

83
00:03:49,470 --> 00:03:54,630
that insider threat maybe right that's

84
00:03:53,100 --> 00:03:57,650
the sort of language that security folks

85
00:03:54,630 --> 00:04:00,329
use so the question really comes down to

86
00:03:57,650 --> 00:04:04,350
who's thinking about the users safety

87
00:04:00,330 --> 00:04:06,540
security and privacy in tech and this is

88
00:04:04,350 --> 00:04:09,780
the question that I've been interested

89
00:04:06,540 --> 00:04:11,760
in with my work in tech in particular

90
00:04:09,780 --> 00:04:13,590
but it comes from before that because

91
00:04:11,760 --> 00:04:18,089
I've worked with in marginalized

92
00:04:13,590 --> 00:04:21,060
communities for quite a long time and in

93
00:04:18,089 --> 00:04:23,640
those spaces Tech is not necessarily a

94
00:04:21,060 --> 00:04:27,350
solution but it sometimes a new form of

95
00:04:23,640 --> 00:04:30,229
oppression or a new risk that comes out

96
00:04:27,350 --> 00:04:33,590
so how are we actually sort of grappling

97
00:04:30,230 --> 00:04:34,760
with this and we see examples that even

98
00:04:33,590 --> 00:04:36,289
though they're people who are thinking

99
00:04:34,760 --> 00:04:39,680
about this they're not necessarily doing

100
00:04:36,290 --> 00:04:41,660
a good job we see for example with uber

101
00:04:39,680 --> 00:04:44,210
they had sent out this email recently

102
00:04:41,660 --> 00:04:46,430
which is a check your ride every time a

103
00:04:44,210 --> 00:04:49,849
mail to remind people to make sure

104
00:04:46,430 --> 00:04:50,750
you're getting into the correct uber so

105
00:04:49,850 --> 00:04:53,030
that you know they're telling you to

106
00:04:50,750 --> 00:04:57,320
check the license plate the make model

107
00:04:53,030 --> 00:04:59,869
the drivers photo and it's actually it's

108
00:04:57,320 --> 00:05:02,090
really nice that they made this but the

109
00:04:59,870 --> 00:05:04,040
context of why they made this email was

110
00:05:02,090 --> 00:05:06,140
someone got murdered for not getting

111
00:05:04,040 --> 00:05:09,680
into an uber for someone they thought it

112
00:05:06,140 --> 00:05:11,840
was an uber and it wasn't and it also

113
00:05:09,680 --> 00:05:14,240
the way that there was have responded it

114
00:05:11,840 --> 00:05:16,789
only focuses on a very specific scenario

115
00:05:14,240 --> 00:05:17,420
one where the user is inherently at

116
00:05:16,790 --> 00:05:19,940
fault

117
00:05:17,420 --> 00:05:22,100
it doesn't look at or talk about some of

118
00:05:19,940 --> 00:05:24,469
the other publicly discussed cases that

119
00:05:22,100 --> 00:05:26,690
have happened with things like driver

120
00:05:24,470 --> 00:05:28,610
assaulting users with things like

121
00:05:26,690 --> 00:05:33,020
drivers going out of their way to make a

122
00:05:28,610 --> 00:05:35,060
higher fare things like that and I'm

123
00:05:33,020 --> 00:05:36,859
sure that some of this has to do with

124
00:05:35,060 --> 00:05:39,460
the question of liability which I know

125
00:05:36,860 --> 00:05:42,440
again came up a lot during Alyssa's talk

126
00:05:39,460 --> 00:05:44,000
and that's something that is I'm sure

127
00:05:42,440 --> 00:05:45,290
again in the back of the minds of all of

128
00:05:44,000 --> 00:05:48,230
these companies with how can they do

129
00:05:45,290 --> 00:05:52,280
some this messaging with that

130
00:05:48,230 --> 00:05:54,880
another example is around what we talk

131
00:05:52,280 --> 00:05:57,710
about cyber flashing so there have been

132
00:05:54,880 --> 00:06:01,159
high-profile cases of airdrop being used

133
00:05:57,710 --> 00:06:02,930
to send people images so the example of

134
00:06:01,160 --> 00:06:05,230
what this looks like is the the middle

135
00:06:02,930 --> 00:06:09,140
picture with the censored phallus

136
00:06:05,230 --> 00:06:11,450
there's a headline from from Huffington

137
00:06:09,140 --> 00:06:14,150
Post that notes you know that again this

138
00:06:11,450 --> 00:06:18,950
is a sexual offense and a recent article

139
00:06:14,150 --> 00:06:20,810
from Rob pakora raro who's saying in

140
00:06:18,950 --> 00:06:24,050
this article that Apple could fix the

141
00:06:20,810 --> 00:06:25,940
airdrop issue with some technical fixes

142
00:06:24,050 --> 00:06:27,530
and this has been something that has

143
00:06:25,940 --> 00:06:31,630
been an issue for like four or five

144
00:06:27,530 --> 00:06:33,799
years now this is not a new issue and

145
00:06:31,630 --> 00:06:35,419
it's really interesting because some of

146
00:06:33,800 --> 00:06:37,940
the technical fixes are not necessarily

147
00:06:35,419 --> 00:06:40,430
very difficult one of the things that

148
00:06:37,940 --> 00:06:42,710
Rob mentions in the article is

149
00:06:40,430 --> 00:06:45,290
you can have a time limit for accepting

150
00:06:42,710 --> 00:06:47,630
from everyone but most people often

151
00:06:45,290 --> 00:06:49,730
focus on the user should have known sort

152
00:06:47,630 --> 00:06:51,560
of like terms and services but or the

153
00:06:49,730 --> 00:06:55,610
user has the control and they've just

154
00:06:51,560 --> 00:06:56,780
configured it improperly so you know

155
00:06:55,610 --> 00:06:59,110
these are some of the people thinking

156
00:06:56,780 --> 00:07:01,909
about users and tech and security and

157
00:06:59,110 --> 00:07:04,010
perhaps another high-profile case is

158
00:07:01,910 --> 00:07:07,160
grinder grinders been getting a lot of

159
00:07:04,010 --> 00:07:10,940
flack recently and most recently with

160
00:07:07,160 --> 00:07:13,460
this article talks in part about the the

161
00:07:10,940 --> 00:07:17,600
current case of Herrick versus grinder

162
00:07:13,460 --> 00:07:21,169
in the US that's about a grinder user

163
00:07:17,600 --> 00:07:26,870
whose ex created a fake profile and sent

164
00:07:21,170 --> 00:07:29,960
a bunch of people for hookups to to the

165
00:07:26,870 --> 00:07:31,940
plaintiff and this gets into me like a

166
00:07:29,960 --> 00:07:34,460
very complicated case that involves

167
00:07:31,940 --> 00:07:36,230
what's the platform's liability with

168
00:07:34,460 --> 00:07:38,900
this that has now been a lot of

169
00:07:36,230 --> 00:07:43,910
discussion in in the US and other places

170
00:07:38,900 --> 00:07:46,700
but it sort of opens up this idea or

171
00:07:43,910 --> 00:07:50,290
this perception that with these sort of

172
00:07:46,700 --> 00:07:55,060
continued issues that platforms are not

173
00:07:50,290 --> 00:07:59,930
thinking or don't care about user safety

174
00:07:55,060 --> 00:08:03,860
so how can tech or security better

175
00:07:59,930 --> 00:08:06,350
support user safety and this is where I

176
00:08:03,860 --> 00:08:09,530
enter and I come from this approach of a

177
00:08:06,350 --> 00:08:11,300
harm reduction approach and I know I'm

178
00:08:09,530 --> 00:08:15,080
not the first person to talk about harm

179
00:08:11,300 --> 00:08:17,810
reduction within security the I think

180
00:08:15,080 --> 00:08:19,969
one of the earliest examples is in 2012

181
00:08:17,810 --> 00:08:24,460
violet-blue gave a talk about harm

182
00:08:19,970 --> 00:08:27,020
reduction focusing on hackers as a

183
00:08:24,460 --> 00:08:31,760
population for harm reduction work has

184
00:08:27,020 --> 00:08:34,159
anyone seen that talk there's so there's

185
00:08:31,760 --> 00:08:35,179
only a couple of people so I just wanted

186
00:08:34,159 --> 00:08:37,520
to put that out there that there are

187
00:08:35,179 --> 00:08:40,849
other people to potentially go see which

188
00:08:37,520 --> 00:08:42,350
is really great but I'm also taking a

189
00:08:40,850 --> 00:08:44,000
slightly different focus because I'm

190
00:08:42,350 --> 00:08:46,580
focusing directly on the end users of

191
00:08:44,000 --> 00:08:50,030
the app and not on the hackers

192
00:08:46,580 --> 00:08:51,650
themselves and to start with harm

193
00:08:50,030 --> 00:08:54,410
reduction I like to start think about

194
00:08:51,650 --> 00:08:56,839
where it came from this tweet

195
00:08:54,410 --> 00:08:59,180
very helpfully to me enlike succinctly

196
00:08:56,839 --> 00:09:01,129
notes that harm-reduction was started by

197
00:08:59,180 --> 00:09:03,469
sex workers queer and trans people of

198
00:09:01,129 --> 00:09:05,569
color people who use drugs people in the

199
00:09:03,470 --> 00:09:07,639
streets saving their own lives and all

200
00:09:05,569 --> 00:09:10,279
the intersections thereof not by public

201
00:09:07,639 --> 00:09:12,050
health folks and they note sort of

202
00:09:10,279 --> 00:09:13,759
respect the origins because when people

203
00:09:12,050 --> 00:09:15,500
talk about harm reduction they

204
00:09:13,759 --> 00:09:17,899
immediately go to talking about public

205
00:09:15,500 --> 00:09:20,269
health because the public health

206
00:09:17,899 --> 00:09:23,449
programming is where harm reduction has

207
00:09:20,269 --> 00:09:25,730
really entered into policy and so those

208
00:09:23,449 --> 00:09:28,430
become the very easy examples for people

209
00:09:25,730 --> 00:09:30,319
to think of but my own experience and

210
00:09:28,430 --> 00:09:33,560
approach really comes from working with

211
00:09:30,319 --> 00:09:36,430
marginalized communities and being a

212
00:09:33,560 --> 00:09:38,660
member of some of these communities so

213
00:09:36,430 --> 00:09:41,569
that's I have potentially different

214
00:09:38,660 --> 00:09:44,719
perspective than just this policy route

215
00:09:41,569 --> 00:09:46,219
and my work is deeply indebted in that

216
00:09:44,720 --> 00:09:51,019
sense to these communities that I've

217
00:09:46,220 --> 00:09:53,269
been a part of so the aspects of harm

218
00:09:51,019 --> 00:09:56,509
reduction and a quick and easy way of

219
00:09:53,269 --> 00:09:58,939
thinking about it is simply that it's

220
00:09:56,509 --> 00:10:01,850
aimed to minimize harm from activities

221
00:09:58,939 --> 00:10:05,089
these activities are usually illegal but

222
00:10:01,850 --> 00:10:08,630
they don't have to be it's explicitly

223
00:10:05,089 --> 00:10:10,850
opposed to stigmatization and judgment

224
00:10:08,630 --> 00:10:14,709
around the activities and this is a

225
00:10:10,850 --> 00:10:17,899
really important point because so often

226
00:10:14,709 --> 00:10:19,849
people who for example use drugs might

227
00:10:17,899 --> 00:10:21,680
be stigmatized and say that they deserve

228
00:10:19,850 --> 00:10:26,839
it whatever happens because they're

229
00:10:21,680 --> 00:10:29,060
using drugs it's not about ignoring the

230
00:10:26,839 --> 00:10:32,839
harm that happens from activities so

231
00:10:29,060 --> 00:10:35,410
it's very upfront about that and it's

232
00:10:32,839 --> 00:10:37,579
about putting the power in the

233
00:10:35,410 --> 00:10:41,059
communities those at risks in their

234
00:10:37,579 --> 00:10:43,309
hands and there's even recognition of

235
00:10:41,059 --> 00:10:45,559
new forms of harm that can come with

236
00:10:43,309 --> 00:10:49,939
harm reduction approaches what I mean by

237
00:10:45,559 --> 00:10:52,819
that is for sex workers who carry

238
00:10:49,939 --> 00:10:54,110
condoms if you carry more than like two

239
00:10:52,819 --> 00:10:56,479
condoms and you're stopped by police

240
00:10:54,110 --> 00:11:01,970
that can be used as evidence of

241
00:10:56,480 --> 00:11:03,649
prostitution so you know using harm

242
00:11:01,970 --> 00:11:05,300
reduction methods like using condoms

243
00:11:03,649 --> 00:11:07,880
when you're meeting with someone to have

244
00:11:05,300 --> 00:11:11,000
sex with them can also then be a

245
00:11:07,880 --> 00:11:14,090
way to put someone at a new risk so harm

246
00:11:11,000 --> 00:11:16,700
reduction is also upfront about that the

247
00:11:14,090 --> 00:11:18,380
the key parts are also at sort of a

248
00:11:16,700 --> 00:11:20,600
higher level is that they're opposed to

249
00:11:18,380 --> 00:11:22,490
abstinence approaches so saying that

250
00:11:20,600 --> 00:11:24,440
it's either this or that you know you

251
00:11:22,490 --> 00:11:26,780
can only have one of the other and it

252
00:11:24,440 --> 00:11:29,690
also recognizes the larger structures

253
00:11:26,780 --> 00:11:31,990
and systems that are in play and that

254
00:11:29,690 --> 00:11:33,860
means that you're taking an inherently

255
00:11:31,990 --> 00:11:35,960
intersectional approach or you're

256
00:11:33,860 --> 00:11:38,780
looking in a broad way at what's

257
00:11:35,960 --> 00:11:40,460
happening what's harm reduction for a

258
00:11:38,780 --> 00:11:41,810
white sex worker might be different than

259
00:11:40,460 --> 00:11:43,160
what's harm reduction for a black sex

260
00:11:41,810 --> 00:11:46,069
worker because of the way that the

261
00:11:43,160 --> 00:11:51,740
police interacts with the sex worker for

262
00:11:46,070 --> 00:11:53,200
example so part of this is that the fact

263
00:11:51,740 --> 00:11:56,600
that harm reduction inherently

264
00:11:53,200 --> 00:11:58,010
recognizes the power of pleasure and

265
00:11:56,600 --> 00:12:01,580
when I'm talking about pleasure here I

266
00:11:58,010 --> 00:12:05,090
don't necessarily mean just sex drugs it

267
00:12:01,580 --> 00:12:07,310
can be a more abstract idea like being

268
00:12:05,090 --> 00:12:10,970
able to dress or be the person that you

269
00:12:07,310 --> 00:12:13,579
want to be or how you feel you are it

270
00:12:10,970 --> 00:12:15,650
can be you know the ability to take time

271
00:12:13,580 --> 00:12:19,700
off of work and just like have some

272
00:12:15,650 --> 00:12:22,280
downtime right so when we when we put

273
00:12:19,700 --> 00:12:23,840
things in this approach that says you

274
00:12:22,280 --> 00:12:27,380
have to either do something that's

275
00:12:23,840 --> 00:12:28,430
pleasurable or you have to be safe most

276
00:12:27,380 --> 00:12:31,960
the time people are gonna do what's

277
00:12:28,430 --> 00:12:34,609
pleasurable and so it creates again this

278
00:12:31,960 --> 00:12:37,190
this danger potentially where people

279
00:12:34,610 --> 00:12:39,500
might know risks but say essentially

280
00:12:37,190 --> 00:12:41,240
 the risks because what's

281
00:12:39,500 --> 00:12:42,350
pleasurable is more important and no

282
00:12:41,240 --> 00:12:46,730
one's trying to tell them that there are

283
00:12:42,350 --> 00:12:48,800
other options and so I'm going to run

284
00:12:46,730 --> 00:12:51,560
through about four examples of harm

285
00:12:48,800 --> 00:12:54,589
reduction programs to give an idea of

286
00:12:51,560 --> 00:12:56,660
what this looks like in practice the

287
00:12:54,590 --> 00:12:58,910
first one our needle or syringe

288
00:12:56,660 --> 00:13:02,120
exchanges and this is one of the classic

289
00:12:58,910 --> 00:13:03,350
examples of harm reduction and when we

290
00:13:02,120 --> 00:13:06,020
think about this from a public policy

291
00:13:03,350 --> 00:13:08,570
perspective or public health perspective

292
00:13:06,020 --> 00:13:10,660
one of the goals of needle exchange

293
00:13:08,570 --> 00:13:13,970
programs is to reduce the spread of HIV

294
00:13:10,660 --> 00:13:18,589
of hepatitis and other blood borne

295
00:13:13,970 --> 00:13:21,260
illnesses and the basic idea with needle

296
00:13:18,589 --> 00:13:23,810
exchanges is you either go to a place or

297
00:13:21,260 --> 00:13:26,660
potentially like a van but you're able

298
00:13:23,810 --> 00:13:28,849
to give use needle and get a new one

299
00:13:26,660 --> 00:13:32,180
usually for free there might be some

300
00:13:28,850 --> 00:13:33,650
like small costs involved but the goal

301
00:13:32,180 --> 00:13:35,630
is that way you're not sharing needles

302
00:13:33,650 --> 00:13:38,480
and if someone's infected you spread an

303
00:13:35,630 --> 00:13:41,210
infection to a lot of people it's not

304
00:13:38,480 --> 00:13:44,050
trying to get people to stop doing drugs

305
00:13:41,210 --> 00:13:47,120
or the other uses of needles and

306
00:13:44,050 --> 00:13:49,849
initially these were actually seen as

307
00:13:47,120 --> 00:13:53,870
illegal people doing needle exchanges

308
00:13:49,850 --> 00:13:55,790
and syringe exchanges were could get in

309
00:13:53,870 --> 00:14:00,470
trouble with the law because it was seen

310
00:13:55,790 --> 00:14:02,689
as supporting drug use right and you

311
00:14:00,470 --> 00:14:04,550
know part of this as things have moved

312
00:14:02,690 --> 00:14:06,350
forward part of the goal of needle

313
00:14:04,550 --> 00:14:09,260
exchange programs has been to change the

314
00:14:06,350 --> 00:14:12,500
laws so nowadays most needle exchange

315
00:14:09,260 --> 00:14:14,810
programs are legal and Canada has even

316
00:14:12,500 --> 00:14:17,780
started piloting needle exchange

317
00:14:14,810 --> 00:14:19,579
programs in prisons which is pretty

318
00:14:17,780 --> 00:14:21,410
radical actually that they're having

319
00:14:19,580 --> 00:14:24,530
this recognition and they're willing to

320
00:14:21,410 --> 00:14:31,550
sort of go that step and that has like

321
00:14:24,530 --> 00:14:33,740
governmental support and so the so we've

322
00:14:31,550 --> 00:14:36,199
moved forward to make what they're doing

323
00:14:33,740 --> 00:14:39,020
more acceptable and oftentimes people

324
00:14:36,200 --> 00:14:40,730
are working at these stigmatizing drugs

325
00:14:39,020 --> 00:14:44,020
at large so working on things like

326
00:14:40,730 --> 00:14:44,020
decriminalization or legalization

327
00:14:44,080 --> 00:14:50,720
another prime example of harm reduction

328
00:14:48,230 --> 00:14:53,090
programs are safer sex and reproductive

329
00:14:50,720 --> 00:14:54,710
justice and usually people talk about

330
00:14:53,090 --> 00:14:56,540
this is just safer sex but I think

331
00:14:54,710 --> 00:14:58,670
within the u.s. context of what's going

332
00:14:56,540 --> 00:15:01,130
on right now with abortions it's really

333
00:14:58,670 --> 00:15:06,560
important to note that part of this

334
00:15:01,130 --> 00:15:08,810
includes safe access to abortions and to

335
00:15:06,560 --> 00:15:11,239
other things that are linked to

336
00:15:08,810 --> 00:15:13,339
reproductive justice into linked to like

337
00:15:11,240 --> 00:15:17,180
family planning that's also a big piece

338
00:15:13,340 --> 00:15:19,610
of harm reduction so I'm assuming some

339
00:15:17,180 --> 00:15:21,829
people have had some variation or have

340
00:15:19,610 --> 00:15:24,170
been exposed to some variation of safer

341
00:15:21,830 --> 00:15:27,110
sex education through knowing that

342
00:15:24,170 --> 00:15:28,839
condoms might be a thing but sometimes

343
00:15:27,110 --> 00:15:31,850
these also don't go far enough there are

344
00:15:28,840 --> 00:15:33,920
additional types of protective equipment

345
00:15:31,850 --> 00:15:34,380
prophylactics like dental dams and

346
00:15:33,920 --> 00:15:37,800
others

347
00:15:34,380 --> 00:15:40,770
people use there's things like prep

348
00:15:37,800 --> 00:15:43,859
which is pre-exposure prophylaxis to

349
00:15:40,770 --> 00:15:47,670
help spread HIV and that's been actually

350
00:15:43,860 --> 00:15:51,690
very effective and there's also having

351
00:15:47,670 --> 00:15:52,800
access to regular STD STI testings to

352
00:15:51,690 --> 00:15:55,220
help ensure that you're not spreading

353
00:15:52,800 --> 00:15:57,719
infections so those are some examples of

354
00:15:55,220 --> 00:16:01,110
harm reduction programs within the safer

355
00:15:57,720 --> 00:16:03,120
sex and reproductive justice world but

356
00:16:01,110 --> 00:16:04,830
there's also things that are will say

357
00:16:03,120 --> 00:16:07,140
human or behavioral practices that

358
00:16:04,830 --> 00:16:09,930
people are able to adopt and this can

359
00:16:07,140 --> 00:16:12,300
include things like negotiation of

360
00:16:09,930 --> 00:16:14,250
sexual encounters prior to having sex

361
00:16:12,300 --> 00:16:17,339
with someone and this is very common

362
00:16:14,250 --> 00:16:19,640
within kink communities to ensure that

363
00:16:17,340 --> 00:16:22,380
you have things like safe words set up

364
00:16:19,640 --> 00:16:26,010
so while you engage in sex that might be

365
00:16:22,380 --> 00:16:27,720
more dangerous you're able to or

366
00:16:26,010 --> 00:16:29,970
actually seen it's more dangerous to be

367
00:16:27,720 --> 00:16:32,070
able to sort of stop pause and you know

368
00:16:29,970 --> 00:16:33,600
cease the activity to help make sure

369
00:16:32,070 --> 00:16:35,490
everyone is okay

370
00:16:33,600 --> 00:16:38,660
it can include things like sex workers

371
00:16:35,490 --> 00:16:43,290
charging less for someone to use condoms

372
00:16:38,660 --> 00:16:45,569
because economics is a reality it can

373
00:16:43,290 --> 00:16:47,790
include things like not brushing your

374
00:16:45,570 --> 00:16:50,310
teeth or flossing before or after oral

375
00:16:47,790 --> 00:16:53,939
sex and even though that's a relatively

376
00:16:50,310 --> 00:16:55,589
minor risk of exposure usually when you

377
00:16:53,940 --> 00:16:57,660
brush or floss you do have a little bit

378
00:16:55,590 --> 00:16:59,360
of bleeding in your gums so again

379
00:16:57,660 --> 00:17:02,310
there's all of these different types of

380
00:16:59,360 --> 00:17:04,800
sort of small practices that are built

381
00:17:02,310 --> 00:17:06,688
into the harm reduction approach and

382
00:17:04,800 --> 00:17:08,790
sorry I know I can do like a whole pride

383
00:17:06,689 --> 00:17:11,160
talk on the sex ed but we're gonna like

384
00:17:08,790 --> 00:17:12,780
you know sort of move on but if anyone

385
00:17:11,160 --> 00:17:19,199
has any of these questions I'm happy to

386
00:17:12,780 --> 00:17:20,849
talk afterwards or around and another

387
00:17:19,199 --> 00:17:22,500
example and this is moving away from the

388
00:17:20,849 --> 00:17:24,780
traditional examples that people talk

389
00:17:22,500 --> 00:17:26,970
about - talking about homeless

390
00:17:24,780 --> 00:17:28,889
communities and a lot of my experience

391
00:17:26,970 --> 00:17:31,800
comes with working with homeless youth

392
00:17:28,890 --> 00:17:34,440
and a drop-in center is a place that's

393
00:17:31,800 --> 00:17:36,840
not a shelter but where someone can go

394
00:17:34,440 --> 00:17:38,250
during the day to get services and some

395
00:17:36,840 --> 00:17:40,590
of the services that they provide are

396
00:17:38,250 --> 00:17:43,410
like access to food clothing medical

397
00:17:40,590 --> 00:17:45,120
supplies it can be computers so they can

398
00:17:43,410 --> 00:17:47,640
communicate with people so they can

399
00:17:45,120 --> 00:17:49,050
create resumes it can be a mailing

400
00:17:47,640 --> 00:17:51,300
address

401
00:17:49,050 --> 00:17:52,860
in the in the US I'm not sure how

402
00:17:51,300 --> 00:17:55,620
accurate it is in Canada but in the u.s.

403
00:17:52,860 --> 00:17:56,879
mailing addresses are still a necessity

404
00:17:55,620 --> 00:18:00,780
to get certain parts of government

405
00:17:56,880 --> 00:18:03,810
services so having a mailing address is

406
00:18:00,780 --> 00:18:07,139
really important they can offer skills

407
00:18:03,810 --> 00:18:09,720
building opportunities one of the the

408
00:18:07,140 --> 00:18:11,520
places that I'm familiar with used to

409
00:18:09,720 --> 00:18:13,590
have a screen printing workshop for

410
00:18:11,520 --> 00:18:15,900
example where homeless youth can help

411
00:18:13,590 --> 00:18:17,699
gain actual like sort of vocational

412
00:18:15,900 --> 00:18:20,130
skills or learn how to do screen

413
00:18:17,700 --> 00:18:22,200
printing and they if they sort of did it

414
00:18:20,130 --> 00:18:23,730
long enough they can also create their

415
00:18:22,200 --> 00:18:25,470
own art so they're given opportunities

416
00:18:23,730 --> 00:18:26,940
that expression and they actually made

417
00:18:25,470 --> 00:18:29,610
money off of this they gain not only

418
00:18:26,940 --> 00:18:32,880
skills but they gained a form of sort of

419
00:18:29,610 --> 00:18:35,189
economic independence and some of them

420
00:18:32,880 --> 00:18:37,320
will even offer street outreach after

421
00:18:35,190 --> 00:18:39,810
their clothes will go out and they'll

422
00:18:37,320 --> 00:18:42,149
provide things like the access to food

423
00:18:39,810 --> 00:18:43,470
though clothing medical supplies they'll

424
00:18:42,150 --> 00:18:44,970
provide that to people living on the

425
00:18:43,470 --> 00:18:48,870
streets who might not come into the

426
00:18:44,970 --> 00:18:51,840
drop-in center and the last example I

427
00:18:48,870 --> 00:18:54,899
want to give is humanitarian assistance

428
00:18:51,840 --> 00:18:57,240
for border crossings so this example is

429
00:18:54,900 --> 00:18:59,310
quite specific to an organization in

430
00:18:57,240 --> 00:19:02,910
Arizona called No More Deaths

431
00:18:59,310 --> 00:19:05,960
or No Mas more at this and they've hit

432
00:19:02,910 --> 00:19:08,870
the news actually recently in the u.s.

433
00:19:05,960 --> 00:19:12,350
because the folks that are working for

434
00:19:08,870 --> 00:19:14,370
no more deaths are being targeted for

435
00:19:12,350 --> 00:19:16,949
surveillance and harassment by police

436
00:19:14,370 --> 00:19:19,620
and other legal cases for doing this

437
00:19:16,950 --> 00:19:22,020
work and what the work that they

438
00:19:19,620 --> 00:19:23,850
primarily do is so exactly what you see

439
00:19:22,020 --> 00:19:26,160
up here on the screen they provide food

440
00:19:23,850 --> 00:19:30,780
and water for people crossing the desert

441
00:19:26,160 --> 00:19:33,240
and having lived in the desert I can

442
00:19:30,780 --> 00:19:35,850
tell you even in city centers where you

443
00:19:33,240 --> 00:19:37,710
can easily go and pick up water from

444
00:19:35,850 --> 00:19:40,230
like a gas station or a corner store

445
00:19:37,710 --> 00:19:42,990
people die every year from dehydration

446
00:19:40,230 --> 00:19:44,880
and heat so if you then imagine you're

447
00:19:42,990 --> 00:19:46,950
crossing a desert where you don't have

448
00:19:44,880 --> 00:19:49,530
that kind of infrastructure support how

449
00:19:46,950 --> 00:19:51,810
important the water is for people to be

450
00:19:49,530 --> 00:19:56,160
able to stay hydrated and continue

451
00:19:51,810 --> 00:20:01,230
walking and at the moment there's a lot

452
00:19:56,160 --> 00:20:02,790
of again a lot of Congress

453
00:20:01,230 --> 00:20:04,620
nations around what's what's going on

454
00:20:02,790 --> 00:20:06,690
there's a lawsuit about whether this is

455
00:20:04,620 --> 00:20:08,580
considered legal or illegal activities

456
00:20:06,690 --> 00:20:09,900
the organization says that what they're

457
00:20:08,580 --> 00:20:11,280
doing is legal and they provide legal

458
00:20:09,900 --> 00:20:13,370
supportive services

459
00:20:11,280 --> 00:20:16,200
but it's an example right now of what's

460
00:20:13,370 --> 00:20:17,729
of some of these conversations is sort

461
00:20:16,200 --> 00:20:19,500
of in real-time as something that's not

462
00:20:17,730 --> 00:20:21,480
necessarily explicitly called harm

463
00:20:19,500 --> 00:20:23,700
reduction in the same way that other

464
00:20:21,480 --> 00:20:26,030
public health programs are is being

465
00:20:23,700 --> 00:20:26,030
debated

466
00:20:26,540 --> 00:20:33,480
so harm reduction is inherently radical

467
00:20:29,910 --> 00:20:34,679
if you hadn't picked up on that well we

468
00:20:33,480 --> 00:20:38,330
were talking about no more deaths

469
00:20:34,679 --> 00:20:41,100
there's been this very strong xenophobic

470
00:20:38,330 --> 00:20:44,309
anti-immigrant anti-migrant rhetoric

471
00:20:41,100 --> 00:20:48,449
cropping up in the US and globally it's

472
00:20:44,309 --> 00:20:51,480
not just in the US unfortunately and so

473
00:20:48,450 --> 00:20:54,270
while the media and other policy folks

474
00:20:51,480 --> 00:20:57,120
are trying to dehumanize people who are

475
00:20:54,270 --> 00:21:01,710
crossing and part of this is language of

476
00:20:57,120 --> 00:21:03,270
saying you know illegals that the goal

477
00:21:01,710 --> 00:21:05,429
of no more deaths again is simply to

478
00:21:03,270 --> 00:21:08,129
view them as humans who deserve to live

479
00:21:05,429 --> 00:21:10,260
and provide water and that's really

480
00:21:08,130 --> 00:21:15,960
radical in this context and in this day

481
00:21:10,260 --> 00:21:18,629
and age and harm reduction actually does

482
00:21:15,960 --> 00:21:20,250
exist in the in the text space as well

483
00:21:18,630 --> 00:21:22,530
and so I want to show at least a couple

484
00:21:20,250 --> 00:21:25,169
of examples so that we can you know see

485
00:21:22,530 --> 00:21:28,139
some of these ways that this is already

486
00:21:25,169 --> 00:21:29,520
being integrated the first one is

487
00:21:28,140 --> 00:21:33,480
talking about sort of social media and

488
00:21:29,520 --> 00:21:38,668
privacy I have a tweet here that I wrote

489
00:21:33,480 --> 00:21:40,830
a while ago in response to research that

490
00:21:38,669 --> 00:21:42,600
Dragonic Arion did on the surveillance

491
00:21:40,830 --> 00:21:45,360
and intimidation against people

492
00:21:42,600 --> 00:21:48,990
live-streaming police brutality in the

493
00:21:45,360 --> 00:21:51,270
US and the the tweets just simply noting

494
00:21:48,990 --> 00:21:52,919
how important it is to have access to

495
00:21:51,270 --> 00:21:55,320
live streaming into social media

496
00:21:52,919 --> 00:21:56,970
platforms beyond just connecting people

497
00:21:55,320 --> 00:22:01,530
because this is about preserving

498
00:21:56,970 --> 00:22:03,240
evidence right and why people who have

499
00:22:01,530 --> 00:22:05,549
been advocating for delete Facebook

500
00:22:03,240 --> 00:22:08,960
which has been such a common refrain

501
00:22:05,549 --> 00:22:12,059
especially after the Cambridge analytic

502
00:22:08,960 --> 00:22:15,479
conversation just doesn't work in those

503
00:22:12,059 --> 00:22:18,450
situations but it goes beyond jazz

504
00:22:15,479 --> 00:22:19,820
sort of preserving evidence it links

505
00:22:18,450 --> 00:22:23,399
into the way that we think about

506
00:22:19,820 --> 00:22:27,749
connection as well I I tend to do a lot

507
00:22:23,399 --> 00:22:29,369
of work in places where Facebook's free

508
00:22:27,749 --> 00:22:31,799
basics which used to be called Internet

509
00:22:29,369 --> 00:22:33,330
org is active and what that means is

510
00:22:31,799 --> 00:22:35,549
that there's people who have free access

511
00:22:33,330 --> 00:22:37,799
to Facebook they have free access to

512
00:22:35,549 --> 00:22:41,039
like Instagram but they don't have free

513
00:22:37,799 --> 00:22:42,989
access to email so things like Facebook

514
00:22:41,039 --> 00:22:45,539
become a very important way for people

515
00:22:42,989 --> 00:22:48,149
to connect to each other to family to

516
00:22:45,539 --> 00:22:49,559
family abroad things like that so when

517
00:22:48,149 --> 00:22:51,359
we talk about things like delete

518
00:22:49,559 --> 00:22:52,950
Facebook we're also than assuming you

519
00:22:51,359 --> 00:22:56,970
know there are alternatives that we have

520
00:22:52,950 --> 00:23:01,679
and so part of this humanization process

521
00:22:56,970 --> 00:23:03,720
is noting these other sort of examples

522
00:23:01,679 --> 00:23:05,070
and thinking about these people you know

523
00:23:03,720 --> 00:23:07,979
that we're not necessary part of their

524
00:23:05,070 --> 00:23:09,960
group but we can see them as deserving

525
00:23:07,979 --> 00:23:14,840
of connection in the same way that we

526
00:23:09,960 --> 00:23:17,309
are the other example is talking about

527
00:23:14,840 --> 00:23:21,389
intimate images what people might talk

528
00:23:17,309 --> 00:23:25,259
about is revenge porn and a very common

529
00:23:21,389 --> 00:23:27,928
refrain I hear is if you don't want your

530
00:23:25,259 --> 00:23:31,619
nudes online just don't take them or

531
00:23:27,929 --> 00:23:33,299
don't send them and this is to me a

532
00:23:31,619 --> 00:23:35,759
perfect example of this abstinence

533
00:23:33,299 --> 00:23:38,249
approach within tech it's saying that

534
00:23:35,759 --> 00:23:41,039
you can either do something like you

535
00:23:38,249 --> 00:23:42,899
know send a send a sext or you can sort

536
00:23:41,039 --> 00:23:45,929
of not there's no in-between and it

537
00:23:42,899 --> 00:23:49,018
ignores the way that sending nudes send

538
00:23:45,929 --> 00:23:50,999
sexting people can be an important piece

539
00:23:49,019 --> 00:23:53,820
of someone's self identity it can be a

540
00:23:50,999 --> 00:23:56,849
way that someone can help feel okay with

541
00:23:53,820 --> 00:23:58,408
their body and have body positivity and

542
00:23:56,849 --> 00:24:00,299
really again really powerful ways of

543
00:23:58,409 --> 00:24:02,639
identity and things that are really

544
00:24:00,299 --> 00:24:05,039
important beyond perhaps just pleasure

545
00:24:02,639 --> 00:24:07,559
and sort of an intimate moment between

546
00:24:05,039 --> 00:24:10,289
other between individuals who are at a

547
00:24:07,559 --> 00:24:13,979
distance and there's an organization

548
00:24:10,289 --> 00:24:16,830
called coding rights that has an awesome

549
00:24:13,979 --> 00:24:18,840
zine called safer nudes that talks about

550
00:24:16,830 --> 00:24:22,228
this and does a very positive sex

551
00:24:18,840 --> 00:24:24,299
positive take on it so I highly

552
00:24:22,229 --> 00:24:26,759
recommend if you do sext or you're

553
00:24:24,299 --> 00:24:28,290
interested in safer ways in terms of

554
00:24:26,759 --> 00:24:30,780
talking people about sexting to take a

555
00:24:28,290 --> 00:24:33,240
look at that zine and I want to

556
00:24:30,780 --> 00:24:36,540
highlight also the Facebook's response

557
00:24:33,240 --> 00:24:38,700
to revenge porn because this was quite

558
00:24:36,540 --> 00:24:40,800
controversial but they were actually

559
00:24:38,700 --> 00:24:43,380
trying to do harm reduction at a

560
00:24:40,800 --> 00:24:44,879
platform level whether they talked about

561
00:24:43,380 --> 00:24:47,250
it that way or not that's really what

562
00:24:44,880 --> 00:24:49,710
was going on and so Facebook's response

563
00:24:47,250 --> 00:24:52,320
if you're not familiar was saying send

564
00:24:49,710 --> 00:24:54,930
us your nudes and we'll hash the image

565
00:24:52,320 --> 00:24:57,649
and if that hash appears we'll like stop

566
00:24:54,930 --> 00:24:59,670
it from being uploaded or spread and

567
00:24:57,650 --> 00:25:01,020
again it's really great that they're

568
00:24:59,670 --> 00:25:06,030
trying to do this harm reduction

569
00:25:01,020 --> 00:25:08,070
approach it's unclear if you they a they

570
00:25:06,030 --> 00:25:10,139
talk to people and like sort of built

571
00:25:08,070 --> 00:25:11,370
and designed with them and supposed to

572
00:25:10,140 --> 00:25:14,700
just talking to people and then building

573
00:25:11,370 --> 00:25:16,320
on their own and it also ignores the

574
00:25:14,700 --> 00:25:17,580
fact of like trust and the world that

575
00:25:16,320 --> 00:25:19,169
Trust plays in this and whether people

576
00:25:17,580 --> 00:25:21,230
actually trusted Facebook enough

577
00:25:19,170 --> 00:25:24,360
especially with some of their other

578
00:25:21,230 --> 00:25:25,860
issues but it meets a really great

579
00:25:24,360 --> 00:25:28,229
example of moving away from this

580
00:25:25,860 --> 00:25:29,850
conversation of perfect security or

581
00:25:28,230 --> 00:25:33,990
perfect privacy that we tend to talk

582
00:25:29,850 --> 00:25:35,909
about so before I jump into the case

583
00:25:33,990 --> 00:25:37,470
study I just want to see if there's any

584
00:25:35,910 --> 00:25:52,320
questions about the harm reduction

585
00:25:37,470 --> 00:25:54,150
approach cool if I can happen let's make

586
00:25:52,320 --> 00:25:56,460
it a video hashed and kept off of

587
00:25:54,150 --> 00:26:00,390
Facebook because it's revenge form porn

588
00:25:56,460 --> 00:26:01,920
can I also submit the video documenting

589
00:26:00,390 --> 00:26:06,270
the police abuse and have that kept off

590
00:26:01,920 --> 00:26:10,200
of Facebook as revenge porn sorry I I

591
00:26:06,270 --> 00:26:13,260
might I might not be following well I I

592
00:26:10,200 --> 00:26:14,790
can rephrase but yeah it was if we send

593
00:26:13,260 --> 00:26:15,830
some content to Facebook and we

594
00:26:14,790 --> 00:26:18,629
determine like this would be

595
00:26:15,830 --> 00:26:20,189
objectionable to have it shared because

596
00:26:18,630 --> 00:26:22,860
it's an intimate photo well the same

597
00:26:20,190 --> 00:26:24,330
technology could be used to censor any

598
00:26:22,860 --> 00:26:28,169
Content that they would deem

599
00:26:24,330 --> 00:26:30,120
unacceptable got it yeah I mean so yes

600
00:26:28,170 --> 00:26:32,490
so we're the this comes down to a

601
00:26:30,120 --> 00:26:34,370
perhaps a approaches right and this is

602
00:26:32,490 --> 00:26:38,190
where I'm talking about the Facebook

603
00:26:34,370 --> 00:26:39,719
revenge porn is will say an example not

604
00:26:38,190 --> 00:26:41,480
necessarily an example that want that

605
00:26:39,720 --> 00:26:43,760
needs to be followed or

606
00:26:41,480 --> 00:26:45,769
the only way of you know sort of going

607
00:26:43,760 --> 00:26:48,649
about this because like you bring up

608
00:26:45,769 --> 00:26:50,389
there are there are issues of them being

609
00:26:48,649 --> 00:26:55,129
able to potentially censor or use this

610
00:26:50,389 --> 00:26:56,840
as a way of having you know using let's

611
00:26:55,130 --> 00:26:59,899
say AI I mean learning other things to

612
00:26:56,840 --> 00:27:01,939
automatically remove content and some of

613
00:26:59,899 --> 00:27:04,309
this actually you saw with YouTube but

614
00:27:01,940 --> 00:27:05,929
taking down videos that were evidence of

615
00:27:04,309 --> 00:27:08,059
human rights abuses and war crimes

616
00:27:05,929 --> 00:27:09,980
because of like sort of AI and things

617
00:27:08,059 --> 00:27:12,289
like that so again in the same things

618
00:27:09,980 --> 00:27:14,210
that are used potentially for some of

619
00:27:12,289 --> 00:27:17,049
this harm reduction stuff can also be

620
00:27:14,210 --> 00:27:20,570
will say misused in sort of other ways

621
00:27:17,049 --> 00:27:23,330
the the key difference or the key thing

622
00:27:20,570 --> 00:27:25,370
I would like to sort of promote with the

623
00:27:23,330 --> 00:27:29,149
thought of harm reduction is how harm

624
00:27:25,370 --> 00:27:31,969
reduction is aimed at putting the voices

625
00:27:29,149 --> 00:27:35,029
of the at-risk communities at the

626
00:27:31,970 --> 00:27:37,100
forefront so one of the reasons I noted

627
00:27:35,029 --> 00:27:40,360
it was unclear whether Facebook designed

628
00:27:37,100 --> 00:27:42,769
this with people who have had

629
00:27:40,360 --> 00:27:46,639
non-consensual spread of intimate images

630
00:27:42,769 --> 00:27:48,950
is because if they didn't really Center

631
00:27:46,639 --> 00:27:51,110
those voices and design with them I'm

632
00:27:48,950 --> 00:27:54,260
not sure whether that's gonna be a

633
00:27:51,110 --> 00:27:56,928
long-lasting or a good solution right

634
00:27:54,260 --> 00:27:58,250
and so if our goal is to sort of really

635
00:27:56,929 --> 00:28:00,919
reduce harm and build something that

636
00:27:58,250 --> 00:28:05,380
will last that's not gonna necessarily

637
00:28:00,919 --> 00:28:05,380
the right route does that help

638
00:28:10,120 --> 00:28:18,080
cool we can talk afterwards so okay so

639
00:28:15,500 --> 00:28:19,820
let's uh let's jump into the start was

640
00:28:18,080 --> 00:28:23,419
there another hand that I saw oh

641
00:28:19,820 --> 00:28:25,639
sorry my computer just went to sleep so

642
00:28:23,420 --> 00:28:32,809
we'll jump into the the case study in

643
00:28:25,640 --> 00:28:35,990
just a second and so we're talking about

644
00:28:32,809 --> 00:28:39,350
queer dating apps here and this work

645
00:28:35,990 --> 00:28:43,420
really comes from a project that was run

646
00:28:39,350 --> 00:28:48,110
by asana regos from article 19 and

647
00:28:43,420 --> 00:28:50,920
looking at apps and abuses that were

648
00:28:48,110 --> 00:28:53,659
going on in Egypt Lebanon and Iran and

649
00:28:50,920 --> 00:28:55,070
so I wanted like also like preface is

650
00:28:53,660 --> 00:28:57,950
right now that even though I'm the one

651
00:28:55,070 --> 00:28:59,510
here talking about this there are so

652
00:28:57,950 --> 00:29:02,480
many other people that were involved in

653
00:28:59,510 --> 00:29:04,190
this project that I'm not necessarily be

654
00:29:02,480 --> 00:29:08,440
able to name them in part do like safety

655
00:29:04,190 --> 00:29:11,540
issues but like this is not like me

656
00:29:08,440 --> 00:29:13,280
doing all of this work and there was an

657
00:29:11,540 --> 00:29:17,960
entire coalition and people who like

658
00:29:13,280 --> 00:29:20,240
volunteered time to do this so the

659
00:29:17,960 --> 00:29:25,100
background of this is it really started

660
00:29:20,240 --> 00:29:29,600
back in 2014 in Egypt after al Sisi took

661
00:29:25,100 --> 00:29:31,550
power there we had reports of using

662
00:29:29,600 --> 00:29:34,100
social media and apps like Grindr to

663
00:29:31,550 --> 00:29:37,790
trap gay people and we were told that

664
00:29:34,100 --> 00:29:40,490
this was linked to geolocation and at

665
00:29:37,790 --> 00:29:43,010
the time you had include security had

666
00:29:40,490 --> 00:29:45,830
published their research on tinder and

667
00:29:43,010 --> 00:29:48,350
geolocation another researcher created

668
00:29:45,830 --> 00:29:52,790
Grindr map that was able to identify and

669
00:29:48,350 --> 00:29:54,590
locate users of Grindr and the apps had

670
00:29:52,790 --> 00:29:56,389
actually responded or said gay dating

671
00:29:54,590 --> 00:29:59,120
apps had respond it's like scruff Hornet

672
00:29:56,390 --> 00:30:02,179
Grindr all did like user safety

673
00:29:59,120 --> 00:30:04,370
awareness little pop-ups and so we're

674
00:30:02,179 --> 00:30:06,170
jumping in and starting sort of slightly

675
00:30:04,370 --> 00:30:08,959
from that or we designed from that and

676
00:30:06,170 --> 00:30:11,690
we started with the users that was that

677
00:30:08,960 --> 00:30:14,420
was our main goal and we wanted to

678
00:30:11,690 --> 00:30:17,060
basically help them connect queer folks

679
00:30:14,420 --> 00:30:19,370
connect in these countries and if they

680
00:30:17,060 --> 00:30:21,290
want to hook up to do that but our main

681
00:30:19,370 --> 00:30:22,830
goal is to understand again what's going

682
00:30:21,290 --> 00:30:26,200
on and how their connect

683
00:30:22,830 --> 00:30:28,090
so our methods we used a lot of

684
00:30:26,200 --> 00:30:29,700
different types of methods landscape

685
00:30:28,090 --> 00:30:32,408
overview so this is like desk research

686
00:30:29,700 --> 00:30:34,240
tech usage and awareness survey and

687
00:30:32,409 --> 00:30:36,880
again that had heavy framing on

688
00:30:34,240 --> 00:30:38,740
geolocation features that's probably the

689
00:30:36,880 --> 00:30:42,460
least qualitative part of our

690
00:30:38,740 --> 00:30:45,220
methodology we did interviews including

691
00:30:42,460 --> 00:30:47,890
sort of group conversations we had a

692
00:30:45,220 --> 00:30:50,020
legal review of court cases we did

693
00:30:47,890 --> 00:30:52,299
security and privacy analysis and we had

694
00:30:50,020 --> 00:30:54,279
this direct collaboration between the

695
00:30:52,299 --> 00:30:56,649
security privacy experts I should put

696
00:30:54,279 --> 00:30:58,480
experts in quotes because there's lots

697
00:30:56,649 --> 00:31:00,520
of sort of questionable advice that's

698
00:30:58,480 --> 00:31:04,950
given and the queer communities

699
00:31:00,520 --> 00:31:07,809
themselves and in particular for the

700
00:31:04,950 --> 00:31:10,120
interviews those were actually run and

701
00:31:07,809 --> 00:31:13,539
helped designed by some of the different

702
00:31:10,120 --> 00:31:14,739
vocal groups that we worked with I'm not

703
00:31:13,539 --> 00:31:16,539
going to name them right now due to time

704
00:31:14,740 --> 00:31:20,559
but if you were interested there are a

705
00:31:16,539 --> 00:31:23,770
few that are public and so our initial

706
00:31:20,559 --> 00:31:25,418
results showed that it's not only dating

707
00:31:23,770 --> 00:31:27,399
apps that were being used for hookups

708
00:31:25,419 --> 00:31:31,179
and dating and this was especially true

709
00:31:27,399 --> 00:31:32,739
in Iran due to censorship and so things

710
00:31:31,179 --> 00:31:35,289
like Grindr were censored so people

711
00:31:32,740 --> 00:31:36,460
tended to use things like Instagram you

712
00:31:35,289 --> 00:31:37,799
know cuz you used what you have

713
00:31:36,460 --> 00:31:39,909
available to you

714
00:31:37,799 --> 00:31:41,918
participants were largely aware of the

715
00:31:39,909 --> 00:31:44,500
risks they were even doing things like

716
00:31:41,919 --> 00:31:46,809
GPS spoofing and sort of other methods

717
00:31:44,500 --> 00:31:48,700
to try and protect themselves the GPS

718
00:31:46,809 --> 00:31:52,029
spoofing is a little questionable

719
00:31:48,700 --> 00:31:53,860
because sometimes people would roots or

720
00:31:52,029 --> 00:31:56,470
jailbreak their phone which could expose

721
00:31:53,860 --> 00:31:57,789
them to greater security risks so that's

722
00:31:56,470 --> 00:32:00,789
like also part of this harm reduction

723
00:31:57,789 --> 00:32:02,919
approach is noting that by not giving

724
00:32:00,789 --> 00:32:05,140
advice people could unintentionally

725
00:32:02,919 --> 00:32:06,640
putting themselves or making themselves

726
00:32:05,140 --> 00:32:09,610
insecure putting themselves at greater

727
00:32:06,640 --> 00:32:12,520
risk or danger there was also this

728
00:32:09,610 --> 00:32:15,129
tension between anonymity and the lack

729
00:32:12,520 --> 00:32:16,600
of trust among users and I highlight

730
00:32:15,130 --> 00:32:18,789
this because we didn't really go

731
00:32:16,600 --> 00:32:20,830
necessarily anywhere but I think this is

732
00:32:18,789 --> 00:32:24,250
a common conversation that's going on in

733
00:32:20,830 --> 00:32:27,039
all these platforms how do you think

734
00:32:24,250 --> 00:32:29,770
about like sort of authentication of a

735
00:32:27,039 --> 00:32:31,690
user beyond let's say like a password

736
00:32:29,770 --> 00:32:34,240
right so you can know if it actually is

737
00:32:31,690 --> 00:32:35,470
a person if it's a bot and then how do

738
00:32:34,240 --> 00:32:40,179
you build that trust

739
00:32:35,470 --> 00:32:41,919
in these digital spaces and perhaps in a

740
00:32:40,179 --> 00:32:44,080
fun way the participants weren't only

741
00:32:41,919 --> 00:32:46,360
interested in digital risks they wanted

742
00:32:44,080 --> 00:32:49,870
other information about you know sex add

743
00:32:46,360 --> 00:32:52,149
legal as well so I'm going to go through

744
00:32:49,870 --> 00:32:54,518
a couple key results the first one is

745
00:32:52,149 --> 00:32:56,590
that participants wanted to use the apps

746
00:32:54,519 --> 00:32:58,840
despite the risks and this is I think

747
00:32:56,590 --> 00:33:00,850
probably the most important result when

748
00:32:58,840 --> 00:33:06,129
thinking about why take a harm reduction

749
00:33:00,850 --> 00:33:07,658
approach the typical approaches to

750
00:33:06,129 --> 00:33:09,759
security we're not addressing the

751
00:33:07,659 --> 00:33:11,919
participant needs there was a lot of

752
00:33:09,759 --> 00:33:13,779
conversation about like why don't you

753
00:33:11,919 --> 00:33:15,789
use encryption why don't you just update

754
00:33:13,779 --> 00:33:17,620
your phone and they were based like

755
00:33:15,789 --> 00:33:22,720
that's not that's not what's going on

756
00:33:17,620 --> 00:33:25,268
here and in part because the primary

757
00:33:22,720 --> 00:33:27,519
risk were other users on the platform

758
00:33:25,269 --> 00:33:28,659
and so that's one of the reasons when

759
00:33:27,519 --> 00:33:30,940
you were perhaps starting to think about

760
00:33:28,659 --> 00:33:32,799
why traditional security advice was not

761
00:33:30,940 --> 00:33:34,659
working is because they weren't thinking

762
00:33:32,799 --> 00:33:36,279
about the risk that the users were

763
00:33:34,659 --> 00:33:39,429
facing they were thinking about perhaps

764
00:33:36,279 --> 00:33:42,789
like risks to the system right and the

765
00:33:39,429 --> 00:33:45,190
app platform so again something like

766
00:33:42,789 --> 00:33:47,860
end-to-end encryption or using something

767
00:33:45,190 --> 00:33:49,960
like signal or another secure messenger

768
00:33:47,860 --> 00:33:54,809
would have done nothing to mitigate the

769
00:33:49,960 --> 00:33:58,090
risk of the other user being malicious

770
00:33:54,809 --> 00:33:59,860
and this one actually really surprised

771
00:33:58,090 --> 00:34:02,439
me is that people like book the

772
00:33:59,860 --> 00:34:03,969
location-based aspect and the reason

773
00:34:02,440 --> 00:34:07,059
that this surprised me I think is part

774
00:34:03,970 --> 00:34:10,810
because within the larger conversation

775
00:34:07,059 --> 00:34:12,489
around privacy in the US and Canada and

776
00:34:10,810 --> 00:34:14,619
Europe we tend to be so anti

777
00:34:12,489 --> 00:34:17,199
location-based services we talked about

778
00:34:14,619 --> 00:34:20,470
it as creepy all of that but what we

779
00:34:17,199 --> 00:34:22,299
what we were learning is that vocation

780
00:34:20,469 --> 00:34:24,189
is really important for safety decision

781
00:34:22,300 --> 00:34:25,659
making for some people they want to be

782
00:34:24,190 --> 00:34:27,129
able to meet up with people in their

783
00:34:25,659 --> 00:34:29,950
area so that way they can meet up in

784
00:34:27,129 --> 00:34:31,868
person for other people there was a risk

785
00:34:29,949 --> 00:34:34,540
because you might be able to be

786
00:34:31,869 --> 00:34:36,190
identified based upon your last name of

787
00:34:34,540 --> 00:34:37,960
having meeting up with people in too

788
00:34:36,190 --> 00:34:39,760
close of proximity so you'd want to make

789
00:34:37,960 --> 00:34:41,440
sure to meet up with people further away

790
00:34:39,760 --> 00:34:44,760
so you might not communicate actually

791
00:34:41,440 --> 00:34:44,760
with someone who's close to you

792
00:34:47,580 --> 00:34:52,830
there we go so and so we also did like I

793
00:34:51,070 --> 00:34:53,950
said we also did this legal analysis and

794
00:34:52,830 --> 00:34:56,080
asana

795
00:34:53,949 --> 00:34:57,819
the principal investigator as I

796
00:34:56,080 --> 00:35:00,580
mentioned earlier is the one who really

797
00:34:57,820 --> 00:35:03,010
developed this methodology around sort

798
00:35:00,580 --> 00:35:04,330
of looking at the evidence but we can

799
00:35:03,010 --> 00:35:06,160
sort of think about it as legal

800
00:35:04,330 --> 00:35:08,170
forensics trying to pick up the pieces

801
00:35:06,160 --> 00:35:10,899
of what we saw with what was being used

802
00:35:08,170 --> 00:35:14,520
to understand sort of what's going on

803
00:35:10,900 --> 00:35:17,020
and to be able to identify things to

804
00:35:14,520 --> 00:35:20,680
waste to reduce harm from what's the

805
00:35:17,020 --> 00:35:23,080
evidence that's being used and the what

806
00:35:20,680 --> 00:35:25,629
we saw were that accounts were created

807
00:35:23,080 --> 00:35:27,880
explicitly for entrapment or identifying

808
00:35:25,630 --> 00:35:30,880
suspects and so that can be people will

809
00:35:27,880 --> 00:35:34,480
say infiltrating a group message apps

810
00:35:30,880 --> 00:35:36,220
screenshots and water marked pictures so

811
00:35:34,480 --> 00:35:39,190
some of the apps used to have watermarks

812
00:35:36,220 --> 00:35:40,930
were used for blackmail potentially for

813
00:35:39,190 --> 00:35:44,590
like blackmail are also blackmailed to

814
00:35:40,930 --> 00:35:45,940
arrest someone and since the context

815
00:35:44,590 --> 00:35:48,700
that we're talking about did include

816
00:35:45,940 --> 00:35:51,220
checkpoints having the presence of the

817
00:35:48,700 --> 00:35:53,230
app on the phone was a risk in itself

818
00:35:51,220 --> 00:35:55,359
because at a checkpoint someone might

819
00:35:53,230 --> 00:35:56,710
take your phone say open it and they'll

820
00:35:55,360 --> 00:35:59,200
flip through and they'll say oh you have

821
00:35:56,710 --> 00:36:02,440
Grindr or you have whore net or you have

822
00:35:59,200 --> 00:36:06,490
these images and so that was also a key

823
00:36:02,440 --> 00:36:08,200
risk perhaps like importantly and

824
00:36:06,490 --> 00:36:10,330
similar to some of the conversations

825
00:36:08,200 --> 00:36:12,850
with sex work and how sex work is

826
00:36:10,330 --> 00:36:15,160
policed is that no sexual activity was

827
00:36:12,850 --> 00:36:17,529
needed for the arrests so they had other

828
00:36:15,160 --> 00:36:20,920
ways of going around this so even in

829
00:36:17,530 --> 00:36:24,700
places where homosexuality wasn't

830
00:36:20,920 --> 00:36:28,530
outright outlawed they used other other

831
00:36:24,700 --> 00:36:31,180
laws and again there were other ways of

832
00:36:28,530 --> 00:36:35,380
bending the laws or interpreting the

833
00:36:31,180 --> 00:36:36,850
evidence to be able to do arrests so we

834
00:36:35,380 --> 00:36:40,360
found that understanding the digital

835
00:36:36,850 --> 00:36:41,470
evidence was action a central point to

836
00:36:40,360 --> 00:36:44,560
basically understanding sort of

837
00:36:41,470 --> 00:36:46,240
adversary methods or what's going on and

838
00:36:44,560 --> 00:36:47,380
so if we hadn't done this we couldn't

839
00:36:46,240 --> 00:36:50,649
have made some of the recommendations

840
00:36:47,380 --> 00:36:52,450
that we did so in the one of the key

841
00:36:50,650 --> 00:36:55,180
recommendations that we had was this app

842
00:36:52,450 --> 00:36:58,600
cloaking feature and app cloaking is

843
00:36:55,180 --> 00:36:59,950
something that came from work that was

844
00:36:58,600 --> 00:37:00,200
done by the Guardian project and the

845
00:36:59,950 --> 00:37:02,720
guard

846
00:37:00,200 --> 00:37:05,240
project had designed for Android a way

847
00:37:02,720 --> 00:37:07,430
to change the icon of the app so it

848
00:37:05,240 --> 00:37:09,709
didn't look like you know that original

849
00:37:07,430 --> 00:37:11,390
icon and so again if space is just

850
00:37:09,710 --> 00:37:13,730
changing the app icon and that was a key

851
00:37:11,390 --> 00:37:15,470
recommendation especially for that part

852
00:37:13,730 --> 00:37:19,040
of having that presence of the app on

853
00:37:15,470 --> 00:37:22,310
your phone to follow best practices for

854
00:37:19,040 --> 00:37:23,750
Transport Security and I sort of chuckle

855
00:37:22,310 --> 00:37:25,369
as I say this because if we think about

856
00:37:23,750 --> 00:37:26,660
where the ethics involved and like

857
00:37:25,369 --> 00:37:28,220
trying to build some of these things in

858
00:37:26,660 --> 00:37:29,450
through the process this is

859
00:37:28,220 --> 00:37:32,390
theoretically something that should have

860
00:37:29,450 --> 00:37:34,790
been done from the very beginning at the

861
00:37:32,390 --> 00:37:38,170
time that we did the research in the

862
00:37:34,790 --> 00:37:41,480
conversations none of the apps had used

863
00:37:38,170 --> 00:37:45,470
SSL pinning and/or certificate pinning

864
00:37:41,480 --> 00:37:48,290
and I don't think any of them were even

865
00:37:45,470 --> 00:37:50,799
using HTTPS or secure transport for

866
00:37:48,290 --> 00:37:53,450
their images for their media servers um

867
00:37:50,800 --> 00:37:56,470
which is which is huge when we know that

868
00:37:53,450 --> 00:37:58,879
images are being used as evidence

869
00:37:56,470 --> 00:38:00,680
working with the local community is like

870
00:37:58,880 --> 00:38:03,310
a key one as well and that goes to parts

871
00:38:00,680 --> 00:38:05,509
like centering those at risk and

872
00:38:03,310 --> 00:38:08,390
increase the safety with the geolocation

873
00:38:05,510 --> 00:38:10,010
feature and we provided some potential

874
00:38:08,390 --> 00:38:12,680
recommendations but we also noted that

875
00:38:10,010 --> 00:38:14,180
this needs a lot more research so we can

876
00:38:12,680 --> 00:38:16,250
we were not saying to get rid of the

877
00:38:14,180 --> 00:38:18,950
location feature which is part of the

878
00:38:16,250 --> 00:38:21,230
initial response in 2014

879
00:38:18,950 --> 00:38:22,819
apps would also at that point time give

880
00:38:21,230 --> 00:38:24,530
you the option to turn off location

881
00:38:22,819 --> 00:38:29,930
services so you're not reporting your

882
00:38:24,530 --> 00:38:31,670
location to the app so within the

883
00:38:29,930 --> 00:38:33,319
implementation what we had sort of done

884
00:38:31,670 --> 00:38:34,579
as a results of this I should say other

885
00:38:33,319 --> 00:38:36,859
than coming up with that list of

886
00:38:34,579 --> 00:38:38,510
recommendations we actually worked with

887
00:38:36,859 --> 00:38:41,150
Grindr to implement some of the

888
00:38:38,510 --> 00:38:43,280
recommendations and among the fun things

889
00:38:41,150 --> 00:38:46,040
that came out of that is a new method

890
00:38:43,280 --> 00:38:47,390
for app cloaking on iOS as I noted the

891
00:38:46,040 --> 00:38:49,250
Guardian project had only done work on

892
00:38:47,390 --> 00:38:51,379
Android but with the work that we had

893
00:38:49,250 --> 00:38:53,540
done we had now not again a new way of

894
00:38:51,380 --> 00:38:55,160
doing this for iOS which was sort of new

895
00:38:53,540 --> 00:38:57,290
research or a new feature in that sense

896
00:38:55,160 --> 00:38:58,848
and the creation of non tech resources

897
00:38:57,290 --> 00:39:02,420
again these are things that were

898
00:38:58,849 --> 00:39:05,270
requested by by the communities that we

899
00:39:02,420 --> 00:39:07,579
talked to so context specific legal

900
00:39:05,270 --> 00:39:10,220
information localized sex health fact

901
00:39:07,579 --> 00:39:13,030
sheets and these were in the languages

902
00:39:10,220 --> 00:39:13,029
that they spoke

903
00:39:13,500 --> 00:39:18,369
so the question is where do we go from

904
00:39:16,210 --> 00:39:20,529
here in terms of harm reduction like

905
00:39:18,369 --> 00:39:23,500
what's how do we actually apply this in

906
00:39:20,529 --> 00:39:25,960
practice and I think one of the first

907
00:39:23,500 --> 00:39:29,200
things is to recognize that security

908
00:39:25,960 --> 00:39:30,910
privacy and safety are not binary and so

909
00:39:29,200 --> 00:39:33,399
again there's not this idea of a perfect

910
00:39:30,910 --> 00:39:35,470
security or perfect safety or perfect

911
00:39:33,400 --> 00:39:37,779
privacy that there are there's the

912
00:39:35,470 --> 00:39:41,950
spectrum and that you know people will

913
00:39:37,779 --> 00:39:44,049
do their own analysis around this focus

914
00:39:41,950 --> 00:39:48,910
on understanding and humanizing

915
00:39:44,049 --> 00:39:50,770
the users so often we I think

916
00:39:48,910 --> 00:39:54,339
stigmatized and we don't think of the

917
00:39:50,770 --> 00:39:56,230
users as humans and I know that this is

918
00:39:54,339 --> 00:39:59,020
part of the role of designers but not

919
00:39:56,230 --> 00:40:01,440
everyone has designers and even when we

920
00:39:59,020 --> 00:40:04,990
have designers they're not necessarily

921
00:40:01,440 --> 00:40:07,059
doing the best job when it comes to the

922
00:40:04,990 --> 00:40:08,500
humanization part in part because

923
00:40:07,059 --> 00:40:11,200
they're building personas and other

924
00:40:08,500 --> 00:40:14,260
things that develop mental models that

925
00:40:11,200 --> 00:40:16,899
might exclude other users right and so

926
00:40:14,260 --> 00:40:18,910
there is already a tension within design

927
00:40:16,900 --> 00:40:21,190
and design itself you know needs to be

928
00:40:18,910 --> 00:40:26,440
it perhaps part of this conversation

929
00:40:21,190 --> 00:40:28,390
with that there are no edge cases in the

930
00:40:26,440 --> 00:40:31,059
sense I've been in enough conversations

931
00:40:28,390 --> 00:40:33,460
with security privacy folks where I've

932
00:40:31,059 --> 00:40:36,490
heard people talk about the most at-risk

933
00:40:33,460 --> 00:40:38,589
or marginalized users as edge cases and

934
00:40:36,490 --> 00:40:41,078
if we're thinking about dehumanizing

935
00:40:38,589 --> 00:40:45,130
language this is a perfect example of

936
00:40:41,079 --> 00:40:47,020
that sort of dehumanizing language we

937
00:40:45,130 --> 00:40:50,470
need to move away from stigmatizing user

938
00:40:47,020 --> 00:40:51,670
activities I'm sure I would not be

939
00:40:50,470 --> 00:40:53,589
surprised I'm not going to necessarily

940
00:40:51,670 --> 00:40:54,640
ask anyone to raise their hands but I

941
00:40:53,589 --> 00:40:57,069
would not be surprised if there are

942
00:40:54,640 --> 00:40:59,558
people in this room who have thought or

943
00:40:57,069 --> 00:41:01,839
said things like a user clicked on that

944
00:40:59,559 --> 00:41:05,200
fishing link that was so obvious they're

945
00:41:01,839 --> 00:41:06,940
so stupid why do they do that and that's

946
00:41:05,200 --> 00:41:09,129
an example again a stigmatizing user

947
00:41:06,940 --> 00:41:13,599
activities as opposed to trying to sort

948
00:41:09,130 --> 00:41:15,849
of understand and build with them and

949
00:41:13,599 --> 00:41:17,710
this is the this is a part that Alyssa

950
00:41:15,849 --> 00:41:20,200
had mentioned as well that we were

951
00:41:17,710 --> 00:41:23,200
talking about which is incorporating

952
00:41:20,200 --> 00:41:25,240
user safety not just system risks into

953
00:41:23,200 --> 00:41:28,890
threat modeling and system design some

954
00:41:25,240 --> 00:41:28,890
of those traditional security parts

955
00:41:29,560 --> 00:41:35,660
but of course this brings up really that

956
00:41:31,880 --> 00:41:38,990
question of who owns user-centric

957
00:41:35,660 --> 00:41:40,460
security and privacy and safety within a

958
00:41:38,990 --> 00:41:43,970
company and within the structures that

959
00:41:40,460 --> 00:41:45,950
we have due to like where security and

960
00:41:43,970 --> 00:41:48,259
privacy teams are usually placed there

961
00:41:45,950 --> 00:41:51,350
under things like compliance which is

962
00:41:48,260 --> 00:41:54,260
good you know I shift that approach they

963
00:41:51,350 --> 00:41:56,420
might be based within organization or

964
00:41:54,260 --> 00:41:57,560
company operations which means that

965
00:41:56,420 --> 00:42:00,950
they're not thinking about the end user

966
00:41:57,560 --> 00:42:02,600
of the app or the platform and even if

967
00:42:00,950 --> 00:42:04,460
they're based within let's say the

968
00:42:02,600 --> 00:42:07,130
product team as in the product teams the

969
00:42:04,460 --> 00:42:10,100
one who is building this they might not

970
00:42:07,130 --> 00:42:11,390
necessarily have the power or ability to

971
00:42:10,100 --> 00:42:13,730
sort of implement some of these things

972
00:42:11,390 --> 00:42:15,589
because the security team might need to

973
00:42:13,730 --> 00:42:17,359
be the one who signs off on everything

974
00:42:15,590 --> 00:42:19,250
you know so there are a some of those

975
00:42:17,359 --> 00:42:21,710
tensions even within where security and

976
00:42:19,250 --> 00:42:23,690
privacy can be placed there's obviously

977
00:42:21,710 --> 00:42:25,760
the design teams maybe have a role the

978
00:42:23,690 --> 00:42:28,400
product or app teams could as well and

979
00:42:25,760 --> 00:42:29,840
the product teams those were actually

980
00:42:28,400 --> 00:42:31,640
the folks that we were talking to at

981
00:42:29,840 --> 00:42:35,270
Grindr they were the ones that were sort

982
00:42:31,640 --> 00:42:37,730
of the owners internally and I want to

983
00:42:35,270 --> 00:42:39,170
perhaps leave with the question of what

984
00:42:37,730 --> 00:42:42,710
would it look like to bring harm

985
00:42:39,170 --> 00:42:44,570
reduction to your work and I think this

986
00:42:42,710 --> 00:42:46,940
is an important question in part because

987
00:42:44,570 --> 00:42:51,590
I've talked so much about we'll say

988
00:42:46,940 --> 00:42:53,780
these more social scenarios but I also

989
00:42:51,590 --> 00:42:56,570
strongly believe that harm reduction as

990
00:42:53,780 --> 00:42:59,180
an approach can be used and brought into

991
00:42:56,570 --> 00:43:02,180
the work that people do within corporate

992
00:42:59,180 --> 00:43:03,770
environments and I would hi would highly

993
00:43:02,180 --> 00:43:05,779
encourage people who are in sort of

994
00:43:03,770 --> 00:43:07,730
enterprises or corporate environments to

995
00:43:05,780 --> 00:43:10,250
think about ways that they can bring in

996
00:43:07,730 --> 00:43:12,200
and incorporate harm reduction and the

997
00:43:10,250 --> 00:43:13,220
implications or what that means into the

998
00:43:12,200 --> 00:43:15,589
security work that they do

999
00:43:13,220 --> 00:43:17,980
so I guess thank you and we'll go to

1000
00:43:15,590 --> 00:43:17,980
questions

1001
00:43:18,550 --> 00:43:20,610
you

