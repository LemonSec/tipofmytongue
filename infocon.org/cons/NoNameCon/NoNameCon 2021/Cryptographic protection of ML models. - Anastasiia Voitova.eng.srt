1
00:00:04,160 --> 00:00:05,920
so let's let's let's move forward

2
00:00:05,920 --> 00:00:07,600
cryptographic protection of machine

3
00:00:07,600 --> 00:00:10,880
learning models uh as large mentioned my

4
00:00:10,880 --> 00:00:12,880
name is anastasi my nickname is

5
00:00:12,880 --> 00:00:15,599
vixentail you can find me online in

6
00:00:15,599 --> 00:00:17,760
twitter github facebook linkedin the

7
00:00:17,760 --> 00:00:21,039
other other and i am secretary of

8
00:00:21,039 --> 00:00:23,119
engineer with a background of software

9
00:00:23,119 --> 00:00:25,119
development so i'm kind of in between

10
00:00:25,119 --> 00:00:27,760
the world of software development

11
00:00:27,760 --> 00:00:30,560
applied crypto security engineering i

12
00:00:30,560 --> 00:00:32,800
work at kozak labs because the clubs is

13
00:00:32,800 --> 00:00:33,520
um

14
00:00:33,520 --> 00:00:34,800
a uk

15
00:00:34,800 --> 00:00:37,440
ukraine data security company we a

16
00:00:37,440 --> 00:00:39,840
product company we create tools and

17
00:00:39,840 --> 00:00:42,879
solutions for data protection some of

18
00:00:42,879 --> 00:00:45,280
our tools are public free and open

19
00:00:45,280 --> 00:00:47,440
source you can find them on a github

20
00:00:47,440 --> 00:00:50,399
some of our tools are paid and closed

21
00:00:50,399 --> 00:00:54,320
source proprietary uh we take part in a

22
00:00:54,320 --> 00:00:57,600
lot of cryptographic r d like research

23
00:00:57,600 --> 00:01:00,399
with novel cryptography as well as use

24
00:01:00,399 --> 00:01:02,960
pretty boring standard cryptography to

25
00:01:02,960 --> 00:01:03,920
solve

26
00:01:03,920 --> 00:01:06,400
problems of data leakage

27
00:01:06,400 --> 00:01:07,439
and

28
00:01:07,439 --> 00:01:10,640
complying to regulations

29
00:01:10,640 --> 00:01:11,520
okay

30
00:01:11,520 --> 00:01:14,159
typically we work with companies that

31
00:01:14,159 --> 00:01:16,880
value data security a lot no matter of

32
00:01:16,880 --> 00:01:19,200
their industry right critical

33
00:01:19,200 --> 00:01:22,640
infrastructure fintech now banking

34
00:01:22,640 --> 00:01:25,040
machine learning even just popular

35
00:01:25,040 --> 00:01:27,680
mobile applications all of them are good

36
00:01:27,680 --> 00:01:31,119
enough for cryptography if they uh take

37
00:01:31,119 --> 00:01:32,560
care of

38
00:01:32,560 --> 00:01:35,759
many like take care of sensitive data

39
00:01:35,759 --> 00:01:38,400
right no matter what kind of data it is

40
00:01:38,400 --> 00:01:40,799
rather user passports

41
00:01:40,799 --> 00:01:43,119
or machine learning models and the

42
00:01:43,119 --> 00:01:46,320
second one we will talk about today

43
00:01:46,320 --> 00:01:49,040
first of all the disclaimer slides okay

44
00:01:49,040 --> 00:01:51,600
this is the most important slide on this

45
00:01:51,600 --> 00:01:54,560
presentation things that we

46
00:01:54,560 --> 00:01:57,200
won't talk about

47
00:01:57,200 --> 00:01:59,520
because i know i know i know no no

48
00:01:59,520 --> 00:02:01,759
machine learning is nice to roam it's

49
00:02:01,759 --> 00:02:03,119
like hype

50
00:02:03,119 --> 00:02:04,880
artificial intelligence machine learning

51
00:02:04,880 --> 00:02:08,560
la la so we won't talk about um

52
00:02:08,560 --> 00:02:10,479
adversarial networks and adversarial

53
00:02:10,479 --> 00:02:13,120
attacks so we won't talk how banana

54
00:02:13,120 --> 00:02:15,680
sticker creates banana into toaster you

55
00:02:15,680 --> 00:02:17,680
know things like that sorry if you're

56
00:02:17,680 --> 00:02:20,000
interested in that follow the link

57
00:02:20,000 --> 00:02:22,879
we won't talk about machine on learning

58
00:02:22,879 --> 00:02:24,800
by the way someone in twitter suggested

59
00:02:24,800 --> 00:02:26,800
this topic to me and i read the paper

60
00:02:26,800 --> 00:02:30,319
this is fascinating so you can basically

61
00:02:30,319 --> 00:02:34,640
make the model to unlearn some things um

62
00:02:34,640 --> 00:02:36,959
i really like the idea from privacy

63
00:02:36,959 --> 00:02:39,840
perspective but no no tackling needs

64
00:02:39,840 --> 00:02:40,720
today

65
00:02:40,720 --> 00:02:42,080
read the link

66
00:02:42,080 --> 00:02:44,560
number three is a malware inside machine

67
00:02:44,560 --> 00:02:47,120
learning models obviously you can kind

68
00:02:47,120 --> 00:02:49,360
of put some custom layers and kind of

69
00:02:49,360 --> 00:02:51,920
height malware in your model we won't

70
00:02:51,920 --> 00:02:54,879
talk about it today and of course in use

71
00:02:54,879 --> 00:02:58,239
of the latest days uh the bug in

72
00:02:58,239 --> 00:02:59,519
tensorflow

73
00:02:59,519 --> 00:03:02,800
in yaml civilization we won't talk about

74
00:03:02,800 --> 00:03:05,200
that today yes sorry sorry not the

75
00:03:05,200 --> 00:03:06,400
topics of the day this is a

76
00:03:06,400 --> 00:03:08,080
cryptographic talk

77
00:03:08,080 --> 00:03:09,920
no fancy things

78
00:03:09,920 --> 00:03:13,120
what we will talk is cryptography a

79
00:03:13,120 --> 00:03:16,239
little bit of tensorflow a little bit of

80
00:03:16,239 --> 00:03:18,000
ip protection intellectual property

81
00:03:18,000 --> 00:03:19,519
protection right

82
00:03:19,519 --> 00:03:22,159
we will name things like application

83
00:03:22,159 --> 00:03:24,480
level encryption we will name things

84
00:03:24,480 --> 00:03:25,519
like

85
00:03:25,519 --> 00:03:29,360
hpka hybrid public key encryption and we

86
00:03:29,360 --> 00:03:32,159
will of course speak how to integrate

87
00:03:32,159 --> 00:03:35,360
cryptography into you know real world

88
00:03:35,360 --> 00:03:38,319
into other traditional security controls

89
00:03:38,319 --> 00:03:40,799
right we will speak about um api

90
00:03:40,799 --> 00:03:43,519
protection cloud security mobile

91
00:03:43,519 --> 00:03:47,360
application security uh anti-reverse

92
00:03:47,360 --> 00:03:48,720
engineering

93
00:03:48,720 --> 00:03:50,879
and anti-fraud

94
00:03:50,879 --> 00:03:53,280
okay so if you

95
00:03:53,280 --> 00:03:56,159
wanna hear about that okay don't don't

96
00:03:56,159 --> 00:03:58,159
like stay stay stand youtube if you

97
00:03:58,159 --> 00:04:00,400
wanna read about fancy things just

98
00:04:00,400 --> 00:04:02,239
follow the links and

99
00:04:02,239 --> 00:04:04,239
obviously i will share my slides

100
00:04:04,239 --> 00:04:06,480
afterwards so all these links will be

101
00:04:06,480 --> 00:04:09,280
available for you to explore and i

102
00:04:09,280 --> 00:04:10,640
really encourage you

103
00:04:10,640 --> 00:04:12,400
exploring things

104
00:04:12,400 --> 00:04:15,280
let's move

105
00:04:15,280 --> 00:04:18,399
what is our case for today

106
00:04:18,399 --> 00:04:21,839
imagine total artificial case no name

107
00:04:21,839 --> 00:04:25,120
dropping no company names imagine that

108
00:04:25,120 --> 00:04:27,280
you're a large company and you work in

109
00:04:27,280 --> 00:04:29,919
machine learning space and to create

110
00:04:29,919 --> 00:04:32,479
mobile applications android and ios

111
00:04:32,479 --> 00:04:34,320
applications that work with this machine

112
00:04:34,320 --> 00:04:35,919
learning with these machine learning

113
00:04:35,919 --> 00:04:38,000
models

114
00:04:38,000 --> 00:04:41,440
right now you have a huge

115
00:04:41,440 --> 00:04:44,080
model on your back end right on your

116
00:04:44,080 --> 00:04:47,040
backhand side that serves requests so

117
00:04:47,040 --> 00:04:49,680
your mobile applications make requests

118
00:04:49,680 --> 00:04:52,400
so your backend your backend use machine

119
00:04:52,400 --> 00:04:55,759
learning to create response and send it

120
00:04:55,759 --> 00:04:58,880
back to your mobile applications however

121
00:04:58,880 --> 00:05:01,360
you have really really a lot of users

122
00:05:01,360 --> 00:05:04,400
millions of downloads you're pretty uh

123
00:05:04,400 --> 00:05:07,680
popular in the app store and

124
00:05:07,680 --> 00:05:09,120
google play market

125
00:05:09,120 --> 00:05:11,520
right so you would like to decrease a

126
00:05:11,520 --> 00:05:14,000
load from your server side to your

127
00:05:14,000 --> 00:05:17,600
client side basically to put some pieces

128
00:05:17,600 --> 00:05:19,840
of this huge machine learning module to

129
00:05:19,840 --> 00:05:23,440
the client side to the application side

130
00:05:23,440 --> 00:05:24,400
but this

131
00:05:24,400 --> 00:05:27,360
opens totally new security challenges

132
00:05:27,360 --> 00:05:29,039
and threat factors

133
00:05:29,039 --> 00:05:31,280
and the case we will discuss today is

134
00:05:31,280 --> 00:05:34,080
how to protect these small pieces the

135
00:05:34,080 --> 00:05:36,240
small machine learning models that you

136
00:05:36,240 --> 00:05:38,880
basically put out of nowhere like you

137
00:05:38,880 --> 00:05:41,680
put out of your trusted back end to

138
00:05:41,680 --> 00:05:44,960
these tiny mobile applications hundreds

139
00:05:44,960 --> 00:05:47,360
of them thousands of them installed uh

140
00:05:47,360 --> 00:05:50,080
in your huge huge user base

141
00:05:50,080 --> 00:05:51,360
so

142
00:05:51,360 --> 00:05:53,280
what is as i mentioned what is was

143
00:05:53,280 --> 00:05:54,400
before

144
00:05:54,400 --> 00:05:57,120
before your mobile application sent a

145
00:05:57,120 --> 00:06:00,000
request to your backend your backend has

146
00:06:00,000 --> 00:06:02,319
access to this large

147
00:06:02,319 --> 00:06:05,199
full machine learning model um it

148
00:06:05,199 --> 00:06:08,880
executes uh this request it generates

149
00:06:08,880 --> 00:06:10,240
something

150
00:06:10,240 --> 00:06:13,840
and it gives response back to the client

151
00:06:13,840 --> 00:06:16,080
side every time when user i don't know

152
00:06:16,080 --> 00:06:18,400
wants to see a cat picture

153
00:06:18,400 --> 00:06:19,680
with

154
00:06:19,680 --> 00:06:23,039
cat ears right like use a photo with cat

155
00:06:23,039 --> 00:06:25,759
ears they send requests to the back end

156
00:06:25,759 --> 00:06:27,600
backhand needs to do these calculations

157
00:06:27,600 --> 00:06:30,960
and send response a response image back

158
00:06:30,960 --> 00:06:32,880
okay repeats every time of course when

159
00:06:32,880 --> 00:06:34,880
you have like hundreds and millions of

160
00:06:34,880 --> 00:06:37,120
users this is a little bit complicated

161
00:06:37,120 --> 00:06:38,880
so you want to change that

162
00:06:38,880 --> 00:06:41,520
uh you are changing the scheme

163
00:06:41,520 --> 00:06:43,840
now application send request to your

164
00:06:43,840 --> 00:06:47,280
backend instead of creating a ready

165
00:06:47,280 --> 00:06:50,240
response your back-end creates small

166
00:06:50,240 --> 00:06:51,919
individual

167
00:06:51,919 --> 00:06:53,840
machine learning module

168
00:06:53,840 --> 00:06:55,840
you know and send it back to the client

169
00:06:55,840 --> 00:06:58,800
side and then client-side executes this

170
00:06:58,800 --> 00:07:02,160
passionate model so instead of creating

171
00:07:02,160 --> 00:07:04,800
um hundreds of images on the backend you

172
00:07:04,800 --> 00:07:06,880
put this load on the client side now

173
00:07:06,880 --> 00:07:09,120
your client side your mobile application

174
00:07:09,120 --> 00:07:11,680
is responsible to create these nice

175
00:07:11,680 --> 00:07:14,800
images of people with cat ears you know

176
00:07:14,800 --> 00:07:16,880
what i mean right so and these

177
00:07:16,880 --> 00:07:18,720
individual machine learning models we

178
00:07:18,720 --> 00:07:21,919
will call them iml during the

179
00:07:21,919 --> 00:07:25,840
presentation uh they are unique per user

180
00:07:25,840 --> 00:07:28,400
so you have hundreds of downloads each

181
00:07:28,400 --> 00:07:30,639
download is a device each device is the

182
00:07:30,639 --> 00:07:33,120
kind of user and this user can have a

183
00:07:33,120 --> 00:07:34,960
lot of these models

184
00:07:34,960 --> 00:07:37,039
but you don't need to make requests

185
00:07:37,039 --> 00:07:40,160
every time user wants to see a picture

186
00:07:40,160 --> 00:07:43,120
of them with the cat's ear

187
00:07:43,120 --> 00:07:45,680
with the cat ears to the back so sounds

188
00:07:45,680 --> 00:07:47,199
good

189
00:07:47,199 --> 00:07:48,000
what

190
00:07:48,000 --> 00:07:51,039
kind of security risks uh it opens from

191
00:07:51,039 --> 00:07:53,919
business perspective this switch opens

192
00:07:53,919 --> 00:07:57,680
like advantages are obvious uh you

193
00:07:57,680 --> 00:07:59,680
change the load from your back end to

194
00:07:59,680 --> 00:08:02,000
the client side and instead of paying

195
00:08:02,000 --> 00:08:04,240
for the cloud computation you make

196
00:08:04,240 --> 00:08:06,639
mobile devices of your users to do these

197
00:08:06,639 --> 00:08:09,680
calculations right all good however what

198
00:08:09,680 --> 00:08:12,240
is risk obviously the leakage of ip

199
00:08:12,240 --> 00:08:14,560
because when you put these small machine

200
00:08:14,560 --> 00:08:16,879
learning models to the client side you

201
00:08:16,879 --> 00:08:20,000
basically kind of cut your large model

202
00:08:20,000 --> 00:08:21,440
and you put the sensitive bits of

203
00:08:21,440 --> 00:08:23,039
information for

204
00:08:23,039 --> 00:08:25,599
hundreds of applications that you have

205
00:08:25,599 --> 00:08:29,039
right and uh things like uh competitor

206
00:08:29,039 --> 00:08:31,520
advantage if someone if your competitors

207
00:08:31,520 --> 00:08:33,440
will steal those small models and if

208
00:08:33,440 --> 00:08:35,760
they understand how it works they can

209
00:08:35,760 --> 00:08:38,399
recreate the same model and they can

210
00:08:38,399 --> 00:08:40,640
move your application rating in the

211
00:08:40,640 --> 00:08:43,440
stores so you will need to do something

212
00:08:43,440 --> 00:08:44,159
to

213
00:08:44,159 --> 00:08:46,560
change your model to to involve machine

214
00:08:46,560 --> 00:08:48,800
learning engineers

215
00:08:48,800 --> 00:08:50,800
uh and of course like things like broken

216
00:08:50,800 --> 00:08:53,120
applications cloned applications api

217
00:08:53,120 --> 00:08:56,640
fraud so when you have an api to

218
00:08:56,640 --> 00:08:59,519
generate those small individual machine

219
00:08:59,519 --> 00:09:02,240
learning models this api can be abused

220
00:09:02,240 --> 00:09:04,000
and we don't want that because it means

221
00:09:04,000 --> 00:09:06,959
abusive infrastructure potential denial

222
00:09:06,959 --> 00:09:09,200
of service potential

223
00:09:09,200 --> 00:09:11,839
loss of revenue and of course

224
00:09:11,839 --> 00:09:15,120
losing leaking and abusing the ib

225
00:09:15,120 --> 00:09:17,760
all the things are about money

226
00:09:17,760 --> 00:09:21,519
so it makes sense to invest a little bit

227
00:09:21,519 --> 00:09:24,399
to protect those tiny tiny individual

228
00:09:24,399 --> 00:09:26,320
machine learning models

229
00:09:26,320 --> 00:09:27,600
now

230
00:09:27,600 --> 00:09:29,519
how to protect them let's dig into

231
00:09:29,519 --> 00:09:31,200
cryptographic uh let's dig into

232
00:09:31,200 --> 00:09:34,000
technical stack that we have uh as i

233
00:09:34,000 --> 00:09:35,600
mentioned we have mobile applications

234
00:09:35,600 --> 00:09:38,320
and in this case these are

235
00:09:38,320 --> 00:09:40,399
native nice and native mobile

236
00:09:40,399 --> 00:09:43,760
applications uh objective c swift and

237
00:09:43,760 --> 00:09:46,800
core male framework on ios site kotlin

238
00:09:46,800 --> 00:09:48,640
and tensorflow literature work on

239
00:09:48,640 --> 00:09:52,240
android style nothing fancy very native

240
00:09:52,240 --> 00:09:55,040
and we have a cloud side and back end

241
00:09:55,040 --> 00:09:57,279
technically this technology like

242
00:09:57,279 --> 00:09:59,120
technology i will speak about the

243
00:09:59,120 --> 00:10:01,279
protection of models itself is cloud

244
00:10:01,279 --> 00:10:04,720
agnostic we don't care what cloud is it

245
00:10:04,720 --> 00:10:07,040
but for the sake of example i will use

246
00:10:07,040 --> 00:10:09,600
google cloud platform so on the back end

247
00:10:09,600 --> 00:10:12,079
we will have python tensorflow and

248
00:10:12,079 --> 00:10:15,920
google cloud platform services like uh

249
00:10:15,920 --> 00:10:19,040
gce computation engine like workers you

250
00:10:19,040 --> 00:10:22,399
know like storage like google cloud kms

251
00:10:22,399 --> 00:10:24,959
different kind of databases firebase all

252
00:10:24,959 --> 00:10:27,519
the nice things that google cloud can

253
00:10:27,519 --> 00:10:28,720
give you

254
00:10:28,720 --> 00:10:32,959
aws has the same so cloud doesn't matter

255
00:10:32,959 --> 00:10:33,920
we just

256
00:10:33,920 --> 00:10:35,680
it just um

257
00:10:35,680 --> 00:10:37,920
just the cloud

258
00:10:37,920 --> 00:10:40,079
moving to architecture

259
00:10:40,079 --> 00:10:41,839
this is more or less how very very

260
00:10:41,839 --> 00:10:44,000
high-level architecture might look like

261
00:10:44,000 --> 00:10:46,480
let's move from right to left on this

262
00:10:46,480 --> 00:10:49,120
scheme let's start from the right so

263
00:10:49,120 --> 00:10:51,279
obviously in your company you have this

264
00:10:51,279 --> 00:10:53,839
main tensorflow architecture where you

265
00:10:53,839 --> 00:10:55,440
have this large

266
00:10:55,440 --> 00:10:57,120
machine learning models where you have

267
00:10:57,120 --> 00:11:00,240
some training services training servers

268
00:11:00,240 --> 00:11:01,920
and we don't care about this piece at

269
00:11:01,920 --> 00:11:05,279
all because this is not a part of ip you

270
00:11:05,279 --> 00:11:07,279
put on the clients this is something

271
00:11:07,279 --> 00:11:10,480
that is trusted in your network right

272
00:11:10,480 --> 00:11:12,720
you try to protect that

273
00:11:12,720 --> 00:11:16,959
next how you generate these small imls

274
00:11:16,959 --> 00:11:19,920
you have some um cloud workers some

275
00:11:19,920 --> 00:11:23,120
servers that probably use outer scale so

276
00:11:23,120 --> 00:11:25,519
they can spawn they can

277
00:11:25,519 --> 00:11:28,800
exit and they generate these small

278
00:11:28,800 --> 00:11:31,360
individual machine learning models based

279
00:11:31,360 --> 00:11:33,279
on some user data

280
00:11:33,279 --> 00:11:36,720
based on this large tension from model

281
00:11:36,720 --> 00:11:39,600
and store put those small machine

282
00:11:39,600 --> 00:11:42,399
learning models into into some storage

283
00:11:42,399 --> 00:11:44,240
it could be google cloud platform

284
00:11:44,240 --> 00:11:48,160
storage it could be a aws s3 bucket no

285
00:11:48,160 --> 00:11:50,639
matter so you generate those individual

286
00:11:50,639 --> 00:11:52,399
machine models you put them into the

287
00:11:52,399 --> 00:11:54,880
storage your mobile application and you

288
00:11:54,880 --> 00:11:56,639
do this on request

289
00:11:56,639 --> 00:11:58,880
on request your mobile application send

290
00:11:58,880 --> 00:12:01,279
request hey i need a machine learning

291
00:12:01,279 --> 00:12:03,200
iml for my user

292
00:12:03,200 --> 00:12:06,320
to the api api triggers cloud worker

293
00:12:06,320 --> 00:12:09,760
cloud workers generate imls they put it

294
00:12:09,760 --> 00:12:13,600
to the storage api provides a link

295
00:12:13,600 --> 00:12:16,079
devices download

296
00:12:16,079 --> 00:12:18,079
the model from a link very

297
00:12:18,079 --> 00:12:19,920
straightforward and then devices will

298
00:12:19,920 --> 00:12:23,680
execute the model on device site so from

299
00:12:23,680 --> 00:12:25,920
in terms of ip protection in terms of

300
00:12:25,920 --> 00:12:28,880
protecting imls we are really interested

301
00:12:28,880 --> 00:12:31,760
only in this part of the data flow right

302
00:12:31,760 --> 00:12:33,839
on the left

303
00:12:33,839 --> 00:12:38,480
uh the the the places where iml is

304
00:12:38,480 --> 00:12:40,560
and to put it in the nice table view we

305
00:12:40,560 --> 00:12:43,040
can say that okay imail

306
00:12:43,040 --> 00:12:46,000
is generated on a client on the cloud

307
00:12:46,000 --> 00:12:46,959
site

308
00:12:46,959 --> 00:12:50,240
and it is in the memory of this worker

309
00:12:50,240 --> 00:12:52,959
right then it's get uh transited to the

310
00:12:52,959 --> 00:12:55,760
storage and it is stored like data

311
00:12:55,760 --> 00:12:58,560
address storage on the cloud side then

312
00:12:58,560 --> 00:13:02,320
it is transited to the via api to the

313
00:13:02,320 --> 00:13:03,839
mobile site

314
00:13:03,839 --> 00:13:06,000
right and on the mobile side it is

315
00:13:06,000 --> 00:13:07,839
stored somewhere in the mobile

316
00:13:07,839 --> 00:13:09,120
application

317
00:13:09,120 --> 00:13:11,839
in some like file system or cache and

318
00:13:11,839 --> 00:13:13,680
then of course in the mobile site it

319
00:13:13,680 --> 00:13:16,639
gets executed so this model appears in

320
00:13:16,639 --> 00:13:19,279
memory so basically we have this machine

321
00:13:19,279 --> 00:13:21,600
learning model like everywhere in memory

322
00:13:21,600 --> 00:13:23,680
in transit and storage

323
00:13:23,680 --> 00:13:27,360
sounds like a cryptographic task

324
00:13:27,360 --> 00:13:28,959
let's talk a little bit about threat

325
00:13:28,959 --> 00:13:30,000
modeling

326
00:13:30,000 --> 00:13:32,399
very very simplified okay

327
00:13:32,399 --> 00:13:34,800
what are the potential threats threat

328
00:13:34,800 --> 00:13:37,120
vectors and attack surfaces in this uh

329
00:13:37,120 --> 00:13:38,560
infrastructure

330
00:13:38,560 --> 00:13:39,760
uh

331
00:13:39,760 --> 00:13:40,800
how

332
00:13:40,800 --> 00:13:43,519
these imls can be steeled obviously

333
00:13:43,519 --> 00:13:46,639
using api uh we are leakage we are

334
00:13:46,639 --> 00:13:48,560
abusing

335
00:13:48,560 --> 00:13:50,959
obviously from the storage if you can

336
00:13:50,959 --> 00:13:53,600
just go and pick a link you know all

337
00:13:53,600 --> 00:13:57,440
these cases with aws three buckets when

338
00:13:57,440 --> 00:14:00,000
buckets are public when links are public

339
00:14:00,000 --> 00:14:02,480
and anyone who knows a link or who can

340
00:14:02,480 --> 00:14:05,040
enumerate all their resources on these

341
00:14:05,040 --> 00:14:07,760
buckets can get access so similar when

342
00:14:07,760 --> 00:14:09,920
you start something on the cloud public

343
00:14:09,920 --> 00:14:12,639
on a public cloud storage

344
00:14:12,639 --> 00:14:15,120
this data can be found so it's very

345
00:14:15,120 --> 00:14:17,120
important to take a look on access

346
00:14:17,120 --> 00:14:18,240
controls

347
00:14:18,240 --> 00:14:21,199
now transit yes active men in the middle

348
00:14:21,199 --> 00:14:23,760
passive man in the middle uh active man

349
00:14:23,760 --> 00:14:25,120
in the middle might be really

350
00:14:25,120 --> 00:14:28,720
interesting imagine that you can

351
00:14:28,720 --> 00:14:31,040
you can uh check

352
00:14:31,040 --> 00:14:32,800
the um

353
00:14:32,800 --> 00:14:35,360
there must like you can intercept and

354
00:14:35,360 --> 00:14:38,480
tamper the machine learning model from

355
00:14:38,480 --> 00:14:40,959
its way through the back end to the

356
00:14:40,959 --> 00:14:44,079
mobile side and change it right it would

357
00:14:44,079 --> 00:14:46,720
be really cool to change the model and

358
00:14:46,720 --> 00:14:49,440
instead of i don't know putting cat ears

359
00:14:49,440 --> 00:14:52,800
on the user faces you can put dog ears

360
00:14:52,800 --> 00:14:54,800
okay like cat nose

361
00:14:54,800 --> 00:14:55,680
or

362
00:14:55,680 --> 00:14:57,760
all really bad things you can put really

363
00:14:57,760 --> 00:14:59,519
bad things on this machine learning

364
00:14:59,519 --> 00:15:03,040
model well so we really care about

365
00:15:03,040 --> 00:15:05,839
men in the middle passive or active and

366
00:15:05,839 --> 00:15:08,160
of course mobile applications are a huge

367
00:15:08,160 --> 00:15:10,320
part of the tax office because the

368
00:15:10,320 --> 00:15:11,680
machine learning models are getting

369
00:15:11,680 --> 00:15:12,560
there

370
00:15:12,560 --> 00:15:14,639
they are stored there so they're subject

371
00:15:14,639 --> 00:15:16,880
to reverse engineering techniques

372
00:15:16,880 --> 00:15:17,680
uh

373
00:15:17,680 --> 00:15:19,519
you can imagine this some kind of

374
00:15:19,519 --> 00:15:22,800
crowdsourcing right if your competitors

375
00:15:22,800 --> 00:15:24,160
would like to

376
00:15:24,160 --> 00:15:27,360
get a lot of those models they can ask

377
00:15:27,360 --> 00:15:30,079
users to send those models to you and

378
00:15:30,079 --> 00:15:32,000
you can also imagine different kind of

379
00:15:32,000 --> 00:15:34,399
cloned applications a broken application

380
00:15:34,399 --> 00:15:36,880
or like malware applications that are

381
00:15:36,880 --> 00:15:39,600
available at 4pda

382
00:15:39,600 --> 00:15:41,120
which

383
00:15:41,120 --> 00:15:44,160
gives gives users like nice shiny

384
00:15:44,160 --> 00:15:47,600
features however uh have some malicious

385
00:15:47,600 --> 00:15:50,240
code that will send those models to

386
00:15:50,240 --> 00:15:52,959
their back-ends instead right so a tax

387
00:15:52,959 --> 00:15:56,800
office is quite large threat vectors are

388
00:15:56,800 --> 00:15:59,360
numerous and if you're talking about

389
00:15:59,360 --> 00:16:01,920
stride kind of model we are mostly

390
00:16:01,920 --> 00:16:04,320
interested in spoofing tampering

391
00:16:04,320 --> 00:16:07,040
disclosure and denial of service and of

392
00:16:07,040 --> 00:16:09,279
course cryptography won't help you a lot

393
00:16:09,279 --> 00:16:11,120
with the number of service but will

394
00:16:11,120 --> 00:16:13,120
definitely help you with confidentiality

395
00:16:13,120 --> 00:16:15,440
integrity and authenticity

396
00:16:15,440 --> 00:16:17,839
of the data of these machine learning

397
00:16:17,839 --> 00:16:18,800
models

398
00:16:18,800 --> 00:16:21,279
this was introduction part

399
00:16:21,279 --> 00:16:23,920
and i think now you're ready

400
00:16:23,920 --> 00:16:27,120
to basically dig into crypto pod

401
00:16:27,120 --> 00:16:29,519
yay

402
00:16:30,079 --> 00:16:34,399
so before we start discussing encryption

403
00:16:34,399 --> 00:16:37,519
of machine learning models let's

404
00:16:37,519 --> 00:16:38,399
think

405
00:16:38,399 --> 00:16:39,920
for a second what is the machine

406
00:16:39,920 --> 00:16:43,040
learning model itself

407
00:16:43,519 --> 00:16:45,759
and disclaimer

408
00:16:45,759 --> 00:16:48,959
i am not an email engineer okay so if

409
00:16:48,959 --> 00:16:51,199
you're an engineer you probably know

410
00:16:51,199 --> 00:16:54,079
things about machine learning model

411
00:16:54,079 --> 00:16:56,480
better than me i am security engineer so

412
00:16:56,480 --> 00:16:59,040
sorry from security perspective um

413
00:16:59,040 --> 00:17:01,519
machine learning model is just a file

414
00:17:01,519 --> 00:17:02,880
okay okay this doesn't look a little bit

415
00:17:02,880 --> 00:17:05,280
sophisticated file because it contains

416
00:17:05,280 --> 00:17:08,000
some model data it contains some like

417
00:17:08,000 --> 00:17:10,880
procedure algorithm how to get this data

418
00:17:10,880 --> 00:17:11,679
right

419
00:17:11,679 --> 00:17:14,160
uh but from security perspective this is

420
00:17:14,160 --> 00:17:17,679
just a file with some structure uh in

421
00:17:17,679 --> 00:17:20,559
our case it was layered structure with

422
00:17:20,559 --> 00:17:21,599
weights

423
00:17:21,599 --> 00:17:23,039
right so

424
00:17:23,039 --> 00:17:25,919
the file with sensitive data the data

425
00:17:25,919 --> 00:17:28,640
inside file like weights is sensitive

426
00:17:28,640 --> 00:17:31,679
data very simple very straightforward

427
00:17:31,679 --> 00:17:34,400
yes sorry no no exciting machine

428
00:17:34,400 --> 00:17:36,320
learning things here for you from

429
00:17:36,320 --> 00:17:38,480
cryptographic perspective when we will

430
00:17:38,480 --> 00:17:40,559
take a look on the architecture scheme

431
00:17:40,559 --> 00:17:43,760
back we will see that um we can use very

432
00:17:43,760 --> 00:17:47,440
naive approach to encrypt data

433
00:17:47,440 --> 00:17:50,480
the machine learning model is created on

434
00:17:50,480 --> 00:17:52,960
the working side on the backend side

435
00:17:52,960 --> 00:17:53,919
cool

436
00:17:53,919 --> 00:17:56,240
we create the model we will encrypt the

437
00:17:56,240 --> 00:17:59,039
model right after creation we will store

438
00:17:59,039 --> 00:18:01,120
this model encrypted across all of the

439
00:18:01,120 --> 00:18:03,679
ecosystem across all the infrastructure

440
00:18:03,679 --> 00:18:05,280
we want to install it in the cloud

441
00:18:05,280 --> 00:18:07,360
storage okay no problem we will store it

442
00:18:07,360 --> 00:18:10,320
encrypted as a file right then when

443
00:18:10,320 --> 00:18:12,320
mobile application will get a link to

444
00:18:12,320 --> 00:18:14,080
download this model they don't know the

445
00:18:14,080 --> 00:18:17,520
model and then they they decrypt

446
00:18:17,520 --> 00:18:19,919
the model very very straightforward and

447
00:18:19,919 --> 00:18:22,000
you as you can as you can see that

448
00:18:22,000 --> 00:18:24,799
encryption and decryption points in this

449
00:18:24,799 --> 00:18:27,280
infrastructure they are different

450
00:18:27,280 --> 00:18:28,480
which means

451
00:18:28,480 --> 00:18:30,160
that we can use

452
00:18:30,160 --> 00:18:32,470
public key encryption cryptography here

453
00:18:32,470 --> 00:18:33,600
[Music]

454
00:18:33,600 --> 00:18:36,400
um but before we do that let's discuss

455
00:18:36,400 --> 00:18:39,039
requirements of encryption layer because

456
00:18:39,039 --> 00:18:42,480
why build things that don't satisfy our

457
00:18:42,480 --> 00:18:43,919
requirements

458
00:18:43,919 --> 00:18:46,240
as any requirements to cryptography it

459
00:18:46,240 --> 00:18:50,080
should be fast smooth cool

460
00:18:50,080 --> 00:18:52,799
it should work everywhere it should be

461
00:18:52,799 --> 00:18:55,280
super easy in terms of cryptography and

462
00:18:55,280 --> 00:18:58,240
super easy in terms of key management

463
00:18:58,240 --> 00:19:00,320
come on we are active we like

464
00:19:00,320 --> 00:19:01,919
application with machine learning and

465
00:19:01,919 --> 00:19:04,080
artificial intelligence we don't know

466
00:19:04,080 --> 00:19:06,799
how to build a proper pki how to build a

467
00:19:06,799 --> 00:19:08,799
proper public infrastructure can we

468
00:19:08,799 --> 00:19:10,480
please avoid that

469
00:19:10,480 --> 00:19:13,039
right uh and obviously cryptographic

470
00:19:13,039 --> 00:19:15,840
protection should should solve two main

471
00:19:15,840 --> 00:19:18,160
challenges to minimize

472
00:19:18,160 --> 00:19:21,039
lifetime of plain text models

473
00:19:21,039 --> 00:19:23,039
so to store it encrypted as much as

474
00:19:23,039 --> 00:19:25,600
possible first right and the second to

475
00:19:25,600 --> 00:19:29,440
avoid accumulating a lot of those small

476
00:19:29,440 --> 00:19:34,240
models which means to use different keys

477
00:19:34,240 --> 00:19:37,120
different encryption keys across the

478
00:19:37,120 --> 00:19:40,320
models because imagine if you have these

479
00:19:40,320 --> 00:19:42,799
hundreds and millions of downloads

480
00:19:42,799 --> 00:19:46,400
hundreds millions of users and even more

481
00:19:46,400 --> 00:19:48,320
models if you use the same encryption

482
00:19:48,320 --> 00:19:50,559
key across all the machine learning

483
00:19:50,559 --> 00:19:51,520
modules

484
00:19:51,520 --> 00:19:54,720
well your security is not so great so we

485
00:19:54,720 --> 00:19:56,960
suggest obviously to use different

486
00:19:56,960 --> 00:19:59,760
encryption keys to use unique encryption

487
00:19:59,760 --> 00:20:01,840
keys per model

488
00:20:01,840 --> 00:20:04,000
and in terms of key management key

489
00:20:04,000 --> 00:20:06,159
management this might be tricky but

490
00:20:06,159 --> 00:20:08,880
cryptography we know things how to build

491
00:20:08,880 --> 00:20:10,640
key hierarchies

492
00:20:10,640 --> 00:20:13,760
right which i will explain soon so

493
00:20:13,760 --> 00:20:15,760
what we want from cryptography

494
00:20:15,760 --> 00:20:17,200
encrypt model

495
00:20:17,200 --> 00:20:19,440
right after generation decrypt it only

496
00:20:19,440 --> 00:20:23,360
before usage use a nice traditional

497
00:20:23,360 --> 00:20:27,600
fan no fancy ciphers like is the 56 gcm

498
00:20:27,600 --> 00:20:30,320
like elliptic of different helmet

499
00:20:30,320 --> 00:20:32,799
fast mode and cryptography

500
00:20:32,799 --> 00:20:35,760
i use the femoral keys like temporary

501
00:20:35,760 --> 00:20:38,240
keys to avoid building complicated

502
00:20:38,240 --> 00:20:40,400
public infrastructure and of course use

503
00:20:40,400 --> 00:20:42,880
cryptographic libraries that work across

504
00:20:42,880 --> 00:20:45,120
all the platform keeping in mind all

505
00:20:45,120 --> 00:20:47,120
future platform you want to build

506
00:20:47,120 --> 00:20:49,840
we will use stems for this purpose

507
00:20:49,840 --> 00:20:53,520
let's see how um how this

508
00:20:53,520 --> 00:20:55,600
architecturally around how these

509
00:20:55,600 --> 00:20:57,679
encryption and decryption points will

510
00:20:57,679 --> 00:21:01,280
look like in a flow in a sequence on the

511
00:21:01,280 --> 00:21:04,000
mobile side mobile application generates

512
00:21:04,000 --> 00:21:06,559
keypair mobile keypad

513
00:21:06,559 --> 00:21:09,360
it sends public key to the backend site

514
00:21:09,360 --> 00:21:12,320
right this step of the key exchange on

515
00:21:12,320 --> 00:21:14,320
the backend side

516
00:21:14,320 --> 00:21:16,799
back-end application workers in this

517
00:21:16,799 --> 00:21:19,200
example it will generate its own

518
00:21:19,200 --> 00:21:20,960
server-side keypad

519
00:21:20,960 --> 00:21:23,440
all right it will take public key from

520
00:21:23,440 --> 00:21:24,640
application

521
00:21:24,640 --> 00:21:28,000
own private key use elliptical difficult

522
00:21:28,000 --> 00:21:32,240
magic to create to derive a shared key

523
00:21:32,240 --> 00:21:33,280
right

524
00:21:33,280 --> 00:21:36,080
then on the back end we will generate

525
00:21:36,080 --> 00:21:37,440
random

526
00:21:37,440 --> 00:21:40,320
deck deck means date encryption key

527
00:21:40,320 --> 00:21:43,120
random data encryption key we will take

528
00:21:43,120 --> 00:21:45,200
our individual machine learning model we

529
00:21:45,200 --> 00:21:47,360
will encrypt it using this

530
00:21:47,360 --> 00:21:52,320
newly generated deck using is the 562cm

531
00:21:52,320 --> 00:21:53,919
encrypt version learning model into

532
00:21:53,919 --> 00:21:55,840
encrypted machine learning model

533
00:21:55,840 --> 00:21:56,880
then

534
00:21:56,880 --> 00:21:58,480
what we will do with the key because we

535
00:21:58,480 --> 00:22:00,559
can generate generate this key we will

536
00:22:00,559 --> 00:22:02,000
encrypt the key

537
00:22:02,000 --> 00:22:03,840
right we will encrypt data encryption

538
00:22:03,840 --> 00:22:06,720
key with shared key we generated on the

539
00:22:06,720 --> 00:22:08,080
step 2.

540
00:22:08,080 --> 00:22:13,399
we will use same i as facing gcm

541
00:22:13,520 --> 00:22:16,159
and this is what we got encrypted model

542
00:22:16,159 --> 00:22:19,520
encrypted data encryption key and server

543
00:22:19,520 --> 00:22:21,440
public key this is our package this is

544
00:22:21,440 --> 00:22:22,320
our

545
00:22:22,320 --> 00:22:23,760
data structure

546
00:22:23,760 --> 00:22:26,240
we send this package we store it on the

547
00:22:26,240 --> 00:22:28,559
cloud side and then we send it to this

548
00:22:28,559 --> 00:22:30,240
mobile application

549
00:22:30,240 --> 00:22:33,760
upon receiving mobile application takes

550
00:22:33,760 --> 00:22:35,840
its own private key

551
00:22:35,840 --> 00:22:39,039
which was a part of a key pair

552
00:22:39,039 --> 00:22:41,440
generated on step one

553
00:22:41,440 --> 00:22:44,159
so it takes its own private key and

554
00:22:44,159 --> 00:22:46,880
server public key from the package to

555
00:22:46,880 --> 00:22:49,280
derive to use the same elliptic code if

556
00:22:49,280 --> 00:22:51,679
you have one to derive the same shared

557
00:22:51,679 --> 00:22:53,039
key

558
00:22:53,039 --> 00:22:56,960
right then using shared key it decrypts

559
00:22:56,960 --> 00:23:00,400
encrypted data encryption key right

560
00:23:00,400 --> 00:23:02,960
uh and using this data encryption key it

561
00:23:02,960 --> 00:23:04,080
decrypts

562
00:23:04,080 --> 00:23:07,280
the machine learning model here you are

563
00:23:07,280 --> 00:23:10,799
simple straightforward um ies gcm

564
00:23:10,799 --> 00:23:13,120
electrical dv helmet well of course in

565
00:23:13,120 --> 00:23:16,000
cryptographic details probably after

566
00:23:16,000 --> 00:23:18,799
deriving shared key we will need to

567
00:23:18,799 --> 00:23:22,000
use h career for something like that to

568
00:23:22,000 --> 00:23:23,919
derive stronger cryptographic keys but

569
00:23:23,919 --> 00:23:25,919
this real cryptography details i don't

570
00:23:25,919 --> 00:23:29,919
want to dig into let's look at the code

571
00:23:29,919 --> 00:23:33,440
uh let's look at the uh format show so

572
00:23:33,440 --> 00:23:36,159
this is how this is how modern machine

573
00:23:36,159 --> 00:23:39,919
learning model might look like or like

574
00:23:39,919 --> 00:23:43,520
api response might look like simple json

575
00:23:43,520 --> 00:23:45,679
you have your your encrypted machine

576
00:23:45,679 --> 00:23:48,000
learning model and encrypted model right

577
00:23:48,000 --> 00:23:50,559
you have your encrypted key you have

578
00:23:50,559 --> 00:23:52,720
public key of the backhand side

579
00:23:52,720 --> 00:23:55,440
why the key is ephemeral

580
00:23:55,440 --> 00:23:58,080
because these key pairs are temporary

581
00:23:58,080 --> 00:23:58,960
and

582
00:23:58,960 --> 00:24:01,840
because backhand won't store it keypair

583
00:24:01,840 --> 00:24:05,440
it just rescue pair it uses keypair

584
00:24:05,440 --> 00:24:06,400
um

585
00:24:06,400 --> 00:24:08,080
this technology like their pro which is

586
00:24:08,080 --> 00:24:10,880
called called ephemeral keys or throw

587
00:24:10,880 --> 00:24:13,360
away keys we generated cryptographic

588
00:24:13,360 --> 00:24:15,600
keys we use them we don't need them

589
00:24:15,600 --> 00:24:17,039
anymore we don't need to store them

590
00:24:17,039 --> 00:24:20,320
anymore right

591
00:24:20,320 --> 00:24:21,919
encryption version because this is very

592
00:24:21,919 --> 00:24:23,840
important to put encryption version on

593
00:24:23,840 --> 00:24:26,240
any encryption systems that you build

594
00:24:26,240 --> 00:24:27,600
because you will

595
00:24:27,600 --> 00:24:30,960
want to rebuild this system soon

596
00:24:30,960 --> 00:24:32,880
and maybe some additional encryption

597
00:24:32,880 --> 00:24:35,679
inside your machine learning model later

598
00:24:35,679 --> 00:24:36,640
later

599
00:24:36,640 --> 00:24:39,440
uh this is how this is how the code

600
00:24:39,440 --> 00:24:42,559
might look like and honestly this is a

601
00:24:42,559 --> 00:24:45,360
more or less compatible python code i

602
00:24:45,360 --> 00:24:47,279
noticed it looks like a pseudocode but

603
00:24:47,279 --> 00:24:49,679
it's technically i think i believe you

604
00:24:49,679 --> 00:24:51,120
can compile it

605
00:24:51,120 --> 00:24:53,840
uh this is all cryptographic codes that

606
00:24:53,840 --> 00:24:56,559
we need if we use stamis temps is a

607
00:24:56,559 --> 00:24:58,480
cryptographic library i will talk about

608
00:24:58,480 --> 00:25:01,440
it in two slides so

609
00:25:01,440 --> 00:25:04,320
uh the encryption part the backend part

610
00:25:04,320 --> 00:25:06,320
as we previously explained

611
00:25:06,320 --> 00:25:09,200
generate compare generate

612
00:25:09,200 --> 00:25:11,840
data encryption key temporary write

613
00:25:11,840 --> 00:25:13,039
encrypt

614
00:25:13,039 --> 00:25:14,400
the model

615
00:25:14,400 --> 00:25:17,600
encrypt date encryption key and send

616
00:25:17,600 --> 00:25:20,240
encrypted model encrypted key and own

617
00:25:20,240 --> 00:25:21,679
public key

618
00:25:21,679 --> 00:25:25,679
decryption part mobile part i used swift

619
00:25:25,679 --> 00:25:28,720
an example here and again this code this

620
00:25:28,720 --> 00:25:30,559
is a code it's not a civic code this is

621
00:25:30,559 --> 00:25:32,080
a real code it's i believe it's

622
00:25:32,080 --> 00:25:33,360
compilable

623
00:25:33,360 --> 00:25:36,240
right and this is all encryption coding

624
00:25:36,240 --> 00:25:38,159
you will need in this case

625
00:25:38,159 --> 00:25:41,520
on mobile site generate keypair

626
00:25:41,520 --> 00:25:42,640
take

627
00:25:42,640 --> 00:25:45,600
own private keys server public key

628
00:25:45,600 --> 00:25:46,960
decrypt

629
00:25:46,960 --> 00:25:49,600
your date encryption key then decrypt a

630
00:25:49,600 --> 00:25:52,240
model here very straightforward very

631
00:25:52,240 --> 00:25:53,520
easy

632
00:25:53,520 --> 00:25:57,760
the reason why we have only like 12

633
00:25:57,760 --> 00:26:00,240
lines of cryptographic code is because

634
00:26:00,240 --> 00:26:02,320
we use nice tools instead of spending

635
00:26:02,320 --> 00:26:05,200
time fighting with openness ssl we can

636
00:26:05,200 --> 00:26:07,840
use modern boring cryptography library

637
00:26:07,840 --> 00:26:10,799
and in this case we use this disclaimer

638
00:26:10,799 --> 00:26:13,520
like this is an open source library

639
00:26:13,520 --> 00:26:16,080
maintained by caller claps team so we

640
00:26:16,080 --> 00:26:18,000
use it pretty often but of course you

641
00:26:18,000 --> 00:26:20,559
can use another boring crypto libraries

642
00:26:20,559 --> 00:26:23,200
like lip sodium for example really nice

643
00:26:23,200 --> 00:26:25,840
they just beware because if you have a

644
00:26:25,840 --> 00:26:29,039
lot of platforms to support you might

645
00:26:29,039 --> 00:26:31,279
want to find libraries that work on

646
00:26:31,279 --> 00:26:34,000
these platforms right because many many

647
00:26:34,000 --> 00:26:36,640
many problems with cryptography come

648
00:26:36,640 --> 00:26:39,279
from different apis of cryptographic

649
00:26:39,279 --> 00:26:42,559
libraries across different platforms

650
00:26:42,559 --> 00:26:45,360
so with stemis it's not the case because

651
00:26:45,360 --> 00:26:47,440
it's a single library that works across

652
00:26:47,440 --> 00:26:49,679
many platforms and it hides

653
00:26:49,679 --> 00:26:52,000
cryptographic details you see in this

654
00:26:52,000 --> 00:26:55,279
code you don't see these uh keywords

655
00:26:55,279 --> 00:26:58,320
like ios you don't see the keyword like

656
00:26:58,320 --> 00:27:01,600
elliptic uh elliptical dv helmet you

657
00:27:01,600 --> 00:27:04,640
don't know anything about init vector

658
00:27:04,640 --> 00:27:07,039
about nouns about key lengths keep

659
00:27:07,039 --> 00:27:08,000
padding

660
00:27:08,000 --> 00:27:10,320
because if you're a software engineer

661
00:27:10,320 --> 00:27:11,520
you don't

662
00:27:11,520 --> 00:27:13,760
need this kind of details you just want

663
00:27:13,760 --> 00:27:15,440
things to work

664
00:27:15,440 --> 00:27:16,400
right

665
00:27:16,400 --> 00:27:19,360
boring clips are not exciting at all

666
00:27:19,360 --> 00:27:21,279
and a nice thing that stamis was

667
00:27:21,279 --> 00:27:23,279
actually recommended by a wasp as a

668
00:27:23,279 --> 00:27:25,760
library to use mobile devices when you

669
00:27:25,760 --> 00:27:27,760
make cross platform application which is

670
00:27:27,760 --> 00:27:30,240
kit and which is technically our use

671
00:27:30,240 --> 00:27:32,159
case here

672
00:27:32,159 --> 00:27:35,600
just to to introduce a new term probably

673
00:27:35,600 --> 00:27:38,000
in your life the idea that they just

674
00:27:38,000 --> 00:27:41,200
explained that back-end and mobile

675
00:27:41,200 --> 00:27:42,559
applications are encrypting and

676
00:27:42,559 --> 00:27:45,360
decrypting better you know and data

677
00:27:45,360 --> 00:27:47,440
stays encrypted across

678
00:27:47,440 --> 00:27:49,200
all the other pieces of your

679
00:27:49,200 --> 00:27:51,840
infrastructure this idea is called

680
00:27:51,840 --> 00:27:54,159
application level encryption

681
00:27:54,159 --> 00:27:56,159
right so new term

682
00:27:56,159 --> 00:27:58,799
new hype works in your vocabulary

683
00:27:58,799 --> 00:28:00,799
basically it's just a marketing term

684
00:28:00,799 --> 00:28:02,399
right basically application level

685
00:28:02,399 --> 00:28:04,399
encryption means that this is encryption

686
00:28:04,399 --> 00:28:06,960
um that is kind of built into

687
00:28:06,960 --> 00:28:09,600
application any application uh triggered

688
00:28:09,600 --> 00:28:11,440
by application part of the application

689
00:28:11,440 --> 00:28:14,559
code right obviously it can be a library

690
00:28:14,559 --> 00:28:16,960
in your code it can be a separate

691
00:28:16,960 --> 00:28:19,600
service right while we distinguish

692
00:28:19,600 --> 00:28:22,320
application level encryption just to

693
00:28:22,320 --> 00:28:23,679
um

694
00:28:23,679 --> 00:28:25,120
to tell

695
00:28:25,120 --> 00:28:26,080
that

696
00:28:26,080 --> 00:28:30,159
there could be data at rest encryption

697
00:28:30,159 --> 00:28:32,559
in your database for example there could

698
00:28:32,559 --> 00:28:36,880
be data in motion encryption like tls

699
00:28:36,880 --> 00:28:38,880
right and there is application level

700
00:28:38,880 --> 00:28:41,279
encryption and only and these three

701
00:28:41,279 --> 00:28:43,279
different types of encryption they work

702
00:28:43,279 --> 00:28:45,919
on different levels so you can have all

703
00:28:45,919 --> 00:28:48,559
of them at the same time and using

704
00:28:48,559 --> 00:28:50,399
application level encryption means that

705
00:28:50,399 --> 00:28:53,200
you probably still use tls you probably

706
00:28:53,200 --> 00:28:55,279
still use data trust encryption in your

707
00:28:55,279 --> 00:28:58,000
database right but now your applications

708
00:28:58,000 --> 00:29:00,240
are responsible to encrypt and decrypt

709
00:29:00,240 --> 00:29:02,559
data of course it could be client-side

710
00:29:02,559 --> 00:29:04,320
server sides or

711
00:29:04,320 --> 00:29:05,120
and

712
00:29:05,120 --> 00:29:07,760
the description is in fact application

713
00:29:07,760 --> 00:29:09,840
level encryption

714
00:29:09,840 --> 00:29:12,480
i don't want to talk more about

715
00:29:12,480 --> 00:29:14,320
application level encryption

716
00:29:14,320 --> 00:29:16,880
it has different um

717
00:29:16,880 --> 00:29:18,960
risks and threats and provide different

718
00:29:18,960 --> 00:29:22,000
like guarantees comparing to tls

719
00:29:22,000 --> 00:29:24,399
comparing to file system encryption or

720
00:29:24,399 --> 00:29:26,720
database encryption and of course

721
00:29:26,720 --> 00:29:29,279
end-to-end just ultimate you know

722
00:29:29,279 --> 00:29:32,320
ultimate um category of application

723
00:29:32,320 --> 00:29:34,399
level encryption if you're curious to

724
00:29:34,399 --> 00:29:36,799
learn more please follow the article

725
00:29:36,799 --> 00:29:39,760
below at infaque we wrote huge huge

726
00:29:39,760 --> 00:29:42,159
article about application of encryption

727
00:29:42,159 --> 00:29:44,799
and different key management problem

728
00:29:44,799 --> 00:29:47,279
related to having your applications

729
00:29:47,279 --> 00:29:50,080
perform cryptographic code

730
00:29:50,080 --> 00:29:52,960
another term that you might like and

731
00:29:52,960 --> 00:29:54,799
another term to your cryptographic

732
00:29:54,799 --> 00:29:58,159
vocabulary is um hybrid public

733
00:29:58,159 --> 00:29:59,720
encryption

734
00:29:59,720 --> 00:30:04,080
hpka so again link in the bottom

735
00:30:04,080 --> 00:30:05,840
so um

736
00:30:05,840 --> 00:30:08,159
what is happening here basically this

737
00:30:08,159 --> 00:30:10,799
approach this idea is not new as many

738
00:30:10,799 --> 00:30:13,279
things in cryptography it's ancient

739
00:30:13,279 --> 00:30:17,039
uh just the name is new because rfc

740
00:30:17,039 --> 00:30:20,720
that explains hpke approach uh is quite

741
00:30:20,720 --> 00:30:22,799
new and rfc

742
00:30:22,799 --> 00:30:27,200
explains like tries to um standard

743
00:30:27,200 --> 00:30:30,320
to make a standard tries to describe

744
00:30:30,320 --> 00:30:35,520
different hpk approaches try to you know

745
00:30:35,520 --> 00:30:37,520
to to make a standard

746
00:30:37,520 --> 00:30:38,399
so

747
00:30:38,399 --> 00:30:41,039
maybe in two or three years when we will

748
00:30:41,039 --> 00:30:43,520
speak about hpke

749
00:30:43,520 --> 00:30:45,760
both of us will understand what it means

750
00:30:45,760 --> 00:30:48,080
because right now

751
00:30:48,080 --> 00:30:50,159
not many people understand what it means

752
00:30:50,159 --> 00:30:53,440
and the rfc tries to make it you know a

753
00:30:53,440 --> 00:30:54,640
standard

754
00:30:54,640 --> 00:30:56,159
basically uh

755
00:30:56,159 --> 00:30:58,159
hybrid public key encryption means that

756
00:30:58,159 --> 00:31:00,880
you combine symmetrical cryptography and

757
00:31:00,880 --> 00:31:03,279
asymmetric cryptography

758
00:31:03,279 --> 00:31:05,760
as we did in our example we use

759
00:31:05,760 --> 00:31:07,840
symmetric cipher in our example we use

760
00:31:07,840 --> 00:31:09,519
symmetric cipher

761
00:31:09,519 --> 00:31:11,039
authentication encryption with

762
00:31:11,039 --> 00:31:15,120
additional data right ilgcm to encrypt

763
00:31:15,120 --> 00:31:18,399
machine learning model itself and then

764
00:31:18,399 --> 00:31:22,159
we use um public key encryption

765
00:31:22,159 --> 00:31:24,880
electrical diffie-hellman drive

766
00:31:24,880 --> 00:31:27,200
shared key at the other to encrypt the

767
00:31:27,200 --> 00:31:29,679
key the data encryption key right and

768
00:31:29,679 --> 00:31:32,640
combining symmetric symmetric encryption

769
00:31:32,640 --> 00:31:33,519
is

770
00:31:33,519 --> 00:31:36,880
an approach called hpk

771
00:31:36,880 --> 00:31:40,000
the rfc describes different um

772
00:31:40,000 --> 00:31:42,640
different formats different ways how to

773
00:31:42,640 --> 00:31:44,399
do that you can combine different

774
00:31:44,399 --> 00:31:46,320
ciphers you can combine different hash

775
00:31:46,320 --> 00:31:47,760
functions

776
00:31:47,760 --> 00:31:50,399
and as i mentioned tries to tries to

777
00:31:50,399 --> 00:31:52,480
make it a standard

778
00:31:52,480 --> 00:31:54,960
so neutron for you okay let's get back

779
00:31:54,960 --> 00:31:57,679
to our cryptographic scheme what in this

780
00:31:57,679 --> 00:32:01,679
scheme uh what we achieved in terms of

781
00:32:01,679 --> 00:32:03,679
key management the key management

782
00:32:03,679 --> 00:32:05,919
another example is super lightweight

783
00:32:05,919 --> 00:32:08,159
it's super easy because we use this

784
00:32:08,159 --> 00:32:11,840
ephemeral key pairs we don't need a

785
00:32:11,840 --> 00:32:15,600
normal strong secure pki you know

786
00:32:15,600 --> 00:32:17,360
building public infrastructure is a

787
00:32:17,360 --> 00:32:19,200
struggle that many companies do

788
00:32:19,200 --> 00:32:22,720
especially even in security right so

789
00:32:22,720 --> 00:32:25,919
in our case we didn't uh we don't build

790
00:32:25,919 --> 00:32:30,399
pki we kind of have protofikai because

791
00:32:30,399 --> 00:32:34,320
to be able to pin our users we can store

792
00:32:34,320 --> 00:32:37,519
the public keys in the database but

793
00:32:37,519 --> 00:32:40,640
this very very lightweight pikai just

794
00:32:40,640 --> 00:32:43,519
storing public user keys it's not a pica

795
00:32:43,519 --> 00:32:47,039
itself right and obviously as our female

796
00:32:47,039 --> 00:32:50,080
as our keepers are ephemeral we don't

797
00:32:50,080 --> 00:32:52,960
actually care a lot about um

798
00:32:52,960 --> 00:32:55,360
key management procedures explained in

799
00:32:55,360 --> 00:32:56,399
nist

800
00:32:56,399 --> 00:32:58,720
yes we care about degeneration we don't

801
00:32:58,720 --> 00:33:01,120
care about key rotation mostly we don't

802
00:33:01,120 --> 00:33:03,120
care about pure vacation because we

803
00:33:03,120 --> 00:33:05,679
create cryptographic keys we use them

804
00:33:05,679 --> 00:33:08,080
and we forget about them easy you don't

805
00:33:08,080 --> 00:33:10,000
need to revolve keys that exist one

806
00:33:10,000 --> 00:33:11,279
minute right

807
00:33:11,279 --> 00:33:13,840
uh very nice very nice approach

808
00:33:13,840 --> 00:33:15,919
obviously it won't work everywhere and

809
00:33:15,919 --> 00:33:18,960
the main burden of key management goes

810
00:33:18,960 --> 00:33:21,679
into mobile applications because on

811
00:33:21,679 --> 00:33:24,720
mobile applications they need to store

812
00:33:24,720 --> 00:33:27,279
encryption keys and they have luckily

813
00:33:27,279 --> 00:33:30,799
they have um keychain and crystal to

814
00:33:30,799 --> 00:33:34,799
store keys and uh on ios for example we

815
00:33:34,799 --> 00:33:38,159
can even bind these keys

816
00:33:38,159 --> 00:33:39,120
using

817
00:33:39,120 --> 00:33:42,320
secure enclave right so build proper key

818
00:33:42,320 --> 00:33:45,440
storage in our bio applications uh

819
00:33:45,440 --> 00:33:47,760
unfortunately this approach won't solve

820
00:33:47,760 --> 00:33:49,600
the authenticity problem

821
00:33:49,600 --> 00:33:52,559
i remember our men in the middle example

822
00:33:52,559 --> 00:33:54,799
if someone will steal the machine

823
00:33:54,799 --> 00:33:56,720
learning model and

824
00:33:56,720 --> 00:34:00,000
change it our client side almost doesn't

825
00:34:00,000 --> 00:34:03,120
have a way to make sure that machine

826
00:34:03,120 --> 00:34:05,360
learning model came from trusted

827
00:34:05,360 --> 00:34:08,000
back-end but cryptography won't help

828
00:34:08,000 --> 00:34:09,359
here

829
00:34:09,359 --> 00:34:11,599
we can use other security like

830
00:34:11,599 --> 00:34:13,760
traditional security things like

831
00:34:13,760 --> 00:34:15,839
server-side attestation and taylor

832
00:34:15,839 --> 00:34:19,040
spinning to make sure that device trusts

833
00:34:19,040 --> 00:34:20,639
the back end

834
00:34:20,639 --> 00:34:23,440
now let's make it even more complicated

835
00:34:23,440 --> 00:34:26,560
because this is just a basically right

836
00:34:26,560 --> 00:34:28,639
on device site

837
00:34:28,639 --> 00:34:30,000
when device

838
00:34:30,000 --> 00:34:31,440
received

839
00:34:31,440 --> 00:34:33,760
individual machine learning model and

840
00:34:33,760 --> 00:34:36,800
the group stage a device can re-encrypt

841
00:34:36,800 --> 00:34:39,199
it like application can re-encrypt the

842
00:34:39,199 --> 00:34:41,520
model before storage

843
00:34:41,520 --> 00:34:44,159
very simple just generate another

844
00:34:44,159 --> 00:34:47,199
symmetric key and encrypt this model

845
00:34:47,199 --> 00:34:48,560
before storage

846
00:34:48,560 --> 00:34:49,760
why

847
00:34:49,760 --> 00:34:53,040
because in this case um

848
00:34:53,040 --> 00:34:55,440
this device this application won't need

849
00:34:55,440 --> 00:34:58,960
access to its own private key or backend

850
00:34:58,960 --> 00:35:00,240
public key

851
00:35:00,240 --> 00:35:01,359
right

852
00:35:01,359 --> 00:35:03,599
if this model with style is there like

853
00:35:03,599 --> 00:35:06,400
for four months for example uh the

854
00:35:06,400 --> 00:35:09,200
application won't need to store

855
00:35:09,200 --> 00:35:11,760
all the keys requires to to decrypt this

856
00:35:11,760 --> 00:35:14,880
model if it uses another symmetric key

857
00:35:14,880 --> 00:35:17,200
to encrypt to re-encrypt the model of

858
00:35:17,200 --> 00:35:18,960
course it will mean that we will need to

859
00:35:18,960 --> 00:35:20,720
store yet another key but come on we

860
00:35:20,720 --> 00:35:22,800
have keystore and keychain we can we can

861
00:35:22,800 --> 00:35:23,760
do that

862
00:35:23,760 --> 00:35:26,400
bonus points if we use uh biometric

863
00:35:26,400 --> 00:35:28,880
binding with keychair for example whisky

864
00:35:28,880 --> 00:35:30,880
chain

865
00:35:30,880 --> 00:35:32,320
now next

866
00:35:32,320 --> 00:35:34,720
so re-encryption on device size

867
00:35:34,720 --> 00:35:37,280
uh step two in our cryptographic defense

868
00:35:37,280 --> 00:35:39,599
and depth adds more cryptography to

869
00:35:39,599 --> 00:35:41,200
protects cryptography

870
00:35:41,200 --> 00:35:44,240
you as you can see from this example

871
00:35:44,240 --> 00:35:47,839
the lifetime of plain text individual

872
00:35:47,839 --> 00:35:48,800
machine

873
00:35:48,800 --> 00:35:52,160
machine learning model is quite limited

874
00:35:52,160 --> 00:35:53,040
right

875
00:35:53,040 --> 00:35:56,640
in plain text those models live on leave

876
00:35:56,640 --> 00:35:58,960
only during generation

877
00:35:58,960 --> 00:36:01,599
during this decryption on mobile site

878
00:36:01,599 --> 00:36:03,359
under encryption likely

879
00:36:03,359 --> 00:36:05,280
and during execution

880
00:36:05,280 --> 00:36:07,440
and the execution part

881
00:36:07,440 --> 00:36:10,880
where mobile application will execute

882
00:36:10,880 --> 00:36:13,119
machine learning model this execution

883
00:36:13,119 --> 00:36:14,480
part is

884
00:36:14,480 --> 00:36:17,359
complicated because most frameworks like

885
00:36:17,359 --> 00:36:20,640
core ml for example on ios it requires

886
00:36:20,640 --> 00:36:22,800
the machine learning file

887
00:36:22,800 --> 00:36:25,920
to be in plain text right when you use

888
00:36:25,920 --> 00:36:29,280
api to load the model into memory the

889
00:36:29,280 --> 00:36:32,640
file should be in plain text however we

890
00:36:32,640 --> 00:36:35,920
can use nice quarter mail tricks

891
00:36:35,920 --> 00:36:37,680
uh to

892
00:36:37,680 --> 00:36:38,839
to add

893
00:36:38,839 --> 00:36:42,240
encryption inside layers

894
00:36:42,240 --> 00:36:44,240
of our model

895
00:36:44,240 --> 00:36:45,839
right so

896
00:36:45,839 --> 00:36:47,839
all the steps before we were talking

897
00:36:47,839 --> 00:36:50,000
about machine learning encryption as a

898
00:36:50,000 --> 00:36:50,960
file

899
00:36:50,960 --> 00:36:51,760
now

900
00:36:51,760 --> 00:36:55,440
remember that these models us have

901
00:36:55,440 --> 00:36:58,560
structure and they have layers

902
00:36:58,560 --> 00:37:02,320
so we can create custom layers that are

903
00:37:02,320 --> 00:37:04,480
encrypted

904
00:37:04,480 --> 00:37:06,400
right and we can decrypt them before

905
00:37:06,400 --> 00:37:08,800
loading the model to the shader

906
00:37:08,800 --> 00:37:11,200
which will means cpu

907
00:37:11,200 --> 00:37:14,079
load on the mobile application or we can

908
00:37:14,079 --> 00:37:18,000
go even further and we can create custom

909
00:37:18,000 --> 00:37:19,280
shaders

910
00:37:19,280 --> 00:37:20,960
to obfuscate

911
00:37:20,960 --> 00:37:22,400
wait before

912
00:37:22,400 --> 00:37:24,960
executing on the gpu before executing on

913
00:37:24,960 --> 00:37:28,400
the shader unfortunately gpus don't have

914
00:37:28,400 --> 00:37:31,440
a lot of memory so we cannot use real

915
00:37:31,440 --> 00:37:33,280
encryption to

916
00:37:33,280 --> 00:37:34,560
um

917
00:37:34,560 --> 00:37:35,839
to

918
00:37:35,839 --> 00:37:36,800
encrypt

919
00:37:36,800 --> 00:37:39,680
weights in the shader itself however you

920
00:37:39,680 --> 00:37:41,280
can use different kind of discussion

921
00:37:41,280 --> 00:37:43,119
techniques source

922
00:37:43,119 --> 00:37:46,079
and very lightweight cryptography also

923
00:37:46,079 --> 00:37:49,119
apple has really nice dopes that explain

924
00:37:49,119 --> 00:37:52,320
that you can in fact encrypt the file of

925
00:37:52,320 --> 00:37:54,480
machine learning model and explains how

926
00:37:54,480 --> 00:37:56,079
to do that

927
00:37:56,079 --> 00:37:58,400
this is like a tricky bit uh a little

928
00:37:58,400 --> 00:38:01,280
bit in from machine learning perspective

929
00:38:01,280 --> 00:38:03,440
right so

930
00:38:03,440 --> 00:38:06,240
model file itself and try to encrypt

931
00:38:06,240 --> 00:38:09,359
layers inside the machine learning

932
00:38:09,359 --> 00:38:10,800
file

933
00:38:10,800 --> 00:38:12,640
obviously encryption means performance

934
00:38:12,640 --> 00:38:15,520
penalties as i mentioned previously gpu

935
00:38:15,520 --> 00:38:16,640
shaders

936
00:38:16,640 --> 00:38:18,880
have quite limited cache memory we

937
00:38:18,880 --> 00:38:20,480
cannot run

938
00:38:20,480 --> 00:38:22,720
typical ciphers there so we either use

939
00:38:22,720 --> 00:38:25,200
obfuscation or we use very very

940
00:38:25,200 --> 00:38:27,200
lightweight cryptography

941
00:38:27,200 --> 00:38:30,079
in our example we use normal standard

942
00:38:30,079 --> 00:38:33,280
like traditional fast cryptography with

943
00:38:33,280 --> 00:38:36,640
hardware acceleration like iodcm so

944
00:38:36,640 --> 00:38:39,280
we don't have crypto won't take a lot of

945
00:38:39,280 --> 00:38:41,599
time the thing here is

946
00:38:41,599 --> 00:38:44,640
if your mobile devices can run caramel

947
00:38:44,640 --> 00:38:47,599
models with quite high

948
00:38:47,599 --> 00:38:50,800
fps right so without noticeable changes

949
00:38:50,800 --> 00:38:52,240
for people

950
00:38:52,240 --> 00:38:53,920
it usually means that your mobile

951
00:38:53,920 --> 00:38:56,320
devices can do cryptography really fast

952
00:38:56,320 --> 00:38:58,400
right so again no noticeability

953
00:38:58,400 --> 00:39:00,960
exchanges

954
00:39:01,200 --> 00:39:03,040
and generally speaking

955
00:39:03,040 --> 00:39:05,280
it might be like on the back end in

956
00:39:05,280 --> 00:39:07,200
generating these individual machine

957
00:39:07,200 --> 00:39:09,440
learning models encrypting them sending

958
00:39:09,440 --> 00:39:12,000
them and declaring on the client side

959
00:39:12,000 --> 00:39:14,560
might be faster

960
00:39:14,560 --> 00:39:15,599
than

961
00:39:15,599 --> 00:39:17,760
exit than the previous approach this

962
00:39:17,760 --> 00:39:20,400
company used executing models on the

963
00:39:20,400 --> 00:39:22,560
backup

964
00:39:22,560 --> 00:39:26,160
so what we did here we encrypted the

965
00:39:26,160 --> 00:39:28,960
machine learning um the machine learning

966
00:39:28,960 --> 00:39:31,839
model life cycle across

967
00:39:31,839 --> 00:39:34,000
like machine learning file across its

968
00:39:34,000 --> 00:39:37,119
life cycle and we did our best to cover

969
00:39:37,119 --> 00:39:38,960
the whole data flow

970
00:39:38,960 --> 00:39:40,960
but as i mentioned previously

971
00:39:40,960 --> 00:39:43,839
cryptography it's kind of boring if you

972
00:39:43,839 --> 00:39:47,759
don't combine it with other

973
00:39:48,320 --> 00:39:50,720
sorry with other

974
00:39:50,720 --> 00:39:53,680
security controls

975
00:39:55,680 --> 00:39:57,520
so remember

976
00:39:57,520 --> 00:39:59,839
now we have the scheme

977
00:39:59,839 --> 00:40:02,160
where we already use uh crypto on the

978
00:40:02,160 --> 00:40:04,720
bottom side we already store encrypted

979
00:40:04,720 --> 00:40:06,960
data on the cloud and we use crypto on

980
00:40:06,960 --> 00:40:09,599
mobile sites to decrypt data

981
00:40:09,599 --> 00:40:12,079
and now let's put traditional security

982
00:40:12,079 --> 00:40:15,359
control there plus ports authentication

983
00:40:15,359 --> 00:40:18,319
api secrets application security frauds

984
00:40:18,319 --> 00:40:21,280
and reverse engineering yada yada yada

985
00:40:21,280 --> 00:40:24,240
because cryptography doesn't uh work in

986
00:40:24,240 --> 00:40:26,720
vacuum and doesn't exist in vacuum you

987
00:40:26,720 --> 00:40:28,560
still need these traditional security

988
00:40:28,560 --> 00:40:30,880
controls you still need to log you still

989
00:40:30,880 --> 00:40:33,040
need to monitor you still need to

990
00:40:33,040 --> 00:40:35,440
understand whether users are malicious

991
00:40:35,440 --> 00:40:36,960
or not

992
00:40:36,960 --> 00:40:39,680
let me talk really quickly about some of

993
00:40:39,680 --> 00:40:42,240
these uh security controls

994
00:40:42,240 --> 00:40:44,960
which are especially efficient working

995
00:40:44,960 --> 00:40:47,200
together with scripture for example

996
00:40:47,200 --> 00:40:49,760
cloud storage security we've

997
00:40:49,760 --> 00:40:52,240
mentioned this previously if you have

998
00:40:52,240 --> 00:40:53,760
aws

999
00:40:53,760 --> 00:40:56,800
s3 buckets or if you have google cloud

1000
00:40:56,800 --> 00:40:58,960
platform storage

1001
00:40:58,960 --> 00:41:01,520
you might want to check

1002
00:41:01,520 --> 00:41:04,560
a wasp has a special like a wasp as a

1003
00:41:04,560 --> 00:41:07,680
guide a guideline how not to make

1004
00:41:07,680 --> 00:41:10,560
configuration mistakes when you use uh

1005
00:41:10,560 --> 00:41:13,599
public cloud storage obviously the

1006
00:41:13,599 --> 00:41:15,920
the approaches are well known

1007
00:41:15,920 --> 00:41:17,839
and you try to limit

1008
00:41:17,839 --> 00:41:20,960
life cycle of the files that you store

1009
00:41:20,960 --> 00:41:23,520
so you don't forget to

1010
00:41:23,520 --> 00:41:26,960
clean those uh files to remove those

1011
00:41:26,960 --> 00:41:29,520
files physically right you don't forget

1012
00:41:29,520 --> 00:41:30,560
to use

1013
00:41:30,560 --> 00:41:31,760
ttl

1014
00:41:31,760 --> 00:41:35,920
on the urls like access urls so the url

1015
00:41:35,920 --> 00:41:38,560
itself will expire really quickly in

1016
00:41:38,560 --> 00:41:40,560
another example basically by the way we

1017
00:41:40,560 --> 00:41:43,200
use ttls really small like one minute or

1018
00:41:43,200 --> 00:41:46,240
so so the idea was that when mobile

1019
00:41:46,240 --> 00:41:48,960
application make request

1020
00:41:48,960 --> 00:41:50,800
backhand can generate all this

1021
00:41:50,800 --> 00:41:52,720
individual machine learning model put it

1022
00:41:52,720 --> 00:41:54,960
to the cloud storage and get it back in

1023
00:41:54,960 --> 00:41:56,240
response

1024
00:41:56,240 --> 00:41:58,319
under several seconds

1025
00:41:58,319 --> 00:42:00,400
right so ttl

1026
00:42:00,400 --> 00:42:04,160
with one minute lifetime was enough

1027
00:42:04,160 --> 00:42:06,319
for mobile application to download the

1028
00:42:06,319 --> 00:42:07,760
model

1029
00:42:07,760 --> 00:42:10,240
obviously authentication access control

1030
00:42:10,240 --> 00:42:12,079
and what is very very interesting that

1031
00:42:12,079 --> 00:42:14,400
many cloud providers have backup

1032
00:42:14,400 --> 00:42:16,480
functionality out of the box

1033
00:42:16,480 --> 00:42:19,520
so do your best try not to backup

1034
00:42:19,520 --> 00:42:21,680
sensitive data

1035
00:42:21,680 --> 00:42:24,400
now api protection well you know all the

1036
00:42:24,400 --> 00:42:26,920
things how to protect api

1037
00:42:26,920 --> 00:42:29,760
authentication api limits request

1038
00:42:29,760 --> 00:42:32,880
rolling firewalling yada yada yada yada

1039
00:42:32,880 --> 00:42:35,920
they just check who was fire squares and

1040
00:42:35,920 --> 00:42:38,400
you're good to go why this is important

1041
00:42:38,400 --> 00:42:42,319
in this case because api was a gateway

1042
00:42:42,319 --> 00:42:45,440
how mobile application will get their

1043
00:42:45,440 --> 00:42:48,640
machine learning models right so yes the

1044
00:42:48,640 --> 00:42:50,400
cryptography of machine learning models

1045
00:42:50,400 --> 00:42:52,240
might be nice but

1046
00:42:52,240 --> 00:42:54,640
if you have uh api without any

1047
00:42:54,640 --> 00:42:57,200
protections anyone can generate like

1048
00:42:57,200 --> 00:42:59,599
hundreds and thousands mathematic models

1049
00:42:59,599 --> 00:43:03,119
for them which defeats the purpose

1050
00:43:03,119 --> 00:43:04,880
of this exercise

1051
00:43:04,880 --> 00:43:07,040
now another nice thing here is

1052
00:43:07,040 --> 00:43:08,800
anti-fraud system

1053
00:43:08,800 --> 00:43:09,920
um

1054
00:43:09,920 --> 00:43:12,960
think about banking anti-fraud think

1055
00:43:12,960 --> 00:43:14,640
about that you

1056
00:43:14,640 --> 00:43:17,920
want to limit

1057
00:43:17,920 --> 00:43:20,400
apis you want to limit

1058
00:43:20,400 --> 00:43:21,920
these models

1059
00:43:21,920 --> 00:43:25,440
for users if they misbehave so you

1060
00:43:25,440 --> 00:43:28,000
basically want to cut malicious uses you

1061
00:43:28,000 --> 00:43:30,319
want to cut suspicious uses and how to

1062
00:43:30,319 --> 00:43:33,680
do that is to calculate user scores

1063
00:43:33,680 --> 00:43:36,160
right you gather events from mobile

1064
00:43:36,160 --> 00:43:38,880
applications from the backend and based

1065
00:43:38,880 --> 00:43:41,920
on these events you calculate scores

1066
00:43:41,920 --> 00:43:44,319
some of these events can be a stop

1067
00:43:44,319 --> 00:43:47,359
factors for example if you detect that

1068
00:43:47,359 --> 00:43:50,319
device is jailbroken or rooted and it's

1069
00:43:50,319 --> 00:43:52,640
important in your case you send this

1070
00:43:52,640 --> 00:43:54,480
event to the backend and this is stop

1071
00:43:54,480 --> 00:43:58,160
factor we won't send our nice and shiny

1072
00:43:58,160 --> 00:44:00,319
machine learning model to this device

1073
00:44:00,319 --> 00:44:03,280
because it's jam broken sorry no sorry

1074
00:44:03,280 --> 00:44:04,079
right

1075
00:44:04,079 --> 00:44:06,720
if uh the remote device attestation call

1076
00:44:06,720 --> 00:44:07,760
failed

1077
00:44:07,760 --> 00:44:09,920
sorry this is a stop factor no machine

1078
00:44:09,920 --> 00:44:11,680
learning model for you

1079
00:44:11,680 --> 00:44:14,960
if uh this device uses some honey

1080
00:44:14,960 --> 00:44:18,720
talking some honey pot right sorry this

1081
00:44:18,720 --> 00:44:21,599
is probably someone tries to

1082
00:44:21,599 --> 00:44:24,480
to attack our nice system no machine

1083
00:44:24,480 --> 00:44:26,480
learning model for you

1084
00:44:26,480 --> 00:44:29,040
and of course these top factors and this

1085
00:44:29,040 --> 00:44:31,680
rules really depends on your use case

1086
00:44:31,680 --> 00:44:35,040
and your exact infrastructure right so

1087
00:44:35,040 --> 00:44:37,599
uh things that i'm explaining right now

1088
00:44:37,599 --> 00:44:39,520
might be relevant for your case might be

1089
00:44:39,520 --> 00:44:41,599
not relevant at all

1090
00:44:41,599 --> 00:44:44,000
right uh stop factors are very

1091
00:44:44,000 --> 00:44:46,640
straightforward if event happened sorry

1092
00:44:46,640 --> 00:44:49,599
the user is malicious however sometimes

1093
00:44:49,599 --> 00:44:51,839
it's complicated to say that so we have

1094
00:44:51,839 --> 00:44:54,400
rules like scoring rules

1095
00:44:54,400 --> 00:44:55,200
if

1096
00:44:55,200 --> 00:44:58,640
this application tries to download url

1097
00:44:58,640 --> 00:45:03,119
and remember we have ttl url has expired

1098
00:45:03,119 --> 00:45:04,880
like ages ago

1099
00:45:04,880 --> 00:45:06,720
we track this error

1100
00:45:06,720 --> 00:45:09,760
and we increase malicious scoring of the

1101
00:45:09,760 --> 00:45:10,720
user

1102
00:45:10,720 --> 00:45:12,960
if the application gets reinstalled

1103
00:45:12,960 --> 00:45:14,240
really often

1104
00:45:14,240 --> 00:45:17,119
say five times a day we increase the

1105
00:45:17,119 --> 00:45:19,760
malicious score if application makes too

1106
00:45:19,760 --> 00:45:22,079
many requests

1107
00:45:22,079 --> 00:45:24,079
so for every user

1108
00:45:24,079 --> 00:45:27,119
we can calculate a scoring model

1109
00:45:27,119 --> 00:45:30,240
and change behavior depending on user

1110
00:45:30,240 --> 00:45:33,920
scores just block malicious users limit

1111
00:45:33,920 --> 00:45:36,800
suspicious users and provide a nice

1112
00:45:36,800 --> 00:45:38,160
service for

1113
00:45:38,160 --> 00:45:40,720
for normal for okay users

1114
00:45:40,720 --> 00:45:43,040
um let's mention really quick remote

1115
00:45:43,040 --> 00:45:46,160
device attestation both ios and android

1116
00:45:46,160 --> 00:45:49,040
provides api to do remote device

1117
00:45:49,040 --> 00:45:51,599
attestation which means to make sure

1118
00:45:51,599 --> 00:45:54,400
that application was installed in

1119
00:45:54,400 --> 00:45:57,040
legitimate way from the app store or

1120
00:45:57,040 --> 00:46:00,000
play market right check this apis apple

1121
00:46:00,000 --> 00:46:02,880
device check or android safety net

1122
00:46:02,880 --> 00:46:06,000
and of course let's not dive in into

1123
00:46:06,000 --> 00:46:08,800
anti-reverse engineering of mobile

1124
00:46:08,800 --> 00:46:12,319
application just open opposed by myspace

1125
00:46:12,319 --> 00:46:15,200
reverse engineering parts and follow all

1126
00:46:15,200 --> 00:46:16,720
these nice things

1127
00:46:16,720 --> 00:46:19,280
that why it is important to build in in

1128
00:46:19,280 --> 00:46:21,839
our system because again uh mobile

1129
00:46:21,839 --> 00:46:24,160
applications have these machine learning

1130
00:46:24,160 --> 00:46:27,440
models and if someone can easily steal

1131
00:46:27,440 --> 00:46:30,319
them from mobile application this is bad

1132
00:46:30,319 --> 00:46:33,119
if someone can write and like clone the

1133
00:46:33,119 --> 00:46:36,319
application that will steal this modules

1134
00:46:36,319 --> 00:46:40,480
and send it to their server this is bad

1135
00:46:40,480 --> 00:46:42,880
from a male perspective we can also do

1136
00:46:42,880 --> 00:46:45,200
some nice things like building

1137
00:46:45,200 --> 00:46:49,040
watermarks like create those layers

1138
00:46:49,040 --> 00:46:53,040
sophisticated layers or even bind

1139
00:46:53,040 --> 00:46:54,480
our model

1140
00:46:54,480 --> 00:46:58,000
into to our application only but this is

1141
00:46:58,000 --> 00:46:59,440
sophisticated machine learning

1142
00:46:59,440 --> 00:47:01,440
engineering again i'm not a machine

1143
00:47:01,440 --> 00:47:02,800
learning engineer

1144
00:47:02,800 --> 00:47:05,280
let's get back to our scheme

1145
00:47:05,280 --> 00:47:07,920
the message here is that cryptography is

1146
00:47:07,920 --> 00:47:10,480
nice we encrypted machine learning

1147
00:47:10,480 --> 00:47:14,319
models as fast as far as we can and then

1148
00:47:14,319 --> 00:47:17,680
we added traditional security defenses

1149
00:47:17,680 --> 00:47:19,920
four mobile applications for api for

1150
00:47:19,920 --> 00:47:22,079
cloud storage for cloud workers we put

1151
00:47:22,079 --> 00:47:25,119
this login monitoring and our actor

1152
00:47:25,119 --> 00:47:28,880
system is not a black box anymore

1153
00:47:28,880 --> 00:47:31,760
right so encryption is an ultimate

1154
00:47:31,760 --> 00:47:34,079
security control and then traditional

1155
00:47:34,079 --> 00:47:37,440
security controls to support to work in

1156
00:47:37,440 --> 00:47:40,559
parallel to work independently defense

1157
00:47:40,559 --> 00:47:41,680
in depths

1158
00:47:41,680 --> 00:47:44,480
right and this is probably the last

1159
00:47:44,480 --> 00:47:46,480
message for my talk today

1160
00:47:46,480 --> 00:47:49,839
just remember when you're creating uh

1161
00:47:49,839 --> 00:47:51,920
any security system when you're solving

1162
00:47:51,920 --> 00:47:55,040
any use case even as simple as

1163
00:47:55,040 --> 00:47:57,200
protecting machine learning models

1164
00:47:57,200 --> 00:48:00,880
um failure of security control itself

1165
00:48:00,880 --> 00:48:02,240
it's just a question of time like

1166
00:48:02,240 --> 00:48:03,839
failure of cryptography is a question of

1167
00:48:03,839 --> 00:48:06,160
time and your responsibility is to build

1168
00:48:06,160 --> 00:48:08,160
a system that has a lot of the security

1169
00:48:08,160 --> 00:48:10,640
controls that work together because this

1170
00:48:10,640 --> 00:48:12,880
the failure of the whole system is how

1171
00:48:12,880 --> 00:48:14,960
bad your design is like how good your

1172
00:48:14,960 --> 00:48:16,400
design is

1173
00:48:16,400 --> 00:48:19,440
um as usual i put a lot of links in my

1174
00:48:19,440 --> 00:48:20,400
slides

1175
00:48:20,400 --> 00:48:22,880
and some of them i will duplicate on

1176
00:48:22,880 --> 00:48:25,760
this slide some of them are new here

1177
00:48:25,760 --> 00:48:29,359
and my name is anastasiy please

1178
00:48:29,359 --> 00:48:31,119
if you have any questions

1179
00:48:31,119 --> 00:48:34,640
check my twitter check my website all

1180
00:48:34,640 --> 00:48:37,680
check i work as a club site and blog

1181
00:48:37,680 --> 00:48:40,480
posts or white papers you write really a

1182
00:48:40,480 --> 00:48:42,480
lot about cryptography

1183
00:48:42,480 --> 00:48:46,760
that's the end thank you

1184
00:48:55,119 --> 00:48:56,800
thank you nicest

1185
00:48:56,800 --> 00:48:58,720
for the great joke

1186
00:48:58,720 --> 00:49:00,640
for the very nice presentation for

1187
00:49:00,640 --> 00:49:04,079
firing up day 2 of no name con i hope we

1188
00:49:04,079 --> 00:49:06,079
will have

1189
00:49:06,079 --> 00:49:08,880
some audience feedback

1190
00:49:08,880 --> 00:49:10,800
do i see it

1191
00:49:10,800 --> 00:49:13,200
nothing yet but experience tells me that

1192
00:49:13,200 --> 00:49:17,040
yeah we need to give people yeah just

1193
00:49:17,040 --> 00:49:19,599
just put thumbs up if you like it like

1194
00:49:19,599 --> 00:49:22,160
thumbs up the stream on youtube so we

1195
00:49:22,160 --> 00:49:25,759
will know that you watch us

1196
00:49:28,559 --> 00:49:31,520
if you're still with us where are thumbs

1197
00:49:31,520 --> 00:49:32,240
up

1198
00:49:32,240 --> 00:49:35,439
oh yeah there are some

1199
00:49:36,800 --> 00:49:39,599
quite a few

1200
00:49:40,160 --> 00:49:41,599
okay

1201
00:49:41,599 --> 00:49:44,559
are there any questions

1202
00:49:44,559 --> 00:49:46,559
i have questions but i would like to

1203
00:49:46,559 --> 00:49:47,760
hear

1204
00:49:47,760 --> 00:49:50,079
someone else

1205
00:49:50,079 --> 00:49:52,400
asking questions there is peter peter

1206
00:49:52,400 --> 00:49:56,000
will be allowed to talk right now peter

1207
00:49:56,000 --> 00:49:57,599
please go on

1208
00:49:57,599 --> 00:49:59,560
the morning pistons

1209
00:49:59,560 --> 00:50:02,619
[Music]

1210
00:50:06,800 --> 00:50:08,400
my question is uh

1211
00:50:08,400 --> 00:50:10,559
how do you see this whole

1212
00:50:10,559 --> 00:50:12,800
development of quantum computing on the

1213
00:50:12,800 --> 00:50:15,359
matter of cryptography

1214
00:50:15,359 --> 00:50:18,720
and the way we uh encrypt nowaday

1215
00:50:18,720 --> 00:50:19,680
the

1216
00:50:19,680 --> 00:50:21,599
systems we have and

1217
00:50:21,599 --> 00:50:24,400
the data we have

1218
00:50:24,960 --> 00:50:28,160
yeah totally not about my talk however

1219
00:50:28,160 --> 00:50:30,800
as you know um

1220
00:50:30,800 --> 00:50:33,599
we already like nist already has um a

1221
00:50:33,599 --> 00:50:35,599
competition for post quantum

1222
00:50:35,599 --> 00:50:38,640
cryptography or how we name it quantum

1223
00:50:38,640 --> 00:50:42,400
safe cyphers right and we have a number

1224
00:50:42,400 --> 00:50:45,839
of cipher candidates so cypher is that

1225
00:50:45,839 --> 00:50:48,480
right now i believe to be

1226
00:50:48,480 --> 00:50:49,680
okay

1227
00:50:49,680 --> 00:50:52,960
to be strong enough not to be broken by

1228
00:50:52,960 --> 00:50:54,400
quantum computing

1229
00:50:54,400 --> 00:50:57,280
right and in terms of quantum computing

1230
00:50:57,280 --> 00:51:00,559
not everything will be broken so with is

1231
00:51:00,559 --> 00:51:02,400
for example what we will need to do is

1232
00:51:02,400 --> 00:51:04,640
just to increase the killings however

1233
00:51:04,640 --> 00:51:07,280
tls might be broken and that's why many

1234
00:51:07,280 --> 00:51:09,280
companies right now like google like

1235
00:51:09,280 --> 00:51:12,400
cloudflare they are looking to decipher

1236
00:51:12,400 --> 00:51:15,359
to to do this um key exchange

1237
00:51:15,359 --> 00:51:18,559
right that will be quantum safe and i

1238
00:51:18,559 --> 00:51:20,720
really recommend you to read a

1239
00:51:20,720 --> 00:51:23,520
cloudflare blog post from previous year

1240
00:51:23,520 --> 00:51:26,079
i believe where they did an experiment

1241
00:51:26,079 --> 00:51:29,040
of two they compared to different pos

1242
00:51:29,040 --> 00:51:34,079
quantum key exchange algorithms in tls

1243
00:51:34,079 --> 00:51:37,280
to check how fast and cool they are i

1244
00:51:37,280 --> 00:51:39,040
will try to find the link to this blog

1245
00:51:39,040 --> 00:51:43,119
post and send it to you so tia uh tldr

1246
00:51:43,119 --> 00:51:46,480
quantum computing will be here

1247
00:51:46,480 --> 00:51:48,000
in not in

1248
00:51:48,000 --> 00:51:51,760
near future but we already prepared

1249
00:51:51,760 --> 00:51:54,079
the competition for the best post

1250
00:51:54,079 --> 00:51:56,640
quantum cipher is happening right now we

1251
00:51:56,640 --> 00:51:58,960
will select the best cipher will change

1252
00:51:58,960 --> 00:52:02,079
the libraries and only systems that will

1253
00:52:02,079 --> 00:52:07,520
use tls 1.2 and 1.3 are scrooge yeah

1254
00:52:07,520 --> 00:52:08,400
okay

1255
00:52:08,400 --> 00:52:11,200
that's good to know

1256
00:52:16,480 --> 00:52:18,640
okay do we have any more questions

1257
00:52:18,640 --> 00:52:21,280
guys who moderate zoom and youtube do we

1258
00:52:21,280 --> 00:52:24,319
have any questions there

1259
00:52:28,960 --> 00:52:31,599
okay i see a lot of likes on youtube so

1260
00:52:31,599 --> 00:52:34,240
we are really sure that audience are

1261
00:52:34,240 --> 00:52:36,240
listening are watching and listening to

1262
00:52:36,240 --> 00:52:38,559
us okay no worries i will have this

1263
00:52:38,559 --> 00:52:40,000
slime

1264
00:52:40,000 --> 00:52:41,760
i see more likes than

1265
00:52:41,760 --> 00:52:44,880
watchers this makes me wonder how how it

1266
00:52:44,880 --> 00:52:47,760
may happen

1267
00:52:47,760 --> 00:52:49,359
they just log in on the different

1268
00:52:49,359 --> 00:52:51,520
accounts you know

1269
00:52:51,520 --> 00:52:53,760
yeah yeah we have a very creative and

1270
00:52:53,760 --> 00:52:56,800
knowledgeable audience

1271
00:52:57,520 --> 00:52:59,520
yeah there is a question practical one

1272
00:52:59,520 --> 00:53:02,480
how long did it take to implement your

1273
00:53:02,480 --> 00:53:06,079
solution into the application

1274
00:53:06,319 --> 00:53:09,359
not long because as you see it's um

1275
00:53:09,359 --> 00:53:11,839
let's define the implementation yes the

1276
00:53:11,839 --> 00:53:12,880
design

1277
00:53:12,880 --> 00:53:15,040
took a couple of months is because of

1278
00:53:15,040 --> 00:53:17,119
this risk modeling like a risk and

1279
00:53:17,119 --> 00:53:19,839
stress modeling right understanding like

1280
00:53:19,839 --> 00:53:21,359
threat vectors and understanding

1281
00:53:21,359 --> 00:53:23,040
defenses understanding cryptographic

1282
00:53:23,040 --> 00:53:25,280
protocol the implementation itself

1283
00:53:25,280 --> 00:53:28,000
developers did it in a day they test it

1284
00:53:28,000 --> 00:53:30,079
in a day and then they were doing all

1285
00:53:30,079 --> 00:53:32,079
this role out to make sure that users

1286
00:53:32,079 --> 00:53:34,240
are not affected so

1287
00:53:34,240 --> 00:53:35,839
you've seen amount of cryptographic

1288
00:53:35,839 --> 00:53:39,359
codes it's teeny tiny code uh

1289
00:53:39,359 --> 00:53:42,079
the main things were not related to

1290
00:53:42,079 --> 00:53:43,839
cryptography itself the main things were

1291
00:53:43,839 --> 00:53:46,400
related to as a whole approach of

1292
00:53:46,400 --> 00:53:48,240
changing large

1293
00:53:48,240 --> 00:53:50,800
ml model into this small individual

1294
00:53:50,800 --> 00:53:53,359
machine models right but again not my

1295
00:53:53,359 --> 00:53:55,599
area of responsibility i'm not emotional

1296
00:53:55,599 --> 00:53:58,800
engineer i'm sure the team did a great

1297
00:53:58,800 --> 00:54:01,520
job in that

1298
00:54:02,319 --> 00:54:04,480
cool

1299
00:54:04,480 --> 00:54:07,440
there is a question in q a section let's

1300
00:54:07,440 --> 00:54:09,680
start with the first one

1301
00:54:09,680 --> 00:54:11,040
[Music]

1302
00:54:11,040 --> 00:54:14,000
i hope i hope you will get it because

1303
00:54:14,000 --> 00:54:15,839
i don't do it

1304
00:54:15,839 --> 00:54:17,599
entirely so

1305
00:54:17,599 --> 00:54:20,400
is it safe to trust users

1306
00:54:20,400 --> 00:54:23,440
it looks like making a wider attack

1307
00:54:23,440 --> 00:54:25,280
vector

1308
00:54:25,280 --> 00:54:27,280
oh no we don't trust users in this

1309
00:54:27,280 --> 00:54:29,839
example at the title outline we don't

1310
00:54:29,839 --> 00:54:33,359
trust users at all and we do our best to

1311
00:54:33,359 --> 00:54:35,520
you know to make attack surface as

1312
00:54:35,520 --> 00:54:38,480
narrow as possible on the user devices

1313
00:54:38,480 --> 00:54:40,559
we use all these anteros engineering

1314
00:54:40,559 --> 00:54:42,720
measures so we don't trust users that

1315
00:54:42,720 --> 00:54:44,640
use jailbroken devices we don't trust

1316
00:54:44,640 --> 00:54:46,559
users that use rooted devices we even

1317
00:54:46,559 --> 00:54:48,960
don't trust users this reinstall

1318
00:54:48,960 --> 00:54:51,599
application multiple times a day right

1319
00:54:51,599 --> 00:54:53,760
so we don't trust users at all in this

1320
00:54:53,760 --> 00:54:57,200
example and we do our best to

1321
00:54:57,200 --> 00:54:59,599
not trust curious users

1322
00:54:59,599 --> 00:55:02,960
because crowd sourcing is a really nice

1323
00:55:02,960 --> 00:55:05,680
attack vector here imagine this a large

1324
00:55:05,680 --> 00:55:08,319
competitor and you ask users to crowd

1325
00:55:08,319 --> 00:55:09,280
source

1326
00:55:09,280 --> 00:55:13,040
to you know to um to find their machine

1327
00:55:13,040 --> 00:55:15,680
learning models and send it to you this

1328
00:55:15,680 --> 00:55:20,240
is cool we don't trust users at all

1329
00:55:20,240 --> 00:55:22,640
yeah who does

1330
00:55:22,640 --> 00:55:24,640
no one else

1331
00:55:24,640 --> 00:55:26,240
okay it seems that

1332
00:55:26,240 --> 00:55:28,480
it's a rather a suggestion but i think

1333
00:55:28,480 --> 00:55:31,040
uh you might have quite a view on that

1334
00:55:31,040 --> 00:55:33,200
so it seems that homomorphic encryption

1335
00:55:33,200 --> 00:55:35,119
will resolve all machine learning

1336
00:55:35,119 --> 00:55:38,640
problems what do you think about that

1337
00:55:38,640 --> 00:55:40,559
i'm not a fan of homomorphic encryption

1338
00:55:40,559 --> 00:55:42,079
i mean the idea is called the

1339
00:55:42,079 --> 00:55:43,599
implementation

1340
00:55:43,599 --> 00:55:46,640
um is quite far from being

1341
00:55:46,640 --> 00:55:49,599
industry ready however you know recently

1342
00:55:49,599 --> 00:55:51,760
google has um

1343
00:55:51,760 --> 00:55:54,559
published yet another open source

1344
00:55:54,559 --> 00:55:56,799
repository for fully homomorphic

1345
00:55:56,799 --> 00:55:58,880
encryption and it's very interesting to

1346
00:55:58,880 --> 00:56:00,240
begin

1347
00:56:00,240 --> 00:56:01,040
but

1348
00:56:01,040 --> 00:56:03,680
yeah let's wait i'm honestly i think

1349
00:56:03,680 --> 00:56:05,839
that personally from my personal opinion

1350
00:56:05,839 --> 00:56:08,400
that post quantum cryptography ready to

1351
00:56:08,400 --> 00:56:09,280
use

1352
00:56:09,280 --> 00:56:10,720
will be here

1353
00:56:10,720 --> 00:56:13,280
faster than ready to use homomorphic

1354
00:56:13,280 --> 00:56:15,359
encryption by like fully homework

1355
00:56:15,359 --> 00:56:17,520
encryption but fight me this is just my

1356
00:56:17,520 --> 00:56:19,599
opinion

1357
00:56:19,599 --> 00:56:23,119
uh the question from me will it be ever

1358
00:56:23,119 --> 00:56:26,079
useful by mere mortals what do you think

1359
00:56:26,079 --> 00:56:27,520
i mean uh

1360
00:56:27,520 --> 00:56:30,079
it's quite a complicated

1361
00:56:30,079 --> 00:56:30,960
math

1362
00:56:30,960 --> 00:56:34,480
to move to make it usable uh fully yeah

1363
00:56:34,480 --> 00:56:36,240
there are some machine machine learning

1364
00:56:36,240 --> 00:56:38,480
models around that for instance uh

1365
00:56:38,480 --> 00:56:40,960
network vendors one of them we can name

1366
00:56:40,960 --> 00:56:42,559
because it's our sponsor cisco for

1367
00:56:42,559 --> 00:56:44,160
instance they have very interesting

1368
00:56:44,160 --> 00:56:45,839
security detection solutions for

1369
00:56:45,839 --> 00:56:48,319
encrypted traffic because uh it's not

1370
00:56:48,319 --> 00:56:50,400
like fully homomorphic

1371
00:56:50,400 --> 00:56:53,119
you know but there are like correlations

1372
00:56:53,119 --> 00:56:55,119
between how malicious traffic looks in

1373
00:56:55,119 --> 00:56:56,960
clear attacks and encrypted

1374
00:56:56,960 --> 00:56:58,960
yeah so you can like

1375
00:56:58,960 --> 00:57:01,119
derive some uh

1376
00:57:01,119 --> 00:57:03,440
knowledge and insight

1377
00:57:03,440 --> 00:57:05,520
from that and then

1378
00:57:05,520 --> 00:57:08,400
basically extrapolate this knowledge to

1379
00:57:08,400 --> 00:57:10,319
something that you do not know directly

1380
00:57:10,319 --> 00:57:12,640
and entirely but you can guess

1381
00:57:12,640 --> 00:57:15,680
yeah some details so it's of course it

1382
00:57:15,680 --> 00:57:17,040
looks more like

1383
00:57:17,040 --> 00:57:21,359
art than science or technology but

1384
00:57:21,359 --> 00:57:23,839
it seemed to work

1385
00:57:23,839 --> 00:57:24,880
you know

1386
00:57:24,880 --> 00:57:28,000
so yeah will we be there

1387
00:57:28,000 --> 00:57:30,079
i think what he explained is more like

1388
00:57:30,079 --> 00:57:31,760
um

1389
00:57:31,760 --> 00:57:34,480
like a traffic inspection and dlp than

1390
00:57:34,480 --> 00:57:36,960
homomorphic encryption itself right

1391
00:57:36,960 --> 00:57:39,359
so how do you find you make some you

1392
00:57:39,359 --> 00:57:41,520
make some derivations you know you

1393
00:57:41,520 --> 00:57:45,119
derive some uh properties of traffic not

1394
00:57:45,119 --> 00:57:47,280
decrypting it you know

1395
00:57:47,280 --> 00:57:49,760
so i i think it looks like something

1396
00:57:49,760 --> 00:57:51,760
very similar but i i provide this

1397
00:57:51,760 --> 00:57:54,400
example just in order to show that

1398
00:57:54,400 --> 00:57:57,440
it's not homomorphic encryption at all

1399
00:57:57,440 --> 00:58:00,400
but uh it's some kind of thermomorphic

1400
00:58:00,400 --> 00:58:02,160
themed

1401
00:58:02,160 --> 00:58:06,720
technology which uh is a dirty hack okay

1402
00:58:06,720 --> 00:58:09,359
let's let's let's call it the name yeah

1403
00:58:09,359 --> 00:58:12,319
it's a dirty hack but will we be able in

1404
00:58:12,319 --> 00:58:14,160
the near future to use our morphic

1405
00:58:14,160 --> 00:58:17,839
encryption for something provable

1406
00:58:18,160 --> 00:58:20,319
i think that we will stay in this dirty

1407
00:58:20,319 --> 00:58:23,359
hack area for a long time because these

1408
00:58:23,359 --> 00:58:25,599
dirty hugs already exist for searchable

1409
00:58:25,599 --> 00:58:28,160
encryption right so it's possible to

1410
00:58:28,160 --> 00:58:30,160
build such a correction without food or

1411
00:58:30,160 --> 00:58:32,720
more encryption again based on dirty

1412
00:58:32,720 --> 00:58:34,799
hugs and

1413
00:58:34,799 --> 00:58:37,599
one of them is this blind indexes

1414
00:58:37,599 --> 00:58:39,920
approach when you take this query you

1415
00:58:39,920 --> 00:58:42,559
calculate a blind index which is hash

1416
00:58:42,559 --> 00:58:45,680
and you encrypt the data and you search

1417
00:58:45,680 --> 00:58:48,079
by hashes right so the data stays

1418
00:58:48,079 --> 00:58:50,559
encrypted but you search from it but you

1419
00:58:50,559 --> 00:58:54,559
search using hashes so dirty hack

1420
00:58:54,559 --> 00:58:58,400
naughty homomorphic encryption at all

1421
00:59:01,520 --> 00:59:04,960
it's not a dirty first because

1422
00:59:07,760 --> 00:59:11,440
you know many dirty hacks have mad proof

1423
00:59:11,440 --> 00:59:12,319
okay

1424
00:59:12,319 --> 00:59:14,319
uh

1425
00:59:14,319 --> 00:59:15,680
another one

1426
00:59:15,680 --> 00:59:18,240
how fast will we have quantum computers

1427
00:59:18,240 --> 00:59:20,960
don't we have them already

1428
00:59:20,960 --> 00:59:22,880
it's not the same as quantum character

1429
00:59:22,880 --> 00:59:25,680
we have but

1430
00:59:26,000 --> 00:59:28,400
um

1431
00:59:28,720 --> 00:59:30,559
yeah i think alexander what's you trying

1432
00:59:30,559 --> 00:59:34,079
to say that quantum same quantum safe

1433
00:59:34,079 --> 00:59:35,760
crypto we believe that quantum safe

1434
00:59:35,760 --> 00:59:37,839
crypto will be good enough that quantum

1435
00:59:37,839 --> 00:59:40,319
computers won't be broken well not in

1436
00:59:40,319 --> 00:59:42,720
the nearest future yeah but right when

1437
00:59:42,720 --> 00:59:45,119
we will have these quantum computers we

1438
00:59:45,119 --> 00:59:47,200
do have them already

1439
00:59:47,200 --> 00:59:48,160
uh

1440
00:59:48,160 --> 00:59:50,480
check out ibm for example however

1441
00:59:50,480 --> 00:59:53,359
however the trick is that right now they

1442
00:59:53,359 --> 00:59:56,160
we have really small amount of qubits in

1443
00:59:56,160 --> 00:59:58,480
these quantum computers and many

1444
00:59:58,480 --> 01:00:00,480
cryptographers many researchers believe

1445
01:00:00,480 --> 01:00:01,839
that we need

1446
01:00:01,839 --> 01:00:05,359
much much larger amounts of cubies right

1447
01:00:05,359 --> 01:00:07,920
right now we have hundreds i believe and

1448
01:00:07,920 --> 01:00:10,799
we need like 100 thousands like millions

1449
01:00:10,799 --> 01:00:13,280
of qubits to be able to to decrypt

1450
01:00:13,280 --> 01:00:16,000
cryptography i really recommend you

1451
01:00:16,000 --> 01:00:19,440
watching a talk by jean-philippe omazon

1452
01:00:19,440 --> 01:00:21,920
at nonemcon last year

1453
01:00:21,920 --> 01:00:24,559
he was speaking about quantum computing

1454
01:00:24,559 --> 01:00:26,720
and post-quantum crypto quantum safe

1455
01:00:26,720 --> 01:00:28,960
crypto and you can find this talk on

1456
01:00:28,960 --> 01:00:31,440
youtube and you can find his slides and

1457
01:00:31,440 --> 01:00:33,920
he did a great job explaining

1458
01:00:33,920 --> 01:00:36,720
where we will have it well what cyphers

1459
01:00:36,720 --> 01:00:39,359
will suffer and what problems will

1460
01:00:39,359 --> 01:00:40,640
remain

1461
01:00:40,640 --> 01:00:43,839
good and strong

1462
01:00:46,079 --> 01:00:47,520
okay

1463
01:00:47,520 --> 01:00:48,400
okay

1464
01:00:48,400 --> 01:00:50,400
thank you i think we will have the last

1465
01:00:50,400 --> 01:00:52,480
question

1466
01:00:52,480 --> 01:00:55,200
uh i have i think i have a right to ask

1467
01:00:55,200 --> 01:00:56,880
you one more question

1468
01:00:56,880 --> 01:00:59,119
uh

1469
01:01:00,319 --> 01:01:02,400
when we meet aliens

1470
01:01:02,400 --> 01:01:06,079
what kind of computers they will have

1471
01:01:06,240 --> 01:01:09,040
quantum computers or something similar

1472
01:01:09,040 --> 01:01:11,760
to to ours like from them and

1473
01:01:11,760 --> 01:01:14,960
i believe they're gonna have this

1474
01:01:14,960 --> 01:01:18,160
silicon uh life forms so they might be

1475
01:01:18,160 --> 01:01:20,799
computers themselves right

1476
01:01:20,799 --> 01:01:23,280
let's talk about artificial intelligence

1477
01:01:23,280 --> 01:01:27,040
let's talk about um singularity right

1478
01:01:27,040 --> 01:01:29,599
maybe we are building aliens right now

1479
01:01:29,599 --> 01:01:32,640
with all these shiny things happening in

1480
01:01:32,640 --> 01:01:34,559
google cloud platform with all these

1481
01:01:34,559 --> 01:01:36,799
codes it gets pushed there

1482
01:01:36,799 --> 01:01:38,720
uh you know feeding

1483
01:01:38,720 --> 01:01:42,160
the learning algorithms

1484
01:01:42,160 --> 01:01:43,680
yeah yeah

1485
01:01:43,680 --> 01:01:46,480
okay okay thank you again for

1486
01:01:46,480 --> 01:01:48,400
um

1487
01:01:48,400 --> 01:01:50,400
for

1488
01:01:50,400 --> 01:01:51,680
the great talk

1489
01:01:51,680 --> 01:01:53,520
and for being

1490
01:01:53,520 --> 01:01:56,480
the part of no name con in a new role uh

1491
01:01:56,480 --> 01:01:58,760
it was a great debut

1492
01:01:58,760 --> 01:02:01,440
congratulations thank you

1493
01:02:01,440 --> 01:02:04,000
thank you my pleasure have a great day

1494
01:02:04,000 --> 01:02:05,599
thank you everyone thank you for your

1495
01:02:05,599 --> 01:02:08,000
questions and let's continue with talks

1496
01:02:08,000 --> 01:02:13,640
bye bye of course of course thank you

