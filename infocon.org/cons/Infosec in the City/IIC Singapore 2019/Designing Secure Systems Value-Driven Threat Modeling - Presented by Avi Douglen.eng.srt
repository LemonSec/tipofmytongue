1
00:00:00,000 --> 00:00:01,620
where'd that before anybody heard that

2
00:00:01,620 --> 00:00:03,600
statement I think it's a terrible thing

3
00:00:03,600 --> 00:00:05,120
to hear it's an awful thing to say

4
00:00:05,120 --> 00:00:06,810
developers don't know jack about

5
00:00:06,810 --> 00:00:09,090
security that was actually a famous line

6
00:00:09,090 --> 00:00:11,130
from a security conference several years

7
00:00:11,130 --> 00:00:13,200
ago developers don't know jack about

8
00:00:13,200 --> 00:00:15,450
security well there was a security guy

9
00:00:15,450 --> 00:00:18,510
sitting in the audience then and his

10
00:00:18,510 --> 00:00:20,100
response was well I Got News for your

11
00:00:20,100 --> 00:00:21,330
friend you don't know jack about

12
00:00:21,330 --> 00:00:24,689
development and this is part of the

13
00:00:24,689 --> 00:00:27,720
friction that we have and we still have

14
00:00:27,720 --> 00:00:30,119
between the security field with the

15
00:00:30,119 --> 00:00:32,159
security people and the developers and

16
00:00:32,159 --> 00:00:34,290
we don't speak their language that they

17
00:00:34,290 --> 00:00:36,149
don't speak our language and this just

18
00:00:36,149 --> 00:00:37,640
creates friction and we're not getting

19
00:00:37,640 --> 00:00:40,379
the results that we need and this is

20
00:00:40,379 --> 00:00:42,680
creating situation where we're creating

21
00:00:42,680 --> 00:00:44,940
insecure software because we're not

22
00:00:44,940 --> 00:00:58,050
working together so I'm gonna tell you

23
00:00:58,050 --> 00:00:59,609
up front what I'm gonna be talking about

24
00:00:59,609 --> 00:01:01,410
no surprises this is about my bottom

25
00:01:01,410 --> 00:01:03,420
line threat modeling is great I'm gonna

26
00:01:03,420 --> 00:01:04,530
tell you all about front modelling

27
00:01:04,530 --> 00:01:06,030
anybody you know what here have done

28
00:01:06,030 --> 00:01:07,229
threat modeling know what threat

29
00:01:07,229 --> 00:01:10,049
modeling is I'll explain what I mean by

30
00:01:10,049 --> 00:01:13,350
threat modeling and what it is and why

31
00:01:13,350 --> 00:01:16,500
it's so great but the problem is that we

32
00:01:16,500 --> 00:01:18,240
can't be the ones doing it it's not

33
00:01:18,240 --> 00:01:19,290
security people that should be doing

34
00:01:19,290 --> 00:01:22,049
threat modeling statistics came out last

35
00:01:22,049 --> 00:01:25,020
year that for every 100 developers you

36
00:01:25,020 --> 00:01:27,540
know many security people they're on

37
00:01:27,540 --> 00:01:30,170
average so that's a whole lot of

38
00:01:30,170 --> 00:01:32,700
security being built as far as a lot of

39
00:01:32,700 --> 00:01:34,350
software being built without any

40
00:01:34,350 --> 00:01:36,600
security going into it there's not

41
00:01:36,600 --> 00:01:38,070
enough of security people to go around

42
00:01:38,070 --> 00:01:41,460
so we need to get the developers to be

43
00:01:41,460 --> 00:01:43,439
doing the security for us we need to get

44
00:01:43,439 --> 00:01:45,149
the developers to be doing threat

45
00:01:45,149 --> 00:01:46,500
modeling and not just the security

46
00:01:46,500 --> 00:01:48,810
people and if we want developers to be

47
00:01:48,810 --> 00:01:50,369
doing threat modeling and security in

48
00:01:50,369 --> 00:01:52,860
general it needs to be quick can't take

49
00:01:52,860 --> 00:01:54,090
up all their own time because they're

50
00:01:54,090 --> 00:01:55,979
busy it needs to be lightweight we can't

51
00:01:55,979 --> 00:01:58,020
give them heavy process and to be agile

52
00:01:58,020 --> 00:01:59,820
because that's the way they work and the

53
00:01:59,820 --> 00:02:01,530
way to do this is by focusing on

54
00:02:01,530 --> 00:02:04,170
business value I'm gonna show you how I

55
00:02:04,170 --> 00:02:06,869
mean because if we keep trying to

56
00:02:06,869 --> 00:02:10,348
enforce our heavy security process and

57
00:02:10,348 --> 00:02:11,730
doing everything the way we've always

58
00:02:11,730 --> 00:02:13,530
been doing we're gonna be looking like

59
00:02:13,530 --> 00:02:14,010
this guy

60
00:02:14,010 --> 00:02:16,590
I trying to do the same security things

61
00:02:16,590 --> 00:02:18,689
and not changing adapting to the

62
00:02:18,689 --> 00:02:20,360
different context a different situation

63
00:02:20,360 --> 00:02:22,349
so let me introduce myself that's what

64
00:02:22,349 --> 00:02:23,640
we're talking about my name is avi

65
00:02:23,640 --> 00:02:26,610
Douglas all right there's my contact

66
00:02:26,610 --> 00:02:28,019
details you'll see my trigger face

67
00:02:28,019 --> 00:02:29,909
bouncing around the internet especially

68
00:02:29,909 --> 00:02:32,579
on Twitter and the most important thing

69
00:02:32,579 --> 00:02:34,530
you should know about me is that if you

70
00:02:34,530 --> 00:02:36,420
ever want to buy me a drink I like my

71
00:02:36,420 --> 00:02:38,549
whiskey smoky I like my beer stout like

72
00:02:38,549 --> 00:02:41,069
my coffee strong I do have five kids at

73
00:02:41,069 --> 00:02:42,090
home so these drinks are kind of

74
00:02:42,090 --> 00:02:44,670
important the other things you might

75
00:02:44,670 --> 00:02:45,959
want to know about me is I have a

76
00:02:45,959 --> 00:02:48,060
boutique consulting company called

77
00:02:48,060 --> 00:02:49,920
bounce security we do software security

78
00:02:49,920 --> 00:02:52,019
consulting things like threat modeling

79
00:02:52,019 --> 00:02:54,840
research and other things I am one of

80
00:02:54,840 --> 00:02:57,150
the leaders of the OWASP Israel chapter

81
00:02:57,150 --> 00:02:59,180
we just had a great global apps tech

82
00:02:59,180 --> 00:03:02,280
conference in Tel Aviv our next we have

83
00:03:02,280 --> 00:03:04,409
a yearly conference called apps like

84
00:03:04,409 --> 00:03:07,409
Israel will be next summer 2020 if you

85
00:03:07,409 --> 00:03:08,519
could make it over to Tel Aviv that'd be

86
00:03:08,519 --> 00:03:11,970
great I'm also one of the moderators on

87
00:03:11,970 --> 00:03:14,069
the security Stack Exchange site anybody

88
00:03:14,069 --> 00:03:15,690
here have a know what that is anybody

89
00:03:15,690 --> 00:03:18,239
have a profile it's kind of like exactly

90
00:03:18,239 --> 00:03:19,889
like Stack Overflow questions and

91
00:03:19,889 --> 00:03:22,560
answers but for security by security

92
00:03:22,560 --> 00:03:25,139
people about security I spent some time

93
00:03:25,139 --> 00:03:27,419
mentoring high school kids about cyber

94
00:03:27,419 --> 00:03:29,519
and getting into the field and whatnot

95
00:03:29,519 --> 00:03:31,199
I'm also the founder one of the leaders

96
00:03:31,199 --> 00:03:35,370
of the OWASP threatened model project so

97
00:03:35,370 --> 00:03:37,440
that is a moment so if you don't know a

98
00:03:37,440 --> 00:03:41,030
threat modeling is in a nutshell

99
00:03:41,030 --> 00:03:43,470
security analysis of your software

100
00:03:43,470 --> 00:03:46,049
basically it's a structure for this

101
00:03:46,049 --> 00:03:48,209
analysis it gives you a framework to

102
00:03:48,209 --> 00:03:50,699
start thinking about threats about

103
00:03:50,699 --> 00:03:52,829
attackers about what can go wrong about

104
00:03:52,829 --> 00:03:54,870
what security we need to build into the

105
00:03:54,870 --> 00:03:57,569
system what we need to fix and why and

106
00:03:57,569 --> 00:03:59,250
we do this by reviewing the different

107
00:03:59,250 --> 00:04:01,650
components of the system and finding the

108
00:04:01,650 --> 00:04:03,090
different security flaws that are

109
00:04:03,090 --> 00:04:05,849
potentially in that's in that component

110
00:04:05,849 --> 00:04:08,159
and then once we understand these

111
00:04:08,159 --> 00:04:10,409
threats we have a better understanding

112
00:04:10,409 --> 00:04:12,569
of how they work we know better how to

113
00:04:12,569 --> 00:04:14,699
fix them we understand the risk involved

114
00:04:14,699 --> 00:04:18,709
and we know what it takes to fix them so

115
00:04:18,709 --> 00:04:21,720
generally speaking threat modeling is

116
00:04:21,720 --> 00:04:24,450
usually done by you know some kind of

117
00:04:24,450 --> 00:04:27,120
diagram focusing on data flows how it

118
00:04:27,120 --> 00:04:27,630
comes into the

119
00:04:27,630 --> 00:04:29,280
system where it goes who has access to

120
00:04:29,280 --> 00:04:32,030
what data where the data comes from

121
00:04:32,030 --> 00:04:34,650
finding the attack surface the

122
00:04:34,650 --> 00:04:37,740
collection of entry points highlighting

123
00:04:37,740 --> 00:04:39,150
the different assets that we're trying

124
00:04:39,150 --> 00:04:42,000
to protect focusing on those calling out

125
00:04:42,000 --> 00:04:44,910
the scary trust boundaries which gives

126
00:04:44,910 --> 00:04:47,550
us the attack surface and we usually use

127
00:04:47,550 --> 00:04:50,430
some things like DFDS data flow diagrams

128
00:04:50,430 --> 00:04:53,070
define it to follows data flows but you

129
00:04:53,070 --> 00:04:54,300
know a lot of people use other types of

130
00:04:54,300 --> 00:04:56,430
diagrams things like swim lanes and

131
00:04:56,430 --> 00:04:58,560
process diagrams whatever they are as

132
00:04:58,560 --> 00:05:01,050
long as it's something visual that you

133
00:05:01,050 --> 00:05:04,430
can trace the data through the system so

134
00:05:04,430 --> 00:05:07,410
overall it's a four-step process for a

135
00:05:07,410 --> 00:05:09,600
threat modeling there's a pre step of

136
00:05:09,600 --> 00:05:12,450
first defining what goes into your model

137
00:05:12,450 --> 00:05:14,520
what part of the system you're working

138
00:05:14,520 --> 00:05:16,620
on right now you're modeling and then

139
00:05:16,620 --> 00:05:18,600
this step the first real step of the

140
00:05:18,600 --> 00:05:21,180
threat model process is to decompose the

141
00:05:21,180 --> 00:05:24,900
application to break out the diagram the

142
00:05:24,900 --> 00:05:27,450
DF D and so on whatever diagrams they

143
00:05:27,450 --> 00:05:29,340
are you know the different parts of the

144
00:05:29,340 --> 00:05:33,150
different components step two would be

145
00:05:33,150 --> 00:05:34,920
to find the threats the attackers is

146
00:05:34,920 --> 00:05:36,330
kind of important to know what you're

147
00:05:36,330 --> 00:05:38,070
fixing but also to understand the

148
00:05:38,070 --> 00:05:40,970
threats and find the involved risk level

149
00:05:40,970 --> 00:05:43,290
and there's a whole methodologies around

150
00:05:43,290 --> 00:05:46,800
that the third step is probably the most

151
00:05:46,800 --> 00:05:48,360
important its defining the

152
00:05:48,360 --> 00:05:50,190
countermeasures what we're going to do

153
00:05:50,190 --> 00:05:52,890
to change our system design because the

154
00:05:52,890 --> 00:05:55,440
threat model is not just about threats

155
00:05:55,440 --> 00:05:57,930
it's about the whole purpose is to have

156
00:05:57,930 --> 00:06:00,870
secure software so that's the step three

157
00:06:00,870 --> 00:06:02,990
defining the the countermeasures and

158
00:06:02,990 --> 00:06:05,220
then step four like any work we've done

159
00:06:05,220 --> 00:06:07,160
did we do you know we need to analyze it

160
00:06:07,160 --> 00:06:10,290
we model our threat model is a complete

161
00:06:10,290 --> 00:06:12,930
and so on if you're not familiar with

162
00:06:12,930 --> 00:06:14,430
what a d if d looks like if there's the

163
00:06:14,430 --> 00:06:15,870
first time you're seeing it you have

164
00:06:15,870 --> 00:06:18,030
over here you have your central process

165
00:06:18,030 --> 00:06:19,650
that could be a service api whatever it

166
00:06:19,650 --> 00:06:21,840
is and you have your databases you have

167
00:06:21,840 --> 00:06:23,880
your data flows going in data coming out

168
00:06:23,880 --> 00:06:25,950
and then over there you have the user of

169
00:06:25,950 --> 00:06:27,660
course sending in the withdrawal

170
00:06:27,660 --> 00:06:30,630
requests and identification and so on

171
00:06:30,630 --> 00:06:32,640
and that comes in and that crosses the

172
00:06:32,640 --> 00:06:34,860
scary trust boundary that's why it's

173
00:06:34,860 --> 00:06:36,930
flagged in red and that's what we're

174
00:06:36,930 --> 00:06:38,700
going to start with obviously because

175
00:06:38,700 --> 00:06:40,590
that's part of our attack surface that's

176
00:06:40,590 --> 00:06:41,490
our entry point

177
00:06:41,490 --> 00:06:43,169
so that's a very simple data flow

178
00:06:43,169 --> 00:06:46,560
diagram now there are a lot of different

179
00:06:46,560 --> 00:06:49,520
approaches to do threat modeling those

180
00:06:49,520 --> 00:06:52,259
4+1 steps that I mentioned there's a lot

181
00:06:52,259 --> 00:06:54,240
of different approaches there's stride

182
00:06:54,240 --> 00:06:55,860
I'm gonna go into this in details an

183
00:06:55,860 --> 00:06:56,970
acronym I'll explain what that means in

184
00:06:56,970 --> 00:06:58,979
a moment stride stride by element

185
00:06:58,979 --> 00:07:00,810
there's a TAC trees and there's a

186
00:07:00,810 --> 00:07:02,639
focusing on the assets that you're

187
00:07:02,639 --> 00:07:04,949
trying to protect and software centric

188
00:07:04,949 --> 00:07:06,270
breaking down the components and of

189
00:07:06,270 --> 00:07:07,680
trying to get into the head of the

190
00:07:07,680 --> 00:07:10,080
attacker attacker focused and the nice

191
00:07:10,080 --> 00:07:12,030
risk based threat modeling approach

192
00:07:12,030 --> 00:07:13,849
we'll explain in a moment

193
00:07:13,849 --> 00:07:16,289
so I mentioned stride stride is an

194
00:07:16,289 --> 00:07:19,740
acronym that's spoofing pretending to be

195
00:07:19,740 --> 00:07:22,949
somebody or not tampering changing data

196
00:07:22,949 --> 00:07:25,520
you shouldn't have access to repudiation

197
00:07:25,520 --> 00:07:28,050
claiming you didn't do something that

198
00:07:28,050 --> 00:07:30,300
you did for example telling the bank I

199
00:07:30,300 --> 00:07:31,830
didn't authorize that transfer and

200
00:07:31,830 --> 00:07:35,030
wasn't me now get my money back

201
00:07:35,030 --> 00:07:37,560
information disclosure is reading data

202
00:07:37,560 --> 00:07:39,750
that shouldn't you shouldn't have access

203
00:07:39,750 --> 00:07:42,389
to denial of service preventing other

204
00:07:42,389 --> 00:07:44,460
users from having access that they

205
00:07:44,460 --> 00:07:47,039
should have access to an elevation of

206
00:07:47,039 --> 00:07:48,630
privilege is basically doing anything

207
00:07:48,630 --> 00:07:53,190
that you shouldn't and we take these

208
00:07:53,190 --> 00:07:54,900
categories is basically categorization

209
00:07:54,900 --> 00:07:57,690
of all the different possible attacks

210
00:07:57,690 --> 00:07:59,610
that an attacker might want to do or

211
00:07:59,610 --> 00:08:02,639
attack or goals and we apply this one by

212
00:08:02,639 --> 00:08:05,270
one by two each element in our diagram

213
00:08:05,270 --> 00:08:08,460
for example we could go and apply stri

214
00:08:08,460 --> 00:08:10,979
to the web server and we say are there

215
00:08:10,979 --> 00:08:13,050
spoofing attacks here can I pretend to

216
00:08:13,050 --> 00:08:16,139
be a different user okay but also the

217
00:08:16,139 --> 00:08:18,539
other direction can I pretend can i

218
00:08:18,539 --> 00:08:20,099
spoof the web server can I pretend to

219
00:08:20,099 --> 00:08:21,690
other users that on the web server and

220
00:08:21,690 --> 00:08:23,969
steal passwords and so on and so forth

221
00:08:23,969 --> 00:08:27,060
obviously if there's HTTPS then not but

222
00:08:27,060 --> 00:08:28,949
then we ask that tampering

223
00:08:28,949 --> 00:08:32,250
can I change data and route right I look

224
00:08:32,250 --> 00:08:34,380
at the data flow its HTTPS I can't

225
00:08:34,380 --> 00:08:36,208
tamper with it but there's might be

226
00:08:36,208 --> 00:08:39,000
other attacks on the web server or the

227
00:08:39,000 --> 00:08:40,919
application server and in this way I go

228
00:08:40,919 --> 00:08:43,260
through one by one each category on each

229
00:08:43,260 --> 00:08:45,180
element but then I could also go and

230
00:08:45,180 --> 00:08:47,779
look at the backend elements for example

231
00:08:47,779 --> 00:08:50,370
the flow between the application server

232
00:08:50,370 --> 00:08:53,550
and the backend messaging bus setting in

233
00:08:53,550 --> 00:08:55,380
let's say some message queue and

234
00:08:55,380 --> 00:08:57,750
sending in different messages and on JMS

235
00:08:57,750 --> 00:09:00,150
and we now we can ask these strike

236
00:09:00,150 --> 00:09:02,430
questions all over again each element

237
00:09:02,430 --> 00:09:04,920
can I spoof the messaging bus so I

238
00:09:04,920 --> 00:09:07,380
intercept every message sent by the

239
00:09:07,380 --> 00:09:09,840
application server and comes to me or

240
00:09:09,840 --> 00:09:11,430
the other way around could I pretend on

241
00:09:11,430 --> 00:09:13,230
the application server and set my own

242
00:09:13,230 --> 00:09:16,800
messages into the bus can I tap R with

243
00:09:16,800 --> 00:09:18,480
the messages that already there or the

244
00:09:18,480 --> 00:09:20,070
message is being sent if this protocol

245
00:09:20,070 --> 00:09:24,690
isn't encrypted can I read the messages

246
00:09:24,690 --> 00:09:28,110
from there right can I can I erase that

247
00:09:28,110 --> 00:09:29,850
and in this way I go through each

248
00:09:29,850 --> 00:09:31,980
element and ask you these questions

249
00:09:31,980 --> 00:09:34,410
looking for threats in each of these

250
00:09:34,410 --> 00:09:38,610
categories of goals now it doesn't need

251
00:09:38,610 --> 00:09:40,950
to be a DFT it could be a process

252
00:09:40,950 --> 00:09:42,960
diagram so people use swimlanes

253
00:09:42,960 --> 00:09:45,480
whatever kind of visual diagram works

254
00:09:45,480 --> 00:09:47,370
for your team for your system that makes

255
00:09:47,370 --> 00:09:49,680
sense and you couldn't go ahead and do

256
00:09:49,680 --> 00:09:52,020
that another very interesting tool is

257
00:09:52,020 --> 00:09:54,720
called attack trees attack trees is very

258
00:09:54,720 --> 00:09:56,100
good for fleshing out a lot of different

259
00:09:56,100 --> 00:09:59,400
details for a specific set of threats

260
00:09:59,400 --> 00:10:01,680
for example I have a specific threat

261
00:10:01,680 --> 00:10:03,510
that an attacker may be able to read

262
00:10:03,510 --> 00:10:07,050
other users secret messages and then I

263
00:10:07,050 --> 00:10:08,400
have here a whole bunch of different

264
00:10:08,400 --> 00:10:11,040
vectors to get to that goal

265
00:10:11,040 --> 00:10:12,960
now I might be able to read the messages

266
00:10:12,960 --> 00:10:15,180
because it's stored in the browser cache

267
00:10:15,180 --> 00:10:18,290
unencrypted or I may be able to bypass

268
00:10:18,290 --> 00:10:20,910
authorization or there's SQL injection

269
00:10:20,910 --> 00:10:22,980
okay and there's a lot of different

270
00:10:22,980 --> 00:10:25,440
vectors to get to that one goal and each

271
00:10:25,440 --> 00:10:27,810
one of these needs to be mitigated and

272
00:10:27,810 --> 00:10:29,880
that's what we have down here the green

273
00:10:29,880 --> 00:10:32,790
Leafs for example in order to prevent

274
00:10:32,790 --> 00:10:34,950
the browser from caching these secret

275
00:10:34,950 --> 00:10:36,570
messages I'm gonna implement the anti

276
00:10:36,570 --> 00:10:39,090
caching headers right I'm going to

277
00:10:39,090 --> 00:10:41,190
enforce authorization checks and that

278
00:10:41,190 --> 00:10:44,190
prevents this vector SQL injection we

279
00:10:44,190 --> 00:10:46,320
know how to prevent but then I have over

280
00:10:46,320 --> 00:10:49,170
here yet another vector user may not

281
00:10:49,170 --> 00:10:52,500
have logged off a shared computer so the

282
00:10:52,500 --> 00:10:54,000
next person at the kiosk can just go and

283
00:10:54,000 --> 00:10:56,400
read that user's messages and there is

284
00:10:56,400 --> 00:10:58,380
no defensive mechanism here there's no

285
00:10:58,380 --> 00:11:00,840
countermeasure so it's very easy using

286
00:11:00,840 --> 00:11:03,990
this attack tree to find the unmitigated

287
00:11:03,990 --> 00:11:07,080
threats it's also really good for a pen

288
00:11:07,080 --> 00:11:09,330
tester for QA to come in and say

289
00:11:09,330 --> 00:11:11,190
okay we don't need to start checking

290
00:11:11,190 --> 00:11:12,750
this we need to verify that this is

291
00:11:12,750 --> 00:11:15,089
implemented correctly there's no point

292
00:11:15,089 --> 00:11:16,470
in checking this because we know it's

293
00:11:16,470 --> 00:11:18,810
not mitigated until the developers go

294
00:11:18,810 --> 00:11:21,510
and create that security control I'm not

295
00:11:21,510 --> 00:11:26,610
going to waste time testing that another

296
00:11:26,610 --> 00:11:28,500
approach I mentioned is called wrist

297
00:11:28,500 --> 00:11:32,610
Bateman risk-based methodology and the

298
00:11:32,610 --> 00:11:34,430
poster trial for this is called pasta

299
00:11:34,430 --> 00:11:36,720
probably all hungry for dinner already

300
00:11:36,720 --> 00:11:39,480
pasta stands for process for attack

301
00:11:39,480 --> 00:11:42,540
simulation and threat analysis okay it's

302
00:11:42,540 --> 00:11:45,930
a very rigorous model called with risk

303
00:11:45,930 --> 00:11:47,310
based because comes from the risk

304
00:11:47,310 --> 00:11:51,120
management field and those four steps it

305
00:11:51,120 --> 00:11:52,589
breaks it down into a lot more detail

306
00:11:52,589 --> 00:11:54,690
there are seven steps here and it

307
00:11:54,690 --> 00:11:56,730
involves things like threat Intel and

308
00:11:56,730 --> 00:11:59,250
business analysis and a whole lot of

309
00:11:59,250 --> 00:12:00,660
other stuff in comes a very rigorous

310
00:12:00,660 --> 00:12:04,040
threat model and the output of this is

311
00:12:04,040 --> 00:12:06,089
without a doubt one of the best threat

312
00:12:06,089 --> 00:12:08,040
models you're gonna get because when

313
00:12:08,040 --> 00:12:09,360
you're working on something you know

314
00:12:09,360 --> 00:12:11,190
without a doubt these are the right

315
00:12:11,190 --> 00:12:13,980
risks to be working on because you have

316
00:12:13,980 --> 00:12:16,170
all the statistical detail you have you

317
00:12:16,170 --> 00:12:18,540
have all that data to back you up and

318
00:12:18,540 --> 00:12:20,730
you know when you fix these threats

319
00:12:20,730 --> 00:12:22,649
these are the right threats to be fixing

320
00:12:22,649 --> 00:12:25,829
in the right possible way now these are

321
00:12:25,829 --> 00:12:28,410
great tools pasta especially but also

322
00:12:28,410 --> 00:12:30,360
the other methodologies these are great

323
00:12:30,360 --> 00:12:33,720
tools for security officers the security

324
00:12:33,720 --> 00:12:37,490
department loves this right any kind of

325
00:12:37,490 --> 00:12:39,420
C so is gonna love this

326
00:12:39,420 --> 00:12:41,850
it's fantastic for a chief risk officer

327
00:12:41,850 --> 00:12:45,240
of multi national bank you know it's not

328
00:12:45,240 --> 00:12:50,850
so before not so great for the way the

329
00:12:50,850 --> 00:12:53,699
developers work right that big seven

330
00:12:53,699 --> 00:12:56,130
stage process with statistical data does

331
00:12:56,130 --> 00:12:59,300
not really fit in with the concept of

332
00:12:59,300 --> 00:13:01,709
continuous integration into deployment

333
00:13:01,709 --> 00:13:04,020
and and so on and so forth so anytime we

334
00:13:04,020 --> 00:13:06,930
go to do threat modeling with developers

335
00:13:06,930 --> 00:13:08,610
and trying to get them to integrate

336
00:13:08,610 --> 00:13:11,610
their process there's gonna be a bunch

337
00:13:11,610 --> 00:13:14,370
of pushback and let's look at some of

338
00:13:14,370 --> 00:13:16,589
the comments that I've gotten over time

339
00:13:16,589 --> 00:13:18,690
and everybody everybody that does threat

340
00:13:18,690 --> 00:13:20,850
balance developer says yeah yeah heard

341
00:13:20,850 --> 00:13:21,900
that all the time

342
00:13:21,900 --> 00:13:23,610
so these are some of the issues that

343
00:13:23,610 --> 00:13:25,350
come up with trying to do threat

344
00:13:25,350 --> 00:13:29,580
modeling with developers right you could

345
00:13:29,580 --> 00:13:31,440
send your application off to the

346
00:13:31,440 --> 00:13:32,940
security department they come back three

347
00:13:32,940 --> 00:13:34,770
weeks later or you call an expensive

348
00:13:34,770 --> 00:13:36,570
consultant they'll come back after two

349
00:13:36,570 --> 00:13:38,220
months with a really big threat model

350
00:13:38,220 --> 00:13:40,680
with a pasta and so on and so forth what

351
00:13:40,680 --> 00:13:42,750
we did we're doing two-week sprints we

352
00:13:42,750 --> 00:13:44,220
don't have time to wait for you to come

353
00:13:44,220 --> 00:13:46,140
back after after you finish with your

354
00:13:46,140 --> 00:13:48,660
massive threat model it's got to be

355
00:13:48,660 --> 00:13:50,060
faster than that

356
00:13:50,060 --> 00:13:52,380
so here's everybody's job we like saying

357
00:13:52,380 --> 00:13:53,670
that right security people love setting

358
00:13:53,670 --> 00:13:55,050
security is everybody's job everybody's

359
00:13:55,050 --> 00:13:56,610
meeting security but you know what I'm a

360
00:13:56,610 --> 00:13:59,220
developer what's my job I write code I

361
00:13:59,220 --> 00:14:01,770
need to deliver features these features

362
00:14:01,770 --> 00:14:03,780
need to bring in customers they need to

363
00:14:03,780 --> 00:14:06,990
sell more product that's my job sure

364
00:14:06,990 --> 00:14:09,720
it's my responsibility security I need

365
00:14:09,720 --> 00:14:12,090
to take care of security and also

366
00:14:12,090 --> 00:14:15,390
performance and also usability and also

367
00:14:15,390 --> 00:14:16,550
ton of other things

368
00:14:16,550 --> 00:14:19,080
all right security is not my job my job

369
00:14:19,080 --> 00:14:21,630
is development I already have eight

370
00:14:21,630 --> 00:14:25,260
bosses now eight bosses Bob do we

371
00:14:25,260 --> 00:14:26,910
security people really want to be bossed

372
00:14:26,910 --> 00:14:30,110
number nine doesn't work

373
00:14:30,110 --> 00:14:32,670
think like an attacker is particularly

374
00:14:32,670 --> 00:14:35,430
insidious because it sounds really good

375
00:14:35,430 --> 00:14:37,560
right think like an attacker think about

376
00:14:37,560 --> 00:14:38,730
everything that the attacker could

377
00:14:38,730 --> 00:14:40,710
possibly want to do to you and stop that

378
00:14:40,710 --> 00:14:44,310
except we think like developers we don't

379
00:14:44,310 --> 00:14:45,300
think like an attacker if we thought

380
00:14:45,300 --> 00:14:47,220
like an attacker we go be a pen tester

381
00:14:47,220 --> 00:14:49,980
right but we think like a developer and

382
00:14:49,980 --> 00:14:51,330
more than that think like an attacker

383
00:14:51,330 --> 00:14:54,510
has no real valuable guidance here it

384
00:14:54,510 --> 00:14:56,430
doesn't tell you anything of what I need

385
00:14:56,430 --> 00:14:58,950
to do to prevent the attacker how do I

386
00:14:58,950 --> 00:15:00,210
think like an attacker what does that

387
00:15:00,210 --> 00:15:04,050
even mean it Adam szostak who literally

388
00:15:04,050 --> 00:15:06,000
wrote the book on threat modeling is the

389
00:15:06,000 --> 00:15:08,100
father of modern threat modeling it

390
00:15:08,100 --> 00:15:10,850
likes to say everybody think like a chef

391
00:15:10,850 --> 00:15:13,500
does that mean you can now make

392
00:15:13,500 --> 00:15:15,330
fantastic soup does that mean you can

393
00:15:15,330 --> 00:15:16,610
bake like Mario Batali

394
00:15:16,610 --> 00:15:18,720
yeah there's no guidance doesn't really

395
00:15:18,720 --> 00:15:24,960
help anything and then you say well why

396
00:15:24,960 --> 00:15:26,760
bother threat modeling what they want to

397
00:15:26,760 --> 00:15:28,650
do is take over the world they want to

398
00:15:28,650 --> 00:15:30,000
steal money from account there's no

399
00:15:30,000 --> 00:15:32,190
point in threat modeling what value am I

400
00:15:32,190 --> 00:15:33,150
getting out of threat modeling because

401
00:15:33,150 --> 00:15:35,850
we don't what they want to do

402
00:15:35,850 --> 00:15:38,040
now overall the threat modeling we're

403
00:15:38,040 --> 00:15:39,300
talking about these big processes and

404
00:15:39,300 --> 00:15:42,900
diagrams and its kind of waterfall II

405
00:15:42,900 --> 00:15:45,390
ish right because we have these big

406
00:15:45,390 --> 00:15:49,260
design and we take all the use cases and

407
00:15:49,260 --> 00:15:51,030
this is the way threat modeling people

408
00:15:51,030 --> 00:15:52,740
like to work security professionals like

409
00:15:52,740 --> 00:15:54,750
to do that especially consultants like

410
00:15:54,750 --> 00:15:57,240
getting all these big design documents

411
00:15:57,240 --> 00:15:58,980
and like the use cases that are very

412
00:15:58,980 --> 00:16:00,960
detailed except that developers don't

413
00:16:00,960 --> 00:16:03,360
really do that anymore use cases don't

414
00:16:03,360 --> 00:16:06,300
exist they have very lightweight minimal

415
00:16:06,300 --> 00:16:09,420
user stories as a user I want to

416
00:16:09,420 --> 00:16:12,210
whatever because that's it and then that

417
00:16:12,210 --> 00:16:14,430
gets fleshed out as they develop it's an

418
00:16:14,430 --> 00:16:17,520
invitation to a conversation to find out

419
00:16:17,520 --> 00:16:18,990
additional information of what they need

420
00:16:18,990 --> 00:16:21,300
to develop so there are no use cases and

421
00:16:21,300 --> 00:16:22,980
trying to build a threat model based on

422
00:16:22,980 --> 00:16:24,990
these use cases doesn't necessarily work

423
00:16:24,990 --> 00:16:27,360
and in the same manner

424
00:16:27,360 --> 00:16:31,080
a lot of agile proponents like to say no

425
00:16:31,080 --> 00:16:33,150
big design up front well if you don't

426
00:16:33,150 --> 00:16:34,650
have a big design up front you can't

427
00:16:34,650 --> 00:16:37,530
build a big model up front in which case

428
00:16:37,530 --> 00:16:39,870
you're gonna get stuck in a hole and not

429
00:16:39,870 --> 00:16:42,540
know how to get out of that one good

430
00:16:42,540 --> 00:16:43,830
thing that develop that threat modeling

431
00:16:43,830 --> 00:16:45,660
does do is create a whole lot of

432
00:16:45,660 --> 00:16:48,300
security documentation you can trace

433
00:16:48,300 --> 00:16:50,040
back the threats you can trace back why

434
00:16:50,040 --> 00:16:52,140
we built this feature to put to this

435
00:16:52,140 --> 00:16:53,930
countermeasure against that threat

436
00:16:53,930 --> 00:16:56,970
except that when I read the functional

437
00:16:56,970 --> 00:16:58,590
design I don't have that information

438
00:16:58,590 --> 00:17:01,650
anymore I have my big threat model over

439
00:17:01,650 --> 00:17:04,020
there I have my design over here in JIRA

440
00:17:04,020 --> 00:17:06,329
or a confluence whatever I'm working on

441
00:17:06,329 --> 00:17:10,710
and never shall between ever meet and in

442
00:17:10,710 --> 00:17:12,150
the same matter be part of that is

443
00:17:12,150 --> 00:17:15,390
because that what happens is that I

444
00:17:15,390 --> 00:17:18,420
change the design in confluence but the

445
00:17:18,420 --> 00:17:20,579
threat model hasn't been updated so

446
00:17:20,579 --> 00:17:22,290
that's how things get out of sync it's

447
00:17:22,290 --> 00:17:24,800
no longer relevant

448
00:17:24,859 --> 00:17:26,849
another thing that threat model the

449
00:17:26,849 --> 00:17:29,250
threat models like to produce is huge

450
00:17:29,250 --> 00:17:31,590
long list of threats and of course for

451
00:17:31,590 --> 00:17:33,300
each threat you have your bunch of

452
00:17:33,300 --> 00:17:34,500
countermeasures that this is what we

453
00:17:34,500 --> 00:17:35,730
need to implement this we need to fill

454
00:17:35,730 --> 00:17:38,540
and you get this massive excel sheet

455
00:17:38,540 --> 00:17:41,250
ever seen a developer develop their

456
00:17:41,250 --> 00:17:43,440
features based on an excel with hundreds

457
00:17:43,440 --> 00:17:45,240
or thousands of lines of threats if it's

458
00:17:45,240 --> 00:17:47,940
not in my backlog I'm not gonna touch it

459
00:17:47,940 --> 00:17:49,710
if it's not in JIRA I don't even know

460
00:17:49,710 --> 00:17:51,659
about it so what I'm going to do with

461
00:17:51,659 --> 00:17:52,950
this massive excel sheet with thousands

462
00:17:52,950 --> 00:17:56,820
of lines and one really good thing about

463
00:17:56,820 --> 00:17:58,320
threat modeling is that you don't waste

464
00:17:58,320 --> 00:17:59,730
time building controls that you don't

465
00:17:59,730 --> 00:18:01,950
need you don't build unnecessary

466
00:18:01,950 --> 00:18:05,429
security but you do waste time threat

467
00:18:05,429 --> 00:18:09,289
modeling unrealistic things

468
00:18:09,679 --> 00:18:12,149
developers are Stallions right they love

469
00:18:12,149 --> 00:18:14,130
to run forward they left to build things

470
00:18:14,130 --> 00:18:17,190
two-week integrations a continuous

471
00:18:17,190 --> 00:18:18,659
integration continuous deployment to

472
00:18:18,659 --> 00:18:20,039
experience everything just really run

473
00:18:20,039 --> 00:18:22,590
fast of security people we like to tear

474
00:18:22,590 --> 00:18:24,840
things apart that's kind of a mismatch

475
00:18:24,840 --> 00:18:28,549
it doesn't really work well together

476
00:18:28,549 --> 00:18:31,230
every quarter security person drops in

477
00:18:31,230 --> 00:18:35,010
and says hey how you doing tell me

478
00:18:35,010 --> 00:18:36,210
what's been going on what you've been

479
00:18:36,210 --> 00:18:37,919
doing the past three months three months

480
00:18:37,919 --> 00:18:39,240
I don't know what I did three days ago

481
00:18:39,240 --> 00:18:42,000
that's why we have stand up for two-week

482
00:18:42,000 --> 00:18:43,529
Sprint's I'm not gonna deal with every

483
00:18:43,529 --> 00:18:45,149
corner of the security person drops in

484
00:18:45,149 --> 00:18:47,880
and wants me to read hit reset and start

485
00:18:47,880 --> 00:18:49,860
all over and this happens far too often

486
00:18:49,860 --> 00:18:52,950
and big corporates and to be fair part

487
00:18:52,950 --> 00:18:55,679
of this is because again a hundred

488
00:18:55,679 --> 00:18:58,590
developers one security person we simply

489
00:18:58,590 --> 00:19:01,020
can't scale we like to pretend we have

490
00:19:01,020 --> 00:19:02,789
of these automated scripts all over the

491
00:19:02,789 --> 00:19:04,470
place but when it comes to things like

492
00:19:04,470 --> 00:19:06,450
threat modeling and secure design

493
00:19:06,450 --> 00:19:08,520
there's simply not enough of us to go

494
00:19:08,520 --> 00:19:12,899
around and what happens as a result of

495
00:19:12,899 --> 00:19:17,130
that the developer is like I will take

496
00:19:17,130 --> 00:19:18,870
your advice into consideration thank you

497
00:19:18,870 --> 00:19:21,840
very much let's meet for lunch sometime

498
00:19:21,840 --> 00:19:24,270
sounds good and goodbye

499
00:19:24,270 --> 00:19:26,340
and that's about where it ends because

500
00:19:26,340 --> 00:19:30,120
it's not usable very often and as

501
00:19:30,120 --> 00:19:31,679
security people we're stuck with the

502
00:19:31,679 --> 00:19:33,090
shovels in our hand trying to paddle

503
00:19:33,090 --> 00:19:36,120
upstream we're using the wrong tool for

504
00:19:36,120 --> 00:19:38,610
the job it's not getting the job done

505
00:19:38,610 --> 00:19:40,740
we're spending so far so much effort and

506
00:19:40,740 --> 00:19:42,870
not getting where we need to go at the

507
00:19:42,870 --> 00:19:46,409
speed that we should be going so let's

508
00:19:46,409 --> 00:19:49,140
try a different approach from our link

509
00:19:49,140 --> 00:19:51,870
is still a great thing still needs to be

510
00:19:51,870 --> 00:19:53,760
done however it needs to be done

511
00:19:53,760 --> 00:19:56,580
differently so let's let's review what

512
00:19:56,580 --> 00:19:59,399
threat modeling is at its core adam

513
00:19:59,399 --> 00:20:02,279
szostak the father of threat modeling

514
00:20:02,279 --> 00:20:03,030
says

515
00:20:03,030 --> 00:20:04,770
whatever methodology you're using it

516
00:20:04,770 --> 00:20:07,080
basically comes down to answering these

517
00:20:07,080 --> 00:20:10,800
four questions number one what are you

518
00:20:10,800 --> 00:20:12,720
building what are you working on there's

519
00:20:12,720 --> 00:20:14,580
the system you're building right the DFT

520
00:20:14,580 --> 00:20:17,310
the diagrams the actual software design

521
00:20:17,310 --> 00:20:20,460
the code what are you building number

522
00:20:20,460 --> 00:20:22,980
two what can go wrong these were the

523
00:20:22,980 --> 00:20:24,690
actual threats these are the tax these

524
00:20:24,690 --> 00:20:27,180
are the things there's security bugs you

525
00:20:27,180 --> 00:20:29,690
might be building into your system

526
00:20:29,690 --> 00:20:31,380
number three what are we going to do

527
00:20:31,380 --> 00:20:31,770
about it

528
00:20:31,770 --> 00:20:34,440
that's the countermeasures right this is

529
00:20:34,440 --> 00:20:36,240
the security controls that we're going

530
00:20:36,240 --> 00:20:37,560
to build and this is effectively the

531
00:20:37,560 --> 00:20:39,900
point of the whole exercise to get

532
00:20:39,900 --> 00:20:42,450
secure software and number four did we

533
00:20:42,450 --> 00:20:43,290
do a good job

534
00:20:43,290 --> 00:20:47,130
does our model our dfd actually reflect

535
00:20:47,130 --> 00:20:48,770
the code that you're actually building

536
00:20:48,770 --> 00:20:52,260
did we capture all the use stories the

537
00:20:52,260 --> 00:20:56,090
user stories did we find all the threats

538
00:20:56,090 --> 00:20:59,010
did we mitigate all the high threats did

539
00:20:59,010 --> 00:21:00,870
we fully mitigate them maybe we put it

540
00:21:00,870 --> 00:21:03,090
in a mitigation that leaves residual

541
00:21:03,090 --> 00:21:04,560
risk okay

542
00:21:04,560 --> 00:21:06,420
and did we introduce any new threats

543
00:21:06,420 --> 00:21:09,030
based on the the new countermeasure that

544
00:21:09,030 --> 00:21:11,010
we built for example the common example

545
00:21:11,010 --> 00:21:13,920
is that on a login script a lock and

546
00:21:13,920 --> 00:21:15,170
screen you might be worried about

547
00:21:15,170 --> 00:21:17,670
brute-forcing attacks so let's put in a

548
00:21:17,670 --> 00:21:19,440
lockout mechanism after five wrong

549
00:21:19,440 --> 00:21:21,750
passwords we're gonna lock you out and

550
00:21:21,750 --> 00:21:23,970
what did we just do we introduced a

551
00:21:23,970 --> 00:21:26,400
denial of service threat so we need to

552
00:21:26,400 --> 00:21:28,230
review the countermeasures that we built

553
00:21:28,230 --> 00:21:30,210
to make sure that yes okay we need to

554
00:21:30,210 --> 00:21:31,650
make sure that that account gets

555
00:21:31,650 --> 00:21:35,570
unlocked after a certain number of time

556
00:21:35,570 --> 00:21:38,970
now Adam likes to quote George box and I

557
00:21:38,970 --> 00:21:42,240
like to misquote Adam all threat models

558
00:21:42,240 --> 00:21:44,640
are wrong some are useful okay if

559
00:21:44,640 --> 00:21:45,810
there's one thing you take away from my

560
00:21:45,810 --> 00:21:48,180
talk it should be this okay all threat

561
00:21:48,180 --> 00:21:51,990
models are wrong some are useful now all

562
00:21:51,990 --> 00:21:54,000
the other models that we've been trying

563
00:21:54,000 --> 00:21:56,970
to build whether it's stride or pasta or

564
00:21:56,970 --> 00:21:58,830
whatever it is tries to make the threat

565
00:21:58,830 --> 00:22:02,100
model as correct as possible right pasta

566
00:22:02,100 --> 00:22:04,140
gives a really really almost 100 percent

567
00:22:04,140 --> 00:22:07,260
correct a model accept all threat models

568
00:22:07,260 --> 00:22:11,190
are wrong they can't be right but some

569
00:22:11,190 --> 00:22:14,660
are useful so if we accept that

570
00:22:14,660 --> 00:22:18,320
the threat model is wrong I say grab it

571
00:22:18,320 --> 00:22:20,660
with both hands lean into being wrong be

572
00:22:20,660 --> 00:22:23,530
proud of being wrong but be useful

573
00:22:23,530 --> 00:22:26,000
optimized for usefulness in this case

574
00:22:26,000 --> 00:22:28,429
what I mean by usefulness is secure

575
00:22:28,429 --> 00:22:30,980
features let's find as quickly as

576
00:22:30,980 --> 00:22:31,640
possible

577
00:22:31,640 --> 00:22:34,010
the security features and functionality

578
00:22:34,010 --> 00:22:36,620
that we need to build without worrying

579
00:22:36,620 --> 00:22:39,650
about the other 80% of the model let us

580
00:22:39,650 --> 00:22:44,510
be wrong as long as we're useful so I'm

581
00:22:44,510 --> 00:22:46,330
proposing different set of questions

582
00:22:46,330 --> 00:22:50,409
okay number one why are we building it

583
00:22:50,409 --> 00:22:54,230
okay why are we building this why do we

584
00:22:54,230 --> 00:22:56,230
choose to implement this user story

585
00:22:56,230 --> 00:22:58,640
right now why are we building this

586
00:22:58,640 --> 00:22:59,990
feature instead of that other feature

587
00:22:59,990 --> 00:23:03,110
over there usually it you know produces

588
00:23:03,110 --> 00:23:05,299
more money more users whatever it is now

589
00:23:05,299 --> 00:23:06,500
take into account developers know

590
00:23:06,500 --> 00:23:08,539
exactly what they're building so coming

591
00:23:08,539 --> 00:23:10,250
in and say build a threat model and

592
00:23:10,250 --> 00:23:11,809
start with what are you building they

593
00:23:11,809 --> 00:23:12,770
know what they're building

594
00:23:12,770 --> 00:23:16,460
start with why okay what is the goal

595
00:23:16,460 --> 00:23:19,240
what are we trying to achieve here and

596
00:23:19,240 --> 00:23:22,610
how does the system actually get

597
00:23:22,610 --> 00:23:24,409
whatever value we're trying to get out

598
00:23:24,409 --> 00:23:26,780
of this feature what is the correct flow

599
00:23:26,780 --> 00:23:29,539
what is the happy path to get that value

600
00:23:29,539 --> 00:23:32,510
to squeeze as much value as possible out

601
00:23:32,510 --> 00:23:35,299
of that feature and what do we has

602
00:23:35,299 --> 00:23:37,429
system implementers as the developers

603
00:23:37,429 --> 00:23:40,460
what do we need to do to ensure we stay

604
00:23:40,460 --> 00:23:42,679
on that happy path what do we need to do

605
00:23:42,679 --> 00:23:45,980
to ensure that we get that value out of

606
00:23:45,980 --> 00:23:48,530
this feature now if you've noticed it's

607
00:23:48,530 --> 00:23:50,270
very similar and there's no fourth step

608
00:23:50,270 --> 00:23:52,010
by the way because did we do a good job

609
00:23:52,010 --> 00:23:54,409
that's already built into the agile

610
00:23:54,409 --> 00:23:54,919
workflow

611
00:23:54,919 --> 00:23:56,330
there's the retrospective that they

612
00:23:56,330 --> 00:23:58,640
always have after you build anything so

613
00:23:58,640 --> 00:24:00,830
you're already doing they did we do a

614
00:24:00,830 --> 00:24:02,870
good job and you don't need to rehash

615
00:24:02,870 --> 00:24:06,950
that separately from the development now

616
00:24:06,950 --> 00:24:08,679
if you've noticed this is very similar

617
00:24:08,679 --> 00:24:11,620
overall to the original four questions

618
00:24:11,620 --> 00:24:15,830
and it's just pivoted around a very

619
00:24:15,830 --> 00:24:18,559
simple concept its pivoted around a

620
00:24:18,559 --> 00:24:22,070
small idea which I warned you can be

621
00:24:22,070 --> 00:24:24,380
shocking it is offensive to some

622
00:24:24,380 --> 00:24:27,559
security people okay so the

623
00:24:27,559 --> 00:24:30,940
concept that it's pivoted around

624
00:24:32,259 --> 00:24:34,669
developers are optimistic by Nature

625
00:24:34,669 --> 00:24:36,710
they build things leave your foot at

626
00:24:36,710 --> 00:24:39,350
home we don't need that leave your stuff

627
00:24:39,350 --> 00:24:40,970
behind people are building stuff here

628
00:24:40,970 --> 00:24:42,440
the sky is falling of course

629
00:24:42,440 --> 00:24:43,789
everything's broken have you seen the

630
00:24:43,789 --> 00:24:45,889
Internet's we know that it doesn't

631
00:24:45,889 --> 00:24:49,029
matter we're still building new features

632
00:24:49,029 --> 00:24:52,009
so instead of focusing every all the

633
00:24:52,009 --> 00:24:53,749
time on attackers and this will break in

634
00:24:53,749 --> 00:24:55,279
that threat and what will go wrong

635
00:24:55,279 --> 00:24:57,529
let's focus on what will go right let's

636
00:24:57,529 --> 00:24:59,330
focus on how to keep things going right

637
00:24:59,330 --> 00:25:01,100
ain't not worry about every possible

638
00:25:01,100 --> 00:25:04,700
thing that could go wrong a while back I

639
00:25:04,700 --> 00:25:07,220
noticed an argument on Twitter in the

640
00:25:07,220 --> 00:25:10,490
context of airline safety and in airline

641
00:25:10,490 --> 00:25:13,279
safety they don't talk about preventing

642
00:25:13,279 --> 00:25:14,990
accidents or making sure it doesn't

643
00:25:14,990 --> 00:25:17,869
crash or basically stopping hacks and

644
00:25:17,869 --> 00:25:20,749
attackers right they worry about safe

645
00:25:20,749 --> 00:25:25,789
transportation secure features not how

646
00:25:25,789 --> 00:25:28,039
to prevent that kind of attack or stop

647
00:25:28,039 --> 00:25:31,159
that threat how to provide secure

648
00:25:31,159 --> 00:25:35,149
features value that's why I call it

649
00:25:35,149 --> 00:25:38,779
value driven and the way to do this is

650
00:25:38,779 --> 00:25:41,570
get developers working with us we have a

651
00:25:41,570 --> 00:25:43,399
huge work force of a hundred times

652
00:25:43,399 --> 00:25:45,019
larger than the security people

653
00:25:45,019 --> 00:25:47,990
Jim Monaco likes to say every dove every

654
00:25:47,990 --> 00:25:49,909
software engineer is now a security

655
00:25:49,909 --> 00:25:51,669
engineer whether they know it or not

656
00:25:51,669 --> 00:25:53,749
they're doing a good job or they're not

657
00:25:53,749 --> 00:25:57,409
so if we get them on our team that we

658
00:25:57,409 --> 00:25:58,730
can do it there's simply not enough

659
00:25:58,730 --> 00:26:00,830
security people to provide all the

660
00:26:00,830 --> 00:26:03,200
software security we need to do so we

661
00:26:03,200 --> 00:26:05,659
need to get security to get developers

662
00:26:05,659 --> 00:26:08,269
to do security for us and we need to

663
00:26:08,269 --> 00:26:10,190
give them the right incentives or the

664
00:26:10,190 --> 00:26:12,919
right workflow to work it with us so

665
00:26:12,919 --> 00:26:16,490
what does that workflow look like number

666
00:26:16,490 --> 00:26:19,700
one we need to focus you need to focus

667
00:26:19,700 --> 00:26:23,360
on what is important let's skip the

668
00:26:23,360 --> 00:26:25,610
things that we already know about we

669
00:26:25,610 --> 00:26:27,740
don't need to bother threat modeling SQL

670
00:26:27,740 --> 00:26:29,690
injection alright we don't need to wait

671
00:26:29,690 --> 00:26:31,789
for the security team to come back after

672
00:26:31,789 --> 00:26:34,519
3x and say oh if you have a website you

673
00:26:34,519 --> 00:26:35,600
have a massive threatened you need to

674
00:26:35,600 --> 00:26:36,889
deal with cross-site scripting we know

675
00:26:36,889 --> 00:26:38,480
that we don't need the consultant to

676
00:26:38,480 --> 00:26:40,399
spend two months to say oh you better

677
00:26:40,399 --> 00:26:40,880
put two

678
00:26:40,880 --> 00:26:43,760
on that end point yeah that's kind of

679
00:26:43,760 --> 00:26:45,530
well-known that should be the point that

680
00:26:45,530 --> 00:26:47,600
we start from and threat model after

681
00:26:47,600 --> 00:26:51,080
that now there is an assumption here but

682
00:26:51,080 --> 00:26:52,460
I mean it can be erased listen about

683
00:26:52,460 --> 00:26:54,710
that assumption that our developers know

684
00:26:54,710 --> 00:26:56,330
the basics okay

685
00:26:56,330 --> 00:26:59,600
they have basic code hygiene right input

686
00:26:59,600 --> 00:27:01,580
validation and so on they know that

687
00:27:01,580 --> 00:27:03,830
basic stuff and if they don't well

688
00:27:03,830 --> 00:27:05,450
that's where training comes in and if

689
00:27:05,450 --> 00:27:06,710
they do you still need more training

690
00:27:06,710 --> 00:27:07,880
fine

691
00:27:07,880 --> 00:27:09,590
trained your developers trained your QA

692
00:27:09,590 --> 00:27:12,350
give them the basics and then have

693
00:27:12,350 --> 00:27:14,630
threat modeling start where that left

694
00:27:14,630 --> 00:27:17,570
leaves off and don't waste time on the

695
00:27:17,570 --> 00:27:19,580
obvious things the other thing that's

696
00:27:19,580 --> 00:27:21,980
very useful to short-circuit those basic

697
00:27:21,980 --> 00:27:23,930
things is what's called a threat library

698
00:27:23,930 --> 00:27:26,900
or threat patterns for example if you

699
00:27:26,900 --> 00:27:29,030
have a relational database there might

700
00:27:29,030 --> 00:27:31,040
be a Skrill injection right if you have

701
00:27:31,040 --> 00:27:32,960
a webpage that your output data

702
00:27:32,960 --> 00:27:35,390
cross-site scripting is a thing so why

703
00:27:35,390 --> 00:27:37,190
bother modeling it you can automatically

704
00:27:37,190 --> 00:27:38,780
pull out the threats and the

705
00:27:38,780 --> 00:27:41,090
countermeasures I'm using docker I don't

706
00:27:41,090 --> 00:27:42,650
need to start researching every possible

707
00:27:42,650 --> 00:27:44,570
hack that there might be I figure using

708
00:27:44,570 --> 00:27:48,050
docker use these guidelines and so on

709
00:27:48,050 --> 00:27:50,330
and you know the theory I'd like to say

710
00:27:50,330 --> 00:27:52,370
that there's a huge open source library

711
00:27:52,370 --> 00:27:53,780
around that there's that yet it's

712
00:27:53,780 --> 00:27:56,210
starting to be developed os pass the

713
00:27:56,210 --> 00:27:57,650
Cloud Security Project and the threat

714
00:27:57,650 --> 00:27:59,150
modeling project there's a few

715
00:27:59,150 --> 00:28:01,100
commercial tools out there and I've

716
00:28:01,100 --> 00:28:02,540
worked with a lot of companies that are

717
00:28:02,540 --> 00:28:04,400
creating that internally for their own

718
00:28:04,400 --> 00:28:05,870
specific threats their own specific

719
00:28:05,870 --> 00:28:09,440
systems and that's great but the point

720
00:28:09,440 --> 00:28:11,930
is that's kind of a shortcut to the

721
00:28:11,930 --> 00:28:14,720
baseline because threat modeling should

722
00:28:14,720 --> 00:28:17,840
be above the baseline so that's number

723
00:28:17,840 --> 00:28:19,610
one we're focusing on the unknown we're

724
00:28:19,610 --> 00:28:22,490
focusing on the actual business logic

725
00:28:22,490 --> 00:28:25,400
attacks and what do we need to focus on

726
00:28:25,400 --> 00:28:26,810
the scope we're not gonna do the whole

727
00:28:26,810 --> 00:28:28,280
system all at once we're not going to do

728
00:28:28,280 --> 00:28:30,320
all the architecture over and over again

729
00:28:30,320 --> 00:28:33,380
we're gonna do for each user story or

730
00:28:33,380 --> 00:28:36,290
the epic or the feature every team works

731
00:28:36,290 --> 00:28:38,180
slightly differently in agile so

732
00:28:38,180 --> 00:28:40,520
wherever you're doing your minimal

733
00:28:40,520 --> 00:28:43,700
design your just-in-time design wherever

734
00:28:43,700 --> 00:28:45,530
you're doing that you're doing this

735
00:28:45,530 --> 00:28:47,660
threat model basically what I'm saying

736
00:28:47,660 --> 00:28:49,220
is when you're doing your just-in-time

737
00:28:49,220 --> 00:28:52,040
design design includes a minimal threat

738
00:28:52,040 --> 00:28:53,090
model

739
00:28:53,090 --> 00:28:56,250
whether it's your discovery or the

740
00:28:56,250 --> 00:28:58,049
sprint planning that's when we're doing

741
00:28:58,049 --> 00:29:02,130
this threat modeling okay if you talk

742
00:29:02,130 --> 00:29:03,900
about just enough design I want us to

743
00:29:03,900 --> 00:29:05,400
talk about just enough threat model

744
00:29:05,400 --> 00:29:08,730
minimally viable threat model okay and

745
00:29:08,730 --> 00:29:10,890
the threat model becomes part of the

746
00:29:10,890 --> 00:29:13,320
user story it's not stored in Excel it's

747
00:29:13,320 --> 00:29:15,360
not stored in my security documentation

748
00:29:15,360 --> 00:29:17,820
it is part of the feature documentation

749
00:29:17,820 --> 00:29:22,169
it's built into the user story now for

750
00:29:22,169 --> 00:29:24,419
each user story or a picker feature we

751
00:29:24,419 --> 00:29:28,260
want to find the actual value usually

752
00:29:28,260 --> 00:29:30,630
you're gonna follow the money that's

753
00:29:30,630 --> 00:29:32,429
usually the value we want to sell more

754
00:29:32,429 --> 00:29:34,649
product we want to upgrade users we want

755
00:29:34,649 --> 00:29:37,200
to get more eyeballs on my social

756
00:29:37,200 --> 00:29:39,809
network for cats whatever it is we want

757
00:29:39,809 --> 00:29:43,380
to create more value for the for the

758
00:29:43,380 --> 00:29:45,149
organization you're creating you're

759
00:29:45,149 --> 00:29:47,730
building this feature usually some form

760
00:29:47,730 --> 00:29:50,340
of money sometimes you want to know how

761
00:29:50,340 --> 00:29:51,840
people died whether it's airline safety

762
00:29:51,840 --> 00:29:54,059
or hospitals or government systems

763
00:29:54,059 --> 00:29:56,039
sometimes how people die might be

764
00:29:56,039 --> 00:29:58,500
meeting regulations whatever that value

765
00:29:58,500 --> 00:30:01,620
is that's what you need to find you put

766
00:30:01,620 --> 00:30:03,690
that into the user story the actual goal

767
00:30:03,690 --> 00:30:09,059
the why and the way the workflow is that

768
00:30:09,059 --> 00:30:11,850
for each user story we're explicit about

769
00:30:11,850 --> 00:30:13,470
the goals again they usually know the

770
00:30:13,470 --> 00:30:16,169
goals sometimes it's implicit sometimes

771
00:30:16,169 --> 00:30:18,330
they don't know it but if the product

772
00:30:18,330 --> 00:30:20,970
owner defines the actual goal of this

773
00:30:20,970 --> 00:30:23,850
user story developers can now align

774
00:30:23,850 --> 00:30:26,850
around that and that now becomes our

775
00:30:26,850 --> 00:30:29,370
incentive when we build our user story

776
00:30:29,370 --> 00:30:32,250
it needs to provide that value so we're

777
00:30:32,250 --> 00:30:34,529
no longer talking about the security of

778
00:30:34,529 --> 00:30:38,220
the feature or the possible attacks

779
00:30:38,220 --> 00:30:40,070
we're talking about how to ensure that

780
00:30:40,070 --> 00:30:46,080
value and usually user stories describe

781
00:30:46,080 --> 00:30:49,380
the flow the happy path sometimes it's

782
00:30:49,380 --> 00:30:52,049
not completely explicit very often they

783
00:30:52,049 --> 00:30:54,450
skip the failure states so we're gonna

784
00:30:54,450 --> 00:30:56,669
be explicit in the user story and

785
00:30:56,669 --> 00:30:59,309
describe what happens when I can't log

786
00:30:59,309 --> 00:31:01,140
in what happens when the values I

787
00:31:01,140 --> 00:31:03,510
provide are wrong what happens what I

788
00:31:03,510 --> 00:31:05,880
has to transfer more money out of my

789
00:31:05,880 --> 00:31:06,300
account

790
00:31:06,300 --> 00:31:09,720
I should be allowed to and one of the

791
00:31:09,720 --> 00:31:11,450
important things here is to find

792
00:31:11,450 --> 00:31:14,760
assumptions one of my mentors used to

793
00:31:14,760 --> 00:31:17,370
say that the attacker starts with your

794
00:31:17,370 --> 00:31:18,120
assumptions

795
00:31:18,120 --> 00:31:20,160
whatever the developer assumptions are

796
00:31:20,160 --> 00:31:22,620
that's what the attacker will find he

797
00:31:22,620 --> 00:31:23,760
was talking about in the context of

798
00:31:23,760 --> 00:31:26,340
penetration testing but it still lasts

799
00:31:26,340 --> 00:31:28,860
now the tricky thing is that finding

800
00:31:28,860 --> 00:31:30,810
your own assumption is usually very hard

801
00:31:30,810 --> 00:31:33,180
you're locked in to your own bias bubble

802
00:31:33,180 --> 00:31:34,320
you're not gonna know about it

803
00:31:34,320 --> 00:31:36,630
it helps to have a discussion with other

804
00:31:36,630 --> 00:31:38,640
people and you can find each other's

805
00:31:38,640 --> 00:31:40,410
assumptions there's a whole bunch of

806
00:31:40,410 --> 00:31:43,640
methods and techniques to find your own

807
00:31:43,640 --> 00:31:46,200
assumptions like Socratic questioning

808
00:31:46,200 --> 00:31:47,670
well that's a whole nother separate

809
00:31:47,670 --> 00:31:49,770
psychology talk but once we find the

810
00:31:49,770 --> 00:31:51,600
assumptions once we're explicit about

811
00:31:51,600 --> 00:31:54,290
our assumptions we can validate them

812
00:31:54,290 --> 00:31:57,030
it's either true or it's not true right

813
00:31:57,030 --> 00:32:00,150
or we can enforce conditions in code by

814
00:32:00,150 --> 00:32:01,800
putting into as part of the design you

815
00:32:01,800 --> 00:32:04,410
put it into the user story the developer

816
00:32:04,410 --> 00:32:06,630
now goes and puts checks in code to

817
00:32:06,630 --> 00:32:09,620
verify that that is actually the case

818
00:32:09,620 --> 00:32:12,390
and you no longer have those implicit

819
00:32:12,390 --> 00:32:16,200
assumptions and you need to be again

820
00:32:16,200 --> 00:32:18,240
explicit about what happens when things

821
00:32:18,240 --> 00:32:20,220
go wrong when you fall off a happy path

822
00:32:20,220 --> 00:32:25,350
what happens then so that's basically

823
00:32:25,350 --> 00:32:28,110
the whole flow overall I'm going to go

824
00:32:28,110 --> 00:32:29,640
into more detail in a moment I want to

825
00:32:29,640 --> 00:32:32,400
give you a quick little example of what

826
00:32:32,400 --> 00:32:34,830
I mean by finding the value and how this

827
00:32:34,830 --> 00:32:36,510
contributes to a threat model so I'm

828
00:32:36,510 --> 00:32:37,890
going to use the elastic juice shop

829
00:32:37,890 --> 00:32:39,180
anybody that's familiar that is

830
00:32:39,180 --> 00:32:41,160
basically the best place not to buy

831
00:32:41,160 --> 00:32:42,030
juice on the Internet

832
00:32:42,030 --> 00:32:44,160
it's an example of a modern web

833
00:32:44,160 --> 00:32:46,880
application that has all these broken

834
00:32:46,880 --> 00:32:49,560
vulnerabilities built into the system so

835
00:32:49,560 --> 00:32:51,420
it's used for a practice and pen testing

836
00:32:51,420 --> 00:32:54,270
and so on so this is great site very

837
00:32:54,270 --> 00:32:57,270
similar to many other e-commerce sites

838
00:32:57,270 --> 00:32:58,890
you go and you choose your juice and

839
00:32:58,890 --> 00:33:00,330
we're gonna choose banana juice because

840
00:33:00,330 --> 00:33:01,620
I have a gorilla at home that needs to

841
00:33:01,620 --> 00:33:03,630
be fed and this is bad watch as much

842
00:33:03,630 --> 00:33:05,190
architecture as we need you have your

843
00:33:05,190 --> 00:33:07,200
single page application built on angular

844
00:33:07,200 --> 00:33:09,390
you have you know GS server calling it a

845
00:33:09,390 --> 00:33:11,600
sequel light that's about as much

846
00:33:11,600 --> 00:33:15,140
architecture as we need for this point

847
00:33:15,140 --> 00:33:17,520
now on a highlight one little feature

848
00:33:17,520 --> 00:33:19,710
when you go to check out with

849
00:33:19,710 --> 00:33:21,870
or you check out you can press this

850
00:33:21,870 --> 00:33:24,510
little orange button which is a gift

851
00:33:24,510 --> 00:33:27,960
coupon and there's a link there to their

852
00:33:27,960 --> 00:33:30,299
Twitter and you can get a coupon code to

853
00:33:30,299 --> 00:33:33,360
get 30% off right if you use it within

854
00:33:33,360 --> 00:33:35,130
within the date before the end of July

855
00:33:35,130 --> 00:33:37,320
and I put the coupon code here and it

856
00:33:37,320 --> 00:33:39,570
applies to 3% off and I get it

857
00:33:39,570 --> 00:33:43,140
great now let me ask you this why do I

858
00:33:43,140 --> 00:33:45,299
have that feature why did we decide to

859
00:33:45,299 --> 00:33:46,279
build that feature

860
00:33:46,279 --> 00:33:51,029
anybody cheaper juice right

861
00:33:51,029 --> 00:33:53,520
no she produces not the reason we built

862
00:33:53,520 --> 00:33:55,590
the feature the reason we built the

863
00:33:55,590 --> 00:33:59,520
feature its marketing right marketing

864
00:33:59,520 --> 00:34:01,260
department came out with some study that

865
00:34:01,260 --> 00:34:03,750
during national juice week if we give a

866
00:34:03,750 --> 00:34:04,890
30% discount

867
00:34:04,890 --> 00:34:07,470
we'll get 40% one-time customers and

868
00:34:07,470 --> 00:34:10,649
half of those will come back right we'll

869
00:34:10,649 --> 00:34:14,099
get ten maybe 15% uptick in continual

870
00:34:14,099 --> 00:34:15,899
customers that will keep buying our

871
00:34:15,899 --> 00:34:18,060
juice at the full price so what is the

872
00:34:18,060 --> 00:34:19,859
value of this feature what is the point

873
00:34:19,859 --> 00:34:23,010
of it what's the goal more customers

874
00:34:23,010 --> 00:34:25,649
that come back not for this sale that

875
00:34:25,649 --> 00:34:26,760
will come back and buyer in the full

876
00:34:26,760 --> 00:34:29,760
price okay great so let me ask you this

877
00:34:29,760 --> 00:34:32,310
if that's the case yeah sure we could go

878
00:34:32,310 --> 00:34:34,139
and try and fuzz that coupon and see if

879
00:34:34,139 --> 00:34:35,969
we could change it but let's ask based

880
00:34:35,969 --> 00:34:38,639
on that value how could I subvert that

881
00:34:38,639 --> 00:34:41,129
value now sure I could ask okay

882
00:34:41,129 --> 00:34:42,899
instead of 30% of Reds gonna say well

883
00:34:42,899 --> 00:34:45,239
could I make it 60% by changing the code

884
00:34:45,239 --> 00:34:48,810
let me get 90% can I make you 200% but

885
00:34:48,810 --> 00:34:51,989
now let's invert that value what happens

886
00:34:51,989 --> 00:34:55,290
if I turn that if I block that coupon

887
00:34:55,290 --> 00:34:57,839
code from other users now nobody can use

888
00:34:57,839 --> 00:34:59,730
the code what happens if what anybody

889
00:34:59,730 --> 00:35:02,970
uses the code will now get a 30%

890
00:35:02,970 --> 00:35:06,170
increase in price or double the price

891
00:35:06,170 --> 00:35:08,310
what happened now fine it's a higher

892
00:35:08,310 --> 00:35:09,869
price big deal we get more money right

893
00:35:09,869 --> 00:35:11,910
no wrong those customers are never

894
00:35:11,910 --> 00:35:13,410
coming back to you because you just

895
00:35:13,410 --> 00:35:15,420
ruined their experience and the whole

896
00:35:15,420 --> 00:35:19,109
point of this feature is new residual

897
00:35:19,109 --> 00:35:21,570
customers you want them to come back and

898
00:35:21,570 --> 00:35:23,790
you just screw them over by doubling

899
00:35:23,790 --> 00:35:29,220
their price small change in concept but

900
00:35:29,220 --> 00:35:31,170
it's a lot easier for developers to grok

901
00:35:31,170 --> 00:35:33,480
and be able to deal with that type of

902
00:35:33,480 --> 00:35:34,619
because that's what they're dealing with

903
00:35:34,619 --> 00:35:37,020
they're implementing business value so

904
00:35:37,020 --> 00:35:39,210
it's easier for them to deal now I'm

905
00:35:39,210 --> 00:35:40,260
going to show you a few techniques that

906
00:35:40,260 --> 00:35:42,390
you can provide for your developers and

907
00:35:42,390 --> 00:35:46,349
let them use this to wrap this into the

908
00:35:46,349 --> 00:35:48,359
process some of these will not apply to

909
00:35:48,359 --> 00:35:50,550
every team so take what you like from

910
00:35:50,550 --> 00:35:53,250
this from this list of techniques see

911
00:35:53,250 --> 00:35:55,349
what works try different things some

912
00:35:55,349 --> 00:35:58,490
things will work some things won't

913
00:35:58,579 --> 00:36:00,480
number one definition of a done

914
00:36:00,480 --> 00:36:02,010
definition of done is something that a

915
00:36:02,010 --> 00:36:04,650
j'l teams use already anyway it's the

916
00:36:04,650 --> 00:36:09,329
process that the team agrees on they

917
00:36:09,329 --> 00:36:11,849
will not start developing unless there's

918
00:36:11,849 --> 00:36:14,369
acceptance tests explicitly designed

919
00:36:14,369 --> 00:36:17,309
they will not accept it until all

920
00:36:17,309 --> 00:36:19,950
exceptions tasks have been tested okay

921
00:36:19,950 --> 00:36:21,349
acceptance requirements

922
00:36:21,349 --> 00:36:23,910
unit tests whatever it is this is a

923
00:36:23,910 --> 00:36:26,490
process that they require before it

924
00:36:26,490 --> 00:36:28,859
moves on to the next projects phase in

925
00:36:28,859 --> 00:36:31,710
the process so we could put in our own

926
00:36:31,710 --> 00:36:33,660
security process assuming the team

927
00:36:33,660 --> 00:36:35,670
agrees to it of course and we'll say

928
00:36:35,670 --> 00:36:38,750
don't start developing this user story

929
00:36:38,750 --> 00:36:41,430
unless you have a minimal threat model

930
00:36:41,430 --> 00:36:44,040
built into the user story and security

931
00:36:44,040 --> 00:36:45,630
tests or whatever we decide whatever we

932
00:36:45,630 --> 00:36:47,549
agree on this will now be part of the

933
00:36:47,549 --> 00:36:49,589
process and that's it you're in this is

934
00:36:49,589 --> 00:36:50,970
part of the process now this is the way

935
00:36:50,970 --> 00:36:52,890
developers work because well that's the

936
00:36:52,890 --> 00:36:55,500
way they agree to work and that is

937
00:36:55,500 --> 00:36:57,630
already enforced by their own process

938
00:36:57,630 --> 00:37:00,200
and you don't need to chase them anymore

939
00:37:00,200 --> 00:37:02,760
acceptance criteria again is something

940
00:37:02,760 --> 00:37:04,559
that they already have they have the

941
00:37:04,559 --> 00:37:06,510
functional requirements the acceptance

942
00:37:06,510 --> 00:37:09,180
criteria is a testable statement of how

943
00:37:09,180 --> 00:37:12,510
do I know that this requirement has been

944
00:37:12,510 --> 00:37:15,030
met I can add that in for security

945
00:37:15,030 --> 00:37:17,160
requirements now so for the login screen

946
00:37:17,160 --> 00:37:18,930
when I log in with wrong password

947
00:37:18,930 --> 00:37:21,119
actually be locked out after five number

948
00:37:21,119 --> 00:37:23,910
of after five wrong attempts this is now

949
00:37:23,910 --> 00:37:26,250
built into the user story now they need

950
00:37:26,250 --> 00:37:28,500
to implement this and it's testable and

951
00:37:28,500 --> 00:37:31,140
because it's testable I can define that

952
00:37:31,140 --> 00:37:33,540
I need to build security unit tests and

953
00:37:33,540 --> 00:37:35,549
develop the QA will build those tests

954
00:37:35,549 --> 00:37:36,839
and run those tests and verify that this

955
00:37:36,839 --> 00:37:39,750
is always the case for example the QA

956
00:37:39,750 --> 00:37:41,910
team will now test that accounts are

957
00:37:41,910 --> 00:37:45,200
locked out after five wrong attempts and

958
00:37:45,200 --> 00:37:47,220
also its corollary

959
00:37:47,220 --> 00:37:49,410
you'll test that the accounts are

960
00:37:49,410 --> 00:37:53,300
unlocked after a certain amount of time

961
00:37:53,300 --> 00:37:56,339
abuser stories are very similar to user

962
00:37:56,339 --> 00:37:58,470
stories but from the perspective of the

963
00:37:58,470 --> 00:38:01,170
attacker okay sometimes it's very good

964
00:38:01,170 --> 00:38:05,460
useful to flesh out the attack case they

965
00:38:05,460 --> 00:38:07,950
attack flow of how it would happen again

966
00:38:07,950 --> 00:38:09,180
I don't want to get into the whole

967
00:38:09,180 --> 00:38:10,650
psychology of what does the attacker

968
00:38:10,650 --> 00:38:12,060
really want and tell me your thoughts

969
00:38:12,060 --> 00:38:13,680
and feelings I don't want to be a

970
00:38:13,680 --> 00:38:16,020
therapist for the attackers but I could

971
00:38:16,020 --> 00:38:18,089
pull this back and trace this back to my

972
00:38:18,089 --> 00:38:21,720
own value as an attacker I want to

973
00:38:21,720 --> 00:38:23,700
impersonate another user so I can steal

974
00:38:23,700 --> 00:38:26,520
their juice box juice box is my value

975
00:38:26,520 --> 00:38:29,099
okay I don't care why he wants to do it

976
00:38:29,099 --> 00:38:32,730
but I care how it effects my value the

977
00:38:32,730 --> 00:38:34,740
value that I'm trying to provide to

978
00:38:34,740 --> 00:38:38,629
another user and now your stole it

979
00:38:39,380 --> 00:38:41,700
everybody's familiar with the user story

980
00:38:41,700 --> 00:38:44,310
format agile likes to use as a I want em

981
00:38:44,310 --> 00:38:47,640
so that mmm so last year at the open

982
00:38:47,640 --> 00:38:50,250
security summit in London a group of us

983
00:38:50,250 --> 00:38:52,170
were talking about how to get something

984
00:38:52,170 --> 00:38:55,319
that simple for developers to apply to

985
00:38:55,319 --> 00:38:57,450
security and we came up with this

986
00:38:57,450 --> 00:39:02,069
without claws without as a customer I

987
00:39:02,069 --> 00:39:04,859
want to buy my juice so that I can have

988
00:39:04,859 --> 00:39:06,660
a nice breakfast in peace and quiet

989
00:39:06,660 --> 00:39:10,290
without my credit card being stolen

990
00:39:10,290 --> 00:39:12,869
without my card being stolen now there

991
00:39:12,869 --> 00:39:15,089
is zero detail there there's no

992
00:39:15,089 --> 00:39:17,040
information but that's okay because

993
00:39:17,040 --> 00:39:18,210
there's no information on the rest of

994
00:39:18,210 --> 00:39:18,960
the user story

995
00:39:18,960 --> 00:39:22,140
this gets fleshed out later during the

996
00:39:22,140 --> 00:39:23,849
discussion an invitation to a

997
00:39:23,849 --> 00:39:26,460
conversation that's the whole point of

998
00:39:26,460 --> 00:39:28,859
how the user stories work we only get

999
00:39:28,859 --> 00:39:30,780
the details that we need when we need

1000
00:39:30,780 --> 00:39:32,300
them we don't have that information

1001
00:39:32,300 --> 00:39:35,520
upfront but what this actually does it

1002
00:39:35,520 --> 00:39:37,589
gets the product owner that define the

1003
00:39:37,589 --> 00:39:40,980
user story just to stick a flag into the

1004
00:39:40,980 --> 00:39:43,109
user story without like card being

1005
00:39:43,109 --> 00:39:43,730
stolen

1006
00:39:43,730 --> 00:39:46,770
now when the developer or the designer

1007
00:39:46,770 --> 00:39:49,410
starts to talk about how to implement

1008
00:39:49,410 --> 00:39:52,079
this user story there is a security flag

1009
00:39:52,079 --> 00:39:53,730
right here and they're gonna need to

1010
00:39:53,730 --> 00:39:55,319
start talking about protecting credit

1011
00:39:55,319 --> 00:39:57,720
card details because that's their the

1012
00:39:57,720 --> 00:39:59,339
rest of the details of how it's done

1013
00:39:59,339 --> 00:40:00,090
that will

1014
00:40:00,090 --> 00:40:02,310
later together with rest of the details

1015
00:40:02,310 --> 00:40:03,960
of the recipes our story now this is

1016
00:40:03,960 --> 00:40:04,980
very very simple

1017
00:40:04,980 --> 00:40:08,730
it's so super lightweight without my car

1018
00:40:08,730 --> 00:40:09,600
being stolen

1019
00:40:09,600 --> 00:40:11,640
that's the minimal threat model that you

1020
00:40:11,640 --> 00:40:13,380
need to deal with when you deal with

1021
00:40:13,380 --> 00:40:15,540
credit cards right and this is something

1022
00:40:15,540 --> 00:40:16,800
that's very easy and simple for

1023
00:40:16,800 --> 00:40:18,660
developers to do because it's right

1024
00:40:18,660 --> 00:40:19,490
there

1025
00:40:19,490 --> 00:40:24,540
I want so that without I'm sure you all

1026
00:40:24,540 --> 00:40:26,040
familiar with the Maslow's hierarchy of

1027
00:40:26,040 --> 00:40:27,810
needs you can't deal with esteem and

1028
00:40:27,810 --> 00:40:30,720
love and so on until your physiological

1029
00:40:30,720 --> 00:40:32,850
needs are met until you have enough

1030
00:40:32,850 --> 00:40:34,920
safety to deal with higher-end needs and

1031
00:40:34,920 --> 00:40:36,570
in the same way we can deal with the

1032
00:40:36,570 --> 00:40:39,450
security right a threat pyramid there's

1033
00:40:39,450 --> 00:40:41,280
no point in dealing with do s attacks

1034
00:40:41,280 --> 00:40:43,380
and user access bypass before you make

1035
00:40:43,380 --> 00:40:46,440
sure there's no remote code execution or

1036
00:40:46,440 --> 00:40:49,350
unauthorized data access except of

1037
00:40:49,350 --> 00:40:50,910
course let's be honest most

1038
00:40:50,910 --> 00:40:52,230
organizations spend most of their time

1039
00:40:52,230 --> 00:40:54,150
dealing with SQL injection and crisis

1040
00:40:54,150 --> 00:40:55,890
scripting a little bit of time and

1041
00:40:55,890 --> 00:40:58,710
forcing weak passwords yes I heard what

1042
00:40:58,710 --> 00:40:59,040
I said

1043
00:40:59,040 --> 00:41:01,290
unfortunately passwords and of course we

1044
00:41:01,290 --> 00:41:03,840
have to deal with spam antivirus but we

1045
00:41:03,840 --> 00:41:06,060
could also turn this around and focus on

1046
00:41:06,060 --> 00:41:08,640
our value our value driven what's the

1047
00:41:08,640 --> 00:41:09,780
most important thing the biggest

1048
00:41:09,780 --> 00:41:11,850
doomsday scenario if somebody gets

1049
00:41:11,850 --> 00:41:13,290
access to our bank account steals all

1050
00:41:13,290 --> 00:41:15,900
the money right obviously and we

1051
00:41:15,900 --> 00:41:18,060
couldn't before we deal that there's no

1052
00:41:18,060 --> 00:41:19,560
point in doing the other higher level

1053
00:41:19,560 --> 00:41:22,230
things but once we're reasonably sure

1054
00:41:22,230 --> 00:41:24,210
that that is done we can now move up our

1055
00:41:24,210 --> 00:41:27,210
business logic stack deal with stolen

1056
00:41:27,210 --> 00:41:29,160
credit cards which has its own finely

1057
00:41:29,160 --> 00:41:29,730
the PII

1058
00:41:29,730 --> 00:41:31,920
and so on until we get to a real

1059
00:41:31,920 --> 00:41:34,410
business value which relies on all the

1060
00:41:34,410 --> 00:41:37,440
other layers somebody stole my juice my

1061
00:41:37,440 --> 00:41:40,260
market share and so on this is a

1062
00:41:40,260 --> 00:41:45,390
business value driven now some of you

1063
00:41:45,390 --> 00:41:47,490
familiar with story points is something

1064
00:41:47,490 --> 00:41:49,050
that developers often use is a very

1065
00:41:49,050 --> 00:41:52,500
rough estimate of how much work is this

1066
00:41:52,500 --> 00:41:55,200
story will take to implement compared to

1067
00:41:55,200 --> 00:41:56,820
that other story it's how much time it

1068
00:41:56,820 --> 00:41:59,550
is but how much work compared to that

1069
00:41:59,550 --> 00:42:01,230
other one for example they usually use

1070
00:42:01,230 --> 00:42:03,000
things like t-shirt sizes or Fibonacci

1071
00:42:03,000 --> 00:42:05,880
this is a small story and that's a

1072
00:42:05,880 --> 00:42:07,830
medium storage twice as much work as

1073
00:42:07,830 --> 00:42:09,870
that other one doesn't say we'll take

1074
00:42:09,870 --> 00:42:11,670
you three hours or two weeks to

1075
00:42:11,670 --> 00:42:13,440
implement it's just places

1076
00:42:13,440 --> 00:42:17,400
okay small medium large now um I was in

1077
00:42:17,400 --> 00:42:19,530
artillery so I don't really hear so well

1078
00:42:19,530 --> 00:42:21,060
and somebody was talking to me about

1079
00:42:21,060 --> 00:42:24,000
story points and I said sorry points

1080
00:42:24,000 --> 00:42:26,280
what's that that sounds really

1081
00:42:26,280 --> 00:42:27,930
interesting tell me more about this

1082
00:42:27,930 --> 00:42:30,570
sorry points so something good good

1083
00:42:30,570 --> 00:42:32,760
things sometimes come out of you know

1084
00:42:32,760 --> 00:42:35,790
not hearing so great and he's usually

1085
00:42:35,790 --> 00:42:37,380
just really funny my kids like to laugh

1086
00:42:37,380 --> 00:42:39,270
at me about it but sometimes good things

1087
00:42:39,270 --> 00:42:40,890
come out of it and turns out their story

1088
00:42:40,890 --> 00:42:42,060
points is a really interesting concept

1089
00:42:42,060 --> 00:42:44,640
because it's very intuitive and if you

1090
00:42:44,640 --> 00:42:46,680
ask developers out of these ten stories

1091
00:42:46,680 --> 00:42:49,350
which is the worst what's the worst

1092
00:42:49,350 --> 00:42:51,270
thing that could happen if this story

1093
00:42:51,270 --> 00:42:52,860
explodes in your face what if I have

1094
00:42:52,860 --> 00:42:55,500
everything goes sideways how bad could

1095
00:42:55,500 --> 00:42:57,810
it possibly be compared to those other

1096
00:42:57,810 --> 00:42:59,820
stories you don't need to put a price

1097
00:42:59,820 --> 00:43:01,860
tag on it just choose which is worse out

1098
00:43:01,860 --> 00:43:04,470
of these two or those three and rank

1099
00:43:04,470 --> 00:43:07,350
them by how bad it could possibly be are

1100
00:43:07,350 --> 00:43:09,180
we talking about a couple hours of

1101
00:43:09,180 --> 00:43:10,980
overtime are we talking about refresh

1102
00:43:10,980 --> 00:43:13,410
your resume because your careers over

1103
00:43:13,410 --> 00:43:17,910
are we talking about wyck having a

1104
00:43:17,910 --> 00:43:19,050
little bit of a headache in the morning

1105
00:43:19,050 --> 00:43:21,270
we're talking about waking up on a beach

1106
00:43:21,270 --> 00:43:22,470
surrounded by it behind a couple of

1107
00:43:22,470 --> 00:43:23,730
pythons with a shark eating dingo

1108
00:43:23,730 --> 00:43:26,040
looking on how bad is one scenario

1109
00:43:26,040 --> 00:43:28,320
compared to the other very rough

1110
00:43:28,320 --> 00:43:30,900
estimate very intuitive you can use

1111
00:43:30,900 --> 00:43:33,000
things like dot voting choose which are

1112
00:43:33,000 --> 00:43:34,710
the worst stories and will threat model

1113
00:43:34,710 --> 00:43:37,440
those it's very intuitive very quick

1114
00:43:37,440 --> 00:43:39,960
very easy to implement raise easy to get

1115
00:43:39,960 --> 00:43:43,410
developers to do this now out of all of

1116
00:43:43,410 --> 00:43:45,660
this is a bunch of techniques out of all

1117
00:43:45,660 --> 00:43:47,610
this this also helps you communicate

1118
00:43:47,610 --> 00:43:49,860
your technical attacks and threats and

1119
00:43:49,860 --> 00:43:51,810
all that in a way that makes sense to

1120
00:43:51,810 --> 00:43:54,060
the business for example how many people

1121
00:43:54,060 --> 00:43:55,470
know how to implement a cross-site

1122
00:43:55,470 --> 00:43:57,710
request forgery attack

1123
00:43:57,710 --> 00:44:01,650
nobody really well that's old-school and

1124
00:44:01,650 --> 00:44:02,910
executives don't even know what language

1125
00:44:02,910 --> 00:44:04,770
you're talking but if you tell them that

1126
00:44:04,770 --> 00:44:08,160
I can I can access your account and

1127
00:44:08,160 --> 00:44:09,180
transfer money out of your account

1128
00:44:09,180 --> 00:44:11,580
without being authenticated well that's

1129
00:44:11,580 --> 00:44:12,990
gonna get some attention even at the

1130
00:44:12,990 --> 00:44:15,150
board level if you tell somebody come

1131
00:44:15,150 --> 00:44:16,710
back with a report and say well there's

1132
00:44:16,710 --> 00:44:18,300
there's a stored cross-site scripting

1133
00:44:18,300 --> 00:44:20,640
attack vulnerability on your application

1134
00:44:20,640 --> 00:44:22,740
I'll say oh that's wrong that's violates

1135
00:44:22,740 --> 00:44:24,030
our policy we need to fix that and

1136
00:44:24,030 --> 00:44:25,470
you'll come back two years later and

1137
00:44:25,470 --> 00:44:26,070
it's

1138
00:44:26,070 --> 00:44:28,170
there but if you tell them I can take

1139
00:44:28,170 --> 00:44:30,270
over that administrator account that's

1140
00:44:30,270 --> 00:44:31,770
gonna get some attention that's gonna

1141
00:44:31,770 --> 00:44:34,470
get fixed the same way I can bypass all

1142
00:44:34,470 --> 00:44:36,030
the rosacea modules and bla bla bla bla

1143
00:44:36,030 --> 00:44:39,390
bla well what does it matter tell me how

1144
00:44:39,390 --> 00:44:41,490
this effects me well I could make sure

1145
00:44:41,490 --> 00:44:43,470
that your every juice you deliver comes

1146
00:44:43,470 --> 00:44:45,480
to me instead of to your customers well

1147
00:44:45,480 --> 00:44:47,250
you know what they're gonna care about

1148
00:44:47,250 --> 00:44:48,960
that that's gonna matter in the same way

1149
00:44:48,960 --> 00:44:51,360
denial-of-service translate that to

1150
00:44:51,360 --> 00:44:53,790
actual business goals actual value

1151
00:44:53,790 --> 00:44:56,220
you're losing revenue you're losing

1152
00:44:56,220 --> 00:44:57,930
market share nobody can come to your

1153
00:44:57,930 --> 00:45:00,960
site and buy stuff and what'd you do

1154
00:45:00,960 --> 00:45:03,030
this this actually really helps you even

1155
00:45:03,030 --> 00:45:05,220
doing something like black box threat

1156
00:45:05,220 --> 00:45:07,680
modeling without full access to the

1157
00:45:07,680 --> 00:45:09,510
system design and architecture just as a

1158
00:45:09,510 --> 00:45:12,360
black box pen tester you can still do a

1159
00:45:12,360 --> 00:45:14,880
really nice threat model based on these

1160
00:45:14,880 --> 00:45:16,830
values what does the application care

1161
00:45:16,830 --> 00:45:19,470
about why do these features exist what

1162
00:45:19,470 --> 00:45:24,270
are you trying to achieve so why is this

1163
00:45:24,270 --> 00:45:27,240
better well first of all it's not better

1164
00:45:27,240 --> 00:45:29,880
it's worse and I'm okay with that right

1165
00:45:29,880 --> 00:45:32,160
all threat models are wrong this is a

1166
00:45:32,160 --> 00:45:34,860
wrong threat model but it's useful why

1167
00:45:34,860 --> 00:45:36,840
is it useful because it's quick you get

1168
00:45:36,840 --> 00:45:40,310
something get output fast resume

1169
00:45:40,310 --> 00:45:42,660
diminishing returns you start with the

1170
00:45:42,660 --> 00:45:45,120
first 80% of value and the 20% of time

1171
00:45:45,120 --> 00:45:47,610
and you get something useful right away

1172
00:45:47,610 --> 00:45:49,710
and it goes with the same speed as

1173
00:45:49,710 --> 00:45:51,240
developers because their developers

1174
00:45:51,240 --> 00:45:52,560
they're the ones doing the threat

1175
00:45:52,560 --> 00:45:54,180
modeling they're doing it as part of the

1176
00:45:54,180 --> 00:45:55,800
development and threat model now becomes

1177
00:45:55,800 --> 00:45:57,840
part of it and cetera if it's part of

1178
00:45:57,840 --> 00:46:00,150
agile workflow it becomes part of how

1179
00:46:00,150 --> 00:46:01,530
they do it and therefore it's natural

1180
00:46:01,530 --> 00:46:03,840
for them to do it as opposed to how we

1181
00:46:03,840 --> 00:46:06,410
like working in the security field

1182
00:46:06,410 --> 00:46:08,370
documentation is up to date because the

1183
00:46:08,370 --> 00:46:10,560
threat model isn't separate it is the

1184
00:46:10,560 --> 00:46:12,300
documentation and if you update your

1185
00:46:12,300 --> 00:46:14,460
design you update your user stories your

1186
00:46:14,460 --> 00:46:15,630
updated your threat model because it's

1187
00:46:15,630 --> 00:46:18,300
right there it's part of it it helps you

1188
00:46:18,300 --> 00:46:19,680
communicate better with other parts of

1189
00:46:19,680 --> 00:46:22,760
the organization with the product owners

1190
00:46:22,760 --> 00:46:25,140
by toxic you to the product owners they

1191
00:46:25,140 --> 00:46:27,900
look at you like you're talking the

1192
00:46:27,900 --> 00:46:30,810
frackie but it helps you to communicate

1193
00:46:30,810 --> 00:46:33,060
with developers with the product owners

1194
00:46:33,060 --> 00:46:35,610
with executives because you're talking

1195
00:46:35,610 --> 00:46:37,020
business value talking the same language

1196
00:46:37,020 --> 00:46:39,150
and of course it's a lot easier to

1197
00:46:39,150 --> 00:46:39,740
integrate

1198
00:46:39,740 --> 00:46:41,510
with whatever process you're using if

1199
00:46:41,510 --> 00:46:42,980
it's scrum or Kanban or whatever it is

1200
00:46:42,980 --> 00:46:45,950
or cowboy agile it's because it's part

1201
00:46:45,950 --> 00:46:47,210
of whatever process you're using you're

1202
00:46:47,210 --> 00:46:50,030
just wrapping it into that and most

1203
00:46:50,030 --> 00:46:51,470
importantly you don't need to be paying

1204
00:46:51,470 --> 00:46:53,349
piles of money to jerks like me

1205
00:46:53,349 --> 00:46:55,520
expensive consultants or whoever it is

1206
00:46:55,520 --> 00:46:58,910
or NCC you don't need us because they're

1207
00:46:58,910 --> 00:47:01,720
doing it themselves and it is scaleable

1208
00:47:01,720 --> 00:47:04,310
we no longer need to rely on that one

1209
00:47:04,310 --> 00:47:06,619
security develop a security person 400

1210
00:47:06,619 --> 00:47:07,849
developers because the hundred

1211
00:47:07,849 --> 00:47:10,790
developers are the ones doing this so I

1212
00:47:10,790 --> 00:47:12,470
told you what's good let me tell you

1213
00:47:12,470 --> 00:47:15,320
what's bad it is not a complete threat

1214
00:47:15,320 --> 00:47:16,660
model by any stretch of the imagination

1215
00:47:16,660 --> 00:47:19,460
okay it is far from finding all the

1216
00:47:19,460 --> 00:47:20,900
threats are we forgetting about a lot of

1217
00:47:20,900 --> 00:47:21,980
threats absolutely

1218
00:47:21,980 --> 00:47:23,810
we're definitely forgetting a lot of

1219
00:47:23,810 --> 00:47:24,800
things even a lot of important things

1220
00:47:24,800 --> 00:47:27,800
all threat models are wrong some are

1221
00:47:27,800 --> 00:47:31,010
useful okay so yes we are as wrong as we

1222
00:47:31,010 --> 00:47:32,810
could possibly be minimally viable

1223
00:47:32,810 --> 00:47:34,609
threat model and we're leaving a lot of

1224
00:47:34,609 --> 00:47:37,220
threats on the table but you'll come

1225
00:47:37,220 --> 00:47:37,940
back to that later

1226
00:47:37,940 --> 00:47:41,839
and that's okay okay um we're relying on

1227
00:47:41,839 --> 00:47:43,730
the developers to do it and how do I

1228
00:47:43,730 --> 00:47:45,260
know that the developers will do a good

1229
00:47:45,260 --> 00:47:47,270
job we don't we need to be okay with

1230
00:47:47,270 --> 00:47:47,540
that

1231
00:47:47,540 --> 00:47:50,420
this is the world we live in how do we

1232
00:47:50,420 --> 00:47:51,470
know that developers are doing a good

1233
00:47:51,470 --> 00:47:53,900
job when we do the threat model and how

1234
00:47:53,900 --> 00:47:55,190
we know the developers are integrating

1235
00:47:55,190 --> 00:47:57,320
we don't we can scan code as much as we

1236
00:47:57,320 --> 00:47:59,390
want underhanded see competition shows

1237
00:47:59,390 --> 00:48:00,859
very clearly that you could review code

1238
00:48:00,859 --> 00:48:02,030
as much as you want and you don't really

1239
00:48:02,030 --> 00:48:05,570
know what the developers are doing so

1240
00:48:05,570 --> 00:48:06,740
we're relying on the fact that

1241
00:48:06,740 --> 00:48:09,470
developers can do a decent job you want

1242
00:48:09,470 --> 00:48:11,930
to give them training security champions

1243
00:48:11,930 --> 00:48:15,410
in the team will definitely help so this

1244
00:48:15,410 --> 00:48:16,730
kind of limitation that you're assuming

1245
00:48:16,730 --> 00:48:19,580
that you'll be able to do that and if

1246
00:48:19,580 --> 00:48:22,670
you're trying to build this for a

1247
00:48:22,670 --> 00:48:25,070
multi-billion dollar international bank

1248
00:48:25,070 --> 00:48:28,430
really it's probably not gonna be enough

1249
00:48:28,430 --> 00:48:31,760
you want a more rigorous process that

1250
00:48:31,760 --> 00:48:33,109
will give you a much higher level of

1251
00:48:33,109 --> 00:48:35,300
assurance but it's really cool to start

1252
00:48:35,300 --> 00:48:37,310
at this with this get your developers to

1253
00:48:37,310 --> 00:48:39,170
start with this and then when you come

1254
00:48:39,170 --> 00:48:41,180
in three days before they want to go

1255
00:48:41,180 --> 00:48:43,369
live with a new version you could start

1256
00:48:43,369 --> 00:48:45,230
at a much higher baseline instead of

1257
00:48:45,230 --> 00:48:46,700
starting from nothing it's like oh your

1258
00:48:46,700 --> 00:48:49,070
login system has is completely bypass

1259
00:48:49,070 --> 00:48:51,589
well well okay we actually started with

1260
00:48:51,589 --> 00:48:54,310
a certain baseline

1261
00:48:54,880 --> 00:48:58,400
so if there's one thing you take away

1262
00:48:58,400 --> 00:48:59,839
from my talk today it should be this not

1263
00:48:59,839 --> 00:49:02,630
not that other one take this one shut up

1264
00:49:02,630 --> 00:49:05,420
I want the developers just start threat

1265
00:49:05,420 --> 00:49:06,650
modeling I want you to get your

1266
00:49:06,650 --> 00:49:09,170
developers to start threat modeling and

1267
00:49:09,170 --> 00:49:12,200
how it needs to be part of the

1268
00:49:12,200 --> 00:49:14,479
development workflow by focusing on

1269
00:49:14,479 --> 00:49:17,869
business value okay focusing on business

1270
00:49:17,869 --> 00:49:20,359
value gives them the minimally viable

1271
00:49:20,359 --> 00:49:25,130
threat model all threat models are wrong

1272
00:49:25,130 --> 00:49:26,779
some are useful let's focus on the

1273
00:49:26,779 --> 00:49:28,519
usefulness start with the useful part

1274
00:49:28,519 --> 00:49:30,589
and that's it

1275
00:49:30,589 --> 00:49:32,269
don't go anywhere else unless you

1276
00:49:32,269 --> 00:49:34,039
absolutely need it when you need to

1277
00:49:34,039 --> 00:49:36,049
escalate using sorry points or whatever

1278
00:49:36,049 --> 00:49:38,420
it is then you can do the full stride

1279
00:49:38,420 --> 00:49:41,599
matrix or whatever it is thank you very

1280
00:49:41,599 --> 00:49:44,089
much for your attention I'll be around

1281
00:49:44,089 --> 00:49:46,720
if you are any questions

