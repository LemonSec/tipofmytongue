1
00:00:09,599 --> 00:00:14,219
great good afternoon everyone it's a

2
00:00:12,450 --> 00:00:15,809
pleasure to be here I'm Dexter Barton

3
00:00:14,219 --> 00:00:18,779
director at the Brunswick

4
00:00:15,809 --> 00:00:21,210
in London this is the session on reaping

5
00:00:18,779 --> 00:00:23,250
the rewards of the digital revolution so

6
00:00:21,210 --> 00:00:26,759
if you're not here for that session time

7
00:00:23,250 --> 00:00:29,759
to depart we're joined by two very

8
00:00:26,759 --> 00:00:32,460
distinguished guests today on my left we

9
00:00:29,759 --> 00:00:35,250
have Anna he'll Gurria who is the

10
00:00:32,460 --> 00:00:37,800
Secretary Journal of the OECD on my

11
00:00:35,250 --> 00:00:39,690
right we have John Lepore who is general

12
00:00:37,800 --> 00:00:42,839
counsel for policy and advocacy at

13
00:00:39,690 --> 00:00:44,610
MasterCard in New York and we're going

14
00:00:42,840 --> 00:00:46,950
to have a great discussion today before

15
00:00:44,610 --> 00:00:49,260
we get started I've been given one piece

16
00:00:46,950 --> 00:00:52,980
of housekeeping information to pass on

17
00:00:49,260 --> 00:00:56,730
we encourage everyone to tweet using the

18
00:00:52,980 --> 00:00:58,498
official hashtag Tatura summit 18 at

19
00:00:56,730 --> 00:01:01,769
least in this room we are going to fully

20
00:00:58,499 --> 00:01:02,850
embrace the digital revolution so we

21
00:01:01,769 --> 00:01:05,370
look forward to seeing all of your

22
00:01:02,850 --> 00:01:08,010
tweets we're gonna spend about 15

23
00:01:05,370 --> 00:01:09,210
minutes with the discussion on the panel

24
00:01:08,010 --> 00:01:11,670
and then we're going to open up for

25
00:01:09,210 --> 00:01:14,100
questions which I'll try to take two at

26
00:01:11,670 --> 00:01:16,140
a time just to keep things efficient so

27
00:01:14,100 --> 00:01:22,079
please do think of your questions for

28
00:01:16,140 --> 00:01:25,140
our guests here great so and he'll thank

29
00:01:22,079 --> 00:01:28,289
you very much for being here I guess my

30
00:01:25,140 --> 00:01:31,649
first question for you is within the

31
00:01:28,290 --> 00:01:34,860
tech industry where I've spent the last

32
00:01:31,649 --> 00:01:38,250
decade often governments have a bad

33
00:01:34,860 --> 00:01:40,649
reputation for embracing new innovations

34
00:01:38,250 --> 00:01:42,360
they're often caricatured as being very

35
00:01:40,649 --> 00:01:45,539
much behind the times when it comes to

36
00:01:42,360 --> 00:01:47,609
new technologies from your experience

37
00:01:45,539 --> 00:01:49,469
and in your role what is government

38
00:01:47,609 --> 00:01:51,750
getting right about the digital

39
00:01:49,469 --> 00:01:54,030
revolution today and what are the

40
00:01:51,750 --> 00:01:55,530
biggest challenges still to deal with

41
00:01:54,030 --> 00:02:02,939
that keep you up at night

42
00:01:55,530 --> 00:02:06,990
I think the regulated are always ahead

43
00:02:02,939 --> 00:02:12,209
of the regulators when it comes to

44
00:02:06,990 --> 00:02:14,760
digital they're a mile ahead the nature

45
00:02:12,210 --> 00:02:17,670
of the problem the nature of the

46
00:02:14,760 --> 00:02:21,480
challenges is such that when you're a

47
00:02:17,670 --> 00:02:26,190
regulator trying to catch up with the

48
00:02:21,480 --> 00:02:29,549
industry it's so fast and also because

49
00:02:26,190 --> 00:02:33,670
in the end what you want is to regulate

50
00:02:29,550 --> 00:02:37,629
the logic of regulation means something

51
00:02:33,670 --> 00:02:40,660
this relatively stationary and then you

52
00:02:37,629 --> 00:02:43,679
diagnose it well and then you find out

53
00:02:40,660 --> 00:02:48,069
the better way in which you can work

54
00:02:43,680 --> 00:02:50,379
that doesn't apply to digital in fact

55
00:02:48,069 --> 00:02:54,790
the word disruptive used to be a bad

56
00:02:50,379 --> 00:02:56,890
word and now everybody's competing to

57
00:02:54,790 --> 00:03:00,429
see who is more disruptive than the next

58
00:02:56,890 --> 00:03:01,690
guy you know you've been you've been

59
00:03:00,430 --> 00:03:03,340
there well that's interesting because I

60
00:03:01,690 --> 00:03:06,790
always advise people not to talk about

61
00:03:03,340 --> 00:03:08,560
disruption well but you you probably the

62
00:03:06,790 --> 00:03:10,569
exception because actually people are

63
00:03:08,560 --> 00:03:13,239
advertising they are so disruptive you

64
00:03:10,569 --> 00:03:16,828
know when it comes and and governments

65
00:03:13,239 --> 00:03:19,269
are totally totally by nature you know

66
00:03:16,829 --> 00:03:24,640
against disruption what they want is

67
00:03:19,269 --> 00:03:29,079
order predictability control etc so the

68
00:03:24,640 --> 00:03:31,480
question is how does one adapt what is

69
00:03:29,079 --> 00:03:35,220
the ultimate mandate of governments

70
00:03:31,480 --> 00:03:39,730
which is well-being and which is to use

71
00:03:35,220 --> 00:03:44,889
anything that comes up so that it adds

72
00:03:39,730 --> 00:03:51,160
to well-being welfare well the Wellness

73
00:03:44,889 --> 00:03:54,220
of society and also do no harm rule

74
00:03:51,160 --> 00:03:56,889
which means how do you avoid the bad

75
00:03:54,220 --> 00:04:00,700
part for example in digital we've

76
00:03:56,889 --> 00:04:03,480
calculated that the OECD 14% of the jobs

77
00:04:00,700 --> 00:04:06,970
are at stake of being basically

78
00:04:03,480 --> 00:04:09,940
displaced by technology but one third of

79
00:04:06,970 --> 00:04:13,930
the total jobs are in danger of being

80
00:04:09,940 --> 00:04:17,260
disrupted so about half of the total

81
00:04:13,930 --> 00:04:21,300
workforce is going to suffer the

82
00:04:17,260 --> 00:04:25,990
consequences of the advancing technology

83
00:04:21,300 --> 00:04:29,229
it's massive how do you take advantage

84
00:04:25,990 --> 00:04:34,500
of let's say the best features how do

85
00:04:29,229 --> 00:04:40,300
you avoid the bad part how do you help

86
00:04:34,500 --> 00:04:42,550
digital become a force for equality

87
00:04:40,300 --> 00:04:45,690
rather than inequality

88
00:04:42,550 --> 00:04:48,610
for gender parity rather than

89
00:04:45,690 --> 00:04:53,980
discriminate against gender how do you

90
00:04:48,610 --> 00:04:58,150
make the digital work in favor of higher

91
00:04:53,980 --> 00:05:01,420
productivity and more competition rather

92
00:04:58,150 --> 00:05:04,780
than winner-take-all type of logic when

93
00:05:01,420 --> 00:05:06,550
you are do not have a competition these

94
00:05:04,780 --> 00:05:08,109
are the kinds of things that regulators

95
00:05:06,550 --> 00:05:13,150
are thinking about the government's are

96
00:05:08,110 --> 00:05:18,610
thinking about and I fully accept the I

97
00:05:13,150 --> 00:05:21,640
would say guilty as charged that the

98
00:05:18,610 --> 00:05:23,560
government's are behind in a way they

99
00:05:21,640 --> 00:05:26,740
always are but in this particular case

100
00:05:23,560 --> 00:05:29,410
but don't underestimate the capacity of

101
00:05:26,740 --> 00:05:31,300
the government's if the government's

102
00:05:29,410 --> 00:05:33,970
actually perceived that there is a

103
00:05:31,300 --> 00:05:37,270
moment in which a particular technology

104
00:05:33,970 --> 00:05:39,490
a particular progress advance or

105
00:05:37,270 --> 00:05:42,010
whatever is innovation is actually

106
00:05:39,490 --> 00:05:44,920
affecting wide swaths of the population

107
00:05:42,010 --> 00:05:46,960
they will act and then what happens is

108
00:05:44,920 --> 00:05:50,920
that because they always act with a very

109
00:05:46,960 --> 00:05:54,870
heavy hand they will act perhaps

110
00:05:50,920 --> 00:05:58,210
somewhat you know brutally so the way

111
00:05:54,870 --> 00:06:00,460
not to have this happen is precisely

112
00:05:58,210 --> 00:06:02,859
rather than either ignore the

113
00:06:00,460 --> 00:06:05,260
regulator's or poke fun at the

114
00:06:02,860 --> 00:06:08,130
regulator's whatever I would say try to

115
00:06:05,260 --> 00:06:10,510
educate the regulator's in the end would

116
00:06:08,130 --> 00:06:12,969
listen to the regulator's in terms of

117
00:06:10,510 --> 00:06:15,520
what they would like to achieve and also

118
00:06:12,970 --> 00:06:18,640
listen to society at large members in

119
00:06:15,520 --> 00:06:21,219
the end the regulator's are going to be

120
00:06:18,640 --> 00:06:24,130
speaking on behalf of society on behalf

121
00:06:21,220 --> 00:06:28,030
what they what they understand is their

122
00:06:24,130 --> 00:06:30,550
job it is going to be about that so the

123
00:06:28,030 --> 00:06:32,349
promotion of the technology the

124
00:06:30,550 --> 00:06:35,440
information about the technology access

125
00:06:32,350 --> 00:06:38,710
to the technology so that it is not just

126
00:06:35,440 --> 00:06:42,190
the privilege of a few that can can

127
00:06:38,710 --> 00:06:45,940
benefit from this skills to deal with

128
00:06:42,190 --> 00:06:46,690
the technology preservation or

129
00:06:45,940 --> 00:06:51,190
competition

130
00:06:46,690 --> 00:06:55,330
the promotion of stem of you know the

131
00:06:51,190 --> 00:06:59,139
girls stem in particular all these are

132
00:06:55,330 --> 00:07:01,479
public policy issues and all can be

133
00:06:59,139 --> 00:07:06,520
better achieved with full cooperation

134
00:07:01,479 --> 00:07:09,039
and coordination with the industry

135
00:07:06,520 --> 00:07:12,609
itself well with the digital but also

136
00:07:09,039 --> 00:07:15,789
with all the companies that use the

137
00:07:12,610 --> 00:07:17,409
technology sure let's bring in John here

138
00:07:15,789 --> 00:07:20,438
from one of those industry voices so um

139
00:07:17,409 --> 00:07:22,120
how does MasterCard view this future you

140
00:07:20,439 --> 00:07:24,099
know what do you see is the biggest sort

141
00:07:22,120 --> 00:07:26,139
of social and economic consequences of

142
00:07:24,099 --> 00:07:29,409
that disruption and how how is master

143
00:07:26,139 --> 00:07:31,389
cog going about responding to those so

144
00:07:29,409 --> 00:07:33,490
one of the clearest benefits of the

145
00:07:31,389 --> 00:07:35,440
digital revolution in the payments

146
00:07:33,490 --> 00:07:38,259
industry has been the financial

147
00:07:35,440 --> 00:07:40,210
inclusion benefits because one of the

148
00:07:38,259 --> 00:07:42,909
loneliest places to be in the world is

149
00:07:40,210 --> 00:07:46,508
unbanked and trapped in a cash economy

150
00:07:42,909 --> 00:07:49,840
because you are at risk of all sorts of

151
00:07:46,509 --> 00:07:51,969
fraud and you are disconnected from the

152
00:07:49,840 --> 00:07:53,710
global economy so what we have seen

153
00:07:51,969 --> 00:07:57,939
around the world is that by digitizing

154
00:07:53,710 --> 00:08:00,669
payments your your mobile becomes both a

155
00:07:57,939 --> 00:08:03,069
payment device and for small merchants

156
00:08:00,669 --> 00:08:05,919
it becomes an acceptance device and

157
00:08:03,069 --> 00:08:11,139
being connecting both small merchants

158
00:08:05,919 --> 00:08:13,089
and unbanked citizens has created a huge

159
00:08:11,139 --> 00:08:15,190
opportunity to address Financial

160
00:08:13,089 --> 00:08:17,050
Inclusion so in terms of social benefits

161
00:08:15,190 --> 00:08:20,110
that's one of the clearest would you say

162
00:08:17,050 --> 00:08:21,099
that you are a technology optimist when

163
00:08:20,110 --> 00:08:23,740
you look at the future

164
00:08:21,099 --> 00:08:26,529
well we describe ourselves these days as

165
00:08:23,740 --> 00:08:28,060
a technology company so I wouldn't be

166
00:08:26,529 --> 00:08:30,129
working there if I weren't a technology

167
00:08:28,060 --> 00:08:32,769
optimists so I would say yes excellent

168
00:08:30,129 --> 00:08:33,760
well before asking and how about this

169
00:08:32,769 --> 00:08:36,219
question we were discussing this

170
00:08:33,760 --> 00:08:38,110
backstage before we started I understand

171
00:08:36,219 --> 00:08:41,349
master cause doing some interesting

172
00:08:38,110 --> 00:08:42,849
stuff in AI and obviously AI is the real

173
00:08:41,349 --> 00:08:44,589
hot-button topic at the conference

174
00:08:42,849 --> 00:08:47,170
everyone's talking about AI and the

175
00:08:44,589 --> 00:08:48,940
future consequences of that how is

176
00:08:47,170 --> 00:08:50,410
master car thinking about AI how big a

177
00:08:48,940 --> 00:08:52,720
piece is that going to be in that future

178
00:08:50,410 --> 00:08:55,480
strategy and let me say up front I'm not

179
00:08:52,720 --> 00:08:57,760
an AI expert but I do know that we've

180
00:08:55,480 --> 00:09:00,490
made some Act was just acquisitions in

181
00:08:57,760 --> 00:09:03,430
that space specifically to bring inside

182
00:09:00,490 --> 00:09:07,540
the company technology that we deployed

183
00:09:03,430 --> 00:09:09,250
to protect card users against fraud so

184
00:09:07,540 --> 00:09:11,709
you know there are a lot of uses for

185
00:09:09,250 --> 00:09:16,240
but we are using it to protect consumers

186
00:09:11,710 --> 00:09:18,580
right are you worried that AI and the

187
00:09:16,240 --> 00:09:20,740
next wave of emerging technologies is

188
00:09:18,580 --> 00:09:22,030
going to overwhelm the capacity of the

189
00:09:20,740 --> 00:09:24,280
existing institutions including the

190
00:09:22,030 --> 00:09:24,970
regulators to manage all of these

191
00:09:24,280 --> 00:09:29,800
challenges

192
00:09:24,970 --> 00:09:31,900
you can't take a position that it's

193
00:09:29,800 --> 00:09:35,079
gonna be overwhelming to deal with it

194
00:09:31,900 --> 00:09:36,910
you have to take a position that you

195
00:09:35,080 --> 00:09:37,390
have to understand what you're talking

196
00:09:36,910 --> 00:09:39,880
about

197
00:09:37,390 --> 00:09:43,180
AI itself you know like like every one

198
00:09:39,880 --> 00:09:45,070
of these issues it's a universe you know

199
00:09:43,180 --> 00:09:47,319
and then whether you're talking about

200
00:09:45,070 --> 00:09:49,900
payment systems or whether you're

201
00:09:47,320 --> 00:09:51,190
talking about creating life or whether

202
00:09:49,900 --> 00:09:55,150
you're talking about in and there's

203
00:09:51,190 --> 00:09:56,560
ethical issues and big red lines or will

204
00:09:55,150 --> 00:09:58,480
you talking about simply machines

205
00:09:56,560 --> 00:10:03,130
learning more about how to do things

206
00:09:58,480 --> 00:10:06,810
better among themselves so the question

207
00:10:03,130 --> 00:10:10,480
then again is governments have to be

208
00:10:06,810 --> 00:10:12,189
have to understand what is involved they

209
00:10:10,480 --> 00:10:13,960
have to understand the technology they

210
00:10:12,190 --> 00:10:17,890
have to understand the implications they

211
00:10:13,960 --> 00:10:21,040
have to understand the limits that is

212
00:10:17,890 --> 00:10:22,750
very important the limits how far can

213
00:10:21,040 --> 00:10:27,280
you go with the technology even if you

214
00:10:22,750 --> 00:10:29,589
could go further but where do what the

215
00:10:27,280 --> 00:10:31,900
society put the limits of what you can

216
00:10:29,589 --> 00:10:34,600
do with this kind of technology and then

217
00:10:31,900 --> 00:10:38,560
last but not least again how do you use

218
00:10:34,600 --> 00:10:42,250
it for the benefit how do you use it for

219
00:10:38,560 --> 00:10:45,520
to avoid the harm and how do you use it

220
00:10:42,250 --> 00:10:47,860
to leapfrog how do you use it for

221
00:10:45,520 --> 00:10:50,829
education how do you use it for health

222
00:10:47,860 --> 00:10:53,440
how do you use it to you know have

223
00:10:50,830 --> 00:10:56,140
children learn more and not only just

224
00:10:53,440 --> 00:10:58,600
you know by memory but also to do more

225
00:10:56,140 --> 00:11:02,949
about what it is that they can do with

226
00:10:58,600 --> 00:11:05,850
what they know and how in the emotional

227
00:11:02,950 --> 00:11:10,180
skills social skills all these things

228
00:11:05,850 --> 00:11:14,130
and and AI can help a lot digital in

229
00:11:10,180 --> 00:11:16,989
general technology in in in not just of

230
00:11:14,130 --> 00:11:19,209
cyber type but also in general

231
00:11:16,990 --> 00:11:22,140
technology advances in technology and

232
00:11:19,209 --> 00:11:24,660
then last but not least the ultimate

233
00:11:22,140 --> 00:11:29,210
edge which is sure could be AI so

234
00:11:24,660 --> 00:11:32,339
basically I would not take the view that

235
00:11:29,210 --> 00:11:34,830
this question is overwhelming or not

236
00:11:32,340 --> 00:11:38,370
overwhelming the question is how do you

237
00:11:34,830 --> 00:11:41,310
approach the challenge today governments

238
00:11:38,370 --> 00:11:44,520
have an enormous challenge some of them

239
00:11:41,310 --> 00:11:47,339
do not fully grasp the importance and

240
00:11:44,520 --> 00:11:50,790
the size and the implications some of

241
00:11:47,340 --> 00:11:52,800
them are already you know advancing

242
00:11:50,790 --> 00:11:53,969
advancing advancing and actually leading

243
00:11:52,800 --> 00:11:55,920
who do you think is doing the best job

244
00:11:53,970 --> 00:11:58,560
there who's at the front of that well

245
00:11:55,920 --> 00:12:02,370
it's almost it's almost a cliche to say

246
00:11:58,560 --> 00:12:04,890
that the Estonians you know are leading

247
00:12:02,370 --> 00:12:08,010
the charge I used to I used to remember

248
00:12:04,890 --> 00:12:10,740
that their president Elvis you know

249
00:12:08,010 --> 00:12:13,170
who's but the the ultimate plugged-in

250
00:12:10,740 --> 00:12:16,080
wired-in guy you know there's a but

251
00:12:13,170 --> 00:12:18,930
basically I would say that it's in the

252
00:12:16,080 --> 00:12:21,150
US where things are happening right

253
00:12:18,930 --> 00:12:22,979
there's more vibrancy with this more and

254
00:12:21,150 --> 00:12:25,680
with more things happening at same time

255
00:12:22,980 --> 00:12:28,770
and therefore there were then you know

256
00:12:25,680 --> 00:12:31,890
eventually things kind of become more

257
00:12:28,770 --> 00:12:33,689
widespread and and then they become well

258
00:12:31,890 --> 00:12:37,650
if not part of the norm but at least

259
00:12:33,690 --> 00:12:40,980
they're more there they leak down right

260
00:12:37,650 --> 00:12:44,430
yeah so I would say the United States

261
00:12:40,980 --> 00:12:46,920
there are places like Israel where all

262
00:12:44,430 --> 00:12:50,030
these things are happening there's that

263
00:12:46,920 --> 00:12:53,880
wherever you have a very large military

264
00:12:50,030 --> 00:12:56,670
complex you know product that's that

265
00:12:53,880 --> 00:13:00,270
that helps because of your base is

266
00:12:56,670 --> 00:13:02,310
bigger but I would say when you have all

267
00:13:00,270 --> 00:13:05,370
these research institutions and where

268
00:13:02,310 --> 00:13:08,219
you have the the idea of the startups

269
00:13:05,370 --> 00:13:11,070
the idea of the startups is so appealing

270
00:13:08,220 --> 00:13:13,710
and you have societies and that's very

271
00:13:11,070 --> 00:13:16,110
my own country Mexico but also in Europe

272
00:13:13,710 --> 00:13:17,910
when you fail once and you get this

273
00:13:16,110 --> 00:13:21,030
stigma for life

274
00:13:17,910 --> 00:13:23,400
I remember gene can tell in in Jerusalem

275
00:13:21,030 --> 00:13:25,829
that was telling me well basically if

276
00:13:23,400 --> 00:13:28,620
somebody has not failed twice we don't

277
00:13:25,830 --> 00:13:30,960
give him a capital in order to get his

278
00:13:28,620 --> 00:13:33,390
star going you know so the whole logic

279
00:13:30,960 --> 00:13:36,000
about and in the US I think this is very

280
00:13:33,390 --> 00:13:39,120
much alive and well so I would say yes

281
00:13:36,000 --> 00:13:41,430
is where it's really happening or where

282
00:13:39,120 --> 00:13:44,130
more things are happening Silicon Valley

283
00:13:41,430 --> 00:13:45,510
right know your nest there certainly you

284
00:13:44,130 --> 00:13:47,760
know can I quickly add to that I mean

285
00:13:45,510 --> 00:13:50,640
one area that hasn't been raised yet

286
00:13:47,760 --> 00:13:52,470
today is digital identity and we're

287
00:13:50,640 --> 00:13:54,510
rapidly at a point I think all of us can

288
00:13:52,470 --> 00:13:57,420
relate to not being able to memorize

289
00:13:54,510 --> 00:13:59,970
another password for your login for

290
00:13:57,420 --> 00:14:02,250
whatever app or service you want to use

291
00:13:59,970 --> 00:14:04,590
online and so there's a lot of interest

292
00:14:02,250 --> 00:14:06,390
right now across many industries looking

293
00:14:04,590 --> 00:14:09,840
at how to solve the digital identity

294
00:14:06,390 --> 00:14:11,460
problem it in order for the private

295
00:14:09,840 --> 00:14:13,170
sector to address that it really needs

296
00:14:11,460 --> 00:14:15,120
to be enabled by government and

297
00:14:13,170 --> 00:14:16,620
Australia from what we have seen

298
00:14:15,120 --> 00:14:18,690
Australia is the government at the

299
00:14:16,620 --> 00:14:21,840
forefront by creating a regulatory

300
00:14:18,690 --> 00:14:23,550
framework that allows the private sector

301
00:14:21,840 --> 00:14:26,100
to innovate for the benefit of consumers

302
00:14:23,550 --> 00:14:29,339
to create a digital identity that you

303
00:14:26,100 --> 00:14:32,940
can use online that's one easier but to

304
00:14:29,340 --> 00:14:34,470
better protected and in contrast you

305
00:14:32,940 --> 00:14:36,600
know the u.s. is actually very far

306
00:14:34,470 --> 00:14:39,300
behind the u.s. hasn't looked at how to

307
00:14:36,600 --> 00:14:40,950
address its own systems you know so that

308
00:14:39,300 --> 00:14:42,660
it could enable the private sector to

309
00:14:40,950 --> 00:14:44,130
innovate and provide these solutions

310
00:14:42,660 --> 00:14:44,520
interest I would say Europe is in the

311
00:14:44,130 --> 00:14:46,650
middle

312
00:14:44,520 --> 00:14:48,870
certainly Estonia but the countries

313
00:14:46,650 --> 00:14:51,270
we've looked at Poland Belgium the UK

314
00:14:48,870 --> 00:14:52,830
are also taking leadership positions on

315
00:14:51,270 --> 00:14:55,350
digital identity interesting so I would

316
00:14:52,830 --> 00:14:56,910
be remiss as a Silicon Valley guy not to

317
00:14:55,350 --> 00:15:01,080
ask a question here about blockchain

318
00:14:56,910 --> 00:15:02,370
technology since it is the other buzz to

319
00:15:01,080 --> 00:15:03,960
what extent you see blockchain is an

320
00:15:02,370 --> 00:15:05,520
important part of that we have big

321
00:15:03,960 --> 00:15:08,610
investments in blockchain we have a

322
00:15:05,520 --> 00:15:10,350
number of patents in that space we

323
00:15:08,610 --> 00:15:11,970
haven't yet deployed it but we're

324
00:15:10,350 --> 00:15:14,160
looking at various different use cases

325
00:15:11,970 --> 00:15:17,400
especially in the Faster Payments

326
00:15:14,160 --> 00:15:19,020
area so we see this as a key part of the

327
00:15:17,400 --> 00:15:22,500
digital future for payments right

328
00:15:19,020 --> 00:15:25,890
texture with blockchain the blockchain

329
00:15:22,500 --> 00:15:29,250
is not a policy blockchain is not a

330
00:15:25,890 --> 00:15:32,270
regulation blockchain is a tool the

331
00:15:29,250 --> 00:15:35,880
question is you have to make the tool

332
00:15:32,270 --> 00:15:38,850
part of the regulation so that you can

333
00:15:35,880 --> 00:15:41,070
then do the policy and that can only be

334
00:15:38,850 --> 00:15:43,530
done by government so no matter how much

335
00:15:41,070 --> 00:15:44,550
you absolutely which has been a big

336
00:15:43,530 --> 00:15:47,010
problem with blocks yeah a lot of

337
00:15:44,550 --> 00:15:50,109
utopian thinking this is the problem the

338
00:15:47,010 --> 00:15:52,930
other day I was you know we had a deal

339
00:15:50,110 --> 00:15:55,450
the two or three full days of blockchain

340
00:15:52,930 --> 00:15:59,680
you know we were lucky enough to hear

341
00:15:55,450 --> 00:16:03,730
his and and everybody was and there were

342
00:15:59,680 --> 00:16:06,399
people who carriers people who handled

343
00:16:03,730 --> 00:16:09,250
ports people who hand her a hundred

344
00:16:06,399 --> 00:16:14,320
million banking accounts all of them

345
00:16:09,250 --> 00:16:16,870
said it's fantastic it works but if I

346
00:16:14,320 --> 00:16:19,779
don't convince Vincent said the banker

347
00:16:16,870 --> 00:16:21,850
enough I don't convince the port

348
00:16:19,779 --> 00:16:24,279
authorities and if I don't convince the

349
00:16:21,850 --> 00:16:26,140
notary publics to give up the stamping

350
00:16:24,279 --> 00:16:27,670
of the thing and the green copy and the

351
00:16:26,140 --> 00:16:30,579
blue copy and the yellow copy and the

352
00:16:27,670 --> 00:16:32,800
pink copy in order to deliver the bills

353
00:16:30,579 --> 00:16:35,410
of lading and things like that then I

354
00:16:32,800 --> 00:16:37,569
will have to do everything twice so

355
00:16:35,410 --> 00:16:40,329
instead of saving money I will be

356
00:16:37,570 --> 00:16:43,329
actually adding to the cost so I'm doing

357
00:16:40,329 --> 00:16:46,569
it to prove that it works but if it does

358
00:16:43,329 --> 00:16:48,459
not become a regulation then it will not

359
00:16:46,570 --> 00:16:49,750
work and that is the part of the

360
00:16:48,459 --> 00:16:51,699
government that's where the government's

361
00:16:49,750 --> 00:16:53,380
have to catch up with the technology and

362
00:16:51,700 --> 00:16:55,000
of course they will be fought by the

363
00:16:53,380 --> 00:16:56,949
lawyers they will be fought by the

364
00:16:55,000 --> 00:16:59,170
notary publics they will be fought but

365
00:16:56,949 --> 00:17:01,719
you know but all the powers that be but

366
00:16:59,170 --> 00:17:04,149
it's that's that's where it's that's

367
00:17:01,720 --> 00:17:06,400
where we're going and holding back on

368
00:17:04,150 --> 00:17:08,650
that will only delay you know and the

369
00:17:06,400 --> 00:17:10,419
ones who are moving faster are gonna be

370
00:17:08,650 --> 00:17:13,959
the ones who get the advantage right

371
00:17:10,419 --> 00:17:16,589
absolutely um one question is around how

372
00:17:13,959 --> 00:17:19,630
the OECD itself is using technology

373
00:17:16,589 --> 00:17:21,490
internally so I used to be at the UN

374
00:17:19,630 --> 00:17:22,839
before I went to Silicon Valley and we

375
00:17:21,490 --> 00:17:24,339
used to go to a lot of conferences where

376
00:17:22,839 --> 00:17:27,040
people would talk about innovation and

377
00:17:24,339 --> 00:17:29,379
technology and I would always think I'm

378
00:17:27,040 --> 00:17:31,870
back in the office struggling to use

379
00:17:29,380 --> 00:17:34,720
Lotus Notes to do my email this ancient

380
00:17:31,870 --> 00:17:36,189
tool that uh had been bought by the UN I

381
00:17:34,720 --> 00:17:38,799
was on this decade-long

382
00:17:36,190 --> 00:17:40,510
deal which seemed absolutely ridiculous

383
00:17:38,799 --> 00:17:42,730
I got a pop up every few minutes saying

384
00:17:40,510 --> 00:17:44,470
would you like to upgrade to Firefox as

385
00:17:42,730 --> 00:17:46,870
a browser which had not been invented

386
00:17:44,470 --> 00:17:50,110
when this thing was launched um how is

387
00:17:46,870 --> 00:17:52,389
the OECD internally using technology to

388
00:17:50,110 --> 00:17:54,129
modernize and to innovate and really

389
00:17:52,390 --> 00:17:56,799
keep pace with all the things that are

390
00:17:54,130 --> 00:18:02,090
happening in the world I think if we

391
00:17:56,799 --> 00:18:06,230
could walk the walk

392
00:18:02,090 --> 00:18:11,600
rather than talk to hock we are I think

393
00:18:06,230 --> 00:18:13,520
we're better at proposing you know our

394
00:18:11,600 --> 00:18:17,149
motto is better policies for better

395
00:18:13,520 --> 00:18:19,670
lives no and we are much better at

396
00:18:17,150 --> 00:18:21,410
proposing to our country's member

397
00:18:19,670 --> 00:18:23,870
countries and other countries that come

398
00:18:21,410 --> 00:18:25,460
to us what can I do about this and now

399
00:18:23,870 --> 00:18:29,020
that we're better than than what we do

400
00:18:25,460 --> 00:18:31,970
or do I think the world of technology is

401
00:18:29,020 --> 00:18:34,610
particularly in the sense that that is

402
00:18:31,970 --> 00:18:38,290
where the gaps are greater and I would

403
00:18:34,610 --> 00:18:40,120
say that we are perhaps like the UN

404
00:18:38,290 --> 00:18:43,820
[Laughter]

405
00:18:40,120 --> 00:18:45,199
nothing is like nothing is like do you

406
00:18:43,820 --> 00:18:47,300
and in many ways good and bad and

407
00:18:45,200 --> 00:18:49,910
everything but but I would say that

408
00:18:47,300 --> 00:18:52,879
because we are a smaller outfit and we

409
00:18:49,910 --> 00:18:54,920
can shape up you know faster and we are

410
00:18:52,880 --> 00:18:56,180
got a lot of people who are working on

411
00:18:54,920 --> 00:18:58,040
these issues you know we're trying to

412
00:18:56,180 --> 00:19:00,410
see how we apply blockchain to ourselves

413
00:18:58,040 --> 00:19:06,110
and we are applied with it but I would

414
00:19:00,410 --> 00:19:07,850
say that we would be yes a certain

415
00:19:06,110 --> 00:19:09,860
distance behind their own

416
00:19:07,850 --> 00:19:11,959
recommendations let's say right of

417
00:19:09,860 --> 00:19:13,969
whether we practice that internally very

418
00:19:11,960 --> 00:19:14,990
interesting so I'd love to open this up

419
00:19:13,970 --> 00:19:16,970
to questions I'm sure there'll be lots

420
00:19:14,990 --> 00:19:17,210
of questions here so I'll take two at a

421
00:19:16,970 --> 00:19:25,160
time

422
00:19:17,210 --> 00:19:26,840
the lady here No thank you very much my

423
00:19:25,160 --> 00:19:28,370
name is Isaac of Raqqa I'm the director

424
00:19:26,840 --> 00:19:30,500
of the European citizen action service

425
00:19:28,370 --> 00:19:32,510
we are European Association

426
00:19:30,500 --> 00:19:34,100
not-for-profit so I'm not from the

427
00:19:32,510 --> 00:19:36,740
government and I'm not from the business

428
00:19:34,100 --> 00:19:38,629
so therefore my question to the speakers

429
00:19:36,740 --> 00:19:41,750
is can you elaborate elaborate a bit

430
00:19:38,630 --> 00:19:44,990
more on your perspective of how you see

431
00:19:41,750 --> 00:19:48,740
the digital transformation effect on our

432
00:19:44,990 --> 00:19:50,240
democracies well now that yes we know

433
00:19:48,740 --> 00:19:52,040
that citizens are informing themselves

434
00:19:50,240 --> 00:19:54,170
in a different way that they're not very

435
00:19:52,040 --> 00:19:55,970
interested in politics as traditionally

436
00:19:54,170 --> 00:19:58,160
practiced and at the same time

437
00:19:55,970 --> 00:20:01,160
apparently technology provides new forms

438
00:19:58,160 --> 00:20:05,020
and possibilities thank you excellent

439
00:20:01,160 --> 00:20:09,500
and this transmen here Marc Fisher G+

440
00:20:05,020 --> 00:20:11,540
Europe the examples that get quoted for

441
00:20:09,500 --> 00:20:14,420
being the most advanced countries and

442
00:20:11,540 --> 00:20:16,039
when it comes to digital Estonia Israel

443
00:20:14,420 --> 00:20:17,359
yes the US but also

444
00:20:16,039 --> 00:20:18,408
part of the years I've lived in the u.s.

445
00:20:17,359 --> 00:20:21,350
they're parts of the US that are

446
00:20:18,409 --> 00:20:22,759
amazingly 21st or 22nd century and there

447
00:20:21,350 --> 00:20:25,178
are paths that are rather charming the

448
00:20:22,759 --> 00:20:27,379
18th century

449
00:20:25,179 --> 00:20:30,739
obviously technologically there is a

450
00:20:27,379 --> 00:20:34,189
systemic problem in reforming large

451
00:20:30,739 --> 00:20:36,289
countries just because of the cost of

452
00:20:34,190 --> 00:20:37,609
investment and also actually coming from

453
00:20:36,289 --> 00:20:39,169
Germany as you probably hear from my

454
00:20:37,609 --> 00:20:42,109
accent it's also actually there's a

455
00:20:39,169 --> 00:20:44,869
barrier in in in fully embracing the

456
00:20:42,109 --> 00:20:46,519
digital revolution in countries that

457
00:20:44,869 --> 00:20:49,728
already have the most modern

458
00:20:46,519 --> 00:20:51,919
infrastructure of the last pre-digital

459
00:20:49,729 --> 00:20:53,299
age because of course that's a lot of

460
00:20:51,919 --> 00:20:54,679
investment that basically becomes

461
00:20:53,299 --> 00:20:58,158
useless and you don't want to let it go

462
00:20:54,679 --> 00:21:00,830
is there a real debate about this and

463
00:20:58,159 --> 00:21:02,059
how do how do these countries deal with

464
00:21:00,830 --> 00:21:03,799
us and how do they then get the

465
00:21:02,059 --> 00:21:05,809
political to really do to make the

466
00:21:03,799 --> 00:21:07,340
investments because obviously Europe

467
00:21:05,809 --> 00:21:09,559
will not succeed if it's just Estonia

468
00:21:07,340 --> 00:21:15,019
Estonia is 2 million inhabitants awesome

469
00:21:09,559 --> 00:21:17,509
as they are sure Czech Republic took

470
00:21:15,019 --> 00:21:20,269
nine months to form a government

471
00:21:17,509 --> 00:21:21,139
Margaret they took only seven months to

472
00:21:20,269 --> 00:21:23,539
form a government

473
00:21:21,139 --> 00:21:28,129
Angela Merkel took five months to form a

474
00:21:23,539 --> 00:21:31,210
government the unexpected results of the

475
00:21:28,129 --> 00:21:33,939
Italian election the unexpected

476
00:21:31,210 --> 00:21:38,379
fragmentation and the very dramatic

477
00:21:33,940 --> 00:21:41,929
transformation of the Spanish political

478
00:21:38,379 --> 00:21:46,969
situation Austria you know

479
00:21:41,929 --> 00:21:51,169
and more recently Sweden the very

480
00:21:46,970 --> 00:21:55,580
dramatic expression and not only in

481
00:21:51,169 --> 00:21:56,479
Europe United States breaks it of course

482
00:21:55,580 --> 00:22:00,889
of course

483
00:21:56,479 --> 00:22:05,840
and then Mexico just results

484
00:22:00,889 --> 00:22:08,539
we're all waiting for Brazil especially

485
00:22:05,840 --> 00:22:10,549
for the second round what does it tell

486
00:22:08,539 --> 00:22:13,190
you there's so many angry people

487
00:22:10,549 --> 00:22:15,139
practically everywhere all they are

488
00:22:13,190 --> 00:22:17,529
voting for is change and even worse

489
00:22:15,139 --> 00:22:21,019
sometimes they're not even voting if a

490
00:22:17,529 --> 00:22:23,059
fraction of the 60% of the youth whose

491
00:22:21,019 --> 00:22:25,549
future was at stake in the case of

492
00:22:23,059 --> 00:22:27,230
brexit had actually voted they would

493
00:22:25,549 --> 00:22:29,239
have turned the thing around and we

494
00:22:27,230 --> 00:22:32,059
wouldn't be having these paints today

495
00:22:29,239 --> 00:22:35,119
you know and I say this because I fought

496
00:22:32,059 --> 00:22:38,090
very hard for a remain and you know we

497
00:22:35,119 --> 00:22:40,970
lost but then what happened of course it

498
00:22:38,090 --> 00:22:42,889
did the campaign for four remain was

499
00:22:40,970 --> 00:22:45,440
like they were trying to elect a prom

500
00:22:42,889 --> 00:22:47,359
queen rather than you know like playing

501
00:22:45,440 --> 00:22:50,419
the future of the UK it was very

502
00:22:47,359 --> 00:22:53,799
amateurish still what am I saying this

503
00:22:50,419 --> 00:22:57,340
because there obviously is a question of

504
00:22:53,799 --> 00:23:00,889
delivery of services of quality of

505
00:22:57,340 --> 00:23:06,039
opportunities of health services yes but

506
00:23:00,889 --> 00:23:09,619
also of Education but jobs jobs jobs the

507
00:23:06,039 --> 00:23:12,919
the differences the inequalities are

508
00:23:09,619 --> 00:23:15,320
growing rather than shrinking you know

509
00:23:12,919 --> 00:23:17,299
so what you have is a situation where

510
00:23:15,320 --> 00:23:18,649
you have a lot of people who are very

511
00:23:17,299 --> 00:23:21,710
angry a lot of people are very

512
00:23:18,649 --> 00:23:24,469
dissatisfied and Digital has the

513
00:23:21,710 --> 00:23:27,980
potential to help you bring it together

514
00:23:24,470 --> 00:23:32,019
or has a potential like this has

515
00:23:27,980 --> 00:23:34,879
happened already in many places in many

516
00:23:32,019 --> 00:23:37,669
instances where they widen the

517
00:23:34,879 --> 00:23:39,678
differences because the access is biased

518
00:23:37,669 --> 00:23:41,809
for those that are already have the

519
00:23:39,679 --> 00:23:43,129
access and therefore it's gonna just get

520
00:23:41,809 --> 00:23:45,980
bigger and bigger and bigger and bigger

521
00:23:43,129 --> 00:23:50,029
so the question of challenging the

522
00:23:45,980 --> 00:23:52,489
democracies is yes but again don't put

523
00:23:50,029 --> 00:23:54,889
digital and democracy it's how digital

524
00:23:52,489 --> 00:23:58,339
can help us with public policies that

525
00:23:54,889 --> 00:23:59,988
are more effective so that they do not

526
00:23:58,339 --> 00:24:01,908
challenge the democracy and we do not

527
00:23:59,989 --> 00:24:03,980
have that completely disparage the

528
00:24:01,909 --> 00:24:06,559
results with elections that we're having

529
00:24:03,980 --> 00:24:08,749
today where the whole of our values are

530
00:24:06,559 --> 00:24:10,879
at stake and everything that we believe

531
00:24:08,749 --> 00:24:14,720
in everything we built over the last 100

532
00:24:10,879 --> 00:24:17,178
years is being cast doubts on sure and

533
00:24:14,720 --> 00:24:19,159
we're like General John actually I'm a

534
00:24:17,179 --> 00:24:21,409
bit take on the second question maybe

535
00:24:19,159 --> 00:24:23,299
the first question to you know what do

536
00:24:21,409 --> 00:24:26,450
yeah I'll address the first one and the

537
00:24:23,299 --> 00:24:28,249
second one quick just very practically

538
00:24:26,450 --> 00:24:30,220
speaking I mean I talked about Financial

539
00:24:28,249 --> 00:24:33,289
Inclusion earlier but I also think

540
00:24:30,220 --> 00:24:36,320
digital payments which is the area I

541
00:24:33,289 --> 00:24:38,269
know best if you look at how governments

542
00:24:36,320 --> 00:24:40,369
can deploy digital payments to improve

543
00:24:38,269 --> 00:24:41,210
the experience of citizens dealing with

544
00:24:40,369 --> 00:24:42,500
their government

545
00:24:41,210 --> 00:24:44,059
whether it's making a payment to

546
00:24:42,500 --> 00:24:45,799
government or in some parts of the world

547
00:24:44,059 --> 00:24:49,100
receiving a benefit from government

548
00:24:45,799 --> 00:24:51,770
making that more efficient more

549
00:24:49,100 --> 00:24:54,428
standardized and more protected against

550
00:24:51,770 --> 00:24:57,100
fraud and abuse is is a definite benefit

551
00:24:54,429 --> 00:24:59,740
also to the extent that payments are

552
00:24:57,100 --> 00:25:02,689
digitized the more that that is

553
00:24:59,740 --> 00:25:05,600
increasing you'll see a decrease in the

554
00:25:02,690 --> 00:25:07,820
so-called gray economy which will be an

555
00:25:05,600 --> 00:25:09,830
automatic benefit in terms of moving

556
00:25:07,820 --> 00:25:12,439
front of fraud and crime out of the

557
00:25:09,830 --> 00:25:14,689
system but also generating more tax

558
00:25:12,440 --> 00:25:18,049
revenue and the third area where we've

559
00:25:14,690 --> 00:25:21,080
seen it is in the area with refugees

560
00:25:18,049 --> 00:25:24,470
we've done a lot of support in the

561
00:25:21,080 --> 00:25:27,139
refugee space to provide cards so that

562
00:25:24,470 --> 00:25:29,029
benefits for refugees are digitized

563
00:25:27,140 --> 00:25:32,049
and what we are finding is that by

564
00:25:29,029 --> 00:25:35,360
simply enabling that way of making a

565
00:25:32,049 --> 00:25:36,918
transaction we have ensured that the

566
00:25:35,360 --> 00:25:40,010
benefit is actually getting to the

567
00:25:36,919 --> 00:25:41,720
people who need it in and in many cases

568
00:25:40,010 --> 00:25:43,850
it's the the woman of the household

569
00:25:41,720 --> 00:25:45,559
putting her in charge of that card to

570
00:25:43,850 --> 00:25:48,350
make sure that the funds are not misused

571
00:25:45,559 --> 00:25:51,350
for some other purpose but also just

572
00:25:48,350 --> 00:25:53,389
being able to track that the the funds

573
00:25:51,350 --> 00:25:54,980
that are provided by multinational

574
00:25:53,390 --> 00:25:56,870
institutions are actually being used for

575
00:25:54,980 --> 00:25:58,159
the purposes that they were intended so

576
00:25:56,870 --> 00:26:01,189
I think there's great benefits for

577
00:25:58,159 --> 00:26:03,080
society and democracy through the

578
00:26:01,190 --> 00:26:04,700
digital revolution on the second

579
00:26:03,080 --> 00:26:06,439
question it's interesting I hadn't

580
00:26:04,700 --> 00:26:09,020
thought about it in terms of the size of

581
00:26:06,440 --> 00:26:11,419
the country and I'm not sure that I

582
00:26:09,020 --> 00:26:13,549
think that matters but I do think your

583
00:26:11,419 --> 00:26:15,470
second point is very valid about where

584
00:26:13,549 --> 00:26:17,990
countries are on their sort of

585
00:26:15,470 --> 00:26:19,850
innovation journey and I think of China

586
00:26:17,990 --> 00:26:23,179
in particular I lived in China for five

587
00:26:19,850 --> 00:26:25,639
years and left in 2013 and when I left I

588
00:26:23,179 --> 00:26:28,490
wasn't aware of anyone making a payment

589
00:26:25,640 --> 00:26:30,380
on their mobile phone and now it

590
00:26:28,490 --> 00:26:32,270
dominates the market I mean it's a

591
00:26:30,380 --> 00:26:34,610
trillion dollar market with companies I

592
00:26:32,270 --> 00:26:38,000
had never heard of before and this is

593
00:26:34,610 --> 00:26:40,418
just in a five-year span of time whereas

594
00:26:38,000 --> 00:26:42,890
in the US you'll find very few people

595
00:26:40,419 --> 00:26:44,779
maybe the Millennials or whatever

596
00:26:42,890 --> 00:26:46,309
generation is before them are doing

597
00:26:44,779 --> 00:26:48,169
payments on their mobile phone but

598
00:26:46,309 --> 00:26:51,649
certainly my friends are not doing it

599
00:26:48,169 --> 00:26:54,350
very often in the case of our German

600
00:26:51,649 --> 00:26:56,449
friend in the case of a country being

601
00:26:54,350 --> 00:26:59,449
very

602
00:26:56,450 --> 00:27:01,519
do not underestimate first of all the

603
00:26:59,450 --> 00:27:05,389
capacity of the private sector simply

604
00:27:01,519 --> 00:27:08,029
out of competitive pressures to catch up

605
00:27:05,389 --> 00:27:09,769
the catch up now when you are in the

606
00:27:08,029 --> 00:27:11,840
business of payments of course you have

607
00:27:09,769 --> 00:27:13,610
to be kind of the cutting edge because

608
00:27:11,840 --> 00:27:16,459
then the other guy will eat your cheese

609
00:27:13,610 --> 00:27:19,340
you know the but even you know even just

610
00:27:16,460 --> 00:27:21,769
any any activity that you may be on

611
00:27:19,340 --> 00:27:25,668
because they're all susceptible even the

612
00:27:21,769 --> 00:27:28,990
more of section sector one agriculture

613
00:27:25,669 --> 00:27:31,639
now everything can be you can use

614
00:27:28,990 --> 00:27:36,529
digital or you can use the technology to

615
00:27:31,639 --> 00:27:38,779
apply to every sector and as the US

616
00:27:36,529 --> 00:27:40,669
Germany for example is a very good

617
00:27:38,779 --> 00:27:45,799
example so when you have very strong

618
00:27:40,669 --> 00:27:47,510
competitive forces and when basically I

619
00:27:45,799 --> 00:27:49,399
would say you have intelligent

620
00:27:47,510 --> 00:27:52,730
regulators that understand the challenge

621
00:27:49,399 --> 00:27:55,580
and basically have an idea that they

622
00:27:52,730 --> 00:27:58,429
will regulate for the for the benefit of

623
00:27:55,580 --> 00:28:01,928
the public but they will not stifle

624
00:27:58,429 --> 00:28:05,480
innovation this is the very critical

625
00:28:01,929 --> 00:28:07,429
balance that you have to establish but I

626
00:28:05,480 --> 00:28:09,649
would I would join John and saying

627
00:28:07,429 --> 00:28:11,389
perhaps the size because the United

628
00:28:09,649 --> 00:28:13,178
States is is a bunch of countries you

629
00:28:11,389 --> 00:28:17,629
know there's a bunch of areas that

630
00:28:13,179 --> 00:28:19,940
Saints in every city you know is like a

631
00:28:17,630 --> 00:28:21,679
different country and the mayors have

632
00:28:19,940 --> 00:28:23,510
capacities and the governors have

633
00:28:21,679 --> 00:28:25,880
capacities but then the national

634
00:28:23,510 --> 00:28:28,010
regulators have capacities the public

635
00:28:25,880 --> 00:28:30,830
has a capacity the people the companies

636
00:28:28,010 --> 00:28:34,519
are dramatic innovators they're pushing

637
00:28:30,830 --> 00:28:37,070
the thing through so I I would I would

638
00:28:34,519 --> 00:28:39,710
say that the the more vibrant the more

639
00:28:37,070 --> 00:28:41,899
modern and then of course you as you

640
00:28:39,710 --> 00:28:45,679
said you have eighteenth century things

641
00:28:41,899 --> 00:28:48,518
and happening in but 22nd century things

642
00:28:45,679 --> 00:28:51,110
out but it will tend to to move ahead

643
00:28:48,519 --> 00:28:53,090
smaller countries yes you're right you

644
00:28:51,110 --> 00:28:55,699
know Estonia is not it's fantastic but

645
00:28:53,090 --> 00:28:58,070
it's not necessarily representing what's

646
00:28:55,700 --> 00:29:00,260
gonna happen with Europe or with the

647
00:28:58,070 --> 00:29:04,340
rest of the world but it's interesting

648
00:29:00,260 --> 00:29:06,840
that you can have a community that can

649
00:29:04,340 --> 00:29:09,389
actually have that

650
00:29:06,840 --> 00:29:18,389
have that happen sure let's open up to

651
00:29:09,390 --> 00:29:20,100
more questions yeah however it's a point

652
00:29:18,390 --> 00:29:23,330
that angle brought up but I guess it's a

653
00:29:20,100 --> 00:29:25,949
question to to all three of you actually

654
00:29:23,330 --> 00:29:27,990
you you talked about the need for

655
00:29:25,950 --> 00:29:30,200
regulators to engage with society and

656
00:29:27,990 --> 00:29:33,270
society to engage with with regulators

657
00:29:30,200 --> 00:29:35,880
how do you think you can ensure that you

658
00:29:33,270 --> 00:29:37,860
get a pleurisy I guess that's a word it

659
00:29:35,880 --> 00:29:40,440
sounds like a word a pleurisy of voices

660
00:29:37,860 --> 00:29:43,139
from society and not just a narrow set

661
00:29:40,440 --> 00:29:45,570
of of interest represented towards you

662
00:29:43,140 --> 00:29:46,980
know a single regulator it is not a part

663
00:29:45,570 --> 00:29:48,330
of people's general anger that we're

664
00:29:46,980 --> 00:29:50,040
seeing across the world at the moment

665
00:29:48,330 --> 00:29:51,510
because they feel and represented and

666
00:29:50,040 --> 00:29:54,659
because they feel that their voices is

667
00:29:51,510 --> 00:29:55,560
not heard let's take let's take one more

668
00:29:54,660 --> 00:30:01,320
question

669
00:29:55,560 --> 00:30:04,379
this gents are in the center here thank

670
00:30:01,320 --> 00:30:06,120
you my name is Zvi roche i am the CEO

671
00:30:04,380 --> 00:30:09,030
and founder of a start-up from israel

672
00:30:06,120 --> 00:30:10,830
and we're in the FinTech in travel tech

673
00:30:09,030 --> 00:30:15,240
area i'd love to talk about it but I

674
00:30:10,830 --> 00:30:18,149
won't like just one one sentence we are

675
00:30:15,240 --> 00:30:20,820
completely disrupting v80 refunds for

676
00:30:18,150 --> 00:30:22,740
tourists through digitization and we

677
00:30:20,820 --> 00:30:24,929
deal with that in first world countries

678
00:30:22,740 --> 00:30:27,630
but also in second and third world

679
00:30:24,930 --> 00:30:30,360
countries and the question is what do

680
00:30:27,630 --> 00:30:33,930
you guys see with digitization creating

681
00:30:30,360 --> 00:30:37,139
a bigger gap or or diminishing the gap

682
00:30:33,930 --> 00:30:38,940
between first world countries OECD

683
00:30:37,140 --> 00:30:41,730
countries and third world countries and

684
00:30:38,940 --> 00:30:43,710
what is the OECD doing to diminish the

685
00:30:41,730 --> 00:30:47,550
gap here interesting let's start with

686
00:30:43,710 --> 00:30:52,140
John so on on the first question about

687
00:30:47,550 --> 00:30:53,700
plurality of voices I think that's a key

688
00:30:52,140 --> 00:30:55,890
issue and we face it all the time

689
00:30:53,700 --> 00:30:59,760
because in the space that we operate

690
00:30:55,890 --> 00:31:04,530
that's regulated what you find are sort

691
00:30:59,760 --> 00:31:07,500
of two big sort of commercial sides of

692
00:31:04,530 --> 00:31:10,230
the debate being the focus of government

693
00:31:07,500 --> 00:31:12,690
attention and and and those industries

694
00:31:10,230 --> 00:31:15,360
being very active in their advocacy

695
00:31:12,690 --> 00:31:18,660
efforts but what is often lost in that

696
00:31:15,360 --> 00:31:20,219
debate is the voice of the consumer and

697
00:31:18,660 --> 00:31:21,029
you know how to get the voice of the

698
00:31:20,220 --> 00:31:23,519
consumer

699
00:31:21,029 --> 00:31:24,960
louder in those discussions I think is a

700
00:31:23,519 --> 00:31:27,929
key challenge that we struggle with

701
00:31:24,960 --> 00:31:33,419
around the world on the second question

702
00:31:27,929 --> 00:31:36,120
about disruption and various of

703
00:31:33,419 --> 00:31:38,519
countries at different places in their

704
00:31:36,120 --> 00:31:40,139
economic development I think it's I

705
00:31:38,519 --> 00:31:42,090
don't think it's a big challenge for the

706
00:31:40,140 --> 00:31:44,720
so called first in second world

707
00:31:42,090 --> 00:31:47,010
countries I just came back from India

708
00:31:44,720 --> 00:31:48,870
and the amount of innovation that's

709
00:31:47,010 --> 00:31:50,580
happening there is incredible

710
00:31:48,870 --> 00:31:52,799
and the u.s. is Silicon Valley so I

711
00:31:50,580 --> 00:31:54,629
don't think you know the first world

712
00:31:52,799 --> 00:31:57,720
needs to worry but I am very much

713
00:31:54,630 --> 00:32:00,450
worried about the third world and we are

714
00:31:57,720 --> 00:32:03,059
doing a lot of work in Africa in Kenya

715
00:32:00,450 --> 00:32:06,360
in particular again working with small

716
00:32:03,059 --> 00:32:09,240
merchants who who are disconnected from

717
00:32:06,360 --> 00:32:12,928
banks and therefore you know don't have

718
00:32:09,240 --> 00:32:15,809
a stable supply chain and and and don't

719
00:32:12,929 --> 00:32:18,659
have a credit history that would even

720
00:32:15,809 --> 00:32:20,870
allow them to have the sort of inventory

721
00:32:18,659 --> 00:32:22,799
that they would need to be as

722
00:32:20,870 --> 00:32:25,559
financially successful as they would

723
00:32:22,799 --> 00:32:27,090
like to be and I think I do think our

724
00:32:25,559 --> 00:32:28,350
efforts are being helpful in there a

725
00:32:27,090 --> 00:32:30,750
certain and we have other partners in

726
00:32:28,350 --> 00:32:32,760
that space but I'm not sure that that

727
00:32:30,750 --> 00:32:37,139
you know in and of itself is going to be

728
00:32:32,760 --> 00:32:40,789
sufficient to address the need great I I

729
00:32:37,139 --> 00:32:43,949
think you you made a very good point

730
00:32:40,789 --> 00:32:47,490
regulators have the obligation to listen

731
00:32:43,950 --> 00:32:51,570
to all the voices the greatest danger

732
00:32:47,490 --> 00:32:52,320
that we have is capture and that's when

733
00:32:51,570 --> 00:32:54,330
the regulator's

734
00:32:52,320 --> 00:32:56,070
and they can also be the regulator's

735
00:32:54,330 --> 00:33:00,570
world so it could be Congress it can be

736
00:32:56,070 --> 00:33:02,908
the chief the executives of AG of a

737
00:33:00,570 --> 00:33:04,980
government are captured either because

738
00:33:02,909 --> 00:33:06,510
of their commitments with the financing

739
00:33:04,980 --> 00:33:09,210
of campaigns or political parties or

740
00:33:06,510 --> 00:33:12,840
whatever or out of ideology or ignorant

741
00:33:09,210 --> 00:33:15,120
and the three sometimes can happen

742
00:33:12,840 --> 00:33:18,740
sometimes all of the above and the

743
00:33:15,120 --> 00:33:21,510
question as you say the the regulator

744
00:33:18,740 --> 00:33:24,480
basically has the obligation to put the

745
00:33:21,510 --> 00:33:27,600
voice of the people in front of the

746
00:33:24,480 --> 00:33:29,520
industry in saying this is what is what

747
00:33:27,600 --> 00:33:32,039
they're asking for therefore let's give

748
00:33:29,520 --> 00:33:34,470
it to them and talk to the industry so

749
00:33:32,039 --> 00:33:36,419
that you can guarantee but it's

750
00:33:34,470 --> 00:33:40,440
it's the ultimate test I would say it's

751
00:33:36,419 --> 00:33:42,660
the acid test and and then putting the

752
00:33:40,440 --> 00:33:44,520
two together bringing developed

753
00:33:42,660 --> 00:33:47,730
developing countries together I think

754
00:33:44,520 --> 00:33:49,490
your your your example is very very

755
00:33:47,730 --> 00:33:53,549
clear

756
00:33:49,490 --> 00:33:57,230
India has just used the technology for

757
00:33:53,549 --> 00:34:00,480
1.1 billion people who had absolutely

758
00:33:57,230 --> 00:34:02,490
most of them no identity even if you had

759
00:34:00,480 --> 00:34:04,500
checks for them you couldn't deliver it

760
00:34:02,490 --> 00:34:07,080
to them because you did not know what

761
00:34:04,500 --> 00:34:11,580
what their name was and what their if if

762
00:34:07,080 --> 00:34:13,469
they had a you know an address and now

763
00:34:11,580 --> 00:34:15,830
they can get the benefits you know

764
00:34:13,469 --> 00:34:18,719
because of the program that they

765
00:34:15,830 --> 00:34:21,600
established so it is not not just for

766
00:34:18,719 --> 00:34:23,149
payments but for everything to have an

767
00:34:21,600 --> 00:34:27,600
identity as you said in the beginning

768
00:34:23,149 --> 00:34:30,690
just to exist to have a name never

769
00:34:27,600 --> 00:34:33,739
places society to have some dignity so

770
00:34:30,690 --> 00:34:36,750
this is some of the things that the

771
00:34:33,739 --> 00:34:38,790
technology provides yes I'm guessing a

772
00:34:36,750 --> 00:34:40,918
high rates person in my ear telling me

773
00:34:38,790 --> 00:34:42,389
we're out of time but I want to say one

774
00:34:40,918 --> 00:34:45,600
last question if someone can keep it

775
00:34:42,389 --> 00:34:47,550
short and we will ask both our panelists

776
00:34:45,600 --> 00:34:52,799
to keep the answer very brief the lady

777
00:34:47,550 --> 00:34:56,100
right here I'm the chief executive of

778
00:34:52,800 --> 00:34:58,020
reimagine Europa we are running a task

779
00:34:56,100 --> 00:35:02,580
force on democracy in a digital society

780
00:34:58,020 --> 00:35:04,650
and the Cambridge the Cambridge analytic

781
00:35:02,580 --> 00:35:06,660
a facebook scandal raised a great

782
00:35:04,650 --> 00:35:08,280
opportunity because all of a sudden

783
00:35:06,660 --> 00:35:09,899
regulators across Europe and I think

784
00:35:08,280 --> 00:35:12,270
across the world are ready to start

785
00:35:09,900 --> 00:35:15,810
regulated and also to do quite quite

786
00:35:12,270 --> 00:35:17,609
original and quite bold moves so we're

787
00:35:15,810 --> 00:35:19,140
running this program headed by Professor

788
00:35:17,609 --> 00:35:21,660
Manuel Castells who's been working on

789
00:35:19,140 --> 00:35:23,580
these issues for over 30 years but my

790
00:35:21,660 --> 00:35:27,029
question is one do you think it would be

791
00:35:23,580 --> 00:35:30,330
possible to develop your pian model of a

792
00:35:27,030 --> 00:35:32,160
digital society and secondly if so what

793
00:35:30,330 --> 00:35:34,170
do you think what would your priority be

794
00:35:32,160 --> 00:35:35,940
for that right and let's keep our

795
00:35:34,170 --> 00:35:39,630
answers to 30 seconds and we're heating

796
00:35:35,940 --> 00:35:42,270
you off yes but not as a digital society

797
00:35:39,630 --> 00:35:46,050
in terms of the instrument but digital

798
00:35:42,270 --> 00:35:47,880
in support of the type of society that

799
00:35:46,050 --> 00:35:50,730
Europe has decided to be

800
00:35:47,880 --> 00:35:55,200
the way they want to go the roadmap of

801
00:35:50,730 --> 00:35:57,600
where they choose you know in in in in

802
00:35:55,200 --> 00:36:00,419
terms of their way of conceiving

803
00:35:57,600 --> 00:36:03,089
themselves not only as an economy but

804
00:36:00,420 --> 00:36:05,550
also as a society and also where they

805
00:36:03,090 --> 00:36:08,310
want their children to be and their use

806
00:36:05,550 --> 00:36:10,710
digital to support that model that are

807
00:36:08,310 --> 00:36:13,259
rather than subjecting the model to the

808
00:36:10,710 --> 00:36:15,480
digital you know digital is a tool it's

809
00:36:13,260 --> 00:36:17,990
not a policy right and the closing words

810
00:36:15,480 --> 00:36:20,490
of John yes and gdpr

811
00:36:17,990 --> 00:36:22,350
creates the conditions to do that indeed

812
00:36:20,490 --> 00:36:24,660
it's necessary to do it as a result of

813
00:36:22,350 --> 00:36:25,980
GDP our I was just in Washington this

814
00:36:24,660 --> 00:36:28,109
week with a bunch of other tech

815
00:36:25,980 --> 00:36:30,720
companies where the debate was should

816
00:36:28,110 --> 00:36:33,060
the u.s. adopt GDP are or something like

817
00:36:30,720 --> 00:36:35,040
it so I do think it's entirely possible

818
00:36:33,060 --> 00:36:38,009
for Europe to create that and just one

819
00:36:35,040 --> 00:36:40,590
quick example we have created a trust in

820
00:36:38,010 --> 00:36:43,680
Ireland where we and other companies can

821
00:36:40,590 --> 00:36:45,780
deposit the data that we have and we

822
00:36:43,680 --> 00:36:48,000
developed this trust with data

823
00:36:45,780 --> 00:36:51,000
protection officers so it's fully gdpr

824
00:36:48,000 --> 00:36:53,520
compliant so that big data analytics can

825
00:36:51,000 --> 00:36:55,860
can can occur and the benefits of big

826
00:36:53,520 --> 00:36:57,720
data can still be derived for companies

827
00:36:55,860 --> 00:36:59,910
and for individuals but in a way that's

828
00:36:57,720 --> 00:37:01,709
fully compliant with GDP are so I think

829
00:36:59,910 --> 00:37:03,149
that's already the beginning of creating

830
00:37:01,710 --> 00:37:05,340
the type of society you were talking

831
00:37:03,150 --> 00:37:08,620
about excellent ladies and gentlemen I

832
00:37:05,340 --> 00:37:11,889
hold Korea and John Lepore thank you

833
00:37:08,620 --> 00:37:11,888
[Applause]

