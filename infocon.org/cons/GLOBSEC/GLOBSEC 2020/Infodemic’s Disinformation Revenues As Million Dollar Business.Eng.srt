1
00:00:00,000 --> 00:00:04,319
commendations to a range of stakeholders

2
00:00:02,159 --> 00:00:06,160
on both sides of the atlantic

3
00:00:04,319 --> 00:00:08,480
but we also try to make a difference on

4
00:00:06,160 --> 00:00:10,080
the ground by partnering with at the

5
00:00:08,480 --> 00:00:11,679
think tanks universities public

6
00:00:10,080 --> 00:00:13,519
institutions or media

7
00:00:11,679 --> 00:00:15,360
we created two online courses on this

8
00:00:13,519 --> 00:00:16,720
information we develop manuals on

9
00:00:15,360 --> 00:00:18,160
strategic communication

10
00:00:16,720 --> 00:00:20,479
we provide trainings for public

11
00:00:18,160 --> 00:00:22,400
officials or ngos we even engage

12
00:00:20,480 --> 00:00:23,680
youtubers in a campaign focusing on

13
00:00:22,400 --> 00:00:25,759
young people

14
00:00:23,680 --> 00:00:28,320
with all these activities we generate

15
00:00:25,760 --> 00:00:30,400
new ideas provide creative solutions

16
00:00:28,320 --> 00:00:31,760
and engage relevant stakeholders to

17
00:00:30,400 --> 00:00:33,839
drive positive change

18
00:00:31,760 --> 00:00:35,840
towards more resilient democracies in

19
00:00:33,840 --> 00:00:38,000
its dynamic and digital age

20
00:00:35,840 --> 00:00:39,040
to find out more follow our debates our

21
00:00:38,000 --> 00:00:45,840
social media

22
00:00:39,040 --> 00:00:45,839
and visit our website globsec.org

23
00:00:50,660 --> 00:00:56,019
[Music]

24
00:00:57,100 --> 00:01:05,659
[Applause]

25
00:01:00,130 --> 00:01:05,659
[Music]

26
00:01:10,900 --> 00:01:14,379
[Music]

27
00:01:23,759 --> 00:01:28,640
ladies and gentlemen dear viewers

28
00:01:26,560 --> 00:01:29,360
welcome to the session on disrupting

29
00:01:28,640 --> 00:01:32,320
economies

30
00:01:29,360 --> 00:01:33,759
of disinformation at globsec 2020

31
00:01:32,320 --> 00:01:35,758
digital stage

32
00:01:33,759 --> 00:01:38,240
my name is katana klingova i'm a senior

33
00:01:35,759 --> 00:01:40,240
research fellow at globesick

34
00:01:38,240 --> 00:01:41,600
and it is my great pleasure today to

35
00:01:40,240 --> 00:01:44,320
moderate the session

36
00:01:41,600 --> 00:01:45,199
i'm very delighted uh that i'm being

37
00:01:44,320 --> 00:01:47,039
joined today

38
00:01:45,200 --> 00:01:48,240
by my distinguished speakers and

39
00:01:47,040 --> 00:01:49,920
panelists

40
00:01:48,240 --> 00:01:51,679
i would like to introduce you vadim

41
00:01:49,920 --> 00:01:55,840
biltchik the member

42
00:01:51,680 --> 00:01:55,840
of the european parliament

43
00:01:56,000 --> 00:02:01,119
bran baltzmann and deputy chief

44
00:01:59,119 --> 00:02:02,399
technology officer and senior

45
00:02:01,119 --> 00:02:05,600
information scientist

46
00:02:02,399 --> 00:02:05,600
at round corporation

47
00:02:05,759 --> 00:02:10,479
and claire melfort co-founder and

48
00:02:08,878 --> 00:02:13,599
executive director of the

49
00:02:10,479 --> 00:02:16,160
global disinformation index thank you

50
00:02:13,599 --> 00:02:17,760
very much for joining us today

51
00:02:16,160 --> 00:02:19,280
and i hope we are going to have a very

52
00:02:17,760 --> 00:02:21,840
fruitful discussions

53
00:02:19,280 --> 00:02:23,920
um before we start i would like to start

54
00:02:21,840 --> 00:02:27,599
with a bit of a housekeeping rules

55
00:02:23,920 --> 00:02:28,640
um we have a huge audience following us

56
00:02:27,599 --> 00:02:30,480
online

57
00:02:28,640 --> 00:02:33,119
therefore i would like to encourage our

58
00:02:30,480 --> 00:02:36,079
audience to post questions

59
00:02:33,120 --> 00:02:38,000
in the question sections at the panel

60
00:02:36,080 --> 00:02:39,360
where you can also vote for particular

61
00:02:38,000 --> 00:02:43,040
questions and

62
00:02:39,360 --> 00:02:45,200
promote them to the top we will have a

63
00:02:43,040 --> 00:02:46,879
session at the end of our panel where

64
00:02:45,200 --> 00:02:48,480
we're going to go to your questions so

65
00:02:46,879 --> 00:02:51,120
please ask and

66
00:02:48,480 --> 00:02:53,920
uh you know pose your questions and

67
00:02:51,120 --> 00:02:58,159
we'll go and try to address them

68
00:02:53,920 --> 00:03:00,159
um so the carbon 19 pandemic

69
00:02:58,159 --> 00:03:02,399
has been accompanied what the world

70
00:03:00,159 --> 00:03:05,440
trade world health organization

71
00:03:02,400 --> 00:03:07,040
described as empademic while this

72
00:03:05,440 --> 00:03:09,760
information has been here for

73
00:03:07,040 --> 00:03:10,959
with us for ages you know many actors

74
00:03:09,760 --> 00:03:13,359
spread this information

75
00:03:10,959 --> 00:03:15,280
and they enable the spread of false

76
00:03:13,360 --> 00:03:16,319
information because they make a lot of

77
00:03:15,280 --> 00:03:18,879
money

78
00:03:16,319 --> 00:03:20,640
out of it while critical thinking and

79
00:03:18,879 --> 00:03:22,799
strategic communication

80
00:03:20,640 --> 00:03:24,079
are important antidotes to epidemic and

81
00:03:22,800 --> 00:03:28,239
disinformation

82
00:03:24,080 --> 00:03:30,319
a truly efficient plan needs to include

83
00:03:28,239 --> 00:03:32,319
a plan how to disrupt the financial

84
00:03:30,319 --> 00:03:34,399
streams of disinformation

85
00:03:32,319 --> 00:03:36,000
and this is what we hope to address

86
00:03:34,400 --> 00:03:38,239
during the sessions

87
00:03:36,000 --> 00:03:39,519
and therefore i would like to start with

88
00:03:38,239 --> 00:03:42,239
claire um

89
00:03:39,519 --> 00:03:44,319
because she's from the global

90
00:03:42,239 --> 00:03:45,920
disinformation index and

91
00:03:44,319 --> 00:03:47,839
they did a really good research on it

92
00:03:45,920 --> 00:03:49,760
and i would like to ask her

93
00:03:47,840 --> 00:03:51,280
you know uh how is this information

94
00:03:49,760 --> 00:03:54,159
monetarized online

95
00:03:51,280 --> 00:03:55,120
who is making profit uh from this

96
00:03:54,159 --> 00:03:58,720
information

97
00:03:55,120 --> 00:04:00,159
and how can we stop it you know and what

98
00:03:58,720 --> 00:04:02,879
kind of changes have you observed

99
00:04:00,159 --> 00:04:05,519
with the covert 19 pandemic and its

100
00:04:02,879 --> 00:04:05,518
financing

101
00:04:06,480 --> 00:04:12,079
thank you so clear thank you can you

102
00:04:09,680 --> 00:04:16,079
hear me okay

103
00:04:12,080 --> 00:04:17,600
yes great there are a huge number of

104
00:04:16,079 --> 00:04:18,880
people making a lot of money from

105
00:04:17,600 --> 00:04:22,079
disinformation

106
00:04:18,880 --> 00:04:23,759
uh we at gdi estimate that uh around

107
00:04:22,079 --> 00:04:26,160
a quarter of a billion dollars a year is

108
00:04:23,759 --> 00:04:28,560
made across disinformation sites

109
00:04:26,160 --> 00:04:31,040
we did a study earlier this year just

110
00:04:28,560 --> 00:04:33,440
looking at covid19 disinformation

111
00:04:31,040 --> 00:04:36,000
which estimated that around 25 million

112
00:04:33,440 --> 00:04:38,320
dollars would go towards covet 19

113
00:04:36,000 --> 00:04:40,800
uh conspiracy theories bunk cures

114
00:04:38,320 --> 00:04:43,520
etcetera just in 2020

115
00:04:40,800 --> 00:04:44,400
the reason this is possible is because

116
00:04:43,520 --> 00:04:46,960
of the

117
00:04:44,400 --> 00:04:48,880
huge increase in use of programmatic

118
00:04:46,960 --> 00:04:51,120
advertising networks which place

119
00:04:48,880 --> 00:04:52,719
ads based on the number of clicks a

120
00:04:51,120 --> 00:04:55,199
piece of content gets

121
00:04:52,720 --> 00:04:56,000
so all a disinformation actor has to do

122
00:04:55,199 --> 00:04:58,880
is make clickable

123
00:04:56,000 --> 00:05:00,479
content that content then immediately uh

124
00:04:58,880 --> 00:05:02,479
earns ads based on

125
00:05:00,479 --> 00:05:04,159
dollars based on the number of clicks it

126
00:05:02,479 --> 00:05:05,120
gets so you get you write something that

127
00:05:04,160 --> 00:05:06,880
gets clicks

128
00:05:05,120 --> 00:05:08,880
you get dollars the more controversial

129
00:05:06,880 --> 00:05:11,280
content the more it enrages us

130
00:05:08,880 --> 00:05:12,960
the more dollars you're going to make

131
00:05:11,280 --> 00:05:14,000
and this is true for covert 19

132
00:05:12,960 --> 00:05:16,080
disinformation

133
00:05:14,000 --> 00:05:17,680
it's true across all sorts of conspiracy

134
00:05:16,080 --> 00:05:19,758
theories and what we're seeing is that

135
00:05:17,680 --> 00:05:22,320
many of the same websites

136
00:05:19,759 --> 00:05:24,240
are trafficking in a lot of the same

137
00:05:22,320 --> 00:05:27,120
conspiracy theories whether it is

138
00:05:24,240 --> 00:05:28,400
kobe 19 or anti-vaxx or climate change

139
00:05:27,120 --> 00:05:31,759
denial

140
00:05:28,400 --> 00:05:34,239
anti-black lives matter anti-islam

141
00:05:31,759 --> 00:05:35,520
you name it many of the same sites come

142
00:05:34,240 --> 00:05:38,000
up time and again

143
00:05:35,520 --> 00:05:39,840
trafficking in these uh in these

144
00:05:38,000 --> 00:05:43,199
conspiracies and this highly

145
00:05:39,840 --> 00:05:46,000
divisive content purely because or

146
00:05:43,199 --> 00:05:46,560
partly because it is a way of generating

147
00:05:46,000 --> 00:05:49,120
uh

148
00:05:46,560 --> 00:05:50,960
high traffic volumes and therefore high

149
00:05:49,120 --> 00:05:52,479
amounts of advertising revenue

150
00:05:50,960 --> 00:05:54,159
but i would just want to add that

151
00:05:52,479 --> 00:05:56,318
advertising is not the only way

152
00:05:54,160 --> 00:05:57,440
that disinformation merchants monetize

153
00:05:56,319 --> 00:06:00,000
their content

154
00:05:57,440 --> 00:06:00,719
there is merchandising there are plenty

155
00:06:00,000 --> 00:06:03,759
of shops

156
00:06:00,720 --> 00:06:04,479
on etsy on ebay on amazon where people

157
00:06:03,759 --> 00:06:07,039
sell

158
00:06:04,479 --> 00:06:08,880
merchandising that uh makes money for

159
00:06:07,039 --> 00:06:10,800
their particular conspiracy theory

160
00:06:08,880 --> 00:06:12,080
and it also stretches across payment

161
00:06:10,800 --> 00:06:15,600
systems so there is

162
00:06:12,080 --> 00:06:16,639
a whole eco of uh ways that people can

163
00:06:15,600 --> 00:06:20,560
monetize

164
00:06:16,639 --> 00:06:23,199
the sort of divisive uh polarizing

165
00:06:20,560 --> 00:06:24,880
and extremely harmful content across a

166
00:06:23,199 --> 00:06:27,039
whole range of narratives

167
00:06:24,880 --> 00:06:28,639
that we've seen particularly painfully

168
00:06:27,039 --> 00:06:30,800
brought to light through the covert

169
00:06:28,639 --> 00:06:33,039
pandemic which has resulted in people

170
00:06:30,800 --> 00:06:34,880
dying from from bunk cures for example

171
00:06:33,039 --> 00:06:36,400
and has undermined the work that public

172
00:06:34,880 --> 00:06:39,039
health authorities are doing

173
00:06:36,400 --> 00:06:48,239
to try and get high quality public

174
00:06:39,039 --> 00:06:51,599
health information out there

175
00:06:48,240 --> 00:06:53,840
but what can we do about it uh rant

176
00:06:51,599 --> 00:06:54,960
you know uh how do we stop financing of

177
00:06:53,840 --> 00:06:56,799
this disinformation

178
00:06:54,960 --> 00:06:58,880
i mean claire mentioned that there is a

179
00:06:56,800 --> 00:07:01,360
whole ecosystem

180
00:06:58,880 --> 00:07:02,000
uh what can we do about it how can we

181
00:07:01,360 --> 00:07:04,319
it's not about

182
00:07:02,000 --> 00:07:06,080
the social media platforms who earn a

183
00:07:04,319 --> 00:07:08,720
lot of revenue about it

184
00:07:06,080 --> 00:07:09,840
uh but it's also you know bots and

185
00:07:08,720 --> 00:07:13,039
trolls that are

186
00:07:09,840 --> 00:07:14,719
readily accessible uh on

187
00:07:13,039 --> 00:07:17,360
your browser you don't even have to

188
00:07:14,720 --> 00:07:19,520
access the the deep web

189
00:07:17,360 --> 00:07:23,039
but it's also about the young people for

190
00:07:19,520 --> 00:07:24,479
example in bellas who are very much

191
00:07:23,039 --> 00:07:26,080
you know popular in spreading this

192
00:07:24,479 --> 00:07:29,280
information and are

193
00:07:26,080 --> 00:07:32,318
earning a lot of money uh prior the

194
00:07:29,280 --> 00:07:34,960
uh past uh presidential elections in the

195
00:07:32,319 --> 00:07:37,039
united states what can we do about it i

196
00:07:34,960 --> 00:07:39,919
mean is it really

197
00:07:37,039 --> 00:07:41,680
about pulling the plug and leaving the

198
00:07:39,919 --> 00:07:44,318
social media platforms

199
00:07:41,680 --> 00:07:45,440
and you know creating the new social

200
00:07:44,319 --> 00:07:49,599
environment

201
00:07:45,440 --> 00:07:52,879
or imposing huge sanctions on

202
00:07:49,599 --> 00:07:53,840
these actors um what do you think from

203
00:07:52,879 --> 00:07:57,120
your experience

204
00:07:53,840 --> 00:08:00,318
uh is the most efficient way

205
00:07:57,120 --> 00:08:01,039
uh how to disrupt these uh financial

206
00:08:00,319 --> 00:08:05,680
streams

207
00:08:01,039 --> 00:08:05,680
and uh what needs to be taken and done

208
00:08:06,479 --> 00:08:09,359
well so i so first of all i don't think

209
00:08:08,319 --> 00:08:11,199
you're really ever gonna be able to

210
00:08:09,360 --> 00:08:12,479
depend on the platforms themselves to

211
00:08:11,199 --> 00:08:15,759
solve the problem

212
00:08:12,479 --> 00:08:16,960
i mean it's not to their advantage to do

213
00:08:15,759 --> 00:08:18,400
that really

214
00:08:16,960 --> 00:08:20,719
and unless you make it to their

215
00:08:18,400 --> 00:08:23,120
advantage somehow then i don't really

216
00:08:20,720 --> 00:08:23,840
expect to see much from them so instead

217
00:08:23,120 --> 00:08:26,000
i think

218
00:08:23,840 --> 00:08:28,000
probably the most efficient thing is to

219
00:08:26,000 --> 00:08:30,000
actually offer us a separate platform a

220
00:08:28,000 --> 00:08:32,320
different type of platform we actually

221
00:08:30,000 --> 00:08:34,240
which is publicly accessible and it's

222
00:08:32,320 --> 00:08:34,800
accessible to controls it's accessible

223
00:08:34,240 --> 00:08:38,000
to

224
00:08:34,799 --> 00:08:39,598
you know it's it offers transparency

225
00:08:38,000 --> 00:08:41,839
you can see exactly what's going on and

226
00:08:39,599 --> 00:08:43,360
you have a chance to really um

227
00:08:41,839 --> 00:08:45,040
you know to get a grip on things i mean

228
00:08:43,360 --> 00:08:47,680
that so that's one general approach

229
00:08:45,040 --> 00:08:48,640
to create you know a really a public

230
00:08:47,680 --> 00:08:50,479
benefit type

231
00:08:48,640 --> 00:08:51,839
social media platform where you can

232
00:08:50,480 --> 00:08:53,279
actually try to establish some kind of

233
00:08:51,839 --> 00:08:55,600
trust in it

234
00:08:53,279 --> 00:08:57,200
i mean you know mark zuckerberg he's not

235
00:08:55,600 --> 00:08:58,959
an elected official

236
00:08:57,200 --> 00:09:00,320
he's not a public servant i mean the man

237
00:08:58,959 --> 00:09:01,920
is running a business and he's going to

238
00:09:00,320 --> 00:09:02,720
do whatever he can to run his business

239
00:09:01,920 --> 00:09:04,319
and so

240
00:09:02,720 --> 00:09:06,080
i mean the first thing i think people

241
00:09:04,320 --> 00:09:07,519
need to stop doing is just just to take

242
00:09:06,080 --> 00:09:10,000
whatever they say

243
00:09:07,519 --> 00:09:11,360
that they say they're doing for granted

244
00:09:10,000 --> 00:09:12,080
i mean i see too many reports where they

245
00:09:11,360 --> 00:09:14,480
say

246
00:09:12,080 --> 00:09:15,760
well facebook is doing so and so well

247
00:09:14,480 --> 00:09:17,120
how do you know they're actually doing

248
00:09:15,760 --> 00:09:18,399
that and the answer is you don't know

249
00:09:17,120 --> 00:09:19,680
because they want to actually show you

250
00:09:18,399 --> 00:09:20,560
all you know is what they say they're

251
00:09:19,680 --> 00:09:22,560
doing

252
00:09:20,560 --> 00:09:24,399
so the very first thing you can do is

253
00:09:22,560 --> 00:09:26,959
try to get you know to try to force

254
00:09:24,399 --> 00:09:28,080
some kind of auditing function on them

255
00:09:26,959 --> 00:09:30,319
that that says

256
00:09:28,080 --> 00:09:32,160
where somebody's allowed to go in and to

257
00:09:30,320 --> 00:09:33,920
verify that they do what they say not

258
00:09:32,160 --> 00:09:34,240
even to critique it but just to verify

259
00:09:33,920 --> 00:09:35,519
that

260
00:09:34,240 --> 00:09:37,120
what what they're saying in there is

261
00:09:35,519 --> 00:09:38,240
actually doing then you have a

262
00:09:37,120 --> 00:09:41,120
foundation at least for

263
00:09:38,240 --> 00:09:42,800
a more a reasonable discussion about

264
00:09:41,120 --> 00:09:44,240
what the right thing to do is

265
00:09:42,800 --> 00:09:46,000
but until you can verify they're doing

266
00:09:44,240 --> 00:09:46,560
things i what they're saying they're

267
00:09:46,000 --> 00:09:48,000
doing

268
00:09:46,560 --> 00:09:51,119
there isn't really much room for

269
00:09:48,000 --> 00:09:53,200
discussion there so

270
00:09:51,120 --> 00:09:54,399
that would mean that would be my general

271
00:09:53,200 --> 00:09:55,120
price the other thing of course is to

272
00:09:54,399 --> 00:09:57,279
disrupt

273
00:09:55,120 --> 00:09:58,160
the activities so i mean i can hack

274
00:09:57,279 --> 00:10:00,800
programmatic

275
00:09:58,160 --> 00:10:02,319
you know ad systems so that while these

276
00:10:00,800 --> 00:10:03,920
guys may try to show ads

277
00:10:02,320 --> 00:10:05,360
i can make sure they don't get shown

278
00:10:03,920 --> 00:10:06,479
with their i replace them with something

279
00:10:05,360 --> 00:10:09,040
else

280
00:10:06,480 --> 00:10:10,480
so i can get in and you know play around

281
00:10:09,040 --> 00:10:13,199
with the bidding systems

282
00:10:10,480 --> 00:10:14,480
so that my ads what i show gets always

283
00:10:13,200 --> 00:10:15,839
displaces them

284
00:10:14,480 --> 00:10:18,240
and i can disrupt their general

285
00:10:15,839 --> 00:10:21,200
activities i was you know sort of

286
00:10:18,240 --> 00:10:23,440
activity along those lines

287
00:10:21,200 --> 00:10:24,959
but there is a whole other area which i

288
00:10:23,440 --> 00:10:25,519
think is worth looking at and that has

289
00:10:24,959 --> 00:10:26,719
to do with

290
00:10:25,519 --> 00:10:28,560
you know using this information to

291
00:10:26,720 --> 00:10:31,600
disrupt supply chains

292
00:10:28,560 --> 00:10:33,279
so the supply chain that

293
00:10:31,600 --> 00:10:34,720
that's becoming a really big problem so

294
00:10:33,279 --> 00:10:36,160
there's a lot of fraud a lot of other

295
00:10:34,720 --> 00:10:38,240
kinds of things

296
00:10:36,160 --> 00:10:39,279
um which i think needs to be looked at

297
00:10:38,240 --> 00:10:41,519
more carefully i've seen some

298
00:10:39,279 --> 00:10:44,560
interesting examples of that

299
00:10:41,519 --> 00:10:47,360
so i'll stop there

300
00:10:44,560 --> 00:10:48,319
well not everybody has your hacking

301
00:10:47,360 --> 00:10:51,839
skills rant

302
00:10:48,320 --> 00:10:53,600
uh and uh yeah you know vladimir he's a

303
00:10:51,839 --> 00:10:55,920
member of european parliament and he's a

304
00:10:53,600 --> 00:10:56,800
policymaker so

305
00:10:55,920 --> 00:10:59,599
what do you think about these

306
00:10:56,800 --> 00:11:00,240
suggestions i mean should the european

307
00:10:59,600 --> 00:11:02,959
union

308
00:11:00,240 --> 00:11:04,800
or european countries develop their own

309
00:11:02,959 --> 00:11:06,800
online platform that is going to be

310
00:11:04,800 --> 00:11:09,920
transparent because

311
00:11:06,800 --> 00:11:12,479
as we see the conversations with social

312
00:11:09,920 --> 00:11:15,839
media giants are not really

313
00:11:12,480 --> 00:11:18,800
fruitful or you know are lengthy or

314
00:11:15,839 --> 00:11:19,760
you know should we develop our own

315
00:11:18,800 --> 00:11:22,959
authority

316
00:11:19,760 --> 00:11:24,800
or i know get our own hackers who are

317
00:11:22,959 --> 00:11:28,880
going to disrupt the

318
00:11:24,800 --> 00:11:31,680
uh bidding systems at as rand suggested

319
00:11:28,880 --> 00:11:33,760
uh what's your how do you see all these

320
00:11:31,680 --> 00:11:35,199
suggestions

321
00:11:33,760 --> 00:11:36,959
well thank you very much for the

322
00:11:35,200 --> 00:11:39,360
questions and i uh really

323
00:11:36,959 --> 00:11:41,040
want to thank the organizers for having

324
00:11:39,360 --> 00:11:43,279
not just this panel but actually

325
00:11:41,040 --> 00:11:45,279
uh much of discussion in the conference

326
00:11:43,279 --> 00:11:46,399
uh dedicated to the problem with via

327
00:11:45,279 --> 00:11:48,480
facebook

328
00:11:46,399 --> 00:11:49,519
the problem empademic that's the problem

329
00:11:48,480 --> 00:11:52,320
of uh

330
00:11:49,519 --> 00:11:52,800
this information that's the problem of

331
00:11:52,320 --> 00:11:54,880
the

332
00:11:52,800 --> 00:11:56,399
quality of the digital space which has

333
00:11:54,880 --> 00:11:58,399
become in many respects

334
00:11:56,399 --> 00:12:00,240
also a dominant space for our public

335
00:11:58,399 --> 00:12:01,600
life so i think

336
00:12:00,240 --> 00:12:03,279
it's something we need to take very

337
00:12:01,600 --> 00:12:04,160
seriously when it comes to policy making

338
00:12:03,279 --> 00:12:06,639
when it comes to

339
00:12:04,160 --> 00:12:07,439
politics when it comes to politicians

340
00:12:06,639 --> 00:12:09,279
it's one of

341
00:12:07,440 --> 00:12:11,360
problem one of event when it comes to

342
00:12:09,279 --> 00:12:14,880
just elections or campaigns

343
00:12:11,360 --> 00:12:17,360
uh it concerns consumers it concerns um

344
00:12:14,880 --> 00:12:18,079
the quality of the market uh because

345
00:12:17,360 --> 00:12:21,360
much of

346
00:12:18,079 --> 00:12:24,160
uh uh the business these days is done

347
00:12:21,360 --> 00:12:26,079
online and so in that sense as claire

348
00:12:24,160 --> 00:12:26,959
was saying there is this whole ecosystem

349
00:12:26,079 --> 00:12:30,239
here which has

350
00:12:26,959 --> 00:12:30,959
uh developed um in the past couple of

351
00:12:30,240 --> 00:12:34,240
decades

352
00:12:30,959 --> 00:12:37,279
um and i think we need to find a proper

353
00:12:34,240 --> 00:12:40,160
responsible public way of how

354
00:12:37,279 --> 00:12:41,040
we address and deal with this ecosystem

355
00:12:40,160 --> 00:12:44,319
to take

356
00:12:41,040 --> 00:12:47,439
uh take out the best of it uh and to

357
00:12:44,320 --> 00:12:50,480
in in a in a uh in a way mitigate uh

358
00:12:47,440 --> 00:12:54,079
uh the evils uh which uh associate

359
00:12:50,480 --> 00:12:55,040
uh with with the digital space and i

360
00:12:54,079 --> 00:12:57,839
think this is uh

361
00:12:55,040 --> 00:12:58,800
um an important task for us in the

362
00:12:57,839 --> 00:13:01,920
policy making

363
00:12:58,800 --> 00:13:03,839
uh business policy making area uh it's

364
00:13:01,920 --> 00:13:05,199
an important task for us also in the

365
00:13:03,839 --> 00:13:06,880
european union

366
00:13:05,200 --> 00:13:09,360
this is not a problem over a single

367
00:13:06,880 --> 00:13:10,720
state this is a global problem so we can

368
00:13:09,360 --> 00:13:13,680
only politically face it

369
00:13:10,720 --> 00:13:14,560
at the level of uh of at least a group

370
00:13:13,680 --> 00:13:17,680
of states and i

371
00:13:14,560 --> 00:13:21,040
i here i see the european union

372
00:13:17,680 --> 00:13:21,839
as as an actor at the forefront of the

373
00:13:21,040 --> 00:13:25,439
efforts

374
00:13:21,839 --> 00:13:28,800
uh to really face uh the um problem of

375
00:13:25,440 --> 00:13:30,880
this information which has consequences

376
00:13:28,800 --> 00:13:31,120
for consumers but also for the quality

377
00:13:30,880 --> 00:13:33,439
of

378
00:13:31,120 --> 00:13:34,160
our public debate public life and the

379
00:13:33,440 --> 00:13:36,800
quality of

380
00:13:34,160 --> 00:13:39,120
of democracies and of course democracy

381
00:13:36,800 --> 00:13:39,920
and market economy go hand in hand so we

382
00:13:39,120 --> 00:13:42,160
must protect

383
00:13:39,920 --> 00:13:44,000
uh both of these by fighting this

384
00:13:42,160 --> 00:13:46,240
information how do we do this

385
00:13:44,000 --> 00:13:47,920
um now in the european union

386
00:13:46,240 --> 00:13:49,360
specifically in the european parliament

387
00:13:47,920 --> 00:13:52,479
uh we are looking at this

388
00:13:49,360 --> 00:13:53,839
as a serious political problem

389
00:13:52,480 --> 00:13:55,199
and i think we need to find serious

390
00:13:53,839 --> 00:13:56,560
political answers and i think they're

391
00:13:55,199 --> 00:13:59,279
coming up

392
00:13:56,560 --> 00:14:00,079
very soon in the established a special

393
00:13:59,279 --> 00:14:03,760
committee

394
00:14:00,079 --> 00:14:05,199
which is going to look into the external

395
00:14:03,760 --> 00:14:07,600
uterus role

396
00:14:05,199 --> 00:14:08,560
in our democracies but also going to

397
00:14:07,600 --> 00:14:10,720
look into

398
00:14:08,560 --> 00:14:12,079
the problem of this information and how

399
00:14:10,720 --> 00:14:13,440
we can best address it

400
00:14:12,079 --> 00:14:15,599
we already adopted an important

401
00:14:13,440 --> 00:14:18,800
resolution in this area

402
00:14:15,600 --> 00:14:20,160
in uh october uh last last year

403
00:14:18,800 --> 00:14:22,719
i was one of the co-authors of this

404
00:14:20,160 --> 00:14:24,319
resolution and i will be also serving on

405
00:14:22,720 --> 00:14:25,920
this special committee which will start

406
00:14:24,320 --> 00:14:28,320
its work in september

407
00:14:25,920 --> 00:14:30,880
uh and i very much look forward to uh

408
00:14:28,320 --> 00:14:33,680
really making progress when it comes to

409
00:14:30,880 --> 00:14:34,720
uh real political answers to the problem

410
00:14:33,680 --> 00:14:36,479
of this information

411
00:14:34,720 --> 00:14:38,800
and what are these potential political

412
00:14:36,480 --> 00:14:40,480
answers let me suggest two which already

413
00:14:38,800 --> 00:14:40,880
on the table and which we'll discuss in

414
00:14:40,480 --> 00:14:43,040
depth

415
00:14:40,880 --> 00:14:45,199
this coming fall one is the digital

416
00:14:43,040 --> 00:14:46,079
services act uh which for the first time

417
00:14:45,199 --> 00:14:49,040
will be a

418
00:14:46,079 --> 00:14:50,000
comprehensive attempt to really uh

419
00:14:49,040 --> 00:14:52,560
regulate

420
00:14:50,000 --> 00:14:53,360
regulate this ecosystem which we have

421
00:14:52,560 --> 00:14:55,199
i'm not sure

422
00:14:53,360 --> 00:14:56,880
uh there is an answer and this is maybe

423
00:14:55,199 --> 00:14:59,040
a response to what brand was saying

424
00:14:56,880 --> 00:15:00,240
that let's create a whole new platform i

425
00:14:59,040 --> 00:15:03,439
think we need to find

426
00:15:00,240 --> 00:15:05,760
the way a way how we can best live with

427
00:15:03,440 --> 00:15:06,480
the existing environment but also

428
00:15:05,760 --> 00:15:08,959
control

429
00:15:06,480 --> 00:15:09,600
uh the evil side effects of it and this

430
00:15:08,959 --> 00:15:11,599
information

431
00:15:09,600 --> 00:15:13,519
is an evil side effect of this

432
00:15:11,600 --> 00:15:16,560
environment it can kill

433
00:15:13,519 --> 00:15:19,040
as the pandemic is showing

434
00:15:16,560 --> 00:15:20,800
um but not just the pandemic you know

435
00:15:19,040 --> 00:15:22,880
look at the genocide in myanmar for

436
00:15:20,800 --> 00:15:23,680
instance had it not been for facebook uh

437
00:15:22,880 --> 00:15:26,320
perhaps

438
00:15:23,680 --> 00:15:26,800
um it may not not not have happened the

439
00:15:26,320 --> 00:15:29,600
way it

440
00:15:26,800 --> 00:15:30,399
it did so uh so so really um this

441
00:15:29,600 --> 00:15:33,279
information

442
00:15:30,399 --> 00:15:34,560
on social media on platforms has real

443
00:15:33,279 --> 00:15:37,519
consequences and

444
00:15:34,560 --> 00:15:38,479
is a matter of uh life and death and uh

445
00:15:37,519 --> 00:15:40,720
oftentimes

446
00:15:38,480 --> 00:15:41,759
um and in addition of course to

447
00:15:40,720 --> 00:15:45,120
regulation

448
00:15:41,759 --> 00:15:48,480
um uh it's also active promotion

449
00:15:45,120 --> 00:15:52,240
of um uh active citizenship

450
00:15:48,480 --> 00:15:55,440
of uh fact checking of awareness

451
00:15:52,240 --> 00:15:58,480
of strong media we need strong

452
00:15:55,440 --> 00:15:59,519
free um responsible media and this is

453
00:15:58,480 --> 00:16:02,399
where i see

454
00:15:59,519 --> 00:16:03,440
again a strong european action plan

455
00:16:02,399 --> 00:16:06,160
which i hope will

456
00:16:03,440 --> 00:16:07,360
come out of the democracy action plan

457
00:16:06,160 --> 00:16:08,079
which is going to be proposed by the

458
00:16:07,360 --> 00:16:09,680
european commission

459
00:16:08,079 --> 00:16:11,439
we'll discuss also in the european

460
00:16:09,680 --> 00:16:13,279
parliament this coming fall so

461
00:16:11,440 --> 00:16:14,959
so these are just the three examples in

462
00:16:13,279 --> 00:16:17,120
terms of how we need to go about it

463
00:16:14,959 --> 00:16:18,399
and let me just make one last point here

464
00:16:17,120 --> 00:16:21,040
i think it's important

465
00:16:18,399 --> 00:16:21,680
uh that europe acts here shows the

466
00:16:21,040 --> 00:16:23,680
leading

467
00:16:21,680 --> 00:16:25,920
way how we can deal with this uh to the

468
00:16:23,680 --> 00:16:26,880
world but also it's important for us in

469
00:16:25,920 --> 00:16:28,959
europe because we have

470
00:16:26,880 --> 00:16:30,560
smaller and larger states we have some

471
00:16:28,959 --> 00:16:31,279
states which have already attempted to

472
00:16:30,560 --> 00:16:33,758
regulate

473
00:16:31,279 --> 00:16:35,360
the digital space uh and the platforms

474
00:16:33,759 --> 00:16:38,320
uh notably germany

475
00:16:35,360 --> 00:16:40,480
but we have smaller states um who really

476
00:16:38,320 --> 00:16:42,720
don't have the power on their own to

477
00:16:40,480 --> 00:16:44,639
get in the direct conversation with uh

478
00:16:42,720 --> 00:16:46,320
facebook google and the other global

479
00:16:44,639 --> 00:16:48,000
platforms so that's why i'm i'm saying

480
00:16:46,320 --> 00:16:50,720
we need a

481
00:16:48,000 --> 00:16:52,320
a proper european policy action

482
00:16:50,720 --> 00:16:55,519
including regulation

483
00:16:52,320 --> 00:16:57,839
which will force uh the platforms to be

484
00:16:55,519 --> 00:16:58,639
as transparent as possible about what

485
00:16:57,839 --> 00:17:00,720
they are actually

486
00:16:58,639 --> 00:17:01,680
doing and how they are fighting this

487
00:17:00,720 --> 00:17:04,559
information

488
00:17:01,680 --> 00:17:04,959
uh among other things and we can only do

489
00:17:04,559 --> 00:17:06,559
this

490
00:17:04,959 --> 00:17:08,880
effectively at the level of the european

491
00:17:06,559 --> 00:17:08,879
union

492
00:17:10,480 --> 00:17:15,280
claire when you hear these

493
00:17:13,599 --> 00:17:17,198
policy measures that are being prepared

494
00:17:15,280 --> 00:17:18,799
at the european level

495
00:17:17,199 --> 00:17:20,319
what do you think about them i mean this

496
00:17:18,799 --> 00:17:23,359
is enough

497
00:17:20,319 --> 00:17:25,039
and then secondly you know you uh with

498
00:17:23,359 --> 00:17:26,240
the global disinformation index have

499
00:17:25,039 --> 00:17:28,960
monitoring

500
00:17:26,240 --> 00:17:30,000
a lot of activities of the the private

501
00:17:28,960 --> 00:17:33,760
companies

502
00:17:30,000 --> 00:17:36,720
uh within um this pandemic

503
00:17:33,760 --> 00:17:37,360
uh but also because of the black lives

504
00:17:36,720 --> 00:17:40,559
matter

505
00:17:37,360 --> 00:17:42,959
uh initiative um we saw

506
00:17:40,559 --> 00:17:43,600
a recent initiative stop hate for profit

507
00:17:42,960 --> 00:17:46,640
uh

508
00:17:43,600 --> 00:17:50,000
um being emerged and launched um

509
00:17:46,640 --> 00:17:51,520
is this enough how do we uh spread it

510
00:17:50,000 --> 00:17:54,160
around how do we build this

511
00:17:51,520 --> 00:17:54,960
corporate social responsibility not only

512
00:17:54,160 --> 00:17:58,400
among the

513
00:17:54,960 --> 00:18:01,520
businesses but among the uh individuals

514
00:17:58,400 --> 00:18:03,120
uh who themselves you know

515
00:18:01,520 --> 00:18:05,840
can spread this information and make

516
00:18:03,120 --> 00:18:05,840
money out of it

517
00:18:06,799 --> 00:18:09,840
so i think the first part of the answer

518
00:18:08,880 --> 00:18:11,919
is uh

519
00:18:09,840 --> 00:18:13,360
it can often feel like it's a the

520
00:18:11,919 --> 00:18:15,039
internet's a big place and it's an

521
00:18:13,360 --> 00:18:17,520
intractable problem

522
00:18:15,039 --> 00:18:19,440
but actually if you focus at least as

523
00:18:17,520 --> 00:18:21,520
the first stage on demonetizing

524
00:18:19,440 --> 00:18:23,679
disinformation and breaking the

525
00:18:21,520 --> 00:18:24,960
revenue flows it becomes a much more

526
00:18:23,679 --> 00:18:27,200
tractable problem

527
00:18:24,960 --> 00:18:28,320
three out of every four dollars that go

528
00:18:27,200 --> 00:18:30,320
to disinformation

529
00:18:28,320 --> 00:18:31,918
particularly their covert disinformation

530
00:18:30,320 --> 00:18:35,039
report we most recently

531
00:18:31,919 --> 00:18:38,000
was uh published were placed

532
00:18:35,039 --> 00:18:39,200
on those websites by google google is by

533
00:18:38,000 --> 00:18:42,559
far the biggest

534
00:18:39,200 --> 00:18:43,520
ad exchange it places by far the largest

535
00:18:42,559 --> 00:18:46,639
amount of

536
00:18:43,520 --> 00:18:47,440
ad dollars in the open web so it's

537
00:18:46,640 --> 00:18:50,320
actually a pretty

538
00:18:47,440 --> 00:18:50,960
tractable problem if google would agree

539
00:18:50,320 --> 00:18:53,678
to

540
00:18:50,960 --> 00:18:54,400
stop providing its ad services to the

541
00:18:53,679 --> 00:18:57,760
worst

542
00:18:54,400 --> 00:19:00,480
100 or 200 sites that traffic

543
00:18:57,760 --> 00:19:02,240
in covert disinformation in anti-black

544
00:19:00,480 --> 00:19:05,200
lives matter conspiracies

545
00:19:02,240 --> 00:19:07,200
that would be a significant blow to the

546
00:19:05,200 --> 00:19:08,799
incentive to the to people to create

547
00:19:07,200 --> 00:19:09,600
that sort of disinformation in the first

548
00:19:08,799 --> 00:19:11,120
place

549
00:19:09,600 --> 00:19:12,879
so the first thing i would say is it is

550
00:19:11,120 --> 00:19:16,239
a tractable problem

551
00:19:12,880 --> 00:19:18,480
the second point i would make is we do

552
00:19:16,240 --> 00:19:19,360
need a systemic solution it cannot just

553
00:19:18,480 --> 00:19:21,840
be about

554
00:19:19,360 --> 00:19:24,479
google because if google stops funding

555
00:19:21,840 --> 00:19:25,280
or providing ad services to certain

556
00:19:24,480 --> 00:19:27,120
sites

557
00:19:25,280 --> 00:19:28,639
they will just go elsewhere and find

558
00:19:27,120 --> 00:19:32,000
another ad exchange

559
00:19:28,640 --> 00:19:34,880
so what will really help is providing

560
00:19:32,000 --> 00:19:35,919
uh and regulation has a as a key role to

561
00:19:34,880 --> 00:19:38,240
play here

562
00:19:35,919 --> 00:19:39,840
establishing a common set of standards

563
00:19:38,240 --> 00:19:43,039
for what sort of content

564
00:19:39,840 --> 00:19:46,559
can be can be monetized

565
00:19:43,039 --> 00:19:48,400
so for example gdi provides a risk score

566
00:19:46,559 --> 00:19:51,039
for every news site

567
00:19:48,400 --> 00:19:52,880
that risk score could be used by google

568
00:19:51,039 --> 00:19:55,840
by other ad exchanges

569
00:19:52,880 --> 00:19:56,240
not only to determine whether or not a

570
00:19:55,840 --> 00:19:59,520
site

571
00:19:56,240 --> 00:20:01,440
should receive ads but also how high up

572
00:19:59,520 --> 00:20:03,520
in your search or your news feed that

573
00:20:01,440 --> 00:20:05,919
site should be

574
00:20:03,520 --> 00:20:07,200
and if the the thing that would

575
00:20:05,919 --> 00:20:09,360
significantly help

576
00:20:07,200 --> 00:20:10,480
with the next phase of european

577
00:20:09,360 --> 00:20:12,719
regulation

578
00:20:10,480 --> 00:20:14,320
is if some sort of common standard

579
00:20:12,720 --> 00:20:17,120
common risk standard

580
00:20:14,320 --> 00:20:19,439
was included in it and if the

581
00:20:17,120 --> 00:20:21,120
enforcement mechanisms were really

582
00:20:19,440 --> 00:20:23,520
well thought through what we saw with

583
00:20:21,120 --> 00:20:26,000
the code of practice on disinformation

584
00:20:23,520 --> 00:20:27,760
which was a great first start but the

585
00:20:26,000 --> 00:20:28,400
enforcement mechanisms just weren't

586
00:20:27,760 --> 00:20:30,879
there

587
00:20:28,400 --> 00:20:31,440
and what the platforms were able to do

588
00:20:30,880 --> 00:20:35,440
is

589
00:20:31,440 --> 00:20:38,559
offer really very very weak compliance

590
00:20:35,440 --> 00:20:42,080
with the code of practice so for example

591
00:20:38,559 --> 00:20:44,000
google's offer of

592
00:20:42,080 --> 00:20:45,120
meeting its disinformation obligations

593
00:20:44,000 --> 00:20:46,240
under the code of practice on

594
00:20:45,120 --> 00:20:49,199
disinformation

595
00:20:46,240 --> 00:20:51,200
was simply to make sure that no site

596
00:20:49,200 --> 00:20:52,480
that didn't that wasn't clear about its

597
00:20:51,200 --> 00:20:55,120
source of funding

598
00:20:52,480 --> 00:20:56,880
would be monetized so all you have to do

599
00:20:55,120 --> 00:20:59,039
is state your source of funding you can

600
00:20:56,880 --> 00:21:00,559
carry any content you like and you will

601
00:20:59,039 --> 00:21:04,320
be monetized by google

602
00:21:00,559 --> 00:21:06,720
this is a really weak uh form of

603
00:21:04,320 --> 00:21:08,559
commitment so whatever comes next

604
00:21:06,720 --> 00:21:11,520
through the digital services act

605
00:21:08,559 --> 00:21:12,639
or whatever mechanism is is to follow

606
00:21:11,520 --> 00:21:15,440
really needs to have

607
00:21:12,640 --> 00:21:17,840
very tight standards and really clear

608
00:21:15,440 --> 00:21:17,840
enforcement

609
00:21:20,000 --> 00:21:23,120
vladimir how do you perceive the

610
00:21:21,440 --> 00:21:24,640
suggestions of claire's i mean is this

611
00:21:23,120 --> 00:21:25,439
something that you're going to be

612
00:21:24,640 --> 00:21:28,640
pursuing

613
00:21:25,440 --> 00:21:30,559
at the eu level i mean this is do you

614
00:21:28,640 --> 00:21:33,120
see this as something that could be

615
00:21:30,559 --> 00:21:35,200
implemented into the uh european

616
00:21:33,120 --> 00:21:38,239
european digital service act

617
00:21:35,200 --> 00:21:41,440
um uh furthermore um

618
00:21:38,240 --> 00:21:43,919
you know how do

619
00:21:41,440 --> 00:21:45,840
you know we see some some actions being

620
00:21:43,919 --> 00:21:49,200
taken by the social media

621
00:21:45,840 --> 00:21:51,039
platforms i mean they're more and more

622
00:21:49,200 --> 00:21:52,480
limiting the spread of this information

623
00:21:51,039 --> 00:21:54,640
but this is not

624
00:21:52,480 --> 00:21:55,679
enough how how do we ensure that they

625
00:21:54,640 --> 00:21:59,039
comply

626
00:21:55,679 --> 00:21:59,679
uh with the policies uh is this a way

627
00:21:59,039 --> 00:22:01,440
how to

628
00:21:59,679 --> 00:22:03,280
start sanctioning the social media

629
00:22:01,440 --> 00:22:05,360
platforms if they don't comply

630
00:22:03,280 --> 00:22:07,600
with the rules and then what kind of

631
00:22:05,360 --> 00:22:11,600
sanctions would be appropriate you know

632
00:22:07,600 --> 00:22:14,959
a few several of thousands of euros

633
00:22:11,600 --> 00:22:18,480
is that enough for a multi-billion

634
00:22:14,960 --> 00:22:21,520
corporation should there be one fit

635
00:22:18,480 --> 00:22:23,760
um you know sanctioned to all

636
00:22:21,520 --> 00:22:25,520
platforms whether they're big or small

637
00:22:23,760 --> 00:22:27,120
applicable or

638
00:22:25,520 --> 00:22:29,760
you know what are the policies that you

639
00:22:27,120 --> 00:22:32,879
think that could be implemented

640
00:22:29,760 --> 00:22:34,799
in the in the measures

641
00:22:32,880 --> 00:22:36,240
this is going to be much of our

642
00:22:34,799 --> 00:22:39,039
discussion in coming uh

643
00:22:36,240 --> 00:22:40,720
weeks and months in the european

644
00:22:39,039 --> 00:22:41,360
institutions and especially in european

645
00:22:40,720 --> 00:22:44,960
parliament

646
00:22:41,360 --> 00:22:46,158
um and uh i think what claire has

647
00:22:44,960 --> 00:22:49,520
actually pointed out

648
00:22:46,159 --> 00:22:50,159
to uh uh is a baseline uh we need to

649
00:22:49,520 --> 00:22:52,720
have

650
00:22:50,159 --> 00:22:54,000
all platforms we need to help the whole

651
00:22:52,720 --> 00:22:56,960
ecosystem on board this

652
00:22:54,000 --> 00:22:57,520
is this is the baseline so you know uh

653
00:22:56,960 --> 00:22:59,280
um

654
00:22:57,520 --> 00:23:01,840
if you have a code of practice code of

655
00:22:59,280 --> 00:23:03,039
conduct it cannot be voluntary and it

656
00:23:01,840 --> 00:23:04,799
you know platforms

657
00:23:03,039 --> 00:23:06,879
some platforms can decide to take part

658
00:23:04,799 --> 00:23:07,440
in some platforms decide to take a free

659
00:23:06,880 --> 00:23:09,280
ride

660
00:23:07,440 --> 00:23:11,280
i think this is this is the baseline

661
00:23:09,280 --> 00:23:13,440
everybody has to be on board

662
00:23:11,280 --> 00:23:14,639
and of course then we need uh clear

663
00:23:13,440 --> 00:23:16,880
standards um

664
00:23:14,640 --> 00:23:18,320
and those standards have to do with the

665
00:23:16,880 --> 00:23:21,919
fact that uh

666
00:23:18,320 --> 00:23:24,879
um we have a clarity of uh

667
00:23:21,919 --> 00:23:26,320
information and data in terms of what

668
00:23:24,880 --> 00:23:27,840
the platforms actually do

669
00:23:26,320 --> 00:23:29,760
i mean the platforms actually provide

670
00:23:27,840 --> 00:23:31,600
some data to us already

671
00:23:29,760 --> 00:23:33,600
but we don't often understand the data

672
00:23:31,600 --> 00:23:36,000
they are not disaggregated

673
00:23:33,600 --> 00:23:37,520
so we don't really know what how how

674
00:23:36,000 --> 00:23:39,919
well the consumer

675
00:23:37,520 --> 00:23:41,679
uh is protected in germany and how well

676
00:23:39,919 --> 00:23:42,960
the consumer is protecting slovakia i

677
00:23:41,679 --> 00:23:45,200
think it's important

678
00:23:42,960 --> 00:23:46,320
that we have a baseline which protects

679
00:23:45,200 --> 00:23:50,080
um uh

680
00:23:46,320 --> 00:23:52,080
the user of uh the platforms um and

681
00:23:50,080 --> 00:23:53,760
the social media and of course the

682
00:23:52,080 --> 00:23:54,960
business environment which is online

683
00:23:53,760 --> 00:23:58,080
which is digital

684
00:23:54,960 --> 00:24:00,240
in a very equal way across the whole of

685
00:23:58,080 --> 00:24:01,918
the european union if we talk about the

686
00:24:00,240 --> 00:24:03,840
eu legislation

687
00:24:01,919 --> 00:24:05,440
so common standards and and the same

688
00:24:03,840 --> 00:24:09,199
level protection for everyone

689
00:24:05,440 --> 00:24:11,520
uh in uh the uh uh digital market

690
00:24:09,200 --> 00:24:13,600
across the europe single market i think

691
00:24:11,520 --> 00:24:15,039
this is this is essential uh and we need

692
00:24:13,600 --> 00:24:16,480
to have a lot more clarity and

693
00:24:15,039 --> 00:24:19,760
transparency on the data

694
00:24:16,480 --> 00:24:22,000
uh so in a sense we need to force

695
00:24:19,760 --> 00:24:23,039
the platforms uh to behave uh

696
00:24:22,000 --> 00:24:26,080
responsibly

697
00:24:23,039 --> 00:24:29,279
uh and not to produce um

698
00:24:26,080 --> 00:24:31,918
if i can use the economic uh language

699
00:24:29,279 --> 00:24:33,520
uh the negative externalities for the

700
00:24:31,919 --> 00:24:34,480
public space because this is what's

701
00:24:33,520 --> 00:24:37,520
happening

702
00:24:34,480 --> 00:24:39,440
um just like we regulate big business

703
00:24:37,520 --> 00:24:41,600
just like we regulate the banking sector

704
00:24:39,440 --> 00:24:42,720
just like we regulate much of the market

705
00:24:41,600 --> 00:24:44,559
because it produces

706
00:24:42,720 --> 00:24:47,039
things we don't like environmental

707
00:24:44,559 --> 00:24:48,320
damage for instance uh we must regulate

708
00:24:47,039 --> 00:24:51,279
the digital space

709
00:24:48,320 --> 00:24:52,240
so it uh uh serves us well and it has

710
00:24:51,279 --> 00:24:53,840
served us very well

711
00:24:52,240 --> 00:24:55,840
you know the digital revolution has been

712
00:24:53,840 --> 00:24:58,000
something many of us have welcomed

713
00:24:55,840 --> 00:25:00,399
uh but today we are critical because we

714
00:24:58,000 --> 00:25:01,120
also see that it produces a lot of

715
00:25:00,400 --> 00:25:04,640
problems

716
00:25:01,120 --> 00:25:06,719
for our daily lives yes people make

717
00:25:04,640 --> 00:25:07,679
huge sums of money of lies and

718
00:25:06,720 --> 00:25:10,159
disinformation

719
00:25:07,679 --> 00:25:12,320
but this information can also really

720
00:25:10,159 --> 00:25:14,880
destroy people's health people's

721
00:25:12,320 --> 00:25:17,120
lives our social and political

722
00:25:14,880 --> 00:25:20,320
environment and this is a huge problem

723
00:25:17,120 --> 00:25:23,678
um so uh yes uh we need regulation

724
00:25:20,320 --> 00:25:26,399
uh we need uh and we need to discuss um

725
00:25:23,679 --> 00:25:27,679
uh in in in detail uh what's the best

726
00:25:26,400 --> 00:25:30,000
way to approach this and that's

727
00:25:27,679 --> 00:25:31,360
that also includes sanctions but i you

728
00:25:30,000 --> 00:25:32,960
know i wouldn't start the political

729
00:25:31,360 --> 00:25:34,719
discussion with sanctions i think

730
00:25:32,960 --> 00:25:35,679
sanctions should be the last bit which

731
00:25:34,720 --> 00:25:37,440
we discuss

732
00:25:35,679 --> 00:25:39,600
and of course for all these rules to be

733
00:25:37,440 --> 00:25:42,880
effective uh we will need

734
00:25:39,600 --> 00:25:46,879
sanctions as well but but

735
00:25:42,880 --> 00:25:49,120
i would engage uh the business here

736
00:25:46,880 --> 00:25:50,159
in a way in which we engage any other

737
00:25:49,120 --> 00:25:53,520
business

738
00:25:50,159 --> 00:25:57,440
which produces a lot of

739
00:25:53,520 --> 00:25:58,559
public good but behaves also responsibly

740
00:25:57,440 --> 00:26:01,760
when it comes to

741
00:25:58,559 --> 00:26:04,399
uh the um all all the

742
00:26:01,760 --> 00:26:05,039
bad uh byproducts uh for the public

743
00:26:04,400 --> 00:26:06,880
space

744
00:26:05,039 --> 00:26:08,799
and i think this is where the platforms

745
00:26:06,880 --> 00:26:09,520
basically will not act on their own

746
00:26:08,799 --> 00:26:11,918
that's clear

747
00:26:09,520 --> 00:26:14,158
already unless we regulate unless we

748
00:26:11,919 --> 00:26:16,240
legislate and unless we

749
00:26:14,159 --> 00:26:17,200
engage very very seriously politically

750
00:26:16,240 --> 00:26:18,880
with this um

751
00:26:17,200 --> 00:26:20,880
and by the way and that's my last remark

752
00:26:18,880 --> 00:26:23,120
here this is not

753
00:26:20,880 --> 00:26:24,159
an issue for a few select policy makers

754
00:26:23,120 --> 00:26:25,678
this is not an issue

755
00:26:24,159 --> 00:26:27,600
which should concern us only when it

756
00:26:25,679 --> 00:26:30,080
comes to elections campaigns

757
00:26:27,600 --> 00:26:30,719
or big scandals this is something which

758
00:26:30,080 --> 00:26:35,039
should uh

759
00:26:30,720 --> 00:26:37,039
become uh the way a part of integral

760
00:26:35,039 --> 00:26:38,320
part of of our policy making when we

761
00:26:37,039 --> 00:26:41,360
think about um

762
00:26:38,320 --> 00:26:44,320
health policy social policy

763
00:26:41,360 --> 00:26:44,799
you know um all sorts of public policies

764
00:26:44,320 --> 00:26:46,720
uh we

765
00:26:44,799 --> 00:26:48,080
we need to think about the digital space

766
00:26:46,720 --> 00:26:50,240
the online space

767
00:26:48,080 --> 00:26:51,360
uh because of course this is where much

768
00:26:50,240 --> 00:26:53,840
of it uh

769
00:26:51,360 --> 00:26:54,799
takes place in terms of the interaction

770
00:26:53,840 --> 00:26:57,120
the information

771
00:26:54,799 --> 00:26:58,320
but also the business which is done

772
00:26:57,120 --> 00:27:01,120
alongside it and

773
00:26:58,320 --> 00:27:01,760
and we simply cannot create policies now

774
00:27:01,120 --> 00:27:07,840
without

775
00:27:01,760 --> 00:27:07,840
regulating the digital space

776
00:27:08,080 --> 00:27:12,559
we see that some social media platforms

777
00:27:10,960 --> 00:27:14,320
are already taking some measures but of

778
00:27:12,559 --> 00:27:16,559
course the spread of this information is

779
00:27:14,320 --> 00:27:17,600
not just about the social media

780
00:27:16,559 --> 00:27:20,960
platforms but

781
00:27:17,600 --> 00:27:24,320
um you know we see that uh

782
00:27:20,960 --> 00:27:25,120
google for example will stop uh putting

783
00:27:24,320 --> 00:27:27,039
ads on

784
00:27:25,120 --> 00:27:28,479
websites that have been known to spread

785
00:27:27,039 --> 00:27:31,440
this information

786
00:27:28,480 --> 00:27:33,600
uh but you know it's not just about that

787
00:27:31,440 --> 00:27:35,039
you know is it enough

788
00:27:33,600 --> 00:27:36,799
we don't know we don't know how

789
00:27:35,039 --> 00:27:39,120
effective that is going to be

790
00:27:36,799 --> 00:27:39,918
we don't know uh whether the data

791
00:27:39,120 --> 00:27:42,479
provided for

792
00:27:39,919 --> 00:27:43,679
by them or by facebook and other social

793
00:27:42,480 --> 00:27:46,799
media platforms

794
00:27:43,679 --> 00:27:49,840
is uh going to be relevant and um

795
00:27:46,799 --> 00:27:52,240
you know trustful let's say uh

796
00:27:49,840 --> 00:27:53,520
but we've seen both claire and and

797
00:27:52,240 --> 00:27:56,399
vladimir talk about

798
00:27:53,520 --> 00:27:57,120
setting a certain standards and and uh

799
00:27:56,399 --> 00:28:01,120
principles

800
00:27:57,120 --> 00:28:03,279
in the european uh information space but

801
00:28:01,120 --> 00:28:04,639
we see that a lot of these social media

802
00:28:03,279 --> 00:28:06,799
platforms are actually based in the

803
00:28:04,640 --> 00:28:08,559
united states where around the space

804
00:28:06,799 --> 00:28:09,918
so my question to you is do you think

805
00:28:08,559 --> 00:28:13,678
that there is a possibility

806
00:28:09,919 --> 00:28:18,080
to set common uh transatlantic

807
00:28:13,679 --> 00:28:20,960
standards you know and um

808
00:28:18,080 --> 00:28:21,678
enhance these principles that could be

809
00:28:20,960 --> 00:28:24,880
founded

810
00:28:21,679 --> 00:28:28,159
and established by the european union uh

811
00:28:24,880 --> 00:28:30,159
on the uh in america or in canada how do

812
00:28:28,159 --> 00:28:32,799
you think that this

813
00:28:30,159 --> 00:28:34,480
legislation could be established or is

814
00:28:32,799 --> 00:28:37,360
there a possibility that

815
00:28:34,480 --> 00:28:39,440
the legislation in europe and the united

816
00:28:37,360 --> 00:28:41,520
states would be compatible

817
00:28:39,440 --> 00:28:43,600
or you know there's a different

818
00:28:41,520 --> 00:28:45,200
perception on how

819
00:28:43,600 --> 00:28:48,480
this information should be dealt with on

820
00:28:45,200 --> 00:28:48,480
the other side of the atlantic

821
00:28:49,440 --> 00:28:52,640
well part of the you know part of the

822
00:28:50,880 --> 00:28:54,240
problem with regulation

823
00:28:52,640 --> 00:28:56,720
and policy and everything else is that

824
00:28:54,240 --> 00:28:58,320
the people who tend to make those

825
00:28:56,720 --> 00:29:00,080
they don't have they don't have a very

826
00:28:58,320 --> 00:29:00,879
clear idea or understanding of what it

827
00:29:00,080 --> 00:29:04,320
takes to actually

828
00:29:00,880 --> 00:29:06,000
implement them so you know the technical

829
00:29:04,320 --> 00:29:07,678
problems with implementing different

830
00:29:06,000 --> 00:29:09,120
types of regulation and legislation i

831
00:29:07,679 --> 00:29:10,399
mean you go to the banking industry yes

832
00:29:09,120 --> 00:29:11,918
when people make regulations in the

833
00:29:10,399 --> 00:29:13,520
banking industry they have a good idea

834
00:29:11,919 --> 00:29:14,320
how to actually technically implement

835
00:29:13,520 --> 00:29:16,639
them

836
00:29:14,320 --> 00:29:17,360
but in this area there's a lot of

837
00:29:16,640 --> 00:29:19,279
unknowns

838
00:29:17,360 --> 00:29:20,559
about how you would implement any policy

839
00:29:19,279 --> 00:29:22,480
so

840
00:29:20,559 --> 00:29:24,158
unless unless government is so or

841
00:29:22,480 --> 00:29:25,120
somebody is willing to invest serious

842
00:29:24,159 --> 00:29:27,120
dollars

843
00:29:25,120 --> 00:29:29,360
in actually developing the technology

844
00:29:27,120 --> 00:29:31,199
that you need to implement the policy

845
00:29:29,360 --> 00:29:32,639
the policy is pretty meaningless i mean

846
00:29:31,200 --> 00:29:33,279
some of this stuff has german stuff that

847
00:29:32,640 --> 00:29:34,720
i've seen

848
00:29:33,279 --> 00:29:36,960
i mean it's ridiculous there's no way to

849
00:29:34,720 --> 00:29:38,320
implement any of it i mean so

850
00:29:36,960 --> 00:29:40,080
since there is no way to actually

851
00:29:38,320 --> 00:29:40,799
implement it technically in a reasonable

852
00:29:40,080 --> 00:29:42,720
way

853
00:29:40,799 --> 00:29:43,840
the application of the policies tends to

854
00:29:42,720 --> 00:29:46,240
be well

855
00:29:43,840 --> 00:29:47,600
not very effective so that's one big

856
00:29:46,240 --> 00:29:50,000
problem

857
00:29:47,600 --> 00:29:52,080
um the other problem is you know like

858
00:29:50,000 --> 00:29:54,080
you say cooperation across well

859
00:29:52,080 --> 00:29:55,279
it's just a global issue the space is

860
00:29:54,080 --> 00:29:57,279
global and unless you're

861
00:29:55,279 --> 00:30:00,080
unless countries are ready to just block

862
00:29:57,279 --> 00:30:02,399
out everybody else like the chinese

863
00:30:00,080 --> 00:30:04,320
then you have to have cooperation and

864
00:30:02,399 --> 00:30:05,600
that's a really big problem because even

865
00:30:04,320 --> 00:30:06,559
within certainly within the united

866
00:30:05,600 --> 00:30:08,639
states

867
00:30:06,559 --> 00:30:10,720
i mean there doesn't seem to be any sign

868
00:30:08,640 --> 00:30:14,559
of anybody doing anything in any kind of

869
00:30:10,720 --> 00:30:18,399
an organized way to deal with issues

870
00:30:14,559 --> 00:30:19,918
so i yeah i don't know but but i i still

871
00:30:18,399 --> 00:30:23,120
emphasize the technical

872
00:30:19,919 --> 00:30:23,679
the technical the technology required to

873
00:30:23,120 --> 00:30:26,239
implement

874
00:30:23,679 --> 00:30:27,679
policy unless you use that develop that

875
00:30:26,240 --> 00:30:28,880
together with the policies the policies

876
00:30:27,679 --> 00:30:31,120
will be meaningless

877
00:30:28,880 --> 00:30:32,399
and the regulations so that's really a

878
00:30:31,120 --> 00:30:36,239
big problem and i've seen this

879
00:30:32,399 --> 00:30:38,959
in many cases this is a very interesting

880
00:30:36,240 --> 00:30:38,960
notion that's why

881
00:30:39,360 --> 00:30:42,799
uh that's why i would like to follow up

882
00:30:40,960 --> 00:30:44,080
you know like okay you you talk about

883
00:30:42,799 --> 00:30:47,200
technical issues

884
00:30:44,080 --> 00:30:48,960
that we need can you name some uh

885
00:30:47,200 --> 00:30:51,520
you know because we have a policy maker

886
00:30:48,960 --> 00:30:55,279
vladimir is there so he can develop some

887
00:30:51,520 --> 00:30:58,320
and or suggest development of some so

888
00:30:55,279 --> 00:31:00,159
can you can you really name few

889
00:30:58,320 --> 00:31:02,399
technical implications that need to be

890
00:31:00,159 --> 00:31:02,399
done

891
00:31:02,799 --> 00:31:06,639
well detecting detecting this first of

892
00:31:04,960 --> 00:31:08,720
all defining this information and then

893
00:31:06,640 --> 00:31:12,080
detecting it at scale

894
00:31:08,720 --> 00:31:14,240
is an unsolved problem okay

895
00:31:12,080 --> 00:31:15,199
i mean people do this by hand okay

896
00:31:14,240 --> 00:31:16,559
there's a lot of people out there

897
00:31:15,200 --> 00:31:18,960
tracing this stuff by hand but that's

898
00:31:16,559 --> 00:31:22,399
limited

899
00:31:18,960 --> 00:31:24,240
the the enormous volume is involved

900
00:31:22,399 --> 00:31:25,840
you can never keep up with it by hand by

901
00:31:24,240 --> 00:31:27,519
the limited tools that people are using

902
00:31:25,840 --> 00:31:29,360
today

903
00:31:27,519 --> 00:31:30,880
so so that's just one problem even

904
00:31:29,360 --> 00:31:32,559
defining what you mean

905
00:31:30,880 --> 00:31:34,000
and then actually developing means to

906
00:31:32,559 --> 00:31:36,000
detect it at scale

907
00:31:34,000 --> 00:31:37,679
which those things don't exist at the

908
00:31:36,000 --> 00:31:41,279
moment so that's just

909
00:31:37,679 --> 00:31:44,720
an example of a problem and you know

910
00:31:41,279 --> 00:31:44,720
how you disrupt the flow of it

911
00:31:45,039 --> 00:31:50,559
yeah okay go ahead uh vladimir you

912
00:31:48,000 --> 00:31:53,279
wanted to point out something

913
00:31:50,559 --> 00:31:54,240
uh i think this is a look um what what

914
00:31:53,279 --> 00:31:56,559
brand is

915
00:31:54,240 --> 00:31:57,279
basically opening up is the cracks of

916
00:31:56,559 --> 00:32:01,120
the matter

917
00:31:57,279 --> 00:32:03,760
um and i agree uh we need electric

918
00:32:01,120 --> 00:32:04,479
mission uh we need rose to be ultimately

919
00:32:03,760 --> 00:32:07,840
effective

920
00:32:04,480 --> 00:32:10,960
uh but you know my point is

921
00:32:07,840 --> 00:32:12,158
we've done this in other industries this

922
00:32:10,960 --> 00:32:14,559
is a whole new area

923
00:32:12,159 --> 00:32:16,080
technologically also politically also in

924
00:32:14,559 --> 00:32:17,200
terms of the implications

925
00:32:16,080 --> 00:32:18,559
we are all excited about new

926
00:32:17,200 --> 00:32:19,919
technologies we are all excited about

927
00:32:18,559 --> 00:32:22,080
the digital space

928
00:32:19,919 --> 00:32:24,159
we you know cannot imagine our lives

929
00:32:22,080 --> 00:32:25,840
without online and digital you know this

930
00:32:24,159 --> 00:32:27,279
is taking place online digital and

931
00:32:25,840 --> 00:32:29,279
thanks for that

932
00:32:27,279 --> 00:32:30,720
we have the pandemic but we can we can

933
00:32:29,279 --> 00:32:32,159
still do this and have this wonderful

934
00:32:30,720 --> 00:32:33,440
exchange many people can watch and

935
00:32:32,159 --> 00:32:35,919
that's good

936
00:32:33,440 --> 00:32:38,399
so there are many advantages but clearly

937
00:32:35,919 --> 00:32:41,360
uh the digital space has also brought

938
00:32:38,399 --> 00:32:42,639
a number of huge problems uh for our

939
00:32:41,360 --> 00:32:46,080
daily lives

940
00:32:42,640 --> 00:32:47,760
for business uh proper business contact

941
00:32:46,080 --> 00:32:49,678
proper proper market conduct and of

942
00:32:47,760 --> 00:32:52,799
course for uh political lives of

943
00:32:49,679 --> 00:32:54,799
democracies for instance um and yes

944
00:32:52,799 --> 00:32:57,519
we've always had this information here

945
00:32:54,799 --> 00:32:59,600
uh we just need to find a way how we

946
00:32:57,519 --> 00:33:02,559
face it and how we fight it

947
00:32:59,600 --> 00:33:03,199
in this new space i do believe it is

948
00:33:02,559 --> 00:33:05,440
possible

949
00:33:03,200 --> 00:33:07,600
uh we need to have a very honest

950
00:33:05,440 --> 00:33:08,399
conversation as policy makers so we need

951
00:33:07,600 --> 00:33:11,918
to have

952
00:33:08,399 --> 00:33:13,360
a very honest and also um responsible

953
00:33:11,919 --> 00:33:16,640
approach by the platforms

954
00:33:13,360 --> 00:33:19,678
um you know the platforms out there uh

955
00:33:16,640 --> 00:33:23,279
as as huge players affecting um

956
00:33:19,679 --> 00:33:26,000
today uh the flow of information uh

957
00:33:23,279 --> 00:33:28,080
way beyond uh what perhaps was

958
00:33:26,000 --> 00:33:30,480
imaginable couple of decades ago

959
00:33:28,080 --> 00:33:31,360
uh i do believe that platforms must be

960
00:33:30,480 --> 00:33:34,240
responsible

961
00:33:31,360 --> 00:33:35,439
for the content that they spread uh now

962
00:33:34,240 --> 00:33:38,159
we can discuss

963
00:33:35,440 --> 00:33:40,000
how exactly this this this this is

964
00:33:38,159 --> 00:33:42,960
defined and and how exactly

965
00:33:40,000 --> 00:33:44,880
this is done uh in practice uh but uh

966
00:33:42,960 --> 00:33:46,399
you know just like uh new york times

967
00:33:44,880 --> 00:33:49,760
will not spread any news

968
00:33:46,399 --> 00:33:51,439
uh the platforms uh uh have become uh

969
00:33:49,760 --> 00:33:52,960
real powerhouses when it comes to the

970
00:33:51,440 --> 00:33:54,720
spread of information

971
00:33:52,960 --> 00:33:56,559
and this information and they simply

972
00:33:54,720 --> 00:33:58,159
have to be responsible and we have to

973
00:33:56,559 --> 00:33:59,760
hold them to account

974
00:33:58,159 --> 00:34:01,360
a lot of this can be done and should be

975
00:33:59,760 --> 00:34:02,879
done by people um

976
00:34:01,360 --> 00:34:04,639
we need to know what the platforms are

977
00:34:02,880 --> 00:34:06,000
doing i have no idea how many fact

978
00:34:04,640 --> 00:34:08,560
checkers facebook has these

979
00:34:06,000 --> 00:34:09,280
days that's the basic piece of data we

980
00:34:08,560 --> 00:34:12,719
are missing

981
00:34:09,280 --> 00:34:14,800
for instance we have no idea how

982
00:34:12,719 --> 00:34:16,319
the algorithm which the facebook uses

983
00:34:14,800 --> 00:34:19,760
for spreading information

984
00:34:16,320 --> 00:34:20,399
and misinformation and this information

985
00:34:19,760 --> 00:34:23,839
actually

986
00:34:20,399 --> 00:34:25,040
uh uh works um so so we need a lot more

987
00:34:23,839 --> 00:34:28,078
transparency here

988
00:34:25,040 --> 00:34:29,599
um and this is all a matter uh for uh

989
00:34:28,079 --> 00:34:31,520
honest discussion

990
00:34:29,599 --> 00:34:34,000
and ultimately a good piece of

991
00:34:31,520 --> 00:34:36,719
legislation now digital services act

992
00:34:34,000 --> 00:34:37,199
um and and of course other measures

993
00:34:36,719 --> 00:34:39,839
which

994
00:34:37,199 --> 00:34:40,319
which we'll discuss and consider are our

995
00:34:39,839 --> 00:34:43,199
first

996
00:34:40,320 --> 00:34:43,760
important step um and i'm sure you know

997
00:34:43,199 --> 00:34:45,759
uh

998
00:34:43,760 --> 00:34:47,119
as as we've done with other industries

999
00:34:45,760 --> 00:34:49,839
uh we will

1000
00:34:47,119 --> 00:34:50,240
we will evolve in this area as well uh

1001
00:34:49,839 --> 00:34:53,359
but

1002
00:34:50,239 --> 00:34:56,479
uh i believe we must start um it's

1003
00:34:53,359 --> 00:34:57,839
uh uh it's it's high task and if we

1004
00:34:56,480 --> 00:34:59,680
cannot do it globally and i

1005
00:34:57,839 --> 00:35:01,359
agree this is a huge challenge we must

1006
00:34:59,680 --> 00:35:02,078
start within europe and and i think

1007
00:35:01,359 --> 00:35:04,560
europe

1008
00:35:02,079 --> 00:35:05,520
can lead and should lead the way here uh

1009
00:35:04,560 --> 00:35:07,440
so this is our

1010
00:35:05,520 --> 00:35:09,599
policy-making task and of course we'll

1011
00:35:07,440 --> 00:35:11,599
engage with

1012
00:35:09,599 --> 00:35:13,200
the business environment we'll engage

1013
00:35:11,599 --> 00:35:15,119
with those who who understand

1014
00:35:13,200 --> 00:35:18,240
technologies in discussing

1015
00:35:15,119 --> 00:35:19,760
uh policy making and rule making in a

1016
00:35:18,240 --> 00:35:22,399
way which will

1017
00:35:19,760 --> 00:35:23,440
improve the quality of our life on

1018
00:35:22,400 --> 00:35:26,960
social platforms

1019
00:35:23,440 --> 00:35:29,440
and also improve the quality of

1020
00:35:26,960 --> 00:35:29,440
information

1021
00:35:29,599 --> 00:35:32,720
but you know i have to say but the

1022
00:35:31,119 --> 00:35:34,720
question is is the government ready to

1023
00:35:32,720 --> 00:35:35,520
put money into developing the necessary

1024
00:35:34,720 --> 00:35:38,560
technology

1025
00:35:35,520 --> 00:35:39,440
because so far it doesn't exist and the

1026
00:35:38,560 --> 00:35:41,440
funding

1027
00:35:39,440 --> 00:35:44,560
that's necessary to develop this kind of

1028
00:35:41,440 --> 00:35:46,960
technology i don't see it coming and so

1029
00:35:44,560 --> 00:35:48,720
you know it's hard to take all of this

1030
00:35:46,960 --> 00:35:50,320
talk about regulation and policy very

1031
00:35:48,720 --> 00:35:52,160
seriously i have to say because

1032
00:35:50,320 --> 00:35:53,839
if there's no way to implement it you

1033
00:35:52,160 --> 00:35:55,680
know in other industries that technology

1034
00:35:53,839 --> 00:35:57,040
exists to implement policies

1035
00:35:55,680 --> 00:35:59,040
related to them in this industry it

1036
00:35:57,040 --> 00:36:01,119
simply doesn't exist for example you

1037
00:35:59,040 --> 00:36:03,279
talk about fact checking

1038
00:36:01,119 --> 00:36:05,200
i can show you two stories with exactly

1039
00:36:03,280 --> 00:36:06,400
the same facts which tell exactly the

1040
00:36:05,200 --> 00:36:08,720
opposite story

1041
00:36:06,400 --> 00:36:10,720
what do you do with that so right now

1042
00:36:08,720 --> 00:36:11,680
there's actually no way to automatically

1043
00:36:10,720 --> 00:36:13,200
detect that

1044
00:36:11,680 --> 00:36:14,879
and until you can automatically detect

1045
00:36:13,200 --> 00:36:17,118
that fact checking has a

1046
00:36:14,880 --> 00:36:19,200
limited value even if you could do it at

1047
00:36:17,119 --> 00:36:20,400
scale which you can't at the moment but

1048
00:36:19,200 --> 00:36:22,078
even if you could

1049
00:36:20,400 --> 00:36:24,480
it's still only limited value because

1050
00:36:22,079 --> 00:36:25,440
you can't there's no way at the moment

1051
00:36:24,480 --> 00:36:27,119
to interpret

1052
00:36:25,440 --> 00:36:28,880
to look at how are the facts being

1053
00:36:27,119 --> 00:36:31,920
twisted and used to tell a story

1054
00:36:28,880 --> 00:36:35,200
it was a completely separate problem so

1055
00:36:31,920 --> 00:36:36,560
and then another great example

1056
00:36:35,200 --> 00:36:39,439
i believe that claire wanted to see

1057
00:36:36,560 --> 00:36:40,320
something yeah i wanted to try and cheer

1058
00:36:39,440 --> 00:36:42,480
rand up

1059
00:36:40,320 --> 00:36:44,480
uh because i think uh i think the

1060
00:36:42,480 --> 00:36:46,160
situation is not as hopeless as perhaps

1061
00:36:44,480 --> 00:36:49,119
rand thinks it is

1062
00:36:46,160 --> 00:36:49,839
uh there this is exactly what we do at

1063
00:36:49,119 --> 00:36:53,440
gdi

1064
00:36:49,839 --> 00:36:54,240
we can detect a conspiratorial

1065
00:36:53,440 --> 00:36:56,880
narratives

1066
00:36:54,240 --> 00:36:58,959
at scale using ai so we use a

1067
00:36:56,880 --> 00:37:01,040
combination of artificial intelligence

1068
00:36:58,960 --> 00:37:02,720
and human review where human review is

1069
00:37:01,040 --> 00:37:05,119
is required because you're right there

1070
00:37:02,720 --> 00:37:06,240
are times when an algorithm is never

1071
00:37:05,119 --> 00:37:07,040
going to be able to pick up the

1072
00:37:06,240 --> 00:37:10,319
subtleties

1073
00:37:07,040 --> 00:37:11,520
of uh pernicious types of manipulated

1074
00:37:10,320 --> 00:37:14,079
content

1075
00:37:11,520 --> 00:37:14,720
but there you this is a tractable

1076
00:37:14,079 --> 00:37:16,960
problem

1077
00:37:14,720 --> 00:37:19,200
there are uh the majority of

1078
00:37:16,960 --> 00:37:21,760
disinformation that we see

1079
00:37:19,200 --> 00:37:23,279
comes from a fairly small number of

1080
00:37:21,760 --> 00:37:24,400
sites we're only looking at the english

1081
00:37:23,280 --> 00:37:26,240
language at the moment

1082
00:37:24,400 --> 00:37:28,000
but the english language is the biggest

1083
00:37:26,240 --> 00:37:31,759
market for disinformation

1084
00:37:28,000 --> 00:37:34,960
globally so you can look for

1085
00:37:31,760 --> 00:37:36,000
narratives and topics that frequently

1086
00:37:34,960 --> 00:37:39,839
appear and you can

1087
00:37:36,000 --> 00:37:42,560
do that at scale so you can look for

1088
00:37:39,839 --> 00:37:44,000
coded 19 disinformation you can look for

1089
00:37:42,560 --> 00:37:46,480
anti-black lives matter

1090
00:37:44,000 --> 00:37:48,160
topics and you can very accurately

1091
00:37:46,480 --> 00:37:51,200
detect with an algorithm

1092
00:37:48,160 --> 00:37:52,640
through a a a combination of the way the

1093
00:37:51,200 --> 00:37:54,879
language is written

1094
00:37:52,640 --> 00:37:55,920
and the type of site it's on whether or

1095
00:37:54,880 --> 00:37:58,560
not it's going to be

1096
00:37:55,920 --> 00:37:59,760
higher risk of disinforming and all

1097
00:37:58,560 --> 00:38:02,560
you're looking for here

1098
00:37:59,760 --> 00:38:03,359
is not an absolute this is definitely

1099
00:38:02,560 --> 00:38:04,799
false

1100
00:38:03,359 --> 00:38:06,799
what you're looking for when you're

1101
00:38:04,800 --> 00:38:09,760
trying to defund this information

1102
00:38:06,800 --> 00:38:11,760
is is this a high risk site is it the

1103
00:38:09,760 --> 00:38:13,040
sort of place an advertiser would want

1104
00:38:11,760 --> 00:38:15,119
to have their brand

1105
00:38:13,040 --> 00:38:17,279
you then give that risk rating to the

1106
00:38:15,119 --> 00:38:20,000
advertiser in real time

1107
00:38:17,280 --> 00:38:21,520
in the ad bidding system and allow the

1108
00:38:20,000 --> 00:38:23,200
advertiser to choose

1109
00:38:21,520 --> 00:38:25,359
this is too high risk for me i don't

1110
00:38:23,200 --> 00:38:26,560
want my ad here or i'm fine with this

1111
00:38:25,359 --> 00:38:29,279
level of risk

1112
00:38:26,560 --> 00:38:30,320
my ad can go here so it is a tractable

1113
00:38:29,280 --> 00:38:34,560
problem

1114
00:38:30,320 --> 00:38:34,560
at least at the level of defunding it

1115
00:38:35,359 --> 00:38:39,119
well so so what about the advertisers

1116
00:38:37,440 --> 00:38:41,119
themselves i mean you're talking about

1117
00:38:39,119 --> 00:38:42,480
the sites but i mean if i'm an ad if i

1118
00:38:41,119 --> 00:38:44,160
want to really spread something i'm

1119
00:38:42,480 --> 00:38:46,079
going to be the advertiser

1120
00:38:44,160 --> 00:38:47,839
i mean i'm placing my ads in all kinds

1121
00:38:46,079 --> 00:38:49,119
of fun places to do all kinds of things

1122
00:38:47,839 --> 00:38:51,040
so

1123
00:38:49,119 --> 00:38:52,800
you know i i mean i don't know i i

1124
00:38:51,040 --> 00:38:54,560
manage a 50 million dollar program in

1125
00:38:52,800 --> 00:38:56,720
technology development to this thing and

1126
00:38:54,560 --> 00:38:57,839
i so far i haven't seen okay you can do

1127
00:38:56,720 --> 00:38:59,439
some things

1128
00:38:57,839 --> 00:39:01,119
but the problem is far from inside just

1129
00:38:59,440 --> 00:39:02,400
for example measures of effectiveness of

1130
00:39:01,119 --> 00:39:04,240
campaigns

1131
00:39:02,400 --> 00:39:05,520
that currently exist no good measures of

1132
00:39:04,240 --> 00:39:08,000
effectiveness

1133
00:39:05,520 --> 00:39:08,720
there's no way to tell for example at

1134
00:39:08,000 --> 00:39:12,000
the moment

1135
00:39:08,720 --> 00:39:14,399
really i mean in an automated

1136
00:39:12,000 --> 00:39:15,520
reliable way whether what i'm doing is

1137
00:39:14,400 --> 00:39:18,079
making any difference

1138
00:39:15,520 --> 00:39:19,280
so for example i can measure an effect

1139
00:39:18,079 --> 00:39:20,880
that's one thing

1140
00:39:19,280 --> 00:39:23,599
but how do i know the effect as a result

1141
00:39:20,880 --> 00:39:25,280
of my action so to measure effectiveness

1142
00:39:23,599 --> 00:39:27,200
i need i'm what i'm interested in is

1143
00:39:25,280 --> 00:39:29,040
how does my action actually contribute

1144
00:39:27,200 --> 00:39:31,279
to the effect happening

1145
00:39:29,040 --> 00:39:32,400
so so that's a pretty unexplored area at

1146
00:39:31,280 --> 00:39:34,079
the moment

1147
00:39:32,400 --> 00:39:35,520
so without this kind of stuff i mean you

1148
00:39:34,079 --> 00:39:36,480
can never really implement these things

1149
00:39:35,520 --> 00:39:39,200
well i i i

1150
00:39:36,480 --> 00:39:40,640
you can do some things sure i agree but

1151
00:39:39,200 --> 00:39:42,480
um

1152
00:39:40,640 --> 00:39:44,640
somebody can always outpace whatever you

1153
00:39:42,480 --> 00:39:46,400
do by hand i mean i

1154
00:39:44,640 --> 00:39:47,680
whatever whatever technology using right

1155
00:39:46,400 --> 00:39:50,079
now i mean there's always

1156
00:39:47,680 --> 00:39:51,440
ways to get around it and and it has to

1157
00:39:50,079 --> 00:39:54,960
be more effort put into

1158
00:39:51,440 --> 00:39:56,960
developing that kind of technology

1159
00:39:54,960 --> 00:39:59,040
i love the fact that everybody is super

1160
00:39:56,960 --> 00:40:02,000
passionate

1161
00:39:59,040 --> 00:40:03,119
i i absolutely agree that that we have

1162
00:40:02,000 --> 00:40:06,400
to do a lot more

1163
00:40:03,119 --> 00:40:10,240
and by um i think uh

1164
00:40:06,400 --> 00:40:14,079
the especially the pandemic uh and

1165
00:40:10,240 --> 00:40:16,000
the information we're getting uh

1166
00:40:14,079 --> 00:40:18,160
out of the pandemic and of course the

1167
00:40:16,000 --> 00:40:18,400
pandemic is not over it continues and we

1168
00:40:18,160 --> 00:40:21,440
are

1169
00:40:18,400 --> 00:40:24,880
starting to learn to live with it um uh

1170
00:40:21,440 --> 00:40:25,359
is is is really uh another game changer

1171
00:40:24,880 --> 00:40:29,040
in this

1172
00:40:25,359 --> 00:40:32,078
uh we are realizing how much damage uh

1173
00:40:29,040 --> 00:40:33,759
this information can do uh to our lives

1174
00:40:32,079 --> 00:40:35,599
and i think this is also catching a lot

1175
00:40:33,760 --> 00:40:38,720
of attention of governments

1176
00:40:35,599 --> 00:40:40,560
um i think the issue is becoming uh

1177
00:40:38,720 --> 00:40:43,680
politically more and more salient

1178
00:40:40,560 --> 00:40:46,160
uh we will certainly uh uh make sure

1179
00:40:43,680 --> 00:40:47,440
it does um and i think this will uh put

1180
00:40:46,160 --> 00:40:49,440
the pressure on the governments

1181
00:40:47,440 --> 00:40:51,119
uh both individually but mainly

1182
00:40:49,440 --> 00:40:51,599
collectively again i think this is where

1183
00:40:51,119 --> 00:40:53,839
we need

1184
00:40:51,599 --> 00:40:55,599
european action we need eu action we

1185
00:40:53,839 --> 00:40:56,240
need european money we need european

1186
00:40:55,599 --> 00:40:58,480
investment

1187
00:40:56,240 --> 00:40:59,279
um because this is going to be european

1188
00:40:58,480 --> 00:41:01,599
regulation

1189
00:40:59,280 --> 00:41:03,040
uh ultimately uh which will make sure

1190
00:41:01,599 --> 00:41:05,440
that we can implement it

1191
00:41:03,040 --> 00:41:06,880
so this is also one of our tasks ahead

1192
00:41:05,440 --> 00:41:09,599
of us

1193
00:41:06,880 --> 00:41:10,640
and sure technology will always be a

1194
00:41:09,599 --> 00:41:13,839
step ahead of us

1195
00:41:10,640 --> 00:41:16,400
but i think we've gotten way behind

1196
00:41:13,839 --> 00:41:18,078
the the technology and we've allowed uh

1197
00:41:16,400 --> 00:41:19,839
too much money to be made of and too

1198
00:41:18,079 --> 00:41:21,520
much damage to be done

1199
00:41:19,839 --> 00:41:22,960
through the spread of this information

1200
00:41:21,520 --> 00:41:23,759
so we really have to get serious about

1201
00:41:22,960 --> 00:41:26,960
this and

1202
00:41:23,760 --> 00:41:30,240
and and i'm hoping that uh

1203
00:41:26,960 --> 00:41:32,560
indeed we can have a very good start

1204
00:41:30,240 --> 00:41:33,279
here uh legislatively uh and also

1205
00:41:32,560 --> 00:41:36,560
politically

1206
00:41:33,280 --> 00:41:36,560
this coming fall next year

1207
00:41:37,839 --> 00:41:41,279
when it came to the time when we go to

1208
00:41:40,880 --> 00:41:45,599
the

1209
00:41:41,280 --> 00:41:48,720
questions from our audience um

1210
00:41:45,599 --> 00:41:48,720
we'll try to

1211
00:41:50,079 --> 00:41:53,599
get as many as possible okay we have one

1212
00:41:52,720 --> 00:41:56,640
question from

1213
00:41:53,599 --> 00:41:58,880
andre matishak that is address durant

1214
00:41:56,640 --> 00:42:00,960
it is less about monetization but more

1215
00:41:58,880 --> 00:42:03,680
about the political power of conspiracy

1216
00:42:00,960 --> 00:42:05,200
theories q unknown is relatively new

1217
00:42:03,680 --> 00:42:08,078
thing but quite successful

1218
00:42:05,200 --> 00:42:11,359
conspiratory movement how dangerous do

1219
00:42:08,079 --> 00:42:11,359
you think you anon is

1220
00:42:14,839 --> 00:42:19,520
is

1221
00:42:17,839 --> 00:42:22,560
okay and then we have another question

1222
00:42:19,520 --> 00:42:22,560
from in person

1223
00:42:25,680 --> 00:42:29,598
can you speak to your question yes sure

1224
00:42:28,640 --> 00:42:32,799
hi there hi

1225
00:42:29,599 --> 00:42:35,200
my name is um and actually

1226
00:42:32,800 --> 00:42:37,040
thank you so much for this very fruitful

1227
00:42:35,200 --> 00:42:38,799
discussion on this information and

1228
00:42:37,040 --> 00:42:41,359
potential solutions

1229
00:42:38,800 --> 00:42:43,280
um my question is to mr bill chick

1230
00:42:41,359 --> 00:42:45,440
because

1231
00:42:43,280 --> 00:42:48,160
now the talk within the european union

1232
00:42:45,440 --> 00:42:51,680
on the digital services act is actually

1233
00:42:48,160 --> 00:42:53,040
quite exciting but um i guess it's going

1234
00:42:51,680 --> 00:42:54,799
to be really important

1235
00:42:53,040 --> 00:42:56,400
what will be you know the crucial

1236
00:42:54,800 --> 00:42:59,280
parameters that this

1237
00:42:56,400 --> 00:43:00,000
sort of regulation will take so one of

1238
00:42:59,280 --> 00:43:01,920
the main

1239
00:43:00,000 --> 00:43:04,319
issues that is being discussed is

1240
00:43:01,920 --> 00:43:05,280
whether actually the liability rules for

1241
00:43:04,319 --> 00:43:08,240
online

1242
00:43:05,280 --> 00:43:09,599
intermediaries that is digital platforms

1243
00:43:08,240 --> 00:43:12,640
will actually need to be

1244
00:43:09,599 --> 00:43:13,280
updated or whether you think that the

1245
00:43:12,640 --> 00:43:16,078
current

1246
00:43:13,280 --> 00:43:18,560
state of affairs is sufficient thank you

1247
00:43:16,079 --> 00:43:18,560
so much

1248
00:43:21,280 --> 00:43:25,520
so we have two questions one from

1249
00:43:23,040 --> 00:43:27,359
miloslava

1250
00:43:25,520 --> 00:43:29,440
let's start with you but keep it please

1251
00:43:27,359 --> 00:43:32,078
short and then let's cover the question

1252
00:43:29,440 --> 00:43:33,920
for around about q anon

1253
00:43:32,079 --> 00:43:36,640
i will be very short i don't think uh

1254
00:43:33,920 --> 00:43:36,640
they are sufficient

1255
00:43:37,040 --> 00:43:41,599
that's very short okay i'll also be sure

1256
00:43:40,240 --> 00:43:44,399
two and i'm these are extremely

1257
00:43:41,599 --> 00:43:46,319
dangerous people

1258
00:43:44,400 --> 00:43:49,280
okay simply because they're selling

1259
00:43:46,319 --> 00:43:49,279
stuff people want to buy

1260
00:43:49,599 --> 00:43:54,640
okay um so since you're super

1261
00:43:52,800 --> 00:43:56,720
short and very effective in addressing

1262
00:43:54,640 --> 00:43:59,839
these questions let's go to

1263
00:43:56,720 --> 00:44:02,879
another question from the audience um

1264
00:43:59,839 --> 00:44:05,440
there's one question from craig

1265
00:44:02,880 --> 00:44:07,440
to you mr bilteek how are they how are

1266
00:44:05,440 --> 00:44:09,599
they working with tech platforms on

1267
00:44:07,440 --> 00:44:11,680
aligning their ad and content policies

1268
00:44:09,599 --> 00:44:13,280
to stop ad funded disinformation

1269
00:44:11,680 --> 00:44:15,359
i think that's uh dealt with the

1270
00:44:13,280 --> 00:44:17,280
european union so how is european union

1271
00:44:15,359 --> 00:44:22,078
working with tech platforms

1272
00:44:17,280 --> 00:44:24,640
on aligning their ads and content

1273
00:44:22,079 --> 00:44:25,440
i think this is going to be uh obviously

1274
00:44:24,640 --> 00:44:27,759
uh

1275
00:44:25,440 --> 00:44:28,560
the this is going to be a big task in

1276
00:44:27,760 --> 00:44:30,480
terms of

1277
00:44:28,560 --> 00:44:32,078
how we address this issue in a

1278
00:44:30,480 --> 00:44:33,040
comprehensive way through the digital

1279
00:44:32,079 --> 00:44:36,400
services act

1280
00:44:33,040 --> 00:44:38,319
um uh the discussions have been going on

1281
00:44:36,400 --> 00:44:40,160
at the level of the european union i

1282
00:44:38,319 --> 00:44:43,680
must say that um

1283
00:44:40,160 --> 00:44:45,040
uh um tech giants are and digital

1284
00:44:43,680 --> 00:44:47,759
platforms are very active

1285
00:44:45,040 --> 00:44:48,640
um in brussels um and so there is a big

1286
00:44:47,760 --> 00:44:52,240
conversation

1287
00:44:48,640 --> 00:44:53,680
uh going on and

1288
00:44:52,240 --> 00:44:55,359
i'm not going to give you an answer in

1289
00:44:53,680 --> 00:44:58,560
terms of how we're going to do this

1290
00:44:55,359 --> 00:45:00,480
but this needs to be part of the way how

1291
00:44:58,560 --> 00:45:03,680
we address

1292
00:45:00,480 --> 00:45:04,640
the proper digital space so uh to keep

1293
00:45:03,680 --> 00:45:07,680
this very short

1294
00:45:04,640 --> 00:45:11,279
uh we are in conversation uh and

1295
00:45:07,680 --> 00:45:11,919
uh i think um what we need to do is to

1296
00:45:11,280 --> 00:45:14,960
inject

1297
00:45:11,920 --> 00:45:16,720
a sense of proper uh public and

1298
00:45:14,960 --> 00:45:18,400
business-like responsibility when it

1299
00:45:16,720 --> 00:45:19,598
comes to digital space i think we need

1300
00:45:18,400 --> 00:45:21,520
this from everyone

1301
00:45:19,599 --> 00:45:23,280
and just like we've been able to achieve

1302
00:45:21,520 --> 00:45:26,319
it offline we have to

1303
00:45:23,280 --> 00:45:26,319
achieve it also online

1304
00:45:27,520 --> 00:45:32,240
well thank you very much for your inputs

1305
00:45:30,000 --> 00:45:35,119
i mean we're at the end of our sessions

1306
00:45:32,240 --> 00:45:35,680
for me it was very interesting and i

1307
00:45:35,119 --> 00:45:38,240
loved that

1308
00:45:35,680 --> 00:45:38,799
everybody was so enthusiastic and you

1309
00:45:38,240 --> 00:45:41,040
could see

1310
00:45:38,800 --> 00:45:43,119
it by the fact that we were jumping

1311
00:45:41,040 --> 00:45:46,400
sometimes into each other's

1312
00:45:43,119 --> 00:45:50,480
uh you know um

1313
00:45:46,400 --> 00:45:53,680
sessions or attempts to answer uh

1314
00:45:50,480 --> 00:45:55,119
the questions um i will remember

1315
00:45:53,680 --> 00:45:56,799
and take from the session the fact that

1316
00:45:55,119 --> 00:46:00,079
we need to

1317
00:45:56,800 --> 00:46:04,480
start hacking upgrade our hacking

1318
00:46:00,079 --> 00:46:07,599
skills upgrade our technological

1319
00:46:04,480 --> 00:46:10,800
capacities we need to set common

1320
00:46:07,599 --> 00:46:14,079
regulation common standards come on

1321
00:46:10,800 --> 00:46:16,880
you know um policy

1322
00:46:14,079 --> 00:46:18,160
so that we understand each other and we

1323
00:46:16,880 --> 00:46:20,640
need to cooperate

1324
00:46:18,160 --> 00:46:21,279
uh first possibly on the european level

1325
00:46:20,640 --> 00:46:24,440
and then

1326
00:46:21,280 --> 00:46:25,599
uh enlarge this cooperation to the uh

1327
00:46:24,440 --> 00:46:29,599
transatlantic

1328
00:46:25,599 --> 00:46:32,240
uh um space um

1329
00:46:29,599 --> 00:46:33,280
i'm very happy that you were able to uh

1330
00:46:32,240 --> 00:46:35,118
join me today

1331
00:46:33,280 --> 00:46:36,319
i'll i want to thank you very much for

1332
00:46:35,119 --> 00:46:39,040
your candor and

1333
00:46:36,319 --> 00:46:40,480
invigorating uh ideas i would like to

1334
00:46:39,040 --> 00:46:43,599
thank vladimir biltzig

1335
00:46:40,480 --> 00:46:46,000
rand balzman and claire melfort for

1336
00:46:43,599 --> 00:46:49,200
joining me today for this debate

1337
00:46:46,000 --> 00:46:49,760
i i hope and i think that we provided a

1338
00:46:49,200 --> 00:46:52,399
lot of

1339
00:46:49,760 --> 00:46:54,160
interesting information for you that

1340
00:46:52,400 --> 00:46:56,480
could be implemented

1341
00:46:54,160 --> 00:46:57,440
you know at the european level and could

1342
00:46:56,480 --> 00:47:00,000
inspire

1343
00:46:57,440 --> 00:47:01,440
uh some of the policies established at

1344
00:47:00,000 --> 00:47:04,000
the

1345
00:47:01,440 --> 00:47:06,000
european union or by the european union

1346
00:47:04,000 --> 00:47:09,040
um

1347
00:47:06,000 --> 00:47:10,400
please stay tuned for our sessions

1348
00:47:09,040 --> 00:47:12,880
because we continue

1349
00:47:10,400 --> 00:47:14,160
our next session is going to be covered

1350
00:47:12,880 --> 00:47:16,560
covering belarus

1351
00:47:14,160 --> 00:47:19,118
and it's titled crafting a transatlantic

1352
00:47:16,560 --> 00:47:22,400
response to the challenge of belarus

1353
00:47:19,119 --> 00:47:25,599
it starts at 7 pm central european time

1354
00:47:22,400 --> 00:47:29,440
so please stay tuned

1355
00:47:25,599 --> 00:47:30,160
and stay safe stay home and i hope to

1356
00:47:29,440 --> 00:47:32,240
see you

1357
00:47:30,160 --> 00:47:34,000
sometimes in future in person and hope

1358
00:47:32,240 --> 00:47:36,640
to continue with this debate

1359
00:47:34,000 --> 00:47:39,839
in person when the pandemic is over

1360
00:47:36,640 --> 00:47:39,839
thank you very much

1361
00:47:40,620 --> 00:47:43,719
[Music]

1362
00:47:46,740 --> 00:47:52,649
[Music]

1363
00:47:54,559 --> 00:47:58,800
so yes the public can work together with

1364
00:47:56,880 --> 00:47:59,839
the private sector to secure our

1365
00:47:58,800 --> 00:48:02,720
infrastructure

1366
00:47:59,839 --> 00:48:04,558
and to help keep society safe in my job

1367
00:48:02,720 --> 00:48:06,959
with the united nations in fact bringing

1368
00:48:04,559 --> 00:48:08,319
public and private sector together is a

1369
00:48:06,960 --> 00:48:10,079
key part of it

1370
00:48:08,319 --> 00:48:12,079
technology is part of the problem but

1371
00:48:10,079 --> 00:48:14,000
it's also part of the solution

1372
00:48:12,079 --> 00:48:16,800
and it can only be part of the solution

1373
00:48:14,000 --> 00:48:16,800
when we have the private

