1
00:00:00,160 --> 00:00:03,679
energy and sustainability and global

2
00:00:02,480 --> 00:00:06,480
order

3
00:00:03,679 --> 00:00:07,520
we're always open for collaboration stay

4
00:00:06,480 --> 00:00:09,440
in touch with us

5
00:00:07,520 --> 00:00:12,239
do not hesitate to approach us with your

6
00:00:09,440 --> 00:00:14,160
thoughts ideas and suggestions

7
00:00:12,240 --> 00:00:15,679
and we promise you that you will hear

8
00:00:14,160 --> 00:00:17,840
from us regularly

9
00:00:15,679 --> 00:00:31,840
about our ideas and what we do to

10
00:00:17,840 --> 00:00:31,840
convert them into reality

11
00:00:32,740 --> 00:00:41,290
[Applause]

12
00:00:34,830 --> 00:00:41,290
[Music]

13
00:00:45,900 --> 00:00:48,960
[Music]

14
00:00:53,120 --> 00:00:57,280
welcome everyone and welcome to the last

15
00:00:55,360 --> 00:00:58,480
session today at gloucester digital

16
00:00:57,280 --> 00:01:00,320
stage

17
00:00:58,480 --> 00:01:02,160
my name is susana pison and i'm a

18
00:01:00,320 --> 00:01:03,680
technology stream lead at the globsec

19
00:01:02,160 --> 00:01:05,679
policy institute

20
00:01:03,680 --> 00:01:07,680
and it is my great pleasure to lead the

21
00:01:05,680 --> 00:01:10,400
following discussion on how automation

22
00:01:07,680 --> 00:01:12,000
will reshape the workforce of tomorrow

23
00:01:10,400 --> 00:01:13,920
first of all i would like to introduce

24
00:01:12,000 --> 00:01:16,240
my very special guest

25
00:01:13,920 --> 00:01:17,280
uh so we'll be speaking to geritrui nica

26
00:01:16,240 --> 00:01:19,280
de catellera

27
00:01:17,280 --> 00:01:20,799
she's a program director of artificial

28
00:01:19,280 --> 00:01:22,799
intelligence at imag

29
00:01:20,799 --> 00:01:24,240
which is an rd and innovation hub in

30
00:01:22,799 --> 00:01:25,439
nano electronics and digital

31
00:01:24,240 --> 00:01:28,720
technologies in

32
00:01:25,439 --> 00:01:29,839
the netherlands then we'll be speaking

33
00:01:28,720 --> 00:01:31,520
to pavel nick

34
00:01:29,840 --> 00:01:33,600
who's a country managing director

35
00:01:31,520 --> 00:01:35,600
slovakia at abb

36
00:01:33,600 --> 00:01:36,880
and he's also the manager of robotics

37
00:01:35,600 --> 00:01:40,000
for eastern europe at

38
00:01:36,880 --> 00:01:43,360
abb another guest is

39
00:01:40,000 --> 00:01:44,000
nikolai stroya soyano he's a policy

40
00:01:43,360 --> 00:01:46,640
officer

41
00:01:44,000 --> 00:01:47,759
uh at future of work uh at the european

42
00:01:46,640 --> 00:01:49,600
commission

43
00:01:47,759 --> 00:01:51,040
and last but not least we'll be speaking

44
00:01:49,600 --> 00:01:53,360
to david tinis

45
00:01:51,040 --> 00:01:54,960
who's an outgoing curity at the global

46
00:01:53,360 --> 00:01:57,119
shapers community

47
00:01:54,960 --> 00:01:58,960
so welcome everyone and thank you for

48
00:01:57,119 --> 00:02:00,880
joining us uh

49
00:01:58,960 --> 00:02:02,640
i also want to encourage our audience to

50
00:02:00,880 --> 00:02:05,280
ask questions and we'll be trying to

51
00:02:02,640 --> 00:02:07,920
answer them at the end of the discussion

52
00:02:05,280 --> 00:02:08,878
uh so now i would like to briefly

53
00:02:07,920 --> 00:02:11,760
introduce the top

54
00:02:08,878 --> 00:02:12,959
our topic today uh we have seen that the

55
00:02:11,760 --> 00:02:15,280
exponential growth of

56
00:02:12,959 --> 00:02:16,720
ai raised concern about job automation

57
00:02:15,280 --> 00:02:17,760
and the possibility of massive

58
00:02:16,720 --> 00:02:20,480
unemployment and

59
00:02:17,760 --> 00:02:21,840
widens widening skills gap these

60
00:02:20,480 --> 00:02:24,799
developments have been further

61
00:02:21,840 --> 00:02:26,879
exacerbated by the coming 19th pandemic

62
00:02:24,800 --> 00:02:28,800
with the accelerated digitalization and

63
00:02:26,879 --> 00:02:30,160
disruptions on the labor markets across

64
00:02:28,800 --> 00:02:32,400
the whole world

65
00:02:30,160 --> 00:02:33,519
so i would like to turn to you nikolai

66
00:02:32,400 --> 00:02:36,000
first to give us an

67
00:02:33,519 --> 00:02:37,920
overview of the situation in europe with

68
00:02:36,000 --> 00:02:40,080
regards to automation meaning like

69
00:02:37,920 --> 00:02:41,440
which types of jobs for example are for

70
00:02:40,080 --> 00:02:43,760
are most likely to be

71
00:02:41,440 --> 00:02:45,120
placed in europe and which roles have

72
00:02:43,760 --> 00:02:47,840
the lowest risk of being

73
00:02:45,120 --> 00:02:49,040
automated and you know these kind of

74
00:02:47,840 --> 00:02:50,720
general questions

75
00:02:49,040 --> 00:02:54,400
so that we know what is what is actually

76
00:02:50,720 --> 00:02:57,120
the situation in europe these days

77
00:02:54,400 --> 00:02:58,400
yes um thank you very much susana first

78
00:02:57,120 --> 00:03:00,959
of all i would like to thank you for

79
00:02:58,400 --> 00:03:02,720
inviting me to take part into this um

80
00:03:00,959 --> 00:03:05,360
very exciting and interesting panel

81
00:03:02,720 --> 00:03:07,920
and before i answer your question if i

82
00:03:05,360 --> 00:03:12,720
might make a rather generous

83
00:03:07,920 --> 00:03:12,720
statement about um exactly the sort of

84
00:03:12,959 --> 00:03:17,040
the sort of discourse which we have in

85
00:03:16,480 --> 00:03:19,679
europe

86
00:03:17,040 --> 00:03:21,359
about automation which is most of the

87
00:03:19,680 --> 00:03:23,280
time is about doom and gloom and that

88
00:03:21,360 --> 00:03:25,519
a lot of jobs will be lost and that

89
00:03:23,280 --> 00:03:27,840
basically masses of people will be left

90
00:03:25,519 --> 00:03:30,239
without anything to do unemployed

91
00:03:27,840 --> 00:03:31,920
and what we see is what we see and what

92
00:03:30,239 --> 00:03:33,280
we think actually is rather that this is

93
00:03:31,920 --> 00:03:35,599
not be the case as

94
00:03:33,280 --> 00:03:37,519
uh the ongoing wave of automation would

95
00:03:35,599 --> 00:03:39,119
most likely affect the specific tasks

96
00:03:37,519 --> 00:03:41,680
within jobs rather than

97
00:03:39,120 --> 00:03:42,959
replace jobs themselves and uh this of

98
00:03:41,680 --> 00:03:44,480
course if you look at the historical

99
00:03:42,959 --> 00:03:47,519
perspective it's not the first

100
00:03:44,480 --> 00:03:49,280
time when we see such a massive shift

101
00:03:47,519 --> 00:03:50,560
in the economic landscape i mean of

102
00:03:49,280 --> 00:03:51,440
course you have the industrial

103
00:03:50,560 --> 00:03:53,920
revolution

104
00:03:51,440 --> 00:03:54,640
switching from agriculture to to to to

105
00:03:53,920 --> 00:03:56,238
factories when

106
00:03:54,640 --> 00:03:58,399
a lot of people moved and then you had a

107
00:03:56,239 --> 00:04:00,720
lot of people moving from manufacturing

108
00:03:58,400 --> 00:04:01,519
to to services so from this point of

109
00:04:00,720 --> 00:04:04,720
view there is no

110
00:04:01,519 --> 00:04:07,280
there's not really um there is not um

111
00:04:04,720 --> 00:04:09,200
really an overwhelming cause for concern

112
00:04:07,280 --> 00:04:10,640
with regards to job losses but as you

113
00:04:09,200 --> 00:04:12,238
correctly pointed out we

114
00:04:10,640 --> 00:04:13,760
will be seeing some some shifts in the

115
00:04:12,239 --> 00:04:15,519
labor markets and

116
00:04:13,760 --> 00:04:17,519
if i look a little bit into the type of

117
00:04:15,519 --> 00:04:20,239
jobs that are threatened uh by

118
00:04:17,519 --> 00:04:22,160
automation by ai the newest um

119
00:04:20,238 --> 00:04:23,679
which is the newest exemplification of

120
00:04:22,160 --> 00:04:26,479
the digital revolution

121
00:04:23,680 --> 00:04:28,160
is it the sort of a routine uh or

122
00:04:26,479 --> 00:04:30,880
mundane rich

123
00:04:28,160 --> 00:04:33,040
task tasks such as for example

124
00:04:30,880 --> 00:04:34,159
analytical or administrative or clerical

125
00:04:33,040 --> 00:04:36,320
jobs where there's like highly

126
00:04:34,160 --> 00:04:38,800
repetitive or rules-based tasks so

127
00:04:36,320 --> 00:04:39,759
these are quite easily um quite easily

128
00:04:38,800 --> 00:04:41,440
automated

129
00:04:39,759 --> 00:04:43,759
and if you look a bit more specific this

130
00:04:41,440 --> 00:04:45,680
could be um professions like for example

131
00:04:43,759 --> 00:04:47,360
office assistants or people working in

132
00:04:45,680 --> 00:04:49,680
finance and accounting

133
00:04:47,360 --> 00:04:51,040
there is also um people working at

134
00:04:49,680 --> 00:04:53,360
cashiers or

135
00:04:51,040 --> 00:04:54,320
um drivers so on so forth which are

136
00:04:53,360 --> 00:04:56,479
really with

137
00:04:54,320 --> 00:04:57,680
jobs which are quite susceptible to

138
00:04:56,479 --> 00:04:59,599
automation

139
00:04:57,680 --> 00:05:01,840
and when we translate this into the sort

140
00:04:59,600 --> 00:05:03,360
of skills required which i'll come back

141
00:05:01,840 --> 00:05:05,359
to later on

142
00:05:03,360 --> 00:05:06,880
because the importance of skills is

143
00:05:05,360 --> 00:05:08,880
really uh cannot be

144
00:05:06,880 --> 00:05:10,320
overstated here in managing the

145
00:05:08,880 --> 00:05:12,080
transitions it's us

146
00:05:10,320 --> 00:05:14,080
we see that it's mostly low and medium

147
00:05:12,080 --> 00:05:15,440
skill jobs that are at higher risk of

148
00:05:14,080 --> 00:05:17,039
automation

149
00:05:15,440 --> 00:05:19,120
and on the other spectrum when you look

150
00:05:17,039 --> 00:05:21,280
at and when you look at jobs that are

151
00:05:19,120 --> 00:05:23,360
not so easily automatable or that not at

152
00:05:21,280 --> 00:05:24,880
high risk at this point in time because

153
00:05:23,360 --> 00:05:27,440
of course everything we speak depends on

154
00:05:24,880 --> 00:05:30,320
how technology ai develops which um

155
00:05:27,440 --> 00:05:31,919
i'm sure my my fellow panel speakers

156
00:05:30,320 --> 00:05:33,680
will also speak about

157
00:05:31,919 --> 00:05:34,960
is that we have these sort of jobs which

158
00:05:33,680 --> 00:05:37,919
are very rich in the

159
00:05:34,960 --> 00:05:38,560
sort of inherently human skills which is

160
00:05:37,919 --> 00:05:40,400
something like

161
00:05:38,560 --> 00:05:41,840
social intelligence or like the ability

162
00:05:40,400 --> 00:05:42,799
to negotiate complex social

163
00:05:41,840 --> 00:05:45,198
relationships

164
00:05:42,800 --> 00:05:45,840
for example if you care for others or if

165
00:05:45,199 --> 00:05:46,960
you manage

166
00:05:45,840 --> 00:05:49,119
if you have to manage cultural

167
00:05:46,960 --> 00:05:50,799
sensitivities or you have to lose a lot

168
00:05:49,120 --> 00:05:52,720
of cognitive challenges these are type

169
00:05:50,800 --> 00:05:54,560
of skills that are not very easily

170
00:05:52,720 --> 00:05:56,000
automatable so the type of jobs that

171
00:05:54,560 --> 00:05:58,960
rely on these will we

172
00:05:56,000 --> 00:06:00,000
will not be so much at risk and uh i

173
00:05:58,960 --> 00:06:02,799
think i'll stop here

174
00:06:00,000 --> 00:06:04,960
because i think i spoke quite well thank

175
00:06:02,800 --> 00:06:04,960
you

176
00:06:05,280 --> 00:06:11,359
thank you david uh do you have something

177
00:06:07,840 --> 00:06:13,599
to add to nikolai's perspective

178
00:06:11,360 --> 00:06:15,280
it was a great perspective first of all

179
00:06:13,600 --> 00:06:16,720
thank you for sharing nikolai and also

180
00:06:15,280 --> 00:06:19,440
thank you for the organizers for

181
00:06:16,720 --> 00:06:20,000
for inviting me maybe just to kind of

182
00:06:19,440 --> 00:06:21,440
sum up

183
00:06:20,000 --> 00:06:23,600
a bit some of the things nikolai said

184
00:06:21,440 --> 00:06:26,080
and maybe add a few numbers to it

185
00:06:23,600 --> 00:06:28,479
i've recently done some research around

186
00:06:26,080 --> 00:06:31,039
the topic of the the impact that the

187
00:06:28,479 --> 00:06:32,880
both automation the current crisis have

188
00:06:31,039 --> 00:06:35,199
has on jobs in europe

189
00:06:32,880 --> 00:06:36,560
and most of the let's say top-notch

190
00:06:35,199 --> 00:06:38,240
research has actually been done by

191
00:06:36,560 --> 00:06:40,560
mckinsey so i based some of these

192
00:06:38,240 --> 00:06:42,240
uh numbers i'm going to provide on their

193
00:06:40,560 --> 00:06:42,560
research the keynesian company has done

194
00:06:42,240 --> 00:06:44,720
some

195
00:06:42,560 --> 00:06:45,680
some great reports recently on on the

196
00:06:44,720 --> 00:06:47,360
subject

197
00:06:45,680 --> 00:06:49,039
and i think what's very important to

198
00:06:47,360 --> 00:06:50,800
realize is that automation is a threat

199
00:06:49,039 --> 00:06:53,680
and has been a threat however

200
00:06:50,800 --> 00:06:55,120
covet 19 has exponentially increased the

201
00:06:53,680 --> 00:06:56,560
risk of jobs being displaced by

202
00:06:55,120 --> 00:06:57,120
automation because there's also now a

203
00:06:56,560 --> 00:07:00,160
health

204
00:06:57,120 --> 00:07:02,080
element to it it's easier to um

205
00:07:00,160 --> 00:07:03,520
as let's say a manager of a warehouse

206
00:07:02,080 --> 00:07:06,639
it's easier to say well

207
00:07:03,520 --> 00:07:08,799
i will uh replace some humans with

208
00:07:06,639 --> 00:07:10,720
with robots now that there's you know

209
00:07:08,800 --> 00:07:12,240
social distancing or physical distancing

210
00:07:10,720 --> 00:07:14,560
in place there's definitely

211
00:07:12,240 --> 00:07:16,800
an impetus given to automation and just

212
00:07:14,560 --> 00:07:19,919
to give you a few numbers so

213
00:07:16,800 --> 00:07:20,560
at the moment um 51 million jobs

214
00:07:19,919 --> 00:07:22,719
according to

215
00:07:20,560 --> 00:07:24,319
the study i quoted from mckinsey 51

216
00:07:22,720 --> 00:07:25,440
million jobs in europe are at risk of

217
00:07:24,319 --> 00:07:27,840
automation

218
00:07:25,440 --> 00:07:30,000
and potentially 59 million are at risk

219
00:07:27,840 --> 00:07:33,520
because of the covet 19 crisis

220
00:07:30,000 --> 00:07:36,720
the problem is uh 24 million so

221
00:07:33,520 --> 00:07:37,599
uh one third of the the the the number i

222
00:07:36,720 --> 00:07:39,759
just mentioned

223
00:07:37,599 --> 00:07:41,680
oh sorry one fourth is actually at risk

224
00:07:39,759 --> 00:07:42,960
both of covet and automation so these

225
00:07:41,680 --> 00:07:44,479
are the jobs that i think already

226
00:07:42,960 --> 00:07:46,719
nikolai described

227
00:07:44,479 --> 00:07:47,840
jobs which which are at risk because

228
00:07:46,720 --> 00:07:50,560
they're you know

229
00:07:47,840 --> 00:07:50,960
physical jobs jobs because jobs at risk

230
00:07:50,560 --> 00:07:52,560
because

231
00:07:50,960 --> 00:07:54,479
they have a lot of interactions between

232
00:07:52,560 --> 00:07:56,160
human face-to-face interactions

233
00:07:54,479 --> 00:07:58,000
so i think what we have to keep in mind

234
00:07:56,160 --> 00:08:00,479
is that covet 19

235
00:07:58,000 --> 00:08:02,400
has exaggerated automation and also not

236
00:08:00,479 --> 00:08:04,318
just automation per se but also anxiety

237
00:08:02,400 --> 00:08:05,840
because of automation so i think

238
00:08:04,319 --> 00:08:07,840
going forward in this discussion we

239
00:08:05,840 --> 00:08:08,318
should definitely speak a bit about how

240
00:08:07,840 --> 00:08:10,400
to

241
00:08:08,319 --> 00:08:11,919
you know prepare people to be more

242
00:08:10,400 --> 00:08:12,479
emotionally and mentally balanced

243
00:08:11,919 --> 00:08:14,878
because

244
00:08:12,479 --> 00:08:16,479
one of the downsides of this uh as a

245
00:08:14,879 --> 00:08:19,440
crisis is the anxiety

246
00:08:16,479 --> 00:08:20,878
that has been uh created which is due to

247
00:08:19,440 --> 00:08:22,879
automation as well so

248
00:08:20,879 --> 00:08:24,400
happy to to bring back this topic when

249
00:08:22,879 --> 00:08:25,280
we speak about skills again with with

250
00:08:24,400 --> 00:08:28,560
nikolai

251
00:08:25,280 --> 00:08:29,520
thank you yes thank you very much for

252
00:08:28,560 --> 00:08:31,840
appointing this

253
00:08:29,520 --> 00:08:33,519
this aspect of the debate as well and

254
00:08:31,840 --> 00:08:36,000
i'm sure we'll come back to it

255
00:08:33,519 --> 00:08:36,959
uh i would like to give floor to to mika

256
00:08:36,000 --> 00:08:39,839
now who's

257
00:08:36,958 --> 00:08:41,359
an expert in ai and a very experienced

258
00:08:39,839 --> 00:08:44,399
researcher in the field

259
00:08:41,360 --> 00:08:46,080
and i would therefore ask like to ask

260
00:08:44,399 --> 00:08:47,519
her which business streams are most

261
00:08:46,080 --> 00:08:48,560
likely to capitalize on the new

262
00:08:47,519 --> 00:08:52,080
technologies

263
00:08:48,560 --> 00:08:54,319
such as ai and robotics

264
00:08:52,080 --> 00:08:55,519
yeah thanks first of all having me it's

265
00:08:54,320 --> 00:08:57,519
a great pleasure

266
00:08:55,519 --> 00:08:59,440
and indeed i'm just gonna align with my

267
00:08:57,519 --> 00:09:01,920
colleagues what they've already said um

268
00:08:59,440 --> 00:09:03,360
on a ai specific um there's some

269
00:09:01,920 --> 00:09:06,479
misunderstandings there i mean

270
00:09:03,360 --> 00:09:09,120
ai was originally created to to replace

271
00:09:06,480 --> 00:09:10,640
the ddd top so the dull dirty difficult

272
00:09:09,120 --> 00:09:13,360
and dangerous drops

273
00:09:10,640 --> 00:09:15,360
but ai can only be used in an area where

274
00:09:13,360 --> 00:09:16,480
automated decisions can have some

275
00:09:15,360 --> 00:09:18,720
uncertainty

276
00:09:16,480 --> 00:09:20,720
and this little thing seems to be lost

277
00:09:18,720 --> 00:09:22,480
if you want to have a decision automated

278
00:09:20,720 --> 00:09:23,600
that needs to have 100 accuracy

279
00:09:22,480 --> 00:09:26,080
it's not the place where you're going to

280
00:09:23,600 --> 00:09:28,320
use ai that's a limitation another

281
00:09:26,080 --> 00:09:30,800
limitation is the fact that ai

282
00:09:28,320 --> 00:09:32,000
is very good in learning and and you

283
00:09:30,800 --> 00:09:33,920
know learning new things

284
00:09:32,000 --> 00:09:35,279
but it's not very good in reasoning

285
00:09:33,920 --> 00:09:38,560
that's where ai

286
00:09:35,279 --> 00:09:41,279
is limited compared to human uh ability

287
00:09:38,560 --> 00:09:42,079
so if you look at profits and the

288
00:09:41,279 --> 00:09:44,160
situation

289
00:09:42,080 --> 00:09:45,920
you have seen that you know the context

290
00:09:44,160 --> 00:09:48,480
of the world has changed law

291
00:09:45,920 --> 00:09:50,000
and you know understanding that change

292
00:09:48,480 --> 00:09:52,560
requests some reasoning

293
00:09:50,000 --> 00:09:53,920
as an adaptation um you know in order to

294
00:09:52,560 --> 00:09:57,119
get an explanation

295
00:09:53,920 --> 00:09:58,959
ai is not there yet so if i look into

296
00:09:57,120 --> 00:10:02,240
what europe could help us with

297
00:09:58,959 --> 00:10:04,640
in the eye space is making sure

298
00:10:02,240 --> 00:10:05,600
that the adoption because it does create

299
00:10:04,640 --> 00:10:08,720
great value

300
00:10:05,600 --> 00:10:11,519
but that adoption uh get increased

301
00:10:08,720 --> 00:10:12,560
by putting on more focus on explainable

302
00:10:11,519 --> 00:10:14,720
ai

303
00:10:12,560 --> 00:10:16,800
you know just explaining why decisions

304
00:10:14,720 --> 00:10:19,200
are made making sure that people get

305
00:10:16,800 --> 00:10:20,160
less frustrated or less scared of the

306
00:10:19,200 --> 00:10:22,640
solutions

307
00:10:20,160 --> 00:10:24,079
but also the responsibility that needs

308
00:10:22,640 --> 00:10:25,839
to be taken by business

309
00:10:24,079 --> 00:10:27,599
because of the limitations i was saying

310
00:10:25,839 --> 00:10:29,680
the limitations at the level of

311
00:10:27,600 --> 00:10:30,959
the reasoning part changing context of

312
00:10:29,680 --> 00:10:33,279
the road which is not

313
00:10:30,959 --> 00:10:34,560
automatically picked up by ai and the

314
00:10:33,279 --> 00:10:36,880
fact that ai

315
00:10:34,560 --> 00:10:37,599
always works with a little uncertainty

316
00:10:36,880 --> 00:10:40,959
so

317
00:10:37,600 --> 00:10:41,519
these limitations are you know unknown

318
00:10:40,959 --> 00:10:43,920
to me

319
00:10:41,519 --> 00:10:44,640
and i think europe can help there to put

320
00:10:43,920 --> 00:10:46,800
some

321
00:10:44,640 --> 00:10:47,680
some principles in place to get this

322
00:10:46,800 --> 00:10:49,519
translation

323
00:10:47,680 --> 00:10:51,199
uh further just like we have when we

324
00:10:49,519 --> 00:10:52,160
take medication we get a leaflet

325
00:10:51,200 --> 00:10:54,800
explaining

326
00:10:52,160 --> 00:10:55,680
how it works what the dangers are how we

327
00:10:54,800 --> 00:10:57,839
have to you know

328
00:10:55,680 --> 00:10:59,199
what what products are in there i'd love

329
00:10:57,839 --> 00:11:01,440
to see the same on the eye

330
00:10:59,200 --> 00:11:03,680
so seeing what data was used where is it

331
00:11:01,440 --> 00:11:05,040
useful what are the potential risks

332
00:11:03,680 --> 00:11:08,959
when do you have to stop using the

333
00:11:05,040 --> 00:11:08,959
system etc that would be great

334
00:11:09,120 --> 00:11:12,880
yes which leads me to another question

335
00:11:11,200 --> 00:11:13,200
so what do you think which policies need

336
00:11:12,880 --> 00:11:15,120
to

337
00:11:13,200 --> 00:11:17,519
be put in place by national governments

338
00:11:15,120 --> 00:11:18,800
on the or the eu to help help address

339
00:11:17,519 --> 00:11:21,200
this is it just the

340
00:11:18,800 --> 00:11:22,160
the informational faction as as mikay

341
00:11:21,200 --> 00:11:25,120
just said or

342
00:11:22,160 --> 00:11:25,439
are there some some other potential uh

343
00:11:25,120 --> 00:11:27,839
uh

344
00:11:25,440 --> 00:11:28,720
aspects of the debate uh related to ai

345
00:11:27,839 --> 00:11:30,640
that the

346
00:11:28,720 --> 00:11:32,160
should be tackled by by upcoming

347
00:11:30,640 --> 00:11:33,439
regulations i think

348
00:11:32,160 --> 00:11:35,680
this could be an interesting question

349
00:11:33,440 --> 00:11:39,200
from who has a very unique

350
00:11:35,680 --> 00:11:39,199
from the private sector

351
00:11:39,360 --> 00:11:42,480
thank you first thanks also for inviting

352
00:11:41,360 --> 00:11:45,120
me for the panel

353
00:11:42,480 --> 00:11:47,040
um i would also first like to react what

354
00:11:45,120 --> 00:11:49,279
was said before

355
00:11:47,040 --> 00:11:51,920
the the threat of losing jobs i mean has

356
00:11:49,279 --> 00:11:53,120
been here since the first automation 200

357
00:11:51,920 --> 00:11:55,360
years ago

358
00:11:53,120 --> 00:11:56,560
and uh what we are what we are

359
00:11:55,360 --> 00:11:58,720
witnessing is

360
00:11:56,560 --> 00:12:00,560
that basically people are risking and

361
00:11:58,720 --> 00:12:03,440
what we what we will be

362
00:12:00,560 --> 00:12:04,800
witnessing uh in in the future that the

363
00:12:03,440 --> 00:12:07,600
risk link

364
00:12:04,800 --> 00:12:09,040
will be much faster than ever because it

365
00:12:07,600 --> 00:12:12,240
has something to do with this

366
00:12:09,040 --> 00:12:12,240
computing power and

367
00:12:13,040 --> 00:12:19,439
increase of the technology ability right

368
00:12:16,399 --> 00:12:21,040
so on one side we are replacing certain

369
00:12:19,440 --> 00:12:22,800
jobs with

370
00:12:21,040 --> 00:12:25,439
with automation on the other side there

371
00:12:22,800 --> 00:12:25,839
is demand for the for the new jobs and

372
00:12:25,440 --> 00:12:28,959
now

373
00:12:25,839 --> 00:12:29,680
the oecd before kovit actually estimated

374
00:12:28,959 --> 00:12:33,439
that

375
00:12:29,680 --> 00:12:35,439
in 2022 will be 133 million new jobs

376
00:12:33,440 --> 00:12:38,560
that didn't exist before

377
00:12:35,440 --> 00:12:41,120
and also uh this risk killing

378
00:12:38,560 --> 00:12:42,638
actually is going extremely fast so in

379
00:12:41,120 --> 00:12:45,680
10 years there is actually

380
00:12:42,639 --> 00:12:49,200
estimate that there will be one billion

381
00:12:45,680 --> 00:12:52,160
jobs needed with rescuing skills

382
00:12:49,200 --> 00:12:54,399
we are all actually being being taught

383
00:12:52,160 --> 00:12:55,040
by the new technologies voluntarily a

384
00:12:54,399 --> 00:12:58,320
lot

385
00:12:55,040 --> 00:13:01,839
with mobile phones and everything but

386
00:12:58,320 --> 00:13:03,680
this is basically where we are at the

387
00:13:01,839 --> 00:13:08,160
moment headed

388
00:13:03,680 --> 00:13:11,599
as for the as for the government's

389
00:13:08,160 --> 00:13:13,199
help or basically framework

390
00:13:11,600 --> 00:13:15,440
what we what we are actually witnessing

391
00:13:13,200 --> 00:13:17,360
is that the technology is much faster

392
00:13:15,440 --> 00:13:19,040
and what mika said about the artificial

393
00:13:17,360 --> 00:13:20,079
intelligence if you look at the most of

394
00:13:19,040 --> 00:13:22,480
the artificial

395
00:13:20,079 --> 00:13:23,439
intelligence applications and put into

396
00:13:22,480 --> 00:13:25,920
this

397
00:13:23,440 --> 00:13:26,560
gartner hype cycle we are still in the

398
00:13:25,920 --> 00:13:29,439
beginning

399
00:13:26,560 --> 00:13:31,040
so we haven't actually exploited the

400
00:13:29,440 --> 00:13:34,240
benefits

401
00:13:31,040 --> 00:13:37,439
commercially uh much

402
00:13:34,240 --> 00:13:39,360
so far but we are really on the start of

403
00:13:37,440 --> 00:13:40,639
exploring the artificial intelligence

404
00:13:39,360 --> 00:13:42,399
and of course i mean

405
00:13:40,639 --> 00:13:44,800
because the development is going so

406
00:13:42,399 --> 00:13:47,120
drastically fast

407
00:13:44,800 --> 00:13:48,639
uh the the states actually are always

408
00:13:47,120 --> 00:13:51,360
behind that

409
00:13:48,639 --> 00:13:52,399
so i don't see that there is actually

410
00:13:51,360 --> 00:13:55,519
much that the

411
00:13:52,399 --> 00:13:55,920
state can do uh in in kind of regulating

412
00:13:55,519 --> 00:13:58,240
it

413
00:13:55,920 --> 00:13:59,279
what we should actually make sure is

414
00:13:58,240 --> 00:14:01,760
that we enable

415
00:13:59,279 --> 00:14:02,959
people to absorb it so they are actually

416
00:14:01,760 --> 00:14:05,680
teaching

417
00:14:02,959 --> 00:14:07,040
uh quickly and they are flexible in in

418
00:14:05,680 --> 00:14:10,560
learning

419
00:14:07,040 --> 00:14:12,319
so that would be my point thank you

420
00:14:10,560 --> 00:14:14,399
pavel both you and i are based in

421
00:14:12,320 --> 00:14:16,160
slovakia in the heart of central europe

422
00:14:14,399 --> 00:14:17,360
which is very much dependent on the

423
00:14:16,160 --> 00:14:20,560
automotive sector

424
00:14:17,360 --> 00:14:22,720
which is under great risk of automation

425
00:14:20,560 --> 00:14:24,319
so what do you think what will what will

426
00:14:22,720 --> 00:14:26,079
the ai and robotics bring

427
00:14:24,320 --> 00:14:28,000
to to the region and what needs to

428
00:14:26,079 --> 00:14:31,519
happen in the region so that we can

429
00:14:28,000 --> 00:14:33,920
actually survive this transition

430
00:14:31,519 --> 00:14:35,440
i would say that we have to i've just

431
00:14:33,920 --> 00:14:36,079
repeat what i said basically because

432
00:14:35,440 --> 00:14:39,360
what we

433
00:14:36,079 --> 00:14:42,560
have to do is enable people to uh

434
00:14:39,360 --> 00:14:45,519
bring high added value so

435
00:14:42,560 --> 00:14:45,839
education is the key for me uh we will

436
00:14:45,519 --> 00:14:48,880
see

437
00:14:45,839 --> 00:14:51,360
actually that uh the automation

438
00:14:48,880 --> 00:14:53,040
and actually automotive is actually one

439
00:14:51,360 --> 00:14:55,600
of the pioneers and

440
00:14:53,040 --> 00:14:56,480
and a great exploiter of automation

441
00:14:55,600 --> 00:15:00,079
right

442
00:14:56,480 --> 00:15:02,399
and we really have to make sure that the

443
00:15:00,079 --> 00:15:03,680
what we have in central europe is the

444
00:15:02,399 --> 00:15:07,199
skilled

445
00:15:03,680 --> 00:15:09,839
uh labor force and then not only people

446
00:15:07,199 --> 00:15:10,880
in the in the automotive or car

447
00:15:09,839 --> 00:15:12,959
manufacturers

448
00:15:10,880 --> 00:15:13,920
companies the people that are working

449
00:15:12,959 --> 00:15:16,800
online

450
00:15:13,920 --> 00:15:18,560
but that we have actually r d and uh and

451
00:15:16,800 --> 00:15:22,079
people who can actually develop things

452
00:15:18,560 --> 00:15:25,518
right so yes we see actually

453
00:15:22,079 --> 00:15:28,239
general uh kind of hiccup

454
00:15:25,519 --> 00:15:30,160
in the in the automotive at the moment

455
00:15:28,240 --> 00:15:33,440
but it's also brought with certain

456
00:15:30,160 --> 00:15:35,439
uh uncertainty but i

457
00:15:33,440 --> 00:15:36,720
i don't think that it's actually it's

458
00:15:35,440 --> 00:15:38,240
the biggest problem i mean

459
00:15:36,720 --> 00:15:39,759
there will be disruption also in

460
00:15:38,240 --> 00:15:42,480
automotive i mean share

461
00:15:39,759 --> 00:15:43,440
the economy of cars sell driving cars

462
00:15:42,480 --> 00:15:48,880
and so on

463
00:15:43,440 --> 00:15:48,880
so but we will just have to deal with it

464
00:15:49,120 --> 00:15:54,079
yes and which leads me to another

465
00:15:51,839 --> 00:15:56,480
question directed at nikolai

466
00:15:54,079 --> 00:15:57,758
so can you please enlighten us what are

467
00:15:56,480 --> 00:16:00,320
the ongoing

468
00:15:57,759 --> 00:16:02,880
policy efforts on the eu level related

469
00:16:00,320 --> 00:16:05,600
to automation and the transformation of

470
00:16:02,880 --> 00:16:08,800
the labor market

471
00:16:05,600 --> 00:16:09,759
yeah sure uh first of all when we speak

472
00:16:08,800 --> 00:16:12,800
about our

473
00:16:09,759 --> 00:16:14,240
policy responses to the challenges um

474
00:16:12,800 --> 00:16:17,120
related to where in the sphere of

475
00:16:14,240 --> 00:16:19,920
employment in the social and employment

476
00:16:17,120 --> 00:16:21,440
aspects we have this sort of overall

477
00:16:19,920 --> 00:16:23,199
guiding framework which is the european

478
00:16:21,440 --> 00:16:23,839
pillar of social rights which is

479
00:16:23,199 --> 00:16:26,399
basically

480
00:16:23,839 --> 00:16:27,360
20 principles which call for a decent

481
00:16:26,399 --> 00:16:29,040
working condition

482
00:16:27,360 --> 00:16:31,279
social protection equal opportunities

483
00:16:29,040 --> 00:16:32,719
for all so this is the sort of

484
00:16:31,279 --> 00:16:34,800
guiding document that frames our

485
00:16:32,720 --> 00:16:37,199
discussions and if i have to speak a bit

486
00:16:34,800 --> 00:16:38,880
more um concretely about the

487
00:16:37,199 --> 00:16:41,599
ongoing or recent initiatives that we

488
00:16:38,880 --> 00:16:43,759
have as as was pointed out

489
00:16:41,600 --> 00:16:44,959
by by power but also uh the other

490
00:16:43,759 --> 00:16:46,800
colleagues um

491
00:16:44,959 --> 00:16:48,160
in the importance of skill we also

492
00:16:46,800 --> 00:16:49,839
recognize it in european level and

493
00:16:48,160 --> 00:16:50,800
that's why in the beginning of july we

494
00:16:49,839 --> 00:16:52,959
um

495
00:16:50,800 --> 00:16:54,880
we we launched the youth employment

496
00:16:52,959 --> 00:16:55,680
support package which among other things

497
00:16:54,880 --> 00:16:58,399
also focus

498
00:16:55,680 --> 00:16:59,439
on skills and which um with which we're

499
00:16:58,399 --> 00:17:01,519
taking action to give

500
00:16:59,440 --> 00:17:03,519
young people the support they need to to

501
00:17:01,519 --> 00:17:05,520
actually realize their full potential

502
00:17:03,519 --> 00:17:07,359
and deal with the challenges from the

503
00:17:05,520 --> 00:17:09,039
green and the digital transitions

504
00:17:07,359 --> 00:17:10,639
also we we launched at the same time the

505
00:17:09,039 --> 00:17:11,679
european skills agenda which is

506
00:17:10,640 --> 00:17:14,079
basically a

507
00:17:11,679 --> 00:17:15,919
five-year plan ahead to help individuals

508
00:17:14,079 --> 00:17:18,399
but also businesses to

509
00:17:15,919 --> 00:17:19,760
develop better better skills which are

510
00:17:18,400 --> 00:17:23,280
also

511
00:17:19,760 --> 00:17:26,000
uh which are also also key for for um

512
00:17:23,280 --> 00:17:26,639
tackling the challenges of automation as

513
00:17:26,000 --> 00:17:28,640
uh

514
00:17:26,640 --> 00:17:30,400
also something that connects quite well

515
00:17:28,640 --> 00:17:32,320
with what with what david said about the

516
00:17:30,400 --> 00:17:34,080
anxiety among some people

517
00:17:32,320 --> 00:17:35,918
about changes coming from automation but

518
00:17:34,080 --> 00:17:38,000
also what mikia mentioned about the sort

519
00:17:35,919 --> 00:17:40,080
of a framework needed to

520
00:17:38,000 --> 00:17:41,760
regulate to regulate or to deal with

521
00:17:40,080 --> 00:17:44,480
some aspects of ai

522
00:17:41,760 --> 00:17:46,000
uh colleagues are working on also on

523
00:17:44,480 --> 00:17:47,679
embracing the opportunities but also

524
00:17:46,000 --> 00:17:50,080
tackling the socioeconomic challenges

525
00:17:47,679 --> 00:17:50,960
coming from ai uh you might be aware

526
00:17:50,080 --> 00:17:54,080
there was a

527
00:17:50,960 --> 00:17:56,799
white paper launched in in february

528
00:17:54,080 --> 00:17:58,639
that um looks at how we can foster

529
00:17:56,799 --> 00:18:00,639
european ecosystems of excellence and

530
00:17:58,640 --> 00:18:03,360
trust when it comes to ai

531
00:18:00,640 --> 00:18:04,240
so um at the moment we are working on

532
00:18:03,360 --> 00:18:06,639
this and we we

533
00:18:04,240 --> 00:18:08,080
look forward to actually coming up with

534
00:18:06,640 --> 00:18:10,480
a more concrete

535
00:18:08,080 --> 00:18:11,520
framework in the beginning of 2021 which

536
00:18:10,480 --> 00:18:14,240
also the

537
00:18:11,520 --> 00:18:14,960
will be dealing with the socio-economic

538
00:18:14,240 --> 00:18:19,200
impacts of

539
00:18:14,960 --> 00:18:20,960
ai also we are working on if we focus on

540
00:18:19,200 --> 00:18:21,600
some of the new business models that are

541
00:18:20,960 --> 00:18:25,600
um

542
00:18:21,600 --> 00:18:27,520
that are um that are made available or

543
00:18:25,600 --> 00:18:29,678
made possible by by new technologies

544
00:18:27,520 --> 00:18:31,918
such as the platform economy platform

545
00:18:29,679 --> 00:18:33,360
work we are currently working on an

546
00:18:31,919 --> 00:18:35,520
initiative to improve the labor

547
00:18:33,360 --> 00:18:37,360
conditions in platform work

548
00:18:35,520 --> 00:18:38,799
which is also planned for next year

549
00:18:37,360 --> 00:18:39,840
basically where we look at how to

550
00:18:38,799 --> 00:18:41,200
achieve a

551
00:18:39,840 --> 00:18:42,720
more dignified transparent and

552
00:18:41,200 --> 00:18:44,799
predictable working conditions for

553
00:18:42,720 --> 00:18:45,360
people working in platform work and

554
00:18:44,799 --> 00:18:46,879
which are

555
00:18:45,360 --> 00:18:49,280
some of the people who are at the front

556
00:18:46,880 --> 00:18:51,360
lines now together with medics

557
00:18:49,280 --> 00:18:53,039
with the medical processor now uh

558
00:18:51,360 --> 00:18:55,199
providing so-called essential services

559
00:18:53,039 --> 00:18:56,879
no because when we were in lockdowns and

560
00:18:55,200 --> 00:18:58,320
people couldn't or wouldn't want to go

561
00:18:56,880 --> 00:19:00,160
to the supermarket

562
00:18:58,320 --> 00:19:01,918
i'm sure that most of us had at least

563
00:19:00,160 --> 00:19:04,320
once recently used the

564
00:19:01,919 --> 00:19:06,240
food delivery guys services so these are

565
00:19:04,320 --> 00:19:07,678
the these are the sort of um

566
00:19:06,240 --> 00:19:09,440
things we're looking into when it comes

567
00:19:07,679 --> 00:19:12,559
to platform work

568
00:19:09,440 --> 00:19:14,799
and um also um

569
00:19:12,559 --> 00:19:16,320
if i have to touch upon a little bit on

570
00:19:14,799 --> 00:19:19,039
what what um

571
00:19:16,320 --> 00:19:19,520
what what is the role of covet here in

572
00:19:19,039 --> 00:19:21,679
this

573
00:19:19,520 --> 00:19:23,200
of course as david mentioned it we

574
00:19:21,679 --> 00:19:25,679
indeed realize or

575
00:19:23,200 --> 00:19:27,760
recognize that this is it is a sort of

576
00:19:25,679 --> 00:19:30,080
accelerator and sort of a driver of

577
00:19:27,760 --> 00:19:32,080
changes or shifts we already see and as

578
00:19:30,080 --> 00:19:35,039
as david

579
00:19:32,080 --> 00:19:35,439
said uh i think in some sectors there is

580
00:19:35,039 --> 00:19:37,760
a

581
00:19:35,440 --> 00:19:39,679
really significant overlapping um the

582
00:19:37,760 --> 00:19:41,520
sort of jobs um

583
00:19:39,679 --> 00:19:43,600
that are threatened by both automation

584
00:19:41,520 --> 00:19:45,679
and uh and covet which is i think up to

585
00:19:43,600 --> 00:19:46,320
70 percent in the wholesale and retail

586
00:19:45,679 --> 00:19:49,200
uh

587
00:19:46,320 --> 00:19:50,720
sectors for example so this is uh this

588
00:19:49,200 --> 00:19:52,480
is indeed how it makes it all the more

589
00:19:50,720 --> 00:19:55,120
urgent to tackle the challenges that are

590
00:19:52,480 --> 00:19:56,720
stemming from automation

591
00:19:55,120 --> 00:19:58,479
and i think i'll stop here and i'll

592
00:19:56,720 --> 00:20:01,440
maybe come back

593
00:19:58,480 --> 00:20:02,000
yep sorry please yeah i want to turn the

594
00:20:01,440 --> 00:20:04,640
debate

595
00:20:02,000 --> 00:20:06,799
more uh again a bit more towards covet

596
00:20:04,640 --> 00:20:09,600
and i'd like to ask uh

597
00:20:06,799 --> 00:20:12,000
a question directly to david uh related

598
00:20:09,600 --> 00:20:12,799
to whether the eu has also responded to

599
00:20:12,000 --> 00:20:15,919
the

600
00:20:12,799 --> 00:20:17,918
uh the covet-induced situation on the

601
00:20:15,919 --> 00:20:19,760
labor markets with like some more let's

602
00:20:17,919 --> 00:20:23,679
say short-term measures so what has been

603
00:20:19,760 --> 00:20:23,679
kind of like the most immediate response

604
00:20:24,240 --> 00:20:27,280
i mean with all due respect i think this

605
00:20:25,919 --> 00:20:28,640
question should be posed to nikolai

606
00:20:27,280 --> 00:20:29,678
because he's representing the european

607
00:20:28,640 --> 00:20:32,000
commission

608
00:20:29,679 --> 00:20:33,200
uh i can define i can give an answer of

609
00:20:32,000 --> 00:20:35,120
course as well

610
00:20:33,200 --> 00:20:37,120
as a citizen in which i think definitely

611
00:20:35,120 --> 00:20:39,199
there's a lot more

612
00:20:37,120 --> 00:20:40,879
work to be done at the eu level when it

613
00:20:39,200 --> 00:20:43,679
comes to supporting each other

614
00:20:40,880 --> 00:20:44,559
as fellow european citizens we all seen

615
00:20:43,679 --> 00:20:46,640
how

616
00:20:44,559 --> 00:20:48,158
initially there was a slower response

617
00:20:46,640 --> 00:20:49,360
than we all have wanted to when it comes

618
00:20:48,159 --> 00:20:51,760
to supporting italy

619
00:20:49,360 --> 00:20:54,000
not just for uh their situation in terms

620
00:20:51,760 --> 00:20:56,080
of jobs and unemployment but

621
00:20:54,000 --> 00:20:57,919
the health crisis itself however the

622
00:20:56,080 --> 00:20:59,918
european commission and the uh

623
00:20:57,919 --> 00:21:01,919
from my perspective again as a citizen

624
00:20:59,919 --> 00:21:03,679
has stepped up since so it was a shaky

625
00:21:01,919 --> 00:21:04,320
beginning but since there has been a lot

626
00:21:03,679 --> 00:21:05,760
of

627
00:21:04,320 --> 00:21:07,520
interesting initiatives targeted

628
00:21:05,760 --> 00:21:08,158
especially to tackle unemployment and

629
00:21:07,520 --> 00:21:09,760
you know

630
00:21:08,159 --> 00:21:11,360
the european skills agenda which is

631
00:21:09,760 --> 00:21:12,960
being rehashed

632
00:21:11,360 --> 00:21:14,080
but again i would leave nikolai maybe to

633
00:21:12,960 --> 00:21:15,520
give more details because i don't want

634
00:21:14,080 --> 00:21:16,960
to steal the limelight since he's

635
00:21:15,520 --> 00:21:19,600
representing the european commission in

636
00:21:16,960 --> 00:21:19,600
this discussion

637
00:21:21,440 --> 00:21:26,320
yes thanks a lot david but as you as

638
00:21:24,480 --> 00:21:28,320
you correctly pointed out it was indeed

639
00:21:26,320 --> 00:21:29,918
challenging times in in the very

640
00:21:28,320 --> 00:21:32,399
beginning but

641
00:21:29,919 --> 00:21:33,919
a lot has been done since then if i can

642
00:21:32,400 --> 00:21:36,080
focus on a few things

643
00:21:33,919 --> 00:21:37,760
for example we were in the very

644
00:21:36,080 --> 00:21:39,360
beginning we launched the coronavirus

645
00:21:37,760 --> 00:21:41,120
response investment initiative which

646
00:21:39,360 --> 00:21:43,600
basically made uh

647
00:21:41,120 --> 00:21:44,879
made the use of available um cohesion

648
00:21:43,600 --> 00:21:46,719
and structural funding much more

649
00:21:44,880 --> 00:21:50,000
flexible and easy to respond

650
00:21:46,720 --> 00:21:52,559
also we had uh we launched quite

651
00:21:50,000 --> 00:21:54,159
quickly an instrument to support uh for

652
00:21:52,559 --> 00:21:57,120
example short-term schemes as

653
00:21:54,159 --> 00:21:58,480
susana pointed out the so-called support

654
00:21:57,120 --> 00:22:01,600
to mitigate unemployment

655
00:21:58,480 --> 00:22:02,960
risks and also i'm sure and i think you

656
00:22:01,600 --> 00:22:03,600
probably have already discussed this

657
00:22:02,960 --> 00:22:05,679
yesterday

658
00:22:03,600 --> 00:22:06,799
in one of the sessions is that there was

659
00:22:05,679 --> 00:22:09,440
really a

660
00:22:06,799 --> 00:22:10,480
a major major recovery package which was

661
00:22:09,440 --> 00:22:13,919
proposed in in the

662
00:22:10,480 --> 00:22:14,799
at the end of may and and um and this

663
00:22:13,919 --> 00:22:17,840
rubber stamped by

664
00:22:14,799 --> 00:22:19,440
european leaders in july these um which

665
00:22:17,840 --> 00:22:20,158
is the next generation eu which

666
00:22:19,440 --> 00:22:23,520
basically

667
00:22:20,159 --> 00:22:25,360
is is a huge uh financial investment in

668
00:22:23,520 --> 00:22:28,320
the recovery of the of the continent

669
00:22:25,360 --> 00:22:29,520
and which is also going to support uh

670
00:22:28,320 --> 00:22:30,799
tackling the challenges which we're

671
00:22:29,520 --> 00:22:33,200
speaking about so

672
00:22:30,799 --> 00:22:34,960
this is maybe just in a nutshell but uh

673
00:22:33,200 --> 00:22:37,679
there is a lot more being done

674
00:22:34,960 --> 00:22:38,240
and it's been uh quite busy times here i

675
00:22:37,679 --> 00:22:41,520
can say

676
00:22:38,240 --> 00:22:43,039
for us as well uh thank you very much

677
00:22:41,520 --> 00:22:45,440
gentlemen for your insight

678
00:22:43,039 --> 00:22:47,520
a really insightful overview of of the

679
00:22:45,440 --> 00:22:50,240
efforts being done on the eu level

680
00:22:47,520 --> 00:22:53,520
uh i would like to uh dig a bit deeper

681
00:22:50,240 --> 00:22:55,280
into the potential of ai

682
00:22:53,520 --> 00:22:57,200
and that would lead me to another

683
00:22:55,280 --> 00:23:00,158
question directed to me

684
00:22:57,200 --> 00:23:01,919
and can you could you please name one or

685
00:23:00,159 --> 00:23:03,280
two specific fields which will be most

686
00:23:01,919 --> 00:23:07,440
affected by ai

687
00:23:03,280 --> 00:23:09,440
in the nearest future yeah sure um and

688
00:23:07,440 --> 00:23:11,280
i'm allowing myself to pick into the

689
00:23:09,440 --> 00:23:12,480
cove discussion um because govi

690
00:23:11,280 --> 00:23:14,799
discussion

691
00:23:12,480 --> 00:23:15,600
shows also the limitation of ai in the

692
00:23:14,799 --> 00:23:18,000
sense that

693
00:23:15,600 --> 00:23:20,000
um if you look at the the algorithms

694
00:23:18,000 --> 00:23:22,799
that were created in the past by

695
00:23:20,000 --> 00:23:24,320
by amazon etc due to the changing

696
00:23:22,799 --> 00:23:25,679
shopping behavior they all had to be

697
00:23:24,320 --> 00:23:27,280
stopped i don't know if people are aware

698
00:23:25,679 --> 00:23:29,280
of this but a lot of algorithms

699
00:23:27,280 --> 00:23:30,559
went completely wrong in their

700
00:23:29,280 --> 00:23:32,799
propositions

701
00:23:30,559 --> 00:23:33,678
and which shows also the limitations of

702
00:23:32,799 --> 00:23:35,918
the ai from one

703
00:23:33,679 --> 00:23:37,039
perspective from another perspective we

704
00:23:35,919 --> 00:23:40,799
noticed um

705
00:23:37,039 --> 00:23:43,440
that the need for open data in order to

706
00:23:40,799 --> 00:23:43,918
have quicker insights you know about the

707
00:23:43,440 --> 00:23:46,559
place

708
00:23:43,919 --> 00:23:47,600
where covet was picking up quite hard

709
00:23:46,559 --> 00:23:50,080
that the need for

710
00:23:47,600 --> 00:23:50,639
this data platform's open data ethics by

711
00:23:50,080 --> 00:23:53,678
design

712
00:23:50,640 --> 00:23:54,720
trans uh transparency by design that uh

713
00:23:53,679 --> 00:23:56,799
this is something where

714
00:23:54,720 --> 00:23:58,880
europe can lead because we don't you

715
00:23:56,799 --> 00:24:00,879
know based on the gdpr we have a good

716
00:23:58,880 --> 00:24:02,159
you know baseline if we can build on

717
00:24:00,880 --> 00:24:05,600
this uh to go

718
00:24:02,159 --> 00:24:06,880
on uh and put best practices uh for ai

719
00:24:05,600 --> 00:24:09,120
cases here as well

720
00:24:06,880 --> 00:24:11,279
now talking about these limitations it's

721
00:24:09,120 --> 00:24:13,520
also interesting to look forward to

722
00:24:11,279 --> 00:24:14,559
you know what what are going to be the

723
00:24:13,520 --> 00:24:16,158
next um

724
00:24:14,559 --> 00:24:18,480
phases that are needed in order to make

725
00:24:16,159 --> 00:24:19,919
sure that ai is going to you know remain

726
00:24:18,480 --> 00:24:21,360
in the summer we are right now and the

727
00:24:19,919 --> 00:24:22,880
summer i mean is there's a lot of

728
00:24:21,360 --> 00:24:24,080
investment there's a lot of excitement

729
00:24:22,880 --> 00:24:26,480
etc

730
00:24:24,080 --> 00:24:27,120
so if we want to make sure that ai

731
00:24:26,480 --> 00:24:29,039
remains

732
00:24:27,120 --> 00:24:30,879
and brings more value there's three

733
00:24:29,039 --> 00:24:33,360
domains that we have to solve so the

734
00:24:30,880 --> 00:24:34,960
first one is the fact that ai

735
00:24:33,360 --> 00:24:37,279
people are not aware of this is

736
00:24:34,960 --> 00:24:39,200
consuming a huge amount of energy

737
00:24:37,279 --> 00:24:41,679
which of course is in conflict with our

738
00:24:39,200 --> 00:24:44,640
system well sustainability goals

739
00:24:41,679 --> 00:24:46,000
so from a certain level we have to look

740
00:24:44,640 --> 00:24:48,080
at you know reducing the

741
00:24:46,000 --> 00:24:49,200
energy level that our systems are using

742
00:24:48,080 --> 00:24:51,678
without touching

743
00:24:49,200 --> 00:24:53,760
the accuracy um in the decisions it's

744
00:24:51,679 --> 00:24:54,799
making so that's one area we have to

745
00:24:53,760 --> 00:24:57,600
focus on

746
00:24:54,799 --> 00:24:58,158
a second area we have to focus on um is

747
00:24:57,600 --> 00:25:00,480
on the

748
00:24:58,159 --> 00:25:02,799
very narrow functionality that we have

749
00:25:00,480 --> 00:25:03,360
you know ai is very good in a very small

750
00:25:02,799 --> 00:25:05,600
way

751
00:25:03,360 --> 00:25:07,760
but it doesn't allow us to incorporate

752
00:25:05,600 --> 00:25:09,439
these tests in in a complex world we're

753
00:25:07,760 --> 00:25:10,640
in so we need to broaden up the

754
00:25:09,440 --> 00:25:12,240
functionality level

755
00:25:10,640 --> 00:25:14,159
and make sure that these systems can

756
00:25:12,240 --> 00:25:16,559
collaborate first of all with each other

757
00:25:14,159 --> 00:25:18,960
so system two system but also a system

758
00:25:16,559 --> 00:25:21,279
to human so that's in the second area

759
00:25:18,960 --> 00:25:22,960
where we need to focus on and the third

760
00:25:21,279 --> 00:25:25,039
area is something that was already

761
00:25:22,960 --> 00:25:27,120
mentioned that's the trustworthiness

762
00:25:25,039 --> 00:25:29,600
if we are unable to create the trust

763
00:25:27,120 --> 00:25:32,559
level in the systems by making them more

764
00:25:29,600 --> 00:25:32,879
transparent explainable people will just

765
00:25:32,559 --> 00:25:35,200
not

766
00:25:32,880 --> 00:25:36,640
adopt them and i think and i'm

767
00:25:35,200 --> 00:25:39,520
absolutely believer that

768
00:25:36,640 --> 00:25:41,360
these three topics are very much close

769
00:25:39,520 --> 00:25:44,879
to the european

770
00:25:41,360 --> 00:25:47,120
right european i'd say dna

771
00:25:44,880 --> 00:25:48,799
um you know especially on energy energy

772
00:25:47,120 --> 00:25:51,039
efficiency i mean that's where we are

773
00:25:48,799 --> 00:25:53,840
squeezed between china and the us

774
00:25:51,039 --> 00:25:54,480
but we can make a leading uh you know

775
00:25:53,840 --> 00:25:57,199
region

776
00:25:54,480 --> 00:25:57,760
on a focus which is also aligned to you

777
00:25:57,200 --> 00:26:00,799
know the

778
00:25:57,760 --> 00:26:03,120
the grain deal green ai etc so

779
00:26:00,799 --> 00:26:04,639
it would be great to see some more work

780
00:26:03,120 --> 00:26:06,399
and some more focus on that part you

781
00:26:04,640 --> 00:26:09,120
know the link between sustainable

782
00:26:06,400 --> 00:26:10,720
uh sustainability and ai i think europe

783
00:26:09,120 --> 00:26:13,600
can really lean on this

784
00:26:10,720 --> 00:26:15,200
now if you ask me about the sectors um i

785
00:26:13,600 --> 00:26:18,639
think the sectors that

786
00:26:15,200 --> 00:26:20,880
are having a big um uh you know

787
00:26:18,640 --> 00:26:22,960
big demand for for the next generation

788
00:26:20,880 --> 00:26:25,919
ai is of course a health

789
00:26:22,960 --> 00:26:26,960
towards preventive ai and predictive and

790
00:26:25,919 --> 00:26:29,440
preventive ai

791
00:26:26,960 --> 00:26:31,200
personalized er sorry preventive health

792
00:26:29,440 --> 00:26:33,039
personalized health

793
00:26:31,200 --> 00:26:34,400
and the second one i'm seeing quite a

794
00:26:33,039 --> 00:26:36,158
lot and and

795
00:26:34,400 --> 00:26:37,600
quite a lot of initiatives as well also

796
00:26:36,159 --> 00:26:40,240
from a research perspective is

797
00:26:37,600 --> 00:26:42,480
everything brutally on the

798
00:26:40,240 --> 00:26:44,640
sustainability goals there's a huge

799
00:26:42,480 --> 00:26:45,840
area where ai can create a lot of

800
00:26:44,640 --> 00:26:47,440
benefits

801
00:26:45,840 --> 00:26:49,120
of course next to the general ones which

802
00:26:47,440 --> 00:26:50,640
are already ongoing manufacturing but

803
00:26:49,120 --> 00:26:53,840
these two areas

804
00:26:50,640 --> 00:26:56,320
um they will just really show the value

805
00:26:53,840 --> 00:26:58,240
that ai can bring a value which is not

806
00:26:56,320 --> 00:27:00,720
always transparent right now to the

807
00:26:58,240 --> 00:27:00,720
audience

808
00:27:00,799 --> 00:27:04,000
thank you very much mika uh pavel what

809
00:27:03,200 --> 00:27:06,080
do you think

810
00:27:04,000 --> 00:27:07,039
uh what do you think about me because he

811
00:27:06,080 --> 00:27:09,360
is regarding the

812
00:27:07,039 --> 00:27:10,720
the impact of ai on two sectors

813
00:27:09,360 --> 00:27:13,520
specifically in the healthcare

814
00:27:10,720 --> 00:27:14,880
sector and sustainability sector do you

815
00:27:13,520 --> 00:27:17,760
have something to add to that do you

816
00:27:14,880 --> 00:27:20,320
agree do you disagree

817
00:27:17,760 --> 00:27:21,279
no i'm not the ai expert but what we see

818
00:27:20,320 --> 00:27:24,879
is actually

819
00:27:21,279 --> 00:27:28,000
uh especially covet now open the new

820
00:27:24,880 --> 00:27:29,440
areas that were not really thought or or

821
00:27:28,000 --> 00:27:31,679
penetrated before

822
00:27:29,440 --> 00:27:32,799
so from this perspective i fully agree

823
00:27:31,679 --> 00:27:36,000
with that

824
00:27:32,799 --> 00:27:36,960
and uh i i already mentioned it i mean

825
00:27:36,000 --> 00:27:38,720
ai is on

826
00:27:36,960 --> 00:27:40,640
on the on the beginning of its

827
00:27:38,720 --> 00:27:42,399
exploration phase right i mean there are

828
00:27:40,640 --> 00:27:43,120
plenty of ideas what to do now there

829
00:27:42,399 --> 00:27:45,360
will be

830
00:27:43,120 --> 00:27:47,199
a little bit the face of frustration how

831
00:27:45,360 --> 00:27:51,039
to implement them properly

832
00:27:47,200 --> 00:27:54,640
but i think it it was also mentioned by

833
00:27:51,039 --> 00:27:56,960
by mikey that basically we still

834
00:27:54,640 --> 00:27:58,159
didn't penetrate the complex solution

835
00:27:56,960 --> 00:28:01,600
with ai

836
00:27:58,159 --> 00:28:03,840
and i think it will actually

837
00:28:01,600 --> 00:28:04,799
it might actually be one of the one of

838
00:28:03,840 --> 00:28:08,158
the

839
00:28:04,799 --> 00:28:10,399
deals that might actually help europe to

840
00:28:08,159 --> 00:28:12,799
to get where it used to be and where it

841
00:28:10,399 --> 00:28:15,760
belongs right because

842
00:28:12,799 --> 00:28:17,679
all this connected and the adaptability

843
00:28:15,760 --> 00:28:20,240
uh

844
00:28:17,679 --> 00:28:21,520
and facing new challenges is actually

845
00:28:20,240 --> 00:28:24,559
something that uh

846
00:28:21,520 --> 00:28:26,639
europe was proven by by centuries

847
00:28:24,559 --> 00:28:27,678
that we always managed right so

848
00:28:26,640 --> 00:28:30,799
hopefully this

849
00:28:27,679 --> 00:28:32,720
new challenge that was

850
00:28:30,799 --> 00:28:36,879
partly caused by or maybe speeded up by

851
00:28:32,720 --> 00:28:36,880
covet might actually help us to

852
00:28:37,039 --> 00:28:40,480
to bring us further as europa

853
00:28:42,399 --> 00:28:46,639
i also want to touch upon one important

854
00:28:44,720 --> 00:28:46,960
uh one other really important part of

855
00:28:46,640 --> 00:28:49,440
the

856
00:28:46,960 --> 00:28:50,640
the question the debate on automation

857
00:28:49,440 --> 00:28:53,760
which is the

858
00:28:50,640 --> 00:28:55,840
the the widening uh skills gap

859
00:28:53,760 --> 00:28:57,039
and uh therefore widening inequalities

860
00:28:55,840 --> 00:28:59,279
as well what is

861
00:28:57,039 --> 00:29:01,520
what are your your views on that and how

862
00:28:59,279 --> 00:29:03,440
can we how can you tackle that

863
00:29:01,520 --> 00:29:06,158
maybe that could be a question directed

864
00:29:03,440 --> 00:29:08,159
to nikolai what should we do about the

865
00:29:06,159 --> 00:29:10,080
the skills guys what would be the most

866
00:29:08,159 --> 00:29:11,600
most feasible policy solutions to that

867
00:29:10,080 --> 00:29:15,279
because it seems like it's

868
00:29:11,600 --> 00:29:15,279
kind of inevitable these days

869
00:29:16,080 --> 00:29:19,439
um yeah thank you susanna thank you for

870
00:29:18,000 --> 00:29:20,320
bringing up this question because it

871
00:29:19,440 --> 00:29:21,520
leads me to

872
00:29:20,320 --> 00:29:23,120
the aspects which you've already

873
00:29:21,520 --> 00:29:24,960
mentioned and it's indeed that if we

874
00:29:23,120 --> 00:29:26,399
want to

875
00:29:24,960 --> 00:29:28,559
make the best use of the of the

876
00:29:26,399 --> 00:29:30,239
opportunities so offered by ai and

877
00:29:28,559 --> 00:29:32,000
by the latest technologies of course we

878
00:29:30,240 --> 00:29:34,159
need to be sure that we are able to

879
00:29:32,000 --> 00:29:35,200
manage the transitions between certain

880
00:29:34,159 --> 00:29:38,159
jobs that uh

881
00:29:35,200 --> 00:29:38,799
that maintenance us as pavel pointed out

882
00:29:38,159 --> 00:29:40,399
earlier

883
00:29:38,799 --> 00:29:42,158
but indeed what we need to do as you

884
00:29:40,399 --> 00:29:43,199
said is to focus on skills and we need

885
00:29:42,159 --> 00:29:45,120
to focus on

886
00:29:43,200 --> 00:29:46,880
to to to focus on equipping the people

887
00:29:45,120 --> 00:29:48,158
with the with the skills they need to to

888
00:29:46,880 --> 00:29:50,720
succeed and

889
00:29:48,159 --> 00:29:52,399
these are as i had touched upon

890
00:29:50,720 --> 00:29:53,200
mentioned earlier these are the sort of

891
00:29:52,399 --> 00:29:54,799
um

892
00:29:53,200 --> 00:29:57,039
skills which are inherently human not

893
00:29:54,799 --> 00:29:58,960
such as ability to negotiate complex

894
00:29:57,039 --> 00:30:01,919
social relationships or to foster

895
00:29:58,960 --> 00:30:04,320
creative complexive reasonings a sort of

896
00:30:01,919 --> 00:30:06,640
soft skills transversal skills

897
00:30:04,320 --> 00:30:07,918
also general cognitive skills as mikey

898
00:30:06,640 --> 00:30:09,919
pointed out the

899
00:30:07,919 --> 00:30:11,520
ai machine learning now the latest

900
00:30:09,919 --> 00:30:13,200
exemplification of ai it's not really

901
00:30:11,520 --> 00:30:14,799
good at reasoning so uh

902
00:30:13,200 --> 00:30:16,640
these are the sort of skills that we

903
00:30:14,799 --> 00:30:19,440
need to really um

904
00:30:16,640 --> 00:30:21,120
sort of underline also uh beyond these

905
00:30:19,440 --> 00:30:23,279
skills you also need to

906
00:30:21,120 --> 00:30:25,120
actually focus and what we're also doing

907
00:30:23,279 --> 00:30:26,480
at trying to promote the european level

908
00:30:25,120 --> 00:30:28,080
is to focus on

909
00:30:26,480 --> 00:30:30,480
the pressing need to support people with

910
00:30:28,080 --> 00:30:32,480
insufficient basic skills which are uh

911
00:30:30,480 --> 00:30:34,320
which are basic digital digital skills

912
00:30:32,480 --> 00:30:36,320
but also basic reading and literacy

913
00:30:34,320 --> 00:30:38,000
skills which surprisingly if

914
00:30:36,320 --> 00:30:39,678
if you're unaware it's really one in

915
00:30:38,000 --> 00:30:40,399
five europeans are still struggling with

916
00:30:39,679 --> 00:30:43,279
reading

917
00:30:40,399 --> 00:30:44,719
or or writing and 42 percent of eu

918
00:30:43,279 --> 00:30:46,960
citizens they they like at least

919
00:30:44,720 --> 00:30:48,480
basic digital skills so you can you can

920
00:30:46,960 --> 00:30:50,640
imagine in this

921
00:30:48,480 --> 00:30:52,960
people with poor literacy and numeracy

922
00:30:50,640 --> 00:30:54,640
or lacking digital skills finding a job

923
00:30:52,960 --> 00:30:55,919
in this new economy so it's not going to

924
00:30:54,640 --> 00:30:57,279
be hard but it's not going to be

925
00:30:55,919 --> 00:30:59,519
impossible so

926
00:30:57,279 --> 00:31:04,399
these are the sort of um skills and

927
00:30:59,519 --> 00:31:06,480
challenges that we're thinking towards

928
00:31:04,399 --> 00:31:08,239
thank you very much we have we actually

929
00:31:06,480 --> 00:31:10,320
had a question from the audience

930
00:31:08,240 --> 00:31:12,240
which is actually very much linked to

931
00:31:10,320 --> 00:31:13,840
the the solutions to the potential

932
00:31:12,240 --> 00:31:15,600
digital device as well

933
00:31:13,840 --> 00:31:16,879
and the question is actually directed to

934
00:31:15,600 --> 00:31:19,678
every speaker

935
00:31:16,880 --> 00:31:21,600
and the question is whether the

936
00:31:19,679 --> 00:31:22,480
universal basic income can become

937
00:31:21,600 --> 00:31:24,559
necessary

938
00:31:22,480 --> 00:31:26,880
to ensure continued demand for output

939
00:31:24,559 --> 00:31:29,918
and a sustainable society

940
00:31:26,880 --> 00:31:32,559
if yes why and if not why so

941
00:31:29,919 --> 00:31:33,600
let's open up the question of uh ubi i'm

942
00:31:32,559 --> 00:31:35,918
sure that's uh

943
00:31:33,600 --> 00:31:36,799
that's a very that has to be quite a

944
00:31:35,919 --> 00:31:39,840
heated debate

945
00:31:36,799 --> 00:31:42,320
and me myself i'm very curious to see

946
00:31:39,840 --> 00:31:44,080
how skeptical or how optimistic you are

947
00:31:42,320 --> 00:31:45,840
about ubi

948
00:31:44,080 --> 00:31:47,439
so i don't know david do you want to

949
00:31:45,840 --> 00:31:49,039
start

950
00:31:47,440 --> 00:31:51,360
yeah i'm happy to start thank you for

951
00:31:49,039 --> 00:31:52,080
the question i definitely think and also

952
00:31:51,360 --> 00:31:54,639
to couple

953
00:31:52,080 --> 00:31:56,000
my answer with what my my previous

954
00:31:54,640 --> 00:31:58,080
previous speakers have said

955
00:31:56,000 --> 00:32:00,240
uh is that we're going for a really

956
00:31:58,080 --> 00:32:01,120
difficult time in which it's not going

957
00:32:00,240 --> 00:32:02,720
to be the same

958
00:32:01,120 --> 00:32:04,080
for everyone for some people the

959
00:32:02,720 --> 00:32:05,760
transition is going to be smoother for

960
00:32:04,080 --> 00:32:08,158
others going to be less move

961
00:32:05,760 --> 00:32:09,840
so what i think we as europeans have to

962
00:32:08,159 --> 00:32:10,640
ensure is that we don't leave anybody

963
00:32:09,840 --> 00:32:12,158
behind

964
00:32:10,640 --> 00:32:14,399
and for those people who have been for

965
00:32:12,159 --> 00:32:15,200
instance displaced of their jobs because

966
00:32:14,399 --> 00:32:17,439
of

967
00:32:15,200 --> 00:32:19,279
enhanced automation caused by the health

968
00:32:17,440 --> 00:32:21,440
crisis there should be a safety net for

969
00:32:19,279 --> 00:32:23,360
them to survive in the coming months

970
00:32:21,440 --> 00:32:24,799
and maybe even the coming year until

971
00:32:23,360 --> 00:32:26,879
things stabilize

972
00:32:24,799 --> 00:32:29,279
i see to be honest personally ubi has

973
00:32:26,880 --> 00:32:31,919
been the solution however i'm also

974
00:32:29,279 --> 00:32:33,200
um let's say not entirely sure that it

975
00:32:31,919 --> 00:32:35,600
can be implemented

976
00:32:33,200 --> 00:32:36,720
at the european scale yet but we already

977
00:32:35,600 --> 00:32:40,399
see examples of

978
00:32:36,720 --> 00:32:42,640
similar initiatives not ubi per se but

979
00:32:40,399 --> 00:32:43,439
a conditional basic income is being uh

980
00:32:42,640 --> 00:32:45,600
or actually has

981
00:32:43,440 --> 00:32:47,360
has started to be implemented in spain

982
00:32:45,600 --> 00:32:49,039
and i read actually just

983
00:32:47,360 --> 00:32:51,039
last week that germany is beginning a

984
00:32:49,039 --> 00:32:52,799
universal basic income trial

985
00:32:51,039 --> 00:32:54,240
with people getting over a thousand

986
00:32:52,799 --> 00:32:56,158
euros for the next few years so there's

987
00:32:54,240 --> 00:32:58,320
experiments which are encouraging

988
00:32:56,159 --> 00:33:00,559
and i think eventually we will get to

989
00:32:58,320 --> 00:33:02,480
something as close to ubi as possible

990
00:33:00,559 --> 00:33:04,480
because i don't see any other way

991
00:33:02,480 --> 00:33:06,320
to protect people in the future from

992
00:33:04,480 --> 00:33:08,880
such unforeseen

993
00:33:06,320 --> 00:33:10,158
uh health crisis or let's say maybe

994
00:33:08,880 --> 00:33:12,720
climate-related disasters

995
00:33:10,159 --> 00:33:14,320
which take many people by surprise and

996
00:33:12,720 --> 00:33:16,960
again not all of us are

997
00:33:14,320 --> 00:33:19,120
as prepared to do upskilling as

998
00:33:16,960 --> 00:33:22,480
everybody else and we have to make sure

999
00:33:19,120 --> 00:33:24,879
uh people are have the safety net to do

1000
00:33:22,480 --> 00:33:26,240
these things in their own time and and

1001
00:33:24,880 --> 00:33:28,960
you know in their own

1002
00:33:26,240 --> 00:33:30,640
sort of a healthy way not be you know

1003
00:33:28,960 --> 00:33:31,519
not to be put under too much pressure so

1004
00:33:30,640 --> 00:33:33,679
to say

1005
00:33:31,519 --> 00:33:35,120
uh might be one thing to add which is to

1006
00:33:33,679 --> 00:33:37,120
to add to what nikolai mentioned

1007
00:33:35,120 --> 00:33:38,959
besides the digital skills the general

1008
00:33:37,120 --> 00:33:41,840
cognitive skills which i think are

1009
00:33:38,960 --> 00:33:43,840
essential for people going forward even

1010
00:33:41,840 --> 00:33:44,959
if it's not crisis time in general it's

1011
00:33:43,840 --> 00:33:47,039
very important

1012
00:33:44,960 --> 00:33:49,200
i would add also another dimension which

1013
00:33:47,039 --> 00:33:51,440
i like to call the growth mindset skill

1014
00:33:49,200 --> 00:33:54,399
set which is another cluster

1015
00:33:51,440 --> 00:33:56,480
sometimes disregarded or not seen as the

1016
00:33:54,399 --> 00:33:58,479
sort of a key priority but i see it as

1017
00:33:56,480 --> 00:34:00,480
an essential cluster

1018
00:33:58,480 --> 00:34:02,399
it's you know it encompasses everything

1019
00:34:00,480 --> 00:34:05,120
from resilience

1020
00:34:02,399 --> 00:34:07,439
grit um you know skills that are

1021
00:34:05,120 --> 00:34:07,760
especially relevant in times of crisis

1022
00:34:07,440 --> 00:34:10,159
but

1023
00:34:07,760 --> 00:34:10,879
even throughout throughout your lifetime

1024
00:34:10,159 --> 00:34:12,720
and i think

1025
00:34:10,879 --> 00:34:14,960
growth mindset which has been popular

1026
00:34:12,719 --> 00:34:17,279
popularized by carol dweck

1027
00:34:14,960 --> 00:34:19,119
and maybe some of you have seen her is

1028
00:34:17,280 --> 00:34:21,359
something which we should instill

1029
00:34:19,119 --> 00:34:22,720
in our in our children very early on

1030
00:34:21,359 --> 00:34:24,480
which i think is another quality

1031
00:34:22,719 --> 00:34:26,319
important to have and i'm going to stop

1032
00:34:24,480 --> 00:34:28,719
here but thank you again for your

1033
00:34:26,320 --> 00:34:28,720
question

1034
00:34:29,679 --> 00:34:36,879
any other views on ubi any volunteers

1035
00:34:33,760 --> 00:34:36,879
with strong opinions

1036
00:34:37,040 --> 00:34:42,960
no i'm just gonna add to the skill set

1037
00:34:40,159 --> 00:34:44,079
um i'm speaking here with a female adam

1038
00:34:42,960 --> 00:34:45,839
um

1039
00:34:44,079 --> 00:34:47,919
what i find personally i'm asked quite a

1040
00:34:45,839 --> 00:34:48,879
lot to talk about women and some you

1041
00:34:47,918 --> 00:34:51,679
know women in

1042
00:34:48,879 --> 00:34:52,319
technical jobs etc um and for me there's

1043
00:34:51,679 --> 00:34:54,720
too much

1044
00:34:52,320 --> 00:34:56,480
you know programs forcing almost women

1045
00:34:54,719 --> 00:34:56,879
to go that direction as as being you

1046
00:34:56,480 --> 00:34:58,960
know

1047
00:34:56,879 --> 00:35:00,880
the place to be and i don't agree

1048
00:34:58,960 --> 00:35:03,119
because it's been said a couple of times

1049
00:35:00,880 --> 00:35:04,400
um and i don't want to judge either that

1050
00:35:03,119 --> 00:35:07,440
it's all women

1051
00:35:04,400 --> 00:35:09,520
but we shouldn't forget that

1052
00:35:07,440 --> 00:35:11,440
software skills you know uh they are

1053
00:35:09,520 --> 00:35:14,240
going to be very very important

1054
00:35:11,440 --> 00:35:15,119
next to data and technology uh skills

1055
00:35:14,240 --> 00:35:17,520
and collaboration

1056
00:35:15,119 --> 00:35:19,119
skills on empathy the skills where we

1057
00:35:17,520 --> 00:35:20,320
can put ourselves in the state of mind

1058
00:35:19,119 --> 00:35:21,839
of the other person making the

1059
00:35:20,320 --> 00:35:24,400
translation work work

1060
00:35:21,839 --> 00:35:24,880
we don't need to have experts on deep

1061
00:35:24,400 --> 00:35:27,280
dive

1062
00:35:24,880 --> 00:35:28,960
topics everywhere we need to have more

1063
00:35:27,280 --> 00:35:31,200
people that can build bridges

1064
00:35:28,960 --> 00:35:32,800
between business and engineers engineers

1065
00:35:31,200 --> 00:35:35,839
and legal people legal

1066
00:35:32,800 --> 00:35:38,000
and governmental people etc and so

1067
00:35:35,839 --> 00:35:40,078
i would like to you know to see more

1068
00:35:38,000 --> 00:35:41,200
focus on the fact that this is very

1069
00:35:40,079 --> 00:35:42,800
valuable as well

1070
00:35:41,200 --> 00:35:44,720
i find too much in the programs that

1071
00:35:42,800 --> 00:35:46,880
it's almost like this is not needed

1072
00:35:44,720 --> 00:35:48,879
if you look at covet and that's a

1073
00:35:46,880 --> 00:35:51,760
reflection i meet myself quite a lot

1074
00:35:48,880 --> 00:35:52,400
looking into it um and you look at the

1075
00:35:51,760 --> 00:35:55,599
role that

1076
00:35:52,400 --> 00:35:58,320
nurses have had in in this in this

1077
00:35:55,599 --> 00:35:59,359
pandemic this is not something that ai

1078
00:35:58,320 --> 00:36:01,359
can do

1079
00:35:59,359 --> 00:36:02,480
i couldn't even tip in what nurses were

1080
00:36:01,359 --> 00:36:05,759
doing um

1081
00:36:02,480 --> 00:36:07,119
so we should go towards a domain where

1082
00:36:05,760 --> 00:36:10,320
there's more humbleness

1083
00:36:07,119 --> 00:36:12,160
um and we were just actually lifting up

1084
00:36:10,320 --> 00:36:13,760
the the people that are down here and

1085
00:36:12,160 --> 00:36:15,839
just bringing down people should

1086
00:36:13,760 --> 00:36:17,119
you know the top people who think that

1087
00:36:15,839 --> 00:36:19,359
they're at the top they should be more

1088
00:36:17,119 --> 00:36:21,599
humble and recognize that the value that

1089
00:36:19,359 --> 00:36:23,598
everybody brings in this society

1090
00:36:21,599 --> 00:36:26,000
and i find this that you know this

1091
00:36:23,599 --> 00:36:27,520
polarization is too large right now

1092
00:36:26,000 --> 00:36:29,359
there should be more humbleness towards

1093
00:36:27,520 --> 00:36:31,599
the other direction and and seeing that

1094
00:36:29,359 --> 00:36:34,799
skills like social skills state of mind

1095
00:36:31,599 --> 00:36:37,520
empathy creativity etc are as valuable

1096
00:36:34,800 --> 00:36:39,040
towards the future and engineering data

1097
00:36:37,520 --> 00:36:42,160
and technology skills

1098
00:36:39,040 --> 00:36:42,160
that's my view as a woman

1099
00:36:42,400 --> 00:36:50,560
i couldn't agree more yeah

1100
00:36:46,960 --> 00:36:53,359
of course i also very much agree because

1101
00:36:50,560 --> 00:36:54,960
we we praise a lot of technical skills

1102
00:36:53,359 --> 00:36:58,078
at the moment

1103
00:36:54,960 --> 00:37:00,960
and we spend a lot of effort in

1104
00:36:58,079 --> 00:37:01,599
in making diversity but i think that we

1105
00:37:00,960 --> 00:37:03,520
should also

1106
00:37:01,599 --> 00:37:04,960
look at this aspect that you just uh

1107
00:37:03,520 --> 00:37:07,200
that you just described

1108
00:37:04,960 --> 00:37:08,000
i mean if i look at the the skills and

1109
00:37:07,200 --> 00:37:10,319
there there were

1110
00:37:08,000 --> 00:37:12,160
multiple searches what will be needed in

1111
00:37:10,320 --> 00:37:14,560
next five ten years

1112
00:37:12,160 --> 00:37:15,598
and first five skills were always very

1113
00:37:14,560 --> 00:37:19,440
technical

1114
00:37:15,599 --> 00:37:21,440
but fortunately uh six

1115
00:37:19,440 --> 00:37:22,960
seven eight were always the people

1116
00:37:21,440 --> 00:37:24,480
skills and i think that we should not

1117
00:37:22,960 --> 00:37:26,880
underestimate those

1118
00:37:24,480 --> 00:37:27,599
and as for the as for the diversity i

1119
00:37:26,880 --> 00:37:30,320
mean

1120
00:37:27,599 --> 00:37:32,400
the diversity should be general um it's

1121
00:37:30,320 --> 00:37:35,040
not only gender diversity but

1122
00:37:32,400 --> 00:37:36,320
still we have we have a gap in in our

1123
00:37:35,040 --> 00:37:39,839
mindsets i mean

1124
00:37:36,320 --> 00:37:42,800
including me if i look at the

1125
00:37:39,839 --> 00:37:44,640
uh at the at the ratio of women on

1126
00:37:42,800 --> 00:37:47,040
technical schools which is actually

1127
00:37:44,640 --> 00:37:48,960
valid for every every technical company

1128
00:37:47,040 --> 00:37:50,800
in in central europe i mean this is

1129
00:37:48,960 --> 00:37:53,599
really unsatisfactory

1130
00:37:50,800 --> 00:37:54,079
and if you look at the you are from ia

1131
00:37:53,599 --> 00:37:56,400
fields

1132
00:37:54,079 --> 00:37:57,359
if i look at the cloud computing for

1133
00:37:56,400 --> 00:38:01,760
instance there is

1134
00:37:57,359 --> 00:38:01,759
i don't know 10 of women it's

1135
00:38:02,839 --> 00:38:05,839
surprising

1136
00:38:06,400 --> 00:38:10,720
yes i mean i have noticed a lot of a lot

1137
00:38:08,880 --> 00:38:13,760
of initiatives across the sea

1138
00:38:10,720 --> 00:38:17,439
region uh related to the

1139
00:38:13,760 --> 00:38:19,440
the both technical skills and female

1140
00:38:17,440 --> 00:38:21,520
leadership in technical skills such as

1141
00:38:19,440 --> 00:38:24,640
checkytas in czech republic or

1142
00:38:21,520 --> 00:38:26,640
uh gold carrots i believe in in poland

1143
00:38:24,640 --> 00:38:28,879
so there are several kind of i would say

1144
00:38:26,640 --> 00:38:31,279
like smaller scale initiatives which you

1145
00:38:28,880 --> 00:38:34,400
know footscare was a great example for

1146
00:38:31,280 --> 00:38:35,839
some larger scale reforms but as we all

1147
00:38:34,400 --> 00:38:38,320
know these kind of

1148
00:38:35,839 --> 00:38:39,440
long-term policy changes are sometimes

1149
00:38:38,320 --> 00:38:42,400
hard to

1150
00:38:39,440 --> 00:38:44,160
uh push politically are not not being as

1151
00:38:42,400 --> 00:38:45,440
prioritized as they as they really

1152
00:38:44,160 --> 00:38:48,480
should be so

1153
00:38:45,440 --> 00:38:50,079
this this does tend to be problematic so

1154
00:38:48,480 --> 00:38:52,320
what should we do kind of like an open

1155
00:38:50,079 --> 00:38:54,240
question to us everyone we all know that

1156
00:38:52,320 --> 00:38:54,880
you know education is important and in

1157
00:38:54,240 --> 00:38:56,799
order to

1158
00:38:54,880 --> 00:38:58,320
give some sort of a long-term change it

1159
00:38:56,800 --> 00:39:01,520
is important to

1160
00:38:58,320 --> 00:39:03,520
instill you know pushed through a

1161
00:39:01,520 --> 00:39:04,720
viewer you know really massive education

1162
00:39:03,520 --> 00:39:07,040
reforms across

1163
00:39:04,720 --> 00:39:08,560
the whole of eu with the exception of

1164
00:39:07,040 --> 00:39:11,440
several countries which are ahead

1165
00:39:08,560 --> 00:39:12,160
for example estonia so what what should

1166
00:39:11,440 --> 00:39:14,240
be the how

1167
00:39:12,160 --> 00:39:16,799
should we kind of like you know make

1168
00:39:14,240 --> 00:39:19,200
this happen

1169
00:39:16,800 --> 00:39:19,920
um i i can i can start with with the

1170
00:39:19,200 --> 00:39:21,520
with a quick

1171
00:39:19,920 --> 00:39:23,760
comment on your question it's that i

1172
00:39:21,520 --> 00:39:25,280
think the solution is not

1173
00:39:23,760 --> 00:39:26,960
let's say a solution caused by the

1174
00:39:25,280 --> 00:39:29,280
current context i think the

1175
00:39:26,960 --> 00:39:30,880
cover 19 crisis as with everything else

1176
00:39:29,280 --> 00:39:32,480
it's a magnifying glass that's how i see

1177
00:39:30,880 --> 00:39:34,400
this crisis it showed

1178
00:39:32,480 --> 00:39:36,000
not just in our education system but in

1179
00:39:34,400 --> 00:39:37,040
our society some of the things that can

1180
00:39:36,000 --> 00:39:38,560
be improved

1181
00:39:37,040 --> 00:39:40,880
and some of the things that can still

1182
00:39:38,560 --> 00:39:42,400
remain the same and they're fine now

1183
00:39:40,880 --> 00:39:44,880
when it comes to the education sector

1184
00:39:42,400 --> 00:39:46,400
what i think it highlights a lot is the

1185
00:39:44,880 --> 00:39:48,079
first of all the inequality between

1186
00:39:46,400 --> 00:39:49,200
people who have access to education and

1187
00:39:48,079 --> 00:39:50,800
those who haven't

1188
00:39:49,200 --> 00:39:53,919
which is i think a huge issue to tackle

1189
00:39:50,800 --> 00:39:56,079
for many countries in europe and abroad

1190
00:39:53,920 --> 00:39:59,040
and another issue is the fact that

1191
00:39:56,079 --> 00:40:01,760
schools still prepare young people for

1192
00:39:59,040 --> 00:40:03,440
jobs that don't yet exist so they should

1193
00:40:01,760 --> 00:40:05,040
focus a lot more on building

1194
00:40:03,440 --> 00:40:06,800
transferable skills in young people

1195
00:40:05,040 --> 00:40:08,160
that's one thing which is

1196
00:40:06,800 --> 00:40:09,920
both the soft skills some of you

1197
00:40:08,160 --> 00:40:11,359
mentioned but also digital skills the

1198
00:40:09,920 --> 00:40:13,119
others mentioned

1199
00:40:11,359 --> 00:40:14,560
and the growth mindset skills as well

1200
00:40:13,119 --> 00:40:15,440
and very importantly and i think this is

1201
00:40:14,560 --> 00:40:18,160
my solution

1202
00:40:15,440 --> 00:40:19,440
uh which maybe is is only now being more

1203
00:40:18,160 --> 00:40:22,078
and more discussed

1204
00:40:19,440 --> 00:40:23,200
is to bring universities and higher

1205
00:40:22,079 --> 00:40:25,040
education in general

1206
00:40:23,200 --> 00:40:26,560
more closely in line with companies

1207
00:40:25,040 --> 00:40:28,640
because at least in the country

1208
00:40:26,560 --> 00:40:29,599
where i come from in romania companies

1209
00:40:28,640 --> 00:40:31,279
have been

1210
00:40:29,599 --> 00:40:32,960
let's say complaining for some some

1211
00:40:31,280 --> 00:40:36,000
years now that the students they

1212
00:40:32,960 --> 00:40:37,440
they get you know as young graduates as

1213
00:40:36,000 --> 00:40:39,119
young trainees in their companies

1214
00:40:37,440 --> 00:40:40,400
they have to re-educate them in some

1215
00:40:39,119 --> 00:40:41,040
sense you know they're not learning

1216
00:40:40,400 --> 00:40:43,200
enough

1217
00:40:41,040 --> 00:40:44,800
practical skills that would enable them

1218
00:40:43,200 --> 00:40:46,879
to start the job

1219
00:40:44,800 --> 00:40:48,079
and and and you know and thrive in it

1220
00:40:46,880 --> 00:40:49,440
they literally have to go through

1221
00:40:48,079 --> 00:40:50,960
another preparation when they start a

1222
00:40:49,440 --> 00:40:52,160
job which should not be the case so i

1223
00:40:50,960 --> 00:40:54,720
think a closer

1224
00:40:52,160 --> 00:40:55,440
collaboration between higher education

1225
00:40:54,720 --> 00:40:58,078
and

1226
00:40:55,440 --> 00:41:00,079
the the the companies be it smbs but

1227
00:40:58,079 --> 00:41:01,920
also large companies in the countries

1228
00:41:00,079 --> 00:41:04,720
would be beneficial to prepare people

1229
00:41:01,920 --> 00:41:06,240
for the future of work

1230
00:41:04,720 --> 00:41:08,319
i couldn't agree more and i think

1231
00:41:06,240 --> 00:41:10,479
there's a big deficit especially in the

1232
00:41:08,319 --> 00:41:12,480
central eastern european countries

1233
00:41:10,480 --> 00:41:14,240
uh what is your perspective mika you

1234
00:41:12,480 --> 00:41:15,920
coming from the netherlands is the

1235
00:41:14,240 --> 00:41:20,240
is the collaboration between the private

1236
00:41:15,920 --> 00:41:22,480
sector and universities any better no

1237
00:41:20,240 --> 00:41:24,479
um maybe just a just small tiny

1238
00:41:22,480 --> 00:41:25,760
correction i'm from belgium so but in

1239
00:41:24,480 --> 00:41:27,920
belgium the system

1240
00:41:25,760 --> 00:41:30,319
is very much still like i used to have

1241
00:41:27,920 --> 00:41:30,720
it when i was uh you know 10 20 30 years

1242
00:41:30,319 --> 00:41:32,640
ago

1243
00:41:30,720 --> 00:41:34,000
which means there's a lot of learning

1244
00:41:32,640 --> 00:41:37,520
out of the hat you know not by

1245
00:41:34,000 --> 00:41:39,359
experience not by by playing um i

1246
00:41:37,520 --> 00:41:41,280
i was very bad in school because i

1247
00:41:39,359 --> 00:41:43,040
didn't understand that i didn't see

1248
00:41:41,280 --> 00:41:44,880
the relationship between these things i

1249
00:41:43,040 --> 00:41:46,800
was studying and how this could be

1250
00:41:44,880 --> 00:41:49,599
relevant for my job later

1251
00:41:46,800 --> 00:41:50,319
and it's only when i started uh you know

1252
00:41:49,599 --> 00:41:52,480
on this

1253
00:41:50,319 --> 00:41:54,160
looking into companies and and like my

1254
00:41:52,480 --> 00:41:56,480
the person just mentioned

1255
00:41:54,160 --> 00:41:57,920
by talking to companies understanding

1256
00:41:56,480 --> 00:41:59,119
what's right relevant and what i'm

1257
00:41:57,920 --> 00:42:00,560
learning and what should i learn and

1258
00:41:59,119 --> 00:42:02,400
what should i not learn

1259
00:42:00,560 --> 00:42:04,078
that i started seeing the relationship

1260
00:42:02,400 --> 00:42:06,079
and i find that there's no

1261
00:42:04,079 --> 00:42:07,440
change at least not in a belgian system

1262
00:42:06,079 --> 00:42:10,160
not enough change

1263
00:42:07,440 --> 00:42:12,240
to to make young youngsters from from

1264
00:42:10,160 --> 00:42:12,799
trophy eight years even six years old

1265
00:42:12,240 --> 00:42:14,640
dream

1266
00:42:12,800 --> 00:42:16,000
you know and see what they could mean

1267
00:42:14,640 --> 00:42:17,520
later on see the relationship

1268
00:42:16,000 --> 00:42:19,359
between the formulas they see right now

1269
00:42:17,520 --> 00:42:21,359
and where it actually ends

1270
00:42:19,359 --> 00:42:23,040
um when i talk to young people and take

1271
00:42:21,359 --> 00:42:25,040
a lot of time to talk to young people

1272
00:42:23,040 --> 00:42:27,040
you see lots of people you know stopping

1273
00:42:25,040 --> 00:42:29,920
school because of this reason

1274
00:42:27,040 --> 00:42:31,040
even today let them play let them learn

1275
00:42:29,920 --> 00:42:32,880
by experience don't make

1276
00:42:31,040 --> 00:42:34,240
robots out of people by you know

1277
00:42:32,880 --> 00:42:36,560
learning out of the hat they don't

1278
00:42:34,240 --> 00:42:38,560
understand the content they don't see it

1279
00:42:36,560 --> 00:42:40,160
um so and this is for me that's missing

1280
00:42:38,560 --> 00:42:42,160
far too much um

1281
00:42:40,160 --> 00:42:43,839
at least i speak for belgium but i i

1282
00:42:42,160 --> 00:42:44,640
compared to what my children seeing here

1283
00:42:43,839 --> 00:42:48,160
and

1284
00:42:44,640 --> 00:42:50,799
i am surprised i am yeah i'd love to see

1285
00:42:48,160 --> 00:42:50,799
that changing

1286
00:42:51,119 --> 00:42:55,280
thank you thank you very much everyone i

1287
00:42:53,359 --> 00:42:56,319
think our time is unfortunately coming

1288
00:42:55,280 --> 00:42:58,640
to an end

1289
00:42:56,319 --> 00:43:00,240
and we really really appreciate the time

1290
00:42:58,640 --> 00:43:01,839
and the your insights

1291
00:43:00,240 --> 00:43:04,240
it's been it's been very very

1292
00:43:01,839 --> 00:43:06,078
interesting uh so thank you very much

1293
00:43:04,240 --> 00:43:08,078
for the engaging discussion

1294
00:43:06,079 --> 00:43:10,079
and uh well even though we are wrapping

1295
00:43:08,079 --> 00:43:12,640
up the program for today the go upset

1296
00:43:10,079 --> 00:43:13,680
digital stage also continues tomorrow

1297
00:43:12,640 --> 00:43:16,960
starting at

1298
00:43:13,680 --> 00:43:17,520
1pm central european time and we'll be

1299
00:43:16,960 --> 00:43:20,160
hosting

1300
00:43:17,520 --> 00:43:22,400
more exciting speakers including the

1301
00:43:20,160 --> 00:43:24,319
belarusian opposition leaders vietlana

1302
00:43:22,400 --> 00:43:26,880
tikanovskaya

1303
00:43:24,319 --> 00:43:27,520
so thank you very much again and stay

1304
00:43:26,880 --> 00:43:31,599
with us

1305
00:43:27,520 --> 00:43:31,599
and enjoy the rest of the evening thanks

1306
00:43:32,630 --> 00:43:37,860
[Music]

1307
00:43:38,839 --> 00:43:41,839
again

1308
00:43:42,020 --> 00:43:45,600
[Music]

1309
00:43:43,520 --> 00:43:52,070
[Applause]

1310
00:43:45,600 --> 00:43:52,069
[Music]

1311
00:43:53,839 --> 00:43:55,920
you

