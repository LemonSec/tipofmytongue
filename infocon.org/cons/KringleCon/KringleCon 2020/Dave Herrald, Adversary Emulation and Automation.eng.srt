1
00:00:02,639 --> 00:00:03,360
welcome to

2
00:00:03,360 --> 00:00:06,640
cringlecon 3 french hens my name is dave

3
00:00:06,640 --> 00:00:08,240
harold i'm a principal security

4
00:00:08,240 --> 00:00:08,960
strategist

5
00:00:08,960 --> 00:00:12,480
at splunk and we're very happy to be

6
00:00:12,480 --> 00:00:14,400
here today at kringlecon to talk to you

7
00:00:14,400 --> 00:00:18,720
about adversary emulation and automation

8
00:00:18,960 --> 00:00:21,520
a bit about my background i've been in

9
00:00:21,520 --> 00:00:23,199
security and technology

10
00:00:23,199 --> 00:00:26,000
for quite a long time now i've had many

11
00:00:26,000 --> 00:00:26,720
different

12
00:00:26,720 --> 00:00:29,599
security roles everything from running

13
00:00:29,599 --> 00:00:31,359
security programs as an information

14
00:00:31,359 --> 00:00:33,840
security officer to being a security

15
00:00:33,840 --> 00:00:35,680
architect security engineer

16
00:00:35,680 --> 00:00:38,399
security analyst and i've had lots of

17
00:00:38,399 --> 00:00:39,760
roles in it

18
00:00:39,760 --> 00:00:42,559
as well mostly around infrastructure

19
00:00:42,559 --> 00:00:44,239
system administration and network

20
00:00:44,239 --> 00:00:45,840
engineering

21
00:00:45,840 --> 00:00:49,039
i'm a former sans mentor and i've

22
00:00:49,039 --> 00:00:52,000
really been a product of sans in my

23
00:00:52,000 --> 00:00:52,559
career

24
00:00:52,559 --> 00:00:55,760
i'm a gse a lot of sand certifications

25
00:00:55,760 --> 00:00:57,199
i've spoken at a number of

26
00:00:57,199 --> 00:00:59,680
sans summits over the past few years

27
00:00:59,680 --> 00:01:02,399
with my colleague ryan kovar

28
00:01:02,399 --> 00:01:04,879
currently in security i'm focusing on

29
00:01:04,879 --> 00:01:06,960
adversary emulation which is the subject

30
00:01:06,960 --> 00:01:08,320
of this talk

31
00:01:08,320 --> 00:01:10,960
cloud security and i've been doing a lot

32
00:01:10,960 --> 00:01:12,960
of full stack development

33
00:01:12,960 --> 00:01:16,080
and getting into devsecops more in

34
00:01:16,080 --> 00:01:18,880
in my in my day job at splunk i've been

35
00:01:18,880 --> 00:01:20,560
at splunk for about six years

36
00:01:20,560 --> 00:01:22,880
and i'm the co-creator of the splunk

37
00:01:22,880 --> 00:01:25,680
boss of the sock

38
00:01:25,680 --> 00:01:28,320
as i said we're very appreciative of the

39
00:01:28,320 --> 00:01:29,920
opportunity to be able

40
00:01:29,920 --> 00:01:32,560
to participate in kringlecon and in

41
00:01:32,560 --> 00:01:35,040
holiday hack challenge

42
00:01:35,040 --> 00:01:36,479
there's a great deal of trust that's

43
00:01:36,479 --> 00:01:39,200
been placed in us by sans and by ed and

44
00:01:39,200 --> 00:01:39,520
by

45
00:01:39,520 --> 00:01:42,159
the folks at counter hack and we take

46
00:01:42,159 --> 00:01:44,479
that very seriously

47
00:01:44,479 --> 00:01:47,840
at every turn we will seek to emphasize

48
00:01:47,840 --> 00:01:50,880
security and best practices and we will

49
00:01:50,880 --> 00:01:53,920
not emphasize product positioning

50
00:01:53,920 --> 00:01:58,719
in these challenges with that said

51
00:01:59,439 --> 00:02:02,000
we do use splunk in these challenges and

52
00:02:02,000 --> 00:02:03,920
it's because that's what we have access

53
00:02:03,920 --> 00:02:04,560
to

54
00:02:04,560 --> 00:02:07,360
but most of these concepts are universal

55
00:02:07,360 --> 00:02:09,119
and could be applied to

56
00:02:09,119 --> 00:02:12,000
really any technology stack that you

57
00:02:12,000 --> 00:02:13,200
have in your sock

58
00:02:13,200 --> 00:02:15,200
so please keep that in mind as we

59
00:02:15,200 --> 00:02:17,520
proceed

60
00:02:17,520 --> 00:02:20,640
why should we emulate the adversary well

61
00:02:20,640 --> 00:02:23,040
number one it allows us to build better

62
00:02:23,040 --> 00:02:24,400
detections

63
00:02:24,400 --> 00:02:26,560
one of the primary activities that you

64
00:02:26,560 --> 00:02:27,680
engage in

65
00:02:27,680 --> 00:02:29,280
as a blue teamer protecting an

66
00:02:29,280 --> 00:02:31,760
organization is to create detections

67
00:02:31,760 --> 00:02:35,120
that can raise alerts when evidence of

68
00:02:35,120 --> 00:02:38,319
adversary activity is detected

69
00:02:38,319 --> 00:02:40,400
in order to do that and in order to

70
00:02:40,400 --> 00:02:42,239
improve those detections over time you

71
00:02:42,239 --> 00:02:43,200
need a source

72
00:02:43,200 --> 00:02:46,080
of telemetry a source of data that

73
00:02:46,080 --> 00:02:49,040
represents the adversary's activities

74
00:02:49,040 --> 00:02:50,480
a great way to get that is through

75
00:02:50,480 --> 00:02:53,120
emulation while it's certainly not the

76
00:02:53,120 --> 00:02:54,879
only way to get that data

77
00:02:54,879 --> 00:02:57,280
it does offer some benefits especially

78
00:02:57,280 --> 00:02:58,400
consistency

79
00:02:58,400 --> 00:03:01,599
and repeatability

80
00:03:02,720 --> 00:03:05,440
the next reason is that emulation allows

81
00:03:05,440 --> 00:03:07,840
you to test your detections

82
00:03:07,840 --> 00:03:09,680
security detections are actually quite

83
00:03:09,680 --> 00:03:11,760
fragile they're subject to

84
00:03:11,760 --> 00:03:14,159
many externalities that can cause them

85
00:03:14,159 --> 00:03:15,920
to stop working

86
00:03:15,920 --> 00:03:18,480
the most successful organizations treat

87
00:03:18,480 --> 00:03:19,840
their detections

88
00:03:19,840 --> 00:03:22,560
like code and they test them with a ci

89
00:03:22,560 --> 00:03:24,159
cd pipeline

90
00:03:24,159 --> 00:03:25,519
in order to do that you need

91
00:03:25,519 --> 00:03:28,000
repeatability you need consistency

92
00:03:28,000 --> 00:03:32,720
and adversary emulation offers that

93
00:03:32,720 --> 00:03:35,040
the third reason is that it allows you

94
00:03:35,040 --> 00:03:36,319
to test your vendors

95
00:03:36,319 --> 00:03:39,360
claims about their products every

96
00:03:39,360 --> 00:03:40,959
security team has dozens

97
00:03:40,959 --> 00:03:43,440
if not hundreds of different tools in

98
00:03:43,440 --> 00:03:45,680
their sock tool chain

99
00:03:45,680 --> 00:03:48,879
each one of those tools claims to

100
00:03:48,879 --> 00:03:50,560
provide certain value to your

101
00:03:50,560 --> 00:03:53,360
organization but it becomes very very

102
00:03:53,360 --> 00:03:56,239
useful to be able to emulate adversary

103
00:03:56,239 --> 00:03:58,640
activity in a realistic way

104
00:03:58,640 --> 00:04:00,959
and then test whether those solutions

105
00:04:00,959 --> 00:04:02,159
can actually

106
00:04:02,159 --> 00:04:05,680
detect that activity we

107
00:04:05,680 --> 00:04:07,840
have seen a dramatic increase over the

108
00:04:07,840 --> 00:04:10,000
last year to 18 months

109
00:04:10,000 --> 00:04:13,360
of customers demanding that

110
00:04:13,360 --> 00:04:16,000
we emulate the adversary and then show

111
00:04:16,000 --> 00:04:18,478
that our products can detect that

112
00:04:18,478 --> 00:04:21,040
it's an extremely effective tactic to

113
00:04:21,040 --> 00:04:21,519
use

114
00:04:21,519 --> 00:04:23,919
when dealing with vendors or when

115
00:04:23,919 --> 00:04:24,639
testing

116
00:04:24,639 --> 00:04:29,600
one vendor solution versus another

117
00:04:29,600 --> 00:04:31,520
if you'd like to dig a little bit deeper

118
00:04:31,520 --> 00:04:32,639
into reasons

119
00:04:32,639 --> 00:04:34,560
why you should include adversary

120
00:04:34,560 --> 00:04:37,040
simulation in your security program

121
00:04:37,040 --> 00:04:38,479
you might want to check out some of

122
00:04:38,479 --> 00:04:40,160
these resources

123
00:04:40,160 --> 00:04:41,600
over the past couple years some

124
00:04:41,600 --> 00:04:43,840
colleagues of mine and i

125
00:04:43,840 --> 00:04:46,080
have been working on an adversary

126
00:04:46,080 --> 00:04:48,080
simulation project

127
00:04:48,080 --> 00:04:49,919
and we've presented on that at a number

128
00:04:49,919 --> 00:04:51,120
of conferences

129
00:04:51,120 --> 00:04:54,479
some splunk user conferences a sans

130
00:04:54,479 --> 00:04:56,720
blue team summit and also black hat

131
00:04:56,720 --> 00:04:57,520
arsenal

132
00:04:57,520 --> 00:05:01,280
both usa and asia in 2020 i do recommend

133
00:05:01,280 --> 00:05:02,320
checking these out

134
00:05:02,320 --> 00:05:04,000
they give a little deeper treatment to

135
00:05:04,000 --> 00:05:05,600
why you might want to do adversary

136
00:05:05,600 --> 00:05:06,800
simulation

137
00:05:06,800 --> 00:05:09,199
but for today we're going to continue on

138
00:05:09,199 --> 00:05:09,840
and show you

139
00:05:09,840 --> 00:05:12,240
exactly how to start simulating the

140
00:05:12,240 --> 00:05:14,960
adversary

141
00:05:15,440 --> 00:05:17,600
so i want to show you one way that you

142
00:05:17,600 --> 00:05:20,320
can get started with adversary emulation

143
00:05:20,320 --> 00:05:22,560
it's really broken down into four easy

144
00:05:22,560 --> 00:05:24,400
components or steps

145
00:05:24,400 --> 00:05:27,120
the first one is splunk attack range

146
00:05:27,120 --> 00:05:29,840
second is the miter attack framework

147
00:05:29,840 --> 00:05:32,000
third is the atomic red team project

148
00:05:32,000 --> 00:05:33,280
from red canary

149
00:05:33,280 --> 00:05:38,240
and fourth is splunk

150
00:05:38,240 --> 00:05:40,320
splunk attack range number one on this

151
00:05:40,320 --> 00:05:42,960
list is a really cool project

152
00:05:42,960 --> 00:05:46,000
it's free it's open source it's created

153
00:05:46,000 --> 00:05:48,320
by some really smart people at splunk

154
00:05:48,320 --> 00:05:51,120
and it makes it really easy to spin up a

155
00:05:51,120 --> 00:05:52,160
range

156
00:05:52,160 --> 00:05:56,080
and then to launch attacks in that range

157
00:05:56,080 --> 00:06:00,240
and then look at the results in splunk

158
00:06:00,240 --> 00:06:03,039
the miter attack framework of course is

159
00:06:03,039 --> 00:06:04,000
the basis of

160
00:06:04,000 --> 00:06:06,960
a lot of security content these days

161
00:06:06,960 --> 00:06:08,080
it's a knowledge base

162
00:06:08,080 --> 00:06:11,280
of adversarial activities and it's free

163
00:06:11,280 --> 00:06:12,240
to use

164
00:06:12,240 --> 00:06:15,360
by published by mitre it's an amazing

165
00:06:15,360 --> 00:06:16,880
resource

166
00:06:16,880 --> 00:06:19,280
most security content these days has

167
00:06:19,280 --> 00:06:20,560
some sort of a mapping

168
00:06:20,560 --> 00:06:24,240
to the mitre attack framework

169
00:06:24,240 --> 00:06:26,080
the third item on this list atomic red

170
00:06:26,080 --> 00:06:27,600
team is also free

171
00:06:27,600 --> 00:06:29,840
it's an open source project it's created

172
00:06:29,840 --> 00:06:30,880
by

173
00:06:30,880 --> 00:06:33,759
red canary amazing company who

174
00:06:33,759 --> 00:06:35,120
contributes so much

175
00:06:35,120 --> 00:06:39,120
to the open source community

176
00:06:39,919 --> 00:06:42,479
the fourth on this list is splunk splunk

177
00:06:42,479 --> 00:06:45,280
has some forms in which it is free

178
00:06:45,280 --> 00:06:48,400
it's freeish certainly for everything

179
00:06:48,400 --> 00:06:50,960
we're going to show you in this

180
00:06:50,960 --> 00:06:53,039
talk today and anything that you'll see

181
00:06:53,039 --> 00:06:54,960
at kringlecon or in the holiday hack

182
00:06:54,960 --> 00:06:55,759
challenge

183
00:06:55,759 --> 00:06:57,919
you can do that with the free version of

184
00:06:57,919 --> 00:06:58,960
splunk

185
00:06:58,960 --> 00:07:01,280
and in fact the splunk attack range item

186
00:07:01,280 --> 00:07:02,479
number one

187
00:07:02,479 --> 00:07:05,599
provides splunk for free it spins up a

188
00:07:05,599 --> 00:07:06,240
splunk

189
00:07:06,240 --> 00:07:09,280
instance running with the free license

190
00:07:09,280 --> 00:07:12,800
the bottom line is you can employ

191
00:07:12,800 --> 00:07:15,680
this flavor of adversary emulation for

192
00:07:15,680 --> 00:07:16,319
free

193
00:07:16,319 --> 00:07:19,360
now you might accumulate a bit of cloud

194
00:07:19,360 --> 00:07:21,599
infrastructure as a service costs to

195
00:07:21,599 --> 00:07:22,560
spin up

196
00:07:22,560 --> 00:07:24,720
systems but there's no software

197
00:07:24,720 --> 00:07:25,840
licensing fees

198
00:07:25,840 --> 00:07:29,840
involved so let's talk about the splunk

199
00:07:29,840 --> 00:07:31,280
attack range

200
00:07:31,280 --> 00:07:33,440
as we mentioned on the last slide splunk

201
00:07:33,440 --> 00:07:35,840
attack range is a free open source

202
00:07:35,840 --> 00:07:37,039
project

203
00:07:37,039 --> 00:07:39,120
you can check it out at the url listed

204
00:07:39,120 --> 00:07:41,280
on the bottom of this slide

205
00:07:41,280 --> 00:07:43,199
attack range is a python script and a

206
00:07:43,199 --> 00:07:45,680
set of configurations for terraform

207
00:07:45,680 --> 00:07:47,919
and ansible that allow you to set up

208
00:07:47,919 --> 00:07:49,039
ranges

209
00:07:49,039 --> 00:07:53,919
in cloud services like aws and azure

210
00:07:53,919 --> 00:07:56,000
you can actually use attack range to set

211
00:07:56,000 --> 00:07:58,000
up ranges locally

212
00:07:58,000 --> 00:08:00,720
on systems as well however we'll only

213
00:08:00,720 --> 00:08:01,360
talk about

214
00:08:01,360 --> 00:08:04,800
the cloud options today

215
00:08:04,879 --> 00:08:07,039
the ranges include an active directory

216
00:08:07,039 --> 00:08:07,919
server

217
00:08:07,919 --> 00:08:10,000
they can include windows servers they

218
00:08:10,000 --> 00:08:11,759
can include windows clients

219
00:08:11,759 --> 00:08:14,560
they can include linux machines the

220
00:08:14,560 --> 00:08:16,160
windows systems are configured with

221
00:08:16,160 --> 00:08:17,199
sysmon

222
00:08:17,199 --> 00:08:19,680
they're configured with a inappropriate

223
00:08:19,680 --> 00:08:22,000
logging policy for windows security

224
00:08:22,000 --> 00:08:23,039
events

225
00:08:23,039 --> 00:08:25,599
you can include os query you can include

226
00:08:25,599 --> 00:08:27,520
caldera and atomic red team

227
00:08:27,520 --> 00:08:29,280
we'll talk a lot about atomic red team

228
00:08:29,280 --> 00:08:30,560
today

229
00:08:30,560 --> 00:08:32,320
you can include things like splunk

230
00:08:32,320 --> 00:08:34,880
stream the splunk universal forwarder

231
00:08:34,880 --> 00:08:36,479
which is the agent that

232
00:08:36,479 --> 00:08:41,839
sends logs from systems to splunk

233
00:08:42,080 --> 00:08:44,399
you can also include miter caldera you

234
00:08:44,399 --> 00:08:45,680
can include

235
00:08:45,680 --> 00:08:48,959
of course splunk and splunk phantom and

236
00:08:48,959 --> 00:08:49,360
even

237
00:08:49,360 --> 00:08:51,920
kali linux and this is all driven by the

238
00:08:51,920 --> 00:08:54,480
configuration that you choose

239
00:08:54,480 --> 00:08:56,959
one thing that is of note is if you see

240
00:08:56,959 --> 00:08:58,399
at the bottom of this slide where it

241
00:08:58,399 --> 00:08:58,720
says

242
00:08:58,720 --> 00:09:02,080
index equals win index equals attack

243
00:09:02,080 --> 00:09:05,040
index equals main these are the places

244
00:09:05,040 --> 00:09:06,560
within splunk

245
00:09:06,560 --> 00:09:08,880
that you are going to see the events

246
00:09:08,880 --> 00:09:10,880
that are generated by our adversary

247
00:09:10,880 --> 00:09:12,000
emulation

248
00:09:12,000 --> 00:09:14,480
it's important when you get into the

249
00:09:14,480 --> 00:09:15,920
holiday hack challenge

250
00:09:15,920 --> 00:09:18,160
that you pay special attention to what

251
00:09:18,160 --> 00:09:18,959
index

252
00:09:18,959 --> 00:09:22,800
you're searching in splunk

253
00:09:22,800 --> 00:09:24,959
i'd like to call out the authors of

254
00:09:24,959 --> 00:09:26,320
splunk attack range

255
00:09:26,320 --> 00:09:29,680
jose hernandez and patrick berries jose

256
00:09:29,680 --> 00:09:30,560
and patrick are

257
00:09:30,560 --> 00:09:32,000
colleagues of mine and good friends of

258
00:09:32,000 --> 00:09:34,160
mine they go to great lengths

259
00:09:34,160 --> 00:09:37,440
to publish the splunk attack range to

260
00:09:37,440 --> 00:09:40,640
quickly address bugs and constantly add

261
00:09:40,640 --> 00:09:42,160
new features to it

262
00:09:42,160 --> 00:09:44,240
they also go to a great amount of effort

263
00:09:44,240 --> 00:09:46,080
to ensure that attack range

264
00:09:46,080 --> 00:09:48,800
remains an open source project not an

265
00:09:48,800 --> 00:09:50,480
easy thing to do at a commercial

266
00:09:50,480 --> 00:09:51,760
software company

267
00:09:51,760 --> 00:09:54,959
i applaud them for their efforts and i

268
00:09:54,959 --> 00:09:57,120
love collaborating with these two

269
00:09:57,120 --> 00:09:58,640
gentlemen and the entire

270
00:09:58,640 --> 00:10:01,760
splunk threat research team let's take a

271
00:10:01,760 --> 00:10:03,200
couple minutes to talk about

272
00:10:03,200 --> 00:10:06,160
mitre attack miter attack is widely

273
00:10:06,160 --> 00:10:06,800
covered

274
00:10:06,800 --> 00:10:09,279
in information security you very likely

275
00:10:09,279 --> 00:10:11,360
have heard about mitre attack and know a

276
00:10:11,360 --> 00:10:12,959
lot about it already so we'll just hit

277
00:10:12,959 --> 00:10:15,200
the high points

278
00:10:15,200 --> 00:10:16,880
miter attack is a knowledge base of

279
00:10:16,880 --> 00:10:18,880
adversary techniques

280
00:10:18,880 --> 00:10:21,279
as such it's very useful to search

281
00:10:21,279 --> 00:10:22,800
through the mitre attack

282
00:10:22,800 --> 00:10:25,680
website when you have a question about

283
00:10:25,680 --> 00:10:28,240
things like adversary simulation

284
00:10:28,240 --> 00:10:30,399
that's something to keep in mind when

285
00:10:30,399 --> 00:10:32,079
you are working through holiday hack

286
00:10:32,079 --> 00:10:34,560
challenge

287
00:10:34,959 --> 00:10:37,279
mitre attacks organized into tactics

288
00:10:37,279 --> 00:10:38,880
tactics often describe

289
00:10:38,880 --> 00:10:41,920
why an adversary might perpetrate a

290
00:10:41,920 --> 00:10:43,920
certain type of attack

291
00:10:43,920 --> 00:10:46,079
techniques are how they will perpetrate

292
00:10:46,079 --> 00:10:47,440
that attack

293
00:10:47,440 --> 00:10:49,920
and techniques as of fairly recently can

294
00:10:49,920 --> 00:10:50,880
be divided

295
00:10:50,880 --> 00:10:53,600
often into sub techniques which allows

296
00:10:53,600 --> 00:10:55,040
another dimension

297
00:10:55,040 --> 00:10:58,720
to more richly describe

298
00:10:58,720 --> 00:11:01,839
adversary techniques

299
00:11:03,760 --> 00:11:06,320
you often see mitre attack expressed as

300
00:11:06,320 --> 00:11:08,160
a matrix this is the miter attack

301
00:11:08,160 --> 00:11:10,079
enterprise matrix

302
00:11:10,079 --> 00:11:12,560
and you can see here that the columns

303
00:11:12,560 --> 00:11:13,120
are

304
00:11:13,120 --> 00:11:15,600
those tactics that we mentioned on the

305
00:11:15,600 --> 00:11:16,800
last slide

306
00:11:16,800 --> 00:11:19,680
now under those tactics are techniques

307
00:11:19,680 --> 00:11:21,519
and in fact if you click on one of these

308
00:11:21,519 --> 00:11:23,200
techniques you'd see

309
00:11:23,200 --> 00:11:26,240
a great deal of detail including

310
00:11:26,240 --> 00:11:28,240
but not limited to these sub techniques

311
00:11:28,240 --> 00:11:30,000
you can see there's 12 sub techniques

312
00:11:30,000 --> 00:11:30,720
here

313
00:11:30,720 --> 00:11:34,399
now this one is id 1547 or i should say

314
00:11:34,399 --> 00:11:35,200
id

315
00:11:35,200 --> 00:11:38,399
t 1547 t is for technique

316
00:11:38,399 --> 00:11:42,560
and boot or logon auto start execution

317
00:11:42,560 --> 00:11:42,880
is

318
00:11:42,880 --> 00:11:46,160
a big big technique it's been used

319
00:11:46,160 --> 00:11:48,560
a great deal over the years and that

320
00:11:48,560 --> 00:11:51,279
really is reflected in the number of sub

321
00:11:51,279 --> 00:11:54,079
techniques now also notice that this

322
00:11:54,079 --> 00:11:54,880
technique

323
00:11:54,880 --> 00:11:58,000
is pertinent to linux platform windows

324
00:11:58,000 --> 00:11:58,639
platform

325
00:11:58,639 --> 00:12:00,880
mac os platform and probably every

326
00:12:00,880 --> 00:12:03,200
operating system that's ever existed

327
00:12:03,200 --> 00:12:06,720
in the history of operating systems

328
00:12:06,720 --> 00:12:09,440
and so you need a lot of sub techniques

329
00:12:09,440 --> 00:12:10,000
to

330
00:12:10,000 --> 00:12:11,839
show all the different ways that you

331
00:12:11,839 --> 00:12:13,839
could attack these various different

332
00:12:13,839 --> 00:12:16,639
operating systems another thing that

333
00:12:16,639 --> 00:12:17,760
you'll notice here

334
00:12:17,760 --> 00:12:20,480
if you look at a particular technique is

335
00:12:20,480 --> 00:12:22,480
you'll find a great deal of historical

336
00:12:22,480 --> 00:12:23,360
research

337
00:12:23,360 --> 00:12:25,600
that's been performed so really any time

338
00:12:25,600 --> 00:12:27,760
that this technique has been used

339
00:12:27,760 --> 00:12:30,800
in a breach or a compromise or a

340
00:12:30,800 --> 00:12:32,240
prominent attack

341
00:12:32,240 --> 00:12:34,240
and there there's been public

342
00:12:34,240 --> 00:12:36,240
information published about that

343
00:12:36,240 --> 00:12:37,920
you'll find that reflected here there's

344
00:12:37,920 --> 00:12:40,320
a great deal of threat intelligence

345
00:12:40,320 --> 00:12:42,240
that goes into the miter attack and

346
00:12:42,240 --> 00:12:43,440
that's one of the most

347
00:12:43,440 --> 00:12:46,000
valuable parts of mitre attack is to

348
00:12:46,000 --> 00:12:47,279
understand

349
00:12:47,279 --> 00:12:50,160
when these techniques have been used and

350
00:12:50,160 --> 00:12:50,720
to what

351
00:12:50,720 --> 00:12:52,720
adversary groups these techniques have

352
00:12:52,720 --> 00:12:56,000
been attributed in the past

353
00:12:56,000 --> 00:12:58,320
so let's talk about item number three on

354
00:12:58,320 --> 00:12:59,360
our list for

355
00:12:59,360 --> 00:13:02,240
adversary emulation and that is atomic

356
00:13:02,240 --> 00:13:03,360
red team

357
00:13:03,360 --> 00:13:05,120
atomic red team is an open source

358
00:13:05,120 --> 00:13:07,200
project it is free

359
00:13:07,200 --> 00:13:10,000
it's published on github and it was

360
00:13:10,000 --> 00:13:12,240
created by a company called red canary

361
00:13:12,240 --> 00:13:15,279
and red canary continues to maintain

362
00:13:15,279 --> 00:13:17,440
atomic red team if you're not familiar

363
00:13:17,440 --> 00:13:18,880
with red canary they are

364
00:13:18,880 --> 00:13:21,760
one of the most prolific contributors to

365
00:13:21,760 --> 00:13:23,839
the security community that you'll ever

366
00:13:23,839 --> 00:13:24,560
find

367
00:13:24,560 --> 00:13:27,200
just an amazing company a really open

368
00:13:27,200 --> 00:13:28,399
group of people

369
00:13:28,399 --> 00:13:30,560
who are really dedicated to sort of

370
00:13:30,560 --> 00:13:31,839
helping the community

371
00:13:31,839 --> 00:13:33,200
they're also a commercial company you

372
00:13:33,200 --> 00:13:34,959
can check out their commercial offerings

373
00:13:34,959 --> 00:13:36,240
as well

374
00:13:36,240 --> 00:13:39,440
but just a really big fan of red canary

375
00:13:39,440 --> 00:13:41,680
let's talk about what atomic red team

376
00:13:41,680 --> 00:13:42,240
brings

377
00:13:42,240 --> 00:13:45,839
to us in terms of adversary emulation

378
00:13:45,839 --> 00:13:48,000
so this is looking at the atomic red

379
00:13:48,000 --> 00:13:50,000
team project on github

380
00:13:50,000 --> 00:13:52,000
its organization mirrors the

381
00:13:52,000 --> 00:13:54,079
organization of

382
00:13:54,079 --> 00:13:56,240
miter attack itself in this case we're

383
00:13:56,240 --> 00:13:58,480
looking at t1547

384
00:13:58,480 --> 00:14:00,000
that's the same technique we looked at

385
00:14:00,000 --> 00:14:01,680
earlier when we were looking at mitre

386
00:14:01,680 --> 00:14:02,800
attack

387
00:14:02,800 --> 00:14:05,600
but where atomic red team comes in is it

388
00:14:05,600 --> 00:14:06,320
picks up

389
00:14:06,320 --> 00:14:09,920
where mitre attack stops and where miter

390
00:14:09,920 --> 00:14:12,079
attack will describe a certain technique

391
00:14:12,079 --> 00:14:13,920
in quite a bit of detail

392
00:14:13,920 --> 00:14:16,560
it stops short of giving us something

393
00:14:16,560 --> 00:14:17,120
that we can

394
00:14:17,120 --> 00:14:19,600
actually execute so it does not give us

395
00:14:19,600 --> 00:14:21,040
source code for

396
00:14:21,040 --> 00:14:23,120
a malicious program it does not give us

397
00:14:23,120 --> 00:14:25,279
a command line that an attacker might

398
00:14:25,279 --> 00:14:26,160
run and that's

399
00:14:26,160 --> 00:14:28,639
where atomic red team comes in atomic

400
00:14:28,639 --> 00:14:30,000
red team provides just

401
00:14:30,000 --> 00:14:33,199
that they call them atomics and atomics

402
00:14:33,199 --> 00:14:35,519
are the actual code for a particular

403
00:14:35,519 --> 00:14:37,199
operating system or a particular

404
00:14:37,199 --> 00:14:38,959
environment that you would run

405
00:14:38,959 --> 00:14:42,000
to implement a technique and so

406
00:14:42,000 --> 00:14:43,440
when we're trying to do adversary

407
00:14:43,440 --> 00:14:46,480
simulation atomic red team fills a big

408
00:14:46,480 --> 00:14:48,639
void it gives us a very large

409
00:14:48,639 --> 00:14:51,440
library of techniques that we can

410
00:14:51,440 --> 00:14:52,079
emulate

411
00:14:52,079 --> 00:14:55,920
at will because we have very specific

412
00:14:55,920 --> 00:14:59,839
atomic tests defined

413
00:15:00,320 --> 00:15:02,399
so let's talk about our fourth and final

414
00:15:02,399 --> 00:15:03,760
component of our

415
00:15:03,760 --> 00:15:06,480
adversary emulation recipe that we're

416
00:15:06,480 --> 00:15:07,440
creating

417
00:15:07,440 --> 00:15:09,920
now recall that we're using attack range

418
00:15:09,920 --> 00:15:10,800
to spin up

419
00:15:10,800 --> 00:15:14,000
some target infrastructure in the cloud

420
00:15:14,000 --> 00:15:16,560
we're selecting some techniques from

421
00:15:16,560 --> 00:15:18,000
mitre attack

422
00:15:18,000 --> 00:15:21,279
and we're instructing

423
00:15:21,279 --> 00:15:24,399
attack range to run atomic tests from

424
00:15:24,399 --> 00:15:25,760
atomic red team

425
00:15:25,760 --> 00:15:28,160
that are aligned with our techniques

426
00:15:28,160 --> 00:15:29,920
from mitre attack

427
00:15:29,920 --> 00:15:33,040
and running those against that cloud

428
00:15:33,040 --> 00:15:34,320
infrastructure

429
00:15:34,320 --> 00:15:36,959
now the result of that will be telemetry

430
00:15:36,959 --> 00:15:38,480
it will be logs

431
00:15:38,480 --> 00:15:40,639
and other types of events that will be

432
00:15:40,639 --> 00:15:41,920
stored in splunk

433
00:15:41,920 --> 00:15:44,639
as a result of executing these

434
00:15:44,639 --> 00:15:46,720
emulations

435
00:15:46,720 --> 00:15:48,720
now for convenience the way we've

436
00:15:48,720 --> 00:15:50,240
organized this

437
00:15:50,240 --> 00:15:51,920
is that all the results from a

438
00:15:51,920 --> 00:15:53,360
particular technique

439
00:15:53,360 --> 00:15:56,480
are stored in their own index so you can

440
00:15:56,480 --> 00:15:57,040
see here

441
00:15:57,040 --> 00:15:59,199
in the splunk search window we're

442
00:15:59,199 --> 00:16:00,639
specifying index

443
00:16:00,639 --> 00:16:04,240
equals t1547 star

444
00:16:04,240 --> 00:16:06,560
star is a wild card there's actually

445
00:16:06,560 --> 00:16:08,160
multiple indexes

446
00:16:08,160 --> 00:16:09,839
for some of these techniques but they

447
00:16:09,839 --> 00:16:11,680
all begin with

448
00:16:11,680 --> 00:16:14,800
the technique id now you'll find some

449
00:16:14,800 --> 00:16:17,199
also that have a technique id followed

450
00:16:17,199 --> 00:16:18,639
by a dot

451
00:16:18,639 --> 00:16:22,000
and then a sub technique id and so

452
00:16:22,000 --> 00:16:25,279
watch out for those as well now beyond

453
00:16:25,279 --> 00:16:27,199
specifying the indexes we're showing

454
00:16:27,199 --> 00:16:29,519
here you can

455
00:16:29,519 --> 00:16:32,560
run all sorts of splunk search commands

456
00:16:32,560 --> 00:16:34,480
any other field that you want to search

457
00:16:34,480 --> 00:16:36,720
on you can simply place after that

458
00:16:36,720 --> 00:16:42,079
index equals t and then the technique id

459
00:16:43,040 --> 00:16:44,720
i want to show you a couple of more

460
00:16:44,720 --> 00:16:46,720
important things that you'll need to

461
00:16:46,720 --> 00:16:48,839
keep in mind as you're searching through

462
00:16:48,839 --> 00:16:50,800
splunk one is that

463
00:16:50,800 --> 00:16:53,920
you want this time picker to be set to

464
00:16:53,920 --> 00:16:56,880
all time don't set it to something

465
00:16:56,880 --> 00:16:58,160
shorter than that like

466
00:16:58,160 --> 00:17:01,199
last 24 hours or last four hours

467
00:17:01,199 --> 00:17:04,319
because this data was collected a few

468
00:17:04,319 --> 00:17:06,079
weeks ago

469
00:17:06,079 --> 00:17:08,559
set it to all time it's important though

470
00:17:08,559 --> 00:17:09,359
to remember

471
00:17:09,359 --> 00:17:11,439
that if you go back to your production

472
00:17:11,439 --> 00:17:12,799
splunk instance

473
00:17:12,799 --> 00:17:15,359
at your day job don't run searches for

474
00:17:15,359 --> 00:17:16,000
all time

475
00:17:16,000 --> 00:17:18,240
because they're typically not going to

476
00:17:18,240 --> 00:17:20,079
be very performant and they typically

477
00:17:20,079 --> 00:17:22,319
will consume a lot of resources and then

478
00:17:22,319 --> 00:17:23,760
your splunk admin

479
00:17:23,760 --> 00:17:27,039
will be upset at you and probably at me

480
00:17:27,039 --> 00:17:29,600
so use all time here in the holiday hack

481
00:17:29,600 --> 00:17:31,360
challenge but don't use that

482
00:17:31,360 --> 00:17:32,960
when you are searching in your

483
00:17:32,960 --> 00:17:35,360
production splunk instance

484
00:17:35,360 --> 00:17:37,200
you should also use smart mode as

485
00:17:37,200 --> 00:17:38,640
indicated here

486
00:17:38,640 --> 00:17:40,480
once in a while this will get set to

487
00:17:40,480 --> 00:17:42,160
something called fast mode

488
00:17:42,160 --> 00:17:44,000
you typically don't want that so just

489
00:17:44,000 --> 00:17:45,679
make sure that that is in

490
00:17:45,679 --> 00:17:48,400
smart mode

491
00:17:50,720 --> 00:17:52,240
another piece of advice that i'll give

492
00:17:52,240 --> 00:17:54,240
you is to watch the

493
00:17:54,240 --> 00:17:58,000
kringle con 2 video from splunk

494
00:17:58,000 --> 00:18:00,080
it's called dashing through the logs

495
00:18:00,080 --> 00:18:02,000
it's from 2019

496
00:18:02,000 --> 00:18:04,480
it was written and presented by james

497
00:18:04,480 --> 00:18:06,320
brodsky of splunk

498
00:18:06,320 --> 00:18:08,720
there's loads of good recommendations in

499
00:18:08,720 --> 00:18:10,720
there about how to be more effective

500
00:18:10,720 --> 00:18:14,480
at searching splunk and how to traverse

501
00:18:14,480 --> 00:18:18,320
through security related source types

502
00:18:18,320 --> 00:18:20,799
inside splunk it's a wealth of knowledge

503
00:18:20,799 --> 00:18:21,360
there

504
00:18:21,360 --> 00:18:23,200
we didn't want to repeat it but if you

505
00:18:23,200 --> 00:18:24,720
feel like you need a little bit more

506
00:18:24,720 --> 00:18:27,200
background on how to search in splunk i

507
00:18:27,200 --> 00:18:28,799
definitely recommend that you check out

508
00:18:28,799 --> 00:18:31,360
this talk

509
00:18:31,840 --> 00:18:33,440
and this might be the most important

510
00:18:33,440 --> 00:18:36,000
slide that you want to take note of

511
00:18:36,000 --> 00:18:38,559
if you're preparing for the splunk

512
00:18:38,559 --> 00:18:39,200
challenge

513
00:18:39,200 --> 00:18:43,679
within holiday hack challenge 2020

514
00:18:43,679 --> 00:18:46,559
stay frosty

515
00:18:53,200 --> 00:18:56,080
thank you so much please do reach out on

516
00:18:56,080 --> 00:18:56,960
twitter

517
00:18:56,960 --> 00:18:59,600
if you have any questions or if you want

518
00:18:59,600 --> 00:19:00,080
to

519
00:19:00,080 --> 00:19:02,720
get any more information on adversary

520
00:19:02,720 --> 00:19:03,840
emulation

521
00:19:03,840 --> 00:19:06,400
i'm at dave herald and we look forward

522
00:19:06,400 --> 00:19:08,559
to you participating in kringlecon

523
00:19:08,559 --> 00:19:11,840
and holiday hack challenge

524
00:19:12,760 --> 00:19:15,920
[Music]

