1
00:00:00,000 --> 00:00:01,760
principal technology technical

2
00:00:01,760 --> 00:00:04,640
consultant at mimecasts

3
00:00:04,640 --> 00:00:07,919
and he joined broadcast in 2015 with the

4
00:00:07,919 --> 00:00:09,920
opening of the sydney office

5
00:00:09,920 --> 00:00:12,880
cool leading the growth and development

6
00:00:12,880 --> 00:00:15,200
of the local team there

7
00:00:15,200 --> 00:00:17,520
with over 20 years experience across

8
00:00:17,520 --> 00:00:18,240
development

9
00:00:18,240 --> 00:00:21,359
ui ux technology communication

10
00:00:21,359 --> 00:00:23,760
training and development and mentoring

11
00:00:23,760 --> 00:00:24,480
garrett now

12
00:00:24,480 --> 00:00:26,080
works to help organizations to

13
00:00:26,080 --> 00:00:27,599
understand and manage their cyber

14
00:00:27,599 --> 00:00:28,320
resilience

15
00:00:28,320 --> 00:00:31,679
strategies so can we have a warm round

16
00:00:31,679 --> 00:00:33,280
of applause for amy and gary who are

17
00:00:33,280 --> 00:00:35,120
going to come up on stage

18
00:00:35,120 --> 00:00:36,399
and they're going to be talking through

19
00:00:36,399 --> 00:00:38,399
the lessons learned from a year

20
00:00:38,399 --> 00:00:45,840
of cyber security podcast interviews

21
00:01:04,799 --> 00:01:08,479
so picture this it's 2000 it's 2017

22
00:01:08,479 --> 00:01:10,080
and i'm five months into working at

23
00:01:10,080 --> 00:01:12,240
mimecast it's my first role

24
00:01:12,240 --> 00:01:14,880
in cyber security i've recently

25
00:01:14,880 --> 00:01:15,520
completed

26
00:01:15,520 --> 00:01:18,080
all my cyber awareness training and

27
00:01:18,080 --> 00:01:19,759
given my inexperience

28
00:01:19,759 --> 00:01:22,159
paranoia might be running a little bit

29
00:01:22,159 --> 00:01:23,360
high

30
00:01:23,360 --> 00:01:25,520
i'm at a conference that also happens to

31
00:01:25,520 --> 00:01:27,759
be on the gold coast

32
00:01:27,759 --> 00:01:29,520
and after a long day on the trade show

33
00:01:29,520 --> 00:01:31,759
floor i go up to my room to catch up on

34
00:01:31,759 --> 00:01:32,799
some work

35
00:01:32,799 --> 00:01:35,040
but my mouse cursor keeps getting away

36
00:01:35,040 --> 00:01:38,159
from me and drifting off the page

37
00:01:38,159 --> 00:01:41,200
right compromise machine but how

38
00:01:41,200 --> 00:01:43,520
was it the wi-fi network at the airport

39
00:01:43,520 --> 00:01:44,960
did i leave my laptop bag

40
00:01:44,960 --> 00:01:47,119
somewhere unattended was it because i

41
00:01:47,119 --> 00:01:49,119
checked my personal email

42
00:01:49,119 --> 00:01:51,759
what to do next i did what anyone would

43
00:01:51,759 --> 00:01:52,320
do

44
00:01:52,320 --> 00:01:55,439
i immediately called the saiso

45
00:01:55,439 --> 00:01:57,280
now because i had recently competed in

46
00:01:57,280 --> 00:01:58,960
the corporate triathlon and happened to

47
00:01:58,960 --> 00:01:59,840
live near our

48
00:01:59,840 --> 00:02:01,680
cell mark i had his phone number in my

49
00:02:01,680 --> 00:02:02,880
phone

50
00:02:02,880 --> 00:02:05,200
before i even finished describing the

51
00:02:05,200 --> 00:02:06,159
nature of my

52
00:02:06,159 --> 00:02:09,360
compromise machine mark cut me off to

53
00:02:09,360 --> 00:02:11,840
ask where my actual mouse was

54
00:02:11,840 --> 00:02:14,879
in my laptop bag why right

55
00:02:14,879 --> 00:02:18,560
being compressed in my laptop bag

56
00:02:18,560 --> 00:02:20,879
now did i feel silly and embarrassed of

57
00:02:20,879 --> 00:02:23,280
course and did mark regret giving me

58
00:02:23,280 --> 00:02:26,400
his personal phone number probably

59
00:02:26,400 --> 00:02:28,319
but the point is i was brought into a

60
00:02:28,319 --> 00:02:30,560
culture that

61
00:02:30,560 --> 00:02:32,160
encouraged employees to speak up or

62
00:02:32,160 --> 00:02:34,000
report anything that they deemed

63
00:02:34,000 --> 00:02:37,280
suspicious going direct to the siso

64
00:02:37,280 --> 00:02:39,840
is definitely not the recommended route

65
00:02:39,840 --> 00:02:41,280
but creating that culture where

66
00:02:41,280 --> 00:02:43,200
employees feel safe to report a mistake

67
00:02:43,200 --> 00:02:44,560
like clicking on a bad

68
00:02:44,560 --> 00:02:46,640
link or reporting anything that seems

69
00:02:46,640 --> 00:02:47,840
off is

70
00:02:47,840 --> 00:02:50,080
absolutely critical to a cyber resilient

71
00:02:50,080 --> 00:02:51,040
strategy

72
00:02:51,040 --> 00:02:52,800
and this is what we heard from a guest

73
00:02:52,800 --> 00:02:55,280
our guest during a year of security

74
00:02:55,280 --> 00:02:58,319
podcast interviews

75
00:02:58,319 --> 00:03:00,319
as a weekly listener to the podcast and

76
00:03:00,319 --> 00:03:02,480
a marketing professional relatively new

77
00:03:02,480 --> 00:03:05,200
to the industry five years ago i can say

78
00:03:05,200 --> 00:03:06,400
that i learned a ton

79
00:03:06,400 --> 00:03:07,920
but i think there's really something in

80
00:03:07,920 --> 00:03:10,480
every episode no matter how deep you are

81
00:03:10,480 --> 00:03:12,319
in the space and you know if you're

82
00:03:12,319 --> 00:03:13,840
looking for an additional way

83
00:03:13,840 --> 00:03:18,080
for for easy to consume information and

84
00:03:18,080 --> 00:03:19,760
over the course of the year we are lucky

85
00:03:19,760 --> 00:03:21,599
to be joined by some of australia's

86
00:03:21,599 --> 00:03:24,480
in the world's mostly most respected

87
00:03:24,480 --> 00:03:26,239
leaders in cyber resilience

88
00:03:26,239 --> 00:03:28,239
and this talk is a shortcut to their

89
00:03:28,239 --> 00:03:30,400
wisdom

90
00:03:30,400 --> 00:03:32,799
throughout the podcast uh we started to

91
00:03:32,799 --> 00:03:35,519
see the common themes emerging

92
00:03:35,519 --> 00:03:37,599
so send over to well before we start

93
00:03:37,599 --> 00:03:38,959
digging into those i'm gonna hand over

94
00:03:38,959 --> 00:03:39,440
to gar

95
00:03:39,440 --> 00:03:41,519
to tell us the reason the podcast came

96
00:03:41,519 --> 00:03:43,040
about and the vision for starting the

97
00:03:43,040 --> 00:03:44,080
podcast

98
00:03:44,080 --> 00:03:46,720
thanks amy yeah so look i i suspect like

99
00:03:46,720 --> 00:03:47,680
many people here

100
00:03:47,680 --> 00:03:50,799
um use podcasts as a way to consume

101
00:03:50,799 --> 00:03:52,560
information and learn quickly so things

102
00:03:52,560 --> 00:03:53,840
like dark net diaries

103
00:03:53,840 --> 00:03:55,680
uh risky biz those kind of podcasts i

104
00:03:55,680 --> 00:03:57,360
find them really really useful

105
00:03:57,360 --> 00:03:58,879
and had it in my mind that it would be

106
00:03:58,879 --> 00:04:00,319
good to be able to have conversations

107
00:04:00,319 --> 00:04:02,239
with local security leaders

108
00:04:02,239 --> 00:04:05,200
authors academics and and get some time

109
00:04:05,200 --> 00:04:06,640
with those people with a view to

110
00:04:06,640 --> 00:04:08,000
hopefully providing

111
00:04:08,000 --> 00:04:09,760
something back to the cyber security

112
00:04:09,760 --> 00:04:11,920
community in australia

113
00:04:11,920 --> 00:04:13,920
and luckily so dan mcdermott who's the

114
00:04:13,920 --> 00:04:15,599
the guy in the uh the photo there

115
00:04:15,599 --> 00:04:17,839
um he's the co-host of the the newsley

116
00:04:17,839 --> 00:04:19,759
episode the news episodes which we do

117
00:04:19,759 --> 00:04:20,798
every two weeks with

118
00:04:20,798 --> 00:04:23,520
bradley singh uh but he was on board too

119
00:04:23,520 --> 00:04:24,800
and we started

120
00:04:24,800 --> 00:04:27,199
uh it's well over a year ago now and it

121
00:04:27,199 --> 00:04:28,639
was myself and a guy called gregory

122
00:04:28,639 --> 00:04:30,400
jeffrey originally and really the only

123
00:04:30,400 --> 00:04:31,919
thing that we wanted to do was make sure

124
00:04:31,919 --> 00:04:33,440
that it was going to be

125
00:04:33,440 --> 00:04:36,000
interesting conversations no sales like

126
00:04:36,000 --> 00:04:37,759
we're aware there were vendors so we had

127
00:04:37,759 --> 00:04:38,800
to be

128
00:04:38,800 --> 00:04:40,560
really strict around anyone who's coming

129
00:04:40,560 --> 00:04:42,080
on no sales pitches

130
00:04:42,080 --> 00:04:43,360
none of that stuff that we wanted to

131
00:04:43,360 --> 00:04:45,520
have quality conversations around cyber

132
00:04:45,520 --> 00:04:46,400
resilience and

133
00:04:46,400 --> 00:04:50,000
so far so good i love that it was such a

134
00:04:50,000 --> 00:04:52,080
collective effort resulting in nearly

135
00:04:52,080 --> 00:04:54,400
45 hours of talking and uncovering

136
00:04:54,400 --> 00:04:56,720
insights from experts

137
00:04:56,720 --> 00:04:58,400
now these are the themes that we started

138
00:04:58,400 --> 00:05:00,240
to see emerging so i'll throw over to

139
00:05:00,240 --> 00:05:01,680
gargan to take us through

140
00:05:01,680 --> 00:05:04,720
how these developed yeah i mean one of

141
00:05:04,720 --> 00:05:05,840
the things that happened over

142
00:05:05,840 --> 00:05:08,320
all these conversations is that um yeah

143
00:05:08,320 --> 00:05:09,520
for me i had some

144
00:05:09,520 --> 00:05:12,000
opinions confirmed and definitely some

145
00:05:12,000 --> 00:05:12,800
challenged

146
00:05:12,800 --> 00:05:15,039
and quite often left with new insights

147
00:05:15,039 --> 00:05:16,639
new opinions things that i didn't even

148
00:05:16,639 --> 00:05:17,360
realize i

149
00:05:17,360 --> 00:05:19,360
maybe needed to know but the thing that

150
00:05:19,360 --> 00:05:20,960
really stood out more than anything else

151
00:05:20,960 --> 00:05:22,400
for me was just the

152
00:05:22,400 --> 00:05:24,320
the spirit of collaboration and sharing

153
00:05:24,320 --> 00:05:25,600
that people showed up with

154
00:05:25,600 --> 00:05:27,759
and that to me was was just very

155
00:05:27,759 --> 00:05:29,600
meaningful people were willing to give

156
00:05:29,600 --> 00:05:31,680
an hour of their time people who are

157
00:05:31,680 --> 00:05:33,199
very very busy people

158
00:05:33,199 --> 00:05:34,960
and but as you can see here on the sort

159
00:05:34,960 --> 00:05:36,720
of the blackboard slide

160
00:05:36,720 --> 00:05:38,479
there certainly were themes and lessons

161
00:05:38,479 --> 00:05:39,680
that emerged over all of the

162
00:05:39,680 --> 00:05:42,960
conversations which we'll go through

163
00:05:43,680 --> 00:05:45,600
so i think people was one of the the

164
00:05:45,600 --> 00:05:47,360
most common topics and it was weaved

165
00:05:47,360 --> 00:05:49,680
into nearly every conversation

166
00:05:49,680 --> 00:05:51,520
that we had so we'll start by talking

167
00:05:51,520 --> 00:05:53,919
about people it's not likely what you'd

168
00:05:53,919 --> 00:05:55,280
expect to be talking about

169
00:05:55,280 --> 00:05:57,520
in a cyber resiliency podcast but people

170
00:05:57,520 --> 00:05:58,720
are core to what

171
00:05:58,720 --> 00:06:01,680
how we succeed and what we do and most

172
00:06:01,680 --> 00:06:02,240
relevant

173
00:06:02,240 --> 00:06:04,240
in regard to people is at a cultural

174
00:06:04,240 --> 00:06:06,160
level and an end user training

175
00:06:06,160 --> 00:06:10,160
level now i spoke to my

176
00:06:10,160 --> 00:06:13,840
experience i spoke to my experience in

177
00:06:13,840 --> 00:06:15,680
reporting what i deemed a suspicious

178
00:06:15,680 --> 00:06:18,160
activity but these are the reasons that

179
00:06:18,160 --> 00:06:18,720
staff

180
00:06:18,720 --> 00:06:22,560
don't report a suspicious activity 38

181
00:06:22,560 --> 00:06:24,720
said they didn't think it was important

182
00:06:24,720 --> 00:06:26,000
and 24

183
00:06:26,000 --> 00:06:29,360
were too embarrassed to report it 19

184
00:06:29,360 --> 00:06:31,520
didn't know how to just call this iso

185
00:06:31,520 --> 00:06:32,400
right

186
00:06:32,400 --> 00:06:34,639
and 10 thought reporting it would

187
00:06:34,639 --> 00:06:36,319
jeopardize their job

188
00:06:36,319 --> 00:06:38,720
so one in five australian workers have

189
00:06:38,720 --> 00:06:40,319
experienced a privacy issue

190
00:06:40,319 --> 00:06:42,400
and didn't report it so this is part of

191
00:06:42,400 --> 00:06:44,319
our research around privacy awareness

192
00:06:44,319 --> 00:06:46,400
week with over a thousand respondents

193
00:06:46,400 --> 00:06:48,080
so it really does go back to the point

194
00:06:48,080 --> 00:06:49,840
that we kept hearing from our guests

195
00:06:49,840 --> 00:06:51,680
that we need to encourage employees to

196
00:06:51,680 --> 00:06:53,680
feel safe and encouraged to report

197
00:06:53,680 --> 00:06:54,880
anything suspicious

198
00:06:54,880 --> 00:06:57,680
and have a culture of transparency with

199
00:06:57,680 --> 00:06:58,319
an open

200
00:06:58,319 --> 00:07:02,479
dialogue now everyone is talking about

201
00:07:02,479 --> 00:07:03,919
end user training and it shows that

202
00:07:03,919 --> 00:07:05,520
we're starting to get this right from a

203
00:07:05,520 --> 00:07:07,120
priorities perspective

204
00:07:07,120 --> 00:07:08,800
and organizations are working through

205
00:07:08,800 --> 00:07:10,160
current best practice

206
00:07:10,160 --> 00:07:12,080
practice approaches to deliver effective

207
00:07:12,080 --> 00:07:13,280
training

208
00:07:13,280 --> 00:07:15,360
kovit has been the big amplifier for

209
00:07:15,360 --> 00:07:16,560
this progression

210
00:07:16,560 --> 00:07:17,759
gar can you take us through what the

211
00:07:17,759 --> 00:07:19,919
guests had to say about this

212
00:07:19,919 --> 00:07:22,080
yeah definitely i think the covet point

213
00:07:22,080 --> 00:07:23,440
is particularly relevant

214
00:07:23,440 --> 00:07:25,520
and what we saw and other vendors too

215
00:07:25,520 --> 00:07:26,800
you know there was reports coming out

216
00:07:26,800 --> 00:07:27,360
were

217
00:07:27,360 --> 00:07:30,720
from recorded future hollow on the the

218
00:07:30,720 --> 00:07:32,479
spike of things like malicious domains

219
00:07:32,479 --> 00:07:34,479
being registered as covet hit

220
00:07:34,479 --> 00:07:36,880
and what what became very obvious was

221
00:07:36,880 --> 00:07:38,000
that awareness training

222
00:07:38,000 --> 00:07:39,840
in those situations was critical because

223
00:07:39,840 --> 00:07:41,840
people were sitting at home

224
00:07:41,840 --> 00:07:44,479
no perimeter in work environments where

225
00:07:44,479 --> 00:07:45,520
they needed to be able to make good

226
00:07:45,520 --> 00:07:47,120
decisions in the moment

227
00:07:47,120 --> 00:07:50,240
um we had a lot of guests talk about

228
00:07:50,240 --> 00:07:52,800
the what casey ellis called it was the

229
00:07:52,800 --> 00:07:54,639
huma intractable human problem

230
00:07:54,639 --> 00:07:58,319
yesterday and it came up with everybody

231
00:07:58,319 --> 00:07:59,840
cheer and joshie talked about it phil

232
00:07:59,840 --> 00:08:02,240
zongo dr kate joram

233
00:08:02,240 --> 00:08:05,280
uh cinel sal we had so many people

234
00:08:05,280 --> 00:08:07,120
nearly every episode we ended up talking

235
00:08:07,120 --> 00:08:07,520
about

236
00:08:07,520 --> 00:08:10,319
the people the big lessons uh is that

237
00:08:10,319 --> 00:08:10,879
cut through

238
00:08:10,879 --> 00:08:12,639
is the most important thing when it

239
00:08:12,639 --> 00:08:14,160
comes to cyber security awareness

240
00:08:14,160 --> 00:08:15,680
training and messaging

241
00:08:15,680 --> 00:08:19,199
and the move away from you know boring

242
00:08:19,199 --> 00:08:21,199
heavy technical emails that are

243
00:08:21,199 --> 00:08:22,240
information heavy

244
00:08:22,240 --> 00:08:23,840
and the move more towards a sort of

245
00:08:23,840 --> 00:08:25,599
behavior change mentality

246
00:08:25,599 --> 00:08:28,080
and leaning and lending from things like

247
00:08:28,080 --> 00:08:29,520
the advertising industry where you're

248
00:08:29,520 --> 00:08:31,120
using whatever it takes you know it may

249
00:08:31,120 --> 00:08:32,799
be videos it may be

250
00:08:32,799 --> 00:08:35,919
funny posters it could be engaging in

251
00:08:35,919 --> 00:08:37,200
person training with

252
00:08:37,200 --> 00:08:40,080
with qualified trainers but it's sort of

253
00:08:40,080 --> 00:08:41,360
a do whatever it takes to get the

254
00:08:41,360 --> 00:08:42,799
messaging through just simple

255
00:08:42,799 --> 00:08:45,920
actionable behavior change um many of

256
00:08:45,920 --> 00:08:48,000
the conversations led to this idea of

257
00:08:48,000 --> 00:08:49,360
some of the failures that we've had when

258
00:08:49,360 --> 00:08:51,360
it comes to the human side which is that

259
00:08:51,360 --> 00:08:52,839
we focused on

260
00:08:52,839 --> 00:08:55,040
uh the compliance rate you know how many

261
00:08:55,040 --> 00:08:57,360
people have done a cbt or lms

262
00:08:57,360 --> 00:08:59,600
training course and you know high fives

263
00:08:59,600 --> 00:09:01,120
all around we got a 95

264
00:09:01,120 --> 00:09:02,480
completion rate but that doesn't

265
00:09:02,480 --> 00:09:04,000
translate into people doing the right

266
00:09:04,000 --> 00:09:04,720
thing

267
00:09:04,720 --> 00:09:06,160
uh you know on a friday afternoon when

268
00:09:06,160 --> 00:09:08,160
people might have had a big gala

269
00:09:08,160 --> 00:09:09,680
at dinner the night before you know that

270
00:09:09,680 --> 00:09:11,279
ability to make good decisions in the

271
00:09:11,279 --> 00:09:12,160
moment

272
00:09:12,160 --> 00:09:14,480
um so we're seeing i think a good shift

273
00:09:14,480 --> 00:09:16,480
there there is some good measures

274
00:09:16,480 --> 00:09:19,519
um things like fish campaign so you know

275
00:09:19,519 --> 00:09:20,800
did people click on the links the one

276
00:09:20,800 --> 00:09:22,640
thing i'd call out there is that's one

277
00:09:22,640 --> 00:09:24,160
very specific

278
00:09:24,160 --> 00:09:26,399
behavior but also what about locking

279
00:09:26,399 --> 00:09:27,760
laptops what about choosing good

280
00:09:27,760 --> 00:09:29,760
passphrases or passwords and

281
00:09:29,760 --> 00:09:31,120
all of those other things that are part

282
00:09:31,120 --> 00:09:33,040
of good cyber security culture

283
00:09:33,040 --> 00:09:35,200
and behavior change and then really the

284
00:09:35,200 --> 00:09:36,480
last point is around

285
00:09:36,480 --> 00:09:38,320
leadership buy-in which you know again

286
00:09:38,320 --> 00:09:39,600
it sort of bubbled up in

287
00:09:39,600 --> 00:09:42,000
in many of the conversations um but this

288
00:09:42,000 --> 00:09:43,600
idea that

289
00:09:43,600 --> 00:09:45,440
none of this succeeds if there isn't

290
00:09:45,440 --> 00:09:46,720
buy-in from not just the

291
00:09:46,720 --> 00:09:48,640
cyber security leadership but also the

292
00:09:48,640 --> 00:09:50,080
broader leadership

293
00:09:50,080 --> 00:09:52,320
within an organization the xco elt

294
00:09:52,320 --> 00:09:53,519
whatever it is

295
00:09:53,519 --> 00:09:55,920
and they need to be visible and vocal um

296
00:09:55,920 --> 00:09:57,200
it's it's one of those things that if

297
00:09:57,200 --> 00:09:58,560
you don't get that right

298
00:09:58,560 --> 00:10:00,480
people can walk into an organization and

299
00:10:00,480 --> 00:10:02,079
if they don't see

300
00:10:02,079 --> 00:10:04,000
the senior leadership taking the stuff

301
00:10:04,000 --> 00:10:05,839
seriously then it's very easy to kind of

302
00:10:05,839 --> 00:10:06,320
go

303
00:10:06,320 --> 00:10:07,839
i don't really need to either so yeah

304
00:10:07,839 --> 00:10:09,680
that buy-in from leadership

305
00:10:09,680 --> 00:10:11,680
yeah and working towards changing

306
00:10:11,680 --> 00:10:13,519
behavior and not just working towards

307
00:10:13,519 --> 00:10:14,800
compliance

308
00:10:14,800 --> 00:10:16,480
there's obviously more to the people

309
00:10:16,480 --> 00:10:18,399
side of cyber than just end user

310
00:10:18,399 --> 00:10:20,000
training and we had an episode with

311
00:10:20,000 --> 00:10:22,160
leone smith that walked us through

312
00:10:22,160 --> 00:10:24,399
the practical tips in navigating cyber

313
00:10:24,399 --> 00:10:25,279
safety

314
00:10:25,279 --> 00:10:28,240
with children i also wanted to share a

315
00:10:28,240 --> 00:10:30,160
story with one of my good friends

316
00:10:30,160 --> 00:10:32,720
laura jeffrey who i met in 2007 on the

317
00:10:32,720 --> 00:10:35,120
gold coast when we studied abroad here

318
00:10:35,120 --> 00:10:36,880
we're both from the northern hemisphere

319
00:10:36,880 --> 00:10:39,120
and we've made australia home

320
00:10:39,120 --> 00:10:41,440
now laura and her family were subject to

321
00:10:41,440 --> 00:10:42,240
a bec

322
00:10:42,240 --> 00:10:44,399
scam which which resulted in them

323
00:10:44,399 --> 00:10:46,640
transferring 65 000

324
00:10:46,640 --> 00:10:48,959
into a fraudulent bank account when they

325
00:10:48,959 --> 00:10:51,120
are doing custom cabinetry for their new

326
00:10:51,120 --> 00:10:52,320
home build

327
00:10:52,320 --> 00:10:54,560
i think laura's story is so relevant as

328
00:10:54,560 --> 00:10:56,079
it depicts how

329
00:10:56,079 --> 00:10:58,079
cyber security is it affects us right

330
00:10:58,079 --> 00:10:59,600
down to a personal level

331
00:10:59,600 --> 00:11:01,680
in our homes it's not just a business

332
00:11:01,680 --> 00:11:03,839
issue so here is laura's

333
00:11:03,839 --> 00:11:06,240
story

334
00:11:08,240 --> 00:11:10,399
bear with me i think this needs to go to

335
00:11:10,399 --> 00:11:12,839
go at a different

336
00:11:12,839 --> 00:11:15,839
audio

337
00:11:18,640 --> 00:11:28,560
try that again

338
00:11:28,560 --> 00:11:31,920
technical glitches

339
00:11:40,839 --> 00:11:43,600
again for everyone in the audience today

340
00:11:43,600 --> 00:11:45,279
i'm laura jeffrey

341
00:11:45,279 --> 00:11:48,320
i run a mining consultancy called tundra

342
00:11:48,320 --> 00:11:50,160
resource analytics and we

343
00:11:50,160 --> 00:11:53,360
primarily do mobile equipment strategy

344
00:11:53,360 --> 00:11:54,480
optimization

345
00:11:54,480 --> 00:11:57,680
and integration and separation work for

346
00:11:57,680 --> 00:11:59,279
acquisition and investment teams within

347
00:11:59,279 --> 00:12:00,959
the mining industry

348
00:12:00,959 --> 00:12:03,680
so i'm an accountant and my husband's an

349
00:12:03,680 --> 00:12:04,480
engineer

350
00:12:04,480 --> 00:12:06,800
and both of us would probably describe

351
00:12:06,800 --> 00:12:07,920
ourselves as

352
00:12:07,920 --> 00:12:11,120
fairly technologically astute and so we

353
00:12:11,120 --> 00:12:11,680
never

354
00:12:11,680 --> 00:12:13,040
imagined that we'd be in the position

355
00:12:13,040 --> 00:12:17,120
that we're in like any just described

356
00:12:18,000 --> 00:12:20,720
basically the cabinet maker's emails had

357
00:12:20,720 --> 00:12:21,360
been

358
00:12:21,360 --> 00:12:24,639
hacked or intercepted possibly

359
00:12:24,639 --> 00:12:26,480
after he clicked on a phishing link but

360
00:12:26,480 --> 00:12:28,320
we'll never get to sort of the bottom of

361
00:12:28,320 --> 00:12:30,079
how it happened

362
00:12:30,079 --> 00:12:32,160
his emails had been intercepted and they

363
00:12:32,160 --> 00:12:34,560
were sort of monitoring his engagements

364
00:12:34,560 --> 00:12:36,240
with his customers

365
00:12:36,240 --> 00:12:39,839
waiting i guess to um

366
00:12:39,839 --> 00:12:43,360
to bounce um and to convince

367
00:12:43,360 --> 00:12:46,480
unsuspecting victims to divert their

368
00:12:46,480 --> 00:12:47,120
money to

369
00:12:47,120 --> 00:12:50,160
their accounts and what's the reality of

370
00:12:50,160 --> 00:12:51,680
being a bec victim some of the most

371
00:12:51,680 --> 00:12:52,480
common

372
00:12:52,480 --> 00:12:55,920
reactions i had were um

373
00:12:55,920 --> 00:12:58,079
oh well the the bank will take care of

374
00:12:58,079 --> 00:12:59,440
it that the

375
00:12:59,440 --> 00:13:03,680
bank would somehow reinstate the balance

376
00:13:03,680 --> 00:13:03,920
of

377
00:13:03,920 --> 00:13:06,800
our account or that insurance would

378
00:13:06,800 --> 00:13:08,399
cover it or that it was the cabinet

379
00:13:08,399 --> 00:13:10,800
makers loss and not ours

380
00:13:10,800 --> 00:13:12,560
and all three of those things ended up

381
00:13:12,560 --> 00:13:14,800
being untrue so first of all

382
00:13:14,800 --> 00:13:17,120
because we willfully made a transaction

383
00:13:17,120 --> 00:13:17,920
to an account

384
00:13:17,920 --> 00:13:20,720
even if that was under sort of

385
00:13:20,720 --> 00:13:22,639
fraudulent terms and we made that

386
00:13:22,639 --> 00:13:24,639
payment in good faith

387
00:13:24,639 --> 00:13:26,480
we still made the payment willfully and

388
00:13:26,480 --> 00:13:28,560
because there was no unauthorized access

389
00:13:28,560 --> 00:13:30,320
to our account

390
00:13:30,320 --> 00:13:33,440
we're basically responsible for that

391
00:13:33,440 --> 00:13:35,920
the other thing is that cyber insurance

392
00:13:35,920 --> 00:13:37,920
is a really

393
00:13:37,920 --> 00:13:40,800
underdeveloped industry in australia and

394
00:13:40,800 --> 00:13:42,880
it's highly unlikely

395
00:13:42,880 --> 00:13:44,959
that businesses or individuals are

396
00:13:44,959 --> 00:13:46,320
covered

397
00:13:46,320 --> 00:13:49,279
for this sort of loss um and the third

398
00:13:49,279 --> 00:13:51,120
thing that sort of surprised us that was

399
00:13:51,120 --> 00:13:52,399
that even though it was the cabinet

400
00:13:52,399 --> 00:13:53,760
makers

401
00:13:53,760 --> 00:13:56,959
emails that were hacked um in the eyes

402
00:13:56,959 --> 00:13:57,600
of the law

403
00:13:57,600 --> 00:13:59,360
because we did actually receive the

404
00:13:59,360 --> 00:14:01,279
cabinets we had received goods for which

405
00:14:01,279 --> 00:14:02,720
we hadn't paid

406
00:14:02,720 --> 00:14:05,600
and therefore we were seen as the

407
00:14:05,600 --> 00:14:06,560
victims

408
00:14:06,560 --> 00:14:09,839
of the um of the crime and

409
00:14:09,839 --> 00:14:12,560
we were essentially responsible for

410
00:14:12,560 --> 00:14:14,959
bearing the extent of the loss

411
00:14:14,959 --> 00:14:18,800
and the impact on a human level

412
00:14:18,880 --> 00:14:22,639
it's also opened our eyes to

413
00:14:22,639 --> 00:14:25,680
to the magnitude of impact

414
00:14:25,680 --> 00:14:29,440
that it can have on people's lives so

415
00:14:29,440 --> 00:14:33,120
shortly after the um

416
00:14:33,120 --> 00:14:36,639
the events unfolded i filed a report

417
00:14:36,639 --> 00:14:39,360
with the national fraud reporting agency

418
00:14:39,360 --> 00:14:42,800
um and at the end you get a

419
00:14:42,800 --> 00:14:45,680
a reference number for your case and it

420
00:14:45,680 --> 00:14:48,079
said this is your reference number

421
00:14:48,079 --> 00:14:49,680
just so you know it is highly unlikely

422
00:14:49,680 --> 00:14:52,160
you will cover any of your funds

423
00:14:52,160 --> 00:14:56,160
this is the number to be on blue

424
00:14:57,680 --> 00:14:59,440
it makes me emotional thinking about it

425
00:14:59,440 --> 00:15:01,600
thinking that um people could be

426
00:15:01,600 --> 00:15:02,880
impacted by this

427
00:15:02,880 --> 00:15:05,920
so substantially that they might be you

428
00:15:05,920 --> 00:15:06,160
know

429
00:15:06,160 --> 00:15:08,959
triggered to um take that sort of action

430
00:15:08,959 --> 00:15:09,760
this is the

431
00:15:09,760 --> 00:15:11,680
um the number to be on blue and this is

432
00:15:11,680 --> 00:15:14,160
the number to lifeline

433
00:15:14,160 --> 00:15:15,760
and how difficult is it to retrieve the

434
00:15:15,760 --> 00:15:17,680
fun so in our case

435
00:15:17,680 --> 00:15:21,279
um the money that we initially

436
00:15:21,279 --> 00:15:25,360
deposited into the scam artists account

437
00:15:25,360 --> 00:15:27,519
went to south australia and then was

438
00:15:27,519 --> 00:15:29,279
transferred to victoria before it

439
00:15:29,279 --> 00:15:32,800
ultimately ended up in nigeria

440
00:15:32,800 --> 00:15:34,880
that's you know three different police

441
00:15:34,880 --> 00:15:36,800
jurisdictions that it's crossed and

442
00:15:36,800 --> 00:15:38,560
every time that it does

443
00:15:38,560 --> 00:15:40,720
that's basically case closed and then

444
00:15:40,720 --> 00:15:42,480
someone else has to pick it up

445
00:15:42,480 --> 00:15:44,959
and start from scratch and so therefore

446
00:15:44,959 --> 00:15:46,240
the investigation

447
00:15:46,240 --> 00:15:50,480
process is very sort of staggered and

448
00:15:50,480 --> 00:15:54,320
um and it's inefficient and it allows

449
00:15:54,320 --> 00:15:56,399
the perpetrators nothing but time to get

450
00:15:56,399 --> 00:15:58,160
away with these activities

451
00:15:58,160 --> 00:16:01,519
if there was a silver lining

452
00:16:01,519 --> 00:16:03,759
and so i think if there's if there's any

453
00:16:03,759 --> 00:16:05,839
silver lining or any good that can come

454
00:16:05,839 --> 00:16:08,800
of the situation it's that if i share my

455
00:16:08,800 --> 00:16:09,519
story

456
00:16:09,519 --> 00:16:12,720
widely enough that i can

457
00:16:12,720 --> 00:16:15,040
help someone from falling prey to the

458
00:16:15,040 --> 00:16:16,800
same situation

459
00:16:16,800 --> 00:16:18,959
and to finding themselves in the shoes

460
00:16:18,959 --> 00:16:22,160
that we find ourselves in

461
00:16:22,160 --> 00:16:23,759
laura's case continues throughout the

462
00:16:23,759 --> 00:16:25,360
australian court system where she's

463
00:16:25,360 --> 00:16:25,920
making

464
00:16:25,920 --> 00:16:28,560
victim impact statements laura is one of

465
00:16:28,560 --> 00:16:30,480
the upcoming guests on the podcast so

466
00:16:30,480 --> 00:16:31,199
stay tuned

467
00:16:31,199 --> 00:16:33,519
for her episode where she can give us an

468
00:16:33,519 --> 00:16:34,800
update on her case

469
00:16:34,800 --> 00:16:38,320
and some more details now there's a

470
00:16:38,320 --> 00:16:39,920
perception and a cliche

471
00:16:39,920 --> 00:16:41,759
that cyber resilience is all about the

472
00:16:41,759 --> 00:16:43,600
technical and the hard skills

473
00:16:43,600 --> 00:16:45,360
but there were so many discussions

474
00:16:45,360 --> 00:16:47,680
around how security leaders must

475
00:16:47,680 --> 00:16:49,600
navigate their organization in terms of

476
00:16:49,600 --> 00:16:51,600
working with people to get outcomes

477
00:16:51,600 --> 00:16:53,279
so i'll throw it over to gar to take us

478
00:16:53,279 --> 00:16:56,399
through the lessons that we learned here

479
00:16:56,399 --> 00:16:58,399
thanks amy yeah so this was one that

480
00:16:58,399 --> 00:17:00,079
came up with multiple people

481
00:17:00,079 --> 00:17:03,040
uh carissa breen mitchell and michael

482
00:17:03,040 --> 00:17:04,400
mckinnon um

483
00:17:04,400 --> 00:17:05,839
quite a few people kind of talked about

484
00:17:05,839 --> 00:17:07,919
this uh this side of things that

485
00:17:07,919 --> 00:17:09,359
actually came up on the panel yesterday

486
00:17:09,359 --> 00:17:11,280
morning as well this idea of security

487
00:17:11,280 --> 00:17:12,959
advocates so creation of

488
00:17:12,959 --> 00:17:15,439
people who buy into the security program

489
00:17:15,439 --> 00:17:16,880
at a human level

490
00:17:16,880 --> 00:17:18,640
and many of the guests talk about how

491
00:17:18,640 --> 00:17:20,480
they built trust and relationships

492
00:17:20,480 --> 00:17:22,079
they'd go play basketball they'd go have

493
00:17:22,079 --> 00:17:23,439
lunch with people they would build

494
00:17:23,439 --> 00:17:24,959
relationships and trust

495
00:17:24,959 --> 00:17:27,199
uh over you know over time doing it

496
00:17:27,199 --> 00:17:28,240
authentically

497
00:17:28,240 --> 00:17:30,240
and what that led to was the the point

498
00:17:30,240 --> 00:17:32,160
where they needed to get buy-in for a

499
00:17:32,160 --> 00:17:34,080
program or a change they needed to roll

500
00:17:34,080 --> 00:17:35,200
at mfa

501
00:17:35,200 --> 00:17:36,720
all of a sudden they've got buy-in from

502
00:17:36,720 --> 00:17:38,720
these people who know and trust the

503
00:17:38,720 --> 00:17:40,320
security leaders so that was a really

504
00:17:40,320 --> 00:17:41,679
big kind of learning

505
00:17:41,679 --> 00:17:43,520
um board communications is the thing

506
00:17:43,520 --> 00:17:45,280
that comes up all

507
00:17:45,280 --> 00:17:47,360
of the time and i loved the commentary

508
00:17:47,360 --> 00:17:49,120
yesterday afternoon around this where

509
00:17:49,120 --> 00:17:53,120
um martin called out the

510
00:17:53,120 --> 00:17:55,120
the fact that boards and businesses can

511
00:17:55,120 --> 00:17:56,880
pull fossil fuels out of the ground and

512
00:17:56,880 --> 00:17:58,960
bring that to market in a sort of useful

513
00:17:58,960 --> 00:18:00,000
way or they

514
00:18:00,000 --> 00:18:02,080
can understand i think it was pension

515
00:18:02,080 --> 00:18:03,919
liability was the other example and this

516
00:18:03,919 --> 00:18:05,120
is kind of true

517
00:18:05,120 --> 00:18:06,480
so i think that's you know there's an

518
00:18:06,480 --> 00:18:08,080
element of responsibility on the board

519
00:18:08,080 --> 00:18:09,280
side but actually the

520
00:18:09,280 --> 00:18:11,440
the other kind of lessons many people

521
00:18:11,440 --> 00:18:13,520
kind of talked about on the pod was

522
00:18:13,520 --> 00:18:15,440
around how you communicate so i think

523
00:18:15,440 --> 00:18:17,280
we're getting there and talking about

524
00:18:17,280 --> 00:18:18,160
risk

525
00:18:18,160 --> 00:18:19,760
uh talking about the business alignments

526
00:18:19,760 --> 00:18:21,120
and kind of business strategies and

527
00:18:21,120 --> 00:18:22,960
that's the kind of um the the way to

528
00:18:22,960 --> 00:18:24,240
approach this stuff

529
00:18:24,240 --> 00:18:25,919
and because ultimately you know the sort

530
00:18:25,919 --> 00:18:28,160
of trust part of this is is absolutely

531
00:18:28,160 --> 00:18:31,280
um critical and um you know ultimately a

532
00:18:31,280 --> 00:18:32,480
lot of this stuff is around kind of

533
00:18:32,480 --> 00:18:33,919
internal and external stakeholder

534
00:18:33,919 --> 00:18:35,280
management you know which we talk about

535
00:18:35,280 --> 00:18:36,400
quite a lot but

536
00:18:36,400 --> 00:18:37,600
ultimately it's getting to the point

537
00:18:37,600 --> 00:18:39,039
where you want to see cyber security as

538
00:18:39,039 --> 00:18:40,799
a you know business function

539
00:18:40,799 --> 00:18:42,720
yeah so being the the yes team and not

540
00:18:42,720 --> 00:18:45,120
the no team to be that business enabler

541
00:18:45,120 --> 00:18:46,720
and that is it so you know all about

542
00:18:46,720 --> 00:18:48,480
trust uh phil zomgo when he was on

543
00:18:48,480 --> 00:18:49,760
talked about this idea of kind of

544
00:18:49,760 --> 00:18:51,440
realistic end states

545
00:18:51,440 --> 00:18:53,280
and i thought that was a really really

546
00:18:53,280 --> 00:18:55,039
insightful comment because what you're

547
00:18:55,039 --> 00:18:56,080
talking about there is not

548
00:18:56,080 --> 00:18:58,000
promising the sun moon and the stars and

549
00:18:58,000 --> 00:19:00,160
then potentially failing to deliver when

550
00:19:00,160 --> 00:19:01,520
reality kicks in

551
00:19:01,520 --> 00:19:03,200
but actually kind of being almost

552
00:19:03,200 --> 00:19:05,039
conservative in terms of security

553
00:19:05,039 --> 00:19:06,559
outcomes and programs

554
00:19:06,559 --> 00:19:08,240
but then when you deliver on those what

555
00:19:08,240 --> 00:19:10,000
you immediately do is build trust within

556
00:19:10,000 --> 00:19:11,039
the organization

557
00:19:11,039 --> 00:19:12,320
and then the next time around as you

558
00:19:12,320 --> 00:19:14,080
iterate and kind of increase or increase

559
00:19:14,080 --> 00:19:16,160
your maturity when it comes to security

560
00:19:16,160 --> 00:19:17,919
uh you'll get better buy in and people

561
00:19:17,919 --> 00:19:19,360
trust that you'll actually deliver on

562
00:19:19,360 --> 00:19:20,960
what you've said you will

563
00:19:20,960 --> 00:19:23,679
um the last one look i'll be honest i

564
00:19:23,679 --> 00:19:25,200
don't know that we got to any answers in

565
00:19:25,200 --> 00:19:26,960
terms of the management and retention of

566
00:19:26,960 --> 00:19:27,679
talent and

567
00:19:27,679 --> 00:19:29,840
mostly the retention um you know there

568
00:19:29,840 --> 00:19:31,120
was commentary around

569
00:19:31,120 --> 00:19:32,559
potentially throwing money at the

570
00:19:32,559 --> 00:19:35,039
problem you know that certainly works or

571
00:19:35,039 --> 00:19:36,240
making sure that there's growth

572
00:19:36,240 --> 00:19:37,919
opportunities for people in security

573
00:19:37,919 --> 00:19:39,520
which you know again i think is

574
00:19:39,520 --> 00:19:41,840
is sort of an obvious thing and i really

575
00:19:41,840 --> 00:19:43,679
liked jeff donovan's comments yesterday

576
00:19:43,679 --> 00:19:45,919
on how soar can play a pretty big

577
00:19:45,919 --> 00:19:47,440
component in this and i suspect that

578
00:19:47,440 --> 00:19:48,559
will be true

579
00:19:48,559 --> 00:19:50,000
where if we can automate some of that

580
00:19:50,000 --> 00:19:52,160
more repetitive tasks and

581
00:19:52,160 --> 00:19:54,880
was adam's comments the uh the wicked

582
00:19:54,880 --> 00:19:55,280
problem

583
00:19:55,280 --> 00:19:57,120
you know get people doing the meaningful

584
00:19:57,120 --> 00:19:58,400
interesting work

585
00:19:58,400 --> 00:20:00,400
um that you know ideally that means they

586
00:20:00,400 --> 00:20:01,840
will stay because they're doing things

587
00:20:01,840 --> 00:20:03,360
that engage them that are challenging

588
00:20:03,360 --> 00:20:04,880
and that they feel are kind of worthy of

589
00:20:04,880 --> 00:20:07,200
their time

590
00:20:07,200 --> 00:20:08,880
there's so much to do in terms of

591
00:20:08,880 --> 00:20:10,640
managing a cyber team

592
00:20:10,640 --> 00:20:13,200
and with all the bombardment of threats

593
00:20:13,200 --> 00:20:14,400
and this can ultimately

594
00:20:14,400 --> 00:20:17,280
lead to a lot of stress which brings us

595
00:20:17,280 --> 00:20:17,600
to

596
00:20:17,600 --> 00:20:19,919
our next lesson that cyber resiliency

597
00:20:19,919 --> 00:20:21,840
ultimately starts with our heads

598
00:20:21,840 --> 00:20:23,600
and our leaders need to be personally

599
00:20:23,600 --> 00:20:25,280
resilient to be able to manage

600
00:20:25,280 --> 00:20:27,440
teams and to to manage the security of a

601
00:20:27,440 --> 00:20:28,400
business and

602
00:20:28,400 --> 00:20:30,480
we talked a lot about saiso burnout and

603
00:20:30,480 --> 00:20:32,080
we had an episode on

604
00:20:32,080 --> 00:20:34,320
just that it was with jessica lee one of

605
00:20:34,320 --> 00:20:36,080
garr's friends from ireland so i'll

606
00:20:36,080 --> 00:20:36,640
throw that

607
00:20:36,640 --> 00:20:39,120
back to you thank you yeah like so i've

608
00:20:39,120 --> 00:20:40,320
known jess for a long time i met her

609
00:20:40,320 --> 00:20:40,880
here

610
00:20:40,880 --> 00:20:43,039
uh in australia but uh she's a really

611
00:20:43,039 --> 00:20:44,559
good friend when she moved back to

612
00:20:44,559 --> 00:20:46,640
dublin she opened an organizational

613
00:20:46,640 --> 00:20:48,960
psychology company so she's one of those

614
00:20:48,960 --> 00:20:50,400
people that just seemed perfect to have

615
00:20:50,400 --> 00:20:50,880
this

616
00:20:50,880 --> 00:20:53,679
conversation and discussion with um you

617
00:20:53,679 --> 00:20:55,200
know inside skinny

618
00:20:55,200 --> 00:20:56,880
she was in ireland when we recorded and

619
00:20:56,880 --> 00:20:58,000
she'd actually had a pretty big night

620
00:20:58,000 --> 00:20:59,440
the night before so she was very

621
00:20:59,440 --> 00:21:01,280
hungover when we did the episode but

622
00:21:01,280 --> 00:21:02,960
i think we still got some some good

623
00:21:02,960 --> 00:21:05,120
commentary from her and good insights

624
00:21:05,120 --> 00:21:07,120
um one of the big things was this idea

625
00:21:07,120 --> 00:21:08,640
of making sure that people put their own

626
00:21:08,640 --> 00:21:09,280
mask on

627
00:21:09,280 --> 00:21:11,200
before they oxygen mask on before they

628
00:21:11,200 --> 00:21:12,799
help others and you know

629
00:21:12,799 --> 00:21:14,080
that's kind of obvious when you're on a

630
00:21:14,080 --> 00:21:15,520
plane they tell you to do that because

631
00:21:15,520 --> 00:21:16,799
if you're the person who's trying to

632
00:21:16,799 --> 00:21:18,799
frantically help other people

633
00:21:18,799 --> 00:21:20,400
and then you pass out not only are you

634
00:21:20,400 --> 00:21:21,679
no use but you're actually now a

635
00:21:21,679 --> 00:21:22,559
liability

636
00:21:22,559 --> 00:21:24,159
and the same thing really operates and

637
00:21:24,159 --> 00:21:25,679
works in the same sense when it comes to

638
00:21:25,679 --> 00:21:26,640
mental health and

639
00:21:26,640 --> 00:21:29,200
and performance within our roles so that

640
00:21:29,200 --> 00:21:30,320
that was a kind of critical

641
00:21:30,320 --> 00:21:33,039
uh learning for me the other thing was

642
00:21:33,039 --> 00:21:34,720
uh talking about ceso burnout

643
00:21:34,720 --> 00:21:36,240
particularly but i would say that that

644
00:21:36,240 --> 00:21:37,919
actually you know the idea of burnout

645
00:21:37,919 --> 00:21:39,440
probably applies to

646
00:21:39,440 --> 00:21:41,120
so many roles within cyber security

647
00:21:41,120 --> 00:21:42,480
because of the pressures that people

648
00:21:42,480 --> 00:21:44,559
feel uh every single day

649
00:21:44,559 --> 00:21:46,640
and the distinction for me was what

650
00:21:46,640 --> 00:21:48,400
burnett actually is and it isn't

651
00:21:48,400 --> 00:21:50,080
long hours and feeling tired because you

652
00:21:50,080 --> 00:21:51,360
can have both of those things but

653
00:21:51,360 --> 00:21:52,080
actually be

654
00:21:52,080 --> 00:21:54,000
really into it and living life and and

655
00:21:54,000 --> 00:21:55,840
really engage in what you're doing

656
00:21:55,840 --> 00:21:57,360
like burnout is the bit where you start

657
00:21:57,360 --> 00:21:58,880
to feel cynical you start to feel

658
00:21:58,880 --> 00:21:59,600
hopeless

659
00:21:59,600 --> 00:22:01,280
you know there's a whole lot of negative

660
00:22:01,280 --> 00:22:02,880
emotions that go along with

661
00:22:02,880 --> 00:22:05,440
true burnout but jess's comments were

662
00:22:05,440 --> 00:22:06,159
that

663
00:22:06,159 --> 00:22:07,600
you really need to spot that pretty

664
00:22:07,600 --> 00:22:09,200
early on

665
00:22:09,200 --> 00:22:10,720
so that you can make the changes that

666
00:22:10,720 --> 00:22:12,960
you need to to protect yourself

667
00:22:12,960 --> 00:22:14,640
and that might seem sort of obvious when

668
00:22:14,640 --> 00:22:16,080
you say it out loud but i think many of

669
00:22:16,080 --> 00:22:16,480
us

670
00:22:16,480 --> 00:22:17,840
um you know as you go through the day

671
00:22:17,840 --> 00:22:19,760
you just keep punching on punching on

672
00:22:19,760 --> 00:22:21,760
and jess's comments were that you kind

673
00:22:21,760 --> 00:22:23,360
of you can't wait until the point where

674
00:22:23,360 --> 00:22:24,400
you've got to either

675
00:22:24,400 --> 00:22:26,240
change jobs because you feel like that's

676
00:22:26,240 --> 00:22:27,440
the solution or

677
00:22:27,440 --> 00:22:29,200
take a leave of absence because you just

678
00:22:29,200 --> 00:22:30,640
can't do it anymore

679
00:22:30,640 --> 00:22:32,320
but if you notice this stuff early and

680
00:22:32,320 --> 00:22:33,840
then protect yourself

681
00:22:33,840 --> 00:22:36,080
mentally and sort of physically as well

682
00:22:36,080 --> 00:22:37,520
that puts you in a better position to

683
00:22:37,520 --> 00:22:37,919
kind of

684
00:22:37,919 --> 00:22:40,640
go and perform role and what i would say

685
00:22:40,640 --> 00:22:41,679
is that

686
00:22:41,679 --> 00:22:43,280
this isn't you know yes it's about

687
00:22:43,280 --> 00:22:44,559
mental health but it's got a very

688
00:22:44,559 --> 00:22:46,480
material impact to the ability of an

689
00:22:46,480 --> 00:22:48,400
organization to do cyber security

690
00:22:48,400 --> 00:22:51,280
resilience which then translates into a

691
00:22:51,280 --> 00:22:52,000
company or

692
00:22:52,000 --> 00:22:54,159
an organization's ability to perform you

693
00:22:54,159 --> 00:22:55,679
know its mission

694
00:22:55,679 --> 00:22:57,360
so they're directly linked if you're not

695
00:22:57,360 --> 00:22:59,760
mentally healthy you're not performing

696
00:22:59,760 --> 00:23:02,000
and and sort of executing as well as you

697
00:23:02,000 --> 00:23:03,840
could or making decisions as

698
00:23:03,840 --> 00:23:05,440
well as you could or as quickly as you

699
00:23:05,440 --> 00:23:07,360
could so there's a real impact to

700
00:23:07,360 --> 00:23:09,600
to organizations on this stuff and one

701
00:23:09,600 --> 00:23:11,200
of the things i would say is that

702
00:23:11,200 --> 00:23:12,400
like this is part of a broad

703
00:23:12,400 --> 00:23:13,840
conversation in australia which i think

704
00:23:13,840 --> 00:23:14,320
is so

705
00:23:14,320 --> 00:23:16,320
so good um i'm certainly having these

706
00:23:16,320 --> 00:23:18,400
conversations with friends with uh in

707
00:23:18,400 --> 00:23:19,679
professional environments

708
00:23:19,679 --> 00:23:21,360
i heard somebody at the conference

709
00:23:21,360 --> 00:23:23,120
overheard a conversation happening about

710
00:23:23,120 --> 00:23:23,840
this exact

711
00:23:23,840 --> 00:23:25,520
topic and i think there's something

712
00:23:25,520 --> 00:23:26,720
lovely about the fact that we're now

713
00:23:26,720 --> 00:23:28,080
talking about this stuff and having the

714
00:23:28,080 --> 00:23:29,280
conversation

715
00:23:29,280 --> 00:23:31,360
um while it is a broad conversation i do

716
00:23:31,360 --> 00:23:32,320
think there is something

717
00:23:32,320 --> 00:23:35,600
very specific to the cso role or

718
00:23:35,600 --> 00:23:37,760
security leader role where there is so

719
00:23:37,760 --> 00:23:39,760
much going on there in terms of

720
00:23:39,760 --> 00:23:41,679
you know standard senior management of

721
00:23:41,679 --> 00:23:43,039
budgets people

722
00:23:43,039 --> 00:23:45,440
programs all of that stuff and but then

723
00:23:45,440 --> 00:23:46,880
the fact that

724
00:23:46,880 --> 00:23:48,559
logos are hitting the news on a regular

725
00:23:48,559 --> 00:23:50,159
basis and that is a

726
00:23:50,159 --> 00:23:51,760
a fairly intimidating thing to

727
00:23:51,760 --> 00:23:53,520
potentially have so they've got a huge

728
00:23:53,520 --> 00:23:55,440
weight on their shoulders

729
00:23:55,440 --> 00:23:58,000
yeah absolutely and something that can

730
00:23:58,000 --> 00:23:58,480
help

731
00:23:58,480 --> 00:24:01,200
with that is by broader collaboration

732
00:24:01,200 --> 00:24:02,640
and there are support networks that

733
00:24:02,640 --> 00:24:03,120
exist

734
00:24:03,120 --> 00:24:06,320
and that are emerging today

735
00:24:06,320 --> 00:24:09,200
yeah so this uh this photo this is my

736
00:24:09,200 --> 00:24:10,720
chopping board at home i got this in in

737
00:24:10,720 --> 00:24:12,400
2017 after doing a

738
00:24:12,400 --> 00:24:15,440
a speaking spot at the ozarks and and

739
00:24:15,440 --> 00:24:17,200
this is actually it so every little cut

740
00:24:17,200 --> 00:24:18,799
that you can see there is probably some

741
00:24:18,799 --> 00:24:20,720
friends had come over for cheese and you

742
00:24:20,720 --> 00:24:22,400
know we're drinking wine so kind of fond

743
00:24:22,400 --> 00:24:23,279
memories but

744
00:24:23,279 --> 00:24:24,720
the important part is in the bottom

745
00:24:24,720 --> 00:24:27,200
right if you can see the united we stand

746
00:24:27,200 --> 00:24:29,039
and like it's four years ago but we kind

747
00:24:29,039 --> 00:24:30,640
of get that that's important so you know

748
00:24:30,640 --> 00:24:32,000
that idea of collaboration was

749
00:24:32,000 --> 00:24:33,679
also something that many of the guests

750
00:24:33,679 --> 00:24:35,520
talked about and um

751
00:24:35,520 --> 00:24:36,880
it was pretty pretty clear that that's

752
00:24:36,880 --> 00:24:39,360
an important part for for all of them

753
00:24:39,360 --> 00:24:41,360
so let's cut to the next slide and talk

754
00:24:41,360 --> 00:24:42,880
about how we achieve this

755
00:24:42,880 --> 00:24:45,200
through technology so we had a lot of

756
00:24:45,200 --> 00:24:47,039
interesting conversations around the

757
00:24:47,039 --> 00:24:48,960
collaboration side from a technology

758
00:24:48,960 --> 00:24:51,120
perspective with methods such as soars

759
00:24:51,120 --> 00:24:51,919
and themes

760
00:24:51,919 --> 00:24:54,240
working with integration partners ml and

761
00:24:54,240 --> 00:24:56,159
ai i'll throw over to gar to take us

762
00:24:56,159 --> 00:24:57,520
through some of the the technical

763
00:24:57,520 --> 00:25:00,240
learnings from these conversations yeah

764
00:25:00,240 --> 00:25:01,600
because there was quite a lot here

765
00:25:01,600 --> 00:25:03,200
uh so you know people who are on lee

766
00:25:03,200 --> 00:25:06,159
weiner from uh rapid seven who are here

767
00:25:06,159 --> 00:25:08,240
uh kendall what from recorded future who

768
00:25:08,240 --> 00:25:09,520
are also here

769
00:25:09,520 --> 00:25:11,840
uh mike ferguson or fergo as everybody

770
00:25:11,840 --> 00:25:13,440
knows him speaking i think next door

771
00:25:13,440 --> 00:25:15,600
right now with dave furman from netscope

772
00:25:15,600 --> 00:25:18,320
um damian luki from palo alto we had

773
00:25:18,320 --> 00:25:18,640
like

774
00:25:18,640 --> 00:25:20,720
lots of kind of uh technology platform

775
00:25:20,720 --> 00:25:21,679
or providers

776
00:25:21,679 --> 00:25:23,440
and again the brief was no sales pitch

777
00:25:23,440 --> 00:25:25,039
we need to you know understand the the

778
00:25:25,039 --> 00:25:26,840
sort of application of your tech for

779
00:25:26,840 --> 00:25:28,480
resilience and

780
00:25:28,480 --> 00:25:30,799
the you know the things that came up for

781
00:25:30,799 --> 00:25:32,240
uh for me was that the technology

782
00:25:32,240 --> 00:25:33,279
platforms were

783
00:25:33,279 --> 00:25:35,360
certainly in a good place and you know

784
00:25:35,360 --> 00:25:36,880
the technology is strong

785
00:25:36,880 --> 00:25:39,039
but the trajectories are in in sort of

786
00:25:39,039 --> 00:25:40,640
going in very meaningful directions you

787
00:25:40,640 --> 00:25:42,159
know we're seeing some cool cool stuff

788
00:25:42,159 --> 00:25:43,840
happening from a tech perspective

789
00:25:43,840 --> 00:25:45,440
yes you know the intractable human

790
00:25:45,440 --> 00:25:46,799
problem but let's be honest we're never

791
00:25:46,799 --> 00:25:47,919
going to get away from

792
00:25:47,919 --> 00:25:49,279
technical controls when it comes to

793
00:25:49,279 --> 00:25:50,960
cyber security

794
00:25:50,960 --> 00:25:53,760
um consolidation and automation came up

795
00:25:53,760 --> 00:25:54,240
a lot

796
00:25:54,240 --> 00:25:55,600
and which i guess is probably no

797
00:25:55,600 --> 00:25:57,440
surprise so that idea of maybe getting

798
00:25:57,440 --> 00:25:59,520
rid of shelfware or things that haven't

799
00:25:59,520 --> 00:26:01,200
been used or haven't been configured to

800
00:26:01,200 --> 00:26:02,320
be effective

801
00:26:02,320 --> 00:26:04,000
and then automation and you know

802
00:26:04,000 --> 00:26:05,360
obviously the theme of the conference is

803
00:26:05,360 --> 00:26:06,640
sore

804
00:26:06,640 --> 00:26:08,080
automation i think from the

805
00:26:08,080 --> 00:26:09,760
conversations over the year i'm at a

806
00:26:09,760 --> 00:26:11,360
point where i feel like it's not even a

807
00:26:11,360 --> 00:26:12,000
cool

808
00:26:12,000 --> 00:26:13,600
thing to do it's actually starting to

809
00:26:13,600 --> 00:26:15,440
feel mandatory uh

810
00:26:15,440 --> 00:26:17,360
to get good security outcomes purely

811
00:26:17,360 --> 00:26:18,960
because of the volume of stuff that we

812
00:26:18,960 --> 00:26:19,919
have to deal with

813
00:26:19,919 --> 00:26:22,080
and the speed that the organizations are

814
00:26:22,080 --> 00:26:23,200
expecting

815
00:26:23,200 --> 00:26:24,799
security practitioners to deal with

816
00:26:24,799 --> 00:26:26,240
their incidents at

817
00:26:26,240 --> 00:26:28,159
so obviously things like uh lower mean

818
00:26:28,159 --> 00:26:30,080
time to detect and respond fall out of

819
00:26:30,080 --> 00:26:30,720
that better

820
00:26:30,720 --> 00:26:33,039
fte util so people in stock environments

821
00:26:33,039 --> 00:26:34,799
are not spending their time doing kind

822
00:26:34,799 --> 00:26:36,159
of donkey work

823
00:26:36,159 --> 00:26:38,480
and good for staff retention one of the

824
00:26:38,480 --> 00:26:39,679
things that did come out though

825
00:26:39,679 --> 00:26:42,880
is the reality versus aspiration and

826
00:26:42,880 --> 00:26:45,440
you know automation putting in a sore

827
00:26:45,440 --> 00:26:46,720
it's not going to happen you know in a

828
00:26:46,720 --> 00:26:47,600
week or a day

829
00:26:47,600 --> 00:26:48,799
it's something that you kind of need to

830
00:26:48,799 --> 00:26:50,640
look at a in terms of uh

831
00:26:50,640 --> 00:26:53,520
longer terms longer term outputs and

832
00:26:53,520 --> 00:26:55,919
well-documented well-defined processes

833
00:26:55,919 --> 00:26:57,360
and i don't think we're ever going to

834
00:26:57,360 --> 00:26:59,200
get to the point soon where it's fully

835
00:26:59,200 --> 00:26:59,840
automated

836
00:26:59,840 --> 00:27:01,520
because if you get it wrong you may be

837
00:27:01,520 --> 00:27:03,600
automated an incident response that

838
00:27:03,600 --> 00:27:04,320
causes

839
00:27:04,320 --> 00:27:06,159
bigger problems than the accident the

840
00:27:06,159 --> 00:27:07,760
actual incident would have

841
00:27:07,760 --> 00:27:09,120
and so i think it's going to be very

842
00:27:09,120 --> 00:27:12,159
largely decision support for now and

843
00:27:12,159 --> 00:27:14,640
good collaboration through automation

844
00:27:14,640 --> 00:27:16,400
yeah so it sounds like there's some some

845
00:27:16,400 --> 00:27:18,159
clear and achievable outcomes and this

846
00:27:18,159 --> 00:27:20,000
will have a hugely positive impact

847
00:27:20,000 --> 00:27:22,480
on security teams i think there's

848
00:27:22,480 --> 00:27:24,399
another piece around collaboration

849
00:27:24,399 --> 00:27:26,480
and it really is that warm and fuzzy

850
00:27:26,480 --> 00:27:28,559
peace and throughout the year we heard

851
00:27:28,559 --> 00:27:30,000
time and time again

852
00:27:30,000 --> 00:27:32,000
that we're all in this together and that

853
00:27:32,000 --> 00:27:34,320
we're all fighting for the same cause

854
00:27:34,320 --> 00:27:36,080
against the cyber crime in the baddies

855
00:27:36,080 --> 00:27:38,080
and this is in vendor land

856
00:27:38,080 --> 00:27:40,559
um and across competitors as well it's

857
00:27:40,559 --> 00:27:42,480
become clear that it's not a competitive

858
00:27:42,480 --> 00:27:43,120
race

859
00:27:43,120 --> 00:27:44,799
and mimecast hosts a cyber resilience

860
00:27:44,799 --> 00:27:47,039
executive society that i've had privy of

861
00:27:47,039 --> 00:27:48,000
being able to be a part

862
00:27:48,000 --> 00:27:50,159
of and it's amazing to see how scissors

863
00:27:50,159 --> 00:27:51,279
are so willing

864
00:27:51,279 --> 00:27:53,279
to come together and to check and to

865
00:27:53,279 --> 00:27:55,279
share their challenges and to help one

866
00:27:55,279 --> 00:27:56,240
another

867
00:27:56,240 --> 00:27:58,159
and god what did your guest have to to

868
00:27:58,159 --> 00:28:00,799
add to the same five and sentiment

869
00:28:00,799 --> 00:28:04,159
yes so we we saw um this idea of

870
00:28:04,159 --> 00:28:06,159
industry and vertical collaboration and

871
00:28:06,159 --> 00:28:07,520
and finally when we're doing the pod

872
00:28:07,520 --> 00:28:08,880
what happens is quite often if it's

873
00:28:08,880 --> 00:28:10,559
somebody i don't know really well

874
00:28:10,559 --> 00:28:12,559
and we'll do a catch-up call beforehand

875
00:28:12,559 --> 00:28:14,080
so we build some rapport we get to kind

876
00:28:14,080 --> 00:28:15,600
of know each other a little bit

877
00:28:15,600 --> 00:28:18,240
and um what often you find out then is

878
00:28:18,240 --> 00:28:19,360
like how their

879
00:28:19,360 --> 00:28:21,279
daily operations are what do they do how

880
00:28:21,279 --> 00:28:22,640
are they connected in those kind of

881
00:28:22,640 --> 00:28:24,240
informal conversations so i learned a

882
00:28:24,240 --> 00:28:24,720
lot

883
00:28:24,720 --> 00:28:26,480
weirdly outside of the kind of recorded

884
00:28:26,480 --> 00:28:28,000
interviews of mike

885
00:28:28,000 --> 00:28:30,399
um how security leaders operate industry

886
00:28:30,399 --> 00:28:32,480
vertical uh collaborations become huge

887
00:28:32,480 --> 00:28:34,720
whatsapp groups for or slack groups for

888
00:28:34,720 --> 00:28:36,399
healthcare for education

889
00:28:36,399 --> 00:28:38,559
um you know the university spaces have

890
00:28:38,559 --> 00:28:40,720
those kind of collaborations happening

891
00:28:40,720 --> 00:28:43,120
sharing um early warnings of campaigns

892
00:28:43,120 --> 00:28:44,000
that are hitting etc

893
00:28:44,000 --> 00:28:45,440
so that's kind of i think a really good

894
00:28:45,440 --> 00:28:47,039
sort of learning

895
00:28:47,039 --> 00:28:49,679
cesars are collaborating uh shaman tan

896
00:28:49,679 --> 00:28:51,279
who many people will probably know

897
00:28:51,279 --> 00:28:53,919
runs the cyber risk meetups and also

898
00:28:53,919 --> 00:28:55,600
does cso groups so dinners and things

899
00:28:55,600 --> 00:28:56,799
like that

900
00:28:56,799 --> 00:28:58,159
but that's something you're seeing a lot

901
00:28:58,159 --> 00:29:00,000
of as well is that cross-industry

902
00:29:00,000 --> 00:29:01,919
collaboration between security leaders

903
00:29:01,919 --> 00:29:03,440
and and csos

904
00:29:03,440 --> 00:29:05,919
the vendors are working together and

905
00:29:05,919 --> 00:29:07,520
which i think is quite a lovely

906
00:29:07,520 --> 00:29:08,799
uh lovely thing when i come to

907
00:29:08,799 --> 00:29:10,960
conferences now so often i spend time

908
00:29:10,960 --> 00:29:12,640
with

909
00:29:12,640 --> 00:29:14,559
other vendors and the reality is the

910
00:29:14,559 --> 00:29:16,320
expectation from

911
00:29:16,320 --> 00:29:17,919
anyone working in security as a

912
00:29:17,919 --> 00:29:20,000
practitioner is that we work together

913
00:29:20,000 --> 00:29:22,080
because that's what we need to do we've

914
00:29:22,080 --> 00:29:23,200
moved away from

915
00:29:23,200 --> 00:29:24,799
point solution thinking obviously into

916
00:29:24,799 --> 00:29:26,480
kind of ecosystem thinking and doing

917
00:29:26,480 --> 00:29:27,360
things like cross

918
00:29:27,360 --> 00:29:30,080
um cross sharing of thread intel or

919
00:29:30,080 --> 00:29:31,840
integration into seam into sword type

920
00:29:31,840 --> 00:29:32,799
systems

921
00:29:32,799 --> 00:29:35,360
and you know we we know our job is to be

922
00:29:35,360 --> 00:29:37,200
part of a broader solution for any

923
00:29:37,200 --> 00:29:38,799
organization that we provide services

924
00:29:38,799 --> 00:29:40,240
into so i think that's quite a kind of

925
00:29:40,240 --> 00:29:41,200
lovely thing

926
00:29:41,200 --> 00:29:43,840
and then in this government private uh

927
00:29:43,840 --> 00:29:45,520
sector kind of working together

928
00:29:45,520 --> 00:29:49,200
jason durden uh was on a an aspie focus

929
00:29:49,200 --> 00:29:50,799
group that we were part of for the new

930
00:29:50,799 --> 00:29:52,240
south wales state government and on

931
00:29:52,240 --> 00:29:54,720
their security strategy and jason had

932
00:29:54,720 --> 00:29:55,039
just

933
00:29:55,039 --> 00:29:56,799
really really good insights in terms of

934
00:29:56,799 --> 00:29:58,960
uh you know the state level strategy so

935
00:29:58,960 --> 00:30:00,399
we got him on the pod but

936
00:30:00,399 --> 00:30:01,600
that's something that we're seeing more

937
00:30:01,600 --> 00:30:03,520
and more of and given the

938
00:30:03,520 --> 00:30:04,960
the national conversation and

939
00:30:04,960 --> 00:30:06,159
international conversation that's

940
00:30:06,159 --> 00:30:08,159
happening around things like ransomware

941
00:30:08,159 --> 00:30:09,919
and you know that collaboration is going

942
00:30:09,919 --> 00:30:11,360
to be more and more important as we go

943
00:30:11,360 --> 00:30:12,960
forward

944
00:30:12,960 --> 00:30:14,640
i love that the community is so willing

945
00:30:14,640 --> 00:30:16,960
to share tips and tricks and best

946
00:30:16,960 --> 00:30:18,880
practices and your comment around

947
00:30:18,880 --> 00:30:21,200
government focus groups it does bring to

948
00:30:21,200 --> 00:30:23,200
light the higher profile commentary from

949
00:30:23,200 --> 00:30:24,000
world government

950
00:30:24,000 --> 00:30:26,240
on the importance of cyber we heard our

951
00:30:26,240 --> 00:30:27,039
prime minister

952
00:30:27,039 --> 00:30:29,440
make a very public statement around

953
00:30:29,440 --> 00:30:32,000
australia being under sustained attack

954
00:30:32,000 --> 00:30:33,919
and there is a general sense that cyber

955
00:30:33,919 --> 00:30:35,039
has been brought to

956
00:30:35,039 --> 00:30:37,279
elevation in public and business

957
00:30:37,279 --> 00:30:38,399
consciousness

958
00:30:38,399 --> 00:30:39,919
and boards are wanting to understand

959
00:30:39,919 --> 00:30:41,840
their risks and breaches are making the

960
00:30:41,840 --> 00:30:43,840
headlines on a daily basis and it's not

961
00:30:43,840 --> 00:30:46,080
just in tech media anymore

962
00:30:46,080 --> 00:30:48,399
it does really seem like cyber has gone

963
00:30:48,399 --> 00:30:49,520
mainstream

964
00:30:49,520 --> 00:30:52,080
what did your guests have to say yeah

965
00:30:52,080 --> 00:30:53,679
look it it sort of came up i think

966
00:30:53,679 --> 00:30:55,039
informally out of the uh the

967
00:30:55,039 --> 00:30:56,880
conversations in the interviews

968
00:30:56,880 --> 00:30:59,919
the the reality is those logos that the

969
00:30:59,919 --> 00:31:01,039
board the xcode the

970
00:31:01,039 --> 00:31:02,799
this imaginary business that we talk

971
00:31:02,799 --> 00:31:04,399
about you know the business functioning

972
00:31:04,399 --> 00:31:05,919
organizations they're really starting to

973
00:31:05,919 --> 00:31:07,760
get this stuff because they see

974
00:31:07,760 --> 00:31:09,760
brands that they know respect and trust

975
00:31:09,760 --> 00:31:10,960
being popped and

976
00:31:10,960 --> 00:31:12,159
you know the impact that it's having to

977
00:31:12,159 --> 00:31:14,159
their businesses so they're asking those

978
00:31:14,159 --> 00:31:15,519
questions around cyber security which is

979
00:31:15,519 --> 00:31:16,840
good and that came out in many of the

980
00:31:16,840 --> 00:31:18,399
conversations

981
00:31:18,399 --> 00:31:20,320
one of the things that came up with

982
00:31:20,320 --> 00:31:22,159
blake deacon who's the

983
00:31:22,159 --> 00:31:24,000
principal broker for cyber insurance

984
00:31:24,000 --> 00:31:25,840
australia we had a conversation around

985
00:31:25,840 --> 00:31:29,039
the role of cyber insurance and um

986
00:31:29,039 --> 00:31:30,480
some of the things there around gotchas

987
00:31:30,480 --> 00:31:31,760
etc which you know i'm guessing many

988
00:31:31,760 --> 00:31:32,640
people know

989
00:31:32,640 --> 00:31:34,480
um but what we're seeing i think is the

990
00:31:34,480 --> 00:31:37,120
build-up of actuarial data so that now

991
00:31:37,120 --> 00:31:39,039
the the boards are asking questions

992
00:31:39,039 --> 00:31:41,200
around you know are we covered

993
00:31:41,200 --> 00:31:42,799
and you know what's the role of cyber

994
00:31:42,799 --> 00:31:44,399
insurance yes it might be a sort of

995
00:31:44,399 --> 00:31:46,000
transferring risk but

996
00:31:46,000 --> 00:31:47,440
these days what's apparent from

997
00:31:47,440 --> 00:31:49,679
conversations is that it's sort of table

998
00:31:49,679 --> 00:31:51,200
stakes to do business

999
00:31:51,200 --> 00:31:53,120
and um you know many people will have

1000
00:31:53,120 --> 00:31:55,200
that sort of uh checkbox of

1001
00:31:55,200 --> 00:31:56,640
do you have this do you have that from a

1002
00:31:56,640 --> 00:31:58,320
compliance perspective

1003
00:31:58,320 --> 00:31:59,679
you see it more and more do you have

1004
00:31:59,679 --> 00:32:01,360
cyber insurance and and what's it for

1005
00:32:01,360 --> 00:32:03,360
and how much does it cover for you for

1006
00:32:03,360 --> 00:32:04,960
so you don't even get to do business you

1007
00:32:04,960 --> 00:32:06,559
can't sell your platform your products

1008
00:32:06,559 --> 00:32:08,640
your services without that in place

1009
00:32:08,640 --> 00:32:11,360
um and then broadly you know and i get

1010
00:32:11,360 --> 00:32:12,880
where i fit you know i'm sort of six

1011
00:32:12,880 --> 00:32:14,080
years into cyber security

1012
00:32:14,080 --> 00:32:15,120
and i know there's people been doing

1013
00:32:15,120 --> 00:32:17,760
this for decades but one of the things i

1014
00:32:17,760 --> 00:32:19,039
feel like i've seen is this kind of

1015
00:32:19,039 --> 00:32:20,559
maturing of

1016
00:32:20,559 --> 00:32:22,640
the the industry in terms of the

1017
00:32:22,640 --> 00:32:24,799
conversations in terms of our

1018
00:32:24,799 --> 00:32:26,960
um our status our role as a business

1019
00:32:26,960 --> 00:32:28,559
function within organizations and that

1020
00:32:28,559 --> 00:32:29,679
was really apparent

1021
00:32:29,679 --> 00:32:31,120
and through the interviews over the

1022
00:32:31,120 --> 00:32:32,559
course of the year and also that the

1023
00:32:32,559 --> 00:32:33,279
businesses

1024
00:32:33,279 --> 00:32:35,440
are really starting to understand why

1025
00:32:35,440 --> 00:32:37,360
this stuff is so important

1026
00:32:37,360 --> 00:32:39,919
yeah it really does sound like it's

1027
00:32:39,919 --> 00:32:41,600
become part of society and not just a

1028
00:32:41,600 --> 00:32:42,799
big a business issue

1029
00:32:42,799 --> 00:32:45,679
anymore so over the course of year the

1030
00:32:45,679 --> 00:32:46,880
year we've you know we've highlighted a

1031
00:32:46,880 --> 00:32:48,480
lot of the messages um

1032
00:32:48,480 --> 00:32:49,919
that have come to the forefront but we

1033
00:32:49,919 --> 00:32:51,679
have had some other kind of light bulb

1034
00:32:51,679 --> 00:32:52,799
moments so

1035
00:32:52,799 --> 00:32:55,440
the first one being coved so it was

1036
00:32:55,440 --> 00:32:56,480
weaved into

1037
00:32:56,480 --> 00:32:58,720
and mentioned in every single episode

1038
00:32:58,720 --> 00:32:59,919
that we had so

1039
00:32:59,919 --> 00:33:01,519
i'll throw over to gar to take us

1040
00:33:01,519 --> 00:33:03,279
through some of those conversation

1041
00:33:03,279 --> 00:33:04,480
takeaways

1042
00:33:04,480 --> 00:33:06,880
yeah okay it was funny we just we

1043
00:33:06,880 --> 00:33:08,159
couldn't not talk about covert

1044
00:33:08,159 --> 00:33:09,440
especially you know in the first kind of

1045
00:33:09,440 --> 00:33:10,880
six months of it hitting it was just one

1046
00:33:10,880 --> 00:33:12,559
of those things we had to talk about

1047
00:33:12,559 --> 00:33:14,960
um weirdly i did record an episode with

1048
00:33:14,960 --> 00:33:17,440
the guy called damien luki from palo

1049
00:33:17,440 --> 00:33:19,039
palo alto which didn't we didn't

1050
00:33:19,039 --> 00:33:20,399
actually end up releasing it but we

1051
00:33:20,399 --> 00:33:21,279
spent about

1052
00:33:21,279 --> 00:33:22,399
probably about an hour and a half

1053
00:33:22,399 --> 00:33:24,320
talking about what it all meant over a

1054
00:33:24,320 --> 00:33:25,760
few beers remotely

1055
00:33:25,760 --> 00:33:27,519
and recorded it but we never got it out

1056
00:33:27,519 --> 00:33:29,840
there but damian commented on

1057
00:33:29,840 --> 00:33:32,399
this idea of work from home has been

1058
00:33:32,399 --> 00:33:34,000
around for a long time but they

1059
00:33:34,000 --> 00:33:35,840
working from home for everybody within

1060
00:33:35,840 --> 00:33:37,600
an organization for every

1061
00:33:37,600 --> 00:33:39,760
organization for every organization

1062
00:33:39,760 --> 00:33:41,840
around the world it was such a new thing

1063
00:33:41,840 --> 00:33:43,600
and in the conversations it became

1064
00:33:43,600 --> 00:33:45,200
really apparent that

1065
00:33:45,200 --> 00:33:46,640
organizations that had already set

1066
00:33:46,640 --> 00:33:48,559
themselves up for cyber resilience so

1067
00:33:48,559 --> 00:33:49,440
they had

1068
00:33:49,440 --> 00:33:50,880
workflows in the cloud they were in

1069
00:33:50,880 --> 00:33:53,279
private cloud or using data centric

1070
00:33:53,279 --> 00:33:55,039
security or xero trust they had a much

1071
00:33:55,039 --> 00:33:56,159
easier time of it

1072
00:33:56,159 --> 00:33:57,840
it literally amounted to sending an

1073
00:33:57,840 --> 00:33:59,360
email to say hey don't bring your laptop

1074
00:33:59,360 --> 00:34:00,080
to

1075
00:34:00,080 --> 00:34:01,840
the office on monday just stay at home

1076
00:34:01,840 --> 00:34:04,480
and use your home wi-fi and away you go

1077
00:34:04,480 --> 00:34:06,000
and the organizations that didn't and

1078
00:34:06,000 --> 00:34:07,600
there was many that um that came

1079
00:34:07,600 --> 00:34:10,079
on to be interviewed you heard stories

1080
00:34:10,079 --> 00:34:11,119
of

1081
00:34:11,119 --> 00:34:13,839
trying to source uh screens or webcams

1082
00:34:13,839 --> 00:34:14,879
you know trying to

1083
00:34:14,879 --> 00:34:16,159
find laptops for people because

1084
00:34:16,159 --> 00:34:17,440
otherwise they would have these huge

1085
00:34:17,440 --> 00:34:19,040
desktops that um were a little bit

1086
00:34:19,040 --> 00:34:21,040
old-school so that was probably a big uh

1087
00:34:21,040 --> 00:34:23,040
a big learning and one of the things i

1088
00:34:23,040 --> 00:34:24,719
took from it was

1089
00:34:24,719 --> 00:34:26,320
there's a really strong analogy which is

1090
00:34:26,320 --> 00:34:27,760
probably fairly obvious to everybody

1091
00:34:27,760 --> 00:34:28,320
between

1092
00:34:28,320 --> 00:34:31,119
covet and server security which is that

1093
00:34:31,119 --> 00:34:32,399
we've been getting warned about

1094
00:34:32,399 --> 00:34:34,320
pandemics for decades the experts have

1095
00:34:34,320 --> 00:34:34,800
said

1096
00:34:34,800 --> 00:34:36,560
it's not is it going to happen we know

1097
00:34:36,560 --> 00:34:38,639
it's going to happen at some point

1098
00:34:38,639 --> 00:34:40,480
but at the same time you saw defunding

1099
00:34:40,480 --> 00:34:42,079
of the organizations and the structures

1100
00:34:42,079 --> 00:34:43,679
that would have helped us with covet and

1101
00:34:43,679 --> 00:34:45,520
and made everything now much cheaper and

1102
00:34:45,520 --> 00:34:46,800
easier and we

1103
00:34:46,800 --> 00:34:48,159
we wouldn't have so much separation

1104
00:34:48,159 --> 00:34:49,440
between chairs and all the things that

1105
00:34:49,440 --> 00:34:50,000
we have to

1106
00:34:50,000 --> 00:34:52,560
to now do and and i think that that was

1107
00:34:52,560 --> 00:34:53,839
one of the big things you know shield

1108
00:34:53,839 --> 00:34:55,679
rewrite it's a beautiful beautiful

1109
00:34:55,679 --> 00:34:58,079
um cultural approach i love it's part of

1110
00:34:58,079 --> 00:35:00,160
why i've been here for 20 years

1111
00:35:00,160 --> 00:35:02,880
but as a business plan uh it's yeah it

1112
00:35:02,880 --> 00:35:06,000
just doesn't wash anymore

1113
00:35:06,880 --> 00:35:09,040
and the next one being estonia i have to

1114
00:35:09,040 --> 00:35:10,880
say this is one of my favorite episodes

1115
00:35:10,880 --> 00:35:11,280
by

1116
00:35:11,280 --> 00:35:13,599
joseph carson it's amazing to hear

1117
00:35:13,599 --> 00:35:16,079
estonia's approach to data integrity

1118
00:35:16,079 --> 00:35:18,720
and hosting data embassies offshore i'll

1119
00:35:18,720 --> 00:35:20,400
throw over to garrigan to take us

1120
00:35:20,400 --> 00:35:22,160
through this one

1121
00:35:22,160 --> 00:35:24,720
yeah so so joseph carson is the chief

1122
00:35:24,720 --> 00:35:26,320
security scientist which i think is a

1123
00:35:26,320 --> 00:35:27,839
very cool job title

1124
00:35:27,839 --> 00:35:30,320
also advisory ciso for psychotic he

1125
00:35:30,320 --> 00:35:31,760
actually has a podcast as well which i

1126
00:35:31,760 --> 00:35:33,359
highly recommend it's very good

1127
00:35:33,359 --> 00:35:35,839
um what i thought was really interesting

1128
00:35:35,839 --> 00:35:37,200
about estonia and for those who don't

1129
00:35:37,200 --> 00:35:37,920
know

1130
00:35:37,920 --> 00:35:39,599
in the early 90s estonia went through

1131
00:35:39,599 --> 00:35:41,200
some stuff which meant that they got to

1132
00:35:41,200 --> 00:35:43,040
basically almost start from scratch in a

1133
00:35:43,040 --> 00:35:44,480
way

1134
00:35:44,480 --> 00:35:46,000
and what that meant was they were able

1135
00:35:46,000 --> 00:35:48,720
to build a advanced digital society very

1136
00:35:48,720 --> 00:35:49,440
very

1137
00:35:49,440 --> 00:35:52,480
um very easily even more easily than it

1138
00:35:52,480 --> 00:35:53,119
would be from

1139
00:35:53,119 --> 00:35:55,040
an established country like australia or

1140
00:35:55,040 --> 00:35:56,720
a longer established country

1141
00:35:56,720 --> 00:35:59,520
so what you see there is first of all

1142
00:35:59,520 --> 00:36:01,040
you can build cyber resilience at a

1143
00:36:01,040 --> 00:36:02,640
national level which i found absolutely

1144
00:36:02,640 --> 00:36:03,520
fascinating

1145
00:36:03,520 --> 00:36:04,800
but when i was doing the research for

1146
00:36:04,800 --> 00:36:06,480
this episode i spent time watching the

1147
00:36:06,480 --> 00:36:08,640
the vox pops interviews with estonian

1148
00:36:08,640 --> 00:36:09,760
citizens and they

1149
00:36:09,760 --> 00:36:12,720
absolutely trust digital much more than

1150
00:36:12,720 --> 00:36:14,320
they trust paper which makes sense if

1151
00:36:14,320 --> 00:36:15,680
you think about it

1152
00:36:15,680 --> 00:36:17,760
the idea that somebody in a government

1153
00:36:17,760 --> 00:36:19,440
department could open a filing cabinet

1154
00:36:19,440 --> 00:36:20,720
and look at paper

1155
00:36:20,720 --> 00:36:22,640
there's no accountability there and

1156
00:36:22,640 --> 00:36:24,240
there's no integrity there's no

1157
00:36:24,240 --> 00:36:26,240
confidentiality confidentiality

1158
00:36:26,240 --> 00:36:27,520
necessarily you know maybe there's a

1159
00:36:27,520 --> 00:36:28,560
lock and a cabinet

1160
00:36:28,560 --> 00:36:30,160
so they were fully bought into this idea

1161
00:36:30,160 --> 00:36:32,240
of digital and then this idea of

1162
00:36:32,240 --> 00:36:34,560
um okay well if you look at resilience

1163
00:36:34,560 --> 00:36:36,000
at a national level what happens if

1164
00:36:36,000 --> 00:36:37,440
there's a land attack

1165
00:36:37,440 --> 00:36:39,599
and then they realize well our dc's get

1166
00:36:39,599 --> 00:36:40,800
popped we might have you know

1167
00:36:40,800 --> 00:36:42,720
data replication and geo separation

1168
00:36:42,720 --> 00:36:44,400
that's cool but if there's a

1169
00:36:44,400 --> 00:36:46,800
land-based attack and the tanks roll in

1170
00:36:46,800 --> 00:36:48,480
well we're still in a lot of trouble so

1171
00:36:48,480 --> 00:36:50,000
they basically set up dc's in other

1172
00:36:50,000 --> 00:36:50,880
countries

1173
00:36:50,880 --> 00:36:53,040
gave them embassy or sovereign rights

1174
00:36:53,040 --> 00:36:54,640
and uh you know i thought that was just

1175
00:36:54,640 --> 00:36:55,680
a really elegant

1176
00:36:55,680 --> 00:36:58,320
approach to you know national level um

1177
00:36:58,320 --> 00:36:59,599
sub-resilience

1178
00:36:59,599 --> 00:37:01,440
i love that and joseph talks about

1179
00:37:01,440 --> 00:37:03,359
estonians being unicorns and really

1180
00:37:03,359 --> 00:37:05,119
thinking outside the box

1181
00:37:05,119 --> 00:37:06,960
which brings us to our last and final

1182
00:37:06,960 --> 00:37:08,240
lesson that we're never

1183
00:37:08,240 --> 00:37:10,640
going to be done in the arms race of

1184
00:37:10,640 --> 00:37:12,640
cyber it really does become evident that

1185
00:37:12,640 --> 00:37:14,800
change is constant and we're always

1186
00:37:14,800 --> 00:37:16,560
looking for new ways and better ways to

1187
00:37:16,560 --> 00:37:18,640
do things i'll throw over to gar just

1188
00:37:18,640 --> 00:37:22,079
tell us your thoughts on that yeah we

1189
00:37:22,079 --> 00:37:23,920
clearly we never will be done hopefully

1190
00:37:23,920 --> 00:37:25,599
keeps us in jobs um

1191
00:37:25,599 --> 00:37:27,040
you know one of the things that i think

1192
00:37:27,040 --> 00:37:28,960
is is sort of

1193
00:37:28,960 --> 00:37:30,480
important is that we just never know

1194
00:37:30,480 --> 00:37:32,320
what's around the corner um

1195
00:37:32,320 --> 00:37:34,000
i was talking so i interviewed um

1196
00:37:34,000 --> 00:37:35,680
dimitri alperovich if people know him he

1197
00:37:35,680 --> 00:37:36,320
was the the

1198
00:37:36,320 --> 00:37:38,960
co-founder former cto of crowdstrike and

1199
00:37:38,960 --> 00:37:40,480
he works with silverado which is a

1200
00:37:40,480 --> 00:37:41,680
policy

1201
00:37:41,680 --> 00:37:43,200
organization out of washington and was

1202
00:37:43,200 --> 00:37:44,720
kind of asking him about this stuff

1203
00:37:44,720 --> 00:37:47,680
last friday so that goes out on tuesday

1204
00:37:47,680 --> 00:37:48,880
that idea that

1205
00:37:48,880 --> 00:37:50,320
we we never really know what's going to

1206
00:37:50,320 --> 00:37:51,839
happen that's a guy who was at that

1207
00:37:51,839 --> 00:37:53,280
intersection of cyber security and

1208
00:37:53,280 --> 00:37:55,280
politics and was there for the dnc hacks

1209
00:37:55,280 --> 00:37:56,560
and all that stuff

1210
00:37:56,560 --> 00:37:58,320
and things like solar winds or holiday

1211
00:37:58,320 --> 00:38:00,000
bear like felt different to me but

1212
00:38:00,000 --> 00:38:01,680
for guys like that that's actually kind

1213
00:38:01,680 --> 00:38:03,920
of been going on for a long time so

1214
00:38:03,920 --> 00:38:04,880
i don't think we're ever going to get

1215
00:38:04,880 --> 00:38:06,960
away from the sophisticated attacks it's

1216
00:38:06,960 --> 00:38:08,079
probably the first thing

1217
00:38:08,079 --> 00:38:09,359
and the incentives you know the other

1218
00:38:09,359 --> 00:38:12,240
thing is that um you can make money from

1219
00:38:12,240 --> 00:38:14,000
unfortunately from ransomware and until

1220
00:38:14,000 --> 00:38:15,760
that changes whether that's regulation

1221
00:38:15,760 --> 00:38:16,480
through

1222
00:38:16,480 --> 00:38:18,400
uh bitcoin which you know we sort of

1223
00:38:18,400 --> 00:38:19,839
talked about a little bit

1224
00:38:19,839 --> 00:38:22,560
um what's the solution to that problem i

1225
00:38:22,560 --> 00:38:23,280
think we're gonna

1226
00:38:23,280 --> 00:38:24,480
you know struggle and then you know

1227
00:38:24,480 --> 00:38:25,680
there's things like you know quantum

1228
00:38:25,680 --> 00:38:27,200
encryption quantum

1229
00:38:27,200 --> 00:38:29,359
computing somebody genius will probably

1230
00:38:29,359 --> 00:38:30,720
break one of the algorithms used for

1231
00:38:30,720 --> 00:38:31,680
encryption so i guess

1232
00:38:31,680 --> 00:38:32,560
you know you just never know what's

1233
00:38:32,560 --> 00:38:34,640
around the corner so yeah i suspect i'll

1234
00:38:34,640 --> 00:38:36,400
search you know it's what 28 years 30

1235
00:38:36,400 --> 00:38:39,040
year 30 years going it's it's probably

1236
00:38:39,040 --> 00:38:40,160
going to keep going which is a good

1237
00:38:40,160 --> 00:38:41,680
thing get to hang out and watch

1238
00:38:41,680 --> 00:38:45,680
pirate rock bands well the podcast is in

1239
00:38:45,680 --> 00:38:46,000
full

1240
00:38:46,000 --> 00:38:48,400
swing uh so stay tuned for for laura's

1241
00:38:48,400 --> 00:38:49,119
episode

1242
00:38:49,119 --> 00:38:51,760
um do you see any more themes emerging

1243
00:38:51,760 --> 00:38:52,720
um

1244
00:38:52,720 --> 00:38:55,040
in this year yeah look i i do i think

1245
00:38:55,040 --> 00:38:56,800
there's the diversity conversation is

1246
00:38:56,800 --> 00:38:58,160
going to happen more and more and you

1247
00:38:58,160 --> 00:38:59,680
know so awards for that last night i

1248
00:38:59,680 --> 00:39:00,400
think that's just

1249
00:39:00,400 --> 00:39:02,720
an incredibly important thing for us as

1250
00:39:02,720 --> 00:39:04,480
an industry for all industries

1251
00:39:04,480 --> 00:39:06,480
um joe stuart retreat was on a couple of

1252
00:39:06,480 --> 00:39:07,520
weeks ago and she

1253
00:39:07,520 --> 00:39:10,160
represented australia at the u.n in the

1254
00:39:10,160 --> 00:39:11,359
commission for the status of women and

1255
00:39:11,359 --> 00:39:12,640
that was like the first time we had a

1256
00:39:12,640 --> 00:39:14,480
proper conversation around you know

1257
00:39:14,480 --> 00:39:17,440
um in that case women and probably more

1258
00:39:17,440 --> 00:39:18,079
broadly

1259
00:39:18,079 --> 00:39:20,320
um diversity in cyber security i think

1260
00:39:20,320 --> 00:39:21,440
that's important

1261
00:39:21,440 --> 00:39:22,880
and i do think there's probably going to

1262
00:39:22,880 --> 00:39:24,800
be more politics and policy stuff coming

1263
00:39:24,800 --> 00:39:26,000
as

1264
00:39:26,000 --> 00:39:27,520
things like ransomware and cyber in

1265
00:39:27,520 --> 00:39:28,960
general just become more of a national

1266
00:39:28,960 --> 00:39:29,680
conversation

1267
00:39:29,680 --> 00:39:32,320
and international conversation well

1268
00:39:32,320 --> 00:39:33,040
thank you gar

1269
00:39:33,040 --> 00:39:34,800
and thanks to our guests for all the

1270
00:39:34,800 --> 00:39:36,320
learnings and insights and thanks to

1271
00:39:36,320 --> 00:39:37,920
everyone for listening and to answer for

1272
00:39:37,920 --> 00:39:39,200
happiness

1273
00:39:39,200 --> 00:39:43,599
thanks all thank you amy and garrett

1274
00:39:43,599 --> 00:39:45,119
uh unfortunately we don't have any time

1275
00:39:45,119 --> 00:39:46,960
for questions and i think

1276
00:39:46,960 --> 00:39:49,200
now we didn't have any questions in the

1277
00:39:49,200 --> 00:39:50,800
in the q a

1278
00:39:50,800 --> 00:39:53,040
section of the application but are you

1279
00:39:53,040 --> 00:39:54,320
two around

1280
00:39:54,320 --> 00:39:56,480
for a chat if there's anyone interested

1281
00:39:56,480 --> 00:39:57,359
um i have to

1282
00:39:57,359 --> 00:39:58,720
i actually have to run away i'll get a

1283
00:39:58,720 --> 00:40:00,079
broken motorbike that i need to get

1284
00:40:00,079 --> 00:40:01,200
fixed weirdly and i've got an

1285
00:40:01,200 --> 00:40:03,119
appointment at a garage at 1 pm so

1286
00:40:03,119 --> 00:40:05,760
that sounds like fun yeah one of those

1287
00:40:05,760 --> 00:40:07,040
around though i think yeah

1288
00:40:07,040 --> 00:40:08,560
and uh can we give another round of

1289
00:40:08,560 --> 00:40:10,319
applause for amy first presentation

1290
00:40:10,319 --> 00:40:12,940
did not notice that's fantastic well

1291
00:40:12,940 --> 00:40:16,110
[Applause]

1292
00:40:18,920 --> 00:40:21,920
done

