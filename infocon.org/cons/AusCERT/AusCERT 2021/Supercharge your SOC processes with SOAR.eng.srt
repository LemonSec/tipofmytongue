1
00:00:01,280 --> 00:00:03,679
[Music]

2
00:00:03,679 --> 00:00:17,919
it went on and on

3
00:00:34,800 --> 00:00:39,920
hello hello hello how we doing

4
00:00:39,920 --> 00:00:42,640
meandering in so for those up the back

5
00:00:42,640 --> 00:00:44,239
there that are walking out could you

6
00:00:44,239 --> 00:00:45,920
close the door behind you

7
00:00:45,920 --> 00:00:49,600
thank you see that crowd sourcing

8
00:00:49,600 --> 00:00:53,920
you see that that's brilliant cool so

9
00:00:53,920 --> 00:00:57,199
cyber security is heavily dependent on

10
00:00:57,199 --> 00:01:00,239
individual knowledge and experience

11
00:01:00,239 --> 00:01:01,520
it's not me presenting by the way i'm

12
00:01:01,520 --> 00:01:03,760
about to call up nick actually i might

13
00:01:03,760 --> 00:01:05,438
just take over mate

14
00:01:05,438 --> 00:01:07,439
one of the biggest challenges we face in

15
00:01:07,439 --> 00:01:09,040
defending against attacks is

16
00:01:09,040 --> 00:01:11,200
scaling analyst expertise and sharing

17
00:01:11,200 --> 00:01:13,119
tribal knowledge

18
00:01:13,119 --> 00:01:15,680
this next talk explores how soar works

19
00:01:15,680 --> 00:01:17,520
as a data platform for security

20
00:01:17,520 --> 00:01:18,640
incidents

21
00:01:18,640 --> 00:01:20,479
how we can use machine learning to

22
00:01:20,479 --> 00:01:21,840
connect people

23
00:01:21,840 --> 00:01:24,840
and how analysts derive meaning and

24
00:01:24,840 --> 00:01:27,360
insights so we have the fabulous

25
00:01:27,360 --> 00:01:29,360
awesome nick pratley about to come up on

26
00:01:29,360 --> 00:01:31,680
stage so nick is a cyber security

27
00:01:31,680 --> 00:01:33,759
professional at bdo risk advisory

28
00:01:33,759 --> 00:01:34,560
practice

29
00:01:34,560 --> 00:01:37,520
specialising in cyber defense and

30
00:01:37,520 --> 00:01:39,200
security operations

31
00:01:39,200 --> 00:01:41,840
nick works with clients across australia

32
00:01:41,840 --> 00:01:44,560
in the private and public sectors

33
00:01:44,560 --> 00:01:46,560
he helps them understand and manage

34
00:01:46,560 --> 00:01:47,680
cyber security risk

35
00:01:47,680 --> 00:01:50,159
and delivers solutions to achieve better

36
00:01:50,159 --> 00:01:52,079
security outcomes

37
00:01:52,079 --> 00:01:55,600
bdo is a global can you guys hear me

38
00:01:55,600 --> 00:01:57,600
yeah okay sorry i just got the feedback

39
00:01:57,600 --> 00:01:59,600
a little bit there so bdo is a global

40
00:01:59,600 --> 00:02:00,159
firm

41
00:02:00,159 --> 00:02:03,280
with over 2500 security cyber security

42
00:02:03,280 --> 00:02:04,000
and technology

43
00:02:04,000 --> 00:02:07,920
technology professionals in 35 countries

44
00:02:07,920 --> 00:02:09,919
we advise clients on cyber security

45
00:02:09,919 --> 00:02:10,639
strategy

46
00:02:10,639 --> 00:02:13,120
risk management and operations as well

47
00:02:13,120 --> 00:02:14,800
as providing managed detection and

48
00:02:14,800 --> 00:02:16,319
response services

49
00:02:16,319 --> 00:02:19,599
so could we please give a nice warm

50
00:02:19,599 --> 00:02:22,400
ausert gold coast very warm welcome to

51
00:02:22,400 --> 00:02:25,040
nick pratley

52
00:02:32,319 --> 00:02:33,840
hi everyone thanks for the intro

53
00:02:33,840 --> 00:02:35,599
introduction and thanks everyone for

54
00:02:35,599 --> 00:02:36,800
coming

55
00:02:36,800 --> 00:02:38,319
my name's nick pratley and i'm going to

56
00:02:38,319 --> 00:02:39,519
be talking about some of the challenges

57
00:02:39,519 --> 00:02:40,720
that we face

58
00:02:40,720 --> 00:02:42,720
in cyber security operations and how

59
00:02:42,720 --> 00:02:44,000
soar can help

60
00:02:44,000 --> 00:02:47,120
as a platform for doing data analysis

61
00:02:47,120 --> 00:02:50,560
to help our analysts derived insights

62
00:02:50,560 --> 00:02:54,239
and meaning out of security incidents

63
00:02:55,840 --> 00:02:57,360
this is a topic that i'm pretty excited

64
00:02:57,360 --> 00:02:58,720
about so i'm happy to be here talking to

65
00:02:58,720 --> 00:03:00,879
you about it today

66
00:03:00,879 --> 00:03:02,239
i hope everyone gets something out of

67
00:03:02,239 --> 00:03:04,080
this so whether you are

68
00:03:04,080 --> 00:03:05,840
involved in cyber security operations in

69
00:03:05,840 --> 00:03:07,200
some way whether you are

70
00:03:07,200 --> 00:03:08,800
an analyst or working in an operational

71
00:03:08,800 --> 00:03:10,879
role or perhaps you are managing a cyber

72
00:03:10,879 --> 00:03:12,319
security team

73
00:03:12,319 --> 00:03:14,239
or and especially if you are studying

74
00:03:14,239 --> 00:03:16,159
cyber security or wanting to move into

75
00:03:16,159 --> 00:03:19,200
a career within cyber security

76
00:03:19,200 --> 00:03:20,319
i'm hoping that you get something out of

77
00:03:20,319 --> 00:03:22,640
this in terms of seeing soar as

78
00:03:22,640 --> 00:03:25,280
a technology that helps us enable people

79
00:03:25,280 --> 00:03:27,760
and process

80
00:03:28,239 --> 00:03:29,920
there are large numbers of people

81
00:03:29,920 --> 00:03:31,680
entering this industry at the moment

82
00:03:31,680 --> 00:03:33,840
which is fantastic we need more people

83
00:03:33,840 --> 00:03:34,720
what i want to show

84
00:03:34,720 --> 00:03:36,319
and talk about today is about how we can

85
00:03:36,319 --> 00:03:38,720
help them become more effective

86
00:03:38,720 --> 00:03:40,720
more quickly by using technology to

87
00:03:40,720 --> 00:03:42,640
support what they're doing

88
00:03:42,640 --> 00:03:45,280
day to day people are at the core of

89
00:03:45,280 --> 00:03:47,200
cyber defence

90
00:03:47,200 --> 00:03:48,640
and scaling analyst knowledge and

91
00:03:48,640 --> 00:03:50,480
expertise is one of the key challenges

92
00:03:50,480 --> 00:03:52,959
that we face

93
00:03:58,480 --> 00:03:59,840
so let's take a look at some of the

94
00:03:59,840 --> 00:04:01,439
challenges that we have within security

95
00:04:01,439 --> 00:04:04,000
operations

96
00:04:04,480 --> 00:04:07,439
if you're a manager you are dealing with

97
00:04:07,439 --> 00:04:09,120
staffing challenges so hiring

98
00:04:09,120 --> 00:04:12,400
retaining and training your analysts

99
00:04:12,400 --> 00:04:15,439
and staff are often

100
00:04:15,439 --> 00:04:17,358
frustrated by the day-to-day of dealing

101
00:04:17,358 --> 00:04:19,839
with security alerts repetitive alerts

102
00:04:19,839 --> 00:04:22,400
uh and false positives so chasing time

103
00:04:22,400 --> 00:04:23,680
spending time chasing down things that

104
00:04:23,680 --> 00:04:24,800
turn out not to be

105
00:04:24,800 --> 00:04:28,560
real security events as an as a manager

106
00:04:28,560 --> 00:04:30,080
it's up to you to help alleviate this

107
00:04:30,080 --> 00:04:30,720
challenge

108
00:04:30,720 --> 00:04:33,759
for your team as an analyst

109
00:04:33,759 --> 00:04:35,600
you're struggling to prioritize amongst

110
00:04:35,600 --> 00:04:37,120
the flight of alerts so what you're

111
00:04:37,120 --> 00:04:37,680
seeing

112
00:04:37,680 --> 00:04:39,360
what does it mean which one do you look

113
00:04:39,360 --> 00:04:40,960
at first

114
00:04:40,960 --> 00:04:42,720
you have many of these that turn out to

115
00:04:42,720 --> 00:04:44,400
be false positives so you spend a lot of

116
00:04:44,400 --> 00:04:45,520
time on things that

117
00:04:45,520 --> 00:04:46,880
were really not what you should be

118
00:04:46,880 --> 00:04:49,280
looking at and

119
00:04:49,280 --> 00:04:50,880
you have limited visibility of the

120
00:04:50,880 --> 00:04:52,080
environment that you're monitoring so

121
00:04:52,080 --> 00:04:53,600
you have imperfect information

122
00:04:53,600 --> 00:04:54,720
you've got to piece together a lot of

123
00:04:54,720 --> 00:04:56,880
things based on what you see

124
00:04:56,880 --> 00:04:59,600
at hand on top of this you have to

125
00:04:59,600 --> 00:05:00,560
constantly work

126
00:05:00,560 --> 00:05:02,400
to share knowledge and collaborate with

127
00:05:02,400 --> 00:05:03,840
your colleagues

128
00:05:03,840 --> 00:05:06,400
and make sure that we are always working

129
00:05:06,400 --> 00:05:08,479
together to standardize the processes

130
00:05:08,479 --> 00:05:10,720
that we have in place to help us deal

131
00:05:10,720 --> 00:05:14,160
with security incidents and events

132
00:05:15,600 --> 00:05:18,800
anyone who has been involved in

133
00:05:18,800 --> 00:05:20,560
cyber security for any amount of time

134
00:05:20,560 --> 00:05:22,639
understands that false positives are

135
00:05:22,639 --> 00:05:25,600
still a massive challenge for us false

136
00:05:25,600 --> 00:05:27,120
positives are always going to exist this

137
00:05:27,120 --> 00:05:28,479
is not something that's going to go away

138
00:05:28,479 --> 00:05:29,680
and part of the reason for this

139
00:05:29,680 --> 00:05:31,680
is that detection technologies are

140
00:05:31,680 --> 00:05:34,080
optimized to avoid false negatives

141
00:05:34,080 --> 00:05:35,440
so if there's an attack that occurs on

142
00:05:35,440 --> 00:05:37,280
an endpoint the endpoint detection

143
00:05:37,280 --> 00:05:38,400
response agent

144
00:05:38,400 --> 00:05:40,240
wants to trigger that wants to flag on

145
00:05:40,240 --> 00:05:41,520
it and wants to let you know that

146
00:05:41,520 --> 00:05:42,560
something has happened

147
00:05:42,560 --> 00:05:44,479
they need to avoid having a security

148
00:05:44,479 --> 00:05:45,680
incident that was missed

149
00:05:45,680 --> 00:05:47,199
so they're always going to optimize to

150
00:05:47,199 --> 00:05:48,800
triggering an alert this is

151
00:05:48,800 --> 00:05:50,000
part of why we have so many false

152
00:05:50,000 --> 00:05:52,720
positives to deal with

153
00:05:52,720 --> 00:05:54,720
the reason why this is a problem though

154
00:05:54,720 --> 00:05:56,080
is not that false positives occur

155
00:05:56,080 --> 00:05:58,160
it's our analysts spend so much time

156
00:05:58,160 --> 00:05:59,759
looking at these and so much time

157
00:05:59,759 --> 00:06:01,280
investigating them

158
00:06:01,280 --> 00:06:04,000
and the irony is that because of that a

159
00:06:04,000 --> 00:06:05,600
real attack might actually go missed

160
00:06:05,600 --> 00:06:07,840
because they're not spending the time

161
00:06:07,840 --> 00:06:08,960
looking at things

162
00:06:08,960 --> 00:06:10,160
that are probably more worthwhile

163
00:06:10,160 --> 00:06:11,840
investigating so it's not the false

164
00:06:11,840 --> 00:06:13,360
positives in themselves are a problem

165
00:06:13,360 --> 00:06:14,560
it's that they take away time from

166
00:06:14,560 --> 00:06:17,280
looking at real things

167
00:06:17,440 --> 00:06:18,720
if we have a look at some of the stats

168
00:06:18,720 --> 00:06:20,960
on this it's pretty horrifying

169
00:06:20,960 --> 00:06:22,880
uh for most stocks around half the

170
00:06:22,880 --> 00:06:24,560
alerts that they look at in a day

171
00:06:24,560 --> 00:06:25,600
are going to turn out to be false

172
00:06:25,600 --> 00:06:27,280
positives and a quarter of the time that

173
00:06:27,280 --> 00:06:28,800
they spend looking at things

174
00:06:28,800 --> 00:06:31,039
are going to be false positives most

175
00:06:31,039 --> 00:06:32,720
stocks can only investigate

176
00:06:32,720 --> 00:06:34,560
45 so not even half of all the alerts

177
00:06:34,560 --> 00:06:36,080
that they actually see

178
00:06:36,080 --> 00:06:37,840
and only half of stocks rate themselves

179
00:06:37,840 --> 00:06:39,440
as actually being effective

180
00:06:39,440 --> 00:06:41,280
at prioritizing alerts that they should

181
00:06:41,280 --> 00:06:44,000
be looking at i've worked with one sock

182
00:06:44,000 --> 00:06:46,479
several years ago that had a team of

183
00:06:46,479 --> 00:06:48,319
analysts that were looking at over 10

184
00:06:48,319 --> 00:06:49,120
000 alerts

185
00:06:49,120 --> 00:06:50,720
every single week at the end of each

186
00:06:50,720 --> 00:06:52,080
week they would tend to just clear the

187
00:06:52,080 --> 00:06:52,479
queue

188
00:06:52,479 --> 00:06:54,400
and start again fresh so those false

189
00:06:54,400 --> 00:06:56,400
positives the false positive rate for

190
00:06:56,400 --> 00:06:56,880
that

191
00:06:56,880 --> 00:06:59,120
was astronomical and you have to wonder

192
00:06:59,120 --> 00:07:00,639
about how many real events were actually

193
00:07:00,639 --> 00:07:03,840
missed as a result

194
00:07:05,360 --> 00:07:07,199
so why is training security analysts so

195
00:07:07,199 --> 00:07:09,120
difficult and why is security

196
00:07:09,120 --> 00:07:14,160
analysis as a field such a challenge

197
00:07:14,160 --> 00:07:16,479
and how does saw help alleviate this as

198
00:07:16,479 --> 00:07:17,360
well because this is

199
00:07:17,360 --> 00:07:19,199
all about saw so i'll get to the sore

200
00:07:19,199 --> 00:07:20,479
part in a moment

201
00:07:20,479 --> 00:07:22,080
but the main reason that analyst

202
00:07:22,080 --> 00:07:23,759
training is so complex is that security

203
00:07:23,759 --> 00:07:24,560
analysis

204
00:07:24,560 --> 00:07:27,360
is more of an art than a science and it

205
00:07:27,360 --> 00:07:28,560
relies on having

206
00:07:28,560 --> 00:07:30,240
people with experience people who've

207
00:07:30,240 --> 00:07:31,840
seen something before to know what

208
00:07:31,840 --> 00:07:32,800
something means

209
00:07:32,800 --> 00:07:34,400
so as a new analyst you don't have that

210
00:07:34,400 --> 00:07:35,759
experience and we need to work to make

211
00:07:35,759 --> 00:07:38,319
that easier

212
00:07:38,639 --> 00:07:40,639
cyber security is not unique in that

213
00:07:40,639 --> 00:07:41,840
regard there are actually quite a lot of

214
00:07:41,840 --> 00:07:43,199
fields that are also

215
00:07:43,199 --> 00:07:45,120
heavily dependent on people and process

216
00:07:45,120 --> 00:07:46,720
to operate and some of these other

217
00:07:46,720 --> 00:07:47,840
fields are starting

218
00:07:47,840 --> 00:07:50,080
more and more to use data and automated

219
00:07:50,080 --> 00:07:53,360
analysis to help them overcome that

220
00:07:53,360 --> 00:07:54,879
i'll give an example from the mining

221
00:07:54,879 --> 00:07:57,759
industry i was at a dinner recently

222
00:07:57,759 --> 00:08:00,160
talking to a senior geologist at a

223
00:08:00,160 --> 00:08:00,960
mining a large

224
00:08:00,960 --> 00:08:03,680
global mining firm who was working with

225
00:08:03,680 --> 00:08:04,960
a team of people

226
00:08:04,960 --> 00:08:07,759
to help use data and automation to solve

227
00:08:07,759 --> 00:08:09,039
some of the problems they have

228
00:08:09,039 --> 00:08:11,520
in the mining industry and this didn't

229
00:08:11,520 --> 00:08:12,479
make a lot of sense to me at first

230
00:08:12,479 --> 00:08:13,120
because i don't know

231
00:08:13,120 --> 00:08:15,120
a whole lot about mining but what he

232
00:08:15,120 --> 00:08:16,560
explained was that

233
00:08:16,560 --> 00:08:18,720
in geology you have geologists all

234
00:08:18,720 --> 00:08:19,759
around the world

235
00:08:19,759 --> 00:08:21,680
sitting looking at core samples which

236
00:08:21,680 --> 00:08:24,240
are drilled from mine sites

237
00:08:24,240 --> 00:08:26,400
and they analyze what's in the sample

238
00:08:26,400 --> 00:08:27,840
and say what they see

239
00:08:27,840 --> 00:08:31,199
so there are various properties

240
00:08:31,199 --> 00:08:34,479
of soil samples that they they record

241
00:08:34,479 --> 00:08:35,440
down

242
00:08:35,440 --> 00:08:36,799
and they spend their time just

243
00:08:36,799 --> 00:08:39,039
explaining what's in the samples

244
00:08:39,039 --> 00:08:40,799
they don't really spend a lot of time

245
00:08:40,799 --> 00:08:43,279
explaining what this means

246
00:08:43,279 --> 00:08:46,560
and every now and then though

247
00:08:46,560 --> 00:08:48,320
there'll be a geologist who's been doing

248
00:08:48,320 --> 00:08:49,920
this for 30 years

249
00:08:49,920 --> 00:08:51,519
who will see something and recognize it

250
00:08:51,519 --> 00:08:53,760
and say ah i've seen this before

251
00:08:53,760 --> 00:08:56,000
i saw this at a mine in south america 10

252
00:08:56,000 --> 00:08:56,800
years ago

253
00:08:56,800 --> 00:08:58,320
and now i know what this means and it's

254
00:08:58,320 --> 00:09:00,560
that meaning that businesses want to get

255
00:09:00,560 --> 00:09:02,399
out of that they want to understand for

256
00:09:02,399 --> 00:09:03,839
a mindset

257
00:09:03,839 --> 00:09:06,720
what is the what's how's this going to

258
00:09:06,720 --> 00:09:08,000
turn out is this going to be a good mind

259
00:09:08,000 --> 00:09:08,399
for us

260
00:09:08,399 --> 00:09:10,959
or bad it comes down to things like that

261
00:09:10,959 --> 00:09:12,320
we have a similar problem

262
00:09:12,320 --> 00:09:14,480
with insecurity in that it relies on

263
00:09:14,480 --> 00:09:16,080
human expertise humans who've seen this

264
00:09:16,080 --> 00:09:17,360
before to know what they're looking at

265
00:09:17,360 --> 00:09:19,040
and know what it means

266
00:09:19,040 --> 00:09:20,959
security analysts spend a lot of time

267
00:09:20,959 --> 00:09:22,560
looking at and describing what things

268
00:09:22,560 --> 00:09:23,760
are without explaining

269
00:09:23,760 --> 00:09:26,399
what they actually mean and so we can

270
00:09:26,399 --> 00:09:28,959
definitely learn from other fields

271
00:09:28,959 --> 00:09:32,000
in in how we come to address and

272
00:09:32,000 --> 00:09:36,480
overcome that

273
00:09:36,480 --> 00:09:39,680
and so the way that uh that they're

274
00:09:39,680 --> 00:09:40,880
solving this within mining i think i

275
00:09:40,880 --> 00:09:41,920
skipped over something here

276
00:09:41,920 --> 00:09:44,720
um is they're taking the manual records

277
00:09:44,720 --> 00:09:45,279
that people

278
00:09:45,279 --> 00:09:47,760
are the geologists are creating and

279
00:09:47,760 --> 00:09:48,839
they're plugging those into massive

280
00:09:48,839 --> 00:09:50,000
databases

281
00:09:50,000 --> 00:09:52,720
and they are extracting those features

282
00:09:52,720 --> 00:09:54,240
and using machines to automate

283
00:09:54,240 --> 00:09:56,640
that process of deriving meaning because

284
00:09:56,640 --> 00:09:58,720
a machine can look at far more samples

285
00:09:58,720 --> 00:10:00,560
than a human ever can and it can pick

286
00:10:00,560 --> 00:10:01,839
out correlations for things that we

287
00:10:01,839 --> 00:10:03,279
wouldn't even think to look for

288
00:10:03,279 --> 00:10:05,839
so again this is what we can do within

289
00:10:05,839 --> 00:10:06,720
cyber security

290
00:10:06,720 --> 00:10:08,720
i want to show how soar is is a platform

291
00:10:08,720 --> 00:10:10,079
to enable this type of automated

292
00:10:10,079 --> 00:10:11,519
analysis

293
00:10:11,519 --> 00:10:14,079
and the only difference here is that we

294
00:10:14,079 --> 00:10:16,079
are dealing with security incidents

295
00:10:16,079 --> 00:10:18,880
as our primary data model as opposed to

296
00:10:18,880 --> 00:10:21,600
core samples

297
00:10:22,480 --> 00:10:24,800
so let's take a look at what soar is

298
00:10:24,800 --> 00:10:26,160
there's been a lot of focus in this

299
00:10:26,160 --> 00:10:28,160
conference and talk about soar in

300
00:10:28,160 --> 00:10:29,839
general that is about

301
00:10:29,839 --> 00:10:32,480
automation as a way to string together

302
00:10:32,480 --> 00:10:33,279
tasks

303
00:10:33,279 --> 00:10:34,880
in a playbook to automate a response to

304
00:10:34,880 --> 00:10:36,399
something and that is really useful and

305
00:10:36,399 --> 00:10:38,000
does save time

306
00:10:38,000 --> 00:10:40,640
what i want to think about though is a

307
00:10:40,640 --> 00:10:42,079
different kind of automation

308
00:10:42,079 --> 00:10:43,760
which is about using saw as a repository

309
00:10:43,760 --> 00:10:45,279
of data

310
00:10:45,279 --> 00:10:47,839
to about security incidents and to help

311
00:10:47,839 --> 00:10:49,519
bring things together

312
00:10:49,519 --> 00:10:51,200
so let's go through the major components

313
00:10:51,200 --> 00:10:53,680
of saw

314
00:10:53,920 --> 00:10:55,680
there is typically a case in our

315
00:10:55,680 --> 00:10:57,279
incident management component this is

316
00:10:57,279 --> 00:11:00,320
where we record all our incidents

317
00:11:00,320 --> 00:11:02,640
this is what analysts use as a console

318
00:11:02,640 --> 00:11:04,480
for dealing with security events

319
00:11:04,480 --> 00:11:06,160
there's automation and orchestration

320
00:11:06,160 --> 00:11:07,600
components so workflows

321
00:11:07,600 --> 00:11:09,920
playbooks task automation that fits

322
00:11:09,920 --> 00:11:10,959
within

323
00:11:10,959 --> 00:11:12,640
the automation component and this is

324
00:11:12,640 --> 00:11:14,000
integration with other

325
00:11:14,000 --> 00:11:16,959
systems as well there's a collaboration

326
00:11:16,959 --> 00:11:17,519
function

327
00:11:17,519 --> 00:11:19,040
in most cases this is about executing

328
00:11:19,040 --> 00:11:20,560
analysts working together recording

329
00:11:20,560 --> 00:11:21,200
notes

330
00:11:21,200 --> 00:11:23,440
um talking to each other and in some

331
00:11:23,440 --> 00:11:25,040
cases talking with external teams as

332
00:11:25,040 --> 00:11:26,240
well to work through

333
00:11:26,240 --> 00:11:28,560
a response to an incident and then

334
00:11:28,560 --> 00:11:29,600
there's a metrics and reporting

335
00:11:29,600 --> 00:11:30,959
component because again we've got a

336
00:11:30,959 --> 00:11:32,640
platform here that has a large and a

337
00:11:32,640 --> 00:11:34,320
large amount of data on security

338
00:11:34,320 --> 00:11:36,399
incidents and we can pull reports

339
00:11:36,399 --> 00:11:39,920
and metrics straight out of that the

340
00:11:39,920 --> 00:11:42,800
saw platform that i personally am most

341
00:11:42,800 --> 00:11:45,600
familiar with is palo alto's cortex-exor

342
00:11:45,600 --> 00:11:46,800
i'm not i don't work for hello i'm not

343
00:11:46,800 --> 00:11:47,920
selling it but this is the one that i've

344
00:11:47,920 --> 00:11:49,040
used the most

345
00:11:49,040 --> 00:11:52,240
so we have worked with xor on a number

346
00:11:52,240 --> 00:11:53,680
of customer deployments and it's also

347
00:11:53,680 --> 00:11:55,279
what we use within our video global

348
00:11:55,279 --> 00:11:56,079
stock

349
00:11:56,079 --> 00:11:58,240
having said that most saw platforms have

350
00:11:58,240 --> 00:12:00,240
the same sets of functionality so

351
00:12:00,240 --> 00:12:01,440
all of what i'm talking about today is

352
00:12:01,440 --> 00:12:03,279
pretty much analogous to any other store

353
00:12:03,279 --> 00:12:05,600
platform

354
00:12:07,519 --> 00:12:09,920
when you deploy saw it becomes a central

355
00:12:09,920 --> 00:12:11,200
platform for dealing with security

356
00:12:11,200 --> 00:12:12,800
incidents

357
00:12:12,800 --> 00:12:14,079
you've got your data coming into the

358
00:12:14,079 --> 00:12:16,880
scene which is where your detection

359
00:12:16,880 --> 00:12:19,440
your detections trigger from so log data

360
00:12:19,440 --> 00:12:21,680
event data comes into the same

361
00:12:21,680 --> 00:12:23,519
detections trigger there and then the

362
00:12:23,519 --> 00:12:25,440
scene sends alerts to saw

363
00:12:25,440 --> 00:12:26,959
which becomes the console this is what

364
00:12:26,959 --> 00:12:30,399
security analysts are looking at

365
00:12:30,399 --> 00:12:32,240
and it's that incident data that's in

366
00:12:32,240 --> 00:12:34,000
that data model that i want to talk

367
00:12:34,000 --> 00:12:39,839
about here

368
00:12:46,240 --> 00:12:48,079
this is just showing a bit of a

369
00:12:48,079 --> 00:12:49,360
breakdown of what's in an incident so

370
00:12:49,360 --> 00:12:50,959
these things apply to pretty much every

371
00:12:50,959 --> 00:12:52,399
security incident that's in the solar

372
00:12:52,399 --> 00:12:54,720
platform you've got a set of categories

373
00:12:54,720 --> 00:12:56,240
and classifications

374
00:12:56,240 --> 00:12:57,279
socks deal with different types of

375
00:12:57,279 --> 00:12:59,040
security incidents not too much of a

376
00:12:59,040 --> 00:13:00,800
surprise

377
00:13:00,800 --> 00:13:02,320
but it is really important to categorize

378
00:13:02,320 --> 00:13:04,000
each one so that you know

379
00:13:04,000 --> 00:13:05,920
how to bucket things um the first thing

380
00:13:05,920 --> 00:13:07,120
you want to do when you're dealing with

381
00:13:07,120 --> 00:13:08,560
an incident is figure out what type of

382
00:13:08,560 --> 00:13:10,480
thing this is so i know how to

383
00:13:10,480 --> 00:13:12,880
analyze and respond appropriately you

384
00:13:12,880 --> 00:13:14,320
have custom fields

385
00:13:14,320 --> 00:13:16,639
now a lot of case instance management

386
00:13:16,639 --> 00:13:18,880
tools have custom fields

387
00:13:18,880 --> 00:13:20,959
typically they're not used very commonly

388
00:13:20,959 --> 00:13:22,240
and this is i think a key

389
00:13:22,240 --> 00:13:24,720
component of us any sore deployment is

390
00:13:24,720 --> 00:13:26,320
making use of custom fields

391
00:13:26,320 --> 00:13:28,560
that contain types of data that are

392
00:13:28,560 --> 00:13:29,600
uniquely relevant

393
00:13:29,600 --> 00:13:31,440
to each different type of incident this

394
00:13:31,440 --> 00:13:32,560
is going to be really important for when

395
00:13:32,560 --> 00:13:33,600
we talk about how

396
00:13:33,600 --> 00:13:34,720
to get machines to automatically

397
00:13:34,720 --> 00:13:36,160
correlate things you've got to break

398
00:13:36,160 --> 00:13:38,320
things out into custom fields

399
00:13:38,320 --> 00:13:40,399
we have custom statuses to define

400
00:13:40,399 --> 00:13:42,160
workflow stages this is really more just

401
00:13:42,160 --> 00:13:43,040
supporting

402
00:13:43,040 --> 00:13:44,800
the particular sock and how they're

403
00:13:44,800 --> 00:13:46,560
using the platform in a way that makes

404
00:13:46,560 --> 00:13:47,360
sense for

405
00:13:47,360 --> 00:13:50,399
how they work through incidents we have

406
00:13:50,399 --> 00:13:52,079
timers associated with each of the stage

407
00:13:52,079 --> 00:13:53,680
fields so as i'm working through

408
00:13:53,680 --> 00:13:55,440
an incident i should always have

409
00:13:55,440 --> 00:13:57,440
knowledge about how long each step has

410
00:13:57,440 --> 00:13:58,320
taken me

411
00:13:58,320 --> 00:14:01,519
time to detect time to contain time to

412
00:14:01,519 --> 00:14:02,000
investigate

413
00:14:02,000 --> 00:14:05,199
time to remediate

414
00:14:10,720 --> 00:14:12,959
so i mentioned that a lot of incident

415
00:14:12,959 --> 00:14:14,160
management tools

416
00:14:14,160 --> 00:14:17,440
have a way to create custom fields think

417
00:14:17,440 --> 00:14:18,560
of soar

418
00:14:18,560 --> 00:14:21,600
as case management on steroids it allows

419
00:14:21,600 --> 00:14:22,639
us to break out

420
00:14:22,639 --> 00:14:26,560
incidents into a really large set of

421
00:14:26,560 --> 00:14:28,320
unique data fields this is like a

422
00:14:28,320 --> 00:14:29,680
taxonomy for dealing with security

423
00:14:29,680 --> 00:14:31,279
incidents

424
00:14:31,279 --> 00:14:33,199
so to make work makes all work for this

425
00:14:33,199 --> 00:14:34,480
kind of automation we want to break

426
00:14:34,480 --> 00:14:35,760
everything out

427
00:14:35,760 --> 00:14:39,279
into a way that describes our incidents

428
00:14:39,279 --> 00:14:42,720
very clearly and very explicitly

429
00:14:42,720 --> 00:14:43,839
so think of a typical incident

430
00:14:43,839 --> 00:14:45,519
management tool that has things like a

431
00:14:45,519 --> 00:14:46,240
name

432
00:14:46,240 --> 00:14:48,560
like a title of the incident the analyst

433
00:14:48,560 --> 00:14:50,720
it's assigned to when it occurred

434
00:14:50,720 --> 00:14:53,040
uh some things like that and then you

435
00:14:53,040 --> 00:14:54,800
just have free text notes describing the

436
00:14:54,800 --> 00:14:56,079
investigation steps

437
00:14:56,079 --> 00:14:57,680
what we want to do here is work out

438
00:14:57,680 --> 00:14:58,959
which features of this particular

439
00:14:58,959 --> 00:15:00,880
incident are actually relevant to

440
00:15:00,880 --> 00:15:03,120
analyzing and solving it and break those

441
00:15:03,120 --> 00:15:05,279
out

442
00:15:05,279 --> 00:15:06,480
so think about the difference between an

443
00:15:06,480 --> 00:15:08,399
attempted account takeover attack for

444
00:15:08,399 --> 00:15:09,199
example

445
00:15:09,199 --> 00:15:11,360
and a malware infected device the things

446
00:15:11,360 --> 00:15:12,800
that i'm looking at as an analyst

447
00:15:12,800 --> 00:15:14,240
are going to be quite different for

448
00:15:14,240 --> 00:15:15,839
those two different types of incidents

449
00:15:15,839 --> 00:15:17,120
so i want to make sure that i have the

450
00:15:17,120 --> 00:15:19,440
information presented to me

451
00:15:19,440 --> 00:15:21,360
what analyst is doing when they are

452
00:15:21,360 --> 00:15:23,120
investigating is they're answering

453
00:15:23,120 --> 00:15:24,320
questions about what this

454
00:15:24,320 --> 00:15:27,360
thing is so they want to know

455
00:15:27,360 --> 00:15:31,279
who what when where how and why

456
00:15:31,279 --> 00:15:32,800
that's what the investigation is focused

457
00:15:32,800 --> 00:15:35,440
on so if we define this into a set of

458
00:15:35,440 --> 00:15:36,399
questions that we need to

459
00:15:36,399 --> 00:15:38,880
ask by saying these are the fields that

460
00:15:38,880 --> 00:15:39,759
we need to have

461
00:15:39,759 --> 00:15:41,360
anytime we look at this particular type

462
00:15:41,360 --> 00:15:43,199
of incident that we know exactly what

463
00:15:43,199 --> 00:15:44,720
questions we need to answer

464
00:15:44,720 --> 00:15:47,759
when we're investigating it

465
00:15:48,480 --> 00:15:50,000
and what this gives us when we start

466
00:15:50,000 --> 00:15:51,440
breaking out our incidents in this way

467
00:15:51,440 --> 00:15:53,279
is a massive relational database

468
00:15:53,279 --> 00:15:56,160
of all of our security incidents we have

469
00:15:56,160 --> 00:15:57,040
in here

470
00:15:57,040 --> 00:16:00,240
not just the log messages and the events

471
00:16:00,240 --> 00:16:02,880
that underlie the incident but also

472
00:16:02,880 --> 00:16:04,240
information about the outcomes

473
00:16:04,240 --> 00:16:06,399
so who did this get assigned to how long

474
00:16:06,399 --> 00:16:08,399
did it take to resolve what was the

475
00:16:08,399 --> 00:16:09,680
classification in the end

476
00:16:09,680 --> 00:16:11,120
was it what the alert said it was

477
00:16:11,120 --> 00:16:12,560
initially or did it actually change

478
00:16:12,560 --> 00:16:14,240
throughout the investigation

479
00:16:14,240 --> 00:16:15,600
what was the result was it a false

480
00:16:15,600 --> 00:16:17,279
positive was it true positive

481
00:16:17,279 --> 00:16:18,639
we've got not just the inputs but the

482
00:16:18,639 --> 00:16:21,040
outputs in the incident data model as

483
00:16:21,040 --> 00:16:22,959
well

484
00:16:22,959 --> 00:16:26,000
this is what sets up the ability to use

485
00:16:26,000 --> 00:16:27,120
machine learning

486
00:16:27,120 --> 00:16:30,240
to generate some insights out of this

487
00:16:30,240 --> 00:16:31,920
just to give a look at what this looks

488
00:16:31,920 --> 00:16:34,240
like in a real saw platform

489
00:16:34,240 --> 00:16:38,399
here's an example of a custom layout

490
00:16:38,399 --> 00:16:41,600
in xor and so this is for a ransomware

491
00:16:41,600 --> 00:16:44,079
incident and we can see we've got some

492
00:16:44,079 --> 00:16:45,920
basic details like when this occurred

493
00:16:45,920 --> 00:16:47,120
but we've got some fields here that are

494
00:16:47,120 --> 00:16:49,120
very specific to a ransomware incident

495
00:16:49,120 --> 00:16:50,560
so we've got the ransomware recovery

496
00:16:50,560 --> 00:16:51,199
tool

497
00:16:51,199 --> 00:16:53,040
in this case not available uh we have

498
00:16:53,040 --> 00:16:55,279
the ransomware encrypted file owner

499
00:16:55,279 --> 00:16:58,000
the approximate number of encrypted

500
00:16:58,000 --> 00:17:00,079
endpoints so it's a numeric field

501
00:17:00,079 --> 00:17:02,720
we have the ransomware strain we have

502
00:17:02,720 --> 00:17:03,120
the

503
00:17:03,120 --> 00:17:05,439
data encryption status the

504
00:17:05,439 --> 00:17:07,839
cryptocurrency address

505
00:17:07,839 --> 00:17:09,919
the ransomware ongoing address and the

506
00:17:09,919 --> 00:17:12,720
ransomware email

507
00:17:14,880 --> 00:17:17,280
so obviously very specific to just

508
00:17:17,280 --> 00:17:18,079
ransomware

509
00:17:18,079 --> 00:17:19,919
incidents but apply this to any other

510
00:17:19,919 --> 00:17:21,919
type of incident we want to be able to

511
00:17:21,919 --> 00:17:24,000
pull these features out and attach it to

512
00:17:24,000 --> 00:17:26,720
the incident directly

513
00:17:29,200 --> 00:17:32,320
within xor indicators so uh indicators

514
00:17:32,320 --> 00:17:33,840
of compromise are their own

515
00:17:33,840 --> 00:17:35,840
model in themselves so we have

516
00:17:35,840 --> 00:17:37,520
indicators that relate to incidents i'm

517
00:17:37,520 --> 00:17:39,440
just showing this so you can see that

518
00:17:39,440 --> 00:17:41,280
while we do have indicators attached to

519
00:17:41,280 --> 00:17:42,720
an incident they're a separate data

520
00:17:42,720 --> 00:17:43,679
model

521
00:17:43,679 --> 00:17:47,679
there as well

522
00:17:47,679 --> 00:17:49,200
so how do we get all our incident data

523
00:17:49,200 --> 00:17:51,440
together this is where

524
00:17:51,440 --> 00:17:53,120
contextual enrichment playbooks come in

525
00:17:53,120 --> 00:17:54,880
and this is a key component of sort

526
00:17:54,880 --> 00:17:56,559
so as i said earlier and a security

527
00:17:56,559 --> 00:17:58,320
analyst is trying to answer questions

528
00:17:58,320 --> 00:18:00,480
about what's happened here

529
00:18:00,480 --> 00:18:02,480
get the machines going and talking to

530
00:18:02,480 --> 00:18:04,080
all the systems to fill that data in

531
00:18:04,080 --> 00:18:06,160
what we've got now at this point is a

532
00:18:06,160 --> 00:18:07,840
data model saying for this type of

533
00:18:07,840 --> 00:18:08,559
incident

534
00:18:08,559 --> 00:18:10,400
i want to populate all of these fields

535
00:18:10,400 --> 00:18:12,320
to answer what's happened here

536
00:18:12,320 --> 00:18:15,600
so i play i i want to hit go the go

537
00:18:15,600 --> 00:18:17,120
button on a playbook

538
00:18:17,120 --> 00:18:18,400
to have it go off and collect all that

539
00:18:18,400 --> 00:18:20,559
data often it's not contained within

540
00:18:20,559 --> 00:18:22,000
the initial event that triggered that

541
00:18:22,000 --> 00:18:23,679
incident but i know where to go and get

542
00:18:23,679 --> 00:18:24,400
it usually

543
00:18:24,400 --> 00:18:25,760
i have to figure this out manually

544
00:18:25,760 --> 00:18:27,440
somehow so i'm going to run a bunch of

545
00:18:27,440 --> 00:18:29,679
commands as part of my investigation

546
00:18:29,679 --> 00:18:31,679
and over time you start to see how did i

547
00:18:31,679 --> 00:18:32,960
answer that question how did i

548
00:18:32,960 --> 00:18:34,640
fill in this field on this incident how

549
00:18:34,640 --> 00:18:42,000
do i know what to look for

550
00:18:42,000 --> 00:18:43,919
and as i said we've got a set of

551
00:18:43,919 --> 00:18:45,679
incidents that also now have

552
00:18:45,679 --> 00:18:49,840
the outcomes associated with these

553
00:18:51,120 --> 00:18:53,760
the outcomes as well don't have to be

554
00:18:53,760 --> 00:18:56,080
just static so we're just a

555
00:18:56,080 --> 00:18:57,760
closed status was this a true positive

556
00:18:57,760 --> 00:18:59,360
versus a false positive we can also

557
00:18:59,360 --> 00:19:00,720
capture things

558
00:19:00,720 --> 00:19:02,720
about the reason why it was a true

559
00:19:02,720 --> 00:19:04,400
positive or a false positive

560
00:19:04,400 --> 00:19:06,720
it may be that we had some missing data

561
00:19:06,720 --> 00:19:08,960
maybe we had some context missing

562
00:19:08,960 --> 00:19:12,240
um indeterminate is a really bad outcome

563
00:19:12,240 --> 00:19:13,679
for security incidents we want to

564
00:19:13,679 --> 00:19:15,440
highlight those and avoid that but if we

565
00:19:15,440 --> 00:19:16,799
start to capture some of the reasons for

566
00:19:16,799 --> 00:19:18,320
these we can do some analysis on

567
00:19:18,320 --> 00:19:21,039
what type of events are we actually

568
00:19:21,039 --> 00:19:22,240
doing a bad job

569
00:19:22,240 --> 00:19:25,039
of um of analyzing and resolving so it's

570
00:19:25,039 --> 00:19:26,000
really key

571
00:19:26,000 --> 00:19:28,400
and again saw enables this by not just

572
00:19:28,400 --> 00:19:29,200
being

573
00:19:29,200 --> 00:19:32,400
a standardized incident management tool

574
00:19:32,400 --> 00:19:34,320
it's fully customizable and fully

575
00:19:34,320 --> 00:19:36,000
programmable

576
00:19:36,000 --> 00:19:37,200
so as long as you know what you want to

577
00:19:37,200 --> 00:19:40,960
do out of it you can typically do it

578
00:19:43,039 --> 00:19:44,400
in the next few slides i'm going to talk

579
00:19:44,400 --> 00:19:46,240
through a few use cases for machine

580
00:19:46,240 --> 00:19:49,360
learning within saw platforms

581
00:19:49,360 --> 00:19:51,039
these can be applied once you have the

582
00:19:51,039 --> 00:19:52,480
incident data model configured and

583
00:19:52,480 --> 00:19:53,760
you've got some data in the system to

584
00:19:53,760 --> 00:19:55,600
work with

585
00:19:55,600 --> 00:19:57,600
these ones are actually out of the box

586
00:19:57,600 --> 00:19:59,360
use cases within xor

587
00:19:59,360 --> 00:20:01,039
so i'm not showing anything too

588
00:20:01,039 --> 00:20:02,799
complicated too advanced as long as you

589
00:20:02,799 --> 00:20:04,559
have the data there to support that

590
00:20:04,559 --> 00:20:06,400
support the use cases these will

591
00:20:06,400 --> 00:20:08,640
actually work by default and again other

592
00:20:08,640 --> 00:20:10,559
platforms have similar

593
00:20:10,559 --> 00:20:14,640
features as well so based on the

594
00:20:14,640 --> 00:20:16,159
datasets we've laid out we've now

595
00:20:16,159 --> 00:20:18,000
enumerated different types of fields for

596
00:20:18,000 --> 00:20:18,880
different incidents

597
00:20:18,880 --> 00:20:20,720
and we've got the outcomes in there we

598
00:20:20,720 --> 00:20:22,960
can start to see

599
00:20:22,960 --> 00:20:24,799
where incidents are related to other

600
00:20:24,799 --> 00:20:27,120
incidents and again the key here is that

601
00:20:27,120 --> 00:20:27,679
it's not an

602
00:20:27,679 --> 00:20:29,679
analyst who remembers what they saw last

603
00:20:29,679 --> 00:20:30,960
week or knows

604
00:20:30,960 --> 00:20:33,280
what they saw a month ago and spent time

605
00:20:33,280 --> 00:20:34,080
working on

606
00:20:34,080 --> 00:20:36,320
we now have a machine looking at large

607
00:20:36,320 --> 00:20:37,440
data sets

608
00:20:37,440 --> 00:20:40,320
of incident data with input parameters

609
00:20:40,320 --> 00:20:41,600
and with outcomes

610
00:20:41,600 --> 00:20:43,360
the machine is doing a better job of

611
00:20:43,360 --> 00:20:44,640
matching related incidents

612
00:20:44,640 --> 00:20:46,559
than we ever could as analysts and it'll

613
00:20:46,559 --> 00:20:47,919
find correlations that we weren't

614
00:20:47,919 --> 00:20:49,919
looking for

615
00:20:49,919 --> 00:20:52,000
the reason this is so useful is this

616
00:20:52,000 --> 00:20:53,360
provides analysts

617
00:20:53,360 --> 00:20:55,200
with information up front about the

618
00:20:55,200 --> 00:20:56,559
event that they're looking at where have

619
00:20:56,559 --> 00:20:59,360
i seen this before

620
00:20:59,440 --> 00:21:02,159
what is this related to and then i can

621
00:21:02,159 --> 00:21:03,120
see

622
00:21:03,120 --> 00:21:04,480
i have all that information at hand

623
00:21:04,480 --> 00:21:06,799
about where we've seen similar

624
00:21:06,799 --> 00:21:09,200
things in the past and i'm getting this

625
00:21:09,200 --> 00:21:10,720
without having to have seen all those

626
00:21:10,720 --> 00:21:11,600
things

627
00:21:11,600 --> 00:21:15,280
myself so this is again about

628
00:21:15,280 --> 00:21:17,440
scaling analyst expertise i learned from

629
00:21:17,440 --> 00:21:18,960
what the machine is now telling me about

630
00:21:18,960 --> 00:21:20,960
this thing

631
00:21:20,960 --> 00:21:23,520
another key aspect of this is that if i

632
00:21:23,520 --> 00:21:25,360
can identify related things

633
00:21:25,360 --> 00:21:26,799
i can work out whether something may be

634
00:21:26,799 --> 00:21:28,480
a duplicate so if i'm looking at an

635
00:21:28,480 --> 00:21:28,960
event

636
00:21:28,960 --> 00:21:31,039
that's come in one of the first filters

637
00:21:31,039 --> 00:21:32,159
that i want to use for whether i'm going

638
00:21:32,159 --> 00:21:33,520
to spend time investigating this

639
00:21:33,520 --> 00:21:35,840
is is this already solved or is someone

640
00:21:35,840 --> 00:21:36,880
else looking at this

641
00:21:36,880 --> 00:21:38,640
by showing how things are related the

642
00:21:38,640 --> 00:21:39,919
tool should be able to tell me if that's

643
00:21:39,919 --> 00:21:41,039
something that i should know about

644
00:21:41,039 --> 00:21:41,679
already

645
00:21:41,679 --> 00:21:43,120
i don't have to go and ask everyone on

646
00:21:43,120 --> 00:21:44,400
the team for every single thing that i'm

647
00:21:44,400 --> 00:21:46,799
looking at

648
00:21:51,120 --> 00:21:52,960
by looking at the related incidents we

649
00:21:52,960 --> 00:21:54,720
can connect analysts with experts

650
00:21:54,720 --> 00:21:57,120
who've dealt with these things before

651
00:21:57,120 --> 00:21:58,000
this helps facilitate

652
00:21:58,000 --> 00:22:01,039
knowledge transfer and give us many way

653
00:22:01,039 --> 00:22:02,799
meaningful ways for people to talk to

654
00:22:02,799 --> 00:22:03,919
each other about the types of things

655
00:22:03,919 --> 00:22:05,120
they're doing rather than just saying

656
00:22:05,120 --> 00:22:06,640
hey has anyone seen this

657
00:22:06,640 --> 00:22:09,600
lately we the machine will now know

658
00:22:09,600 --> 00:22:10,559
someone else has looked at this

659
00:22:10,559 --> 00:22:11,520
particular one

660
00:22:11,520 --> 00:22:12,960
and it'll make some recommendations to

661
00:22:12,960 --> 00:22:14,720
say you should speak to this

662
00:22:14,720 --> 00:22:16,960
person who typically closes these ones

663
00:22:16,960 --> 00:22:18,080
out maybe they

664
00:22:18,080 --> 00:22:19,840
are the most efficient at closing them

665
00:22:19,840 --> 00:22:21,919
out so maybe you should assign it to

666
00:22:21,919 --> 00:22:22,320
them

667
00:22:22,320 --> 00:22:24,159
now i don't want to suggest just assign

668
00:22:24,159 --> 00:22:25,520
it to them and make it their problem

669
00:22:25,520 --> 00:22:27,039
but it gives me an opportunity to go and

670
00:22:27,039 --> 00:22:28,640
talk to them about why do you typically

671
00:22:28,640 --> 00:22:30,320
have these ones what do you know

672
00:22:30,320 --> 00:22:32,880
about this one that you can teach me so

673
00:22:32,880 --> 00:22:35,840
that i can then get better at doing this

674
00:22:35,840 --> 00:22:37,200
sometimes you're not assigning it to

675
00:22:37,200 --> 00:22:38,559
someone else you just want to pull a

676
00:22:38,559 --> 00:22:39,600
collaborator in

677
00:22:39,600 --> 00:22:41,200
and again learn from what they're doing

678
00:22:41,200 --> 00:22:42,960
so you may have someone on the team

679
00:22:42,960 --> 00:22:45,520
who is an absolute gun at pulling apart

680
00:22:45,520 --> 00:22:47,280
exploit kits

681
00:22:47,280 --> 00:22:48,640
i want to talk to them when i have

682
00:22:48,640 --> 00:22:50,400
something that looks like an exploit kit

683
00:22:50,400 --> 00:22:52,080
and get them to teach me what do they

684
00:22:52,080 --> 00:22:53,840
normally do what are the actions they

685
00:22:53,840 --> 00:22:54,799
take

686
00:22:54,799 --> 00:22:59,440
and be able to

687
00:22:59,440 --> 00:23:00,559
yeah come to them with something that is

688
00:23:00,559 --> 00:23:02,080
focused in their area of expertise so

689
00:23:02,080 --> 00:23:03,600
this is the most efficient way

690
00:23:03,600 --> 00:23:06,320
to get through a large set of incidents

691
00:23:06,320 --> 00:23:07,039
that i may have

692
00:23:07,039 --> 00:23:09,440
to deal with at this time so this is all

693
00:23:09,440 --> 00:23:10,159
about

694
00:23:10,159 --> 00:23:12,000
using technology to connect humans

695
00:23:12,000 --> 00:23:14,000
together so they can collaborate and

696
00:23:14,000 --> 00:23:16,799
learn from each other

697
00:23:18,320 --> 00:23:20,000
and following on directly from that is

698
00:23:20,000 --> 00:23:21,600
analyst guidance so

699
00:23:21,600 --> 00:23:24,000
as i said every action that you take

700
00:23:24,000 --> 00:23:25,360
within the platform

701
00:23:25,360 --> 00:23:28,480
is now attached as a it's a command

702
00:23:28,480 --> 00:23:31,760
that ran on that incident so even before

703
00:23:31,760 --> 00:23:32,159
we've

704
00:23:32,159 --> 00:23:33,360
gone down the path of setting up

705
00:23:33,360 --> 00:23:34,799
standardized playbooks for every single

706
00:23:34,799 --> 00:23:35,679
type of incident

707
00:23:35,679 --> 00:23:37,520
i can already learn from what other

708
00:23:37,520 --> 00:23:38,960
analysts are doing what they typically

709
00:23:38,960 --> 00:23:39,440
do

710
00:23:39,440 --> 00:23:41,360
i can see their thought processes to see

711
00:23:41,360 --> 00:23:42,880
what uh what create

712
00:23:42,880 --> 00:23:45,039
queries they ran what commands they ran

713
00:23:45,039 --> 00:23:46,400
what did they do to help answer these

714
00:23:46,400 --> 00:23:47,039
questions

715
00:23:47,039 --> 00:23:48,559
so even before i talk to them i should

716
00:23:48,559 --> 00:23:49,600
probably have a look at some of the

717
00:23:49,600 --> 00:23:50,640
related incidents

718
00:23:50,640 --> 00:23:52,240
and see how they typically go through

719
00:23:52,240 --> 00:23:54,320
this and i've got it all broken out

720
00:23:54,320 --> 00:23:56,480
but the machine can also then provide

721
00:23:56,480 --> 00:23:57,360
recommendations

722
00:23:57,360 --> 00:24:00,080
say there's this thing that's just

723
00:24:00,080 --> 00:24:01,679
occurred

724
00:24:01,679 --> 00:24:03,679
you see five of these a week the first

725
00:24:03,679 --> 00:24:04,799
three things

726
00:24:04,799 --> 00:24:06,159
that other analysts do when they see

727
00:24:06,159 --> 00:24:08,000
this one are these commands

728
00:24:08,000 --> 00:24:09,520
give that a try so it gives me a

729
00:24:09,520 --> 00:24:12,080
starting point

730
00:24:12,080 --> 00:24:13,200
and as i said this is a bit more

731
00:24:13,200 --> 00:24:15,360
flexible than trying to create

732
00:24:15,360 --> 00:24:17,039
everything as a standardized playbook

733
00:24:17,039 --> 00:24:18,240
and say

734
00:24:18,240 --> 00:24:21,360
a simple if this then that which is what

735
00:24:21,360 --> 00:24:23,120
playbooks are commonly

736
00:24:23,120 --> 00:24:24,960
set up you might get to that for some

737
00:24:24,960 --> 00:24:26,320
things but you want to also have some

738
00:24:26,320 --> 00:24:28,240
flexibility about how you get to

739
00:24:28,240 --> 00:24:29,760
understanding what i need to do it's not

740
00:24:29,760 --> 00:24:31,279
the same in every single case

741
00:24:31,279 --> 00:24:32,880
and an experienced analyst who's done

742
00:24:32,880 --> 00:24:34,960
this before will intuitively know when i

743
00:24:34,960 --> 00:24:36,400
need to vary from the script

744
00:24:36,400 --> 00:24:37,679
but newer analysts don't have that

745
00:24:37,679 --> 00:24:38,880
expertise and they haven't learnt that

746
00:24:38,880 --> 00:24:40,480
yet so this helps them

747
00:24:40,480 --> 00:24:42,640
understand this is the normal path that

748
00:24:42,640 --> 00:24:44,159
i go through but maybe you want to try

749
00:24:44,159 --> 00:24:45,440
some other things as well just to get

750
00:24:45,440 --> 00:24:48,400
some more of that context

751
00:24:49,760 --> 00:24:52,720
for the last part of this talk i'm going

752
00:24:52,720 --> 00:24:54,240
to shift gears a little bit

753
00:24:54,240 --> 00:24:56,400
and talk about using attack simulation

754
00:24:56,400 --> 00:24:57,360
to generate

755
00:24:57,360 --> 00:24:59,520
a set of incidents there was a great

756
00:24:59,520 --> 00:25:01,279
talk about this earlier today

757
00:25:01,279 --> 00:25:02,559
which actually focused much more on the

758
00:25:02,559 --> 00:25:04,640
attack simulation side and i wanted to

759
00:25:04,640 --> 00:25:06,240
show how that fits into

760
00:25:06,240 --> 00:25:09,840
the the soar aspect of this

761
00:25:10,640 --> 00:25:12,640
we use attack simulation with many of

762
00:25:12,640 --> 00:25:14,000
our customers who have a sock

763
00:25:14,000 --> 00:25:16,000
to help them understand how effective

764
00:25:16,000 --> 00:25:17,360
and efficient their stock is

765
00:25:17,360 --> 00:25:20,400
at detecting or responding to attacks as

766
00:25:20,400 --> 00:25:21,440
a side effect of running these

767
00:25:21,440 --> 00:25:22,320
simulations

768
00:25:22,320 --> 00:25:24,320
what we're actually doing is generating

769
00:25:24,320 --> 00:25:26,080
a set of known

770
00:25:26,080 --> 00:25:29,279
bad actions these are confirmed

771
00:25:29,279 --> 00:25:30,880
malicious events

772
00:25:30,880 --> 00:25:33,039
so think of this as a labeled training

773
00:25:33,039 --> 00:25:34,720
set we know these things are bad

774
00:25:34,720 --> 00:25:37,919
because our red team did them

775
00:25:37,919 --> 00:25:42,640
we don't have to guess at this

776
00:25:42,640 --> 00:25:43,840
the general process for running

777
00:25:43,840 --> 00:25:47,679
simulations is

778
00:25:47,679 --> 00:25:50,400
shown on screen here so we work with the

779
00:25:50,400 --> 00:25:51,200
customer to

780
00:25:51,200 --> 00:25:54,159
identify some threat scenarios that they

781
00:25:54,159 --> 00:25:54,880
should be

782
00:25:54,880 --> 00:25:57,520
testing in their environment we map that

783
00:25:57,520 --> 00:25:58,960
into a sequence

784
00:25:58,960 --> 00:26:01,919
of a chain of events that that incident

785
00:26:01,919 --> 00:26:04,000
will look like end-to-end

786
00:26:04,000 --> 00:26:06,559
we we turn that into a set of test cases

787
00:26:06,559 --> 00:26:07,600
for each stage

788
00:26:07,600 --> 00:26:10,400
of the attack and we build scripts and

789
00:26:10,400 --> 00:26:11,279
automation to

790
00:26:11,279 --> 00:26:12,320
execute those attacks in their

791
00:26:12,320 --> 00:26:13,600
environment we set up some

792
00:26:13,600 --> 00:26:15,520
infrastructure to run it on

793
00:26:15,520 --> 00:26:16,880
and then we document the expected

794
00:26:16,880 --> 00:26:18,720
outcomes so based on what we know

795
00:26:18,720 --> 00:26:21,039
about your detection technology in your

796
00:26:21,039 --> 00:26:22,320
environment and the information you have

797
00:26:22,320 --> 00:26:23,279
at hand

798
00:26:23,279 --> 00:26:25,440
we have an idea on how they should

799
00:26:25,440 --> 00:26:26,960
perform in that scenario

800
00:26:26,960 --> 00:26:30,400
and then of course we run the exercise

801
00:26:32,080 --> 00:26:33,919
so simulations are a great way to build

802
00:26:33,919 --> 00:26:36,480
up those contextual enrichment playbooks

803
00:26:36,480 --> 00:26:38,400
by having this repeatable exercise that

804
00:26:38,400 --> 00:26:39,679
you can run

805
00:26:39,679 --> 00:26:41,919
and knowing for every incident that's

806
00:26:41,919 --> 00:26:42,720
going to be triggered

807
00:26:42,720 --> 00:26:44,559
as a result of this these are the

808
00:26:44,559 --> 00:26:46,000
questions that i have to answer because

809
00:26:46,000 --> 00:26:48,799
i've got my fields broken out

810
00:26:48,799 --> 00:26:51,360
you can iterate through this and build

811
00:26:51,360 --> 00:26:52,960
up playbooks to help you go and populate

812
00:26:52,960 --> 00:26:53,840
that data model

813
00:26:53,840 --> 00:26:56,159
and say for this type of incident i need

814
00:26:56,159 --> 00:26:58,400
all these questions answered

815
00:26:58,400 --> 00:26:59,600
i'm only going to be effective at

816
00:26:59,600 --> 00:27:00,799
dealing with this one if i have all that

817
00:27:00,799 --> 00:27:02,480
information available so you're filling

818
00:27:02,480 --> 00:27:03,120
in

819
00:27:03,120 --> 00:27:05,200
data visibility gaps as you go through

820
00:27:05,200 --> 00:27:06,960
this or at least it can be used

821
00:27:06,960 --> 00:27:08,480
to do that if you run it on a regular

822
00:27:08,480 --> 00:27:11,520
basis so as well as providing some data

823
00:27:11,520 --> 00:27:13,440
through running it as a one-off use this

824
00:27:13,440 --> 00:27:15,120
as a training platform for your analyst

825
00:27:15,120 --> 00:27:16,640
to go and build out those playbooks

826
00:27:16,640 --> 00:27:18,480
because again it's confirmed malicious

827
00:27:18,480 --> 00:27:21,200
you know sorry you know that this thing

828
00:27:21,200 --> 00:27:21,840
was bad

829
00:27:21,840 --> 00:27:23,520
you know how it should end up so build

830
00:27:23,520 --> 00:27:24,960
your playbooks around those types of

831
00:27:24,960 --> 00:27:27,279
incidents

832
00:27:31,679 --> 00:27:32,720
at the end of the day you get a

833
00:27:32,720 --> 00:27:34,320
measurable result on how well the stock

834
00:27:34,320 --> 00:27:35,679
performed and that's that's nice in

835
00:27:35,679 --> 00:27:36,960
terms of seeing where you are

836
00:27:36,960 --> 00:27:39,200
uh and being able to show improvement in

837
00:27:39,200 --> 00:27:41,600
detection effectiveness over time

838
00:27:41,600 --> 00:27:44,880
but as i said the real key from a sore

839
00:27:44,880 --> 00:27:47,520
perspective here is building up that set

840
00:27:47,520 --> 00:27:48,080
of

841
00:27:48,080 --> 00:27:50,960
malicious events that help to inform the

842
00:27:50,960 --> 00:27:52,480
data models in the sim

843
00:27:52,480 --> 00:27:56,480
sorry in the saw and

844
00:27:56,480 --> 00:27:58,559
help to build up what the machine has

845
00:27:58,559 --> 00:28:00,720
available to analyze and to help

846
00:28:00,720 --> 00:28:02,799
bring analysts together and inform their

847
00:28:02,799 --> 00:28:05,279
processes

848
00:28:09,120 --> 00:28:11,039
so if you're going to do all this work

849
00:28:11,039 --> 00:28:12,159
you need to have some measures to show

850
00:28:12,159 --> 00:28:15,039
how this is helping over

851
00:28:15,760 --> 00:28:16,799
i time back to the challenges at the

852
00:28:16,799 --> 00:28:19,520
start around the challenge of dealing

853
00:28:19,520 --> 00:28:20,000
with

854
00:28:20,000 --> 00:28:21,360
false positives and how much time that

855
00:28:21,360 --> 00:28:23,520
takes up and the challenge of scaling

856
00:28:23,520 --> 00:28:25,120
analyst expertise and helping people

857
00:28:25,120 --> 00:28:27,360
learn from each other

858
00:28:27,360 --> 00:28:30,399
what we want to understand at the end

859
00:28:30,399 --> 00:28:32,480
of all this is how as we're addressing

860
00:28:32,480 --> 00:28:34,240
those challenges how are we improving

861
00:28:34,240 --> 00:28:37,440
efficiency and effectiveness of the sock

862
00:28:37,440 --> 00:28:40,480
and from an efficiency perspective

863
00:28:40,480 --> 00:28:43,760
this is around seeing the time to

864
00:28:43,760 --> 00:28:45,840
the time spent on investigating false

865
00:28:45,840 --> 00:28:46,799
positives drop

866
00:28:46,799 --> 00:28:49,919
so by having a data set that allows

867
00:28:49,919 --> 00:28:52,880
a sore platform to tell analysts go and

868
00:28:52,880 --> 00:28:53,840
talk to this person

869
00:28:53,840 --> 00:28:56,320
or run this set of commands it's pretty

870
00:28:56,320 --> 00:28:57,200
logical to see

871
00:28:57,200 --> 00:28:59,520
that that should drop the time spent on

872
00:28:59,520 --> 00:29:00,799
investigating each one of those new

873
00:29:00,799 --> 00:29:01,600
things

874
00:29:01,600 --> 00:29:03,200
we should have we should be over time

875
00:29:03,200 --> 00:29:04,640
avoiding having

876
00:29:04,640 --> 00:29:06,799
an analyst who is new who hasn't seen

877
00:29:06,799 --> 00:29:07,919
this thing before

878
00:29:07,919 --> 00:29:10,320
having to relearn from the very

879
00:29:10,320 --> 00:29:11,120
beginning

880
00:29:11,120 --> 00:29:13,200
how to address that entire incident just

881
00:29:13,200 --> 00:29:14,320
to find out every time

882
00:29:14,320 --> 00:29:15,919
that many of these are false positives

883
00:29:15,919 --> 00:29:16,960
they still need to go through that

884
00:29:16,960 --> 00:29:18,320
process but we can accelerate that

885
00:29:18,320 --> 00:29:20,640
learning process

886
00:29:20,640 --> 00:29:22,240
and that's what the system is intended

887
00:29:22,240 --> 00:29:24,480
to do

888
00:29:25,200 --> 00:29:27,279
and in terms of effectiveness at the end

889
00:29:27,279 --> 00:29:28,880
of the day we want to be able to show

890
00:29:28,880 --> 00:29:29,279
that we

891
00:29:29,279 --> 00:29:31,919
are getting better at doing what the

892
00:29:31,919 --> 00:29:33,279
business is paying us to do which is to

893
00:29:33,279 --> 00:29:35,200
detect and respond to attacks

894
00:29:35,200 --> 00:29:38,559
so the the outcome i mean

895
00:29:38,559 --> 00:29:41,760
the proof of that is in the sock

896
00:29:41,760 --> 00:29:43,600
simulation attack tests the results of

897
00:29:43,600 --> 00:29:45,440
that is just getting better over time

898
00:29:45,440 --> 00:29:47,679
and again just based on the fact that we

899
00:29:47,679 --> 00:29:49,120
are repeatedly building up our

900
00:29:49,120 --> 00:29:50,799
contextual enrichment playbooks

901
00:29:50,799 --> 00:29:52,640
every time we run these and iterating

902
00:29:52,640 --> 00:29:54,320
over that we

903
00:29:54,320 --> 00:29:55,600
should be seeing improvements in this

904
00:29:55,600 --> 00:29:58,080
over time

905
00:29:59,200 --> 00:30:02,320
the key points i wanted to get through

906
00:30:02,320 --> 00:30:04,320
in this presentation are that cyber

907
00:30:04,320 --> 00:30:05,840
security is heavily dependent

908
00:30:05,840 --> 00:30:07,440
on human expertise and having

909
00:30:07,440 --> 00:30:08,880
standardized processes

910
00:30:08,880 --> 00:30:11,360
technology is fantastic but we are at

911
00:30:11,360 --> 00:30:13,279
the end of the day dependent on humans

912
00:30:13,279 --> 00:30:15,360
to be to know what they're looking at

913
00:30:15,360 --> 00:30:16,880
and to learn from each other and share

914
00:30:16,880 --> 00:30:17,520
that knowledge

915
00:30:17,520 --> 00:30:19,440
and get better at what they're doing the

916
00:30:19,440 --> 00:30:21,200
promise of thor

917
00:30:21,200 --> 00:30:22,960
is that technology can assist us with

918
00:30:22,960 --> 00:30:25,679
these processes

919
00:30:25,760 --> 00:30:28,559
and that technology exists today so the

920
00:30:28,559 --> 00:30:30,240
use cases that i showed for using

921
00:30:30,240 --> 00:30:31,600
machine learning

922
00:30:31,600 --> 00:30:33,679
in a sore platform were out of the box

923
00:30:33,679 --> 00:30:35,440
they exist today and we can make use of

924
00:30:35,440 --> 00:30:36,960
that as long as we structure our data

925
00:30:36,960 --> 00:30:37,919
correctly

926
00:30:37,919 --> 00:30:39,600
it does require a bit of a shift in

927
00:30:39,600 --> 00:30:41,840
thinking

928
00:30:41,840 --> 00:30:44,159
we need to understand how we need to

929
00:30:44,159 --> 00:30:44,960
model data

930
00:30:44,960 --> 00:30:46,720
for the platform to be able to do this

931
00:30:46,720 --> 00:30:48,720
so there is some work involved

932
00:30:48,720 --> 00:30:51,279
in creating that in engineering that so

933
00:30:51,279 --> 00:30:52,480
that we have the environment available

934
00:30:52,480 --> 00:30:55,600
for the tool to do its job

935
00:30:58,159 --> 00:31:00,399
so if we just add new tools like saw but

936
00:31:00,399 --> 00:31:01,600
we don't change the way that we actually

937
00:31:01,600 --> 00:31:03,360
use with them

938
00:31:03,360 --> 00:31:05,679
where that we use them we're not really

939
00:31:05,679 --> 00:31:08,000
doing enough to address those challenges

940
00:31:08,000 --> 00:31:10,880
that we discussed up front and we're

941
00:31:10,880 --> 00:31:12,320
still gonna

942
00:31:12,320 --> 00:31:14,880
remain uh unable to yeah scale analyst

943
00:31:14,880 --> 00:31:15,840
expertise

944
00:31:15,840 --> 00:31:17,760
and deal with uh knowledge transfer and

945
00:31:17,760 --> 00:31:20,240
sharing collaboration and improvement

946
00:31:20,240 --> 00:31:21,360
that brings me to the end of my talk

947
00:31:21,360 --> 00:31:24,470
thank you very much thank you nate

948
00:31:24,470 --> 00:31:26,960
[Applause]

949
00:31:26,960 --> 00:31:29,679
fantastic that was really good thank you

950
00:31:29,679 --> 00:31:30,720
were there any questions

951
00:31:30,720 --> 00:31:32,799
no questions on the on the app through

952
00:31:32,799 --> 00:31:34,480
the q a button

953
00:31:34,480 --> 00:31:35,760
i'm hoping there might be some questions

954
00:31:35,760 --> 00:31:37,519
on the floor i can get my steps up

955
00:31:37,519 --> 00:31:40,000
running around

956
00:31:43,279 --> 00:31:45,600
nope doesn't look like it getting off

957
00:31:45,600 --> 00:31:46,559
easy all right

958
00:31:46,559 --> 00:31:48,399
easy so thank you thanks again nick it

959
00:31:48,399 --> 00:31:50,880
was really really insightful thank you

960
00:31:50,880 --> 00:31:53,200
thank you

961
00:31:53,200 --> 00:31:55,840
[Applause]

962
00:31:55,840 --> 00:31:58,399
so we've got about 10 or so minutes just

963
00:31:58,399 --> 00:32:00,240
over 10 minutes before the next speaker

964
00:32:00,240 --> 00:32:03,840
comes on who's going to be zooming to us

965
00:32:03,840 --> 00:32:06,559
see what i did there uh so don't go away

966
00:32:06,559 --> 00:32:08,159
or if you do want to go away please come

967
00:32:08,159 --> 00:32:09,279
back

968
00:32:09,279 --> 00:32:12,000
um grab a refreshment there's some water

969
00:32:12,000 --> 00:32:13,919
outside as well as some mints and stuff

970
00:32:13,919 --> 00:32:14,559
so

971
00:32:14,559 --> 00:32:29,840
see you all back here shortly

972
00:34:17,440 --> 00:34:19,520
you

