1
00:00:02,000 --> 00:00:05,600
good morning everyone

2
00:00:03,120 --> 00:00:06,319
welcome back to day two of the oddssert

3
00:00:05,600 --> 00:00:09,200
conference

4
00:00:06,319 --> 00:00:11,360
um we've got our first of the session

5
00:00:09,200 --> 00:00:13,678
presentations today we have

6
00:00:11,360 --> 00:00:15,518
nick ellsmore with his presentation on

7
00:00:13,679 --> 00:00:16,480
the case for back burning your data

8
00:00:15,519 --> 00:00:18,000
environment

9
00:00:16,480 --> 00:00:20,480
um for those who just joined us today

10
00:00:18,000 --> 00:00:22,480
maybe um just a reminder that

11
00:00:20,480 --> 00:00:25,119
chrome seems to be the more preferred

12
00:00:22,480 --> 00:00:27,760
browser so if you are having any issues

13
00:00:25,119 --> 00:00:29,359
um it's recommended to use chrome um and

14
00:00:27,760 --> 00:00:30,080
if you do have issues with screen

15
00:00:29,359 --> 00:00:33,280
freezing and

16
00:00:30,080 --> 00:00:36,239
such to just kind of refresh the the or

17
00:00:33,280 --> 00:00:38,879
reload the page and that seems to be uh

18
00:00:36,239 --> 00:00:41,839
the good solution for fixing things

19
00:00:38,879 --> 00:00:42,960
um so yeah you're more all more than

20
00:00:41,840 --> 00:00:45,440
welcome to ask

21
00:00:42,960 --> 00:00:46,800
questions throughout um nick will do his

22
00:00:45,440 --> 00:00:48,559
best to try and

23
00:00:46,800 --> 00:00:50,800
field those questions throughout else

24
00:00:48,559 --> 00:00:53,120
and i also deal with them at the end

25
00:00:50,800 --> 00:00:54,078
so without further ado i'm going to pass

26
00:00:53,120 --> 00:00:56,399
it on to nick

27
00:00:54,079 --> 00:00:58,719
um again his presentation the case for

28
00:00:56,399 --> 00:01:03,520
back burning your data environment

29
00:00:58,719 --> 00:01:06,560
thanks nick fantastic thanks aaron

30
00:01:03,520 --> 00:01:09,680
uh this is uh of course my

31
00:01:06,560 --> 00:01:13,040
my first attempt at uh at one of these

32
00:01:09,680 --> 00:01:15,360
remote presentations um but

33
00:01:13,040 --> 00:01:17,040
uh i think after the last few months

34
00:01:15,360 --> 00:01:19,280
we're all pretty familiar now with

35
00:01:17,040 --> 00:01:21,600
with speaking into a screen and a camera

36
00:01:19,280 --> 00:01:22,799
uh so although i can't uh i can't see

37
00:01:21,600 --> 00:01:26,080
anyone

38
00:01:22,799 --> 00:01:28,720
please do engage through the q a

39
00:01:26,080 --> 00:01:30,079
particularly and hopefully this

40
00:01:28,720 --> 00:01:33,280
presentation

41
00:01:30,079 --> 00:01:34,559
is something that's of value to you i'll

42
00:01:33,280 --> 00:01:37,119
just share this

43
00:01:34,560 --> 00:01:37,119
with you

44
00:01:37,759 --> 00:01:42,320
there we go all right um so

45
00:01:40,960 --> 00:01:45,600
for those who don't know me my name's

46
00:01:42,320 --> 00:01:47,360
nick ellsmore i am

47
00:01:45,600 --> 00:01:48,720
currently the director of consulting and

48
00:01:47,360 --> 00:01:52,000
professional services

49
00:01:48,720 --> 00:01:53,200
at uh trustwave uh prior to that uh i

50
00:01:52,000 --> 00:01:55,680
started a company called

51
00:01:53,200 --> 00:01:58,560
hyvent which was acquired by trustwave

52
00:01:55,680 --> 00:02:00,560
at the end of 2018

53
00:01:58,560 --> 00:02:02,240
being a cyber security uh consulting and

54
00:02:00,560 --> 00:02:04,799
advisory firm

55
00:02:02,240 --> 00:02:06,719
and going back further was the founder

56
00:02:04,799 --> 00:02:07,920
of a company called sift which became

57
00:02:06,719 --> 00:02:10,359
stratsec

58
00:02:07,920 --> 00:02:12,160
and that was acquired by bae systems in

59
00:02:10,360 --> 00:02:13,760
2010

60
00:02:12,160 --> 00:02:15,200
so i've been in the cyber security

61
00:02:13,760 --> 00:02:18,640
industry now for about uh

62
00:02:15,200 --> 00:02:20,720
20 years uh i have been

63
00:02:18,640 --> 00:02:23,760
i think my first presentation at ausert

64
00:02:20,720 --> 00:02:27,520
was in 2005

65
00:02:23,760 --> 00:02:29,760
and was on the uh was actually on

66
00:02:27,520 --> 00:02:30,560
uh culture culture of security and the

67
00:02:29,760 --> 00:02:33,760
risk of

68
00:02:30,560 --> 00:02:35,760
security fatigue the fact that if we

69
00:02:33,760 --> 00:02:37,840
kept running awareness campaigns telling

70
00:02:35,760 --> 00:02:39,840
people that the world was going to end

71
00:02:37,840 --> 00:02:41,360
that that people would eventually tune

72
00:02:39,840 --> 00:02:43,360
out so it's uh

73
00:02:41,360 --> 00:02:45,120
it's been a long and interesting journey

74
00:02:43,360 --> 00:02:47,040
so this presentation is uh

75
00:02:45,120 --> 00:02:49,200
as head on back burning your data

76
00:02:47,040 --> 00:02:51,040
environment

77
00:02:49,200 --> 00:02:52,958
this is a concept i've been working on

78
00:02:51,040 --> 00:02:55,280
for a while now and i've

79
00:02:52,959 --> 00:02:56,720
alternated between using the metaphor

80
00:02:55,280 --> 00:02:59,040
around back burning

81
00:02:56,720 --> 00:02:59,920
and more recently on i think murray

82
00:02:59,040 --> 00:03:02,480
condo's

83
00:02:59,920 --> 00:03:04,399
approach to cleaning the idea that you

84
00:03:02,480 --> 00:03:04,959
should throw out data if it doesn't

85
00:03:04,400 --> 00:03:07,840
spark

86
00:03:04,959 --> 00:03:08,400
joy um but i think i think the current

87
00:03:07,840 --> 00:03:10,000
um

88
00:03:08,400 --> 00:03:12,400
uh the current one around back burning

89
00:03:10,000 --> 00:03:14,080
probably uh was particularly relevant at

90
00:03:12,400 --> 00:03:14,879
the end of last year when i started

91
00:03:14,080 --> 00:03:17,599
writing it

92
00:03:14,879 --> 00:03:20,319
uh is less relevant now now i probably

93
00:03:17,599 --> 00:03:22,480
need to find a pandemic

94
00:03:20,319 --> 00:03:25,440
metaphor to uh to really tie it to

95
00:03:22,480 --> 00:03:27,119
current current times

96
00:03:25,440 --> 00:03:28,799
so what i'm going to talk about today is

97
00:03:27,120 --> 00:03:30,879
is really i think what i sort of

98
00:03:28,799 --> 00:03:32,080
consider the wonder drug of cyber

99
00:03:30,879 --> 00:03:35,840
security projects

100
00:03:32,080 --> 00:03:39,120
which is a project that is very low cost

101
00:03:35,840 --> 00:03:41,040
it actually saves you money directly

102
00:03:39,120 --> 00:03:42,560
and so you're very rarely going to have

103
00:03:41,040 --> 00:03:45,679
any real resistance

104
00:03:42,560 --> 00:03:47,840
to two people funding the project

105
00:03:45,680 --> 00:03:48,879
and it significantly improves your risk

106
00:03:47,840 --> 00:03:50,640
posture

107
00:03:48,879 --> 00:03:52,239
and if if someone came to you and said

108
00:03:50,640 --> 00:03:53,040
we've got the cyber security project

109
00:03:52,239 --> 00:03:54,480
it's going to cost

110
00:03:53,040 --> 00:03:57,120
next to nothing it's going to make you

111
00:03:54,480 --> 00:03:58,798
money and it's going to reduce your risk

112
00:03:57,120 --> 00:04:00,879
generally speaking that's the sort of

113
00:03:58,799 --> 00:04:03,439
cyber security project that

114
00:04:00,879 --> 00:04:06,000
we're all going to sign up for because

115
00:04:03,439 --> 00:04:07,920
it's it's pretty much the antithesis of

116
00:04:06,000 --> 00:04:08,319
every other cyber security project that

117
00:04:07,920 --> 00:04:11,439
we

118
00:04:08,319 --> 00:04:14,560
that we seem to be investing in

119
00:04:11,439 --> 00:04:15,680
now the back burning metaphor um this in

120
00:04:14,560 --> 00:04:18,639
many ways is

121
00:04:15,680 --> 00:04:19,680
is is what most organizations uh sort of

122
00:04:18,639 --> 00:04:22,320
data stores

123
00:04:19,680 --> 00:04:24,240
look like um and this is not good if

124
00:04:22,320 --> 00:04:26,639
you're looking to try to avoid a

125
00:04:24,240 --> 00:04:28,960
a bush fire or rather if you're trying

126
00:04:26,639 --> 00:04:31,520
to manage the impact of a bushfire and

127
00:04:28,960 --> 00:04:32,960
and part of this is is really just

128
00:04:31,520 --> 00:04:34,960
highlighting the fact that for

129
00:04:32,960 --> 00:04:38,000
organizations at the moment

130
00:04:34,960 --> 00:04:40,479
we've focused so much on data retention

131
00:04:38,000 --> 00:04:42,479
and on this this sort of concept around

132
00:04:40,479 --> 00:04:44,639
big data and the belief that

133
00:04:42,479 --> 00:04:46,560
data may somehow magically become

134
00:04:44,639 --> 00:04:48,960
valuable over time

135
00:04:46,560 --> 00:04:50,720
that we've built up really really large

136
00:04:48,960 --> 00:04:51,758
amounts of data without necessarily

137
00:04:50,720 --> 00:04:54,400
considering the

138
00:04:51,759 --> 00:04:54,960
the risk that that introduces or the the

139
00:04:54,400 --> 00:04:58,239
cost

140
00:04:54,960 --> 00:05:00,638
associated with that risk and so

141
00:04:58,240 --> 00:05:03,680
metaphorically this is uh this is what

142
00:05:00,639 --> 00:05:04,400
many organizations data stores uh look

143
00:05:03,680 --> 00:05:06,800
like

144
00:05:04,400 --> 00:05:08,400
um technically this isn't really just

145
00:05:06,800 --> 00:05:10,639
leaf litter i actually think that this

146
00:05:08,400 --> 00:05:13,359
is a really really extreme

147
00:05:10,639 --> 00:05:15,280
uh brushed turkey's nest but uh either

148
00:05:13,360 --> 00:05:18,560
way if they uh if a bush fire comes

149
00:05:15,280 --> 00:05:19,758
through bad things are going to happen

150
00:05:18,560 --> 00:05:21,199
one of the sayings that you all would

151
00:05:19,759 --> 00:05:22,880
have heard at one point or another is

152
00:05:21,199 --> 00:05:24,320
this concept that sometimes you have to

153
00:05:22,880 --> 00:05:26,560
fight fire with fire

154
00:05:24,320 --> 00:05:28,479
of course that is effectively back

155
00:05:26,560 --> 00:05:31,440
burning that's that concept

156
00:05:28,479 --> 00:05:33,280
um interestingly as i as i started

157
00:05:31,440 --> 00:05:34,320
putting this together i came to find

158
00:05:33,280 --> 00:05:36,840
that

159
00:05:34,320 --> 00:05:39,039
my understanding of back burning was uh

160
00:05:36,840 --> 00:05:42,479
significantly

161
00:05:39,039 --> 00:05:44,159
less accurate than i thought it was

162
00:05:42,479 --> 00:05:45,919
and technically a lot of what i'm going

163
00:05:44,160 --> 00:05:48,320
to be talking about isn't

164
00:05:45,919 --> 00:05:51,520
really back burning it's actually a

165
00:05:48,320 --> 00:05:53,599
hazard reduction burn

166
00:05:51,520 --> 00:05:55,599
the concept of back burning is actually

167
00:05:53,600 --> 00:05:57,440
that when you have a fire coming towards

168
00:05:55,600 --> 00:05:58,720
you you actually start a fire to

169
00:05:57,440 --> 00:06:00,719
basically burn back in the other

170
00:05:58,720 --> 00:06:02,160
direction so that you can stop it in its

171
00:06:00,720 --> 00:06:04,000
tracks

172
00:06:02,160 --> 00:06:06,080
from a data security perspective

173
00:06:04,000 --> 00:06:08,000
metaphor kind of breaks down if you use

174
00:06:06,080 --> 00:06:10,159
that pure definition because

175
00:06:08,000 --> 00:06:11,919
it's like saying that you've already had

176
00:06:10,160 --> 00:06:13,840
a security incident but you're quickly

177
00:06:11,919 --> 00:06:16,960
going to jump in and start deleting all

178
00:06:13,840 --> 00:06:18,638
of your data to stop it from being taken

179
00:06:16,960 --> 00:06:20,638
while there may be some merit in that

180
00:06:18,639 --> 00:06:22,639
i'm not sort of suggesting that that's

181
00:06:20,639 --> 00:06:24,880
going to be the best approach

182
00:06:22,639 --> 00:06:27,280
the hazard reduction concept or control

183
00:06:24,880 --> 00:06:28,639
burning is is much more relevant

184
00:06:27,280 --> 00:06:30,799
and the control burning or hazard

185
00:06:28,639 --> 00:06:31,199
reduction concept is basically if you

186
00:06:30,800 --> 00:06:33,919
have

187
00:06:31,199 --> 00:06:36,080
huge amounts of you know leaf litter and

188
00:06:33,919 --> 00:06:38,799
and other material that would

189
00:06:36,080 --> 00:06:39,680
in the event of a fire cause real

190
00:06:38,800 --> 00:06:42,000
problems

191
00:06:39,680 --> 00:06:43,759
um try to get rid of it in the coal of

192
00:06:42,000 --> 00:06:46,319
months before a fire starts

193
00:06:43,759 --> 00:06:48,720
so that you can stop uh an actual

194
00:06:46,319 --> 00:06:50,400
bushfire being much much worse

195
00:06:48,720 --> 00:06:52,240
this is really i think what i'm trying

196
00:06:50,400 --> 00:06:56,000
to harness from the perspective

197
00:06:52,240 --> 00:06:58,319
of uh of data security which is

198
00:06:56,000 --> 00:06:59,680
as organizations we've built up and

199
00:06:58,319 --> 00:07:02,560
allowed to occur

200
00:06:59,680 --> 00:07:04,720
this um you know this this spread of

201
00:07:02,560 --> 00:07:06,319
data this sprawl of data

202
00:07:04,720 --> 00:07:08,160
that we need to start getting under

203
00:07:06,319 --> 00:07:10,080
control and we need to actually start

204
00:07:08,160 --> 00:07:11,840
reducing that fuel

205
00:07:10,080 --> 00:07:13,599
because ultimately a lot of that is

206
00:07:11,840 --> 00:07:14,239
turning into data breaches and is

207
00:07:13,599 --> 00:07:16,479
actually

208
00:07:14,240 --> 00:07:18,240
costing us a lot when those uh when

209
00:07:16,479 --> 00:07:19,919
those breaches are happening

210
00:07:18,240 --> 00:07:22,080
but i did need to have this definition

211
00:07:19,919 --> 00:07:24,479
there definition in there because

212
00:07:22,080 --> 00:07:26,240
um in case anyone was actually in the

213
00:07:24,479 --> 00:07:26,719
rural fire service or something like

214
00:07:26,240 --> 00:07:29,680
that

215
00:07:26,720 --> 00:07:30,400
and uh objected uh significantly to my

216
00:07:29,680 --> 00:07:33,680
misuse

217
00:07:30,400 --> 00:07:35,120
of uh of the back burning concept

218
00:07:33,680 --> 00:07:36,960
this is back burning just because you

219
00:07:35,120 --> 00:07:40,080
can never have too many photos of

220
00:07:36,960 --> 00:07:43,440
of firefighters so

221
00:07:40,080 --> 00:07:46,240
the simple parallel we can't stop

222
00:07:43,440 --> 00:07:48,080
uh bush fires um but we can reduce the

223
00:07:46,240 --> 00:07:48,879
impact of bushfires and certainly that's

224
00:07:48,080 --> 00:07:51,039
what a lot of

225
00:07:48,879 --> 00:07:53,759
back burning is is about or has a

226
00:07:51,039 --> 00:07:55,919
reduction burn it is about

227
00:07:53,759 --> 00:07:57,599
likewise i think we are all coming to

228
00:07:55,919 --> 00:08:00,719
terms and are accepting the fact that

229
00:07:57,599 --> 00:08:03,440
there are going to be data breaches

230
00:08:00,720 --> 00:08:05,520
it's not going to be possible to to

231
00:08:03,440 --> 00:08:08,479
fully prevent them from happening

232
00:08:05,520 --> 00:08:10,318
but what we can do is reduce the impact

233
00:08:08,479 --> 00:08:11,680
we can also reduce the likelihood in

234
00:08:10,319 --> 00:08:14,639
some cases

235
00:08:11,680 --> 00:08:16,479
but we can definitely reduce the impact

236
00:08:14,639 --> 00:08:18,560
and so in the same way that you know

237
00:08:16,479 --> 00:08:21,039
data is effectively the the fuel to a

238
00:08:18,560 --> 00:08:22,639
data breach if there's less fuel

239
00:08:21,039 --> 00:08:25,360
then there's less likelihood that the

240
00:08:22,639 --> 00:08:27,840
breach is going to be catastrophic

241
00:08:25,360 --> 00:08:30,080
now a lot of you i'm sure will come from

242
00:08:27,840 --> 00:08:33,360
regulated environments

243
00:08:30,080 --> 00:08:35,679
where for a whole variety of reasons

244
00:08:33,360 --> 00:08:36,880
there is a real concern about deleting

245
00:08:35,679 --> 00:08:40,079
data

246
00:08:36,880 --> 00:08:42,080
and there's a real risk about

247
00:08:40,080 --> 00:08:44,720
deleting data that you're obligated to

248
00:08:42,080 --> 00:08:46,080
keep and finding out later on that some

249
00:08:44,720 --> 00:08:48,160
of the data that was deleted is

250
00:08:46,080 --> 00:08:49,920
something that is then subject to either

251
00:08:48,160 --> 00:08:51,760
you know court action or regulatory

252
00:08:49,920 --> 00:08:54,800
action or something similar

253
00:08:51,760 --> 00:08:57,519
i understand that pain

254
00:08:54,800 --> 00:08:59,519
um the main uh sort of premise of this

255
00:08:57,519 --> 00:09:01,760
presentation is simply that

256
00:08:59,519 --> 00:09:03,600
there is a cost associated with keeping

257
00:09:01,760 --> 00:09:04,640
the information not just the cost of

258
00:09:03,600 --> 00:09:07,360
storage and the

259
00:09:04,640 --> 00:09:09,120
you know the operational it cost but the

260
00:09:07,360 --> 00:09:11,040
cost associated with

261
00:09:09,120 --> 00:09:13,440
from a formal risk perspective what you

262
00:09:11,040 --> 00:09:16,399
would call the annual loss expectancy

263
00:09:13,440 --> 00:09:17,680
associated with retaining that data so

264
00:09:16,399 --> 00:09:20,240
my argument is that

265
00:09:17,680 --> 00:09:21,599
every record that you retain every piece

266
00:09:20,240 --> 00:09:24,399
of data that you retain

267
00:09:21,600 --> 00:09:25,360
has an annual loss expectancy of some

268
00:09:24,399 --> 00:09:26,640
kind

269
00:09:25,360 --> 00:09:28,640
and the more data you have then

270
00:09:26,640 --> 00:09:31,439
obviously the the higher that annual

271
00:09:28,640 --> 00:09:33,120
loss expectancy becomes

272
00:09:31,440 --> 00:09:35,839
and while it's really hard to calculate

273
00:09:33,120 --> 00:09:37,680
it it's almost certain that if we could

274
00:09:35,839 --> 00:09:39,519
calculate it accurately

275
00:09:37,680 --> 00:09:41,519
it would actually change a lot of the

276
00:09:39,519 --> 00:09:43,600
decisions that we make

277
00:09:41,519 --> 00:09:46,560
around which data is stored how long

278
00:09:43,600 --> 00:09:48,000
it's stored for and so on

279
00:09:46,560 --> 00:09:49,599
one of the other statements that was

280
00:09:48,000 --> 00:09:51,839
that was made elsewhere was

281
00:09:49,600 --> 00:09:53,279
you know the data that you don't have

282
00:09:51,839 --> 00:09:55,200
doesn't have to be checked for

283
00:09:53,279 --> 00:09:57,200
compliance against gdpr

284
00:09:55,200 --> 00:09:58,560
doesn't have to be released in a data

285
00:09:57,200 --> 00:10:01,040
access request

286
00:09:58,560 --> 00:10:03,518
and it can't be subject to a data breach

287
00:10:01,040 --> 00:10:05,760
which is a really really simple message

288
00:10:03,519 --> 00:10:09,519
but i think in many ways is also a

289
00:10:05,760 --> 00:10:09,519
really effective way of looking at this

290
00:10:11,279 --> 00:10:14,480
so what's the specific data that we're

291
00:10:13,600 --> 00:10:17,200
talking about

292
00:10:14,480 --> 00:10:19,519
when i start talking to clients about

293
00:10:17,200 --> 00:10:21,680
this sort of leaf litter concept the

294
00:10:19,519 --> 00:10:23,920
the data that has sort of dropped off

295
00:10:21,680 --> 00:10:26,719
and aggregated on the floor of

296
00:10:23,920 --> 00:10:28,880
of your organization um it tends to

297
00:10:26,720 --> 00:10:30,160
break down to four groups and and these

298
00:10:28,880 --> 00:10:33,200
are them

299
00:10:30,160 --> 00:10:33,519
the first is old backups uh and they may

300
00:10:33,200 --> 00:10:34,880
be

301
00:10:33,519 --> 00:10:36,720
you know old backups that are sort of

302
00:10:34,880 --> 00:10:39,279
physically stored on on

303
00:10:36,720 --> 00:10:40,000
tape or on disks somewhere uh or it may

304
00:10:39,279 --> 00:10:41,680
just be

305
00:10:40,000 --> 00:10:44,079
you know backed up systems that have

306
00:10:41,680 --> 00:10:46,560
been um you know sort of archived off

307
00:10:44,079 --> 00:10:48,560
and left alone

308
00:10:46,560 --> 00:10:50,239
there's a lot of databases for systems

309
00:10:48,560 --> 00:10:52,399
that are no longer in use

310
00:10:50,240 --> 00:10:54,720
uh often systems are decommissioned but

311
00:10:52,399 --> 00:10:56,480
the the actual databases or the actual

312
00:10:54,720 --> 00:11:00,240
sort of content of those systems aren't

313
00:10:56,480 --> 00:11:02,640
actually removed one of the biggest uh

314
00:11:00,240 --> 00:11:04,640
in almost every organization though is

315
00:11:02,640 --> 00:11:07,839
this third one which is

316
00:11:04,640 --> 00:11:10,560
exports and extracts of data sets um

317
00:11:07,839 --> 00:11:11,920
that were once used for analysis but are

318
00:11:10,560 --> 00:11:14,399
no longer being used

319
00:11:11,920 --> 00:11:15,279
and the the reality is the vast majority

320
00:11:14,399 --> 00:11:18,480
of this stuff

321
00:11:15,279 --> 00:11:19,439
uh is excel files excel files and csv

322
00:11:18,480 --> 00:11:20,959
files

323
00:11:19,440 --> 00:11:23,200
um and so these are files that have

324
00:11:20,959 --> 00:11:24,800
basically been extracted or exported

325
00:11:23,200 --> 00:11:26,320
from a live system

326
00:11:24,800 --> 00:11:28,319
um have been used for some kind of

327
00:11:26,320 --> 00:11:28,800
analysis they've probably been emailed

328
00:11:28,320 --> 00:11:31,600
around

329
00:11:28,800 --> 00:11:34,160
they've been stored on file shares and

330
00:11:31,600 --> 00:11:36,480
over time they've just been forgotten

331
00:11:34,160 --> 00:11:37,519
and every organization that we work with

332
00:11:36,480 --> 00:11:40,320
has a

333
00:11:37,519 --> 00:11:42,240
vast amount of sensitive data sitting in

334
00:11:40,320 --> 00:11:44,640
these exports and extracts

335
00:11:42,240 --> 00:11:46,880
that for various reasons have been have

336
00:11:44,640 --> 00:11:49,439
been left and forgotten

337
00:11:46,880 --> 00:11:51,279
and then the fourth one really is a i

338
00:11:49,440 --> 00:11:54,000
think a more recent

339
00:11:51,279 --> 00:11:56,079
a more recent occurrence which is as the

340
00:11:54,000 --> 00:11:57,920
cost of storage has started going

341
00:11:56,079 --> 00:12:00,239
down pretty drastically and and the

342
00:11:57,920 --> 00:12:03,360
ability to scale up storage

343
00:12:00,240 --> 00:12:05,600
um elastically has increased um

344
00:12:03,360 --> 00:12:06,880
you haven't had this sort of the same

345
00:12:05,600 --> 00:12:08,399
driver of

346
00:12:06,880 --> 00:12:10,480
you know we're going to need to buy a

347
00:12:08,399 --> 00:12:12,320
new sand if we're going to keep storing

348
00:12:10,480 --> 00:12:13,920
data it's now just a case of

349
00:12:12,320 --> 00:12:15,760
you know that the storage is just going

350
00:12:13,920 --> 00:12:17,040
to keep expanding based on the data that

351
00:12:15,760 --> 00:12:19,040
we have

352
00:12:17,040 --> 00:12:20,760
and so there's there's really a much

353
00:12:19,040 --> 00:12:24,079
lower um

354
00:12:20,760 --> 00:12:25,680
disincentive against storing additional

355
00:12:24,079 --> 00:12:27,439
information and so we've started just

356
00:12:25,680 --> 00:12:28,719
retaining lots and lots and lots of

357
00:12:27,440 --> 00:12:31,600
additional data

358
00:12:28,720 --> 00:12:32,880
just in case now in many ways the

359
00:12:31,600 --> 00:12:36,240
interesting part about this

360
00:12:32,880 --> 00:12:39,200
is if you look at these four one two and

361
00:12:36,240 --> 00:12:41,279
three are often not conscious decisions

362
00:12:39,200 --> 00:12:42,560
so the old backups the databases the

363
00:12:41,279 --> 00:12:44,560
exports

364
00:12:42,560 --> 00:12:45,760
it's rarely the case that someone has

365
00:12:44,560 --> 00:12:48,638
specifically said

366
00:12:45,760 --> 00:12:50,839
let's make sure that we keep that data

367
00:12:48,639 --> 00:12:54,560
it's more a case that the data has been

368
00:12:50,839 --> 00:12:56,800
forgotten whereas with the fourth case

369
00:12:54,560 --> 00:12:59,040
that's generally a conscious decision so

370
00:12:56,800 --> 00:13:01,839
that's actually a case of someone saying

371
00:12:59,040 --> 00:13:02,319
yes we definitely want to keep that

372
00:13:01,839 --> 00:13:04,480
again

373
00:13:02,320 --> 00:13:05,839
just in case and the reason that's

374
00:13:04,480 --> 00:13:07,680
important is

375
00:13:05,839 --> 00:13:09,839
they're different responses that are

376
00:13:07,680 --> 00:13:11,680
needed based on the fact that either

377
00:13:09,839 --> 00:13:13,839
you've intentionally decided to keep it

378
00:13:11,680 --> 00:13:16,239
or you've just forgotten that it's there

379
00:13:13,839 --> 00:13:18,240
and so the fundamental challenge is

380
00:13:16,240 --> 00:13:20,000
often it's a different person

381
00:13:18,240 --> 00:13:22,079
that is having to make the decision

382
00:13:20,000 --> 00:13:23,920
about retaining or deleting data

383
00:13:22,079 --> 00:13:25,680
as opposed to the person who created it

384
00:13:23,920 --> 00:13:28,560
in the first place and i'll explain some

385
00:13:25,680 --> 00:13:30,479
of that challenge as we go through

386
00:13:28,560 --> 00:13:32,000
now we absolutely aren't the only one

387
00:13:30,480 --> 00:13:34,560
only ones who are seeing this

388
00:13:32,000 --> 00:13:36,639
um jake williams malware jake from

389
00:13:34,560 --> 00:13:39,839
rendition sex some of you may uh

390
00:13:36,639 --> 00:13:43,040
may know or have heard of um this

391
00:13:39,839 --> 00:13:46,160
literally was uh just five days ago

392
00:13:43,040 --> 00:13:48,639
um posted on on twitter that you know

393
00:13:46,160 --> 00:13:50,719
every year they work on cases where

394
00:13:48,639 --> 00:13:52,480
they're um as they explain to the

395
00:13:50,720 --> 00:13:54,880
victims what the attacker stole

396
00:13:52,480 --> 00:13:56,560
uh the victim argues about the findings

397
00:13:54,880 --> 00:13:58,320
not because they doubt the methods but

398
00:13:56,560 --> 00:14:00,239
because they're sure the data that we're

399
00:13:58,320 --> 00:14:01,120
referencing no longer exists in their

400
00:14:00,240 --> 00:14:03,040
networks

401
00:14:01,120 --> 00:14:05,199
and that is exactly what we're talking

402
00:14:03,040 --> 00:14:05,839
about here and and we see the same thing

403
00:14:05,199 --> 00:14:08,800
in our

404
00:14:05,839 --> 00:14:10,320
in our incident response work as well um

405
00:14:08,800 --> 00:14:11,839
this scenario where

406
00:14:10,320 --> 00:14:14,480
the data that is actually being

407
00:14:11,839 --> 00:14:16,959
compromised is data that from the

408
00:14:14,480 --> 00:14:19,360
organization's perspective they weren't

409
00:14:16,959 --> 00:14:20,959
they weren't aware that it existed

410
00:14:19,360 --> 00:14:22,800
or they weren't aware that it existed

411
00:14:20,959 --> 00:14:25,279
anymore

412
00:14:22,800 --> 00:14:27,680
in one particular case that we saw a

413
00:14:25,279 --> 00:14:29,439
couple of years ago

414
00:14:27,680 --> 00:14:31,760
we actually had a case where an

415
00:14:29,440 --> 00:14:34,959
e-commerce company had had

416
00:14:31,760 --> 00:14:37,040
a database that had been

417
00:14:34,959 --> 00:14:38,638
stolen or the contents of that database

418
00:14:37,040 --> 00:14:41,599
had been taken

419
00:14:38,639 --> 00:14:43,360
and it was a particularly bizarre

420
00:14:41,600 --> 00:14:45,600
situation in that the information they

421
00:14:43,360 --> 00:14:48,720
were fed by the attacker

422
00:14:45,600 --> 00:14:51,760
to try and uh get the ransom try and get

423
00:14:48,720 --> 00:14:53,920
get a ransom paid had actually been

424
00:14:51,760 --> 00:14:55,040
modified from the original data that was

425
00:14:53,920 --> 00:14:57,360
stolen

426
00:14:55,040 --> 00:14:59,279
and so a lot of effort had to go into

427
00:14:57,360 --> 00:15:01,120
trying to figure out where this data set

428
00:14:59,279 --> 00:15:03,920
came from because

429
00:15:01,120 --> 00:15:05,839
part of the data set looked real and

430
00:15:03,920 --> 00:15:07,760
matched up with current clients

431
00:15:05,839 --> 00:15:10,240
part of the data set looked real but

432
00:15:07,760 --> 00:15:12,639
didn't match up to current clients

433
00:15:10,240 --> 00:15:14,240
and then there was also a set of credit

434
00:15:12,639 --> 00:15:15,839
card data in there

435
00:15:14,240 --> 00:15:17,839
that didn't really make any sense

436
00:15:15,839 --> 00:15:19,920
because the organization had stopped

437
00:15:17,839 --> 00:15:20,959
accepting uh or stopped storing credit

438
00:15:19,920 --> 00:15:23,760
card data

439
00:15:20,959 --> 00:15:25,040
many many years ago and what it turned

440
00:15:23,760 --> 00:15:27,839
out had actually happened

441
00:15:25,040 --> 00:15:29,920
is the attackers had actually tried to

442
00:15:27,839 --> 00:15:30,959
increase the value of the compromised

443
00:15:29,920 --> 00:15:33,680
data set

444
00:15:30,959 --> 00:15:34,560
by actually adding in a fictitious set

445
00:15:33,680 --> 00:15:36,880
of credit card

446
00:15:34,560 --> 00:15:38,560
numbers credit card data so that when

447
00:15:36,880 --> 00:15:40,000
they sent it to the organization and

448
00:15:38,560 --> 00:15:41,839
tried to extort them

449
00:15:40,000 --> 00:15:43,759
they could purport to have a more

450
00:15:41,839 --> 00:15:45,440
valuable data set so they could try and

451
00:15:43,759 --> 00:15:48,399
extort more money

452
00:15:45,440 --> 00:15:49,279
which was you know particularly creative

453
00:15:48,399 --> 00:15:51,120
uh as

454
00:15:49,279 --> 00:15:53,040
it turned out the organization talk

455
00:15:51,120 --> 00:15:54,560
spoke to their the bank about it tried

456
00:15:53,040 --> 00:15:55,519
to sort of cross-reference some data

457
00:15:54,560 --> 00:15:57,518
points

458
00:15:55,519 --> 00:15:59,279
um found out that the credit card

459
00:15:57,519 --> 00:16:01,839
numbers were were fake

460
00:15:59,279 --> 00:16:04,000
uh but ultimately then realized that the

461
00:16:01,839 --> 00:16:06,079
data set itself was real

462
00:16:04,000 --> 00:16:07,440
and came from a legacy system that that

463
00:16:06,079 --> 00:16:08,399
they were pretty sure had been

464
00:16:07,440 --> 00:16:11,440
decommissioned

465
00:16:08,399 --> 00:16:13,360
years ago um and as as jake says if you

466
00:16:11,440 --> 00:16:16,480
don't have it it can't be stolen which

467
00:16:13,360 --> 00:16:18,560
is a pretty compelling message

468
00:16:16,480 --> 00:16:19,600
so the question at the heart of of of

469
00:16:18,560 --> 00:16:22,160
this concept

470
00:16:19,600 --> 00:16:23,839
is whether or not the the cost

471
00:16:22,160 --> 00:16:27,360
associated with the risk of

472
00:16:23,839 --> 00:16:29,120
keeping the data um is greater than the

473
00:16:27,360 --> 00:16:32,320
cost associated with the risk

474
00:16:29,120 --> 00:16:33,199
of deleting the data so effectively is

475
00:16:32,320 --> 00:16:36,399
the risk

476
00:16:33,199 --> 00:16:39,279
higher to have this legacy data

477
00:16:36,399 --> 00:16:40,880
than it is to delete it and run the risk

478
00:16:39,279 --> 00:16:42,560
of falling fail of some retention

479
00:16:40,880 --> 00:16:45,439
requirements

480
00:16:42,560 --> 00:16:47,359
it's a difficult calculation but

481
00:16:45,440 --> 00:16:47,920
ultimately if you accept that there is a

482
00:16:47,360 --> 00:16:50,959
cost

483
00:16:47,920 --> 00:16:52,560
on both sides of this transaction

484
00:16:50,959 --> 00:16:54,638
then it does start leading us down a

485
00:16:52,560 --> 00:16:56,719
path of trying to say okay so we really

486
00:16:54,639 --> 00:16:59,040
need to start evaluating it much more

487
00:16:56,720 --> 00:17:02,160
accurately and much more meaningfully

488
00:16:59,040 --> 00:17:02,160
than we have in the past

489
00:17:02,720 --> 00:17:07,600
now the next section the next few slides

490
00:17:05,839 --> 00:17:08,799
i'll i'll run through are actually some

491
00:17:07,599 --> 00:17:11,280
example breaches

492
00:17:08,799 --> 00:17:13,119
um and i think it's important to uh to

493
00:17:11,280 --> 00:17:13,760
contextualize this by saying that

494
00:17:13,119 --> 00:17:15,520
there's

495
00:17:13,760 --> 00:17:18,079
you know there's no blame attribution

496
00:17:15,520 --> 00:17:21,599
guilt or anything else implied in this

497
00:17:18,079 --> 00:17:22,720
as uh the 16th century reformer john

498
00:17:21,599 --> 00:17:24,319
bradford says

499
00:17:22,720 --> 00:17:26,400
you know there but for the grace of god

500
00:17:24,319 --> 00:17:28,720
go i i think all of us

501
00:17:26,400 --> 00:17:31,520
in this industry recognize that data

502
00:17:28,720 --> 00:17:34,640
breaches can happen to everyone

503
00:17:31,520 --> 00:17:36,960
and at the same time

504
00:17:34,640 --> 00:17:39,039
we need to be able to learn from them

505
00:17:36,960 --> 00:17:41,440
and so the intent here is to uh

506
00:17:39,039 --> 00:17:43,200
to basically look at these and and see

507
00:17:41,440 --> 00:17:46,160
them as a demonstration of the point

508
00:17:43,200 --> 00:17:50,400
that uh that i'm trying to make

509
00:17:46,160 --> 00:17:51,679
the first nova entertainment in 2019 had

510
00:17:50,400 --> 00:17:54,559
a data breach

511
00:17:51,679 --> 00:17:56,480
uh the key point here is that the data

512
00:17:54,559 --> 00:17:59,200
set contained details collected between

513
00:17:56,480 --> 00:18:02,320
2009 and 2011.

514
00:17:59,200 --> 00:18:05,120
um you know so this is decade-old uh

515
00:18:02,320 --> 00:18:06,799
information uh some of it may be dummy

516
00:18:05,120 --> 00:18:08,879
data some of it maybe

517
00:18:06,799 --> 00:18:09,840
may not be legitimate a lot of it's not

518
00:18:08,880 --> 00:18:12,880
going to be active

519
00:18:09,840 --> 00:18:14,559
there's a lot of expired data but again

520
00:18:12,880 --> 00:18:17,679
it still goes down as a data breach

521
00:18:14,559 --> 00:18:21,760
affecting 250 000 people

522
00:18:17,679 --> 00:18:25,200
uh anu had a security breach in 2018

523
00:18:21,760 --> 00:18:27,360
uh data was up to 19 years old

524
00:18:25,200 --> 00:18:28,960
it was came about through some legacy

525
00:18:27,360 --> 00:18:32,159
infrastructure

526
00:18:28,960 --> 00:18:36,160
and a legacy mail server but again

527
00:18:32,160 --> 00:18:39,200
some very very old data was in there

528
00:18:36,160 --> 00:18:41,520
adult friend finder is another one um

529
00:18:39,200 --> 00:18:42,559
they had a data breach 412 million

530
00:18:41,520 --> 00:18:44,720
records

531
00:18:42,559 --> 00:18:46,160
and obviously given the nature of that

532
00:18:44,720 --> 00:18:48,400
site uh

533
00:18:46,160 --> 00:18:50,320
if you deleted your account you really

534
00:18:48,400 --> 00:18:52,320
really wanted it to be deleted

535
00:18:50,320 --> 00:18:54,840
uh it turned out that the hack included

536
00:18:52,320 --> 00:18:56,720
some 15 million accounts that had been

537
00:18:54,840 --> 00:18:58,240
deleted uh but they weren't

538
00:18:56,720 --> 00:19:00,559
purged from the database so they were

539
00:18:58,240 --> 00:19:01,919
still there so even though the accounts

540
00:19:00,559 --> 00:19:03,678
had been deleted

541
00:19:01,919 --> 00:19:06,160
um that didn't mean that they couldn't

542
00:19:03,679 --> 00:19:08,720
be subject to a data breach

543
00:19:06,160 --> 00:19:10,799
um and so that you know this sort of two

544
00:19:08,720 --> 00:19:13,120
decades worth of data

545
00:19:10,799 --> 00:19:14,000
and all sorts of accounts that um that

546
00:19:13,120 --> 00:19:17,120
really should uh

547
00:19:14,000 --> 00:19:19,200
shouldn't have been there at the time uh

548
00:19:17,120 --> 00:19:22,719
another peculiar one

549
00:19:19,200 --> 00:19:24,960
symantec in 2019 this is a peculiar one

550
00:19:22,720 --> 00:19:26,559
because it really reading through the

551
00:19:24,960 --> 00:19:28,799
the information available seems like

552
00:19:26,559 --> 00:19:31,760
there's nothing to see here uh it's just

553
00:19:28,799 --> 00:19:33,520
test data maybe some details of clients

554
00:19:31,760 --> 00:19:35,200
who had had a demo

555
00:19:33,520 --> 00:19:36,720
but given that it's a security company

556
00:19:35,200 --> 00:19:38,640
it's obviously a story when there's a

557
00:19:36,720 --> 00:19:40,160
potential data breach regardless of what

558
00:19:38,640 --> 00:19:42,640
the data is

559
00:19:40,160 --> 00:19:44,559
um but the key point here again is you

560
00:19:42,640 --> 00:19:46,240
know this wasn't this wasn't a live

561
00:19:44,559 --> 00:19:46,720
system it wasn't a key system that was

562
00:19:46,240 --> 00:19:49,760
being

563
00:19:46,720 --> 00:19:50,160
uh being sort of protected actively it

564
00:19:49,760 --> 00:19:52,400
was

565
00:19:50,160 --> 00:19:53,600
you know a demo lab it had some pretty

566
00:19:52,400 --> 00:19:55,200
low value data

567
00:19:53,600 --> 00:19:56,799
but it was still something that ended up

568
00:19:55,200 --> 00:19:59,280
having an impact and ended up being

569
00:19:56,799 --> 00:19:59,280
reported

570
00:19:59,520 --> 00:20:04,240
another one calpex through accenture

571
00:20:02,400 --> 00:20:06,320
accenture

572
00:20:04,240 --> 00:20:07,280
had some cloud-based storage service

573
00:20:06,320 --> 00:20:09,120
compromised

574
00:20:07,280 --> 00:20:10,639
uh and caltex ended up being caught up

575
00:20:09,120 --> 00:20:12,879
because they had provided

576
00:20:10,640 --> 00:20:14,640
um some sets of dummy data across a

577
00:20:12,880 --> 00:20:16,159
couple of years before to actually test

578
00:20:14,640 --> 00:20:18,559
out the platform

579
00:20:16,159 --> 00:20:20,799
so again it's it's not live data it's a

580
00:20:18,559 --> 00:20:22,799
test platform a dummy platform

581
00:20:20,799 --> 00:20:24,158
and yet the information still ends up

582
00:20:22,799 --> 00:20:27,520
being subject to the same

583
00:20:24,159 --> 00:20:29,600
to the same type of breach uh

584
00:20:27,520 --> 00:20:30,720
san francisco employees retirement

585
00:20:29,600 --> 00:20:33,280
system uh

586
00:20:30,720 --> 00:20:35,600
had a test environment again database

587
00:20:33,280 --> 00:20:37,200
had about 74 000 members in it

588
00:20:35,600 --> 00:20:38,879
uh included some pretty sensitive

589
00:20:37,200 --> 00:20:41,919
information in there

590
00:20:38,880 --> 00:20:42,559
and the data itself um again went went

591
00:20:41,919 --> 00:20:44,960
back

592
00:20:42,559 --> 00:20:47,840
quite a while so it the late the most

593
00:20:44,960 --> 00:20:49,360
recent data was from 2018

594
00:20:47,840 --> 00:20:51,840
but it was an old database and there was

595
00:20:49,360 --> 00:20:52,959
a significant amount of legacy data in

596
00:20:51,840 --> 00:20:56,000
there

597
00:20:52,960 --> 00:20:59,120
and then i think one of the last ones

598
00:20:56,000 --> 00:21:01,120
blackboard in the uk labour party

599
00:20:59,120 --> 00:21:02,239
sorry blackboard which is a service

600
00:21:01,120 --> 00:21:04,479
provider

601
00:21:02,240 --> 00:21:06,000
had their system compromised sometime

602
00:21:04,480 --> 00:21:08,480
earlier this year

603
00:21:06,000 --> 00:21:09,919
and again another historic backup file

604
00:21:08,480 --> 00:21:11,440
was compromised

605
00:21:09,919 --> 00:21:13,280
and ended up with a significant amount

606
00:21:11,440 --> 00:21:16,880
of data from the uk labor party

607
00:21:13,280 --> 00:21:18,000
uh being stolen the communication that

608
00:21:16,880 --> 00:21:20,080
went out around this

609
00:21:18,000 --> 00:21:22,240
is from my perspective particularly

610
00:21:20,080 --> 00:21:23,120
amusing in that it tells the affected

611
00:21:22,240 --> 00:21:26,240
users

612
00:21:23,120 --> 00:21:26,959
that the ransom was paid uh and you know

613
00:21:26,240 --> 00:21:29,120
that the

614
00:21:26,960 --> 00:21:30,480
data has been destroyed and so there's

615
00:21:29,120 --> 00:21:31,520
you know there's there's not really an

616
00:21:30,480 --> 00:21:33,360
issue anymore

617
00:21:31,520 --> 00:21:35,280
um the fact that we're actually relying

618
00:21:33,360 --> 00:21:37,360
on the assurances of the people who just

619
00:21:35,280 --> 00:21:39,840
stole our data and extorted us

620
00:21:37,360 --> 00:21:41,120
to tell us that they've deleted the data

621
00:21:39,840 --> 00:21:45,199
i think is uh

622
00:21:41,120 --> 00:21:47,439
is not necessarily a a great philosophy

623
00:21:45,200 --> 00:21:49,919
uh in fact the last one so instagram and

624
00:21:47,440 --> 00:21:52,640
twitter uh of course have both

625
00:21:49,919 --> 00:21:53,760
also had um sort of security issues

626
00:21:52,640 --> 00:21:55,120
raised where

627
00:21:53,760 --> 00:21:57,200
they've had this situation where they're

628
00:21:55,120 --> 00:21:58,239
retaining data after that data has been

629
00:21:57,200 --> 00:22:02,000
deleted

630
00:21:58,240 --> 00:22:04,159
um and so all of these really are just

631
00:22:02,000 --> 00:22:05,200
um are just referenced to highlight the

632
00:22:04,159 --> 00:22:07,520
fact that this

633
00:22:05,200 --> 00:22:09,520
this sort of scenario that i'm talking

634
00:22:07,520 --> 00:22:13,120
about about

635
00:22:09,520 --> 00:22:15,280
about non-production or about unneeded

636
00:22:13,120 --> 00:22:17,439
or about backup data legacy data

637
00:22:15,280 --> 00:22:19,120
old data the leaf litter in your

638
00:22:17,440 --> 00:22:21,760
organization

639
00:22:19,120 --> 00:22:22,399
being subject to a breach and causing a

640
00:22:21,760 --> 00:22:25,120
problem

641
00:22:22,400 --> 00:22:26,480
is very real um and and this is just a

642
00:22:25,120 --> 00:22:28,959
handful of

643
00:22:26,480 --> 00:22:29,840
particular scenarios we identified uh

644
00:22:28,960 --> 00:22:31,919
pretty quickly

645
00:22:29,840 --> 00:22:33,840
uh if you go through things like the the

646
00:22:31,919 --> 00:22:35,760
privacy rights clearinghouse list of

647
00:22:33,840 --> 00:22:36,639
data breaches and you start digging into

648
00:22:35,760 --> 00:22:38,799
them

649
00:22:36,640 --> 00:22:39,679
a pretty significant proportion of

650
00:22:38,799 --> 00:22:42,320
breaches

651
00:22:39,679 --> 00:22:44,080
are about non-core systems or about

652
00:22:42,320 --> 00:22:46,158
non-production systems

653
00:22:44,080 --> 00:22:47,840
they're about data sets that probably

654
00:22:46,159 --> 00:22:49,360
didn't need to be there a lot of the

655
00:22:47,840 --> 00:22:52,639
time

656
00:22:49,360 --> 00:22:55,039
and then closer to home of course in

657
00:22:52,640 --> 00:22:56,880
this earlier this year uh scott morrison

658
00:22:55,039 --> 00:22:57,760
gave his press conference about this

659
00:22:56,880 --> 00:23:00,720
about the

660
00:22:57,760 --> 00:23:02,559
the copy-paste compromises um and one of

661
00:23:00,720 --> 00:23:04,400
the lines in there was this the the

662
00:23:02,559 --> 00:23:06,639
attacker has shown an aptitude for

663
00:23:04,400 --> 00:23:07,679
identifying development tests and orphan

664
00:23:06,640 --> 00:23:10,080
services

665
00:23:07,679 --> 00:23:11,760
that are not well known or maintained by

666
00:23:10,080 --> 00:23:13,520
victim organizations

667
00:23:11,760 --> 00:23:15,200
now technically this isn't about the

668
00:23:13,520 --> 00:23:16,960
data this is about the systems the

669
00:23:15,200 --> 00:23:18,799
compromise vector

670
00:23:16,960 --> 00:23:20,000
but it's a similar issue you know

671
00:23:18,799 --> 00:23:22,480
basically as as an

672
00:23:20,000 --> 00:23:23,520
it industry and more broadly as a

673
00:23:22,480 --> 00:23:25,840
society

674
00:23:23,520 --> 00:23:27,760
we focus so much on the next thing that

675
00:23:25,840 --> 00:23:28,639
we haven't really come to terms with

676
00:23:27,760 --> 00:23:30,879
what's involved

677
00:23:28,640 --> 00:23:31,840
in effectively decommissioning the last

678
00:23:30,880 --> 00:23:33,440
thing

679
00:23:31,840 --> 00:23:35,199
and removing the data that goes along

680
00:23:33,440 --> 00:23:36,799
with it and

681
00:23:35,200 --> 00:23:38,240
you know the reality is that if you

682
00:23:36,799 --> 00:23:40,400
think it's hard to get a budget for

683
00:23:38,240 --> 00:23:42,080
securing your new systems

684
00:23:40,400 --> 00:23:44,000
trying to get a budget for securing

685
00:23:42,080 --> 00:23:48,480
systems that aren't used anymore

686
00:23:44,000 --> 00:23:48,480
is uh is genuinely nearly impossible

687
00:23:48,720 --> 00:23:52,480
so as a notorious big said no money mo

688
00:23:51,840 --> 00:23:54,320
problems

689
00:23:52,480 --> 00:23:57,039
you know i i would argue that it's also

690
00:23:54,320 --> 00:23:59,840
the case that uh mode data mode problems

691
00:23:57,039 --> 00:24:02,400
um you know most organizations will have

692
00:23:59,840 --> 00:24:03,520
a clear desk policy but not a clear file

693
00:24:02,400 --> 00:24:05,360
system policy

694
00:24:03,520 --> 00:24:07,520
you know so we end up with this sprawl

695
00:24:05,360 --> 00:24:10,879
of files and this amount of data

696
00:24:07,520 --> 00:24:12,720
that is subject to a potential breach

697
00:24:10,880 --> 00:24:15,039
we went through a phase where you know

698
00:24:12,720 --> 00:24:15,919
big data was becoming very popular and

699
00:24:15,039 --> 00:24:18,240
people would say

700
00:24:15,919 --> 00:24:19,679
you know data is the new oil um well i

701
00:24:18,240 --> 00:24:20,480
think we're starting to hear now this

702
00:24:19,679 --> 00:24:22,080
concept that

703
00:24:20,480 --> 00:24:24,480
you know data is actually the new

704
00:24:22,080 --> 00:24:26,480
uranium uh it has value

705
00:24:24,480 --> 00:24:28,880
but after it's used it's a nightmare to

706
00:24:26,480 --> 00:24:30,559
store it securely and it's toxic

707
00:24:28,880 --> 00:24:32,240
and i think that's a pretty healthy way

708
00:24:30,559 --> 00:24:34,000
to look at it

709
00:24:32,240 --> 00:24:36,640
another way to look at it is is this

710
00:24:34,000 --> 00:24:37,360
which is the the value versus the cost

711
00:24:36,640 --> 00:24:38,960
of the

712
00:24:37,360 --> 00:24:41,039
the risk of storing the data that i

713
00:24:38,960 --> 00:24:42,400
spoke about earlier and the argument

714
00:24:41,039 --> 00:24:44,960
that i'd make is

715
00:24:42,400 --> 00:24:47,360
data loses its value over time to your

716
00:24:44,960 --> 00:24:48,880
business but the cost associated with

717
00:24:47,360 --> 00:24:50,000
that risk is static or the other way to

718
00:24:48,880 --> 00:24:52,960
look at that is

719
00:24:50,000 --> 00:24:53,919
the value to an attacker is pretty

720
00:24:52,960 --> 00:24:56,960
static

721
00:24:53,919 --> 00:25:00,240
over time whereas the value to you

722
00:24:56,960 --> 00:25:01,279
goes down pretty quickly and a really

723
00:25:00,240 --> 00:25:04,559
simple example

724
00:25:01,279 --> 00:25:07,919
is if you have a record of my last

725
00:25:04,559 --> 00:25:11,520
three places of residence that doesn't

726
00:25:07,919 --> 00:25:13,919
really help your business a lot you need

727
00:25:11,520 --> 00:25:15,520
my current place of residence so you can

728
00:25:13,919 --> 00:25:17,200
send me bills and you can send debt

729
00:25:15,520 --> 00:25:18,799
collectors to find me if i don't pay

730
00:25:17,200 --> 00:25:22,080
them

731
00:25:18,799 --> 00:25:23,440
but the historic records don't

732
00:25:22,080 --> 00:25:24,799
necessarily add value to the

733
00:25:23,440 --> 00:25:27,200
organization

734
00:25:24,799 --> 00:25:28,400
whereas from an attacker's perspective

735
00:25:27,200 --> 00:25:31,279
that information

736
00:25:28,400 --> 00:25:32,880
is quite useful uh for any attempt to

737
00:25:31,279 --> 00:25:34,559
stealing an identity

738
00:25:32,880 --> 00:25:36,320
because often things like you know what

739
00:25:34,559 --> 00:25:38,399
are your past addresses

740
00:25:36,320 --> 00:25:39,600
other sort of historic information can

741
00:25:38,400 --> 00:25:41,840
actually be used

742
00:25:39,600 --> 00:25:43,760
for verifying identity and so

743
00:25:41,840 --> 00:25:45,199
effectively you've got no upside but you

744
00:25:43,760 --> 00:25:46,720
have a downside risk

745
00:25:45,200 --> 00:25:49,360
and so you really need to get rid of

746
00:25:46,720 --> 00:25:51,520
that data at some point the value of the

747
00:25:49,360 --> 00:25:53,120
data to your organization will be less

748
00:25:51,520 --> 00:25:54,080
than the value of the data to an

749
00:25:53,120 --> 00:25:56,320
attacker

750
00:25:54,080 --> 00:25:58,158
and at that point you're really in a

751
00:25:56,320 --> 00:25:59,918
troublesome place if you're storing that

752
00:25:58,159 --> 00:26:02,080
data for a long time

753
00:25:59,919 --> 00:26:03,520
um a guy called john kallus who's a

754
00:26:02,080 --> 00:26:06,720
senior technology fellow

755
00:26:03,520 --> 00:26:08,000
at the aclu the american civil liberties

756
00:26:06,720 --> 00:26:09,679
union

757
00:26:08,000 --> 00:26:11,679
actually wrote about this as well and

758
00:26:09,679 --> 00:26:14,400
the way he described it was this it's

759
00:26:11,679 --> 00:26:16,159
you know very articulate it says the

760
00:26:14,400 --> 00:26:18,000
cost of keeping data are higher than you

761
00:26:16,159 --> 00:26:20,080
think and the benefits are lower

762
00:26:18,000 --> 00:26:21,760
um there's a chance it will be useful

763
00:26:20,080 --> 00:26:23,199
but there's a chance it will be harmful

764
00:26:21,760 --> 00:26:24,640
like being lost in a breach or

765
00:26:23,200 --> 00:26:27,440
subpoenaed in a lawsuit

766
00:26:24,640 --> 00:26:29,360
which is another interesting angle but

767
00:26:27,440 --> 00:26:31,679
the chance it will be useful goes down

768
00:26:29,360 --> 00:26:33,039
over time but the harm value stays the

769
00:26:31,679 --> 00:26:34,720
same

770
00:26:33,039 --> 00:26:36,879
if you lose the address somebody lived

771
00:26:34,720 --> 00:26:38,400
at five years ago the eu doesn't care

772
00:26:36,880 --> 00:26:40,320
that it was inaccurate data that you

773
00:26:38,400 --> 00:26:42,720
didn't want and wasn't helping you

774
00:26:40,320 --> 00:26:44,399
losing it is still losing it at some

775
00:26:42,720 --> 00:26:47,600
point those lines cross and you should

776
00:26:44,400 --> 00:26:49,120
toss the data before they cross

777
00:26:47,600 --> 00:26:50,879
and it's a really really important point

778
00:26:49,120 --> 00:26:52,559
again just to have this this

779
00:26:50,880 --> 00:26:54,559
understanding that there is a value to

780
00:26:52,559 --> 00:26:57,039
the attacker or a cost of keeping it

781
00:26:54,559 --> 00:27:00,559
as well as the cost of uh of the the

782
00:26:57,039 --> 00:27:00,559
value that it creates to the business

783
00:27:02,400 --> 00:27:06,480
of course in theory that's all pretty

784
00:27:03,840 --> 00:27:08,480
sound but there's a reason there are no

785
00:27:06,480 --> 00:27:10,960
numbers on this diagram

786
00:27:08,480 --> 00:27:11,679
and that is there's really no particular

787
00:27:10,960 --> 00:27:13,679
science

788
00:27:11,679 --> 00:27:15,440
to doing these calculations and of

789
00:27:13,679 --> 00:27:17,840
course not all data sets are created

790
00:27:15,440 --> 00:27:17,840
equal

791
00:27:18,720 --> 00:27:22,960
the other challenge that we have here is

792
00:27:20,799 --> 00:27:23,360
um the average job tenure in australia

793
00:27:22,960 --> 00:27:26,320
is

794
00:27:23,360 --> 00:27:28,719
three years and four months um whereas

795
00:27:26,320 --> 00:27:31,760
the average data retention obligation is

796
00:27:28,720 --> 00:27:32,640
uh as says on the slide uh lol good luck

797
00:27:31,760 --> 00:27:35,840
have fun

798
00:27:32,640 --> 00:27:37,360
um it's it's complicated uh the data

799
00:27:35,840 --> 00:27:39,918
retention obligation is

800
00:27:37,360 --> 00:27:40,719
ranges from seven years for company

801
00:27:39,919 --> 00:27:43,760
records

802
00:27:40,720 --> 00:27:45,039
to seven years fair work five or seven

803
00:27:43,760 --> 00:27:47,520
years under the ato

804
00:27:45,039 --> 00:27:48,240
two years for telco data no longer than

805
00:27:47,520 --> 00:27:51,760
necessary

806
00:27:48,240 --> 00:27:53,760
on gdpr six years for hipaa

807
00:27:51,760 --> 00:27:55,360
uh indefinitely for certain financial

808
00:27:53,760 --> 00:27:57,120
transactions

809
00:27:55,360 --> 00:27:59,279
five years for credit reporting two

810
00:27:57,120 --> 00:28:02,320
years under the national credit code

811
00:27:59,279 --> 00:28:05,919
the lifetime of the security under ppsr

812
00:28:02,320 --> 00:28:07,600
and three months for lottery's data

813
00:28:05,919 --> 00:28:09,200
and then the start of that varies from

814
00:28:07,600 --> 00:28:11,199
the creation of a record

815
00:28:09,200 --> 00:28:12,640
to the end of a transaction to the end

816
00:28:11,200 --> 00:28:13,919
of a financial year in which a

817
00:28:12,640 --> 00:28:16,559
transaction happened

818
00:28:13,919 --> 00:28:18,320
and so on and so the point being that

819
00:28:16,559 --> 00:28:19,760
there really is no average data

820
00:28:18,320 --> 00:28:21,840
attention obligation

821
00:28:19,760 --> 00:28:24,080
and identifying what those obligations

822
00:28:21,840 --> 00:28:25,678
are is actually really really hard

823
00:28:24,080 --> 00:28:28,080
and so you've got this situation where

824
00:28:25,679 --> 00:28:30,080
you've got staff who are

825
00:28:28,080 --> 00:28:31,199
on average turning over every three in a

826
00:28:30,080 --> 00:28:33,120
bit years

827
00:28:31,200 --> 00:28:34,320
and data retention obligations that

828
00:28:33,120 --> 00:28:36,879
often run for

829
00:28:34,320 --> 00:28:37,918
five six or seven years which again

830
00:28:36,880 --> 00:28:39,919
means that

831
00:28:37,919 --> 00:28:41,279
the person who is having to decide to

832
00:28:39,919 --> 00:28:43,200
delete data

833
00:28:41,279 --> 00:28:44,799
wasn't there at the time the data or the

834
00:28:43,200 --> 00:28:46,559
system was created so they don't

835
00:28:44,799 --> 00:28:47,918
actually understand the context around

836
00:28:46,559 --> 00:28:50,080
it

837
00:28:47,919 --> 00:28:52,080
which really necessitates that whenever

838
00:28:50,080 --> 00:28:53,840
a new system is built whenever a new

839
00:28:52,080 --> 00:28:55,918
data set is created

840
00:28:53,840 --> 00:28:57,039
whoever is building it or designing it

841
00:28:55,919 --> 00:28:59,200
at the time

842
00:28:57,039 --> 00:29:00,320
really has to build in with crystal

843
00:28:59,200 --> 00:29:02,960
clarity

844
00:29:00,320 --> 00:29:04,320
when data can be and should be deleted

845
00:29:02,960 --> 00:29:05,760
because they're the person who are

846
00:29:04,320 --> 00:29:08,960
actually in the best position

847
00:29:05,760 --> 00:29:08,960
to have that information

848
00:29:09,039 --> 00:29:12,799
now when we're looking at the data being

849
00:29:11,440 --> 00:29:14,080
stolen there are a number of different

850
00:29:12,799 --> 00:29:16,158
types that get stolen

851
00:29:14,080 --> 00:29:17,678
and i'll i'll skip through this because

852
00:29:16,159 --> 00:29:18,880
you know this is uh is reasonably

853
00:29:17,679 --> 00:29:22,000
straightforward

854
00:29:18,880 --> 00:29:23,840
um i'm sure everyone here has seen some

855
00:29:22,000 --> 00:29:25,679
of this data before so

856
00:29:23,840 --> 00:29:27,918
there's a lot of information about you

857
00:29:25,679 --> 00:29:31,520
know the value of records on the

858
00:29:27,919 --> 00:29:33,200
on the dark web now my my recommendation

859
00:29:31,520 --> 00:29:34,879
is always to take some of this data with

860
00:29:33,200 --> 00:29:36,720
a grain of salt because

861
00:29:34,880 --> 00:29:39,120
you know the reality is this isn't a

862
00:29:36,720 --> 00:29:40,720
hugely transparent market

863
00:29:39,120 --> 00:29:42,239
and although you can see what people are

864
00:29:40,720 --> 00:29:44,320
asking for stolen data

865
00:29:42,240 --> 00:29:45,760
you can't necessarily you know verify

866
00:29:44,320 --> 00:29:47,760
that that's actually the amount that

867
00:29:45,760 --> 00:29:49,679
people are paying

868
00:29:47,760 --> 00:29:51,520
you know things like patient records are

869
00:29:49,679 --> 00:29:53,200
really going to vary in value based on

870
00:29:51,520 --> 00:29:55,360
who the person is

871
00:29:53,200 --> 00:29:56,799
even things like social media accounts

872
00:29:55,360 --> 00:29:58,639
you know a hacked twitter account the

873
00:29:56,799 --> 00:30:00,799
hacked twitter account of elon musk is

874
00:29:58,640 --> 00:30:02,480
probably worth more than 49

875
00:30:00,799 --> 00:30:05,679
the hacked twitter account of your

876
00:30:02,480 --> 00:30:07,679
little sister is probably not worth 49.

877
00:30:05,679 --> 00:30:09,039
you know so these these numbers really

878
00:30:07,679 --> 00:30:10,080
you know should be taken with a grain of

879
00:30:09,039 --> 00:30:13,120
salt but

880
00:30:10,080 --> 00:30:15,279
the key point is that there is a value

881
00:30:13,120 --> 00:30:16,959
now whether that value is one dollar or

882
00:30:15,279 --> 00:30:17,760
fifteen dollars or a thousand dollars

883
00:30:16,960 --> 00:30:20,240
obviously has an

884
00:30:17,760 --> 00:30:21,679
impact but if we accept as a starting

885
00:30:20,240 --> 00:30:23,120
point that there's a value

886
00:30:21,679 --> 00:30:24,720
then it leads into some really

887
00:30:23,120 --> 00:30:28,719
interesting questions

888
00:30:24,720 --> 00:30:30,799
and the main one is this which is

889
00:30:28,720 --> 00:30:33,679
if you have a certain number of records

890
00:30:30,799 --> 00:30:36,240
files data points within an organization

891
00:30:33,679 --> 00:30:37,679
then you in theory can sum that all up

892
00:30:36,240 --> 00:30:39,200
and come up with the amount of value

893
00:30:37,679 --> 00:30:41,440
that you're protecting

894
00:30:39,200 --> 00:30:42,720
um and if the value of those records is

895
00:30:41,440 --> 00:30:46,159
greater than the cost

896
00:30:42,720 --> 00:30:47,760
of compromising those records then bad

897
00:30:46,159 --> 00:30:50,320
things are likely to happen

898
00:30:47,760 --> 00:30:52,080
and so what what that breaks down to is

899
00:30:50,320 --> 00:30:54,559
you know it's it's the simple

900
00:30:52,080 --> 00:30:56,240
if you have a a million dollars in cash

901
00:30:54,559 --> 00:30:58,960
and the cost of

902
00:30:56,240 --> 00:30:59,360
stealing that cash is a thousand dollars

903
00:30:58,960 --> 00:31:01,840
then

904
00:30:59,360 --> 00:31:03,199
you're probably going to have a bad time

905
00:31:01,840 --> 00:31:05,918
and in many ways looking

906
00:31:03,200 --> 00:31:08,559
at data protection in a same way and

907
00:31:05,919 --> 00:31:11,039
figuring out the value of those records

908
00:31:08,559 --> 00:31:13,039
to an attacker is actually an

909
00:31:11,039 --> 00:31:15,039
interesting way of considering

910
00:31:13,039 --> 00:31:17,120
how you can then balance out that cost

911
00:31:15,039 --> 00:31:18,480
of compromise

912
00:31:17,120 --> 00:31:20,399
now one of the challenges or one of the

913
00:31:18,480 --> 00:31:23,200
interesting pieces here is how do you

914
00:31:20,399 --> 00:31:24,719
calculate that cost of compromise so one

915
00:31:23,200 --> 00:31:26,159
of our clients has a

916
00:31:24,720 --> 00:31:28,559
really really good approach to this

917
00:31:26,159 --> 00:31:29,760
which is they actually use a bug bounty

918
00:31:28,559 --> 00:31:33,360
program

919
00:31:29,760 --> 00:31:35,039
and they use basically the cost of a

920
00:31:33,360 --> 00:31:36,639
we'll call it a sort of severity one or

921
00:31:35,039 --> 00:31:39,279
a high high impact

922
00:31:36,640 --> 00:31:41,039
compromise as the indicator of what the

923
00:31:39,279 --> 00:31:42,559
cost of compromise is

924
00:31:41,039 --> 00:31:44,480
and what you actually want is you

925
00:31:42,559 --> 00:31:45,678
actually want the cost of that to go up

926
00:31:44,480 --> 00:31:47,360
over time

927
00:31:45,679 --> 00:31:48,720
and so even though that's a cost that

928
00:31:47,360 --> 00:31:50,479
you're paying

929
00:31:48,720 --> 00:31:51,919
what you're effectively doing is trying

930
00:31:50,480 --> 00:31:54,559
to manage that cost

931
00:31:51,919 --> 00:31:56,000
so that you get a consistent number of

932
00:31:54,559 --> 00:31:58,480
compromises

933
00:31:56,000 --> 00:32:00,159
so for example you want to say our aim

934
00:31:58,480 --> 00:32:04,159
is to have

935
00:32:00,159 --> 00:32:07,600
one high-end compromise vector

936
00:32:04,159 --> 00:32:09,039
identified every year or every six

937
00:32:07,600 --> 00:32:11,120
months

938
00:32:09,039 --> 00:32:12,799
and so if you start out you say we'll

939
00:32:11,120 --> 00:32:14,399
pay a thousand dollars for someone to

940
00:32:12,799 --> 00:32:16,720
give us that vector and you get

941
00:32:14,399 --> 00:32:18,239
10 of them then it tells you you've got

942
00:32:16,720 --> 00:32:20,559
a lot of problems

943
00:32:18,240 --> 00:32:22,399
once those problems are fixed and you

944
00:32:20,559 --> 00:32:24,240
don't get any more notifications at a

945
00:32:22,399 --> 00:32:27,360
thousand dollars it's effectively saying

946
00:32:24,240 --> 00:32:29,360
that it's not worth someone's time

947
00:32:27,360 --> 00:32:30,559
to identify that compromise because it's

948
00:32:29,360 --> 00:32:32,799
going to take longer than that it's

949
00:32:30,559 --> 00:32:34,480
going to be more complicated

950
00:32:32,799 --> 00:32:36,720
so you increase it to ten thousand

951
00:32:34,480 --> 00:32:38,159
dollars now at ten thousand dollars a

952
00:32:36,720 --> 00:32:39,679
whole group of people

953
00:32:38,159 --> 00:32:41,600
are willing to spend more time on

954
00:32:39,679 --> 00:32:42,880
identifying those compromises than they

955
00:32:41,600 --> 00:32:44,799
were before

956
00:32:42,880 --> 00:32:46,640
and so they're now going to come back in

957
00:32:44,799 --> 00:32:48,000
and conduct the assessments

958
00:32:46,640 --> 00:32:50,559
and so maybe you start getting them

959
00:32:48,000 --> 00:32:52,080
again and then after a while

960
00:32:50,559 --> 00:32:54,080
all of those ones have gone and they're

961
00:32:52,080 --> 00:32:55,678
not there anymore so now you make it

962
00:32:54,080 --> 00:32:57,760
fifty thousand dollars

963
00:32:55,679 --> 00:32:59,120
and so what you can actually do is use

964
00:32:57,760 --> 00:33:02,000
that value

965
00:32:59,120 --> 00:33:02,959
of how much it costs you to get a

966
00:33:02,000 --> 00:33:05,519
high-end

967
00:33:02,960 --> 00:33:07,279
you know tier one compromise of a system

968
00:33:05,519 --> 00:33:09,519
or your organization

969
00:33:07,279 --> 00:33:11,600
through a bug bounty program as a

970
00:33:09,519 --> 00:33:13,519
mechanism to actually demonstrate

971
00:33:11,600 --> 00:33:15,199
what the cost of compromise of your

972
00:33:13,519 --> 00:33:17,279
organization is

973
00:33:15,200 --> 00:33:18,559
so then you can basically look at what

974
00:33:17,279 --> 00:33:20,320
that looks like

975
00:33:18,559 --> 00:33:22,080
versus the value of the records that

976
00:33:20,320 --> 00:33:24,158
you're holding and you can actually

977
00:33:22,080 --> 00:33:25,760
start to do these calculations

978
00:33:24,159 --> 00:33:27,919
which means you can actually then start

979
00:33:25,760 --> 00:33:30,000
to identify um whether you have a

980
00:33:27,919 --> 00:33:31,440
problem

981
00:33:30,000 --> 00:33:33,200
so it's again this concept that

982
00:33:31,440 --> 00:33:33,760
basically every day you're pretty much

983
00:33:33,200 --> 00:33:36,880
in an

984
00:33:33,760 --> 00:33:39,279
in an auction for your data um you know

985
00:33:36,880 --> 00:33:41,760
so we when we say that it's unrealistic

986
00:33:39,279 --> 00:33:43,279
to stop a nation state from getting in

987
00:33:41,760 --> 00:33:45,760
what we're effectively saying is they

988
00:33:43,279 --> 00:33:48,720
have abundant resources and you don't

989
00:33:45,760 --> 00:33:49,600
uh and so conceptually if we accept the

990
00:33:48,720 --> 00:33:51,919
fact

991
00:33:49,600 --> 00:33:54,158
that there is a level of investment that

992
00:33:51,919 --> 00:33:56,080
if made will defeat your controls

993
00:33:54,159 --> 00:33:58,720
then the question we ultimately need to

994
00:33:56,080 --> 00:34:00,399
ask is is that level of investment at a

995
00:33:58,720 --> 00:34:01,840
level that's high enough that it stops a

996
00:34:00,399 --> 00:34:03,039
breach

997
00:34:01,840 --> 00:34:05,279
and there are two ways that we can

998
00:34:03,039 --> 00:34:07,279
address that

999
00:34:05,279 --> 00:34:08,639
the first is that we can raise the cost

1000
00:34:07,279 --> 00:34:10,560
of a successful breach

1001
00:34:08,639 --> 00:34:12,879
and the second is that we can reduce the

1002
00:34:10,560 --> 00:34:14,719
value of a successful breach

1003
00:34:12,879 --> 00:34:17,359
now as an industry we've spent most of

1004
00:34:14,719 --> 00:34:19,520
our time on the left hand side of this

1005
00:34:17,359 --> 00:34:20,560
this is putting in place controls it's

1006
00:34:19,520 --> 00:34:23,040
introducing

1007
00:34:20,560 --> 00:34:25,040
new controls it's tightening things it's

1008
00:34:23,040 --> 00:34:26,399
trying to make it more expensive

1009
00:34:25,040 --> 00:34:28,239
for someone to compromise the

1010
00:34:26,399 --> 00:34:30,239
organization

1011
00:34:28,239 --> 00:34:31,598
we haven't spent nearly as much time on

1012
00:34:30,239 --> 00:34:33,199
the right hand side

1013
00:34:31,599 --> 00:34:34,639
which is reducing the value of a

1014
00:34:33,199 --> 00:34:36,399
successful breach

1015
00:34:34,639 --> 00:34:38,079
now there are some cases where we have

1016
00:34:36,399 --> 00:34:38,960
done that and it's been wildly

1017
00:34:38,079 --> 00:34:41,440
successful

1018
00:34:38,960 --> 00:34:42,159
and pci dss is really the playbook for

1019
00:34:41,440 --> 00:34:44,159
this

1020
00:34:42,159 --> 00:34:46,879
which is the whole model started being

1021
00:34:44,159 --> 00:34:49,520
to increase the costs around compliance

1022
00:34:46,879 --> 00:34:50,799
to incentivize people to use things like

1023
00:34:49,520 --> 00:34:53,679
tokenization

1024
00:34:50,800 --> 00:34:55,919
to stop storing credit card data so that

1025
00:34:53,679 --> 00:34:58,320
it reduces the value of a breach

1026
00:34:55,918 --> 00:35:00,078
against that organization if you don't

1027
00:34:58,320 --> 00:35:01,680
hold the credit card data obviously you

1028
00:35:00,079 --> 00:35:03,359
then can't lose it

1029
00:35:01,680 --> 00:35:05,759
and so as an industry we've focused a

1030
00:35:03,359 --> 00:35:06,240
lot on raising the cost but we haven't

1031
00:35:05,760 --> 00:35:09,200
focused

1032
00:35:06,240 --> 00:35:11,439
nearly as much on reducing the value and

1033
00:35:09,200 --> 00:35:13,598
so really my argument is that

1034
00:35:11,440 --> 00:35:15,440
this utopian cyber security project

1035
00:35:13,599 --> 00:35:18,800
really does exist

1036
00:35:15,440 --> 00:35:20,400
and it is as simple as deleting

1037
00:35:18,800 --> 00:35:21,920
vast amounts of data from our

1038
00:35:20,400 --> 00:35:24,640
organizations

1039
00:35:21,920 --> 00:35:26,240
it costs very little it will save you

1040
00:35:24,640 --> 00:35:29,118
significant amount of money

1041
00:35:26,240 --> 00:35:30,479
even just from a storage perspective

1042
00:35:29,119 --> 00:35:32,240
particularly if you also get to

1043
00:35:30,480 --> 00:35:33,760
decommission some systems

1044
00:35:32,240 --> 00:35:35,759
and it does improve your security

1045
00:35:33,760 --> 00:35:37,119
posture

1046
00:35:35,760 --> 00:35:38,400
so in terms of what we're really

1047
00:35:37,119 --> 00:35:39,760
recommending there are sort of three

1048
00:35:38,400 --> 00:35:42,320
main groups here

1049
00:35:39,760 --> 00:35:44,560
the first is establishing this concept

1050
00:35:42,320 --> 00:35:46,960
of a sensitive data environment so

1051
00:35:44,560 --> 00:35:48,720
in the same way again taking the pci dss

1052
00:35:46,960 --> 00:35:49,680
playbook they have a cardholder data

1053
00:35:48,720 --> 00:35:51,359
environment

1054
00:35:49,680 --> 00:35:53,040
the sensitive data environment is a

1055
00:35:51,359 --> 00:35:55,040
similar thing it's about

1056
00:35:53,040 --> 00:35:56,960
trying to keep all of the sensitive data

1057
00:35:55,040 --> 00:35:58,880
in the same place

1058
00:35:56,960 --> 00:36:01,040
it's important to build out a really

1059
00:35:58,880 --> 00:36:04,000
clear data deletion policy and capture

1060
00:36:01,040 --> 00:36:05,680
that at the creation of systems and data

1061
00:36:04,000 --> 00:36:07,760
because of that issue around staff

1062
00:36:05,680 --> 00:36:09,759
retention over time

1063
00:36:07,760 --> 00:36:11,760
but mostly the main thing is is really

1064
00:36:09,760 --> 00:36:13,839
to make this someone's job

1065
00:36:11,760 --> 00:36:16,160
for a while we had this concept of a

1066
00:36:13,839 --> 00:36:18,400
wiki gardener or a data gardener whose

1067
00:36:16,160 --> 00:36:19,759
job was basically to tidy up wikis and

1068
00:36:18,400 --> 00:36:22,720
delete data and

1069
00:36:19,760 --> 00:36:25,280
improve things it's really worthwhile to

1070
00:36:22,720 --> 00:36:26,720
have a role like that

1071
00:36:25,280 --> 00:36:29,280
if you're running threat hunts at the

1072
00:36:26,720 --> 00:36:31,759
moment consider running data hunts

1073
00:36:29,280 --> 00:36:33,440
so try to find sensitive data in places

1074
00:36:31,760 --> 00:36:34,960
that it shouldn't be

1075
00:36:33,440 --> 00:36:37,359
there are obviously all the tools that

1076
00:36:34,960 --> 00:36:39,680
have been built for pci dss that can do

1077
00:36:37,359 --> 00:36:42,720
this really really effectively

1078
00:36:39,680 --> 00:36:44,399
or at least allocate this to someone as

1079
00:36:42,720 --> 00:36:46,399
a responsibility in the same way that

1080
00:36:44,400 --> 00:36:47,280
you do with fire wardens and work health

1081
00:36:46,400 --> 00:36:49,040
and safety

1082
00:36:47,280 --> 00:36:51,760
so have someone who is actually

1083
00:36:49,040 --> 00:36:54,079
responsible for trying to minimize

1084
00:36:51,760 --> 00:36:55,839
the amount of data sprawl and sensitive

1085
00:36:54,079 --> 00:36:56,240
data being stored where it shouldn't and

1086
00:36:55,839 --> 00:36:59,359
who's

1087
00:36:56,240 --> 00:37:01,839
actively trying to solve that problem

1088
00:36:59,359 --> 00:37:03,040
and then lastly build it into a security

1089
00:37:01,839 --> 00:37:04,960
awareness program

1090
00:37:03,040 --> 00:37:07,040
so have this concept of an amnesty to

1091
00:37:04,960 --> 00:37:09,200
hand back rogue data

1092
00:37:07,040 --> 00:37:11,040
reward people for basically deleting

1093
00:37:09,200 --> 00:37:12,720
files cleaning their room getting rid of

1094
00:37:11,040 --> 00:37:15,119
sensitive information

1095
00:37:12,720 --> 00:37:17,598
and so if we actually start focusing on

1096
00:37:15,119 --> 00:37:19,599
how we can help organizations to

1097
00:37:17,599 --> 00:37:21,520
clean up a lot of this information

1098
00:37:19,599 --> 00:37:23,440
reduce the leaf litter

1099
00:37:21,520 --> 00:37:25,200
do some back burning i think we'll

1100
00:37:23,440 --> 00:37:26,640
actually be in a much better position

1101
00:37:25,200 --> 00:37:28,720
and we'll end up with a situation where

1102
00:37:26,640 --> 00:37:31,920
the only data breaches that we see

1103
00:37:28,720 --> 00:37:33,759
are data breaches of our core systems

1104
00:37:31,920 --> 00:37:35,599
that in theory should already be the

1105
00:37:33,760 --> 00:37:37,200
area where we're investing the most from

1106
00:37:35,599 --> 00:37:39,760
a security perspective

1107
00:37:37,200 --> 00:37:41,759
which again is then raising that cost of

1108
00:37:39,760 --> 00:37:44,240
a breach for the attacker

1109
00:37:41,760 --> 00:37:45,280
so hopefully that's been a helpful uh

1110
00:37:44,240 --> 00:37:47,759
sort of view on the

1111
00:37:45,280 --> 00:37:50,240
on the issue and the problem i'm happy

1112
00:37:47,760 --> 00:37:53,680
to uh happy to take any any questions

1113
00:37:50,240 --> 00:37:54,959
now i think we might not have any time

1114
00:37:53,680 --> 00:37:56,319
it doesn't appear there's any questions

1115
00:37:54,960 --> 00:37:58,640
we might be just running a little bit

1116
00:37:56,320 --> 00:38:01,680
short of time um

1117
00:37:58,640 --> 00:38:02,240
nick so we might uh if um thank you very

1118
00:38:01,680 --> 00:38:04,960
much

1119
00:38:02,240 --> 00:38:06,560
uh nick for your awesome presentation um

1120
00:38:04,960 --> 00:38:07,200
we might just um have a little bit of a

1121
00:38:06,560 --> 00:38:10,400
pause

1122
00:38:07,200 --> 00:38:13,040
between the next presentation and um

1123
00:38:10,400 --> 00:38:15,040
uh which will be kashal shah with uh

1124
00:38:13,040 --> 00:38:17,119
software zero day discovery

1125
00:38:15,040 --> 00:38:18,240
we'll be back shortly uh everyone thank

1126
00:38:17,119 --> 00:38:20,000
you lovely

1127
00:38:18,240 --> 00:38:21,439
thanks guys sorry around a bit long no

1128
00:38:20,000 --> 00:38:23,920
no nick you're perfect thank you very

1129
00:38:21,440 --> 00:38:23,920
much nick

1130
00:38:26,040 --> 00:38:29,040
thanks

