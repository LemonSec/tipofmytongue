1
00:00:02,320 --> 00:00:05,920
good

2
00:00:03,120 --> 00:00:07,359
morning everyone hope everyone had a

3
00:00:05,920 --> 00:00:10,320
great night last night

4
00:00:07,359 --> 00:00:11,759
um that show was absolutely amazing i

5
00:00:10,320 --> 00:00:14,960
really really enjoyed it

6
00:00:11,759 --> 00:00:16,880
um so a few little housekeeping

7
00:00:14,960 --> 00:00:18,560
things we'll kind of get through as well

8
00:00:16,880 --> 00:00:19,840
so we on the right hand side for those

9
00:00:18,560 --> 00:00:21,759
that are not familiar with the platform

10
00:00:19,840 --> 00:00:24,320
we have a little chat window there

11
00:00:21,760 --> 00:00:25,439
and q a window as well so if you do have

12
00:00:24,320 --> 00:00:27,920
questions

13
00:00:25,439 --> 00:00:30,080
for any of our speakers today you can

14
00:00:27,920 --> 00:00:33,360
just ask them within that platform

15
00:00:30,080 --> 00:00:36,559
and you can also move around after

16
00:00:33,360 --> 00:00:39,280
the the presentations and we'll be

17
00:00:36,559 --> 00:00:40,559
sharing a link in that chat window so to

18
00:00:39,280 --> 00:00:43,840
take you out of the

19
00:00:40,559 --> 00:00:44,480
out of the um the room now our next

20
00:00:43,840 --> 00:00:46,879
speaker

21
00:00:44,480 --> 00:00:47,680
i was just chatting to before so he

22
00:00:46,879 --> 00:00:50,559
comes

23
00:00:47,680 --> 00:00:51,199
from all the way from chicago in the u.s

24
00:00:50,559 --> 00:00:53,360
and

25
00:00:51,199 --> 00:00:54,800
we are very fortunate and he's very

26
00:00:53,360 --> 00:00:57,280
fortunate that's

27
00:00:54,800 --> 00:00:58,718
normal time you know or reasonable time

28
00:00:57,280 --> 00:01:00,960
for him so it's only you know in the

29
00:00:58,719 --> 00:01:02,640
afternoon or late afternoon for him so

30
00:01:00,960 --> 00:01:04,239
it's not three in the morning which is

31
00:01:02,640 --> 00:01:05,920
quite quite lovely

32
00:01:04,239 --> 00:01:07,920
um so we have john bambernek who's going

33
00:01:05,920 --> 00:01:11,119
to be presenting so he's the president

34
00:01:07,920 --> 00:01:13,360
of bambinect consulting he's also a phd

35
00:01:11,119 --> 00:01:14,880
student at the university of illinois

36
00:01:13,360 --> 00:01:18,080
and also a handler

37
00:01:14,880 --> 00:01:19,920
with the sans internet storm center and

38
00:01:18,080 --> 00:01:22,158
i would say is probably a very very busy

39
00:01:19,920 --> 00:01:23,680
person with a lot of spare time

40
00:01:22,159 --> 00:01:25,759
he has over 20 years experience in

41
00:01:23,680 --> 00:01:26,400
information security and lead several

42
00:01:25,759 --> 00:01:28,400
international

43
00:01:26,400 --> 00:01:29,920
international investigative efforts

44
00:01:28,400 --> 00:01:32,000
tracking cyber criminals

45
00:01:29,920 --> 00:01:34,159
some of which have led to some very high

46
00:01:32,000 --> 00:01:35,680
profile arrests and illegal action which

47
00:01:34,159 --> 00:01:38,400
is a very positive thing to

48
00:01:35,680 --> 00:01:40,079
see he currently tracks neo-nazi

49
00:01:38,400 --> 00:01:42,560
fundraising via cryptocurrency

50
00:01:40,079 --> 00:01:44,399
and publishes that online to twitter and

51
00:01:42,560 --> 00:01:46,159
has other monitoring solutions for

52
00:01:44,399 --> 00:01:47,920
cryptocurrency activity

53
00:01:46,159 --> 00:01:49,840
so first and foremost thank you very

54
00:01:47,920 --> 00:01:52,079
much john for being

55
00:01:49,840 --> 00:01:53,200
one of our heroes of the internet so

56
00:01:52,079 --> 00:01:55,520
he's going to be talking

57
00:01:53,200 --> 00:01:56,399
around adversarial machine learning and

58
00:01:55,520 --> 00:01:59,520
its impacts

59
00:01:56,399 --> 00:02:00,159
on uh cyber security so without further

60
00:01:59,520 --> 00:02:04,798
ado

61
00:02:00,159 --> 00:02:07,439
thank you very much john thank you i'll

62
00:02:04,799 --> 00:02:09,520
share my screen here really quick all

63
00:02:07,439 --> 00:02:11,359
right well

64
00:02:09,520 --> 00:02:13,840
it's going to be a little meta here for

65
00:02:11,360 --> 00:02:19,280
a second so i can find where my

66
00:02:13,840 --> 00:02:19,280
powerpoint there we go

67
00:02:20,160 --> 00:02:25,120
all right um so today uh this evening

68
00:02:23,520 --> 00:02:27,120
for me but today for you i'm going to

69
00:02:25,120 --> 00:02:29,280
talk about adversarial machine learning

70
00:02:27,120 --> 00:02:30,319
uh i already went over my bio a little

71
00:02:29,280 --> 00:02:33,599
bit uh but

72
00:02:30,319 --> 00:02:36,879
uh um i've recently uh

73
00:02:33,599 --> 00:02:39,440
gone back to my phd in machine learning

74
00:02:36,879 --> 00:02:41,040
and what i call multi uh domain cyber

75
00:02:39,440 --> 00:02:43,040
security machine learning so using the

76
00:02:41,040 --> 00:02:45,519
context of

77
00:02:43,040 --> 00:02:46,079
activity as it relates to each other to

78
00:02:45,519 --> 00:02:48,800
come to

79
00:02:46,080 --> 00:02:50,640
some better uh decision making in some

80
00:02:48,800 --> 00:02:52,720
of the machine learning models that we

81
00:02:50,640 --> 00:02:53,440
have and there's aspects of that that'll

82
00:02:52,720 --> 00:02:56,319
talk about this

83
00:02:53,440 --> 00:02:58,000
specifically how the criminals try to

84
00:02:56,319 --> 00:03:00,799
abuse machine learning

85
00:02:58,000 --> 00:03:03,680
to obviously create bad classifications

86
00:03:00,800 --> 00:03:05,360
and bad outcomes

87
00:03:03,680 --> 00:03:06,800
so generally the state of the problem in

88
00:03:05,360 --> 00:03:07,680
cyber security right this is a

89
00:03:06,800 --> 00:03:10,560
tongue-in-cheek

90
00:03:07,680 --> 00:03:11,760
uh onion article uh which is a parody

91
00:03:10,560 --> 00:03:13,040
news site

92
00:03:11,760 --> 00:03:14,959
i don't know how many of you familiar

93
00:03:13,040 --> 00:03:16,000
with uh from five years ago but it still

94
00:03:14,959 --> 00:03:19,040
holds true

95
00:03:16,000 --> 00:03:22,480
the the vulnerable attack surface

96
00:03:19,040 --> 00:03:24,720
uh of of of many of our countries

97
00:03:22,480 --> 00:03:25,599
is so huge that even the criminals are

98
00:03:24,720 --> 00:03:28,640
having uh

99
00:03:25,599 --> 00:03:31,200
a hard time uh keeping up with it

100
00:03:28,640 --> 00:03:33,440
so we have a whole lot of problem and

101
00:03:31,200 --> 00:03:36,879
not enough people trying to solve it

102
00:03:33,440 --> 00:03:37,440
uh and one way that we try to with that

103
00:03:36,879 --> 00:03:40,798
that has been

104
00:03:37,440 --> 00:03:41,599
advertised to address the cyber security

105
00:03:40,799 --> 00:03:43,440
problem

106
00:03:41,599 --> 00:03:44,879
is to try to automate just security

107
00:03:43,440 --> 00:03:46,959
automation generally

108
00:03:44,879 --> 00:03:48,480
right if we can have computers automate

109
00:03:46,959 --> 00:03:50,480
uh so many tasks

110
00:03:48,480 --> 00:03:51,840
less people will be needed to secure

111
00:03:50,480 --> 00:03:55,280
things which

112
00:03:51,840 --> 00:03:55,840
sounds good uh with some caveats a part

113
00:03:55,280 --> 00:03:58,400
of that

114
00:03:55,840 --> 00:04:00,080
of course is is machine learning right

115
00:03:58,400 --> 00:04:01,040
machine learning is one form of

116
00:04:00,080 --> 00:04:02,720
automation

117
00:04:01,040 --> 00:04:04,879
uh and with as with everything of

118
00:04:02,720 --> 00:04:05,760
technology there's an xkcd that kind of

119
00:04:04,879 --> 00:04:08,079
makes fun of

120
00:04:05,760 --> 00:04:09,439
some fun of some things but there's an

121
00:04:08,080 --> 00:04:12,480
element of truth

122
00:04:09,439 --> 00:04:13,599
you know is a lot of machine learning is

123
00:04:12,480 --> 00:04:16,639
people taking

124
00:04:13,599 --> 00:04:18,478
data putting it into a pile running uh

125
00:04:16,639 --> 00:04:19,680
linear mathematical algorithms over

126
00:04:18,478 --> 00:04:21,680
there and seeing

127
00:04:19,680 --> 00:04:23,120
what comes out of it and and the

128
00:04:21,680 --> 00:04:25,120
clusters and they don't

129
00:04:23,120 --> 00:04:26,240
a lot of people don't spend any real

130
00:04:25,120 --> 00:04:28,240
time

131
00:04:26,240 --> 00:04:29,919
asking fundamental questions of where

132
00:04:28,240 --> 00:04:31,680
the data comes from

133
00:04:29,919 --> 00:04:33,840
you know what kind of classifications

134
00:04:31,680 --> 00:04:35,120
there are and what is outputted for the

135
00:04:33,840 --> 00:04:38,320
system

136
00:04:35,120 --> 00:04:40,479
a lot of machine learning research and

137
00:04:38,320 --> 00:04:42,000
discussion and tools focuses a lot about

138
00:04:40,479 --> 00:04:44,880
on the algorithms that do linear

139
00:04:42,000 --> 00:04:46,160
algebra and that's all very interesting

140
00:04:44,880 --> 00:04:47,440
and complicated if you're a

141
00:04:46,160 --> 00:04:49,759
mathematician

142
00:04:47,440 --> 00:04:52,400
but by and large the algorithms just

143
00:04:49,759 --> 00:04:55,199
work right you can trust the algorithm

144
00:04:52,400 --> 00:04:56,719
to do its job most much like anything

145
00:04:55,199 --> 00:04:58,800
you program a computer to do

146
00:04:56,720 --> 00:05:00,800
right it will do exactly what you tell

147
00:04:58,800 --> 00:05:02,720
it to do the problem is if you put

148
00:05:00,800 --> 00:05:04,639
garbage in you get garbage out

149
00:05:02,720 --> 00:05:05,919
and we're going to talk about one aspect

150
00:05:04,639 --> 00:05:08,800
of that is is

151
00:05:05,919 --> 00:05:11,280
is adversarial behavior so there's a

152
00:05:08,800 --> 00:05:13,199
handful of machine learning use cases

153
00:05:11,280 --> 00:05:15,198
uh people are doing it for ad tracking

154
00:05:13,199 --> 00:05:17,759
and related behaviors to

155
00:05:15,199 --> 00:05:20,000
uh find based on these attributes of

156
00:05:17,759 --> 00:05:22,639
what websites you go to and how you post

157
00:05:20,000 --> 00:05:24,800
on facebook and who you interact with on

158
00:05:22,639 --> 00:05:27,120
on twitter what kind of products should

159
00:05:24,800 --> 00:05:28,800
i advertise to you

160
00:05:27,120 --> 00:05:31,120
there's image classification object

161
00:05:28,800 --> 00:05:31,600
recognition right if i'm a self-driving

162
00:05:31,120 --> 00:05:33,759
car

163
00:05:31,600 --> 00:05:34,880
i need to know what's going on around me

164
00:05:33,759 --> 00:05:37,840
to

165
00:05:34,880 --> 00:05:38,800
avoid accidents or facial recognition

166
00:05:37,840 --> 00:05:41,520
systems that

167
00:05:38,800 --> 00:05:43,600
are not just used in social media but

168
00:05:41,520 --> 00:05:46,320
used by law enforcement which is

169
00:05:43,600 --> 00:05:48,080
its own human rights concern right and

170
00:05:46,320 --> 00:05:49,599
and quite frankly a lot of machine

171
00:05:48,080 --> 00:05:52,479
learning use cases

172
00:05:49,600 --> 00:05:54,400
are creating human rights issues in ways

173
00:05:52,479 --> 00:05:56,318
that aren't anticipated that many of us

174
00:05:54,400 --> 00:05:58,719
will have to start dealing with here

175
00:05:56,319 --> 00:06:00,880
uh in the near term uh but this this

176
00:05:58,720 --> 00:06:03,440
talk is specifically about cyber

177
00:06:00,880 --> 00:06:05,919
security machine learning there's also a

178
00:06:03,440 --> 00:06:08,880
conversation about machine the

179
00:06:05,919 --> 00:06:09,758
cyber security in machine learning uh

180
00:06:08,880 --> 00:06:12,159
that's its own

181
00:06:09,759 --> 00:06:14,000
topic that deals in with human rights uh

182
00:06:12,160 --> 00:06:15,520
there's natural language processing

183
00:06:14,000 --> 00:06:16,880
uh but specifically we're gonna talk

184
00:06:15,520 --> 00:06:18,479
about the last one of security

185
00:06:16,880 --> 00:06:19,759
automation right it could be something

186
00:06:18,479 --> 00:06:22,159
as rudimentary as

187
00:06:19,759 --> 00:06:23,039
is this file malware malicious is this

188
00:06:22,160 --> 00:06:26,880
domain

189
00:06:23,039 --> 00:06:28,479
uh uh bad is this set of network traffic

190
00:06:26,880 --> 00:06:31,440
uh something that should be blocked or

191
00:06:28,479 --> 00:06:34,800
interdicted uh how do i process

192
00:06:31,440 --> 00:06:36,479
uh you know a seem and data and all that

193
00:06:34,800 --> 00:06:38,240
data in a scene to

194
00:06:36,479 --> 00:06:41,520
bubble up to the surface of stuff that

195
00:06:38,240 --> 00:06:43,600
really needs to be responded to

196
00:06:41,520 --> 00:06:46,080
there's a handful of of products out

197
00:06:43,600 --> 00:06:49,599
there in the open source world

198
00:06:46,080 --> 00:06:50,960
um there is uh dga detection right

199
00:06:49,599 --> 00:06:53,280
there's lots of open source

200
00:06:50,960 --> 00:06:55,680
products and researches that will help

201
00:06:53,280 --> 00:06:57,440
you detect whether a given input domain

202
00:06:55,680 --> 00:06:59,360
is generated by a domain generation

203
00:06:57,440 --> 00:07:01,039
algorithm uh

204
00:06:59,360 --> 00:07:03,199
phishing right is something a phishing

205
00:07:01,039 --> 00:07:04,719
email or a phishing web page right

206
00:07:03,199 --> 00:07:06,479
some of that uses natural language

207
00:07:04,720 --> 00:07:09,199
processing some of that uses image

208
00:07:06,479 --> 00:07:10,719
recognition right is this paypal is this

209
00:07:09,199 --> 00:07:12,960
a paypal logo on this

210
00:07:10,720 --> 00:07:13,759
on this page that isn't on a paypal

211
00:07:12,960 --> 00:07:15,680
property

212
00:07:13,759 --> 00:07:17,599
uh and there's someone ran there are

213
00:07:15,680 --> 00:07:20,479
some commercial products that advertise

214
00:07:17,599 --> 00:07:21,120
machine learning functionality uh with

215
00:07:20,479 --> 00:07:24,240
endpoint

216
00:07:21,120 --> 00:07:26,639
uh products uh scene-based analysis

217
00:07:24,240 --> 00:07:28,840
and network traffic and attack service

218
00:07:26,639 --> 00:07:31,840
monitoring and threatened vulnerability

219
00:07:28,840 --> 00:07:33,280
analysis there's lots of ways that

220
00:07:31,840 --> 00:07:34,638
people are trying to deploy machine

221
00:07:33,280 --> 00:07:35,198
learning to figure out what really

222
00:07:34,639 --> 00:07:36,960
matters

223
00:07:35,199 --> 00:07:39,199
in terms of threats and um in the

224
00:07:36,960 --> 00:07:39,919
network um and those exist and are

225
00:07:39,199 --> 00:07:42,800
deployed

226
00:07:39,919 --> 00:07:44,400
today uh whether those technologies are

227
00:07:42,800 --> 00:07:47,039
all that they're

228
00:07:44,400 --> 00:07:49,039
made out to be is another question but

229
00:07:47,039 --> 00:07:50,639
why machine learning

230
00:07:49,039 --> 00:07:52,318
right i mean there's several several

231
00:07:50,639 --> 00:07:54,720
reasons right is um

232
00:07:52,319 --> 00:07:56,319
i don't know the technical breakdown but

233
00:07:54,720 --> 00:07:57,039
having been to an officer conference

234
00:07:56,319 --> 00:07:58,560
before

235
00:07:57,039 --> 00:08:00,800
uh i don't know you know there's there

236
00:07:58,560 --> 00:08:02,479
are reverse engineers at this conference

237
00:08:00,800 --> 00:08:03,440
who who handle malware they're sock

238
00:08:02,479 --> 00:08:05,440
analysts

239
00:08:03,440 --> 00:08:07,120
there are people who you know are doing

240
00:08:05,440 --> 00:08:08,000
compliance the wide gamut of cyber

241
00:08:07,120 --> 00:08:10,960
security and all

242
00:08:08,000 --> 00:08:12,879
all you all know that responding to an

243
00:08:10,960 --> 00:08:15,359
incident and recognizing an incident

244
00:08:12,879 --> 00:08:16,960
takes time and it takes analysis uh

245
00:08:15,360 --> 00:08:19,759
human beings make mistakes

246
00:08:16,960 --> 00:08:20,080
i mean phishing inherently is really you

247
00:08:19,759 --> 00:08:22,639
know

248
00:08:20,080 --> 00:08:23,199
at its core human beings making mistakes

249
00:08:22,639 --> 00:08:25,520
but even

250
00:08:23,199 --> 00:08:28,479
even us who have been in this industry

251
00:08:25,520 --> 00:08:30,639
for a long time have have made mistakes

252
00:08:28,479 --> 00:08:32,000
we don't pay attention to detail we miss

253
00:08:30,639 --> 00:08:33,839
important things

254
00:08:32,000 --> 00:08:35,360
uh some of those things that make it

255
00:08:33,839 --> 00:08:36,680
very easy to miss with

256
00:08:35,360 --> 00:08:39,039
with puny code and the

257
00:08:36,679 --> 00:08:41,760
internationalization of domain names

258
00:08:39,039 --> 00:08:43,799
right the letter o there's like 22

259
00:08:41,760 --> 00:08:45,040
versions of the letter o so when i type

260
00:08:43,799 --> 00:08:47,760
microsoft.com

261
00:08:45,040 --> 00:08:49,920
or when i see microsoft.com in a link is

262
00:08:47,760 --> 00:08:52,080
it really going to redmond washington

263
00:08:49,920 --> 00:08:54,319
or is that oh something different where

264
00:08:52,080 --> 00:08:55,920
it's efficient web pages and human

265
00:08:54,320 --> 00:08:58,560
beings are not consistent

266
00:08:55,920 --> 00:08:59,279
we get tired we have biases we make

267
00:08:58,560 --> 00:09:01,119
mistakes

268
00:08:59,279 --> 00:09:02,320
you know we could be operating under

269
00:09:01,120 --> 00:09:03,360
stress and having to make quick

270
00:09:02,320 --> 00:09:05,920
decisions

271
00:09:03,360 --> 00:09:06,720
computers you know do things quickly you

272
00:09:05,920 --> 00:09:08,160
know and

273
00:09:06,720 --> 00:09:10,399
they're not subject to the human

274
00:09:08,160 --> 00:09:12,079
stresses and psychological impacts that

275
00:09:10,399 --> 00:09:13,839
we are

276
00:09:12,080 --> 00:09:15,839
but does machine learning really fix

277
00:09:13,839 --> 00:09:19,680
this yeah i mean computers do

278
00:09:15,839 --> 00:09:21,920
things at scale very fast you know

279
00:09:19,680 --> 00:09:23,760
and machine learning can operate fast

280
00:09:21,920 --> 00:09:24,399
sometimes it's a little slower depending

281
00:09:23,760 --> 00:09:26,319
on

282
00:09:24,399 --> 00:09:29,440
how much uh how much you're trying to

283
00:09:26,320 --> 00:09:31,839
process but the cluster data

284
00:09:29,440 --> 00:09:33,279
but the fundamental problem of machine

285
00:09:31,839 --> 00:09:34,959
learning is not the math

286
00:09:33,279 --> 00:09:37,279
in fact the fundamental problem of any

287
00:09:34,959 --> 00:09:39,439
computer flaw is not the code

288
00:09:37,279 --> 00:09:41,040
it's the human being creating the system

289
00:09:39,440 --> 00:09:43,120
in the case of machine learning

290
00:09:41,040 --> 00:09:45,040
picking the features right of what

291
00:09:43,120 --> 00:09:46,880
attributes am i analyzing

292
00:09:45,040 --> 00:09:48,800
choosing the training data the training

293
00:09:46,880 --> 00:09:51,920
set of what data do i

294
00:09:48,800 --> 00:09:54,880
do i start with an analyzing you know

295
00:09:51,920 --> 00:09:55,519
how am i operating in what context am i

296
00:09:54,880 --> 00:09:57,279
operating

297
00:09:55,519 --> 00:09:58,800
in an internal system operating on a

298
00:09:57,279 --> 00:09:59,519
scene am i operating on the internet at

299
00:09:58,800 --> 00:10:01,120
large

300
00:09:59,519 --> 00:10:03,360
and there's a human being evaluating the

301
00:10:01,120 --> 00:10:05,519
results and these are where the errors

302
00:10:03,360 --> 00:10:07,440
come in despite a lot of the research

303
00:10:05,519 --> 00:10:09,920
being focused on the math

304
00:10:07,440 --> 00:10:10,959
uh by mathematicians which means you

305
00:10:09,920 --> 00:10:13,599
know there's lots

306
00:10:10,959 --> 00:10:16,239
of the problem space that's under

307
00:10:13,600 --> 00:10:18,880
analyzed and under considered from

308
00:10:16,240 --> 00:10:20,560
a risk a risk perspective that if you're

309
00:10:18,880 --> 00:10:22,640
deploying these things

310
00:10:20,560 --> 00:10:24,160
even outside the cyber security context

311
00:10:22,640 --> 00:10:27,199
if you're doing fraud detection

312
00:10:24,160 --> 00:10:27,680
right is are people really looking at

313
00:10:27,200 --> 00:10:30,720
all

314
00:10:27,680 --> 00:10:33,120
all of the human decisions in there to

315
00:10:30,720 --> 00:10:36,160
ensure that there's not errors

316
00:10:33,120 --> 00:10:37,200
right the the cynical answer to that is

317
00:10:36,160 --> 00:10:39,760
machine learning

318
00:10:37,200 --> 00:10:40,720
makes human mistakes at machine speed

319
00:10:39,760 --> 00:10:42,880
right because

320
00:10:40,720 --> 00:10:44,399
it's very easy to make mistakes and

321
00:10:42,880 --> 00:10:47,360
those above four

322
00:10:44,399 --> 00:10:49,519
in if those mistakes are not caught your

323
00:10:47,360 --> 00:10:50,079
that mistake is just being multiplied at

324
00:10:49,519 --> 00:10:52,560
scale

325
00:10:50,079 --> 00:10:55,279
of whatever the the context of that

326
00:10:52,560 --> 00:10:55,279
system in there

327
00:10:55,519 --> 00:10:58,959
so the domain of adversarial machine

328
00:10:57,839 --> 00:11:02,000
learning begins with

329
00:10:58,959 --> 00:11:05,279
with training data right it's if i

330
00:11:02,000 --> 00:11:07,040
can give inputs to this machine learning

331
00:11:05,279 --> 00:11:08,720
algorithm and ultimately i can right

332
00:11:07,040 --> 00:11:11,839
either in the training data

333
00:11:08,720 --> 00:11:14,560
uh or in its processing how can i

334
00:11:11,839 --> 00:11:17,839
manipulate that system to

335
00:11:14,560 --> 00:11:19,359
make incorrect decisions right up front

336
00:11:17,839 --> 00:11:21,519
right there's poisoning the trade and

337
00:11:19,360 --> 00:11:24,000
training data um

338
00:11:21,519 --> 00:11:26,000
you know but certainly just the data in

339
00:11:24,000 --> 00:11:29,040
general that it's processed on

340
00:11:26,000 --> 00:11:31,160
right and and this third point here

341
00:11:29,040 --> 00:11:32,560
seems subtle and self and kind of

342
00:11:31,160 --> 00:11:34,399
self-explanatory

343
00:11:32,560 --> 00:11:35,680
but it's really the most profound

344
00:11:34,399 --> 00:11:38,000
problem

345
00:11:35,680 --> 00:11:40,479
for machine learning generally your

346
00:11:38,000 --> 00:11:42,800
training data starts with benign things

347
00:11:40,480 --> 00:11:44,399
you know facebook has algorithms to say

348
00:11:42,800 --> 00:11:46,399
oh you like this artist

349
00:11:44,399 --> 00:11:47,839
and you're posting about this news and

350
00:11:46,399 --> 00:11:48,959
it can kind of figure out what you're

351
00:11:47,839 --> 00:11:52,480
interested in

352
00:11:48,959 --> 00:11:56,560
to basically sell targeted advertising

353
00:11:52,480 --> 00:11:58,000
uh access to advertisers okay but by and

354
00:11:56,560 --> 00:12:00,560
large

355
00:11:58,000 --> 00:12:01,920
all the data that's being analyzed is is

356
00:12:00,560 --> 00:12:04,959
generally benign

357
00:12:01,920 --> 00:12:06,479
right it's you know how impo most people

358
00:12:04,959 --> 00:12:08,800
are posting on facebook not to

359
00:12:06,480 --> 00:12:10,639
manipulate the algorithms

360
00:12:08,800 --> 00:12:12,560
people are doing image recognition based

361
00:12:10,639 --> 00:12:14,000
on google images they type in cap they

362
00:12:12,560 --> 00:12:14,959
select okay here are all the cat

363
00:12:14,000 --> 00:12:16,800
pictures

364
00:12:14,959 --> 00:12:18,239
um if you're doing natural language

365
00:12:16,800 --> 00:12:18,880
processing you're operating on

366
00:12:18,240 --> 00:12:21,680
literature

367
00:12:18,880 --> 00:12:24,079
or news articles right and and one

368
00:12:21,680 --> 00:12:25,760
particularly interesting thing is there

369
00:12:24,079 --> 00:12:26,959
are machine learning systems out there

370
00:12:25,760 --> 00:12:29,040
that are analyzing

371
00:12:26,959 --> 00:12:30,399
news news sites now particularly

372
00:12:29,040 --> 00:12:32,719
business news

373
00:12:30,399 --> 00:12:34,959
to do high frequency trading oh this

374
00:12:32,720 --> 00:12:38,160
news article or this social media post

375
00:12:34,959 --> 00:12:38,638
is good news for this company i should

376
00:12:38,160 --> 00:12:41,199
buy

377
00:12:38,639 --> 00:12:42,800
or it's bad news and i should sell or do

378
00:12:41,200 --> 00:12:44,480
options trading and the like

379
00:12:42,800 --> 00:12:47,120
uh you know we're deploying a lot of

380
00:12:44,480 --> 00:12:49,839
these things and when you train them

381
00:12:47,120 --> 00:12:50,839
and you starting with good data and

382
00:12:49,839 --> 00:12:54,560
that's fine

383
00:12:50,839 --> 00:12:56,480
right in cyber security what we have is

384
00:12:54,560 --> 00:12:58,079
malicious data we actually don't have a

385
00:12:56,480 --> 00:13:01,360
lot of good

386
00:12:58,079 --> 00:13:03,599
good data sets right so if you think

387
00:13:01,360 --> 00:13:05,839
about it you know i want to create

388
00:13:03,600 --> 00:13:07,120
a machine learning tool to determine if

389
00:13:05,839 --> 00:13:08,639
something's malware or not

390
00:13:07,120 --> 00:13:10,800
you've got lots of malware you can go to

391
00:13:08,639 --> 00:13:12,079
virustotal and get it how do you find

392
00:13:10,800 --> 00:13:13,839
benign

393
00:13:12,079 --> 00:13:16,160
executables well you can start with

394
00:13:13,839 --> 00:13:19,200
windows and maybe office

395
00:13:16,160 --> 00:13:21,279
and web browsers but

396
00:13:19,200 --> 00:13:23,200
going to all of the third-party tools

397
00:13:21,279 --> 00:13:25,519
even conventional ones is hard

398
00:13:23,200 --> 00:13:26,880
and i'm sure many of you have ever been

399
00:13:25,519 --> 00:13:29,040
responsible for

400
00:13:26,880 --> 00:13:31,519
antivirus systems in an enterprise know

401
00:13:29,040 --> 00:13:34,639
that i don't know once a year or so

402
00:13:31,519 --> 00:13:38,079
a major antivirus product detects

403
00:13:34,639 --> 00:13:40,320
you know some major dll or executable

404
00:13:38,079 --> 00:13:42,319
like word as malicious

405
00:13:40,320 --> 00:13:43,600
major antivirus companies get it wrong

406
00:13:42,320 --> 00:13:45,279
every now and then

407
00:13:43,600 --> 00:13:47,120
you've got malicious network traffic

408
00:13:45,279 --> 00:13:49,839
you've got phishing emails

409
00:13:47,120 --> 00:13:51,199
all of this is created by the adversary

410
00:13:49,839 --> 00:13:53,279
who has

411
00:13:51,199 --> 00:13:54,880
decades of experience tricking our

412
00:13:53,279 --> 00:13:56,320
systems in automated ways i'm going to

413
00:13:54,880 --> 00:14:00,240
talk about how they do that

414
00:13:56,320 --> 00:14:02,240
uh in this talk right um

415
00:14:00,240 --> 00:14:03,279
so that's the profound difference is

416
00:14:02,240 --> 00:14:06,399
that we're starting

417
00:14:03,279 --> 00:14:09,680
operating on not just malicious stuff

418
00:14:06,399 --> 00:14:11,519
but malicious uh data sets

419
00:14:09,680 --> 00:14:15,199
where the adversary is actively trying

420
00:14:11,519 --> 00:14:16,880
to manipulate information systems

421
00:14:15,199 --> 00:14:18,560
so let's give an example of poisoning

422
00:14:16,880 --> 00:14:20,079
the data set right poisoning your

423
00:14:18,560 --> 00:14:22,079
training data set

424
00:14:20,079 --> 00:14:24,239
so of just domain names we've talked

425
00:14:22,079 --> 00:14:27,199
about domain generation algorithms right

426
00:14:24,240 --> 00:14:29,120
mathematical uh formulas that take input

427
00:14:27,199 --> 00:14:30,479
that just produce random looking domain

428
00:14:29,120 --> 00:14:31,760
names

429
00:14:30,480 --> 00:14:33,519
well if you were going to create a white

430
00:14:31,760 --> 00:14:35,760
list what would you do

431
00:14:33,519 --> 00:14:37,680
right you'd go to majestic or umbrella

432
00:14:35,760 --> 00:14:40,720
or alexa

433
00:14:37,680 --> 00:14:41,920
that creates lists of the most popular

434
00:14:40,720 --> 00:14:44,560
domains on the internet

435
00:14:41,920 --> 00:14:46,399
right up to a million uh and that's what

436
00:14:44,560 --> 00:14:47,839
everybody uses as whitelist if you take

437
00:14:46,399 --> 00:14:49,040
a look at domain white lists and

438
00:14:47,839 --> 00:14:50,480
scholar.google

439
00:14:49,040 --> 00:14:52,079
you're going to see lots of research

440
00:14:50,480 --> 00:14:54,000
into that

441
00:14:52,079 --> 00:14:56,079
well that can't be manipulated right you

442
00:14:54,000 --> 00:14:58,000
know it's the most popular stuff right

443
00:14:56,079 --> 00:15:00,319
the top 10 is pretty static it's

444
00:14:58,000 --> 00:15:01,279
youtube and facebook and apple and

445
00:15:00,320 --> 00:15:03,440
amazon

446
00:15:01,279 --> 00:15:05,439
things you would expect right but you

447
00:15:03,440 --> 00:15:08,800
get much farther down that list

448
00:15:05,440 --> 00:15:12,000
and and things do get manipulated

449
00:15:08,800 --> 00:15:12,880
right and not necessarily with with what

450
00:15:12,000 --> 00:15:14,720
you would consider

451
00:15:12,880 --> 00:15:17,040
machine air machine learning attack

452
00:15:14,720 --> 00:15:18,959
tools right there's black hat

453
00:15:17,040 --> 00:15:21,040
search engine optimization right there's

454
00:15:18,959 --> 00:15:23,839
an entire cottage industry

455
00:15:21,040 --> 00:15:25,199
and and we call it black cat seo but we

456
00:15:23,839 --> 00:15:26,160
really don't treat it as a criminal

457
00:15:25,199 --> 00:15:28,719
marketplace

458
00:15:26,160 --> 00:15:29,439
right is is google and the search

459
00:15:28,720 --> 00:15:32,000
engines

460
00:15:29,440 --> 00:15:33,839
try to figure out algorithms to stop it

461
00:15:32,000 --> 00:15:36,160
but by and large there are people

462
00:15:33,839 --> 00:15:36,880
who do nothing all day who've made lots

463
00:15:36,160 --> 00:15:39,759
of money

464
00:15:36,880 --> 00:15:41,600
that make sure their client websites are

465
00:15:39,759 --> 00:15:43,279
the top of whatever targeted google

466
00:15:41,600 --> 00:15:45,920
searches or bang or

467
00:15:43,279 --> 00:15:47,279
duckduckgo or whatever right the social

468
00:15:45,920 --> 00:15:49,519
media amplification

469
00:15:47,279 --> 00:15:51,439
right that's a huge threat we'll talk

470
00:15:49,519 --> 00:15:54,079
about that specifically uh

471
00:15:51,440 --> 00:15:56,560
in a little bit but almost all of the

472
00:15:54,079 --> 00:15:59,359
activity around election manipulation

473
00:15:56,560 --> 00:16:00,479
is is based off of disinformation in

474
00:15:59,360 --> 00:16:02,560
social media

475
00:16:00,480 --> 00:16:04,399
and you know it's not just one person

476
00:16:02,560 --> 00:16:05,119
posting to twitter or facebook you've

477
00:16:04,399 --> 00:16:06,959
got to get

478
00:16:05,120 --> 00:16:09,759
you've got to get that information out

479
00:16:06,959 --> 00:16:12,479
there their traffic delivery systems

480
00:16:09,759 --> 00:16:13,120
uh to make websites artificially more

481
00:16:12,480 --> 00:16:16,079
popular

482
00:16:13,120 --> 00:16:17,040
it's done with click fraud or uh uh

483
00:16:16,079 --> 00:16:20,239
click fraud type

484
00:16:17,040 --> 00:16:22,959
networks uh it's also done an exploit uh

485
00:16:20,240 --> 00:16:23,920
exploit kits it already exists it exists

486
00:16:22,959 --> 00:16:25,439
before

487
00:16:23,920 --> 00:16:27,519
there was a notion of using cyber

488
00:16:25,440 --> 00:16:29,279
security machine learning

489
00:16:27,519 --> 00:16:31,120
but the fundamental point is criminals

490
00:16:29,279 --> 00:16:31,839
have been exploiting automated systems

491
00:16:31,120 --> 00:16:34,240
forever

492
00:16:31,839 --> 00:16:35,360
right is the fundamental computer

493
00:16:34,240 --> 00:16:37,920
security problem

494
00:16:35,360 --> 00:16:39,519
that we're all addressing is that we

495
00:16:37,920 --> 00:16:40,160
have information systems that are

496
00:16:39,519 --> 00:16:42,240
processing

497
00:16:40,160 --> 00:16:43,759
inputs that we can't trust and how do

498
00:16:42,240 --> 00:16:45,920
you do that safely

499
00:16:43,759 --> 00:16:47,519
right whether that's buffer overflows or

500
00:16:45,920 --> 00:16:49,759
sql injection

501
00:16:47,519 --> 00:16:50,959
uh the list goes on but ultimately comes

502
00:16:49,759 --> 00:16:53,440
down to

503
00:16:50,959 --> 00:16:55,199
it's easy to create untrusted inputs and

504
00:16:53,440 --> 00:16:56,720
it's hard to create systems that will

505
00:16:55,199 --> 00:16:59,359
safely process them

506
00:16:56,720 --> 00:17:00,160
that problem did not go away in machine

507
00:16:59,360 --> 00:17:02,079
learning

508
00:17:00,160 --> 00:17:04,159
it's just a lot of people just pretend

509
00:17:02,079 --> 00:17:05,438
that it doesn't exist because the

510
00:17:04,160 --> 00:17:07,120
algorithms don't lie

511
00:17:05,439 --> 00:17:09,280
well the problem isn't the algorithms

512
00:17:07,119 --> 00:17:11,359
it's the four aspects i showed earlier

513
00:17:09,280 --> 00:17:14,480
and if i can poison the upfront training

514
00:17:11,359 --> 00:17:17,520
set because people use white lists

515
00:17:14,480 --> 00:17:19,520
that are based on popularity which is a

516
00:17:17,520 --> 00:17:22,160
rough analogy of safe

517
00:17:19,520 --> 00:17:22,639
but not complete if i can manipulate

518
00:17:22,160 --> 00:17:24,240
that

519
00:17:22,640 --> 00:17:26,079
then all of a sudden my attacks get

520
00:17:24,240 --> 00:17:27,679
white listed and i'm through

521
00:17:26,079 --> 00:17:30,320
right and i i defeat the machine

522
00:17:27,679 --> 00:17:31,840
learning system

523
00:17:30,320 --> 00:17:33,760
so when you talk about adversarial

524
00:17:31,840 --> 00:17:35,678
machine learning and research

525
00:17:33,760 --> 00:17:37,440
uh and see the academic literature you

526
00:17:35,679 --> 00:17:40,480
talking about uh you know

527
00:17:37,440 --> 00:17:43,840
generative uh generated samples where

528
00:17:40,480 --> 00:17:46,960
here i get a panda and i apply some very

529
00:17:43,840 --> 00:17:49,360
uh subtle noise to the image um

530
00:17:46,960 --> 00:17:50,880
you know uh that is imperceptible to the

531
00:17:49,360 --> 00:17:52,879
human eye so when a machine learning

532
00:17:50,880 --> 00:17:54,799
image looks at this panda over here

533
00:17:52,880 --> 00:17:55,919
it doesn't see a pendant he's a given

534
00:17:54,799 --> 00:17:58,000
even though

535
00:17:55,919 --> 00:17:59,200
in my human eye i'm looking at it i see

536
00:17:58,000 --> 00:18:02,000
what it is

537
00:17:59,200 --> 00:18:03,919
because unlike humans that ignore

538
00:18:02,000 --> 00:18:06,799
immense amounts of information

539
00:18:03,919 --> 00:18:08,720
computers see it and process all of it

540
00:18:06,799 --> 00:18:09,520
that's how research does it those are

541
00:18:08,720 --> 00:18:12,559
how people

542
00:18:09,520 --> 00:18:14,160
who are generating the attacks against

543
00:18:12,559 --> 00:18:15,120
machine learning systems are trying to

544
00:18:14,160 --> 00:18:17,520
test it right

545
00:18:15,120 --> 00:18:19,039
in these obscure mathematical ways right

546
00:18:17,520 --> 00:18:20,400
and i'm using image classification to

547
00:18:19,039 --> 00:18:22,799
make a point

548
00:18:20,400 --> 00:18:25,039
well if you were trying to trick a

549
00:18:22,799 --> 00:18:27,600
facial recognition system

550
00:18:25,039 --> 00:18:28,080
first a facial recognitionist system

551
00:18:27,600 --> 00:18:30,000
isn't

552
00:18:28,080 --> 00:18:32,480
operating off of static images it's

553
00:18:30,000 --> 00:18:34,559
operating off of actual live video

554
00:18:32,480 --> 00:18:36,480
and what it's observing you know you're

555
00:18:34,559 --> 00:18:37,520
not doing things like this if you're an

556
00:18:36,480 --> 00:18:40,080
attacker

557
00:18:37,520 --> 00:18:40,720
what you're doing is things like this

558
00:18:40,080 --> 00:18:43,120
this is

559
00:18:40,720 --> 00:18:44,080
uh from the hong kong protests where

560
00:18:43,120 --> 00:18:46,559
somebody has

561
00:18:44,080 --> 00:18:47,520
in essence right a light projector over

562
00:18:46,559 --> 00:18:49,440
his face

563
00:18:47,520 --> 00:18:51,360
so now a machine doesn't know okay where

564
00:18:49,440 --> 00:18:51,840
exactly are the eyes where's the nose

565
00:18:51,360 --> 00:18:53,840
where's

566
00:18:51,840 --> 00:18:54,879
where's the mouth and all the features

567
00:18:53,840 --> 00:18:56,959
are on

568
00:18:54,880 --> 00:18:58,559
right that's how it works in real life

569
00:18:56,960 --> 00:19:00,240
that's what an and i don't want to say

570
00:18:58,559 --> 00:19:02,480
an adversary in this case because this

571
00:19:00,240 --> 00:19:03,360
is a pro-democracy protester in hong

572
00:19:02,480 --> 00:19:06,000
kong

573
00:19:03,360 --> 00:19:08,000
um but it's somebody actively trying to

574
00:19:06,000 --> 00:19:09,760
defeat a facial recognition system

575
00:19:08,000 --> 00:19:11,520
right uh and these are the kind of

576
00:19:09,760 --> 00:19:13,520
things that attackers do

577
00:19:11,520 --> 00:19:15,679
and the point of these two slides is to

578
00:19:13,520 --> 00:19:17,440
say how we research

579
00:19:15,679 --> 00:19:19,200
and look at attacks against machine

580
00:19:17,440 --> 00:19:21,280
learning is not at all

581
00:19:19,200 --> 00:19:24,320
the techniques of what attackers are

582
00:19:21,280 --> 00:19:26,879
actually doing

583
00:19:24,320 --> 00:19:28,240
so i say our adversary has tons of

584
00:19:26,880 --> 00:19:30,320
experience

585
00:19:28,240 --> 00:19:32,240
right you know but we're not really

586
00:19:30,320 --> 00:19:33,520
studying those attacks and i've got an

587
00:19:32,240 --> 00:19:35,760
example in here

588
00:19:33,520 --> 00:19:36,720
uh that goes back 11 years right it was

589
00:19:35,760 --> 00:19:40,000
a 4chan

590
00:19:36,720 --> 00:19:42,400
related uh attack called operation and

591
00:19:40,000 --> 00:19:43,760
and you get the idea of profanity and

592
00:19:42,400 --> 00:19:44,480
what it was doing was trying to

593
00:19:43,760 --> 00:19:47,280
manipulate

594
00:19:44,480 --> 00:19:48,880
the top 10 twitter trending topics and

595
00:19:47,280 --> 00:19:50,720
it was basically a

596
00:19:48,880 --> 00:19:52,240
a somewhat inappropriate expression

597
00:19:50,720 --> 00:19:54,320
about guerrillas

598
00:19:52,240 --> 00:19:56,240
and for a while they had taken over the

599
00:19:54,320 --> 00:19:59,760
twenty trending topics

600
00:19:56,240 --> 00:20:00,960
um basically with social uh social media

601
00:19:59,760 --> 00:20:03,280
manipulator uh

602
00:20:00,960 --> 00:20:05,120
magnification and amplification right

603
00:20:03,280 --> 00:20:07,600
enough people at 4chan got together

604
00:20:05,120 --> 00:20:09,360
started posting the same hashtags and

605
00:20:07,600 --> 00:20:12,158
the algorithms were quite simple

606
00:20:09,360 --> 00:20:14,000
it took things over well when we talk

607
00:20:12,159 --> 00:20:14,799
about disinformation and electoral

608
00:20:14,000 --> 00:20:16,960
manipulation

609
00:20:14,799 --> 00:20:18,879
certainly with social media it's doing

610
00:20:16,960 --> 00:20:20,240
basically the same things

611
00:20:18,880 --> 00:20:22,000
is yeah it's a little bit more

612
00:20:20,240 --> 00:20:23,360
complicated now to engage in

613
00:20:22,000 --> 00:20:25,600
amplification

614
00:20:23,360 --> 00:20:26,879
but not only are nation states you know

615
00:20:25,600 --> 00:20:27,360
from the perspective of the united

616
00:20:26,880 --> 00:20:28,880
states

617
00:20:27,360 --> 00:20:30,959
in what's going on right now with a

618
00:20:28,880 --> 00:20:32,400
presidential election russia china and

619
00:20:30,960 --> 00:20:33,679
others are trying to sit there and get

620
00:20:32,400 --> 00:20:36,000
their messages out

621
00:20:33,679 --> 00:20:36,960
to manipulate the public but there's

622
00:20:36,000 --> 00:20:39,200
also

623
00:20:36,960 --> 00:20:40,799
political activists and parties who are

624
00:20:39,200 --> 00:20:43,039
doing the same thing

625
00:20:40,799 --> 00:20:44,320
right um is that not only of the

626
00:20:43,039 --> 00:20:45,280
criminals or i shouldn't say the

627
00:20:44,320 --> 00:20:48,000
criminals because

628
00:20:45,280 --> 00:20:49,200
that's not i'm not entirely sure this is

629
00:20:48,000 --> 00:20:50,559
criminal behavior

630
00:20:49,200 --> 00:20:52,559
but people are manipulating the

631
00:20:50,559 --> 00:20:53,600
algorithms both foreign and hostile

632
00:20:52,559 --> 00:20:55,840
adversaries

633
00:20:53,600 --> 00:20:57,280
and people within our within our own

634
00:20:55,840 --> 00:21:00,080
political ecosystem

635
00:20:57,280 --> 00:21:01,120
and that happens everywhere to to a much

636
00:21:00,080 --> 00:21:04,399
larger extent

637
00:21:01,120 --> 00:21:06,000
right it's the same thing um and

638
00:21:04,400 --> 00:21:07,840
you know i said they've been doing it

639
00:21:06,000 --> 00:21:10,960
for a while and

640
00:21:07,840 --> 00:21:12,799
you know this from 2009 was i said it

641
00:21:10,960 --> 00:21:15,200
was it was a bunch of people on 4chan

642
00:21:12,799 --> 00:21:16,799
doing relatively unsophisticated things

643
00:21:15,200 --> 00:21:18,640
they're not generating adversarial

644
00:21:16,799 --> 00:21:20,080
samples you know they're just figuring

645
00:21:18,640 --> 00:21:21,600
out the weak points of the algorithm and

646
00:21:20,080 --> 00:21:24,240
kicking it over they're not bothering

647
00:21:21,600 --> 00:21:24,240
with the math

648
00:21:25,200 --> 00:21:29,679
so when we talk about machine learning

649
00:21:27,440 --> 00:21:30,080
especially in the cyber security context

650
00:21:29,679 --> 00:21:32,320
right

651
00:21:30,080 --> 00:21:34,320
ultimately what comes down to is there

652
00:21:32,320 --> 00:21:37,039
there's an attempt for classification

653
00:21:34,320 --> 00:21:37,600
right now classification generally right

654
00:21:37,039 --> 00:21:39,679
you know

655
00:21:37,600 --> 00:21:40,799
what kind of class is this is it a cat

656
00:21:39,679 --> 00:21:44,000
is it a panda

657
00:21:40,799 --> 00:21:45,918
is it good is it bad is it is this image

658
00:21:44,000 --> 00:21:48,159
represent john bambonek or does it

659
00:21:45,919 --> 00:21:51,760
represent somebody else right

660
00:21:48,159 --> 00:21:53,600
uh that is entirely a choice of who

661
00:21:51,760 --> 00:21:55,039
uh makes the system and what they're

662
00:21:53,600 --> 00:21:57,760
trying to accomplish

663
00:21:55,039 --> 00:21:59,120
um and it has caused some awful bias

664
00:21:57,760 --> 00:22:03,440
problems when you look at

665
00:21:59,120 --> 00:22:06,000
facial recognition systems applied to

666
00:22:03,440 --> 00:22:06,799
african-american or people people that

667
00:22:06,000 --> 00:22:10,400
are black

668
00:22:06,799 --> 00:22:12,400
the systems behave quite poorly right so

669
00:22:10,400 --> 00:22:13,679
you you quite literally in a computer

670
00:22:12,400 --> 00:22:16,720
science context

671
00:22:13,679 --> 00:22:18,720
have systemic bias

672
00:22:16,720 --> 00:22:21,120
um but like i said those classifications

673
00:22:18,720 --> 00:22:23,840
are determined by people

674
00:22:21,120 --> 00:22:24,158
they're also hard to decide right you

675
00:22:23,840 --> 00:22:26,639
can

676
00:22:24,159 --> 00:22:28,960
you can have classes that are too course

677
00:22:26,640 --> 00:22:31,200
you can have them that too narrow

678
00:22:28,960 --> 00:22:32,080
you know if you have a very course class

679
00:22:31,200 --> 00:22:33,600
it includes

680
00:22:32,080 --> 00:22:35,678
it could include things that you really

681
00:22:33,600 --> 00:22:37,199
don't want included if it's too narrow

682
00:22:35,679 --> 00:22:39,440
you exclude things you don't want to

683
00:22:37,200 --> 00:22:40,400
exclude you could create a machine

684
00:22:39,440 --> 00:22:42,640
learning

685
00:22:40,400 --> 00:22:43,600
system that doesn't just classify

686
00:22:42,640 --> 00:22:46,640
something as

687
00:22:43,600 --> 00:22:47,520
malware or benign you could say it's not

688
00:22:46,640 --> 00:22:50,559
just malware

689
00:22:47,520 --> 00:22:53,600
this is njrat or um

690
00:22:50,559 --> 00:22:55,918
adwind or luminosity link right

691
00:22:53,600 --> 00:22:58,480
and those are just rats you know this is

692
00:22:55,919 --> 00:23:00,159
this is a specific brand of stock aware

693
00:22:58,480 --> 00:23:02,000
well if that's your class when somebody

694
00:23:00,159 --> 00:23:04,559
develops new malware

695
00:23:02,000 --> 00:23:05,039
the system won't detect it if it's too

696
00:23:04,559 --> 00:23:09,280
coarse

697
00:23:05,039 --> 00:23:11,679
it may detect benign things

698
00:23:09,280 --> 00:23:13,440
so as an example going back to domain

699
00:23:11,679 --> 00:23:16,480
generation algorithms

700
00:23:13,440 --> 00:23:18,000
right is generally a dga produces random

701
00:23:16,480 --> 00:23:18,880
looking domain names of random

702
00:23:18,000 --> 00:23:20,799
characters right

703
00:23:18,880 --> 00:23:22,400
it's like somebody bashed their fists on

704
00:23:20,799 --> 00:23:25,600
a keyboard and creating it

705
00:23:22,400 --> 00:23:27,360
we know malware uses dgas but so do ad

706
00:23:25,600 --> 00:23:30,240
trackers in related technologies

707
00:23:27,360 --> 00:23:31,360
right for similar reasons um so the

708
00:23:30,240 --> 00:23:33,919
class contains

709
00:23:31,360 --> 00:23:35,360
both you know all right maybe not

710
00:23:33,919 --> 00:23:37,360
malicious

711
00:23:35,360 --> 00:23:39,280
if you don't want to call it good and

712
00:23:37,360 --> 00:23:41,039
bad right we can agree that ransomware

713
00:23:39,280 --> 00:23:44,000
is better than pervasive

714
00:23:41,039 --> 00:23:46,240
ad and web tracking um so if you're

715
00:23:44,000 --> 00:23:48,799
choosing a class of is a dj

716
00:23:46,240 --> 00:23:50,000
or not right you're including data that

717
00:23:48,799 --> 00:23:51,918
you might not necessarily

718
00:23:50,000 --> 00:23:54,400
want to action and certainly that you

719
00:23:51,919 --> 00:23:57,600
wouldn't want to action the same way as

720
00:23:54,400 --> 00:23:58,000
ransomware or botnets or so on right uh

721
00:23:57,600 --> 00:23:59,918
and that

722
00:23:58,000 --> 00:24:01,440
and by i said this is a large body of

723
00:23:59,919 --> 00:24:02,159
cyber security machine learning right

724
00:24:01,440 --> 00:24:04,400
here

725
00:24:02,159 --> 00:24:06,080
where it's just kind of hand waving well

726
00:24:04,400 --> 00:24:08,080
we know dgas are bad

727
00:24:06,080 --> 00:24:09,279
so anything that's detected as a dg is

728
00:24:08,080 --> 00:24:10,960
bad well

729
00:24:09,279 --> 00:24:13,440
your class is a little too coarse

730
00:24:10,960 --> 00:24:16,720
because there is some

731
00:24:13,440 --> 00:24:18,799
uh non-malicious or less malicious uses

732
00:24:16,720 --> 00:24:19,840
of dgas they're just not used by human

733
00:24:18,799 --> 00:24:21,360
beings

734
00:24:19,840 --> 00:24:23,678
that doesn't mean the classifier doesn't

735
00:24:21,360 --> 00:24:25,678
give you interesting information it does

736
00:24:23,679 --> 00:24:28,960
but it's not sufficient because you

737
00:24:25,679 --> 00:24:31,600
didn't choose your classes correctly

738
00:24:28,960 --> 00:24:32,480
so i mean a defense for this is like a

739
00:24:31,600 --> 00:24:34,719
red team right

740
00:24:32,480 --> 00:24:36,720
we've discussed red z i mean there's

741
00:24:34,720 --> 00:24:37,679
lots of discussions on red teams and pen

742
00:24:36,720 --> 00:24:39,120
testers

743
00:24:37,679 --> 00:24:41,600
but there isn't really a lot of

744
00:24:39,120 --> 00:24:43,360
discussion and and enterprises

745
00:24:41,600 --> 00:24:44,879
either both with security vendors who

746
00:24:43,360 --> 00:24:47,360
are creating ml tools

747
00:24:44,880 --> 00:24:48,799
or enterprises that have red teams that

748
00:24:47,360 --> 00:24:51,520
are deploying them

749
00:24:48,799 --> 00:24:52,639
right how do you attack this system with

750
00:24:51,520 --> 00:24:54,960
a hacker mindset

751
00:24:52,640 --> 00:24:56,799
right i don't i'm not interested in

752
00:24:54,960 --> 00:24:57,919
people doing interesting gaussian

753
00:24:56,799 --> 00:25:00,720
transforms

754
00:24:57,919 --> 00:25:02,720
against an ml system what would a hacker

755
00:25:00,720 --> 00:25:04,880
actually do what would a criminal do

756
00:25:02,720 --> 00:25:06,320
to defeat this system and what kind of

757
00:25:04,880 --> 00:25:08,480
person are you hiring

758
00:25:06,320 --> 00:25:10,240
to figure that out right and i don't

759
00:25:08,480 --> 00:25:11,600
know that we we've trained an awful lot

760
00:25:10,240 --> 00:25:13,279
of people i don't i don't know how many

761
00:25:11,600 --> 00:25:16,158
people specialize in it

762
00:25:13,279 --> 00:25:17,520
um i've not heard of a machine learning

763
00:25:16,159 --> 00:25:19,360
red team per se

764
00:25:17,520 --> 00:25:21,120
i know they're people thinking about it

765
00:25:19,360 --> 00:25:22,799
you know but if you're deploying

766
00:25:21,120 --> 00:25:25,439
machine learning say just in fraud

767
00:25:22,799 --> 00:25:28,240
detection at a major financial institute

768
00:25:25,440 --> 00:25:30,159
who do you have and that system is is

769
00:25:28,240 --> 00:25:31,039
responsible for protecting billions of

770
00:25:30,159 --> 00:25:32,799
dollars

771
00:25:31,039 --> 00:25:34,720
who do you have that's taking that's

772
00:25:32,799 --> 00:25:36,480
kicking the tires of that thing

773
00:25:34,720 --> 00:25:39,440
doing the kind of things an actual

774
00:25:36,480 --> 00:25:39,440
adversary would do

775
00:25:40,000 --> 00:25:43,200
so vulnerability too is class confusion

776
00:25:42,559 --> 00:25:45,279
right

777
00:25:43,200 --> 00:25:46,960
so what if i can make something say the

778
00:25:45,279 --> 00:25:49,600
national security agency

779
00:25:46,960 --> 00:25:50,960
right it's an intelligence agency that

780
00:25:49,600 --> 00:25:53,760
steals a lot of information

781
00:25:50,960 --> 00:25:55,279
right as an american i you know most

782
00:25:53,760 --> 00:25:55,600
americans i guess have a mixed view of

783
00:25:55,279 --> 00:25:58,080
it

784
00:25:55,600 --> 00:26:00,080
but generally right that's the home team

785
00:25:58,080 --> 00:26:02,639
now if i'm china or russia

786
00:26:00,080 --> 00:26:04,240
that's the adversary uh but what if i

787
00:26:02,640 --> 00:26:07,440
could make the nsa

788
00:26:04,240 --> 00:26:09,679
look like facebook right you know

789
00:26:07,440 --> 00:26:11,360
where you can have class confusion well

790
00:26:09,679 --> 00:26:12,559
depending on what features that's not

791
00:26:11,360 --> 00:26:15,439
entirely

792
00:26:12,559 --> 00:26:16,000
outside the realm of possibility right

793
00:26:15,440 --> 00:26:17,679
you know

794
00:26:16,000 --> 00:26:19,679
here's an example of the attributes of

795
00:26:17,679 --> 00:26:22,320
both it's it's a crafted example

796
00:26:19,679 --> 00:26:23,279
right they both take and process lots of

797
00:26:22,320 --> 00:26:25,039
information

798
00:26:23,279 --> 00:26:26,480
they're executing on objectives that

799
00:26:25,039 --> 00:26:29,520
have nothing to do

800
00:26:26,480 --> 00:26:30,799
necessarily with the interests of what

801
00:26:29,520 --> 00:26:33,039
they're surveilling

802
00:26:30,799 --> 00:26:35,279
right you know the nsa you know

803
00:26:33,039 --> 00:26:37,360
obviously it's an intelligence agency

804
00:26:35,279 --> 00:26:38,960
uh assassination is ultimately in the

805
00:26:37,360 --> 00:26:42,158
cards facebook

806
00:26:38,960 --> 00:26:44,000
hopefully not but they both behave

807
00:26:42,159 --> 00:26:46,000
similar to intelligence agencies but you

808
00:26:44,000 --> 00:26:47,919
would you would treat them differently

809
00:26:46,000 --> 00:26:49,200
right uh depending on how you would

810
00:26:47,919 --> 00:26:51,039
define that class but

811
00:26:49,200 --> 00:26:52,559
thinking about it it's it's it's an

812
00:26:51,039 --> 00:26:53,919
absurd example you shouldn't treat

813
00:26:52,559 --> 00:26:55,520
facebook the same way you treat an

814
00:26:53,919 --> 00:26:56,960
intelligence agency

815
00:26:55,520 --> 00:26:59,120
but if you're creating your classes

816
00:26:56,960 --> 00:27:02,799
coarsely enough both would be

817
00:26:59,120 --> 00:27:04,479
uh both would be captured

818
00:27:02,799 --> 00:27:06,480
but it's interesting right if you just

819
00:27:04,480 --> 00:27:08,080
take a look at let's define the class of

820
00:27:06,480 --> 00:27:09,760
malicious software

821
00:27:08,080 --> 00:27:11,360
we'd all agree ransomware should be on

822
00:27:09,760 --> 00:27:14,000
it ransomware is awful right

823
00:27:11,360 --> 00:27:16,240
there's talks about uh about this at

824
00:27:14,000 --> 00:27:19,760
this conference it's still a problem

825
00:27:16,240 --> 00:27:22,000
uh you know going on seven years now um

826
00:27:19,760 --> 00:27:23,679
going back to cryptolocker in 2013 which

827
00:27:22,000 --> 00:27:25,360
is kind of the first modern

828
00:27:23,679 --> 00:27:27,279
successful form of ransom where it's

829
00:27:25,360 --> 00:27:29,199
still with us

830
00:27:27,279 --> 00:27:30,799
stalkerware we can all agree that

831
00:27:29,200 --> 00:27:33,039
domestic abuse is horrible

832
00:27:30,799 --> 00:27:34,799
and software that enables domestic abuse

833
00:27:33,039 --> 00:27:36,879
is horrible right

834
00:27:34,799 --> 00:27:38,399
well what about potentially unwanted uh

835
00:27:36,880 --> 00:27:41,279
applications

836
00:27:38,399 --> 00:27:42,639
well you know as an i.t administrator

837
00:27:41,279 --> 00:27:44,240
you might not want it

838
00:27:42,640 --> 00:27:45,840
uh but maybe your policies don't

839
00:27:44,240 --> 00:27:47,520
prohibit it right it's certainly

840
00:27:45,840 --> 00:27:49,600
different than ransomware

841
00:27:47,520 --> 00:27:51,840
what about cryptominers right a lot of

842
00:27:49,600 --> 00:27:53,360
antivirus is very strong at detecting

843
00:27:51,840 --> 00:27:54,959
things mining monero

844
00:27:53,360 --> 00:27:56,479
but that also means people who are

845
00:27:54,960 --> 00:27:57,279
hobbyists who want to mine monero at

846
00:27:56,480 --> 00:27:59,840
home

847
00:27:57,279 --> 00:28:00,640
all of a sudden have difficulty either

848
00:27:59,840 --> 00:28:02,639
and

849
00:28:00,640 --> 00:28:03,919
and if the antivirus doesn't allow them

850
00:28:02,640 --> 00:28:05,600
to create exceptions

851
00:28:03,919 --> 00:28:08,640
either they've got to decide not to run

852
00:28:05,600 --> 00:28:11,439
antivirus or not to mine monero

853
00:28:08,640 --> 00:28:12,159
you know there's the individual you know

854
00:28:11,440 --> 00:28:14,399
that has

855
00:28:12,159 --> 00:28:15,360
all of those i don't i don't know how

856
00:28:14,399 --> 00:28:17,439
this happens

857
00:28:15,360 --> 00:28:19,279
or if this still happens anymore but

858
00:28:17,440 --> 00:28:21,039
back in the day when i did it support

859
00:28:19,279 --> 00:28:23,279
there's always somebody who had like six

860
00:28:21,039 --> 00:28:24,399
seven different toolbars and internet

861
00:28:23,279 --> 00:28:26,720
explorer

862
00:28:24,399 --> 00:28:28,000
you know to provide you know information

863
00:28:26,720 --> 00:28:30,480
or ads and

864
00:28:28,000 --> 00:28:32,240
um you know oh they'd see an ad every

865
00:28:30,480 --> 00:28:35,200
now and then and they get two cents

866
00:28:32,240 --> 00:28:37,039
for clicking it or whatever right um as

867
00:28:35,200 --> 00:28:39,520
an i.t administrator i didn't

868
00:28:37,039 --> 00:28:41,679
i didn't hate it or i did i didn't i you

869
00:28:39,520 --> 00:28:44,080
know i didn't treat it as ransomware

870
00:28:41,679 --> 00:28:46,159
but the policy at the place didn't allow

871
00:28:44,080 --> 00:28:47,760
me to do anything about it except saying

872
00:28:46,159 --> 00:28:49,279
hey by the way this stuff is kind of

873
00:28:47,760 --> 00:28:52,399
spying on you you might not

874
00:28:49,279 --> 00:28:54,880
want to think about not using it anymore

875
00:28:52,399 --> 00:28:55,918
so defenses to that don't do

876
00:28:54,880 --> 00:28:57,600
unsupervised

877
00:28:55,919 --> 00:28:59,840
machine learning and don't use products

878
00:28:57,600 --> 00:29:01,760
that do it right if you're doing kind of

879
00:28:59,840 --> 00:29:02,480
research to go find new and interesting

880
00:29:01,760 --> 00:29:04,399
things

881
00:29:02,480 --> 00:29:06,080
your your hunt team to try to see if you

882
00:29:04,399 --> 00:29:08,158
can get insights generally

883
00:29:06,080 --> 00:29:09,840
okay you can do unsupervised machine

884
00:29:08,159 --> 00:29:10,960
learning but in the cyber security

885
00:29:09,840 --> 00:29:13,520
context

886
00:29:10,960 --> 00:29:14,159
right you wanna you wanna provide known

887
00:29:13,520 --> 00:29:17,360
classed

888
00:29:14,159 --> 00:29:20,080
uh and labeled data uh to the system uh

889
00:29:17,360 --> 00:29:21,439
because again you have the class

890
00:29:20,080 --> 00:29:24,158
confusion problem

891
00:29:21,440 --> 00:29:25,840
right if i'm just doing uh unsupervised

892
00:29:24,159 --> 00:29:26,640
machine learning on domain names yeah

893
00:29:25,840 --> 00:29:28,399
i'm going to get all this

894
00:29:26,640 --> 00:29:30,159
algorithmically generated domains

895
00:29:28,399 --> 00:29:31,918
clustered over here

896
00:29:30,159 --> 00:29:34,080
well there's some good and bad in there

897
00:29:31,919 --> 00:29:35,840
that doesn't give me anything to act on

898
00:29:34,080 --> 00:29:39,039
or i should say if i act on it

899
00:29:35,840 --> 00:29:40,240
i'm going to be making mistakes so spend

900
00:29:39,039 --> 00:29:42,559
real time on figuring what the

901
00:29:40,240 --> 00:29:44,480
classifications are and labeling them

902
00:29:42,559 --> 00:29:46,080
and defining that of what's included and

903
00:29:44,480 --> 00:29:47,840
what's not with

904
00:29:46,080 --> 00:29:49,199
like i said trying to balance the being

905
00:29:47,840 --> 00:29:52,158
too course being brain

906
00:29:49,200 --> 00:29:54,320
too narrow but also bear in mind the

907
00:29:52,159 --> 00:29:57,360
attackers know kind of know our classes

908
00:29:54,320 --> 00:30:00,559
everything we do is public uh in essence

909
00:29:57,360 --> 00:30:03,600
uh so they're able to uh determine that

910
00:30:00,559 --> 00:30:03,600
and act accordingly

911
00:30:03,679 --> 00:30:06,960
you'll hear uh vendors say it but our

912
00:30:06,240 --> 00:30:08,720
machine learning

913
00:30:06,960 --> 00:30:10,399
models are proprietary the attackers

914
00:30:08,720 --> 00:30:11,919
don't have them

915
00:30:10,399 --> 00:30:13,039
in adversarial machine learning there's

916
00:30:11,919 --> 00:30:14,080
a concept of what's called

917
00:30:13,039 --> 00:30:16,720
transferability

918
00:30:14,080 --> 00:30:17,360
namely that if you have models that are

919
00:30:16,720 --> 00:30:20,159
roughly

920
00:30:17,360 --> 00:30:22,158
and and i emphasize rough similar in

921
00:30:20,159 --> 00:30:24,399
terms of the kind of features they use

922
00:30:22,159 --> 00:30:26,080
and the kind of data they used attacks

923
00:30:24,399 --> 00:30:28,559
against one are valid against

924
00:30:26,080 --> 00:30:29,360
all of them the percentages might change

925
00:30:28,559 --> 00:30:32,080
a little bit

926
00:30:29,360 --> 00:30:33,279
but by and large if i can take a white

927
00:30:32,080 --> 00:30:35,360
paper a vendor does

928
00:30:33,279 --> 00:30:36,799
and kind of infer okay this is the

929
00:30:35,360 --> 00:30:37,760
features that they're using and the

930
00:30:36,799 --> 00:30:39,120
attributes

931
00:30:37,760 --> 00:30:41,520
and here's the data sets that they're

932
00:30:39,120 --> 00:30:42,158
using i can simply just create my own

933
00:30:41,520 --> 00:30:45,200
model

934
00:30:42,159 --> 00:30:46,880
with my own data that's roughly similar

935
00:30:45,200 --> 00:30:48,960
and then keep attacking that until i'm

936
00:30:46,880 --> 00:30:51,039
successful and then deploy that attack

937
00:30:48,960 --> 00:30:55,840
and i will probably be successful

938
00:30:51,039 --> 00:30:55,840
in defeating that proprietary model

939
00:30:56,240 --> 00:30:59,279
this is what i call the virus total

940
00:30:57,840 --> 00:31:01,360
problem right is

941
00:30:59,279 --> 00:31:03,200
if i want to see if my piece of malware

942
00:31:01,360 --> 00:31:04,240
is detected i simply could submit it to

943
00:31:03,200 --> 00:31:06,720
virustotal

944
00:31:04,240 --> 00:31:08,320
and it runs against all the av engines

945
00:31:06,720 --> 00:31:10,240
uh i could buy the av

946
00:31:08,320 --> 00:31:11,360
tools or the endpoint tools and run my

947
00:31:10,240 --> 00:31:13,519
attacks against it

948
00:31:11,360 --> 00:31:15,120
if i'm an intelligence agency i i have a

949
00:31:13,519 --> 00:31:16,320
budget to do exactly that if i'm an

950
00:31:15,120 --> 00:31:19,439
attacker i've got to

951
00:31:16,320 --> 00:31:21,039
do more tr uh crafted things but the

952
00:31:19,440 --> 00:31:23,039
point is the attacker

953
00:31:21,039 --> 00:31:24,480
can test attacks as much as they want

954
00:31:23,039 --> 00:31:27,519
until they get it right

955
00:31:24,480 --> 00:31:28,559
or for that matter um and what we see

956
00:31:27,519 --> 00:31:30,559
particularly with phishing

957
00:31:28,559 --> 00:31:32,320
is they simply just keep attacking in

958
00:31:30,559 --> 00:31:33,600
production because they don't need every

959
00:31:32,320 --> 00:31:36,158
attack to work

960
00:31:33,600 --> 00:31:37,918
they just need one to get through right

961
00:31:36,159 --> 00:31:39,840
they need to get lucky once we need to

962
00:31:37,919 --> 00:31:43,279
get lucky every single time

963
00:31:39,840 --> 00:31:45,039
right but not every attack is the same

964
00:31:43,279 --> 00:31:46,559
right which means like i said they can

965
00:31:45,039 --> 00:31:48,879
experiment and

966
00:31:46,559 --> 00:31:50,559
if the models are done too narrowly

967
00:31:48,880 --> 00:31:52,960
things will slip through because

968
00:31:50,559 --> 00:31:54,720
it's new and doesn't match any of the

969
00:31:52,960 --> 00:31:57,760
previous labels

970
00:31:54,720 --> 00:31:58,880
right so the model should be ambiguous

971
00:31:57,760 --> 00:32:01,840
and what does that mean

972
00:31:58,880 --> 00:32:02,720
right is in data science you want your

973
00:32:01,840 --> 00:32:04,959
models

974
00:32:02,720 --> 00:32:06,480
typically to make a decision i want to

975
00:32:04,960 --> 00:32:08,000
run machine learning and i want to have

976
00:32:06,480 --> 00:32:10,399
an answer

977
00:32:08,000 --> 00:32:12,000
a lot of times a lot of the data it's

978
00:32:10,399 --> 00:32:13,840
very certain it's very obvious

979
00:32:12,000 --> 00:32:15,600
right and it and and those of you who

980
00:32:13,840 --> 00:32:16,879
are stock analysts

981
00:32:15,600 --> 00:32:18,639
there's lots of things that you could

982
00:32:16,880 --> 00:32:20,399
look at and make a determination in

983
00:32:18,640 --> 00:32:22,240
seconds and you know you're right

984
00:32:20,399 --> 00:32:23,840
and then there's some that takes some

985
00:32:22,240 --> 00:32:28,159
time and work the same

986
00:32:23,840 --> 00:32:30,559
is true by analogy and machine learning

987
00:32:28,159 --> 00:32:32,080
the data that's not clear cut is what's

988
00:32:30,559 --> 00:32:34,240
interesting to you

989
00:32:32,080 --> 00:32:35,199
right we talk about hunt teams we know

990
00:32:34,240 --> 00:32:37,760
we know that uh

991
00:32:35,200 --> 00:32:38,960
in threat intelligence and sock teams is

992
00:32:37,760 --> 00:32:41,760
there's people out there

993
00:32:38,960 --> 00:32:43,039
looking for failures what's the analogy

994
00:32:41,760 --> 00:32:44,240
in data science right there should be

995
00:32:43,039 --> 00:32:46,158
people looking

996
00:32:44,240 --> 00:32:47,519
whether it's a vendor deploying these

997
00:32:46,159 --> 00:32:49,120
tools or

998
00:32:47,519 --> 00:32:51,200
an enterprise who's using machine

999
00:32:49,120 --> 00:32:54,239
learning tools to figure stuff out is

1000
00:32:51,200 --> 00:32:56,880
i want to figure out where you know

1001
00:32:54,240 --> 00:32:59,039
where's the model what data and results

1002
00:32:56,880 --> 00:33:00,640
is the model only 60 percent confident

1003
00:32:59,039 --> 00:33:01,440
of me that's what i should be taking a

1004
00:33:00,640 --> 00:33:02,720
look at

1005
00:33:01,440 --> 00:33:04,799
because you never want to take the

1006
00:33:02,720 --> 00:33:06,399
humans out of the mix because like i

1007
00:33:04,799 --> 00:33:08,960
said there's human error

1008
00:33:06,399 --> 00:33:09,439
that's already caked into these models

1009
00:33:08,960 --> 00:33:11,440
um

1010
00:33:09,440 --> 00:33:13,120
so you know you don't have to analyze

1011
00:33:11,440 --> 00:33:13,840
every decision a machine learning model

1012
00:33:13,120 --> 00:33:16,239
makes

1013
00:33:13,840 --> 00:33:17,519
but certainly you could do ten percent

1014
00:33:16,240 --> 00:33:19,279
you know manually

1015
00:33:17,519 --> 00:33:20,960
uh when a model is new and then one

1016
00:33:19,279 --> 00:33:22,000
percent going forward if something makes

1017
00:33:20,960 --> 00:33:23,679
a decision

1018
00:33:22,000 --> 00:33:25,519
you know one out a hundred times send it

1019
00:33:23,679 --> 00:33:27,519
to a sock anyway to say

1020
00:33:25,519 --> 00:33:28,960
take a look at this give it a thumbs up

1021
00:33:27,519 --> 00:33:30,720
or thumbs down about whether it's

1022
00:33:28,960 --> 00:33:32,799
correct or not

1023
00:33:30,720 --> 00:33:34,399
but like i said also have a machine

1024
00:33:32,799 --> 00:33:35,600
learning hub team look at the ambiguous

1025
00:33:34,399 --> 00:33:37,039
results because that's where the

1026
00:33:35,600 --> 00:33:39,120
interesting data lives

1027
00:33:37,039 --> 00:33:40,960
that's where your apt is going to be

1028
00:33:39,120 --> 00:33:41,840
right that's where your targeted attacks

1029
00:33:40,960 --> 00:33:43,840
are going to be

1030
00:33:41,840 --> 00:33:45,279
more often than not there's a couple of

1031
00:33:43,840 --> 00:33:46,559
things that make it look bad

1032
00:33:45,279 --> 00:33:48,559
but they're really trying to make it

1033
00:33:46,559 --> 00:33:50,240
look good right uh

1034
00:33:48,559 --> 00:33:52,240
there's lots of stuff that's just going

1035
00:33:50,240 --> 00:33:53,600
to be the noise uh the internet

1036
00:33:52,240 --> 00:33:55,120
background radiation

1037
00:33:53,600 --> 00:33:57,039
block it by all means if you can get

1038
00:33:55,120 --> 00:33:59,840
that off of your socks desk

1039
00:33:57,039 --> 00:34:01,600
great you you've got a big win but focus

1040
00:33:59,840 --> 00:34:04,840
on that interesting data and don't

1041
00:34:01,600 --> 00:34:06,000
force a model uh to make a decision for

1042
00:34:04,840 --> 00:34:08,560
you

1043
00:34:06,000 --> 00:34:10,079
and the last point right is is many of

1044
00:34:08,560 --> 00:34:12,159
your enterprises

1045
00:34:10,079 --> 00:34:13,760
and a lot of people are saying hey you

1046
00:34:12,159 --> 00:34:15,040
know this machine learning this and

1047
00:34:13,760 --> 00:34:17,119
machine learning lab

1048
00:34:15,040 --> 00:34:18,639
you know and it's a buzzword some people

1049
00:34:17,119 --> 00:34:20,000
are saying machine learning and it's not

1050
00:34:18,639 --> 00:34:23,280
really doing any real machine

1051
00:34:20,000 --> 00:34:24,399
learning but you can ask vendors right

1052
00:34:23,280 --> 00:34:26,000
and your partners

1053
00:34:24,399 --> 00:34:28,159
all right exactly what are you doing

1054
00:34:26,000 --> 00:34:29,199
right you know where did you curate your

1055
00:34:28,159 --> 00:34:31,520
training data

1056
00:34:29,199 --> 00:34:32,638
right how did when how often do you

1057
00:34:31,520 --> 00:34:34,159
update it

1058
00:34:32,639 --> 00:34:36,079
uh you know how do you define your

1059
00:34:34,159 --> 00:34:37,760
classes are you doing unsupervised for

1060
00:34:36,079 --> 00:34:39,839
supervised learning right

1061
00:34:37,760 --> 00:34:41,520
and some people say hey these algorithms

1062
00:34:39,839 --> 00:34:42,719
and data science and they'll try to

1063
00:34:41,520 --> 00:34:44,480
dazzle you with

1064
00:34:42,719 --> 00:34:46,000
with math and and that's not the

1065
00:34:44,480 --> 00:34:47,599
interesting questions that's not really

1066
00:34:46,000 --> 00:34:49,599
the important questions

1067
00:34:47,599 --> 00:34:50,639
it's where you got your data how are you

1068
00:34:49,599 --> 00:34:52,639
curating it

1069
00:34:50,639 --> 00:34:54,399
how are you labeling it classifying it

1070
00:34:52,639 --> 00:34:56,240
how are you defining the classes

1071
00:34:54,399 --> 00:34:58,160
are you doing supervised burst

1072
00:34:56,239 --> 00:35:00,399
unsupervised and you're analyzing

1073
00:34:58,160 --> 00:35:02,480
results are you getting telemetry back

1074
00:35:00,400 --> 00:35:04,079
to sit there for somebody to evaluate

1075
00:35:02,480 --> 00:35:05,920
saying hey we got this wrong

1076
00:35:04,079 --> 00:35:08,240
and we need to go tweak our models and

1077
00:35:05,920 --> 00:35:09,839
re-en and re-learn

1078
00:35:08,240 --> 00:35:11,680
right somebody's saying but the

1079
00:35:09,839 --> 00:35:12,400
algorithms is not a good answer because

1080
00:35:11,680 --> 00:35:14,319
like i said

1081
00:35:12,400 --> 00:35:16,480
the human error isn't in the linear

1082
00:35:14,320 --> 00:35:18,000
algebra the human errors and all the hum

1083
00:35:16,480 --> 00:35:20,480
the human decisions that go

1084
00:35:18,000 --> 00:35:21,359
into what gets thrown through the linear

1085
00:35:20,480 --> 00:35:24,160
algebra

1086
00:35:21,359 --> 00:35:26,400
right uh and a last point right ml can

1087
00:35:24,160 --> 00:35:28,720
classify and do a fairly decent job if

1088
00:35:26,400 --> 00:35:30,640
you can control all of the above

1089
00:35:28,720 --> 00:35:32,160
there are a lot of people trying to to

1090
00:35:30,640 --> 00:35:33,759
to do machine learning to protect

1091
00:35:32,160 --> 00:35:35,839
outcomes right and that's

1092
00:35:33,760 --> 00:35:37,920
not just in cyber security right there's

1093
00:35:35,839 --> 00:35:41,440
lots of other uk use cases with

1094
00:35:37,920 --> 00:35:42,160
insurance companies and education and on

1095
00:35:41,440 --> 00:35:44,480
and on

1096
00:35:42,160 --> 00:35:45,359
uh machine learning does not fare well

1097
00:35:44,480 --> 00:35:47,520
there right

1098
00:35:45,359 --> 00:35:49,839
so if somebody's peddling you know

1099
00:35:47,520 --> 00:35:51,680
machine learning to predict outcomes

1100
00:35:49,839 --> 00:35:53,040
you know not even the research and the

1101
00:35:51,680 --> 00:35:56,480
math shows

1102
00:35:53,040 --> 00:35:59,759
that that is that is truly a uh a viable

1103
00:35:56,480 --> 00:36:01,839
way to apply this technology

1104
00:35:59,760 --> 00:36:03,760
i think we've got about three and a half

1105
00:36:01,839 --> 00:36:05,359
minutes left for questions

1106
00:36:03,760 --> 00:36:07,200
uh thank you for attending my session if

1107
00:36:05,359 --> 00:36:10,480
you have any questions uh

1108
00:36:07,200 --> 00:36:11,598
there's an uh email there uh available

1109
00:36:10,480 --> 00:36:15,680
on twitter as well

1110
00:36:11,599 --> 00:36:18,240
uh and i will uh give some time here now

1111
00:36:15,680 --> 00:36:19,759
for your questions uh before the next

1112
00:36:18,240 --> 00:36:21,520
video comes up

1113
00:36:19,760 --> 00:36:24,240
thank you very much john that was really

1114
00:36:21,520 --> 00:36:26,480
really interesting i'm sure um

1115
00:36:24,240 --> 00:36:28,479
it was uh quite quite interesting to

1116
00:36:26,480 --> 00:36:31,119
kind of leverage your your phd studies

1117
00:36:28,480 --> 00:36:32,400
in the in in this field as well right so

1118
00:36:31,119 --> 00:36:34,480
it's really really good when you can do

1119
00:36:32,400 --> 00:36:35,599
that uh two birds one stone and all that

1120
00:36:34,480 --> 00:36:39,200
um

1121
00:36:35,599 --> 00:36:41,040
yeah um so i did have a question for you

1122
00:36:39,200 --> 00:36:43,359
so there was a presentation earlier

1123
00:36:41,040 --> 00:36:44,240
uh from australia's e-safety

1124
00:36:43,359 --> 00:36:46,799
commissioner

1125
00:36:44,240 --> 00:36:48,720
and she was asked whether or not the

1126
00:36:46,800 --> 00:36:51,440
technology companies were doing enough

1127
00:36:48,720 --> 00:36:53,759
for safety or whether it's it a problem

1128
00:36:51,440 --> 00:36:55,920
that's a little bit too hard to solve

1129
00:36:53,760 --> 00:36:57,280
in your opinion do you feel as though a

1130
00:36:55,920 --> 00:37:00,000
lot of the tech companies

1131
00:36:57,280 --> 00:37:02,079
are using machine learning uh in the

1132
00:37:00,000 --> 00:37:05,200
appropriate ways to kind of

1133
00:37:02,079 --> 00:37:07,520
potentially limit the

1134
00:37:05,200 --> 00:37:08,480
the threat to democracy or the threat to

1135
00:37:07,520 --> 00:37:10,000
kind of

1136
00:37:08,480 --> 00:37:11,520
these types of things that we have seen

1137
00:37:10,000 --> 00:37:12,160
you know potentially in the 2016

1138
00:37:11,520 --> 00:37:14,320
elections

1139
00:37:12,160 --> 00:37:15,759
you know in in in your neck of the woods

1140
00:37:14,320 --> 00:37:19,119
in the u.s

1141
00:37:15,760 --> 00:37:21,520
um i every time you know most days

1142
00:37:19,119 --> 00:37:22,800
i go to twitter and i look at trending

1143
00:37:21,520 --> 00:37:24,880
topics

1144
00:37:22,800 --> 00:37:26,320
and i mean i don't know who's

1145
00:37:24,880 --> 00:37:27,119
manipulating it but i know it's

1146
00:37:26,320 --> 00:37:30,400
manipulated

1147
00:37:27,119 --> 00:37:32,079
right um you know i said you dig into

1148
00:37:30,400 --> 00:37:35,280
amplification networks

1149
00:37:32,079 --> 00:37:36,240
it's it's you know with seo and social

1150
00:37:35,280 --> 00:37:38,960
media

1151
00:37:36,240 --> 00:37:40,240
we are really nowhere yeah maybe that's

1152
00:37:38,960 --> 00:37:43,040
too cynical

1153
00:37:40,240 --> 00:37:44,319
uh but i'm irish by heritage and

1154
00:37:43,040 --> 00:37:48,160
everything kind of sucks

1155
00:37:44,320 --> 00:37:51,680
so um uh we're not very far along

1156
00:37:48,160 --> 00:37:53,598
in trying to curate out manipulated

1157
00:37:51,680 --> 00:37:54,879
online content

1158
00:37:53,599 --> 00:37:57,599
you know and then whether that's

1159
00:37:54,880 --> 00:37:59,680
phishing emails efficient web pages or

1160
00:37:57,599 --> 00:38:01,280
uh manipulated search results or any of

1161
00:37:59,680 --> 00:38:01,680
that i mean it's it's a cat and mouse

1162
00:38:01,280 --> 00:38:04,560
game

1163
00:38:01,680 --> 00:38:06,480
nobody has solved that they're trying

1164
00:38:04,560 --> 00:38:08,320
but i don't know that it's a terribly

1165
00:38:06,480 --> 00:38:10,320
solvable problem

1166
00:38:08,320 --> 00:38:11,839
uh based on the techniques and what

1167
00:38:10,320 --> 00:38:13,760
we're trying to do today

1168
00:38:11,839 --> 00:38:15,279
um so yeah we're still seeing

1169
00:38:13,760 --> 00:38:17,839
manipulated content the difference

1170
00:38:15,280 --> 00:38:19,359
between 2016 and 2020

1171
00:38:17,839 --> 00:38:21,520
from the united states perspective in

1172
00:38:19,359 --> 00:38:24,480
foreign adversaries is that

1173
00:38:21,520 --> 00:38:26,640
russia was predominantly the one trying

1174
00:38:24,480 --> 00:38:28,079
to influence in 2016.

1175
00:38:26,640 --> 00:38:30,640
now there's several other countries

1176
00:38:28,079 --> 00:38:32,480
doing it as well and they have divergent

1177
00:38:30,640 --> 00:38:34,480
incentives so i don't know if it's

1178
00:38:32,480 --> 00:38:35,119
canceled out right russia wants to have

1179
00:38:34,480 --> 00:38:37,200
trump win

1180
00:38:35,119 --> 00:38:38,880
china wants biden to win they're both

1181
00:38:37,200 --> 00:38:42,240
relatively sophisticated as their

1182
00:38:38,880 --> 00:38:46,960
influence cancelling each other out

1183
00:38:42,240 --> 00:38:46,959
that's really fun two big waves kind

1184
00:38:52,320 --> 00:38:55,920
uh and we've got about 40 seconds left

1185
00:38:54,560 --> 00:38:59,440
so there is one question

1186
00:38:55,920 --> 00:39:01,599
in the q a tab is there any category

1187
00:38:59,440 --> 00:39:02,079
slash use cases where you find machine

1188
00:39:01,599 --> 00:39:04,480
learning

1189
00:39:02,079 --> 00:39:06,560
to be better or more reliable than

1190
00:39:04,480 --> 00:39:08,800
others

1191
00:39:06,560 --> 00:39:08,799
um

1192
00:39:09,599 --> 00:39:12,720
i said i mean it really it depends on

1193
00:39:11,520 --> 00:39:14,880
the on on

1194
00:39:12,720 --> 00:39:16,640
just data that you start with i mean

1195
00:39:14,880 --> 00:39:18,480
natural language processing is

1196
00:39:16,640 --> 00:39:19,920
is pretty good depending on what you're

1197
00:39:18,480 --> 00:39:22,400
doing with it right

1198
00:39:19,920 --> 00:39:24,000
um i've got an amazon echo behind me i

1199
00:39:22,400 --> 00:39:24,880
can give it instructions and it's fairly

1200
00:39:24,000 --> 00:39:26,480
accurate

1201
00:39:24,880 --> 00:39:28,240
uh but we've all kind of seen the voice

1202
00:39:26,480 --> 00:39:31,200
recognition failures

1203
00:39:28,240 --> 00:39:33,118
um and cyber security is very difficult

1204
00:39:31,200 --> 00:39:34,879
because we don't have a lot of good

1205
00:39:33,119 --> 00:39:37,920
curated data sets

1206
00:39:34,880 --> 00:39:41,040
right could i model benign

1207
00:39:37,920 --> 00:39:42,960
uh endpoint behavior sure

1208
00:39:41,040 --> 00:39:44,880
if there's an enterprise out there in

1209
00:39:42,960 --> 00:39:47,119
the audience who is willing to let me

1210
00:39:44,880 --> 00:39:49,920
run an agent on all of their endpoints

1211
00:39:47,119 --> 00:39:50,800
and i'll anonymize the data to create a

1212
00:39:49,920 --> 00:39:53,119
a good

1213
00:39:50,800 --> 00:39:55,200
uh data set of benign workstation

1214
00:39:53,119 --> 00:39:57,119
behavior i'm more than happy to do it

1215
00:39:55,200 --> 00:39:59,200
but your counsel would say no because

1216
00:39:57,119 --> 00:40:00,400
it's a huge privacy and confidentiality

1217
00:39:59,200 --> 00:40:03,040
risk

1218
00:40:00,400 --> 00:40:04,800
right well thank you very much for the

1219
00:40:03,040 --> 00:40:05,839
great presentation and if there are any

1220
00:40:04,800 --> 00:40:07,839
other questions from

1221
00:40:05,839 --> 00:40:09,680
any of the members of the audience

1222
00:40:07,839 --> 00:40:11,440
please do please do reach out to john

1223
00:40:09,680 --> 00:40:12,240
his contact details are on the slide

1224
00:40:11,440 --> 00:40:14,880
just there

1225
00:40:12,240 --> 00:40:16,479
thanks again um enjoy your evening and

1226
00:40:14,880 --> 00:40:18,319
hopefully you can you can stick around

1227
00:40:16,480 --> 00:40:21,440
and see some presentations and

1228
00:40:18,319 --> 00:40:25,839
before it becomes too late in your time

1229
00:40:21,440 --> 00:40:25,839
and thanks again and take care thank you

