1
00:00:00,000 --> 00:00:03,540
for our last session in this room we've

2
00:00:02,129 --> 00:00:05,580
got Gary Gaskell talking about

3
00:00:03,540 --> 00:00:08,129
influencing security decisions and

4
00:00:05,580 --> 00:00:10,050
hopefully giving us some great tools and

5
00:00:08,130 --> 00:00:11,639
techniques for managing up words and

6
00:00:10,050 --> 00:00:18,660
probably our peers and downwards even

7
00:00:11,639 --> 00:00:20,009
please welcome Gary thank you it's it's

8
00:00:18,660 --> 00:00:22,859
a pleasure to be here today and I

9
00:00:20,010 --> 00:00:26,060
thought I'd start out talking about just

10
00:00:22,859 --> 00:00:30,660
seems to be echoing back at me sorry oh

11
00:00:26,060 --> 00:00:33,629
that's why to start talking about why

12
00:00:30,660 --> 00:00:35,850
because I've come to these conferences

13
00:00:33,630 --> 00:00:38,940
for many years I started out as a tech

14
00:00:35,850 --> 00:00:40,710
26 years ago or something and you have a

15
00:00:38,940 --> 00:00:43,110
lot of discussions and coffees with

16
00:00:40,710 --> 00:00:46,350
people going it just doesn't make sense

17
00:00:43,110 --> 00:00:49,760
I've done the best analysis we've got

18
00:00:46,350 --> 00:00:52,170
this system web application with no

19
00:00:49,760 --> 00:00:54,629
admin access control or something this

20
00:00:52,170 --> 00:00:56,640
just seems to be insane and you're

21
00:00:54,629 --> 00:00:59,339
trying to get things fixed and people

22
00:00:56,640 --> 00:01:00,780
put roadblocks in your way they don't

23
00:00:59,340 --> 00:01:02,309
give you the downtime permission they

24
00:01:00,780 --> 00:01:04,349
don't give you the minor money or they

25
00:01:02,309 --> 00:01:06,330
don't give you the big money and people

26
00:01:04,349 --> 00:01:08,750
have been very frustrated and I've

27
00:01:06,330 --> 00:01:12,929
sympathized with them for many years

28
00:01:08,750 --> 00:01:15,060
and a few years ago so that's why I'm

29
00:01:12,930 --> 00:01:17,070
here that's what I'm gonna I'm talking

30
00:01:15,060 --> 00:01:18,720
to share my insights I'm not a

31
00:01:17,070 --> 00:01:20,820
psychologist I come from a tech

32
00:01:18,720 --> 00:01:22,320
background I do a lot of security

33
00:01:20,820 --> 00:01:25,020
management risk management sort of stuff

34
00:01:22,320 --> 00:01:26,729
these days but I'm trying to make sense

35
00:01:25,020 --> 00:01:29,908
of it myself so I started doing some

36
00:01:26,729 --> 00:01:32,009
research but probably about five or six

37
00:01:29,909 --> 00:01:36,119
years ago I sat down and looked at all

38
00:01:32,009 --> 00:01:39,450
the reviews are done and over all the

39
00:01:36,119 --> 00:01:42,570
years and I looked probably that it was

40
00:01:39,450 --> 00:01:45,000
a small majority where people said thank

41
00:01:42,570 --> 00:01:47,850
you I'm glad you found it and we fix it

42
00:01:45,000 --> 00:01:51,899
that's fantastic then there's probably

43
00:01:47,850 --> 00:01:53,220
another 20 or 30% that said great but

44
00:01:51,899 --> 00:01:57,000
you go back or you can see them in the

45
00:01:53,220 --> 00:01:58,469
street a year later and I go and you go

46
00:01:57,000 --> 00:01:59,430
how you're going to go yeah we know

47
00:01:58,469 --> 00:02:02,548
we've got to act but we haven't done

48
00:01:59,430 --> 00:02:04,560
anything yet and then is about the five

49
00:02:02,549 --> 00:02:07,020
or ten percent or just straight-out

50
00:02:04,560 --> 00:02:09,179
denial their attack you it's really

51
00:02:07,020 --> 00:02:11,459
awful sort of thing and I was trying to

52
00:02:09,179 --> 00:02:13,470
understand that like how did how did

53
00:02:11,459 --> 00:02:14,010
that sort of small majority say sixty

54
00:02:13,470 --> 00:02:15,870
percent

55
00:02:14,010 --> 00:02:18,179
actually go thank you and start acting

56
00:02:15,870 --> 00:02:20,310
straightaway what was the difference

57
00:02:18,180 --> 00:02:23,880
that created at last ten percent that

58
00:02:20,310 --> 00:02:25,860
were totally in denial and hostile to me

59
00:02:23,880 --> 00:02:27,390
attack my reputation you know this is

60
00:02:25,860 --> 00:02:29,670
the sort of thing where you find 50

61
00:02:27,390 --> 00:02:31,679
issues and but you made one mistake and

62
00:02:29,670 --> 00:02:34,799
they try and just discredit you for the

63
00:02:31,680 --> 00:02:35,670
one mistake when 99% of the analysis is

64
00:02:34,800 --> 00:02:37,920
just spot-on

65
00:02:35,670 --> 00:02:41,190
like what's motivating him to be like

66
00:02:37,920 --> 00:02:44,250
that so that's where this started and I

67
00:02:41,190 --> 00:02:45,660
hope some of it can help you as well if

68
00:02:44,250 --> 00:02:47,130
you've got to make sure insights I'd

69
00:02:45,660 --> 00:02:50,040
love you to share that with me because I

70
00:02:47,130 --> 00:02:51,390
can I loved reading in this space like

71
00:02:50,040 --> 00:02:53,579
we all know it's hard to keep up with

72
00:02:51,390 --> 00:02:55,920
the tech james's and what we need to

73
00:02:53,580 --> 00:02:58,790
know to protect something in the cloud

74
00:02:55,920 --> 00:03:01,290
or some extra container security stuff

75
00:02:58,790 --> 00:03:04,048
but this stuff's also fascinating and

76
00:03:01,290 --> 00:03:05,970
it's it's fun stuff to listen to podcast

77
00:03:04,049 --> 00:03:07,980
podcast like Mark was talking about is

78
00:03:05,970 --> 00:03:09,480
he's one of my favorite ways because I

79
00:03:07,980 --> 00:03:10,890
can do a lot of this stuff while I'm

80
00:03:09,480 --> 00:03:15,260
driving for kids and all that sort of

81
00:03:10,890 --> 00:03:18,358
stuff so that's how we got here

82
00:03:15,260 --> 00:03:19,679
but then a friend was doing his PhD on

83
00:03:18,359 --> 00:03:22,410
risk management he said Gary

84
00:03:19,680 --> 00:03:24,239
you need to read Kahneman and that

85
00:03:22,410 --> 00:03:25,799
opened my eyes because I actually had

86
00:03:24,239 --> 00:03:27,660
thought had gone back to theory books on

87
00:03:25,799 --> 00:03:29,070
how to write better reports because I

88
00:03:27,660 --> 00:03:31,829
thought it was my communication skills

89
00:03:29,070 --> 00:03:33,930
and when he introduced me to Carmen and

90
00:03:31,829 --> 00:03:36,570
he's talking about people don't always

91
00:03:33,930 --> 00:03:38,370
make rational decisions because that guy

92
00:03:36,570 --> 00:03:39,510
ended up the Nobel Prize for that so

93
00:03:38,370 --> 00:03:42,049
we're gonna talk so that's what we're

94
00:03:39,510 --> 00:03:44,790
going to talk about but we're talking

95
00:03:42,049 --> 00:03:47,340
the part of the purposes from what I've

96
00:03:44,790 --> 00:03:50,010
learned and maybe you can use some of it

97
00:03:47,340 --> 00:03:51,450
yourself to increase your odds when

98
00:03:50,010 --> 00:03:53,880
you're communicating with senior

99
00:03:51,450 --> 00:03:56,040
management because they typically talk a

100
00:03:53,880 --> 00:03:59,609
different language than we do in the

101
00:03:56,040 --> 00:04:02,340
security services section right I think

102
00:03:59,609 --> 00:04:04,620
they they they could actually be often

103
00:04:02,340 --> 00:04:06,359
talking in pidgin English and we come

104
00:04:04,620 --> 00:04:08,250
along with our big vocabulary from our

105
00:04:06,359 --> 00:04:10,350
tech background and we just sound like

106
00:04:08,250 --> 00:04:11,790
we're speaking of foreign language so we

107
00:04:10,350 --> 00:04:13,620
need to help know how to communicate

108
00:04:11,790 --> 00:04:16,649
with them so if we can improve some of

109
00:04:13,620 --> 00:04:17,519
that so stuff for you and some benefits

110
00:04:16,649 --> 00:04:19,469
for them as well

111
00:04:17,519 --> 00:04:22,800
because they might get get the message a

112
00:04:19,470 --> 00:04:24,419
bit more clearly but hopefully this will

113
00:04:22,800 --> 00:04:26,630
help you get some buy-in for security

114
00:04:24,419 --> 00:04:26,630
plans

115
00:04:26,670 --> 00:04:31,080
and please use it for good because

116
00:04:28,950 --> 00:04:33,330
certainly some of this stuff gets used

117
00:04:31,080 --> 00:04:36,450
for evil as we can see in some political

118
00:04:33,330 --> 00:04:38,550
marketing campaigns maybe some of the

119
00:04:36,450 --> 00:04:40,740
denial stuff and creating fear

120
00:04:38,550 --> 00:04:43,170
uncertainty and doubt meant we meant we

121
00:04:40,740 --> 00:04:45,660
had asbestos and tobacco for many more

122
00:04:43,170 --> 00:04:47,370
years before we should the same

123
00:04:45,660 --> 00:04:51,030
behavioral science can be used for good

124
00:04:47,370 --> 00:04:53,340
and bad so essentially we're going to

125
00:04:51,030 --> 00:04:56,099
talk about what we know now from social

126
00:04:53,340 --> 00:05:00,179
scientists on us the science of making

127
00:04:56,100 --> 00:05:01,500
decisions and that you know essentially

128
00:05:00,180 --> 00:05:04,350
that's we call it judgments or

129
00:05:01,500 --> 00:05:05,670
decision-making and we're going to talk

130
00:05:04,350 --> 00:05:07,860
a little bit about putting that to work

131
00:05:05,670 --> 00:05:09,150
I have been trying to put some of this

132
00:05:07,860 --> 00:05:11,730
to work the last few years

133
00:05:09,150 --> 00:05:14,190
I remember presenting it at audit risk

134
00:05:11,730 --> 00:05:15,930
committee of a board and the chair of

135
00:05:14,190 --> 00:05:17,820
the board came up afterwards later and

136
00:05:15,930 --> 00:05:19,230
said fantastic I had you how did you get

137
00:05:17,820 --> 00:05:21,180
to CEO ohnparrot

138
00:05:19,230 --> 00:05:22,500
how did they do that right because we

139
00:05:21,180 --> 00:05:24,630
talked about it in terms of what it

140
00:05:22,500 --> 00:05:27,150
meant to them and we're inside the team

141
00:05:24,630 --> 00:05:29,909
and the audit report wasn't a critique

142
00:05:27,150 --> 00:05:31,950
it was like here's something if you care

143
00:05:29,910 --> 00:05:33,660
it might help you protect yourself

144
00:05:31,950 --> 00:05:37,969
rather than I'm telling you you're doing

145
00:05:33,660 --> 00:05:40,380
a crap job and it changed the discussion

146
00:05:37,970 --> 00:05:42,540
so that's we're going to talk about

147
00:05:40,380 --> 00:05:44,159
I was also as I said I I'm not a

148
00:05:42,540 --> 00:05:47,580
psychologist I come from and tech

149
00:05:44,160 --> 00:05:49,770
background and it's the first time I've

150
00:05:47,580 --> 00:05:52,340
attempted to give this talk so we'll see

151
00:05:49,770 --> 00:05:55,469
how we go in terms of content and Jamie

152
00:05:52,340 --> 00:05:57,060
sorry going to create James it's hard to

153
00:05:55,470 --> 00:06:00,480
change old habits later mark you'll give

154
00:05:57,060 --> 00:06:02,670
us a five minute warning way to yeah but

155
00:06:00,480 --> 00:06:05,190
if we we think about it if we're doing

156
00:06:02,670 --> 00:06:07,260
risk assessments our goals aren't to go

157
00:06:05,190 --> 00:06:08,490
through the methodical process like

158
00:06:07,260 --> 00:06:09,810
we're talking about the other day

159
00:06:08,490 --> 00:06:12,720
because we're an attitude here on risk

160
00:06:09,810 --> 00:06:14,310
management what we really want is making

161
00:06:12,720 --> 00:06:16,890
good decisions that's what we're really

162
00:06:14,310 --> 00:06:18,930
about and if we're putting a business

163
00:06:16,890 --> 00:06:21,690
case up to get twenty million dollars

164
00:06:18,930 --> 00:06:23,310
for our security program because we've

165
00:06:21,690 --> 00:06:24,930
got to do an uplift and a lot of us are

166
00:06:23,310 --> 00:06:26,640
doing that that's why this conference is

167
00:06:24,930 --> 00:06:30,180
so big it's it's why it's outgrown this

168
00:06:26,640 --> 00:06:34,560
hotel like it's it's totally chokers and

169
00:06:30,180 --> 00:06:36,150
I think the first security conference I

170
00:06:34,560 --> 00:06:38,520
went to was a crypto conference here on

171
00:06:36,150 --> 00:06:41,969
the Gold Coast in 92 I think there's 120

172
00:06:38,520 --> 00:06:45,039
people but the game's just chained

173
00:06:41,970 --> 00:06:47,140
so we've got to get these business cases

174
00:06:45,040 --> 00:06:49,660
up and that's that's what a lot of us

175
00:06:47,140 --> 00:06:52,450
are doing so what we're going to talk

176
00:06:49,660 --> 00:06:54,760
about in this decision Theory until

177
00:06:52,450 --> 00:06:56,590
Kahneman and Tversky came out with their

178
00:06:54,760 --> 00:06:59,860
stuff saying we actually make strange

179
00:06:56,590 --> 00:07:01,929
decisions at times economists money

180
00:06:59,860 --> 00:07:04,120
talked about the rational person theory

181
00:07:01,930 --> 00:07:06,430
that everyone made rational decisions

182
00:07:04,120 --> 00:07:08,560
because they evaluated it for themselves

183
00:07:06,430 --> 00:07:11,020
and under that theory would never have

184
00:07:08,560 --> 00:07:13,180
stock market bubbles Sydney house prices

185
00:07:11,020 --> 00:07:15,909
wouldn't be 14 times average incomes

186
00:07:13,180 --> 00:07:17,650
that sort of thing but we know these we

187
00:07:15,910 --> 00:07:21,550
do have property bubbles and stuff like

188
00:07:17,650 --> 00:07:24,310
that also in this case making judgments

189
00:07:21,550 --> 00:07:27,940
it's human nature to be uncomfortable

190
00:07:24,310 --> 00:07:29,740
with uncertainty so there's a lot of

191
00:07:27,940 --> 00:07:33,310
people here and I think our profession

192
00:07:29,740 --> 00:07:35,200
attracts a certain personality where we

193
00:07:33,310 --> 00:07:37,570
gravitate to having a lot of comfort we

194
00:07:35,200 --> 00:07:39,670
get more information and we try and

195
00:07:37,570 --> 00:07:41,290
collect so much information so we can

196
00:07:39,670 --> 00:07:43,150
maximize our decisions and make a

197
00:07:41,290 --> 00:07:45,400
perfect decision and we're really

198
00:07:43,150 --> 00:07:46,630
nervous if we push to make an early

199
00:07:45,400 --> 00:07:51,099
decision based on partial information

200
00:07:46,630 --> 00:07:55,990
and just being aware of that really

201
00:07:51,100 --> 00:07:58,840
helps we can also have fear of hindsight

202
00:07:55,990 --> 00:08:00,970
judgments so if I make a decision it's

203
00:07:58,840 --> 00:08:02,919
it's it's a line in the ground and then

204
00:08:00,970 --> 00:08:04,750
something might go wrong and come back

205
00:08:02,920 --> 00:08:06,280
and someone all judge me and this

206
00:08:04,750 --> 00:08:08,530
happens when we have royal commissions

207
00:08:06,280 --> 00:08:09,640
I was watching closely the Royal

208
00:08:08,530 --> 00:08:11,919
Commission in the Queensland Health

209
00:08:09,640 --> 00:08:13,840
payroll and the retired judge and the

210
00:08:11,920 --> 00:08:16,440
barristers were quizzing the CIO on

211
00:08:13,840 --> 00:08:18,820
risk-based decision he had made and

212
00:08:16,440 --> 00:08:20,500
pretty clearly that when you're in a

213
00:08:18,820 --> 00:08:22,360
courtroom being quizzed by barristers

214
00:08:20,500 --> 00:08:24,160
it's not a great day at work when

215
00:08:22,360 --> 00:08:26,290
someone's second-guessing your decision

216
00:08:24,160 --> 00:08:27,880
that you're made on a small amount of

217
00:08:26,290 --> 00:08:30,370
information you didn't like they've

218
00:08:27,880 --> 00:08:31,750
spent months reading all the paperwork

219
00:08:30,370 --> 00:08:34,020
and you've got a paper and you made a

220
00:08:31,750 --> 00:08:37,809
decision by lunchtime that's not a great

221
00:08:34,020 --> 00:08:41,140
great comfortable situation but

222
00:08:37,809 --> 00:08:44,290
essentially uncertainty can unsettles

223
00:08:41,140 --> 00:08:46,180
people and what I'm talking about us

224
00:08:44,290 --> 00:08:48,339
making decisions it's also our

225
00:08:46,180 --> 00:08:50,560
executives so you put your business case

226
00:08:48,340 --> 00:08:53,500
on the table and the executives are also

227
00:08:50,560 --> 00:08:55,030
going what decision do I have to base

228
00:08:53,500 --> 00:08:57,010
this decision on

229
00:08:55,030 --> 00:09:00,430
Gary seems to know his stuff he's been

230
00:08:57,010 --> 00:09:02,350
here for a little while but what if what

231
00:09:00,430 --> 00:09:05,229
if he's a bit bias what if he's too

232
00:09:02,350 --> 00:09:06,640
passionate about his area and he's

233
00:09:05,230 --> 00:09:08,110
asking for 20 mil and I should be

234
00:09:06,640 --> 00:09:09,310
spending two mil because I should be

235
00:09:08,110 --> 00:09:12,220
spending the rest of money on something

236
00:09:09,310 --> 00:09:13,900
else that's those sort of things are

237
00:09:12,220 --> 00:09:18,580
going through the mind of your CFO or

238
00:09:13,900 --> 00:09:20,260
your CEO and just so I've got a lot a

239
00:09:18,580 --> 00:09:24,880
few words and the slide money to prompt

240
00:09:20,260 --> 00:09:26,770
me speaking but we can if we go from

241
00:09:24,880 --> 00:09:29,560
simple to complicated situations and

242
00:09:26,770 --> 00:09:30,939
let's face it the way cybersecurity is

243
00:09:29,560 --> 00:09:33,280
so intermeshed it's often very

244
00:09:30,940 --> 00:09:35,950
complicated we can fix one problem and

245
00:09:33,280 --> 00:09:37,930
it impacts something else over here

246
00:09:35,950 --> 00:09:40,390
psychologists call about cognitive load

247
00:09:37,930 --> 00:09:44,170
it gets so much people flip out and just

248
00:09:40,390 --> 00:09:47,699
go no just give me a or B type stuff we

249
00:09:44,170 --> 00:09:49,540
overload and if we're overloading people

250
00:09:47,700 --> 00:09:51,730
particularly people in stressful

251
00:09:49,540 --> 00:09:59,469
situations we don't tend to make the

252
00:09:51,730 --> 00:10:02,410
right decisions so anyway I just wanted

253
00:09:59,470 --> 00:10:04,570
to put some stuff out right but this is

254
00:10:02,410 --> 00:10:06,520
like the second guessing like door

255
00:10:04,570 --> 00:10:08,020
really trust him so they go do some

256
00:10:06,520 --> 00:10:10,210
google search in the first couple things

257
00:10:08,020 --> 00:10:11,710
pop up may well be what's perceived to

258
00:10:10,210 --> 00:10:13,750
be the truth rather than what you've

259
00:10:11,710 --> 00:10:15,820
just spent a month doing your analysis

260
00:10:13,750 --> 00:10:21,160
to put up your security program sort of

261
00:10:15,820 --> 00:10:25,540
stuff so here's a quick quote from CS

262
00:10:21,160 --> 00:10:27,760
Lewis and I think there's some important

263
00:10:25,540 --> 00:10:29,740
message from this is what we what we

264
00:10:27,760 --> 00:10:32,230
what we perceive and what we hear it

265
00:10:29,740 --> 00:10:37,000
depends on where we're standing and that

266
00:10:32,230 --> 00:10:38,650
if we take that on board is our role say

267
00:10:37,000 --> 00:10:41,710
we're a size o somewhere a security

268
00:10:38,650 --> 00:10:44,410
manager we think the world is the way we

269
00:10:41,710 --> 00:10:47,500
see it but a CFO might be might be

270
00:10:44,410 --> 00:10:50,439
coming in on a perpendicular level of or

271
00:10:47,500 --> 00:10:51,640
view of the same environment and I have

272
00:10:50,440 --> 00:10:54,010
a different view of it they hear a

273
00:10:51,640 --> 00:10:56,199
different message they might just hear a

274
00:10:54,010 --> 00:10:59,560
passionate person who thinks we've got

275
00:10:56,200 --> 00:11:01,690
to have zero risk and it needs a hundred

276
00:10:59,560 --> 00:11:04,359
million dollars that's that's the way

277
00:11:01,690 --> 00:11:05,620
they start thinking about it and if we

278
00:11:04,360 --> 00:11:08,080
can be aware of these different

279
00:11:05,620 --> 00:11:10,090
perspectives maybe we can head off

280
00:11:08,080 --> 00:11:12,340
some of those perceptions rather than

281
00:11:10,090 --> 00:11:16,930
just coming in I've got the only way of

282
00:11:12,340 --> 00:11:19,300
viewing this thing now let's say we

283
00:11:16,930 --> 00:11:21,040
we're talking about making decisions and

284
00:11:19,300 --> 00:11:22,209
it's not always the rational person

285
00:11:21,040 --> 00:11:24,849
thing there's a lot of other things

286
00:11:22,210 --> 00:11:27,880
reflect it so particularly as we get up

287
00:11:24,850 --> 00:11:31,600
in more senior management we can be seen

288
00:11:27,880 --> 00:11:34,600
that our decisions reflect who we are so

289
00:11:31,600 --> 00:11:36,490
if you CEOs an accountant that might

290
00:11:34,600 --> 00:11:37,990
impact the way they think because part

291
00:11:36,490 --> 00:11:39,820
of their identity is they're very

292
00:11:37,990 --> 00:11:41,980
prudent financial managers they don't go

293
00:11:39,820 --> 00:11:43,600
wasting money on things and if you come

294
00:11:41,980 --> 00:11:45,460
in with a business case that says I need

295
00:11:43,600 --> 00:11:47,800
a lot of money really urgently and stuff

296
00:11:45,460 --> 00:11:49,600
and they go why never do things urgently

297
00:11:47,800 --> 00:11:52,329
I always do things prudently always

298
00:11:49,600 --> 00:11:54,610
analyze things always cut the cost down

299
00:11:52,330 --> 00:11:56,740
to minimize that sort of stuff that's

300
00:11:54,610 --> 00:11:58,960
how they perceive themselves making

301
00:11:56,740 --> 00:12:00,880
decisions hello how they want to be

302
00:11:58,960 --> 00:12:09,430
perceived so that drives their

303
00:12:00,880 --> 00:12:11,110
decision-making process sorry I'm a

304
00:12:09,430 --> 00:12:14,560
little nervous making this talk because

305
00:12:11,110 --> 00:12:17,020
I don't know why but I've been nervous

306
00:12:14,560 --> 00:12:19,119
talking at a conference for 10 years so

307
00:12:17,020 --> 00:12:22,600
but maybe because it's a new topic for

308
00:12:19,120 --> 00:12:26,490
me so I'm throwing up a lot of things to

309
00:12:22,600 --> 00:12:29,320
think about there's a great book about

310
00:12:26,490 --> 00:12:30,120
making decisions as bets like and we

311
00:12:29,320 --> 00:12:32,110
talked about in risk management

312
00:12:30,120 --> 00:12:34,720
improving our odds if we go through a

313
00:12:32,110 --> 00:12:36,670
bit of a reasonable analysis I think

314
00:12:34,720 --> 00:12:37,570
it's Annie Dukes thinking in bets book

315
00:12:36,670 --> 00:12:40,209
which is really

316
00:12:37,570 --> 00:12:42,040
Reverend Bayes theorem from the 1970s

317
00:12:40,210 --> 00:12:47,980
but couched in the way of management

318
00:12:42,040 --> 00:12:49,660
language today so there's another field

319
00:12:47,980 --> 00:12:52,210
of behavioral science talking about

320
00:12:49,660 --> 00:12:54,189
common knowledge but to create joke

321
00:12:52,210 --> 00:12:56,620
about it is the perception of common

322
00:12:54,190 --> 00:12:58,990
knowledge that the knowledge is the

323
00:12:56,620 --> 00:13:00,670
common knowledge isn't common and I

324
00:12:58,990 --> 00:13:02,950
think that applies to our community

325
00:13:00,670 --> 00:13:04,240
right so a lot of people here whether

326
00:13:02,950 --> 00:13:05,950
you're in the real tech side of the

327
00:13:04,240 --> 00:13:07,810
thing or the the security management

328
00:13:05,950 --> 00:13:10,000
side of what we think how the world

329
00:13:07,810 --> 00:13:11,800
works we perceive as common knowledge we

330
00:13:10,000 --> 00:13:14,260
think everyone understands that it's

331
00:13:11,800 --> 00:13:16,240
just obvious but that knowledge isn't

332
00:13:14,260 --> 00:13:18,640
common around the board table or the

333
00:13:16,240 --> 00:13:20,830
executive leadership team so we've got

334
00:13:18,640 --> 00:13:23,160
some communication tasks to do in that

335
00:13:20,830 --> 00:13:23,160
space

336
00:13:24,740 --> 00:13:29,839
so I feel it doesn't quite flow

337
00:13:27,410 --> 00:13:33,620
perfectly but another part of

338
00:13:29,839 --> 00:13:35,420
decision-making is where people they go

339
00:13:33,620 --> 00:13:36,680
Gary's asking for money he claims to be

340
00:13:35,420 --> 00:13:39,589
a security expert he's got a couple

341
00:13:36,680 --> 00:13:43,819
certifications and did some masters far

342
00:13:39,589 --> 00:13:45,320
too long ago but how do I I'm a CEO

343
00:13:43,820 --> 00:13:47,120
who's done accountancy or law or

344
00:13:45,320 --> 00:13:50,690
something maybe even engineering in a

345
00:13:47,120 --> 00:13:53,690
mining company how do I know that he's

346
00:13:50,690 --> 00:13:56,810
he's he's the goods and he's just not

347
00:13:53,690 --> 00:14:00,579
self-deluded sort of person these can be

348
00:13:56,810 --> 00:14:03,469
a subconscious process or really overtly

349
00:14:00,579 --> 00:14:06,439
conscious process so they make decisions

350
00:14:03,470 --> 00:14:09,380
by proxy and we all we've all probably

351
00:14:06,440 --> 00:14:12,320
been at work when big for consultancy

352
00:14:09,380 --> 00:14:15,439
turns up on McKinsey they always walk in

353
00:14:12,320 --> 00:14:18,170
in their suits right because maybe

354
00:14:15,440 --> 00:14:21,589
they're accountants or whatever but they

355
00:14:18,170 --> 00:14:23,899
they look like there should be in the

356
00:14:21,589 --> 00:14:25,730
board table room because of the way

357
00:14:23,899 --> 00:14:27,649
they're dressed and they get some

358
00:14:25,730 --> 00:14:30,199
credibility because maybe that's a

359
00:14:27,649 --> 00:14:31,490
$2,000 suit and you bought your suit at

360
00:14:30,199 --> 00:14:32,810
Lowe's or you don't ever wear a suit

361
00:14:31,490 --> 00:14:33,949
because you just wear a black t-shirt to

362
00:14:32,810 --> 00:14:36,550
work

363
00:14:33,949 --> 00:14:39,469
so the concept I'm introducing here is

364
00:14:36,550 --> 00:14:41,779
people who don't have the skills to know

365
00:14:39,470 --> 00:14:44,570
whether we are good at our job make

366
00:14:41,779 --> 00:14:46,790
decisions by proxy often it's the way we

367
00:14:44,570 --> 00:14:48,829
dress it might be we went to the same

368
00:14:46,790 --> 00:14:54,490
school and that's a terrible thing but

369
00:14:48,829 --> 00:14:58,160
it's a real thing it could be we make

370
00:14:54,490 --> 00:15:00,290
comments about we're in the same view on

371
00:14:58,160 --> 00:15:03,290
the world in terms of politics or

372
00:15:00,290 --> 00:15:06,140
approach to this organization making

373
00:15:03,290 --> 00:15:09,849
decisions by proxy might be we're

374
00:15:06,140 --> 00:15:09,850
driving the right type of car who knows

375
00:15:11,410 --> 00:15:16,610
so essentially we're trying to influence

376
00:15:14,600 --> 00:15:18,829
these decisions so go back nearly two

377
00:15:16,610 --> 00:15:21,079
and a half thousand years to Aristotle

378
00:15:18,829 --> 00:15:23,959
and he was talking about this three main

379
00:15:21,079 --> 00:15:26,810
aspects to it and I think if we listen

380
00:15:23,959 --> 00:15:29,359
to what Aristotle said to say a lot of

381
00:15:26,810 --> 00:15:32,000
us have been using just the one way to

382
00:15:29,360 --> 00:15:34,279
try and get the decisions we think the

383
00:15:32,000 --> 00:15:35,590
organization needs going near the

384
00:15:34,279 --> 00:15:37,870
logical approach

385
00:15:35,590 --> 00:15:40,630
but he said we've got a couple other

386
00:15:37,870 --> 00:15:43,360
ways we make decisions by social things

387
00:15:40,630 --> 00:15:47,140
that's like we trust people from inside

388
00:15:43,360 --> 00:15:51,610
the tent so maybe it's useful if we're

389
00:15:47,140 --> 00:15:53,380
working for bhp maybe we wear a suit but

390
00:15:51,610 --> 00:15:55,420
maybe you should have bit put a bhp

391
00:15:53,380 --> 00:15:56,560
t-shirt on that when we're going up and

392
00:15:55,420 --> 00:15:58,569
talking to people because we're inside

393
00:15:56,560 --> 00:16:00,459
the organization we're protecting from

394
00:15:58,570 --> 00:16:03,839
the inside rather than coming from

395
00:16:00,460 --> 00:16:06,940
outside and telling someone what to do

396
00:16:03,839 --> 00:16:09,070
so and then his middle one there is you

397
00:16:06,940 --> 00:16:11,200
know the pathos is appeal to the

398
00:16:09,070 --> 00:16:13,360
audience's emotion because people make

399
00:16:11,200 --> 00:16:15,190
emotional decisions and I think one of

400
00:16:13,360 --> 00:16:17,620
the great lines from Gruen show if

401
00:16:15,190 --> 00:16:20,860
anyone watches it I've been a fan anyone

402
00:16:17,620 --> 00:16:22,120
a few people here imagine the people at

403
00:16:20,860 --> 00:16:23,710
this conference that come to this talk

404
00:16:22,120 --> 00:16:25,510
might be the sort of people who watch it

405
00:16:23,710 --> 00:16:26,860
but I remember one of those shows they

406
00:16:25,510 --> 00:16:29,500
are talking about some marketing

407
00:16:26,860 --> 00:16:32,560
campaign and one of the panelists just

408
00:16:29,500 --> 00:16:35,260
they just go stop stop everyone makes

409
00:16:32,560 --> 00:16:37,420
the emotional decisions then dresses it

410
00:16:35,260 --> 00:16:40,180
up as a logical decision as what one of

411
00:16:37,420 --> 00:16:41,800
the marketers said and I was like yeah

412
00:16:40,180 --> 00:16:45,219
that happens so much in our workplace

413
00:16:41,800 --> 00:16:46,900
right we want to think it's we've gone

414
00:16:45,220 --> 00:16:48,930
through an analytical approach but it's

415
00:16:46,900 --> 00:16:52,959
ends up being an emotional approach and

416
00:16:48,930 --> 00:16:55,209
I mean I'm on risking ground but

417
00:16:52,960 --> 00:16:57,580
Australian divorce rates fifty percent

418
00:16:55,210 --> 00:16:59,710
right so if we all made perfect rational

419
00:16:57,580 --> 00:17:01,920
decisions with perfect information there

420
00:16:59,710 --> 00:17:04,240
would be no divorce we'd all be and

421
00:17:01,920 --> 00:17:06,639
everyone behaves themselves all the time

422
00:17:04,240 --> 00:17:08,770
right but in the end we get it wrong all

423
00:17:06,640 --> 00:17:12,420
the time because we make quick emotional

424
00:17:08,770 --> 00:17:12,420
decisions that are quite bias

425
00:17:13,179 --> 00:17:18,130
well we're talking about changing these

426
00:17:15,579 --> 00:17:20,649
decisions so just dumping a lot of facts

427
00:17:18,130 --> 00:17:22,839
on people as a lot of security people do

428
00:17:20,650 --> 00:17:25,060
hey we're getting we're blocking a

429
00:17:22,839 --> 00:17:26,919
hundred thousand spam a day therefore we

430
00:17:25,060 --> 00:17:29,530
need to spend this money for something

431
00:17:26,920 --> 00:17:32,080
else that also doesn't always drive

432
00:17:29,530 --> 00:17:33,760
decisions dumping facts on people about

433
00:17:32,080 --> 00:17:36,970
the property market in Sydney Melbourne

434
00:17:33,760 --> 00:17:39,010
or Brisbane or the economics and this

435
00:17:36,970 --> 00:17:41,200
comes the political science love getting

436
00:17:39,010 --> 00:17:43,900
into this around planning elections and

437
00:17:41,200 --> 00:17:45,640
what politicians say to audiences but

438
00:17:43,900 --> 00:17:47,850
dumping facts about debt and I was

439
00:17:45,640 --> 00:17:49,600
watching the last election campaign

440
00:17:47,850 --> 00:17:52,090
hopefully from an unbiased

441
00:17:49,600 --> 00:17:54,309
perspective and let's talk about where

442
00:17:52,090 --> 00:17:55,809
the debt came from this and I like facts

443
00:17:54,309 --> 00:17:57,668
weren't coming into the discussion very

444
00:17:55,809 --> 00:17:59,320
much right and if you're on Twitter

445
00:17:57,669 --> 00:18:00,789
watching what economists say about the

446
00:17:59,320 --> 00:18:02,879
facts compared to what the politicians

447
00:18:00,789 --> 00:18:05,530
are saying it was chalk and cheese

448
00:18:02,880 --> 00:18:07,270
but the politicians were the ones that

449
00:18:05,530 --> 00:18:09,760
got the decisions they wanted right

450
00:18:07,270 --> 00:18:11,710
or maybe thought they were going to get

451
00:18:09,760 --> 00:18:16,809
NIM didn't get where they want but it

452
00:18:11,710 --> 00:18:19,080
wasn't based on facts and Ellen elder's

453
00:18:16,809 --> 00:18:22,000
Dunning sadly he's got Parkinson's now

454
00:18:19,080 --> 00:18:25,299
but in his retirement from acting career

455
00:18:22,000 --> 00:18:27,039
he set up I guess it's a charity to try

456
00:18:25,299 --> 00:18:29,110
and help scientists with their

457
00:18:27,039 --> 00:18:32,230
communication and part of what he's

458
00:18:29,110 --> 00:18:34,600
saying is we typically sit around fires

459
00:18:32,230 --> 00:18:36,789
over evolutionary time and tell stories

460
00:18:34,600 --> 00:18:38,289
and that's how we start to understand

461
00:18:36,789 --> 00:18:40,210
things and he's saying that's what

462
00:18:38,289 --> 00:18:42,580
scientists need to do because stories

463
00:18:40,210 --> 00:18:45,100
involve people it generates emotion and

464
00:18:42,580 --> 00:18:47,408
then we have outcomes rather than just

465
00:18:45,100 --> 00:18:49,840
dumping facts on it so they're looked at

466
00:18:47,409 --> 00:18:53,860
in that sort of area of this behavioral

467
00:18:49,840 --> 00:18:57,340
sciences like just factual overload that

468
00:18:53,860 --> 00:18:59,110
more facts will push you to a better

469
00:18:57,340 --> 00:19:01,389
decision and they call it like an

470
00:18:59,110 --> 00:19:02,620
information deficit model and scientists

471
00:19:01,390 --> 00:19:04,690
will come along with more facts for

472
00:19:02,620 --> 00:19:12,610
climate change but that's not really

473
00:19:04,690 --> 00:19:15,010
cutting the mustard so so originally our

474
00:19:12,610 --> 00:19:16,689
view until they're about the 70s were

475
00:19:15,010 --> 00:19:19,330
the predominant view with economists was

476
00:19:16,690 --> 00:19:22,120
everyone makes rational decisions which

477
00:19:19,330 --> 00:19:27,490
we knew from the Dutch tulip mania we

478
00:19:22,120 --> 00:19:29,559
don't and there's still a lot of

479
00:19:27,490 --> 00:19:33,940
economic schools around the world talk

480
00:19:29,559 --> 00:19:37,510
trained rational economic theory but we

481
00:19:33,940 --> 00:19:41,890
have these various some asset bubbles as

482
00:19:37,510 --> 00:19:43,510
we and we can list many more right but

483
00:19:41,890 --> 00:19:46,270
so Daniel Kahneman came along with

484
00:19:43,510 --> 00:19:50,140
Tversky some key work in the 70s here is

485
00:19:46,270 --> 00:19:51,789
an Israeli psychologist because they are

486
00:19:50,140 --> 00:19:54,039
Israeli army we realized they weren't

487
00:19:51,789 --> 00:19:56,590
getting the best offices and he realized

488
00:19:54,039 --> 00:19:57,730
the selection process was bias and he

489
00:19:56,590 --> 00:20:00,540
started some research now he's a

490
00:19:57,730 --> 00:20:03,190
emeritus professor at Princeton

491
00:20:00,540 --> 00:20:06,460
fascinating story about Carmen he

492
00:20:03,190 --> 00:20:09,100
never have got the Nobel Prize because

493
00:20:06,460 --> 00:20:11,680
he was a Jewish kid somewhere in Europe

494
00:20:09,100 --> 00:20:13,810
I think it was Italy how come he ended

495
00:20:11,680 --> 00:20:17,170
up there I'm not sure and an SS officer

496
00:20:13,810 --> 00:20:18,730
saw him and ran up to him and he thought

497
00:20:17,170 --> 00:20:21,100
I'm a goner

498
00:20:18,730 --> 00:20:22,870
and it turned out he got the SS officer

499
00:20:21,100 --> 00:20:24,189
gave him a hug and then he showed him a

500
00:20:22,870 --> 00:20:27,699
photo and he he just happened to look

501
00:20:24,190 --> 00:20:29,470
like this German officers son and then

502
00:20:27,700 --> 00:20:31,510
he was sent on his way home so that that

503
00:20:29,470 --> 00:20:34,570
story could have been like sliding doors

504
00:20:31,510 --> 00:20:35,470
and just gone a totally different way so

505
00:20:34,570 --> 00:20:37,570
anyway anyway

506
00:20:35,470 --> 00:20:39,490
Tversky didn't you've got to be alive to

507
00:20:37,570 --> 00:20:43,030
get the Nobel Prize

508
00:20:39,490 --> 00:20:44,530
so Kahneman got it in 2002 he's got a

509
00:20:43,030 --> 00:20:47,190
book on his life's work Thinking Fast

510
00:20:44,530 --> 00:20:49,629
and Slow it's a really good read

511
00:20:47,190 --> 00:20:51,850
fundamentally he says we don't have the

512
00:20:49,630 --> 00:20:54,250
luxury to fully analyze stuff all the

513
00:20:51,850 --> 00:20:57,280
time so we we make decisions based on

514
00:20:54,250 --> 00:20:59,980
heuristics based on what we think we

515
00:20:57,280 --> 00:21:01,980
know based on our previous things and

516
00:20:59,980 --> 00:21:04,120
we'll go into that a little bit more to

517
00:21:01,980 --> 00:21:07,830
seeing how the time goes but he's like

518
00:21:04,120 --> 00:21:09,820
we we don't have the time to make fully

519
00:21:07,830 --> 00:21:13,060
analyzed decisions all the time we're

520
00:21:09,820 --> 00:21:14,649
going to make quick decisions and you

521
00:21:13,060 --> 00:21:17,740
could think of that as evolutionary if

522
00:21:14,650 --> 00:21:20,320
we sit there and the grass moves we can

523
00:21:17,740 --> 00:21:23,710
go I wonder if it's a tiger or a

524
00:21:20,320 --> 00:21:26,649
poisonous snake or we can go it could be

525
00:21:23,710 --> 00:21:29,680
bad I'm just going to get up and run

526
00:21:26,650 --> 00:21:33,640
and that the quick decisions become a

527
00:21:29,680 --> 00:21:35,650
survival technique and then along comes

528
00:21:33,640 --> 00:21:40,210
Richard Thaler he also got a Nobel Prize

529
00:21:35,650 --> 00:21:42,060
I think it was 2017 but and he was an

530
00:21:40,210 --> 00:21:45,520
economist actually getting into

531
00:21:42,060 --> 00:21:48,970
behavioural science and his work his

532
00:21:45,520 --> 00:21:51,280
famous work is the book it nudge and you

533
00:21:48,970 --> 00:21:54,040
know Tony Blair and Barack Obama had no

534
00:21:51,280 --> 00:21:56,290
junit set up where they realize you

535
00:21:54,040 --> 00:21:59,440
dumped facts on people and think of

536
00:21:56,290 --> 00:22:02,020
young men big things that kills our

537
00:21:59,440 --> 00:22:05,230
young men in our 20s is road crashes and

538
00:22:02,020 --> 00:22:05,850
if we tell them speeding kills they just

539
00:22:05,230 --> 00:22:07,780
ignore it

540
00:22:05,850 --> 00:22:10,659
but if we nudge them in the right

541
00:22:07,780 --> 00:22:12,520
direction by saying things like your

542
00:22:10,660 --> 00:22:14,230
girlfriend won't be impressed or if you

543
00:22:12,520 --> 00:22:16,570
crash your car you're gonna have to

544
00:22:14,230 --> 00:22:18,490
drive a detsen 120y they

545
00:22:16,570 --> 00:22:21,700
might slow down seriously this is how

546
00:22:18,490 --> 00:22:24,509
some of this stuff works right for the

547
00:22:21,700 --> 00:22:26,860
OL set of the old security people here a

548
00:22:24,509 --> 00:22:29,590
guy always took as a bit of a mentor

549
00:22:26,860 --> 00:22:32,320
John Kidston Tommy his story and it was

550
00:22:29,590 --> 00:22:34,539
Victoria advertising about drink-driving

551
00:22:32,320 --> 00:22:36,309
and you know yeah you can remember all

552
00:22:34,539 --> 00:22:38,740
the scare campaigns of drink-driving

553
00:22:36,309 --> 00:22:40,990
but they said if you get pulled up for

554
00:22:38,740 --> 00:22:44,110
RBT can you can you afford the taxi cuz

555
00:22:40,990 --> 00:22:46,240
you've lost your license and that has

556
00:22:44,110 --> 00:22:49,090
some impact because it brings it down to

557
00:22:46,240 --> 00:22:50,320
a much more probable outcome it's like

558
00:22:49,090 --> 00:22:51,519
you think I won't get caught I'm a good

559
00:22:50,320 --> 00:22:52,360
driver I won't crash because I'm a

560
00:22:51,519 --> 00:22:55,179
really good driver

561
00:22:52,360 --> 00:22:57,758
but geez the cops might get me and then

562
00:22:55,179 --> 00:22:59,590
I won't be able to drive and I'll and

563
00:22:57,759 --> 00:23:01,179
can I afford a taxi to catch up with my

564
00:22:59,590 --> 00:23:03,549
mates that brought it down to a much

565
00:23:01,179 --> 00:23:05,289
more probable case and it was very

566
00:23:03,549 --> 00:23:05,860
effective advertising against

567
00:23:05,289 --> 00:23:08,710
drink-driving

568
00:23:05,860 --> 00:23:10,389
that's an example of lunch stuff and I

569
00:23:08,710 --> 00:23:12,850
think fail is the one that gets to the

570
00:23:10,389 --> 00:23:15,100
credence for that so I think we can

571
00:23:12,850 --> 00:23:19,719
learn things from these these smart

572
00:23:15,100 --> 00:23:21,519
people to influence and nudge some of

573
00:23:19,720 --> 00:23:23,950
our people might be nudging our execs it

574
00:23:21,519 --> 00:23:25,720
might be done geing our staff whether

575
00:23:23,950 --> 00:23:30,009
it's clicking on links or ringing the

576
00:23:25,720 --> 00:23:32,700
helpdesk all that sort of stuff so I

577
00:23:30,009 --> 00:23:34,960
mean I just grabbed this why not I've

578
00:23:32,700 --> 00:23:37,090
followed too many people on Twitter but

579
00:23:34,960 --> 00:23:38,409
a lot of them economists and this one

580
00:23:37,090 --> 00:23:40,928
just came up a couple of weeks before

581
00:23:38,409 --> 00:23:42,850
this presentation talking about the rise

582
00:23:40,929 --> 00:23:45,909
of chief behavioral officers in

583
00:23:42,850 --> 00:23:51,039
organizations so I think it's a pretty

584
00:23:45,909 --> 00:23:52,899
exciting area of social science and it

585
00:23:51,039 --> 00:23:55,059
and this one probably sort of more came

586
00:23:52,899 --> 00:23:58,120
out of marriage counseling right so

587
00:23:55,059 --> 00:23:59,980
where they say hang on if you're having

588
00:23:58,120 --> 00:24:02,168
a discussion there's a speaker and a

589
00:23:59,980 --> 00:24:04,240
listener but it's up to the listener of

590
00:24:02,169 --> 00:24:06,039
whether they hear you and it's the same

591
00:24:04,240 --> 00:24:07,389
whether you're making your pitch for

592
00:24:06,039 --> 00:24:09,639
your multi-million dollar security

593
00:24:07,389 --> 00:24:13,449
program or you trying to work stuff out

594
00:24:09,639 --> 00:24:15,279
with your partner so we've got to do

595
00:24:13,450 --> 00:24:17,230
stuff and then here's some things that

596
00:24:15,279 --> 00:24:20,379
I've sort of adapted from that sort of

597
00:24:17,230 --> 00:24:21,669
area of science for us so typically we

598
00:24:20,379 --> 00:24:24,730
say let's use the person's first

599
00:24:21,669 --> 00:24:26,620
language and friends are size o of a

600
00:24:24,730 --> 00:24:29,230
multinational where I think the Board

601
00:24:26,620 --> 00:24:31,600
meets in Germany somewhere right so he'd

602
00:24:29,230 --> 00:24:34,090
be better learning some German

603
00:24:31,600 --> 00:24:36,520
so we but certainly we don't want to use

604
00:24:34,090 --> 00:24:37,689
tech jargon we're going to talk in the

605
00:24:36,520 --> 00:24:41,260
language of the business people we're

606
00:24:37,690 --> 00:24:42,940
trying to influence and if we're running

607
00:24:41,260 --> 00:24:45,370
a security awareness program for our

608
00:24:42,940 --> 00:24:47,380
staff and say they're bank tellers and

609
00:24:45,370 --> 00:24:52,239
bank managers we want to talk in the

610
00:24:47,380 --> 00:24:54,520
banking language not the tech jargon we

611
00:24:52,240 --> 00:24:56,320
could listen to their current worries my

612
00:24:54,520 --> 00:24:58,810
favorite question with executives when I

613
00:24:56,320 --> 00:25:00,460
say do a security review for us is what

614
00:24:58,810 --> 00:25:03,879
keeps you awake at night and they're

615
00:25:00,460 --> 00:25:11,020
like declining retail sales or whatever

616
00:25:03,880 --> 00:25:14,530
it is what thinking here about novelty

617
00:25:11,020 --> 00:25:16,330
and oh if we repeat what they expect us

618
00:25:14,530 --> 00:25:18,250
to say they may not be listening but if

619
00:25:16,330 --> 00:25:21,040
you say something novel that might catch

620
00:25:18,250 --> 00:25:23,200
the attention our marketers do this with

621
00:25:21,040 --> 00:25:25,120
billboards on the highways if it's the

622
00:25:23,200 --> 00:25:26,890
same for five years we never notice it

623
00:25:25,120 --> 00:25:28,840
and that's the great boon of these

624
00:25:26,890 --> 00:25:30,520
electronic notice billboards down our

625
00:25:28,840 --> 00:25:31,959
highways they change all the time we

626
00:25:30,520 --> 00:25:35,200
actually do notice that it catches our

627
00:25:31,960 --> 00:25:37,420
attention so we can do that right we

628
00:25:35,200 --> 00:25:42,340
instead of coming back every quarter

629
00:25:37,420 --> 00:25:45,880
with our antivirus stats or heck knows

630
00:25:42,340 --> 00:25:47,350
what number a number of denied port

631
00:25:45,880 --> 00:25:48,670
scans on the file we'll come back with

632
00:25:47,350 --> 00:25:50,409
something different every time and it

633
00:25:48,670 --> 00:25:54,610
might catch the attention so we can use

634
00:25:50,410 --> 00:25:56,980
some of this ourselves but also it they

635
00:25:54,610 --> 00:25:58,810
have to be safe enough to to hear I mean

636
00:25:56,980 --> 00:26:01,030
certainly any marriage counselor is

637
00:25:58,810 --> 00:26:03,550
going to say that right but it's the

638
00:26:01,030 --> 00:26:05,590
same for the executive team if you come

639
00:26:03,550 --> 00:26:09,490
in and you're a bit cocky or arrogant

640
00:26:05,590 --> 00:26:11,020
and it appears they might end up being a

641
00:26:09,490 --> 00:26:12,130
little bit embarrassed because they

642
00:26:11,020 --> 00:26:14,020
don't understand what you're talking

643
00:26:12,130 --> 00:26:16,120
about that's going to put them in more

644
00:26:14,020 --> 00:26:18,129
of a defensive approach and that's

645
00:26:16,120 --> 00:26:20,770
shutting down the listening whereas if

646
00:26:18,130 --> 00:26:23,440
you come in and like I'm not here to

647
00:26:20,770 --> 00:26:25,510
preach to you I'm actually here to help

648
00:26:23,440 --> 00:26:27,010
we've got some things what are your

649
00:26:25,510 --> 00:26:28,900
concerns about and then you can relate

650
00:26:27,010 --> 00:26:30,460
it to those concerns they're getting in

651
00:26:28,900 --> 00:26:36,100
you're getting these people into a

652
00:26:30,460 --> 00:26:38,950
receptive position so apparently one of

653
00:26:36,100 --> 00:26:40,629
the key things in this listening area is

654
00:26:38,950 --> 00:26:43,200
if they perceive they share the same

655
00:26:40,630 --> 00:26:45,670
values as you

656
00:26:43,200 --> 00:26:47,740
so we're that's about it's not about

657
00:26:45,670 --> 00:26:50,080
your security program it's about the

658
00:26:47,740 --> 00:26:52,510
organization making a profit or whatever

659
00:26:50,080 --> 00:26:55,449
those executive leadership type people

660
00:26:52,510 --> 00:26:57,220
their goals are and protecting organize

661
00:26:55,450 --> 00:26:59,230
it could be a government agency it's all

662
00:26:57,220 --> 00:27:01,120
about getting the centerlink paychecks

663
00:26:59,230 --> 00:27:08,290
out on time it's not about your security

664
00:27:01,120 --> 00:27:10,929
program don't think what else are say

665
00:27:08,290 --> 00:27:13,270
about this our listeners are typically

666
00:27:10,930 --> 00:27:15,640
receptive to people like them they're

667
00:27:13,270 --> 00:27:18,370
sort of touching on this before when we

668
00:27:15,640 --> 00:27:20,830
were talking about decisions by proxy so

669
00:27:18,370 --> 00:27:23,260
if we really only mainly comfortable in

670
00:27:20,830 --> 00:27:27,129
a black t-shirt but we know our boss is

671
00:27:23,260 --> 00:27:28,990
always in a white shirt and tie then

672
00:27:27,130 --> 00:27:30,760
maybe we should put a white shirt and

673
00:27:28,990 --> 00:27:33,880
tie in a bit more or certainly when

674
00:27:30,760 --> 00:27:36,160
we're making our pitch for things I know

675
00:27:33,880 --> 00:27:37,960
one organisation I was working the CEO

676
00:27:36,160 --> 00:27:40,390
was watch it and tie the next one comes

677
00:27:37,960 --> 00:27:42,070
along he came up from Victoria his ties

678
00:27:40,390 --> 00:27:44,380
off him and Queensland I'm relaxed he

679
00:27:42,070 --> 00:27:45,700
thought Queens he's like we don't need

680
00:27:44,380 --> 00:27:49,180
to wear suits we're in Queensland now

681
00:27:45,700 --> 00:27:50,620
the total office changed and you can see

682
00:27:49,180 --> 00:27:52,360
all the sycophants and there's plenty in

683
00:27:50,620 --> 00:27:53,919
that organization they all started

684
00:27:52,360 --> 00:27:59,080
changing the last guy was a teetotaler

685
00:27:53,920 --> 00:28:01,330
the new guy was hey you know but because

686
00:27:59,080 --> 00:28:08,399
they subconsciously wanted to get on his

687
00:28:01,330 --> 00:28:10,960
side cool but we won't get any listening

688
00:28:08,400 --> 00:28:13,990
if people get into defensive mode

689
00:28:10,960 --> 00:28:16,720
because you're coming and go you've

690
00:28:13,990 --> 00:28:19,330
ignored the risk and stuff like that so

691
00:28:16,720 --> 00:28:21,670
so one of my techniques recently has

692
00:28:19,330 --> 00:28:23,679
been saying but I know one organization

693
00:28:21,670 --> 00:28:26,170
has been in having pretty much the same

694
00:28:23,680 --> 00:28:29,560
issues for 10 years the same issues of

695
00:28:26,170 --> 00:28:31,780
patching you know but you come in and go

696
00:28:29,560 --> 00:28:33,639
hey but the world's changed it's a

697
00:28:31,780 --> 00:28:35,830
different situation now we need to

698
00:28:33,640 --> 00:28:36,910
respond rather than going your mob of

699
00:28:35,830 --> 00:28:38,919
idiots you haven't made the obvious

700
00:28:36,910 --> 00:28:40,420
decision from five years just coming in

701
00:28:38,920 --> 00:28:42,760
and complaining they're going to be in a

702
00:28:40,420 --> 00:28:45,190
defensive mode and they're just itching

703
00:28:42,760 --> 00:28:47,140
to say no to you even though if they go

704
00:28:45,190 --> 00:28:49,510
I probably should be listening to him

705
00:28:47,140 --> 00:28:51,190
they just emotionally want to go get out

706
00:28:49,510 --> 00:28:56,620
of here I don't to see you you're making

707
00:28:51,190 --> 00:28:57,880
me feel bad a lot

708
00:28:56,620 --> 00:28:59,739
another bit of that thing is about

709
00:28:57,880 --> 00:29:02,800
worldview or self identity we talked a

710
00:28:59,740 --> 00:29:06,160
little bit before about identity there's

711
00:29:02,800 --> 00:29:09,070
a great book I think it's debunking miss

712
00:29:06,160 --> 00:29:11,470
but Gary Lewandowski he was I think at

713
00:29:09,070 --> 00:29:13,510
UQ and he's now gone to America and

714
00:29:11,470 --> 00:29:15,400
another colleague it's just a short

715
00:29:13,510 --> 00:29:17,770
eight page book and it's talking about

716
00:29:15,400 --> 00:29:20,440
people that have irrational beliefs by

717
00:29:17,770 --> 00:29:22,870
anti-vaxxers and denying climate change

718
00:29:20,440 --> 00:29:24,880
because actually looking for the things

719
00:29:22,870 --> 00:29:28,300
that support a preconceived outcome and

720
00:29:24,880 --> 00:29:30,420
we're just openly ignoring the facts but

721
00:29:28,300 --> 00:29:33,340
and they've got some techniques in that

722
00:29:30,420 --> 00:29:36,010
debunking handbook where if we can get

723
00:29:33,340 --> 00:29:38,230
on and say not challenge the worldview

724
00:29:36,010 --> 00:29:39,700
but say hey we've got a problem to face

725
00:29:38,230 --> 00:29:41,590
can you help me solve it can we work

726
00:29:39,700 --> 00:29:47,050
together rather than preaching to them

727
00:29:41,590 --> 00:29:52,570
they'll be less defensive debunk myths

728
00:29:47,050 --> 00:29:53,649
debunking handbook I think if you send

729
00:29:52,570 --> 00:29:55,840
me an email or something else certainly

730
00:29:53,650 --> 00:29:59,170
but probably just shoot a copy back but

731
00:29:55,840 --> 00:30:01,389
we'll fine but if we're delivering

732
00:29:59,170 --> 00:30:02,650
unwelcome messages and let's face when

733
00:30:01,390 --> 00:30:04,360
we're talking about risk we're typically

734
00:30:02,650 --> 00:30:05,950
talking about downside risk and we

735
00:30:04,360 --> 00:30:08,020
haven't been doing a good enough job or

736
00:30:05,950 --> 00:30:11,290
spending enough money it's much better

737
00:30:08,020 --> 00:30:13,360
to receive a uncomfortable message from

738
00:30:11,290 --> 00:30:15,790
someone inside the family tent rather

739
00:30:13,360 --> 00:30:17,559
from some smart-aleck outsider so if we

740
00:30:15,790 --> 00:30:20,379
can try and pitch it that way like

741
00:30:17,559 --> 00:30:22,480
wearing a t-shirt that says bhp when

742
00:30:20,380 --> 00:30:26,890
we're working a bhp maybe or that sort

743
00:30:22,480 --> 00:30:28,360
of thing and also taking this approach

744
00:30:26,890 --> 00:30:29,590
is I'm not here to let you but I'm here

745
00:30:28,360 --> 00:30:32,350
to help we've got a problem to solve

746
00:30:29,590 --> 00:30:33,879
together I've done some analysis what do

747
00:30:32,350 --> 00:30:38,290
you think you got any other ideas and

748
00:30:33,880 --> 00:30:41,679
that's starting to build some buying I

749
00:30:38,290 --> 00:30:43,480
mentioned the groom transfer show but

750
00:30:41,679 --> 00:30:45,100
one of the things they they nailed with

751
00:30:43,480 --> 00:30:48,550
that one was there's a whole psychology

752
00:30:45,100 --> 00:30:50,620
around decision making but one of it is

753
00:30:48,550 --> 00:30:52,889
called is we make the emotional decision

754
00:30:50,620 --> 00:30:55,449
then we come back and the site the

755
00:30:52,890 --> 00:30:58,030
social site psychologists call it

756
00:30:55,450 --> 00:31:01,360
motivated reasoning we make the decision

757
00:30:58,030 --> 00:31:03,910
then we find ways to dress it up as we

758
00:31:01,360 --> 00:31:06,250
made it in a rational decision way okay

759
00:31:03,910 --> 00:31:08,830
and let's think we might do that in cars

760
00:31:06,250 --> 00:31:10,330
I bought this car and you know you can

761
00:31:08,830 --> 00:31:12,699
buy a big SUV

762
00:31:10,330 --> 00:31:13,809
by a mini and in the end you go I bought

763
00:31:12,700 --> 00:31:15,669
this mini because it's really

764
00:31:13,809 --> 00:31:17,799
fuel-efficient I can park it anywhere or

765
00:31:15,669 --> 00:31:19,269
if you bought the SUV you go I can go

766
00:31:17,799 --> 00:31:21,850
anywhere in the world and go up a

767
00:31:19,269 --> 00:31:23,620
mountain Kosciusko you start

768
00:31:21,850 --> 00:31:28,510
rationalizing it in that way and we do

769
00:31:23,620 --> 00:31:31,268
the same thing it worked right so I've

770
00:31:28,510 --> 00:31:32,890
talked about introduced that the stuff

771
00:31:31,269 --> 00:31:34,690
from Carmen Tversky those saying we

772
00:31:32,890 --> 00:31:36,760
weren't we aren't all rational decisions

773
00:31:34,690 --> 00:31:39,640
we make biased decisions and we have to

774
00:31:36,760 --> 00:31:41,950
make rap pretty quick decisions a lot of

775
00:31:39,640 --> 00:31:44,649
the time based on heuristics based on

776
00:31:41,950 --> 00:31:46,809
rules of thumb they also introduce this

777
00:31:44,649 --> 00:31:49,870
concept of cognitive biases mark

778
00:31:46,809 --> 00:31:52,210
mentioned a few I think they their

779
00:31:49,870 --> 00:31:54,518
original papers in the 70s listed three

780
00:31:52,210 --> 00:31:57,460
if you get under Wikipedia now it's like

781
00:31:54,519 --> 00:31:59,980
200 you can tell everyone that wants to

782
00:31:57,460 --> 00:32:01,510
get a PhD in this space goes what girls

783
00:31:59,980 --> 00:32:04,450
thinking of ok and then there's another

784
00:32:01,510 --> 00:32:07,539
cognitive bias on the Wikipedia page but

785
00:32:04,450 --> 00:32:09,220
some of them are pretty interesting so

786
00:32:07,539 --> 00:32:10,750
and I've got a list of some in here that

787
00:32:09,220 --> 00:32:15,760
I think are relevant to information

788
00:32:10,750 --> 00:32:17,260
security so but essentially it's our

789
00:32:15,760 --> 00:32:19,419
rules of thumb and this is the way a lot

790
00:32:17,260 --> 00:32:20,950
of our decisions will be made and it

791
00:32:19,419 --> 00:32:21,429
might be made before we come into the

792
00:32:20,950 --> 00:32:24,669
room

793
00:32:21,429 --> 00:32:27,309
no security budgets been going up by 20%

794
00:32:24,669 --> 00:32:31,059
each year that's too much

795
00:32:27,309 --> 00:32:33,730
certainly CFOs are always watching areas

796
00:32:31,059 --> 00:32:35,980
where there's a growth in in spending

797
00:32:33,730 --> 00:32:38,409
and going that has to be contained in

798
00:32:35,980 --> 00:32:40,419
even one of our big banks changed their

799
00:32:38,409 --> 00:32:41,919
size oh because I think the previous one

800
00:32:40,419 --> 00:32:44,529
was saying I've got six hundred people

801
00:32:41,919 --> 00:32:47,139
and another banks similar banks add add

802
00:32:44,529 --> 00:32:48,370
200 but we all know the firewall people

803
00:32:47,139 --> 00:32:49,928
could be in a security team or they

804
00:32:48,370 --> 00:32:53,110
could be in a network ops team it's like

805
00:32:49,929 --> 00:32:54,370
how you count and the new guy was asked

806
00:32:53,110 --> 00:32:55,990
to cut the numbers down because there's

807
00:32:54,370 --> 00:32:58,590
a perception of being growing too much

808
00:32:55,990 --> 00:33:01,240
now it's flipped on its head again but

809
00:32:58,590 --> 00:33:04,980
these perceptions can drive these chain

810
00:33:01,240 --> 00:33:07,960
arm decisions right there's also a

811
00:33:04,980 --> 00:33:10,210
common heuristic of a major change must

812
00:33:07,960 --> 00:33:12,399
be a major risk so if you're pitching it

813
00:33:10,210 --> 00:33:15,220
is a major change rather evolutionary

814
00:33:12,399 --> 00:33:17,018
growth and stuff like that then then

815
00:33:15,220 --> 00:33:18,820
you're you're butting up and creating

816
00:33:17,019 --> 00:33:21,549
some resistance that you may not need to

817
00:33:18,820 --> 00:33:23,770
have so if you come in and go I'm the

818
00:33:21,549 --> 00:33:24,360
new security manager oh my god the last

819
00:33:23,770 --> 00:33:26,670
guys

820
00:33:24,360 --> 00:33:28,169
girls were hopeless have mi the solution

821
00:33:26,670 --> 00:33:30,360
for you everything's got to change

822
00:33:28,170 --> 00:33:33,929
instantly there's a perception there's a

823
00:33:30,360 --> 00:33:36,059
lot of risk with that so in terms of the

824
00:33:33,929 --> 00:33:39,860
way we present how we're trying to do

825
00:33:36,059 --> 00:33:42,899
things so here's some cognitive biases

826
00:33:39,860 --> 00:33:44,639
we won't get through them all but

827
00:33:42,900 --> 00:33:47,700
anchoring is one we were drawn to the

828
00:33:44,640 --> 00:33:50,460
first information we hear in on a

829
00:33:47,700 --> 00:33:52,580
certain topic I think I remember when

830
00:33:50,460 --> 00:33:55,049
Microsoft was advertising a lot of stuff

831
00:33:52,580 --> 00:33:57,689
when we still had Novell systems their

832
00:33:55,049 --> 00:33:59,400
advertising on planes because that's

833
00:33:57,690 --> 00:34:01,530
where the executive decision makers were

834
00:33:59,400 --> 00:34:04,010
and if you talk to text at a conference

835
00:34:01,530 --> 00:34:06,809
like this you'd say Novell is superior

836
00:34:04,010 --> 00:34:08,668
actually remember a conference where it

837
00:34:06,809 --> 00:34:10,918
was where they're debating or where the

838
00:34:08,668 --> 00:34:12,658
UNIX or Windows is better and of course

839
00:34:10,918 --> 00:34:15,750
there's never going to be a sensible

840
00:34:12,659 --> 00:34:16,859
outcome of that discussion but people

841
00:34:15,750 --> 00:34:19,889
were anchored from where they came from

842
00:34:16,859 --> 00:34:21,060
our executives are often in this case it

843
00:34:19,889 --> 00:34:24,090
might have been something that came up

844
00:34:21,060 --> 00:34:25,199
in the company directors magazine that

845
00:34:24,090 --> 00:34:27,540
might anchor their thinking on

846
00:34:25,199 --> 00:34:29,609
cybersecurity data sixty ones been

847
00:34:27,540 --> 00:34:32,250
writing some of that stuff if we know of

848
00:34:29,609 --> 00:34:35,879
it at least we can present it in the way

849
00:34:32,250 --> 00:34:37,859
that they're already anchored so if but

850
00:34:35,879 --> 00:34:39,179
if you go head-to-head with what data 61

851
00:34:37,859 --> 00:34:41,129
has been saying to company directors

852
00:34:39,179 --> 00:34:46,379
then you're setting yourself up for a

853
00:34:41,129 --> 00:34:47,909
much more challenging outcome another I

854
00:34:46,379 --> 00:34:50,368
think mark mentioned this one so I won't

855
00:34:47,909 --> 00:34:51,990
say too much but the availability

856
00:34:50,369 --> 00:34:54,540
heuristic is the first thing that comes

857
00:34:51,989 --> 00:34:56,279
to something that comes to mind is going

858
00:34:54,540 --> 00:34:57,869
to drive the decision more and it might

859
00:34:56,280 --> 00:35:01,500
come to mind because it's in the medium

860
00:34:57,869 --> 00:35:05,250
or or if we're working at one bank and I

861
00:35:01,500 --> 00:35:06,630
I think in Obie's had some power power

862
00:35:05,250 --> 00:35:08,970
supply issues for their mainframes they

863
00:35:06,630 --> 00:35:10,530
had some down time they regulated the

864
00:35:08,970 --> 00:35:11,970
executives could well think that's the

865
00:35:10,530 --> 00:35:12,960
biggest risk happening at the moment

866
00:35:11,970 --> 00:35:14,640
because the regulator is talking about

867
00:35:12,960 --> 00:35:17,040
it it's in what we were all talking

868
00:35:14,640 --> 00:35:20,190
about I think the classic thing would

869
00:35:17,040 --> 00:35:21,779
have been September 12 2001 and people

870
00:35:20,190 --> 00:35:22,980
were just think there's much higher risk

871
00:35:21,780 --> 00:35:24,630
from airplanes flying into buildings

872
00:35:22,980 --> 00:35:26,130
then there normally is

873
00:35:24,630 --> 00:35:29,010
I mean the Yanks responded with three

874
00:35:26,130 --> 00:35:30,960
trillion dollars of efforts saying the

875
00:35:29,010 --> 00:35:32,700
fear of terrorism because it's much more

876
00:35:30,960 --> 00:35:34,590
it's likely everyone's scared of

877
00:35:32,700 --> 00:35:37,350
terrorists particularly politicians push

878
00:35:34,590 --> 00:35:38,220
this around right but fifty five

879
00:35:37,350 --> 00:35:40,589
thousand a mirror

880
00:35:38,220 --> 00:35:42,509
died each year on the roads in road but

881
00:35:40,589 --> 00:35:44,730
the you're much more likely to die in

882
00:35:42,510 --> 00:35:46,680
America in a road accident and we know I

883
00:35:44,730 --> 00:35:49,170
think you're 15 times more likely to buy

884
00:35:46,680 --> 00:35:51,328
die by a gun homicide in America and in

885
00:35:49,170 --> 00:35:53,819
Australia but they spent three trillion

886
00:35:51,329 --> 00:35:55,440
on terrorism threats the perception of

887
00:35:53,819 --> 00:35:56,640
the availability thing really changed

888
00:35:55,440 --> 00:36:01,740
and of course there's people with

889
00:35:56,640 --> 00:36:04,230
agendas behind that so what are you

890
00:36:01,740 --> 00:36:06,720
saying two minutes so there's a whole

891
00:36:04,230 --> 00:36:08,700
lot of biases here I presume also it

892
00:36:06,720 --> 00:36:12,689
gives the slides out I'm happy if they

893
00:36:08,700 --> 00:36:14,220
do that I also use Google Images marking

894
00:36:12,690 --> 00:36:18,210
or like the one I was like dear feel

895
00:36:14,220 --> 00:36:19,589
lucky punk but talking about this our

896
00:36:18,210 --> 00:36:21,780
leaders typically think they're really

897
00:36:19,589 --> 00:36:23,369
lucky the bad stuff you're talking about

898
00:36:21,780 --> 00:36:26,099
it's not going to happen to them because

899
00:36:23,369 --> 00:36:28,829
they're lucky and let's face it you

900
00:36:26,099 --> 00:36:31,619
don't become CEO of our big companies if

901
00:36:28,829 --> 00:36:34,020
you're really negative person you view

902
00:36:31,619 --> 00:36:36,030
yourself as by taking on risks I make

903
00:36:34,020 --> 00:36:37,530
the luck happen all the bad stuff that

904
00:36:36,030 --> 00:36:40,680
happens to other that happens the other

905
00:36:37,530 --> 00:36:45,020
people that are terrible CEOs I'm the

906
00:36:40,680 --> 00:36:45,020
lucky one so if you come in and go

907
00:36:45,170 --> 00:36:50,369
everything's negative and I need this

908
00:36:47,550 --> 00:36:52,260
security program and stuff you you're

909
00:36:50,369 --> 00:36:54,599
not going to be on the side of that

910
00:36:52,260 --> 00:37:00,000
really positive optimistically minded

911
00:36:54,599 --> 00:37:03,660
executive so there's a few here there's

912
00:37:00,000 --> 00:37:05,310
a couple others I wanted to get to I'll

913
00:37:03,660 --> 00:37:07,170
just flip over that one of conflict of

914
00:37:05,310 --> 00:37:08,578
interest but certainly executive biases

915
00:37:07,170 --> 00:37:10,349
I have seen in my career

916
00:37:08,579 --> 00:37:19,349
impact the decisions we're making this

917
00:37:10,349 --> 00:37:21,660
space so this cognitive biases galore I

918
00:37:19,349 --> 00:37:26,010
had pulled some out just that I think

919
00:37:21,660 --> 00:37:29,509
were relevant to us there's so many this

920
00:37:26,010 --> 00:37:32,730
one's interesting is if we people are

921
00:37:29,510 --> 00:37:36,000
not innately receptive to our message

922
00:37:32,730 --> 00:37:38,160
more facts of the inconvenient truth can

923
00:37:36,000 --> 00:37:39,750
actually create is backfire effect and

924
00:37:38,160 --> 00:37:43,020
it entrenches them because they become

925
00:37:39,750 --> 00:37:45,810
defensive so this this happens in

926
00:37:43,020 --> 00:37:47,609
smoking it probably happened with some

927
00:37:45,810 --> 00:37:50,069
of our companies in the asbestos debates

928
00:37:47,609 --> 00:37:51,990
people go no they keep going looking for

929
00:37:50,069 --> 00:37:56,490
evidence to counter predict you

930
00:37:51,990 --> 00:37:58,589
kind of counteract your argument so I

931
00:37:56,490 --> 00:38:00,779
mean I've certainly had that where we go

932
00:37:58,589 --> 00:38:03,990
you look at shadow bro shut not shadow

933
00:38:00,780 --> 00:38:06,000
broker shadow servers and get that one

934
00:38:03,990 --> 00:38:08,250
right and any virus depending on when

935
00:38:06,000 --> 00:38:11,790
you look is you know twenty percent

936
00:38:08,250 --> 00:38:13,080
effective on a zero day but it the CIOs

937
00:38:11,790 --> 00:38:16,830
or something scope no no I've got any

938
00:38:13,080 --> 00:38:18,060
virus I'm safe and you say no I think

939
00:38:16,830 --> 00:38:19,500
we've got problems here we need to do

940
00:38:18,060 --> 00:38:20,759
some white listing the Connell

941
00:38:19,500 --> 00:38:23,400
government said it's very effective

942
00:38:20,760 --> 00:38:24,900
control and they go off to their vendors

943
00:38:23,400 --> 00:38:27,060
they go looking for the evidence to

944
00:38:24,900 --> 00:38:28,490
counteract you this is the sort of stuff

945
00:38:27,060 --> 00:38:31,290
that's happening here

946
00:38:28,490 --> 00:38:33,450
really with this is driven by the facts

947
00:38:31,290 --> 00:38:36,440
don't drop it drive the change your

948
00:38:33,450 --> 00:38:39,060
minds the emotions do around this stuff

949
00:38:36,440 --> 00:38:41,369
so it is interesting with this backfire

950
00:38:39,060 --> 00:38:43,200
effect this social psychologists and

951
00:38:41,369 --> 00:38:46,320
there is a tipping point where enough

952
00:38:43,200 --> 00:38:47,730
facts go hang on a cio that's fighting

953
00:38:46,320 --> 00:38:49,950
you with your antivirus type comments

954
00:38:47,730 --> 00:38:51,720
and whitelisting enough facts we'll get

955
00:38:49,950 --> 00:38:53,460
to a tipping point when I go hang on a

956
00:38:51,720 --> 00:38:56,040
minute I'm going to have to re-evaluate

957
00:38:53,460 --> 00:38:57,930
it because it's going to start to create

958
00:38:56,040 --> 00:39:00,210
this cognitive dissonance that markers

959
00:38:57,930 --> 00:39:02,069
also talking about where you going maybe

960
00:39:00,210 --> 00:39:04,920
I am wrong here and I maybe I need to

961
00:39:02,070 --> 00:39:07,109
change my bets and I'm maybe I better

962
00:39:04,920 --> 00:39:08,310
change so there's a weight thing there's

963
00:39:07,109 --> 00:39:10,200
a lot of effort though if you're going

964
00:39:08,310 --> 00:39:15,000
to fight it that way there's a lot of

965
00:39:10,200 --> 00:39:17,490
effort so there's different graphics for

966
00:39:15,000 --> 00:39:21,270
cognitive biases and we don't need to

967
00:39:17,490 --> 00:39:23,129
get to the extra notes so look I hope

968
00:39:21,270 --> 00:39:25,710
this talk is giving you some things to

969
00:39:23,130 --> 00:39:27,990
think about some there's a whole lot of

970
00:39:25,710 --> 00:39:30,089
reading I wish I'd had when I saw marks

971
00:39:27,990 --> 00:39:31,890
slide about different podcasts I've got

972
00:39:30,089 --> 00:39:33,450
a whole lot of favorite ones I was

973
00:39:31,890 --> 00:39:34,710
actually a you know the famous security

974
00:39:33,450 --> 00:39:36,868
guy Eric Young here at this very

975
00:39:34,710 --> 00:39:38,369
conference about four years ago saying

976
00:39:36,869 --> 00:39:41,760
Gary you need to listen to a podcast

977
00:39:38,369 --> 00:39:44,250
called you are not so smart where the

978
00:39:41,760 --> 00:39:45,540
whole effort of the podcast is where

979
00:39:44,250 --> 00:39:47,640
people aren't making the obvious

980
00:39:45,540 --> 00:39:49,529
decisions because we're making and I've

981
00:39:47,640 --> 00:39:51,390
learned a lot from that and I hope some

982
00:39:49,530 --> 00:39:53,490
of it can be put to use in your your

983
00:39:51,390 --> 00:39:57,348
workplaces for benefit of your

984
00:39:53,490 --> 00:39:57,348
organization's and your careers I hope

985
00:40:01,549 --> 00:40:05,339
for everybody is curious the book that

986
00:40:04,229 --> 00:40:06,899
Gary was actually reference Carol is

987
00:40:05,339 --> 00:40:08,160
called the debunking handbook by John

988
00:40:06,900 --> 00:40:09,539
Cook and Stephen levin dosti

989
00:40:08,160 --> 00:40:11,489
and both still Gary and myself have

990
00:40:09,539 --> 00:40:13,529
posted links on Twitter thanks very much

991
00:40:11,489 --> 00:40:16,499
Gary um there's a fantastic presentation

992
00:40:13,529 --> 00:40:17,999
so any questions if you don't have

993
00:40:16,499 --> 00:40:19,589
questions but if you've got any extra

994
00:40:17,999 --> 00:40:21,450
insights or extra books you think I

995
00:40:19,589 --> 00:40:24,049
should read I'd love to hear from you

996
00:40:21,450 --> 00:40:24,049
thank you

