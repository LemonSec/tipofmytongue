1
00:00:09,300 --> 00:00:13,790
thank

2
00:00:10,500 --> 00:00:15,740
and so I'll be prayers

3
00:00:13,790 --> 00:00:19,509
sure of highly available service using

4
00:00:15,740 --> 00:00:21,530
any car that segment routing in ipv6

5
00:00:19,510 --> 00:00:23,300
just a little bit of more information

6
00:00:21,530 --> 00:00:25,340
about me I'm a soft engineer with

7
00:00:23,300 --> 00:00:27,350
Comcast I've been involved in different

8
00:00:25,340 --> 00:00:29,990
projects at different layers I have

9
00:00:27,350 --> 00:00:31,910
touched the gdb trying to make in-house

10
00:00:29,990 --> 00:00:34,970
modifications before at one point in

11
00:00:31,910 --> 00:00:36,860
time I be involved in some content based

12
00:00:34,970 --> 00:00:39,769
routing ad hoc networks so I know a

13
00:00:36,860 --> 00:00:43,010
little bit more about networks just a

14
00:00:39,770 --> 00:00:45,170
little bit on that side but I definitely

15
00:00:43,010 --> 00:00:47,420
have a lot more background as a software

16
00:00:45,170 --> 00:00:49,879
developer and actually that's the same

17
00:00:47,420 --> 00:00:52,879
background for most of the team which I

18
00:00:49,879 --> 00:00:54,140
belong to we named our team Aachen is on

19
00:00:52,879 --> 00:00:57,849
the Occam's razor

20
00:00:54,140 --> 00:00:59,780
we believe that solutions should be only

21
00:00:57,850 --> 00:01:03,979
involved parts that are really necessary

22
00:00:59,780 --> 00:01:06,140
right so we try to only necessary and

23
00:01:03,979 --> 00:01:10,039
not more than that I definitely would

24
00:01:06,140 --> 00:01:13,040
not call myself say network engineer in

25
00:01:10,040 --> 00:01:16,460
the traditional sense but I'm very happy

26
00:01:13,040 --> 00:01:18,170
for say the Monday afternoon panel when

27
00:01:16,460 --> 00:01:20,419
it was discussed that you know the

28
00:01:18,170 --> 00:01:22,490
networking food also professionals that

29
00:01:20,420 --> 00:01:25,070
are interested in solving like

30
00:01:22,490 --> 00:01:27,140
distributed systems problems which is

31
00:01:25,070 --> 00:01:30,229
definitely something that motivated us

32
00:01:27,140 --> 00:01:33,200
our team to seek a solution this address

33
00:01:30,230 --> 00:01:36,590
base we were trying to figure out how to

34
00:01:33,200 --> 00:01:38,890
improve availability in the many

35
00:01:36,590 --> 00:01:42,440
services that we offer in the company

36
00:01:38,890 --> 00:01:44,780
and as we delved into this problem we

37
00:01:42,440 --> 00:01:46,820
started noticing any cast as one

38
00:01:44,780 --> 00:01:50,390
component that could help address many

39
00:01:46,820 --> 00:01:53,839
issues and we saw and also as we you

40
00:01:50,390 --> 00:01:56,890
know that looked into this field we we

41
00:01:53,840 --> 00:02:00,710
felt that SRB six might be a very also

42
00:01:56,890 --> 00:02:02,360
provide capabilities we need I mean from

43
00:02:00,710 --> 00:02:04,759
the start I would like to say that we

44
00:02:02,360 --> 00:02:07,220
are not advocating one approach for

45
00:02:04,760 --> 00:02:09,500
segment routing over the other we are

46
00:02:07,220 --> 00:02:11,330
you know we're definitely users of

47
00:02:09,500 --> 00:02:13,930
technology in this field and we will be

48
00:02:11,330 --> 00:02:16,040
very happy to try out different

49
00:02:13,930 --> 00:02:18,470
approaches that help us improve the

50
00:02:16,040 --> 00:02:20,450
performance which were seeking so in

51
00:02:18,470 --> 00:02:22,040
this talk I'll be presenting all these

52
00:02:20,450 --> 00:02:24,560
points and

53
00:02:22,040 --> 00:02:26,929
we'll be showing how we think all these

54
00:02:24,560 --> 00:02:30,859
pieces can fit together and provide a

55
00:02:26,930 --> 00:02:33,799
short demo in container net so you know

56
00:02:30,859 --> 00:02:36,200
again we are we don't declare ourselves

57
00:02:33,799 --> 00:02:37,730
to be the subject matters in this field

58
00:02:36,200 --> 00:02:39,798
and we'll be more than happy to learn

59
00:02:37,730 --> 00:02:41,420
from the community so that you know

60
00:02:39,799 --> 00:02:44,239
please tell us you know if anything's

61
00:02:41,420 --> 00:02:48,379
missing what we have overlooked all

62
00:02:44,239 --> 00:02:50,000
right so what do we mean by providing a

63
00:02:48,379 --> 00:02:52,280
highly available service that's

64
00:02:50,000 --> 00:02:53,989
attributable beginning point so usually

65
00:02:52,280 --> 00:02:56,810
like we'd have a client make a request

66
00:02:53,989 --> 00:02:59,599
and the server who can answer that's the

67
00:02:56,810 --> 00:03:01,849
normal flow now what happens if the

68
00:02:59,599 --> 00:03:04,730
server goes down well then the client

69
00:03:01,849 --> 00:03:06,619
doesn't get the answer so what can we do

70
00:03:04,730 --> 00:03:10,040
to address this issue highly available

71
00:03:06,620 --> 00:03:12,139
service we assume that if the same

72
00:03:10,040 --> 00:03:14,328
content or same configuration of the

73
00:03:12,139 --> 00:03:17,689
original server is replicated at the

74
00:03:14,329 --> 00:03:19,909
second one then the second one can reply

75
00:03:17,689 --> 00:03:22,129
to the service provided that the request

76
00:03:19,909 --> 00:03:25,370
can be mapped to that one that's

77
00:03:22,129 --> 00:03:27,620
available by providing this other than

78
00:03:25,370 --> 00:03:30,739
the server can reply and by providing

79
00:03:27,620 --> 00:03:33,379
this multiplicity of resource providers

80
00:03:30,739 --> 00:03:36,260
we increase the availability of the

81
00:03:33,379 --> 00:03:42,738
service person right so this concept of

82
00:03:36,260 --> 00:03:45,948
course is used fairly like details like

83
00:03:42,739 --> 00:03:48,769
a present in say like a DNS base global

84
00:03:45,949 --> 00:03:52,010
traffic managers or layer 7 mapping a

85
00:03:48,769 --> 00:03:54,260
client reach out for of fqdn which is

86
00:03:52,010 --> 00:03:56,448
mapped to different IP addresses as they

87
00:03:54,260 --> 00:03:59,239
are available or based on certain policy

88
00:03:56,449 --> 00:04:01,370
based right and not only only our

89
00:03:59,239 --> 00:04:04,310
seventh is as possible of course in

90
00:04:01,370 --> 00:04:08,030
layer three it's also possible like a a

91
00:04:04,310 --> 00:04:10,189
single IP address can be the front right

92
00:04:08,030 --> 00:04:13,430
and in the back there are multiple

93
00:04:10,189 --> 00:04:15,828
different back-end servers so do this

94
00:04:13,430 --> 00:04:19,720
would be the principal of say a local

95
00:04:15,829 --> 00:04:23,330
traffic manager that operates a layer 3

96
00:04:19,720 --> 00:04:26,449
now when we group this together this

97
00:04:23,330 --> 00:04:28,139
often present architecture for highly

98
00:04:26,449 --> 00:04:33,389
available service right I mean

99
00:04:28,139 --> 00:04:36,900
we have like like a DNS base the global

100
00:04:33,389 --> 00:04:40,530
traffic manager that the word monitor

101
00:04:36,900 --> 00:04:43,560
different IP addresses for service

102
00:04:40,530 --> 00:04:46,138
availability and these IP addresses are

103
00:04:43,560 --> 00:04:49,050
actually not single servers but they are

104
00:04:46,139 --> 00:04:53,039
the front IP addresses of like multiple

105
00:04:49,050 --> 00:04:56,610
local locally available back-end servers

106
00:04:53,039 --> 00:04:58,770
so this is welcome architecture that we

107
00:04:56,610 --> 00:05:01,680
had actually when we started looking

108
00:04:58,770 --> 00:05:05,279
into that this providing highly

109
00:05:01,680 --> 00:05:07,590
available service now some of the issues

110
00:05:05,279 --> 00:05:11,789
that we at least experienced when we had

111
00:05:07,590 --> 00:05:14,878
this was that okay before like so this

112
00:05:11,789 --> 00:05:20,460
would be how this plays out saying like

113
00:05:14,879 --> 00:05:23,490
Novus era like us right so fqdn that it

114
00:05:20,460 --> 00:05:25,590
indicates the resource right is will be

115
00:05:23,490 --> 00:05:28,949
mapped multiple different IP addresses

116
00:05:25,590 --> 00:05:31,529
in this in the slide you can see that on

117
00:05:28,949 --> 00:05:34,020
three local data centers they would have

118
00:05:31,529 --> 00:05:36,240
different IP addresses the 2tm then

119
00:05:34,020 --> 00:05:38,609
provides a geographical diversity for

120
00:05:36,240 --> 00:05:40,919
the client access and the request will

121
00:05:38,610 --> 00:05:45,680
then be mapped to one of the data

122
00:05:40,919 --> 00:05:52,109
centers that have local redundancy now

123
00:05:45,680 --> 00:05:55,830
so this is actually how usually like the

124
00:05:52,110 --> 00:05:57,539
service is deployed right now some of

125
00:05:55,830 --> 00:06:00,000
the issues that we have found with this

126
00:05:57,539 --> 00:06:02,759
approach well it's highly dependent on

127
00:06:00,000 --> 00:06:04,860
client behavior right a client is can

128
00:06:02,759 --> 00:06:07,169
cache the results are of DNS lookup

129
00:06:04,860 --> 00:06:10,740
indefinitely if you want it it doesn't

130
00:06:07,169 --> 00:06:13,020
really have to obey the TTL field even

131
00:06:10,740 --> 00:06:15,900
though it's advantage to it so a day and

132
00:06:13,020 --> 00:06:19,318
II like the problem with this approach

133
00:06:15,900 --> 00:06:21,719
is that if say the client get an IP

134
00:06:19,319 --> 00:06:24,029
address from the DNS server then

135
00:06:21,719 --> 00:06:27,270
immediately after getting this IP

136
00:06:24,029 --> 00:06:29,849
address the server itself goes down then

137
00:06:27,270 --> 00:06:32,698
the client in mobians a compliance with

138
00:06:29,849 --> 00:06:35,699
the TTL will not try to do a new look up

139
00:06:32,699 --> 00:06:37,649
it will just keep trying retry maybe the

140
00:06:35,699 --> 00:06:40,050
original TTL a original IP address

141
00:06:37,649 --> 00:06:41,169
Aragon even though there are other

142
00:06:40,050 --> 00:06:43,479
servers

143
00:06:41,169 --> 00:06:46,870
servers that are available to provide

144
00:06:43,479 --> 00:06:48,729
the answer the requested wanted so that

145
00:06:46,870 --> 00:06:52,539
was one issue that we wanted to avoid

146
00:06:48,729 --> 00:06:55,719
and then of course depending on how this

147
00:06:52,539 --> 00:06:59,050
DNS resolution is done oftentimes the

148
00:06:55,719 --> 00:07:01,419
policy does not include leveraging the

149
00:06:59,050 --> 00:07:04,479
route information that's present rather

150
00:07:01,419 --> 00:07:07,330
the IP addresses return can be like say

151
00:07:04,479 --> 00:07:10,060
round robin or sometimes the DNS servers

152
00:07:07,330 --> 00:07:14,109
would like try to like establish the

153
00:07:10,060 --> 00:07:15,759
latency base but this is in a sense like

154
00:07:14,110 --> 00:07:17,620
solving the same problem twice the

155
00:07:15,759 --> 00:07:19,990
routing layer already solved that the

156
00:07:17,620 --> 00:07:22,810
cost based on a path based on the cost

157
00:07:19,990 --> 00:07:25,569
but we are like Travis on same problem

158
00:07:22,810 --> 00:07:32,860
twice so that was another issue that we

159
00:07:25,569 --> 00:07:34,870
found and then some groups in our

160
00:07:32,860 --> 00:07:38,080
company who have been who used this kind

161
00:07:34,870 --> 00:07:41,020
of like architecture they shared how

162
00:07:38,080 --> 00:07:44,620
like a local DNS resolvers end up being

163
00:07:41,020 --> 00:07:46,779
the unit of traffic control when the dns

164
00:07:44,620 --> 00:07:49,000
updates are different to a different

165
00:07:46,779 --> 00:07:51,370
resolution IP address say all the

166
00:07:49,000 --> 00:07:53,979
clients that go to their local resolver

167
00:07:51,370 --> 00:07:56,770
then they wholly get shifted right so

168
00:07:53,979 --> 00:08:02,020
becomes harder to control the traffic

169
00:07:56,770 --> 00:08:04,688
unit of course like extension the DNS or

170
00:08:02,020 --> 00:08:07,029
client subnet can mitigate this approach

171
00:08:04,689 --> 00:08:10,210
but well I guess it depends on whether

172
00:08:07,029 --> 00:08:13,870
it's available and then also if you can

173
00:08:10,210 --> 00:08:17,289
truly aggregate multiple like CIDR azure

174
00:08:13,870 --> 00:08:19,300
subnets so that it can scale well right

175
00:08:17,289 --> 00:08:21,339
I mean I mean those are some the issues

176
00:08:19,300 --> 00:08:25,479
that we have found and we would like to

177
00:08:21,339 --> 00:08:26,580
address them so in our understand and

178
00:08:25,479 --> 00:08:29,649
then how could these issues be addressed

179
00:08:26,580 --> 00:08:32,468
well one problem of the dependency on

180
00:08:29,649 --> 00:08:33,820
client behavior is that the ones that

181
00:08:32,469 --> 00:08:34,839
were the resource the resource that

182
00:08:33,820 --> 00:08:37,810
client needs

183
00:08:34,839 --> 00:08:40,570
once it gets it can change over time

184
00:08:37,809 --> 00:08:43,630
right but what if right in this whole

185
00:08:40,570 --> 00:08:47,019
stack we provide say an IP address that

186
00:08:43,630 --> 00:08:48,970
should always be valid as long as there

187
00:08:47,019 --> 00:08:52,420
is a server there that can provide the

188
00:08:48,970 --> 00:08:54,730
service so we go down the layer we don't

189
00:08:52,420 --> 00:08:56,949
use a layer 7 map

190
00:08:54,730 --> 00:08:59,320
to provide multiple redundancy of

191
00:08:56,949 --> 00:09:02,439
resources we use layer three and by

192
00:08:59,320 --> 00:09:05,440
using a layer three of solution right we

193
00:09:02,440 --> 00:09:08,910
would be actually leveraging already the

194
00:09:05,440 --> 00:09:13,660
like cost computation that the routers

195
00:09:08,910 --> 00:09:17,589
have given us so that is that's a

196
00:09:13,660 --> 00:09:19,930
thought that we had consider and for the

197
00:09:17,589 --> 00:09:21,880
traffic control issue with like we

198
00:09:19,930 --> 00:09:24,130
resorted to maybe having gateways that

199
00:09:21,880 --> 00:09:27,610
could intercept the packet and forward

200
00:09:24,130 --> 00:09:30,639
them to whatever you need it to be know

201
00:09:27,610 --> 00:09:33,699
for the first two issues that sounds

202
00:09:30,639 --> 00:09:38,110
very similar so how any case would work

203
00:09:33,699 --> 00:09:40,060
right in say if we have servers

204
00:09:38,110 --> 00:09:41,889
announcing the same IP address over

205
00:09:40,060 --> 00:09:45,130
different locations that would be any

206
00:09:41,889 --> 00:09:47,620
caste then in a local data center there

207
00:09:45,130 --> 00:09:50,949
would still be a service redundancy

208
00:09:47,620 --> 00:09:53,470
right but the fqdn if instead of mapping

209
00:09:50,949 --> 00:09:57,819
to multiple IP address gets mapped on a

210
00:09:53,470 --> 00:10:00,579
single one and then this single IP

211
00:09:57,820 --> 00:10:03,940
address would be present in all three

212
00:10:00,579 --> 00:10:07,300
say data centers or like the front end

213
00:10:03,940 --> 00:10:09,220
out to the service and then it said IP

214
00:10:07,300 --> 00:10:11,889
layer that we will be seeing this

215
00:10:09,220 --> 00:10:14,949
geographical diversity and when a client

216
00:10:11,889 --> 00:10:17,860
request goes in it will be then sent to

217
00:10:14,949 --> 00:10:19,510
one of the data centers that you know

218
00:10:17,860 --> 00:10:24,250
has that's advertising as a destination

219
00:10:19,510 --> 00:10:27,370
for that IP address now then assuming

220
00:10:24,250 --> 00:10:30,220
Anika's works well in that sense then we

221
00:10:27,370 --> 00:10:33,790
eliminate the issue of dependency on the

222
00:10:30,220 --> 00:10:35,769
client behavior and we actually leverage

223
00:10:33,790 --> 00:10:38,769
all relative information that is present

224
00:10:35,769 --> 00:10:41,800
in the routing layer in the network so

225
00:10:38,769 --> 00:10:44,350
we have addressed two issues but of

226
00:10:41,800 --> 00:10:46,359
course we know that most many traffic

227
00:10:44,350 --> 00:10:49,779
must most of traffic I guess right and

228
00:10:46,360 --> 00:10:52,300
still rely on TCP for correctness what

229
00:10:49,779 --> 00:10:56,589
would happen to a TCP based connection

230
00:10:52,300 --> 00:10:59,500
in this setup well we have the fqdn

231
00:10:56,589 --> 00:11:01,870
that map to single IP address that is

232
00:10:59,500 --> 00:11:04,390
advertised from multiple locations and

233
00:11:01,870 --> 00:11:07,660
then say a local back-end server goes

234
00:11:04,390 --> 00:11:08,500
down then the closest local server is no

235
00:11:07,660 --> 00:11:11,740
longer available

236
00:11:08,500 --> 00:11:14,280
a client then request that comes would

237
00:11:11,740 --> 00:11:17,590
be redirected to a remote one maybe and

238
00:11:14,280 --> 00:11:19,540
then what happens then if the closest

239
00:11:17,590 --> 00:11:22,210
local server recovers and the new the

240
00:11:19,540 --> 00:11:24,670
route is reestablished this of course

241
00:11:22,210 --> 00:11:28,090
will break the ongoing TCP connection

242
00:11:24,670 --> 00:11:30,010
state so this connectivity connection

243
00:11:28,090 --> 00:11:35,460
instability then is an issue that we

244
00:11:30,010 --> 00:11:38,170
should solve and but then we actually

245
00:11:35,460 --> 00:11:40,600
had already proposed the existence of a

246
00:11:38,170 --> 00:11:43,420
gateway that can help forward packets as

247
00:11:40,600 --> 00:11:46,780
a measure as a way of controlling

248
00:11:43,420 --> 00:11:48,729
traffic so in that case we can then take

249
00:11:46,780 --> 00:11:51,790
advantage of this solution this approach

250
00:11:48,730 --> 00:11:57,480
we had already proposed and used that to

251
00:11:51,790 --> 00:12:00,370
track connection state for TCP so then

252
00:11:57,480 --> 00:12:03,640
then the question that becomes if we

253
00:12:00,370 --> 00:12:06,370
need to have servers that can like

254
00:12:03,640 --> 00:12:09,340
dictate how trafficker will go how can

255
00:12:06,370 --> 00:12:13,270
we make that happen how can we direct

256
00:12:09,340 --> 00:12:16,480
traffic on a legacy from like a machine

257
00:12:13,270 --> 00:12:19,510
server that we have well we did that's

258
00:12:16,480 --> 00:12:23,980
when we looked and we looked into a

259
00:12:19,510 --> 00:12:27,340
segment rowdy right as but I'm just

260
00:12:23,980 --> 00:12:29,020
going to go briefly since we like had

261
00:12:27,340 --> 00:12:31,560
already like talks about segment routing

262
00:12:29,020 --> 00:12:34,720
but set my routing is essentially

263
00:12:31,560 --> 00:12:38,410
extension to the routing extension

264
00:12:34,720 --> 00:12:43,170
header that essentially we push into the

265
00:12:38,410 --> 00:12:45,730
ipv6 header a list of segments and the

266
00:12:43,170 --> 00:12:48,910
those knows that support the segment

267
00:12:45,730 --> 00:12:51,640
routing and conform to the list

268
00:12:48,910 --> 00:12:53,860
and send the packets accordingly right

269
00:12:51,640 --> 00:12:55,750
to the to the path that specified by the

270
00:12:53,860 --> 00:12:59,080
list in a sense is a source based

271
00:12:55,750 --> 00:13:01,990
routing right so say how does that work

272
00:12:59,080 --> 00:13:05,770
like just very simply say the original

273
00:13:01,990 --> 00:13:08,350
path from lower node s to D goes through

274
00:13:05,770 --> 00:13:11,590
x and y right that that if I could do if

275
00:13:08,350 --> 00:13:13,780
you just say sources s and D is the

276
00:13:11,590 --> 00:13:16,690
destination then this will be the path

277
00:13:13,780 --> 00:13:19,930
that a packet will follow but with

278
00:13:16,690 --> 00:13:21,360
segment routing then the source can say

279
00:13:19,930 --> 00:13:25,920
no I want

280
00:13:21,360 --> 00:13:29,220
so go through s xzd when this happens

281
00:13:25,920 --> 00:13:32,370
when this is set then the packet goes

282
00:13:29,220 --> 00:13:35,399
through s to X X we'll look at the

283
00:13:32,370 --> 00:13:38,570
segment and say oh the next hop that

284
00:13:35,399 --> 00:13:42,209
must go the packet must go through is Z

285
00:13:38,570 --> 00:13:46,410
so for sure the packet will go to Z you

286
00:13:42,209 --> 00:13:49,319
may cross Y but for sure we know Z will

287
00:13:46,410 --> 00:13:51,390
be present in the path then Z will look

288
00:13:49,320 --> 00:13:56,700
at the segment and say the next one is

289
00:13:51,390 --> 00:14:00,510
DS so I'll just send to D so in this set

290
00:13:56,700 --> 00:14:03,329
up the nodes that are in between this SX

291
00:14:00,510 --> 00:14:05,250
X Y Z they don't need to know actually

292
00:14:03,329 --> 00:14:06,630
set my routing at all seven rounds so

293
00:14:05,250 --> 00:14:08,790
only these note that are participating

294
00:14:06,630 --> 00:14:12,300
you need to be able to process the

295
00:14:08,790 --> 00:14:14,760
segment routes and then if this is the

296
00:14:12,300 --> 00:14:17,069
case then we have found a way to

297
00:14:14,760 --> 00:14:18,959
manipulate traffic to force them go

298
00:14:17,070 --> 00:14:24,060
wherever we want of course we are

299
00:14:18,959 --> 00:14:27,180
focusing on pv6 right so how that would

300
00:14:24,060 --> 00:14:30,119
work say like the same scenario the

301
00:14:27,180 --> 00:14:32,339
local backend server goes down it's no

302
00:14:30,120 --> 00:14:35,279
longer available the client requests

303
00:14:32,339 --> 00:14:37,949
goes to look for the IP address but

304
00:14:35,279 --> 00:14:41,640
because our gateway says due up in the

305
00:14:37,949 --> 00:14:45,990
inter locality the packet will still be

306
00:14:41,640 --> 00:14:49,170
forward to the closest or let's say the

307
00:14:45,990 --> 00:14:52,019
result of the anycast route and our

308
00:14:49,170 --> 00:14:55,860
gateways then would forward the packet

309
00:14:52,019 --> 00:14:58,050
to a remote cluster I mean this slide

310
00:14:55,860 --> 00:15:01,110
that may be like I put the map the first

311
00:14:58,050 --> 00:15:03,209
map like on the top just imply that it's

312
00:15:01,110 --> 00:15:04,589
just a lookup right so the client is

313
00:15:03,209 --> 00:15:08,310
still talking to the closest and then

314
00:15:04,589 --> 00:15:11,130
from we forward to the next and when the

315
00:15:08,310 --> 00:15:13,529
local cluster recovers we our gateways

316
00:15:11,130 --> 00:15:17,100
keep the state of the CP connection and

317
00:15:13,529 --> 00:15:19,800
they continue any data exchange still

318
00:15:17,100 --> 00:15:22,350
towards the remote server and but of

319
00:15:19,800 --> 00:15:25,979
course any new incoming requests can

320
00:15:22,350 --> 00:15:29,779
just be served locally so that's how we

321
00:15:25,980 --> 00:15:32,970
like this our architecture will work now

322
00:15:29,779 --> 00:15:34,209
then when we put all the pieces together

323
00:15:32,970 --> 00:15:36,999
this is how it

324
00:15:34,209 --> 00:15:41,709
would look like say in a data center

325
00:15:36,999 --> 00:15:44,800
this is how things you know could be we

326
00:15:41,709 --> 00:15:47,349
have a bunch of hash sure gateway notes

327
00:15:44,800 --> 00:15:49,779
these will be appearing that we're

328
00:15:47,350 --> 00:15:51,670
appearing with the local router they

329
00:15:49,779 --> 00:15:54,939
announced themselves as the destination

330
00:15:51,670 --> 00:15:58,719
for the anycase IP address and they will

331
00:15:54,939 --> 00:16:03,279
also take any incoming flow generator

332
00:15:58,720 --> 00:16:06,720
hash and send it to one of the second

333
00:16:03,279 --> 00:16:11,980
leader the router elements the og router

334
00:16:06,720 --> 00:16:15,490
the og router is the element then that

335
00:16:11,980 --> 00:16:18,160
will keep track of the connection it's

336
00:16:15,490 --> 00:16:21,699
this connection information then is

337
00:16:18,160 --> 00:16:24,040
split not split is duplicated between a

338
00:16:21,699 --> 00:16:27,069
primary or Jurado in a secondary router

339
00:16:24,040 --> 00:16:29,230
so that if the primary goes down the

340
00:16:27,069 --> 00:16:31,329
connection information is with pain on

341
00:16:29,230 --> 00:16:36,160
the secondary and the caseta connection

342
00:16:31,329 --> 00:16:38,649
can keep going then on the back end

343
00:16:36,160 --> 00:16:41,860
server side we will be running an agent

344
00:16:38,649 --> 00:16:44,829
an agent would be an e b PF filter

345
00:16:41,860 --> 00:16:46,660
that's running transparently to the

346
00:16:44,829 --> 00:16:49,839
application but is on the same host and

347
00:16:46,660 --> 00:16:53,019
they can actually remove and or air as

348
00:16:49,839 --> 00:16:55,839
our v6 headers as needed so they could

349
00:16:53,019 --> 00:16:57,699
send responses back to the router or g

350
00:16:55,839 --> 00:17:01,379
router for connection tracking purposes

351
00:16:57,699 --> 00:17:06,668
or send response directly to the client

352
00:17:01,379 --> 00:17:08,829
so this is an overall architecture that

353
00:17:06,669 --> 00:17:12,610
we envision for that will improve the

354
00:17:08,829 --> 00:17:15,188
availability so so if this is

355
00:17:12,609 --> 00:17:18,849
architecture then how do we see it

356
00:17:15,189 --> 00:17:20,649
working say for TCP connection so bear

357
00:17:18,849 --> 00:17:23,500
with me this packet animation there are

358
00:17:20,648 --> 00:17:25,688
few glitches here and there but say a

359
00:17:23,500 --> 00:17:27,869
client sends out sim packet you want to

360
00:17:25,689 --> 00:17:31,120
talk to the service IP get a request

361
00:17:27,869 --> 00:17:32,949
then it will just set the destination to

362
00:17:31,120 --> 00:17:36,309
be the server's IP to any case address

363
00:17:32,950 --> 00:17:38,919
the packet would then go to the hasher

364
00:17:36,309 --> 00:17:41,320
which is the destination that has been

365
00:17:38,919 --> 00:17:43,990
said the Hatter then we'll add the

366
00:17:41,320 --> 00:17:46,970
segment route to the packet and sent to

367
00:17:43,990 --> 00:17:50,750
the local OD router is on the hash

368
00:17:46,970 --> 00:17:52,460
result the og router monitors the local

369
00:17:50,750 --> 00:17:54,770
back-end servers and say oh I have

370
00:17:52,460 --> 00:17:57,770
actually a back-end server available so

371
00:17:54,770 --> 00:18:00,790
I will update the segment route list and

372
00:17:57,770 --> 00:18:05,210
then I would send a segment to the agent

373
00:18:00,790 --> 00:18:07,639
the agent grabs the packet at xdp point

374
00:18:05,210 --> 00:18:09,800
before sending it into the kernel so

375
00:18:07,640 --> 00:18:11,660
it's able to see oh it's a new

376
00:18:09,800 --> 00:18:14,360
connection I will add an entry to my

377
00:18:11,660 --> 00:18:16,190
connection table I will strip down the

378
00:18:14,360 --> 00:18:18,889
segment routes the segment extension

379
00:18:16,190 --> 00:18:20,330
header it just becomes a regular ipv6

380
00:18:18,890 --> 00:18:22,070
packet and I sent to the kernel and the

381
00:18:20,330 --> 00:18:24,530
kernel will then forward a package to

382
00:18:22,070 --> 00:18:27,200
the application once the application

383
00:18:24,530 --> 00:18:29,899
responds the same agent then we'll grab

384
00:18:27,200 --> 00:18:33,590
the packet and see oh this belongs to

385
00:18:29,900 --> 00:18:36,230
the flow that I've been tracking so what

386
00:18:33,590 --> 00:18:38,990
we'll do in this initial TCP three-way

387
00:18:36,230 --> 00:18:42,080
handshake it will add a segment route to

388
00:18:38,990 --> 00:18:45,110
the response packet that will send back

389
00:18:42,080 --> 00:18:48,889
to the OG router so that og router now

390
00:18:45,110 --> 00:18:50,540
knows okay for this flow is that that

391
00:18:48,890 --> 00:18:53,660
can server that I need to send a packet

392
00:18:50,540 --> 00:18:58,370
soon so this then goes to the og router

393
00:18:53,660 --> 00:19:00,350
and now the Fuji router has the connect

394
00:18:58,370 --> 00:19:04,909
information it will take this packet

395
00:19:00,350 --> 00:19:06,919
strips the segment out and like make the

396
00:19:04,910 --> 00:19:08,540
packet on just like regular ipv6 packet

397
00:19:06,920 --> 00:19:11,510
without like my route but from the

398
00:19:08,540 --> 00:19:15,830
source address of the service IP and

399
00:19:11,510 --> 00:19:19,129
send it back to the client so in this

400
00:19:15,830 --> 00:19:20,480
way the client to the client he just

401
00:19:19,130 --> 00:19:23,900
sent us impacted to the server's IP

402
00:19:20,480 --> 00:19:26,210
address and got a reply back then the

403
00:19:23,900 --> 00:19:28,610
client will usually analogous in syn ack

404
00:19:26,210 --> 00:19:31,310
ack three-way handshake and this add

405
00:19:28,610 --> 00:19:33,889
packet and followed the same path go

406
00:19:31,310 --> 00:19:37,250
through the og router agent and the

407
00:19:33,890 --> 00:19:40,700
agent sends the act from the client to

408
00:19:37,250 --> 00:19:41,480
the application to the kernel know what

409
00:19:40,700 --> 00:19:44,180
happens then

410
00:19:41,480 --> 00:19:46,910
for an ongoing TCP connection when data

411
00:19:44,180 --> 00:19:50,830
is being transferred say the client

412
00:19:46,910 --> 00:19:53,090
wants to fetch some data then the the

413
00:19:50,830 --> 00:19:55,820
you know the Pak original goes to the

414
00:19:53,090 --> 00:19:58,189
hasher and because it's the same TCP

415
00:19:55,820 --> 00:19:59,210
flow the Hatcher was sent to the virtual

416
00:19:58,190 --> 00:20:01,580
router

417
00:19:59,210 --> 00:20:03,409
and the og router look at the segment

418
00:20:01,580 --> 00:20:06,918
router censored og router the og router

419
00:20:03,409 --> 00:20:08,480
will then update that take a look at the

420
00:20:06,919 --> 00:20:10,490
segment route and decide that okay he

421
00:20:08,480 --> 00:20:12,649
needs to go to the agent and the agent

422
00:20:10,490 --> 00:20:14,570
will do the same thing we'll take the

423
00:20:12,649 --> 00:20:15,889
incoming packet the stricter segment

424
00:20:14,570 --> 00:20:18,918
route and send to the application

425
00:20:15,890 --> 00:20:21,529
now when the data front application

426
00:20:18,919 --> 00:20:22,760
comes back it realized it looks up and

427
00:20:21,529 --> 00:20:25,279
said oh this is not a connection

428
00:20:22,760 --> 00:20:27,260
establishing I assume the og primary and

429
00:20:25,279 --> 00:20:29,059
secondary routers have already the

430
00:20:27,260 --> 00:20:32,000
connection information I can just send

431
00:20:29,059 --> 00:20:36,440
the data back direct to the client so in

432
00:20:32,000 --> 00:20:39,980
this way we preserve the cement so TCP

433
00:20:36,440 --> 00:20:42,770
connection so using this segment routes

434
00:20:39,980 --> 00:20:46,580
and hna PPF now why do we need all that

435
00:20:42,770 --> 00:20:49,399
right so well consider if there is a

436
00:20:46,580 --> 00:20:51,850
failover that's needed all right so in

437
00:20:49,399 --> 00:20:54,889
this I like so far we've only seen

438
00:20:51,850 --> 00:20:57,799
animations on the east side of the slide

439
00:20:54,890 --> 00:21:01,850
what happens if say a seeing packet goes

440
00:20:57,799 --> 00:21:02,510
to the national and the local service

441
00:21:01,850 --> 00:21:05,600
isn't available

442
00:21:02,510 --> 00:21:07,700
well the hasher will still send to the

443
00:21:05,600 --> 00:21:10,389
OT router but what you router now

444
00:21:07,700 --> 00:21:12,409
noticing that the local is unavailable

445
00:21:10,390 --> 00:21:14,659
forwards the packets to the remote

446
00:21:12,409 --> 00:21:16,760
cluster it will go through the remote

447
00:21:14,659 --> 00:21:19,130
cluster huh sure the hasher will pick

448
00:21:16,760 --> 00:21:21,770
will update the segment list and sense

449
00:21:19,130 --> 00:21:24,080
with its own local OT router that will

450
00:21:21,770 --> 00:21:27,320
then notice oh I still have a back-end

451
00:21:24,080 --> 00:21:30,830
server available I can send it to there

452
00:21:27,320 --> 00:21:33,230
now in this slide I've shown east and

453
00:21:30,830 --> 00:21:36,918
west but nothing prevents say you have

454
00:21:33,230 --> 00:21:40,970
more is west central one could imagine

455
00:21:36,919 --> 00:21:43,940
this packet can traverse and find

456
00:21:40,970 --> 00:21:44,929
Quantico the best data center to answer

457
00:21:43,940 --> 00:21:47,690
this request

458
00:21:44,929 --> 00:21:50,750
policy base it depends on how we want to

459
00:21:47,690 --> 00:21:53,419
set how this packet is respond will

460
00:21:50,750 --> 00:21:55,940
respond right not simply if just one

461
00:21:53,419 --> 00:21:59,539
fell over but we can incorporate

462
00:21:55,940 --> 00:22:02,090
elements that dictate how the incoming

463
00:21:59,539 --> 00:22:04,309
request should be answer so but continue

464
00:22:02,090 --> 00:22:07,668
our example the age and then here we'll

465
00:22:04,309 --> 00:22:09,678
know exactly how it should like image

466
00:22:07,669 --> 00:22:11,500
just strip the segment route ghosted

467
00:22:09,679 --> 00:22:14,980
application grab the response

468
00:22:11,500 --> 00:22:16,210
and then it travels back it goes back to

469
00:22:14,980 --> 00:22:20,080
the same path

470
00:22:16,210 --> 00:22:21,760
it went came from so the local would you

471
00:22:20,080 --> 00:22:23,590
router knows that the packet can be

472
00:22:21,760 --> 00:22:26,410
forward to that one specific remote

473
00:22:23,590 --> 00:22:29,620
cluster and the connection is tracked

474
00:22:26,410 --> 00:22:32,650
also in the remote cluster and then of

475
00:22:29,620 --> 00:22:39,729
course this syn/ack packet is sent back

476
00:22:32,650 --> 00:22:41,620
and the ACK response will then go the

477
00:22:39,730 --> 00:22:46,630
same same way same path right so the

478
00:22:41,620 --> 00:22:48,459
acting come and we'll go to the leg the

479
00:22:46,630 --> 00:22:53,070
same thing same thing will happen add a

480
00:22:48,460 --> 00:22:55,410
segment route and send back and ongoing

481
00:22:53,070 --> 00:22:58,870
data transfer will follow the same path

482
00:22:55,410 --> 00:23:01,800
but in in the same way the GATT will go

483
00:22:58,870 --> 00:23:04,959
to the local which will be then like

484
00:23:01,800 --> 00:23:06,580
forwarded to the remote and at this

485
00:23:04,960 --> 00:23:09,700
point because the connection has been

486
00:23:06,580 --> 00:23:12,129
established this agent then can choose

487
00:23:09,700 --> 00:23:13,680
to respect will will respond directly to

488
00:23:12,130 --> 00:23:17,770
the client because there's no need for

489
00:23:13,680 --> 00:23:19,690
tracking this connection so that's how

490
00:23:17,770 --> 00:23:22,420
we're doing vision and I don't have to

491
00:23:19,690 --> 00:23:24,700
effect animation here but at the close

492
00:23:22,420 --> 00:23:28,320
of a TCP session when during the

493
00:23:24,700 --> 00:23:30,400
exchange of a thin packet then this

494
00:23:28,320 --> 00:23:32,560
connections can be cleared from the

495
00:23:30,400 --> 00:23:37,210
connection table both in the OD router

496
00:23:32,560 --> 00:23:39,310
and on the client side so in this way we

497
00:23:37,210 --> 00:23:42,310
preserve the semantics of TCP for that

498
00:23:39,310 --> 00:23:44,530
client we hide the fill over details to

499
00:23:42,310 --> 00:23:46,840
the client and we can keep an ongoing

500
00:23:44,530 --> 00:23:51,820
TCP connection even if the local

501
00:23:46,840 --> 00:23:54,220
back-end server recovers right so we

502
00:23:51,820 --> 00:23:56,560
allow failover but as I mentioned

503
00:23:54,220 --> 00:23:58,870
failover you can just consider a

504
00:23:56,560 --> 00:24:01,690
specific instance of a policy-based

505
00:23:58,870 --> 00:24:04,780
traffic management right because our og

506
00:24:01,690 --> 00:24:07,570
known as gateway to incoming trafficker

507
00:24:04,780 --> 00:24:10,330
we convey because of the SR v6 or

508
00:24:07,570 --> 00:24:13,419
segment route we control exactly how we

509
00:24:10,330 --> 00:24:15,879
want this tractor to go so we can shape

510
00:24:13,420 --> 00:24:19,030
the traffic based on the needs of the

511
00:24:15,880 --> 00:24:22,170
back-end server and create policy

512
00:24:19,030 --> 00:24:25,629
profiles for traffic management

513
00:24:22,170 --> 00:24:27,310
so say when incoming traffic to local

514
00:24:25,630 --> 00:24:29,650
cluster he's 90% to start forwarding

515
00:24:27,310 --> 00:24:33,220
travel to remote cluster right so that's

516
00:24:29,650 --> 00:24:35,080
actually something that we can

517
00:24:33,220 --> 00:24:37,060
incorporate it doesn't have to be to

518
00:24:35,080 --> 00:24:39,730
this one specific and filled over you

519
00:24:37,060 --> 00:24:41,379
can split across multiple right and then

520
00:24:39,730 --> 00:24:43,660
this connects would all be tracked and

521
00:24:41,380 --> 00:24:45,610
of course as I mentioned filled over

522
00:24:43,660 --> 00:24:47,620
would be say cluster capacitor up to 0

523
00:24:45,610 --> 00:24:52,240
any new incoming trackers were to remote

524
00:24:47,620 --> 00:24:55,449
cluster so that's how we envision this

525
00:24:52,240 --> 00:24:58,900
architecture it definitely does not like

526
00:24:55,450 --> 00:25:01,300
address the issue that we have seen now

527
00:24:58,900 --> 00:25:04,210
I mentioned our background is software

528
00:25:01,300 --> 00:25:07,510
development we work actually collaborate

529
00:25:04,210 --> 00:25:10,360
with the network team in a Comcast so

530
00:25:07,510 --> 00:25:11,170
that we can also try out our ideas and

531
00:25:10,360 --> 00:25:15,790
test

532
00:25:11,170 --> 00:25:17,440
we are currently like like trying to set

533
00:25:15,790 --> 00:25:21,159
up a lab so that we can test this idea

534
00:25:17,440 --> 00:25:23,710
but to say it sort of as a proof of

535
00:25:21,160 --> 00:25:26,890
concept to our like vision or

536
00:25:23,710 --> 00:25:30,550
architecture we actually enable a like

537
00:25:26,890 --> 00:25:34,060
this set up in container net now what is

538
00:25:30,550 --> 00:25:35,889
container net is Porter of mignonette

539
00:25:34,060 --> 00:25:38,169
the supports running docker containers

540
00:25:35,890 --> 00:25:41,980
as nodes in the I should say they're

541
00:25:38,170 --> 00:25:44,260
virtual network all right now like you

542
00:25:41,980 --> 00:25:45,880
know I did a recursive definition right

543
00:25:44,260 --> 00:25:48,520
so what is container there's a Porter

544
00:25:45,880 --> 00:25:50,650
mininet so what is mini net mini net is

545
00:25:48,520 --> 00:25:53,530
defined as a network emulation

546
00:25:50,650 --> 00:25:55,480
orchestration system that allows us to

547
00:25:53,530 --> 00:25:57,730
run a collection of n nodes nodes link

548
00:25:55,480 --> 00:26:01,210
switches to provide a instant virtual

549
00:25:57,730 --> 00:26:04,930
network on your laptop it does this by

550
00:26:01,210 --> 00:26:08,500
using network namespaces so that you can

551
00:26:04,930 --> 00:26:11,710
create nodes in your in the laptop to

552
00:26:08,500 --> 00:26:15,880
emulate the presence of a host and it

553
00:26:11,710 --> 00:26:20,290
uses VF pairs virtual Ethernet pairs to

554
00:26:15,880 --> 00:26:22,540
emulate links right so it has a Python

555
00:26:20,290 --> 00:26:25,270
API that allows us to create a network

556
00:26:22,540 --> 00:26:28,560
from scratch and set up the links and

557
00:26:25,270 --> 00:26:32,010
the switches the switches are usually in

558
00:26:28,560 --> 00:26:33,929
by running the open flow controller so

559
00:26:32,010 --> 00:26:36,930
that the switch element is a learning

560
00:26:33,930 --> 00:26:39,750
switch and when advantage that the

561
00:26:36,930 --> 00:26:42,630
software is run as is right once against

562
00:26:39,750 --> 00:26:45,060
the real leanest network stack so that's

563
00:26:42,630 --> 00:26:47,820
how we can we actually our the

564
00:26:45,060 --> 00:26:49,530
development right so we did our code and

565
00:26:47,820 --> 00:26:52,889
we can test against the venous network

566
00:26:49,530 --> 00:26:56,700
stack so one adventure that's listed by

567
00:26:52,890 --> 00:26:58,920
container net is that say when T CBR was

568
00:26:56,700 --> 00:27:01,950
released as a dinner tomorrow we could

569
00:26:58,920 --> 00:27:04,260
running container net or at mini net but

570
00:27:01,950 --> 00:27:09,300
of course because it's an emulation on a

571
00:27:04,260 --> 00:27:11,490
local machine its you cannot emulate say

572
00:27:09,300 --> 00:27:13,230
speed higher than is possible by the

573
00:27:11,490 --> 00:27:15,480
underlying hardware rather you cannot do

574
00:27:13,230 --> 00:27:18,300
that it's it's bound by the physical

575
00:27:15,480 --> 00:27:20,490
laws unlike a simulator I the simulator

576
00:27:18,300 --> 00:27:22,940
can simulate things that are different

577
00:27:20,490 --> 00:27:25,590
but the emulator you hit the capacity

578
00:27:22,940 --> 00:27:27,900
limitations of the physical hardware and

579
00:27:25,590 --> 00:27:31,909
it's leanness only and you only suppose

580
00:27:27,900 --> 00:27:35,340
ethernet links but it served our purpose

581
00:27:31,910 --> 00:27:39,930
we were able to use container to test

582
00:27:35,340 --> 00:27:42,899
our ideas so how do we develop our OG

583
00:27:39,930 --> 00:27:45,420
nodes hash and router we're actually

584
00:27:42,900 --> 00:27:49,080
using a DB TK for fast data processing

585
00:27:45,420 --> 00:27:50,640
we develop using rust so all the packet

586
00:27:49,080 --> 00:27:53,250
animation actually we already

587
00:27:50,640 --> 00:27:56,880
implemented in the using this network's

588
00:27:53,250 --> 00:28:00,330
framework right it's is that you know

589
00:27:56,880 --> 00:28:03,810
based on TB TK we are actively working

590
00:28:00,330 --> 00:28:07,169
on refactoring networks to suit our

591
00:28:03,810 --> 00:28:09,810
purposes like that's and then hopefully

592
00:28:07,170 --> 00:28:11,730
as are we our project matures more and

593
00:28:09,810 --> 00:28:13,350
more then we'll be sharing with the

594
00:28:11,730 --> 00:28:17,160
community and like hoping to get

595
00:28:13,350 --> 00:28:19,530
feedback the agent as I mention briefly

596
00:28:17,160 --> 00:28:23,460
is in click was implemented using EBP F

597
00:28:19,530 --> 00:28:27,330
was the code written in C and we load it

598
00:28:23,460 --> 00:28:30,630
to the nodes using DCC so it's it's it's

599
00:28:27,330 --> 00:28:33,689
a filter that runs on X DB x DP extra

600
00:28:30,630 --> 00:28:36,680
Express data path on the ingress and a

601
00:28:33,690 --> 00:28:40,820
PC on the egress

602
00:28:36,680 --> 00:28:46,670
so all this actually is the real code

603
00:28:40,820 --> 00:28:49,370
that is run in container net so in the

604
00:28:46,670 --> 00:28:52,370
routers in the container net demo that

605
00:28:49,370 --> 00:28:55,149
I'm gonna show they run like old routing

606
00:28:52,370 --> 00:28:57,320
software progress zebra BGP and for

607
00:28:55,150 --> 00:28:59,980
peering for our oh ji-hun should not

608
00:28:57,320 --> 00:29:02,840
appear we run go BGP Tucker

609
00:28:59,980 --> 00:29:07,430
so container now right so we actually

610
00:29:02,840 --> 00:29:10,939
run we make the containers and we

611
00:29:07,430 --> 00:29:12,230
emulate them like we use in container

612
00:29:10,940 --> 00:29:14,690
net themselves we use something called

613
00:29:12,230 --> 00:29:17,630
docker compose that can bring multiple

614
00:29:14,690 --> 00:29:21,350
different docker containers and run them

615
00:29:17,630 --> 00:29:25,790
on top of a docker container so emulate

616
00:29:21,350 --> 00:29:29,480
the same layout that will have say in a

617
00:29:25,790 --> 00:29:33,260
real bare metal server so actually like

618
00:29:29,480 --> 00:29:35,870
for instance in one of our hash test we

619
00:29:33,260 --> 00:29:38,570
just push out a docker compose yellow

620
00:29:35,870 --> 00:29:40,969
file and we grab the containers that we

621
00:29:38,570 --> 00:29:42,379
can just pick them up so in the same way

622
00:29:40,970 --> 00:29:44,690
in the Barents the server in the same

623
00:29:42,380 --> 00:29:49,730
way in the container in container net

624
00:29:44,690 --> 00:29:51,770
and currently in our demo we actually

625
00:29:49,730 --> 00:29:54,440
run console for health check and status

626
00:29:51,770 --> 00:29:57,379
and in today's demo we'll be showing a

627
00:29:54,440 --> 00:30:01,940
dashboard that was generated by having

628
00:29:57,380 --> 00:30:04,880
our clients and servers admit like stats

629
00:30:01,940 --> 00:30:09,230
to influx to be known and we visualize

630
00:30:04,880 --> 00:30:11,660
it via Agrafena dashboard so this is

631
00:30:09,230 --> 00:30:15,140
just an introduction to the container

632
00:30:11,660 --> 00:30:22,310
net demo so next i will be showing the

633
00:30:15,140 --> 00:30:26,870
video so say in our topology right so we

634
00:30:22,310 --> 00:30:29,120
say make run so this will bring up and

635
00:30:26,870 --> 00:30:31,250
the python script you can see through

636
00:30:29,120 --> 00:30:35,629
here that is try go out and pulling the

637
00:30:31,250 --> 00:30:37,550
containers and this video was sped up a

638
00:30:35,630 --> 00:30:39,470
little bit it's not as fast as this so

639
00:30:37,550 --> 00:30:41,510
that you know our save a little space in

640
00:30:39,470 --> 00:30:42,740
the presentation file but this is how

641
00:30:41,510 --> 00:30:46,250
you can happen where the nodes are

642
00:30:42,740 --> 00:30:48,590
brought up they are different commands

643
00:30:46,250 --> 00:30:49,810
that apply to them see we can list here

644
00:30:48,590 --> 00:30:53,379
all the different nodes that

645
00:30:49,810 --> 00:30:56,230
they're the og H is our hash notes OG

646
00:30:53,380 --> 00:30:58,900
our Aurora knowns and then east and west

647
00:30:56,230 --> 00:31:03,040
right so in this demo we're going to

648
00:30:58,900 --> 00:31:05,920
show a Phil over when og so then two

649
00:31:03,040 --> 00:31:09,700
routers the r1 and r2 in the same layout

650
00:31:05,920 --> 00:31:12,010
of the slide and when the oGH container

651
00:31:09,700 --> 00:31:15,490
is brought up the gobi GP container

652
00:31:12,010 --> 00:31:19,480
peers with the BGP running on the r1 r2

653
00:31:15,490 --> 00:31:23,050
and we can establish connection and like

654
00:31:19,480 --> 00:31:31,240
announce the routes for our any class IP

655
00:31:23,050 --> 00:31:33,280
address and then have it set up so then

656
00:31:31,240 --> 00:31:36,040
we will start also the monitoring nodes

657
00:31:33,280 --> 00:31:38,980
and then the influx DB and the graph

658
00:31:36,040 --> 00:31:44,920
under nodes so that we can visualize on

659
00:31:38,980 --> 00:31:50,080
the dashboard so like this is the end

660
00:31:44,920 --> 00:31:52,060
result of the dashboard so you can see

661
00:31:50,080 --> 00:31:54,550
that on the top we have a client with

662
00:31:52,060 --> 00:31:56,950
track client and on the bottom we have

663
00:31:54,550 --> 00:31:59,950
one hash node and we already scroll down

664
00:31:56,950 --> 00:32:01,900
to three router nodes and then the agent

665
00:31:59,950 --> 00:32:04,000
which is the backend server in this

666
00:32:01,900 --> 00:32:06,190
specific that we haven't then at east

667
00:32:04,000 --> 00:32:07,480
and the west dashboard right so not

668
00:32:06,190 --> 00:32:09,370
right now there's no traffic

669
00:32:07,480 --> 00:32:11,710
I just wanted to measure that in this

670
00:32:09,370 --> 00:32:16,229
specific the polish scenario our client

671
00:32:11,710 --> 00:32:18,370
didn't is not emitting stats to the

672
00:32:16,230 --> 00:32:19,960
dashboard so we will not see any stats

673
00:32:18,370 --> 00:32:22,750
on the client side I have another video

674
00:32:19,960 --> 00:32:26,020
that will show but there now we need to

675
00:32:22,750 --> 00:32:27,820
start the the traffic we wrapped so

676
00:32:26,020 --> 00:32:29,500
these are actually all commands that we

677
00:32:27,820 --> 00:32:31,300
use via like a doctor right because

678
00:32:29,500 --> 00:32:33,760
there's an all docker containers that

679
00:32:31,300 --> 00:32:35,560
running on this vagrant machine so but

680
00:32:33,760 --> 00:32:38,290
we wrapped them using the script and the

681
00:32:35,560 --> 00:32:39,940
film over to means that we send one curl

682
00:32:38,290 --> 00:32:42,460
when it just be request every two

683
00:32:39,940 --> 00:32:45,220
seconds so we can see that this client

684
00:32:42,460 --> 00:32:47,830
is on the west side so it hit the server

685
00:32:45,220 --> 00:32:50,500
on the west side that 2001 five and

686
00:32:47,830 --> 00:32:52,840
eight is our anycast IP address now we

687
00:32:50,500 --> 00:32:54,970
can see data flowing the hash sure takes

688
00:32:52,840 --> 00:32:57,370
these are short-lived curl HTTP requests

689
00:32:54,970 --> 00:32:58,990
so each one is a different flow these

690
00:32:57,370 --> 00:33:01,330
flows get spread by the hasha to the

691
00:32:58,990 --> 00:33:02,770
multiple og routers right so that each

692
00:33:01,330 --> 00:33:06,428
one will be tracking the

693
00:33:02,770 --> 00:33:08,620
connection information so you know for

694
00:33:06,429 --> 00:33:09,940
scalability and then this connection

695
00:33:08,620 --> 00:33:12,070
think we all go back to the same

696
00:33:09,940 --> 00:33:16,179
back-end server because we in this

697
00:33:12,070 --> 00:33:18,010
topology we only brought up one but yeah

698
00:33:16,179 --> 00:33:20,320
so this is just to show that you know

699
00:33:18,010 --> 00:33:22,270
the traffic is spread in a sense evenly

700
00:33:20,320 --> 00:33:25,600
among the three routers and then the

701
00:33:22,270 --> 00:33:29,830
goes to the back end now next what we

702
00:33:25,600 --> 00:33:33,040
need to do then is to stop the backend

703
00:33:29,830 --> 00:33:41,110
server that is running on this current

704
00:33:33,040 --> 00:33:42,639
cluster so yeah oh yeah then to confirm

705
00:33:41,110 --> 00:33:45,309
right there's currently no traffic going

706
00:33:42,640 --> 00:33:47,470
to decide because the ne has would

707
00:33:45,309 --> 00:33:51,840
attract all the traffic to this closest

708
00:33:47,470 --> 00:33:55,660
cluster so now we need to then stop the

709
00:33:51,840 --> 00:33:58,840
West clock like a West server and once

710
00:33:55,660 --> 00:34:01,179
this West server client is stopped we

711
00:33:58,840 --> 00:34:05,379
should see the response coming back from

712
00:34:01,179 --> 00:34:08,230
the east and wish but however the packet

713
00:34:05,380 --> 00:34:09,730
would still flow through the hasher and

714
00:34:08,230 --> 00:34:11,500
the routers on the West because

715
00:34:09,730 --> 00:34:15,609
connections still moving forward

716
00:34:11,500 --> 00:34:19,480
directions being tracked right the agent

717
00:34:15,609 --> 00:34:22,779
will yeah so you know there was some

718
00:34:19,480 --> 00:34:25,359
like a delay in this stock command so

719
00:34:22,780 --> 00:34:27,879
that why it's not as fast as we would

720
00:34:25,359 --> 00:34:30,969
like to be we are definitely looking

721
00:34:27,879 --> 00:34:36,339
into how to like improve this process

722
00:34:30,969 --> 00:34:40,540
but the overall would happen is that

723
00:34:36,340 --> 00:34:42,070
during this time when the backend server

724
00:34:40,540 --> 00:34:45,699
starts the server

725
00:34:42,070 --> 00:34:49,060
stop yeah so finally the responded then

726
00:34:45,699 --> 00:34:50,830
you see that was a on the left side of

727
00:34:49,060 --> 00:34:53,379
the screen there was an empty response

728
00:34:50,830 --> 00:34:55,509
this is the time when the console the

729
00:34:53,379 --> 00:34:57,759
health the health check did not detected

730
00:34:55,510 --> 00:34:59,520
that that had failed but immediately

731
00:34:57,760 --> 00:35:02,440
upon detection the East server

732
00:34:59,520 --> 00:35:04,240
responsible came back so in this way we

733
00:35:02,440 --> 00:35:06,550
can see that is no longer dependent on

734
00:35:04,240 --> 00:35:09,939
the TTL the client just keeps making

735
00:35:06,550 --> 00:35:11,760
requests and is up to how fast me in the

736
00:35:09,940 --> 00:35:14,350
service provider can detect the failure

737
00:35:11,760 --> 00:35:15,190
once the detection happens takes place

738
00:35:14,350 --> 00:35:18,880
the route is

739
00:35:15,190 --> 00:35:21,070
we can be set out so so to the server

740
00:35:18,880 --> 00:35:24,130
that's available right and then on this

741
00:35:21,070 --> 00:35:26,770
side we can see that the traffic started

742
00:35:24,130 --> 00:35:29,590
flowing to the east cluster flows

743
00:35:26,770 --> 00:35:34,960
through the east router and is getting

744
00:35:29,590 --> 00:35:38,470
serviced by the east side back-end

745
00:35:34,960 --> 00:35:40,810
server now I mean I don't have a long

746
00:35:38,470 --> 00:35:43,569
live TCP connection example here to

747
00:35:40,810 --> 00:35:46,240
track but you know just this short-lived

748
00:35:43,570 --> 00:35:49,930
ones if we start the web server on the

749
00:35:46,240 --> 00:35:55,060
West then the traffic will shift back to

750
00:35:49,930 --> 00:35:59,560
the west right so that's how this would

751
00:35:55,060 --> 00:36:02,200
happen now and then yes again it depends

752
00:35:59,560 --> 00:36:04,570
all depends on how fast we can detect a

753
00:36:02,200 --> 00:36:07,060
change of conditions in our network we

754
00:36:04,570 --> 00:36:10,480
no longer need to rely on client

755
00:36:07,060 --> 00:36:15,009
behavior to address availability issues

756
00:36:10,480 --> 00:36:17,260
right so let me go to the next video in

757
00:36:15,010 --> 00:36:19,450
this second video I skipped all the

758
00:36:17,260 --> 00:36:21,940
initialization part in the second video

759
00:36:19,450 --> 00:36:26,200
and we're going to show a long-lived TCP

760
00:36:21,940 --> 00:36:28,870
connection and how that long lead is the

761
00:36:26,200 --> 00:36:31,839
connection will reactor will survive say

762
00:36:28,870 --> 00:36:33,520
going to the router going down right so

763
00:36:31,840 --> 00:36:35,590
we've talked about how connections

764
00:36:33,520 --> 00:36:41,410
tracked by two routers primary in the

765
00:36:35,590 --> 00:36:43,120
secondary and how this connection will

766
00:36:41,410 --> 00:36:47,339
not be broken even if one of the routers

767
00:36:43,120 --> 00:36:52,270
go down this recovery script will start

768
00:36:47,340 --> 00:36:54,370
will create TCP connection and all this

769
00:36:52,270 --> 00:36:55,900
visit connection it will send HTTP

770
00:36:54,370 --> 00:36:59,200
request that will keep the connection

771
00:36:55,900 --> 00:37:02,140
open right so it's one TCP connection

772
00:36:59,200 --> 00:37:05,200
that is being and then HTTP traffic is

773
00:37:02,140 --> 00:37:08,799
flowing on top of that so because it is

774
00:37:05,200 --> 00:37:13,480
just one connection the hasher will take

775
00:37:08,800 --> 00:37:16,510
this flow and map to just one single og

776
00:37:13,480 --> 00:37:18,850
router right but we see a blip on Oh -

777
00:37:16,510 --> 00:37:21,250
our doublet - sorry and one of the left

778
00:37:18,850 --> 00:37:22,930
ones and in this scenario we have like

779
00:37:21,250 --> 00:37:26,350
to be provided to be back-end servers

780
00:37:22,930 --> 00:37:28,509
this flip is a packet exchange that took

781
00:37:26,350 --> 00:37:29,890
place to coordinate who is the

782
00:37:28,510 --> 00:37:32,860
I'm sorry who is the primary the

783
00:37:29,890 --> 00:37:35,650
secondary so we know that through this

784
00:37:32,860 --> 00:37:37,360
my dashboard that the primary is getting

785
00:37:35,650 --> 00:37:39,760
all the incoming traffic and there is a

786
00:37:37,360 --> 00:37:42,610
secondary that can serve as a backup so

787
00:37:39,760 --> 00:37:45,790
in this case let's try to bring down the

788
00:37:42,610 --> 00:37:52,780
primary router and see what will happen

789
00:37:45,790 --> 00:37:55,450
to our open TCP connection this so

790
00:37:52,780 --> 00:37:58,480
eventually what we will see is that the

791
00:37:55,450 --> 00:38:00,850
up to the clients side which is using a

792
00:37:58,480 --> 00:38:02,890
socket on like a Python client socket

793
00:38:00,850 --> 00:38:04,810
and select to check on incoming packets

794
00:38:02,890 --> 00:38:07,720
it will not break

795
00:38:04,810 --> 00:38:10,000
you know the throughput of the client it

796
00:38:07,720 --> 00:38:13,390
may drop a little bit as TCP gets maybe

797
00:38:10,000 --> 00:38:16,240
experiencing more delays because of the

798
00:38:13,390 --> 00:38:18,759
shift on the primary secondary but the

799
00:38:16,240 --> 00:38:21,160
connection will be held constant right

800
00:38:18,760 --> 00:38:23,230
so we can see here that it dropped a

801
00:38:21,160 --> 00:38:25,230
little bit of throughput but overall it

802
00:38:23,230 --> 00:38:32,410
recovers and the connection does not

803
00:38:25,230 --> 00:38:34,570
break down so so in this way we have

804
00:38:32,410 --> 00:38:37,899
verified our implementation you can

805
00:38:34,570 --> 00:38:39,880
contain the net and we are actually I

806
00:38:37,900 --> 00:38:45,070
mentioned we are trying to move towards

807
00:38:39,880 --> 00:38:48,820
a lab in our company so that we can test

808
00:38:45,070 --> 00:38:54,580
this in a real like real like a

809
00:38:48,820 --> 00:38:57,130
bare-metal system so so in conclusion in

810
00:38:54,580 --> 00:38:58,600
today's talk I presented a common

811
00:38:57,130 --> 00:39:00,970
architecture for highly available

812
00:38:58,600 --> 00:39:04,360
service that address these issues we

813
00:39:00,970 --> 00:39:08,350
have found in a DNS based system and we

814
00:39:04,360 --> 00:39:11,110
definitely wanted to bring any cast and

815
00:39:08,350 --> 00:39:14,410
I service six together that we and we

816
00:39:11,110 --> 00:39:15,880
believe that provides clients in our

817
00:39:14,410 --> 00:39:18,220
solution we provide clients where the

818
00:39:15,880 --> 00:39:20,290
closest available server and we leverage

819
00:39:18,220 --> 00:39:24,069
the network layer to provide proximity

820
00:39:20,290 --> 00:39:26,259
and the speed of fell over is as fast as

821
00:39:24,070 --> 00:39:29,680
detection of the down local server as we

822
00:39:26,260 --> 00:39:31,690
have seen once the detection of the

823
00:39:29,680 --> 00:39:34,330
local server happened we are immediately

824
00:39:31,690 --> 00:39:38,550
able to switch traffic to an available

825
00:39:34,330 --> 00:39:38,549
server to answer requests and

826
00:39:38,600 --> 00:39:43,310
traffic up forwarding is can be

827
00:39:41,150 --> 00:39:46,100
policy-based our settlement route

828
00:39:43,310 --> 00:39:48,620
approach allows us actually to reach all

829
00:39:46,100 --> 00:39:52,160
available clusters where the server is

830
00:39:48,620 --> 00:39:55,220
available so that like depending on how

831
00:39:52,160 --> 00:39:57,830
we decide this traffic should be the

832
00:39:55,220 --> 00:40:00,109
client request should be answer we can

833
00:39:57,830 --> 00:40:04,640
pick which data center to answer the

834
00:40:00,110 --> 00:40:08,140
request based on any policy we like that

835
00:40:04,640 --> 00:40:13,640
might be having like previously decided

836
00:40:08,140 --> 00:40:16,210
so thank you so I am like have some type

837
00:40:13,640 --> 00:40:16,210
of questions

838
00:40:26,130 --> 00:40:34,109
I all drain you mentioned server failure

839
00:40:31,079 --> 00:40:35,999
and og router failure but what if you

840
00:40:34,109 --> 00:40:39,269
have a long live connection is coming

841
00:40:35,999 --> 00:40:43,769
into your site one and needs to move

842
00:40:39,269 --> 00:40:47,220
over to site - oh you mean say if

843
00:40:43,769 --> 00:40:49,049
there's a local failure yeah your your

844
00:40:47,220 --> 00:40:52,379
advertisement - the internet from one

845
00:40:49,049 --> 00:40:55,319
site is goes down right you end up with

846
00:40:52,380 --> 00:40:56,989
another mmm oh gee hasha hasha right

847
00:40:55,319 --> 00:40:59,910
uh-huh

848
00:40:56,989 --> 00:41:03,779
but that ot hasher has no state about

849
00:40:59,910 --> 00:41:06,328
the flow right what happens then well I

850
00:41:03,779 --> 00:41:09,299
mean so you're saying if our og - oh

851
00:41:06,329 --> 00:41:10,890
let's go down and then what route is

852
00:41:09,299 --> 00:41:12,479
somehow he's withdrawing or yeah the

853
00:41:10,890 --> 00:41:14,339
route is began one so if the router

854
00:41:12,479 --> 00:41:17,098
withdrawn then yes there's no what

855
00:41:14,339 --> 00:41:21,299
nothing we can do we can actually be

856
00:41:17,099 --> 00:41:23,279
broken that's that's a problem that a

857
00:41:21,299 --> 00:41:25,859
lot of operators have you know that's

858
00:41:23,279 --> 00:41:28,769
right I mean yes if we are like our

859
00:41:25,859 --> 00:41:31,589
assumption is that say the load balancer

860
00:41:28,769 --> 00:41:33,899
service is up while the backend server

861
00:41:31,589 --> 00:41:38,339
goes down right so in that scenario yes

862
00:41:33,900 --> 00:41:41,160
we can definitely address outages but if

863
00:41:38,339 --> 00:41:43,319
our load balancer service goes down then

864
00:41:41,160 --> 00:41:45,690
yes on any ongoing stuff like this

865
00:41:43,319 --> 00:41:47,460
because that should be broken in case

866
00:41:45,690 --> 00:41:48,269
the anycast advertisement in internet

867
00:41:47,460 --> 00:41:51,479
doesn't help

868
00:41:48,269 --> 00:41:53,279
so the any cast of any new incoming

869
00:41:51,479 --> 00:41:56,098
requests would be directed to an

870
00:41:53,279 --> 00:41:58,380
available like cluster right but you

871
00:41:56,099 --> 00:42:01,109
still break the connection if you if you

872
00:41:58,380 --> 00:42:02,969
had to flip sites well it so forth yes

873
00:42:01,109 --> 00:42:05,400
any any ongoing connection will be

874
00:42:02,969 --> 00:42:07,469
broken but any new ones will go to the

875
00:42:05,400 --> 00:42:11,009
remote and that will be cared for as

876
00:42:07,469 --> 00:42:14,219
long as our og services up right even if

877
00:42:11,009 --> 00:42:19,900
the local like cluster recovers that one

878
00:42:14,219 --> 00:42:21,880
will still that's a good question right

879
00:42:19,900 --> 00:42:25,779
okay we're definitely look into the word

880
00:42:21,880 --> 00:42:27,700
to that I think you just might Minerva

881
00:42:25,779 --> 00:42:29,589
Verizon I'm just curious

882
00:42:27,700 --> 00:42:32,379
the motivation for all this is to

883
00:42:29,589 --> 00:42:35,740
preserve client-to-server or cluster

884
00:42:32,380 --> 00:42:38,079
stickiness to what to preserve the

885
00:42:35,740 --> 00:42:39,519
stickiness right yeah wean the client

886
00:42:38,079 --> 00:42:41,289
and a server right so that means you

887
00:42:39,519 --> 00:42:45,038
look at your traffic profile and found

888
00:42:41,289 --> 00:42:46,299
most of it needs to be that stickiness

889
00:42:45,039 --> 00:42:48,910
needs to be preserved and you have

890
00:42:46,299 --> 00:42:52,839
long-lived TCP sex sessions right is

891
00:42:48,910 --> 00:42:55,180
that it yes okay but yes we we use this

892
00:42:52,839 --> 00:42:57,759
to preserve TCP sessions but we want to

893
00:42:55,180 --> 00:43:01,538
use eventually to shape traffic right so

894
00:42:57,759 --> 00:43:02,980
say we want to eventually like depending

895
00:43:01,539 --> 00:43:04,690
on the capacity we want to allocate

896
00:43:02,980 --> 00:43:09,420
however much traffic that can be

897
00:43:04,690 --> 00:43:09,420
forwarded okay thank you

898
00:43:12,350 --> 00:43:22,839
all right if no more questions thank you

899
00:43:15,640 --> 00:43:22,839
[Applause]

900
00:43:27,520 --> 00:43:29,580
you

