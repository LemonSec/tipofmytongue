1
00:00:08,119 --> 00:00:14,399
hello good morning guys my name is

2
00:00:11,700 --> 00:00:16,200
Archana cassavan I am representing

3
00:00:14,400 --> 00:00:17,820
Thousand Eyes here some of you are

4
00:00:16,200 --> 00:00:20,490
probably familiar with the name

5
00:00:17,820 --> 00:00:21,960
maybe the t-shirt rings about but if not

6
00:00:20,490 --> 00:00:24,060
we're here for a couple of days and you

7
00:00:21,960 --> 00:00:27,179
can get to know us but more importantly

8
00:00:24,060 --> 00:00:28,740
the reason I'm here is to talk about a

9
00:00:27,179 --> 00:00:31,619
research and study that we conducted

10
00:00:28,740 --> 00:00:33,600
earlier last year that compares the

11
00:00:31,619 --> 00:00:37,970
network performance of the big three

12
00:00:33,600 --> 00:00:42,930
cloud providers AWS Google cloud and

13
00:00:37,970 --> 00:00:45,239
Microsoft Azure start with this so for

14
00:00:42,930 --> 00:00:47,670
the next 25 minutes or so what we're

15
00:00:45,240 --> 00:00:50,850
going to do is I'm going to give you an

16
00:00:47,670 --> 00:00:53,130
overview of why we did this study what

17
00:00:50,850 --> 00:00:56,430
was the reason behind the study the

18
00:00:53,130 --> 00:00:58,110
genesis of it and then get into the data

19
00:00:56,430 --> 00:01:00,840
methodology that we used to gather

20
00:00:58,110 --> 00:01:03,269
results and then actually talk about the

21
00:01:00,840 --> 00:01:05,880
insights or how did these three

22
00:01:03,270 --> 00:01:07,640
providers perform what was the network

23
00:01:05,880 --> 00:01:10,009
performance like were there any

24
00:01:07,640 --> 00:01:12,960
similarities were there any differences

25
00:01:10,010 --> 00:01:15,210
gotchas that you know came out and then

26
00:01:12,960 --> 00:01:16,710
we'll start with some summary

27
00:01:15,210 --> 00:01:18,979
recommendations and we'll have time for

28
00:01:16,710 --> 00:01:21,899
Q&A as well

29
00:01:18,980 --> 00:01:23,850
so when we started you know before we

30
00:01:21,900 --> 00:01:26,040
went on this study we're looking at how

31
00:01:23,850 --> 00:01:29,399
our cloud decisions made today at

32
00:01:26,040 --> 00:01:31,590
enterprises how are you picking AWS

33
00:01:29,400 --> 00:01:34,140
versus Google cloud versus Microsoft

34
00:01:31,590 --> 00:01:36,300
Azure and it turns out that obviously

35
00:01:34,140 --> 00:01:38,700
there are a few guiding principles that

36
00:01:36,300 --> 00:01:41,280
come into play right you're interested

37
00:01:38,700 --> 00:01:44,250
in understanding the global presence of

38
00:01:41,280 --> 00:01:46,740
these providers which is where are their

39
00:01:44,250 --> 00:01:48,810
regions located how many data centers do

40
00:01:46,740 --> 00:01:51,048
they have how many availability zones

41
00:01:48,810 --> 00:01:53,970
exist within these regions and so on

42
00:01:51,049 --> 00:01:56,280
pricing is definitely a big

43
00:01:53,970 --> 00:01:58,710
consideration and sometimes it has the

44
00:01:56,280 --> 00:02:00,930
power to sway decisions one way or the

45
00:01:58,710 --> 00:02:02,429
other depending on how many free credits

46
00:02:00,930 --> 00:02:05,280
you end up getting from each of these

47
00:02:02,430 --> 00:02:09,509
providers and then most importantly is

48
00:02:05,280 --> 00:02:11,849
the technical fit is ec2 or compute

49
00:02:09,508 --> 00:02:13,798
available in all form factors that match

50
00:02:11,849 --> 00:02:15,599
your requirements what's the load

51
00:02:13,799 --> 00:02:18,090
balancing architecture like what is a

52
00:02:15,599 --> 00:02:19,519
firewall look like and so on and that's

53
00:02:18,090 --> 00:02:21,290
a really important criteria

54
00:02:19,520 --> 00:02:24,440
when it comes to you know making your

55
00:02:21,290 --> 00:02:27,049
selection of these three providers but

56
00:02:24,440 --> 00:02:29,300
then performance is important as well

57
00:02:27,050 --> 00:02:31,790
who performs better do they perform

58
00:02:29,300 --> 00:02:34,760
better in certain situations what should

59
00:02:31,790 --> 00:02:38,750
you be aware of and it turns out that if

60
00:02:34,760 --> 00:02:40,609
you do a google search on AWS vs. google

61
00:02:38,750 --> 00:02:42,770
cloud versus as you're the first three

62
00:02:40,610 --> 00:02:44,750
quadrants that we just discussed you'll

63
00:02:42,770 --> 00:02:47,180
get a lot of information out there but

64
00:02:44,750 --> 00:02:49,250
performance was something that we saw

65
00:02:47,180 --> 00:02:51,980
was deficit with very little information

66
00:02:49,250 --> 00:02:55,490
in there and whatever information was

67
00:02:51,980 --> 00:02:57,619
available was not really comprehensive

68
00:02:55,490 --> 00:03:00,860
from the perspective of the depth of

69
00:02:57,620 --> 00:03:03,200
data that it had all also they were in

70
00:03:00,860 --> 00:03:05,810
snapshots in time there was not a lot of

71
00:03:03,200 --> 00:03:08,000
trend analysis out there there was very

72
00:03:05,810 --> 00:03:10,160
less information on network connectivity

73
00:03:08,000 --> 00:03:12,260
architectures how does the network look

74
00:03:10,160 --> 00:03:14,810
like within these three cloud providers

75
00:03:12,260 --> 00:03:17,390
for instance so when we notice this

76
00:03:14,810 --> 00:03:20,200
deficit of data we decided to go ahead

77
00:03:17,390 --> 00:03:24,279
and bridge that gap by doing this study

78
00:03:20,200 --> 00:03:28,250
and we leveraged our fleet of you know

79
00:03:24,280 --> 00:03:32,240
agents or monitoring probes to gather

80
00:03:28,250 --> 00:03:34,760
data so a little bit about how we can do

81
00:03:32,240 --> 00:03:38,240
this data how we went about doing the

82
00:03:34,760 --> 00:03:40,880
study is think of we have what we call

83
00:03:38,240 --> 00:03:44,330
as software probes or monitoring agents

84
00:03:40,880 --> 00:03:47,510
right and they are located in tier 2 and

85
00:03:44,330 --> 00:03:49,700
tier 3 ISPs around the globe and also

86
00:03:47,510 --> 00:03:52,940
within each of these cloud service

87
00:03:49,700 --> 00:03:56,329
providers so now these agents are

88
00:03:52,940 --> 00:03:58,850
emulating user traffic and let's call it

89
00:03:56,330 --> 00:04:00,770
by using what is called a test where

90
00:03:58,850 --> 00:04:04,130
they trigger a test that emulates user

91
00:04:00,770 --> 00:04:07,040
traffic now these tests inject network

92
00:04:04,130 --> 00:04:09,230
packets into the system and they can

93
00:04:07,040 --> 00:04:11,570
understand not just end-to-end network

94
00:04:09,230 --> 00:04:14,510
performance metrics like lost latency

95
00:04:11,570 --> 00:04:18,200
but what we do is also use a highly

96
00:04:14,510 --> 00:04:20,298
customized form of traceroute in there

97
00:04:18,200 --> 00:04:22,880
that can give you information on network

98
00:04:20,298 --> 00:04:25,520
paths as well something that we wanted

99
00:04:22,880 --> 00:04:28,640
to address in here while we were looking

100
00:04:25,520 --> 00:04:31,609
at would be the right you know mechanism

101
00:04:28,640 --> 00:04:31,950
to get gather this data was we wanted to

102
00:04:31,610 --> 00:04:35,370
stay

103
00:04:31,950 --> 00:04:37,440
away from ICMP because ICMP has

104
00:04:35,370 --> 00:04:39,990
shortfalls are that we're aware of for

105
00:04:37,440 --> 00:04:42,660
instance that can be rate limited you

106
00:04:39,990 --> 00:04:47,070
know within these hops in the network so

107
00:04:42,660 --> 00:04:48,990
we chose TCP traces to get this data the

108
00:04:47,070 --> 00:04:52,680
other thing that we wanted to be aware

109
00:04:48,990 --> 00:04:55,800
of and bear in mind was how to get past

110
00:04:52,680 --> 00:04:58,470
around the asymmetry in network routing

111
00:04:55,800 --> 00:05:00,930
and when that means is forward routes

112
00:04:58,470 --> 00:05:02,130
are different and reverse routes so we

113
00:05:00,930 --> 00:05:04,890
wanted to make sure while we're

114
00:05:02,130 --> 00:05:06,600
understanding performance and gathering

115
00:05:04,890 --> 00:05:09,180
these you know network performance data

116
00:05:06,600 --> 00:05:13,110
we look at both forward path and reverse

117
00:05:09,180 --> 00:05:16,110
path as well so every time a test is

118
00:05:13,110 --> 00:05:18,810
triggered data is collected and this

119
00:05:16,110 --> 00:05:21,930
happens periodically it happens every 10

120
00:05:18,810 --> 00:05:25,440
minutes and we collected this data for a

121
00:05:21,930 --> 00:05:27,990
four-week period we ran the data for in

122
00:05:25,440 --> 00:05:30,360
July of last year for a four-week period

123
00:05:27,990 --> 00:05:32,520
with these tests triggering every 10

124
00:05:30,360 --> 00:05:34,590
minutes right so every time a test is

125
00:05:32,520 --> 00:05:36,150
triggered there's some amount of data

126
00:05:34,590 --> 00:05:38,039
that's collected so what is this data

127
00:05:36,150 --> 00:05:41,159
look like what would we get out of here

128
00:05:38,040 --> 00:05:43,350
is n 2 n metrics so we can understand

129
00:05:41,160 --> 00:05:45,390
what the end-to-end source to

130
00:05:43,350 --> 00:05:47,460
destination and destination to source

131
00:05:45,390 --> 00:05:50,729
because we are using bi-directional

132
00:05:47,460 --> 00:05:52,500
traces here network loss latency and

133
00:05:50,730 --> 00:05:55,320
jitter look like we're also

134
00:05:52,500 --> 00:05:57,570
understanding when the network path

135
00:05:55,320 --> 00:06:00,570
looks like I mentioned we use a highly

136
00:05:57,570 --> 00:06:02,670
customized you know version of trace

137
00:06:00,570 --> 00:06:05,250
route that can give us information on

138
00:06:02,670 --> 00:06:07,800
the layer three hop-by-hop view of the

139
00:06:05,250 --> 00:06:11,100
network with details on you know where

140
00:06:07,800 --> 00:06:13,860
these hops are located which a SN or a s

141
00:06:11,100 --> 00:06:16,350
network they're apart of N and so on so

142
00:06:13,860 --> 00:06:18,480
what does allowed us to do was really

143
00:06:16,350 --> 00:06:20,550
understand performance from two aspects

144
00:06:18,480 --> 00:06:23,100
one is connectivity architectures to

145
00:06:20,550 --> 00:06:25,050
these cloud providers and also end-user

146
00:06:23,100 --> 00:06:29,010
performance metric to these cloud

147
00:06:25,050 --> 00:06:30,450
providers so the probes are these agents

148
00:06:29,010 --> 00:06:32,490
that I was referring to which was

149
00:06:30,450 --> 00:06:34,530
basically the source or the foundation

150
00:06:32,490 --> 00:06:37,710
of our data collection mechanism are

151
00:06:34,530 --> 00:06:39,780
they managed by us what that means is we

152
00:06:37,710 --> 00:06:42,599
have continuous access to these agents

153
00:06:39,780 --> 00:06:44,090
so that allows for any easy detection or

154
00:06:42,600 --> 00:06:46,160
if there were issues with

155
00:06:44,090 --> 00:06:48,349
say connectivity or local false we could

156
00:06:46,160 --> 00:06:50,600
eliminate it and replace it a new agent

157
00:06:48,350 --> 00:06:52,520
but fortunately in this four-week period

158
00:06:50,600 --> 00:06:55,550
we did not see anything like that which

159
00:06:52,520 --> 00:06:57,740
was a win it was a very clean test run

160
00:06:55,550 --> 00:07:00,740
for these four weeks four weeks that we

161
00:06:57,740 --> 00:07:03,139
run these tests also I'm just a point to

162
00:07:00,740 --> 00:07:05,750
note that there were no outages as in

163
00:07:03,139 --> 00:07:09,320
these timeframe as well and what I mean

164
00:07:05,750 --> 00:07:11,510
by outages is there's no net heavy

165
00:07:09,320 --> 00:07:14,510
network packet loss that was seen or an

166
00:07:11,510 --> 00:07:16,669
ISP outage in the network or within

167
00:07:14,510 --> 00:07:19,310
these cloud providers as well so really

168
00:07:16,669 --> 00:07:21,770
for for most parts it was a very clean

169
00:07:19,310 --> 00:07:23,690
run so the data that you're here is

170
00:07:21,770 --> 00:07:27,039
unbiased in terms of you know any

171
00:07:23,690 --> 00:07:30,560
external factors that was influencing it

172
00:07:27,040 --> 00:07:32,270
once the data is collected it's you know

173
00:07:30,560 --> 00:07:34,760
periodically exported to a cloud-based

174
00:07:32,270 --> 00:07:36,710
engine that can do trend analysis and

175
00:07:34,760 --> 00:07:38,690
reporting which is how we were able to

176
00:07:36,710 --> 00:07:42,500
crunch the data here to come up with

177
00:07:38,690 --> 00:07:44,120
like inside system what this meant now

178
00:07:42,500 --> 00:07:45,320
just something that I want to note here

179
00:07:44,120 --> 00:07:46,729
is it throughout the rest of the

180
00:07:45,320 --> 00:07:49,430
presentation I'm going to be heavily

181
00:07:46,729 --> 00:07:52,250
focusing on network latency because that

182
00:07:49,430 --> 00:07:54,889
was one metric which were we did see you

183
00:07:52,250 --> 00:07:57,440
know anomalous behaviors and trends loss

184
00:07:54,889 --> 00:07:59,599
and jitter were metrics that were

185
00:07:57,440 --> 00:08:01,160
collected as a part of the test but I'm

186
00:07:59,599 --> 00:08:02,719
not going to talk about it specifically

187
00:08:01,160 --> 00:08:04,729
here just because there was nothing

188
00:08:02,720 --> 00:08:07,700
interesting to report lots of latency

189
00:08:04,729 --> 00:08:09,710
was class was really minimal and jitter

190
00:08:07,700 --> 00:08:13,219
was as expected so there was nothing you

191
00:08:09,710 --> 00:08:17,060
know pending that really stood out to

192
00:08:13,220 --> 00:08:18,950
talk about it all right a little bit

193
00:08:17,060 --> 00:08:21,110
into test scope so that was the

194
00:08:18,950 --> 00:08:23,539
infrastructure that was used for testing

195
00:08:21,110 --> 00:08:26,750
but how what were the different vantage

196
00:08:23,539 --> 00:08:28,940
points we looked at this comparison from

197
00:08:26,750 --> 00:08:30,560
is we try to understand end-user

198
00:08:28,940 --> 00:08:33,500
measurements so we're trying to

199
00:08:30,560 --> 00:08:35,179
understand how the users connecting to

200
00:08:33,500 --> 00:08:36,860
these cloud providers what do they

201
00:08:35,179 --> 00:08:39,348
experience from the perspective of

202
00:08:36,860 --> 00:08:42,110
network performance and connectivity

203
00:08:39,349 --> 00:08:43,700
what does inter AC and intelligent

204
00:08:42,110 --> 00:08:46,640
machines within a single truck cloud

205
00:08:43,700 --> 00:08:48,589
provider look like as well because we

206
00:08:46,640 --> 00:08:51,830
know that redundancy load balancing

207
00:08:48,589 --> 00:08:54,200
microservices architecture is increasing

208
00:08:51,830 --> 00:08:55,350
the communication within availability

209
00:08:54,200 --> 00:08:58,590
zones across these

210
00:08:55,350 --> 00:09:00,540
and within regions within you know in

211
00:08:58,590 --> 00:09:02,730
each of these providers so we wanted to

212
00:09:00,540 --> 00:09:05,010
understand that metric as well and then

213
00:09:02,730 --> 00:09:07,880
finally we did multi-cloud measurements

214
00:09:05,010 --> 00:09:10,950
which is understanding connectivity and

215
00:09:07,880 --> 00:09:13,439
network metrics from AWS to assure

216
00:09:10,950 --> 00:09:15,150
assured and Google and all the

217
00:09:13,440 --> 00:09:18,210
permutation combinations that exists

218
00:09:15,150 --> 00:09:21,000
there so when it comes to end-user

219
00:09:18,210 --> 00:09:24,210
measurements we place these monitoring

220
00:09:21,000 --> 00:09:28,170
software probes in 27 global locations

221
00:09:24,210 --> 00:09:31,470
so 27 global locations connecting 255

222
00:09:28,170 --> 00:09:35,280
regions of each of these providers so 15

223
00:09:31,470 --> 00:09:38,430
AWS regions were used as in this study

224
00:09:35,280 --> 00:09:39,930
25 Azure and 15 Google Cloud regions

225
00:09:38,430 --> 00:09:42,900
were used here so they were

226
00:09:39,930 --> 00:09:46,680
bi-directional tests running across from

227
00:09:42,900 --> 00:09:49,350
27 global locations to 55 regions agents

228
00:09:46,680 --> 00:09:51,120
located within these cloud service

229
00:09:49,350 --> 00:09:52,800
providers as well which is how we were

230
00:09:51,120 --> 00:09:55,470
able to generate this data so that

231
00:09:52,800 --> 00:09:57,540
amounted to approximately thousand four

232
00:09:55,470 --> 00:09:59,490
hundred and eighty five tests these

233
00:09:57,540 --> 00:10:02,699
tests were again triggered every 10

234
00:09:59,490 --> 00:10:04,890
minutes for a period of four weeks we

235
00:10:02,700 --> 00:10:06,750
looked at inter AC measurements same way

236
00:10:04,890 --> 00:10:08,790
through these agents that are pre

237
00:10:06,750 --> 00:10:11,100
deployed within availability zones

238
00:10:08,790 --> 00:10:13,380
within a single provider now the

239
00:10:11,100 --> 00:10:15,750
interesting thing about availability

240
00:10:13,380 --> 00:10:18,090
zones and how they are a map is that

241
00:10:15,750 --> 00:10:19,650
they're really independent per account

242
00:10:18,090 --> 00:10:22,620
so we wanted to take that into

243
00:10:19,650 --> 00:10:26,340
consideration what that means is if I

244
00:10:22,620 --> 00:10:28,770
log into AWS with my account login what

245
00:10:26,340 --> 00:10:31,500
gets assigned to me as availability zone

246
00:10:28,770 --> 00:10:33,300
could be different for somebody else

247
00:10:31,500 --> 00:10:35,310
so we wanted to you know take care of

248
00:10:33,300 --> 00:10:37,319
that exception any anomalies that might

249
00:10:35,310 --> 00:10:38,969
create so we had multiple samples

250
00:10:37,320 --> 00:10:43,170
running across multiple availability

251
00:10:38,970 --> 00:10:45,990
zones within a region and as a for this

252
00:10:43,170 --> 00:10:48,990
study we tested this across for AWS

253
00:10:45,990 --> 00:10:51,600
regions for Google Cloud regions but we

254
00:10:48,990 --> 00:10:54,330
tested only two one major region and and

255
00:10:51,600 --> 00:10:56,640
that's because of azure is still warming

256
00:10:54,330 --> 00:10:58,890
up to the idea of availability zones so

257
00:10:56,640 --> 00:11:03,030
we just started with one region future

258
00:10:58,890 --> 00:11:06,090
we'll be expanding that and then inter

259
00:11:03,030 --> 00:11:07,689
region was across regions within a

260
00:11:06,090 --> 00:11:11,080
single provider so

261
00:11:07,690 --> 00:11:13,780
fifteen regions in AWS 25 in Azure and

262
00:11:11,080 --> 00:11:16,240
then 15 in Google Cloud and these were

263
00:11:13,780 --> 00:11:19,540
all bi-directional tests again running

264
00:11:16,240 --> 00:11:21,480
periodically and the final piece of

265
00:11:19,540 --> 00:11:24,069
measurement that we looked at was

266
00:11:21,480 --> 00:11:27,160
looking at multi cloud which is

267
00:11:24,070 --> 00:11:29,350
connecting each of these regions from a

268
00:11:27,160 --> 00:11:31,600
single provider to another provider so

269
00:11:29,350 --> 00:11:33,360
you can imagine the amount of crisscross

270
00:11:31,600 --> 00:11:37,180
communication and tests that were

271
00:11:33,360 --> 00:11:41,200
executed as a part of this so what did

272
00:11:37,180 --> 00:11:43,420
this really result in right 30 days 10

273
00:11:41,200 --> 00:11:45,990
minute interval a test triggered every

274
00:11:43,420 --> 00:11:48,189
10 minutes across those four different

275
00:11:45,990 --> 00:11:50,830
you know verticals that we just

276
00:11:48,190 --> 00:11:53,110
discussed end user interests inter

277
00:11:50,830 --> 00:11:55,840
region and multi cloud that gave us

278
00:11:53,110 --> 00:11:58,810
about 20 million unique measurements

279
00:11:55,840 --> 00:12:01,120
after a month but we were looking at it

280
00:11:58,810 --> 00:12:03,310
by directionally which means we had 40

281
00:12:01,120 --> 00:12:05,980
million unique measurements and each

282
00:12:03,310 --> 00:12:08,410
measurement that we get takes into

283
00:12:05,980 --> 00:12:11,590
consideration network loss latency

284
00:12:08,410 --> 00:12:15,430
jitter and network path data so that's

285
00:12:11,590 --> 00:12:17,260
four attributes for data point that will

286
00:12:15,430 --> 00:12:19,989
make measurement that was collected so

287
00:12:17,260 --> 00:12:22,240
about 160 million unique data points

288
00:12:19,990 --> 00:12:25,720
that we had gathered over a period of a

289
00:12:22,240 --> 00:12:27,310
month to come up with these insights and

290
00:12:25,720 --> 00:12:31,480
and to look at how these three providers

291
00:12:27,310 --> 00:12:34,150
were performing so now to the fun part

292
00:12:31,480 --> 00:12:35,380
of this who was a good ballad a gay of

293
00:12:34,150 --> 00:12:38,319
network performance where their

294
00:12:35,380 --> 00:12:40,750
similarities who performed well who won

295
00:12:38,320 --> 00:12:43,510
the cloud war will start with the good

296
00:12:40,750 --> 00:12:46,390
really here is interesting performance

297
00:12:43,510 --> 00:12:49,210
so there has been a lot of claims we've

298
00:12:46,390 --> 00:12:51,720
heard made by each of these three

299
00:12:49,210 --> 00:12:53,800
providers that inter AC performance is

300
00:12:51,720 --> 00:12:55,750
always going to be below two

301
00:12:53,800 --> 00:12:57,910
milliseconds we've heard that in a lot

302
00:12:55,750 --> 00:13:00,010
of talks that have occurred in the past

303
00:12:57,910 --> 00:13:02,410
those were claims that were made and

304
00:13:00,010 --> 00:13:03,819
what our study showed that with all

305
00:13:02,410 --> 00:13:05,589
these three providers performed

306
00:13:03,820 --> 00:13:09,610
exceptionally well when it came to

307
00:13:05,590 --> 00:13:12,670
network latency within between

308
00:13:09,610 --> 00:13:14,590
availability zones so AWS and this

309
00:13:12,670 --> 00:13:16,719
instance averaged at point eight two

310
00:13:14,590 --> 00:13:18,910
millisecond and you can see the you know

311
00:13:16,720 --> 00:13:21,100
split across each of those regions that

312
00:13:18,910 --> 00:13:23,230
we picked as your

313
00:13:21,100 --> 00:13:25,720
the same 1 millisecond range and then

314
00:13:23,230 --> 00:13:29,560
Google Cloud with 0.79 as well so

315
00:13:25,720 --> 00:13:31,540
overall interesting measurements or you

316
00:13:29,560 --> 00:13:33,670
know performance network latency was

317
00:13:31,540 --> 00:13:36,730
really good its signal that these

318
00:13:33,670 --> 00:13:38,949
providers have robust well connected

319
00:13:36,730 --> 00:13:41,320
internal architectures it also gives you

320
00:13:38,950 --> 00:13:43,600
an idea of how far apart a data center

321
00:13:41,320 --> 00:13:46,690
might be located within a region given

322
00:13:43,600 --> 00:13:48,820
the latency numbers next year will be

323
00:13:46,690 --> 00:13:52,530
increasing the number of regions that we

324
00:13:48,820 --> 00:13:54,550
are going to be testing along with

325
00:13:52,530 --> 00:13:57,150
increasing the number of regions in

326
00:13:54,550 --> 00:13:59,979
Azure as well

327
00:13:57,150 --> 00:14:03,459
the next is inter region performance

328
00:13:59,980 --> 00:14:06,310
inter region performance is measuring

329
00:14:03,460 --> 00:14:08,380
Network latency large and jitter within

330
00:14:06,310 --> 00:14:11,140
a single provider but across multiple

331
00:14:08,380 --> 00:14:14,320
regions for instance testing between AWS

332
00:14:11,140 --> 00:14:15,910
East and AWS London for example Wahby

333
00:14:14,320 --> 00:14:17,680
node is the first thing that stood out

334
00:14:15,910 --> 00:14:19,689
and this is you know based on the

335
00:14:17,680 --> 00:14:22,060
network path information that these

336
00:14:19,690 --> 00:14:25,000
agents are continuously collecting we

337
00:14:22,060 --> 00:14:27,040
notice the traffic stays within the same

338
00:14:25,000 --> 00:14:29,080
provider when you're talking about inter

339
00:14:27,040 --> 00:14:31,630
agent communication so think of these

340
00:14:29,080 --> 00:14:34,120
agents are they deployed within these

341
00:14:31,630 --> 00:14:36,880
providers is compute so if that means

342
00:14:34,120 --> 00:14:39,130
AWS its ec2 instances that we are

343
00:14:36,880 --> 00:14:40,870
triggering tests across it's a

344
00:14:39,130 --> 00:14:45,880
communication between two easy two

345
00:14:40,870 --> 00:14:48,040
instances go between go within an AWS

346
00:14:45,880 --> 00:14:51,010
network right that's the first thing

347
00:14:48,040 --> 00:14:53,530
that stood out and we were able to get a

348
00:14:51,010 --> 00:14:56,020
lot of absolute measurements in terms of

349
00:14:53,530 --> 00:14:58,990
what the latency looked like but we were

350
00:14:56,020 --> 00:15:01,030
not able to you know understand if this

351
00:14:58,990 --> 00:15:04,330
was good or if this is you know

352
00:15:01,030 --> 00:15:06,699
suboptimal performance so what we did to

353
00:15:04,330 --> 00:15:09,910
get a better idea of that is to we

354
00:15:06,700 --> 00:15:11,440
baselined it with internet averages so

355
00:15:09,910 --> 00:15:14,170
we understood performance from a

356
00:15:11,440 --> 00:15:16,180
relative you know score so what that

357
00:15:14,170 --> 00:15:19,510
really means is I'll give you an example

358
00:15:16,180 --> 00:15:21,670
to explain this is if you're looking at

359
00:15:19,510 --> 00:15:24,490
interesting measurements for AWS for

360
00:15:21,670 --> 00:15:26,199
instance between Ashburn and London we

361
00:15:24,490 --> 00:15:28,210
get an absolute measurement value for

362
00:15:26,200 --> 00:15:30,310
latency which is great but we also

363
00:15:28,210 --> 00:15:32,890
wanted to see is that how does that

364
00:15:30,310 --> 00:15:34,510
compare with respect to internet-based

365
00:15:32,890 --> 00:15:37,510
lines going from

366
00:15:34,510 --> 00:15:40,810
two points in Ashburn and in London

367
00:15:37,510 --> 00:15:43,149
outside a WSS Network right that's how

368
00:15:40,810 --> 00:15:44,560
we baseline it and we got this relative

369
00:15:43,149 --> 00:15:48,190
measurement so we did those bad

370
00:15:44,560 --> 00:15:50,079
performance across those 15 25 and 15

371
00:15:48,190 --> 00:15:53,199
regions across all of these providers

372
00:15:50,079 --> 00:15:55,750
now the assumption is that these

373
00:15:53,199 --> 00:15:57,519
providers have really robust backbones

374
00:15:55,750 --> 00:15:59,170
you know it's not the best effort

375
00:15:57,519 --> 00:16:01,029
Network so it's a private connective

376
00:15:59,170 --> 00:16:03,490
network so that should perform better

377
00:16:01,029 --> 00:16:06,699
than internet averages and that's how we

378
00:16:03,490 --> 00:16:08,889
did this grouping here so the first two

379
00:16:06,699 --> 00:16:11,769
as you can see the first two vertical

380
00:16:08,889 --> 00:16:13,930
very leaning heavily there in that angle

381
00:16:11,769 --> 00:16:16,660
and what that distribution really means

382
00:16:13,930 --> 00:16:18,939
is the number of intelligent pairs that

383
00:16:16,660 --> 00:16:21,160
performed better than the Internet or

384
00:16:18,940 --> 00:16:23,709
same as baseline to the Internet is

385
00:16:21,160 --> 00:16:27,149
greater which is good and what we should

386
00:16:23,709 --> 00:16:29,768
be expecting compared to certain regions

387
00:16:27,149 --> 00:16:32,350
performed really poorly there were some

388
00:16:29,769 --> 00:16:33,639
regions that was 30% slower than the

389
00:16:32,350 --> 00:16:36,970
Internet all the way to the extreme

390
00:16:33,639 --> 00:16:39,160
right for instance right so again from

391
00:16:36,970 --> 00:16:40,630
overall most parts into region

392
00:16:39,160 --> 00:16:44,230
measurements were good but they were

393
00:16:40,630 --> 00:16:46,930
exceptions that existed and one of the

394
00:16:44,230 --> 00:16:49,839
example is here in terms of exceptions

395
00:16:46,930 --> 00:16:51,638
that exist so the data that you're

396
00:16:49,839 --> 00:16:54,040
looking at here what the chart is

397
00:16:51,639 --> 00:16:58,149
representing is bi-directional Layton

398
00:16:54,040 --> 00:17:01,599
sees going in from Sydney Australia all

399
00:16:58,149 --> 00:17:03,699
the three providers regions to Tokyo

400
00:17:01,600 --> 00:17:05,620
Singapore and Mumbai regions for all

401
00:17:03,699 --> 00:17:09,040
these these three providers and that's

402
00:17:05,619 --> 00:17:12,069
the comparative metric and the green the

403
00:17:09,040 --> 00:17:13,809
color coding that you see is average and

404
00:17:12,069 --> 00:17:16,240
relative to internet baseline so when

405
00:17:13,809 --> 00:17:19,449
you see green it means that connection

406
00:17:16,240 --> 00:17:24,790
between Sydney Australia and let's take

407
00:17:19,449 --> 00:17:26,919
AWS and 109 millisecond latency so AWS

408
00:17:24,790 --> 00:17:29,918
latency between Sydney Australia and

409
00:17:26,919 --> 00:17:33,490
Tokyo is Green and 109 which means it's

410
00:17:29,919 --> 00:17:38,230
10% better than internet averages but if

411
00:17:33,490 --> 00:17:40,960
you look at GC p and Mumbai which is 228

412
00:17:38,230 --> 00:17:43,090
92 milliseconds that's 30% slower than

413
00:17:40,960 --> 00:17:44,490
what you would expect on going across

414
00:17:43,090 --> 00:17:47,220
those two location

415
00:17:44,490 --> 00:17:49,920
on the internet right so there are

416
00:17:47,220 --> 00:17:51,600
exceptions that did exist and it comes

417
00:17:49,920 --> 00:17:53,760
into play when you're making these

418
00:17:51,600 --> 00:17:56,010
choices on your architecture in terms of

419
00:17:53,760 --> 00:17:58,350
how to choose these region pairs so this

420
00:17:56,010 --> 00:18:00,900
can be a guiding factor in terms of what

421
00:17:58,350 --> 00:18:04,129
constitutes good performance versus poor

422
00:18:00,900 --> 00:18:07,290
performance in an inter region setup

423
00:18:04,130 --> 00:18:09,630
well then jump over to what an end-user

424
00:18:07,290 --> 00:18:11,730
performance look like and just to recap

425
00:18:09,630 --> 00:18:15,750
the end-user performance measurements

426
00:18:11,730 --> 00:18:18,390
were done from 27 locations globally to

427
00:18:15,750 --> 00:18:21,630
55 regions of across these three

428
00:18:18,390 --> 00:18:23,700
providers again now the way to the key

429
00:18:21,630 --> 00:18:25,950
to reading this graph here you're going

430
00:18:23,700 --> 00:18:28,440
to see few more occurrences of this

431
00:18:25,950 --> 00:18:30,960
graph so let me spend a few minutes here

432
00:18:28,440 --> 00:18:33,570
explaining it what you see on the x-axis

433
00:18:30,960 --> 00:18:35,850
is the user location so these are

434
00:18:33,570 --> 00:18:39,149
continents from where the user is

435
00:18:35,850 --> 00:18:41,639
connecting to do this cloud service

436
00:18:39,150 --> 00:18:44,790
provider which is denoted by the hosting

437
00:18:41,640 --> 00:18:46,800
region so the graph on the Left that

438
00:18:44,790 --> 00:18:50,428
you're seeing here is users connecting

439
00:18:46,800 --> 00:18:53,970
from Asia Europe North America Australia

440
00:18:50,429 --> 00:18:57,750
and then South America to u.s. East

441
00:18:53,970 --> 00:19:00,120
Virginia or to Microsoft's East data

442
00:18:57,750 --> 00:19:02,610
center located in Redmond and and the

443
00:19:00,120 --> 00:19:05,550
cloud same thing as GCP counterpart as

444
00:19:02,610 --> 00:19:08,280
well and then the one other graph is

445
00:19:05,550 --> 00:19:10,559
very similarly it's connecting to United

446
00:19:08,280 --> 00:19:12,629
Kingdom which is London and Cardiff or

447
00:19:10,559 --> 00:19:14,639
as where these providers have their data

448
00:19:12,630 --> 00:19:17,370
centers located and then the three

449
00:19:14,640 --> 00:19:19,860
colors represent AWS Asia and Google

450
00:19:17,370 --> 00:19:22,409
Club so what you notice here very

451
00:19:19,860 --> 00:19:24,928
quickly is that if you're hosting

452
00:19:22,410 --> 00:19:27,480
centers are in North America and in

453
00:19:24,929 --> 00:19:29,340
Europe then your latency for users

454
00:19:27,480 --> 00:19:31,200
connecting to these hosting centers are

455
00:19:29,340 --> 00:19:34,559
really comparable across these three

456
00:19:31,200 --> 00:19:37,260
providers there's not really a question

457
00:19:34,559 --> 00:19:39,420
of who does better here they are their

458
00:19:37,260 --> 00:19:41,850
comparatively all doing really good

459
00:19:39,420 --> 00:19:43,550
no outages like I mentioned in this four

460
00:19:41,850 --> 00:19:46,590
week period so this was really positive

461
00:19:43,550 --> 00:19:48,899
information in terms of performance but

462
00:19:46,590 --> 00:19:52,199
this only holds true if you are

463
00:19:48,900 --> 00:19:54,450
connecting to North America and Western

464
00:19:52,200 --> 00:19:57,480
Europe for instance as your data centers

465
00:19:54,450 --> 00:20:01,200
when you move to Asia we start see

466
00:19:57,480 --> 00:20:03,809
a different story right again the way

467
00:20:01,200 --> 00:20:07,549
you read this chart here is the graph

468
00:20:03,809 --> 00:20:11,010
here is user locations connecting to

469
00:20:07,549 --> 00:20:12,990
hosting region in Bombay India all these

470
00:20:11,010 --> 00:20:15,570
three cloud providers have hosting

471
00:20:12,990 --> 00:20:17,820
regions in Bombay so it was easy to

472
00:20:15,570 --> 00:20:21,210
compare them right and the first thing

473
00:20:17,820 --> 00:20:24,059
that stands out here is that Google has

474
00:20:21,210 --> 00:20:27,720
three terms a network latency when users

475
00:20:24,059 --> 00:20:30,389
are coming in from Europe to India so if

476
00:20:27,720 --> 00:20:32,790
you see the other user locations it's

477
00:20:30,390 --> 00:20:34,799
it's it's pretty comparable but the only

478
00:20:32,790 --> 00:20:37,530
thing that stands out here is that red

479
00:20:34,799 --> 00:20:39,510
line which is Google's Network latency

480
00:20:37,530 --> 00:20:44,160
bi-directional latency which is three

481
00:20:39,510 --> 00:20:46,169
times that of AWS and sure the reason

482
00:20:44,160 --> 00:20:49,080
for that it turns out is that Google

483
00:20:46,169 --> 00:20:51,830
uses a very suboptimal route to move

484
00:20:49,080 --> 00:20:55,199
traffic from Europe all the way to India

485
00:20:51,830 --> 00:20:57,540
Google GCP they heav'nly rely on their

486
00:20:55,200 --> 00:20:59,880
backbone to move traffic around and it

487
00:20:57,540 --> 00:21:02,730
sounds like and it naturally sounds like

488
00:20:59,880 --> 00:21:05,070
what if data showed is that traffic

489
00:21:02,730 --> 00:21:07,710
moves all the way from Europe to the

490
00:21:05,070 --> 00:21:10,860
United States to get to India so let me

491
00:21:07,710 --> 00:21:12,840
explain this visualization that you see

492
00:21:10,860 --> 00:21:15,178
here is the green dots that you're

493
00:21:12,840 --> 00:21:17,399
seeing there are representative of our

494
00:21:15,179 --> 00:21:19,740
agents located in Europe in those

495
00:21:17,400 --> 00:21:22,440
particular locations and all the way on

496
00:21:19,740 --> 00:21:25,650
the extreme right which is Mumbai India

497
00:21:22,440 --> 00:21:28,679
that's the region you're connecting to

498
00:21:25,650 --> 00:21:30,990
so these agents are emulating user

499
00:21:28,679 --> 00:21:36,090
traffic going all the way up to Mumbai

500
00:21:30,990 --> 00:21:38,340
India and back now the the the marked

501
00:21:36,090 --> 00:21:40,110
region there towards the very end is a

502
00:21:38,340 --> 00:21:42,600
representation of Google's backbone

503
00:21:40,110 --> 00:21:44,790
those nodes there that you see show the

504
00:21:42,600 --> 00:21:47,070
data is traversing the Google Blog phone

505
00:21:44,790 --> 00:21:49,320
but it also shows the location of where

506
00:21:47,070 --> 00:21:51,510
those nodes are located so all the way

507
00:21:49,320 --> 00:21:54,240
from Europe they go to the United States

508
00:21:51,510 --> 00:21:57,750
come they hit California and then they

509
00:21:54,240 --> 00:22:00,480
go over to Bombay now that explains why

510
00:21:57,750 --> 00:22:05,640
the latency was three times compared to

511
00:22:00,480 --> 00:22:07,830
AWS and Microsoft Azure so what we

512
00:22:05,640 --> 00:22:08,800
wanted to do is we wanted to verify and

513
00:22:07,830 --> 00:22:10,960
validate that this is

514
00:22:08,800 --> 00:22:13,149
indeed you know right this is how

515
00:22:10,960 --> 00:22:14,590
Google's backbone works so what we did

516
00:22:13,150 --> 00:22:17,500
was we look a look at the fiber

517
00:22:14,590 --> 00:22:20,199
connectivity of Google cloud right and

518
00:22:17,500 --> 00:22:22,030
it turns out the reason Google takes a

519
00:22:20,200 --> 00:22:24,520
circuit shows part is because there is

520
00:22:22,030 --> 00:22:26,920
no direct route in the Google backbone

521
00:22:24,520 --> 00:22:29,200
from Europe to India so the only way

522
00:22:26,920 --> 00:22:33,700
they can go around is to actually go

523
00:22:29,200 --> 00:22:35,380
around right so this was this was really

524
00:22:33,700 --> 00:22:38,040
interesting this stood out for us from

525
00:22:35,380 --> 00:22:40,300
means if you know the data that we got

526
00:22:38,040 --> 00:22:43,330
but something else that caught our eye

527
00:22:40,300 --> 00:22:46,300
as well from an exception is how AWS was

528
00:22:43,330 --> 00:22:48,340
performing now let's shift focus and

529
00:22:46,300 --> 00:22:51,580
this is the exact same graph that we saw

530
00:22:48,340 --> 00:22:53,860
earlier which showed performance network

531
00:22:51,580 --> 00:22:57,220
latency bi-directional network latency

532
00:22:53,860 --> 00:22:59,649
from these global locations to a hosting

533
00:22:57,220 --> 00:23:01,540
Center in Mumbai but let's focus on

534
00:22:59,650 --> 00:23:04,360
those black lines that you see they're

535
00:23:01,540 --> 00:23:06,879
not the actual vertical bars itself and

536
00:23:04,360 --> 00:23:10,209
what that represents is basically

537
00:23:06,880 --> 00:23:12,850
standard deviation right it shows how

538
00:23:10,210 --> 00:23:16,330
much latency can vary in a given period

539
00:23:12,850 --> 00:23:19,419
of time and as you notice AWS seems to

540
00:23:16,330 --> 00:23:21,909
have the largest variation in network

541
00:23:19,420 --> 00:23:24,910
latency for users coming in from Asia

542
00:23:21,910 --> 00:23:27,700
but connecting to Bombay now this seemed

543
00:23:24,910 --> 00:23:29,560
anomalous as well so digging into the

544
00:23:27,700 --> 00:23:31,840
data a little bit more we noticed that

545
00:23:29,560 --> 00:23:35,070
this is a trend that we've seen across

546
00:23:31,840 --> 00:23:37,889
all AWS deployments especially in Asia

547
00:23:35,070 --> 00:23:41,620
so what you see here is bi-directional

548
00:23:37,890 --> 00:23:44,980
latency variations for AWS for users

549
00:23:41,620 --> 00:23:48,129
connecting from Asia to hosting centers

550
00:23:44,980 --> 00:23:50,770
in Tokyo Singapore and and Bombay and as

551
00:23:48,130 --> 00:23:53,380
you notice the yellow line here is AWS

552
00:23:50,770 --> 00:23:55,450
is variation in network latency and it's

553
00:23:53,380 --> 00:23:57,700
so bad in one way that it your network

554
00:23:55,450 --> 00:24:01,630
latency can vary anywhere between 0 to

555
00:23:57,700 --> 00:24:04,060
150 milliseconds that's pretty high the

556
00:24:01,630 --> 00:24:05,830
reason AWS behaves this way again this

557
00:24:04,060 --> 00:24:08,050
was if we were able to dig into the

558
00:24:05,830 --> 00:24:11,800
network path data that was collected is

559
00:24:08,050 --> 00:24:14,200
because AWS relies heavily on the

560
00:24:11,800 --> 00:24:16,270
Internet to move traffic so AWS

561
00:24:14,200 --> 00:24:18,580
basically hot potatoes traffic from the

562
00:24:16,270 --> 00:24:22,180
user location to their region where does

563
00:24:18,580 --> 00:24:22,870
that mean a user coming in from Mumbai

564
00:24:22,180 --> 00:24:26,230
for an

565
00:24:22,870 --> 00:24:29,159
Stan's going up to AWS east in Ashburn

566
00:24:26,230 --> 00:24:34,300
is going to go over multiple IP hops

567
00:24:29,160 --> 00:24:37,300
right and enter AWS is network pretty

568
00:24:34,300 --> 00:24:38,950
far away from blue close to the region

569
00:24:37,300 --> 00:24:40,780
where its host it's pretty far away from

570
00:24:38,950 --> 00:24:43,870
the user location so in this particular

571
00:24:40,780 --> 00:24:46,270
example users in frack Frankfort traffic

572
00:24:43,870 --> 00:24:48,580
from Frankfort only enters AWS is back

573
00:24:46,270 --> 00:24:50,410
one in Hong Kong for instance but that's

574
00:24:48,580 --> 00:24:53,199
not the case when it comes to Google

575
00:24:50,410 --> 00:24:55,690
cloud and Microsoft Azure if you notice

576
00:24:53,200 --> 00:24:58,630
your traffic from the same user location

577
00:24:55,690 --> 00:25:00,550
in Frankfort they enter the back one of

578
00:24:58,630 --> 00:25:03,580
these two other providers in Frankfort

579
00:25:00,550 --> 00:25:06,129
itself which means they ride the

580
00:25:03,580 --> 00:25:09,220
backbone of these providers longer than

581
00:25:06,130 --> 00:25:11,290
how a user who relies on AWS might and

582
00:25:09,220 --> 00:25:15,130
we know that the Internet is less

583
00:25:11,290 --> 00:25:17,110
predictable has has is you know is more

584
00:25:15,130 --> 00:25:19,510
vulnerable to like it's a best-effort

585
00:25:17,110 --> 00:25:21,159
network so you can see variations and

586
00:25:19,510 --> 00:25:22,840
performance that exists when you're

587
00:25:21,160 --> 00:25:25,929
starting to rely heavily on the internet

588
00:25:22,840 --> 00:25:28,240
for example which is which explains AWS

589
00:25:25,929 --> 00:25:31,210
is you know variation and performance

590
00:25:28,240 --> 00:25:33,700
especially in Asia now again this is a

591
00:25:31,210 --> 00:25:37,620
snapshot which shows how traffic moves

592
00:25:33,700 --> 00:25:40,780
from global users to AWS this network in

593
00:25:37,620 --> 00:25:43,719
AWS region in u.s. East which is Ashford

594
00:25:40,780 --> 00:25:45,970
so notice how like users from Singapore

595
00:25:43,720 --> 00:25:47,770
they have to go through multiple high

596
00:25:45,970 --> 00:25:50,980
speeds going all the way from Singapore

597
00:25:47,770 --> 00:25:52,990
to LA to Texas and they enter Amazon in

598
00:25:50,980 --> 00:25:55,059
either Texas or they're entering

599
00:25:52,990 --> 00:25:57,460
Amazon's network and Ashburn or New York

600
00:25:55,059 --> 00:26:00,250
so it's really close to where the

601
00:25:57,460 --> 00:26:01,780
hosting or the data center is this is

602
00:26:00,250 --> 00:26:04,870
completely different than what is your

603
00:26:01,780 --> 00:26:07,600
and GCP do same user coming in from

604
00:26:04,870 --> 00:26:11,530
Singapore is going to enter Microsoft's

605
00:26:07,600 --> 00:26:13,178
backbone in Singapore to go to Richmond

606
00:26:11,530 --> 00:26:15,100
Virginia which is Microsoft's hosting

607
00:26:13,179 --> 00:26:17,559
data center right so there's definitely

608
00:26:15,100 --> 00:26:19,449
a difference in terms of how you connect

609
00:26:17,559 --> 00:26:21,690
to the cloud so there's a variation in

610
00:26:19,450 --> 00:26:25,000
cloud connectivity architectures as such

611
00:26:21,690 --> 00:26:27,429
so this research that we did it was

612
00:26:25,000 --> 00:26:30,820
conducted like I mentioned last year in

613
00:26:27,429 --> 00:26:34,020
July and the research is now available

614
00:26:30,820 --> 00:26:36,720
online for everybody we list it in

615
00:26:34,020 --> 00:26:39,780
early November right and as we know

616
00:26:36,720 --> 00:26:42,300
reinvent is end of November it happened

617
00:26:39,780 --> 00:26:45,450
end of 2018 and AW was very

618
00:26:42,300 --> 00:26:47,190
interestingly introduced a new service

619
00:26:45,450 --> 00:26:50,550
in there called the global accelerator

620
00:26:47,190 --> 00:26:53,070
the global accelerator they say is for

621
00:26:50,550 --> 00:26:55,440
improved performance and in what it

622
00:26:53,070 --> 00:26:57,419
translates to in simple terms is you pay

623
00:26:55,440 --> 00:27:00,960
w as more money to write their network

624
00:26:57,420 --> 00:27:04,980
to get better performance right that's

625
00:27:00,960 --> 00:27:07,740
what it means and that's a that's a

626
00:27:04,980 --> 00:27:09,540
ploughed trend that we are starting to

627
00:27:07,740 --> 00:27:11,460
see it's it's what I call the

628
00:27:09,540 --> 00:27:15,000
monetization of the cloud backbone and

629
00:27:11,460 --> 00:27:16,920
this is not just specific to AWS Google

630
00:27:15,000 --> 00:27:19,500
made such an announcement as well last

631
00:27:16,920 --> 00:27:21,840
year so Google now gives you two tiers

632
00:27:19,500 --> 00:27:24,000
of service a standard trio and a premium

633
00:27:21,840 --> 00:27:25,919
tier if you pick the standard tier

634
00:27:24,000 --> 00:27:27,780
you're going to hot potater around use

635
00:27:25,920 --> 00:27:29,550
the Internet you're not gonna write

636
00:27:27,780 --> 00:27:30,870
Google's network but if you pick the

637
00:27:29,550 --> 00:27:32,510
premium tier you're going to go on

638
00:27:30,870 --> 00:27:34,770
Google's network faster which means

639
00:27:32,510 --> 00:27:36,870
couldn't code better performance right

640
00:27:34,770 --> 00:27:40,410
so in lwith made this recent

641
00:27:36,870 --> 00:27:41,820
announcement last year we don't know how

642
00:27:40,410 --> 00:27:44,010
much of an improvement in performance

643
00:27:41,820 --> 00:27:46,320
this is going to give and that's going

644
00:27:44,010 --> 00:27:47,940
to be on a use case by use case basis

645
00:27:46,320 --> 00:27:50,730
but this would be really interesting to

646
00:27:47,940 --> 00:27:52,590
compare Internet performance versus

647
00:27:50,730 --> 00:27:56,310
performance through AWS is global

648
00:27:52,590 --> 00:27:58,129
accelerator all right finally we coming

649
00:27:56,310 --> 00:28:01,320
to multi-cloud performance so

650
00:27:58,130 --> 00:28:03,900
multi-cloud performance involved you

651
00:28:01,320 --> 00:28:06,540
know testing from multiple regions

652
00:28:03,900 --> 00:28:08,550
within a single provider to multiple

653
00:28:06,540 --> 00:28:10,320
regions to another provider because

654
00:28:08,550 --> 00:28:12,090
there's a lot of communication today in

655
00:28:10,320 --> 00:28:14,820
enterprise architectures that involve in

656
00:28:12,090 --> 00:28:16,679
multi club so we wanted to see what this

657
00:28:14,820 --> 00:28:18,360
looks like and as you can see here a

658
00:28:16,680 --> 00:28:20,040
jitter and packet loss and I mentioned

659
00:28:18,360 --> 00:28:22,199
this earlier as well that was not

660
00:28:20,040 --> 00:28:24,659
anything significant or interesting that

661
00:28:22,200 --> 00:28:26,580
we noticed in terms of trends the

662
00:28:24,660 --> 00:28:28,530
interesting takeaway from a multi cloud

663
00:28:26,580 --> 00:28:30,270
performance angle with how these three

664
00:28:28,530 --> 00:28:32,399
providers connect and pure with each

665
00:28:30,270 --> 00:28:34,830
other so they obviously pair directly

666
00:28:32,400 --> 00:28:37,410
with each other and what that means is

667
00:28:34,830 --> 00:28:39,419
traffic in a multi cloud scenario never

668
00:28:37,410 --> 00:28:42,000
really leaves the backbone of these

669
00:28:39,420 --> 00:28:44,370
cloud providers so if you are connecting

670
00:28:42,000 --> 00:28:48,000
AWS to Google cloud you're pretty much

671
00:28:44,370 --> 00:28:50,459
going to take either go with AWS and

672
00:28:48,000 --> 00:28:54,030
then move on to Google Club now the

673
00:28:50,460 --> 00:28:56,970
interesting note however is because AWS

674
00:28:54,030 --> 00:28:59,399
does not use their backbone to move

675
00:28:56,970 --> 00:29:02,250
traffic they will push the traffic over

676
00:28:59,400 --> 00:29:04,290
to Google as soon as possible and Google

677
00:29:02,250 --> 00:29:06,150
will carry the rest of the traffic so

678
00:29:04,290 --> 00:29:08,280
that's just you know an interesting

679
00:29:06,150 --> 00:29:11,000
detail that we noticed while we were

680
00:29:08,280 --> 00:29:13,350
looking at I'll take you out performance

681
00:29:11,000 --> 00:29:15,690
so really that that kind of brings me to

682
00:29:13,350 --> 00:29:18,480
the end of you know the the presentation

683
00:29:15,690 --> 00:29:20,340
here and put me learn from this which we

684
00:29:18,480 --> 00:29:22,740
went in this into this without any

685
00:29:20,340 --> 00:29:24,330
assumptions or not expecting one is

686
00:29:22,740 --> 00:29:26,610
going one provider is going to perform

687
00:29:24,330 --> 00:29:29,490
better than the other right the idea was

688
00:29:26,610 --> 00:29:30,990
to learn and find out what the

689
00:29:29,490 --> 00:29:33,540
differences are what the similarities

690
00:29:30,990 --> 00:29:36,240
might exist and what we noticed is that

691
00:29:33,540 --> 00:29:38,430
cloud connectivity architectures are not

692
00:29:36,240 --> 00:29:40,200
the same they have an impact on

693
00:29:38,430 --> 00:29:42,690
performance and it's something we should

694
00:29:40,200 --> 00:29:45,000
be aware of geographical performance

695
00:29:42,690 --> 00:29:48,110
varies especially when it comes to Asia

696
00:29:45,000 --> 00:29:50,400
not so much in North America and Europe

697
00:29:48,110 --> 00:29:52,350
intra-cloud performance which is inter

698
00:29:50,400 --> 00:29:54,870
region and Inter is a performance for

699
00:29:52,350 --> 00:29:57,300
most parts did really well so that's

700
00:29:54,870 --> 00:29:59,100
definitely a positive and then multi

701
00:29:57,300 --> 00:30:00,480
cloud is a safe alternative right these

702
00:29:59,100 --> 00:30:02,699
three providers have a symbiotic

703
00:30:00,480 --> 00:30:04,980
relationship so multi cloud is

704
00:30:02,700 --> 00:30:08,100
definitely a good way to go if you're

705
00:30:04,980 --> 00:30:11,120
considering that so in terms of

706
00:30:08,100 --> 00:30:13,560
recommendations what does this mean for

707
00:30:11,120 --> 00:30:15,149
you know enterprises moving to the cloud

708
00:30:13,560 --> 00:30:18,300
or starting to rely on these cloud

709
00:30:15,150 --> 00:30:19,920
providers is use data as a guiding

710
00:30:18,300 --> 00:30:21,899
factor to make your cloud investment

711
00:30:19,920 --> 00:30:23,820
decisions there are a lot of criteria

712
00:30:21,900 --> 00:30:25,490
that you need to consider while you're

713
00:30:23,820 --> 00:30:29,399
picking your right cloud provider right

714
00:30:25,490 --> 00:30:32,010
pricing geographical location services

715
00:30:29,400 --> 00:30:36,000
availability but use data as well do not

716
00:30:32,010 --> 00:30:38,160
discount data right because in the cloud

717
00:30:36,000 --> 00:30:40,290
you can trust but you always always

718
00:30:38,160 --> 00:30:42,030
always need to verify and you cannot

719
00:30:40,290 --> 00:30:44,159
afford to make assumptions in the cloud

720
00:30:42,030 --> 00:30:45,990
because there is no steady state in the

721
00:30:44,160 --> 00:30:48,180
cloud what looks like good performance

722
00:30:45,990 --> 00:30:50,340
today might not be good performance

723
00:30:48,180 --> 00:30:51,900
tomorrow all these three providers are

724
00:30:50,340 --> 00:30:55,050
continuously investing in their

725
00:30:51,900 --> 00:30:56,550
architectures to make it better so good

726
00:30:55,050 --> 00:30:59,070
today might not be good tomorrow

727
00:30:56,550 --> 00:31:00,310
which really brings us to our research

728
00:30:59,070 --> 00:31:03,520
vision right since we

729
00:31:00,310 --> 00:31:05,889
nice that this is not a snapshot this

730
00:31:03,520 --> 00:31:08,560
cannot be a snapshot in time we want to

731
00:31:05,890 --> 00:31:10,300
keep doing this research every year and

732
00:31:08,560 --> 00:31:13,000
we want to broaden the scope of this

733
00:31:10,300 --> 00:31:14,860
research as well this year again it was

734
00:31:13,000 --> 00:31:16,300
the first time we were doing it we

735
00:31:14,860 --> 00:31:19,870
started with the big three

736
00:31:16,300 --> 00:31:21,550
you know we had 27 global locations 55

737
00:31:19,870 --> 00:31:23,439
regions but in the future we're

738
00:31:21,550 --> 00:31:26,139
expanding we're thinking of expanding it

739
00:31:23,440 --> 00:31:29,430
to maybe other providers maybe more

740
00:31:26,140 --> 00:31:31,990
regions also understanding and comparing

741
00:31:29,430 --> 00:31:34,150
differences and performance for their

742
00:31:31,990 --> 00:31:36,040
private connectivity service right which

743
00:31:34,150 --> 00:31:38,620
is Express route versus direct connect

744
00:31:36,040 --> 00:31:41,110
and and so on so that's something we are

745
00:31:38,620 --> 00:31:43,469
thinking of going forward and you know

746
00:31:41,110 --> 00:31:45,850
executing later on this year as well so

747
00:31:43,470 --> 00:31:47,680
it really brings me to the end of the

748
00:31:45,850 --> 00:31:49,870
presentation if you are interested in

749
00:31:47,680 --> 00:31:51,790
you know looking at the report reading

750
00:31:49,870 --> 00:31:54,550
more about it you can download it from

751
00:31:51,790 --> 00:31:57,159
the link there it's it's free if you

752
00:31:54,550 --> 00:31:58,419
have questions hit me up now or I'm

753
00:31:57,160 --> 00:32:00,910
gonna be around for the next couple of

754
00:31:58,420 --> 00:32:01,920
days and happy to sync up with you thank

755
00:32:00,910 --> 00:32:09,800
you

756
00:32:01,920 --> 00:32:13,350
[Applause]

757
00:32:09,800 --> 00:32:18,240
you're there first hi Dan Goulding with

758
00:32:13,350 --> 00:32:19,860
Google first but first I just wanna say

759
00:32:18,240 --> 00:32:22,110
great present don't be nervous cuz this

760
00:32:19,860 --> 00:32:23,820
is a great presentation yeah really

761
00:32:22,110 --> 00:32:25,949
impressive in terms of what you're

762
00:32:23,820 --> 00:32:29,159
working on next would love to see the

763
00:32:25,950 --> 00:32:31,200
private interconnect stuff I I think you

764
00:32:29,160 --> 00:32:33,270
may want to consider some different

765
00:32:31,200 --> 00:32:36,510
forms of measurement when you when you

766
00:32:33,270 --> 00:32:38,850
do that and even private interconnect

767
00:32:36,510 --> 00:32:40,530
from one provider to another provider it

768
00:32:38,850 --> 00:32:43,230
could also be extremely interesting we

769
00:32:40,530 --> 00:32:47,850
would love to see that data as far as

770
00:32:43,230 --> 00:32:49,860
the Mumbai issue great catch I by the by

771
00:32:47,850 --> 00:32:53,399
the time you run another set of tests

772
00:32:49,860 --> 00:32:55,300
that will be resolved okay great

773
00:32:53,400 --> 00:32:59,410
[Applause]

774
00:32:55,300 --> 00:33:02,210
[Music]

775
00:32:59,410 --> 00:33:04,520
definitely great talk met PTAC here on

776
00:33:02,210 --> 00:33:07,190
the inter region one of the earlier

777
00:33:04,520 --> 00:33:09,770
slides there you tossed out a comparison

778
00:33:07,190 --> 00:33:11,750
to internet baseline without really

779
00:33:09,770 --> 00:33:14,300
defining that too clearly if you come

780
00:33:11,750 --> 00:33:15,590
back and do a future report I would love

781
00:33:14,300 --> 00:33:18,080
to hear a little bit more about how you

782
00:33:15,590 --> 00:33:20,419
decided on what that internet baseline

783
00:33:18,080 --> 00:33:22,220
was because that is a whole kettle of

784
00:33:20,420 --> 00:33:24,680
worms on how you measure that piece of

785
00:33:22,220 --> 00:33:26,870
it absolutely so the way we did that is

786
00:33:24,680 --> 00:33:28,670
these agents we're talking about for

787
00:33:26,870 --> 00:33:30,820
inter region we're located within the

788
00:33:28,670 --> 00:33:33,140
service providers but we also have

789
00:33:30,820 --> 00:33:35,000
reagents that are located outside these

790
00:33:33,140 --> 00:33:37,820
service providers in tier 2 and tier 3

791
00:33:35,000 --> 00:33:40,640
networks so when we picked say Ashburn

792
00:33:37,820 --> 00:33:42,560
in London for instance the measurement

793
00:33:40,640 --> 00:33:45,530
that we got the absolute value was

794
00:33:42,560 --> 00:33:47,270
within AWS and then we used the internet

795
00:33:45,530 --> 00:33:50,570
baseline was we picked our agents

796
00:33:47,270 --> 00:33:52,879
outside which was a which is either and

797
00:33:50,570 --> 00:33:54,980
I can't remember which exact ISP it's

798
00:33:52,880 --> 00:33:57,530
located out of for that region but we

799
00:33:54,980 --> 00:33:59,060
looked at Ashburn and then another agent

800
00:33:57,530 --> 00:34:01,700
in London and that's really what we

801
00:33:59,060 --> 00:34:04,790
meant by internet baseline which with it

802
00:34:01,700 --> 00:34:06,830
was in going with in AWS Azure Amazon

803
00:34:04,790 --> 00:34:08,899
right but where the selection of your

804
00:34:06,830 --> 00:34:13,279
agents is you're measuring specific

805
00:34:08,899 --> 00:34:15,080
backbone tier 2 connectivity and that's

806
00:34:13,280 --> 00:34:17,240
not really internet average so

807
00:34:15,080 --> 00:34:22,310
reflecting that out saying okay this was

808
00:34:17,239 --> 00:34:24,500
a CenturyLink to a cogent measurement

809
00:34:22,310 --> 00:34:26,330
point you're looking at two specific

810
00:34:24,500 --> 00:34:28,219
providers there unless you have enough

811
00:34:26,330 --> 00:34:30,860
data points to really get a good

812
00:34:28,219 --> 00:34:32,239
aggregate you're actually looking at a

813
00:34:30,860 --> 00:34:34,220
separate set of measurements which is

814
00:34:32,239 --> 00:34:36,620
yes full of provider to provider

815
00:34:34,219 --> 00:34:40,189
connectivity but generalizing that as an

816
00:34:36,620 --> 00:34:42,250
internet baseline might be good talking

817
00:34:40,190 --> 00:34:45,020
great thank you

818
00:34:42,250 --> 00:34:47,810
hi my name is Evan Moore from first

819
00:34:45,020 --> 00:34:50,300
light fibre corporation I'm very curious

820
00:34:47,810 --> 00:34:53,360
on this ten minute sampling interval

821
00:34:50,300 --> 00:34:56,419
that you used in your study and what

822
00:34:53,360 --> 00:34:59,060
discussion or consideration brought you

823
00:34:56,418 --> 00:35:03,049
to the ten minute interval my first

824
00:34:59,060 --> 00:35:06,049
response is ten minutes is an eon so I'd

825
00:35:03,050 --> 00:35:08,180
like to hear that well there's nothing

826
00:35:06,050 --> 00:35:09,780
really restricting us from you know

827
00:35:08,180 --> 00:35:12,990
reducing this intro

828
00:35:09,780 --> 00:35:15,180
all the way up to one minute as well it

829
00:35:12,990 --> 00:35:17,700
means to be honest we thought well do we

830
00:35:15,180 --> 00:35:19,500
want to test it once every hour or once

831
00:35:17,700 --> 00:35:21,210
every minute is there going to be much

832
00:35:19,500 --> 00:35:22,890
changes once every minute because we

833
00:35:21,210 --> 00:35:25,350
were measuring over a period of time so

834
00:35:22,890 --> 00:35:28,980
we just picked 10 minutes as you know a

835
00:35:25,350 --> 00:35:30,690
point that that worked out well it is

836
00:35:28,980 --> 00:35:35,600
possible that we can reduce that in the

837
00:35:30,690 --> 00:35:41,190
future as well David Silberman LinkedIn

838
00:35:35,600 --> 00:35:43,710
hi so glad to see that I sure wasn't

839
00:35:41,190 --> 00:35:47,190
worst of most of the categories I was

840
00:35:43,710 --> 00:35:49,830
positive plus one on the private

841
00:35:47,190 --> 00:35:50,850
connectivity part Express route and if

842
00:35:49,830 --> 00:35:53,460
you're not aware of it the Express route

843
00:35:50,850 --> 00:35:54,990
direct might have different performance

844
00:35:53,460 --> 00:35:56,730
envelope so you might want to look at

845
00:35:54,990 --> 00:35:58,560
those somewhat separately or whatever

846
00:35:56,730 --> 00:36:00,840
they're renaming them to but most

847
00:35:58,560 --> 00:36:04,920
importantly did you do these tests over

848
00:36:00,840 --> 00:36:07,520
ipv4 ipv6 or both it would be before you

849
00:36:04,920 --> 00:36:10,170
have any plans to include ipv6 for 2019

850
00:36:07,520 --> 00:36:12,660
it's possible I haven't really thought

851
00:36:10,170 --> 00:36:14,910
about it right now but our agents R and

852
00:36:12,660 --> 00:36:17,490
B for mv6 environments as well so that

853
00:36:14,910 --> 00:36:19,200
is something we could consider I'd like

854
00:36:17,490 --> 00:36:20,700
to touch base with you later on to see

855
00:36:19,200 --> 00:36:27,589
if there's specifics with v6 you're

856
00:36:20,700 --> 00:36:29,819
looking for oh sorry any other questions

857
00:36:27,590 --> 00:36:32,680
all right I won't stand in a way between

858
00:36:29,820 --> 00:36:35,830
lunch and you guys so thank you so much

859
00:36:32,680 --> 00:36:35,830
[Applause]

860
00:36:41,390 --> 00:36:43,450
you

