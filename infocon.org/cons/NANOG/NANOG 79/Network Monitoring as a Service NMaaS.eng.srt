1
00:00:00,000 --> 00:00:03,030
[Music]

2
00:00:03,420 --> 00:00:07,659
you

3
00:00:04,360 --> 00:00:07,659
[Music]

4
00:00:10,960 --> 00:00:15,710
because I would like to introduce our

5
00:00:13,100 --> 00:00:18,050
speaker Brian to vent rank who is the

6
00:00:15,710 --> 00:00:20,029
DevOps engineer in orange you'll be

7
00:00:18,050 --> 00:00:23,540
presenting on the network monitoring as

8
00:00:20,029 --> 00:00:26,240
a service so hi everyone thanks for

9
00:00:23,540 --> 00:00:28,939
tuning in to this presentation I'm going

10
00:00:26,240 --> 00:00:33,250
to talk about the Animas platform which

11
00:00:28,939 --> 00:00:36,739
stands for network metering as a service

12
00:00:33,250 --> 00:00:40,580
so let's jump right into it let's

13
00:00:36,739 --> 00:00:46,190
introduce the MS network quality and

14
00:00:40,580 --> 00:00:49,610
security is crucial for any is B however

15
00:00:46,190 --> 00:00:52,190
and in monolithic systems isn't tailored

16
00:00:49,610 --> 00:00:54,559
for today's ISPs infrastructures

17
00:00:52,190 --> 00:00:57,349
therefore we need distributed systems

18
00:00:54,559 --> 00:01:01,190
here well we'll talk about distributed

19
00:00:57,350 --> 00:01:04,099
measurement systems or DMS to put it

20
00:01:01,190 --> 00:01:06,950
simply DMS are monitoring applications

21
00:01:04,099 --> 00:01:09,740
that are deploying devices over networks

22
00:01:06,950 --> 00:01:11,780
and these monitoring applications are

23
00:01:09,740 --> 00:01:14,119
retrieving network measurements that can

24
00:01:11,780 --> 00:01:17,120
be used to be visualized on dashboarding

25
00:01:14,119 --> 00:01:23,450
used for other thing that the study is

26
00:01:17,120 --> 00:01:26,690
etc several examples of DMS already

27
00:01:23,450 --> 00:01:29,060
exists for example some knows which

28
00:01:26,690 --> 00:01:31,370
works on private infrastructures in

29
00:01:29,060 --> 00:01:34,970
order to measure quality of experience

30
00:01:31,370 --> 00:01:39,050
of its end users or we also have DNS

31
00:01:34,970 --> 00:01:41,539
like cut tighter arc or ripe Atlas that

32
00:01:39,050 --> 00:01:44,860
studies internet tomography on larger

33
00:01:41,540 --> 00:01:44,860
scale public infrastructure

34
00:01:44,950 --> 00:01:51,470
therefore the complexity of designing

35
00:01:48,050 --> 00:01:54,710
such DNS is about scalability and the

36
00:01:51,470 --> 00:01:57,320
reliability of these measurements for

37
00:01:54,710 --> 00:01:59,780
instance since many applications can be

38
00:01:57,320 --> 00:02:01,460
hosted on the same device we have to

39
00:01:59,780 --> 00:02:04,760
make sure that these applications do not

40
00:02:01,460 --> 00:02:06,050
compete for computing resources so that

41
00:02:04,760 --> 00:02:09,908
the collected measurements are not

42
00:02:06,050 --> 00:02:12,590
biased here were simply illustrating

43
00:02:09,908 --> 00:02:16,429
applications through their concern

44
00:02:12,590 --> 00:02:20,950
consumptions of RAM over time and our

45
00:02:16,430 --> 00:02:20,950
goal is for them not to overlap

46
00:02:22,239 --> 00:02:27,739
so that's why we're proposing our and

47
00:02:25,430 --> 00:02:30,230
math solutions and mass is an

48
00:02:27,739 --> 00:02:33,530
open-source platform which is currently

49
00:02:30,230 --> 00:02:36,079
publicly available yet and the N mass

50
00:02:33,530 --> 00:02:38,380
uses the flexibility of container

51
00:02:36,080 --> 00:02:41,959
technology in order to deploy and manage

52
00:02:38,380 --> 00:02:44,599
applications through pour of physical

53
00:02:41,959 --> 00:02:47,209
machines so this we are adding our

54
00:02:44,599 --> 00:02:49,220
custom scheduler to the endless which

55
00:02:47,209 --> 00:02:54,500
ensures that these applications do not

56
00:02:49,220 --> 00:02:57,140
compete with the resources the N mass is

57
00:02:54,500 --> 00:02:59,150
reaching to main use cases that had been

58
00:02:57,140 --> 00:03:02,029
mentioned earlier the first end mass can

59
00:02:59,150 --> 00:03:04,580
be a private JMS where one can deploy it

60
00:03:02,030 --> 00:03:07,670
on the network and measure its

61
00:03:04,580 --> 00:03:09,910
performance and services the other use

62
00:03:07,670 --> 00:03:12,980
case would be that the n mass becomes

63
00:03:09,910 --> 00:03:14,959
public JMS where one deploys it on

64
00:03:12,980 --> 00:03:21,230
multiple networks as a large-scale

65
00:03:14,959 --> 00:03:24,799
public in space Jemma's through online

66
00:03:21,230 --> 00:03:28,310
applications and n mass solution catters

67
00:03:24,799 --> 00:03:30,769
too many functionalities first one can

68
00:03:28,310 --> 00:03:33,380
choose which monitoring applications to

69
00:03:30,769 --> 00:03:36,560
deploy from a catalog over the machines

70
00:03:33,380 --> 00:03:39,769
in the network then one can visualize

71
00:03:36,560 --> 00:03:41,359
and manage a pool of machines as well as

72
00:03:39,769 --> 00:03:44,630
the applications that are hosted and

73
00:03:41,359 --> 00:03:46,579
running then once that these

74
00:03:44,630 --> 00:03:48,769
applications have finished retrieving

75
00:03:46,579 --> 00:03:52,989
the measurements one can examine these

76
00:03:48,769 --> 00:03:52,989
results and raise alerts if necessary

77
00:03:54,400 --> 00:03:59,510
several rows can be used a customized

78
00:03:57,650 --> 00:04:02,720
into endless environments but we are

79
00:03:59,510 --> 00:04:04,819
looking here for four main roles first

80
00:04:02,720 --> 00:04:07,280
of all we got the user simply put the

81
00:04:04,819 --> 00:04:09,350
user logs in and mass chooses an

82
00:04:07,280 --> 00:04:12,290
application deployed it and run the

83
00:04:09,350 --> 00:04:15,010
tests then we got the node owner which

84
00:04:12,290 --> 00:04:18,560
manages machines over a network

85
00:04:15,010 --> 00:04:20,690
we got the app developer and as it name

86
00:04:18,560 --> 00:04:23,720
suggests it develops the apps submits

87
00:04:20,690 --> 00:04:25,820
the apps to a catalog and finally we got

88
00:04:23,720 --> 00:04:29,120
the validator which lines up nodes

89
00:04:25,820 --> 00:04:32,320
applications and users for security and

90
00:04:29,120 --> 00:04:32,320
compatibility issues

91
00:04:32,810 --> 00:04:39,300
let's get an overview of the enemas then

92
00:04:36,840 --> 00:04:42,479
us needs several modules in order to

93
00:04:39,300 --> 00:04:45,689
work since the end mass is a distributed

94
00:04:42,479 --> 00:04:48,080
system we want to manage efficiently so

95
00:04:45,689 --> 00:04:49,979
we will mid needing orchestration

96
00:04:48,080 --> 00:04:52,770
furthermore we want to ease the

97
00:04:49,979 --> 00:04:54,960
deployments which means automation we

98
00:04:52,770 --> 00:04:57,539
also need to store the measurements in a

99
00:04:54,960 --> 00:04:59,878
database and since the data model of

100
00:04:57,539 --> 00:05:03,780
these measurements are typically metrics

101
00:04:59,879 --> 00:05:06,449
these metrics will need a connector then

102
00:05:03,780 --> 00:05:08,940
we will be needing to display these

103
00:05:06,449 --> 00:05:11,370
metrics on a graphic user interface and

104
00:05:08,940 --> 00:05:13,759
the dashboard will be here for the user

105
00:05:11,370 --> 00:05:16,650
to choose the application and deploy it

106
00:05:13,759 --> 00:05:20,669
finally we can add a middleware which

107
00:05:16,650 --> 00:05:24,330
links all these services so the goal

108
00:05:20,669 --> 00:05:27,389
here one of the goal of the Animas is to

109
00:05:24,330 --> 00:05:31,139
be and stay open source so we will be

110
00:05:27,389 --> 00:05:32,430
using only open source solutions since

111
00:05:31,139 --> 00:05:34,650
we will be working with docker

112
00:05:32,430 --> 00:05:38,039
containers will be orchestrating with

113
00:05:34,650 --> 00:05:40,190
cuban it is to configure the server will

114
00:05:38,039 --> 00:05:44,310
be automating it with ansible

115
00:05:40,190 --> 00:05:47,940
for metric collection and storage we got

116
00:05:44,310 --> 00:05:50,009
from Matthias and as many may know graph

117
00:05:47,940 --> 00:05:53,879
Ana will be here to display graphs of

118
00:05:50,009 --> 00:05:56,099
data for the dashboard we will not be

119
00:05:53,879 --> 00:05:58,770
using the default kubernetes dashboard

120
00:05:56,099 --> 00:06:02,029
since we want to add this catalog

121
00:05:58,770 --> 00:06:05,339
feature which is enabled in renter and

122
00:06:02,029 --> 00:06:10,050
finally we suggest to take SEO for the

123
00:06:05,339 --> 00:06:11,909
mesh of micro services furthermore we

124
00:06:10,050 --> 00:06:15,060
are not using these open source

125
00:06:11,909 --> 00:06:18,330
solutions as is because we are basing

126
00:06:15,060 --> 00:06:22,699
our network mentoring at the service

127
00:06:18,330 --> 00:06:26,878
solutions on previous works the

128
00:06:22,699 --> 00:06:29,099
automatic deployment of humanities

129
00:06:26,879 --> 00:06:32,940
cluster is made available with cube

130
00:06:29,099 --> 00:06:35,610
spray and the deployment of a monitoring

131
00:06:32,940 --> 00:06:39,060
system on the humanities cluster is also

132
00:06:35,610 --> 00:06:41,399
made available with two primitives as of

133
00:06:39,060 --> 00:06:44,159
right now we are currently working on

134
00:06:41,399 --> 00:06:46,690
implementing Rancher and later on we

135
00:06:44,159 --> 00:06:51,409
will be working on this deal

136
00:06:46,690 --> 00:06:55,430
to this we have several added values for

137
00:06:51,410 --> 00:06:58,790
reminder we want a catalog so we've been

138
00:06:55,430 --> 00:07:00,980
using a private local repository so

139
00:06:58,790 --> 00:07:04,310
that's the app developers can submit

140
00:07:00,980 --> 00:07:07,310
their own apps on their own premises and

141
00:07:04,310 --> 00:07:10,490
this is made available and will be

142
00:07:07,310 --> 00:07:13,070
generated by keep spray furthermore

143
00:07:10,490 --> 00:07:16,850
chipra matures implements another module

144
00:07:13,070 --> 00:07:20,419
with our ad manager where users can

145
00:07:16,850 --> 00:07:23,270
choose to be notified whenever a metric

146
00:07:20,419 --> 00:07:26,240
which is a specific threshold whether

147
00:07:23,270 --> 00:07:30,139
it's a note metric or an application

148
00:07:26,240 --> 00:07:32,389
metric and finally with sto we are

149
00:07:30,139 --> 00:07:35,660
looking for key ally which is basically

150
00:07:32,389 --> 00:07:38,750
a graphic interface for the measures of

151
00:07:35,660 --> 00:07:41,330
services where we can't see where the

152
00:07:38,750 --> 00:07:46,430
applications are hosted and linked to

153
00:07:41,330 --> 00:07:51,020
the machines now more on the scheduler

154
00:07:46,430 --> 00:07:52,760
the scheduler is for minder here to

155
00:07:51,020 --> 00:07:55,930
ensure the applications do not compete

156
00:07:52,760 --> 00:07:58,700
with computer with computing resources

157
00:07:55,930 --> 00:08:01,250
this scheduler is based on the ant

158
00:07:58,700 --> 00:08:03,650
colony system that we'll be explaining

159
00:08:01,250 --> 00:08:06,410
on the next slide and in handles

160
00:08:03,650 --> 00:08:09,950
requests for deployments basically what

161
00:08:06,410 --> 00:08:11,930
does it do it takes in input the current

162
00:08:09,950 --> 00:08:14,150
state of the cluster machines and

163
00:08:11,930 --> 00:08:18,289
applications currently running and

164
00:08:14,150 --> 00:08:21,219
hosted and gives in outputs new resource

165
00:08:18,289 --> 00:08:24,020
allocations in a schedule with potential

166
00:08:21,220 --> 00:08:27,050
integrations over several devices and

167
00:08:24,020 --> 00:08:31,460
these migrations are eased up thanks to

168
00:08:27,050 --> 00:08:35,060
the container technology now more on the

169
00:08:31,460 --> 00:08:38,718
end current system what does it how does

170
00:08:35,059 --> 00:08:40,760
it work basically when an ant is looking

171
00:08:38,719 --> 00:08:44,180
for food it drops some pheromones and

172
00:08:40,760 --> 00:08:46,370
when other ends is are also looking for

173
00:08:44,179 --> 00:08:48,380
food as well that will follow a path

174
00:08:46,370 --> 00:08:50,900
where there's the highest concentration

175
00:08:48,380 --> 00:08:53,439
of pheromones which with time will lead

176
00:08:50,900 --> 00:08:56,150
to the shortest path to this food

177
00:08:53,440 --> 00:08:58,459
therefore our scheduler takes

178
00:08:56,150 --> 00:08:59,030
inspiration in this and colony systems

179
00:08:58,459 --> 00:09:01,520
to

180
00:08:59,030 --> 00:09:08,000
braw the research space and find the

181
00:09:01,520 --> 00:09:10,910
best optimize resource locations now

182
00:09:08,000 --> 00:09:15,200
finally on the apps catalog the apps

183
00:09:10,910 --> 00:09:18,380
credit catalog is basically an app store

184
00:09:15,200 --> 00:09:20,660
which is container based as of right now

185
00:09:18,380 --> 00:09:23,360
the first catalog contains an IP

186
00:09:20,660 --> 00:09:25,969
spoofing detection app quality of

187
00:09:23,360 --> 00:09:28,850
service measuring up and a cartography

188
00:09:25,970 --> 00:09:31,060
application of course the catalog is not

189
00:09:28,850 --> 00:09:34,820
limited to these three applications

190
00:09:31,060 --> 00:09:37,369
since one of our other goal is for you

191
00:09:34,820 --> 00:09:40,960
to develop your own applications that

192
00:09:37,370 --> 00:09:40,960
you want to test on your own networks

193
00:09:42,040 --> 00:09:47,780
now let's see what's happening when we

194
00:09:44,570 --> 00:09:49,730
deploy to Emma's since we are working

195
00:09:47,780 --> 00:09:52,699
with the communities cluster we'll be

196
00:09:49,730 --> 00:09:54,320
using a master worker system so let's

197
00:09:52,700 --> 00:09:57,440
say for example one master and two

198
00:09:54,320 --> 00:09:59,720
workers we also want to prove that the

199
00:09:57,440 --> 00:10:03,230
master can also be a worker thanks to

200
00:09:59,720 --> 00:10:06,460
the communities features we want the end

201
00:10:03,230 --> 00:10:10,340
mass to be able to be to scare through

202
00:10:06,460 --> 00:10:12,980
several lands or to work with one land

203
00:10:10,340 --> 00:10:15,890
only so we are trusting two machines in

204
00:10:12,980 --> 00:10:19,970
our first lab and another machine in a

205
00:10:15,890 --> 00:10:23,000
second land and finally we want it to is

206
00:10:19,970 --> 00:10:25,400
the deployments by installing on your

207
00:10:23,000 --> 00:10:28,850
own machines which here is represented

208
00:10:25,400 --> 00:10:31,040
by the installer the first step will be

209
00:10:28,850 --> 00:10:34,190
to register all your nodes to the

210
00:10:31,040 --> 00:10:37,490
automation tool then the second step

211
00:10:34,190 --> 00:10:39,920
would be to initialize a cluster with

212
00:10:37,490 --> 00:10:42,980
kubernetes thanks to all the register

213
00:10:39,920 --> 00:10:47,209
node on the automation tool and once all

214
00:10:42,980 --> 00:10:51,350
these platforms and machines have been

215
00:10:47,210 --> 00:10:54,950
installed if we ever want to continue

216
00:10:51,350 --> 00:10:57,110
expanding this cluster the process goes

217
00:10:54,950 --> 00:10:59,510
the same way when we have an additional

218
00:10:57,110 --> 00:11:02,090
machine will be registering this machine

219
00:10:59,510 --> 00:11:03,800
to the automation agents and then we'll

220
00:11:02,090 --> 00:11:08,200
be adding this machine to the

221
00:11:03,800 --> 00:11:11,229
communities cluster so

222
00:11:08,200 --> 00:11:13,330
what's happening in micro overview for

223
00:11:11,230 --> 00:11:17,440
master and worker we got the automation

224
00:11:13,330 --> 00:11:20,770
agents and on orchestration agent thanks

225
00:11:17,440 --> 00:11:22,900
to doctor we got to have virtual

226
00:11:20,770 --> 00:11:25,510
environments for your own applications

227
00:11:22,900 --> 00:11:27,579
and masters and workers can communicate

228
00:11:25,510 --> 00:11:31,569
between themselves of our container

229
00:11:27,580 --> 00:11:34,420
network then the third step would be to

230
00:11:31,570 --> 00:11:37,360
install all the modules that we have

231
00:11:34,420 --> 00:11:40,060
mentioned earlier UI dashboard at the

232
00:11:37,360 --> 00:11:45,150
basement aware application and metric

233
00:11:40,060 --> 00:11:48,579
collectors how does the work flow goes

234
00:11:45,150 --> 00:11:50,829
here we got a user that we choose an

235
00:11:48,580 --> 00:11:52,930
application on the dashboard and deploy

236
00:11:50,830 --> 00:11:55,090
it on the worker so the dashboard will

237
00:11:52,930 --> 00:11:57,010
send the request to humanity's that we

238
00:11:55,090 --> 00:11:59,740
asked the worker to deploy these

239
00:11:57,010 --> 00:12:02,260
applications once these applications

240
00:11:59,740 --> 00:12:03,910
have finished working the metric

241
00:12:02,260 --> 00:12:06,310
collector we're retrieved these

242
00:12:03,910 --> 00:12:09,010
measurements and send it to store into

243
00:12:06,310 --> 00:12:14,229
the database on the master then the user

244
00:12:09,010 --> 00:12:16,390
can visualize on the UI the results in

245
00:12:14,230 --> 00:12:18,580
the first step we can add a middleware

246
00:12:16,390 --> 00:12:21,610
agents whenever you want to add

247
00:12:18,580 --> 00:12:24,340
additional modules to see the

248
00:12:21,610 --> 00:12:27,190
compatibility between the database for

249
00:12:24,340 --> 00:12:29,830
example and the metric collector another

250
00:12:27,190 --> 00:12:31,690
use of the mineral agent is whenever you

251
00:12:29,830 --> 00:12:34,260
want to link to application style

252
00:12:31,690 --> 00:12:34,260
working together

253
00:12:35,029 --> 00:12:41,910
what about security for reminder were

254
00:12:39,749 --> 00:12:44,220
using ansible for automation which means

255
00:12:41,910 --> 00:12:47,550
we're registering all the notes and the

256
00:12:44,220 --> 00:12:49,589
credentials with unstable votes unstable

257
00:12:47,550 --> 00:12:52,079
votes encrypts your credentials by

258
00:12:49,589 --> 00:12:56,009
concatenating the cipher texts and the

259
00:12:52,079 --> 00:12:58,709
sha-256 digest what about the notes well

260
00:12:56,009 --> 00:13:00,809
the end mass is based on a cloud

261
00:12:58,709 --> 00:13:03,170
structure which means that you trust

262
00:13:00,809 --> 00:13:06,389
your own infrastructure security

263
00:13:03,170 --> 00:13:08,389
therefore if anything we recommend to

264
00:13:06,389 --> 00:13:11,429
use a VPN for the deployments

265
00:13:08,389 --> 00:13:15,119
furthermore the communities to add a

266
00:13:11,429 --> 00:13:17,549
layer for the APHA API traffic we've

267
00:13:15,119 --> 00:13:21,239
generated certificates and role based

268
00:13:17,549 --> 00:13:24,540
access control whenever a user wants to

269
00:13:21,239 --> 00:13:27,720
access an application if we have to use

270
00:13:24,540 --> 00:13:30,899
services services in Kerber natives are

271
00:13:27,720 --> 00:13:37,410
made here to expose a specific endpoints

272
00:13:30,899 --> 00:13:40,889
through HTTP now let's see how we deploy

273
00:13:37,410 --> 00:13:42,990
the Animas the first step would be to

274
00:13:40,889 --> 00:13:45,720
setup the deployment which means to

275
00:13:42,990 --> 00:13:50,220
update your packages on masters workers

276
00:13:45,720 --> 00:13:53,429
and new installer the OpenSSH Python and

277
00:13:50,220 --> 00:13:56,369
it package are needed in order to run

278
00:13:53,429 --> 00:13:57,179
ansible and once you have cloned the

279
00:13:56,369 --> 00:13:58,980
repository

280
00:13:57,179 --> 00:14:03,329
you should install the requirements in

281
00:13:58,980 --> 00:14:05,339
the fight with it then in the second

282
00:14:03,329 --> 00:14:07,559
step you have to register your nodes by

283
00:14:05,339 --> 00:14:12,569
listing all the IP addresses in the

284
00:14:07,559 --> 00:14:16,259
inventory for the credentials this goes

285
00:14:12,569 --> 00:14:19,829
as juice sub step with and supports

286
00:14:16,259 --> 00:14:23,249
first you need to create for each node a

287
00:14:19,829 --> 00:14:26,699
specific file written as is so between

288
00:14:23,249 --> 00:14:31,949
brackets votes and stable user note 1

289
00:14:26,699 --> 00:14:33,929
note2 etc and then on another file you

290
00:14:31,949 --> 00:14:36,179
will create and encrypt with unstable

291
00:14:33,929 --> 00:14:39,119
votes or fire where you will be putting

292
00:14:36,179 --> 00:14:42,089
your real credentials here so this is

293
00:14:39,119 --> 00:14:44,819
the credential for the SSH communication

294
00:14:42,089 --> 00:14:46,710
with hostname password and the port

295
00:14:44,819 --> 00:14:49,209
number

296
00:14:46,710 --> 00:14:51,940
once this is done the third step would

297
00:14:49,210 --> 00:14:54,250
be to test the connection between all

298
00:14:51,940 --> 00:14:57,120
these machines so with an SI bow it is

299
00:14:54,250 --> 00:15:00,340
easy to do this with a simple ping and

300
00:14:57,120 --> 00:15:02,860
once everything goes well you can launch

301
00:15:00,340 --> 00:15:08,050
the deployment mix an instable playbook

302
00:15:02,860 --> 00:15:10,630
comment finally once all everything has

303
00:15:08,050 --> 00:15:14,349
finished you have to check if everything

304
00:15:10,630 --> 00:15:15,970
runs smoothly since every modules and

305
00:15:14,350 --> 00:15:19,510
services are running on the kubernetes

306
00:15:15,970 --> 00:15:22,330
platform we'll be using a kubernetes

307
00:15:19,510 --> 00:15:27,880
command to check if all services or

308
00:15:22,330 --> 00:15:31,000
running so in conclusion the Enna's

309
00:15:27,880 --> 00:15:34,570
platform is here to monitor the network

310
00:15:31,000 --> 00:15:37,540
and its services and it goes on

311
00:15:34,570 --> 00:15:40,870
scalability and provides accurate

312
00:15:37,540 --> 00:15:43,930
measurements we want it to be open

313
00:15:40,870 --> 00:15:47,440
source so that is publicly available for

314
00:15:43,930 --> 00:15:50,680
the community to use and contributes we

315
00:15:47,440 --> 00:15:53,110
want the automation to be to ease the

316
00:15:50,680 --> 00:15:55,750
deployment of the end mass which for the

317
00:15:53,110 --> 00:15:59,530
current state for example with social

318
00:15:55,750 --> 00:16:01,540
distancing pandemic etc it is quite

319
00:15:59,530 --> 00:16:04,240
lockdown friendly since we don't have to

320
00:16:01,540 --> 00:16:08,740
go to each machines and configure deeds

321
00:16:04,240 --> 00:16:11,530
on the premises then it's also easy and

322
00:16:08,740 --> 00:16:14,590
quick to integrate applications on the

323
00:16:11,530 --> 00:16:16,569
App Store the catalog and where you can

324
00:16:14,590 --> 00:16:19,900
test your network with your own

325
00:16:16,570 --> 00:16:22,750
applications and finally a force

326
00:16:19,900 --> 00:16:27,670
strength would be the end colony system

327
00:16:22,750 --> 00:16:30,340
based that is taking inspiration for the

328
00:16:27,670 --> 00:16:36,089
scheduler which enables proper resource

329
00:16:30,340 --> 00:16:36,090
allocation thank you for listening

330
00:16:38,819 --> 00:16:42,329
t-brain mrs. fascinating I'm actually

331
00:16:40,859 --> 00:16:45,149
looking forward to running it on my own

332
00:16:42,329 --> 00:16:46,829
network we've got three questions so far

333
00:16:45,149 --> 00:16:48,269
or if anybody else wants to go for

334
00:16:46,829 --> 00:16:50,579
anybody else wants to speak in a less

335
00:16:48,269 --> 00:16:52,889
mint one we'll try to fit it in but

336
00:16:50,579 --> 00:16:55,498
here's the first one are all these

337
00:16:52,889 --> 00:16:58,589
modules that is Griff Rana Prometheus

338
00:16:55,499 --> 00:17:02,419
and so on installed in every node well

339
00:16:58,589 --> 00:17:06,240
Griffin I'm Prometheus or right now

340
00:17:02,419 --> 00:17:09,209
installed on the master on every master

341
00:17:06,240 --> 00:17:11,490
that you got but if you want them to be

342
00:17:09,209 --> 00:17:14,579
installed on all the nodes you can and

343
00:17:11,490 --> 00:17:20,029
if you want them to be installed on one

344
00:17:14,579 --> 00:17:23,158
machine only you can as well okay our

345
00:17:20,029 --> 00:17:25,138
metrics just SNMP instruments limit

346
00:17:23,159 --> 00:17:30,179
reorder the extent of things like flow

347
00:17:25,138 --> 00:17:31,979
data it can measure anything actually

348
00:17:30,179 --> 00:17:34,230
that's the point of the end mass as long

349
00:17:31,980 --> 00:17:36,720
as you got the right application to test

350
00:17:34,230 --> 00:17:42,629
what you want to test it can be a simple

351
00:17:36,720 --> 00:17:44,279
thing latency or it can be data from our

352
00:17:42,629 --> 00:17:49,259
workers deployed in the network devices

353
00:17:44,279 --> 00:17:52,139
themselves well no we don't deliver

354
00:17:49,259 --> 00:17:53,580
specific network devices or specific

355
00:17:52,139 --> 00:17:55,229
electronics for it

356
00:17:53,580 --> 00:17:59,189
we want them to be installed on any

357
00:17:55,230 --> 00:18:03,629
server that you possibly have in your

358
00:17:59,190 --> 00:18:05,970
networks that you want to analyze okay

359
00:18:03,629 --> 00:18:08,399
his remote periodic auto discovery

360
00:18:05,970 --> 00:18:13,409
supported in this and math and a cell

361
00:18:08,399 --> 00:18:17,549
how is it being implemented here

362
00:18:13,409 --> 00:18:21,059
attenuated this so setting is remote

363
00:18:17,549 --> 00:18:26,250
periodic auto discovery supported and of

364
00:18:21,059 --> 00:18:30,379
so how are you are doing it if you're

365
00:18:26,250 --> 00:18:33,960
talking about auto discovery for

366
00:18:30,379 --> 00:18:38,250
applications we haven't implemented that

367
00:18:33,960 --> 00:18:39,809
yet the thing is on the kettle on the on

368
00:18:38,250 --> 00:18:43,409
the dashboard where you deploy to

369
00:18:39,809 --> 00:18:47,100
applications that's where the MS where

370
00:18:43,409 --> 00:18:50,460
be where a knowledge which application

371
00:18:47,100 --> 00:18:52,260
you want to you you want to activate and

372
00:18:50,460 --> 00:18:56,160
get measurements

373
00:18:52,260 --> 00:18:59,640
so the discovery is not here alright two

374
00:18:56,160 --> 00:19:01,860
more questions at all okay

375
00:18:59,640 --> 00:19:07,430
how do you absolute information and how

376
00:19:01,860 --> 00:19:10,110
are they written the applications

377
00:19:07,430 --> 00:19:14,540
collects information well for that

378
00:19:10,110 --> 00:19:19,830
that's according to your deployment team

379
00:19:14,540 --> 00:19:22,080
typically you want to just send any type

380
00:19:19,830 --> 00:19:23,970
of measuring tool network measuring tool

381
00:19:22,080 --> 00:19:27,110
but how are they written and how they

382
00:19:23,970 --> 00:19:30,240
are stored we're working right now to

383
00:19:27,110 --> 00:19:34,860
implement these network measurements as

384
00:19:30,240 --> 00:19:38,430
llamó files where we can used feature of

385
00:19:34,860 --> 00:19:41,669
Prometheus that or is using metrics so

386
00:19:38,430 --> 00:19:46,410
that it can be efficiently displayed on

387
00:19:41,670 --> 00:19:47,970
a GUI like Prasanna okay and I think

388
00:19:46,410 --> 00:19:49,110
they'll do it the last question looks

389
00:19:47,970 --> 00:19:52,290
like something you've already answered

390
00:19:49,110 --> 00:19:54,300
so um we'll skip it and we're running a

391
00:19:52,290 --> 00:19:58,260
bit over time so thank you very much

392
00:19:54,300 --> 00:19:59,940
Brian this concludes our session and we

393
00:19:58,260 --> 00:20:01,350
are gonna go next into the Nanak

394
00:19:59,940 --> 00:20:05,030
community meeting and our conference

395
00:20:01,350 --> 00:20:05,030
closing thank you again for attending

396
00:20:09,789 --> 00:20:11,850
you

