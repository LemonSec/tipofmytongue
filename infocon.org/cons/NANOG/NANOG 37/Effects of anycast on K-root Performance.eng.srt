1
00:00:01,250 --> 00:00:14,490
so yes so um a little bit of<font color="#E5E5E5"> an agenda</font>

2
00:00:09,719 --> 00:00:16,020
beforehand just<font color="#CCCCCC"> introduced the problem</font>

3
00:00:14,490 --> 00:00:18,539
that what we were trying<font color="#E5E5E5"> to do basically</font>

4
00:00:16,020 --> 00:00:20,970
how we were trying<font color="#E5E5E5"> to evaluate the</font>

5
00:00:18,539 --> 00:00:23,369
performance of any cost then we'll look

6
00:00:20,970 --> 00:00:26,098
at how we the ways we try to measure

7
00:00:23,369 --> 00:00:27,930
latency latency performance how to

8
00:00:26,099 --> 00:00:31,369
evaluate the benefit of individuals and

9
00:00:27,930 --> 00:00:35,820
loudoun in any class cloud a couple of

10
00:00:31,369 --> 00:00:38,489
slides on stability and then if we have

11
00:00:35,820 --> 00:00:40,860
time a couple of routing issues that we

12
00:00:38,489 --> 00:00:42,989
<font color="#CCCCCC">encounter during in the inner k</font>

13
00:00:40,860 --> 00:00:47,850
deployment and<font color="#E5E5E5"> their non-obvious and</font>

14
00:00:42,989 --> 00:00:49,890
<font color="#CCCCCC">I'll discuss those a five-time so so to</font>

15
00:00:47,850 --> 00:00:53,910
<font color="#E5E5E5">figure out what if any cast is effective</font>

16
00:00:49,890 --> 00:00:56,039
or not we<font color="#CCCCCC"> need to look</font><font color="#E5E5E5"> at the goals so</font>

17
00:00:53,910 --> 00:00:59,489
the goals are to provide resiliency

18
00:00:56,039 --> 00:01:01,050
that's the main goal to avoid them there

19
00:00:59,489 --> 00:01:02,430
are such attacks who spread load over

20
00:01:01,050 --> 00:01:06,658
multiple servers and to increase

21
00:01:02,430 --> 00:01:08,909
performance but<font color="#CCCCCC"> the feeling that that I</font>

22
00:01:06,659 --> 00:01:11,400
have and that other people have is that

23
00:01:08,909 --> 00:01:15,450
we<font color="#E5E5E5"> don't</font><font color="#CCCCCC"> really understand how any cast</font>

24
00:01:11,400 --> 00:01:17,130
affects performance we six as least six

25
00:01:15,450 --> 00:01:19,830
of the<font color="#CCCCCC"> route service or any custard and</font>

26
00:01:17,130 --> 00:01:21,689
we have hundreds I think 112 or

27
00:01:19,830 --> 00:01:22,979
something<font color="#E5E5E5"> nodes spread around the</font><font color="#CCCCCC"> world</font>

28
00:01:21,689 --> 00:01:25,380
but<font color="#E5E5E5"> we don't</font><font color="#CCCCCC"> really know how this</font>

29
00:01:22,979 --> 00:01:27,810
affects performance so this<font color="#E5E5E5"> is an</font>

30
00:01:25,380 --> 00:01:29,460
initial these are innocent<font color="#E5E5E5"> measure</font>

31
00:01:27,810 --> 00:01:33,600
methodologies that we can use to try to

32
00:01:29,460 --> 00:01:36,839
quantify that<font color="#E5E5E5"> oh how do we measure later</font>

33
00:01:33,600 --> 00:01:38,820
see so the<font color="#E5E5E5"> idea is in an ideal world if</font>

34
00:01:36,840 --> 00:01:41,610
the anycast deployment were perfect then

35
00:01:38,820 --> 00:01:43,770
we would throw the roots into bgp bgp

36
00:01:41,610 --> 00:01:46,170
would work its magic and every client

37
00:01:43,770 --> 00:01:48,539
every client of the root server would

38
00:01:46,170 --> 00:01:51,240
see the instance of the root server<font color="#CCCCCC"> i'll</font>

39
00:01:48,540 --> 00:01:54,899
<font color="#E5E5E5">use node from here on we'll see the node</font>

40
00:01:51,240 --> 00:01:58,649
with the lowest round trip time does it

41
00:01:54,899 --> 00:02:01,110
do this well we can if we had<font color="#CCCCCC"> access to</font>

42
00:01:58,649 --> 00:02:04,829
all the clients of the root server we

43
00:02:01,110 --> 00:02:09,000
could<font color="#E5E5E5"> just use we could just do measure</font>

44
00:02:04,829 --> 00:02:11,760
the RT<font color="#E5E5E5"> T's to the to</font><font color="#CCCCCC"> the K IP address or</font>

45
00:02:09,000 --> 00:02:13,349
to<font color="#CCCCCC"> the IP address of whatever root</font>

46
00:02:11,760 --> 00:02:13,859
server<font color="#CCCCCC"> we're entering i'll use</font><font color="#E5E5E5"> k because</font>

47
00:02:13,349 --> 00:02:15,690
we

48
00:02:13,860 --> 00:02:17,160
this one work on<font color="#CCCCCC"> K but we're very</font>

49
00:02:15,690 --> 00:02:19,470
<font color="#E5E5E5">interested in taking this to other root</font>

50
00:02:17,160 --> 00:02:21,780
servers as well to<font color="#CCCCCC"> see how deployment</font>

51
00:02:19,470 --> 00:02:24,030
affects performance so for every client

52
00:02:21,780 --> 00:02:26,430
we can measure the round-trip time of a

53
00:02:24,030 --> 00:02:27,960
query to<font color="#CCCCCC"> K and then we can measure round</font>

54
00:02:26,430 --> 00:02:30,870
trip times the queries<font color="#CCCCCC"> of all the other</font>

55
00:02:27,960 --> 00:02:32,370
<font color="#E5E5E5">nodes that are deployed and in our case</font>

56
00:02:30,870 --> 00:02:34,200
we did it<font color="#CCCCCC"> for the global nodes because</font>

57
00:02:32,370 --> 00:02:38,070
the global<font color="#E5E5E5"> node local nodes won't be</font>

58
00:02:34,200 --> 00:02:41,459
reachable from most clients and then we

59
00:02:38,070 --> 00:02:43,380
compare<font color="#E5E5E5"> the results so the</font><font color="#CCCCCC"> rit the</font>

60
00:02:41,459 --> 00:02:45,720
round-trip time to the<font color="#CCCCCC"> k IP address</font>

61
00:02:43,380 --> 00:02:47,670
gives the gives us an idea<font color="#CCCCCC"> of what the</font>

62
00:02:45,720 --> 00:02:52,220
query time of what the time of a query

63
00:02:47,670 --> 00:02:54,480
to k will<font color="#CCCCCC"> be and the time to the</font>

64
00:02:52,220 --> 00:02:56,550
addresses<font color="#CCCCCC"> of the other global nodes</font>

65
00:02:54,480 --> 00:03:00,590
gives us an idea<font color="#CCCCCC"> of what performance we</font>

66
00:02:56,550 --> 00:03:05,160
would see if<font color="#E5E5E5"> bgp had chosen that node so</font>

67
00:03:00,590 --> 00:03:08,010
when we compare these<font color="#CCCCCC"> results if we</font>

68
00:03:05,160 --> 00:03:09,930
simply divide one number by the other if

69
00:03:08,010 --> 00:03:11,820
we get a<font color="#CCCCCC"> result of one that means that</font>

70
00:03:09,930 --> 00:03:12,989
bgp is picking the right node it's

71
00:03:11,820 --> 00:03:15,600
choosing the node with the best

72
00:03:12,989 --> 00:03:18,269
performance<font color="#E5E5E5"> if the value alpha is</font>

73
00:03:15,600 --> 00:03:21,329
greater than one then bgp is making the

74
00:03:18,269 --> 00:03:23,880
wrong choice it's giving<font color="#E5E5E5"> us a client is</font>

75
00:03:21,330 --> 00:03:28,170
seeing a node with worst performance

76
00:03:23,880 --> 00:03:29,640
than it would<font color="#CCCCCC"> be able</font><font color="#E5E5E5"> to see if alpha is</font>

77
00:03:28,170 --> 00:03:32,548
less than<font color="#CCCCCC"> 1 then we're probably seeing</font>

78
00:03:29,640 --> 00:03:37,160
the local node in everything in fact in

79
00:03:32,549 --> 00:03:40,350
every case we were seeing local nodes so

80
00:03:37,160 --> 00:03:42,840
we did these measurements from both

81
00:03:40,350 --> 00:03:45,570
sides first of all we use the TTM

82
00:03:42,840 --> 00:03:47,750
<font color="#E5E5E5">network which is about network of about</font>

83
00:03:45,570 --> 00:03:50,880
a hundred boxes spread around the world

84
00:03:47,750 --> 00:03:53,549
mostly concentrated in<font color="#CCCCCC"> Europe and we</font>

85
00:03:50,880 --> 00:03:57,000
<font color="#E5E5E5">simply use dig to run the</font><font color="#CCCCCC"> queries we did</font>

86
00:03:53,549 --> 00:03:59,940
a hostname<font color="#CCCCCC"> top bind query to find out</font>

87
00:03:57,000 --> 00:04:03,000
which instance which node of the server

88
00:03:59,940 --> 00:04:04,440
was answering the query you expect the

89
00:04:03,000 --> 00:04:07,730
entities take that it took the minimum

90
00:04:04,440 --> 00:04:09,989
<font color="#E5E5E5">of five queries and we calculated alpha</font>

91
00:04:07,730 --> 00:04:12,450
just<font color="#CCCCCC"> to</font><font color="#E5E5E5"> make sure this was a fair</font>

92
00:04:09,989 --> 00:04:15,900
comparison we checked<font color="#E5E5E5"> the paths to the</font>

93
00:04:12,450 --> 00:04:18,570
single node interfaces before we them

94
00:04:15,900 --> 00:04:20,579
before we did this and the paths that<font color="#E5E5E5"> we</font>

95
00:04:18,570 --> 00:04:25,560
see to them to the single nodes are the

96
00:04:20,579 --> 00:04:27,000
same in in almost<font color="#E5E5E5"> every case the the</font>

97
00:04:25,560 --> 00:04:29,550
path to the K

98
00:04:27,000 --> 00:04:31,590
<font color="#E5E5E5">root IP address in almost every case is</font>

99
00:04:29,550 --> 00:04:33,810
the same as one of the paths to the<font color="#CCCCCC"> go</font>

100
00:04:31,590 --> 00:04:37,289
to<font color="#CCCCCC"> the global node so this is a fair</font>

101
00:04:33,810 --> 00:04:39,510
comparison so these<font color="#E5E5E5"> are the problems we</font>

102
00:04:37,290 --> 00:04:43,470
<font color="#CCCCCC">have as you can see they are mostly</font>

103
00:04:39,510 --> 00:04:44,940
concentrated in Europe this will we'll

104
00:04:43,470 --> 00:04:47,130
see how<font color="#CCCCCC"> that affects our results later</font>

105
00:04:44,940 --> 00:04:53,010
when we compare it to our server side

106
00:04:47,130 --> 00:04:59,090
measurements so these are<font color="#CCCCCC"> results I</font>

107
00:04:53,010 --> 00:05:06,240
believe these were on in april 2006 and

108
00:04:59,090 --> 00:05:08,760
so what do<font color="#CCCCCC"> we see here the on the y axis</font>

109
00:05:06,240 --> 00:05:10,800
<font color="#E5E5E5">we have the value of alpha remember one</font>

110
00:05:08,760 --> 00:05:13,349
means<font color="#CCCCCC"> bgp is choosing the right node</font>

111
00:05:10,800 --> 00:05:15,720
greater than 1 means bgp is making a

112
00:05:13,350 --> 00:05:18,300
mistake and<font color="#E5E5E5"> that's the factor of the</font><font color="#CCCCCC"> rtt</font>

113
00:05:15,720 --> 00:05:20,580
we get so<font color="#E5E5E5"> for example 2 means that our</font>

114
00:05:18,300 --> 00:05:23,100
<font color="#CCCCCC">RTT is double what we would have if bgp</font>

115
00:05:20,580 --> 00:05:27,240
picked the right node and lower than one

116
00:05:23,100 --> 00:05:28,590
and also marked with these<font color="#CCCCCC"> i don't know</font>

117
00:05:27,240 --> 00:05:33,600
if you can<font color="#E5E5E5"> see them these circles are</font>

118
00:05:28,590 --> 00:05:37,619
the values for<font color="#E5E5E5"> local nodes test boxes</font>

119
00:05:33,600 --> 00:05:40,169
that see local<font color="#E5E5E5"> nodes so if we exclude</font>

120
00:05:37,620 --> 00:05:42,390
the local nodes which are for the most

121
00:05:40,169 --> 00:05:46,530
part less than one except<font color="#CCCCCC"> for a few</font>

122
00:05:42,390 --> 00:05:48,090
cases and we see<font color="#CCCCCC"> that the most of the</font>

123
00:05:46,530 --> 00:05:50,250
values are actually pretty close to one

124
00:05:48,090 --> 00:05:55,729
which means that<font color="#E5E5E5"> for most of our test</font>

125
00:05:50,250 --> 00:05:59,790
boxes the<font color="#CCCCCC"> bgp is doing a pretty good job</font>

126
00:05:55,729 --> 00:06:01,020
so these are graphs which exclude the

127
00:05:59,790 --> 00:06:04,860
effect of local nodes which make it

128
00:06:01,020 --> 00:06:07,320
<font color="#E5E5E5">easier to compare these results the</font>

129
00:06:04,860 --> 00:06:09,330
deployment on the left is the way we had

130
00:06:07,320 --> 00:06:12,320
it in april<font color="#CCCCCC"> two thousand five ie we had</font>

131
00:06:09,330 --> 00:06:15,240
London and Amsterdam and then a few

132
00:06:12,320 --> 00:06:19,620
about<font color="#CCCCCC"> ten or I think 11 local nodes and</font>

133
00:06:15,240 --> 00:06:23,430
in 2006 we had five nodes and as you can

134
00:06:19,620 --> 00:06:24,930
see they mostly look the same most of

135
00:06:23,430 --> 00:06:26,820
the results are clustered around one

136
00:06:24,930 --> 00:06:29,910
which means<font color="#CCCCCC"> the BGP is doing a pretty</font>

137
00:06:26,820 --> 00:06:34,950
good job most of the cases we get the

138
00:06:29,910 --> 00:06:36,890
best performance just<font color="#CCCCCC"> to</font><font color="#E5E5E5"> make sure this</font>

139
00:06:34,950 --> 00:06:39,539
wasn't a chance event that happened

140
00:06:36,890 --> 00:06:40,740
while we were running our measurements

141
00:06:39,539 --> 00:06:45,000
just<font color="#CCCCCC"> to make sure we didn't</font>

142
00:06:40,740 --> 00:06:48,569
lucky we took the average of<font color="#E5E5E5"> that and so</font>

143
00:06:45,000 --> 00:06:51,360
<font color="#E5E5E5">this</font><font color="#CCCCCC"> is the outlier you see here is TT</font>

144
00:06:48,569 --> 00:06:53,639
103 I'll get<font color="#E5E5E5"> to</font><font color="#CCCCCC"> that later I'll</font><font color="#E5E5E5"> explain</font>

145
00:06:51,360 --> 00:06:56,699
later why that is so that value is so

146
00:06:53,639 --> 00:06:59,810
high but when we calculated the average

147
00:06:56,699 --> 00:07:02,810
over time we<font color="#E5E5E5"> excluded this box so we</font>

148
00:06:59,810 --> 00:07:05,130
plotted the average value<font color="#CCCCCC"> of</font><font color="#E5E5E5"> alpha</font>

149
00:07:02,810 --> 00:07:09,330
averaged over all the tests boxes over

150
00:07:05,130 --> 00:07:13,680
time<font color="#E5E5E5"> every hour and the results are</font>

151
00:07:09,330 --> 00:07:15,270
pretty consistent it's the average is a

152
00:07:13,680 --> 00:07:18,180
little bit higher than one and it's

153
00:07:15,270 --> 00:07:20,219
mostly consistent over time so this is

154
00:07:18,180 --> 00:07:27,860
<font color="#CCCCCC">not a chance of X</font><font color="#E5E5E5"> this is seems to be</font>

155
00:07:20,220 --> 00:07:29,970
quite stable so that gives us a

156
00:07:27,860 --> 00:07:33,569
reasonable picture everything<font color="#E5E5E5"> seems to</font>

157
00:07:29,970 --> 00:07:35,819
be fine from where we see it however the

158
00:07:33,569 --> 00:07:37,979
the measurements we do on the client

159
00:07:35,819 --> 00:07:40,259
side are biased because the test boxes

160
00:07:37,979 --> 00:07:41,520
are mainly in Europe because we only

161
00:07:40,259 --> 00:07:44,039
have a limited number<font color="#E5E5E5"> of them their</font>

162
00:07:41,520 --> 00:07:46,349
order of 100 so definitely<font color="#CCCCCC"> not the same</font>

163
00:07:44,039 --> 00:07:50,159
order of magnitude as the as the client

164
00:07:46,349 --> 00:07:52,380
population and they obviously don't

165
00:07:50,159 --> 00:07:55,979
necessarily affect the distribution of

166
00:07:52,380 --> 00:07:58,680
clients of<font color="#E5E5E5"> K so what what do we do well</font>

167
00:07:55,979 --> 00:08:03,800
<font color="#CCCCCC">we can do it the other way around we can</font>

168
00:07:58,680 --> 00:08:06,210
ping the clients from the server nodes

169
00:08:03,800 --> 00:08:07,860
doing this we can now we have a much we

170
00:08:06,210 --> 00:08:10,859
<font color="#E5E5E5">can play with</font><font color="#CCCCCC"> a much bigger data set</font>

171
00:08:07,860 --> 00:08:14,159
which is about 1 million 1 million

172
00:08:10,860 --> 00:08:16,530
Clytie p addresses that we used and this

173
00:08:14,159 --> 00:08:20,069
obviously measures the effect on the

174
00:08:16,530 --> 00:08:23,818
actual clients<font color="#CCCCCC"> okay so what do we do we</font>

175
00:08:20,069 --> 00:08:26,639
extract we we keep packet thumps of

176
00:08:23,819 --> 00:08:29,430
queries that go into<font color="#CCCCCC"> K so we process</font>

177
00:08:26,639 --> 00:08:32,520
these packet traces we take out a list

178
00:08:29,430 --> 00:08:35,459
of IP addresses and we from all the

179
00:08:32,520 --> 00:08:37,319
global nodes as<font color="#E5E5E5"> okay of the K any gas</font>

180
00:08:35,458 --> 00:08:39,750
cloud we paying all these addresses and

181
00:08:37,320 --> 00:08:43,500
then for every for every address we

182
00:08:39,750 --> 00:08:49,260
calculate alpha as as<font color="#E5E5E5"> I stated before so</font>

183
00:08:43,500 --> 00:08:52,020
the<font color="#CCCCCC"> rtt to them to the</font><font color="#E5E5E5"> K node / the</font><font color="#CCCCCC"> rtt</font>

184
00:08:49,260 --> 00:08:53,370
to the node in question we took six

185
00:08:52,020 --> 00:08:54,360
hours of data for that six hours of

186
00:08:53,370 --> 00:08:55,920
dumps which

187
00:08:54,360 --> 00:09:00,269
gives us a standard<font color="#CCCCCC"> a million IP</font>

188
00:08:55,920 --> 00:09:04,319
addresses 246 million queries and this

189
00:09:00,269 --> 00:09:08,970
is what<font color="#E5E5E5"> comes out so basically fifty</font>

190
00:09:04,320 --> 00:09:11,459
percent of the fifty percent of client

191
00:09:08,970 --> 00:09:14,760
IP addresses are actually hitting the

192
00:09:11,459 --> 00:09:17,268
node with the best performance the rest

193
00:09:14,760 --> 00:09:23,370
are seeing varying performance penalties

194
00:09:17,269 --> 00:09:26,190
with about ten percent having hefty

195
00:09:23,370 --> 00:09:29,010
performance losses well for four times

196
00:09:26,190 --> 00:09:30,660
slower but most of our clients are doing

197
00:09:29,010 --> 00:09:34,260
<font color="#CCCCCC">pretty well the results are not as good</font>

198
00:09:30,660 --> 00:09:35,760
as unseen by TTM<font color="#CCCCCC"> TT MC is very good very</font>

199
00:09:34,260 --> 00:09:37,920
good performance<font color="#E5E5E5"> and</font><font color="#CCCCCC"> that is probably</font>

200
00:09:35,760 --> 00:09:39,959
because<font color="#E5E5E5"> most of the TTM boxes are</font>

201
00:09:37,920 --> 00:09:41,729
concentrated in<font color="#CCCCCC"> Europe which is very</font>

202
00:09:39,959 --> 00:09:48,709
well provisioned by K which has two

203
00:09:41,730 --> 00:09:51,149
nodes in Europe to global node so<font color="#CCCCCC"> ya</font>

204
00:09:48,709 --> 00:09:53,130
seen<font color="#E5E5E5"> from TTM things are</font><font color="#CCCCCC"> very good and</font>

205
00:09:51,149 --> 00:09:55,440
it doesn't<font color="#E5E5E5"> seem to depend on the</font>

206
00:09:53,130 --> 00:09:57,540
<font color="#E5E5E5">deployment we had when we moved from two</font>

207
00:09:55,440 --> 00:09:59,970
nodes last year to five nodes this year

208
00:09:57,540 --> 00:10:01,349
it doesn't<font color="#CCCCCC"> seem to make a difference bgp</font>

209
00:09:59,970 --> 00:10:04,290
still seems to<font color="#E5E5E5"> be able to discriminate</font>

210
00:10:01,350 --> 00:10:09,959
if we look at the total k client

211
00:10:04,290 --> 00:10:11,910
population things are not so rosy so

212
00:10:09,959 --> 00:10:14,550
another question we looked at was how

213
00:10:11,910 --> 00:10:17,279
many<font color="#E5E5E5"> nodes are enough does it make sense</font>

214
00:10:14,550 --> 00:10:19,519
for us to deploy more nodes or have we

215
00:10:17,279 --> 00:10:21,990
reached the point of diminishing returns

216
00:10:19,519 --> 00:10:25,350
to answer that question<font color="#E5E5E5"> what we can do</font>

217
00:10:21,990 --> 00:10:27,600
is well the first step we can<font color="#E5E5E5"> do is</font>

218
00:10:25,350 --> 00:10:30,209
evaluate the benefit of existing senses

219
00:10:27,600 --> 00:10:32,459
and this will hopefully tell us at which

220
00:10:30,209 --> 00:10:34,920
point of the curve we're on and tell us

221
00:10:32,459 --> 00:10:39,569
if it makes sense to deploy more nodes

222
00:10:34,920 --> 00:10:42,120
or not so how do we<font color="#E5E5E5"> measure what Bennett</font>

223
00:10:39,570 --> 00:10:44,100
what the benefit of an Evernote is well

224
00:10:42,120 --> 00:10:45,690
we can simply quantify how much

225
00:10:44,100 --> 00:10:50,220
performance<font color="#CCCCCC"> would be worse if that</font>

226
00:10:45,690 --> 00:10:53,100
instance didn't exist so if<font color="#E5E5E5"> we assume</font>

227
00:10:50,220 --> 00:10:55,620
<font color="#E5E5E5">optimal instance selection which means</font>

228
00:10:53,100 --> 00:10:58,410
that<font color="#E5E5E5"> every client sees the instance with</font>

229
00:10:55,620 --> 00:11:00,029
the best performance then it's easy

230
00:10:58,410 --> 00:11:05,600
because all<font color="#E5E5E5"> we need to do is take the</font>

231
00:11:00,029 --> 00:11:08,230
numbers we have and do divisions so the

232
00:11:05,600 --> 00:11:10,120
fact that we assume optimal instance

233
00:11:08,230 --> 00:11:12,610
election gives us an upper bound to the

234
00:11:10,120 --> 00:11:13,570
benefit of a<font color="#CCCCCC"> node but</font><font color="#E5E5E5"> this is okay</font>

235
00:11:12,610 --> 00:11:14,980
because we're trying to figure<font color="#CCCCCC"> out</font>

236
00:11:13,570 --> 00:11:18,460
whether we've reached a<font color="#CCCCCC"> point of</font>

237
00:11:14,980 --> 00:11:21,070
diminishing returns on top so for every

238
00:11:18,460 --> 00:11:24,040
client we see how much its performance

239
00:11:21,070 --> 00:11:26,710
would<font color="#CCCCCC"> be worse if a given instance</font>

240
00:11:24,040 --> 00:11:28,270
didn't exist and we have the numbers for

241
00:11:26,710 --> 00:11:34,870
that because we ping all the clients

242
00:11:28,270 --> 00:11:37,449
from all the all the server nodes so for

243
00:11:34,870 --> 00:11:42,040
every client we are assigned a number

244
00:11:37,450 --> 00:11:44,670
beta which is<font color="#E5E5E5"> the loss in performance</font>

245
00:11:42,040 --> 00:11:47,620
that that client would have if a given

246
00:11:44,670 --> 00:11:50,829
if a given server node was knocked out

247
00:11:47,620 --> 00:11:54,940
so<font color="#E5E5E5"> for every client we have a value of</font>

248
00:11:50,830 --> 00:11:58,510
<font color="#E5E5E5">beta for every node so a client might</font>

249
00:11:54,940 --> 00:12:00,850
suffer suppose<font color="#CCCCCC"> a</font><font color="#E5E5E5"> client a client's</font>

250
00:11:58,510 --> 00:12:03,460
performance would get<font color="#CCCCCC"> two times were to</font>

251
00:12:00,850 --> 00:12:05,560
worsen x factor<font color="#CCCCCC"> of</font><font color="#E5E5E5"> two if the</font><font color="#CCCCCC"> Amsterdam</font>

252
00:12:03,460 --> 00:12:07,390
node didn't exist well then in that case

253
00:12:05,560 --> 00:12:12,609
<font color="#E5E5E5">the beta for that client for Amsterdam</font>

254
00:12:07,390 --> 00:12:15,670
is too so then we plot the beta for

255
00:12:12,610 --> 00:12:21,520
every node and this gives us an idea<font color="#CCCCCC"> of</font>

256
00:12:15,670 --> 00:12:23,140
how important that notice so how do we

257
00:12:21,520 --> 00:12:27,040
read this graph this is a graph of links

258
00:12:23,140 --> 00:12:29,920
this tells us that about almost ninety

259
00:12:27,040 --> 00:12:32,640
percent of clients wouldn't see big

260
00:12:29,920 --> 00:12:34,930
performance if links were taken away so

261
00:12:32,640 --> 00:12:36,910
<font color="#CCCCCC">about ten percent would get worse and</font>

262
00:12:34,930 --> 00:12:40,650
the number of clients that<font color="#E5E5E5"> will get</font>

263
00:12:36,910 --> 00:12:40,650
serious seriously worse is very very low

264
00:12:41,250 --> 00:12:48,340
<font color="#CCCCCC">okay this is what the geographical query</font>

265
00:12:44,920 --> 00:12:50,380
distribution the geographical clients

266
00:12:48,340 --> 00:12:52,750
distribution looks like for the links

267
00:12:50,380 --> 00:12:55,270
node will see will for other nodes this

268
00:12:52,750 --> 00:12:57,070
this note is fairly spread out we'll see

269
00:12:55,270 --> 00:12:59,980
<font color="#CCCCCC">for other nodes that's not</font><font color="#E5E5E5"> the case and</font>

270
00:12:57,070 --> 00:13:03,070
we'll<font color="#E5E5E5"> discuss how that impacts the the</font>

271
00:12:59,980 --> 00:13:06,760
Glaus we<font color="#E5E5E5"> see this is the Amsterdam node</font>

272
00:13:03,070 --> 00:13:08,830
similar to London if we if the Amsterdam

273
00:13:06,760 --> 00:13:10,710
node were to be turned off tomorrow<font color="#E5E5E5"> only</font>

274
00:13:08,830 --> 00:13:15,880
about<font color="#E5E5E5"> twenty</font><font color="#CCCCCC"> percent of clients would</font>

275
00:13:10,710 --> 00:13:17,680
suffer<font color="#CCCCCC"> a performance penalty so this is</font>

276
00:13:15,880 --> 00:13:21,610
<font color="#CCCCCC">kind of unexpected because these are the</font>

277
00:13:17,680 --> 00:13:22,180
busiest two nodes and they they do see a

278
00:13:21,610 --> 00:13:24,420
lot of client

279
00:13:22,180 --> 00:13:32,050
and they<font color="#CCCCCC"> are important to the k</font>

280
00:13:24,420 --> 00:13:35,620
deployment however if we if we plot that

281
00:13:32,050 --> 00:13:38,050
if we plot this for both k<font color="#E5E5E5"> at for both</font>

282
00:13:35,620 --> 00:13:40,450
m6 and links taken together ie if

283
00:13:38,050 --> 00:13:42,130
neither of those two two nodes existed

284
00:13:40,450 --> 00:13:44,800
then we would get substantial

285
00:13:42,130 --> 00:13:47,170
performance penalties about sixty-five

286
00:13:44,800 --> 00:13:49,930
percent of the note of<font color="#E5E5E5"> the clients</font>

287
00:13:47,170 --> 00:13:51,250
wouldn't wouldn't be affected but most

288
00:13:49,930 --> 00:13:53,560
of the others would see substantial

289
00:13:51,250 --> 00:13:55,899
performance hit about twenty percent

290
00:13:53,560 --> 00:13:58,029
<font color="#E5E5E5">would would get four times worse about</font>

291
00:13:55,899 --> 00:14:01,600
just over ten percent<font color="#E5E5E5"> would get seven</font>

292
00:13:58,029 --> 00:14:03,250
times of us and so and so<font color="#E5E5E5"> on so taken</font>

293
00:14:01,600 --> 00:14:08,220
<font color="#E5E5E5">together the links and am six nodes are</font>

294
00:14:03,250 --> 00:14:11,589
important so these<font color="#CCCCCC"> numbers show us in a</font>

295
00:14:08,220 --> 00:14:13,180
in a fairly solid way that these that

296
00:14:11,589 --> 00:14:15,459
the two nodes<font color="#E5E5E5"> in</font><font color="#CCCCCC"> am Sam in</font><font color="#E5E5E5"> London are</font>

297
00:14:13,180 --> 00:14:19,349
pretty<font color="#E5E5E5"> much redundant to each other but</font>

298
00:14:15,459 --> 00:14:23,410
taken together<font color="#E5E5E5"> they're important tokyo</font>

299
00:14:19,350 --> 00:14:25,779
<font color="#E5E5E5">tokyo is the best node for very few</font>

300
00:14:23,410 --> 00:14:27,939
clients but those clients that<font color="#E5E5E5"> it does</font>

301
00:14:25,779 --> 00:14:30,100
have tend to be very badly served by

302
00:14:27,940 --> 00:14:31,930
other nodes so there's about the ten

303
00:14:30,100 --> 00:14:35,290
percent of clients which would get very

304
00:14:31,930 --> 00:14:39,969
very<font color="#E5E5E5"> very badly worse if</font><font color="#CCCCCC"> Tokyo didn't</font>

305
00:14:35,290 --> 00:14:42,490
exist so it does provide a benefit these

306
00:14:39,970 --> 00:14:48,400
clients are mostly as<font color="#E5E5E5"> you can see in in</font>

307
00:14:42,490 --> 00:14:50,410
<font color="#E5E5E5">Japan and in Asia obviously which is an</font>

308
00:14:48,400 --> 00:14:53,800
area which we serve only was with Tokyo

309
00:14:50,410 --> 00:14:58,150
<font color="#E5E5E5">not the node in Miami we have at</font><font color="#CCCCCC"> nap of</font>

310
00:14:53,800 --> 00:15:00,040
the<font color="#E5E5E5"> Americas has provides moderate but</font><font color="#CCCCCC"> a</font>

311
00:14:58,150 --> 00:15:02,230
<font color="#E5E5E5">moderate benefit for some clients it</font>

312
00:15:00,040 --> 00:15:05,529
does a lot of it handles a lot of

313
00:15:02,230 --> 00:15:08,740
traffic in in the US and in the South

314
00:15:05,529 --> 00:15:10,570
America so these clients would be very

315
00:15:08,740 --> 00:15:15,190
badly served if they were<font color="#E5E5E5"> to go to</font>

316
00:15:10,570 --> 00:15:18,579
Europe or to Tokyo for instance<font color="#E5E5E5"> the</font>

317
00:15:15,190 --> 00:15:21,250
Delhi node is not particularly effective

318
00:15:18,579 --> 00:15:25,569
it turns out most of our clients would

319
00:15:21,250 --> 00:15:28,029
be better served by somebody else so

320
00:15:25,570 --> 00:15:31,480
this<font color="#CCCCCC"> is</font><font color="#E5E5E5"> the geographic distribution of</font>

321
00:15:28,029 --> 00:15:34,589
clients not many not much to see here so

322
00:15:31,480 --> 00:15:36,130
once we have these numbers we can try to

323
00:15:34,589 --> 00:15:38,890
condense the graph

324
00:15:36,130 --> 00:15:40,810
into one number so that we<font color="#E5E5E5"> can</font><font color="#CCCCCC"> have an</font>

325
00:15:38,890 --> 00:15:42,189
idea of how effective a node really is

326
00:15:40,810 --> 00:15:45,069
we can try to<font color="#E5E5E5"> put a number on the</font>

327
00:15:42,190 --> 00:15:46,960
effectiveness of one particular node how

328
00:15:45,070 --> 00:15:48,520
do<font color="#E5E5E5"> we do that well we take the beta</font>

329
00:15:46,960 --> 00:15:50,440
values for<font color="#E5E5E5"> all the clients of a given</font>

330
00:15:48,520 --> 00:15:52,360
load and we take the weighted average

331
00:15:50,440 --> 00:15:55,780
where the weights of the number<font color="#E5E5E5"> of</font>

332
00:15:52,360 --> 00:15:59,830
queries<font color="#E5E5E5"> of that client sees that the</font>

333
00:15:55,780 --> 00:16:04,900
client<font color="#CCCCCC"> sensory and so simple weighted</font>

334
00:15:59,830 --> 00:16:07,510
average and what comes out is so what do

335
00:16:04,900 --> 00:16:10,630
we<font color="#CCCCCC"> expect if the value of the benefit</font>

336
00:16:07,510 --> 00:16:14,319
value of<font color="#E5E5E5"> b is</font><font color="#CCCCCC"> 1 then that</font><font color="#E5E5E5"> node basically</font>

337
00:16:10,630 --> 00:16:15,910
<font color="#E5E5E5">doesn't provide any benefit at all since</font>

338
00:16:14,320 --> 00:16:20,980
it's a weighted average<font color="#CCCCCC"> of beta and beta</font>

339
00:16:15,910 --> 00:16:24,270
is equal to one if the if the node

340
00:16:20,980 --> 00:16:29,050
doesn't provide any benefit at all and

341
00:16:24,270 --> 00:16:32,980
so if we<font color="#CCCCCC"> look at it the Europe</font><font color="#E5E5E5"> ie links</font>

342
00:16:29,050 --> 00:16:35,530
and<font color="#E5E5E5"> antics taken together are the most</font>

343
00:16:32,980 --> 00:16:37,810
important factor if so would if those

344
00:16:35,530 --> 00:16:41,709
were<font color="#CCCCCC"> taken away performance would suffer</font>

345
00:16:37,810 --> 00:16:43,180
very very badly Tokyo is also pretty

346
00:16:41,710 --> 00:16:46,930
important because the clients it does

347
00:16:43,180 --> 00:16:52,540
serve tend to be very badly served by

348
00:16:46,930 --> 00:16:54,819
other nodes and the<font color="#E5E5E5"> Miami node is not so</font>

349
00:16:52,540 --> 00:16:56,740
effective because the performance impact

350
00:16:54,820 --> 00:16:58,510
of taking it away would only mean that

351
00:16:56,740 --> 00:17:02,170
clients get to go to Europe or Tokyo

352
00:16:58,510 --> 00:17:05,709
which whichever is closer which<font color="#CCCCCC"> is not a</font>

353
00:17:02,170 --> 00:17:11,470
big deal and the Delhi node is pretty

354
00:17:05,709 --> 00:17:16,589
much no not very<font color="#E5E5E5"> useful so wrapping that</font>

355
00:17:11,470 --> 00:17:19,510
up so did it make sense to do any cost

356
00:17:16,589 --> 00:17:22,480
well what we can do is we knock out

357
00:17:19,510 --> 00:17:25,030
everything except for links in 1997 we

358
00:17:22,480 --> 00:17:29,620
only had the links node until the am six

359
00:17:25,030 --> 00:17:33,399
node was deployed so the dark red or

360
00:17:29,620 --> 00:17:35,439
brown curve here shows that ten percent

361
00:17:33,400 --> 00:17:37,840
of clients are<font color="#CCCCCC"> the best wouldn't</font>

362
00:17:35,440 --> 00:17:39,190
wouldn't notice and about eighty-five

363
00:17:37,840 --> 00:17:43,360
percent of clients would get worse and

364
00:17:39,190 --> 00:17:45,160
the benefit value is 18.8 so it does

365
00:17:43,360 --> 00:17:47,709
work any<font color="#E5E5E5"> cast does work for</font><font color="#CCCCCC"> us and it</font>

366
00:17:45,160 --> 00:17:49,980
has brought a substantial performance

367
00:17:47,710 --> 00:17:55,740
improve

368
00:17:49,980 --> 00:17:59,500
so a few words on<font color="#CCCCCC"> Const ability</font>

369
00:17:55,740 --> 00:18:02,020
obviously the more nodes we deploy the

370
00:17:59,500 --> 00:18:05,380
more roots compete in BGP and the more

371
00:18:02,020 --> 00:18:08,139
churn and obviously if we have<font color="#E5E5E5"> tcp DNS</font>

372
00:18:05,380 --> 00:18:11,080
queries or if we<font color="#CCCCCC"> have per packet load</font>

373
00:18:08,140 --> 00:18:12,880
balancing and UDP fragments then that

374
00:18:11,080 --> 00:18:15,250
might be a problem if I know it's best

375
00:18:12,880 --> 00:18:17,140
if a client's best no changes while the

376
00:18:15,250 --> 00:18:22,510
query is being done in<font color="#E5E5E5"> that case</font><font color="#CCCCCC"> the</font>

377
00:18:17,140 --> 00:18:24,130
query fails so we try to<font color="#CCCCCC"> get</font><font color="#E5E5E5"> a evaluate</font>

378
00:18:22,510 --> 00:18:26,020
the impact<font color="#E5E5E5"> to this problem by measuring</font>

379
00:18:24,130 --> 00:18:28,780
at the server nodes we looked at the

380
00:18:26,020 --> 00:18:30,610
node switches that actually occurred so

381
00:18:28,780 --> 00:18:34,600
we basically take the packet dumps from

382
00:18:30,610 --> 00:18:36,760
all the global nodes at the time<font color="#E5E5E5"> there</font>

383
00:18:34,600 --> 00:18:38,709
<font color="#E5E5E5">only to global nodes yes actually we did</font>

384
00:18:36,760 --> 00:18:41,350
them on five as well we extracted<font color="#E5E5E5"> all</font>

385
00:18:38,710 --> 00:18:43,210
DNS traffic and for each IP address we

386
00:18:41,350 --> 00:18:45,639
remembered where<font color="#E5E5E5"> it was last seen and if</font>

387
00:18:43,210 --> 00:18:49,030
it then is seen at another node then we

388
00:18:45,640 --> 00:18:51,430
log a switch the K nodes are only ntp

389
00:18:49,030 --> 00:18:54,940
synchronized which should be<font color="#CCCCCC"> enough to</font>

390
00:18:51,430 --> 00:18:59,260
<font color="#E5E5E5">catch most synchronization problems but</font>

391
00:18:54,940 --> 00:19:05,530
they are not<font color="#E5E5E5"> microsecond synchronized so</font>

392
00:18:59,260 --> 00:19:09,390
these<font color="#E5E5E5"> are the</font><font color="#CCCCCC"> results the the important</font>

393
00:19:05,530 --> 00:19:12,820
numbers here basically are these ones

394
00:19:09,390 --> 00:19:17,230
the fact that in in five<font color="#E5E5E5"> hours of data</font>

395
00:19:12,820 --> 00:19:22,300
we saw only 0.06 percent of queries used

396
00:19:17,230 --> 00:19:23,740
a different note in that for only 0.06

397
00:19:22,300 --> 00:19:25,360
percent of queries the client used a

398
00:19:23,740 --> 00:19:29,710
different node then it had for the

399
00:19:25,360 --> 00:19:31,990
<font color="#CCCCCC">previous query and only about 0.3 three</font>

400
00:19:29,710 --> 00:19:35,110
percent of the client IPS actually

401
00:19:31,990 --> 00:19:40,270
switched once or more so this is

402
00:19:35,110 --> 00:19:41,949
increased significantly from the two no

403
00:19:40,270 --> 00:19:44,350
diff from the two no data that we have

404
00:19:41,950 --> 00:19:46,360
<font color="#E5E5E5">one year ago but the results aren't</font>

405
00:19:44,350 --> 00:19:48,490
<font color="#E5E5E5">directly comparable because they are</font>

406
00:19:46,360 --> 00:19:50,649
taking on different time scales and<font color="#CCCCCC"> they</font>

407
00:19:48,490 --> 00:19:54,400
<font color="#CCCCCC">are</font><font color="#E5E5E5"> still very low so we</font><font color="#CCCCCC"> don't see a</font>

408
00:19:50,650 --> 00:19:56,980
serious problem with with instant

409
00:19:54,400 --> 00:20:01,739
switches at least in our deployment it's

410
00:19:56,980 --> 00:20:04,059
not doesn't seem to be a big problem so

411
00:20:01,739 --> 00:20:11,739
couple words on the routing issues we

412
00:20:04,059 --> 00:20:15,039
faced so we saw basically a couple of

413
00:20:11,739 --> 00:20:18,970
problems<font color="#E5E5E5"> that can lead to performance</font>

414
00:20:15,039 --> 00:20:20,289
problems prepending different prepending

415
00:20:18,970 --> 00:20:24,190
values<font color="#E5E5E5"> announced from different nodes</font>

416
00:20:20,289 --> 00:20:26,619
and no export causing various various

417
00:20:24,190 --> 00:20:28,899
kinds<font color="#E5E5E5"> of trouble both loss of reach</font>

418
00:20:26,619 --> 00:20:33,369
ability if it is honored and also bad

419
00:20:28,899 --> 00:20:37,869
performance if it's not so as I said<font color="#E5E5E5"> the</font>

420
00:20:33,369 --> 00:20:42,009
this is<font color="#E5E5E5"> the data from April 2000-2006</font>

421
00:20:37,869 --> 00:20:43,570
the outlier is TT 1 or 3 it doesn't

422
00:20:42,009 --> 00:20:47,080
<font color="#E5E5E5">actually have a value of 10 it has a</font>

423
00:20:43,570 --> 00:20:52,029
value of 200 because the graph is the

424
00:20:47,080 --> 00:20:56,199
<font color="#E5E5E5">axis is cut so what happened there so TT</font>

425
00:20:52,029 --> 00:20:58,350
103 is in is in<font color="#E5E5E5"> Yokohama and the</font><font color="#CCCCCC"> Tokyo</font>

426
00:20:56,200 --> 00:21:01,929
node is only about<font color="#CCCCCC"> 2 milliseconds away</font>

427
00:20:58,350 --> 00:21:04,928
but the query goes to Delhi through

428
00:21:01,929 --> 00:21:07,149
Tokyo Los Angeles and Hong Kong and it

429
00:21:04,929 --> 00:21:09,519
gets served by the Delhi node which

430
00:21:07,149 --> 00:21:11,139
results in a round trip time of 460

431
00:21:09,519 --> 00:21:15,929
milliseconds instead of 2 and<font color="#E5E5E5"> therefore</font>

432
00:21:11,139 --> 00:21:19,059
a value of 208 so what is the problem

433
00:21:15,929 --> 00:21:22,169
<font color="#E5E5E5">thanks again to Randy</font><font color="#CCCCCC"> bhushan matsuzaki</font>

434
00:21:19,059 --> 00:21:24,549
for giving us the<font color="#CCCCCC"> BGP information here</font>

435
00:21:22,169 --> 00:21:27,159
what happened is that we we're

436
00:21:24,549 --> 00:21:31,090
announcing Tokyo with different with

437
00:21:27,159 --> 00:21:34,330
with forum prepended four times and

438
00:21:31,090 --> 00:21:38,439
Delhi prepended three times and so the

439
00:21:34,330 --> 00:21:42,449
paths<font color="#E5E5E5"> that the best pass was seen by by</font>

440
00:21:38,440 --> 00:21:44,710
TT 103 was the path to the deli node so

441
00:21:42,450 --> 00:21:46,929
this can lead to very<font color="#CCCCCC"> very bad</font>

442
00:21:44,710 --> 00:21:48,639
performance for some clients and that's

443
00:21:46,929 --> 00:21:51,429
something<font color="#E5E5E5"> we need</font><font color="#CCCCCC"> to take into account</font>

444
00:21:48,639 --> 00:21:54,789
in this kind of deployments where we use

445
00:21:51,429 --> 00:22:00,639
prepending to stop global to give an

446
00:21:54,789 --> 00:22:03,820
advantage to local nodes another thing

447
00:22:00,639 --> 00:22:05,979
that can happen with no export is that

448
00:22:03,820 --> 00:22:10,600
it can lead local nodes to be worse than

449
00:22:05,980 --> 00:22:13,480
<font color="#CCCCCC">global notes this</font><font color="#E5E5E5"> is an example that was</font>

450
00:22:10,600 --> 00:22:15,070
since been fixed so we couldn't debug it

451
00:22:13,480 --> 00:22:18,940
much but

452
00:22:15,070 --> 00:22:23,639
basically a TT 89 was seeing a local

453
00:22:18,940 --> 00:22:26,769
node DD<font color="#CCCCCC"> neck node with 30 milliseconds</font>

454
00:22:23,639 --> 00:22:30,939
instead of<font color="#E5E5E5"> going</font><font color="#CCCCCC"> to London why is that</font>

455
00:22:26,769 --> 00:22:33,190
well<font color="#E5E5E5"> because local node announcements if</font>

456
00:22:30,940 --> 00:22:36,490
they know exporters is ignored they they

457
00:22:33,190 --> 00:22:38,740
get announced the customers and since

458
00:22:36,490 --> 00:22:40,000
<font color="#E5E5E5">they are announcements for shorter when</font>

459
00:22:38,740 --> 00:22:43,870
they compete<font color="#CCCCCC"> with the announcement of</font>

460
00:22:40,000 --> 00:22:46,350
the global nodes they win so if no

461
00:22:43,870 --> 00:22:50,529
export is not honored and a s is a large

462
00:22:46,350 --> 00:22:55,090
then it can lead to big performance

463
00:22:50,529 --> 00:22:57,580
problems another thing it can do is lead

464
00:22:55,090 --> 00:23:01,049
to loss of reach ability thanks to Randy

465
00:22:57,580 --> 00:23:01,049
for pushing for pointing this out

466
00:23:01,559 --> 00:23:06,460
basically we use now export to prevent

467
00:23:04,840 --> 00:23:09,279
local node announcements<font color="#E5E5E5"> from leaking to</font>

468
00:23:06,460 --> 00:23:12,460
the<font color="#CCCCCC"> internet</font><font color="#E5E5E5"> and from attracting traffic</font>

469
00:23:09,279 --> 00:23:14,590
from elsewhere but<font color="#E5E5E5"> if we have an S whose</font>

470
00:23:12,460 --> 00:23:17,470
providers all pier with with a local

471
00:23:14,590 --> 00:23:19,299
node and who all on a no export then

472
00:23:17,470 --> 00:23:21,309
these providers will be forbidden from

473
00:23:19,299 --> 00:23:24,340
announcing the route to K so that<font color="#CCCCCC"> click</font>

474
00:23:21,309 --> 00:23:28,690
<font color="#E5E5E5">to that a s so that a s would see no</font>

475
00:23:24,340 --> 00:23:31,449
root<font color="#E5E5E5"> K at all so um it wouldn't be able</font>

476
00:23:28,690 --> 00:23:33,899
<font color="#E5E5E5">to reach the kettle so we what we do</font>

477
00:23:31,450 --> 00:23:36,009
here is we<font color="#CCCCCC"> announce a less specific and</font>

478
00:23:33,899 --> 00:23:38,049
from one of the nodes it doesn't matter

479
00:23:36,009 --> 00:23:41,649
<font color="#E5E5E5">which one we announced and less specific</font>

480
00:23:38,049 --> 00:23:45,639
prefix and if the service prefix the /

481
00:23:41,649 --> 00:23:49,539
24 which which is<font color="#CCCCCC"> the</font><font color="#E5E5E5"> K network is not</font>

482
00:23:45,639 --> 00:23:51,879
announcing due to no export then the

483
00:23:49,539 --> 00:23:54,370
customer will see the / 23 the less

484
00:23:51,879 --> 00:23:56,918
specific and this does not affect

485
00:23:54,370 --> 00:23:59,889
routing in any way because what happens

486
00:23:56,919 --> 00:24:01,539
is once the packet reaches one of the up

487
00:23:59,889 --> 00:24:03,969
streams<font color="#CCCCCC"> its rooted according to</font><font color="#E5E5E5"> the</font>

488
00:24:01,539 --> 00:24:05,440
upstream routing policies<font color="#E5E5E5"> ie according</font>

489
00:24:03,970 --> 00:24:10,299
to<font color="#E5E5E5"> their best route and therefore it</font>

490
00:24:05,440 --> 00:24:14,889
goes<font color="#CCCCCC"> to one</font><font color="#E5E5E5"> of the local nodes so this</font>

491
00:24:10,299 --> 00:24:17,049
<font color="#E5E5E5">is more or less how it works if the</font>

492
00:24:14,889 --> 00:24:20,289
custom in the bottom left appears with

493
00:24:17,049 --> 00:24:23,620
two isps who both have the roots look

494
00:24:20,289 --> 00:24:25,850
like with no export and those Reuters

495
00:24:23,620 --> 00:24:27,918
have a best path<font color="#CCCCCC"> to the low</font>

496
00:24:25,850 --> 00:24:32,030
load and they can't announce it because

497
00:24:27,919 --> 00:24:35,450
they<font color="#E5E5E5"> on a no export so the customers no</font>

498
00:24:32,030 --> 00:24:37,789
root and therefore we in if<font color="#E5E5E5"> we</font><font color="#CCCCCC"> announce</font>

499
00:24:35,450 --> 00:24:39,530
the aggregate then the packets from the

500
00:24:37,789 --> 00:24:40,730
customer to can reach the upstream

501
00:24:39,530 --> 00:24:43,220
because the customer does have a route

502
00:24:40,730 --> 00:24:45,890
to the<font color="#CCCCCC"> k IP address and once it's there</font>

503
00:24:43,220 --> 00:24:52,299
it will get routed to the ler to the

504
00:24:45,890 --> 00:24:52,299
local<font color="#CCCCCC"> node that</font><font color="#E5E5E5"> that is</font><font color="#CCCCCC"> P is chosen so</font>

505
00:24:52,570 --> 00:24:58,990
that's it if there<font color="#E5E5E5"> are any questions I'm</font>

506
00:24:56,240 --> 00:24:58,990
happy to take them

507
00:25:08,950 --> 00:25:15,290
<font color="#CCCCCC">mark Oscars fair</font><font color="#E5E5E5"> sign I did a similar</font>

508
00:25:12,530 --> 00:25:17,210
sort of study on this about two and a

509
00:25:15,290 --> 00:25:19,490
half years ago<font color="#E5E5E5"> yeah i saw a much higher</font>

510
00:25:17,210 --> 00:25:21,140
sort of switching rates<font color="#CCCCCC"> i was wondering</font>

511
00:25:19,490 --> 00:25:25,610
<font color="#CCCCCC">if</font><font color="#E5E5E5"> you could define what switching</font>

512
00:25:21,140 --> 00:25:27,980
really means if you ping pong between

513
00:25:25,610 --> 00:25:30,320
two different sites that once which we

514
00:25:27,980 --> 00:25:32,150
define a switch as an IP address that

515
00:25:30,320 --> 00:25:34,310
seen as a client of one node at one

516
00:25:32,150 --> 00:25:37,160
point in time and then is seen as a

517
00:25:34,310 --> 00:25:39,470
client of another node subsequently that

518
00:25:37,160 --> 00:25:41,450
is a switch<font color="#CCCCCC"> okay but if it ping pongs is</font>

519
00:25:39,470 --> 00:25:44,090
that still one switch it goes back and

520
00:25:41,450 --> 00:25:49,640
forth<font color="#CCCCCC"> no that's tip s2</font><font color="#E5E5E5"> okay that's</font><font color="#CCCCCC"> two</font>

521
00:25:44,090 --> 00:25:52,750
<font color="#CCCCCC">okay interesting again this probably</font>

522
00:25:49,640 --> 00:25:52,750
depends on deployment a lot

