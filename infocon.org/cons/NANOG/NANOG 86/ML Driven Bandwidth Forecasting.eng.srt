1
00:00:00,000 --> 00:00:00,060
[Music]

2
00:00:00,060 --> 00:00:02,210
foreign

3
00:00:02,210 --> 00:00:05,100
[Music]

4
00:00:05,100 --> 00:00:07,859
this is Ben Carter he is a staff

5
00:00:07,859 --> 00:00:10,139
software engineer at Juniper

6
00:00:10,139 --> 00:00:11,820
and has traveled to us today from

7
00:00:11,820 --> 00:00:13,920
Sunnyvale California

8
00:00:13,920 --> 00:00:16,980
this is vincardo's first time presenting

9
00:00:16,980 --> 00:00:18,900
at nanog and it's a pleasure to have him

10
00:00:18,900 --> 00:00:23,119
here speaking with us today welcome

11
00:00:30,000 --> 00:00:33,300
thank you for that introduction and it

12
00:00:33,300 --> 00:00:34,860
is my first time at nanak and I'm very

13
00:00:34,860 --> 00:00:36,420
excited to be here

14
00:00:36,420 --> 00:00:38,399
uh before I begin I would like to thank

15
00:00:38,399 --> 00:00:41,160
my fellow collaborators uh Colby Barth

16
00:00:41,160 --> 00:00:43,500
uh Krishna karthika Raju and Vishnu

17
00:00:43,500 --> 00:00:44,760
Pawan biram

18
00:00:44,760 --> 00:00:46,920
I would also like to thank rajat sethia

19
00:00:46,920 --> 00:00:50,340
and my shepherd Steve cloth for their

20
00:00:50,340 --> 00:00:52,500
guidance

21
00:00:52,500 --> 00:00:53,460
um

22
00:00:53,460 --> 00:00:54,660
so

23
00:00:54,660 --> 00:00:56,280
let me give you a brief introduction

24
00:00:56,280 --> 00:00:58,440
into the topic and then take a deep dive

25
00:00:58,440 --> 00:01:00,719
into it

26
00:01:00,719 --> 00:01:03,120
so we are living there of 5G and we are

27
00:01:03,120 --> 00:01:05,159
surrounded by numerous services and

28
00:01:05,159 --> 00:01:06,299
applications

29
00:01:06,299 --> 00:01:08,520
these Services demand a vast amount of

30
00:01:08,520 --> 00:01:11,760
bandwidth and accuracy accurately

31
00:01:11,760 --> 00:01:13,200
assessing these bandwidth requirements

32
00:01:13,200 --> 00:01:16,260
has become a challenge for uh all the

33
00:01:16,260 --> 00:01:17,939
network operators

34
00:01:17,939 --> 00:01:20,119
so

35
00:01:20,119 --> 00:01:21,680
uh

36
00:01:21,680 --> 00:01:25,159
bandwidth management is

37
00:01:25,159 --> 00:01:28,740
a credit score involves monitoring the

38
00:01:28,740 --> 00:01:31,680
bandwidth throughout the day week month

39
00:01:31,680 --> 00:01:33,600
or the year

40
00:01:33,600 --> 00:01:36,619
and uh

41
00:01:36,619 --> 00:01:39,659
it it it helps not a Carpenters plan

42
00:01:39,659 --> 00:01:43,079
their plan design the network for

43
00:01:43,079 --> 00:01:45,780
Optimal Performance and growth

44
00:01:45,780 --> 00:01:48,180
uh one of the most well-known solutions

45
00:01:48,180 --> 00:01:49,860
for bandwidth Management in the traffic

46
00:01:49,860 --> 00:01:53,159
engineering space is auto bandwidth so

47
00:01:53,159 --> 00:01:56,540
what is auto bandwidth

48
00:01:58,439 --> 00:02:01,439
so on every networking device there's a

49
00:02:01,439 --> 00:02:03,180
certain routing process that collects

50
00:02:03,180 --> 00:02:05,640
traffic statistics corresponding to all

51
00:02:05,640 --> 00:02:06,899
the tunnels

52
00:02:06,899 --> 00:02:08,399
and auto bandwidth solution

53
00:02:08,399 --> 00:02:10,220
automatically adjusts the bandwidth

54
00:02:10,220 --> 00:02:12,599
allocation based on the volume of

55
00:02:12,599 --> 00:02:13,680
traffic that's flowing through these

56
00:02:13,680 --> 00:02:15,720
tunnels in real time

57
00:02:15,720 --> 00:02:18,599
now let me get further into the details

58
00:02:18,599 --> 00:02:21,540
the what the when so what bandwidth to

59
00:02:21,540 --> 00:02:24,060
adjust to so the auto bandwidth solution

60
00:02:24,060 --> 00:02:27,060
uses a computation uh that we call Max

61
00:02:27,060 --> 00:02:28,680
maximum average

62
00:02:28,680 --> 00:02:31,020
which is computed as the maximum of the

63
00:02:31,020 --> 00:02:33,480
sample byte rates from the previous uh

64
00:02:33,480 --> 00:02:35,580
previous interval

65
00:02:35,580 --> 00:02:37,980
the next logical question that comes is

66
00:02:37,980 --> 00:02:40,500
when when do we adjust such a bandwidth

67
00:02:40,500 --> 00:02:42,840
now this is determined by something that

68
00:02:42,840 --> 00:02:46,620
that is termed as adjustment interval

69
00:02:46,620 --> 00:02:47,459
um

70
00:02:47,459 --> 00:02:51,180
and the automated solution adjusts the

71
00:02:51,180 --> 00:02:52,860
bandwidth periodically after at the end

72
00:02:52,860 --> 00:02:54,599
of every adjustment

73
00:02:54,599 --> 00:02:58,019
now unless uh overflow or underflow are

74
00:02:58,019 --> 00:02:59,580
provision

75
00:02:59,580 --> 00:03:01,920
so what is Overflow around the floor

76
00:03:01,920 --> 00:03:05,580
so if the sample bandwidth exceeds the

77
00:03:05,580 --> 00:03:07,379
current bandwidth on the tunnel

78
00:03:07,379 --> 00:03:09,300
by a certain threshold a certain number

79
00:03:09,300 --> 00:03:12,000
of times it is deemed to be an overflow

80
00:03:12,000 --> 00:03:13,920
and if it falls below the current

81
00:03:13,920 --> 00:03:15,840
bandwidth because by a certain threshold

82
00:03:15,840 --> 00:03:17,220
a certain number of times it is deemed

83
00:03:17,220 --> 00:03:21,540
to be an underflow and when underfloor

84
00:03:21,540 --> 00:03:25,379
overlocker the bandwidth the adjustment

85
00:03:25,379 --> 00:03:27,180
interval is preempted and bandwidth is

86
00:03:27,180 --> 00:03:29,220
adjusted on the LSPs

87
00:03:29,220 --> 00:03:33,060
now uh in in a regular scenario once the

88
00:03:33,060 --> 00:03:35,819
adjustment uh interval expires

89
00:03:35,819 --> 00:03:39,420
the bandwidth is adjusted if if the

90
00:03:39,420 --> 00:03:41,879
computed bandwidth exceeds the current

91
00:03:41,879 --> 00:03:43,620
bandwidth by a certain threshold also

92
00:03:43,620 --> 00:03:45,540
known as adjustment threshold

93
00:03:45,540 --> 00:03:48,000
and new parts are computed to to check

94
00:03:48,000 --> 00:03:49,980
if resources are available

95
00:03:49,980 --> 00:03:52,500
now if resources are available the the

96
00:03:52,500 --> 00:03:56,299
tunnel is re-signaled and uh

97
00:03:56,299 --> 00:03:58,980
new new tunnel is established with with

98
00:03:58,980 --> 00:04:01,440
the computed bandwidth

99
00:04:01,440 --> 00:04:03,480
now this solution looks looks good in

100
00:04:03,480 --> 00:04:04,860
theory and works well in certain

101
00:04:04,860 --> 00:04:06,780
scenarios

102
00:04:06,780 --> 00:04:07,860
but

103
00:04:07,860 --> 00:04:09,780
there have been some well-documented

104
00:04:09,780 --> 00:04:11,879
struggles with respect to provisioning

105
00:04:11,879 --> 00:04:15,299
uh feature features uh for auto

106
00:04:15,299 --> 00:04:17,760
bandwidth such as overflow underflow and

107
00:04:17,760 --> 00:04:19,978
and migrate of other features that are

108
00:04:19,978 --> 00:04:21,540
provided by vendors

109
00:04:21,540 --> 00:04:26,160
R to uh get get an accurate uh to get an

110
00:04:26,160 --> 00:04:29,160
accurate accurate adjustment bandwidth

111
00:04:29,160 --> 00:04:32,340
uh and uh but tune it in such a way that

112
00:04:32,340 --> 00:04:36,060
uh the solution works works really well

113
00:04:36,060 --> 00:04:38,460
and we have also seen numerous requests

114
00:04:38,460 --> 00:04:39,960
from Network operators to go a bit

115
00:04:39,960 --> 00:04:43,500
faster than uh uh than what what is

116
00:04:43,500 --> 00:04:45,600
supported currently

117
00:04:45,600 --> 00:04:47,460
which this is not possible with the

118
00:04:47,460 --> 00:04:49,560
current Auto bandwidth solution

119
00:04:49,560 --> 00:04:52,680
oh partly because the current automatic

120
00:04:52,680 --> 00:04:54,960
solution is is reactive in nature

121
00:04:54,960 --> 00:04:57,660
if you look at the plot on to the right

122
00:04:57,660 --> 00:05:00,120
we see that the auto bandwidth solution

123
00:05:00,120 --> 00:05:02,759
user using the max average computation

124
00:05:02,759 --> 00:05:06,180
adjust the bandwidth from the max using

125
00:05:06,180 --> 00:05:07,500
the maximum of the previous adjustment

126
00:05:07,500 --> 00:05:10,680
rule uh for the next adjustment interval

127
00:05:10,680 --> 00:05:16,460
which which causes a certain uh

128
00:05:16,500 --> 00:05:19,620
certain inconsistencies and using using

129
00:05:19,620 --> 00:05:21,300
the network resources

130
00:05:21,300 --> 00:05:25,259
so and there are many many

131
00:05:25,259 --> 00:05:26,639
interdependent knobs as I mentioned

132
00:05:26,639 --> 00:05:30,000
earlier uh to get this to get the to get

133
00:05:30,000 --> 00:05:31,320
the current outer bandwidth solution to

134
00:05:31,320 --> 00:05:34,320
work work accurately

135
00:05:34,320 --> 00:05:35,580
um

136
00:05:35,580 --> 00:05:36,900
with that said

137
00:05:36,900 --> 00:05:38,639
um

138
00:05:38,639 --> 00:05:40,320
this gives us the motivation to come up

139
00:05:40,320 --> 00:05:42,180
with a brand new framework

140
00:05:42,180 --> 00:05:45,000
now we want to proactively predict the

141
00:05:45,000 --> 00:05:47,639
future bandwidth uh using uh by treating

142
00:05:47,639 --> 00:05:49,199
the bandwidth calculation as a Time

143
00:05:49,199 --> 00:05:50,940
series forecasting problem

144
00:05:50,940 --> 00:05:53,639
uh using the trends and patterns and in

145
00:05:53,639 --> 00:05:55,979
the historical bandwidth values

146
00:05:55,979 --> 00:05:59,720
now this this approach uh can help in

147
00:05:59,720 --> 00:06:02,400
allocating the bandwidth faster uh

148
00:06:02,400 --> 00:06:05,220
compared to the current current solution

149
00:06:05,220 --> 00:06:08,460
since we predict the values uh using

150
00:06:08,460 --> 00:06:11,900
using historical traffic trends

151
00:06:12,240 --> 00:06:13,979
we would also like to build a data

152
00:06:13,979 --> 00:06:15,300
driven solution

153
00:06:15,300 --> 00:06:17,820
by leveraging real-time statistics uh

154
00:06:17,820 --> 00:06:20,000
real-time data that are streamed today

155
00:06:20,000 --> 00:06:22,860
at a higher frequency

156
00:06:22,860 --> 00:06:25,919
and this enables uh the machine learning

157
00:06:25,919 --> 00:06:28,500
based solutions to be able to cater to

158
00:06:28,500 --> 00:06:31,740
Shorter historical Windows as well

159
00:06:31,740 --> 00:06:34,440
the other goal that we set out to

160
00:06:34,440 --> 00:06:36,120
achieve was to build a low footprint

161
00:06:36,120 --> 00:06:37,080
approach

162
00:06:37,080 --> 00:06:37,800
um

163
00:06:37,800 --> 00:06:40,699
by reducing the operational overhead and

164
00:06:40,699 --> 00:06:43,259
make sure that we we make minimal

165
00:06:43,259 --> 00:06:44,940
changes to the network to the to the

166
00:06:44,940 --> 00:06:46,680
network design

167
00:06:46,680 --> 00:06:49,319
now we have spoken about treating a

168
00:06:49,319 --> 00:06:50,699
bandwidth calculation as a Time series

169
00:06:50,699 --> 00:06:52,800
forecasting forecasting method

170
00:06:52,800 --> 00:06:55,800
uh time series forecasting is is quite

171
00:06:55,800 --> 00:06:59,460
popular in in a throat or daily lives we

172
00:06:59,460 --> 00:07:01,020
have seen a Time series for forecasting

173
00:07:01,020 --> 00:07:04,020
being used in weather predicting the

174
00:07:04,020 --> 00:07:07,199
weather uh to stock market to retail

175
00:07:07,199 --> 00:07:11,460
sales as well so what is Time series

176
00:07:11,460 --> 00:07:13,800
so a Time series is a series of

177
00:07:13,800 --> 00:07:16,020
observations that are taken at specified

178
00:07:16,020 --> 00:07:19,460
specified times at equal intervals now

179
00:07:19,460 --> 00:07:21,840
it can be used to predict feature values

180
00:07:21,840 --> 00:07:23,819
based on historical traffic Trends using

181
00:07:23,819 --> 00:07:25,440
using some machine learning models or

182
00:07:25,440 --> 00:07:28,620
for the uh time series models

183
00:07:28,620 --> 00:07:31,080
a Time series can be univariated or

184
00:07:31,080 --> 00:07:32,340
multivariate based on the number of

185
00:07:32,340 --> 00:07:35,340
variables that we observe

186
00:07:35,340 --> 00:07:38,099
and a Time series exhibit a lot of

187
00:07:38,099 --> 00:07:40,020
properties a couple of them being

188
00:07:40,020 --> 00:07:42,419
trenched and seasonality that is the

189
00:07:42,419 --> 00:07:44,819
data can exhibit an increasing or

190
00:07:44,819 --> 00:07:46,259
decreasing trend

191
00:07:46,259 --> 00:07:48,120
or not and at all

192
00:07:48,120 --> 00:07:51,479
and the data can repeat itself over a

193
00:07:51,479 --> 00:07:54,120
certain period which which can be

194
00:07:54,120 --> 00:07:57,900
leveraged for time series forecasting

195
00:07:57,900 --> 00:07:59,819
now sometimes it is possible for that

196
00:07:59,819 --> 00:08:01,440
data can exhibit Trend and seasonality

197
00:08:01,440 --> 00:08:03,840
together as well

198
00:08:03,840 --> 00:08:06,240
and since time series forecasting is

199
00:08:06,240 --> 00:08:09,360
popular there have been uh quite a few

200
00:08:09,360 --> 00:08:10,740
number of methods that that are

201
00:08:10,740 --> 00:08:11,880
available today

202
00:08:11,880 --> 00:08:15,180
uh that that exploit patterns in the in

203
00:08:15,180 --> 00:08:17,880
the data to predict future Behavior

204
00:08:17,880 --> 00:08:19,740
there are there are also some regression

205
00:08:19,740 --> 00:08:21,360
based methods as well as deep learning

206
00:08:21,360 --> 00:08:23,879
methods that are available

207
00:08:23,879 --> 00:08:26,220
now with these goals in mind

208
00:08:26,220 --> 00:08:26,940
um

209
00:08:26,940 --> 00:08:28,800
let's look at how the bandwidth

210
00:08:28,800 --> 00:08:31,740
forecasting has evolved

211
00:08:31,740 --> 00:08:34,500
so this this particular framework uh is

212
00:08:34,500 --> 00:08:37,320
uh is can be algorithm agnostic so it we

213
00:08:37,320 --> 00:08:39,240
can leverage any of the machine learning

214
00:08:39,240 --> 00:08:42,979
uh deep learning or statistical methods

215
00:08:42,979 --> 00:08:46,740
and two predict feature values

216
00:08:46,740 --> 00:08:48,899
this this is applicable to any type any

217
00:08:48,899 --> 00:08:52,200
technology any technology area uh and

218
00:08:52,200 --> 00:08:54,060
any type of traffic can leverage this

219
00:08:54,060 --> 00:08:56,700
this this this particular framework

220
00:08:56,700 --> 00:09:00,000
since we treat this since we treat this

221
00:09:00,000 --> 00:09:03,000
problem as a as a data driven solution

222
00:09:03,000 --> 00:09:05,580
um and uh

223
00:09:05,580 --> 00:09:07,620
this particular solution can a framework

224
00:09:07,620 --> 00:09:10,380
can be used to to leverage uh to monitor

225
00:09:10,380 --> 00:09:13,200
the network and uh using using

226
00:09:13,200 --> 00:09:16,019
applications such as health monitoring

227
00:09:16,019 --> 00:09:19,620
and this framework is is lightweight to

228
00:09:19,620 --> 00:09:21,380
be able to deploy anywhere

229
00:09:21,380 --> 00:09:24,000
and with minimal set of configuration

230
00:09:24,000 --> 00:09:26,100
changes to the device using microservice

231
00:09:26,100 --> 00:09:28,560
based architecture

232
00:09:28,560 --> 00:09:31,860
now we have seen the the uh the

233
00:09:31,860 --> 00:09:33,720
particular the overarching application

234
00:09:33,720 --> 00:09:36,000
framework now let's look at the building

235
00:09:36,000 --> 00:09:38,160
blocks of such a framework

236
00:09:38,160 --> 00:09:40,440
now obviously there will be a network

237
00:09:40,440 --> 00:09:42,420
device or a set of network devices that

238
00:09:42,420 --> 00:09:45,600
stream uh Telemetry data or data from uh

239
00:09:45,600 --> 00:09:49,019
data out and there needs to be a

240
00:09:49,019 --> 00:09:51,300
collector that collects this data and

241
00:09:51,300 --> 00:09:54,740
stores that data in a database

242
00:09:54,860 --> 00:09:57,240
there also needs to be a an application

243
00:09:57,240 --> 00:09:58,680
with which which hosts the machine

244
00:09:58,680 --> 00:10:01,620
learning models uh which processes this

245
00:10:01,620 --> 00:10:04,260
data and comes up with a prediction

246
00:10:04,260 --> 00:10:06,300
and there can be an action policy engine

247
00:10:06,300 --> 00:10:08,519
that decides whether uh whether to feed

248
00:10:08,519 --> 00:10:12,000
this pack uh to the device to the device

249
00:10:12,000 --> 00:10:13,560
now all this information can be

250
00:10:13,560 --> 00:10:16,320
visualized and logged for Network

251
00:10:16,320 --> 00:10:18,240
operator use

252
00:10:18,240 --> 00:10:20,700
uh this this particular framework allows

253
00:10:20,700 --> 00:10:23,339
for uh Plato carburetors to run to run

254
00:10:23,339 --> 00:10:26,760
and monitor mode to validate the

255
00:10:26,760 --> 00:10:27,779
performance of the machine learning

256
00:10:27,779 --> 00:10:30,600
models or flip it to active mode to

257
00:10:30,600 --> 00:10:33,300
adjust the bandwidth on the device and

258
00:10:33,300 --> 00:10:35,279
complete the loop

259
00:10:35,279 --> 00:10:39,120
now this framework is is modular nature

260
00:10:39,120 --> 00:10:42,480
so it allows for Plug and Play at all

261
00:10:42,480 --> 00:10:45,120
the all the bidding blocks and of course

262
00:10:45,120 --> 00:10:46,980
you you can we should be in a position

263
00:10:46,980 --> 00:10:48,899
to add any any other building blocks to

264
00:10:48,899 --> 00:10:51,000
this uh to this framework as well

265
00:10:51,000 --> 00:10:53,100
so we'll revisit this framework at the

266
00:10:53,100 --> 00:10:55,380
end to identify a couple of applications

267
00:10:55,380 --> 00:10:59,000
that can leverage this framework

268
00:10:59,100 --> 00:11:00,839
now that we have seen the the building

269
00:11:00,839 --> 00:11:02,820
blocks and the framework for bandwidth

270
00:11:02,820 --> 00:11:05,459
forecasting let's look at the logic uh

271
00:11:05,459 --> 00:11:07,620
that that typical bandwidth forecasting

272
00:11:07,620 --> 00:11:09,360
application can follow

273
00:11:09,360 --> 00:11:11,160
uh to come up with the prediction and

274
00:11:11,160 --> 00:11:14,519
and uh and solve solve the problem

275
00:11:14,519 --> 00:11:16,680
so once the data is collected in the

276
00:11:16,680 --> 00:11:20,579
database this data is fed fed to uh the

277
00:11:20,579 --> 00:11:22,980
machine learning models uh for training

278
00:11:22,980 --> 00:11:25,079
so the models are trained continuously

279
00:11:25,079 --> 00:11:27,120
uh

280
00:11:27,120 --> 00:11:29,459
you have we have the ability to use uh

281
00:11:29,459 --> 00:11:31,440
an ensemble of machine learning models

282
00:11:31,440 --> 00:11:34,200
as well and these models are trained

283
00:11:34,200 --> 00:11:37,740
continuously and it is important to test

284
00:11:37,740 --> 00:11:41,040
if the models are performing well

285
00:11:41,040 --> 00:11:43,500
um so that the models are tested and uh

286
00:11:43,500 --> 00:11:46,980
once uh once we uh at this point if we

287
00:11:46,980 --> 00:11:49,019
have an ensemble of models we can select

288
00:11:49,019 --> 00:11:50,640
the best model that gives us the best

289
00:11:50,640 --> 00:11:51,720
prediction

290
00:11:51,720 --> 00:11:54,180
and use that value to adjust the

291
00:11:54,180 --> 00:11:55,980
bandwidth on the device

292
00:11:55,980 --> 00:11:57,779
so in the example below

293
00:11:57,779 --> 00:12:00,660
we see uh we have used a 300 second

294
00:12:00,660 --> 00:12:02,459
adjustment rule

295
00:12:02,459 --> 00:12:05,339
um and we train the models using using

296
00:12:05,339 --> 00:12:07,620
data from the past to adjustment

297
00:12:07,620 --> 00:12:09,600
controls as well as a chunk of data from

298
00:12:09,600 --> 00:12:11,640
the current adjustment interval

299
00:12:11,640 --> 00:12:14,700
now the the data collection and training

300
00:12:14,700 --> 00:12:17,160
have is happening periodically uh as

301
00:12:17,160 --> 00:12:19,140
throughout the application uh throughout

302
00:12:19,140 --> 00:12:21,899
the application lifecycle

303
00:12:21,899 --> 00:12:23,820
and the models are also tested

304
00:12:23,820 --> 00:12:26,300
continuously

305
00:12:27,660 --> 00:12:29,940
now uh if you if you look at the plot

306
00:12:29,940 --> 00:12:32,040
underneath we we see that the

307
00:12:32,040 --> 00:12:34,500
forecasting models make a prediction uh

308
00:12:34,500 --> 00:12:37,019
uh at the uh at the middle of the

309
00:12:37,019 --> 00:12:39,540
current adjustment interval for the end

310
00:12:39,540 --> 00:12:41,940
of the next adjustment interval that is

311
00:12:41,940 --> 00:12:45,120
um uh they based on the based on the

312
00:12:45,120 --> 00:12:47,820
previous data it it it sees it it

313
00:12:47,820 --> 00:12:50,220
predicts that the bandwidth would be at

314
00:12:50,220 --> 00:12:52,139
the black line at the end of the next

315
00:12:52,139 --> 00:12:55,019
adjustment interval and the models are

316
00:12:55,019 --> 00:12:56,399
continuously tested

317
00:12:56,399 --> 00:12:58,440
um in the in the test period

318
00:12:58,440 --> 00:13:02,160
now if the if something from the example

319
00:13:02,160 --> 00:13:04,079
if 95 percent of the traffic is covered

320
00:13:04,079 --> 00:13:07,860
by uh by the model's prediction and the

321
00:13:07,860 --> 00:13:09,660
predicted value exceeds the adjustment

322
00:13:09,660 --> 00:13:11,700
threshold which is 10 percent

323
00:13:11,700 --> 00:13:14,339
in the example here we select the the

324
00:13:14,339 --> 00:13:16,560
model with with a higher prediction

325
00:13:16,560 --> 00:13:18,959
um to adjust the bandwidth

326
00:13:18,959 --> 00:13:20,880
if none of the machine learning models

327
00:13:20,880 --> 00:13:22,980
cover 95 percent of the other values we

328
00:13:22,980 --> 00:13:24,420
sell we can always fall back to the max

329
00:13:24,420 --> 00:13:26,220
maximum average computation

330
00:13:26,220 --> 00:13:29,279
and as you see uh underneath the maximum

331
00:13:29,279 --> 00:13:32,639
average computation uh happens uh at the

332
00:13:32,639 --> 00:13:34,980
end of every adjustment interval

333
00:13:34,980 --> 00:13:37,500
so it's important to note that the

334
00:13:37,500 --> 00:13:40,019
values in blue are are all configurable

335
00:13:40,019 --> 00:13:42,720
parameters uh it's uh it's up to the

336
00:13:42,720 --> 00:13:45,779
implementation to modify uh modify these

337
00:13:45,779 --> 00:13:48,260
parameters

338
00:13:51,060 --> 00:13:54,480
now one of them one of the properties of

339
00:13:54,480 --> 00:13:56,940
machine learning models is uh are the

340
00:13:56,940 --> 00:13:59,820
forecasting models is they tend to

341
00:13:59,820 --> 00:14:02,639
identify uh uh and if there is a trend

342
00:14:02,639 --> 00:14:04,860
or a pattern in the data

343
00:14:04,860 --> 00:14:07,139
as we see in the in the example here

344
00:14:07,139 --> 00:14:09,540
the machine learning models uh uh the

345
00:14:09,540 --> 00:14:12,300
prediction in the black uh and the

346
00:14:12,300 --> 00:14:14,760
attention of identified that the

347
00:14:14,760 --> 00:14:16,620
bandwidth would be at the at the black

348
00:14:16,620 --> 00:14:18,779
the black level at the end of the next

349
00:14:18,779 --> 00:14:20,279
adjustment interval

350
00:14:20,279 --> 00:14:22,620
but since Max average is a is a

351
00:14:22,620 --> 00:14:24,480
computation that that follows the

352
00:14:24,480 --> 00:14:25,860
maximum from the previous adjustment

353
00:14:25,860 --> 00:14:26,820
interval

354
00:14:26,820 --> 00:14:28,920
it it tends to mess miss the increasing

355
00:14:28,920 --> 00:14:30,240
trend

356
00:14:30,240 --> 00:14:31,800
now

357
00:14:31,800 --> 00:14:34,500
in general machine learning models tend

358
00:14:34,500 --> 00:14:37,620
to recognize uh Trends or patterns and

359
00:14:37,620 --> 00:14:39,600
when Trend Trend or pattern appear

360
00:14:39,600 --> 00:14:41,779
together

361
00:14:43,019 --> 00:14:44,820
now let's let's take a look at the

362
00:14:44,820 --> 00:14:46,380
machine learning based forecasting in

363
00:14:46,380 --> 00:14:47,519
action

364
00:14:47,519 --> 00:14:51,240
now uh since the it's important to track

365
00:14:51,240 --> 00:14:53,100
all the metrics that correspond to

366
00:14:53,100 --> 00:14:54,959
correspond to the correspond to such a

367
00:14:54,959 --> 00:14:57,779
solution such as what data is being

368
00:14:57,779 --> 00:15:01,320
collected the demo the the

369
00:15:01,320 --> 00:15:03,060
time it takes to train the machine

370
00:15:03,060 --> 00:15:06,120
learning models uh what is the what is

371
00:15:06,120 --> 00:15:08,699
the best model and the bandwidth that we

372
00:15:08,699 --> 00:15:12,000
use to to Ser to set our uh the

373
00:15:12,000 --> 00:15:12,959
bandwidth that we have selected

374
00:15:12,959 --> 00:15:15,240
corresponding to the best model as well

375
00:15:15,240 --> 00:15:17,100
as the error corresponding to each each

376
00:15:17,100 --> 00:15:18,839
of the ml models each of the machine

377
00:15:18,839 --> 00:15:20,160
learning models

378
00:15:20,160 --> 00:15:22,920
now all these metrics are tracked can be

379
00:15:22,920 --> 00:15:25,440
can be logged back can be logged in the

380
00:15:25,440 --> 00:15:27,240
file or can be written back to the

381
00:15:27,240 --> 00:15:29,459
database for visualization on the

382
00:15:29,459 --> 00:15:30,420
feature

383
00:15:30,420 --> 00:15:33,300
here we see uh at the bottom we see such

384
00:15:33,300 --> 00:15:34,980
a an example of all the metrics being

385
00:15:34,980 --> 00:15:36,720
tracked

386
00:15:36,720 --> 00:15:39,740
um in a log file

387
00:15:42,000 --> 00:15:44,820
now the most logical question that

388
00:15:44,820 --> 00:15:46,620
everyone would ask is is machine

389
00:15:46,620 --> 00:15:49,139
learning based forecasting better

390
00:15:49,139 --> 00:15:51,300
now based on our experience we have seen

391
00:15:51,300 --> 00:15:53,279
that the machine learning models are

392
00:15:53,279 --> 00:15:55,860
less susceptible to outliers uh than the

393
00:15:55,860 --> 00:15:57,779
max average computation

394
00:15:57,779 --> 00:15:59,100
uh

395
00:15:59,100 --> 00:16:01,220
as we see in the plot on the top left

396
00:16:01,220 --> 00:16:04,800
the maximum average bandwidth

397
00:16:04,800 --> 00:16:07,079
actually adjust the bandwidth for the

398
00:16:07,079 --> 00:16:08,699
next adjustment interval because of a

399
00:16:08,699 --> 00:16:11,160
spike saying because of a single Spike

400
00:16:11,160 --> 00:16:12,480
from the previous adjustment interval

401
00:16:12,480 --> 00:16:14,459
which may lead to inefficient use of the

402
00:16:14,459 --> 00:16:16,380
network resources

403
00:16:16,380 --> 00:16:18,839
and because of the fact that machine

404
00:16:18,839 --> 00:16:21,060
learning models uh are less susceptible

405
00:16:21,060 --> 00:16:22,339
to outliers

406
00:16:22,339 --> 00:16:26,040
the error of of the machine learning

407
00:16:26,040 --> 00:16:28,019
models is significantly lower than the

408
00:16:28,019 --> 00:16:29,760
max average

409
00:16:29,760 --> 00:16:32,519
uh which which which tend to explain

410
00:16:32,519 --> 00:16:34,740
that the machine learning model

411
00:16:34,740 --> 00:16:37,259
prediction is much closer to the actual

412
00:16:37,259 --> 00:16:39,959
actual traffic than than the max average

413
00:16:39,959 --> 00:16:41,759
uh computation

414
00:16:41,759 --> 00:16:45,779
and the the bottom right uh plot shows

415
00:16:45,779 --> 00:16:47,759
the coverage percentage of of all the

416
00:16:47,759 --> 00:16:48,420
traffic

417
00:16:48,420 --> 00:16:50,880
and we see that the machine learning

418
00:16:50,880 --> 00:16:54,240
models tend to cover more or less same

419
00:16:54,240 --> 00:16:56,480
amount of same amount of traffic

420
00:16:56,480 --> 00:16:59,699
compared to the max average uh but with

421
00:16:59,699 --> 00:17:02,040
the with the lower error

422
00:17:02,040 --> 00:17:04,559
now in general uh machine learning

423
00:17:04,559 --> 00:17:07,260
models tend to perform well when uh when

424
00:17:07,260 --> 00:17:11,359
there is patterns in the data

425
00:17:13,020 --> 00:17:15,720
now to summarize we have seen how the

426
00:17:15,720 --> 00:17:18,419
machine learning driven application for

427
00:17:18,419 --> 00:17:20,819
forecasting framework leverages

428
00:17:20,819 --> 00:17:24,900
real-time data uh to enable proactive

429
00:17:24,900 --> 00:17:27,720
bandwidth Fork enable which enables

430
00:17:27,720 --> 00:17:29,780
proactive bandwidth forecasting

431
00:17:29,780 --> 00:17:33,000
by exploiting data from from the from

432
00:17:33,000 --> 00:17:35,520
the historical patterns

433
00:17:35,520 --> 00:17:38,760
and it allows for faster adjustment of

434
00:17:38,760 --> 00:17:40,919
the bandwidth uh which which is one of

435
00:17:40,919 --> 00:17:42,840
the one of the goals that we set out

436
00:17:42,840 --> 00:17:45,240
and since we offload the bandwidth

437
00:17:45,240 --> 00:17:48,120
calculation uh out uh it says some

438
00:17:48,120 --> 00:17:52,039
precious CPU Cycles on on the device

439
00:17:52,320 --> 00:17:54,960
now let's Circle back to the application

440
00:17:54,960 --> 00:17:57,840
framework uh to identify a couple of

441
00:17:57,840 --> 00:18:01,020
applications that uh that that can

442
00:18:01,020 --> 00:18:03,780
Leverage The Leverage the framework

443
00:18:03,780 --> 00:18:05,460
now this is something that we call

444
00:18:05,460 --> 00:18:08,059
real-time insights so

445
00:18:08,059 --> 00:18:10,919
once the data collected from the from

446
00:18:10,919 --> 00:18:13,020
from the device or the devices can is

447
00:18:13,020 --> 00:18:14,460
stored in the database

448
00:18:14,460 --> 00:18:17,220
this can be visualized and real-time

449
00:18:17,220 --> 00:18:19,740
insights can be drawn into into the

450
00:18:19,740 --> 00:18:21,900
traffic Behavior using statistical

451
00:18:21,900 --> 00:18:24,000
methods

452
00:18:24,000 --> 00:18:26,760
um this this actually gives uh the

453
00:18:26,760 --> 00:18:28,520
network operator

454
00:18:28,520 --> 00:18:30,960
this this house as a tool for Network

455
00:18:30,960 --> 00:18:34,799
operator to plan uh for for the future

456
00:18:34,799 --> 00:18:38,039
uh based on uh look based based on the

457
00:18:38,039 --> 00:18:41,660
data that that they've collected already

458
00:18:42,299 --> 00:18:44,580
and this is the and and the second

459
00:18:44,580 --> 00:18:46,020
application that we have identified is

460
00:18:46,020 --> 00:18:47,480
there's something that we call uh

461
00:18:47,480 --> 00:18:49,740
configuration evaluation

462
00:18:49,740 --> 00:18:51,179
now this is something that a network

463
00:18:51,179 --> 00:18:56,460
operator can use uh to uh make changes

464
00:18:56,460 --> 00:18:57,840
to the configuration on on the network

465
00:18:57,840 --> 00:18:58,919
device

466
00:18:58,919 --> 00:19:01,500
and collect the data and have the data

467
00:19:01,500 --> 00:19:03,840
processing pipeline process it and come

468
00:19:03,840 --> 00:19:06,419
up with the come up with a value now

469
00:19:06,419 --> 00:19:07,980
it's up to the network operator to

470
00:19:07,980 --> 00:19:10,200
decide which configuration performs

471
00:19:10,200 --> 00:19:11,460
performs the best

472
00:19:11,460 --> 00:19:15,240
and make a call as to uh which gives

473
00:19:15,240 --> 00:19:16,559
which gives the network operator the

474
00:19:16,559 --> 00:19:17,700
best efficiency

475
00:19:17,700 --> 00:19:22,380
and best based on the uh based on uh the

476
00:19:22,380 --> 00:19:25,320
uh most efficient performance they can

477
00:19:25,320 --> 00:19:26,880
always go back and provision their

478
00:19:26,880 --> 00:19:28,440
devices with that particular

479
00:19:28,440 --> 00:19:30,980
configuration

480
00:19:32,220 --> 00:19:35,220
thank you I I do have a demo for this uh

481
00:19:35,220 --> 00:19:36,720
for this application for this solution

482
00:19:36,720 --> 00:19:39,299
and if anyone is interested feel free to

483
00:19:39,299 --> 00:19:41,940
tap me on my back

484
00:19:41,940 --> 00:19:42,910
thank you

485
00:19:42,910 --> 00:19:46,189
[Applause]

486
00:19:59,039 --> 00:20:02,100
so when do you think the system doesn't

487
00:20:02,100 --> 00:20:04,260
perform as expected do you see a

488
00:20:04,260 --> 00:20:06,840
correlation in or an infection in drop

489
00:20:06,840 --> 00:20:08,039
packets

490
00:20:08,039 --> 00:20:10,740
as the system is training itself and

491
00:20:10,740 --> 00:20:12,720
second is do you think uh

492
00:20:12,720 --> 00:20:15,419
network-centric view would be most you

493
00:20:15,419 --> 00:20:18,059
more useful especially uh when you have

494
00:20:18,059 --> 00:20:20,039
tier deployments when Network operators

495
00:20:20,039 --> 00:20:21,660
let's say they purchase a juniper box

496
00:20:21,660 --> 00:20:23,880
but some other vendors does not have

497
00:20:23,880 --> 00:20:26,280
this so how do you train systems which

498
00:20:26,280 --> 00:20:28,919
are asymmetric for example it's not like

499
00:20:28,919 --> 00:20:31,140
all systems are built with the same

500
00:20:31,140 --> 00:20:34,700
algorithm or will exhibit the same now

501
00:20:34,700 --> 00:20:38,280
data patterns right as you test them so

502
00:20:38,280 --> 00:20:40,500
each vendors tests it differently each

503
00:20:40,500 --> 00:20:42,960
network is built differently right how

504
00:20:42,960 --> 00:20:43,980
do you what do you what are your

505
00:20:43,980 --> 00:20:46,919
recommendations on a mixed test and

506
00:20:46,919 --> 00:20:51,780
Analysis scenario yeah so uh this the

507
00:20:51,780 --> 00:20:54,299
solution can be both distributed and and

508
00:20:54,299 --> 00:20:57,480
centralized uh so uh with with if if it

509
00:20:57,480 --> 00:20:59,340
is distributed you you you put you

510
00:20:59,340 --> 00:21:01,620
particularly cater to a certain devices

511
00:21:01,620 --> 00:21:04,080
in your network and if it is if it is

512
00:21:04,080 --> 00:21:06,240
centralized it's possible for you to to

513
00:21:06,240 --> 00:21:07,679
collect the statistics from all the

514
00:21:07,679 --> 00:21:09,900
devices in the network and and correlate

515
00:21:09,900 --> 00:21:12,780
that with with the uh you know uh

516
00:21:12,780 --> 00:21:13,980
something like traffic engineering

517
00:21:13,980 --> 00:21:17,280
database uh to sort of make uh make a

518
00:21:17,280 --> 00:21:19,400
call at the centralized network uh

519
00:21:19,400 --> 00:21:21,660
centralized location and then feed it

520
00:21:21,660 --> 00:21:23,039
back to the different uh different

521
00:21:23,039 --> 00:21:25,740
devices and of course traffic patterns

522
00:21:25,740 --> 00:21:28,260
are different on on every device and

523
00:21:28,260 --> 00:21:29,460
it's up to the machine learning model

524
00:21:29,460 --> 00:21:33,419
that you pick uh to uh to sort of uh and

525
00:21:33,419 --> 00:21:35,580
the the model that you train and and

526
00:21:35,580 --> 00:21:38,820
predict uh to come up with a with with

527
00:21:38,820 --> 00:21:40,980
an accurate value to to feed it back

528
00:21:40,980 --> 00:21:43,440
feedback to the device I hope that

529
00:21:43,440 --> 00:21:45,179
answers your question if not I can

530
00:21:45,179 --> 00:21:48,260
definitely Circle

531
00:21:48,600 --> 00:21:50,220
oh drop package

532
00:21:50,220 --> 00:21:52,559
yeah uh and that's that's a totally

533
00:21:52,559 --> 00:21:54,240
different I can get back to you with

534
00:21:54,240 --> 00:21:55,679
that there's there is there is a

535
00:21:55,679 --> 00:21:57,120
different proposal for that yes I can

536
00:21:57,120 --> 00:22:00,379
get back to you yeah

537
00:22:00,480 --> 00:22:03,360
do you have any thoughts on or plans for

538
00:22:03,360 --> 00:22:06,240
integrating this into a routing protocol

539
00:22:06,240 --> 00:22:07,380
um that's like operating on a device

540
00:22:07,380 --> 00:22:10,320
such that the path that traffic takes is

541
00:22:10,320 --> 00:22:11,700
updated

542
00:22:11,700 --> 00:22:12,780
um live

543
00:22:12,780 --> 00:22:16,080
yes uh so yes uh

544
00:22:16,080 --> 00:22:19,260
uh so it's it's again depending on uh

545
00:22:19,260 --> 00:22:23,400
the types of models that you use and uh

546
00:22:23,400 --> 00:22:27,059
uh if if your device is capable of of uh

547
00:22:27,059 --> 00:22:28,380
handling the machine learning model

548
00:22:28,380 --> 00:22:30,659
training and and inference on the device

549
00:22:30,659 --> 00:22:33,120
this this can definitely be deployed

550
00:22:33,120 --> 00:22:36,539
onto the device and uh you know this can

551
00:22:36,539 --> 00:22:38,580
definitely replace the traditional uh

552
00:22:38,580 --> 00:22:41,280
Max average of the max average solution

553
00:22:41,280 --> 00:22:43,140
it depends on the compute that you have

554
00:22:43,140 --> 00:22:45,500
on the device

555
00:22:46,020 --> 00:22:48,840
yeah excuse me a two-part question

556
00:22:48,840 --> 00:22:51,539
um did in the modeling that you did did

557
00:22:51,539 --> 00:22:54,659
you see any like it looked like the ml

558
00:22:54,659 --> 00:22:57,600
uh like the the model driven approach

559
00:22:57,600 --> 00:22:59,760
yielded a lower required you know

560
00:22:59,760 --> 00:23:01,679
bandwidth requirement did you see did

561
00:23:01,679 --> 00:23:03,720
you do like Network wide modeling that

562
00:23:03,720 --> 00:23:05,940
uh gave you an idea what the kind of

563
00:23:05,940 --> 00:23:07,919
like increase in additional capacity

564
00:23:07,919 --> 00:23:09,600
Network wide might be

565
00:23:09,600 --> 00:23:11,640
but could you repeat the second part I

566
00:23:11,640 --> 00:23:13,380
guess the the for both two two questions

567
00:23:13,380 --> 00:23:14,340
rather

568
00:23:14,340 --> 00:23:15,780
um the like

569
00:23:15,780 --> 00:23:17,880
this looks like a very LSP Centric

570
00:23:17,880 --> 00:23:19,980
perspective on things in terms of you

571
00:23:19,980 --> 00:23:21,600
know like Auto bandwidth adjustment yeah

572
00:23:21,600 --> 00:23:23,820
and it looks like it yields a you know a

573
00:23:23,820 --> 00:23:25,860
lower uh you know bandwidth requirement

574
00:23:25,860 --> 00:23:27,600
you know more broadly relative to Max

575
00:23:27,600 --> 00:23:29,520
average I guess I'm curious as to

576
00:23:29,520 --> 00:23:32,039
whether you saw a net Improvement in

577
00:23:32,039 --> 00:23:35,220
overall network capacity across like you

578
00:23:35,220 --> 00:23:37,200
know folks are doing multiple parallel

579
00:23:37,200 --> 00:23:38,820
LSPs to a common destination or

580
00:23:38,820 --> 00:23:39,960
something along these lines so that

581
00:23:39,960 --> 00:23:42,539
you're improving bin packing overall yes

582
00:23:42,539 --> 00:23:45,299
we did see a a significant Improvement

583
00:23:45,299 --> 00:23:47,520
in uh in network capacity because

584
00:23:47,520 --> 00:23:48,720
because of the fact that machine

585
00:23:48,720 --> 00:23:52,380
learning models uh tend to predict uh uh

586
00:23:52,380 --> 00:23:54,000
predict the bandwidth much closer to the

587
00:23:54,000 --> 00:23:55,440
actual traffic

588
00:23:55,440 --> 00:23:57,900
um so uh compared to Max average which

589
00:23:57,900 --> 00:24:00,659
which again reacts to uh the spikes in

590
00:24:00,659 --> 00:24:03,360
data uh again if there is random data

591
00:24:03,360 --> 00:24:05,940
and if the if the data is spiky I'm

592
00:24:05,940 --> 00:24:08,400
pretty sure uh both the models would do

593
00:24:08,400 --> 00:24:10,860
pretty much pretty much the same but

594
00:24:10,860 --> 00:24:12,900
because if there are if there are trench

595
00:24:12,900 --> 00:24:14,520
and patterns and data I'm pretty sure

596
00:24:14,520 --> 00:24:16,980
the machine learning models and so the

597
00:24:16,980 --> 00:24:18,659
next question is specifically focused on

598
00:24:18,659 --> 00:24:21,179
the models uh like is there any do you

599
00:24:21,179 --> 00:24:23,280
see a mechanism for operators to be able

600
00:24:23,280 --> 00:24:25,980
to inspect or understand what the models

601
00:24:25,980 --> 00:24:29,460
are doing or what the inputs beyond the

602
00:24:29,460 --> 00:24:31,860
training on the models are and like how

603
00:24:31,860 --> 00:24:34,740
do you see those being exchanged or

604
00:24:34,740 --> 00:24:37,559
um you know shared sure so uh yeah we do

605
00:24:37,559 --> 00:24:39,539
have we have built a solution on this

606
00:24:39,539 --> 00:24:44,460
and what we do is we um uh use we take

607
00:24:44,460 --> 00:24:46,260
all this all the metadata corresponding

608
00:24:46,260 --> 00:24:49,200
to the training and prediction and we

609
00:24:49,200 --> 00:24:50,940
write it back to the database for

610
00:24:50,940 --> 00:24:53,520
visualizing uh later so that's that's

611
00:24:53,520 --> 00:24:56,220
that can always serve as as the as the

612
00:24:56,220 --> 00:24:57,240
source of Truth for the network

613
00:24:57,240 --> 00:24:59,220
operators uh to understand if the

614
00:24:59,220 --> 00:25:00,360
machine learning models are performing

615
00:25:00,360 --> 00:25:02,280
well and we do have something called

616
00:25:02,280 --> 00:25:04,260
monitor mode if I I don't know how to go

617
00:25:04,260 --> 00:25:05,700
back

618
00:25:05,700 --> 00:25:08,640
oh sorry it's close Okay uh we do have

619
00:25:08,640 --> 00:25:10,919
something called a monitor mode for for

620
00:25:10,919 --> 00:25:12,600
Network operators to see how the machine

621
00:25:12,600 --> 00:25:14,640
learning models are performing uh and

622
00:25:14,640 --> 00:25:17,159
make a call whether to uh you know start

623
00:25:17,159 --> 00:25:18,539
making the adjustments back to the

624
00:25:18,539 --> 00:25:21,179
device and by flipping to update mode so

625
00:25:21,179 --> 00:25:23,760
all those Provisions are in place uh and

626
00:25:23,760 --> 00:25:25,200
you know you can always visualize the

627
00:25:25,200 --> 00:25:26,460
data that's coming out of the machine

628
00:25:26,460 --> 00:25:28,799
learning models as well

629
00:25:28,799 --> 00:25:30,840
hi thank you for the talk uh out of

630
00:25:30,840 --> 00:25:33,600
curiosity two questions I'm wondering um

631
00:25:33,600 --> 00:25:35,700
of the machine learning algorithms was

632
00:25:35,700 --> 00:25:37,500
regression or deep learning approaches

633
00:25:37,500 --> 00:25:39,059
were any of them were performant and the

634
00:25:39,059 --> 00:25:41,640
second part is I'm speculating that

635
00:25:41,640 --> 00:25:43,320
you're running inferences and training

636
00:25:43,320 --> 00:25:45,360
quite frequently to model this data but

637
00:25:45,360 --> 00:25:47,400
I'd like you to kind of expand on how

638
00:25:47,400 --> 00:25:50,039
often that actually is running so uh can

639
00:25:50,039 --> 00:25:51,539
you repeat it first question please I

640
00:25:51,539 --> 00:25:52,799
can answer the second question so in

641
00:25:52,799 --> 00:25:54,539
term of the actual model that you're

642
00:25:54,539 --> 00:25:56,940
using or did you notice a increase in

643
00:25:56,940 --> 00:25:58,679
accuracy or performance for either

644
00:25:58,679 --> 00:26:00,600
regression or deep learning basic models

645
00:26:00,600 --> 00:26:02,100
I'm assuming you're doing RNN on the

646
00:26:02,100 --> 00:26:04,740
Deep learning side yeah so uh we have

647
00:26:04,740 --> 00:26:06,659
used we have used multiple we have tried

648
00:26:06,659 --> 00:26:08,779
multiple machine learning statistical

649
00:26:08,779 --> 00:26:11,279
some and a couple of neural networks as

650
00:26:11,279 --> 00:26:12,360
well

651
00:26:12,360 --> 00:26:13,740
um

652
00:26:13,740 --> 00:26:16,380
okay the based on an experience it's

653
00:26:16,380 --> 00:26:18,659
it's uh

654
00:26:18,659 --> 00:26:21,840
it makes more more and based on the data

655
00:26:21,840 --> 00:26:24,419
that we have collected uh we have seen

656
00:26:24,419 --> 00:26:27,960
that the traditional uh statistical uh

657
00:26:27,960 --> 00:26:30,299
or the regression models non-linear

658
00:26:30,299 --> 00:26:32,580
education models tend to perform much

659
00:26:32,580 --> 00:26:34,200
better than uh you know complicated

660
00:26:34,200 --> 00:26:36,779
neural network that we have written uh

661
00:26:36,779 --> 00:26:39,299
and uh okay can you could you repeat

662
00:26:39,299 --> 00:26:41,039
your second question please sorry sorry

663
00:26:41,039 --> 00:26:42,960
the second question was how frequently

664
00:26:42,960 --> 00:26:44,520
are you running training on these assets

665
00:26:44,520 --> 00:26:46,919
and inferences okay so it again depends

666
00:26:46,919 --> 00:26:50,460
on uh the uh adjustment interval uh uh

667
00:26:50,460 --> 00:26:52,799
uh if if you are forecast if you are

668
00:26:52,799 --> 00:26:54,900
trying to forecast a way into the future

669
00:26:54,900 --> 00:26:57,080
uh we would suggest to

670
00:26:57,080 --> 00:27:01,200
take the data from uh you know a longer

671
00:27:01,200 --> 00:27:03,120
longer historical window and train the

672
00:27:03,120 --> 00:27:05,100
models if you are looking at a very

673
00:27:05,100 --> 00:27:07,860
short historical windows or if you're

674
00:27:07,860 --> 00:27:09,779
looking for a short-term prediction you

675
00:27:09,779 --> 00:27:11,760
can always train the models using using

676
00:27:11,760 --> 00:27:13,860
uh the last few adjustment Rules by

677
00:27:13,860 --> 00:27:15,360
intervals worth of data to come up with

678
00:27:15,360 --> 00:27:17,700
the short temperature so it it purely

679
00:27:17,700 --> 00:27:19,380
depends on the types of types of models

680
00:27:19,380 --> 00:27:21,059
that you're using and the type of

681
00:27:21,059 --> 00:27:24,779
forecasting that you want yeah

682
00:27:24,779 --> 00:27:27,419
Robert CC

683
00:27:27,419 --> 00:27:28,919
um very good talk thank you very much

684
00:27:28,919 --> 00:27:31,260
I'm interested in the cost of actually

685
00:27:31,260 --> 00:27:33,840
running the ml engine itself I can

686
00:27:33,840 --> 00:27:35,940
imagine a scenario where this is highly

687
00:27:35,940 --> 00:27:37,980
interesting to run per peering session

688
00:27:37,980 --> 00:27:39,900
for example and if I have hundreds and

689
00:27:39,900 --> 00:27:41,700
thousands of that I really want to see

690
00:27:41,700 --> 00:27:43,380
if some of them is speaking or are

691
00:27:43,380 --> 00:27:44,940
peaking and you know there's an anomaly

692
00:27:44,940 --> 00:27:46,740
somewhere not in the whole system yeah

693
00:27:46,740 --> 00:27:49,260
but on some of those so and that's only

694
00:27:49,260 --> 00:27:51,960
feasible if the cost of doing this is

695
00:27:51,960 --> 00:27:53,820
actually low enough yeah so can you can

696
00:27:53,820 --> 00:27:55,860
you address like how expensive is is

697
00:27:55,860 --> 00:27:58,500
this to draw yeah yeah so uh you have it

698
00:27:58,500 --> 00:28:00,000
with the Advent of microservice

699
00:28:00,000 --> 00:28:02,820
architecture the operational overhead

700
00:28:02,820 --> 00:28:04,980
for deploying such applications has has

701
00:28:04,980 --> 00:28:07,860
come down drastically especially these

702
00:28:07,860 --> 00:28:10,039
days

703
00:28:10,039 --> 00:28:14,059
and gpus are fairly fairly cheap to

704
00:28:14,059 --> 00:28:16,340
install uh

705
00:28:16,340 --> 00:28:18,900
not that you need a GPU for this but

706
00:28:18,900 --> 00:28:21,840
yeah uh it's uh that increases the cost

707
00:28:21,840 --> 00:28:25,320
right so it does but uh as I said you if

708
00:28:25,320 --> 00:28:27,360
you already have such uh these resources

709
00:28:27,360 --> 00:28:28,679
you should be in a position to deploy

710
00:28:28,679 --> 00:28:31,140
this even on a virtual machine

711
00:28:31,140 --> 00:28:32,700
um and of course I understand the fact

712
00:28:32,700 --> 00:28:34,679
that you need to uh you need a

713
00:28:34,679 --> 00:28:36,419
distributed solution for this and you

714
00:28:36,419 --> 00:28:40,559
you need more multiple uh VMS are forced

715
00:28:40,559 --> 00:28:44,900
to to deploy this but yeah it's it's a

716
00:28:44,900 --> 00:28:47,340
you'd say pressure CPU Cycles on your

717
00:28:47,340 --> 00:28:49,559
device as well so uh it's a it's a

718
00:28:49,559 --> 00:28:51,360
trade-off I would say

719
00:28:51,360 --> 00:28:52,799
fair enough can you state that it's

720
00:28:52,799 --> 00:28:54,900
actually cheap to do

721
00:28:54,900 --> 00:28:55,500
um

722
00:28:55,500 --> 00:28:58,799
I I'd leave I'd leave that to uh the

723
00:28:58,799 --> 00:29:00,419
network operators I will let you guys

724
00:29:00,419 --> 00:29:03,360
answer that question but yeah I'm a

725
00:29:03,360 --> 00:29:04,980
developer so

726
00:29:04,980 --> 00:29:07,380
I don't have insights into that

727
00:29:07,380 --> 00:29:10,020
so any other questions out there

728
00:29:10,020 --> 00:29:12,360
anything online Chris excellent yeah

729
00:29:12,360 --> 00:29:14,940
thanks thank you

730
00:29:14,940 --> 00:29:17,659
thank you

731
00:29:17,680 --> 00:29:21,410
[Music]

