1
00:00:11,940 --> 00:00:15,750
hello<font color="#E5E5E5"> everyone my name is Husain</font><font color="#CCCCCC"> lutfi</font>

2
00:00:14,429 --> 00:00:17,160
and

3
00:00:15,750 --> 00:00:20,960
a performance engineering team at

4
00:00:17,160 --> 00:00:23,340
verizon<font color="#CCCCCC"> EdgeCast I'm</font><font color="#E5E5E5"> here to talk about</font>

5
00:00:20,960 --> 00:00:25,260
<font color="#E5E5E5">the challenges</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> we had when we</font>

6
00:00:23,340 --> 00:00:27,990
initially testing our network for ipv6

7
00:00:25,260 --> 00:00:30,570
the problems we found and possible

8
00:00:27,990 --> 00:00:32,430
solutions to those problems since this

9
00:00:30,570 --> 00:00:35,309
is the first time that we're<font color="#CCCCCC"> presenting</font>

10
00:00:32,430 --> 00:00:38,040
at a<font color="#CCCCCC"> nog I have two slides to explain</font>

11
00:00:35,309 --> 00:00:40,169
who we<font color="#E5E5E5"> are and what we do</font><font color="#CCCCCC"> edgecast is a</font>

12
00:00:38,040 --> 00:00:41,850
content delivery network with presence

13
00:00:40,170 --> 00:00:44,550
in more than 40 locations around the

14
00:00:41,850 --> 00:00:47,870
world and<font color="#E5E5E5"> it's rapidly expanding we have</font>

15
00:00:44,550 --> 00:00:51,209
a small<font color="#E5E5E5"> object and large object object</font>

16
00:00:47,870 --> 00:00:53,280
static delivery platform we also have a

17
00:00:51,210 --> 00:00:56,280
dynamic object delivery platform which

18
00:00:53,280 --> 00:00:58,440
has a lot of<font color="#E5E5E5"> TCP optimizations in it we</font>

19
00:00:56,280 --> 00:01:00,329
do streaming and dns and as you might

20
00:00:58,440 --> 00:01:04,319
have heard we were<font color="#E5E5E5"> recently acquired by</font>

21
00:01:00,329 --> 00:01:06,750
<font color="#E5E5E5">Verizon here's what my team does at</font>

22
00:01:04,319 --> 00:01:09,660
<font color="#CCCCCC">edgecast we're a bunch of full stack</font>

23
00:01:06,750 --> 00:01:12,420
engineers that look at mountains of

24
00:01:09,660 --> 00:01:13,920
mountains of performance data and we try

25
00:01:12,420 --> 00:01:16,830
<font color="#CCCCCC">to come</font><font color="#E5E5E5"> up with ways that we can make</font>

26
00:01:13,920 --> 00:01:18,630
this CD and faster basically we're up

27
00:01:16,830 --> 00:01:20,039
against what Einstein predicted right we

28
00:01:18,630 --> 00:01:21,810
can't go faster than speed of light

29
00:01:20,040 --> 00:01:25,320
we're coming<font color="#CCCCCC"> up with different ways</font><font color="#E5E5E5"> to</font>

30
00:01:21,810 --> 00:01:27,450
<font color="#E5E5E5">deliver the objects faster and what</font>

31
00:01:25,320 --> 00:01:30,689
we're going<font color="#CCCCCC"> to do what we're doing is</font>

32
00:01:27,450 --> 00:01:32,759
that we look at the entire stack and

33
00:01:30,689 --> 00:01:35,339
what it<font color="#E5E5E5"> makes it really interesting is</font>

34
00:01:32,759 --> 00:01:37,740
that one day<font color="#CCCCCC"> we focus on Colonel file</font>

35
00:01:35,340 --> 00:01:39,750
system TCP the next day its application

36
00:01:37,740 --> 00:01:42,330
optimization the day after that its

37
00:01:39,750 --> 00:01:44,009
network in any<font color="#CCCCCC"> case optimization and we</font>

38
00:01:42,330 --> 00:01:46,860
have we had several<font color="#E5E5E5"> cases that we</font>

39
00:01:44,009 --> 00:01:48,329
<font color="#E5E5E5">actually had to do physical changes in</font>

40
00:01:46,860 --> 00:01:51,329
our data centers to improve performance

41
00:01:48,329 --> 00:01:53,008
and so basically whenever<font color="#E5E5E5"> there's a</font>

42
00:01:51,329 --> 00:01:54,689
complex case coming up and<font color="#E5E5E5"> no one else</font>

43
00:01:53,009 --> 00:01:57,210
<font color="#E5E5E5">can explain what's going on and it</font>

44
00:01:54,689 --> 00:01:58,798
touches multiple areas its performance

45
00:01:57,210 --> 00:02:02,399
engineering team that gets involved to

46
00:01:58,799 --> 00:02:04,220
be able<font color="#E5E5E5"> to address those issues in my</font>

47
00:02:02,399 --> 00:02:07,950
<font color="#E5E5E5">talk you're going to hear a lot about</font>

48
00:02:04,220 --> 00:02:09,720
response times and milliseconds and let

49
00:02:07,950 --> 00:02:11,760
me<font color="#CCCCCC"> just</font><font color="#E5E5E5"> quickly explain why it matters</font>

50
00:02:09,720 --> 00:02:14,070
so much there are a lot of independent

51
00:02:11,760 --> 00:02:16,048
studies that measures the CDM

52
00:02:14,070 --> 00:02:18,900
performances and they actually publish

53
00:02:16,049 --> 00:02:20,579
the data publicly and if you look<font color="#CCCCCC"> at one</font>

54
00:02:18,900 --> 00:02:23,220
of these benchmarks this is<font color="#CCCCCC"> said access</font>

55
00:02:20,579 --> 00:02:25,200
data the difference<font color="#CCCCCC"> between the best</font>

56
00:02:23,220 --> 00:02:29,630
<font color="#CCCCCC">performing CDN at the worst one in u.s.</font>

57
00:02:25,200 --> 00:02:31,519
is only 17 milliseconds<font color="#E5E5E5"> so</font>

58
00:02:29,630 --> 00:02:32,870
that's why every millisecond counts

59
00:02:31,520 --> 00:02:34,880
that's why we're so anxious to<font color="#E5E5E5"> be able</font>

60
00:02:32,870 --> 00:02:38,570
<font color="#E5E5E5">to cut round trips and minimize the</font>

61
00:02:34,880 --> 00:02:42,140
internal latency of our applications<font color="#CCCCCC"> all</font>

62
00:02:38,570 --> 00:02:43,730
<font color="#CCCCCC">right so in my talk initially i</font><font color="#E5E5E5"> had when</font>

63
00:02:42,140 --> 00:02:45,589
i submitted to talk to<font color="#CCCCCC"> knock it was</font>

64
00:02:43,730 --> 00:02:47,119
talking about patentable problems and

65
00:02:45,590 --> 00:02:49,100
the solutions around it the feedback

66
00:02:47,120 --> 00:02:50,900
<font color="#CCCCCC">that I got from a program committee was</font>

67
00:02:49,100 --> 00:02:52,609
that it's good to<font color="#E5E5E5"> explain how we</font>

68
00:02:50,900 --> 00:02:54,260
discovered those issues as well because

69
00:02:52,610 --> 00:02:57,230
<font color="#E5E5E5">there might never be more interesting</font>

70
00:02:54,260 --> 00:02:59,420
the audience to to know about our

71
00:02:57,230 --> 00:03:02,299
experience with testing our network for

72
00:02:59,420 --> 00:03:04,250
ipv6 compatibility so let<font color="#E5E5E5"> me start with</font>

73
00:03:02,300 --> 00:03:06,680
that whenever we<font color="#E5E5E5"> launch a new product</font>

74
00:03:04,250 --> 00:03:08,810
what we do is that<font color="#E5E5E5"> we have a tool set</font>

75
00:03:06,680 --> 00:03:11,120
that we go<font color="#E5E5E5"> over the stool set to be</font><font color="#CCCCCC"> able</font>

76
00:03:08,810 --> 00:03:12,830
to<font color="#E5E5E5"> make sure that availability is what</font>

77
00:03:11,120 --> 00:03:14,570
we expect and the performance is good

78
00:03:12,830 --> 00:03:18,740
I'm going<font color="#E5E5E5"> to walk over all of these</font>

79
00:03:14,570 --> 00:03:22,730
steps and explain how we use these tools

80
00:03:18,740 --> 00:03:25,940
to detect ipv6 problems our<font color="#E5E5E5"> target</font>

81
00:03:22,730 --> 00:03:27,590
launch was ipv6 launch day so we had a

82
00:03:25,940 --> 00:03:30,380
set deadline that we had to make<font color="#E5E5E5"> sure</font>

83
00:03:27,590 --> 00:03:32,000
<font color="#E5E5E5">everything is good by</font><font color="#CCCCCC"> that normally when</font>

84
00:03:30,380 --> 00:03:33,829
you launch a new platform the first

85
00:03:32,000 --> 00:03:36,890
thing we test is<font color="#E5E5E5"> synthetic monitoring</font>

86
00:03:33,830 --> 00:03:39,470
these are servers around the world very

87
00:03:36,890 --> 00:03:41,119
<font color="#CCCCCC">well-managed where we</font><font color="#E5E5E5"> will appear and we</font>

88
00:03:39,470 --> 00:03:42,920
love synthetic monitoring because it's

89
00:03:41,120 --> 00:03:45,080
reproducible it's controllable when we

90
00:03:42,920 --> 00:03:47,209
have a new idea that we want<font color="#E5E5E5"> to test</font>

91
00:03:45,080 --> 00:03:48,740
usually the first thing that<font color="#CCCCCC"> we</font><font color="#E5E5E5"> still we</font>

92
00:03:47,210 --> 00:03:52,580
start testing is this synthetic test

93
00:03:48,740 --> 00:03:54,740
because generally the random noise over

94
00:03:52,580 --> 00:03:56,900
internet is not pursued present in these

95
00:03:54,740 --> 00:03:58,550
platforms so we can rely<font color="#CCCCCC"> on the data</font>

96
00:03:56,900 --> 00:04:01,340
that we were collecting from these

97
00:03:58,550 --> 00:04:05,090
servers we had a<font color="#E5E5E5"> lot of synthetic notes</font>

98
00:04:01,340 --> 00:04:07,820
at before ipv6<font color="#CCCCCC"> launch but the problem is</font>

99
00:04:05,090 --> 00:04:09,740
none of<font color="#E5E5E5"> them were v6 capable at that</font>

100
00:04:07,820 --> 00:04:12,920
time so synthetic monitoring wasn't

101
00:04:09,740 --> 00:04:14,870
really an option price to this day one

102
00:04:12,920 --> 00:04:16,820
of<font color="#CCCCCC"> the platforms two of them</font><font color="#E5E5E5"> actually</font>

103
00:04:14,870 --> 00:04:20,329
supported but there's still not that

104
00:04:16,820 --> 00:04:23,150
good of a coverage so the<font color="#CCCCCC"> next tool that</font>

105
00:04:20,329 --> 00:04:25,039
is usually available to us is wrong real

106
00:04:23,150 --> 00:04:30,020
user monitoring is a very clever idea

107
00:04:25,040 --> 00:04:32,000
that what they do at the<font color="#CCCCCC"> end</font><font color="#E5E5E5"> of the</font><font color="#CCCCCC"> web</font>

108
00:04:30,020 --> 00:04:35,599
<font color="#CCCCCC">page browse what happens is that the web</font>

109
00:04:32,000 --> 00:04:38,090
page becomes your test platform and the

110
00:04:35,600 --> 00:04:39,890
<font color="#E5E5E5">user browser is going to call multiple</font>

111
00:04:38,090 --> 00:04:41,810
objects from different CD ends<font color="#CCCCCC"> and</font>

112
00:04:39,890 --> 00:04:42,840
report the timing<font color="#E5E5E5"> back to a central</font>

113
00:04:41,810 --> 00:04:45,070
server

114
00:04:42,840 --> 00:04:47,409
their companies out there who are

115
00:04:45,070 --> 00:04:49,300
basically offering this product you can

116
00:04:47,410 --> 00:04:52,330
you can get the raw data you can get a

117
00:04:49,300 --> 00:04:55,210
lot of analysis from these platforms the

118
00:04:52,330 --> 00:04:56,710
problem again<font color="#CCCCCC"> i'ma let me mention the</font>

119
00:04:55,210 --> 00:04:59,770
value of these wrong platforms because

120
00:04:56,710 --> 00:05:01,719
now you get you can see visibility into

121
00:04:59,770 --> 00:05:05,260
areas that you had no visibility before

122
00:05:01,720 --> 00:05:07,630
an interesting case we were<font color="#E5E5E5"> getting</font>

123
00:05:05,260 --> 00:05:09,610
reports from one of these<font color="#E5E5E5"> run platforms</font>

124
00:05:07,630 --> 00:05:11,080
that<font color="#E5E5E5"> our response time in Albania for</font>

125
00:05:09,610 --> 00:05:13,660
some reason is 40 milliseconds higher

126
00:05:11,080 --> 00:05:15,700
than the best CDN in that country<font color="#E5E5E5"> and</font>

127
00:05:13,660 --> 00:05:17,380
we're<font color="#E5E5E5"> really curious what's going on</font>

128
00:05:15,700 --> 00:05:19,090
there was no synthetic<font color="#E5E5E5"> node in that</font>

129
00:05:17,380 --> 00:05:21,610
country so<font color="#CCCCCC"> that was the only indication</font>

130
00:05:19,090 --> 00:05:23,650
that something is wrong so we looked at

131
00:05:21,610 --> 00:05:25,180
it<font color="#E5E5E5"> and we discovered</font><font color="#CCCCCC"> the GUI p mapping</font>

132
00:05:23,650 --> 00:05:26,349
problem and then once we were able<font color="#E5E5E5"> to</font>

133
00:05:25,180 --> 00:05:29,220
fix that<font color="#E5E5E5"> we're able to match the</font>

134
00:05:26,350 --> 00:05:32,770
performance of the other city<font color="#E5E5E5"> n there</font>

135
00:05:29,220 --> 00:05:34,870
rom just the general caution is that the

136
00:05:32,770 --> 00:05:37,120
data is full of noise so we don't look

137
00:05:34,870 --> 00:05:39,610
at<font color="#CCCCCC"> rom data in real time we</font><font color="#E5E5E5"> don't set</font>

138
00:05:37,120 --> 00:05:41,800
<font color="#CCCCCC">real-time alerts on these things we look</font>

139
00:05:39,610 --> 00:05:43,360
at wrong data mainly for trending

140
00:05:41,800 --> 00:05:46,150
purposes what you're seeing in this

141
00:05:43,360 --> 00:05:50,230
chart is one of the<font color="#CCCCCC"> TCP optimizations</font>

142
00:05:46,150 --> 00:05:51,849
idea that we had and the blue line is<font color="#CCCCCC"> a</font>

143
00:05:50,230 --> 00:05:56,260
<font color="#E5E5E5">target line you can see</font><font color="#CCCCCC"> that when we</font>

144
00:05:51,850 --> 00:05:58,090
applied the to the red chart the

145
00:05:56,260 --> 00:05:59,650
throughput goes up and just<font color="#E5E5E5"> to prove</font>

146
00:05:58,090 --> 00:06:01,060
that<font color="#E5E5E5"> it was rtcp performance</font>

147
00:05:59,650 --> 00:06:03,940
optimization that made things<font color="#E5E5E5"> better and</font>

148
00:06:01,060 --> 00:06:05,890
not any other random effect when we turn

149
00:06:03,940 --> 00:06:09,910
it off we went back<font color="#CCCCCC"> to</font><font color="#E5E5E5"> the control set</font>

150
00:06:05,890 --> 00:06:11,830
where we used<font color="#CCCCCC"> to be before but again the</font>

151
00:06:09,910 --> 00:06:13,770
problem with the<font color="#E5E5E5"> ROM at that time was</font>

152
00:06:11,830 --> 00:06:16,090
that there were not ipv6 capable and

153
00:06:13,770 --> 00:06:20,200
none of the platforms to my knowledge

154
00:06:16,090 --> 00:06:22,989
<font color="#E5E5E5">today are so now wasn't</font><font color="#CCCCCC"> an option for us</font>

155
00:06:20,200 --> 00:06:25,090
we have to<font color="#E5E5E5"> skip to the next option which</font>

156
00:06:22,990 --> 00:06:29,410
turned out to be really<font color="#E5E5E5"> amazing these</font>

157
00:06:25,090 --> 00:06:32,500
<font color="#E5E5E5">little probes that ripe distributed was</font>

158
00:06:29,410 --> 00:06:34,570
extremely helpful<font color="#E5E5E5"> for us ripe I'm sure</font>

159
00:06:32,500 --> 00:06:36,310
they've presented this before and you

160
00:06:34,570 --> 00:06:40,450
<font color="#E5E5E5">guys are all familiar but I'm going to</font>

161
00:06:36,310 --> 00:06:42,910
<font color="#E5E5E5">explain</font><font color="#CCCCCC"> how this probe helped us to find</font>

162
00:06:40,450 --> 00:06:45,099
a v6 problems they have pretty good

163
00:06:42,910 --> 00:06:47,560
coverage around the world<font color="#CCCCCC"> they now more</font>

164
00:06:45,100 --> 00:06:50,200
than 4,000 notes they're deployed and

165
00:06:47,560 --> 00:06:52,330
what we really like about<font color="#E5E5E5"> Atlas is that</font>

166
00:06:50,200 --> 00:06:54,070
it's completely programmable you can say

167
00:06:52,330 --> 00:06:55,940
you can set your<font color="#CCCCCC"> test</font><font color="#E5E5E5"> using IP eyes and</font>

168
00:06:54,070 --> 00:06:58,370
get the results back from the API

169
00:06:55,940 --> 00:07:02,620
they can do<font color="#CCCCCC"> ptrace</font><font color="#E5E5E5"> dns ssl certs and</font>

170
00:06:58,370 --> 00:07:05,210
they're<font color="#E5E5E5"> doing HTTP taste say in beta now</font>

171
00:07:02,620 --> 00:07:07,850
one of<font color="#E5E5E5"> the cool</font><font color="#CCCCCC"> things that</font><font color="#E5E5E5"> you could</font>

172
00:07:05,210 --> 00:07:10,609
you can have an atlas this is not

173
00:07:07,850 --> 00:07:12,950
available to to all at last users and

174
00:07:10,610 --> 00:07:15,860
ripe will be probably really bad mad at

175
00:07:12,950 --> 00:07:18,890
me by telling you this but the beta

176
00:07:15,860 --> 00:07:20,750
testers of ipv6<font color="#E5E5E5"> network had access to a</font>

177
00:07:18,890 --> 00:07:23,240
certain tool that could actually launch

178
00:07:20,750 --> 00:07:26,420
v6 pings and traces from their entire

179
00:07:23,240 --> 00:07:30,140
network and they'll give you<font color="#CCCCCC"> the is</font>

180
00:07:26,420 --> 00:07:31,280
mapping and the is graph and on the

181
00:07:30,140 --> 00:07:34,099
graph on the right<font color="#CCCCCC"> I'm</font><font color="#E5E5E5"> not sure if it's</font>

182
00:07:31,280 --> 00:07:36,349
visible enough but you can<font color="#E5E5E5"> actually see</font>

183
00:07:34,100 --> 00:07:39,680
the failed passes and you can actually

184
00:07:36,350 --> 00:07:43,010
see what was the last<font color="#CCCCCC"> AAS that you saw</font>

185
00:07:39,680 --> 00:07:45,620
in the trace before going blank going

186
00:07:43,010 --> 00:07:48,680
<font color="#E5E5E5">dark so it was extremely helpful for us</font>

187
00:07:45,620 --> 00:07:52,490
to detect the to zoom<font color="#E5E5E5"> into the primary</font>

188
00:07:48,680 --> 00:07:55,190
assets that we had a<font color="#E5E5E5"> problem with all</font>

189
00:07:52,490 --> 00:07:57,260
right a general<font color="#E5E5E5"> note is that we need</font>

190
00:07:55,190 --> 00:07:59,030
more<font color="#E5E5E5"> at last probes in</font><font color="#CCCCCC"> u.s. it's heavily</font>

191
00:07:57,260 --> 00:08:00,890
<font color="#CCCCCC">Europe centric I guess because</font><font color="#E5E5E5"> ripe</font>

192
00:07:59,030 --> 00:08:02,869
started it they have a ton of nodes

193
00:08:00,890 --> 00:08:05,000
there but when you look at us this is

194
00:08:02,870 --> 00:08:06,470
one of<font color="#E5E5E5"> the largest</font><font color="#CCCCCC"> US networks and you</font>

195
00:08:05,000 --> 00:08:09,770
can see<font color="#CCCCCC"> that it's very</font><font color="#E5E5E5"> East Coast</font>

196
00:08:06,470 --> 00:08:11,120
centric the problem with this sort of

197
00:08:09,770 --> 00:08:13,490
deployment is that<font color="#E5E5E5"> especially for</font>

198
00:08:11,120 --> 00:08:15,860
networks like us<font color="#CCCCCC"> that rely on</font><font color="#E5E5E5"> any cast</font>

199
00:08:13,490 --> 00:08:17,150
we need to be able<font color="#E5E5E5"> to see the traffic we</font>

200
00:08:15,860 --> 00:08:19,100
need to see<font color="#CCCCCC"> we'll be able</font><font color="#E5E5E5"> to see the</font>

201
00:08:17,150 --> 00:08:22,429
performance from around the country not

202
00:08:19,100 --> 00:08:23,930
<font color="#E5E5E5">just the</font><font color="#CCCCCC"> East Coast heavy so if you're</font>

203
00:08:22,430 --> 00:08:26,360
<font color="#CCCCCC">thinking about launching a looking glass</font>

204
00:08:23,930 --> 00:08:28,040
<font color="#E5E5E5">I highly encourage considering outlast</font>

205
00:08:26,360 --> 00:08:30,380
instead it will help the community much

206
00:08:28,040 --> 00:08:33,050
better it's programmable I can do

207
00:08:30,380 --> 00:08:36,140
everything<font color="#E5E5E5"> that then a looking glass can</font>

208
00:08:33,049 --> 00:08:38,270
do<font color="#CCCCCC"> with way less</font><font color="#E5E5E5"> than risk of a</font>

209
00:08:36,140 --> 00:08:41,390
traditional looking glass but of course

210
00:08:38,270 --> 00:08:44,360
<font color="#E5E5E5">you can't give you bgp lookups which</font>

211
00:08:41,390 --> 00:08:46,550
ripe has a different solution for it<font color="#CCCCCC"> all</font>

212
00:08:44,360 --> 00:08:50,870
<font color="#CCCCCC">right so what did we learn from at last</font>

213
00:08:46,550 --> 00:08:53,770
when we tested our v6 which ability we

214
00:08:50,870 --> 00:08:57,200
the first thing<font color="#CCCCCC"> that we compiled was a</font>

215
00:08:53,770 --> 00:08:59,060
pop to<font color="#CCCCCC"> contrary mapping and it we</font>

216
00:08:57,200 --> 00:09:00,680
drilled down to a s level and subnet

217
00:08:59,060 --> 00:09:02,719
level as Latin as well and we<font color="#E5E5E5"> try to</font>

218
00:09:00,680 --> 00:09:05,900
visualize the latencies and then we

219
00:09:02,720 --> 00:09:07,730
uncovered pretty amazing<font color="#E5E5E5"> things one of</font>

220
00:09:05,900 --> 00:09:09,410
<font color="#CCCCCC">the examples in</font><font color="#E5E5E5"> this chart is that the</font>

221
00:09:07,730 --> 00:09:11,209
country<font color="#CCCCCC"> in the center of that</font>

222
00:09:09,410 --> 00:09:13,759
art is Ukraine and you can see<font color="#CCCCCC"> that it's</font>

223
00:09:11,209 --> 00:09:16,189
going to two of our pops one of them is

224
00:09:13,759 --> 00:09:18,589
showing relatively good latency the

225
00:09:16,190 --> 00:09:20,899
other one is has high latency so we

226
00:09:18,589 --> 00:09:22,790
wanted to<font color="#CCCCCC"> know why part of that country</font>

227
00:09:20,899 --> 00:09:25,579
is<font color="#CCCCCC"> going to a different pub that is not</font>

228
00:09:22,790 --> 00:09:27,349
the<font color="#CCCCCC"> right location for it and we</font><font color="#E5E5E5"> focus</font>

229
00:09:25,579 --> 00:09:29,479
on these high latency links first and

230
00:09:27,350 --> 00:09:32,209
then we we<font color="#E5E5E5"> untangle the problems there</font>

231
00:09:29,480 --> 00:09:35,870
and this study is actually published by

232
00:09:32,209 --> 00:09:40,189
ripe as one of the case studies<font color="#E5E5E5"> of using</font>

233
00:09:35,870 --> 00:09:42,319
at last so we learned a lot from at last

234
00:09:40,189 --> 00:09:44,329
we we wanted to<font color="#E5E5E5"> understand our</font>

235
00:09:42,319 --> 00:09:49,128
availability what we needed more data

236
00:09:44,329 --> 00:09:51,378
that's why<font color="#E5E5E5"> we launched our own rom to</font>

237
00:09:49,129 --> 00:09:53,839
basically test three different objects

238
00:09:51,379 --> 00:09:56,120
we were<font color="#E5E5E5"> calling a v4 object a v6 only</font>

239
00:09:53,839 --> 00:09:59,990
address and a<font color="#E5E5E5"> dual stack dual</font><font color="#CCCCCC"> address</font>

240
00:09:56,120 --> 00:10:02,000
just to make sure that to understand the

241
00:09:59,990 --> 00:10:04,569
availability of these three as well as

242
00:10:02,000 --> 00:10:09,470
the<font color="#E5E5E5"> difference between the latencies and</font>

243
00:10:04,569 --> 00:10:12,079
we wanted<font color="#E5E5E5"> to focus</font><font color="#CCCCCC"> on the most the main</font>

244
00:10:09,470 --> 00:10:14,240
problem areas so one idea was that<font color="#CCCCCC"> okay</font>

245
00:10:12,079 --> 00:10:17,779
let's add a control set let's add ipv6

246
00:10:14,240 --> 00:10:19,189
google google com as well to be able to

247
00:10:17,779 --> 00:10:21,920
understand our their networks out there

248
00:10:19,189 --> 00:10:24,860
that can reach to<font color="#E5E5E5"> google but</font><font color="#CCCCCC"> what failed</font>

249
00:10:21,920 --> 00:10:28,490
<font color="#E5E5E5">to reach to us over v6 and that was the</font>

250
00:10:24,860 --> 00:10:32,389
primary focus to fix these routing

251
00:10:28,490 --> 00:10:35,089
issues we also did latency calculations

252
00:10:32,389 --> 00:10:38,120
we knew<font color="#CCCCCC"> ahead of the time that going v6</font>

253
00:10:35,089 --> 00:10:39,589
is actually in a lot of<font color="#E5E5E5"> cases is not</font>

254
00:10:38,120 --> 00:10:41,300
good for<font color="#CCCCCC"> the performance because mainly</font>

255
00:10:39,589 --> 00:10:43,310
because of<font color="#CCCCCC"> the peering policies that we</font>

256
00:10:41,300 --> 00:10:45,349
have with about<font color="#E5E5E5"> all the networks we have</font>

257
00:10:43,310 --> 00:10:47,810
a very rich peering data set with all of

258
00:10:45,350 --> 00:10:50,300
you guys but that's<font color="#E5E5E5"> not the case for all</font>

259
00:10:47,810 --> 00:10:51,560
the v6 connections and we knew ahead<font color="#E5E5E5"> of</font>

260
00:10:50,300 --> 00:10:54,019
<font color="#E5E5E5">the time that there will be</font><font color="#CCCCCC"> a</font>

261
00:10:51,560 --> 00:10:56,689
performance hit and over time you can

262
00:10:54,019 --> 00:10:58,370
see this is a set random is that<font color="#E5E5E5"> I plot</font>

263
00:10:56,689 --> 00:11:00,170
<font color="#E5E5E5">it out you can see that</font><font color="#CCCCCC"> over time we</font>

264
00:10:58,370 --> 00:11:02,480
made it better and better and that's an

265
00:11:00,170 --> 00:11:05,360
ongoing process<font color="#E5E5E5"> attached gasps what we</font>

266
00:11:02,480 --> 00:11:07,279
do is we look at these gaps between v4

267
00:11:05,360 --> 00:11:11,689
and v6 and we try<font color="#E5E5E5"> to come up with</font><font color="#CCCCCC"> ways</font>

268
00:11:07,279 --> 00:11:13,879
that we can close this gap but it's a

269
00:11:11,689 --> 00:11:15,980
little bit<font color="#E5E5E5"> more complex for us I mean</font>

270
00:11:13,879 --> 00:11:18,019
resolving these issues<font color="#E5E5E5"> because we run</font>

271
00:11:15,980 --> 00:11:20,930
any cast and<font color="#E5E5E5"> this is usually the way</font>

272
00:11:18,019 --> 00:11:22,100
that I explain any cast a cube make made

273
00:11:20,930 --> 00:11:26,089
out of bulky<font color="#E5E5E5"> bolts</font>

274
00:11:22,100 --> 00:11:28,160
<font color="#E5E5E5">right and it's a stable system as long</font>

275
00:11:26,089 --> 00:11:30,259
<font color="#CCCCCC">as you don't introduce a change as soon</font>

276
00:11:28,160 --> 00:11:32,569
<font color="#CCCCCC">as you add a new pier or remove</font>

277
00:11:30,259 --> 00:11:35,000
something the whole cube changes the

278
00:11:32,569 --> 00:11:37,250
structure of your routing changes so you

279
00:11:35,000 --> 00:11:40,310
have to<font color="#E5E5E5"> be really careful about how to</font>

280
00:11:37,250 --> 00:11:42,860
add a new<font color="#E5E5E5"> player into an anycast mix and</font>

281
00:11:40,310 --> 00:11:44,888
that's why it's a little bit challenging

282
00:11:42,860 --> 00:11:48,170
for us and a<font color="#E5E5E5"> time-consuming</font><font color="#CCCCCC"> I should say</font>

283
00:11:44,889 --> 00:11:52,339
to be able<font color="#E5E5E5"> to fix all of the v6 peering</font>

284
00:11:48,170 --> 00:11:54,410
problems the<font color="#CCCCCC"> biggest enemy</font><font color="#E5E5E5"> of you have</font>

285
00:11:52,339 --> 00:11:57,170
any cast is there are your own local

286
00:11:54,410 --> 00:12:00,019
<font color="#E5E5E5">profs I'm very</font><font color="#CCCCCC"> excited to do this talk</font>

287
00:11:57,170 --> 00:12:01,910
here because look at<font color="#CCCCCC"> all the that</font>

288
00:12:00,019 --> 00:12:04,069
are present in this room and we either

289
00:12:01,910 --> 00:12:07,279
directly<font color="#E5E5E5"> pier with you or</font><font color="#CCCCCC"> only</font><font color="#E5E5E5"> one asla</font>

290
00:12:04,069 --> 00:12:10,819
and in our daily optimizations<font color="#CCCCCC"> there ton</font>

291
00:12:07,279 --> 00:12:12,500
of cases<font color="#CCCCCC"> that whatever change or perhaps</font>

292
00:12:10,819 --> 00:12:14,180
that you guys have in your no local

293
00:12:12,500 --> 00:12:17,089
networks are actually killing the

294
00:12:14,180 --> 00:12:19,219
anycast performance and I like to go

295
00:12:17,089 --> 00:12:22,190
back to<font color="#E5E5E5"> this topic</font><font color="#CCCCCC"> and maybe in another</font>

296
00:12:19,220 --> 00:12:24,709
talk and explain what are the things

297
00:12:22,190 --> 00:12:27,920
<font color="#E5E5E5">that you guys can do to help improve the</font>

298
00:12:24,709 --> 00:12:30,589
global anycast performance<font color="#E5E5E5"> all right the</font>

299
00:12:27,920 --> 00:12:32,689
<font color="#E5E5E5">last tool that we use the that we</font>

300
00:12:30,589 --> 00:12:35,569
couldn't use but as actually part of our

301
00:12:32,689 --> 00:12:37,099
used tool kit is a<font color="#E5E5E5"> TCP info we</font>

302
00:12:35,569 --> 00:12:39,979
internally we call it the awesome TV

303
00:12:37,100 --> 00:12:43,790
info because it gives the best value of

304
00:12:39,980 --> 00:12:47,079
looking at the behavior<font color="#CCCCCC"> of intra that</font>

305
00:12:43,790 --> 00:12:51,130
other global scale what we do is that we

306
00:12:47,079 --> 00:12:54,199
<font color="#CCCCCC">first publicly discuss this in the last</font>

307
00:12:51,130 --> 00:12:56,720
velocity conference in New York that's

308
00:12:54,199 --> 00:12:58,310
what I'm reiterating over that our chief

309
00:12:56,720 --> 00:13:00,380
architect Rob Peters had a very

310
00:12:58,310 --> 00:13:02,508
interesting talk about how we use the

311
00:13:00,380 --> 00:13:04,250
TCP info data basically the idea is that

312
00:13:02,509 --> 00:13:05,930
at the end of<font color="#E5E5E5"> the connection we capture</font>

313
00:13:04,250 --> 00:13:07,939
everything we know about that connection

314
00:13:05,930 --> 00:13:09,739
all the packets that were transferred

315
00:13:07,939 --> 00:13:12,050
the latency the<font color="#CCCCCC"> round-trip</font><font color="#E5E5E5"> the number of</font>

316
00:13:09,740 --> 00:13:15,130
retransmissions all that stuff and then

317
00:13:12,050 --> 00:13:18,170
we can do deep dive into<font color="#E5E5E5"> the global PCP</font>

318
00:13:15,130 --> 00:13:21,259
performance one of the<font color="#E5E5E5"> things that we do</font>

319
00:13:18,170 --> 00:13:24,649
with this data is that we map round<font color="#E5E5E5"> ship</font>

320
00:13:21,259 --> 00:13:26,630
based on the subnets so in if inside

321
00:13:24,649 --> 00:13:28,639
your network you<font color="#E5E5E5"> decide to route one</font>

322
00:13:26,630 --> 00:13:30,620
subnet and a different route than the

323
00:13:28,639 --> 00:13:32,480
other one it<font color="#E5E5E5"> will actually show up in</font>

324
00:13:30,620 --> 00:13:35,510
our latency differences charts and we

325
00:13:32,480 --> 00:13:38,030
know ahead<font color="#CCCCCC"> of the time that we know in</font>

326
00:13:35,510 --> 00:13:41,300
near<font color="#E5E5E5"> real time that you guys are making</font>

327
00:13:38,030 --> 00:13:43,430
these changes countless examples but

328
00:13:41,300 --> 00:13:44,959
we've had cases that you<font color="#CCCCCC"> know I squeezed</font>

329
00:13:43,430 --> 00:13:46,670
in Germany they had a problem<font color="#E5E5E5"> with the</font>

330
00:13:44,960 --> 00:13:48,230
line card they didn't know about it but

331
00:13:46,670 --> 00:13:50,540
the int latency<font color="#CCCCCC"> that they introduced</font>

332
00:13:48,230 --> 00:13:52,160
we're completely visible in these charts

333
00:13:50,540 --> 00:13:56,270
what but none of the monitoring

334
00:13:52,160 --> 00:13:58,780
platforms<font color="#E5E5E5"> of that</font><font color="#CCCCCC"> isp picked it up we</font>

335
00:13:56,270 --> 00:14:03,650
also do we started doing<font color="#E5E5E5"> some global</font>

336
00:13:58,780 --> 00:14:06,500
<font color="#E5E5E5">internet health studies this is an</font>

337
00:14:03,650 --> 00:14:09,079
interesting slide it's a<font color="#E5E5E5"> little bit off</font>

338
00:14:06,500 --> 00:14:13,580
topic<font color="#CCCCCC"> I have to skip a really fast but</font>

339
00:14:09,080 --> 00:14:16,340
we detected a lot of a certain anomaly

340
00:14:13,580 --> 00:14:19,010
in the internet that some folks are

341
00:14:16,340 --> 00:14:21,260
assassinating the window scaling bit to

342
00:14:19,010 --> 00:14:23,120
slow down the<font color="#CCCCCC"> internet</font><font color="#E5E5E5"> these are</font>

343
00:14:21,260 --> 00:14:25,819
corporates that are not<font color="#E5E5E5"> really happy</font>

344
00:14:23,120 --> 00:14:27,740
about users having exponential growth

345
00:14:25,820 --> 00:14:29,720
and<font color="#CCCCCC"> their TCP congestion window and</font>

346
00:14:27,740 --> 00:14:31,610
they're actually setting the congestion

347
00:14:29,720 --> 00:14:34,180
the window<font color="#E5E5E5"> is gaining bit on purpose</font>

348
00:14:31,610 --> 00:14:37,040
that's the optic at the end<font color="#E5E5E5"> of the chart</font>

349
00:14:34,180 --> 00:14:38,390
to slow down the connections and we're

350
00:14:37,040 --> 00:14:40,760
planning<font color="#CCCCCC"> to do a stubble talk around</font>

351
00:14:38,390 --> 00:14:44,689
this this is very interesting<font color="#CCCCCC"> all right</font>

352
00:14:40,760 --> 00:14:47,600
well let me go back<font color="#CCCCCC"> to the actual they</font>

353
00:14:44,690 --> 00:14:49,490
did the track of my talk it this is<font color="#E5E5E5"> the</font>

354
00:14:47,600 --> 00:14:51,980
problem<font color="#CCCCCC"> that we discussed we found a lot</font>

355
00:14:49,490 --> 00:14:54,530
<font color="#CCCCCC">of</font><font color="#E5E5E5"> sessions that were able</font><font color="#CCCCCC"> to complete</font>

356
00:14:51,980 --> 00:14:58,430
the v6 trace to us but we're not able<font color="#E5E5E5"> to</font>

357
00:14:54,530 --> 00:15:00,140
download the v6 object and we<font color="#E5E5E5"> were lucky</font>

358
00:14:58,430 --> 00:15:01,609
enough to be able to do some packet

359
00:15:00,140 --> 00:15:04,630
captures and we saw<font color="#E5E5E5"> something really</font>

360
00:15:01,610 --> 00:15:07,520
<font color="#E5E5E5">interesting when we sent the initial</font>

361
00:15:04,630 --> 00:15:10,580
congestion out initial congestion window

362
00:15:07,520 --> 00:15:12,470
out only few packets were acknowledged

363
00:15:10,580 --> 00:15:14,390
not all of them we were getting feedback

364
00:15:12,470 --> 00:15:16,250
back from the client but that was only

365
00:15:14,390 --> 00:15:18,140
for you for a few packets<font color="#CCCCCC"> not the entire</font>

366
00:15:16,250 --> 00:15:19,700
transmission well this<font color="#CCCCCC"> is a clear</font><font color="#E5E5E5"> sign</font>

367
00:15:18,140 --> 00:15:22,780
of a path and<font color="#CCCCCC"> two problem because if you</font>

368
00:15:19,700 --> 00:15:26,000
look<font color="#E5E5E5"> at</font><font color="#CCCCCC"> the trace again you only see a</font>

369
00:15:22,780 --> 00:15:27,620
sub MSS packets being acknowledged none

370
00:15:26,000 --> 00:15:29,600
of the<font color="#E5E5E5"> 1500 bite messages are being</font>

371
00:15:27,620 --> 00:15:31,250
acknowledged so that tells<font color="#E5E5E5"> us there's</font>

372
00:15:29,600 --> 00:15:33,410
probably a choke point there's a black

373
00:15:31,250 --> 00:15:37,280
hole in there in the path<font color="#CCCCCC"> that is not</font>

374
00:15:33,410 --> 00:15:38,810
happy with us sending the full MSS what

375
00:15:37,280 --> 00:15:42,589
the explanation<font color="#CCCCCC"> display</font><font color="#E5E5E5"> is pretty simple</font>

376
00:15:38,810 --> 00:15:46,170
<font color="#E5E5E5">right there has to be a v4 only internet</font>

377
00:15:42,590 --> 00:15:48,630
that cannot route these packets

378
00:15:46,170 --> 00:15:50,639
and someone had to<font color="#CCCCCC"> establish a tunnel</font>

379
00:15:48,630 --> 00:15:53,040
between these two points<font color="#E5E5E5"> in order to</font>

380
00:15:50,639 --> 00:15:55,110
make a uniform v6 connectivity between

381
00:15:53,040 --> 00:15:57,510
these two but the<font color="#E5E5E5"> problem with these</font>

382
00:15:55,110 --> 00:16:00,149
tunnels is that when you send the<font color="#CCCCCC"> 1,500</font>

383
00:15:57,510 --> 00:16:01,950
packet out the router the beginning<font color="#E5E5E5"> of</font>

384
00:16:00,149 --> 00:16:04,470
the tunnel has to inject its own header

385
00:16:01,950 --> 00:16:07,440
into it when we send a 1500 bytes out

386
00:16:04,470 --> 00:16:09,300
the router cannot inject anything more

387
00:16:07,440 --> 00:16:11,190
into the packet so will actually send

388
00:16:09,300 --> 00:16:13,560
you down send you a message that says

389
00:16:11,190 --> 00:16:16,440
slow down you have to lower your MTU

390
00:16:13,560 --> 00:16:18,359
this is this is a known issue in the

391
00:16:16,440 --> 00:16:21,060
internet and had been had been addressed

392
00:16:18,360 --> 00:16:23,399
before that's why the ICMP packet to big

393
00:16:21,060 --> 00:16:25,018
<font color="#E5E5E5">messages are for so it shouldn't break</font>

394
00:16:23,399 --> 00:16:27,000
the internet and we're curious to

395
00:16:25,019 --> 00:16:29,100
understand we're not filtering the

396
00:16:27,000 --> 00:16:31,649
message we know<font color="#CCCCCC"> that the ICMP is being</font>

397
00:16:29,100 --> 00:16:35,370
sent out why the connection is actually

398
00:16:31,649 --> 00:16:36,750
getting black hole so we<font color="#E5E5E5"> looked at the</font>

399
00:16:35,370 --> 00:16:38,880
server that was handling<font color="#E5E5E5"> the connection</font>

400
00:16:36,750 --> 00:16:41,430
it was in<font color="#E5E5E5"> Frankfurt the black hole</font>

401
00:16:38,880 --> 00:16:43,889
session was in Frankfurt we didn't see

402
00:16:41,430 --> 00:16:46,649
the ICMP packet we looked at all the

403
00:16:43,889 --> 00:16:49,649
servers in Frankfurt it was in there so

404
00:16:46,649 --> 00:16:51,810
we launched a global packet hunt for

405
00:16:49,649 --> 00:16:54,029
that ICMP message which is by itself is

406
00:16:51,810 --> 00:16:56,699
a very big challenge at a network at our

407
00:16:54,029 --> 00:16:58,740
size but we managed to<font color="#E5E5E5"> run that that</font>

408
00:16:56,699 --> 00:17:01,890
packet capture globally and we<font color="#E5E5E5"> found the</font>

409
00:16:58,740 --> 00:17:04,230
packet what we found it in Paris it<font color="#E5E5E5"> was</font>

410
00:17:01,890 --> 00:17:07,139
very<font color="#E5E5E5"> curious the</font><font color="#CCCCCC"> conde flow was in</font>

411
00:17:04,230 --> 00:17:10,770
<font color="#E5E5E5">Frankfurt but das ICMP telling us to</font>

412
00:17:07,140 --> 00:17:12,900
slow down was arrived in Paris why is

413
00:17:10,770 --> 00:17:16,770
that well the<font color="#CCCCCC"> answer is inside the</font>

414
00:17:12,900 --> 00:17:18,209
packet when you send out the offending

415
00:17:16,770 --> 00:17:22,199
packet let's call it the one that is

416
00:17:18,209 --> 00:17:23,480
<font color="#E5E5E5">sending out at 1500 by the size you're</font>

417
00:17:22,199 --> 00:17:26,579
so seeing it from the anycast address

418
00:17:23,480 --> 00:17:28,620
towards the client but when<font color="#CCCCCC"> the icy</font>

419
00:17:26,579 --> 00:17:30,240
jacket is coming back it's from a

420
00:17:28,620 --> 00:17:33,928
different source it's from the router

421
00:17:30,240 --> 00:17:37,049
itself and it happens in that scenario

422
00:17:33,929 --> 00:17:38,309
that the router itself was making it was

423
00:17:37,049 --> 00:17:40,410
actually looking into<font color="#CCCCCC"> a different</font>

424
00:17:38,309 --> 00:17:43,139
routing table to make routing decisions

425
00:17:40,410 --> 00:17:46,710
for its own IP address it was<font color="#E5E5E5"> completely</font>

426
00:17:43,140 --> 00:17:48,480
<font color="#E5E5E5">in a different routing table so we have</font>

427
00:17:46,710 --> 00:17:49,740
<font color="#CCCCCC">different peering policies anycast</font>

428
00:17:48,480 --> 00:17:51,720
behaves differently on<font color="#CCCCCC"> there for</font>

429
00:17:49,740 --> 00:17:53,669
networks so we ended up that the actual

430
00:17:51,720 --> 00:17:55,440
<font color="#CCCCCC">is client</font><font color="#E5E5E5"> 20 cash flow was in</font><font color="#CCCCCC"> Frankfurt</font>

431
00:17:53,669 --> 00:17:58,919
but the router to any cash flow was<font color="#E5E5E5"> in</font>

432
00:17:55,440 --> 00:17:59,640
Paris we managed<font color="#CCCCCC"> to fix that on</font><font color="#E5E5E5"> this one</font>

433
00:17:58,919 --> 00:18:02,190
in

434
00:17:59,640 --> 00:18:03,960
since this was actually a hurricane

435
00:18:02,190 --> 00:18:06,930
electric and we were able to address

436
00:18:03,960 --> 00:18:10,230
this issue with working<font color="#CCCCCC"> with them</font>

437
00:18:06,930 --> 00:18:12,240
directly but again<font color="#CCCCCC"> going back</font><font color="#E5E5E5"> to the</font>

438
00:18:10,230 --> 00:18:14,010
flow the packet didn't arrive on the

439
00:18:12,240 --> 00:18:17,820
same server it was<font color="#E5E5E5"> delivered to</font>

440
00:18:14,010 --> 00:18:19,860
<font color="#CCCCCC">Frankfurt but not to the right server so</font>

441
00:18:17,820 --> 00:18:22,110
we thought<font color="#CCCCCC"> that there must be something</font>

442
00:18:19,860 --> 00:18:25,560
else<font color="#E5E5E5"> going on there we look deeper and</font>

443
00:18:22,110 --> 00:18:27,629
we<font color="#CCCCCC"> notice that one of our systems we</font>

444
00:18:25,560 --> 00:18:30,030
<font color="#E5E5E5">have multiple layers of load balancing</font>

445
00:18:27,630 --> 00:18:32,580
one of the layers is doing is the source

446
00:18:30,030 --> 00:18:34,800
destination based hashing and what

447
00:18:32,580 --> 00:18:36,120
happens is that the load balancer looks

448
00:18:34,800 --> 00:18:37,620
at the source and<font color="#E5E5E5"> destination of the</font>

449
00:18:36,120 --> 00:18:41,280
packet to make the routing decision

450
00:18:37,620 --> 00:18:43,590
forwarding decision but the ICMP packet

451
00:18:41,280 --> 00:18:45,090
that is arriving is this is sourced from

452
00:18:43,590 --> 00:18:46,530
a different<font color="#CCCCCC"> addresses source from the</font>

453
00:18:45,090 --> 00:18:49,949
router address so we<font color="#CCCCCC"> will map</font>

454
00:18:46,530 --> 00:18:54,690
differently to a different path and it

455
00:18:49,950 --> 00:18:56,910
ever makes it to the actual server the

456
00:18:54,690 --> 00:18:58,800
<font color="#E5E5E5">solution</font><font color="#CCCCCC"> to this is different</font><font color="#E5E5E5"> from</font>

457
00:18:56,910 --> 00:19:02,490
deployment to deployment it depends on

458
00:18:58,800 --> 00:19:05,450
what kind of router or load balancing

459
00:19:02,490 --> 00:19:08,990
you're using so<font color="#CCCCCC"> I can't talk about</font>

460
00:19:05,450 --> 00:19:12,630
<font color="#E5E5E5">specifics of your network but generally</font>

461
00:19:08,990 --> 00:19:15,090
one of the ideas is that we have<font color="#CCCCCC"> to look</font>

462
00:19:12,630 --> 00:19:17,820
deeper and we have to<font color="#E5E5E5"> look inside the</font>

463
00:19:15,090 --> 00:19:20,159
ICMP packet to make forwarding decisions

464
00:19:17,820 --> 00:19:21,389
based on the offending packet because

465
00:19:20,160 --> 00:19:23,670
the offending packet is actually a

466
00:19:21,390 --> 00:19:27,960
snapshot of it is including in the ICMP

467
00:19:23,670 --> 00:19:31,920
packet<font color="#CCCCCC"> all right so how can we</font><font color="#E5E5E5"> fix this</font>

468
00:19:27,960 --> 00:19:34,770
and how big<font color="#E5E5E5"> of a problem this</font><font color="#CCCCCC"> is the</font>

469
00:19:31,920 --> 00:19:38,340
<font color="#E5E5E5">simplest solution is the RFC itself the</font>

470
00:19:34,770 --> 00:19:42,660
RFC says that 1280 is the safest MTU and

471
00:19:38,340 --> 00:19:44,520
the<font color="#CCCCCC"> internet in the v6 internet so all</font>

472
00:19:42,660 --> 00:19:48,740
the nodes have to be capable<font color="#CCCCCC"> of</font>

473
00:19:44,520 --> 00:19:51,570
transferring 12 messages with 1280<font color="#E5E5E5"> sites</font>

474
00:19:48,740 --> 00:19:54,360
the bigger<font color="#E5E5E5"> problem is that this</font><font color="#CCCCCC"> is</font>

475
00:19:51,570 --> 00:19:56,040
happening in v4 address space as well

476
00:19:54,360 --> 00:19:58,590
the same problem<font color="#CCCCCC"> that i just explained</font>

477
00:19:56,040 --> 00:20:01,200
<font color="#CCCCCC">can happen in before as well and it is</font>

478
00:19:58,590 --> 00:20:03,419
happening one of our synthetic platforms

479
00:20:01,200 --> 00:20:05,880
is catch point they<font color="#CCCCCC"> recently launched a</font>

480
00:20:03,420 --> 00:20:07,970
note in<font color="#CCCCCC"> Iceland and it was amazing</font>

481
00:20:05,880 --> 00:20:10,530
because as soon as they launched a note

482
00:20:07,970 --> 00:20:12,830
we received the ticket from them that<font color="#E5E5E5"> it</font>

483
00:20:10,530 --> 00:20:15,379
said you know we can't get to etch gas

484
00:20:12,830 --> 00:20:17,360
<font color="#CCCCCC">cannock to get to yahoo we can get</font><font color="#E5E5E5"> to a</font>

485
00:20:15,380 --> 00:20:20,990
lot<font color="#E5E5E5"> of</font><font color="#CCCCCC"> different sites</font><font color="#E5E5E5"> and it seemed</font>

486
00:20:17,360 --> 00:20:23,149
that<font color="#E5E5E5"> it this is a you know not in first</font>

487
00:20:20,990 --> 00:20:24,289
it happens in before as well and second

488
00:20:23,149 --> 00:20:28,850
of all is that there<font color="#E5E5E5"> are a lot of folks</font>

489
00:20:24,289 --> 00:20:30,320
out there<font color="#CCCCCC"> that have this</font><font color="#E5E5E5"> issue so the</font>

490
00:20:28,850 --> 00:20:32,000
suggestions that<font color="#CCCCCC"> I have</font><font color="#E5E5E5"> for you i mean</font>

491
00:20:30,320 --> 00:20:33,639
<font color="#E5E5E5">the solutions to address to sue this</font>

492
00:20:32,000 --> 00:20:36,860
problem is it's different per

493
00:20:33,640 --> 00:20:39,590
implementation but generally what i can

494
00:20:36,860 --> 00:20:41,479
recommend is<font color="#CCCCCC"> that if you have if you run</font>

495
00:20:39,590 --> 00:20:43,730
an<font color="#CCCCCC"> anycast network look for these</font>

496
00:20:41,480 --> 00:20:45,860
orphaned icmp packets that arrive

497
00:20:43,730 --> 00:20:48,049
somewhere in your network with no

498
00:20:45,860 --> 00:20:50,689
matching<font color="#E5E5E5"> flow there could be sign of an</font>

499
00:20:48,049 --> 00:20:52,639
attack for sure but if they're

500
00:20:50,690 --> 00:20:55,010
legitimate and you have a flow somewhere

501
00:20:52,639 --> 00:20:57,320
else in your network this ICMP packet is

502
00:20:55,010 --> 00:20:59,149
telling you something that that<font color="#E5E5E5"> probe</font>

503
00:20:57,320 --> 00:21:03,260
<font color="#E5E5E5">that the initial the actual flow is</font>

504
00:20:59,149 --> 00:21:05,600
suffering from a path MTU problem the

505
00:21:03,260 --> 00:21:09,260
other<font color="#E5E5E5"> idea is that you can set up last</font>

506
00:21:05,600 --> 00:21:12,799
mile tests and compare your availability

507
00:21:09,260 --> 00:21:14,299
between any caste and unicast if<font color="#E5E5E5"> going</font>

508
00:21:12,799 --> 00:21:17,059
directly to the servers are going

509
00:21:14,299 --> 00:21:19,668
directly to your pops shows higher

510
00:21:17,059 --> 00:21:22,279
availability than going to the anycast

511
00:21:19,669 --> 00:21:24,440
address that's another indication that

512
00:21:22,279 --> 00:21:26,539
any<font color="#CCCCCC"> caste routing is basically sending</font>

513
00:21:24,440 --> 00:21:29,750
the package icmp packets to<font color="#CCCCCC"> the wrong</font>

514
00:21:26,539 --> 00:21:32,240
place another solution to this problem

515
00:21:29,750 --> 00:21:35,710
<font color="#E5E5E5">is empty you probing this was deployed</font>

516
00:21:32,240 --> 00:21:38,330
in<font color="#E5E5E5"> linux kernel a long time ago and</font>

517
00:21:35,710 --> 00:21:40,870
general idea is that they look for black

518
00:21:38,330 --> 00:21:43,220
holing signatures if they see packets

519
00:21:40,870 --> 00:21:45,260
that are being acknowledged in the same

520
00:21:43,220 --> 00:21:47,779
way that<font color="#CCCCCC"> i</font><font color="#E5E5E5"> explain what happens is that</font>

521
00:21:45,260 --> 00:21:50,149
these packets the<font color="#E5E5E5"> systems will actually</font>

522
00:21:47,779 --> 00:21:54,799
start lowering the MTO based on a set

523
00:21:50,149 --> 00:21:57,799
speed and try out those steps it brings

524
00:21:54,799 --> 00:22:00,110
<font color="#E5E5E5">up your availability but</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> problem is</font>

525
00:21:57,799 --> 00:22:02,658
it will cost your real response time

526
00:22:00,110 --> 00:22:05,658
because the<font color="#CCCCCC"> MTU tables are very</font>

527
00:22:02,659 --> 00:22:07,070
aggressive<font color="#CCCCCC"> and you can see this this tcp</font>

528
00:22:05,659 --> 00:22:09,799
chart of that connection it'll actually

529
00:22:07,070 --> 00:22:13,850
takes a long time to be able<font color="#E5E5E5"> to ramp up</font>

530
00:22:09,799 --> 00:22:16,720
and deliver the object<font color="#CCCCCC"> all right that</font>

531
00:22:13,850 --> 00:22:20,809
was my last slide thanks for<font color="#E5E5E5"> your time</font>

532
00:22:16,720 --> 00:22:23,470
<font color="#CCCCCC">I'll be happy to</font><font color="#E5E5E5"> take questions you can</font>

533
00:22:20,809 --> 00:22:23,470
take questions now

534
00:22:30,130 --> 00:22:37,820
<font color="#E5E5E5">Leo</font><font color="#CCCCCC"> McNall Farsight security the root</font>

535
00:22:35,960 --> 00:22:40,730
name server operators have been any

536
00:22:37,820 --> 00:22:43,299
casting for quite a while and there has

537
00:22:40,730 --> 00:22:47,059
<font color="#CCCCCC">been great debate over the years about</font>

538
00:22:43,299 --> 00:22:49,100
the impact of any cast on that<font color="#E5E5E5"> service</font>

539
00:22:47,059 --> 00:22:53,110
and they have investigated many of these

540
00:22:49,100 --> 00:22:57,020
probably more focused in v4 than in v6

541
00:22:53,110 --> 00:23:00,409
<font color="#E5E5E5">the interesting conclusions there is</font>

542
00:22:57,020 --> 00:23:03,799
that of course the longer duration of

543
00:23:00,410 --> 00:23:06,520
your<font color="#CCCCCC"> TCP connection the more likely it</font>

544
00:23:03,799 --> 00:23:08,980
is to be clobbered in an anycast world

545
00:23:06,520 --> 00:23:11,120
because of instability in the<font color="#E5E5E5"> network</font>

546
00:23:08,980 --> 00:23:14,059
causing these<font color="#CCCCCC"> return packets to go to</font>

547
00:23:11,120 --> 00:23:16,219
the wrong place<font color="#E5E5E5"> and so the general</font>

548
00:23:14,059 --> 00:23:18,918
thought is that<font color="#E5E5E5"> if you're going</font><font color="#CCCCCC"> to</font><font color="#E5E5E5"> do</font>

549
00:23:16,220 --> 00:23:20,960
any cast for<font color="#CCCCCC"> tcp you should do it for</font>

550
00:23:18,919 --> 00:23:23,630
very short-lived connections for

551
00:23:20,960 --> 00:23:26,299
instance if you<font color="#E5E5E5"> wanted to serve up a six</font>

552
00:23:23,630 --> 00:23:29,179
hundred megabyte<font color="#E5E5E5"> ISO image or something</font>

553
00:23:26,299 --> 00:23:31,340
you would any cast a HTTP connection

554
00:23:29,179 --> 00:23:33,290
that was a 302 redirect to<font color="#CCCCCC"> the server</font>

555
00:23:31,340 --> 00:23:35,689
sitting right next to<font color="#CCCCCC"> it that was a</font>

556
00:23:33,290 --> 00:23:36,889
standard unicast connection so my

557
00:23:35,690 --> 00:23:39,440
question kind of comes are you<font color="#E5E5E5"> really</font>

558
00:23:36,890 --> 00:23:41,960
trying<font color="#E5E5E5"> to any cast all of your content</font>

559
00:23:39,440 --> 00:23:43,790
because that sounds very risky based on

560
00:23:41,960 --> 00:23:47,140
what I've heard are you are you any

561
00:23:43,790 --> 00:23:49,668
casting redirections to the<font color="#E5E5E5"> actual</font>

562
00:23:47,140 --> 00:23:52,309
content involved and and have you looked

563
00:23:49,669 --> 00:23:54,669
at any<font color="#E5E5E5"> of that root name server research</font>

564
00:23:52,309 --> 00:23:57,020
along with us I looked at with seven

565
00:23:54,669 --> 00:23:59,179
studies for a different purpose because

566
00:23:57,020 --> 00:24:01,429
ripe has a very<font color="#CCCCCC"> interesting model for</font>

567
00:23:59,179 --> 00:24:03,110
the announcements and how they because

568
00:24:01,429 --> 00:24:05,270
ripe has global instances of local

569
00:24:03,110 --> 00:24:07,428
instances and how they<font color="#CCCCCC"> manage to</font><font color="#E5E5E5"> make</font>

570
00:24:05,270 --> 00:24:09,230
<font color="#E5E5E5">sure that their global instances don't</font>

571
00:24:07,429 --> 00:24:10,880
get majority of the traffic<font color="#E5E5E5"> and they can</font>

572
00:24:09,230 --> 00:24:13,309
absorb local traffic into locals ones

573
00:24:10,880 --> 00:24:17,030
looked at it from that perspective but

574
00:24:13,309 --> 00:24:19,399
not from this the general idea<font color="#E5E5E5"> is that a</font>

575
00:24:17,030 --> 00:24:21,440
side note is that the performance<font color="#CCCCCC"> of</font>

576
00:24:19,400 --> 00:24:23,419
these root servers are not the same the

577
00:24:21,440 --> 00:24:25,910
performance of these nodes are not the

578
00:24:23,419 --> 00:24:29,690
same so it is extremely important to

579
00:24:25,910 --> 00:24:31,820
land on the right cluster it's a bigger

580
00:24:29,690 --> 00:24:34,520
problem with<font color="#E5E5E5"> the</font><font color="#CCCCCC"> gtld than what it is</font>

581
00:24:31,820 --> 00:24:37,309
with the root servers because<font color="#CCCCCC"> gTLD if</font>

582
00:24:34,520 --> 00:24:39,530
you look at individual<font color="#CCCCCC"> gtld responses</font>

583
00:24:37,309 --> 00:24:42,139
they're very different especially<font color="#CCCCCC"> the</font>

584
00:24:39,530 --> 00:24:44,510
note that runs out of<font color="#CCCCCC"> Japan</font>

585
00:24:42,140 --> 00:24:48,890
it's<font color="#E5E5E5"> not a match for</font><font color="#CCCCCC"> the rest of the</font>

586
00:24:44,510 --> 00:24:54,350
notes longleaf<font color="#E5E5E5"> TCP connections yes the</font>

587
00:24:48,890 --> 00:24:56,480
risk is there the we do a little bit of

588
00:24:54,350 --> 00:24:59,240
the inside trick on how to make sure

589
00:24:56,480 --> 00:25:02,060
that the connection as long as it's

590
00:24:59,240 --> 00:25:06,830
within<font color="#E5E5E5"> the same pop gets the right</font>

591
00:25:02,060 --> 00:25:09,800
server even<font color="#CCCCCC"> after the internal changes</font>

592
00:25:06,830 --> 00:25:13,570
that we make to the pop hour traffic

593
00:25:09,800 --> 00:25:16,790
distribution is based on multiple layers

594
00:25:13,570 --> 00:25:18,950
but any cast is primarily the way we're

595
00:25:16,790 --> 00:25:21,649
out the objects in<font color="#E5E5E5"> there inside one</font>

596
00:25:18,950 --> 00:25:24,080
region and<font color="#E5E5E5"> I agree with you any any</font>

597
00:25:21,650 --> 00:25:25,480
change on over a<font color="#E5E5E5"> long live TCP</font>

598
00:25:24,080 --> 00:25:29,540
connection can I can make this happen

599
00:25:25,480 --> 00:25:31,640
<font color="#CCCCCC">but I wish I had that chart it's very</font>

600
00:25:29,540 --> 00:25:33,980
amazing when we looked at the<font color="#CCCCCC"> TCP data</font>

601
00:25:31,640 --> 00:25:36,790
and we looked at the total bytes that

602
00:25:33,980 --> 00:25:41,210
were transferred into each connection

603
00:25:36,790 --> 00:25:43,970
internet is amazingly very small when<font color="#E5E5E5"> we</font>

604
00:25:41,210 --> 00:25:46,040
give you this the metric more than

605
00:25:43,970 --> 00:25:48,920
<font color="#CCCCCC">eighty two percent of all the</font>

606
00:25:46,040 --> 00:25:52,490
connections that<font color="#E5E5E5"> we serve they fit into</font>

607
00:25:48,920 --> 00:25:54,320
one tcp burst so the<font color="#E5E5E5"> client never goes</font>

608
00:25:52,490 --> 00:25:57,920
back to actually request the second

609
00:25:54,320 --> 00:26:01,550
burst yes it's as if<font color="#CCCCCC"> this is a 600 Meg</font>

610
00:25:57,920 --> 00:26:03,980
file and you expand it over minutes and

611
00:26:01,550 --> 00:26:05,450
hours and any change in<font color="#E5E5E5"> the network</font>

612
00:26:03,980 --> 00:26:09,500
happens yes you will end up going<font color="#CCCCCC"> to the</font>

613
00:26:05,450 --> 00:26:12,320
right wrong pop but this is surprisingly

614
00:26:09,500 --> 00:26:14,620
a very very small percentage that<font color="#CCCCCC"> the</font>

615
00:26:12,320 --> 00:26:17,149
very long tail<font color="#CCCCCC"> of the connections</font>

616
00:26:14,620 --> 00:26:18,409
<font color="#CCCCCC">alright since there's no one else up</font>

617
00:26:17,150 --> 00:26:22,820
here<font color="#CCCCCC"> I'll make my one other comment</font>

618
00:26:18,410 --> 00:26:25,340
which was buried<font color="#E5E5E5"> in the details of why</font>

619
00:26:22,820 --> 00:26:28,250
that packet<font color="#E5E5E5"> to big message comes back is</font>

620
00:26:25,340 --> 00:26:30,439
actually a subtle difference in v6 that

621
00:26:28,250 --> 00:26:33,290
<font color="#CCCCCC">I think many people haven't gotten their</font>

622
00:26:30,440 --> 00:26:36,200
mind around yet and that<font color="#CCCCCC"> is in v4 we can</font>

623
00:26:33,290 --> 00:26:38,870
send<font color="#E5E5E5"> out a packet that is 1500 bytes and</font>

624
00:26:36,200 --> 00:26:40,780
allow<font color="#CCCCCC"> it to be fragmented and if there's</font>

625
00:26:38,870 --> 00:26:43,459
a tunnel it will go on its merry way in

626
00:26:40,780 --> 00:26:45,889
v6 there is no fragmentation at

627
00:26:43,460 --> 00:26:48,530
intermediate nodes and so you will<font color="#E5E5E5"> get</font>

628
00:26:45,890 --> 00:26:50,480
many more packet<font color="#E5E5E5"> two bigs in v6 than you</font>

629
00:26:48,530 --> 00:26:51,440
have gotten in before particularly<font color="#E5E5E5"> with</font>

630
00:26:50,480 --> 00:26:55,009
the tunneling since you

631
00:26:51,440 --> 00:26:57,080
which really accentuates this problem it

632
00:26:55,009 --> 00:26:59,090
also accentuates the standard black

633
00:26:57,080 --> 00:27:02,480
holing problem of people filtering

634
00:26:59,090 --> 00:27:04,070
packet too big and stalling and so

635
00:27:02,480 --> 00:27:06,230
<font color="#E5E5E5">studying both of those on the v6 and</font>

636
00:27:04,070 --> 00:27:07,570
comparing to v4 is is interesting i'd

637
00:27:06,230 --> 00:27:09,889
like to see more charts about that

638
00:27:07,570 --> 00:27:14,080
thanks for my information again it's a

639
00:27:09,889 --> 00:27:14,080
good point<font color="#E5E5E5"> all right thank</font><font color="#CCCCCC"> you</font><font color="#E5E5E5"> the</font><font color="#CCCCCC"> same</font>

640
00:27:22,690 --> 00:27:24,750
you

