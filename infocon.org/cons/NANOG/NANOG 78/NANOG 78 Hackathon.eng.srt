1
00:00:10,250 --> 00:00:15,049
so good morning welcome everybody thank

2
00:00:12,620 --> 00:00:17,299
you all for coming out for the for the

3
00:00:15,049 --> 00:00:21,380
hackathon my name is Ian Flint and I

4
00:00:17,300 --> 00:00:23,810
work for Verizon media which is in our

5
00:00:21,380 --> 00:00:30,140
case it's the combination of Yahoo and

6
00:00:23,810 --> 00:00:32,150
edge cast the edge cast CDN so today we

7
00:00:30,140 --> 00:00:35,510
are going to be hacking I got a little

8
00:00:32,150 --> 00:00:38,269
feedback that way we're going to be

9
00:00:35,510 --> 00:00:40,629
hacking on Panoptix and so I'd like to

10
00:00:38,269 --> 00:00:44,329
talk a little bit about Panoptix

11
00:00:40,629 --> 00:00:47,660
Panoptix is our open source monitoring

12
00:00:44,329 --> 00:00:50,020
platform I was built by the the team and

13
00:00:47,660 --> 00:00:52,099
we open sourced it I about two years ago

14
00:00:50,020 --> 00:00:54,230
and what it is the problem we were

15
00:00:52,100 --> 00:00:55,850
trying to solve was we had a bunch of

16
00:00:54,230 --> 00:00:57,529
different Polar's bunch of different

17
00:00:55,850 --> 00:00:59,120
metric systems that were hitting our

18
00:00:57,530 --> 00:00:59,989
routers some of our routers were being

19
00:00:59,120 --> 00:01:02,419
over polled

20
00:00:59,989 --> 00:01:04,849
four or five systems hitting them at the

21
00:01:02,420 --> 00:01:07,340
same time and so what we needed to build

22
00:01:04,849 --> 00:01:10,250
was we needed to build a system that

23
00:01:07,340 --> 00:01:14,450
could both whole network devices but

24
00:01:10,250 --> 00:01:17,090
also had an a distribution bus and the

25
00:01:14,450 --> 00:01:18,470
ability to build different clients to do

26
00:01:17,090 --> 00:01:19,549
different things with those metrics so

27
00:01:18,470 --> 00:01:22,939
for example you might pull something

28
00:01:19,549 --> 00:01:24,680
once and send the metric to a capacity

29
00:01:22,939 --> 00:01:27,289
planning systems and the thing to an

30
00:01:24,680 --> 00:01:29,840
anomaly detection system send it to a

31
00:01:27,290 --> 00:01:31,369
graphing system so you can you know

32
00:01:29,840 --> 00:01:33,710
actually see what's going on so the idea

33
00:01:31,369 --> 00:01:35,659
was rather than having separate polling

34
00:01:33,710 --> 00:01:37,820
for every single system that needed this

35
00:01:35,659 --> 00:01:41,810
data that you'd have a single polling

36
00:01:37,820 --> 00:01:43,789
agent with a distribution bus and and in

37
00:01:41,810 --> 00:01:45,799
order to do that we also needed to build

38
00:01:43,790 --> 00:01:47,990
some other features into it needed to

39
00:01:45,799 --> 00:01:49,520
have enrichment so you get your data you

40
00:01:47,990 --> 00:01:51,829
know maybe you know that this particular

41
00:01:49,520 --> 00:01:53,210
interface is doing a certain amount of

42
00:01:51,829 --> 00:01:55,880
traffic you want to say what is that

43
00:01:53,210 --> 00:01:58,639
interface connected to which client is

44
00:01:55,880 --> 00:02:01,039
using it and so we're able to enrich the

45
00:01:58,640 --> 00:02:02,479
data as it comes through and and make it

46
00:02:01,040 --> 00:02:05,750
more meaningful to the downstream

47
00:02:02,479 --> 00:02:08,060
systems and finally when we open sourced

48
00:02:05,750 --> 00:02:10,369
it you know no monitoring system is good

49
00:02:08,060 --> 00:02:12,560
without visualization and so we stuck a

50
00:02:10,369 --> 00:02:14,570
visualization system on it we did a and

51
00:02:12,560 --> 00:02:20,810
integration with influx DB so out of the

52
00:02:14,570 --> 00:02:21,049
box you have a influx DB integration so

53
00:02:20,810 --> 00:02:26,000
what

54
00:02:21,050 --> 00:02:27,380
makes it special its able to scale in

55
00:02:26,000 --> 00:02:29,360
our case it's really big we're

56
00:02:27,380 --> 00:02:32,240
monitoring tens of thousands of network

57
00:02:29,360 --> 00:02:38,150
elements and we're doing I think on the

58
00:02:32,240 --> 00:02:41,030
order of 30 to 40 actual metrics per

59
00:02:38,150 --> 00:02:42,710
interface across our entire network and

60
00:02:41,030 --> 00:02:45,080
so there's a lot of data flowing through

61
00:02:42,710 --> 00:02:47,210
the system battle-tested we've been

62
00:02:45,080 --> 00:02:49,760
running it in production for a couple of

63
00:02:47,210 --> 00:02:51,980
years now and you know not without its

64
00:02:49,760 --> 00:02:53,899
hiccups but but we've definitely you

65
00:02:51,980 --> 00:02:56,030
know it's it's been through sort of the

66
00:02:53,900 --> 00:02:58,850
production wringer and we've proven it

67
00:02:56,030 --> 00:03:01,340
so you know if you were to adopt that

68
00:02:58,850 --> 00:03:03,049
you would have reasonable assurances

69
00:03:01,340 --> 00:03:05,660
that it would work in your in your

70
00:03:03,050 --> 00:03:07,850
environment plug in the architecture

71
00:03:05,660 --> 00:03:11,000
this is huge so this is the ability to

72
00:03:07,850 --> 00:03:13,730
arbitrarily extend the system to do

73
00:03:11,000 --> 00:03:17,090
whatever you want so if you want to do

74
00:03:13,730 --> 00:03:20,630
GN mi for example and actually take

75
00:03:17,090 --> 00:03:23,360
streaming telemetry pluggin bring in the

76
00:03:20,630 --> 00:03:25,310
streaming telemetry and and you can

77
00:03:23,360 --> 00:03:28,010
translate it to a universal format and

78
00:03:25,310 --> 00:03:29,840
put it on our data bus if you want to do

79
00:03:28,010 --> 00:03:31,489
a special enrichment you've got special

80
00:03:29,840 --> 00:03:33,590
information you want to tack on to your

81
00:03:31,489 --> 00:03:34,970
metrics the facilities are there to be

82
00:03:33,590 --> 00:03:37,640
able to do that if you want to integrate

83
00:03:34,970 --> 00:03:39,440
with your own visualization system or

84
00:03:37,640 --> 00:03:41,238
your own alerting system there's a

85
00:03:39,440 --> 00:03:44,060
plug-in spot there where you can

86
00:03:41,239 --> 00:03:45,970
actually plug in and do that so the

87
00:03:44,060 --> 00:03:48,410
plug-in architecture is very powerful

88
00:03:45,970 --> 00:03:53,359
and finally it's open source so anybody

89
00:03:48,410 --> 00:03:56,570
can use it so scale I talked a little

90
00:03:53,360 --> 00:03:58,130
about this on the order of 10 million

91
00:03:56,570 --> 00:04:01,100
time series are flowing through it right

92
00:03:58,130 --> 00:04:02,959
now in our production environment we're

93
00:04:01,100 --> 00:04:05,420
monitoring hundreds of thousands of

94
00:04:02,959 --> 00:04:08,780
network interfaces tens of thousands of

95
00:04:05,420 --> 00:04:11,450
network devices and this is interesting

96
00:04:08,780 --> 00:04:13,610
distributed across hundreds of sites and

97
00:04:11,450 --> 00:04:14,958
so you know we actually have a global

98
00:04:13,610 --> 00:04:16,940
footprint of this that's that's

99
00:04:14,959 --> 00:04:18,738
monitoring stuff across every single pop

100
00:04:16,940 --> 00:04:24,020
every single data center that that

101
00:04:18,738 --> 00:04:26,599
Verizon media has and how's it evolving

102
00:04:24,020 --> 00:04:28,340
so actually Panoptix has been a journey

103
00:04:26,600 --> 00:04:31,070
that nanog has gotten to witness

104
00:04:28,340 --> 00:04:33,799
firsthand we actually announced Panoptix

105
00:04:31,070 --> 00:04:35,900
in 2017

106
00:04:33,800 --> 00:04:39,050
one of the Nanak's a 20-18 we open

107
00:04:35,900 --> 00:04:42,109
sourced it announced it here we spun a

108
00:04:39,050 --> 00:04:44,210
docker image in 2019 to make it more

109
00:04:42,110 --> 00:04:47,090
accessible to customers and easier to

110
00:04:44,210 --> 00:04:50,270
install and work with and this year

111
00:04:47,090 --> 00:04:53,780
we've been working on open sourcing our

112
00:04:50,270 --> 00:04:54,979
plugins so we originally and release

113
00:04:53,780 --> 00:04:56,270
monopolies without a whole lot of

114
00:04:54,979 --> 00:04:58,758
plugins without a whole lot of

115
00:04:56,270 --> 00:05:01,068
integrations but we've been working on

116
00:04:58,759 --> 00:05:02,629
open sourcing as many of these plugins

117
00:05:01,069 --> 00:05:04,550
so that you have good functionality out

118
00:05:02,629 --> 00:05:09,469
of the box and you're able to monitor

119
00:05:04,550 --> 00:05:12,039
real networked devices and so the team

120
00:05:09,469 --> 00:05:14,960
me I don't really do anything

121
00:05:12,039 --> 00:05:17,389
we've got Varun rune can you raise your

122
00:05:14,960 --> 00:05:23,599
hand please Bruna in the back there so

123
00:05:17,389 --> 00:05:25,960
he is the architect of panopticon right

124
00:05:23,599 --> 00:05:30,878
here back there

125
00:05:25,960 --> 00:05:34,128
Nathan and Ian right here and James are

126
00:05:30,879 --> 00:05:35,870
the active Panoptix team right now

127
00:05:34,129 --> 00:05:37,069
within Yahoo so they're the ones

128
00:05:35,870 --> 00:05:38,659
actually doing the work and they're the

129
00:05:37,069 --> 00:05:41,630
ones who will be walking around helping

130
00:05:38,659 --> 00:05:43,159
you out as you start to kick the tires

131
00:05:41,630 --> 00:05:47,599
on this infrastructure and figure out

132
00:05:43,159 --> 00:05:49,719
how it works that is all I got with that

133
00:05:47,599 --> 00:06:05,180
I'm gonna hand it off to Varun Verma to

134
00:05:49,719 --> 00:06:08,900
talk about the architecture thanks to

135
00:06:05,180 --> 00:06:11,330
him I guess my name is Varun like you

136
00:06:08,900 --> 00:06:13,779
mentioned you know I'd hired me into the

137
00:06:11,330 --> 00:06:15,650
team I believe late 2015

138
00:06:13,779 --> 00:06:18,229
describing all the problems that you

139
00:06:15,650 --> 00:06:20,179
describe the problem wasn't that we

140
00:06:18,229 --> 00:06:23,090
didn't have one shrink the problem is we

141
00:06:20,180 --> 00:06:24,620
had too much of it we had you know 78

142
00:06:23,090 --> 00:06:26,479
different systems all trying to do

143
00:06:24,620 --> 00:06:28,190
similar things if not exactly the same

144
00:06:26,479 --> 00:06:30,349
thing and the idea was to build

145
00:06:28,190 --> 00:06:32,180
something that unifies them collects

146
00:06:30,349 --> 00:06:35,240
data wants but lets you do interesting

147
00:06:32,180 --> 00:06:37,759
things after you connect the data there

148
00:06:35,240 --> 00:06:38,930
is one small thing I now work for

149
00:06:37,759 --> 00:06:42,500
LinkedIn but I never asked them

150
00:06:38,930 --> 00:06:43,470
permission for this event so I ignore

151
00:06:42,500 --> 00:06:46,370
that

152
00:06:43,470 --> 00:06:49,950
and Linkedin does not use properties so

153
00:06:46,370 --> 00:06:55,920
yeah so let's just call me a monitoring

154
00:06:49,950 --> 00:06:58,680
enthusiast okay with that let's get into

155
00:06:55,920 --> 00:07:00,540
the architecture this is going to be a

156
00:06:58,680 --> 00:07:03,030
lot to take in to be very honest but not

157
00:07:00,540 --> 00:07:05,900
pleased because it was designed to be a

158
00:07:03,030 --> 00:07:09,510
a large-scale distributed system

159
00:07:05,900 --> 00:07:12,840
honestly has a lot of moving pieces so

160
00:07:09,510 --> 00:07:14,820
we've put an effort to make trying this

161
00:07:12,840 --> 00:07:16,409
out much simpler James has done an

162
00:07:14,820 --> 00:07:19,710
awesome job of putting together docker

163
00:07:16,410 --> 00:07:21,330
container where basically not just try

164
00:07:19,710 --> 00:07:25,109
out the system but actually develop

165
00:07:21,330 --> 00:07:27,060
within it but it might be interesting to

166
00:07:25,110 --> 00:07:29,910
know the architecture and you know when

167
00:07:27,060 --> 00:07:32,760
you guys get on to the actual hacking it

168
00:07:29,910 --> 00:07:34,590
some of the pieces of it written in it I

169
00:07:32,760 --> 00:07:37,740
guess the bottom Radio makers don't try

170
00:07:34,590 --> 00:07:40,679
to take all of this in hand yet but have

171
00:07:37,740 --> 00:07:42,630
this for reference when you know during

172
00:07:40,680 --> 00:07:45,480
the course of the day this stuff is also

173
00:07:42,630 --> 00:07:47,700
up on our site on get panopticon i/o so

174
00:07:45,480 --> 00:07:50,190
if you need to refer back to this but

175
00:07:47,700 --> 00:07:52,530
with that background here is what we

176
00:07:50,190 --> 00:07:56,370
have so we have a foundational layer a

177
00:07:52,530 --> 00:07:59,010
set of services which we use across the

178
00:07:56,370 --> 00:08:02,130
entire platform so we have celery which

179
00:07:59,010 --> 00:08:04,530
is a job pretty popular Python based job

180
00:08:02,130 --> 00:08:06,060
scheduling system this is actually what

181
00:08:04,530 --> 00:08:07,679
gives Panoptix the horizontal

182
00:08:06,060 --> 00:08:09,810
scalability you can just keep on putting

183
00:08:07,680 --> 00:08:13,470
in more hosts and you know it just keeps

184
00:08:09,810 --> 00:08:18,290
on being able to do more work if you

185
00:08:13,470 --> 00:08:22,169
have Redis which is a high-throughput

186
00:08:18,290 --> 00:08:23,700
in-memory no sequel store zookeeper

187
00:08:22,169 --> 00:08:26,070
which we use for various things like

188
00:08:23,700 --> 00:08:27,780
distributed locking and master election

189
00:08:26,070 --> 00:08:29,310
again being a distributed system we've

190
00:08:27,780 --> 00:08:30,960
designed it not to have single points of

191
00:08:29,310 --> 00:08:33,630
failure but that does require

192
00:08:30,960 --> 00:08:35,968
coordination and zookeeper is what gives

193
00:08:33,630 --> 00:08:39,679
us that coordination and then we have

194
00:08:35,969 --> 00:08:42,510
Kafka which we use as the message pass

195
00:08:39,679 --> 00:08:44,609
basically going with the philosophy of

196
00:08:42,510 --> 00:08:49,439
generate the data once but being able to

197
00:08:44,610 --> 00:08:51,480
consume it many times so these with on

198
00:08:49,440 --> 00:08:53,440
top of these foundational components we

199
00:08:51,480 --> 00:08:55,300
have the plug-in framework as

200
00:08:53,440 --> 00:08:57,550
you know mentioned this is where the

201
00:08:55,300 --> 00:09:01,150
superpower comes in this is not a fixed

202
00:08:57,550 --> 00:09:03,040
purpose system a lot of people who've

203
00:09:01,150 --> 00:09:04,240
looked at panopticon to the realization

204
00:09:03,040 --> 00:09:05,500
that's the heck this is nothing to ruin

205
00:09:04,240 --> 00:09:07,960
network monitoring you could do any

206
00:09:05,500 --> 00:09:09,880
monitoring with this it's just that we

207
00:09:07,960 --> 00:09:12,520
kind of the first use case we put it to

208
00:09:09,880 --> 00:09:14,020
is towards network monitoring but is

209
00:09:12,520 --> 00:09:17,020
essentially the plug-in framework that

210
00:09:14,020 --> 00:09:19,210
allows that now we do have three types

211
00:09:17,020 --> 00:09:21,100
of plugins I'm going to talk about this

212
00:09:19,210 --> 00:09:23,740
a bit here go into a bit more detail

213
00:09:21,100 --> 00:09:25,930
then Nathan is going to go into a whole

214
00:09:23,740 --> 00:09:27,340
lot more detail about plugins but

215
00:09:25,930 --> 00:09:29,199
essentially we have three types of

216
00:09:27,340 --> 00:09:31,120
plugins discovery pulling and enrichment

217
00:09:29,200 --> 00:09:33,600
plugins and I'll talk about them in a

218
00:09:31,120 --> 00:09:36,570
bit more detail in the next few slides

219
00:09:33,600 --> 00:09:39,850
but now these are classes of plugins

220
00:09:36,570 --> 00:09:43,500
what we have finally the workhorse is

221
00:09:39,850 --> 00:09:46,420
the actual device specific plugins now

222
00:09:43,500 --> 00:09:49,360
plugins for the most part is just Python

223
00:09:46,420 --> 00:09:51,760
code okay it just basically has an input

224
00:09:49,360 --> 00:09:53,530
and output contract with monopolies but

225
00:09:51,760 --> 00:09:56,710
you could write basically any code you

226
00:09:53,530 --> 00:09:58,630
want which does anything you want which

227
00:09:56,710 --> 00:10:00,840
honestly is a potential security risk

228
00:09:58,630 --> 00:10:04,090
but the reality it gives you immense

229
00:10:00,840 --> 00:10:05,800
flexibility we have a CMP and API

230
00:10:04,090 --> 00:10:09,850
plugins in our environment but there's

231
00:10:05,800 --> 00:10:11,729
no reason you couldn't use SSH or RPC or

232
00:10:09,850 --> 00:10:16,630
any other mechanism that you need to

233
00:10:11,730 --> 00:10:19,150
actually write a plug-in over to the

234
00:10:16,630 --> 00:10:20,680
right-hand side oh well yeah I guess the

235
00:10:19,150 --> 00:10:24,130
slides right hand side is a set of

236
00:10:20,680 --> 00:10:26,530
services which are not co2 per knob

237
00:10:24,130 --> 00:10:28,870
these per se these are services we

238
00:10:26,530 --> 00:10:32,079
actually use so we have a time series

239
00:10:28,870 --> 00:10:33,550
data base in Verizon media's

240
00:10:32,080 --> 00:10:35,080
implementation there is a company-wide

241
00:10:33,550 --> 00:10:37,569
time series database that's available

242
00:10:35,080 --> 00:10:39,400
for us to write to in the open source

243
00:10:37,570 --> 00:10:41,080
version we've chosen to go with influx

244
00:10:39,400 --> 00:10:43,420
TV which package that as a time series

245
00:10:41,080 --> 00:10:47,560
database but what I'm going to say is

246
00:10:43,420 --> 00:10:49,329
that is that while we need these

247
00:10:47,560 --> 00:10:51,040
services these are not services are not

248
00:10:49,330 --> 00:10:53,050
inherently part of properties and you're

249
00:10:51,040 --> 00:10:56,140
free to kind of you know plug in

250
00:10:53,050 --> 00:10:57,849
anything else you want it there there is

251
00:10:56,140 --> 00:11:00,520
a CMDB

252
00:10:57,850 --> 00:11:02,050
you know you need to begin from

253
00:11:00,520 --> 00:11:04,449
somewhere you need to figure out what

254
00:11:02,050 --> 00:11:05,949
devices to monitor and in our case the

255
00:11:04,450 --> 00:11:07,240
source of truth is again a company-wide

256
00:11:05,950 --> 00:11:09,279
CMDB

257
00:11:07,240 --> 00:11:12,879
the open-source version is literally a

258
00:11:09,279 --> 00:11:14,439
JSON file you can plug in the name of

259
00:11:12,879 --> 00:11:16,480
the device you want to monitor into a

260
00:11:14,439 --> 00:11:19,149
plugin file and that acts as the source

261
00:11:16,480 --> 00:11:20,559
of truth and then internally we have our

262
00:11:19,149 --> 00:11:22,209
Chris tration because again it's a large

263
00:11:20,559 --> 00:11:23,829
distributed system so we have our

264
00:11:22,209 --> 00:11:26,469
castration which sets all of this up and

265
00:11:23,829 --> 00:11:30,368
manages it the open source version is

266
00:11:26,470 --> 00:11:33,639
again bundled up into a single dollar

267
00:11:30,369 --> 00:11:36,160
container so really on the three things

268
00:11:33,639 --> 00:11:38,079
on the right probably don't matter to

269
00:11:36,160 --> 00:11:39,999
you right now unless you want to start

270
00:11:38,079 --> 00:11:41,138
using properties in production which is

271
00:11:39,999 --> 00:11:45,819
when I think you should think about them

272
00:11:41,139 --> 00:11:48,429
more deeply let's talk about the core

273
00:11:45,819 --> 00:11:50,679
concepts plugins resources metrics and

274
00:11:48,429 --> 00:11:54,610
which means and how we do data encoding

275
00:11:50,679 --> 00:11:57,059
and distribution um let me elaborate I

276
00:11:54,610 --> 00:12:01,149
have slides for each one of these

277
00:11:57,059 --> 00:12:03,249
plugins okay so like I said that just

278
00:12:01,149 --> 00:12:05,860
Python classes which have an interface

279
00:12:03,249 --> 00:12:07,389
so there's a fixed input the plugins get

280
00:12:05,860 --> 00:12:09,929
which you know think about it it's

281
00:12:07,389 --> 00:12:12,519
basically what is the device to monitor

282
00:12:09,929 --> 00:12:14,679
some other metadata about the device for

283
00:12:12,519 --> 00:12:17,920
example the u.s. name and the OS version

284
00:12:14,679 --> 00:12:19,389
what is the you know I submit community

285
00:12:17,920 --> 00:12:21,099
string you should use to monitor the

286
00:12:19,389 --> 00:12:23,230
device or the API password you should

287
00:12:21,100 --> 00:12:26,529
use to monitor the device this is all

288
00:12:23,230 --> 00:12:29,230
input the plug-in can expect okay

289
00:12:26,529 --> 00:12:32,290
V output that the plugin produces is

290
00:12:29,230 --> 00:12:33,910
again very well-defined set of classes

291
00:12:32,290 --> 00:12:36,790
which you have to stuff your data in to

292
00:12:33,910 --> 00:12:38,618
and I believe Nathan is going to into a

293
00:12:36,790 --> 00:12:41,049
lot of details about that and again this

294
00:12:38,619 --> 00:12:44,860
is documented in detail on ket

295
00:12:41,049 --> 00:12:47,860
panopticon IO and because the Python

296
00:12:44,860 --> 00:12:51,369
classes they can process here from any

297
00:12:47,860 --> 00:12:53,170
source anything you know SNMP CLI is API

298
00:12:51,369 --> 00:12:55,749
is anything we've not thought about yet

299
00:12:53,170 --> 00:12:57,790
okay but take code consume data from

300
00:12:55,749 --> 00:12:58,990
another Kafka bus if you know for

301
00:12:57,790 --> 00:13:03,129
example you have some system which

302
00:12:58,990 --> 00:13:05,019
already is collecting data as I

303
00:13:03,129 --> 00:13:08,589
mentioned there's three types of plugins

304
00:13:05,019 --> 00:13:10,990
discovery enrichment and metrics and I'm

305
00:13:08,589 --> 00:13:12,339
going to go into these details now what

306
00:13:10,990 --> 00:13:15,429
is the difference between these plugins

307
00:13:12,339 --> 00:13:16,600
oh sorry I'm I guess I'm going to talk

308
00:13:15,429 --> 00:13:17,199
about resources and then come back to

309
00:13:16,600 --> 00:13:20,440
that

310
00:13:17,200 --> 00:13:24,610
again another fundamental concept in

311
00:13:20,440 --> 00:13:26,410
Panoptix is resources so resource is

312
00:13:24,610 --> 00:13:30,550
what should be monitored okay

313
00:13:26,410 --> 00:13:32,709
in a simple context or in the network

314
00:13:30,550 --> 00:13:35,410
telemetry context reduces most often is

315
00:13:32,710 --> 00:13:37,360
the device to monitor but think about

316
00:13:35,410 --> 00:13:39,010
this for example let's say you want to

317
00:13:37,360 --> 00:13:41,620
talk to the peering db-api

318
00:13:39,010 --> 00:13:44,110
okay that is a resource that you would

319
00:13:41,620 --> 00:13:45,760
define because you take actions against

320
00:13:44,110 --> 00:13:49,440
resources and you define the resource

321
00:13:45,760 --> 00:13:51,700
you wanna monitor okay this is where

322
00:13:49,440 --> 00:13:53,620
resources are discovered through

323
00:13:51,700 --> 00:13:55,630
discovery plugins discovery plugins job

324
00:13:53,620 --> 00:13:59,650
is to populate the set of resources

325
00:13:55,630 --> 00:14:01,780
Panoptix can act on and this is in our

326
00:13:59,650 --> 00:14:03,220
case like I said we use a configuration

327
00:14:01,780 --> 00:14:05,050
management database to pull this data

328
00:14:03,220 --> 00:14:07,090
down but it could be anything the open

329
00:14:05,050 --> 00:14:08,829
source version is a flat is a JSON file

330
00:14:07,090 --> 00:14:10,990
you could integrate it with a flat file

331
00:14:08,830 --> 00:14:14,860
anything you like you know just to

332
00:14:10,990 --> 00:14:19,390
literally let Panoptix I want to get

333
00:14:14,860 --> 00:14:21,130
data from this two key elements to a

334
00:14:19,390 --> 00:14:23,230
resource there's an ID which has to be

335
00:14:21,130 --> 00:14:25,330
unique throughout the system there is an

336
00:14:23,230 --> 00:14:28,000
endpoint which is what the plugin will

337
00:14:25,330 --> 00:14:30,250
actually talk to so think about this way

338
00:14:28,000 --> 00:14:32,230
again for an API an endpoint would be

339
00:14:30,250 --> 00:14:35,080
the URL for a device the endpoint would

340
00:14:32,230 --> 00:14:36,880
be the device name for example okay but

341
00:14:35,080 --> 00:14:38,950
if there are the use cases that come up

342
00:14:36,880 --> 00:14:41,230
those are the abstractions available and

343
00:14:38,950 --> 00:14:43,750
then there's a lot of us any amount of

344
00:14:41,230 --> 00:14:45,400
associated metadata that you want again

345
00:14:43,750 --> 00:14:47,340
in our context in Verizon media's

346
00:14:45,400 --> 00:14:52,120
context the metadata that we store is

347
00:14:47,340 --> 00:14:53,170
the make bottle the the OS for each of

348
00:14:52,120 --> 00:14:57,250
the resources that we're trying to

349
00:14:53,170 --> 00:14:59,949
monitor which allows us to do something

350
00:14:57,250 --> 00:15:03,130
interesting so we have a specific DSL in

351
00:14:59,950 --> 00:15:07,000
Panoptix to actually select resources to

352
00:15:03,130 --> 00:15:09,580
act on so again Verizon media has a very

353
00:15:07,000 --> 00:15:11,200
high change of rate network so because

354
00:15:09,580 --> 00:15:13,540
there's so many devices and devices are

355
00:15:11,200 --> 00:15:14,950
being added and removed all the time we

356
00:15:13,540 --> 00:15:16,719
cannot have a fixed set of resources

357
00:15:14,950 --> 00:15:18,880
defined we can't have like here's the

358
00:15:16,720 --> 00:15:20,530
20,000 network devices that we will

359
00:15:18,880 --> 00:15:24,010
monitor please keep on changing all the

360
00:15:20,530 --> 00:15:25,569
time so discovery begins you know

361
00:15:24,010 --> 00:15:26,550
obviously can't rediscover those devices

362
00:15:25,570 --> 00:15:29,490
to monitor

363
00:15:26,550 --> 00:15:34,500
but here is another problem so let's say

364
00:15:29,490 --> 00:15:36,330
I did a new Cisco device right now how

365
00:15:34,500 --> 00:15:38,610
do I tell the rest of the system that I

366
00:15:36,330 --> 00:15:41,580
want these actions to be taken on all

367
00:15:38,610 --> 00:15:43,530
Cisco devices okay and that's where the

368
00:15:41,580 --> 00:15:46,560
resource dsl comes in so you're not

369
00:15:43,530 --> 00:15:48,569
configuring monitoring against an IP or

370
00:15:46,560 --> 00:15:51,959
against a hostname but essentially a

371
00:15:48,570 --> 00:15:55,410
class of devices so in our case you know

372
00:15:51,960 --> 00:15:57,450
we've designed this that hey anything

373
00:15:55,410 --> 00:16:00,300
that meets this criteria pick that up

374
00:15:57,450 --> 00:16:01,770
for monitoring okay like I said this is

375
00:16:00,300 --> 00:16:02,729
gonna be a lot to take in a lot of this

376
00:16:01,770 --> 00:16:04,410
is going to make sense when you guys

377
00:16:02,730 --> 00:16:08,790
actually get down to the hacking but you

378
00:16:04,410 --> 00:16:10,980
know context the other cool concept is

379
00:16:08,790 --> 00:16:13,260
metrics so resources is what you act on

380
00:16:10,980 --> 00:16:16,980
right metrics are what you actually

381
00:16:13,260 --> 00:16:19,110
collect from the devices okay metrics

382
00:16:16,980 --> 00:16:21,300
are a specific type of information that

383
00:16:19,110 --> 00:16:23,520
you collect from devices just a quick

384
00:16:21,300 --> 00:16:25,319
show of hands who here has worked with

385
00:16:23,520 --> 00:16:26,819
any kind of time series data bases and

386
00:16:25,320 --> 00:16:30,930
for example all the difference counters

387
00:16:26,820 --> 00:16:32,990
and gauges okay not a lot so a limited

388
00:16:30,930 --> 00:16:35,849
delve into this point a bit more a

389
00:16:32,990 --> 00:16:38,940
metric specifically has to be a number

390
00:16:35,850 --> 00:16:40,530
that it has to be measured okay if you

391
00:16:38,940 --> 00:16:43,650
want to collect data which is not a

392
00:16:40,530 --> 00:16:45,240
number that panopticon for that but

393
00:16:43,650 --> 00:16:48,540
please be clear that it cannot be a

394
00:16:45,240 --> 00:16:50,760
metric so a very simple example is the

395
00:16:48,540 --> 00:16:52,620
bytes in bytes out counter on an

396
00:16:50,760 --> 00:16:56,640
interface that's a metric because it's a

397
00:16:52,620 --> 00:16:59,310
measurable number the interface name is

398
00:16:56,640 --> 00:17:04,770
not a metric because that's not a number

399
00:16:59,310 --> 00:17:07,109
it's a textual description okay metrics

400
00:17:04,770 --> 00:17:09,780
by their weight nature typically are

401
00:17:07,109 --> 00:17:11,819
fast changing so between two pole cycles

402
00:17:09,780 --> 00:17:14,879
typically you will see the metric change

403
00:17:11,819 --> 00:17:17,250
now that's not necessarily true but the

404
00:17:14,880 --> 00:17:19,320
key point to remember here is they have

405
00:17:17,250 --> 00:17:21,030
the potential to be fast changing

406
00:17:19,319 --> 00:17:23,339
they're not necessarily fascinating a

407
00:17:21,030 --> 00:17:26,339
good example is for people who familiar

408
00:17:23,339 --> 00:17:31,530
with network operations is in networks

409
00:17:26,339 --> 00:17:33,240
add male status okay is a number it's up

410
00:17:31,530 --> 00:17:36,120
or down you can represent it as a number

411
00:17:33,240 --> 00:17:37,680
up or down zero one right now that

412
00:17:36,120 --> 00:17:39,570
doesn't keep on changing on every pull

413
00:17:37,680 --> 00:17:40,440
cycle I mean it can if it's changing

414
00:17:39,570 --> 00:17:42,210
every pose

415
00:17:40,440 --> 00:17:45,269
obviously have a operations problem we

416
00:17:42,210 --> 00:17:48,029
have a flapping interface but the point

417
00:17:45,269 --> 00:17:49,980
is it can potentially change because

418
00:17:48,029 --> 00:17:51,330
it's operational State and that's

419
00:17:49,980 --> 00:17:53,179
something you should think about as a

420
00:17:51,330 --> 00:17:55,320
metric okay

421
00:17:53,179 --> 00:17:57,120
again you could collect it through any

422
00:17:55,320 --> 00:17:59,240
of these means because plugins let you

423
00:17:57,120 --> 00:18:04,229
collect data through any possible

424
00:17:59,240 --> 00:18:06,600
mechanism the counterpart two metrics

425
00:18:04,230 --> 00:18:08,970
are enrichments enrichments are data

426
00:18:06,600 --> 00:18:10,379
that you want to collect which is not a

427
00:18:08,970 --> 00:18:14,730
number

428
00:18:10,379 --> 00:18:17,250
enrichments are what are called tags or

429
00:18:14,730 --> 00:18:19,889
labels in some implants sometimes it is

430
00:18:17,250 --> 00:18:22,320
to two pieces what they are are of way

431
00:18:19,889 --> 00:18:24,120
to add more context to a metric so for

432
00:18:22,320 --> 00:18:27,029
example you get the bytes in bytes out

433
00:18:24,120 --> 00:18:28,889
from an interface which interface how do

434
00:18:27,029 --> 00:18:31,139
you define that interface so at the very

435
00:18:28,889 --> 00:18:32,850
least you'd probably collect like an

436
00:18:31,139 --> 00:18:35,340
ayah filius or a knife description of

437
00:18:32,850 --> 00:18:37,830
that interface but actually say okay

438
00:18:35,340 --> 00:18:41,428
it's this interface which has this bytes

439
00:18:37,830 --> 00:18:43,500
in my chart okay but why stop there I

440
00:18:41,429 --> 00:18:44,940
mean actually to be honest even that's

441
00:18:43,500 --> 00:18:47,809
not sufficient the other metadata that

442
00:18:44,940 --> 00:18:50,669
you need is which device right because

443
00:18:47,809 --> 00:18:54,029
it's zero but it's zero where so that's

444
00:18:50,669 --> 00:18:58,100
another enrichment that you add and then

445
00:18:54,029 --> 00:19:00,240
this can go ad infinitum you for example

446
00:18:58,100 --> 00:19:01,620
there are enrichments that you can

447
00:19:00,240 --> 00:19:03,990
collect by talking to the device itself

448
00:19:01,620 --> 00:19:05,309
because when you get in counters from a

449
00:19:03,990 --> 00:19:07,169
device you know the interface you

450
00:19:05,309 --> 00:19:10,500
getting that counters for you know the

451
00:19:07,169 --> 00:19:13,559
device name that's straightforward but

452
00:19:10,500 --> 00:19:15,960
let's say you wanted to collect the

453
00:19:13,559 --> 00:19:17,668
geographical region that device isn't is

454
00:19:15,960 --> 00:19:20,460
it in North America is it in South

455
00:19:17,669 --> 00:19:22,549
America is it in Asia so that you could

456
00:19:20,460 --> 00:19:25,830
do actually feature reporting right

457
00:19:22,549 --> 00:19:27,960
that's an enrichment that's an

458
00:19:25,830 --> 00:19:30,059
enrichment that you don't collect from

459
00:19:27,960 --> 00:19:32,340
the device because the devices don't

460
00:19:30,059 --> 00:19:34,440
know where they are some devices let you

461
00:19:32,340 --> 00:19:37,230
configure it but as a general rule it's

462
00:19:34,440 --> 00:19:39,960
not in it's not inherently a device

463
00:19:37,230 --> 00:19:41,100
property it comes from somewhere else so

464
00:19:39,960 --> 00:19:43,649
the other thing to remember at

465
00:19:41,100 --> 00:19:45,449
enrichments is while they describe a

466
00:19:43,649 --> 00:19:49,500
metric they don't necessarily need to

467
00:19:45,450 --> 00:19:50,239
come from the same source as the metric

468
00:19:49,500 --> 00:19:52,369
comes from

469
00:19:50,239 --> 00:19:56,239
another example is how many of you are

470
00:19:52,369 --> 00:19:59,988
familiar with pairing BB yeah I they're

471
00:19:56,239 --> 00:20:02,239
not north not a lot but one of the use

472
00:19:59,989 --> 00:20:05,749
cases pairing DB has is to let you map

473
00:20:02,239 --> 00:20:07,009
an ESN to a name right so when you're

474
00:20:05,749 --> 00:20:08,839
collecting painting information on a

475
00:20:07,009 --> 00:20:10,849
device you get SN numbers you'll get

476
00:20:08,839 --> 00:20:13,129
1701 whatever right and that's

477
00:20:10,849 --> 00:20:14,629
meaningless to a lot of people do a

478
00:20:13,129 --> 00:20:16,009
network a lot of network operators it's

479
00:20:14,629 --> 00:20:17,688
not like they know off the top of their

480
00:20:16,009 --> 00:20:20,569
head what the Piggy's ends are but for

481
00:20:17,689 --> 00:20:22,939
the most general users it's going to be

482
00:20:20,569 --> 00:20:24,829
meaningless there is an external API

483
00:20:22,939 --> 00:20:28,849
available then lets you map it to a

484
00:20:24,829 --> 00:20:30,289
company name you know that this is and

485
00:20:28,849 --> 00:20:32,149
maps to this company I am embarrassed

486
00:20:30,289 --> 00:20:37,099
because I forgotten Verizon media zsn

487
00:20:32,149 --> 00:20:38,748
but that is again an enrichment but

488
00:20:37,099 --> 00:20:40,158
that's again an enrichment that doesn't

489
00:20:38,749 --> 00:20:42,379
necessarily come from the device itself

490
00:20:40,159 --> 00:20:47,349
but device doesn't know what yes and

491
00:20:42,379 --> 00:20:50,509
that which company wants that yes n okay

492
00:20:47,349 --> 00:20:51,979
yeah so and I'm giving you this context

493
00:20:50,509 --> 00:20:54,439
because when you're building plug-ins

494
00:20:51,979 --> 00:20:56,839
told fuel that enrichments have to come

495
00:20:54,439 --> 00:20:58,489
just from the device in fact some of the

496
00:20:56,839 --> 00:21:00,678
most valuable instruments you can come

497
00:20:58,489 --> 00:21:04,269
you can come up with are actually

498
00:21:00,679 --> 00:21:04,269
mashups from different sources

499
00:21:06,159 --> 00:21:11,389
now enrichments typically because

500
00:21:09,919 --> 00:21:13,999
they're not numbers they're typically

501
00:21:11,389 --> 00:21:16,218
more expensive to process they could be

502
00:21:13,999 --> 00:21:18,979
dictionaries or strings or basically any

503
00:21:16,219 --> 00:21:21,379
Python data structure but you know

504
00:21:18,979 --> 00:21:24,529
obviously they have a higher cost

505
00:21:21,379 --> 00:21:29,269
overhead so what we do with in

506
00:21:24,529 --> 00:21:30,889
panopticon Richmonds we cache them it's

507
00:21:29,269 --> 00:21:33,679
configurable you can decide how long and

508
00:21:30,889 --> 00:21:35,918
enrichment should be cached and again

509
00:21:33,679 --> 00:21:38,659
the thing to realize here is therefore

510
00:21:35,919 --> 00:21:41,809
enrichments big things which will not

511
00:21:38,659 --> 00:21:44,389
change frequently and I have named an

512
00:21:41,809 --> 00:21:46,039
interface name can change but usually

513
00:21:44,389 --> 00:21:47,359
practice doesn't change that frequently

514
00:21:46,039 --> 00:21:48,649
so that's something you should think

515
00:21:47,359 --> 00:21:50,629
about as an enrichment

516
00:21:48,649 --> 00:21:52,008
this cache invalidation mechanisms

517
00:21:50,629 --> 00:21:55,158
within properties but that's very

518
00:21:52,009 --> 00:21:56,419
detailed but the point is stuff that

519
00:21:55,159 --> 00:21:59,599
you're going to use to describe the

520
00:21:56,419 --> 00:22:01,750
metrics you want to look up once and

521
00:21:59,599 --> 00:22:03,939
sort of cache for some time we

522
00:22:01,750 --> 00:22:05,560
usually cash between you know fifteen to

523
00:22:03,940 --> 00:22:07,180
thirty minutes so it's not a very long

524
00:22:05,560 --> 00:22:09,970
cache it's not a cache that goes on for

525
00:22:07,180 --> 00:22:14,980
days but it's also not something that we

526
00:22:09,970 --> 00:22:16,120
collect on every cycle and by you knows

527
00:22:14,980 --> 00:22:19,210
making this point that we collect like

528
00:22:16,120 --> 00:22:20,739
3040 metrics the amount of enrichments

529
00:22:19,210 --> 00:22:23,530
we collect per interfaces actually

530
00:22:20,740 --> 00:22:25,570
double the number of metrics we collect

531
00:22:23,530 --> 00:22:27,820
there's actually more metadata that we

532
00:22:25,570 --> 00:22:30,790
used to describe the interface then the

533
00:22:27,820 --> 00:22:32,409
matrix itself we collect and if you were

534
00:22:30,790 --> 00:22:34,450
to do that on every pull cycle you know

535
00:22:32,410 --> 00:22:37,590
the system would be that much slower so

536
00:22:34,450 --> 00:22:40,060
what we typically do is because we

537
00:22:37,590 --> 00:22:42,010
asynchronously collect enrichments cache

538
00:22:40,060 --> 00:22:45,220
them and then use them in every poll

539
00:22:42,010 --> 00:22:50,260
cycle we basically add more efficient

540
00:22:45,220 --> 00:22:51,700
and we could scale better with this the

541
00:22:50,260 --> 00:22:54,730
other aspect is data encoding

542
00:22:51,700 --> 00:22:56,440
distribution day one properties was

543
00:22:54,730 --> 00:22:58,990
designed as a distribution system it was

544
00:22:56,440 --> 00:23:00,850
not a single standalone system which was

545
00:22:58,990 --> 00:23:04,270
retrofitted to be distributed but it was

546
00:23:00,850 --> 00:23:06,189
designed as a distributed system what

547
00:23:04,270 --> 00:23:08,080
that means is that these three phases

548
00:23:06,190 --> 00:23:09,910
discovery enrichment and pooling are

549
00:23:08,080 --> 00:23:12,280
completely decoupled from each other

550
00:23:09,910 --> 00:23:14,230
they work at different paces this can be

551
00:23:12,280 --> 00:23:16,930
sometimes difficult to wrap your head

552
00:23:14,230 --> 00:23:18,610
around again the docker container

553
00:23:16,930 --> 00:23:19,780
James is written helper tools which can

554
00:23:18,610 --> 00:23:23,080
actually help you understand what's

555
00:23:19,780 --> 00:23:25,570
going on and what stage the system is in

556
00:23:23,080 --> 00:23:29,439
right now and there's documentation as

557
00:23:25,570 --> 00:23:31,629
well but please be aware that things

558
00:23:29,440 --> 00:23:33,490
will not necessarily work exactly in a

559
00:23:31,630 --> 00:23:35,680
sequence because they're all decoupled

560
00:23:33,490 --> 00:23:37,510
from this so for example you start a

561
00:23:35,680 --> 00:23:39,340
polling plugin but discovery has not

562
00:23:37,510 --> 00:23:40,660
completed by now what will happen in the

563
00:23:39,340 --> 00:23:42,939
pudding plugin is gonna fail it's gonna

564
00:23:40,660 --> 00:23:45,190
say I'm nothing to monitor right

565
00:23:42,940 --> 00:23:47,110
only when discovery finishes when the

566
00:23:45,190 --> 00:23:49,810
polling plugin succeed so things like

567
00:23:47,110 --> 00:23:53,409
that which are you know nature of our

568
00:23:49,810 --> 00:23:57,220
distributed asynchronous system if we

569
00:23:53,410 --> 00:23:59,260
use Kafka to pass data we use Redis for

570
00:23:57,220 --> 00:24:02,560
some small cases but it's mostly Kafka

571
00:23:59,260 --> 00:24:05,379
that we use to actually pass theater we

572
00:24:02,560 --> 00:24:08,919
in quote all data in properties using

573
00:24:05,380 --> 00:24:10,780
JSON which is supremely inefficient it's

574
00:24:08,920 --> 00:24:14,109
extremely non performant it's a

575
00:24:10,780 --> 00:24:17,889
conscious choice we made in terms of

576
00:24:14,109 --> 00:24:20,449
yeah exactly developer productivity and

577
00:24:17,889 --> 00:24:22,549
actually even Python per se is actually

578
00:24:20,450 --> 00:24:27,079
a choice choice in terms of developer

579
00:24:22,549 --> 00:24:29,119
productivity rather than performance so

580
00:24:27,079 --> 00:24:32,299
with all that context this is kind of

581
00:24:29,119 --> 00:24:35,359
what the workflow looks for us we

582
00:24:32,299 --> 00:24:37,369
collect data plugins do this we support

583
00:24:35,359 --> 00:24:38,839
some amount of post processing within

584
00:24:37,369 --> 00:24:40,668
monopolies right now the only post

585
00:24:38,839 --> 00:24:43,609
processing that we have is being able to

586
00:24:40,669 --> 00:24:46,219
convert a counter into a gauge which is

587
00:24:43,609 --> 00:24:48,799
basically you know you get the number of

588
00:24:46,219 --> 00:24:50,149
bytes from a interface that's going to

589
00:24:48,799 --> 00:24:51,709
be an ever-increasing number because

590
00:24:50,149 --> 00:24:54,379
it's a counter it's going up and up and

591
00:24:51,709 --> 00:24:55,669
up but as a network operator you're not

592
00:24:54,379 --> 00:24:57,859
interested in that you're interested in

593
00:24:55,669 --> 00:24:59,659
their rate how many bits per second does

594
00:24:57,859 --> 00:25:01,458
this translate to so that's a

595
00:24:59,659 --> 00:25:05,209
transformation and we do that in

596
00:25:01,459 --> 00:25:07,190
post-processing once we do this we place

597
00:25:05,209 --> 00:25:09,079
the data on the message pass okay and

598
00:25:07,190 --> 00:25:12,139
then we have multiple downstream

599
00:25:09,079 --> 00:25:14,178
consumers we have a time series database

600
00:25:12,139 --> 00:25:18,258
consumer which again in the open source

601
00:25:14,179 --> 00:25:19,369
case is the craft is in flux DB and you

602
00:25:18,259 --> 00:25:22,700
can set up alerts on that also

603
00:25:19,369 --> 00:25:24,859
internally we use open TS DB and

604
00:25:22,700 --> 00:25:30,169
internally we also sent the data to

605
00:25:24,859 --> 00:25:32,239
Hadoop grade for batch analytics we also

606
00:25:30,169 --> 00:25:35,179
have another flow which we've not open

607
00:25:32,239 --> 00:25:40,129
sourced yet we also send this data to a

608
00:25:35,179 --> 00:25:42,169
my sequel server and to build a very to

609
00:25:40,129 --> 00:25:44,658
build purpose specific API I actually

610
00:25:42,169 --> 00:25:48,259
have a slide about that later but

611
00:25:44,659 --> 00:25:49,099
basically this is you know long term

612
00:25:48,259 --> 00:25:54,369
historical data

613
00:25:49,099 --> 00:25:54,369
this is faster instantaneous data I

614
00:25:55,299 --> 00:26:01,399
think stuff I've already covered we

615
00:25:59,509 --> 00:26:03,099
wanted this to be horizontal scalable

616
00:26:01,399 --> 00:26:07,939
and you know single points of failure

617
00:26:03,099 --> 00:26:09,678
which kind of are you know to make the

618
00:26:07,940 --> 00:26:14,209
system complicated but those were what

619
00:26:09,679 --> 00:26:16,429
our requirements for like I said iPhone

620
00:26:14,209 --> 00:26:18,739
is developer friendly it's not

621
00:26:16,429 --> 00:26:20,239
performant but that's a batter we

622
00:26:18,739 --> 00:26:22,279
actually had to fight with the technical

623
00:26:20,239 --> 00:26:23,659
counsel inside saying that we understand

624
00:26:22,279 --> 00:26:25,129
that we signing off Python we understand

625
00:26:23,659 --> 00:26:26,809
it's going to be slow but we're doing it

626
00:26:25,129 --> 00:26:32,020
because we think it'll be

627
00:26:26,809 --> 00:26:36,620
easier for us to put in more developers

628
00:26:32,020 --> 00:26:39,049
we know on our scale when we deployed

629
00:26:36,620 --> 00:26:40,610
everything we broke everything we had to

630
00:26:39,049 --> 00:26:43,070
do a lot of cooling of of these

631
00:26:40,610 --> 00:26:45,020
components if you guys when you guys

632
00:26:43,070 --> 00:26:47,928
consider running properties in your

633
00:26:45,020 --> 00:26:49,700
environments please be advised the taça

634
00:26:47,929 --> 00:26:52,400
container is great to get started but

635
00:26:49,700 --> 00:26:53,659
that's not supposed to run at scale

636
00:26:52,400 --> 00:26:55,309
you'll have to set up clusters for

637
00:26:53,659 --> 00:26:58,070
everything and you'll have to tune these

638
00:26:55,309 --> 00:27:02,899
components this is just a reality of how

639
00:26:58,070 --> 00:27:05,480
these things work um I'm actually gonna

640
00:27:02,900 --> 00:27:06,650
skip over this slide if you guys that

641
00:27:05,480 --> 00:27:08,630
really interested I can come back to

642
00:27:06,650 --> 00:27:10,730
this because it's not only very useful

643
00:27:08,630 --> 00:27:13,100
in the context of the hackathon I mean

644
00:27:10,730 --> 00:27:16,760
this is how we kind of have a divide and

645
00:27:13,100 --> 00:27:18,439
conquer strategy of not transmitting

646
00:27:16,760 --> 00:27:20,570
data across all our data centers but yet

647
00:27:18,440 --> 00:27:26,809
making it look like that the details

648
00:27:20,570 --> 00:27:29,030
available instantaneously some of the

649
00:27:26,809 --> 00:27:31,460
operational experiences we had is one

650
00:27:29,030 --> 00:27:35,178
thing that was extremely painful how

651
00:27:31,460 --> 00:27:37,730
many when how many participants do we

652
00:27:35,179 --> 00:27:41,230
have were from a network device when the

653
00:27:37,730 --> 00:27:47,390
company or is the Juniper you guys I

654
00:27:41,230 --> 00:27:50,600
have choice words for you we are second

655
00:27:47,390 --> 00:27:53,150
single biggest time train was getting

656
00:27:50,600 --> 00:27:54,740
and normalizing these metrics ian holmes

657
00:27:53,150 --> 00:27:57,620
who's sitting right up here has done

658
00:27:54,740 --> 00:27:59,960
phenomenal work in terms of making sense

659
00:27:57,620 --> 00:28:01,610
out of these metrics cpu from one device

660
00:27:59,960 --> 00:28:04,549
does not mean the CP from another device

661
00:28:01,610 --> 00:28:07,070
and that was you know we chose a

662
00:28:04,549 --> 00:28:09,559
strategic decision to take that hit up

663
00:28:07,070 --> 00:28:11,480
front rather than just expose that data

664
00:28:09,559 --> 00:28:13,549
to a user who has who now has the

665
00:28:11,480 --> 00:28:15,500
cognitive load when looking at dashboard

666
00:28:13,549 --> 00:28:17,450
to figure out oh wait this is this

667
00:28:15,500 --> 00:28:19,580
device with this at least therefore this

668
00:28:17,450 --> 00:28:21,620
is how I should interpret the CPU versus

669
00:28:19,580 --> 00:28:23,720
this device from this release has a

670
00:28:21,620 --> 00:28:25,959
different interpretation so we put a lot

671
00:28:23,720 --> 00:28:29,510
of effort in normalizing these metrics

672
00:28:25,960 --> 00:28:32,590
so that when a user looks at it they can

673
00:28:29,510 --> 00:28:37,340
actually make sense of what's going on

674
00:28:32,590 --> 00:28:39,750
we Verizon media this is a fact this is

675
00:28:37,340 --> 00:28:42,449
an SNMP shop

676
00:28:39,750 --> 00:28:44,659
it's you pictures horizon media's a

677
00:28:42,450 --> 00:28:47,070
multi-generational multi-vendor network

678
00:28:44,659 --> 00:28:49,049
there are some much more performant

679
00:28:47,070 --> 00:28:51,270
technologies out there there's API is

680
00:28:49,049 --> 00:28:52,830
this human telemetry but I said MP

681
00:28:51,270 --> 00:28:54,090
honestly is still the lowest common

682
00:28:52,830 --> 00:28:57,120
denominator it's something we can

683
00:28:54,090 --> 00:29:02,730
recently expect to work on our entire

684
00:28:57,120 --> 00:29:04,289
fleet SNP performance sucks it's a 22

685
00:29:02,730 --> 00:29:06,419
year old protocol it was designed for a

686
00:29:04,289 --> 00:29:07,500
different day and age it was designed

687
00:29:06,419 --> 00:29:08,850
when network manuals that really

688
00:29:07,500 --> 00:29:11,490
expensive they spend a lot of CPU time

689
00:29:08,850 --> 00:29:13,110
compacting it and there's a lot of the

690
00:29:11,490 --> 00:29:16,440
sorting does a lot of design decisions

691
00:29:13,110 --> 00:29:18,899
which made sense 22 years ago which make

692
00:29:16,440 --> 00:29:22,520
a semi not performant today

693
00:29:18,900 --> 00:29:25,230
apo performance is definitely far better

694
00:29:22,520 --> 00:29:27,780
the other issue was when you building

695
00:29:25,230 --> 00:29:29,640
this we had some use cases of what we

696
00:29:27,780 --> 00:29:31,559
want to do the data we didn't didn't

697
00:29:29,640 --> 00:29:33,330
have all the use cases but we kind of

698
00:29:31,559 --> 00:29:34,740
knew that if he produced data we will be

699
00:29:33,330 --> 00:29:36,899
tempted to use it in different ways and

700
00:29:34,740 --> 00:29:37,950
that's proven to be true I think we

701
00:29:36,900 --> 00:29:40,409
already have three or four different

702
00:29:37,950 --> 00:29:42,000
consumers I think we've opens only open

703
00:29:40,409 --> 00:29:44,549
sourced to one but we have multiple

704
00:29:42,000 --> 00:29:49,080
other consumers which take the same data

705
00:29:44,549 --> 00:29:52,860
and something interesting with it one

706
00:29:49,080 --> 00:29:55,710
other key thing is so a lot of our

707
00:29:52,860 --> 00:29:57,928
partner teams infrastructure teams or

708
00:29:55,710 --> 00:29:59,400
planning beings they want to get to the

709
00:29:57,929 --> 00:30:01,530
data that we've collected and they say

710
00:29:59,400 --> 00:30:04,559
hey guys let us just why don't you just

711
00:30:01,530 --> 00:30:05,610
let us hook into your kafka bus and then

712
00:30:04,559 --> 00:30:07,200
you don't have to worry about it you

713
00:30:05,610 --> 00:30:09,719
produce the metrics and we can consume

714
00:30:07,200 --> 00:30:12,240
it and you know able to be happy we've

715
00:30:09,720 --> 00:30:13,789
taken a stand not to do that the reason

716
00:30:12,240 --> 00:30:16,440
for that is when you do things like that

717
00:30:13,789 --> 00:30:17,879
there's a particular on on bus

718
00:30:16,440 --> 00:30:19,679
serialization format that we've chosen

719
00:30:17,880 --> 00:30:21,960
or there's a particular Kafka client

720
00:30:19,679 --> 00:30:24,390
version that we've chosen the moment you

721
00:30:21,960 --> 00:30:26,970
allow users to actually hook in to your

722
00:30:24,390 --> 00:30:29,280
raw systems changing means that you have

723
00:30:26,970 --> 00:30:31,230
to coordinate with everybody so what

724
00:30:29,280 --> 00:30:33,389
we've done instead is and it's been

725
00:30:31,230 --> 00:30:35,549
harder and it takes has a performance

726
00:30:33,390 --> 00:30:37,919
hit is to actually store the data and

727
00:30:35,549 --> 00:30:39,360
make it available through an API because

728
00:30:37,919 --> 00:30:42,330
that way what happens is we have a very

729
00:30:39,360 --> 00:30:43,830
clean contact with our customers and if

730
00:30:42,330 --> 00:30:48,030
you need to change anything we can

731
00:30:43,830 --> 00:30:50,668
change it behind the scenes with the but

732
00:30:48,030 --> 00:30:52,620
as long as we keep the API the same but

733
00:30:50,669 --> 00:30:54,130
it's just you know a border wise if you

734
00:30:52,620 --> 00:30:57,760
guys attend to

735
00:30:54,130 --> 00:31:00,680
consuming properties data can consider

736
00:30:57,760 --> 00:31:03,379
you know your partner team's not

737
00:31:00,680 --> 00:31:07,340
exposing the rot it as as you produce

738
00:31:03,380 --> 00:31:11,120
them we have some custom UIs as well I

739
00:31:07,340 --> 00:31:14,449
think we have some screenshots so this

740
00:31:11,120 --> 00:31:17,090
is one example of a purpose specific EPA

741
00:31:14,450 --> 00:31:19,370
that we've built and it generic API that

742
00:31:17,090 --> 00:31:21,830
we get from the time series database so

743
00:31:19,370 --> 00:31:23,989
it's actually a query for the same data

744
00:31:21,830 --> 00:31:27,439
we what we're doing is requiring load

745
00:31:23,990 --> 00:31:28,640
balancers in both the cases and at first

746
00:31:27,440 --> 00:31:32,480
short it's actually going to seem that

747
00:31:28,640 --> 00:31:36,770
the bulk and historical data is query is

748
00:31:32,480 --> 00:31:39,590
actually simpler then the data for query

749
00:31:36,770 --> 00:31:43,430
for the real time for the purpose

750
00:31:39,590 --> 00:31:46,340
Pacific API the problem is with the bulk

751
00:31:43,430 --> 00:31:49,160
or historical API you have to learn a

752
00:31:46,340 --> 00:31:51,050
whole new query language it's think of

753
00:31:49,160 --> 00:31:53,120
it having to learn like something like

754
00:31:51,050 --> 00:31:55,490
sequel not exactly is equal but

755
00:31:53,120 --> 00:31:57,679
something like sequel not an

756
00:31:55,490 --> 00:31:59,770
insurmountable task but what tends to

757
00:31:57,680 --> 00:32:02,570
happen is it creates a barrier to entry

758
00:31:59,770 --> 00:32:04,610
versus people who are very who want to

759
00:32:02,570 --> 00:32:06,169
work with load balancers know what these

760
00:32:04,610 --> 00:32:08,090
all of these mean they they're familiar

761
00:32:06,170 --> 00:32:10,610
with whatever there's on the left hand

762
00:32:08,090 --> 00:32:13,189
side so it's actually easier for them to

763
00:32:10,610 --> 00:32:15,649
get started the other thing is the

764
00:32:13,190 --> 00:32:17,120
performance on the of the API on the

765
00:32:15,650 --> 00:32:19,250
Left which is purpose specific is

766
00:32:17,120 --> 00:32:20,989
actually far faster than the performance

767
00:32:19,250 --> 00:32:22,790
of the historical API and the only

768
00:32:20,990 --> 00:32:24,440
reason for that or one of the reasons

769
00:32:22,790 --> 00:32:27,649
for that is because this is only built

770
00:32:24,440 --> 00:32:30,560
to provide the last point in time data

771
00:32:27,650 --> 00:32:32,420
well the historical API will scan over

772
00:32:30,560 --> 00:32:33,770
all the time ranges that you specify

773
00:32:32,420 --> 00:32:35,810
even if you're trying to just get to the

774
00:32:33,770 --> 00:32:37,610
last data point there is a much more

775
00:32:35,810 --> 00:32:39,740
overhead it has to go through before it

776
00:32:37,610 --> 00:32:42,290
can return the data to you so this is

777
00:32:39,740 --> 00:32:45,230
another experience we've had is that you

778
00:32:42,290 --> 00:32:50,960
we do need different ApS for different

779
00:32:45,230 --> 00:32:53,990
use cases this is what our view looks

780
00:32:50,960 --> 00:32:55,700
like this is the centralized telemetry

781
00:32:53,990 --> 00:32:59,930
system that we have within Verizon

782
00:32:55,700 --> 00:33:01,160
meteor which is based on open TST be the

783
00:32:59,930 --> 00:33:04,700
open source view looks different

784
00:33:01,160 --> 00:33:07,250
openSUSE open source is kevanna so how

785
00:33:04,700 --> 00:33:08,999
many of you later on used

786
00:33:07,250 --> 00:33:12,460
[Music]

787
00:33:08,999 --> 00:33:14,619
so the open suppose just refine and it's

788
00:33:12,460 --> 00:33:17,850
well documented and hopefully you

789
00:33:14,619 --> 00:33:17,850
shouldn't have any issues with that so

790
00:33:18,299 --> 00:33:22,960
in our case internally because this is a

791
00:33:21,190 --> 00:33:27,090
big central cluster we don't manage it

792
00:33:22,960 --> 00:33:30,009
it makes operations for us much easier

793
00:33:27,090 --> 00:33:31,988
but in addition we also have custom UI's

794
00:33:30,009 --> 00:33:34,360
which we've done this is a gain of view

795
00:33:31,989 --> 00:33:36,460
of the load balancer and you can see

796
00:33:34,360 --> 00:33:39,039
that the thing is here we have simple

797
00:33:36,460 --> 00:33:41,739
charting very useful help you figure out

798
00:33:39,039 --> 00:33:43,600
trends and anomalies but this is a

799
00:33:41,739 --> 00:33:46,330
completely different view this is far

800
00:33:43,600 --> 00:33:48,428
more richer information about a load

801
00:33:46,330 --> 00:33:50,590
balancer then a simple set of charts

802
00:33:48,429 --> 00:33:53,230
would give you so we've also built

803
00:33:50,590 --> 00:33:54,999
custom UIs they've been built on the

804
00:33:53,230 --> 00:33:57,639
purpose specific EPS that we've written

805
00:33:54,999 --> 00:33:59,769
and this is all context this is all what

806
00:33:57,639 --> 00:34:01,209
panopticon off anyway so thinking about

807
00:33:59,769 --> 00:34:03,909
hacks or anything but using it

808
00:34:01,210 --> 00:34:07,929
internally this is what all the platform

809
00:34:03,909 --> 00:34:21,280
will let you do okay and with that we

810
00:34:07,929 --> 00:34:25,359
will have so what we do is actually this

811
00:34:21,280 --> 00:34:29,619
we expose internally through my sequel

812
00:34:25,359 --> 00:34:31,418
and the real time API is built over my

813
00:34:29,619 --> 00:34:32,290
sequel and the bulk API is built over

814
00:34:31,418 --> 00:34:35,078
tsdp

815
00:34:32,290 --> 00:34:37,690
so in the open source example it'll be

816
00:34:35,079 --> 00:34:40,780
the influx deep ease API which is a very

817
00:34:37,690 --> 00:34:50,470
well defined API to query the data that

818
00:34:40,780 --> 00:35:03,160
you produce as if I know you could do a

819
00:34:50,469 --> 00:35:05,529
query in flux TB right yes you're right

820
00:35:03,160 --> 00:35:07,029
there's nothing right now which streams

821
00:35:05,530 --> 00:35:10,470
out the data which is collected so it

822
00:35:07,030 --> 00:35:10,470
does become a pull system yes

823
00:35:15,660 --> 00:35:21,219
yeah yeah and that's not that's not a

824
00:35:18,819 --> 00:35:22,449
bad hack actually to be honest yeah it's

825
00:35:21,219 --> 00:35:23,769
pretty good it's actually why don't I

826
00:35:22,449 --> 00:35:41,769
think one of the suggestions we have as

827
00:35:23,769 --> 00:35:43,808
a hack idea so yes a couple of things

828
00:35:41,769 --> 00:35:46,448
that's where every society comes in what

829
00:35:43,809 --> 00:35:48,369
we simply do is we use the device name

830
00:35:46,449 --> 00:35:51,809
as every society that makes it unique

831
00:35:48,369 --> 00:35:54,160
but that's a problem that panopticon

832
00:35:51,809 --> 00:35:56,589
inherently solve it's a problem that

833
00:35:54,160 --> 00:35:59,529
discovery plugin has to solve because

834
00:35:56,589 --> 00:36:00,849
you know again we there's some

835
00:35:59,529 --> 00:36:02,829
reasonable assumptions we could make

836
00:36:00,849 --> 00:36:04,869
about some topologies but we can't

837
00:36:02,829 --> 00:36:08,579
assume all topologies so the discovery

838
00:36:04,869 --> 00:36:10,539
plugin would have to have that logic

839
00:36:08,579 --> 00:36:13,539
there disco by the way another thing

840
00:36:10,539 --> 00:36:15,519
generally as we don't actually do

841
00:36:13,539 --> 00:36:17,529
topology walks to populate resources

842
00:36:15,519 --> 00:36:19,569
there's a potential security risk there

843
00:36:17,529 --> 00:36:22,809
so basically there's an unauthorized

844
00:36:19,569 --> 00:36:24,249
device plugged into our network if we

845
00:36:22,809 --> 00:36:26,109
discover that device has a neighbor of

846
00:36:24,249 --> 00:36:27,819
some other device and now what we do is

847
00:36:26,109 --> 00:36:30,189
we like yeah this is our device let's

848
00:36:27,819 --> 00:36:31,839
hand it all the credentials we know so

849
00:36:30,189 --> 00:36:34,449
there's a very big risk so we've taken

850
00:36:31,839 --> 00:36:36,609
conscious decision that we bubble up

851
00:36:34,449 --> 00:36:38,199
differences between what our CMDB says

852
00:36:36,609 --> 00:36:40,979
and what our topology says to our

853
00:36:38,199 --> 00:36:43,059
security team and we like guys this is

854
00:36:40,979 --> 00:36:45,640
we thought we've supposed to have X

855
00:36:43,059 --> 00:36:47,079
devices we have X plus one device can

856
00:36:45,640 --> 00:36:48,879
you please tell us if this X device is

857
00:36:47,079 --> 00:36:50,920
supposed to be and if it is it goes back

858
00:36:48,880 --> 00:36:52,900
into our CMDB database that's an

859
00:36:50,920 --> 00:36:57,339
operational you know call that we've

860
00:36:52,900 --> 00:36:59,410
taken but if your absolute confident of

861
00:36:57,339 --> 00:37:00,969
your network you could do discovery

862
00:36:59,410 --> 00:37:04,890
through topology you could do topology

863
00:37:00,969 --> 00:37:04,890
box to build your list of resources

864
00:37:37,680 --> 00:37:42,220
so for that problem what we've done is

865
00:37:40,359 --> 00:37:47,980
we've actually published two data

866
00:37:42,220 --> 00:37:59,919
modules we've published one oh I'm sorry

867
00:37:47,980 --> 00:38:02,590
yes the question that I was asking was I

868
00:37:59,920 --> 00:38:04,840
have a set of devices which may be

869
00:38:02,590 --> 00:38:07,390
hundreds or thousands but for a given

870
00:38:04,840 --> 00:38:09,910
device I may have some things like optic

871
00:38:07,390 --> 00:38:11,710
temperatures which only get from CLI I

872
00:38:09,910 --> 00:38:12,190
may have some things but your only

873
00:38:11,710 --> 00:38:14,410
router

874
00:38:12,190 --> 00:38:16,750
API and then I may have some things

875
00:38:14,410 --> 00:38:18,069
which are SNMP and then some things like

876
00:38:16,750 --> 00:38:20,290
queue depth that I can only get from

877
00:38:18,070 --> 00:38:22,300
streaming telemetry and because of our

878
00:38:20,290 --> 00:38:25,119
wonderful beloved router vendors I might

879
00:38:22,300 --> 00:38:27,220
not I might still need SNMP so how do I

880
00:38:25,119 --> 00:38:31,210
describe for all my devices for all the

881
00:38:27,220 --> 00:38:35,649
metrics that I want how to grab them so

882
00:38:31,210 --> 00:38:39,150
let's do this problem what we do is we

883
00:38:35,650 --> 00:38:42,160
define schemas by contract so we define

884
00:38:39,150 --> 00:38:43,630
you know a head said we make a lot of

885
00:38:42,160 --> 00:38:45,819
effort to normalize everything and

886
00:38:43,630 --> 00:38:48,010
normalizing does sometimes mean choosing

887
00:38:45,820 --> 00:38:49,660
the lowest common denominator so what

888
00:38:48,010 --> 00:38:51,940
we've done is we've published this this

889
00:38:49,660 --> 00:38:54,279
is one get panopticon for system metrics

890
00:38:51,940 --> 00:38:55,359
what is it that we will collect across

891
00:38:54,280 --> 00:38:57,640
all the devices

892
00:38:55,359 --> 00:38:59,770
what is optional what is mandatory now

893
00:38:57,640 --> 00:39:02,200
unfortunately this fortunately

894
00:38:59,770 --> 00:39:04,180
unfortunately this is a design my

895
00:39:02,200 --> 00:39:06,250
contract it's it's a schema which is

896
00:39:04,180 --> 00:39:08,290
well defined it's actually like

897
00:39:06,250 --> 00:39:11,680
literally a schema that you define but

898
00:39:08,290 --> 00:39:15,070
it's not enforced anywhere so you could

899
00:39:11,680 --> 00:39:17,169
write a plug-in which that scheme and

900
00:39:15,070 --> 00:39:18,910
things will still work but what we would

901
00:39:17,170 --> 00:39:20,680
highly recommend you to do is look at

902
00:39:18,910 --> 00:39:22,450
the schema write a plugin that conform

903
00:39:20,680 --> 00:39:23,290
to the schema because think about your

904
00:39:22,450 --> 00:39:24,669
end-to-end system

905
00:39:23,290 --> 00:39:25,990
there'll be downstream systems which

906
00:39:24,670 --> 00:39:27,700
will make some assumptions about the

907
00:39:25,990 --> 00:39:30,100
data that are coming in so you know as

908
00:39:27,700 --> 00:39:32,319
long as you adhere to that schema you

909
00:39:30,100 --> 00:39:35,170
the whole system gets the benefit okay

910
00:39:32,320 --> 00:39:36,460
so that's one part i just relized we've

911
00:39:35,170 --> 00:39:38,260
not published one of them

912
00:39:36,460 --> 00:39:42,130
gee mom maybe I'll do that during the

913
00:39:38,260 --> 00:39:44,050
hack day but the other part of your

914
00:39:42,130 --> 00:39:45,400
question is so this is what we expect a

915
00:39:44,050 --> 00:39:49,089
plug-in to produce the other question is

916
00:39:45,400 --> 00:39:51,880
you're absolutely right it's extremely

917
00:39:49,089 --> 00:39:52,869
common that it's not uncommon that we

918
00:39:51,880 --> 00:39:55,540
have to collect data from multiple

919
00:39:52,869 --> 00:39:57,580
sources so this is where the genre's

920
00:39:55,540 --> 00:39:59,710
city of the plugins come in it's a

921
00:39:57,580 --> 00:40:01,359
Python script so if you need to make out

922
00:39:59,710 --> 00:40:03,670
multiple calls we actually do do that

923
00:40:01,359 --> 00:40:06,848
there is there is a specific plugin

924
00:40:03,670 --> 00:40:09,220
which makes SNMP calls and API calls and

925
00:40:06,849 --> 00:40:11,950
CLI calls because the data is not

926
00:40:09,220 --> 00:40:14,740
available in one place but once it's

927
00:40:11,950 --> 00:40:39,759
done all of that in the end it produces

928
00:40:14,740 --> 00:40:43,868
output per piece-- schema yes there is a

929
00:40:39,760 --> 00:40:49,480
there is this is my funniest story I

930
00:40:43,869 --> 00:40:52,990
have ok there is a platform Wender who

931
00:40:49,480 --> 00:40:55,780
on a certain platform reports the

932
00:40:52,990 --> 00:40:57,759
temperature sensors at 1 million I mean

933
00:40:55,780 --> 00:40:59,650
it's not it's not a scaling factor issue

934
00:40:57,760 --> 00:41:01,750
some of that most of the temperature

935
00:40:59,650 --> 00:41:05,530
sensors are fine there's one temperature

936
00:41:01,750 --> 00:41:07,540
sensor which reports a weird value this

937
00:41:05,530 --> 00:41:09,099
is the funniest I mean I was laughing

938
00:41:07,540 --> 00:41:11,290
and crying Ian made this change

939
00:41:09,099 --> 00:41:13,480
he literally encoding the melting point

940
00:41:11,290 --> 00:41:15,190
of steel into the code and said if a

941
00:41:13,480 --> 00:41:16,359
temperature comes more than this yeah

942
00:41:15,190 --> 00:41:19,810
let's cap it at the melting point of

943
00:41:16,359 --> 00:41:22,690
steel very high T his devices are going

944
00:41:19,810 --> 00:41:24,339
to report random and we have to

945
00:41:22,690 --> 00:41:26,050
deal with that and that's exactly what

946
00:41:24,339 --> 00:41:28,839
the plug-in the heavy lifting the plugin

947
00:41:26,050 --> 00:41:31,170
has to do so that the users don't have

948
00:41:28,839 --> 00:41:31,170
to do it

949
00:41:43,650 --> 00:41:50,859
sure sure

950
00:41:47,859 --> 00:41:52,660
so we are going to start we want to

951
00:41:50,859 --> 00:41:54,490
start doing open conflict but there's a

952
00:41:52,660 --> 00:41:57,700
few things to realize there first and

953
00:41:54,490 --> 00:42:00,669
foremost open conflict defines a piece

954
00:41:57,700 --> 00:42:04,569
in tax not the semantics a vendor can

955
00:42:00,670 --> 00:42:08,260
still misreport a cpu it will to put it

956
00:42:04,570 --> 00:42:10,450
like a open config in the structure that

957
00:42:08,260 --> 00:42:13,560
open comp it wants but what prevents

958
00:42:10,450 --> 00:42:18,129
event or the example I just gave you

959
00:42:13,560 --> 00:42:20,200
yeah exactly the semantic interpretation

960
00:42:18,130 --> 00:42:23,080
and implementation still left to Enders

961
00:42:20,200 --> 00:42:25,689
there's a vendor who just decides to

962
00:42:23,080 --> 00:42:28,660
report the load average of a CPU as the

963
00:42:25,690 --> 00:42:30,160
CPU utilization and nothing prevents

964
00:42:28,660 --> 00:42:32,649
them from passing an open conflict

965
00:42:30,160 --> 00:42:34,960
certification with that data you still

966
00:42:32,650 --> 00:42:36,820
would have to do massage the data the

967
00:42:34,960 --> 00:42:38,589
other thing is open config is nascent

968
00:42:36,820 --> 00:42:41,380
there's some really good things about it

969
00:42:38,589 --> 00:42:43,029
you know that it's operator driven and

970
00:42:41,380 --> 00:42:45,640
things like that but remember another

971
00:42:43,030 --> 00:42:48,310
thing sauce SNMP SMB is highly

972
00:42:45,640 --> 00:42:50,650
structured nothing prevents vendors from

973
00:42:48,310 --> 00:42:53,020
and this example amount will call them

974
00:42:50,650 --> 00:42:55,599
or by name but vendors won't him

975
00:42:53,020 --> 00:42:58,390
entirely implement remember open convict

976
00:42:55,599 --> 00:42:59,920
lets you extend an override models there

977
00:42:58,390 --> 00:43:01,690
is a vendor that extends and overrides

978
00:42:59,920 --> 00:43:05,530
the model and does not provide error

979
00:43:01,690 --> 00:43:09,400
interface the interface error data with

980
00:43:05,530 --> 00:43:10,660
open conflict open config is a step in

981
00:43:09,400 --> 00:43:14,280
the right direction it's not a panacea

982
00:43:10,660 --> 00:43:14,279
that's I guess what I'm going to say

983
00:43:16,020 --> 00:43:19,020
questions

984
00:43:31,190 --> 00:43:36,210
hello welcome to the hackathon

985
00:43:34,440 --> 00:43:40,020
I'm Nathan and I'm gonna be talking

986
00:43:36,210 --> 00:43:44,790
about polling plugins and the lifecycle

987
00:43:40,020 --> 00:43:46,800
of a polling plugin so so this is the

988
00:43:44,790 --> 00:43:49,259
display of the Pinocchios architecture

989
00:43:46,800 --> 00:43:53,280
as presented earlier by my colleague

990
00:43:49,260 --> 00:43:55,020
Vernon we have external open source

991
00:43:53,280 --> 00:43:58,290
projects we depend upon on the bottom

992
00:43:55,020 --> 00:44:01,050
celery for tasks scheduling Redis are in

993
00:43:58,290 --> 00:44:02,520
the memory key value store zookeeper for

994
00:44:01,050 --> 00:44:05,640
locking and then we have the message bus

995
00:44:02,520 --> 00:44:08,970
Kafka we have chef and time series

996
00:44:05,640 --> 00:44:10,440
database on the right framework which

997
00:44:08,970 --> 00:44:13,259
provides the hooks to the external

998
00:44:10,440 --> 00:44:14,700
services and kind of stitches the bottom

999
00:44:13,260 --> 00:44:16,500
dependencies and the plugins together

1000
00:44:14,700 --> 00:44:20,189
and then we have device specific API is

1001
00:44:16,500 --> 00:44:21,750
on the top but for this talk I'm really

1002
00:44:20,190 --> 00:44:25,140
only going to be focusing on pulling

1003
00:44:21,750 --> 00:44:30,650
plugins and the interaction between the

1004
00:44:25,140 --> 00:44:33,270
plugin framework so what is a plug-in a

1005
00:44:30,650 --> 00:44:35,010
plugin is a combination of two files as

1006
00:44:33,270 --> 00:44:38,460
you can see on the right we have a

1007
00:44:35,010 --> 00:44:40,560
Python class to load you can put

1008
00:44:38,460 --> 00:44:44,280
anything you want in this um you can

1009
00:44:40,560 --> 00:44:45,900
import external Python libraries and use

1010
00:44:44,280 --> 00:44:49,230
them call functions on them inside of

1011
00:44:45,900 --> 00:44:52,079
the code you can make an SSA or SNMP

1012
00:44:49,230 --> 00:44:53,819
connection to a device you can import

1013
00:44:52,079 --> 00:44:56,640
the request library and make an API

1014
00:44:53,819 --> 00:44:58,980
connection so really anything you can do

1015
00:44:56,640 --> 00:45:03,118
in Python code you can do within panop

1016
00:44:58,980 --> 00:45:06,810
these plug-in and then on the Left we

1017
00:45:03,119 --> 00:45:08,280
have a config file so the config file is

1018
00:45:06,810 --> 00:45:10,020
actually is what's loaded by the

1019
00:45:08,280 --> 00:45:14,700
scheduler and I'll discuss that in a

1020
00:45:10,020 --> 00:45:18,390
minute and you can see module so that

1021
00:45:14,700 --> 00:45:20,460
tells the panopticon work where to look

1022
00:45:18,390 --> 00:45:23,520
for the plugin there's some

1023
00:45:20,460 --> 00:45:24,960
documentation below and then under the

1024
00:45:23,520 --> 00:45:29,609
main section there's the execution

1025
00:45:24,960 --> 00:45:32,010
frequency so we have this plug-in it

1026
00:45:29,609 --> 00:45:34,470
does something there's code in it but

1027
00:45:32,010 --> 00:45:36,869
how often do we want it to run so within

1028
00:45:34,470 --> 00:45:38,490
the plugin config file you can make

1029
00:45:36,869 --> 00:45:40,230
these specifications here so right now

1030
00:45:38,490 --> 00:45:42,779
the execution frequency for this plug-in

1031
00:45:40,230 --> 00:45:47,130
is 60 seconds so this plug-in will be

1032
00:45:42,779 --> 00:45:49,469
vipin oppas every 60 seconds the next

1033
00:45:47,130 --> 00:45:51,900
item is the resource filter so we have a

1034
00:45:49,469 --> 00:45:55,469
plugin but we need to plug-in to run

1035
00:45:51,900 --> 00:45:56,909
against a device or a set of devices so

1036
00:45:55,469 --> 00:45:59,689
we have essentially what's the

1037
00:45:56,909 --> 00:46:04,589
equivalent of a sequel Lite database

1038
00:45:59,689 --> 00:46:06,149
within cannot these and the polling that

1039
00:46:04,589 --> 00:46:08,099
the plugin scheduler will take the

1040
00:46:06,150 --> 00:46:10,650
resource filter and essentially query

1041
00:46:08,099 --> 00:46:12,689
the database so this one is saying

1042
00:46:10,650 --> 00:46:16,319
resource endpoint is tutorial the device

1043
00:46:12,689 --> 00:46:19,078
so it looks for a unique device ID and

1044
00:46:16,319 --> 00:46:20,880
just returns that device and the plug-in

1045
00:46:19,079 --> 00:46:24,989
will run against the specific device but

1046
00:46:20,880 --> 00:46:26,369
you can say device a resource vendor is

1047
00:46:24,989 --> 00:46:28,109
equal to juniper and that'll return all

1048
00:46:26,369 --> 00:46:29,640
the junipers then you can specify and

1049
00:46:28,109 --> 00:46:31,140
drill down on the operating system name

1050
00:46:29,640 --> 00:46:34,259
so this is just the DSL that allows you

1051
00:46:31,140 --> 00:46:36,179
to specify what devices you want the

1052
00:46:34,259 --> 00:46:38,729
plug-in you've written to run against

1053
00:46:36,179 --> 00:46:42,390
and then finally if you have any

1054
00:46:38,729 --> 00:46:44,519
counters that's in bits out unicast

1055
00:46:42,390 --> 00:46:47,189
packet so anything you can specify that

1056
00:46:44,519 --> 00:46:48,508
here um with the transforms and that'll

1057
00:46:47,189 --> 00:46:51,149
automatically provide rate

1058
00:46:48,509 --> 00:46:53,159
transformation or transformations for

1059
00:46:51,150 --> 00:46:56,130
you and here we specified errors in

1060
00:46:53,159 --> 00:47:01,159
errors out so that'll convert that over

1061
00:46:56,130 --> 00:47:01,159
the execution frequency which is sixty

1062
00:47:01,999 --> 00:47:08,848
so on top of the plugin file there are

1063
00:47:05,939 --> 00:47:11,819
two additional important processes that

1064
00:47:08,849 --> 00:47:14,039
are part of running the plugins as my

1065
00:47:11,819 --> 00:47:17,219
colleague Varun said um we use celery

1066
00:47:14,039 --> 00:47:19,349
for task scheduling and have Redis for

1067
00:47:17,219 --> 00:47:21,390
the backend for that with celery there

1068
00:47:19,349 --> 00:47:24,569
are two parts we have the scheduler and

1069
00:47:21,390 --> 00:47:27,529
the agent what the scheduler does is it

1070
00:47:24,569 --> 00:47:33,558
scans directories and it looks for the

1071
00:47:27,529 --> 00:47:36,209
config files it loads the config files

1072
00:47:33,559 --> 00:47:39,029
module and it uses the resource filter

1073
00:47:36,209 --> 00:47:42,448
located to query the internal device

1074
00:47:39,029 --> 00:47:44,099
list once it has the list of devices to

1075
00:47:42,449 --> 00:47:48,079
run the plugins against it creates a

1076
00:47:44,099 --> 00:47:51,659
schedule entry for each resource ID and

1077
00:47:48,079 --> 00:47:53,459
the plug-in name so essentially when a

1078
00:47:51,659 --> 00:47:55,229
plug-in is scheduled the task is added

1079
00:47:53,459 --> 00:47:56,520
to the queue with the appropriate

1080
00:47:55,229 --> 00:47:59,240
arguments and in this case

1081
00:47:56,520 --> 00:48:02,490
it's just name of the plug-in to run and

1082
00:47:59,240 --> 00:48:05,129
the resource ID and then we have the

1083
00:48:02,490 --> 00:48:07,399
agent we can spin up as many of these as

1084
00:48:05,130 --> 00:48:09,900
you'd like across any number of hosts

1085
00:48:07,400 --> 00:48:12,750
these are processes that run plug-ins

1086
00:48:09,900 --> 00:48:15,570
and agents can load any plugins they can

1087
00:48:12,750 --> 00:48:17,490
run any plug-in assigned to it so it's

1088
00:48:15,570 --> 00:48:19,260
very generic um so it will watch the

1089
00:48:17,490 --> 00:48:21,600
celery queue for incoming jobs it

1090
00:48:19,260 --> 00:48:21,840
constantly ask asks do you have work for

1091
00:48:21,600 --> 00:48:23,190
me

1092
00:48:21,840 --> 00:48:25,770
do you have work for me do work for me

1093
00:48:23,190 --> 00:48:28,260
the second there is work it's a sign it

1094
00:48:25,770 --> 00:48:31,259
receives a task goes into a busy state

1095
00:48:28,260 --> 00:48:33,900
it'll load the plugin execute it and

1096
00:48:31,260 --> 00:48:36,000
then handle the output accordingly and a

1097
00:48:33,900 --> 00:48:40,500
few slides down I'll just be going into

1098
00:48:36,000 --> 00:48:45,630
a step-by-step walkthrough of exactly

1099
00:48:40,500 --> 00:48:48,660
what the agent does just another data

1100
00:48:45,630 --> 00:48:54,960
flow picture this is the data flow of

1101
00:48:48,660 --> 00:48:58,620
the poling plugins we have a plugin run

1102
00:48:54,960 --> 00:49:03,090
against some sort of device SSH

1103
00:48:58,620 --> 00:49:05,009
connection SNMP API query again these

1104
00:49:03,090 --> 00:49:08,070
plugins are Python code and they can do

1105
00:49:05,010 --> 00:49:09,450
anything they query the device gets the

1106
00:49:08,070 --> 00:49:12,770
results some sort of post processing

1107
00:49:09,450 --> 00:49:16,589
occurs if you specify in the config file

1108
00:49:12,770 --> 00:49:19,200
its then put on the message bus and you

1109
00:49:16,590 --> 00:49:21,840
can spin up any number of consumer

1110
00:49:19,200 --> 00:49:23,850
groups to ingest the data and read it as

1111
00:49:21,840 --> 00:49:26,190
you'd like for instance what we have

1112
00:49:23,850 --> 00:49:29,460
built in the doctor and container is an

1113
00:49:26,190 --> 00:49:29,970
influx DB consumer that's set up with

1114
00:49:29,460 --> 00:49:31,710
Griffin ax

1115
00:49:29,970 --> 00:49:32,970
so the second the metrics are ingested

1116
00:49:31,710 --> 00:49:36,420
you can automatically go to localhost

1117
00:49:32,970 --> 00:49:39,899
8080 if you follow the commands on get

1118
00:49:36,420 --> 00:49:42,690
penalties io and metrics are immediately

1119
00:49:39,900 --> 00:49:44,100
available one of the consumers were

1120
00:49:42,690 --> 00:49:46,740
working to open source we have a few

1121
00:49:44,100 --> 00:49:49,020
django applications that automatically

1122
00:49:46,740 --> 00:49:50,879
ingest load balancer interface data and

1123
00:49:49,020 --> 00:49:53,490
make that available and then internally

1124
00:49:50,880 --> 00:50:00,630
we use a variant of open TST v2 and

1125
00:49:53,490 --> 00:50:02,310
metrics so a polling agent when a

1126
00:50:00,630 --> 00:50:04,860
polling agent runs it creates something

1127
00:50:02,310 --> 00:50:06,720
what's called a polling plugin runner

1128
00:50:04,860 --> 00:50:08,790
and this is the task that constantly

1129
00:50:06,720 --> 00:50:10,109
asks do you have work from a do work for

1130
00:50:08,790 --> 00:50:11,700
me do you work for me and

1131
00:50:10,109 --> 00:50:14,359
it does it receives a task and that's

1132
00:50:11,700 --> 00:50:19,200
the combination of the plug-in name and

1133
00:50:14,359 --> 00:50:22,529
the resource ID and remember earlier a

1134
00:50:19,200 --> 00:50:25,489
resource is a representation of a device

1135
00:50:22,529 --> 00:50:28,319
or something that should be monitored

1136
00:50:25,489 --> 00:50:31,380
what happens next is the device lookup

1137
00:50:28,319 --> 00:50:33,210
so it takes this ID and it goes to our

1138
00:50:31,380 --> 00:50:35,460
device store which in this case we use

1139
00:50:33,210 --> 00:50:37,920
Redis so it takes the key looks up the

1140
00:50:35,460 --> 00:50:41,220
value it'll return device data and some

1141
00:50:37,920 --> 00:50:43,380
metadata about the device and the next

1142
00:50:41,220 --> 00:50:45,269
step is loading the plugin remember we

1143
00:50:43,380 --> 00:50:47,880
have the plug-in name that was first

1144
00:50:45,269 --> 00:50:49,769
sent to the pulling plug-in runner so it

1145
00:50:47,880 --> 00:50:52,680
looks through the current directory for

1146
00:50:49,769 --> 00:50:56,549
all files that end in panop DS plugin

1147
00:50:52,680 --> 00:50:59,279
and it loads all of this python code and

1148
00:50:56,549 --> 00:51:05,519
then it applies the filter of the plugin

1149
00:50:59,279 --> 00:51:10,019
name to it to determine which file to

1150
00:51:05,519 --> 00:51:11,879
load when it loads a plugin it loads its

1151
00:51:10,019 --> 00:51:14,459
it loads it into a class called a

1152
00:51:11,880 --> 00:51:17,579
pulling plug-in info on this holds a

1153
00:51:14,460 --> 00:51:20,160
reference to the plug-in to execute as

1154
00:51:17,579 --> 00:51:22,619
well as all sorts of metadata associated

1155
00:51:20,160 --> 00:51:24,749
with a plugin so has the last execution

1156
00:51:22,619 --> 00:51:27,539
time to stamp for the plug-in name

1157
00:51:24,749 --> 00:51:31,859
device pair so when did this plugin

1158
00:51:27,539 --> 00:51:34,319
execute last it also has their last

1159
00:51:31,859 --> 00:51:36,869
results time stamp so when did this

1160
00:51:34,319 --> 00:51:39,420
plug-in execute last and actually return

1161
00:51:36,869 --> 00:51:41,789
time series of that aren't of length

1162
00:51:39,420 --> 00:51:43,109
zero so that's important for debugging

1163
00:51:41,789 --> 00:51:44,640
this plugins running this plugins

1164
00:51:43,109 --> 00:51:46,558
running but we're not getting results

1165
00:51:44,640 --> 00:51:48,808
let's check the last results times down

1166
00:51:46,559 --> 00:51:51,210
resource data so we have some sort of

1167
00:51:48,809 --> 00:51:53,749
metadata about the device also comes

1168
00:51:51,210 --> 00:51:55,920
with a zookeeper lock before penalties

1169
00:51:53,749 --> 00:51:58,980
framework runs a plugin against the

1170
00:51:55,920 --> 00:52:00,509
device it creates and right if it needs

1171
00:51:58,980 --> 00:52:02,609
to be created it will create it if it's

1172
00:52:00,509 --> 00:52:04,380
not and if there already is one it'll

1173
00:52:02,609 --> 00:52:07,950
attempt to acquire a device specific

1174
00:52:04,380 --> 00:52:10,499
lock one of the things we looked at

1175
00:52:07,950 --> 00:52:12,269
initially was we don't want multiple

1176
00:52:10,499 --> 00:52:15,480
plugins running against the same device

1177
00:52:12,269 --> 00:52:20,069
at the same time over pulling was a big

1178
00:52:15,480 --> 00:52:21,450
issue so in order to fix that in order

1179
00:52:20,069 --> 00:52:23,069
to run a plug-in it has to acquire a

1180
00:52:21,450 --> 00:52:23,730
lock which is then released once the

1181
00:52:23,069 --> 00:52:27,240
plug-in is done

1182
00:52:23,730 --> 00:52:29,190
securing so it's a zookeeper lock has a

1183
00:52:27,240 --> 00:52:31,350
reference to the key value store this is

1184
00:52:29,190 --> 00:52:32,790
where all the metadata stored so once

1185
00:52:31,350 --> 00:52:35,040
the plugin is done running it has to go

1186
00:52:32,790 --> 00:52:36,660
back and next update these values so it

1187
00:52:35,040 --> 00:52:39,350
has the reference and then there's the

1188
00:52:36,660 --> 00:52:42,629
config info like execution frequency and

1189
00:52:39,350 --> 00:52:45,420
basically the entire config file that I

1190
00:52:42,630 --> 00:52:47,040
showed you initially so next thing that

1191
00:52:45,420 --> 00:52:49,050
happens it checks to make sure that the

1192
00:52:47,040 --> 00:52:52,109
plugin is able to be executed so it

1193
00:52:49,050 --> 00:52:54,060
checks the last execution time and make

1194
00:52:52,109 --> 00:52:57,029
sure that the execution frequency has

1195
00:52:54,060 --> 00:52:59,640
passed so 60 seconds and make sure that

1196
00:52:57,030 --> 00:53:01,950
at least 60 seconds has passed since the

1197
00:52:59,640 --> 00:53:03,450
plug-in was lost executed and then it

1198
00:53:01,950 --> 00:53:06,270
acquires the lock and then what it does

1199
00:53:03,450 --> 00:53:07,560
next is it calls the run method um you

1200
00:53:06,270 --> 00:53:09,270
look through the code a little bit

1201
00:53:07,560 --> 00:53:11,220
you'll see that all penalties plug-ins

1202
00:53:09,270 --> 00:53:13,619
inherit from the cannot be spaced club

1203
00:53:11,220 --> 00:53:15,569
plugin this is an abstract based class

1204
00:53:13,619 --> 00:53:18,480
so if you inherit from it you have to

1205
00:53:15,570 --> 00:53:20,280
implement the run method this is as you

1206
00:53:18,480 --> 00:53:22,260
can see on the right a function that

1207
00:53:20,280 --> 00:53:24,090
returns Pataki's metrics group set which

1208
00:53:22,260 --> 00:53:26,450
is just containerized time series and

1209
00:53:24,090 --> 00:53:29,640
our internal and serialization format

1210
00:53:26,450 --> 00:53:32,129
just core it's the start time and time

1211
00:53:29,640 --> 00:53:33,868
calls function get time series you can

1212
00:53:32,130 --> 00:53:36,480
implement that however you want it can

1213
00:53:33,869 --> 00:53:38,790
make an API call do anything and then

1214
00:53:36,480 --> 00:53:42,480
log successfully pull device and then

1215
00:53:38,790 --> 00:53:45,080
the time series are returned so great we

1216
00:53:42,480 --> 00:53:48,470
have some results in this case it's

1217
00:53:45,080 --> 00:53:53,549
interface unicast packets in four

1218
00:53:48,470 --> 00:53:57,000
interface name and one em1 as we did as

1219
00:53:53,550 --> 00:54:02,280
we specified some rate transformations

1220
00:53:57,000 --> 00:54:04,500
within the file so it's going to perform

1221
00:54:02,280 --> 00:54:09,109
those transformations and the actual

1222
00:54:04,500 --> 00:54:12,750
output is both a counter and a gauge and

1223
00:54:09,109 --> 00:54:14,460
then the output is pipe to the messaging

1224
00:54:12,750 --> 00:54:18,200
system and it's consumed

1225
00:54:14,460 --> 00:54:21,960
however the consumers are set up so

1226
00:54:18,200 --> 00:54:23,549
that's basically a plugin it's very easy

1227
00:54:21,960 --> 00:54:26,430
to hit the ground running on the get

1228
00:54:23,550 --> 00:54:28,710
Pinnochio website we have a starter SNMP

1229
00:54:26,430 --> 00:54:31,520
plugin that'll automatically connect to

1230
00:54:28,710 --> 00:54:34,980
the device you specify and make a few

1231
00:54:31,520 --> 00:54:37,080
Klerk SNMP queries against interface oh

1232
00:54:34,980 --> 00:54:38,730
it's so that works

1233
00:54:37,080 --> 00:54:40,500
right out of the box it's very easy to

1234
00:54:38,730 --> 00:54:43,440
extend that if you'd like to build some

1235
00:54:40,500 --> 00:54:45,630
sort of SNMP polling plugin we also on

1236
00:54:43,440 --> 00:54:47,640
the get Konopka i/o website we have a

1237
00:54:45,630 --> 00:54:49,500
starter napalm plugin so if you'd like

1238
00:54:47,640 --> 00:54:53,430
to experiment using the napalm library

1239
00:54:49,500 --> 00:54:55,980
against the two pseudo setup the lab you

1240
00:54:53,430 --> 00:54:57,600
can copy and paste that right into your

1241
00:54:55,980 --> 00:54:59,310
code base it'll work right out of the

1242
00:54:57,600 --> 00:55:02,549
box and you can extend that as you see

1243
00:54:59,310 --> 00:55:04,890
fit so start our plugin there and then

1244
00:55:02,550 --> 00:55:06,930
we just have a another plugin that makes

1245
00:55:04,890 --> 00:55:09,029
API calls so we have a few starter

1246
00:55:06,930 --> 00:55:12,870
plugins if you'd like to work on plugins

1247
00:55:09,030 --> 00:55:16,050
and yeah we have documentation and get

1248
00:55:12,870 --> 00:55:19,339
confused i/o next my colleague ian

1249
00:55:16,050 --> 00:55:24,570
holmes is going to be doing a live demo

1250
00:55:19,340 --> 00:55:26,370
ok so starting from the top then so they

1251
00:55:24,570 --> 00:55:28,200
already mentioned the properties docker

1252
00:55:26,370 --> 00:55:29,910
container we have and i have actually

1253
00:55:28,200 --> 00:55:31,890
gone ahead and built that and happened

1254
00:55:29,910 --> 00:55:34,609
running but I did just want to highlight

1255
00:55:31,890 --> 00:55:39,620
one thing which is in my instance I'm

1256
00:55:34,610 --> 00:55:39,620
actually using got my mouse real quick

1257
00:55:40,910 --> 00:55:47,819
in my instance I'm use it I'm actually

1258
00:55:43,530 --> 00:55:49,860
mounting in a directory that I have

1259
00:55:47,820 --> 00:55:53,280
where I'm going to actually be updating

1260
00:55:49,860 --> 00:55:55,800
the tutorial plug-in and then hard to

1261
00:55:53,280 --> 00:56:00,780
hear back there okay if I lean in is

1262
00:55:55,800 --> 00:56:02,700
this okay or is it just well I need both

1263
00:56:00,780 --> 00:56:05,580
hands-free is the only thing you're

1264
00:56:02,700 --> 00:56:09,049
testing testing good I can just hold it

1265
00:56:05,580 --> 00:56:13,890
here alright there we go

1266
00:56:09,050 --> 00:56:16,560
anyway mounting in a the files that I

1267
00:56:13,890 --> 00:56:19,440
need into the appropriate place along

1268
00:56:16,560 --> 00:56:23,160
the polling plugin path here and then

1269
00:56:19,440 --> 00:56:25,740
likewise for dropping in a local host

1270
00:56:23,160 --> 00:56:29,490
JSON file that we will be using for

1271
00:56:25,740 --> 00:56:32,520
defining where where our resources are

1272
00:56:29,490 --> 00:56:37,589
coming from okay so then I'm gonna go

1273
00:56:32,520 --> 00:56:39,509
ahead and just yep awesome so the first

1274
00:56:37,590 --> 00:56:41,550
thing once you get in here and this is

1275
00:56:39,510 --> 00:56:44,610
just separate step is to actually run a

1276
00:56:41,550 --> 00:56:47,540
populate Reedus shell script we have and

1277
00:56:44,610 --> 00:57:00,730
this is just a quick one liner

1278
00:56:47,540 --> 00:57:00,730
whoa okay

1279
00:57:02,840 --> 00:57:14,630
take four all right just go okay so the

1280
00:57:11,000 --> 00:57:18,740
populate Reedus is going to actually go

1281
00:57:14,630 --> 00:57:24,110
ahead and just stick a secret that we

1282
00:57:18,740 --> 00:57:27,549
have for sec for our local community

1283
00:57:24,110 --> 00:57:30,530
site and so you can configure multiple

1284
00:57:27,550 --> 00:57:32,960
sites that you want a given copies in

1285
00:57:30,530 --> 00:57:35,780
certain instance to actually monitor for

1286
00:57:32,960 --> 00:57:37,460
some simplicity's sake you might want to

1287
00:57:35,780 --> 00:57:40,160
define the resources all within a local

1288
00:57:37,460 --> 00:57:43,760
site and then if i actually just copy

1289
00:57:40,160 --> 00:57:47,180
this down and do a get of this in this

1290
00:57:43,760 --> 00:57:50,540
case this is a SNMP community string

1291
00:57:47,180 --> 00:57:59,440
just for public that I will drop it in

1292
00:57:50,540 --> 00:58:06,350
here just show it off and there we go

1293
00:57:59,440 --> 00:58:08,930
okay awesome

1294
00:58:06,350 --> 00:58:10,250
so then for any of the programming that

1295
00:58:08,930 --> 00:58:14,029
you want to do today you're going to

1296
00:58:10,250 --> 00:58:15,830
want to define your resources first so

1297
00:58:14,030 --> 00:58:18,740
let me see here I couldn't figure out

1298
00:58:15,830 --> 00:58:20,029
how to make this sidebar larger but just

1299
00:58:18,740 --> 00:58:21,919
quick rundown on what I have a heaven

1300
00:58:20,030 --> 00:58:26,990
for a configuration I have this

1301
00:58:21,920 --> 00:58:29,000
localhost JSON file here I don't know

1302
00:58:26,990 --> 00:58:35,080
how to do all right I've used it I just

1303
00:58:29,000 --> 00:58:35,080
I'm not you presentation mode this try

1304
00:58:37,930 --> 00:58:44,120
yep let me just escape out of there

1305
00:58:41,890 --> 00:58:46,240
fortunately it's only a few I can't get

1306
00:58:44,120 --> 00:58:46,240
out

1307
00:58:54,540 --> 00:58:58,029
there's only three files that are really

1308
00:58:57,070 --> 00:59:00,640
important just for right at this moment

1309
00:58:58,030 --> 00:59:01,930
one is this local host Jason I'll go

1310
00:59:00,640 --> 00:59:05,470
into in a sec here and then the other

1311
00:59:01,930 --> 00:59:08,379
one is our polling plug-in code so the

1312
00:59:05,470 --> 00:59:11,970
dot pi file that we have and then the

1313
00:59:08,380 --> 00:59:15,099
panopticon plug-in configuration file so

1314
00:59:11,970 --> 00:59:17,319
then what we will want to do and I've

1315
00:59:15,099 --> 00:59:19,240
actually already dropped one in here if

1316
00:59:17,320 --> 00:59:20,980
you were to open this file oh sorry

1317
00:59:19,240 --> 00:59:25,750
sorry to do that this does everybody

1318
00:59:20,980 --> 00:59:27,480
have the docker I do is anybody raise

1319
00:59:25,750 --> 00:59:33,030
your hand if you don't have the docker

1320
00:59:27,480 --> 00:59:33,030
okay so go to get panopticon

1321
00:59:37,570 --> 00:59:44,849
ian is going through is in the tutorial

1322
00:59:40,390 --> 00:59:49,569
pages so you can see a large review

1323
00:59:44,849 --> 00:59:53,290
especially the amounts for the docker

1324
00:59:49,570 --> 00:59:56,170
start so the details about structuring a

1325
00:59:53,290 --> 00:59:58,480
plugin is all there

1326
00:59:56,170 --> 00:59:59,740
Nathan wrote wonderful documentation for

1327
00:59:58,480 --> 01:00:01,690
that so I definitely recommend reading

1328
00:59:59,740 --> 01:00:04,839
through that here too if you're doing

1329
01:00:01,690 --> 01:00:07,150
plugins today to get started in more

1330
01:00:04,839 --> 01:00:09,310
vegas holistic understanding I'm

1331
01:00:07,150 --> 01:00:11,380
actually going to basically show the

1332
01:00:09,310 --> 01:00:13,900
environment where what you have is the

1333
01:00:11,380 --> 01:00:15,760
output of that tutorial where you can

1334
01:00:13,900 --> 01:00:18,490
find various files see how everything's

1335
01:00:15,760 --> 01:00:20,890
melting together so what I've done here

1336
01:00:18,490 --> 01:00:24,160
and actually I'll just drop it back in

1337
01:00:20,890 --> 01:00:26,830
if you open up the localhost JSON file

1338
01:00:24,160 --> 01:00:31,649
you should see this which is a resource

1339
01:00:26,830 --> 01:00:34,509
site a little bigger for your localhost

1340
01:00:31,650 --> 01:00:36,160
resource ID set to the device name like

1341
01:00:34,510 --> 01:00:38,230
room was mentioning and the endpoint

1342
01:00:36,160 --> 01:00:42,220
which is localhost so I'm actually going

1343
01:00:38,230 --> 01:00:44,830
to copy that in order to create a

1344
01:00:42,220 --> 01:00:46,899
resource for one of the virtual devices

1345
01:00:44,830 --> 01:00:50,529
we have today and our emulated network

1346
01:00:46,900 --> 01:00:52,780
from to sudo and so I'm going to keep

1347
01:00:50,530 --> 01:00:56,470
the other details the same here but

1348
01:00:52,780 --> 01:01:00,070
change the resource ID to or the

1349
01:00:56,470 --> 01:01:03,819
resource endpoint first to VM X this is

1350
01:01:00,070 --> 01:01:06,640
a virtual Juniper 10x device and the URL

1351
01:01:03,820 --> 01:01:09,160
format that they have is DMX dot the

1352
01:01:06,640 --> 01:01:13,029
community name which is Nanog 78 the

1353
01:01:09,160 --> 01:01:16,930
organization name which is panopticon to

1354
01:01:13,029 --> 01:01:19,930
sudo dot-com and we actually have if I

1355
01:01:16,930 --> 01:01:21,460
scroll over here we'll leave this up at

1356
01:01:19,930 --> 01:01:24,700
the end here but we actually have the

1357
01:01:21,460 --> 01:01:26,079
devices that we've defined also it up

1358
01:01:24,700 --> 01:01:29,288
here just so that you know what you have

1359
01:01:26,079 --> 01:01:32,200
access to a couple of Cisco's and Arista

1360
01:01:29,289 --> 01:01:34,420
a Juniper device and if anybody needs

1361
01:01:32,200 --> 01:01:37,029
cumulus come help us because we don't

1362
01:01:34,420 --> 01:01:43,210
know how to set up SNMP on it we don't

1363
01:01:37,029 --> 01:01:44,250
use those internally see you did okay

1364
01:01:43,210 --> 01:01:46,900
wonderful

1365
01:01:44,250 --> 01:01:50,619
feel free to a con key boys I may do

1366
01:01:46,900 --> 01:01:51,849
that today all right so once we have

1367
01:01:50,619 --> 01:01:53,619
this set in here I'm going to go and

1368
01:01:51,849 --> 01:01:57,970
just copy that over to be the resource

1369
01:01:53,619 --> 01:02:00,130
ID as well so we defined off the off the

1370
01:01:57,970 --> 01:02:04,328
resource endpoint and then if we drop

1371
01:02:00,130 --> 01:02:08,730
back over into our docker we should see

1372
01:02:04,329 --> 01:02:08,730
this already coming up so let me

1373
01:02:17,130 --> 01:02:24,290
I'm just gonna do keys one more time

1374
01:02:21,300 --> 01:02:24,290
here and

1375
01:02:31,670 --> 01:02:39,500
and excellent so we have our resource

1376
01:02:36,270 --> 01:02:42,330
manager key value store here has already

1377
01:02:39,500 --> 01:02:49,820
discovered the resource that we just

1378
01:02:42,330 --> 01:02:49,819
defined and if we do a get for this one

1379
01:03:02,020 --> 01:03:07,330
we can see there's a pipe too limited

1380
01:03:04,900 --> 01:03:11,110
description of what that looks like and

1381
01:03:07,330 --> 01:03:12,819
so we can see that again actually here I

1382
01:03:11,110 --> 01:03:16,270
guess we just have the timestamp that it

1383
01:03:12,820 --> 01:03:18,130
was created and the resource TTL so

1384
01:03:16,270 --> 01:03:19,630
that's time to live and so this is what

1385
01:03:18,130 --> 01:03:22,930
we used to configure Reedus in order to

1386
01:03:19,630 --> 01:03:34,510
know how long to persist the resources

1387
01:03:22,930 --> 01:03:38,370
that we discover okay so then okay all

1388
01:03:34,510 --> 01:03:42,400
right so I'm going to hop on over to the

1389
01:03:38,370 --> 01:03:44,740
tutorial plugin and so again Nathan

1390
01:03:42,400 --> 01:03:47,620
wrote a really wonderful tutorial I

1391
01:03:44,740 --> 01:03:50,350
recommend stepping through which goes

1392
01:03:47,620 --> 01:03:53,080
into the details of what you can find in

1393
01:03:50,350 --> 01:03:54,790
each polling plugin and it's nice as

1394
01:03:53,080 --> 01:03:56,770
he's actually stripped away some of the

1395
01:03:54,790 --> 01:03:58,330
abstractions so you can see exactly what

1396
01:03:56,770 --> 01:04:04,390
you're working with we're going to

1397
01:03:58,330 --> 01:04:06,730
define a Panoptix group set and then in

1398
01:04:04,390 --> 01:04:08,950
the context of run we're going to grab

1399
01:04:06,730 --> 01:04:13,030
you scroll up here to figure out what we

1400
01:04:08,950 --> 01:04:17,770
have it grab an SNMP connection and then

1401
01:04:13,030 --> 01:04:21,760
make a few queries to populate where am

1402
01:04:17,770 --> 01:04:24,759
I looking for this I think that's the

1403
01:04:21,760 --> 01:04:36,040
case there we go thank you very much

1404
01:04:24,760 --> 01:04:42,540
all right so P there we go

1405
01:04:36,040 --> 01:04:45,100
so for each of these in run we have a

1406
01:04:42,540 --> 01:04:48,520
few commands for interface name

1407
01:04:45,100 --> 01:04:52,060
interface alias speed and then packets

1408
01:04:48,520 --> 01:04:55,120
in packets out and then we're actually

1409
01:04:52,060 --> 01:04:58,240
going to take each of sorry for each of

1410
01:04:55,120 --> 01:05:02,109
these he's decomposed out methods that

1411
01:04:58,240 --> 01:05:06,160
actually query the object ID that

1412
01:05:02,110 --> 01:05:08,110
they're handed steps over for each of

1413
01:05:06,160 --> 01:05:10,899
the indices that are in those relative

1414
01:05:08,110 --> 01:05:14,080
tables stores it internally in the

1415
01:05:10,900 --> 01:05:15,520
interface table and then down here when

1416
01:05:14,080 --> 01:05:17,350
he actually does

1417
01:05:15,520 --> 01:05:19,869
the populate the penalty's metrics group

1418
01:05:17,350 --> 01:05:24,940
set is actually going to drop those in

1419
01:05:19,869 --> 01:05:27,880
so here we have where he's adding each

1420
01:05:24,940 --> 01:05:34,630
of these given metrics as its query from

1421
01:05:27,880 --> 01:05:37,750
the internal table okay so then if I hop

1422
01:05:34,630 --> 01:05:41,530
over now to will actually first let me

1423
01:05:37,750 --> 01:05:44,590
show you a log here if we just tail so

1424
01:05:41,530 --> 01:05:47,200
from home not ease there's a logs

1425
01:05:44,590 --> 01:05:49,050
directory and let me just LS that as

1426
01:05:47,200 --> 01:05:52,180
well so you know what you have access to

1427
01:05:49,050 --> 01:05:54,730
so you have the scheduler and the agent

1428
01:05:52,180 --> 01:05:58,210
that Nathan was talking about for each

1429
01:05:54,730 --> 01:06:01,030
of discovery enrichment and polling

1430
01:05:58,210 --> 01:06:02,800
plugins so in this case we're abstract

1431
01:06:01,030 --> 01:06:07,480
away the enrichment plug-in so I'm just

1432
01:06:02,800 --> 01:06:10,060
going to tail the polling plug-in

1433
01:06:07,480 --> 01:06:12,190
scheduler log so that's going to be

1434
01:06:10,060 --> 01:06:17,860
pulling plug-in sorry click the

1435
01:06:12,190 --> 01:06:20,670
scheduler and we should see here we

1436
01:06:17,860 --> 01:06:20,670
actually grabbed here

1437
01:06:26,140 --> 01:06:31,270
okay that's intended

1438
01:06:41,170 --> 01:06:45,490
see what we got going on here that

1439
01:06:46,300 --> 01:06:51,110
wouldn't actually be named there so

1440
01:06:48,500 --> 01:06:53,210
anyway you can see the scheduler for the

1441
01:06:51,110 --> 01:06:57,110
polling plugins now has four tasks and

1442
01:06:53,210 --> 01:06:58,550
so that would be running the plugins

1443
01:06:57,110 --> 01:07:01,700
that we defined against each of the

1444
01:06:58,550 --> 01:07:03,290
resources so we've defined three or

1445
01:07:01,700 --> 01:07:05,060
sorry three resources at this point two

1446
01:07:03,290 --> 01:07:06,730
of which are one of which is being run

1447
01:07:05,060 --> 01:07:09,560
twice that's why we have a total of four

1448
01:07:06,730 --> 01:07:14,060
and let me actually just hop over then

1449
01:07:09,560 --> 01:07:16,810
to our Ravana dashboard so localhost

1450
01:07:14,060 --> 01:07:21,320
port 8080

1451
01:07:16,810 --> 01:07:23,170
and then I'll actually go to create a

1452
01:07:21,320 --> 01:07:26,330
new dashboard and add a query here

1453
01:07:23,170 --> 01:07:29,390
select the data source from and off

1454
01:07:26,330 --> 01:07:33,590
these and then I'll go to our interface

1455
01:07:29,390 --> 01:07:36,020
data and then set the resource endpoint

1456
01:07:33,590 --> 01:07:37,310
and we can see that may be very small in

1457
01:07:36,020 --> 01:07:39,320
the back but there's localhost and

1458
01:07:37,310 --> 01:07:42,549
there's the VM X that I was just

1459
01:07:39,320 --> 01:07:48,920
mentioning so if I click on the VM X

1460
01:07:42,550 --> 01:07:50,510
let's just grab say the packets in I'm

1461
01:07:48,920 --> 01:07:52,220
going to change the selector for mean

1462
01:07:50,510 --> 01:07:55,850
since we're looking at a specific device

1463
01:07:52,220 --> 01:07:59,270
to last and we can see it's been coming

1464
01:07:55,850 --> 01:08:01,880
in just for an hour so let me grab last

1465
01:07:59,270 --> 01:08:03,140
15 minutes and so that this actually

1466
01:08:01,880 --> 01:08:04,880
shows up better I'm going to fill in

1467
01:08:03,140 --> 01:08:07,819
from previous we can see that it is

1468
01:08:04,880 --> 01:08:11,060
actually getting these metrics already

1469
01:08:07,820 --> 01:08:14,690
coming in so just plugged in from that

1470
01:08:11,060 --> 01:08:18,490
and so what we also have then is I'm

1471
01:08:14,690 --> 01:08:22,880
just going to dart back over here the

1472
01:08:18,490 --> 01:08:24,590
excuse me the tutorial plug-in that we

1473
01:08:22,880 --> 01:08:31,550
have right here so I go back to the

1474
01:08:24,590 --> 01:08:34,190
right one is reading from just a sorry

1475
01:08:31,550 --> 01:08:36,950
it's actually querying the interface

1476
01:08:34,189 --> 01:08:38,870
name interface speed alias as well as

1477
01:08:36,950 --> 01:08:42,679
the packets in and out on every polling

1478
01:08:38,870 --> 01:08:44,660
execution and so unfortunately I had to

1479
01:08:42,680 --> 01:08:47,710
copy this over from another computer

1480
01:08:44,660 --> 01:08:50,389
this morning so things are a little bit

1481
01:08:47,710 --> 01:08:52,550
misaligned right now but I did want to

1482
01:08:50,390 --> 01:08:53,910
show that it is actually possible to

1483
01:08:52,550 --> 01:08:56,730
collect these

1484
01:08:53,910 --> 01:09:00,120
seldom changing data the enrichments for

1485
01:08:56,729 --> 01:09:02,910
the name the alias and the was the other

1486
01:09:00,120 --> 01:09:06,750
one that I just mentioned name alias and

1487
01:09:02,910 --> 01:09:08,309
configure speed to be coming from an

1488
01:09:06,750 --> 01:09:11,490
enrichment and we actually already have

1489
01:09:08,310 --> 01:09:15,180
a plug-in enrichment interface that is

1490
01:09:11,490 --> 01:09:20,580
stored or that is up and running so if I

1491
01:09:15,180 --> 01:09:28,200
go back over to read this real quick I'm

1492
01:09:20,580 --> 01:09:35,420
gonna do echo when I grab keys just see

1493
01:09:28,200 --> 01:09:40,260
what I have for all real quick and then

1494
01:09:35,420 --> 01:09:42,359
here we have so this is line 6 here the

1495
01:09:40,260 --> 01:09:47,100
plugins key value store we're grabbing

1496
01:09:42,359 --> 01:09:51,649
an enrichment for our virtual MX device

1497
01:09:47,100 --> 01:09:55,500
and for the enrichment namespace

1498
01:09:51,649 --> 01:09:57,480
interface like foreign mentioned the

1499
01:09:55,500 --> 01:10:00,720
enrichments really powerful I recommend

1500
01:09:57,480 --> 01:10:02,519
digging into enrichment by looking at

1501
01:10:00,720 --> 01:10:03,810
the enrichment schema and seeing if it's

1502
01:10:02,520 --> 01:10:07,170
abused to you to go ahead and configure

1503
01:10:03,810 --> 01:10:08,880
that as well I think many of you will

1504
01:10:07,170 --> 01:10:11,310
probably choose to work entirely within

1505
01:10:08,880 --> 01:10:13,770
the polling plug-in framework today at

1506
01:10:11,310 --> 01:10:16,980
least to hit the ground running but this

1507
01:10:13,770 --> 01:10:24,020
is worth looking at so let me do a get

1508
01:10:16,980 --> 01:10:24,019
of that value so copy this back over

1509
01:10:28,190 --> 01:10:32,900
grabbed it from the reetou CLI and then

1510
01:10:30,480 --> 01:10:37,469
this is actually JSON so I'm going to

1511
01:10:32,900 --> 01:10:39,269
pretty print the JSON and so for and I

1512
01:10:37,470 --> 01:10:41,340
just remembered I grabbed this from a

1513
01:10:39,270 --> 01:10:45,330
virtual next device so there are a lot

1514
01:10:41,340 --> 01:10:48,720
of entries in here but you can see for a

1515
01:10:45,330 --> 01:10:50,220
given port number because it's coming

1516
01:10:48,720 --> 01:10:52,500
from a virtual device a lot of these are

1517
01:10:50,220 --> 01:10:54,840
actually not set but you have media type

1518
01:10:52,500 --> 01:10:56,280
defined just various enrichments that

1519
01:10:54,840 --> 01:10:58,500
are already collected by our interface

1520
01:10:56,280 --> 01:11:00,929
enrichment polling plug-in and so we

1521
01:10:58,500 --> 01:11:02,280
have a lot of descriptive data to show

1522
01:11:00,930 --> 01:11:06,310
and let me see if I can just get to the

1523
01:11:02,280 --> 01:11:09,730
top here just to show with the

1524
01:11:06,310 --> 01:11:11,440
and I were scrolled just wanted to show

1525
01:11:09,730 --> 01:11:13,450
with the beginning yeah and then we have

1526
01:11:11,440 --> 01:11:15,219
metadata about that enrichment so again

1527
01:11:13,450 --> 01:11:17,889
in this case we're persisting the

1528
01:11:15,220 --> 01:11:21,790
enrichment for 900 seconds or 15 minutes

1529
01:11:17,890 --> 01:11:23,620
and whereas Broome mentioned we

1530
01:11:21,790 --> 01:11:26,110
typically would run enrichments every 30

1531
01:11:23,620 --> 01:11:28,150
minutes for development I because it's

1532
01:11:26,110 --> 01:11:29,410
just on a docker container here only a

1533
01:11:28,150 --> 01:11:33,179
couple plugins I have it running every

1534
01:11:29,410 --> 01:11:33,180
60 seconds so that you can iterate on it

1535
01:11:33,390 --> 01:11:50,770
let me see here so as I go through so if

1536
01:11:45,070 --> 01:11:52,509
the TTL the data expires then you it

1537
01:11:50,770 --> 01:11:54,130
would disappear so that's why you're

1538
01:11:52,510 --> 01:11:55,780
relying on the enrichment plugin

1539
01:11:54,130 --> 01:11:57,300
actually running in this case every

1540
01:11:55,780 --> 01:12:00,340
minute so that it will overwrite the

1541
01:11:57,300 --> 01:12:02,380
data that was stored in and Reedus so

1542
01:12:00,340 --> 01:12:04,510
Reedus is just for those that may not be

1543
01:12:02,380 --> 01:12:07,540
familiar just a temporary key value

1544
01:12:04,510 --> 01:12:09,040
store and so you can define define what

1545
01:12:07,540 --> 01:12:11,470
you want the time to live to be of each

1546
01:12:09,040 --> 01:12:13,000
element for some of those we haven't

1547
01:12:11,470 --> 01:12:15,270
configured to like a week and in other

1548
01:12:13,000 --> 01:12:19,800
cases only for a few minutes like here

1549
01:12:15,270 --> 01:12:19,800
so then

1550
01:12:26,699 --> 01:12:37,648
I can't hear you Vern I believe the

1551
01:12:35,399 --> 01:12:39,809
question was that on the PTL so the TTL

1552
01:12:37,649 --> 01:12:41,820
is typically defined as multiples of the

1553
01:12:39,809 --> 01:12:45,329
execution frequency so even if one

1554
01:12:41,820 --> 01:12:47,849
execution freak fails we'd still be able

1555
01:12:45,329 --> 01:12:50,299
to work with the cached information we

1556
01:12:47,849 --> 01:12:53,010
have in this case it's almost 15 X but

1557
01:12:50,300 --> 01:12:54,630
typically it's uncommon for us to define

1558
01:12:53,010 --> 01:13:04,079
it eight to ten times of what the

1559
01:12:54,630 --> 01:13:05,969
execution execution frequency is right

1560
01:13:04,079 --> 01:13:07,889
but the thing is in the enrichments

1561
01:13:05,969 --> 01:13:09,630
would be updated every 60 seconds so

1562
01:13:07,889 --> 01:13:12,419
only if they're not updated for 15

1563
01:13:09,630 --> 01:13:14,340
minutes continuously then yes you would

1564
01:13:12,419 --> 01:13:18,030
lose polling later because at that point

1565
01:13:14,340 --> 01:13:26,610
you're not sure if you know how fresh

1566
01:13:18,030 --> 01:13:28,380
your data is all right then so then let

1567
01:13:26,610 --> 01:13:33,558
me do one more quick check over anger

1568
01:13:28,380 --> 01:13:37,380
fauna and I believe that in this case

1569
01:13:33,559 --> 01:13:42,269
yes here so let me just head back over

1570
01:13:37,380 --> 01:13:43,889
to hi charm just the last thing that I

1571
01:13:42,269 --> 01:13:45,929
wanted to drive home and I unfortunately

1572
01:13:43,889 --> 01:13:47,849
have been working with this and I think

1573
01:13:45,929 --> 01:13:51,360
I had something just misconfigured on my

1574
01:13:47,849 --> 01:13:55,229
laptop specifically but if you wanted to

1575
01:13:51,360 --> 01:13:56,789
actually so in this case again these

1576
01:13:55,229 --> 01:13:58,860
first three here the interface name

1577
01:13:56,789 --> 01:14:01,139
configures speed and aeleus would be

1578
01:13:58,860 --> 01:14:03,630
what we would think of as enrichments

1579
01:14:01,139 --> 01:14:06,899
that you could grab and if you wanted to

1580
01:14:03,630 --> 01:14:08,699
actually do that or get them from an

1581
01:14:06,899 --> 01:14:10,979
enrichment plug-in the way that that

1582
01:14:08,699 --> 01:14:16,909
would look in code is that you would

1583
01:14:10,979 --> 01:14:19,649
actually define let me see here

1584
01:14:16,909 --> 01:14:24,780
basically here we have penalties SNMP

1585
01:14:19,649 --> 01:14:27,320
based plug-in and there's a a subclass

1586
01:14:24,780 --> 01:14:30,329
of that which is base with enrichment

1587
01:14:27,320 --> 01:14:33,499
plug-in and then what you would do at

1588
01:14:30,329 --> 01:14:38,058
that point is actually just add self dot

1589
01:14:33,499 --> 01:14:40,610
enrichment under your NIT to your

1590
01:14:38,059 --> 01:14:43,969
sorry to your properties and then down

1591
01:14:40,610 --> 01:14:45,619
here you would sorry to your attributes

1592
01:14:43,969 --> 01:14:48,170
and then down here you would actually

1593
01:14:45,619 --> 01:14:52,699
define your enrichment that would be

1594
01:14:48,170 --> 01:14:54,710
defined from the context coming in and

1595
01:14:52,699 --> 01:14:56,119
so then what you can do and I'm just

1596
01:14:54,710 --> 01:14:58,039
going to just show you what the line of

1597
01:14:56,119 --> 01:15:00,049
code looks like and then point you

1598
01:14:58,039 --> 01:15:01,909
towards the other open source plugins to

1599
01:15:00,050 --> 01:15:03,349
look for examples here since

1600
01:15:01,909 --> 01:15:09,098
unfortunately I can't do this portion

1601
01:15:03,349 --> 01:15:20,300
live is you would actually grab self dot

1602
01:15:09,099 --> 01:15:30,469
enrichment and then let me see here just

1603
01:15:20,300 --> 01:15:34,699
scroll up yeah dot enrichment dot get

1604
01:15:30,469 --> 01:15:37,070
enriched min value and then you're

1605
01:15:34,699 --> 01:15:39,440
actually what this is going to do is

1606
01:15:37,070 --> 01:15:40,849
we're going to define the resource for

1607
01:15:39,440 --> 01:15:44,178
grabbing it for us on this case this

1608
01:15:40,849 --> 01:15:45,829
resolves to self results to the resource

1609
01:15:44,179 --> 01:15:50,090
ID that this plugin is being executed

1610
01:15:45,829 --> 01:15:53,349
against the namespace we're wanting to

1611
01:15:50,090 --> 01:15:56,349
grab so that would be the interface and

1612
01:15:53,349 --> 01:15:56,349
then

1613
01:16:06,230 --> 01:16:12,320
and then for whatever specific index you

1614
01:16:09,650 --> 01:16:15,290
might want to actually grab so in this

1615
01:16:12,320 --> 01:16:20,090
case we would define the inner we would

1616
01:16:15,290 --> 01:16:22,400
have populated a interface table like

1617
01:16:20,090 --> 01:16:24,050
Nathan had already done previously in

1618
01:16:22,400 --> 01:16:25,879
his example that I'm copying down this

1619
01:16:24,050 --> 01:16:28,700
interface table and then we would loop

1620
01:16:25,880 --> 01:16:31,330
over that and for each of the indices

1621
01:16:28,700 --> 01:16:36,470
that we have we would actually then

1622
01:16:31,330 --> 01:16:41,420
so getting the enrichment in to call

1623
01:16:36,470 --> 01:16:43,670
this enrichment table and then from the

1624
01:16:41,420 --> 01:16:48,710
enrichment table we would actually do

1625
01:16:43,670 --> 01:16:53,930
see here which my table that I get on

1626
01:16:48,710 --> 01:16:55,850
the specific enrichment name like this

1627
01:16:53,930 --> 01:16:58,700
and then you would probably want to drop

1628
01:16:55,850 --> 01:17:00,260
that into another into the interface

1629
01:16:58,700 --> 01:17:02,510
table or into some other internal

1630
01:17:00,260 --> 01:17:04,580
dictionary that you would use to create

1631
01:17:02,510 --> 01:17:06,080
your PIN appease metrics groups and then

1632
01:17:04,580 --> 01:17:10,220
use those to put into the pen options

1633
01:17:06,080 --> 01:17:11,930
metrics group set button like I said so

1634
01:17:10,220 --> 01:17:14,180
this is messy but there are the other

1635
01:17:11,930 --> 01:17:15,890
plugins that are open-source that that

1636
01:17:14,180 --> 01:17:18,470
are a lot cleaner that you can step

1637
01:17:15,890 --> 01:17:20,000
through for those who are just starting

1638
01:17:18,470 --> 01:17:21,890
off with it I would begin with the

1639
01:17:20,000 --> 01:17:23,810
polling plugins and then look at how

1640
01:17:21,890 --> 01:17:25,130
they're using the enrichment plugins and

1641
01:17:23,810 --> 01:17:27,620
see if that's something that makes

1642
01:17:25,130 --> 01:17:29,960
design sense for you to pick up that's

1643
01:17:27,620 --> 01:17:31,580
all I hang up over here over here yes

1644
01:17:29,960 --> 01:17:34,310
you're actually editing the polling

1645
01:17:31,580 --> 01:17:36,320
plugin it says to add the enrichments in

1646
01:17:34,310 --> 01:17:37,610
this case yes so then you would also I

1647
01:17:36,320 --> 01:17:39,739
don't have a copied in here but you

1648
01:17:37,610 --> 01:17:41,690
would have a separate enrichment plug-in

1649
01:17:39,739 --> 01:17:43,879
that encapsulates your logic about

1650
01:17:41,690 --> 01:17:46,820
actually going out whether it's the SNMP

1651
01:17:43,880 --> 01:17:48,020
API etc to get that information so I'm

1652
01:17:46,820 --> 01:17:49,549
saying pretending you've written that

1653
01:17:48,020 --> 01:17:53,060
plug-in because it's how you would

1654
01:17:49,550 --> 01:17:54,410
actually want it in and and I think that

1655
01:17:53,060 --> 01:17:56,960
probably for most people here would be

1656
01:17:54,410 --> 01:17:59,330
more instructive just to open up one of

1657
01:17:56,960 --> 01:18:01,070
the complete bonafide plugins and just

1658
01:17:59,330 --> 01:18:02,989
look at where that's hook dead

1659
01:18:01,070 --> 01:18:07,250
the main takeaway I just want you to

1660
01:18:02,989 --> 01:18:10,519
take from this is that where you see the

1661
01:18:07,250 --> 01:18:13,250
panopticon pibe plug-in at the end of

1662
01:18:10,520 --> 01:18:15,739
the tutorial that Nathan wrote if you

1663
01:18:13,250 --> 01:18:18,200
wanted to hook in an enrichment then you

1664
01:18:15,739 --> 01:18:19,500
can just call that base with enrichment

1665
01:18:18,200 --> 01:18:20,849
plug-in

1666
01:18:19,500 --> 01:18:22,230
and then if you're in PyCharm like here

1667
01:18:20,850 --> 01:18:24,750
you can actually just command click in

1668
01:18:22,230 --> 01:18:28,650
order to go find a declaration in your

1669
01:18:24,750 --> 01:18:30,180
code base the process for like for

1670
01:18:28,650 --> 01:18:32,099
example when we load the polling plugin

1671
01:18:30,180 --> 01:18:34,200
we change the count file and then we

1672
01:18:32,100 --> 01:18:36,030
went into the Python file within that

1673
01:18:34,200 --> 01:18:37,980
part and added that would we need to do

1674
01:18:36,030 --> 01:18:40,800
the same things for enrichment as well

1675
01:18:37,980 --> 01:18:43,259
change the config file changing the

1676
01:18:40,800 --> 01:18:44,520
convict file so actually yes and I'm

1677
01:18:43,260 --> 01:18:47,640
glad you mentioned that because here

1678
01:18:44,520 --> 01:18:49,650
what we would do is again if we if we

1679
01:18:47,640 --> 01:18:52,110
have this being populated we'd want to

1680
01:18:49,650 --> 01:18:55,679
add the enrichment section and then

1681
01:18:52,110 --> 01:18:57,750
there's going to be a preload key and

1682
01:18:55,680 --> 01:19:00,450
we're going to that would be in this

1683
01:18:57,750 --> 01:19:02,070
case self and the name of your namespace

1684
01:19:00,450 --> 01:19:03,720
in this case interface thank you for

1685
01:19:02,070 --> 01:19:05,429
reminding me of that because you could

1686
01:19:03,720 --> 01:19:10,400
go drop this in but you do actually need

1687
01:19:05,430 --> 01:19:10,400
this configuration for it to run awesome

1688
01:19:13,200 --> 01:19:20,639
hi everyone I'm Caltech I'm from George

1689
01:19:16,960 --> 01:19:24,400
Mason University I'm a master student

1690
01:19:20,640 --> 01:19:31,350
this is my team his Syal Rosita Anamika

1691
01:19:24,400 --> 01:19:34,179
and SIA T thank you

1692
01:19:31,350 --> 01:19:36,000
we literally had no experience with the

1693
01:19:34,180 --> 01:19:40,000
network automation

1694
01:19:36,000 --> 01:19:44,020
thank you if I thank everyone who helped

1695
01:19:40,000 --> 01:19:47,500
us achieve what we have done today we

1696
01:19:44,020 --> 01:19:53,530
have gone through the website and there

1697
01:19:47,500 --> 01:20:00,100
was a tutorial so we tried to create two

1698
01:19:53,530 --> 01:20:02,920
plugins one was the basic polling plugin

1699
01:20:00,100 --> 01:20:09,489
and the other was the Napalm plugin and

1700
01:20:02,920 --> 01:20:12,489
then we got an output yeah we got an

1701
01:20:09,489 --> 01:20:17,980
output like this on our localhost and

1702
01:20:12,489 --> 01:20:22,150
then we still had time so nathan hell

1703
01:20:17,980 --> 01:20:25,629
does add a few metrics to our napalm and

1704
01:20:22,150 --> 01:20:27,969
then we added few metrics one of them

1705
01:20:25,630 --> 01:20:30,700
were me like they were last flagged and

1706
01:20:27,970 --> 01:20:32,770
speed and then we added the metrics we

1707
01:20:30,700 --> 01:20:36,519
changed I mean like we updated

1708
01:20:32,770 --> 01:20:41,770
everything and then we got the logs and

1709
01:20:36,520 --> 01:20:48,030
then we try to pipe the logs into a JSON

1710
01:20:41,770 --> 01:20:48,030
file and then it was looking like this

1711
01:20:48,180 --> 01:20:55,870
and then this is how it looks how the

1712
01:20:53,410 --> 01:21:02,200
output looks on the localhost when we

1713
01:20:55,870 --> 01:21:06,730
add speed and last flab this is all we

1714
01:21:02,200 --> 01:21:10,330
could achieve yeah this is all good we

1715
01:21:06,730 --> 01:21:13,150
could achieve today and thank you Nathan

1716
01:21:10,330 --> 01:21:14,350
he helped us a lot thank you very much

1717
01:21:13,150 --> 01:21:22,129
and

1718
01:21:14,350 --> 01:21:23,690
this is it and thanks Nana and I mean

1719
01:21:22,130 --> 01:21:26,300
all the sponsors for giving us this

1720
01:21:23,690 --> 01:21:28,610
opportunity this was more like a

1721
01:21:26,300 --> 01:21:30,460
learning experience for us than like a

1722
01:21:28,610 --> 01:21:34,660
hackathon and me like a hacking

1723
01:21:30,460 --> 01:21:39,550
competition thank you thank you everyone

1724
01:21:34,660 --> 01:21:44,780
[Applause]

1725
01:21:39,550 --> 01:21:47,630
so hello hello everyone so we are team

1726
01:21:44,780 --> 01:21:49,400
buffs and we are master servants from in

1727
01:21:47,630 --> 01:21:52,940
network engineering from University of

1728
01:21:49,400 --> 01:21:54,410
Colorado Boulder so today today morning

1729
01:21:52,940 --> 01:21:56,599
we got to know about none of this

1730
01:21:54,410 --> 01:21:59,570
actually and we know that right now it's

1731
01:21:56,600 --> 01:22:02,000
a great tool for monitoring on across

1732
01:21:59,570 --> 01:22:04,969
all the platforms so when one mentioned

1733
01:22:02,000 --> 01:22:06,980
that we can add the custom own plugin so

1734
01:22:04,970 --> 01:22:09,380
ipython so we thought we can add more

1735
01:22:06,980 --> 01:22:11,360
functionality to buy one of these by

1736
01:22:09,380 --> 01:22:13,640
creating the adding configuration

1737
01:22:11,360 --> 01:22:15,349
functionalities to that so panneti is

1738
01:22:13,640 --> 01:22:17,090
the tool which monitors everything so

1739
01:22:15,350 --> 01:22:20,060
let's add a configuration functionality

1740
01:22:17,090 --> 01:22:22,730
once we get the alerts so how we did it

1741
01:22:20,060 --> 01:22:25,400
so our hackers we added the custom

1742
01:22:22,730 --> 01:22:27,889
plugins using Python and once we caught

1743
01:22:25,400 --> 01:22:30,530
the alerts to the users who are slack

1744
01:22:27,890 --> 01:22:33,110
when we have a function which will kick

1745
01:22:30,530 --> 01:22:35,269
in into the picture and it will

1746
01:22:33,110 --> 01:22:37,940
configure and it will try to mitigate

1747
01:22:35,270 --> 01:22:38,720
the problem we are trying to solve so

1748
01:22:37,940 --> 01:22:40,400
and yeah

1749
01:22:38,720 --> 01:22:42,560
for the multi vendor capabilities we

1750
01:22:40,400 --> 01:22:44,870
tested it on Juno's as well as Cisco and

1751
01:22:42,560 --> 01:22:48,290
how we did it so let's go to the net

1752
01:22:44,870 --> 01:22:51,620
flow workflow so for monitoring we have

1753
01:22:48,290 --> 01:22:54,290
used net conf and SNMP so due to time

1754
01:22:51,620 --> 01:22:57,110
constraint what we did we had only one

1755
01:22:54,290 --> 01:22:58,970
metric that was our CP utilization so

1756
01:22:57,110 --> 01:23:01,099
while we are getting the real-time CPU

1757
01:22:58,970 --> 01:23:04,220
utilization values we fed it into influx

1758
01:23:01,100 --> 01:23:07,460
DB and visualize that using Gravano so

1759
01:23:04,220 --> 01:23:10,160
to say we had our CPU utilization like

1760
01:23:07,460 --> 01:23:12,440
around 20% at this particular point of

1761
01:23:10,160 --> 01:23:14,510
time so make it more than our threshold

1762
01:23:12,440 --> 01:23:16,549
we reduce the fragmentation on the

1763
01:23:14,510 --> 01:23:19,460
interface that's why the CPU utilization

1764
01:23:16,550 --> 01:23:21,800
crossed our limit so when I say P

1765
01:23:19,460 --> 01:23:24,020
utilization cross the limit then the

1766
01:23:21,800 --> 01:23:26,450
Python program will order to the network

1767
01:23:24,020 --> 01:23:27,360
admin and at the same time it will kick

1768
01:23:26,450 --> 01:23:30,420
in or killing

1769
01:23:27,360 --> 01:23:32,610
script so how we did that I will go into

1770
01:23:30,420 --> 01:23:35,520
the deep so for the key implementations

1771
01:23:32,610 --> 01:23:37,290
for net configuration purpose the

1772
01:23:35,520 --> 01:23:40,530
ceiling script I didn't talking about

1773
01:23:37,290 --> 01:23:43,170
that was used by net conf and why we use

1774
01:23:40,530 --> 01:23:45,840
net Cornett conf is a generic template

1775
01:23:43,170 --> 01:23:48,480
it's an end vendor neutral that's why so

1776
01:23:45,840 --> 01:23:50,880
as a part of Panoptix we have used

1777
01:23:48,480 --> 01:23:53,000
influx DP ingre fauna and just for the

1778
01:23:50,880 --> 01:23:57,300
alert mechanism should have used slack

1779
01:23:53,000 --> 01:23:59,760
so our custom plugin was named as hack

1780
01:23:57,300 --> 01:24:03,750
py as you can see on the left hand side

1781
01:23:59,760 --> 01:24:05,639
that's on the CLI that's our CP utilize

1782
01:24:03,750 --> 01:24:09,810
and we were getting and that were fair

1783
01:24:05,639 --> 01:24:11,730
into our influx DB so that's our

1784
01:24:09,810 --> 01:24:14,040
visualization using graph on ax just to

1785
01:24:11,730 --> 01:24:17,009
explain you can see there is one dot

1786
01:24:14,040 --> 01:24:19,380
over in the red area so that's where our

1787
01:24:17,010 --> 01:24:22,110
CPU utilization cross the threshold

1788
01:24:19,380 --> 01:24:24,659
value and the event alert was generated

1789
01:24:22,110 --> 01:24:27,089
so event an event alert was a thing

1790
01:24:24,659 --> 01:24:29,369
where we were making sure that how many

1791
01:24:27,090 --> 01:24:31,739
times the cell filling script was ran

1792
01:24:29,369 --> 01:24:34,500
into so while we are we captured the

1793
01:24:31,739 --> 01:24:38,489
graph it was once the sleep utilization

1794
01:24:34,500 --> 01:24:41,340
crossed 35 and we got that alert for the

1795
01:24:38,489 --> 01:24:43,949
alerting mechanism we go we use slack

1796
01:24:41,340 --> 01:24:45,900
and that is a slack snippet where it

1797
01:24:43,949 --> 01:24:50,369
shows that there was a CP utilization

1798
01:24:45,900 --> 01:24:52,530
error which had 36% over there so to

1799
01:24:50,369 --> 01:24:55,139
mitigate that I just mentioned that we

1800
01:24:52,530 --> 01:24:57,900
have used net conf and that's the XML

1801
01:24:55,139 --> 01:25:00,900
format the RPC called we were pushing

1802
01:24:57,900 --> 01:25:03,780
the MTU size of 2500 on the Nexus device

1803
01:25:00,900 --> 01:25:06,210
and it got refer after configuring that

1804
01:25:03,780 --> 01:25:09,239
we just checked on the Nexus device that

1805
01:25:06,210 --> 01:25:13,409
was how it does say that the MTU was

1806
01:25:09,239 --> 01:25:15,269
changed to 2500 so after our custom

1807
01:25:13,409 --> 01:25:17,190
plugin we had word with Verone and you

1808
01:25:15,270 --> 01:25:19,350
mentioned and how we can integrate our

1809
01:25:17,190 --> 01:25:22,110
custom plugin into Panoptix and that's

1810
01:25:19,350 --> 01:25:24,179
how we try to plug in our custom plugin

1811
01:25:22,110 --> 01:25:25,980
into pan of things due to the short time

1812
01:25:24,179 --> 01:25:29,159
we haven't tested it very well the

1813
01:25:25,980 --> 01:25:31,769
plugin yeah and the future scope what we

1814
01:25:29,159 --> 01:25:33,540
are going what we can look for is we can

1815
01:25:31,770 --> 01:25:36,780
integrate more sophisticated network

1816
01:25:33,540 --> 01:25:39,210
monitoring as we have net conf it might

1817
01:25:36,780 --> 01:25:40,409
be differing to according to the

1818
01:25:39,210 --> 01:25:43,769
platforms

1819
01:25:40,409 --> 01:25:45,929
and why right now due to time constraint

1820
01:25:43,769 --> 01:25:48,869
we have just used CP utilization or

1821
01:25:45,929 --> 01:25:51,150
monitor mult metric and if we can add

1822
01:25:48,869 --> 01:25:53,159
more metrics into that as well as create

1823
01:25:51,150 --> 01:25:55,409
the potential and the corrective actions

1824
01:25:53,159 --> 01:25:58,079
according to the metrics so these are

1825
01:25:55,409 --> 01:26:01,259
our key takeaways we learn a lot about

1826
01:25:58,079 --> 01:26:03,780
pun of these how we can include the

1827
01:26:01,260 --> 01:26:05,880
subprocesses graph on the influx DV was

1828
01:26:03,780 --> 01:26:09,360
new to me and then net conf

1829
01:26:05,880 --> 01:26:12,360
so and above that we got to we learned

1830
01:26:09,360 --> 01:26:14,249
how the how we can in a leverage the

1831
01:26:12,360 --> 01:26:17,969
power of automation and network proper

1832
01:26:14,249 --> 01:26:20,669
programming program ability so so the

1833
01:26:17,969 --> 01:26:23,729
teamwork time management and yeah never

1834
01:26:20,669 --> 01:26:25,949
give up anything we do that so these are

1835
01:26:23,729 --> 01:26:29,159
my team members so they are sitting over

1836
01:26:25,949 --> 01:26:31,259
there and and if you have any questions

1837
01:26:29,159 --> 01:26:32,969
on how we did that what are the codes we

1838
01:26:31,260 --> 01:26:39,239
have run you can any anytime you can

1839
01:26:32,969 --> 01:26:40,860
email us and thank you so much hi

1840
01:26:39,239 --> 01:26:42,959
everyone I'm Serena D and those are my

1841
01:26:40,860 --> 01:26:44,728
teammates Simran and Vinayak we're a

1842
01:26:42,959 --> 01:26:46,829
team from Juniper Networks we also had

1843
01:26:44,729 --> 01:26:49,469
another member who had to leave early so

1844
01:26:46,829 --> 01:26:52,199
what we did was in addition to the basic

1845
01:26:49,469 --> 01:26:54,419
plugin we added a napalm plugin and the

1846
01:26:52,199 --> 01:26:57,688
focus of it was traffic visualization of

1847
01:26:54,419 --> 01:26:59,010
a typical day for a network operator so

1848
01:26:57,689 --> 01:27:03,059
this was the topology that we were

1849
01:26:59,010 --> 01:27:05,939
working with Chris reserved a different

1850
01:27:03,059 --> 01:27:08,820
topology for us so in the initially we

1851
01:27:05,939 --> 01:27:11,939
had any bgp fabric running B BGP and

1852
01:27:08,820 --> 01:27:13,469
then when we were pinging traffic

1853
01:27:11,939 --> 01:27:16,199
between host 1 and host hood used to

1854
01:27:13,469 --> 01:27:17,849
take the mx2 so even in the trace route

1855
01:27:16,199 --> 01:27:20,459
you can see that the traffic is going

1856
01:27:17,849 --> 01:27:22,979
through mx2 so the scenario for a

1857
01:27:20,459 --> 01:27:25,099
network operator is upgrading the

1858
01:27:22,979 --> 01:27:27,689
devices so if you want to upgrade the

1859
01:27:25,099 --> 01:27:30,360
mx2 you steer the traffic away through

1860
01:27:27,689 --> 01:27:32,239
mx3 so we wrote an custom application

1861
01:27:30,360 --> 01:27:35,549
called drain dot P Y which would

1862
01:27:32,239 --> 01:27:39,119
advertise suboptimal BGP metrics to mx2

1863
01:27:35,550 --> 01:27:41,459
and here the traffic aware and then you

1864
01:27:39,119 --> 01:27:45,598
see that it's taking it through the MX 3

1865
01:27:41,459 --> 01:27:48,119
as the next stop this looks ok but the

1866
01:27:45,599 --> 01:27:50,130
real goal was to actually visualize it

1867
01:27:48,119 --> 01:27:52,530
and give more context to how this all

1868
01:27:50,130 --> 01:27:53,390
looks like so this is a detailed view on

1869
01:27:52,530 --> 01:27:55,330
what we had

1870
01:27:53,390 --> 01:27:57,800
mx2 we were pulling the net nape

1871
01:27:55,330 --> 01:28:00,410
information from the Napalm and we

1872
01:27:57,800 --> 01:28:03,590
resource mx2 and the interface

1873
01:28:00,410 --> 01:28:06,260
statistics and this is on MXC we were

1874
01:28:03,590 --> 01:28:10,760
visualizing the last scene packet value

1875
01:28:06,260 --> 01:28:12,530
and this is a more important slide

1876
01:28:10,760 --> 01:28:13,910
because it brings it all together we

1877
01:28:12,530 --> 01:28:16,040
initially see that the traffic was all

1878
01:28:13,910 --> 01:28:18,200
on vm x 2 and on vm x see the interface

1879
01:28:16,040 --> 01:28:20,360
statistics is less so when we run the

1880
01:28:18,200 --> 01:28:22,550
custom drain application you see that it

1881
01:28:20,360 --> 01:28:24,290
becomes stagnant on vm x 2 so the

1882
01:28:22,550 --> 01:28:25,700
interface statistic the last scene

1883
01:28:24,290 --> 01:28:27,320
packet is the same you don't see any

1884
01:28:25,700 --> 01:28:31,309
additional packets whereas it starts to

1885
01:28:27,320 --> 01:28:33,349
grow on em X 3 and it becomes constant

1886
01:28:31,310 --> 01:28:36,940
there and that's when you see it go down

1887
01:28:33,350 --> 01:28:39,770
that is a simulated upgrade of vm X 2

1888
01:28:36,940 --> 01:28:42,259
and all through this process we see that

1889
01:28:39,770 --> 01:28:43,550
there are no packet drops now granted

1890
01:28:42,260 --> 01:28:44,990
that this was a ping traffic that we

1891
01:28:43,550 --> 01:28:47,720
were running if there were more traffic

1892
01:28:44,990 --> 01:28:50,120
intensive applications we may have seen

1893
01:28:47,720 --> 01:28:51,650
some bad packet drops potentially but

1894
01:28:50,120 --> 01:28:54,470
it's a good way to visualize it all

1895
01:28:51,650 --> 01:28:56,120
together and when we under in it once

1896
01:28:54,470 --> 01:28:58,520
we're done with the upgrade we see that

1897
01:28:56,120 --> 01:29:00,769
the traffic is we run a custom and drain

1898
01:28:58,520 --> 01:29:04,300
application and the traffic goes back to

1899
01:29:00,770 --> 01:29:07,520
VM X to us we see that and in conclusion

1900
01:29:04,300 --> 01:29:09,500
we learnt two new tools we'd never work

1901
01:29:07,520 --> 01:29:11,720
with Panoptix before and graph on either

1902
01:29:09,500 --> 01:29:13,460
so it was a good way to bring it all

1903
01:29:11,720 --> 01:29:15,530
together and I really liked how

1904
01:29:13,460 --> 01:29:18,920
programmer friendly the tool was with

1905
01:29:15,530 --> 01:29:20,179
Python and JSON it was a nice way even

1906
01:29:18,920 --> 01:29:22,310
though it was a short amount of time we

1907
01:29:20,180 --> 01:29:24,890
were able to work well because of how

1908
01:29:22,310 --> 01:29:26,600
efficient it is coding wise and we had

1909
01:29:24,890 --> 01:29:28,700
challenges with the polling scheduler it

1910
01:29:26,600 --> 01:29:31,250
was not even though we had it in the

1911
01:29:28,700 --> 01:29:32,720
docker image build the packages were not

1912
01:29:31,250 --> 01:29:34,550
installed like the Napalm package that

1913
01:29:32,720 --> 01:29:35,900
had to be there so we had to

1914
01:29:34,550 --> 01:29:38,240
troubleshoot a little bit of that so we

1915
01:29:35,900 --> 01:29:41,440
learnt debugging in doing so we learnt a

1916
01:29:38,240 --> 01:29:44,120
lot of debugging and the future work we

1917
01:29:41,440 --> 01:29:46,639
got a start on this is to have a custom

1918
01:29:44,120 --> 01:29:50,480
Kafka consumer which pulls the data and

1919
01:29:46,640 --> 01:29:52,880
maybe data like traffic discards or

1920
01:29:50,480 --> 01:29:55,790
traffic errors you could report it to

1921
01:29:52,880 --> 01:29:57,230
via email or tools like ServiceNow we

1922
01:29:55,790 --> 01:29:59,780
couldn't complete that but that's

1923
01:29:57,230 --> 01:30:01,700
probably a future work that we have so

1924
01:29:59,780 --> 01:30:03,590
there's a nice programmer friendly tool

1925
01:30:01,700 --> 01:30:05,450
and a multi vendor - coming from a

1926
01:30:03,590 --> 01:30:06,630
vendor perspective I think that's really

1927
01:30:05,450 --> 01:30:18,000
cool

1928
01:30:06,630 --> 01:30:21,429
thank you so we don't have a lot of

1929
01:30:18,000 --> 01:30:25,480
great progress so we are not going to

1930
01:30:21,429 --> 01:30:29,350
get in the wheel price tonight but but I

1931
01:30:25,480 --> 01:30:33,040
want to mention that I think Nathan and

1932
01:30:29,350 --> 01:30:36,040
then James for helping out we were

1933
01:30:33,040 --> 01:30:38,350
figuring out different thing and then

1934
01:30:36,040 --> 01:30:41,440
this fall we go we got a troop foot of

1935
01:30:38,350 --> 01:30:46,510
the network and then the red means that

1936
01:30:41,440 --> 01:30:51,129
this alert alert and we also figure out

1937
01:30:46,510 --> 01:30:55,449
the tool to find the OID value from

1938
01:30:51,130 --> 01:30:58,230
online URL we are trying to get more

1939
01:30:55,449 --> 01:31:01,509
detail but we kind of stuck on that but

1940
01:30:58,230 --> 01:31:03,790
since we have a some time we are going

1941
01:31:01,510 --> 01:31:06,310
to bring back the history coming from

1942
01:31:03,790 --> 01:31:08,199
Asia country we have a lot of history

1943
01:31:06,310 --> 01:31:10,420
but so my colleague is going to share

1944
01:31:08,199 --> 01:31:16,928
with you some of the history of SNMP and

1945
01:31:10,420 --> 01:31:20,409
other stuff yes I mean Henry is play

1946
01:31:16,929 --> 01:31:25,420
also we work in OSPF and for me and free

1947
01:31:20,409 --> 01:31:27,610
command bgp so there's been a lot of bad

1948
01:31:25,420 --> 01:31:29,320
memory I think one of the well the

1949
01:31:27,610 --> 01:31:30,820
biggest problem challenge today today

1950
01:31:29,320 --> 01:31:32,620
BGP burst when he started the whole

1951
01:31:30,820 --> 01:31:35,230
thing was not very designed for video

1952
01:31:32,620 --> 01:31:36,940
input the whole thing today shaping this

1953
01:31:35,230 --> 01:31:40,120
video thing is never-ending chasing

1954
01:31:36,940 --> 01:31:42,489
stuff so wherever you have ping traffic

1955
01:31:40,120 --> 01:31:44,500
have no meaning in reality at all you

1956
01:31:42,489 --> 01:31:47,440
don't know the sauce and client things

1957
01:31:44,500 --> 01:31:49,060
and the codec how they shape the part so

1958
01:31:47,440 --> 01:31:50,949
if they'll be cheaper code don't stay

1959
01:31:49,060 --> 01:31:53,949
Cote independent which but your traffic

1960
01:31:50,949 --> 01:31:56,500
in today's video it says never chasing

1961
01:31:53,949 --> 01:32:01,000
down a wall that is not manageable

1962
01:31:56,500 --> 01:32:03,219
because original in 1996 in 2000 that

1963
01:32:01,000 --> 01:32:05,920
was never the idea to do this video

1964
01:32:03,219 --> 01:32:08,290
stuff that's the reason why you need

1965
01:32:05,920 --> 01:32:10,420
integration between codec and bandwidth

1966
01:32:08,290 --> 01:32:12,699
and stuff like that you do so so

1967
01:32:10,420 --> 01:32:15,310
whatever you do to remind me the

1968
01:32:12,699 --> 01:32:18,419
application the heat sorry to the work

1969
01:32:15,310 --> 01:32:18,420
pain does not work

1970
01:32:18,710 --> 01:32:22,710
thank you very much again for all the

1971
01:32:20,970 --> 01:32:29,160
help in learning about this wonderful

1972
01:32:22,710 --> 01:32:33,840
tool so we have a team of folks made up

1973
01:32:29,160 --> 01:32:36,150
from students and faculty at Purdue

1974
01:32:33,840 --> 01:32:39,000
University as well as an employee of

1975
01:32:36,150 --> 01:32:40,950
mythic beasts and so we would like to

1976
01:32:39,000 --> 01:32:46,790
share with you what we have accomplished

1977
01:32:40,950 --> 01:32:54,720
here today do i do i what like that ok

1978
01:32:46,790 --> 01:32:55,890
louder ok so we chose to add a we kind

1979
01:32:54,720 --> 01:32:57,900
of took a different path than other

1980
01:32:55,890 --> 01:33:02,970
folks so far and that we added some new

1981
01:32:57,900 --> 01:33:05,969
functionality to to this pen Aptus set

1982
01:33:02,970 --> 01:33:09,810
up and now it normally communicates with

1983
01:33:05,970 --> 01:33:12,660
in flux DB and and then displays through

1984
01:33:09,810 --> 01:33:14,910
Befana and we are replaced in flux DB

1985
01:33:12,660 --> 01:33:18,300
with prometheus

1986
01:33:14,910 --> 01:33:25,099
and the reason being is that the in flux

1987
01:33:18,300 --> 01:33:30,830
DB is a great x time slice time series

1988
01:33:25,100 --> 01:33:32,760
database however it it has a couple of

1989
01:33:30,830 --> 01:33:35,760
characteristics that we would like to

1990
01:33:32,760 --> 01:33:38,610
offer an alternative for and one of

1991
01:33:35,760 --> 01:33:41,280
those is that it does not allow for high

1992
01:33:38,610 --> 01:33:45,120
availability and horizontal clustering

1993
01:33:41,280 --> 01:33:47,580
so it unless you want to pay so it has

1994
01:33:45,120 --> 01:33:50,430
that option but it's closed source and

1995
01:33:47,580 --> 01:33:52,920
for pay and it's a chunk of change if

1996
01:33:50,430 --> 01:33:56,160
you're looking to implement open source

1997
01:33:52,920 --> 01:33:58,170
software solutions and so Prometheus

1998
01:33:56,160 --> 01:34:00,930
does have that that sort of thing in the

1999
01:33:58,170 --> 01:34:03,300
licensing fee as free as in speech as

2000
01:34:00,930 --> 01:34:05,850
well as free as in beer I'm glad to be

2001
01:34:03,300 --> 01:34:07,740
able to use that particular phrase

2002
01:34:05,850 --> 01:34:11,030
outside of the university setting

2003
01:34:07,740 --> 01:34:11,030
because can't usually do that

2004
01:34:12,449 --> 01:34:17,249
all right so a little bit of extra

2005
01:34:15,719 --> 01:34:19,199
background information especially for

2006
01:34:17,249 --> 01:34:21,719
people that may not have a full

2007
01:34:19,199 --> 01:34:25,829
comprehension on both of these in flux

2008
01:34:21,719 --> 01:34:28,260
DB versus Prometheus in flux is a push

2009
01:34:25,829 --> 01:34:30,090
based system which means if we want to

2010
01:34:28,260 --> 01:34:31,829
make these changes for how frequently

2011
01:34:30,090 --> 01:34:35,059
we're getting this information we have

2012
01:34:31,829 --> 01:34:37,558
to redeploy a lot of different elements

2013
01:34:35,059 --> 01:34:40,229
whereas on a poll based system we make

2014
01:34:37,559 --> 01:34:42,679
that change in one location it can save

2015
01:34:40,229 --> 01:34:45,059
us time it can save us computation

2016
01:34:42,679 --> 01:34:46,829
additionally if you're looking at both

2017
01:34:45,059 --> 01:34:50,459
of the next two slides they kind of

2018
01:34:46,829 --> 01:34:52,499
correlate with each other in flux the

2019
01:34:50,459 --> 01:34:57,329
way they store their values generally

2020
01:34:52,499 --> 01:35:00,809
has a bigger impact on data storage

2021
01:34:57,329 --> 01:35:03,299
you're gonna ultimately store 10 times

2022
01:35:00,809 --> 01:35:05,400
20 times depending on the metrics you're

2023
01:35:03,300 --> 01:35:09,659
gonna store a lot more data for the same

2024
01:35:05,400 --> 01:35:12,239
data set and additionally that can come

2025
01:35:09,659 --> 01:35:14,098
at a higher CPU load so this is

2026
01:35:12,239 --> 01:35:17,129
something that we thought ramiz could

2027
01:35:14,099 --> 01:35:21,030
help solve and then just a couple other

2028
01:35:17,130 --> 01:35:22,949
things to add in flux uses SQL variant

2029
01:35:21,030 --> 01:35:26,550
whereas prometheus uses a simplified

2030
01:35:22,949 --> 01:35:29,249
query model that's more of a preference

2031
01:35:26,550 --> 01:35:31,380
thing doesn't really matter what we will

2032
01:35:29,249 --> 01:35:33,329
give in flux though is that it does have

2033
01:35:31,380 --> 01:35:36,300
role based access controls whereas

2034
01:35:33,329 --> 01:35:39,058
Prometheus does not actually have basic

2035
01:35:36,300 --> 01:35:40,949
auth or are back at all that being said

2036
01:35:39,059 --> 01:35:43,409
there are solutions out there to fix

2037
01:35:40,949 --> 01:35:48,018
that placing it behind a reverse proxy

2038
01:35:43,409 --> 01:35:51,018
can really help get it in that security

2039
01:35:48,019 --> 01:35:51,019
stance

2040
01:35:54,150 --> 01:35:57,179
[Music]

2041
01:35:59,860 --> 01:36:06,139
so we had a in order to implement the

2042
01:36:03,560 --> 01:36:09,350
meteor center into the product we had to

2043
01:36:06,140 --> 01:36:11,330
change the the layout of Howard I would

2044
01:36:09,350 --> 01:36:13,340
give them to the database so originally

2045
01:36:11,330 --> 01:36:17,000
I was pushing it from the kafka consumer

2046
01:36:13,340 --> 01:36:18,860
into into info TV directly we had to

2047
01:36:17,000 --> 01:36:20,990
move it so that we went into Vedas is an

2048
01:36:18,860 --> 01:36:25,089
intermediate database and then Paul

2049
01:36:20,990 --> 01:36:27,380
pulled out of various into Prometheus

2050
01:36:25,090 --> 01:36:28,970
asynchronously so it would push into

2051
01:36:27,380 --> 01:36:40,070
medicine and pull out of that for

2052
01:36:28,970 --> 01:36:47,870
Prometheus okay so to finish this off

2053
01:36:40,070 --> 01:36:50,030
quick demonstration so the influx DB

2054
01:36:47,870 --> 01:36:53,840
variant looks something like this

2055
01:36:50,030 --> 01:37:00,019
and if we take the variant that we

2056
01:36:53,840 --> 01:37:02,450
created it looks something like that

2057
01:37:00,020 --> 01:37:05,210
so you effectively get the same set of

2058
01:37:02,450 --> 01:37:07,849
data being represented it using slightly

2059
01:37:05,210 --> 01:37:09,560
differently structured queries but you

2060
01:37:07,850 --> 01:37:12,860
can get the same result using a database

2061
01:37:09,560 --> 01:37:16,720
that is inherently very different and

2062
01:37:12,860 --> 01:37:16,719
uses a different licensing model so

2063
01:37:18,280 --> 01:37:21,769
[Applause]

2064
01:37:22,719 --> 01:37:28,030
okay hello everybody my name is Eddie

2065
01:37:25,790 --> 01:37:33,159
Metzger and I am here with Team Rocket

2066
01:37:28,030 --> 01:37:35,360
and we had a problem that we identified

2067
01:37:33,159 --> 01:37:37,280
so we're gonna run through kind of a

2068
01:37:35,360 --> 01:37:39,650
couple of things here and then

2069
01:37:37,280 --> 01:37:42,590
demonstrate the solution script at the

2070
01:37:39,650 --> 01:37:45,888
end so we identified that there's an

2071
01:37:42,590 --> 01:37:48,739
issue with troubleshooting so I mean

2072
01:37:45,889 --> 01:37:50,329
mainly it's just expensive you have

2073
01:37:48,739 --> 01:37:52,159
these different ticket levels that are

2074
01:37:50,329 --> 01:37:54,079
assigned and it moves through this layer

2075
01:37:52,159 --> 01:37:57,619
that takes too much time and too much

2076
01:37:54,079 --> 01:38:00,739
money so there are multiple types of

2077
01:37:57,619 --> 01:38:02,119
packets and all of them cost different

2078
01:38:00,739 --> 01:38:04,040
things but on average they're costing

2079
01:38:02,119 --> 01:38:06,829
you about you know $100 each ticket

2080
01:38:04,040 --> 01:38:08,530
which can add up you know throughout the

2081
01:38:06,829 --> 01:38:10,579
months and then eventually the year into

2082
01:38:08,530 --> 01:38:11,900
hundreds of thousands of dollars each

2083
01:38:10,579 --> 01:38:17,659
year and just ticketing and solving

2084
01:38:11,900 --> 01:38:22,610
these problems and so and so we

2085
01:38:17,659 --> 01:38:24,530
recognized we recognized that there's a

2086
01:38:22,610 --> 01:38:26,929
need for really kind of an automating

2087
01:38:24,530 --> 01:38:29,690
this process of troubleshooting and

2088
01:38:26,929 --> 01:38:31,520
testing and so with automated regression

2089
01:38:29,690 --> 01:38:33,500
testing you're ensuring that the

2090
01:38:31,520 --> 01:38:35,030
features work is intended and don't

2091
01:38:33,500 --> 01:38:37,460
negatively affect the environment that

2092
01:38:35,030 --> 01:38:38,869
you're producing in so kind of assuming

2093
01:38:37,460 --> 01:38:40,250
that you have a new device that you're

2094
01:38:38,869 --> 01:38:42,889
running a new configuration on this is

2095
01:38:40,250 --> 01:38:44,329
where it becomes really helpful so why

2096
01:38:42,889 --> 01:38:46,520
don't benders always conduct this

2097
01:38:44,329 --> 01:38:49,670
regression testing on devices it takes a

2098
01:38:46,520 --> 01:38:51,469
lot of time and so the plugin that we

2099
01:38:49,670 --> 01:38:53,300
kind of developed or worked on and

2100
01:38:51,469 --> 01:38:55,310
started to create really creates an

2101
01:38:53,300 --> 01:38:56,570
automated troubleshooting environment to

2102
01:38:55,310 --> 01:38:58,429
help you move through these levels of

2103
01:38:56,570 --> 01:39:00,290
ticketing and so it automates the

2104
01:38:58,429 --> 01:39:02,929
process using automated regression

2105
01:39:00,290 --> 01:39:05,210
cycles so a couple of use cases would be

2106
01:39:02,929 --> 01:39:07,130
testing new software for code and then

2107
01:39:05,210 --> 01:39:11,480
testing custom solutions POC for

2108
01:39:07,130 --> 01:39:12,739
customers and so finally the the

2109
01:39:11,480 --> 01:39:14,290
structure of this is you know you

2110
01:39:12,739 --> 01:39:16,669
configure a device with specifications

2111
01:39:14,290 --> 01:39:19,190
and the devices that might have new

2112
01:39:16,670 --> 01:39:20,659
ports and then you run this automated

2113
01:39:19,190 --> 01:39:22,190
regression testing on that new port

2114
01:39:20,659 --> 01:39:23,900
using the plug-in and address the

2115
01:39:22,190 --> 01:39:28,549
problems immediately rather than in a

2116
01:39:23,900 --> 01:39:31,820
future ticket hello my name is Hasan and

2117
01:39:28,550 --> 01:39:34,559
I'll just give a couple of minutes for

2118
01:39:31,820 --> 01:39:38,188
the use case so the use case is this

2119
01:39:34,559 --> 01:39:39,869
about we open customers have issues they

2120
01:39:38,189 --> 01:39:41,569
open a particular and they have me

2121
01:39:39,869 --> 01:39:43,829
sometimes may have more than one

2122
01:39:41,569 --> 01:39:46,109
departments in Walled and you try to

2123
01:39:43,829 --> 01:39:48,688
troubleshoot the tickets is assigned to

2124
01:39:46,109 --> 01:39:52,229
tier 1 tier 2 or tier 3 but in this

2125
01:39:48,689 --> 01:39:54,959
scenario if we automate the matching

2126
01:39:52,229 --> 01:39:57,469
condition for the boolean ones and zeros

2127
01:39:54,959 --> 01:40:00,269
like if the route is coming from this

2128
01:39:57,469 --> 01:40:02,519
router or not or if there is a ping is

2129
01:40:00,269 --> 01:40:04,709
going on from this router or not then

2130
01:40:02,519 --> 01:40:08,369
that would say and assign that portal to

2131
01:40:04,709 --> 01:40:10,589
specific customers that would help for

2132
01:40:08,369 --> 01:40:14,009
them to in fact diagnose where the

2133
01:40:10,589 --> 01:40:15,959
problem could be in the first hand so

2134
01:40:14,010 --> 01:40:18,149
that they don't have to wait and see or

2135
01:40:15,959 --> 01:40:20,188
call the nog and save the resources and

2136
01:40:18,149 --> 01:40:22,530
their times for the troubleshooting part

2137
01:40:20,189 --> 01:40:26,010
but right now what we worked on and

2138
01:40:22,530 --> 01:40:28,199
another aspect of this is cisco juniper

2139
01:40:26,010 --> 01:40:31,349
all the vendors there in releasing new

2140
01:40:28,199 --> 01:40:33,749
softwares every other day and as being

2141
01:40:31,349 --> 01:40:35,729
your operator you want to make sure that

2142
01:40:33,749 --> 01:40:38,129
sort of sports all the features and

2143
01:40:35,729 --> 01:40:40,169
functions which you're providing

2144
01:40:38,129 --> 01:40:43,439
solution to your corporate customers so

2145
01:40:40,169 --> 01:40:46,499
to test that automation and make it an

2146
01:40:43,439 --> 01:40:48,510
automated solution we need to configure

2147
01:40:46,499 --> 01:40:51,300
and test those features on the new

2148
01:40:48,510 --> 01:40:55,409
software codes and that's what we tried

2149
01:40:51,300 --> 01:40:59,219
in this first plugin we were working on

2150
01:40:55,409 --> 01:41:02,818
building one configuration template to

2151
01:40:59,219 --> 01:41:05,189
push the configs on the devices and then

2152
01:41:02,819 --> 01:41:07,649
test them that ok this feature is

2153
01:41:05,189 --> 01:41:09,239
working for example for this is an OS PF

2154
01:41:07,649 --> 01:41:11,819
neighbor ship we're pushing the

2155
01:41:09,239 --> 01:41:15,780
conflicts to configure or SPF on the 2mx

2156
01:41:11,819 --> 01:41:20,099
which we got set up and this is just the

2157
01:41:15,780 --> 01:41:24,688
snapshots of the na pom napalm plugin

2158
01:41:20,099 --> 01:41:26,550
and the previous plug in 2 for the just

2159
01:41:24,689 --> 01:41:30,119
the output so that we can see we already

2160
01:41:26,550 --> 01:41:35,179
established the baseline for this this

2161
01:41:30,119 --> 01:41:37,889
one is the napalm output as well and

2162
01:41:35,179 --> 01:41:40,260
that's pretty much it if everybody had

2163
01:41:37,889 --> 01:41:42,809
and has any question they can come up or

2164
01:41:40,260 --> 01:41:44,309
we can explain and the more application

2165
01:41:42,809 --> 01:41:45,040
just to quickly mention David also

2166
01:41:44,309 --> 01:41:47,590
mentioned we

2167
01:41:45,040 --> 01:41:51,850
can use ansible if we integrate ansible

2168
01:41:47,590 --> 01:41:53,770
with the penalty it's going to help us a

2169
01:41:51,850 --> 01:41:56,440
lot in the longer and where we can

2170
01:41:53,770 --> 01:41:58,660
automate the jobs and do the monitoring

2171
01:41:56,440 --> 01:42:30,849
at the same time of the results thank

2172
01:41:58,660 --> 01:42:35,200
you do I really need the microphone I'm

2173
01:42:30,850 --> 01:42:38,260
really really yellow darn it okay

2174
01:42:35,200 --> 01:42:46,599
as I said we're noobs there we go

2175
01:42:38,260 --> 01:42:49,510
so me TJ d J and J on so except me I'm

2176
01:42:46,600 --> 01:42:54,250
not a J so this is what we managed to

2177
01:42:49,510 --> 01:42:55,870
get working in grow fauna it's super

2178
01:42:54,250 --> 01:42:58,330
fancy I know I worked really hard on

2179
01:42:55,870 --> 01:43:00,070
this we worked really hard on this there

2180
01:42:58,330 --> 01:43:01,510
were very very long paths I'm including

2181
01:43:00,070 --> 01:43:04,330
this in case anybody wants to reproduce

2182
01:43:01,510 --> 01:43:06,390
any of this work we're gonna refer them

2183
01:43:04,330 --> 01:43:09,250
refer to them by the file names

2184
01:43:06,390 --> 01:43:11,830
reproduction steps are from this get

2185
01:43:09,250 --> 01:43:15,100
panicked he's done IO document and in

2186
01:43:11,830 --> 01:43:17,850
that I added the definitions Oh ID

2187
01:43:15,100 --> 01:43:21,820
definitions in the Python script I

2188
01:43:17,850 --> 01:43:24,580
commented with what I added how do we

2189
01:43:21,820 --> 01:43:28,240
find those I used the provided

2190
01:43:24,580 --> 01:43:30,970
documentation or the Junos mid explore

2191
01:43:28,240 --> 01:43:32,440
and verify them on the router itself

2192
01:43:30,970 --> 01:43:33,990
since y'all kindly gave us read-only

2193
01:43:32,440 --> 01:43:36,400
access

2194
01:43:33,990 --> 01:43:38,260
reproduction steps there were a couple

2195
01:43:36,400 --> 01:43:42,490
of other places that we had to edit the

2196
01:43:38,260 --> 01:43:48,370
polling plugin dot py script this is the

2197
01:43:42,490 --> 01:43:50,889
second third and then we had to make a

2198
01:43:48,370 --> 01:43:53,710
dot panic tease plugin for it which

2199
01:43:50,890 --> 01:43:55,330
references those things the winds were

2200
01:43:53,710 --> 01:43:57,310
that it works it was simple to get the

2201
01:43:55,330 --> 01:43:58,269
same docker setup on an ec2 instance

2202
01:43:57,310 --> 01:44:00,670
with just a dish

2203
01:43:58,269 --> 01:44:02,019
port forwarding foregrip onna the

2204
01:44:00,670 --> 01:44:04,150
struggles there were too many shells

2205
01:44:02,019 --> 01:44:05,519
Python docker and bash and in which

2206
01:44:04,150 --> 01:44:07,480
shell everything was supposed to live

2207
01:44:05,519 --> 01:44:09,880
changes outside the docker container

2208
01:44:07,480 --> 01:44:12,339
being for absolute not and wasting a

2209
01:44:09,880 --> 01:44:13,659
little bit of our time trying changes

2210
01:44:12,340 --> 01:44:15,010
not immediately propagating and having

2211
01:44:13,659 --> 01:44:17,920
to wait for some of it windows

2212
01:44:15,010 --> 01:44:19,809
compatibility was problem plugins

2213
01:44:17,920 --> 01:44:21,130
crashing with no nothing no notification

2214
01:44:19,809 --> 01:44:22,809
because lines that begin with eight

2215
01:44:21,130 --> 01:44:27,760
spaces that look like tabs are not

2216
01:44:22,809 --> 01:44:34,840
actually tabs and general complaining

2217
01:44:27,760 --> 01:44:37,659
about the Mac keyboard so you can either

2218
01:44:34,840 --> 01:44:39,730
interpret this as how the noobs saw our

2219
01:44:37,659 --> 01:44:54,610
day to day or you can say that

2220
01:44:39,730 --> 01:44:56,919
panopticon fire alright so I think we're

2221
01:44:54,610 --> 01:44:58,869
team you forge a also cannot B's graph I

2222
01:44:56,920 --> 01:45:00,249
don't like naming teams those of you who

2223
01:44:58,869 --> 01:45:03,518
are at the last hackathon would remember

2224
01:45:00,249 --> 01:45:06,269
team pod one but we did some interesting

2225
01:45:03,519 --> 01:45:09,249
graph database stuff with penalties so

2226
01:45:06,269 --> 01:45:11,469
just a quick summary of what we did we

2227
01:45:09,249 --> 01:45:13,329
wrote a generic napalm polling plugin

2228
01:45:11,469 --> 01:45:15,460
that all of our different vendor plugins

2229
01:45:13,329 --> 01:45:17,799
inherited from this polling plug-in

2230
01:45:15,460 --> 01:45:21,369
added lldp data to our interface

2231
01:45:17,800 --> 01:45:24,340
counters as well as speed so that we

2232
01:45:21,369 --> 01:45:27,249
could calculate link utilization and we

2233
01:45:24,340 --> 01:45:29,079
then added a Kafka consumer that listen

2234
01:45:27,249 --> 01:45:32,499
to the Kafka topic that copies publishes

2235
01:45:29,079 --> 01:45:35,590
to and forwarded that data into neo4j

2236
01:45:32,499 --> 01:45:37,329
using neo model which is a or m for

2237
01:45:35,590 --> 01:45:42,070
neo4j and you know four days craft

2238
01:45:37,329 --> 01:45:47,139
database and then using that neo4j

2239
01:45:42,070 --> 01:45:49,840
browser we plotted some pretty graphs so

2240
01:45:47,139 --> 01:45:53,230
this is what we wanted this has you know

2241
01:45:49,840 --> 01:45:54,460
the full they be had some struggles and

2242
01:45:53,230 --> 01:45:55,959
while we hit those struggles i answered

2243
01:45:54,460 --> 01:45:57,159
a bunch of dumb you database data into

2244
01:45:55,960 --> 01:45:58,570
the database so that we could at least

2245
01:45:57,159 --> 01:45:59,219
show you a pretty graph if everything

2246
01:45:58,570 --> 01:46:02,549
went to hell

2247
01:45:59,219 --> 01:46:04,989
so this is the pretty graph we won in

2248
01:46:02,550 --> 01:46:06,760
this just a pre graph we got so we

2249
01:46:04,989 --> 01:46:09,019
actually got really really close we're

2250
01:46:06,760 --> 01:46:11,540
only missing one set of links in there

2251
01:46:09,020 --> 01:46:13,400
as the problem we had here was that

2252
01:46:11,540 --> 01:46:15,290
cumulus does not have a napalm driver

2253
01:46:13,400 --> 01:46:19,129
and we didn't have time to write a

2254
01:46:15,290 --> 01:46:20,960
napalm very free cumulus and the Nexus

2255
01:46:19,130 --> 01:46:22,600
napalm driver doesn't have a get

2256
01:46:20,960 --> 01:46:25,400
interface counters method implemented

2257
01:46:22,600 --> 01:46:28,090
which really surprising because Nexus is

2258
01:46:25,400 --> 01:46:30,860
a pretty popular platform but you know

2259
01:46:28,090 --> 01:46:32,750
so excited we got really really close

2260
01:46:30,860 --> 01:46:34,400
one of the things you can't see on this

2261
01:46:32,750 --> 01:46:36,080
because we didn't get a chance to do any

2262
01:46:34,400 --> 01:46:40,730
fancier interfaces is that we actually

2263
01:46:36,080 --> 01:46:42,440
store speed port names etc on that link

2264
01:46:40,730 --> 01:46:43,910
relationship and so you can actually

2265
01:46:42,440 --> 01:46:45,799
query that data out of the graph

2266
01:46:43,910 --> 01:46:47,090
database and if we'd had more time we

2267
01:46:45,800 --> 01:46:50,740
would have had some pretty colors on

2268
01:46:47,090 --> 01:46:50,740
these lengths to demonstrate utilization

2269
01:46:51,040 --> 01:46:56,570
so challenges we hit like I mentioned

2270
01:46:54,200 --> 01:46:58,340
napalm support cumulus totally

2271
01:46:56,570 --> 01:47:02,000
unsupported Nexus had broken interface

2272
01:46:58,340 --> 01:47:04,100
counters and then iOS XR the counters

2273
01:47:02,000 --> 01:47:05,360
were just oh sorry napalm their Nexus

2274
01:47:04,100 --> 01:47:07,550
didn't even have the interface counter

2275
01:47:05,360 --> 01:47:10,190
method and iOS XR was not correctly

2276
01:47:07,550 --> 01:47:11,510
reporting counters and so we didn't get

2277
01:47:10,190 --> 01:47:14,540
the you know the pretty numbers we

2278
01:47:11,510 --> 01:47:16,720
wanted there and then with the big issue

2279
01:47:14,540 --> 01:47:18,890
we hit is we found out the hard way that

2280
01:47:16,720 --> 01:47:21,770
cannot be use doesn't support relative

2281
01:47:18,890 --> 01:47:23,780
imports and your plugin file and so we

2282
01:47:21,770 --> 01:47:27,380
spent god knows how long

2283
01:47:23,780 --> 01:47:28,880
debugging that had smith frantically

2284
01:47:27,380 --> 01:47:31,790
filling the graph database with dummy

2285
01:47:28,880 --> 01:47:35,810
data but we found it eventually and we

2286
01:47:31,790 --> 01:47:38,480
got copies working so next steps

2287
01:47:35,810 --> 01:47:39,740
obviously napalm support or replacing

2288
01:47:38,480 --> 01:47:42,769
napalm with some other device

2289
01:47:39,740 --> 01:47:45,620
interaction layer adding that pretty

2290
01:47:42,770 --> 01:47:46,820
coloring you know building a more kind

2291
01:47:45,620 --> 01:47:48,410
of advanced interface to that graph

2292
01:47:46,820 --> 01:47:50,809
database because said we just use neo4j

2293
01:47:48,410 --> 01:47:52,400
browser for this but there are a lot of

2294
01:47:50,810 --> 01:47:54,740
really cool javascript libraries out

2295
01:47:52,400 --> 01:47:58,309
there that can connect directly at any

2296
01:47:54,740 --> 01:48:00,800
o4j and do more advanced display and

2297
01:47:58,310 --> 01:48:02,660
then finally doing something more

2298
01:48:00,800 --> 01:48:04,100
interesting than just topology maps with

2299
01:48:02,660 --> 01:48:05,540
this data with the state in a graph

2300
01:48:04,100 --> 01:48:08,120
database there's kind of a ton of

2301
01:48:05,540 --> 01:48:10,670
different applications out there and so

2302
01:48:08,120 --> 01:48:13,099
this is definitely a starting point for

2303
01:48:10,670 --> 01:48:13,860
a lot of other interesting work thank

2304
01:48:13,100 --> 01:48:19,950
you

2305
01:48:13,860 --> 01:48:22,929
[Applause]

2306
01:48:19,950 --> 01:48:24,730
okay we have a number of votes in and

2307
01:48:22,930 --> 01:48:27,490
we're going to call it with the top two

2308
01:48:24,730 --> 01:48:36,070
teams being the neo4j graft team and the

2309
01:48:27,490 --> 01:48:38,050
Perdue teams so and of course a huge

2310
01:48:36,070 --> 01:48:39,610
thank you to everybody so we're going to

2311
01:48:38,050 --> 01:48:42,780
do a couple more things before breaking

2312
01:48:39,610 --> 01:48:45,519
here so the first order of business is

2313
01:48:42,780 --> 01:48:48,580
having at least one person from both of

2314
01:48:45,520 --> 01:48:53,080
those teams come and see me afterwards

2315
01:48:48,580 --> 01:48:55,870
so we can wrangle presentations for the

2316
01:48:53,080 --> 01:48:58,380
plenary session on Tuesday all right

2317
01:48:55,870 --> 01:49:00,940
thank you everybody for coming out and

2318
01:48:58,380 --> 01:49:04,410
congratulations to all of our winners

2319
01:49:00,940 --> 01:49:07,240
[Applause]

2320
01:49:04,410 --> 01:49:10,240
and I'd like to put in a plug right now

2321
01:49:07,240 --> 01:49:12,880
to say if you did your hacks and you're

2322
01:49:10,240 --> 01:49:14,800
proud of them contribute them back do a

2323
01:49:12,880 --> 01:49:16,870
pull request against the the hackathon

2324
01:49:14,800 --> 01:49:18,280
base and yeah let's get some community

2325
01:49:16,870 --> 01:49:21,880
involvement and and get people

2326
01:49:18,280 --> 01:49:24,550
contributing to Panoptix so yeah thanks

2327
01:49:21,880 --> 01:49:27,370
again and the reception is out under the

2328
01:49:24,550 --> 01:49:31,500
giant mysterious copper ball in the

2329
01:49:27,370 --> 01:49:31,500
lobby so we'll see you all out there

