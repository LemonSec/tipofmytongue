1
00:00:01,040 --> 00:00:07,120
[Music]

2
00:00:07,120 --> 00:00:09,040
so thank you jan and thank you for

3
00:00:09,040 --> 00:00:11,519
the to the panelists for this uh

4
00:00:11,519 --> 00:00:12,400
interesting and

5
00:00:12,400 --> 00:00:15,679
and very active discussion now our day

6
00:00:15,679 --> 00:00:17,359
will be concluded with a keynote from

7
00:00:17,359 --> 00:00:17,840
the

8
00:00:17,840 --> 00:00:19,840
vice president on european government

9
00:00:19,840 --> 00:00:21,359
affairs of microsoft

10
00:00:21,359 --> 00:00:24,000
mr kasper klinger the discussion with mr

11
00:00:24,000 --> 00:00:25,439
klinger will be held by our

12
00:00:25,439 --> 00:00:27,119
international law researcher

13
00:00:27,119 --> 00:00:30,080
tachyana yanchakova please tanya the

14
00:00:30,080 --> 00:00:32,879
floor is yours

15
00:00:32,900 --> 00:00:41,619
[Music]

16
00:00:41,920 --> 00:00:44,960
thank you very much henrik

17
00:00:44,960 --> 00:00:47,280
ladies and gentlemen in the good time of

18
00:00:47,280 --> 00:00:49,440
the day to your respective time zones

19
00:00:49,440 --> 00:00:51,600
as hendrick has hinted i have the

20
00:00:51,600 --> 00:00:53,199
pleasure today to welcome mr

21
00:00:53,199 --> 00:00:54,399
kaspeklinger

22
00:00:54,399 --> 00:00:56,879
microsoft's vice president for european

23
00:00:56,879 --> 00:00:58,079
government affairs

24
00:00:58,079 --> 00:01:01,120
before joining microsoft mr klinger has

25
00:01:01,120 --> 00:01:04,000
had gained authority in as denmark's and

26
00:01:04,000 --> 00:01:05,280
the world's first

27
00:01:05,280 --> 00:01:07,920
tech ambassador connecting those domains

28
00:01:07,920 --> 00:01:09,920
of diplomacy and the big tech

29
00:01:09,920 --> 00:01:11,680
he therefore has a unique insight into

30
00:01:11,680 --> 00:01:13,840
the mindset of tech industry

31
00:01:13,840 --> 00:01:15,360
while understanding the concerns

32
00:01:15,360 --> 00:01:17,439
governments might have when reconciling

33
00:01:17,439 --> 00:01:19,200
technological advancement

34
00:01:19,200 --> 00:01:21,680
and values they are tasks to protect in

35
00:01:21,680 --> 00:01:22,479
this session

36
00:01:22,479 --> 00:01:24,720
mr klinger will set the ground with his

37
00:01:24,720 --> 00:01:26,159
opening remarks

38
00:01:26,159 --> 00:01:28,320
upon which we will continue in a more

39
00:01:28,320 --> 00:01:29,520
interactive manner

40
00:01:29,520 --> 00:01:30,799
and hopefully have an interesting

41
00:01:30,799 --> 00:01:33,840
conversation on artificial intelligence

42
00:01:33,840 --> 00:01:36,479
its responsible use and defense context

43
00:01:36,479 --> 00:01:38,000
you are all

44
00:01:38,000 --> 00:01:39,840
warmly invited to contribute with your

45
00:01:39,840 --> 00:01:41,520
questions by the chat function

46
00:01:41,520 --> 00:01:44,000
on the conference webpage mr klinger

47
00:01:44,000 --> 00:01:45,119
welcome the floor

48
00:01:45,119 --> 00:01:55,840
floor is yours

49
00:01:58,320 --> 00:01:59,840
well first of all thanks very much

50
00:01:59,840 --> 00:02:01,520
tatyana and thanks for the uh the warm

51
00:02:01,520 --> 00:02:02,799
welcome today

52
00:02:02,799 --> 00:02:04,799
um and let me begin by saying i think

53
00:02:04,799 --> 00:02:06,399
what what everybody else have been

54
00:02:06,399 --> 00:02:07,920
feeling and saying earlier today it's

55
00:02:07,920 --> 00:02:09,840
such a shame that we cannot be together

56
00:02:09,840 --> 00:02:10,479
for

57
00:02:10,479 --> 00:02:12,160
what i think is a really timely uh

58
00:02:12,160 --> 00:02:13,920
discussion uh today but but hopefully

59
00:02:13,920 --> 00:02:15,520
next year will will come together as

60
00:02:15,520 --> 00:02:16,560
well

61
00:02:16,560 --> 00:02:19,599
and listen as i said i i think it is you

62
00:02:19,599 --> 00:02:21,520
know fantastic that you put

63
00:02:21,520 --> 00:02:24,000
on the topic on the agenda for today a

64
00:02:24,000 --> 00:02:26,480
discussion about sort of nato's

65
00:02:26,480 --> 00:02:29,440
involvement in new technologies the role

66
00:02:29,440 --> 00:02:31,360
of the technology industry and i

67
00:02:31,360 --> 00:02:32,959
might be able to repeat a couple of

68
00:02:32,959 --> 00:02:34,840
points that i heard in the previous

69
00:02:34,840 --> 00:02:37,440
discussion i think it's timely and as

70
00:02:37,440 --> 00:02:39,440
we've seen also during the the last

71
00:02:39,440 --> 00:02:42,959
14 15 months you know technology is

72
00:02:42,959 --> 00:02:45,760
uh penetrating or transcending every

73
00:02:45,760 --> 00:02:46,480
single

74
00:02:46,480 --> 00:02:48,080
sector that we're involved in so i think

75
00:02:48,080 --> 00:02:49,360
it's only natural that we're beginning

76
00:02:49,360 --> 00:02:50,080
this discussion

77
00:02:50,080 --> 00:02:53,200
also focusing on on nato's role and i

78
00:02:53,200 --> 00:02:54,560
actually wanted to go back to

79
00:02:54,560 --> 00:02:58,000
to december 2019 and the london summit

80
00:02:58,000 --> 00:02:59,920
of nato that i

81
00:02:59,920 --> 00:03:01,840
remember quite clearly and the reason i

82
00:03:01,840 --> 00:03:03,360
remember it is that i think

83
00:03:03,360 --> 00:03:06,319
the declaration we saw coming forward on

84
00:03:06,319 --> 00:03:09,200
emerging and disruptive technologies was

85
00:03:09,200 --> 00:03:11,120
nato basically looking into the crystal

86
00:03:11,120 --> 00:03:13,360
ball and i think taking a very strategic

87
00:03:13,360 --> 00:03:15,040
and important step forward

88
00:03:15,040 --> 00:03:17,920
in recognizing that also you know the

89
00:03:17,920 --> 00:03:19,840
strongest defense alliance of this world

90
00:03:19,840 --> 00:03:22,319
will lead to increasingly focusing on

91
00:03:22,319 --> 00:03:24,319
what technologies will do both in terms

92
00:03:24,319 --> 00:03:26,239
of opportunities but certainly also in

93
00:03:26,239 --> 00:03:28,319
terms of challenges

94
00:03:28,319 --> 00:03:30,239
and and i think what we all realize

95
00:03:30,239 --> 00:03:32,640
today regardless of whether we

96
00:03:32,640 --> 00:03:35,040
work on on the private sector side or in

97
00:03:35,040 --> 00:03:36,480
governments or in international

98
00:03:36,480 --> 00:03:37,599
organizations like

99
00:03:37,599 --> 00:03:40,319
like nato is that technology has a

100
00:03:40,319 --> 00:03:41,840
fundamental impact on

101
00:03:41,840 --> 00:03:45,360
international relations on geopolitics

102
00:03:45,360 --> 00:03:47,280
but also really on the foundation of our

103
00:03:47,280 --> 00:03:49,920
societies defending democracy etc

104
00:03:49,920 --> 00:03:51,680
so i think it's fantastic that we we

105
00:03:51,680 --> 00:03:53,120
have this discussion

106
00:03:53,120 --> 00:03:55,920
today i also want to welcome you know

107
00:03:55,920 --> 00:03:56,799
recent steps

108
00:03:56,799 --> 00:03:58,879
taken by nato and in this regard i'm of

109
00:03:58,879 --> 00:04:00,000
course talking about the

110
00:04:00,000 --> 00:04:03,040
upcoming strategy on artificial

111
00:04:03,040 --> 00:04:04,319
intelligence

112
00:04:04,319 --> 00:04:06,239
and this is perhaps the topic i will try

113
00:04:06,239 --> 00:04:08,239
and focus a little bit on in the

114
00:04:08,239 --> 00:04:09,519
introductory remarks

115
00:04:09,519 --> 00:04:12,319
today because i think it is a technology

116
00:04:12,319 --> 00:04:13,439
that is going to have

117
00:04:13,439 --> 00:04:16,560
a significant impact on our societies

118
00:04:16,560 --> 00:04:19,120
but also on the alliance

119
00:04:19,120 --> 00:04:21,358
i think the first point to to make as

120
00:04:21,358 --> 00:04:23,919
others have done earlier today is that

121
00:04:23,919 --> 00:04:26,479
artificial intelligence is or machine

122
00:04:26,479 --> 00:04:29,040
learning is of course a technology that

123
00:04:29,040 --> 00:04:31,919
can be used for many good things but it

124
00:04:31,919 --> 00:04:34,080
can also be used

125
00:04:34,080 --> 00:04:37,199
as a as a weapon as a tool against us i

126
00:04:37,199 --> 00:04:39,199
think striking that balance and making

127
00:04:39,199 --> 00:04:41,840
sure that we approach artificial

128
00:04:41,840 --> 00:04:44,000
in a responsible way is in many ways one

129
00:04:44,000 --> 00:04:45,840
of the key challenges

130
00:04:45,840 --> 00:04:48,720
of our time and i think when you look at

131
00:04:48,720 --> 00:04:50,960
it from a defense point of view or

132
00:04:50,960 --> 00:04:54,240
in a conflict concept

133
00:04:54,240 --> 00:04:56,320
and one of the key things that we look

134
00:04:56,320 --> 00:04:58,320
at from an industry point of view is of

135
00:04:58,320 --> 00:04:59,280
course how ai

136
00:04:59,280 --> 00:05:02,320
is going to help us also mitigate some

137
00:05:02,320 --> 00:05:04,080
of the key challenges of our time and i

138
00:05:04,080 --> 00:05:05,199
just want to point out

139
00:05:05,199 --> 00:05:07,680
on the cyber security agenda that this

140
00:05:07,680 --> 00:05:08,560
is certainly an

141
00:05:08,560 --> 00:05:10,240
area where artificial intelligence

142
00:05:10,240 --> 00:05:12,240
already today is playing

143
00:05:12,240 --> 00:05:15,199
a remarkable role in trying to mitigate

144
00:05:15,199 --> 00:05:16,400
the threat that is

145
00:05:16,400 --> 00:05:18,880
coming towards us from both state and

146
00:05:18,880 --> 00:05:20,160
non-state actors

147
00:05:20,160 --> 00:05:22,320
if you look at a company like microsoft

148
00:05:22,320 --> 00:05:24,720
we have in fact as of today automated

149
00:05:24,720 --> 00:05:28,800
you know almost 97 of our routine tasks

150
00:05:28,800 --> 00:05:30,560
using machine learning and artificial

151
00:05:30,560 --> 00:05:32,880
intelligence and we've also become much

152
00:05:32,880 --> 00:05:34,000
better at detecting

153
00:05:34,000 --> 00:05:36,720
uh some of the attacks that are coming

154
00:05:36,720 --> 00:05:38,000
in in the direction so that

155
00:05:38,000 --> 00:05:40,240
makes us better at being the first

156
00:05:40,240 --> 00:05:42,400
responders in defending our customers

157
00:05:42,400 --> 00:05:44,000
but also defending

158
00:05:44,000 --> 00:05:46,160
the public sector from from one of the

159
00:05:46,160 --> 00:05:47,360
key challenges of

160
00:05:47,360 --> 00:05:50,400
today one of the ways

161
00:05:50,400 --> 00:05:52,639
that it is is enabling us to use

162
00:05:52,639 --> 00:05:54,960
artificial intelligence is of course

163
00:05:54,960 --> 00:05:57,039
uh our cloud first strategy the fact

164
00:05:57,039 --> 00:05:58,080
that the

165
00:05:58,080 --> 00:06:00,639
cloud offers unique and unprecedented

166
00:06:00,639 --> 00:06:03,280
unprecedented opportunities for using

167
00:06:03,280 --> 00:06:05,680
you know large-scale data sets and and

168
00:06:05,680 --> 00:06:07,520
using ai and ml

169
00:06:07,520 --> 00:06:11,199
uh for for better defending the

170
00:06:11,199 --> 00:06:12,880
the systems that we have out and about

171
00:06:12,880 --> 00:06:14,720
today so one of the points that we of

172
00:06:14,720 --> 00:06:15,759
course wanted to make

173
00:06:15,759 --> 00:06:18,319
is that you know a cloud strategy in our

174
00:06:18,319 --> 00:06:19,199
view

175
00:06:19,199 --> 00:06:21,600
is is a fundamental aspect of utilizing

176
00:06:21,600 --> 00:06:23,280
the opportunities that ai is bringing

177
00:06:23,280 --> 00:06:24,160
forward

178
00:06:24,160 --> 00:06:26,800
and then you know tatyana you might get

179
00:06:26,800 --> 00:06:28,639
a question from the audience you know do

180
00:06:28,639 --> 00:06:29,120
we have

181
00:06:29,120 --> 00:06:32,160
interest in microsoft in promoting

182
00:06:32,160 --> 00:06:34,319
a cloud first strategy and the answer is

183
00:06:34,319 --> 00:06:36,160
of course yes we do we are

184
00:06:36,160 --> 00:06:38,080
one of the hyper skill providers of this

185
00:06:38,080 --> 00:06:40,000
world but i would still say that

186
00:06:40,000 --> 00:06:43,280
we would advocate a cloud strategy

187
00:06:43,280 --> 00:06:45,199
any day of the week also if those cloud

188
00:06:45,199 --> 00:06:46,800
opportunities would fall

189
00:06:46,800 --> 00:06:48,960
into the hands of our competitors as

190
00:06:48,960 --> 00:06:51,039
we've seen with some of the latest

191
00:06:51,039 --> 00:06:54,240
cyber attacks you know on-premise rather

192
00:06:54,240 --> 00:06:54,880
than

193
00:06:54,880 --> 00:06:57,599
in cloud actually provides less security

194
00:06:57,599 --> 00:06:58,240
and

195
00:06:58,240 --> 00:07:00,800
makes it more difficult also for us to

196
00:07:00,800 --> 00:07:01,680
defend

197
00:07:01,680 --> 00:07:05,120
our customers sensitive data etc

198
00:07:05,120 --> 00:07:06,800
but i think we also have to recognize as

199
00:07:06,800 --> 00:07:08,080
others have mentioned in the previous

200
00:07:08,080 --> 00:07:09,520
discussion that

201
00:07:09,520 --> 00:07:12,319
there is an arms race out here ai and ml

202
00:07:12,319 --> 00:07:14,000
can also be used by

203
00:07:14,000 --> 00:07:16,479
the aggressors by the adversaries for

204
00:07:16,479 --> 00:07:18,560
launching increasingly sophisticated

205
00:07:18,560 --> 00:07:19,440
attacks

206
00:07:19,440 --> 00:07:20,960
and we've seen just in the last six

207
00:07:20,960 --> 00:07:23,599
months attacks like solar winds

208
00:07:23,599 --> 00:07:25,919
we've seen the recent half pneumatec and

209
00:07:25,919 --> 00:07:27,120
i think those are good

210
00:07:27,120 --> 00:07:29,840
reminders that artificial intelligence

211
00:07:29,840 --> 00:07:31,599
is not only going to be used

212
00:07:31,599 --> 00:07:33,440
as a tool to defend our systems and

213
00:07:33,440 --> 00:07:35,599
defend our societies is also going to be

214
00:07:35,599 --> 00:07:37,440
used by the perpetrators to launch

215
00:07:37,440 --> 00:07:38,880
increasingly

216
00:07:38,880 --> 00:07:41,520
complicated attacks and and that i think

217
00:07:41,520 --> 00:07:42,000
brings

218
00:07:42,000 --> 00:07:43,599
us to the discussion of why it is that

219
00:07:43,599 --> 00:07:45,680
nato needs to focus and invest more on

220
00:07:45,680 --> 00:07:47,280
artificial intelligence

221
00:07:47,280 --> 00:07:50,080
and why i think again that the upcoming

222
00:07:50,080 --> 00:07:52,080
er strategy is such a welcome step

223
00:07:52,080 --> 00:07:52,720
forward

224
00:07:52,720 --> 00:07:55,199
i think ultimately for for nato this is

225
00:07:55,199 --> 00:07:56,840
about retaining

226
00:07:56,840 --> 00:07:59,919
superiority in a world that is becoming

227
00:07:59,919 --> 00:08:02,240
increasingly different by technology and

228
00:08:02,240 --> 00:08:04,479
i think it is absolutely necessary for

229
00:08:04,479 --> 00:08:06,080
nature to focus on

230
00:08:06,080 --> 00:08:08,639
a concept like artificial intelligence

231
00:08:08,639 --> 00:08:10,160
if you want me to be a little bit

232
00:08:10,160 --> 00:08:11,120
provocative

233
00:08:11,120 --> 00:08:13,039
and i apologize in advance for doing

234
00:08:13,039 --> 00:08:14,639
that i think we've seen

235
00:08:14,639 --> 00:08:16,639
the european union we've seen the united

236
00:08:16,639 --> 00:08:17,680
nations

237
00:08:17,680 --> 00:08:19,440
actually investing quite a lot in

238
00:08:19,440 --> 00:08:21,440
looking into the crystal ball trying to

239
00:08:21,440 --> 00:08:23,520
find strategies for

240
00:08:23,520 --> 00:08:25,360
adopting and handling the new

241
00:08:25,360 --> 00:08:27,280
technologies that are coming forward so

242
00:08:27,280 --> 00:08:29,280
to some extent the question is not

243
00:08:29,280 --> 00:08:30,960
whether nato should do it i think the

244
00:08:30,960 --> 00:08:32,799
question is why nato has not done it

245
00:08:32,799 --> 00:08:33,599
before

246
00:08:33,599 --> 00:08:35,279
and i'm saying this of course in a

247
00:08:35,279 --> 00:08:37,200
friendly way of teasing nato a little

248
00:08:37,200 --> 00:08:37,599
bit

249
00:08:37,599 --> 00:08:39,120
but fundamentally saying that i think

250
00:08:39,120 --> 00:08:41,039
it's it's high noon and very timely that

251
00:08:41,039 --> 00:08:43,200
nato is investing a lot in looking

252
00:08:43,200 --> 00:08:45,600
at the technology of artificial

253
00:08:45,600 --> 00:08:47,040
intelligence

254
00:08:47,040 --> 00:08:49,279
i think finding the responsible way of

255
00:08:49,279 --> 00:08:50,640
looking at ai

256
00:08:50,640 --> 00:08:53,519
is also an area where nato has a unique

257
00:08:53,519 --> 00:08:54,959
opportunity

258
00:08:54,959 --> 00:08:56,480
both to make sure that also in the

259
00:08:56,480 --> 00:08:58,880
battlefield when we deal with this in

260
00:08:58,880 --> 00:09:00,080
the defense area

261
00:09:00,080 --> 00:09:02,560
that ai is used in really in a

262
00:09:02,560 --> 00:09:03,760
responsible way

263
00:09:03,760 --> 00:09:05,440
but then i think the the advantage of

264
00:09:05,440 --> 00:09:07,279
nate so that also for a company like

265
00:09:07,279 --> 00:09:09,120
microsoft is incredibly important is

266
00:09:09,120 --> 00:09:09,839
that

267
00:09:09,839 --> 00:09:11,839
this is also a way of of keeping the

268
00:09:11,839 --> 00:09:14,000
transatlantic relationship together and

269
00:09:14,000 --> 00:09:15,600
making sure that we also across the

270
00:09:15,600 --> 00:09:17,680
atlantic have a clear focus on

271
00:09:17,680 --> 00:09:19,200
again the opportunities of these new

272
00:09:19,200 --> 00:09:21,519
technologies but also developing them in

273
00:09:21,519 --> 00:09:24,320
a way forward that is is responsible

274
00:09:24,320 --> 00:09:26,080
and the last thing i would say is that i

275
00:09:26,080 --> 00:09:27,839
think when you look at the broader

276
00:09:27,839 --> 00:09:30,160
framework of nature looking at emerging

277
00:09:30,160 --> 00:09:32,000
and disruptive technologies

278
00:09:32,000 --> 00:09:33,760
i think one of the advantages here is

279
00:09:33,760 --> 00:09:35,519
that that gives the opportunity to

280
00:09:35,519 --> 00:09:36,560
create

281
00:09:36,560 --> 00:09:39,680
or perhaps even create a new opportunity

282
00:09:39,680 --> 00:09:42,160
in in creating a dialogue between the

283
00:09:42,160 --> 00:09:43,360
industry and needs so

284
00:09:43,360 --> 00:09:45,760
perhaps even creating an interface of a

285
00:09:45,760 --> 00:09:47,680
continued dialogue between nato and the

286
00:09:47,680 --> 00:09:48,560
industry

287
00:09:48,560 --> 00:09:50,640
i think for us in in microsoft that is

288
00:09:50,640 --> 00:09:51,760
something that we would

289
00:09:51,760 --> 00:09:55,120
warmly welcome we are struggling with

290
00:09:55,120 --> 00:09:56,959
finding the right way forward on on

291
00:09:56,959 --> 00:09:58,480
responsible use of ai

292
00:09:58,480 --> 00:10:00,560
every single day but actually having a

293
00:10:00,560 --> 00:10:02,320
dialogue with nato

294
00:10:02,320 --> 00:10:04,720
looking at ethical principles coming out

295
00:10:04,720 --> 00:10:05,760
of nato

296
00:10:05,760 --> 00:10:07,680
would enable not only us working closely

297
00:10:07,680 --> 00:10:09,360
together with nato but i think it would

298
00:10:09,360 --> 00:10:10,320
also

299
00:10:10,320 --> 00:10:12,959
open up to opportunities for the wider

300
00:10:12,959 --> 00:10:15,360
ecosystem of of innovative technology

301
00:10:15,360 --> 00:10:17,200
companies to really align with

302
00:10:17,200 --> 00:10:20,079
with nato so wrapping up sort of the

303
00:10:20,079 --> 00:10:22,160
introductory remark here i think

304
00:10:22,160 --> 00:10:24,399
first of all fantastic we're seeing nato

305
00:10:24,399 --> 00:10:25,760
move into this area

306
00:10:25,760 --> 00:10:27,839
secondly we want to be a partner with

307
00:10:27,839 --> 00:10:29,200
nato we want to help

308
00:10:29,200 --> 00:10:31,360
both develop the strategy but also make

309
00:10:31,360 --> 00:10:34,480
make sure that our technology

310
00:10:34,480 --> 00:10:36,480
can can come forward in a responsible

311
00:10:36,480 --> 00:10:38,560
way in a helpful way to the alliance

312
00:10:38,560 --> 00:10:40,800
and therefore we would strongly advocate

313
00:10:40,800 --> 00:10:43,279
as the previous speaker also did that

314
00:10:43,279 --> 00:10:45,120
perhaps time is right for us to create

315
00:10:45,120 --> 00:10:47,279
sort of a multi-stakeholder framework

316
00:10:47,279 --> 00:10:48,800
where the industry can come closer

317
00:10:48,800 --> 00:10:50,880
together with nato in solving

318
00:10:50,880 --> 00:10:53,279
some of the big issues of our time i'll

319
00:10:53,279 --> 00:10:54,720
leave it at that to begin with but

320
00:10:54,720 --> 00:10:55,680
thanks again for

321
00:10:55,680 --> 00:11:00,880
giving me the flow thank you very much

322
00:11:00,880 --> 00:11:01,920
mr klinger

323
00:11:01,920 --> 00:11:04,720
uh i like the the level of introspection

324
00:11:04,720 --> 00:11:06,640
when you spoke about microsoft's uh

325
00:11:06,640 --> 00:11:10,320
being a primary supplier of

326
00:11:10,320 --> 00:11:12,720
cloud services and you're interested in

327
00:11:12,720 --> 00:11:14,160
it however let me take you

328
00:11:14,160 --> 00:11:17,760
uh even further down the memory lane

329
00:11:17,760 --> 00:11:20,160
uh in 2017 actually microsoft's

330
00:11:20,160 --> 00:11:21,519
president brett smith

331
00:11:21,519 --> 00:11:24,560
in his tools and weapons book because a

332
00:11:24,560 --> 00:11:27,440
meeting in davos i believe in 2017

333
00:11:27,440 --> 00:11:30,320
when where a discussion on artificial

334
00:11:30,320 --> 00:11:32,320
intelligence was in full swing

335
00:11:32,320 --> 00:11:34,160
yet it was clear that half of the

336
00:11:34,160 --> 00:11:35,680
audience didn't really have an idea of

337
00:11:35,680 --> 00:11:37,920
what artificial intelligence was

338
00:11:37,920 --> 00:11:40,000
and at the same time we're too shy to

339
00:11:40,000 --> 00:11:42,720
ask so i wonder

340
00:11:42,720 --> 00:11:45,040
since this is a very timely and topic

341
00:11:45,040 --> 00:11:47,760
and substantively charged debate

342
00:11:47,760 --> 00:11:49,680
do you get the impression with your from

343
00:11:49,680 --> 00:11:51,200
your discussions with governments and

344
00:11:51,200 --> 00:11:52,560
military representatives

345
00:11:52,560 --> 00:11:55,760
that this extent

346
00:11:55,760 --> 00:11:59,279
of um let's say level of awareness

347
00:11:59,279 --> 00:12:01,760
has changed for the better today are we

348
00:12:01,760 --> 00:12:03,440
all on the same page today when we

349
00:12:03,440 --> 00:12:05,600
speak about artificial intelligence and

350
00:12:05,600 --> 00:12:08,720
it's responsible use

351
00:12:09,279 --> 00:12:10,959
i think it would probably be going too

352
00:12:10,959 --> 00:12:12,959
far to say we're on the same page

353
00:12:12,959 --> 00:12:15,040
because you know even for those of us

354
00:12:15,040 --> 00:12:16,480
working within one of the most

355
00:12:16,480 --> 00:12:18,399
innovative companies of this world

356
00:12:18,399 --> 00:12:20,240
i think keeping up with our engineers

357
00:12:20,240 --> 00:12:21,440
and understanding

358
00:12:21,440 --> 00:12:22,800
you know where this technology is

359
00:12:22,800 --> 00:12:24,959
heading and and and the usability of

360
00:12:24,959 --> 00:12:27,120
this technology is just incredibly

361
00:12:27,120 --> 00:12:30,240
difficult and and it perhaps shows the

362
00:12:30,240 --> 00:12:30,800
pace

363
00:12:30,800 --> 00:12:32,639
of developing of these technologies

364
00:12:32,639 --> 00:12:34,720
which again might be unprecedented

365
00:12:34,720 --> 00:12:37,440
but but i do want to be a little bit

366
00:12:37,440 --> 00:12:38,000
positive

367
00:12:38,000 --> 00:12:39,360
in this area because i do think that

368
00:12:39,360 --> 00:12:41,519
when we look at at the last sort of 14

369
00:12:41,519 --> 00:12:43,680
15 months with a global pandemic

370
00:12:43,680 --> 00:12:45,040
you know one of the areas where we've

371
00:12:45,040 --> 00:12:47,040
seen a massive change is of course the

372
00:12:47,040 --> 00:12:49,680
acceleration of digitalization at least

373
00:12:49,680 --> 00:12:51,200
here in europe

374
00:12:51,200 --> 00:12:53,600
and and for whatever it's worth i think

375
00:12:53,600 --> 00:12:54,959
in in my own dialogue

376
00:12:54,959 --> 00:12:56,959
with european governments with european

377
00:12:56,959 --> 00:12:58,000
stakeholders

378
00:12:58,000 --> 00:13:00,720
with nato with nato member states with

379
00:13:00,720 --> 00:13:02,399
the european commission as well as many

380
00:13:02,399 --> 00:13:04,399
many other stakeholders across europe

381
00:13:04,399 --> 00:13:06,160
i think there is a better understanding

382
00:13:06,160 --> 00:13:08,000
today of the roller technology the

383
00:13:08,000 --> 00:13:09,680
importance of technology

384
00:13:09,680 --> 00:13:11,200
and i would actually take that one step

385
00:13:11,200 --> 00:13:13,120
forward forward in saying that i do

386
00:13:13,120 --> 00:13:14,079
think that the

387
00:13:14,079 --> 00:13:16,160
fundamental the basic concepts around

388
00:13:16,160 --> 00:13:18,720
machine learning artificial intelligence

389
00:13:18,720 --> 00:13:22,079
is better understood today and and

390
00:13:22,079 --> 00:13:24,240
some of it because of interest in in

391
00:13:24,240 --> 00:13:26,000
looking at the opportunities this might

392
00:13:26,000 --> 00:13:27,760
create for our societies for

393
00:13:27,760 --> 00:13:30,000
small and medium-sized enterprises but

394
00:13:30,000 --> 00:13:31,600
of course also because there is a

395
00:13:31,600 --> 00:13:33,600
i think a better understanding today

396
00:13:33,600 --> 00:13:34,959
that these technologies

397
00:13:34,959 --> 00:13:38,560
are potentially going to have a dramatic

398
00:13:38,560 --> 00:13:41,199
impact on our societies on our economy

399
00:13:41,199 --> 00:13:42,560
on the job creation

400
00:13:42,560 --> 00:13:44,639
but i would also say moving into a nato

401
00:13:44,639 --> 00:13:45,680
context

402
00:13:45,680 --> 00:13:47,360
in the way that we look at at the

403
00:13:47,360 --> 00:13:48,959
defense alliance and the way we look at

404
00:13:48,959 --> 00:13:50,480
how we defend

405
00:13:50,480 --> 00:13:53,519
our societies our democracies and so i

406
00:13:53,519 --> 00:13:54,399
do think there is

407
00:13:54,399 --> 00:13:55,920
a better understanding of those concepts

408
00:13:55,920 --> 00:13:58,160
today do i think where we are where we

409
00:13:58,160 --> 00:13:59,360
need to be

410
00:13:59,360 --> 00:14:00,959
no i don't and that is one of the

411
00:14:00,959 --> 00:14:03,519
reasons why i think what is particularly

412
00:14:03,519 --> 00:14:06,639
important in today's world and looking

413
00:14:06,639 --> 00:14:07,040
at

414
00:14:07,040 --> 00:14:09,920
where we are here in 2021 um you know

415
00:14:09,920 --> 00:14:11,920
governments cannot do it alone

416
00:14:11,920 --> 00:14:14,399
at the international the international

417
00:14:14,399 --> 00:14:16,320
industry cannot do it alone

418
00:14:16,320 --> 00:14:18,000
as you mentioned mentioned very kindly

419
00:14:18,000 --> 00:14:19,839
in your introductory remark i used to

420
00:14:19,839 --> 00:14:20,560
work

421
00:14:20,560 --> 00:14:22,880
on the government side in nato and in

422
00:14:22,880 --> 00:14:24,160
the european union

423
00:14:24,160 --> 00:14:25,839
i've moved to the other side of the

424
00:14:25,839 --> 00:14:27,760
table in one of the big technology

425
00:14:27,760 --> 00:14:28,560
companies

426
00:14:28,560 --> 00:14:30,959
but i remain still today convinced that

427
00:14:30,959 --> 00:14:32,480
we have to make sure that we have a much

428
00:14:32,480 --> 00:14:32,880
closer

429
00:14:32,880 --> 00:14:34,959
closer dialogue today that we better

430
00:14:34,959 --> 00:14:36,720
understand what is happening

431
00:14:36,720 --> 00:14:38,639
in the on the industry side we have to

432
00:14:38,639 --> 00:14:40,480
make sure that we provide

433
00:14:40,480 --> 00:14:42,639
our insights and our experts are able to

434
00:14:42,639 --> 00:14:44,480
share with governments and international

435
00:14:44,480 --> 00:14:47,680
organization organization what is coming

436
00:14:47,680 --> 00:14:49,360
in in their way and i think on the

437
00:14:49,360 --> 00:14:51,680
industry side we have to double down in

438
00:14:51,680 --> 00:14:52,959
better understanding

439
00:14:52,959 --> 00:14:55,120
both the concerns of governments the

440
00:14:55,120 --> 00:14:56,959
interests of international organization

441
00:14:56,959 --> 00:14:59,519
in using the new technology so

442
00:14:59,519 --> 00:15:02,480
still a little little a little bit to go

443
00:15:02,480 --> 00:15:03,360
but but from

444
00:15:03,360 --> 00:15:05,120
i think a slightly better starting point

445
00:15:05,120 --> 00:15:07,839
today than even just a few years ago

446
00:15:07,839 --> 00:15:09,600
well that's great to hear that the trend

447
00:15:09,600 --> 00:15:11,199
is positive because

448
00:15:11,199 --> 00:15:12,639
indeed as you have mentioned the

449
00:15:12,639 --> 00:15:14,639
upcoming nato summit aspires among

450
00:15:14,639 --> 00:15:15,040
others

451
00:15:15,040 --> 00:15:17,120
to discuss a new nato artificial

452
00:15:17,120 --> 00:15:18,560
intelligence strategy

453
00:15:18,560 --> 00:15:20,800
inscribing into a broader debate uh on

454
00:15:20,800 --> 00:15:21,600
emerging and

455
00:15:21,600 --> 00:15:24,399
disrupting disruptive technologies also

456
00:15:24,399 --> 00:15:26,639
within the nato 2030 initiative several

457
00:15:26,639 --> 00:15:28,560
proposals have been made with regard to

458
00:15:28,560 --> 00:15:30,000
artificial intelligence

459
00:15:30,000 --> 00:15:32,160
while we have yet to see what uh to what

460
00:15:32,160 --> 00:15:34,720
extent they will be taken on board

461
00:15:34,720 --> 00:15:38,000
uh we it would be interesting to

462
00:15:38,000 --> 00:15:41,279
to to hear your take uh on the direction

463
00:15:41,279 --> 00:15:42,639
nato should take in

464
00:15:42,639 --> 00:15:45,279
in respect of those proposals and do you

465
00:15:45,279 --> 00:15:45,920
feel that

466
00:15:45,920 --> 00:15:48,690
industries views have been um

467
00:15:48,690 --> 00:15:50,079
[Music]

468
00:15:50,079 --> 00:15:54,959
have been listened to during the process

469
00:15:54,959 --> 00:15:57,519
yeah let me say yes to the last bit of

470
00:15:57,519 --> 00:15:58,399
it um

471
00:15:58,399 --> 00:16:00,800
because i i do think there has been a

472
00:16:00,800 --> 00:16:02,720
lot of dialogue a lot of consultations

473
00:16:02,720 --> 00:16:03,759
going on

474
00:16:03,759 --> 00:16:06,399
um i've had the pleasure myself to to be

475
00:16:06,399 --> 00:16:08,000
involved in a couple of discussions also

476
00:16:08,000 --> 00:16:09,519
with the secretariat looking at

477
00:16:09,519 --> 00:16:10,880
developing the uh

478
00:16:10,880 --> 00:16:13,360
the new upcoming ai strategy and and i

479
00:16:13,360 --> 00:16:15,440
think that's exactly the way forward

480
00:16:15,440 --> 00:16:17,360
and and i i think that is the right way

481
00:16:17,360 --> 00:16:18,720
forward for a number of reasons

482
00:16:18,720 --> 00:16:20,079
first of all because it gives us the

483
00:16:20,079 --> 00:16:22,399
opportunity to share what we know

484
00:16:22,399 --> 00:16:24,959
uh on the new technologies but also on a

485
00:16:24,959 --> 00:16:26,959
topic like cyber security discussed

486
00:16:26,959 --> 00:16:27,920
previously

487
00:16:27,920 --> 00:16:30,160
um i think one of the big differences as

488
00:16:30,160 --> 00:16:31,519
i mentioned earlier on is

489
00:16:31,519 --> 00:16:33,519
that in today's world you know the

490
00:16:33,519 --> 00:16:34,800
private industry

491
00:16:34,800 --> 00:16:36,560
to some extent operate the digital

492
00:16:36,560 --> 00:16:38,560
infrastructure but we're also the first

493
00:16:38,560 --> 00:16:40,240
responders when we see

494
00:16:40,240 --> 00:16:42,240
for example attacks on on critical

495
00:16:42,240 --> 00:16:43,680
infrastructure in

496
00:16:43,680 --> 00:16:45,920
nato member states across europe so i

497
00:16:45,920 --> 00:16:47,440
think that dialogue is incredibly

498
00:16:47,440 --> 00:16:48,079
important

499
00:16:48,079 --> 00:16:49,519
but i think it is also important for us

500
00:16:49,519 --> 00:16:51,120
to listen very carefully

501
00:16:51,120 --> 00:16:53,199
to in this case nato or nato member

502
00:16:53,199 --> 00:16:54,240
states

503
00:16:54,240 --> 00:16:56,720
what are the concerns expressed by nato

504
00:16:56,720 --> 00:16:57,600
member states

505
00:16:57,600 --> 00:16:58,880
you know what are the opportunities that

506
00:16:58,880 --> 00:17:01,519
they see in using the new technologies

507
00:17:01,519 --> 00:17:03,120
what are the concerns about going to the

508
00:17:03,120 --> 00:17:04,799
cloud what can we do more

509
00:17:04,799 --> 00:17:06,720
to develop and deploy technology that

510
00:17:06,720 --> 00:17:09,599
has aligned with in this case what nato

511
00:17:09,599 --> 00:17:11,119
is is looking for

512
00:17:11,119 --> 00:17:14,240
and so my hope is of course that

513
00:17:14,240 --> 00:17:15,760
the heads of states and government will

514
00:17:15,760 --> 00:17:18,240
be looking at this in in a few weeks

515
00:17:18,240 --> 00:17:18,799
time

516
00:17:18,799 --> 00:17:20,959
and they will really try and and and

517
00:17:20,959 --> 00:17:22,959
develop and give a clear mandate also to

518
00:17:22,959 --> 00:17:23,760
nato

519
00:17:23,760 --> 00:17:27,119
to expand the activities focusing on

520
00:17:27,119 --> 00:17:29,360
emerging and disruptive technologies

521
00:17:29,360 --> 00:17:31,120
and if you want me to give a little bit

522
00:17:31,120 --> 00:17:32,960
of a wish in

523
00:17:32,960 --> 00:17:34,480
in nato's direction and i don't think

524
00:17:34,480 --> 00:17:36,160
anybody will listen very carefully to

525
00:17:36,160 --> 00:17:36,720
this

526
00:17:36,720 --> 00:17:39,200
but i think any wording that would

527
00:17:39,200 --> 00:17:40,240
indicate that

528
00:17:40,240 --> 00:17:41,919
nato is interested in in sort of

529
00:17:41,919 --> 00:17:43,440
formalizing a dialogue with the

530
00:17:43,440 --> 00:17:44,640
technology industry

531
00:17:44,640 --> 00:17:46,720
i think would be a very welcoming step

532
00:17:46,720 --> 00:17:48,640
forward and it would also put

533
00:17:48,640 --> 00:17:50,559
a bit of responsible burden on the

534
00:17:50,559 --> 00:17:51,840
shoulders of the industry

535
00:17:51,840 --> 00:17:54,000
to engage in a more formalized way with

536
00:17:54,000 --> 00:17:55,039
with nato so

537
00:17:55,039 --> 00:17:57,200
that's a little bit the wish list

538
00:17:57,200 --> 00:18:00,400
looking a few weeks ahead thank you very

539
00:18:00,400 --> 00:18:01,120
much you

540
00:18:01,120 --> 00:18:03,039
you provided a good opening to my

541
00:18:03,039 --> 00:18:04,240
following question

542
00:18:04,240 --> 00:18:07,840
uh apart from this wish for closer

543
00:18:07,840 --> 00:18:09,679
relationship between

544
00:18:09,679 --> 00:18:12,720
governments and nato and industry what

545
00:18:12,720 --> 00:18:15,120
would be or what maybe have been other

546
00:18:15,120 --> 00:18:17,360
recommendations of the industry for

547
00:18:17,360 --> 00:18:19,840
responsible ai strategy based on

548
00:18:19,840 --> 00:18:20,640
microsoft's

549
00:18:20,640 --> 00:18:23,919
clearly vast experience around ai

550
00:18:23,919 --> 00:18:25,440
where do you see the greatest risk and

551
00:18:25,440 --> 00:18:26,960
the greatest opportunities

552
00:18:26,960 --> 00:18:30,640
or potential for responsible use

553
00:18:31,039 --> 00:18:33,360
yeah i think i think as an industry and

554
00:18:33,360 --> 00:18:35,600
as one of the key technology providers

555
00:18:35,600 --> 00:18:38,799
we have to operate in in

556
00:18:38,799 --> 00:18:41,039
a complex situation right now we're

557
00:18:41,039 --> 00:18:42,000
beginning to look

558
00:18:42,000 --> 00:18:44,160
at regulations coming forward i think

559
00:18:44,160 --> 00:18:45,360
one of the previous

560
00:18:45,360 --> 00:18:48,559
speakers mentioned the uh the draft

561
00:18:48,559 --> 00:18:50,240
proposal of the european union on

562
00:18:50,240 --> 00:18:52,799
artificial intelligence i think that's

563
00:18:52,799 --> 00:18:56,080
a landmark a regulatory proposal that

564
00:18:56,080 --> 00:18:57,440
contains

565
00:18:57,440 --> 00:18:59,039
a lot of good elements including

566
00:18:59,039 --> 00:19:01,520
including focusing on high-risk areas as

567
00:19:01,520 --> 00:19:02,799
the area that really needs to be

568
00:19:02,799 --> 00:19:04,080
regulated

569
00:19:04,080 --> 00:19:06,720
a bit more i think also when you look at

570
00:19:06,720 --> 00:19:09,120
what we've done internally in microsoft

571
00:19:09,120 --> 00:19:11,039
and that is to make sure that we take

572
00:19:11,039 --> 00:19:13,440
into account from the very outset

573
00:19:13,440 --> 00:19:16,080
you know how we develop systems that are

574
00:19:16,080 --> 00:19:17,200
responsible

575
00:19:17,200 --> 00:19:20,320
we now have an office for responsible ai

576
00:19:20,320 --> 00:19:22,559
we make sure that when our engineers are

577
00:19:22,559 --> 00:19:24,720
developing the systems of tomorrow

578
00:19:24,720 --> 00:19:26,640
that you know ethical principles

579
00:19:26,640 --> 00:19:29,120
responsible principles for for ai

580
00:19:29,120 --> 00:19:31,120
that is taken into account from the very

581
00:19:31,120 --> 00:19:33,600
outset and i think that's a slightly

582
00:19:33,600 --> 00:19:34,400
different

583
00:19:34,400 --> 00:19:36,840
approach to developing these these new

584
00:19:36,840 --> 00:19:38,160
technologies

585
00:19:38,160 --> 00:19:39,919
but i would also say that i think that

586
00:19:39,919 --> 00:19:42,000
framework and perhaps even the framework

587
00:19:42,000 --> 00:19:43,360
of the european union

588
00:19:43,360 --> 00:19:46,080
are areas where nato perhaps could get a

589
00:19:46,080 --> 00:19:48,080
bit of inspiration but because it goes

590
00:19:48,080 --> 00:19:49,679
without saying that as we move into the

591
00:19:49,679 --> 00:19:50,799
defense domain

592
00:19:50,799 --> 00:19:52,160
those are areas that are currently of

593
00:19:52,160 --> 00:19:54,400
course not covered by the eu regulation

594
00:19:54,400 --> 00:19:56,400
and where i also think that in the

595
00:19:56,400 --> 00:19:57,919
industry we would welcome some

596
00:19:57,919 --> 00:19:59,840
principles some guidelines

597
00:19:59,840 --> 00:20:02,159
you know a clearly defined strategy on

598
00:20:02,159 --> 00:20:03,039
what we can do

599
00:20:03,039 --> 00:20:05,120
again to develop and deploy technologies

600
00:20:05,120 --> 00:20:06,240
that will cater

601
00:20:06,240 --> 00:20:08,720
for the specific requirements of nato

602
00:20:08,720 --> 00:20:10,080
and i think there are unlimited

603
00:20:10,080 --> 00:20:12,080
opportunities also for nato

604
00:20:12,080 --> 00:20:14,000
you know everything from building on

605
00:20:14,000 --> 00:20:16,400
better cyber security defense systems to

606
00:20:16,400 --> 00:20:17,840
logistics to

607
00:20:17,840 --> 00:20:19,760
you know battlefield management systems

608
00:20:19,760 --> 00:20:21,440
you know all of these areas

609
00:20:21,440 --> 00:20:23,679
uh would would definitely be areas where

610
00:20:23,679 --> 00:20:25,520
artificial intelligence can

611
00:20:25,520 --> 00:20:28,159
or are already playing a significant

612
00:20:28,159 --> 00:20:28,640
role

613
00:20:28,640 --> 00:20:31,679
but creating the framework uh on the

614
00:20:31,679 --> 00:20:33,919
responsible use of ai i think would set

615
00:20:33,919 --> 00:20:36,720
a very very strong

616
00:20:36,720 --> 00:20:39,120
signal or message and it would also i

617
00:20:39,120 --> 00:20:40,960
think mark the territory and where nato

618
00:20:40,960 --> 00:20:41,440
can

619
00:20:41,440 --> 00:20:43,919
come across as being the responsible

620
00:20:43,919 --> 00:20:45,039
defense alliance

621
00:20:45,039 --> 00:20:48,000
that we all have to align with thank you

622
00:20:48,000 --> 00:20:50,000
i'm glad that you mentioned

623
00:20:50,000 --> 00:20:53,120
the various use cases or possibilities

624
00:20:53,120 --> 00:20:55,360
of use for artificial intelligence so

625
00:20:55,360 --> 00:20:56,240
it's clear that

626
00:20:56,240 --> 00:20:58,799
iai is not only about killer robots but

627
00:20:58,799 --> 00:21:00,400
in fact it can be used

628
00:21:00,400 --> 00:21:03,120
in in many other many other contexts as

629
00:21:03,120 --> 00:21:03,840
well

630
00:21:03,840 --> 00:21:06,480
um however about regulation of ai it

631
00:21:06,480 --> 00:21:07,760
indeed has been the talk

632
00:21:07,760 --> 00:21:11,120
for some time and recently has

633
00:21:11,120 --> 00:21:14,559
gained on um on speed with the

634
00:21:14,559 --> 00:21:17,760
with the european commission proposing

635
00:21:17,760 --> 00:21:19,520
uh the draft regulation artificial

636
00:21:19,520 --> 00:21:21,919
intelligence uh while it explicitly

637
00:21:21,919 --> 00:21:24,480
excludes military use from its scope

638
00:21:24,480 --> 00:21:27,280
it's undoubtedly it will undoubtedly

639
00:21:27,280 --> 00:21:27,760
have an

640
00:21:27,760 --> 00:21:31,039
impact on technologies used in and by

641
00:21:31,039 --> 00:21:32,240
nato member states

642
00:21:32,240 --> 00:21:34,320
also for defense purposes because only

643
00:21:34,320 --> 00:21:35,760
about military purpose

644
00:21:35,760 --> 00:21:39,039
and i wonder maybe from industry's

645
00:21:39,039 --> 00:21:40,159
perspective

646
00:21:40,159 --> 00:21:42,000
and especially if you're keen on

647
00:21:42,000 --> 00:21:43,440
innovation if you're keen

648
00:21:43,440 --> 00:21:47,600
on on new ideas

649
00:21:47,600 --> 00:21:50,799
how and flexibility is legal regulation

650
00:21:50,799 --> 00:21:51,760
and binding

651
00:21:51,760 --> 00:21:54,400
binding rules really the way to go will

652
00:21:54,400 --> 00:21:55,679
eu

653
00:21:55,679 --> 00:21:58,480
not achieve quite the opposite and maybe

654
00:21:58,480 --> 00:22:00,159
if not hampered then at least

655
00:22:00,159 --> 00:22:02,960
slow down innovation perhaps for the

656
00:22:02,960 --> 00:22:03,840
benefit of

657
00:22:03,840 --> 00:22:05,919
other countries that do not push for for

658
00:22:05,919 --> 00:22:06,960
binding rules

659
00:22:06,960 --> 00:22:13,840
or even to the benefit of the adversary

660
00:22:14,480 --> 00:22:16,320
i think that's the the sort of million

661
00:22:16,320 --> 00:22:18,000
or perhaps billion dollar question that

662
00:22:18,000 --> 00:22:20,000
everybody is asking tatyana

663
00:22:20,000 --> 00:22:22,240
and um and i can give you sort of my

664
00:22:22,240 --> 00:22:24,080
perspective on it and the first thing i

665
00:22:24,080 --> 00:22:25,200
want to say is

666
00:22:25,200 --> 00:22:27,280
to correct one misunderstanding that i

667
00:22:27,280 --> 00:22:28,400
think quite often

668
00:22:28,400 --> 00:22:30,559
that i see quite often um sort of

669
00:22:30,559 --> 00:22:32,000
referred to and that is that

670
00:22:32,000 --> 00:22:34,240
in the industry we are against

671
00:22:34,240 --> 00:22:36,080
regulation per se

672
00:22:36,080 --> 00:22:38,400
and that is simply not the case and and

673
00:22:38,400 --> 00:22:39,600
you know in microsoft we've been

674
00:22:39,600 --> 00:22:40,320
advocating

675
00:22:40,320 --> 00:22:43,280
for stronger regulation around ai for

676
00:22:43,280 --> 00:22:45,200
for years we've been talking about

677
00:22:45,200 --> 00:22:47,039
the necessity for example on facial

678
00:22:47,039 --> 00:22:49,120
recognition systems to our strong

679
00:22:49,120 --> 00:22:51,760
regulations in place to avoid um issues

680
00:22:51,760 --> 00:22:52,960
of those technologies

681
00:22:52,960 --> 00:22:55,520
but i think also in terms of avoiding

682
00:22:55,520 --> 00:22:57,280
you know in the lighter scale of things

683
00:22:57,280 --> 00:23:00,240
biases in in in facial recognition

684
00:23:00,240 --> 00:23:01,679
systems which means that

685
00:23:01,679 --> 00:23:03,520
you know when you are a middle-aged

686
00:23:03,520 --> 00:23:05,360
white man like me you know those systems

687
00:23:05,360 --> 00:23:06,799
are working relatively well

688
00:23:06,799 --> 00:23:09,280
if you're a woman or a person of color

689
00:23:09,280 --> 00:23:11,760
then those systems are much less

690
00:23:11,760 --> 00:23:13,280
effective today we know that that's a

691
00:23:13,280 --> 00:23:15,120
matter of fact and actually making sure

692
00:23:15,120 --> 00:23:17,200
that we have regulation in place that

693
00:23:17,200 --> 00:23:19,600
that prevents systems from from being

694
00:23:19,600 --> 00:23:21,039
developed with those biases i think

695
00:23:21,039 --> 00:23:22,720
would be would be absolute absolutely

696
00:23:22,720 --> 00:23:23,840
necessary

697
00:23:23,840 --> 00:23:25,360
now looking at what is happening in the

698
00:23:25,360 --> 00:23:26,880
european union

699
00:23:26,880 --> 00:23:29,280
and as i said as i said before i

700
00:23:29,280 --> 00:23:31,120
actually think that the regulation

701
00:23:31,120 --> 00:23:33,360
is a very balanced way forward that

702
00:23:33,360 --> 00:23:35,440
identifying high-risk areas you know

703
00:23:35,440 --> 00:23:37,840
areas where it's about your fundamental

704
00:23:37,840 --> 00:23:38,960
rights

705
00:23:38,960 --> 00:23:41,120
it's about making sure that you know if

706
00:23:41,120 --> 00:23:42,080
you go to

707
00:23:42,080 --> 00:23:44,320
a job interview that you're not discreet

708
00:23:44,320 --> 00:23:45,520
and then screened in an

709
00:23:45,520 --> 00:23:47,360
appropriate way and thereby disregarded

710
00:23:47,360 --> 00:23:49,360
in the beginning it's about making sure

711
00:23:49,360 --> 00:23:51,120
the facial recognition systems

712
00:23:51,120 --> 00:23:52,880
are on those misuse so it's about

713
00:23:52,880 --> 00:23:54,960
protecting you know fundamental

714
00:23:54,960 --> 00:23:58,159
serious high-risk rights uh for for

715
00:23:58,159 --> 00:24:00,080
for citizens that would be absolutely

716
00:24:00,080 --> 00:24:01,919
necessary i think where

717
00:24:01,919 --> 00:24:04,080
europe and the european union as well as

718
00:24:04,080 --> 00:24:06,000
any other country around the world

719
00:24:06,000 --> 00:24:07,600
will have to sort of make sure you find

720
00:24:07,600 --> 00:24:09,200
the right balance this is exactly on

721
00:24:09,200 --> 00:24:10,799
what you were saying tatyana

722
00:24:10,799 --> 00:24:13,039
you know avoiding this becoming sort of

723
00:24:13,039 --> 00:24:14,559
a straight jacket a

724
00:24:14,559 --> 00:24:16,240
regulatory straightjacket that will

725
00:24:16,240 --> 00:24:18,080
prevent innovation

726
00:24:18,080 --> 00:24:20,159
and you know i'm a european as you can

727
00:24:20,159 --> 00:24:22,400
hear from my accent

728
00:24:22,400 --> 00:24:25,600
apologies for that and i do think that

729
00:24:25,600 --> 00:24:26,720
of course in europe

730
00:24:26,720 --> 00:24:29,600
we are increasingly concerned about

731
00:24:29,600 --> 00:24:31,279
whether europe will remain

732
00:24:31,279 --> 00:24:34,240
competitive on a global stage where the

733
00:24:34,240 --> 00:24:36,080
technology development is moving very

734
00:24:36,080 --> 00:24:36,640
quickly

735
00:24:36,640 --> 00:24:39,360
not least in the united states and in

736
00:24:39,360 --> 00:24:40,080
asia and

737
00:24:40,080 --> 00:24:42,720
particularly in china so for whatever

738
00:24:42,720 --> 00:24:44,240
it's worth when i speak to european

739
00:24:44,240 --> 00:24:46,000
decision makers i think those are one of

740
00:24:46,000 --> 00:24:46,960
the main concerns

741
00:24:46,960 --> 00:24:48,880
how do we make sure that europe will be

742
00:24:48,880 --> 00:24:51,200
relevant in the next decade as well how

743
00:24:51,200 --> 00:24:53,039
will we make sure that europe will

744
00:24:53,039 --> 00:24:55,200
will create an ecosystem of innovation

745
00:24:55,200 --> 00:24:56,080
that will be

746
00:24:56,080 --> 00:24:59,200
competitive on the global stage and and

747
00:24:59,200 --> 00:25:00,159
i have noticed

748
00:25:00,159 --> 00:25:02,320
uh after the uh the draft proposal

749
00:25:02,320 --> 00:25:03,440
coming forward from the european

750
00:25:03,440 --> 00:25:05,360
commission that there has been voices

751
00:25:05,360 --> 00:25:07,360
not least among the startup environment

752
00:25:07,360 --> 00:25:09,120
among entrepreneurs among small and

753
00:25:09,120 --> 00:25:11,039
medium-sized enterprises saying

754
00:25:11,039 --> 00:25:12,559
you know there are some concerns of

755
00:25:12,559 --> 00:25:15,039
whether you know new regulation would

756
00:25:15,039 --> 00:25:16,799
would make it more difficult for them to

757
00:25:16,799 --> 00:25:17,600
innovate

758
00:25:17,600 --> 00:25:18,960
for example in the area of machine

759
00:25:18,960 --> 00:25:21,200
learning and artificial intelligence

760
00:25:21,200 --> 00:25:22,960
and i think we are in the middle of a

761
00:25:22,960 --> 00:25:24,640
consultation process

762
00:25:24,640 --> 00:25:25,919
where i'm absolutely sure that the

763
00:25:25,919 --> 00:25:27,360
european commission is going to pay a

764
00:25:27,360 --> 00:25:28,880
lot of attention to that because we

765
00:25:28,880 --> 00:25:31,279
don't have any interest in making sure

766
00:25:31,279 --> 00:25:34,159
that you know the regulations coming out

767
00:25:34,159 --> 00:25:35,679
will primarily

768
00:25:35,679 --> 00:25:38,000
it will primarily be it will be easier

769
00:25:38,000 --> 00:25:40,080
for for larger companies to adhere to

770
00:25:40,080 --> 00:25:40,720
that

771
00:25:40,720 --> 00:25:42,159
i think we want to make sure that the

772
00:25:42,159 --> 00:25:45,039
new regulations will also help spark

773
00:25:45,039 --> 00:25:46,559
you know a lot of innovation in europe

774
00:25:46,559 --> 00:25:48,240
not least in the area of ai

775
00:25:48,240 --> 00:25:50,559
and why do we want that well you know we

776
00:25:50,559 --> 00:25:52,880
see ourselves of being a provider of

777
00:25:52,880 --> 00:25:55,120
i would say the foundation productivity

778
00:25:55,120 --> 00:25:56,960
tools critical infrastructure

779
00:25:56,960 --> 00:25:59,679
that enable european companies to to

780
00:25:59,679 --> 00:26:00,640
benefit

781
00:26:00,640 --> 00:26:04,320
to innovate to create uh you know

782
00:26:04,320 --> 00:26:06,720
the framework that will enable them to

783
00:26:06,720 --> 00:26:08,720
to reap the full benefits of the digital

784
00:26:08,720 --> 00:26:09,200
age

785
00:26:09,200 --> 00:26:10,400
and i think we want to make sure that

786
00:26:10,400 --> 00:26:12,000
the new regulations will go in that

787
00:26:12,000 --> 00:26:12,880
direction

788
00:26:12,880 --> 00:26:14,400
and i'm pretty sure that everybody

789
00:26:14,400 --> 00:26:16,720
inside the european commission are

790
00:26:16,720 --> 00:26:18,720
completing agreement with these with

791
00:26:18,720 --> 00:26:20,080
these points and we'll be looking at

792
00:26:20,080 --> 00:26:20,960
that during the

793
00:26:20,960 --> 00:26:24,080
consultation process

794
00:26:24,080 --> 00:26:26,400
me as a lawyer i'm very glad to to hear

795
00:26:26,400 --> 00:26:27,360
this perspective

796
00:26:27,360 --> 00:26:29,919
i must admit and indeed we have seen uh

797
00:26:29,919 --> 00:26:31,520
we've seen it in the cyberspace norm's

798
00:26:31,520 --> 00:26:33,440
discussion that actually industry

799
00:26:33,440 --> 00:26:35,919
with microsoft at a prominent place has

800
00:26:35,919 --> 00:26:37,919
been the norms entrepreneur uh

801
00:26:37,919 --> 00:26:41,520
in in some cases so this might be

802
00:26:41,520 --> 00:26:42,799
something

803
00:26:42,799 --> 00:26:46,640
to to be expected in ai ai domain as

804
00:26:46,640 --> 00:26:47,600
well we'll see

805
00:26:47,600 --> 00:26:49,440
i hear from from my colleagues that

806
00:26:49,440 --> 00:26:50,640
we're having a lot of

807
00:26:50,640 --> 00:26:53,840
questions from the audience so if i

808
00:26:53,840 --> 00:26:55,039
managed to read them

809
00:26:55,039 --> 00:26:58,080
then i would like

810
00:26:58,080 --> 00:27:00,080
our audience would like to ask mr

811
00:27:00,080 --> 00:27:01,840
kelling how can microsoft

812
00:27:01,840 --> 00:27:03,600
and other big tech companies better

813
00:27:03,600 --> 00:27:06,080
cooperate and support nato and allies

814
00:27:06,080 --> 00:27:06,799
efforts

815
00:27:06,799 --> 00:27:09,679
in operation operationalizing ai

816
00:27:09,679 --> 00:27:11,200
applications for opportunities in

817
00:27:11,200 --> 00:27:12,400
military defense and

818
00:27:12,400 --> 00:27:15,679
cyber security yeah

819
00:27:15,679 --> 00:27:17,840
it's not a good a good question and

820
00:27:17,840 --> 00:27:19,200
definitely a question that we've been

821
00:27:19,200 --> 00:27:20,559
trying to

822
00:27:20,559 --> 00:27:23,120
to address already i think one of the

823
00:27:23,120 --> 00:27:25,039
basic starting points is

824
00:27:25,039 --> 00:27:27,840
this closer dialogue between nato and

825
00:27:27,840 --> 00:27:28,960
the industry

826
00:27:28,960 --> 00:27:30,880
and and as i said earlier on i think

827
00:27:30,880 --> 00:27:32,559
we've taken some pretty important steps

828
00:27:32,559 --> 00:27:33,440
forward

829
00:27:33,440 --> 00:27:36,720
in in creating a closer interface

830
00:27:36,720 --> 00:27:38,320
i think the question is whether we take

831
00:27:38,320 --> 00:27:40,080
that to the next level and create sort

832
00:27:40,080 --> 00:27:42,080
of a more formalized structure

833
00:27:42,080 --> 00:27:43,600
as we've seen again you know in the

834
00:27:43,600 --> 00:27:45,200
european union we

835
00:27:45,200 --> 00:27:47,200
we we've seen under the high

836
00:27:47,200 --> 00:27:48,240
representative

837
00:27:48,240 --> 00:27:51,440
a tick panel being set up that sort of

838
00:27:51,440 --> 00:27:51,760
is

839
00:27:51,760 --> 00:27:52,960
set up to make sure that there is a

840
00:27:52,960 --> 00:27:54,720
dialogue between decision makers and the

841
00:27:54,720 --> 00:27:56,320
external action service

842
00:27:56,320 --> 00:27:57,679
so the foreign policy anchor of the

843
00:27:57,679 --> 00:27:59,919
european union and the industry

844
00:27:59,919 --> 00:28:02,320
and if we go back a few years we saw the

845
00:28:02,320 --> 00:28:04,240
united nations and the secretary general

846
00:28:04,240 --> 00:28:05,279
set down

847
00:28:05,279 --> 00:28:08,240
you know a panel on digital corporation

848
00:28:08,240 --> 00:28:09,679
that again we're trying to look

849
00:28:09,679 --> 00:28:11,520
at where the world is heading and how

850
00:28:11,520 --> 00:28:13,520
the united nations can can align with

851
00:28:13,520 --> 00:28:14,720
that future

852
00:28:14,720 --> 00:28:16,720
and and i think again i'm not objective

853
00:28:16,720 --> 00:28:18,559
and i realized that this will be

854
00:28:18,559 --> 00:28:20,720
sort of my personal view on this but but

855
00:28:20,720 --> 00:28:22,480
i think honestly time is right

856
00:28:22,480 --> 00:28:24,080
for us to do something similar with nate

857
00:28:24,080 --> 00:28:26,080
so i think the benefit of that would be

858
00:28:26,080 --> 00:28:26,399
that

859
00:28:26,399 --> 00:28:28,080
we would enable it would enable us to

860
00:28:28,080 --> 00:28:30,080
share our experiences our insights

861
00:28:30,080 --> 00:28:32,399
including on how you develop artificial

862
00:28:32,399 --> 00:28:33,600
intelligence systems that are

863
00:28:33,600 --> 00:28:34,720
responsible

864
00:28:34,720 --> 00:28:36,880
and it would also enable us to better

865
00:28:36,880 --> 00:28:38,480
understand and hear

866
00:28:38,480 --> 00:28:40,399
you know the concerns of nature or the

867
00:28:40,399 --> 00:28:41,679
areas where they think the industry

868
00:28:41,679 --> 00:28:42,559
needs to

869
00:28:42,559 --> 00:28:46,080
to to come together as as uh as one

870
00:28:46,080 --> 00:28:47,760
but fundamentally i think where nato can

871
00:28:47,760 --> 00:28:49,200
make a real difference is

872
00:28:49,200 --> 00:28:51,200
when you look at the military domain or

873
00:28:51,200 --> 00:28:52,480
the defense domain

874
00:28:52,480 --> 00:28:53,919
you know having an organization like

875
00:28:53,919 --> 00:28:56,840
nato you know setting a very clear

876
00:28:56,840 --> 00:28:59,679
um signal in

877
00:28:59,679 --> 00:29:01,760
in wanting to move ahead in a way where

878
00:29:01,760 --> 00:29:03,840
you you take full advantage

879
00:29:03,840 --> 00:29:06,080
also for the superiority of the alliance

880
00:29:06,080 --> 00:29:07,919
in the new technologies coming forward

881
00:29:07,919 --> 00:29:10,159
but doing that in a responsible way i

882
00:29:10,159 --> 00:29:12,240
think it would not only benefit

883
00:29:12,240 --> 00:29:14,640
nato member states it would also set a

884
00:29:14,640 --> 00:29:16,320
precedence or create the norms that you

885
00:29:16,320 --> 00:29:17,679
spoke about before

886
00:29:17,679 --> 00:29:19,840
that others will will adhere to in other

887
00:29:19,840 --> 00:29:21,360
words i think there will be a rip

888
00:29:21,360 --> 00:29:23,840
ripple of effects for for the rest of

889
00:29:23,840 --> 00:29:25,360
the world which i think is incredibly

890
00:29:25,360 --> 00:29:26,480
important when you look at where the

891
00:29:26,480 --> 00:29:27,360
world today

892
00:29:27,360 --> 00:29:29,039
where the world is today and when you

893
00:29:29,039 --> 00:29:30,799
look at the threat uh threats coming

894
00:29:30,799 --> 00:29:32,080
forward not at least from a cyber

895
00:29:32,080 --> 00:29:34,000
security point of view

896
00:29:34,000 --> 00:29:36,080
thank you very much then we have a more

897
00:29:36,080 --> 00:29:37,919
of a photograph like a question and i

898
00:29:37,919 --> 00:29:38,799
don't actually know whether you're

899
00:29:38,799 --> 00:29:40,880
allowed to answer that but let's see

900
00:29:40,880 --> 00:29:44,159
how was ai used in in the solar winds

901
00:29:44,159 --> 00:29:47,200
and hoffner attacks

902
00:29:47,679 --> 00:29:49,440
i i think i can give you sort of a

903
00:29:49,440 --> 00:29:51,120
general uh response to that

904
00:29:51,120 --> 00:29:52,960
and and i've already alluded to the fact

905
00:29:52,960 --> 00:29:54,720
that i think in microsoft

906
00:29:54,720 --> 00:29:56,880
you know we have more than 3 000 people

907
00:29:56,880 --> 00:29:58,000
working 24

908
00:29:58,000 --> 00:30:01,039
7 in in creating the best possible

909
00:30:01,039 --> 00:30:02,240
defense against

910
00:30:02,240 --> 00:30:04,799
the what i would call very unethical

911
00:30:04,799 --> 00:30:06,399
very irresponsible

912
00:30:06,399 --> 00:30:08,799
cyber that that we are seeing uh you

913
00:30:08,799 --> 00:30:10,559
know unfortunate around the clock

914
00:30:10,559 --> 00:30:12,399
and i just want to add even when we look

915
00:30:12,399 --> 00:30:14,720
back at the global pandemic

916
00:30:14,720 --> 00:30:17,200
a very difficult situation for i think

917
00:30:17,200 --> 00:30:19,279
all societies around the world

918
00:30:19,279 --> 00:30:21,520
we did not see a moratorium come forward

919
00:30:21,520 --> 00:30:23,200
on cyber attacks in fact we

920
00:30:23,200 --> 00:30:25,600
saw some of the perpetrators attack you

921
00:30:25,600 --> 00:30:27,440
know healthcare organization

922
00:30:27,440 --> 00:30:29,200
you know frontline workers in in our

923
00:30:29,200 --> 00:30:30,559
healthcare system so

924
00:30:30,559 --> 00:30:32,000
this is definitely an area that will

925
00:30:32,000 --> 00:30:33,679
will unfortunately disappear

926
00:30:33,679 --> 00:30:36,559
and we are using ai systems every single

927
00:30:36,559 --> 00:30:37,200
day

928
00:30:37,200 --> 00:30:38,880
to try and make sure that our customers

929
00:30:38,880 --> 00:30:40,240
whether in the private sector in the

930
00:30:40,240 --> 00:30:41,520
public sector

931
00:30:41,520 --> 00:30:43,760
have uh you know access to to

932
00:30:43,760 --> 00:30:45,200
state-of-the-art technology that will

933
00:30:45,200 --> 00:30:45,919
hopefully

934
00:30:45,919 --> 00:30:48,080
create the best possible defense against

935
00:30:48,080 --> 00:30:49,760
these attacks but i also want to be

936
00:30:49,760 --> 00:30:51,440
honest in saying that this is not

937
00:30:51,440 --> 00:30:53,520
something that ends tomorrow the day

938
00:30:53,520 --> 00:30:55,200
after you know this is

939
00:30:55,200 --> 00:30:57,279
an arms race where the sophistication

940
00:30:57,279 --> 00:30:58,799
and the complexity of the attacks

941
00:30:58,799 --> 00:31:00,960
unfortunately are developing as well so

942
00:31:00,960 --> 00:31:02,480
we need to constantly innovate

943
00:31:02,480 --> 00:31:04,720
constantly use new technology

944
00:31:04,720 --> 00:31:07,440
to do our utmost to defense to defend

945
00:31:07,440 --> 00:31:08,880
our societies

946
00:31:08,880 --> 00:31:10,399
and this is of course one of the areas

947
00:31:10,399 --> 00:31:11,600
again going back to the normal

948
00:31:11,600 --> 00:31:12,720
discussion where

949
00:31:12,720 --> 00:31:15,039
creating sort of a shared sense of the

950
00:31:15,039 --> 00:31:17,440
traffic rules in cyberspace

951
00:31:17,440 --> 00:31:20,320
pointing out what is irresponsible your

952
00:31:20,320 --> 00:31:22,000
behavior in cyberspace

953
00:31:22,000 --> 00:31:25,039
is where that discussion ties very

954
00:31:25,039 --> 00:31:27,279
neatly together with what we do as an

955
00:31:27,279 --> 00:31:27,919
industry

956
00:31:27,919 --> 00:31:29,919
but also what i think we need to expect

957
00:31:29,919 --> 00:31:31,919
from some countries and actors around

958
00:31:31,919 --> 00:31:33,039
the world

959
00:31:33,039 --> 00:31:36,000
thank you very much the next question

960
00:31:36,000 --> 00:31:38,000
what is microsoft's commitment

961
00:31:38,000 --> 00:31:40,640
for to giving the cloud infrastructure

962
00:31:40,640 --> 00:31:42,559
into the hands of independent european

963
00:31:42,559 --> 00:31:43,519
operators

964
00:31:43,519 --> 00:31:48,559
relinquishing access to metadata

965
00:31:49,120 --> 00:31:51,039
well you know if we we're sitting in

966
00:31:51,039 --> 00:31:52,640
europe and um

967
00:31:52,640 --> 00:31:54,559
and i think if we if we look at the

968
00:31:54,559 --> 00:31:56,399
discussion that is happening here you're

969
00:31:56,399 --> 00:31:58,320
right now around strategic autonomy and

970
00:31:58,320 --> 00:32:00,240
digital sovereignty

971
00:32:00,240 --> 00:32:02,080
and you know that is a discussion that

972
00:32:02,080 --> 00:32:03,360
certainly has an impact on the

973
00:32:03,360 --> 00:32:04,960
technology industry

974
00:32:04,960 --> 00:32:06,880
and it has raised a lot of concerns

975
00:32:06,880 --> 00:32:08,799
about whether europe is turning inward

976
00:32:08,799 --> 00:32:11,120
looking whether this is sort of a new

977
00:32:11,120 --> 00:32:12,880
sign of protectionism coming forward in

978
00:32:12,880 --> 00:32:14,080
europe

979
00:32:14,080 --> 00:32:16,080
that's not the way that that we look at

980
00:32:16,080 --> 00:32:17,360
it in microsoft

981
00:32:17,360 --> 00:32:20,080
in fact we look at it as some very valid

982
00:32:20,080 --> 00:32:22,080
and legitimate discussions around

983
00:32:22,080 --> 00:32:24,960
making sure that europe will remain you

984
00:32:24,960 --> 00:32:26,480
know in charge will remain

985
00:32:26,480 --> 00:32:28,720
uh you know in a position to take

986
00:32:28,720 --> 00:32:30,559
decisions independently

987
00:32:30,559 --> 00:32:32,399
and i think commissioner vesta of the

988
00:32:32,399 --> 00:32:34,399
european union has defined it as sort of

989
00:32:34,399 --> 00:32:36,480
regular sort of regulatory sovereignty

990
00:32:36,480 --> 00:32:38,080
in other words the european union

991
00:32:38,080 --> 00:32:39,840
will continue to be able to define the

992
00:32:39,840 --> 00:32:42,240
rules that applies in

993
00:32:42,240 --> 00:32:44,320
in europe and and when you look at the

994
00:32:44,320 --> 00:32:45,760
cloud market you have

995
00:32:45,760 --> 00:32:47,679
various initiatives coming forward new

996
00:32:47,679 --> 00:32:49,519
regulation inside the european union you

997
00:32:49,519 --> 00:32:51,840
also have an initiative like ix

998
00:32:51,840 --> 00:32:53,919
uh creating a sort of a federated cloud

999
00:32:53,919 --> 00:32:55,440
structure in in europe

1000
00:32:55,440 --> 00:32:57,360
and i think all of that is really aimed

1001
00:32:57,360 --> 00:33:00,000
at making sure that europe will benefit

1002
00:33:00,000 --> 00:33:03,200
um to the fullest fullest extent extent

1003
00:33:03,200 --> 00:33:05,760
of cloud opportunities and as i said

1004
00:33:05,760 --> 00:33:07,039
before

1005
00:33:07,039 --> 00:33:08,799
in my view which is certainly not

1006
00:33:08,799 --> 00:33:10,720
objective but but i do want to make the

1007
00:33:10,720 --> 00:33:11,840
point nonetheless

1008
00:33:11,840 --> 00:33:13,919
i think cloud computing is not something

1009
00:33:13,919 --> 00:33:16,240
that is nice to have i think it is

1010
00:33:16,240 --> 00:33:18,080
a need to have today it's a fundamental

1011
00:33:18,080 --> 00:33:19,519
aspect if you want to make it in a

1012
00:33:19,519 --> 00:33:21,039
digitalized world

1013
00:33:21,039 --> 00:33:22,880
and it actually creates benefits i i

1014
00:33:22,880 --> 00:33:24,320
mentioned before you know

1015
00:33:24,320 --> 00:33:27,279
increasing uh cyber security i want to

1016
00:33:27,279 --> 00:33:27,840
add

1017
00:33:27,840 --> 00:33:29,679
you know sustainability as another area

1018
00:33:29,679 --> 00:33:30,880
where we know there are huge

1019
00:33:30,880 --> 00:33:33,039
efficiencies by going to the cloud for

1020
00:33:33,039 --> 00:33:34,320
for companies as well as

1021
00:33:34,320 --> 00:33:36,320
the private sector i think for us in

1022
00:33:36,320 --> 00:33:38,080
microsoft listening to the debate in

1023
00:33:38,080 --> 00:33:39,039
europe

1024
00:33:39,039 --> 00:33:41,200
also around sovereignty one of the clear

1025
00:33:41,200 --> 00:33:42,960
lessons is we have to make sure that we

1026
00:33:42,960 --> 00:33:44,720
align our technologies with

1027
00:33:44,720 --> 00:33:46,320
what europe wants and the european

1028
00:33:46,320 --> 00:33:48,399
aspirations so one of the things we've

1029
00:33:48,399 --> 00:33:50,480
done in microsoft is to come up with a

1030
00:33:50,480 --> 00:33:52,480
concept we call techfit for europe

1031
00:33:52,480 --> 00:33:54,640
and it's basic recognition that whether

1032
00:33:54,640 --> 00:33:56,320
you look at data residency whether you

1033
00:33:56,320 --> 00:33:58,720
look at concerns about access to to data

1034
00:33:58,720 --> 00:33:59,440
sets

1035
00:33:59,440 --> 00:34:01,440
we have to do everything we can to make

1036
00:34:01,440 --> 00:34:03,120
sure that we develop technologies that

1037
00:34:03,120 --> 00:34:05,039
are fully aligned with what europe wants

1038
00:34:05,039 --> 00:34:07,519
so europe fit for the digital age and i

1039
00:34:07,519 --> 00:34:08,960
do think that looking back

1040
00:34:08,960 --> 00:34:11,440
at at a very very challenging year or 15

1041
00:34:11,440 --> 00:34:12,639
months

1042
00:34:12,639 --> 00:34:14,000
you know the dependencies on

1043
00:34:14,000 --> 00:34:16,159
technologies that has made sure that we

1044
00:34:16,159 --> 00:34:16,639
have

1045
00:34:16,639 --> 00:34:19,760
hopefully come through the crisis in in

1046
00:34:19,760 --> 00:34:20,719
a better way than

1047
00:34:20,719 --> 00:34:23,119
without access to those technologies

1048
00:34:23,119 --> 00:34:24,079
that has also

1049
00:34:24,079 --> 00:34:25,599
revealed the dependency of those

1050
00:34:25,599 --> 00:34:27,280
technologies which in

1051
00:34:27,280 --> 00:34:29,280
in my view makes it even more necessary

1052
00:34:29,280 --> 00:34:31,599
for us to to really align

1053
00:34:31,599 --> 00:34:33,679
with the european agenda and i think you

1054
00:34:33,679 --> 00:34:36,159
can you can basically use the same

1055
00:34:36,159 --> 00:34:39,119
uh mindset when looking at at nato and

1056
00:34:39,119 --> 00:34:40,719
again i just want to make

1057
00:34:40,719 --> 00:34:42,079
make the point once again that i think

1058
00:34:42,079 --> 00:34:44,719
it is reassuring but it is also

1059
00:34:44,719 --> 00:34:47,040
really welcoming that nate's was now so

1060
00:34:47,040 --> 00:34:48,960
deeply focusing on on emerging and

1061
00:34:48,960 --> 00:34:50,960
disruptive technologies as well as ai

1062
00:34:50,960 --> 00:34:51,760
systems

1063
00:34:51,760 --> 00:34:54,560
and artificial intelligence systems and

1064
00:34:54,560 --> 00:34:56,000
we want to be a part of that we want to

1065
00:34:56,000 --> 00:34:57,599
listen to nato we want to make sure that

1066
00:34:57,599 --> 00:34:58,640
we align with

1067
00:34:58,640 --> 00:35:00,320
with where nato is going and where nato

1068
00:35:00,320 --> 00:35:02,000
wants to go

1069
00:35:02,000 --> 00:35:04,400
thank you very much you mentioned you've

1070
00:35:04,400 --> 00:35:06,240
gone back to nato

1071
00:35:06,240 --> 00:35:07,520
traditionally one last question

1072
00:35:07,520 --> 00:35:09,920
traditionally interoperability has been

1073
00:35:09,920 --> 00:35:11,839
one of the biggest challenges

1074
00:35:11,839 --> 00:35:15,040
for for nato member states how do you

1075
00:35:15,040 --> 00:35:16,000
see challenges

1076
00:35:16,000 --> 00:35:20,480
uh in ai in respect of ai applications

1077
00:35:20,480 --> 00:35:21,920
in terms of uh in terms of

1078
00:35:21,920 --> 00:35:24,800
interoperability

1079
00:35:24,800 --> 00:35:26,720
but but i think those are some of the

1080
00:35:26,720 --> 00:35:28,960
criterias that nato needs to put down in

1081
00:35:28,960 --> 00:35:30,240
other words if you want to provide

1082
00:35:30,240 --> 00:35:32,400
technology to nato interoperability is

1083
00:35:32,400 --> 00:35:34,320
going to be one of the key parameters

1084
00:35:34,320 --> 00:35:35,760
i don't think that's different in the

1085
00:35:35,760 --> 00:35:38,720
hardware world of nato and and and

1086
00:35:38,720 --> 00:35:40,240
i don't think that will be the case in

1087
00:35:40,240 --> 00:35:42,160
the software part either but i think

1088
00:35:42,160 --> 00:35:42,880
it's one of those

1089
00:35:42,880 --> 00:35:45,200
areas again where you know we will have

1090
00:35:45,200 --> 00:35:46,960
to listen very carefully we want to have

1091
00:35:46,960 --> 00:35:48,560
a dialogue with with nato we want to

1092
00:35:48,560 --> 00:35:50,160
better understand where nato wants to go

1093
00:35:50,160 --> 00:35:51,599
and then we will have to

1094
00:35:51,599 --> 00:35:54,240
to align our technologies with with with

1095
00:35:54,240 --> 00:35:54,720
that

1096
00:35:54,720 --> 00:35:56,560
situation and we are completely prepared

1097
00:35:56,560 --> 00:35:59,119
to do that that's great well tomorrow we

1098
00:35:59,119 --> 00:36:00,880
will hear from native undersecretary for

1099
00:36:00,880 --> 00:36:02,640
emerging security challenges

1100
00:36:02,640 --> 00:36:04,160
so maybe we can start having the

1101
00:36:04,160 --> 00:36:05,920
conversation already

1102
00:36:05,920 --> 00:36:07,760
and maybe get some answers of tomorrow

1103
00:36:07,760 --> 00:36:09,440
to the point we've raised today

1104
00:36:09,440 --> 00:36:11,680
i thank you very much mr klinger for

1105
00:36:11,680 --> 00:36:12,960
being with us today

1106
00:36:12,960 --> 00:36:15,760
you've provided a very interesting

1107
00:36:15,760 --> 00:36:16,640
perspective

1108
00:36:16,640 --> 00:36:18,800
on the issues on the matter of

1109
00:36:18,800 --> 00:36:20,800
artificial intelligence and its use

1110
00:36:20,800 --> 00:36:24,000
in and by nato

1111
00:36:24,000 --> 00:36:26,320
i thank you again for being with us

1112
00:36:26,320 --> 00:36:27,440
today i hope to

1113
00:36:27,440 --> 00:36:30,079
see you again in the future in person in

1114
00:36:30,079 --> 00:36:31,760
tallinn

1115
00:36:31,760 --> 00:36:33,839
and with this i'm giving flow back to

1116
00:36:33,839 --> 00:36:39,900
our lovely hosts thank you very much

1117
00:36:39,900 --> 00:36:47,260
[Music]

1118
00:36:49,040 --> 00:36:51,040
so thank you casper and tanya for

1119
00:36:51,040 --> 00:36:52,960
providing us with yet another

1120
00:36:52,960 --> 00:36:55,119
insightful and stimulating discussion

1121
00:36:55,119 --> 00:36:56,480
which certainly gave us some

1122
00:36:56,480 --> 00:36:59,680
food for thought that brings us to the

1123
00:36:59,680 --> 00:37:00,480
conclusion

1124
00:37:00,480 --> 00:37:03,680
of day one all that remains for us is to

1125
00:37:03,680 --> 00:37:04,960
thank you all

1126
00:37:04,960 --> 00:37:07,680
for your active participation and we

1127
00:37:07,680 --> 00:37:08,000
look

1128
00:37:08,000 --> 00:37:10,400
forward to seeing you again tomorrow

1129
00:37:10,400 --> 00:37:12,000
starting at the same time

1130
00:37:12,000 --> 00:37:22,260
as today

1131
00:37:22,260 --> 00:37:31,960
[Music]

1132
00:37:32,480 --> 00:37:34,560
you

