1
00:00:04,790 --> 00:00:14,629
[Music]

2
00:00:20,720 --> 00:00:21,840
ladies and gentlemen

3
00:00:21,840 --> 00:00:23,600
dear friends in the cyber community

4
00:00:23,600 --> 00:00:25,199
welcome to the workshop day

5
00:00:25,199 --> 00:00:27,359
of the 13th international conference on

6
00:00:27,359 --> 00:00:28,480
cyber conflict

7
00:00:28,480 --> 00:00:31,199
with a theme going viral my name is

8
00:00:31,199 --> 00:00:32,479
henrik beckwat

9
00:00:32,479 --> 00:00:35,360
and my name is lina lumista this is the

10
00:00:35,360 --> 00:00:36,160
first time

11
00:00:36,160 --> 00:00:38,160
that we are conducting cycan as an

12
00:00:38,160 --> 00:00:39,360
online event

13
00:00:39,360 --> 00:00:41,440
and even though virtually we have been

14
00:00:41,440 --> 00:00:42,800
looking forward to the stay

15
00:00:42,800 --> 00:00:46,079
for a long time the programme for today

16
00:00:46,079 --> 00:00:48,719
consists of a virtual book launch of the

17
00:00:48,719 --> 00:00:51,120
book autonomous cyber capabilities under

18
00:00:51,120 --> 00:00:52,399
international law

19
00:00:52,399 --> 00:00:56,000
on stage one and workshops with fortinet

20
00:00:56,000 --> 00:00:59,280
and leonardo on stage two

21
00:00:59,280 --> 00:01:01,199
for joining the two workshops simply

22
00:01:01,199 --> 00:01:02,960
click on your preferred option

23
00:01:02,960 --> 00:01:05,119
stage one or two on the right of your

24
00:01:05,119 --> 00:01:06,240
screen

25
00:01:06,240 --> 00:01:08,560
but without further ado we give the word

26
00:01:08,560 --> 00:01:10,960
to miss anne vale tiger on stage one

27
00:01:10,960 --> 00:01:12,799
and lieutenant colonel franzlantenhammer

28
00:01:12,799 --> 00:01:14,880
on stage two and wish you a fruitful

29
00:01:14,880 --> 00:01:27,840
workshop day

30
00:01:32,320 --> 00:01:36,320
hello dear friends ladies gentlemen

31
00:01:36,320 --> 00:01:39,439
and colleagues excellencies and first

32
00:01:39,439 --> 00:01:40,240
and foremost

33
00:01:40,240 --> 00:01:42,320
the contributors to this volume that's

34
00:01:42,320 --> 00:01:44,159
we that we are going to present

35
00:01:44,159 --> 00:01:47,840
right now we are honored to present

36
00:01:47,840 --> 00:01:50,720
an edited volume titled autonomous cyber

37
00:01:50,720 --> 00:01:51,600
capabilities

38
00:01:51,600 --> 00:01:54,880
under international law the volume

39
00:01:54,880 --> 00:01:55,439
continues

40
00:01:55,439 --> 00:01:58,560
consists of 13 chapters exploring

41
00:01:58,560 --> 00:02:01,600
in in detail

42
00:02:01,600 --> 00:02:04,640
how autonomous cyber capabilities

43
00:02:04,640 --> 00:02:06,240
are viewed through the lens of

44
00:02:06,240 --> 00:02:09,520
internationals in international law

45
00:02:09,520 --> 00:02:13,040
and it comes as a follow-up

46
00:02:13,040 --> 00:02:16,400
to the working paper bearing the same

47
00:02:16,400 --> 00:02:21,280
title which was published in 2019

48
00:02:21,360 --> 00:02:24,720
speaking of the working paper then here

49
00:02:24,720 --> 00:02:28,480
i would like to bring your attention to

50
00:02:28,480 --> 00:02:29,680
the fact that

51
00:02:29,680 --> 00:02:32,080
the working paper would never have seen

52
00:02:32,080 --> 00:02:33,680
light without

53
00:02:33,680 --> 00:02:37,760
the without the enthusiasm and

54
00:02:37,760 --> 00:02:41,760
the triggering power and force of um

55
00:02:41,760 --> 00:02:44,959
miss mario nagal who was also alongside

56
00:02:44,959 --> 00:02:46,480
professor ryan levoya

57
00:02:46,480 --> 00:02:49,519
and me one of the goaters then

58
00:02:49,519 --> 00:02:52,800
so that maria is truly the person behind

59
00:02:52,800 --> 00:02:56,160
the scenes of this project

60
00:02:56,160 --> 00:02:58,319
but just as the work paper working paper

61
00:02:58,319 --> 00:02:59,840
back then

62
00:02:59,840 --> 00:03:03,440
this book also explores but on an

63
00:03:03,440 --> 00:03:07,440
entirely different new level of

64
00:03:07,440 --> 00:03:11,519
detail and complexity questions such as

65
00:03:11,519 --> 00:03:15,599
what do sovereignty accountability

66
00:03:15,599 --> 00:03:19,120
responsibility due diligence culpability

67
00:03:19,120 --> 00:03:22,239
and intent or knowledge mean at a point

68
00:03:22,239 --> 00:03:23,519
where

69
00:03:23,519 --> 00:03:26,799
autonomy autonomous technologies meet

70
00:03:26,799 --> 00:03:30,959
cyber operations quite ironically so far

71
00:03:30,959 --> 00:03:34,400
the two conversations have run

72
00:03:34,400 --> 00:03:37,599
on parallel but not

73
00:03:37,599 --> 00:03:40,480
convergent tracks even though

74
00:03:40,480 --> 00:03:41,440
technically

75
00:03:41,440 --> 00:03:45,440
one might say that the first ever

76
00:03:45,440 --> 00:03:48,400
truly autonomous weapon system or also

77
00:03:48,400 --> 00:03:48,879
the

78
00:03:48,879 --> 00:03:51,360
perhaps most notorious uh piece of

79
00:03:51,360 --> 00:03:52,159
malware

80
00:03:52,159 --> 00:03:55,439
ever to existed stocksnet was in fact

81
00:03:55,439 --> 00:03:59,920
a software that could be classified as

82
00:03:59,920 --> 00:04:03,679
an autonomous cyber capability

83
00:04:06,000 --> 00:04:08,560
even though we are forced to hold this

84
00:04:08,560 --> 00:04:10,000
event here virtually

85
00:04:10,000 --> 00:04:12,710
at the moment

86
00:04:12,710 --> 00:04:13,760
[Music]

87
00:04:13,760 --> 00:04:17,279
and we definitely would prefer to do it

88
00:04:17,279 --> 00:04:19,120
so that there would be a table and

89
00:04:19,120 --> 00:04:21,040
around the table we would have all the

90
00:04:21,040 --> 00:04:23,600
17 authors

91
00:04:23,600 --> 00:04:27,520
it is still a great achievement to our

92
00:04:27,520 --> 00:04:28,160
center

93
00:04:28,160 --> 00:04:30,800
and to at least the estonian legal

94
00:04:30,800 --> 00:04:31,600
community

95
00:04:31,600 --> 00:04:34,560
to have this book published in estonia

96
00:04:34,560 --> 00:04:36,639
and um

97
00:04:36,639 --> 00:04:39,360
due to the circumstances that we're all

98
00:04:39,360 --> 00:04:40,800
too

99
00:04:40,800 --> 00:04:43,840
too well aware of we also were forced to

100
00:04:43,840 --> 00:04:44,479
hold

101
00:04:44,479 --> 00:04:47,520
three workshops during autumn time

102
00:04:47,520 --> 00:04:51,120
also virtually and there the authors

103
00:04:51,120 --> 00:04:54,840
demonstrated um

104
00:04:54,840 --> 00:04:57,600
wonderful degree of

105
00:04:57,600 --> 00:05:01,360
involvement not only did their own work

106
00:05:01,360 --> 00:05:04,479
but also with the works of the other

107
00:05:04,479 --> 00:05:05,039
authors

108
00:05:05,039 --> 00:05:08,800
and it truly turned out in a way

109
00:05:08,800 --> 00:05:11,440
that the authors became the best

110
00:05:11,440 --> 00:05:12,240
reviewers

111
00:05:12,240 --> 00:05:15,039
sometimes the harshest critics and the

112
00:05:15,039 --> 00:05:16,479
best supporters for

113
00:05:16,479 --> 00:05:19,840
each other which made the work of the

114
00:05:19,840 --> 00:05:21,600
editors

115
00:05:21,600 --> 00:05:24,080
not really hard quite easy and pleasant

116
00:05:24,080 --> 00:05:26,719
to be honest

117
00:05:29,759 --> 00:05:32,960
and as a result i think that we have

118
00:05:32,960 --> 00:05:36,560
published a book that in a way can be

119
00:05:36,560 --> 00:05:40,080
described as a niche product

120
00:05:40,080 --> 00:05:43,520
since the technologies described their

121
00:05:43,520 --> 00:05:46,800
hypothetical and real alike are

122
00:05:46,800 --> 00:05:51,520
not the ones that define the standards

123
00:05:51,520 --> 00:05:53,680
used in practice right now they are

124
00:05:53,680 --> 00:05:55,759
sometimes

125
00:05:55,759 --> 00:05:59,120
rather futuristic but

126
00:05:59,120 --> 00:06:02,240
even though for me at least it turned

127
00:06:02,240 --> 00:06:03,919
out to be

128
00:06:03,919 --> 00:06:06,960
that autonomy serves as a wonderful

129
00:06:06,960 --> 00:06:09,120
catalyst for all the well-known

130
00:06:09,120 --> 00:06:10,880
problematics of

131
00:06:10,880 --> 00:06:14,000
international law as applied to cyber

132
00:06:14,000 --> 00:06:15,520
operations

133
00:06:15,520 --> 00:06:19,280
therefore despite its

134
00:06:19,280 --> 00:06:22,960
density and richness of thought

135
00:06:22,960 --> 00:06:26,240
it is not a mere legalistic exercise of

136
00:06:26,240 --> 00:06:29,360
academic thought and

137
00:06:29,360 --> 00:06:33,440
scholarly dialogue but it is

138
00:06:33,440 --> 00:06:36,319
our true hope that it also serves as a

139
00:06:36,319 --> 00:06:37,919
valuable compass

140
00:06:37,919 --> 00:06:41,280
to practitioners students

141
00:06:41,280 --> 00:06:44,880
technologists and everyone

142
00:06:44,880 --> 00:06:47,360
with a healthy degree of curiosity in

143
00:06:47,360 --> 00:06:49,039
all things related to

144
00:06:49,039 --> 00:06:52,800
law and new technologies

145
00:06:53,120 --> 00:06:57,120
this book owes its existence

146
00:06:57,120 --> 00:06:59,680
also to our language editor miss isabel

147
00:06:59,680 --> 00:07:00,880
beard

148
00:07:00,880 --> 00:07:04,319
and uh to miss agnes raddas

149
00:07:04,319 --> 00:07:07,759
from design studio studio studio

150
00:07:07,759 --> 00:07:11,280
who gave a form to all these

151
00:07:11,280 --> 00:07:13,758
ideas

152
00:07:14,880 --> 00:07:18,080
also the astor process turned out to be

153
00:07:18,080 --> 00:07:21,120
slightly more isolated and lonelier than

154
00:07:21,120 --> 00:07:24,240
initially expected

155
00:07:24,240 --> 00:07:27,120
it was um

156
00:07:27,280 --> 00:07:30,639
it was a true gem to have

157
00:07:30,639 --> 00:07:34,560
a working environment as warm

158
00:07:34,560 --> 00:07:37,759
diverse and inspiring as the one that

159
00:07:37,759 --> 00:07:40,319
has been cultivated by our

160
00:07:40,319 --> 00:07:44,000
head of legal branch miss godric oscar

161
00:07:44,000 --> 00:07:46,319
to whom i'm now happy to give word so

162
00:07:46,319 --> 00:07:47,120
that

163
00:07:47,120 --> 00:07:50,400
she could put the book in the broader

164
00:07:50,400 --> 00:07:52,560
context of the previous work of the

165
00:07:52,560 --> 00:07:53,680
center

166
00:07:53,680 --> 00:07:58,900
thank you and kadri welcome

167
00:07:58,900 --> 00:08:03,758
[Music]

168
00:08:04,879 --> 00:08:07,440
thank you very much anne ladies and

169
00:08:07,440 --> 00:08:08,319
gentlemen

170
00:08:08,319 --> 00:08:11,039
friends of cycon dear colleagues i am

171
00:08:11,039 --> 00:08:13,280
delighted to give a few introductory uh

172
00:08:13,280 --> 00:08:14,720
remarks at this event

173
00:08:14,720 --> 00:08:16,479
which for us is actually the conclusion

174
00:08:16,479 --> 00:08:18,240
of a three-year

175
00:08:18,240 --> 00:08:20,639
journey on the topic of the legal

176
00:08:20,639 --> 00:08:21,919
aspects of autonomy

177
00:08:21,919 --> 00:08:24,000
and if experience of the past is any

178
00:08:24,000 --> 00:08:26,000
good for predicting future these

179
00:08:26,000 --> 00:08:30,319
days because the days are indeed odd

180
00:08:30,319 --> 00:08:33,760
it is we we hope one step into more

181
00:08:33,760 --> 00:08:36,958
informed and rational discussion uh with

182
00:08:36,958 --> 00:08:37,760
actionable

183
00:08:37,760 --> 00:08:41,679
outcomes at least for for our ccdcoe

184
00:08:41,679 --> 00:08:44,320
community our community of nations

185
00:08:44,320 --> 00:08:48,080
and the western like-minded

186
00:08:48,080 --> 00:08:51,760
liberal democracies as well

187
00:08:51,760 --> 00:08:53,760
i'm sincerely inspired i must say by the

188
00:08:53,760 --> 00:08:55,040
work done by

189
00:08:55,040 --> 00:08:57,920
my dear colleague and ccdcoe researcher

190
00:08:57,920 --> 00:08:59,760
anwaliataka

191
00:08:59,760 --> 00:09:02,160
professor ryan livoya who has been our

192
00:09:02,160 --> 00:09:03,760
good collaboration partner for

193
00:09:03,760 --> 00:09:06,880
for several years and to each of the

194
00:09:06,880 --> 00:09:07,839
dozen

195
00:09:07,839 --> 00:09:09,760
authors of the book who labored over

196
00:09:09,760 --> 00:09:11,120
translating law

197
00:09:11,120 --> 00:09:15,200
into complex technology and back

198
00:09:15,200 --> 00:09:17,600
shared their findings with each other

199
00:09:17,600 --> 00:09:19,040
debated the contents of the

200
00:09:19,040 --> 00:09:22,160
of the book with other authors

201
00:09:22,160 --> 00:09:25,120
and the result is a contribution that

202
00:09:25,120 --> 00:09:27,120
brings together the legal research done

203
00:09:27,120 --> 00:09:31,360
on cyber operations and on autonomy

204
00:09:31,360 --> 00:09:33,600
and of course for the cctcoe community

205
00:09:33,600 --> 00:09:34,800
of nations

206
00:09:34,800 --> 00:09:38,240
the study helps national and nato legal

207
00:09:38,240 --> 00:09:40,160
advisors and policy makers

208
00:09:40,160 --> 00:09:43,680
to understand the legal obligations

209
00:09:43,680 --> 00:09:46,320
constraints and responsibilities

210
00:09:46,320 --> 00:09:48,880
involved in cyber operations using

211
00:09:48,880 --> 00:09:53,600
autonomous features so as

212
00:09:53,680 --> 00:09:56,880
on very well said

213
00:09:57,360 --> 00:09:59,839
when studying the legal debates on the

214
00:09:59,839 --> 00:10:01,519
issues of autonomy and cyber operations

215
00:10:01,519 --> 00:10:04,320
you will see that the work has

216
00:10:04,320 --> 00:10:06,560
occurred in largely parallel strands

217
00:10:06,560 --> 00:10:09,440
with far fewer encounters

218
00:10:09,440 --> 00:10:12,480
between them than one would imagine

219
00:10:12,480 --> 00:10:15,040
on the one hand there is the very very

220
00:10:15,040 --> 00:10:17,120
visible very active discussion

221
00:10:17,120 --> 00:10:20,720
concerning states conduct in cyberspace

222
00:10:20,720 --> 00:10:23,279
the state's practice of cyber operations

223
00:10:23,279 --> 00:10:24,640
for which both

224
00:10:24,640 --> 00:10:27,600
legal practices tangibly accumulating

225
00:10:27,600 --> 00:10:30,640
and legal research abounds

226
00:10:30,640 --> 00:10:34,320
demonstrated not least by the ccdcoe

227
00:10:34,320 --> 00:10:37,279
initiated and hosted italy manual

228
00:10:37,279 --> 00:10:38,399
project

229
00:10:38,399 --> 00:10:41,120
but also through state's recent activity

230
00:10:41,120 --> 00:10:41,440
in

231
00:10:41,440 --> 00:10:44,079
expressing their official positions uh

232
00:10:44,079 --> 00:10:44,959
responding to

233
00:10:44,959 --> 00:10:47,279
cyber operations malicious cyber

234
00:10:47,279 --> 00:10:48,480
activities by means of

235
00:10:48,480 --> 00:10:52,399
public attributions sanctions etc

236
00:10:52,399 --> 00:10:54,000
and through the variety of

237
00:10:54,000 --> 00:10:56,160
intergovernmental and multi-stakeholder

238
00:10:56,160 --> 00:10:57,040
fora that

239
00:10:57,040 --> 00:10:59,920
uh discussed these matters and then the

240
00:10:59,920 --> 00:11:00,399
other

241
00:11:00,399 --> 00:11:03,680
uh sort of strand of discussion concerns

242
00:11:03,680 --> 00:11:04,399
its

243
00:11:04,399 --> 00:11:07,200
complicated little brother which neither

244
00:11:07,200 --> 00:11:11,120
policy makers nor scholars have uh

245
00:11:11,120 --> 00:11:14,240
considered as something or or

246
00:11:14,240 --> 00:11:17,120
someone of too much of their own yet and

247
00:11:17,120 --> 00:11:19,120
that's the issue of autonomous military

248
00:11:19,120 --> 00:11:21,839
systems their development and deployment

249
00:11:21,839 --> 00:11:23,040
and containment

250
00:11:23,040 --> 00:11:25,519
which have i'd say not been through put

251
00:11:25,519 --> 00:11:26,560
through the

252
00:11:26,560 --> 00:11:29,680
the demystification process

253
00:11:29,680 --> 00:11:32,000
somewhat understandably given the

254
00:11:32,000 --> 00:11:35,440
complexity and obscurity of the topic

255
00:11:35,440 --> 00:11:37,519
and debates over autonomous weapons

256
00:11:37,519 --> 00:11:38,480
systems have been

257
00:11:38,480 --> 00:11:40,880
more focused on the containing the

258
00:11:40,880 --> 00:11:42,320
killer drones

259
00:11:42,320 --> 00:11:45,519
themselves in the actual state use

260
00:11:45,519 --> 00:11:48,320
including conscious human judgment and

261
00:11:48,320 --> 00:11:49,920
control

262
00:11:49,920 --> 00:11:52,880
yet both of those issues share the same

263
00:11:52,880 --> 00:11:55,120
technological and strategic and

264
00:11:55,120 --> 00:11:58,880
legal environment and given that the

265
00:11:58,880 --> 00:12:02,320
digital and cyber development in general

266
00:12:02,320 --> 00:12:06,000
involves an somehow inherent

267
00:12:06,000 --> 00:12:09,440
drive towards more automation autonomous

268
00:12:09,440 --> 00:12:10,560
functionalities

269
00:12:10,560 --> 00:12:13,200
it is of course no surprise that this

270
00:12:13,200 --> 00:12:14,959
tendency spills over to weapons

271
00:12:14,959 --> 00:12:16,639
development military systems and

272
00:12:16,639 --> 00:12:19,440
capabilities

273
00:12:19,440 --> 00:12:22,639
and as policy developments

274
00:12:22,639 --> 00:12:26,000
and legal advisors we cannot

275
00:12:26,000 --> 00:12:28,880
choose the menu here anymore that sort

276
00:12:28,880 --> 00:12:29,360
of

277
00:12:29,360 --> 00:12:32,480
era is passed the meal is already being

278
00:12:32,480 --> 00:12:34,480
prepared for us in the in the kitchens

279
00:12:34,480 --> 00:12:35,200
these

280
00:12:35,200 --> 00:12:37,600
topics land on our table sooner rather

281
00:12:37,600 --> 00:12:40,160
than later

282
00:12:41,200 --> 00:12:45,040
for as for ccds ccdcoe's work on the

283
00:12:45,040 --> 00:12:46,240
issue

284
00:12:46,240 --> 00:12:49,680
we did after several attempts which were

285
00:12:49,680 --> 00:12:50,480
admittedly met

286
00:12:50,480 --> 00:12:53,760
with little enthusiasm even from our own

287
00:12:53,760 --> 00:12:55,760
member nations

288
00:12:55,760 --> 00:12:58,560
the ccdcoe took on a first research

289
00:12:58,560 --> 00:13:00,079
project on international law and

290
00:13:00,079 --> 00:13:00,880
autonomous

291
00:13:00,880 --> 00:13:04,240
capabilities in 2018

292
00:13:04,240 --> 00:13:06,880
and on gave you an overview into the

293
00:13:06,880 --> 00:13:07,920
evolution of the

294
00:13:07,920 --> 00:13:11,600
of the discussion as uh as seen

295
00:13:11,600 --> 00:13:14,639
from where we stand uh

296
00:13:14,639 --> 00:13:18,079
last year no not in this

297
00:13:18,079 --> 00:13:21,680
sort of fluid era that we now live in

298
00:13:21,680 --> 00:13:24,399
actually more time is past in 2019 we

299
00:13:24,399 --> 00:13:25,519
published an

300
00:13:25,519 --> 00:13:27,839
exploratory working paper on these

301
00:13:27,839 --> 00:13:28,800
issues

302
00:13:28,800 --> 00:13:30,720
called the autonomous cyber capabilities

303
00:13:30,720 --> 00:13:32,720
under international law

304
00:13:32,720 --> 00:13:35,760
and with uh two of its three authors

305
00:13:35,760 --> 00:13:39,199
uh being

306
00:13:39,199 --> 00:13:42,399
on this physical or virtual uh stage

307
00:13:42,399 --> 00:13:45,519
today and these uh addressed

308
00:13:45,519 --> 00:13:47,440
or this report addressed the issues of

309
00:13:47,440 --> 00:13:48,720
defence and offensive

310
00:13:48,720 --> 00:13:51,120
autonomous cyber capabilities what are

311
00:13:51,120 --> 00:13:53,120
the criteria to determine

312
00:13:53,120 --> 00:13:55,519
when the use of automated or autonomous

313
00:13:55,519 --> 00:13:56,320
means

314
00:13:56,320 --> 00:13:58,320
results in for example a breach of

315
00:13:58,320 --> 00:13:59,600
sovereignty

316
00:13:59,600 --> 00:14:02,079
or intervention by a state or the use of

317
00:14:02,079 --> 00:14:03,839
force

318
00:14:03,839 --> 00:14:06,880
and how the principles of international

319
00:14:06,880 --> 00:14:08,920
humanitarian law of distinction

320
00:14:08,920 --> 00:14:12,079
proportionality or precautions must be

321
00:14:12,079 --> 00:14:13,040
factored in

322
00:14:13,040 --> 00:14:15,760
in autonomous decision making and what

323
00:14:15,760 --> 00:14:17,600
is the state's responsibility in such

324
00:14:17,600 --> 00:14:19,600
setting

325
00:14:19,600 --> 00:14:22,240
the new volume presented today goes

326
00:14:22,240 --> 00:14:22,800
wider

327
00:14:22,800 --> 00:14:25,519
and deeper into those issues and we are

328
00:14:25,519 --> 00:14:27,279
happy to have

329
00:14:27,279 --> 00:14:30,240
again a few of the of its dozen authors

330
00:14:30,240 --> 00:14:32,880
on this virtual stage with us to

331
00:14:32,880 --> 00:14:35,680
explain the subjects and unpack the the

332
00:14:35,680 --> 00:14:37,600
contents the thinking and the the

333
00:14:37,600 --> 00:14:38,720
findings for us

334
00:14:38,720 --> 00:14:43,279
today where we are today is that

335
00:14:43,279 --> 00:14:46,639
yes states have

336
00:14:47,279 --> 00:14:50,399
confirmed the application of existing

337
00:14:50,399 --> 00:14:52,800
international law to cyber operations

338
00:14:52,800 --> 00:14:54,079
and to the use of

339
00:14:54,079 --> 00:14:56,480
autonomous weapons systems there is

340
00:14:56,480 --> 00:14:58,079
little doubt that the international law

341
00:14:58,079 --> 00:14:59,199
is both relevant

342
00:14:59,199 --> 00:15:02,639
and applicable to the use of cyber

343
00:15:02,639 --> 00:15:04,320
capabilities including autonomous

344
00:15:04,320 --> 00:15:06,240
capabilities

345
00:15:06,240 --> 00:15:09,440
but autonomy does add complexity

346
00:15:09,440 --> 00:15:12,160
to ex to the application of those

347
00:15:12,160 --> 00:15:14,240
existing rules

348
00:15:14,240 --> 00:15:15,920
even though it doesn't necessarily

349
00:15:15,920 --> 00:15:17,600
create legal vacuums

350
00:15:17,600 --> 00:15:20,079
or make existing rules obsolete or

351
00:15:20,079 --> 00:15:22,800
ineffective

352
00:15:23,199 --> 00:15:26,320
but like other major technological

353
00:15:26,320 --> 00:15:27,120
advancements

354
00:15:27,120 --> 00:15:31,839
autonomous cyber capabilities do demand

355
00:15:31,839 --> 00:15:36,160
new interpretations rethinking re-asking

356
00:15:36,160 --> 00:15:38,880
the questions of how the rules initially

357
00:15:38,880 --> 00:15:41,440
designed for an entirely different

358
00:15:41,440 --> 00:15:45,040
circumstances and technologies

359
00:15:45,040 --> 00:15:48,959
are applicable are to be applied today

360
00:15:48,959 --> 00:15:51,839
and if i may borrow from the book once

361
00:15:51,839 --> 00:15:52,959
more there are some

362
00:15:52,959 --> 00:15:55,199
prepositions that drive and guide the

363
00:15:55,199 --> 00:15:57,519
legal analysis

364
00:15:57,519 --> 00:16:00,560
uh four of them namely

365
00:16:00,560 --> 00:16:02,959
autonomous capabilities are pursued

366
00:16:02,959 --> 00:16:04,560
because they can allow systems to

367
00:16:04,560 --> 00:16:05,600
outperform

368
00:16:05,600 --> 00:16:09,199
humans they enable greater speed

369
00:16:09,199 --> 00:16:11,839
speed precision uh the ability to

370
00:16:11,839 --> 00:16:12,480
analyze

371
00:16:12,480 --> 00:16:15,600
large uh data sets that humans are not

372
00:16:15,600 --> 00:16:18,639
uh capable

373
00:16:18,639 --> 00:16:21,519
of without the technology so the same

374
00:16:21,519 --> 00:16:23,759
trait of being able to surpass

375
00:16:23,759 --> 00:16:26,320
human performance that means that in

376
00:16:26,320 --> 00:16:27,839
these respects

377
00:16:27,839 --> 00:16:30,880
uh it is not possible uh to subject

378
00:16:30,880 --> 00:16:31,600
autonomous

379
00:16:31,600 --> 00:16:34,880
systems to real-time human control the

380
00:16:34,880 --> 00:16:37,440
human is

381
00:16:37,440 --> 00:16:41,600
to to many extents removed from the loop

382
00:16:41,600 --> 00:16:44,959
and actually forcing or trying to place

383
00:16:44,959 --> 00:16:46,480
the human back in the loop would

384
00:16:46,480 --> 00:16:48,399
degrade or defeat the whole purpose of

385
00:16:48,399 --> 00:16:51,839
the autonomous functionality

386
00:16:52,639 --> 00:16:54,320
on the other hand human actors and

387
00:16:54,320 --> 00:16:55,839
states

388
00:16:55,839 --> 00:16:57,920
can be held responsible for the

389
00:16:57,920 --> 00:17:00,320
consequences of using a special

390
00:17:00,320 --> 00:17:03,440
or specific autonomous capability

391
00:17:03,440 --> 00:17:06,799
in those specific circumstances since

392
00:17:06,799 --> 00:17:09,599
humans and states unlike technology are

393
00:17:09,599 --> 00:17:11,439
the legal actors who must comply with

394
00:17:11,439 --> 00:17:12,559
international law

395
00:17:12,559 --> 00:17:14,400
and therefore must understand the

396
00:17:14,400 --> 00:17:16,079
conduct and the rationale

397
00:17:16,079 --> 00:17:19,679
of the of the machine and therefore

398
00:17:19,679 --> 00:17:22,160
our defence policy planners our military

399
00:17:22,160 --> 00:17:23,839
commanders and their staff

400
00:17:23,839 --> 00:17:27,199
including legal advisers cannot afford

401
00:17:27,199 --> 00:17:27,839
to not

402
00:17:27,839 --> 00:17:31,360
understand the fundamentals and

403
00:17:31,360 --> 00:17:32,960
ask informed questions about the

404
00:17:32,960 --> 00:17:35,679
operation of autonomous capabilities

405
00:17:35,679 --> 00:17:37,640
and know their own duties and

406
00:17:37,640 --> 00:17:38,799
responsibilities

407
00:17:38,799 --> 00:17:42,960
despite their complexity so this book

408
00:17:42,960 --> 00:17:45,440
is offering a chance to ask why is there

409
00:17:45,440 --> 00:17:46,799
more nuanced

410
00:17:46,799 --> 00:17:49,679
more informed questions to comply with

411
00:17:49,679 --> 00:17:50,080
our

412
00:17:50,080 --> 00:17:52,720
international legal obligations and

413
00:17:52,720 --> 00:17:53,360
hence

414
00:17:53,360 --> 00:17:56,480
sustain the security and stability of

415
00:17:56,480 --> 00:17:59,440
the cyberspace that we all depend on

416
00:17:59,440 --> 00:18:03,440
so i hope this session and your reading

417
00:18:03,440 --> 00:18:05,600
of the book will be inspiring and

418
00:18:05,600 --> 00:18:07,360
enlightening

419
00:18:07,360 --> 00:18:11,120
and with that i

420
00:18:11,120 --> 00:18:13,520
passed back the floor to on who will

421
00:18:13,520 --> 00:18:14,960
introduce the panelists

422
00:18:14,960 --> 00:18:18,960
and and guide the the discussions coming

423
00:18:18,960 --> 00:18:19,360
now

424
00:18:19,360 --> 00:18:22,720
so uh on i'm looking forward to uh

425
00:18:22,720 --> 00:18:26,000
to hearing the session uh enjoy both on

426
00:18:26,000 --> 00:18:26,720
stage and

427
00:18:26,720 --> 00:18:28,640
and in the audience and thank you very

428
00:18:28,640 --> 00:18:32,000
much for for being with us

429
00:18:34,310 --> 00:18:37,520
[Music]

430
00:18:40,840 --> 00:18:43,840
thanks

431
00:18:47,120 --> 00:18:50,720
thank you godree for not only putting

432
00:18:50,720 --> 00:18:52,960
our work in the broader context of what

433
00:18:52,960 --> 00:18:54,160
the center does but

434
00:18:54,160 --> 00:18:57,039
also in the broader context of what's

435
00:18:57,039 --> 00:18:58,960
going on in technology law

436
00:18:58,960 --> 00:19:01,760
and strategy in the field and how

437
00:19:01,760 --> 00:19:03,600
understanding autonomous cyber

438
00:19:03,600 --> 00:19:07,280
capabilities is perhaps becoming

439
00:19:07,280 --> 00:19:11,280
inevitable in a sense so

440
00:19:11,280 --> 00:19:14,160
to proceed then i would like to

441
00:19:14,160 --> 00:19:15,039
introduce

442
00:19:15,039 --> 00:19:18,160
our distinguished panel

443
00:19:18,160 --> 00:19:20,640
where each and every member is somehow

444
00:19:20,640 --> 00:19:24,559
involved with the book

445
00:19:24,559 --> 00:19:28,000
editors and authors so

446
00:19:28,000 --> 00:19:31,440
everybody's there yeah and uh first we

447
00:19:31,440 --> 00:19:32,320
have professor

448
00:19:32,320 --> 00:19:34,799
ryan livo from university of queensland

449
00:19:34,799 --> 00:19:35,760
who serves as the

450
00:19:35,760 --> 00:19:39,039
lead editor of the book second it's uh

451
00:19:39,039 --> 00:19:41,919
dr russell buchenbachen who's from the

452
00:19:41,919 --> 00:19:43,919
university of sheffield and

453
00:19:43,919 --> 00:19:46,000
authored a chapter about command

454
00:19:46,000 --> 00:19:48,000
responsibility

455
00:19:48,000 --> 00:19:49,919
third we have professor thomas body from

456
00:19:49,919 --> 00:19:51,360
university of st cullen from in

457
00:19:51,360 --> 00:19:52,480
switzerland

458
00:19:52,480 --> 00:19:57,520
and his research or his contribution

459
00:19:57,520 --> 00:20:01,520
took a look into how

460
00:20:01,520 --> 00:20:06,240
how or disembodied systems can be

461
00:20:06,240 --> 00:20:09,360
subjected to ethical evaluation

462
00:20:09,360 --> 00:20:12,640
and third we have professor eric johnson

463
00:20:12,640 --> 00:20:16,320
from pre-chem school of university

464
00:20:16,320 --> 00:20:20,240
and his contribution

465
00:20:20,320 --> 00:20:23,760
pondered on the actual alleged

466
00:20:23,760 --> 00:20:27,360
inherent uh value of human judgment

467
00:20:27,360 --> 00:20:30,400
in in

468
00:20:30,400 --> 00:20:33,679
applying international humanitarian law

469
00:20:33,679 --> 00:20:38,960
when using autonomous

470
00:20:38,960 --> 00:20:41,760
capabilities or weapon systems either

471
00:20:41,760 --> 00:20:43,440
kinetic or

472
00:20:43,440 --> 00:20:46,960
purely virtual and

473
00:20:46,960 --> 00:20:50,080
i'm delighted to host the panel and

474
00:20:50,080 --> 00:20:52,799
i'm trying to put some of my knowledge

475
00:20:52,799 --> 00:20:53,840
obtained as

476
00:20:53,840 --> 00:20:57,120
uh the co-editor in use

477
00:20:57,120 --> 00:21:01,280
but first and foremost maybe it's

478
00:21:01,280 --> 00:21:04,559
nice transition from from from from

479
00:21:04,559 --> 00:21:06,159
describing the

480
00:21:06,159 --> 00:21:09,280
genesis and

481
00:21:09,360 --> 00:21:12,559
and the story of the book

482
00:21:12,559 --> 00:21:16,080
but i would like to turn to roy levoya

483
00:21:16,080 --> 00:21:17,039
right now

484
00:21:17,039 --> 00:21:19,280
and

485
00:21:20,720 --> 00:21:25,039
ask about what was in fact

486
00:21:25,039 --> 00:21:28,400
the main question that guided you on the

487
00:21:28,400 --> 00:21:28,880
way or

488
00:21:28,880 --> 00:21:31,600
inspired you to become the lead editor

489
00:21:31,600 --> 00:21:33,039
of this

490
00:21:33,039 --> 00:21:36,720
uh this volume and

491
00:21:36,799 --> 00:21:38,799
is it somehow related to your previous

492
00:21:38,799 --> 00:21:40,960
academic research or your

493
00:21:40,960 --> 00:21:44,000
experience in the lowest group of

494
00:21:44,000 --> 00:21:45,600
governmental experts

495
00:21:45,600 --> 00:21:47,840
or anything else that comes to your mind

496
00:21:47,840 --> 00:21:48,960
so

497
00:21:48,960 --> 00:21:51,679
ryan please

498
00:21:52,960 --> 00:21:56,000
thanks on and thanks um also kadri for

499
00:21:56,000 --> 00:21:57,760
the very kind introductions and for the

500
00:21:57,760 --> 00:21:59,760
opportunity to speak today

501
00:21:59,760 --> 00:22:02,000
um it's regrettable that we we can't

502
00:22:02,000 --> 00:22:03,360
meet in person but

503
00:22:03,360 --> 00:22:06,080
but it's all still good to have a

504
00:22:06,080 --> 00:22:08,000
conversation around this book and and

505
00:22:08,000 --> 00:22:10,240
i'm very pleased that you were able to

506
00:22:10,240 --> 00:22:12,720
uh join us um this morning this

507
00:22:12,720 --> 00:22:14,400
afternoon this evening

508
00:22:14,400 --> 00:22:17,600
depending on where in the world you are

509
00:22:17,600 --> 00:22:20,320
so the book really st the the question

510
00:22:20,320 --> 00:22:21,360
that drove the book

511
00:22:21,360 --> 00:22:25,440
was uh a an observed disconnect between

512
00:22:25,440 --> 00:22:27,600
the discussions around

513
00:22:27,600 --> 00:22:30,400
autonomous capabilities and cyber

514
00:22:30,400 --> 00:22:31,840
capabilities

515
00:22:31,840 --> 00:22:34,960
and at the time the ccdcoe

516
00:22:34,960 --> 00:22:37,280
had identified the development of

517
00:22:37,280 --> 00:22:39,280
artificial intelligence

518
00:22:39,280 --> 00:22:42,880
as a significant concern

519
00:22:42,880 --> 00:22:45,840
in the context of cyber capabilities

520
00:22:45,840 --> 00:22:46,799
with potential

521
00:22:46,799 --> 00:22:51,360
implications for the applicable law

522
00:22:51,360 --> 00:22:54,400
whereas i had participated

523
00:22:54,400 --> 00:22:57,919
in the work of the group of governmental

524
00:22:57,919 --> 00:22:59,760
experts on lethal autonomous weapon

525
00:22:59,760 --> 00:23:00,880
systems

526
00:23:00,880 --> 00:23:03,280
and observed there the fact that the

527
00:23:03,280 --> 00:23:05,200
discussion was entirely focused on

528
00:23:05,200 --> 00:23:07,039
kinetic capabilities

529
00:23:07,039 --> 00:23:09,440
there was no reference to potential

530
00:23:09,440 --> 00:23:11,760
autonomy and cyber capabilities

531
00:23:11,760 --> 00:23:13,679
despite the fact as has already been

532
00:23:13,679 --> 00:23:14,960
mentioned

533
00:23:14,960 --> 00:23:17,600
at the most autonomous cyber capability

534
00:23:17,600 --> 00:23:19,120
that the world has seen

535
00:23:19,120 --> 00:23:22,159
um stuxnet is or was in fact

536
00:23:22,159 --> 00:23:25,360
a cyber capability and

537
00:23:25,360 --> 00:23:28,400
um it's all the more curious

538
00:23:28,400 --> 00:23:32,559
as a discussion of cyber capabilities

539
00:23:32,559 --> 00:23:34,960
would be relevant to a conversation

540
00:23:34,960 --> 00:23:36,799
about autonomous weapons systems and for

541
00:23:36,799 --> 00:23:38,640
a number of reasons

542
00:23:38,640 --> 00:23:42,159
on the one hand there are certain legal

543
00:23:42,159 --> 00:23:45,200
uh considerations that are the same

544
00:23:45,200 --> 00:23:47,840
for both types of capabilities so

545
00:23:47,840 --> 00:23:50,159
autonomous kinetic capabilities um

546
00:23:50,159 --> 00:23:52,720
and cyber capabilities which is that

547
00:23:52,720 --> 00:23:53,200
there

548
00:23:53,200 --> 00:23:54,880
are potentially quite significant

549
00:23:54,880 --> 00:23:56,720
concerns uh about

550
00:23:56,720 --> 00:23:59,440
attribution uh of conduct and this is an

551
00:23:59,440 --> 00:24:00,480
issue well known

552
00:24:00,480 --> 00:24:02,960
for uh people operating in the in the

553
00:24:02,960 --> 00:24:04,240
cyber domain

554
00:24:04,240 --> 00:24:06,080
but the same problem can arise in

555
00:24:06,080 --> 00:24:08,080
circumstances where potentially large

556
00:24:08,080 --> 00:24:08,880
numbers

557
00:24:08,880 --> 00:24:12,000
of autonomous systems are deployed

558
00:24:12,000 --> 00:24:15,039
in context in in conflicts

559
00:24:15,039 --> 00:24:17,120
and the other consideration is a

560
00:24:17,120 --> 00:24:18,240
strategic one

561
00:24:18,240 --> 00:24:20,400
um autonomous functionality in weapon

562
00:24:20,400 --> 00:24:21,360
systems is

563
00:24:21,360 --> 00:24:23,919
software based uh which means that it

564
00:24:23,919 --> 00:24:25,600
can potentially proliferate

565
00:24:25,600 --> 00:24:28,720
uh very cheaply and quickly

566
00:24:28,720 --> 00:24:30,320
and so it's a little bit curious as to

567
00:24:30,320 --> 00:24:33,200
why um cyber capabilities really haven't

568
00:24:33,200 --> 00:24:34,799
been looked at in the debates

569
00:24:34,799 --> 00:24:37,360
around uh autonomous weapon systems and

570
00:24:37,360 --> 00:24:38,559
and i can come back to

571
00:24:38,559 --> 00:24:42,000
uh speculate about that um but but

572
00:24:42,000 --> 00:24:44,880
this i think was was what drove uh uh

573
00:24:44,880 --> 00:24:46,480
the project

574
00:24:46,480 --> 00:24:49,600
and also the lack of scholarly attention

575
00:24:49,600 --> 00:24:50,559
to

576
00:24:50,559 --> 00:24:52,880
autonomous cyber capabilities from from

577
00:24:52,880 --> 00:24:54,720
a legal perspective was

578
00:24:54,720 --> 00:24:57,120
an important consideration so we hoped

579
00:24:57,120 --> 00:24:58,000
that we could

580
00:24:58,000 --> 00:25:00,159
trigger something of a discussion with

581
00:25:00,159 --> 00:25:01,840
our working paper

582
00:25:01,840 --> 00:25:05,679
and then invite experts in various

583
00:25:05,679 --> 00:25:06,640
fields along

584
00:25:06,640 --> 00:25:10,480
to engage with that paper

585
00:25:10,480 --> 00:25:12,720
and develop and contribute their own

586
00:25:12,720 --> 00:25:14,720
thinking around some of the issues that

587
00:25:14,720 --> 00:25:15,840
we identified

588
00:25:15,840 --> 00:25:18,320
or potentially other issues that are

589
00:25:18,320 --> 00:25:21,520
contributors identified

590
00:25:22,720 --> 00:25:25,760
and thank you very much and indeed the

591
00:25:25,760 --> 00:25:28,400
major issue was that while kinetic

592
00:25:28,400 --> 00:25:30,400
autonomous capabilities tend to be the

593
00:25:30,400 --> 00:25:31,440
hot topic

594
00:25:31,440 --> 00:25:33,360
and cyber operations tend to be a hot

595
00:25:33,360 --> 00:25:34,640
topic as well

596
00:25:34,640 --> 00:25:39,200
but the conversations rarely merge then

597
00:25:39,200 --> 00:25:43,679
we came to the wonderful idea that

598
00:25:43,679 --> 00:25:47,039
perhaps it should be tested

599
00:25:47,039 --> 00:25:50,240
whether disembodied

600
00:25:50,240 --> 00:25:53,120
capabilities can be evaluated according

601
00:25:53,120 --> 00:25:54,880
to the same models

602
00:25:54,880 --> 00:25:57,220
that are applied to

603
00:25:57,220 --> 00:25:58,400
[Music]

604
00:25:58,400 --> 00:26:02,400
kinetic systems so and for this we

605
00:26:02,400 --> 00:26:05,440
invited professor thomas puri who

606
00:26:05,440 --> 00:26:07,840
previously has come up with a model for

607
00:26:07,840 --> 00:26:09,760
evaluating

608
00:26:09,760 --> 00:26:12,480
evaluating autonomous weapon systems

609
00:26:12,480 --> 00:26:12,960
that

610
00:26:12,960 --> 00:26:16,320
operate in the kinetic realms and wanted

611
00:26:16,320 --> 00:26:17,360
to know

612
00:26:17,360 --> 00:26:19,840
if and to which extent can the same

613
00:26:19,840 --> 00:26:22,080
model called the schema can you perhaps

614
00:26:22,080 --> 00:26:25,279
introduce it a bit be applied to

615
00:26:25,279 --> 00:26:27,120
disembodied systems and what are the

616
00:26:27,120 --> 00:26:28,640
main obstacles and when

617
00:26:28,640 --> 00:26:32,000
are analogies rather sufficient so

618
00:26:32,000 --> 00:26:38,240
welcome and floor is for yours

619
00:26:38,240 --> 00:26:41,919
thank you anne um this is not a very

620
00:26:41,919 --> 00:26:43,279
straightforward question

621
00:26:43,279 --> 00:26:46,080
you know when i when i talk about this

622
00:26:46,080 --> 00:26:46,640
tool

623
00:26:46,640 --> 00:26:50,080
we developed to assess

624
00:26:50,080 --> 00:26:52,480
robotic systems in an ethical

625
00:26:52,480 --> 00:26:53,679
perspective

626
00:26:53,679 --> 00:26:55,120
and you know when i usually when i

627
00:26:55,120 --> 00:26:56,799
introduce it it takes me around two

628
00:26:56,799 --> 00:26:57,840
hours and people

629
00:26:57,840 --> 00:27:00,000
are usually then very very confused so

630
00:27:00,000 --> 00:27:01,760
here i have a couple of minutes

631
00:27:01,760 --> 00:27:03,520
and that is bound to be not fully

632
00:27:03,520 --> 00:27:04,799
satisfactory

633
00:27:04,799 --> 00:27:09,600
and but look i mean the thing is

634
00:27:09,600 --> 00:27:13,279
when we came to this idea of evaluating

635
00:27:13,279 --> 00:27:16,159
cyber systems autonomous cyber systems

636
00:27:16,159 --> 00:27:19,039
and it was very clear to us us being

637
00:27:19,039 --> 00:27:20,480
myself and

638
00:27:20,480 --> 00:27:23,120
my co-author of daniel trisillo and it

639
00:27:23,120 --> 00:27:24,799
was very clear to us that

640
00:27:24,799 --> 00:27:26,880
we brought some let's say significant

641
00:27:26,880 --> 00:27:28,480
experience we talked about five

642
00:27:28,480 --> 00:27:30,799
six seven years of of working with

643
00:27:30,799 --> 00:27:31,679
autonomous

644
00:27:31,679 --> 00:27:34,080
physical embodied systems to this

645
00:27:34,080 --> 00:27:34,799
project

646
00:27:34,799 --> 00:27:36,640
we have developed the tool we call it

647
00:27:36,640 --> 00:27:38,880
the schema which

648
00:27:38,880 --> 00:27:41,840
you know takes a very comprehensive look

649
00:27:41,840 --> 00:27:42,960
at autonomous

650
00:27:42,960 --> 00:27:46,640
systems in the security field

651
00:27:46,640 --> 00:27:50,240
loosely said and you know this has

652
00:27:50,240 --> 00:27:51,760
multiple steps but one of the most

653
00:27:51,760 --> 00:27:54,559
important steps for this project here

654
00:27:54,559 --> 00:27:56,159
is to decide whether the system has

655
00:27:56,159 --> 00:27:58,000
autonomy you know in the first place is

656
00:27:58,000 --> 00:27:59,279
it an autonomous systems

657
00:27:59,279 --> 00:28:01,120
in our case we talked about robots

658
00:28:01,120 --> 00:28:02,559
autonomous robots

659
00:28:02,559 --> 00:28:04,399
we took that and applied this to

660
00:28:04,399 --> 00:28:06,799
autonomous cyber capabilities

661
00:28:06,799 --> 00:28:09,760
we had a notion say that relied on sort

662
00:28:09,760 --> 00:28:12,240
of five composite elements

663
00:28:12,240 --> 00:28:15,039
um to uh to determine whether the robot

664
00:28:15,039 --> 00:28:16,559
was autonomous

665
00:28:16,559 --> 00:28:19,520
and of these elements which you know

666
00:28:19,520 --> 00:28:20,240
broadly

667
00:28:20,240 --> 00:28:21,919
are based on the question look is this

668
00:28:21,919 --> 00:28:23,440
thing you're looking at is it

669
00:28:23,440 --> 00:28:25,120
authentic has it auto key is it

670
00:28:25,120 --> 00:28:26,559
independent from energy

671
00:28:26,559 --> 00:28:29,919
is it independent from human control

672
00:28:29,919 --> 00:28:31,279
does it learn

673
00:28:31,279 --> 00:28:33,520
does it interact with the environment

674
00:28:33,520 --> 00:28:34,640
with the environment

675
00:28:34,640 --> 00:28:37,679
and is it is it mobile does it move so

676
00:28:37,679 --> 00:28:39,279
these five factors

677
00:28:39,279 --> 00:28:42,799
for us for a physical system determined

678
00:28:42,799 --> 00:28:45,679
whether the thing we're looking at is an

679
00:28:45,679 --> 00:28:47,360
autonomous system

680
00:28:47,360 --> 00:28:50,399
now for cyber systems like

681
00:28:50,399 --> 00:28:52,640
these criterions make sense but only to

682
00:28:52,640 --> 00:28:53,760
a certain extent

683
00:28:53,760 --> 00:28:56,320
you can't really consider whether a

684
00:28:56,320 --> 00:28:57,440
cyber system is

685
00:28:57,440 --> 00:28:59,600
autonomous in the sense that it has or

686
00:28:59,600 --> 00:29:00,559
turkey

687
00:29:00,559 --> 00:29:02,320
independence from energy source if it

688
00:29:02,320 --> 00:29:03,679
doesn't have energy

689
00:29:03,679 --> 00:29:06,480
a cyber system at least as far as i know

690
00:29:06,480 --> 00:29:08,159
can't survive

691
00:29:08,159 --> 00:29:11,279
so survive and then of course in a

692
00:29:11,279 --> 00:29:14,399
in a metaphorical sense so to speak and

693
00:29:14,399 --> 00:29:15,440
it also doesn't

694
00:29:15,440 --> 00:29:18,880
make too much sense to say whether

695
00:29:18,880 --> 00:29:21,200
it is mobile you know or does it move

696
00:29:21,200 --> 00:29:22,159
around

697
00:29:22,159 --> 00:29:24,480
that doesn't make too much sense you can

698
00:29:24,480 --> 00:29:26,480
look at whether it learns does it have

699
00:29:26,480 --> 00:29:28,000
machine learning and that of course

700
00:29:28,000 --> 00:29:29,840
links to the question is it an

701
00:29:29,840 --> 00:29:31,679
artificial intelligence which again is

702
00:29:31,679 --> 00:29:34,000
one of those other subgroups

703
00:29:34,000 --> 00:29:37,200
which you know develops evolves large in

704
00:29:37,200 --> 00:29:38,640
parallel to the discussion about

705
00:29:38,640 --> 00:29:40,640
autonomous weapon systems and the cyber

706
00:29:40,640 --> 00:29:41,760
discussion

707
00:29:41,760 --> 00:29:43,840
does it have artificial intelligence and

708
00:29:43,840 --> 00:29:44,799
then mostly

709
00:29:44,799 --> 00:29:47,600
um is it subject to some sort of an

710
00:29:47,600 --> 00:29:49,200
adequate human control

711
00:29:49,200 --> 00:29:51,279
and that of course is a bridge to the

712
00:29:51,279 --> 00:29:53,279
situation or the discussion we have in

713
00:29:53,279 --> 00:29:54,640
geneva

714
00:29:54,640 --> 00:29:56,480
so essentially when we look at

715
00:29:56,480 --> 00:29:58,559
autonomous cyber systems we are

716
00:29:58,559 --> 00:30:01,120
almost thrown back on this very central

717
00:30:01,120 --> 00:30:02,399
notion of

718
00:30:02,399 --> 00:30:06,840
is it subject to some adequate level of

719
00:30:06,840 --> 00:30:08,480
control

720
00:30:08,480 --> 00:30:10,000
this is a it's obviously an open

721
00:30:10,000 --> 00:30:11,840
discussion but we can say that the

722
00:30:11,840 --> 00:30:14,559
the ccw has discussed this notion

723
00:30:14,559 --> 00:30:15,520
whether and when

724
00:30:15,520 --> 00:30:17,279
something is subject to adequate human

725
00:30:17,279 --> 00:30:19,760
control for almost seven years now

726
00:30:19,760 --> 00:30:23,840
and it has come to let's say

727
00:30:24,000 --> 00:30:27,679
a rather minimal consensus for the cyber

728
00:30:27,679 --> 00:30:28,080
or

729
00:30:28,080 --> 00:30:32,399
cyber realm if you like cyberspace

730
00:30:32,399 --> 00:30:34,399
we have to see whether the whether there

731
00:30:34,399 --> 00:30:36,159
is it's easier to achieve

732
00:30:36,159 --> 00:30:39,679
consensus our experience for ccws tells

733
00:30:39,679 --> 00:30:41,120
us well it's not

734
00:30:41,120 --> 00:30:43,279
um but that doesn't mean we don't have

735
00:30:43,279 --> 00:30:44,720
to have the conversation

736
00:30:44,720 --> 00:30:47,919
i leave it uh here for the moment maybe

737
00:30:47,919 --> 00:30:49,120
i could say more during

738
00:30:49,120 --> 00:30:52,799
discussion then back to you and

739
00:30:52,880 --> 00:30:55,039
yeah definitely coming back to many of

740
00:30:55,039 --> 00:30:56,720
the facets that you just

741
00:30:56,720 --> 00:31:00,720
briefly flew by right now because

742
00:31:00,720 --> 00:31:03,760
they are so substantial to the whole

743
00:31:03,760 --> 00:31:06,559
to the whole debate but moving on to

744
00:31:06,559 --> 00:31:07,200
professor

745
00:31:07,200 --> 00:31:10,279
eric chance and then as

746
00:31:10,279 --> 00:31:13,440
reiterated by the

747
00:31:13,440 --> 00:31:16,080
previous two speakers and by thousands

748
00:31:16,080 --> 00:31:17,120
of others

749
00:31:17,120 --> 00:31:20,320
then the core of all these debates

750
00:31:20,320 --> 00:31:24,240
and that creates this quiet

751
00:31:24,240 --> 00:31:27,279
and misunderstanding is the

752
00:31:27,279 --> 00:31:29,679
may i say shifting notion of what in

753
00:31:29,679 --> 00:31:31,279
fact

754
00:31:31,279 --> 00:31:34,480
constitutes human control but

755
00:31:34,480 --> 00:31:36,880
if we for a second leave the technical

756
00:31:36,880 --> 00:31:38,960
and ethical issues aside

757
00:31:38,960 --> 00:31:42,960
then what does international law

758
00:31:42,960 --> 00:31:46,880
law of countermeasures use

759
00:31:46,880 --> 00:31:49,760
what does international humanitarian law

760
00:31:49,760 --> 00:31:50,640
also has

761
00:31:50,640 --> 00:31:54,880
to have to say about these issues

762
00:31:55,440 --> 00:31:59,279
so welcome thank you anna thank you for

763
00:31:59,279 --> 00:32:01,600
letting me uh be here i i'm grateful to

764
00:32:01,600 --> 00:32:02,320
be a part of

765
00:32:02,320 --> 00:32:04,799
uh cycon it's always the best cyber

766
00:32:04,799 --> 00:32:05,840
conference each year

767
00:32:05,840 --> 00:32:08,240
and i'm grateful to to be asked to

768
00:32:08,240 --> 00:32:09,840
participate

769
00:32:09,840 --> 00:32:12,159
i was very grateful for ryan's and and

770
00:32:12,159 --> 00:32:14,000
thomas's earlier remarks because

771
00:32:14,000 --> 00:32:17,200
i think they set up my uh question

772
00:32:17,200 --> 00:32:20,720
quite well this one of the

773
00:32:20,720 --> 00:32:22,559
one of the fundamental threshold

774
00:32:22,559 --> 00:32:23,919
questions is how we

775
00:32:23,919 --> 00:32:27,760
define autonomy what we think autonomy

776
00:32:27,760 --> 00:32:30,000
means and and we have to at least

777
00:32:30,000 --> 00:32:31,840
embrace that question and understand it

778
00:32:31,840 --> 00:32:33,120
before we can

779
00:32:33,120 --> 00:32:35,440
then look at the legal restraints that

780
00:32:35,440 --> 00:32:36,720
might be in place

781
00:32:36,720 --> 00:32:39,440
on the use of autonomous weapon systems

782
00:32:39,440 --> 00:32:39,760
and

783
00:32:39,760 --> 00:32:42,080
and ryan along with a co-author chris

784
00:32:42,080 --> 00:32:43,840
jenks have written a great article

785
00:32:43,840 --> 00:32:46,240
this book has a great chapter uh that

786
00:32:46,240 --> 00:32:48,240
will talk about that as well by tim

787
00:32:48,240 --> 00:32:49,440
mcfarlane

788
00:32:49,440 --> 00:32:51,919
there are lots of issues fundamental

789
00:32:51,919 --> 00:32:53,840
threshold issues on how we define

790
00:32:53,840 --> 00:32:55,120
autonomy that i think

791
00:32:55,120 --> 00:32:58,240
are are important for us to make sure we

792
00:32:58,240 --> 00:32:59,760
understand when we get to the legal

793
00:32:59,760 --> 00:33:00,720
question

794
00:33:00,720 --> 00:33:02,880
because autonomy will inevitably be on

795
00:33:02,880 --> 00:33:04,480
the battlefield there is no

796
00:33:04,480 --> 00:33:07,440
doubt about that that that that ship has

797
00:33:07,440 --> 00:33:08,399
already sailed in

798
00:33:08,399 --> 00:33:11,120
in the in to use the colloquial term

799
00:33:11,120 --> 00:33:13,440
autonomy will be involved in logistics

800
00:33:13,440 --> 00:33:15,360
it will be involved in data collection

801
00:33:15,360 --> 00:33:16,320
and compilation

802
00:33:16,320 --> 00:33:17,919
it will be involved in intelligence

803
00:33:17,919 --> 00:33:19,200
gathering it will be involved in

804
00:33:19,200 --> 00:33:20,399
analysis

805
00:33:20,399 --> 00:33:23,039
autonomous systems will be functioning

806
00:33:23,039 --> 00:33:24,640
on the battlefield

807
00:33:24,640 --> 00:33:29,440
in a in a many many different facets

808
00:33:29,440 --> 00:33:32,640
so the the type of autonomous system i

809
00:33:32,640 --> 00:33:33,600
want to focus on

810
00:33:33,600 --> 00:33:36,320
that is important for my chapter my

811
00:33:36,320 --> 00:33:36,960
research

812
00:33:36,960 --> 00:33:39,360
is autonomous systems that are engaged

813
00:33:39,360 --> 00:33:41,840
in selecting and engaging targets

814
00:33:41,840 --> 00:33:45,120
and this is where i think the the most

815
00:33:45,120 --> 00:33:47,440
important questions and maybe the most

816
00:33:47,440 --> 00:33:49,039
difficult questions

817
00:33:49,039 --> 00:33:50,960
have arisen thomas mentioned the

818
00:33:50,960 --> 00:33:52,640
discussions that have been going on

819
00:33:52,640 --> 00:33:54,720
in geneva at the the certain

820
00:33:54,720 --> 00:33:56,080
conventional weapons convention

821
00:33:56,080 --> 00:33:58,559
state parties meetings they've been

822
00:33:58,559 --> 00:34:00,640
going on for a long time there is indeed

823
00:34:00,640 --> 00:34:03,840
uh a great lack of meaningful consensus

824
00:34:03,840 --> 00:34:06,960
on this issue but two major

825
00:34:06,960 --> 00:34:09,280
questions i think have emerged and the

826
00:34:09,280 --> 00:34:10,879
first question

827
00:34:10,879 --> 00:34:15,199
is what level of human control if any

828
00:34:15,199 --> 00:34:17,280
does the law require from autonomous

829
00:34:17,280 --> 00:34:18,399
weapons including

830
00:34:18,399 --> 00:34:20,879
autonomous cyber weapons that will

831
00:34:20,879 --> 00:34:21,440
select

832
00:34:21,440 --> 00:34:25,280
and engage targets again the key here is

833
00:34:25,280 --> 00:34:27,359
the selecting and engaging targets

834
00:34:27,359 --> 00:34:29,679
autonomy will be involved in lots of

835
00:34:29,679 --> 00:34:30,480
other systems

836
00:34:30,480 --> 00:34:33,440
but when that system begins to select

837
00:34:33,440 --> 00:34:34,000
and engage

838
00:34:34,000 --> 00:34:37,199
targets then the issue of what law

839
00:34:37,199 --> 00:34:39,119
applies what legal constraints might

840
00:34:39,119 --> 00:34:42,159
apply to that situation becomes key

841
00:34:42,159 --> 00:34:45,199
and then the second question would be if

842
00:34:45,199 --> 00:34:46,560
no human control

843
00:34:46,560 --> 00:34:48,960
is required what is the standard

844
00:34:48,960 --> 00:34:50,800
required for states to field such

845
00:34:50,800 --> 00:34:51,440
weapons

846
00:34:51,440 --> 00:34:54,399
uh for example does an autonomous weapon

847
00:34:54,399 --> 00:34:55,599
that selects and engage

848
00:34:55,599 --> 00:34:59,280
and engages targets have to be 100

849
00:34:59,280 --> 00:35:02,160
correct every case never make a mistake

850
00:35:02,160 --> 00:35:03,680
or does it just have to be better than

851
00:35:03,680 --> 00:35:04,480
humans

852
00:35:04,480 --> 00:35:07,040
or is there some standard in the middle

853
00:35:07,040 --> 00:35:08,880
that will be acceptable for autonomous

854
00:35:08,880 --> 00:35:10,079
weapon systems to select

855
00:35:10,079 --> 00:35:13,440
engage uh targets let me deal

856
00:35:13,440 --> 00:35:15,440
briefly with that first question what

857
00:35:15,440 --> 00:35:17,119
level of human control if any

858
00:35:17,119 --> 00:35:20,240
does the law require uh including for

859
00:35:20,240 --> 00:35:22,640
autonomous weapons systems and here we

860
00:35:22,640 --> 00:35:24,560
have some differing views as thomas is

861
00:35:24,560 --> 00:35:25,599
highlighted there

862
00:35:25,599 --> 00:35:28,079
there are there are some elements some

863
00:35:28,079 --> 00:35:30,079
individuals some organizations who argue

864
00:35:30,079 --> 00:35:30,960
that

865
00:35:30,960 --> 00:35:33,760
um there there must be some form of

866
00:35:33,760 --> 00:35:35,200
human control

867
00:35:35,200 --> 00:35:37,440
uh in the system and then there is a

868
00:35:37,440 --> 00:35:38,240
great

869
00:35:38,240 --> 00:35:40,400
debate about where that what what that

870
00:35:40,400 --> 00:35:41,440
means what that

871
00:35:41,440 --> 00:35:44,240
human involvement means does it mean at

872
00:35:44,240 --> 00:35:46,640
the time of selecting and engaging

873
00:35:46,640 --> 00:35:49,839
does it mean somewhere in the life cycle

874
00:35:49,839 --> 00:35:53,040
that would provide confidence in the

875
00:35:53,040 --> 00:35:56,160
weapons ability to select and engage

876
00:35:56,160 --> 00:35:58,320
and we can talk much more about this as

877
00:35:58,320 --> 00:36:00,560
we go through the presentation

878
00:36:00,560 --> 00:36:03,280
my own personal view and i will end with

879
00:36:03,280 --> 00:36:03,680
this

880
00:36:03,680 --> 00:36:06,640
is that fixating on the amount of human

881
00:36:06,640 --> 00:36:08,240
control that is required in the

882
00:36:08,240 --> 00:36:08,960
employment of

883
00:36:08,960 --> 00:36:11,119
autonomous weapons including autonomous

884
00:36:11,119 --> 00:36:12,079
cyber

885
00:36:12,079 --> 00:36:14,079
capabilities is really the wrong

886
00:36:14,079 --> 00:36:16,560
question with respect to autonomy

887
00:36:16,560 --> 00:36:18,079
the question we should be asking

888
00:36:18,079 --> 00:36:20,079
ourselves or be focused on

889
00:36:20,079 --> 00:36:23,200
is whether or not the system

890
00:36:23,200 --> 00:36:25,599
wherever the human control is or is not

891
00:36:25,599 --> 00:36:26,640
can comply

892
00:36:26,640 --> 00:36:28,480
with the principles of the law of armed

893
00:36:28,480 --> 00:36:30,000
conflict and

894
00:36:30,000 --> 00:36:31,280
that to me seems to be the more

895
00:36:31,280 --> 00:36:32,720
important question and that should be

896
00:36:32,720 --> 00:36:34,000
the question that we should be focused

897
00:36:34,000 --> 00:36:35,040
on

898
00:36:35,040 --> 00:36:38,640
thanks ann back to you and

899
00:36:38,640 --> 00:36:41,359
thank you and as we saw then it's not

900
00:36:41,359 --> 00:36:42,480
about

901
00:36:42,480 --> 00:36:46,079
losing control or it's not about

902
00:36:46,079 --> 00:36:48,560
not having any human element in the

903
00:36:48,560 --> 00:36:49,680
whole process

904
00:36:49,680 --> 00:36:53,520
but it's rather about shifting notion of

905
00:36:53,520 --> 00:36:54,000
control

906
00:36:54,000 --> 00:36:56,000
that we are not so much focusing on the

907
00:36:56,000 --> 00:36:57,440
very

908
00:36:57,440 --> 00:37:00,960
limited exact moment of deployment but

909
00:37:00,960 --> 00:37:02,720
we are moving towards more abstract

910
00:37:02,720 --> 00:37:04,000
forms

911
00:37:04,000 --> 00:37:07,200
but since

912
00:37:07,200 --> 00:37:10,880
more abstract forms mean more complexity

913
00:37:10,880 --> 00:37:11,359
when

914
00:37:11,359 --> 00:37:14,720
interpreting subjective issues such as

915
00:37:14,720 --> 00:37:17,760
intent or knowledge then

916
00:37:17,760 --> 00:37:21,040
since your chapter in fact

917
00:37:21,040 --> 00:37:24,480
i explored these issues then uh

918
00:37:24,480 --> 00:37:28,240
russell perhaps i would ask you

919
00:37:28,240 --> 00:37:32,079
what are your views of um

920
00:37:32,079 --> 00:37:36,320
after what are your views of

921
00:37:37,280 --> 00:37:39,760
the law as it currently stands does it

922
00:37:39,760 --> 00:37:40,560
in fact

923
00:37:40,560 --> 00:37:43,760
provide any interpretative means of

924
00:37:43,760 --> 00:37:47,640
overcoming the perceived

925
00:37:47,640 --> 00:37:50,800
responsibility gap when it comes to

926
00:37:50,800 --> 00:37:54,079
subjective elements in a context where

927
00:37:54,079 --> 00:37:57,040
control is abstract

928
00:37:57,040 --> 00:37:59,359
well thank you very much and for that

929
00:37:59,359 --> 00:38:00,880
question and thank you to yourself from

930
00:38:00,880 --> 00:38:03,119
the center and ryan for

931
00:38:03,119 --> 00:38:04,720
beginning this important project and

932
00:38:04,720 --> 00:38:06,560
bringing it to such a successful uh

933
00:38:06,560 --> 00:38:07,520
conclusion

934
00:38:07,520 --> 00:38:09,520
the chapter that i authored for the book

935
00:38:09,520 --> 00:38:10,960
was co-authored with a colleague of mine

936
00:38:10,960 --> 00:38:12,640
professor nicholas sigorius and we

937
00:38:12,640 --> 00:38:13,680
looked to

938
00:38:13,680 --> 00:38:15,520
the doctrine of command responsibility

939
00:38:15,520 --> 00:38:16,800
and whether this doctrine can be

940
00:38:16,800 --> 00:38:17,520
leveraged

941
00:38:17,520 --> 00:38:20,480
in order to provide accountability where

942
00:38:20,480 --> 00:38:22,400
autonomous cyber weapons

943
00:38:22,400 --> 00:38:24,160
go forward and commit international

944
00:38:24,160 --> 00:38:26,400
crimes and perhaps more specifically

945
00:38:26,400 --> 00:38:28,800
war crimes so i'll restrict my comments

946
00:38:28,800 --> 00:38:30,800
and to the context of international

947
00:38:30,800 --> 00:38:31,520
criminal law

948
00:38:31,520 --> 00:38:33,200
now of course in the in context of

949
00:38:33,200 --> 00:38:34,800
international criminal law individuals

950
00:38:34,800 --> 00:38:35,920
commit crimes

951
00:38:35,920 --> 00:38:37,839
um uh where they do so with the

952
00:38:37,839 --> 00:38:39,920
requisite uh actors race and

953
00:38:39,920 --> 00:38:42,480
men's race and the actors raise theirs

954
00:38:42,480 --> 00:38:44,560
you know the guilty crimes so the war

955
00:38:44,560 --> 00:38:46,320
crime the targeting of civilians or

956
00:38:46,320 --> 00:38:47,599
civilian objects

957
00:38:47,599 --> 00:38:50,320
and the men's ray is um that that act

958
00:38:50,320 --> 00:38:51,680
has been committed with

959
00:38:51,680 --> 00:38:54,160
intent or knowledge under article 30 of

960
00:38:54,160 --> 00:38:55,599
the rome statute established in the

961
00:38:55,599 --> 00:38:56,720
international criminal court

962
00:38:56,720 --> 00:38:58,079
and the rome statute has really become

963
00:38:58,079 --> 00:39:01,119
the focus on our debates around

964
00:39:01,119 --> 00:39:02,880
international criminal law in in recent

965
00:39:02,880 --> 00:39:04,560
years um

966
00:39:04,560 --> 00:39:07,839
now it may be the case that

967
00:39:07,839 --> 00:39:09,839
an individual that deploys an autonomous

968
00:39:09,839 --> 00:39:11,440
cyber weapon

969
00:39:11,440 --> 00:39:14,880
does so in a way that meets um

970
00:39:14,880 --> 00:39:16,720
the actress race and the menswear of a

971
00:39:16,720 --> 00:39:18,640
particular crime for example a war crime

972
00:39:18,640 --> 00:39:21,200
um so that autonomous cyber weapon and

973
00:39:21,200 --> 00:39:22,720
can be deployed into an environment in

974
00:39:22,720 --> 00:39:23,760
which the

975
00:39:23,760 --> 00:39:26,960
the operator is aware knows it's

976
00:39:26,960 --> 00:39:28,240
reasonably likely

977
00:39:28,240 --> 00:39:32,480
um that that particular weapon

978
00:39:32,480 --> 00:39:35,520
may misidentify a

979
00:39:35,520 --> 00:39:37,839
civilian object as a military object and

980
00:39:37,839 --> 00:39:38,640
engage

981
00:39:38,640 --> 00:39:41,920
and target it now if that's the case

982
00:39:41,920 --> 00:39:42,640
then

983
00:39:42,640 --> 00:39:44,720
as i say the the the actress race the

984
00:39:44,720 --> 00:39:46,320
men's ray of the particular crime the

985
00:39:46,320 --> 00:39:46,960
war crime

986
00:39:46,960 --> 00:39:48,960
will be present and the operator could

987
00:39:48,960 --> 00:39:50,640
be held responsible

988
00:39:50,640 --> 00:39:53,119
um as a perpetrator of an international

989
00:39:53,119 --> 00:39:55,359
crime

990
00:39:55,359 --> 00:39:57,680
the problem however is as you move along

991
00:39:57,680 --> 00:39:59,599
the continuum of autonomy

992
00:39:59,599 --> 00:40:03,040
um and as autonomous weapons become

993
00:40:03,040 --> 00:40:04,880
or start to be deployed into very

994
00:40:04,880 --> 00:40:07,680
complex and dynamic and um

995
00:40:07,680 --> 00:40:10,240
changing environments it's often quite

996
00:40:10,240 --> 00:40:11,119
difficult to say

997
00:40:11,119 --> 00:40:12,960
that the the actors rares and the men's

998
00:40:12,960 --> 00:40:15,680
rare for example a war crime has been

999
00:40:15,680 --> 00:40:18,000
committed i mean how can it be said that

1000
00:40:18,000 --> 00:40:18,720
um

1001
00:40:18,720 --> 00:40:20,480
the operator that deployed a truly

1002
00:40:20,480 --> 00:40:22,160
autonomous cyber weapon

1003
00:40:22,160 --> 00:40:24,560
into um you know this unstable and

1004
00:40:24,560 --> 00:40:25,920
ever-changing environment

1005
00:40:25,920 --> 00:40:28,079
and did so with in intent or knowledge i

1006
00:40:28,079 --> 00:40:29,599
think that's that that's very difficult

1007
00:40:29,599 --> 00:40:30,079
to

1008
00:40:30,079 --> 00:40:32,560
establish so what we try to do in in our

1009
00:40:32,560 --> 00:40:33,359
chapter

1010
00:40:33,359 --> 00:40:36,319
is to think um a bit more broadly and

1011
00:40:36,319 --> 00:40:38,240
think a bit more constructively about

1012
00:40:38,240 --> 00:40:38,880
whether there

1013
00:40:38,880 --> 00:40:41,200
are other rules of international law in

1014
00:40:41,200 --> 00:40:41,920
particular

1015
00:40:41,920 --> 00:40:43,680
international criminal law that can be

1016
00:40:43,680 --> 00:40:45,119
used to provide

1017
00:40:45,119 --> 00:40:47,280
accountability um and impose

1018
00:40:47,280 --> 00:40:48,480
responsibility

1019
00:40:48,480 --> 00:40:51,119
um where autonomous cyber weapons do

1020
00:40:51,119 --> 00:40:52,400
commit um in

1021
00:40:52,400 --> 00:40:55,040
international crimes as i say we look to

1022
00:40:55,040 --> 00:40:56,560
uh the doctrine here of command

1023
00:40:56,560 --> 00:40:57,839
responsibility which is very well

1024
00:40:57,839 --> 00:40:58,560
established

1025
00:40:58,560 --> 00:41:01,599
in uh military doctrine in humanitarian

1026
00:41:01,599 --> 00:41:03,200
law but as i say also uh

1027
00:41:03,200 --> 00:41:05,680
in international criminal and article 28

1028
00:41:05,680 --> 00:41:07,359
of the rome statute has become the

1029
00:41:07,359 --> 00:41:09,280
the focus there so i won't go through

1030
00:41:09,280 --> 00:41:10,560
the different criteria that

1031
00:41:10,560 --> 00:41:12,800
are needed but um you know there are a

1032
00:41:12,800 --> 00:41:14,560
number of recognized

1033
00:41:14,560 --> 00:41:17,520
um tenets of the doctrine of command

1034
00:41:17,520 --> 00:41:18,480
responsibility

1035
00:41:18,480 --> 00:41:21,040
and in our chapter we look through those

1036
00:41:21,040 --> 00:41:21,680
different

1037
00:41:21,680 --> 00:41:23,680
tenets and see whether or not they can

1038
00:41:23,680 --> 00:41:25,040
be established in

1039
00:41:25,040 --> 00:41:27,359
uh the context of um autonomous cyber

1040
00:41:27,359 --> 00:41:28,960
weapons when those cyber weapons go on

1041
00:41:28,960 --> 00:41:29,760
to commit

1042
00:41:29,760 --> 00:41:32,240
for example war crimes in essence you

1043
00:41:32,240 --> 00:41:34,000
know we say that um

1044
00:41:34,000 --> 00:41:36,000
command responsibility can be uh

1045
00:41:36,000 --> 00:41:37,280
utilized um

1046
00:41:37,280 --> 00:41:39,440
in in the context of autonomous and

1047
00:41:39,440 --> 00:41:41,040
cyber uh weapons

1048
00:41:41,040 --> 00:41:42,560
that these particular features and

1049
00:41:42,560 --> 00:41:44,720
conditions of command responsibility

1050
00:41:44,720 --> 00:41:47,760
can be met um although the caveat there

1051
00:41:47,760 --> 00:41:48,400
is

1052
00:41:48,400 --> 00:41:50,640
as autonomous cyber weapons move along

1053
00:41:50,640 --> 00:41:52,319
that autonomy continuum

1054
00:41:52,319 --> 00:41:54,240
for example where they're embedded with

1055
00:41:54,240 --> 00:41:55,760
artificial intelligence

1056
00:41:55,760 --> 00:41:59,440
and they can truly be saying to mimic um

1057
00:41:59,440 --> 00:42:02,960
human intelligence then perhaps the

1058
00:42:02,960 --> 00:42:04,800
the doctrine of command responsibility

1059
00:42:04,800 --> 00:42:06,319
becomes more difficult

1060
00:42:06,319 --> 00:42:10,079
to to apply so yes i think i'll leave it

1061
00:42:10,079 --> 00:42:14,079
there and pass back to you and thank you

1062
00:42:14,319 --> 00:42:18,240
and thank you and as we saw really that

1063
00:42:18,640 --> 00:42:21,359
the book one of the nicest feature there

1064
00:42:21,359 --> 00:42:22,560
is in fact that

1065
00:42:22,560 --> 00:42:26,240
it turned out to be strongly

1066
00:42:26,240 --> 00:42:29,200
solution focused in a way that majority

1067
00:42:29,200 --> 00:42:30,880
of the authors really suggested

1068
00:42:30,880 --> 00:42:32,079
different ways of

1069
00:42:32,079 --> 00:42:35,760
overcoming the perceived

1070
00:42:35,760 --> 00:42:39,440
responsibility gap for instance or or

1071
00:42:39,440 --> 00:42:42,000
the perceived lack of administrative

1072
00:42:42,000 --> 00:42:44,160
oversight and control or parliamentary

1073
00:42:44,160 --> 00:42:46,240
control and accountability

1074
00:42:46,240 --> 00:42:50,400
and one of the other authors

1075
00:42:50,400 --> 00:42:53,119
writing about issues surrounding

1076
00:42:53,119 --> 00:42:54,640
international criminal law also

1077
00:42:54,640 --> 00:42:57,440
suggested that perhaps when a

1078
00:42:57,440 --> 00:43:00,960
system is being systematically misused

1079
00:43:00,960 --> 00:43:01,920
by a state

1080
00:43:01,920 --> 00:43:04,960
then we shouldn't focus so much on

1081
00:43:04,960 --> 00:43:08,640
criminal law that uh involves a

1082
00:43:08,640 --> 00:43:10,640
heavy subjective element but we should

1083
00:43:10,640 --> 00:43:12,000
in fact go and play

1084
00:43:12,000 --> 00:43:15,280
plain and simple apply

1085
00:43:15,680 --> 00:43:18,319
the law of state responsibility which is

1086
00:43:18,319 --> 00:43:20,400
less problematic when it comes to

1087
00:43:20,400 --> 00:43:24,560
automatic autonomous systems as such but

1088
00:43:24,560 --> 00:43:27,599
coming back or or

1089
00:43:27,599 --> 00:43:31,520
rather not moving further from

1090
00:43:31,520 --> 00:43:34,960
the concept of control then

1091
00:43:34,960 --> 00:43:38,000
um as mentioned there are many venues

1092
00:43:38,000 --> 00:43:40,400
and alternatives to in fact gaining or

1093
00:43:40,400 --> 00:43:42,800
holding some kind of control and

1094
00:43:42,800 --> 00:43:44,480
some of them might be in prior

1095
00:43:44,480 --> 00:43:46,960
intelligence before

1096
00:43:46,960 --> 00:43:50,160
selecting or engaging target there has

1097
00:43:50,160 --> 00:43:52,560
to be a certain amount of information

1098
00:43:52,560 --> 00:43:54,240
gathered in a very diligent manner

1099
00:43:54,240 --> 00:43:55,119
before

1100
00:43:55,119 --> 00:43:59,119
and also integrated technical

1101
00:43:59,119 --> 00:44:02,319
constraints for instance geographical or

1102
00:44:02,319 --> 00:44:03,920
temporal or

1103
00:44:03,920 --> 00:44:07,440
kill switch and

1104
00:44:07,599 --> 00:44:11,440
also uh instruments uh um

1105
00:44:11,440 --> 00:44:14,400
akin to uh those applied to intelligence

1106
00:44:14,400 --> 00:44:14,880
like

1107
00:44:14,880 --> 00:44:17,920
intelligence oversight committees uh and

1108
00:44:17,920 --> 00:44:18,400
uh

1109
00:44:18,400 --> 00:44:22,560
um and also to borrow from um

1110
00:44:22,560 --> 00:44:25,839
to borrow from state practices of how

1111
00:44:25,839 --> 00:44:30,000
uh how use of force is being approved

1112
00:44:30,000 --> 00:44:33,119
then what

1113
00:44:33,119 --> 00:44:35,680
this goes to all of the panelists right

1114
00:44:35,680 --> 00:44:36,480
now

1115
00:44:36,480 --> 00:44:40,319
then what of these and

1116
00:44:40,319 --> 00:44:43,839
all the other measures of

1117
00:44:43,839 --> 00:44:46,960
gaining or exercising control sound

1118
00:44:46,960 --> 00:44:49,599
the most feasible to your ear and what

1119
00:44:49,599 --> 00:44:50,240
are the

1120
00:44:50,240 --> 00:44:52,880
advantages and disadvantages of all of

1121
00:44:52,880 --> 00:44:53,920
them so just

1122
00:44:53,920 --> 00:44:56,079
but of course there was no exhaustive

1123
00:44:56,079 --> 00:44:58,000
list presented right now so you are free

1124
00:44:58,000 --> 00:44:58,880
to think

1125
00:44:58,880 --> 00:45:02,319
and so ryan maybe

1126
00:45:02,319 --> 00:45:05,839
any thoughts on this matter

1127
00:45:05,920 --> 00:45:08,800
sure perhaps one of the most important

1128
00:45:08,800 --> 00:45:10,800
starting points is that

1129
00:45:10,800 --> 00:45:13,839
um autonomy doesn't mean

1130
00:45:13,839 --> 00:45:17,119
a lack of control i think this myth is

1131
00:45:17,119 --> 00:45:18,960
based on the understanding

1132
00:45:18,960 --> 00:45:22,079
of control as the ability to directly

1133
00:45:22,079 --> 00:45:23,680
manipulate with the system

1134
00:45:23,680 --> 00:45:26,560
in real time however there are various

1135
00:45:26,560 --> 00:45:28,000
other ways in which

1136
00:45:28,000 --> 00:45:30,960
one can influence the effects that a

1137
00:45:30,960 --> 00:45:32,240
particular capability

1138
00:45:32,240 --> 00:45:35,040
achieves whether that capability be a

1139
00:45:35,040 --> 00:45:36,880
cyber capability

1140
00:45:36,880 --> 00:45:40,720
or a kinetic capability

1141
00:45:40,720 --> 00:45:43,599
so something that the australian

1142
00:45:43,599 --> 00:45:44,839
government has

1143
00:45:44,839 --> 00:45:48,079
um highlighted in the context of the

1144
00:45:48,079 --> 00:45:50,319
autonomous weapon systems debate

1145
00:45:50,319 --> 00:45:52,640
and that is perhaps relevant here as

1146
00:45:52,640 --> 00:45:53,440
well

1147
00:45:53,440 --> 00:45:57,200
is the idea of a system of control

1148
00:45:57,200 --> 00:46:00,400
which is that throughout the life cycle

1149
00:46:00,400 --> 00:46:02,160
of a particular capability

1150
00:46:02,160 --> 00:46:05,440
there are various touch points at which

1151
00:46:05,440 --> 00:46:08,079
human beings can influence the way in

1152
00:46:08,079 --> 00:46:10,400
which that particular capability

1153
00:46:10,400 --> 00:46:13,680
operates and the effects that it has

1154
00:46:13,680 --> 00:46:16,280
when deployed this starts from the

1155
00:46:16,280 --> 00:46:17,440
conceptualization

1156
00:46:17,440 --> 00:46:20,640
to the design to the programming to the

1157
00:46:20,640 --> 00:46:21,760
testing

1158
00:46:21,760 --> 00:46:24,960
to the deployment to the review

1159
00:46:24,960 --> 00:46:26,960
the after action review to

1160
00:46:26,960 --> 00:46:28,960
accountability measures and so and so

1161
00:46:28,960 --> 00:46:29,680
forth

1162
00:46:29,680 --> 00:46:31,839
so particularly with autonomous

1163
00:46:31,839 --> 00:46:33,760
capabilities again whether cyber or

1164
00:46:33,760 --> 00:46:34,800
kinetic

1165
00:46:34,800 --> 00:46:37,200
there is an increased need to look at

1166
00:46:37,200 --> 00:46:39,920
this whole range of control measures

1167
00:46:39,920 --> 00:46:43,359
that can be taken that influence the uh

1168
00:46:43,359 --> 00:46:46,640
the outcome of a particular operation

1169
00:46:46,640 --> 00:46:48,720
and the result of this perhaps is that

1170
00:46:48,720 --> 00:46:50,000
even though the

1171
00:46:50,000 --> 00:46:52,160
operator of the system still has a very

1172
00:46:52,160 --> 00:46:54,720
particular responsibility under the law

1173
00:46:54,720 --> 00:46:56,800
as the law prescribes specific

1174
00:46:56,800 --> 00:46:58,880
responsibilities for those who

1175
00:46:58,880 --> 00:47:02,560
uh decide upon uh and plan attacks

1176
00:47:02,560 --> 00:47:05,040
um there are various other people who

1177
00:47:05,040 --> 00:47:05,680
can have an

1178
00:47:05,680 --> 00:47:08,079
impact on whether the the system

1179
00:47:08,079 --> 00:47:10,079
complies with the law whether it's

1180
00:47:10,079 --> 00:47:13,440
use uh complies with the law

1181
00:47:13,440 --> 00:47:16,720
and from that perspective perhaps um

1182
00:47:16,720 --> 00:47:18,960
testing and evaluation of the system

1183
00:47:18,960 --> 00:47:20,640
becomes particularly

1184
00:47:20,640 --> 00:47:23,760
critical uh and i think from that

1185
00:47:23,760 --> 00:47:25,680
perspective the contribution that

1186
00:47:25,680 --> 00:47:28,880
uh alec tatusol and damian copeland have

1187
00:47:28,880 --> 00:47:30,079
made to the book

1188
00:47:30,079 --> 00:47:33,520
on applying um weapons review processes

1189
00:47:33,520 --> 00:47:35,280
to cyber capabilities

1190
00:47:35,280 --> 00:47:38,079
and autonomous cyber capabilities is

1191
00:47:38,079 --> 00:47:40,000
particularly significant

1192
00:47:40,000 --> 00:47:43,680
there are already challenges involved in

1193
00:47:43,680 --> 00:47:47,440
legally reviewing cyber capabilities

1194
00:47:47,440 --> 00:47:51,040
and autonomy ads sort of an

1195
00:47:51,040 --> 00:47:54,240
an additional uh level of complexity

1196
00:47:54,240 --> 00:47:57,760
to that but perhaps to to sum up

1197
00:47:57,760 --> 00:47:59,280
i think it's important to note that

1198
00:47:59,280 --> 00:48:01,839
there is no specific type of control

1199
00:48:01,839 --> 00:48:04,240
that the law would require

1200
00:48:04,240 --> 00:48:06,640
i would argue that what the law requires

1201
00:48:06,640 --> 00:48:07,440
is that

1202
00:48:07,440 --> 00:48:10,559
such human control be exercised as may

1203
00:48:10,559 --> 00:48:12,640
be necessary to achieve compliance with

1204
00:48:12,640 --> 00:48:13,599
the law

1205
00:48:13,599 --> 00:48:16,559
in some circumstances that control is

1206
00:48:16,559 --> 00:48:18,880
more likely to be

1207
00:48:18,880 --> 00:48:21,520
exercised by the operator of the system

1208
00:48:21,520 --> 00:48:23,440
in other circumstances that control is

1209
00:48:23,440 --> 00:48:25,520
more likely to be exercised by those

1210
00:48:25,520 --> 00:48:29,119
who design and test the system

1211
00:48:31,359 --> 00:48:33,599
thank you and uh coming back to the

1212
00:48:33,599 --> 00:48:35,599
issue of weapons reviews

1213
00:48:35,599 --> 00:48:38,160
and when should they take place should

1214
00:48:38,160 --> 00:48:40,720
they be continuous or one-off procedures

1215
00:48:40,720 --> 00:48:41,520
for instance

1216
00:48:41,520 --> 00:48:44,079
and should they uh involve also after

1217
00:48:44,079 --> 00:48:45,359
action reviews

1218
00:48:45,359 --> 00:48:48,800
and when is in fact when

1219
00:48:48,800 --> 00:48:52,000
does the moment of uh

1220
00:48:52,000 --> 00:48:56,240
deploying a cyber capability happen then

1221
00:48:56,240 --> 00:48:58,319
because of these particularities then

1222
00:48:58,319 --> 00:49:00,480
weapons reviews really are

1223
00:49:00,480 --> 00:49:04,480
on one hand the key to balancing the

1224
00:49:04,480 --> 00:49:09,440
slightly unconventionally abstract

1225
00:49:09,440 --> 00:49:11,520
notion of control and but on the other

1226
00:49:11,520 --> 00:49:13,440
end it's

1227
00:49:13,440 --> 00:49:16,000
extremely complicated and i also recall

1228
00:49:16,000 --> 00:49:18,240
that

1229
00:49:19,119 --> 00:49:23,359
i also recall that thomas in your

1230
00:49:23,359 --> 00:49:25,599
chapter weapons reviews were mentioned

1231
00:49:25,599 --> 00:49:27,520
and briefly

1232
00:49:27,520 --> 00:49:30,400
analyzed and also in eric's chapter and

1233
00:49:30,400 --> 00:49:31,920
do you have

1234
00:49:31,920 --> 00:49:33,760
any viewpoints that you would like to

1235
00:49:33,760 --> 00:49:36,640
share as to the

1236
00:49:36,640 --> 00:49:41,440
as to the complications that one might

1237
00:49:41,440 --> 00:49:44,880
face when trying to work out foolproof

1238
00:49:44,880 --> 00:49:45,839
procedure

1239
00:49:45,839 --> 00:49:48,720
of reviewing capabilities such as

1240
00:49:48,720 --> 00:49:49,599
autonomous

1241
00:49:49,599 --> 00:49:54,240
cyber capabilities so first

1242
00:49:54,240 --> 00:49:59,440
eric are you them i am and uh and i

1243
00:49:59,440 --> 00:49:59,760
think

1244
00:49:59,760 --> 00:50:02,079
uh what ryan said was really important

1245
00:50:02,079 --> 00:50:04,319
about this exercise of control

1246
00:50:04,319 --> 00:50:06,720
the uk has made a great statement about

1247
00:50:06,720 --> 00:50:08,000
control needs to be

1248
00:50:08,000 --> 00:50:10,319
thought about over the life cycle of the

1249
00:50:10,319 --> 00:50:11,200
system

1250
00:50:11,200 --> 00:50:13,440
not at one particular moment in the

1251
00:50:13,440 --> 00:50:15,200
system's execution

1252
00:50:15,200 --> 00:50:17,839
and you might you might think of this as

1253
00:50:17,839 --> 00:50:19,280
contrasting

1254
00:50:19,280 --> 00:50:23,200
control in selecting and engaging

1255
00:50:23,200 --> 00:50:25,599
targets as opposed to control on the

1256
00:50:25,599 --> 00:50:28,240
selection and engagement of targets

1257
00:50:28,240 --> 00:50:30,880
and uh ryan's point that the real goal

1258
00:50:30,880 --> 00:50:31,680
is to get

1259
00:50:31,680 --> 00:50:34,480
to compliance with the low act that's

1260
00:50:34,480 --> 00:50:36,160
what the weapons review is designed to

1261
00:50:36,160 --> 00:50:38,319
do is to make sure that when the weapon

1262
00:50:38,319 --> 00:50:41,760
is used or when the weapon is uh takes

1263
00:50:41,760 --> 00:50:44,880
uh has an effect in combat that that

1264
00:50:44,880 --> 00:50:47,280
effect is in compliance with the law of

1265
00:50:47,280 --> 00:50:48,720
armed conflict

1266
00:50:48,720 --> 00:50:51,920
if we try and limit control to the

1267
00:50:51,920 --> 00:50:54,559
moment where selection and engaging

1268
00:50:54,559 --> 00:50:57,520
takes place we are really limiting the

1269
00:50:57,520 --> 00:50:59,839
value of the speed and the precision and

1270
00:50:59,839 --> 00:51:01,359
the things mentioned earlier

1271
00:51:01,359 --> 00:51:03,760
in this conference that come with

1272
00:51:03,760 --> 00:51:06,160
autonomous weapon systems

1273
00:51:06,160 --> 00:51:08,000
just one example one of the autonomous

1274
00:51:08,000 --> 00:51:09,760
weapon systems that currently

1275
00:51:09,760 --> 00:51:12,880
is uh being used is called the cram

1276
00:51:12,880 --> 00:51:16,000
and it's basically a land-based system

1277
00:51:16,000 --> 00:51:19,359
that is designed to engage in coming

1278
00:51:19,359 --> 00:51:21,119
artillery and destroy that artillery

1279
00:51:21,119 --> 00:51:22,079
shell before it lands

1280
00:51:22,079 --> 00:51:24,400
and does its damage the mathematical

1281
00:51:24,400 --> 00:51:25,520
calculations

1282
00:51:25,520 --> 00:51:29,040
and the the science required to

1283
00:51:29,040 --> 00:51:32,559
intercept the parabolic uh flight path

1284
00:51:32,559 --> 00:51:34,319
of that incoming missile could never be

1285
00:51:34,319 --> 00:51:36,000
done by a human in the time

1286
00:51:36,000 --> 00:51:38,800
that it would have to be done to happen

1287
00:51:38,800 --> 00:51:39,200
so

1288
00:51:39,200 --> 00:51:41,200
you have you couldn't even have the

1289
00:51:41,200 --> 00:51:43,680
machine do all the math and spit it out

1290
00:51:43,680 --> 00:51:47,119
to a human and say now you confirm that

1291
00:51:47,119 --> 00:51:49,520
so that then i can launch my anti-rocket

1292
00:51:49,520 --> 00:51:50,240
missile

1293
00:51:50,240 --> 00:51:52,400
that that just isn't the time to do that

1294
00:51:52,400 --> 00:51:54,400
rather that system because it's

1295
00:51:54,400 --> 00:51:57,040
autonomous and can engage that incoming

1296
00:51:57,040 --> 00:51:57,680
missile

1297
00:51:57,680 --> 00:51:59,599
on its own do all the math on its own

1298
00:51:59,599 --> 00:52:00,880
and and

1299
00:52:00,880 --> 00:52:03,359
and then launch its anti-rocket it's

1300
00:52:03,359 --> 00:52:04,400
anti-missile rocket

1301
00:52:04,400 --> 00:52:06,480
is what makes that weapon system

1302
00:52:06,480 --> 00:52:08,720
effective the control to make that

1303
00:52:08,720 --> 00:52:10,400
weapon system comply with the low act

1304
00:52:10,400 --> 00:52:11,839
happens long before

1305
00:52:11,839 --> 00:52:14,160
the actual selection and engagement and

1306
00:52:14,160 --> 00:52:15,760
that's what the weapons review

1307
00:52:15,760 --> 00:52:17,760
should consider in the end when the

1308
00:52:17,760 --> 00:52:19,599
effect happens has there been sufficient

1309
00:52:19,599 --> 00:52:21,040
input to make sure that that weapon

1310
00:52:21,040 --> 00:52:22,880
system can't comply with the load

1311
00:52:22,880 --> 00:52:26,720
when it actually selects and engages

1312
00:52:28,000 --> 00:52:31,200
but should we look forward to

1313
00:52:31,200 --> 00:52:34,400
some kind of universal

1314
00:52:34,400 --> 00:52:37,520
uniform guidelines to how

1315
00:52:37,520 --> 00:52:39,440
to conduct weapons reviews when it comes

1316
00:52:39,440 --> 00:52:41,280
to technologies like this because

1317
00:52:41,280 --> 00:52:44,960
the landscape of state practices

1318
00:52:44,960 --> 00:52:48,160
and state

1319
00:52:48,160 --> 00:52:51,280
and and different regulations is

1320
00:52:51,280 --> 00:52:54,480
a very secretive and b

1321
00:52:54,480 --> 00:52:57,040
very scattered so should this perhaps be

1322
00:52:57,040 --> 00:52:58,960
a field that

1323
00:52:58,960 --> 00:53:01,440
would benefit from more black and white

1324
00:53:01,440 --> 00:53:04,000
clarity

1325
00:53:05,680 --> 00:53:08,000
well i think that there are some

1326
00:53:08,000 --> 00:53:09,359
publications for example the us

1327
00:53:09,359 --> 00:53:10,640
department of defense has

1328
00:53:10,640 --> 00:53:12,480
published an example of what a weapons

1329
00:53:12,480 --> 00:53:14,160
review is

1330
00:53:14,160 --> 00:53:17,040
how they apply weapons review and what

1331
00:53:17,040 --> 00:53:18,400
things they consider

1332
00:53:18,400 --> 00:53:19,760
so i think that there could be more

1333
00:53:19,760 --> 00:53:21,680
clarity but the the basic

1334
00:53:21,680 --> 00:53:23,520
concept is that much must comply with

1335
00:53:23,520 --> 00:53:24,880
the low act the principles that we all

1336
00:53:24,880 --> 00:53:25,440
know

1337
00:53:25,440 --> 00:53:28,240
uh apply to the loac um that's that's

1338
00:53:28,240 --> 00:53:29,680
what i would say thomas i'm sure you

1339
00:53:29,680 --> 00:53:32,720
have some views on that as well

1340
00:53:38,319 --> 00:53:42,319
yes i do i'm just not sure what i'm on

1341
00:53:42,319 --> 00:53:46,079
yes sure okay good yes no i mean

1342
00:53:46,079 --> 00:53:49,040
look the i think we all agree that the

1343
00:53:49,040 --> 00:53:49,839
articles

1344
00:53:49,839 --> 00:53:53,760
article 36 weapons review is key here

1345
00:53:53,760 --> 00:53:55,520
and i'm not so particularly worried

1346
00:53:55,520 --> 00:53:56,880
about the weapons review yes it's

1347
00:53:56,880 --> 00:53:58,400
secretive we don't really know what the

1348
00:53:58,400 --> 00:53:59,520
states are doing

1349
00:53:59,520 --> 00:54:02,079
or most of the states are doing fully

1350
00:54:02,079 --> 00:54:02,800
clear

1351
00:54:02,800 --> 00:54:05,119
um but it's not you know in the weapons

1352
00:54:05,119 --> 00:54:06,000
review

1353
00:54:06,000 --> 00:54:07,680
in my understanding you know you look at

1354
00:54:07,680 --> 00:54:09,040
the weapon and you

1355
00:54:09,040 --> 00:54:10,960
look at what it can do and you look what

1356
00:54:10,960 --> 00:54:12,960
it needs to be doing in order to comply

1357
00:54:12,960 --> 00:54:13,440
with the

1358
00:54:13,440 --> 00:54:16,319
ihl and then you clear it and then you

1359
00:54:16,319 --> 00:54:17,440
can't just you know

1360
00:54:17,440 --> 00:54:19,760
let it evolve and do something else do a

1361
00:54:19,760 --> 00:54:21,040
little machine learning

1362
00:54:21,040 --> 00:54:22,720
no then you have to go back you know you

1363
00:54:22,720 --> 00:54:24,000
go back to the beginning and do a

1364
00:54:24,000 --> 00:54:25,359
definitional review

1365
00:54:25,359 --> 00:54:27,760
so i'm not so worried about that about

1366
00:54:27,760 --> 00:54:28,880
that

1367
00:54:28,880 --> 00:54:31,599
particular sort of point in time where

1368
00:54:31,599 --> 00:54:32,720
you release it

1369
00:54:32,720 --> 00:54:35,599
later on that's not so much my worry of

1370
00:54:35,599 --> 00:54:38,079
course i mean i read from from rain

1371
00:54:38,079 --> 00:54:40,559
and from from eric of course the uh you

1372
00:54:40,559 --> 00:54:41,359
know

1373
00:54:41,359 --> 00:54:44,799
the question is what does control mean

1374
00:54:44,799 --> 00:54:46,640
so that we can apply it in the weapons

1375
00:54:46,640 --> 00:54:48,559
review is it as

1376
00:54:48,559 --> 00:54:50,559
ryan seemed to suggest some sort of a

1377
00:54:50,559 --> 00:54:52,480
meta notion that kind of

1378
00:54:52,480 --> 00:54:55,920
extends into all aspects of the weapon

1379
00:54:55,920 --> 00:54:58,559
and with the risk that ultimately it

1380
00:54:58,559 --> 00:54:59,200
just means

1381
00:54:59,200 --> 00:55:02,160
please comply with ihl which is not very

1382
00:55:02,160 --> 00:55:02,559
much

1383
00:55:02,559 --> 00:55:04,559
i mean a huge expectation but you know

1384
00:55:04,559 --> 00:55:06,000
we were looking for

1385
00:55:06,000 --> 00:55:07,599
the the answer to the question what does

1386
00:55:07,599 --> 00:55:09,680
that mean when we brought up the notion

1387
00:55:09,680 --> 00:55:11,760
of meaningful human control

1388
00:55:11,760 --> 00:55:14,880
um you know although can you narrow it

1389
00:55:14,880 --> 00:55:16,480
down sort of you know in a sense of a

1390
00:55:16,480 --> 00:55:18,480
controller you know a joystick we know

1391
00:55:18,480 --> 00:55:20,000
that controls something

1392
00:55:20,000 --> 00:55:22,720
and that's it you know it doesn't extend

1393
00:55:22,720 --> 00:55:24,000
to the question

1394
00:55:24,000 --> 00:55:25,599
when you for instance have a machine

1395
00:55:25,599 --> 00:55:27,680
learning system and these systems are

1396
00:55:27,680 --> 00:55:29,440
kind of hard to explain

1397
00:55:29,440 --> 00:55:32,079
um it doesn't for instance mean that you

1398
00:55:32,079 --> 00:55:34,480
only have control over the system

1399
00:55:34,480 --> 00:55:37,599
when you can actually say you know i can

1400
00:55:37,599 --> 00:55:38,799
explain it

1401
00:55:38,799 --> 00:55:41,599
it's explainable it's interpretable does

1402
00:55:41,599 --> 00:55:42,240
that

1403
00:55:42,240 --> 00:55:44,960
notion of interpretive interpretability

1404
00:55:44,960 --> 00:55:46,160
actually figure

1405
00:55:46,160 --> 00:55:48,640
in the notion of control and that's not

1406
00:55:48,640 --> 00:55:50,079
you know in a sense not an academic

1407
00:55:50,079 --> 00:55:51,440
example you know when you have a

1408
00:55:51,440 --> 00:55:54,400
defensive weapon system that learns to

1409
00:55:54,400 --> 00:55:55,760
shoot down

1410
00:55:55,760 --> 00:55:58,960
like incoming missiles whatever

1411
00:55:58,960 --> 00:56:02,000
and you know it's so good as eric

1412
00:56:02,000 --> 00:56:04,079
suggested that you can't really control

1413
00:56:04,079 --> 00:56:07,599
it manually so to speak in real time

1414
00:56:07,599 --> 00:56:09,760
it's so good that it just shoots down

1415
00:56:09,760 --> 00:56:11,280
the right things but you don't really

1416
00:56:11,280 --> 00:56:13,119
know why and you can't really explain

1417
00:56:13,119 --> 00:56:14,000
why

1418
00:56:14,000 --> 00:56:16,799
and you can't really interpret it and is

1419
00:56:16,799 --> 00:56:18,559
that still human control

1420
00:56:18,559 --> 00:56:20,559
can you just say well you know we don't

1421
00:56:20,559 --> 00:56:22,000
really know what it's doing

1422
00:56:22,000 --> 00:56:25,040
but it has proven pretty effective 90.9

1423
00:56:25,040 --> 00:56:26,160
percent of the time

1424
00:56:26,160 --> 00:56:29,440
maybe 9.9.9

1425
00:56:29,440 --> 00:56:31,440
is that enough is that enough for us to

1426
00:56:31,440 --> 00:56:33,760
control that system

1427
00:56:33,760 --> 00:56:34,960
these are the notions we have to

1428
00:56:34,960 --> 00:56:36,799
confront them these notions in a sense

1429
00:56:36,799 --> 00:56:40,240
also arise in cyberspace of course um

1430
00:56:40,240 --> 00:56:42,000
they're in some regards they're less

1431
00:56:42,000 --> 00:56:43,920
complicated than other regards they're

1432
00:56:43,920 --> 00:56:45,680
more complicated

1433
00:56:45,680 --> 00:56:48,720
and that's about as much as i can say

1434
00:56:48,720 --> 00:56:51,279
for the moment

1435
00:56:51,680 --> 00:56:55,599
and eric maybe something as a response

1436
00:56:55,599 --> 00:56:58,640
to a slightly different view here or

1437
00:56:58,640 --> 00:56:59,359
only

1438
00:56:59,359 --> 00:57:02,400
marginally different

1439
00:57:03,520 --> 00:57:06,400
um so i i i don't think there's anything

1440
00:57:06,400 --> 00:57:07,760
in what thomas said that i would

1441
00:57:07,760 --> 00:57:09,119
disagree with

1442
00:57:09,119 --> 00:57:12,319
except maybe the fundamental

1443
00:57:12,319 --> 00:57:15,200
requirement of human control we might

1444
00:57:15,200 --> 00:57:16,640
differ a little bit on how we think that

1445
00:57:16,640 --> 00:57:17,920
human control

1446
00:57:17,920 --> 00:57:20,240
first of all it's the legality of the

1447
00:57:20,240 --> 00:57:21,839
need for human control and then

1448
00:57:21,839 --> 00:57:24,000
how it might fit into that system but i

1449
00:57:24,000 --> 00:57:26,079
agree with him that

1450
00:57:26,079 --> 00:57:28,720
the weapons review is not really

1451
00:57:28,720 --> 00:57:30,960
problematic in the sense that we can

1452
00:57:30,960 --> 00:57:34,240
we can analyze the application of the

1453
00:57:34,240 --> 00:57:35,599
weapon system and figure out

1454
00:57:35,599 --> 00:57:38,160
how it performs thomas does raise a

1455
00:57:38,160 --> 00:57:39,599
really great question which hopefully

1456
00:57:39,599 --> 00:57:41,359
we'll come to at some point which is

1457
00:57:41,359 --> 00:57:45,040
what level of effect or what level of

1458
00:57:45,040 --> 00:57:46,000
success

1459
00:57:46,000 --> 00:57:48,960
in applying that the principles of the

1460
00:57:48,960 --> 00:57:50,480
loac are required of an autonomous

1461
00:57:50,480 --> 00:57:53,599
system versus a human for example

1462
00:57:53,599 --> 00:57:56,960
and um thank you and

1463
00:57:56,960 --> 00:58:00,079
also in uh one of the chapters authored

1464
00:58:00,079 --> 00:58:02,160
by professor peter margulis

1465
00:58:02,160 --> 00:58:05,920
it was brought out that the prior

1466
00:58:05,920 --> 00:58:06,880
intelligence

1467
00:58:06,880 --> 00:58:10,319
might be one way of

1468
00:58:10,319 --> 00:58:13,359
mitigating the risks then i'm looking to

1469
00:58:13,359 --> 00:58:15,119
you russell right now since

1470
00:58:15,119 --> 00:58:18,160
you have devoted

1471
00:58:18,160 --> 00:58:21,359
a large share of your

1472
00:58:21,359 --> 00:58:24,400
academic work so far to cyber espionage

1473
00:58:24,400 --> 00:58:28,720
then would you agree that in some cases

1474
00:58:28,720 --> 00:58:31,839
the necessity to

1475
00:58:31,839 --> 00:58:34,720
have control over an autonomous system

1476
00:58:34,720 --> 00:58:37,040
in fact raises

1477
00:58:37,040 --> 00:58:39,680
espionage from the status of a necessary

1478
00:58:39,680 --> 00:58:40,720
evil to this

1479
00:58:40,720 --> 00:58:44,000
of a necessary precondition

1480
00:58:44,000 --> 00:58:48,720
of proportionality for instance

1481
00:58:48,720 --> 00:58:50,240
yes i mean very good very good question

1482
00:58:50,240 --> 00:58:51,520
and i mean certainly when you move

1483
00:58:51,520 --> 00:58:53,359
towards the the law of armed conflict

1484
00:58:53,359 --> 00:58:54,319
you know different

1485
00:58:54,319 --> 00:58:56,400
very different rules apply in my opinion

1486
00:58:56,400 --> 00:58:57,839
um than they were during uh

1487
00:58:57,839 --> 00:58:59,920
peace time i largely see there being

1488
00:58:59,920 --> 00:59:01,839
quite a number of prohibitive rules

1489
00:59:01,839 --> 00:59:04,160
applicable to cyber espionage and

1490
00:59:04,160 --> 00:59:05,200
autonomous

1491
00:59:05,200 --> 00:59:08,000
cyber espionage um under the peacetime

1492
00:59:08,000 --> 00:59:08,400
law

1493
00:59:08,400 --> 00:59:10,079
whereas as you move to the law of armed

1494
00:59:10,079 --> 00:59:12,559
conflict as i say a different regime

1495
00:59:12,559 --> 00:59:13,920
obviously applies and

1496
00:59:13,920 --> 00:59:16,160
you know there's no doubt about it that

1497
00:59:16,160 --> 00:59:16,960
partisan

1498
00:59:16,960 --> 00:59:19,680
conflicts can gather intelligence on

1499
00:59:19,680 --> 00:59:20,799
their enemies

1500
00:59:20,799 --> 00:59:21,920
and as i said that's very well

1501
00:59:21,920 --> 00:59:23,680
established going back at least as far

1502
00:59:23,680 --> 00:59:24,240
as

1503
00:59:24,240 --> 00:59:25,920
um the libra code but through the

1504
00:59:25,920 --> 00:59:27,280
brussels declaration and the hague

1505
00:59:27,280 --> 00:59:28,480
regulations

1506
00:59:28,480 --> 00:59:31,920
and um if states look to use autonomous

1507
00:59:31,920 --> 00:59:33,520
cyber capabilities to

1508
00:59:33,520 --> 00:59:35,599
augment their intelligence collection

1509
00:59:35,599 --> 00:59:36,559
efforts then

1510
00:59:36,559 --> 00:59:39,280
i don't see um you know that that

1511
00:59:39,280 --> 00:59:40,960
addition of autonomy there

1512
00:59:40,960 --> 00:59:44,160
being creating any you know brand new

1513
00:59:44,160 --> 00:59:47,280
uh legal uh questions of course

1514
00:59:47,280 --> 00:59:49,920
um when intelligence collection is

1515
00:59:49,920 --> 00:59:50,799
conducted

1516
00:59:50,799 --> 00:59:53,200
um autonomously or through autonomous

1517
00:59:53,200 --> 00:59:54,000
systems

1518
00:59:54,000 --> 00:59:56,160
um you know perhaps there are additional

1519
00:59:56,160 --> 00:59:57,040
risks there

1520
00:59:57,040 --> 00:59:58,480
and some of those risks could be for

1521
00:59:58,480 --> 01:00:01,040
example that um

1522
01:00:01,040 --> 01:00:02,640
you know the intelligence collection

1523
01:00:02,640 --> 01:00:04,319
hooves up huge amounts of

1524
01:00:04,319 --> 01:00:06,880
um information and suddenly the

1525
01:00:06,880 --> 01:00:08,160
information being collected isn't

1526
01:00:08,160 --> 01:00:09,760
necessarily on the enemy

1527
01:00:09,760 --> 01:00:11,839
but is perhaps against you know ordinary

1528
01:00:11,839 --> 01:00:12,880
civilians

1529
01:00:12,880 --> 01:00:14,960
um which you know in my view would be

1530
01:00:14,960 --> 01:00:16,160
that um

1531
01:00:16,160 --> 01:00:17,920
you know the concurrent application of

1532
01:00:17,920 --> 01:00:19,200
peacetime law with

1533
01:00:19,200 --> 01:00:21,440
uh on human rights law for example with

1534
01:00:21,440 --> 01:00:23,200
the robot conflict would apply there so

1535
01:00:23,200 --> 01:00:24,319
if the information

1536
01:00:24,319 --> 01:00:25,920
collected doesn't have a nexus to the

1537
01:00:25,920 --> 01:00:27,599
prosecution of the armed conflict then

1538
01:00:27,599 --> 01:00:29,200
then peacetime law would apply

1539
01:00:29,200 --> 01:00:30,799
but also of course you know it may be

1540
01:00:30,799 --> 01:00:32,880
that the autonomous system

1541
01:00:32,880 --> 01:00:35,839
collects information um that goes beyond

1542
01:00:35,839 --> 01:00:37,359
the cyber infrastructure

1543
01:00:37,359 --> 01:00:41,200
of the um of the adversary or the

1544
01:00:41,200 --> 01:00:42,079
opponent

1545
01:00:42,079 --> 01:00:44,240
um you know and strays onto the cyber

1546
01:00:44,240 --> 01:00:45,440
infrastructure of

1547
01:00:45,440 --> 01:00:47,520
third states or perhaps neutral states

1548
01:00:47,520 --> 01:00:49,680
um you know which raises a host of

1549
01:00:49,680 --> 01:00:51,599
difficult questions about the law of

1550
01:00:51,599 --> 01:00:52,720
neutrality and

1551
01:00:52,720 --> 01:00:55,280
um whether that neutral state becomes a

1552
01:00:55,280 --> 01:00:56,319
co-religion

1553
01:00:56,319 --> 01:00:58,480
and that's a party to the armed conflict

1554
01:00:58,480 --> 01:00:59,760
um so

1555
01:00:59,760 --> 01:01:01,440
yes i mean my position there would

1556
01:01:01,440 --> 01:01:02,880
probably be the same as it is on

1557
01:01:02,880 --> 01:01:05,119
you know most issues related to autonomy

1558
01:01:05,119 --> 01:01:05,920
i don't think

1559
01:01:05,920 --> 01:01:09,520
it creates any brand new legal issues

1560
01:01:09,520 --> 01:01:10,000
but it does

1561
01:01:10,000 --> 01:01:12,880
complexify and intensify some of the

1562
01:01:12,880 --> 01:01:14,240
existing problems that we

1563
01:01:14,240 --> 01:01:18,240
would otherwise would otherwise find

1564
01:01:18,240 --> 01:01:22,160
and thank you and you also mentioned

1565
01:01:22,160 --> 01:01:24,319
a particular feature of the cyber

1566
01:01:24,319 --> 01:01:25,839
environment is that it does not

1567
01:01:25,839 --> 01:01:27,119
recognize political

1568
01:01:27,119 --> 01:01:31,839
borders and uh propagates uh

1569
01:01:31,839 --> 01:01:34,240
in a speedy manner and that uh lowest

1570
01:01:34,240 --> 01:01:34,880
possible

1571
01:01:34,880 --> 01:01:38,000
cost for instance and it in a way

1572
01:01:38,000 --> 01:01:40,960
it's once out it's hard to call back

1573
01:01:40,960 --> 01:01:43,280
this is

1574
01:01:43,359 --> 01:01:45,680
and it's also very dynamic environment

1575
01:01:45,680 --> 01:01:47,680
and

1576
01:01:47,680 --> 01:01:50,960
this is related to the

1577
01:01:51,520 --> 01:01:54,119
a very prevalent fear of

1578
01:01:54,119 --> 01:01:55,440
unpredictability

1579
01:01:55,440 --> 01:01:59,480
is that a the weapon system is

1580
01:01:59,480 --> 01:02:01,599
unpredictable because of some of his

1581
01:02:01,599 --> 01:02:02,480
features

1582
01:02:02,480 --> 01:02:05,280
and second the very operational

1583
01:02:05,280 --> 01:02:06,240
environment

1584
01:02:06,240 --> 01:02:11,359
is arguably the most unpredictable so

1585
01:02:11,520 --> 01:02:14,480
i've read different positions on this

1586
01:02:14,480 --> 01:02:16,240
one

1587
01:02:16,240 --> 01:02:19,280
from from overbook

1588
01:02:19,280 --> 01:02:22,319
and elsewhere but what are your

1589
01:02:22,319 --> 01:02:24,359
views on the inherent the

1590
01:02:24,359 --> 01:02:25,680
unpredictability

1591
01:02:25,680 --> 01:02:29,920
and the and

1592
01:02:29,920 --> 01:02:33,200
statements that there is no uh equally

1593
01:02:33,200 --> 01:02:34,160
unpredictable

1594
01:02:34,160 --> 01:02:37,280
environment so

1595
01:02:37,280 --> 01:02:40,240
is it really that that bad or perhaps

1596
01:02:40,240 --> 01:02:41,119
even

1597
01:02:41,119 --> 01:02:44,480
cyber domain helps to mitigate

1598
01:02:44,480 --> 01:02:48,160
some of the concerns related to

1599
01:02:48,160 --> 01:02:49,160
unpredictable

1600
01:02:49,160 --> 01:02:51,680
unpredictability so uh russell maybe

1601
01:02:51,680 --> 01:02:53,039
some thoughts about

1602
01:02:53,039 --> 01:02:56,400
them yeah i mean i i think

1603
01:02:56,400 --> 01:02:58,640
you know the the adjective ryan used to

1604
01:02:58,640 --> 01:02:59,440
describe

1605
01:02:59,440 --> 01:03:02,160
thomas um some of the discussions around

1606
01:03:02,160 --> 01:03:03,359
autonomous weapons

1607
01:03:03,359 --> 01:03:05,839
um uh it is appropriate you know that

1608
01:03:05,839 --> 01:03:06,960
there is this myth

1609
01:03:06,960 --> 01:03:08,720
that they are and somehow divorced from

1610
01:03:08,720 --> 01:03:10,079
human control

1611
01:03:10,079 --> 01:03:13,280
um and the reality is is that you know

1612
01:03:13,280 --> 01:03:14,640
at a very minimum

1613
01:03:14,640 --> 01:03:17,440
um these autonomous um cyber weapons or

1614
01:03:17,440 --> 01:03:19,039
suffocated releases are given

1615
01:03:19,039 --> 01:03:21,280
life by the fact that they are

1616
01:03:21,280 --> 01:03:23,680
human-made so they will be powered by

1617
01:03:23,680 --> 01:03:26,079
algorithms for example um that have been

1618
01:03:26,079 --> 01:03:26,720
written

1619
01:03:26,720 --> 01:03:29,760
uh encoded by by humans um often you

1620
01:03:29,760 --> 01:03:31,119
know in collaboration with the private

1621
01:03:31,119 --> 01:03:31,760
sector

1622
01:03:31,760 --> 01:03:34,240
they've said they've been tested um but

1623
01:03:34,240 --> 01:03:34,960
also

1624
01:03:34,960 --> 01:03:37,039
in addition those weapons will be

1625
01:03:37,039 --> 01:03:38,240
deployed into

1626
01:03:38,240 --> 01:03:40,640
um particular environments and i think

1627
01:03:40,640 --> 01:03:41,520
the analogy there

1628
01:03:41,520 --> 01:03:43,680
with with kinetic weapons or

1629
01:03:43,680 --> 01:03:44,640
conventional weapons

1630
01:03:44,640 --> 01:03:47,359
is very close a commander for example

1631
01:03:47,359 --> 01:03:48,640
will always have to

1632
01:03:48,640 --> 01:03:51,839
um judge distances wind speeds um

1633
01:03:51,839 --> 01:03:54,160
the weight of weapons the blast radius

1634
01:03:54,160 --> 01:03:55,440
and can use different types of

1635
01:03:55,440 --> 01:03:57,280
technology to estimate the blast radius

1636
01:03:57,280 --> 01:03:58,880
depending on the weapons used and the

1637
01:03:58,880 --> 01:03:59,599
munitions

1638
01:03:59,599 --> 01:04:01,039
and all these types of things i think

1639
01:04:01,039 --> 01:04:03,599
that applies with equal force to the

1640
01:04:03,599 --> 01:04:04,559
cyber setting

1641
01:04:04,559 --> 01:04:06,880
yes there can be you know it can be more

1642
01:04:06,880 --> 01:04:07,599
difficult

1643
01:04:07,599 --> 01:04:11,119
yes perhaps the testing um uh you know

1644
01:04:11,119 --> 01:04:14,240
needs to be more intensive um

1645
01:04:14,240 --> 01:04:17,280
or more specific um and

1646
01:04:17,280 --> 01:04:19,440
uh you know perhaps the level of control

1647
01:04:19,440 --> 01:04:21,039
that's exercised as the

1648
01:04:21,039 --> 01:04:23,039
as the weapon um enters into the

1649
01:04:23,039 --> 01:04:24,319
operational domain

1650
01:04:24,319 --> 01:04:25,920
also you know there needs to be more

1651
01:04:25,920 --> 01:04:27,760
supervision or the kill switch needs to

1652
01:04:27,760 --> 01:04:28,240
be

1653
01:04:28,240 --> 01:04:31,039
um you know available or all of these

1654
01:04:31,039 --> 01:04:32,160
types of things

1655
01:04:32,160 --> 01:04:36,240
um so yes i i i don't see um

1656
01:04:36,240 --> 01:04:39,359
cyber weapons autonomous weapons being

1657
01:04:39,359 --> 01:04:41,520
so unpredictable as to preclude their

1658
01:04:41,520 --> 01:04:43,200
use under under international

1659
01:04:43,200 --> 01:04:45,039
i just think that more care and

1660
01:04:45,039 --> 01:04:46,559
responsibility is needed

1661
01:04:46,559 --> 01:04:48,240
in the way in which they are developed

1662
01:04:48,240 --> 01:04:49,839
and into the the environments in which

1663
01:04:49,839 --> 01:04:51,440
they're deployed

1664
01:04:51,440 --> 01:04:53,119
and an international is obviously an

1665
01:04:53,119 --> 01:04:55,680
important guide there in that context

1666
01:04:55,680 --> 01:04:59,200
thank you and as i remember then

1667
01:04:59,200 --> 01:05:02,400
uh you thomas alongside daniel trusillo

1668
01:05:02,400 --> 01:05:03,280
in your chapter

1669
01:05:03,280 --> 01:05:06,400
you also took a rather lukewarm position

1670
01:05:06,400 --> 01:05:08,550
to the statements regarding the

1671
01:05:08,550 --> 01:05:09,760
[Music]

1672
01:05:09,760 --> 01:05:12,960
unprecedented unpredictability

1673
01:05:12,960 --> 01:05:15,920
of the cyber environment claiming that

1674
01:05:15,920 --> 01:05:18,000
there are natural environments that are

1675
01:05:18,000 --> 01:05:18,880
in fact

1676
01:05:18,880 --> 01:05:21,680
at least equally unpredictable and harsh

1677
01:05:21,680 --> 01:05:22,480
so

1678
01:05:22,480 --> 01:05:25,520
maybe a few thoughts about this one from

1679
01:05:25,520 --> 01:05:28,000
your side

1680
01:05:28,640 --> 01:05:32,160
absolutely thank you and i

1681
01:05:32,160 --> 01:05:34,079
wasn't aware that our position was

1682
01:05:34,079 --> 01:05:38,079
lukewarm but i'm thinking that you mean

1683
01:05:38,079 --> 01:05:39,839
that we didn't take a firm position of

1684
01:05:39,839 --> 01:05:41,280
this and

1685
01:05:41,280 --> 01:05:44,799
yes i mean i i'd say look predictability

1686
01:05:44,799 --> 01:05:45,520
in a sense

1687
01:05:45,520 --> 01:05:49,359
is uh you know a a problem that

1688
01:05:49,359 --> 01:05:52,480
is really present when you have like

1689
01:05:52,480 --> 01:05:54,880
these new machine learning systems

1690
01:05:54,880 --> 01:05:57,520
ai systems you know a kind of crunch

1691
01:05:57,520 --> 01:05:59,440
huge amount of data and then they

1692
01:05:59,440 --> 01:06:01,119
they do something which is really hard

1693
01:06:01,119 --> 01:06:02,640
to predict and

1694
01:06:02,640 --> 01:06:04,880
in a sense that's okay because that's

1695
01:06:04,880 --> 01:06:07,039
precisely the reason why we have these

1696
01:06:07,039 --> 01:06:08,720
systems because we want them to figure

1697
01:06:08,720 --> 01:06:10,400
out something from the data which we

1698
01:06:10,400 --> 01:06:13,039
can't figure out ourselves

1699
01:06:13,039 --> 01:06:15,119
in the physical environment an embodied

1700
01:06:15,119 --> 01:06:17,440
weapon system so to speak this problem

1701
01:06:17,440 --> 01:06:18,079
is not

1702
01:06:18,079 --> 01:06:20,480
so let's say this classic artificial

1703
01:06:20,480 --> 01:06:23,119
intelligence sense is not so

1704
01:06:23,119 --> 01:06:25,920
present because you know in a sense

1705
01:06:25,920 --> 01:06:27,520
having an unpredictable

1706
01:06:27,520 --> 01:06:29,920
physical weapon system is precisely the

1707
01:06:29,920 --> 01:06:30,559
opposite

1708
01:06:30,559 --> 01:06:33,760
of what any kind of same military person

1709
01:06:33,760 --> 01:06:34,559
would want

1710
01:06:34,559 --> 01:06:36,319
you know you would always want to be in

1711
01:06:36,319 --> 01:06:39,119
control you want to know you know

1712
01:06:39,119 --> 01:06:41,280
what will it do so the worst case will

1713
01:06:41,280 --> 01:06:43,039
be you know you send it in and it does

1714
01:06:43,039 --> 01:06:44,960
something you didn't predict

1715
01:06:44,960 --> 01:06:47,119
so there's a natural incentive and a

1716
01:06:47,119 --> 01:06:49,359
tendency to avoid that situation you

1717
01:06:49,359 --> 01:06:50,160
know

1718
01:06:50,160 --> 01:06:52,240
if you're in a sense of a good faith

1719
01:06:52,240 --> 01:06:53,599
actor

1720
01:06:53,599 --> 01:06:56,480
you know who is looking for compliance

1721
01:06:56,480 --> 01:07:00,000
with international law and so on so

1722
01:07:00,319 --> 01:07:01,680
if you're a bad faith actor it's a

1723
01:07:01,680 --> 01:07:03,599
completely different story

1724
01:07:03,599 --> 01:07:06,400
and with the online case the cyber

1725
01:07:06,400 --> 01:07:07,680
capabilities

1726
01:07:07,680 --> 01:07:10,400
um since there is no embodiment and you

1727
01:07:10,400 --> 01:07:13,839
know there is no this natural

1728
01:07:13,839 --> 01:07:17,119
to go into a physical situation and

1729
01:07:17,119 --> 01:07:19,760
and do something that has real work

1730
01:07:19,760 --> 01:07:21,920
consequences you just you know

1731
01:07:21,920 --> 01:07:23,920
you're sending this thing online this

1732
01:07:23,920 --> 01:07:25,440
algorithm maybe there's a little bit of

1733
01:07:25,440 --> 01:07:26,160
a less

1734
01:07:26,160 --> 01:07:29,599
of a natural barrier to uh

1735
01:07:29,599 --> 01:07:31,440
to you know to make things as

1736
01:07:31,440 --> 01:07:32,960
unpredictable as possible that's

1737
01:07:32,960 --> 01:07:33,839
something i see

1738
01:07:33,839 --> 01:07:36,640
but honestly i think in that sense we

1739
01:07:36,640 --> 01:07:37,200
don't

1740
01:07:37,200 --> 01:07:40,000
know enough about autonomous cyber

1741
01:07:40,000 --> 01:07:42,000
capabilities to really judge

1742
01:07:42,000 --> 01:07:44,400
you know whether they do something that

1743
01:07:44,400 --> 01:07:45,520
can be

1744
01:07:45,520 --> 01:07:47,520
unpredictable my feeling about you know

1745
01:07:47,520 --> 01:07:48,559
algorithms

1746
01:07:48,559 --> 01:07:51,680
coding and everything and you know

1747
01:07:51,680 --> 01:07:53,839
things are more predictable than we

1748
01:07:53,839 --> 01:07:56,880
might actually

1749
01:07:56,880 --> 01:07:59,920
fear that they are

1750
01:08:00,240 --> 01:08:03,839
and thank you but so far it has been the

1751
01:08:03,839 --> 01:08:04,640
case

1752
01:08:04,640 --> 01:08:06,640
and it does not come as a surprise to

1753
01:08:06,640 --> 01:08:08,319
anyone who has for instance read a

1754
01:08:08,319 --> 01:08:11,280
working paper that

1755
01:08:11,280 --> 01:08:14,720
we seem to agree that autonomy does not

1756
01:08:14,720 --> 01:08:19,359
add a whole set of new legal problems

1757
01:08:19,359 --> 01:08:21,439
it maybe amplifies some of the existing

1758
01:08:21,439 --> 01:08:23,279
ones but and and also

1759
01:08:23,279 --> 01:08:25,920
maturity of the talk here or uh the

1760
01:08:25,920 --> 01:08:28,319
scholarly writing on this issue can

1761
01:08:28,319 --> 01:08:32,080
with some modification be nicely applied

1762
01:08:32,080 --> 01:08:34,640
uh to just cyber capabilities or on the

1763
01:08:34,640 --> 01:08:36,080
other hand some of it to just

1764
01:08:36,080 --> 01:08:38,799
autonomous weapon systems but what in

1765
01:08:38,799 --> 01:08:41,279
your view this also resonates nicely

1766
01:08:41,279 --> 01:08:42,960
with one of the questions that we have

1767
01:08:42,960 --> 01:08:44,960
received from the audience

1768
01:08:44,960 --> 01:08:48,158
what in your view is that is the one

1769
01:08:48,158 --> 01:08:51,279
thing that makes autonomous

1770
01:08:51,279 --> 01:08:54,560
cyber capabilities truly special and

1771
01:08:54,560 --> 01:08:57,279
intricate from the legal point of view

1772
01:08:57,279 --> 01:08:59,359
and

1773
01:08:59,359 --> 01:09:02,640
so that we really have to in a way

1774
01:09:02,640 --> 01:09:04,560
overthink what we have learned so far

1775
01:09:04,560 --> 01:09:06,640
about conventional cyber operations

1776
01:09:06,640 --> 01:09:08,960
and that's the and as they are used

1777
01:09:08,960 --> 01:09:09,679
during

1778
01:09:09,679 --> 01:09:14,480
armed conflict and also

1779
01:09:14,960 --> 01:09:18,319
re-evaluate what we know about kinetic

1780
01:09:18,319 --> 01:09:21,040
autonomous weapon systems so what makes

1781
01:09:21,040 --> 01:09:22,238
autonomous cyber

1782
01:09:22,238 --> 01:09:24,238
capabilities truly special one

1783
01:09:24,238 --> 01:09:27,358
distinguishing feature

1784
01:09:27,520 --> 01:09:31,279
you're with us well thanks i i get the

1785
01:09:31,279 --> 01:09:32,319
easy questions

1786
01:09:32,319 --> 01:09:36,158
um look i i think that one of the

1787
01:09:36,158 --> 01:09:39,120
uh the really interesting things is that

1788
01:09:39,120 --> 01:09:40,158
particularly

1789
01:09:40,158 --> 01:09:43,759
defensive autonomous cyber capabilities

1790
01:09:43,759 --> 01:09:46,158
are systems that potentially need to be

1791
01:09:46,158 --> 01:09:46,799
able to

1792
01:09:46,799 --> 01:09:49,040
operate within different legal

1793
01:09:49,040 --> 01:09:50,319
frameworks

1794
01:09:50,319 --> 01:09:52,640
so if you have a defensive cyber

1795
01:09:52,640 --> 01:09:54,238
capability which protects

1796
01:09:54,238 --> 01:09:57,600
your network and you switch it on

1797
01:09:57,600 --> 01:10:00,080
in time of peace and you keep it

1798
01:10:00,080 --> 01:10:02,480
switched on in terms of armed conflict

1799
01:10:02,480 --> 01:10:04,719
it must be able to operate in a way that

1800
01:10:04,719 --> 01:10:06,159
complies both with

1801
01:10:06,159 --> 01:10:08,000
with the regime that applies during

1802
01:10:08,000 --> 01:10:10,719
peace time and the regime that applies

1803
01:10:10,719 --> 01:10:13,199
in time of an armed conflict that is

1804
01:10:13,199 --> 01:10:14,640
normally not the case

1805
01:10:14,640 --> 01:10:17,760
with autonomous weapons systems which

1806
01:10:17,760 --> 01:10:21,440
assume that there is an armed conflict

1807
01:10:21,440 --> 01:10:24,480
when they are switched on or

1808
01:10:24,480 --> 01:10:27,920
an autonomous offensive cyber capability

1809
01:10:27,920 --> 01:10:30,080
which is deployed in a particular

1810
01:10:30,080 --> 01:10:31,440
context such that we

1811
01:10:31,440 --> 01:10:34,560
know uh what the the legal framework

1812
01:10:34,560 --> 01:10:37,199
is so i think from that perspective

1813
01:10:37,199 --> 01:10:39,679
autonomous defensive cyber capabilities

1814
01:10:39,679 --> 01:10:43,440
uh pose an interesting uh conundrum

1815
01:10:43,440 --> 01:10:46,080
and they basically have to be designed

1816
01:10:46,080 --> 01:10:48,000
so that they can comply

1817
01:10:48,000 --> 01:10:50,480
with the law that is effectively the

1818
01:10:50,480 --> 01:10:52,560
that sets the highest power

1819
01:10:52,560 --> 01:10:55,679
uh um uh to um to

1820
01:10:55,679 --> 01:10:59,520
to the use of an offensive capability

1821
01:10:59,520 --> 01:11:02,480
thank you and for instance uh when it

1822
01:11:02,480 --> 01:11:04,960
comes to

1823
01:11:04,960 --> 01:11:08,320
data collection and cyber capabilities

1824
01:11:08,320 --> 01:11:09,920
are in the end of the day still made up

1825
01:11:09,920 --> 01:11:11,840
of data then the highest bar is

1826
01:11:11,840 --> 01:11:14,159
oftentimes set by peacetime law

1827
01:11:14,159 --> 01:11:17,280
and now coming back to you russell you

1828
01:11:17,280 --> 01:11:18,080
mentioned

1829
01:11:18,080 --> 01:11:20,320
that

1830
01:11:21,199 --> 01:11:24,560
in the framework of ihl

1831
01:11:24,560 --> 01:11:27,840
espionage not forbidden but

1832
01:11:27,840 --> 01:11:30,159
when the data is being collected for

1833
01:11:30,159 --> 01:11:31,040
during

1834
01:11:31,040 --> 01:11:34,159
peace time for instance but put to use

1835
01:11:34,159 --> 01:11:37,280
during an armed conflict in a let's say

1836
01:11:37,280 --> 01:11:39,120
in a seamless

1837
01:11:39,120 --> 01:11:41,840
integrated way

1838
01:11:42,560 --> 01:11:44,640
through the use of a particular

1839
01:11:44,640 --> 01:11:45,760
particular

1840
01:11:45,760 --> 01:11:49,360
software autonomous or not

1841
01:11:49,360 --> 01:11:51,600
yes i mean i think you know as ryan said

1842
01:11:51,600 --> 01:11:54,080
you know the distinction between uh the

1843
01:11:54,080 --> 01:11:55,920
law of peace and law of armed conflict

1844
01:11:55,920 --> 01:11:58,320
not as is not as stark or as binary as

1845
01:11:58,320 --> 01:11:59,600
it once was and you know there can be

1846
01:11:59,600 --> 01:12:00,960
the concurrent applications

1847
01:12:00,960 --> 01:12:02,719
of those of those frameworks you know

1848
01:12:02,719 --> 01:12:05,360
depending on a variety of different

1849
01:12:05,360 --> 01:12:06,239
factors

1850
01:12:06,239 --> 01:12:09,360
i mean you know the issue for me under

1851
01:12:09,360 --> 01:12:10,080
the

1852
01:12:10,080 --> 01:12:12,239
law of peace times that you know whether

1853
01:12:12,239 --> 01:12:13,360
or not the

1854
01:12:13,360 --> 01:12:15,679
the information be can be collected and

1855
01:12:15,679 --> 01:12:17,120
you know that's that that's the critical

1856
01:12:17,120 --> 01:12:17,440
issue

1857
01:12:17,440 --> 01:12:18,800
whether it runs into conflict with

1858
01:12:18,800 --> 01:12:20,400
principles general principles such as

1859
01:12:20,400 --> 01:12:21,360
sovereignty

1860
01:12:21,360 --> 01:12:23,199
uh whether it's pacific regime such as

1861
01:12:23,199 --> 01:12:24,480
human rights law

1862
01:12:24,480 --> 01:12:27,040
um but when it comes to the the passing

1863
01:12:27,040 --> 01:12:28,800
of that that data and being used in the

1864
01:12:28,800 --> 01:12:29,199
in

1865
01:12:29,199 --> 01:12:31,040
in the context of armed conflict i think

1866
01:12:31,040 --> 01:12:32,800
you know what's really important there

1867
01:12:32,800 --> 01:12:33,840
is the way in which

1868
01:12:33,840 --> 01:12:36,560
that intelligence it's put into action

1869
01:12:36,560 --> 01:12:38,800
the way in which it's used so

1870
01:12:38,800 --> 01:12:41,600
as eric has said already um you know

1871
01:12:41,600 --> 01:12:42,400
there can be

1872
01:12:42,400 --> 01:12:43,760
there are important rules around

1873
01:12:43,760 --> 01:12:45,840
targeting um you know around distinction

1874
01:12:45,840 --> 01:12:47,360
around proportionality around

1875
01:12:47,360 --> 01:12:49,199
precautions in attack so

1876
01:12:49,199 --> 01:12:50,719
you know that intelligence can be used

1877
01:12:50,719 --> 01:12:52,239
to inform that process but of course

1878
01:12:52,239 --> 01:12:54,400
there can be mistakes in the context

1879
01:12:54,400 --> 01:12:56,880
in this context as well um and you know

1880
01:12:56,880 --> 01:12:57,760
those things

1881
01:12:57,760 --> 01:12:59,199
that those mistakes can also lead

1882
01:12:59,199 --> 01:13:01,120
through to violations of uh

1883
01:13:01,120 --> 01:13:02,960
international humanitarian laws i think

1884
01:13:02,960 --> 01:13:04,719
you know the takeaway point here is that

1885
01:13:04,719 --> 01:13:06,159
you know states have to be very careful

1886
01:13:06,159 --> 01:13:07,199
in the way in which they collect

1887
01:13:07,199 --> 01:13:08,320
intelligence but also

1888
01:13:08,320 --> 01:13:10,239
the way in which they in they use it so

1889
01:13:10,239 --> 01:13:12,080
they have to ensure it's probity

1890
01:13:12,080 --> 01:13:13,920
they have to ensure its reliability they

1891
01:13:13,920 --> 01:13:15,440
have to ensure that if it's been passed

1892
01:13:15,440 --> 01:13:16,080
to them

1893
01:13:16,080 --> 01:13:17,840
that you know it's compatible with you

1894
01:13:17,840 --> 01:13:19,120
know certain rules whether it be

1895
01:13:19,120 --> 01:13:20,159
national rules on

1896
01:13:20,159 --> 01:13:21,920
uh sharing of intelligence whether it's

1897
01:13:21,920 --> 01:13:23,840
international rules around shows of

1898
01:13:23,840 --> 01:13:24,880
intelligence which of course

1899
01:13:24,880 --> 01:13:26,880
internationally human rights law says

1900
01:13:26,880 --> 01:13:28,080
quite a lot about

1901
01:13:28,080 --> 01:13:29,520
so you know it's a precarious

1902
01:13:29,520 --> 01:13:31,920
environment in which states have to to

1903
01:13:31,920 --> 01:13:32,640
operate but

1904
01:13:32,640 --> 01:13:33,760
you know what's really important is

1905
01:13:33,760 --> 01:13:36,640
they're cognisant of their of of the

1906
01:13:36,640 --> 01:13:38,800
their legal obligations and how they

1907
01:13:38,800 --> 01:13:42,480
apply in particular context

1908
01:13:42,480 --> 01:13:45,600
and thank you and now

1909
01:13:45,600 --> 01:13:48,400
i would like to hear about the one

1910
01:13:48,400 --> 01:13:50,560
distinguishing feature

1911
01:13:50,560 --> 01:13:54,640
uh from eric's perspective

1912
01:13:55,120 --> 01:13:57,840
what makes autonomous cyber capabilities

1913
01:13:57,840 --> 01:13:58,960
special

1914
01:13:58,960 --> 01:14:02,719
from a foreign international loyal

1915
01:14:02,960 --> 01:14:04,800
so if i can and i hope you don't mind i

1916
01:14:04,800 --> 01:14:06,000
just want to make a couple of comments

1917
01:14:06,000 --> 01:14:07,360
back on predictability and then i will

1918
01:14:07,360 --> 01:14:08,800
come to your question

1919
01:14:08,800 --> 01:14:12,640
um the fact that we don't know why

1920
01:14:12,640 --> 01:14:14,960
uh an autonomous system will do what it

1921
01:14:14,960 --> 01:14:16,320
does doesn't mean it's

1922
01:14:16,320 --> 01:14:18,880
unpredictable it may be very predictable

1923
01:14:18,880 --> 01:14:20,400
even if we don't understand why and i

1924
01:14:20,400 --> 01:14:22,640
think that's a that's a big point

1925
01:14:22,640 --> 01:14:24,719
thomas's point about commanders wanting

1926
01:14:24,719 --> 01:14:26,800
predictability is absolutely true

1927
01:14:26,800 --> 01:14:29,280
no commander wants to employ a system

1928
01:14:29,280 --> 01:14:31,199
that is unpredictable and so that will

1929
01:14:31,199 --> 01:14:32,080
become a very

1930
01:14:32,080 --> 01:14:34,400
important point as we field autonomous

1931
01:14:34,400 --> 01:14:35,440
systems including

1932
01:14:35,440 --> 01:14:37,679
autonomous weapon systems and cyber

1933
01:14:37,679 --> 01:14:39,120
autonomous systems

1934
01:14:39,120 --> 01:14:41,199
and then the last point is um having

1935
01:14:41,199 --> 01:14:43,120
been a legal adviser to commanders

1936
01:14:43,120 --> 01:14:43,760
during

1937
01:14:43,760 --> 01:14:47,120
actual armed conflict um humans are not

1938
01:14:47,120 --> 01:14:49,520
that predictable if they were russell

1939
01:14:49,520 --> 01:14:50,560
wouldn't be

1940
01:14:50,560 --> 01:14:52,800
studying international criminal law you

1941
01:14:52,800 --> 01:14:54,080
know governments usually don't send

1942
01:14:54,080 --> 01:14:54,480
their

1943
01:14:54,480 --> 01:14:56,719
militaries out with the intent to commit

1944
01:14:56,719 --> 01:14:57,600
war crimes

1945
01:14:57,600 --> 01:14:59,679
those are unpredictable actions by

1946
01:14:59,679 --> 01:15:01,120
humans

1947
01:15:01,120 --> 01:15:04,640
so this idea of predictability

1948
01:15:04,640 --> 01:15:06,560
in some senses deserves a lot more

1949
01:15:06,560 --> 01:15:08,080
attention and a lot more focus rather

1950
01:15:08,080 --> 01:15:08,480
than

1951
01:15:08,480 --> 01:15:11,520
than just in most in more broad terms

1952
01:15:11,520 --> 01:15:13,280
now with respect to what makes cyber

1953
01:15:13,280 --> 01:15:14,960
autonomous weapons truly

1954
01:15:14,960 --> 01:15:18,000
special i think for me the the

1955
01:15:18,000 --> 01:15:20,480
there are many uh things but the maybe

1956
01:15:20,480 --> 01:15:21,120
the one

1957
01:15:21,120 --> 01:15:23,360
key point is this idea of speed and

1958
01:15:23,360 --> 01:15:24,960
precision

1959
01:15:24,960 --> 01:15:28,320
cyber capabilities will allow us to

1960
01:15:28,320 --> 01:15:32,560
get to targets and effects in ways

1961
01:15:32,560 --> 01:15:35,040
that humans just can't do in that kind

1962
01:15:35,040 --> 01:15:35,920
of time

1963
01:15:35,920 --> 01:15:39,840
and with that kind of precision

1964
01:15:40,880 --> 01:15:44,800
and now this is the popular question

1965
01:15:44,800 --> 01:15:45,950
but i'm

1966
01:15:45,950 --> 01:15:48,080
[Music]

1967
01:15:48,080 --> 01:15:50,560
curious about the one distinguishing

1968
01:15:50,560 --> 01:15:52,080
feature according to

1969
01:15:52,080 --> 01:15:54,559
thomas

1970
01:15:56,080 --> 01:15:59,040
look i mean now i'm a bit at the tail

1971
01:15:59,040 --> 01:15:59,520
end of the

1972
01:15:59,520 --> 01:16:01,280
of the question which which is fine with

1973
01:16:01,280 --> 01:16:03,679
me but you know if you ask me what is

1974
01:16:03,679 --> 01:16:04,840
the main difference of the

1975
01:16:04,840 --> 01:16:07,280
distinguishing feature it's you know

1976
01:16:07,280 --> 01:16:10,480
the cyber system lacks a body and

1977
01:16:10,480 --> 01:16:13,040
an autonomous weapon system has a body

1978
01:16:13,040 --> 01:16:14,480
and that has

1979
01:16:14,480 --> 01:16:16,640
in a sense leads to everything the other

1980
01:16:16,640 --> 01:16:18,640
said you know and

1981
01:16:18,640 --> 01:16:20,560
when there's a body you know it's it's

1982
01:16:20,560 --> 01:16:22,719
somehow easier to distinguish

1983
01:16:22,719 --> 01:16:25,600
is it ihl is it a non-conflict or is it

1984
01:16:25,600 --> 01:16:27,520
peacetime you know

1985
01:16:27,520 --> 01:16:30,159
when there is nobody and things are more

1986
01:16:30,159 --> 01:16:31,040
rapid

1987
01:16:31,040 --> 01:16:33,280
the the whole system becomes extremely

1988
01:16:33,280 --> 01:16:34,960
rapid why because it's not hindered by

1989
01:16:34,960 --> 01:16:36,719
the body it doesn't have to interact

1990
01:16:36,719 --> 01:16:39,520
with the environment in a physical sense

1991
01:16:39,520 --> 01:16:42,000
and so it doesn't have to actuate in in

1992
01:16:42,000 --> 01:16:42,719
in the in

1993
01:16:42,719 --> 01:16:45,920
the language of hypotheses to speak

1994
01:16:45,920 --> 01:16:49,120
so it sounds rather trivial but the fact

1995
01:16:49,120 --> 01:16:49,520
that

1996
01:16:49,520 --> 01:16:51,840
that you know psycho capabilities and

1997
01:16:51,840 --> 01:16:53,280
especially quantum cyberkey

1998
01:16:53,280 --> 01:16:56,719
of course do not necessarily travel

1999
01:16:56,719 --> 01:16:59,120
physically is of course the main

2000
01:16:59,120 --> 01:17:00,080
difference but that

2001
01:17:00,080 --> 01:17:01,920
in a sense is more stating the problem

2002
01:17:01,920 --> 01:17:03,199
and give you the solution i'm fully

2003
01:17:03,199 --> 01:17:04,800
aware of this

2004
01:17:04,800 --> 01:17:08,320
and yeah

2005
01:17:10,560 --> 01:17:14,080
and this leads us

2006
01:17:14,080 --> 01:17:17,679
again to the many reasons why these two

2007
01:17:17,679 --> 01:17:20,239
conversations should in fact go hand in

2008
01:17:20,239 --> 01:17:22,239
hand or at least in the same assembly

2009
01:17:22,239 --> 01:17:23,120
halls

2010
01:17:23,120 --> 01:17:26,480
because when talking about autonomy and

2011
01:17:26,480 --> 01:17:29,120
overlooking

2012
01:17:29,360 --> 01:17:31,760
these autonomous technologies that are

2013
01:17:31,760 --> 01:17:34,800
disembodied but for this reason

2014
01:17:34,800 --> 01:17:37,840
especially especially

2015
01:17:37,840 --> 01:17:41,120
covert and reluctant to

2016
01:17:41,120 --> 01:17:43,679
any kind of oversight for instance then

2017
01:17:43,679 --> 01:17:44,239
we

2018
01:17:44,239 --> 01:17:47,600
might end up with we

2019
01:17:47,600 --> 01:17:51,050
might end up with problems later on and

2020
01:17:51,050 --> 01:17:52,320
[Music]

2021
01:17:52,320 --> 01:17:55,920
but when you think back about the book

2022
01:17:55,920 --> 01:17:58,960
and the process of writing your

2023
01:17:58,960 --> 01:18:00,159
contribution

2024
01:18:00,159 --> 01:18:03,360
and reviewing those of the other authors

2025
01:18:03,360 --> 01:18:06,239
then is there something is this question

2026
01:18:06,239 --> 01:18:06,800
of course

2027
01:18:06,800 --> 01:18:09,840
goes to all of the panelists is there

2028
01:18:09,840 --> 01:18:10,400
something

2029
01:18:10,400 --> 01:18:12,080
that you felt that you would like to

2030
01:18:12,080 --> 01:18:14,320
explore in more depth in the future and

2031
01:18:14,320 --> 01:18:15,840
something that you know there is always

2032
01:18:15,840 --> 01:18:16,560
this

2033
01:18:16,560 --> 01:18:20,000
uh missing two days in the end that you

2034
01:18:20,000 --> 01:18:22,000
all of a sudden you feel inspired about

2035
01:18:22,000 --> 01:18:23,199
the thing that uh

2036
01:18:23,199 --> 01:18:27,199
felt a bit marginal in the beginning

2037
01:18:27,199 --> 01:18:30,239
but and then there is no time left

2038
01:18:30,239 --> 01:18:31,840
anymore so

2039
01:18:31,840 --> 01:18:33,440
what is your topic what would you like

2040
01:18:33,440 --> 01:18:35,679
to explore further

2041
01:18:35,679 --> 01:18:37,600
in the field of autonomous cyber

2042
01:18:37,600 --> 01:18:41,199
capability and international law so um

2043
01:18:41,199 --> 01:18:44,400
i think yeah thomas

2044
01:18:44,880 --> 01:18:48,800
thank you uh um i mean uh you know if

2045
01:18:48,800 --> 01:18:50,800
i'm not sure whether you really ask me

2046
01:18:50,800 --> 01:18:52,400
whether we want to go to tell him you

2047
01:18:52,400 --> 01:18:52,960
know

2048
01:18:52,960 --> 01:18:54,560
be physically present for a conference

2049
01:18:54,560 --> 01:18:55,840
the answer i think from all the

2050
01:18:55,840 --> 01:18:57,440
panelists and from everyone in the book

2051
01:18:57,440 --> 01:18:59,679
of course is a resounding yes

2052
01:18:59,679 --> 01:19:02,400
and there if you ask me you know we

2053
01:19:02,400 --> 01:19:04,560
would have to in a sense

2054
01:19:04,560 --> 01:19:07,199
discuss this overlap you know between

2055
01:19:07,199 --> 01:19:08,239
these two worlds

2056
01:19:08,239 --> 01:19:10,480
we have discussed now i mean now in a

2057
01:19:10,480 --> 01:19:11,920
sense you know we have talked a lot

2058
01:19:11,920 --> 01:19:14,000
about autonomous weapon systems the

2059
01:19:14,000 --> 01:19:16,640
the physical world where ihl clearly

2060
01:19:16,640 --> 01:19:17,920
applies and everything and then there's

2061
01:19:17,920 --> 01:19:19,600
the cyber world

2062
01:19:19,600 --> 01:19:22,640
but it so happens that these two fields

2063
01:19:22,640 --> 01:19:24,080
or domains or

2064
01:19:24,080 --> 01:19:26,320
worlds if you like are not entirely

2065
01:19:26,320 --> 01:19:29,040
separate they merge you know and and

2066
01:19:29,040 --> 01:19:30,560
when you especially when you have some

2067
01:19:30,560 --> 01:19:32,080
sort of an attack

2068
01:19:32,080 --> 01:19:34,000
you will want to use one and the other

2069
01:19:34,000 --> 01:19:35,600
end at the same time

2070
01:19:35,600 --> 01:19:38,719
and that of course creates new problems

2071
01:19:38,719 --> 01:19:41,520
uh which we we of course haven't really

2072
01:19:41,520 --> 01:19:42,800
understood yet

2073
01:19:42,800 --> 01:19:45,040
and then there's also the overlap ryan

2074
01:19:45,040 --> 01:19:46,800
has already mentioned you know the fact

2075
01:19:46,800 --> 01:19:47,760
that

2076
01:19:47,760 --> 01:19:51,920
cyprus systems tend to in a sense to

2077
01:19:51,920 --> 01:19:54,159
to phase into peace time and it's not

2078
01:19:54,159 --> 01:19:55,760
really clear whether

2079
01:19:55,760 --> 01:19:58,159
you know when they are applied it's

2080
01:19:58,159 --> 01:19:59,920
really part of a non-conflict so it's

2081
01:19:59,920 --> 01:20:02,400
not really clear what the ihl applies so

2082
01:20:02,400 --> 01:20:04,320
you fall back on international human

2083
01:20:04,320 --> 01:20:05,520
rights law

2084
01:20:05,520 --> 01:20:07,760
where you do have some norms about data

2085
01:20:07,760 --> 01:20:08,639
collection

2086
01:20:08,639 --> 01:20:10,639
you know i mean when you do facial

2087
01:20:10,639 --> 01:20:13,360
recognition you gather personal data

2088
01:20:13,360 --> 01:20:15,679
a biometric information in general and

2089
01:20:15,679 --> 01:20:17,360
then human rights law has a lot to say

2090
01:20:17,360 --> 01:20:18,639
about this

2091
01:20:18,639 --> 01:20:21,440
you know can you do facial recognition

2092
01:20:21,440 --> 01:20:22,159
in in

2093
01:20:22,159 --> 01:20:24,159
you know passivated sense and so on and

2094
01:20:24,159 --> 01:20:26,080
so forth but there's a lot going on

2095
01:20:26,080 --> 01:20:30,400
in the in the peacetime law if you like

2096
01:20:30,400 --> 01:20:32,960
and that with cyber system that kind of

2097
01:20:32,960 --> 01:20:33,440
you know

2098
01:20:33,440 --> 01:20:35,600
merges with the you know that other body

2099
01:20:35,600 --> 01:20:37,520
of law which is ihl much more

2100
01:20:37,520 --> 01:20:40,560
evidently than than than is the case in

2101
01:20:40,560 --> 01:20:41,600
physical system so

2102
01:20:41,600 --> 01:20:43,760
i think we should probably explore this

2103
01:20:43,760 --> 01:20:46,239
and we probably have

2104
01:20:46,239 --> 01:20:49,360
you know a lot of a lot of topics to

2105
01:20:49,360 --> 01:20:52,560
to discuss for two days workshop and

2106
01:20:52,560 --> 01:20:55,679
um ryan do you

2107
01:20:55,679 --> 01:20:57,920
agree or do you have any ideas for

2108
01:20:57,920 --> 01:21:02,320
autonomous cyber capabilities 2.0

2109
01:21:04,400 --> 01:21:05,920
well look i think that there are a

2110
01:21:05,920 --> 01:21:07,840
number of contributions to this book

2111
01:21:07,840 --> 01:21:09,280
that could be developed

2112
01:21:09,280 --> 01:21:12,400
into a research project in their own

2113
01:21:12,400 --> 01:21:13,520
right

2114
01:21:13,520 --> 01:21:15,840
perhaps the one that really fascinates

2115
01:21:15,840 --> 01:21:16,800
me is

2116
01:21:16,800 --> 01:21:20,480
what eric's chapter focused on and that

2117
01:21:20,480 --> 01:21:23,040
peter's chapter touched upon to some

2118
01:21:23,040 --> 01:21:24,560
degree as well

2119
01:21:24,560 --> 01:21:26,719
which is precautionary measures you know

2120
01:21:26,719 --> 01:21:28,800
articles 57 and 58 of additional

2121
01:21:28,800 --> 01:21:30,159
protocol 1

2122
01:21:30,159 --> 01:21:33,280
to the geneva conventions and

2123
01:21:33,280 --> 01:21:35,520
the rich range of legal obligations that

2124
01:21:35,520 --> 01:21:36,639
these provisions

2125
01:21:36,639 --> 01:21:40,239
create and how they apply in the context

2126
01:21:40,239 --> 01:21:41,360
of

2127
01:21:41,360 --> 01:21:44,800
cyber capabilities so so what does it

2128
01:21:44,800 --> 01:21:46,719
mean to take constant care of the

2129
01:21:46,719 --> 01:21:47,920
civilian population

2130
01:21:47,920 --> 01:21:51,600
whilst using an autonomous capability

2131
01:21:51,600 --> 01:21:53,600
what kind of precautionary measures can

2132
01:21:53,600 --> 01:21:56,480
potentially be delegated to

2133
01:21:56,480 --> 01:21:59,199
an autonomous capability what

2134
01:21:59,199 --> 01:22:01,120
precautionary measures have to be taken

2135
01:22:01,120 --> 01:22:03,520
by a human being before deploying

2136
01:22:03,520 --> 01:22:07,360
uh on autonomous capability

2137
01:22:07,360 --> 01:22:10,639
i think i i wasn't terribly optimistic

2138
01:22:10,639 --> 01:22:12,960
about the ability of autonomous systems

2139
01:22:12,960 --> 01:22:14,080
to comply

2140
01:22:14,080 --> 01:22:16,480
with the precautionary measures

2141
01:22:16,480 --> 01:22:18,560
requirement but

2142
01:22:18,560 --> 01:22:20,960
eric eric's piece has instilled some

2143
01:22:20,960 --> 01:22:22,480
optimism in me so

2144
01:22:22,480 --> 01:22:24,080
that's something that i would would like

2145
01:22:24,080 --> 01:22:26,560
to explore further

2146
01:22:26,560 --> 01:22:28,320
and i think that the question about the

2147
01:22:28,320 --> 01:22:29,679
accountability gap

2148
01:22:29,679 --> 01:22:32,800
um is an interesting one as well um and

2149
01:22:32,800 --> 01:22:34,639
i think the contributions to this book

2150
01:22:34,639 --> 01:22:35,840
suggests that

2151
01:22:35,840 --> 01:22:38,480
the accounting notability gap is perhaps

2152
01:22:38,480 --> 01:22:40,080
somewhat overstated

2153
01:22:40,080 --> 01:22:43,199
in existing literature um and and i

2154
01:22:43,199 --> 01:22:44,480
think that's an interesting

2155
01:22:44,480 --> 01:22:49,759
uh uh issue to to tease out further

2156
01:22:50,000 --> 01:22:53,600
and does any of it

2157
01:22:53,600 --> 01:22:57,120
sound inspiring to eric for instance

2158
01:22:57,120 --> 01:23:00,400
to collaborate with ryan and furthermore

2159
01:23:00,400 --> 01:23:03,600
uh outline how actual

2160
01:23:03,600 --> 01:23:05,760
feasible precautions might look like

2161
01:23:05,760 --> 01:23:06,719
when

2162
01:23:06,719 --> 01:23:09,679
applying autonomous cyber capabilities

2163
01:23:09,679 --> 01:23:12,719
or any other topic

2164
01:23:13,040 --> 01:23:15,120
yes well having had ryan's endorsement i

2165
01:23:15,120 --> 01:23:16,800
should just be quiet because nothing i

2166
01:23:16,800 --> 01:23:18,800
could say would be more persuasive

2167
01:23:18,800 --> 01:23:21,920
than that but but i do think

2168
01:23:21,920 --> 01:23:24,400
that the next step in those questions or

2169
01:23:24,400 --> 01:23:26,560
maybe a piece of those questions

2170
01:23:26,560 --> 01:23:29,600
is the standard of review when we

2171
01:23:29,600 --> 01:23:32,320
start to look at how autonomous systems

2172
01:23:32,320 --> 01:23:33,679
can comply

2173
01:23:33,679 --> 01:23:35,280
what is the standard of review must

2174
01:23:35,280 --> 01:23:36,880
these autonomous weapon systems be

2175
01:23:36,880 --> 01:23:38,000
perfect

2176
01:23:38,000 --> 01:23:40,560
do we compare them with with the data we

2177
01:23:40,560 --> 01:23:42,000
have which is very scant

2178
01:23:42,000 --> 01:23:43,920
on how humans perform in these

2179
01:23:43,920 --> 01:23:45,199
precautionary measures

2180
01:23:45,199 --> 01:23:46,800
you know what is the standard review by

2181
01:23:46,800 --> 01:23:48,320
which we will then say okay

2182
01:23:48,320 --> 01:23:50,480
now that autonomous weapon system is

2183
01:23:50,480 --> 01:23:52,320
good enough to be employed

2184
01:23:52,320 --> 01:23:54,560
i think that really could uh could use

2185
01:23:54,560 --> 01:23:55,760
some development

2186
01:23:55,760 --> 01:23:57,920
and then just one other point that goes

2187
01:23:57,920 --> 01:24:00,239
to russell's expertise

2188
01:24:00,239 --> 01:24:02,719
this idea of data has been really

2189
01:24:02,719 --> 01:24:03,520
interesting

2190
01:24:03,520 --> 01:24:06,719
uh and and how we use data and

2191
01:24:06,719 --> 01:24:09,600
the corruption of data and how you might

2192
01:24:09,600 --> 01:24:10,159
uh

2193
01:24:10,159 --> 01:24:13,199
you know trust in data versus espionage

2194
01:24:13,199 --> 01:24:14,400
and sabotage i think

2195
01:24:14,400 --> 01:24:16,000
those are some really interesting

2196
01:24:16,000 --> 01:24:17,920
questions as well and and i obviously

2197
01:24:17,920 --> 01:24:19,199
love everything russell writes that the

2198
01:24:19,199 --> 01:24:20,560
book on our side of espionage is

2199
01:24:20,560 --> 01:24:21,520
fantastic but

2200
01:24:21,520 --> 01:24:23,760
it makes me think about those kinds of

2201
01:24:23,760 --> 01:24:25,280
questions that i think will be

2202
01:24:25,280 --> 01:24:27,520
more and more important if we ever go

2203
01:24:27,520 --> 01:24:28,639
into a large-scale

2204
01:24:28,639 --> 01:24:30,719
uh armed conflict where cyber tools are

2205
01:24:30,719 --> 01:24:33,120
engaged

2206
01:24:34,000 --> 01:24:37,760
may i know not in a somewhat

2207
01:24:37,760 --> 01:24:40,080
organic way we proceed to give the mic

2208
01:24:40,080 --> 01:24:41,199
to russell

2209
01:24:41,199 --> 01:24:44,080
to add anything and introduce his ideas

2210
01:24:44,080 --> 01:24:45,280
for further research

2211
01:24:45,280 --> 01:24:48,719
on this matter or related matters

2212
01:24:48,719 --> 01:24:51,760
yes yes well leading on from

2213
01:24:51,760 --> 01:24:55,520
um perhaps a bit of selfless

2214
01:24:55,520 --> 01:24:58,880
promotion for both the nate

2215
01:25:03,120 --> 01:25:05,280
leading a new project for the nato cyber

2216
01:25:05,280 --> 01:25:06,320
center on the

2217
01:25:06,320 --> 01:25:08,880
right to uh data protection during times

2218
01:25:08,880 --> 01:25:09,920
of armed conflict

2219
01:25:09,920 --> 01:25:12,320
and you know the right data protection

2220
01:25:12,320 --> 01:25:14,000
intel divine conflict i think is often

2221
01:25:14,000 --> 01:25:15,360
eclipsed or dwarfed

2222
01:25:15,360 --> 01:25:18,080
or crowded out um by kind of more you

2223
01:25:18,080 --> 01:25:19,840
know military considerations

2224
01:25:19,840 --> 01:25:21,440
um and you know other areas of

2225
01:25:21,440 --> 01:25:23,199
international humanitarian at all but

2226
01:25:23,199 --> 01:25:24,840
of course you know there is a right

2227
01:25:24,840 --> 01:25:26,400
state of protection

2228
01:25:26,400 --> 01:25:27,760
during times of armed conflicts and it

2229
01:25:27,760 --> 01:25:29,679
manifests itself in different areas

2230
01:25:29,679 --> 01:25:32,719
pows for example or i mean the way in

2231
01:25:32,719 --> 01:25:34,320
which intelligence is collected and used

2232
01:25:34,320 --> 01:25:35,679
for targeting decisions

2233
01:25:35,679 --> 01:25:37,600
or the way in which peacekeeping

2234
01:25:37,600 --> 01:25:39,040
operations or the way in which war

2235
01:25:39,040 --> 01:25:40,960
crimes trials and you know we go on and

2236
01:25:40,960 --> 01:25:42,719
on listen all these different examples

2237
01:25:42,719 --> 01:25:43,600
of the way in which

2238
01:25:43,600 --> 01:25:45,280
the rights of data protection is really

2239
01:25:45,280 --> 01:25:47,520
important um during times of armed

2240
01:25:47,520 --> 01:25:48,560
conflict and i think

2241
01:25:48,560 --> 01:25:51,600
uh if you put the autonomous side today

2242
01:25:51,600 --> 01:25:54,159
into the mix there then lots of those

2243
01:25:54,159 --> 01:25:56,080
already unexplored questions

2244
01:25:56,080 --> 01:25:58,480
become even more difficult um and you

2245
01:25:58,480 --> 01:25:59,600
know i think those

2246
01:25:59,600 --> 01:26:01,120
those questions are critically important

2247
01:26:01,120 --> 01:26:02,639
to to answer

2248
01:26:02,639 --> 01:26:04,560
and hopefully the project um that as

2249
01:26:04,560 --> 01:26:05,679
that for myself

2250
01:26:05,679 --> 01:26:08,719
um doing the nato cyber center

2251
01:26:08,719 --> 01:26:10,880
uh will go some way towards answering

2252
01:26:10,880 --> 01:26:12,719
them but uh just to say

2253
01:26:12,719 --> 01:26:14,239
um you know the project's in its early

2254
01:26:14,239 --> 01:26:15,760
stages at the moment but

2255
01:26:15,760 --> 01:26:18,639
issues around autonomy and cyber um

2256
01:26:18,639 --> 01:26:20,239
autonomous capabilities

2257
01:26:20,239 --> 01:26:23,040
will be addressed in in in the edited

2258
01:26:23,040 --> 01:26:24,480
collection in the project

2259
01:26:24,480 --> 01:26:26,560
um and to that extent you know it's kind

2260
01:26:26,560 --> 01:26:28,080
of a natural progression on from

2261
01:26:28,080 --> 01:26:29,760
from the project that you've done with

2262
01:26:29,760 --> 01:26:32,080
brian

2263
01:26:32,320 --> 01:26:35,360
thank you so much for sharing your

2264
01:26:35,360 --> 01:26:36,159
thoughts and

2265
01:26:36,159 --> 01:26:39,280
really probably

2266
01:26:39,679 --> 01:26:43,040
leaving thankfully more questions

2267
01:26:43,040 --> 01:26:46,960
than a full and um full and ready-made

2268
01:26:46,960 --> 01:26:50,000
100 proof answers so and

2269
01:26:50,000 --> 01:26:52,080
right now i'm going to move on to a

2270
01:26:52,080 --> 01:26:53,199
slightly

2271
01:26:53,199 --> 01:26:55,679
weird experience of disembodied

2272
01:26:55,679 --> 01:26:58,719
questions and answers

2273
01:26:58,719 --> 01:27:02,880
so far we have received one question

2274
01:27:02,880 --> 01:27:05,199
that comes back to control and reviews

2275
01:27:05,199 --> 01:27:06,320
this regards

2276
01:27:06,320 --> 01:27:09,760
testing and

2277
01:27:09,760 --> 01:27:12,000
the participant is asking to what extent

2278
01:27:12,000 --> 01:27:13,199
can testing

2279
01:27:13,199 --> 01:27:15,440
for example as part of weapons reviews

2280
01:27:15,440 --> 01:27:17,520
be trusted when it comes to systems

2281
01:27:17,520 --> 01:27:20,239
built on machine learning

2282
01:27:20,239 --> 01:27:22,320
especially for a system that is

2283
01:27:22,320 --> 01:27:23,520
continuously

2284
01:27:23,520 --> 01:27:27,600
learning may i

2285
01:27:27,600 --> 01:27:33,040
direct this question to eric

2286
01:27:33,040 --> 01:27:34,880
yes and i think it's a great question

2287
01:27:34,880 --> 01:27:36,480
and something that we need to really

2288
01:27:36,480 --> 01:27:37,520
think about hard

2289
01:27:37,520 --> 01:27:40,000
but but i would start by saying that and

2290
01:27:40,000 --> 01:27:42,400
that's in one spot this is no different

2291
01:27:42,400 --> 01:27:43,920
than the human right

2292
01:27:43,920 --> 01:27:46,320
we get a human we we put him or her in

2293
01:27:46,320 --> 01:27:48,159
the military as a private we send them

2294
01:27:48,159 --> 01:27:49,520
out into armed conflict

2295
01:27:49,520 --> 01:27:52,480
and they absolutely learn and what do we

2296
01:27:52,480 --> 01:27:52,880
do

2297
01:27:52,880 --> 01:27:54,800
with their learning and adaptation we

2298
01:27:54,800 --> 01:27:56,719
bring them back from time to time we

2299
01:27:56,719 --> 01:27:58,880
review the law of armed conflict

2300
01:27:58,880 --> 01:28:00,800
we review their practices their

2301
01:28:00,800 --> 01:28:02,320
processes what they're thinking and then

2302
01:28:02,320 --> 01:28:04,080
we send them back out again

2303
01:28:04,080 --> 01:28:05,840
and and no doubt we will have to do

2304
01:28:05,840 --> 01:28:07,199
something like this with autonomous

2305
01:28:07,199 --> 01:28:08,239
weapon systems

2306
01:28:08,239 --> 01:28:09,920
we will in we will engage them and

2307
01:28:09,920 --> 01:28:11,600
utilize them in our conflict we will

2308
01:28:11,600 --> 01:28:13,280
review how they do

2309
01:28:13,280 --> 01:28:14,719
and then we will bring them back and

2310
01:28:14,719 --> 01:28:16,960
tinker and adjust and make corrections

2311
01:28:16,960 --> 01:28:18,000
as needed

2312
01:28:18,000 --> 01:28:20,000
so i think it's an important question

2313
01:28:20,000 --> 01:28:21,920
but i don't think it's an unanswerable

2314
01:28:21,920 --> 01:28:23,440
question i don't think it's a bridge too

2315
01:28:23,440 --> 01:28:24,400
far i don't think it

2316
01:28:24,400 --> 01:28:26,239
is really anything that detracts from

2317
01:28:26,239 --> 01:28:27,760
our use of autonomous weapons

2318
01:28:27,760 --> 01:28:29,440
it just highlights the fact that like

2319
01:28:29,440 --> 01:28:31,440
with humans we need to continuously

2320
01:28:31,440 --> 01:28:33,600
review and update and make sure that it

2321
01:28:33,600 --> 01:28:34,880
is functioning as we desire

2322
01:28:34,880 --> 01:28:38,800
to does any of the other speakers

2323
01:28:38,800 --> 01:28:42,639
want to add anything to this one

2324
01:28:42,639 --> 01:28:46,719
yes okay well maybe you ran

2325
01:28:47,679 --> 01:28:50,960
i would just make the edition

2326
01:28:51,440 --> 01:28:54,480
alphabetically right

2327
01:28:54,800 --> 01:28:56,400
so i would just make the observation

2328
01:28:56,400 --> 01:28:58,639
that uh perhaps autonomous cyber

2329
01:28:58,639 --> 01:28:59,920
capabilities

2330
01:28:59,920 --> 01:29:02,880
uh have some additional opportunities

2331
01:29:02,880 --> 01:29:04,960
for testing compared to kinetic

2332
01:29:04,960 --> 01:29:06,960
capabilities so with kinetic

2333
01:29:06,960 --> 01:29:09,199
capabilities you need to at some point

2334
01:29:09,199 --> 01:29:11,199
put them in a natural environment

2335
01:29:11,199 --> 01:29:14,400
and see how they perform there whereas

2336
01:29:14,400 --> 01:29:16,800
an autonomous cyber capability you can

2337
01:29:16,800 --> 01:29:18,000
potentially test

2338
01:29:18,000 --> 01:29:21,600
in a synthetically created or virtual

2339
01:29:21,600 --> 01:29:22,800
environment

2340
01:29:22,800 --> 01:29:25,679
and you can test it continuously you

2341
01:29:25,679 --> 01:29:26,239
know

2342
01:29:26,239 --> 01:29:28,800
thousands or tens of thousands of time

2343
01:29:28,800 --> 01:29:29,920
so perhaps

2344
01:29:29,920 --> 01:29:32,159
uh it could be said that autonomous

2345
01:29:32,159 --> 01:29:33,440
cyber capabilities

2346
01:29:33,440 --> 01:29:36,560
are more susceptible to comprehensive

2347
01:29:36,560 --> 01:29:37,360
testing

2348
01:29:37,360 --> 01:29:42,239
than autonomous kinetic capabilities

2349
01:29:42,239 --> 01:29:46,239
and thomas may i also

2350
01:29:46,239 --> 01:29:49,600
ask can you please display question

2351
01:29:49,600 --> 01:29:52,000
number three

2352
01:29:52,000 --> 01:29:55,199
thank you and please go on okay um

2353
01:29:55,199 --> 01:29:57,520
look i mean the you know the the the

2354
01:29:57,520 --> 01:29:59,280
thing with the learning machine

2355
01:29:59,280 --> 01:30:01,600
the learning weapon when it's a physical

2356
01:30:01,600 --> 01:30:03,040
weapon an autonomous weapon

2357
01:30:03,040 --> 01:30:05,440
system is really not such a problem you

2358
01:30:05,440 --> 01:30:06,560
know because

2359
01:30:06,560 --> 01:30:08,960
um you know the weapons review must just

2360
01:30:08,960 --> 01:30:10,159
be understood

2361
01:30:10,159 --> 01:30:12,400
in the sense that you know learning in

2362
01:30:12,400 --> 01:30:13,360
the wild

2363
01:30:13,360 --> 01:30:16,480
adaptive systems in the true sense

2364
01:30:16,480 --> 01:30:19,520
are precluded by the law i mean and

2365
01:30:19,520 --> 01:30:21,440
and there's also a very strong incentive

2366
01:30:21,440 --> 01:30:23,920
not to have learning systems that you

2367
01:30:23,920 --> 01:30:25,520
know that are out there learning the

2368
01:30:25,520 --> 01:30:27,280
wild and adapting all the time because

2369
01:30:27,280 --> 01:30:29,600
these systems can very easily be gained

2370
01:30:29,600 --> 01:30:31,840
right you can just you know modify the

2371
01:30:31,840 --> 01:30:33,199
data and you know

2372
01:30:33,199 --> 01:30:35,440
in a sense feed it the data that you

2373
01:30:35,440 --> 01:30:36,239
think will do

2374
01:30:36,239 --> 01:30:37,920
will do the trick and then all of a

2375
01:30:37,920 --> 01:30:39,440
sudden it does something else

2376
01:30:39,440 --> 01:30:41,440
so in a sense with physical systems you

2377
01:30:41,440 --> 01:30:42,800
know learning systems

2378
01:30:42,800 --> 01:30:45,360
that are learning in the wild as opposed

2379
01:30:45,360 --> 01:30:47,440
to those that are actually frozen

2380
01:30:47,440 --> 01:30:49,040
at the point in time where you do the

2381
01:30:49,040 --> 01:30:50,480
weapons review

2382
01:30:50,480 --> 01:30:52,320
which make out the data and then when

2383
01:30:52,320 --> 01:30:54,080
you learn on the base of that data you

2384
01:30:54,080 --> 01:30:55,120
have to go through

2385
01:30:55,120 --> 01:30:57,840
the the clearance again so that's the

2386
01:30:57,840 --> 01:30:59,679
whole thing you do with physical systems

2387
01:30:59,679 --> 01:31:02,960
cyber systems in a sense there is maybe

2388
01:31:02,960 --> 01:31:03,840
a

2389
01:31:03,840 --> 01:31:06,800
sense that you know learning in the wild

2390
01:31:06,800 --> 01:31:08,320
life so to speak

2391
01:31:08,320 --> 01:31:12,159
um would be possible more than

2392
01:31:12,159 --> 01:31:14,320
would be more let's say acceptable than

2393
01:31:14,320 --> 01:31:16,719
maybe with an autonomous weapon systems

2394
01:31:16,719 --> 01:31:19,199
in the physical sense that is possible

2395
01:31:19,199 --> 01:31:22,480
um but there also i would caution i mean

2396
01:31:22,480 --> 01:31:24,880
you know learning in the wild is really

2397
01:31:24,880 --> 01:31:25,760
uh

2398
01:31:25,760 --> 01:31:28,159
something that is very very risky and

2399
01:31:28,159 --> 01:31:30,000
very uh you know you need to be very

2400
01:31:30,000 --> 01:31:32,960
very careful when you let loose a system

2401
01:31:32,960 --> 01:31:34,639
um that is capable of learning and that

2402
01:31:34,639 --> 01:31:35,840
it acts on the goal

2403
01:31:35,840 --> 01:31:38,960
you know and you know while interacting

2404
01:31:38,960 --> 01:31:39,440
with the

2405
01:31:39,440 --> 01:31:42,000
with the environment this is something

2406
01:31:42,000 --> 01:31:42,639
of a myth

2407
01:31:42,639 --> 01:31:44,639
of a myth with machine learning that you

2408
01:31:44,639 --> 01:31:45,760
know

2409
01:31:45,760 --> 01:31:47,280
commonly we don't distinguish

2410
01:31:47,280 --> 01:31:48,960
sufficiently between

2411
01:31:48,960 --> 01:31:50,719
systems that are frozen that have been

2412
01:31:50,719 --> 01:31:52,880
trained and then are frozen and then

2413
01:31:52,880 --> 01:31:55,199
are you know in a sense working on the

2414
01:31:55,199 --> 01:31:56,239
basis of this

2415
01:31:56,239 --> 01:31:58,239
learning in the past and the systems

2416
01:31:58,239 --> 01:32:00,159
that are learning on the go

2417
01:32:00,159 --> 01:32:02,480
which are much rarer and which create

2418
01:32:02,480 --> 01:32:03,679
much much

2419
01:32:03,679 --> 01:32:06,719
much more significant problems

2420
01:32:06,719 --> 01:32:09,600
anything to add on this one we have in

2421
01:32:09,600 --> 01:32:10,560
fact

2422
01:32:10,560 --> 01:32:12,800
received a question that's very closely

2423
01:32:12,800 --> 01:32:13,840
related to

2424
01:32:13,840 --> 01:32:16,880
the previous one and disregards the

2425
01:32:16,880 --> 01:32:20,239
responsible ways of testing autonomous

2426
01:32:20,239 --> 01:32:22,560
cyber capabilities since they tend to be

2427
01:32:22,560 --> 01:32:23,840
custom tailored

2428
01:32:23,840 --> 01:32:27,040
and can we really realistically imagine

2429
01:32:27,040 --> 01:32:30,639
them being tested only on in cyber

2430
01:32:30,639 --> 01:32:31,840
ranges and not

2431
01:32:31,840 --> 01:32:36,000
on the very uh targets that they are

2432
01:32:36,000 --> 01:32:39,199
meant for in the end is it

2433
01:32:39,199 --> 01:32:41,280
it would be probably ethical but is it

2434
01:32:41,280 --> 01:32:43,840
realistic

2435
01:32:44,639 --> 01:32:47,280
any thoughts

2436
01:32:52,840 --> 01:32:55,760
eric i would just say to the extent that

2437
01:32:55,760 --> 01:32:57,679
stuxnet is an example of that

2438
01:32:57,679 --> 01:33:00,080
that if suxnet was designed to

2439
01:33:00,080 --> 01:33:01,840
accomplish a specific thing

2440
01:33:01,840 --> 01:33:04,480
and it did it that seems to be a good

2441
01:33:04,480 --> 01:33:06,960
example of a time when a cyber tool was

2442
01:33:06,960 --> 01:33:08,960
tested in range and then applied

2443
01:33:08,960 --> 01:33:10,320
generally and applied

2444
01:33:10,320 --> 01:33:12,159
as it should have been thomas back to

2445
01:33:12,159 --> 01:33:14,638
you sorry

2446
01:33:15,360 --> 01:33:16,639
well i was just going to say i'm not

2447
01:33:16,639 --> 01:33:19,120
sure i got the answer fully so

2448
01:33:19,120 --> 01:33:22,239
yeah but obviously eric got it so

2449
01:33:22,239 --> 01:33:28,159
i'm fine i got it maybe i didn't thomas

2450
01:33:30,159 --> 01:33:31,840
the question comes from the audience so

2451
01:33:31,840 --> 01:33:33,520
it's for them to decide but

2452
01:33:33,520 --> 01:33:35,679
in my opinion you did get it but yeah

2453
01:33:35,679 --> 01:33:36,719
come yeah please

2454
01:33:36,719 --> 01:33:40,000
russell sorry i didn't uh

2455
01:33:40,000 --> 01:33:42,719
uh speak over talking there um i i think

2456
01:33:42,719 --> 01:33:44,239
what we've not mentioned so far is in

2457
01:33:44,239 --> 01:33:45,920
the context of the weapons review

2458
01:33:45,920 --> 01:33:47,760
the intersection with the private sector

2459
01:33:47,760 --> 01:33:49,520
is going to be critically important

2460
01:33:49,520 --> 01:33:51,520
i think the militaries are very familiar

2461
01:33:51,520 --> 01:33:52,880
with you know regular

2462
01:33:52,880 --> 01:33:55,360
normal military-grade weapons and you

2463
01:33:55,360 --> 01:33:56,880
know the testing to a certain extent of

2464
01:33:56,880 --> 01:33:57,760
those weapons

2465
01:33:57,760 --> 01:33:59,679
um can be conducted you know much more

2466
01:33:59,679 --> 01:34:01,360
in-house if we can put it

2467
01:34:01,360 --> 01:34:03,840
in that way whereas with the the the

2468
01:34:03,840 --> 01:34:05,280
cyber weapons i think

2469
01:34:05,280 --> 01:34:07,600
more than than any other type of weapon

2470
01:34:07,600 --> 01:34:09,199
um the role of the private sector will

2471
01:34:09,199 --> 01:34:10,719
be really important there

2472
01:34:10,719 --> 01:34:13,120
and you know because of the black box

2473
01:34:13,120 --> 01:34:14,239
nature of the weapons

2474
01:34:14,239 --> 01:34:17,440
uh review um you know one wonders how

2475
01:34:17,440 --> 01:34:18,719
closely militaries are

2476
01:34:18,719 --> 01:34:20,480
liaising with the private sector whether

2477
01:34:20,480 --> 01:34:24,638
or not that is an effective relationship

2478
01:34:26,480 --> 01:34:30,280
then one more question uh it

2479
01:34:30,280 --> 01:34:33,120
concerns the line between offense and

2480
01:34:33,120 --> 01:34:33,840
defense

2481
01:34:33,840 --> 01:34:37,840
uh in cyber warfare or conduct of

2482
01:34:37,840 --> 01:34:40,000
hostilities in general

2483
01:34:40,000 --> 01:34:43,600
and is it is this

2484
01:34:43,600 --> 01:34:46,320
in some way further complicated by

2485
01:34:46,320 --> 01:34:46,960
adding

2486
01:34:46,960 --> 01:34:50,960
autonomy to the usual cyber mix

2487
01:34:50,960 --> 01:34:54,159
making the distinction between offensive

2488
01:34:54,159 --> 01:34:54,480
and

2489
01:34:54,480 --> 01:34:58,159
defensive that is any volunteers

2490
01:34:58,159 --> 01:35:01,839
for this one

2491
01:35:07,760 --> 01:35:11,280
there are more questions related to

2492
01:35:11,280 --> 01:35:14,400
what does the standard of

2493
01:35:14,400 --> 01:35:18,000
of of care mean when

2494
01:35:18,000 --> 01:35:20,159
at the point where cyber meets autonomy

2495
01:35:20,159 --> 01:35:21,360
and so on so forth

2496
01:35:21,360 --> 01:35:22,719
i have a file with the questions that

2497
01:35:22,719 --> 01:35:24,719
i'm going to send you afterwards

2498
01:35:24,719 --> 01:35:27,440
but uh right now it seems to me that is

2499
01:35:27,440 --> 01:35:29,040
time to

2500
01:35:29,040 --> 01:35:33,520
wrap it up as previously mentioned

2501
01:35:33,520 --> 01:35:37,360
a fair reflection of the actual content

2502
01:35:37,360 --> 01:35:39,600
and the actual diversity and richness of

2503
01:35:39,600 --> 01:35:40,480
thought

2504
01:35:40,480 --> 01:35:43,119
between the covers of this book would in

2505
01:35:43,119 --> 01:35:43,600
fact

2506
01:35:43,600 --> 01:35:48,000
hijack the whole cyclone 2020

2507
01:35:48,000 --> 01:35:52,000
and involve at least 17 people around

2508
01:35:52,000 --> 01:35:52,639
the table

2509
01:35:52,639 --> 01:35:56,080
and many more

2510
01:35:56,080 --> 01:36:01,440
among the participants so thank you for

2511
01:36:01,440 --> 01:36:04,800
giving such a great

2512
01:36:04,800 --> 01:36:09,199
great overview and uh and and

2513
01:36:09,280 --> 01:36:12,560
managing to summarize the main points

2514
01:36:12,560 --> 01:36:14,560
and the main

2515
01:36:14,560 --> 01:36:17,760
controversies contained in this book

2516
01:36:17,760 --> 01:36:20,880
um the book should be online now it is

2517
01:36:20,880 --> 01:36:25,679
online under ccdc

2518
01:36:25,679 --> 01:36:30,080
publications and it contains

2519
01:36:30,080 --> 01:36:33,040
it contains the names and affiliations

2520
01:36:33,040 --> 01:36:35,440
of all the authors

2521
01:36:35,440 --> 01:36:38,960
who i cannot name right now since

2522
01:36:38,960 --> 01:36:41,600
it's it would be slightly robotic and we

2523
01:36:41,600 --> 01:36:42,480
do not have

2524
01:36:42,480 --> 01:36:46,000
the time as of now but the least that we

2525
01:36:46,000 --> 01:36:46,880
could do

2526
01:36:46,880 --> 01:36:50,000
is to have an applause for all the

2527
01:36:50,000 --> 01:36:51,360
authors involved

2528
01:36:51,360 --> 01:36:53,840
and to row into isabella and to agnes in

2529
01:36:53,840 --> 01:36:55,679
the end so thank you so much and thank

2530
01:36:55,679 --> 01:36:56,960
you

2531
01:36:56,960 --> 01:36:59,840
for the speakers the authors and for the

2532
01:36:59,840 --> 01:37:01,600
organizer of saigon

2533
01:37:01,600 --> 01:37:07,840
thank you and thank you read the book

2534
01:37:18,590 --> 01:37:24,130
[Music]

2535
01:37:24,480 --> 01:37:26,559
you

