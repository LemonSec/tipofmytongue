1
00:00:00,089 --> 00:00:07,529
welcome back from lunch to the first

2
00:00:03,179 --> 00:00:09,420
tech track of this saikhan machine

3
00:00:07,529 --> 00:00:13,200
learning as the way forward to defend

4
00:00:09,420 --> 00:00:15,900
against the emerging sets my name is

5
00:00:13,200 --> 00:00:18,779
Arturo Ramos I am technology researcher

6
00:00:15,900 --> 00:00:22,439
at CDC OE and I will be moderating this

7
00:00:18,779 --> 00:00:24,930
panel my main field of interests are

8
00:00:22,439 --> 00:00:28,019
rebel network security and lately I have

9
00:00:24,930 --> 00:00:31,349
been focusing more on the network

10
00:00:28,019 --> 00:00:36,660
security research which often results in

11
00:00:31,349 --> 00:00:38,879
huge datasets that can be processed by

12
00:00:36,660 --> 00:00:42,360
humans even in semi automated way

13
00:00:38,879 --> 00:00:44,550
so after considerations investigations I

14
00:00:42,360 --> 00:00:47,250
have come to conclusions that my and

15
00:00:44,550 --> 00:00:49,169
many other researchers you can move

16
00:00:47,250 --> 00:00:52,050
forward only by applying machine

17
00:00:49,170 --> 00:00:55,050
learning techniques and I am very

18
00:00:52,050 --> 00:00:57,769
grateful that I have colleagues that are

19
00:00:55,050 --> 00:01:00,209
much more knowledgeable in this field

20
00:00:57,770 --> 00:01:02,460
sadly machine learning is not the magic

21
00:01:00,210 --> 00:01:05,549
bullets it automatically solves all the

22
00:01:02,460 --> 00:01:08,659
problems it would be very nice it's

23
00:01:05,549 --> 00:01:14,189
applicability is highly dependent on the

24
00:01:08,659 --> 00:01:16,189
problem domain and also experts it seems

25
00:01:14,189 --> 00:01:18,600
that the approach of joining together

26
00:01:16,189 --> 00:01:23,158
machine learning experts and cyber

27
00:01:18,600 --> 00:01:25,640
experts is the most efficient way have

28
00:01:23,159 --> 00:01:29,100
to proceed because these fields are very

29
00:01:25,640 --> 00:01:31,829
large and complicated and becoming

30
00:01:29,100 --> 00:01:35,009
expert even in one is is quite

31
00:01:31,829 --> 00:01:38,309
problematic and today we are going to

32
00:01:35,009 --> 00:01:41,250
see machine learning experts that have

33
00:01:38,310 --> 00:01:46,439
joined as their forces to solve cyber

34
00:01:41,250 --> 00:01:49,200
problems in this session first we will

35
00:01:46,439 --> 00:01:51,689
have mr. Ilan mayor from MIT house

36
00:01:49,200 --> 00:01:53,479
eureka introduce us to their approach to

37
00:01:51,689 --> 00:01:57,658
detecting command and control channels

38
00:01:53,479 --> 00:02:00,020
our next panelist is dr. Roman graph

39
00:01:57,659 --> 00:02:03,570
from Austrian Institute of Technology

40
00:02:00,020 --> 00:02:05,579
who will explore applicability of neural

41
00:02:03,570 --> 00:02:08,970
networks for Android application

42
00:02:05,579 --> 00:02:12,930
classification and our third panelist

43
00:02:08,970 --> 00:02:13,740
professor Mikhail kyani from University

44
00:02:12,930 --> 00:02:16,470
of Modena

45
00:02:13,740 --> 00:02:19,110
and Reggio Emilia will provide closer

46
00:02:16,470 --> 00:02:23,960
look at the other sink adversarial a

47
00:02:19,110 --> 00:02:23,960
text against machine learning algorithms

48
00:02:24,650 --> 00:02:31,770
as you just heard we have very research

49
00:02:28,530 --> 00:02:33,750
centered panel we have distinguished

50
00:02:31,770 --> 00:02:38,130
speakers from two universities and one

51
00:02:33,750 --> 00:02:41,160
research organization and before we

52
00:02:38,130 --> 00:02:44,579
start just a few words about the format

53
00:02:41,160 --> 00:02:48,150
of this panel we have one half hours and

54
00:02:44,580 --> 00:02:50,120
three speakers every speaker has up to

55
00:02:48,150 --> 00:02:53,070
20 minutes to present the research after

56
00:02:50,120 --> 00:02:56,790
that he will have a chance to ask a

57
00:02:53,070 --> 00:02:59,100
couple questions for everyone so listen

58
00:02:56,790 --> 00:03:02,280
and come up with questions related to

59
00:02:59,100 --> 00:03:04,710
the specific presentation and please

60
00:03:02,280 --> 00:03:10,260
keep the questions short and concise and

61
00:03:04,710 --> 00:03:12,030
if you have something long long formal

62
00:03:10,260 --> 00:03:13,769
questions or discussions for specific

63
00:03:12,030 --> 00:03:15,690
topic you can always find the outers

64
00:03:13,770 --> 00:03:18,060
after the panels till the end of saikhan

65
00:03:15,690 --> 00:03:22,590
week and at the very end we will have

66
00:03:18,060 --> 00:03:24,570
about 10 minutes of panel discussion we

67
00:03:22,590 --> 00:03:27,570
will try to tie everything together and

68
00:03:24,570 --> 00:03:32,130
if you have topic you want to hear being

69
00:03:27,570 --> 00:03:35,820
discussed you can you can propose end so

70
00:03:32,130 --> 00:03:39,000
first stone you have mr. Ron mayor who

71
00:03:35,820 --> 00:03:42,420
is PhD student at the historic he is a

72
00:03:39,000 --> 00:03:44,700
part of networked systems group where he

73
00:03:42,420 --> 00:03:46,829
is research focuses on the security of

74
00:03:44,700 --> 00:03:49,530
computer networks in particular he works

75
00:03:46,830 --> 00:03:50,850
on solutions which leverage recent

76
00:03:49,530 --> 00:03:53,520
advances in network programming

77
00:03:50,850 --> 00:03:55,650
programming program ability to make

78
00:03:53,520 --> 00:03:58,650
networks able to detect and mitigate

79
00:03:55,650 --> 00:04:01,920
attacks and provide more security and

80
00:03:58,650 --> 00:04:05,160
privacy roland is presenting already sir

81
00:04:01,920 --> 00:04:08,459
dear and first one was in 2017 when he

82
00:04:05,160 --> 00:04:10,650
won junior scholar award his presented

83
00:04:08,460 --> 00:04:14,010
research investigates machine learning

84
00:04:10,650 --> 00:04:16,320
applicability for detecting of command

85
00:04:14,010 --> 00:04:19,140
and control channels in Lock shields

86
00:04:16,320 --> 00:04:22,580
defenders data set ok

87
00:04:19,140 --> 00:04:22,580
please roll on the floor is yours

88
00:04:26,020 --> 00:04:30,830
thank you very much and I'm very happy

89
00:04:27,979 --> 00:04:32,900
to present our work on detecting command

90
00:04:30,830 --> 00:04:35,539
and control channels in the Lock shields

91
00:04:32,900 --> 00:04:38,448
exercise here at saikhan most of this

92
00:04:35,539 --> 00:04:39,710
work was done by Nicholas kensic and the

93
00:04:38,449 --> 00:04:41,960
project was done for further

94
00:04:39,710 --> 00:04:44,870
collaboration with Luca combat sea and

95
00:04:41,960 --> 00:04:48,080
Vasa lenders from Armistice and Laurel

96
00:04:44,870 --> 00:04:50,240
and Weber from ETH Zurich to start with

97
00:04:48,080 --> 00:04:51,139
I'm sure all of you have heard headlines

98
00:04:50,240 --> 00:04:53,270
such as this one

99
00:04:51,139 --> 00:04:55,520
describing large-scale cyber attacks

100
00:04:53,270 --> 00:04:56,870
against critical infrastructure this is

101
00:04:55,520 --> 00:04:59,090
an example of a ransomware

102
00:04:56,870 --> 00:05:01,699
attack that hit many UK hospitals or

103
00:04:59,090 --> 00:05:04,369
another attack that was targeting the

104
00:05:01,699 --> 00:05:06,260
power grid in the Ukraine and apparently

105
00:05:04,370 --> 00:05:09,430
there was even a high tech war here in

106
00:05:06,260 --> 00:05:11,780
Estonia taking place two years ago and

107
00:05:09,430 --> 00:05:14,000
from a research point of view from what

108
00:05:11,780 --> 00:05:15,979
we are looking at these attacks are very

109
00:05:14,000 --> 00:05:18,139
interesting or would be very interesting

110
00:05:15,979 --> 00:05:20,659
to learn from but it's very difficult to

111
00:05:18,139 --> 00:05:22,849
get data so data in terms of for example

112
00:05:20,660 --> 00:05:25,849
network traffic that was exchanged and

113
00:05:22,849 --> 00:05:28,039
data that would be required to learn how

114
00:05:25,849 --> 00:05:31,430
we can defend against such attacks in

115
00:05:28,039 --> 00:05:33,380
the future however the last example was

116
00:05:31,430 --> 00:05:35,660
actually slightly different most of you

117
00:05:33,380 --> 00:05:37,430
probably realized that this was not a

118
00:05:35,660 --> 00:05:40,520
real war but this was just the log

119
00:05:37,430 --> 00:05:42,610
Shields exercise which takes place here

120
00:05:40,520 --> 00:05:46,900
every year and in fact it's the largest

121
00:05:42,610 --> 00:05:50,720
cyber defence exercise of its kind and

122
00:05:46,900 --> 00:05:52,159
it is a red team vs. blue team exercise

123
00:05:50,720 --> 00:05:54,590
which means there is a right team

124
00:05:52,159 --> 00:05:56,240
running attacks against blue teams which

125
00:05:54,590 --> 00:05:58,429
have to defend against the attacks and

126
00:05:56,240 --> 00:06:00,440
in the case of log kills the the red

127
00:05:58,430 --> 00:06:03,620
team is one central team and the blue

128
00:06:00,440 --> 00:06:08,300
team are usually one blue team per

129
00:06:03,620 --> 00:06:09,560
participating country this attack this

130
00:06:08,300 --> 00:06:11,539
exercise launched

131
00:06:09,560 --> 00:06:15,080
runs at a very large scale with over

132
00:06:11,539 --> 00:06:18,199
1,000 experts in the intervals of these

133
00:06:15,080 --> 00:06:20,180
red and blue teams and these experts

134
00:06:18,199 --> 00:06:22,039
come from all over the world there are

135
00:06:20,180 --> 00:06:24,680
thousands of systems that are attacked

136
00:06:22,039 --> 00:06:27,530
and thousands of attacks that are run

137
00:06:24,680 --> 00:06:32,300
over a period of up of about two days of

138
00:06:27,530 --> 00:06:34,609
this exercise and the unique thing about

139
00:06:32,300 --> 00:06:37,700
this exercise is compared to real

140
00:06:34,610 --> 00:06:39,650
incidents that we do not only have to

141
00:06:37,700 --> 00:06:41,810
in terms of the network traffic that was

142
00:06:39,650 --> 00:06:43,640
exchanged during the exercise but we

143
00:06:41,810 --> 00:06:45,680
also have a ground truth which tells us

144
00:06:43,640 --> 00:06:48,080
what the attackers were doing or so what

145
00:06:45,680 --> 00:06:50,050
the red team was doing and what the

146
00:06:48,080 --> 00:06:52,609
infrastructure was that they were using

147
00:06:50,050 --> 00:06:54,920
to run the attacks this you usually

148
00:06:52,610 --> 00:06:56,510
don't have in the case of normal attacks

149
00:06:54,920 --> 00:06:58,760
because the attackers will not tell you

150
00:06:56,510 --> 00:07:01,610
what they did you only know what you

151
00:06:58,760 --> 00:07:04,400
found out yourself through forensics for

152
00:07:01,610 --> 00:07:08,270
example and the goal of our project was

153
00:07:04,400 --> 00:07:10,909
that we got the data from the Swiss blue

154
00:07:08,270 --> 00:07:12,830
team in this log shields exercise and we

155
00:07:10,910 --> 00:07:14,480
wanted to develop a system that helped

156
00:07:12,830 --> 00:07:17,450
the Swiss blue team or blue teams in

157
00:07:14,480 --> 00:07:19,910
general to improve their defense in the

158
00:07:17,450 --> 00:07:22,550
following years and what we could

159
00:07:19,910 --> 00:07:25,130
already tell from the evaluation results

160
00:07:22,550 --> 00:07:27,260
that we got with our data is that if the

161
00:07:25,130 --> 00:07:29,810
Swiss blue team had used our system in

162
00:07:27,260 --> 00:07:31,580
2018 they could have discovered more

163
00:07:29,810 --> 00:07:34,310
than 80 percent of the command and

164
00:07:31,580 --> 00:07:36,890
control servers by looking only at data

165
00:07:34,310 --> 00:07:40,040
that was exchanged over about 30 minutes

166
00:07:36,890 --> 00:07:42,080
of the first day of the exercise I will

167
00:07:40,040 --> 00:07:44,390
later present you more results from our

168
00:07:42,080 --> 00:07:46,820
evaluation but first I would like to

169
00:07:44,390 --> 00:07:48,440
cover two other parts in the first part

170
00:07:46,820 --> 00:07:50,420
I will speak a bit more about locked

171
00:07:48,440 --> 00:07:52,640
shields and how it works from a more

172
00:07:50,420 --> 00:07:54,650
technical perspective then I will

173
00:07:52,640 --> 00:07:58,550
present you how our system works that

174
00:07:54,650 --> 00:08:01,250
that takes network traffic and tells the

175
00:07:58,550 --> 00:08:04,490
defenders which of these flows are

176
00:08:01,250 --> 00:08:06,620
command and control flows before I will

177
00:08:04,490 --> 00:08:09,710
present you more evaluation results in

178
00:08:06,620 --> 00:08:12,250
the last part so a few more words about

179
00:08:09,710 --> 00:08:14,659
locked shields I already told you that

180
00:08:12,250 --> 00:08:17,390
there are blue teams that have to defend

181
00:08:14,660 --> 00:08:19,820
their network and such a network is a

182
00:08:17,390 --> 00:08:21,890
very fairly big for example it can be

183
00:08:19,820 --> 00:08:24,980
the one of a military airbase which

184
00:08:21,890 --> 00:08:29,060
consists of Industry control systems of

185
00:08:24,980 --> 00:08:31,640
maybe air vehicles of traditional coma

186
00:08:29,060 --> 00:08:33,650
and client-server infrastructure and so

187
00:08:31,640 --> 00:08:36,530
on so we have many different systems

188
00:08:33,650 --> 00:08:38,090
that have potentially vulnerabilities

189
00:08:36,530 --> 00:08:41,900
and can be attacked by the right team

190
00:08:38,090 --> 00:08:43,669
and then there is a for each blue team

191
00:08:41,900 --> 00:08:45,319
that is participating there is one

192
00:08:43,669 --> 00:08:47,810
instance of such a network or such a

193
00:08:45,320 --> 00:08:50,089
virtualized Network and there is one

194
00:08:47,810 --> 00:08:50,739
central right team that is running

195
00:08:50,089 --> 00:08:54,160
attacks

196
00:08:50,740 --> 00:08:56,380
and all these networks and the red team

197
00:08:54,160 --> 00:08:58,630
is quite free to use whatever techniques

198
00:08:56,380 --> 00:09:01,120
they want to attack but at least part of

199
00:08:58,630 --> 00:09:02,950
the attacks are run over a command and

200
00:09:01,120 --> 00:09:05,950
control infrastructure in that case

201
00:09:02,950 --> 00:09:07,649
using the COBOL strike framework so

202
00:09:05,950 --> 00:09:09,910
therefore the setting for the red team

203
00:09:07,649 --> 00:09:12,399
during lob shields even though it's only

204
00:09:09,910 --> 00:09:14,829
an exercise it's very realistic

205
00:09:12,399 --> 00:09:17,110
these are very skilled people that are

206
00:09:14,830 --> 00:09:18,670
experts for different types of devices

207
00:09:17,110 --> 00:09:20,980
they know how to run attacks against

208
00:09:18,670 --> 00:09:22,930
these devices and at least part of the

209
00:09:20,980 --> 00:09:25,899
attacks are on over a control command

210
00:09:22,930 --> 00:09:27,880
control infrastructure on the other hand

211
00:09:25,899 --> 00:09:31,240
we have two blue teams which need to

212
00:09:27,880 --> 00:09:35,399
defend their network there is one blue

213
00:09:31,240 --> 00:09:38,290
team for each network and usually it's

214
00:09:35,399 --> 00:09:40,870
one blue team per participating country

215
00:09:38,290 --> 00:09:42,939
and these blue teams they can access the

216
00:09:40,870 --> 00:09:45,399
network that they need to defend over a

217
00:09:42,940 --> 00:09:48,459
remote connection over a VPN tunnel and

218
00:09:45,399 --> 00:09:50,800
they have some virtual machines some

219
00:09:48,459 --> 00:09:53,709
devices where they can run their systems

220
00:09:50,800 --> 00:09:56,170
within the within the network that they

221
00:09:53,709 --> 00:09:57,640
need to defend and these two things I

222
00:09:56,170 --> 00:10:00,160
mention it because it's important for

223
00:09:57,640 --> 00:10:02,230
the approach that we developed and these

224
00:10:00,160 --> 00:10:03,790
are two constraint that first the

225
00:10:02,230 --> 00:10:05,860
bandwidth that they can use to access

226
00:10:03,790 --> 00:10:07,719
their network is limited so it's not

227
00:10:05,860 --> 00:10:10,089
possible to exchange large amount of

228
00:10:07,720 --> 00:10:13,029
data between where the blue team is and

229
00:10:10,089 --> 00:10:16,570
the network that they need to defend and

230
00:10:13,029 --> 00:10:17,829
second the infrastructure these virtual

231
00:10:16,570 --> 00:10:20,370
machines that they can use to run

232
00:10:17,829 --> 00:10:22,479
attacks are limited in terms of

233
00:10:20,370 --> 00:10:24,399
computing power and in terms of memory

234
00:10:22,480 --> 00:10:28,240
so it's also not possible to run very

235
00:10:24,399 --> 00:10:31,180
complex systems within this network in

236
00:10:28,240 --> 00:10:34,779
general also the blue team setting is

237
00:10:31,180 --> 00:10:37,569
very realistic despite even though it's

238
00:10:34,779 --> 00:10:39,430
only an exercise and when the blue team

239
00:10:37,570 --> 00:10:41,170
arrives the network is already under

240
00:10:39,430 --> 00:10:44,529
attack and some systems are already

241
00:10:41,170 --> 00:10:47,140
compromised and as usually it's not not

242
00:10:44,529 --> 00:10:48,939
only the they do not only need to

243
00:10:47,140 --> 00:10:51,250
defense the network but they also need

244
00:10:48,940 --> 00:10:54,700
to may keep its availability because

245
00:10:51,250 --> 00:10:57,579
there are normal users that need to use

246
00:10:54,700 --> 00:10:59,500
the network for checking their emails or

247
00:10:57,579 --> 00:11:01,359
browsing the web or whatever so just

248
00:10:59,500 --> 00:11:03,980
turning everything off cleaning it and

249
00:11:01,360 --> 00:11:08,030
starting it again it's not the solution

250
00:11:03,980 --> 00:11:09,710
for the defenders so that was the part

251
00:11:08,030 --> 00:11:11,900
about locked shields and now I would

252
00:11:09,710 --> 00:11:14,780
like to describe the system that we use

253
00:11:11,900 --> 00:11:18,459
to in that context of Lock shields

254
00:11:14,780 --> 00:11:21,740
detect command and control servers we

255
00:11:18,460 --> 00:11:24,230
started by our goal which was to have a

256
00:11:21,740 --> 00:11:26,180
classifier that can tell you given

257
00:11:24,230 --> 00:11:28,400
network traffic which of this traffic is

258
00:11:26,180 --> 00:11:30,560
commander control and which is other

259
00:11:28,400 --> 00:11:33,620
traffic that referred to as normal

260
00:11:30,560 --> 00:11:36,140
traffic here so in the end we want you

261
00:11:33,620 --> 00:11:38,480
to end up with such a classifier in the

262
00:11:36,140 --> 00:11:40,819
beginning we had as input data we had

263
00:11:38,480 --> 00:11:44,450
the network traffic from the Swiss blue

264
00:11:40,820 --> 00:11:46,640
team and we also had the recordings of

265
00:11:44,450 --> 00:11:49,970
the activities of the provided by the

266
00:11:46,640 --> 00:11:52,720
Red Team that we could use to as a

267
00:11:49,970 --> 00:11:56,000
ground truth for this network traffic as

268
00:11:52,720 --> 00:11:58,460
usual in machine learning projects we

269
00:11:56,000 --> 00:12:01,790
then splits our pipeline into two phases

270
00:11:58,460 --> 00:12:04,280
first of all we had an offline phase for

271
00:12:01,790 --> 00:12:06,800
the training which is done before the

272
00:12:04,280 --> 00:12:09,319
exercise and which is not time critical

273
00:12:06,800 --> 00:12:12,890
and the second phase is the online phase

274
00:12:09,320 --> 00:12:15,800
where the classifier is applied in

275
00:12:12,890 --> 00:12:19,730
real-time to a network traffic during

276
00:12:15,800 --> 00:12:22,160
the lab chills exercise we further split

277
00:12:19,730 --> 00:12:24,620
each of the phases into four steps where

278
00:12:22,160 --> 00:12:26,719
we first get the data for example from

279
00:12:24,620 --> 00:12:29,600
the recorded data of past year's

280
00:12:26,720 --> 00:12:31,760
exercises and from the reports that are

281
00:12:29,600 --> 00:12:33,650
provided then we need to do some

282
00:12:31,760 --> 00:12:36,439
pre-processing which is more a technical

283
00:12:33,650 --> 00:12:38,870
detail to align the information that we

284
00:12:36,440 --> 00:12:41,720
get from the network traffic and from

285
00:12:38,870 --> 00:12:44,330
the reports then we extract features

286
00:12:41,720 --> 00:12:46,400
features are kind of properties that we

287
00:12:44,330 --> 00:12:49,550
use later to distinguish between command

288
00:12:46,400 --> 00:12:52,010
and control flows and other flows we

289
00:12:49,550 --> 00:12:54,680
then come to the machine learning part

290
00:12:52,010 --> 00:12:56,330
where we label the data so we have a

291
00:12:54,680 --> 00:12:58,040
list of flows we have all the features

292
00:12:56,330 --> 00:13:01,010
that we extracted for all the flows and

293
00:12:58,040 --> 00:13:02,660
now we need to add a label so for each

294
00:13:01,010 --> 00:13:04,700
of the flows we need to say whether it

295
00:13:02,660 --> 00:13:08,480
is normal traffic or command-and-control

296
00:13:04,700 --> 00:13:11,180
traffic and once we have this we can use

297
00:13:08,480 --> 00:13:12,500
this information to select a subset of

298
00:13:11,180 --> 00:13:15,170
the features that we previously

299
00:13:12,500 --> 00:13:16,760
extracted this is done in order to make

300
00:13:15,170 --> 00:13:17,290
the system more efficient and more

301
00:13:16,760 --> 00:13:20,680
perform

302
00:13:17,290 --> 00:13:22,990
and after we selected the features that

303
00:13:20,680 --> 00:13:25,780
we used we can train the classifier

304
00:13:22,990 --> 00:13:27,910
based on these features and we end up

305
00:13:25,780 --> 00:13:31,000
with a classifier that we can then apply

306
00:13:27,910 --> 00:13:33,280
to traffic in real time that is captured

307
00:13:31,000 --> 00:13:35,110
during the exercise where we extract the

308
00:13:33,280 --> 00:13:36,699
same features and get a label for all

309
00:13:35,110 --> 00:13:40,210
the flows afterwards whether it is a

310
00:13:36,700 --> 00:13:42,340
command and control flow or not so this

311
00:13:40,210 --> 00:13:44,650
is the overview of the entire system

312
00:13:42,340 --> 00:13:46,240
that we were developing here and I will

313
00:13:44,650 --> 00:13:48,430
now go a bit more into the details of

314
00:13:46,240 --> 00:13:51,850
some of the phases here starting with

315
00:13:48,430 --> 00:13:54,699
the feature extraction here we used we

316
00:13:51,850 --> 00:13:56,850
extracted 77 widely used network traffic

317
00:13:54,700 --> 00:13:59,890
features of three different categories

318
00:13:56,850 --> 00:14:01,750
first we had metadata such as the flow

319
00:13:59,890 --> 00:14:04,449
direction or which protocols were used

320
00:14:01,750 --> 00:14:06,160
then we had time related features such

321
00:14:04,450 --> 00:14:08,770
as how long a flow takes or how many

322
00:14:06,160 --> 00:14:11,079
packets it sends per second and third we

323
00:14:08,770 --> 00:14:13,090
had volume related to be features which

324
00:14:11,080 --> 00:14:15,760
include features such as the number of

325
00:14:13,090 --> 00:14:18,250
packets or how many bytes are exchanged

326
00:14:15,760 --> 00:14:22,930
per flow or how big the individual

327
00:14:18,250 --> 00:14:27,250
packets are so we have about or we have

328
00:14:22,930 --> 00:14:30,430
77 features of this kind and we compute

329
00:14:27,250 --> 00:14:34,030
all of them we then have a list of all

330
00:14:30,430 --> 00:14:36,280
the flows to and 77 features assigned to

331
00:14:34,030 --> 00:14:38,620
each of the flows and we now need to

332
00:14:36,280 --> 00:14:41,020
compute the label for the flows and this

333
00:14:38,620 --> 00:14:43,450
is fairly simple we get from the Red

334
00:14:41,020 --> 00:14:45,189
Team reports a list of all the command

335
00:14:43,450 --> 00:14:47,740
and control servers that they were using

336
00:14:45,190 --> 00:14:50,230
and whenever a flow either has the

337
00:14:47,740 --> 00:14:51,940
source or the destination as one of

338
00:14:50,230 --> 00:14:54,190
these servers we label it as a command

339
00:14:51,940 --> 00:14:57,400
or control flow and if not we label it

340
00:14:54,190 --> 00:15:00,850
as a normal flow so at this point we

341
00:14:57,400 --> 00:15:04,840
have a list of the closed features and

342
00:15:00,850 --> 00:15:06,520
labels and we can use this to select to

343
00:15:04,840 --> 00:15:08,800
reduce now the set of features that we

344
00:15:06,520 --> 00:15:11,500
need to consider to make the system more

345
00:15:08,800 --> 00:15:13,540
efficient that to make it run in the

346
00:15:11,500 --> 00:15:16,900
restricted environment of the log fields

347
00:15:13,540 --> 00:15:18,969
exercise and to reduce the set of

348
00:15:16,900 --> 00:15:21,880
features we apply kind of a recursive

349
00:15:18,970 --> 00:15:23,740
elimination scheme where we first train

350
00:15:21,880 --> 00:15:25,870
a random forest model on all the

351
00:15:23,740 --> 00:15:29,020
features that we have so 77 in the

352
00:15:25,870 --> 00:15:30,310
beginning this then gives us a score for

353
00:15:29,020 --> 00:15:32,079
each feature of how

354
00:15:30,310 --> 00:15:35,020
this feature contributed to the

355
00:15:32,080 --> 00:15:37,120
classification result and we can remove

356
00:15:35,020 --> 00:15:39,250
just the feature with the lowest

357
00:15:37,120 --> 00:15:42,460
contributions or the least important

358
00:15:39,250 --> 00:15:46,140
feature write it to a list and remove it

359
00:15:42,460 --> 00:15:48,339
from our set start entire process again

360
00:15:46,140 --> 00:15:50,260
after the second iteration we will

361
00:15:48,339 --> 00:15:52,720
remove the second least important

362
00:15:50,260 --> 00:15:54,970
feature and so on until we have no

363
00:15:52,720 --> 00:15:56,620
features left in our set that we use for

364
00:15:54,970 --> 00:15:59,470
the training and we have a list of

365
00:15:56,620 --> 00:16:02,800
features ranked in increasing importance

366
00:15:59,470 --> 00:16:05,110
and later if we want to use the 20 most

367
00:16:02,800 --> 00:16:09,430
important features we just take the

368
00:16:05,110 --> 00:16:12,040
lowest 20 entries of this list so the

369
00:16:09,430 --> 00:16:13,810
next question now is or next task now is

370
00:16:12,040 --> 00:16:15,969
to train a classifier and the question

371
00:16:13,810 --> 00:16:19,599
here is which one we take there are many

372
00:16:15,970 --> 00:16:22,960
different classifiers usable in machine

373
00:16:19,600 --> 00:16:27,460
learning and for our circumstances where

374
00:16:22,960 --> 00:16:29,290
we had one set one challenge which is

375
00:16:27,460 --> 00:16:32,500
that while the command-and-control

376
00:16:29,290 --> 00:16:34,540
traffic is expected to be similar over

377
00:16:32,500 --> 00:16:35,860
many iterations of log shields the

378
00:16:34,540 --> 00:16:37,750
normal traffic is probably very

379
00:16:35,860 --> 00:16:39,730
different because the network might

380
00:16:37,750 --> 00:16:42,010
change a lot so maybe one year it's a

381
00:16:39,730 --> 00:16:45,040
military air based network another year

382
00:16:42,010 --> 00:16:47,980
it's a network of a city and we also

383
00:16:45,040 --> 00:16:50,380
have the constraints of the limited

384
00:16:47,980 --> 00:16:52,660
computing and memory that is available

385
00:16:50,380 --> 00:16:56,290
and that we want to have a system that

386
00:16:52,660 --> 00:16:59,500
performs in classification in the real

387
00:16:56,290 --> 00:17:01,870
time or at least close to real time what

388
00:16:59,500 --> 00:17:04,420
we observed over after trying many

389
00:17:01,870 --> 00:17:06,609
different model is that a very simple

390
00:17:04,420 --> 00:17:10,360
one works very well and that is random

391
00:17:06,609 --> 00:17:13,030
forests and so these models are very

392
00:17:10,359 --> 00:17:16,629
efficient to compute and they achieve

393
00:17:13,030 --> 00:17:18,849
good results as I will show later ok so

394
00:17:16,630 --> 00:17:21,520
now at this point we have our classifier

395
00:17:18,849 --> 00:17:23,740
and now we can apply it in real time on

396
00:17:21,520 --> 00:17:27,939
the network traffic that is exchanged

397
00:17:23,740 --> 00:17:29,620
during locked shields now if this I come

398
00:17:27,939 --> 00:17:32,920
to the third part of my talk where I

399
00:17:29,620 --> 00:17:34,959
want to share some evaluation results we

400
00:17:32,920 --> 00:17:36,730
did this evaluation based on two data

401
00:17:34,960 --> 00:17:38,530
sets that we obtained by the Swiss blue

402
00:17:36,730 --> 00:17:41,980
team and these are the data sets from

403
00:17:38,530 --> 00:17:43,720
locked chills 2000 17 and 18 which gives

404
00:17:41,980 --> 00:17:44,350
us the possibility to have two models

405
00:17:43,720 --> 00:17:47,080
one

406
00:17:44,350 --> 00:17:49,360
that we train on the data from 17 and

407
00:17:47,080 --> 00:17:51,939
evaluate with data from 18 and the other

408
00:17:49,360 --> 00:17:55,719
one that we train on data from 2018 and

409
00:17:51,940 --> 00:17:57,700
test with data from 2017 again this is a

410
00:17:55,720 --> 00:18:00,340
very nice situation where we have two

411
00:17:57,700 --> 00:18:01,660
real data sets that are independent

412
00:18:00,340 --> 00:18:03,310
because they are from two different

413
00:18:01,660 --> 00:18:06,340
years of locked shields and they are

414
00:18:03,310 --> 00:18:08,710
realistic because it's it represent or

415
00:18:06,340 --> 00:18:10,540
it contains traffic generated by humans

416
00:18:08,710 --> 00:18:13,870
by skilled attackers and skilled

417
00:18:10,540 --> 00:18:15,610
defenders which is very rare to be in

418
00:18:13,870 --> 00:18:18,939
such a nice situation when you do

419
00:18:15,610 --> 00:18:20,620
machine learning we then train these

420
00:18:18,940 --> 00:18:23,380
models we tried many different

421
00:18:20,620 --> 00:18:26,379
parameters and found that these ones

422
00:18:23,380 --> 00:18:29,890
obtain good results if we take random

423
00:18:26,380 --> 00:18:32,590
forests with 128 trees each tree maximum

424
00:18:29,890 --> 00:18:35,320
depth of 10 and we take the 20 most

425
00:18:32,590 --> 00:18:38,080
important features so when you do

426
00:18:35,320 --> 00:18:40,210
machine learning that one important

427
00:18:38,080 --> 00:18:42,810
score for the evaluation or 2 importance

428
00:18:40,210 --> 00:18:45,790
course or precision and recall and

429
00:18:42,810 --> 00:18:47,740
precision kind of tells you if you get

430
00:18:45,790 --> 00:18:50,500
an alert what is the probability that

431
00:18:47,740 --> 00:18:53,230
this alert was actually a true alert so

432
00:18:50,500 --> 00:18:56,110
it represents real Emily Emily malicious

433
00:18:53,230 --> 00:18:58,330
or command control flow and recall is if

434
00:18:56,110 --> 00:19:00,939
you take all the alerts that you get how

435
00:18:58,330 --> 00:19:03,429
much of the command and control flows

436
00:19:00,940 --> 00:19:05,710
did you cover or data system cover with

437
00:19:03,430 --> 00:19:08,650
these alerts and especially the

438
00:19:05,710 --> 00:19:10,560
precision is quite important because if

439
00:19:08,650 --> 00:19:13,810
you have low precision it means you get

440
00:19:10,560 --> 00:19:15,960
many falls alert and in the environment

441
00:19:13,810 --> 00:19:19,540
of log fields where you need to run this

442
00:19:15,960 --> 00:19:21,850
in in real time and the defenders need

443
00:19:19,540 --> 00:19:25,050
to decide quickly whether or not an

444
00:19:21,850 --> 00:19:27,520
alert is true or not it would be

445
00:19:25,050 --> 00:19:30,220
suboptimal to have many false positive

446
00:19:27,520 --> 00:19:32,860
alerts what we observed is that our

447
00:19:30,220 --> 00:19:36,570
models achieve more than 99 precision

448
00:19:32,860 --> 00:19:41,350
and also higher currency of 98 or 90%

449
00:19:36,570 --> 00:19:43,240
depending on the model the next aspect

450
00:19:41,350 --> 00:19:44,169
that is important is the run time

451
00:19:43,240 --> 00:19:46,660
because we want to have the

452
00:19:44,170 --> 00:19:49,960
classification in real time or as close

453
00:19:46,660 --> 00:19:53,140
as possible to real time and there what

454
00:19:49,960 --> 00:19:56,410
we found is that on our machine it takes

455
00:19:53,140 --> 00:19:59,010
about three microseconds to classify one

456
00:19:56,410 --> 00:20:02,500
flow which is very fast

457
00:19:59,010 --> 00:20:04,570
so now that I presented this approach

458
00:20:02,500 --> 00:20:07,540
here and that maybe if members of the

459
00:20:04,570 --> 00:20:09,270
right teams are listening they might ask

460
00:20:07,540 --> 00:20:11,500
themselves how can we avoid this

461
00:20:09,270 --> 00:20:13,600
classification so how can we modify the

462
00:20:11,500 --> 00:20:15,760
command and control traffic such that

463
00:20:13,600 --> 00:20:17,830
this classifier does not detect it

464
00:20:15,760 --> 00:20:18,970
anymore and of course this is always a

465
00:20:17,830 --> 00:20:20,740
problem when you do machine learning

466
00:20:18,970 --> 00:20:24,310
there will be a talk later about

467
00:20:20,740 --> 00:20:26,650
adversarial machine learning and we also

468
00:20:24,310 --> 00:20:29,290
did some steps in this direction I think

469
00:20:26,650 --> 00:20:32,350
there is more work to do but what we did

470
00:20:29,290 --> 00:20:35,860
so far is that we looked at what happens

471
00:20:32,350 --> 00:20:37,990
if the blue team can obfuscate some of

472
00:20:35,860 --> 00:20:40,810
the features that we are using to do the

473
00:20:37,990 --> 00:20:44,830
classification so features like the

474
00:20:40,810 --> 00:20:49,810
packet size timing aspects or the volume

475
00:20:44,830 --> 00:20:51,939
of flows and what we found is that up to

476
00:20:49,810 --> 00:20:55,270
eight features so vias were zooming here

477
00:20:51,940 --> 00:20:56,800
the red team can choose the eight most

478
00:20:55,270 --> 00:20:58,840
important features from our list

479
00:20:56,800 --> 00:21:01,540
arbitrarily so we cannot use them

480
00:20:58,840 --> 00:21:03,340
anymore for classification we observe

481
00:21:01,540 --> 00:21:05,080
that there is no impact on the

482
00:21:03,340 --> 00:21:07,379
classification result and only if you

483
00:21:05,080 --> 00:21:10,090
modify more than eight features which is

484
00:21:07,380 --> 00:21:12,070
highly non-trivial in practice then you

485
00:21:10,090 --> 00:21:17,169
would see the score dropping at least

486
00:21:12,070 --> 00:21:18,939
four in this dataset so that was it for

487
00:21:17,170 --> 00:21:21,190
the evaluation that we also have in the

488
00:21:18,940 --> 00:21:23,470
paper and where you can find much more

489
00:21:21,190 --> 00:21:26,770
details in a paper in the last two

490
00:21:23,470 --> 00:21:28,930
minutes I would now like to share more

491
00:21:26,770 --> 00:21:30,670
insights about something that is not in

492
00:21:28,930 --> 00:21:32,500
the paper because it's very recent and

493
00:21:30,670 --> 00:21:34,230
this is that the Swiss blue team

494
00:21:32,500 --> 00:21:37,360
actually used that system in log chillz

495
00:21:34,230 --> 00:21:41,350
2019 just a few weeks ago and from the

496
00:21:37,360 --> 00:21:43,659
feedback that we got we were happy about

497
00:21:41,350 --> 00:21:45,399
happy to hear that it actually helped

498
00:21:43,660 --> 00:21:48,280
them to discover command and control

499
00:21:45,400 --> 00:21:50,830
channels that they didn't see by other

500
00:21:48,280 --> 00:21:52,930
means and it also helped them to confirm

501
00:21:50,830 --> 00:21:54,100
alerts that they got from other systems

502
00:21:52,930 --> 00:21:56,590
or maybe other intrusion detection

503
00:21:54,100 --> 00:21:58,090
systems but because they had an

504
00:21:56,590 --> 00:21:59,679
independent source here of the same

505
00:21:58,090 --> 00:22:02,560
alert they could be more certain that

506
00:21:59,680 --> 00:22:04,690
this is really a malicious server behind

507
00:22:02,560 --> 00:22:08,379
it or a command and control server

508
00:22:04,690 --> 00:22:11,060
behind it they used exactly the same

509
00:22:08,380 --> 00:22:15,680
models that we reused

510
00:22:11,060 --> 00:22:17,720
in that we developed in our project the

511
00:22:15,680 --> 00:22:19,550
user a slightly different way to extract

512
00:22:17,720 --> 00:22:21,950
the features because their workflow was

513
00:22:19,550 --> 00:22:24,560
slightly different and the this might

514
00:22:21,950 --> 00:22:26,420
have had a small impact on the results

515
00:22:24,560 --> 00:22:28,280
but again from the feedback that we got

516
00:22:26,420 --> 00:22:30,080
is that they were happy with the hydro

517
00:22:28,280 --> 00:22:32,660
positive rate and it helped them to

518
00:22:30,080 --> 00:22:34,280
detect command and control servers that

519
00:22:32,660 --> 00:22:36,410
they didn't detect otherwise or to

520
00:22:34,280 --> 00:22:40,760
confirm result or alerts that they got

521
00:22:36,410 --> 00:22:42,230
from other systems with this I come to

522
00:22:40,760 --> 00:22:44,120
the end of my talk I hope I could show

523
00:22:42,230 --> 00:22:46,280
you how we identified command and

524
00:22:44,120 --> 00:22:50,620
control channels at the example of the

525
00:22:46,280 --> 00:22:53,960
lock yields exercise we did all these

526
00:22:50,620 --> 00:22:55,370
evaluation development with data from

527
00:22:53,960 --> 00:22:57,680
the Swiss blue team we are extremely

528
00:22:55,370 --> 00:22:59,479
thankful for this collaboration for that

529
00:22:57,680 --> 00:23:02,180
they shared the data and their expertise

530
00:22:59,480 --> 00:23:03,980
with us if there are blue teams of other

531
00:23:02,180 --> 00:23:06,440
countries that are interested in testing

532
00:23:03,980 --> 00:23:08,300
this system or collaborating with us to

533
00:23:06,440 --> 00:23:11,210
develop it further we are very

534
00:23:08,300 --> 00:23:13,430
interested in and these approaches in

535
00:23:11,210 --> 00:23:15,290
that case also if you have more

536
00:23:13,430 --> 00:23:18,290
questions the first four authors of the

537
00:23:15,290 --> 00:23:20,360
paper are here at saikhan and please

538
00:23:18,290 --> 00:23:22,250
approach any of us if you want to know

539
00:23:20,360 --> 00:23:26,500
more about the system and I'm also very

540
00:23:22,250 --> 00:23:26,500
happy to answer questions now thank you

541
00:23:26,970 --> 00:23:33,980
[Applause]

542
00:23:31,600 --> 00:23:37,310
thank you all for your insights into

543
00:23:33,980 --> 00:23:38,840
detecting team activities we have the

544
00:23:37,310 --> 00:23:40,060
time for a few questions from the

545
00:23:38,840 --> 00:23:43,790
audience

546
00:23:40,060 --> 00:23:45,710
okay the microphone is coming towards

547
00:23:43,790 --> 00:23:48,020
you

548
00:23:45,710 --> 00:23:53,950
thanks for your talk did you try the

549
00:23:48,020 --> 00:23:57,950
model in a real real world scenario and

550
00:23:53,950 --> 00:24:00,350
not so far nope okay because we we don't

551
00:23:57,950 --> 00:24:06,500
have a comparable data set to test it

552
00:24:00,350 --> 00:24:09,350
there but you but you just using the the

553
00:24:06,500 --> 00:24:12,650
various features anyway so who didn't

554
00:24:09,350 --> 00:24:16,340
matter if yes well that there are papers

555
00:24:12,650 --> 00:24:18,590
that show that exactly random forest in

556
00:24:16,340 --> 00:24:20,629
in other data set there were that were

557
00:24:18,590 --> 00:24:23,120
synthetically generated to work very

558
00:24:20,630 --> 00:24:24,680
well so we expect we would have the same

559
00:24:23,120 --> 00:24:28,550
results for this

560
00:24:24,680 --> 00:24:30,080
other data set but we were focusing here

561
00:24:28,550 --> 00:24:38,570
on the on the locked shields and yet

562
00:24:30,080 --> 00:24:41,510
elevators okay okay thank you for the

563
00:24:38,570 --> 00:24:43,340
presentation it's a pity that the domain

564
00:24:41,510 --> 00:24:46,520
controller people didn't perform better

565
00:24:43,340 --> 00:24:49,429
in our blue team despite the fact that

566
00:24:46,520 --> 00:24:52,190
we had do list information so the result

567
00:24:49,430 --> 00:24:57,470
was not so good but that's it

568
00:24:52,190 --> 00:25:01,480
is there is the route dependent is the

569
00:24:57,470 --> 00:25:01,480
training set you obtained or the Train

570
00:25:01,960 --> 00:25:10,480
machine from the tools used by the by

571
00:25:06,650 --> 00:25:15,350
the by the red team or how could one

572
00:25:10,480 --> 00:25:19,130
enlarge the number of recognized command

573
00:25:15,350 --> 00:25:22,250
control channels using auto perhaps a

574
00:25:19,130 --> 00:25:25,340
tool sets and attack tools you mean

575
00:25:22,250 --> 00:25:30,500
other other command control infrared at

576
00:25:25,340 --> 00:25:32,240
holes etc I think right now so it's

577
00:25:30,500 --> 00:25:34,070
always what you train the system with

578
00:25:32,240 --> 00:25:35,990
this is what you can detect later so

579
00:25:34,070 --> 00:25:39,409
since we train it with this command

580
00:25:35,990 --> 00:25:42,110
control traffic generated using cobalt

581
00:25:39,410 --> 00:25:44,929
strike it will detect this if we include

582
00:25:42,110 --> 00:25:47,389
other types of attack traffic I would

583
00:25:44,929 --> 00:25:49,910
expect we can also detect other types of

584
00:25:47,390 --> 00:25:51,860
of command and control actually

585
00:25:49,910 --> 00:25:54,890
what is nice if you do if you have this

586
00:25:51,860 --> 00:25:56,659
command control channels is that you

587
00:25:54,890 --> 00:26:00,050
kind of can attack at the root of the

588
00:25:56,660 --> 00:26:02,000
problem and you don't get to the very

589
00:26:00,050 --> 00:26:05,480
deep attacks that are probably very

590
00:26:02,000 --> 00:26:07,400
different if two very particular attacks

591
00:26:05,480 --> 00:26:08,840
that cause different traffic depending

592
00:26:07,400 --> 00:26:11,110
on on the environment in which you're

593
00:26:08,840 --> 00:26:11,110
under

594
00:26:11,870 --> 00:26:18,199
okayhow question from the back yeah cool

595
00:26:14,840 --> 00:26:20,090
presentation first you used your tool

596
00:26:18,200 --> 00:26:22,730
just for detection or also for

597
00:26:20,090 --> 00:26:25,850
prevention to help the blue team and the

598
00:26:22,730 --> 00:26:29,320
second part of the question is if so do

599
00:26:25,850 --> 00:26:29,320
you see adaptation from the red team

600
00:26:29,950 --> 00:26:35,480
sir can you repeat the second part yeah

601
00:26:32,420 --> 00:26:37,970
so this is detection tool yeah

602
00:26:35,480 --> 00:26:40,100
but the added value is to go into

603
00:26:37,970 --> 00:26:42,650
prevention what you detect as a CNC you

604
00:26:40,100 --> 00:26:43,669
block it yes with automation or what

605
00:26:42,650 --> 00:26:46,550
whatsoever you want you want to

606
00:26:43,670 --> 00:26:50,179
integrate with with solution did you

607
00:26:46,550 --> 00:26:53,480
well did the blue team did prevention

608
00:26:50,179 --> 00:26:57,290
based on your observation and if so is

609
00:26:53,480 --> 00:27:01,840
the red team also even evolving into the

610
00:26:57,290 --> 00:27:05,360
attacks or it just launching the attacks

611
00:27:01,840 --> 00:27:07,490
so I'm I'm not part of the blue team I I

612
00:27:05,360 --> 00:27:11,870
don't I cannot provide all the details

613
00:27:07,490 --> 00:27:17,770
here but from what I see I think there

614
00:27:11,870 --> 00:27:23,409
was no reaction from the Reds yep yep

615
00:27:17,770 --> 00:27:23,410
yep okay no questions here

616
00:27:26,529 --> 00:27:29,610
microphones coming together

617
00:27:32,440 --> 00:27:36,360
thank you for the presentation relay

618
00:27:34,810 --> 00:27:39,700
common transformation we are using

619
00:27:36,360 --> 00:27:43,030
machine learning to detect inside the

620
00:27:39,700 --> 00:27:45,970
threat detection and modeling we

621
00:27:43,030 --> 00:27:47,620
navigate the levels of detection that

622
00:27:45,970 --> 00:27:52,300
you mention like ninety and ninety eight

623
00:27:47,620 --> 00:27:55,719
percent and the reason is that the let's

624
00:27:52,300 --> 00:27:58,810
say the radio of of actual traffic

625
00:27:55,720 --> 00:28:02,440
versus the variability of common traffic

626
00:27:58,810 --> 00:28:03,879
on a network it's simply too low which

627
00:28:02,440 --> 00:28:08,340
extent would you say that your

628
00:28:03,880 --> 00:28:08,340
measurement conditions are realistic and

629
00:28:08,580 --> 00:28:13,210
they are realistic for the environment

630
00:28:11,680 --> 00:28:15,790
of log shield for sure because we have

631
00:28:13,210 --> 00:28:18,580
this two data set but I don't know how

632
00:28:15,790 --> 00:28:21,460
realistic they are to or if you would

633
00:28:18,580 --> 00:28:24,840
have to same the same activities but in

634
00:28:21,460 --> 00:28:28,810
a in a different network environment

635
00:28:24,840 --> 00:28:31,120
rephrase your question if that air base

636
00:28:28,810 --> 00:28:33,360
that you mentioned is modeling is a

637
00:28:31,120 --> 00:28:36,010
model of your network if that was a real

638
00:28:33,360 --> 00:28:38,530
network on an air base with a real

639
00:28:36,010 --> 00:28:41,050
traffic of different users applications

640
00:28:38,530 --> 00:28:43,030
and hacker intrusion activity do you

641
00:28:41,050 --> 00:28:46,840
think that you get you would get by far

642
00:28:43,030 --> 00:28:48,460
to those detection results it is the

643
00:28:46,840 --> 00:28:49,959
case during also during lob chills

644
00:28:48,460 --> 00:28:52,120
during this exercise that you have real

645
00:28:49,960 --> 00:28:55,090
user traffic and you have generated

646
00:28:52,120 --> 00:28:58,060
traffic to to load the network so it's

647
00:28:55,090 --> 00:29:00,399
not I think that the traffic is

648
00:28:58,060 --> 00:29:03,970
realistic and to some extent generated

649
00:29:00,400 --> 00:29:07,300
by real users so I think from that I'm

650
00:29:03,970 --> 00:29:09,580
confident that it would work also in in

651
00:29:07,300 --> 00:29:11,850
other settings but I don't have results

652
00:29:09,580 --> 00:29:11,850
for them

653
00:29:12,990 --> 00:29:17,490
well there was let's take last question

654
00:29:15,600 --> 00:29:21,290
and you can remember your question for

655
00:29:17,490 --> 00:29:21,290
the discussion around you

656
00:29:25,930 --> 00:29:30,880
thank you as far as I understood you

657
00:29:27,970 --> 00:29:34,210
trained your system on one sort on one

658
00:29:30,880 --> 00:29:36,370
type of button infrastructure do we have

659
00:29:34,210 --> 00:29:38,230
an idea how many different types of

660
00:29:36,370 --> 00:29:45,250
button it researchers out there in the

661
00:29:38,230 --> 00:29:45,760
world I don't have a number what many

662
00:29:45,250 --> 00:29:52,830
yes

663
00:29:45,760 --> 00:30:01,750
too many yes okay thank you Ron

664
00:29:52,830 --> 00:30:03,730
okay okay next up we have dr. Roman Graf

665
00:30:01,750 --> 00:30:05,350
who is the research engineer at center

666
00:30:03,730 --> 00:30:07,840
for digital safety and security at

667
00:30:05,350 --> 00:30:09,969
Houston Institute of Technology he works

668
00:30:07,840 --> 00:30:11,770
on cyber security and data analytics

669
00:30:09,970 --> 00:30:14,590
topics contributing to the development

670
00:30:11,770 --> 00:30:17,429
of several European research projects

671
00:30:14,590 --> 00:30:20,678
like a Gaussian planets assets and scape

672
00:30:17,429 --> 00:30:25,600
he has published widely in the area of

673
00:30:20,679 --> 00:30:27,820
cyber security and risk management Roman

674
00:30:25,600 --> 00:30:29,949
has supported development of cyber

675
00:30:27,820 --> 00:30:34,720
threat intelligence solutions like

676
00:30:29,950 --> 00:30:39,190
Caesar and also the one we all at NATO

677
00:30:34,720 --> 00:30:43,390
know and love missed so his present

678
00:30:39,190 --> 00:30:46,420
topic is very relevant to all of us we

679
00:30:43,390 --> 00:30:48,490
use Android phones because as you might

680
00:30:46,420 --> 00:30:51,400
know that even if you take applications

681
00:30:48,490 --> 00:30:53,920
from the trusted sources like Play Store

682
00:30:51,400 --> 00:30:59,679
you actually can be hundred percent sure

683
00:30:53,920 --> 00:31:02,620
that it is it is safe so Roman is going

684
00:30:59,679 --> 00:31:04,660
to do to try to explain how they are

685
00:31:02,620 --> 00:31:08,290
trying to make it safer at least the

686
00:31:04,660 --> 00:31:11,710
floor is yours thank you

687
00:31:08,290 --> 00:31:15,940
okay I will I would like to present our

688
00:31:11,710 --> 00:31:17,670
research about network based technique

689
00:31:15,940 --> 00:31:21,130
vondre smart with application

690
00:31:17,670 --> 00:31:23,890
classification I prepared this with my

691
00:31:21,130 --> 00:31:27,940
colleague Aaron Copland from Sirte ET

692
00:31:23,890 --> 00:31:29,710
and with my boss Ross King the beginning

693
00:31:27,940 --> 00:31:33,610
I will briefly describe what is the

694
00:31:29,710 --> 00:31:38,710
problem why is it necessary then I will

695
00:31:33,610 --> 00:31:42,040
explain two real-life scenarios and I

696
00:31:38,710 --> 00:31:43,630
will turn to base of our associates

697
00:31:42,040 --> 00:31:48,280
Drebin solution for pick a

698
00:31:43,630 --> 00:31:50,679
classification and then I will describe

699
00:31:48,280 --> 00:31:55,810
our approach for neural network for this

700
00:31:50,679 --> 00:31:57,340
solution so by it is dangerous to upload

701
00:31:55,810 --> 00:32:01,270
Marvell

702
00:31:57,340 --> 00:32:04,510
because then user can lose money or his

703
00:32:01,270 --> 00:32:07,720
private data for example here is a porno

704
00:32:04,510 --> 00:32:10,750
player example so I should mention we

705
00:32:07,720 --> 00:32:12,940
got our samples from a kickers company

706
00:32:10,750 --> 00:32:16,179
which is antivirus company from Austrian

707
00:32:12,940 --> 00:32:19,780
and they have a lot of malicious samples

708
00:32:16,179 --> 00:32:22,630
and also been in samples this is one of

709
00:32:19,780 --> 00:32:27,370
malicious samples and it's belongs to a

710
00:32:22,630 --> 00:32:29,880
drone family of Mario applications you

711
00:32:27,370 --> 00:32:34,709
will see in a red circle

712
00:32:29,880 --> 00:32:37,990
user has installed Marga application

713
00:32:34,710 --> 00:32:45,940
because he was motivated by work or not

714
00:32:37,990 --> 00:32:49,810
and what does it make this location

715
00:32:45,940 --> 00:32:54,310
it sends expensive calls too expensive

716
00:32:49,810 --> 00:32:57,159
SMS to some numbers as you see I will

717
00:32:54,310 --> 00:33:02,889
show you the source code later and tall

718
00:32:57,160 --> 00:33:05,830
so why we found it out and and why it is

719
00:33:02,890 --> 00:33:09,100
possible because user gave permission by

720
00:33:05,830 --> 00:33:12,399
installation to do it he hoped it would

721
00:33:09,100 --> 00:33:15,340
be interesting application maybe and so

722
00:33:12,400 --> 00:33:17,710
it's a source code and with red color I

723
00:33:15,340 --> 00:33:19,520
marked important parts of the source

724
00:33:17,710 --> 00:33:26,560
code you see

725
00:33:19,520 --> 00:33:29,360
it is SMS for this expensive numbers and

726
00:33:26,560 --> 00:33:33,080
it's all features I will explain in

727
00:33:29,360 --> 00:33:36,790
details more how we get them but you see

728
00:33:33,080 --> 00:33:39,439
also marked in red why we decide our

729
00:33:36,790 --> 00:33:43,340
approach decided that it's Marvel

730
00:33:39,440 --> 00:33:46,220
occasion so in second sample is take

731
00:33:43,340 --> 00:33:49,610
Netflix application you see the user

732
00:33:46,220 --> 00:33:53,240
also tries to install nest Netflix and

733
00:33:49,610 --> 00:33:56,540
accepts and expects that it is a major

734
00:33:53,240 --> 00:34:00,470
application to see videos of some sales

735
00:33:56,540 --> 00:34:04,879
and application ask him to insert

736
00:34:00,470 --> 00:34:08,030
passport and login then it notice give

737
00:34:04,880 --> 00:34:10,790
not that not that hard doesn't match to

738
00:34:08,030 --> 00:34:14,000
this application he should in the

739
00:34:10,790 --> 00:34:15,980
install this but if he doesn't want to

740
00:34:14,000 --> 00:34:19,790
the install it will try to do it by

741
00:34:15,980 --> 00:34:22,250
itself and in the meanwhile already his

742
00:34:19,790 --> 00:34:29,779
leg in data was passed to Marlboro

743
00:34:22,250 --> 00:34:33,880
server and he has lost his data and in

744
00:34:29,780 --> 00:34:38,570
this sample we found out that it was a

745
00:34:33,880 --> 00:34:41,480
encrypted and he was interesting it was

746
00:34:38,570 --> 00:34:44,210
in source code in plain text almost just

747
00:34:41,480 --> 00:34:47,870
a little bit encoded and for this

748
00:34:44,210 --> 00:34:50,210
application only one scene was important

749
00:34:47,870 --> 00:34:55,730
that application could connect to

750
00:34:50,210 --> 00:35:04,880
internet so you see it's also marked in

751
00:34:55,730 --> 00:35:08,540
red key and also encoded or and below

752
00:35:04,880 --> 00:35:13,520
you see it's a rule - if it's decoded

753
00:35:08,540 --> 00:35:16,490
it's all - a malicious error there are

754
00:35:13,520 --> 00:35:19,340
multiple permissions that user provided

755
00:35:16,490 --> 00:35:22,910
but actually attacker just needs only

756
00:35:19,340 --> 00:35:25,560
one marked in red so if you post an

757
00:35:22,910 --> 00:35:29,250
internet connection

758
00:35:25,560 --> 00:35:32,220
our research started from vapor of

759
00:35:29,250 --> 00:35:36,450
Drebin project done by NASA researchers

760
00:35:32,220 --> 00:35:39,240
but very famous research and Iran with

761
00:35:36,450 --> 00:35:42,230
his students provided further research

762
00:35:39,240 --> 00:35:45,569
and applied support vector machine and

763
00:35:42,230 --> 00:35:48,390
compared to other machine learning

764
00:35:45,570 --> 00:35:51,390
algorithms in order to improve the

765
00:35:48,390 --> 00:35:54,900
results the idea of this Drebin project

766
00:35:51,390 --> 00:35:58,589
was to classified my application for

767
00:35:54,900 --> 00:36:02,460
android and to distinguish from been in

768
00:35:58,590 --> 00:36:04,950
applications this approach was good

769
00:36:02,460 --> 00:36:11,510
because as you see we have different

770
00:36:04,950 --> 00:36:16,350
features splitted by groups and then

771
00:36:11,510 --> 00:36:19,350
they created director and classified and

772
00:36:16,350 --> 00:36:22,080
at the output they could say is it is

773
00:36:19,350 --> 00:36:24,600
possibly a Marvel application and they

774
00:36:22,080 --> 00:36:30,090
could explain why because all features

775
00:36:24,600 --> 00:36:34,200
belonging to this Marvel families in

776
00:36:30,090 --> 00:36:38,100
plain text read the moon feature sets

777
00:36:34,200 --> 00:36:41,310
are combined in some subsets you can see

778
00:36:38,100 --> 00:36:47,009
a brief list actually Android package

779
00:36:41,310 --> 00:36:49,560
contains manifest file and some features

780
00:36:47,010 --> 00:36:53,100
belongs to this mini festival and for

781
00:36:49,560 --> 00:36:57,660
other parts as there is as the source

782
00:36:53,100 --> 00:37:03,810
code analysis and also it contains

783
00:36:57,660 --> 00:37:06,259
different groups subtopics here are some

784
00:37:03,810 --> 00:37:10,230
samples of Marvel families and

785
00:37:06,260 --> 00:37:12,780
associated subsets of features features

786
00:37:10,230 --> 00:37:16,380
are actually a plain text and we analyze

787
00:37:12,780 --> 00:37:23,070
plain text but it's it was Drebin

788
00:37:16,380 --> 00:37:27,380
publication so support vector machine

789
00:37:23,070 --> 00:37:31,010
provided good results it was up to 97

790
00:37:27,380 --> 00:37:34,680
purity of true positive rate previous

791
00:37:31,010 --> 00:37:35,100
speaker already explains is estimation

792
00:37:34,680 --> 00:37:38,759
method

793
00:37:35,100 --> 00:37:43,259
and a false-positive rate is about one

794
00:37:38,760 --> 00:37:45,270
percent but it was a huge feature set

795
00:37:43,260 --> 00:37:49,950
and that was a really a problem because

796
00:37:45,270 --> 00:37:52,410
for some for our sample it was 200

797
00:37:49,950 --> 00:37:57,930
gigabyte it will do con a gigabyte of

798
00:37:52,410 --> 00:38:01,410
ram and that's why we decided to try to

799
00:37:57,930 --> 00:38:06,930
find a nicer approach and developed a

800
00:38:01,410 --> 00:38:10,220
neural network approach it was it it is

801
00:38:06,930 --> 00:38:13,560
good because it requires less ram but

802
00:38:10,220 --> 00:38:17,430
problem is that is not explainable you

803
00:38:13,560 --> 00:38:18,960
know possibly that mostly neural

804
00:38:17,430 --> 00:38:23,100
networks are not explainable because

805
00:38:18,960 --> 00:38:26,520
there are neurons that that have rights

806
00:38:23,100 --> 00:38:28,980
rights are initialized randomly and then

807
00:38:26,520 --> 00:38:31,230
they during the trainings they adjust a

808
00:38:28,980 --> 00:38:34,440
rights so it's not explainable there are

809
00:38:31,230 --> 00:38:37,080
some attempts to make explainable neural

810
00:38:34,440 --> 00:38:39,270
networks but again it is it making

811
00:38:37,080 --> 00:38:43,710
explainable with another neural network

812
00:38:39,270 --> 00:38:48,060
so we don't really can explain this and

813
00:38:43,710 --> 00:38:52,080
we have sets of samples about 1 terabyte

814
00:38:48,060 --> 00:38:52,940
now and it's about 56,000 of marvelous

815
00:38:52,080 --> 00:38:57,120
samples

816
00:38:52,940 --> 00:39:02,480
it's our approach overview we have

817
00:38:57,120 --> 00:39:07,700
situation awareness system and we get

818
00:39:02,480 --> 00:39:11,430
epoca applications code and we use

819
00:39:07,700 --> 00:39:14,640
Drebin code is not public actually we

820
00:39:11,430 --> 00:39:19,770
use source code of simple researches

821
00:39:14,640 --> 00:39:22,410
that try to who try to repeat this quote

822
00:39:19,770 --> 00:39:25,259
according to driven publication actually

823
00:39:22,410 --> 00:39:28,440
it works well and we get features using

824
00:39:25,260 --> 00:39:37,260
this code of hitches as I said some text

825
00:39:28,440 --> 00:39:42,540
and then we parse it and prepare feature

826
00:39:37,260 --> 00:39:45,330
model split we split out the set of

827
00:39:42,540 --> 00:39:47,060
samples into training covilhã Dacian and

828
00:39:45,330 --> 00:39:49,190
test sets

829
00:39:47,060 --> 00:39:52,700
trained our model use these features

830
00:39:49,190 --> 00:39:56,360
I'll explain later in details how we do

831
00:39:52,700 --> 00:40:00,410
it exactly and additional part what is

832
00:39:56,360 --> 00:40:03,110
important this applications the unions

833
00:40:00,410 --> 00:40:06,710
the time changes also attack attacker

834
00:40:03,110 --> 00:40:09,260
methods changes early it was SMS now it

835
00:40:06,710 --> 00:40:11,390
is not more same as some other methods

836
00:40:09,260 --> 00:40:15,050
that's why it's not possible to train

837
00:40:11,390 --> 00:40:19,240
just one model and we decided to train

838
00:40:15,050 --> 00:40:25,970
different models distinguish it by

839
00:40:19,240 --> 00:40:29,959
different rules for instance time from

840
00:40:25,970 --> 00:40:32,990
where we get the smarter samples so each

841
00:40:29,960 --> 00:40:35,830
of these modest ease and situational

842
00:40:32,990 --> 00:40:41,120
warning system one two or three and then

843
00:40:35,830 --> 00:40:42,580
we share our results with people who

844
00:40:41,120 --> 00:40:46,390
requested it

845
00:40:42,580 --> 00:40:49,580
we plan that we had a service where

846
00:40:46,390 --> 00:40:52,730
somebody can upload application and

847
00:40:49,580 --> 00:40:59,330
check if it is already known that is

848
00:40:52,730 --> 00:41:00,680
marvel or not we apply employed for 10

849
00:40:59,330 --> 00:41:03,020
meetings method in our neural network

850
00:41:00,680 --> 00:41:07,359
because it's one of the best to analyze

851
00:41:03,020 --> 00:41:09,680
such text fishes how it works

852
00:41:07,360 --> 00:41:14,500
text cannot be analyzed by neural

853
00:41:09,680 --> 00:41:19,879
network that's why we converted to

854
00:41:14,500 --> 00:41:21,740
arrange into numbers and then for

855
00:41:19,880 --> 00:41:24,470
instance if we would have sentenced

856
00:41:21,740 --> 00:41:27,560
icons very interesting very helpful so I

857
00:41:24,470 --> 00:41:30,770
would give index for each word if what

858
00:41:27,560 --> 00:41:35,270
repeats and it has the same index and in

859
00:41:30,770 --> 00:41:38,240
the next turn we converted to embedding

860
00:41:35,270 --> 00:41:40,970
vector which is where we can just

861
00:41:38,240 --> 00:41:43,189
provide the size and it will be done

862
00:41:40,970 --> 00:41:46,220
automatically and you have seen you you

863
00:41:43,190 --> 00:41:50,330
see here a sample of this is it's just

864
00:41:46,220 --> 00:41:54,319
some numbers and but it's a vector and

865
00:41:50,330 --> 00:41:58,190
which file will create a list of size M

866
00:41:54,320 --> 00:41:59,640
but in embedded words and that is input

867
00:41:58,190 --> 00:42:02,910
for our neural net

868
00:41:59,640 --> 00:42:06,240
for train here is our workflow how we

869
00:42:02,910 --> 00:42:08,370
train it as I already mentioned we get

870
00:42:06,240 --> 00:42:12,600
Fischer first then we check if it's

871
00:42:08,370 --> 00:42:14,970
already now trained model or not if not

872
00:42:12,600 --> 00:42:20,420
then we add it to the model and return

873
00:42:14,970 --> 00:42:23,279
it if yes we just query the model and

874
00:42:20,420 --> 00:42:25,710
then go through a rule engine as I

875
00:42:23,280 --> 00:42:29,000
already mentioned and provide the

876
00:42:25,710 --> 00:42:33,420
classification result which Marvel not

877
00:42:29,000 --> 00:42:37,370
here is a brief overview about about our

878
00:42:33,420 --> 00:42:41,760
rule engine we have for instance just

879
00:42:37,370 --> 00:42:47,000
simple rules for instance which date

880
00:42:41,760 --> 00:42:50,610
which operation system which render

881
00:42:47,000 --> 00:42:52,950
produces static and using appliances

882
00:42:50,610 --> 00:42:55,530
rules we could additionally improve

883
00:42:52,950 --> 00:42:58,020
quality if we have additional knowledge

884
00:42:55,530 --> 00:43:00,990
about some things and we could implement

885
00:42:58,020 --> 00:43:04,310
it in such rule system so this blue

886
00:43:00,990 --> 00:43:07,859
icons are if statements actually and

887
00:43:04,310 --> 00:43:12,690
they produced in conclusion and we

888
00:43:07,860 --> 00:43:16,950
aggregate conclusions and go to results

889
00:43:12,690 --> 00:43:21,030
in some conclusion we our neural network

890
00:43:16,950 --> 00:43:25,890
has different parameters such as

891
00:43:21,030 --> 00:43:28,800
learning rate and vector size maximal

892
00:43:25,890 --> 00:43:32,910
vector size embedding vector size then

893
00:43:28,800 --> 00:43:35,270
we have training loss training accuracy

894
00:43:32,910 --> 00:43:38,160
relation loss validation accuracy and

895
00:43:35,270 --> 00:43:40,920
combine in different settings we

896
00:43:38,160 --> 00:43:47,160
analyzed what is a better performance

897
00:43:40,920 --> 00:43:49,470
for our model and in result we have list

898
00:43:47,160 --> 00:43:53,009
of true positive raise rates and most

899
00:43:49,470 --> 00:43:56,189
post positive rates so then we can

900
00:43:53,010 --> 00:44:01,670
estimate which setting for particular

901
00:43:56,190 --> 00:44:04,410
model provides the best accuracy here is

902
00:44:01,670 --> 00:44:08,880
summary about neural network training

903
00:44:04,410 --> 00:44:11,210
process you see do we have we can

904
00:44:08,880 --> 00:44:14,060
provide how many iterations

905
00:44:11,210 --> 00:44:16,880
of training we will do so here is say

906
00:44:14,060 --> 00:44:20,029
five iterations it was enough and you

907
00:44:16,880 --> 00:44:22,609
see that accuracy taking accuracy and

908
00:44:20,030 --> 00:44:26,560
validation accuracy constantly increases

909
00:44:22,609 --> 00:44:29,060
and then is fix it at some point and

910
00:44:26,560 --> 00:44:33,049
error validation error and training

911
00:44:29,060 --> 00:44:38,720
error as expected are reduced the end

912
00:44:33,050 --> 00:44:43,970
and we used the input layer then we

913
00:44:38,720 --> 00:44:46,689
flatten this input data and we used

914
00:44:43,970 --> 00:44:50,959
addition area the hidden layers to

915
00:44:46,690 --> 00:44:53,800
calculate our model and Sigma it was the

916
00:44:50,960 --> 00:44:56,900
activation function for training model

917
00:44:53,800 --> 00:45:00,890
this is relative operations operating

918
00:44:56,900 --> 00:45:03,890
characteristic that also provides visual

919
00:45:00,890 --> 00:45:08,930
visual result of our calculations with

920
00:45:03,890 --> 00:45:12,259
different settings so on the right in

921
00:45:08,930 --> 00:45:14,710
the right part above in the upper side

922
00:45:12,260 --> 00:45:18,859
you see the perfect classification point

923
00:45:14,710 --> 00:45:21,619
and this red line divides good results

924
00:45:18,859 --> 00:45:25,670
from not so good results and you see

925
00:45:21,619 --> 00:45:28,730
that our all our results are located on

926
00:45:25,670 --> 00:45:31,690
the left side in the higher part so we

927
00:45:28,730 --> 00:45:35,720
can see saying all of them are quite

928
00:45:31,690 --> 00:45:38,150
good results and so perfect

929
00:45:35,720 --> 00:45:45,529
classification point is on the x axis

930
00:45:38,150 --> 00:45:50,450
it's near the one so near to this point

931
00:45:45,530 --> 00:45:53,180
the Baptist result section so I can

932
00:45:50,450 --> 00:45:56,200
conclude that we developed real-time

933
00:45:53,180 --> 00:46:00,500
automatic solution that analyzes

934
00:45:56,200 --> 00:46:04,430
classifies apks in my opinion and we

935
00:46:00,500 --> 00:46:07,960
combined rule engine feature extraction

936
00:46:04,430 --> 00:46:10,970
and neural networks to achieve this

937
00:46:07,960 --> 00:46:13,580
decision support method and I would like

938
00:46:10,970 --> 00:46:16,000
to thanks equals company for provided

939
00:46:13,580 --> 00:46:16,000
samples

940
00:46:16,360 --> 00:46:24,790
[Applause]

941
00:46:22,390 --> 00:46:27,589
see

942
00:46:24,790 --> 00:46:30,259
yes thank you Ramon for trying to keep

943
00:46:27,590 --> 00:46:31,460
us under it user safer we have a time

944
00:46:30,260 --> 00:46:36,340
for a few questions

945
00:46:31,460 --> 00:46:36,340
oh it's a nice question

946
00:46:41,410 --> 00:46:46,180
thank you very much for your great

947
00:46:43,750 --> 00:46:50,500
presentation I have one question

948
00:46:46,180 --> 00:46:52,750
have you been able to test AP case that

949
00:46:50,500 --> 00:46:54,870
actually passed a Google verification

950
00:46:52,750 --> 00:46:57,640
test and ended up in the Play Store and

951
00:46:54,870 --> 00:47:00,310
if so have you been able to detect

952
00:46:57,640 --> 00:47:04,180
malicious apps that ended up there no

953
00:47:00,310 --> 00:47:07,509
it's just draft so prototype and we just

954
00:47:04,180 --> 00:47:10,419
used samples that we got from the Icarus

955
00:47:07,510 --> 00:47:12,700
company we are just related on these

956
00:47:10,420 --> 00:47:14,950
samples also it was important to compare

957
00:47:12,700 --> 00:47:17,140
because we wanted to compare previous

958
00:47:14,950 --> 00:47:19,620
calculation is support vector machine

959
00:47:17,140 --> 00:47:21,640
and if it's new application improves

960
00:47:19,620 --> 00:47:23,170
previous application and previous

961
00:47:21,640 --> 00:47:27,220
application was trained with the same

962
00:47:23,170 --> 00:47:29,890
data to have the same ability to compare

963
00:47:27,220 --> 00:47:31,930
them we need the same data but we are

964
00:47:29,890 --> 00:47:34,690
working in one project now and we

965
00:47:31,930 --> 00:47:37,359
collected we want to collect now much

966
00:47:34,690 --> 00:47:39,430
more samples and would like if somebody

967
00:47:37,360 --> 00:47:42,340
can provide especially Benetton samples

968
00:47:39,430 --> 00:47:45,190
so we would like to try our model on

969
00:47:42,340 --> 00:47:47,020
this new samples yes because it will be

970
00:47:45,190 --> 00:47:49,810
interesting if it would this would be an

971
00:47:47,020 --> 00:47:53,490
additional layer on top of the standard

972
00:47:49,810 --> 00:47:53,490
verification procedure of course

973
00:47:55,310 --> 00:48:02,600
another question what kind of a neural

974
00:48:00,350 --> 00:48:05,150
network did you use like a traditional

975
00:48:02,600 --> 00:48:07,520
let's say shallow neural network or you

976
00:48:05,150 --> 00:48:11,270
went into deep networks if deep neural

977
00:48:07,520 --> 00:48:13,970
network with Walter Manning's sorry it's

978
00:48:11,270 --> 00:48:16,520
a deep neural network with embedded

979
00:48:13,970 --> 00:48:18,919
World War 10 buildings of wartime

980
00:48:16,520 --> 00:48:22,670
buildings is a general approach for this

981
00:48:18,920 --> 00:48:25,880
ok and so if you use a deep neural

982
00:48:22,670 --> 00:48:28,820
network weren't you concerned about the

983
00:48:25,880 --> 00:48:31,220
sides of the train network and and the

984
00:48:28,820 --> 00:48:34,490
computational power required to run it

985
00:48:31,220 --> 00:48:38,480
on the actual phone we run it on server

986
00:48:34,490 --> 00:48:40,729
with Hadoop and GPU but currently we

987
00:48:38,480 --> 00:48:45,140
don't have so much data it was not a big

988
00:48:40,730 --> 00:48:47,450
issue we will look at that problem later

989
00:48:45,140 --> 00:48:49,930
when we have more data but which

990
00:48:47,450 --> 00:48:52,370
actually training itself was quite fast

991
00:48:49,930 --> 00:48:55,009
training yes but what about deployment

992
00:48:52,370 --> 00:48:57,970
because SVM is a very compact model once

993
00:48:55,010 --> 00:49:01,010
trained whereas deep neural network is

994
00:48:57,970 --> 00:49:03,980
can be fairly large even when trained I

995
00:49:01,010 --> 00:49:07,450
mean so yeah but we have splitted it in

996
00:49:03,980 --> 00:49:09,980
different smaller models and we will

997
00:49:07,450 --> 00:49:12,020
also apply this rule engines that we

998
00:49:09,980 --> 00:49:13,400
select which model we apply so it is not

999
00:49:12,020 --> 00:49:16,040
so big in any way

1000
00:49:13,400 --> 00:49:23,120
ok thanks ok we have another question

1001
00:49:16,040 --> 00:49:25,940
here Roman was any a priori information

1002
00:49:23,120 --> 00:49:32,630
known any contextual information known

1003
00:49:25,940 --> 00:49:37,220
to the classifier actually not we just

1004
00:49:32,630 --> 00:49:39,050
looked some samples we didn't know

1005
00:49:37,220 --> 00:49:41,720
anything about the nature of the

1006
00:49:39,050 --> 00:49:43,910
applications no we just but we of course

1007
00:49:41,720 --> 00:49:46,819
we had a label set from provided from

1008
00:49:43,910 --> 00:49:51,440
Icarus company they have possibly say

1009
00:49:46,820 --> 00:49:55,730
rules and methods but we just use this

1010
00:49:51,440 --> 00:49:57,800
sample the classical unsupervised

1011
00:49:55,730 --> 00:50:01,430
learning you know it's supervised

1012
00:49:57,800 --> 00:50:03,680
because we had labels also you had but

1013
00:50:01,430 --> 00:50:07,870
it was provided by ikarus and how they

1014
00:50:03,680 --> 00:50:07,870
decided it it's they

1015
00:50:07,880 --> 00:50:13,339
the rules we don't know this rules but

1016
00:50:10,579 --> 00:50:18,099
we already had a label that said thank

1017
00:50:13,339 --> 00:50:18,099
you okay I have another question here

1018
00:50:18,640 --> 00:50:23,598
thank you for the presentation you

1019
00:50:20,839 --> 00:50:26,690
showed a very high accuracy of your

1020
00:50:23,599 --> 00:50:29,750
system and then you told us that you you

1021
00:50:26,690 --> 00:50:32,269
tried your your classifier on several

1022
00:50:29,750 --> 00:50:34,549
hundreds of gigabytes of apk

1023
00:50:32,269 --> 00:50:37,598
but what was the size of the often

1024
00:50:34,549 --> 00:50:41,059
labeled data in order to train us such

1025
00:50:37,599 --> 00:50:48,380
as if I label data was fifty six

1026
00:50:41,059 --> 00:50:50,900
thousand samples the size it's not not

1027
00:50:48,380 --> 00:50:54,910
so extremely big but we know we got

1028
00:50:50,900 --> 00:50:59,750
bigger size we will proceed with this

1029
00:50:54,910 --> 00:51:02,420
okay do you have any other question no

1030
00:50:59,750 --> 00:51:05,029
okay then I will ask you one question so

1031
00:51:02,420 --> 00:51:07,579
what should the adversary do to avoid

1032
00:51:05,029 --> 00:51:10,549
your detection can another three just

1033
00:51:07,579 --> 00:51:15,319
take most popular common application

1034
00:51:10,549 --> 00:51:18,109
from Playstore and add some some unknown

1035
00:51:15,319 --> 00:51:20,869
malicious code that was not previously

1036
00:51:18,109 --> 00:51:23,348
used anywhere something custom oh no

1037
00:51:20,869 --> 00:51:26,240
this is a static of course if people

1038
00:51:23,349 --> 00:51:30,490
produce customized applications they

1039
00:51:26,240 --> 00:51:34,879
have chance to circumvent our model but

1040
00:51:30,490 --> 00:51:38,240
it's quite complicated because we also

1041
00:51:34,880 --> 00:51:41,119
don't know by ourselves which features

1042
00:51:38,240 --> 00:51:43,640
we analyze them automatically and there

1043
00:51:41,119 --> 00:51:44,660
is possibly a chance to circumvent it

1044
00:51:43,640 --> 00:51:47,960
but possibly not

1045
00:51:44,660 --> 00:51:50,299
if this customized quad has some

1046
00:51:47,960 --> 00:51:52,279
specific features that we already had in

1047
00:51:50,299 --> 00:51:55,690
our trained models and it also will be

1048
00:51:52,279 --> 00:51:58,670
detected so if you'll take already known

1049
00:51:55,690 --> 00:52:04,339
as caught it possibly will be detected

1050
00:51:58,670 --> 00:52:06,890
and just just adjust it somehow okay

1051
00:52:04,339 --> 00:52:12,710
thank you no more questions and we can

1052
00:52:06,890 --> 00:52:14,598
continue and our next speaker is Mikkel

1053
00:52:12,710 --> 00:52:17,410
ko Yuni who is full professor of

1054
00:52:14,599 --> 00:52:20,359
security of engineering at the

1055
00:52:17,410 --> 00:52:21,440
University of modern energy emilia italy

1056
00:52:20,359 --> 00:52:24,200
since the house

1057
00:52:21,440 --> 00:52:26,300
his research interests include system

1058
00:52:24,200 --> 00:52:29,029
and network security scale vulnerable

1059
00:52:26,300 --> 00:52:31,790
architecture and security analytics he

1060
00:52:29,030 --> 00:52:34,010
directs the research center on security

1061
00:52:31,790 --> 00:52:36,770
and safety the cyber Academy for ethical

1062
00:52:34,010 --> 00:52:39,859
hackers and masters in cyber defense

1063
00:52:36,770 --> 00:52:41,869
governance for zermatt four sons Bologna

1064
00:52:39,859 --> 00:52:44,299
Business School today he is presenting

1065
00:52:41,869 --> 00:52:46,880
possibly one of the most important

1066
00:52:44,300 --> 00:52:48,650
topics for this future of cyber security

1067
00:52:46,880 --> 00:52:52,130
systems that are based on machine

1068
00:52:48,650 --> 00:52:54,680
learning so adversarial attacks against

1069
00:52:52,130 --> 00:52:56,420
them which are trying to poison machine

1070
00:52:54,680 --> 00:52:58,490
learning colleges please thanks very

1071
00:52:56,420 --> 00:53:04,460
much those were very kind introductions

1072
00:52:58,490 --> 00:53:08,810
so I can leverage the third position

1073
00:53:04,460 --> 00:53:11,390
because my colleagues already presented

1074
00:53:08,810 --> 00:53:14,210
all the technical details about machine

1075
00:53:11,390 --> 00:53:17,089
learning and so I will try to actually

1076
00:53:14,210 --> 00:53:21,410
to answer the main question of this

1077
00:53:17,089 --> 00:53:24,160
session if artificial intelligence

1078
00:53:21,410 --> 00:53:28,160
machine learning and learning canal pass

1079
00:53:24,160 --> 00:53:29,839
now and in the future so just a

1080
00:53:28,160 --> 00:53:34,250
precision because I'm sorry I'm a

1081
00:53:29,839 --> 00:53:37,069
professor I need to to clarify all the

1082
00:53:34,250 --> 00:53:39,560
terms so because some people say okay

1083
00:53:37,069 --> 00:53:44,569
artificial intelligence is 60 years old

1084
00:53:39,560 --> 00:53:46,759
this is not true because in the first

1085
00:53:44,569 --> 00:53:51,589
part what we can call the artificial

1086
00:53:46,760 --> 00:53:56,060
intelligence 1.0 we tried our goal was

1087
00:53:51,589 --> 00:54:00,589
to teach to the machine to resonate so

1088
00:53:56,060 --> 00:54:03,670
we define Haunt ologies semantics a lot

1089
00:54:00,589 --> 00:54:07,700
of formal meters for reasoning and

1090
00:54:03,670 --> 00:54:10,280
actually it didn't work but in the last

1091
00:54:07,700 --> 00:54:14,779
10 years we changed completely the

1092
00:54:10,280 --> 00:54:15,560
approach now we are trying to teach to

1093
00:54:14,780 --> 00:54:19,430
the machine

1094
00:54:15,560 --> 00:54:24,349
how to learn and this approach is

1095
00:54:19,430 --> 00:54:26,990
working much better the novelty is also

1096
00:54:24,349 --> 00:54:30,050
a technological novelty we have a huge

1097
00:54:26,990 --> 00:54:33,790
amount of data huge computational power

1098
00:54:30,050 --> 00:54:34,910
and so we can introduce a lot of fancy

1099
00:54:33,790 --> 00:54:37,089
algorithm

1100
00:54:34,910 --> 00:54:41,049
she learning deep learning and whatever

1101
00:54:37,089 --> 00:54:43,279
the other colleagues explained so

1102
00:54:41,049 --> 00:54:47,030
another point agree that we should

1103
00:54:43,280 --> 00:54:51,619
clarify is the real priority the real

1104
00:54:47,030 --> 00:54:53,930
importance of all these methods in my

1105
00:54:51,619 --> 00:54:58,130
metaphor artificial intelligence is like

1106
00:54:53,930 --> 00:55:01,720
a refinery but the refinery is useless

1107
00:54:58,130 --> 00:55:06,559
if you don't have oil and oil is

1108
00:55:01,720 --> 00:55:10,279
represented by data a notion of data you

1109
00:55:06,559 --> 00:55:13,490
need a large amount of them and the

1110
00:55:10,280 --> 00:55:18,109
declaration the claims at the end of the

1111
00:55:13,490 --> 00:55:19,939
slide are clear which is more important

1112
00:55:18,109 --> 00:55:22,910
is the amount of data the amount of data

1113
00:55:19,940 --> 00:55:26,289
and the type of data that you choose for

1114
00:55:22,910 --> 00:55:31,098
machine learning to train your systems

1115
00:55:26,289 --> 00:55:34,910
you made a mistake there the output is

1116
00:55:31,099 --> 00:55:37,369
brought fresh in treasure so you need a

1117
00:55:34,910 --> 00:55:46,399
huge amount of data a huge amount of

1118
00:55:37,369 --> 00:55:48,970
useful and data is not the reality data

1119
00:55:46,400 --> 00:55:52,069
is just a portion of the reality is a

1120
00:55:48,970 --> 00:55:55,160
representation of the reality so if you

1121
00:55:52,069 --> 00:56:00,740
look at this picture you look young

1122
00:55:55,160 --> 00:56:04,578
people smiling people we look at data so

1123
00:56:00,740 --> 00:56:08,899
the definition of these people is not

1124
00:56:04,579 --> 00:56:11,720
the reality nevertheless artificial

1125
00:56:08,900 --> 00:56:14,119
intelligence works there are several

1126
00:56:11,720 --> 00:56:19,129
problem domains where artificial

1127
00:56:14,119 --> 00:56:22,089
intelligence work and this doesn't mean

1128
00:56:19,130 --> 00:56:26,000
that artificial intelligence works

1129
00:56:22,089 --> 00:56:28,670
everywhere so artificial integers works

1130
00:56:26,000 --> 00:56:33,460
very well in computer vision in speech

1131
00:56:28,670 --> 00:56:37,220
recognition text interpretation

1132
00:56:33,460 --> 00:56:40,670
analytics micro profiling and neuro

1133
00:56:37,220 --> 00:56:45,569
marketing is very perfect for profiling

1134
00:56:40,670 --> 00:56:51,099
each of you what's very well in games

1135
00:56:45,569 --> 00:56:53,890
Ches you remember deep blue didn't go

1136
00:56:51,099 --> 00:56:56,170
and even poker this is an interesting

1137
00:56:53,890 --> 00:56:59,078
game because is that you have a partial

1138
00:56:56,170 --> 00:57:02,049
information about this game on the other

1139
00:56:59,079 --> 00:57:03,819
end all the pieces of the chess are on

1140
00:57:02,049 --> 00:57:07,569
the table so it's a different problem

1141
00:57:03,819 --> 00:57:11,799
and actually artificial intelligence now

1142
00:57:07,569 --> 00:57:13,180
helps a lot the bad guys at which

1143
00:57:11,799 --> 00:57:15,700
intelligence is used for malware

1144
00:57:13,180 --> 00:57:18,339
production at visual intelligence is

1145
00:57:15,700 --> 00:57:21,220
used for chat BOTS for information

1146
00:57:18,339 --> 00:57:22,990
warfare so there are several problem

1147
00:57:21,220 --> 00:57:25,959
domains where artificial intelligence

1148
00:57:22,990 --> 00:57:30,879
actually work and improves here by here

1149
00:57:25,960 --> 00:57:35,410
but which are the common features of

1150
00:57:30,880 --> 00:57:39,730
this problem domain they are clear

1151
00:57:35,410 --> 00:57:42,779
definition they have rules you can have

1152
00:57:39,730 --> 00:57:45,730
an optimization vector because you know

1153
00:57:42,779 --> 00:57:49,119
when the problem and the solution is a

1154
00:57:45,730 --> 00:57:51,029
better solution in comparison to the

1155
00:57:49,119 --> 00:57:54,190
previous solution on the other end I

1156
00:57:51,029 --> 00:57:57,609
think that we are working on the most

1157
00:57:54,190 --> 00:58:00,130
complex domain we have no rules

1158
00:57:57,609 --> 00:58:05,170
we have no border definition of our

1159
00:58:00,130 --> 00:58:10,269
problems and even worse we have to model

1160
00:58:05,170 --> 00:58:12,279
human behavior we can model in a certain

1161
00:58:10,269 --> 00:58:14,919
way when a precise way the machine

1162
00:58:12,279 --> 00:58:19,930
behavior but what about the attackers

1163
00:58:14,920 --> 00:58:23,170
what about your people the user of your

1164
00:58:19,930 --> 00:58:25,899
machines the insiders I mean is very

1165
00:58:23,170 --> 00:58:29,680
very difficult and there is a third

1166
00:58:25,900 --> 00:58:32,769
problem we are facing a dynamic a

1167
00:58:29,680 --> 00:58:36,160
continuously dynamic problem the other

1168
00:58:32,769 --> 00:58:39,399
problems are static if you have to

1169
00:58:36,160 --> 00:58:42,160
recognize a cut a cut is always a cut in

1170
00:58:39,400 --> 00:58:45,910
our context the data change the problem

1171
00:58:42,160 --> 00:58:49,240
change the system of a medium large

1172
00:58:45,910 --> 00:58:52,359
enterprise change continuously so we

1173
00:58:49,240 --> 00:58:54,339
have this to face this very well-known

1174
00:58:52,359 --> 00:58:57,369
problem there is a concept drift where

1175
00:58:54,339 --> 00:58:58,810
we don't know the real correlation

1176
00:58:57,369 --> 00:59:01,120
between the inputs

1177
00:58:58,810 --> 00:59:06,250
and the outputs and the dis correlation

1178
00:59:01,120 --> 00:59:08,910
change evolved over times and we have

1179
00:59:06,250 --> 00:59:12,160
another problems that the other

1180
00:59:08,910 --> 00:59:14,859
presenter explained we have a lot of

1181
00:59:12,160 --> 00:59:19,180
good samples even in networks and the

1182
00:59:14,860 --> 00:59:21,730
very few malware samples so actually we

1183
00:59:19,180 --> 00:59:23,649
can train the machine to recognize the

1184
00:59:21,730 --> 00:59:25,240
good but it's very difficult to

1185
00:59:23,650 --> 00:59:29,410
recognize the bad because we don't have

1186
00:59:25,240 --> 00:59:32,430
enough Sam and if this is not enough and

1187
00:59:29,410 --> 00:59:34,720
this is my last challenge is we have

1188
00:59:32,430 --> 00:59:37,169
adversarial on the other side on the

1189
00:59:34,720 --> 00:59:43,390
other side and this is much much worse

1190
00:59:37,170 --> 00:59:46,180
so someone said that this is the

1191
00:59:43,390 --> 00:59:50,160
direction I mean I agree that this is

1192
00:59:46,180 --> 00:59:52,660
the direction the static solutions the

1193
00:59:50,160 --> 00:59:56,230
antivirus the static anta valves the

1194
00:59:52,660 --> 00:59:57,009
typical pattern metro solution don't

1195
00:59:56,230 --> 01:00:01,840
work anymore

1196
00:59:57,010 --> 01:00:04,210
the typical rules for devices firewall

1197
01:00:01,840 --> 01:00:06,790
or whatever don't work anymore because

1198
01:00:04,210 --> 01:00:10,180
we are facing a continuously evolving

1199
01:00:06,790 --> 01:00:13,210
domain so and we cannot manage indeed

1200
01:00:10,180 --> 01:00:15,970
the human cannot manage all this amount

1201
01:00:13,210 --> 01:00:20,350
of data I mean it's not much whether in

1202
01:00:15,970 --> 01:00:24,339
a in a company something like traffic 20

1203
01:00:20,350 --> 01:00:29,440
millions of packets per day there is no

1204
01:00:24,340 --> 01:00:33,790
way we cannot manage so we need to go

1205
01:00:29,440 --> 01:00:37,270
this is the direction the problem is

1206
01:00:33,790 --> 01:00:42,640
that the attackers are human as marked

1207
01:00:37,270 --> 01:00:46,810
are motivated and so they know that we

1208
01:00:42,640 --> 01:00:49,210
are changing the detection rules we are

1209
01:00:46,810 --> 01:00:53,200
changing the devices and so they are

1210
01:00:49,210 --> 01:00:55,840
also improving their attacks they know

1211
01:00:53,200 --> 01:00:59,580
and they are studying how to evade the

1212
01:00:55,840 --> 01:01:03,430
dynamic rules that you use for detection

1213
01:00:59,580 --> 01:01:06,880
and that versary attacks is very

1214
01:01:03,430 --> 01:01:08,560
well-known professor incent early

1215
01:01:06,880 --> 01:01:12,280
already explained in

1216
01:01:08,560 --> 01:01:15,970
great talk this morning in adversarial

1217
01:01:12,280 --> 01:01:18,760
any when with few introduction of pixel

1218
01:01:15,970 --> 01:01:21,549
the same algorithm that in the first

1219
01:01:18,760 --> 01:01:24,340
part on your left part recognized was

1220
01:01:21,550 --> 01:01:29,950
able to classify exactly a cat on the

1221
01:01:24,340 --> 01:01:33,460
right part with a small number of pixels

1222
01:01:29,950 --> 01:01:35,410
that you cannot recognize was recognized

1223
01:01:33,460 --> 01:01:37,810
as a whack-a-mole is a South American

1224
01:01:35,410 --> 01:01:40,299
source that in some sense if you saw

1225
01:01:37,810 --> 01:01:47,670
this and it's not so different there is

1226
01:01:40,300 --> 01:01:47,670
some gray part is some difference so

1227
01:01:47,730 --> 01:01:52,240
extremely new is extremely challenging

1228
01:01:49,870 --> 01:01:56,410
on the other end the problem with

1229
01:01:52,240 --> 01:02:00,430
adversary attack on cybersecurity so in

1230
01:01:56,410 --> 01:02:03,279
the paper we tried to introduce a small

1231
01:02:00,430 --> 01:02:07,109
taxonomy is not a very huge taxonomy

1232
01:02:03,280 --> 01:02:11,680
because the the adversarial can

1233
01:02:07,110 --> 01:02:14,680
intervene can influence the data set so

1234
01:02:11,680 --> 01:02:17,230
if he knows which is which are the main

1235
01:02:14,680 --> 01:02:21,790
feature in a in a random forest model

1236
01:02:17,230 --> 01:02:24,780
that I use to recognize to classify a

1237
01:02:21,790 --> 01:02:28,000
malicious packet it can introduce more

1238
01:02:24,780 --> 01:02:30,670
changes more very small changes that are

1239
01:02:28,000 --> 01:02:34,810
not recognized as as an attack but that

1240
01:02:30,670 --> 01:02:37,810
change the training of the continuous

1241
01:02:34,810 --> 01:02:39,880
training of the algorithm or you can use

1242
01:02:37,810 --> 01:02:44,110
the same approach at the operation time

1243
01:02:39,880 --> 01:02:48,310
at the test time where there is a there

1244
01:02:44,110 --> 01:02:51,130
is a trade-off here if you want to the

1245
01:02:48,310 --> 01:02:53,710
tech to detect adversarial attack in

1246
01:02:51,130 --> 01:02:57,340
some senses you have to enlarge the data

1247
01:02:53,710 --> 01:02:59,710
set you have to have a larger data set

1248
01:02:57,340 --> 01:03:01,540
that is recognized as an attack but if

1249
01:02:59,710 --> 01:03:03,130
you enlarge that other sects on the

1250
01:03:01,540 --> 01:03:07,000
other end you have a lot of false

1251
01:03:03,130 --> 01:03:11,310
detection so is a difficult trade-off to

1252
01:03:07,000 --> 01:03:14,500
find the right definition of true

1253
01:03:11,310 --> 01:03:16,900
attacks and false attack you can violate

1254
01:03:14,500 --> 01:03:20,170
the data set the integrity you can

1255
01:03:16,900 --> 01:03:22,370
introduce a loss a lot of packets just

1256
01:03:20,170 --> 01:03:26,690
to arise a huge amount

1257
01:03:22,370 --> 01:03:29,390
alarms that force in some sense the the

1258
01:03:26,690 --> 01:03:34,670
system operator to turn off the the

1259
01:03:29,390 --> 01:03:37,700
detector so since the first presenter

1260
01:03:34,670 --> 01:03:40,820
discussed about random forests we the my

1261
01:03:37,700 --> 01:03:44,529
example is on the same direction random

1262
01:03:40,820 --> 01:03:49,150
forest is in this case is a good

1263
01:03:44,530 --> 01:03:51,920
detector a simplification for our

1264
01:03:49,150 --> 01:03:53,780
problem is that we are we need just a

1265
01:03:51,920 --> 01:03:55,910
binary classification because the random

1266
01:03:53,780 --> 01:03:58,400
forest K user can be used also for

1267
01:03:55,910 --> 01:04:02,060
larger sets of a classification the

1268
01:03:58,400 --> 01:04:07,390
other end we need just a binary

1269
01:04:02,060 --> 01:04:10,460
classification so the idea is that

1270
01:04:07,390 --> 01:04:17,600
random for original random forests whose

1271
01:04:10,460 --> 01:04:22,400
use uses static parameters and this is

1272
01:04:17,600 --> 01:04:27,610
fine for the static problems but in some

1273
01:04:22,400 --> 01:04:32,570
sense our problem domain is more fuzzy a

1274
01:04:27,610 --> 01:04:36,020
packet can be malicious or not so it can

1275
01:04:32,570 --> 01:04:39,800
be malicious with some probability so

1276
01:04:36,020 --> 01:04:44,000
instead of reducing the probability part

1277
01:04:39,800 --> 01:04:48,820
as a deterministic part we preserve it

1278
01:04:44,000 --> 01:04:52,510
the probabilistic path in some sense we

1279
01:04:48,820 --> 01:04:57,380
could have a first part of a classifier

1280
01:04:52,510 --> 01:05:00,920
with the probability that remains in the

1281
01:04:57,380 --> 01:05:05,030
in the model and then which we we train

1282
01:05:00,920 --> 01:05:08,240
the the system with this flexible

1283
01:05:05,030 --> 01:05:14,570
parameters and then we used in the test

1284
01:05:08,240 --> 01:05:18,020
part the interesting point is that you

1285
01:05:14,570 --> 01:05:23,690
need to continuously update and train

1286
01:05:18,020 --> 01:05:26,290
your model if I can keep your question

1287
01:05:23,690 --> 01:05:29,660
this was an interesting question about

1288
01:05:26,290 --> 01:05:33,500
can the random forester can be used in

1289
01:05:29,660 --> 01:05:34,240
another network oh I'm sure I can guess

1290
01:05:33,500 --> 01:05:36,430
that

1291
01:05:34,240 --> 01:05:38,770
it will work in another system in the

1292
01:05:36,430 --> 01:05:45,009
another method with a different traffic

1293
01:05:38,770 --> 01:05:47,440
the question is what if saikhan 2020 we

1294
01:05:45,010 --> 01:05:48,490
use a different botnet a different

1295
01:05:47,440 --> 01:05:51,330
malware family

1296
01:05:48,490 --> 01:05:55,359
this is the real quest and we don't know

1297
01:05:51,330 --> 01:05:56,980
we don't know I I can suggest that we

1298
01:05:55,359 --> 01:05:59,980
have to change whether wises whistlin

1299
01:05:56,980 --> 01:06:04,330
will win I mean they have a good support

1300
01:05:59,980 --> 01:06:09,430
so first hint is to change because they

1301
01:06:04,330 --> 01:06:19,170
are it and the result was about the

1302
01:06:09,430 --> 01:06:24,399
results I I cannot sell you anything on

1303
01:06:19,170 --> 01:06:27,010
the on the table you have the the data

1304
01:06:24,400 --> 01:06:29,619
set the data set is extremely realistic

1305
01:06:27,010 --> 01:06:37,510
we have something about 1 billion

1306
01:06:29,619 --> 01:06:41,770
packets in I mean normal traffic where

1307
01:06:37,510 --> 01:06:46,960
we introduces 13 types of botnets

1308
01:06:41,770 --> 01:06:49,330
so 13 types of malware from this table

1309
01:06:46,960 --> 01:06:52,270
you can recognize the problems we have

1310
01:06:49,330 --> 01:06:55,270
an a number of net flow in terms of

1311
01:06:52,270 --> 01:06:59,410
millions but in the militia flow are two

1312
01:06:55,270 --> 01:07:03,780
of three orders of magnitude lower do

1313
01:06:59,410 --> 01:07:06,790
you remember my problems how I can train

1314
01:07:03,780 --> 01:07:10,270
an automatic and machine learning with

1315
01:07:06,790 --> 01:07:15,910
this few in some sense packets with

1316
01:07:10,270 --> 01:07:21,849
respect to the normal net flow and okay

1317
01:07:15,910 --> 01:07:26,080
I can present just the last results

1318
01:07:21,849 --> 01:07:30,510
where you can appreciate that

1319
01:07:26,080 --> 01:07:34,839
our algorithm then the state-of-the-art

1320
01:07:30,510 --> 01:07:37,690
because our results are always on top of

1321
01:07:34,839 --> 01:07:41,320
the previous result indication the

1322
01:07:37,690 --> 01:07:45,849
detection rate is high in some sense but

1323
01:07:41,320 --> 01:07:49,019
I want to say the truth all the truth

1324
01:07:45,849 --> 01:07:54,420
and if you look at the entire picture

1325
01:07:49,019 --> 01:07:59,468
that is the 13 or 14 instagrams

1326
01:07:54,420 --> 01:08:02,469
top right where an adversarial attack

1327
01:07:59,469 --> 01:08:06,039
could change some parameters of the

1328
01:08:02,469 --> 01:08:09,789
features that we used for detection so

1329
01:08:06,039 --> 01:08:13,539
there are four the first for Instagram

1330
01:08:09,789 --> 01:08:18,569
the adversarial attack was could change

1331
01:08:13,539 --> 01:08:23,139
just one fifth so in the in the second

1332
01:08:18,569 --> 01:08:27,489
set it could change two features and so

1333
01:08:23,139 --> 01:08:31,270
on until four features and the final

1334
01:08:27,488 --> 01:08:35,698
results is what we expected is a

1335
01:08:31,270 --> 01:08:37,929
continuous discrete and decreasing and

1336
01:08:35,698 --> 01:08:39,848
this is the truth today

1337
01:08:37,929 --> 01:08:41,980
now we can improve the state around

1338
01:08:39,849 --> 01:08:43,900
research is his based on this a

1339
01:08:41,979 --> 01:08:49,388
continuous improve this improve our

1340
01:08:43,899 --> 01:08:53,049
results so the truth is that there is an

1341
01:08:49,389 --> 01:08:56,920
assumption an abstention behind the

1342
01:08:53,049 --> 01:09:00,698
scene the assumption is that what is

1343
01:08:56,920 --> 01:09:05,759
anomalous is also malicious and what is

1344
01:09:00,698 --> 01:09:13,658
malicious generates an anomaly but

1345
01:09:05,759 --> 01:09:16,679
unfortunately this is not always true so

1346
01:09:13,658 --> 01:09:22,778
we have false positive and false

1347
01:09:16,679 --> 01:09:28,239
negatives and would you buy a detector

1348
01:09:22,779 --> 01:09:30,369
that is precise and 99.99 percent four

1349
01:09:28,238 --> 01:09:36,309
four five four nines

1350
01:09:30,368 --> 01:09:41,049
will you buy hit yes or no why not come

1351
01:09:36,310 --> 01:09:44,199
on 99.99 no it's yes or not it depends

1352
01:09:41,049 --> 01:09:46,778
on the number of flaws number of packets

1353
01:09:44,198 --> 01:09:52,178
if you have a ten millions packet per

1354
01:09:46,779 --> 01:09:56,559
day that is normal 99.99 means at least

1355
01:09:52,179 --> 01:09:57,980
1000 false alarm birthday you cannot

1356
01:09:56,559 --> 01:10:01,970
manage one

1357
01:09:57,980 --> 01:10:05,719
if you know so we don't need 99 we need

1358
01:10:01,970 --> 01:10:09,110
99 I mean at least five or six nine

1359
01:10:05,720 --> 01:10:11,450
precision and we are not yet there this

1360
01:10:09,110 --> 01:10:16,400
is the truth this is the truth on the

1361
01:10:11,450 --> 01:10:18,650
other end so positive message even the

1362
01:10:16,400 --> 01:10:21,860
biggest cloud provided Microsoft Azure

1363
01:10:18,650 --> 01:10:25,460
Amazon Google are using the same thing

1364
01:10:21,860 --> 01:10:27,320
so because as I said before the

1365
01:10:25,460 --> 01:10:30,380
direction is this there is no

1366
01:10:27,320 --> 01:10:35,420
alternative so this is the direction and

1367
01:10:30,380 --> 01:10:37,220
they have much better results but they

1368
01:10:35,420 --> 01:10:41,540
have much better results because they

1369
01:10:37,220 --> 01:10:44,390
have huge huge amount of days later they

1370
01:10:41,540 --> 01:10:47,120
don't have millions of date they have

1371
01:10:44,390 --> 01:10:54,920
billions and billions of data per day

1372
01:10:47,120 --> 01:10:58,160
so summary either you can define a limit

1373
01:10:54,920 --> 01:11:00,730
your problem otherwise you need a huge

1374
01:10:58,160 --> 01:11:07,550
amount of data to have better better

1375
01:11:00,730 --> 01:11:10,009
results and to conclude these are not my

1376
01:11:07,550 --> 01:11:15,470
requirements especially the fourth one

1377
01:11:10,010 --> 01:11:18,830
so we need fairness explain ability this

1378
01:11:15,470 --> 01:11:22,940
is an important point because most of

1379
01:11:18,830 --> 01:11:27,880
these deep-learning alchemists work but

1380
01:11:22,940 --> 01:11:31,940
we don't know why we don't know why and

1381
01:11:27,880 --> 01:11:35,750
DARPA open interesting project about the

1382
01:11:31,940 --> 01:11:38,780
explain ability why we want to know the

1383
01:11:35,750 --> 01:11:42,500
motivation if we want to apply this

1384
01:11:38,780 --> 01:11:45,559
algorithm in the society in the real we

1385
01:11:42,500 --> 01:11:50,380
we want to need the motivation why this

1386
01:11:45,560 --> 01:11:54,620
alchemist work this should be robust to

1387
01:11:50,380 --> 01:11:57,350
an evolving data set and even robusta to

1388
01:11:54,620 --> 01:12:00,680
adversarial attacks the fourth one is

1389
01:11:57,350 --> 01:12:03,830
scaring for all the technology people

1390
01:12:00,680 --> 01:12:07,510
that are around not for the lawyers

1391
01:12:03,830 --> 01:12:10,050
because they are trying to say the

1392
01:12:07,510 --> 01:12:12,900
organization for

1393
01:12:10,050 --> 01:12:16,340
Commerce and development we are trying

1394
01:12:12,900 --> 01:12:19,889
to say that organization individuals

1395
01:12:16,340 --> 01:12:23,340
that operate and deploy artificial

1396
01:12:19,890 --> 01:12:28,110
intelligence should be should be

1397
01:12:23,340 --> 01:12:32,310
accountable should be accountable when

1398
01:12:28,110 --> 01:12:34,650
should we become must I will go fishing

1399
01:12:32,310 --> 01:12:37,710
and sailing because this is dangerous I

1400
01:12:34,650 --> 01:12:42,000
mean I agree that the society the real

1401
01:12:37,710 --> 01:12:43,890
world want this accountability from us

1402
01:12:42,000 --> 01:12:47,880
but this will change the industry

1403
01:12:43,890 --> 01:12:50,400
because until now 50 or 60 years of

1404
01:12:47,880 --> 01:12:53,850
computer science of computer and

1405
01:12:50,400 --> 01:12:59,429
software industry has never never been

1406
01:12:53,850 --> 01:13:02,510
liable about the mistake we produce beta

1407
01:12:59,430 --> 01:13:08,850
testing products that are not product

1408
01:13:02,510 --> 01:13:12,240
you accept patching every week every

1409
01:13:08,850 --> 01:13:13,830
month this is not possible when

1410
01:13:12,240 --> 01:13:16,530
artificial integer when the software

1411
01:13:13,830 --> 01:13:18,300
will become an important part of this

1412
01:13:16,530 --> 01:13:20,759
already became a very important part of

1413
01:13:18,300 --> 01:13:24,720
the society of the Internet of Things

1414
01:13:20,760 --> 01:13:27,210
world accountability liability for the

1415
01:13:24,720 --> 01:13:29,700
computer industry by divino for for us

1416
01:13:27,210 --> 01:13:33,410
that want to apply this is an important

1417
01:13:29,700 --> 01:13:33,410
part thank you very much for your

1418
01:13:37,430 --> 01:13:42,120
okay thank you Michael for enlightening

1419
01:13:40,230 --> 01:13:44,629
us about problems relating machine

1420
01:13:42,120 --> 01:13:47,970
learning in security systems you have a

1421
01:13:44,630 --> 01:13:51,870
few time for few questions but before

1422
01:13:47,970 --> 01:13:54,570
panel discussion do we have any because

1423
01:13:51,870 --> 01:13:57,240
there is one questions there sir here in

1424
01:13:54,570 --> 01:13:59,580
the back I really appreciate your talk

1425
01:13:57,240 --> 01:14:07,950
I was just wondering as far as obstacles

1426
01:13:59,580 --> 01:14:09,900
- I'm back here so I'll stand up as far

1427
01:14:07,950 --> 01:14:11,429
as obstacles for improving our ability

1428
01:14:09,900 --> 01:14:14,009
to use machine learning algorithms did

1429
01:14:11,430 --> 01:14:16,440
you say that our ability to process

1430
01:14:14,010 --> 01:14:18,210
large quantities of data is the bigger

1431
01:14:16,440 --> 01:14:19,530
obstacle or ability to understand and

1432
01:14:18,210 --> 01:14:21,360
articulate to the machine learning

1433
01:14:19,530 --> 01:14:26,009
algorithm what it is that we're

1434
01:14:21,360 --> 01:14:29,190
providing as inputs no sorry I didn't

1435
01:14:26,010 --> 01:14:32,970
say that the impossibility to provide to

1436
01:14:29,190 --> 01:14:35,580
manage a huge amount of data is our

1437
01:14:32,970 --> 01:14:38,070
limit our limit is to have this huge

1438
01:14:35,580 --> 01:14:40,440
amount of data for training to

1439
01:14:38,070 --> 01:14:42,960
continuously have this amount of data

1440
01:14:40,440 --> 01:14:46,349
for training is I don't think that any I

1441
01:14:42,960 --> 01:14:48,630
mean the architectural part of the

1442
01:14:46,350 --> 01:14:51,510
machine part is the limit today I mean

1443
01:14:48,630 --> 01:14:53,990
the hardware is and the memories always

1444
01:14:51,510 --> 01:14:55,980
and always improving things with our

1445
01:14:53,990 --> 01:14:58,340
electronics colleagues it's not that the

1446
01:14:55,980 --> 01:15:01,860
probability problem is how you can get

1447
01:14:58,340 --> 01:15:06,000
this data and that you can manage

1448
01:15:01,860 --> 01:15:08,969
continuously changing because I mean as

1449
01:15:06,000 --> 01:15:12,630
we are working in an evolving model I

1450
01:15:08,970 --> 01:15:15,840
mean the chess are jewels the cat is the

1451
01:15:12,630 --> 01:15:19,530
cat the the text is the text but on the

1452
01:15:15,840 --> 01:15:21,750
other end I mean the the typical

1453
01:15:19,530 --> 01:15:25,860
approach that they have I use a 1

1454
01:15:21,750 --> 01:15:29,730
billions photo so billions of text and

1455
01:15:25,860 --> 01:15:33,519
then I can train the algorithms on this

1456
01:15:29,730 --> 01:15:36,790
on this set and then I can use the

1457
01:15:33,520 --> 01:15:40,750
the results for new tests that I didn't

1458
01:15:36,790 --> 01:15:43,300
see before I mean in this scenarios the

1459
01:15:40,750 --> 01:15:45,460
de algún is work but in our salad

1460
01:15:43,300 --> 01:15:47,920
our scenario is not that our scenario is

1461
01:15:45,460 --> 01:15:51,070
a continuous change in scenario so it's

1462
01:15:47,920 --> 01:15:54,460
not only to manage a huge amount of set

1463
01:15:51,070 --> 01:15:58,840
of data now but to manage a huge amount

1464
01:15:54,460 --> 01:16:03,550
of data now tomorrow next week and so on

1465
01:15:58,840 --> 01:16:07,360
and actually there aren't enough tools

1466
01:16:03,550 --> 01:16:09,460
that not yet I mean is a this is an open

1467
01:16:07,360 --> 01:16:11,110
it for us is a dream I mean any problem

1468
01:16:09,460 --> 01:16:15,180
before a researchers is the dream now

1469
01:16:11,110 --> 01:16:17,469
because we have problems to solve

1470
01:16:15,180 --> 01:16:21,360
please there are few questions in the

1471
01:16:17,470 --> 01:16:21,360
middle you need microphone

1472
01:16:36,880 --> 01:16:42,280
so I was curious about whether or not

1473
01:16:40,119 --> 01:16:44,199
anyone is actually attempting to develop

1474
01:16:42,280 --> 01:16:45,820
and use adversarial models in the real

1475
01:16:44,199 --> 01:16:47,589
world to attack machine learning systems

1476
01:16:45,820 --> 01:16:49,090
or when you think that might happen and

1477
01:16:47,590 --> 01:16:54,219
kind of what industries would be the

1478
01:16:49,090 --> 01:16:59,829
focal point for that okay do you want

1479
01:16:54,219 --> 01:17:02,820
the truth of the truth I don't know the

1480
01:16:59,829 --> 01:17:06,099
truth so is my opinion

1481
01:17:02,820 --> 01:17:13,030
the adversary attack I mean the attacker

1482
01:17:06,099 --> 01:17:15,570
now don't need not yet because I mean

1483
01:17:13,030 --> 01:17:20,980
even the best machine learning

1484
01:17:15,570 --> 01:17:24,460
algorithms and as I said before 99 is

1485
01:17:20,980 --> 01:17:27,089
not enough so they don't need but what I

1486
01:17:24,460 --> 01:17:31,239
can say if you use automatic attack

1487
01:17:27,090 --> 01:17:34,570
botnet they use automatic communication

1488
01:17:31,239 --> 01:17:38,290
standard communication we can in some

1489
01:17:34,570 --> 01:17:40,540
sense address the issue if there is a

1490
01:17:38,290 --> 01:17:44,889
human we are in the scene a competent

1491
01:17:40,540 --> 01:17:47,130
humans we are in the scene it wins I

1492
01:17:44,889 --> 01:17:54,820
mean as usually he wins

1493
01:17:47,130 --> 01:17:56,619
thanks please another question a bit

1494
01:17:54,820 --> 01:17:58,989
more about this principle of

1495
01:17:56,619 --> 01:18:02,170
accountability that's being developed

1496
01:17:58,989 --> 01:18:04,598
because from what I understand from what

1497
01:18:02,170 --> 01:18:06,570
you explained so they could hold the

1498
01:18:04,599 --> 01:18:08,800
person operating that algorithm

1499
01:18:06,570 --> 01:18:12,730
responsible but then that person doesn't

1500
01:18:08,800 --> 01:18:16,090
know how it's been developed so if I

1501
01:18:12,730 --> 01:18:19,839
understood what you were saying sorry no

1502
01:18:16,090 --> 01:18:22,469
no okay can you look amazing another

1503
01:18:19,840 --> 01:18:24,940
very sure when you were talking about AI

1504
01:18:22,469 --> 01:18:27,520
accountability there was something up

1505
01:18:24,940 --> 01:18:29,320
there about holding the person the

1506
01:18:27,520 --> 01:18:32,679
people developing deploying and

1507
01:18:29,320 --> 01:18:35,670
operating the AI systems yes would they

1508
01:18:32,679 --> 01:18:37,659
hold the person operating the AI system

1509
01:18:35,670 --> 01:18:39,760
responsible even if they hadn't

1510
01:18:37,659 --> 01:18:42,059
developed it so that person might not

1511
01:18:39,760 --> 01:18:45,460
know how the algorithms been developed

1512
01:18:42,060 --> 01:18:48,480
okay luckily this is just a proposal

1513
01:18:45,460 --> 01:18:53,400
just a proposal

1514
01:18:48,480 --> 01:18:56,519
but I mean the law system the society

1515
01:18:53,400 --> 01:19:01,910
wants this I mean there is a famous

1516
01:18:56,520 --> 01:19:07,430
example deep learning algorithm is walls

1517
01:19:01,910 --> 01:19:10,830
from dogs better than humans

1518
01:19:07,430 --> 01:19:14,160
but they didn't know why and after

1519
01:19:10,830 --> 01:19:17,070
months after months of research they

1520
01:19:14,160 --> 01:19:20,130
recognized that a machine didn't look at

1521
01:19:17,070 --> 01:19:22,769
the animal the machine looked at the

1522
01:19:20,130 --> 01:19:27,540
environment so an open environment the

1523
01:19:22,770 --> 01:19:30,330
boots is recognized as a world with high

1524
01:19:27,540 --> 01:19:33,060
probability in a domestic a city

1525
01:19:30,330 --> 01:19:34,920
environment today they didn't know the

1526
01:19:33,060 --> 01:19:37,740
machine learn by itself mean in some

1527
01:19:34,920 --> 01:19:40,440
sense this is real intelligence because

1528
01:19:37,740 --> 01:19:44,250
they didn't know at the beginning mud I

1529
01:19:40,440 --> 01:19:45,929
mean we cannot accept in the defense in

1530
01:19:44,250 --> 01:19:49,290
the society in the military space

1531
01:19:45,930 --> 01:19:51,990
something like this that work just war

1532
01:19:49,290 --> 01:19:56,510
it's not it's not enough but you just if

1533
01:19:51,990 --> 01:19:59,610
so I suggest ok there's another question

1534
01:19:56,510 --> 01:20:05,340
professor I particularly like your slide

1535
01:19:59,610 --> 01:20:07,559
13 sorry can we go back

1536
01:20:05,340 --> 01:20:09,840
among all the other it basically says

1537
01:20:07,560 --> 01:20:12,150
that we are looking for anomalies yeah

1538
01:20:09,840 --> 01:20:14,880
for us in particular we have an approach

1539
01:20:12,150 --> 01:20:17,910
that works much better which his face on

1540
01:20:14,880 --> 01:20:20,610
the data representation they the filter

1541
01:20:17,910 --> 01:20:24,120
ended up reprocessing we are talking

1542
01:20:20,610 --> 01:20:27,540
about forest algorithms algorithms based

1543
01:20:24,120 --> 01:20:30,120
on classification we find extremely

1544
01:20:27,540 --> 01:20:33,990
useful if we don't let the a neural

1545
01:20:30,120 --> 01:20:37,019
network run wild if we pre button the

1546
01:20:33,990 --> 01:20:40,830
information like you see in framework

1547
01:20:37,020 --> 01:20:43,650
like you see in Fourier transforms

1548
01:20:40,830 --> 01:20:46,440
gravel transforms forever to pattern

1549
01:20:43,650 --> 01:20:48,540
eyes input set you know in those cases

1550
01:20:46,440 --> 01:20:50,700
as I said before we don't get to ninety

1551
01:20:48,540 --> 01:20:53,700
percent we don't get to 98 percent but

1552
01:20:50,700 --> 01:20:55,710
we get to rates that are pretty robust

1553
01:20:53,700 --> 01:20:58,830
against change meaning that when we

1554
01:20:55,710 --> 01:21:00,920
change the dataset or we change the

1555
01:20:58,830 --> 01:21:03,890
adversary behavior the

1556
01:21:00,920 --> 01:21:06,230
she is still useful it doesn't go from

1557
01:21:03,890 --> 01:21:07,190
92 doesn't she do you agree with my last

1558
01:21:06,230 --> 01:21:10,580
comment

1559
01:21:07,190 --> 01:21:14,120
my suggestion combine multiple meters is

1560
01:21:10,580 --> 01:21:16,820
I I'm sorry I didn't present the last

1561
01:21:14,120 --> 01:21:19,910
claim by I completely agree with you and

1562
01:21:16,820 --> 01:21:22,549
I we cannot have just one one approach

1563
01:21:19,910 --> 01:21:27,469
we have to combine multiple fir I agree

1564
01:21:22,550 --> 01:21:29,449
perfectly this is the dead Iraq you can

1565
01:21:27,469 --> 01:21:33,620
take your seat and we will move into

1566
01:21:29,449 --> 01:21:39,940
panel discussion so let's let's take

1567
01:21:33,620 --> 01:21:41,300
first question for panel setting oh okay

1568
01:21:39,940 --> 01:21:43,928
okay

1569
01:21:41,300 --> 01:21:43,929
microphone is here

1570
01:21:47,649 --> 01:21:53,110
first you know thank you very much for

1571
01:21:49,869 --> 01:21:55,119
interesting talk and I do have a kind of

1572
01:21:53,110 --> 01:21:58,478
follow-up question actually it's not

1573
01:21:55,119 --> 01:22:01,688
you know question but rather than as a

1574
01:21:58,479 --> 01:22:09,189
statement you know again on this

1575
01:22:01,689 --> 01:22:13,149
thirteen slide and and the statement

1576
01:22:09,189 --> 01:22:17,050
that any detection of an anomaly may

1577
01:22:13,149 --> 01:22:21,099
lead to a malicious attack which is

1578
01:22:17,050 --> 01:22:24,039
pretty true but I would caution not to

1579
01:22:21,099 --> 01:22:28,809
generalize these principles because in

1580
01:22:24,039 --> 01:22:32,199
AI area in learning we actually for

1581
01:22:28,809 --> 01:22:38,110
example let's say emergent behavior of

1582
01:22:32,199 --> 01:22:42,428
complex systems the in principle the

1583
01:22:38,110 --> 01:22:45,188
emergent behavior leads to discovery to

1584
01:22:42,429 --> 01:22:48,070
new forms of species like in a world

1585
01:22:45,189 --> 01:22:49,989
like in evolution and they should be

1586
01:22:48,070 --> 01:22:53,530
considered like a positive feature

1587
01:22:49,989 --> 01:22:55,749
rather than something negative so yes

1588
01:22:53,530 --> 01:22:59,648
your statement is correct in the

1589
01:22:55,749 --> 01:23:03,429
specific domain but not to generalize in

1590
01:22:59,649 --> 01:23:07,090
other systems and processes if I can

1591
01:23:03,429 --> 01:23:11,649
generalize your comment it's true I mean

1592
01:23:07,090 --> 01:23:14,499
what we have to understand is not just a

1593
01:23:11,649 --> 01:23:16,929
model that is training and then a model

1594
01:23:14,499 --> 01:23:18,820
that is applied at a model that is

1595
01:23:16,929 --> 01:23:22,389
trained that is applied that is

1596
01:23:18,820 --> 01:23:27,459
continuously improved and so on and so

1597
01:23:22,389 --> 01:23:31,329
in in some sense the training part will

1598
01:23:27,459 --> 01:23:34,929
never hand because some emergent feature

1599
01:23:31,329 --> 01:23:37,119
can can be everyday answered even

1600
01:23:34,929 --> 01:23:38,739
something that you didn't think about or

1601
01:23:37,119 --> 01:23:45,308
some correlation that you didn't think

1602
01:23:38,739 --> 01:23:48,669
in advance I mean is some sense one of

1603
01:23:45,309 --> 01:23:51,459
the most challenging problem setting

1604
01:23:48,669 --> 01:23:53,979
that we have because you know different

1605
01:23:51,459 --> 01:23:55,729
data different attacks different system

1606
01:23:53,979 --> 01:24:00,989
because our systems change

1607
01:23:55,729 --> 01:24:03,239
and even without adversarial attacks is

1608
01:24:00,989 --> 01:24:05,098
already a really complex problem

1609
01:24:03,239 --> 01:24:07,320
this already is a complex problem then a

1610
01:24:05,099 --> 01:24:09,959
continuous improvement different model

1611
01:24:07,320 --> 01:24:18,179
the integration is the only way I mean

1612
01:24:09,959 --> 01:24:22,550
is easier to say than to implement do

1613
01:24:18,179 --> 01:24:22,550
you have topic for discussion yes please

1614
01:24:25,170 --> 01:24:29,250
I'd like to know just in general what

1615
01:24:27,180 --> 01:24:30,600
the panel thinks the impact of quantum

1616
01:24:29,250 --> 01:24:34,230
computing would have on their different

1617
01:24:30,600 --> 01:24:42,000
models yes and although no patent for

1618
01:24:34,230 --> 01:24:50,459
all three of you yeah I miss it quantum

1619
01:24:42,000 --> 01:24:53,400
computer and blockchain quantum computer

1620
01:24:50,460 --> 01:24:57,600
I don't I mean my colleagues want to

1621
01:24:53,400 --> 01:25:00,240
expect there are two quantum computing

1622
01:24:57,600 --> 01:25:05,160
it can be divided into different parts

1623
01:25:00,240 --> 01:25:08,460
one is quantum communications for

1624
01:25:05,160 --> 01:25:12,240
transmission that already worked it was

1625
01:25:08,460 --> 01:25:15,390
an interesting display experience from

1626
01:25:12,240 --> 01:25:17,550
China satellite to platform one is

1627
01:25:15,390 --> 01:25:20,120
whistlin or the other in China and so

1628
01:25:17,550 --> 01:25:25,620
quantum communication already wars

1629
01:25:20,120 --> 01:25:28,290
quantum computing is is a desire I mean

1630
01:25:25,620 --> 01:25:32,640
I mean the problem is still a problem we

1631
01:25:28,290 --> 01:25:36,420
are improving improving but we have not

1632
01:25:32,640 --> 01:25:38,400
only to improve the hardware part but

1633
01:25:36,420 --> 01:25:41,900
then we need a lot of software we have

1634
01:25:38,400 --> 01:25:46,469
to change completely the software so

1635
01:25:41,900 --> 01:25:49,440
it's not something that will be there in

1636
01:25:46,470 --> 01:25:54,050
few years this is on the other end our

1637
01:25:49,440 --> 01:25:58,589
community not me already are working on

1638
01:25:54,050 --> 01:26:01,350
on post quantum cryptography so the

1639
01:25:58,590 --> 01:26:04,950
academic research is already trying to

1640
01:26:01,350 --> 01:26:09,660
face the issue of tomorrow as far as I

1641
01:26:04,950 --> 01:26:11,550
know I don't know if you have more our

1642
01:26:09,660 --> 01:26:16,200
company is working on quantum

1643
01:26:11,550 --> 01:26:18,210
cryptography but for artificial

1644
01:26:16,200 --> 01:26:21,900
intelligence application I don't know

1645
01:26:18,210 --> 01:26:26,870
now it's not developed yet the hardware

1646
01:26:21,900 --> 01:26:26,870
and so on it's too early I see

1647
01:26:27,390 --> 01:26:31,530
okay another puppy here

1648
01:26:37,960 --> 01:26:42,760
thank you for your presentations and a

1649
01:26:41,200 --> 01:26:44,710
question for the for the panel it's an

1650
01:26:42,760 --> 01:26:46,630
open question in what way would you

1651
01:26:44,710 --> 01:26:57,570
think that machine learning would be

1652
01:26:46,630 --> 01:27:01,540
helpful in attribution of attack I know

1653
01:26:57,570 --> 01:27:03,610
I'm not sure I think for this test case

1654
01:27:01,540 --> 01:27:06,280
it's even much much harder to get the

1655
01:27:03,610 --> 01:27:09,160
datasets with which you could train such

1656
01:27:06,280 --> 01:27:13,090
a system so I don't see a

1657
01:27:09,160 --> 01:27:15,510
straightforward way to you earn a

1658
01:27:13,090 --> 01:27:18,940
promising way to use machine learning

1659
01:27:15,510 --> 01:27:23,650
there but maybe my colleagues have more

1660
01:27:18,940 --> 01:27:25,030
ideas emotions no sorry please no

1661
01:27:23,650 --> 01:27:28,210
attribution in general is very

1662
01:27:25,030 --> 01:27:30,639
complicated problem it's very very hard

1663
01:27:28,210 --> 01:27:32,260
to say

1664
01:27:30,640 --> 01:27:34,630
artificial intelligence depends on that

1665
01:27:32,260 --> 01:27:39,570
and if that is wrong you can produce

1666
01:27:34,630 --> 01:27:39,570
wrong attribution results it's dangerous

1667
01:27:41,520 --> 01:27:49,660
attribution is the problem all the

1668
01:27:47,260 --> 01:27:53,950
international community is based on this

1669
01:27:49,660 --> 01:28:01,990
fundamental and the the problem with

1670
01:27:53,950 --> 01:28:07,090
attribution is not only I mean we can

1671
01:28:01,990 --> 01:28:11,679
easily artifact the source I mean the

1672
01:28:07,090 --> 01:28:15,570
where attribution because there was some

1673
01:28:11,680 --> 01:28:18,400
comment in Islamic language come on

1674
01:28:15,570 --> 01:28:21,460
anybody can introduce some Russian

1675
01:28:18,400 --> 01:28:28,379
common source I mean it's not enough

1676
01:28:21,460 --> 01:28:31,990
it's not enough I think that these

1677
01:28:28,380 --> 01:28:34,570
models can help to circumvent the

1678
01:28:31,990 --> 01:28:38,620
problem mean something that should be in

1679
01:28:34,570 --> 01:28:41,349
this area because they use this tool but

1680
01:28:38,620 --> 01:28:45,130
then you need others other means I mean

1681
01:28:41,350 --> 01:28:47,920
you need other means that other other

1682
01:28:45,130 --> 01:28:51,460
approaches against is a combination is

1683
01:28:47,920 --> 01:28:53,739
any digital investigation is not

1684
01:28:51,460 --> 01:28:57,190
cannot be just digital not just based on

1685
01:28:53,739 --> 01:28:59,320
digital because in attack I mean I don't

1686
01:28:57,190 --> 01:29:02,790
think that there are any people now that

1687
01:28:59,320 --> 01:29:07,299
say they're build a completely new

1688
01:29:02,790 --> 01:29:09,640
malware a completely new botnet a new

1689
01:29:07,300 --> 01:29:13,510
button it is a combination of different

1690
01:29:09,640 --> 01:29:17,290
parts that are in the wild so the

1691
01:29:13,510 --> 01:29:22,830
attackers typically at the some software

1692
01:29:17,290 --> 01:29:26,170
combine had some masquerading some new

1693
01:29:22,830 --> 01:29:31,120
cryptography but most of the software is

1694
01:29:26,170 --> 01:29:34,900
already there is already there so can

1695
01:29:31,120 --> 01:29:38,170
you say that no it's not the environment

1696
01:29:34,900 --> 01:29:46,299
well you can say this I can tell you in

1697
01:29:38,170 --> 01:29:47,580
private there is a station here I don't

1698
01:29:46,300 --> 01:29:55,000
like polonium M

1699
01:29:47,580 --> 01:29:56,820
thank you do we have another topic no

1700
01:29:55,000 --> 01:30:00,580
then I will ask you a final question

1701
01:29:56,820 --> 01:30:04,299
with expected one sentence answer should

1702
01:30:00,580 --> 01:30:07,930
we be concerned about machine learning

1703
01:30:04,300 --> 01:30:12,780
in security systems in 5-10 years or are

1704
01:30:07,930 --> 01:30:12,780
we going in in some dangerous direction

1705
01:30:14,010 --> 01:30:19,810
the direction as I said that the

1706
01:30:16,900 --> 01:30:22,839
direction is this there is no the

1707
01:30:19,810 --> 01:30:26,380
problem is the the finish line and we

1708
01:30:22,840 --> 01:30:30,850
are not arrived on on the probably there

1709
01:30:26,380 --> 01:30:35,140
will not be a finish line I mean the

1710
01:30:30,850 --> 01:30:39,340
problem the society should decide which

1711
01:30:35,140 --> 01:30:41,170
is the autonomy that we want to give to

1712
01:30:39,340 --> 01:30:44,410
the machines I mean this is the real

1713
01:30:41,170 --> 01:30:48,910
question for a Anatoly for security how

1714
01:30:44,410 --> 01:30:52,620
much the machine can take the power in

1715
01:30:48,910 --> 01:30:55,780
games they want I mean in chess go poker

1716
01:30:52,620 --> 01:30:58,840
they win every time so they are better

1717
01:30:55,780 --> 01:31:00,000
than us in other context they are better

1718
01:30:58,840 --> 01:31:03,330
than us

1719
01:31:00,000 --> 01:31:07,560
Health System imagery connection they

1720
01:31:03,330 --> 01:31:10,199
are better than us in other open

1721
01:31:07,560 --> 01:31:13,110
environment where the decision is not

1722
01:31:10,199 --> 01:31:15,389
clear when we cannot apply a clear

1723
01:31:13,110 --> 01:31:17,880
optimization function because all the

1724
01:31:15,390 --> 01:31:19,910
machine learning is a actually data and

1725
01:31:17,880 --> 01:31:25,650
optimization and continuous optimization

1726
01:31:19,910 --> 01:31:28,790
if we don't tell the this optimization

1727
01:31:25,650 --> 01:31:31,290
file if we don't take the ground truth

1728
01:31:28,790 --> 01:31:33,840
we have a problem with the ground truth

1729
01:31:31,290 --> 01:31:36,630
we cannot compare the previous results

1730
01:31:33,840 --> 01:31:38,670
with another one it's difficult the

1731
01:31:36,630 --> 01:31:41,670
probably is not of the machine Lamy the

1732
01:31:38,670 --> 01:31:45,930
problem is is a is our problem that

1733
01:31:41,670 --> 01:31:48,300
decide to the odd source this decision

1734
01:31:45,930 --> 01:31:51,300
to a machine it's not a problem of the

1735
01:31:48,300 --> 01:31:58,050
machine the machine does whatever he can

1736
01:31:51,300 --> 01:32:01,530
but in some in some areas before quantum

1737
01:31:58,050 --> 01:32:04,680
computing that will open new issues and

1738
01:32:01,530 --> 01:32:07,380
they will open over a new solution we

1739
01:32:04,680 --> 01:32:10,710
are in the middle now there is an

1740
01:32:07,380 --> 01:32:17,820
interesting case as I know it is

1741
01:32:10,710 --> 01:32:20,760
Japanese so check that lose 20 millions

1742
01:32:17,820 --> 01:32:24,019
dollars because the algorithmic a

1743
01:32:20,760 --> 01:32:29,610
financial an algorithm enansal

1744
01:32:24,020 --> 01:32:32,520
investment made mistake it was to suit

1745
01:32:29,610 --> 01:32:35,130
the algorithm of the of the product so

1746
01:32:32,520 --> 01:32:37,860
it's something strange can you sue an

1747
01:32:35,130 --> 01:32:43,230
alchemist a it is related also to the

1748
01:32:37,860 --> 01:32:46,469
problem with assignment to liability I

1749
01:32:43,230 --> 01:32:49,820
mean it's a very interesting open

1750
01:32:46,469 --> 01:32:51,000
question that the society lawyers

1751
01:32:49,820 --> 01:32:54,330
politicals

1752
01:32:51,000 --> 01:32:56,430
and the technology we have to solve and

1753
01:32:54,330 --> 01:32:59,340
I mean I don't have the solution I don't

1754
01:32:56,430 --> 01:33:01,230
think that anybody here as the so this

1755
01:32:59,340 --> 01:33:05,910
is the solution we have to study I mean

1756
01:33:01,230 --> 01:33:09,809
if there is a positive effect of this

1757
01:33:05,910 --> 01:33:12,280
Congress is that we we can collaborate

1758
01:33:09,810 --> 01:33:15,250
we can discuss from different

1759
01:33:12,280 --> 01:33:17,710
different cultures and this I think that

1760
01:33:15,250 --> 01:33:19,930
is the real direction to discuss

1761
01:33:17,710 --> 01:33:21,550
together okay thank you roll on do you

1762
01:33:19,930 --> 01:33:22,360
have any concerns about future of

1763
01:33:21,550 --> 01:33:24,820
machine learning

1764
01:33:22,360 --> 01:33:28,389
I seen it depends on particular change

1765
01:33:24,820 --> 01:33:32,880
in some cases it's very good applicable

1766
01:33:28,390 --> 01:33:36,880
like image processing and some high risk

1767
01:33:32,880 --> 01:33:41,100
tasks maybe it's too dangerous because

1768
01:33:36,880 --> 01:33:45,250
we will not get hundred percent accuracy

1769
01:33:41,100 --> 01:33:49,930
okay Roland any final thoughts I think

1770
01:33:45,250 --> 01:33:52,870
we are at least in cybersecurity it's

1771
01:33:49,930 --> 01:33:55,270
not that we need to be worried about

1772
01:33:52,870 --> 01:33:56,769
what machine learning does it's more

1773
01:33:55,270 --> 01:33:58,140
that we need to be aware that machine

1774
01:33:56,770 --> 01:34:01,180
learning probably does not do everything

1775
01:33:58,140 --> 01:34:03,670
we want and it's always machine learning

1776
01:34:01,180 --> 01:34:05,830
more helps to fight against things that

1777
01:34:03,670 --> 01:34:09,040
we know or that happen in the past and

1778
01:34:05,830 --> 01:34:12,100
we have on the other hand skilled

1779
01:34:09,040 --> 01:34:13,420
attackers that do things that we do not

1780
01:34:12,100 --> 01:34:16,840
expect and that our machine learning

1781
01:34:13,420 --> 01:34:20,680
does not expect we cannot expect the

1782
01:34:16,840 --> 01:34:23,080
machine learning to defend us against

1783
01:34:20,680 --> 01:34:25,770
everything okay thank you let's give a

1784
01:34:23,080 --> 01:34:25,769
round of applause

