1
00:00:00,030 --> 00:00:03,899
talking about people not as the

2
00:00:01,650 --> 00:00:07,919
strongest link but from my perspective

3
00:00:03,899 --> 00:00:11,340
how people are and can enable to be more

4
00:00:07,919 --> 00:00:14,460
of a stronger link now what I'm talking

5
00:00:11,340 --> 00:00:16,259
about today is how we make people the

6
00:00:14,460 --> 00:00:19,500
strongest link and that's my first

7
00:00:16,260 --> 00:00:21,779
thought on it is that actually humor can

8
00:00:19,500 --> 00:00:23,698
be really effective and often when we're

9
00:00:21,779 --> 00:00:27,000
talking about cybersecurity we make it

10
00:00:23,699 --> 00:00:28,500
very serious I'm very dry and that means

11
00:00:27,000 --> 00:00:30,109
as soon as we start to say to people

12
00:00:28,500 --> 00:00:32,399
we're going to talk about cybersecurity

13
00:00:30,109 --> 00:00:34,110
they're expecting something sort of

14
00:00:32,399 --> 00:00:36,090
serious and dry and thinking that

15
00:00:34,110 --> 00:00:38,190
they're going to be bored if we can turn

16
00:00:36,090 --> 00:00:40,530
that on its head that's one way of

17
00:00:38,190 --> 00:00:43,230
getting engagement why is this so

18
00:00:40,530 --> 00:00:45,420
important of course one of the reasons

19
00:00:43,230 --> 00:00:48,569
is the fact that people have become more

20
00:00:45,420 --> 00:00:51,719
and more important to cybersecurity for

21
00:00:48,570 --> 00:00:54,750
families for organizations for countries

22
00:00:51,719 --> 00:00:56,309
and this is partly because of the huge

23
00:00:54,750 --> 00:00:59,250
rise that we have seen in social

24
00:00:56,309 --> 00:01:01,500
engineering over the last few years it's

25
00:00:59,250 --> 00:01:04,110
become probably the biggest threat that

26
00:01:01,500 --> 00:01:08,430
my corporate clients come to us about

27
00:01:04,110 --> 00:01:11,039
and we certainly see that this kind of

28
00:01:08,430 --> 00:01:14,400
combination of an external malicious

29
00:01:11,040 --> 00:01:17,240
attacker and people is what's at the

30
00:01:14,400 --> 00:01:21,659
heart of so many breaches so many issues

31
00:01:17,240 --> 00:01:23,009
not least arguably election hacking so

32
00:01:21,659 --> 00:01:24,810
we're asking people to do things that

33
00:01:23,009 --> 00:01:27,659
are pretty much impossible don't click

34
00:01:24,810 --> 00:01:29,520
on suspicious links well what's a

35
00:01:27,659 --> 00:01:32,729
suspicious link how is someone supposed

36
00:01:29,520 --> 00:01:36,090
to identify that and they have to click

37
00:01:32,729 --> 00:01:37,979
on links that's their job so we're

38
00:01:36,090 --> 00:01:40,950
making it very hard on people but we're

39
00:01:37,979 --> 00:01:44,100
also not recognizing where people get it

40
00:01:40,950 --> 00:01:46,170
right and there's a lot more that needs

41
00:01:44,100 --> 00:01:48,689
to go in this because once you start

42
00:01:46,170 --> 00:01:51,210
looking for how we've made progress you

43
00:01:48,689 --> 00:01:54,298
realize how far we have come from the

44
00:01:51,210 --> 00:01:56,639
early days where we're having the basic

45
00:01:54,299 --> 00:01:58,500
technical controls you know where we're

46
00:01:56,640 --> 00:02:00,509
putting in place the first firewalls the

47
00:01:58,500 --> 00:02:03,719
first antivirus starting to use

48
00:02:00,509 --> 00:02:06,270
passwords fast-forward to recent years

49
00:02:03,719 --> 00:02:08,128
and we've moved on from just the basic

50
00:02:06,270 --> 00:02:11,790
technical controls and how we improve

51
00:02:08,128 --> 00:02:13,230
those to more human based controls and a

52
00:02:11,790 --> 00:02:18,179
more human understanding

53
00:02:13,230 --> 00:02:20,099
of security and for me this is a change

54
00:02:18,180 --> 00:02:22,170
a kind of a paradigm shift that we're

55
00:02:20,099 --> 00:02:24,929
starting to see in the industry that is

56
00:02:22,170 --> 00:02:27,530
moving away from just trying to tick the

57
00:02:24,930 --> 00:02:30,330
box of the human side to actually

58
00:02:27,530 --> 00:02:33,480
looking at what is it that makes people

59
00:02:30,330 --> 00:02:35,730
tick how do they behave and how do we

60
00:02:33,480 --> 00:02:39,780
need to incorporate that into our

61
00:02:35,730 --> 00:02:43,768
approach so how do we do this how do we

62
00:02:39,780 --> 00:02:45,930
think about people first one thing that

63
00:02:43,769 --> 00:02:48,000
I think is really interesting one

64
00:02:45,930 --> 00:02:51,569
element we can take from psychology is

65
00:02:48,000 --> 00:02:54,959
the understanding of social proof so

66
00:02:51,569 --> 00:02:57,450
social proof is the notion that if we as

67
00:02:54,959 --> 00:03:01,260
humans don't know what to do we copy

68
00:02:57,450 --> 00:03:03,839
other people with social proof we look

69
00:03:01,260 --> 00:03:06,569
to other people in general but anyone

70
00:03:03,840 --> 00:03:08,670
that we particularly respect anyone that

71
00:03:06,569 --> 00:03:13,048
we admire anyone in a position of

72
00:03:08,670 --> 00:03:14,660
authority we are more likely to mimic so

73
00:03:13,049 --> 00:03:18,299
when it comes to cybersecurity

74
00:03:14,660 --> 00:03:20,250
leadership is so important if the

75
00:03:18,299 --> 00:03:23,400
leaders of an organization or of a

76
00:03:20,250 --> 00:03:25,079
country or of a family aren't seem to be

77
00:03:23,400 --> 00:03:27,870
acting in the way that they are

78
00:03:25,079 --> 00:03:30,329
recommending then people will follow the

79
00:03:27,870 --> 00:03:32,940
actions if people are acting in securely

80
00:03:30,329 --> 00:03:36,180
despite what they say then they become

81
00:03:32,940 --> 00:03:38,430
the social norms so what we need to do

82
00:03:36,180 --> 00:03:42,919
is speak to people in a more empowering

83
00:03:38,430 --> 00:03:45,569
way and embrace social proof so why I am

84
00:03:42,919 --> 00:03:47,519
strategically optimistic is down to

85
00:03:45,569 --> 00:03:51,599
what's known in neuroscience as the

86
00:03:47,519 --> 00:03:54,450
optimism bias good news is that optimism

87
00:03:51,599 --> 00:03:56,548
makes people try harder but if we can

88
00:03:54,450 --> 00:03:59,040
tell people actually these basic

89
00:03:56,549 --> 00:04:01,349
behaviors good passwords use a password

90
00:03:59,040 --> 00:04:04,440
manager two-factor authentication

91
00:04:01,349 --> 00:04:07,530
you know rapport phishing emails if we

92
00:04:04,440 --> 00:04:10,590
tell people these basic practices will

93
00:04:07,530 --> 00:04:13,530
protect them from what 95 98 percent of

94
00:04:10,590 --> 00:04:15,739
the threat which is true then they're

95
00:04:13,530 --> 00:04:18,978
more likely to engage in those behavior

96
00:04:15,739 --> 00:04:22,650
so that's my second recommendation

97
00:04:18,978 --> 00:04:24,330
engage with positivity so when we are

98
00:04:22,650 --> 00:04:26,489
talking to people about something scary

99
00:04:24,330 --> 00:04:27,780
and trying to change their behavior

100
00:04:26,490 --> 00:04:30,600
we're engaging in

101
00:04:27,780 --> 00:04:32,820
what's known as a fear appeal and that's

102
00:04:30,600 --> 00:04:36,510
led to this which is known as the

103
00:04:32,820 --> 00:04:39,150
extended parallel process model and this

104
00:04:36,510 --> 00:04:41,190
model is to show how you talk about

105
00:04:39,150 --> 00:04:43,770
something scary to get people to

106
00:04:41,190 --> 00:04:45,690
actually engage with the danger rather

107
00:04:43,770 --> 00:04:48,659
than just engage with the emotional

108
00:04:45,690 --> 00:04:51,780
response which is the fear that those

109
00:04:48,660 --> 00:04:54,660
responses will be effective and also

110
00:04:51,780 --> 00:04:56,520
that they are capable of engaging with

111
00:04:54,660 --> 00:05:00,270
them that they have the time the money

112
00:04:56,520 --> 00:05:02,880
the technical know-how the support only

113
00:05:00,270 --> 00:05:05,310
then if we convince people of all of

114
00:05:02,880 --> 00:05:09,030
that will they engage with the actual

115
00:05:05,310 --> 00:05:12,360
danger if we don't they will just engage

116
00:05:09,030 --> 00:05:14,340
with the emotion the fear so yes we need

117
00:05:12,360 --> 00:05:16,500
to talk about the threat but we need to

118
00:05:14,340 --> 00:05:20,369
do so in a way that recognizes the

119
00:05:16,500 --> 00:05:23,880
psychological response and we also don't

120
00:05:20,370 --> 00:05:25,830
always have to try to use fear we can

121
00:05:23,880 --> 00:05:29,700
think about how actually we can

122
00:05:25,830 --> 00:05:33,300
intrinsically motivate how do we spread

123
00:05:29,700 --> 00:05:35,610
empowerment rather than fear and one of

124
00:05:33,300 --> 00:05:39,180
the most effective mechanisms I've found

125
00:05:35,610 --> 00:05:41,460
in a company is what's known often as a

126
00:05:39,180 --> 00:05:43,530
Champions Network and ambassadors

127
00:05:41,460 --> 00:05:45,570
Network whatever you want to call it

128
00:05:43,530 --> 00:05:48,359
people who are not cyber security

129
00:05:45,570 --> 00:05:51,659
experts who act kind of like fire and

130
00:05:48,360 --> 00:05:55,560
safety marshals to represent cyber

131
00:05:51,660 --> 00:05:57,690
security in their department and I've

132
00:05:55,560 --> 00:06:00,330
always worked on this within companies

133
00:05:57,690 --> 00:06:02,370
but I think it's a great model outside

134
00:06:00,330 --> 00:06:04,680
of that I think this can be used between

135
00:06:02,370 --> 00:06:06,840
companies I think this could be used to

136
00:06:04,680 --> 00:06:09,990
scale up how we talk about cyber

137
00:06:06,840 --> 00:06:13,140
security not just at a company level but

138
00:06:09,990 --> 00:06:14,580
potentially a national level because

139
00:06:13,140 --> 00:06:18,240
this is what we need we need herd

140
00:06:14,580 --> 00:06:21,419
immunity and as soon as we are lacking

141
00:06:18,240 --> 00:06:23,070
that that's when we are all weaker so

142
00:06:21,419 --> 00:06:27,270
that's always my final recommendation

143
00:06:23,070 --> 00:06:29,610
how do we build a Champions Network this

144
00:06:27,270 --> 00:06:31,770
stuff is not about having new messages

145
00:06:29,610 --> 00:06:34,830
it's about how you shape the messages

146
00:06:31,770 --> 00:06:37,919
how you frame communications to have the

147
00:06:34,830 --> 00:06:41,370
most impact and enable people to be the

148
00:06:37,919 --> 00:06:43,409
strongest link embrace social proof and

149
00:06:41,370 --> 00:06:46,020
engage with positivity spread

150
00:06:43,410 --> 00:06:48,780
empowerment not fear and build a

151
00:06:46,020 --> 00:06:50,280
Champions Network if you're interested

152
00:06:48,780 --> 00:06:51,869
in anything I've talked about today and

153
00:06:50,280 --> 00:06:54,570
if you're not familiar with the

154
00:06:51,870 --> 00:06:56,160
behavioral economics with the psychology

155
00:06:54,570 --> 00:06:58,919
with the neuroscience then these are

156
00:06:56,160 --> 00:07:02,300
three great books to start with and so

157
00:06:58,919 --> 00:07:02,299
that's my take away reading list

