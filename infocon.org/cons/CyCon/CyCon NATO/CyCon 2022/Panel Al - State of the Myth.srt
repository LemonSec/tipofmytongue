1
00:00:00,160 --> 00:00:01,839
so good afternoon and welcome

2
00:00:01,839 --> 00:00:03,439
distinguished guests and ladies and

3
00:00:03,439 --> 00:00:05,440
gentlemen it's a real pleasure and an

4
00:00:05,440 --> 00:00:06,879
honor to be the moderator of this

5
00:00:06,879 --> 00:00:08,559
session this afternoon

6
00:00:08,559 --> 00:00:10,480
um as you can already guess you know i

7
00:00:10,480 --> 00:00:12,080
do some research in this area but it's

8
00:00:12,080 --> 00:00:14,160
my pleasure to actually be the

9
00:00:14,160 --> 00:00:16,000
the the glue that binds together a

10
00:00:16,000 --> 00:00:17,279
number of interesting talks that we're

11
00:00:17,279 --> 00:00:18,960
going to have this afternoon

12
00:00:18,960 --> 00:00:20,480
and for that reason i'm just going to

13
00:00:20,480 --> 00:00:21,920
limit myself to a fairly short

14
00:00:21,920 --> 00:00:23,840
introduction then i'll introduce our

15
00:00:23,840 --> 00:00:26,240
speakers and give you a short overview

16
00:00:26,240 --> 00:00:28,480
of what the uh what the rules of the

17
00:00:28,480 --> 00:00:29,920
game are i'd like to encourage

18
00:00:29,920 --> 00:00:32,000
discussion and questions so there'll be

19
00:00:32,000 --> 00:00:33,920
a couple of opportunities to ask these

20
00:00:33,920 --> 00:00:35,920
questions as well

21
00:00:35,920 --> 00:00:37,360
i think many of the speakers already

22
00:00:37,360 --> 00:00:39,120
this morning have

23
00:00:39,120 --> 00:00:40,719
have echoed that many of us are very

24
00:00:40,719 --> 00:00:42,960
thankful to be here again

25
00:00:42,960 --> 00:00:45,280
certainly a big round of thanks to the

26
00:00:45,280 --> 00:00:47,840
organizers to ccdcoe and the cycon

27
00:00:47,840 --> 00:00:50,079
organizers it's really visionary that

28
00:00:50,079 --> 00:00:52,160
they actually put together panels uh

29
00:00:52,160 --> 00:00:54,079
like this and actually bring in speakers

30
00:00:54,079 --> 00:00:55,840
that i think all of you are are

31
00:00:55,840 --> 00:00:58,640
interested in hearing from and for those

32
00:00:58,640 --> 00:00:59,920
of you that are here for the first time

33
00:00:59,920 --> 00:01:01,600
or the first time in person you may not

34
00:01:01,600 --> 00:01:03,680
know that there's a lot of competition

35
00:01:03,680 --> 00:01:05,519
to get room number one

36
00:01:05,519 --> 00:01:08,400
and it's relatively rare that a

37
00:01:08,400 --> 00:01:10,240
somewhat technical discussion actually

38
00:01:10,240 --> 00:01:12,159
gets to have room number one so it's

39
00:01:12,159 --> 00:01:14,000
very nice to be back here and of course

40
00:01:14,000 --> 00:01:16,000
for me moderating as well and listening

41
00:01:16,000 --> 00:01:17,280
to the speakers

42
00:01:17,280 --> 00:01:19,280
so uh before i dive in and introduce the

43
00:01:19,280 --> 00:01:20,880
speakers i'd just like to mention the

44
00:01:20,880 --> 00:01:24,240
the title of the panel and of course our

45
00:01:24,240 --> 00:01:25,680
our theme for this year within the

46
00:01:25,680 --> 00:01:27,520
conference keep moving the title of

47
00:01:27,520 --> 00:01:30,400
panel is ai the state of the myth

48
00:01:30,400 --> 00:01:31,520
i'm not going to give you much more

49
00:01:31,520 --> 00:01:33,200
detail about that but we'll let the

50
00:01:33,200 --> 00:01:35,360
speakers elaborate on that the one thing

51
00:01:35,360 --> 00:01:37,280
i would like to emphasize is that

52
00:01:37,280 --> 00:01:39,439
artificial intelligence ai researchers

53
00:01:39,439 --> 00:01:41,040
in general

54
00:01:41,040 --> 00:01:42,640
have been viewed by you know something

55
00:01:42,640 --> 00:01:44,320
the computer science community as being

56
00:01:44,320 --> 00:01:45,680
charlatans

57
00:01:45,680 --> 00:01:48,720
for about 55 years uh ai researchers

58
00:01:48,720 --> 00:01:50,000
have been on the verge of the big

59
00:01:50,000 --> 00:01:51,600
breakthroughs that actually bring us

60
00:01:51,600 --> 00:01:52,479
true

61
00:01:52,479 --> 00:01:55,840
modern artificial intelligence and i can

62
00:01:55,840 --> 00:01:58,159
safely say that i'm you know currently a

63
00:01:58,159 --> 00:02:00,079
believer that we really are on the verge

64
00:02:00,079 --> 00:02:03,200
of meaningful advances in that direction

65
00:02:03,200 --> 00:02:05,600
not just with self-driving cars and

66
00:02:05,600 --> 00:02:07,280
various other kinds of automated systems

67
00:02:07,280 --> 00:02:08,878
that actually make the news very often

68
00:02:08,878 --> 00:02:11,840
but also automation of decision making

69
00:02:11,840 --> 00:02:13,840
and things along those lines so the

70
00:02:13,840 --> 00:02:15,680
reason i mentioned decision making is i

71
00:02:15,680 --> 00:02:16,959
feel that

72
00:02:16,959 --> 00:02:19,360
this is one of the under valued but

73
00:02:19,360 --> 00:02:21,200
extremely important aspects of how we

74
00:02:21,200 --> 00:02:24,400
conduct things so if i were to um to

75
00:02:24,400 --> 00:02:26,400
choose the two single most important

76
00:02:26,400 --> 00:02:28,640
things that any living thing does

77
00:02:28,640 --> 00:02:29,840
one of the two would be taking a

78
00:02:29,840 --> 00:02:31,680
decision so decision making actually at

79
00:02:31,680 --> 00:02:32,640
the core

80
00:02:32,640 --> 00:02:34,959
of potential successful outcomes not

81
00:02:34,959 --> 00:02:37,280
just within uh let's say a cyber and

82
00:02:37,280 --> 00:02:39,280
military context but also

83
00:02:39,280 --> 00:02:41,840
running our careers uh running our daily

84
00:02:41,840 --> 00:02:43,519
lives and so on so taking a decision is

85
00:02:43,519 --> 00:02:46,000
extremely important and we are sort of

86
00:02:46,000 --> 00:02:47,760
the product of the accumulation of the

87
00:02:47,760 --> 00:02:49,760
various decisions that we make and we'd

88
00:02:49,760 --> 00:02:51,360
like to make high quality decisions

89
00:02:51,360 --> 00:02:53,599
which means high quality inputs and of

90
00:02:53,599 --> 00:02:55,120
course executing on the decisions

91
00:02:55,120 --> 00:02:56,560
afterwards so

92
00:02:56,560 --> 00:02:57,920
the decision

93
00:02:57,920 --> 00:03:00,080
level which is considerably higher than

94
00:03:00,080 --> 00:03:02,480
data security information security

95
00:03:02,480 --> 00:03:04,080
eventually takes us up to knowledge

96
00:03:04,080 --> 00:03:06,080
security and that's where decisions get

97
00:03:06,080 --> 00:03:07,840
taken and where artificial intelligence

98
00:03:07,840 --> 00:03:10,080
sits and we need to look at how to use

99
00:03:10,080 --> 00:03:12,000
artificial intelligence appropriately to

100
00:03:12,000 --> 00:03:14,480
augment and provide an audit trail in

101
00:03:14,480 --> 00:03:16,159
our decision making but also we need to

102
00:03:16,159 --> 00:03:17,760
look at security of artificial

103
00:03:17,760 --> 00:03:19,519
intelligence systems

104
00:03:19,519 --> 00:03:20,480
to make sure that they're not

105
00:03:20,480 --> 00:03:23,280
susceptible so i think the time is now

106
00:03:23,280 --> 00:03:25,760
for us to take a look at how to do cyber

107
00:03:25,760 --> 00:03:27,200
security in particular knowledge

108
00:03:27,200 --> 00:03:29,920
security decision security and this is

109
00:03:29,920 --> 00:03:32,000
what we can call the high hanging fruit

110
00:03:32,000 --> 00:03:33,440
okay so everyone knows how to deal with

111
00:03:33,440 --> 00:03:35,360
the low hanging fruit we don't always do

112
00:03:35,360 --> 00:03:37,599
it properly but we now actually just

113
00:03:37,599 --> 00:03:38,879
need to start thinking about the high

114
00:03:38,879 --> 00:03:40,959
hanging fruit and if we're not already

115
00:03:40,959 --> 00:03:42,720
thinking about it we have certainly

116
00:03:42,720 --> 00:03:44,640
enough adversaries who are thinking

117
00:03:44,640 --> 00:03:46,799
about that kind of thing so anyway that

118
00:03:46,799 --> 00:03:47,519
uh

119
00:03:47,519 --> 00:03:49,680
functions hopefully as the the glue of

120
00:03:49,680 --> 00:03:51,920
what we'll be talking about today uh as

121
00:03:51,920 --> 00:03:53,760
i said some of my research is interwoven

122
00:03:53,760 --> 00:03:55,920
with this and it relates of course to

123
00:03:55,920 --> 00:03:57,760
decision security so i'm going to

124
00:03:57,760 --> 00:04:00,560
introduce emre

125
00:04:00,879 --> 00:04:02,319
as our first speaker he's going to come

126
00:04:02,319 --> 00:04:03,760
up in a moment all of the speakers are

127
00:04:03,760 --> 00:04:05,360
coming up to the podium

128
00:04:05,360 --> 00:04:07,680
and uh and give their talk we have

129
00:04:07,680 --> 00:04:10,640
pizzerias pikens and we have sampath

130
00:04:10,640 --> 00:04:12,959
rajapaksa sitting at the end there and

131
00:04:12,959 --> 00:04:14,720
as as i said they'll come up to the the

132
00:04:14,720 --> 00:04:16,160
podium in a moment they're going to

133
00:04:16,160 --> 00:04:17,839
speak for roughly 20 minutes we've got

134
00:04:17,839 --> 00:04:20,000
five minutes to allow for

135
00:04:20,000 --> 00:04:21,918
any questions immediate questions to

136
00:04:21,918 --> 00:04:23,360
them so i'd encourage that if you have

137
00:04:23,360 --> 00:04:25,280
something right then if you have a nice

138
00:04:25,280 --> 00:04:26,960
overarching question we have 10 minutes

139
00:04:26,960 --> 00:04:29,520
at the end to stimulate discussion

140
00:04:29,520 --> 00:04:31,360
and hopefully we actually collect enough

141
00:04:31,360 --> 00:04:33,759
from the audience so uh without further

142
00:04:33,759 --> 00:04:36,240
ado let me please hand it off to to emre

143
00:04:36,240 --> 00:04:37,919
i would strongly encourage you to please

144
00:04:37,919 --> 00:04:40,080
read the the bios and profiles on the

145
00:04:40,080 --> 00:04:42,479
website in the agenda and i'm not going

146
00:04:42,479 --> 00:04:44,560
to read them for you right now but very

147
00:04:44,560 --> 00:04:46,240
interesting people and

148
00:04:46,240 --> 00:04:49,040
take it away andre

149
00:04:49,120 --> 00:04:51,440
thank you

150
00:04:51,930 --> 00:04:55,520
[Applause]

151
00:04:55,520 --> 00:04:58,160
uh thanks you bruce uh good afternoon

152
00:04:58,160 --> 00:05:00,080
dear participants

153
00:05:00,080 --> 00:05:02,479
i'm major emeritus i'm from turkish air

154
00:05:02,479 --> 00:05:05,520
force i've been working in ccdcoe for

155
00:05:05,520 --> 00:05:09,039
three years as strategy researcher

156
00:05:09,039 --> 00:05:11,600
i'm really quite happy to

157
00:05:11,600 --> 00:05:14,400
present our article a data quality

158
00:05:14,400 --> 00:05:16,880
quality problem in ai based idea studies

159
00:05:16,880 --> 00:05:17,680
and

160
00:05:17,680 --> 00:05:20,000
a solution proposal

161
00:05:20,000 --> 00:05:21,280
article

162
00:05:21,280 --> 00:05:23,840
we worked together with my dear friends

163
00:05:23,840 --> 00:05:25,440
mauna felgas

164
00:05:25,440 --> 00:05:26,880
from estonia

165
00:05:26,880 --> 00:05:28,960
sambacho from

166
00:05:28,960 --> 00:05:31,919
south korea hajar karajan from turkey

167
00:05:31,919 --> 00:05:36,520
and thomas lepik from estonia

168
00:05:38,560 --> 00:05:40,720
uh i'd like to start

169
00:05:40,720 --> 00:05:42,639
the presentation with the explanation of

170
00:05:42,639 --> 00:05:45,199
one of the most important components of

171
00:05:45,199 --> 00:05:47,600
cyber security architecture

172
00:05:47,600 --> 00:05:50,720
is network intrusion detection systems

173
00:05:50,720 --> 00:05:52,479
these systems have been used to increase

174
00:05:52,479 --> 00:05:54,800
the level of network security for many

175
00:05:54,800 --> 00:05:57,680
years uh the main proposal of this uh

176
00:05:57,680 --> 00:05:59,759
system such system is to detect

177
00:05:59,759 --> 00:06:01,759
malicious activity in the network

178
00:06:01,759 --> 00:06:02,960
traffic

179
00:06:02,960 --> 00:06:06,400
the first idea study started in 1980s

180
00:06:06,400 --> 00:06:09,758
using expert systems

181
00:06:11,120 --> 00:06:14,080
in the years since with the increasing

182
00:06:14,080 --> 00:06:17,600
level of complexity of the attacks many

183
00:06:17,600 --> 00:06:20,319
machine learning and ai methods have

184
00:06:20,319 --> 00:06:23,440
been used in ideas development studies

185
00:06:23,440 --> 00:06:25,600
in the literature review we saw that

186
00:06:25,600 --> 00:06:27,600
deep learning a type of artificial

187
00:06:27,600 --> 00:06:30,319
intelligence is mostly used in recent

188
00:06:30,319 --> 00:06:33,319
publications

189
00:06:34,080 --> 00:06:36,319
from the ids development perspective we

190
00:06:36,319 --> 00:06:39,360
have to uh empa emphasize two

191
00:06:39,360 --> 00:06:41,280
important aspects

192
00:06:41,280 --> 00:06:43,520
one of them is a data set and

193
00:06:43,520 --> 00:06:45,919
the other one is model

194
00:06:45,919 --> 00:06:47,440
you can see some of the important

195
00:06:47,440 --> 00:06:48,960
publicly available

196
00:06:48,960 --> 00:06:51,039
ids data sets and

197
00:06:51,039 --> 00:06:52,800
some models that

198
00:06:52,800 --> 00:06:54,960
some techniques that can be used to

199
00:06:54,960 --> 00:06:59,120
develop your models on the slide

200
00:07:01,599 --> 00:07:03,680
as mentioned before model development

201
00:07:03,680 --> 00:07:06,160
studies have evolved into

202
00:07:06,160 --> 00:07:08,479
ai based techniques and we can

203
00:07:08,479 --> 00:07:10,240
confidently say that

204
00:07:10,240 --> 00:07:12,639
they have probed their success

205
00:07:12,639 --> 00:07:15,520
however generating ids data sets with an

206
00:07:15,520 --> 00:07:16,800
appropriate

207
00:07:16,800 --> 00:07:18,720
quality and quantity

208
00:07:18,720 --> 00:07:20,880
of data still remains a problem

209
00:07:20,880 --> 00:07:21,919
moreover

210
00:07:21,919 --> 00:07:24,080
there are problems in the

211
00:07:24,080 --> 00:07:26,560
evolution comparation and implementation

212
00:07:26,560 --> 00:07:29,360
of ideas mainly because of the lack of

213
00:07:29,360 --> 00:07:31,440
appropriate data sets

214
00:07:31,440 --> 00:07:33,759
most organizational uh organizational

215
00:07:33,759 --> 00:07:36,080
datasets are not publicly available due

216
00:07:36,080 --> 00:07:36,960
to

217
00:07:36,960 --> 00:07:41,440
reasonable security and privacy concerns

218
00:07:41,440 --> 00:07:42,560
most and

219
00:07:42,560 --> 00:07:45,520
the others public ones do not reflect uh

220
00:07:45,520 --> 00:07:47,520
the current attack trends

221
00:07:47,520 --> 00:07:49,840
also many data sets contain imbalanced

222
00:07:49,840 --> 00:07:52,080
data and requires synthetic data

223
00:07:52,080 --> 00:07:54,000
generation techniques to have more

224
00:07:54,000 --> 00:07:56,720
balanced uh training and test

225
00:07:56,720 --> 00:07:59,840
data sets and labeling the attacks is

226
00:07:59,840 --> 00:08:02,879
another problem since many methods only

227
00:08:02,879 --> 00:08:07,039
based on ip addresses and mac addresses

228
00:08:07,039 --> 00:08:09,840
and port numbers

229
00:08:11,039 --> 00:08:12,639
uh there are

230
00:08:12,639 --> 00:08:15,039
various publicly available ideas data

231
00:08:15,039 --> 00:08:18,000
sets as i said before and we chose six

232
00:08:18,000 --> 00:08:20,560
of them which have been widely used in

233
00:08:20,560 --> 00:08:23,039
ideas development studies regardless of

234
00:08:23,039 --> 00:08:25,039
their different properties

235
00:08:25,039 --> 00:08:28,000
such as formats size and attack types

236
00:08:28,000 --> 00:08:30,879
each data set has uniquely contributed

237
00:08:30,879 --> 00:08:34,559
to ideas the development studies however

238
00:08:34,559 --> 00:08:37,440
there are also some criticism of each

239
00:08:37,440 --> 00:08:40,559
data set

240
00:08:40,559 --> 00:08:42,240
for example uh

241
00:08:42,240 --> 00:08:43,200
although

242
00:08:43,200 --> 00:08:45,279
i want to speak about that those

243
00:08:45,279 --> 00:08:46,640
criticism now

244
00:08:46,640 --> 00:08:47,760
and uh

245
00:08:47,760 --> 00:08:49,680
for instance uh

246
00:08:49,680 --> 00:08:52,720
although the kdd cup 99 that set has

247
00:08:52,720 --> 00:08:54,240
made significant significant

248
00:08:54,240 --> 00:08:55,839
contributions to ideas development

249
00:08:55,839 --> 00:08:57,360
studies in the past

250
00:08:57,360 --> 00:08:59,600
it has been strongly criticized due to

251
00:08:59,600 --> 00:09:01,920
its low level of difficulty and the

252
00:09:01,920 --> 00:09:04,160
presence of redundant records it was

253
00:09:04,160 --> 00:09:07,200
revised in 2009 it created the

254
00:09:07,200 --> 00:09:08,800
kdd data set

255
00:09:08,800 --> 00:09:10,560
which is still frequently used in ios

256
00:09:10,560 --> 00:09:12,000
development studies

257
00:09:12,000 --> 00:09:15,200
however nsl kdd data set does not have a

258
00:09:15,200 --> 00:09:16,160
normal

259
00:09:16,160 --> 00:09:17,680
traffic distribution

260
00:09:17,680 --> 00:09:19,600
due to small amount of

261
00:09:19,600 --> 00:09:21,600
number of records it contains for some

262
00:09:21,600 --> 00:09:23,279
attack types like

263
00:09:23,279 --> 00:09:25,519
l2r or r2r

264
00:09:25,519 --> 00:09:26,880
attack types

265
00:09:26,880 --> 00:09:28,480
categories actually

266
00:09:28,480 --> 00:09:31,760
other important datasets is unsw

267
00:09:31,760 --> 00:09:35,360
nb15 was produced in a short period of

268
00:09:35,360 --> 00:09:37,600
31 hours using the

269
00:09:37,600 --> 00:09:39,680
traffic generator generator perfect

270
00:09:39,680 --> 00:09:42,800
strong it includes attacks for many

271
00:09:42,800 --> 00:09:44,399
attack categories

272
00:09:44,399 --> 00:09:46,880
from the perspective of attack types

273
00:09:46,880 --> 00:09:49,120
and data set size it can be used

274
00:09:49,120 --> 00:09:52,000
effectively in ids development studies

275
00:09:52,000 --> 00:09:54,640
a disadvantage however is that it was

276
00:09:54,640 --> 00:09:58,240
produced from a small emulated network

277
00:09:58,240 --> 00:10:00,640
the most important feature of another

278
00:10:00,640 --> 00:10:03,839
dataset ugr16 is that it was generated

279
00:10:03,839 --> 00:10:04,720
from a

280
00:10:04,720 --> 00:10:07,839
real isp network produced over a period

281
00:10:07,839 --> 00:10:10,480
of four months however the data set

282
00:10:10,480 --> 00:10:13,760
which contains both normal and

283
00:10:13,760 --> 00:10:14,800
attack

284
00:10:14,800 --> 00:10:17,360
traffic is inevitably quite large

285
00:10:17,360 --> 00:10:20,480
compared to other flow based data sets

286
00:10:20,480 --> 00:10:22,079
the

287
00:10:22,079 --> 00:10:26,160
currently this since its 2017 data set

288
00:10:26,160 --> 00:10:28,720
is the most advantageous in that is the

289
00:10:28,720 --> 00:10:32,079
most recent these public data sets but

290
00:10:32,079 --> 00:10:35,680
it's already over five years old and the

291
00:10:35,680 --> 00:10:37,920
fact it was produced in

292
00:10:37,920 --> 00:10:42,560
using a synthetic mesh is a drawback

293
00:10:43,360 --> 00:10:45,120
as i said before

294
00:10:45,120 --> 00:10:47,519
at the beginning of the evolution of the

295
00:10:47,519 --> 00:10:49,360
datasets uh

296
00:10:49,360 --> 00:10:51,680
that they have served all the datasets

297
00:10:51,680 --> 00:10:52,640
solved

298
00:10:52,640 --> 00:10:55,360
ideas development studies for many years

299
00:10:55,360 --> 00:10:59,200
and our aim is not slander them here

300
00:10:59,200 --> 00:11:02,320
our aim is to reveal the deficiencies of

301
00:11:02,320 --> 00:11:04,880
publicly available data sets and to make

302
00:11:04,880 --> 00:11:06,399
an evolution in the light of this

303
00:11:06,399 --> 00:11:07,839
information

304
00:11:07,839 --> 00:11:10,880
after the evolutions on the data sets

305
00:11:10,880 --> 00:11:13,440
we decided to research ways to benefit

306
00:11:13,440 --> 00:11:14,399
from

307
00:11:14,399 --> 00:11:17,600
network traffic of the most popular

308
00:11:17,600 --> 00:11:20,399
cyber security exercise in the world

309
00:11:20,399 --> 00:11:23,360
lux shields exercise is an annual live

310
00:11:23,360 --> 00:11:26,160
fire cyber security exercise that has

311
00:11:26,160 --> 00:11:30,800
been organized by nato ccdc since 2010

312
00:11:30,800 --> 00:11:32,320
in the exercise

313
00:11:32,320 --> 00:11:34,640
blue teams learn and test their skills

314
00:11:34,640 --> 00:11:35,839
in many

315
00:11:35,839 --> 00:11:37,920
interdisciplinary categories

316
00:11:37,920 --> 00:11:40,399
for instance defending against real-time

317
00:11:40,399 --> 00:11:43,200
cyber attacks situation assessment

318
00:11:43,200 --> 00:11:44,959
incident response

319
00:11:44,959 --> 00:11:47,839
handling varies inject scenarios and

320
00:11:47,839 --> 00:11:49,920
maintaining the functionality of their

321
00:11:49,920 --> 00:11:52,240
computer systems

322
00:11:52,240 --> 00:11:55,680
as ls is a defense oriented exercise

323
00:11:55,680 --> 00:11:57,920
the primary training audience is all of

324
00:11:57,920 --> 00:12:01,120
course the blue teams

325
00:12:01,440 --> 00:12:04,160
blue teams are required to defend

326
00:12:04,160 --> 00:12:07,279
a variety of type typical i.t systems as

327
00:12:07,279 --> 00:12:09,120
well as specialized industrial control

328
00:12:09,120 --> 00:12:11,040
systems for instance

329
00:12:11,040 --> 00:12:13,279
linux and windows servers

330
00:12:13,279 --> 00:12:16,240
linux and windows workstations free

331
00:12:16,240 --> 00:12:19,120
freebsd firewalls industrial con

332
00:12:19,120 --> 00:12:23,040
programmable logical logic controllers

333
00:12:23,040 --> 00:12:25,680
professional power management systems

334
00:12:25,680 --> 00:12:27,440
water treatment plants air defense

335
00:12:27,440 --> 00:12:30,720
systems and 4g lte gateways

336
00:12:30,720 --> 00:12:32,240
you can see a

337
00:12:32,240 --> 00:12:35,120
an example network that the blue teams

338
00:12:35,120 --> 00:12:36,839
must defend during the

339
00:12:36,839 --> 00:12:39,760
exercise the red team conducts a variety

340
00:12:39,760 --> 00:12:42,079
of escalating attacks from initial

341
00:12:42,079 --> 00:12:44,800
access continuing persistence

342
00:12:44,800 --> 00:12:46,959
and previous escalation to data

343
00:12:46,959 --> 00:12:50,720
collection exfiltration and destruction

344
00:12:50,720 --> 00:12:53,279
due to short time of spend the exercise

345
00:12:53,279 --> 00:12:56,079
the number and the pace of attacks are

346
00:12:56,079 --> 00:12:59,279
high compared to any real environment

347
00:12:59,279 --> 00:13:01,519
attack techniques from prior exercises

348
00:13:01,519 --> 00:13:04,320
include exploiting public facing

349
00:13:04,320 --> 00:13:07,360
applications compromising valid user

350
00:13:07,360 --> 00:13:10,320
accounts exploiting privilege escalation

351
00:13:10,320 --> 00:13:13,200
lateral moment using remote service data

352
00:13:13,200 --> 00:13:15,839
collection and exfiltration from target

353
00:13:15,839 --> 00:13:18,639
systems defacement of websites and

354
00:13:18,639 --> 00:13:21,839
denial of service

355
00:13:23,040 --> 00:13:25,600
after the explanation of the features of

356
00:13:25,600 --> 00:13:27,279
lux shields data sets now i want to

357
00:13:27,279 --> 00:13:28,480
mention about

358
00:13:28,480 --> 00:13:32,480
this data set generation process a bit

359
00:13:32,959 --> 00:13:35,120
uh the process starts with

360
00:13:35,120 --> 00:13:37,279
the network capture

361
00:13:37,279 --> 00:13:38,959
network traffic capture

362
00:13:38,959 --> 00:13:41,279
the network traffic can be captured uh

363
00:13:41,279 --> 00:13:43,440
using different types of network uh

364
00:13:43,440 --> 00:13:44,959
monitoring tools

365
00:13:44,959 --> 00:13:47,199
uh and additionally the modern network

366
00:13:47,199 --> 00:13:50,000
devices have data collection features

367
00:13:50,000 --> 00:13:52,240
and the data can be captured directly

368
00:13:52,240 --> 00:13:56,399
from the network devices as well

369
00:13:57,440 --> 00:13:59,839
but pcapp data collected during the

370
00:13:59,839 --> 00:14:02,880
exercise are split into separate

371
00:14:02,880 --> 00:14:06,000
separate files for each blue teams

372
00:14:06,000 --> 00:14:09,120
these blue team specific pkf files are

373
00:14:09,120 --> 00:14:11,600
then shared with the corresponding

374
00:14:11,600 --> 00:14:14,399
nation after the exercise has concluded

375
00:14:14,399 --> 00:14:17,360
therefore nations can typically analyze

376
00:14:17,360 --> 00:14:20,320
their pkf files to conduct an after

377
00:14:20,320 --> 00:14:23,440
action assessment improve their

378
00:14:23,440 --> 00:14:25,680
defensive techniques develop novel

379
00:14:25,680 --> 00:14:27,760
research and prepare the for the next

380
00:14:27,760 --> 00:14:29,279
exercise

381
00:14:29,279 --> 00:14:31,839
however there is a problem here and we

382
00:14:31,839 --> 00:14:34,320
focused on this problem actually

383
00:14:34,320 --> 00:14:37,760
this pcap data may include information

384
00:14:37,760 --> 00:14:39,760
that can be used to determine nations

385
00:14:39,760 --> 00:14:41,120
defense

386
00:14:41,120 --> 00:14:42,240
tactics

387
00:14:42,240 --> 00:14:44,160
response patterns and tools tests

388
00:14:44,160 --> 00:14:45,839
utilized to defend

389
00:14:45,839 --> 00:14:48,240
against various attack cyber attacks

390
00:14:48,240 --> 00:14:51,120
therefore uh as a procuration

391
00:14:51,120 --> 00:14:55,839
these pcap files cannot be shared by the

392
00:14:55,920 --> 00:15:00,399
countries because it's con it includes

393
00:15:00,399 --> 00:15:01,680
some

394
00:15:01,680 --> 00:15:04,959
confidential data

395
00:15:05,760 --> 00:15:08,959
the sensitivity of the data basically

396
00:15:08,959 --> 00:15:11,279
depends on the possibility to retrieve

397
00:15:11,279 --> 00:15:14,079
defense behaviors of the teams

398
00:15:14,079 --> 00:15:16,560
in our study we propose a method to

399
00:15:16,560 --> 00:15:18,800
overcome this problem and generate a

400
00:15:18,800 --> 00:15:21,839
publicly available unclassified data set

401
00:15:21,839 --> 00:15:25,199
creating a simple unoccupied blue team

402
00:15:25,199 --> 00:15:27,680
has already been attempted in past

403
00:15:27,680 --> 00:15:30,399
exercise iterations however without

404
00:15:30,399 --> 00:15:33,279
actual players this empty team did not

405
00:15:33,279 --> 00:15:35,360
achieve the same level of interaction

406
00:15:35,360 --> 00:15:36,480
with the

407
00:15:36,480 --> 00:15:39,440
red team and user simulation team

408
00:15:39,440 --> 00:15:42,320
as the other blue teams

409
00:15:42,320 --> 00:15:43,360
thus

410
00:15:43,360 --> 00:15:45,279
actual players within a blue team are

411
00:15:45,279 --> 00:15:46,720
necessary to

412
00:15:46,720 --> 00:15:49,279
create a more realistic data set it

413
00:15:49,279 --> 00:15:50,720
solves this issue

414
00:15:50,720 --> 00:15:52,639
we introduced the concept of the

415
00:15:52,639 --> 00:15:55,680
research team this team will operate

416
00:15:55,680 --> 00:15:59,040
similarly to other teams however data

417
00:15:59,040 --> 00:16:00,720
captured from this

418
00:16:00,720 --> 00:16:02,160
team

419
00:16:02,160 --> 00:16:04,079
this team will be prepared for

420
00:16:04,079 --> 00:16:05,839
public release

421
00:16:05,839 --> 00:16:10,000
initially the research team will include

422
00:16:10,000 --> 00:16:11,040
in the

423
00:16:11,040 --> 00:16:12,880
elections exercise and will include

424
00:16:12,880 --> 00:16:16,639
volunteers from the nations and

425
00:16:16,639 --> 00:16:18,720
maybe later within the recent

426
00:16:18,720 --> 00:16:21,360
advances and to us autonomous cyber

427
00:16:21,360 --> 00:16:22,959
defense techniques and

428
00:16:22,959 --> 00:16:24,720
the future research team

429
00:16:24,720 --> 00:16:26,880
should be they should

430
00:16:26,880 --> 00:16:29,920
ideally be a virtual team uh or at least

431
00:16:29,920 --> 00:16:32,560
a a hybrid between a artificial

432
00:16:32,560 --> 00:16:34,639
intelligence defense component and a

433
00:16:34,639 --> 00:16:38,160
small number of human players

434
00:16:39,680 --> 00:16:43,360
sharing pkf files for an any purpose can

435
00:16:43,360 --> 00:16:44,800
be challenging

436
00:16:44,800 --> 00:16:47,440
due to the large file sizes this is

437
00:16:47,440 --> 00:16:49,120
another problem

438
00:16:49,120 --> 00:16:52,160
because you know processing that data

439
00:16:52,160 --> 00:16:54,079
might be a problem for the researchers

440
00:16:54,079 --> 00:16:54,800
and

441
00:16:54,800 --> 00:16:58,560
the academia so the entire luxurious

442
00:16:58,560 --> 00:17:00,160
full packet capture produces

443
00:17:00,160 --> 00:17:01,360
approximately

444
00:17:01,360 --> 00:17:04,079
11 terabyte of pcap data for the two

445
00:17:04,079 --> 00:17:05,919
days of the exercise

446
00:17:05,919 --> 00:17:08,160
when this pcap data is split

447
00:17:08,160 --> 00:17:11,039
up into individual bulletins the median

448
00:17:11,039 --> 00:17:13,359
size of the data for a single team is

449
00:17:13,359 --> 00:17:16,000
about 400 gigabytes

450
00:17:16,000 --> 00:17:18,319
the proposed research team will likely

451
00:17:18,319 --> 00:17:20,640
produce a similar amount of

452
00:17:20,640 --> 00:17:22,240
network data

453
00:17:22,240 --> 00:17:23,919
this will mean

454
00:17:23,919 --> 00:17:27,119
an exceedingly large amount of raw data

455
00:17:27,119 --> 00:17:30,799
from various networks of mixed types

456
00:17:30,799 --> 00:17:32,559
simply providing this large amount of

457
00:17:32,559 --> 00:17:34,799
data as i said uh

458
00:17:34,799 --> 00:17:37,200
would be a problem for the researchers

459
00:17:37,200 --> 00:17:39,440
therefore the published data needs to be

460
00:17:39,440 --> 00:17:42,000
more manageable for a future research

461
00:17:42,000 --> 00:17:43,280
endeavors

462
00:17:43,280 --> 00:17:46,320
we propose to split or filter the data

463
00:17:46,320 --> 00:17:49,360
once more by captured network type

464
00:17:49,360 --> 00:17:50,880
for example

465
00:17:50,880 --> 00:17:52,960
according to luxurious exercise

466
00:17:52,960 --> 00:17:54,240
infrastructure

467
00:17:54,240 --> 00:17:55,520
the data

468
00:17:55,520 --> 00:17:56,880
could be split into different

469
00:17:56,880 --> 00:17:59,840
collections based on the defined network

470
00:17:59,840 --> 00:18:02,799
segments such as public services office

471
00:18:02,799 --> 00:18:03,919
segment

472
00:18:03,919 --> 00:18:06,160
drone research lab and power generator

473
00:18:06,160 --> 00:18:07,840
network

474
00:18:07,840 --> 00:18:09,919
this will be result in

475
00:18:09,919 --> 00:18:12,000
smaller several smaller p-cap

476
00:18:12,000 --> 00:18:14,080
collections that are less complicated to

477
00:18:14,080 --> 00:18:15,280
handle

478
00:18:15,280 --> 00:18:17,760
since ids configuration and network

479
00:18:17,760 --> 00:18:19,280
defense techniques can differ

480
00:18:19,280 --> 00:18:21,760
significantly across public private and

481
00:18:21,760 --> 00:18:22,799
spatial

482
00:18:22,799 --> 00:18:25,280
proposed networks this kind of

483
00:18:25,280 --> 00:18:27,600
separation would also benefit benefit

484
00:18:27,600 --> 00:18:29,760
detection beneficial for the detection

485
00:18:29,760 --> 00:18:33,120
algorithm development studies

486
00:18:35,039 --> 00:18:38,720
when the manageable pcaps be generated

487
00:18:38,720 --> 00:18:41,120
the poor pcaps can be shared or a data

488
00:18:41,120 --> 00:18:42,559
set can be produced

489
00:18:42,559 --> 00:18:44,960
we have options for that we can share

490
00:18:44,960 --> 00:18:45,919
the

491
00:18:45,919 --> 00:18:48,720
you know raw pkp file or we can work on

492
00:18:48,720 --> 00:18:49,440
that

493
00:18:49,440 --> 00:18:53,280
pkf file to generate a new data set

494
00:18:53,280 --> 00:18:55,280
to generate a more usable data set the

495
00:18:55,280 --> 00:18:56,799
pkf files

496
00:18:56,799 --> 00:18:58,799
has to be converted to a readable format

497
00:18:58,799 --> 00:18:59,600
by

498
00:18:59,600 --> 00:19:03,039
using developing an application or using

499
00:19:03,039 --> 00:19:05,600
open source tools such as

500
00:19:05,600 --> 00:19:09,159
kickflow meter

501
00:19:10,000 --> 00:19:12,160
using a pcap converter basically

502
00:19:12,160 --> 00:19:14,160
provides us a

503
00:19:14,160 --> 00:19:16,880
more readable pkf file the file includes

504
00:19:16,880 --> 00:19:19,520
flaws with many features and the number

505
00:19:19,520 --> 00:19:21,679
of features can be decreased

506
00:19:21,679 --> 00:19:22,640
using

507
00:19:22,640 --> 00:19:25,039
various types of future extraction

508
00:19:25,039 --> 00:19:26,160
techniques

509
00:19:26,160 --> 00:19:27,919
you can apply

510
00:19:27,919 --> 00:19:30,080
deep learning techniques as well for uh

511
00:19:30,080 --> 00:19:32,240
feature extraction or manual the feature

512
00:19:32,240 --> 00:19:34,559
extraction techniques can be used

513
00:19:34,559 --> 00:19:38,480
for future extraction

514
00:19:38,480 --> 00:19:40,080
but for me

515
00:19:40,080 --> 00:19:41,840
the most important part of the ideas

516
00:19:41,840 --> 00:19:44,160
data set generation is labeling

517
00:19:44,160 --> 00:19:46,880
labeling is a really important

518
00:19:46,880 --> 00:19:48,960
aspect of part of this

519
00:19:48,960 --> 00:19:50,000
process

520
00:19:50,000 --> 00:19:52,559
because many researchers just only use

521
00:19:52,559 --> 00:19:54,720
as i said before ip addresses mac

522
00:19:54,720 --> 00:19:57,360
addresses and

523
00:19:57,840 --> 00:20:00,400
port numbers

524
00:20:00,400 --> 00:20:02,640
however a red team machine generates

525
00:20:02,640 --> 00:20:06,559
also a normal attack traffic and be

526
00:20:06,559 --> 00:20:09,600
behind besides malicious attack so

527
00:20:09,600 --> 00:20:11,520
we cannot use

528
00:20:11,520 --> 00:20:12,720
those

529
00:20:12,720 --> 00:20:14,960
features we cannot just use those

530
00:20:14,960 --> 00:20:17,520
features to label a data set

531
00:20:17,520 --> 00:20:18,720
therefore

532
00:20:18,720 --> 00:20:21,280
expert evolution and lock analysis have

533
00:20:21,280 --> 00:20:25,039
to be included in the labeling process

534
00:20:28,960 --> 00:20:30,480
in summary

535
00:20:30,480 --> 00:20:32,960
in this study we firstly

536
00:20:32,960 --> 00:20:35,600
examined the properties of six data sets

537
00:20:35,600 --> 00:20:36,400
a

538
00:20:36,400 --> 00:20:38,480
widely used six data set

539
00:20:38,480 --> 00:20:39,520
and

540
00:20:39,520 --> 00:20:42,559
we propose a method to generate a novel

541
00:20:42,559 --> 00:20:45,520
and annually available ids data set

542
00:20:45,520 --> 00:20:47,679
benefiting from the unique environment

543
00:20:47,679 --> 00:20:49,840
of luxurious exercise

544
00:20:49,840 --> 00:20:52,240
to create an efficient data set for

545
00:20:52,240 --> 00:20:55,360
research decisions uh on which sub

546
00:20:55,360 --> 00:20:57,120
network to choose from the entire

547
00:20:57,120 --> 00:20:59,120
exercise infrastructure and how to

548
00:20:59,120 --> 00:21:01,360
adjust the attack and normal traffic

549
00:21:01,360 --> 00:21:03,600
balance should be made in a sound manner

550
00:21:03,600 --> 00:21:06,240
the anonymity of the data will also need

551
00:21:06,240 --> 00:21:08,799
to be evaluated thoroughly prior to

552
00:21:08,799 --> 00:21:11,600
publication and this is going to be a

553
00:21:11,600 --> 00:21:14,240
challenging process for us as well

554
00:21:14,240 --> 00:21:17,039
another important feature of nids is

555
00:21:17,039 --> 00:21:17,919
attack

556
00:21:17,919 --> 00:21:20,480
diversity it contains

557
00:21:20,480 --> 00:21:22,480
the attack types included in the

558
00:21:22,480 --> 00:21:24,480
luxurious exercise are determined by the

559
00:21:24,480 --> 00:21:25,600
red team

560
00:21:25,600 --> 00:21:28,000
based on their research carried out

561
00:21:28,000 --> 00:21:30,880
every year every each year within the

562
00:21:30,880 --> 00:21:33,120
scope of the exercise

563
00:21:33,120 --> 00:21:35,039
up to date attack types are applied

564
00:21:35,039 --> 00:21:37,120
every year we are sure about that and

565
00:21:37,120 --> 00:21:39,360
the responses from the blue teams to

566
00:21:39,360 --> 00:21:41,360
these attacks are measured

567
00:21:41,360 --> 00:21:44,080
the attack categories used by the

568
00:21:44,080 --> 00:21:47,039
luxurious exercise in past years

569
00:21:47,039 --> 00:21:48,880
are presented in this

570
00:21:48,880 --> 00:21:50,240
slide

571
00:21:50,240 --> 00:21:53,480
in this table

572
00:21:58,000 --> 00:21:59,840
in conclusion

573
00:21:59,840 --> 00:22:02,799
conducting the exercise every year

574
00:22:02,799 --> 00:22:04,799
will ensure that up-to-date attack

575
00:22:04,799 --> 00:22:06,480
categories are added

576
00:22:06,480 --> 00:22:07,919
and up-to-date

577
00:22:07,919 --> 00:22:10,559
infrastructure devices are used

578
00:22:10,559 --> 00:22:13,360
in addition the fact that the exercise

579
00:22:13,360 --> 00:22:15,520
infrastructure is quite extensive will

580
00:22:15,520 --> 00:22:17,919
offer several advantages for producing a

581
00:22:17,919 --> 00:22:20,080
realistic data set

582
00:22:20,080 --> 00:22:22,159
there are many different systems which

583
00:22:22,159 --> 00:22:24,640
specific network with specific network

584
00:22:24,640 --> 00:22:26,960
infrastructure in the exercise is

585
00:22:26,960 --> 00:22:28,559
so beneficial for

586
00:22:28,559 --> 00:22:30,400
research studies actually

587
00:22:30,400 --> 00:22:33,120
addressing some of these

588
00:22:33,120 --> 00:22:35,520
systems each year will also

589
00:22:35,520 --> 00:22:37,280
provide an important opportunity to

590
00:22:37,280 --> 00:22:38,400
observe

591
00:22:38,400 --> 00:22:39,919
the network behavior of different

592
00:22:39,919 --> 00:22:42,480
environments

593
00:22:42,880 --> 00:22:44,799
furthermore background traffic

594
00:22:44,799 --> 00:22:46,880
generation in the exit size

595
00:22:46,880 --> 00:22:48,799
will contribute to the normal traffic

596
00:22:48,799 --> 00:22:50,320
distribution

597
00:22:50,320 --> 00:22:51,919
therefore the

598
00:22:51,919 --> 00:22:54,480
data set will include a balance of

599
00:22:54,480 --> 00:22:57,120
normal and attack traffic

600
00:22:57,120 --> 00:22:58,559
as a result

601
00:22:58,559 --> 00:23:00,480
considering the data set features and

602
00:23:00,480 --> 00:23:03,039
the attack categories of this kind of

603
00:23:03,039 --> 00:23:07,600
data set it can be expected that

604
00:23:07,600 --> 00:23:09,520
a data set created from a unique

605
00:23:09,520 --> 00:23:12,720
infrastructure of a luxurious exercise

606
00:23:12,720 --> 00:23:13,679
will

607
00:23:13,679 --> 00:23:16,320
make a significant contribution to

608
00:23:16,320 --> 00:23:19,120
ideas development studies

609
00:23:19,120 --> 00:23:21,760
carried on carried out in academia and

610
00:23:21,760 --> 00:23:24,320
industry

611
00:23:24,880 --> 00:23:27,520
uh this is the end of my presentation

612
00:23:27,520 --> 00:23:29,280
we are always ready to answer your

613
00:23:29,280 --> 00:23:32,000
questions me and my friends you can

614
00:23:32,000 --> 00:23:35,600
shoot email anyone anytime you want

615
00:23:35,600 --> 00:23:37,440
and i'm ready to answer your questions

616
00:23:37,440 --> 00:23:39,919
now as well thanks very much emily

617
00:23:39,919 --> 00:23:41,919
thank you

618
00:23:41,919 --> 00:23:43,440
please feel free to stay at the podium

619
00:23:43,440 --> 00:23:45,520
while we see if there are questions okay

620
00:23:45,520 --> 00:23:47,360
um so you know of course this is the

621
00:23:47,360 --> 00:23:48,880
first round of questions immediately

622
00:23:48,880 --> 00:23:50,640
after lunch so hopefully not too many

623
00:23:50,640 --> 00:23:52,799
people have a food coma and we can

624
00:23:52,799 --> 00:23:54,400
encourage some questions directly from

625
00:23:54,400 --> 00:23:56,240
the audience while you think up your

626
00:23:56,240 --> 00:23:57,520
question i don't know if we have the

627
00:23:57,520 --> 00:23:59,200
microphone people around but while you

628
00:23:59,200 --> 00:24:01,039
think up your question let me quickly

629
00:24:01,039 --> 00:24:02,400
tie this in with what we're about to

630
00:24:02,400 --> 00:24:05,200
hear also from peterson later from from

631
00:24:05,200 --> 00:24:06,640
sampath

632
00:24:06,640 --> 00:24:09,039
the work that underlies this done by

633
00:24:09,039 --> 00:24:10,240
emre and

634
00:24:10,240 --> 00:24:12,799
his co-authors and co-researchers is

635
00:24:12,799 --> 00:24:14,320
important in the sense that for those of

636
00:24:14,320 --> 00:24:15,679
you that don't come from a machine

637
00:24:15,679 --> 00:24:17,200
learning data science or artificial

638
00:24:17,200 --> 00:24:19,520
intelligence background the need for

639
00:24:19,520 --> 00:24:21,360
clean interesting data that actually

640
00:24:21,360 --> 00:24:24,000
reflects the reality of the situation

641
00:24:24,000 --> 00:24:26,720
is unbelievably important and i happen

642
00:24:26,720 --> 00:24:28,559
to have worked many years ago for a

643
00:24:28,559 --> 00:24:29,840
large

644
00:24:29,840 --> 00:24:31,200
company that

645
00:24:31,200 --> 00:24:33,120
an unnamed company that's unfortunately

646
00:24:33,120 --> 00:24:35,120
not a sponsor but nonetheless that

647
00:24:35,120 --> 00:24:36,640
company

648
00:24:36,640 --> 00:24:38,320
developed various kinds of intrusion

649
00:24:38,320 --> 00:24:39,840
detection and intrusion prevention

650
00:24:39,840 --> 00:24:41,360
systems and these were those so-called

651
00:24:41,360 --> 00:24:43,520
rule-based systems which are not at all

652
00:24:43,520 --> 00:24:45,360
based on adaptive technology like

653
00:24:45,360 --> 00:24:47,440
artificial intelligence and

654
00:24:47,440 --> 00:24:49,760
machine learning and the opportunities

655
00:24:49,760 --> 00:24:51,840
now algorithmically to be able to adapt

656
00:24:51,840 --> 00:24:54,400
to to various threats is uh is very

657
00:24:54,400 --> 00:24:56,240
impressive but of course it rests

658
00:24:56,240 --> 00:24:59,120
entirely on having good quality data and

659
00:24:59,120 --> 00:25:00,720
of course that comes with all kinds of

660
00:25:00,720 --> 00:25:02,799
uh interesting privacy challenges so i

661
00:25:02,799 --> 00:25:04,240
think the the team is uniquely

662
00:25:04,240 --> 00:25:06,559
challenged um uh but also uniquely

663
00:25:06,559 --> 00:25:08,480
positioned to be generating such data

664
00:25:08,480 --> 00:25:10,720
and uh locked shields is is probably the

665
00:25:10,720 --> 00:25:12,960
the single best venue for that other

666
00:25:12,960 --> 00:25:15,440
than collecting data in some uh let's

667
00:25:15,440 --> 00:25:17,360
say random other way by sitting in

668
00:25:17,360 --> 00:25:19,840
coffee shops and uh and sniffing wi-fi

669
00:25:19,840 --> 00:25:21,919
but anyway nonetheless uh let me kick

670
00:25:21,919 --> 00:25:23,919
things off with a very short question uh

671
00:25:23,919 --> 00:25:25,520
to to emery because i don't immediately

672
00:25:25,520 --> 00:25:27,200
see hands but it could be the lights

673
00:25:27,200 --> 00:25:28,720
jump up if you do have a question sorry

674
00:25:28,720 --> 00:25:30,799
i we do have one from the front here so

675
00:25:30,799 --> 00:25:34,320
we can have a microphone for you

676
00:25:34,320 --> 00:25:37,520
i'll come back to mine in a moment

677
00:25:37,760 --> 00:25:40,000
hi uh john fernandez i'm from the us

678
00:25:40,000 --> 00:25:41,520
army cyber institute

679
00:25:41,520 --> 00:25:43,360
um if i understood correctly the data

680
00:25:43,360 --> 00:25:44,720
that you're generating is coming from a

681
00:25:44,720 --> 00:25:47,039
relatively condensed time period and

682
00:25:47,039 --> 00:25:49,279
you're going to have maybe more than

683
00:25:49,279 --> 00:25:50,720
what you'd see in an open environment in

684
00:25:50,720 --> 00:25:52,799
terms of malicious traffic

685
00:25:52,799 --> 00:25:54,559
so how do you

686
00:25:54,559 --> 00:25:56,159
see that then affecting the models you

687
00:25:56,159 --> 00:25:57,919
train when that probability distribution

688
00:25:57,919 --> 00:25:59,200
might actually be different than the

689
00:25:59,200 --> 00:26:01,279
real world

690
00:26:01,279 --> 00:26:04,480
yes uh our luxurious exercise

691
00:26:04,480 --> 00:26:07,039
takes almost two days and there are many

692
00:26:07,039 --> 00:26:09,440
attack types

693
00:26:09,440 --> 00:26:11,840
applied for the red teams and

694
00:26:11,840 --> 00:26:14,400
yes the time period is so

695
00:26:14,400 --> 00:26:15,600
tight but

696
00:26:15,600 --> 00:26:17,760
the attack types and the normal traffic

697
00:26:17,760 --> 00:26:20,000
is enough for creating a

698
00:26:20,000 --> 00:26:22,480
beneficial data set for

699
00:26:22,480 --> 00:26:25,520
this kind of ideas development studies

700
00:26:25,520 --> 00:26:26,720
so

701
00:26:26,720 --> 00:26:28,799
as i said before we sh we are sharing

702
00:26:28,799 --> 00:26:29,520
these

703
00:26:29,520 --> 00:26:32,080
pkf files with the countries but

704
00:26:32,080 --> 00:26:33,760
uh of course this

705
00:26:33,760 --> 00:26:34,960
uh this is

706
00:26:34,960 --> 00:26:38,799
this includes some uh data that reflects

707
00:26:38,799 --> 00:26:40,559
their

708
00:26:40,559 --> 00:26:41,760
behaviors

709
00:26:41,760 --> 00:26:43,039
for the attacks

710
00:26:43,039 --> 00:26:45,279
so

711
00:26:46,000 --> 00:26:48,320
this is the actually the

712
00:26:48,320 --> 00:26:50,080
main

713
00:26:50,080 --> 00:26:52,320
purpose of this i think we'll also take

714
00:26:52,320 --> 00:26:53,679
a little bit of that along in the

715
00:26:53,679 --> 00:26:54,960
discussion at the end of the session

716
00:26:54,960 --> 00:26:57,360
because the the issue of very long time

717
00:26:57,360 --> 00:26:58,320
signals

718
00:26:58,320 --> 00:27:00,000
and and having those present enough in

719
00:27:00,000 --> 00:27:02,240
the data is is an interesting problem

720
00:27:02,240 --> 00:27:04,159
and and how to uh how to deal with that

721
00:27:04,159 --> 00:27:06,080
over short time frames do you have

722
00:27:06,080 --> 00:27:07,600
another immediate question from the

723
00:27:07,600 --> 00:27:08,799
audience

724
00:27:08,799 --> 00:27:11,360
sorry gabor

725
00:27:11,360 --> 00:27:14,720
yeah i got a mic so you mentioned the

726
00:27:14,720 --> 00:27:16,880
feature selection does your paper

727
00:27:16,880 --> 00:27:19,440
contain the feature certain section the

728
00:27:19,440 --> 00:27:22,159
selected features are they introduced

729
00:27:22,159 --> 00:27:23,600
no actually

730
00:27:23,600 --> 00:27:26,320
we it our paper does not contain future

731
00:27:26,320 --> 00:27:27,760
selection process

732
00:27:27,760 --> 00:27:29,520
but we mentioned we are mentioning about

733
00:27:29,520 --> 00:27:30,480
it

734
00:27:30,480 --> 00:27:32,720
as i said before you can use many type

735
00:27:32,720 --> 00:27:34,799
of feature selection algorithms

736
00:27:34,799 --> 00:27:36,720
to select the features effective

737
00:27:36,720 --> 00:27:40,000
features there are some studies

738
00:27:40,000 --> 00:27:42,559
previous studies actually

739
00:27:42,559 --> 00:27:43,600
happened

740
00:27:43,600 --> 00:27:44,640
on this

741
00:27:44,640 --> 00:27:45,760
part

742
00:27:45,760 --> 00:27:47,279
so

743
00:27:47,279 --> 00:27:48,960
thank you very much yeah

744
00:27:48,960 --> 00:27:51,039
we don't mention about it

745
00:27:51,039 --> 00:27:52,640
we have another question from the middle

746
00:27:52,640 --> 00:27:53,840
um

747
00:27:53,840 --> 00:27:56,639
close to the aisle

748
00:27:58,320 --> 00:28:01,440
yeah thank you for your presentation um

749
00:28:01,440 --> 00:28:04,159
i'm a phd at university in norwegian

750
00:28:04,159 --> 00:28:06,640
university of science and technology so

751
00:28:06,640 --> 00:28:08,000
my question is

752
00:28:08,000 --> 00:28:10,000
have you considered the

753
00:28:10,000 --> 00:28:12,799
coming trending uh threat of adversarial

754
00:28:12,799 --> 00:28:14,799
machine learning and how it will affect

755
00:28:14,799 --> 00:28:17,200
the future introducing detection system

756
00:28:17,200 --> 00:28:18,480
for such

757
00:28:18,480 --> 00:28:20,720
malwares that aim to do

758
00:28:20,720 --> 00:28:24,880
model poisoning and that they transmit

759
00:28:24,880 --> 00:28:26,720
traffic in the network for long long

760
00:28:26,720 --> 00:28:29,679
time so that it becomes normal and

761
00:28:29,679 --> 00:28:30,480
just

762
00:28:30,480 --> 00:28:32,240
play within the

763
00:28:32,240 --> 00:28:34,640
thresholds of normal to malicious have

764
00:28:34,640 --> 00:28:36,240
you considered that and what do you

765
00:28:36,240 --> 00:28:37,279
think

766
00:28:37,279 --> 00:28:40,000
the ideas toward answering that issue

767
00:28:40,000 --> 00:28:41,600
thank you

768
00:28:41,600 --> 00:28:44,720
thank you for the question is is related

769
00:28:44,720 --> 00:28:47,520
with labeling the data actually

770
00:28:47,520 --> 00:28:49,760
this is the important part of

771
00:28:49,760 --> 00:28:52,799
as i said in during my presentation

772
00:28:52,799 --> 00:28:54,320
labeling the data

773
00:28:54,320 --> 00:28:57,520
is the most important part of this study

774
00:28:57,520 --> 00:29:00,320
our team is working on it with

775
00:29:00,320 --> 00:29:02,320
the red team

776
00:29:02,320 --> 00:29:03,360
and

777
00:29:03,360 --> 00:29:04,799
we will create

778
00:29:04,799 --> 00:29:06,320
some methods for

779
00:29:06,320 --> 00:29:08,799
you know separating malicious data and

780
00:29:08,799 --> 00:29:12,240
the normal attack traffic so we are

781
00:29:12,240 --> 00:29:14,080
still working on it and

782
00:29:14,080 --> 00:29:15,919
i will share some information

783
00:29:15,919 --> 00:29:18,080
with you

784
00:29:18,080 --> 00:29:19,679
i think you actually open up a very

785
00:29:19,679 --> 00:29:21,360
interesting line of questions that ties

786
00:29:21,360 --> 00:29:22,399
back to

787
00:29:22,399 --> 00:29:24,559
the need to protect the models the

788
00:29:24,559 --> 00:29:26,240
underlying models model poisoning of

789
00:29:26,240 --> 00:29:28,720
course and you know modern threats that

790
00:29:28,720 --> 00:29:30,000
are manipulating

791
00:29:30,000 --> 00:29:32,080
decision making and

792
00:29:32,080 --> 00:29:34,159
operating over very long time scales

793
00:29:34,159 --> 00:29:35,679
typically are designed of course to

794
00:29:35,679 --> 00:29:38,000
remain subclinical so that they're

795
00:29:38,000 --> 00:29:39,760
essentially undetected over these long

796
00:29:39,760 --> 00:29:41,919
times time scales but i think we'll

797
00:29:41,919 --> 00:29:43,279
leave it at that for now believe me

798
00:29:43,279 --> 00:29:44,799
there will be more questions or during

799
00:29:44,799 --> 00:29:46,720
the the continued discussion period

800
00:29:46,720 --> 00:29:49,120
thank you very much emre and i'll

801
00:29:49,120 --> 00:29:52,000
immediately call peters up to

802
00:29:52,000 --> 00:29:54,320
begin his talk and we have exactly the

803
00:29:54,320 --> 00:29:56,080
same format and i'm sure there are

804
00:29:56,080 --> 00:29:57,679
questions that will be overarching so

805
00:29:57,679 --> 00:29:59,279
don't forget to save those additionally

806
00:29:59,279 --> 00:30:03,120
for uh for the end thank you

807
00:30:03,120 --> 00:30:06,219
[Applause]

808
00:30:08,159 --> 00:30:11,919
okay uh so nice nice to see you all here

809
00:30:11,919 --> 00:30:13,520
uh so

810
00:30:13,520 --> 00:30:15,360
i'm here to present let's say an

811
00:30:15,360 --> 00:30:18,080
overview of how machine learning impacts

812
00:30:18,080 --> 00:30:20,880
the security of cyber physical systems

813
00:30:20,880 --> 00:30:22,720
i'm patrick spikenz i'm from university

814
00:30:22,720 --> 00:30:24,559
of latvia institute mathematics computer

815
00:30:24,559 --> 00:30:25,840
science artificial intelligence

816
00:30:25,840 --> 00:30:28,720
laboratory and i'm working as mostly

817
00:30:28,720 --> 00:30:31,279
machine learning researcher with focus

818
00:30:31,279 --> 00:30:33,200
on both natural language processing and

819
00:30:33,200 --> 00:30:36,720
also in cyber security

820
00:30:36,720 --> 00:30:37,600
so

821
00:30:37,600 --> 00:30:39,919
my agenda today is essentially three

822
00:30:39,919 --> 00:30:42,799
topics one is applications of machine

823
00:30:42,799 --> 00:30:45,200
learning to mitigate threats the blue

824
00:30:45,200 --> 00:30:46,880
team approach

825
00:30:46,880 --> 00:30:48,320
the second part would be machine

826
00:30:48,320 --> 00:30:49,919
learning applications to find the

827
00:30:49,919 --> 00:30:50,880
threats

828
00:30:50,880 --> 00:30:53,279
which more like red team approach and

829
00:30:53,279 --> 00:30:54,399
third part

830
00:30:54,399 --> 00:30:56,880
is probably more interesting in recent

831
00:30:56,880 --> 00:30:58,320
research

832
00:30:58,320 --> 00:31:00,640
various threats to the machine learning

833
00:31:00,640 --> 00:31:04,120
systems themselves

834
00:31:04,480 --> 00:31:06,000
uh so

835
00:31:06,000 --> 00:31:08,960
the context of cyber physical systems uh

836
00:31:08,960 --> 00:31:11,279
is all these software systems which

837
00:31:11,279 --> 00:31:14,159
directly interrupts our physical reality

838
00:31:14,159 --> 00:31:16,720
uh the most popular approaches seen in

839
00:31:16,720 --> 00:31:19,440
media at least are consumer automation

840
00:31:19,440 --> 00:31:21,120
all the smart home and internet of

841
00:31:21,120 --> 00:31:22,799
things technologies

842
00:31:22,799 --> 00:31:26,480
and the less seen approaches are those

843
00:31:26,480 --> 00:31:29,279
used in industrial systems

844
00:31:29,279 --> 00:31:32,240
uh industrial automation and industrial

845
00:31:32,240 --> 00:31:34,880
control systems are a big part of our

846
00:31:34,880 --> 00:31:36,640
critical infrastructure

847
00:31:36,640 --> 00:31:38,960
and those are cyber physical systems

848
00:31:38,960 --> 00:31:40,799
that matter a lot for

849
00:31:40,799 --> 00:31:42,559
let's say recent

850
00:31:42,559 --> 00:31:44,480
state-based attacks

851
00:31:44,480 --> 00:31:47,120
and uh there are also emerging

852
00:31:47,120 --> 00:31:49,200
technologies like personal wearables

853
00:31:49,200 --> 00:31:51,279
health monitoring systems optimus

854
00:31:51,279 --> 00:31:53,760
driving and all kinds of other

855
00:31:53,760 --> 00:31:55,600
increased integration of cyber

856
00:31:55,600 --> 00:31:59,200
technology into our physical reality

857
00:31:59,200 --> 00:32:02,799
uh so looking at applications of machine

858
00:32:02,799 --> 00:32:05,200
learning which we are seeing in the

859
00:32:05,200 --> 00:32:07,200
industrial aspect

860
00:32:07,200 --> 00:32:08,240
uh

861
00:32:08,240 --> 00:32:09,039
like

862
00:32:09,039 --> 00:32:11,519
emery just con

863
00:32:11,519 --> 00:32:14,000
presented a nice talk about the let's

864
00:32:14,000 --> 00:32:16,559
say mainstream uh application of machine

865
00:32:16,559 --> 00:32:18,480
learning and threat mitigation in

866
00:32:18,480 --> 00:32:20,640
intrusion detection systems

867
00:32:20,640 --> 00:32:24,080
in let's say normal i.t networks uh but

868
00:32:24,080 --> 00:32:25,919
there are also uh

869
00:32:25,919 --> 00:32:28,159
very important networks which are the

870
00:32:28,159 --> 00:32:29,679
operation technology networks the

871
00:32:29,679 --> 00:32:31,840
industrial networks on which uh the

872
00:32:31,840 --> 00:32:34,880
cyber physical infrastructure runs

873
00:32:34,880 --> 00:32:38,000
and it's uh technically uses similar

874
00:32:38,000 --> 00:32:40,720
technologies however conceptually it's

875
00:32:40,720 --> 00:32:43,840
quite different uh in the net

876
00:32:43,840 --> 00:32:45,760
in the way how machine learning can be

877
00:32:45,760 --> 00:32:47,519
applied how intrusion detection should

878
00:32:47,519 --> 00:32:50,080
be made for those networks

879
00:32:50,080 --> 00:32:51,279
like

880
00:32:51,279 --> 00:32:54,240
the big reason for machine learning in

881
00:32:54,240 --> 00:32:55,120
i.t

882
00:32:55,120 --> 00:32:58,480
intrusion detection systems is that

883
00:32:58,480 --> 00:33:00,640
new things come in all the time every

884
00:33:00,640 --> 00:33:03,200
day in any large organization

885
00:33:03,200 --> 00:33:05,679
and only a machine learning systems

886
00:33:05,679 --> 00:33:07,279
currently

887
00:33:07,279 --> 00:33:08,159
are

888
00:33:08,159 --> 00:33:09,440
used to

889
00:33:09,440 --> 00:33:11,279
be to be able to adapt to all these

890
00:33:11,279 --> 00:33:13,840
changes and detect novel threats and

891
00:33:13,840 --> 00:33:17,200
also not detect novel benign behavior

892
00:33:17,200 --> 00:33:19,360
uh however operational technology

893
00:33:19,360 --> 00:33:21,840
networks are a bit different they are

894
00:33:21,840 --> 00:33:26,240
predictable they change rarely and

895
00:33:26,240 --> 00:33:28,559
here the application of machine learning

896
00:33:28,559 --> 00:33:30,720
sometimes perhaps it's over exaggerated

897
00:33:30,720 --> 00:33:32,960
in my opinion because

898
00:33:32,960 --> 00:33:33,840
over

899
00:33:33,840 --> 00:33:37,039
when an industrial system changes it's a

900
00:33:37,039 --> 00:33:40,320
relatively rare event you can solve

901
00:33:40,320 --> 00:33:42,320
intrusion protection in certain aspects

902
00:33:42,320 --> 00:33:45,120
by very strict rule-based whitelisting

903
00:33:45,120 --> 00:33:47,039
because you know you implement the

904
00:33:47,039 --> 00:33:48,799
system you know what traffic should be

905
00:33:48,799 --> 00:33:52,000
there and it should not just randomly

906
00:33:52,000 --> 00:33:53,919
change from day to day

907
00:33:53,919 --> 00:33:56,000
so the big question is there is

908
00:33:56,000 --> 00:33:58,480
maintaining a machine learning intrusion

909
00:33:58,480 --> 00:34:01,039
detection system simpler or more

910
00:34:01,039 --> 00:34:03,360
difficult than maintaining a rule-based

911
00:34:03,360 --> 00:34:05,120
system that

912
00:34:05,120 --> 00:34:06,559
tackles

913
00:34:06,559 --> 00:34:08,480
intrusion detection however a big

914
00:34:08,480 --> 00:34:10,560
application of machine learning in those

915
00:34:10,560 --> 00:34:12,960
industrial networks is detecting unusual

916
00:34:12,960 --> 00:34:15,679
physical scenarios and anomalies raising

917
00:34:15,679 --> 00:34:19,599
alerts about an unexpected unusual event

918
00:34:19,599 --> 00:34:21,359
which sometimes will be caused by an

919
00:34:21,359 --> 00:34:23,199
accident but sometimes will because my

920
00:34:23,199 --> 00:34:26,480
malicious action and then can be used to

921
00:34:26,480 --> 00:34:29,760
inform people and raise alerts

922
00:34:29,760 --> 00:34:32,079
the second major application of machine

923
00:34:32,079 --> 00:34:33,760
learning in

924
00:34:33,760 --> 00:34:36,399
detecting threats is in various app

925
00:34:36,399 --> 00:34:40,320
ecosystems uh in many cases we have like

926
00:34:40,320 --> 00:34:43,440
app stores for our smartphones smart

927
00:34:43,440 --> 00:34:46,239
watches sometimes smart home devices

928
00:34:46,239 --> 00:34:49,440
like alexa skills and so on

929
00:34:49,440 --> 00:34:52,480
where people are offering third-party

930
00:34:52,480 --> 00:34:55,199
applications which are totally

931
00:34:55,199 --> 00:34:58,240
untrusted but should be trusted because

932
00:34:58,240 --> 00:35:01,200
people consumers interact with them

933
00:35:01,200 --> 00:35:02,400
and

934
00:35:02,400 --> 00:35:04,240
one of the major applications machine

935
00:35:04,240 --> 00:35:06,560
learning here is detecting abuse of

936
00:35:06,560 --> 00:35:09,760
sensitive permissions privileges

937
00:35:09,760 --> 00:35:12,560
and analysis of those third-party

938
00:35:12,560 --> 00:35:14,800
applications by machine learning

939
00:35:14,800 --> 00:35:18,160
approaches because current testing which

940
00:35:18,160 --> 00:35:20,640
is done by let's say often rule based

941
00:35:20,640 --> 00:35:22,800
scanning and sometimes manual

942
00:35:22,800 --> 00:35:24,640
verification which is rare because it

943
00:35:24,640 --> 00:35:25,520
takes

944
00:35:25,520 --> 00:35:27,359
time and resources

945
00:35:27,359 --> 00:35:29,760
but machine learning can be very useful

946
00:35:29,760 --> 00:35:32,640
in detecting variations of known malware

947
00:35:32,640 --> 00:35:34,400
and implants because you know the

948
00:35:34,400 --> 00:35:37,839
attackers may create many new

949
00:35:37,839 --> 00:35:39,839
applications for each attack but they

950
00:35:39,839 --> 00:35:41,760
want to reuse their software

951
00:35:41,760 --> 00:35:43,119
infrastructure

952
00:35:43,119 --> 00:35:44,320
and

953
00:35:44,320 --> 00:35:47,359
code but with small variations and that

954
00:35:47,359 --> 00:35:48,880
can be detected

955
00:35:48,880 --> 00:35:51,119
with machine learning systems quite

956
00:35:51,119 --> 00:35:53,520
quite well

957
00:35:53,520 --> 00:35:57,119
and the next part is the consumer aspect

958
00:35:57,119 --> 00:35:59,440
like again

959
00:35:59,440 --> 00:36:01,359
continuing on the topic for intrusion

960
00:36:01,359 --> 00:36:04,720
detection systems in corporate networks

961
00:36:04,720 --> 00:36:08,960
we can treat smartphone a smart home

962
00:36:08,960 --> 00:36:11,280
attacks as a special case of network

963
00:36:11,280 --> 00:36:14,079
intrusion detection systems

964
00:36:14,079 --> 00:36:16,640
but again

965
00:36:17,839 --> 00:36:19,599
i'd like to perhaps point out some

966
00:36:19,599 --> 00:36:21,920
skepticism towards application machine

967
00:36:21,920 --> 00:36:23,599
learning

968
00:36:23,599 --> 00:36:26,320
here because current machine learning

969
00:36:26,320 --> 00:36:28,320
approaches are quite good at

970
00:36:28,320 --> 00:36:30,560
interpolation between known data that we

971
00:36:30,560 --> 00:36:33,040
see and they are not yet quite quite

972
00:36:33,040 --> 00:36:35,680
good at extrapolation to novel scenarios

973
00:36:35,680 --> 00:36:38,560
and consumer scenarios consumer

974
00:36:38,560 --> 00:36:40,720
environments in smart home

975
00:36:40,720 --> 00:36:42,800
uh often do have

976
00:36:42,800 --> 00:36:45,200
novel behaviors it's perfectly good you

977
00:36:45,200 --> 00:36:48,079
know some person bought a completely new

978
00:36:48,079 --> 00:36:50,240
device that was just released yesterday

979
00:36:50,240 --> 00:36:52,480
and they want to plug it in and they

980
00:36:52,480 --> 00:36:55,359
want it to work and not raise any alarms

981
00:36:55,359 --> 00:36:58,079
and that's that should be expected

982
00:36:58,079 --> 00:37:01,200
and uh in a home environment there's

983
00:37:01,200 --> 00:37:04,160
much less tolerance to false positives

984
00:37:04,160 --> 00:37:06,720
like in in normal intrusion detection

985
00:37:06,720 --> 00:37:08,560
systems the major problem is false

986
00:37:08,560 --> 00:37:10,800
positives and reacting them filtering

987
00:37:10,800 --> 00:37:11,599
them

988
00:37:11,599 --> 00:37:14,720
and in a home environment

989
00:37:14,720 --> 00:37:16,880
false positives are essentially a

990
00:37:16,880 --> 00:37:19,200
disaster because there's no one to look

991
00:37:19,200 --> 00:37:20,240
at them

992
00:37:20,240 --> 00:37:21,440
so

993
00:37:21,440 --> 00:37:23,760
in my view there's i have seen lots of

994
00:37:23,760 --> 00:37:25,520
research about machine learning

995
00:37:25,520 --> 00:37:28,640
applications to smart home uh intrusion

996
00:37:28,640 --> 00:37:29,839
detection

997
00:37:29,839 --> 00:37:31,920
but i would say that it's an interesting

998
00:37:31,920 --> 00:37:34,000
research problem which is not yet

999
00:37:34,000 --> 00:37:36,480
sufficiently mature for consumer

1000
00:37:36,480 --> 00:37:39,280
applications

1001
00:37:40,079 --> 00:37:42,000
another approach

1002
00:37:42,000 --> 00:37:45,520
of applying machine learning is to

1003
00:37:45,520 --> 00:37:49,040
try and find vulnerabilities before they

1004
00:37:49,040 --> 00:37:53,680
can be used for actual malicious acts

1005
00:37:53,680 --> 00:37:55,839
one one this is topics that i've been

1006
00:37:55,839 --> 00:37:58,000
researching myself recently

1007
00:37:58,000 --> 00:37:59,760
we are looking at wireless protocol

1008
00:37:59,760 --> 00:38:00,960
security

1009
00:38:00,960 --> 00:38:03,599
vulnerabilities for example common

1010
00:38:03,599 --> 00:38:06,560
bluetooth devices uh have

1011
00:38:06,560 --> 00:38:09,040
uh all kinds of interesting thermal

1012
00:38:09,040 --> 00:38:11,359
firmware vulnerabilities in them

1013
00:38:11,359 --> 00:38:12,240
and

1014
00:38:12,240 --> 00:38:14,079
those are

1015
00:38:14,079 --> 00:38:16,240
quite quite interesting from security

1016
00:38:16,240 --> 00:38:17,920
perspective because

1017
00:38:17,920 --> 00:38:20,800
those small devices wearable devices

1018
00:38:20,800 --> 00:38:22,800
with bluetooth chips in them

1019
00:38:22,800 --> 00:38:24,480
first often

1020
00:38:24,480 --> 00:38:27,359
unlike software on your computer it's

1021
00:38:27,359 --> 00:38:30,000
quite hard or even impossible to dispute

1022
00:38:30,000 --> 00:38:32,400
updates to them sometimes the vendors

1023
00:38:32,400 --> 00:38:35,119
don't want to support those devices and

1024
00:38:35,119 --> 00:38:37,119
sometimes the device simply does not

1025
00:38:37,119 --> 00:38:40,240
support any uh update mechanism at all

1026
00:38:40,240 --> 00:38:41,839
because you know you have your

1027
00:38:41,839 --> 00:38:43,200
headphones

1028
00:38:43,200 --> 00:38:46,079
how would you update the software on

1029
00:38:46,079 --> 00:38:48,160
your headphones like there's no

1030
00:38:48,160 --> 00:38:49,520
mechanism

1031
00:38:49,520 --> 00:38:51,040
in designs

1032
00:38:51,040 --> 00:38:53,920
for such features

1033
00:38:54,480 --> 00:38:57,520
and a big problem there is that existing

1034
00:38:57,520 --> 00:38:59,040
quality assurance processes and

1035
00:38:59,040 --> 00:39:01,680
certification processes they test for

1036
00:39:01,680 --> 00:39:04,800
compliance with standards

1037
00:39:04,800 --> 00:39:06,079
in

1038
00:39:06,079 --> 00:39:08,400
proper reaction to other standards

1039
00:39:08,400 --> 00:39:10,880
compliant devices

1040
00:39:10,880 --> 00:39:14,560
however this standard certifications

1041
00:39:14,560 --> 00:39:17,040
they do not test for malicious data for

1042
00:39:17,040 --> 00:39:20,800
harmful data that's intentionally wrong

1043
00:39:20,800 --> 00:39:23,760
so you can have a bluetooth device pass

1044
00:39:23,760 --> 00:39:27,280
all the certification and

1045
00:39:27,280 --> 00:39:28,720
be

1046
00:39:28,720 --> 00:39:30,480
expected that it

1047
00:39:30,480 --> 00:39:33,119
works properly however the standard so

1048
00:39:33,119 --> 00:39:35,119
it does not cover all the malicious

1049
00:39:35,119 --> 00:39:38,000
scenarios and so a compliant device can

1050
00:39:38,000 --> 00:39:38,880
be

1051
00:39:38,880 --> 00:39:40,800
broken or buggy despite the

1052
00:39:40,800 --> 00:39:42,400
certification

1053
00:39:42,400 --> 00:39:44,880
in response to non-compliant malicious

1054
00:39:44,880 --> 00:39:46,800
data

1055
00:39:46,800 --> 00:39:47,599
and

1056
00:39:47,599 --> 00:39:50,480
another important aspect is that all

1057
00:39:50,480 --> 00:39:53,200
these firmware vulnerabilities in

1058
00:39:53,200 --> 00:39:55,520
bluetooth is just one example wi-fi is

1059
00:39:55,520 --> 00:39:57,119
another and

1060
00:39:57,119 --> 00:39:58,320
there are

1061
00:39:58,320 --> 00:39:59,760
other interesting firmware in your

1062
00:39:59,760 --> 00:40:00,880
computers

1063
00:40:00,880 --> 00:40:02,640
modern devices are essentially

1064
00:40:02,640 --> 00:40:05,200
distributed network of computers in a

1065
00:40:05,200 --> 00:40:08,800
single device if you have an iphone then

1066
00:40:08,800 --> 00:40:10,400
the bluetooth chip is a separate

1067
00:40:10,400 --> 00:40:13,920
processor with a separate logic uh that

1068
00:40:13,920 --> 00:40:16,240
even if the iphone is turned off

1069
00:40:16,240 --> 00:40:18,400
uh the bluetooth chip can be powered and

1070
00:40:18,400 --> 00:40:22,640
can execute malicious activities on it

1071
00:40:22,640 --> 00:40:23,680
so

1072
00:40:23,680 --> 00:40:26,240
this firmware vulnerabilities are very

1073
00:40:26,240 --> 00:40:27,680
interesting from the security

1074
00:40:27,680 --> 00:40:29,680
perspective because they can circumvent

1075
00:40:29,680 --> 00:40:32,560
usual operating system security measures

1076
00:40:32,560 --> 00:40:33,520
because

1077
00:40:33,520 --> 00:40:36,000
they are separate hardware that can

1078
00:40:36,000 --> 00:40:38,400
sometimes have right access to the

1079
00:40:38,400 --> 00:40:40,800
system memory and just

1080
00:40:40,800 --> 00:40:42,560
break all the security assumptions of

1081
00:40:42,560 --> 00:40:46,079
the core core operating system

1082
00:40:46,079 --> 00:40:47,839
um

1083
00:40:47,839 --> 00:40:50,319
so we are working and

1084
00:40:50,319 --> 00:40:52,319
this is not yet a

1085
00:40:52,319 --> 00:40:54,880
proper result to present on its own but

1086
00:40:54,880 --> 00:40:57,280
we are working again on a different data

1087
00:40:57,280 --> 00:40:58,720
set to improve machine learning

1088
00:40:58,720 --> 00:41:01,040
approaches for this wireless protocol

1089
00:41:01,040 --> 00:41:02,079
testing

1090
00:41:02,079 --> 00:41:04,480
uh we have an ongoing project

1091
00:41:04,480 --> 00:41:06,240
to develop methodology for gathering

1092
00:41:06,240 --> 00:41:09,040
data and build the data set for these

1093
00:41:09,040 --> 00:41:11,040
wireless protocol communications

1094
00:41:11,040 --> 00:41:12,880
software devices

1095
00:41:12,880 --> 00:41:15,680
uh for for this machine learning

1096
00:41:15,680 --> 00:41:17,119
applications

1097
00:41:17,119 --> 00:41:19,440
and uh we are looking at

1098
00:41:19,440 --> 00:41:20,800
again

1099
00:41:20,800 --> 00:41:23,760
just as emory wanted to capture the

1100
00:41:23,760 --> 00:41:26,720
whole network data so that it's properly

1101
00:41:26,720 --> 00:41:28,880
used for all kinds of machine learning

1102
00:41:28,880 --> 00:41:31,200
applications where you just don't don't

1103
00:41:31,200 --> 00:41:35,200
just take the network flow data and

1104
00:41:35,200 --> 00:41:37,280
some limited features but you have all

1105
00:41:37,280 --> 00:41:39,839
the raw data available to improve new

1106
00:41:39,839 --> 00:41:41,839
methods we want to do the same for

1107
00:41:41,839 --> 00:41:44,000
wireless communication and the problem

1108
00:41:44,000 --> 00:41:45,359
there is that

1109
00:41:45,359 --> 00:41:48,319
capturing raw radio data on the scale is

1110
00:41:48,319 --> 00:41:50,880
not trivial if we want to enable

1111
00:41:50,880 --> 00:41:52,880
hardware fingerprinting and

1112
00:41:52,880 --> 00:41:55,920
let's say time timing based physical

1113
00:41:55,920 --> 00:41:57,599
layer attacks

1114
00:41:57,599 --> 00:41:59,760
then we need to essentially capture

1115
00:41:59,760 --> 00:42:02,160
large quantities of raw radio data which

1116
00:42:02,160 --> 00:42:03,200
is

1117
00:42:03,200 --> 00:42:05,760
technically challenging but we hope to

1118
00:42:05,760 --> 00:42:07,359
have some interesting results to present

1119
00:42:07,359 --> 00:42:09,759
soon

1120
00:42:10,000 --> 00:42:12,240
so

1121
00:42:14,560 --> 00:42:17,920
so the next approach to this

1122
00:42:17,920 --> 00:42:19,599
vulnerability detection by machine

1123
00:42:19,599 --> 00:42:20,800
learning

1124
00:42:20,800 --> 00:42:22,800
how would this data set be used

1125
00:42:22,800 --> 00:42:25,680
essentially is to improve the process of

1126
00:42:25,680 --> 00:42:28,160
quality assurance by vendors so we all

1127
00:42:28,160 --> 00:42:29,359
know that

1128
00:42:29,359 --> 00:42:31,280
current state of security and smart

1129
00:42:31,280 --> 00:42:33,040
devices signed into the internet of

1130
00:42:33,040 --> 00:42:35,520
things is

1131
00:42:35,520 --> 00:42:37,680
not as good as we would like

1132
00:42:37,680 --> 00:42:40,240
and of course the main reason is a lack

1133
00:42:40,240 --> 00:42:42,720
of motivation by harbor vendors to focus

1134
00:42:42,720 --> 00:42:44,960
on security because it's expensive and

1135
00:42:44,960 --> 00:42:46,800
time-consuming and consumers don't

1136
00:42:46,800 --> 00:42:47,839
really

1137
00:42:47,839 --> 00:42:49,680
are not willing to pay much for extra

1138
00:42:49,680 --> 00:42:50,880
security

1139
00:42:50,880 --> 00:42:53,119
uh which might be solved by legal

1140
00:42:53,119 --> 00:42:55,760
solutions like regulation and liability

1141
00:42:55,760 --> 00:42:57,839
measures however from the technical

1142
00:42:57,839 --> 00:42:59,760
perspective uh

1143
00:42:59,760 --> 00:43:00,960
a part of

1144
00:43:00,960 --> 00:43:04,079
the saying why it's uh not as good

1145
00:43:04,079 --> 00:43:06,000
security as we would like

1146
00:43:06,000 --> 00:43:08,240
is because of in my opinion lack of

1147
00:43:08,240 --> 00:43:09,359
tooling

1148
00:43:09,359 --> 00:43:11,520
like we had lots of

1149
00:43:11,520 --> 00:43:14,560
security challenges for traditional

1150
00:43:14,560 --> 00:43:16,960
desktop and server-based software

1151
00:43:16,960 --> 00:43:19,680
and we have mitigated many types of

1152
00:43:19,680 --> 00:43:21,599
these vulnerabilities whole classes of

1153
00:43:21,599 --> 00:43:25,200
them by various safeguards like in

1154
00:43:25,200 --> 00:43:28,000
operating systems application isolation

1155
00:43:28,000 --> 00:43:31,280
process isolation hardware changes

1156
00:43:31,280 --> 00:43:32,560
and

1157
00:43:32,560 --> 00:43:35,680
memory safe languages and in embedded

1158
00:43:35,680 --> 00:43:39,359
world it's not as applied yet for all

1159
00:43:39,359 --> 00:43:41,280
kinds of practical reasons

1160
00:43:41,280 --> 00:43:43,280
and also the process of development

1161
00:43:43,280 --> 00:43:45,440
practices lag behind the other id

1162
00:43:45,440 --> 00:43:48,640
domains so

1163
00:43:48,960 --> 00:43:51,599
we would like to help the vendors make

1164
00:43:51,599 --> 00:43:54,079
security testing more easier and this is

1165
00:43:54,079 --> 00:43:57,440
one way how machine learning can help

1166
00:43:57,440 --> 00:44:00,079
them test their software better so if we

1167
00:44:00,079 --> 00:44:02,160
can provide machine learning driven

1168
00:44:02,160 --> 00:44:05,359
fuzzing tools or source code analysis

1169
00:44:05,359 --> 00:44:07,520
that are able to identify such

1170
00:44:07,520 --> 00:44:10,079
vulnerabilities in a way that's

1171
00:44:10,079 --> 00:44:12,800
relatively simple and cheap to use then

1172
00:44:12,800 --> 00:44:14,800
we can hope that the vendors would apply

1173
00:44:14,800 --> 00:44:17,119
them and make their

1174
00:44:17,119 --> 00:44:20,240
smart devices not only smart but also

1175
00:44:20,240 --> 00:44:23,119
secure

1176
00:44:23,119 --> 00:44:25,520
so coming to the second part of my talk

1177
00:44:25,520 --> 00:44:27,440
the threats to machine learning systems

1178
00:44:27,440 --> 00:44:28,800
themselves

1179
00:44:28,800 --> 00:44:30,640
not applying machine learning to solve

1180
00:44:30,640 --> 00:44:32,720
security problems but the security

1181
00:44:32,720 --> 00:44:34,480
problems which are caused by machine

1182
00:44:34,480 --> 00:44:37,599
learning so the biggest part

1183
00:44:37,599 --> 00:44:39,599
in current research are

1184
00:44:39,599 --> 00:44:41,760
adversarial attacks

1185
00:44:41,760 --> 00:44:45,280
so by adverse adversarial attack i mean

1186
00:44:45,280 --> 00:44:46,160
uh

1187
00:44:46,160 --> 00:44:48,000
some kind of if you have machine

1188
00:44:48,000 --> 00:44:50,079
learning systems that's designed to

1189
00:44:50,079 --> 00:44:54,319
classify to give an answer or a decision

1190
00:44:54,319 --> 00:44:55,200
uh

1191
00:44:55,200 --> 00:44:57,680
an adversarial attack would be

1192
00:44:57,680 --> 00:45:00,000
some kind of input that tricks the

1193
00:45:00,000 --> 00:45:02,400
system into making a different decision

1194
00:45:02,400 --> 00:45:05,920
that it should make and uh and that's a

1195
00:45:05,920 --> 00:45:08,560
known issue because by default machine

1196
00:45:08,560 --> 00:45:10,640
learning models are not really robust to

1197
00:45:10,640 --> 00:45:12,319
malicious input

1198
00:45:12,319 --> 00:45:14,800
we have some kind of tech

1199
00:45:14,800 --> 00:45:18,480
theoretical guarantees to accuracy

1200
00:45:18,480 --> 00:45:20,800
of data which is somewhat within the

1201
00:45:20,800 --> 00:45:23,280
distribution of the data on which it was

1202
00:45:23,280 --> 00:45:25,839
trained but if you have

1203
00:45:25,839 --> 00:45:29,920
data that is widely unexpected out of

1204
00:45:29,920 --> 00:45:32,240
distribution then current methods don't

1205
00:45:32,240 --> 00:45:33,200
really

1206
00:45:33,200 --> 00:45:35,680
provide any guarantees about system

1207
00:45:35,680 --> 00:45:38,800
behavior to seeing such out of sample

1208
00:45:38,800 --> 00:45:41,760
novel data and

1209
00:45:41,760 --> 00:45:44,560
it can be it's not usually a big problem

1210
00:45:44,560 --> 00:45:47,280
in most applications because such data

1211
00:45:47,280 --> 00:45:50,000
does not appear in practice however a

1212
00:45:50,000 --> 00:45:52,640
malicious attacker can introduce such

1213
00:45:52,640 --> 00:45:54,640
data if they really want to

1214
00:45:54,640 --> 00:45:56,880
and there is a lot of interesting

1215
00:45:56,880 --> 00:45:59,520
research both recent and quite old

1216
00:45:59,520 --> 00:46:00,400
already

1217
00:46:00,400 --> 00:46:02,079
that we have

1218
00:46:02,079 --> 00:46:04,400
lots of methods and

1219
00:46:04,400 --> 00:46:07,280
publications on these methods how to

1220
00:46:07,280 --> 00:46:10,240
make these malicious adversarial inputs

1221
00:46:10,240 --> 00:46:13,119
so that has been a focus of

1222
00:46:13,119 --> 00:46:15,599
research for quite some time and there's

1223
00:46:15,599 --> 00:46:17,280
large body of research on how to make

1224
00:46:17,280 --> 00:46:18,720
these uh

1225
00:46:18,720 --> 00:46:20,560
adversarial

1226
00:46:20,560 --> 00:46:23,359
inputs in a way that they are

1227
00:46:23,359 --> 00:46:25,680
less detectable to humans it looks

1228
00:46:25,680 --> 00:46:28,480
similar to normal input and so on

1229
00:46:28,480 --> 00:46:31,760
and uh so that's a real concern those

1230
00:46:31,760 --> 00:46:34,960
are territorial attacks are possible and

1231
00:46:34,960 --> 00:46:36,160
while

1232
00:46:36,160 --> 00:46:38,640
uh many of those attacks are let's say

1233
00:46:38,640 --> 00:46:41,440
white box attacks where an attacker has

1234
00:46:41,440 --> 00:46:43,680
knowledge of your machine learning model

1235
00:46:43,680 --> 00:46:45,760
how it's built how it's structured

1236
00:46:45,760 --> 00:46:49,119
perhaps is a model data itself it's not

1237
00:46:49,119 --> 00:46:51,040
really necessary there are

1238
00:46:51,040 --> 00:46:53,599
lots of publications on how to make

1239
00:46:53,599 --> 00:46:56,480
those attacks with just black box access

1240
00:46:56,480 --> 00:46:58,319
to the model you make

1241
00:46:58,319 --> 00:47:00,400
let's say a thousand queries to a

1242
00:47:00,400 --> 00:47:02,480
classification model and you are able to

1243
00:47:02,480 --> 00:47:04,960
make a malicious input that will cheat

1244
00:47:04,960 --> 00:47:06,880
the model somehow

1245
00:47:06,880 --> 00:47:08,000
and

1246
00:47:08,000 --> 00:47:10,720
an observation that i'm seeing in all

1247
00:47:10,720 --> 00:47:14,000
these papers is they usually offer

1248
00:47:14,000 --> 00:47:16,319
actual defenses like these are not

1249
00:47:16,319 --> 00:47:18,560
papers for attackers they are also

1250
00:47:18,560 --> 00:47:20,319
researchers who are trying to improve

1251
00:47:20,319 --> 00:47:24,000
security uh they suggest how defenses

1252
00:47:24,000 --> 00:47:26,720
how the models could be made more robust

1253
00:47:26,720 --> 00:47:29,200
but then i go back to practice how

1254
00:47:29,200 --> 00:47:30,640
people make

1255
00:47:30,640 --> 00:47:32,960
systems and for example natural language

1256
00:47:32,960 --> 00:47:36,559
processing well people do not really

1257
00:47:36,559 --> 00:47:39,200
apply those defenses because again it's

1258
00:47:39,200 --> 00:47:41,359
extra work and uh

1259
00:47:41,359 --> 00:47:42,960
if it's not

1260
00:47:42,960 --> 00:47:46,160
mandatory then people are skipping those

1261
00:47:46,160 --> 00:47:48,800
defenses so that's a

1262
00:47:48,800 --> 00:47:51,040
problem for for the whole industry in

1263
00:47:51,040 --> 00:47:53,599
some in some sense

1264
00:47:53,599 --> 00:47:55,520
and some examples of those adversarial

1265
00:47:55,520 --> 00:47:57,760
attacks to make uh

1266
00:47:57,760 --> 00:48:00,400
to place them into a better context uh

1267
00:48:00,400 --> 00:48:02,319
lots of research has been done in uh

1268
00:48:02,319 --> 00:48:05,040
adversarial attacks for object detection

1269
00:48:05,040 --> 00:48:06,880
in computer vision

1270
00:48:06,880 --> 00:48:09,200
uh a popular application of computer

1271
00:48:09,200 --> 00:48:10,800
vision is in

1272
00:48:10,800 --> 00:48:12,640
self-driving cars

1273
00:48:12,640 --> 00:48:14,559
so you have a system that tries to

1274
00:48:14,559 --> 00:48:16,880
analyze street signs and there are all

1275
00:48:16,880 --> 00:48:19,520
kinds of interesting attacks on how an

1276
00:48:19,520 --> 00:48:21,359
attacker can make a street science

1277
00:48:21,359 --> 00:48:23,760
that's going to be misclassified as an

1278
00:48:23,760 --> 00:48:26,000
entirely different straight signed or

1279
00:48:26,000 --> 00:48:29,359
ignored or how to make road marks that

1280
00:48:29,359 --> 00:48:32,079
will look normal to human but a

1281
00:48:32,079 --> 00:48:34,400
self-driving car will see them as

1282
00:48:34,400 --> 00:48:36,880
road turning in a different direction so

1283
00:48:36,880 --> 00:48:38,960
it might it would uh

1284
00:48:38,960 --> 00:48:42,800
tricks a car into going off-road

1285
00:48:42,800 --> 00:48:46,400
so again some some real impact to

1286
00:48:46,400 --> 00:48:48,960
physical security and the same or

1287
00:48:48,960 --> 00:48:51,599
similar attacks are possible for lidar

1288
00:48:51,599 --> 00:48:53,760
sensors not only into visual attacks but

1289
00:48:53,760 --> 00:48:56,079
also radar and lidar sensors on

1290
00:48:56,079 --> 00:49:00,160
self-driving cars and we have also seen

1291
00:49:00,160 --> 00:49:02,160
similar attacks for essentially every

1292
00:49:02,160 --> 00:49:04,559
domain where machine learning is applied

1293
00:49:04,559 --> 00:49:07,280
phase detection textual analysis for

1294
00:49:07,280 --> 00:49:10,160
toxic comment detection all those topics

1295
00:49:10,160 --> 00:49:12,400
where classifiers are used

1296
00:49:12,400 --> 00:49:15,280
they there are ways to make adversarial

1297
00:49:15,280 --> 00:49:17,920
examples for them

1298
00:49:17,920 --> 00:49:19,440
a second

1299
00:49:19,440 --> 00:49:20,960
big

1300
00:49:20,960 --> 00:49:22,720
class of vulnerabilities of machine

1301
00:49:22,720 --> 00:49:24,800
learning systems is poisoning of

1302
00:49:24,800 --> 00:49:28,079
continuous learning systems many

1303
00:49:28,079 --> 00:49:30,640
say industrial or practical applications

1304
00:49:30,640 --> 00:49:32,400
of machine learning

1305
00:49:32,400 --> 00:49:35,119
try to use a continuous learning system

1306
00:49:35,119 --> 00:49:37,280
to have it adapt

1307
00:49:37,280 --> 00:49:40,319
continuously to new data this was also

1308
00:49:40,319 --> 00:49:42,160
asked as a question after the previous

1309
00:49:42,160 --> 00:49:43,040
talk

1310
00:49:43,040 --> 00:49:44,800
and

1311
00:49:44,800 --> 00:49:47,040
the problem with this is

1312
00:49:47,040 --> 00:49:47,920
really

1313
00:49:47,920 --> 00:49:48,960
that

1314
00:49:48,960 --> 00:49:50,960
machine learning systems can learn all

1315
00:49:50,960 --> 00:49:52,880
kinds of arbitrary associations and

1316
00:49:52,880 --> 00:49:54,319
attacker

1317
00:49:54,319 --> 00:49:56,319
as soon as an attacker is able to

1318
00:49:56,319 --> 00:49:58,400
control data that will be used by the

1319
00:49:58,400 --> 00:50:00,880
system as training data afterwards an

1320
00:50:00,880 --> 00:50:02,960
attacker can influence a system to

1321
00:50:02,960 --> 00:50:04,720
artificially create

1322
00:50:04,720 --> 00:50:07,520
an association that will

1323
00:50:07,520 --> 00:50:09,040
let's say

1324
00:50:09,040 --> 00:50:11,599
that can later be used to

1325
00:50:11,599 --> 00:50:14,720
disguise malicious traffic or malicious

1326
00:50:14,720 --> 00:50:17,440
data as something benign

1327
00:50:17,440 --> 00:50:20,000
and circumvent some protections

1328
00:50:20,000 --> 00:50:22,880
so as that's a big question how do we

1329
00:50:22,880 --> 00:50:26,000
know what is normal for the system like

1330
00:50:26,000 --> 00:50:27,839
if we train a network intrusion

1331
00:50:27,839 --> 00:50:30,480
detection system on a corporate network

1332
00:50:30,480 --> 00:50:34,079
that has undetected attacker with cobble

1333
00:50:34,079 --> 00:50:36,240
strike beacons in them then the system

1334
00:50:36,240 --> 00:50:38,000
will learn that cobalt strike beacons

1335
00:50:38,000 --> 00:50:39,839
are a normal part of this network and

1336
00:50:39,839 --> 00:50:41,760
should not be detected

1337
00:50:41,760 --> 00:50:44,720
and yeah

1338
00:50:45,119 --> 00:50:46,079
and

1339
00:50:46,079 --> 00:50:48,000
the third class of

1340
00:50:48,000 --> 00:50:49,680
in vulnerabilities machine learning

1341
00:50:49,680 --> 00:50:52,640
system are intentional backdoors

1342
00:50:52,640 --> 00:50:57,920
uh just as an attacker can poison data

1343
00:50:57,920 --> 00:51:00,240
of your system

1344
00:51:00,240 --> 00:51:02,319
you often will be used systems built by

1345
00:51:02,319 --> 00:51:04,160
someone else

1346
00:51:04,160 --> 00:51:07,280
and system developer can make

1347
00:51:07,280 --> 00:51:09,760
a system with backdoors that are hard or

1348
00:51:09,760 --> 00:51:11,599
impossible to detect

1349
00:51:11,599 --> 00:51:13,599
in a sense they can make

1350
00:51:13,599 --> 00:51:15,680
machine learning systems that will

1351
00:51:15,680 --> 00:51:19,760
perform accurately for almost all cases

1352
00:51:19,760 --> 00:51:20,960
but if

1353
00:51:20,960 --> 00:51:24,800
let's say a secret password in a

1354
00:51:24,800 --> 00:51:28,240
broad sense in an image

1355
00:51:28,240 --> 00:51:30,720
analysis systems a password would be

1356
00:51:30,720 --> 00:51:34,800
some interesting trigger of pixels uh

1357
00:51:34,800 --> 00:51:36,800
in the presence of a trigger the

1358
00:51:36,800 --> 00:51:38,480
behavior of a system is completely

1359
00:51:38,480 --> 00:51:41,280
opposite so such systems are again

1360
00:51:41,280 --> 00:51:43,760
possible to design it's well-known how

1361
00:51:43,760 --> 00:51:47,040
to design them and

1362
00:51:47,040 --> 00:51:49,520
the big issue is that

1363
00:51:49,520 --> 00:51:52,640
it may not be detectable until after

1364
00:51:52,640 --> 00:51:55,440
it's used like there's very recent

1365
00:51:55,440 --> 00:51:57,680
research suggesting that there may be

1366
00:51:57,680 --> 00:51:59,200
methods to make it

1367
00:51:59,200 --> 00:52:01,440
completely undetectable it's

1368
00:52:01,440 --> 00:52:04,800
perhaps needs verification still but

1369
00:52:04,800 --> 00:52:07,440
in any case it's a big danger

1370
00:52:07,440 --> 00:52:08,240
and

1371
00:52:08,240 --> 00:52:10,640
even if you trust the system developer

1372
00:52:10,640 --> 00:52:13,040
they may have malicious insider they may

1373
00:52:13,040 --> 00:52:15,200
have attacker in their network and they

1374
00:52:15,200 --> 00:52:19,839
may be simply using data sources made by

1375
00:52:19,839 --> 00:52:21,760
someone else or gathered from the

1376
00:52:21,760 --> 00:52:23,760
internet that have been poisoned by a

1377
00:52:23,760 --> 00:52:25,920
smart attacker

1378
00:52:25,920 --> 00:52:26,880
so

1379
00:52:26,880 --> 00:52:30,160
the risk of backdoors is something that

1380
00:52:30,160 --> 00:52:32,079
in my opinion needs more attention from

1381
00:52:32,079 --> 00:52:34,240
the machine learning community

1382
00:52:34,240 --> 00:52:35,280
and again

1383
00:52:35,280 --> 00:52:37,839
example use cases for such attacks are

1384
00:52:37,839 --> 00:52:40,400
essentially every security rate in

1385
00:52:40,400 --> 00:52:43,280
machine learning system that

1386
00:52:43,280 --> 00:52:46,400
if it's backdoor can simply

1387
00:52:46,400 --> 00:52:48,079
remove its protections intrusion

1388
00:52:48,079 --> 00:52:50,960
detection system can be back door to

1389
00:52:50,960 --> 00:52:52,800
allow malicious traffic

1390
00:52:52,800 --> 00:52:55,839
video surveillance system may not detect

1391
00:52:55,839 --> 00:52:56,720
cis

1392
00:52:56,720 --> 00:52:58,319
people if they are

1393
00:52:58,319 --> 00:53:00,319
let's say carrying a certain visual

1394
00:53:00,319 --> 00:53:03,680
trigger and and so on and so on uh all

1395
00:53:03,680 --> 00:53:06,240
those aspects have

1396
00:53:06,240 --> 00:53:09,440
their own separate risks

1397
00:53:09,440 --> 00:53:11,520
and uh

1398
00:53:11,520 --> 00:53:13,680
are these risks practical

1399
00:53:13,680 --> 00:53:16,640
and in my opinion not yet

1400
00:53:16,640 --> 00:53:18,160
because

1401
00:53:18,160 --> 00:53:19,760
first

1402
00:53:19,760 --> 00:53:22,000
we are still seeing quite limited

1403
00:53:22,000 --> 00:53:24,240
adoption actual adoption of machine

1404
00:53:24,240 --> 00:53:25,760
learning systems

1405
00:53:25,760 --> 00:53:27,359
if we look at vendors who are

1406
00:53:27,359 --> 00:53:29,760
advertising their machine learning based

1407
00:53:29,760 --> 00:53:32,400
systems some of them

1408
00:53:32,400 --> 00:53:34,480
are not really using machine learning

1409
00:53:34,480 --> 00:53:38,319
much but just advertising them

1410
00:53:38,319 --> 00:53:39,440
and

1411
00:53:39,440 --> 00:53:42,160
the biggest part is that those backdoors

1412
00:53:42,160 --> 00:53:44,720
they don't in my opinion have a direct

1413
00:53:44,720 --> 00:53:46,640
financial motivation for attackers

1414
00:53:46,640 --> 00:53:48,480
because we're seeing lots of attacks

1415
00:53:48,480 --> 00:53:51,040
which are essentially motivated by cyber

1416
00:53:51,040 --> 00:53:54,079
crime ransomware ability to steal money

1417
00:53:54,079 --> 00:53:56,960
and those backdoor attacks are not as

1418
00:53:56,960 --> 00:54:00,400
useful for their level of difficulty for

1419
00:54:00,400 --> 00:54:03,040
a financially motivated attacker however

1420
00:54:03,040 --> 00:54:05,359
in the context of this conference

1421
00:54:05,359 --> 00:54:07,200
such backdoor attacks can be quite

1422
00:54:07,200 --> 00:54:10,240
relevant for sophisticated attackers who

1423
00:54:10,240 --> 00:54:12,319
are who want to influence let's say

1424
00:54:12,319 --> 00:54:14,960
state security measures

1425
00:54:14,960 --> 00:54:17,200
and uh also it

1426
00:54:17,200 --> 00:54:19,280
it's likely to become more relevant in

1427
00:54:19,280 --> 00:54:22,079
future so we as

1428
00:54:22,079 --> 00:54:24,160
uh machine learning industry not perhaps

1429
00:54:24,160 --> 00:54:26,079
we as security industry but more as we

1430
00:54:26,079 --> 00:54:28,319
as machine learning researchers need

1431
00:54:28,319 --> 00:54:32,240
uh more time to prepare for

1432
00:54:32,480 --> 00:54:35,760
countering these attacks

1433
00:54:35,920 --> 00:54:37,520
and one way to

1434
00:54:37,520 --> 00:54:39,760
being prepared for for these attacks is

1435
00:54:39,760 --> 00:54:42,319
need for supply chain security uh

1436
00:54:42,319 --> 00:54:44,720
because common currently practically

1437
00:54:44,720 --> 00:54:47,599
used ml practices often rely on

1438
00:54:47,599 --> 00:54:50,160
untrusted sources of data people use all

1439
00:54:50,160 --> 00:54:52,240
the data they can get because more data

1440
00:54:52,240 --> 00:54:54,160
is better

1441
00:54:54,160 --> 00:54:56,640
and we are using third-party models we

1442
00:54:56,640 --> 00:54:58,640
are using combinations of multiple

1443
00:54:58,640 --> 00:55:00,640
third-party models and we don't even

1444
00:55:00,640 --> 00:55:03,440
know who made them and

1445
00:55:03,440 --> 00:55:06,079
and the same applies for data sources we

1446
00:55:06,079 --> 00:55:08,160
use data sources from web scraping for

1447
00:55:08,160 --> 00:55:11,200
volunteers and of course if i'm

1448
00:55:11,200 --> 00:55:12,799
gathering data from volunteers an

1449
00:55:12,799 --> 00:55:15,200
attacker can volunteer to provide me all

1450
00:55:15,200 --> 00:55:17,359
the data they want

1451
00:55:17,359 --> 00:55:18,880
and

1452
00:55:18,880 --> 00:55:21,119
auditing models is impractical but

1453
00:55:21,119 --> 00:55:23,920
perhaps auditing the sources of the data

1454
00:55:23,920 --> 00:55:27,280
can be practically possible there's a

1455
00:55:27,280 --> 00:55:29,920
recent movement for software bill of

1456
00:55:29,920 --> 00:55:32,720
materials to track all the sources of

1457
00:55:32,720 --> 00:55:35,280
your software and libraries perhaps the

1458
00:55:35,280 --> 00:55:37,839
same approach should be used for machine

1459
00:55:37,839 --> 00:55:40,079
learning systems

1460
00:55:40,079 --> 00:55:41,839
so to summarize

1461
00:55:41,839 --> 00:55:43,920
machine learning systems

1462
00:55:43,920 --> 00:55:46,079
not only can be used to improve security

1463
00:55:46,079 --> 00:55:47,680
but they have their own

1464
00:55:47,680 --> 00:55:50,000
new types of vulnerabilities which

1465
00:55:50,000 --> 00:55:51,839
present new and interesting challenges

1466
00:55:51,839 --> 00:55:53,599
for this audience

1467
00:55:53,599 --> 00:55:56,000
and for adversarial attacks

1468
00:55:56,000 --> 00:55:58,240
the researchers have identified all

1469
00:55:58,240 --> 00:56:01,119
kinds of mitigations which are not

1470
00:56:01,119 --> 00:56:03,760
widely applied in practice yet perhaps

1471
00:56:03,760 --> 00:56:05,520
there are some parallels with normal

1472
00:56:05,520 --> 00:56:07,680
security measures as well

1473
00:56:07,680 --> 00:56:10,160
the same problem of not applying known

1474
00:56:10,160 --> 00:56:11,200
things but

1475
00:56:11,200 --> 00:56:12,079
it's

1476
00:56:12,079 --> 00:56:13,599
quite prevalent in machine learning

1477
00:56:13,599 --> 00:56:17,040
industry and for backdoor attacks we

1478
00:56:17,040 --> 00:56:20,640
don't have yet effective controls

1479
00:56:20,640 --> 00:56:22,319
we have some

1480
00:56:22,319 --> 00:56:24,480
generic mitigations

1481
00:56:24,480 --> 00:56:26,559
like the last year's anissa report

1482
00:56:26,559 --> 00:56:28,880
suggests all kinds of

1483
00:56:28,880 --> 00:56:32,000
generic mitigations for such risks but

1484
00:56:32,000 --> 00:56:34,079
they are not let's say comprehensive and

1485
00:56:34,079 --> 00:56:36,319
practical yet to be treated as a

1486
00:56:36,319 --> 00:56:38,720
solution for for this problem

1487
00:56:38,720 --> 00:56:40,720
so for cyber physical systems machine

1488
00:56:40,720 --> 00:56:42,079
learning it's

1489
00:56:42,079 --> 00:56:45,599
still buyer beware test what you have

1490
00:56:45,599 --> 00:56:46,799
and

1491
00:56:46,799 --> 00:56:48,960
a separate point the last point is

1492
00:56:48,960 --> 00:56:50,559
coming back to the first part of this

1493
00:56:50,559 --> 00:56:52,799
talk uh i think there's a great

1494
00:56:52,799 --> 00:56:54,480
potential for machine learning to be

1495
00:56:54,480 --> 00:56:58,160
used to improve security by vendor by

1496
00:56:58,160 --> 00:57:00,480
improving vendor quality assurance for

1497
00:57:00,480 --> 00:57:04,640
those vendors who make all these gadgets

1498
00:57:04,640 --> 00:57:05,839
and

1499
00:57:05,839 --> 00:57:09,599
might want to make them more secure

1500
00:57:09,599 --> 00:57:12,079
okay here are some references for those

1501
00:57:12,079 --> 00:57:14,240
who will look at it later

1502
00:57:14,240 --> 00:57:15,599
and

1503
00:57:15,599 --> 00:57:17,520
time for questions thank you

1504
00:57:17,520 --> 00:57:18,740
thank you very much

1505
00:57:18,740 --> 00:57:24,509
[Applause]

1506
00:57:25,040 --> 00:57:27,440
so we have a moment to uh allow a couple

1507
00:57:27,440 --> 00:57:28,640
of questions

1508
00:57:28,640 --> 00:57:30,160
we have um

1509
00:57:30,160 --> 00:57:32,079
also as i said a time buffer towards the

1510
00:57:32,079 --> 00:57:34,319
end so we'll be hearing from sampati in

1511
00:57:34,319 --> 00:57:36,559
a moment gabor let me go to you

1512
00:57:36,559 --> 00:57:39,119
since you have a microphone

1513
00:57:39,119 --> 00:57:40,640
thank you all for your excellent

1514
00:57:40,640 --> 00:57:42,960
presentation i really loved it and i'm

1515
00:57:42,960 --> 00:57:45,839
not a building man i just

1516
00:57:45,839 --> 00:57:47,680
have some room for improvement so the

1517
00:57:47,680 --> 00:57:48,960
i.t er

1518
00:57:48,960 --> 00:57:51,040
usually or the security in it usually

1519
00:57:51,040 --> 00:57:53,119
focuses on the information security

1520
00:57:53,119 --> 00:57:55,839
while in ot we are dealing with process

1521
00:57:55,839 --> 00:57:58,480
security and safety

1522
00:57:58,480 --> 00:57:59,440
and i

1523
00:57:59,440 --> 00:58:02,079
i'm always thinking if we introduce

1524
00:58:02,079 --> 00:58:04,559
ideas for example intrusion prevention

1525
00:58:04,559 --> 00:58:07,760
systems and they filter out for example

1526
00:58:07,760 --> 00:58:10,000
very special pocket like an emergency

1527
00:58:10,000 --> 00:58:13,440
stop that will be a kind of disaster so

1528
00:58:13,440 --> 00:58:16,319
don't you think that the these

1529
00:58:16,319 --> 00:58:19,680
solutions will take in front the

1530
00:58:19,680 --> 00:58:22,079
information security over the process

1531
00:58:22,079 --> 00:58:25,280
security in ot

1532
00:58:25,359 --> 00:58:27,040
oh

1533
00:58:27,040 --> 00:58:30,000
well this is perhaps uh a different

1534
00:58:30,000 --> 00:58:32,400
reason why i'm a bit skeptical about

1535
00:58:32,400 --> 00:58:34,720
application of machine learning in this

1536
00:58:34,720 --> 00:58:38,319
process security aspect because uh if

1537
00:58:38,319 --> 00:58:40,640
you may have legitimate scenarios that

1538
00:58:40,640 --> 00:58:43,280
you have in your industrial process that

1539
00:58:43,280 --> 00:58:45,280
you have planned and scheduled but you

1540
00:58:45,280 --> 00:58:47,359
never had actually in practice because

1541
00:58:47,359 --> 00:58:49,520
those are like emergency situations

1542
00:58:49,520 --> 00:58:52,000
which you know you have nuclear reactors

1543
00:58:52,000 --> 00:58:53,920
that has not been close to exploding yet

1544
00:58:53,920 --> 00:58:54,640
so

1545
00:58:54,640 --> 00:58:57,119
uh you will not have training data for

1546
00:58:57,119 --> 00:58:58,799
it for machine learning system but you

1547
00:58:58,799 --> 00:59:01,040
can write a rule-based system to cover

1548
00:59:01,040 --> 00:59:03,119
those scenarios oh clear thank you very

1549
00:59:03,119 --> 00:59:06,079
much for an answer

1550
00:59:06,079 --> 00:59:08,640
we have another one from the front row

1551
00:59:08,640 --> 00:59:10,880
dr bloomberg from certal v

1552
00:59:10,880 --> 00:59:12,960
i have a question so you mentioned that

1553
00:59:12,960 --> 00:59:15,040
there is a risk of adversary trying to

1554
00:59:15,040 --> 00:59:16,319
poison the

1555
00:59:16,319 --> 00:59:18,960
data which is used for learning of the

1556
00:59:18,960 --> 00:59:21,359
machine learning or ai systems

1557
00:59:21,359 --> 00:59:23,040
just thinking about and this is just a

1558
00:59:23,040 --> 00:59:25,040
question out uh would you what do you

1559
00:59:25,040 --> 00:59:27,280
think would it make sense to create a

1560
00:59:27,280 --> 00:59:29,839
guardian or a sentinel ai systems that

1561
00:59:29,839 --> 00:59:31,599
can be used to supervise the learning

1562
00:59:31,599 --> 00:59:34,319
process and identify a malicious

1563
00:59:34,319 --> 00:59:36,960
intrusion into the learning process by

1564
00:59:36,960 --> 00:59:39,200
an adversary i know this is an inception

1565
00:59:39,200 --> 00:59:41,760
of trying to layer and bringing layers

1566
00:59:41,760 --> 00:59:43,359
and adversary will for sure try to

1567
00:59:43,359 --> 00:59:45,359
figure out the ways on how to interfere

1568
00:59:45,359 --> 00:59:48,400
with this but is there an any attempt on

1569
00:59:48,400 --> 00:59:51,040
using an iai to protect the learning of

1570
00:59:51,040 --> 00:59:52,720
an ai

1571
00:59:52,720 --> 00:59:55,119
i think that

1572
00:59:55,119 --> 00:59:57,119
that would be a nice thing if we not

1573
00:59:57,119 --> 00:59:59,839
knew how to do it and as far as i'm

1574
00:59:59,839 --> 01:00:02,240
looking at current research i i think we

1575
01:00:02,240 --> 01:00:04,880
do not have a good working solution for

1576
01:00:04,880 --> 01:00:06,640
that yet

1577
01:00:06,640 --> 01:00:08,960
it's a very clever pop culture reference

1578
01:00:08,960 --> 01:00:10,720
to inception as well

1579
01:00:10,720 --> 01:00:13,119
but uh yeah i very much agree with this

1580
01:00:13,119 --> 01:00:14,240
answer and i think if you have

1581
01:00:14,240 --> 01:00:16,640
supervision of of other systems

1582
01:00:16,640 --> 01:00:17,920
there of course are it's known that

1583
01:00:17,920 --> 01:00:19,839
there will be fixed points that are

1584
01:00:19,839 --> 01:00:21,280
emergent so

1585
01:00:21,280 --> 01:00:23,280
you may get the behavior you want uh or

1586
01:00:23,280 --> 01:00:25,119
potentially something completely

1587
01:00:25,119 --> 01:00:26,240
different

1588
01:00:26,240 --> 01:00:28,720
on that note i oh sorry i think there's

1589
01:00:28,720 --> 01:00:30,960
one more question sorry hello thank you

1590
01:00:30,960 --> 01:00:33,119
so much um i'm carly winkler i'm from

1591
01:00:33,119 --> 01:00:34,720
australia australian strategic policy

1592
01:00:34,720 --> 01:00:36,640
institute i'm curious as to whether or

1593
01:00:36,640 --> 01:00:39,599
not you've investigated looking at um

1594
01:00:39,599 --> 01:00:41,200
some of the huge machine learning models

1595
01:00:41,200 --> 01:00:42,559
that have been developed by a private

1596
01:00:42,559 --> 01:00:45,599
industry like bert in the nlp space

1597
01:00:45,599 --> 01:00:47,200
and looked at adversarial attacks and

1598
01:00:47,200 --> 01:00:49,119
whether or not they survive

1599
01:00:49,119 --> 01:00:51,040
through the refining of those models

1600
01:00:51,040 --> 01:00:53,520
when they get to be used in practice

1601
01:00:53,520 --> 01:00:57,040
there is research that uh supports that

1602
01:00:57,040 --> 01:01:00,319
if you poison a core model like birth or

1603
01:01:00,319 --> 01:01:02,640
similar models that fine tuning on them

1604
01:01:02,640 --> 01:01:04,720
will still preserve the malicious

1605
01:01:04,720 --> 01:01:08,960
properties so it's a quite real danger

1606
01:01:08,960 --> 01:01:09,920
could view that as a kind of

1607
01:01:09,920 --> 01:01:11,440
steganography

1608
01:01:11,440 --> 01:01:13,280
thanks very much okay thank you we'll be

1609
01:01:13,280 --> 01:01:15,119
continuing uh with the questions also

1610
01:01:15,119 --> 01:01:17,359
covering your talk in just a moment in

1611
01:01:17,359 --> 01:01:20,559
the last section so thanks again petrus

1612
01:01:20,559 --> 01:01:23,559
and

1613
01:01:25,359 --> 01:01:28,640
don't forget to allow us the time

1614
01:01:31,839 --> 01:01:33,520
uh good afternoon

1615
01:01:33,520 --> 01:01:36,000
uh since morning we were talking about

1616
01:01:36,000 --> 01:01:39,200
keep moving now let me talk about

1617
01:01:39,200 --> 01:01:41,839
how to keep your moving vehicles secure

1618
01:01:41,839 --> 01:01:44,480
that means if you have a modern vehicles

1619
01:01:44,480 --> 01:01:46,799
you are in a risk

1620
01:01:46,799 --> 01:01:49,040
let me start this by explaining the

1621
01:01:49,040 --> 01:01:52,720
complexity of modern vehicles

1622
01:01:52,720 --> 01:01:55,440
when it comes to this modern vehicle

1623
01:01:55,440 --> 01:01:57,200
there are some software's which have

1624
01:01:57,200 --> 01:01:59,599
around 100 million line of code and in

1625
01:01:59,599 --> 01:02:01,760
the near future it will exceed 200 to

1626
01:02:01,760 --> 01:02:04,400
300 million lines of code and also there

1627
01:02:04,400 --> 01:02:07,680
are some systems to support and provide

1628
01:02:07,680 --> 01:02:11,680
the safe comfortable and efficient

1629
01:02:11,680 --> 01:02:14,000
service to the its passengers and also

1630
01:02:14,000 --> 01:02:16,640
at the same time these modded vehicles

1631
01:02:16,640 --> 01:02:19,200
include electronic control unit around

1632
01:02:19,200 --> 01:02:21,440
100 electronic control unit

1633
01:02:21,440 --> 01:02:23,359
to control different functions of the

1634
01:02:23,359 --> 01:02:25,920
vehicle as an example engine control

1635
01:02:25,920 --> 01:02:28,240
unit control the engine related

1636
01:02:28,240 --> 01:02:29,680
functions whereas the transmission

1637
01:02:29,680 --> 01:02:31,760
control unit control the transmission

1638
01:02:31,760 --> 01:02:32,839
related

1639
01:02:32,839 --> 01:02:35,039
functions all these

1640
01:02:35,039 --> 01:02:37,200
ecu's are interconnected using the

1641
01:02:37,200 --> 01:02:39,520
different vehicle and network protocol

1642
01:02:39,520 --> 01:02:43,680
among those internal network protocol

1643
01:02:43,680 --> 01:02:46,000
control area network or other can bus is

1644
01:02:46,000 --> 01:02:47,760
considered as the most widely used in

1645
01:02:47,760 --> 01:02:50,000
vehicle network protocol that's because

1646
01:02:50,000 --> 01:02:52,079
of different advantages provided by this

1647
01:02:52,079 --> 01:02:54,960
protocol such as local speed light and

1648
01:02:54,960 --> 01:02:57,440
robustness however despite these

1649
01:02:57,440 --> 01:03:00,240
advantages by design can bus is

1650
01:03:00,240 --> 01:03:02,400
vulnerable to cyber attacks that's

1651
01:03:02,400 --> 01:03:03,920
mainly because of

1652
01:03:03,920 --> 01:03:06,480
no authentication broadcast domain no

1653
01:03:06,480 --> 01:03:09,359
encryption and id based priority

1654
01:03:09,359 --> 01:03:11,920
in this image you can see that in figure

1655
01:03:11,920 --> 01:03:14,480
2 the different fields of the can data

1656
01:03:14,480 --> 01:03:16,640
frame the most important fields are the

1657
01:03:16,640 --> 01:03:20,000
id which is unique for each cu and also

1658
01:03:20,000 --> 01:03:22,160
the payload which contain the actual

1659
01:03:22,160 --> 01:03:25,119
message which transit by the ecu

1660
01:03:25,119 --> 01:03:26,960
and also in the figure 3 you can see

1661
01:03:26,960 --> 01:03:29,280
that how an attacker can access to the

1662
01:03:29,280 --> 01:03:31,680
ui vehicle network protocol

1663
01:03:31,680 --> 01:03:33,839
india you can see how ecu's are

1664
01:03:33,839 --> 01:03:35,839
interconnected to each other using the

1665
01:03:35,839 --> 01:03:39,119
can bus and attacker can get

1666
01:03:39,119 --> 01:03:42,079
accessed through either physical devices

1667
01:03:42,079 --> 01:03:45,200
like obd2 port or more commonly

1668
01:03:45,200 --> 01:03:47,039
through

1669
01:03:47,039 --> 01:03:48,960
wireless networks such as wi-fi

1670
01:03:48,960 --> 01:03:51,440
bluetooth and cellular network then they

1671
01:03:51,440 --> 01:03:53,359
can launch different uh

1672
01:03:53,359 --> 01:03:55,280
inject different message into the can

1673
01:03:55,280 --> 01:03:57,520
bus and do some changes into your

1674
01:03:57,520 --> 01:03:58,400
vehicle

1675
01:03:58,400 --> 01:04:00,960
and also intrusion detection systems are

1676
01:04:00,960 --> 01:04:04,319
there to detect these attacks

1677
01:04:04,319 --> 01:04:05,920
however when it comes to the insurance

1678
01:04:05,920 --> 01:04:07,839
detection system for individual network

1679
01:04:07,839 --> 01:04:09,520
there are different challenges the the

1680
01:04:09,520 --> 01:04:11,599
biggest challenge is lack of knowledge

1681
01:04:11,599 --> 01:04:13,520
about the can data specification that

1682
01:04:13,520 --> 01:04:15,760
means this we don't know what that what

1683
01:04:15,760 --> 01:04:17,920
this data means this is a kind of a

1684
01:04:17,920 --> 01:04:19,839
confidential database file for a vehicle

1685
01:04:19,839 --> 01:04:21,680
manufacturer without knowing this

1686
01:04:21,680 --> 01:04:23,520
specification it's really hard to come

1687
01:04:23,520 --> 01:04:26,240
up with the generalizable solution to

1688
01:04:26,240 --> 01:04:27,839
apply into different vehicles to

1689
01:04:27,839 --> 01:04:30,400
identify these attacks the second attack

1690
01:04:30,400 --> 01:04:32,160
the second challenge is

1691
01:04:32,160 --> 01:04:33,760
whatever the solution we have come up

1692
01:04:33,760 --> 01:04:36,559
with it should be able to operate under

1693
01:04:36,559 --> 01:04:39,200
computational constraint environment and

1694
01:04:39,200 --> 01:04:41,760
will be able to detect this attack near

1695
01:04:41,760 --> 01:04:44,880
time or under near real time and third

1696
01:04:44,880 --> 01:04:47,039
challenge it is applicable for any cyber

1697
01:04:47,039 --> 01:04:49,200
security domain various type of attack

1698
01:04:49,200 --> 01:04:50,960
and the next biggest challenge is the

1699
01:04:50,960 --> 01:04:53,039
limited attack attack data availability

1700
01:04:53,039 --> 01:04:56,000
unlike other security domains

1701
01:04:56,000 --> 01:04:58,400
to come up with the attack data for a

1702
01:04:58,400 --> 01:05:01,440
vehicle network its risk can cost in all

1703
01:05:01,440 --> 01:05:03,200
with this experiment because of that

1704
01:05:03,200 --> 01:05:05,119
reason it's really hard to find the

1705
01:05:05,119 --> 01:05:06,839
attack data for this

1706
01:05:06,839 --> 01:05:09,599
domain first we did the kind of data

1707
01:05:09,599 --> 01:05:12,319
analysis to identify what was what sort

1708
01:05:12,319 --> 01:05:15,760
of trends are in the can data and to

1709
01:05:15,760 --> 01:05:17,760
identify different patterns

1710
01:05:17,760 --> 01:05:20,160
so in the for this we use a data set

1711
01:05:20,160 --> 01:05:22,400
called road road data set which has kind

1712
01:05:22,400 --> 01:05:24,960
of a realistic attack

1713
01:05:24,960 --> 01:05:27,359
basically there are two type of attack

1714
01:05:27,359 --> 01:05:29,280
available in this data set which is a

1715
01:05:29,280 --> 01:05:31,119
injection attack or the fabrication

1716
01:05:31,119 --> 01:05:32,559
attack where i attack

1717
01:05:32,559 --> 01:05:35,599
inject malicious id into the can bus and

1718
01:05:35,599 --> 01:05:37,920
the second type of attack which is known

1719
01:05:37,920 --> 01:05:40,000
as the masquerade attack which is a kind

1720
01:05:40,000 --> 01:05:42,640
of a more sophisticated attack where i

1721
01:05:42,640 --> 01:05:45,440
attack a compromise ecu and

1722
01:05:45,440 --> 01:05:48,240
stop sending the message from then is eu

1723
01:05:48,240 --> 01:05:50,640
and instead attacks in malicious message

1724
01:05:50,640 --> 01:05:53,280
message to that tcu

1725
01:05:53,280 --> 01:05:55,680
throughout this analysis uh the our

1726
01:05:55,680 --> 01:05:58,480
findings were the periodic behave can id

1727
01:05:58,480 --> 01:06:01,359
transmission you can see in these two

1728
01:06:01,359 --> 01:06:02,799
images

1729
01:06:02,799 --> 01:06:04,480
it has a predefined

1730
01:06:04,480 --> 01:06:06,960
frequency range to transmit the message

1731
01:06:06,960 --> 01:06:08,319
and also

1732
01:06:08,319 --> 01:06:10,400
find a set of can id sequencer for fixed

1733
01:06:10,400 --> 01:06:12,720
window size that means if we selected

1734
01:06:12,720 --> 01:06:16,319
the window size such as 10 10 can ids

1735
01:06:16,319 --> 01:06:18,319
then since we have a limited number of

1736
01:06:18,319 --> 01:06:20,319
ecu's in the vehicle that means for

1737
01:06:20,319 --> 01:06:23,520
example 100 is used this create a final

1738
01:06:23,520 --> 01:06:25,680
set of sequences

1739
01:06:25,680 --> 01:06:28,240
for a normal driving behavior

1740
01:06:28,240 --> 01:06:31,359
so when there is an attack

1741
01:06:31,359 --> 01:06:33,280
both of these properties will change it

1742
01:06:33,280 --> 01:06:36,079
will create new can id sequences as well

1743
01:06:36,079 --> 01:06:38,400
as it will change the interarrival time

1744
01:06:38,400 --> 01:06:40,799
between the consecutive can ids so that

1745
01:06:40,799 --> 01:06:42,400
means we can use these properties to

1746
01:06:42,400 --> 01:06:45,359
identify the this attacks

1747
01:06:45,359 --> 01:06:47,680
now let me explain you the methodology

1748
01:06:47,680 --> 01:06:50,799
of our model can sent id can cid

1749
01:06:50,799 --> 01:06:53,200
prediction task we inspired from our one

1750
01:06:53,200 --> 01:06:56,079
of our previous uh work which is the

1751
01:06:56,079 --> 01:06:59,200
engram based model where we use the set

1752
01:06:59,200 --> 01:07:02,880
of pass can id to predict the future can

1753
01:07:02,880 --> 01:07:04,799
id this is something like

1754
01:07:04,799 --> 01:07:07,119
next to a prediction in a language you

1755
01:07:07,119 --> 01:07:08,960
know that in your mobile phone when you

1756
01:07:08,960 --> 01:07:10,720
are typing something it will suggest you

1757
01:07:10,720 --> 01:07:12,000
the next word

1758
01:07:12,000 --> 01:07:14,240
this the same logic can be applied into

1759
01:07:14,240 --> 01:07:16,000
the can data as well because of the

1760
01:07:16,000 --> 01:07:19,280
sequential behavior uh but one of the

1761
01:07:19,280 --> 01:07:21,520
problem with this engram model was

1762
01:07:21,520 --> 01:07:24,160
engrams are highly inefficient when any

1763
01:07:24,160 --> 01:07:26,079
increases so

1764
01:07:26,079 --> 01:07:27,920
since modern vehicles includes around

1765
01:07:27,920 --> 01:07:28,960
100

1766
01:07:28,960 --> 01:07:32,319
ecu's we need to consider more context

1767
01:07:32,319 --> 01:07:34,640
to predict the next id that means for

1768
01:07:34,640 --> 01:07:36,640
modern vehicles this model is no longer

1769
01:07:36,640 --> 01:07:37,599
valid

1770
01:07:37,599 --> 01:07:40,400
so and also there's another inspiration

1771
01:07:40,400 --> 01:07:42,160
for our model which is the continuous

1772
01:07:42,160 --> 01:07:43,760
bag of word model architecture

1773
01:07:43,760 --> 01:07:46,559
introduced by google in 2013

1774
01:07:46,559 --> 01:07:48,400
in here what happens is they use the

1775
01:07:48,400 --> 01:07:50,400
context from the both side of the word

1776
01:07:50,400 --> 01:07:52,960
to predict the center word

1777
01:07:52,960 --> 01:07:53,680
but

1778
01:07:53,680 --> 01:07:55,920
the intention of this continuous back of

1779
01:07:55,920 --> 01:07:58,480
model architectures in google it's not

1780
01:07:58,480 --> 01:08:00,400
to predict the center word

1781
01:08:00,400 --> 01:08:02,960
but to learn the word vectors

1782
01:08:02,960 --> 01:08:05,520
which represent the semantic meaning of

1783
01:08:05,520 --> 01:08:08,160
this relationship of these words

1784
01:08:08,160 --> 01:08:10,640
so let me explain you how we can apply

1785
01:08:10,640 --> 01:08:12,640
this concept into our domain vehicle

1786
01:08:12,640 --> 01:08:15,599
domain think about uh right hand turn at

1787
01:08:15,599 --> 01:08:17,359
an intersection of a vehicle the

1788
01:08:17,359 --> 01:08:20,560
possible event ah x1 activate signal

1789
01:08:20,560 --> 01:08:22,399
light and then you deaccelerate to a

1790
01:08:22,399 --> 01:08:24,479
vehicle but what we want to predict is

1791
01:08:24,479 --> 01:08:26,479
the next movement that is a stop in this

1792
01:08:26,479 --> 01:08:28,238
case uh

1793
01:08:28,238 --> 01:08:30,640
think about the second case x2 we give

1794
01:08:30,640 --> 01:08:32,719
the context from the both side that

1795
01:08:32,719 --> 01:08:35,600
means activate signal light decelerate

1796
01:08:35,600 --> 01:08:38,560
then what we wanted to predict and next

1797
01:08:38,560 --> 01:08:40,960
context is accelerate turn right now you

1798
01:08:40,960 --> 01:08:42,080
can see that

1799
01:08:42,080 --> 01:08:44,238
when you consider the both cases

1800
01:08:44,238 --> 01:08:46,158
in the first case

1801
01:08:46,158 --> 01:08:47,839
accelerate would be another option for

1802
01:08:47,839 --> 01:08:49,679
the third word third

1803
01:08:49,679 --> 01:08:51,920
event but given the accelerate as

1804
01:08:51,920 --> 01:08:54,560
another context in the second situation

1805
01:08:54,560 --> 01:08:56,560
we can predict it as

1806
01:08:56,560 --> 01:08:59,198
stop be more with more confident so that

1807
01:08:59,198 --> 01:09:00,560
means we can

1808
01:09:00,560 --> 01:09:02,479
easily use this concept into the vehicle

1809
01:09:02,479 --> 01:09:05,198
network one of possible limitation would

1810
01:09:05,198 --> 01:09:08,399
be we have to wait until some message

1811
01:09:08,399 --> 01:09:11,120
appear to know whether that id is

1812
01:09:11,120 --> 01:09:13,359
anomalous or not but considering the can

1813
01:09:13,359 --> 01:09:14,399
id

1814
01:09:14,399 --> 01:09:16,319
message transmission rate that means for

1815
01:09:16,319 --> 01:09:19,920
one second is 2500 message around 2500

1816
01:09:19,920 --> 01:09:22,799
message is a very tiny time period and

1817
01:09:22,799 --> 01:09:24,719
also security researchers have shown

1818
01:09:24,719 --> 01:09:25,439
that

1819
01:09:25,439 --> 01:09:27,679
it requires attacker to continuously

1820
01:09:27,679 --> 01:09:29,920
inject a message to override the

1821
01:09:29,920 --> 01:09:31,759
legitimate message that means even

1822
01:09:31,759 --> 01:09:33,679
before the attack still we can use this

1823
01:09:33,679 --> 01:09:37,359
model to identify different attacks

1824
01:09:37,439 --> 01:09:39,198
now let me explain the model

1825
01:09:39,198 --> 01:09:40,640
architecture

1826
01:09:40,640 --> 01:09:43,679
we have the can data streams

1827
01:09:43,679 --> 01:09:44,960
we take a

1828
01:09:44,960 --> 01:09:47,759
window of time tree time t and within

1829
01:09:47,759 --> 01:09:51,198
that time vt window we take a slide

1830
01:09:51,198 --> 01:09:54,480
another sliding window of size n

1831
01:09:54,480 --> 01:09:57,120
we input this into our model the input

1832
01:09:57,120 --> 01:09:59,280
is the context from the both side of a

1833
01:09:59,280 --> 01:10:01,280
word or id

1834
01:10:01,280 --> 01:10:02,640
what we wanted to predict with the

1835
01:10:02,640 --> 01:10:04,159
center id

1836
01:10:04,159 --> 01:10:05,199
so

1837
01:10:05,199 --> 01:10:07,040
according to the bag of word condition

1838
01:10:07,040 --> 01:10:08,800
background architecture this learns the

1839
01:10:08,800 --> 01:10:11,040
word embedding when you feed the normal

1840
01:10:11,040 --> 01:10:11,920
data

1841
01:10:11,920 --> 01:10:14,239
and this learns the vectors for the very

1842
01:10:14,239 --> 01:10:16,000
vectors and then we will send this into

1843
01:10:16,000 --> 01:10:18,480
the grou get a recurrent network unit

1844
01:10:18,480 --> 01:10:20,000
the reason is

1845
01:10:20,000 --> 01:10:21,600
one of the limitation of the containers

1846
01:10:21,600 --> 01:10:24,640
back of model architecture is it doesn't

1847
01:10:24,640 --> 01:10:27,040
consider the order of the words but when

1848
01:10:27,040 --> 01:10:29,600
it comes to the scan data oda is highly

1849
01:10:29,600 --> 01:10:30,480
important

1850
01:10:30,480 --> 01:10:32,159
to learn that

1851
01:10:32,159 --> 01:10:34,640
temporal behavior we use the get a

1852
01:10:34,640 --> 01:10:36,480
recurrent network unit this is a more

1853
01:10:36,480 --> 01:10:39,600
efficient version of the lstm network

1854
01:10:39,600 --> 01:10:42,000
next we use the dropout layer to make

1855
01:10:42,000 --> 01:10:43,440
the model

1856
01:10:43,440 --> 01:10:45,760
regularized and the final output is a

1857
01:10:45,760 --> 01:10:47,600
dense layer which is a softmax

1858
01:10:47,600 --> 01:10:50,159
probability which is equivalent to the

1859
01:10:50,159 --> 01:10:51,840
total number of ids

1860
01:10:51,840 --> 01:10:54,719
so then after we train the model it will

1861
01:10:54,719 --> 01:10:57,840
learn the w1w and w3 through the back

1862
01:10:57,840 --> 01:11:00,400
propagation during the training process

1863
01:11:00,400 --> 01:11:03,360
and then we will use another benign data

1864
01:11:03,360 --> 01:11:06,080
set to identify the to calculate the

1865
01:11:06,080 --> 01:11:08,719
thresholds we use only the b9 data to

1866
01:11:08,719 --> 01:11:10,080
train our algorithm one of the

1867
01:11:10,080 --> 01:11:13,199
limitations as we seen is to

1868
01:11:13,199 --> 01:11:15,679
not available of the attack data but in

1869
01:11:15,679 --> 01:11:18,159
here we only use the b9 data and we what

1870
01:11:18,159 --> 01:11:21,040
we do is we define what is normal

1871
01:11:21,040 --> 01:11:22,560
out of the normal we consider it as

1872
01:11:22,560 --> 01:11:23,679
anomalous

1873
01:11:23,679 --> 01:11:26,800
in in here we use the separate b9 data

1874
01:11:26,800 --> 01:11:29,760
sets and we calculate the minimum

1875
01:11:29,760 --> 01:11:32,159
softmax probability which you observe

1876
01:11:32,159 --> 01:11:34,080
during the normal driving behavior and

1877
01:11:34,080 --> 01:11:35,520
anything below this threshold we

1878
01:11:35,520 --> 01:11:37,600
consider as a weak anomaly in here you

1879
01:11:37,600 --> 01:11:40,560
can see that the abc if we can consider

1880
01:11:40,560 --> 01:11:42,320
as the weekly anomaly at the same time

1881
01:11:42,320 --> 01:11:44,880
we use a time based model as well we you

1882
01:11:44,880 --> 01:11:47,280
know we throughout the analysis we

1883
01:11:47,280 --> 01:11:48,880
noticed that

1884
01:11:48,880 --> 01:11:50,880
since because of the message injection

1885
01:11:50,880 --> 01:11:52,640
it reduced the inter-arrival time

1886
01:11:52,640 --> 01:11:56,560
between the malicious ids so we use we

1887
01:11:56,560 --> 01:11:57,679
learn that

1888
01:11:57,679 --> 01:11:59,760
minimum and maximum range for enter

1889
01:11:59,760 --> 01:12:02,560
arrival time for each and every id and

1890
01:12:02,560 --> 01:12:04,880
we will monitor this time as well to

1891
01:12:04,880 --> 01:12:07,199
identify the weak anomalies then we

1892
01:12:07,199 --> 01:12:09,679
combine these two predictions into

1893
01:12:09,679 --> 01:12:13,040
ensembl model using a operator and then

1894
01:12:13,040 --> 01:12:15,280
we use the anomaly threshold

1895
01:12:15,280 --> 01:12:17,199
which we can define

1896
01:12:17,199 --> 01:12:19,520
if we if our

1897
01:12:19,520 --> 01:12:22,800
window contains hardware messages if 506

1898
01:12:22,800 --> 01:12:25,120
message is malicious weekly and normally

1899
01:12:25,120 --> 01:12:26,560
we can consider that's windows and

1900
01:12:26,560 --> 01:12:29,280
normally or rather mini then we update

1901
01:12:29,280 --> 01:12:30,320
the

1902
01:12:30,320 --> 01:12:33,120
t window and we continuously do this

1903
01:12:33,120 --> 01:12:36,120
process

1904
01:12:36,239 --> 01:12:38,320
to evaluate our model as

1905
01:12:38,320 --> 01:12:41,040
i discussed earlier i we use the

1906
01:12:41,040 --> 01:12:42,640
road data set which is kind of a more

1907
01:12:42,640 --> 01:12:44,000
sophisticated

1908
01:12:44,000 --> 01:12:46,480
realistic data set and also to evaluate

1909
01:12:46,480 --> 01:12:47,280
the

1910
01:12:47,280 --> 01:12:49,360
generalization capability of algorithm

1911
01:12:49,360 --> 01:12:51,280
we use two more data set car hacking

1912
01:12:51,280 --> 01:12:53,120
data set for intrusion detection system

1913
01:12:53,120 --> 01:12:55,600
and survival analysis uh data set for

1914
01:12:55,600 --> 01:12:58,719
automobile ids and when it comes to road

1915
01:12:58,719 --> 01:13:00,880
data set it has five types of attack

1916
01:13:00,880 --> 01:13:02,800
fusing attack where they injected random

1917
01:13:02,800 --> 01:13:05,040
ids and arbitrary payload

1918
01:13:05,040 --> 01:13:06,560
they experience wide variety of

1919
01:13:06,560 --> 01:13:08,800
unexpected behaviors in the vehicle the

1920
01:13:08,800 --> 01:13:11,040
second one is correlator signal attack

1921
01:13:11,040 --> 01:13:13,679
where the injectors fall for false

1922
01:13:13,679 --> 01:13:15,920
inject false wheel speed values where

1923
01:13:15,920 --> 01:13:18,480
the experience stop the car due to the

1924
01:13:18,480 --> 01:13:20,719
different pairwise wheel speed next max

1925
01:13:20,719 --> 01:13:22,800
speedometer value change the byte of

1926
01:13:22,800 --> 01:13:24,800
payload to maximum value and they

1927
01:13:24,800 --> 01:13:27,280
experience display force for speedometer

1928
01:13:27,280 --> 01:13:29,280
values and there are two slightly

1929
01:13:29,280 --> 01:13:30,719
similar attacks reverse light tone

1930
01:13:30,719 --> 01:13:33,920
attack and reverse light of attack

1931
01:13:33,920 --> 01:13:35,520
as a result of the attack reverse light

1932
01:13:35,520 --> 01:13:37,440
do not reflect what the other car is

1933
01:13:37,440 --> 01:13:40,800
using uh for out apart from the fusing

1934
01:13:40,800 --> 01:13:42,960
attack all for all type of four other

1935
01:13:42,960 --> 01:13:44,640
attacks they have a more sophisticated

1936
01:13:44,640 --> 01:13:48,800
muscular data cache attacks as well

1937
01:13:49,760 --> 01:13:51,440
first we want to identify the effect of

1938
01:13:51,440 --> 01:13:54,080
the context to this model so we build

1939
01:13:54,080 --> 01:13:56,719
another model which we call as can nid

1940
01:13:56,719 --> 01:13:59,199
that that means a can next id prediction

1941
01:13:59,199 --> 01:14:00,880
the only difference with our original

1942
01:14:00,880 --> 01:14:03,040
model is for this model we gave the

1943
01:14:03,040 --> 01:14:05,040
context from the one side of the

1944
01:14:05,040 --> 01:14:06,400
can sequences

1945
01:14:06,400 --> 01:14:08,640
then you can see in the orange color the

1946
01:14:08,640 --> 01:14:10,800
uh you can see the accuracy of the can

1947
01:14:10,800 --> 01:14:12,640
in idea model which we could achieve

1948
01:14:12,640 --> 01:14:15,199
maximum 60 accuracy to predict the next

1949
01:14:15,199 --> 01:14:18,159
side in a b9 data set but using our can

1950
01:14:18,159 --> 01:14:20,159
ci decent id prediction we could achieve

1951
01:14:20,159 --> 01:14:22,320
80 percent of accuracy using the for the

1952
01:14:22,320 --> 01:14:24,640
b9 data sets and also we did the

1953
01:14:24,640 --> 01:14:27,120
experiment with different word embedding

1954
01:14:27,120 --> 01:14:29,920
size and after 50 we could see that

1955
01:14:29,920 --> 01:14:31,920
accuracy improvement after 50 we

1956
01:14:31,920 --> 01:14:33,920
couldn't see any significant improvement

1957
01:14:33,920 --> 01:14:35,360
so we keep the

1958
01:14:35,360 --> 01:14:36,800
50s

1959
01:14:36,800 --> 01:14:42,159
our debian size to model light weight

1960
01:14:42,159 --> 01:14:43,840
uh here you can see that the performance

1961
01:14:43,840 --> 01:14:46,560
comparison for the road data set

1962
01:14:46,560 --> 01:14:47,920
we could achieve hundred percent for a

1963
01:14:47,920 --> 01:14:50,080
fascinating attack and also we used two

1964
01:14:50,080 --> 01:14:52,080
baseline models to compare our model

1965
01:14:52,080 --> 01:14:53,280
which is the

1966
01:14:53,280 --> 01:14:55,120
engram model which i discussed earlier

1967
01:14:55,120 --> 01:14:56,880
and a transition matrix based model

1968
01:14:56,880 --> 01:14:59,280
which is more similar to two grams based

1969
01:14:59,280 --> 01:15:01,760
model and also the canon idea our other

1970
01:15:01,760 --> 01:15:03,840
variant of the model and

1971
01:15:03,840 --> 01:15:06,560
we outperform all of these models and

1972
01:15:06,560 --> 01:15:09,679
also achieved around 100 accuracy except

1973
01:15:09,679 --> 01:15:11,199
one case for the correlated signal you

1974
01:15:11,199 --> 01:15:13,840
say 91 percent and for the mystery data

1975
01:15:13,840 --> 01:15:15,440
question that means the more

1976
01:15:15,440 --> 01:15:17,040
sophisticated type of attack which is

1977
01:15:17,040 --> 01:15:19,280
harder to detect we achieve also eighty

1978
01:15:19,280 --> 01:15:20,719
nine percent hundred percent ninety nine

1979
01:15:20,719 --> 01:15:23,679
percent and hundred percent accuracy

1980
01:15:23,679 --> 01:15:25,360
and this is the comparison between the

1981
01:15:25,360 --> 01:15:28,080
time based model and the gre based model

1982
01:15:28,080 --> 01:15:30,640
as you can see the gre model

1983
01:15:30,640 --> 01:15:32,960
outperformed the time based model for

1984
01:15:32,960 --> 01:15:34,880
most of the attack only two occasion

1985
01:15:34,880 --> 01:15:36,560
time based model output from the gre

1986
01:15:36,560 --> 01:15:38,159
based model but when it comes to the

1987
01:15:38,159 --> 01:15:39,280
masculine

1988
01:15:39,280 --> 01:15:41,120
mesquite attack

1989
01:15:41,120 --> 01:15:43,040
a time based model almost failed to

1990
01:15:43,040 --> 01:15:44,800
detect any type of the attack that's

1991
01:15:44,800 --> 01:15:46,800
because it doesn't change the

1992
01:15:46,800 --> 01:15:48,800
inter-arrival time between the

1993
01:15:48,800 --> 01:15:51,040
messages

1994
01:15:51,040 --> 01:15:53,360
so this is the result for the hcrl data

1995
01:15:53,360 --> 01:15:54,159
set

1996
01:15:54,159 --> 01:15:55,280
uh

1997
01:15:55,280 --> 01:15:57,679
it's a two data set htr real

1998
01:15:57,679 --> 01:15:59,679
hacking data set and htrl survival

1999
01:15:59,679 --> 01:16:02,320
analysis dataset still we outperform the

2000
01:16:02,320 --> 01:16:05,520
old other four tree model with 99

2001
01:16:05,520 --> 01:16:06,880
hundred percent and ninety nine percent

2002
01:16:06,880 --> 01:16:09,520
accuracy for hcr lch data set and for

2003
01:16:09,520 --> 01:16:12,159
the crl's sa data set it's hundred

2004
01:16:12,159 --> 01:16:13,760
percent hundred percent and ninety nine

2005
01:16:13,760 --> 01:16:15,520
a ninety six percent accurate accurate

2006
01:16:15,520 --> 01:16:16,880
accuracy meaning they fund scores in

2007
01:16:16,880 --> 01:16:19,760
this case actually

2008
01:16:19,760 --> 01:16:22,239
next uh we did the comparison for the

2009
01:16:22,239 --> 01:16:25,280
average uh detection latency which is

2010
01:16:25,280 --> 01:16:27,600
another critical important factor for

2011
01:16:27,600 --> 01:16:29,840
this domain

2012
01:16:29,840 --> 01:16:32,800
simply in our model outperform all three

2013
01:16:32,800 --> 01:16:34,880
other model as i explained earlier and

2014
01:16:34,880 --> 01:16:37,840
as we expected that gram took 452

2015
01:16:37,840 --> 01:16:39,440
milliseconds

2016
01:16:39,440 --> 01:16:41,760
to give the prediction for a 100

2017
01:16:41,760 --> 01:16:43,360
millisecond window

2018
01:16:43,360 --> 01:16:46,159
but our model can cid just took 10

2019
01:16:46,159 --> 01:16:49,040
millisecond to give the prediction for a

2020
01:16:49,040 --> 01:16:51,199
100 millisecond window 100 millisecond

2021
01:16:51,199 --> 01:16:52,320
window

2022
01:16:52,320 --> 01:16:53,440
equally

2023
01:16:53,440 --> 01:16:55,760
it was around 250 can messages that

2024
01:16:55,760 --> 01:16:57,199
means our model

2025
01:16:57,199 --> 01:17:00,000
capable of processing 250 message within

2026
01:17:00,000 --> 01:17:02,800
10 millisecond which is ideal for this

2027
01:17:02,800 --> 01:17:05,280
conventional constraint environment

2028
01:17:05,280 --> 01:17:07,520
next uh

2029
01:17:07,520 --> 01:17:09,520
conclusion and future works

2030
01:17:09,520 --> 01:17:12,480
uh and our ensemble based model improve

2031
01:17:12,480 --> 01:17:14,560
the accuracy of the

2032
01:17:14,560 --> 01:17:16,320
overall accuracy of the individual

2033
01:17:16,320 --> 01:17:18,239
models of the gru base model and the

2034
01:17:18,239 --> 01:17:20,880
time based model and also this shows

2035
01:17:20,880 --> 01:17:21,600
that

2036
01:17:21,600 --> 01:17:24,800
can ids require an ensemble model

2037
01:17:24,800 --> 01:17:28,560
with optimized model for each specific

2038
01:17:28,560 --> 01:17:31,520
fields of the can id can id frame to

2039
01:17:31,520 --> 01:17:33,760
identify the wide variety of

2040
01:17:33,760 --> 01:17:34,880
attack

2041
01:17:34,880 --> 01:17:36,800
as our future works we are working on

2042
01:17:36,800 --> 01:17:38,719
the can payload base model

2043
01:17:38,719 --> 01:17:41,600
to detect more advanced type of attack

2044
01:17:41,600 --> 01:17:44,320
in case if the attack does not change

2045
01:17:44,320 --> 01:17:46,000
any

2046
01:17:46,000 --> 01:17:48,159
any sequence or a timing

2047
01:17:48,159 --> 01:17:50,640
which will be a very sophisticated type

2048
01:17:50,640 --> 01:17:53,040
of attack and also we are planning to

2049
01:17:53,040 --> 01:17:54,880
use the streaming learning one of the

2050
01:17:54,880 --> 01:17:56,840
major assumptions of our model

2051
01:17:56,840 --> 01:18:00,320
is it depends on the normal data so what

2052
01:18:00,320 --> 01:18:02,239
what should be the normal so the

2053
01:18:02,239 --> 01:18:04,800
solution would be what we thought was to

2054
01:18:04,800 --> 01:18:07,120
continuously train our algorithm with

2055
01:18:07,120 --> 01:18:09,360
the benign data set or rather using the

2056
01:18:09,360 --> 01:18:11,280
normal driving behavior we deploy a

2057
01:18:11,280 --> 01:18:14,400
vehicle in a real vehicle then it should

2058
01:18:14,400 --> 01:18:17,360
be able to continuously train to learn

2059
01:18:17,360 --> 01:18:20,000
the normal behavior and also we are

2060
01:18:20,000 --> 01:18:22,480
planning to deploy this our ideas into

2061
01:18:22,480 --> 01:18:24,159
the real vehicle we have our industry

2062
01:18:24,159 --> 01:18:26,239
partner which is called at horimamira in

2063
01:18:26,239 --> 01:18:28,560
uk they are industry partner they have

2064
01:18:28,560 --> 01:18:29,840
dedicated

2065
01:18:29,840 --> 01:18:31,040
resources

2066
01:18:31,040 --> 01:18:32,880
and expert knowledge

2067
01:18:32,880 --> 01:18:33,760
to

2068
01:18:33,760 --> 01:18:36,400
get a real vehicle and

2069
01:18:36,400 --> 01:18:37,920
deploy our model

2070
01:18:37,920 --> 01:18:39,440
and launch

2071
01:18:39,440 --> 01:18:42,400
realistic attack there are no any more

2072
01:18:42,400 --> 01:18:44,960
data sets or experiments have done

2073
01:18:44,960 --> 01:18:46,960
to this type of thing

2074
01:18:46,960 --> 01:18:48,960
to drive the vehicle in a real early

2075
01:18:48,960 --> 01:18:50,960
environment and do the attack so we are

2076
01:18:50,960 --> 01:18:52,080
planning to

2077
01:18:52,080 --> 01:18:54,239
deploy our goals with them and get their

2078
01:18:54,239 --> 01:18:58,559
support and to test those things as well

2079
01:18:59,280 --> 01:19:03,360
yeah thank you thanks very much

2080
01:19:05,040 --> 01:19:07,360
cool

2081
01:19:07,679 --> 01:19:09,280
feel free to ask any question you may

2082
01:19:09,280 --> 01:19:11,520
have indeed a very uh

2083
01:19:11,520 --> 01:19:12,960
very interesting technical talk

2084
01:19:12,960 --> 01:19:15,120
befitting of the the session in general

2085
01:19:15,120 --> 01:19:16,159
so

2086
01:19:16,159 --> 01:19:18,239
i'd also like to encourage people to ask

2087
01:19:18,239 --> 01:19:20,000
more general questions right now i don't

2088
01:19:20,000 --> 01:19:21,440
want to deprive somebody of the

2089
01:19:21,440 --> 01:19:24,159
opportunity to answer questions but this

2090
01:19:24,159 --> 01:19:26,159
is a good time to also as you ask a

2091
01:19:26,159 --> 01:19:27,679
question just state for whom the

2092
01:19:27,679 --> 01:19:28,880
question is

2093
01:19:28,880 --> 01:19:30,480
perhaps it's a broader question so we

2094
01:19:30,480 --> 01:19:31,440
have one

2095
01:19:31,440 --> 01:19:33,920
in the middle in the aisle there

2096
01:19:33,920 --> 01:19:37,840
the microphones coming to you

2097
01:19:40,880 --> 01:19:42,880
thank you i just wanted to ask a

2098
01:19:42,880 --> 01:19:44,960
question to the entire panel how much of

2099
01:19:44,960 --> 01:19:47,760
the data is generally unencrypted in

2100
01:19:47,760 --> 01:19:49,120
these

2101
01:19:49,120 --> 01:19:50,960
modeling sessions

2102
01:19:50,960 --> 01:19:53,120
or modeling exercises

2103
01:19:53,120 --> 01:19:55,120
well let's start with you i don't know

2104
01:19:55,120 --> 01:19:57,679
how much of the data is unencrypted

2105
01:19:57,679 --> 01:20:00,400
uh that's either processed or used for

2106
01:20:00,400 --> 01:20:02,960
training uh actually it depends uh these

2107
01:20:02,960 --> 01:20:04,960
are the benchmark data set which is

2108
01:20:04,960 --> 01:20:07,280
available in a publicly for

2109
01:20:07,280 --> 01:20:10,159
this data set actually for uh

2110
01:20:10,159 --> 01:20:11,920
as i remember it's

2111
01:20:11,920 --> 01:20:13,760
three billion of three billion rows of

2112
01:20:13,760 --> 01:20:14,880
red data

2113
01:20:14,880 --> 01:20:16,080
i used

2114
01:20:16,080 --> 01:20:18,400
and in a normal can bus system

2115
01:20:18,400 --> 01:20:20,639
the normal live traffic is unencrypted

2116
01:20:20,639 --> 01:20:22,800
unencrypted yeah okay

2117
01:20:22,800 --> 01:20:25,360
and uh if i can turn to uh

2118
01:20:25,360 --> 01:20:27,360
you of course looking at locked shields

2119
01:20:27,360 --> 01:20:28,639
you know much of the traffic will be

2120
01:20:28,639 --> 01:20:31,440
encrypted in various ways um

2121
01:20:31,440 --> 01:20:34,000
exactly yeah

2122
01:20:34,000 --> 01:20:35,840
some of the data

2123
01:20:35,840 --> 01:20:38,639
uh will be encrypted but uh generally we

2124
01:20:38,639 --> 01:20:40,560
can uh

2125
01:20:40,560 --> 01:20:44,080
we are gonna be able to uh use that data

2126
01:20:44,080 --> 01:20:45,920
and and presumably a lot a lot of what

2127
01:20:45,920 --> 01:20:48,080
you really want to train on is the the

2128
01:20:48,080 --> 01:20:51,040
unencrypted header and footer of uh

2129
01:20:51,040 --> 01:20:53,040
or trail of of the packet so it's not

2130
01:20:53,040 --> 01:20:55,120
necessarily the content but you know who

2131
01:20:55,120 --> 01:20:57,120
it's going from and to

2132
01:20:57,120 --> 01:20:59,040
bitters

2133
01:20:59,040 --> 01:21:00,400
yeah so

2134
01:21:00,400 --> 01:21:02,320
encryption is an interesting aspect

2135
01:21:02,320 --> 01:21:03,840
because uh

2136
01:21:03,840 --> 01:21:06,960
again in this uh wireless security uh

2137
01:21:06,960 --> 01:21:09,120
research uh like all the traffic is

2138
01:21:09,120 --> 01:21:11,199
encrypted and then uh

2139
01:21:11,199 --> 01:21:12,960
that's a big challenge for detecting

2140
01:21:12,960 --> 01:21:15,920
attacks because you know if you can't

2141
01:21:15,920 --> 01:21:17,679
listen to the actual content then you

2142
01:21:17,679 --> 01:21:19,120
can't detect them

2143
01:21:19,120 --> 01:21:20,639
from the sides

2144
01:21:20,639 --> 01:21:22,639
it's a challenge

2145
01:21:22,639 --> 01:21:24,080
very true

2146
01:21:24,080 --> 01:21:26,239
okay thank you

2147
01:21:26,239 --> 01:21:28,719
another question yes sorry

2148
01:21:28,719 --> 01:21:32,159
microphone coming to you as well

2149
01:21:34,880 --> 01:21:37,840
my question goes to all of you and it

2150
01:21:37,840 --> 01:21:41,440
addresses the uh complaints

2151
01:21:41,440 --> 01:21:43,360
about the lack of

2152
01:21:43,360 --> 01:21:46,400
supply chain security

2153
01:21:46,400 --> 01:21:49,600
european legislation

2154
01:21:49,600 --> 01:21:52,560
includes the cyber security act

2155
01:21:52,560 --> 01:21:54,840
cyber security act

2156
01:21:54,840 --> 01:21:56,480
addresses

2157
01:21:56,480 --> 01:21:58,560
certification schemes

2158
01:21:58,560 --> 01:22:02,159
for software for processes

2159
01:22:02,159 --> 01:22:05,120
and for services to which extent have

2160
01:22:05,120 --> 01:22:06,719
you embraced

2161
01:22:06,719 --> 01:22:07,520
this

2162
01:22:07,520 --> 01:22:10,400
idea of certification schemes

2163
01:22:10,400 --> 01:22:11,520
for

2164
01:22:11,520 --> 01:22:15,120
artificial intelligence artifacts

2165
01:22:15,120 --> 01:22:16,639
in terms of

2166
01:22:16,639 --> 01:22:19,760
securing them and

2167
01:22:20,080 --> 01:22:22,320
to give a better understanding

2168
01:22:22,320 --> 01:22:24,480
certification doesn't say

2169
01:22:24,480 --> 01:22:26,480
we guarantee that

2170
01:22:26,480 --> 01:22:27,840
that

2171
01:22:27,840 --> 01:22:31,199
we would be protected but it comes with

2172
01:22:31,199 --> 01:22:34,159
obligations of informing

2173
01:22:34,159 --> 01:22:36,960
about discovered vulnerabilities once

2174
01:22:36,960 --> 01:22:38,719
the thing is out

2175
01:22:38,719 --> 01:22:39,840
warning

2176
01:22:39,840 --> 01:22:43,600
and the obligation to update

2177
01:22:43,600 --> 01:22:44,719
and

2178
01:22:44,719 --> 01:22:46,480
while you maintain

2179
01:22:46,480 --> 01:22:49,520
business secrets that's also what you

2180
01:22:49,520 --> 01:22:51,199
addressed

2181
01:22:51,199 --> 01:22:52,560
explain

2182
01:22:52,560 --> 01:22:53,440
or

2183
01:22:53,440 --> 01:22:57,360
give warnings to the users sufficient

2184
01:22:57,360 --> 01:23:01,280
to ensure their level of security as

2185
01:23:01,280 --> 01:23:04,960
users or a subsequence in the supply

2186
01:23:04,960 --> 01:23:06,719
chain thank you

2187
01:23:06,719 --> 01:23:08,719
very nice question thanks uh very much

2188
01:23:08,719 --> 01:23:11,440
and in fact i'll ask peters uh

2189
01:23:11,440 --> 01:23:14,080
to maybe go first okay

2190
01:23:14,080 --> 01:23:15,440
so in my view

2191
01:23:15,440 --> 01:23:17,040
it would be very useful the

2192
01:23:17,040 --> 01:23:18,880
certification to essentially track

2193
01:23:18,880 --> 01:23:21,920
provenance of your parts of the systems

2194
01:23:21,920 --> 01:23:23,520
that you are using

2195
01:23:23,520 --> 01:23:25,600
and

2196
01:23:25,600 --> 01:23:26,880
again

2197
01:23:26,880 --> 01:23:27,600
like

2198
01:23:27,600 --> 01:23:29,440
legislation is probably the proper

2199
01:23:29,440 --> 01:23:32,560
solution to motivate organizations to do

2200
01:23:32,560 --> 01:23:35,600
it because otherwise it's treated as a

2201
01:23:35,600 --> 01:23:37,600
concern that

2202
01:23:37,600 --> 01:23:39,280
does not directly benefit the

2203
01:23:39,280 --> 01:23:42,719
organization and extra work so but if

2204
01:23:42,719 --> 01:23:45,040
it's required then it will be done

2205
01:23:45,040 --> 01:23:46,800
and

2206
01:23:46,800 --> 01:23:48,639
for machine learning uh

2207
01:23:48,639 --> 01:23:51,120
the current problem perhaps is that we

2208
01:23:51,120 --> 01:23:52,480
don't have this

2209
01:23:52,480 --> 01:23:55,120
infrastructure of vulnerability tracking

2210
01:23:55,120 --> 01:23:56,159
and

2211
01:23:56,159 --> 01:23:57,040
uh

2212
01:23:57,040 --> 01:23:58,239
you know

2213
01:23:58,239 --> 01:24:00,000
we don't have this like for software

2214
01:24:00,000 --> 01:24:01,520
vulnerabilities when library has

2215
01:24:01,520 --> 01:24:04,080
vulnerability all this notification of

2216
01:24:04,080 --> 01:24:06,880
all the downstream recipients but we

2217
01:24:06,880 --> 01:24:09,760
probably will have sometime soon and as

2218
01:24:09,760 --> 01:24:12,320
soon as we will have the first major

2219
01:24:12,320 --> 01:24:15,120
incident then this provenance will be

2220
01:24:15,120 --> 01:24:18,239
very important to actually track

2221
01:24:18,239 --> 01:24:20,320
all the different people who are using

2222
01:24:20,320 --> 01:24:23,040
this vulnerable model

2223
01:24:23,040 --> 01:24:27,120
any other comments from our panelists or

2224
01:24:27,280 --> 01:24:28,480
because otherwise i'll just add

2225
01:24:28,480 --> 01:24:30,480
something to the it's a very interesting

2226
01:24:30,480 --> 01:24:32,320
question and i think one of the things

2227
01:24:32,320 --> 01:24:34,480
that's sort of overlooked is unlike many

2228
01:24:34,480 --> 01:24:36,960
other previous endeavors in engineering

2229
01:24:36,960 --> 01:24:38,480
we're now at a point where we actually

2230
01:24:38,480 --> 01:24:41,600
are shipping self-modifying systems that

2231
01:24:41,600 --> 01:24:44,480
are continually adapting and this of

2232
01:24:44,480 --> 01:24:45,920
course fights against you know the

2233
01:24:45,920 --> 01:24:47,280
notion that the

2234
01:24:47,280 --> 01:24:49,040
the original manufacturer should have

2235
01:24:49,040 --> 01:24:51,360
any uh insight or control over the

2236
01:24:51,360 --> 01:24:53,840
potential behavior in the field

2237
01:24:53,840 --> 01:24:54,960
and i think there's an additional

2238
01:24:54,960 --> 01:24:57,040
question that maybe ties into some but

2239
01:24:57,040 --> 01:24:58,560
and that is whether we're devoting

2240
01:24:58,560 --> 01:25:00,719
enough additional computing power and

2241
01:25:00,719 --> 01:25:04,000
resources after the fact uh you you said

2242
01:25:04,000 --> 01:25:05,600
already that there's a

2243
01:25:05,600 --> 01:25:07,520
computationally constrained environment

2244
01:25:07,520 --> 01:25:09,360
yeah do you find that there's enough

2245
01:25:09,360 --> 01:25:11,600
extra computing power

2246
01:25:11,600 --> 01:25:14,320
to to solve security problems or is

2247
01:25:14,320 --> 01:25:16,320
everyone being too cheap yeah when it

2248
01:25:16,320 --> 01:25:19,120
comes to the vehicles actually uh the

2249
01:25:19,120 --> 01:25:21,199
when it comes to edge computing that's a

2250
01:25:21,199 --> 01:25:23,760
main issue we have the limited num

2251
01:25:23,760 --> 01:25:25,199
limited resource

2252
01:25:25,199 --> 01:25:27,360
the solution would be actually we can

2253
01:25:27,360 --> 01:25:29,760
deploy our algorithm in a cloud

2254
01:25:29,760 --> 01:25:32,400
again we will have then security issues

2255
01:25:32,400 --> 01:25:34,000
uh as a solution we can use the

2256
01:25:34,000 --> 01:25:36,080
federated learning to address this issue

2257
01:25:36,080 --> 01:25:38,239
or we can use the edge computing or tiny

2258
01:25:38,239 --> 01:25:41,199
ml techniques to handle that tissue

2259
01:25:41,199 --> 01:25:42,080
nice

2260
01:25:42,080 --> 01:25:44,000
i'm mindful that we've only touched on a

2261
01:25:44,000 --> 01:25:45,600
possible answer so we'll engage during

2262
01:25:45,600 --> 01:25:47,440
the coffee break i hope and

2263
01:25:47,440 --> 01:25:51,199
thomas behind you also

2264
01:25:51,600 --> 01:25:52,840
for another

2265
01:25:52,840 --> 01:25:55,440
question thank you

2266
01:25:55,440 --> 01:25:57,280
thanks everyone really enjoyed those

2267
01:25:57,280 --> 01:25:59,520
talks um we heard a lot about how

2268
01:25:59,520 --> 01:26:01,440
artificial intelligence were used for

2269
01:26:01,440 --> 01:26:03,520
cyber defense but wondering if you have

2270
01:26:03,520 --> 01:26:06,080
any comments on how ai machine learning

2271
01:26:06,080 --> 01:26:09,840
might be utilized by threat actors

2272
01:26:11,120 --> 01:26:13,280
okay

2273
01:26:13,280 --> 01:26:14,800
so

2274
01:26:14,800 --> 01:26:17,280
we are seeing some ex let's say

2275
01:26:17,280 --> 01:26:20,639
experimental applications of automated

2276
01:26:20,639 --> 01:26:23,120
attack generation and automated exploit

2277
01:26:23,120 --> 01:26:24,480
generation

2278
01:26:24,480 --> 01:26:25,920
essentially

2279
01:26:25,920 --> 01:26:29,760
machine learning guided fuzzing so

2280
01:26:29,760 --> 01:26:32,080
my in my talk i mentioned that is a

2281
01:26:32,080 --> 01:26:34,639
great potential use for any vendors in

2282
01:26:34,639 --> 01:26:37,440
quality assurance but of course the same

2283
01:26:37,440 --> 01:26:40,000
techniques can be used by potential

2284
01:26:40,000 --> 01:26:41,679
attackers to

2285
01:26:41,679 --> 01:26:42,800
to find

2286
01:26:42,800 --> 01:26:44,960
new new vulnerabilities in other

2287
01:26:44,960 --> 01:26:47,679
people's software and devices

2288
01:26:47,679 --> 01:26:49,040
to to that i would add you know if

2289
01:26:49,040 --> 01:26:51,280
you're familiar with genetic programming

2290
01:26:51,280 --> 01:26:52,960
it's more or less a forgotten subfield

2291
01:26:52,960 --> 01:26:54,880
of artificial intelligence but there's a

2292
01:26:54,880 --> 01:26:57,600
tremendous toolbox of of abilities to

2293
01:26:57,600 --> 01:27:01,120
hybridize uh existing malware and of

2294
01:27:01,120 --> 01:27:02,800
course try them out in a sandbox in an

2295
01:27:02,800 --> 01:27:04,800
evolutionary fashion ever i don't know

2296
01:27:04,800 --> 01:27:06,639
if you have something to to add to to

2297
01:27:06,639 --> 01:27:08,320
that this uh

2298
01:27:08,320 --> 01:27:09,760
because you do see a lot of traffic in

2299
01:27:09,760 --> 01:27:12,480
what you do yes of course uh

2300
01:27:12,480 --> 01:27:15,199
uh of course we the defending part is

2301
01:27:15,199 --> 01:27:17,440
important but of course the attack part

2302
01:27:17,440 --> 01:27:19,840
and the offensive part of using a

2303
01:27:19,840 --> 01:27:21,679
artificial intelligence

2304
01:27:21,679 --> 01:27:22,400
at

2305
01:27:22,400 --> 01:27:25,520
offensive side is also important

2306
01:27:25,520 --> 01:27:28,000
we we we are working on general

2307
01:27:28,000 --> 01:27:29,199
basically

2308
01:27:29,199 --> 01:27:31,679
on the defensive side side

2309
01:27:31,679 --> 01:27:32,639
but

2310
01:27:32,639 --> 01:27:34,159
we know how to

2311
01:27:34,159 --> 01:27:36,719
attack and we know how to red team you

2312
01:27:36,719 --> 01:27:38,080
know behaviors

2313
01:27:38,080 --> 01:27:40,560
so those behaviors can be easily

2314
01:27:40,560 --> 01:27:43,040
adapted to a in artificial intelligence

2315
01:27:43,040 --> 01:27:43,920
based

2316
01:27:43,920 --> 01:27:45,600
systems so

2317
01:27:45,600 --> 01:27:48,159
those can be used for a taxi

2318
01:27:48,159 --> 01:27:50,239
very nice question and answers i think

2319
01:27:50,239 --> 01:27:52,080
we are running down the clock so we have

2320
01:27:52,080 --> 01:27:53,760
time for another short question sorry

2321
01:27:53,760 --> 01:27:55,040
neil i'll

2322
01:27:55,040 --> 01:27:56,560
ask you

2323
01:27:56,560 --> 01:27:59,360
don't speak too fast but

2324
01:27:59,360 --> 01:28:02,799
sorry there's a microphone coming to you

2325
01:28:04,159 --> 01:28:06,239
good talks guys thank you very much uh

2326
01:28:06,239 --> 01:28:08,000
neil from canada i have a question

2327
01:28:08,000 --> 01:28:09,440
related to

2328
01:28:09,440 --> 01:28:11,679
kind of tying all of yours together

2329
01:28:11,679 --> 01:28:13,840
first one was really about uh you know

2330
01:28:13,840 --> 01:28:15,679
lock shields data let's call that really

2331
01:28:15,679 --> 01:28:18,000
high amount of unique data which you

2332
01:28:18,000 --> 01:28:19,679
would not normally see

2333
01:28:19,679 --> 01:28:21,679
in a really tight cluster

2334
01:28:21,679 --> 01:28:23,040
and then the second is all commercial

2335
01:28:23,040 --> 01:28:26,400
data which is again a really mishmash of

2336
01:28:26,400 --> 01:28:29,360
mixed behaviors that if we try and use

2337
01:28:29,360 --> 01:28:30,960
that to normalize it really makes it

2338
01:28:30,960 --> 01:28:32,239
really messy

2339
01:28:32,239 --> 01:28:34,800
the third again vehicle behaviors very

2340
01:28:34,800 --> 01:28:36,880
messy right so if we're using that to

2341
01:28:36,880 --> 01:28:39,120
normalize the data and help commercial

2342
01:28:39,120 --> 01:28:41,360
commercially built systems for example

2343
01:28:41,360 --> 01:28:44,159
technological systems to unique home

2344
01:28:44,159 --> 01:28:45,760
automation systems to automobile

2345
01:28:45,760 --> 01:28:48,639
manufacturers try and create some normal

2346
01:28:48,639 --> 01:28:50,960
tools to secure these things capacities

2347
01:28:50,960 --> 01:28:52,239
to secure these things how do we

2348
01:28:52,239 --> 01:28:53,840
convince them to do this when at the end

2349
01:28:53,840 --> 01:28:56,239
of the day it's us commercial buyers who

2350
01:28:56,239 --> 01:28:58,159
want the cheapest the fastest result on

2351
01:28:58,159 --> 01:28:59,679
the product on the market as quickly as

2352
01:28:59,679 --> 01:29:01,199
we can

2353
01:29:01,199 --> 01:29:02,159
really

2354
01:29:02,159 --> 01:29:03,920
how do you propose that this would be

2355
01:29:03,920 --> 01:29:06,080
useful to those companies

2356
01:29:06,080 --> 01:29:08,000
that create the product so that we can

2357
01:29:08,000 --> 01:29:10,239
get a secure product

2358
01:29:10,239 --> 01:29:11,520
i don't think that question is clear

2359
01:29:11,520 --> 01:29:13,520
enough it's a fantastic question it's a

2360
01:29:13,520 --> 01:29:15,360
very deep question and the clock has

2361
01:29:15,360 --> 01:29:16,800
just run down

2362
01:29:16,800 --> 01:29:18,480
so we

2363
01:29:18,480 --> 01:29:20,560
it's very carefully posed and i think

2364
01:29:20,560 --> 01:29:22,880
it's very good coffee material is there

2365
01:29:22,880 --> 01:29:24,880
anyone who wants to give a short answer

2366
01:29:24,880 --> 01:29:26,480
otherwise um

2367
01:29:26,480 --> 01:29:28,320
we will leave this for for an ongoing

2368
01:29:28,320 --> 01:29:30,880
discussion i can yeah so

2369
01:29:30,880 --> 01:29:32,960
from my my point of view this will

2370
01:29:32,960 --> 01:29:35,840
happen only if companies are forced to

2371
01:29:35,840 --> 01:29:39,840
so regulation or liability like market

2372
01:29:39,840 --> 01:29:42,159
forces will force them to take its

2373
01:29:42,159 --> 01:29:44,480
security seriously if they are liable

2374
01:29:44,480 --> 01:29:47,599
for the consequences

2375
01:29:48,480 --> 01:29:49,520
very good

2376
01:29:49,520 --> 01:29:51,440
on that note we're going to close things

2377
01:29:51,440 --> 01:29:53,199
off i realize that we're the people that

2378
01:29:53,199 --> 01:29:54,960
stand between you and coffee and other

2379
01:29:54,960 --> 01:29:57,040
treats before you run out of the room

2380
01:29:57,040 --> 01:29:59,679
i'm going to be handing the uh the gifts

2381
01:29:59,679 --> 01:30:02,320
and certainly thanks also from ccdcoe

2382
01:30:02,320 --> 01:30:04,800
and from cycon to these three excellent

2383
01:30:04,800 --> 01:30:06,560
speakers please applaud for them while i

2384
01:30:06,560 --> 01:30:09,450
hand these over

2385
01:30:09,450 --> 01:30:12,059
[Applause]

