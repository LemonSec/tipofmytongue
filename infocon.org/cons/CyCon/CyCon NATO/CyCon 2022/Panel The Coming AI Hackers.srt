1
00:00:00,960 --> 00:00:02,320
thank you so i think this is going to be

2
00:00:02,320 --> 00:00:05,200
the speculative part of the uh

3
00:00:05,200 --> 00:00:07,359
of the conference so i spent the

4
00:00:07,359 --> 00:00:10,080
pandemic writing a book which is due to

5
00:00:10,080 --> 00:00:13,360
the publisher in two and a half hours

6
00:00:13,360 --> 00:00:15,360
so luckily it's mostly done

7
00:00:15,360 --> 00:00:19,199
and i what i'm writing about is hacking

8
00:00:19,199 --> 00:00:21,840
extending the hacking metaphor toward

9
00:00:21,840 --> 00:00:24,560
social political economic systems and

10
00:00:24,560 --> 00:00:26,560
what that means and how to think about

11
00:00:26,560 --> 00:00:29,439
that and what i want to talk about now

12
00:00:29,439 --> 00:00:31,760
is the notion of ai hackers

13
00:00:31,760 --> 00:00:33,360
so i think ai

14
00:00:33,360 --> 00:00:36,719
is going to hack all sorts of

15
00:00:36,719 --> 00:00:39,280
social economic political systems and

16
00:00:39,280 --> 00:00:42,160
use and exploit them at

17
00:00:42,160 --> 00:00:44,079
an unprecedented rate and i think it's

18
00:00:44,079 --> 00:00:46,559
not just a difference in degree

19
00:00:46,559 --> 00:00:48,559
it's a difference in kind and will

20
00:00:48,559 --> 00:00:51,120
culminate in ai systems hacking other ai

21
00:00:51,120 --> 00:00:54,000
systems and we humans kind of being

22
00:00:54,000 --> 00:00:56,640
bystanders and collateral damage

23
00:00:56,640 --> 00:00:58,480
all right so maybe that's a bit of

24
00:00:58,480 --> 00:01:02,000
hyperbole but none of that requires any

25
00:01:02,000 --> 00:01:04,640
far future science fiction technology

26
00:01:04,640 --> 00:01:06,720
i'm not postulating a singularity i'm

27
00:01:06,720 --> 00:01:09,040
not assuming intelligent androids not

28
00:01:09,040 --> 00:01:10,720
even actually assuming evil intent on

29
00:01:10,720 --> 00:01:12,960
the part of anyone the hacks going to

30
00:01:12,960 --> 00:01:15,360
talk about don't even require major

31
00:01:15,360 --> 00:01:17,280
breakthroughs in ai they'll improve as

32
00:01:17,280 --> 00:01:20,640
a.i gets better but we can see

33
00:01:20,640 --> 00:01:22,479
hints of them today

34
00:01:22,479 --> 00:01:25,360
and these hacks will come naturally as

35
00:01:25,360 --> 00:01:27,680
ai's become more advanced at learning

36
00:01:27,680 --> 00:01:29,840
understanding and problem solving

37
00:01:29,840 --> 00:01:32,079
alright so first i want to generalize

38
00:01:32,079 --> 00:01:34,400
the term hacking

39
00:01:34,400 --> 00:01:36,320
think about the tax code it's not

40
00:01:36,320 --> 00:01:38,720
computer code but it's it's code it's a

41
00:01:38,720 --> 00:01:40,640
series of algorithms with inputs and

42
00:01:40,640 --> 00:01:42,000
outputs

43
00:01:42,000 --> 00:01:43,759
those are the tax rules

44
00:01:43,759 --> 00:01:46,320
it has vulnerabilities we call them tax

45
00:01:46,320 --> 00:01:47,439
loopholes

46
00:01:47,439 --> 00:01:49,759
it has exploits we call them tax

47
00:01:49,759 --> 00:01:52,079
avoidance strategies and there's a whole

48
00:01:52,079 --> 00:01:54,240
industry of black hat hackers whose job

49
00:01:54,240 --> 00:01:56,719
is to find exploits in the tax code we

50
00:01:56,719 --> 00:01:58,799
call them tax attorneys and tax

51
00:01:58,799 --> 00:02:00,479
accountants

52
00:02:00,479 --> 00:02:02,719
right so what is a hack here's my

53
00:02:02,719 --> 00:02:04,000
definition

54
00:02:04,000 --> 00:02:06,560
something that a system permits but is

55
00:02:06,560 --> 00:02:08,959
unanticipated and unintended by the

56
00:02:08,959 --> 00:02:10,318
designers

57
00:02:10,318 --> 00:02:12,080
or another definition

58
00:02:12,080 --> 00:02:15,040
a clever unintended exploitation of a

59
00:02:15,040 --> 00:02:17,840
system which one subverts the rules of

60
00:02:17,840 --> 00:02:20,400
the system to at the expense of some

61
00:02:20,400 --> 00:02:22,640
other part of the system

62
00:02:22,640 --> 00:02:24,560
it's a subjective term

63
00:02:24,560 --> 00:02:26,879
encompasses a notion of a novelty and

64
00:02:26,879 --> 00:02:28,080
cleverness

65
00:02:28,080 --> 00:02:30,959
it's a subversion an exploitation

66
00:02:30,959 --> 00:02:33,599
it's unintended and unanticipated

67
00:02:33,599 --> 00:02:36,480
hacks follow the rules of the system but

68
00:02:36,480 --> 00:02:39,920
subvert its goals or intent

69
00:02:39,920 --> 00:02:42,480
and i postulate that all systems of

70
00:02:42,480 --> 00:02:44,319
rules can be hacked

71
00:02:44,319 --> 00:02:46,160
you can find hacks in professional

72
00:02:46,160 --> 00:02:47,360
sports

73
00:02:47,360 --> 00:02:49,760
in airline frequent flyer programs

74
00:02:49,760 --> 00:02:52,080
financial systems politics

75
00:02:52,080 --> 00:02:54,400
lots of economic political and social

76
00:02:54,400 --> 00:02:56,879
systems against our cognitive functions

77
00:02:56,879 --> 00:02:59,040
right the talk we just heard

78
00:02:59,040 --> 00:03:02,159
a curved hockey stick is a hack

79
00:03:02,159 --> 00:03:03,760
and we know the name of the hacker who

80
00:03:03,760 --> 00:03:05,040
invented it

81
00:03:05,040 --> 00:03:07,280
mileage runs are a hack

82
00:03:07,280 --> 00:03:09,840
the filibuster was originally a hack

83
00:03:09,840 --> 00:03:12,239
back in roman times

84
00:03:12,239 --> 00:03:13,599
hedge funds

85
00:03:13,599 --> 00:03:17,359
private banking full of hacks

86
00:03:17,680 --> 00:03:20,319
but even the most best thought out

87
00:03:20,319 --> 00:03:23,440
systems of rules will be incomplete and

88
00:03:23,440 --> 00:03:26,319
inconsistent it'll have ambiguities

89
00:03:26,319 --> 00:03:28,080
that's why we have courts that's why we

90
00:03:28,080 --> 00:03:30,319
have attorneys

91
00:03:30,319 --> 00:03:31,599
and there'll be things the designers

92
00:03:31,599 --> 00:03:33,760
haven't thought of and as long as there

93
00:03:33,760 --> 00:03:35,599
are people who want to subvert the the

94
00:03:35,599 --> 00:03:39,360
goals of a system there will be hacks

95
00:03:39,360 --> 00:03:42,159
and ais are becoming hackers

96
00:03:42,159 --> 00:03:45,440
so in 2016 darpa held an ai capture the

97
00:03:45,440 --> 00:03:46,799
flag contest

98
00:03:46,799 --> 00:03:48,159
so if you go to hacker conferences you

99
00:03:48,159 --> 00:03:50,480
know this game

100
00:03:50,480 --> 00:03:51,680
basically

101
00:03:51,680 --> 00:03:54,400
teams compete on a simulated network

102
00:03:54,400 --> 00:03:56,400
defending their network hacking hacking

103
00:03:56,400 --> 00:03:58,720
others and and best wins

104
00:03:58,720 --> 00:04:00,799
at this darpa competition 2016 there

105
00:04:00,799 --> 00:04:03,680
were a hundred different ais competing

106
00:04:03,680 --> 00:04:06,560
seven finalists faced off at defcon for

107
00:04:06,560 --> 00:04:08,080
10 hours

108
00:04:08,080 --> 00:04:09,760
all the ais hacked each other they did

109
00:04:09,760 --> 00:04:11,200
it on stage it's actually pretty boring

110
00:04:11,200 --> 00:04:12,879
it was like six computers

111
00:04:12,879 --> 00:04:15,280
standing there for 10 hours it was an ai

112
00:04:15,280 --> 00:04:17,120
called mayhem that won and it's actually

113
00:04:17,120 --> 00:04:18,880
now a commercial product

114
00:04:18,880 --> 00:04:21,040
darpa never

115
00:04:21,040 --> 00:04:22,960
never did this event again but it's been

116
00:04:22,960 --> 00:04:25,600
happening every year in china since

117
00:04:25,600 --> 00:04:27,840
and we know very little about

118
00:04:27,840 --> 00:04:29,520
what's coming out of that

119
00:04:29,520 --> 00:04:31,680
ais are also finding vulnerabilities in

120
00:04:31,680 --> 00:04:33,199
computer code i mean they're not that

121
00:04:33,199 --> 00:04:34,400
good at it but they're going to get

122
00:04:34,400 --> 00:04:35,680
better

123
00:04:35,680 --> 00:04:37,199
and you know how this works with pretty

124
00:04:37,199 --> 00:04:39,600
much all ai systems they start out not

125
00:04:39,600 --> 00:04:41,040
very good and they get better and you

126
00:04:41,040 --> 00:04:43,280
know humans are here and eventually

127
00:04:43,280 --> 00:04:45,759
the ais pass

128
00:04:45,759 --> 00:04:47,600
but the implications go far beyond

129
00:04:47,600 --> 00:04:49,040
computer networks

130
00:04:49,040 --> 00:04:51,280
to vulnerabilities in the tax code

131
00:04:51,280 --> 00:04:53,440
vulnerabilities of financial regulations

132
00:04:53,440 --> 00:04:56,240
vulnerabilities in all sorts of systems

133
00:04:56,240 --> 00:04:58,080
and there are really two different

134
00:04:58,080 --> 00:05:00,240
issues here the first and you can

135
00:05:00,240 --> 00:05:02,479
imagine that an ai might be instructed

136
00:05:02,479 --> 00:05:04,560
to hack one of these systems

137
00:05:04,560 --> 00:05:06,880
you could uh imagine someone feeding an

138
00:05:06,880 --> 00:05:09,120
ai the world's tax codes or the world's

139
00:05:09,120 --> 00:05:11,280
financial regulations with the goal of

140
00:05:11,280 --> 00:05:14,960
it creating a bunch of profitable hacks

141
00:05:14,960 --> 00:05:16,960
the other issue is that an ai might

142
00:05:16,960 --> 00:05:19,840
naturally albeit inadvertently

143
00:05:19,840 --> 00:05:21,440
hack a system

144
00:05:21,440 --> 00:05:23,280
both are dangerous

145
00:05:23,280 --> 00:05:24,960
but the second is actually more

146
00:05:24,960 --> 00:05:26,639
dangerous because we might actually

147
00:05:26,639 --> 00:05:28,960
never know what happened

148
00:05:28,960 --> 00:05:30,720
and that's because of the explainability

149
00:05:30,720 --> 00:05:32,800
problem

150
00:05:32,800 --> 00:05:34,320
right so the hitchhiker's guide to the

151
00:05:34,320 --> 00:05:36,400
galaxy if you remember the book

152
00:05:36,400 --> 00:05:38,720
there was a race of hyper-intelligent

153
00:05:38,720 --> 00:05:40,400
pan-dimensional beings they built the

154
00:05:40,400 --> 00:05:42,400
world's most powerful computer deep

155
00:05:42,400 --> 00:05:44,560
thought to answer the ultimate question

156
00:05:44,560 --> 00:05:46,479
of life the universe and everything and

157
00:05:46,479 --> 00:05:48,240
the answer was

158
00:05:48,240 --> 00:05:49,600
42

159
00:05:49,600 --> 00:05:51,600
and if you remember deep thought wasn't

160
00:05:51,600 --> 00:05:55,120
unable to explain its answer or even

161
00:05:55,120 --> 00:05:57,360
tell you what the question was

162
00:05:57,360 --> 00:06:00,000
that's the explainability problem

163
00:06:00,000 --> 00:06:02,160
modern ai systems are essentially black

164
00:06:02,160 --> 00:06:05,120
boxes data goes in one end answer comes

165
00:06:05,120 --> 00:06:07,199
out the other and it can be impossible

166
00:06:07,199 --> 00:06:09,520
to understand how the system reaches its

167
00:06:09,520 --> 00:06:12,000
conclusion even if you're the programmer

168
00:06:12,000 --> 00:06:14,479
even if you have access to the code

169
00:06:14,479 --> 00:06:17,919
ai's don't solve problems like humans do

170
00:06:17,919 --> 00:06:19,440
their limitations are different than

171
00:06:19,440 --> 00:06:20,560
ours

172
00:06:20,560 --> 00:06:22,639
they consider more possible solutions

173
00:06:22,639 --> 00:06:24,560
than we might more importantly they look

174
00:06:24,560 --> 00:06:26,880
at different types of solutions they go

175
00:06:26,880 --> 00:06:30,800
down paths that we humans don't consider

176
00:06:30,800 --> 00:06:32,800
sort of more complex than the kinds of

177
00:06:32,800 --> 00:06:36,160
things we can normally keep in mind

178
00:06:36,160 --> 00:06:39,600
so 2016 the ai program alphago won a

179
00:06:39,600 --> 00:06:41,199
five game match against one of the

180
00:06:41,199 --> 00:06:43,280
world's best go players this is

181
00:06:43,280 --> 00:06:45,199
something that shocked both the

182
00:06:45,199 --> 00:06:48,479
ai and the go playing worlds alphago's

183
00:06:48,479 --> 00:06:51,919
most famous move was move 37 game two

184
00:06:51,919 --> 00:06:54,479
and without going into ghost strategy

185
00:06:54,479 --> 00:06:56,960
it's hard to explain but it was a move

186
00:06:56,960 --> 00:07:01,199
that no human would have ever made

187
00:07:01,199 --> 00:07:03,599
uh 2015 there's a research group that

188
00:07:03,599 --> 00:07:06,880
fed an ai system data from about 7 000

189
00:07:06,880 --> 00:07:09,280
patients and testing whether the ai can

190
00:07:09,280 --> 00:07:10,880
predict diseases

191
00:07:10,880 --> 00:07:12,880
the result was a success but deep

192
00:07:12,880 --> 00:07:14,720
patient as it was called

193
00:07:14,720 --> 00:07:16,400
provides no explanation

194
00:07:16,400 --> 00:07:18,720
of how it reaches a diagnosis

195
00:07:18,720 --> 00:07:20,400
and the researchers

196
00:07:20,400 --> 00:07:21,919
have no idea how it reaches its

197
00:07:21,919 --> 00:07:24,960
conclusions a doctor can either accept

198
00:07:24,960 --> 00:07:27,360
what the patient says but it can't query

199
00:07:27,360 --> 00:07:29,520
it for more info

200
00:07:29,520 --> 00:07:31,039
now researchers are working on

201
00:07:31,039 --> 00:07:32,720
explainable ai

202
00:07:32,720 --> 00:07:34,160
and they're going to be advances in this

203
00:07:34,160 --> 00:07:36,160
field this seems to be a trade-off

204
00:07:36,160 --> 00:07:38,960
between capability and explainability

205
00:07:38,960 --> 00:07:41,360
explanations are a cognitive shorthand

206
00:07:41,360 --> 00:07:43,919
used by humans suited for the way humans

207
00:07:43,919 --> 00:07:47,360
make decisions and forcing an ai to

208
00:07:47,360 --> 00:07:49,039
boost an explanation

209
00:07:49,039 --> 00:07:51,199
is an additional constraint

210
00:07:51,199 --> 00:07:52,639
that can affect the quality of its

211
00:07:52,639 --> 00:07:53,919
decisions

212
00:07:53,919 --> 00:07:56,160
and at least in the near term ai's are

213
00:07:56,160 --> 00:07:58,000
becoming even more opaque and less

214
00:07:58,000 --> 00:08:00,000
explainable

215
00:08:00,000 --> 00:08:01,599
all right so now i want to talk about

216
00:08:01,599 --> 00:08:03,360
reward hacking

217
00:08:03,360 --> 00:08:05,759
i said that ai's don't solve problems in

218
00:08:05,759 --> 00:08:07,520
the same way humans do

219
00:08:07,520 --> 00:08:09,919
and they invariably stumble on solutions

220
00:08:09,919 --> 00:08:12,479
that we humans don't anticipate

221
00:08:12,479 --> 00:08:14,560
and some of them will subvert the intent

222
00:08:14,560 --> 00:08:16,400
of the system

223
00:08:16,400 --> 00:08:18,319
and that's because ai's don't think in

224
00:08:18,319 --> 00:08:21,199
terms of the implications context norms

225
00:08:21,199 --> 00:08:23,199
and values that we humans take for

226
00:08:23,199 --> 00:08:24,319
granted

227
00:08:24,319 --> 00:08:26,879
so that's reward hacking it involves

228
00:08:26,879 --> 00:08:29,599
achieving a goal but in a way that the

229
00:08:29,599 --> 00:08:33,120
ai designers neither wanted nor intended

230
00:08:33,120 --> 00:08:35,519
and the examples are pretty great

231
00:08:35,519 --> 00:08:38,000
so there's a soccer simulation where an

232
00:08:38,000 --> 00:08:40,159
ai figured out that instead of kicking

233
00:08:40,159 --> 00:08:42,479
the ball to the goal it kicked the ball

234
00:08:42,479 --> 00:08:44,959
out of bounds the opponent's opponent

235
00:08:44,959 --> 00:08:47,279
opponent opposing player have to throw

236
00:08:47,279 --> 00:08:49,440
the ball back into bounds leave the goal

237
00:08:49,440 --> 00:08:50,720
unattended

238
00:08:50,720 --> 00:08:52,399
there was a stacking simulation where

239
00:08:52,399 --> 00:08:54,160
the ai figured out that it could flip a

240
00:08:54,160 --> 00:08:57,360
block upside down rather than stack it

241
00:08:57,360 --> 00:08:59,760
and there was an evolution simulation

242
00:08:59,760 --> 00:09:01,440
where you know instead

243
00:09:01,440 --> 00:09:03,680
the goal was to reach a distant finish

244
00:09:03,680 --> 00:09:06,240
line and instead of growing stronger

245
00:09:06,240 --> 00:09:08,959
muscles or longer limbs the ai grew

246
00:09:08,959 --> 00:09:13,199
really tall and just fell over the goal

247
00:09:13,279 --> 00:09:15,760
so these are all hacks you can blame

248
00:09:15,760 --> 00:09:17,680
them on poorly specified goals or

249
00:09:17,680 --> 00:09:19,600
rewards and you'd be correct

250
00:09:19,600 --> 00:09:21,519
you can point out that they all occurred

251
00:09:21,519 --> 00:09:23,120
in stimulated environments you'll also

252
00:09:23,120 --> 00:09:25,279
be correct but the problem is more

253
00:09:25,279 --> 00:09:26,320
general

254
00:09:26,320 --> 00:09:29,279
ais will inadvertently hack systems in

255
00:09:29,279 --> 00:09:31,200
ways we won't expect

256
00:09:31,200 --> 00:09:33,120
is the story of a researcher trying to

257
00:09:33,120 --> 00:09:34,880
teach his robot vacuum cleaner not to

258
00:09:34,880 --> 00:09:37,200
bump into things and instead of not

259
00:09:37,200 --> 00:09:38,880
bumping into things it learned to drive

260
00:09:38,880 --> 00:09:40,640
backwards because there are no sensors

261
00:09:40,640 --> 00:09:42,320
back there

262
00:09:42,320 --> 00:09:45,519
right any good ai system will naturally

263
00:09:45,519 --> 00:09:46,800
find hacks

264
00:09:46,800 --> 00:09:49,440
if there are problems inconsistencies or

265
00:09:49,440 --> 00:09:51,519
loopholes in the rules and if those

266
00:09:51,519 --> 00:09:53,200
properties lead to an acceptable

267
00:09:53,200 --> 00:09:55,040
solution as defined by the rules then

268
00:09:55,040 --> 00:09:57,920
the ai will find them

269
00:09:57,920 --> 00:10:01,040
so we all learn this problem as a child

270
00:10:01,040 --> 00:10:04,640
and that's the king midas story so after

271
00:10:04,640 --> 00:10:07,680
the god dionysus grants him a wish

272
00:10:07,680 --> 00:10:10,320
midas wishes that everything he touches

273
00:10:10,320 --> 00:10:11,760
turns to gold

274
00:10:11,760 --> 00:10:13,760
and he ends up miserable and starving

275
00:10:13,760 --> 00:10:15,680
when his food drink and daughter all

276
00:10:15,680 --> 00:10:18,640
turn to gold on touch so it's a

277
00:10:18,640 --> 00:10:21,440
specification problem midas program the

278
00:10:21,440 --> 00:10:24,480
wrong goal into the system

279
00:10:24,480 --> 00:10:26,720
we also know that genies can be very

280
00:10:26,720 --> 00:10:29,120
precise about the wording of wishes

281
00:10:29,120 --> 00:10:30,959
and can be maliciously pedantic when

282
00:10:30,959 --> 00:10:32,399
granting them

283
00:10:32,399 --> 00:10:34,800
but here's the thing there's no way to

284
00:10:34,800 --> 00:10:38,320
outsmart the genie whatever you wish for

285
00:10:38,320 --> 00:10:40,399
he will be able to grant it in a way

286
00:10:40,399 --> 00:10:43,600
that you wish he hadn't the genie will

287
00:10:43,600 --> 00:10:46,640
always be able to hack your wish

288
00:10:46,640 --> 00:10:49,440
the general problem is that in human

289
00:10:49,440 --> 00:10:52,560
language and thought goals and desires

290
00:10:52,560 --> 00:10:54,880
are always underspecified

291
00:10:54,880 --> 00:10:57,279
we never describe all the options we

292
00:10:57,279 --> 00:10:58,800
never include all the exceptions and

293
00:10:58,800 --> 00:11:00,640
provisos

294
00:11:00,640 --> 00:11:03,360
we can't any goal we specify will

295
00:11:03,360 --> 00:11:05,680
necessarily be incomplete

296
00:11:05,680 --> 00:11:07,360
and this is largely okay in human

297
00:11:07,360 --> 00:11:09,360
interactions because people understand

298
00:11:09,360 --> 00:11:12,160
context and act in good faith

299
00:11:12,160 --> 00:11:14,959
so if i ask you to get me some coffee

300
00:11:14,959 --> 00:11:16,880
you would probably go outside and pour

301
00:11:16,880 --> 00:11:19,279
me a cup or maybe go down the street to

302
00:11:19,279 --> 00:11:22,240
a coffee shop and buy a cup for me

303
00:11:22,240 --> 00:11:24,240
you would not bring me a pound of raw

304
00:11:24,240 --> 00:11:25,279
beans

305
00:11:25,279 --> 00:11:28,160
you would not buy me a coffee plantation

306
00:11:28,160 --> 00:11:29,680
you wouldn't look the person next to you

307
00:11:29,680 --> 00:11:31,120
rip the cup of coffee out of his hands

308
00:11:31,120 --> 00:11:33,120
and give it to me

309
00:11:33,120 --> 00:11:35,040
you wouldn't give me your week old cold

310
00:11:35,040 --> 00:11:37,680
coffee or a used paper towel that wiped

311
00:11:37,680 --> 00:11:39,920
up a coffee spill i wouldn't have to

312
00:11:39,920 --> 00:11:44,560
specify any of that you would just know

313
00:11:44,560 --> 00:11:46,480
and similarly if i asked you to develop

314
00:11:46,480 --> 00:11:48,640
a technology i would turn things into

315
00:11:48,640 --> 00:11:51,279
gold on touch you wouldn't design it in

316
00:11:51,279 --> 00:11:54,320
a way that starved the person using it

317
00:11:54,320 --> 00:11:56,399
i wouldn't have to tell you you would

318
00:11:56,399 --> 00:11:58,160
just know

319
00:11:58,160 --> 00:12:00,720
we can't completely specify goals to an

320
00:12:00,720 --> 00:12:01,760
ai

321
00:12:01,760 --> 00:12:03,760
and an ai won't be able to completely

322
00:12:03,760 --> 00:12:06,320
understand context

323
00:12:06,320 --> 00:12:08,880
so 2015 volkswagen was caught cheating

324
00:12:08,880 --> 00:12:11,200
on emission control tests this is not an

325
00:12:11,200 --> 00:12:14,160
ai story human engineers programmed a

326
00:12:14,160 --> 00:12:16,240
regular computer to cheat but it

327
00:12:16,240 --> 00:12:18,399
illustrates the problem really nicely

328
00:12:18,399 --> 00:12:20,800
so the engineers program the engine to

329
00:12:20,800 --> 00:12:22,639
detect emission control tests in

330
00:12:22,639 --> 00:12:24,720
progress and behave differently when

331
00:12:24,720 --> 00:12:26,000
being tested

332
00:12:26,000 --> 00:12:27,519
and the cheat remained undetected for

333
00:12:27,519 --> 00:12:29,120
about a decade because it's hard to

334
00:12:29,120 --> 00:12:31,360
figure out what computers are doing

335
00:12:31,360 --> 00:12:34,560
now if i asked you to design an engine

336
00:12:34,560 --> 00:12:37,440
control software to maximize performance

337
00:12:37,440 --> 00:12:39,200
while still passing all emission control

338
00:12:39,200 --> 00:12:41,120
tests you wouldn't cheat with

339
00:12:41,120 --> 00:12:43,920
understanding that you were cheating

340
00:12:43,920 --> 00:12:46,560
that isn't true for an ai

341
00:12:46,560 --> 00:12:48,399
right it's gonna think out of the box

342
00:12:48,399 --> 00:12:50,839
because it doesn't know what the box

343
00:12:50,839 --> 00:12:54,000
is and unless programmers

344
00:12:54,000 --> 00:12:56,320
specify the goal of not behaving

345
00:12:56,320 --> 00:12:59,279
differently while being tested an ai

346
00:12:59,279 --> 00:13:02,480
might come up with that hack on its own

347
00:13:02,480 --> 00:13:04,399
the programmers will be satisfied the

348
00:13:04,399 --> 00:13:06,560
accountants will be a static and because

349
00:13:06,560 --> 00:13:08,880
of the explainability problem we're not

350
00:13:08,880 --> 00:13:11,760
going to know how the software works

351
00:13:11,760 --> 00:13:14,240
and yes now that we know the volkswagen

352
00:13:14,240 --> 00:13:15,120
story

353
00:13:15,120 --> 00:13:17,200
we can explicitly set the goal to avoid

354
00:13:17,200 --> 00:13:19,120
that particular hack

355
00:13:19,120 --> 00:13:20,160
but

356
00:13:20,160 --> 00:13:22,000
there are other hacks that programmers

357
00:13:22,000 --> 00:13:24,639
won't anticipate the lesson of the genie

358
00:13:24,639 --> 00:13:27,360
is they'll always be hacks

359
00:13:27,360 --> 00:13:30,079
the programmers won't anticipate

360
00:13:30,079 --> 00:13:31,600
and the worry isn't limited to the

361
00:13:31,600 --> 00:13:33,440
obvious hacks

362
00:13:33,440 --> 00:13:35,600
the greatest worry is the hacks that

363
00:13:35,600 --> 00:13:38,000
aren't so obvious the ones whose effects

364
00:13:38,000 --> 00:13:40,639
are subtle like the volkswagen hack that

365
00:13:40,639 --> 00:13:43,279
we're not going to see

366
00:13:43,279 --> 00:13:44,639
now we're already seeing the first

367
00:13:44,639 --> 00:13:46,320
generation of this

368
00:13:46,320 --> 00:13:47,519
a lot has been written about

369
00:13:47,519 --> 00:13:50,079
recommendation engines on social media

370
00:13:50,079 --> 00:13:51,360
how they push people towards extreme

371
00:13:51,360 --> 00:13:53,760
content they weren't programmed to do

372
00:13:53,760 --> 00:13:56,000
that it's a property that naturally

373
00:13:56,000 --> 00:13:58,720
emerged the algorithms learned to push

374
00:13:58,720 --> 00:14:00,839
extreme content because that's what

375
00:14:00,839 --> 00:14:03,920
people engage with

376
00:14:03,920 --> 00:14:06,000
right and that's important it doesn't

377
00:14:06,000 --> 00:14:09,279
take a bad actor to create the hack

378
00:14:09,279 --> 00:14:11,279
a pretty basic automatic system did it

379
00:14:11,279 --> 00:14:13,839
on its own

380
00:14:14,240 --> 00:14:16,880
so nothing i'm saying here

381
00:14:16,880 --> 00:14:19,760
is news to ai researchers and there are

382
00:14:19,760 --> 00:14:21,839
many that are currently working on ways

383
00:14:21,839 --> 00:14:23,440
to defend against goal and reward

384
00:14:23,440 --> 00:14:24,560
hacking

385
00:14:24,560 --> 00:14:27,920
one solution is to teach ai's context

386
00:14:27,920 --> 00:14:29,920
general term for this research is value

387
00:14:29,920 --> 00:14:32,720
alignment how do we create ais that

388
00:14:32,720 --> 00:14:34,480
mirror our values

389
00:14:34,480 --> 00:14:35,920
you can think of it in terms of two

390
00:14:35,920 --> 00:14:38,079
extremes the first is to explicitly

391
00:14:38,079 --> 00:14:41,199
specify what our values are good luck

392
00:14:41,199 --> 00:14:43,120
the other is to create ais that figure

393
00:14:43,120 --> 00:14:45,040
out our values by learning about humans

394
00:14:45,040 --> 00:14:47,920
in action good luck

395
00:14:47,920 --> 00:14:50,320
right both of these have problems

396
00:14:50,320 --> 00:14:52,800
but that's where the research is

397
00:14:52,800 --> 00:14:54,880
and so how realistic is anything i've

398
00:14:54,880 --> 00:14:58,800
said so far the answer is it depends

399
00:14:58,800 --> 00:15:01,600
the feasibility of any ai hacking

400
00:15:01,600 --> 00:15:03,600
depends on the specific system being

401
00:15:03,600 --> 00:15:04,959
modeled

402
00:15:04,959 --> 00:15:08,000
for an ai to start optimizing a problem

403
00:15:08,000 --> 00:15:09,760
let alone hacking a complete novel

404
00:15:09,760 --> 00:15:12,000
solution the rules of the environment

405
00:15:12,000 --> 00:15:14,160
has to be formalized in a way that

406
00:15:14,160 --> 00:15:15,920
computer can understand

407
00:15:15,920 --> 00:15:18,000
goals and ai we call them objective

408
00:15:18,000 --> 00:15:20,240
functions need to be established and the

409
00:15:20,240 --> 00:15:22,399
ai needs some sort of feedback mechanism

410
00:15:22,399 --> 00:15:24,320
on how well it's doing so it can improve

411
00:15:24,320 --> 00:15:26,240
its performance

412
00:15:26,240 --> 00:15:28,320
sometimes this is a trivial matter for a

413
00:15:28,320 --> 00:15:31,040
game of go it's easy right the rules

414
00:15:31,040 --> 00:15:33,519
objective feedback did you win or lose

415
00:15:33,519 --> 00:15:35,759
are all precisely specified

416
00:15:35,759 --> 00:15:37,680
there's nothing outside of those things

417
00:15:37,680 --> 00:15:39,680
to muddy the waters

418
00:15:39,680 --> 00:15:41,600
and that's why most the current examples

419
00:15:41,600 --> 00:15:43,600
of gold and reward hacking come from

420
00:15:43,600 --> 00:15:45,440
simulated environments

421
00:15:45,440 --> 00:15:47,440
right they're artificial and constrained

422
00:15:47,440 --> 00:15:51,199
with all the rules specified by the ai

423
00:15:51,199 --> 00:15:53,120
what matters is the ambiguity of the

424
00:15:53,120 --> 00:15:55,759
system we can imagine feeding the

425
00:15:55,759 --> 00:15:58,480
world's tax laws into an ai because the

426
00:15:58,480 --> 00:16:00,880
tax code consists of formulas

427
00:16:00,880 --> 00:16:02,959
but there's still ambiguity in many of

428
00:16:02,959 --> 00:16:05,199
those laws and that's why we have tax

429
00:16:05,199 --> 00:16:07,440
courts and tax attorneys

430
00:16:07,440 --> 00:16:09,199
and that ambiguity is difficult to

431
00:16:09,199 --> 00:16:12,959
translate into code which makes an ai

432
00:16:12,959 --> 00:16:15,279
have trouble dealing with

433
00:16:15,279 --> 00:16:17,199
so most human systems are even more

434
00:16:17,199 --> 00:16:18,560
ambiguous

435
00:16:18,560 --> 00:16:20,560
it's hard to imagine an ai coming up

436
00:16:20,560 --> 00:16:22,800
with a real world sports hack like

437
00:16:22,800 --> 00:16:24,639
curving a hockey stick

438
00:16:24,639 --> 00:16:26,399
the iai would have to understand not

439
00:16:26,399 --> 00:16:28,399
just the rules of the game but the

440
00:16:28,399 --> 00:16:30,240
physiology of the players the

441
00:16:30,240 --> 00:16:32,320
aerodynamics the stick and puck and sort

442
00:16:32,320 --> 00:16:35,279
of everything else about the environment

443
00:16:35,279 --> 00:16:37,279
and that ambiguity ends up being a

444
00:16:37,279 --> 00:16:39,360
near-term security defense against the

445
00:16:39,360 --> 00:16:41,199
sort of ai hacking

446
00:16:41,199 --> 00:16:43,759
and it'll be a long time before ai's are

447
00:16:43,759 --> 00:16:45,600
capable of simulating

448
00:16:45,600 --> 00:16:48,880
and modeling the ways that people work

449
00:16:48,880 --> 00:16:51,199
and before the cable of coming up with

450
00:16:51,199 --> 00:16:53,839
ways to hack a legislative process

451
00:16:53,839 --> 00:16:55,519
we're not going to see ai generated

452
00:16:55,519 --> 00:16:57,279
sports hacks until

453
00:16:57,279 --> 00:16:59,759
we have androids actually playing the

454
00:16:59,759 --> 00:17:01,199
sports

455
00:17:01,199 --> 00:17:04,480
or maybe some kind of generalized ai

456
00:17:04,480 --> 00:17:06,079
i think probably the first place to look

457
00:17:06,079 --> 00:17:09,199
for ai hacking is in financial systems

458
00:17:09,199 --> 00:17:11,520
since those systems are designed to be

459
00:17:11,520 --> 00:17:13,839
algorithmically tractable

460
00:17:13,839 --> 00:17:16,400
and we can imagine equipping an ai with

461
00:17:16,400 --> 00:17:18,640
all the world's financial laws

462
00:17:18,640 --> 00:17:20,959
plus all the world's news and

463
00:17:20,959 --> 00:17:22,799
financial information and then giving it

464
00:17:22,799 --> 00:17:24,799
the goal of a maximum profit and you

465
00:17:24,799 --> 00:17:27,439
know my guess is that's not very far off

466
00:17:27,439 --> 00:17:28,960
and the result will be all sorts of

467
00:17:28,960 --> 00:17:31,200
novel hacks

468
00:17:31,200 --> 00:17:33,600
but here's the thing about ai advances

469
00:17:33,600 --> 00:17:36,799
are discontinuous and counter-intuitive

470
00:17:36,799 --> 00:17:39,200
things that seem easy should not be hard

471
00:17:39,200 --> 00:17:41,919
things that seem hard to not to be easy

472
00:17:41,919 --> 00:17:44,080
and we don't know until a breakthrough

473
00:17:44,080 --> 00:17:45,360
occurs

474
00:17:45,360 --> 00:17:46,960
when i was a college student in the

475
00:17:46,960 --> 00:17:49,600
early 80s we learned that the game of go

476
00:17:49,600 --> 00:17:50,960
would never

477
00:17:50,960 --> 00:17:53,200
be solved by an ai

478
00:17:53,200 --> 00:17:55,200
because of its enormous complexity not

479
00:17:55,200 --> 00:17:56,799
the rules with the number of possible

480
00:17:56,799 --> 00:17:58,160
moves

481
00:17:58,160 --> 00:18:00,559
and now a computer has beaten a human

482
00:18:00,559 --> 00:18:02,240
world champion

483
00:18:02,240 --> 00:18:03,919
some of this was due to advances in

484
00:18:03,919 --> 00:18:06,640
science of ai but a lot of it was due to

485
00:18:06,640 --> 00:18:08,000
just throwing more computing power at

486
00:18:08,000 --> 00:18:10,080
the problem

487
00:18:10,080 --> 00:18:12,480
so while a world filled with ai hackers

488
00:18:12,480 --> 00:18:15,520
is still science fiction it's not stupid

489
00:18:15,520 --> 00:18:17,520
science fiction

490
00:18:17,520 --> 00:18:18,559
and i

491
00:18:18,559 --> 00:18:20,559
want us to start thinking about the

492
00:18:20,559 --> 00:18:23,600
implications right now

493
00:18:23,600 --> 00:18:26,640
so hacking is as old as humanity

494
00:18:26,640 --> 00:18:29,600
we are creative problem solvers we are

495
00:18:29,600 --> 00:18:32,559
loophole exploiters we manipulate

496
00:18:32,559 --> 00:18:34,640
systems to serve our interests

497
00:18:34,640 --> 00:18:36,559
and we strive for more influence more

498
00:18:36,559 --> 00:18:39,120
power more wealth and hacking has always

499
00:18:39,120 --> 00:18:41,200
been a part of that

500
00:18:41,200 --> 00:18:44,240
still no humans maximize their interests

501
00:18:44,240 --> 00:18:47,280
without constraint that even sociopaths

502
00:18:47,280 --> 00:18:49,360
are constrained by the complexity of

503
00:18:49,360 --> 00:18:52,559
society their own contract impulses

504
00:18:52,559 --> 00:18:56,640
their reputation or punishment

505
00:18:56,640 --> 00:18:59,280
their limited time

506
00:18:59,280 --> 00:19:01,919
hacking changed as everything became

507
00:19:01,919 --> 00:19:03,520
computerized

508
00:19:03,520 --> 00:19:05,760
because of their

509
00:19:05,760 --> 00:19:08,160
formalism and complexity computers are

510
00:19:08,160 --> 00:19:11,280
uniquely hackable and today everything

511
00:19:11,280 --> 00:19:12,799
is a computer

512
00:19:12,799 --> 00:19:15,679
but to date hacking has exclusively been

513
00:19:15,679 --> 00:19:18,799
a human creative activity

514
00:19:18,799 --> 00:19:21,360
searching for new hacks requires

515
00:19:21,360 --> 00:19:26,080
expertise creativity time and luck

516
00:19:26,080 --> 00:19:28,320
and that is gonna change

517
00:19:28,320 --> 00:19:31,440
and when hacking when ai's start hacking

518
00:19:31,440 --> 00:19:34,000
everything will change yet again

519
00:19:34,000 --> 00:19:35,919
they won't be constrained in the same

520
00:19:35,919 --> 00:19:39,200
ways or have the same limits as people

521
00:19:39,200 --> 00:19:41,600
they will think like aliens

522
00:19:41,600 --> 00:19:44,799
and they will change hacking speed scale

523
00:19:44,799 --> 00:19:46,720
and scope

524
00:19:46,720 --> 00:19:48,799
so speed is easy computers are much

525
00:19:48,799 --> 00:19:50,240
faster than people

526
00:19:50,240 --> 00:19:52,720
a human creative process that might take

527
00:19:52,720 --> 00:19:55,039
months or years could get compressed to

528
00:19:55,039 --> 00:19:57,360
days hours or even seconds

529
00:19:57,360 --> 00:20:00,320
what might happen when you feed an ai

530
00:20:00,320 --> 00:20:03,200
an entire country's tax code

531
00:20:03,200 --> 00:20:04,559
or in case of a multinational

532
00:20:04,559 --> 00:20:08,000
corporation the entire world's tax codes

533
00:20:08,000 --> 00:20:11,039
and will it figure out

534
00:20:11,039 --> 00:20:12,799
that you should register your ship in

535
00:20:12,799 --> 00:20:14,320
panama

536
00:20:14,320 --> 00:20:16,320
and how many loopholes will it find that

537
00:20:16,320 --> 00:20:18,840
we don't already know about dozens

538
00:20:18,840 --> 00:20:21,760
hundreds gonna find thousands we

539
00:20:21,760 --> 00:20:24,400
actually have no clue

540
00:20:24,400 --> 00:20:26,400
and it's not just speed but it's scale

541
00:20:26,400 --> 00:20:28,480
as well once ai systems start

542
00:20:28,480 --> 00:20:30,159
discovering hacks they'll be able to

543
00:20:30,159 --> 00:20:32,640
exploit them at a scale we're not ready

544
00:20:32,640 --> 00:20:34,159
for

545
00:20:34,159 --> 00:20:35,520
we're starting to see some of this with

546
00:20:35,520 --> 00:20:37,360
ai generated text

547
00:20:37,360 --> 00:20:39,200
and conversation bots

548
00:20:39,200 --> 00:20:42,320
it's going to get a lot bigger

549
00:20:42,559 --> 00:20:44,559
now you can imagine tech spots

550
00:20:44,559 --> 00:20:46,840
replicated by the millions across social

551
00:20:46,840 --> 00:20:49,919
media you know not with large platforms

552
00:20:49,919 --> 00:20:52,320
with small platforms making regular

553
00:20:52,320 --> 00:20:54,880
conversation occasionally

554
00:20:54,880 --> 00:20:58,159
saying something with a political nature

555
00:20:58,159 --> 00:21:00,400
right run rampant it will change what

556
00:21:00,400 --> 00:21:02,159
political debate looks like what we see

557
00:21:02,159 --> 00:21:04,720
as debate

558
00:21:05,280 --> 00:21:07,280
increasing scope of ai systems also

559
00:21:07,280 --> 00:21:09,039
makes hacks more dangerous

560
00:21:09,039 --> 00:21:10,559
ais are already making important

561
00:21:10,559 --> 00:21:12,720
decisions that affect our lives

562
00:21:12,720 --> 00:21:14,480
decisions that we used to believe were

563
00:21:14,480 --> 00:21:16,640
the exclusive purview of humans

564
00:21:16,640 --> 00:21:19,200
ais make bail and parole decisions help

565
00:21:19,200 --> 00:21:21,200
decide who receives bank loans who gets

566
00:21:21,200 --> 00:21:25,039
into college they scream job candidates

567
00:21:25,039 --> 00:21:26,880
government services

568
00:21:26,880 --> 00:21:29,919
as ai systems get more capable society

569
00:21:29,919 --> 00:21:32,000
will cede more and more important

570
00:21:32,000 --> 00:21:33,520
decisions to them

571
00:21:33,520 --> 00:21:35,520
and that means hacks of those systems

572
00:21:35,520 --> 00:21:38,159
become more damaging

573
00:21:38,159 --> 00:21:41,039
and largely these hacks will perpetuate

574
00:21:41,039 --> 00:21:44,000
the existing power structure

575
00:21:44,000 --> 00:21:45,919
and they'll be perpetrated by the

576
00:21:45,919 --> 00:21:48,640
powerful against the people

577
00:21:48,640 --> 00:21:51,120
and while we have societal systems that

578
00:21:51,120 --> 00:21:54,320
deal with hacks we've had for millennia

579
00:21:54,320 --> 00:21:55,840
they were developed when hackers were

580
00:21:55,840 --> 00:21:57,520
human and reflect the pace of human

581
00:21:57,520 --> 00:21:58,960
hackers

582
00:21:58,960 --> 00:22:01,600
we don't have any system of governance

583
00:22:01,600 --> 00:22:03,600
that can deal with hundreds let alone

584
00:22:03,600 --> 00:22:05,679
thousands of newly discovered tax

585
00:22:05,679 --> 00:22:07,200
loopholes

586
00:22:07,200 --> 00:22:08,799
right we won't be able to recover from

587
00:22:08,799 --> 00:22:11,440
an ai figuring out unanticipated but

588
00:22:11,440 --> 00:22:13,919
legal hacks of financial systems

589
00:22:13,919 --> 00:22:16,240
at computer speed scale and scope

590
00:22:16,240 --> 00:22:18,320
hacking becomes a problem that we as

591
00:22:18,320 --> 00:22:21,360
society can no longer manage

592
00:22:21,360 --> 00:22:24,799
and so finally let's talk about defense

593
00:22:24,799 --> 00:22:28,240
when a back to computers when ais are

594
00:22:28,240 --> 00:22:29,760
able to discover new software

595
00:22:29,760 --> 00:22:31,760
vulnerabilities it will be an incredible

596
00:22:31,760 --> 00:22:33,840
boon to hackers everywhere they'll be

597
00:22:33,840 --> 00:22:35,200
able to use those vulnerabilities to

598
00:22:35,200 --> 00:22:37,520
hack computer systems around the world

599
00:22:37,520 --> 00:22:40,159
it will put us all at risk

600
00:22:40,159 --> 00:22:41,840
but those same

601
00:22:41,840 --> 00:22:45,039
technological ais will be useful for the

602
00:22:45,039 --> 00:22:46,720
defense as well

603
00:22:46,720 --> 00:22:49,440
we can imagine a software company

604
00:22:49,440 --> 00:22:52,240
deploying it

605
00:22:52,480 --> 00:22:54,640
as a vulnerability finding ai against

606
00:22:54,640 --> 00:22:56,320
its own code

607
00:22:56,320 --> 00:22:59,679
it could identify and then patch all

608
00:22:59,679 --> 00:23:02,080
or at least all of the discoverable

609
00:23:02,080 --> 00:23:04,000
vulnerabilities in its products before

610
00:23:04,000 --> 00:23:06,240
release

611
00:23:06,240 --> 00:23:07,840
right the technology benefits the

612
00:23:07,840 --> 00:23:10,480
attacker and the defender

613
00:23:10,480 --> 00:23:12,799
equally but the defender can patch it

614
00:23:12,799 --> 00:23:15,120
and it's forever fixed

615
00:23:15,120 --> 00:23:17,120
i can imagine this feature being built

616
00:23:17,120 --> 00:23:18,880
into compilers

617
00:23:18,880 --> 00:23:21,039
being automatic happening to every piece

618
00:23:21,039 --> 00:23:22,559
of code everywhere

619
00:23:22,559 --> 00:23:24,960
we can imagine a future where software

620
00:23:24,960 --> 00:23:27,840
vulnerabilities are a thing of the past

621
00:23:27,840 --> 00:23:30,000
which is kind of amazing

622
00:23:30,000 --> 00:23:32,000
now right the transition period is

623
00:23:32,000 --> 00:23:35,120
dangerous the new stuff is secure

624
00:23:35,120 --> 00:23:37,919
but the legacy codes is vulnerable and

625
00:23:37,919 --> 00:23:40,240
there the attackers have the advantage

626
00:23:40,240 --> 00:23:42,240
but over the long run

627
00:23:42,240 --> 00:23:45,120
an ai vulnerability fighting technology

628
00:23:45,120 --> 00:23:47,760
favors the defense

629
00:23:47,760 --> 00:23:49,200
and i think this is the same when we

630
00:23:49,200 --> 00:23:52,159
turn to hacking broader social systems

631
00:23:52,159 --> 00:23:54,960
sure ai hackers might find hundreds of

632
00:23:54,960 --> 00:23:57,360
vulnerabilities in the existing tax code

633
00:23:57,360 --> 00:23:59,279
but the same technology can be used to

634
00:23:59,279 --> 00:24:01,679
evaluate potential vulnerabilities in

635
00:24:01,679 --> 00:24:04,960
any new tax law or tax ruling

636
00:24:04,960 --> 00:24:06,720
right we can imagine a tax law being

637
00:24:06,720 --> 00:24:08,960
tested in this way someone it could be a

638
00:24:08,960 --> 00:24:11,919
legislature a watched organization the

639
00:24:11,919 --> 00:24:12,799
press

640
00:24:12,799 --> 00:24:15,279
could test the text of a bill

641
00:24:15,279 --> 00:24:16,640
and find all the explainable

642
00:24:16,640 --> 00:24:18,240
vulnerabilities it doesn't mean they're

643
00:24:18,240 --> 00:24:19,600
going to get fixed right lots of

644
00:24:19,600 --> 00:24:21,279
loopholes are put in for political

645
00:24:21,279 --> 00:24:23,360
reasons but it does mean they become

646
00:24:23,360 --> 00:24:25,679
public and part of the debate

647
00:24:25,679 --> 00:24:28,320
and they can in theory be patched before

648
00:24:28,320 --> 00:24:31,200
the rich and powerful exploit them

649
00:24:31,200 --> 00:24:33,039
and here too right the transition period

650
00:24:33,039 --> 00:24:35,120
is dangerous

651
00:24:35,120 --> 00:24:38,880
but while ai hackers can be employed by

652
00:24:38,880 --> 00:24:41,279
the attacker and the defender in the

653
00:24:41,279 --> 00:24:44,880
long term the defense prevails

654
00:24:45,440 --> 00:24:47,760
so ensuring the defense prevails also

655
00:24:47,760 --> 00:24:49,440
requires building

656
00:24:49,440 --> 00:24:51,760
uh resilient governance structures that

657
00:24:51,760 --> 00:24:53,520
can quickly and effectively respond to

658
00:24:53,520 --> 00:24:55,039
new hacks

659
00:24:55,039 --> 00:24:57,279
it won't do any good if it takes years

660
00:24:57,279 --> 00:24:59,279
to update the tax code like it does in

661
00:24:59,279 --> 00:25:00,880
the us right now

662
00:25:00,880 --> 00:25:03,520
or if a legislative hack can become

663
00:25:03,520 --> 00:25:05,360
so entrenched that it can't politically

664
00:25:05,360 --> 00:25:06,640
be be

665
00:25:06,640 --> 00:25:07,679
patched

666
00:25:07,679 --> 00:25:09,600
like happens in the u.s right now

667
00:25:09,600 --> 00:25:11,760
right think about modern software it's

668
00:25:11,760 --> 00:25:14,240
continuously patched

669
00:25:14,240 --> 00:25:17,200
you know we need to figure out

670
00:25:17,200 --> 00:25:19,840
you know how to have that kind of

671
00:25:19,840 --> 00:25:21,919
agility

672
00:25:21,919 --> 00:25:22,960
with

673
00:25:22,960 --> 00:25:24,000
law

674
00:25:24,000 --> 00:25:27,360
that we do with computer code

675
00:25:27,360 --> 00:25:28,880
so this is a hard problem modern

676
00:25:28,880 --> 00:25:31,039
governance and it's kind of well beyond

677
00:25:31,039 --> 00:25:33,520
the scope of this talk my book this

678
00:25:33,520 --> 00:25:34,960
conference

679
00:25:34,960 --> 00:25:36,320
but something we need to start thinking

680
00:25:36,320 --> 00:25:37,840
about

681
00:25:37,840 --> 00:25:39,279
it's not substantially different than

682
00:25:39,279 --> 00:25:40,880
the problem of building governance

683
00:25:40,880 --> 00:25:42,880
structures that can operate at the speed

684
00:25:42,880 --> 00:25:46,320
and complexity of the information age

685
00:25:46,320 --> 00:25:47,919
and that's also something we need to

686
00:25:47,919 --> 00:25:49,679
figure out how to do

687
00:25:49,679 --> 00:25:52,240
right it's not doing us any good to let

688
00:25:52,240 --> 00:25:55,360
corporations lead technology

689
00:25:55,360 --> 00:25:57,360
that we need to sort of decide as

690
00:25:57,360 --> 00:26:01,600
society what we want out of technology

691
00:26:01,600 --> 00:26:04,799
the overarching solution here is people

692
00:26:04,799 --> 00:26:06,320
what i've been describing is the

693
00:26:06,320 --> 00:26:07,919
interplay between humans and computer

694
00:26:07,919 --> 00:26:10,480
systems and the risks inherent when the

695
00:26:10,480 --> 00:26:12,080
computers start doing the parts of the

696
00:26:12,080 --> 00:26:13,679
humans

697
00:26:13,679 --> 00:26:15,760
and this too is a more general problem

698
00:26:15,760 --> 00:26:18,159
than ai hackers it's also one that

699
00:26:18,159 --> 00:26:20,480
technologists and futurists are writing

700
00:26:20,480 --> 00:26:21,600
about

701
00:26:21,600 --> 00:26:23,600
and while it's easy to let technology

702
00:26:23,600 --> 00:26:25,279
lead us into the future i think we're

703
00:26:25,279 --> 00:26:28,400
much better off as a society if we as a

704
00:26:28,400 --> 00:26:31,120
society decide what technology's role in

705
00:26:31,120 --> 00:26:32,640
our future should be

706
00:26:32,640 --> 00:26:33,840
and this is all something we need to

707
00:26:33,840 --> 00:26:36,559
figure out now before these ais start

708
00:26:36,559 --> 00:26:39,120
coming online and hacking our world

709
00:26:39,120 --> 00:26:41,710
so with that i thank you

710
00:26:41,710 --> 00:26:48,019
[Applause]

