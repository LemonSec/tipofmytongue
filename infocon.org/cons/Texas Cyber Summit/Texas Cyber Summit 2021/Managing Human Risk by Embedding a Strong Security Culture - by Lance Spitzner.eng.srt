1
00:00:02,800 --> 00:00:05,680
hey folks and welcome my name is lance

2
00:00:05,680 --> 00:00:07,440
spitzner and thank you so much for

3
00:00:07,440 --> 00:00:09,920
inviting me today very excited to be

4
00:00:09,920 --> 00:00:13,040
virtually part of texas

5
00:00:13,040 --> 00:00:15,519
before we jump in just real briefly

6
00:00:15,519 --> 00:00:18,400
about me as mentioned my name is lance

7
00:00:18,400 --> 00:00:21,279
spitzner and i'm a director and an

8
00:00:21,279 --> 00:00:24,640
instructor at the sands institute my job

9
00:00:24,640 --> 00:00:26,000
and passion there is helping

10
00:00:26,000 --> 00:00:28,560
organizations better understand

11
00:00:28,560 --> 00:00:31,519
how to manage their human risk

12
00:00:31,519 --> 00:00:34,239
i've been in cyber security for over 20

13
00:00:34,239 --> 00:00:36,880
years now the first 10 years or so

14
00:00:36,880 --> 00:00:39,840
highly technical sun microsystems pen

15
00:00:39,840 --> 00:00:43,360
testing firewalls cyber intel honeypots

16
00:00:43,360 --> 00:00:44,559
forensics

17
00:00:44,559 --> 00:00:46,719
pretty much did it all

18
00:00:46,719 --> 00:00:49,360
but really the past 10 years or so i

19
00:00:49,360 --> 00:00:52,480
flipped to the human side because that

20
00:00:52,480 --> 00:00:55,920
is where i passionately feel we can make

21
00:00:55,920 --> 00:00:57,440
the biggest difference

22
00:00:57,440 --> 00:01:00,000
so that is why i'm so excited today to

23
00:01:00,000 --> 00:01:03,600
share about you or share with you about

24
00:01:03,600 --> 00:01:06,479
security culture really what is it and

25
00:01:06,479 --> 00:01:08,400
why should we care

26
00:01:08,400 --> 00:01:12,000
so before we jump into the what and why

27
00:01:12,000 --> 00:01:14,880
let's start first with the problem i

28
00:01:14,880 --> 00:01:16,880
always like to start with the problem

29
00:01:16,880 --> 00:01:20,799
before i jump into the solution oh by

30
00:01:20,799 --> 00:01:21,840
the way

31
00:01:21,840 --> 00:01:23,360
at the end of this talk i'm going to

32
00:01:23,360 --> 00:01:25,439
share with you my email address so if

33
00:01:25,439 --> 00:01:27,600
you have any questions

34
00:01:27,600 --> 00:01:29,920
keep them in here and then just shoot me

35
00:01:29,920 --> 00:01:33,600
an email when we're done okay back to

36
00:01:33,600 --> 00:01:37,600
the talk starting with the problem what

37
00:01:37,600 --> 00:01:39,119
is the problem

38
00:01:39,119 --> 00:01:41,600
well when i started in cyber security 20

39
00:01:41,600 --> 00:01:44,240
years ago cyber security was primarily

40
00:01:44,240 --> 00:01:48,240
pretty much purely a technical challenge

41
00:01:48,240 --> 00:01:50,799
but fast forward to today we need to

42
00:01:50,799 --> 00:01:54,640
also start taking the human into account

43
00:01:54,640 --> 00:01:57,280
now lots of different data points to

44
00:01:57,280 --> 00:01:59,119
really hit this home but probably my

45
00:01:59,119 --> 00:02:01,119
single most favorite one is the most

46
00:02:01,119 --> 00:02:05,680
recent one from this year's verizon dbir

47
00:02:05,680 --> 00:02:07,520
if you're not familiar with this report

48
00:02:07,520 --> 00:02:09,360
it's probably one of the world's most

49
00:02:09,360 --> 00:02:12,400
respected data-driven reports

50
00:02:12,400 --> 00:02:14,959
on the most common drivers of breaches

51
00:02:14,959 --> 00:02:17,680
and incidents at a global level

52
00:02:17,680 --> 00:02:20,080
and for the past three years they've

53
00:02:20,080 --> 00:02:22,319
found that the human is the biggest

54
00:02:22,319 --> 00:02:26,080
driver of beach beaches of breaches

55
00:02:26,080 --> 00:02:28,800
today and for this year they actually

56
00:02:28,800 --> 00:02:31,680
put a number on it after analyzing

57
00:02:31,680 --> 00:02:34,319
thousands and thousands of breaches

58
00:02:34,319 --> 00:02:38,400
globally they identified over 85

59
00:02:38,400 --> 00:02:40,640
of breaches globally

60
00:02:40,640 --> 00:02:42,959
where it had the human involved at some

61
00:02:42,959 --> 00:02:44,640
point in other words people were

62
00:02:44,640 --> 00:02:47,440
involved in breaches and over 85 percent

63
00:02:47,440 --> 00:02:48,560
of breaches

64
00:02:48,560 --> 00:02:51,200
and they also found less than five

65
00:02:51,200 --> 00:02:53,680
percent of breaches were purely a

66
00:02:53,680 --> 00:02:55,840
technical exploit where there's just

67
00:02:55,840 --> 00:02:59,200
technology alone involved

68
00:02:59,200 --> 00:03:02,879
so first of all people we have to start

69
00:03:02,879 --> 00:03:05,280
addressing the human element or we're

70
00:03:05,280 --> 00:03:08,239
just going to continue to lose this

71
00:03:08,239 --> 00:03:09,360
battle

72
00:03:09,360 --> 00:03:11,680
but why is that the case

73
00:03:11,680 --> 00:03:14,159
well as i mentioned 20 years ago

74
00:03:14,159 --> 00:03:16,959
technology or security was perceived

75
00:03:16,959 --> 00:03:19,519
primarily as a technical challenge

76
00:03:19,519 --> 00:03:22,400
and 20 years ago it was pretty easy to

77
00:03:22,400 --> 00:03:24,480
hack into technology

78
00:03:24,480 --> 00:03:28,239
in 2000 and 2001 the average life

79
00:03:28,239 --> 00:03:30,879
expectancy of a default microsoft

80
00:03:30,879 --> 00:03:32,400
windows computer

81
00:03:32,400 --> 00:03:35,200
was about three hours in other words a

82
00:03:35,200 --> 00:03:38,319
cyber attacker would find and hack it in

83
00:03:38,319 --> 00:03:40,000
three hours

84
00:03:40,000 --> 00:03:42,000
we know this for fact to include based

85
00:03:42,000 --> 00:03:44,400
on the research from the honeynet

86
00:03:44,400 --> 00:03:45,440
project

87
00:03:45,440 --> 00:03:48,319
now fast forward 20 years

88
00:03:48,319 --> 00:03:52,000
and nowadays it is very very hard to

89
00:03:52,000 --> 00:03:54,159
hack into the default

90
00:03:54,159 --> 00:03:57,599
installation of any modern microsoft

91
00:03:57,599 --> 00:04:00,640
windows computer and that is or that is

92
00:04:00,640 --> 00:04:03,519
because in the past 20 years microsoft

93
00:04:03,519 --> 00:04:05,920
has implemented a huge number of

94
00:04:05,920 --> 00:04:07,519
technical controls

95
00:04:07,519 --> 00:04:10,720
to secure the default installation and

96
00:04:10,720 --> 00:04:13,200
this is just a small overview of all

97
00:04:13,200 --> 00:04:15,760
those different technical controls

98
00:04:15,760 --> 00:04:18,639
but as a result today i put that default

99
00:04:18,639 --> 00:04:20,399
system on the internet

100
00:04:20,399 --> 00:04:23,040
it can take weeks months

101
00:04:23,040 --> 00:04:25,840
if not years before somebody finds and

102
00:04:25,840 --> 00:04:29,680
can hack into it that is until the human

103
00:04:29,680 --> 00:04:31,600
touches the keyboard

104
00:04:31,600 --> 00:04:34,479
once people interact with technology as

105
00:04:34,479 --> 00:04:36,720
we know game over

106
00:04:36,720 --> 00:04:39,120
but why is that the case

107
00:04:39,120 --> 00:04:40,800
well if we've done this

108
00:04:40,800 --> 00:04:42,880
for the windows operating system over

109
00:04:42,880 --> 00:04:44,800
the past 20 years

110
00:04:44,800 --> 00:04:46,560
what have we done for the human

111
00:04:46,560 --> 00:04:49,919
operating system over the past 20 years

112
00:04:49,919 --> 00:04:52,800
comparatively very little we've done

113
00:04:52,800 --> 00:04:55,440
very little to train and educate people

114
00:04:55,440 --> 00:04:58,160
in their terms we've done little to make

115
00:04:58,160 --> 00:04:59,840
cyber security

116
00:04:59,840 --> 00:05:01,600
simple for them

117
00:05:01,600 --> 00:05:04,800
as a result i would argue we have become

118
00:05:04,800 --> 00:05:07,520
so good at using technology to secure

119
00:05:07,520 --> 00:05:11,360
technology we excuse me we are literally

120
00:05:11,360 --> 00:05:14,240
driving the cyber attacker to target and

121
00:05:14,240 --> 00:05:18,160
hack the human in fact that is why i am

122
00:05:18,160 --> 00:05:18,960
not

123
00:05:18,960 --> 00:05:21,600
a fan of saying people are the weakest

124
00:05:21,600 --> 00:05:22,479
link

125
00:05:22,479 --> 00:05:25,360
that implies it is their fault

126
00:05:25,360 --> 00:05:28,639
i would argue in many ways it is our

127
00:05:28,639 --> 00:05:31,520
fault and that's why i prefer to say

128
00:05:31,520 --> 00:05:35,360
people are the primary attack vector in

129
00:05:35,360 --> 00:05:37,360
some ways it takes the blame off them

130
00:05:37,360 --> 00:05:39,280
and in some ways

131
00:05:39,280 --> 00:05:41,840
it puts it on us

132
00:05:41,840 --> 00:05:44,000
so that's really what i'm going to be

133
00:05:44,000 --> 00:05:46,400
talking about today how we can address

134
00:05:46,400 --> 00:05:50,080
the human element but primarily from a

135
00:05:50,080 --> 00:05:52,880
culture perspective

136
00:05:52,880 --> 00:05:53,600
so

137
00:05:53,600 --> 00:05:55,680
what is culture and

138
00:05:55,680 --> 00:05:58,240
why do i care it's that squishy thing

139
00:05:58,240 --> 00:05:59,919
that everybody talks about but really

140
00:05:59,919 --> 00:06:02,560
nobody knows what to do about

141
00:06:02,560 --> 00:06:03,680
culture

142
00:06:03,680 --> 00:06:06,479
is people's attitudes perceptions and

143
00:06:06,479 --> 00:06:07,520
beliefs

144
00:06:07,520 --> 00:06:10,400
and the idea of organizational culture

145
00:06:10,400 --> 00:06:12,240
is something that has been well

146
00:06:12,240 --> 00:06:15,840
researched over the past several decades

147
00:06:15,840 --> 00:06:17,440
hundreds if not thousands of

148
00:06:17,440 --> 00:06:20,479
publications books research and case

149
00:06:20,479 --> 00:06:21,520
studies

150
00:06:21,520 --> 00:06:25,120
and quite often culture is equated to an

151
00:06:25,120 --> 00:06:26,720
iceberg

152
00:06:26,720 --> 00:06:29,600
a culture like an iceberg can be hard to

153
00:06:29,600 --> 00:06:32,880
move and culture like an iceberg most of

154
00:06:32,880 --> 00:06:36,479
it is hard to see and measure

155
00:06:36,479 --> 00:06:39,199
if you would use the iceberg model

156
00:06:39,199 --> 00:06:41,120
everything below the water would be what

157
00:06:41,120 --> 00:06:43,680
people are thinking their attitudes

158
00:06:43,680 --> 00:06:46,400
perceptions and beliefs the only part we

159
00:06:46,400 --> 00:06:48,560
can really see are what people say and

160
00:06:48,560 --> 00:06:49,759
what people

161
00:06:49,759 --> 00:06:50,800
do

162
00:06:50,800 --> 00:06:53,199
so if culture is primarily what people

163
00:06:53,199 --> 00:06:55,680
think their attitudes perceptions and

164
00:06:55,680 --> 00:06:57,120
beliefs

165
00:06:57,120 --> 00:07:00,000
what is a security culture and really

166
00:07:00,000 --> 00:07:03,039
why do i care

167
00:07:03,039 --> 00:07:05,520
security culture are people's attitudes

168
00:07:05,520 --> 00:07:08,960
perceptions and beliefs about security

169
00:07:08,960 --> 00:07:10,479
quite often it's their attitudes

170
00:07:10,479 --> 00:07:12,479
perceptions and beliefs about your

171
00:07:12,479 --> 00:07:15,599
security team and your security policies

172
00:07:15,599 --> 00:07:18,240
because to them it's all the same thing

173
00:07:18,240 --> 00:07:20,560
so what are their attitudes perceptions

174
00:07:20,560 --> 00:07:23,360
and beliefs towards security

175
00:07:23,360 --> 00:07:27,120
and the reason we care is this

176
00:07:27,120 --> 00:07:30,479
the stronger your security culture is

177
00:07:30,479 --> 00:07:32,720
the more likely people will exhibit

178
00:07:32,720 --> 00:07:35,599
strong secure behaviors

179
00:07:35,599 --> 00:07:37,680
but also the stronger your security

180
00:07:37,680 --> 00:07:40,240
culture is the more likely all of your

181
00:07:40,240 --> 00:07:42,840
different security initiatives will

182
00:07:42,840 --> 00:07:45,599
succeed how many vulnerability

183
00:07:45,599 --> 00:07:47,680
management programs fail

184
00:07:47,680 --> 00:07:49,840
because there is a toxic culture between

185
00:07:49,840 --> 00:07:51,280
the security team

186
00:07:51,280 --> 00:07:53,599
and i t operations

187
00:07:53,599 --> 00:07:56,319
how many dev secops

188
00:07:56,319 --> 00:07:58,639
initiatives fail because there's a toxic

189
00:07:58,639 --> 00:08:00,960
culture between the security team and

190
00:08:00,960 --> 00:08:03,440
developers or you're doing a single

191
00:08:03,440 --> 00:08:06,560
sign-on roll-out fte roll-out mdm

192
00:08:06,560 --> 00:08:07,599
roll-out

193
00:08:07,599 --> 00:08:10,319
a lot of security initiatives fail

194
00:08:10,319 --> 00:08:13,280
because not of the technology

195
00:08:13,280 --> 00:08:15,440
but of the security

196
00:08:15,440 --> 00:08:17,520
culture it's one of those things that

197
00:08:17,520 --> 00:08:20,160
permeates everything we do and it's one

198
00:08:20,160 --> 00:08:22,800
of the reasons why organizations

199
00:08:22,800 --> 00:08:25,039
struggle so much

200
00:08:25,039 --> 00:08:28,720
securing their workforce

201
00:08:28,720 --> 00:08:30,319
so

202
00:08:30,319 --> 00:08:33,039
what are the indicators of a strong

203
00:08:33,039 --> 00:08:35,919
security culture now here is a couple of

204
00:08:35,919 --> 00:08:37,760
my favorite

205
00:08:37,760 --> 00:08:41,039
indicators but probably my absolute

206
00:08:41,039 --> 00:08:44,240
favorite indicator is the very first one

207
00:08:44,240 --> 00:08:46,720
if you read the very first one people

208
00:08:46,720 --> 00:08:50,160
feel safe reporting an incident

209
00:08:50,160 --> 00:08:52,880
even if they caused it

210
00:08:52,880 --> 00:08:55,760
now if you have a very punitive culture

211
00:08:55,760 --> 00:08:59,040
a very arrogant or egotistical security

212
00:08:59,040 --> 00:09:01,120
team people aren't going to want to

213
00:09:01,120 --> 00:09:03,519
report it in fact if they get their

214
00:09:03,519 --> 00:09:05,839
computer infected with ransomware and

215
00:09:05,839 --> 00:09:08,160
you have a very negative security

216
00:09:08,160 --> 00:09:09,120
culture

217
00:09:09,120 --> 00:09:11,040
they may actually think to themselves

218
00:09:11,040 --> 00:09:14,000
wow if i pay this ransom maybe i won't

219
00:09:14,000 --> 00:09:16,160
have to tell anybody that my computer

220
00:09:16,160 --> 00:09:18,080
got infected

221
00:09:18,080 --> 00:09:20,080
another one is when people are actively

222
00:09:20,080 --> 00:09:22,399
engaging your security team asking for

223
00:09:22,399 --> 00:09:24,959
help hey can you come to our meeting for

224
00:09:24,959 --> 00:09:27,120
briefings they're asking questions

225
00:09:27,120 --> 00:09:28,720
things like that

226
00:09:28,720 --> 00:09:31,440
if your workforce is avoiding your

227
00:09:31,440 --> 00:09:34,080
security team like the plague

228
00:09:34,080 --> 00:09:37,360
that's an indication of a weak security

229
00:09:37,360 --> 00:09:38,399
culture

230
00:09:38,399 --> 00:09:40,399
now i'm not going to read all of these

231
00:09:40,399 --> 00:09:42,480
you can read but these are just some of

232
00:09:42,480 --> 00:09:44,800
my favorite indicators if do we have a

233
00:09:44,800 --> 00:09:47,440
strong security culture or do we have a

234
00:09:47,440 --> 00:09:49,360
weak or even worse

235
00:09:49,360 --> 00:09:52,000
toxic security culture

236
00:09:52,000 --> 00:09:54,800
and if you're not able to answer yes to

237
00:09:54,800 --> 00:09:57,200
um some of these or if you're concerned

238
00:09:57,200 --> 00:10:00,880
that you have a more toxic culture

239
00:10:00,880 --> 00:10:02,880
that could be why you're running into so

240
00:10:02,880 --> 00:10:04,560
many issues

241
00:10:04,560 --> 00:10:07,279
now i know i get hey the security team

242
00:10:07,279 --> 00:10:10,000
goes but we're trying so hard we're

243
00:10:10,000 --> 00:10:11,440
reaching out to people we're

244
00:10:11,440 --> 00:10:13,920
communicating to people we're trying to

245
00:10:13,920 --> 00:10:16,560
enable people they're just not doing

246
00:10:16,560 --> 00:10:19,040
what we tell them to do they just don't

247
00:10:19,040 --> 00:10:20,720
understand us

248
00:10:20,720 --> 00:10:22,560
and i totally get it

249
00:10:22,560 --> 00:10:24,959
we perceive ourselves as the digital

250
00:10:24,959 --> 00:10:28,480
guardians of cyberspace worthy heroes to

251
00:10:28,480 --> 00:10:29,839
help people

252
00:10:29,839 --> 00:10:34,240
why don't they get it this is why

253
00:10:34,240 --> 00:10:37,839
you and i perceive that this is what we

254
00:10:37,839 --> 00:10:38,640
do

255
00:10:38,640 --> 00:10:41,200
but the problem is when we start sending

256
00:10:41,200 --> 00:10:43,680
emails to the workforce when we start

257
00:10:43,680 --> 00:10:46,480
talking to it admins or developers or

258
00:10:46,480 --> 00:10:49,519
accounts payable or to our leadership

259
00:10:49,519 --> 00:10:51,680
while we perceive this

260
00:10:51,680 --> 00:10:56,320
what they perceive what they see is this

261
00:10:56,320 --> 00:10:57,519
yes

262
00:10:57,519 --> 00:11:00,480
by the way can you name which movie this

263
00:11:00,480 --> 00:11:01,839
is from

264
00:11:01,839 --> 00:11:03,519
i'll give you a moment

265
00:11:03,519 --> 00:11:05,279
i will give you a hint

266
00:11:05,279 --> 00:11:08,880
if you know the name of this movie a it

267
00:11:08,880 --> 00:11:10,640
means you're nerd

268
00:11:10,640 --> 00:11:11,600
and b

269
00:11:11,600 --> 00:11:14,480
it means you're a really old nerd

270
00:11:14,480 --> 00:11:16,800
it's from the movie classic 80s movie

271
00:11:16,800 --> 00:11:20,000
revenge of the nerds highly recommended

272
00:11:20,000 --> 00:11:22,880
by the way but seriously the problem is

273
00:11:22,880 --> 00:11:23,680
this

274
00:11:23,680 --> 00:11:26,399
a lot of times when we are communicating

275
00:11:26,399 --> 00:11:29,839
to our workforce to our leadership

276
00:11:29,839 --> 00:11:32,160
updating people on our policies rolling

277
00:11:32,160 --> 00:11:33,760
out a new initiative

278
00:11:33,760 --> 00:11:36,160
we're speaking geek and to you and i we

279
00:11:36,160 --> 00:11:38,640
perceive it as really really simple

280
00:11:38,640 --> 00:11:40,800
and very very common sense but to the

281
00:11:40,800 --> 00:11:43,200
rest of the world we've totally lost

282
00:11:43,200 --> 00:11:44,399
them

283
00:11:44,399 --> 00:11:45,279
so

284
00:11:45,279 --> 00:11:46,800
what can we do

285
00:11:46,800 --> 00:11:49,279
well fortunately as i mentioned earlier

286
00:11:49,279 --> 00:11:52,079
there is an entire field of study on

287
00:11:52,079 --> 00:11:53,040
culture

288
00:11:53,040 --> 00:11:55,600
not security culture but just culture in

289
00:11:55,600 --> 00:11:56,399
general

290
00:11:56,399 --> 00:11:59,040
how to make your culture more innovative

291
00:11:59,040 --> 00:12:01,600
how to create a safety culture how to

292
00:12:01,600 --> 00:12:04,480
create a wellness culture and as i

293
00:12:04,480 --> 00:12:07,440
mentioned there are decades and decades

294
00:12:07,440 --> 00:12:10,160
and decades of research case studies

295
00:12:10,160 --> 00:12:11,760
scientific theory

296
00:12:11,760 --> 00:12:14,320
on organizational culture

297
00:12:14,320 --> 00:12:16,160
and these are just some of the many

298
00:12:16,160 --> 00:12:18,160
books that have really helped influence

299
00:12:18,160 --> 00:12:21,040
me and better understand culture because

300
00:12:21,040 --> 00:12:23,920
if we want to build a strong security

301
00:12:23,920 --> 00:12:25,120
culture

302
00:12:25,120 --> 00:12:27,120
let's not reinvent the wheel

303
00:12:27,120 --> 00:12:29,279
let's go all righty to what people have

304
00:12:29,279 --> 00:12:31,440
already discovered and researched in

305
00:12:31,440 --> 00:12:34,160
books like these and then apply them to

306
00:12:34,160 --> 00:12:36,000
our world

307
00:12:36,000 --> 00:12:38,079
far too often in cyber security we try

308
00:12:38,079 --> 00:12:39,760
to reinvent the wheel

309
00:12:39,760 --> 00:12:41,760
and instead of reinventing the wheel

310
00:12:41,760 --> 00:12:43,760
let's just build on the work of others

311
00:12:43,760 --> 00:12:45,760
and so these are all different types of

312
00:12:45,760 --> 00:12:48,560
research in organizational culture and

313
00:12:48,560 --> 00:12:50,560
what's interesting is as you begin to

314
00:12:50,560 --> 00:12:52,720
study all this research

315
00:12:52,720 --> 00:12:54,639
they're all pretty much saying the same

316
00:12:54,639 --> 00:12:55,680
thing

317
00:12:55,680 --> 00:12:57,200
so what i'm going to do in the short

318
00:12:57,200 --> 00:13:00,800
talk is synthesize two key lessons

319
00:13:00,800 --> 00:13:03,360
from all of this research to enable you

320
00:13:03,360 --> 00:13:06,639
to build a stronger security culture

321
00:13:06,639 --> 00:13:08,240
by the way if you're interested in

322
00:13:08,240 --> 00:13:10,720
starting research in this field all of

323
00:13:10,720 --> 00:13:13,279
these are from fantastic books but i

324
00:13:13,279 --> 00:13:15,120
recommend you start with this one as

325
00:13:15,120 --> 00:13:18,639
it's probably one of the easiest ones to

326
00:13:18,639 --> 00:13:21,040
get started in organizational culture

327
00:13:21,040 --> 00:13:23,600
behavior change the book right above it

328
00:13:23,600 --> 00:13:26,160
thinking fast and slow is probably the

329
00:13:26,160 --> 00:13:29,040
hardest one but daniel kahneman won the

330
00:13:29,040 --> 00:13:32,720
nobel prize for that book alone it also

331
00:13:32,720 --> 00:13:34,639
took me two to three months just to read

332
00:13:34,639 --> 00:13:36,480
that one book

333
00:13:36,480 --> 00:13:39,519
so what are the lessons learned well

334
00:13:39,519 --> 00:13:40,880
first of all

335
00:13:40,880 --> 00:13:44,079
our goal is not so much to change our

336
00:13:44,079 --> 00:13:46,320
organization's culture but to embed

337
00:13:46,320 --> 00:13:49,440
cyber security into the existing culture

338
00:13:49,440 --> 00:13:52,160
we want to align security with it and

339
00:13:52,160 --> 00:13:53,519
two

340
00:13:53,519 --> 00:13:55,760
changing culture is not about one big

341
00:13:55,760 --> 00:13:57,760
security initiative all right let's go

342
00:13:57,760 --> 00:14:00,000
out communicate all this stuff and six

343
00:14:00,000 --> 00:14:02,639
months later poof we have our culture

344
00:14:02,639 --> 00:14:04,959
there's really no such thing as a single

345
00:14:04,959 --> 00:14:06,959
culture initiative

346
00:14:06,959 --> 00:14:09,519
instead your security culture is driven

347
00:14:09,519 --> 00:14:12,160
by every time your workforce interacts

348
00:14:12,160 --> 00:14:14,000
with your security team

349
00:14:14,000 --> 00:14:16,399
every time your security team develops

350
00:14:16,399 --> 00:14:19,279
and or communicates a policy

351
00:14:19,279 --> 00:14:22,079
every time you and or your security team

352
00:14:22,079 --> 00:14:25,360
enforces a behavior or enforces a policy

353
00:14:25,360 --> 00:14:27,680
in other words the behaviors you reward

354
00:14:27,680 --> 00:14:28,800
and punish

355
00:14:28,800 --> 00:14:31,440
so your cultures over time

356
00:14:31,440 --> 00:14:34,959
are really driven by your security team

357
00:14:34,959 --> 00:14:37,199
and the policies they develop

358
00:14:37,199 --> 00:14:38,800
and enforce

359
00:14:38,800 --> 00:14:41,760
so what we need to do is take this

360
00:14:41,760 --> 00:14:44,000
scientific knowledge and apply it to our

361
00:14:44,000 --> 00:14:45,120
world

362
00:14:45,120 --> 00:14:46,639
and one of the very first things that

363
00:14:46,639 --> 00:14:49,120
you quickly learn and this is from

364
00:14:49,120 --> 00:14:51,120
daniel kahneman's book but of the others

365
00:14:51,120 --> 00:14:52,800
referencing also

366
00:14:52,800 --> 00:14:55,600
is in many ways people think and operate

367
00:14:55,600 --> 00:14:59,199
at two different levels system one and

368
00:14:59,199 --> 00:15:00,959
system two

369
00:15:00,959 --> 00:15:02,480
system one is

370
00:15:02,480 --> 00:15:03,760
emotion

371
00:15:03,760 --> 00:15:06,160
gut instinct

372
00:15:06,160 --> 00:15:09,120
system two is logic

373
00:15:09,120 --> 00:15:10,839
analytics

374
00:15:10,839 --> 00:15:13,600
rational we like to think the human

375
00:15:13,600 --> 00:15:16,240
brain is operating in system two at all

376
00:15:16,240 --> 00:15:18,639
times very logical rational but that's

377
00:15:18,639 --> 00:15:20,959
how we like to perceive ourselves like

378
00:15:20,959 --> 00:15:22,000
spock

379
00:15:22,000 --> 00:15:24,079
but all the different research has shown

380
00:15:24,079 --> 00:15:26,560
us that while humans can operate at a

381
00:15:26,560 --> 00:15:29,440
very logical rational level say you're

382
00:15:29,440 --> 00:15:32,639
solving a math problem the vast majority

383
00:15:32,639 --> 00:15:35,920
of the time by default you're

384
00:15:35,920 --> 00:15:39,040
operating at a very much gut instinct

385
00:15:39,040 --> 00:15:41,839
intuitive level malcolm gladwell's book

386
00:15:41,839 --> 00:15:44,480
blink is all about this

387
00:15:44,480 --> 00:15:46,560
and if you think about it it makes sense

388
00:15:46,560 --> 00:15:47,759
because

389
00:15:47,759 --> 00:15:49,920
operating from a very emotional gut

390
00:15:49,920 --> 00:15:52,880
instinct intuition kind of perspective

391
00:15:52,880 --> 00:15:56,079
saves calories saves energy just gets us

392
00:15:56,079 --> 00:15:57,680
straight to the point

393
00:15:57,680 --> 00:15:59,440
so system two

394
00:15:59,440 --> 00:16:01,759
logic rationalize

395
00:16:01,759 --> 00:16:04,720
think dr spock

396
00:16:04,720 --> 00:16:08,639
intuitive gut instinct emotion think

397
00:16:08,639 --> 00:16:10,399
homer simpson

398
00:16:10,399 --> 00:16:12,320
the whole reason i'm bringing this up is

399
00:16:12,320 --> 00:16:13,360
this

400
00:16:13,360 --> 00:16:16,639
people by default including me and you

401
00:16:16,639 --> 00:16:19,120
our brain prefers to operate in the

402
00:16:19,120 --> 00:16:21,199
homer simpson mode the emotional mode

403
00:16:21,199 --> 00:16:23,920
it's just simpler and faster we only

404
00:16:23,920 --> 00:16:26,800
engage the spock mode system two when we

405
00:16:26,800 --> 00:16:28,160
have to

406
00:16:28,160 --> 00:16:30,639
why is this important because i tend to

407
00:16:30,639 --> 00:16:33,519
see everything in cyber security is

408
00:16:33,519 --> 00:16:36,720
design architected and communicated

409
00:16:36,720 --> 00:16:40,000
assuming dr spock

410
00:16:40,000 --> 00:16:42,800
in reality all of our policies all of

411
00:16:42,800 --> 00:16:44,639
our communication and all of our

412
00:16:44,639 --> 00:16:45,680
outreach

413
00:16:45,680 --> 00:16:46,720
should be

414
00:16:46,720 --> 00:16:49,440
for homer simpson and i'm not saying

415
00:16:49,440 --> 00:16:51,920
people are stupid i'm just saying

416
00:16:51,920 --> 00:16:55,360
by human nature we tend to operate from

417
00:16:55,360 --> 00:16:59,199
a very emotional intuitive perspective

418
00:16:59,199 --> 00:17:01,040
so hopefully you're already beginning to

419
00:17:01,040 --> 00:17:01,839
see

420
00:17:01,839 --> 00:17:03,279
why we're running issues with our

421
00:17:03,279 --> 00:17:05,439
security architecture policies things

422
00:17:05,439 --> 00:17:08,480
like that when we start bringing in

423
00:17:08,480 --> 00:17:09,760
people

424
00:17:09,760 --> 00:17:11,199
so when it comes to building that

425
00:17:11,199 --> 00:17:12,480
culture

426
00:17:12,480 --> 00:17:13,760
what can we do

427
00:17:13,760 --> 00:17:16,240
well we need to apply force

428
00:17:16,240 --> 00:17:18,160
of change

429
00:17:18,160 --> 00:17:20,720
but people are just like mass or an

430
00:17:20,720 --> 00:17:22,959
object remember newton's famous first

431
00:17:22,959 --> 00:17:26,000
law an object at rest stays at rest

432
00:17:26,000 --> 00:17:28,480
unless we apply a force and that force

433
00:17:28,480 --> 00:17:31,200
was mass times acceleration

434
00:17:31,200 --> 00:17:33,200
exact same thing for people all the

435
00:17:33,200 --> 00:17:35,919
research shows by nature people don't

436
00:17:35,919 --> 00:17:38,880
change the way they think or behave

437
00:17:38,880 --> 00:17:41,679
unless a force is applied and we too are

438
00:17:41,679 --> 00:17:43,919
going to apply a force but instead of m

439
00:17:43,919 --> 00:17:47,120
a we're calling it an e because it's all

440
00:17:47,120 --> 00:17:48,799
about me

441
00:17:48,799 --> 00:17:51,120
uh actually what we're going to do is me

442
00:17:51,120 --> 00:17:54,480
stands for motivate and enable

443
00:17:54,480 --> 00:17:56,799
and this is what i mean by it

444
00:17:56,799 --> 00:17:59,360
anytime you're communicating to your

445
00:17:59,360 --> 00:18:01,679
workforce anytime you're developing or

446
00:18:01,679 --> 00:18:03,919
architecting a policy process or

447
00:18:03,919 --> 00:18:06,559
procedure anytime you need to enforce

448
00:18:06,559 --> 00:18:09,520
good or bad behaviors apply the me

449
00:18:09,520 --> 00:18:12,640
principle and the me principle is how

450
00:18:12,640 --> 00:18:15,200
can we motivate people about cyber

451
00:18:15,200 --> 00:18:18,640
security and how can we enable cyber

452
00:18:18,640 --> 00:18:19,760
security

453
00:18:19,760 --> 00:18:22,880
now you could spend days on these topics

454
00:18:22,880 --> 00:18:24,880
alone and in fact i do i teach a

455
00:18:24,880 --> 00:18:28,480
five-day course on security culture but

456
00:18:28,480 --> 00:18:31,039
at the highest level you can use a

457
00:18:31,039 --> 00:18:32,880
variety of different models and

458
00:18:32,880 --> 00:18:34,960
frameworks to both motivate

459
00:18:34,960 --> 00:18:36,720
and enable

460
00:18:36,720 --> 00:18:39,520
people with from a cyber security

461
00:18:39,520 --> 00:18:41,760
perspective and i'm just going to do the

462
00:18:41,760 --> 00:18:45,120
highest briefest overview of both of

463
00:18:45,120 --> 00:18:47,280
these starting with

464
00:18:47,280 --> 00:18:48,880
motivate

465
00:18:48,880 --> 00:18:50,000
now

466
00:18:50,000 --> 00:18:53,200
the key number one takeaway from

467
00:18:53,200 --> 00:18:55,760
motivation is this concept called start

468
00:18:55,760 --> 00:18:56,960
with why

469
00:18:56,960 --> 00:18:59,360
lots of great books on this concept lots

470
00:18:59,360 --> 00:19:02,160
of great research models and frameworks

471
00:19:02,160 --> 00:19:05,200
ad car cutters don cotter's eight steps

472
00:19:05,200 --> 00:19:08,400
the book switch made to stick

473
00:19:08,400 --> 00:19:11,039
but my favorite is this simon cynic

474
00:19:11,039 --> 00:19:14,080
start with y that's the name of the book

475
00:19:14,080 --> 00:19:16,080
but the book really centers around what

476
00:19:16,080 --> 00:19:18,480
he calls the golden circle and there is

477
00:19:18,480 --> 00:19:21,919
a mind-blowing 17-minute talk about the

478
00:19:21,919 --> 00:19:24,960
golden circle on ted ted talks just do

479
00:19:24,960 --> 00:19:28,720
ted talk golden circle in google boom

480
00:19:28,720 --> 00:19:30,240
it's awesome

481
00:19:30,240 --> 00:19:32,799
and ultimately what simon shows us is

482
00:19:32,799 --> 00:19:35,919
the most influential leaders the best

483
00:19:35,919 --> 00:19:38,640
marketing programs uh mark best

484
00:19:38,640 --> 00:19:40,960
marketing initiatives things like that

485
00:19:40,960 --> 00:19:42,960
apply the golden circle

486
00:19:42,960 --> 00:19:45,120
and what you don't want to do is start

487
00:19:45,120 --> 00:19:48,000
your communications to people or your

488
00:19:48,000 --> 00:19:50,320
marketing initiatives to people with the

489
00:19:50,320 --> 00:19:53,200
what and the how but you always want to

490
00:19:53,200 --> 00:19:56,080
start with the why if you can explain

491
00:19:56,080 --> 00:19:58,640
why something is important

492
00:19:58,640 --> 00:20:01,039
why people are going to benefit

493
00:20:01,039 --> 00:20:03,200
why it's all about me

494
00:20:03,200 --> 00:20:05,679
they're far more likely to engage

495
00:20:05,679 --> 00:20:07,760
you're far more likely to motivate

496
00:20:07,760 --> 00:20:08,640
people

497
00:20:08,640 --> 00:20:10,640
and if you think about it

498
00:20:10,640 --> 00:20:13,440
this is why so many security initiatives

499
00:20:13,440 --> 00:20:14,320
fail

500
00:20:14,320 --> 00:20:16,480
security teams it's not that security

501
00:20:16,480 --> 00:20:18,559
teams are bad at communicating the why

502
00:20:18,559 --> 00:20:21,919
it's in a lot of cases we never try

503
00:20:21,919 --> 00:20:24,799
we never even think about it to us the

504
00:20:24,799 --> 00:20:27,200
wide part is just common sense everyone

505
00:20:27,200 --> 00:20:28,559
should know

506
00:20:28,559 --> 00:20:31,120
or we just mandate it and then we take a

507
00:20:31,120 --> 00:20:35,200
baseball bat why because i said so

508
00:20:35,200 --> 00:20:36,799
and then we wonder why there's so much

509
00:20:36,799 --> 00:20:39,360
resistance why people don't do what we

510
00:20:39,360 --> 00:20:41,760
ask them or tell them to do

511
00:20:41,760 --> 00:20:43,840
we have to start all of our

512
00:20:43,840 --> 00:20:46,559
communications and initiatives you know

513
00:20:46,559 --> 00:20:48,320
rolling out a vulnerability management

514
00:20:48,320 --> 00:20:51,120
program make sure itops first buys into

515
00:20:51,120 --> 00:20:54,080
the why rolling up devsecops makes your

516
00:20:54,080 --> 00:20:57,760
developers buy into the why

517
00:20:57,760 --> 00:20:59,760
one of my absolute favorite ways to

518
00:20:59,760 --> 00:21:01,600
explain this is

519
00:21:01,600 --> 00:21:04,559
password managers a lot of organizations

520
00:21:04,559 --> 00:21:07,200
are rolling out password managers to

521
00:21:07,200 --> 00:21:09,200
their workforce

522
00:21:09,200 --> 00:21:10,000
so

523
00:21:10,000 --> 00:21:13,200
making passwords easier for them

524
00:21:13,200 --> 00:21:16,240
and quite often i'll see a password

525
00:21:16,240 --> 00:21:18,480
manager roll out

526
00:21:18,480 --> 00:21:20,400
something like this

527
00:21:20,400 --> 00:21:22,960
the security team will roll out an email

528
00:21:22,960 --> 00:21:24,960
monday morning and then tell everybody

529
00:21:24,960 --> 00:21:28,320
okay folks starting this week everybody

530
00:21:28,320 --> 00:21:31,039
has to implement password managers this

531
00:21:31,039 --> 00:21:32,640
is what they are

532
00:21:32,640 --> 00:21:35,200
and this is how you use them

533
00:21:35,200 --> 00:21:37,440
good luck you have to be doing it by

534
00:21:37,440 --> 00:21:40,880
friday we never even consider explaining

535
00:21:40,880 --> 00:21:43,280
the why and then we wonder why there's

536
00:21:43,280 --> 00:21:46,000
all this resistance in fact i have a

537
00:21:46,000 --> 00:21:49,360
great example right here of a typical

538
00:21:49,360 --> 00:21:51,600
email sent out by security teams

539
00:21:51,600 --> 00:21:53,440
announcing a

540
00:21:53,440 --> 00:21:56,720
password manager rollout a it tends to

541
00:21:56,720 --> 00:21:58,559
be too technical by the way i'm just

542
00:21:58,559 --> 00:22:00,320
gonna let you read this i'm not gonna

543
00:22:00,320 --> 00:22:03,120
read it but a it tends to be technical

544
00:22:03,120 --> 00:22:05,280
easy for us to understand but for most

545
00:22:05,280 --> 00:22:07,039
of the workforce

546
00:22:07,039 --> 00:22:09,360
nerds they don't get it we're confusing

547
00:22:09,360 --> 00:22:10,159
them

548
00:22:10,159 --> 00:22:12,240
two quite often when we're explaining

549
00:22:12,240 --> 00:22:13,919
the value of something it's all about

550
00:22:13,919 --> 00:22:16,240
the security team and how to secure the

551
00:22:16,240 --> 00:22:17,360
company

552
00:22:17,360 --> 00:22:20,480
remember people are not rational they're

553
00:22:20,480 --> 00:22:23,360
emotional when you explain why something

554
00:22:23,360 --> 00:22:25,919
is important to the company people will

555
00:22:25,919 --> 00:22:28,640
get it but then they forget it but if

556
00:22:28,640 --> 00:22:30,960
you explain why it's important to them

557
00:22:30,960 --> 00:22:33,440
they're far more likely to get excited

558
00:22:33,440 --> 00:22:36,559
they're far more likely to buy in and

559
00:22:36,559 --> 00:22:38,960
that is where you start building your

560
00:22:38,960 --> 00:22:41,120
strong security culture

561
00:22:41,120 --> 00:22:43,360
if you announce a password manager

562
00:22:43,360 --> 00:22:45,840
program or initiative like this right

563
00:22:45,840 --> 00:22:46,880
here

564
00:22:46,880 --> 00:22:48,559
people are just going to tune you out

565
00:22:48,559 --> 00:22:50,159
they're going to be oh great another

566
00:22:50,159 --> 00:22:52,559
thing mandated by the security team

567
00:22:52,559 --> 00:22:54,400
they're always a pain in the ass i can

568
00:22:54,400 --> 00:22:56,799
never understand their emails why are

569
00:22:56,799 --> 00:22:58,960
these people so egotistical arrogant

570
00:22:58,960 --> 00:23:00,400
confusing

571
00:23:00,400 --> 00:23:03,200
technical they're a pain in the ass

572
00:23:03,200 --> 00:23:05,039
and then you underst

573
00:23:05,039 --> 00:23:06,559
you don't understand why you have that

574
00:23:06,559 --> 00:23:08,799
negative security culture

575
00:23:08,799 --> 00:23:10,799
whereas think about it if we applied

576
00:23:10,799 --> 00:23:13,600
this concept of start with why and we

577
00:23:13,600 --> 00:23:16,000
explain with people hey do you hate

578
00:23:16,000 --> 00:23:18,640
passwords you know what the security

579
00:23:18,640 --> 00:23:20,159
team does too

580
00:23:20,159 --> 00:23:22,320
but we've got this awesome solution

581
00:23:22,320 --> 00:23:24,240
that's going to make your life so much

582
00:23:24,240 --> 00:23:27,039
simpler it will remember passwords for

583
00:23:27,039 --> 00:23:29,919
you it will log you into websites for

584
00:23:29,919 --> 00:23:32,799
you it will generate passwords for you

585
00:23:32,799 --> 00:23:35,520
it will verify the authenticity of

586
00:23:35,520 --> 00:23:37,360
websites for you

587
00:23:37,360 --> 00:23:40,320
even more exciting our vendor has given

588
00:23:40,320 --> 00:23:42,960
us a free copy to give to all of you to

589
00:23:42,960 --> 00:23:45,279
use for your personal use at home and

590
00:23:45,279 --> 00:23:48,559
help secure your family

591
00:23:48,559 --> 00:23:49,360
now

592
00:23:49,360 --> 00:23:52,640
both emails exact same thing announced a

593
00:23:52,640 --> 00:23:54,559
security initiative called password

594
00:23:54,559 --> 00:23:57,200
managers but the first one was very

595
00:23:57,200 --> 00:23:59,760
technical and all about why or how it

596
00:23:59,760 --> 00:24:01,919
benefited the company

597
00:24:01,919 --> 00:24:04,799
this one is all about hey we're solving

598
00:24:04,799 --> 00:24:06,559
your problems we're making your life

599
00:24:06,559 --> 00:24:08,240
simpler and we're going to make you more

600
00:24:08,240 --> 00:24:12,080
secure not only at work but at home

601
00:24:12,080 --> 00:24:15,279
the security teams looking out for you

602
00:24:15,279 --> 00:24:17,679
now we're the heroes now we're building

603
00:24:17,679 --> 00:24:19,919
a stronger culture now people are

604
00:24:19,919 --> 00:24:21,520
banging on your door

605
00:24:21,520 --> 00:24:24,240
how do i get this password manager thing

606
00:24:24,240 --> 00:24:27,760
you can do this same thing for 2fa fde

607
00:24:27,760 --> 00:24:30,799
vpn or whatever initiatives

608
00:24:30,799 --> 00:24:33,600
you have going out there it just takes a

609
00:24:33,600 --> 00:24:36,880
brief moment and explain the why

610
00:24:36,880 --> 00:24:38,640
but the other side of the coin is the

611
00:24:38,640 --> 00:24:41,440
enable far too often we make cyber

612
00:24:41,440 --> 00:24:44,240
security really hard for people

613
00:24:44,240 --> 00:24:47,200
yes you and i perceive it as simple but

614
00:24:47,200 --> 00:24:49,919
yes it's our job it's our passion and we

615
00:24:49,919 --> 00:24:52,159
deal with it every day have you ever

616
00:24:52,159 --> 00:24:54,240
gone to a tax accountant and they start

617
00:24:54,240 --> 00:24:55,840
speaking their lingo and you're like

618
00:24:55,840 --> 00:24:58,320
what are they saying or a doctor or a

619
00:24:58,320 --> 00:25:00,559
lawyer or a mechanic

620
00:25:00,559 --> 00:25:02,720
we got to remember just because it's

621
00:25:02,720 --> 00:25:05,120
easy for us it doesn't mean it's easy

622
00:25:05,120 --> 00:25:07,919
for them so we want to architect an

623
00:25:07,919 --> 00:25:10,159
environment where people are going to

624
00:25:10,159 --> 00:25:13,120
find it as easy as possible to do what

625
00:25:13,120 --> 00:25:14,720
we want them to do

626
00:25:14,720 --> 00:25:17,360
for example at chippell airport

627
00:25:17,360 --> 00:25:20,559
they had a problem with spillage

628
00:25:20,559 --> 00:25:21,840
in other words

629
00:25:21,840 --> 00:25:23,679
this was only happening in the boys room

630
00:25:23,679 --> 00:25:25,679
in the men's room but in the case of the

631
00:25:25,679 --> 00:25:28,400
urinals men were consistently

632
00:25:28,400 --> 00:25:31,919
missing in the urinals making a mess

633
00:25:31,919 --> 00:25:33,919
so instead of creating all these signs

634
00:25:33,919 --> 00:25:36,240
telling people or telling all the men

635
00:25:36,240 --> 00:25:39,039
how to improve their aim

636
00:25:39,039 --> 00:25:41,919
they simply put a sticker of a fly or a

637
00:25:41,919 --> 00:25:43,520
spider at the bottom of the men's

638
00:25:43,520 --> 00:25:46,559
urinals and as a result

639
00:25:46,559 --> 00:25:49,200
eighty percent reduction in spillage

640
00:25:49,200 --> 00:25:52,080
eight percent overall reduction in costs

641
00:25:52,080 --> 00:25:54,240
radical change in behavior

642
00:25:54,240 --> 00:25:56,559
all by architecting environment to get

643
00:25:56,559 --> 00:25:59,120
people to do what we want him to do but

644
00:25:59,120 --> 00:26:00,240
in this case

645
00:26:00,240 --> 00:26:03,200
with a simple sticker

646
00:26:03,200 --> 00:26:05,760
the other flip side is not only

647
00:26:05,760 --> 00:26:07,919
architecting an environment where we get

648
00:26:07,919 --> 00:26:10,240
people to do whatever we want them to do

649
00:26:10,240 --> 00:26:11,600
but

650
00:26:11,600 --> 00:26:14,799
provide as little information as

651
00:26:14,799 --> 00:26:17,600
possible far too often in cyber security

652
00:26:17,600 --> 00:26:20,720
we overwhelm people with tips tricks

653
00:26:20,720 --> 00:26:24,000
choices attack nectars things like that

654
00:26:24,000 --> 00:26:26,720
the fewer behaviors we teach

655
00:26:26,720 --> 00:26:29,520
the simpler we make cyber security and

656
00:26:29,520 --> 00:26:31,120
the more likely they'll exhibit the

657
00:26:31,120 --> 00:26:33,120
behaviors we want

658
00:26:33,120 --> 00:26:35,120
let me just give you a quick example and

659
00:26:35,120 --> 00:26:37,360
then we're going to wrap things up

660
00:26:37,360 --> 00:26:40,240
passwords huge pain point nobody does

661
00:26:40,240 --> 00:26:42,240
what we ask them to do

662
00:26:42,240 --> 00:26:44,080
but if you think about it we've made

663
00:26:44,080 --> 00:26:46,400
passwords really really complex we're

664
00:26:46,400 --> 00:26:48,559
telling people hey folks passwords are

665
00:26:48,559 --> 00:26:51,760
so simple 16 characters uppercase

666
00:26:51,760 --> 00:26:54,720
lowercase symbol number mixing the blood

667
00:26:54,720 --> 00:26:57,360
of a virgin oh by the way

668
00:26:57,360 --> 00:26:59,360
every password has to be unique for

669
00:26:59,360 --> 00:27:02,320
every account and change them every 90

670
00:27:02,320 --> 00:27:04,320
days and by the way

671
00:27:04,320 --> 00:27:06,480
you can't write them down

672
00:27:06,480 --> 00:27:08,960
but what can we do going through that

673
00:27:08,960 --> 00:27:11,440
process and simplifying it so people do

674
00:27:11,440 --> 00:27:13,600
exhibit the behaviors we want

675
00:27:13,600 --> 00:27:15,279
first start with

676
00:27:15,279 --> 00:27:17,279
password expiration

677
00:27:17,279 --> 00:27:20,159
that's a very very painful costly

678
00:27:20,159 --> 00:27:23,279
behavior that 20 years ago

679
00:27:23,279 --> 00:27:25,840
may have had value but in today's world

680
00:27:25,840 --> 00:27:27,520
has no value

681
00:27:27,520 --> 00:27:30,080
nowadays if a bad guy gets your password

682
00:27:30,080 --> 00:27:32,000
they get it right away they're not going

683
00:27:32,000 --> 00:27:35,360
to wait 90 days before they use it

684
00:27:35,360 --> 00:27:38,000
two if you think having everyone in your

685
00:27:38,000 --> 00:27:40,159
organization change that number one at

686
00:27:40,159 --> 00:27:42,480
the end of the password to a number two

687
00:27:42,480 --> 00:27:44,080
has any value

688
00:27:44,080 --> 00:27:46,720
well we're really misguiding ourselves

689
00:27:46,720 --> 00:27:48,880
and then finally quite often password

690
00:27:48,880 --> 00:27:51,360
expiration has password history

691
00:27:51,360 --> 00:27:53,200
which means there's multiple hashes now

692
00:27:53,200 --> 00:27:55,360
for the bad guys to crack so first of

693
00:27:55,360 --> 00:27:57,360
all password expiration

694
00:27:57,360 --> 00:27:59,760
in most cases we can get rid of

695
00:27:59,760 --> 00:28:02,720
but can we replace our pro policies with

696
00:28:02,720 --> 00:28:04,240
technology two

697
00:28:04,240 --> 00:28:06,880
i love things like biometrics or single

698
00:28:06,880 --> 00:28:08,000
sign-on

699
00:28:08,000 --> 00:28:11,600
they make passwords so simple

700
00:28:11,600 --> 00:28:13,840
so are there passwords or policies what

701
00:28:13,840 --> 00:28:16,000
can we eliminate can we replace them

702
00:28:16,000 --> 00:28:19,120
with technologies can we simplify the

703
00:28:19,120 --> 00:28:20,320
policies

704
00:28:20,320 --> 00:28:22,480
absolutely when it comes to passwords

705
00:28:22,480 --> 00:28:26,640
eliminate complexity replace with length

706
00:28:26,640 --> 00:28:30,320
pass phrases length is the new entropy

707
00:28:30,320 --> 00:28:33,679
multiple words easier to remember

708
00:28:33,679 --> 00:28:35,360
easier to type

709
00:28:35,360 --> 00:28:38,399
if we can't remove the policy if we

710
00:28:38,399 --> 00:28:40,720
can't replace it with technology if we

711
00:28:40,720 --> 00:28:43,279
can't simplify the policy then can we

712
00:28:43,279 --> 00:28:46,640
give people tools to make the job easier

713
00:28:46,640 --> 00:28:48,159
and this is where things like where

714
00:28:48,159 --> 00:28:51,360
password managers are fantastic

715
00:28:51,360 --> 00:28:53,279
and this would be a great process to

716
00:28:53,279 --> 00:28:56,399
apply to your most painful policies what

717
00:28:56,399 --> 00:28:58,320
are the policies that people hate the

718
00:28:58,320 --> 00:29:00,880
most or have difficulty following or

719
00:29:00,880 --> 00:29:03,120
complain about the most instead of

720
00:29:03,120 --> 00:29:04,559
blaming them

721
00:29:04,559 --> 00:29:06,080
take a step back

722
00:29:06,080 --> 00:29:08,080
go through this process

723
00:29:08,080 --> 00:29:11,360
the simpler we make cyber security

724
00:29:11,360 --> 00:29:13,760
not only will more likely will people do

725
00:29:13,760 --> 00:29:16,320
it but the simpler we make it the more

726
00:29:16,320 --> 00:29:18,960
they like us that is one of the key

727
00:29:18,960 --> 00:29:21,200
fundamental approaches

728
00:29:21,200 --> 00:29:24,399
to building your strong security culture

729
00:29:24,399 --> 00:29:27,120
and then find fun easy ways for people

730
00:29:27,120 --> 00:29:29,440
to consume and understand it

731
00:29:29,440 --> 00:29:30,720
policies

732
00:29:30,720 --> 00:29:32,960
security communications things like that

733
00:29:32,960 --> 00:29:35,440
tend to be very technical and or very

734
00:29:35,440 --> 00:29:37,120
legal

735
00:29:37,120 --> 00:29:39,159
here's an awesome idea

736
00:29:39,159 --> 00:29:41,760
usaa one of the largest banks in the

737
00:29:41,760 --> 00:29:45,440
united states um based in where texas by

738
00:29:45,440 --> 00:29:48,720
the way down in san antonio uh huge fans

739
00:29:48,720 --> 00:29:51,200
of them and they actually for their

740
00:29:51,200 --> 00:29:53,600
customer support team document their

741
00:29:53,600 --> 00:29:55,919
policies and processes

742
00:29:55,919 --> 00:29:58,559
using a comic book

743
00:29:58,559 --> 00:30:00,480
and what they've done is it's the same

744
00:30:00,480 --> 00:30:02,159
policies you would find in a real

745
00:30:02,159 --> 00:30:04,000
security policy book but they're

746
00:30:04,000 --> 00:30:06,159
communicating in a way that's easy for

747
00:30:06,159 --> 00:30:08,799
people to understand remember just

748
00:30:08,799 --> 00:30:11,360
because you or i understand it doesn't

749
00:30:11,360 --> 00:30:13,760
mean it's simple for other people

750
00:30:13,760 --> 00:30:16,399
take your policy ask your mom to read it

751
00:30:16,399 --> 00:30:19,520
if mom can't understand it then perhaps

752
00:30:19,520 --> 00:30:22,000
most of your workforce can't understand

753
00:30:22,000 --> 00:30:23,760
it also

754
00:30:23,760 --> 00:30:25,600
all right we're wrapping things up

755
00:30:25,600 --> 00:30:27,840
couple of key takeaways first and

756
00:30:27,840 --> 00:30:31,360
foremost a strong security culture

757
00:30:31,360 --> 00:30:34,559
enables you to have a more secure

758
00:30:34,559 --> 00:30:36,880
workforce but also more successful

759
00:30:36,880 --> 00:30:38,799
security initiatives

760
00:30:38,799 --> 00:30:40,960
by security culture i mean people's

761
00:30:40,960 --> 00:30:43,120
attitudes perceptions and beliefs

762
00:30:43,120 --> 00:30:46,080
towards cyber security and really that

763
00:30:46,080 --> 00:30:49,679
is driven by how your security team

764
00:30:49,679 --> 00:30:52,000
interacts with the workforce the emails

765
00:30:52,000 --> 00:30:53,919
they send out the conversations they

766
00:30:53,919 --> 00:30:57,360
have on slack the policies you develop

767
00:30:57,360 --> 00:31:00,720
and the behaviors you enforce either

768
00:31:00,720 --> 00:31:03,519
reward or punish

769
00:31:03,519 --> 00:31:05,679
really really recommend partnering with

770
00:31:05,679 --> 00:31:08,240
your communications team having them

771
00:31:08,240 --> 00:31:10,960
help you build communications that a

772
00:31:10,960 --> 00:31:14,559
everybody understands but b starts with

773
00:31:14,559 --> 00:31:15,440
why

774
00:31:15,440 --> 00:31:17,279
anytime you communicate to your

775
00:31:17,279 --> 00:31:19,440
workforce start with why should they

776
00:31:19,440 --> 00:31:23,360
care and from a personal level remember

777
00:31:23,360 --> 00:31:26,640
we're communicating to homer not spock

778
00:31:26,640 --> 00:31:29,200
finally we want to make security as

779
00:31:29,200 --> 00:31:32,080
simple as possible communicate as few

780
00:31:32,080 --> 00:31:34,880
tips and as few policies as possible and

781
00:31:34,880 --> 00:31:38,000
the policies and tips you do communicate

782
00:31:38,000 --> 00:31:41,039
make them simple to understand consume

783
00:31:41,039 --> 00:31:42,640
and follow

784
00:31:42,640 --> 00:31:44,960
all right folks that was fast and

785
00:31:44,960 --> 00:31:46,720
furious this is something i'm really

786
00:31:46,720 --> 00:31:48,320
really passionate about and this is

787
00:31:48,320 --> 00:31:50,240
something we're hearing more and more

788
00:31:50,240 --> 00:31:51,360
about

789
00:31:51,360 --> 00:31:54,240
security is no longer just a technical

790
00:31:54,240 --> 00:31:57,120
challenge it's a human challenge also

791
00:31:57,120 --> 00:31:59,679
and until we start addressing both sides

792
00:31:59,679 --> 00:32:01,039
of that coin

793
00:32:01,039 --> 00:32:03,440
we are going to continue to lose this

794
00:32:03,440 --> 00:32:04,399
battle

795
00:32:04,399 --> 00:32:06,799
as promised if you have any questions i

796
00:32:06,799 --> 00:32:08,960
would love to hear from you this is my

797
00:32:08,960 --> 00:32:11,440
work email address otherwise thank you

798
00:32:11,440 --> 00:32:16,640
so much stay safe out there bye-bye

