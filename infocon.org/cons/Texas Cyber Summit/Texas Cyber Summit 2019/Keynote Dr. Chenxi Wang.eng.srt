1
00:00:46,040 --> 00:00:54,930
hello alright everybody thanks for your

2
00:00:49,620 --> 00:00:57,510
patience without further ado I am going

3
00:00:54,930 --> 00:01:08,580
to introduce our next keynote speaker

4
00:00:57,510 --> 00:01:14,190
dr. Chang C Wang thank you good morning

5
00:01:08,580 --> 00:01:16,320
Texas very happy to be here I live in

6
00:01:14,190 --> 00:01:19,350
California I don't get to Texas that

7
00:01:16,320 --> 00:01:24,839
often but I love Texas barbecue so thank

8
00:01:19,350 --> 00:01:27,899
you for having me I am going to talk

9
00:01:24,840 --> 00:01:31,979
about mostly today about artificial

10
00:01:27,899 --> 00:01:34,710
intelligence and what the impact is to

11
00:01:31,979 --> 00:01:38,250
cyber security so a little bit about

12
00:01:34,710 --> 00:01:41,059
myself I'm the founder and general

13
00:01:38,250 --> 00:01:44,880
partner of a cyber focused venture fund

14
00:01:41,060 --> 00:01:47,790
called ring capital I'm also on the

15
00:01:44,880 --> 00:01:51,179
board global board for Oh wasp and which

16
00:01:47,790 --> 00:01:53,939
I trust a lot of you are members of I'm

17
00:01:51,180 --> 00:01:58,110
also a member of the board of directors

18
00:01:53,939 --> 00:01:59,630
of and the resources which is a public

19
00:01:58,110 --> 00:02:02,460
utility company

20
00:01:59,630 --> 00:02:04,220
so other than serving on boards and

21
00:02:02,460 --> 00:02:07,320
doing investment I'm actually a

22
00:02:04,220 --> 00:02:11,940
cybersecurity person been trained in

23
00:02:07,320 --> 00:02:15,030
cyber security technology been in the

24
00:02:11,940 --> 00:02:19,109
industry for a long time and I also have

25
00:02:15,030 --> 00:02:23,160
a PhD in computer science all right

26
00:02:19,110 --> 00:02:25,560
so part of my work even though I do

27
00:02:23,160 --> 00:02:28,769
investment a lot part of my work is to

28
00:02:25,560 --> 00:02:30,580
understand cutting edge technology and

29
00:02:28,769 --> 00:02:33,690
understand how to

30
00:02:30,580 --> 00:02:40,120
evaluate technologies as well as

31
00:02:33,690 --> 00:02:44,040
business so recently I had to go to

32
00:02:40,120 --> 00:02:47,140
Australia again for a board meeting and

33
00:02:44,040 --> 00:02:49,690
Here I am in the morning I had to give a

34
00:02:47,140 --> 00:02:52,630
talk on an event in San Francisco so I

35
00:02:49,690 --> 00:02:55,840
just packed my stuff and got in the uber

36
00:02:52,630 --> 00:02:59,290
and went to they event and give a talk

37
00:02:55,840 --> 00:03:02,410
and then afternoon like another we were

38
00:02:59,290 --> 00:03:06,670
you know to the airport and I came out a

39
00:03:02,410 --> 00:03:09,700
little bit and I was like I didn't have

40
00:03:06,670 --> 00:03:12,250
my passport okay so I was flying to

41
00:03:09,700 --> 00:03:15,310
Australia because I'm so used to getting

42
00:03:12,250 --> 00:03:18,760
on the plane and just have my driver

43
00:03:15,310 --> 00:03:21,370
license and stuff so so I I called my

44
00:03:18,760 --> 00:03:24,750
husband and luckily I had enough time

45
00:03:21,370 --> 00:03:29,440
and he dropped everything and brought

46
00:03:24,750 --> 00:03:30,810
passport to me so I was fine as I got

47
00:03:29,440 --> 00:03:33,160
through the customer got through

48
00:03:30,810 --> 00:03:35,440
security and everything got on playing

49
00:03:33,160 --> 00:03:38,859
and I was flying to Sydney and

50
00:03:35,440 --> 00:03:40,720
connecting at Auckland New Zealand so I

51
00:03:38,860 --> 00:03:42,430
came out of playing an awkward waiting

52
00:03:40,720 --> 00:03:44,260
for my connection fly out of the local

53
00:03:42,430 --> 00:03:48,120
jet lie don't want to go buy a cup of

54
00:03:44,260 --> 00:03:53,649
coffee I went to the coffee shop in the

55
00:03:48,120 --> 00:03:59,200
airport and went to pee and I searched

56
00:03:53,650 --> 00:04:01,720
all over my bag and I had no wallet so

57
00:03:59,200 --> 00:04:03,910
there was right so I am Haley that day

58
00:04:01,720 --> 00:04:05,769
left him with no wallet no guys bored

59
00:04:03,910 --> 00:04:09,430
and wanting to board a flight to

60
00:04:05,769 --> 00:04:13,180
Australia so there was an all girls and

61
00:04:09,430 --> 00:04:16,390
what do I do and of course I am I'm a

62
00:04:13,180 --> 00:04:18,668
social media feed right so first thing I

63
00:04:16,390 --> 00:04:26,560
did stepping out of the play also in

64
00:04:18,668 --> 00:04:28,659
Auckland and then I was like huh and

65
00:04:26,560 --> 00:04:31,450
nobody why I definitely I have a

66
00:04:28,660 --> 00:04:33,700
passport so I was like what do I do and

67
00:04:31,450 --> 00:04:35,558
and my lot of my friends on Twitter is

68
00:04:33,700 --> 00:04:41,049
like oh I have people you know straight

69
00:04:35,559 --> 00:04:43,209
some cash and I called actually called

70
00:04:41,049 --> 00:04:45,839
my creditor company and and they're like

71
00:04:43,209 --> 00:04:48,969
we can FedEx you a card but

72
00:04:45,839 --> 00:04:51,309
internationally would take a week and I

73
00:04:48,969 --> 00:04:58,839
was only gonna be there for like four

74
00:04:51,309 --> 00:05:01,329
days and I was like okay I was at the

75
00:04:58,839 --> 00:05:03,489
coffee shop and I said well I have

76
00:05:01,329 --> 00:05:06,339
mobile pay I don't have I don't carry

77
00:05:03,489 --> 00:05:10,268
Apple I care at pixel phone so I said

78
00:05:06,339 --> 00:05:15,369
well let's try mobile pay and it worked

79
00:05:10,269 --> 00:05:19,329
great so I said okay well I'm just gonna

80
00:05:15,369 --> 00:05:22,119
be in Australia for a week and I'm gonna

81
00:05:19,329 --> 00:05:24,819
run this experiment how far I can get

82
00:05:22,119 --> 00:05:28,149
with mobile pay no wallet no driver

83
00:05:24,819 --> 00:05:32,619
license but does have a passport so I

84
00:05:28,149 --> 00:05:34,359
got to the hotel and the hotel usually

85
00:05:32,619 --> 00:05:36,089
in the US you have to give a credit card

86
00:05:34,359 --> 00:05:39,878
right

87
00:05:36,089 --> 00:05:42,279
they're like you know you got your

88
00:05:39,879 --> 00:05:50,069
password nowhere to go that's fine we'll

89
00:05:42,279 --> 00:05:53,529
check it I said hey this is what I

90
00:05:50,069 --> 00:05:55,899
posted on Twitter when I checked it I

91
00:05:53,529 --> 00:05:57,819
said well hopefully I can get around

92
00:05:55,899 --> 00:05:59,679
with mobile payment otherwise I have to

93
00:05:57,819 --> 00:06:01,989
rely on the kindness of strangers in

94
00:05:59,679 --> 00:06:07,779
Australia which actually comes in

95
00:06:01,989 --> 00:06:11,138
abundance now in the end I went for four

96
00:06:07,779 --> 00:06:14,379
days in Austria without a single time

97
00:06:11,139 --> 00:06:16,419
having to take out a credit card so

98
00:06:14,379 --> 00:06:17,449
mobile payment that was everywhere I got

99
00:06:16,419 --> 00:06:20,878
on this

100
00:06:17,449 --> 00:06:23,519
in the Australia Harbor when from the

101
00:06:20,879 --> 00:06:26,639
harbor to manly Beach and even buying

102
00:06:23,519 --> 00:06:31,529
tickets on the harbor and subway all use

103
00:06:26,639 --> 00:06:34,439
mobile pay so dinner I even went into a

104
00:06:31,529 --> 00:06:38,459
shop to buy some clothing all mobile pay

105
00:06:34,439 --> 00:06:41,449
and no so that's when I was thinking

106
00:06:38,459 --> 00:06:44,939
gosh that the world is really changing

107
00:06:41,449 --> 00:06:48,869
this is what I experienced as a first

108
00:06:44,939 --> 00:06:52,019
hand what we typically call digital

109
00:06:48,869 --> 00:06:54,709
transformation everything is is moving

110
00:06:52,019 --> 00:06:58,439
from the more physical

111
00:06:54,709 --> 00:07:03,599
so the instantiation of it to the

112
00:06:58,439 --> 00:07:06,209
digital counterpart so really is digital

113
00:07:03,599 --> 00:07:10,349
technologies everywhere to change and

114
00:07:06,209 --> 00:07:13,499
fun in some fundamental ways change all

115
00:07:10,349 --> 00:07:17,009
aspects of our everyday life and also

116
00:07:13,499 --> 00:07:22,799
the businesses that I work with and

117
00:07:17,009 --> 00:07:26,999
evaluate every day the interesting thing

118
00:07:22,799 --> 00:07:30,959
is I didn't just talk about this story

119
00:07:26,999 --> 00:07:33,949
for the funny parts of it although it is

120
00:07:30,959 --> 00:07:38,429
funny after I came back from Australia

121
00:07:33,949 --> 00:07:40,709
just so happens I got a pitch for a

122
00:07:38,429 --> 00:07:44,308
company a new startup that's coming from

123
00:07:40,709 --> 00:07:46,860
Asia actually and this startup and

124
00:07:44,309 --> 00:07:49,889
combined with the experience I just had

125
00:07:46,860 --> 00:07:53,369
a Australia was so interesting and kind

126
00:07:49,889 --> 00:07:58,019
of sobering to me so what this company

127
00:07:53,369 --> 00:07:58,999
does is they have a way of pulling cell

128
00:07:58,019 --> 00:08:02,759
phone data

129
00:07:58,999 --> 00:08:05,939
alrightso locations what kind of apps

130
00:08:02,759 --> 00:08:10,169
you use and this is again it's a it's a

131
00:08:05,939 --> 00:08:12,089
company out of Asia so the way they are

132
00:08:10,169 --> 00:08:14,099
able to access cell phone data is

133
00:08:12,089 --> 00:08:16,079
different than here right so they were

134
00:08:14,099 --> 00:08:19,080
able to piece together data from

135
00:08:16,079 --> 00:08:22,319
different sources to tell you

136
00:08:19,080 --> 00:08:25,050
this spell number belongs to a truck

137
00:08:22,319 --> 00:08:28,379
driver this number belongs to a

138
00:08:25,050 --> 00:08:31,789
policeman this one number is a student

139
00:08:28,379 --> 00:08:35,039
this number is a doctor just by

140
00:08:31,789 --> 00:08:38,578
processing the movement of the right

141
00:08:35,039 --> 00:08:41,309
where does the folder location wise and

142
00:08:38,578 --> 00:08:44,189
what time does the front appear in this

143
00:08:41,309 --> 00:08:48,239
location and what apps does this foe

144
00:08:44,190 --> 00:08:50,870
have and they told me that they're able

145
00:08:48,240 --> 00:08:53,940
to very accurately identify the

146
00:08:50,870 --> 00:08:57,740
occupation of the person who holds the

147
00:08:53,940 --> 00:09:02,760
phone now what is the application of

148
00:08:57,740 --> 00:09:06,480
this kind of data they are selling some

149
00:09:02,760 --> 00:09:12,540
of the data feeds to investment banks to

150
00:09:06,480 --> 00:09:17,130
Wall Street entities for very specific

151
00:09:12,540 --> 00:09:21,140
reasons they're able to tell the

152
00:09:17,130 --> 00:09:26,459
investors that last month this

153
00:09:21,140 --> 00:09:29,910
manufacturing facility had an ax 3000

154
00:09:26,459 --> 00:09:33,599
truck drivers showed up there right but

155
00:09:29,910 --> 00:09:35,790
the month before they only had 700 what

156
00:09:33,600 --> 00:09:37,920
does that mean that means this

157
00:09:35,790 --> 00:09:41,310
particular manufacturing for somebody is

158
00:09:37,920 --> 00:09:45,300
doing a lot more business this month now

159
00:09:41,310 --> 00:09:47,790
maybe I should go buy the stock it's

160
00:09:45,300 --> 00:09:50,910
really really interesting data when you

161
00:09:47,790 --> 00:09:53,699
think of how you can really look at the

162
00:09:50,910 --> 00:09:58,680
world from the movement of our

163
00:09:53,700 --> 00:10:00,600
cellphones and I was like dude that was

164
00:09:58,680 --> 00:10:03,209
in Australia buy all these things on my

165
00:10:00,600 --> 00:10:06,570
mobile payment right if they were able

166
00:10:03,209 --> 00:10:09,770
to get hold of my data I don't know what

167
00:10:06,570 --> 00:10:13,709
they'll they'll decipher from that

168
00:10:09,770 --> 00:10:17,920
one-week movement but the the high water

169
00:10:13,709 --> 00:10:21,640
pit is we are all doing a lot more now

170
00:10:17,920 --> 00:10:23,650
using digital means and our footprint is

171
00:10:21,640 --> 00:10:26,350
getting more and more in this digital

172
00:10:23,650 --> 00:10:29,709
world hence there are a lot more

173
00:10:26,350 --> 00:10:32,410
information people can pool and decipher

174
00:10:29,710 --> 00:10:35,290
about us as individuals also about

175
00:10:32,410 --> 00:10:38,560
businesses and those information can

176
00:10:35,290 --> 00:10:44,589
lead to really interesting applications

177
00:10:38,560 --> 00:10:48,790
some of them are very very scary others

178
00:10:44,590 --> 00:10:51,730
really help us better a more efficient

179
00:10:48,790 --> 00:10:54,540
life so how do we handle the two

180
00:10:51,730 --> 00:10:57,040
different the whole spectrum of

181
00:10:54,540 --> 00:11:00,209
implications with this digital

182
00:10:57,040 --> 00:11:02,709
transformation and the abundance of data

183
00:11:00,210 --> 00:11:07,950
and that is a question that sort of

184
00:11:02,710 --> 00:11:10,450
opinion on my mind some of the other

185
00:11:07,950 --> 00:11:14,230
interesting things that I have been

186
00:11:10,450 --> 00:11:16,570
looking at this is again from the

187
00:11:14,230 --> 00:11:18,610
pitches of companies that I've I've

188
00:11:16,570 --> 00:11:22,750
received and also things that I've been

189
00:11:18,610 --> 00:11:27,910
looking at I don't know if any of you

190
00:11:22,750 --> 00:11:31,690
working manufacturing in yes some of you

191
00:11:27,910 --> 00:11:33,250
right so apparently the data I mean you

192
00:11:31,690 --> 00:11:36,280
can you can tell me whether it's true or

193
00:11:33,250 --> 00:11:40,410
not so there's about five to ten percent

194
00:11:36,280 --> 00:11:43,689
of payment a payroll fraud in

195
00:11:40,410 --> 00:11:46,870
manufacturing plants where because

196
00:11:43,690 --> 00:11:49,090
typically today you swipe your your card

197
00:11:46,870 --> 00:11:52,420
it's going and then they record and what

198
00:11:49,090 --> 00:11:54,040
time you go in the the manufacturing

199
00:11:52,420 --> 00:11:57,610
plan some of them are paid by hours

200
00:11:54,040 --> 00:12:02,290
right so there's five to ten percent

201
00:11:57,610 --> 00:12:04,450
fraud in that people will know swipe for

202
00:12:02,290 --> 00:12:07,000
other people or you come out early or do

203
00:12:04,450 --> 00:12:09,820
all kinds of things to avoid working but

204
00:12:07,000 --> 00:12:14,950
still get paid so five to ten percent

205
00:12:09,820 --> 00:12:18,160
fraud in in large manufacturing company

206
00:12:14,950 --> 00:12:20,259
is a lot so

207
00:12:18,160 --> 00:12:23,980
they've been looking at different

208
00:12:20,259 --> 00:12:27,970
technologies to help them reduce the

209
00:12:23,980 --> 00:12:29,470
fraud rate so one of the applications

210
00:12:27,970 --> 00:12:33,819
I've seen so far is kind of interesting

211
00:12:29,470 --> 00:12:35,110
so they have instead of having you swipe

212
00:12:33,819 --> 00:12:38,319
the badge

213
00:12:35,110 --> 00:12:42,160
there's facial recognition iPads right

214
00:12:38,319 --> 00:12:44,829
at the entrance to the plan and so you

215
00:12:42,160 --> 00:12:47,709
go and you know you take a picture and

216
00:12:44,829 --> 00:12:50,229
they recognize your face and then the

217
00:12:47,709 --> 00:12:54,579
turnstile opens once authentication is

218
00:12:50,230 --> 00:12:58,540
done and at the same time this

219
00:12:54,579 --> 00:13:01,029
information is sent in that instance to

220
00:12:58,540 --> 00:13:04,569
the payroll system and seamlessly

221
00:13:01,029 --> 00:13:05,920
recorded what time you went in and along

222
00:13:04,569 --> 00:13:08,229
with the action of you know

223
00:13:05,920 --> 00:13:13,500
authentication the follow up actions

224
00:13:08,230 --> 00:13:17,079
turnstile open and then payroll log and

225
00:13:13,500 --> 00:13:20,910
they've also done it in different parts

226
00:13:17,079 --> 00:13:25,569
of the plan so that they could tie you

227
00:13:20,910 --> 00:13:27,939
go in there with your movement inside

228
00:13:25,569 --> 00:13:31,870
the plan to say hey you know this person

229
00:13:27,939 --> 00:13:33,819
did go in throughout the day he or she

230
00:13:31,870 --> 00:13:35,380
is working because they are showing up

231
00:13:33,819 --> 00:13:37,899
at different parts of the building as

232
00:13:35,380 --> 00:13:41,560
opposed to they were just out there

233
00:13:37,899 --> 00:13:44,079
smoke a cigarette and that day that

234
00:13:41,560 --> 00:13:46,180
getting is back to the payroll system so

235
00:13:44,079 --> 00:13:48,099
that there's evidence that there's

236
00:13:46,180 --> 00:13:50,310
entrance to the building and there's

237
00:13:48,100 --> 00:13:53,249
evidence work being done

238
00:13:50,310 --> 00:13:55,529
and apparently one of the manufacturer

239
00:13:53,249 --> 00:13:58,920
large electronics manufacturing

240
00:13:55,529 --> 00:14:02,490
companies in the world their Cecil told

241
00:13:58,920 --> 00:14:04,920
me that they are able to reduce the flow

242
00:14:02,490 --> 00:14:07,379
rate from a pair of arrayed from a

243
00:14:04,920 --> 00:14:11,399
double-digit to a single-digit just by

244
00:14:07,379 --> 00:14:13,920
deploying this one system at the same

245
00:14:11,399 --> 00:14:17,370
time he said now I've got a lot more

246
00:14:13,920 --> 00:14:19,920
personal data in my system that I have

247
00:14:17,370 --> 00:14:23,059
to protect them because I've got facial

248
00:14:19,920 --> 00:14:26,128
recognition data I've got you know purse

249
00:14:23,059 --> 00:14:30,139
people movement data lot of them

250
00:14:26,129 --> 00:14:35,160
depending on which country from have PII

251
00:14:30,139 --> 00:14:38,809
Protection consequence another

252
00:14:35,160 --> 00:14:43,139
interesting example also the use of data

253
00:14:38,809 --> 00:14:47,189
there's a ton of health tech innovation

254
00:14:43,139 --> 00:14:51,769
so this one I really like a company I

255
00:14:47,189 --> 00:14:57,120
know in in San Francisco is working with

256
00:14:51,769 --> 00:15:00,990
a network of hospitals to the first

257
00:14:57,120 --> 00:15:03,540
application they do is get data from the

258
00:15:00,990 --> 00:15:06,420
hospital on how many beds are occupied a

259
00:15:03,540 --> 00:15:10,529
day you know on the given day and how

260
00:15:06,420 --> 00:15:13,439
long a patient stays in the hospital and

261
00:15:10,529 --> 00:15:16,500
they got like five years worth of data

262
00:15:13,439 --> 00:15:19,099
or something so by churning through the

263
00:15:16,500 --> 00:15:23,329
data and build a model and along with

264
00:15:19,100 --> 00:15:27,360
data they get elsewhere such as weather

265
00:15:23,329 --> 00:15:30,540
what events are happening they able to

266
00:15:27,360 --> 00:15:33,209
build a model a predictive model to tell

267
00:15:30,540 --> 00:15:36,480
the hospital on any given day how many

268
00:15:33,209 --> 00:15:38,780
empty beds they gonna have on a given

269
00:15:36,480 --> 00:15:42,950
day now why is that interesting

270
00:15:38,780 --> 00:15:45,380
because if I know today's gonna be a

271
00:15:42,950 --> 00:15:47,620
slow day I can stop it right I don't

272
00:15:45,380 --> 00:15:53,090
have to have as many nurses or doctors

273
00:15:47,620 --> 00:15:55,700
also if I have more capacity then I had

274
00:15:53,090 --> 00:15:59,720
orderly thought in my hospital I can

275
00:15:55,700 --> 00:16:02,720
take more overflow patients from no

276
00:15:59,720 --> 00:16:05,720
neighboring health care and and hospital

277
00:16:02,720 --> 00:16:07,910
facility so the projection now this is

278
00:16:05,720 --> 00:16:10,790
still an experiment ongoing experiment

279
00:16:07,910 --> 00:16:14,089
but the projection from the hospital

280
00:16:10,790 --> 00:16:16,780
states that they should be able to

281
00:16:14,090 --> 00:16:20,150
increase that revenue and decrease cost

282
00:16:16,780 --> 00:16:22,760
well I think it's let's just look at

283
00:16:20,150 --> 00:16:25,790
increased revenue by a double digit not

284
00:16:22,760 --> 00:16:28,160
by 20-some percent which is a really

285
00:16:25,790 --> 00:16:31,670
rare occurrence these days for a

286
00:16:28,160 --> 00:16:36,020
hospital so this again illustrates the

287
00:16:31,670 --> 00:16:43,240
power of the right use of data and data

288
00:16:36,020 --> 00:16:48,740
science data science and AI is really

289
00:16:43,240 --> 00:16:51,950
well that is that is a typo seeping into

290
00:16:48,740 --> 00:16:58,550
our lives as a well maybe it is see into

291
00:16:51,950 --> 00:17:00,560
our lives in some ways another example I

292
00:16:58,550 --> 00:17:03,770
to give it's kind of scary but it's

293
00:17:00,560 --> 00:17:06,470
really really interesting does any of

294
00:17:03,770 --> 00:17:13,520
you know heart rate variability what

295
00:17:06,470 --> 00:17:16,250
that is so heart rate variability is bio

296
00:17:13,520 --> 00:17:20,869
signature if you will that each of us

297
00:17:16,250 --> 00:17:23,930
have so instead of measuring heart rate

298
00:17:20,869 --> 00:17:27,530
per per minute so what they measure is

299
00:17:23,930 --> 00:17:32,090
the the difference between the peaks

300
00:17:27,530 --> 00:17:34,010
right so the peaks are not exactly same

301
00:17:32,090 --> 00:17:37,070
intervals they have a little bit

302
00:17:34,010 --> 00:17:39,350
difference and there's a mathematical

303
00:17:37,070 --> 00:17:41,270
calculation to know measure your heart

304
00:17:39,350 --> 00:17:44,379
rate for some period of time and tell

305
00:17:41,270 --> 00:17:47,379
you what your HRV is

306
00:17:44,380 --> 00:17:49,809
and if you read bioscience literature

307
00:17:47,380 --> 00:17:55,480
there's actually a lot of research today

308
00:17:49,809 --> 00:17:58,418
on getting your HR ARB data heart rate

309
00:17:55,480 --> 00:18:02,100
variability which is actually a fairly

310
00:17:58,419 --> 00:18:05,950
accurate prediction predictive

311
00:18:02,100 --> 00:18:08,350
characteristic for certain diseases so

312
00:18:05,950 --> 00:18:10,120
if your heart rate variability is of no

313
00:18:08,350 --> 00:18:15,789
falling to a certain range you're more

314
00:18:10,120 --> 00:18:17,039
susceptible to certain diseases now how

315
00:18:15,789 --> 00:18:18,820
do we get heart rate variability

316
00:18:17,039 --> 00:18:21,070
traditionally you have to wear a device

317
00:18:18,820 --> 00:18:24,299
a monitor right and then the reads are

318
00:18:21,070 --> 00:18:30,100
resurfaced so it's not easy to get that

319
00:18:24,299 --> 00:18:32,049
however this is Israeli company that

320
00:18:30,100 --> 00:18:37,020
I've been looking at it's a really

321
00:18:32,049 --> 00:18:42,549
interesting again AI based bioscience

322
00:18:37,020 --> 00:18:44,980
start-up so they have a way to process

323
00:18:42,549 --> 00:18:46,840
video just like you know if I'm here

324
00:18:44,980 --> 00:18:49,600
talking and the video is being taken now

325
00:18:46,840 --> 00:18:52,780
this is not high def probably I don't

326
00:18:49,600 --> 00:18:57,428
know if they can do it if they have a

327
00:18:52,780 --> 00:18:59,200
high def video of someone not this

328
00:18:57,429 --> 00:19:02,080
person doesn't have to do anything right

329
00:18:59,200 --> 00:19:05,020
just a video and they're able to just

330
00:19:02,080 --> 00:19:08,649
process the video to pull out your heart

331
00:19:05,020 --> 00:19:11,230
rate information from the video and the

332
00:19:08,650 --> 00:19:15,730
way they do it is every time our heart

333
00:19:11,230 --> 00:19:19,150
beats our heart beat the blood comes to

334
00:19:15,730 --> 00:19:23,110
the face right and the it comes behind

335
00:19:19,150 --> 00:19:25,389
the skin on our face and ever so

336
00:19:23,110 --> 00:19:29,408
slightly changes

337
00:19:25,389 --> 00:19:32,139
light that reflects off our skin of our

338
00:19:29,409 --> 00:19:34,720
cheeks and so they just focus on these

339
00:19:32,139 --> 00:19:36,908
two regions and every time the

340
00:19:34,720 --> 00:19:38,619
reflection of a light changes they

341
00:19:36,909 --> 00:19:41,499
record that as a heartbeat

342
00:19:38,619 --> 00:19:44,230
and they they have tuned their algorithm

343
00:19:41,499 --> 00:19:46,299
to a degree that it's it's actually

344
00:19:44,230 --> 00:19:49,389
scarily accurate so I'm gonna show you a

345
00:19:46,299 --> 00:19:51,730
video this is the demo they have is this

346
00:19:49,389 --> 00:19:55,029
woman is wearing a heartrate monitor

347
00:19:51,730 --> 00:19:58,090
which records her heart rate and at the

348
00:19:55,029 --> 00:20:00,940
same time they taking a video of her and

349
00:19:58,090 --> 00:20:03,279
pulling off heart rate information from

350
00:20:00,940 --> 00:20:06,129
just the video and overlay the two

351
00:20:03,279 --> 00:20:08,710
information to see whether they you know

352
00:20:06,129 --> 00:20:10,859
the actual reading of heart rate and the

353
00:20:08,710 --> 00:20:20,950
reading off the video to see if it is

354
00:20:10,859 --> 00:20:25,090
accurate hopefully the video plays okay

355
00:20:20,950 --> 00:20:28,119
now starting the blue line or the black

356
00:20:25,090 --> 00:20:31,119
line is the monitor reading the brown

357
00:20:28,119 --> 00:20:35,649
line is the lying that a process out of

358
00:20:31,119 --> 00:20:39,820
the video look after a while the two

359
00:20:35,649 --> 00:20:42,070
lines are very much aligned so what does

360
00:20:39,820 --> 00:20:47,109
that mean that means today we have

361
00:20:42,070 --> 00:20:50,129
technologies that can remotely lead your

362
00:20:47,109 --> 00:20:54,519
heart rate variability bio signature

363
00:20:50,129 --> 00:20:57,189
it's insurance companies really like it

364
00:20:54,519 --> 00:20:59,200
they are looking at different kinds of

365
00:20:57,190 --> 00:21:01,450
applications you can you can kind of

366
00:20:59,200 --> 00:21:04,629
imagine what kind of application they

367
00:21:01,450 --> 00:21:10,529
have in mind however there are a lot of

368
00:21:04,629 --> 00:21:10,529
other applications right so it's Mitzy

369
00:21:13,049 --> 00:21:18,480
so this is another video they did

370
00:21:20,009 --> 00:21:29,580
this was Mark Zuckerberg Sam no that

371
00:21:27,220 --> 00:21:29,580
doesn't work

372
00:21:39,929 --> 00:21:53,320
yeah okay there's actually some sound

373
00:21:49,840 --> 00:21:55,809
but you can see that they're pulling out

374
00:21:53,320 --> 00:22:00,129
his heart rate and the woman sitting

375
00:21:55,809 --> 00:22:02,860
behind him and and they have the

376
00:22:00,129 --> 00:22:05,199
information of the pulse rates like the

377
00:22:02,860 --> 00:22:09,580
blue one is his at the bottom there and

378
00:22:05,200 --> 00:22:11,799
the brown one is hers and they also can

379
00:22:09,580 --> 00:22:13,870
by looking at the heart rate they they

380
00:22:11,799 --> 00:22:27,970
plotted out the stress level of the

381
00:22:13,870 --> 00:22:32,080
person was talking so if you look at the

382
00:22:27,970 --> 00:22:35,590
stress level plot right so when he said

383
00:22:32,080 --> 00:22:41,019
Cambridge and I let it go hurt his heart

384
00:22:35,590 --> 00:22:43,689
rate went up its just level went up so

385
00:22:41,019 --> 00:22:45,429
this is kind of scary this is I don't

386
00:22:43,690 --> 00:22:49,000
know if it will be a virtual lie

387
00:22:45,429 --> 00:22:54,240
detector but at least they kind of know

388
00:22:49,000 --> 00:22:54,240
the emotion behind their speech

389
00:22:58,870 --> 00:23:05,290
and and you guys are in security I'm in

390
00:23:02,740 --> 00:23:08,080
security we know that in security you

391
00:23:05,290 --> 00:23:10,750
can sell all vulnerable tea right you

392
00:23:08,080 --> 00:23:13,629
can sell a zero-day these days if a

393
00:23:10,750 --> 00:23:16,570
zero-day of iOS could be sold in

394
00:23:13,630 --> 00:23:20,740
millions of dollars what if it's a bio

395
00:23:16,570 --> 00:23:23,110
signature of a head of state how much

396
00:23:20,740 --> 00:23:25,960
can you sell what if you buy a

397
00:23:23,110 --> 00:23:28,570
processing a video of president of some

398
00:23:25,960 --> 00:23:33,280
country you know that this person might

399
00:23:28,570 --> 00:23:36,070
be susceptible to seizure maybe and you

400
00:23:33,280 --> 00:23:41,290
could somehow feed them a video that

401
00:23:36,070 --> 00:23:43,419
that triggers seizure would not be a

402
00:23:41,290 --> 00:23:46,149
really really scary scenario and we're

403
00:23:43,420 --> 00:23:49,600
not that far from it and what is the

404
00:23:46,150 --> 00:23:52,780
price of human vulnerability that we can

405
00:23:49,600 --> 00:23:56,370
sell we don't know these are all

406
00:23:52,780 --> 00:23:58,990
interesting questions to ponder and

407
00:23:56,370 --> 00:24:01,570
because I'm a security person so the

408
00:23:58,990 --> 00:24:05,290
first thing I look at is whose job is it

409
00:24:01,570 --> 00:24:08,129
to deliver trust to ensure trust in this

410
00:24:05,290 --> 00:24:13,059
world where data is of abundance and

411
00:24:08,130 --> 00:24:17,260
information can be had in a fairly cheap

412
00:24:13,059 --> 00:24:19,870
way and of course computer scientists

413
00:24:17,260 --> 00:24:23,320
are working on newer and more innovative

414
00:24:19,870 --> 00:24:26,409
way to process data to pull data out of

415
00:24:23,320 --> 00:24:30,639
ordinary things in ways that we didn't

416
00:24:26,410 --> 00:24:33,429
even know before and who this job is it

417
00:24:30,640 --> 00:24:36,360
to ensure that these things are done in

418
00:24:33,429 --> 00:24:40,630
the trustworthy way and in a way that

419
00:24:36,360 --> 00:24:44,889
has the right societal impact versus

420
00:24:40,630 --> 00:24:49,600
otherwise so what do you trust trust is

421
00:24:44,890 --> 00:24:51,820
really we have confidence in the true in

422
00:24:49,600 --> 00:24:55,540
the strength in the truth of something

423
00:24:51,820 --> 00:24:59,439
right and these days Trust is actually

424
00:24:55,540 --> 00:25:03,190
really hard to come by imagining all

425
00:24:59,440 --> 00:25:04,800
these things could happen and do you

426
00:25:03,190 --> 00:25:06,840
guys know deep fake

427
00:25:04,800 --> 00:25:12,990
you heard of deep fake have you watched

428
00:25:06,840 --> 00:25:18,090
the videos no do you want to see one so

429
00:25:12,990 --> 00:25:22,200
deep fake is is a way to use deep

430
00:25:18,090 --> 00:25:25,409
learning to basically cheat transform a

431
00:25:22,200 --> 00:25:28,590
person's face into a different person's

432
00:25:25,410 --> 00:25:35,250
face with the same movement of mouth and

433
00:25:28,590 --> 00:25:39,720
expressions and it is Erie it is Erie so

434
00:25:35,250 --> 00:25:47,460
this one now we don't have audio so it's

435
00:25:39,720 --> 00:26:06,530
a little disappointing huh you know any

436
00:25:47,460 --> 00:26:11,610
way we can get all of you this is a

437
00:26:06,530 --> 00:26:14,879
Bhama talking about something they never

438
00:26:11,610 --> 00:26:18,240
actually spoke these words and you look

439
00:26:14,880 --> 00:26:20,150
at him and he looks like he's talking in

440
00:26:18,240 --> 00:26:24,810
those words

441
00:26:20,150 --> 00:26:28,320
he also part of this video said I think

442
00:26:24,810 --> 00:26:30,919
president Trump is an idiot he didn't

443
00:26:28,320 --> 00:26:30,919
say those words

444
00:26:31,390 --> 00:26:38,679
I don't think he said these were the

445
00:26:35,620 --> 00:26:41,559
enroll in this video he didn't say those

446
00:26:38,679 --> 00:26:46,240
words but those words were in the video

447
00:26:41,559 --> 00:26:53,530
and it's actually done by this actor the

448
00:26:46,240 --> 00:26:59,049
voicedub oath is their real-time tech

449
00:26:53,530 --> 00:27:01,870
support it's okay if we can't do it but

450
00:26:59,049 --> 00:27:08,470
it the sound is interesting because he

451
00:27:01,870 --> 00:27:09,090
kind of it does sound like him does it

452
00:27:08,470 --> 00:27:11,500
work

453
00:27:09,090 --> 00:27:17,949
are you gonna have to turn on back there

454
00:27:11,500 --> 00:27:19,750
okay so let's wait a little bit and

455
00:27:17,950 --> 00:27:21,970
there's also another video if you

456
00:27:19,750 --> 00:27:28,240
haven't seen our Instagram of Kim

457
00:27:21,970 --> 00:27:30,640
Kardashian video of her say all I want

458
00:27:28,240 --> 00:27:33,750
is manipulating people on internet and

459
00:27:30,640 --> 00:27:37,090
make a lot of money doing it

460
00:27:33,750 --> 00:27:39,970
and that is like look like her it's her

461
00:27:37,090 --> 00:27:42,659
voice and she obviously never said those

462
00:27:39,970 --> 00:27:42,660
words in public

463
00:27:44,360 --> 00:27:56,570
you get it can I play the video now

464
00:27:50,370 --> 00:27:56,570
let's see still not working

465
00:27:58,909 --> 00:28:06,899
can you yeah that's okay that's okay

466
00:28:04,830 --> 00:28:17,399
so basically he set words but he never

467
00:28:06,899 --> 00:28:20,489
said before what I was working a video

468
00:28:17,399 --> 00:28:26,029
YouTube not my mind let's see if it

469
00:28:20,490 --> 00:28:26,029
works yes

470
00:28:59,910 --> 00:29:03,079
[Music]

471
00:29:05,560 --> 00:29:16,280
all right so that's enough I think so

472
00:29:13,940 --> 00:29:21,770
don't need to find anyone but that's I

473
00:29:16,280 --> 00:29:24,920
just want to show the effect of it now

474
00:29:21,770 --> 00:29:27,350
if you didn't know D fake existed it

475
00:29:24,920 --> 00:29:29,780
would be really hard to watch a video

476
00:29:27,350 --> 00:29:32,870
like this and thinking oh he didn't say

477
00:29:29,780 --> 00:29:36,410
these words right so so this is again an

478
00:29:32,870 --> 00:29:39,020
artificial intelligence mechanism that

479
00:29:36,410 --> 00:29:41,450
when somebody's talking they process the

480
00:29:39,020 --> 00:29:43,820
video and pull out the structure of your

481
00:29:41,450 --> 00:29:45,950
face the movement of your mouth and

482
00:29:43,820 --> 00:29:48,020
movement of you know soothe of your

483
00:29:45,950 --> 00:29:50,720
brows with respect to the different

484
00:29:48,020 --> 00:29:53,510
parts of the face and then they replace

485
00:29:50,720 --> 00:29:55,820
it with a different person's face but

486
00:29:53,510 --> 00:29:58,190
with the same kind of movements that's

487
00:29:55,820 --> 00:30:01,550
that's pulled out as a model and then

488
00:29:58,190 --> 00:30:04,640
they can make that person say the same

489
00:30:01,550 --> 00:30:07,629
thing and do the same facial expressions

490
00:30:04,640 --> 00:30:07,630
it's really eerie

491
00:30:10,150 --> 00:30:16,580
there's also another branch of AI

492
00:30:13,040 --> 00:30:21,260
research called adversarial use and the

493
00:30:16,580 --> 00:30:23,090
adversary are use examples if you will

494
00:30:21,260 --> 00:30:25,010
are really really interesting to

495
00:30:23,090 --> 00:30:27,919
computer security I've been keeping an

496
00:30:25,010 --> 00:30:31,370
eye on there for a few years now

497
00:30:27,920 --> 00:30:36,380
this is one of the early examples of a

498
00:30:31,370 --> 00:30:39,280
serial sample what does that mean is you

499
00:30:36,380 --> 00:30:42,890
can manipulate the data that goes into a

500
00:30:39,280 --> 00:30:45,440
an algorithm which then will trick the

501
00:30:42,890 --> 00:30:48,920
algorithm into giving you the wrong

502
00:30:45,440 --> 00:30:51,680
reading so this is to your left right is

503
00:30:48,920 --> 00:30:53,660
a picture of a panda and if you show

504
00:30:51,680 --> 00:30:56,870
this picture to a facial recognition or

505
00:30:53,660 --> 00:30:58,940
the picture processing algorithm it'll

506
00:30:56,870 --> 00:31:00,830
tell you yet - panda is there you know a

507
00:30:58,940 --> 00:31:04,460
lot of all of them they're trained on

508
00:31:00,830 --> 00:31:07,389
recognizing animals stuff but the

509
00:31:04,460 --> 00:31:10,450
researcher was able to show

510
00:31:07,389 --> 00:31:13,779
if you just take the vector image of the

511
00:31:10,450 --> 00:31:16,719
Panda and overlay with you know this

512
00:31:13,779 --> 00:31:19,989
sort of gibberish image which is also

513
00:31:16,719 --> 00:31:23,019
vector image overlay then the the

514
00:31:19,989 --> 00:31:25,419
resulting image to a naked eye to human

515
00:31:23,019 --> 00:31:28,359
eye is exactly like that it's at a panda

516
00:31:25,419 --> 00:31:32,700
but if you then feed that composite

517
00:31:28,359 --> 00:31:35,739
image but to your right to the same

518
00:31:32,700 --> 00:31:38,859
facial recognition algorithm you don't

519
00:31:35,739 --> 00:31:42,669
say it's a Gibbon because it has

520
00:31:38,859 --> 00:31:45,789
manipulated data in a very subtle way

521
00:31:42,669 --> 00:31:48,429
that tricks the algorithm to instead of

522
00:31:45,789 --> 00:31:50,859
classifying it into one class it

523
00:31:48,429 --> 00:31:54,099
classifies into a different class and

524
00:31:50,859 --> 00:31:56,728
this was the very first known or

525
00:31:54,099 --> 00:32:00,249
published examples of how you could

526
00:31:56,729 --> 00:32:04,419
intentionally manipulate data to reach a

527
00:32:00,249 --> 00:32:10,239
different conclusion of a predictive AI

528
00:32:04,419 --> 00:32:12,729
with them and then following that

529
00:32:10,239 --> 00:32:14,849
research there's a branch of AI now is

530
00:32:12,729 --> 00:32:18,479
called a generative

531
00:32:14,849 --> 00:32:21,279
adversarial network so what happens is

532
00:32:18,479 --> 00:32:24,009
you use you have a bunch of data to

533
00:32:21,279 --> 00:32:27,190
train an algorithm and this this

534
00:32:24,009 --> 00:32:30,219
mechanism will have two models they're

535
00:32:27,190 --> 00:32:32,979
trained by either same set of data or

536
00:32:30,219 --> 00:32:36,190
similar set of data and then the first

537
00:32:32,979 --> 00:32:40,320
model will start generating things will

538
00:32:36,190 --> 00:32:43,029
generate a you know this is actually a

539
00:32:40,320 --> 00:32:47,379
normal painting that's done by in the AI

540
00:32:43,029 --> 00:32:49,690
algorithm so imagine this one model is

541
00:32:47,379 --> 00:32:51,988
generating all your painting and every

542
00:32:49,690 --> 00:32:55,389
time you generates an oil painting be

543
00:32:51,989 --> 00:33:00,279
the the second model will look at it and

544
00:32:55,389 --> 00:33:02,529
you will say we try to decipher whether

545
00:33:00,279 --> 00:33:06,159
this is a real painting or this is

546
00:33:02,529 --> 00:33:07,309
generated by AI and the first a few

547
00:33:06,159 --> 00:33:09,110
times this

548
00:33:07,309 --> 00:33:12,139
and model will always be able to tell

549
00:33:09,110 --> 00:33:15,620
we're saying okay this is fake this is

550
00:33:12,139 --> 00:33:17,870
real this fake but then then this first

551
00:33:15,620 --> 00:33:20,629
model with that based on the result of

552
00:33:17,870 --> 00:33:22,580
the the fake or real will tune its

553
00:33:20,629 --> 00:33:25,039
algorithm will get a better and better

554
00:33:22,580 --> 00:33:26,960
every time and this is essentially two

555
00:33:25,039 --> 00:33:29,690
models like competing with each other

556
00:33:26,960 --> 00:33:32,690
and then at some point it'll generate a

557
00:33:29,690 --> 00:33:35,509
result either painting or something that

558
00:33:32,690 --> 00:33:37,850
will fool the second model and when that

559
00:33:35,509 --> 00:33:41,690
happens you reach the results you want

560
00:33:37,850 --> 00:33:44,059
so this is a famous painting done by a

561
00:33:41,690 --> 00:33:49,129
guy who's actually 19 years old at the

562
00:33:44,059 --> 00:33:52,519
time who was really specialized in this

563
00:33:49,129 --> 00:33:55,369
kind of Gann model no GAA and gam model

564
00:33:52,519 --> 00:34:01,249
generation and and he did this painting

565
00:33:55,369 --> 00:34:04,240
and in 2018 not this painting but a few

566
00:34:01,249 --> 00:34:07,490
paintings that was generated by a gang

567
00:34:04,240 --> 00:34:11,440
was auctioned off I think two paintings

568
00:34:07,490 --> 00:34:14,210
auction of $425,000 I'm Christine

569
00:34:11,440 --> 00:34:17,450
because they were not only they were the

570
00:34:14,210 --> 00:34:20,060
first known sort of art that's generated

571
00:34:17,449 --> 00:34:24,078
by AI ever they were really good quality

572
00:34:20,060 --> 00:34:29,270
they mimic the Impressionism look and

573
00:34:24,079 --> 00:34:32,869
feel so not only speech facial

574
00:34:29,270 --> 00:34:33,379
recognition can be faked our work can be

575
00:34:32,869 --> 00:34:39,409
faked

576
00:34:33,379 --> 00:34:42,440
so what's what is real anymore I'm gonna

577
00:34:39,409 --> 00:34:46,970
skip that I was also interesting but I

578
00:34:42,440 --> 00:34:48,770
think we lo a bit a long time but the

579
00:34:46,969 --> 00:34:52,158
societal impact we talked about some of

580
00:34:48,770 --> 00:34:55,429
the attacks out of Serra impact but the

581
00:34:52,159 --> 00:34:57,349
societal impact of having the abundance

582
00:34:55,429 --> 00:35:00,280
of data and having the way of processing

583
00:34:57,349 --> 00:35:03,980
data and getting information at the rate

584
00:35:00,280 --> 00:35:07,819
at a precision that was not previously

585
00:35:03,980 --> 00:35:11,480
possible the impact goes beyond just

586
00:35:07,819 --> 00:35:14,359
attacked beyond faking things

587
00:35:11,480 --> 00:35:19,310
so this is a video that's generated

588
00:35:14,359 --> 00:35:23,630
actually by a European company and so

589
00:35:19,310 --> 00:35:25,970
it's a regular just a subway everyday

590
00:35:23,630 --> 00:35:29,930
subway surveillance video and they're

591
00:35:25,970 --> 00:35:32,240
able to use the AI algorithm to not only

592
00:35:29,930 --> 00:35:36,460
identify his a person he has a person

593
00:35:32,240 --> 00:35:39,078
his person but then Wow very detailed

594
00:35:36,460 --> 00:35:42,230
character characteristics of a person

595
00:35:39,079 --> 00:35:46,460
the way this person moves the person

596
00:35:42,230 --> 00:35:50,720
what the person wearing and what is his

597
00:35:46,460 --> 00:35:56,960
or her emotion at that moment and this

598
00:35:50,720 --> 00:36:00,709
is a an example of what they see as the

599
00:35:56,960 --> 00:36:02,990
result on the dashboard so you know the

600
00:36:00,710 --> 00:36:05,990
attributes of a person this is just a

601
00:36:02,990 --> 00:36:10,790
person walking on the subway platform so

602
00:36:05,990 --> 00:36:13,220
you know is it gender age possible age

603
00:36:10,790 --> 00:36:16,970
is that less than 30 the less than 45

604
00:36:13,220 --> 00:36:19,578
and the hair color all that and it goes

605
00:36:16,970 --> 00:36:22,250
on goes on like you know is this person

606
00:36:19,579 --> 00:36:26,030
of good health and all that that can

607
00:36:22,250 --> 00:36:31,160
just be processed out of a regular video

608
00:36:26,030 --> 00:36:33,470
that people going to work and we have

609
00:36:31,160 --> 00:36:36,950
all seen those surveillance Hollywood

610
00:36:33,470 --> 00:36:41,270
surveillance movies where interesting

611
00:36:36,950 --> 00:36:43,549
things could happen and this is this is

612
00:36:41,270 --> 00:36:45,890
a actually not even a very interesting

613
00:36:43,550 --> 00:36:53,810
use of AI algorithm but this is reality

614
00:36:45,890 --> 00:36:59,960
today this experiment was done in 2018

615
00:36:53,810 --> 00:37:01,970
by ACLU ACLU took at that time Amazon's

616
00:36:59,960 --> 00:37:04,760
facial recognition algorithm which was

617
00:37:01,970 --> 00:37:05,700
available publicly through API and they

618
00:37:04,760 --> 00:37:10,230
fed

619
00:37:05,700 --> 00:37:13,770
that 50 Congress members face into the

620
00:37:10,230 --> 00:37:17,610
facial recognition algorithm along with

621
00:37:13,770 --> 00:37:23,120
a database of 200,000 inmates it's also

622
00:37:17,610 --> 00:37:28,620
faith and then guess what they got the

623
00:37:23,120 --> 00:37:31,920
the the algorithm misidentified 28

624
00:37:28,620 --> 00:37:36,750
Congress members as the same person in

625
00:37:31,920 --> 00:37:38,820
the inmate database 28 out of 50 oh no

626
00:37:36,750 --> 00:37:45,000
wait a minute is it 50 or more than 50

627
00:37:38,820 --> 00:37:48,600
more than 50 but still 28 people right

628
00:37:45,000 --> 00:37:53,430
there I mean we think they're not

629
00:37:48,600 --> 00:37:58,009
inmates right but what's interesting is

630
00:37:53,430 --> 00:38:03,259
within the set that is misidentified

631
00:37:58,010 --> 00:38:06,710
people of color of a higher percentage

632
00:38:03,260 --> 00:38:11,190
so what does I mean is the algorithm is

633
00:38:06,710 --> 00:38:15,080
weaker in correctly identify people of

634
00:38:11,190 --> 00:38:17,280
color processing their facial

635
00:38:15,080 --> 00:38:20,549
expressions and facial characteristics

636
00:38:17,280 --> 00:38:24,990
and why would that be the case because

637
00:38:20,550 --> 00:38:29,040
the training data that goes into these

638
00:38:24,990 --> 00:38:33,390
AI algorithms have less data on people

639
00:38:29,040 --> 00:38:35,310
of color than Caucasian folks because

640
00:38:33,390 --> 00:38:39,480
you have less data to work with so your

641
00:38:35,310 --> 00:38:45,120
model is not as accurate and this is

642
00:38:39,480 --> 00:38:49,260
clearly a problem so who is there to

643
00:38:45,120 --> 00:38:52,109
ensure that the AI models we build which

644
00:38:49,260 --> 00:38:55,980
has impact on everyday life has the

645
00:38:52,110 --> 00:38:57,990
correct type of training data that I was

646
00:38:55,980 --> 00:39:03,740
interest we will not be biased it would

647
00:38:57,990 --> 00:39:07,140
not make mistakes in a way that is very

648
00:39:03,740 --> 00:39:12,899
very what's the word I'm looking for not

649
00:39:07,140 --> 00:39:15,710
interesting but scary also Amazon two

650
00:39:12,900 --> 00:39:19,010
years ago done this experiment

651
00:39:15,710 --> 00:39:21,290
experiment that because they got tons of

652
00:39:19,010 --> 00:39:24,230
thousands or maybe even more hundred

653
00:39:21,290 --> 00:39:27,080
thousands of resumes every year and they

654
00:39:24,230 --> 00:39:30,430
just couldn't human-looking through them

655
00:39:27,080 --> 00:39:33,200
just not possible so they had a OCR

656
00:39:30,430 --> 00:39:35,569
optical character recognition algorithm

657
00:39:33,200 --> 00:39:39,109
built which is just two first level

658
00:39:35,570 --> 00:39:44,750
filtering of the resumes before it gets

659
00:39:39,109 --> 00:39:47,660
to a naturally HR person so what

660
00:39:44,750 --> 00:39:50,020
happened was they found out after

661
00:39:47,660 --> 00:39:54,589
running this algorithm for several month

662
00:39:50,020 --> 00:39:59,540
that one-minute resumes we're just not

663
00:39:54,589 --> 00:40:02,690
getting through because the algorithm

664
00:39:59,540 --> 00:40:06,410
was biased against women's names if your

665
00:40:02,690 --> 00:40:10,190
name had in a recognizable woman's name

666
00:40:06,410 --> 00:40:14,089
he'll give you a rank you lower and they

667
00:40:10,190 --> 00:40:18,020
did this experiment is a shame a set of

668
00:40:14,089 --> 00:40:22,310
same resumes changing the name change

669
00:40:18,020 --> 00:40:27,680
from Katherine to Chad and it went

670
00:40:22,310 --> 00:40:33,859
through so why because the training data

671
00:40:27,680 --> 00:40:37,520
we used had less women less high ranked

672
00:40:33,859 --> 00:40:40,069
women candidate information in the

673
00:40:37,520 --> 00:40:41,660
training data so the algorithm the

674
00:40:40,070 --> 00:40:43,730
algorithm was not really a fault it

675
00:40:41,660 --> 00:40:46,368
correctly saying if it's a woman the

676
00:40:43,730 --> 00:40:49,310
success rate is lower so let's not give

677
00:40:46,369 --> 00:40:50,869
this resume a chance because the

678
00:40:49,310 --> 00:40:55,220
algorithm doesn't care as a woman no man

679
00:40:50,869 --> 00:40:57,109
just say this this set of data success

680
00:40:55,220 --> 00:41:02,180
rates low that said the data success

681
00:40:57,109 --> 00:41:04,910
rate is high and and then Amazon faded

682
00:41:02,180 --> 00:41:10,160
this out and they had to like stop this

683
00:41:04,910 --> 00:41:12,319
program how would I Amazon know in the

684
00:41:10,160 --> 00:41:15,830
beginning that the data they used to

685
00:41:12,320 --> 00:41:18,170
train this algorithm is biased and how

686
00:41:15,830 --> 00:41:20,810
does anybody know they three were to

687
00:41:18,170 --> 00:41:22,760
embark on this kind of analysis that we

688
00:41:20,810 --> 00:41:25,730
have the right set of training data to

689
00:41:22,760 --> 00:41:26,850
work from and you know this is actually

690
00:41:25,730 --> 00:41:30,030
a big debate in

691
00:41:26,850 --> 00:41:33,540
I community because the real world is

692
00:41:30,030 --> 00:41:36,240
biased right and so there's one school

693
00:41:33,540 --> 00:41:39,420
of thought in the eye community that

694
00:41:36,240 --> 00:41:42,930
says hey the real world is biased we

695
00:41:39,420 --> 00:41:45,780
just giving a representation of the real

696
00:41:42,930 --> 00:41:48,480
world to the algorithm and another

697
00:41:45,780 --> 00:41:50,460
school of thought is yeah the real world

698
00:41:48,480 --> 00:41:53,880
of bias doesn't mean we have to repeat

699
00:41:50,460 --> 00:41:57,420
this in in AI world we have to fix

700
00:41:53,880 --> 00:42:02,220
biased now when you get to fix bias

701
00:41:57,420 --> 00:42:07,100
you're kind of like a god so how far do

702
00:42:02,220 --> 00:42:11,370
you change the bias how far where is

703
00:42:07,100 --> 00:42:15,540
where is the the center of fairness it's

704
00:42:11,370 --> 00:42:18,750
really hard to to determine because now

705
00:42:15,540 --> 00:42:25,410
you're playing not only with data you

706
00:42:18,750 --> 00:42:27,840
playing with actual societal impact so

707
00:42:25,410 --> 00:42:28,440
again going back to what's real what's

708
00:42:27,840 --> 00:42:30,900
fair

709
00:42:28,440 --> 00:42:32,610
we don't write in the early days

710
00:42:30,900 --> 00:42:35,880
remember the saying nobody knows you are

711
00:42:32,610 --> 00:42:42,180
a dog on the internet today nobody knows

712
00:42:35,880 --> 00:42:44,490
you are an AI on the Internet the big

713
00:42:42,180 --> 00:42:48,500
question a lot of computer scientists

714
00:42:44,490 --> 00:42:52,319
are wondering is how far are we

715
00:42:48,500 --> 00:42:56,190
until an AI algorithm can very

716
00:42:52,320 --> 00:42:58,380
confidently pass the Turing test you

717
00:42:56,190 --> 00:43:01,770
guys know what the Turing test is right

718
00:42:58,380 --> 00:43:04,770
so today even though I've shown you a

719
00:43:01,770 --> 00:43:06,470
ton of interesting examples of AI

720
00:43:04,770 --> 00:43:09,000
[Music]

721
00:43:06,470 --> 00:43:12,959
manipulating data or generating results

722
00:43:09,000 --> 00:43:16,470
look like a real still it has not been

723
00:43:12,960 --> 00:43:19,350
the case that an AI algorithm can

724
00:43:16,470 --> 00:43:22,319
consistently pass Turing test because

725
00:43:19,350 --> 00:43:26,220
why most of the AI algorithm has an

726
00:43:22,320 --> 00:43:28,090
immediate scope it's written for a Java

727
00:43:26,220 --> 00:43:33,160
for a specific

728
00:43:28,090 --> 00:43:36,220
purpose or it's processing specific set

729
00:43:33,160 --> 00:43:38,440
of application data there has to be able

730
00:43:36,220 --> 00:43:41,709
to pass touring test it has to be a

731
00:43:38,440 --> 00:43:43,930
general purpose algorithm just like a

732
00:43:41,710 --> 00:43:46,750
human you know you can you can take any

733
00:43:43,930 --> 00:43:49,720
kind of input you ask me any question

734
00:43:46,750 --> 00:43:51,430
I'll give you an answer may not be the

735
00:43:49,720 --> 00:43:55,750
right answer but I know how to process

736
00:43:51,430 --> 00:43:58,600
this question and generate an answer the

737
00:43:55,750 --> 00:44:02,470
AI algorithms today and I don't know how

738
00:43:58,600 --> 00:44:04,630
many of you have seen the so Google i/o

739
00:44:02,470 --> 00:44:07,049
conference every year they have these

740
00:44:04,630 --> 00:44:10,780
really interesting demos and last year

741
00:44:07,050 --> 00:44:14,080
the president the Google CEO did this

742
00:44:10,780 --> 00:44:16,810
demo of having AI calling a restaurant

743
00:44:14,080 --> 00:44:20,310
to make a reservation actually used that

744
00:44:16,810 --> 00:44:23,590
quite a few times and it's really really

745
00:44:20,310 --> 00:44:27,250
real I mean the way I algorithm would

746
00:44:23,590 --> 00:44:30,040
even say oh I want three people Oh No

747
00:44:27,250 --> 00:44:34,150
maybe four people tonight and they did

748
00:44:30,040 --> 00:44:36,730
this live on stage with a restaurant in

749
00:44:34,150 --> 00:44:38,800
New York making reservations with a

750
00:44:36,730 --> 00:44:40,390
Chinese restaurant in New York and the

751
00:44:38,800 --> 00:44:44,260
person who picked up the phone on the

752
00:44:40,390 --> 00:44:47,049
other hand had no idea it was AI calling

753
00:44:44,260 --> 00:44:49,840
her and she's a worker in the Chinese

754
00:44:47,050 --> 00:44:52,990
restaurant with heavy Chinese accent

755
00:44:49,840 --> 00:44:56,020
speaking back how many people you want

756
00:44:52,990 --> 00:45:00,069
and that algorithm correctly answered

757
00:44:56,020 --> 00:45:03,400
all her questions that particular

758
00:45:00,070 --> 00:45:06,370
algorithm if you give give the algorithm

759
00:45:03,400 --> 00:45:08,380
a question about what's the weather like

760
00:45:06,370 --> 00:45:10,330
today you may not be able to answer

761
00:45:08,380 --> 00:45:15,270
really well because that the core

762
00:45:10,330 --> 00:45:18,700
algorithm anticipates questions

763
00:45:15,270 --> 00:45:20,620
interactions in a booking restaurant

764
00:45:18,700 --> 00:45:22,930
type of interaction it doesn't process

765
00:45:20,620 --> 00:45:25,710
others really well so it does not

766
00:45:22,930 --> 00:45:31,470
qualify as a general purpose AI

767
00:45:25,710 --> 00:45:34,480
algorithm now this is a 2014 test where

768
00:45:31,470 --> 00:45:37,299
hundreds of people were brought in and

769
00:45:34,480 --> 00:45:39,020
needs university to interact with with a

770
00:45:37,300 --> 00:45:42,200
chat bar they they

771
00:45:39,020 --> 00:45:44,570
and randomly either intact with the

772
00:45:42,200 --> 00:45:48,020
chapel or intact with a real human and

773
00:45:44,570 --> 00:45:49,580
then in the end write down whether they

774
00:45:48,020 --> 00:45:57,490
think it's they're interacting with

775
00:45:49,580 --> 00:46:02,660
about or human so 33% the test subject

776
00:45:57,490 --> 00:46:06,490
misidentified AI versus human so 33 you

777
00:46:02,660 --> 00:46:09,109
know it's not quite at the level passing

778
00:46:06,490 --> 00:46:10,850
this this particular test for instance

779
00:46:09,110 --> 00:46:13,730
it's actually disqualifying me and

780
00:46:10,850 --> 00:46:18,799
because they put in too much constraints

781
00:46:13,730 --> 00:46:21,140
but 33% is not low in the real-world use

782
00:46:18,800 --> 00:46:23,360
case right but again it's not quite

783
00:46:21,140 --> 00:46:26,810
passing the Turing test but what happens

784
00:46:23,360 --> 00:46:31,640
when it does pass touring test I was

785
00:46:26,810 --> 00:46:35,060
gonna do a video of do you guys want to

786
00:46:31,640 --> 00:46:37,879
see this making reservations this is

787
00:46:35,060 --> 00:46:41,000
interesting I actually now when you go

788
00:46:37,880 --> 00:46:44,720
to Google Google map if you search for a

789
00:46:41,000 --> 00:46:47,930
business and it pops up some businesses

790
00:46:44,720 --> 00:46:49,790
has a underneath it has a reserved a

791
00:46:47,930 --> 00:46:51,109
table you just reserved it in the

792
00:46:49,790 --> 00:46:54,430
backend Google is calling that

793
00:46:51,110 --> 00:46:54,430
restaurant to reserve for you

794
00:47:35,420 --> 00:47:41,240
so the man's voice through the AI

795
00:47:39,090 --> 00:47:44,640
January voice the woman is a real

796
00:47:41,240 --> 00:47:47,729
restaurant worker in New York right can

797
00:47:44,640 --> 00:47:53,129
you tell you can't tell I was so

798
00:47:47,730 --> 00:48:00,030
impressed when I saw this but the

799
00:47:53,130 --> 00:48:03,750
problem is obviously as AI gets more and

800
00:48:00,030 --> 00:48:06,840
more sophisticated it's just harder and

801
00:48:03,750 --> 00:48:09,060
harder for us to tell whether it's AI or

802
00:48:06,840 --> 00:48:11,490
human and as we know in computer

803
00:48:09,060 --> 00:48:13,740
security there are a lot of scenarios in

804
00:48:11,490 --> 00:48:15,779
which we need to tell whether this is

805
00:48:13,740 --> 00:48:18,089
human or not a human right some of you

806
00:48:15,780 --> 00:48:21,090
work on authentication right

807
00:48:18,090 --> 00:48:22,110
so how do we do this when the chat bots

808
00:48:21,090 --> 00:48:23,790
are getting more and more sophisticated

809
00:48:22,110 --> 00:48:27,720
when AI is getting more and more

810
00:48:23,790 --> 00:48:31,140
sophisticated the only way we can

811
00:48:27,720 --> 00:48:41,339
determine between humans and computers

812
00:48:31,140 --> 00:48:45,750
are and you guess so yeah find problems

813
00:48:41,340 --> 00:48:49,200
that are hard for computers but are easy

814
00:48:45,750 --> 00:48:51,630
for humans what what kind of problem are

815
00:48:49,200 --> 00:48:56,879
there that are easy for humans and

816
00:48:51,630 --> 00:49:01,400
difficult for computers I'm sorry say it

817
00:48:56,880 --> 00:49:01,400
again emotional

818
00:49:01,890 --> 00:49:11,680
how do you process emotion so touring

819
00:49:07,900 --> 00:49:19,240
has this famous well not a quote but

820
00:49:11,680 --> 00:49:22,060
famous response to to a challenger in

821
00:49:19,240 --> 00:49:25,959
his lifetime I guess so so this person

822
00:49:22,060 --> 00:49:29,140
was saying that to touring that you can

823
00:49:25,960 --> 00:49:32,800
never have a computer that as as

824
00:49:29,140 --> 00:49:35,109
equivalent as I am because how does the

825
00:49:32,800 --> 00:49:38,800
computer feel emotion how does the

826
00:49:35,110 --> 00:49:42,730
computer feel the the tell me the

827
00:49:38,800 --> 00:49:47,080
feeling of rain on my skin and then then

828
00:49:42,730 --> 00:49:49,360
touring retorted back says you think you

829
00:49:47,080 --> 00:49:53,259
know emotions but how do you demonstrate

830
00:49:49,360 --> 00:49:56,290
to me that you know emotion that's the

831
00:49:53,260 --> 00:49:58,360
question is you know you're a person but

832
00:49:56,290 --> 00:50:00,430
how do you that the trick is not you

833
00:49:58,360 --> 00:50:03,700
know is you have to convince other

834
00:50:00,430 --> 00:50:05,919
people that you know emotions better

835
00:50:03,700 --> 00:50:12,220
than the computer algorithm and that

836
00:50:05,920 --> 00:50:14,350
demonstration is hard now this is a

837
00:50:12,220 --> 00:50:17,830
simple example that's getting more and

838
00:50:14,350 --> 00:50:21,069
more actually not not as clear-cut

839
00:50:17,830 --> 00:50:23,380
anymore but capture everybody knows the

840
00:50:21,070 --> 00:50:27,520
reason capture was generated was that

841
00:50:23,380 --> 00:50:29,530
it's at that time optical character

842
00:50:27,520 --> 00:50:31,990
recognition algorithm was hard to for

843
00:50:29,530 --> 00:50:34,990
computers but easy for human human look

844
00:50:31,990 --> 00:50:37,450
at twisted characters and can tell very

845
00:50:34,990 --> 00:50:39,669
easily by for computers are harder now

846
00:50:37,450 --> 00:50:41,950
today they don't actually do that much

847
00:50:39,670 --> 00:50:44,530
anymore right so today they just ask you

848
00:50:41,950 --> 00:50:46,899
to click I'm another robot right you

849
00:50:44,530 --> 00:50:48,940
have this experience right so why did

850
00:50:46,900 --> 00:50:52,900
they go from having you recognize these

851
00:50:48,940 --> 00:50:56,380
twit twit ly characters to just click a

852
00:50:52,900 --> 00:51:03,220
button says I'm not a robot do you know

853
00:50:56,380 --> 00:51:06,479
do you know why they can't the the box

854
00:51:03,220 --> 00:51:09,729
can can click buttons but guess what

855
00:51:06,479 --> 00:51:12,509
it's hard for them to mimic the way you

856
00:51:09,729 --> 00:51:15,249
move the mouse to click the button

857
00:51:12,509 --> 00:51:17,079
humans moving mouse is never in a

858
00:51:15,249 --> 00:51:19,299
consistent way you never move in the

859
00:51:17,079 --> 00:51:21,069
straight-line you move in their way the

860
00:51:19,299 --> 00:51:28,960
only humans do right because you just

861
00:51:21,069 --> 00:51:32,049
not that precise seriously and turns out

862
00:51:28,960 --> 00:51:33,970
the computer can fake an aqua size but

863
00:51:32,049 --> 00:51:35,920
for them to be not precise in the same

864
00:51:33,970 --> 00:51:38,769
way humans not precise that's actually

865
00:51:35,920 --> 00:51:40,539
work so that's why they actually doing

866
00:51:38,769 --> 00:51:42,609
this I'm not a robot they just all they

867
00:51:40,539 --> 00:51:45,549
want is to show how you do add the mouse

868
00:51:42,609 --> 00:51:46,900
across the screen and click it and if

869
00:51:45,549 --> 00:51:57,069
you're able to do it in the human way

870
00:51:46,900 --> 00:52:01,180
you're human AI is hard in identifying

871
00:51:57,069 --> 00:52:06,089
nuances humans are good in identifying

872
00:52:01,180 --> 00:52:09,009
nuances I'll give you one example a

873
00:52:06,089 --> 00:52:13,920
friend not actually friends but know

874
00:52:09,009 --> 00:52:19,239
somebody you recognize then this is a

875
00:52:13,920 --> 00:52:27,609
fitness model picture online and these

876
00:52:19,239 --> 00:52:29,380
are again other models online so I as a

877
00:52:27,609 --> 00:52:31,719
human I look at the picture of the

878
00:52:29,380 --> 00:52:33,579
friend and I look at the three three

879
00:52:31,719 --> 00:52:35,680
women picture kind of look like I'm like

880
00:52:33,579 --> 00:52:37,569
and that's not her cuz I know those

881
00:52:35,680 --> 00:52:40,210
women look like her but that's not her

882
00:52:37,569 --> 00:52:44,259
but if you see these grouper picture

883
00:52:40,210 --> 00:52:46,059
into an AI algorithm this is a natural

884
00:52:44,259 --> 00:52:50,289
experiment the algorithm one I'm not

885
00:52:46,059 --> 00:52:55,749
gonna say who's 73% misidentified

886
00:52:50,289 --> 00:52:59,969
meaning that 73% of time actually I'm

887
00:52:55,749 --> 00:53:01,828
sorry 73% of time it correctly identify

888
00:52:59,969 --> 00:53:05,969
27% of time

889
00:53:01,829 --> 00:53:08,519
identify sorry I was wrong in the column

890
00:53:05,969 --> 00:53:11,579
there and algorithm to perform even

891
00:53:08,519 --> 00:53:14,160
worse right so what that says 20-some

892
00:53:11,579 --> 00:53:16,700
percent of the time they misidentified

893
00:53:14,160 --> 00:53:19,769
this woman as as part of that data set

894
00:53:16,700 --> 00:53:21,779
while she's not the reason she's

895
00:53:19,769 --> 00:53:24,029
misidentified is she has the

896
00:53:21,779 --> 00:53:26,819
characteristics of similar to the other

897
00:53:24,029 --> 00:53:28,769
woman where you know the distance

898
00:53:26,819 --> 00:53:30,599
between R is the distance between the

899
00:53:28,769 --> 00:53:33,629
brow and the mouth these are all

900
00:53:30,599 --> 00:53:37,499
computer that the information algorithm

901
00:53:33,630 --> 00:53:40,049
pulls out and calculate but for human

902
00:53:37,499 --> 00:53:42,419
human doesn't look at that human kind of

903
00:53:40,049 --> 00:53:44,640
have an imprint of a face and then look

904
00:53:42,420 --> 00:53:46,380
at another face and of all not the same

905
00:53:44,640 --> 00:53:48,239
person even though if they have the same

906
00:53:46,380 --> 00:53:50,309
distance between our eyes and same

907
00:53:48,239 --> 00:53:53,069
distance between so that's the human

908
00:53:50,309 --> 00:53:57,569
processing nuances computers processed

909
00:53:53,069 --> 00:54:01,380
data now given either case you could

910
00:53:57,569 --> 00:54:03,538
actually generate algorithm having

911
00:54:01,380 --> 00:54:07,430
specific data that you can spot the

912
00:54:03,539 --> 00:54:08,640
human user consistently versus the the

913
00:54:07,430 --> 00:54:12,569
AI

914
00:54:08,640 --> 00:54:14,879
the bot so the way to do it this is just

915
00:54:12,569 --> 00:54:17,489
an experiment you put up you know that

916
00:54:14,880 --> 00:54:21,749
somebody you know the face then you put

917
00:54:17,489 --> 00:54:24,809
up a group of faces that are similar but

918
00:54:21,749 --> 00:54:27,118
with one other face that's that person's

919
00:54:24,809 --> 00:54:29,519
face and then you ask the human you ask

920
00:54:27,119 --> 00:54:31,559
to whoever comes to authenticate pick

921
00:54:29,519 --> 00:54:33,839
the picture

922
00:54:31,559 --> 00:54:37,249
pick the picture that is that person

923
00:54:33,839 --> 00:54:41,819
right the first first face now humans

924
00:54:37,249 --> 00:54:44,578
knowing that friend it has to be

925
00:54:41,819 --> 00:54:46,920
familiar friend face know always

926
00:54:44,579 --> 00:54:51,779
correctly identify who that is

927
00:54:46,920 --> 00:54:54,329
and say I would have you know as I said

928
00:54:51,779 --> 00:54:58,769
earlier 73 percent 68 percent confidence

929
00:54:54,329 --> 00:55:02,130
now in that there's got their human can

930
00:54:58,769 --> 00:55:04,738
correctly identify AI cannot but a

931
00:55:02,130 --> 00:55:06,329
real-world use case is harder because

932
00:55:04,739 --> 00:55:08,400
you can't just keep feeding them those

933
00:55:06,329 --> 00:55:10,759
faces and have the human authentic a

934
00:55:08,400 --> 00:55:12,810
that use abilities not there right but

935
00:55:10,759 --> 00:55:16,560
theoretically that's

936
00:55:12,810 --> 00:55:19,470
and if you want more confidence what you

937
00:55:16,560 --> 00:55:21,660
could do is you could then flip the

938
00:55:19,470 --> 00:55:24,720
problem around you can show the human a

939
00:55:21,660 --> 00:55:27,240
strangers face that face that he or

940
00:55:24,720 --> 00:55:30,450
she's never seen it before and then you

941
00:55:27,240 --> 00:55:33,600
gave them another set of faces to say

942
00:55:30,450 --> 00:55:36,600
hey pick out one that's that person now

943
00:55:33,600 --> 00:55:39,330
given that a stranger's face the human's

944
00:55:36,600 --> 00:55:42,900
guessing will be probably as good as

945
00:55:39,330 --> 00:55:46,560
random guessing but computers will

946
00:55:42,900 --> 00:55:48,450
actually make a better guess because

947
00:55:46,560 --> 00:55:53,180
it's trying to pick out the same

948
00:55:48,450 --> 00:55:54,319
characteristics so there again is the

949
00:55:53,180 --> 00:55:57,660
[Music]

950
00:55:54,320 --> 00:56:00,750
trying to tell the difference between a

951
00:55:57,660 --> 00:56:04,470
human how human process information and

952
00:56:00,750 --> 00:56:07,860
how computer process information so as

953
00:56:04,470 --> 00:56:10,200
as you seen more and more education

954
00:56:07,860 --> 00:56:10,920
algorithm these days are picking on that

955
00:56:10,200 --> 00:56:13,980
difference

956
00:56:10,920 --> 00:56:18,240
humans are less precise computers are

957
00:56:13,980 --> 00:56:21,210
more precise and that is an interesting

958
00:56:18,240 --> 00:56:26,160
difference so um how much time do I have

959
00:56:21,210 --> 00:56:27,900
I don't want we have 15 minutes okay so

960
00:56:26,160 --> 00:56:32,609
I'm coming to them so we can have some

961
00:56:27,900 --> 00:56:36,830
questions in the artificial intelligence

962
00:56:32,610 --> 00:56:39,930
world you have so the ranking of

963
00:56:36,830 --> 00:56:42,240
complexity and sophistication of things

964
00:56:39,930 --> 00:56:45,509
you can do natural language processing

965
00:56:42,240 --> 00:56:47,910
is the lowest also lowest on the run and

966
00:56:45,510 --> 00:56:51,690
then you have processing of audio and

967
00:56:47,910 --> 00:56:55,580
video information then you have being

968
00:56:51,690 --> 00:56:58,800
able to perform a physical task by a

969
00:56:55,580 --> 00:57:01,350
computer by a robot as opposed to in the

970
00:56:58,800 --> 00:57:03,960
human perform physical task then then

971
00:57:01,350 --> 00:57:06,960
you go to thought patterns how does

972
00:57:03,960 --> 00:57:08,640
human process thought patterns and and

973
00:57:06,960 --> 00:57:11,520
how does computer repeat thought

974
00:57:08,640 --> 00:57:14,730
patterns and then as this gentleman

975
00:57:11,520 --> 00:57:18,330
there correctly said emotions how do we

976
00:57:14,730 --> 00:57:21,630
replicate human emotions and it is

977
00:57:18,330 --> 00:57:22,710
really about not about thinking of

978
00:57:21,630 --> 00:57:26,820
emotion

979
00:57:22,710 --> 00:57:29,190
about the interaction of emotions can I

980
00:57:26,820 --> 00:57:32,510
ask you a question that you give me an

981
00:57:29,190 --> 00:57:35,640
answer which tells me you correctly

982
00:57:32,510 --> 00:57:38,310
generate an emotional response to that

983
00:57:35,640 --> 00:57:41,129
question and what would that question be

984
00:57:38,310 --> 00:57:44,790
and what is the anticipated emotional

985
00:57:41,130 --> 00:57:47,339
response if you are human that is a

986
00:57:44,790 --> 00:57:50,220
really really interesting research area

987
00:57:47,339 --> 00:57:53,130
in artificial intelligence today and at

988
00:57:50,220 --> 00:57:55,680
the end and that actually deception I

989
00:57:53,130 --> 00:57:59,520
added in the end I said you know if all

990
00:57:55,680 --> 00:58:05,069
else if all these sophistication levels

991
00:57:59,520 --> 00:58:09,119
been passed and computers can deceive

992
00:58:05,070 --> 00:58:13,470
humans in the end that is where all

993
00:58:09,119 --> 00:58:15,960
fails because if they are not a not only

994
00:58:13,470 --> 00:58:20,129
able to process language process all the

995
00:58:15,960 --> 00:58:22,260
video process a lot of data but they're

996
00:58:20,130 --> 00:58:25,430
able to actually correctly give you

997
00:58:22,260 --> 00:58:28,710
information that deceives you

998
00:58:25,430 --> 00:58:36,210
then we are entering an era that is

999
00:58:28,710 --> 00:58:45,180
posterior and if we look to the future

1000
00:58:36,210 --> 00:58:48,510
we're working Moore's laws are giving us

1001
00:58:45,180 --> 00:58:53,520
more and more resources to play with

1002
00:58:48,510 --> 00:58:56,099
right so the problems that are hard for

1003
00:58:53,520 --> 00:58:58,140
computers today may not be hard for

1004
00:58:56,099 --> 00:59:01,320
computers tomorrow because we have more

1005
00:58:58,140 --> 00:59:03,839
resources to play with and we better a

1006
00:59:01,320 --> 00:59:06,930
generating AI algorithms now we're

1007
00:59:03,839 --> 00:59:09,180
better at classification and also we

1008
00:59:06,930 --> 00:59:15,089
have more and more data every day to

1009
00:59:09,180 --> 00:59:17,700
play with so that works for both sides

1010
00:59:15,089 --> 00:59:20,640
no more data more resources are

1011
00:59:17,700 --> 00:59:22,830
available for the defenders so we can do

1012
00:59:20,640 --> 00:59:26,009
things better but they're also available

1013
00:59:22,830 --> 00:59:29,490
for the attackers so they can attack us

1014
00:59:26,010 --> 00:59:35,140
in a more sophisticated way

1015
00:59:29,490 --> 00:59:40,359
whose job is it to ensure trust in the

1016
00:59:35,140 --> 00:59:42,790
AI world in the post AI world if it is

1017
00:59:40,359 --> 00:59:45,779
not the job of a computer security

1018
00:59:42,790 --> 00:59:50,829
professionals I think it's absolutely

1019
00:59:45,780 --> 00:59:55,089
our community's job to ensure that the

1020
00:59:50,829 --> 00:59:59,560
information that we use the data we get

1021
00:59:55,089 --> 01:00:04,690
the decisions we make in the future are

1022
00:59:59,560 --> 01:00:09,490
trustworthy or robust are sound and how

1023
01:00:04,690 --> 01:00:15,579
do we do that I think a lot of us should

1024
01:00:09,490 --> 01:00:18,569
become data scientists computer security

1025
01:00:15,579 --> 01:00:23,230
expertise a lot of it is about spotting

1026
01:00:18,569 --> 01:00:28,000
signals from noise right so we are we're

1027
01:00:23,230 --> 01:00:32,700
looking at extracting events from sock

1028
01:00:28,000 --> 01:00:36,160
that are interesting to process that

1029
01:00:32,700 --> 01:00:38,529
fundamentally is a data analytics job

1030
01:00:36,160 --> 01:00:44,339
even though on a day to day basis you

1031
01:00:38,530 --> 01:00:51,510
may not think of that way so I think

1032
01:00:44,339 --> 01:00:55,299
many of us we would have a better

1033
01:00:51,510 --> 01:00:58,690
interesting platform to play with if we

1034
01:00:55,300 --> 01:01:01,150
were to pick up more data science data

1035
01:00:58,690 --> 01:01:07,869
analytics capabilities as computer

1036
01:01:01,150 --> 01:01:10,750
security person and as a community so

1037
01:01:07,869 --> 01:01:14,130
what is data science right it's it's

1038
01:01:10,750 --> 01:01:17,020
really about getting a bunch of data

1039
01:01:14,130 --> 01:01:19,000
into a black box could be an algorithm

1040
01:01:17,020 --> 01:01:21,240
could be in a human assisted algorithm

1041
01:01:19,000 --> 01:01:24,940
at the end you come out with different

1042
01:01:21,240 --> 01:01:28,209
classification so this is this data item

1043
01:01:24,940 --> 01:01:30,640
belong in the red class this data item

1044
01:01:28,210 --> 01:01:36,140
belongs in the blue class

1045
01:01:30,640 --> 01:01:40,000
all a I does is that not much beyond

1046
01:01:36,140 --> 01:01:42,770
that today but the transformation

1047
01:01:40,000 --> 01:01:46,190
meaning that going from data to that

1048
01:01:42,770 --> 01:01:48,170
classification is extremely interesting

1049
01:01:46,190 --> 01:01:50,900
and you can see lots of applications for

1050
01:01:48,170 --> 01:01:53,480
computer security right is the blue the

1051
01:01:50,900 --> 01:01:56,480
blue class the legitimate class the red

1052
01:01:53,480 --> 01:01:59,960
class the anomaly the the attacks the

1053
01:01:56,480 --> 01:02:02,690
threats those are the differentiation

1054
01:01:59,960 --> 01:02:08,690
the the determination that we need to

1055
01:02:02,690 --> 01:02:12,860
make so just to close up you saw some

1056
01:02:08,690 --> 01:02:15,290
deep fake videos earlier and so there's

1057
01:02:12,860 --> 01:02:18,800
obviously a lot of research now focusing

1058
01:02:15,290 --> 01:02:22,940
on how to spot deep fake okay and and

1059
01:02:18,800 --> 01:02:26,780
that is a defense touch so the way to

1060
01:02:22,940 --> 01:02:28,340
spot it not not foolproof but when the

1061
01:02:26,780 --> 01:02:30,140
person speaks

1062
01:02:28,340 --> 01:02:37,900
this person has a particular way of

1063
01:02:30,140 --> 01:02:42,020
tilting his or her head the the way they

1064
01:02:37,900 --> 01:02:44,930
changed the like the corner of the mouth

1065
01:02:42,020 --> 01:02:47,780
how they moves is also fairly particular

1066
01:02:44,930 --> 01:02:50,839
to that person so getting those

1067
01:02:47,780 --> 01:02:53,330
information out and comparing with a

1068
01:02:50,840 --> 01:02:55,340
deep fake video comparing with just

1069
01:02:53,330 --> 01:02:58,069
another video to see if that's deep fake

1070
01:02:55,340 --> 01:03:02,510
that is where the research today lies

1071
01:02:58,070 --> 01:03:05,870
and again that is know nothing more than

1072
01:03:02,510 --> 01:03:08,090
anomaly detection right so building a

1073
01:03:05,870 --> 01:03:10,819
model of what's normal and you're trying

1074
01:03:08,090 --> 01:03:18,130
to detect the new item whether that's

1075
01:03:10,820 --> 01:03:21,740
normal or not so for us I think

1076
01:03:18,130 --> 01:03:25,610
defendable AI is the future right so

1077
01:03:21,740 --> 01:03:29,149
what is defendable AI is we have to

1078
01:03:25,610 --> 01:03:32,890
develop models and test methods to build

1079
01:03:29,150 --> 01:03:35,810
trust in our model so we have to be

1080
01:03:32,890 --> 01:03:39,140
comfortable and confident that the data

1081
01:03:35,810 --> 01:03:40,290
is robust is not tamper it's not

1082
01:03:39,140 --> 01:03:43,980
tampered

1083
01:03:40,290 --> 01:03:48,529
is robust and is fair according to some

1084
01:03:43,980 --> 01:03:52,380
metric of fairness and we can use

1085
01:03:48,530 --> 01:03:55,140
generative adversarial network to test

1086
01:03:52,380 --> 01:03:59,010
the robustness and soundness of the

1087
01:03:55,140 --> 01:04:00,750
model and another thing that we need to

1088
01:03:59,010 --> 01:04:02,880
do that which I didn't even get into

1089
01:04:00,750 --> 01:04:05,400
those talk words because a whole other

1090
01:04:02,880 --> 01:04:09,510
talk can go along with it is how do we

1091
01:04:05,400 --> 01:04:12,330
establish privacy baselines for the use

1092
01:04:09,510 --> 01:04:16,620
of data for the dissemination and the

1093
01:04:12,330 --> 01:04:21,029
for the correct governance of analytics

1094
01:04:16,620 --> 01:04:24,390
on the data so with that I'm going to

1095
01:04:21,030 --> 01:04:26,520
conclude and this is my contact

1096
01:04:24,390 --> 01:04:28,560
information feel free to send me email

1097
01:04:26,520 --> 01:04:32,190
or follow me on Twitter or LinkedIn pie

1098
01:04:28,560 --> 01:04:55,830
in Arlington I am happy to take

1099
01:04:32,190 --> 01:04:58,040
questions now if there is any consider

1100
01:04:55,830 --> 01:04:58,040
what

1101
01:05:07,599 --> 01:05:15,619
yeah so the question is he works this

1102
01:05:13,069 --> 01:05:18,710
gentleman works in telecom and they have

1103
01:05:15,619 --> 01:05:22,819
lots of voice recordings and natural

1104
01:05:18,710 --> 01:05:25,759
language of processing capabilities that

1105
01:05:22,819 --> 01:05:29,180
can take the voice recording into actual

1106
01:05:25,759 --> 01:05:31,160
text and there's confusion about what

1107
01:05:29,180 --> 01:05:36,259
the legal implication is does that

1108
01:05:31,160 --> 01:05:37,069
constitute voice typing right now I'm

1109
01:05:36,259 --> 01:05:39,499
not a lawyer

1110
01:05:37,069 --> 01:05:42,529
so I can't answer that question from a

1111
01:05:39,499 --> 01:05:46,519
legal standpoint but what I what I do

1112
01:05:42,529 --> 01:05:50,960
know from discussion with my friends who

1113
01:05:46,519 --> 01:05:54,649
are in the privacy sector is that if the

1114
01:05:50,960 --> 01:06:01,190
recording is out is public as opposed to

1115
01:05:54,650 --> 01:06:06,499
you know lawyers clients you know that

1116
01:06:01,190 --> 01:06:08,749
kind of a confidential conversation but

1117
01:06:06,499 --> 01:06:11,569
if the recording is public and if I

1118
01:06:08,749 --> 01:06:14,509
publish if I consent it for this video

1119
01:06:11,569 --> 01:06:18,288
this to be published I have no way of

1120
01:06:14,509 --> 01:06:22,279
claiming that is why tapping right so

1121
01:06:18,289 --> 01:06:23,960
but in your case I don't know if the

1122
01:06:22,279 --> 01:06:30,319
video recordings are public

1123
01:06:23,960 --> 01:06:32,269
hence the usage of I guess taking a step

1124
01:06:30,319 --> 01:06:35,589
back what my friend said and then you

1125
01:06:32,269 --> 01:06:37,848
need to check that the the privacy

1126
01:06:35,589 --> 01:06:40,339
implication that governing the video

1127
01:06:37,849 --> 01:06:42,950
recording is the same that governs the

1128
01:06:40,339 --> 01:06:47,150
text because the text is generated from

1129
01:06:42,950 --> 01:06:48,919
the recording so but check your lead

1130
01:06:47,150 --> 01:06:54,750
with your legal counsel don't take my

1131
01:06:48,920 --> 01:07:44,170
word other questions yes

1132
01:06:54,750 --> 01:07:45,790
yes yeah yeah absolutely so this is

1133
01:07:44,170 --> 01:07:48,130
really good question this gentleman

1134
01:07:45,790 --> 01:07:50,950
asked you know because where I show deep

1135
01:07:48,130 --> 01:07:54,880
fake video shows briefly some of the

1136
01:07:50,950 --> 01:07:57,490
mitigation methods there's also the Gann

1137
01:07:54,880 --> 01:08:01,420
method which is you know 2 AI algorithms

1138
01:07:57,490 --> 01:08:05,500
competing against each other and making

1139
01:08:01,420 --> 01:08:07,480
the making one like subsequently

1140
01:08:05,500 --> 01:08:12,010
produced by the results and and he was

1141
01:08:07,480 --> 01:08:13,750
asking that you know this whole field is

1142
01:08:12,010 --> 01:08:16,600
just going the direction that's really a

1143
01:08:13,750 --> 01:08:19,420
part to get your hands around and you

1144
01:08:16,600 --> 01:08:21,520
could get to a stage where you know a

1145
01:08:19,420 --> 01:08:25,299
head of state would declare war on each

1146
01:08:21,520 --> 01:08:29,650
other with a deep fake video and and the

1147
01:08:25,299 --> 01:08:32,470
other I guess mitigation method methods

1148
01:08:29,649 --> 01:08:36,129
outside of just processing the data and

1149
01:08:32,470 --> 01:08:39,310
making sure the data or detecting deep

1150
01:08:36,130 --> 01:08:42,430
fake are their methods like PK I you

1151
01:08:39,310 --> 01:08:46,960
know signing the video and absolutely

1152
01:08:42,430 --> 01:08:49,750
yes so I this talk focused on what's

1153
01:08:46,960 --> 01:08:53,049
happening in AI a community right this

1154
01:08:49,750 --> 01:08:56,410
is all about how do I make sure my

1155
01:08:53,049 --> 01:09:01,210
algorithm is accurate or how do I detect

1156
01:08:56,410 --> 01:09:02,630
this is deep fake they don't you know in

1157
01:09:01,210 --> 01:09:04,939
this talk and

1158
01:09:02,630 --> 01:09:07,100
papers that I've been following don't

1159
01:09:04,939 --> 01:09:09,979
really talk about what are the external

1160
01:09:07,100 --> 01:09:12,980
compensating controls that you can use

1161
01:09:09,979 --> 01:09:15,080
to mitigate some societal impact but but

1162
01:09:12,979 --> 01:09:18,049
you bet that outside of that community a

1163
01:09:15,080 --> 01:09:20,089
ton of discussion is happening on what

1164
01:09:18,049 --> 01:09:23,120
can we do if there's dick fake fake

1165
01:09:20,089 --> 01:09:25,689
video out there that really has severe

1166
01:09:23,120 --> 01:09:28,580
consequence to society

1167
01:09:25,689 --> 01:09:31,009
absolutely the source authentication

1168
01:09:28,580 --> 01:09:34,698
where it came from

1169
01:09:31,009 --> 01:09:36,889
the watermarking they're people working

1170
01:09:34,698 --> 01:09:42,769
on water marking of videos tamper

1171
01:09:36,889 --> 01:09:44,929
resistance videos all that are will come

1172
01:09:42,770 --> 01:09:46,909
to play I think when this actually

1173
01:09:44,929 --> 01:09:51,830
becomes a problem that we need to deal

1174
01:09:46,908 --> 01:09:56,629
with the question right now is how far

1175
01:09:51,830 --> 01:09:59,600
can these mechanisms go right before it

1176
01:09:56,630 --> 01:10:01,909
really becomes a widespread problem and

1177
01:09:59,600 --> 01:10:04,400
and today the compensating controls

1178
01:10:01,909 --> 01:10:06,559
around that not in not yet deployed

1179
01:10:04,400 --> 01:10:13,330
because it's not quite a problem but at

1180
01:10:06,560 --> 01:10:13,330
some point yes yes another question

1181
01:10:17,460 --> 01:10:20,649
[Music]

1182
01:10:28,540 --> 01:10:31,680
[Music]

1183
01:10:45,320 --> 01:10:53,280
yeah yeah so that right so is that the

1184
01:10:50,790 --> 01:10:57,150
question well just a comment coming yeah

1185
01:10:53,280 --> 01:10:59,580
so yeah right the capture was getting

1186
01:10:57,150 --> 01:11:01,860
harder and harder for human because they

1187
01:10:59,580 --> 01:11:03,750
would get OCR who's getting better and

1188
01:11:01,860 --> 01:11:06,290
computer algorithms were passing them

1189
01:11:03,750 --> 01:11:09,690
more and more so they had to make the

1190
01:11:06,290 --> 01:11:11,280
character more obscure more difficult

1191
01:11:09,690 --> 01:11:13,740
and then you got to a point that

1192
01:11:11,280 --> 01:11:15,540
usability was so poor so they had to

1193
01:11:13,740 --> 01:11:19,170
move on from the first generation

1194
01:11:15,540 --> 01:11:22,710
capture but capture was generated the

1195
01:11:19,170 --> 01:11:26,640
manual um who was a colleague of mine at

1196
01:11:22,710 --> 01:11:28,620
CMU I remember CAPTCHA was done when I

1197
01:11:26,640 --> 01:11:30,360
was there and I remember he will walk

1198
01:11:28,620 --> 01:11:32,970
down the corridor I see him here and say

1199
01:11:30,360 --> 01:11:35,130
and he would I rarely grab a person said

1200
01:11:32,970 --> 01:11:38,460
what do you think a heartful computer

1201
01:11:35,130 --> 01:11:40,770
easy for human give me a problem and and

1202
01:11:38,460 --> 01:11:43,110
he will ask anyone and then so

1203
01:11:40,770 --> 01:11:45,660
eventually they zeroed in on this

1204
01:11:43,110 --> 01:11:47,820
problem of recognizing optical

1205
01:11:45,660 --> 01:11:52,740
characters that as the first generation

1206
01:11:47,820 --> 01:11:55,130
of CAPTCHA good observation any other

1207
01:11:52,740 --> 01:11:55,130
questions

1208
01:11:55,910 --> 01:12:03,269
well I think maybe we're done thank you

1209
01:12:01,230 --> 01:12:07,949
so much

1210
01:12:03,270 --> 01:12:07,949
[Applause]

