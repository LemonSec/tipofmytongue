1
00:00:01,630 --> 00:00:13,759
[Music]

2
00:00:13,759 --> 00:00:16,619
thank you

3
00:00:16,619 --> 00:00:19,439
um as Eric said my name is Frank I'm

4
00:00:19,439 --> 00:00:22,260
here together with Emily but before we

5
00:00:22,260 --> 00:00:28,320
start we are going to do the first move

6
00:00:28,320 --> 00:00:34,620
and we are in a very large room and uh I

7
00:00:34,620 --> 00:00:38,160
think we are almost with uh four or 500

8
00:00:38,160 --> 00:00:40,340
people but

9
00:00:40,340 --> 00:00:43,500
it's it's there's room for 800 I believe

10
00:00:43,500 --> 00:00:46,980
so I suggest add that we are going to

11
00:00:46,980 --> 00:00:48,600
move and

12
00:00:48,600 --> 00:00:53,480
um there are two rules in this move

13
00:00:53,840 --> 00:00:56,000
thank you Emily

14
00:00:56,000 --> 00:00:59,059
uh two rules in this move

15
00:00:59,059 --> 00:01:04,199
one move to the person nearest to you

16
00:01:04,199 --> 00:01:07,380
the second rule is you can only move

17
00:01:07,380 --> 00:01:11,640
forward and forward is to us

18
00:01:11,640 --> 00:01:14,460
so this is the algorithm with the two

19
00:01:14,460 --> 00:01:17,119
rules

20
00:01:17,160 --> 00:01:23,700
[Laughter]

21
00:01:23,700 --> 00:01:35,000
[Music]

22
00:01:35,000 --> 00:01:38,600
we got another guest here

23
00:01:38,600 --> 00:01:42,119
thank you so that's that's where we we

24
00:01:42,119 --> 00:01:46,140
we must acknowledge that things go wrong

25
00:01:46,140 --> 00:01:49,320
and so our starting point is in the

26
00:01:49,320 --> 00:01:52,799
projects we do things are going wrong if

27
00:01:52,799 --> 00:01:55,619
everything is okay we stop

28
00:01:55,619 --> 00:01:58,680
may we stop asking questions and asking

29
00:01:58,680 --> 00:02:00,479
questions is one of the most important

30
00:02:00,479 --> 00:02:04,740
part of our talk today and also of

31
00:02:04,740 --> 00:02:07,380
Ethics so

32
00:02:07,380 --> 00:02:11,400
um well let's uh let's go on to the

33
00:02:11,400 --> 00:02:15,000
second move hmm

34
00:02:15,900 --> 00:02:18,180
first we're going to do some profiling

35
00:02:18,180 --> 00:02:20,819
who are you

36
00:02:20,819 --> 00:02:22,500
um if everyone could stand up that would

37
00:02:22,500 --> 00:02:24,800
be great

38
00:02:29,780 --> 00:02:32,940
take care you can also just use your

39
00:02:32,940 --> 00:02:35,660
hand if you want

40
00:02:35,760 --> 00:02:39,300
um so the first question is are you a

41
00:02:39,300 --> 00:02:42,000
techie or not a techie if you are a

42
00:02:42,000 --> 00:02:46,700
techie stand if not take a seat

43
00:02:50,280 --> 00:02:52,879
[Music]

44
00:02:52,879 --> 00:02:58,099
if you are half techy you do a squat

45
00:02:58,099 --> 00:03:01,440
nice all right next question everyone

46
00:03:01,440 --> 00:03:04,159
can stand again

47
00:03:05,159 --> 00:03:08,280
who are you do you prefer techno music

48
00:03:08,280 --> 00:03:11,780
or disco music

49
00:03:12,920 --> 00:03:15,959
okay okay is there a relation between

50
00:03:15,959 --> 00:03:19,200
techies and techno music yeah there is a

51
00:03:19,200 --> 00:03:22,260
relationship yeah for disco music you

52
00:03:22,260 --> 00:03:24,720
are welcome on the 80s party tonight in

53
00:03:24,720 --> 00:03:27,080
the 80s Village yeah

54
00:03:27,080 --> 00:03:30,959
next question everyone can stand again

55
00:03:30,959 --> 00:03:32,700
is this the first time you've heard

56
00:03:32,700 --> 00:03:36,480
ethics add a session in uh MCH then

57
00:03:36,480 --> 00:03:40,500
please stand otherwise sit

58
00:03:40,500 --> 00:03:41,519
huh

59
00:03:41,519 --> 00:03:43,140
okay

60
00:03:43,140 --> 00:03:47,659
cool 74 I've heard of before okay

61
00:03:48,780 --> 00:03:51,500
let's stand again please

62
00:03:51,500 --> 00:03:55,220
do you also keep losing all your stuff

63
00:03:55,220 --> 00:03:58,260
then stay standing if you know exactly

64
00:03:58,260 --> 00:04:00,720
where everything is take a seat wow

65
00:04:00,720 --> 00:04:02,840
that's surprising

66
00:04:02,840 --> 00:04:05,340
it must be something about the 80s

67
00:04:05,340 --> 00:04:08,780
village where everything just goes along

68
00:04:08,930 --> 00:04:15,120
[Laughter]

69
00:04:16,500 --> 00:04:18,899
and then for the final one everyone

70
00:04:18,899 --> 00:04:20,820
stand up again

71
00:04:20,820 --> 00:04:22,979
do you know what Earth data ethics is

72
00:04:22,979 --> 00:04:25,919
then please stay standing if you think I

73
00:04:25,919 --> 00:04:27,990
don't know what it is then take a seat

74
00:04:27,990 --> 00:04:31,149
[Music]

75
00:04:32,940 --> 00:04:35,040
okay we've got some people already know

76
00:04:35,040 --> 00:04:37,380
what's up yeah thank you yeah there was

77
00:04:37,380 --> 00:04:39,300
a little bit profiling of you but uh we

78
00:04:39,300 --> 00:04:41,880
know you very good at this moment and so

79
00:04:41,880 --> 00:04:43,979
that's also one of the most important

80
00:04:43,979 --> 00:04:46,380
things uh not only asking questions but

81
00:04:46,380 --> 00:04:50,400
also understand your audience so that's

82
00:04:50,400 --> 00:04:52,800
what we did at this moment and now we

83
00:04:52,800 --> 00:04:55,979
fully know your situation your context

84
00:04:55,979 --> 00:04:59,280
how you act how you had this that's just

85
00:04:59,280 --> 00:05:03,479
good no no no no I I understand so so

86
00:05:03,479 --> 00:05:06,000
here we have to do some more research

87
00:05:06,000 --> 00:05:09,000
but we only have 50 minutes so we will

88
00:05:09,000 --> 00:05:13,860
do that afterwards or in another time so

89
00:05:13,860 --> 00:05:16,680
go ahead who are we Frank

90
00:05:16,680 --> 00:05:20,280
yeah I already uh um introduced it said

91
00:05:20,280 --> 00:05:24,660
it's Frank and Emily welcome and uh

92
00:05:24,660 --> 00:05:27,120
special also we are part of the 80s

93
00:05:27,120 --> 00:05:29,300
Village

94
00:05:29,479 --> 00:05:31,280
area

95
00:05:31,280 --> 00:05:34,320
if also our fans

96
00:05:34,320 --> 00:05:37,800
um and every night we have the 80s party

97
00:05:37,800 --> 00:05:40,740
and it's at eight o'clock and to

98
00:05:40,740 --> 00:05:43,800
understand for the people who are Dutch

99
00:05:43,800 --> 00:05:46,620
in this uh

100
00:05:46,620 --> 00:05:49,620
alone

101
00:05:51,720 --> 00:05:53,699
[Laughter]

102
00:05:53,699 --> 00:05:56,220
and the 80s party

103
00:05:56,220 --> 00:05:59,759
um 80s and uh for the for the for the

104
00:05:59,759 --> 00:06:04,139
one who is not Dutch 80s is uh in Dutch

105
00:06:04,139 --> 00:06:07,979
is uh is ethical so 80s is ethical so

106
00:06:07,979 --> 00:06:10,800
that's why we call it aids party uh we

107
00:06:10,800 --> 00:06:13,560
have all kind of activities and one of

108
00:06:13,560 --> 00:06:16,259
them is every night the the the AIDS

109
00:06:16,259 --> 00:06:18,259
party where where we have a nice disco

110
00:06:18,259 --> 00:06:22,620
and also for you the the makeup tutorial

111
00:06:22,620 --> 00:06:25,860
um that you cannot that people cannot of

112
00:06:25,860 --> 00:06:29,699
cameras cannot recognize you on uh as

113
00:06:29,699 --> 00:06:32,639
face recognition sorry for my uh so so

114
00:06:32,639 --> 00:06:34,979
you're very welcome

115
00:06:34,979 --> 00:06:38,340
um now we're going to the content

116
00:06:38,340 --> 00:06:40,199
all right

117
00:06:40,199 --> 00:06:42,900
so data ethics what is it some of you

118
00:06:42,900 --> 00:06:45,120
maybe most of you said that you already

119
00:06:45,120 --> 00:06:47,340
have an idea of what it is

120
00:06:47,340 --> 00:06:48,780
um the first question is what do you

121
00:06:48,780 --> 00:06:51,599
think responsible use of data looks like

122
00:06:51,599 --> 00:06:53,400
and maybe think about it for yourself

123
00:06:53,400 --> 00:06:55,740
first just a little bit are there

124
00:06:55,740 --> 00:06:58,080
certain words that come up in your mind

125
00:06:58,080 --> 00:07:00,479
if you have one feel free to shout it

126
00:07:00,479 --> 00:07:02,659
out

127
00:07:04,580 --> 00:07:06,120
[Music]

128
00:07:06,120 --> 00:07:10,139
Sound Engineering sounds of nature

129
00:07:10,139 --> 00:07:12,319
foreign

130
00:07:15,560 --> 00:07:18,840
good data engineering okay

131
00:07:18,840 --> 00:07:21,479
thank you yeah what anyone what do you

132
00:07:21,479 --> 00:07:24,060
think uh responsible use of data looks

133
00:07:24,060 --> 00:07:27,680
like anyone who wants a shout

134
00:07:29,580 --> 00:07:31,979
first

135
00:07:31,979 --> 00:07:34,440
getting data by informed consent first

136
00:07:34,440 --> 00:07:36,970
yes thank you

137
00:07:36,970 --> 00:07:38,580
[Music]

138
00:07:38,580 --> 00:07:41,639
data minimization nice one yeah that's a

139
00:07:41,639 --> 00:07:44,699
nice one what

140
00:07:44,699 --> 00:07:47,819
gold mining

141
00:07:47,819 --> 00:07:51,120
oh oh goal binding do yeah exactly yeah

142
00:07:51,120 --> 00:07:54,979
thank you yes very good

143
00:07:57,440 --> 00:08:00,240
purpose limitation

144
00:08:00,240 --> 00:08:01,680
yeah

145
00:08:01,680 --> 00:08:04,879
same thing yeah

146
00:08:05,879 --> 00:08:07,340
yeah

147
00:08:07,340 --> 00:08:08,660
[Music]

148
00:08:08,660 --> 00:08:12,800
sell everything on the dark web

149
00:08:13,500 --> 00:08:17,000
last but not least

150
00:08:18,120 --> 00:08:20,220
good science

151
00:08:20,220 --> 00:08:22,259
involved involved in primary

152
00:08:22,259 --> 00:08:24,060
stakeholders involved the Prime Minister

153
00:08:24,060 --> 00:08:27,300
are you yeah you are familiar with the

154
00:08:27,300 --> 00:08:29,280
ethical framework we're going to deal

155
00:08:29,280 --> 00:08:32,099
with okay good thank you yeah that's

156
00:08:32,099 --> 00:08:35,399
nice yeah that are all stuff which is

157
00:08:35,399 --> 00:08:38,640
very important so good input yeah

158
00:08:38,640 --> 00:08:40,380
we've found a little different

159
00:08:40,380 --> 00:08:42,179
definition from the open data Institute

160
00:08:42,179 --> 00:08:44,760
that we quite like for data ethics it's

161
00:08:44,760 --> 00:08:46,320
a branch of Ethics that considers the

162
00:08:46,320 --> 00:08:48,000
impact of data practices on people

163
00:08:48,000 --> 00:08:51,060
society and the environment

164
00:08:51,060 --> 00:08:51,779
um

165
00:08:51,779 --> 00:08:54,360
so I'm sure a lot of things that you

166
00:08:54,360 --> 00:08:56,339
just shouted kind of fall within that

167
00:08:56,339 --> 00:08:59,360
definition as well

168
00:09:04,019 --> 00:09:08,580
now the another sitting up standing down

169
00:09:08,580 --> 00:09:12,180
standing up sitting down question

170
00:09:12,180 --> 00:09:14,279
um who uses tool specifically for data

171
00:09:14,279 --> 00:09:16,200
ethics in their work and with tools we

172
00:09:16,200 --> 00:09:18,240
mean instruments codes of conduct

173
00:09:18,240 --> 00:09:20,700
anything

174
00:09:20,700 --> 00:09:23,420
like that

175
00:09:23,580 --> 00:09:25,700
thank you

176
00:09:28,140 --> 00:09:30,080
okay cool

177
00:09:30,080 --> 00:09:32,940
this uh that's yeah that's very good

178
00:09:32,940 --> 00:09:36,000
thank you that's uh it's more than we

179
00:09:36,000 --> 00:09:39,420
had expected yeah yeah much more yeah I

180
00:09:39,420 --> 00:09:41,519
didn't need her yeah I think maybe we

181
00:09:41,519 --> 00:09:43,680
have some time to hear what kind of

182
00:09:43,680 --> 00:09:46,200
instruments people use yeah

183
00:09:46,200 --> 00:09:49,500
is there somebody you'd like to share

184
00:09:49,500 --> 00:09:52,880
let's go to the microphone

185
00:09:57,080 --> 00:09:58,880
yeah

186
00:09:58,880 --> 00:10:01,260
anyone can say what kind of instrument

187
00:10:01,260 --> 00:10:03,920
you use

188
00:10:05,300 --> 00:10:09,180
and I guess for a subset of data ethics

189
00:10:09,180 --> 00:10:11,940
which is specific around people and the

190
00:10:11,940 --> 00:10:13,440
rights and freedoms and the protection

191
00:10:13,440 --> 00:10:15,420
it would be data protection impact

192
00:10:15,420 --> 00:10:18,180
assessments that include the

193
00:10:18,180 --> 00:10:19,800
transparency principle and the

194
00:10:19,800 --> 00:10:22,079
involvement of the stakeholders so

195
00:10:22,079 --> 00:10:23,519
basically you have that stuff covered

196
00:10:23,519 --> 00:10:25,980
but it's really just one bit oh I see

197
00:10:25,980 --> 00:10:28,680
thank you impact assessments

198
00:10:28,680 --> 00:10:31,519
I've got this framework Frank

199
00:10:31,519 --> 00:10:34,019
you have a framework

200
00:10:34,019 --> 00:10:35,779
yeah cool

201
00:10:35,779 --> 00:10:39,380
anyone else Ladies One the last one

202
00:10:39,380 --> 00:10:43,740
okay then we go on oh

203
00:10:43,740 --> 00:10:46,440
and of course our two also have frankly

204
00:10:46,440 --> 00:10:48,899
is of course the draft of the AI Act of

205
00:10:48,899 --> 00:10:51,120
the European Union because it will hit

206
00:10:51,120 --> 00:10:53,820
you anyhow so yeah yeah

207
00:10:53,820 --> 00:10:58,220
the the the AI yeah

208
00:10:58,590 --> 00:11:02,720
[Music]

209
00:11:02,720 --> 00:11:06,000
so technical tools like explainable Ai

210
00:11:06,000 --> 00:11:08,880
and fairness metrics so I'm a data

211
00:11:08,880 --> 00:11:12,000
scientist I use those tools okay cool

212
00:11:12,000 --> 00:11:15,000
thank you thank you really okay next one

213
00:11:15,000 --> 00:11:17,579
and actually what's super powerful and

214
00:11:17,579 --> 00:11:19,860
should be used massively is that on the

215
00:11:19,860 --> 00:11:22,800
gdpr if you use legitimate interest you

216
00:11:22,800 --> 00:11:24,480
are legally applied to do a legitimate

217
00:11:24,480 --> 00:11:26,880
interest assessment and that actually

218
00:11:26,880 --> 00:11:29,579
goes quite deeply to ethics and that is

219
00:11:29,579 --> 00:11:31,860
mandatory for everybody who would rely

220
00:11:31,860 --> 00:11:35,640
on article 6 what if and which two is

221
00:11:35,640 --> 00:11:37,620
that the gdpr legitimate interest

222
00:11:37,620 --> 00:11:40,380
assessment yeah

223
00:11:40,380 --> 00:11:42,120
okay thank you

224
00:11:42,120 --> 00:11:44,399
thank you very much

225
00:11:44,399 --> 00:11:46,920
very interesting it's good to have

226
00:11:46,920 --> 00:11:50,700
feedback yeah and uh this are a couple

227
00:11:50,700 --> 00:11:53,339
of instruments and there are also

228
00:11:53,339 --> 00:11:55,440
um uh all other instruments developed

229
00:11:55,440 --> 00:11:59,639
for example uh the the ODI has uh

230
00:11:59,639 --> 00:12:02,339
developed the data ethics canvas you

231
00:12:02,339 --> 00:12:04,139
have they also developed the data ethics

232
00:12:04,139 --> 00:12:06,480
majority model

233
00:12:06,480 --> 00:12:07,200
um

234
00:12:07,200 --> 00:12:09,120
and these are just examples the area

235
00:12:09,120 --> 00:12:11,700
also did they also have the tech blacks

236
00:12:11,700 --> 00:12:13,800
people know the tech latch from uh

237
00:12:13,800 --> 00:12:16,760
Denmark and it is it's a community

238
00:12:16,760 --> 00:12:20,459
framework uh developed by a community in

239
00:12:20,459 --> 00:12:24,120
a big event in in Copa so there are

240
00:12:24,120 --> 00:12:26,100
different ways to develop ethical

241
00:12:26,100 --> 00:12:28,760
Frameworks

242
00:12:28,800 --> 00:12:31,560
um and also for example uh companies

243
00:12:31,560 --> 00:12:33,959
like UNICEF who do a lot of in

244
00:12:33,959 --> 00:12:36,560
developing countries so it's it's very

245
00:12:36,560 --> 00:12:38,700
important that they do that on a

246
00:12:38,700 --> 00:12:41,399
responsible way they also have uh

247
00:12:41,399 --> 00:12:44,660
ethical guidelines in this case for

248
00:12:44,660 --> 00:12:47,220
geospatial Technologies because that's

249
00:12:47,220 --> 00:12:50,700
very important in their in their work so

250
00:12:50,700 --> 00:12:54,000
if you go search in on Google you find a

251
00:12:54,000 --> 00:12:57,300
lot of ethical uh Frameworks it's

252
00:12:57,300 --> 00:13:03,240
exploding uh um yeah it's exploding

253
00:13:03,240 --> 00:13:06,420
and also as this show yeah okay we

254
00:13:06,420 --> 00:13:10,920
cannot uh uh stay behind and so we also

255
00:13:10,920 --> 00:13:13,019
together with uh in the Netherlands

256
00:13:13,019 --> 00:13:14,820
would you know them someone knows you we

257
00:13:14,820 --> 00:13:16,139
know them

258
00:13:16,139 --> 00:13:19,260
and the ministry of uh Internal Affairs

259
00:13:19,260 --> 00:13:23,940
you know uh Emily and I uh lead the the

260
00:13:23,940 --> 00:13:27,300
development uh of an ethical framework I

261
00:13:27,300 --> 00:13:30,839
had this um uh for the responsible use

262
00:13:30,839 --> 00:13:34,800
of location data but it's also for all

263
00:13:34,800 --> 00:13:37,200
data because it are general principles

264
00:13:37,200 --> 00:13:41,940
and uh Forex that are it at least those

265
00:13:41,940 --> 00:13:44,399
four main principles uh the Justified

266
00:13:44,399 --> 00:13:47,459
purpose already said and to be open and

267
00:13:47,459 --> 00:13:51,480
transparent uh fair in uh in inclusivity

268
00:13:51,480 --> 00:13:53,959
and quality and

269
00:13:53,959 --> 00:13:59,420
solidarity in engagement and Emily will

270
00:13:59,720 --> 00:14:04,380
give a uh explanation about these values

271
00:14:04,380 --> 00:14:06,240
maybe a good thing to add at the moment

272
00:14:06,240 --> 00:14:07,800
is that

273
00:14:07,800 --> 00:14:10,260
um our framework at this point is still

274
00:14:10,260 --> 00:14:12,360
in Dutch we will probably translate it

275
00:14:12,360 --> 00:14:14,399
into English at some point soon but

276
00:14:14,399 --> 00:14:16,740
these are the the main

277
00:14:16,740 --> 00:14:18,420
principles that we got out of a lot of

278
00:14:18,420 --> 00:14:21,779
other Frameworks as well so yeah and to

279
00:14:21,779 --> 00:14:25,220
add is developed with uh with 12

280
00:14:25,220 --> 00:14:28,740
organizations and 12 cases where we have

281
00:14:28,740 --> 00:14:31,800
learned okay what's important in your uh

282
00:14:31,800 --> 00:14:35,040
in in your situation in your context

283
00:14:35,040 --> 00:14:36,540
yeah

284
00:14:36,540 --> 00:14:39,660
so the first principle that we came up

285
00:14:39,660 --> 00:14:41,279
with is a Justified purpose it's

286
00:14:41,279 --> 00:14:44,160
actually was already mentioned by many

287
00:14:44,160 --> 00:14:46,260
of you just now so that's very nice so

288
00:14:46,260 --> 00:14:47,699
that's also the first thing that we

289
00:14:47,699 --> 00:14:49,160
found

290
00:14:49,160 --> 00:14:52,800
this is about data minimization

291
00:14:52,800 --> 00:14:55,019
um the purpose that the whole project is

292
00:14:55,019 --> 00:14:57,959
about the context of the goal so not

293
00:14:57,959 --> 00:14:59,100
only do you know what you're working

294
00:14:59,100 --> 00:15:01,380
towards but do you understand where it's

295
00:15:01,380 --> 00:15:03,779
coming from have you been to the place

296
00:15:03,779 --> 00:15:05,699
that maybe is relevant if we're talking

297
00:15:05,699 --> 00:15:09,660
about geolocation location data

298
00:15:09,660 --> 00:15:11,519
um the third question we think is a

299
00:15:11,519 --> 00:15:12,959
really interesting one do you even need

300
00:15:12,959 --> 00:15:15,300
data to reach this goal or could you use

301
00:15:15,300 --> 00:15:18,360
other sources

302
00:15:18,360 --> 00:15:19,320
um

303
00:15:19,320 --> 00:15:21,120
yeah those are like the those are the

304
00:15:21,120 --> 00:15:22,740
main questions that fall under this

305
00:15:22,740 --> 00:15:24,360
principle

306
00:15:24,360 --> 00:15:25,880
is there something you would like to add

307
00:15:25,880 --> 00:15:29,880
uh yeah what we always see is that the

308
00:15:29,880 --> 00:15:33,300
purpose why why are we doing this is in

309
00:15:33,300 --> 00:15:36,300
every case we we did research with

310
00:15:36,300 --> 00:15:39,480
what's the most important uh question

311
00:15:39,480 --> 00:15:42,959
because a lot of the cases we studied

312
00:15:42,959 --> 00:15:45,600
was started as okay we're going to do

313
00:15:45,600 --> 00:15:46,980
something with data and we're going to

314
00:15:46,980 --> 00:15:49,079
do something with tag and there was two

315
00:15:49,079 --> 00:15:55,638
less connection with uh with the the the

316
00:15:58,680 --> 00:16:01,459
the

317
00:16:01,680 --> 00:16:05,220
the mission and the reason and it was

318
00:16:05,220 --> 00:16:06,660
mainly for for governmental

319
00:16:06,660 --> 00:16:11,459
organizations so the uh uh so so that

320
00:16:11,459 --> 00:16:13,500
there was really a disconnection between

321
00:16:13,500 --> 00:16:17,579
the tech data and the the clients uh who

322
00:16:17,579 --> 00:16:21,180
have to solve important issues in in the

323
00:16:21,180 --> 00:16:22,259
Netherlands

324
00:16:22,259 --> 00:16:24,540
yeah

325
00:16:24,540 --> 00:16:27,800
um question

326
00:16:32,160 --> 00:16:34,860
so so if you've defined your goal

327
00:16:34,860 --> 00:16:38,699
how do you work out what data you need

328
00:16:38,699 --> 00:16:40,860
to satisfy your goal

329
00:16:40,860 --> 00:16:43,259
because you say what data do we need how

330
00:16:43,259 --> 00:16:46,040
do you do that

331
00:16:48,180 --> 00:16:49,680
are you if

332
00:16:49,680 --> 00:16:50,360
um

333
00:16:50,360 --> 00:16:53,399
that's the first step that is what we

334
00:16:53,399 --> 00:16:57,959
see is okay uh what data do we have and

335
00:16:57,959 --> 00:17:00,060
which is in this domain and then people

336
00:17:00,060 --> 00:17:03,300
consume what you want to do is to not

337
00:17:03,300 --> 00:17:05,699
knowing which data there is however it's

338
00:17:05,699 --> 00:17:07,799
mostly reused that you are going to

339
00:17:07,799 --> 00:17:09,079
figure out

340
00:17:09,079 --> 00:17:13,199
uh what data you you need before you go

341
00:17:13,199 --> 00:17:17,339
search for the data and you uh you have

342
00:17:17,339 --> 00:17:20,220
at the first step you have to do is to

343
00:17:20,220 --> 00:17:23,459
understand uh the question and you have

344
00:17:23,459 --> 00:17:26,579
to understand uh what is needed here so

345
00:17:26,579 --> 00:17:28,919
you have to understand the primary

346
00:17:28,919 --> 00:17:31,200
stakeholders and we come there and later

347
00:17:31,200 --> 00:17:35,160
on as it starts with understanding and

348
00:17:35,160 --> 00:17:38,400
then you go look okay what data do we

349
00:17:38,400 --> 00:17:41,059
need here

350
00:17:41,880 --> 00:17:43,340
[Music]

351
00:17:43,340 --> 00:17:45,840
oh do you need to have some sort of

352
00:17:45,840 --> 00:17:48,780
hypothesis to start off with that says

353
00:17:48,780 --> 00:17:51,480
if this is what I'm trying to do then

354
00:17:51,480 --> 00:17:54,720
this probably is the data I need

355
00:17:54,720 --> 00:17:55,799
presumably you have to understand

356
00:17:55,799 --> 00:17:58,200
something about the domain yeah exactly

357
00:17:58,200 --> 00:17:59,820
yeah you have to really understand the

358
00:17:59,820 --> 00:18:02,940
domain and that's that's uh that's a

359
00:18:02,940 --> 00:18:07,160
must that you understand it yeah

360
00:18:07,700 --> 00:18:11,520
how is proportionality included in the

361
00:18:11,520 --> 00:18:14,600
Justified purpose

362
00:18:15,299 --> 00:18:19,980
um I would say it's included in

363
00:18:19,980 --> 00:18:22,039
um

364
00:18:25,200 --> 00:18:28,740
well do we is I suppose it's included in

365
00:18:28,740 --> 00:18:32,280
the context of the goal is it clear

366
00:18:32,280 --> 00:18:33,120
um

367
00:18:33,120 --> 00:18:35,160
is the data that you're using

368
00:18:35,160 --> 00:18:36,600
proportional to the goal that you're

369
00:18:36,600 --> 00:18:38,760
trying to achieve

370
00:18:38,760 --> 00:18:41,340
um looking at judging by the purpose

371
00:18:41,340 --> 00:18:42,960
that you have is that justified is the

372
00:18:42,960 --> 00:18:44,880
context clear

373
00:18:44,880 --> 00:18:46,860
um it's also in the word just Justified

374
00:18:46,860 --> 00:18:49,740
I think yeah that's a bit hard sometimes

375
00:18:49,740 --> 00:18:52,440
because you sometimes have companies

376
00:18:52,440 --> 00:18:55,380
that say hey we want to do this yeah so

377
00:18:55,380 --> 00:18:56,760
it's Justified

378
00:18:56,760 --> 00:19:00,120
but then it's not proportional yeah so

379
00:19:00,120 --> 00:19:02,940
it would be really nice to have

380
00:19:02,940 --> 00:19:04,700
proportionality

381
00:19:04,700 --> 00:19:06,780
explicitly mentioned in the framework

382
00:19:06,780 --> 00:19:09,419
yeah yeah thank you it's a nice point

383
00:19:09,419 --> 00:19:12,000
maybe we should add that these are just

384
00:19:12,000 --> 00:19:15,419
for this is a very big summary of the

385
00:19:15,419 --> 00:19:18,120
framework that that we have created in

386
00:19:18,120 --> 00:19:20,280
the actual framework we have four roles

387
00:19:20,280 --> 00:19:23,520
that we go into we have the the project

388
00:19:23,520 --> 00:19:26,100
leader the

389
00:19:26,100 --> 00:19:30,480
um the client the primary stakeholders

390
00:19:30,480 --> 00:19:32,880
and the people who are actually doing

391
00:19:32,880 --> 00:19:34,280
the the

392
00:19:34,280 --> 00:19:37,020
data science

393
00:19:37,020 --> 00:19:39,120
um and then we go into each one of these

394
00:19:39,120 --> 00:19:41,340
specific areas and look at what they

395
00:19:41,340 --> 00:19:43,679
should specifically look into but yes

396
00:19:43,679 --> 00:19:45,360
proportionality is very important I

397
00:19:45,360 --> 00:19:45,650
agree

398
00:19:45,650 --> 00:19:47,940
[Music]

399
00:19:47,940 --> 00:19:50,640
uh then the next uh principle that we

400
00:19:50,640 --> 00:19:53,220
have is open and transparent

401
00:19:53,220 --> 00:19:55,799
um probably not new to you

402
00:19:55,799 --> 00:19:57,539
um this is mainly looking at not only

403
00:19:57,539 --> 00:19:59,340
whether the data is open and transparent

404
00:19:59,340 --> 00:20:01,020
but whether the whole life cycle is open

405
00:20:01,020 --> 00:20:02,820
and transparent and is that something

406
00:20:02,820 --> 00:20:04,620
that you want

407
00:20:04,620 --> 00:20:08,280
um also the the adaptations to the data

408
00:20:08,280 --> 00:20:12,179
are clear so the metadata is the

409
00:20:12,179 --> 00:20:14,880
communication understandable not only

410
00:20:14,880 --> 00:20:16,860
for people who speak the language of

411
00:20:16,860 --> 00:20:20,220
tech but also the non-techies and

412
00:20:20,220 --> 00:20:22,140
um what about personal data obviously

413
00:20:22,140 --> 00:20:23,460
there's a lot of legislation around

414
00:20:23,460 --> 00:20:25,440
personal data but that should be a

415
00:20:25,440 --> 00:20:28,080
minimum bar what else can you do to make

416
00:20:28,080 --> 00:20:30,780
sure that it's open and transparent

417
00:20:30,780 --> 00:20:32,040
yeah

418
00:20:32,040 --> 00:20:33,600
[Music]

419
00:20:33,600 --> 00:20:36,980
the questions about this one

420
00:20:38,340 --> 00:20:42,799
so sometimes you have openness

421
00:20:42,799 --> 00:20:45,539
conflicting with for example the the

422
00:20:45,539 --> 00:20:48,900
personal data protection and that is

423
00:20:48,900 --> 00:20:51,240
quite a hard balance to find sometimes

424
00:20:51,240 --> 00:20:53,640
especially as combining data from

425
00:20:53,640 --> 00:20:56,760
different sources might cause data that

426
00:20:56,760 --> 00:20:59,600
on the first side is not personally

427
00:20:59,600 --> 00:21:02,780
identifiable to to become personally

428
00:21:02,780 --> 00:21:06,539
identifiable so how do you find that

429
00:21:06,539 --> 00:21:08,820
balance

430
00:21:08,820 --> 00:21:10,679
yeah that's that's a very good question

431
00:21:10,679 --> 00:21:14,039
and it depends on the situation and uh

432
00:21:14,039 --> 00:21:16,320
one of the most important uh thing is

433
00:21:16,320 --> 00:21:19,679
that you include also the the the people

434
00:21:19,679 --> 00:21:23,340
who are directly uh uh involved and

435
00:21:23,340 --> 00:21:26,340
affected uh by your decisions or by your

436
00:21:26,340 --> 00:21:29,520
information product and to do that uh

437
00:21:29,520 --> 00:21:33,179
together and of course uh according also

438
00:21:33,179 --> 00:21:35,700
to the law

439
00:21:35,700 --> 00:21:39,900
I I quite often see that companies name

440
00:21:39,900 --> 00:21:41,760
their customers the persons being

441
00:21:41,760 --> 00:21:44,280
involved but not the data subjects yeah

442
00:21:44,280 --> 00:21:47,280
exactly they'd be really nice if the

443
00:21:47,280 --> 00:21:49,559
data subjects are explicitly mentioned

444
00:21:49,559 --> 00:21:51,720
yeah because they are often forgotten

445
00:21:51,720 --> 00:21:54,780
yeah the data that's that's all the

446
00:21:54,780 --> 00:21:56,340
primary stakeholders and all the other

447
00:21:56,340 --> 00:21:58,679
ones are secondary so you have to

448
00:21:58,679 --> 00:22:00,720
involve the primary stakeholders in this

449
00:22:00,720 --> 00:22:03,860
discussion yeah

450
00:22:03,860 --> 00:22:07,799
all right the next principle is fair and

451
00:22:07,799 --> 00:22:09,840
inclusivity and quality the difficult

452
00:22:09,840 --> 00:22:11,640
thing about ethics I suppose is that we

453
00:22:11,640 --> 00:22:14,340
use words like fairness and Justified

454
00:22:14,340 --> 00:22:17,400
and nobody really you know you have to

455
00:22:17,400 --> 00:22:20,700
see pert in each situation what that

456
00:22:20,700 --> 00:22:22,740
means

457
00:22:22,740 --> 00:22:25,620
um so uh that's why the questions might

458
00:22:25,620 --> 00:22:28,440
also seem a little bit Broad and vague

459
00:22:28,440 --> 00:22:30,539
um but in this case we're looking at

460
00:22:30,539 --> 00:22:31,740
bias

461
00:22:31,740 --> 00:22:34,440
um are we aware of our own bias

462
00:22:34,440 --> 00:22:36,360
um are our sources and data diverse and

463
00:22:36,360 --> 00:22:39,059
inclusive so it's not are you only using

464
00:22:39,059 --> 00:22:41,760
data are you using just expert knowledge

465
00:22:41,760 --> 00:22:44,000
and other kind of sources

466
00:22:44,000 --> 00:22:47,280
is the quality sufficient

467
00:22:47,280 --> 00:22:48,600
um you don't necessarily always have to

468
00:22:48,600 --> 00:22:50,159
have the best quality but is it

469
00:22:50,159 --> 00:22:51,720
sufficient to reach the goal that you

470
00:22:51,720 --> 00:22:54,539
want and the last question can we trust

471
00:22:54,539 --> 00:22:57,080
the data

472
00:22:57,240 --> 00:22:59,340
that I suppose is a feeling of do you

473
00:22:59,340 --> 00:23:01,200
think that the data that you have is

474
00:23:01,200 --> 00:23:02,880
trustworthy enough to apply it in your

475
00:23:02,880 --> 00:23:03,840
projects

476
00:23:03,840 --> 00:23:07,320
what we uh what we often see in the head

477
00:23:07,320 --> 00:23:09,919
is also this trend of data driven

478
00:23:09,919 --> 00:23:12,320
activities and data driven government

479
00:23:12,320 --> 00:23:16,020
data-driven companies uh is that when

480
00:23:16,020 --> 00:23:17,940
there is a question they go in they

481
00:23:17,940 --> 00:23:20,880
start with finding as much data as

482
00:23:20,880 --> 00:23:23,280
possible and they go to the structured

483
00:23:23,280 --> 00:23:26,280
data sets we are available often open

484
00:23:26,280 --> 00:23:31,159
data but they forget to also to include

485
00:23:31,159 --> 00:23:34,740
again the primary stakeholders and but

486
00:23:34,740 --> 00:23:36,620
also expertise

487
00:23:36,620 --> 00:23:39,299
from the organization with also

488
00:23:39,299 --> 00:23:42,659
expertise from knowledge institutes and

489
00:23:42,659 --> 00:23:45,299
they don't do that and then you miss too

490
00:23:45,299 --> 00:23:47,580
much information to make a good

491
00:23:47,580 --> 00:23:50,159
information product yeah

492
00:23:50,159 --> 00:23:52,200
so this principle is not only about the

493
00:23:52,200 --> 00:23:54,179
data itself but also about the people in

494
00:23:54,179 --> 00:23:57,600
the team who uh are involved in the

495
00:23:57,600 --> 00:23:59,899
process

496
00:24:00,120 --> 00:24:02,460
the question

497
00:24:02,460 --> 00:24:05,100
I'm sorry

498
00:24:05,100 --> 00:24:10,440
um so have you got any way to find out

499
00:24:10,440 --> 00:24:13,200
what your own bias is because are you

500
00:24:13,200 --> 00:24:16,679
aware of your own bias definitely not no

501
00:24:16,679 --> 00:24:21,600
so is there any tool to discover if you

502
00:24:21,600 --> 00:24:24,720
have a bias that's that's really a good

503
00:24:24,720 --> 00:24:27,539
good question uh Greg you want to answer

504
00:24:27,539 --> 00:24:29,840
that

505
00:24:30,480 --> 00:24:32,700
yeah I don't have an answer a complete

506
00:24:32,700 --> 00:24:34,020
answer but

507
00:24:34,020 --> 00:24:36,659
one of the ways to do it is to

508
00:24:36,659 --> 00:24:39,000
um differentiate between different types

509
00:24:39,000 --> 00:24:44,220
of bias so for example if um if you've

510
00:24:44,220 --> 00:24:47,520
if you've got a uh an algorithm you're

511
00:24:47,520 --> 00:24:50,460
you're developing to recruit data

512
00:24:50,460 --> 00:24:53,700
scientists for example then you go out

513
00:24:53,700 --> 00:24:56,159
you get your sample and you find out

514
00:24:56,159 --> 00:24:59,880
that 80 percent of data scientists are

515
00:24:59,880 --> 00:25:04,200
all men okay so if your sample has 80

516
00:25:04,200 --> 00:25:06,059
percent

517
00:25:06,059 --> 00:25:08,880
um men in it then your sample isn't

518
00:25:08,880 --> 00:25:11,520
biased okay that's the first thing to

519
00:25:11,520 --> 00:25:13,380
remember but

520
00:25:13,380 --> 00:25:16,320
the domain the population from which

521
00:25:16,320 --> 00:25:19,039
you've drawn it which is data scientists

522
00:25:19,039 --> 00:25:22,260
is biased in relation to the general

523
00:25:22,260 --> 00:25:25,620
population where 50 percent

524
00:25:25,620 --> 00:25:27,900
are people are female

525
00:25:27,900 --> 00:25:32,039
so uh part of it is just identifying our

526
00:25:32,039 --> 00:25:35,340
human biases so I agree but some of it

527
00:25:35,340 --> 00:25:37,799
is having technical tools to actually

528
00:25:37,799 --> 00:25:40,200
Define what these biases are and then

529
00:25:40,200 --> 00:25:42,000
being able to measure them

530
00:25:42,000 --> 00:25:45,179
ah thank you so so there must be some of

531
00:25:45,179 --> 00:25:48,539
day of bias assessment uh and that's

532
00:25:48,539 --> 00:25:50,760
also with the team you work with the

533
00:25:50,760 --> 00:25:54,059
people you work also the client uh the

534
00:25:54,059 --> 00:25:56,700
project leader and they all have biases

535
00:25:56,700 --> 00:25:59,640
and you have to address that and to take

536
00:25:59,640 --> 00:26:01,440
that in your breakdown structure as a

537
00:26:01,440 --> 00:26:04,080
project leader to discuss that and also

538
00:26:04,080 --> 00:26:06,419
to privilege that what you have done so

539
00:26:06,419 --> 00:26:08,640
that other people can control that

540
00:26:08,640 --> 00:26:10,919
and of course the more diverse your team

541
00:26:10,919 --> 00:26:12,779
is the more likely you have to pick up

542
00:26:12,779 --> 00:26:15,799
on each other's biases

543
00:26:16,320 --> 00:26:19,140
yes okay I have a question about what

544
00:26:19,140 --> 00:26:21,299
you exactly mean with Fair because I

545
00:26:21,299 --> 00:26:23,700
know it has different meanings but for

546
00:26:23,700 --> 00:26:27,539
me in philosophy when we say fairness we

547
00:26:27,539 --> 00:26:30,299
refer to principles of fairness and

548
00:26:30,299 --> 00:26:32,159
therefore we're referring to ethics of

549
00:26:32,159 --> 00:26:36,059
Rights and so when and I read fair I

550
00:26:36,059 --> 00:26:37,620
feel like okay this is not going any

551
00:26:37,620 --> 00:26:40,380
further than law this is just basic

552
00:26:40,380 --> 00:26:42,440
ethics that's about rights and about law

553
00:26:42,440 --> 00:26:45,900
some hops some Russo and that's it so

554
00:26:45,900 --> 00:26:48,240
but I feel like your framework goes

555
00:26:48,240 --> 00:26:49,919
further than law and tries to do

556
00:26:49,919 --> 00:26:53,100
something more so I want to ask you how

557
00:26:53,100 --> 00:26:55,380
you see that is that on purpose or yeah

558
00:26:55,380 --> 00:26:57,480
yeah that's that's really on purpose

559
00:26:57,480 --> 00:26:59,940
because we always gets back okay people

560
00:26:59,940 --> 00:27:02,400
say Okay ethics that's law and we have

561
00:27:02,400 --> 00:27:05,760
and ethics goes beyond the law it goes

562
00:27:05,760 --> 00:27:10,279
further than that and the law is

563
00:27:10,279 --> 00:27:14,580
mainly is a high over and then how you

564
00:27:14,580 --> 00:27:17,880
fill it in and you can use use ethics so

565
00:27:17,880 --> 00:27:21,299
ethics is going further and every value

566
00:27:21,299 --> 00:27:25,200
we described has also a paragraph which

567
00:27:25,200 --> 00:27:26,940
says okay what's the difference between

568
00:27:26,940 --> 00:27:29,700
this value and the low and ethics and

569
00:27:29,700 --> 00:27:31,980
the law so that's really a very

570
00:27:31,980 --> 00:27:34,200
important Point some people say okay

571
00:27:34,200 --> 00:27:36,059
it's in the law so why do we have to do

572
00:27:36,059 --> 00:27:38,100
it it's not in the law

573
00:27:38,100 --> 00:27:40,559
and maybe to answer your first question

574
00:27:40,559 --> 00:27:43,200
how do you define fairness

575
00:27:43,200 --> 00:27:44,760
um I think you'll notice we keep going

576
00:27:44,760 --> 00:27:46,799
back to this because Frank and I think

577
00:27:46,799 --> 00:27:48,840
it's very important but

578
00:27:48,840 --> 00:27:51,899
um you do that as with your primary

579
00:27:51,899 --> 00:27:53,820
stakeholders the people who you're doing

580
00:27:53,820 --> 00:27:55,679
the projects for the people who will be

581
00:27:55,679 --> 00:27:58,380
impacted by your data they should be

582
00:27:58,380 --> 00:28:01,260
deciding what they feel is fair and it's

583
00:28:01,260 --> 00:28:02,460
a conversation that you have to have

584
00:28:02,460 --> 00:28:03,299
together

585
00:28:03,299 --> 00:28:05,700
yeah and it's very important guided

586
00:28:05,700 --> 00:28:07,559
conversation yeah and it's also very

587
00:28:07,559 --> 00:28:09,720
hard to explain what you are doing to

588
00:28:09,720 --> 00:28:12,360
the people so that's that's also a one

589
00:28:12,360 --> 00:28:15,480
of a very important principle is the

590
00:28:15,480 --> 00:28:17,580
explanation of what you are doing and

591
00:28:17,580 --> 00:28:19,140
the discussing with those primary

592
00:28:19,140 --> 00:28:21,419
stakeholders

593
00:28:21,419 --> 00:28:24,179
but thanks nice question

594
00:28:24,179 --> 00:28:27,059
so if you're in government how do you

595
00:28:27,059 --> 00:28:28,980
involve your primary stakeholders

596
00:28:28,980 --> 00:28:30,539
because they're basically the whole

597
00:28:30,539 --> 00:28:33,960
population but mostly yeah that's but

598
00:28:33,960 --> 00:28:37,559
that that's uh something yeah we um uh

599
00:28:37,559 --> 00:28:42,000
uh every project has its specific yeah

600
00:28:42,000 --> 00:28:44,100
every project is also unique every

601
00:28:44,100 --> 00:28:47,520
project has a specific uh um primary

602
00:28:47,520 --> 00:28:49,860
stakeholders and that's also related to

603
00:28:49,860 --> 00:28:51,840
the the first one

604
00:28:51,840 --> 00:28:55,940
um uh I had to have a specific goal

605
00:28:55,940 --> 00:28:59,580
just a Justified purpose and when you

606
00:28:59,580 --> 00:29:02,279
make it small this purpose if you have a

607
00:29:02,279 --> 00:29:05,159
large very large purpose and then it's

608
00:29:05,159 --> 00:29:08,159
very hard to identify the stakeholders

609
00:29:08,159 --> 00:29:10,919
so you have to make also your purpose

610
00:29:10,919 --> 00:29:13,980
smart then you can Define your

611
00:29:13,980 --> 00:29:17,460
stakeholders very good and then and then

612
00:29:17,460 --> 00:29:18,980
you can

613
00:29:18,980 --> 00:29:22,679
yeah involve them in your project on

614
00:29:22,679 --> 00:29:26,159
several ways yeah yeah but if I'm making

615
00:29:26,159 --> 00:29:28,620
a project for collecting data for

616
00:29:28,620 --> 00:29:30,899
government purposes for example

617
00:29:30,899 --> 00:29:33,720
and I collect data of people in the

618
00:29:33,720 --> 00:29:36,179
Netherlands yeah it would be very hard

619
00:29:36,179 --> 00:29:39,299
to talk directly to stakeholders because

620
00:29:39,299 --> 00:29:41,580
they will think well yeah but if you

621
00:29:41,580 --> 00:29:43,740
make a data set for for governmental

622
00:29:43,740 --> 00:29:46,980
organization then it's probably a a high

623
00:29:46,980 --> 00:29:49,440
abstracted or whatever dates a bit then

624
00:29:49,440 --> 00:29:52,320
it's going to be used the the user of

625
00:29:52,320 --> 00:29:55,740
that data he is he or yeah but that

626
00:29:55,740 --> 00:29:57,899
might be someone in government where the

627
00:29:57,899 --> 00:30:00,299
data subjects for example I collect data

628
00:30:00,299 --> 00:30:02,520
about everybody who Cycles in the

629
00:30:02,520 --> 00:30:04,980
Netherlands and then you have this

630
00:30:04,980 --> 00:30:07,260
organization of cyclists you can involve

631
00:30:07,260 --> 00:30:10,919
but if it's if it's a bit more abstract

632
00:30:10,919 --> 00:30:14,340
than that then mostly the user of the

633
00:30:14,340 --> 00:30:17,399
data is some government organization and

634
00:30:17,399 --> 00:30:19,919
the people affected or the data subjects

635
00:30:19,919 --> 00:30:22,620
that are in that set

636
00:30:22,620 --> 00:30:25,980
they don't they find the use quite

637
00:30:25,980 --> 00:30:28,260
abstract so it's quite hard to reach

638
00:30:28,260 --> 00:30:32,960
them so it's quite a a hard group to

639
00:30:32,960 --> 00:30:36,419
involve and have as a stakeholder yeah

640
00:30:36,419 --> 00:30:39,080
that's true

641
00:30:39,299 --> 00:30:42,059
actually a question for you so you say

642
00:30:42,059 --> 00:30:44,279
you're collecting data what is the

643
00:30:44,279 --> 00:30:46,080
purpose for which you are collecting the

644
00:30:46,080 --> 00:30:48,240
data do you already know

645
00:30:48,240 --> 00:30:50,760
I know but are you are you collecting

646
00:30:50,760 --> 00:30:52,620
data for a purpose or are you just

647
00:30:52,620 --> 00:30:54,480
collecting data because it might be

648
00:30:54,480 --> 00:30:57,919
useful to somebody in the future

649
00:30:59,000 --> 00:31:02,100
per definition you're collecting data

650
00:31:02,100 --> 00:31:04,440
for a specific purpose for example

651
00:31:04,440 --> 00:31:07,740
improving bicycle paths or improving

652
00:31:07,740 --> 00:31:12,559
commutes of people in the Netherlands

653
00:31:15,500 --> 00:31:17,880
so the purpose limitation of course we

654
00:31:17,880 --> 00:31:20,340
get directly via gdpr for the collection

655
00:31:20,340 --> 00:31:23,279
of personal data but gdpr would also

656
00:31:23,279 --> 00:31:26,640
allow you to then create synthetic data

657
00:31:26,640 --> 00:31:28,919
or pseudonymize the data which I think

658
00:31:28,919 --> 00:31:31,380
should work very nicely for like bicycle

659
00:31:31,380 --> 00:31:33,299
route utilization because you can

660
00:31:33,299 --> 00:31:35,940
actually move you can blur you you can

661
00:31:35,940 --> 00:31:38,580
actually make that non-traceable now I

662
00:31:38,580 --> 00:31:40,740
think the ethical question and I think

663
00:31:40,740 --> 00:31:42,720
when I look at the open data initiative

664
00:31:42,720 --> 00:31:45,019
is actually an expectation from society

665
00:31:45,019 --> 00:31:48,059
and the different members in society be

666
00:31:48,059 --> 00:31:50,580
it private citizens be it NGO speed

667
00:31:50,580 --> 00:31:53,519
companies to then actually make use of

668
00:31:53,519 --> 00:31:56,519
that collected location data so I think

669
00:31:56,519 --> 00:31:58,679
when you're looking at location data and

670
00:31:58,679 --> 00:32:01,440
data ethics there is a strict limitation

671
00:32:01,440 --> 00:32:03,419
with a distinction between the

672
00:32:03,419 --> 00:32:06,299
processing of personal data where you're

673
00:32:06,299 --> 00:32:07,919
clearly clearly under purpose limitation

674
00:32:07,919 --> 00:32:11,519
but then I would assume that there is

675
00:32:11,519 --> 00:32:14,220
likely and we see that in the European

676
00:32:14,220 --> 00:32:15,179
data

677
00:32:15,179 --> 00:32:18,299
Service Act a very strong moral

678
00:32:18,299 --> 00:32:20,220
incentive to actually share that data

679
00:32:20,220 --> 00:32:21,960
and not keep that because if you would

680
00:32:21,960 --> 00:32:23,760
go out and collect the same data you

681
00:32:23,760 --> 00:32:26,700
would again be causing harm on these

682
00:32:26,700 --> 00:32:27,840
people because they would actually keep

683
00:32:27,840 --> 00:32:30,059
up the data so if you would have like an

684
00:32:30,059 --> 00:32:33,779
aggregated good Central data set that is

685
00:32:33,779 --> 00:32:35,220
of good quality and would that actually

686
00:32:35,220 --> 00:32:38,700
be reused by others for potentially

687
00:32:38,700 --> 00:32:40,200
other purposes because they want to do

688
00:32:40,200 --> 00:32:42,419
other things based on that then that

689
00:32:42,419 --> 00:32:44,880
should be completely okay and then you

690
00:32:44,880 --> 00:32:47,760
really have this break between the

691
00:32:47,760 --> 00:32:50,399
personal data processing the obviously

692
00:32:50,399 --> 00:32:51,960
and you need to have a data protection

693
00:32:51,960 --> 00:32:53,340
impact assessment because of the

694
00:32:53,340 --> 00:32:55,559
location data so you have of course

695
00:32:55,559 --> 00:32:58,399
Naturally by law the

696
00:32:58,399 --> 00:33:01,320
putting in the primary stakeholders but

697
00:33:01,320 --> 00:33:03,600
then for the further use I really

698
00:33:03,600 --> 00:33:05,760
wouldn't see that so I'm interested in

699
00:33:05,760 --> 00:33:08,460
how you cut between the location data

700
00:33:08,460 --> 00:33:09,779
that's still personal

701
00:33:09,779 --> 00:33:12,720
and then the I think much bigger data

702
00:33:12,720 --> 00:33:14,519
ethics obligations that come with

703
00:33:14,519 --> 00:33:16,440
actually then potentially holding

704
00:33:16,440 --> 00:33:20,720
anonymized aggregated location data

705
00:33:21,539 --> 00:33:23,700
yeah that's also a really interesting

706
00:33:23,700 --> 00:33:26,039
question actually I think yesterday we

707
00:33:26,039 --> 00:33:27,840
were in a session where somebody said

708
00:33:27,840 --> 00:33:29,340
that

709
00:33:29,340 --> 00:33:31,799
um oh I'm sorry

710
00:33:31,799 --> 00:33:35,340
um having as soon as you put out data

711
00:33:35,340 --> 00:33:39,120
sets where uh even if it's anonymized if

712
00:33:39,120 --> 00:33:41,159
it's open then you can combine different

713
00:33:41,159 --> 00:33:43,019
data sets from different areas can it

714
00:33:43,019 --> 00:33:44,640
ever be anonymous because you can always

715
00:33:44,640 --> 00:33:49,260
somehow then track and Trace who who's

716
00:33:49,260 --> 00:33:52,940
behind it yes feel free

717
00:33:54,000 --> 00:33:55,740
um you can't um so there is actually

718
00:33:55,740 --> 00:33:58,140
guidance on anonymization techniques

719
00:33:58,140 --> 00:34:00,480
that came by the article 29 working

720
00:34:00,480 --> 00:34:04,679
party and there it's a very

721
00:34:04,679 --> 00:34:07,140
they they they there's approaches to

722
00:34:07,140 --> 00:34:10,260
that there's existing approaches on how

723
00:34:10,260 --> 00:34:13,320
to determine whether there is only

724
00:34:13,320 --> 00:34:15,060
um a very low remote likelihood of

725
00:34:15,060 --> 00:34:18,480
people of data to be re-um identified

726
00:34:18,480 --> 00:34:20,579
but if you have look look look

727
00:34:20,579 --> 00:34:23,159
um location data like the use of bicycle

728
00:34:23,159 --> 00:34:25,619
path then you can actually aggregate

729
00:34:25,619 --> 00:34:27,239
that you can actually say I have

730
00:34:27,239 --> 00:34:28,859
threatened that many people at a given

731
00:34:28,859 --> 00:34:30,780
point in time during the day on certain

732
00:34:30,780 --> 00:34:33,480
paths and I just cut everybody there

733
00:34:33,480 --> 00:34:36,540
like a people count of below five

734
00:34:36,540 --> 00:34:39,359
and with this thing you you can really

735
00:34:39,359 --> 00:34:42,000
end up with non-personal data you can

736
00:34:42,000 --> 00:34:44,460
also create synthetic data by basically

737
00:34:44,460 --> 00:34:46,440
training machine learning models on the

738
00:34:46,440 --> 00:34:48,060
actual observed personal load location

739
00:34:48,060 --> 00:34:51,060
data and then create a data that would

740
00:34:51,060 --> 00:34:53,760
be statistically the same but no longer

741
00:34:53,760 --> 00:34:55,500
personal so so there's approaches to

742
00:34:55,500 --> 00:34:58,140
that I think uh thank you very much for

743
00:34:58,140 --> 00:35:00,780
your addition because of the time we

744
00:35:00,780 --> 00:35:03,000
have to go on sorry for that we can talk

745
00:35:03,000 --> 00:35:04,980
later on

746
00:35:04,980 --> 00:35:07,079
um so Emily

747
00:35:07,079 --> 00:35:09,420
oh you have the solidarity and we

748
00:35:09,420 --> 00:35:11,640
already had oh sorry no we skipped that

749
00:35:11,640 --> 00:35:14,900
one the most important on

750
00:35:15,300 --> 00:35:16,980
um solidarity and engagement is what

751
00:35:16,980 --> 00:35:18,060
we've been coming back through

752
00:35:18,060 --> 00:35:19,859
throughout all the other principles as

753
00:35:19,859 --> 00:35:21,000
well

754
00:35:21,000 --> 00:35:22,800
um who are the primary stakeholders who

755
00:35:22,800 --> 00:35:24,480
are the most important people who are

756
00:35:24,480 --> 00:35:26,339
actually being impacted by whatever

757
00:35:26,339 --> 00:35:28,140
you're doing

758
00:35:28,140 --> 00:35:30,180
um are they treated equally that's the

759
00:35:30,180 --> 00:35:33,000
point the word solidarities put in there

760
00:35:33,000 --> 00:35:35,280
to make sure that you're not just adding

761
00:35:35,280 --> 00:35:37,560
them because you feel like the law says

762
00:35:37,560 --> 00:35:39,359
it or you know then you look good you

763
00:35:39,359 --> 00:35:40,859
really genuinely want to know what they

764
00:35:40,859 --> 00:35:42,599
how they feel about things you've had a

765
00:35:42,599 --> 00:35:44,280
proper conversation with them

766
00:35:44,280 --> 00:35:47,160
uh do you really understand them and how

767
00:35:47,160 --> 00:35:48,960
do you give them a voice and actual

768
00:35:48,960 --> 00:35:51,440
influence

769
00:35:51,660 --> 00:35:54,960
something you want to add no I think

770
00:35:54,960 --> 00:35:57,000
this is the most important I had to uh

771
00:35:57,000 --> 00:35:58,800
to involve the prime mistakes and is

772
00:35:58,800 --> 00:36:00,660
that for how do you do that and there

773
00:36:00,660 --> 00:36:02,940
are several ways to do it and it's very

774
00:36:02,940 --> 00:36:06,359
and what we see in our job it mostly Is

775
00:36:06,359 --> 00:36:08,640
Never Done people say okay we first do

776
00:36:08,640 --> 00:36:11,460
it internally we do it closed and then

777
00:36:11,460 --> 00:36:13,260
we open and then we're going to talk

778
00:36:13,260 --> 00:36:15,540
with the primary stakeholders but the

779
00:36:15,540 --> 00:36:17,839
most important is also that the client

780
00:36:17,839 --> 00:36:19,640
already

781
00:36:19,640 --> 00:36:23,040
did his or her understanding together

782
00:36:23,040 --> 00:36:26,940
with this primary uh stakeholders for

783
00:36:26,940 --> 00:36:29,760
the question he is faced too so that's a

784
00:36:29,760 --> 00:36:32,460
very important step that it has to be

785
00:36:32,460 --> 00:36:34,560
much earlier in the process than it

786
00:36:34,560 --> 00:36:38,700
happens now and we do that a lot and

787
00:36:38,700 --> 00:36:41,579
there are several ways to do that but we

788
00:36:41,579 --> 00:36:44,460
see it's the the the the Armenian

789
00:36:44,460 --> 00:36:47,040
governments policy makers they are very

790
00:36:47,040 --> 00:36:49,320
afraid to go outside to talk to people

791
00:36:49,320 --> 00:36:51,599
to to to to to ring the bell on the

792
00:36:51,599 --> 00:36:54,420
houses to go to Farmers to talk that

793
00:36:54,420 --> 00:36:55,800
kind of stuff and then you have to do it

794
00:36:55,800 --> 00:36:59,460
you have to go out and talk to people uh

795
00:36:59,460 --> 00:37:01,619
go to theirs they have to their

796
00:37:01,619 --> 00:37:05,040
situation to their location to see how

797
00:37:05,040 --> 00:37:07,500
they live how they work what's in the

798
00:37:07,500 --> 00:37:09,780
surrounding have to have instead of

799
00:37:09,780 --> 00:37:12,000
getting them to you and that's something

800
00:37:12,000 --> 00:37:16,619
uh yeah we are uh we try to achieve also

801
00:37:16,619 --> 00:37:19,800
within government organizations

802
00:37:19,800 --> 00:37:22,260
uh do we have time for questions or is

803
00:37:22,260 --> 00:37:26,460
it no music okay no more questions but

804
00:37:26,460 --> 00:37:28,020
if you have any questions feel free to

805
00:37:28,020 --> 00:37:30,480
ask us at the end or come to the 80s

806
00:37:30,480 --> 00:37:33,119
Village

807
00:37:33,119 --> 00:37:35,400
um now we have another way just to show

808
00:37:35,400 --> 00:37:36,839
you that you don't necessarily need to

809
00:37:36,839 --> 00:37:39,240
use Frameworks and and laws and all

810
00:37:39,240 --> 00:37:41,400
these the difficult things you can also

811
00:37:41,400 --> 00:37:43,980
find ethics in more simple fun things

812
00:37:43,980 --> 00:37:47,820
yeah yeah yeah we did a we did a study

813
00:37:47,820 --> 00:37:49,740
on the head we you have all kind of

814
00:37:49,740 --> 00:37:54,180
Frameworks and uh we did a study and not

815
00:37:54,180 --> 00:37:57,900
hinted by law or science and that's

816
00:37:57,900 --> 00:38:01,440
another way how you can practice ethics

817
00:38:01,440 --> 00:38:05,420
on a daily basis everywhere anytime

818
00:38:05,420 --> 00:38:08,579
where you are and that is of course

819
00:38:08,579 --> 00:38:11,280
through 80s music

820
00:38:11,280 --> 00:38:14,760
because of course 80s music if you

821
00:38:14,760 --> 00:38:17,940
listen to it there are mostly deep

822
00:38:17,940 --> 00:38:22,079
ethical messages in the music you can

823
00:38:22,079 --> 00:38:25,380
use uh in your project right so but you

824
00:38:25,380 --> 00:38:26,640
couldn't also do it when you are going

825
00:38:26,640 --> 00:38:28,619
to college in the car listen to music

826
00:38:28,619 --> 00:38:31,099
and then you can start the conversation

827
00:38:31,099 --> 00:38:35,460
about the messages in the music so you

828
00:38:35,460 --> 00:38:37,020
can do that every day and the most

829
00:38:37,020 --> 00:38:39,240
important in ethics is to start that

830
00:38:39,240 --> 00:38:41,339
conversation so we're going to practice

831
00:38:41,339 --> 00:38:44,520
that together so

832
00:38:44,520 --> 00:38:47,579
um it's it's quite easy and that's

833
00:38:47,579 --> 00:38:48,740
um

834
00:38:48,740 --> 00:38:52,260
sorry I have to put it on and everybody

835
00:38:52,260 --> 00:38:54,060
can see it that's good

836
00:38:54,060 --> 00:38:56,240
foreign

837
00:39:09,140 --> 00:39:14,960
a low profile Manner and for low profile

838
00:39:14,960 --> 00:39:17,880
framework is to listen to music and we

839
00:39:17,880 --> 00:39:20,040
do 80 music but you can also listen to

840
00:39:20,040 --> 00:39:23,520
your music because also there are very a

841
00:39:23,520 --> 00:39:25,640
nice ethical

842
00:39:25,640 --> 00:39:29,040
messages so the first one I want you to

843
00:39:29,040 --> 00:39:32,339
listen and after that you can talk to

844
00:39:32,339 --> 00:39:35,220
your neighbor from what kind of ethical

845
00:39:35,220 --> 00:39:38,220
message is this for me in my work or in

846
00:39:38,220 --> 00:39:39,900
the project I work for

847
00:39:39,900 --> 00:39:43,099
this is the first one

848
00:41:01,880 --> 00:41:05,280
all right so uh discuss uh with your

849
00:41:05,280 --> 00:41:08,160
neighbor what deep ethical

850
00:41:08,160 --> 00:41:13,759
um messages is in this uh song

851
00:41:16,840 --> 00:41:23,300
[Music]

852
00:41:26,380 --> 00:41:43,760
[Music]

853
00:41:53,070 --> 00:41:56,189
[Music]

854
00:41:56,480 --> 00:41:59,400
all right

855
00:41:59,400 --> 00:42:02,280
it was a little short exercise and uh

856
00:42:02,280 --> 00:42:06,780
did anyone find something in it food

857
00:42:06,780 --> 00:42:07,920
yeah

858
00:42:07,920 --> 00:42:10,319
okay great anyone also who has a good

859
00:42:10,319 --> 00:42:13,200
discussion about it yeah great I have a

860
00:42:13,200 --> 00:42:14,819
good it's also searching for a

861
00:42:14,819 --> 00:42:18,060
destination that's mine and uh what we

862
00:42:18,060 --> 00:42:20,819
see is then most clients don't search

863
00:42:20,819 --> 00:42:23,520
that good for destination for example I

864
00:42:23,520 --> 00:42:25,700
don't know whether you had that also

865
00:42:25,700 --> 00:42:28,980
touching many hearts along the way well

866
00:42:28,980 --> 00:42:31,920
most projects don't touch any heart with

867
00:42:31,920 --> 00:42:34,380
others and so

868
00:42:34,380 --> 00:42:37,079
um and so and

869
00:42:37,079 --> 00:42:40,740
um I hoping I'll never have to say It's

870
00:42:40,740 --> 00:42:44,180
Just an Illusion I hope that that that

871
00:42:44,180 --> 00:42:47,400
we acknowledge that what we do is an

872
00:42:47,400 --> 00:42:49,859
illusion and that we share that so I had

873
00:42:49,859 --> 00:42:52,500
that's that's something which I get from

874
00:42:52,500 --> 00:42:54,240
this song for example

875
00:42:54,240 --> 00:42:57,420
okay so you can I have this this is the

876
00:42:57,420 --> 00:42:59,280
example for which you can do every day

877
00:42:59,280 --> 00:43:02,160
every day every time anywhere you want

878
00:43:02,160 --> 00:43:04,200
to do this before you start a project at

879
00:43:04,200 --> 00:43:05,880
the start of a meeting whatever you like

880
00:43:05,880 --> 00:43:08,540
also with colleagues so let's do this

881
00:43:08,540 --> 00:43:12,240
low profile okay and it's also very

882
00:43:12,240 --> 00:43:15,300
important to do things together and I

883
00:43:15,300 --> 00:43:18,480
know in ethics we are not alone and we

884
00:43:18,480 --> 00:43:20,280
are with the community we saw it people

885
00:43:20,280 --> 00:43:23,400
standing up we are not alone to achieve

886
00:43:23,400 --> 00:43:26,040
this mission to it to ahead of our

887
00:43:26,040 --> 00:43:28,800
mission of doing things well of of

888
00:43:28,800 --> 00:43:31,740
making good data projects and that it it

889
00:43:31,740 --> 00:43:34,500
has really a value for Society for

890
00:43:34,500 --> 00:43:38,280
people so I want to uh to strengthen

891
00:43:38,280 --> 00:43:42,420
that feeling with you all so let's sing

892
00:43:42,420 --> 00:43:44,220
together

893
00:43:44,220 --> 00:43:47,220
foreign

894
00:43:49,480 --> 00:43:52,570
[Music]

895
00:44:02,370 --> 00:44:06,040
[Music]

896
00:44:13,819 --> 00:44:16,520
at the end

897
00:44:16,520 --> 00:44:20,180
of the storm

898
00:44:20,180 --> 00:44:23,480
there is

899
00:44:36,210 --> 00:44:39,260
[Music]

900
00:44:39,300 --> 00:44:41,960
welcome

901
00:44:45,870 --> 00:44:48,989
[Music]

902
00:44:58,440 --> 00:45:02,000
and hello

903
00:45:03,250 --> 00:45:06,550
[Music]

904
00:45:49,290 --> 00:45:51,079
[Music]

905
00:45:51,079 --> 00:45:53,640
okay thank you very much see you next

906
00:45:53,640 --> 00:45:55,819
time

907
00:45:58,579 --> 00:46:01,740
Emily on ethics thank you give him a big

908
00:46:01,740 --> 00:46:04,220
hand again

909
00:46:07,260 --> 00:46:10,210
and may you never walk alone

910
00:46:10,210 --> 00:46:14,430
[Laughter]

911
00:46:14,430 --> 00:46:17,859
[Applause]

