1
00:00:02,100 --> 00:00:23,840
[Music]

2
00:00:41,989 --> 00:00:54,209
good evening disobey do you ever get the

3
00:00:50,010 --> 00:01:00,739
feeling that there has to be more to

4
00:00:54,210 --> 00:01:00,739
life than just computers and hacking a

5
00:01:01,339 --> 00:01:08,100
great thing about this obey is that this

6
00:01:04,830 --> 00:01:12,289
isn't only for us who enjoy breaking

7
00:01:08,100 --> 00:01:17,729
things this is also for creators and

8
00:01:12,290 --> 00:01:20,460
makers today is Valentine's Day and what

9
00:01:17,729 --> 00:01:26,310
would be a more beautiful thing to make

10
00:01:20,460 --> 00:01:29,100
than love so let's get physical but

11
00:01:26,310 --> 00:01:31,200
before we do that we would really like

12
00:01:29,100 --> 00:01:34,020
to present our latest research on

13
00:01:31,200 --> 00:01:37,320
credential theft we will start the

14
00:01:34,020 --> 00:01:40,199
presentation by giving a brief history

15
00:01:37,320 --> 00:01:43,190
of the evolution of credential theft

16
00:01:40,200 --> 00:01:45,659
attacks and the related defenses and

17
00:01:43,190 --> 00:01:47,908
hopefully this will show you why we felt

18
00:01:45,659 --> 00:01:51,060
that a new approach to stealing

19
00:01:47,909 --> 00:01:53,340
credentials was needed then we will

20
00:01:51,060 --> 00:01:55,800
share the story of how we developed a

21
00:01:53,340 --> 00:01:58,200
new tool called fist meme to profit

22
00:01:55,800 --> 00:02:03,229
which is designed to steal credentials

23
00:01:58,200 --> 00:02:05,700
directly from the physical memory and

24
00:02:03,229 --> 00:02:08,549
this is something that your open

25
00:02:05,700 --> 00:02:12,840
sourcing today so you are the first

26
00:02:08,549 --> 00:02:14,129
people outside f-secure to see this now

27
00:02:12,840 --> 00:02:16,470
hopefully this is all very interesting

28
00:02:14,129 --> 00:02:18,899
for those of you in the audience who

29
00:02:16,470 --> 00:02:23,580
self-identify as attackers or red

30
00:02:18,900 --> 00:02:25,799
teamers but what about the defenders for

31
00:02:23,580 --> 00:02:30,599
the defenders we have three key

32
00:02:25,799 --> 00:02:32,879
takeaways number one we will advise how

33
00:02:30,599 --> 00:02:35,970
to approach this kind of new and novel

34
00:02:32,879 --> 00:02:38,700
attack techniques in general keep our

35
00:02:35,970 --> 00:02:41,410
number two we will give recommendations

36
00:02:38,700 --> 00:02:45,880
on where to focus your detection ever

37
00:02:41,410 --> 00:02:48,609
and finally keep on number three we see

38
00:02:45,880 --> 00:02:52,299
both attacks and defenses moving lower

39
00:02:48,610 --> 00:02:54,280
and lower on the technology stack and we

40
00:02:52,300 --> 00:02:58,030
believe this is a trend that benefits

41
00:02:54,280 --> 00:03:01,510
the defenders but it does require action

42
00:02:58,030 --> 00:03:03,430
from you if you have any questions

43
00:03:01,510 --> 00:03:04,989
during the presentation I kindly ask you

44
00:03:03,430 --> 00:03:06,760
to make a mental note and we're more

45
00:03:04,990 --> 00:03:09,070
than happy to answer your questions in

46
00:03:06,760 --> 00:03:12,010
the Q&A section at the end of the

47
00:03:09,070 --> 00:03:13,989
presentation my name is Tim O'Hara

48
00:03:12,010 --> 00:03:15,540
Vernon this is my brilliant colleague

49
00:03:13,990 --> 00:03:18,610
Robert Baer speak

50
00:03:15,540 --> 00:03:21,070
Robert moved from UK to Finland about a

51
00:03:18,610 --> 00:03:22,600
year ago and he's such a good fiend that

52
00:03:21,070 --> 00:03:26,980
we've already given him the Feeney's

53
00:03:22,600 --> 00:03:29,890
name Robert Carter hula but that's not

54
00:03:26,980 --> 00:03:33,220
the reason why he is here Robert is the

55
00:03:29,890 --> 00:03:34,290
father of the idea behind all this thank

56
00:03:33,220 --> 00:03:37,690
you mate

57
00:03:34,290 --> 00:03:39,910
so recently Timo and I was struggling to

58
00:03:37,690 --> 00:03:42,430
get code execution on a red team

59
00:03:39,910 --> 00:03:44,650
operation and the reason for this was

60
00:03:42,430 --> 00:03:46,840
something called attack surface

61
00:03:44,650 --> 00:03:48,190
reduction which is part of the advanced

62
00:03:46,840 --> 00:03:48,760
threat protection suite offered by

63
00:03:48,190 --> 00:03:50,920
Microsoft

64
00:03:48,760 --> 00:03:52,480
according to Microsoft's attack surface

65
00:03:50,920 --> 00:03:54,760
reduction is a tool that prevents

66
00:03:52,480 --> 00:03:57,630
behaviors that malware often uses to

67
00:03:54,760 --> 00:04:00,880
infect computers with malicious code I

68
00:03:57,630 --> 00:04:02,620
found this frustrating but I also

69
00:04:00,880 --> 00:04:05,170
thought it was quite interesting so I

70
00:04:02,620 --> 00:04:06,910
started reading about it my wife went to

71
00:04:05,170 --> 00:04:09,700
bed I carried on reading about it and

72
00:04:06,910 --> 00:04:11,950
what curiosity led me to several other

73
00:04:09,700 --> 00:04:13,839
tool sets as well why found is that

74
00:04:11,950 --> 00:04:17,529
these modern defensive security software

75
00:04:13,840 --> 00:04:19,180
or solutions are effective they're

76
00:04:17,529 --> 00:04:21,570
sophisticated and they're really

77
00:04:19,180 --> 00:04:24,340
focusing on the right things

78
00:04:21,570 --> 00:04:26,290
the problem for me was the the things

79
00:04:24,340 --> 00:04:28,349
they're focusing on are so pivotal to

80
00:04:26,290 --> 00:04:30,610
the success of our red team operations

81
00:04:28,350 --> 00:04:32,890
made me realise that the game is

82
00:04:30,610 --> 00:04:37,750
changing it's time for us to sink or

83
00:04:32,890 --> 00:04:40,210
swim and it made me realize that I just

84
00:04:37,750 --> 00:04:41,320
wanted to kind of push back so I set the

85
00:04:40,210 --> 00:04:45,190
message to my good friend and colleague

86
00:04:41,320 --> 00:04:47,710
Timo and I said Timo the game is

87
00:04:45,190 --> 00:04:50,350
changing it's time to sink or swim I

88
00:04:47,710 --> 00:04:52,690
want to push back an hour Timo spent six

89
00:04:50,350 --> 00:04:54,310
years specializing in reverse

90
00:04:52,690 --> 00:04:55,449
engineering and exploit development than

91
00:04:54,310 --> 00:04:57,099
the last three years doing red

92
00:04:55,449 --> 00:04:59,620
operations so of course he immediately

93
00:04:57,099 --> 00:05:01,870
just said yes let's do that where do I

94
00:04:59,620 --> 00:05:04,120
begin and that's ultimately why we're

95
00:05:01,870 --> 00:05:05,860
here in front of you today here we have

96
00:05:04,120 --> 00:05:08,620
the kill chain was originally developed

97
00:05:05,860 --> 00:05:10,419
by Lockheed Martin as a way to

98
00:05:08,620 --> 00:05:12,639
illustrate the stages of an intrusion

99
00:05:10,419 --> 00:05:14,710
into a computer network and what we mean

100
00:05:12,639 --> 00:05:17,589
by stages our intelligence gathering

101
00:05:14,710 --> 00:05:20,080
activities the delivery of a weaponized

102
00:05:17,589 --> 00:05:22,479
payload the execution of code on a

103
00:05:20,080 --> 00:05:25,210
victim system the ability to control

104
00:05:22,479 --> 00:05:26,979
that victim system remotely the process

105
00:05:25,210 --> 00:05:29,739
of obtaining persistent access to that

106
00:05:26,979 --> 00:05:32,529
system internal enumeration of an

107
00:05:29,740 --> 00:05:34,569
environment the movement through that

108
00:05:32,529 --> 00:05:37,960
environment and finally the actions on

109
00:05:34,569 --> 00:05:39,879
objective exfiltrating data modifying a

110
00:05:37,960 --> 00:05:42,008
database something along those lines

111
00:05:39,879 --> 00:05:43,960
now f-secure has released public

112
00:05:42,009 --> 00:05:45,699
presentations and tooling around most of

113
00:05:43,960 --> 00:05:48,909
the elements of this kill chain most

114
00:05:45,699 --> 00:05:52,149
notably at command and control with the

115
00:05:48,909 --> 00:05:53,919
release of c3 last year some of you may

116
00:05:52,149 --> 00:05:56,649
have heard of c3 already essentially the

117
00:05:53,919 --> 00:05:58,089
team behind c3 found that their command

118
00:05:56,649 --> 00:06:00,360
and control channels kept getting caught

119
00:05:58,089 --> 00:06:02,439
by defensive security teams and

120
00:06:00,360 --> 00:06:05,169
defensive security products and so they

121
00:06:02,439 --> 00:06:06,180
wanted a way to push back they found

122
00:06:05,169 --> 00:06:08,109
that they could tunnel their

123
00:06:06,180 --> 00:06:10,210
communication the command and control

124
00:06:08,110 --> 00:06:11,740
channels over existing communication

125
00:06:10,210 --> 00:06:13,330
channels that are often present within

126
00:06:11,740 --> 00:06:15,189
the enterprise things like Microsoft

127
00:06:13,330 --> 00:06:16,930
teams and slack and to my knowledge

128
00:06:15,189 --> 00:06:18,639
they've been using it successfully ever

129
00:06:16,930 --> 00:06:20,889
since today we're going to be talking

130
00:06:18,639 --> 00:06:22,089
about lateral movement lateral movement

131
00:06:20,889 --> 00:06:23,979
is made up of a number of things

132
00:06:22,089 --> 00:06:27,939
arguably one of the most important of

133
00:06:23,979 --> 00:06:30,399
those is credential theft this felt like

134
00:06:27,939 --> 00:06:33,009
the next logical step for us following

135
00:06:30,399 --> 00:06:34,449
the success of c3 but it also just felt

136
00:06:33,009 --> 00:06:36,819
like a really interesting space for us

137
00:06:34,449 --> 00:06:38,709
to investigate based on the attention

138
00:06:36,819 --> 00:06:41,370
and the focus that defensive security

139
00:06:38,709 --> 00:06:44,289
solutions place on lateral movement

140
00:06:41,370 --> 00:06:46,449
credential theft is the process of user

141
00:06:44,289 --> 00:06:49,318
using privileged access to an operating

142
00:06:46,449 --> 00:06:51,759
system to obtain credential material

143
00:06:49,319 --> 00:06:54,009
here we have a computer and inside that

144
00:06:51,759 --> 00:06:56,110
computer is an operating system inside

145
00:06:54,009 --> 00:06:58,479
that operating system our services that

146
00:06:56,110 --> 00:07:00,490
support its operation the most

147
00:06:58,479 --> 00:07:02,620
interesting of these for us as security

148
00:07:00,490 --> 00:07:05,050
professionals is the local security

149
00:07:02,620 --> 00:07:09,190
authority subsystem service or else a

150
00:07:05,050 --> 00:07:10,990
CXC L SAS manages the local security

151
00:07:09,190 --> 00:07:12,610
policy of the operating system it

152
00:07:10,990 --> 00:07:15,040
manages local users and groups as well

153
00:07:12,610 --> 00:07:16,900
as their passwords and it facilitates

154
00:07:15,040 --> 00:07:18,280
single sign-on so that users don't need

155
00:07:16,900 --> 00:07:21,039
to keep entering their passwords to

156
00:07:18,280 --> 00:07:22,390
access resources ultimately that means

157
00:07:21,040 --> 00:07:24,010
that it contains interesting things

158
00:07:22,390 --> 00:07:26,140
within its memory space things like

159
00:07:24,010 --> 00:07:28,240
passwords password hashes Kerberos

160
00:07:26,140 --> 00:07:29,620
tickets certificates these things can be

161
00:07:28,240 --> 00:07:31,930
used to authenticate yourself on a

162
00:07:29,620 --> 00:07:34,300
computer network verify your identity

163
00:07:31,930 --> 00:07:35,680
and so they're interesting to us as

164
00:07:34,300 --> 00:07:37,630
attackers because if we can compromise

165
00:07:35,680 --> 00:07:40,120
them then we can impersonate legitimate

166
00:07:37,630 --> 00:07:42,460
users and expand our access to a target

167
00:07:40,120 --> 00:07:44,800
environment this fits into lateral

168
00:07:42,460 --> 00:07:47,140
movement because if we compromised a

169
00:07:44,800 --> 00:07:49,570
workstation and we want to gain access

170
00:07:47,140 --> 00:07:51,310
to a target database we find some

171
00:07:49,570 --> 00:07:53,890
credentials for an administrator of a

172
00:07:51,310 --> 00:07:55,870
server called server one so we use those

173
00:07:53,890 --> 00:07:57,729
to authenticate to server one and we

174
00:07:55,870 --> 00:07:59,400
compromised the credential material

175
00:07:57,730 --> 00:08:01,480
stored within its memory space of alsace

176
00:07:59,400 --> 00:08:03,969
we get some credentials for an

177
00:08:01,480 --> 00:08:05,980
administrator of server two and this

178
00:08:03,970 --> 00:08:07,470
cyclic or process this iterative

179
00:08:05,980 --> 00:08:09,340
approach to credential theft is

180
00:08:07,470 --> 00:08:10,780
essentially what makes up lateral

181
00:08:09,340 --> 00:08:12,880
movement it's made up of many things but

182
00:08:10,780 --> 00:08:15,070
you can see that it's at the core of

183
00:08:12,880 --> 00:08:16,510
what happens here so we authenticate to

184
00:08:15,070 --> 00:08:18,219
server 2 we obtain the credential

185
00:08:16,510 --> 00:08:21,190
material and we find some administrative

186
00:08:18,220 --> 00:08:22,870
credentials for server 3 we authenticate

187
00:08:21,190 --> 00:08:24,550
to a third server we do the same thing

188
00:08:22,870 --> 00:08:26,080
and we find some credentials to our

189
00:08:24,550 --> 00:08:28,030
target database and we can authenticate

190
00:08:26,080 --> 00:08:30,370
the purpose of this slide is really just

191
00:08:28,030 --> 00:08:35,650
to show you how credential theft fits in

192
00:08:30,370 --> 00:08:37,090
with in lateral movement it was a lot

193
00:08:35,650 --> 00:08:39,130
harder to retrieve credential material

194
00:08:37,090 --> 00:08:42,340
from an end point until Benjamin Del P

195
00:08:39,130 --> 00:08:43,840
released mini cats in 2007 essentially

196
00:08:42,340 --> 00:08:45,490
mainly cats is a tool that allows you to

197
00:08:43,840 --> 00:08:47,470
extract condense credential material

198
00:08:45,490 --> 00:08:48,790
from an endpoint and this is one of my

199
00:08:47,470 --> 00:08:50,980
favorite quotes from the InfoSec

200
00:08:48,790 --> 00:08:52,780
community essentially mini cats was one

201
00:08:50,980 --> 00:08:55,300
of the greatest contributions to InfoSec

202
00:08:52,780 --> 00:08:58,300
and Benjamin Delpy did it to learn C

203
00:08:55,300 --> 00:08:59,859
which is quite remarkable as I said you

204
00:08:58,300 --> 00:09:01,329
can run me me caps on an endpoint and it

205
00:08:59,860 --> 00:09:04,290
retrieves credential material in the

206
00:09:01,330 --> 00:09:07,090
glory days it was possible to do this

207
00:09:04,290 --> 00:09:08,740
directly and you could just obtain all

208
00:09:07,090 --> 00:09:10,090
that lovely credential material but

209
00:09:08,740 --> 00:09:11,350
obviously security products wanted to

210
00:09:10,090 --> 00:09:15,460
prevent against this they didn't want

211
00:09:11,350 --> 00:09:16,780
this to happen and this kind of started

212
00:09:15,460 --> 00:09:18,280
that struggle between the red team and

213
00:09:16,780 --> 00:09:20,199
the blue team where the red team wanted

214
00:09:18,280 --> 00:09:22,270
to carry out an offensive operation and

215
00:09:20,200 --> 00:09:26,140
the blue team wanted to prevent it

216
00:09:22,270 --> 00:09:27,939
or detective so to begin with the red

217
00:09:26,140 --> 00:09:30,370
team started applying simple obfuscation

218
00:09:27,940 --> 00:09:32,290
to the tool things as simple as renaming

219
00:09:30,370 --> 00:09:35,050
it to mini dogs and ultimately in

220
00:09:32,290 --> 00:09:37,030
certain situations that was enough to be

221
00:09:35,050 --> 00:09:39,819
able to run it and bypass the antivirus

222
00:09:37,030 --> 00:09:45,339
software as you can see here but this

223
00:09:39,820 --> 00:09:46,930
couldn't go on forever and so the red

224
00:09:45,340 --> 00:09:49,150
team needed a way of pushing back again

225
00:09:46,930 --> 00:09:51,130
and what better way to push back then

226
00:09:49,150 --> 00:09:54,699
not to run the tool on the endpoint at

227
00:09:51,130 --> 00:09:56,080
all essentially Benjy Benjamin Delpy

228
00:09:54,700 --> 00:09:57,670
introduced support for something called

229
00:09:56,080 --> 00:10:00,510
a process dump which is a file that

230
00:09:57,670 --> 00:10:02,829
contains the memory of a target process

231
00:10:00,510 --> 00:10:04,420
essentially if an attacker could create

232
00:10:02,830 --> 00:10:05,740
a process dump of their target system

233
00:10:04,420 --> 00:10:07,420
they could download it's they're

234
00:10:05,740 --> 00:10:08,950
attacking machine and they could run it

235
00:10:07,420 --> 00:10:10,390
through mini cats far away from any

236
00:10:08,950 --> 00:10:13,000
defensive security software that was

237
00:10:10,390 --> 00:10:14,890
getting in the way this might sound

238
00:10:13,000 --> 00:10:16,810
complex but there are legitimate reasons

239
00:10:14,890 --> 00:10:18,430
to create a process dump of a process

240
00:10:16,810 --> 00:10:21,699
and that's why Microsoft provides this

241
00:10:18,430 --> 00:10:23,380
functionality the most simple of these

242
00:10:21,700 --> 00:10:25,180
is task manager as you can see here you

243
00:10:23,380 --> 00:10:27,370
can right click the process click create

244
00:10:25,180 --> 00:10:28,839
dump file and ultimately create a

245
00:10:27,370 --> 00:10:30,760
process done for the process you can

246
00:10:28,840 --> 00:10:32,380
always see also use proc dump which is

247
00:10:30,760 --> 00:10:33,670
part of the system eternals toolkit and

248
00:10:32,380 --> 00:10:35,140
administrative tool kit for Windows

249
00:10:33,670 --> 00:10:37,180
environments and there are of course

250
00:10:35,140 --> 00:10:38,980
custom implementations of these tools

251
00:10:37,180 --> 00:10:40,420
that do the same thing they might use

252
00:10:38,980 --> 00:10:42,220
different techniques but ultimately they

253
00:10:40,420 --> 00:10:45,550
result in a process dump that can be

254
00:10:42,220 --> 00:10:47,230
used with many cats here we have mini

255
00:10:45,550 --> 00:10:49,240
cats and you just say I'd like to use

256
00:10:47,230 --> 00:10:52,630
this process dump and it uses it instead

257
00:10:49,240 --> 00:10:55,180
of using the local host in some cases

258
00:10:52,630 --> 00:10:57,189
this process can even be automated the

259
00:10:55,180 --> 00:10:59,589
else a see is a tool that was recently

260
00:10:57,190 --> 00:11:01,420
released and built on top of the impact

261
00:10:59,590 --> 00:11:03,520
in packet framework so that this can be

262
00:11:01,420 --> 00:11:05,680
done at scale this is a great option

263
00:11:03,520 --> 00:11:07,569
when you don't need to bypass EDR

264
00:11:05,680 --> 00:11:11,469
products where you're not trying to

265
00:11:07,570 --> 00:11:12,850
bypass detection go undetected but

266
00:11:11,470 --> 00:11:15,040
obviously security software I wanted to

267
00:11:12,850 --> 00:11:16,360
prevent against this as well and they do

268
00:11:15,040 --> 00:11:17,530
this using something called function

269
00:11:16,360 --> 00:11:19,060
hooking which I'm going to briefly

270
00:11:17,530 --> 00:11:20,470
describe here because it sets up some

271
00:11:19,060 --> 00:11:23,020
concepts that we're going to talk about

272
00:11:20,470 --> 00:11:24,340
a little bit later on there are two

273
00:11:23,020 --> 00:11:26,170
modes of operation within a Windows

274
00:11:24,340 --> 00:11:28,690
environment user mode and kernel mode

275
00:11:26,170 --> 00:11:30,250
user mode is for date for users to carry

276
00:11:28,690 --> 00:11:32,260
out their day-to-day business activities

277
00:11:30,250 --> 00:11:34,150
like checking their email running Google

278
00:11:32,260 --> 00:11:36,019
Chrome things like that and kernel mode

279
00:11:34,150 --> 00:11:38,600
is reserved for critical operating

280
00:11:36,019 --> 00:11:40,759
system components it's a kernel-mode is

281
00:11:38,600 --> 00:11:42,259
a highly privileged environment has a

282
00:11:40,759 --> 00:11:44,929
complete view of the operating system

283
00:11:42,259 --> 00:11:46,939
and its memory and essentially is home

284
00:11:44,929 --> 00:11:48,589
to the core of the operating system that

285
00:11:46,939 --> 00:11:51,920
provides services to user mode

286
00:11:48,589 --> 00:11:54,350
applications when an application wants

287
00:11:51,920 --> 00:11:56,779
to interact with a file or communicate

288
00:11:54,350 --> 00:11:57,980
over a network it does it requests this

289
00:11:56,779 --> 00:12:00,049
service from the kernel and the kernel

290
00:11:57,980 --> 00:12:01,850
happily obliges now to provide some

291
00:12:00,049 --> 00:12:03,920
stability Microsoft introduced a set of

292
00:12:01,850 --> 00:12:05,420
api is called the windows api x' and

293
00:12:03,920 --> 00:12:07,488
essentially they handle this

294
00:12:05,420 --> 00:12:09,860
communication with the kernel on behalf

295
00:12:07,489 --> 00:12:10,910
of the user mode application and this is

296
00:12:09,860 --> 00:12:13,100
where hooking comes in

297
00:12:10,910 --> 00:12:14,868
so these user mode applications when

298
00:12:13,100 --> 00:12:16,910
they request the windows api these

299
00:12:14,869 --> 00:12:18,799
requests can be intercepted and

300
00:12:16,910 --> 00:12:21,529
redirected and this essentially lets

301
00:12:18,799 --> 00:12:22,999
security software intercept and redirect

302
00:12:21,529 --> 00:12:24,649
certain API calls that they're

303
00:12:22,999 --> 00:12:26,959
interested in and assess them to

304
00:12:24,649 --> 00:12:28,939
identify whether they are malicious if

305
00:12:26,959 --> 00:12:30,949
they're considered to be malicious they

306
00:12:28,939 --> 00:12:32,889
can be prevented but if not they can be

307
00:12:30,949 --> 00:12:35,329
allowed to continue

308
00:12:32,889 --> 00:12:37,759
so attackers wanted to obviously find

309
00:12:35,329 --> 00:12:40,309
ways around this and one of those

310
00:12:37,759 --> 00:12:42,709
options is to unhook these hooked API

311
00:12:40,309 --> 00:12:45,319
calls if you can identify them there's a

312
00:12:42,709 --> 00:12:47,268
tool called Andrew special if you look

313
00:12:45,319 --> 00:12:49,128
for that on github it's effectively at

314
00:12:47,269 --> 00:12:52,100
all based around unhooking a certain

315
00:12:49,129 --> 00:12:53,749
security product and another option is

316
00:12:52,100 --> 00:12:55,999
to just not use the wind yet windows api

317
00:12:53,749 --> 00:12:58,369
is at all just used sis calls directly

318
00:12:55,999 --> 00:12:59,990
bypass calling those windows api s and

319
00:12:58,369 --> 00:13:02,540
actually there's a company in Holland or

320
00:12:59,990 --> 00:13:04,309
the Netherlands called outflank and they

321
00:13:02,540 --> 00:13:07,279
have developed a tool called dumper that

322
00:13:04,309 --> 00:13:10,850
does exactly this but defensive security

323
00:13:07,279 --> 00:13:12,709
solutions are aware of this of course

324
00:13:10,850 --> 00:13:14,509
and they have a component of this

325
00:13:12,709 --> 00:13:15,799
software all security software has a

326
00:13:14,509 --> 00:13:17,569
component of its software running in

327
00:13:15,799 --> 00:13:19,669
kernel mode essentially what this allows

328
00:13:17,569 --> 00:13:21,079
it to do is register to the operating

329
00:13:19,669 --> 00:13:23,329
split system for something called a

330
00:13:21,079 --> 00:13:25,519
callback and the operating system will

331
00:13:23,329 --> 00:13:31,878
notify the security software each time a

332
00:13:25,519 --> 00:13:33,769
certain event occurs the purpose of this

333
00:13:31,879 --> 00:13:36,139
slide is not to show you new techniques

334
00:13:33,769 --> 00:13:37,790
on how you can dump credential dump the

335
00:13:36,139 --> 00:13:40,549
else's process the purpose of this slide

336
00:13:37,790 --> 00:13:42,230
is to say that these techniques are

337
00:13:40,549 --> 00:13:44,059
nothing new and what we want to

338
00:13:42,230 --> 00:13:45,799
illustrate here is that things have

339
00:13:44,059 --> 00:13:47,899
gotten Heron T complicated they've

340
00:13:45,799 --> 00:13:49,730
become quite complex and this is

341
00:13:47,899 --> 00:13:51,560
ultimately why Timo and I asked

342
00:13:49,730 --> 00:13:53,660
our selves is there another approach to

343
00:13:51,560 --> 00:13:54,310
doing this is there something that we're

344
00:13:53,660 --> 00:13:58,180
missing

345
00:13:54,310 --> 00:14:03,529
could we be could we do this differently

346
00:13:58,180 --> 00:14:06,050
like Robert explained ADR has all sorts

347
00:14:03,529 --> 00:14:11,600
of methods for monitoring access to the

348
00:14:06,050 --> 00:14:15,170
LSS process a key observation for us was

349
00:14:11,600 --> 00:14:18,709
that the EDR is monitoring the LSS

350
00:14:15,170 --> 00:14:21,380
process not access to the credential

351
00:14:18,709 --> 00:14:24,529
material and this let us do the

352
00:14:21,380 --> 00:14:27,399
following problem statement how can we

353
00:14:24,529 --> 00:14:31,639
access the credential material without

354
00:14:27,399 --> 00:14:34,370
interacting with the LSS process if you

355
00:14:31,639 --> 00:14:36,800
look at all the existing tools for

356
00:14:34,370 --> 00:14:39,320
credential theft they are all focused on

357
00:14:36,800 --> 00:14:43,010
illnesses and the virtual memory around

358
00:14:39,320 --> 00:14:46,490
it but what is virtual memory basically

359
00:14:43,010 --> 00:14:48,740
it's just an addressing method just like

360
00:14:46,490 --> 00:14:51,320
a street name and a number is an

361
00:14:48,740 --> 00:14:55,579
addressing method for your home that has

362
00:14:51,320 --> 00:14:57,410
a specific physical location it's the

363
00:14:55,579 --> 00:14:59,630
same thing with the credentials yes they

364
00:14:57,410 --> 00:15:03,529
do have a virtual address but ultimately

365
00:14:59,630 --> 00:15:05,480
they live in the physical memory so we

366
00:15:03,529 --> 00:15:08,870
decided to target the physical memory

367
00:15:05,480 --> 00:15:11,540
instead so the existing attacks they

368
00:15:08,870 --> 00:15:13,940
work on the virtual memory layer we went

369
00:15:11,540 --> 00:15:16,969
one layer down into stack and targeted

370
00:15:13,940 --> 00:15:21,350
physical memory deal directly in other

371
00:15:16,970 --> 00:15:26,000
words we went in from below the approach

372
00:15:21,350 --> 00:15:28,670
isn't new this has already been done by

373
00:15:26,000 --> 00:15:33,769
criminals and not the kind of criminals

374
00:15:28,670 --> 00:15:37,189
you would expect in 2005 the central

375
00:15:33,769 --> 00:15:39,139
bank of Brazil was robbed and the

376
00:15:37,190 --> 00:15:41,149
interesting part is how they did it it

377
00:15:39,139 --> 00:15:46,149
has absolutely nothing to do with

378
00:15:41,149 --> 00:15:48,800
computers instead of trying to access

379
00:15:46,149 --> 00:15:52,250
the vault by going through one of these

380
00:15:48,800 --> 00:15:54,949
massive doors or trying to explode a

381
00:15:52,250 --> 00:15:58,640
hole in the wall they did something very

382
00:15:54,949 --> 00:16:02,260
different they dug two hundred meters of

383
00:15:58,640 --> 00:16:04,040
tunnel and access the vault from below

384
00:16:02,260 --> 00:16:06,230
now this approach

385
00:16:04,040 --> 00:16:08,420
was very successful for these guys

386
00:16:06,230 --> 00:16:11,269
because this is one of the biggest bank

387
00:16:08,420 --> 00:16:13,459
robberies in history and it remains to

388
00:16:11,269 --> 00:16:16,430
be seen whether this approach is equally

389
00:16:13,459 --> 00:16:18,349
successful for stealing credentials so

390
00:16:16,430 --> 00:16:20,569
the recap we did the same thing and as

391
00:16:18,350 --> 00:16:25,310
the bank robbers and went in from below

392
00:16:20,569 --> 00:16:27,649
and targeted the physical memory now if

393
00:16:25,310 --> 00:16:29,899
you want to make any sense of the data

394
00:16:27,649 --> 00:16:33,440
in the physical memory who you gonna

395
00:16:29,899 --> 00:16:35,690
call ghostbusters no you call your

396
00:16:33,440 --> 00:16:37,880
colleagues in the incident response team

397
00:16:35,690 --> 00:16:39,920
because they know how to do memory

398
00:16:37,880 --> 00:16:42,699
forensics and they will tell you that

399
00:16:39,920 --> 00:16:46,519
the in practice there's two good tools

400
00:16:42,699 --> 00:16:48,529
volatility and recall so we started this

401
00:16:46,519 --> 00:16:51,709
research by comparing these two and

402
00:16:48,529 --> 00:16:54,079
after a very brief evaluation we had a

403
00:16:51,709 --> 00:16:56,750
clear winner because volatility was

404
00:16:54,079 --> 00:16:59,930
super slow I mean just running the image

405
00:16:56,750 --> 00:17:02,029
info command that took ages and that

406
00:16:59,930 --> 00:17:04,459
gives you only the high-level summary of

407
00:17:02,029 --> 00:17:08,589
the image now you might be wondering

408
00:17:04,459 --> 00:17:11,209
that is the speed really relevant here

409
00:17:08,589 --> 00:17:13,908
the way we look at this is that we

410
00:17:11,209 --> 00:17:16,790
wanted to create something that people

411
00:17:13,909 --> 00:17:19,370
actually want to use so it doesn't

412
00:17:16,790 --> 00:17:22,129
really matter if you have really cool

413
00:17:19,369 --> 00:17:25,188
technical tricks but your tool is so

414
00:17:22,130 --> 00:17:29,240
slow that nobody likes to use it so we

415
00:17:25,189 --> 00:17:31,250
decided to go it recall so what we do we

416
00:17:29,240 --> 00:17:35,419
steal credentials using a tool that

417
00:17:31,250 --> 00:17:37,730
defenders typically use at the other end

418
00:17:35,419 --> 00:17:40,159
the other end of the pipeline we knew

419
00:17:37,730 --> 00:17:41,900
that we want to be able to produce mini

420
00:17:40,159 --> 00:17:44,960
Dom's because like Robert explained

421
00:17:41,900 --> 00:17:47,390
earlier mimikatz has the capability to

422
00:17:44,960 --> 00:17:50,210
analyze mimi dumps the mini dumps and

423
00:17:47,390 --> 00:17:52,280
extract credentials from those in

424
00:17:50,210 --> 00:17:54,080
addition we already had developed

425
00:17:52,280 --> 00:17:56,658
internal automation where you can just

426
00:17:54,080 --> 00:17:58,460
give it a mini dump it uses mimic ads to

427
00:17:56,659 --> 00:18:00,370
extract the credentials and then

428
00:17:58,460 --> 00:18:04,940
forwards those to our post exploitation

429
00:18:00,370 --> 00:18:07,340
toolkits these are also the reasons why

430
00:18:04,940 --> 00:18:10,340
we didn't use an existing tool called pi

431
00:18:07,340 --> 00:18:13,850
pi cuts which on paper dance made this

432
00:18:10,340 --> 00:18:17,059
use case but there is still something

433
00:18:13,850 --> 00:18:17,879
missing in the middle we have all the

434
00:18:17,059 --> 00:18:20,340
relevant date

435
00:18:17,880 --> 00:18:23,010
and we know that there is a specific

436
00:18:20,340 --> 00:18:26,610
file format that we want to use but how

437
00:18:23,010 --> 00:18:29,310
to connect these two this is exactly

438
00:18:26,610 --> 00:18:32,669
what the first proof of concept of this

439
00:18:29,310 --> 00:18:35,010
memory prophet did it used recall to

440
00:18:32,670 --> 00:18:37,980
analyze an image of the entire physical

441
00:18:35,010 --> 00:18:40,170
memory it located the else's process

442
00:18:37,980 --> 00:18:42,990
then snipped out all the relevant data

443
00:18:40,170 --> 00:18:46,170
and then say that in the minidom file

444
00:18:42,990 --> 00:18:48,570
format now most of the development

445
00:18:46,170 --> 00:18:51,480
effort here went into writing those

446
00:18:48,570 --> 00:18:54,060
minidom files and I can tell you that

447
00:18:51,480 --> 00:18:56,880
that's not really the nicest the easiest

448
00:18:54,060 --> 00:18:59,610
file format out there so we used a

449
00:18:56,880 --> 00:19:02,180
Python module called construct but still

450
00:18:59,610 --> 00:19:05,990
it was it was quite a lot of work

451
00:19:02,180 --> 00:19:08,940
however the end result was quite nice

452
00:19:05,990 --> 00:19:10,530
with the first proof-of-concept you

453
00:19:08,940 --> 00:19:11,060
could steal credentials in three easy

454
00:19:10,530 --> 00:19:14,790
steps

455
00:19:11,060 --> 00:19:16,889
first you use those existing established

456
00:19:14,790 --> 00:19:19,170
memory acquisition tools like dumb bit

457
00:19:16,890 --> 00:19:21,510
or wimpy mem to dump the physical memory

458
00:19:19,170 --> 00:19:23,340
you give that memory dump the fish mem

459
00:19:21,510 --> 00:19:25,740
to profit and you get a mini DOM and

460
00:19:23,340 --> 00:19:28,610
then you give that mini dump to mimic

461
00:19:25,740 --> 00:19:32,120
ads and there you have your credentials

462
00:19:28,610 --> 00:19:35,159
the beauty of this approach is that

463
00:19:32,120 --> 00:19:37,860
we're not interacting with the else's

464
00:19:35,160 --> 00:19:40,260
process of the target system in any way

465
00:19:37,860 --> 00:19:44,699
and what that means is that it's very

466
00:19:40,260 --> 00:19:46,440
difficult for EDR to detect this now

467
00:19:44,700 --> 00:19:48,600
even though we didn't really have to

468
00:19:46,440 --> 00:19:51,630
write that many lines of code for the

469
00:19:48,600 --> 00:19:54,240
proof of concept the minidom file format

470
00:19:51,630 --> 00:19:56,970
is a pain so there was quite a lot of

471
00:19:54,240 --> 00:19:59,310
troubleshooting and debugging involved

472
00:19:56,970 --> 00:20:02,730
so I can tell you that when we finally

473
00:19:59,310 --> 00:20:04,950
got a valid mini dump gave it to me me

474
00:20:02,730 --> 00:20:07,920
cats and got those first lovely cringe

475
00:20:04,950 --> 00:20:12,210
credentials that felt pretty great that

476
00:20:07,920 --> 00:20:14,040
was a good day so we could steal

477
00:20:12,210 --> 00:20:17,670
credentials by accessing the physical

478
00:20:14,040 --> 00:20:19,139
memory what's more it didn't cause an

479
00:20:17,670 --> 00:20:20,460
alert in our detection platform which

480
00:20:19,140 --> 00:20:22,830
kind of gave us the encouragement we

481
00:20:20,460 --> 00:20:23,880
needed to continue and we thought this

482
00:20:22,830 --> 00:20:27,360
was pretty cool we thought this was

483
00:20:23,880 --> 00:20:29,010
pretty pretty groundbreaking but then on

484
00:20:27,360 --> 00:20:30,600
closer inspection we realized that we

485
00:20:29,010 --> 00:20:31,650
perhaps had a - a few too many

486
00:20:30,600 --> 00:20:33,510
similarities

487
00:20:31,650 --> 00:20:35,760
to the bank robbers in Brazil than we'd

488
00:20:33,510 --> 00:20:38,100
care to admit they created a fake

489
00:20:35,760 --> 00:20:39,629
construction company to excavate all the

490
00:20:38,100 --> 00:20:42,209
dirt from the tunnel they were digging

491
00:20:39,630 --> 00:20:43,910
to the bank and our initial proof of

492
00:20:42,210 --> 00:20:46,920
concept was quite similar to this

493
00:20:43,910 --> 00:20:49,770
because we would create an image of the

494
00:20:46,920 --> 00:20:52,610
main memory of our target and then we

495
00:20:49,770 --> 00:20:54,930
would excavate that across a network

496
00:20:52,610 --> 00:20:57,000
essentially we'd do this with dump it or

497
00:20:54,930 --> 00:21:00,420
wimpy mem to create that main memory

498
00:20:57,000 --> 00:21:03,030
image you know luckily for the bank

499
00:21:00,420 --> 00:21:04,710
robbers the neighbors didn't notice

500
00:21:03,030 --> 00:21:07,470
anything suspicious about this dumper

501
00:21:04,710 --> 00:21:09,270
truck going back and forth but we have

502
00:21:07,470 --> 00:21:11,370
to contend with modern security products

503
00:21:09,270 --> 00:21:13,620
and modern security teams and they would

504
00:21:11,370 --> 00:21:16,590
definitely notice such a huge amount of

505
00:21:13,620 --> 00:21:17,969
data coming out of their network we knew

506
00:21:16,590 --> 00:21:19,620
that this wasn't very elegant from an

507
00:21:17,970 --> 00:21:21,720
operational security standpoint and

508
00:21:19,620 --> 00:21:25,679
ultimately we knew that we needed to do

509
00:21:21,720 --> 00:21:28,710
better but we also knew that dump it and

510
00:21:25,680 --> 00:21:30,300
wind pea men had to have a component of

511
00:21:28,710 --> 00:21:32,430
their software running in kernel modes

512
00:21:30,300 --> 00:21:35,250
because they had comprehensive and

513
00:21:32,430 --> 00:21:38,430
random access to the memory so we

514
00:21:35,250 --> 00:21:42,360
thought well what if we lose the

515
00:21:38,430 --> 00:21:45,750
executable could we interact with that

516
00:21:42,360 --> 00:21:49,199
kernel mode component directly and it

517
00:21:45,750 --> 00:21:51,570
turns out you can so we developed a fizz

518
00:21:49,200 --> 00:21:54,390
mem to profit c-sharp server component

519
00:21:51,570 --> 00:21:58,290
that runs on our target host and exposes

520
00:21:54,390 --> 00:22:00,690
the physical memory of the device we

521
00:21:58,290 --> 00:22:03,030
then run our fizz mem to profit client

522
00:22:00,690 --> 00:22:04,500
component and we mount that physical

523
00:22:03,030 --> 00:22:06,960
memory as a fire we do this using the

524
00:22:04,500 --> 00:22:09,600
file system in userspace or fuse via the

525
00:22:06,960 --> 00:22:13,350
fuse py Python module essentially fuse

526
00:22:09,600 --> 00:22:14,879
py or fuse PI offers a simple interface

527
00:22:13,350 --> 00:22:16,320
to fuse and with less than a hundred

528
00:22:14,880 --> 00:22:18,920
lines of Python we were able to achieve

529
00:22:16,320 --> 00:22:22,050
our objective

530
00:22:18,920 --> 00:22:25,140
what we do is proxy our read requests

531
00:22:22,050 --> 00:22:27,810
over the TCP connection we can then use

532
00:22:25,140 --> 00:22:30,000
office mem to profit client component to

533
00:22:27,810 --> 00:22:31,950
analyze that physical memory find the

534
00:22:30,000 --> 00:22:33,990
LSS process the bit we're interested in

535
00:22:31,950 --> 00:22:36,150
snip it out and create a process thump

536
00:22:33,990 --> 00:22:40,290
that ultimately we can use with mini

537
00:22:36,150 --> 00:22:42,300
cats at this point we felt a lot less

538
00:22:40,290 --> 00:22:44,670
like the bank robbers in Brazil and a

539
00:22:42,300 --> 00:22:45,560
lot more like Leslie Nielsen in Naked

540
00:22:44,670 --> 00:22:47,810
Gun the final in

541
00:22:45,560 --> 00:22:49,760
so I'm really hoping there's some people

542
00:22:47,810 --> 00:22:52,070
who are familiar with Naked Gun in the

543
00:22:49,760 --> 00:22:53,780
audience he was digging a tunnel out of

544
00:22:52,070 --> 00:23:00,860
prison and that's how he smuggled the

545
00:22:53,780 --> 00:23:02,660
dirt this all sounds great but as I

546
00:23:00,860 --> 00:23:04,370
mentioned kernel-mode is a highly

547
00:23:02,660 --> 00:23:06,430
privileged environment has a complete

548
00:23:04,370 --> 00:23:08,719
view of the OS and its memory and

549
00:23:06,430 --> 00:23:11,000
ultimately even though we were using a

550
00:23:08,720 --> 00:23:12,500
tool like wind P mem which is a robust

551
00:23:11,000 --> 00:23:14,450
and comprehensive piece of software

552
00:23:12,500 --> 00:23:17,000
sometimes if you're using a really

553
00:23:14,450 --> 00:23:19,400
powerful tool like a chainsaw you can

554
00:23:17,000 --> 00:23:22,790
lose a leg or end up with a blue screen

555
00:23:19,400 --> 00:23:24,620
of death but we were able to overcome

556
00:23:22,790 --> 00:23:26,060
this and ultimately create a proof of

557
00:23:24,620 --> 00:23:28,310
concept that we're going to share with

558
00:23:26,060 --> 00:23:30,230
you now so here we have F secures

559
00:23:28,310 --> 00:23:32,000
detection platform on the left you see

560
00:23:30,230 --> 00:23:33,740
Fizz mem demo1 and on the right you

561
00:23:32,000 --> 00:23:35,630
fitzy Fizz mem demo - these are two

562
00:23:33,740 --> 00:23:37,400
windows 10 workstations that have our

563
00:23:35,630 --> 00:23:39,410
agent installed on them we go to our

564
00:23:37,400 --> 00:23:41,870
attacking machine and we RDP into Fizz

565
00:23:39,410 --> 00:23:43,280
mem demo one we run hostname so you can

566
00:23:41,870 --> 00:23:45,110
see which endpoint we're talking about

567
00:23:43,280 --> 00:23:46,490
and then we run proc dump which is

568
00:23:45,110 --> 00:23:48,500
commonly used by attackers and red

569
00:23:46,490 --> 00:23:50,780
teamers around the world and will cause

570
00:23:48,500 --> 00:23:54,010
a severe detection in our endpoint

571
00:23:50,780 --> 00:23:56,600
platform as you can see here on the Left

572
00:23:54,010 --> 00:23:59,450
we go back to our attacking machine and

573
00:23:56,600 --> 00:24:01,820
we RDP into fizz mem demo - we run

574
00:23:59,450 --> 00:24:04,340
hostname once more so you can see which

575
00:24:01,820 --> 00:24:05,929
endpoint we're running on and then we

576
00:24:04,340 --> 00:24:07,520
run our c-sharp fizz mint a profit

577
00:24:05,930 --> 00:24:09,110
server component we give it an IP

578
00:24:07,520 --> 00:24:11,900
address so it knows which interface to

579
00:24:09,110 --> 00:24:13,370
listen on and we give it a port you

580
00:24:11,900 --> 00:24:15,410
don't have to do this at will default to

581
00:24:13,370 --> 00:24:19,939
port 8080 but we wanted to be modular

582
00:24:15,410 --> 00:24:21,530
and flexible so we give it port 8080 it

583
00:24:19,940 --> 00:24:23,210
all starts listening we cancel out of

584
00:24:21,530 --> 00:24:25,970
our RDP session and we go back to our

585
00:24:23,210 --> 00:24:27,980
attacking machine we run our FISMA into

586
00:24:25,970 --> 00:24:30,110
profit client component which connects

587
00:24:27,980 --> 00:24:32,290
to that tcp port loads the kernel mode

588
00:24:30,110 --> 00:24:35,149
component exposes the physical memory

589
00:24:32,290 --> 00:24:37,730
mounts the physical memory analyze it to

590
00:24:35,150 --> 00:24:39,950
find the LSS process snips it out

591
00:24:37,730 --> 00:24:41,780
creates a process dump and drops it into

592
00:24:39,950 --> 00:24:44,950
the output folder as you can see here it

593
00:24:41,780 --> 00:24:47,149
is important to note at this point that

594
00:24:44,950 --> 00:24:49,310
we did speed the tool up for the

595
00:24:47,150 --> 00:24:51,110
purposes of this demonstration the

596
00:24:49,310 --> 00:24:53,510
typical run time is around two minutes

597
00:24:51,110 --> 00:24:55,870
we go back to our detection platform and

598
00:24:53,510 --> 00:24:58,490
you can see that no detection occurred

599
00:24:55,870 --> 00:24:59,419
we can then use the mini dump with

600
00:24:58,490 --> 00:25:00,890
mitty-kats

601
00:24:59,420 --> 00:25:06,860
and you can find out my super secret

602
00:25:00,890 --> 00:25:08,270
passwords down below you might be able

603
00:25:06,860 --> 00:25:11,240
to see the floor with our plan here

604
00:25:08,270 --> 00:25:13,370
though they're introducing something to

605
00:25:11,240 --> 00:25:14,930
our target operating system we're

606
00:25:13,370 --> 00:25:18,110
introducing a driver that wasn't there

607
00:25:14,930 --> 00:25:20,830
before and windows event ID number six

608
00:25:18,110 --> 00:25:23,689
driver load it doesn't happen that often

609
00:25:20,830 --> 00:25:25,040
so a defensive security team would

610
00:25:23,690 --> 00:25:27,710
probably start looking into that because

611
00:25:25,040 --> 00:25:30,320
it seems quite suspicious and so we

612
00:25:27,710 --> 00:25:32,980
started thinking to ourselves what's

613
00:25:30,320 --> 00:25:35,570
present on the operating system already

614
00:25:32,980 --> 00:25:37,820
that perhaps has access to the physical

615
00:25:35,570 --> 00:25:41,330
memory and then we remembered that EDR

616
00:25:37,820 --> 00:25:44,210
products are commonly present in

617
00:25:41,330 --> 00:25:46,010
enterprise environments and they provide

618
00:25:44,210 --> 00:25:49,580
functionality that supports Incident

619
00:25:46,010 --> 00:25:52,190
Response which ultimately means they can

620
00:25:49,580 --> 00:25:53,960
access the physical memory and then we

621
00:25:52,190 --> 00:25:55,790
thought well we can't just poker a

622
00:25:53,960 --> 00:25:57,380
competitor's EDR products because that

623
00:25:55,790 --> 00:26:01,460
wouldn't be very fair just to come along

624
00:25:57,380 --> 00:26:03,490
and release a tool that targets them but

625
00:26:01,460 --> 00:26:07,690
we could and should as an objective

626
00:26:03,490 --> 00:26:10,310
consultancy target our own so we did

627
00:26:07,690 --> 00:26:12,320
what we found as I mentioned earlier is

628
00:26:10,310 --> 00:26:14,540
that our IDI opera EDR products had a

629
00:26:12,320 --> 00:26:17,689
component of its software running in

630
00:26:14,540 --> 00:26:19,460
kernel mode as I also mentioned Fitz

631
00:26:17,690 --> 00:26:21,040
meant a prophet has a component of its

632
00:26:19,460 --> 00:26:24,110
software running in kernel mode on

633
00:26:21,040 --> 00:26:26,120
closer inspection it turns out that Fizz

634
00:26:24,110 --> 00:26:27,919
meant a prophet uses the same kernel

635
00:26:26,120 --> 00:26:30,080
mode component that our EDR product does

636
00:26:27,920 --> 00:26:31,760
and so essentially we turned up to rob a

637
00:26:30,080 --> 00:26:35,320
bank with a small drill and there was a

638
00:26:31,760 --> 00:26:39,379
diamond coring machine already present

639
00:26:35,320 --> 00:26:41,210
we are really excited to say that his

640
00:26:39,380 --> 00:26:44,180
mentor prophet is available as of right

641
00:26:41,210 --> 00:26:46,250
now on f-secure labs github there is an

642
00:26:44,180 --> 00:26:48,230
accompanying blog accompanying blog post

643
00:26:46,250 --> 00:26:52,010
called rethinking credential theft on

644
00:26:48,230 --> 00:26:53,870
the f-secure labs blog but we would like

645
00:26:52,010 --> 00:26:56,060
to stress at the moment that his mentor

646
00:26:53,870 --> 00:26:58,010
prophet was not designed to be a silver

647
00:26:56,060 --> 00:27:01,370
bullet for all edr products that are out

648
00:26:58,010 --> 00:27:04,310
there what we wanted to do with this

649
00:27:01,370 --> 00:27:06,439
research was just rethink credential

650
00:27:04,310 --> 00:27:11,090
theft propose an alternative approach

651
00:27:06,440 --> 00:27:12,480
and release a tool a framework that's

652
00:27:11,090 --> 00:27:14,820
modular and

653
00:27:12,480 --> 00:27:17,280
extendable to support additional drivers

654
00:27:14,820 --> 00:27:18,809
that have access to physical memory so

655
00:27:17,280 --> 00:27:23,850
that perhaps one day it could become

656
00:27:18,809 --> 00:27:29,010
part of the red teamers toolbox on the

657
00:27:23,850 --> 00:27:30,418
note of extending Fishman's prophet we

658
00:27:29,010 --> 00:27:34,860
were having a conversation I was talking

659
00:27:30,419 --> 00:27:35,790
to the team oh one Sunday and we were

660
00:27:34,860 --> 00:27:38,189
saying you know we want this to be a

661
00:27:35,790 --> 00:27:39,659
community project we want to make sure

662
00:27:38,190 --> 00:27:40,919
people contribute whether they just tell

663
00:27:39,660 --> 00:27:43,980
us there's a bug in it or whether they

664
00:27:40,919 --> 00:27:45,960
just tell us they don't like it but we

665
00:27:43,980 --> 00:27:47,100
want people to get involved and so we

666
00:27:45,960 --> 00:27:49,770
said well you know we should really test

667
00:27:47,100 --> 00:27:53,939
out how modular this is is it possible

668
00:27:49,770 --> 00:27:55,559
is it easy to extend it and Timo said

669
00:27:53,940 --> 00:27:56,640
yeah you know what I'm going to try this

670
00:27:55,559 --> 00:27:57,660
I'm going to try this tonight I'm going

671
00:27:56,640 --> 00:27:59,340
to see if I can just add some

672
00:27:57,660 --> 00:28:02,010
functionality or add support for another

673
00:27:59,340 --> 00:28:06,659
driver and then 30 minutes later I get

674
00:28:02,010 --> 00:28:08,280
this text message which for those of you

675
00:28:06,660 --> 00:28:10,350
who aren't from fillin that you work

676
00:28:08,280 --> 00:28:11,850
with fins you'll know that a smiley face

677
00:28:10,350 --> 00:28:14,909
in a text message means he's literally

678
00:28:11,850 --> 00:28:16,379
jumping for joy and those of you that

679
00:28:14,910 --> 00:28:18,360
work with Timo or you know him

680
00:28:16,380 --> 00:28:21,059
personally will know that this text

681
00:28:18,360 --> 00:28:23,610
message sums him up perfectly you'll be

682
00:28:21,059 --> 00:28:24,870
working on a complex challenge and he'll

683
00:28:23,610 --> 00:28:26,428
come back to you in quite a short

684
00:28:24,870 --> 00:28:32,580
timeframe and just tell you he's already

685
00:28:26,429 --> 00:28:35,100
done it yeah this is actually a true

686
00:28:32,580 --> 00:28:38,178
story it was my wife's turn to put our

687
00:28:35,100 --> 00:28:40,740
son to bed so I had some free time I

688
00:28:38,179 --> 00:28:43,169
started googling searching for drivers

689
00:28:40,740 --> 00:28:45,450
that would allow access the physical

690
00:28:43,169 --> 00:28:49,320
memory and I found this

691
00:28:45,450 --> 00:28:52,710
awesome blog post titled reading

692
00:28:49,320 --> 00:28:57,350
physical memory using carbon blacks and

693
00:28:52,710 --> 00:29:00,630
point driver this is quite nice because

694
00:28:57,350 --> 00:29:03,299
during many of the read in red team

695
00:29:00,630 --> 00:29:06,450
engagements that we've had we had to

696
00:29:03,299 --> 00:29:08,668
evade carbon black and in this book post

697
00:29:06,450 --> 00:29:10,440
you have all the necessary technical

698
00:29:08,669 --> 00:29:14,370
details to read the physical memory

699
00:29:10,440 --> 00:29:17,370
using carbon black so not only teach you

700
00:29:14,370 --> 00:29:20,219
maybe evade carbon black you could even

701
00:29:17,370 --> 00:29:23,070
abuse it to steal credentials and for a

702
00:29:20,220 --> 00:29:24,750
red teamer that's that's really cool for

703
00:29:23,070 --> 00:29:26,250
those of you wondering whether the

704
00:29:24,750 --> 00:29:28,140
author of the blog post

705
00:29:26,250 --> 00:29:31,530
disclosed these issues two carbon black

706
00:29:28,140 --> 00:29:35,250
according to the blogpost yes he did the

707
00:29:31,530 --> 00:29:37,410
reply from carbon black this is not a

708
00:29:35,250 --> 00:29:39,870
security issue because you need to have

709
00:29:37,410 --> 00:29:43,530
admin privilege seized so fair enough

710
00:29:39,870 --> 00:29:46,409
now to secure the issue let me show you

711
00:29:43,530 --> 00:29:49,560
how easy it is to add support for this

712
00:29:46,410 --> 00:29:51,960
driver in face memory profit when you

713
00:29:49,560 --> 00:29:54,780
run the tool you see those output lines

714
00:29:51,960 --> 00:29:57,090
saying registered command all you need

715
00:29:54,780 --> 00:29:59,280
to do is implement three four different

716
00:29:57,090 --> 00:30:02,129
commands and that's as simple as

717
00:29:59,280 --> 00:30:04,230
creating a single c-sharp class in

718
00:30:02,130 --> 00:30:06,570
hearing inheriting that from a couple of

719
00:30:04,230 --> 00:30:08,940
other classes and then implementing

720
00:30:06,570 --> 00:30:11,429
those methods let's start with the

721
00:30:08,940 --> 00:30:14,850
install method you probably didn't guess

722
00:30:11,430 --> 00:30:16,950
this but it installs the driver with the

723
00:30:14,850 --> 00:30:19,260
wind pmm driver what we do is we use a

724
00:30:16,950 --> 00:30:21,360
service to install the driver but with

725
00:30:19,260 --> 00:30:23,430
carbon black this is easier because the

726
00:30:21,360 --> 00:30:25,770
driver is already there so we just need

727
00:30:23,430 --> 00:30:29,070
to call create file and we get a handle

728
00:30:25,770 --> 00:30:31,290
to the device object so all the code

729
00:30:29,070 --> 00:30:34,320
needed for this step you see here on the

730
00:30:31,290 --> 00:30:37,530
screen the second method you want to

731
00:30:34,320 --> 00:30:41,460
implement is called map and the purpose

732
00:30:37,530 --> 00:30:43,379
of this method is to return the list of

733
00:30:41,460 --> 00:30:47,100
memory ranges that can be safely

734
00:30:43,380 --> 00:30:49,740
accessed if you access a memory address

735
00:30:47,100 --> 00:30:51,510
outside those ranges you will get one of

736
00:30:49,740 --> 00:30:54,050
those deadly blue screens that robert

737
00:30:51,510 --> 00:30:56,730
showed earlier that was the root cause

738
00:30:54,050 --> 00:30:59,490
so yeah you need to implement this

739
00:30:56,730 --> 00:31:02,070
there's three device IO control calls

740
00:30:59,490 --> 00:31:04,650
the first one authenticates with the

741
00:31:02,070 --> 00:31:06,899
driver and this is a requirement that's

742
00:31:04,650 --> 00:31:09,930
specific to the carbon bag driver this

743
00:31:06,900 --> 00:31:12,420
is a special case the second device IO

744
00:31:09,930 --> 00:31:14,880
control there we set the acquisition

745
00:31:12,420 --> 00:31:18,030
mode and what that simply means is we

746
00:31:14,880 --> 00:31:20,400
select the technical method that is used

747
00:31:18,030 --> 00:31:22,980
then access that physical memory and

748
00:31:20,400 --> 00:31:25,980
then finally in the last device IO

749
00:31:22,980 --> 00:31:28,740
control call we request from the driver

750
00:31:25,980 --> 00:31:30,060
the list of memory ranges and then all

751
00:31:28,740 --> 00:31:32,310
you need to do is parse the response

752
00:31:30,060 --> 00:31:35,190
from the driver and there you have it

753
00:31:32,310 --> 00:31:38,490
again all the relevant code here on the

754
00:31:35,190 --> 00:31:40,200
slide the third and final method you

755
00:31:38,490 --> 00:31:42,119
probably want to implement is free

756
00:31:40,200 --> 00:31:44,580
and that's the one that surprise

757
00:31:42,119 --> 00:31:47,939
surprise reads the physical memory you

758
00:31:44,580 --> 00:31:49,559
give the driver a physical address and

759
00:31:47,940 --> 00:31:52,039
the number of bytes you want to read

760
00:31:49,559 --> 00:31:56,428
then you get the response and that's it

761
00:31:52,039 --> 00:31:59,820
so not that many lines of code 30

762
00:31:56,429 --> 00:32:02,179
minutes and suddenly carbon black EDR

763
00:31:59,820 --> 00:32:11,879
becomes the red teamers best friend I

764
00:32:02,179 --> 00:32:14,309
like that thank you yeah we were pretty

765
00:32:11,879 --> 00:32:16,918
pretty happy about this so we were

766
00:32:14,309 --> 00:32:18,149
celebrating this like high-fiving and

767
00:32:16,919 --> 00:32:21,149
being like this is the greatest

768
00:32:18,149 --> 00:32:24,649
credential theft ever we were so proud

769
00:32:21,149 --> 00:32:30,498
of this and then we have a colleague

770
00:32:24,649 --> 00:32:33,090
Charlie Charlie coming to us saying guys

771
00:32:30,499 --> 00:32:36,450
I'm I'm sorry to interrupt your

772
00:32:33,090 --> 00:32:39,509
celebration but have you have you guys

773
00:32:36,450 --> 00:32:41,639
heard of credential guard and then I was

774
00:32:39,509 --> 00:32:43,259
like haha sure we have heard of

775
00:32:41,639 --> 00:32:45,508
credential guard but that's not a

776
00:32:43,259 --> 00:32:47,429
problem I mean you need to have admin

777
00:32:45,509 --> 00:32:49,289
privileges on the box anyway and if your

778
00:32:47,429 --> 00:32:51,359
admin on the box then you have access to

779
00:32:49,289 --> 00:32:52,980
the entire physical memory and the

780
00:32:51,359 --> 00:32:54,570
credentials needs to be somewhere in

781
00:32:52,980 --> 00:32:56,779
that physical memory so it's not a

782
00:32:54,570 --> 00:33:00,210
problem

783
00:32:56,779 --> 00:33:02,730
sounds logical but there was this minor

784
00:33:00,210 --> 00:33:04,759
thing that we didn't quite understand

785
00:33:02,730 --> 00:33:07,950
how credential guard works

786
00:33:04,759 --> 00:33:11,129
so here's credential guard for you it

787
00:33:07,950 --> 00:33:14,580
uses a feature called virtualization

788
00:33:11,129 --> 00:33:18,209
based security so what you have is a

789
00:33:14,580 --> 00:33:20,928
hypervisor layer and then all the daily

790
00:33:18,210 --> 00:33:24,809
operations that you do on that computer

791
00:33:20,929 --> 00:33:28,049
in reality those happen inside a virtual

792
00:33:24,809 --> 00:33:30,509
machine so all the daily stuff you do

793
00:33:28,049 --> 00:33:31,918
you do it inside a virtual machine and

794
00:33:30,509 --> 00:33:34,639
you don't even know it because this is

795
00:33:31,919 --> 00:33:37,739
totally transparent to the end-user

796
00:33:34,639 --> 00:33:40,799
but this also means that if you have

797
00:33:37,739 --> 00:33:43,529
those admin privileges you have admin

798
00:33:40,799 --> 00:33:47,730
privileges only within that virtual

799
00:33:43,529 --> 00:33:50,960
machine now where do the credentials

800
00:33:47,730 --> 00:33:53,639
live I have good news and bad news

801
00:33:50,960 --> 00:33:54,140
the credentials is the good news the

802
00:33:53,639 --> 00:33:58,159
credit

803
00:33:54,140 --> 00:33:59,870
shall still live in the normal world now

804
00:33:58,160 --> 00:34:03,020
the bad news is that those credentials

805
00:33:59,870 --> 00:34:05,060
are encrypted so it doesn't help you

806
00:34:03,020 --> 00:34:07,840
much unless you know the encryption key

807
00:34:05,060 --> 00:34:10,610
and by now you probably already guessed

808
00:34:07,840 --> 00:34:12,918
that the encryption key lives in an

809
00:34:10,610 --> 00:34:15,710
other virtual machine called the secure

810
00:34:12,918 --> 00:34:17,658
world now if you want to decrypt the

811
00:34:15,710 --> 00:34:20,690
credentials and bypass credential guard

812
00:34:17,659 --> 00:34:23,570
you would need to escape a virtual

813
00:34:20,690 --> 00:34:26,030
machine and then read the encryption key

814
00:34:23,570 --> 00:34:27,500
and you probably know that escaping a

815
00:34:26,030 --> 00:34:30,440
virtual machine is a pretty difficult

816
00:34:27,500 --> 00:34:33,409
problem in fact it's so difficult that

817
00:34:30,440 --> 00:34:35,899
Microsoft is willing to pay two hundred

818
00:34:33,409 --> 00:34:40,220
and fifty thousand US dollars for any

819
00:34:35,899 --> 00:34:43,759
reports of such more abilities so in my

820
00:34:40,219 --> 00:34:46,580
books this is a difficult problem the

821
00:34:43,760 --> 00:34:49,130
great news is that if there is something

822
00:34:46,580 --> 00:34:52,429
I really enjoy doing it's solving

823
00:34:49,130 --> 00:34:56,690
difficult problems the other good news

824
00:34:52,429 --> 00:34:59,320
is not at blackhat 2017 Intel

825
00:34:56,690 --> 00:35:02,330
researchers gave this great presentation

826
00:34:59,320 --> 00:35:04,790
about why passing credential guard by

827
00:35:02,330 --> 00:35:08,299
exploiting a vulnerability in firmware

828
00:35:04,790 --> 00:35:10,279
and I I think the information in this

829
00:35:08,300 --> 00:35:12,950
presentation is really golden I think

830
00:35:10,280 --> 00:35:14,690
this presentation is very underrated so

831
00:35:12,950 --> 00:35:17,390
if you're interested in the topic please

832
00:35:14,690 --> 00:35:20,810
go and check out the presentation they

833
00:35:17,390 --> 00:35:23,480
also detailed what are the crypto

834
00:35:20,810 --> 00:35:25,970
methods used by credential guard to

835
00:35:23,480 --> 00:35:28,220
protect the credentials there's two key

836
00:35:25,970 --> 00:35:32,509
concepts and I will explain this very

837
00:35:28,220 --> 00:35:34,009
briefly one is he derivation and then

838
00:35:32,510 --> 00:35:37,250
the other one is authenticated

839
00:35:34,010 --> 00:35:39,710
encryption now those key derivation

840
00:35:37,250 --> 00:35:41,990
functions are a challenge from an

841
00:35:39,710 --> 00:35:46,790
attackers perspective let me explain why

842
00:35:41,990 --> 00:35:49,729
each and every credential is encrypted

843
00:35:46,790 --> 00:35:52,640
with a unique key and those keys are

844
00:35:49,730 --> 00:35:55,760
derived you have a master key and then

845
00:35:52,640 --> 00:35:59,629
from that master key you derive unique

846
00:35:55,760 --> 00:36:02,480
keys the problem here is that if you

847
00:35:59,630 --> 00:36:05,300
somehow get access to the memory of the

848
00:36:02,480 --> 00:36:07,789
secure world and try to find those

849
00:36:05,300 --> 00:36:10,909
derived keys those are not

850
00:36:07,789 --> 00:36:13,999
there they are not in memory based on

851
00:36:10,909 --> 00:36:17,449
our experiments my theory is that those

852
00:36:13,999 --> 00:36:19,399
keys are derived on demand so those are

853
00:36:17,449 --> 00:36:21,319
derived on demand and as soon as you

854
00:36:19,399 --> 00:36:23,779
don't need a key anymore it swipe from

855
00:36:21,319 --> 00:36:26,509
memory so you cannot find those keys in

856
00:36:23,779 --> 00:36:29,569
memory which means that you need to find

857
00:36:26,509 --> 00:36:31,809
that master key you need to find that

858
00:36:29,569 --> 00:36:35,449
and then you also need to know how

859
00:36:31,809 --> 00:36:37,759
exactly those keys are derived you need

860
00:36:35,449 --> 00:36:40,099
to know the exact details of that key

861
00:36:37,759 --> 00:36:43,039
derivation function that's the

862
00:36:40,099 --> 00:36:45,649
challenging part the good news is the

863
00:36:43,039 --> 00:36:48,499
second part and that's the authenticated

864
00:36:45,649 --> 00:36:51,799
encryption what that simply means is

865
00:36:48,499 --> 00:36:54,738
that for each encrypted credential there

866
00:36:51,799 --> 00:36:57,049
is also a message authentication code

867
00:36:54,739 --> 00:36:59,539
that comes with that credential and what

868
00:36:57,049 --> 00:37:02,179
that means is that if you try to decrypt

869
00:36:59,539 --> 00:37:04,729
something you always know whether the

870
00:37:02,179 --> 00:37:06,049
operation succeeded or failed you don't

871
00:37:04,729 --> 00:37:07,999
need to guess whether you have the right

872
00:37:06,049 --> 00:37:10,279
key you will always know whether the

873
00:37:07,999 --> 00:37:12,799
operation was a success or a failure and

874
00:37:10,279 --> 00:37:15,439
what that means is that if you're able

875
00:37:12,799 --> 00:37:17,959
to successfully decrypt the credential

876
00:37:15,439 --> 00:37:21,199
it means that you had the correct

877
00:37:17,959 --> 00:37:25,069
derived key which also implies that you

878
00:37:21,199 --> 00:37:27,199
must have had the correct master key so

879
00:37:25,069 --> 00:37:31,519
this is a nice way of checking whether

880
00:37:27,199 --> 00:37:34,219
you found the correct master key if you

881
00:37:31,519 --> 00:37:35,928
look at the output from mimikatz on a

882
00:37:34,219 --> 00:37:38,179
system that's running credential guard

883
00:37:35,929 --> 00:37:40,849
the line at the bottom there

884
00:37:38,179 --> 00:37:44,329
that's your encrypted credentials that's

885
00:37:40,849 --> 00:37:47,599
the cipher text the line above that what

886
00:37:44,329 --> 00:37:50,809
mimikar mimikatz called Anki I have no

887
00:37:47,599 --> 00:37:54,439
idea what that means in that field you

888
00:37:50,809 --> 00:37:57,409
have the message authentication code and

889
00:37:54,439 --> 00:38:01,519
also the needed input for the key

890
00:37:57,409 --> 00:38:04,479
derivation function so mimic ATS is able

891
00:38:01,519 --> 00:38:10,339
to give you all the needed input values

892
00:38:04,479 --> 00:38:13,729
except for that master key now the nice

893
00:38:10,339 --> 00:38:16,159
thing here is that the data in the

894
00:38:13,729 --> 00:38:18,799
secure world the amount of data is only

895
00:38:16,159 --> 00:38:21,230
around 50 megabytes so what you can do

896
00:38:18,799 --> 00:38:24,890
is to try a value from each

897
00:38:21,230 --> 00:38:28,100
Avery's offset you try that as the

898
00:38:24,890 --> 00:38:30,529
master key and at some point the

899
00:38:28,100 --> 00:38:33,859
decription will succeed and you know you

900
00:38:30,530 --> 00:38:37,040
have found the man the master key so

901
00:38:33,859 --> 00:38:40,040
here you have all the needed details of

902
00:38:37,040 --> 00:38:42,800
the creep though to decrypt those

903
00:38:40,040 --> 00:38:44,690
credentials and even though the black

904
00:38:42,800 --> 00:38:46,760
hat presentation by Intel researchers

905
00:38:44,690 --> 00:38:49,430
they mentioned the Windows crypto API

906
00:38:46,760 --> 00:38:51,320
sand they they talk about the creep

907
00:38:49,430 --> 00:38:53,930
though they don't give any code examples

908
00:38:51,320 --> 00:38:58,600
and they didn't share any tools so uh as

909
00:38:53,930 --> 00:39:01,549
far as I know here you have the first

910
00:38:58,600 --> 00:39:05,060
public implementation of decrypting

911
00:39:01,550 --> 00:39:07,190
credentials from credential guard you

912
00:39:05,060 --> 00:39:09,350
give it the output from mimikatz place

913
00:39:07,190 --> 00:39:11,660
it in the correct variables then you

914
00:39:09,350 --> 00:39:13,790
place your guess as of the master key in

915
00:39:11,660 --> 00:39:16,040
the boot key and then you just run this

916
00:39:13,790 --> 00:39:18,140
in a loop for all the values in the

917
00:39:16,040 --> 00:39:20,060
secure world and at some point you get a

918
00:39:18,140 --> 00:39:25,220
hit and you're able to decrypt the

919
00:39:20,060 --> 00:39:27,400
credentials but this is the easy part

920
00:39:25,220 --> 00:39:30,529
there's nothing nothing difficult here

921
00:39:27,400 --> 00:39:32,600
the challenge is getting access to the

922
00:39:30,530 --> 00:39:34,760
data that's part of the secure world

923
00:39:32,600 --> 00:39:36,950
because like you remember even if you

924
00:39:34,760 --> 00:39:39,020
have admin you're still inside your own

925
00:39:36,950 --> 00:39:42,589
little virtual machine so how do you get

926
00:39:39,020 --> 00:39:45,140
the data from the secure world the Intel

927
00:39:42,590 --> 00:39:47,990
researchers they exploited a firmer

928
00:39:45,140 --> 00:39:49,580
vulnerability and the thing is that we

929
00:39:47,990 --> 00:39:51,770
didn't really have any experience in

930
00:39:49,580 --> 00:39:55,720
exploiting Firma vulnerabilities but hey

931
00:39:51,770 --> 00:40:00,280
come on how hard can it be

932
00:39:55,720 --> 00:40:03,740
turns out pretty hard but we got lucky

933
00:40:00,280 --> 00:40:07,280
we find this found this noise firmware

934
00:40:03,740 --> 00:40:11,029
vulnerability from 2015 and here's the

935
00:40:07,280 --> 00:40:13,550
result this system is running credential

936
00:40:11,030 --> 00:40:16,820
guard you can see the encrypted

937
00:40:13,550 --> 00:40:20,690
credentials there then we run our tool

938
00:40:16,820 --> 00:40:22,609
and what it does first is it tries to

939
00:40:20,690 --> 00:40:23,990
access now remember this is running

940
00:40:22,609 --> 00:40:26,420
within that virtual machine in that

941
00:40:23,990 --> 00:40:29,839
normal world it tries to access each and

942
00:40:26,420 --> 00:40:32,570
every page of the physical memory if the

943
00:40:29,840 --> 00:40:35,090
access fails it probably means that that

944
00:40:32,570 --> 00:40:37,040
page is part of the secure world

945
00:40:35,090 --> 00:40:39,290
so it collects a list of these pages

946
00:40:37,040 --> 00:40:42,050
that cannot be accessed from the normal

947
00:40:39,290 --> 00:40:44,540
world once you have the list then we

948
00:40:42,050 --> 00:40:47,540
exploit that firm of our nobility that

949
00:40:44,540 --> 00:40:50,360
allows us to modify a script that is

950
00:40:47,540 --> 00:40:53,150
part of the firmware and that script is

951
00:40:50,360 --> 00:40:56,480
executed when the computer receives from

952
00:40:53,150 --> 00:40:59,810
slave so when the system receives from

953
00:40:56,480 --> 00:41:02,330
sleep our code gets executed it copies

954
00:40:59,810 --> 00:41:04,700
all the data from the secure world back

955
00:41:02,330 --> 00:41:07,730
to the normal world so we can access it

956
00:41:04,700 --> 00:41:09,529
normally and then it's only a matter of

957
00:41:07,730 --> 00:41:12,410
running that Python algorithm you saw

958
00:41:09,530 --> 00:41:15,980
earlier trying the key from every offset

959
00:41:12,410 --> 00:41:18,520
and at some point you get a hit and then

960
00:41:15,980 --> 00:41:29,170
you have the credentials from a system

961
00:41:18,520 --> 00:41:32,240
protected by credential guard thank you

962
00:41:29,170 --> 00:41:34,360
now the key thing here isn't the

963
00:41:32,240 --> 00:41:37,399
technical details of this particular

964
00:41:34,360 --> 00:41:40,780
firmware nobility the key thing is that

965
00:41:37,400 --> 00:41:45,680
if your firmware is not up-to-date

966
00:41:40,780 --> 00:41:47,480
credential card cannot help you in the

967
00:41:45,680 --> 00:41:51,560
beginning of the presentation we promise

968
00:41:47,480 --> 00:41:53,960
to deliver three key points our first

969
00:41:51,560 --> 00:41:57,529
key point is that we might be able to

970
00:41:53,960 --> 00:42:00,220
bypass a particular protection and go

971
00:41:57,530 --> 00:42:02,870
undetected at a specific point in time

972
00:42:00,220 --> 00:42:04,700
but attackers don't perform one action

973
00:42:02,870 --> 00:42:07,759
they perform many and they perform them

974
00:42:04,700 --> 00:42:10,240
all along this kill chain it's the

975
00:42:07,760 --> 00:42:13,100
combination of man and machine

976
00:42:10,240 --> 00:42:18,020
well-trained threat hunters with modern

977
00:42:13,100 --> 00:42:20,660
security software that's important what

978
00:42:18,020 --> 00:42:22,759
we actually found is that F secures EDR

979
00:42:20,660 --> 00:42:25,250
product did contain information that

980
00:42:22,760 --> 00:42:27,730
could be used to identify the presence

981
00:42:25,250 --> 00:42:30,140
and the operation of Fizz mints profit

982
00:42:27,730 --> 00:42:31,670
we've of course notified them and

983
00:42:30,140 --> 00:42:33,710
they've are the developers of the EDR

984
00:42:31,670 --> 00:42:35,450
products and they've been busy building

985
00:42:33,710 --> 00:42:37,730
detection ever since team I actually

986
00:42:35,450 --> 00:42:40,029
tested the tool yesterday I think in the

987
00:42:37,730 --> 00:42:42,680
in our test environment and it

988
00:42:40,030 --> 00:42:44,990
identified the tool which was great now

989
00:42:42,680 --> 00:42:46,569
we just need to figure out how to bypass

990
00:42:44,990 --> 00:42:49,459
that again

991
00:42:46,570 --> 00:42:51,890
our second key point is that attackers

992
00:42:49,460 --> 00:42:53,210
will always steal credentials whether

993
00:42:51,890 --> 00:42:54,950
that's through social engineering

994
00:42:53,210 --> 00:42:57,320
whether that's because they dumped them

995
00:42:54,950 --> 00:42:59,060
from a file server or whether perhaps

996
00:42:57,320 --> 00:43:01,190
they just found them on a file share

997
00:42:59,060 --> 00:43:03,470
it's the misuse of these credentials

998
00:43:01,190 --> 00:43:05,600
that's important if we have a file

999
00:43:03,470 --> 00:43:07,250
server admin who authenticates to a file

1000
00:43:05,600 --> 00:43:09,529
server to carry out their day-to-day

1001
00:43:07,250 --> 00:43:12,620
business activities and we have an email

1002
00:43:09,530 --> 00:43:14,170
server admin and he authenticates to an

1003
00:43:12,620 --> 00:43:16,730
email server to carry out their

1004
00:43:14,170 --> 00:43:19,070
day-to-day business activities if these

1005
00:43:16,730 --> 00:43:20,870
two users have no legitimate reasons to

1006
00:43:19,070 --> 00:43:23,120
cross paths and they never have done

1007
00:43:20,870 --> 00:43:25,220
before but all of a sudden the email

1008
00:43:23,120 --> 00:43:27,350
server admin authenticates to the file

1009
00:43:25,220 --> 00:43:28,879
server and starts a numerating the local

1010
00:43:27,350 --> 00:43:31,790
system that would be a fairly good

1011
00:43:28,880 --> 00:43:37,340
indication of something that should be

1012
00:43:31,790 --> 00:43:40,460
investigated a third key point as Timo

1013
00:43:37,340 --> 00:43:42,290
mentioned attacks and defenses are

1014
00:43:40,460 --> 00:43:45,320
moving lower and lower on the technology

1015
00:43:42,290 --> 00:43:47,600
stack initially we were stealing

1016
00:43:45,320 --> 00:43:49,690
credentials in virtual memory we then

1017
00:43:47,600 --> 00:43:53,450
stole credentials in physical memory

1018
00:43:49,690 --> 00:43:55,850
Microsoft went one layer down and built

1019
00:43:53,450 --> 00:43:58,160
credential guard to defend against this

1020
00:43:55,850 --> 00:43:59,990
and finally we went one layer further

1021
00:43:58,160 --> 00:44:02,990
and attack the firmware in order to

1022
00:43:59,990 --> 00:44:05,540
steal credentials credentials on the

1023
00:44:02,990 --> 00:44:07,580
only thing that Microsoft is trying

1024
00:44:05,540 --> 00:44:10,730
separate use is trying to protect with

1025
00:44:07,580 --> 00:44:12,770
virtualization sorry app the defender

1026
00:44:10,730 --> 00:44:15,560
application guard can now run Microsoft

1027
00:44:12,770 --> 00:44:17,390
edge in hyper-v enabled containers which

1028
00:44:15,560 --> 00:44:18,860
means that if you browsed to a malicious

1029
00:44:17,390 --> 00:44:21,830
website and it exploited your browser

1030
00:44:18,860 --> 00:44:22,580
and ran some ransomware for example then

1031
00:44:21,830 --> 00:44:24,319
the ransomware

1032
00:44:22,580 --> 00:44:27,560
would run within the container in your

1033
00:44:24,320 --> 00:44:30,020
files would not be encrypted but

1034
00:44:27,560 --> 00:44:33,259
Microsoft cannot do all the work for you

1035
00:44:30,020 --> 00:44:34,970
and if you want to coerce a attacker in

1036
00:44:33,260 --> 00:44:38,990
to write it to it using a vulnerability

1037
00:44:34,970 --> 00:44:41,750
worth 250,000 dollars then you need to

1038
00:44:38,990 --> 00:44:43,430
keep your firmware up-to-date we

1039
00:44:41,750 --> 00:44:45,290
recently ran this presentation at an

1040
00:44:43,430 --> 00:44:46,790
internal event in London and when we

1041
00:44:45,290 --> 00:44:48,170
asked the room how many people keep

1042
00:44:46,790 --> 00:44:50,570
their operating systems up-to-date

1043
00:44:48,170 --> 00:44:53,120
everyone raised their hand but when we

1044
00:44:50,570 --> 00:44:55,130
said how many of you update your

1045
00:44:53,120 --> 00:44:57,230
firmware as timely as you update your

1046
00:44:55,130 --> 00:44:59,870
operating system no one raised their

1047
00:44:57,230 --> 00:45:00,349
hand which is fairly telling so our call

1048
00:44:59,870 --> 00:45:02,890
to action

1049
00:45:00,349 --> 00:45:05,989
is this a deployed credential guard and

1050
00:45:02,890 --> 00:45:07,670
keep your firmware up-to-date and with

1051
00:45:05,989 --> 00:45:10,160
that we would like to say thank you to

1052
00:45:07,670 --> 00:45:11,340
disobey for having us and open the floor

1053
00:45:10,160 --> 00:45:20,239
for questions

1054
00:45:11,340 --> 00:45:20,239
[Applause]

