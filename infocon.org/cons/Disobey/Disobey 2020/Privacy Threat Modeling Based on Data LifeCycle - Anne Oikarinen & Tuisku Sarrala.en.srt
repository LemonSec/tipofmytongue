1
00:00:01,990 --> 00:00:23,729
[Music]

2
00:00:31,000 --> 00:00:34,840
[Music]

3
00:00:36,520 --> 00:00:43,040
good evening everybody my name is Onika

4
00:00:39,410 --> 00:00:44,959
Renan and I'm to Sarila and we're going

5
00:00:43,040 --> 00:00:47,809
to talk about privacy threat modeling

6
00:00:44,960 --> 00:00:49,610
how you can discover privacy problems

7
00:00:47,809 --> 00:00:52,989
from the data lifecycle of your

8
00:00:49,610 --> 00:00:56,300
applications the first of all who are we

9
00:00:52,989 --> 00:00:59,390
who are you - it's cool

10
00:00:56,300 --> 00:01:03,019
I'm a private consultant at NIC sue and

11
00:00:59,390 --> 00:01:05,349
I love extreme sports and getting into

12
00:01:03,019 --> 00:01:08,600
dangerous situations but I also love

13
00:01:05,349 --> 00:01:12,408
techie stuff and of course privacy

14
00:01:08,600 --> 00:01:15,229
problems and I'm a security consultant

15
00:01:12,409 --> 00:01:17,330
the Knicks ooh I really like threat

16
00:01:15,229 --> 00:01:19,340
modeling I've been doing this and that

17
00:01:17,330 --> 00:01:21,880
in cyber security but this is something

18
00:01:19,340 --> 00:01:24,260
that allows us to find weaknesses early

19
00:01:21,880 --> 00:01:26,869
I've been a computer geek

20
00:01:24,260 --> 00:01:29,150
since kid this is me and my first

21
00:01:26,869 --> 00:01:31,490
computer I'm like eight in that and

22
00:01:29,150 --> 00:01:33,619
that's a so-called portable computer

23
00:01:31,490 --> 00:01:40,280
because it weights nearly 10 kilos

24
00:01:33,619 --> 00:01:43,780
something really heavy so we are here to

25
00:01:40,280 --> 00:01:46,729
hear about privacy threat modeling but

26
00:01:43,780 --> 00:01:49,420
what if I first told you that there is

27
00:01:46,729 --> 00:01:53,240
actually no agreed definition about

28
00:01:49,420 --> 00:01:58,909
privacy you know we need to get a better

29
00:01:53,240 --> 00:02:01,999
idea of that before we we start it's not

30
00:01:58,909 --> 00:02:06,890
the GDP or that's about data protection

31
00:02:01,999 --> 00:02:09,710
and various laws they try to ensure

32
00:02:06,890 --> 00:02:12,470
privacy but you know the legal

33
00:02:09,710 --> 00:02:16,640
definitions and people's own definitions

34
00:02:12,470 --> 00:02:19,400
they do differ and it still differs

35
00:02:16,640 --> 00:02:26,799
massively across societies and cultures

36
00:02:19,400 --> 00:02:29,870
and across time you know what is privacy

37
00:02:26,800 --> 00:02:31,910
so I thought it would be a nice idea to

38
00:02:29,870 --> 00:02:39,100
look at you know how we've seen it

39
00:02:31,910 --> 00:02:42,019
through through time going back to the

40
00:02:39,100 --> 00:02:44,420
hunter-gatherers times people lived in

41
00:02:42,020 --> 00:02:47,900
huts and you know there were no secrets

42
00:02:44,420 --> 00:02:51,140
really you knew you know everything

43
00:02:47,900 --> 00:02:54,500
really people start living in houses

44
00:02:51,140 --> 00:02:57,890
that created some kind of a boundary you

45
00:02:54,500 --> 00:03:01,760
would have your own room that would mean

46
00:02:57,890 --> 00:03:04,250
this is my private space and then you'd

47
00:03:01,760 --> 00:03:07,340
have postal service people started

48
00:03:04,250 --> 00:03:13,580
thinking wait somebody else shouldn't

49
00:03:07,340 --> 00:03:21,590
read my letters so the idea of private

50
00:03:13,580 --> 00:03:26,000
correspondence came up in 1890 that's

51
00:03:21,590 --> 00:03:29,900
when say the first so proper definition

52
00:03:26,000 --> 00:03:34,250
came up Boren and brandi's rose law

53
00:03:29,900 --> 00:03:37,160
article in Harvard Law Review and they

54
00:03:34,250 --> 00:03:39,230
defined its privacy as the right to be

55
00:03:37,160 --> 00:03:41,260
let alone and that's

56
00:03:39,230 --> 00:03:44,720
mchip and I talked about you know how

57
00:03:41,260 --> 00:03:47,120
technology oil changes have you know

58
00:03:44,720 --> 00:03:49,250
brought all these challenges and this

59
00:03:47,120 --> 00:03:52,190
was kind of the same thing so around

60
00:03:49,250 --> 00:03:55,490
that time people could start taking

61
00:03:52,190 --> 00:03:57,130
pictures they could start recording boys

62
00:03:55,490 --> 00:03:59,960
and so on

63
00:03:57,130 --> 00:04:02,930
it was realized that you know they could

64
00:03:59,960 --> 00:04:04,340
make this public and then there was this

65
00:04:02,930 --> 00:04:06,950
concern that you know you shouldn't

66
00:04:04,340 --> 00:04:13,000
really publish stuff about private

67
00:04:06,950 --> 00:04:16,250
people going Second World War

68
00:04:13,000 --> 00:04:19,310
after that the idea of human rights came

69
00:04:16,250 --> 00:04:25,250
up and privacy was recognized as a human

70
00:04:19,310 --> 00:04:28,729
right then so people's private family

71
00:04:25,250 --> 00:04:34,940
home life or correspondence should not

72
00:04:28,729 --> 00:04:36,669
be interfered with okay um this was an

73
00:04:34,940 --> 00:04:41,090
interesting one

74
00:04:36,669 --> 00:04:45,200
Alan West in 1967 very influential piece

75
00:04:41,090 --> 00:04:52,150
Hiro's about privacy and freedom this

76
00:04:45,200 --> 00:04:55,400
piece and there he defined privacy as

77
00:04:52,150 --> 00:04:57,679
claim of individuals groups or

78
00:04:55,400 --> 00:04:59,239
institutions and that's quite

79
00:04:57,680 --> 00:05:04,370
interesting institutions could have

80
00:04:59,240 --> 00:05:06,980
privacy to to determine themselves what

81
00:05:04,370 --> 00:05:13,130
to what extent and whom information

82
00:05:06,980 --> 00:05:15,770
should be released to how information

83
00:05:13,130 --> 00:05:18,350
should be communicated to to others so

84
00:05:15,770 --> 00:05:25,479
it is something about self determined

85
00:05:18,350 --> 00:05:29,270
privacy then we'd have Cold War and

86
00:05:25,480 --> 00:05:33,290
stays would be the enemy to privacy bit

87
00:05:29,270 --> 00:05:37,250
different kind of idea we would have the

88
00:05:33,290 --> 00:05:42,440
first date production lore 1990

89
00:05:37,250 --> 00:05:46,100
that you dead Protection Directive going

90
00:05:42,440 --> 00:05:49,219
forward the gdpr era we would have a

91
00:05:46,100 --> 00:05:51,919
social media maybe companies would start

92
00:05:49,220 --> 00:05:56,540
becoming the enemy you know to to our

93
00:05:51,919 --> 00:05:58,010
privacy and what's happening now what's

94
00:05:56,540 --> 00:06:00,140
happening in the future

95
00:05:58,010 --> 00:06:01,820
if we look at the my data movement for

96
00:06:00,140 --> 00:06:03,710
example is quite interesting because it

97
00:06:01,820 --> 00:06:06,469
goes back to the Allen western-style

98
00:06:03,710 --> 00:06:10,039
idea of freedom where person should

99
00:06:06,470 --> 00:06:12,260
themselves determine you know what

100
00:06:10,040 --> 00:06:15,050
privacy means and they should be in

101
00:06:12,260 --> 00:06:18,530
control what is released and to to you

102
00:06:15,050 --> 00:06:24,530
and they should know what information

103
00:06:18,530 --> 00:06:27,530
goes out so before you start threat

104
00:06:24,530 --> 00:06:29,599
modeling you need to think about what is

105
00:06:27,530 --> 00:06:32,539
privacy to you what kind of privacy you

106
00:06:29,600 --> 00:06:35,780
want to implement in your system or

107
00:06:32,540 --> 00:06:40,880
target of the modeling so you probably

108
00:06:35,780 --> 00:06:45,799
need to do something about GDP or how

109
00:06:40,880 --> 00:06:49,700
well the companies of protects the data

110
00:06:45,800 --> 00:06:53,419
you might want to also do some kind of

111
00:06:49,700 --> 00:06:54,469
ideological self-determine style use the

112
00:06:53,419 --> 00:06:58,219
choice and control

113
00:06:54,470 --> 00:07:04,570
or you may want to ensure secrecy

114
00:06:58,220 --> 00:07:04,570
anonymity hiding of data Leave No Trace

115
00:07:07,150 --> 00:07:13,729
and because you probably have to duty

116
00:07:09,980 --> 00:07:16,070
DPR let's be clear about that and we

117
00:07:13,730 --> 00:07:19,010
often talk about GDP are as synonymous

118
00:07:16,070 --> 00:07:21,469
to privacy but actually the GDP or

119
00:07:19,010 --> 00:07:23,630
doesn't really mention the word privacy

120
00:07:21,470 --> 00:07:26,390
many times at all and it doesn't

121
00:07:23,630 --> 00:07:30,680
actually define it because as I said

122
00:07:26,390 --> 00:07:33,159
earlier GDP is about data protection it

123
00:07:30,680 --> 00:07:36,800
does recognize previous privacy as a

124
00:07:33,160 --> 00:07:40,040
fundamental right but then that is

125
00:07:36,800 --> 00:07:43,460
balanced against private interests

126
00:07:40,040 --> 00:07:45,410
business interest and so on it's about

127
00:07:43,460 --> 00:07:47,719
good management of people's information

128
00:07:45,410 --> 00:07:51,560
and making sure that the personal data

129
00:07:47,720 --> 00:07:54,650
use doesn't harm people and also making

130
00:07:51,560 --> 00:07:58,370
sure that you set your security to the

131
00:07:54,650 --> 00:07:59,960
level of the data sensitivity and the

132
00:07:58,370 --> 00:08:05,150
usage that you are going to use the data

133
00:07:59,960 --> 00:08:07,940
for then the other part of the puzzle

134
00:08:05,150 --> 00:08:10,609
what is threat modeling well the general

135
00:08:07,940 --> 00:08:13,760
idea is to think that what can go wrong

136
00:08:10,610 --> 00:08:16,400
and what's going to be do about it it's

137
00:08:13,760 --> 00:08:19,310
not being pessimistic to the maximum

138
00:08:16,400 --> 00:08:22,400
it's just systematically thinking that

139
00:08:19,310 --> 00:08:25,790
what are the possible negative scenarios

140
00:08:22,400 --> 00:08:27,919
and what's the impact check modeling

141
00:08:25,790 --> 00:08:30,919
techniques like stride focus on

142
00:08:27,919 --> 00:08:33,020
architecture and data flows in addition

143
00:08:30,919 --> 00:08:36,740
you should consider things like system

144
00:08:33,020 --> 00:08:41,329
features maintenance development and

145
00:08:36,740 --> 00:08:43,549
also privacy topic of today and when we

146
00:08:41,330 --> 00:08:47,510
put privacy and threat modeling together

147
00:08:43,549 --> 00:08:49,699
what do we get well first of all the

148
00:08:47,510 --> 00:08:52,720
general idea thinking what can go wrong

149
00:08:49,700 --> 00:08:57,230
in terms of privacy it's really good

150
00:08:52,720 --> 00:08:59,060
starting point we can think about system

151
00:08:57,230 --> 00:08:59,870
features maybe they are designed

152
00:08:59,060 --> 00:09:01,130
incorrectly

153
00:08:59,870 --> 00:09:04,400
maybe there's a flaw in the

154
00:09:01,130 --> 00:09:07,490
implementation what about architecture

155
00:09:04,400 --> 00:09:08,150
or the components that we use maybe they

156
00:09:07,490 --> 00:09:13,070
are

157
00:09:08,150 --> 00:09:16,339
vulnerabilities weaknesses again then

158
00:09:13,070 --> 00:09:19,220
there might be loopholes in the data

159
00:09:16,339 --> 00:09:24,650
lifecycle in the processes how we handle

160
00:09:19,220 --> 00:09:27,529
data and as to each per said it's good

161
00:09:24,650 --> 00:09:29,480
to understand at what can what is the

162
00:09:27,529 --> 00:09:31,880
privacy that you're aiming for

163
00:09:29,480 --> 00:09:34,460
are you building an application a

164
00:09:31,880 --> 00:09:37,070
messaging app for whistleblowers are you

165
00:09:34,460 --> 00:09:39,290
going for total anonymity are you

166
00:09:37,070 --> 00:09:41,779
handling health data or are you building

167
00:09:39,290 --> 00:09:46,279
an app for hair salon appointments

168
00:09:41,779 --> 00:09:48,380
different kind of privacy needed there

169
00:09:46,279 --> 00:09:51,529
are existing best modeling approaches

170
00:09:48,380 --> 00:09:55,100
there's Glyndon all the letters mean a

171
00:09:51,529 --> 00:09:58,220
specific privacy threat it's really

172
00:09:55,100 --> 00:10:00,040
useful to understand these concepts when

173
00:09:58,220 --> 00:10:04,520
it's linked ability a problem

174
00:10:00,040 --> 00:10:08,599
what does detectability mean and so on

175
00:10:04,520 --> 00:10:11,180
but linden the pure approach focuses and

176
00:10:08,600 --> 00:10:14,420
data flows and the anonymity of data

177
00:10:11,180 --> 00:10:18,079
flows well it's useful if you're going

178
00:10:14,420 --> 00:10:22,760
for the total and a limited minimization

179
00:10:18,080 --> 00:10:26,900
of everything but the problem is that it

180
00:10:22,760 --> 00:10:29,779
doesn't really give the idea of the data

181
00:10:26,900 --> 00:10:34,040
lifecycle it just gives you a snapshot

182
00:10:29,779 --> 00:10:37,700
of the system at one point in time then

183
00:10:34,040 --> 00:10:39,949
there's trim it's created by this cyber

184
00:10:37,700 --> 00:10:45,500
security company that you might have

185
00:10:39,950 --> 00:10:47,720
heard of as secure well trim has also

186
00:10:45,500 --> 00:10:49,570
very useful concepts to understand for

187
00:10:47,720 --> 00:10:53,630
threat modeling like minimization

188
00:10:49,570 --> 00:10:55,130
transferring of data and it's when you

189
00:10:53,630 --> 00:10:59,810
use it you need to understand the

190
00:10:55,130 --> 00:11:01,910
business use cases for privacy but what

191
00:10:59,810 --> 00:11:04,939
these models seem to lack is taking a

192
00:11:01,910 --> 00:11:08,420
look at the data lifecycle data always

193
00:11:04,940 --> 00:11:10,630
has a life cycle especially personal

194
00:11:08,420 --> 00:11:10,630
data

195
00:11:12,350 --> 00:11:18,529
so I'm a special quality about privacy

196
00:11:15,660 --> 00:11:22,709
threats is there is always a victim and

197
00:11:18,529 --> 00:11:24,420
the victim is not the company okay or at

198
00:11:22,709 --> 00:11:30,149
least it's not the useful focus to have

199
00:11:24,420 --> 00:11:31,949
the company ask the victim so the user

200
00:11:30,149 --> 00:11:34,170
is your primary asset and you know you

201
00:11:31,949 --> 00:11:36,839
need to protect them because they may be

202
00:11:34,170 --> 00:11:39,209
the victim of the privacy threat and

203
00:11:36,839 --> 00:11:42,240
this will help you to spot relevant

204
00:11:39,209 --> 00:11:43,920
threats and understand also how critical

205
00:11:42,240 --> 00:11:47,579
they are because you always related to

206
00:11:43,920 --> 00:11:49,860
the person and if you think about health

207
00:11:47,579 --> 00:11:53,239
and safety laws so it's quite similar to

208
00:11:49,860 --> 00:11:55,889
that so they require companies to

209
00:11:53,240 --> 00:11:59,509
protect people from getting injured or

210
00:11:55,889 --> 00:12:04,350
getting from dying you know even and

211
00:11:59,509 --> 00:12:07,619
similarly in privacy you try to protect

212
00:12:04,350 --> 00:12:11,269
the person from getting somehow harmed

213
00:12:07,619 --> 00:12:15,240
by the way you use their personal data

214
00:12:11,269 --> 00:12:18,480
so to the company the consequence is

215
00:12:15,240 --> 00:12:22,970
always sanctions or reputation or risk

216
00:12:18,480 --> 00:12:25,589
but let's leave that on the background

217
00:12:22,970 --> 00:12:29,059
another useful thing to think about is

218
00:12:25,589 --> 00:12:34,410
these threats are often accidental or

219
00:12:29,059 --> 00:12:36,240
unintentional so people may not think or

220
00:12:34,410 --> 00:12:40,980
understand you know how they're hunting

221
00:12:36,240 --> 00:12:43,049
the data and things such like poor

222
00:12:40,980 --> 00:12:47,220
management of people's information or

223
00:12:43,049 --> 00:12:50,850
use cases at home people or security

224
00:12:47,220 --> 00:12:52,079
it's not so set to the same level or the

225
00:12:50,850 --> 00:12:57,929
to the level it should be for the

226
00:12:52,079 --> 00:13:00,719
sensitivity of data to help you take

227
00:12:57,929 --> 00:13:03,439
into account all these bodies harm doers

228
00:13:00,720 --> 00:13:06,119
and people who make mistakes we have

229
00:13:03,439 --> 00:13:09,689
collected this users something called

230
00:13:06,119 --> 00:13:11,850
cyber bogeys cyber bogeys is term coming

231
00:13:09,689 --> 00:13:15,269
up by my colleague Darryl svenska he's

232
00:13:11,850 --> 00:13:17,519
an excellent threat model these

233
00:13:15,269 --> 00:13:20,730
characters are based on caricatures and

234
00:13:17,519 --> 00:13:22,470
stereotypes like in movies you might

235
00:13:20,730 --> 00:13:25,770
have the superhero and

236
00:13:22,470 --> 00:13:28,470
villain and in our office me might have

237
00:13:25,770 --> 00:13:30,630
someone who's really helpful and maybe

238
00:13:28,470 --> 00:13:33,840
likely to fall for social engineering

239
00:13:30,630 --> 00:13:36,900
scams this and we're gonna attack this

240
00:13:33,840 --> 00:13:40,580
character so long our presentation to

241
00:13:36,900 --> 00:13:44,280
remind you of the threats they bring and

242
00:13:40,580 --> 00:13:46,650
before we go to the data lifecycle we

243
00:13:44,280 --> 00:13:49,079
can represent this example system that

244
00:13:46,650 --> 00:13:50,640
we're going to use for highlighting and

245
00:13:49,080 --> 00:13:53,520
what kind of threats you can discover

246
00:13:50,640 --> 00:13:56,460
and how to how to make threat modeling

247
00:13:53,520 --> 00:13:59,220
privacy practical and this is a dog

248
00:13:56,460 --> 00:14:02,480
fitness tracker application there's a

249
00:13:59,220 --> 00:14:05,730
device that you put on your dog's collar

250
00:14:02,480 --> 00:14:08,520
it's a GPS on it it's collects the

251
00:14:05,730 --> 00:14:10,680
location of the dog all the time a SIM

252
00:14:08,520 --> 00:14:13,350
card sends the data to the cloud and the

253
00:14:10,680 --> 00:14:17,099
owner can check them location of the dog

254
00:14:13,350 --> 00:14:20,490
and activity on a mobile app real-time

255
00:14:17,100 --> 00:14:24,560
activity report workout reports

256
00:14:20,490 --> 00:14:28,920
nutrition tips there's a dating feature

257
00:14:24,560 --> 00:14:36,479
whoa how nice and you can find your pet

258
00:14:28,920 --> 00:14:39,569
all the time so um I'm never talking

259
00:14:36,480 --> 00:14:41,820
about the cyber bogeys so I'm gonna talk

260
00:14:39,570 --> 00:14:43,140
about different kind of characters again

261
00:14:41,820 --> 00:14:45,240
useful to think about them as characters

262
00:14:43,140 --> 00:14:48,569
and they are the users and as I said

263
00:14:45,240 --> 00:14:50,250
earlier they are primary asset so it's a

264
00:14:48,570 --> 00:14:52,590
really good idea to get to know your

265
00:14:50,250 --> 00:14:54,690
users think about who they might be

266
00:14:52,590 --> 00:14:56,970
because they different users attract

267
00:14:54,690 --> 00:14:58,680
different kind of risks you can see you

268
00:14:56,970 --> 00:15:03,390
know these sort of users there may be

269
00:14:58,680 --> 00:15:05,130
military personnel couples kids so on it

270
00:15:03,390 --> 00:15:09,960
does make a big difference it helps you

271
00:15:05,130 --> 00:15:13,560
to find the relevant threats and let's

272
00:15:09,960 --> 00:15:19,260
break it up so we're gonna start threat

273
00:15:13,560 --> 00:15:21,839
modeling this device so this is the

274
00:15:19,260 --> 00:15:26,760
target of the modeling the dog fitness

275
00:15:21,839 --> 00:15:29,070
tracker your primary asset is the user I

276
00:15:26,760 --> 00:15:30,140
see and you're trying to protect them

277
00:15:29,070 --> 00:15:33,600
okay

278
00:15:30,140 --> 00:15:36,120
the target of the attack is a personal

279
00:15:33,600 --> 00:15:39,880
data so how they might be harm

280
00:15:36,120 --> 00:15:42,370
attacks dude a personal data and the

281
00:15:39,880 --> 00:15:44,829
attacks may come you know via the device

282
00:15:42,370 --> 00:15:46,300
and he software around it any business

283
00:15:44,829 --> 00:15:48,670
processes around it because we're

284
00:15:46,300 --> 00:15:51,040
talking about data lifecycle so we need

285
00:15:48,670 --> 00:15:53,199
to think about those processes as well

286
00:15:51,040 --> 00:15:55,889
that are outside of this physical thing

287
00:15:53,199 --> 00:15:59,800
you know the business and the people

288
00:15:55,889 --> 00:16:02,910
people there so you need to understand

289
00:15:59,800 --> 00:16:09,130
all these aspects to do your threat

290
00:16:02,910 --> 00:16:12,250
modeling and to help you to get on the

291
00:16:09,130 --> 00:16:15,279
right track these are the sort of things

292
00:16:12,250 --> 00:16:18,430
that you need to watch out for how

293
00:16:15,279 --> 00:16:23,259
people might be harmed through an attack

294
00:16:18,430 --> 00:16:29,439
to their personal data privacy is there

295
00:16:23,259 --> 00:16:34,230
of course and few more concrete examples

296
00:16:29,440 --> 00:16:39,160
you know what to watch out for

297
00:16:34,230 --> 00:16:45,040
so with this thoughts let's go into the

298
00:16:39,160 --> 00:16:47,529
actual threat modeling cycle this is the

299
00:16:45,040 --> 00:16:51,750
life cycle we're talking about five

300
00:16:47,529 --> 00:16:56,110
phases collecting data storing data

301
00:16:51,750 --> 00:16:57,970
handling data then anonymizing our

302
00:16:56,110 --> 00:17:00,660
student I'm assigning data for sharing

303
00:16:57,970 --> 00:17:02,980
purposes and then finally removing data

304
00:17:00,660 --> 00:17:05,980
and logically wearing a stock with

305
00:17:02,980 --> 00:17:09,339
collecting data but you register for new

306
00:17:05,980 --> 00:17:12,309
application well you will fill in your

307
00:17:09,339 --> 00:17:16,510
name or email address typically may be a

308
00:17:12,309 --> 00:17:19,540
birthday gender location all kinds of

309
00:17:16,510 --> 00:17:23,049
things and what's not visible in the

310
00:17:19,540 --> 00:17:26,199
form well your IP address might get

311
00:17:23,049 --> 00:17:29,860
collected your operating system version

312
00:17:26,199 --> 00:17:33,040
name brussels browser settings brussels

313
00:17:29,860 --> 00:17:34,449
language all kinds of things i'm going

314
00:17:33,040 --> 00:17:38,530
to use the service it gets collected

315
00:17:34,450 --> 00:17:40,690
again with dog fitness tracker let's

316
00:17:38,530 --> 00:17:43,299
take a look at look about the gps data

317
00:17:40,690 --> 00:17:45,909
collection this is the what the design

318
00:17:43,299 --> 00:17:46,600
team thought it should work let's keep

319
00:17:45,909 --> 00:17:49,540
the

320
00:17:46,600 --> 00:17:52,899
GPS data collection always on so we get

321
00:17:49,540 --> 00:17:55,990
accurate activity statistics no problems

322
00:17:52,900 --> 00:18:01,240
in finding your dog if it gets lost all

323
00:17:55,990 --> 00:18:05,050
that hmm that's useful so um if I was

324
00:18:01,240 --> 00:18:06,580
the user this would track my dog all the

325
00:18:05,050 --> 00:18:12,460
time I want to be able to see where they

326
00:18:06,580 --> 00:18:14,230
are at any time yeah I could put it in

327
00:18:12,460 --> 00:18:19,120
my boyfriend's car and I could see where

328
00:18:14,230 --> 00:18:21,880
they where they go that's useful yeah I

329
00:18:19,120 --> 00:18:24,489
guess if we think about the evil cyber

330
00:18:21,880 --> 00:18:28,030
bogeys and a stalker could do the same I

331
00:18:24,490 --> 00:18:31,030
guess okay well why don't we put the

332
00:18:28,030 --> 00:18:34,149
button on the color so you can disable

333
00:18:31,030 --> 00:18:37,810
and enable that location tracking would

334
00:18:34,150 --> 00:18:40,690
that be better um yeah that is a good

335
00:18:37,810 --> 00:18:43,720
idea and actually that's goes with the

336
00:18:40,690 --> 00:18:45,850
privacy by design and privacy by default

337
00:18:43,720 --> 00:18:50,140
so you would make sure that all the

338
00:18:45,850 --> 00:18:52,449
features are turned off so that privacy

339
00:18:50,140 --> 00:18:55,450
doesn't get breached and users can make

340
00:18:52,450 --> 00:19:02,280
the choice to you know be tracked so not

341
00:18:55,450 --> 00:19:06,790
to be tracked okay let's do that so

342
00:19:02,280 --> 00:19:10,270
sorry to remind you about the users ya

343
00:19:06,790 --> 00:19:12,490
know it's it's a good idea to at every

344
00:19:10,270 --> 00:19:15,129
step just think about you know is this a

345
00:19:12,490 --> 00:19:20,110
opportunity orchid dis harm home that

346
00:19:15,130 --> 00:19:22,930
uses anyway there's loads of threads or

347
00:19:20,110 --> 00:19:26,679
cyber bogeys when you collect data first

348
00:19:22,930 --> 00:19:29,470
of all the data may may be wrong you you

349
00:19:26,680 --> 00:19:32,560
faked something or you make a typo and

350
00:19:29,470 --> 00:19:36,430
the email address is incorrect some

351
00:19:32,560 --> 00:19:40,750
extra data may be collected like images

352
00:19:36,430 --> 00:19:43,750
may contain the location tags or you're

353
00:19:40,750 --> 00:19:47,290
trans transmitted in securely something

354
00:19:43,750 --> 00:19:51,640
is chosen throwing in the URL and

355
00:19:47,290 --> 00:19:53,139
actually it's the legal side I mean you

356
00:19:51,640 --> 00:19:56,980
can collect some of the data for

357
00:19:53,140 --> 00:19:58,600
business purposes or vital interest and

358
00:19:56,980 --> 00:19:59,350
so sometimes you need to ask for

359
00:19:58,600 --> 00:20:02,709
concepts so

360
00:19:59,350 --> 00:20:03,879
how do you know mmm you should go back

361
00:20:02,710 --> 00:20:05,860
to thinking you know what sort of

362
00:20:03,880 --> 00:20:07,720
privacy or actually want you to

363
00:20:05,860 --> 00:20:10,780
implement if you wanting to implement

364
00:20:07,720 --> 00:20:12,910
the sort of user choice and control then

365
00:20:10,780 --> 00:20:14,200
of course you would ask users every time

366
00:20:12,910 --> 00:20:18,280
and make sure that they can change their

367
00:20:14,200 --> 00:20:20,620
mind any time but if you're doing

368
00:20:18,280 --> 00:20:24,070
something like GDP or soil you could

369
00:20:20,620 --> 00:20:25,689
rely on contracts or you know maybe

370
00:20:24,070 --> 00:20:28,210
legitimate business interests or

371
00:20:25,690 --> 00:20:37,710
something else to just collect the data

372
00:20:28,210 --> 00:20:40,840
so it depends and the next phase is

373
00:20:37,710 --> 00:20:45,520
storing data all the places where you

374
00:20:40,840 --> 00:20:49,120
keep it databases tiles logs temporary

375
00:20:45,520 --> 00:20:53,200
caches now you need to take a look at

376
00:20:49,120 --> 00:20:55,658
the architecture and with the dog

377
00:20:53,200 --> 00:21:01,000
fitness tracker well different kind of

378
00:20:55,659 --> 00:21:05,169
needs for storage and here access access

379
00:21:01,000 --> 00:21:08,320
to data storage goes hand-in-hand first

380
00:21:05,169 --> 00:21:11,200
of all someone for the QA might want to

381
00:21:08,320 --> 00:21:13,780
keep the production data and store it in

382
00:21:11,200 --> 00:21:18,730
the testing system as well to make

383
00:21:13,780 --> 00:21:21,668
better tests ok let's see maybe the

384
00:21:18,730 --> 00:21:24,390
testing environment is less secure if

385
00:21:21,669 --> 00:21:27,820
you add new features maybe they are

386
00:21:24,390 --> 00:21:29,620
containing bugs and then all these extra

387
00:21:27,820 --> 00:21:33,309
people may be rummaging around the

388
00:21:29,620 --> 00:21:36,219
system external consultants like us

389
00:21:33,309 --> 00:21:39,879
doing pen testing is it really necessary

390
00:21:36,220 --> 00:21:43,780
if they see all these names and in this

391
00:21:39,880 --> 00:21:46,120
case location of real people I don't

392
00:21:43,780 --> 00:21:47,950
think so I would go for generating the

393
00:21:46,120 --> 00:21:53,590
data from scratch or using pseudonym

394
00:21:47,950 --> 00:21:55,659
ization the new features well I was

395
00:21:53,590 --> 00:21:57,760
actually working in a project once where

396
00:21:55,659 --> 00:21:59,850
the project manager wanted to keep all

397
00:21:57,760 --> 00:22:03,010
the data forever

398
00:21:59,850 --> 00:22:06,399
just in case they think of a new feature

399
00:22:03,010 --> 00:22:08,559
that they can use it for and I think he

400
00:22:06,400 --> 00:22:10,530
was the only person in Europe who hadn't

401
00:22:08,559 --> 00:22:12,690
heard about gdpr

402
00:22:10,530 --> 00:22:15,639
unfortunately you cannot

403
00:22:12,690 --> 00:22:19,059
collect anything everything and store it

404
00:22:15,640 --> 00:22:25,090
forever unless you really have a purpose

405
00:22:19,059 --> 00:22:28,120
for it and then logs debugging useful

406
00:22:25,090 --> 00:22:30,730
actually also proving that you have done

407
00:22:28,120 --> 00:22:34,030
security and privacy right and if you

408
00:22:30,730 --> 00:22:39,130
log too much you end up having another

409
00:22:34,030 --> 00:22:40,750
personal data storage who needs to see

410
00:22:39,130 --> 00:22:43,360
that information again if you're

411
00:22:40,750 --> 00:22:46,059
debugging a problem in your code maybe

412
00:22:43,360 --> 00:22:50,790
you don't need to see that location info

413
00:22:46,059 --> 00:22:55,178
email addresses of real people and

414
00:22:50,790 --> 00:22:57,790
analytics power bi clicks ends do it in

415
00:22:55,179 --> 00:23:00,280
your Excel if you store something to

416
00:22:57,790 --> 00:23:04,809
your another computer it becomes a new

417
00:23:00,280 --> 00:23:06,730
storage is it secure enough and for

418
00:23:04,809 --> 00:23:13,420
statistical purposes I would go for

419
00:23:06,730 --> 00:23:16,450
another - data probably enough well

420
00:23:13,420 --> 00:23:19,210
again many things to think about threats

421
00:23:16,450 --> 00:23:21,520
in storing data first of all is the data

422
00:23:19,210 --> 00:23:24,910
confidential where do you actually keep

423
00:23:21,520 --> 00:23:29,170
it and all the places you keep it all

424
00:23:24,910 --> 00:23:33,550
the temporary wants logs then think

425
00:23:29,170 --> 00:23:35,980
about who can access the data and how

426
00:23:33,550 --> 00:23:39,159
they access it maybe there is something

427
00:23:35,980 --> 00:23:41,650
in the configuration it's a bit in

428
00:23:39,160 --> 00:23:44,559
securely configured you're using weak

429
00:23:41,650 --> 00:23:48,370
passwords maybe somebody can bypass the

430
00:23:44,559 --> 00:23:51,100
authentication and what you think about

431
00:23:48,370 --> 00:23:53,919
databases well might be tempting to use

432
00:23:51,100 --> 00:23:55,600
email addresses as unique identifiers

433
00:23:53,920 --> 00:23:59,350
because well hey they're unique per

434
00:23:55,600 --> 00:24:01,240
person but hey you can also identify the

435
00:23:59,350 --> 00:24:03,750
person from the email address really

436
00:24:01,240 --> 00:24:03,750
easily

437
00:24:05,600 --> 00:24:12,620
okay so you have collected all this data

438
00:24:09,130 --> 00:24:16,700
what next so the next step is handling

439
00:24:12,620 --> 00:24:18,919
it that's a core lifecycle step and here

440
00:24:16,700 --> 00:24:20,900
we want to focus what you do with all

441
00:24:18,920 --> 00:24:23,450
the data and you know are you handling

442
00:24:20,900 --> 00:24:28,670
it properly and what could happen to

443
00:24:23,450 --> 00:24:33,010
users through that again accidental and

444
00:24:28,670 --> 00:24:36,710
unintentional threats are very

445
00:24:33,010 --> 00:24:38,960
significant here so mmm a large number

446
00:24:36,710 --> 00:24:41,120
of data leaks can happen through like

447
00:24:38,960 --> 00:24:44,720
mishandling of people's information like

448
00:24:41,120 --> 00:24:47,209
last year a database of the personal

449
00:24:44,720 --> 00:24:50,660
records of almost anyone everyone in

450
00:24:47,210 --> 00:24:54,820
Ecuador was leaked because the sloppy

451
00:24:50,660 --> 00:25:01,880
miss configuration of elasticsearch and

452
00:24:54,820 --> 00:25:04,700
that was 16 and 1/2 million people and

453
00:25:01,880 --> 00:25:08,050
that's about three times the people in

454
00:25:04,700 --> 00:25:11,450
Finland that's pretty significant and

455
00:25:08,050 --> 00:25:13,550
two years ago in in the u.s. health

456
00:25:11,450 --> 00:25:16,190
records went missing because somebody

457
00:25:13,550 --> 00:25:18,409
left unencrypted left up in a car again

458
00:25:16,190 --> 00:25:25,220
you know these things can happen so

459
00:25:18,410 --> 00:25:27,940
easily just simple errors but then bad

460
00:25:25,220 --> 00:25:30,590
things can happen as well when

461
00:25:27,940 --> 00:25:35,720
businesses try to keep their products

462
00:25:30,590 --> 00:25:37,399
current and exciting and they come up

463
00:25:35,720 --> 00:25:39,530
with new uses with the day that they

464
00:25:37,400 --> 00:25:41,900
already have and of course they forget

465
00:25:39,530 --> 00:25:46,700
that it's not their days are it's the

466
00:25:41,900 --> 00:25:48,890
usage data hmm yeah so we have now

467
00:25:46,700 --> 00:25:51,170
collected all this data from different

468
00:25:48,890 --> 00:25:53,750
dogs you could have a new feature to

469
00:25:51,170 --> 00:25:56,030
match the lifestyles of these dogs like

470
00:25:53,750 --> 00:25:58,280
somebody who like CityWalk somebody who

471
00:25:56,030 --> 00:26:02,300
likes to play in the bark and the owner

472
00:25:58,280 --> 00:26:02,720
can have someone to talk to while taking

473
00:26:02,300 --> 00:26:06,710
up

474
00:26:02,720 --> 00:26:10,660
wagging the dog to the walk so so we got

475
00:26:06,710 --> 00:26:14,350
all this data feed it to the AI and then

476
00:26:10,660 --> 00:26:20,830
come up with some great stuff some

477
00:26:14,350 --> 00:26:25,520
matches maybe how dogs female lifestyles

478
00:26:20,830 --> 00:26:30,669
hmm yeah I think we have all the day

479
00:26:25,520 --> 00:26:35,660
that wakin we can try try it out sure

480
00:26:30,670 --> 00:26:37,630
okay so the AI department went and took

481
00:26:35,660 --> 00:26:42,410
all this data and came up with this nice

482
00:26:37,630 --> 00:26:45,230
Doc matching feature for that so what we

483
00:26:42,410 --> 00:26:47,300
can see here is looks like a pretty nice

484
00:26:45,230 --> 00:26:51,950
walk the doc went around the turn I love

485
00:26:47,300 --> 00:26:56,210
the area and seems to like nice long

486
00:26:51,950 --> 00:26:58,940
walks and probably pretty fit pretty fit

487
00:26:56,210 --> 00:27:01,670
doc or I'm actually looking at the owner

488
00:26:58,940 --> 00:27:05,420
here because every dog has as an owner

489
00:27:01,670 --> 00:27:08,900
and you know whose days is this at the

490
00:27:05,420 --> 00:27:12,760
end hmm hmm I wonder what else I can

491
00:27:08,900 --> 00:27:12,760
tell from this day sir

492
00:27:17,590 --> 00:27:22,090
so this is how the dis time did Tim did

493
00:27:20,510 --> 00:27:25,640
it

494
00:27:22,090 --> 00:27:28,070
well looks pretty nice doesn't it yeah

495
00:27:25,640 --> 00:27:31,730
it looks great it's like we have this

496
00:27:28,070 --> 00:27:34,840
new feature on the app where Bella has

497
00:27:31,730 --> 00:27:37,970
found a match with the little Bernie and

498
00:27:34,840 --> 00:27:40,669
they both like long walks they both like

499
00:27:37,970 --> 00:27:43,220
city works they both like evening works

500
00:27:40,670 --> 00:27:47,270
that sounds like a really nice match

501
00:27:43,220 --> 00:27:50,180
yeah although it says that they both go

502
00:27:47,270 --> 00:27:52,220
to this a a meeting really often it's

503
00:27:50,180 --> 00:27:56,680
not really something we need to show and

504
00:27:52,220 --> 00:28:01,960
know about all these details and roots

505
00:27:56,680 --> 00:28:01,960
that's pretty private I would say yeah

506
00:28:02,320 --> 00:28:11,330
so all sorts of threats can emerge from

507
00:28:07,580 --> 00:28:12,889
the handling of data you really need to

508
00:28:11,330 --> 00:28:15,669
think about you know do you actually

509
00:28:12,890 --> 00:28:19,100
need that amount of detail can you

510
00:28:15,670 --> 00:28:22,480
achieve the same result with bit less

511
00:28:19,100 --> 00:28:26,000
granularity or something more general

512
00:28:22,480 --> 00:28:29,540
and also as we just saw new use cases

513
00:28:26,000 --> 00:28:31,940
for for data they can be problematic

514
00:28:29,540 --> 00:28:35,840
you need to think about users did they

515
00:28:31,940 --> 00:28:40,240
give the data to you for that reason or

516
00:28:35,840 --> 00:28:43,090
what was the original reason for it and

517
00:28:40,240 --> 00:28:45,520
think about the cyber bogeys maybe

518
00:28:43,090 --> 00:28:50,149
malicious admin could turn their

519
00:28:45,520 --> 00:28:52,160
tracking on remotely and see where the

520
00:28:50,150 --> 00:28:54,350
dog is going and I think we need to

521
00:28:52,160 --> 00:28:56,600
remember that all kind of people owned

522
00:28:54,350 --> 00:29:00,050
dogs you know the president also has a

523
00:28:56,600 --> 00:29:02,600
dog and you know these people who are

524
00:29:00,050 --> 00:29:04,730
these malicious cyber bogeys you've got

525
00:29:02,600 --> 00:29:07,790
interesting these kind of people they

526
00:29:04,730 --> 00:29:12,950
would have the resources to you know to

527
00:29:07,790 --> 00:29:15,409
do that and how about if you build a

528
00:29:12,950 --> 00:29:20,390
website that showed some statistical

529
00:29:15,410 --> 00:29:24,350
data maybe about you know the dogs maybe

530
00:29:20,390 --> 00:29:28,100
by filtering by area by dog breed if you

531
00:29:24,350 --> 00:29:30,350
had a really special kind of breed there

532
00:29:28,100 --> 00:29:33,620
was only one in the area a stalker or

533
00:29:30,350 --> 00:29:35,030
Burke or I could actually find out when

534
00:29:33,620 --> 00:29:38,360
you're when you're in and when you're

535
00:29:35,030 --> 00:29:45,560
out and and yeah that would be pretty

536
00:29:38,360 --> 00:29:49,280
bad um so from those kind of thoughts we

537
00:29:45,560 --> 00:29:53,300
go into anonymization and pseudonymous

538
00:29:49,280 --> 00:29:55,399
ation so and these techniques you would

539
00:29:53,300 --> 00:29:58,879
use if you want to use the data without

540
00:29:55,400 --> 00:30:00,710
revealing who that area is about so like

541
00:29:58,880 --> 00:30:03,680
in this example when you want to put

542
00:30:00,710 --> 00:30:07,630
some dates on a website and maybe use it

543
00:30:03,680 --> 00:30:11,270
for some statistical purposes however

544
00:30:07,630 --> 00:30:14,570
you can easily create the privacy risk

545
00:30:11,270 --> 00:30:16,460
by using these techniques if you do not

546
00:30:14,570 --> 00:30:18,409
do you not know what you're doing if

547
00:30:16,460 --> 00:30:22,670
you're not do them don't do them

548
00:30:18,410 --> 00:30:25,550
properly and if we talk about an

549
00:30:22,670 --> 00:30:28,910
animation that's essentially a personal

550
00:30:25,550 --> 00:30:31,460
data removal technique because after

551
00:30:28,910 --> 00:30:33,440
that you can't reverse it you can't tell

552
00:30:31,460 --> 00:30:37,400
anymore who the who the data is about

553
00:30:33,440 --> 00:30:40,950
and pseudonym ization that is a security

554
00:30:37,400 --> 00:30:43,590
technique which means that you have

555
00:30:40,950 --> 00:30:53,130
Kian holidays are and you can still tell

556
00:30:43,590 --> 00:30:55,559
if you need to who the person is so here

557
00:30:53,130 --> 00:30:58,320
is the case let's say the company

558
00:30:55,559 --> 00:30:59,789
they've got all this data lots of very

559
00:30:58,320 --> 00:31:04,408
very good data they want to sell it

560
00:30:59,789 --> 00:31:06,750
that's pretty common use case and they

561
00:31:04,409 --> 00:31:08,519
think you know they're gonna remove all

562
00:31:06,750 --> 00:31:11,700
the identifying data so that you know

563
00:31:08,519 --> 00:31:14,360
it's anonymous and it's safe to sell so

564
00:31:11,700 --> 00:31:20,039
they are gonna go with removing the

565
00:31:14,360 --> 00:31:27,320
device ID name address email address

566
00:31:20,039 --> 00:31:32,149
phone number okay so but it's not enough

567
00:31:27,320 --> 00:31:35,340
well let's see news from January 2018

568
00:31:32,149 --> 00:31:39,268
the fitness app Strava was supposed to

569
00:31:35,340 --> 00:31:42,418
be anonymized but well there was a flaw

570
00:31:39,269 --> 00:31:44,970
in it and by calculating the midpoints

571
00:31:42,419 --> 00:31:46,350
from the starting point and the ending

572
00:31:44,970 --> 00:31:49,789
point of the workout you could

573
00:31:46,350 --> 00:31:54,240
practically deduce where somebody lives

574
00:31:49,789 --> 00:31:57,269
again in July 2018 another fitness app

575
00:31:54,240 --> 00:32:01,919
polar they have this feature where you

576
00:31:57,269 --> 00:32:04,769
can show your routes they were supposed

577
00:32:01,919 --> 00:32:07,200
to be even private and you can select if

578
00:32:04,769 --> 00:32:09,240
there are private or public but then you

579
00:32:07,200 --> 00:32:11,429
could actually browse to somebody's

580
00:32:09,240 --> 00:32:17,669
private workout routes if you just

581
00:32:11,429 --> 00:32:23,399
tamper the URL so it's not easy

582
00:32:17,669 --> 00:32:27,029
apparently so again we have some threats

583
00:32:23,399 --> 00:32:28,590
there you might have noticed that that I

584
00:32:27,029 --> 00:32:30,450
don't know my station pseudonym I say

585
00:32:28,590 --> 00:32:32,580
she's not really a life cycle step as

586
00:32:30,450 --> 00:32:34,649
such but you know because of the threats

587
00:32:32,580 --> 00:32:37,289
because how you use these techniques

588
00:32:34,649 --> 00:32:41,399
it's actually worth looking at it as a

589
00:32:37,289 --> 00:32:43,710
not a separate step it's not probably

590
00:32:41,399 --> 00:32:46,168
enough to just remove their identifying

591
00:32:43,710 --> 00:32:47,909
attributes you know not all may

592
00:32:46,169 --> 00:32:51,269
understand this so that may raise a

593
00:32:47,909 --> 00:32:53,820
threat or people don't simply recognize

594
00:32:51,269 --> 00:32:54,720
what's identifying information it might

595
00:32:53,820 --> 00:32:56,789
be that's

596
00:32:54,720 --> 00:32:59,549
the number of attributes is so large in

597
00:32:56,789 --> 00:33:02,158
the dataset that you can tell by just

598
00:32:59,549 --> 00:33:05,039
looking at them together you know who

599
00:33:02,159 --> 00:33:07,169
the person is or maybe the dataset is so

600
00:33:05,039 --> 00:33:12,269
small that you can by deduction tell

601
00:33:07,169 --> 00:33:14,759
tell who this about an employee you know

602
00:33:12,269 --> 00:33:17,879
social engineering which victim they

603
00:33:14,759 --> 00:33:22,049
could be tricked into sending some data

604
00:33:17,879 --> 00:33:22,918
sets out maybe is if it's been its

605
00:33:22,049 --> 00:33:26,129
dynamized

606
00:33:22,919 --> 00:33:26,970
it might be that both of em look totally

607
00:33:26,129 --> 00:33:29,719
safe

608
00:33:26,970 --> 00:33:32,249
do you not appear to have any

609
00:33:29,720 --> 00:33:37,879
identifying information but together

610
00:33:32,249 --> 00:33:37,879
actually they reveal people's identities

611
00:33:38,989 --> 00:33:45,749
so it's not easy and we want to think

612
00:33:44,249 --> 00:33:50,820
about you know we don't know what they

613
00:33:45,749 --> 00:33:53,340
see enough how can you get there and in

614
00:33:50,820 --> 00:33:55,849
some cases actually it may not be

615
00:33:53,340 --> 00:34:01,619
possible it's nearly impossible to

616
00:33:55,849 --> 00:34:03,599
anonymize days are completely but um

617
00:34:01,619 --> 00:34:06,359
there are some techniques for example

618
00:34:03,599 --> 00:34:09,328
Apple uses this differential privacy I

619
00:34:06,359 --> 00:34:12,179
would say go and search for it search

620
00:34:09,329 --> 00:34:15,359
for it and read a bit more it's uses

621
00:34:12,179 --> 00:34:18,059
some putting random noise in a current

622
00:34:15,359 --> 00:34:21,929
data and tries to anonymize it

623
00:34:18,059 --> 00:34:24,869
that's way or you could try analyzing

624
00:34:21,929 --> 00:34:27,119
the data at the user end so that when it

625
00:34:24,869 --> 00:34:29,250
leaves the user is already anonymized

626
00:34:27,119 --> 00:34:32,190
but then the company may not necessarily

627
00:34:29,250 --> 00:34:34,889
be able to use it for some calculations

628
00:34:32,190 --> 00:34:39,149
or something so there is a there is a

629
00:34:34,889 --> 00:34:43,020
trade-off but something to really keep

630
00:34:39,149 --> 00:34:45,839
in mind and look what's the right sort

631
00:34:43,020 --> 00:34:48,538
of level when you think about the users

632
00:34:45,839 --> 00:34:50,730
and the threats to the users so if it's

633
00:34:48,539 --> 00:34:52,889
military if it's some private

634
00:34:50,730 --> 00:34:58,319
individuals and so on it it does make a

635
00:34:52,889 --> 00:35:00,450
difference and the final phase is

636
00:34:58,319 --> 00:35:04,799
removing data or at least them

637
00:35:00,450 --> 00:35:06,069
identifiable parts of data let's see

638
00:35:04,799 --> 00:35:08,590
well

639
00:35:06,070 --> 00:35:11,790
expectations that when does the data

640
00:35:08,590 --> 00:35:14,260
actually gets removed Maeva rile up

641
00:35:11,790 --> 00:35:16,330
somebody might think that now that I

642
00:35:14,260 --> 00:35:17,440
have removed this app from my phone it's

643
00:35:16,330 --> 00:35:21,420
completely gone

644
00:35:17,440 --> 00:35:25,210
also from the cloud forever but actually

645
00:35:21,420 --> 00:35:28,120
why not if your users haven't been using

646
00:35:25,210 --> 00:35:30,460
it service for like a year maybe you can

647
00:35:28,120 --> 00:35:32,859
send them a weak email that are you

648
00:35:30,460 --> 00:35:39,280
gonna use this service again and if

649
00:35:32,860 --> 00:35:40,600
nobody replies just delete it but it

650
00:35:39,280 --> 00:35:42,520
would be really sad if I got a

651
00:35:40,600 --> 00:35:43,569
notification when my dog had already

652
00:35:42,520 --> 00:35:46,509
passed away

653
00:35:43,570 --> 00:35:48,460
that's true maybe I want to keep the

654
00:35:46,510 --> 00:35:53,620
data for sentimental reasons you know

655
00:35:48,460 --> 00:35:56,710
I'm how about then hmm anyway life

656
00:35:53,620 --> 00:35:58,900
happens maybe you broke up you don't

657
00:35:56,710 --> 00:36:01,840
want to see your exposés box and roots

658
00:35:58,900 --> 00:36:03,730
anymore or maybe you want to sell the

659
00:36:01,840 --> 00:36:06,430
device it's not really useful for a

660
00:36:03,730 --> 00:36:08,200
hamster maybe after all but you want to

661
00:36:06,430 --> 00:36:13,299
ensure that there's nothing in the

662
00:36:08,200 --> 00:36:15,819
device that will identify you and who

663
00:36:13,300 --> 00:36:18,640
knows you might have a internal threats

664
00:36:15,820 --> 00:36:20,350
cyber bogey that's a evil data scientist

665
00:36:18,640 --> 00:36:28,299
and just wants the hoarder information

666
00:36:20,350 --> 00:36:30,850
just keep it forever there are many

667
00:36:28,300 --> 00:36:33,520
threats in removing data many people

668
00:36:30,850 --> 00:36:37,390
actually affecting it and the security

669
00:36:33,520 --> 00:36:40,270
of it do you remove data automatically

670
00:36:37,390 --> 00:36:42,879
or manually if you do it manually maybe

671
00:36:40,270 --> 00:36:44,710
you forget a step sometimes you don't

672
00:36:42,880 --> 00:36:48,730
remove all the data and that's from

673
00:36:44,710 --> 00:36:51,640
every place or what if you restore

674
00:36:48,730 --> 00:36:55,290
backups you may need to remove the data

675
00:36:51,640 --> 00:36:58,420
again again and on from all the places I

676
00:36:55,290 --> 00:37:04,540
might be all sort of secondary storage

677
00:36:58,420 --> 00:37:05,310
is so difficult and many things to

678
00:37:04,540 --> 00:37:09,250
remember

679
00:37:05,310 --> 00:37:12,040
hmm and so if you think about data

680
00:37:09,250 --> 00:37:14,980
removal you may assume that Jesus mean

681
00:37:12,040 --> 00:37:17,529
like removing all today's at once but

682
00:37:14,980 --> 00:37:19,280
actually users may have different wishes

683
00:37:17,530 --> 00:37:20,930
and different requirements so

684
00:37:19,280 --> 00:37:23,420
how can you make sure that your system

685
00:37:20,930 --> 00:37:26,750
supports the idea of maybe removing only

686
00:37:23,420 --> 00:37:28,730
some data attributes and so on you know

687
00:37:26,750 --> 00:37:31,220
there might be legal reasons for keep

688
00:37:28,730 --> 00:37:33,730
some data for much longer than some

689
00:37:31,220 --> 00:37:36,980
other days and what does actually

690
00:37:33,730 --> 00:37:40,220
trigger that if it's set in 20 years

691
00:37:36,980 --> 00:37:42,590
ahead yeah you know I've always thought

692
00:37:40,220 --> 00:37:45,620
about yeah what if the don't day that's

693
00:37:42,590 --> 00:37:46,940
actually data of multiple people all the

694
00:37:45,620 --> 00:37:49,460
people who have worked with it

695
00:37:46,940 --> 00:37:52,880
can I reboot one person from the data

696
00:37:49,460 --> 00:37:55,310
set is it technically possible that's a

697
00:37:52,880 --> 00:37:57,260
good point because a piece of data can

698
00:37:55,310 --> 00:38:01,370
actually be one piece of data can be a

699
00:37:57,260 --> 00:38:03,590
data of two people so you can't actually

700
00:38:01,370 --> 00:38:05,980
then separate it so yeah yeah we don't

701
00:38:03,590 --> 00:38:09,320
remove the other person as well along

702
00:38:05,980 --> 00:38:11,630
and it's not always up to the company to

703
00:38:09,320 --> 00:38:14,240
decide you know what the data retention

704
00:38:11,630 --> 00:38:17,810
period should be because a person could

705
00:38:14,240 --> 00:38:20,870
ask you to actually retain it past the

706
00:38:17,810 --> 00:38:25,810
retention time and what do you do then

707
00:38:20,870 --> 00:38:25,810
can you make sure that you you keep it

708
00:38:27,340 --> 00:38:32,270
okay we've gone through the data

709
00:38:29,900 --> 00:38:40,130
lifecycle and we've got lots of threats

710
00:38:32,270 --> 00:38:42,410
now what do we do next if your system is

711
00:38:40,130 --> 00:38:44,600
not totally ready you might want to

712
00:38:42,410 --> 00:38:46,940
iterate a bit this threat modeling

713
00:38:44,600 --> 00:38:49,279
process first start with the overall

714
00:38:46,940 --> 00:38:51,470
idea of the system that is it gonna fly

715
00:38:49,280 --> 00:38:54,530
are people going to use it does it feel

716
00:38:51,470 --> 00:38:56,930
okay is it legal to collect and handle a

717
00:38:54,530 --> 00:39:00,200
data that way I think about the first

718
00:38:56,930 --> 00:39:02,120
features as well next time you do threat

719
00:39:00,200 --> 00:39:05,060
moving a thing about the first features

720
00:39:02,120 --> 00:39:07,910
a bit about the storage and handling and

721
00:39:05,060 --> 00:39:08,500
then go over to civilization if you need

722
00:39:07,910 --> 00:39:12,080
it

723
00:39:08,500 --> 00:39:14,030
removal of data and what's important to

724
00:39:12,080 --> 00:39:18,259
keep in mind that when you discover all

725
00:39:14,030 --> 00:39:20,300
these threats don't just forget them try

726
00:39:18,260 --> 00:39:22,580
to think what do you need to do do how

727
00:39:20,300 --> 00:39:25,400
can you mitigate the threat do you need

728
00:39:22,580 --> 00:39:28,160
to change the future somehow you need to

729
00:39:25,400 --> 00:39:31,400
add a security control and put all these

730
00:39:28,160 --> 00:39:34,229
mitigation is your backlog

731
00:39:31,400 --> 00:39:36,329
and when you're doing this brainstorming

732
00:39:34,229 --> 00:39:39,058
you might need some help

733
00:39:36,329 --> 00:39:43,319
think about the lending model all this

734
00:39:39,059 --> 00:39:45,929
link ability and detectability I think

735
00:39:43,319 --> 00:39:48,630
of how these threads will apply to your

736
00:39:45,929 --> 00:39:50,579
system and then you can use the cyber

737
00:39:48,630 --> 00:39:53,189
buggy cards we're actually going to

738
00:39:50,579 --> 00:39:55,259
release them pretty soon so check our

739
00:39:53,189 --> 00:39:57,109
next attacker team Twitter account we

740
00:39:55,259 --> 00:40:00,390
will tell you when they're ready and

741
00:39:57,109 --> 00:40:02,489
this the cards that were related to trim

742
00:40:00,390 --> 00:40:04,589
these elevation of privacy cards

743
00:40:02,489 --> 00:40:07,409
actually they have really useful

744
00:40:04,589 --> 00:40:09,179
examples concrete examples that that you

745
00:40:07,409 --> 00:40:13,199
can reflect or not how this would work

746
00:40:09,179 --> 00:40:18,179
on your system again and next thing to

747
00:40:13,199 --> 00:40:21,329
do is risk analysis okay so let's

748
00:40:18,179 --> 00:40:23,880
imagine we have some two dozen three

749
00:40:21,329 --> 00:40:26,759
dozen hundreds of threats gathered in

750
00:40:23,880 --> 00:40:28,979
that ball how do we actually know that

751
00:40:26,759 --> 00:40:30,929
they are relevant what do we do with

752
00:40:28,979 --> 00:40:34,799
them whether they're something to worry

753
00:40:30,929 --> 00:40:36,179
about or not we understand that people

754
00:40:34,799 --> 00:40:38,640
can be home but we are running a

755
00:40:36,179 --> 00:40:41,429
business so how to relate to that to the

756
00:40:38,640 --> 00:40:43,799
business as well we need to remember

757
00:40:41,429 --> 00:40:46,229
that threat modeling and risk assessment

758
00:40:43,799 --> 00:40:50,249
are two distinct processes in threes

759
00:40:46,229 --> 00:40:53,759
threat you uncover threats and risks you

760
00:40:50,249 --> 00:40:57,959
assess so you put them through that risk

761
00:40:53,759 --> 00:41:04,919
assessment mincer and outcomes your risk

762
00:40:57,959 --> 00:41:08,189
treatment decisions okay

763
00:41:04,919 --> 00:41:10,890
so you need to remember to evaluate them

764
00:41:08,189 --> 00:41:13,558
at the right level so let's think you've

765
00:41:10,890 --> 00:41:16,019
discovered some threats you've you know

766
00:41:13,559 --> 00:41:17,789
your system vulnerabilities you've

767
00:41:16,019 --> 00:41:20,279
understood the context and the nature of

768
00:41:17,789 --> 00:41:22,469
the day so you have you know your users

769
00:41:20,279 --> 00:41:24,839
that was important and the consequences

770
00:41:22,469 --> 00:41:29,249
you've kind of uncovered them together

771
00:41:24,839 --> 00:41:31,078
with the threats then if you can do

772
00:41:29,249 --> 00:41:34,259
something about them yeah go ahead and

773
00:41:31,079 --> 00:41:36,779
fix them yeah definitely but of course

774
00:41:34,259 --> 00:41:38,880
you can only do stuff with in your remus

775
00:41:36,779 --> 00:41:43,049
and within your resources you know the

776
00:41:38,880 --> 00:41:44,520
money and time you have and you might be

777
00:41:43,049 --> 00:41:50,520
left with stuff that's

778
00:41:44,520 --> 00:41:53,070
you cannot fix and these is best that

779
00:41:50,520 --> 00:41:55,290
you feed them in the proper risk

780
00:41:53,070 --> 00:41:57,960
assessment process of the company

781
00:41:55,290 --> 00:42:01,020
because they may be compliance threats

782
00:41:57,960 --> 00:42:03,360
and compliance threats they sit at the

783
00:42:01,020 --> 00:42:06,509
company level they are both level of

784
00:42:03,360 --> 00:42:07,740
risks because they can mean bad stuff to

785
00:42:06,510 --> 00:42:09,750
the company you know

786
00:42:07,740 --> 00:42:13,319
sanctions reputation risk compliance

787
00:42:09,750 --> 00:42:15,780
risk that developer cannot really carry

788
00:42:13,320 --> 00:42:18,270
and what the company does it then has to

789
00:42:15,780 --> 00:42:22,460
think about you know what its resources

790
00:42:18,270 --> 00:42:27,690
are and make a proper you know formal

791
00:42:22,460 --> 00:42:29,220
analysis of it and here is really

792
00:42:27,690 --> 00:42:31,710
important to remember that it's not

793
00:42:29,220 --> 00:42:34,109
really for the company to decide that

794
00:42:31,710 --> 00:42:36,330
you know what their risk appetite is

795
00:42:34,110 --> 00:42:39,810
with these kind of things as they might

796
00:42:36,330 --> 00:42:43,230
be able to do with financial risk they

797
00:42:39,810 --> 00:42:45,029
can't think you know let's let some okay

798
00:42:43,230 --> 00:42:48,210
let's make a risky financial decision

799
00:42:45,030 --> 00:42:50,550
you know that's that's fine but creating

800
00:42:48,210 --> 00:42:56,190
a system of product that's risky for

801
00:42:50,550 --> 00:42:58,100
people that's just not right and so the

802
00:42:56,190 --> 00:43:01,200
law is there to protect people from

803
00:42:58,100 --> 00:43:03,480
getting enjoy getting harmed and it says

804
00:43:01,200 --> 00:43:05,220
you know you need to be able to reduce

805
00:43:03,480 --> 00:43:09,450
the risk so that doesn't produce any

806
00:43:05,220 --> 00:43:12,180
significant risk to people so and if you

807
00:43:09,450 --> 00:43:18,000
don't do this process then you're

808
00:43:12,180 --> 00:43:19,470
breaking the law unfortunately probably

809
00:43:18,000 --> 00:43:22,170
the truth modeling actually makes your

810
00:43:19,470 --> 00:43:24,689
product better it's nicer for the

811
00:43:22,170 --> 00:43:27,270
end-users to use you have less

812
00:43:24,690 --> 00:43:31,080
weaknesses and as a bonus it can't be

813
00:43:27,270 --> 00:43:33,030
gdpr compliant as well it's vital to

814
00:43:31,080 --> 00:43:37,020
think about that what kind of privacy

815
00:43:33,030 --> 00:43:40,650
are you aiming for total anonymity my

816
00:43:37,020 --> 00:43:45,000
data my control compliance type of

817
00:43:40,650 --> 00:43:47,359
privacy or maybe all of them and it's

818
00:43:45,000 --> 00:43:51,570
important to take the user viewpoints

819
00:43:47,359 --> 00:43:55,470
users are important in privacy how are

820
00:43:51,570 --> 00:43:58,580
they going to use the system how could

821
00:43:55,470 --> 00:44:02,759
they misuse the system maybe

822
00:43:58,580 --> 00:44:06,779
and remember that your intention for

823
00:44:02,760 --> 00:44:08,130
privacy can actually go wrong if you

824
00:44:06,780 --> 00:44:10,160
don't think about the tress in the

825
00:44:08,130 --> 00:44:12,780
design or if you don't test your

826
00:44:10,160 --> 00:44:14,040
implementation you might actually end up

827
00:44:12,780 --> 00:44:15,720
harming privacy

828
00:44:14,040 --> 00:44:19,920
remember there's news about

829
00:44:15,720 --> 00:44:24,120
anonymization flaws maybe your data

830
00:44:19,920 --> 00:44:28,890
request feature actually allows to take

831
00:44:24,120 --> 00:44:30,859
a look at other people's data and take

832
00:44:28,890 --> 00:44:35,220
the full data lifecycle into account

833
00:44:30,860 --> 00:44:39,120
from the moment of collecting data in a

834
00:44:35,220 --> 00:44:41,290
moment of deleting it thank you for

835
00:44:39,120 --> 00:44:48,450
listening

836
00:44:41,290 --> 00:44:48,450
[Applause]

