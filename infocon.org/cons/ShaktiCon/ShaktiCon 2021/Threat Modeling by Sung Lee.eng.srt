1
00:00:00,240 --> 00:00:02,720
uh so for the next talk we have sangili

2
00:00:02,720 --> 00:00:04,720
as the speaker who is a staff security

3
00:00:04,720 --> 00:00:06,319
architect at vmware

4
00:00:06,319 --> 00:00:09,840
uh miss lee joined uh vmware in 2020 as

5
00:00:09,840 --> 00:00:11,200
a security architect

6
00:00:11,200 --> 00:00:13,200
she had developed interest in security

7
00:00:13,200 --> 00:00:15,679
in the early 2000s while she was

8
00:00:15,679 --> 00:00:17,520
leading a research team in the area of

9
00:00:17,520 --> 00:00:19,359
pervasive computing

10
00:00:19,359 --> 00:00:22,080
prior to joining vmware she served in

11
00:00:22,080 --> 00:00:23,119
various roles at

12
00:00:23,119 --> 00:00:24,880
several companies including product

13
00:00:24,880 --> 00:00:27,920
development r d standard development

14
00:00:27,920 --> 00:00:29,920
and defining product and business

15
00:00:29,920 --> 00:00:31,039
strategies

16
00:00:31,039 --> 00:00:34,000
uh she received her bas ms and phd

17
00:00:34,000 --> 00:00:35,760
degrees in comprehensive

18
00:00:35,760 --> 00:00:37,920
computer science from the university of

19
00:00:37,920 --> 00:00:40,000
maryland college park

20
00:00:40,000 --> 00:00:43,360
so during this talk ms lee will tell us

21
00:00:43,360 --> 00:00:46,079
how and why threat modeling is important

22
00:00:46,079 --> 00:00:48,320
what threat modeling is uh what it can

23
00:00:48,320 --> 00:00:50,079
prevent and what it cannot

24
00:00:50,079 --> 00:00:52,079
and how threat modeling fits into the

25
00:00:52,079 --> 00:00:54,000
overall product development life cycle

26
00:00:54,000 --> 00:00:56,079
and secure development life cycle

27
00:00:56,079 --> 00:00:58,239
so this talk will also introduce us to

28
00:00:58,239 --> 00:01:00,480
various threat modeling methodologies

29
00:01:00,480 --> 00:01:04,159
so over to you ms lee all right

30
00:01:04,159 --> 00:01:07,200
um good evening everyone

31
00:01:07,200 --> 00:01:10,159
i am totally impressed by the energy

32
00:01:10,159 --> 00:01:11,439
that's in this

33
00:01:11,439 --> 00:01:14,720
webinar i mean it's laid in your local

34
00:01:14,720 --> 00:01:15,520
time

35
00:01:15,520 --> 00:01:19,200
and 200 participants that's impressive

36
00:01:19,200 --> 00:01:22,640
and i hope that this session will be

37
00:01:22,640 --> 00:01:24,479
intellectually stimulating and

38
00:01:24,479 --> 00:01:26,640
interesting as well so that

39
00:01:26,640 --> 00:01:29,840
it's worthwhile to stay up um

40
00:01:29,840 --> 00:01:31,360
you know because i'm standing between

41
00:01:31,360 --> 00:01:33,280
you and your rest right

42
00:01:33,280 --> 00:01:36,079
uh and with that um i want to introduce

43
00:01:36,079 --> 00:01:36,640
myself

44
00:01:36,640 --> 00:01:39,920
as gita said i'm a security architect at

45
00:01:39,920 --> 00:01:40,880
vmware

46
00:01:40,880 --> 00:01:43,439
and today's session i want to introduce

47
00:01:43,439 --> 00:01:45,280
you to drug modeling

48
00:01:45,280 --> 00:01:47,759
if it is new to you and not just the

49
00:01:47,759 --> 00:01:48,720
definition

50
00:01:48,720 --> 00:01:52,079
of it but i want to give you some sample

51
00:01:52,079 --> 00:01:54,880
experience what it's like to perform

52
00:01:54,880 --> 00:01:56,320
threat modeling

53
00:01:56,320 --> 00:01:59,200
so that's my goal now before we get

54
00:01:59,200 --> 00:02:00,240
started

55
00:02:00,240 --> 00:02:02,880
um i want to set that expectation

56
00:02:02,880 --> 00:02:04,320
clearly

57
00:02:04,320 --> 00:02:06,719
after this session you will not come out

58
00:02:06,719 --> 00:02:08,318
as an expert

59
00:02:08,318 --> 00:02:11,038
but i want to give you plenty of

60
00:02:11,038 --> 00:02:12,480
foundation

61
00:02:12,480 --> 00:02:15,680
that will entice you to practice in your

62
00:02:15,680 --> 00:02:17,280
daily life

63
00:02:17,280 --> 00:02:20,560
and with that one more disclaimer

64
00:02:20,560 --> 00:02:24,560
i collected i my slides are mostly

65
00:02:24,560 --> 00:02:28,319
figures and i collected a lot of um

66
00:02:28,319 --> 00:02:31,680
pictures from the net and i tried to

67
00:02:31,680 --> 00:02:34,800
attribute to the original owners of it

68
00:02:34,800 --> 00:02:36,000
but if i missed it by

69
00:02:36,000 --> 00:02:38,640
accident please note that these are not

70
00:02:38,640 --> 00:02:42,319
my original work most of it

71
00:02:42,879 --> 00:02:45,599
now i would love to have an interactive

72
00:02:45,599 --> 00:02:46,720
session in this

73
00:02:46,720 --> 00:02:50,239
you know enthusiastic um audience

74
00:02:50,239 --> 00:02:52,879
here but because it's in the webinar

75
00:02:52,879 --> 00:02:53,440
format

76
00:02:53,440 --> 00:02:55,680
i want you to think as i call out

77
00:02:55,680 --> 00:02:57,040
different questions

78
00:02:57,040 --> 00:03:00,560
and see which one applies to you and um

79
00:03:00,560 --> 00:03:04,159
so let's let's do the first one have you

80
00:03:04,159 --> 00:03:07,920
heard of threat modeling

81
00:03:08,480 --> 00:03:11,120
i'm giving you a little bit of time just

82
00:03:11,120 --> 00:03:12,480
keep in mind

83
00:03:12,480 --> 00:03:16,238
have you done any threat modeling

84
00:03:17,360 --> 00:03:20,239
now last to some degree this is

85
00:03:20,239 --> 00:03:22,959
important to me

86
00:03:23,120 --> 00:03:27,360
do you think it's only a special

87
00:03:27,360 --> 00:03:31,200
exclusive club uh members of security

88
00:03:31,200 --> 00:03:32,640
experts who can do

89
00:03:32,640 --> 00:03:35,440
threat modeling

90
00:03:35,760 --> 00:03:38,640
now see which one applies to you

91
00:03:38,640 --> 00:03:39,519
especially

92
00:03:39,519 --> 00:03:43,120
in the last group i really want to

93
00:03:43,120 --> 00:03:46,959
convince you otherwise this is not

94
00:03:46,959 --> 00:03:49,519
someone who can do only by security

95
00:03:49,519 --> 00:03:50,400
expert

96
00:03:50,400 --> 00:03:52,720
i want to convince you that this is

97
00:03:52,720 --> 00:03:53,599
something that

98
00:03:53,599 --> 00:03:58,319
everybody can do all right

99
00:03:59,280 --> 00:04:01,840
before i go any further i want to bring

100
00:04:01,840 --> 00:04:02,799
you to

101
00:04:02,799 --> 00:04:05,280
uh to your attention to these three

102
00:04:05,280 --> 00:04:06,159
books

103
00:04:06,159 --> 00:04:09,439
that um i find them interesting and if

104
00:04:09,439 --> 00:04:10,000
you

105
00:04:10,000 --> 00:04:12,239
have additional interest in learning

106
00:04:12,239 --> 00:04:13,120
about it

107
00:04:13,120 --> 00:04:15,120
these three books will give you very

108
00:04:15,120 --> 00:04:17,358
strong foundation

109
00:04:17,358 --> 00:04:20,160
the uh on the far right drug modeling is

110
00:04:20,160 --> 00:04:20,798
a book

111
00:04:20,798 --> 00:04:23,919
by adam shostak he's a very well-known

112
00:04:23,919 --> 00:04:24,560
figure

113
00:04:24,560 --> 00:04:27,280
in this domain and his book will give

114
00:04:27,280 --> 00:04:28,080
you

115
00:04:28,080 --> 00:04:31,840
very solid foundation now the book

116
00:04:31,840 --> 00:04:35,040
in the middle securing systems is

117
00:04:35,040 --> 00:04:38,479
uh by brook seanfeld i was very

118
00:04:38,479 --> 00:04:42,400
fortunate enough to be trained by work

119
00:04:42,400 --> 00:04:45,440
and my the way i

120
00:04:45,440 --> 00:04:48,320
do my drug modeling was influenced quite

121
00:04:48,320 --> 00:04:49,440
by brooke

122
00:04:49,440 --> 00:04:53,759
and um so i naturally have um

123
00:04:53,759 --> 00:04:56,800
a lot of respect and

124
00:04:56,800 --> 00:05:00,800
he's just phenomenal so i recommend

125
00:05:00,800 --> 00:05:03,919
his book as well and most recently i

126
00:05:03,919 --> 00:05:04,800
read

127
00:05:04,800 --> 00:05:06,880
this thread modeling book on the left

128
00:05:06,880 --> 00:05:08,479
corner by

129
00:05:08,479 --> 00:05:11,680
izar turn duck and matic holes

130
00:05:11,680 --> 00:05:15,280
and um i especially included the

131
00:05:15,280 --> 00:05:16,479
examples

132
00:05:16,479 --> 00:05:19,120
toward the end as an exercise how you

133
00:05:19,120 --> 00:05:19,520
can

134
00:05:19,520 --> 00:05:22,639
try out the threat modeling well i did

135
00:05:22,639 --> 00:05:25,680
countless thread modeling in my career

136
00:05:25,680 --> 00:05:29,120
i um it's the outcome of threat modeling

137
00:05:29,120 --> 00:05:30,720
is considered

138
00:05:30,720 --> 00:05:35,120
confidential and it's very difficult to

139
00:05:35,120 --> 00:05:38,400
construct an example without revealing

140
00:05:38,400 --> 00:05:40,880
anything that's confidential right so i

141
00:05:40,880 --> 00:05:42,240
would have to put a lot of

142
00:05:42,240 --> 00:05:44,639
thought into it for me to construct one

143
00:05:44,639 --> 00:05:46,240
but since um

144
00:05:46,240 --> 00:05:48,800
uh the authors of this threat modeling

145
00:05:48,800 --> 00:05:49,360
book

146
00:05:49,360 --> 00:05:52,400
graciously put examples there

147
00:05:52,400 --> 00:05:54,400
i want to share that with you and then

148
00:05:54,400 --> 00:05:55,919
you can practice with me

149
00:05:55,919 --> 00:05:58,639
in this session

150
00:06:00,319 --> 00:06:02,639
now let's start with what is threat

151
00:06:02,639 --> 00:06:04,080
modeling

152
00:06:04,080 --> 00:06:07,440
i'm going to start with two formal

153
00:06:07,440 --> 00:06:10,319
somehow formal definition from um the

154
00:06:10,319 --> 00:06:12,400
authors of previous books that i just

155
00:06:12,400 --> 00:06:13,919
introduced you to

156
00:06:13,919 --> 00:06:16,880
and then i will add not quite definition

157
00:06:16,880 --> 00:06:18,400
but what i consider

158
00:06:18,400 --> 00:06:21,520
threat modeling characteristics what um

159
00:06:21,520 --> 00:06:24,960
this is my perspective so with that the

160
00:06:24,960 --> 00:06:25,600
first one

161
00:06:25,600 --> 00:06:29,280
is the definition by the um

162
00:06:29,280 --> 00:06:33,120
the left book the process of analyzing

163
00:06:33,120 --> 00:06:36,240
a system to look for weaknesses

164
00:06:36,240 --> 00:06:39,759
and that come from less desirable

165
00:06:39,759 --> 00:06:43,360
design choices i underlined

166
00:06:43,360 --> 00:06:46,400
design because

167
00:06:46,400 --> 00:06:49,039
it is a design you're looking at the

168
00:06:49,039 --> 00:06:49,919
design

169
00:06:49,919 --> 00:06:52,000
you're not looking at the implementation

170
00:06:52,000 --> 00:06:52,960
part of it

171
00:06:52,960 --> 00:06:55,520
and what is not said here in this

172
00:06:55,520 --> 00:06:57,680
definition is that you want to find

173
00:06:57,680 --> 00:06:58,160
these

174
00:06:58,160 --> 00:07:01,680
weaknesses at the design time

175
00:07:01,680 --> 00:07:05,120
not after uh implementation so just keep

176
00:07:05,120 --> 00:07:07,440
that in mind

177
00:07:07,440 --> 00:07:10,800
next definition is by brooke he defines

178
00:07:10,800 --> 00:07:13,680
a threat modeling as a technique to

179
00:07:13,680 --> 00:07:17,199
identify the attacks a system must

180
00:07:17,199 --> 00:07:20,319
withstand and the defenses that will

181
00:07:20,319 --> 00:07:21,680
bring the system

182
00:07:21,680 --> 00:07:25,599
to a state that is defensive

183
00:07:25,599 --> 00:07:29,280
a system can resist that right so here

184
00:07:29,280 --> 00:07:33,360
he uh puts an emphasis on defenses

185
00:07:33,360 --> 00:07:35,039
and if you think about a previous

186
00:07:35,039 --> 00:07:36,800
definition didn't talk about

187
00:07:36,800 --> 00:07:39,520
anything about defense and this you will

188
00:07:39,520 --> 00:07:40,080
learn

189
00:07:40,080 --> 00:07:42,560
this is referring to mitigations that

190
00:07:42,560 --> 00:07:43,599
you're going to put

191
00:07:43,599 --> 00:07:46,720
so it's not just finding where the

192
00:07:46,720 --> 00:07:47,840
weaknesses are

193
00:07:47,840 --> 00:07:51,199
but threat modeling is also giving

194
00:07:51,199 --> 00:07:54,400
mitigation on how to avoid it so that

195
00:07:54,400 --> 00:07:55,919
your system overall

196
00:07:55,919 --> 00:07:59,840
becomes secure

197
00:07:59,919 --> 00:08:04,240
now what is the most

198
00:08:04,240 --> 00:08:07,759
secure system that will be

199
00:08:07,759 --> 00:08:10,800
one that is turned off and not

200
00:08:10,800 --> 00:08:14,080
used at all but we all know that that

201
00:08:14,080 --> 00:08:17,840
has no value right and a lot of times

202
00:08:17,840 --> 00:08:18,319
when

203
00:08:18,319 --> 00:08:20,879
especially when i started out my career

204
00:08:20,879 --> 00:08:22,400
in security domain

205
00:08:22,400 --> 00:08:24,720
people hear security and they

206
00:08:24,720 --> 00:08:26,400
automatically think

207
00:08:26,400 --> 00:08:28,800
even now they roll their eyes like oh

208
00:08:28,800 --> 00:08:30,479
those security people

209
00:08:30,479 --> 00:08:33,120
they wouldn't let us do this and that

210
00:08:33,120 --> 00:08:33,519
and

211
00:08:33,519 --> 00:08:36,000
um so it's almost synonymous that

212
00:08:36,000 --> 00:08:37,279
security is a

213
00:08:37,279 --> 00:08:40,320
blocker right but i want to change that

214
00:08:40,320 --> 00:08:44,240
culture security is not a blocker

215
00:08:44,240 --> 00:08:47,760
it's an enabler if you have your

216
00:08:47,760 --> 00:08:51,360
system built securely you can open

217
00:08:51,360 --> 00:08:55,760
more applications you can have a better

218
00:08:55,760 --> 00:08:58,800
interaction with your users so

219
00:08:58,800 --> 00:09:01,839
i see security as an enabler

220
00:09:01,839 --> 00:09:04,959
now to add to create your

221
00:09:04,959 --> 00:09:08,240
secure system be a enabler

222
00:09:08,240 --> 00:09:11,360
you will need a whole a lot of

223
00:09:11,360 --> 00:09:14,560
tools to make it secure so

224
00:09:14,560 --> 00:09:17,920
thread modeling is just one

225
00:09:17,920 --> 00:09:21,279
of the many tools that you will need

226
00:09:21,279 --> 00:09:25,040
so this will help you create a built-in

227
00:09:25,040 --> 00:09:28,560
not bolt on security

228
00:09:28,560 --> 00:09:30,480
now one of the characteristics of drug

229
00:09:30,480 --> 00:09:32,000
modeling is

230
00:09:32,000 --> 00:09:35,360
it's highly interactive it's not a

231
00:09:35,360 --> 00:09:37,680
one-time activity that you can do and

232
00:09:37,680 --> 00:09:38,800
forget about

233
00:09:38,800 --> 00:09:41,120
if you think about it as you develop

234
00:09:41,120 --> 00:09:42,320
your system

235
00:09:42,320 --> 00:09:44,959
is your system static or is it

236
00:09:44,959 --> 00:09:47,279
constantly changing

237
00:09:47,279 --> 00:09:50,640
it's constantly changing i i hope and

238
00:09:50,640 --> 00:09:53,920
threat modeling needs to evolve with it

239
00:09:53,920 --> 00:09:58,800
so you will go through this many times

240
00:09:58,959 --> 00:10:02,560
now i call this a team sport it's not

241
00:10:02,560 --> 00:10:03,680
something that a

242
00:10:03,680 --> 00:10:06,320
special someone does and then everybody

243
00:10:06,320 --> 00:10:07,040
is just

244
00:10:07,040 --> 00:10:10,320
watching um be a spectator or just

245
00:10:10,320 --> 00:10:13,120
do nothing it's not that it's a team

246
00:10:13,120 --> 00:10:14,160
sport

247
00:10:14,160 --> 00:10:17,040
there are many many different parties

248
00:10:17,040 --> 00:10:17,760
involved

249
00:10:17,760 --> 00:10:21,120
in creating this and i'll tell you why

250
00:10:21,120 --> 00:10:24,079
in a typical product development

251
00:10:24,079 --> 00:10:25,200
scenarios

252
00:10:25,200 --> 00:10:27,360
there are many different roles involved

253
00:10:27,360 --> 00:10:28,800
there's a product owner

254
00:10:28,800 --> 00:10:32,560
or product um manager

255
00:10:32,560 --> 00:10:34,560
or product manager yes product manager

256
00:10:34,560 --> 00:10:35,920
or product owner

257
00:10:35,920 --> 00:10:39,440
they own the um requirements

258
00:10:39,440 --> 00:10:40,959
set of requirements that they're gonna

259
00:10:40,959 --> 00:10:42,480
drive and

260
00:10:42,480 --> 00:10:44,880
there's an architect who's gonna design

261
00:10:44,880 --> 00:10:46,000
the system

262
00:10:46,000 --> 00:10:48,880
obviously there are critical members of

263
00:10:48,880 --> 00:10:49,360
doing

264
00:10:49,360 --> 00:10:51,440
dot modeling and you will see that in a

265
00:10:51,440 --> 00:10:53,440
minute why that is the case

266
00:10:53,440 --> 00:10:56,399
and of course developers have hands in

267
00:10:56,399 --> 00:10:56,720
it

268
00:10:56,720 --> 00:10:59,040
in creating this so they're also very

269
00:10:59,040 --> 00:11:00,079
important

270
00:11:00,079 --> 00:11:03,360
testers absolutely if they're not

271
00:11:03,360 --> 00:11:06,160
involved they wouldn't know how what to

272
00:11:06,160 --> 00:11:06,959
test for it

273
00:11:06,959 --> 00:11:09,200
right um well if they are very

274
00:11:09,200 --> 00:11:10,160
experienced

275
00:11:10,160 --> 00:11:13,120
security testers they will know but it

276
00:11:13,120 --> 00:11:14,000
is always good

277
00:11:14,000 --> 00:11:17,120
to know and have a clear understanding

278
00:11:17,120 --> 00:11:20,079
among team members what are the common

279
00:11:20,079 --> 00:11:21,040
objective

280
00:11:21,040 --> 00:11:22,640
from the security that we're trying to

281
00:11:22,640 --> 00:11:25,360
reach and so all of these

282
00:11:25,360 --> 00:11:28,160
members are needed because they bring

283
00:11:28,160 --> 00:11:29,360
different perspective

284
00:11:29,360 --> 00:11:33,600
into it and the more people look at it

285
00:11:33,600 --> 00:11:36,720
and do this together you will have a

286
00:11:36,720 --> 00:11:37,200
better

287
00:11:37,200 --> 00:11:39,600
outcome

288
00:11:40,480 --> 00:11:43,760
now this point i want to emphasize that

289
00:11:43,760 --> 00:11:47,200
um threat modeling is something anybody

290
00:11:47,200 --> 00:11:50,800
can do it and i will go one step further

291
00:11:50,800 --> 00:11:53,920
that threat modeling should be done by

292
00:11:53,920 --> 00:11:57,200
everybody and you will

293
00:11:57,200 --> 00:12:01,760
see that software developers especially

294
00:12:01,760 --> 00:12:04,800
there are security engineers you may not

295
00:12:04,800 --> 00:12:05,839
define yourself

296
00:12:05,839 --> 00:12:08,720
as security person but if you think

297
00:12:08,720 --> 00:12:10,000
about it

298
00:12:10,000 --> 00:12:13,120
your system system that you have written

299
00:12:13,120 --> 00:12:16,399
is could be part of

300
00:12:16,399 --> 00:12:19,839
the um entry point for attackers

301
00:12:19,839 --> 00:12:22,720
or the weakest point for the attackers

302
00:12:22,720 --> 00:12:24,160
so that they can

303
00:12:24,160 --> 00:12:27,920
go around and even hack the entire

304
00:12:27,920 --> 00:12:28,720
system

305
00:12:28,720 --> 00:12:31,839
so all of you who are software

306
00:12:31,839 --> 00:12:33,680
developers and i would say you're

307
00:12:33,680 --> 00:12:35,120
security engineers

308
00:12:35,120 --> 00:12:38,240
and you really cannot afford to

309
00:12:38,240 --> 00:12:41,600
not to do this activity now what is this

310
00:12:41,600 --> 00:12:42,760
number

311
00:12:42,760 --> 00:12:45,920
159 to 1.

312
00:12:45,920 --> 00:12:49,760
this is a number the median

313
00:12:49,760 --> 00:12:53,040
ratio of developers to full-time

314
00:12:53,040 --> 00:12:55,440
software security team members

315
00:12:55,440 --> 00:12:58,480
think about it if you just rely

316
00:12:58,480 --> 00:13:01,600
on security expert to do

317
00:13:01,600 --> 00:13:05,200
the work then it is very likely

318
00:13:05,200 --> 00:13:08,880
that your weaknesses can leak

319
00:13:08,880 --> 00:13:12,720
into the product because it's possible

320
00:13:12,720 --> 00:13:15,200
that the security experts do not have

321
00:13:15,200 --> 00:13:16,880
time to tackle

322
00:13:16,880 --> 00:13:20,079
your particular part of the program or

323
00:13:20,079 --> 00:13:21,519
your particular product

324
00:13:21,519 --> 00:13:24,560
right and so this is

325
00:13:24,560 --> 00:13:27,760
another reason why as a developer or

326
00:13:27,760 --> 00:13:30,800
anybody who's involved in this team

327
00:13:30,800 --> 00:13:34,320
to look at it and conduct this

328
00:13:34,320 --> 00:13:37,519
threat modeling so

329
00:13:37,519 --> 00:13:39,680
at this moment i want to bring one

330
00:13:39,680 --> 00:13:40,560
example

331
00:13:40,560 --> 00:13:43,600
real world example i titled it

332
00:13:43,600 --> 00:13:46,800
haunted or not and

333
00:13:46,800 --> 00:13:50,880
you may recall in 2015 these two

334
00:13:50,880 --> 00:13:54,639
security um researchers they

335
00:13:54,639 --> 00:13:57,680
hacked into jeep chrysler

336
00:13:57,680 --> 00:14:00,560
jeep passenger vehicles so that they

337
00:14:00,560 --> 00:14:02,399
remotely controlled it

338
00:14:02,399 --> 00:14:05,839
they while wired reporter was

339
00:14:05,839 --> 00:14:08,560
driving the car these two researchers

340
00:14:08,560 --> 00:14:09,680
miles away

341
00:14:09,680 --> 00:14:13,680
controlled the car turning the wiper on

342
00:14:13,680 --> 00:14:16,320
turning on and off and you know blasting

343
00:14:16,320 --> 00:14:17,199
the radio

344
00:14:17,199 --> 00:14:21,040
sound raising up and down the uh windows

345
00:14:21,040 --> 00:14:24,639
giving the the driver the haunted

346
00:14:24,639 --> 00:14:28,240
part feeling right and eventually these

347
00:14:28,240 --> 00:14:30,399
guys demonstrated at

348
00:14:30,399 --> 00:14:34,240
a low speed taking over

349
00:14:34,240 --> 00:14:37,279
the control of the car so

350
00:14:37,279 --> 00:14:39,519
as you can see that the car is in a

351
00:14:39,519 --> 00:14:40,639
ditch

352
00:14:40,639 --> 00:14:44,639
now imagine that's you driving

353
00:14:44,639 --> 00:14:47,360
wouldn't that be scary anyway coming

354
00:14:47,360 --> 00:14:49,279
back to my point about threat modeling

355
00:14:49,279 --> 00:14:51,279
why am i talking about this

356
00:14:51,279 --> 00:14:54,720
this particular hack was possible

357
00:14:54,720 --> 00:14:57,680
because the entertainment system in the

358
00:14:57,680 --> 00:14:58,959
car

359
00:14:58,959 --> 00:15:02,720
had a external connection to

360
00:15:02,720 --> 00:15:06,000
like say verizon or something right

361
00:15:06,000 --> 00:15:08,880
so that the passengers could download

362
00:15:08,880 --> 00:15:11,120
for instance their choice of movies

363
00:15:11,120 --> 00:15:14,160
or programs meanwhile

364
00:15:14,160 --> 00:15:17,440
this entertainment system for unknown

365
00:15:17,440 --> 00:15:19,040
reason

366
00:15:19,040 --> 00:15:22,320
had also connectivity to

367
00:15:22,320 --> 00:15:26,800
the canvas which is the

368
00:15:26,800 --> 00:15:29,920
connection for controlling all the

369
00:15:29,920 --> 00:15:33,279
cars control so

370
00:15:33,279 --> 00:15:36,320
they shouldn't have that connectivity

371
00:15:36,320 --> 00:15:37,440
between them

372
00:15:37,440 --> 00:15:40,480
but they did and this is

373
00:15:40,480 --> 00:15:43,440
what these two researchers utilized to

374
00:15:43,440 --> 00:15:45,519
hack the system

375
00:15:45,519 --> 00:15:48,320
now if they had gone through proper

376
00:15:48,320 --> 00:15:49,920
threat modeling

377
00:15:49,920 --> 00:15:52,720
that would have been cut it would have

378
00:15:52,720 --> 00:15:54,399
been questioned

379
00:15:54,399 --> 00:15:57,440
why is this connection necessary there

380
00:15:57,440 --> 00:15:58,399
was no reason

381
00:15:58,399 --> 00:16:01,440
they should be connected but they did

382
00:16:01,440 --> 00:16:04,240
and probably it would have been cut off

383
00:16:04,240 --> 00:16:05,440
connect connection would have been

384
00:16:05,440 --> 00:16:06,480
disabled

385
00:16:06,480 --> 00:16:11,519
but it didn't and it was in the market

386
00:16:11,519 --> 00:16:14,639
now when a bug is

387
00:16:14,639 --> 00:16:17,120
found at the early stage of product

388
00:16:17,120 --> 00:16:18,639
development such as

389
00:16:18,639 --> 00:16:21,120
requirement gathering coding or

390
00:16:21,120 --> 00:16:22,880
integration and even

391
00:16:22,880 --> 00:16:27,040
testing the cost could be somewhat

392
00:16:27,040 --> 00:16:29,759
manageable but as you can tell that as

393
00:16:29,759 --> 00:16:31,759
you discover the bug toward the later

394
00:16:31,759 --> 00:16:33,759
stage of the product development

395
00:16:33,759 --> 00:16:35,440
it is actually it's a little difficult

396
00:16:35,440 --> 00:16:37,040
to see in the in this particular figure

397
00:16:37,040 --> 00:16:39,680
but it is growing exponentially

398
00:16:39,680 --> 00:16:42,959
now if the bug is found after

399
00:16:42,959 --> 00:16:45,360
the product is released then you can

400
00:16:45,360 --> 00:16:46,240
imagine that

401
00:16:46,240 --> 00:16:49,519
it's even higher to fix that bug

402
00:16:49,519 --> 00:16:53,040
and indeed that was the case for

403
00:16:53,040 --> 00:16:56,079
uh chrysler jim this resulted

404
00:16:56,079 --> 00:16:59,120
in massive 1.4

405
00:16:59,120 --> 00:17:02,000
million vehicle recall and it is

406
00:17:02,000 --> 00:17:03,199
estimated that

407
00:17:03,199 --> 00:17:07,280
it it cost about 10 million dollars

408
00:17:07,280 --> 00:17:10,559
to address this issue so that

409
00:17:10,559 --> 00:17:13,679
particular simple design flaw

410
00:17:13,679 --> 00:17:17,039
led to 10 million dollars

411
00:17:17,039 --> 00:17:20,079
worth of fixes so

412
00:17:20,079 --> 00:17:23,039
just remember that

413
00:17:23,679 --> 00:17:27,119
now i want to make sure that

414
00:17:27,119 --> 00:17:28,880
you don't get the impression that drug

415
00:17:28,880 --> 00:17:30,559
modeling is panacea

416
00:17:30,559 --> 00:17:35,280
it is not um and i'm gonna talk about it

417
00:17:35,280 --> 00:17:37,280
so it will not solve all of your

418
00:17:37,280 --> 00:17:38,640
security issues

419
00:17:38,640 --> 00:17:41,280
remember the first formal definition

420
00:17:41,280 --> 00:17:42,240
that i brought

421
00:17:42,240 --> 00:17:44,720
which is finding weaknesses in the

422
00:17:44,720 --> 00:17:45,440
design

423
00:17:45,440 --> 00:17:49,120
at design time so naturally

424
00:17:49,120 --> 00:17:51,600
threat modeling will not be able to

425
00:17:51,600 --> 00:17:52,799
catch

426
00:17:52,799 --> 00:17:55,840
implementation errors and here is one

427
00:17:55,840 --> 00:17:57,200
example

428
00:17:57,200 --> 00:18:01,360
anybody we call heartbleed heartbleed

429
00:18:01,360 --> 00:18:05,679
is a weakness in

430
00:18:05,679 --> 00:18:08,480
secure connection tls implementation

431
00:18:08,480 --> 00:18:09,360
open ssl

432
00:18:09,360 --> 00:18:12,480
implementation and in particular

433
00:18:12,480 --> 00:18:16,240
there was a um the memory

434
00:18:16,240 --> 00:18:19,280
length checking that was missing and

435
00:18:19,280 --> 00:18:19,679
which

436
00:18:19,679 --> 00:18:22,640
was which could have well which was um

437
00:18:22,640 --> 00:18:23,039
uh

438
00:18:23,039 --> 00:18:26,840
utilized to to extract any information

439
00:18:26,840 --> 00:18:29,360
including critical information such as

440
00:18:29,360 --> 00:18:31,360
username and password

441
00:18:31,360 --> 00:18:34,799
and um there's a really good cartoon

442
00:18:34,799 --> 00:18:36,799
that explains how it is done

443
00:18:36,799 --> 00:18:39,679
but ultimately what happened is that

444
00:18:39,679 --> 00:18:41,919
there's a heartbeat

445
00:18:41,919 --> 00:18:45,360
between server and client that's sent

446
00:18:45,360 --> 00:18:47,120
to make sure that the connection is

447
00:18:47,120 --> 00:18:48,640
still active right

448
00:18:48,640 --> 00:18:51,600
and then um a client can send to the

449
00:18:51,600 --> 00:18:52,320
server

450
00:18:52,320 --> 00:18:54,080
and say hey i'm going to send you a

451
00:18:54,080 --> 00:18:57,039
heartbeat of x number of characters

452
00:18:57,039 --> 00:19:00,320
but what happens is that and and then um

453
00:19:00,320 --> 00:19:02,080
at the time the server is supposed to

454
00:19:02,080 --> 00:19:04,640
send back that many characters back to

455
00:19:04,640 --> 00:19:06,480
the client to indicate that they're

456
00:19:06,480 --> 00:19:07,679
still alive

457
00:19:07,679 --> 00:19:10,559
now on the server end it was not

458
00:19:10,559 --> 00:19:11,280
checking

459
00:19:11,280 --> 00:19:14,799
whether actually clients sent that many

460
00:19:14,799 --> 00:19:18,160
um bytes of information and

461
00:19:18,160 --> 00:19:19,919
so what happened was that anything that

462
00:19:19,919 --> 00:19:21,919
was in memory

463
00:19:21,919 --> 00:19:24,799
here the client could send a less number

464
00:19:24,799 --> 00:19:25,440
of bytes

465
00:19:25,440 --> 00:19:27,840
over to the server but the server

466
00:19:27,840 --> 00:19:28,799
without checking

467
00:19:28,799 --> 00:19:31,440
how many actual bytes came from the

468
00:19:31,440 --> 00:19:32,240
client

469
00:19:32,240 --> 00:19:36,080
can just respond with whatever client

470
00:19:36,080 --> 00:19:38,160
has sent so there's a cartoon that you

471
00:19:38,160 --> 00:19:40,480
can search google and it'll explain very

472
00:19:40,480 --> 00:19:41,039
well

473
00:19:41,039 --> 00:19:44,799
nevertheless this is an implementation

474
00:19:44,799 --> 00:19:47,840
error no amount of threat modeling

475
00:19:47,840 --> 00:19:51,200
could have cut this error

476
00:19:51,200 --> 00:19:54,400
now with that um i want to move on to

477
00:19:54,400 --> 00:19:58,000
threat model process this is a very

478
00:19:58,000 --> 00:20:01,120
typical threat modeling process and you

479
00:20:01,120 --> 00:20:01,679
will see

480
00:20:01,679 --> 00:20:04,000
on the left side what is called the

481
00:20:04,000 --> 00:20:05,440
system model

482
00:20:05,440 --> 00:20:09,120
and you move from system model to

483
00:20:09,120 --> 00:20:12,080
identify asset and then identify threats

484
00:20:12,080 --> 00:20:13,600
and attack surfaces

485
00:20:13,600 --> 00:20:16,240
provide mitigations and i'm going to

486
00:20:16,240 --> 00:20:16,799
talk about

487
00:20:16,799 --> 00:20:19,039
security requirements so what this

488
00:20:19,039 --> 00:20:20,080
security requirement

489
00:20:20,080 --> 00:20:23,280
is about is that you want to have

490
00:20:23,280 --> 00:20:25,600
your product after doing all the threat

491
00:20:25,600 --> 00:20:26,480
analysis

492
00:20:26,480 --> 00:20:29,200
and which ones that you want to mitigate

493
00:20:29,200 --> 00:20:29,840
um and

494
00:20:29,840 --> 00:20:31,360
and i'll i'll be honest with you there

495
00:20:31,360 --> 00:20:33,200
are sometimes

496
00:20:33,200 --> 00:20:36,640
threats that you identify but the

497
00:20:36,640 --> 00:20:40,320
uh the cost of fixing that could be very

498
00:20:40,320 --> 00:20:40,960
high

499
00:20:40,960 --> 00:20:44,400
and the chance of this being taken

500
00:20:44,400 --> 00:20:47,280
could be very minimum and you have

501
00:20:47,280 --> 00:20:48,000
product

502
00:20:48,000 --> 00:20:50,960
development schedule that is very tight

503
00:20:50,960 --> 00:20:53,280
then you may have to prioritize it

504
00:20:53,280 --> 00:20:56,400
so for this round of product release you

505
00:20:56,400 --> 00:20:56,960
may

506
00:20:56,960 --> 00:21:00,320
def de-prioritize that particular

507
00:21:00,320 --> 00:21:03,600
mitigate the attack and mitigation

508
00:21:03,600 --> 00:21:06,000
implementation and so that's gonna

509
00:21:06,000 --> 00:21:08,080
impact the security requirement

510
00:21:08,080 --> 00:21:11,600
and so this is a typical process

511
00:21:11,600 --> 00:21:14,400
now system model and all of these you

512
00:21:14,400 --> 00:21:15,280
kind of go through

513
00:21:15,280 --> 00:21:18,400
iteratively and revisit and until you

514
00:21:18,400 --> 00:21:19,919
come to the point where

515
00:21:19,919 --> 00:21:22,320
you feel pretty confident that you have

516
00:21:22,320 --> 00:21:23,440
found everything

517
00:21:23,440 --> 00:21:24,960
and we're going to talk about when to

518
00:21:24,960 --> 00:21:26,720
stop later on

519
00:21:26,720 --> 00:21:29,120
but in this typical threat modeling

520
00:21:29,120 --> 00:21:30,799
process

521
00:21:30,799 --> 00:21:34,640
i find that the most time that most of

522
00:21:34,640 --> 00:21:36,159
the security it's not just i

523
00:21:36,159 --> 00:21:38,880
actually most of the security architects

524
00:21:38,880 --> 00:21:40,559
where they spend most of the time

525
00:21:40,559 --> 00:21:43,840
is representing the system

526
00:21:43,840 --> 00:21:46,640
in the system model so what what is

527
00:21:46,640 --> 00:21:47,440
system model

528
00:21:47,440 --> 00:21:51,120
system model is how do you represent

529
00:21:51,120 --> 00:21:54,640
your uh product or the system that

530
00:21:54,640 --> 00:21:55,679
you're building

531
00:21:55,679 --> 00:21:58,799
into something that um shows

532
00:21:58,799 --> 00:22:01,039
how they interact with each other so

533
00:22:01,039 --> 00:22:02,400
it's all

534
00:22:02,400 --> 00:22:04,720
it's like a diagram system interaction

535
00:22:04,720 --> 00:22:06,080
diagram where

536
00:22:06,080 --> 00:22:09,120
you will see an example later on but um

537
00:22:09,120 --> 00:22:11,360
it shows how they interact where the

538
00:22:11,360 --> 00:22:13,039
security boundaries are

539
00:22:13,039 --> 00:22:15,440
what are the data that's being kept

540
00:22:15,440 --> 00:22:16,080
where

541
00:22:16,080 --> 00:22:18,880
how it's moved around all of those will

542
00:22:18,880 --> 00:22:19,840
be represented

543
00:22:19,840 --> 00:22:23,200
in this system model now

544
00:22:23,200 --> 00:22:26,159
i'm going to talk about drug modeling

545
00:22:26,159 --> 00:22:26,880
soft

546
00:22:26,880 --> 00:22:28,960
secure development life cycle product

547
00:22:28,960 --> 00:22:31,039
development life cycle it's a

548
00:22:31,039 --> 00:22:35,039
acronym superior but the very top line

549
00:22:35,039 --> 00:22:36,080
the blue boxes

550
00:22:36,080 --> 00:22:38,000
are typical product development

551
00:22:38,000 --> 00:22:39,200
lifecycle

552
00:22:39,200 --> 00:22:42,240
the requirements designs development

553
00:22:42,240 --> 00:22:42,960
testing

554
00:22:42,960 --> 00:22:46,080
and release right and the boxes

555
00:22:46,080 --> 00:22:46,799
underneath

556
00:22:46,799 --> 00:22:49,039
are activities that are sort of mapped

557
00:22:49,039 --> 00:22:51,280
into these

558
00:22:51,280 --> 00:22:53,760
secure development lifecycle activities

559
00:22:53,760 --> 00:22:55,600
that map and i try to map them

560
00:22:55,600 --> 00:22:58,159
into the product development life cycle

561
00:22:58,159 --> 00:22:58,720
so

562
00:22:58,720 --> 00:23:01,200
at the early stage you try to assess

563
00:23:01,200 --> 00:23:02,480
what are the risks

564
00:23:02,480 --> 00:23:05,280
uh security privacy risks and then

565
00:23:05,280 --> 00:23:06,559
during the design

566
00:23:06,559 --> 00:23:09,120
phase you do threat modeling and

567
00:23:09,120 --> 00:23:10,080
development

568
00:23:10,080 --> 00:23:12,480
and testing phase is where you do code

569
00:23:12,480 --> 00:23:14,080
review static analysis

570
00:23:14,080 --> 00:23:16,400
dynamic code analysis buzzing and all of

571
00:23:16,400 --> 00:23:18,320
those

572
00:23:18,320 --> 00:23:21,440
these are not comprehensive list of

573
00:23:21,440 --> 00:23:22,000
activities

574
00:23:22,000 --> 00:23:24,000
but i try to kind of represent what are

575
00:23:24,000 --> 00:23:26,480
the things that you would commonly do

576
00:23:26,480 --> 00:23:28,799
and um before you release you do pen

577
00:23:28,799 --> 00:23:31,120
testing you do final reviews and

578
00:23:31,120 --> 00:23:34,320
you um have a plan on how you

579
00:23:34,320 --> 00:23:36,320
address vulnerability and stuff like

580
00:23:36,320 --> 00:23:38,799
that so this is the typical process

581
00:23:38,799 --> 00:23:41,520
and where the threat modeling fits into

582
00:23:41,520 --> 00:23:42,080
it

583
00:23:42,080 --> 00:23:45,520
so dry modeling goes around the design

584
00:23:45,520 --> 00:23:46,400
time

585
00:23:46,400 --> 00:23:50,320
now you may be asking okay who develops

586
00:23:50,320 --> 00:23:52,960
water bowl model anymore this is very

587
00:23:52,960 --> 00:23:54,000
like a linear

588
00:23:54,000 --> 00:23:56,480
from requirements all the way to the um

589
00:23:56,480 --> 00:23:57,679
product release

590
00:23:57,679 --> 00:24:00,720
and actually it doesn't have to be

591
00:24:00,720 --> 00:24:03,200
that way and and i kind of represented

592
00:24:03,200 --> 00:24:05,120
in this circular motion

593
00:24:05,120 --> 00:24:09,200
and um i introduced another term called

594
00:24:09,200 --> 00:24:12,480
use scenarios so before you do

595
00:24:12,480 --> 00:24:15,760
system models i tend to

596
00:24:15,760 --> 00:24:18,960
gather use scenarios and

597
00:24:18,960 --> 00:24:21,840
i find my brain works to be the best to

598
00:24:21,840 --> 00:24:22,960
start from there

599
00:24:22,960 --> 00:24:25,600
then i can construct the system models

600
00:24:25,600 --> 00:24:26,640
and then i can

601
00:24:26,640 --> 00:24:29,520
you know go identify assets and threats

602
00:24:29,520 --> 00:24:29,840
and

603
00:24:29,840 --> 00:24:32,080
attack services and mitigations this is

604
00:24:32,080 --> 00:24:33,679
how my brain works

605
00:24:33,679 --> 00:24:36,720
i have worked with other people who just

606
00:24:36,720 --> 00:24:37,360
hears

607
00:24:37,360 --> 00:24:39,679
about what the product does and started

608
00:24:39,679 --> 00:24:40,640
to

609
00:24:40,640 --> 00:24:43,840
just list all the assets or threats so

610
00:24:43,840 --> 00:24:45,919
some people's brain work differently

611
00:24:45,919 --> 00:24:46,960
there's no

612
00:24:46,960 --> 00:24:50,559
right or wrong way to start

613
00:24:50,559 --> 00:24:54,240
which of these part of the circles but

614
00:24:54,240 --> 00:24:57,440
what i want to put emphasis on is that

615
00:24:57,440 --> 00:24:59,760
regardless of where you start you want

616
00:24:59,760 --> 00:25:00,960
to make sure that you

617
00:25:00,960 --> 00:25:04,159
go to all of them

618
00:25:04,159 --> 00:25:07,919
now coming back to agile methodology

619
00:25:07,919 --> 00:25:10,720
how does that modeling fit with the

620
00:25:10,720 --> 00:25:12,000
agile

621
00:25:12,000 --> 00:25:14,880
methodology it things are changing so

622
00:25:14,880 --> 00:25:15,600
fast

623
00:25:15,600 --> 00:25:18,880
i mean you know where does it fit right

624
00:25:18,880 --> 00:25:21,919
and you can thread model every

625
00:25:21,919 --> 00:25:25,200
story and in my experience remember that

626
00:25:25,200 --> 00:25:26,080
use story

627
00:25:26,080 --> 00:25:28,400
i mean you can replace it with the story

628
00:25:28,400 --> 00:25:30,159
and use scenarios with the

629
00:25:30,159 --> 00:25:33,279
uh story in my experience i've worked

630
00:25:33,279 --> 00:25:35,200
with many teams who

631
00:25:35,200 --> 00:25:38,640
uh use as our development and it's

632
00:25:38,640 --> 00:25:40,960
the very first one may take a little bit

633
00:25:40,960 --> 00:25:42,000
but i find

634
00:25:42,000 --> 00:25:45,120
it actually very easy to do this very

635
00:25:45,120 --> 00:25:46,080
quickly

636
00:25:46,080 --> 00:25:49,760
every spring cycle and it worked out

637
00:25:49,760 --> 00:25:53,120
very well all right

638
00:25:53,120 --> 00:25:56,480
at this point you may be asking

639
00:25:56,480 --> 00:25:59,279
is there any modeling methodology if you

640
00:25:59,279 --> 00:26:00,640
are not familiar with

641
00:26:00,640 --> 00:26:03,200
and you will discover there are many and

642
00:26:03,200 --> 00:26:04,720
then you may be asking

643
00:26:04,720 --> 00:26:07,360
okay which one to use of all of these

644
00:26:07,360 --> 00:26:08,480
many things

645
00:26:08,480 --> 00:26:11,840
right so um i give you

646
00:26:11,840 --> 00:26:15,360
a few names here on the slide deck

647
00:26:15,360 --> 00:26:18,559
you can see i mean these just a few of

648
00:26:18,559 --> 00:26:19,120
them

649
00:26:19,120 --> 00:26:23,439
right so how do you select which one

650
00:26:23,520 --> 00:26:26,400
remember adam shostak the author of the

651
00:26:26,400 --> 00:26:28,159
book on the right hand side

652
00:26:28,159 --> 00:26:31,200
he said that a good threat model

653
00:26:31,200 --> 00:26:34,720
is one that produces valid finding

654
00:26:34,720 --> 00:26:38,400
that's what's important and i will go

655
00:26:38,400 --> 00:26:41,520
one step further and i will say

656
00:26:41,520 --> 00:26:44,880
that the good threat model is the one

657
00:26:44,880 --> 00:26:45,760
that you can find

658
00:26:45,760 --> 00:26:50,400
valid findings and you can use

659
00:26:50,400 --> 00:26:54,960
some of these um different methodologies

660
00:26:54,960 --> 00:26:58,320
i encourage you to read about and try it

661
00:26:58,320 --> 00:26:59,039
out

662
00:26:59,039 --> 00:27:02,080
and you will find some of them is

663
00:27:02,080 --> 00:27:06,799
too cumbersome and it's taking too long

664
00:27:06,799 --> 00:27:09,360
you may not want to use it and then i

665
00:27:09,360 --> 00:27:12,000
would say that's not a good one for you

666
00:27:12,000 --> 00:27:14,919
i'll find something and i i don't

667
00:27:14,919 --> 00:27:17,039
particularly follow

668
00:27:17,039 --> 00:27:19,919
one methodology over the years i kind of

669
00:27:19,919 --> 00:27:20,640
developed

670
00:27:20,640 --> 00:27:23,440
what worked for me and i suspect that

671
00:27:23,440 --> 00:27:25,200
you will also find that

672
00:27:25,200 --> 00:27:27,760
but highly encourage you to try a few of

673
00:27:27,760 --> 00:27:30,240
them out

674
00:27:30,880 --> 00:27:35,840
but if you ever want to

675
00:27:35,919 --> 00:27:37,840
consider a little bit more formally

676
00:27:37,840 --> 00:27:39,360
which one to choose

677
00:27:39,360 --> 00:27:42,960
then i recommend you watch this um

678
00:27:42,960 --> 00:27:44,880
talk it's on youtube and i believe that

679
00:27:44,880 --> 00:27:46,159
i've

680
00:27:46,159 --> 00:27:48,799
embedded a link to it so you can go

681
00:27:48,799 --> 00:27:49,520
directly

682
00:27:49,520 --> 00:27:51,919
but otherwise you can go to youtube or

683
00:27:51,919 --> 00:27:52,799
abstract call

684
00:27:52,799 --> 00:27:56,080
kali 2019 and you will see this one

685
00:27:56,080 --> 00:27:58,880
and um this is the author of the book on

686
00:27:58,880 --> 00:28:00,240
the left hand side

687
00:28:00,240 --> 00:28:02,720
and um he the threat bottle book that i

688
00:28:02,720 --> 00:28:04,799
recently uh went through

689
00:28:04,799 --> 00:28:08,559
and the the way he selected

690
00:28:08,559 --> 00:28:10,799
the threat model or he he provided a

691
00:28:10,799 --> 00:28:13,120
little bit more formal way to select a

692
00:28:13,120 --> 00:28:15,760
truck methodology dramatic methodology

693
00:28:15,760 --> 00:28:17,120
that you could use

694
00:28:17,120 --> 00:28:20,000
and he considered these seven attributes

695
00:28:20,000 --> 00:28:22,080
that's listed on this page

696
00:28:22,080 --> 00:28:25,200
and i kind of screen captured a few

697
00:28:25,200 --> 00:28:27,840
shots from his talk to give you the

698
00:28:27,840 --> 00:28:28,480
flavor

699
00:28:28,480 --> 00:28:31,760
of how he's doing it so for

700
00:28:31,760 --> 00:28:35,039
uh several of us

701
00:28:35,039 --> 00:28:38,960
considering he you will see these

702
00:28:38,960 --> 00:28:41,919
the outer edges there are the attributes

703
00:28:41,919 --> 00:28:45,120
in the previous page and

704
00:28:45,120 --> 00:28:48,240
he kind of evaluated in this page

705
00:28:48,240 --> 00:28:52,320
it's stride okay stride is very

706
00:28:52,320 --> 00:28:54,480
unconstrained and it's not really good

707
00:28:54,480 --> 00:28:55,679
for agile

708
00:28:55,679 --> 00:28:57,679
it's pretty useful and all of those

709
00:28:57,679 --> 00:28:59,440
right of course these are

710
00:28:59,440 --> 00:29:02,480
his opinion in his opinion

711
00:29:02,480 --> 00:29:05,840
that's what he um evaluated and then he

712
00:29:05,840 --> 00:29:08,399
evaluated stride element compared to

713
00:29:08,399 --> 00:29:09,039
stride

714
00:29:09,039 --> 00:29:12,799
how it fits into that structure

715
00:29:12,799 --> 00:29:15,440
and also he did threat library and then

716
00:29:15,440 --> 00:29:16,640
also this is a

717
00:29:16,640 --> 00:29:20,880
basically expert led threat analysis

718
00:29:20,880 --> 00:29:23,360
so i watch it it's a pretty interesting

719
00:29:23,360 --> 00:29:24,080
one

720
00:29:24,080 --> 00:29:26,320
but at the end of the day i will

721
00:29:26,320 --> 00:29:27,360
emphasize

722
00:29:27,360 --> 00:29:30,559
try a few and find the one that works

723
00:29:30,559 --> 00:29:32,080
with you

724
00:29:32,080 --> 00:29:35,440
now here i'm calling out couple of

725
00:29:35,440 --> 00:29:39,200
methodology for um a reason first one is

726
00:29:39,200 --> 00:29:43,440
lyndon linden is privacy focused

727
00:29:43,440 --> 00:29:45,840
so if you're in a market domain where

728
00:29:45,840 --> 00:29:48,159
privacy is really important

729
00:29:48,159 --> 00:29:50,799
i think it might be interesting to check

730
00:29:50,799 --> 00:29:51,840
this particular

731
00:29:51,840 --> 00:29:54,320
methodology out in in addition to other

732
00:29:54,320 --> 00:29:56,480
ones that you will

733
00:29:56,480 --> 00:29:59,760
the second one is includes no dirt and

734
00:29:59,760 --> 00:30:00,960
it's actually in

735
00:30:00,960 --> 00:30:03,679
acronym you can see in the second bullet

736
00:30:03,679 --> 00:30:05,039
point there

737
00:30:05,039 --> 00:30:08,240
this particular one is focusing on

738
00:30:08,240 --> 00:30:09,200
privacy

739
00:30:09,200 --> 00:30:12,480
and compliance in particular clinical

740
00:30:12,480 --> 00:30:13,440
environment

741
00:30:13,440 --> 00:30:16,480
so if you're in a marketplace of

742
00:30:16,480 --> 00:30:20,159
let's say medical devices

743
00:30:20,159 --> 00:30:22,480
this might be interesting one to check

744
00:30:22,480 --> 00:30:25,120
out so

745
00:30:25,520 --> 00:30:28,880
now if you have done

746
00:30:28,880 --> 00:30:31,520
that modeling you may say oh this takes

747
00:30:31,520 --> 00:30:33,039
such a long time

748
00:30:33,039 --> 00:30:36,240
it's just very intense effort yes it is

749
00:30:36,240 --> 00:30:37,760
it's a very brain draining

750
00:30:37,760 --> 00:30:40,880
effort can we automate it in this

751
00:30:40,880 --> 00:30:44,799
automating everything kind of era

752
00:30:44,799 --> 00:30:47,679
well um lucky for us there is some

753
00:30:47,679 --> 00:30:48,399
effort

754
00:30:48,399 --> 00:30:52,000
but the trouble is that the system model

755
00:30:52,000 --> 00:30:55,039
that feeds into finding assets and

756
00:30:55,039 --> 00:30:59,840
threats and other mitigations

757
00:31:00,000 --> 00:31:03,360
if you do not have a good system model

758
00:31:03,360 --> 00:31:05,519
your outcome is not going to be good and

759
00:31:05,519 --> 00:31:07,519
this is why most security architects

760
00:31:07,519 --> 00:31:08,000
spend

761
00:31:08,000 --> 00:31:10,480
a lot of time creating a good system

762
00:31:10,480 --> 00:31:11,600
model

763
00:31:11,600 --> 00:31:14,559
so the challenge is how do you express

764
00:31:14,559 --> 00:31:16,080
your system

765
00:31:16,080 --> 00:31:18,159
in a manner that the computer can

766
00:31:18,159 --> 00:31:19,760
understand right

767
00:31:19,760 --> 00:31:23,039
so this is a new area and if

768
00:31:23,039 --> 00:31:26,880
among you are um intending to

769
00:31:26,880 --> 00:31:30,399
pursue your phd this might be one area

770
00:31:30,399 --> 00:31:32,159
that you can

771
00:31:32,159 --> 00:31:34,799
dig into and make our lives easier in a

772
00:31:34,799 --> 00:31:35,840
few years

773
00:31:35,840 --> 00:31:38,240
so there are two approaches threat

774
00:31:38,240 --> 00:31:38,880
modeling

775
00:31:38,880 --> 00:31:42,080
from code or within with code

776
00:31:42,080 --> 00:31:45,039
now the first approach of drag modeling

777
00:31:45,039 --> 00:31:46,000
from code

778
00:31:46,000 --> 00:31:48,799
is that it tried to construct the system

779
00:31:48,799 --> 00:31:49,679
model

780
00:31:49,679 --> 00:31:52,159
from the code itself now here's a

781
00:31:52,159 --> 00:31:53,039
problem

782
00:31:53,039 --> 00:31:56,799
remember i said the definition of

783
00:31:56,799 --> 00:32:00,080
drop modeling is to find weaknesses

784
00:32:00,080 --> 00:32:03,679
at the design time we don't have

785
00:32:03,679 --> 00:32:07,440
implementation but this model from code

786
00:32:07,440 --> 00:32:09,919
assumes that you have a code so there's

787
00:32:09,919 --> 00:32:11,279
little

788
00:32:11,279 --> 00:32:13,760
a little bit contradicting points there

789
00:32:13,760 --> 00:32:16,000
so i don't know the future of it

790
00:32:16,000 --> 00:32:18,559
how it's going to take off or not it'll

791
00:32:18,559 --> 00:32:21,039
be interesting space to watch

792
00:32:21,039 --> 00:32:23,360
this bottom half is direct modeling with

793
00:32:23,360 --> 00:32:24,320
a code

794
00:32:24,320 --> 00:32:27,440
and this is um

795
00:32:27,440 --> 00:32:30,399
it's um it's basically annotating code

796
00:32:30,399 --> 00:32:31,279
but not really

797
00:32:31,279 --> 00:32:34,320
implementing it i that that was the

798
00:32:34,320 --> 00:32:36,320
feeling that i got but to be honest with

799
00:32:36,320 --> 00:32:37,519
you um i

800
00:32:37,519 --> 00:32:40,559
haven't had a chance to check out these

801
00:32:40,559 --> 00:32:43,039
modeling automation tools and this is

802
00:32:43,039 --> 00:32:44,880
one of my goals this year

803
00:32:44,880 --> 00:32:47,679
and if anybody want to like inspect this

804
00:32:47,679 --> 00:32:49,440
with me i would love to collaborate with

805
00:32:49,440 --> 00:32:51,039
you

806
00:32:51,039 --> 00:32:53,279
but i put the links here so that you can

807
00:32:53,279 --> 00:32:56,559
go check out and learn about it

808
00:32:56,559 --> 00:32:59,200
now um i put additional threat modeling

809
00:32:59,200 --> 00:32:59,760
tools

810
00:32:59,760 --> 00:33:02,799
and again feel free to go out and check

811
00:33:02,799 --> 00:33:05,120
it out

812
00:33:06,080 --> 00:33:09,120
now i have come to the point where i can

813
00:33:09,120 --> 00:33:09,600
do

814
00:33:09,600 --> 00:33:12,480
drop online practice with you again this

815
00:33:12,480 --> 00:33:13,200
is taken

816
00:33:13,200 --> 00:33:15,279
directly from the threat modeling book

817
00:33:15,279 --> 00:33:17,200
that i introduced you to uh to you

818
00:33:17,200 --> 00:33:18,559
earlier

819
00:33:18,559 --> 00:33:21,279
so at this point if you don't already

820
00:33:21,279 --> 00:33:21,840
have it

821
00:33:21,840 --> 00:33:24,799
i want you to go grab a piece of paper

822
00:33:24,799 --> 00:33:25,120
and

823
00:33:25,120 --> 00:33:30,158
pen or pencil we're going to do this

824
00:33:36,840 --> 00:33:38,240
together

825
00:33:38,240 --> 00:33:42,000
now this is a

826
00:33:42,000 --> 00:33:45,200
theoretical industrial control system

827
00:33:45,200 --> 00:33:49,440
and i want you to read it and construct

828
00:33:49,440 --> 00:33:52,320
on piece of paper what you think the

829
00:33:52,320 --> 00:33:52,960
system

830
00:33:52,960 --> 00:33:55,519
interaction or what are the components

831
00:33:55,519 --> 00:33:56,640
that are involved

832
00:33:56,640 --> 00:33:59,039
in this system and how they're

833
00:33:59,039 --> 00:34:00,399
interacting

834
00:34:00,399 --> 00:34:03,440
you can draw boxes or

835
00:34:03,440 --> 00:34:06,480
circles to indicate a different part

836
00:34:06,480 --> 00:34:10,079
of the system and also

837
00:34:10,079 --> 00:34:12,800
draw arrows you can have a directional

838
00:34:12,800 --> 00:34:14,879
arrows to indicate where the information

839
00:34:14,879 --> 00:34:15,280
is

840
00:34:15,280 --> 00:34:19,040
flowing and if there are certain

841
00:34:19,040 --> 00:34:21,760
data that is being stored you can

842
00:34:21,760 --> 00:34:24,079
indicate that data

843
00:34:24,079 --> 00:34:27,119
the database box usually that's um

844
00:34:27,119 --> 00:34:29,918
in uml diagrams you can use those kind

845
00:34:29,918 --> 00:34:31,119
of things

846
00:34:31,119 --> 00:34:33,918
so i'm going to be quiet for next two

847
00:34:33,918 --> 00:34:34,480
minutes

848
00:34:34,480 --> 00:34:49,839
for you to read and construct that

849
00:35:39,680 --> 00:35:43,040
all right i hope you have something um

850
00:35:43,040 --> 00:35:47,280
on the piece of paper now

851
00:35:47,280 --> 00:35:49,839
let's see

852
00:35:50,640 --> 00:35:53,599
so in this circular diagram that i

853
00:35:53,599 --> 00:35:54,480
showed you

854
00:35:54,480 --> 00:35:57,839
earlier um we're at the system modeling

855
00:35:57,839 --> 00:35:59,359
stage

856
00:35:59,359 --> 00:36:01,359
previous page you can look at it as use

857
00:36:01,359 --> 00:36:02,960
scenario how this is

858
00:36:02,960 --> 00:36:05,760
used and then now we're trying to

859
00:36:05,760 --> 00:36:07,520
construct the architecture

860
00:36:07,520 --> 00:36:10,560
based on that and as

861
00:36:10,560 --> 00:36:12,880
a as part of development groups

862
00:36:12,880 --> 00:36:14,079
oftentimes

863
00:36:14,079 --> 00:36:17,119
people do have design docs right

864
00:36:17,119 --> 00:36:19,920
you can utilize that as much as possible

865
00:36:19,920 --> 00:36:21,200
you don't have to draw

866
00:36:21,200 --> 00:36:24,480
a special diagram just for this but i'm

867
00:36:24,480 --> 00:36:26,400
a very highly visual person

868
00:36:26,400 --> 00:36:28,960
and for me it works really well and i

869
00:36:28,960 --> 00:36:30,320
think uh most

870
00:36:30,320 --> 00:36:33,440
system model representation also has

871
00:36:33,440 --> 00:36:36,000
the visual aspect of it and this is why

872
00:36:36,000 --> 00:36:37,599
i asked you to draw

873
00:36:37,599 --> 00:36:40,320
and of course in the book it also

874
00:36:40,320 --> 00:36:41,599
represents the

875
00:36:41,599 --> 00:36:44,640
diagram so if you recall that

876
00:36:44,640 --> 00:36:48,880
it's a iot sensor where there is a valve

877
00:36:48,880 --> 00:36:52,160
control it reads the data

878
00:36:52,160 --> 00:36:55,440
from the pressure monitor and um

879
00:36:55,440 --> 00:36:58,880
it interacts with this um control

880
00:36:58,880 --> 00:37:02,320
and analytics service and based on the

881
00:37:02,320 --> 00:37:05,359
the pressure level the reading levels it

882
00:37:05,359 --> 00:37:07,359
either you know turns on and off the

883
00:37:07,359 --> 00:37:08,880
valve to

884
00:37:08,880 --> 00:37:12,800
um release the pressure for instance now

885
00:37:12,800 --> 00:37:15,760
i like this example because it's very

886
00:37:15,760 --> 00:37:16,640
simple

887
00:37:16,640 --> 00:37:18,400
but at the same time this is very

888
00:37:18,400 --> 00:37:21,280
representative of real world

889
00:37:21,280 --> 00:37:24,480
implementation as many of you know so

890
00:37:24,480 --> 00:37:27,520
this is a good one to exercise with

891
00:37:27,520 --> 00:37:30,480
here you can see the directional arrow

892
00:37:30,480 --> 00:37:31,280
where

893
00:37:31,280 --> 00:37:33,760
which ones that they're the information

894
00:37:33,760 --> 00:37:35,359
is going and coming

895
00:37:35,359 --> 00:37:38,720
now these uh tiny extra um

896
00:37:38,720 --> 00:37:41,520
what appears to be looking like a say

897
00:37:41,520 --> 00:37:42,240
between a

898
00:37:42,240 --> 00:37:44,880
valve and valve the actuator there's a

899
00:37:44,880 --> 00:37:46,560
little tiny short arrow

900
00:37:46,560 --> 00:37:49,680
that looks like number one it's actually

901
00:37:49,680 --> 00:37:52,880
indicating that valve actuator

902
00:37:52,880 --> 00:37:56,240
is initiating the communication to

903
00:37:56,240 --> 00:37:59,119
valve when there's unidirectional

904
00:37:59,119 --> 00:38:00,880
information

905
00:38:00,880 --> 00:38:02,960
bi-directional information you wouldn't

906
00:38:02,960 --> 00:38:04,640
know which one is initiating that

907
00:38:04,640 --> 00:38:06,000
information

908
00:38:06,000 --> 00:38:09,040
so again valve actuator and sensor array

909
00:38:09,040 --> 00:38:12,160
to control analytic service it's the

910
00:38:12,160 --> 00:38:12,640
valve

911
00:38:12,640 --> 00:38:14,560
actuator who's initiating that

912
00:38:14,560 --> 00:38:16,160
communication even though

913
00:38:16,160 --> 00:38:19,839
they communicate bi-directionally

914
00:38:20,800 --> 00:38:23,040
i hope that your diagram is something

915
00:38:23,040 --> 00:38:24,160
close to

916
00:38:24,160 --> 00:38:27,680
um what is shown here

917
00:38:27,680 --> 00:38:32,000
now but this is like two

918
00:38:32,000 --> 00:38:34,240
high level and maybe a little bit

919
00:38:34,240 --> 00:38:35,440
difficult to see

920
00:38:35,440 --> 00:38:38,480
what's the the next level of um

921
00:38:38,480 --> 00:38:41,200
drop modeling that we gotta do so then

922
00:38:41,200 --> 00:38:41,920
um

923
00:38:41,920 --> 00:38:44,079
you know at this point oftentimes what

924
00:38:44,079 --> 00:38:46,160
happens is the security architect would

925
00:38:46,160 --> 00:38:50,160
ask developers or the product teams

926
00:38:50,160 --> 00:38:51,760
hey you know give me a little bit more

927
00:38:51,760 --> 00:38:54,480
details and what's involved what are the

928
00:38:54,480 --> 00:38:56,240
communication mechanisms

929
00:38:56,240 --> 00:38:59,440
so this is the next level detail and one

930
00:38:59,440 --> 00:39:01,280
thing that i want to point out

931
00:39:01,280 --> 00:39:04,000
is the dotted line around it it

932
00:39:04,000 --> 00:39:05,359
indicates that

933
00:39:05,359 --> 00:39:08,480
it's a security domain right here

934
00:39:08,480 --> 00:39:11,440
this is one security domain and anything

935
00:39:11,440 --> 00:39:12,160
outside

936
00:39:12,160 --> 00:39:15,280
is a different security domain which

937
00:39:15,280 --> 00:39:16,400
means that you

938
00:39:16,400 --> 00:39:18,880
are crossing the security boundaries and

939
00:39:18,880 --> 00:39:20,880
these are the points that you have to be

940
00:39:20,880 --> 00:39:22,000
very careful

941
00:39:22,000 --> 00:39:26,480
in looking for a potential attack points

942
00:39:27,200 --> 00:39:30,720
it's a blow up of how a

943
00:39:30,720 --> 00:39:32,880
if you recall the reading or if you go

944
00:39:32,880 --> 00:39:34,400
back to the previous page of the

945
00:39:34,400 --> 00:39:35,440
description

946
00:39:35,440 --> 00:39:38,079
there's a shadow service and so it kind

947
00:39:38,079 --> 00:39:39,119
of describes

948
00:39:39,119 --> 00:39:41,920
how the shadow service architecture

949
00:39:41,920 --> 00:39:44,079
would look like

950
00:39:44,079 --> 00:39:47,119
again at this point um i would do

951
00:39:47,119 --> 00:39:51,040
okay where are the assets so

952
00:39:51,040 --> 00:39:53,680
a lot of times um you can do threat

953
00:39:53,680 --> 00:39:54,400
modeling

954
00:39:54,400 --> 00:39:58,400
based on assets or you can just

955
00:39:58,400 --> 00:40:01,280
see where the attacks are again there's

956
00:40:01,280 --> 00:40:02,240
no right or

957
00:40:02,240 --> 00:40:05,280
wrong way what works best for you i'm

958
00:40:05,280 --> 00:40:08,240
very comfortable with looking for assets

959
00:40:08,240 --> 00:40:08,720
first

960
00:40:08,720 --> 00:40:12,560
first because um my reasoning is

961
00:40:12,560 --> 00:40:15,680
that without asset what are we trying to

962
00:40:15,680 --> 00:40:16,400
protect

963
00:40:16,400 --> 00:40:19,520
right so where are the assets within my

964
00:40:19,520 --> 00:40:20,640
system

965
00:40:20,640 --> 00:40:24,400
and um the i listed the assets and

966
00:40:24,400 --> 00:40:26,160
i think yeah part of it is like uh from

967
00:40:26,160 --> 00:40:27,920
the book as well sorry um

968
00:40:27,920 --> 00:40:31,599
i don't mean to imply that i the only um

969
00:40:31,599 --> 00:40:34,000
i came up with this list but anyway if

970
00:40:34,000 --> 00:40:35,839
you look at the books uh book

971
00:40:35,839 --> 00:40:38,480
um you will see these are the assets and

972
00:40:38,480 --> 00:40:39,839
for all of these

973
00:40:39,839 --> 00:40:43,760
assets you go through which of the cia

974
00:40:43,760 --> 00:40:46,800
triad does it apply right and

975
00:40:46,800 --> 00:40:49,839
in the industrial control context a lot

976
00:40:49,839 --> 00:40:50,839
of times

977
00:40:50,839 --> 00:40:54,319
confidentiality is not important so

978
00:40:54,319 --> 00:40:57,440
you may have nothing applied

979
00:40:57,440 --> 00:41:00,560
in the sensor data aspect of it but i

980
00:41:00,560 --> 00:41:01,359
kind of marked

981
00:41:01,359 --> 00:41:04,560
as analytics database as confidential

982
00:41:04,560 --> 00:41:08,079
and most of the um

983
00:41:08,079 --> 00:41:11,280
ml um the model developers they they

984
00:41:11,280 --> 00:41:14,800
consider their model to be very

985
00:41:14,800 --> 00:41:17,599
critical and it's an ip right so that's

986
00:41:17,599 --> 00:41:19,119
why i kind of marked it as

987
00:41:19,119 --> 00:41:22,319
confidential and but in other cases

988
00:41:22,319 --> 00:41:23,440
sensor data

989
00:41:23,440 --> 00:41:27,280
may be also um

990
00:41:27,280 --> 00:41:29,680
confidential as well the example is that

991
00:41:29,680 --> 00:41:30,480
you're a

992
00:41:30,480 --> 00:41:33,200
pharmaceutical company and you're

993
00:41:33,200 --> 00:41:34,319
working on a

994
00:41:34,319 --> 00:41:37,680
special well we have a good example

995
00:41:37,680 --> 00:41:40,800
the vaccine right code vaccine needs to

996
00:41:40,800 --> 00:41:41,520
be stored

997
00:41:41,520 --> 00:41:45,200
at an extremely low temperature so

998
00:41:45,200 --> 00:41:48,640
the fact that your temperature reading

999
00:41:48,640 --> 00:41:49,680
is very low

1000
00:41:49,680 --> 00:41:52,800
if it leaked maybe it gives some clues

1001
00:41:52,800 --> 00:41:53,200
to

1002
00:41:53,200 --> 00:41:55,839
competitor that they need to work with

1003
00:41:55,839 --> 00:41:57,440
something that works at a low

1004
00:41:57,440 --> 00:42:00,000
um temperature setting so that could be

1005
00:42:00,000 --> 00:42:01,280
also confidential

1006
00:42:01,280 --> 00:42:03,599
but in this particular example it is not

1007
00:42:03,599 --> 00:42:06,079
considered confidential

1008
00:42:06,079 --> 00:42:09,440
again we come to okay since we

1009
00:42:09,440 --> 00:42:12,160
found out all the assets and what their

1010
00:42:12,160 --> 00:42:12,880
um

1011
00:42:12,880 --> 00:42:15,599
whether it's a cia confidentiality

1012
00:42:15,599 --> 00:42:16,800
integrity or

1013
00:42:16,800 --> 00:42:19,520
um a variability which one is important

1014
00:42:19,520 --> 00:42:21,760
now we try to identify direct center

1015
00:42:21,760 --> 00:42:23,200
task services

1016
00:42:23,200 --> 00:42:25,599
and so these are the typical questions

1017
00:42:25,599 --> 00:42:26,960
that you ask

1018
00:42:26,960 --> 00:42:29,680
trying to see how that particular asset

1019
00:42:29,680 --> 00:42:31,680
could be attacked

1020
00:42:31,680 --> 00:42:34,800
um and then in the book

1021
00:42:34,800 --> 00:42:37,520
it talks about the weaknesses and

1022
00:42:37,520 --> 00:42:38,640
vulnerability

1023
00:42:38,640 --> 00:42:41,839
that you find and um so yeah

1024
00:42:41,839 --> 00:42:43,680
in the interest of time i'm not going to

1025
00:42:43,680 --> 00:42:45,040
go over all of it

1026
00:42:45,040 --> 00:42:46,960
but you know here's the information that

1027
00:42:46,960 --> 00:42:49,119
you can read

1028
00:42:49,119 --> 00:42:52,560
and um now that we have and this is just

1029
00:42:52,560 --> 00:42:53,040
some

1030
00:42:53,040 --> 00:42:55,359
identifying the threats based on

1031
00:42:55,359 --> 00:42:58,319
previous two slides that we talked about

1032
00:42:58,319 --> 00:43:02,079
and we come to the mitigation part of it

1033
00:43:02,079 --> 00:43:05,520
so in the mitigation you know how do you

1034
00:43:05,520 --> 00:43:06,480
address this

1035
00:43:06,480 --> 00:43:09,680
so again depends on what the threat

1036
00:43:09,680 --> 00:43:12,000
is you come up with the mitigation and

1037
00:43:12,000 --> 00:43:13,839
this takes a little bit of practice

1038
00:43:13,839 --> 00:43:17,440
there's additional resource that um

1039
00:43:17,440 --> 00:43:20,000
in the future if we ever come across

1040
00:43:20,000 --> 00:43:20,800
again um

1041
00:43:20,800 --> 00:43:24,000
we could delve into deeper but

1042
00:43:24,000 --> 00:43:26,240
in the interest of time i didn't include

1043
00:43:26,240 --> 00:43:28,880
those in this talk

1044
00:43:28,880 --> 00:43:32,160
now we went over quite a lot

1045
00:43:32,160 --> 00:43:36,400
and we went over formal definition of it

1046
00:43:36,400 --> 00:43:39,280
i'm going to put the rep modeling a

1047
00:43:39,280 --> 00:43:40,160
little bit more

1048
00:43:40,160 --> 00:43:43,599
in layman's term if you had forgotten

1049
00:43:43,599 --> 00:43:45,839
the formal definition here's how adam

1050
00:43:45,839 --> 00:43:47,359
shows that puts it

1051
00:43:47,359 --> 00:43:50,720
and it may be easier for you to remember

1052
00:43:50,720 --> 00:43:53,359
he's asking he's saying that we're

1053
00:43:53,359 --> 00:43:54,240
asking these

1054
00:43:54,240 --> 00:43:57,200
four fundamental questions what are we

1055
00:43:57,200 --> 00:43:58,880
working on

1056
00:43:58,880 --> 00:44:01,359
so if you think about it that kind of

1057
00:44:01,359 --> 00:44:02,400
maps to

1058
00:44:02,400 --> 00:44:05,440
system model right we want to know

1059
00:44:05,440 --> 00:44:08,400
what our system is doing what can go

1060
00:44:08,400 --> 00:44:09,520
wrong

1061
00:44:09,520 --> 00:44:13,119
this is identifying assets and threats

1062
00:44:13,119 --> 00:44:13,599
and

1063
00:44:13,599 --> 00:44:17,280
attack surfaces what are we going to do

1064
00:44:17,280 --> 00:44:18,640
about it

1065
00:44:18,640 --> 00:44:22,000
this is the mitigation now the last

1066
00:44:22,000 --> 00:44:25,520
question did we do a good job

1067
00:44:25,520 --> 00:44:27,520
remember i said earlier it's an

1068
00:44:27,520 --> 00:44:28,960
iterative process

1069
00:44:28,960 --> 00:44:32,000
until you feel pretty confident that

1070
00:44:32,000 --> 00:44:33,760
you've done a good job

1071
00:44:33,760 --> 00:44:36,560
how do you know how do you know that

1072
00:44:36,560 --> 00:44:38,640
you've done a good job

1073
00:44:38,640 --> 00:44:41,839
now when i first started in this domain

1074
00:44:41,839 --> 00:44:44,400
of doing threat modeling this is what

1075
00:44:44,400 --> 00:44:45,040
kept me

1076
00:44:45,040 --> 00:44:48,400
up at night did i

1077
00:44:48,400 --> 00:44:52,560
do a good job did i find everything

1078
00:44:52,560 --> 00:44:56,720
then over time i change my mind

1079
00:44:56,720 --> 00:44:59,760
threat modeling at every stage i'm

1080
00:44:59,760 --> 00:45:01,520
trying to find

1081
00:45:01,520 --> 00:45:05,280
as many as i can it's okay i may have

1082
00:45:05,280 --> 00:45:08,560
missed it um there are even cases where

1083
00:45:08,560 --> 00:45:11,520
i just spent a lot of time trying to

1084
00:45:11,520 --> 00:45:12,000
find

1085
00:45:12,000 --> 00:45:15,040
all the threats possible and then

1086
00:45:15,040 --> 00:45:18,800
um i in my previous job there was a

1087
00:45:18,800 --> 00:45:21,599
review board where i bring my threat

1088
00:45:21,599 --> 00:45:23,520
bottling and then it's reviewed by

1089
00:45:23,520 --> 00:45:25,920
many security architects and there was a

1090
00:45:25,920 --> 00:45:28,560
really obvious one that i completely

1091
00:45:28,560 --> 00:45:29,440
left out

1092
00:45:29,440 --> 00:45:32,640
yes i felt mortified but that was the

1093
00:45:32,640 --> 00:45:34,480
purpose of the review board

1094
00:45:34,480 --> 00:45:36,640
because we're human beings and sometimes

1095
00:45:36,640 --> 00:45:38,000
we make mistakes

1096
00:45:38,000 --> 00:45:42,319
and it's okay so i want to leave you

1097
00:45:42,319 --> 00:45:46,160
with this message perfectionism

1098
00:45:46,160 --> 00:45:50,319
is not the key to the success letting go

1099
00:45:50,319 --> 00:45:53,839
of perfection is nism is

1100
00:45:53,839 --> 00:45:57,359
so let go of perfectionism

1101
00:45:57,359 --> 00:46:00,960
and try it out and as you develop your

1102
00:46:00,960 --> 00:46:01,520
system

1103
00:46:01,520 --> 00:46:04,720
think about what can go wrong

1104
00:46:04,720 --> 00:46:09,439
and trying to see how you can prevent it

1105
00:46:09,920 --> 00:46:15,359
with that i return back to host kita

1106
00:46:15,359 --> 00:46:18,079
yep sure yeah thanks a lot miss lee for

1107
00:46:18,079 --> 00:46:18,640
the talk

1108
00:46:18,640 --> 00:46:22,240
uh so we'll move on to the q a session

1109
00:46:22,240 --> 00:46:29,839
and look for some interesting questions

1110
00:46:39,200 --> 00:46:42,960
okay uh yeah there is a question

1111
00:46:42,960 --> 00:46:44,960
uh could you explain what's a shadow

1112
00:46:44,960 --> 00:46:47,280
device

1113
00:46:47,280 --> 00:46:51,520
oh um in these um so if you

1114
00:46:51,520 --> 00:46:53,760
i suppose that i'm gonna share this

1115
00:46:53,760 --> 00:46:54,960
slide deck

1116
00:46:54,960 --> 00:46:57,680
and in the example i'm looking at the

1117
00:46:57,680 --> 00:46:58,800
example

1118
00:46:58,800 --> 00:47:02,160
it's on slide page 39 and when you get

1119
00:47:02,160 --> 00:47:04,160
it you will take a look at it

1120
00:47:04,160 --> 00:47:06,960
in this theoretical industrial control

1121
00:47:06,960 --> 00:47:07,920
system

1122
00:47:07,920 --> 00:47:10,560
there is a system where you take the

1123
00:47:10,560 --> 00:47:12,240
valve

1124
00:47:12,240 --> 00:47:14,079
pressure reading and then controls the

1125
00:47:14,079 --> 00:47:15,440
valve right

1126
00:47:15,440 --> 00:47:18,800
and um if you think about it if you only

1127
00:47:18,800 --> 00:47:19,119
have

1128
00:47:19,119 --> 00:47:22,480
one system and if that fails it could

1129
00:47:22,480 --> 00:47:23,200
blow up

1130
00:47:23,200 --> 00:47:26,160
right so in a critical system like this

1131
00:47:26,160 --> 00:47:27,839
there's a secondary device

1132
00:47:27,839 --> 00:47:30,880
that's uh inactive but it is monitoring

1133
00:47:30,880 --> 00:47:34,000
it has all the capability to do control

1134
00:47:34,000 --> 00:47:34,720
as well

1135
00:47:34,720 --> 00:47:37,040
so in this description they talk about

1136
00:47:37,040 --> 00:47:39,119
there is a shadow system

1137
00:47:39,119 --> 00:47:42,800
that it's implementing

1138
00:47:45,280 --> 00:47:48,559
okay so the next question is

1139
00:47:48,559 --> 00:47:50,559
which threat modeling tool is the best

1140
00:47:50,559 --> 00:47:53,040
to use

1141
00:47:53,040 --> 00:47:55,599
um and again what works best with you

1142
00:47:55,599 --> 00:47:56,480
and this is why

1143
00:47:56,480 --> 00:48:00,160
you'll have to try it out now um

1144
00:48:00,160 --> 00:48:02,480
so if you were talking about tool i

1145
00:48:02,480 --> 00:48:04,880
think you're looking at the automatic uh

1146
00:48:04,880 --> 00:48:07,280
ones and i'll be honest with you i am

1147
00:48:07,280 --> 00:48:08,640
little old school so

1148
00:48:08,640 --> 00:48:12,000
i do it myself and i don't rely on

1149
00:48:12,000 --> 00:48:14,559
automated systems so much and so my

1150
00:48:14,559 --> 00:48:16,640
experience is limited

1151
00:48:16,640 --> 00:48:20,559
but um the tricky part is the one that

1152
00:48:20,559 --> 00:48:21,599
can

1153
00:48:21,599 --> 00:48:25,040
map your system as accurately as

1154
00:48:25,040 --> 00:48:27,920
possible to the format that computer can

1155
00:48:27,920 --> 00:48:28,960
understand

1156
00:48:28,960 --> 00:48:31,599
again that system modeling is key

1157
00:48:31,599 --> 00:48:32,480
because

1158
00:48:32,480 --> 00:48:35,119
if you do not construct construct a good

1159
00:48:35,119 --> 00:48:36,160
system model

1160
00:48:36,160 --> 00:48:38,240
then in the end it's a garbage in

1161
00:48:38,240 --> 00:48:39,359
garbage out

1162
00:48:39,359 --> 00:48:42,720
right so how do we make sure uh

1163
00:48:42,720 --> 00:48:44,720
you may want to try out different tools

1164
00:48:44,720 --> 00:48:46,160
to see how

1165
00:48:46,160 --> 00:48:51,118
they accurately represent your system

1166
00:49:00,839 --> 00:49:03,839
um

1167
00:49:09,200 --> 00:49:14,558
i think kita is muted

1168
00:49:14,839 --> 00:49:17,440
or

1169
00:49:17,440 --> 00:49:20,960
uh hey uh yeah so

1170
00:49:20,960 --> 00:49:24,000
uh we have one more question lined up

1171
00:49:24,000 --> 00:49:26,880
uh which is uh which type of industry

1172
00:49:26,880 --> 00:49:27,359
must

1173
00:49:27,359 --> 00:49:31,200
have the threat modeling team

1174
00:49:31,200 --> 00:49:34,480
all of them but if you

1175
00:49:34,480 --> 00:49:37,760
are um that's my opinion but i'm not

1176
00:49:37,760 --> 00:49:38,640
biased

1177
00:49:38,640 --> 00:49:42,000
um but if you are talking about anything

1178
00:49:42,000 --> 00:49:45,280
that's interfacing external system

1179
00:49:45,280 --> 00:49:48,000
that's very important anything web-based

1180
00:49:48,000 --> 00:49:48,319
but

1181
00:49:48,319 --> 00:49:51,680
even um products that are being

1182
00:49:51,680 --> 00:49:54,079
installed at home for instance you know

1183
00:49:54,079 --> 00:49:55,520
let's talk about light bulbs

1184
00:49:55,520 --> 00:49:57,839
right there had been a hack where

1185
00:49:57,839 --> 00:49:59,839
hackers were able to

1186
00:49:59,839 --> 00:50:02,160
hack into light bulb and get into

1187
00:50:02,160 --> 00:50:03,520
somebody's house

1188
00:50:03,520 --> 00:50:05,920
so if you think about light bulb but hey

1189
00:50:05,920 --> 00:50:07,359
you know who cares about light bulb

1190
00:50:07,359 --> 00:50:08,160
being hacked

1191
00:50:08,160 --> 00:50:10,559
right but the key thing is that light

1192
00:50:10,559 --> 00:50:11,599
bulb is

1193
00:50:11,599 --> 00:50:14,960
one of the components

1194
00:50:14,960 --> 00:50:18,079
in a more expanded and system

1195
00:50:18,079 --> 00:50:21,040
like a home automation system and it can

1196
00:50:21,040 --> 00:50:21,760
provide

1197
00:50:21,760 --> 00:50:24,880
the the weakest link for

1198
00:50:24,880 --> 00:50:27,760
attackers to come baby monitor same

1199
00:50:27,760 --> 00:50:28,319
thing

1200
00:50:28,319 --> 00:50:31,599
baby monitor seem like nothing but

1201
00:50:31,599 --> 00:50:34,960
again it could be utilized to

1202
00:50:34,960 --> 00:50:37,920
hack into the rest of the system so i

1203
00:50:37,920 --> 00:50:38,839
think that

1204
00:50:38,839 --> 00:50:41,920
um it should be exercise in

1205
00:50:41,920 --> 00:50:45,200
all domains

1206
00:50:45,440 --> 00:50:49,280
okay another question is

1207
00:50:49,280 --> 00:50:52,480
as a phd topic what do you think

1208
00:50:52,480 --> 00:50:56,079
can be done in threat modeling

1209
00:50:56,079 --> 00:50:58,240
uh so i kind of mentioned earlier while

1210
00:50:58,240 --> 00:51:00,079
we're looking into automation

1211
00:51:00,079 --> 00:51:03,440
i think automation is um not

1212
00:51:03,440 --> 00:51:07,040
fully developed that's how i think

1213
00:51:07,040 --> 00:51:10,000
so there are some um aspects of

1214
00:51:10,000 --> 00:51:11,920
automating threat modeling

1215
00:51:11,920 --> 00:51:14,720
and another thing is that i i don't know

1216
00:51:14,720 --> 00:51:16,319
if it came clear or not

1217
00:51:16,319 --> 00:51:19,200
but threat modeling is considered very

1218
00:51:19,200 --> 00:51:21,280
time consuming and

1219
00:51:21,280 --> 00:51:24,800
energy draining extensive work so if we

1220
00:51:24,800 --> 00:51:25,599
can help

1221
00:51:25,599 --> 00:51:29,520
automate this and get developers

1222
00:51:29,520 --> 00:51:33,680
to aid developers to do this while

1223
00:51:33,680 --> 00:51:35,680
they're doing their development work

1224
00:51:35,680 --> 00:51:38,160
i think it would be great help to the

1225
00:51:38,160 --> 00:51:41,040
whole industry

1226
00:51:44,240 --> 00:51:47,760
okay next question

1227
00:51:47,760 --> 00:51:51,119
is isolating individual systems from one

1228
00:51:51,119 --> 00:51:52,319
another

1229
00:51:52,319 --> 00:51:55,359
will it be helpful

1230
00:51:55,440 --> 00:51:59,119
yes i mean isolated is

1231
00:51:59,119 --> 00:52:03,680
as helpful as possible because you are

1232
00:52:03,680 --> 00:52:05,839
not allowing one interaction to another

1233
00:52:05,839 --> 00:52:07,920
but let's talk about that

1234
00:52:07,920 --> 00:52:10,319
in the talk i said the most secure

1235
00:52:10,319 --> 00:52:11,440
system is the one that's

1236
00:52:11,440 --> 00:52:14,720
turned off and not used at all right so

1237
00:52:14,720 --> 00:52:18,079
can you do what you want to do by

1238
00:52:18,079 --> 00:52:20,880
isolating all of these systems if the

1239
00:52:20,880 --> 00:52:21,839
answer is

1240
00:52:21,839 --> 00:52:25,440
yes can you afford to isolate them

1241
00:52:25,440 --> 00:52:27,680
because that may mean that you may have

1242
00:52:27,680 --> 00:52:29,520
to get extra hardware

1243
00:52:29,520 --> 00:52:33,119
or extra setup maybe

1244
00:52:33,119 --> 00:52:35,200
but a lot of times you will find that

1245
00:52:35,200 --> 00:52:36,880
the customers would want to

1246
00:52:36,880 --> 00:52:39,440
minimize the cost in implementing

1247
00:52:39,440 --> 00:52:40,400
something right

1248
00:52:40,400 --> 00:52:43,839
so therefore while that's your desire

1249
00:52:43,839 --> 00:52:45,839
from security perspective that is not

1250
00:52:45,839 --> 00:52:49,520
always the possibility

1251
00:52:53,680 --> 00:52:57,599
okay the next question

1252
00:52:57,599 --> 00:53:00,640
what criteria is used to prioritize

1253
00:53:00,640 --> 00:53:05,520
discarding threats during product design

1254
00:53:05,520 --> 00:53:07,520
discarding threats meaning that you

1255
00:53:07,520 --> 00:53:09,040
identify threats

1256
00:53:09,040 --> 00:53:12,880
but you are not mitigating it

1257
00:53:12,880 --> 00:53:18,000
is that right um

1258
00:53:18,000 --> 00:53:22,000
okay let us yes yes

1259
00:53:22,000 --> 00:53:25,680
okay so um this is why

1260
00:53:25,680 --> 00:53:28,480
it's a team sport you need to have

1261
00:53:28,480 --> 00:53:29,920
multiple

1262
00:53:29,920 --> 00:53:32,480
various stakeholders in place to answer

1263
00:53:32,480 --> 00:53:34,240
that question

1264
00:53:34,240 --> 00:53:37,680
and there's no single guideline

1265
00:53:37,680 --> 00:53:40,720
it is about but but generally this is

1266
00:53:40,720 --> 00:53:41,760
what i use

1267
00:53:41,760 --> 00:53:45,280
i use um 80 20 or 20 80 however you want

1268
00:53:45,280 --> 00:53:46,400
to call it right

1269
00:53:46,400 --> 00:53:51,119
so what are the most impact could i have

1270
00:53:51,119 --> 00:53:54,319
with the smallest resource right and i

1271
00:53:54,319 --> 00:53:55,040
tried to

1272
00:53:55,040 --> 00:53:57,520
address all of those but there's always

1273
00:53:57,520 --> 00:53:59,280
some corner case

1274
00:53:59,280 --> 00:54:02,319
that is very difficult to actually make

1275
00:54:02,319 --> 00:54:04,720
it happen from attackers perspective

1276
00:54:04,720 --> 00:54:07,040
and let's say that it's especially high

1277
00:54:07,040 --> 00:54:08,559
cost to mitigate it

1278
00:54:08,559 --> 00:54:11,599
then those at a high candidate to be

1279
00:54:11,599 --> 00:54:14,240
put on the back um you know to be

1280
00:54:14,240 --> 00:54:15,280
addressed later on

1281
00:54:15,280 --> 00:54:18,960
for instance but this will be

1282
00:54:18,960 --> 00:54:21,440
um ultimately product owners decision

1283
00:54:21,440 --> 00:54:23,200
business owners decision

1284
00:54:23,200 --> 00:54:26,880
because uh you will find in reality that

1285
00:54:26,880 --> 00:54:28,960
the business people will say we need to

1286
00:54:28,960 --> 00:54:30,960
release this product by this state

1287
00:54:30,960 --> 00:54:33,040
otherwise we don't make any money right

1288
00:54:33,040 --> 00:54:35,040
so you would have to consult with them

1289
00:54:35,040 --> 00:54:36,880
and come to consensus

1290
00:54:36,880 --> 00:54:39,839
with full knowledge

1291
00:54:42,240 --> 00:54:45,520
okay so uh i guess

1292
00:54:45,520 --> 00:54:48,799
uh we are done with the uh q a session

1293
00:54:48,799 --> 00:54:52,480
uh and uh it's

1294
00:54:52,480 --> 00:54:54,400
yeah i guess there are no more questions

1295
00:54:54,400 --> 00:54:55,760
so

1296
00:54:55,760 --> 00:54:58,880
uh thanks a lot uh like we have got

1297
00:54:58,880 --> 00:55:02,400
really deeply insights into this

1298
00:55:02,400 --> 00:55:05,520
topic of threat modeling and also we

1299
00:55:05,520 --> 00:55:06,000
would like

1300
00:55:06,000 --> 00:55:09,119
to uh we would like to take a minute to

1301
00:55:09,119 --> 00:55:12,240
thanks uh thank our sponsors

1302
00:55:12,240 --> 00:55:15,599
uh vmware for making this uh conference

1303
00:55:15,599 --> 00:55:16,799
possible

1304
00:55:16,799 --> 00:55:20,160
and reaching out to the

1305
00:55:20,160 --> 00:55:21,760
people who are interested in this

1306
00:55:21,760 --> 00:55:24,079
particular field

1307
00:55:24,079 --> 00:55:28,000
so yeah

1308
00:55:29,839 --> 00:55:33,119
thank you

