1
00:00:12,480 --> 00:00:14,320
okay sorry everyone for the for the

2
00:00:14,320 --> 00:00:15,839
audio travels i guess loader will be

3
00:00:15,839 --> 00:00:18,480
with us in a second again um so this is

4
00:00:18,480 --> 00:00:19,199
the

5
00:00:19,199 --> 00:00:21,760
panel with the slightly cumbersome title

6
00:00:21,760 --> 00:00:23,840
regulation versus governance who is

7
00:00:23,840 --> 00:00:25,920
marginalized who is privileged and is

8
00:00:25,920 --> 00:00:27,920
previously the right focus

9
00:00:27,920 --> 00:00:31,599
um so so i think what we've all learned

10
00:00:31,599 --> 00:00:34,000
over the last um

11
00:00:34,000 --> 00:00:35,760
couple of panels over the last hours of

12
00:00:35,760 --> 00:00:37,360
today is that many of us have been

13
00:00:37,360 --> 00:00:39,920
thinking about um

14
00:00:39,920 --> 00:00:42,399
security and privacy needs for

15
00:00:42,399 --> 00:00:45,920
certain groups of people that we often

16
00:00:45,920 --> 00:00:48,559
refer to as marginalized i'm not even

17
00:00:48,559 --> 00:00:50,000
sure if that's a good term anymore

18
00:00:50,000 --> 00:00:51,680
because there seem to be so many of

19
00:00:51,680 --> 00:00:53,280
these groups of people that it really

20
00:00:53,280 --> 00:00:55,760
affects like a um

21
00:00:55,760 --> 00:00:58,800
huge group of the population

22
00:00:58,800 --> 00:01:02,399
we've also been talking about

23
00:01:02,399 --> 00:01:03,520
how

24
00:01:03,520 --> 00:01:05,280
these

25
00:01:05,280 --> 00:01:08,000
these security and privacy requirements

26
00:01:08,000 --> 00:01:10,880
or needs often intersect directly with

27
00:01:10,880 --> 00:01:13,280
safety requirements for these groups of

28
00:01:13,280 --> 00:01:15,439
people for these communities

29
00:01:15,439 --> 00:01:18,320
and we're talking about

30
00:01:18,320 --> 00:01:20,960
online safety as well as direct physical

31
00:01:20,960 --> 00:01:22,080
safety

32
00:01:22,080 --> 00:01:23,119
and

33
00:01:23,119 --> 00:01:25,759
we've also listened a little bit about

34
00:01:25,759 --> 00:01:27,439
um

35
00:01:27,439 --> 00:01:29,119
or learned a little bit about what

36
00:01:29,119 --> 00:01:31,200
people expect how digital

37
00:01:31,200 --> 00:01:33,840
digital platforms should behave in order

38
00:01:33,840 --> 00:01:35,520
to cater for

39
00:01:35,520 --> 00:01:38,400
um people's safety security needs but

40
00:01:38,400 --> 00:01:40,640
also for their direct safety

41
00:01:40,640 --> 00:01:42,479
and i think in in this panel we want to

42
00:01:42,479 --> 00:01:45,840
distill this a little bit again um but

43
00:01:45,840 --> 00:01:47,840
look at

44
00:01:47,840 --> 00:01:50,079
rather specific examples from a couple

45
00:01:50,079 --> 00:01:51,600
of communities that we have personal

46
00:01:51,600 --> 00:01:53,200
experience with

47
00:01:53,200 --> 00:01:54,640
um i'm jan tobias milberg i'm a

48
00:01:54,640 --> 00:01:56,640
researcher at keoluvin and and one of

49
00:01:56,640 --> 00:01:58,560
the aspects that i've been working is is

50
00:01:58,560 --> 00:02:00,399
people on the move some papier community

51
00:02:00,399 --> 00:02:01,600
specifically

52
00:02:01,600 --> 00:02:05,759
um and there we see groups of people who

53
00:02:05,759 --> 00:02:09,280
need to interact with digital platforms

54
00:02:09,280 --> 00:02:12,800
often being aware that their data traces

55
00:02:12,800 --> 00:02:14,959
can become a problem for them personally

56
00:02:14,959 --> 00:02:16,480
for their own safety for their visa

57
00:02:16,480 --> 00:02:18,800
applications for their

58
00:02:18,800 --> 00:02:20,560
proceedings in migration procedures and

59
00:02:20,560 --> 00:02:21,840
so forth

60
00:02:21,840 --> 00:02:24,319
we just had the edps civil society

61
00:02:24,319 --> 00:02:26,400
summit that was looking into that

62
00:02:26,400 --> 00:02:29,120
specific topic and raising a couple of

63
00:02:29,120 --> 00:02:31,440
points there another community that we

64
00:02:31,440 --> 00:02:34,239
want to look into specifically are sex

65
00:02:34,239 --> 00:02:37,040
workers who need to use online platforms

66
00:02:37,040 --> 00:02:38,480
to advertise their services to

67
00:02:38,480 --> 00:02:40,720
communicate with clients specifically in

68
00:02:40,720 --> 00:02:42,400
times of corona

69
00:02:42,400 --> 00:02:44,480
and who have concerns about their own

70
00:02:44,480 --> 00:02:45,840
safety while

71
00:02:45,840 --> 00:02:48,000
using these platforms

72
00:02:48,000 --> 00:02:50,720
but also about being to some extent

73
00:02:50,720 --> 00:02:53,680
exploited by these platforms for for

74
00:02:53,680 --> 00:02:55,760
advertising purposes by these platforms

75
00:02:55,760 --> 00:02:58,080
for using their own materials but also

76
00:02:58,080 --> 00:03:00,159
are constantly at the risk of just being

77
00:03:00,159 --> 00:03:02,159
shut down from certain platforms by

78
00:03:02,159 --> 00:03:05,360
regulation by

79
00:03:05,360 --> 00:03:07,360
platforms deciding that this kind of

80
00:03:07,360 --> 00:03:09,680
services are not appropriate anymore for

81
00:03:09,680 --> 00:03:11,920
the audience things like that and on

82
00:03:11,920 --> 00:03:14,959
this specific topic we have um lola here

83
00:03:14,959 --> 00:03:17,519
who's a representative of utsopi that's

84
00:03:17,519 --> 00:03:19,920
the belgian sex work community and we

85
00:03:19,920 --> 00:03:22,239
have this uh dr eliza redmiles here who

86
00:03:22,239 --> 00:03:24,879
works at the max planck institute for

87
00:03:24,879 --> 00:03:26,640
software systems and who has a long

88
00:03:26,640 --> 00:03:28,799
experience in working

89
00:03:28,799 --> 00:03:30,959
on security and privacy needs of sex

90
00:03:30,959 --> 00:03:33,360
workers and another community we

91
00:03:33,360 --> 00:03:35,280
actually want to look in are our

92
00:03:35,280 --> 00:03:37,840
children and their interactions with for

93
00:03:37,840 --> 00:03:40,560
example educational platforms or online

94
00:03:40,560 --> 00:03:42,239
gaming platforms

95
00:03:42,239 --> 00:03:44,480
and

96
00:03:45,440 --> 00:03:47,920
how these platforms potentially exploit

97
00:03:47,920 --> 00:03:50,239
data of these subjects and how they

98
00:03:50,239 --> 00:03:53,360
might potentially subject um

99
00:03:53,360 --> 00:03:54,480
um

100
00:03:54,480 --> 00:03:57,439
children to forms of discrimination or

101
00:03:57,439 --> 00:03:59,840
or other forms of exploitation based on

102
00:03:59,840 --> 00:04:01,280
the data traces they leave on these

103
00:04:01,280 --> 00:04:02,400
platforms

104
00:04:02,400 --> 00:04:05,439
we were planning to have professor

105
00:04:05,439 --> 00:04:07,360
patricia garcia here as one of the

106
00:04:07,360 --> 00:04:09,280
speakers from the university of michigan

107
00:04:09,280 --> 00:04:11,280
who has been working with

108
00:04:11,280 --> 00:04:13,840
black girls in educational communities

109
00:04:13,840 --> 00:04:15,760
in the us unfortunately she cannot make

110
00:04:15,760 --> 00:04:17,759
it for a personal and covert related

111
00:04:17,759 --> 00:04:20,320
reasons we still have tommaso kaypaks

112
00:04:20,320 --> 00:04:22,560
here from santa

113
00:04:22,560 --> 00:04:24,479
from san ana and pisa

114
00:04:24,479 --> 00:04:26,560
who has been working partly together

115
00:04:26,560 --> 00:04:28,400
with me on this topic and we'll share a

116
00:04:28,400 --> 00:04:31,759
little bit of their insights on um

117
00:04:31,759 --> 00:04:34,800
data collection in online games and what

118
00:04:34,800 --> 00:04:37,680
that might potentially mean

119
00:04:37,680 --> 00:04:41,199
for children and and to what extent

120
00:04:41,199 --> 00:04:44,160
parents can even protect the data

121
00:04:44,160 --> 00:04:46,400
subjects in that case from app use and

122
00:04:46,400 --> 00:04:48,639
then coming from from these different

123
00:04:48,639 --> 00:04:51,759
points we want to talk about how we see

124
00:04:51,759 --> 00:04:54,400
platform governance and how we want

125
00:04:54,400 --> 00:04:57,199
platforms to protect people's safety

126
00:04:57,199 --> 00:05:00,240
people's well-being and um

127
00:05:00,240 --> 00:05:04,240
cater for their subject rights so my

128
00:05:04,240 --> 00:05:06,240
wish would be since i still don't see

129
00:05:06,240 --> 00:05:08,400
lola in the chat in the audi channel my

130
00:05:08,400 --> 00:05:10,880
wish would be that um tommaso starts

131
00:05:10,880 --> 00:05:12,560
with talking a little bit about what you

132
00:05:12,560 --> 00:05:15,120
work on and what you found out and then

133
00:05:15,120 --> 00:05:16,800
maybe we can switch to lola and get some

134
00:05:16,800 --> 00:05:19,680
hands-on experience on how the situation

135
00:05:19,680 --> 00:05:21,840
looks for sex workers

136
00:05:21,840 --> 00:05:25,520
the muscle the floor is yours

137
00:05:25,520 --> 00:05:27,360
perfect very thank you very much and

138
00:05:27,360 --> 00:05:29,199
tobias for the introduction and thank

139
00:05:29,199 --> 00:05:31,280
you very much to all the panelists

140
00:05:31,280 --> 00:05:34,479
um i feel like what i'm about to say at

141
00:05:34,479 --> 00:05:36,560
least in the beginning is going to sound

142
00:05:36,560 --> 00:05:38,960
quite familiar to many if not most of

143
00:05:38,960 --> 00:05:40,080
you

144
00:05:40,080 --> 00:05:42,320
however the fact that something so

145
00:05:42,320 --> 00:05:44,960
obvious still today must be restated in

146
00:05:44,960 --> 00:05:47,039
january 2022 is pretty much

147
00:05:47,039 --> 00:05:49,199
self-explanatory as to why

148
00:05:49,199 --> 00:05:50,880
it is important indeed to find new

149
00:05:50,880 --> 00:05:53,360
solutions even to all problems

150
00:05:53,360 --> 00:05:56,240
now let me start with the quote

151
00:05:56,240 --> 00:05:59,199
the defining industry of our time is the

152
00:05:59,199 --> 00:06:02,160
capture and resale of

153
00:06:02,160 --> 00:06:04,880
it's not personal data it is capturing

154
00:06:04,880 --> 00:06:07,280
resale of human attention

155
00:06:07,280 --> 00:06:09,280
and these are the team the words of team

156
00:06:09,280 --> 00:06:10,080
wu

157
00:06:10,080 --> 00:06:12,560
who is summarizing the attention economy

158
00:06:12,560 --> 00:06:15,759
we're not data but attention is the new

159
00:06:15,759 --> 00:06:16,720
oil

160
00:06:16,720 --> 00:06:17,440
but

161
00:06:17,440 --> 00:06:20,080
wait a minute we've all been told over

162
00:06:20,080 --> 00:06:22,000
and over again along these years that

163
00:06:22,000 --> 00:06:24,560
data was the new oil so if but if human

164
00:06:24,560 --> 00:06:27,199
attention is in oil what is the role of

165
00:06:27,199 --> 00:06:29,360
data in the attention economy

166
00:06:29,360 --> 00:06:30,639
now

167
00:06:30,639 --> 00:06:33,199
the competition among big tech giants to

168
00:06:33,199 --> 00:06:35,759
predominate in this attention economy

169
00:06:35,759 --> 00:06:38,319
inspired the uh knolls

170
00:06:38,319 --> 00:06:39,759
arms race

171
00:06:39,759 --> 00:06:41,759
to find the most efficient techniques to

172
00:06:41,759 --> 00:06:44,000
engage and preserve users attention and

173
00:06:44,000 --> 00:06:46,240
this is nothing new they use dark

174
00:06:46,240 --> 00:06:49,280
patterns use nudges they use sludges and

175
00:06:49,280 --> 00:06:50,880
all sorts of other forms of manipulation

176
00:06:50,880 --> 00:06:52,160
really

177
00:06:52,160 --> 00:06:54,400
now this arm race

178
00:06:54,400 --> 00:06:57,120
brings up an attention war

179
00:06:57,120 --> 00:07:00,080
and in this potential war digital is

180
00:07:00,080 --> 00:07:02,639
firmly at the center and rights

181
00:07:02,639 --> 00:07:05,039
unfortunately are left at the margins

182
00:07:05,039 --> 00:07:05,840
um

183
00:07:05,840 --> 00:07:08,000
in attention war you can

184
00:07:08,000 --> 00:07:11,360
easily imagine who are the civilians

185
00:07:11,360 --> 00:07:14,160
um to which category will belong amongst

186
00:07:14,160 --> 00:07:15,680
the civilians the casualties

187
00:07:15,680 --> 00:07:18,000
unfortunately and who in the society

188
00:07:18,000 --> 00:07:19,520
together with their rights is left at

189
00:07:19,520 --> 00:07:20,720
the margin

190
00:07:20,720 --> 00:07:21,919
now

191
00:07:21,919 --> 00:07:25,280
the hyper personalization of both dark

192
00:07:25,280 --> 00:07:26,639
pattern which is

193
00:07:26,639 --> 00:07:28,800
what makes us fall in the trap

194
00:07:28,800 --> 00:07:31,120
and of hyper personalization of the

195
00:07:31,120 --> 00:07:33,599
content that's what keeps us in the trap

196
00:07:33,599 --> 00:07:35,599
it's possible thanks to the collection

197
00:07:35,599 --> 00:07:38,720
and analysis of well surprise surprise

198
00:07:38,720 --> 00:07:42,080
gigantic amount of personal information

199
00:07:42,080 --> 00:07:45,759
and that's the answer to our question so

200
00:07:45,759 --> 00:07:48,240
human attention is the oil still

201
00:07:48,240 --> 00:07:50,720
but personal data is the drill that's

202
00:07:50,720 --> 00:07:54,240
used to extract it to extract it

203
00:07:54,240 --> 00:07:55,520
now

204
00:07:55,520 --> 00:07:58,400
um the this economic the whole economic

205
00:07:58,400 --> 00:08:00,319
system is so wide-reaching and so

206
00:08:00,319 --> 00:08:03,280
pervasive that it generated a global

207
00:08:03,280 --> 00:08:06,080
problem really of digital manipulation

208
00:08:06,080 --> 00:08:08,160
digital addiction if you want to know

209
00:08:08,160 --> 00:08:10,479
more about it there's zubov who's

210
00:08:10,479 --> 00:08:12,560
written plenty about it but also like

211
00:08:12,560 --> 00:08:14,639
you know martin like snowden hull

212
00:08:14,639 --> 00:08:17,440
variant and and oh all of those

213
00:08:17,440 --> 00:08:18,319
um

214
00:08:18,319 --> 00:08:19,919
the system is

215
00:08:19,919 --> 00:08:22,319
unfortunately exacerbated at one

216
00:08:22,319 --> 00:08:24,720
paradigmatic commercial example which

217
00:08:24,720 --> 00:08:26,160
also together we've done to be as we

218
00:08:26,160 --> 00:08:28,560
started uh quite uh recently

219
00:08:28,560 --> 00:08:30,479
uh which we call the ultimate data

220
00:08:30,479 --> 00:08:32,559
collection manipulation and addiction

221
00:08:32,559 --> 00:08:33,440
machine

222
00:08:33,440 --> 00:08:36,559
which is uh free-to-play online games

223
00:08:36,559 --> 00:08:37,360
those

224
00:08:37,360 --> 00:08:39,279
many of you call like in the name of

225
00:08:39,279 --> 00:08:40,399
freemiums

226
00:08:40,399 --> 00:08:42,958
so these are games which have a data

227
00:08:42,958 --> 00:08:45,839
driven business model which is based on

228
00:08:45,839 --> 00:08:47,680
fully on personal data

229
00:08:47,680 --> 00:08:50,560
analytics to technically on the one side

230
00:08:50,560 --> 00:08:52,880
by machine learning ai and whatnot and

231
00:08:52,880 --> 00:08:54,959
economically by predatory marketing

232
00:08:54,959 --> 00:08:57,760
tactics even neuromarketing tactics

233
00:08:57,760 --> 00:08:58,560
now

234
00:08:58,560 --> 00:09:01,200
um these online games literally use

235
00:09:01,200 --> 00:09:03,519
thousands of what to call sticky

236
00:09:03,519 --> 00:09:04,480
features

237
00:09:04,480 --> 00:09:08,320
to um hijack users minds um yeah daily

238
00:09:08,320 --> 00:09:11,120
logins straight rewards uh rewards for

239
00:09:11,120 --> 00:09:13,600
ad watching uh you have timed alerts

240
00:09:13,600 --> 00:09:17,040
push notifications the use of red icons

241
00:09:17,040 --> 00:09:19,360
uh summons for when you're already out

242
00:09:19,360 --> 00:09:21,440
of the game that keeps you on the loop

243
00:09:21,440 --> 00:09:23,519
constantly back in the trap stay in the

244
00:09:23,519 --> 00:09:24,399
track

245
00:09:24,399 --> 00:09:26,640
now because freemius are free to play

246
00:09:26,640 --> 00:09:28,320
then of course they're vastly played by

247
00:09:28,320 --> 00:09:30,000
younger children so of course everyone

248
00:09:30,000 --> 00:09:33,120
uses those games but mostly children but

249
00:09:33,120 --> 00:09:35,600
just to sum up so these freemiums are a

250
00:09:35,600 --> 00:09:36,880
paradise

251
00:09:36,880 --> 00:09:39,600
or perhaps a hell for children profiling

252
00:09:39,600 --> 00:09:41,519
children manipulation and children

253
00:09:41,519 --> 00:09:43,200
addiction just

254
00:09:43,200 --> 00:09:45,120
really let it sink in

255
00:09:45,120 --> 00:09:47,680
these are services that are created with

256
00:09:47,680 --> 00:09:50,160
principles of addiction by design not

257
00:09:50,160 --> 00:09:52,399
privacy and compulsion by design in

258
00:09:52,399 --> 00:09:54,959
their core mechanics

259
00:09:54,959 --> 00:09:58,240
and well the risks are pretty high um

260
00:09:58,240 --> 00:10:00,560
children are exposed to psychological

261
00:10:00,560 --> 00:10:04,079
social physical and mental health risks

262
00:10:04,079 --> 00:10:06,480
like not long ago the world health

263
00:10:06,480 --> 00:10:08,079
organization has included gaming

264
00:10:08,079 --> 00:10:09,600
disorder in the international

265
00:10:09,600 --> 00:10:12,800
classification of disorders and diseases

266
00:10:12,800 --> 00:10:14,079
well i

267
00:10:14,079 --> 00:10:16,959
my nephew is only nine years old and he

268
00:10:16,959 --> 00:10:19,680
has been for years the praise of the

269
00:10:19,680 --> 00:10:22,320
googles the metas the ubisoft the roblox

270
00:10:22,320 --> 00:10:24,399
the gotham the gamma whatever you call

271
00:10:24,399 --> 00:10:26,800
them that's feasting on his attention

272
00:10:26,800 --> 00:10:28,560
and these are the most of course

273
00:10:28,560 --> 00:10:30,399
critical years where his upbringing and

274
00:10:30,399 --> 00:10:32,560
and that's without even knowing it and

275
00:10:32,560 --> 00:10:34,399
his parents knowing it

276
00:10:34,399 --> 00:10:36,320
and um with repercussions that will

277
00:10:36,320 --> 00:10:39,360
perhaps endure forever if you've written

278
00:10:39,360 --> 00:10:41,760
read the permanent record now the power

279
00:10:41,760 --> 00:10:43,760
imbalance is really what's shocking me

280
00:10:43,760 --> 00:10:45,519
the most uh these are

281
00:10:45,519 --> 00:10:47,600
to rephrase uh wilson god-like

282
00:10:47,600 --> 00:10:50,320
technologies taking advantage of

283
00:10:50,320 --> 00:10:53,839
children's paladitic emotions

284
00:10:53,839 --> 00:10:56,399
my question is as as a lawyer and a

285
00:10:56,399 --> 00:10:58,800
researcher in this is how do we even get

286
00:10:58,800 --> 00:10:59,600
there

287
00:10:59,600 --> 00:11:02,240
so as for law well the practical

288
00:11:02,240 --> 00:11:04,480
implementations in the eu human rights

289
00:11:04,480 --> 00:11:06,880
but also consumer law and up until

290
00:11:06,880 --> 00:11:09,440
recently this is the service regulation

291
00:11:09,440 --> 00:11:11,839
have failed the test of digital reality

292
00:11:11,839 --> 00:11:15,920
mostly due to i'd say three plus reasons

293
00:11:15,920 --> 00:11:18,480
one is the discounting of negative

294
00:11:18,480 --> 00:11:21,120
effects on children of the future of

295
00:11:21,120 --> 00:11:22,560
children

296
00:11:22,560 --> 00:11:24,320
one other one and we've been discussing

297
00:11:24,320 --> 00:11:26,800
this today it's the overestimation of

298
00:11:26,800 --> 00:11:29,279
supervisory authorities capabilities

299
00:11:29,279 --> 00:11:31,680
versus the in well on the one hand the

300
00:11:31,680 --> 00:11:33,519
data protection is law of everything as

301
00:11:33,519 --> 00:11:35,200
portable would say it and the

302
00:11:35,200 --> 00:11:37,120
enforcement paralysis that we've seen in

303
00:11:37,120 --> 00:11:38,560
recent years

304
00:11:38,560 --> 00:11:40,720
which are of course linked

305
00:11:40,720 --> 00:11:41,760
um

306
00:11:41,760 --> 00:11:44,480
a general fixation on risk-based

307
00:11:44,480 --> 00:11:47,200
regulation uh which relies on notice and

308
00:11:47,200 --> 00:11:49,760
consent which does not account for well

309
00:11:49,760 --> 00:11:52,079
the priority problem the privacy paradox

310
00:11:52,079 --> 00:11:54,240
the privacy calculus which is discounted

311
00:11:54,240 --> 00:11:56,720
by cognitive biases and

312
00:11:56,720 --> 00:11:58,320
what's most interesting to me is in the

313
00:11:58,320 --> 00:12:00,320
words of sartori is that the fact that

314
00:12:00,320 --> 00:12:03,600
data subjects opportunity to to consent

315
00:12:03,600 --> 00:12:05,600
to risks that they do not understand for

316
00:12:05,600 --> 00:12:08,000
good reasons is not an asset for them

317
00:12:08,000 --> 00:12:10,399
but a liability

318
00:12:10,399 --> 00:12:11,450
but there's one more thing

319
00:12:11,450 --> 00:12:13,600
[Music]

320
00:12:13,600 --> 00:12:16,160
we claim that the failure is due to a

321
00:12:16,160 --> 00:12:19,120
fundamental error in the detection of

322
00:12:19,120 --> 00:12:20,800
the asset to protect

323
00:12:20,800 --> 00:12:23,279
this asset in fact is not

324
00:12:23,279 --> 00:12:25,519
the human right to privacy

325
00:12:25,519 --> 00:12:27,360
let alone data protection but something

326
00:12:27,360 --> 00:12:29,600
that goes beyond privacy

327
00:12:29,600 --> 00:12:30,320
now

328
00:12:30,320 --> 00:12:32,639
why is that and how do we fix this

329
00:12:32,639 --> 00:12:35,360
a hint to the solution was indicated by

330
00:12:35,360 --> 00:12:38,720
the the council of europe in 2019 when

331
00:12:38,720 --> 00:12:40,000
they produce a declaration on the

332
00:12:40,000 --> 00:12:42,399
manipulative capabilities of algorithm

333
00:12:42,399 --> 00:12:44,560
processes and i'm going to read

334
00:12:44,560 --> 00:12:46,959
about it so they say fine-grained

335
00:12:46,959 --> 00:12:48,880
subconscious and personalized level of

336
00:12:48,880 --> 00:12:51,040
algorithm persuasion we have significant

337
00:12:51,040 --> 00:12:53,519
effects on the cognitive autonomy on the

338
00:12:53,519 --> 00:12:55,600
individuals

339
00:12:55,600 --> 00:12:57,519
which may weaken the exercise and

340
00:12:57,519 --> 00:12:59,920
enjoyment of individual human rights and

341
00:12:59,920 --> 00:13:01,920
to the corrosion of the very foundation

342
00:13:01,920 --> 00:13:04,000
of the council of europe

343
00:13:04,000 --> 00:13:04,800
now

344
00:13:04,800 --> 00:13:08,560
um what is the solution well in in my

345
00:13:08,560 --> 00:13:11,440
opinion and not only my opinion uh susie

346
00:13:11,440 --> 00:13:13,279
allegri is another one that has this

347
00:13:13,279 --> 00:13:15,440
opinion before me probably is that the

348
00:13:15,440 --> 00:13:17,040
right to privacy as in surface

349
00:13:17,040 --> 00:13:19,360
determination the right to autonomy when

350
00:13:19,360 --> 00:13:22,160
applied to certain kinds of digital

351
00:13:22,160 --> 00:13:24,480
manipulation and addiction

352
00:13:24,480 --> 00:13:26,560
shall be upgraded

353
00:13:26,560 --> 00:13:28,480
read under the lenses of the right to

354
00:13:28,480 --> 00:13:30,959
freedom of thought

355
00:13:30,959 --> 00:13:32,320
of course it is

356
00:13:32,320 --> 00:13:34,399
perhaps too naive right now to think

357
00:13:34,399 --> 00:13:35,760
that okay such a grace should

358
00:13:35,760 --> 00:13:38,480
immediately apply to everyone without

359
00:13:38,480 --> 00:13:39,519
overturning the surveillance

360
00:13:39,519 --> 00:13:41,440
capitalistic system we all know it's

361
00:13:41,440 --> 00:13:44,399
gonna it's here to stay for a while

362
00:13:44,399 --> 00:13:47,440
anyhow um during times of war the

363
00:13:47,440 --> 00:13:49,360
attention were we should at least maybe

364
00:13:49,360 --> 00:13:51,199
have the decency

365
00:13:51,199 --> 00:13:54,000
to save the most vulnerable which

366
00:13:54,000 --> 00:13:56,000
in my understanding amongst which at

367
00:13:56,000 --> 00:13:57,519
least are children

368
00:13:57,519 --> 00:13:58,320
now

369
00:13:58,320 --> 00:13:59,839
um the committee on the rights of the

370
00:13:59,839 --> 00:14:03,040
child in general comment 25 it says that

371
00:14:03,040 --> 00:14:05,120
it state that states parties should

372
00:14:05,120 --> 00:14:06,160
respect

373
00:14:06,160 --> 00:14:07,680
the right of the child to freedom of

374
00:14:07,680 --> 00:14:08,800
thought

375
00:14:08,800 --> 00:14:10,959
state parties should prohibit practices

376
00:14:10,959 --> 00:14:12,880
that manipulate or interfere with

377
00:14:12,880 --> 00:14:14,880
children's right to freedom of thought

378
00:14:14,880 --> 00:14:16,399
and this is the first time in which we

379
00:14:16,399 --> 00:14:18,560
are talking about freedom of thought in

380
00:14:18,560 --> 00:14:21,279
you um in the uncrc

381
00:14:21,279 --> 00:14:22,560
now

382
00:14:22,560 --> 00:14:24,800
to to to end

383
00:14:24,800 --> 00:14:26,560
the correction for tuner against digital

384
00:14:26,560 --> 00:14:28,959
manipulation addiction is the absolute

385
00:14:28,959 --> 00:14:30,639
human right of freedom of thought and

386
00:14:30,639 --> 00:14:33,040
make no mistake privacy is not an

387
00:14:33,040 --> 00:14:35,760
absolute right it's only qualified so

388
00:14:35,760 --> 00:14:37,680
because because freedom of thought is

389
00:14:37,680 --> 00:14:40,079
absolute it cannot lawfully be

390
00:14:40,079 --> 00:14:42,639
interfered with no matter how important

391
00:14:42,639 --> 00:14:44,800
the the public interest is and no matter

392
00:14:44,800 --> 00:14:46,079
what other

393
00:14:46,079 --> 00:14:48,160
qualified human rights will the the big

394
00:14:48,160 --> 00:14:50,800
tech come out with to legitimize

395
00:14:50,800 --> 00:14:52,639
children manipulation

396
00:14:52,639 --> 00:14:54,880
and and that's pretty much what i think

397
00:14:54,880 --> 00:14:58,279
about the topic

398
00:14:59,920 --> 00:15:02,079
okay that's a good starting point

399
00:15:02,079 --> 00:15:04,720
um i i'm so we have lola back so i'm

400
00:15:04,720 --> 00:15:06,160
really happy we have a pretty much

401
00:15:06,160 --> 00:15:08,000
complete panel thanks a lot for being

402
00:15:08,000 --> 00:15:08,800
here

403
00:15:08,800 --> 00:15:12,480
um i think so after having heard

404
00:15:12,480 --> 00:15:15,199
tommaso's opinion on

405
00:15:15,199 --> 00:15:17,199
children protection online games i think

406
00:15:17,199 --> 00:15:20,160
i would want to have a round with lola

407
00:15:20,160 --> 00:15:21,120
on

408
00:15:21,120 --> 00:15:24,160
sex workers on their perceived and and

409
00:15:24,160 --> 00:15:25,600
real

410
00:15:25,600 --> 00:15:27,360
privacy and security requirements and

411
00:15:27,360 --> 00:15:30,160
how you see platforms and how you you

412
00:15:30,160 --> 00:15:31,440
you feel

413
00:15:31,440 --> 00:15:33,519
that platforms protect your safety or do

414
00:15:33,519 --> 00:15:37,519
not so load up the floor is yours

415
00:15:38,320 --> 00:15:41,560
you're muted

416
00:15:46,160 --> 00:15:49,040
you're muted lola

417
00:15:53,360 --> 00:15:56,160
yes i'm unmuted now

418
00:15:56,160 --> 00:15:58,079
i'm so sorry

419
00:15:58,079 --> 00:16:00,240
uh

420
00:16:00,240 --> 00:16:03,600
i have a way with technology that it

421
00:16:03,600 --> 00:16:06,000
doesn't always work out with me

422
00:16:06,000 --> 00:16:09,839
so thank you antobias um my name is lola

423
00:16:09,839 --> 00:16:12,240
and i'm speaking for it sophie

424
00:16:12,240 --> 00:16:14,560
mitsubis is a union in support of sex

425
00:16:14,560 --> 00:16:18,240
worker rights in belgium since 2015

426
00:16:18,240 --> 00:16:21,120
run by sex workers and allies

427
00:16:21,120 --> 00:16:23,279
the work we do consists of a political

428
00:16:23,279 --> 00:16:25,600
work concerning the decriminalization of

429
00:16:25,600 --> 00:16:27,440
sex work in belgium

430
00:16:27,440 --> 00:16:29,360
and also providing social cynical

431
00:16:29,360 --> 00:16:31,199
support in different places around

432
00:16:31,199 --> 00:16:35,120
belgium brussels and flanders

433
00:16:35,600 --> 00:16:37,680
um as an organization we don't really

434
00:16:37,680 --> 00:16:41,759
have um researched expertise

435
00:16:41,759 --> 00:16:44,160
on privacy and safety

436
00:16:44,160 --> 00:16:44,959
yet

437
00:16:44,959 --> 00:16:47,600
uh so rather a basic understanding of

438
00:16:47,600 --> 00:16:50,959
how how it's lived and how digital

439
00:16:50,959 --> 00:16:53,440
spaces are perceived safe or not for sex

440
00:16:53,440 --> 00:16:54,800
workers

441
00:16:54,800 --> 00:16:57,120
um so doing the field work

442
00:16:57,120 --> 00:16:59,519
and since sex workers are experts of

443
00:16:59,519 --> 00:17:01,199
their own reality i'm going to speak

444
00:17:01,199 --> 00:17:03,120
from this perspective

445
00:17:03,120 --> 00:17:04,640
based on the questions we get to deal

446
00:17:04,640 --> 00:17:08,240
with in the community work

447
00:17:09,359 --> 00:17:12,480
i think that internet also has provided

448
00:17:12,480 --> 00:17:15,839
substantial benefits for sex workers

449
00:17:15,839 --> 00:17:18,480
in general it made it easier for people

450
00:17:18,480 --> 00:17:20,959
more people industry to

451
00:17:20,959 --> 00:17:23,039
find each other and fully organize their

452
00:17:23,039 --> 00:17:26,160
own work and logistics

453
00:17:26,160 --> 00:17:28,559
downside on the cyber workspace for sex

454
00:17:28,559 --> 00:17:31,840
workers are mostly matters of access

455
00:17:31,840 --> 00:17:34,000
privacy safety

456
00:17:34,000 --> 00:17:37,120
algorithmic biases that kind of excludes

457
00:17:37,120 --> 00:17:38,960
employees

458
00:17:38,960 --> 00:17:40,720
sex worker businesses

459
00:17:40,720 --> 00:17:43,520
so this is an impact we should also be

460
00:17:43,520 --> 00:17:44,880
studying on

461
00:17:44,880 --> 00:17:47,840
belgian terms

462
00:17:48,240 --> 00:17:50,880
and yes of course sex worker identities

463
00:17:50,880 --> 00:17:54,240
are dependent on the internet

464
00:17:54,320 --> 00:17:57,120
as a site for um like

465
00:17:57,120 --> 00:17:59,120
informational exchange

466
00:17:59,120 --> 00:18:00,799
to gather

467
00:18:00,799 --> 00:18:02,880
find community to use practical tools

468
00:18:02,880 --> 00:18:05,120
for payments digital communication with

469
00:18:05,120 --> 00:18:08,080
clients self advertisements

470
00:18:08,080 --> 00:18:11,919
so how do we kind of keep it clean

471
00:18:11,919 --> 00:18:12,919
how do we prevent cross

472
00:18:12,919 --> 00:18:15,360
cross-contamination across different

473
00:18:15,360 --> 00:18:17,200
accounts and devices

474
00:18:17,200 --> 00:18:20,080
how do we minimize the likelihood of our

475
00:18:20,080 --> 00:18:21,919
personal information

476
00:18:21,919 --> 00:18:24,880
being leaked and shared

477
00:18:24,880 --> 00:18:27,440
so in taking care of our online behavior

478
00:18:27,440 --> 00:18:29,840
as sex workers we kind of want to secure

479
00:18:29,840 --> 00:18:32,799
own sex worker identities

480
00:18:32,799 --> 00:18:35,120
but also secure the identity of our

481
00:18:35,120 --> 00:18:37,200
clients who often have as because we

482
00:18:37,200 --> 00:18:40,080
wish in staying anonymous

483
00:18:40,080 --> 00:18:41,679
we want to secure

484
00:18:41,679 --> 00:18:43,760
the community and our colleague workers

485
00:18:43,760 --> 00:18:45,919
and also secure third parties like

486
00:18:45,919 --> 00:18:49,440
family and friends co-workers

487
00:18:49,440 --> 00:18:51,440
from potential exposure and

488
00:18:51,440 --> 00:18:53,440
stigmatization

489
00:18:53,440 --> 00:18:55,600
yeah definitely

490
00:18:55,600 --> 00:18:58,240
so yeah little tips i think of and i

491
00:18:58,240 --> 00:19:01,200
give the people i work with are exactly

492
00:19:01,200 --> 00:19:03,120
also using different browsers for

493
00:19:03,120 --> 00:19:04,960
different profiles

494
00:19:04,960 --> 00:19:07,280
uh trying not to share your location

495
00:19:07,280 --> 00:19:09,919
with your apps too many times use and

496
00:19:09,919 --> 00:19:12,000
encrypted communication

497
00:19:12,000 --> 00:19:15,039
try to not mix so much your working

498
00:19:15,039 --> 00:19:18,480
profiles and your private devices

499
00:19:18,480 --> 00:19:21,840
be mindful about

500
00:19:22,720 --> 00:19:25,280
how and where you use your legal name on

501
00:19:25,280 --> 00:19:27,120
social media

502
00:19:27,120 --> 00:19:30,160
so i think it's very basic um

503
00:19:30,160 --> 00:19:32,480
prevention and protection

504
00:19:32,480 --> 00:19:36,320
as i say we're not really experts um

505
00:19:36,320 --> 00:19:37,520
i'm not yet

506
00:19:37,520 --> 00:19:41,679
the sexy tech tech nerds i wish to be

507
00:19:41,679 --> 00:19:42,880
um

508
00:19:42,880 --> 00:19:44,000
but yes

509
00:19:44,000 --> 00:19:46,640
sex work is in bodywork

510
00:19:46,640 --> 00:19:49,840
so for many workers it means a good

511
00:19:49,840 --> 00:19:51,520
separation of the work in a private

512
00:19:51,520 --> 00:19:52,720
sphere

513
00:19:52,720 --> 00:19:54,880
and that's a boundary

514
00:19:54,880 --> 00:19:57,200
between the physical and digital that

515
00:19:57,200 --> 00:19:59,840
actually overlaps while working which

516
00:19:59,840 --> 00:20:01,760
makes it

517
00:20:01,760 --> 00:20:03,280
not easy to

518
00:20:03,280 --> 00:20:06,400
protect your information either

519
00:20:06,400 --> 00:20:09,840
so in our physical spaces when we host

520
00:20:09,840 --> 00:20:12,480
clients at home for example we also go

521
00:20:12,480 --> 00:20:13,760
through the process of removing

522
00:20:13,760 --> 00:20:16,320
sensitive information

523
00:20:16,320 --> 00:20:19,280
covering up photos covering up letters

524
00:20:19,280 --> 00:20:21,120
official documents etc everything that

525
00:20:21,120 --> 00:20:23,600
gives away like identity so people

526
00:20:23,600 --> 00:20:25,840
cannot like name search and find us on

527
00:20:25,840 --> 00:20:27,600
our private profiles

528
00:20:27,600 --> 00:20:29,600
and this is uh similar to how we should

529
00:20:29,600 --> 00:20:31,039
kind of behave

530
00:20:31,039 --> 00:20:32,559
online

531
00:20:32,559 --> 00:20:34,400
where we need to practice a good um

532
00:20:34,400 --> 00:20:35,310
digital hygiene

533
00:20:35,310 --> 00:20:36,799
[Music]

534
00:20:36,799 --> 00:20:39,919
um yeah for example um we had a sex

535
00:20:39,919 --> 00:20:42,960
worker whose clients did find out their

536
00:20:42,960 --> 00:20:44,559
legal name

537
00:20:44,559 --> 00:20:45,760
um

538
00:20:45,760 --> 00:20:48,640
so next what happened is

539
00:20:48,640 --> 00:20:50,400
they got

540
00:20:50,400 --> 00:20:53,360
announced presents at their address

541
00:20:53,360 --> 00:20:55,600
this is an example in the physical world

542
00:20:55,600 --> 00:20:59,039
but an online scenario is

543
00:20:59,039 --> 00:21:01,840
where a client's fixation for sex worker

544
00:21:01,840 --> 00:21:03,520
who is a member of us

545
00:21:03,520 --> 00:21:06,320
led to threatening to expose them which

546
00:21:06,320 --> 00:21:07,520
declined them

547
00:21:07,520 --> 00:21:10,559
pursued by creating a fake profile

548
00:21:10,559 --> 00:21:14,000
facebook profile and a fake

549
00:21:14,159 --> 00:21:17,280
facebook page and it led to the

550
00:21:17,280 --> 00:21:20,480
profile being uh getting rid of but the

551
00:21:20,480 --> 00:21:22,720
page we could not delete because of

552
00:21:22,720 --> 00:21:25,360
different policy or something so it's

553
00:21:25,360 --> 00:21:27,520
a lot of difficulties

554
00:21:27,520 --> 00:21:29,600
in these things

555
00:21:29,600 --> 00:21:31,280
but these are still very up-to-date

556
00:21:31,280 --> 00:21:32,480
scenarios

557
00:21:32,480 --> 00:21:34,480
workers come to us about rather than

558
00:21:34,480 --> 00:21:38,640
official instances like police and such

559
00:21:39,039 --> 00:21:41,280
um

560
00:21:41,760 --> 00:21:44,480
yeah the general fears and concerns from

561
00:21:44,480 --> 00:21:45,919
the community

562
00:21:45,919 --> 00:21:48,480
um stem from the fear of being boxed

563
00:21:48,480 --> 00:21:50,400
having your uh

564
00:21:50,400 --> 00:21:52,799
having the laws of privacy and having

565
00:21:52,799 --> 00:21:55,280
your personal information shared being

566
00:21:55,280 --> 00:21:58,159
outed as a sex worker

567
00:21:58,159 --> 00:21:59,679
so in terms of prevention and harm

568
00:21:59,679 --> 00:22:01,760
reduction this is something social

569
00:22:01,760 --> 00:22:03,840
supports organizations should be

570
00:22:03,840 --> 00:22:06,720
definitely informed about

571
00:22:06,720 --> 00:22:08,960
and fear of losing privacy is also

572
00:22:08,960 --> 00:22:10,720
reflection of a state of surveillance

573
00:22:10,720 --> 00:22:13,280
and censorship on which sex workers

574
00:22:13,280 --> 00:22:14,799
operates

575
00:22:14,799 --> 00:22:17,520
thinking about losing access to services

576
00:22:17,520 --> 00:22:20,640
deep blatant deep platformation

577
00:22:20,640 --> 00:22:21,600
by

578
00:22:21,600 --> 00:22:22,960
algorithms

579
00:22:22,960 --> 00:22:25,200
and as you know algorithms also have

580
00:22:25,200 --> 00:22:27,520
proved kind of like uh

581
00:22:27,520 --> 00:22:29,919
to like a more fiber so it's really hard

582
00:22:29,919 --> 00:22:34,240
by the rules they um they make up if

583
00:22:34,240 --> 00:22:37,280
um algorithms are not able to distribute

584
00:22:37,280 --> 00:22:40,240
distinguish like nuances between what is

585
00:22:40,240 --> 00:22:44,000
pleasurable and what is problematic

586
00:22:46,960 --> 00:22:48,240
same

587
00:22:48,240 --> 00:22:50,080
fears for

588
00:22:50,080 --> 00:22:52,320
financial systems

589
00:22:52,320 --> 00:22:55,280
digital financial transaction

590
00:22:55,280 --> 00:22:57,039
um

591
00:22:57,039 --> 00:22:58,799
to be email services and apps are

592
00:22:58,799 --> 00:23:01,039
willingly wanting to be linked to a sex

593
00:23:01,039 --> 00:23:02,559
worker's income

594
00:23:02,559 --> 00:23:05,200
so that makes sex workers often

595
00:23:05,200 --> 00:23:07,280
suspicious of using digital payment

596
00:23:07,280 --> 00:23:08,640
platforms

597
00:23:08,640 --> 00:23:10,320
since it's also linked to our personal

598
00:23:10,320 --> 00:23:12,080
information

599
00:23:12,080 --> 00:23:13,280
the fear is

600
00:23:13,280 --> 00:23:14,880
what if

601
00:23:14,880 --> 00:23:16,880
all of our data is getting collected and

602
00:23:16,880 --> 00:23:20,480
sold to someone who is going to out us

603
00:23:20,480 --> 00:23:23,039
what if our activities are being

604
00:23:23,039 --> 00:23:25,360
monitored what if

605
00:23:25,360 --> 00:23:27,679
i will lose my social support because of

606
00:23:27,679 --> 00:23:30,240
that what if i'm committing federal

607
00:23:30,240 --> 00:23:34,000
crime what if um a lot of questions so

608
00:23:34,000 --> 00:23:35,520
just to illustrate that even like

609
00:23:35,520 --> 00:23:38,960
mundane tasks like banking and payments

610
00:23:38,960 --> 00:23:40,240
actually have

611
00:23:40,240 --> 00:23:42,080
a way to them

612
00:23:42,080 --> 00:23:43,840
which is very annoying

613
00:23:43,840 --> 00:23:46,000
a lot

614
00:23:46,000 --> 00:23:48,400
um

615
00:23:48,640 --> 00:23:51,039
yeah just to

616
00:23:51,039 --> 00:23:53,520
highlight that safety in all means is

617
00:23:53,520 --> 00:23:56,000
something sex workers are very uh

618
00:23:56,000 --> 00:23:58,240
concerned occupied with

619
00:23:58,240 --> 00:23:59,840
you just want to have a stress-free and

620
00:23:59,840 --> 00:24:01,440
healthy and

621
00:24:01,440 --> 00:24:03,520
normal life and safety in the fields

622
00:24:03,520 --> 00:24:05,679
will mean many different things to many

623
00:24:05,679 --> 00:24:07,679
different people

624
00:24:07,679 --> 00:24:10,080
considering all of the diversity in

625
00:24:10,080 --> 00:24:13,279
identities we want to protect

626
00:24:13,279 --> 00:24:16,640
and the anonymity remaining anonymous is

627
00:24:16,640 --> 00:24:19,120
one big way to do so i think that really

628
00:24:19,120 --> 00:24:20,640
helps

629
00:24:20,640 --> 00:24:22,480
as a protection

630
00:24:22,480 --> 00:24:24,559
and it's not just

631
00:24:24,559 --> 00:24:26,880
a brainless action it's actually whole

632
00:24:26,880 --> 00:24:28,320
work on itself

633
00:24:28,320 --> 00:24:29,840
um

634
00:24:29,840 --> 00:24:32,720
remaining privates

635
00:24:32,720 --> 00:24:33,840
because we

636
00:24:33,840 --> 00:24:36,480
sex workers just also use a lot of

637
00:24:36,480 --> 00:24:39,520
different devices for a lot of different

638
00:24:39,520 --> 00:24:41,760
accounts like email accounts social

639
00:24:41,760 --> 00:24:44,000
media accounts sex worker profiles kinky

640
00:24:44,000 --> 00:24:45,840
profiles payment process all these

641
00:24:45,840 --> 00:24:47,840
things and we reach out to a lot of

642
00:24:47,840 --> 00:24:49,520
different people

643
00:24:49,520 --> 00:24:52,400
between clients um

644
00:24:52,400 --> 00:24:54,480
our community again or

645
00:24:54,480 --> 00:24:56,960
personal spheres so that leaves light

646
00:24:56,960 --> 00:24:59,760
behind a lot of choices

647
00:24:59,760 --> 00:25:01,840
meaning a lot of data needs to be

648
00:25:01,840 --> 00:25:04,399
protected

649
00:25:04,640 --> 00:25:05,760
yeah

650
00:25:05,760 --> 00:25:08,559
how can technology become beneficial

651
00:25:08,559 --> 00:25:10,960
towards seeing um freeing futures for

652
00:25:10,960 --> 00:25:13,279
six work and help creates

653
00:25:13,279 --> 00:25:15,440
six positive spaces online

654
00:25:15,440 --> 00:25:16,880
i do wonder

655
00:25:16,880 --> 00:25:19,440
because i don't don't have answers

656
00:25:19,440 --> 00:25:22,240
i just work in the fields

657
00:25:22,240 --> 00:25:23,440
i think of

658
00:25:23,440 --> 00:25:26,159
definitely super secure and stable

659
00:25:26,159 --> 00:25:29,039
platforms

660
00:25:29,039 --> 00:25:32,320
again payments secure secure payments

661
00:25:32,320 --> 00:25:34,880
making sure you are getting paid

662
00:25:34,880 --> 00:25:37,760
and not being flagged by your bank

663
00:25:37,760 --> 00:25:39,360
i think of

664
00:25:39,360 --> 00:25:41,120
it could be nice to have some kind of

665
00:25:41,120 --> 00:25:43,760
like a mutual feedback with the client

666
00:25:43,760 --> 00:25:45,919
and the worker where you can leave

667
00:25:45,919 --> 00:25:47,520
both like positive and negative feedback

668
00:25:47,520 --> 00:25:48,960
kind of like

669
00:25:48,960 --> 00:25:51,039
you can do a self screening in who you

670
00:25:51,039 --> 00:25:53,520
would like to work with

671
00:25:53,520 --> 00:25:56,720
of course not everyone is in a position

672
00:25:56,720 --> 00:25:59,440
to deny

673
00:25:59,440 --> 00:26:01,600
deny clients

674
00:26:01,600 --> 00:26:03,760
i think what's also important is a

675
00:26:03,760 --> 00:26:07,039
nuance in flagging making sure not

676
00:26:07,039 --> 00:26:08,840
we don't

677
00:26:08,840 --> 00:26:11,840
see threats of violence

678
00:26:11,840 --> 00:26:14,000
the same way as a client not showing up

679
00:26:14,000 --> 00:26:15,840
which is also very annoying and happens

680
00:26:15,840 --> 00:26:18,000
so often and you lose time and money

681
00:26:18,000 --> 00:26:19,520
over it especially when you're the one

682
00:26:19,520 --> 00:26:21,840
who's moving towards the space but it's

683
00:26:21,840 --> 00:26:25,600
not the same way we should alarm

684
00:26:25,600 --> 00:26:28,400
these profiles i think of a moderation

685
00:26:28,400 --> 00:26:30,960
on platforms

686
00:26:30,960 --> 00:26:32,480
red lights actually doing a really good

687
00:26:32,480 --> 00:26:34,159
job on this

688
00:26:34,159 --> 00:26:35,039
they're

689
00:26:35,039 --> 00:26:36,960
also screening whoever is underage

690
00:26:36,960 --> 00:26:38,960
filtering them out

691
00:26:38,960 --> 00:26:40,640
going against

692
00:26:40,640 --> 00:26:43,279
forms of exploitation and harm

693
00:26:43,279 --> 00:26:44,240
so

694
00:26:44,240 --> 00:26:47,760
monitoring to have a safe space to

695
00:26:47,760 --> 00:26:50,320
find your clients at communicate you

696
00:26:50,320 --> 00:26:54,000
know like your advertisements

697
00:26:54,080 --> 00:26:56,399
um

698
00:26:56,480 --> 00:26:59,360
so yeah this is very general i think

699
00:26:59,360 --> 00:27:01,120
um

700
00:27:01,120 --> 00:27:03,279
based on the most

701
00:27:03,279 --> 00:27:05,919
fears that come up definitely payments

702
00:27:05,919 --> 00:27:08,320
privacy and such um

703
00:27:08,320 --> 00:27:11,440
and now i thought about a bit

704
00:27:11,440 --> 00:27:12,240
my

705
00:27:12,240 --> 00:27:14,000
about my position

706
00:27:14,000 --> 00:27:16,720
um doing community work in sop i think

707
00:27:16,720 --> 00:27:18,240
it is

708
00:27:18,240 --> 00:27:20,880
good for me to or for us to start think

709
00:27:20,880 --> 00:27:23,600
of response plan

710
00:27:23,600 --> 00:27:25,440
um think about

711
00:27:25,440 --> 00:27:27,360
what do we want to protect who do we

712
00:27:27,360 --> 00:27:29,200
want to protect it from

713
00:27:29,200 --> 00:27:31,440
what are the implications of having that

714
00:27:31,440 --> 00:27:33,120
information shared

715
00:27:33,120 --> 00:27:34,720
what are the risks

716
00:27:34,720 --> 00:27:36,399
what are we going to take seriously and

717
00:27:36,399 --> 00:27:38,959
what not

718
00:27:40,399 --> 00:27:43,439
and really help

719
00:27:45,120 --> 00:27:47,200
i mean the the legal

720
00:27:47,200 --> 00:27:48,960
status of sex work in belgium is

721
00:27:48,960 --> 00:27:51,679
non-existent so it's not that there's

722
00:27:51,679 --> 00:27:54,880
many ways we can help ourselves

723
00:27:54,880 --> 00:27:57,520
um since we have a tolerated status of

724
00:27:57,520 --> 00:27:58,720
sex work

725
00:27:58,720 --> 00:28:01,919
a decriminalization would already be

726
00:28:01,919 --> 00:28:03,760
would be heaven a lot of more

727
00:28:03,760 --> 00:28:07,120
possibilities in being safe

728
00:28:08,080 --> 00:28:09,440
what also could be good for

729
00:28:09,440 --> 00:28:11,200
organizations like us

730
00:28:11,200 --> 00:28:13,760
is collaboration in

731
00:28:13,760 --> 00:28:16,559
hosting workshops for sex workers and

732
00:28:16,559 --> 00:28:19,279
gaining more insights in crypto payments

733
00:28:19,279 --> 00:28:22,320
everything like with tokens uh

734
00:28:22,320 --> 00:28:23,679
and

735
00:28:23,679 --> 00:28:25,039
yeah yeah

736
00:28:25,039 --> 00:28:27,120
it's online

737
00:28:27,120 --> 00:28:29,120
thank you interesting perspectives very

738
00:28:29,120 --> 00:28:31,600
personal perspectives as well um maybe

739
00:28:31,600 --> 00:28:33,440
if we now move to eliza we can take a

740
00:28:33,440 --> 00:28:36,159
step back because you have maybe data on

741
00:28:36,159 --> 00:28:37,840
the bigger picture

742
00:28:37,840 --> 00:28:39,919
what happens international on the on the

743
00:28:39,919 --> 00:28:41,760
sex worker scene and how people protect

744
00:28:41,760 --> 00:28:44,640
themselves and what the

745
00:28:44,640 --> 00:28:47,360
safety and and and privacy requirements

746
00:28:47,360 --> 00:28:48,960
are there

747
00:28:48,960 --> 00:28:51,039
yeah absolutely um

748
00:28:51,039 --> 00:28:53,120
yeah so i wanted to pick up a couple of

749
00:28:53,120 --> 00:28:55,679
threads um that lola has brought up and

750
00:28:55,679 --> 00:28:57,440
so the context

751
00:28:57,440 --> 00:28:59,760
for what i'll speak about is some of the

752
00:28:59,760 --> 00:29:02,240
empirical work in our own group which

753
00:29:02,240 --> 00:29:03,679
consists of both flex working

754
00:29:03,679 --> 00:29:05,840
researchers as well as allies who are

755
00:29:05,840 --> 00:29:07,760
academic researchers

756
00:29:07,760 --> 00:29:10,480
and we have studied sex workers in the

757
00:29:10,480 --> 00:29:13,919
eu as well as um sex workers who do work

758
00:29:13,919 --> 00:29:16,720
in the u.s although uh primarily that

759
00:29:16,720 --> 00:29:18,480
has been with folks who have switched to

760
00:29:18,480 --> 00:29:21,760
online work um in the u.s context

761
00:29:21,760 --> 00:29:23,919
um so the first part was kind of this

762
00:29:23,919 --> 00:29:26,320
piece of of the de-platforming and i

763
00:29:26,320 --> 00:29:27,440
think for

764
00:29:27,440 --> 00:29:29,200
some of the folks in the panel like one

765
00:29:29,200 --> 00:29:31,200
of the questions i often get is sort of

766
00:29:31,200 --> 00:29:32,720
what is the

767
00:29:32,720 --> 00:29:35,200
the regulatory framework right that sort

768
00:29:35,200 --> 00:29:37,679
of leads to this d platforming and and

769
00:29:37,679 --> 00:29:40,080
lola mentioned like the moral encoding

770
00:29:40,080 --> 00:29:42,080
and these algorithms right and a lot of

771
00:29:42,080 --> 00:29:44,799
times um not in all cases but in the

772
00:29:44,799 --> 00:29:47,200
case of a lot of large platforms so if

773
00:29:47,200 --> 00:29:49,200
we think about paypal or we think about

774
00:29:49,200 --> 00:29:51,760
facebook we think about airbnb

775
00:29:51,760 --> 00:29:53,679
these are platforms that started in the

776
00:29:53,679 --> 00:29:56,720
us right and so a lot of times the u.s

777
00:29:56,720 --> 00:29:59,679
um internet regulation context can

778
00:29:59,679 --> 00:30:03,120
influence how these platforms um react

779
00:30:03,120 --> 00:30:05,279
and so there's sort of this u.s moral

780
00:30:05,279 --> 00:30:06,640
encoding

781
00:30:06,640 --> 00:30:09,679
that gets put in these platforms um

782
00:30:09,679 --> 00:30:10,559
and

783
00:30:10,559 --> 00:30:13,120
that means that people might not have

784
00:30:13,120 --> 00:30:15,200
access to platforms for business right

785
00:30:15,200 --> 00:30:17,520
as as lola mentioned for being able to

786
00:30:17,520 --> 00:30:20,159
take payments um etc they may get

787
00:30:20,159 --> 00:30:22,080
flagged and they may get banned for life

788
00:30:22,080 --> 00:30:23,919
from the platform even if the work that

789
00:30:23,919 --> 00:30:26,480
they're doing is legal and registered in

790
00:30:26,480 --> 00:30:27,520
the country

791
00:30:27,520 --> 00:30:30,000
um in which they're doing it the other

792
00:30:30,000 --> 00:30:31,840
thing that it means that we got a number

793
00:30:31,840 --> 00:30:33,520
of reports about and there have been

794
00:30:33,520 --> 00:30:35,440
news articles about as well

795
00:30:35,440 --> 00:30:37,840
is that people can get banned from

796
00:30:37,840 --> 00:30:40,640
platforms um even for just being

797
00:30:40,640 --> 00:30:43,279
identified as a sex worker so like

798
00:30:43,279 --> 00:30:44,559
airbnb

799
00:30:44,559 --> 00:30:46,399
has a patent

800
00:30:46,399 --> 00:30:47,840
that uses

801
00:30:47,840 --> 00:30:50,640
mysterious machine learning in order to

802
00:30:50,640 --> 00:30:53,679
identify uh people who for a variety of

803
00:30:53,679 --> 00:30:55,919
different reasons they don't want to use

804
00:30:55,919 --> 00:30:59,279
airbnb and so even if you

805
00:30:59,279 --> 00:31:01,440
say have three different devices one for

806
00:31:01,440 --> 00:31:03,679
your sex work one for your personal work

807
00:31:03,679 --> 00:31:06,240
and then one just for airbnb which one

808
00:31:06,240 --> 00:31:08,880
person described to us airbnb was still

809
00:31:08,880 --> 00:31:10,320
able to determine that they're a sex

810
00:31:10,320 --> 00:31:12,720
worker and ban them from using airbnb

811
00:31:12,720 --> 00:31:14,000
even though they didn't want to use it

812
00:31:14,000 --> 00:31:15,679
for their work they just wanted to to

813
00:31:15,679 --> 00:31:17,360
stay for vacation

814
00:31:17,360 --> 00:31:18,799
um and so there's this sort of

815
00:31:18,799 --> 00:31:21,919
regulation of your identity as someone

816
00:31:21,919 --> 00:31:24,640
who works in a particular area versus

817
00:31:24,640 --> 00:31:26,880
just the work itself both of which are

818
00:31:26,880 --> 00:31:28,559
problematic but that sort of shows the

819
00:31:28,559 --> 00:31:30,799
depth to which this um kind of moral

820
00:31:30,799 --> 00:31:32,799
encoding can go

821
00:31:32,799 --> 00:31:33,679
um

822
00:31:33,679 --> 00:31:36,000
this kind of the platforming right also

823
00:31:36,000 --> 00:31:39,039
creates invisibility um and lola has

824
00:31:39,039 --> 00:31:41,279
much more uh experience i'm sure you

825
00:31:41,279 --> 00:31:43,279
could share about this but some of the

826
00:31:43,279 --> 00:31:46,000
folks that we spoke with talked about um

827
00:31:46,000 --> 00:31:48,159
the fact that even if they were working

828
00:31:48,159 --> 00:31:50,240
in a country where sex work was legal

829
00:31:50,240 --> 00:31:52,559
they still wanted to do activism or

830
00:31:52,559 --> 00:31:54,240
share articles about sex work

831
00:31:54,240 --> 00:31:57,919
regulations etc um and so when there is

832
00:31:57,919 --> 00:32:00,320
kind of platform policing of any

833
00:32:00,320 --> 00:32:02,399
conversations let's say about commercial

834
00:32:02,399 --> 00:32:04,960
sex work um that can lead to the

835
00:32:04,960 --> 00:32:07,120
community becoming sort of invisible

836
00:32:07,120 --> 00:32:10,640
online um which can have problems for

837
00:32:10,640 --> 00:32:12,960
uh community activism and worker rights

838
00:32:12,960 --> 00:32:14,720
and so forth

839
00:32:14,720 --> 00:32:17,279
um the second piece that i wanted to

840
00:32:17,279 --> 00:32:19,919
pick up on was this idea of sort of what

841
00:32:19,919 --> 00:32:23,519
are the digital tools right um and lola

842
00:32:23,519 --> 00:32:25,519
mentioned this this idea of you have

843
00:32:25,519 --> 00:32:26,720
these separate accounts and you have

844
00:32:26,720 --> 00:32:28,240
these separate devices and you try to

845
00:32:28,240 --> 00:32:30,880
keep the information separate on them um

846
00:32:30,880 --> 00:32:33,440
and that can be really

847
00:32:33,440 --> 00:32:35,360
challenging and really overwhelming for

848
00:32:35,360 --> 00:32:37,120
folks right like lola mentioned this is

849
00:32:37,120 --> 00:32:39,360
not brainless work this is something

850
00:32:39,360 --> 00:32:42,320
that takes a lot of effort um and so

851
00:32:42,320 --> 00:32:45,600
from the kind of developer side

852
00:32:45,600 --> 00:32:47,440
one of the things we think about a lot

853
00:32:47,440 --> 00:32:50,399
is that in some cases not all cases but

854
00:32:50,399 --> 00:32:52,960
in some cases kind of existing privacy

855
00:32:52,960 --> 00:32:56,159
tools things like privacy settings etc

856
00:32:56,159 --> 00:32:57,840
those kind of aren't good enough right

857
00:32:57,840 --> 00:32:59,519
they aren't trustworthy enough there are

858
00:32:59,519 --> 00:33:02,240
sometimes software errors etc and so

859
00:33:02,240 --> 00:33:04,080
folks are really having to kind of roll

860
00:33:04,080 --> 00:33:06,320
their own options like having separate

861
00:33:06,320 --> 00:33:09,360
devices um and so is there space for us

862
00:33:09,360 --> 00:33:12,480
to do development or research that would

863
00:33:12,480 --> 00:33:15,440
say allow for hardware segmentation on a

864
00:33:15,440 --> 00:33:18,159
single device where you could guarantee

865
00:33:18,159 --> 00:33:20,240
that this the you know signature of the

866
00:33:20,240 --> 00:33:22,720
devices would look different etc

867
00:33:22,720 --> 00:33:24,720
um are there other tools that one could

868
00:33:24,720 --> 00:33:27,279
design to kind of help people manage

869
00:33:27,279 --> 00:33:29,760
these separate profiles um because that

870
00:33:29,760 --> 00:33:31,679
idea is not how

871
00:33:31,679 --> 00:33:33,919
um many internet platforms were designed

872
00:33:33,919 --> 00:33:35,760
right they want you to have one profile

873
00:33:35,760 --> 00:33:37,679
that they aggregate all of this data

874
00:33:37,679 --> 00:33:38,399
about

875
00:33:38,399 --> 00:33:41,519
and so how do we kind of um

876
00:33:41,519 --> 00:33:43,039
push against that through the

877
00:33:43,039 --> 00:33:45,679
development of tools

878
00:33:45,679 --> 00:33:49,919
um a secondary point in tool development

879
00:33:49,919 --> 00:33:51,600
is that often when we think about

880
00:33:51,600 --> 00:33:54,080
developing privacy tools we think of one

881
00:33:54,080 --> 00:33:57,279
individual using this tool right but

882
00:33:57,279 --> 00:34:00,399
in some cases uh it's both the client

883
00:34:00,399 --> 00:34:01,840
and the worker who need to be able to

884
00:34:01,840 --> 00:34:03,919
use the tool so like lola brought up

885
00:34:03,919 --> 00:34:06,000
cryptocurrency right one of the things

886
00:34:06,000 --> 00:34:08,399
that we heard from folks was i really

887
00:34:08,399 --> 00:34:11,679
don't use cryptocurrency that much not

888
00:34:11,679 --> 00:34:13,520
necessarily because of my own comfort

889
00:34:13,520 --> 00:34:15,918
level but because my clients don't know

890
00:34:15,918 --> 00:34:18,879
how to use it and you know just like i

891
00:34:18,879 --> 00:34:21,040
can't ask my employer to necessarily pay

892
00:34:21,040 --> 00:34:23,359
me in cryptocurrency um because that

893
00:34:23,359 --> 00:34:24,960
would be like a lot of effort for them

894
00:34:24,960 --> 00:34:27,199
to figure out uh there is kind of a

895
00:34:27,199 --> 00:34:29,280
two-way relationship here and so that's

896
00:34:29,280 --> 00:34:31,199
a little bit of a different development

897
00:34:31,199 --> 00:34:33,839
context than what we typically have when

898
00:34:33,839 --> 00:34:36,560
we're thinking about um particular tools

899
00:34:36,560 --> 00:34:38,560
same thing for you know and an encrypted

900
00:34:38,560 --> 00:34:41,119
chat etc

901
00:34:41,119 --> 00:34:43,760
um and then the final piece uh that i

902
00:34:43,760 --> 00:34:46,239
wanted to kind of pick up on from the

903
00:34:46,239 --> 00:34:49,440
things that lola raised um was you know

904
00:34:49,440 --> 00:34:52,719
that privacy is part of this holistic

905
00:34:52,719 --> 00:34:55,040
type of safety right so when we think

906
00:34:55,040 --> 00:34:57,359
about privacy sometimes we think about

907
00:34:57,359 --> 00:35:00,320
privacy from data aggregation or could

908
00:35:00,320 --> 00:35:03,119
have privacy as a personal right um

909
00:35:03,119 --> 00:35:05,200
which it absolutely is

910
00:35:05,200 --> 00:35:08,320
uh it's also part of this broader

911
00:35:08,320 --> 00:35:10,960
sense of safety right am i having my

912
00:35:10,960 --> 00:35:13,440
boundaries respected do i have physical

913
00:35:13,440 --> 00:35:15,200
safety so that someone isn't going to

914
00:35:15,200 --> 00:35:18,640
stalk me um do i have

915
00:35:18,640 --> 00:35:20,400
the type of safety in which there's

916
00:35:20,400 --> 00:35:21,359
actually

917
00:35:21,359 --> 00:35:22,240
you know

918
00:35:22,240 --> 00:35:24,640
someone who can respond when there are

919
00:35:24,640 --> 00:35:26,480
problems right so if i have a physical

920
00:35:26,480 --> 00:35:28,960
safety problem is law enforcement or

921
00:35:28,960 --> 00:35:30,800
whoever i go to going to take those

922
00:35:30,800 --> 00:35:34,320
seriously um and the digital piece of

923
00:35:34,320 --> 00:35:37,040
that last component um i've heard a lot

924
00:35:37,040 --> 00:35:39,359
about recently from folks we've spoken

925
00:35:39,359 --> 00:35:40,720
with who do

926
00:35:40,720 --> 00:35:43,839
online only work um where they're

927
00:35:43,839 --> 00:35:46,800
producing content um or they're doing

928
00:35:46,800 --> 00:35:49,200
kind of live video streams um and

929
00:35:49,200 --> 00:35:51,760
they're finding that that content gets

930
00:35:51,760 --> 00:35:54,960
um screen recorded downloaded kind of

931
00:35:54,960 --> 00:35:56,560
basically stolen

932
00:35:56,560 --> 00:35:58,640
and distributed around the internet and

933
00:35:58,640 --> 00:36:01,520
there are not good mechanisms for

934
00:36:01,520 --> 00:36:03,280
tracking that content

935
00:36:03,280 --> 00:36:05,920
or getting it back um and there's also

936
00:36:05,920 --> 00:36:08,960
sometimes the assumption that um because

937
00:36:08,960 --> 00:36:12,480
you're creating intimate content um you

938
00:36:12,480 --> 00:36:14,880
must be consenting it for it to go

939
00:36:14,880 --> 00:36:16,880
everywhere on the internet um but that's

940
00:36:16,880 --> 00:36:18,160
not the case right you might be

941
00:36:18,160 --> 00:36:19,920
consenting to put your content in one

942
00:36:19,920 --> 00:36:21,680
particular place for one particular

943
00:36:21,680 --> 00:36:23,839
audience you're not consenting for it to

944
00:36:23,839 --> 00:36:25,280
go everywhere

945
00:36:25,280 --> 00:36:27,440
and so i think from kind of a technology

946
00:36:27,440 --> 00:36:29,599
standpoint that's making sure that we're

947
00:36:29,599 --> 00:36:32,079
building tools we're building regulation

948
00:36:32,079 --> 00:36:33,680
that respects

949
00:36:33,680 --> 00:36:35,200
where people are comfortable having

950
00:36:35,200 --> 00:36:36,400
their content where people are

951
00:36:36,400 --> 00:36:38,880
comfortable having their data associated

952
00:36:38,880 --> 00:36:40,960
with what platforms what uses what

953
00:36:40,960 --> 00:36:43,440
identities how do we build tools that

954
00:36:43,440 --> 00:36:45,760
kind of make sure that people are able

955
00:36:45,760 --> 00:36:47,359
to have

956
00:36:47,359 --> 00:36:50,160
that consent based ownership over their

957
00:36:50,160 --> 00:36:53,520
content and over their data

958
00:36:53,520 --> 00:36:55,920
that was it for me

959
00:36:55,920 --> 00:36:58,400
so i observe one really interesting

960
00:36:58,400 --> 00:37:00,640
thing from the statements i have so far

961
00:37:00,640 --> 00:37:01,920
and that is

962
00:37:01,920 --> 00:37:03,839
we talk about

963
00:37:03,839 --> 00:37:05,680
groups here that have completely

964
00:37:05,680 --> 00:37:07,760
different awareness of their privacy

965
00:37:07,760 --> 00:37:09,839
needs and also completely different

966
00:37:09,839 --> 00:37:11,280
ability to act

967
00:37:11,280 --> 00:37:13,920
so what i understand from from elisa and

968
00:37:13,920 --> 00:37:16,800
lola right now is that sex workers are

969
00:37:16,800 --> 00:37:18,560
very much aware

970
00:37:18,560 --> 00:37:21,119
and very consciously choose the services

971
00:37:21,119 --> 00:37:23,359
and devices and whatever they they want

972
00:37:23,359 --> 00:37:26,240
to work with to control

973
00:37:26,240 --> 00:37:29,040
what they can control

974
00:37:29,040 --> 00:37:32,079
but for example for the children the

975
00:37:32,079 --> 00:37:34,160
statement we had by tommaso before or

976
00:37:34,160 --> 00:37:36,560
the people on the move the example i

977
00:37:36,560 --> 00:37:38,320
introduced earlier or that we've learned

978
00:37:38,320 --> 00:37:40,480
from in the previous panels and the

979
00:37:40,480 --> 00:37:42,560
situation is different right so people

980
00:37:42,560 --> 00:37:44,720
on the move for example

981
00:37:44,720 --> 00:37:46,960
are often very much aware from my

982
00:37:46,960 --> 00:37:49,680
personal experience but

983
00:37:49,680 --> 00:37:51,119
they'll just consent to everything

984
00:37:51,119 --> 00:37:53,040
because they have no choice

985
00:37:53,040 --> 00:37:55,760
but they are so much under pressure to

986
00:37:55,760 --> 00:37:57,200
um

987
00:37:57,200 --> 00:37:58,720
use whatever communications

988
00:37:58,720 --> 00:38:00,880
infrastructure they have to

989
00:38:00,880 --> 00:38:03,599
find some short-term employment or to

990
00:38:03,599 --> 00:38:05,599
get access to certain funds or certain

991
00:38:05,599 --> 00:38:07,520
services that they really have no choice

992
00:38:07,520 --> 00:38:09,920
to choose the platform and for children

993
00:38:09,920 --> 00:38:11,839
i think it's it's even further on that

994
00:38:11,839 --> 00:38:14,400
spectrum they use what their parents

995
00:38:14,400 --> 00:38:16,960
give them and the awareness is often not

996
00:38:16,960 --> 00:38:19,440
there so i'm trying to push this back to

997
00:38:19,440 --> 00:38:22,400
to muscle how can we deal with these

998
00:38:22,400 --> 00:38:24,960
different levels of awareness and of

999
00:38:24,960 --> 00:38:28,320
ability to act upon the awareness

1000
00:38:28,320 --> 00:38:30,000
well um

1001
00:38:30,000 --> 00:38:32,400
the the problem that that you perfectly

1002
00:38:32,400 --> 00:38:34,800
identified it's exactly one of awareness

1003
00:38:34,800 --> 00:38:37,280
i mean on the one hand you have people

1004
00:38:37,280 --> 00:38:39,839
so there's privacy which is uh at

1005
00:38:39,839 --> 00:38:42,640
different levels uh still brought up as

1006
00:38:42,640 --> 00:38:45,920
a fundamental fantastic human right so

1007
00:38:45,920 --> 00:38:47,599
on the one hand you have again sex

1008
00:38:47,599 --> 00:38:50,000
workers who need the privacy to be in

1009
00:38:50,000 --> 00:38:52,320
the digital con in digital individual

1010
00:38:52,320 --> 00:38:54,400
platforms whereas you have

1011
00:38:54,400 --> 00:38:57,520
kids or children in which

1012
00:38:57,520 --> 00:38:58,960
um

1013
00:38:58,960 --> 00:39:01,680
they they still would like to use those

1014
00:39:01,680 --> 00:39:04,000
the the the same platforms but without

1015
00:39:04,000 --> 00:39:05,359
having the risk that they don't even

1016
00:39:05,359 --> 00:39:06,640
know they're they're they're running

1017
00:39:06,640 --> 00:39:10,000
right now and the problem is um not only

1018
00:39:10,000 --> 00:39:12,240
of of they themselves but also like of

1019
00:39:12,240 --> 00:39:14,960
the type of regulation that are being i

1020
00:39:14,960 --> 00:39:18,640
i am designed so to protect them and

1021
00:39:18,640 --> 00:39:21,920
which rely on again consent and notice

1022
00:39:21,920 --> 00:39:24,079
and consent and telling you like what

1023
00:39:24,079 --> 00:39:26,800
are the risks but again as as also elisa

1024
00:39:26,800 --> 00:39:29,119
just just mentioned right now it's a

1025
00:39:29,119 --> 00:39:31,839
it's a problem of contextual integrity

1026
00:39:31,839 --> 00:39:35,920
so um this the the the fact that a a

1027
00:39:35,920 --> 00:39:38,960
naked picture is in a platform for i

1028
00:39:38,960 --> 00:39:40,880
don't know for a

1029
00:39:40,880 --> 00:39:43,040
for sexual workers is a thing if that

1030
00:39:43,040 --> 00:39:45,040
same picture is on a billboard it's it's

1031
00:39:45,040 --> 00:39:47,119
the same exact thing but in different

1032
00:39:47,119 --> 00:39:50,400
contexts contexts so we go we go back

1033
00:39:50,400 --> 00:39:53,680
again to the contextual integrity and

1034
00:39:53,680 --> 00:39:55,119
for children

1035
00:39:55,119 --> 00:39:56,400
um

1036
00:39:56,400 --> 00:39:58,079
other than

1037
00:39:58,079 --> 00:40:00,000
you know like kind of tweaking and

1038
00:40:00,000 --> 00:40:02,800
reading the right of privacy under the

1039
00:40:02,800 --> 00:40:04,640
new lenses of

1040
00:40:04,640 --> 00:40:06,960
of um of freedom of thought there's

1041
00:40:06,960 --> 00:40:09,520
there's not much else other than

1042
00:40:09,520 --> 00:40:11,920
technical solutions that um that you

1043
00:40:11,920 --> 00:40:14,800
yourself devised

1044
00:40:16,160 --> 00:40:18,000
but your reasoning in the framework of

1045
00:40:18,000 --> 00:40:21,119
freedom of thought is for example

1046
00:40:21,119 --> 00:40:22,560
at least i don't see it yet it's not

1047
00:40:22,560 --> 00:40:24,319
applicable for example the sex worker

1048
00:40:24,319 --> 00:40:26,560
case

1049
00:40:26,960 --> 00:40:27,839
um

1050
00:40:27,839 --> 00:40:31,839
i wouldn't say so and the reason is

1051
00:40:31,839 --> 00:40:34,960
the fact that we can apply the the the

1052
00:40:34,960 --> 00:40:35,920
um

1053
00:40:35,920 --> 00:40:38,000
the right to freedom of thought it's it

1054
00:40:38,000 --> 00:40:41,119
has it's has two reasoning mainly one is

1055
00:40:41,119 --> 00:40:44,160
um the fact that children are still

1056
00:40:44,160 --> 00:40:46,640
developing their thoughts therefore

1057
00:40:46,640 --> 00:40:49,280
manipulation can have not only longer

1058
00:40:49,280 --> 00:40:51,040
effects but more critical effects that's

1059
00:40:51,040 --> 00:40:53,040
one thing

1060
00:40:53,040 --> 00:40:56,319
and second is there is thanks to the

1061
00:40:56,319 --> 00:40:59,440
general comment 25 of the uncrc there is

1062
00:40:59,440 --> 00:41:01,760
a reference in the law now which by the

1063
00:41:01,760 --> 00:41:03,839
way the dsa

1064
00:41:03,839 --> 00:41:04,640
um

1065
00:41:04,640 --> 00:41:08,240
references to so now it's not that

1066
00:41:08,240 --> 00:41:10,720
far-fetched that we can actually use the

1067
00:41:10,720 --> 00:41:13,200
right to write in the the um the writer

1068
00:41:13,200 --> 00:41:15,680
freedom of thought as the last line of

1069
00:41:15,680 --> 00:41:17,920
defense uh against

1070
00:41:17,920 --> 00:41:21,839
manipulation for children

1071
00:41:25,359 --> 00:41:27,280
um lola you mentioned at some point that

1072
00:41:27,280 --> 00:41:28,960
you have good collaborations with red

1073
00:41:28,960 --> 00:41:30,400
lights which is one of the platforms

1074
00:41:30,400 --> 00:41:32,400
that is heavily used for for sex workers

1075
00:41:32,400 --> 00:41:34,560
to advertise their services in belgium

1076
00:41:34,560 --> 00:41:37,520
can you maybe say a little bit about

1077
00:41:37,520 --> 00:41:40,319
how that collaboration works and

1078
00:41:40,319 --> 00:41:43,040
what the platform is doing to make it a

1079
00:41:43,040 --> 00:41:48,119
safe space for the people you support

1080
00:41:50,079 --> 00:41:53,280
yeah it's definitely a safer space um

1081
00:41:53,280 --> 00:41:54,880
because

1082
00:41:54,880 --> 00:41:56,000
i think

1083
00:41:56,000 --> 00:41:59,119
it's a platform that also uh recognized

1084
00:41:59,119 --> 00:42:02,960
its um just respond responsibility of uh

1085
00:42:02,960 --> 00:42:05,200
hosting advertisements

1086
00:42:05,200 --> 00:42:08,480
uh in a very sensitive field for where

1087
00:42:08,480 --> 00:42:10,640
people are

1088
00:42:10,640 --> 00:42:12,880
also actively fighting against human

1089
00:42:12,880 --> 00:42:15,520
trafficking and

1090
00:42:15,520 --> 00:42:17,040
child pornography and all these things

1091
00:42:17,040 --> 00:42:19,280
so it's really important that

1092
00:42:19,280 --> 00:42:21,040
there's also a moderation happening on

1093
00:42:21,040 --> 00:42:24,560
this these parts which is happening

1094
00:42:24,560 --> 00:42:28,880
so there are moderators who actively

1095
00:42:28,880 --> 00:42:33,040
kind of do screening of the profiles and

1096
00:42:33,040 --> 00:42:35,359
give tools for people to

1097
00:42:35,359 --> 00:42:37,280
inform them about what is legal and

1098
00:42:37,280 --> 00:42:39,680
what's not and how to act on it which

1099
00:42:39,680 --> 00:42:41,680
you think it's really important

1100
00:42:41,680 --> 00:42:45,799
as users or

1101
00:42:45,839 --> 00:42:47,530
i mean as clients or workers

1102
00:42:47,530 --> 00:42:49,200
[Music]

1103
00:42:49,200 --> 00:42:53,599
there is also the opportunity to report

1104
00:42:53,599 --> 00:42:56,160
bad clients so you can

1105
00:42:56,160 --> 00:42:58,480
there's a lot of websites or like web

1106
00:42:58,480 --> 00:43:01,920
pages that um have the opportunity to

1107
00:43:01,920 --> 00:43:04,160
alert someone but then again this i

1108
00:43:04,160 --> 00:43:05,680
don't think there's a

1109
00:43:05,680 --> 00:43:07,839
nuanced way of doing it

1110
00:43:07,839 --> 00:43:08,720
and

1111
00:43:08,720 --> 00:43:12,319
if it's a page full of phone numbers i'm

1112
00:43:12,319 --> 00:43:14,430
also critical about like how do we then

1113
00:43:14,430 --> 00:43:15,920
[Music]

1114
00:43:15,920 --> 00:43:17,680
if we get a text message or a phone call

1115
00:43:17,680 --> 00:43:19,920
from someone in at the same time screen

1116
00:43:19,920 --> 00:43:20,960
it

1117
00:43:20,960 --> 00:43:23,200
in the list of phone numbers um how can

1118
00:43:23,200 --> 00:43:25,119
we centralize or like

1119
00:43:25,119 --> 00:43:26,800
automatize

1120
00:43:26,800 --> 00:43:29,520
um blocking certain type of numbers that

1121
00:43:29,520 --> 00:43:31,440
could be also like thinking a bit in the

1122
00:43:31,440 --> 00:43:32,480
future

1123
00:43:32,480 --> 00:43:35,440
but yeah in these ways definitely by by

1124
00:43:35,440 --> 00:43:38,480
making sure there it's not a total moral

1125
00:43:38,480 --> 00:43:42,240
free website meaning that

1126
00:43:43,599 --> 00:43:45,520
yeah harm can be done as well we don't

1127
00:43:45,520 --> 00:43:47,280
have to be naive of course there's

1128
00:43:47,280 --> 00:43:49,520
people who are out to

1129
00:43:49,520 --> 00:43:51,359
have

1130
00:43:51,359 --> 00:43:53,680
bad intentions

1131
00:43:53,680 --> 00:43:55,920
so i think i really like to put them out

1132
00:43:55,920 --> 00:43:59,200
as a good example on this

1133
00:43:59,200 --> 00:44:01,599
yeah quite interesting i think so so

1134
00:44:01,599 --> 00:44:03,680
these rating schemes exist for many

1135
00:44:03,680 --> 00:44:05,680
things like for uber drivers and for

1136
00:44:05,680 --> 00:44:07,839
uber clients and whatever but i do have

1137
00:44:07,839 --> 00:44:09,599
a feeling that they're in no case

1138
00:44:09,599 --> 00:44:12,800
actually legitimate so i i i'm

1139
00:44:12,800 --> 00:44:14,720
worried about all this data collection

1140
00:44:14,720 --> 00:44:16,319
from all sides whether it's for good

1141
00:44:16,319 --> 00:44:20,000
intentions or for bad intentions

1142
00:44:20,960 --> 00:44:23,440
yeah i can understand maybe just like

1143
00:44:23,440 --> 00:44:26,319
adds up to the

1144
00:44:26,319 --> 00:44:28,240
to the whole data pool

1145
00:44:28,240 --> 00:44:30,960
um but then it's also like combining a

1146
00:44:30,960 --> 00:44:33,599
desire to also have

1147
00:44:33,599 --> 00:44:35,920
more of like a general or like more

1148
00:44:35,920 --> 00:44:37,760
extensive profile

1149
00:44:37,760 --> 00:44:39,599
if it's about who you would like to work

1150
00:44:39,599 --> 00:44:41,359
with it could be nice to see like oh

1151
00:44:41,359 --> 00:44:44,400
this is actually someone who has has

1152
00:44:44,400 --> 00:44:45,680
um

1153
00:44:45,680 --> 00:44:47,920
good experiences with his client oh he

1154
00:44:47,920 --> 00:44:49,599
looks attractive then becomes more like

1155
00:44:49,599 --> 00:44:51,280
a mutual exchange

1156
00:44:51,280 --> 00:44:53,359
but maybe that's already a luxury or

1157
00:44:53,359 --> 00:44:56,000
like that's already looking ahead a bit

1158
00:44:56,000 --> 00:44:59,200
um but in terms of like sex positivity

1159
00:44:59,200 --> 00:45:01,599
it could be a good way to develop as

1160
00:45:01,599 --> 00:45:04,000
well but then how do you do this how do

1161
00:45:04,000 --> 00:45:07,200
you like apply this without

1162
00:45:07,200 --> 00:45:10,000
complicating things further and leaving

1163
00:45:10,000 --> 00:45:11,839
more traces

1164
00:45:11,839 --> 00:45:13,440
yeah

1165
00:45:13,440 --> 00:45:16,720
i think one piece too that sort of

1166
00:45:16,720 --> 00:45:19,839
interlaced through um both what masa and

1167
00:45:19,839 --> 00:45:22,000
lila have have mentioned

1168
00:45:22,000 --> 00:45:26,240
is um you know can we shift toward

1169
00:45:26,240 --> 00:45:29,200
better partnership in some cases right

1170
00:45:29,200 --> 00:45:31,839
between the platform and the end user so

1171
00:45:31,839 --> 00:45:33,280
a lot of times i think when we talk

1172
00:45:33,280 --> 00:45:35,280
about privacy we think about it as sort

1173
00:45:35,280 --> 00:45:36,960
of like ah

1174
00:45:36,960 --> 00:45:39,119
anti-platform or adversarial or

1175
00:45:39,119 --> 00:45:40,720
something like that and platforms in a

1176
00:45:40,720 --> 00:45:41,520
way

1177
00:45:41,520 --> 00:45:43,359
are often designed in this sort of

1178
00:45:43,359 --> 00:45:45,680
carceral or adversarial way right like

1179
00:45:45,680 --> 00:45:47,839
people post content and then the content

1180
00:45:47,839 --> 00:45:49,839
gets taken down and they're punished for

1181
00:45:49,839 --> 00:45:51,440
having posted something

1182
00:45:51,440 --> 00:45:53,760
incorrect etc etc

1183
00:45:53,760 --> 00:45:56,480
um and so one of the things that we've

1184
00:45:56,480 --> 00:45:58,560
been thinking about a bit is like what

1185
00:45:58,560 --> 00:46:00,560
what does it look like

1186
00:46:00,560 --> 00:46:01,440
when

1187
00:46:01,440 --> 00:46:03,839
um say a platform provides a

1188
00:46:03,839 --> 00:46:07,040
transparency tool where someone can say

1189
00:46:07,040 --> 00:46:09,520
pre-upload an image and get told whether

1190
00:46:09,520 --> 00:46:11,440
or not that's permitted on the website

1191
00:46:11,440 --> 00:46:13,119
right like this is something i think

1192
00:46:13,119 --> 00:46:14,640
lola was sort of mentioning about what

1193
00:46:14,640 --> 00:46:16,960
happens if that gets moved up

1194
00:46:16,960 --> 00:46:19,920
earlier so it's sort of collaborative um

1195
00:46:19,920 --> 00:46:21,839
between the platform and the end users

1196
00:46:21,839 --> 00:46:24,240
to make the kind of community they want

1197
00:46:24,240 --> 00:46:28,160
um similarly what would it look like if

1198
00:46:28,160 --> 00:46:30,880
you know platforms got votes from users

1199
00:46:30,880 --> 00:46:33,599
that they aggregated um in a reasonable

1200
00:46:33,599 --> 00:46:36,240
way around kind of what kind of privacy

1201
00:46:36,240 --> 00:46:38,480
protections they might prefer um

1202
00:46:38,480 --> 00:46:40,319
obviously that has to be balanced again

1203
00:46:40,319 --> 00:46:43,280
like against what um you know makes the

1204
00:46:43,280 --> 00:46:46,000
platform viable to operate um but there

1205
00:46:46,000 --> 00:46:48,000
is a lot of opportunity here i think to

1206
00:46:48,000 --> 00:46:48,960
create

1207
00:46:48,960 --> 00:46:52,000
more partnerships um where all of the

1208
00:46:52,000 --> 00:46:54,640
stakeholders have a voice um for example

1209
00:46:54,640 --> 00:46:57,440
you know clients and workers and uh

1210
00:46:57,440 --> 00:46:59,040
whatever the platform's needs are in

1211
00:46:59,040 --> 00:47:01,520
terms of uh monetization

1212
00:47:01,520 --> 00:47:03,920
uh so i think that's one piece as well

1213
00:47:03,920 --> 00:47:06,560
that would make people feel like they

1214
00:47:06,560 --> 00:47:08,800
uh have more autonomy and might actually

1215
00:47:08,800 --> 00:47:10,880
realize more autonomy as opposed to

1216
00:47:10,880 --> 00:47:12,160
being in this situation where you're

1217
00:47:12,160 --> 00:47:13,920
kind of stuck

1218
00:47:13,920 --> 00:47:17,520
with the tools that are available

1219
00:47:18,880 --> 00:47:21,599
so community driven governance

1220
00:47:21,599 --> 00:47:24,800
tommaso do you think that could work in

1221
00:47:24,800 --> 00:47:26,960
a

1222
00:47:27,040 --> 00:47:31,119
children and parent context with with um

1223
00:47:31,119 --> 00:47:33,920
game providers

1224
00:47:34,319 --> 00:47:37,319
um

1225
00:47:38,880 --> 00:47:41,200
the law is there

1226
00:47:41,200 --> 00:47:43,760
the law is there human rights are there

1227
00:47:43,760 --> 00:47:46,880
i mean i mean it enough with the the law

1228
00:47:46,880 --> 00:47:48,800
which is catching up with the technology

1229
00:47:48,800 --> 00:47:50,720
no law was there already

1230
00:47:50,720 --> 00:47:53,520
human rights were there already so how

1231
00:47:53,520 --> 00:47:56,720
about we we i mean again it's a matter

1232
00:47:56,720 --> 00:47:59,839
of uh again how to enforce it but the

1233
00:47:59,839 --> 00:48:00,960
law it's

1234
00:48:00,960 --> 00:48:03,440
uh nice nice enough

1235
00:48:03,440 --> 00:48:05,599
so it really is a matter of enforcement

1236
00:48:05,599 --> 00:48:07,760
at some point and whether that's that's

1237
00:48:07,760 --> 00:48:11,040
governance based uh well

1238
00:48:11,040 --> 00:48:13,839
yes to some extent i'm i'm fine with it

1239
00:48:13,839 --> 00:48:15,599
um but

1240
00:48:15,599 --> 00:48:17,760
in certain so

1241
00:48:17,760 --> 00:48:20,079
we need to understand that there are

1242
00:48:20,079 --> 00:48:22,480
some specifics and some characteristics

1243
00:48:22,480 --> 00:48:24,559
of some vulnerable

1244
00:48:24,559 --> 00:48:26,000
digital users

1245
00:48:26,000 --> 00:48:28,720
and that some types of business models

1246
00:48:28,720 --> 00:48:29,599
and

1247
00:48:29,599 --> 00:48:32,839
cannot be used on those types of

1248
00:48:32,839 --> 00:48:34,640
vulnerabilities you cannot make money

1249
00:48:34,640 --> 00:48:36,160
out of children that's that's that's as

1250
00:48:36,160 --> 00:48:39,520
easy like i can make it

1251
00:48:39,520 --> 00:48:41,920
there's also the question in the chat

1252
00:48:41,920 --> 00:48:44,400
whether you know of of resources or or

1253
00:48:44,400 --> 00:48:47,119
anything that allows children as

1254
00:48:47,119 --> 00:48:49,200
individuals to better fend for

1255
00:48:49,200 --> 00:48:52,000
themselves against such threats

1256
00:48:52,000 --> 00:48:53,839
um i'm kind of wondering if that even

1257
00:48:53,839 --> 00:48:56,079
makes sense

1258
00:48:56,079 --> 00:48:57,040
um

1259
00:48:57,040 --> 00:48:59,440
you mean should really children be the

1260
00:48:59,440 --> 00:49:00,240
last

1261
00:49:00,240 --> 00:49:02,000
should we enable children or should

1262
00:49:02,000 --> 00:49:04,960
children be the last line of defense

1263
00:49:04,960 --> 00:49:05,839
um

1264
00:49:05,839 --> 00:49:09,680
children are meant to play and fall and

1265
00:49:09,680 --> 00:49:11,599
becca and getting back up again and

1266
00:49:11,599 --> 00:49:13,280
these and the data that we collect while

1267
00:49:13,280 --> 00:49:15,839
the while they fall and and while they

1268
00:49:15,839 --> 00:49:17,599
make stupid videos online shall not be

1269
00:49:17,599 --> 00:49:19,440
used against them in 10 years

1270
00:49:19,440 --> 00:49:21,359
nor are using right now

1271
00:49:21,359 --> 00:49:23,839
to uh to to to start collecting data

1272
00:49:23,839 --> 00:49:25,760
that will i don't know in 10 years time

1273
00:49:25,760 --> 00:49:29,359
make their their their insurance

1274
00:49:29,359 --> 00:49:32,079
health insurance more and more expensive

1275
00:49:32,079 --> 00:49:35,119
that's that's i i don't spend it i can't

1276
00:49:35,119 --> 00:49:36,800
it's not it's not have does not have to

1277
00:49:36,800 --> 00:49:38,000
be on children

1278
00:49:38,000 --> 00:49:41,280
nor their parents it's too complicated

1279
00:49:41,280 --> 00:49:42,559
yeah yeah i think that's important to

1280
00:49:42,559 --> 00:49:44,400
make a point also for their parents it

1281
00:49:44,400 --> 00:49:46,240
is often too important to understand

1282
00:49:46,240 --> 00:49:48,079
what data is being collected where and

1283
00:49:48,079 --> 00:49:50,400
and what it might potentially be useful

1284
00:49:50,400 --> 00:49:52,800
um so luisa says we have five minutes

1285
00:49:52,800 --> 00:49:56,319
left um last round how do you

1286
00:49:56,319 --> 00:49:58,240
if you're in a in a world where you

1287
00:49:58,240 --> 00:50:00,480
where all your choices will come through

1288
00:50:00,480 --> 00:50:03,599
how how do you anticipate platforms to

1289
00:50:03,599 --> 00:50:07,680
be governed in a future to care for the

1290
00:50:07,680 --> 00:50:08,800
community

1291
00:50:08,800 --> 00:50:12,440
that you work with

1292
00:50:13,359 --> 00:50:15,839
two minutes or one minute each elisa if

1293
00:50:15,839 --> 00:50:18,720
you want to go i see you smiling

1294
00:50:18,720 --> 00:50:20,480
sure i was like oh that's a hard

1295
00:50:20,480 --> 00:50:22,319
question and a good question

1296
00:50:22,319 --> 00:50:24,800
um i guess kind of picking up right this

1297
00:50:24,800 --> 00:50:27,680
community driven uh governance piece

1298
00:50:27,680 --> 00:50:30,240
there's been increasing interest in

1299
00:50:30,240 --> 00:50:32,640
uh what they call like decentralized

1300
00:50:32,640 --> 00:50:34,319
online platforms right so if you think

1301
00:50:34,319 --> 00:50:37,920
about things like mastodon uh etc and i

1302
00:50:37,920 --> 00:50:39,760
think one of the interesting things that

1303
00:50:39,760 --> 00:50:41,599
i expect to see change there whether

1304
00:50:41,599 --> 00:50:43,119
it's for those platforms or even

1305
00:50:43,119 --> 00:50:45,280
platforms like reddit etc

1306
00:50:45,280 --> 00:50:48,400
is kind of recognition of the labor

1307
00:50:48,400 --> 00:50:51,040
involved in moderation or the labor

1308
00:50:51,040 --> 00:50:53,359
involved in doing community driven

1309
00:50:53,359 --> 00:50:56,079
governance um and so i imagine that we

1310
00:50:56,079 --> 00:50:58,880
may see a shift toward more and more

1311
00:50:58,880 --> 00:51:01,040
kind of paid whether they're freelance

1312
00:51:01,040 --> 00:51:04,559
positions or et cetera paid positions um

1313
00:51:04,559 --> 00:51:06,640
to allow for

1314
00:51:06,640 --> 00:51:08,480
uh more community-driven

1315
00:51:08,480 --> 00:51:10,559
moderation possibly in these kind of

1316
00:51:10,559 --> 00:51:13,760
decentralized communities

1317
00:51:13,760 --> 00:51:16,720
lola your opinion

1318
00:51:16,800 --> 00:51:18,319
yeah

1319
00:51:18,319 --> 00:51:20,559
nice to think about like um

1320
00:51:20,559 --> 00:51:23,040
idolization of these things

1321
00:51:23,040 --> 00:51:25,920
um so i as i say i'm not an expert on

1322
00:51:25,920 --> 00:51:28,160
all the like the digital but what i see

1323
00:51:28,160 --> 00:51:30,720
would be like how i see it what would be

1324
00:51:30,720 --> 00:51:32,480
amazing is if you would

1325
00:51:32,480 --> 00:51:34,640
give more um

1326
00:51:34,640 --> 00:51:36,400
a voice and platform to

1327
00:51:36,400 --> 00:51:39,359
field organizations as well to be able

1328
00:51:39,359 --> 00:51:40,400
to

1329
00:51:40,400 --> 00:51:43,520
um give an evaluation of platforms in

1330
00:51:43,520 --> 00:51:46,240
way that we are also being heard as

1331
00:51:46,240 --> 00:51:47,440
users

1332
00:51:47,440 --> 00:51:48,400
um

1333
00:51:48,400 --> 00:51:50,800
and we can have impact in on on this

1334
00:51:50,800 --> 00:51:52,800
level

1335
00:51:52,800 --> 00:51:55,200
that the evaluation comes from

1336
00:51:55,200 --> 00:51:57,040
the experiences i gather and collect

1337
00:51:57,040 --> 00:52:00,160
let's say and um we as

1338
00:52:00,160 --> 00:52:03,520
uh non-experts and academics

1339
00:52:03,520 --> 00:52:06,960
and researchers on the digital spaces

1340
00:52:06,960 --> 00:52:09,920
also have autonomy

1341
00:52:10,000 --> 00:52:13,920
it would be my very simplified answer

1342
00:52:16,559 --> 00:52:18,400
do you know when you were all kids and

1343
00:52:18,400 --> 00:52:20,079
we were with our friends playing our

1344
00:52:20,079 --> 00:52:22,079
rooms and then the parents would come in

1345
00:52:22,079 --> 00:52:24,640
and they were like just stop all at once

1346
00:52:24,640 --> 00:52:26,400
doing whatever

1347
00:52:26,400 --> 00:52:28,640
yes that happens every day right so how

1348
00:52:28,640 --> 00:52:31,280
about that type of privacy space for

1349
00:52:31,280 --> 00:52:33,599
children themselves like i mean um a

1350
00:52:33,599 --> 00:52:38,079
place where even even when willing to um

1351
00:52:38,079 --> 00:52:39,040
um

1352
00:52:39,040 --> 00:52:40,640
there's no centralization so of course

1353
00:52:40,640 --> 00:52:42,240
decentralized systems definitely

1354
00:52:42,240 --> 00:52:44,160
decentralized systems of course in our

1355
00:52:44,160 --> 00:52:46,800
case it cannot be um

1356
00:52:46,800 --> 00:52:48,160
let's say um

1357
00:52:48,160 --> 00:52:50,559
governed by children themselves

1358
00:52:50,559 --> 00:52:53,599
um but giving to the centralization the

1359
00:52:53,599 --> 00:52:55,760
the biggest

1360
00:52:55,760 --> 00:52:57,040
um

1361
00:52:57,040 --> 00:52:58,839
i'll put it this

1362
00:52:58,839 --> 00:53:02,000
way making sure that that the the system

1363
00:53:02,000 --> 00:53:04,400
is decentralized to a point where

1364
00:53:04,400 --> 00:53:07,359
um no one can enter in the room and and

1365
00:53:07,359 --> 00:53:10,880
prey on on kids playing

1366
00:53:12,640 --> 00:53:15,920
okay i think it's 4 20 and with this we

1367
00:53:15,920 --> 00:53:18,160
have to finish i'm sorry for the hiccups

1368
00:53:18,160 --> 00:53:19,760
at the beginning and thanks to everyone

1369
00:53:19,760 --> 00:53:21,520
for listening to us and i hope we we all

1370
00:53:21,520 --> 00:53:23,520
learned something about how we can maybe

1371
00:53:23,520 --> 00:53:25,280
uh build platforms better thank you

1372
00:53:25,280 --> 00:53:26,720
everyone

1373
00:53:26,720 --> 00:53:29,839
thank you

