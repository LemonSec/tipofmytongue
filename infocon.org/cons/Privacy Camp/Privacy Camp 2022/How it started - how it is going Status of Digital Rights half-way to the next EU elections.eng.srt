1
00:00:07,839 --> 00:00:08,800
um

2
00:00:08,800 --> 00:00:10,559
well thank you everyone welcome to this

3
00:00:10,559 --> 00:00:13,440
panel we are halfway into the current

4
00:00:13,440 --> 00:00:15,280
legislative term

5
00:00:15,280 --> 00:00:17,600
which means also we are halfway until

6
00:00:17,600 --> 00:00:19,920
the next eu elections and the new

7
00:00:19,920 --> 00:00:22,560
college of commissioners

8
00:00:22,560 --> 00:00:24,960
it is a therefore a good time for for

9
00:00:24,960 --> 00:00:27,920
every for european digital rights and

10
00:00:27,920 --> 00:00:30,800
other ngos and digital rights advocates

11
00:00:30,800 --> 00:00:33,760
to look backwards and also forward to

12
00:00:33,760 --> 00:00:37,760
analyze the impact adapt strategies and

13
00:00:37,760 --> 00:00:41,040
receive constructive criticism of our

14
00:00:41,040 --> 00:00:42,879
work

15
00:00:42,879 --> 00:00:45,039
looking backwards and the purpose of

16
00:00:45,039 --> 00:00:48,399
this panel is to have an overview on

17
00:00:48,399 --> 00:00:50,719
how how it has been for digital rights

18
00:00:50,719 --> 00:00:51,920
so far

19
00:00:51,920 --> 00:00:54,800
in the current eu legislative term this

20
00:00:54,800 --> 00:00:55,600
means

21
00:00:55,600 --> 00:00:57,520
how well have digital rights being

22
00:00:57,520 --> 00:00:58,480
defended

23
00:00:58,480 --> 00:01:00,879
are we advancing are we creating more

24
00:01:00,879 --> 00:01:03,039
legislation that perhaps will never be

25
00:01:03,039 --> 00:01:04,239
enforced

26
00:01:04,239 --> 00:01:06,640
and how are civil society groups doing

27
00:01:06,640 --> 00:01:08,880
are we being effective are we engaging

28
00:01:08,880 --> 00:01:11,360
with people outside the eu bubble

29
00:01:11,360 --> 00:01:13,439
and also how do the members of the

30
00:01:13,439 --> 00:01:15,520
european parliament also vocab academia

31
00:01:15,520 --> 00:01:17,520
see us how do they perceive

32
00:01:17,520 --> 00:01:18,799
our work

33
00:01:18,799 --> 00:01:20,720
this is looking backwards by looking

34
00:01:20,720 --> 00:01:23,280
forward and being halfway until the next

35
00:01:23,280 --> 00:01:25,600
elections also means it is also a good

36
00:01:25,600 --> 00:01:28,960
moment to take two three takeaways

37
00:01:28,960 --> 00:01:32,560
of what to expect by 2024

38
00:01:32,560 --> 00:01:35,200
so what is the next digital services act

39
00:01:35,200 --> 00:01:37,600
type of legislation that is coming or

40
00:01:37,600 --> 00:01:39,040
what we should be

41
00:01:39,040 --> 00:01:42,079
pushing to to be proposed by the next uh

42
00:01:42,079 --> 00:01:43,360
representative

43
00:01:43,360 --> 00:01:46,079
by the next uh college of commissioners

44
00:01:46,079 --> 00:01:48,880
or should we perhaps both policymakers

45
00:01:48,880 --> 00:01:50,960
and human rights groups focus rather in

46
00:01:50,960 --> 00:01:53,600
the implementation we have the gdpr we

47
00:01:53,600 --> 00:01:56,000
have the e-privacy some time soon

48
00:01:56,000 --> 00:01:57,600
hopefully the regulation

49
00:01:57,600 --> 00:02:00,880
the dsa soon the dna we have we in the

50
00:02:00,880 --> 00:02:02,719
process of adopting the

51
00:02:02,719 --> 00:02:05,680
the artificial intelligence act

52
00:02:05,680 --> 00:02:06,799
and then

53
00:02:06,799 --> 00:02:09,199
european data rights is also starting an

54
00:02:09,199 --> 00:02:11,120
internal review process

55
00:02:11,120 --> 00:02:13,599
in this moment and we're trying to take

56
00:02:13,599 --> 00:02:15,120
all of these questions into

57
00:02:15,120 --> 00:02:16,640
consideration

58
00:02:16,640 --> 00:02:18,640
with this panel we hope that we will be

59
00:02:18,640 --> 00:02:21,360
able to to obtain some analytical and

60
00:02:21,360 --> 00:02:23,760
strategic tools for civil society

61
00:02:23,760 --> 00:02:25,760
to face the existing and future

62
00:02:25,760 --> 00:02:28,080
challenges that we are facing

63
00:02:28,080 --> 00:02:30,160
and in order for this panel to be

64
00:02:30,160 --> 00:02:32,239
relevant for all of us i i'd like to

65
00:02:32,239 --> 00:02:34,480
encourage a self-criticism

66
00:02:34,480 --> 00:02:37,519
of strategy strategies and acknowledging

67
00:02:37,519 --> 00:02:39,519
what could have been what could have

68
00:02:39,519 --> 00:02:41,280
worked better so we can address these

69
00:02:41,280 --> 00:02:44,239
failures in our current and future work

70
00:02:44,239 --> 00:02:46,720
but also to recognize all the progress

71
00:02:46,720 --> 00:02:49,280
that we have achieved so far

72
00:02:49,280 --> 00:02:51,360
so summarizing some of the questions we

73
00:02:51,360 --> 00:02:53,920
are going to try to respond today

74
00:02:53,920 --> 00:02:55,440
is other ones that i'm going to be

75
00:02:55,440 --> 00:02:57,519
basing in the chat

76
00:02:57,519 --> 00:02:59,440
so how are the european commission the

77
00:02:59,440 --> 00:03:01,680
european parliament standing in terms of

78
00:03:01,680 --> 00:03:03,760
digital rights and policies

79
00:03:03,760 --> 00:03:05,599
what are the biggest threats to the

80
00:03:05,599 --> 00:03:08,400
rights of u.s citizens now halfway and

81
00:03:08,400 --> 00:03:10,000
they have a point to the next few

82
00:03:10,000 --> 00:03:12,319
elections and where should we focus our

83
00:03:12,319 --> 00:03:14,720
energies in 2024

84
00:03:14,720 --> 00:03:16,480
and beyond

85
00:03:16,480 --> 00:03:18,720
as you know um my name is igor naranjo

86
00:03:18,720 --> 00:03:20,560
i'm the head of policy of european

87
00:03:20,560 --> 00:03:22,239
leader rights i have four wonderful

88
00:03:22,239 --> 00:03:23,680
speakers coming from the european

89
00:03:23,680 --> 00:03:25,280
parliament from the civil society and

90
00:03:25,280 --> 00:03:26,640
from academia

91
00:03:26,640 --> 00:03:28,720
in the interest of time i will avoid

92
00:03:28,720 --> 00:03:30,799
reading any biographies and i'm gonna

93
00:03:30,799 --> 00:03:32,480
head directly to the first one of

94
00:03:32,480 --> 00:03:34,400
questions i will start with you

95
00:03:34,400 --> 00:03:36,720
alexandra alexandra is of course a

96
00:03:36,720 --> 00:03:38,239
well-known mep

97
00:03:38,239 --> 00:03:39,920
and member of the group of the greens

98
00:03:39,920 --> 00:03:42,159
iup and free alliance she's

99
00:03:42,159 --> 00:03:44,640
not only a member of the internal market

100
00:03:44,640 --> 00:03:46,400
in consumer protection committee where

101
00:03:46,400 --> 00:03:48,720
we all know her very well she's also

102
00:03:48,720 --> 00:03:50,239
part of the budget committee and the

103
00:03:50,239 --> 00:03:52,319
artificial intelligence in a digital age

104
00:03:52,319 --> 00:03:53,360
committee

105
00:03:53,360 --> 00:03:55,439
and and she's also a former interpreter

106
00:03:55,439 --> 00:03:56,879
in the european parliament and so

107
00:03:56,879 --> 00:03:59,680
alexandra even though you have worked in

108
00:03:59,680 --> 00:04:02,000
the ep before this is if i'm not wrong

109
00:04:02,000 --> 00:04:04,400
with your first term as an mep and you

110
00:04:04,400 --> 00:04:06,799
quickly show the interest in working on

111
00:04:06,799 --> 00:04:09,360
digital issues since then and we know

112
00:04:09,360 --> 00:04:11,120
well you and your team you have been

113
00:04:11,120 --> 00:04:13,040
working on very intensive on a number of

114
00:04:13,040 --> 00:04:14,400
cs namely

115
00:04:14,400 --> 00:04:16,959
but not only the digital services act

116
00:04:16,959 --> 00:04:18,720
and the entire artificial intelligence

117
00:04:18,720 --> 00:04:19,440
act

118
00:04:19,440 --> 00:04:21,519
so the dsa was voted last week which

119
00:04:21,519 --> 00:04:24,479
marks a positive step forward to advance

120
00:04:24,479 --> 00:04:26,080
human rights online i think it's a great

121
00:04:26,080 --> 00:04:29,040
victory for of us it is a bit clear at

122
00:04:29,040 --> 00:04:31,919
least for me where the ai acts will be

123
00:04:31,919 --> 00:04:34,000
heading to and now that we are halfway

124
00:04:34,000 --> 00:04:36,400
in the legion what is the balance what

125
00:04:36,400 --> 00:04:38,400
is the balance so far for digital rights

126
00:04:38,400 --> 00:04:41,960
generally for you

127
00:04:42,080 --> 00:04:44,240
um thank you diego um thank you for

128
00:04:44,240 --> 00:04:46,000
those kind words and thanks thanks for

129
00:04:46,000 --> 00:04:47,280
having me here

130
00:04:47,280 --> 00:04:50,560
um well difficult question um for me

131
00:04:50,560 --> 00:04:52,080
personally i think the balance is

132
00:04:52,080 --> 00:04:54,639
positive because working on the digital

133
00:04:54,639 --> 00:04:57,120
services sect um i believe what we

134
00:04:57,120 --> 00:04:59,680
achieved last thursday and plenary is is

135
00:04:59,680 --> 00:05:01,759
amazing it's a lot more than than we

136
00:05:01,759 --> 00:05:04,160
expected when we started out i remember

137
00:05:04,160 --> 00:05:06,000
when we started when i started working

138
00:05:06,000 --> 00:05:08,320
on this the line was more well we have

139
00:05:08,320 --> 00:05:11,199
to defend the existing situation to make

140
00:05:11,199 --> 00:05:13,759
sure that liability exemption will hold

141
00:05:13,759 --> 00:05:16,000
and so on and now we we got really so

142
00:05:16,000 --> 00:05:17,520
much more we get users right through

143
00:05:17,520 --> 00:05:19,440
good good notice and action

144
00:05:19,440 --> 00:05:22,320
complaint management um out of court

145
00:05:22,320 --> 00:05:25,280
settlement and we got what is even more

146
00:05:25,280 --> 00:05:26,400
important

147
00:05:26,400 --> 00:05:29,440
for the very large online platforms

148
00:05:29,440 --> 00:05:31,280
we got the risk assessments and

149
00:05:31,280 --> 00:05:34,720
especially external scrutiny

150
00:05:34,720 --> 00:05:38,320
even by independent researchers and by

151
00:05:38,320 --> 00:05:41,360
independent ngos which i think is

152
00:05:41,360 --> 00:05:44,400
absolutely a game changer so i think the

153
00:05:44,400 --> 00:05:46,479
dsa will not you know it will not be

154
00:05:46,479 --> 00:05:48,960
felt maybe from the first day for for

155
00:05:48,960 --> 00:05:51,600
individuals but but the structural

156
00:05:51,600 --> 00:05:53,600
change this will bring about that we can

157
00:05:53,600 --> 00:05:55,039
finally look under the hood of what

158
00:05:55,039 --> 00:05:56,880
these platforms are doing

159
00:05:56,880 --> 00:06:00,080
is is really really important and um

160
00:06:00,080 --> 00:06:02,560
that's that is i think one of the areas

161
00:06:02,560 --> 00:06:06,479
where um area and we could focus or ngos

162
00:06:06,479 --> 00:06:08,720
in general could focus the work on

163
00:06:08,720 --> 00:06:10,160
try to

164
00:06:10,160 --> 00:06:13,199
to hold to be in touch with the networks

165
00:06:13,199 --> 00:06:15,919
of ngos and researchers and universities

166
00:06:15,919 --> 00:06:17,840
all over europe to define research

167
00:06:17,840 --> 00:06:20,240
programs projects that you can do on the

168
00:06:20,240 --> 00:06:23,360
basis of article 31

169
00:06:23,360 --> 00:06:26,960
trying to tell the stories of what

170
00:06:26,960 --> 00:06:30,240
happens in the digital space and what is

171
00:06:30,240 --> 00:06:32,800
the influence on everyday lives of

172
00:06:32,800 --> 00:06:35,280
people and on politics because i think

173
00:06:35,280 --> 00:06:37,440
one of my difficulties but everybody's

174
00:06:37,440 --> 00:06:39,840
difficulties with telling

175
00:06:39,840 --> 00:06:42,160
with changing the political attitude

176
00:06:42,160 --> 00:06:44,160
towards digital policy

177
00:06:44,160 --> 00:06:46,000
is that it's so abstract there's no

178
00:06:46,000 --> 00:06:48,000
images they're very little stories

179
00:06:48,000 --> 00:06:50,000
except of individuals and it's so

180
00:06:50,000 --> 00:06:51,759
difficult to tell the story because it's

181
00:06:51,759 --> 00:06:53,759
so complicated you know explain the dsa

182
00:06:53,759 --> 00:06:54,880
to a normal person it's almost

183
00:06:54,880 --> 00:06:56,080
impossible

184
00:06:56,080 --> 00:06:57,840
um it takes to ten minutes and then

185
00:06:57,840 --> 00:06:59,520
person is not listening anymore so i

186
00:06:59,520 --> 00:07:00,479
think

187
00:07:00,479 --> 00:07:01,520
one thing

188
00:07:01,520 --> 00:07:04,639
we we should be doing all together

189
00:07:04,639 --> 00:07:07,280
is is trying to tell the story so if for

190
00:07:07,280 --> 00:07:09,520
germany it might be why do we have all

191
00:07:09,520 --> 00:07:12,000
these fans of natural medicine from the

192
00:07:12,000 --> 00:07:13,840
south of germany who are marching in the

193
00:07:13,840 --> 00:07:16,400
streets against which is together

194
00:07:16,400 --> 00:07:19,360
with nazis from the east or other places

195
00:07:19,360 --> 00:07:21,599
you know how and this is about targeting

196
00:07:21,599 --> 00:07:23,919
this is a digital topic

197
00:07:23,919 --> 00:07:25,680
but as long as you don't have the

198
00:07:25,680 --> 00:07:27,919
research to back it up so you need the

199
00:07:27,919 --> 00:07:29,759
evidence you need access to the data to

200
00:07:29,759 --> 00:07:31,120
have the evidence and you need to be

201
00:07:31,120 --> 00:07:32,800
able to tell the story and you need to

202
00:07:32,800 --> 00:07:34,160
be able to tell a story about real

203
00:07:34,160 --> 00:07:35,199
people

204
00:07:35,199 --> 00:07:38,080
in order to to elicit emotions and then

205
00:07:38,080 --> 00:07:40,400
people will be ready to act

206
00:07:40,400 --> 00:07:42,479
so i think that is that is a really

207
00:07:42,479 --> 00:07:44,960
important task for for ngos and for edwy

208
00:07:44,960 --> 00:07:46,400
to look around i mean who are

209
00:07:46,400 --> 00:07:48,160
interesting people who are ngos

210
00:07:48,160 --> 00:07:49,840
interested in doing this telling them

211
00:07:49,840 --> 00:07:52,400
about this possibility that dsa offers

212
00:07:52,400 --> 00:07:54,319
and maybe try to see who are the

213
00:07:54,319 --> 00:07:56,080
universities that aren't maybe not

214
00:07:56,080 --> 00:07:57,840
funded by google and facebook and who

215
00:07:57,840 --> 00:07:59,680
could do the research part the

216
00:07:59,680 --> 00:08:01,840
mathematical part the data analysis and

217
00:08:01,840 --> 00:08:03,120
so on you know

218
00:08:03,120 --> 00:08:04,639
i think that's that's one thing that is

219
00:08:04,639 --> 00:08:06,960
that is really important

220
00:08:06,960 --> 00:08:08,240
um

221
00:08:08,240 --> 00:08:09,280
maybe

222
00:08:09,280 --> 00:08:11,599
i have to well maybe i just stopped here

223
00:08:11,599 --> 00:08:13,120
because with so many people on the panel

224
00:08:13,120 --> 00:08:15,120
i have more points but i i just stop you

225
00:08:15,120 --> 00:08:17,199
for the moment

226
00:08:17,199 --> 00:08:19,120
okay that was good i was looking forward

227
00:08:19,120 --> 00:08:20,800
to see what you were going to follow

228
00:08:20,800 --> 00:08:22,240
let's leave it for later and asha

229
00:08:22,240 --> 00:08:24,479
perhaps we can continue with you and

230
00:08:24,479 --> 00:08:26,639
because i think what uh alexandra was

231
00:08:26,639 --> 00:08:29,120
saying on the the need to to

232
00:08:29,120 --> 00:08:31,840
uh to tell stories to find the evidence

233
00:08:31,840 --> 00:08:34,880
and make all of these digital rights uh

234
00:08:34,880 --> 00:08:38,320
abstract type of policy policy speech

235
00:08:38,320 --> 00:08:40,159
and making it a bit more concrete for

236
00:08:40,159 --> 00:08:42,159
people and you you come from the

237
00:08:42,159 --> 00:08:44,399
european women's lobby where you joined

238
00:08:44,399 --> 00:08:46,080
and you were already working on digital

239
00:08:46,080 --> 00:08:48,480
affairs and you joined the cdt's last

240
00:08:48,480 --> 00:08:50,800
year you were the advocacy director of

241
00:08:50,800 --> 00:08:52,880
uh for europe online expression city

242
00:08:52,880 --> 00:08:55,040
space acidity for those of you who do

243
00:08:55,040 --> 00:08:56,720
not know her yet

244
00:08:56,720 --> 00:08:59,519
um so what do you think how how can we

245
00:08:59,519 --> 00:09:02,880
start telling stories how can we build

246
00:09:02,880 --> 00:09:04,959
build on the evidence that we we are

247
00:09:04,959 --> 00:09:06,560
gathering some of us are

248
00:09:06,560 --> 00:09:08,160
either researchers or in the specific

249
00:09:08,160 --> 00:09:09,519
are gathering everything so how can we

250
00:09:09,519 --> 00:09:11,279
tell better these stories

251
00:09:11,279 --> 00:09:14,160
and and how does it uh especially for in

252
00:09:14,160 --> 00:09:15,760
the case of marginalized groups and for

253
00:09:15,760 --> 00:09:17,200
people on the ground

254
00:09:17,200 --> 00:09:19,760
and how can we make them involved in the

255
00:09:19,760 --> 00:09:22,080
in policy making sense sometimes or very

256
00:09:22,080 --> 00:09:24,399
often they are the most impacted by some

257
00:09:24,399 --> 00:09:28,080
of the of the digital rights policies

258
00:09:28,320 --> 00:09:30,080
thank you very much jaeger and thank you

259
00:09:30,080 --> 00:09:32,000
for the invitation to speak on this uh

260
00:09:32,000 --> 00:09:33,839
really important panel i'm so honored to

261
00:09:33,839 --> 00:09:36,959
be uh supported by so many uh allies

262
00:09:36,959 --> 00:09:39,360
here and as you mentioned kind of coming

263
00:09:39,360 --> 00:09:41,279
from that gender equality digital rights

264
00:09:41,279 --> 00:09:43,440
expertise background it really was at

265
00:09:43,440 --> 00:09:45,120
the foundation about seeing the

266
00:09:45,120 --> 00:09:46,800
intersections between digital rights

267
00:09:46,800 --> 00:09:49,040
policies and existing equality

268
00:09:49,040 --> 00:09:50,959
legislation equality laws and existing

269
00:09:50,959 --> 00:09:53,839
equality policies for those of us who've

270
00:09:53,839 --> 00:09:55,360
been in that online gender-based

271
00:09:55,360 --> 00:09:57,279
violence space especially for the last

272
00:09:57,279 --> 00:09:59,200
kind of five or six years

273
00:09:59,200 --> 00:10:01,760
back in 2017 it was still like a nice

274
00:10:01,760 --> 00:10:04,240
subject we had some political awareness

275
00:10:04,240 --> 00:10:06,399
uh mainly from politically engaged women

276
00:10:06,399 --> 00:10:08,000
who unfortunately had first-hand

277
00:10:08,000 --> 00:10:09,360
experience of the issues that we were

278
00:10:09,360 --> 00:10:11,519
talking about um but the small

279
00:10:11,519 --> 00:10:13,920
communities who focused uh on online

280
00:10:13,920 --> 00:10:15,120
gender-based violence couldn't have

281
00:10:15,120 --> 00:10:16,399
imagined that we were having the

282
00:10:16,399 --> 00:10:17,760
conversations that we're having right

283
00:10:17,760 --> 00:10:18,480
now

284
00:10:18,480 --> 00:10:20,800
and that's because of the

285
00:10:20,800 --> 00:10:22,640
political willingness that we have seen

286
00:10:22,640 --> 00:10:25,120
which i think taps into where we are in

287
00:10:25,120 --> 00:10:26,720
the middle of this term we are seeing a

288
00:10:26,720 --> 00:10:29,279
lot more political willingness um from

289
00:10:29,279 --> 00:10:31,120
champions such as alexandria in the

290
00:10:31,120 --> 00:10:32,800
european parliament but in the european

291
00:10:32,800 --> 00:10:34,240
institutions and i think in civil

292
00:10:34,240 --> 00:10:36,160
society we are always hoping for that

293
00:10:36,160 --> 00:10:38,240
political will to be there so that we're

294
00:10:38,240 --> 00:10:40,399
able to move that needle forward

295
00:10:40,399 --> 00:10:42,560
but specifically when it comes to to

296
00:10:42,560 --> 00:10:45,040
marginalized groups and tapping into

297
00:10:45,040 --> 00:10:47,200
that conversation on fundamental rights

298
00:10:47,200 --> 00:10:48,399
i would actually say we need to go

299
00:10:48,399 --> 00:10:50,720
beyond stories because at this moment in

300
00:10:50,720 --> 00:10:53,440
time i think stories very much give a

301
00:10:53,440 --> 00:10:55,519
personality to the abstract and this is

302
00:10:55,519 --> 00:10:58,000
incredibly important agreeing trying to

303
00:10:58,000 --> 00:11:01,040
explain the dsa in short concrete terms

304
00:11:01,040 --> 00:11:03,200
and how this directly impacts on a

305
00:11:03,200 --> 00:11:05,760
person can be quite difficult to do but

306
00:11:05,760 --> 00:11:07,120
when you're looking at it through an

307
00:11:07,120 --> 00:11:08,320
intersectional perspective and

308
00:11:08,320 --> 00:11:09,920
intersectional lens of looking at the

309
00:11:09,920 --> 00:11:11,680
impacts of the things that we're talking

310
00:11:11,680 --> 00:11:13,760
about on marginalized groups this is

311
00:11:13,760 --> 00:11:15,600
where you can get a better shape

312
00:11:15,600 --> 00:11:17,440
of what we're looking at here but the

313
00:11:17,440 --> 00:11:19,279
reason i say that we also go beyond

314
00:11:19,279 --> 00:11:21,279
stories is because we also need to go

315
00:11:21,279 --> 00:11:23,440
into the adoption of a clear

316
00:11:23,440 --> 00:11:25,920
intersectional methodology in our policy

317
00:11:25,920 --> 00:11:28,320
making and also need to be very very

318
00:11:28,320 --> 00:11:30,560
aware and just to be quite truthful that

319
00:11:30,560 --> 00:11:33,040
the eu policy making space and the tech

320
00:11:33,040 --> 00:11:35,200
space and the digital rights base remain

321
00:11:35,200 --> 00:11:37,760
somewhat homogenous um i work with a

322
00:11:37,760 --> 00:11:40,240
group of incredible activists on the who

323
00:11:40,240 --> 00:11:42,399
rights the rules campaign initiated by

324
00:11:42,399 --> 00:11:44,399
digital action and this is a group of

325
00:11:44,399 --> 00:11:46,560
six women of color who are calling on

326
00:11:46,560 --> 00:11:48,720
the eu institutions to do better on

327
00:11:48,720 --> 00:11:50,480
their commitments when it comes to

328
00:11:50,480 --> 00:11:53,760
inclusion of marginalized groups often

329
00:11:53,760 --> 00:11:55,839
we may be invited in the room to share

330
00:11:55,839 --> 00:11:57,440
our stories but it needs to go beyond

331
00:11:57,440 --> 00:11:59,200
that it needs to go into helping with

332
00:11:59,200 --> 00:12:00,880
the policy making and the decision

333
00:12:00,880 --> 00:12:03,120
making and the analysis and being there

334
00:12:03,120 --> 00:12:05,120
as the researchers as well at the same

335
00:12:05,120 --> 00:12:07,680
time so it's a multifaceted approach so

336
00:12:07,680 --> 00:12:09,839
often when i have this conversation i

337
00:12:09,839 --> 00:12:11,320
always remind people that

338
00:12:11,320 --> 00:12:13,440
intersectionality is a concrete

339
00:12:13,440 --> 00:12:16,079
methodology and framework for analyzing

340
00:12:16,079 --> 00:12:18,000
the interplay between class race and

341
00:12:18,000 --> 00:12:20,880
gender it's not a checklist exercise

342
00:12:20,880 --> 00:12:22,560
when you kind of refer to marginalized

343
00:12:22,560 --> 00:12:24,480
groups but it's an actual strategy that

344
00:12:24,480 --> 00:12:26,880
you could put into industry into policy

345
00:12:26,880 --> 00:12:29,760
making um and into research as well so

346
00:12:29,760 --> 00:12:32,079
it's quite important we have to

347
00:12:32,079 --> 00:12:34,160
maximize on the opportunity that we have

348
00:12:34,160 --> 00:12:36,079
where fundamental rights has been at the

349
00:12:36,079 --> 00:12:37,519
core some of the conversations around

350
00:12:37,519 --> 00:12:39,120
the digital services act for example i

351
00:12:39,120 --> 00:12:41,519
think so many of the wins that we saw

352
00:12:41,519 --> 00:12:43,040
from the plenary last week were based

353
00:12:43,040 --> 00:12:45,040
because we had people really championing

354
00:12:45,040 --> 00:12:47,760
fundamental rights in this legislation

355
00:12:47,760 --> 00:12:50,320
but we can go a step further and really

356
00:12:50,320 --> 00:12:51,519
think about what are we talking about

357
00:12:51,519 --> 00:12:53,279
when we say fundamental rights whose

358
00:12:53,279 --> 00:12:55,200
fundamental rights and how are those

359
00:12:55,200 --> 00:12:56,720
different sites interplaying with each

360
00:12:56,720 --> 00:12:58,320
other and how do they manifest in real

361
00:12:58,320 --> 00:13:00,639
terms

362
00:13:02,720 --> 00:13:04,800
thank you asha and that's actually a

363
00:13:04,800 --> 00:13:06,480
very good uh

364
00:13:06,480 --> 00:13:09,120
link to to bring you seven hoboken with

365
00:13:09,120 --> 00:13:11,360
us he's a previous uh

366
00:13:11,360 --> 00:13:12,959
post-doctoral research fellow at the

367
00:13:12,959 --> 00:13:14,800
information law institute

368
00:13:14,800 --> 00:13:17,440
at new york university but we we haven't

369
00:13:17,440 --> 00:13:20,079
met before i i met a joist when he was

370
00:13:20,079 --> 00:13:22,240
still at the board of directors of the

371
00:13:22,240 --> 00:13:24,160
dutch digital advice organization pizza

372
00:13:24,160 --> 00:13:25,279
freedom

373
00:13:25,279 --> 00:13:27,760
for which he was the chairman so he was

374
00:13:27,760 --> 00:13:30,560
a long time every elderly friend

375
00:13:30,560 --> 00:13:32,880
and so uh joris i think you also were

376
00:13:32,880 --> 00:13:34,720
interested in in this issue of the

377
00:13:34,720 --> 00:13:36,880
fundamental rights being at the core of

378
00:13:36,880 --> 00:13:39,760
uh eu tech policy making and

379
00:13:39,760 --> 00:13:42,320
and when we were we prepared this final

380
00:13:42,320 --> 00:13:44,560
you were mentioning how it was in a bit

381
00:13:44,560 --> 00:13:47,600
surprising how fundamentalized are

382
00:13:47,600 --> 00:13:50,399
have become so central in this discourse

383
00:13:50,399 --> 00:13:53,040
so how how do you see this change in

384
00:13:53,040 --> 00:13:56,160
policymaking in the last 10 years is it

385
00:13:56,160 --> 00:13:58,240
a change is the real concept for

386
00:13:58,240 --> 00:13:59,839
fundamental rights is it just on the

387
00:13:59,839 --> 00:14:02,560
superficial level is just a

388
00:14:02,560 --> 00:14:04,560
a way to add in the end of some

389
00:14:04,560 --> 00:14:06,000
amendments and the respect of

390
00:14:06,000 --> 00:14:08,320
fundamental rights and to to do sort of

391
00:14:08,320 --> 00:14:11,519
a tick box exercise that ash allen was

392
00:14:11,519 --> 00:14:15,880
mentioning what do you think

393
00:14:16,079 --> 00:14:17,920
well thank you thanks first of all for

394
00:14:17,920 --> 00:14:19,600
uh for having me

395
00:14:19,600 --> 00:14:21,600
it's a real pleasure um

396
00:14:21,600 --> 00:14:23,440
also to be here with uh amongst the

397
00:14:23,440 --> 00:14:25,839
other speakers so maybe the first i

398
00:14:25,839 --> 00:14:28,720
would say is that you know reflecting on

399
00:14:28,720 --> 00:14:31,360
the state of play from a digital rights

400
00:14:31,360 --> 00:14:34,639
perspective from a perspective of edri

401
00:14:34,639 --> 00:14:37,680
it just strikes me that i mean it's not

402
00:14:37,680 --> 00:14:40,320
the first time that we speak about

403
00:14:40,320 --> 00:14:42,720
this but there's really such an

404
00:14:42,720 --> 00:14:44,480
avalanche of

405
00:14:44,480 --> 00:14:47,120
regulatory proposals and also other

406
00:14:47,120 --> 00:14:49,120
legal developments that are extremely

407
00:14:49,120 --> 00:14:51,279
relevant in this space

408
00:14:51,279 --> 00:14:53,920
the targets that are being regulated

409
00:14:53,920 --> 00:14:57,360
also are immensely powerful and complex

410
00:14:57,360 --> 00:15:00,399
and very fast moving you know both in

411
00:15:00,399 --> 00:15:02,160
the government space and in the private

412
00:15:02,160 --> 00:15:06,240
sector space so uh it's uh it's really

413
00:15:06,240 --> 00:15:08,720
it's a rather challenging environment

414
00:15:08,720 --> 00:15:09,839
and

415
00:15:09,839 --> 00:15:11,519
i mean we know that europe and the

416
00:15:11,519 --> 00:15:12,959
european union and the european

417
00:15:12,959 --> 00:15:15,120
commission has this you know particular

418
00:15:15,120 --> 00:15:17,040
appetite to regulate you know because

419
00:15:17,040 --> 00:15:18,720
maybe other political tools like

420
00:15:18,720 --> 00:15:20,880
spending money in different directions

421
00:15:20,880 --> 00:15:23,680
you know that is not so available uh to

422
00:15:23,680 --> 00:15:26,000
europe there's not so much flexibility

423
00:15:26,000 --> 00:15:27,120
there so

424
00:15:27,120 --> 00:15:29,279
you know furthering the european project

425
00:15:29,279 --> 00:15:31,519
means typically that there will be more

426
00:15:31,519 --> 00:15:34,560
uh regulation more harmonization

427
00:15:34,560 --> 00:15:37,680
but it's very striking how much

428
00:15:37,680 --> 00:15:39,600
is there on the table we have mentioned

429
00:15:39,600 --> 00:15:41,120
already a few

430
00:15:41,120 --> 00:15:42,880
files that are very important but there

431
00:15:42,880 --> 00:15:45,279
are a ton of other files that are very

432
00:15:45,279 --> 00:15:46,959
important from a fundamental rights

433
00:15:46,959 --> 00:15:48,720
perspective and a digital rights

434
00:15:48,720 --> 00:15:51,120
perspective and there's actually hardly

435
00:15:51,120 --> 00:15:52,560
anything

436
00:15:52,560 --> 00:15:54,480
at the table nowadays politically

437
00:15:54,480 --> 00:15:56,880
speaking speaking that doesn't touch of

438
00:15:56,880 --> 00:15:59,839
course on uh the digital in one way or

439
00:15:59,839 --> 00:16:01,360
another so

440
00:16:01,360 --> 00:16:03,759
a bigger reflection i have on that

441
00:16:03,759 --> 00:16:06,399
is that in my uh view

442
00:16:06,399 --> 00:16:09,199
the digital transformation uh

443
00:16:09,199 --> 00:16:12,639
presents uh the european union uh with

444
00:16:12,639 --> 00:16:15,040
somewhat of a constitutional opportunity

445
00:16:15,040 --> 00:16:16,959
like it's a constitutional moment to

446
00:16:16,959 --> 00:16:20,240
kind of re-articulate itself uh in this

447
00:16:20,240 --> 00:16:23,839
time and also um and uh and one of the

448
00:16:23,839 --> 00:16:27,120
ways uh it i mean it does that through a

449
00:16:27,120 --> 00:16:28,560
lot of these kind of regulatory

450
00:16:28,560 --> 00:16:32,480
proposals very very active uh engagement

451
00:16:32,480 --> 00:16:35,440
uh with uh with policy making with new

452
00:16:35,440 --> 00:16:37,120
legislation

453
00:16:37,120 --> 00:16:39,519
and what we can see is that

454
00:16:39,519 --> 00:16:41,839
the digital rights fundamental rights

455
00:16:41,839 --> 00:16:44,959
have really become very very central to

456
00:16:44,959 --> 00:16:49,440
that regulatory project of the ident

457
00:16:49,440 --> 00:16:51,279
articulating europe

458
00:16:51,279 --> 00:16:54,480
with respect to that the challenges of

459
00:16:54,480 --> 00:16:56,959
the digital transformation and and that

460
00:16:56,959 --> 00:16:59,920
is uh quite different i think if we look

461
00:16:59,920 --> 00:17:00,800
back

462
00:17:00,800 --> 00:17:03,360
20 years ago and if we look lower back

463
00:17:03,360 --> 00:17:05,520
of course europe and european union had

464
00:17:05,520 --> 00:17:08,559
a rather ambiguous relationship with

465
00:17:08,559 --> 00:17:10,160
fundamental rights you know before the

466
00:17:10,160 --> 00:17:12,480
charter and when you know europe was

467
00:17:12,480 --> 00:17:14,240
really much more about an internal

468
00:17:14,240 --> 00:17:16,160
market project which of course it still

469
00:17:16,160 --> 00:17:18,160
is you know it is still europe is very

470
00:17:18,160 --> 00:17:20,640
much about the digital single market the

471
00:17:20,640 --> 00:17:21,520
digital

472
00:17:21,520 --> 00:17:23,039
the single market

473
00:17:23,039 --> 00:17:25,439
uh but fundamental rights have become uh

474
00:17:25,439 --> 00:17:27,280
very central to that so

475
00:17:27,280 --> 00:17:30,240
with that i think also that presents uh

476
00:17:30,240 --> 00:17:32,720
communities that are you know really

477
00:17:32,720 --> 00:17:35,919
fighting for uh fundamental rights in uh

478
00:17:35,919 --> 00:17:37,919
protection kind of to get them protected

479
00:17:37,919 --> 00:17:39,919
in a very meaningful way but somewhat of

480
00:17:39,919 --> 00:17:41,440
a challenge because like that

481
00:17:41,440 --> 00:17:43,600
fundamental rights becoming kind of a

482
00:17:43,600 --> 00:17:46,639
more mainstream

483
00:17:46,720 --> 00:17:49,919
thing that is that is on the table so i

484
00:17:49,919 --> 00:17:52,640
do agree with uh with what was asha was

485
00:17:52,640 --> 00:17:54,960
saying that we have to be looking very

486
00:17:54,960 --> 00:17:56,559
carefully what

487
00:17:56,559 --> 00:17:58,960
is actually meant with

488
00:17:58,960 --> 00:18:00,720
protecting fundamental rights you know

489
00:18:00,720 --> 00:18:03,600
just to give one particular example in

490
00:18:03,600 --> 00:18:06,160
the context of the digital services act

491
00:18:06,160 --> 00:18:08,080
one of the fundamental rights that is

492
00:18:08,080 --> 00:18:10,160
obviously very much at stake is the

493
00:18:10,160 --> 00:18:12,160
right to freedom of expression but how

494
00:18:12,160 --> 00:18:14,160
do we define that right what is in the

495
00:18:14,160 --> 00:18:16,559
end the purpose of that right

496
00:18:16,559 --> 00:18:17,840
is it

497
00:18:17,840 --> 00:18:21,520
a very basic kind of a little bit

498
00:18:21,520 --> 00:18:24,480
superficial understanding that

499
00:18:24,480 --> 00:18:26,720
any communication that is free and

500
00:18:26,720 --> 00:18:29,760
unhindered is free speech and everything

501
00:18:29,760 --> 00:18:32,080
that has some kind of restricting effect

502
00:18:32,080 --> 00:18:34,400
on what people can say you know that is

503
00:18:34,400 --> 00:18:37,600
a that is bad so more speech is good uh

504
00:18:37,600 --> 00:18:39,919
less speech restrictions

505
00:18:39,919 --> 00:18:42,160
uh is a is a bad thing from freedom of

506
00:18:42,160 --> 00:18:43,840
expression i think that is an

507
00:18:43,840 --> 00:18:45,440
understanding of freedom of expression

508
00:18:45,440 --> 00:18:47,600
that is typically furthered in a lot of

509
00:18:47,600 --> 00:18:50,000
conversations but of course it uh

510
00:18:50,000 --> 00:18:52,559
disconnects us from what are ultimately

511
00:18:52,559 --> 00:18:55,280
the underlying goals of uh freedom of

512
00:18:55,280 --> 00:18:57,919
expression and and obviously also it can

513
00:18:57,919 --> 00:19:00,640
easily create dynamics where uh

514
00:19:00,640 --> 00:19:03,039
marginalized groups are being pushed out

515
00:19:03,039 --> 00:19:05,679
of the public debate um where

516
00:19:05,679 --> 00:19:08,960
um you know actually we don't get uh

517
00:19:08,960 --> 00:19:11,360
the voices that uh we should all be

518
00:19:11,360 --> 00:19:14,240
hearing you know in uh in our public uh

519
00:19:14,240 --> 00:19:17,039
discussion so i think that is uh that is

520
00:19:17,039 --> 00:19:19,120
super important with fundamental rights

521
00:19:19,120 --> 00:19:20,880
going mainstream i think it's the role

522
00:19:20,880 --> 00:19:23,039
of eduri and other civil society actors

523
00:19:23,039 --> 00:19:26,559
to to really uh to to to to articulate

524
00:19:26,559 --> 00:19:29,200
what these rights should really mean uh

525
00:19:29,200 --> 00:19:32,160
in practice and uh so maybe paying a

526
00:19:32,160 --> 00:19:34,080
little bit more attention to to the

527
00:19:34,080 --> 00:19:37,120
politics of fundamental rights in the in

528
00:19:37,120 --> 00:19:40,719
the eu dynamics

529
00:19:42,480 --> 00:19:43,840
uh thank you

530
00:19:43,840 --> 00:19:45,200
i'm gonna

531
00:19:45,200 --> 00:19:47,120
follow up now with anna but uh for the

532
00:19:47,120 --> 00:19:49,760
rest of the speaker feel free please to

533
00:19:49,760 --> 00:19:51,440
to react directly to each other feel

534
00:19:51,440 --> 00:19:52,640
free to raise your hand either

535
00:19:52,640 --> 00:19:54,480
electronically on the bottom right of

536
00:19:54,480 --> 00:19:56,720
the corner or physically showing me your

537
00:19:56,720 --> 00:19:57,520
hand

538
00:19:57,520 --> 00:19:59,200
and because i'd like to keep this as an

539
00:19:59,200 --> 00:20:01,280
open conversation but i let let's say

540
00:20:01,280 --> 00:20:04,000
let's pass on first to anna and i feel

541
00:20:04,000 --> 00:20:05,919
that she's the our every president she

542
00:20:05,919 --> 00:20:08,320
is also the currently the senior policy

543
00:20:08,320 --> 00:20:10,159
advisor and chairman of privacy

544
00:20:10,159 --> 00:20:12,240
international one of our members

545
00:20:12,240 --> 00:20:14,320
also the senior policy advisor to the

546
00:20:14,320 --> 00:20:16,720
transatlantic consumer dialogue she

547
00:20:16,720 --> 00:20:19,280
covers all types of aspects of consumer

548
00:20:19,280 --> 00:20:21,840
policy from regulations to vital rights

549
00:20:21,840 --> 00:20:24,080
and she works also independently as a

550
00:20:24,080 --> 00:20:27,280
policy research advisor for other public

551
00:20:27,280 --> 00:20:29,200
interest organizations

552
00:20:29,200 --> 00:20:31,200
so so anna i guess you you will have a

553
00:20:31,200 --> 00:20:33,200
lot of things to react all of these you

554
00:20:33,200 --> 00:20:35,679
you have the two hearts and the u.s side

555
00:20:35,679 --> 00:20:37,280
on the eu side you have

556
00:20:37,280 --> 00:20:40,799
a an extensive uh experience so

557
00:20:40,799 --> 00:20:42,799
i guess you want to react to what ugly

558
00:20:42,799 --> 00:20:44,799
said already

559
00:20:44,799 --> 00:20:47,280
well thank you very much for having me

560
00:20:47,280 --> 00:20:48,799
and uh

561
00:20:48,799 --> 00:20:51,120
i'm i'm really pleased to be on such a

562
00:20:51,120 --> 00:20:53,679
distinguished panel with such brilliant

563
00:20:53,679 --> 00:20:54,799
colleagues

564
00:20:54,799 --> 00:20:58,880
um i actually agree with parts or of

565
00:20:58,880 --> 00:21:01,600
everything that my colleague said

566
00:21:01,600 --> 00:21:03,919
previously on this panel

567
00:21:03,919 --> 00:21:06,799
um so maybe i can connect in different

568
00:21:06,799 --> 00:21:09,679
ways and since i'm the old ancient one

569
00:21:09,679 --> 00:21:10,640
here

570
00:21:10,640 --> 00:21:13,600
and i was around and campaigning during

571
00:21:13,600 --> 00:21:16,799
the gdpr days i can actually

572
00:21:16,799 --> 00:21:18,960
put my edri hat on

573
00:21:18,960 --> 00:21:21,840
and and maybe say a little bit what i

574
00:21:21,840 --> 00:21:25,120
think has worked for civil society and

575
00:21:25,120 --> 00:21:27,760
what hasn't but also linking it to a lot

576
00:21:27,760 --> 00:21:29,919
of the messages that

577
00:21:29,919 --> 00:21:32,799
were said previously on this panel

578
00:21:32,799 --> 00:21:33,679
so

579
00:21:33,679 --> 00:21:37,039
what what i've noticed uh in the last 10

580
00:21:37,039 --> 00:21:39,840
years since i joined adrian since we

581
00:21:39,840 --> 00:21:43,200
were campaigning on gdpr

582
00:21:43,200 --> 00:21:46,159
what was quite remarkable during the

583
00:21:46,159 --> 00:21:49,600
gdpr campaign is that we had a lot of

584
00:21:49,600 --> 00:21:51,520
confluences of

585
00:21:51,520 --> 00:21:52,400
um

586
00:21:52,400 --> 00:21:55,360
very good opportunity and in particular

587
00:21:55,360 --> 00:21:57,840
the fact that it was

588
00:21:57,840 --> 00:22:00,159
the rapporteur for that

589
00:22:00,159 --> 00:22:02,400
regulation was a very

590
00:22:02,400 --> 00:22:05,440
fundamental rights friendly

591
00:22:05,440 --> 00:22:08,159
uh supportive person

592
00:22:08,159 --> 00:22:09,679
and and

593
00:22:09,679 --> 00:22:14,240
uh i'm i'm obviously referring to um

594
00:22:14,240 --> 00:22:15,919
jan albrecht

595
00:22:15,919 --> 00:22:20,000
um at that time edri was a relatively

596
00:22:20,000 --> 00:22:23,360
small under-resourced organization

597
00:22:23,360 --> 00:22:26,159
so having this kind of collaboration

598
00:22:26,159 --> 00:22:28,320
with the liber committee and with a

599
00:22:28,320 --> 00:22:29,440
really

600
00:22:29,440 --> 00:22:30,480
um

601
00:22:30,480 --> 00:22:33,679
friendly rapporteur was essential

602
00:22:33,679 --> 00:22:36,240
um and that was very lucky but it

603
00:22:36,240 --> 00:22:38,640
doesn't happen anymore and it's not

604
00:22:38,640 --> 00:22:41,520
quite easy anymore despite the fact that

605
00:22:41,520 --> 00:22:43,919
we've got colleagues like alexandre

606
00:22:43,919 --> 00:22:45,679
giese

607
00:22:45,679 --> 00:22:48,000
is very supportive and

608
00:22:48,000 --> 00:22:52,159
and very welcoming to civil society

609
00:22:52,159 --> 00:22:53,280
so

610
00:22:53,280 --> 00:22:55,600
the positive things that's happened is

611
00:22:55,600 --> 00:22:58,080
that the resources

612
00:22:58,080 --> 00:23:01,520
of the entry and civil society generally

613
00:23:01,520 --> 00:23:04,080
have increased considerably

614
00:23:04,080 --> 00:23:07,679
so we can devote more times to campaign

615
00:23:07,679 --> 00:23:10,799
more times to telling stories

616
00:23:10,799 --> 00:23:13,440
like the the citizen

617
00:23:13,440 --> 00:23:16,559
defend your face campaign

618
00:23:16,559 --> 00:23:19,200
we can form more alliances and that's

619
00:23:19,200 --> 00:23:21,120
another good thing that happened that

620
00:23:21,120 --> 00:23:22,960
the more and more

621
00:23:22,960 --> 00:23:25,679
ngos that don't come from the expert

622
00:23:25,679 --> 00:23:27,840
digital rights field

623
00:23:27,840 --> 00:23:30,240
uh can actually

624
00:23:30,240 --> 00:23:33,039
relate much more to digital rights and

625
00:23:33,039 --> 00:23:35,360
they can tell a story much better than

626
00:23:35,360 --> 00:23:37,039
us i mean

627
00:23:37,039 --> 00:23:38,400
um

628
00:23:38,400 --> 00:23:41,120
to some extent uh for it to give you a

629
00:23:41,120 --> 00:23:43,039
concrete example

630
00:23:43,039 --> 00:23:46,799
um in in the uk when it was still a eu

631
00:23:46,799 --> 00:23:48,000
member

632
00:23:48,000 --> 00:23:52,159
uh when we were arguing for the dpa

633
00:23:52,159 --> 00:23:55,320
digital protection data protection act

634
00:23:55,320 --> 00:23:56,960
implementation

635
00:23:56,960 --> 00:23:59,200
we managed to get through a lot of

636
00:23:59,200 --> 00:24:01,520
positive changes by telling the

637
00:24:01,520 --> 00:24:03,279
children's stories

638
00:24:03,279 --> 00:24:07,000
children are always a good

639
00:24:07,000 --> 00:24:09,840
constituency to tell stories you know

640
00:24:09,840 --> 00:24:10,720
when

641
00:24:10,720 --> 00:24:13,360
in my old days they used to say

642
00:24:13,360 --> 00:24:15,840
if you want a politicians to make

643
00:24:15,840 --> 00:24:17,200
changes

644
00:24:17,200 --> 00:24:21,360
find children animals or dead bodies

645
00:24:21,360 --> 00:24:24,159
and and this is probably

646
00:24:24,159 --> 00:24:26,559
still true today

647
00:24:26,559 --> 00:24:29,760
so i think uh you know we've we've seen

648
00:24:29,760 --> 00:24:33,200
a lot of progress on the part of ngos

649
00:24:33,200 --> 00:24:34,240
but

650
00:24:34,240 --> 00:24:36,799
i've also got very deep questions of

651
00:24:36,799 --> 00:24:39,200
where we go in the future and it is

652
00:24:39,200 --> 00:24:41,600
linked to something that yori said and

653
00:24:41,600 --> 00:24:44,640
also what alexandre has said

654
00:24:44,640 --> 00:24:48,080
we have a tsunami of legislation

655
00:24:48,080 --> 00:24:51,039
uh there's more coming down the line on

656
00:24:51,039 --> 00:24:54,240
different aspects of of digital

657
00:24:54,240 --> 00:24:56,159
it's all pervasive

658
00:24:56,159 --> 00:24:59,200
we spend a lot of effort

659
00:24:59,200 --> 00:25:03,919
on the european parliament legislation

660
00:25:03,919 --> 00:25:07,440
detailed comments on all the amendments

661
00:25:07,440 --> 00:25:10,080
do we really need to do that in the

662
00:25:10,080 --> 00:25:12,799
future or is it something much more

663
00:25:12,799 --> 00:25:15,760
effective that we can do

664
00:25:15,760 --> 00:25:18,400
for example on the alliance side on the

665
00:25:18,400 --> 00:25:20,240
campaigning side

666
00:25:20,240 --> 00:25:23,520
on the story telling side on what asha

667
00:25:23,520 --> 00:25:24,799
is saying

668
00:25:24,799 --> 00:25:28,640
you know finding the right visions and

669
00:25:28,640 --> 00:25:30,240
and also

670
00:25:30,240 --> 00:25:32,640
you know i would i would like to know do

671
00:25:32,640 --> 00:25:36,320
we need this tsunami of laws because

672
00:25:36,320 --> 00:25:39,200
uh whatever happens in the next 10 years

673
00:25:39,200 --> 00:25:41,200
there's more coming down the line

674
00:25:41,200 --> 00:25:42,640
there's the

675
00:25:42,640 --> 00:25:45,760
um the driverless cars they're the

676
00:25:45,760 --> 00:25:49,200
robots there's even smarter cities

677
00:25:49,200 --> 00:25:51,120
and do you know

678
00:25:51,120 --> 00:25:53,720
do we need to concentrate more on the

679
00:25:53,720 --> 00:25:56,799
fundamentals and and find something

680
00:25:56,799 --> 00:26:01,360
overarching and visionary that can sort

681
00:26:01,360 --> 00:26:04,720
the fundamental rights the economics the

682
00:26:04,720 --> 00:26:07,360
ethical aspects

683
00:26:07,360 --> 00:26:09,760
and so on maybe i'll stop here because i

684
00:26:09,760 --> 00:26:12,400
got lots more to say but i i don't want

685
00:26:12,400 --> 00:26:13,440
to

686
00:26:13,440 --> 00:26:15,679
speak too long

687
00:26:15,679 --> 00:26:18,320
okay every speaker ends with a fantastic

688
00:26:18,320 --> 00:26:19,840
cliffhanger

689
00:26:19,840 --> 00:26:21,760
letting us there we need to hear more

690
00:26:21,760 --> 00:26:23,760
from them alexandra you you're the the

691
00:26:23,760 --> 00:26:26,400
policymaker in the room and and

692
00:26:26,400 --> 00:26:28,000
many if not all of this because i

693
00:26:28,000 --> 00:26:30,559
mentioned the tsunami of legislation so

694
00:26:30,559 --> 00:26:32,240
i'd like to hear how do you see that

695
00:26:32,240 --> 00:26:34,400
specific you want to react to that and

696
00:26:34,400 --> 00:26:37,279
also a bit different i'd like to to see

697
00:26:37,279 --> 00:26:38,480
um

698
00:26:38,480 --> 00:26:40,960
to hear from you and i the first time i

699
00:26:40,960 --> 00:26:43,279
met you i i realized you were very

700
00:26:43,279 --> 00:26:45,760
direct very critical which is fantastic

701
00:26:45,760 --> 00:26:47,760
and so i wanted to hear from you i'd

702
00:26:47,760 --> 00:26:50,159
like you to be critical i direct

703
00:26:50,159 --> 00:26:53,600
um since the beginning of the of the uh

704
00:26:53,600 --> 00:26:55,520
of your this little term when you became

705
00:26:55,520 --> 00:26:58,159
mep you were very receptive to ngos who

706
00:26:58,159 --> 00:27:00,640
worked on topics such as these rights

707
00:27:00,640 --> 00:27:02,559
and and you progressed many meeting

708
00:27:02,559 --> 00:27:04,559
requests even more impact from the

709
00:27:04,559 --> 00:27:06,960
industry so there's no need to ask you

710
00:27:06,960 --> 00:27:08,880
if industry is more present than the

711
00:27:08,880 --> 00:27:11,360
city society but i'd like you

712
00:27:11,360 --> 00:27:13,360
if you can in addition to to reply to

713
00:27:13,360 --> 00:27:15,679
the tsunami legislation to try to let us

714
00:27:15,679 --> 00:27:16,480
know

715
00:27:16,480 --> 00:27:19,600
how do you balance the impact of the

716
00:27:19,600 --> 00:27:21,919
tsunami of the of the industry

717
00:27:21,919 --> 00:27:23,039
trying to act on the tsunami or

718
00:27:23,039 --> 00:27:25,679
destination and the the small but

719
00:27:25,679 --> 00:27:27,039
increasing group of digital rights

720
00:27:27,039 --> 00:27:30,399
groups how do you see that

721
00:27:30,399 --> 00:27:32,320
yeah thank you for that complicated

722
00:27:32,320 --> 00:27:34,080
question i i start being a lot a little

723
00:27:34,080 --> 00:27:35,520
bit worried about all these people

724
00:27:35,520 --> 00:27:38,000
telling me i'm very direct

725
00:27:38,000 --> 00:27:39,440
i think that

726
00:27:39,440 --> 00:27:41,360
might might be a lack of of the warm

727
00:27:41,360 --> 00:27:44,320
dream diplomatic skills as well but yeah

728
00:27:44,320 --> 00:27:47,039
i take it as a compliment for this time

729
00:27:47,039 --> 00:27:49,600
um there is indeed a tsunami of

730
00:27:49,600 --> 00:27:52,799
legislation coming um directly uh

731
00:27:52,799 --> 00:27:55,600
political advertising which uh i think

732
00:27:55,600 --> 00:27:57,279
would give us the chance to reopen the

733
00:27:57,279 --> 00:27:59,039
battle on surveillance advertising

734
00:27:59,039 --> 00:28:01,200
explaining even better having even

735
00:28:01,200 --> 00:28:02,960
better stories and getting politicians

736
00:28:02,960 --> 00:28:05,039
even a lot more involved so i think that

737
00:28:05,039 --> 00:28:06,000
is one

738
00:28:06,000 --> 00:28:08,720
and the ai act obviously is is the big

739
00:28:08,720 --> 00:28:10,880
one that everybody's already working on

740
00:28:10,880 --> 00:28:13,120
and and it's it's a tsunami even for us

741
00:28:13,120 --> 00:28:15,279
because even we you know we are paid for

742
00:28:15,279 --> 00:28:17,039
just doing that and have a team to do

743
00:28:17,039 --> 00:28:20,000
that to sort of lose um control over

744
00:28:20,000 --> 00:28:23,200
what's going on and can cover everything

745
00:28:23,200 --> 00:28:25,440
um

746
00:28:25,919 --> 00:28:28,240
in terms of um

747
00:28:28,240 --> 00:28:30,240
i really don't know how to solve the

748
00:28:30,240 --> 00:28:33,760
problem that obviously companies have a

749
00:28:33,760 --> 00:28:37,360
lot more lobbying power than than ngos i

750
00:28:37,360 --> 00:28:40,240
mean i personally try to say you know my

751
00:28:40,240 --> 00:28:43,840
team um is supposed to organize meetings

752
00:28:43,840 --> 00:28:45,279
50

753
00:28:45,279 --> 00:28:47,520
civil society and 50

754
00:28:47,520 --> 00:28:48,880
companies

755
00:28:48,880 --> 00:28:51,039
um but the requests that are coming it's

756
00:28:51,039 --> 00:28:53,520
like 98 come from companies and we

757
00:28:53,520 --> 00:28:55,919
ignore like hundreds of them

758
00:28:55,919 --> 00:28:57,919
so it's it's really difficult and i

759
00:28:57,919 --> 00:28:59,279
don't know how to solve that i mean

760
00:28:59,279 --> 00:29:01,520
there's specific issues in specific

761
00:29:01,520 --> 00:29:02,880
countries like in german we're in

762
00:29:02,880 --> 00:29:05,279
germany we have fiscal issues and so on

763
00:29:05,279 --> 00:29:08,080
but i think on a european level i i i

764
00:29:08,080 --> 00:29:10,320
just don't have the solution um to be to

765
00:29:10,320 --> 00:29:13,279
be very very honest i just do what i can

766
00:29:13,279 --> 00:29:15,360
to to have you on board to talk as much

767
00:29:15,360 --> 00:29:16,880
as possible

768
00:29:16,880 --> 00:29:19,840
um i think anna made an important point

769
00:29:19,840 --> 00:29:22,480
saying well maybe we don't need to do

770
00:29:22,480 --> 00:29:24,320
detailed comments on every single

771
00:29:24,320 --> 00:29:27,919
amendment i mean i think it you as like

772
00:29:27,919 --> 00:29:30,240
the same way that i have to prioritize

773
00:29:30,240 --> 00:29:32,159
and i just can't do everything i know

774
00:29:32,159 --> 00:29:34,000
would be helpful and i tried to pick

775
00:29:34,000 --> 00:29:36,159
just this this one two three important

776
00:29:36,159 --> 00:29:38,799
political points and to work on those

777
00:29:38,799 --> 00:29:40,880
i think that's what what you can do as

778
00:29:40,880 --> 00:29:41,679
well

779
00:29:41,679 --> 00:29:43,919
what has been very successful i think in

780
00:29:43,919 --> 00:29:45,919
this term especially around surveillance

781
00:29:45,919 --> 00:29:48,960
advertising um which the campaign that

782
00:29:48,960 --> 00:29:50,640
i've been you know pushing and following

783
00:29:50,640 --> 00:29:52,720
most was the alliance building i mean

784
00:29:52,720 --> 00:29:54,240
that was really exceptional like

785
00:29:54,240 --> 00:29:57,279
throughout five ngos working together so

786
00:29:57,279 --> 00:29:59,360
maybe you can use that for some kind of

787
00:29:59,360 --> 00:30:02,720
division of labor so some people in one

788
00:30:02,720 --> 00:30:05,600
law specialize in in one aspect of it

789
00:30:05,600 --> 00:30:08,399
and others and others you know just do

790
00:30:08,399 --> 00:30:11,200
some division of labor and so because

791
00:30:11,200 --> 00:30:13,440
just very frankly policy makers don't

792
00:30:13,440 --> 00:30:16,960
read 100 different comments on

793
00:30:16,960 --> 00:30:18,799
3 000 amendments there's just no way to

794
00:30:18,799 --> 00:30:19,760
do that

795
00:30:19,760 --> 00:30:22,640
so maybe it's important to pick those

796
00:30:22,640 --> 00:30:24,960
aspects that you specialize on exchange

797
00:30:24,960 --> 00:30:28,559
a little bit with other ngos um and then

798
00:30:28,559 --> 00:30:30,559
put that forward i mean that's probably

799
00:30:30,559 --> 00:30:32,480
what you're already doing but i i have

800
00:30:32,480 --> 00:30:34,399
seen very long comments from from your

801
00:30:34,399 --> 00:30:35,360
part

802
00:30:35,360 --> 00:30:37,679
and and i know how much work is involved

803
00:30:37,679 --> 00:30:39,520
and maybe there's a way to deal with

804
00:30:39,520 --> 00:30:41,840
that that better we won't solve the

805
00:30:41,840 --> 00:30:43,520
problem that google has so much more

806
00:30:43,520 --> 00:30:45,200
money than edwy that's

807
00:30:45,200 --> 00:30:47,279
you know nobody has the solution of us i

808
00:30:47,279 --> 00:30:48,880
think

809
00:30:48,880 --> 00:30:50,960
um there are a couple of more points i

810
00:30:50,960 --> 00:30:54,000
wanted to make i think joe's point about

811
00:30:54,000 --> 00:30:56,159
what exactly is freedom of expression

812
00:30:56,159 --> 00:30:58,559
was extremely important because that's

813
00:30:58,559 --> 00:31:00,240
something i've been

814
00:31:00,240 --> 00:31:02,559
particularly struggling with and some of

815
00:31:02,559 --> 00:31:04,960
you have followed that um with with the

816
00:31:04,960 --> 00:31:07,120
issues on the point platforms where we

817
00:31:07,120 --> 00:31:08,880
clearly have that that issue what is

818
00:31:08,880 --> 00:31:11,200
freedom of expression is it just being

819
00:31:11,200 --> 00:31:13,760
able to post and say and post any image

820
00:31:13,760 --> 00:31:15,919
you want to you want to post or is it

821
00:31:15,919 --> 00:31:18,480
about giving making sure that everybody

822
00:31:18,480 --> 00:31:20,559
is included in the conversation

823
00:31:20,559 --> 00:31:23,039
and that today is not the case so i

824
00:31:23,039 --> 00:31:25,200
think an organization like edward has a

825
00:31:25,200 --> 00:31:27,600
really important role in and taking this

826
00:31:27,600 --> 00:31:29,519
conversation forward because nobody has

827
00:31:29,519 --> 00:31:30,960
the exact

828
00:31:30,960 --> 00:31:32,480
solution for that

829
00:31:32,480 --> 00:31:34,559
um two more

830
00:31:34,559 --> 00:31:36,480
um points like that where i think the

831
00:31:36,480 --> 00:31:38,960
conversation is shifting and where i

832
00:31:38,960 --> 00:31:41,600
really appreciate your your contribution

833
00:31:41,600 --> 00:31:42,640
is that

834
00:31:42,640 --> 00:31:44,880
when i started privacy was very much

835
00:31:44,880 --> 00:31:47,840
seen as as an individual right so as

836
00:31:47,840 --> 00:31:50,159
long as i as an individual can protect

837
00:31:50,159 --> 00:31:52,480
myself from being spied on everything is

838
00:31:52,480 --> 00:31:55,039
fine and i think what we're seeing now

839
00:31:55,039 --> 00:31:57,679
is that privacy is something that

840
00:31:57,679 --> 00:32:00,240
preserves democracies because it keeps

841
00:32:00,240 --> 00:32:02,720
governments but also private companies

842
00:32:02,720 --> 00:32:05,600
from manipulating society as a whole or

843
00:32:05,600 --> 00:32:07,519
larger population groups

844
00:32:07,519 --> 00:32:10,640
so i think that is that is a a paradigm

845
00:32:10,640 --> 00:32:12,960
shift that still needs to be pronounced

846
00:32:12,960 --> 00:32:14,960
more clearly and made made more more

847
00:32:14,960 --> 00:32:16,799
clear and open and be worked on and

848
00:32:16,799 --> 00:32:17,919
discussed

849
00:32:17,919 --> 00:32:19,519
that privacy is really not only an

850
00:32:19,519 --> 00:32:20,880
individual instrument but it's a

851
00:32:20,880 --> 00:32:22,640
collective instrument to protect

852
00:32:22,640 --> 00:32:24,320
democracy

853
00:32:24,320 --> 00:32:26,000
and the other one is

854
00:32:26,000 --> 00:32:30,960
that privacy is important to um to

855
00:32:30,960 --> 00:32:32,880
implement not only against governments

856
00:32:32,880 --> 00:32:35,440
but against private actors as well

857
00:32:35,440 --> 00:32:37,120
because what we see today is that the

858
00:32:37,120 --> 00:32:39,120
platforms private actors are more

859
00:32:39,120 --> 00:32:41,760
powerful than most governments actually

860
00:32:41,760 --> 00:32:43,919
and that is something that not everybody

861
00:32:43,919 --> 00:32:44,880
who

862
00:32:44,880 --> 00:32:46,799
you know is an activist in terms of

863
00:32:46,799 --> 00:32:49,440
digital rights is sharing as a view so i

864
00:32:49,440 --> 00:32:51,600
think that's that's already also so very

865
00:32:51,600 --> 00:32:53,360
very very important

866
00:32:53,360 --> 00:32:55,440
but um

867
00:32:55,440 --> 00:32:58,960
yeah that's i think basically my my most

868
00:32:58,960 --> 00:33:00,640
important points i have to say i've been

869
00:33:00,640 --> 00:33:04,159
extremely happy um about our cooperation

870
00:33:04,159 --> 00:33:07,120
work with you and the other um ngos i

871
00:33:07,120 --> 00:33:08,960
mean what we achieved in the dsa last

872
00:33:08,960 --> 00:33:10,480
week would not have been possible

873
00:33:10,480 --> 00:33:13,039
without you absolutely not so your role

874
00:33:13,039 --> 00:33:15,200
was was absolutely instrumental

875
00:33:15,200 --> 00:33:17,840
absolutely crucial and i'm i'm extremely

876
00:33:17,840 --> 00:33:19,840
grateful so i i'm not here to give

877
00:33:19,840 --> 00:33:21,600
advice but rather to to thank you for

878
00:33:21,600 --> 00:33:23,200
what you're already doing

879
00:33:23,200 --> 00:33:25,039
very in a great place to continue doing

880
00:33:25,039 --> 00:33:26,559
that

881
00:33:26,559 --> 00:33:28,320
thank you alexandra i wish those were

882
00:33:28,320 --> 00:33:29,679
your final words and we can finish with

883
00:33:29,679 --> 00:33:32,240
that but we're gonna continue thank you

884
00:33:32,240 --> 00:33:34,960
for being both direct and very kind and

885
00:33:34,960 --> 00:33:37,760
asha i know you wanted to to react to

886
00:33:37,760 --> 00:33:40,159
the tsunami issue and then

887
00:33:40,159 --> 00:33:42,320
how uh the harmonization and the

888
00:33:42,320 --> 00:33:44,559
enforcement and implementation

889
00:33:44,559 --> 00:33:47,519
what do we do with all of this

890
00:33:47,519 --> 00:33:49,120
so yeah i would love to touch on those

891
00:33:49,120 --> 00:33:50,960
issues but i i can't not take the

892
00:33:50,960 --> 00:33:52,960
opportunity to touch on the other ones

893
00:33:52,960 --> 00:33:55,760
as well and just absolutely plus one uh

894
00:33:55,760 --> 00:33:57,519
alexandra there on the paradigm shift

895
00:33:57,519 --> 00:33:59,519
when it comes to talking about privacy

896
00:33:59,519 --> 00:34:01,519
because one of the aspects that we've

897
00:34:01,519 --> 00:34:02,880
been following and kind of using the

898
00:34:02,880 --> 00:34:04,559
perspective that we have is what is

899
00:34:04,559 --> 00:34:05,919
going to be the impact of these

900
00:34:05,919 --> 00:34:09,359
legislations on online civic spaces

901
00:34:09,359 --> 00:34:11,839
we're in a context in which consistently

902
00:34:11,839 --> 00:34:13,119
we are looking at shrinking civil

903
00:34:13,119 --> 00:34:15,280
society space in europe but also

904
00:34:15,280 --> 00:34:17,440
globally and so this is kind of the lens

905
00:34:17,440 --> 00:34:18,639
that we're looking through this and it's

906
00:34:18,639 --> 00:34:20,159
so important that that collective

907
00:34:20,159 --> 00:34:22,320
dynamic is kind of understood because

908
00:34:22,320 --> 00:34:23,679
then it relates to what i was talking

909
00:34:23,679 --> 00:34:25,359
about earlier in terms of the impact on

910
00:34:25,359 --> 00:34:26,960
marginalized groups and and how that

911
00:34:26,960 --> 00:34:29,440
manifests in that in that sort of way

912
00:34:29,440 --> 00:34:31,679
um and once again two plus one on the

913
00:34:31,679 --> 00:34:33,599
civil society collaboration we've had

914
00:34:33,599 --> 00:34:35,760
the honor of working so closely um with

915
00:34:35,760 --> 00:34:38,000
all of you uh on these different pieces

916
00:34:38,000 --> 00:34:40,560
and i think that's been the strength um

917
00:34:40,560 --> 00:34:42,159
i come from a background in which

918
00:34:42,159 --> 00:34:43,839
working together women's organizations

919
00:34:43,839 --> 00:34:45,839
having to come together um even on the

920
00:34:45,839 --> 00:34:48,399
minuscule amount of capacity and funding

921
00:34:48,399 --> 00:34:50,719
that's necessary and that's available to

922
00:34:50,719 --> 00:34:53,359
be able to to work miracles um and so

923
00:34:53,359 --> 00:34:54,800
this is really our strength that

924
00:34:54,800 --> 00:34:57,200
coordination and coming together but

925
00:34:57,200 --> 00:34:58,720
it's not just with the digital rights

926
00:34:58,720 --> 00:35:00,320
colleagues that we may be more familiar

927
00:35:00,320 --> 00:35:01,599
with it is about those other

928
00:35:01,599 --> 00:35:03,920
organizations who are working on these

929
00:35:03,920 --> 00:35:05,599
issues from their different perspectives

930
00:35:05,599 --> 00:35:07,359
i know that we're in close collaboration

931
00:35:07,359 --> 00:35:09,119
with say the european disability forum

932
00:35:09,119 --> 00:35:11,599
and anti-racism networks and lgbt

933
00:35:11,599 --> 00:35:13,200
networks and women's networks and i

934
00:35:13,200 --> 00:35:15,920
think we really need to maximize on that

935
00:35:15,920 --> 00:35:17,839
so maybe a thought in terms of what the

936
00:35:17,839 --> 00:35:19,920
digital rights field can be doing next i

937
00:35:19,920 --> 00:35:21,440
know we're already doing this but we

938
00:35:21,440 --> 00:35:22,960
definitely have the opportunity to ramp

939
00:35:22,960 --> 00:35:25,280
up on this as we move forward but when

940
00:35:25,280 --> 00:35:27,040
it comes to the harmonization and the

941
00:35:27,040 --> 00:35:28,880
tsunami of legislation i'm definitely

942
00:35:28,880 --> 00:35:31,440
taking that term with me um after this

943
00:35:31,440 --> 00:35:33,760
session but i think the biggest thing

944
00:35:33,760 --> 00:35:36,240
here is around harmonization i know we

945
00:35:36,240 --> 00:35:37,839
were kind of addressing this question on

946
00:35:37,839 --> 00:35:39,680
you know do we need more and and what do

947
00:35:39,680 --> 00:35:41,760
we need to do and

948
00:35:41,760 --> 00:35:43,200
when it comes to harmonization i mean

949
00:35:43,200 --> 00:35:45,280
there's the traditional eu sense of

950
00:35:45,280 --> 00:35:47,119
ensuring regulations are equally

951
00:35:47,119 --> 00:35:49,359
parachuted out into the 27 member states

952
00:35:49,359 --> 00:35:50,960
but more importantly i would highlight

953
00:35:50,960 --> 00:35:52,320
the need to harmonize between the

954
00:35:52,320 --> 00:35:54,079
different legislative pieces as

955
00:35:54,079 --> 00:35:56,560
alexander was getting to that are coming

956
00:35:56,560 --> 00:35:58,400
up that may not even necessarily be at

957
00:35:58,400 --> 00:36:00,400
the forefront of the mind um when it

958
00:36:00,400 --> 00:36:02,079
comes to this so we have the online

959
00:36:02,079 --> 00:36:05,359
political ads for sure um and i think

960
00:36:05,359 --> 00:36:06,800
big questions are going to have to be

961
00:36:06,800 --> 00:36:08,320
addressed um in this and we'll be

962
00:36:08,320 --> 00:36:10,560
engaging quite a lot um because there

963
00:36:10,560 --> 00:36:12,560
are you know how effective is this going

964
00:36:12,560 --> 00:36:14,400
to be how much is it going to align with

965
00:36:14,400 --> 00:36:16,079
the digital services act do the

966
00:36:16,079 --> 00:36:18,160
provisions make sense and how do certain

967
00:36:18,160 --> 00:36:20,560
articles work um and i won't get into

968
00:36:20,560 --> 00:36:22,320
the details of that but we have some

969
00:36:22,320 --> 00:36:23,760
questions around how this will work and

970
00:36:23,760 --> 00:36:25,839
how it'll be effective but we also know

971
00:36:25,839 --> 00:36:28,079
that there's going to be um a directive

972
00:36:28,079 --> 00:36:29,839
or some sort of legislation on on

973
00:36:29,839 --> 00:36:32,000
gender-based violence which will include

974
00:36:32,000 --> 00:36:34,079
uh obligations for platforms to address

975
00:36:34,079 --> 00:36:36,320
online gender-based violence how is this

976
00:36:36,320 --> 00:36:38,400
going to work in line with the other

977
00:36:38,400 --> 00:36:40,079
legislations that we have on our hands

978
00:36:40,079 --> 00:36:41,839
how is it going to be effective to

979
00:36:41,839 --> 00:36:44,160
actually help uh survivors and have

980
00:36:44,160 --> 00:36:45,839
preventative measures to make sure that

981
00:36:45,839 --> 00:36:47,280
we are addressing the issues that we're

982
00:36:47,280 --> 00:36:49,760
trying to address so this brings me all

983
00:36:49,760 --> 00:36:52,000
to the conversation around enforcement

984
00:36:52,000 --> 00:36:54,480
and implementation and this is really

985
00:36:54,480 --> 00:36:56,560
where the meat of the bones are i think

986
00:36:56,560 --> 00:36:58,400
are for the next kind of two and a half

987
00:36:58,400 --> 00:37:00,640
years of this legislative term really

988
00:37:00,640 --> 00:37:03,119
getting into that because having worked

989
00:37:03,119 --> 00:37:05,680
in civil society for a long time um i

990
00:37:05,680 --> 00:37:06,960
think when you have a piece of

991
00:37:06,960 --> 00:37:08,400
legislation that's well defined it's

992
00:37:08,400 --> 00:37:09,839
fantastic it's good to have the

993
00:37:09,839 --> 00:37:11,760
legislative clarity it's good to have a

994
00:37:11,760 --> 00:37:13,760
framework that you can build upon and

995
00:37:13,760 --> 00:37:15,599
there can be enforcement and mechanisms

996
00:37:15,599 --> 00:37:18,640
outlines but if it is not effectively

997
00:37:18,640 --> 00:37:20,640
effectively implemented it's not going

998
00:37:20,640 --> 00:37:22,720
to have the impact that it's intended to

999
00:37:22,720 --> 00:37:24,880
have and so this is where i think the

1000
00:37:24,880 --> 00:37:27,119
shift and the focus needs to be

1001
00:37:27,119 --> 00:37:29,119
throughout the next uh the rest of this

1002
00:37:29,119 --> 00:37:30,960
legislative term but probably into the

1003
00:37:30,960 --> 00:37:33,359
next one um as well about how do we

1004
00:37:33,359 --> 00:37:34,720
enforce the mechanisms that we have

1005
00:37:34,720 --> 00:37:36,720
spent a lot of time and a lot of energy

1006
00:37:36,720 --> 00:37:39,359
into designing and making sure that they

1007
00:37:39,359 --> 00:37:40,960
actively work so whether we need new

1008
00:37:40,960 --> 00:37:43,040
legislation in the new led in the next

1009
00:37:43,040 --> 00:37:46,160
term is a very good question and i think

1010
00:37:46,160 --> 00:37:48,560
just in general continuity of these

1011
00:37:48,560 --> 00:37:50,720
five-year eu terms needs to be a

1012
00:37:50,720 --> 00:37:53,520
fundamental thread um that moves forward

1013
00:37:53,520 --> 00:37:55,200
but i would really just love to see the

1014
00:37:55,200 --> 00:37:57,760
shift be there how is this going to work

1015
00:37:57,760 --> 00:37:59,440
practically and how are we going to make

1016
00:37:59,440 --> 00:38:02,720
sure it's as effective as

1017
00:38:02,839 --> 00:38:05,920
possible thank you anna you you raised

1018
00:38:05,920 --> 00:38:08,400
your hand and perhaps in addition to

1019
00:38:08,400 --> 00:38:10,960
what you might want to react to directly

1020
00:38:10,960 --> 00:38:12,560
also to hear your views from the hr

1021
00:38:12,560 --> 00:38:14,560
enforcement because uh

1022
00:38:14,560 --> 00:38:15,920
as you said you were involved in the

1023
00:38:15,920 --> 00:38:19,040
gdpr negotiations i write halfway or

1024
00:38:19,040 --> 00:38:21,200
closer to the end of gdpr but i'm also

1025
00:38:21,200 --> 00:38:22,800
curious to see to hear your views on

1026
00:38:22,800 --> 00:38:25,440
this open person but let's go ahead

1027
00:38:25,440 --> 00:38:27,920
yeah i'd i raised my hand because i

1028
00:38:27,920 --> 00:38:30,720
wanted to react directly to what asha

1029
00:38:30,720 --> 00:38:32,640
was saying and continue that

1030
00:38:32,640 --> 00:38:35,599
conversation which is effectively about

1031
00:38:35,599 --> 00:38:38,079
member states and then enforcement of

1032
00:38:38,079 --> 00:38:39,040
course

1033
00:38:39,040 --> 00:38:39,920
um

1034
00:38:39,920 --> 00:38:42,880
we we must remember the you know the the

1035
00:38:42,880 --> 00:38:46,000
eu does harmonization and regulations

1036
00:38:46,000 --> 00:38:49,040
but not all member states are equal and

1037
00:38:49,040 --> 00:38:50,880
by that i mean

1038
00:38:50,880 --> 00:38:53,839
in the way they interpret legislation in

1039
00:38:53,839 --> 00:38:56,880
the way they treat civil society

1040
00:38:56,880 --> 00:38:58,480
and

1041
00:38:58,480 --> 00:39:00,480
in in the way

1042
00:39:00,480 --> 00:39:02,480
they are willing to enforce this

1043
00:39:02,480 --> 00:39:05,440
legislation and i myself come from

1044
00:39:05,440 --> 00:39:06,960
eastern europe

1045
00:39:06,960 --> 00:39:10,079
um so i'm very very familiar with that

1046
00:39:10,079 --> 00:39:11,839
part of the world

1047
00:39:11,839 --> 00:39:14,400
and as you know what's happening now in

1048
00:39:14,400 --> 00:39:17,359
hungary and what's happening in poland

1049
00:39:17,359 --> 00:39:21,920
um is not is not entirely um you know

1050
00:39:21,920 --> 00:39:25,440
conductive to social democracy not

1051
00:39:25,440 --> 00:39:27,440
conductive to

1052
00:39:27,440 --> 00:39:30,000
implementation of this very valuable

1053
00:39:30,000 --> 00:39:32,640
fundamental rights laws

1054
00:39:32,640 --> 00:39:35,119
so i think we need to very think very

1055
00:39:35,119 --> 00:39:37,280
carefully and take that into account

1056
00:39:37,280 --> 00:39:40,079
also in our ngo strategy

1057
00:39:40,079 --> 00:39:43,119
how do we engage

1058
00:39:43,119 --> 00:39:45,599
uh civil society not just our entry

1059
00:39:45,599 --> 00:39:47,200
members but

1060
00:39:47,200 --> 00:39:50,320
you know all civil society

1061
00:39:50,320 --> 00:39:51,920
in those country

1062
00:39:51,920 --> 00:39:54,560
in those countries to actually

1063
00:39:54,560 --> 00:39:57,839
influence more and be heard more and be

1064
00:39:57,839 --> 00:39:59,440
more developed

1065
00:39:59,440 --> 00:40:01,359
because until

1066
00:40:01,359 --> 00:40:03,599
we learn how to

1067
00:40:03,599 --> 00:40:07,680
operate effectively in member states

1068
00:40:07,680 --> 00:40:10,000
and you know in some countries we have

1069
00:40:10,000 --> 00:40:12,640
very powerful members in you know in the

1070
00:40:12,640 --> 00:40:14,319
netherlands and

1071
00:40:14,319 --> 00:40:17,119
france and so on but we don't in all

1072
00:40:17,119 --> 00:40:20,480
member states and and those states come

1073
00:40:20,480 --> 00:40:23,599
into trial logs they come and negotiate

1074
00:40:23,599 --> 00:40:26,560
and they're very very much influenced by

1075
00:40:26,560 --> 00:40:29,280
their industries

1076
00:40:29,280 --> 00:40:32,480
and and we've seen many many examples of

1077
00:40:32,480 --> 00:40:36,079
that including to come to enforcement

1078
00:40:36,079 --> 00:40:38,560
uh what's happening with the gdpr

1079
00:40:38,560 --> 00:40:41,359
enforcement in ireland for example

1080
00:40:41,359 --> 00:40:44,319
where economic consideration the fact

1081
00:40:44,319 --> 00:40:47,359
that these companies employ many many

1082
00:40:47,359 --> 00:40:50,400
irish people have primary consideration

1083
00:40:50,400 --> 00:40:54,880
over enforcement of the legislation

1084
00:40:54,880 --> 00:40:57,760
so so how do we deal with that i mean

1085
00:40:57,760 --> 00:41:00,079
what's been really positive in the

1086
00:41:00,079 --> 00:41:02,400
enforcement of gdpr

1087
00:41:02,400 --> 00:41:05,839
has been this uh very rapid development

1088
00:41:05,839 --> 00:41:09,680
of so-called strategic litigation

1089
00:41:09,680 --> 00:41:11,119
we now have

1090
00:41:11,119 --> 00:41:12,640
um

1091
00:41:12,640 --> 00:41:16,480
many uh ngo organizations that

1092
00:41:16,480 --> 00:41:18,839
engage in that we we actually have a

1093
00:41:18,839 --> 00:41:21,119
specialist litigation member

1094
00:41:21,119 --> 00:41:23,920
organization in austria that does

1095
00:41:23,920 --> 00:41:25,920
fantastic job

1096
00:41:25,920 --> 00:41:27,920
of course i'm referring to

1097
00:41:27,920 --> 00:41:29,200
to noibe

1098
00:41:29,200 --> 00:41:31,119
but actually

1099
00:41:31,119 --> 00:41:34,240
is this the best way is litigation the

1100
00:41:34,240 --> 00:41:36,400
best way to proceed i mean we've got the

1101
00:41:36,400 --> 00:41:38,960
collective redress directive coming on

1102
00:41:38,960 --> 00:41:40,800
the way and being implemented and

1103
00:41:40,800 --> 00:41:43,280
hopefully that will mean

1104
00:41:43,280 --> 00:41:45,839
that you know it will enable

1105
00:41:45,839 --> 00:41:48,880
at least consumer organizations because

1106
00:41:48,880 --> 00:41:52,720
even that directive is very restrictive

1107
00:41:52,720 --> 00:41:54,400
to take more

1108
00:41:54,400 --> 00:41:57,520
collective redress or class action cases

1109
00:41:57,520 --> 00:41:59,560
because a lot of the

1110
00:41:59,560 --> 00:42:03,040
implementation problems with gdpr and

1111
00:42:03,040 --> 00:42:06,000
other legislation like this it doesn't

1112
00:42:06,000 --> 00:42:10,160
show necessarily huge material damage

1113
00:42:10,160 --> 00:42:12,800
to individuals but when you take the

1114
00:42:12,800 --> 00:42:15,839
collective of individual and mass when

1115
00:42:15,839 --> 00:42:18,560
you take the future of society and

1116
00:42:18,560 --> 00:42:22,000
democracy into consideration the impact

1117
00:42:22,000 --> 00:42:24,640
is enormous so i don't think we've

1118
00:42:24,640 --> 00:42:27,359
solved the enforcement dilemma

1119
00:42:27,359 --> 00:42:28,640
and and

1120
00:42:28,640 --> 00:42:32,160
laws such as gdpr allow for too much

1121
00:42:32,160 --> 00:42:34,400
flexibility

1122
00:42:34,400 --> 00:42:37,119
that poses too many challenges in

1123
00:42:37,119 --> 00:42:40,480
enforcement and litigation is one

1124
00:42:40,480 --> 00:42:43,200
solution but it's not ultimately the

1125
00:42:43,200 --> 00:42:47,200
solution in in my view

1126
00:42:47,920 --> 00:42:50,160
do you want to react to that

1127
00:42:50,160 --> 00:42:52,000
no those those were all really great

1128
00:42:52,000 --> 00:42:54,160
comments i mean i'm i'm wondering uh

1129
00:42:54,160 --> 00:42:56,000
what i was gonna say i mean

1130
00:42:56,000 --> 00:42:58,560
maybe

1131
00:42:58,560 --> 00:43:00,720
i mean that question of that question of

1132
00:43:00,720 --> 00:43:02,800
enforcement you know like i mean i think

1133
00:43:02,800 --> 00:43:04,640
i mean i think the worry is that you can

1134
00:43:04,640 --> 00:43:06,640
be very effective maybe at the european

1135
00:43:06,640 --> 00:43:08,880
level but ultimately those laws are not

1136
00:43:08,880 --> 00:43:10,800
landing and you know like what is

1137
00:43:10,800 --> 00:43:12,400
actually happening in our societies

1138
00:43:12,400 --> 00:43:14,400
doesn't reflect you know the laws that

1139
00:43:14,400 --> 00:43:15,359
end up

1140
00:43:15,359 --> 00:43:17,520
being adopted at the eu level

1141
00:43:17,520 --> 00:43:19,040
and um

1142
00:43:19,040 --> 00:43:21,200
and i think that is uh i think that is a

1143
00:43:21,200 --> 00:43:23,359
real danger i think with gdpr

1144
00:43:23,359 --> 00:43:25,680
enforcement the glass is also half full

1145
00:43:25,680 --> 00:43:28,319
you know it's it's quite easy to to to

1146
00:43:28,319 --> 00:43:30,000
complain about a lot of the things that

1147
00:43:30,000 --> 00:43:31,920
are are not going well but there's a lot

1148
00:43:31,920 --> 00:43:33,839
of attention also to the things that are

1149
00:43:33,839 --> 00:43:36,800
not going well which is a very good sign

1150
00:43:36,800 --> 00:43:39,920
uh and and i think uh we're all learning

1151
00:43:39,920 --> 00:43:42,319
uh from that the thing that i would say

1152
00:43:42,319 --> 00:43:43,760
is that

1153
00:43:43,760 --> 00:43:46,160
it is very important to take a broad

1154
00:43:46,160 --> 00:43:49,040
view uh if you want effective protection

1155
00:43:49,040 --> 00:43:51,040
of digital rights and effectuate

1156
00:43:51,040 --> 00:43:52,880
fundamental rights protection more

1157
00:43:52,880 --> 00:43:55,599
generally i'm a little bit concerned

1158
00:43:55,599 --> 00:43:59,280
about uh the kind of outsized role uh

1159
00:43:59,280 --> 00:44:01,520
that is sometimes imagined uh for

1160
00:44:01,520 --> 00:44:04,319
certain players you know like

1161
00:44:04,319 --> 00:44:06,720
actually like civil society and academia

1162
00:44:06,720 --> 00:44:08,800
you know they get this role in the in

1163
00:44:08,800 --> 00:44:11,280
the digital service act no

1164
00:44:11,280 --> 00:44:13,520
the idea seems to be that

1165
00:44:13,520 --> 00:44:16,000
civil society and and academic

1166
00:44:16,000 --> 00:44:17,760
organizations are going to basically

1167
00:44:17,760 --> 00:44:20,240
systematically monitor all sorts of ways

1168
00:44:20,240 --> 00:44:22,880
in which platform companies dominant

1169
00:44:22,880 --> 00:44:24,960
platform companies are presenting issues

1170
00:44:24,960 --> 00:44:27,359
and personally my experience in academia

1171
00:44:27,359 --> 00:44:29,119
is academics they like to write papers

1172
00:44:29,119 --> 00:44:30,960
about new stuff and then they will move

1173
00:44:30,960 --> 00:44:33,760
on to new topics so really doing

1174
00:44:33,760 --> 00:44:35,920
systematic monitoring it doesn't really

1175
00:44:35,920 --> 00:44:38,720
fit uh let's put it very bluntly the

1176
00:44:38,720 --> 00:44:41,520
academic publication business uh

1177
00:44:41,520 --> 00:44:43,200
incentives you know the business model

1178
00:44:43,200 --> 00:44:44,400
of

1179
00:44:44,400 --> 00:44:46,720
in academia and i think for civil

1180
00:44:46,720 --> 00:44:48,480
society it's it's a little bit

1181
00:44:48,480 --> 00:44:51,119
overstretched and then i mean the dsa is

1182
00:44:51,119 --> 00:44:53,520
a very good example of actually it's a

1183
00:44:53,520 --> 00:44:55,680
big it's a big change we're moving from

1184
00:44:55,680 --> 00:44:58,400
this kind of self-regulatory status quo

1185
00:44:58,400 --> 00:45:00,480
we're with a bunch of you know pressure

1186
00:45:00,480 --> 00:45:02,480
quite a bit of kind of pressure on

1187
00:45:02,480 --> 00:45:03,599
companies

1188
00:45:03,599 --> 00:45:05,920
to to to regulate we're moving to a

1189
00:45:05,920 --> 00:45:07,680
place where we're going to have you know

1190
00:45:07,680 --> 00:45:09,599
a whole bunch of obligations and public

1191
00:45:09,599 --> 00:45:12,160
regulatory oversight but

1192
00:45:12,160 --> 00:45:14,160
what is what is needed of course for

1193
00:45:14,160 --> 00:45:16,000
that to function

1194
00:45:16,000 --> 00:45:18,000
is a whole bunch of people that

1195
00:45:18,000 --> 00:45:20,640
understand how that should function in

1196
00:45:20,640 --> 00:45:23,839
key roles you know so what that needs is

1197
00:45:23,839 --> 00:45:26,319
a whole kind of generation of people

1198
00:45:26,319 --> 00:45:29,119
with the right expertise moving into

1199
00:45:29,119 --> 00:45:31,680
these new types of oversight positions

1200
00:45:31,680 --> 00:45:34,880
in uh oversight regulatory agencies but

1201
00:45:34,880 --> 00:45:37,200
also in other key positions in other

1202
00:45:37,200 --> 00:45:39,040
kind of stakeholders you know and even

1203
00:45:39,040 --> 00:45:40,800
internal internally of course to

1204
00:45:40,800 --> 00:45:43,119
companies and i think that is some that

1205
00:45:43,119 --> 00:45:45,760
is a place where where in in many ways

1206
00:45:45,760 --> 00:45:47,839
the real battle is you know that kind of

1207
00:45:47,839 --> 00:45:49,839
building that building that future

1208
00:45:49,839 --> 00:45:52,240
expertise that is needed to understand

1209
00:45:52,240 --> 00:45:55,040
these issues and getting these people uh

1210
00:45:55,040 --> 00:45:57,760
out so in uh

1211
00:45:57,760 --> 00:46:00,400
that expertise is partly a legal

1212
00:46:00,400 --> 00:46:03,119
expertise you know and the the avalanche

1213
00:46:03,119 --> 00:46:06,880
you know tsunami of uh legislation it

1214
00:46:06,880 --> 00:46:09,599
even means that experts relative experts

1215
00:46:09,599 --> 00:46:12,560
like me are struggling to keep up with

1216
00:46:12,560 --> 00:46:16,319
what is uh eo law in my area what is it

1217
00:46:16,319 --> 00:46:18,400
actually you know like what

1218
00:46:18,400 --> 00:46:20,560
really knowing the latest developing uh

1219
00:46:20,560 --> 00:46:22,800
developments and understanding the nuts

1220
00:46:22,800 --> 00:46:25,040
and bolts of uh protect particular

1221
00:46:25,040 --> 00:46:27,440
legislative files uh when they are uh

1222
00:46:27,440 --> 00:46:31,440
completed but it's uh um it is of course

1223
00:46:31,440 --> 00:46:34,079
uh a much bigger uh challenge you know

1224
00:46:34,079 --> 00:46:36,880
like and i think uh so the in the legal

1225
00:46:36,880 --> 00:46:39,040
domain and getting uh legal and

1226
00:46:39,040 --> 00:46:41,440
political talent you know lined up that

1227
00:46:41,440 --> 00:46:44,000
that understands all these dynamics but

1228
00:46:44,000 --> 00:46:46,160
there's a there's a bigger a much bigger

1229
00:46:46,160 --> 00:46:47,520
uh

1230
00:46:47,520 --> 00:46:50,000
challenge that i think digital rights

1231
00:46:50,000 --> 00:46:51,760
organizations in the digital rights

1232
00:46:51,760 --> 00:46:53,680
fields activism field more generally can

1233
00:46:53,680 --> 00:46:56,720
play a very important role is in in is

1234
00:46:56,720 --> 00:46:58,960
in building that expertise and working

1235
00:46:58,960 --> 00:47:01,200
also in that together with others it's a

1236
00:47:01,200 --> 00:47:02,800
bit of a softer

1237
00:47:02,800 --> 00:47:05,839
it's a softer agenda but ultimately it's

1238
00:47:05,839 --> 00:47:08,319
a very very important uh political

1239
00:47:08,319 --> 00:47:09,920
battle i'm a little bit worried that

1240
00:47:09,920 --> 00:47:12,400
sometimes the battle gets lost there and

1241
00:47:12,400 --> 00:47:14,400
keep like the the the people that are

1242
00:47:14,400 --> 00:47:16,880
really understanding uh things they're

1243
00:47:16,880 --> 00:47:19,920
not uh end up being the dominant uh

1244
00:47:19,920 --> 00:47:22,720
voices in in some of those uh agencies

1245
00:47:22,720 --> 00:47:27,439
so including like in the gdpr space

1246
00:47:27,839 --> 00:47:30,000
good point i guess so next stop uh

1247
00:47:30,000 --> 00:47:32,319
applying for jobs at the dpas um

1248
00:47:32,319 --> 00:47:34,319
alexander you you left us on a

1249
00:47:34,319 --> 00:47:36,559
cliffhanger before do you want to follow

1250
00:47:36,559 --> 00:47:38,160
up on that or do you want to react over

1251
00:47:38,160 --> 00:47:41,118
to any of these speakers

1252
00:47:49,839 --> 00:47:51,839
learning to unmute my microphone after

1253
00:47:51,839 --> 00:47:54,480
two years pandemic um i i don't remember

1254
00:47:54,480 --> 00:47:56,400
what the cliffhanger was but i i

1255
00:47:56,400 --> 00:47:58,960
certainly agree um to what yours just

1256
00:47:58,960 --> 00:48:00,960
said that we will need a lot of

1257
00:48:00,960 --> 00:48:03,520
qualified staff on on technical level

1258
00:48:03,520 --> 00:48:05,599
legal level and so on to to do all this

1259
00:48:05,599 --> 00:48:07,119
oversight and all this monitoring this

1260
00:48:07,119 --> 00:48:08,319
is going to be a very interesting

1261
00:48:08,319 --> 00:48:09,920
challenge and it's something that

1262
00:48:09,920 --> 00:48:12,079
francis hogan mentioned as well facebook

1263
00:48:12,079 --> 00:48:14,720
whistleblower and we're hearing at the

1264
00:48:14,720 --> 00:48:16,720
european uh parliament that there are

1265
00:48:16,720 --> 00:48:19,440
very few people who actually know um

1266
00:48:19,440 --> 00:48:21,359
what kind of data did you do you need to

1267
00:48:21,359 --> 00:48:23,440
ask for if you want to monitor the big

1268
00:48:23,440 --> 00:48:25,680
platforms especially facebook and

1269
00:48:25,680 --> 00:48:28,079
so that that is a very

1270
00:48:28,079 --> 00:48:30,000
very very interesting

1271
00:48:30,000 --> 00:48:32,839
uh very interesting question

1272
00:48:32,839 --> 00:48:35,440
um yeah what what else what was a

1273
00:48:35,440 --> 00:48:36,720
cliffhanger

1274
00:48:36,720 --> 00:48:38,079
i don't

1275
00:48:38,079 --> 00:48:40,000
think i love you precisely you were

1276
00:48:40,000 --> 00:48:41,599
saying that i have much more to say but

1277
00:48:41,599 --> 00:48:43,760
i will leave it uh for later but uh

1278
00:48:43,760 --> 00:48:46,800
perhaps there is nothing for you my food

1279
00:48:46,800 --> 00:48:48,559
and i i caught up with the with the

1280
00:48:48,559 --> 00:48:51,920
second one um

1281
00:48:52,000 --> 00:48:55,200
yeah i think the ai act is going to be a

1282
00:48:55,200 --> 00:48:56,960
really huge challenge

1283
00:48:56,960 --> 00:48:59,200
because there i really

1284
00:48:59,200 --> 00:49:02,400
see that the influence of industry is

1285
00:49:02,400 --> 00:49:04,079
extremely strong

1286
00:49:04,079 --> 00:49:07,599
because it is also so difficult to come

1287
00:49:07,599 --> 00:49:11,599
up with alternative proposals

1288
00:49:11,599 --> 00:49:13,920
for example i was in committee before

1289
00:49:13,920 --> 00:49:16,720
and we had director general of dg

1290
00:49:16,720 --> 00:49:19,359
connect speaking about ai and we could

1291
00:49:19,359 --> 00:49:21,359
ask questions and one of the questions i

1292
00:49:21,359 --> 00:49:23,839
asked was how can you

1293
00:49:23,839 --> 00:49:27,119
involve affected groups of people so the

1294
00:49:27,119 --> 00:49:29,280
people who will be particularly affected

1295
00:49:29,280 --> 00:49:31,520
by artificial intelligence are not the

1296
00:49:31,520 --> 00:49:34,160
ones that are developing ai tools right

1297
00:49:34,160 --> 00:49:35,920
now because it's women it's people of

1298
00:49:35,920 --> 00:49:38,160
color it's poor people people with

1299
00:49:38,160 --> 00:49:40,319
disabilities and so on and they're

1300
00:49:40,319 --> 00:49:42,640
extremely unlikely to be involved in the

1301
00:49:42,640 --> 00:49:44,880
development of those tools and also in

1302
00:49:44,880 --> 00:49:47,040
the regulation of those tools but they

1303
00:49:47,040 --> 00:49:48,480
will be most impacted and most

1304
00:49:48,480 --> 00:49:50,960
negatively impacted and how can we

1305
00:49:50,960 --> 00:49:52,800
involve them in the first place and he

1306
00:49:52,800 --> 00:49:54,319
he just ignored the question i have to

1307
00:49:54,319 --> 00:49:55,760
say you know we have these form it's

1308
00:49:55,760 --> 00:49:57,119
like two minutes two minutes and then

1309
00:49:57,119 --> 00:49:58,800
you ask three two three questions so

1310
00:49:58,800 --> 00:50:00,079
they pick the question they want to

1311
00:50:00,079 --> 00:50:01,359
answer

1312
00:50:01,359 --> 00:50:04,079
but i think nobody has a really precise

1313
00:50:04,079 --> 00:50:07,040
solution how that that could work

1314
00:50:07,040 --> 00:50:09,280
um you know there's no ready-made

1315
00:50:09,280 --> 00:50:10,880
solution we said okay you put that

1316
00:50:10,880 --> 00:50:12,880
amendment into the regulation and it's

1317
00:50:12,880 --> 00:50:14,640
done you have to sort of think out of

1318
00:50:14,640 --> 00:50:16,880
the box and and develop solutions and i

1319
00:50:16,880 --> 00:50:18,160
think that would be an interesting

1320
00:50:18,160 --> 00:50:19,680
challenge as well

1321
00:50:19,680 --> 00:50:23,040
for ngos to sort of come up together to

1322
00:50:23,040 --> 00:50:24,960
start this discussion how could we

1323
00:50:24,960 --> 00:50:27,680
operationalize fundamental rights and

1324
00:50:27,680 --> 00:50:29,280
inclusion of everybody in the

1325
00:50:29,280 --> 00:50:31,280
conversation how what does it exactly

1326
00:50:31,280 --> 00:50:32,559
mean you know we are speaking a lot

1327
00:50:32,559 --> 00:50:34,559
about redress and consumer organizations

1328
00:50:34,559 --> 00:50:36,240
have the possibility

1329
00:50:36,240 --> 00:50:38,800
um to have redress but i think that's

1330
00:50:38,800 --> 00:50:40,240
not enough i think we really have to

1331
00:50:40,240 --> 00:50:42,079
come up with solution because that's

1332
00:50:42,079 --> 00:50:43,839
something the commission can't do this

1333
00:50:43,839 --> 00:50:45,040
is something that has to be done

1334
00:50:45,040 --> 00:50:46,720
grassroots and by all of us

1335
00:50:46,720 --> 00:50:48,240
brainstorming together and coming

1336
00:50:48,240 --> 00:50:49,920
together and coming up with something

1337
00:50:49,920 --> 00:50:51,839
that we then all defend i think there is

1338
00:50:51,839 --> 00:50:53,280
a chance to get things into the

1339
00:50:53,280 --> 00:50:55,280
regulation but we need to operationalize

1340
00:50:55,280 --> 00:50:56,640
it and not just stay at the level saying

1341
00:50:56,640 --> 00:50:58,880
well we want fundamental rights and even

1342
00:50:58,880 --> 00:51:00,400
the human rights assessment is it's a

1343
00:51:00,400 --> 00:51:02,240
great thing but then you come then you

1344
00:51:02,240 --> 00:51:03,839
have the problem you know which

1345
00:51:03,839 --> 00:51:05,200
fundamental rights and where's the

1346
00:51:05,200 --> 00:51:06,640
balance it's too abstract i think we

1347
00:51:06,640 --> 00:51:10,000
need some very precise concrete ideas to

1348
00:51:10,000 --> 00:51:11,680
put into that regulation and that might

1349
00:51:11,680 --> 00:51:13,599
be something we we could you could do as

1350
00:51:13,599 --> 00:51:16,240
ngos and then come to us as politicians

1351
00:51:16,240 --> 00:51:18,240
discuss it and see how we can

1352
00:51:18,240 --> 00:51:19,920
operationalize it and

1353
00:51:19,920 --> 00:51:23,440
pour it into into amendments

1354
00:51:23,440 --> 00:51:25,760
thank you alexander i very good comments

1355
00:51:25,760 --> 00:51:28,240
we have only uh five minutes left i'd

1356
00:51:28,240 --> 00:51:29,680
like to follow up on each of the human

1357
00:51:29,680 --> 00:51:32,160
rights impact assessment because i also

1358
00:51:32,160 --> 00:51:34,240
struggle to imagine how they will look

1359
00:51:34,240 --> 00:51:35,920
in practice and how will they protect

1360
00:51:35,920 --> 00:51:38,000
people in practice but i yours you have

1361
00:51:38,000 --> 00:51:40,640
the your hand raised so please go ahead

1362
00:51:40,640 --> 00:51:41,440
and

1363
00:51:41,440 --> 00:51:44,480
and after your intervention i'd like to

1364
00:51:44,480 --> 00:51:48,480
take 30 seconds each uh to try to to to

1365
00:51:48,480 --> 00:51:50,559
have a break we we we're talking about

1366
00:51:50,559 --> 00:51:52,960
uh what happened so far what's coming up

1367
00:51:52,960 --> 00:51:55,440
in the media term what ngos should do

1368
00:51:55,440 --> 00:51:57,800
um but i'd like to to think in the

1369
00:51:57,800 --> 00:51:59,880
2024 uh

1370
00:51:59,880 --> 00:52:03,520
2029 uh legislative term and and what

1371
00:52:03,520 --> 00:52:05,839
what to expect from that and we were

1372
00:52:05,839 --> 00:52:07,359
saying that perhaps we should focus on

1373
00:52:07,359 --> 00:52:09,680
implementation go to campaigning go to

1374
00:52:09,680 --> 00:52:12,160
the national member state but uh whether

1375
00:52:12,160 --> 00:52:15,279
we like to not

1376
00:52:15,480 --> 00:52:18,079
understand a new parliament so we will

1377
00:52:18,079 --> 00:52:19,839
need to say if we propose something or

1378
00:52:19,839 --> 00:52:22,000
what we propose is

1379
00:52:22,000 --> 00:52:24,720
pushing institutions to enforce the

1380
00:52:24,720 --> 00:52:26,720
existing legislation but yours please go

1381
00:52:26,720 --> 00:52:28,400
ahead and then we go to the general

1382
00:52:28,400 --> 00:52:31,680
question for hopes and prospects

1383
00:52:31,680 --> 00:52:33,520
yeah i just i wanted to say there's

1384
00:52:33,520 --> 00:52:35,440
something about the ai hack that i think

1385
00:52:35,440 --> 00:52:38,240
is quite uh

1386
00:52:38,240 --> 00:52:40,480
characterizes it a bit in a way the

1387
00:52:40,480 --> 00:52:42,960
dynamics which is i think this is a this

1388
00:52:42,960 --> 00:52:43,839
is

1389
00:52:43,839 --> 00:52:45,839
an act that has been put on the table

1390
00:52:45,839 --> 00:52:48,240
mostly because it's been a big industry

1391
00:52:48,240 --> 00:52:51,040
push to frame the conversation about you

1392
00:52:51,040 --> 00:52:53,280
know certain kind of algorithmic systems

1393
00:52:53,280 --> 00:52:55,359
in that kind of way and the main goal

1394
00:52:55,359 --> 00:52:57,359
for industry is to create predictable

1395
00:52:57,359 --> 00:52:59,440
markets you know in europe and mostly

1396
00:52:59,440 --> 00:53:00,640
also like

1397
00:53:00,640 --> 00:53:03,680
one market for for for ai you know like

1398
00:53:03,680 --> 00:53:05,200
many many different things

1399
00:53:05,200 --> 00:53:07,920
so there's many years that go before

1400
00:53:07,920 --> 00:53:10,000
that and a whole kind of campaign and

1401
00:53:10,000 --> 00:53:11,599
framing the conversation and then at

1402
00:53:11,599 --> 00:53:13,119
some point that lands in the european

1403
00:53:13,119 --> 00:53:14,720
commission comes with a proposal you

1404
00:53:14,720 --> 00:53:16,400
know after the whole expert group kind

1405
00:53:16,400 --> 00:53:19,040
of thing and so that whole process

1406
00:53:19,040 --> 00:53:21,839
before has been quite dominated by a

1407
00:53:21,839 --> 00:53:23,839
particular framing coming of the

1408
00:53:23,839 --> 00:53:26,000
conversation coming from industry so

1409
00:53:26,000 --> 00:53:28,559
looking to the next period i think you

1410
00:53:28,559 --> 00:53:31,359
know every can maybe come together and

1411
00:53:31,359 --> 00:53:33,520
you know put your heads together what is

1412
00:53:33,520 --> 00:53:35,200
one of those types of things that you

1413
00:53:35,200 --> 00:53:37,839
want to do where you like really frame

1414
00:53:37,839 --> 00:53:39,760
the conversation slowly and move you

1415
00:53:39,760 --> 00:53:42,079
know towards that type of target i mean

1416
00:53:42,079 --> 00:53:44,000
there are some really important

1417
00:53:44,000 --> 00:53:45,760
conversations happening now and you're

1418
00:53:45,760 --> 00:53:48,160
doing a really great job on but yeah i

1419
00:53:48,160 --> 00:53:50,720
think there there is an opportunity uh

1420
00:53:50,720 --> 00:53:53,280
there i think to to to have a longer

1421
00:53:53,280 --> 00:53:55,359
term kind of investment in building a

1422
00:53:55,359 --> 00:53:57,200
file and working also then with the

1423
00:53:57,200 --> 00:53:59,119
institutions that can you know that can

1424
00:53:59,119 --> 00:54:00,400
help to maybe

1425
00:54:00,400 --> 00:54:04,480
materialize that that agenda

1426
00:54:04,800 --> 00:54:06,640
thank you

1427
00:54:06,640 --> 00:54:10,079
anna i see you already ready to react

1428
00:54:10,079 --> 00:54:12,800
i think institution influencing is a

1429
00:54:12,800 --> 00:54:17,040
really important future activity

1430
00:54:17,040 --> 00:54:19,280
and there's also you know a really good

1431
00:54:19,280 --> 00:54:22,559
expression for ngos called watch dogs

1432
00:54:22,559 --> 00:54:24,640
you know we have to be

1433
00:54:24,640 --> 00:54:29,119
more watchdog orientated than um

1434
00:54:29,119 --> 00:54:32,079
maybe not so much new legislation

1435
00:54:32,079 --> 00:54:33,440
influencing

1436
00:54:33,440 --> 00:54:35,119
but but actually

1437
00:54:35,119 --> 00:54:39,200
to lend the expertise be watch dogs and

1438
00:54:39,200 --> 00:54:40,720
also

1439
00:54:40,720 --> 00:54:43,839
research and finding the evidence is

1440
00:54:43,839 --> 00:54:46,400
very very important also in

1441
00:54:46,400 --> 00:54:47,760
in

1442
00:54:47,760 --> 00:54:48,559
in

1443
00:54:48,559 --> 00:54:51,440
enforcement and finally don't forget we

1444
00:54:51,440 --> 00:54:53,839
are talking about global issues and

1445
00:54:53,839 --> 00:54:56,640
global companies and europe is not a

1446
00:54:56,640 --> 00:54:57,920
fortress

1447
00:54:57,920 --> 00:54:58,720
so

1448
00:54:58,720 --> 00:55:01,200
we also need to know how to engage

1449
00:55:01,200 --> 00:55:03,920
beyond european borders because you know

1450
00:55:03,920 --> 00:55:06,880
like with covid until we get the whole

1451
00:55:06,880 --> 00:55:09,599
world on the same page it's not going to

1452
00:55:09,599 --> 00:55:12,960
resolve our problems

1453
00:55:13,599 --> 00:55:15,839
wise words anna thank you asha final

1454
00:55:15,839 --> 00:55:17,599
comments before we go to the closing

1455
00:55:17,599 --> 00:55:18,799
ceremony

1456
00:55:18,799 --> 00:55:20,640
i will try and be as quick as i can but

1457
00:55:20,640 --> 00:55:22,640
i think like an alexandra's case you

1458
00:55:22,640 --> 00:55:24,160
often get a short amount of time to try

1459
00:55:24,160 --> 00:55:26,720
and get a lot of concepts across uh but

1460
00:55:26,720 --> 00:55:29,119
i would um plus one on the uh on the

1461
00:55:29,119 --> 00:55:31,040
ideas of kind of cross-dissemination of

1462
00:55:31,040 --> 00:55:33,359
expertise when it comes to civil society

1463
00:55:33,359 --> 00:55:34,720
i think there's actually opportunities

1464
00:55:34,720 --> 00:55:36,720
for us to do the development of

1465
00:55:36,720 --> 00:55:38,640
legislation and operationalization

1466
00:55:38,640 --> 00:55:40,280
processes in a much more

1467
00:55:40,280 --> 00:55:42,799
inter-institutional way i think in part

1468
00:55:42,799 --> 00:55:44,240
of these conversations we've talked

1469
00:55:44,240 --> 00:55:45,920
about the kind of democratic processes

1470
00:55:45,920 --> 00:55:47,599
and how civil society can have a real

1471
00:55:47,599 --> 00:55:49,440
impact and i know claire mentioned in

1472
00:55:49,440 --> 00:55:51,599
the in the comments there about making

1473
00:55:51,599 --> 00:55:53,280
sure civil society remains part of the

1474
00:55:53,280 --> 00:55:54,880
triads process which is the biggest

1475
00:55:54,880 --> 00:55:56,720
question i think for civil society right

1476
00:55:56,720 --> 00:55:58,559
now how do we maintain our impact in

1477
00:55:58,559 --> 00:56:00,799
there and protect what we uh we've been

1478
00:56:00,799 --> 00:56:02,799
able to win um in the european

1479
00:56:02,799 --> 00:56:05,040
parliament so really fundamentally

1480
00:56:05,040 --> 00:56:07,680
changing as we look to the future how do

1481
00:56:07,680 --> 00:56:09,920
we have an actual real multi-stakeholder

1482
00:56:09,920 --> 00:56:11,760
approach that is based on the european

1483
00:56:11,760 --> 00:56:13,839
values of democratic participation

1484
00:56:13,839 --> 00:56:16,079
rather than consultation after the fact

1485
00:56:16,079 --> 00:56:18,319
or having a few people who can champion

1486
00:56:18,319 --> 00:56:20,240
us being in those spaces but it's not

1487
00:56:20,240 --> 00:56:23,200
coherent um and then to think forward to

1488
00:56:23,200 --> 00:56:25,119
2024

1489
00:56:25,119 --> 00:56:26,960
it's a long time in political terms but

1490
00:56:26,960 --> 00:56:28,400
we have to think because what we're

1491
00:56:28,400 --> 00:56:30,400
talking about is generational defining

1492
00:56:30,400 --> 00:56:32,000
legislation it's going to go beyond the

1493
00:56:32,000 --> 00:56:33,599
next five years we need to think in

1494
00:56:33,599 --> 00:56:36,559
those terms so continuity i think is a

1495
00:56:36,559 --> 00:56:39,599
main message and i would pick up on and

1496
00:56:39,599 --> 00:56:41,359
definitely the focus on effective

1497
00:56:41,359 --> 00:56:43,599
implementation what we don't want with

1498
00:56:43,599 --> 00:56:46,000
things that we have like the dsa is to

1499
00:56:46,000 --> 00:56:47,280
have the same conversation that we've

1500
00:56:47,280 --> 00:56:49,119
been having on say the racial equality

1501
00:56:49,119 --> 00:56:51,119
directive 20 years later where we then

1502
00:56:51,119 --> 00:56:52,960
say it wasn't effective we now need to

1503
00:56:52,960 --> 00:56:54,319
think of something else to make this

1504
00:56:54,319 --> 00:56:55,680
work so

1505
00:56:55,680 --> 00:56:58,319
effective enforcement continuity and

1506
00:56:58,319 --> 00:56:59,760
real inter-institutional and

1507
00:56:59,760 --> 00:57:01,680
multi-stakeholder approach to how we do

1508
00:57:01,680 --> 00:57:03,919
this

1509
00:57:04,319 --> 00:57:07,359
fantastic summary asha plus one to that

1510
00:57:07,359 --> 00:57:09,440
alexander very quick word we already

1511
00:57:09,440 --> 00:57:09,990
over time

1512
00:57:09,990 --> 00:57:11,839
[Music]

1513
00:57:11,839 --> 00:57:13,119
yeah yeah

1514
00:57:13,119 --> 00:57:14,400
but yes

1515
00:57:14,400 --> 00:57:16,720
i'll be very quick um i think on trilox

1516
00:57:16,720 --> 00:57:18,400
where the question was how to influence

1517
00:57:18,400 --> 00:57:20,640
trilog um influence national governments

1518
00:57:20,640 --> 00:57:22,400
i mean the only ones who have really an

1519
00:57:22,400 --> 00:57:24,799
influence on trilogs now uh on the pound

1520
00:57:24,799 --> 00:57:26,240
that can change that the council

1521
00:57:26,240 --> 00:57:28,160
position on national governments so

1522
00:57:28,160 --> 00:57:30,079
where you see there might be a change in

1523
00:57:30,079 --> 00:57:31,440
national governance because there's new

1524
00:57:31,440 --> 00:57:33,440
evidence because there's a new political

1525
00:57:33,440 --> 00:57:35,119
constellation or something you have

1526
00:57:35,119 --> 00:57:36,799
parties in that governments you can talk

1527
00:57:36,799 --> 00:57:39,200
to that's what we need to do and maybe

1528
00:57:39,200 --> 00:57:40,960
coordinate a little bit with us because

1529
00:57:40,960 --> 00:57:42,960
obviously we have an idea as well which

1530
00:57:42,960 --> 00:57:44,160
governments are moving in the right

1531
00:57:44,160 --> 00:57:45,599
direction if you have any sources of

1532
00:57:45,599 --> 00:57:47,599
counsel extremely helpful

1533
00:57:47,599 --> 00:57:50,240
um use your member organization in the

1534
00:57:50,240 --> 00:57:52,559
member states to do that i think that's

1535
00:57:52,559 --> 00:57:54,480
that is what really helps um let's

1536
00:57:54,480 --> 00:57:56,880
coordinate on on the main goals um i

1537
00:57:56,880 --> 00:58:00,160
think that's helpful on 24 to 29 um i

1538
00:58:00,160 --> 00:58:02,559
have no idea you know digital world is

1539
00:58:02,559 --> 00:58:04,160
moving so fast

1540
00:58:04,160 --> 00:58:06,160
i i one

1541
00:58:06,160 --> 00:58:08,480
one thing i would suspect the research

1542
00:58:08,480 --> 00:58:11,280
um coming out of the dsa you know the

1543
00:58:11,280 --> 00:58:13,680
access to the data article 31 the work

1544
00:58:13,680 --> 00:58:16,079
us ngos will be doing the work we us

1545
00:58:16,079 --> 00:58:18,319
researchers will be doing that will give

1546
00:58:18,319 --> 00:58:21,359
us new stories but also new evidence

1547
00:58:21,359 --> 00:58:23,839
in order to find out which way to go and

1548
00:58:23,839 --> 00:58:25,440
there might be some follow-up on

1549
00:58:25,440 --> 00:58:28,319
legislation to to the dsa sectoral

1550
00:58:28,319 --> 00:58:31,200
legislation um related to the dsa and

1551
00:58:31,200 --> 00:58:34,240
somehow that's something i would see

1552
00:58:34,240 --> 00:58:35,440
thank you

1553
00:58:35,440 --> 00:58:36,960
thank you thank you

1554
00:58:36,960 --> 00:58:39,440
very fantastic last words i i now we

1555
00:58:39,440 --> 00:58:41,280
need to finish we have three minutes

1556
00:58:41,280 --> 00:58:42,400
after

1557
00:58:42,400 --> 00:58:44,559
uh our time i need to go to the closing

1558
00:58:44,559 --> 00:58:47,599
ceremony which is in the alice room so i

1559
00:58:47,599 --> 00:58:50,160
just want to finalize i think this panic

1560
00:58:50,160 --> 00:58:51,760
would have lasted for another hour at

1561
00:58:51,760 --> 00:58:52,559
least

1562
00:58:52,559 --> 00:58:54,000
and so thank you so much thank you

1563
00:58:54,000 --> 00:58:56,240
alexandra anna asha and yours for being

1564
00:58:56,240 --> 00:58:57,920
with us fantastic panels i'm looking

1565
00:58:57,920 --> 00:58:59,920
forward to actually watch it again and

1566
00:58:59,920 --> 00:59:01,440
take even more notes so thank you so

1567
00:59:01,440 --> 00:59:07,799
much and see you soon thank you goodbye

