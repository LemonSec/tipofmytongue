1
00:00:02,000 --> 00:00:03,600
hi everyone

2
00:00:03,600 --> 00:00:05,520
welcome to the machine learning security

3
00:00:05,520 --> 00:00:08,480
invasion competition 2020.

4
00:00:08,480 --> 00:00:10,639
my name is zoetambaraj and i'm the head

5
00:00:10,639 --> 00:00:13,759
of vulnerability research lab at cujo ai

6
00:00:13,759 --> 00:00:15,920
i had some offensive research in the

7
00:00:15,920 --> 00:00:17,920
past for example you might have heard

8
00:00:17,920 --> 00:00:20,240
about the zombie browser toolkit

9
00:00:20,240 --> 00:00:22,960
the hardware firewall bypass tool the

10
00:00:22,960 --> 00:00:24,080
mother analysis

11
00:00:24,080 --> 00:00:27,039
sandbox tester tool or you might have

12
00:00:27,039 --> 00:00:27,519
heard

13
00:00:27,519 --> 00:00:29,840
that i played with some crappy iot

14
00:00:29,840 --> 00:00:30,960
devices

15
00:00:30,960 --> 00:00:33,920
where i invented the idea of encrypted

16
00:00:33,920 --> 00:00:36,160
exploit delivery via diffie-hellman key

17
00:00:36,160 --> 00:00:37,520
exchanges

18
00:00:37,520 --> 00:00:39,920
besides these offensive researches i am

19
00:00:39,920 --> 00:00:41,120
the co-organizer

20
00:00:41,120 --> 00:00:44,239
of the accessory meetup here in hungary

21
00:00:44,239 --> 00:00:46,079
and i'm the program committee member of

22
00:00:46,079 --> 00:00:48,960
the activity conference

23
00:00:48,960 --> 00:00:51,360
this is a joint research together with

24
00:00:51,360 --> 00:00:53,120
dr hiram anderson

25
00:00:53,120 --> 00:00:55,039
he's an architect at the azure

26
00:00:55,039 --> 00:00:57,199
trustworthy machine learning at

27
00:00:57,199 --> 00:01:00,239
microsoft and he is the co-founder and

28
00:01:00,239 --> 00:01:00,960
co-chair

29
00:01:00,960 --> 00:01:04,159
at canvas organization his background is

30
00:01:04,159 --> 00:01:06,080
from signal processing and machine

31
00:01:06,080 --> 00:01:06,640
learning

32
00:01:06,640 --> 00:01:08,560
but he's also very good when it comes to

33
00:01:08,560 --> 00:01:10,560
information security

34
00:01:10,560 --> 00:01:13,680
his main relevant research is that

35
00:01:13,680 --> 00:01:16,720
he created some code regarding

36
00:01:16,720 --> 00:01:18,159
reinforcement

37
00:01:18,159 --> 00:01:21,200
learning with av evasion and he's also

38
00:01:21,200 --> 00:01:23,119
the co-creator of the amber

39
00:01:23,119 --> 00:01:26,960
data sets machine learning

40
00:01:26,960 --> 00:01:29,680
is used in an awful lot of different

41
00:01:29,680 --> 00:01:30,320
ways

42
00:01:30,320 --> 00:01:34,320
in our life for example researchers can

43
00:01:34,320 --> 00:01:38,159
use machine learning to classify objects

44
00:01:38,159 --> 00:01:41,200
and for example when the machine

45
00:01:41,200 --> 00:01:42,399
learning model

46
00:01:42,399 --> 00:01:45,119
looks at the photo it can decide whether

47
00:01:45,119 --> 00:01:46,399
there's a boss or an

48
00:01:46,399 --> 00:01:49,520
animal on this object there was some

49
00:01:49,520 --> 00:01:51,280
interesting research

50
00:01:51,280 --> 00:01:54,560
done in the past by to trick these

51
00:01:54,560 --> 00:01:55,920
machine learning

52
00:01:55,920 --> 00:01:59,360
classifiers on the left side

53
00:01:59,360 --> 00:02:02,880
you can see a normal boss and on the

54
00:02:02,880 --> 00:02:03,759
right side

55
00:02:03,759 --> 00:02:06,000
for the human eye you can see the same

56
00:02:06,000 --> 00:02:09,840
bus but because there was an added layer

57
00:02:09,840 --> 00:02:13,319
to this photo if you try to

58
00:02:13,319 --> 00:02:16,319
reclassify the photo on the right it

59
00:02:16,319 --> 00:02:17,440
will classify this

60
00:02:17,440 --> 00:02:20,720
as an ostrich but we are in

61
00:02:20,720 --> 00:02:23,520
information security right now so we are

62
00:02:23,520 --> 00:02:25,840
interested in malicious software

63
00:02:25,840 --> 00:02:29,440
detection there were multiple

64
00:02:29,440 --> 00:02:32,160
research in the past how you can bypass

65
00:02:32,160 --> 00:02:34,000
machine learning based

66
00:02:34,000 --> 00:02:37,680
mother detection for example last year

67
00:02:37,680 --> 00:02:40,640
some researchers found that if you

68
00:02:40,640 --> 00:02:42,400
extract strings

69
00:02:42,400 --> 00:02:45,920
from a game file and just dumbly

70
00:02:45,920 --> 00:02:48,640
append these strings to a known

71
00:02:48,640 --> 00:02:50,400
malicious executable

72
00:02:50,400 --> 00:02:54,160
you can bypass the machine learning

73
00:02:54,160 --> 00:02:57,280
detection i also did

74
00:02:57,280 --> 00:03:00,239
some research in the past and four years

75
00:03:00,239 --> 00:03:01,360
ago

76
00:03:01,360 --> 00:03:05,040
you could even bypass some

77
00:03:05,040 --> 00:03:07,920
machine learning models just by packing

78
00:03:07,920 --> 00:03:08,720
the file

79
00:03:08,720 --> 00:03:12,080
with a known packer like upx

80
00:03:12,080 --> 00:03:15,280
luckily this has changed

81
00:03:15,280 --> 00:03:18,159
recently so you cannot use this trick

82
00:03:18,159 --> 00:03:20,720
anymore

83
00:03:21,280 --> 00:03:25,120
me and hyrum thought that there's a nice

84
00:03:25,120 --> 00:03:26,319
potential here

85
00:03:26,319 --> 00:03:29,360
to create a competition

86
00:03:29,360 --> 00:03:32,680
so we created the website

87
00:03:32,680 --> 00:03:34,720
evademoverml.io

88
00:03:34,720 --> 00:03:37,200
and what you have to do is basically

89
00:03:37,200 --> 00:03:37,760
download

90
00:03:37,760 --> 00:03:40,879
50 working mother samples and

91
00:03:40,879 --> 00:03:43,360
download free machine learning models

92
00:03:43,360 --> 00:03:44,640
with its weights

93
00:03:44,640 --> 00:03:47,920
modify the mother samples to evade

94
00:03:47,920 --> 00:03:49,760
the detection by these machine learning

95
00:03:49,760 --> 00:03:52,480
models submit those to our website

96
00:03:52,480 --> 00:03:55,360
and if you achieve the highest scores

97
00:03:55,360 --> 00:03:56,239
you could win

98
00:03:56,239 --> 00:04:01,519
this nice nvidia gpu

99
00:04:01,519 --> 00:04:03,439
the outcome of this competition was

100
00:04:03,439 --> 00:04:05,120
pretty interesting

101
00:04:05,120 --> 00:04:07,439
around 70 people registered for the

102
00:04:07,439 --> 00:04:08,319
competition

103
00:04:08,319 --> 00:04:11,439
and at least 11 were able to bypass at

104
00:04:11,439 --> 00:04:11,920
least

105
00:04:11,920 --> 00:04:15,439
one machine learning model at the end of

106
00:04:15,439 --> 00:04:16,079
august

107
00:04:16,079 --> 00:04:19,918
william flashman submitted his

108
00:04:19,918 --> 00:04:23,360
latest samples and scored the

109
00:04:23,360 --> 00:04:25,919
maximum score you can have in the

110
00:04:25,919 --> 00:04:27,280
competition

111
00:04:27,280 --> 00:04:29,680
i highly recommend everyone to go and

112
00:04:29,680 --> 00:04:30,720
check out

113
00:04:30,720 --> 00:04:34,000
his excellent blog post about how he was

114
00:04:34,000 --> 00:04:35,759
able to do this

115
00:04:35,759 --> 00:04:38,400
you can also find other interesting

116
00:04:38,400 --> 00:04:40,160
write-ups

117
00:04:40,160 --> 00:04:42,720
for example you can check out jacob

118
00:04:42,720 --> 00:04:44,479
devski's or fabregio

119
00:04:44,479 --> 00:04:47,919
chess cleans research

120
00:04:47,919 --> 00:04:51,759
and how they were able to bypass

121
00:04:51,759 --> 00:04:55,360
the machine learning models

122
00:04:55,440 --> 00:04:58,120
for example it might be

123
00:04:58,120 --> 00:04:59,680
[Music]

124
00:04:59,680 --> 00:05:02,080
interesting to see whether you can

125
00:05:02,080 --> 00:05:03,120
bypass

126
00:05:03,120 --> 00:05:06,479
detection by using a packer packers were

127
00:05:06,479 --> 00:05:08,080
mostly used in the past

128
00:05:08,080 --> 00:05:11,680
to bypass av-based av signature

129
00:05:11,680 --> 00:05:13,360
detection

130
00:05:13,360 --> 00:05:16,080
but turned out that because in this

131
00:05:16,080 --> 00:05:18,960
competition we are using binaries

132
00:05:18,960 --> 00:05:22,000
and some of these samples are already

133
00:05:22,000 --> 00:05:25,600
packed adding another layer of packer

134
00:05:25,600 --> 00:05:27,840
on top of it might break the

135
00:05:27,840 --> 00:05:32,239
functionality of the sample itself

136
00:05:33,039 --> 00:05:36,160
another interesting solution was to

137
00:05:36,160 --> 00:05:40,560
add new sections to the pe executable

138
00:05:40,560 --> 00:05:42,960
and for example you can extract

139
00:05:42,960 --> 00:05:43,840
resources

140
00:05:43,840 --> 00:05:47,280
from known files like microsoft files

141
00:05:47,280 --> 00:05:50,720
and add these resources

142
00:05:50,720 --> 00:05:54,800
to the malicious sample turned out

143
00:05:54,800 --> 00:05:57,039
again this can be very effective to

144
00:05:57,039 --> 00:05:59,680
evade the models in our competition

145
00:05:59,680 --> 00:06:03,919
but unfortunately it broke some mother

146
00:06:03,919 --> 00:06:07,680
because some other samples had

147
00:06:07,680 --> 00:06:10,880
packers or self checks and

148
00:06:10,880 --> 00:06:13,199
just by adding a new section to the

149
00:06:13,199 --> 00:06:14,160
sample

150
00:06:14,160 --> 00:06:17,680
broke the functionality

151
00:06:17,680 --> 00:06:20,880
fun fact just by adding

152
00:06:20,880 --> 00:06:25,280
a simple empty section

153
00:06:25,280 --> 00:06:28,960
to a sample

154
00:06:28,960 --> 00:06:32,840
you can even bypass some antivirus

155
00:06:32,840 --> 00:06:34,000
engines

156
00:06:34,000 --> 00:06:36,960
i believe this is because of performance

157
00:06:36,960 --> 00:06:37,919
reasons

158
00:06:37,919 --> 00:06:40,960
because the ev engine can quickly

159
00:06:40,960 --> 00:06:43,280
check how many sections are in the

160
00:06:43,280 --> 00:06:44,240
marvel

161
00:06:44,240 --> 00:06:47,280
and only use

162
00:06:47,280 --> 00:06:50,319
those signatures on the sample which

163
00:06:50,319 --> 00:06:53,919
check the section size so this can be

164
00:06:53,919 --> 00:06:58,960
a nice trick for your heavy evasion

165
00:06:59,199 --> 00:07:03,199
last but not least the winning strategy

166
00:07:03,199 --> 00:07:06,479
was to append some extra data to the

167
00:07:06,479 --> 00:07:08,160
executable

168
00:07:08,160 --> 00:07:10,240
with this technique is also called an

169
00:07:10,240 --> 00:07:11,840
overlay

170
00:07:11,840 --> 00:07:14,960
and even though this is very dumb and

171
00:07:14,960 --> 00:07:17,039
plain turned out this was the winning

172
00:07:17,039 --> 00:07:20,160
strategy after all

173
00:07:20,160 --> 00:07:23,599
and williams

174
00:07:23,599 --> 00:07:27,039
solution was to brute force the ml

175
00:07:27,039 --> 00:07:29,680
models and found the pattern which

176
00:07:29,680 --> 00:07:31,440
evades

177
00:07:31,440 --> 00:07:34,880
all machine learning models

178
00:07:34,880 --> 00:07:38,639
and again fun fact by significantly

179
00:07:38,639 --> 00:07:39,440
changing

180
00:07:39,440 --> 00:07:43,120
the size of a sample for example just by

181
00:07:43,120 --> 00:07:46,720
adding a lot of overlay to it

182
00:07:46,720 --> 00:07:49,120
you might be able to bypass some av

183
00:07:49,120 --> 00:07:49,919
engines

184
00:07:49,919 --> 00:07:52,639
again i believe this is because of

185
00:07:52,639 --> 00:07:53,599
performance

186
00:07:53,599 --> 00:07:57,120
reasons for example

187
00:07:57,120 --> 00:08:00,240
here you can see one mother sample we

188
00:08:00,240 --> 00:08:02,319
are using in the competition

189
00:08:02,319 --> 00:08:06,080
and if you are adding some overlaid text

190
00:08:06,080 --> 00:08:09,759
to the end of the sample you can see

191
00:08:09,759 --> 00:08:12,800
how the visual representation of the

192
00:08:12,800 --> 00:08:13,440
file

193
00:08:13,440 --> 00:08:17,199
changes some key takeaways

194
00:08:17,199 --> 00:08:20,319
from last year's competition turned out

195
00:08:20,319 --> 00:08:24,960
that the markov and non-neck mark of

196
00:08:24,960 --> 00:08:27,120
machine learning models are a bit too

197
00:08:27,120 --> 00:08:29,360
academic and they are not very effective

198
00:08:29,360 --> 00:08:30,319
when it comes to

199
00:08:30,319 --> 00:08:33,919
practical mother detection

200
00:08:33,919 --> 00:08:36,799
the life project which you can use to

201
00:08:36,799 --> 00:08:38,880
modify

202
00:08:38,880 --> 00:08:43,200
binaries is awesome and

203
00:08:43,200 --> 00:08:46,399
it's not that shocking but dealing with

204
00:08:46,399 --> 00:08:48,080
malware is tricky

205
00:08:48,080 --> 00:08:51,600
because the iocs they can produce

206
00:08:51,600 --> 00:08:55,120
can change over time which

207
00:08:55,120 --> 00:08:58,959
makes it hard for us to detect whether

208
00:08:58,959 --> 00:09:02,959
this is the same sample or not

209
00:09:02,959 --> 00:09:06,080
and there was also this epic challenge

210
00:09:06,080 --> 00:09:08,800
that some pack and protected samples are

211
00:09:08,800 --> 00:09:09,200
hard

212
00:09:09,200 --> 00:09:13,440
to deal with i also checked uh

213
00:09:13,440 --> 00:09:16,720
some of these samples with the ssd

214
00:09:16,720 --> 00:09:19,680
patch and turned out that those samples

215
00:09:19,680 --> 00:09:20,399
which had

216
00:09:20,399 --> 00:09:24,000
either these repeating

217
00:09:24,000 --> 00:09:27,120
sections or some repeating

218
00:09:27,120 --> 00:09:30,560
overlaid data they create

219
00:09:30,560 --> 00:09:33,200
repeating patterns in the ssd patch

220
00:09:33,200 --> 00:09:34,839
itself

221
00:09:34,839 --> 00:09:37,760
and uh one interesting fact is that

222
00:09:37,760 --> 00:09:41,360
uh from now on you can basically check

223
00:09:41,360 --> 00:09:45,040
the ssd hash of a sample and if you see

224
00:09:45,040 --> 00:09:48,839
repeating patterns in it it might

225
00:09:48,839 --> 00:09:52,480
be suspicious because uh

226
00:09:52,480 --> 00:09:56,800
in an average benign

227
00:09:56,800 --> 00:09:59,200
binary sample there are no repeating

228
00:09:59,200 --> 00:10:00,640
patterns there is

229
00:10:00,640 --> 00:10:03,920
no reason to do this so this could be

230
00:10:03,920 --> 00:10:04,560
some way

231
00:10:04,560 --> 00:10:07,519
suspicious that for example someone

232
00:10:07,519 --> 00:10:10,000
tries to evade a machine learning model

233
00:10:10,000 --> 00:10:14,240
with this technique this year

234
00:10:14,240 --> 00:10:17,680
we created a new defender challenge on

235
00:10:17,680 --> 00:10:20,160
the top of the attacker challenge

236
00:10:20,160 --> 00:10:22,240
where you had to create your own machine

237
00:10:22,240 --> 00:10:24,240
learning model and submit it to the

238
00:10:24,240 --> 00:10:25,839
competition

239
00:10:25,839 --> 00:10:29,120
via docker format and in the edit care

240
00:10:29,120 --> 00:10:29,760
challenge

241
00:10:29,760 --> 00:10:32,000
you have to evade these previously

242
00:10:32,000 --> 00:10:33,600
submitted

243
00:10:33,600 --> 00:10:36,959
machine learning models but now

244
00:10:36,959 --> 00:10:40,160
this was a black box attack

245
00:10:40,160 --> 00:10:42,959
compared to last year where the

246
00:10:42,959 --> 00:10:44,720
challengers at the

247
00:10:44,720 --> 00:10:47,040
white box access to these machine

248
00:10:47,040 --> 00:10:49,200
learning models

249
00:10:49,200 --> 00:10:51,920
this year our sponsors and partners are

250
00:10:51,920 --> 00:10:53,600
microsoft kujo ai

251
00:10:53,600 --> 00:10:56,240
vm ray and mrg avitas but the main

252
00:10:56,240 --> 00:10:57,760
organizer people remained

253
00:10:57,760 --> 00:11:00,800
the same in the competition

254
00:11:00,800 --> 00:11:06,000
and one reason why

255
00:11:07,440 --> 00:11:10,880
it makes sense to participate in our

256
00:11:10,880 --> 00:11:12,320
competition is that you can

257
00:11:12,320 --> 00:11:15,680
win azure credits for your machine

258
00:11:15,680 --> 00:11:16,320
learning

259
00:11:16,320 --> 00:11:20,640
research plans in the defensive track

260
00:11:20,640 --> 00:11:23,680
we received two submissions which passed

261
00:11:23,680 --> 00:11:27,360
the minimum requirements and

262
00:11:27,360 --> 00:11:32,240
you can see when you submit uh your

263
00:11:32,240 --> 00:11:34,560
samples that there are three models

264
00:11:34,560 --> 00:11:35,279
right now

265
00:11:35,279 --> 00:11:38,640
the ember model the need for speed model

266
00:11:38,640 --> 00:11:43,519
and random string model dom

267
00:11:44,560 --> 00:11:47,200
these are the mother families we have

268
00:11:47,200 --> 00:11:49,839
used in the attacker offensive

269
00:11:49,839 --> 00:11:53,519
track which ends on at the 18th

270
00:11:53,519 --> 00:11:57,440
of september at the time of this

271
00:11:57,440 --> 00:11:59,040
recording

272
00:11:59,040 --> 00:12:02,240
this competition has not finished yet so

273
00:12:02,240 --> 00:12:06,639
we don't know the results

274
00:12:07,200 --> 00:12:09,680
the flowchart of the attacker challenge

275
00:12:09,680 --> 00:12:11,560
is that you go to the

276
00:12:11,560 --> 00:12:14,720
msr.io website register there

277
00:12:14,720 --> 00:12:17,360
review the terms and services and accept

278
00:12:17,360 --> 00:12:18,000
it

279
00:12:18,000 --> 00:12:21,040
download the 50 provided mother

280
00:12:21,040 --> 00:12:24,480
samples you somehow modify your

281
00:12:24,480 --> 00:12:27,680
samples you know and hope that it will

282
00:12:27,680 --> 00:12:29,120
evade all three

283
00:12:29,120 --> 00:12:32,560
machine learning models we also

284
00:12:32,560 --> 00:12:34,720
hope that you check your mother

285
00:12:34,720 --> 00:12:37,040
functionality in a windows 10

286
00:12:37,040 --> 00:12:40,399
sandbox and new this year

287
00:12:40,399 --> 00:12:44,160
we have an api to submit

288
00:12:44,160 --> 00:12:47,200
your samples or query the results if you

289
00:12:47,200 --> 00:12:47,760
don't

290
00:12:47,760 --> 00:12:51,200
like the web-based ui

291
00:12:51,200 --> 00:12:54,560
and you can use this api now

292
00:12:54,560 --> 00:12:57,680
and whenever you are satisfied with your

293
00:12:57,680 --> 00:12:58,399
samples

294
00:12:58,399 --> 00:13:02,880
just create a zip file and upload it

295
00:13:02,880 --> 00:13:06,320
to our website you can get

296
00:13:06,320 --> 00:13:08,800
up to three points for each sample based

297
00:13:08,800 --> 00:13:09,760
on how many

298
00:13:09,760 --> 00:13:13,279
machine learning models you invaded and

299
00:13:13,279 --> 00:13:16,320
the highest score wins but

300
00:13:16,320 --> 00:13:19,440
with this year we are also counting the

301
00:13:19,440 --> 00:13:22,800
number of total api queries

302
00:13:22,800 --> 00:13:25,680
which is counted whenever you check a

303
00:13:25,680 --> 00:13:26,560
sample

304
00:13:26,560 --> 00:13:30,399
with a machine learning model and

305
00:13:30,399 --> 00:13:32,880
in order to claim your price your

306
00:13:32,880 --> 00:13:34,000
solution must be

307
00:13:34,000 --> 00:13:38,079
published on a blog post

308
00:13:38,639 --> 00:13:41,760
as it was the case last year please

309
00:13:41,760 --> 00:13:44,320
check that your file names remain the

310
00:13:44,320 --> 00:13:45,199
same

311
00:13:45,199 --> 00:13:47,839
in the zip file otherwise we have no way

312
00:13:47,839 --> 00:13:48,240
to

313
00:13:48,240 --> 00:13:53,279
identify which sample is which

314
00:13:53,279 --> 00:13:56,320
and besides the tricks last year

315
00:13:56,320 --> 00:13:59,519
we have also some additional tips and

316
00:13:59,519 --> 00:14:01,519
tricks you can use to manipulate the

317
00:14:01,519 --> 00:14:02,480
binaries

318
00:14:02,480 --> 00:14:04,320
for example you can add or remove

319
00:14:04,320 --> 00:14:05,600
signatures

320
00:14:05,600 --> 00:14:08,240
change the section names or properties

321
00:14:08,240 --> 00:14:09,199
modify the

322
00:14:09,199 --> 00:14:12,079
import or export tables create a tls

323
00:14:12,079 --> 00:14:12,880
callback

324
00:14:12,880 --> 00:14:16,720
change the header maybe fix or change

325
00:14:16,720 --> 00:14:20,160
check sum add modify or remove

326
00:14:20,160 --> 00:14:22,959
the version information create a new

327
00:14:22,959 --> 00:14:24,079
entry point

328
00:14:24,079 --> 00:14:26,399
or change some code or data which

329
00:14:26,399 --> 00:14:27,519
doesn't affect

330
00:14:27,519 --> 00:14:31,279
the behavior of the sample

331
00:14:31,279 --> 00:14:34,880
still it's not allowed to use droppers

332
00:14:34,880 --> 00:14:38,000
or self-extracting air highs

333
00:14:38,000 --> 00:14:40,480
and multiple registration is against the

334
00:14:40,480 --> 00:14:42,839
rules and will result in immediate

335
00:14:42,839 --> 00:14:44,560
disqualification

336
00:14:44,560 --> 00:14:48,880
feel free to join our slack channel

337
00:14:48,880 --> 00:14:52,720
and last year and this year

338
00:14:52,720 --> 00:14:54,959
if you are interested how we have

339
00:14:54,959 --> 00:14:56,560
created this challenge

340
00:14:56,560 --> 00:14:59,600
it's all based on python flask admin and

341
00:14:59,600 --> 00:15:00,480
we are using

342
00:15:00,480 --> 00:15:02,800
cloudflare enginex ng unicorn for

343
00:15:02,800 --> 00:15:05,199
scalability and performance reasons

344
00:15:05,199 --> 00:15:07,360
and we are running python backend

345
00:15:07,360 --> 00:15:08,320
scripts

346
00:15:08,320 --> 00:15:11,600
and we are using the vmree memory

347
00:15:11,600 --> 00:15:13,279
sandbox

348
00:15:13,279 --> 00:15:16,000
to check whether the mother sample

349
00:15:16,000 --> 00:15:17,040
behaves

350
00:15:17,040 --> 00:15:20,959
the same as it was originally

351
00:15:20,959 --> 00:15:24,560
as mentioned we have an api this year

352
00:15:24,560 --> 00:15:27,199
for example if you want to submit your

353
00:15:27,199 --> 00:15:28,240
sample to all

354
00:15:28,240 --> 00:15:30,000
machine learning models and get an

355
00:15:30,000 --> 00:15:31,519
immediate feedback

356
00:15:31,519 --> 00:15:35,199
feedback on it you can see the api

357
00:15:35,199 --> 00:15:38,639
endpoint on the point one or if you just

358
00:15:38,639 --> 00:15:40,560
want to submit your sample

359
00:15:40,560 --> 00:15:43,360
to one specific emma model you can do

360
00:15:43,360 --> 00:15:45,040
that as well

361
00:15:45,040 --> 00:15:47,920
uh on the point three you can see the

362
00:15:47,920 --> 00:15:48,480
api

363
00:15:48,480 --> 00:15:51,680
endpoint to get the results

364
00:15:51,680 --> 00:15:55,279
or if you already are satisfied with the

365
00:15:55,279 --> 00:15:57,199
results and want to upload your

366
00:15:57,199 --> 00:16:00,000
zip file with all the samples you can do

367
00:16:00,000 --> 00:16:00,399
this

368
00:16:00,399 --> 00:16:03,600
with the api as well or

369
00:16:03,600 --> 00:16:06,800
you can query the specific zip status or

370
00:16:06,800 --> 00:16:10,000
query all samples or specific samples

371
00:16:10,000 --> 00:16:14,160
based on these api endpoints

372
00:16:14,320 --> 00:16:16,399
but let me show you how this really

373
00:16:16,399 --> 00:16:18,480
looks like in practice

374
00:16:18,480 --> 00:16:22,399
so you visit our website mnsec dot io

375
00:16:22,399 --> 00:16:24,480
you definitely should check out the

376
00:16:24,480 --> 00:16:26,959
rules because you have to be familiar

377
00:16:26,959 --> 00:16:27,759
with

378
00:16:27,759 --> 00:16:31,040
everything that's written here we also

379
00:16:31,040 --> 00:16:32,079
recommend you

380
00:16:32,079 --> 00:16:35,440
to check out our github page for example

381
00:16:35,440 --> 00:16:37,680
for the attackers section

382
00:16:37,680 --> 00:16:40,959
hirom already uploaded

383
00:16:40,959 --> 00:16:44,160
some interesting files which you will be

384
00:16:44,160 --> 00:16:45,120
able to see

385
00:16:45,120 --> 00:16:49,440
later now if i go and

386
00:16:49,440 --> 00:16:52,880
login to the website

387
00:16:53,920 --> 00:16:57,360
here as you can see you can download

388
00:16:57,360 --> 00:17:01,519
the mother samples for this competition

389
00:17:01,519 --> 00:17:05,199
and if i check what's inside

390
00:17:05,199 --> 00:17:08,079
uh this

391
00:17:08,319 --> 00:17:11,520
compressed zip file you can see it's 50

392
00:17:11,520 --> 00:17:12,559
samples

393
00:17:12,559 --> 00:17:16,240
with sequential names and now your task

394
00:17:16,240 --> 00:17:16,959
is to

395
00:17:16,959 --> 00:17:19,280
change these files in a way that

396
00:17:19,280 --> 00:17:21,280
hopefully it will bypass

397
00:17:21,280 --> 00:17:25,119
the machine learning detection but still

398
00:17:25,119 --> 00:17:29,520
the sample will remain functional

399
00:17:29,520 --> 00:17:32,880
now let's go and

400
00:17:32,880 --> 00:17:35,919
upload our file

401
00:17:35,919 --> 00:17:38,240
and

402
00:17:39,440 --> 00:17:41,840
let me show it this to you it's

403
00:17:41,840 --> 00:17:42,720
important

404
00:17:42,720 --> 00:17:45,520
that in the zip files the file names

405
00:17:45,520 --> 00:17:47,280
remain the same and you don't

406
00:17:47,280 --> 00:17:50,960
use any directories for example

407
00:17:50,960 --> 00:17:54,640
so let's download this new

408
00:17:54,640 --> 00:17:58,320
zip file and

409
00:17:58,320 --> 00:18:03,520
let's see what will happen

410
00:18:09,440 --> 00:18:12,799
i paused the recording for a little bit

411
00:18:12,799 --> 00:18:16,880
but now as you can see the samples

412
00:18:16,880 --> 00:18:20,080
has been started to in the analyze

413
00:18:20,080 --> 00:18:22,000
process

414
00:18:22,000 --> 00:18:24,880
and here you can see all the different

415
00:18:24,880 --> 00:18:25,840
information

416
00:18:25,840 --> 00:18:29,120
uh from my test upload as you can see

417
00:18:29,120 --> 00:18:32,000
even though these executables were valid

418
00:18:32,000 --> 00:18:35,200
new executables for the competition i

419
00:18:35,200 --> 00:18:37,679
was not able to bypass

420
00:18:37,679 --> 00:18:41,280
any of these machine learning algorithms

421
00:18:41,280 --> 00:18:45,440
mainly because i did not intend to do so

422
00:18:45,440 --> 00:18:48,480
but as you can see

423
00:18:48,480 --> 00:18:52,960
now the whole sample processing started

424
00:18:52,960 --> 00:18:56,160
it's uh also interesting to check out

425
00:18:56,160 --> 00:18:59,600
your user management site and

426
00:18:59,600 --> 00:19:02,400
change your nickname to something better

427
00:19:02,400 --> 00:19:04,240
because by default it's randomly

428
00:19:04,240 --> 00:19:06,080
generated

429
00:19:06,080 --> 00:19:09,360
and it's also important to have a look

430
00:19:09,360 --> 00:19:09,679
at

431
00:19:09,679 --> 00:19:13,600
the total api queries because

432
00:19:13,600 --> 00:19:17,760
this counts into the your

433
00:19:17,760 --> 00:19:20,880
total ranking and

434
00:19:20,880 --> 00:19:23,200
every time a sample of yours is

435
00:19:23,200 --> 00:19:24,240
submitted to

436
00:19:24,240 --> 00:19:27,360
a single machine learning model this

437
00:19:27,360 --> 00:19:28,880
counter is

438
00:19:28,880 --> 00:19:31,919
incremented by one

439
00:19:31,919 --> 00:19:35,280
and now if i check out

440
00:19:35,280 --> 00:19:38,880
the scores section you can see that

441
00:19:38,880 --> 00:19:42,240
someone already has the

442
00:19:42,240 --> 00:19:46,240
best scores when it comes to

443
00:19:46,240 --> 00:19:49,280
bypassing the machine learning models

444
00:19:49,280 --> 00:19:51,600
because we have the free machine

445
00:19:51,600 --> 00:19:53,840
learning model and 50 samples so that's

446
00:19:53,840 --> 00:19:54,640
a total

447
00:19:54,640 --> 00:19:57,760
of 150 scores

448
00:19:57,760 --> 00:20:02,280
but this contestant used

449
00:20:02,280 --> 00:20:07,840
741 total api queries for his solution

450
00:20:07,840 --> 00:20:12,640
so maybe we will we don't know

451
00:20:12,640 --> 00:20:15,600
maybe someone else will be able to

452
00:20:15,600 --> 00:20:17,520
achieve the same score

453
00:20:17,520 --> 00:20:23,280
with less number of total api queries

454
00:20:23,280 --> 00:20:26,320
basically that is all what i wanted

455
00:20:26,320 --> 00:20:30,559
to share with you you can also remove

456
00:20:30,559 --> 00:20:34,159
some of your samples if it's

457
00:20:34,159 --> 00:20:37,840
it was not able to bypass anything

458
00:20:37,840 --> 00:20:41,200
you can also filter these

459
00:20:41,200 --> 00:20:44,240
columns if you are interested or

460
00:20:44,240 --> 00:20:48,640
you can also export all of your

461
00:20:48,640 --> 00:20:51,679
all of data from this table to a csv

462
00:20:51,679 --> 00:20:53,520
file if you want to process it for

463
00:20:53,520 --> 00:20:55,520
yourself

464
00:20:55,520 --> 00:21:02,159
so that's all thank you

465
00:21:02,159 --> 00:21:04,159
this is all i wanted to share with you

466
00:21:04,159 --> 00:21:05,919
guys today but

467
00:21:05,919 --> 00:21:08,400
please stay because here comes hyrum

468
00:21:08,400 --> 00:21:09,840
anderson

469
00:21:09,840 --> 00:21:12,720
who will show you an example solution

470
00:21:12,720 --> 00:21:14,159
which could have been used

471
00:21:14,159 --> 00:21:17,840
to win the competition

472
00:21:19,600 --> 00:21:21,760
my name is hyrum anderson and i'm

473
00:21:21,760 --> 00:21:23,600
delighted to present virtually at

474
00:21:23,600 --> 00:21:27,120
activity i'm going to be

475
00:21:27,120 --> 00:21:29,360
presenting the machine learning evasion

476
00:21:29,360 --> 00:21:30,400
code walkthrough

477
00:21:30,400 --> 00:21:32,480
this tool was included in the sample

478
00:21:32,480 --> 00:21:34,480
solution to the attacker challenge

479
00:21:34,480 --> 00:21:36,240
in the machine learning security evasion

480
00:21:36,240 --> 00:21:37,919
competition

481
00:21:37,919 --> 00:21:39,679
you can download and play with this code

482
00:21:39,679 --> 00:21:42,320
by visiting mlsec.io

483
00:21:42,320 --> 00:21:44,240
and navigating to the attacker challenge

484
00:21:44,240 --> 00:21:46,960
github repo

485
00:21:47,280 --> 00:21:49,679
our example solution was designed with

486
00:21:49,679 --> 00:21:51,360
the following things in mind

487
00:21:51,360 --> 00:21:53,919
number one the models to be attacked

488
00:21:53,919 --> 00:21:55,919
were submitted by contestants

489
00:21:55,919 --> 00:21:58,080
in the defender challenge that concluded

490
00:21:58,080 --> 00:21:59,840
previously

491
00:21:59,840 --> 00:22:02,000
two models from the previous round

492
00:22:02,000 --> 00:22:04,159
qualified to be included in the attacker

493
00:22:04,159 --> 00:22:05,760
challenge

494
00:22:05,760 --> 00:22:09,039
in addition we have hosted our own model

495
00:22:09,039 --> 00:22:10,880
to be attacked that is based on the

496
00:22:10,880 --> 00:22:13,840
ember data set

497
00:22:14,640 --> 00:22:17,760
the models to be attacked report hard

498
00:22:17,760 --> 00:22:18,640
labels

499
00:22:18,640 --> 00:22:20,799
for submissions provided to them that is

500
00:22:20,799 --> 00:22:22,880
they do not provide a score between 0

501
00:22:22,880 --> 00:22:23,520
and 1

502
00:22:23,520 --> 00:22:26,240
but just a 0 for benign and one for

503
00:22:26,240 --> 00:22:28,799
malicious

504
00:22:28,960 --> 00:22:32,159
finally we considered the leaderboard

505
00:22:32,159 --> 00:22:33,039
criteria

506
00:22:33,039 --> 00:22:36,480
while designing our solution the first

507
00:22:36,480 --> 00:22:38,159
criterion

508
00:22:38,159 --> 00:22:40,400
considers the number of model evasions

509
00:22:40,400 --> 00:22:42,960
with three models and 50 malware samples

510
00:22:42,960 --> 00:22:46,880
the maximum score is 150 points

511
00:22:46,880 --> 00:22:50,000
a tiebreaker would be decided by the

512
00:22:50,000 --> 00:22:51,039
efficiency

513
00:22:51,039 --> 00:22:53,520
in which the models were evaded so we

514
00:22:53,520 --> 00:22:56,240
count the number of model queries

515
00:22:56,240 --> 00:22:59,039
thus contestants are incentivized not

516
00:22:59,039 --> 00:23:00,480
only to be evasive

517
00:23:00,480 --> 00:23:04,159
but also to do it efficiently

518
00:23:05,360 --> 00:23:07,200
contestants were able to choose any

519
00:23:07,200 --> 00:23:08,960
strategy that they like

520
00:23:08,960 --> 00:23:11,919
to demonstrate one strategy we released

521
00:23:11,919 --> 00:23:13,360
this example code

522
00:23:13,360 --> 00:23:16,720
on our competitions github site

523
00:23:16,720 --> 00:23:20,000
the code uses discrete optimization

524
00:23:20,000 --> 00:23:22,400
over functionality preserving file

525
00:23:22,400 --> 00:23:24,000
modifications

526
00:23:24,000 --> 00:23:26,559
using a package called hyperopt which

527
00:23:26,559 --> 00:23:27,760
ironically

528
00:23:27,760 --> 00:23:30,799
is often used for tuning

529
00:23:30,799 --> 00:23:33,440
machine learning models you can learn

530
00:23:33,440 --> 00:23:34,159
more about

531
00:23:34,159 --> 00:23:37,200
the details from the code

532
00:23:37,200 --> 00:23:40,720
and documentation on the website

533
00:23:40,720 --> 00:23:43,039
however the broader strategy may be of

534
00:23:43,039 --> 00:23:45,919
general interest

535
00:23:46,320 --> 00:23:48,640
it consists of employing an algorithm in

536
00:23:48,640 --> 00:23:49,760
part a

537
00:23:49,760 --> 00:23:51,679
to get the bulk of the malware to be

538
00:23:51,679 --> 00:23:52,880
evasive

539
00:23:52,880 --> 00:23:55,840
while remaining functional followed by

540
00:23:55,840 --> 00:23:56,400
any

541
00:23:56,400 --> 00:23:59,520
additional manual steps in part b to

542
00:23:59,520 --> 00:24:03,279
fix any few remaining samples

543
00:24:03,279 --> 00:24:06,640
we use the example code in our strategy

544
00:24:06,640 --> 00:24:08,159
in part a

545
00:24:08,159 --> 00:24:12,159
in which we break our algorithmic attack

546
00:24:12,159 --> 00:24:14,960
into two phases an offline attack

547
00:24:14,960 --> 00:24:15,600
against

548
00:24:15,600 --> 00:24:18,799
a known defender model for which we have

549
00:24:18,799 --> 00:24:19,919
code and weights

550
00:24:19,919 --> 00:24:22,559
and an online attack the hope is that

551
00:24:22,559 --> 00:24:23,840
many of the samples

552
00:24:23,840 --> 00:24:25,440
that were discovered in the offline

553
00:24:25,440 --> 00:24:27,520
attack will cross evade

554
00:24:27,520 --> 00:24:30,320
the hosted online models without having

555
00:24:30,320 --> 00:24:32,640
used any additional queries against the

556
00:24:32,640 --> 00:24:34,559
api

557
00:24:34,559 --> 00:24:37,120
you may visit mlsectao to download this

558
00:24:37,120 --> 00:24:37,840
code

559
00:24:37,840 --> 00:24:40,240
however please be warned that when you

560
00:24:40,240 --> 00:24:41,440
run this demo code

561
00:24:41,440 --> 00:24:43,360
you will write functional malware to

562
00:24:43,360 --> 00:24:46,240
disk so please do so only using a linux

563
00:24:46,240 --> 00:24:48,640
vm

564
00:24:49,120 --> 00:24:51,679
to begin we initialize the attack by

565
00:24:51,679 --> 00:24:54,799
analyzing a collection of benign files

566
00:24:54,799 --> 00:24:57,440
the init sub-command extracts elements

567
00:24:57,440 --> 00:24:59,039
of the benign files that will be

568
00:24:59,039 --> 00:25:00,080
injected

569
00:25:00,080 --> 00:25:03,440
later into the malware to launch our

570
00:25:03,440 --> 00:25:04,720
offline attack

571
00:25:04,720 --> 00:25:07,360
we first run a local copy of the ember

572
00:25:07,360 --> 00:25:08,159
model

573
00:25:08,159 --> 00:25:10,559
in the top window then in the bottom

574
00:25:10,559 --> 00:25:11,440
window

575
00:25:11,440 --> 00:25:13,760
we'll use the run subcommand of our

576
00:25:13,760 --> 00:25:15,120
attack script

577
00:25:15,120 --> 00:25:18,960
passing in malware samples

578
00:25:18,960 --> 00:25:22,480
that were downloaded by contestants

579
00:25:22,480 --> 00:25:24,720
the tool will write successful evasion

580
00:25:24,720 --> 00:25:25,919
attempts to

581
00:25:25,919 --> 00:25:29,679
pass one success and failed attempts to

582
00:25:29,679 --> 00:25:30,720
pass one

583
00:25:30,720 --> 00:25:34,960
slash failure also included in each

584
00:25:34,960 --> 00:25:35,760
directory

585
00:25:35,760 --> 00:25:38,240
are history files that would allow us to

586
00:25:38,240 --> 00:25:40,840
resume our optimization of failed

587
00:25:40,840 --> 00:25:43,840
attempts

588
00:25:48,240 --> 00:25:51,200
in a second pass we begin with only the

589
00:25:51,200 --> 00:25:51,600
past

590
00:25:51,600 --> 00:25:53,360
one failures and iterate on the

591
00:25:53,360 --> 00:25:54,720
optimization

592
00:25:54,720 --> 00:25:57,120
again storing successes and failures to

593
00:25:57,120 --> 00:26:00,399
a folder of our choice

594
00:26:01,520 --> 00:26:03,120
having now collected candidates that

595
00:26:03,120 --> 00:26:05,120
evade the ember model

596
00:26:05,120 --> 00:26:08,240
we use those candidates as seeds for an

597
00:26:08,240 --> 00:26:09,360
online attack

598
00:26:09,360 --> 00:26:11,840
which now counts against our api query

599
00:26:11,840 --> 00:26:12,960
usage

600
00:26:12,960 --> 00:26:14,960
the online attack is enabled with a

601
00:26:14,960 --> 00:26:16,240
simple dash dash

602
00:26:16,240 --> 00:26:18,960
online flag

603
00:26:21,360 --> 00:26:24,559
after several iterations we can now

604
00:26:24,559 --> 00:26:27,840
gather the successfully evasive variants

605
00:26:27,840 --> 00:26:31,039
and create a zip file to be uploaded to

606
00:26:31,039 --> 00:26:33,679
the website

607
00:26:36,320 --> 00:26:38,240
since there is a chance that the file

608
00:26:38,240 --> 00:26:39,919
modifications have broken

609
00:26:39,919 --> 00:26:43,200
some of the files contestants

610
00:26:43,200 --> 00:26:45,679
have been encouraged to run the samples

611
00:26:45,679 --> 00:26:47,600
in a windows 10 sandbox

612
00:26:47,600 --> 00:26:49,919
to validate functionality before

613
00:26:49,919 --> 00:26:53,840
uploading to the competition website

614
00:26:54,480 --> 00:26:57,440
as a final note since the host of models

615
00:26:57,440 --> 00:26:57,840
may

616
00:26:57,840 --> 00:27:00,080
learn from the queries issued by

617
00:27:00,080 --> 00:27:01,360
contestants

618
00:27:01,360 --> 00:27:04,000
there is a possibility that an evasive

619
00:27:04,000 --> 00:27:06,000
variant discovered by a contestant at

620
00:27:06,000 --> 00:27:08,159
the beginning of the competition

621
00:27:08,159 --> 00:27:11,840
may no longer be evasive to a model

622
00:27:11,840 --> 00:27:14,320
by the end of the competition because

623
00:27:14,320 --> 00:27:18,159
the model has changed its state

624
00:27:18,159 --> 00:27:20,399
we're recording these talks prior to

625
00:27:20,399 --> 00:27:21,840
knowing the winners

626
00:27:21,840 --> 00:27:23,919
of the attacker challenge i would like

627
00:27:23,919 --> 00:27:26,159
to preemptively congratulate

628
00:27:26,159 --> 00:27:28,720
those who have won our grand and first

629
00:27:28,720 --> 00:27:30,960
prizes respectively

630
00:27:30,960 --> 00:27:33,279
in order to receive those prizes the

631
00:27:33,279 --> 00:27:34,000
contestants

632
00:27:34,000 --> 00:27:36,320
must publish or blog about their

633
00:27:36,320 --> 00:27:38,000
solutions

634
00:27:38,000 --> 00:27:39,600
i look forward to learning about the

635
00:27:39,600 --> 00:27:41,840
winning competition strategies

636
00:27:41,840 --> 00:27:43,679
i would like to thank our sponsors and

637
00:27:43,679 --> 00:27:46,000
partners for making this competition

638
00:27:46,000 --> 00:27:49,840
a reality

