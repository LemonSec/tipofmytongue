1
00:00:00,180 --> 00:00:05,580
hello everyone good evening

2
00:00:03,600 --> 00:00:07,290
now I was thinking about giving you some

3
00:00:05,580 --> 00:00:11,129
time to read the title but I think it's

4
00:00:07,290 --> 00:00:13,498
better if I explain so we are from the

5
00:00:11,129 --> 00:00:17,160
civils fear project and our goal is to

6
00:00:13,499 --> 00:00:20,820
protect people at risk and we do that by

7
00:00:17,160 --> 00:00:25,349
analyzing their traffic and one of the

8
00:00:20,820 --> 00:00:27,900
ways to help increase the efficiency of

9
00:00:25,349 --> 00:00:31,259
the whole process is machine learning

10
00:00:27,900 --> 00:00:32,449
and so that's what we're gonna explain

11
00:00:31,259 --> 00:00:35,610
today

12
00:00:32,450 --> 00:00:37,410
I'm Frank Cossack I'm student of

13
00:00:35,610 --> 00:00:39,150
artificial intelligence in Czech

14
00:00:37,410 --> 00:00:43,440
Technical University in Prague in the

15
00:00:39,150 --> 00:00:46,170
Czech Republic I focus on machine

16
00:00:43,440 --> 00:00:48,780
learning in cybersecurity and for last

17
00:00:46,170 --> 00:00:51,960
five weeks I start to exercise yoga so I

18
00:00:48,780 --> 00:00:54,000
like yoga and here is Jana Pfeiffer he's

19
00:00:51,960 --> 00:00:57,000
also researcher and student in the same

20
00:00:54,000 --> 00:00:59,310
University and he also focused on

21
00:00:57,000 --> 00:01:02,310
machine learning in cyber security and

22
00:00:59,310 --> 00:01:05,550
traffic analysis and he loves singing in

23
00:01:02,310 --> 00:01:08,130
shower and both of us like actually

24
00:01:05,550 --> 00:01:11,120
laugh the beers and for last two days we

25
00:01:08,130 --> 00:01:15,030
like also the best it's very nice yeah

26
00:01:11,120 --> 00:01:18,600
so the goal of this whole project of our

27
00:01:15,030 --> 00:01:22,800
research is for stuff like that to

28
00:01:18,600 --> 00:01:23,970
happen less so when I said we help

29
00:01:22,800 --> 00:01:29,280
people at risk

30
00:01:23,970 --> 00:01:31,950
I meant journalists lawyers human rights

31
00:01:29,280 --> 00:01:34,620
defenders basically anyone who's not

32
00:01:31,950 --> 00:01:39,780
from the corporate world and doesn't

33
00:01:34,620 --> 00:01:43,290
have a lot of money to get a good

34
00:01:39,780 --> 00:01:46,530
security team and take care of all the

35
00:01:43,290 --> 00:01:51,510
ways and of their basically of their

36
00:01:46,530 --> 00:01:55,950
security but we also care about other

37
00:01:51,510 --> 00:01:59,909
threats more common which are headlines

38
00:01:55,950 --> 00:02:02,450
like these so attacks that are not

39
00:01:59,909 --> 00:02:06,510
targeted not targeting the specific

40
00:02:02,450 --> 00:02:11,790
person but are generally attacking

41
00:02:06,510 --> 00:02:14,140
everyone so what can you do when you get

42
00:02:11,790 --> 00:02:17,190
infected you

43
00:02:14,140 --> 00:02:21,390
panic that's one one thing you could do

44
00:02:17,190 --> 00:02:25,690
there are the other ways that a person

45
00:02:21,390 --> 00:02:28,630
can do so imagine a journalist that has

46
00:02:25,690 --> 00:02:32,170
their phone and the journalist might

47
00:02:28,630 --> 00:02:33,940
suspect that the phone is infected so

48
00:02:32,170 --> 00:02:37,149
the first thing you could do is get rid

49
00:02:33,940 --> 00:02:39,940
of the phone throw it in the trash that

50
00:02:37,150 --> 00:02:42,780
might solve the problem but also the

51
00:02:39,940 --> 00:02:46,660
person loses all the data and the device

52
00:02:42,780 --> 00:02:49,600
another option is to factory reset the

53
00:02:46,660 --> 00:02:53,130
device wipe the disk which also loses

54
00:02:49,600 --> 00:02:55,870
the data and it's not a good solution

55
00:02:53,130 --> 00:02:59,070
anytime a person becomes suspicious that

56
00:02:55,870 --> 00:03:03,850
something might be happening right

57
00:02:59,070 --> 00:03:08,260
antivirus is another option which might

58
00:03:03,850 --> 00:03:11,590
help in some cases but usually with

59
00:03:08,260 --> 00:03:16,870
sophisticated and targeted attacks it

60
00:03:11,590 --> 00:03:19,870
doesn't really help now a good way to

61
00:03:16,870 --> 00:03:22,239
figure out if if your device is infected

62
00:03:19,870 --> 00:03:25,690
is to perform a forensic analysis

63
00:03:22,239 --> 00:03:28,600
actually look at the disk but that also

64
00:03:25,690 --> 00:03:32,100
means that you have to give your device

65
00:03:28,600 --> 00:03:34,269
to someone go somewhere and physically

66
00:03:32,100 --> 00:03:39,430
physically give the device to someone

67
00:03:34,269 --> 00:03:41,650
which is not always convenient a good

68
00:03:39,430 --> 00:03:47,250
way might be to analyze the traffic of

69
00:03:41,650 --> 00:03:51,130
the device and one thing there is that

70
00:03:47,250 --> 00:03:53,500
how to give your traffic or show your

71
00:03:51,130 --> 00:03:57,370
traffic to the correct person who can

72
00:03:53,500 --> 00:04:00,190
analyze it and that's when our project

73
00:03:57,370 --> 00:04:06,190
comes in it's called the Emergency VPN

74
00:04:00,190 --> 00:04:10,320
project the goal is to find any

75
00:04:06,190 --> 00:04:12,910
vulnerabilities and anything basically

76
00:04:10,320 --> 00:04:16,029
that we can see that could harm the

77
00:04:12,910 --> 00:04:19,600
person that is happening on their device

78
00:04:16,029 --> 00:04:23,400
usually a mobile phone a cell phone now

79
00:04:19,600 --> 00:04:26,169
why network traffic

80
00:04:23,400 --> 00:04:27,650
well network traffic is a good indicator

81
00:04:26,169 --> 00:04:30,560
of what is happening in

82
00:04:27,650 --> 00:04:34,250
phone there's a lot of data a lot of

83
00:04:30,560 --> 00:04:39,830
information so for a network analyst it

84
00:04:34,250 --> 00:04:42,139
is it is easy to guess a lot of the

85
00:04:39,830 --> 00:04:47,150
things that are happening there also

86
00:04:42,139 --> 00:04:50,030
with a lot of infections and malware

87
00:04:47,150 --> 00:04:52,520
there is malicious communication

88
00:04:50,030 --> 00:04:54,830
malicious traffic that is happening so

89
00:04:52,520 --> 00:05:00,109
that will also be in that network

90
00:04:54,830 --> 00:05:04,039
traffic right it's not just a good

91
00:05:00,110 --> 00:05:08,600
indicator for an out for an analyst it's

92
00:05:04,039 --> 00:05:12,169
also a way for attackers to get the

93
00:05:08,600 --> 00:05:15,970
information from the traffic or use the

94
00:05:12,169 --> 00:05:22,090
traffic as a way to infect the device as

95
00:05:15,970 --> 00:05:25,190
you can see for example a person lawyer

96
00:05:22,090 --> 00:05:28,400
connecting to a Wi-Fi public Wi-Fi at a

97
00:05:25,190 --> 00:05:32,620
cafe there are a lot of people that can

98
00:05:28,400 --> 00:05:36,948
actually look at its traffic and

99
00:05:32,620 --> 00:05:41,060
possibly modify it there is and usually

100
00:05:36,949 --> 00:05:43,460
anyone connecting to the Wi-Fi and then

101
00:05:41,060 --> 00:05:47,900
anyone with the access to the Internet

102
00:05:43,460 --> 00:05:51,830
Service Providers rotors that also

103
00:05:47,900 --> 00:05:54,560
depends on the country but the general

104
00:05:51,830 --> 00:05:57,859
idea is that network traffic tells a lot

105
00:05:54,560 --> 00:06:02,949
and it's important to have an idea of

106
00:05:57,860 --> 00:06:06,289
what's happening in the phone so

107
00:06:02,949 --> 00:06:09,139
emergency VPN is a free service for

108
00:06:06,289 --> 00:06:12,440
people at risk the goal is always to

109
00:06:09,139 --> 00:06:16,099
find anything that could harm the person

110
00:06:12,440 --> 00:06:18,560
that means ongoing infections malware

111
00:06:16,099 --> 00:06:21,639
that is already installed and it's

112
00:06:18,560 --> 00:06:24,770
generating or generating some traffic or

113
00:06:21,639 --> 00:06:28,970
sending information to the attacker

114
00:06:24,770 --> 00:06:31,359
or any vulnerabilities that are in the

115
00:06:28,970 --> 00:06:34,460
system

116
00:06:31,360 --> 00:06:39,409
we do that by manually analyzing the

117
00:06:34,460 --> 00:06:40,529
traffic and then we craft a report that

118
00:06:39,409 --> 00:06:43,529
we share with the person

119
00:06:40,529 --> 00:06:48,529
and give them the details of how to

120
00:06:43,529 --> 00:06:51,359
proceed we usually take three days to

121
00:06:48,529 --> 00:06:54,929
capture the traffic three days of

122
00:06:51,359 --> 00:06:58,979
traffic to basically get an idea of what

123
00:06:54,929 --> 00:07:02,149
is happening in that device so the usual

124
00:06:58,979 --> 00:07:06,688
process would be a person contacts us

125
00:07:02,149 --> 00:07:11,299
tells us they want an assessment of what

126
00:07:06,689 --> 00:07:14,879
is happening in their phone so they get

127
00:07:11,299 --> 00:07:17,938
we send them a over OpenVPN profile

128
00:07:14,879 --> 00:07:21,299
which enables them to connect to our

129
00:07:17,939 --> 00:07:24,629
Open VPN server to our VPN server at our

130
00:07:21,299 --> 00:07:28,948
university in czech republic and then

131
00:07:24,629 --> 00:07:31,819
the person uses the phone depending on

132
00:07:28,949 --> 00:07:35,909
their suspicions but all the traffic is

133
00:07:31,819 --> 00:07:39,239
first sent to our university as in the

134
00:07:35,909 --> 00:07:41,248
normal VPN the twist is that we capture

135
00:07:39,239 --> 00:07:45,869
all the traffic we copy all the traffic

136
00:07:41,249 --> 00:07:49,499
and but the functionality of the VPN

137
00:07:45,869 --> 00:07:52,169
stays and when we usually take three

138
00:07:49,499 --> 00:07:56,369
days we capture the traffic and that's

139
00:07:52,169 --> 00:08:00,239
when the core part starts the traffic

140
00:07:56,369 --> 00:08:06,229
analysis we have the data and we try to

141
00:08:00,239 --> 00:08:08,909
find anything suspicious and malicious

142
00:08:06,229 --> 00:08:11,459
usually at the start we get an overview

143
00:08:08,909 --> 00:08:14,308
of what is happening right we can see

144
00:08:11,459 --> 00:08:19,829
the device that we can usually guess the

145
00:08:14,309 --> 00:08:22,709
device of the user we can get

146
00:08:19,829 --> 00:08:26,399
information about what application the

147
00:08:22,709 --> 00:08:32,068
person is using and we look at all the

148
00:08:26,399 --> 00:08:35,250
protocols the device is using and we try

149
00:08:32,068 --> 00:08:38,578
to separate the traffic so for example

150
00:08:35,250 --> 00:08:41,370
if we know that the that the device is

151
00:08:38,578 --> 00:08:45,149
an Android we know of the background

152
00:08:41,370 --> 00:08:47,550
processes we know the IPS that the

153
00:08:45,149 --> 00:08:51,809
operating system usually connects you

154
00:08:47,550 --> 00:08:53,819
and we can take that traffic out of the

155
00:08:51,809 --> 00:08:55,829
analysis similar with

156
00:08:53,820 --> 00:08:58,260
loan applications that we know that the

157
00:08:55,830 --> 00:09:04,950
person is using and are not malicious

158
00:08:58,260 --> 00:09:07,439
and then we do a detailed look at the

159
00:09:04,950 --> 00:09:11,730
rest of the stuff sometimes we go packet

160
00:09:07,440 --> 00:09:15,450
by packet analyzing what is happening we

161
00:09:11,730 --> 00:09:18,150
use several tools to help us speed this

162
00:09:15,450 --> 00:09:21,110
process up and make it faster you

163
00:09:18,150 --> 00:09:26,760
probably know some of these for example

164
00:09:21,110 --> 00:09:30,150
seek or sericata to help us get an idea

165
00:09:26,760 --> 00:09:34,520
of some events or unusual events in the

166
00:09:30,150 --> 00:09:39,720
traffic we use the stratosphere Linux

167
00:09:34,520 --> 00:09:43,439
IPs and of course Wireshark when it

168
00:09:39,720 --> 00:09:46,140
comes to the detailed stuff now with

169
00:09:43,440 --> 00:09:50,310
this analysis there are several

170
00:09:46,140 --> 00:09:54,480
positives and negatives so the positive

171
00:09:50,310 --> 00:09:59,130
side the upsides the analysis is pretty

172
00:09:54,480 --> 00:10:02,700
detailed we get a good idea of what is

173
00:09:59,130 --> 00:10:06,510
happening we know what each connection

174
00:10:02,700 --> 00:10:09,720
does and why is it happening and we can

175
00:10:06,510 --> 00:10:12,630
confidently say if in the traffic that

176
00:10:09,720 --> 00:10:17,940
we saw if there's any anything malicious

177
00:10:12,630 --> 00:10:21,870
or suspicious however there are a lot of

178
00:10:17,940 --> 00:10:26,160
issues the first issue is that it takes

179
00:10:21,870 --> 00:10:29,430
a lot of time for three days of traffic

180
00:10:26,160 --> 00:10:32,490
usually takes at least eight hours to go

181
00:10:29,430 --> 00:10:37,560
through everything and craft a report

182
00:10:32,490 --> 00:10:42,540
for that person and the main the main

183
00:10:37,560 --> 00:10:46,290
time consumer is HTTP traffic because

184
00:10:42,540 --> 00:10:49,670
obviously we cannot see the content so

185
00:10:46,290 --> 00:10:53,160
we cannot see if it's malicious or not

186
00:10:49,670 --> 00:10:55,349
we know that it's not a vulnerable

187
00:10:53,160 --> 00:10:59,400
connection because it's hard to modify

188
00:10:55,350 --> 00:11:03,720
it but it's generally harder to assess

189
00:10:59,400 --> 00:11:06,819
and a thing connected to this is

190
00:11:03,720 --> 00:11:11,949
patterns in traffic which means

191
00:11:06,819 --> 00:11:15,669
is that for example uh apt the when a

192
00:11:11,949 --> 00:11:19,929
person has a an infected device and the

193
00:11:15,669 --> 00:11:22,419
attacker periodically gets the location

194
00:11:19,929 --> 00:11:25,569
of the person or there are some patterns

195
00:11:22,419 --> 00:11:32,019
in the traffic that might be observable

196
00:11:25,569 --> 00:11:34,149
but are difficult to by a human so how

197
00:11:32,019 --> 00:11:38,039
do we make this process more effective

198
00:11:34,149 --> 00:11:43,509
so that we can actually help a

199
00:11:38,039 --> 00:11:50,319
significant number of people and make

200
00:11:43,509 --> 00:11:53,919
take the day for one analysis down so

201
00:11:50,319 --> 00:11:59,439
the idea that we came up with was using

202
00:11:53,919 --> 00:12:02,559
machine learning yes we tried to deploy

203
00:11:59,439 --> 00:12:05,309
machine learning techniques and data

204
00:12:02,559 --> 00:12:07,899
collection systems to speed up this

205
00:12:05,309 --> 00:12:11,199
analysis of the Internet traffic and

206
00:12:07,899 --> 00:12:15,089
also try to learn machine learning

207
00:12:11,199 --> 00:12:17,769
system what is the HTTP malicious

208
00:12:15,089 --> 00:12:23,829
connections because it's pretty hard to

209
00:12:17,769 --> 00:12:27,159
say if if it's malicious or not so in

210
00:12:23,829 --> 00:12:31,659
the beginning we can we were see this

211
00:12:27,159 --> 00:12:34,209
picture of the normal scenario machine

212
00:12:31,659 --> 00:12:36,909
learning process so when the mechanic we

213
00:12:34,209 --> 00:12:39,518
need the data enough data and reliable

214
00:12:36,909 --> 00:12:41,859
data then we extract the features from

215
00:12:39,519 --> 00:12:44,319
that so it means that we have to

216
00:12:41,859 --> 00:12:46,359
understand the problem and make some

217
00:12:44,319 --> 00:12:50,949
research what is actually malicious

218
00:12:46,359 --> 00:12:54,369
behavior and train model it means choose

219
00:12:50,949 --> 00:12:56,498
the right high level features for our

220
00:12:54,369 --> 00:12:59,169
algorithm and also choose the right

221
00:12:56,499 --> 00:13:02,319
machine learning algorithm and then

222
00:12:59,169 --> 00:13:03,999
evaluate it if you are not happy with

223
00:13:02,319 --> 00:13:06,899
the results you can start from the

224
00:13:03,999 --> 00:13:09,720
beginning so it means put more later or

225
00:13:06,899 --> 00:13:13,479
choose another interpretation of your

226
00:13:09,720 --> 00:13:16,209
samples or choose another type a

227
00:13:13,479 --> 00:13:17,660
parameters for machine learning

228
00:13:16,209 --> 00:13:20,510
algorithm

229
00:13:17,660 --> 00:13:23,689
the importance the most important stuff

230
00:13:20,510 --> 00:13:25,880
is data sent for each machine learning

231
00:13:23,690 --> 00:13:28,310
tasks if we start from the image

232
00:13:25,880 --> 00:13:31,250
classification or to language processing

233
00:13:28,310 --> 00:13:34,280
and we if we end here in the

234
00:13:31,250 --> 00:13:37,760
cybersecurity the data set is core of

235
00:13:34,280 --> 00:13:40,430
the research so it can sometimes gonna

236
00:13:37,760 --> 00:13:44,060
be very tough and you can die during the

237
00:13:40,430 --> 00:13:47,719
late blink hopefully and fortunately we

238
00:13:44,060 --> 00:13:50,390
have data set it's available and it's

239
00:13:47,720 --> 00:13:53,090
also free so you can use for your

240
00:13:50,390 --> 00:13:57,110
research if you need and we have enough

241
00:13:53,090 --> 00:13:59,390
samples for that so we have C 214 data

242
00:13:57,110 --> 00:14:02,600
set and M CFP data set which is was

243
00:13:59,390 --> 00:14:05,960
which was generated in our University in

244
00:14:02,600 --> 00:14:08,750
Prague so you can use it if you want but

245
00:14:05,960 --> 00:14:11,540
in that moment we had enough malware

246
00:14:08,750 --> 00:14:14,510
captures and enough samples for training

247
00:14:11,540 --> 00:14:18,790
but we didn't have enough normal samples

248
00:14:14,510 --> 00:14:21,650
so it means that we spend some days of

249
00:14:18,790 --> 00:14:25,790
clicking under normal websites which we

250
00:14:21,650 --> 00:14:28,579
know there are safe and we generate new

251
00:14:25,790 --> 00:14:33,020
accounts on fake accounts of Facebook

252
00:14:28,580 --> 00:14:36,020
Twitter and so on and then we also ask

253
00:14:33,020 --> 00:14:39,170
our department if we can capture the

254
00:14:36,020 --> 00:14:41,600
data from the employees there so we we

255
00:14:39,170 --> 00:14:42,740
went door by door and asked people yes

256
00:14:41,600 --> 00:14:44,690
are you human

257
00:14:42,740 --> 00:14:46,250
because you know in our department

258
00:14:44,690 --> 00:14:49,310
there's a lot of printers and robots so

259
00:14:46,250 --> 00:14:52,880
we first we had to ask and if we person

260
00:14:49,310 --> 00:14:56,599
agree so then we could use his or her IP

261
00:14:52,880 --> 00:15:01,340
for our data set and get rid from that

262
00:14:56,600 --> 00:15:05,270
so after this capturing and analyzing

263
00:15:01,340 --> 00:15:07,520
data we had enough data to train so we

264
00:15:05,270 --> 00:15:12,170
could start with in with extracting

265
00:15:07,520 --> 00:15:15,560
features and training on the beginning

266
00:15:12,170 --> 00:15:21,410
each capture has pickup file with the

267
00:15:15,560 --> 00:15:26,510
packets and we use cheek or bra program

268
00:15:21,410 --> 00:15:29,430
to generate those from that packets so

269
00:15:26,510 --> 00:15:32,069
we had the flows we can see

270
00:15:29,430 --> 00:15:34,469
and for all of those with the same

271
00:15:32,070 --> 00:15:37,440
source IP destination IP destination

272
00:15:34,470 --> 00:15:40,170
port and protocol we group it to one

273
00:15:37,440 --> 00:15:43,110
object which we say to assess our

274
00:15:40,170 --> 00:15:48,719
aggregation so SSR aggregation is unlike

275
00:15:43,110 --> 00:15:52,410
object having all same flows and from

276
00:15:48,720 --> 00:15:55,620
that flows for each SSL aggregation so

277
00:15:52,410 --> 00:15:57,240
for each group of those with the same

278
00:15:55,620 --> 00:15:59,370
source IP destination IP destination

279
00:15:57,240 --> 00:16:02,430
port and protocol we compute the

280
00:15:59,370 --> 00:16:07,110
features actually we had 40 features and

281
00:16:02,430 --> 00:16:09,239
it was mainly about TLS certificate

282
00:16:07,110 --> 00:16:12,510
because you know we want we want to

283
00:16:09,240 --> 00:16:14,190
detect and classify if the connection is

284
00:16:12,510 --> 00:16:16,140
malicious or not because it's the core

285
00:16:14,190 --> 00:16:21,720
of the main of the problem of the

286
00:16:16,140 --> 00:16:25,650
analysis and yeah and we we put some

287
00:16:21,720 --> 00:16:27,840
machine learning algorithms we had there

288
00:16:25,650 --> 00:16:31,949
are no 4sg boosters we end the basic

289
00:16:27,840 --> 00:16:34,710
ones and we got 95% of accuracy we got

290
00:16:31,950 --> 00:16:37,380
also quite high false positive rate and

291
00:16:34,710 --> 00:16:39,810
I get afraid but it's not for real

292
00:16:37,380 --> 00:16:42,180
scenario that you put this detector to

293
00:16:39,810 --> 00:16:45,719
your order and say ok I'm I'm safe

294
00:16:42,180 --> 00:16:49,859
however it's still very good speed-up of

295
00:16:45,720 --> 00:16:52,110
the analysis if 90% of the traffic is

296
00:16:49,860 --> 00:16:54,660
filtered and you just can focus for a

297
00:16:52,110 --> 00:16:58,670
10% of the traffic and say ok I just

298
00:16:54,660 --> 00:17:01,800
want to focus on that however there is

299
00:16:58,670 --> 00:17:04,649
this year we realize really realize the

300
00:17:01,800 --> 00:17:06,599
big problem and it is dilemma point

301
00:17:04,650 --> 00:17:10,080
three the last one point three is not

302
00:17:06,599 --> 00:17:13,189
problem it's a very good protocol from

303
00:17:10,079 --> 00:17:18,419
our point of view and it's very good

304
00:17:13,190 --> 00:17:21,150
thing for users of Internet because he

305
00:17:18,420 --> 00:17:25,110
was fine point free is faster during the

306
00:17:21,150 --> 00:17:26,580
handshake there is there is only if if

307
00:17:25,109 --> 00:17:29,610
we compare Tweety at some point - and

308
00:17:26,579 --> 00:17:33,210
previous version there is only one key

309
00:17:29,610 --> 00:17:37,939
exchange algorithm determined group to

310
00:17:33,210 --> 00:17:41,100
tune to ask server if what supported and

311
00:17:37,940 --> 00:17:42,840
so there is no less negotiating with the

312
00:17:41,100 --> 00:17:47,309
parameters between client and server

313
00:17:42,840 --> 00:17:49,649
so if we can see this picture there is

314
00:17:47,309 --> 00:17:52,730
the difference is 100 milliseconds for

315
00:17:49,649 --> 00:17:56,428
each handshake if we compare the TL son

316
00:17:52,730 --> 00:18:00,899
21.3 so it's a big advantage and also

317
00:17:56,429 --> 00:18:03,749
the example free is safer because no

318
00:18:00,899 --> 00:18:07,289
danger ciphers are used there there is

319
00:18:03,749 --> 00:18:08,220
only that which we know and suppose that

320
00:18:07,289 --> 00:18:11,999
they are safe

321
00:18:08,220 --> 00:18:16,590
so from user point of view TS weapon

322
00:18:11,999 --> 00:18:18,210
free is super good however from us and

323
00:18:16,590 --> 00:18:21,240
from our point of view and this

324
00:18:18,210 --> 00:18:24,090
organization Secretary's ation and

325
00:18:21,240 --> 00:18:27,570
security companies I've supposed that it

326
00:18:24,090 --> 00:18:32,029
can be very bad side because the other

327
00:18:27,570 --> 00:18:37,649
sample free also an create certificate

328
00:18:32,029 --> 00:18:39,809
so we lost most of the features which we

329
00:18:37,649 --> 00:18:41,668
use in the research how I showed in

330
00:18:39,809 --> 00:18:45,119
there was 40 features which we use and

331
00:18:41,669 --> 00:18:46,909
most of them was from a certificate in

332
00:18:45,119 --> 00:18:51,449
this moment with the teal sample free

333
00:18:46,909 --> 00:18:55,440
most of them are encrypt actually hidden

334
00:18:51,450 --> 00:18:57,059
due to encryption so we lost for example

335
00:18:55,440 --> 00:18:59,220
well at length after certificate it

336
00:18:57,059 --> 00:19:02,249
means when the certificate starts and we

337
00:18:59,220 --> 00:19:04,950
expires so it was one of the interesting

338
00:19:02,249 --> 00:19:06,899
- I don't want to say most powerful but

339
00:19:04,950 --> 00:19:10,019
it was very good feature for the

340
00:19:06,899 --> 00:19:13,080
detection or exam then also the Sun

341
00:19:10,019 --> 00:19:15,710
domain so this is this is the example of

342
00:19:13,080 --> 00:19:19,110
our certificate from the avast antivirus

343
00:19:15,710 --> 00:19:20,789
company so this is list of the host

344
00:19:19,110 --> 00:19:24,090
names so we lost this feature as well

345
00:19:20,789 --> 00:19:27,450
and we also lost two certificates ends

346
00:19:24,090 --> 00:19:29,610
so these features and much more this

347
00:19:27,450 --> 00:19:34,139
suppose this is just example we lost

348
00:19:29,610 --> 00:19:38,008
them so we were set we cry my boss cry I

349
00:19:34,139 --> 00:19:40,889
was cry once I cry it was bad so we

350
00:19:38,009 --> 00:19:43,999
didn't know what to do how to continue

351
00:19:40,889 --> 00:19:49,049
to improve the speed of the Alyce's of

352
00:19:43,999 --> 00:19:52,980
people in risk so we had to create new

353
00:19:49,049 --> 00:19:56,040
hypothesis and new hypothesis was ok

354
00:19:52,980 --> 00:20:01,350
let's try to detect or classify

355
00:19:56,040 --> 00:20:05,879
all ssl connections on the our bath only

356
00:20:01,350 --> 00:20:07,980
from TLS TCP layer so no certificate

357
00:20:05,880 --> 00:20:10,860
let's try to focus on live on bytes

358
00:20:07,980 --> 00:20:12,900
packets per D city and so on and write

359
00:20:10,860 --> 00:20:17,040
to the tank SSL connections

360
00:20:12,900 --> 00:20:19,170
SSS SSL molecule detection and also it

361
00:20:17,040 --> 00:20:22,970
means that if we have only these

362
00:20:19,170 --> 00:20:25,650
features which are is quite raw because

363
00:20:22,970 --> 00:20:27,810
if you have number of bytes a number of

364
00:20:25,650 --> 00:20:29,640
packets it's more raw later than its

365
00:20:27,810 --> 00:20:34,409
state of the connections for example

366
00:20:29,640 --> 00:20:35,760
let's try to deep learning so and finish

367
00:20:34,410 --> 00:20:38,160
the game with the image classification

368
00:20:35,760 --> 00:20:41,070
and like which processing

369
00:20:38,160 --> 00:20:45,770
so let's write the deep learning on real

370
00:20:41,070 --> 00:20:49,800
traffic which we use and real problem

371
00:20:45,770 --> 00:20:52,350
the technique of the creating the

372
00:20:49,800 --> 00:20:55,110
samples is the same and also data set is

373
00:20:52,350 --> 00:20:58,590
same on the thing which we have to

374
00:20:55,110 --> 00:21:03,179
realize that this data set is generated

375
00:20:58,590 --> 00:21:06,120
from Windows computers so we still have

376
00:21:03,180 --> 00:21:09,150
we have we still have to in mind that we

377
00:21:06,120 --> 00:21:11,820
try to detect in evpn the mobile traffic

378
00:21:09,150 --> 00:21:14,610
so we don't know if it will work but

379
00:21:11,820 --> 00:21:16,889
let's try it so we still we have a

380
00:21:14,610 --> 00:21:20,040
bigger file the zig program which

381
00:21:16,890 --> 00:21:22,380
creates the flows and again we create a

382
00:21:20,040 --> 00:21:24,870
social aggregation and now there is a

383
00:21:22,380 --> 00:21:26,640
point for features the features in this

384
00:21:24,870 --> 00:21:30,050
for deep learning has to be different

385
00:21:26,640 --> 00:21:34,100
and as I said it should be more raw data

386
00:21:30,050 --> 00:21:37,950
no standard deviation or means and so on

387
00:21:34,100 --> 00:21:40,800
so we define eight these six features

388
00:21:37,950 --> 00:21:43,230
and for each low in this SS of

389
00:21:40,800 --> 00:21:46,020
aggregation we extracted for that for

390
00:21:43,230 --> 00:21:46,590
them so this is the example of SS or

391
00:21:46,020 --> 00:21:51,270
aggregation

392
00:21:46,590 --> 00:21:53,850
it's from IP 10005 to Google for part 4

393
00:21:51,270 --> 00:21:55,980
for free on TCP and we have the first

394
00:21:53,850 --> 00:21:59,669
flow and the flow are sorted by

395
00:21:55,980 --> 00:22:04,140
timestamp so it's by dam and we take

396
00:21:59,670 --> 00:22:06,450
this information from the flow then we

397
00:22:04,140 --> 00:22:08,330
take the second flow and by by the time

398
00:22:06,450 --> 00:22:09,980
and we again we

399
00:22:08,330 --> 00:22:14,449
to the information from the flow and we

400
00:22:09,980 --> 00:22:17,780
did it so we continue and until we put

401
00:22:14,450 --> 00:22:22,730
all information from the from the social

402
00:22:17,780 --> 00:22:27,860
aggregation we are in the convolutional

403
00:22:22,730 --> 00:22:31,790
neural network so we need to have the

404
00:22:27,860 --> 00:22:35,120
size this input size has to be same so

405
00:22:31,790 --> 00:22:37,610
we had to put it with zero and we define

406
00:22:35,120 --> 00:22:41,929
it that the input size to our neural

407
00:22:37,610 --> 00:22:47,350
network will be 250 so at the end each

408
00:22:41,930 --> 00:22:50,270
sample has six sequences of numbers and

409
00:22:47,350 --> 00:22:54,500
these sequences as the input we put

410
00:22:50,270 --> 00:22:57,550
inside the neural network so we the idea

411
00:22:54,500 --> 00:23:00,800
out the beginning was take take the

412
00:22:57,550 --> 00:23:04,340
structure from ResNet narrow Network

413
00:23:00,800 --> 00:23:07,100
which is architecture for image

414
00:23:04,340 --> 00:23:10,459
classification so it's it's not so it's

415
00:23:07,100 --> 00:23:13,730
not exactly same but the idea on the

416
00:23:10,460 --> 00:23:15,140
beginning was from this architecture as

417
00:23:13,730 --> 00:23:18,530
you can see on the beginning we had

418
00:23:15,140 --> 00:23:21,320
these six segments of the numbers and at

419
00:23:18,530 --> 00:23:23,330
the end we classify each sample it means

420
00:23:21,320 --> 00:23:26,800
two 1s or aggregation it's one sample

421
00:23:23,330 --> 00:23:32,510
for us as a normal or malware connection

422
00:23:26,800 --> 00:23:34,430
if there's one links there that in image

423
00:23:32,510 --> 00:23:37,220
classification you have RGB images

424
00:23:34,430 --> 00:23:39,620
mostly and it's a free channels there is

425
00:23:37,220 --> 00:23:42,200
very very similar because we have six

426
00:23:39,620 --> 00:23:44,780
cellos it means that we have six six

427
00:23:42,200 --> 00:23:49,960
sequences of numbers so there is some

428
00:23:44,780 --> 00:23:53,120
similarity it's not different so much

429
00:23:49,960 --> 00:23:56,240
for from our data set we have 80

430
00:23:53,120 --> 00:23:57,739
thousand samples for each class so we

431
00:23:56,240 --> 00:24:00,740
have eighty thousand for malware and

432
00:23:57,740 --> 00:24:03,850
edit eighty thousand for normal and we

433
00:24:00,740 --> 00:24:07,730
split it to normal machine learning way

434
00:24:03,850 --> 00:24:09,830
so in the training part is for train

435
00:24:07,730 --> 00:24:12,440
train the parameter inside the neural

436
00:24:09,830 --> 00:24:16,220
network the validation part is only for

437
00:24:12,440 --> 00:24:19,310
checking if your model is not if your

438
00:24:16,220 --> 00:24:21,200
model doesn't over fit so it's trained

439
00:24:19,310 --> 00:24:21,860
orally only your on your training data

440
00:24:21,200 --> 00:24:23,450
but

441
00:24:21,860 --> 00:24:26,600
under testing and validation doesn't

442
00:24:23,450 --> 00:24:29,450
work and finally when when a promoter

443
00:24:26,600 --> 00:24:33,260
was trained it we we check it on the

444
00:24:29,450 --> 00:24:36,140
testing later which we didn't yet so we

445
00:24:33,260 --> 00:24:38,360
got accuracy nineteen ninety-four

446
00:24:36,140 --> 00:24:39,769
percent false positive right seven

447
00:24:38,360 --> 00:24:42,139
percent left was negative three three

448
00:24:39,769 --> 00:24:44,720
percent in our terminology first

449
00:24:42,140 --> 00:24:47,659
positive rate means that we say okay

450
00:24:44,720 --> 00:24:50,899
this connection is malicious but it's

451
00:24:47,659 --> 00:24:53,600
not true so we we say this in this seven

452
00:24:50,899 --> 00:24:55,699
seven percent and for sneaked up the

453
00:24:53,600 --> 00:24:59,000
phrase is again this we say it's normal

454
00:24:55,700 --> 00:25:01,909
but it's not true so the question is is

455
00:24:59,000 --> 00:25:05,450
it is it is it good enough for real

456
00:25:01,909 --> 00:25:07,100
usage the questions were for me it's

457
00:25:05,450 --> 00:25:09,169
very interesting because if you if you

458
00:25:07,100 --> 00:25:13,840
realize that we took only features from

459
00:25:09,169 --> 00:25:18,409
TCP layer and we were able to classify

460
00:25:13,840 --> 00:25:20,928
TLS connections in accuracy 94 percent

461
00:25:18,409 --> 00:25:25,130
it's interesting at least interesting

462
00:25:20,929 --> 00:25:27,320
but it's still it's not able to use in

463
00:25:25,130 --> 00:25:29,779
the real scenario like in the real life

464
00:25:27,320 --> 00:25:32,418
because it's so much there's so many

465
00:25:29,779 --> 00:25:39,559
false positive samples and false

466
00:25:32,419 --> 00:25:43,250
negative examples so let's take a look

467
00:25:39,559 --> 00:25:48,678
at how we use this with our emergency

468
00:25:43,250 --> 00:25:51,500
VPN now we have a little demo prepared

469
00:25:48,679 --> 00:25:54,529
but we cannot really show you the

470
00:25:51,500 --> 00:25:58,940
traffic of the people that we work with

471
00:25:54,529 --> 00:26:04,340
so we did a simulation basically we took

472
00:25:58,940 --> 00:26:06,860
a phone and we installed basic

473
00:26:04,340 --> 00:26:09,230
applications used it as a normal user

474
00:26:06,860 --> 00:26:12,049
would we connected it to our emergency

475
00:26:09,230 --> 00:26:17,510
VPN where we started to capture the

476
00:26:12,049 --> 00:26:19,399
traffic and then we took a lower sample

477
00:26:17,510 --> 00:26:23,539
and we executed it

478
00:26:19,399 --> 00:26:25,899
so we infected the phone and we were

479
00:26:23,539 --> 00:26:30,770
able to capture the malicious traffic

480
00:26:25,899 --> 00:26:33,168
now with this sample let's see how the

481
00:26:30,770 --> 00:26:35,440
train model that we have how it's gonna

482
00:26:33,169 --> 00:26:35,440
perform

483
00:26:41,380 --> 00:26:54,940
so the script is this is in Python it's

484
00:26:49,480 --> 00:27:00,100
it takes the pcap file uses the Zeke to

485
00:26:54,940 --> 00:27:03,950
extract the features and then flex

486
00:27:00,100 --> 00:27:07,908
connections as malicious so these are

487
00:27:03,950 --> 00:27:12,019
the 13 connections from several hours of

488
00:27:07,909 --> 00:27:15,080
the traffic that were captured and as

489
00:27:12,019 --> 00:27:19,419
you can see there are a lot of false

490
00:27:15,080 --> 00:27:24,949
positives that means the model flagged

491
00:27:19,419 --> 00:27:28,490
connections such as inbox Google as

492
00:27:24,950 --> 00:27:32,350
malicious which when we take a look at

493
00:27:28,490 --> 00:27:36,380
it it's obviously normal benign traffic

494
00:27:32,350 --> 00:27:41,178
but what's interesting is that the

495
00:27:36,380 --> 00:27:45,139
malicious connection that was generated

496
00:27:41,179 --> 00:27:47,269
by the malware is also there it's a

497
00:27:45,139 --> 00:27:52,340
connection to the command and control

498
00:27:47,269 --> 00:27:56,630
server which was which is giving orders

499
00:27:52,340 --> 00:28:01,639
to the malware this is an IP from China

500
00:27:56,630 --> 00:28:04,850
which the malware was using and so from

501
00:28:01,639 --> 00:28:09,830
all the traffic that we see from the

502
00:28:04,850 --> 00:28:12,070
pcap file with this tool in a small

503
00:28:09,830 --> 00:28:15,080
amount of time we can get several

504
00:28:12,070 --> 00:28:19,220
connections that are flagged as

505
00:28:15,080 --> 00:28:22,490
malicious now when we with a couple

506
00:28:19,220 --> 00:28:25,039
other tools we can separate the traffic

507
00:28:22,490 --> 00:28:27,649
that we already know and if we would do

508
00:28:25,039 --> 00:28:29,720
that from all the traffic all that will

509
00:28:27,649 --> 00:28:34,908
be left would be probably three

510
00:28:29,720 --> 00:28:37,519
connections flight as malicious now from

511
00:28:34,909 --> 00:28:40,700
the analysis point of view this is a

512
00:28:37,519 --> 00:28:44,210
real help from the whole traffic there

513
00:28:40,700 --> 00:28:47,510
are several several connections flagged

514
00:28:44,210 --> 00:28:50,390
and basically the model telling me

515
00:28:47,510 --> 00:28:59,390
this is a suspicious behavior take a

516
00:28:50,390 --> 00:29:02,990
look at that so we took 40 captures that

517
00:28:59,390 --> 00:29:07,550
we had to see how this model is gonna

518
00:29:02,990 --> 00:29:11,930
perform on our traffic on the traffic

519
00:29:07,550 --> 00:29:14,870
that was analyzed and we found out that

520
00:29:11,930 --> 00:29:21,200
the model was able to filter out almost

521
00:29:14,870 --> 00:29:25,040
91 percent of the traffic as benign with

522
00:29:21,200 --> 00:29:26,900
the combination of filtering out of the

523
00:29:25,040 --> 00:29:31,040
background traffic of the operating

524
00:29:26,900 --> 00:29:38,000
system the number of 91% would increase

525
00:29:31,040 --> 00:29:42,470
a lot so to conclude what what can we

526
00:29:38,000 --> 00:29:45,080
take away from this we we definitely you

527
00:29:42,470 --> 00:29:48,470
we can definitely use machine learning

528
00:29:45,080 --> 00:29:51,919
to make this whole process of evaluating

529
00:29:48,470 --> 00:29:56,780
and analyzing network traffic much more

530
00:29:51,920 --> 00:30:01,520
effective and faster however it is in no

531
00:29:56,780 --> 00:30:05,600
way prepared to serve as a standalone

532
00:30:01,520 --> 00:30:08,360
detection program because it would from

533
00:30:05,600 --> 00:30:10,639
days of traffic it would still flag a

534
00:30:08,360 --> 00:30:14,659
lot of connections as malicious that are

535
00:30:10,640 --> 00:30:19,190
not but it is a good way to combine with

536
00:30:14,660 --> 00:30:22,190
the manual analysis moreover there are

537
00:30:19,190 --> 00:30:25,280
several exciting ways that we can go

538
00:30:22,190 --> 00:30:28,520
forward to move the numbers and the

539
00:30:25,280 --> 00:30:32,060
accuracy even higher because right now

540
00:30:28,520 --> 00:30:35,600
realize that all the traffic that we had

541
00:30:32,060 --> 00:30:41,659
in the data set the data that we used to

542
00:30:35,600 --> 00:30:44,379
train the model was used to was used

543
00:30:41,660 --> 00:30:48,680
when executing malware on desktops on

544
00:30:44,380 --> 00:30:53,630
Windows machines yeah so and right and

545
00:30:48,680 --> 00:30:57,650
we used it to like detect the behavior

546
00:30:53,630 --> 00:31:00,680
in a mobile phone so there are things

547
00:30:57,650 --> 00:31:04,550
that are gonna vary so

548
00:31:00,680 --> 00:31:06,200
the next thing that is going to drive

549
00:31:04,550 --> 00:31:08,750
this research forward and make the

550
00:31:06,200 --> 00:31:11,750
analysis even more effective is using

551
00:31:08,750 --> 00:31:14,960
the same model but training it with

552
00:31:11,750 --> 00:31:18,800
different data that means creating

553
00:31:14,960 --> 00:31:21,830
several models for each four different

554
00:31:18,800 --> 00:31:31,010
models of the phone operating systems

555
00:31:21,830 --> 00:31:34,669
and protocols so that is how that is

556
00:31:31,010 --> 00:31:38,720
what helps us analyze traffic a little

557
00:31:34,670 --> 00:31:42,200
faster and make this world a better

558
00:31:38,720 --> 00:31:46,190
place at least a little bit so thank you

559
00:31:42,200 --> 00:31:48,230
and thank you for attention and if your

560
00:31:46,190 --> 00:31:50,630
question we will be gone too

561
00:31:48,230 --> 00:31:52,840
actually if you know yeah feel free to

562
00:31:50,630 --> 00:31:52,840
ask

563
00:31:53,460 --> 00:31:59,460
[Applause]

