1
00:00:00,719 --> 00:00:03,780
hi my name's Tom I want to talk to you

2
00:00:03,780 --> 00:00:06,180
about command line data wrangling

3
00:00:06,180 --> 00:00:09,300
or you might say just using the command

4
00:00:09,300 --> 00:00:11,519
line to handle the kinds of data that

5
00:00:11,519 --> 00:00:13,019
you might encounter when you're doing

6
00:00:13,019 --> 00:00:15,780
bug Bounty security work or any other

7
00:00:15,780 --> 00:00:17,400
kind of technical work

8
00:00:17,400 --> 00:00:19,500
and my intention is for this to be a

9
00:00:19,500 --> 00:00:21,619
relatively beginner friendly talk but

10
00:00:21,619 --> 00:00:24,779
hopefully just about anybody can get

11
00:00:24,779 --> 00:00:26,880
something out of it at least

12
00:00:26,880 --> 00:00:29,880
so when you run a command on a unix-like

13
00:00:29,880 --> 00:00:32,279
operating system whether it be Linux or

14
00:00:32,279 --> 00:00:36,899
Mac OS or any actual proper Unix like or

15
00:00:36,899 --> 00:00:38,520
maybe like a FreeBSD variant or

16
00:00:38,520 --> 00:00:40,800
something like that every time you run a

17
00:00:40,800 --> 00:00:43,800
command you get three i o streams or

18
00:00:43,800 --> 00:00:45,899
input output streams for that command

19
00:00:45,899 --> 00:00:49,079
and each one has a name and a number so

20
00:00:49,079 --> 00:00:52,140
stream zero is what we call an input

21
00:00:52,140 --> 00:00:55,379
stream so it's a way to provide data to

22
00:00:55,379 --> 00:00:58,079
the command and by default we get one

23
00:00:58,079 --> 00:01:01,199
called stood in or standard input we

24
00:01:01,199 --> 00:01:03,120
also get stream one which is an output

25
00:01:03,120 --> 00:01:05,519
stream called standard out

26
00:01:05,519 --> 00:01:08,939
and that's where you tend to get the

27
00:01:08,939 --> 00:01:11,040
main output from a command so if you run

28
00:01:11,040 --> 00:01:13,920
LS for example all of the text that's

29
00:01:13,920 --> 00:01:15,420
written to the screen that gives you a

30
00:01:15,420 --> 00:01:17,640
listing of directories and files is

31
00:01:17,640 --> 00:01:19,380
written to standard output

32
00:01:19,380 --> 00:01:21,840
then you get stream two as well and

33
00:01:21,840 --> 00:01:23,700
that's an error stream called standard

34
00:01:23,700 --> 00:01:26,220
error it's another output stream and

35
00:01:26,220 --> 00:01:27,780
that's where error messages and

36
00:01:27,780 --> 00:01:29,580
sometimes help output and that kind of

37
00:01:29,580 --> 00:01:31,979
thing goes by default

38
00:01:31,979 --> 00:01:34,200
now all three of these attached to the

39
00:01:34,200 --> 00:01:36,180
terminal by default and what that means

40
00:01:36,180 --> 00:01:38,939
is for an input stream it's essentially

41
00:01:38,939 --> 00:01:41,640
attached to your keyboard if you run a

42
00:01:41,640 --> 00:01:43,079
command and it tries to read from

43
00:01:43,079 --> 00:01:46,619
standard input it will pause and wait

44
00:01:46,619 --> 00:01:48,420
for you to type things in with your

45
00:01:48,420 --> 00:01:50,220
keyboard

46
00:01:50,220 --> 00:01:51,320
um

47
00:01:51,320 --> 00:01:54,299
for the output streams standard out

48
00:01:54,299 --> 00:01:56,220
standard error being attached to the

49
00:01:56,220 --> 00:01:58,619
terminal means you see the text printed

50
00:01:58,619 --> 00:02:00,180
in your terminal

51
00:02:00,180 --> 00:02:02,820
now those are the defaults but you can

52
00:02:02,820 --> 00:02:04,860
change those defaults so you can attach

53
00:02:04,860 --> 00:02:06,960
one command's standard output to another

54
00:02:06,960 --> 00:02:09,060
command's standard input with a thing

55
00:02:09,060 --> 00:02:13,080
called a pipe uh which looks like this

56
00:02:13,080 --> 00:02:15,060
um I often think this pipe is kind of

57
00:02:15,060 --> 00:02:17,220
almost the wrong way around uh it should

58
00:02:17,220 --> 00:02:20,400
be a horizontal one connecting the one

59
00:02:20,400 --> 00:02:21,840
side of the command to the other but

60
00:02:21,840 --> 00:02:24,360
this is the pipe that we have so here we

61
00:02:24,360 --> 00:02:26,400
attach the standard output of command a

62
00:02:26,400 --> 00:02:28,440
to command B to the standard input of

63
00:02:28,440 --> 00:02:30,420
command B

64
00:02:30,420 --> 00:02:32,220
you can also attach a file to a command

65
00:02:32,220 --> 00:02:35,400
standard input using a less than sign so

66
00:02:35,400 --> 00:02:37,680
what this means is instead of reading

67
00:02:37,680 --> 00:02:39,420
input from the terminal or from another

68
00:02:39,420 --> 00:02:41,940
command the input will be read from a

69
00:02:41,940 --> 00:02:43,800
file instead

70
00:02:43,800 --> 00:02:45,959
you can also do effectively the reverse

71
00:02:45,959 --> 00:02:48,120
and connect connected commands standard

72
00:02:48,120 --> 00:02:50,400
output to a file using a greater than

73
00:02:50,400 --> 00:02:52,980
sign and I call these less than or

74
00:02:52,980 --> 00:02:55,140
greater than but really I think it's

75
00:02:55,140 --> 00:02:56,940
easier to think of these as being arrows

76
00:02:56,940 --> 00:03:01,980
so the file is into this command or this

77
00:03:01,980 --> 00:03:06,738
command output goes into this file

78
00:03:07,019 --> 00:03:10,080
now standard error often stays attached

79
00:03:10,080 --> 00:03:12,239
to the terminal even when you use those

80
00:03:12,239 --> 00:03:14,400
pipes and less than and greater than to

81
00:03:14,400 --> 00:03:16,260
redirect things into files and so on and

82
00:03:16,260 --> 00:03:20,040
so forth but you can change that so here

83
00:03:20,040 --> 00:03:22,739
for example we take a command command a

84
00:03:22,739 --> 00:03:25,200
and we attach stream 2 to the standard

85
00:03:25,200 --> 00:03:28,620
error to stream one and then we use a

86
00:03:28,620 --> 00:03:31,200
pipe to pipe all of standard out into

87
00:03:31,200 --> 00:03:34,800
the standard in of command B this is a

88
00:03:34,800 --> 00:03:37,680
lot to remember but thankfully most

89
00:03:37,680 --> 00:03:41,099
modern shells so zsh and Bash newer than

90
00:03:41,099 --> 00:03:43,560
version four and probably others provide

91
00:03:43,560 --> 00:03:45,120
a little shortcut to this which is the

92
00:03:45,120 --> 00:03:48,080
pipe and then an ampersand to attach

93
00:03:48,080 --> 00:03:51,120
both the standard out and standard error

94
00:03:51,120 --> 00:03:54,480
to the standard input of another command

95
00:03:54,480 --> 00:03:57,019
you can also use the output of a command

96
00:03:57,019 --> 00:04:00,060
in a couple of different ways one of

97
00:04:00,060 --> 00:04:02,580
those is in the place of an argument so

98
00:04:02,580 --> 00:04:06,299
using this dollar and brackets here we

99
00:04:06,299 --> 00:04:09,360
will run command B take that output and

100
00:04:09,360 --> 00:04:11,400
provide it as an argument to command a

101
00:04:11,400 --> 00:04:13,920
as though we typed the output of command

102
00:04:13,920 --> 00:04:15,299
B ourselves

103
00:04:15,299 --> 00:04:19,079
except in this case we don't have to

104
00:04:19,079 --> 00:04:22,500
you can also use this pattern here so a

105
00:04:22,500 --> 00:04:25,440
less than and then brackets with a

106
00:04:25,440 --> 00:04:27,300
command in between to use the output of

107
00:04:27,300 --> 00:04:29,460
a command in place of a file

108
00:04:29,460 --> 00:04:31,919
so here if we pretend command a is

109
00:04:31,919 --> 00:04:34,259
expecting a file to be passed as an

110
00:04:34,259 --> 00:04:36,900
argument to dash F and we don't have a

111
00:04:36,900 --> 00:04:39,240
file but we do have a command that

112
00:04:39,240 --> 00:04:40,620
provides the output we would have wanted

113
00:04:40,620 --> 00:04:43,139
in that file we can use this pattern

114
00:04:43,139 --> 00:04:44,580
instead

115
00:04:44,580 --> 00:04:47,220
now on the last slide we saw you could

116
00:04:47,220 --> 00:04:51,000
use the graded and symbol to send the

117
00:04:51,000 --> 00:04:52,800
output of a command or the standard

118
00:04:52,800 --> 00:04:55,860
output of a command into a file but when

119
00:04:55,860 --> 00:04:57,780
you do that by default it will overwrite

120
00:04:57,780 --> 00:05:00,240
the output file so if this file already

121
00:05:00,240 --> 00:05:04,199
exists and has contents in it when you

122
00:05:04,199 --> 00:05:06,780
run this command it will be overwritten

123
00:05:06,780 --> 00:05:09,000
with the output of this command

124
00:05:09,000 --> 00:05:11,340
okay thankfully though you can use two

125
00:05:11,340 --> 00:05:14,520
of them and instead it will append new

126
00:05:14,520 --> 00:05:18,560
data to this output file instead

127
00:05:18,720 --> 00:05:22,380
one slight downside to that is you don't

128
00:05:22,380 --> 00:05:24,780
get to immediately see the output of

129
00:05:24,780 --> 00:05:26,220
this command when it's written to the

130
00:05:26,220 --> 00:05:29,100
file your terminal will just print the

131
00:05:29,100 --> 00:05:32,759
prompt for you ready to accept a new

132
00:05:32,759 --> 00:05:34,259
command and you don't get to see what's

133
00:05:34,259 --> 00:05:36,360
happened and something that's tripped me

134
00:05:36,360 --> 00:05:38,880
up many times is I've run a command

135
00:05:38,880 --> 00:05:41,460
which is waiting for some input and I

136
00:05:41,460 --> 00:05:43,740
think I'm writing its output to some

137
00:05:43,740 --> 00:05:46,500
file but actually it's just sitting and

138
00:05:46,500 --> 00:05:48,660
doing nothing and I've waited several

139
00:05:48,660 --> 00:05:50,100
minutes for it to finish before I've

140
00:05:50,100 --> 00:05:52,139
realized

141
00:05:52,139 --> 00:05:54,479
um something I use quite often is the T

142
00:05:54,479 --> 00:05:59,520
command to get around this so T splits

143
00:05:59,520 --> 00:06:03,600
the uh it's the data it receives on its

144
00:06:03,600 --> 00:06:07,440
standard input uh between a file and its

145
00:06:07,440 --> 00:06:08,820
standard output

146
00:06:08,820 --> 00:06:11,039
so the effect of this has is the output

147
00:06:11,039 --> 00:06:12,780
from command will be written to our

148
00:06:12,780 --> 00:06:15,180
output file but it will also be printed

149
00:06:15,180 --> 00:06:16,199
to the screen

150
00:06:16,199 --> 00:06:18,780
and just like the double greater than

151
00:06:18,780 --> 00:06:21,120
symbol we have an equivalent with t Dash

152
00:06:21,120 --> 00:06:24,000
a if we'd prefer to append the output to

153
00:06:24,000 --> 00:06:25,979
the file rather than overwriting the

154
00:06:25,979 --> 00:06:27,600
file

155
00:06:27,600 --> 00:06:29,780
foreign

156
00:06:30,199 --> 00:06:33,780
tools I would argue most tools that you

157
00:06:33,780 --> 00:06:36,180
will encounter on a unixplex system I'll

158
00:06:36,180 --> 00:06:39,360
put plain text so when you run LS for

159
00:06:39,360 --> 00:06:43,139
example you get a list of files and

160
00:06:43,139 --> 00:06:46,020
there's no real uh

161
00:06:46,020 --> 00:06:48,419
structure to them it's just plain old

162
00:06:48,419 --> 00:06:49,680
text

163
00:06:49,680 --> 00:06:52,080
often the output commands will be one

164
00:06:52,080 --> 00:06:54,660
item per the line and sometimes there's

165
00:06:54,660 --> 00:06:57,840
more than one field per line so you

166
00:06:57,840 --> 00:06:59,880
might have say three words on each line

167
00:06:59,880 --> 00:07:02,280
separated by some white space be they

168
00:07:02,280 --> 00:07:05,660
spaces or perhaps their tabs

169
00:07:05,660 --> 00:07:09,180
uh you can extract or exclude lines from

170
00:07:09,180 --> 00:07:12,600
that output easily using the grep tool

171
00:07:12,600 --> 00:07:15,720
so for example to extract a line that

172
00:07:15,720 --> 00:07:17,639
matches some particular pattern from a

173
00:07:17,639 --> 00:07:20,699
command you can use grep pattern with a

174
00:07:20,699 --> 00:07:22,500
pipe joining the command

175
00:07:22,500 --> 00:07:25,199
output into the input grip and to

176
00:07:25,199 --> 00:07:27,360
exclude you do almost exactly the same

177
00:07:27,360 --> 00:07:29,240
with the dash V

178
00:07:29,240 --> 00:07:32,039
and the mnemonic for me there is the V

179
00:07:32,039 --> 00:07:35,099
is the V invert it inverts the behavior

180
00:07:35,099 --> 00:07:37,080
of grip

181
00:07:37,080 --> 00:07:39,180
to extract fields from lines of text

182
00:07:39,180 --> 00:07:42,000
though I recommend you use the orc tool

183
00:07:42,000 --> 00:07:44,160
orc is actually a fully fetched

184
00:07:44,160 --> 00:07:46,500
programming language and is incredibly

185
00:07:46,500 --> 00:07:49,620
powerful so I'm I'm using it for an

186
00:07:49,620 --> 00:07:52,319
incredibly simple purpose here but we

187
00:07:52,319 --> 00:07:54,120
might want to for example extract the

188
00:07:54,120 --> 00:07:56,580
Third Field from each line in the output

189
00:07:56,580 --> 00:07:59,580
of a command and for that we use ook and

190
00:07:59,580 --> 00:08:01,319
we give it a little awk program to run

191
00:08:01,319 --> 00:08:04,919
it's between curly braces and here we

192
00:08:04,919 --> 00:08:06,979
say we want to print a dollar three

193
00:08:06,979 --> 00:08:09,539
which is aux

194
00:08:09,539 --> 00:08:12,960
way to represent the Third Field in each

195
00:08:12,960 --> 00:08:13,860
line

196
00:08:13,860 --> 00:08:15,539
we might also want to extract instead

197
00:08:15,539 --> 00:08:18,000
the last field this is quite useful if

198
00:08:18,000 --> 00:08:19,680
we don't know how many fields there are

199
00:08:19,680 --> 00:08:21,660
or if there's a variable number of

200
00:08:21,660 --> 00:08:24,660
fields per line so dollar NF or I

201
00:08:24,660 --> 00:08:26,160
believe the NF stands for a number of

202
00:08:26,160 --> 00:08:27,780
fields

203
00:08:27,780 --> 00:08:31,319
we'll print the last field in each line

204
00:08:31,319 --> 00:08:34,440
we can also modify the line as well so

205
00:08:34,440 --> 00:08:37,320
here for example we might set the fifth

206
00:08:37,320 --> 00:08:39,419
element in a line to be an empty string

207
00:08:39,419 --> 00:08:42,299
and then print dollar zero so dollar

208
00:08:42,299 --> 00:08:44,760
zero is the variable that represents the

209
00:08:44,760 --> 00:08:47,339
entire line but in this case the fifth

210
00:08:47,339 --> 00:08:49,320
field will have been removed

211
00:08:49,320 --> 00:08:52,920
now you can use cut to extract Fields as

212
00:08:52,920 --> 00:08:54,660
well and you might be more familiar with

213
00:08:54,660 --> 00:08:56,040
that tool

214
00:08:56,040 --> 00:08:58,320
um but I use Orc in these situations

215
00:08:58,320 --> 00:09:00,839
primarily because cut doesn't handle

216
00:09:00,839 --> 00:09:03,680
mixed white space as well as orc does

217
00:09:03,680 --> 00:09:07,019
you really have to jump through some

218
00:09:07,019 --> 00:09:09,240
hoops to make it work well if some

219
00:09:09,240 --> 00:09:11,399
fields are separated by spaces and some

220
00:09:11,399 --> 00:09:14,040
by tabs or a variable number of spaces

221
00:09:14,040 --> 00:09:17,420
and so on and so forth

222
00:09:17,519 --> 00:09:19,740
so when you are dealing with plain text

223
00:09:19,740 --> 00:09:22,440
it's really common to have Files full of

224
00:09:22,440 --> 00:09:24,120
duplicate lines so there might be

225
00:09:24,120 --> 00:09:27,480
domains or URLs or IPS or something like

226
00:09:27,480 --> 00:09:30,720
that right so a common task in uh

227
00:09:30,720 --> 00:09:34,140
wrangling raw data into usable data is

228
00:09:34,140 --> 00:09:35,820
to remove duplicates and there's a few

229
00:09:35,820 --> 00:09:38,279
ways you can do that one way is using

230
00:09:38,279 --> 00:09:39,600
the sort command

231
00:09:39,600 --> 00:09:43,019
so here we pipe a command into sort Dash

232
00:09:43,019 --> 00:09:45,480
U and the U is for unique and that will

233
00:09:45,480 --> 00:09:48,300
remove duplicates but it also has the

234
00:09:48,300 --> 00:09:51,420
side effect of sorting the output and

235
00:09:51,420 --> 00:09:52,920
you might not want to do that you might

236
00:09:52,920 --> 00:09:56,820
have a very specific order in mind so I

237
00:09:56,820 --> 00:09:58,980
wrote a little tool called a new and

238
00:09:58,980 --> 00:10:00,660
there's a link down here in the right

239
00:10:00,660 --> 00:10:02,459
bottom right hand corner should you want

240
00:10:02,459 --> 00:10:04,800
to have a look which will remove

241
00:10:04,800 --> 00:10:07,860
duplicates but whilst preserving the

242
00:10:07,860 --> 00:10:10,019
order of the input

243
00:10:10,019 --> 00:10:13,500
uh it'll also allow you to write unique

244
00:10:13,500 --> 00:10:16,200
lines to a file by giving it a file name

245
00:10:16,200 --> 00:10:20,040
as an argument so here if any line that

246
00:10:20,040 --> 00:10:21,839
is in the output from the command

247
00:10:21,839 --> 00:10:25,500
already exists in output file it will

248
00:10:25,500 --> 00:10:27,720
not be written to that file and it will

249
00:10:27,720 --> 00:10:30,120
be not written to the terminal either

250
00:10:30,120 --> 00:10:32,420
so that's a really useful way to use

251
00:10:32,420 --> 00:10:35,220
plain text files that's essentially sort

252
00:10:35,220 --> 00:10:38,399
of almost I I'm hesitant to use the term

253
00:10:38,399 --> 00:10:42,360
databases much simpler than that but as

254
00:10:42,360 --> 00:10:45,019
storage containers for domains

255
00:10:45,019 --> 00:10:47,700
subdomains IPS those kinds of things but

256
00:10:47,700 --> 00:10:49,440
you only really want to store each thing

257
00:10:49,440 --> 00:10:52,040
once

258
00:10:52,140 --> 00:10:53,040
um

259
00:10:53,040 --> 00:10:55,760
another really common trick uh when

260
00:10:55,760 --> 00:10:58,440
taking raw data and making it into

261
00:10:58,440 --> 00:11:00,120
something usable especially when you're

262
00:11:00,120 --> 00:11:01,680
working with word lists and things like

263
00:11:01,680 --> 00:11:04,680
that is to sort things by frequency

264
00:11:04,680 --> 00:11:06,839
um and there's a couple of ways you

265
00:11:06,839 --> 00:11:09,899
might do that one of which is one that

266
00:11:09,899 --> 00:11:12,360
preserves the counts for each thing so

267
00:11:12,360 --> 00:11:13,980
if you want to know exactly how many

268
00:11:13,980 --> 00:11:17,940
times each thing occurred in the output

269
00:11:17,940 --> 00:11:20,220
um we'll take a command and we'll pipe

270
00:11:20,220 --> 00:11:23,760
to sort which sorts the output and that

271
00:11:23,760 --> 00:11:26,339
really is only a prerequisite to Unique

272
00:11:26,339 --> 00:11:28,459
which requires that its input be sorted

273
00:11:28,459 --> 00:11:31,880
unique with the dash C flag

274
00:11:31,880 --> 00:11:33,720
prints a

275
00:11:33,720 --> 00:11:38,760
count of each unique line in its input

276
00:11:38,760 --> 00:11:41,399
we then pack back to sort with dash n

277
00:11:41,399 --> 00:11:43,740
for numeric because we have now account

278
00:11:43,740 --> 00:11:47,579
preceding each line and reverse and that

279
00:11:47,579 --> 00:11:50,040
means that the largest count will come

280
00:11:50,040 --> 00:11:51,180
first

281
00:11:51,180 --> 00:11:53,220
we might also want to remove those

282
00:11:53,220 --> 00:11:54,660
counts so that we end up with something

283
00:11:54,660 --> 00:11:57,540
sorted by frequency and an easy way to

284
00:11:57,540 --> 00:11:59,579
do that is just to tuck an awk command

285
00:11:59,579 --> 00:12:02,100
on here like we saw in a previous slide

286
00:12:02,100 --> 00:12:04,040
to print the last field

287
00:12:04,040 --> 00:12:06,779
in the output and that will remove the

288
00:12:06,779 --> 00:12:10,579
counts which appear in the first field

289
00:12:10,820 --> 00:12:13,920
now regular expressions are something

290
00:12:13,920 --> 00:12:16,800
that crop up a lot in these tools and

291
00:12:16,800 --> 00:12:18,300
several of the tools that we're going to

292
00:12:18,300 --> 00:12:19,920
talk about and indeed have talked about

293
00:12:19,920 --> 00:12:23,399
already make use of regular expressions

294
00:12:23,399 --> 00:12:25,079
now they're often fact it is something

295
00:12:25,079 --> 00:12:26,940
that a lot of people really don't

296
00:12:26,940 --> 00:12:30,019
understand uh and

297
00:12:30,019 --> 00:12:33,779
giving a really good tutorial on regular

298
00:12:33,779 --> 00:12:35,579
Expressions is something way outside the

299
00:12:35,579 --> 00:12:37,740
scope of this talk and perhaps you could

300
00:12:37,740 --> 00:12:40,380
argue with any single talk but I want to

301
00:12:40,380 --> 00:12:42,060
give you a flavor of the kinds of things

302
00:12:42,060 --> 00:12:44,220
you can do with regular expressions

303
00:12:44,220 --> 00:12:46,920
uh they used to match extract and

304
00:12:46,920 --> 00:12:51,120
replace pieces of text primarily along I

305
00:12:51,120 --> 00:12:53,700
said there is a lot to learn but here's

306
00:12:53,700 --> 00:12:55,740
a few basic things so in a regular

307
00:12:55,740 --> 00:12:56,700
expression

308
00:12:56,700 --> 00:12:59,339
a DOT matches any character any

309
00:12:59,339 --> 00:13:02,700
character at all could be an A or a b a

310
00:13:02,700 --> 00:13:04,740
seven or an ampersand or a percent sign

311
00:13:04,740 --> 00:13:07,260
it doesn't matter what it is a DOT

312
00:13:07,260 --> 00:13:08,339
matches it

313
00:13:08,339 --> 00:13:10,260
you also get these things called classes

314
00:13:10,260 --> 00:13:12,480
and classes are surrounded by square

315
00:13:12,480 --> 00:13:16,800
braces and they contain either ranges so

316
00:13:16,800 --> 00:13:20,279
for example A to Z or not to nine would

317
00:13:20,279 --> 00:13:22,620
include any character between a to z or

318
00:13:22,620 --> 00:13:25,800
any number between 0 to 9. you can have

319
00:13:25,800 --> 00:13:28,019
compound ranges as well so here we have

320
00:13:28,019 --> 00:13:30,899
notodyne a to z uppercase and lowercase

321
00:13:30,899 --> 00:13:33,240
but also individual characters so here

322
00:13:33,240 --> 00:13:36,240
an underscore and a slash as an example

323
00:13:36,240 --> 00:13:38,760
there are also negated classes

324
00:13:38,760 --> 00:13:41,760
so here for example we would match any

325
00:13:41,760 --> 00:13:44,279
character that is not in the range A to

326
00:13:44,279 --> 00:13:46,980
Z lowercase or not in the range not the

327
00:13:46,980 --> 00:13:49,279
nine

328
00:13:51,060 --> 00:13:53,339
then we have a few options for

329
00:13:53,339 --> 00:13:56,220
specifying how many characters will

330
00:13:56,220 --> 00:13:58,620
appear so this could be preceding a DOT

331
00:13:58,620 --> 00:14:01,320
or a character class or any of the other

332
00:14:01,320 --> 00:14:04,680
kinds of patterns uh so we have 0 1

333
00:14:04,680 --> 00:14:07,260
which is a question mark an asterisk for

334
00:14:07,260 --> 00:14:10,380
zero or more a plus for one or more uh

335
00:14:10,380 --> 00:14:12,420
we then we have these curly brace

336
00:14:12,420 --> 00:14:16,500
wrapped uh ranges so for example two to

337
00:14:16,500 --> 00:14:19,940
seven so we might have a DOT followed by

338
00:14:19,940 --> 00:14:22,920
uh this curly brace is two to seven and

339
00:14:22,920 --> 00:14:25,800
that would match any pair of characters

340
00:14:25,800 --> 00:14:28,380
any three characters any four five six

341
00:14:28,380 --> 00:14:30,720
or seven characters

342
00:14:30,720 --> 00:14:33,180
we can also omit the second option in

343
00:14:33,180 --> 00:14:36,120
this range to just have a minimum number

344
00:14:36,120 --> 00:14:38,399
so for example at least three things

345
00:14:38,399 --> 00:14:40,079
have to match

346
00:14:40,079 --> 00:14:41,820
we can group

347
00:14:41,820 --> 00:14:44,040
parts of patterns and use pipes in

348
00:14:44,040 --> 00:14:48,019
between them to match entire words

349
00:14:48,019 --> 00:14:50,820
and only one of those

350
00:14:50,820 --> 00:14:53,639
which is quite useful and also we have

351
00:14:53,639 --> 00:14:55,260
these things called anchors

352
00:14:55,260 --> 00:14:58,079
so a carrot character when it's not

353
00:14:58,079 --> 00:15:00,660
inside a class represents the start of a

354
00:15:00,660 --> 00:15:02,820
line and a dollar represents the end of

355
00:15:02,820 --> 00:15:05,160
the line and we'll see a few examples of

356
00:15:05,160 --> 00:15:09,620
these things used in the coming slides

357
00:15:10,199 --> 00:15:12,380
so grep we've mentioned already

358
00:15:12,380 --> 00:15:14,459
what I want to give you a few more

359
00:15:14,459 --> 00:15:16,199
examples of the kinds of things it can

360
00:15:16,199 --> 00:15:17,040
do

361
00:15:17,040 --> 00:15:19,139
so grep works on its standard input by

362
00:15:19,139 --> 00:15:22,560
default and outputs any matching line so

363
00:15:22,560 --> 00:15:25,139
you might for example have a file full

364
00:15:25,139 --> 00:15:28,440
of domains and subdomains and you want

365
00:15:28,440 --> 00:15:32,639
to find only subdomains of example.com

366
00:15:32,639 --> 00:15:35,100
so here we pipe the output to grep

367
00:15:35,100 --> 00:15:38,579
and we have a pattern I want to point a

368
00:15:38,579 --> 00:15:40,440
couple of things out here so you'll

369
00:15:40,440 --> 00:15:42,180
remember that we mentioned that a dot in

370
00:15:42,180 --> 00:15:43,980
a regular expression matches any

371
00:15:43,980 --> 00:15:46,800
character but here we want an actual

372
00:15:46,800 --> 00:15:49,740
literal dot so we use a backslash to

373
00:15:49,740 --> 00:15:52,199
escape the dot and make sure that grep

374
00:15:52,199 --> 00:15:54,600
knows we don't mean any character we

375
00:15:54,600 --> 00:15:57,180
mean an actual Dot

376
00:15:57,180 --> 00:15:59,279
we also have a dollar here and this

377
00:15:59,279 --> 00:16:01,560
dollar represents the end of the line

378
00:16:01,560 --> 00:16:03,360
and that means that we won't match

379
00:16:03,360 --> 00:16:05,940
against for example

380
00:16:05,940 --> 00:16:09,959
um a domain that is blog.example.com.au

381
00:16:13,260 --> 00:16:15,839
the dash o flag is actually really

382
00:16:15,839 --> 00:16:17,760
useful for when we don't want to Output

383
00:16:17,760 --> 00:16:20,279
the whole line that matches but only the

384
00:16:20,279 --> 00:16:23,220
specific part that matches the pattern

385
00:16:23,220 --> 00:16:25,260
and this is especially useful when in

386
00:16:25,260 --> 00:16:27,000
combination used in combination with

387
00:16:27,000 --> 00:16:29,519
more complicated regular expressions and

388
00:16:29,519 --> 00:16:31,019
in order to use those more complicated

389
00:16:31,019 --> 00:16:33,060
regular Expressions we need to use the

390
00:16:33,060 --> 00:16:36,779
dash Big E flag for extended regular

391
00:16:36,779 --> 00:16:40,259
Expressions so here for example we have

392
00:16:40,259 --> 00:16:43,620
our same text file full of domains we

393
00:16:43,620 --> 00:16:45,839
might want to extract all of the tlds

394
00:16:45,839 --> 00:16:48,060
from those so we use grep with the O

395
00:16:48,060 --> 00:16:51,300
flag to say only output the part of each

396
00:16:51,300 --> 00:16:53,160
line which matches the pattern that has

397
00:16:53,160 --> 00:16:56,880
been provided we use capital E for

398
00:16:56,880 --> 00:16:58,980
extended regular expressions

399
00:16:58,980 --> 00:17:00,959
and then we say we want to find a

400
00:17:00,959 --> 00:17:04,439
literal Dot followed by one or more

401
00:17:04,439 --> 00:17:06,299
characters which are in the range

402
00:17:06,299 --> 00:17:08,939
lowercase A to Z and uppercase A to Z

403
00:17:08,939 --> 00:17:13,520
that appears at the end of the line

404
00:17:13,559 --> 00:17:15,559
if we have a directory full of files

405
00:17:15,559 --> 00:17:18,299
rather than wanting to search the

406
00:17:18,299 --> 00:17:20,819
content of just one file or the output

407
00:17:20,819 --> 00:17:22,799
of one command we can use the dash R

408
00:17:22,799 --> 00:17:25,619
flag to search recursively through the

409
00:17:25,619 --> 00:17:27,780
current directory structure

410
00:17:27,780 --> 00:17:30,540
so for example if we want to look for uh

411
00:17:30,540 --> 00:17:34,260
gcp keys in a bunch of files in our

412
00:17:34,260 --> 00:17:36,299
current directory we might run the grep

413
00:17:36,299 --> 00:17:39,299
command with r for recursive and E for

414
00:17:39,299 --> 00:17:42,419
extended regular Expressions a matched

415
00:17:42,419 --> 00:17:46,820
the known prefix for gcp Keys a i z a

416
00:17:46,820 --> 00:17:50,640
followed by one or more of

417
00:17:50,640 --> 00:17:52,559
the characters in The Range A to Z

418
00:17:52,559 --> 00:17:55,260
lowercase and uppercase and numbers and

419
00:17:55,260 --> 00:17:57,780
dashes and I think possibly there should

420
00:17:57,780 --> 00:18:00,539
be underscores as well in there but uh I

421
00:18:00,539 --> 00:18:02,160
seem to have forgotten those

422
00:18:02,160 --> 00:18:05,280
and we have an asterisk here to say that

423
00:18:05,280 --> 00:18:07,860
we want to look for in all files in the

424
00:18:07,860 --> 00:18:09,720
current directory

425
00:18:09,720 --> 00:18:11,460
as we mentioned before you can exclude

426
00:18:11,460 --> 00:18:13,919
lines with Dash fee but you can also be

427
00:18:13,919 --> 00:18:16,620
case insensitive with Dash I so here for

428
00:18:16,620 --> 00:18:19,200
example we might want to exclude any

429
00:18:19,200 --> 00:18:22,500
domain that mentions the word blog in

430
00:18:22,500 --> 00:18:25,080
uppercase lowercase or any kind of mixed

431
00:18:25,080 --> 00:18:27,900
case in this file

432
00:18:27,900 --> 00:18:29,760
one thing that we've done a couple of

433
00:18:29,760 --> 00:18:31,740
times in this slide already that I want

434
00:18:31,740 --> 00:18:33,660
to draw attention to is many tools let

435
00:18:33,660 --> 00:18:36,299
you combine these flags together so

436
00:18:36,299 --> 00:18:39,240
instead of having Dash V and dash I we

437
00:18:39,240 --> 00:18:41,940
can just do VI that's not true for every

438
00:18:41,940 --> 00:18:45,600
tool but it's true for lots of them

439
00:18:45,600 --> 00:18:48,059
um these regular Expressions can get

440
00:18:48,059 --> 00:18:50,340
quite complicated and you may find

441
00:18:50,340 --> 00:18:52,500
yourself using the same ones over and

442
00:18:52,500 --> 00:18:55,140
over and over again and I wrote a tool

443
00:18:55,140 --> 00:18:56,820
to help deal with that situation called

444
00:18:56,820 --> 00:19:00,840
GF a shot for grep 4 and you might want

445
00:19:00,840 --> 00:19:02,640
to check it out if you find yourself

446
00:19:02,640 --> 00:19:06,500
using grep very often

447
00:19:07,980 --> 00:19:09,840
sometimes you want to actually change

448
00:19:09,840 --> 00:19:12,559
what appears on a line

449
00:19:12,559 --> 00:19:15,900
and said is a great tool for doing that

450
00:19:15,900 --> 00:19:17,580
so where grep we used regular

451
00:19:17,580 --> 00:19:21,299
Expressions to Simply match things said

452
00:19:21,299 --> 00:19:23,340
let's just use them to match and replace

453
00:19:23,340 --> 00:19:26,039
against regular expressions

454
00:19:26,039 --> 00:19:28,260
so the most basic usage is we take the

455
00:19:28,260 --> 00:19:29,780
output of some command

456
00:19:29,780 --> 00:19:34,100
we invoke said and tell it to replace

457
00:19:34,100 --> 00:19:36,240
some search pattern with some

458
00:19:36,240 --> 00:19:37,380
replacement

459
00:19:37,380 --> 00:19:40,160
and one thing I want to point out is

460
00:19:40,160 --> 00:19:42,840
often you find yourself using said

461
00:19:42,840 --> 00:19:45,020
against things that have slashes in them

462
00:19:45,020 --> 00:19:48,539
like file paths or URLs and things like

463
00:19:48,539 --> 00:19:50,100
that for example and in those

464
00:19:50,100 --> 00:19:52,260
circumstances you can replace these

465
00:19:52,260 --> 00:19:54,780
slashes with something else so here I

466
00:19:54,780 --> 00:19:57,299
use a hash as an example some people use

467
00:19:57,299 --> 00:19:59,820
pipes and so on and so forth but you can

468
00:19:59,820 --> 00:20:01,799
change what that is depending on what

469
00:20:01,799 --> 00:20:04,260
the data you're working with looks like

470
00:20:04,260 --> 00:20:06,620
so as an example using our same

471
00:20:06,620 --> 00:20:10,559
domains.txt we might want to change.com

472
00:20:10,559 --> 00:20:12,840
tlds2.net

473
00:20:12,840 --> 00:20:15,059
so here we have a regular expression

474
00:20:15,059 --> 00:20:19,080
which looks for a literal Dot and com at

475
00:20:19,080 --> 00:20:20,820
the end of the line again we don't want

476
00:20:20,820 --> 00:20:23,820
to accidentally replace Dot com.eu

477
00:20:23,820 --> 00:20:25,919
with.net

478
00:20:25,919 --> 00:20:27,780
note that I don't have to escape the dot

479
00:20:27,780 --> 00:20:30,120
here because the replacement is not a

480
00:20:30,120 --> 00:20:33,240
regular expression it's just regular

481
00:20:33,240 --> 00:20:36,120
text for the most part

482
00:20:36,120 --> 00:20:38,640
uh you might also want to for example

483
00:20:38,640 --> 00:20:41,220
take a list of URLs and replace some

484
00:20:41,220 --> 00:20:44,100
query string values with payloads

485
00:20:44,100 --> 00:20:46,500
so here our regular expression looks for

486
00:20:46,500 --> 00:20:48,179
an equal sign

487
00:20:48,179 --> 00:20:50,580
and then looks for one or more

488
00:20:50,580 --> 00:20:54,000
characters which are not an ampersand as

489
00:20:54,000 --> 00:20:57,780
you may recall uh URL query string

490
00:20:57,780 --> 00:21:00,240
parameters are delimited by ampersands

491
00:21:00,240 --> 00:21:02,880
so here we're saying we want to read any

492
00:21:02,880 --> 00:21:05,760
characters until we hit an ampersand and

493
00:21:05,760 --> 00:21:08,520
we replace that with equals and here

494
00:21:08,520 --> 00:21:10,799
sort of a standard cross-site scripting

495
00:21:10,799 --> 00:21:13,320
payload just as an example

496
00:21:13,320 --> 00:21:15,419
a pretty common use case when doing

497
00:21:15,419 --> 00:21:18,059
Replacements is to want to use part of

498
00:21:18,059 --> 00:21:20,000
the thing you matched in the replacement

499
00:21:20,000 --> 00:21:22,440
and we have a facility to do that

500
00:21:22,440 --> 00:21:25,140
they're called back references and they

501
00:21:25,140 --> 00:21:27,120
look like this slash one backslash two

502
00:21:27,120 --> 00:21:29,940
backslash three and so on so as an

503
00:21:29,940 --> 00:21:33,000
example we might take an HTML file and

504
00:21:33,000 --> 00:21:35,700
we want to remove quotes around a

505
00:21:35,700 --> 00:21:38,100
particular attribute so I've chosen a

506
00:21:38,100 --> 00:21:39,539
type attribute here

507
00:21:39,539 --> 00:21:42,299
so we're looking for type equals and a

508
00:21:42,299 --> 00:21:44,820
double quote and then we are using

509
00:21:44,820 --> 00:21:47,340
brackets to group a pattern which

510
00:21:47,340 --> 00:21:49,980
matches one or more characters which are

511
00:21:49,980 --> 00:21:52,860
not double quotes

512
00:21:52,860 --> 00:21:55,200
followed by a double quote and we

513
00:21:55,200 --> 00:21:57,480
replace that with type equals backslash

514
00:21:57,480 --> 00:22:00,419
one and the backslash one here refers to

515
00:22:00,419 --> 00:22:03,120
everything that was matched by this

516
00:22:03,120 --> 00:22:04,620
particular part of the pattern

517
00:22:04,620 --> 00:22:05,940
everything between the brackets

518
00:22:05,940 --> 00:22:09,179
everything in group number one

519
00:22:09,179 --> 00:22:10,679
something that trips people up quite

520
00:22:10,679 --> 00:22:12,419
often using said

521
00:22:12,419 --> 00:22:15,900
is that by default it will only

522
00:22:15,900 --> 00:22:18,539
replace the first item that was matched

523
00:22:18,539 --> 00:22:22,020
in a given line so here if we Echo Tim

524
00:22:22,020 --> 00:22:24,840
nim nim into said and tell it we want to

525
00:22:24,840 --> 00:22:28,320
replace I with o the output will be

526
00:22:28,320 --> 00:22:31,860
perhaps surprisingly to some Tom nimnim

527
00:22:31,860 --> 00:22:33,360
which is uh

528
00:22:33,360 --> 00:22:35,220
well it's not right it doesn't sound

529
00:22:35,220 --> 00:22:37,919
quite right but we can change that by

530
00:22:37,919 --> 00:22:40,380
adding a g to the end here the G stands

531
00:22:40,380 --> 00:22:43,080
for Global to make sure that we replace

532
00:22:43,080 --> 00:22:45,960
all instances in this case our output

533
00:22:45,960 --> 00:22:48,120
would be Tom Nom Nom because we replace

534
00:22:48,120 --> 00:22:51,799
all three eyes with those

535
00:22:51,900 --> 00:22:53,760
another useful thing is you can use the

536
00:22:53,760 --> 00:22:55,620
anchors that we mentioned earlier on the

537
00:22:55,620 --> 00:22:57,419
carrot and the dollar to match the start

538
00:22:57,419 --> 00:23:00,539
and end of lines so for example we might

539
00:23:00,539 --> 00:23:02,280
want to remove the first character of

540
00:23:02,280 --> 00:23:04,799
each line and we can do that by matching

541
00:23:04,799 --> 00:23:07,140
the start of the line followed by any

542
00:23:07,140 --> 00:23:08,820
character and having an empty

543
00:23:08,820 --> 00:23:09,960
replacement

544
00:23:09,960 --> 00:23:13,140
or we might for example especially uh

545
00:23:13,140 --> 00:23:15,840
common in data that has been pasted from

546
00:23:15,840 --> 00:23:18,240
web pages and so on remove extraneous

547
00:23:18,240 --> 00:23:20,280
white space from the end of each line

548
00:23:20,280 --> 00:23:22,620
and we can do that by looking for a

549
00:23:22,620 --> 00:23:24,539
space character or one or more space

550
00:23:24,539 --> 00:23:27,000
characters at the end of the line and

551
00:23:27,000 --> 00:23:29,960
replacing them with nothing

552
00:23:32,580 --> 00:23:36,120
data is usually stored in files or maybe

553
00:23:36,120 --> 00:23:37,860
it's transient and it comes from

554
00:23:37,860 --> 00:23:40,679
commands but also there's data that's

555
00:23:40,679 --> 00:23:42,419
effectively

556
00:23:42,419 --> 00:23:45,659
not in the files but is in the metadata

557
00:23:45,659 --> 00:23:48,000
for those files things like the file

558
00:23:48,000 --> 00:23:52,020
name all the file location and so on

559
00:23:52,020 --> 00:23:54,419
but also you know if the data is in the

560
00:23:54,419 --> 00:23:57,419
files itself you often need to find them

561
00:23:57,419 --> 00:23:59,820
and look for particular types of files

562
00:23:59,820 --> 00:24:01,919
and the find command is incredibly

563
00:24:01,919 --> 00:24:04,980
useful for that I would argue it's

564
00:24:04,980 --> 00:24:08,340
possibly badly named it can be used to

565
00:24:08,340 --> 00:24:09,900
find things but what it really does is

566
00:24:09,900 --> 00:24:12,900
it lists files recursively from the

567
00:24:12,900 --> 00:24:15,120
profile provided directory

568
00:24:15,120 --> 00:24:18,360
and applies filters to them and those

569
00:24:18,360 --> 00:24:20,340
filters change which files you will see

570
00:24:20,340 --> 00:24:22,880
so you might filter by for example type

571
00:24:22,880 --> 00:24:25,679
and look for just files so this is

572
00:24:25,679 --> 00:24:27,000
defined

573
00:24:27,000 --> 00:24:29,039
files in the current directory which is

574
00:24:29,039 --> 00:24:33,059
dot uh I have a type of f so type f

575
00:24:33,059 --> 00:24:35,340
means files or you might look for

576
00:24:35,340 --> 00:24:38,039
directories in slash Etc that's with

577
00:24:38,039 --> 00:24:39,600
type D

578
00:24:39,600 --> 00:24:42,000
you can filter by name as well so we

579
00:24:42,000 --> 00:24:43,980
might for example look for files that

580
00:24:43,980 --> 00:24:45,780
end with txt

581
00:24:45,780 --> 00:24:47,280
so we'll look

582
00:24:47,280 --> 00:24:50,700
in the current directory for type files

583
00:24:50,700 --> 00:24:53,760
with the name of star.txt

584
00:24:53,760 --> 00:24:55,980
and note that I've wrapped this star.txt

585
00:24:55,980 --> 00:24:58,740
in single quotes and that is to prevent

586
00:24:58,740 --> 00:25:00,780
the shell from expanding this pattern

587
00:25:00,780 --> 00:25:03,299
itself if there's any files in the

588
00:25:03,299 --> 00:25:04,880
current directory

589
00:25:04,880 --> 00:25:09,179
that happen to be named something.txt by

590
00:25:09,179 --> 00:25:12,000
default many shells will expand that to

591
00:25:12,000 --> 00:25:13,500
the actual file names and things won't

592
00:25:13,500 --> 00:25:15,659
work quite the way you expect

593
00:25:15,659 --> 00:25:18,000
or we might look for anything at all

594
00:25:18,000 --> 00:25:20,820
files directories containing the word

595
00:25:20,820 --> 00:25:22,320
conf

596
00:25:22,320 --> 00:25:25,380
you can also look for files by size so

597
00:25:25,380 --> 00:25:27,059
this is really useful if you want to for

598
00:25:27,059 --> 00:25:30,539
example delete empty files you might

599
00:25:30,539 --> 00:25:32,520
start by finding files in the current

600
00:25:32,520 --> 00:25:35,039
directory with no size or perhaps you

601
00:25:35,039 --> 00:25:37,620
want to find big files so files larger

602
00:25:37,620 --> 00:25:39,140
than 200k

603
00:25:39,140 --> 00:25:41,220
things that might be candidates to be

604
00:25:41,220 --> 00:25:43,020
deleted or perhaps there are files that

605
00:25:43,020 --> 00:25:45,120
are more interesting

606
00:25:45,120 --> 00:25:47,640
you can also look for files by when they

607
00:25:47,640 --> 00:25:50,580
were changed so here we look for files

608
00:25:50,580 --> 00:25:52,799
that have been modified in the last five

609
00:25:52,799 --> 00:25:55,020
minutes and that can be quite useful if

610
00:25:55,020 --> 00:25:58,200
for example a command has written lots

611
00:25:58,200 --> 00:26:00,000
of files into an already populated

612
00:26:00,000 --> 00:26:01,740
directory and you want to know what they

613
00:26:01,740 --> 00:26:02,700
are were

614
00:26:02,700 --> 00:26:05,400
uh or perhaps we want to find older

615
00:26:05,400 --> 00:26:07,620
files so we might look for files older

616
00:26:07,620 --> 00:26:09,539
than 30 minutes ago

617
00:26:09,539 --> 00:26:11,760
Now find is incredibly powerful and has

618
00:26:11,760 --> 00:26:14,039
lots and lots of options

619
00:26:14,039 --> 00:26:16,140
um negations and you can combine these

620
00:26:16,140 --> 00:26:17,880
things and so on and so forth so I

621
00:26:17,880 --> 00:26:20,760
highly encourage you give the man page a

622
00:26:20,760 --> 00:26:23,640
read by Running Man find and looking at

623
00:26:23,640 --> 00:26:26,039
some of the examples and crazy things it

624
00:26:26,039 --> 00:26:28,140
can do

625
00:26:28,140 --> 00:26:30,179
a really useful companion to lots of

626
00:26:30,179 --> 00:26:32,840
tools but find in particular is

627
00:26:32,840 --> 00:26:35,700
XOXOX runs a command using each line of

628
00:26:35,700 --> 00:26:38,880
its input as an argument and as I said

629
00:26:38,880 --> 00:26:40,799
it's super handy with the output of find

630
00:26:40,799 --> 00:26:43,500
if you want to say for example run a

631
00:26:43,500 --> 00:26:46,260
command for every file that you found

632
00:26:46,260 --> 00:26:49,860
you might for example use find with the

633
00:26:49,860 --> 00:26:54,120
size mode to find empty files and pass

634
00:26:54,120 --> 00:26:56,760
them to RM so that they are deleted

635
00:26:56,760 --> 00:26:59,940
it's the kind of thing you can do

636
00:26:59,940 --> 00:27:01,860
but there's a few options that I think

637
00:27:01,860 --> 00:27:06,000
are worth knowing about so dash n is a

638
00:27:06,000 --> 00:27:09,840
one that I use nearly all the time so by

639
00:27:09,840 --> 00:27:12,860
default X args will pass lots of lines

640
00:27:12,860 --> 00:27:16,440
as arguments to a single command and you

641
00:27:16,440 --> 00:27:18,299
can make it past just one at a time with

642
00:27:18,299 --> 00:27:21,360
Dash N1 or if you want it to be two at a

643
00:27:21,360 --> 00:27:23,700
time it would be Dash N2 and so on and

644
00:27:23,700 --> 00:27:26,460
so forth so here we take a list of

645
00:27:26,460 --> 00:27:28,140
domains and we run the host command

646
00:27:28,140 --> 00:27:30,720
against them which does a DNS look upon

647
00:27:30,720 --> 00:27:31,620
them

648
00:27:31,620 --> 00:27:33,900
if we want to run things in parallel we

649
00:27:33,900 --> 00:27:36,419
can use Dash big p and a number to

650
00:27:36,419 --> 00:27:38,279
specify how many commands we want to run

651
00:27:38,279 --> 00:27:39,779
at a time

652
00:27:39,779 --> 00:27:42,179
so here we run the host command again

653
00:27:42,179 --> 00:27:45,179
against those domains but we run five at

654
00:27:45,179 --> 00:27:46,980
a time and this is particularly useful

655
00:27:46,980 --> 00:27:49,320
with slower commands for example you

656
00:27:49,320 --> 00:27:51,960
might be doing HTTP requests or

657
00:27:51,960 --> 00:27:54,720
something like that that takes quite a

658
00:27:54,720 --> 00:27:57,980
bit of time waiting on the network

659
00:27:58,200 --> 00:28:02,220
by default xox will pass its the

660
00:28:02,220 --> 00:28:04,260
arguments to the end of the command that

661
00:28:04,260 --> 00:28:08,460
you give so here host is uh has its

662
00:28:08,460 --> 00:28:10,440
argument after it but that's not always

663
00:28:10,440 --> 00:28:13,559
true for every command we might want to

664
00:28:13,559 --> 00:28:15,419
use

665
00:28:15,419 --> 00:28:18,659
um the file name somewhere else and dash

666
00:28:18,659 --> 00:28:21,840
big I followed by a placeholder which by

667
00:28:21,840 --> 00:28:24,299
convention and I guess habit on my part

668
00:28:24,299 --> 00:28:27,179
I use an opening and a closing curly

669
00:28:27,179 --> 00:28:29,279
brace uh

670
00:28:29,279 --> 00:28:32,820
can uh be used as a placeholder for the

671
00:28:32,820 --> 00:28:35,820
file name so here we use find to look in

672
00:28:35,820 --> 00:28:38,279
the current directory for files that end

673
00:28:38,279 --> 00:28:42,720
in dot txt I pass them to xargs tell it

674
00:28:42,720 --> 00:28:45,659
to pass one line to as an argument to

675
00:28:45,659 --> 00:28:48,179
each command he's a placeholder of

676
00:28:48,179 --> 00:28:50,640
opening and closing curly braces to run

677
00:28:50,640 --> 00:28:53,400
CP the copy command on the file in

678
00:28:53,400 --> 00:28:56,340
question into the backup directory which

679
00:28:56,340 --> 00:28:59,220
is one level above us

680
00:28:59,220 --> 00:29:01,919
now when things get really complex or

681
00:29:01,919 --> 00:29:03,659
you want to set variables and run

682
00:29:03,659 --> 00:29:05,880
conditionals and that kind of thing I

683
00:29:05,880 --> 00:29:09,059
think using while Loops or perhaps for

684
00:29:09,059 --> 00:29:10,980
Loops as well but I won't cover them

685
00:29:10,980 --> 00:29:13,740
here is a good alternative to xox you

686
00:29:13,740 --> 00:29:16,260
don't get the parallelism options but

687
00:29:16,260 --> 00:29:19,200
when you want to do some mini pipeline

688
00:29:19,200 --> 00:29:21,059
so for example here we take a list of

689
00:29:21,059 --> 00:29:23,940
domains read each line run the host

690
00:29:23,940 --> 00:29:26,640
command against each domain and grep for

691
00:29:26,640 --> 00:29:28,740
the hazard rest line and print the last

692
00:29:28,740 --> 00:29:31,080
field of that line which is the IP

693
00:29:31,080 --> 00:29:32,059
address

694
00:29:32,059 --> 00:29:34,679
doing that kind of thing with X arcs can

695
00:29:34,679 --> 00:29:36,659
be a little bit tricky so while Loops

696
00:29:36,659 --> 00:29:38,460
are well worth considering and I'm

697
00:29:38,460 --> 00:29:41,120
reading up on

698
00:29:42,299 --> 00:29:45,299
a really common thing for me at least is

699
00:29:45,299 --> 00:29:47,760
that I often end up with several files

700
00:29:47,760 --> 00:29:50,460
that have similar data in them so I

701
00:29:50,460 --> 00:29:52,500
might have for example two files filled

702
00:29:52,500 --> 00:29:54,120
with domains that came from two

703
00:29:54,120 --> 00:29:57,600
different sources and I want to know uh

704
00:29:57,600 --> 00:30:01,260
which domains are unique to each file or

705
00:30:01,260 --> 00:30:03,480
what the overlap is and so on and so

706
00:30:03,480 --> 00:30:05,100
forth

707
00:30:05,100 --> 00:30:08,399
now com is a little bit of a an unusual

708
00:30:08,399 --> 00:30:11,220
command in how it works

709
00:30:11,220 --> 00:30:13,020
and it can be a little bit tricky to

710
00:30:13,020 --> 00:30:13,980
remember

711
00:30:13,980 --> 00:30:17,039
so the default use the basic usages you

712
00:30:17,039 --> 00:30:19,980
run com with two files file a and file B

713
00:30:19,980 --> 00:30:22,380
and it will print three columns column

714
00:30:22,380 --> 00:30:24,120
one is the lines that only appear in

715
00:30:24,120 --> 00:30:26,340
file a column two is the lines that only

716
00:30:26,340 --> 00:30:29,460
appear in file B and line three or

717
00:30:29,460 --> 00:30:31,440
column three sorry is the lines that

718
00:30:31,440 --> 00:30:33,419
appear in both files

719
00:30:33,419 --> 00:30:36,659
now you can use Dash 1-2 and 3 to

720
00:30:36,659 --> 00:30:41,640
suppress a column so for example if you

721
00:30:41,640 --> 00:30:44,520
wanted to show the file lines that are

722
00:30:44,520 --> 00:30:48,720
only in file a you would use Dash 2 3 to

723
00:30:48,720 --> 00:30:50,760
suppress the lines that are only in file

724
00:30:50,760 --> 00:30:55,020
B and the lines that are in both files

725
00:30:55,020 --> 00:30:57,179
another slightly annoying prerequisite

726
00:30:57,179 --> 00:30:59,520
of com is that like the unique command

727
00:30:59,520 --> 00:31:02,460
the files that you give as input must be

728
00:31:02,460 --> 00:31:03,440
sorted

729
00:31:03,440 --> 00:31:06,240
now you might not want to sort your

730
00:31:06,240 --> 00:31:09,480
files the order might have significance

731
00:31:09,480 --> 00:31:13,200
um or you might not even have right

732
00:31:13,200 --> 00:31:16,020
access to that file even

733
00:31:16,020 --> 00:31:18,120
but thankfully one of the tricks we

734
00:31:18,120 --> 00:31:20,940
learned earlier comes to the rescue so

735
00:31:20,940 --> 00:31:23,039
we can use the less than brackets

736
00:31:23,039 --> 00:31:26,220
command substitution here to instead of

737
00:31:26,220 --> 00:31:28,500
using the file directly use a sorted

738
00:31:28,500 --> 00:31:31,200
copy of the file so we run the sort

739
00:31:31,200 --> 00:31:33,600
command against file a and we use the

740
00:31:33,600 --> 00:31:36,240
output as

741
00:31:36,240 --> 00:31:39,539
a file as far as com is concerned as

742
00:31:39,539 --> 00:31:41,399
representing a file

743
00:31:41,399 --> 00:31:43,980
so we might for example want to print

744
00:31:43,980 --> 00:31:46,320
the lines only in file a we would use

745
00:31:46,320 --> 00:31:49,740
Dash 2 3. again that suppresses columns

746
00:31:49,740 --> 00:31:53,460
2 and and three only in the for the

747
00:31:53,460 --> 00:31:55,559
lines are lean file B we would use dash

748
00:31:55,559 --> 00:31:58,080
one three suppressing the lines only in

749
00:31:58,080 --> 00:32:00,360
vial a and the lines in both files and

750
00:32:00,360 --> 00:32:02,640
so on

751
00:32:02,640 --> 00:32:05,100
now a lot of tools out from plain text

752
00:32:05,100 --> 00:32:08,700
but increasingly tools and also websites

753
00:32:08,700 --> 00:32:11,399
and apis and things output Json and

754
00:32:11,399 --> 00:32:12,960
you've probably heard of it it stands

755
00:32:12,960 --> 00:32:15,080
for JavaScript object notation

756
00:32:15,080 --> 00:32:17,580
but I want to give you a few examples of

757
00:32:17,580 --> 00:32:21,299
Json data so here is an object and this

758
00:32:21,299 --> 00:32:22,380
is probably the thing you're most

759
00:32:22,380 --> 00:32:24,720
familiar with it has keys like here we

760
00:32:24,720 --> 00:32:27,539
have name and values so the value here

761
00:32:27,539 --> 00:32:28,620
is Tom

762
00:32:28,620 --> 00:32:31,620
uh but there are also arrays and they

763
00:32:31,620 --> 00:32:33,779
can be of mixed types so here we have an

764
00:32:33,779 --> 00:32:36,899
array of both strings and numbers

765
00:32:36,899 --> 00:32:38,760
they can be just numbers

766
00:32:38,760 --> 00:32:41,700
strings booleans lecture and false and

767
00:32:41,700 --> 00:32:43,020
null as well

768
00:32:43,020 --> 00:32:44,220
and one of the things I want to point

769
00:32:44,220 --> 00:32:46,620
out is that all of these above things

770
00:32:46,620 --> 00:32:48,299
are valid Json

771
00:32:48,299 --> 00:32:50,460
it's really common to think of Json as

772
00:32:50,460 --> 00:32:53,220
being just objects I mean it's in the

773
00:32:53,220 --> 00:32:55,860
name right JavaScript object notation

774
00:32:55,860 --> 00:32:59,760
but also you know arrays by themselves

775
00:32:59,760 --> 00:33:01,740
are valid and even just strings by

776
00:33:01,740 --> 00:33:03,720
themselves are valid and so on and so

777
00:33:03,720 --> 00:33:06,600
forth and most good JavaScript parsers

778
00:33:06,600 --> 00:33:08,340
will deal with all of these situations

779
00:33:08,340 --> 00:33:10,879
well

780
00:33:10,940 --> 00:33:13,940
relatedly increasingly

781
00:33:13,940 --> 00:33:17,580
tools are outputting a format that gets

782
00:33:17,580 --> 00:33:20,100
called Json lines and this is just like

783
00:33:20,100 --> 00:33:22,980
Json but there's one item per line

784
00:33:22,980 --> 00:33:25,679
instead and I think this is really one

785
00:33:25,679 --> 00:33:28,080
of the best options for When lines of

786
00:33:28,080 --> 00:33:31,080
plain text won't quite cut it when the

787
00:33:31,080 --> 00:33:33,840
data is very complex

788
00:33:33,840 --> 00:33:34,440
um

789
00:33:34,440 --> 00:33:36,899
or has quite a lot of structure to it

790
00:33:36,899 --> 00:33:38,519
lots of different fields and so on and

791
00:33:38,519 --> 00:33:40,380
so forth you know you find yourself

792
00:33:40,380 --> 00:33:43,740
writing things like orc print dollar 25

793
00:33:43,740 --> 00:33:46,679
to get the 25th field things are getting

794
00:33:46,679 --> 00:33:48,000
a little bit out of hand it would be

795
00:33:48,000 --> 00:33:50,880
much better if they had names and Json l

796
00:33:50,880 --> 00:33:53,059
or Json lines I think is a great

797
00:33:53,059 --> 00:33:56,159
solution to that problem I want to give

798
00:33:56,159 --> 00:33:57,539
a particular shout out to project

799
00:33:57,539 --> 00:34:00,600
Discovery for pretty much all of their

800
00:34:00,600 --> 00:34:03,600
tools have a dash Json option which uses

801
00:34:03,600 --> 00:34:06,600
Json L as output

802
00:34:06,600 --> 00:34:07,980
um although if any other project

803
00:34:07,980 --> 00:34:09,780
Discovery people are watching

804
00:34:09,780 --> 00:34:11,699
I do have a personal plea to make Dash

805
00:34:11,699 --> 00:34:14,460
silent the default because I I pretty

806
00:34:14,460 --> 00:34:17,040
much every command for every tool of

807
00:34:17,040 --> 00:34:18,780
yours that I ever run has Dash silent

808
00:34:18,780 --> 00:34:23,399
Json on it uh now you can pipe the Json

809
00:34:23,399 --> 00:34:25,918
line output straight into JQ or grand s

810
00:34:25,918 --> 00:34:28,320
which we'll look at in a moment and if

811
00:34:28,320 --> 00:34:29,699
you want to turn it into an array

812
00:34:29,699 --> 00:34:33,300
instead uh jq-s or Dash slurp we'll do

813
00:34:33,300 --> 00:34:36,300
that for you So speaking of which

814
00:34:36,300 --> 00:34:39,239
uh Grana is a tool which turns Json into

815
00:34:39,239 --> 00:34:41,460
a series of assignments primarily so

816
00:34:41,460 --> 00:34:42,899
that you can grab them and that's

817
00:34:42,899 --> 00:34:44,639
actually where the name comes from it's

818
00:34:44,639 --> 00:34:47,780
a portmento of grep and Json

819
00:34:47,780 --> 00:34:50,040
it also lets you turn the output back

820
00:34:50,040 --> 00:34:52,139
into Json with Dash U or Dash Dash

821
00:34:52,139 --> 00:34:54,659
unground and get the value of an

822
00:34:54,659 --> 00:34:56,520
assignment with Dash V or dash dash

823
00:34:56,520 --> 00:34:57,660
value

824
00:34:57,660 --> 00:35:00,180
so here we have some example Json which

825
00:35:00,180 --> 00:35:02,400
I've set to a variable so we can reuse

826
00:35:02,400 --> 00:35:04,680
it more easily

827
00:35:04,680 --> 00:35:08,220
so it has a key of name with a value of

828
00:35:08,220 --> 00:35:10,619
Tom and a key fillings which is a value

829
00:35:10,619 --> 00:35:12,599
of array with my favorites how much

830
00:35:12,599 --> 00:35:14,280
fillings

831
00:35:14,280 --> 00:35:17,060
so here we pipe that Json into ground

832
00:35:17,060 --> 00:35:20,280
and we can easily grep for Jam which is

833
00:35:20,280 --> 00:35:23,339
one of the fillings and we can see an

834
00:35:23,339 --> 00:35:25,380
assignment statement here which tells us

835
00:35:25,380 --> 00:35:28,020
the full path as it were to that

836
00:35:28,020 --> 00:35:30,180
particular value

837
00:35:30,180 --> 00:35:33,720
so the root Json object where the

838
00:35:33,720 --> 00:35:36,359
fillings property is an array and it's

839
00:35:36,359 --> 00:35:39,380
index one

840
00:35:39,380 --> 00:35:43,920
we can use Grand V to extract values so

841
00:35:43,920 --> 00:35:45,960
it might be that we don't you know care

842
00:35:45,960 --> 00:35:48,359
about the path to it at all we just want

843
00:35:48,359 --> 00:35:51,920
the particular value so here we go for p

844
00:35:51,920 --> 00:35:54,780
uh and use Grand Dash V and the result

845
00:35:54,780 --> 00:35:56,579
is we get just the value

846
00:35:56,579 --> 00:35:58,980
we can also modify the structure of Json

847
00:35:58,980 --> 00:36:02,280
and when it's in the grand output format

848
00:36:02,280 --> 00:36:05,460
and use Grand Dash U or unground to turn

849
00:36:05,460 --> 00:36:08,160
it back into Json so here we go up for

850
00:36:08,160 --> 00:36:11,520
just the filling part of the structure

851
00:36:11,520 --> 00:36:16,380
and use Grand Dash U to turn uh

852
00:36:16,380 --> 00:36:19,079
it back into this Json object that

853
00:36:19,079 --> 00:36:22,500
doesn't include the name Tom part it's

854
00:36:22,500 --> 00:36:25,640
just the fillings part

855
00:36:25,800 --> 00:36:29,579
now gron is useful in particular if you

856
00:36:29,579 --> 00:36:31,320
don't already understand the structure

857
00:36:31,320 --> 00:36:33,960
of the Json that you're working with but

858
00:36:33,960 --> 00:36:35,640
a tool that has a great deal more power

859
00:36:35,640 --> 00:36:37,859
and I consider to be effectively the

860
00:36:37,859 --> 00:36:41,099
Json utility belt is JQ you can use it

861
00:36:41,099 --> 00:36:44,040
to filter extract and modify Json that's

862
00:36:44,040 --> 00:36:46,260
provided on its standard input so you

863
00:36:46,260 --> 00:36:48,060
might for example extract a particular

864
00:36:48,060 --> 00:36:49,260
field

865
00:36:49,260 --> 00:36:52,640
from a Json object by

866
00:36:52,640 --> 00:36:55,740
writing a DOT and then the field name

867
00:36:55,740 --> 00:36:58,500
I'll give you the value you can also

868
00:36:58,500 --> 00:37:01,260
filter the input as well so you might

869
00:37:01,260 --> 00:37:05,099
have an input of Json lines maybe it's

870
00:37:05,099 --> 00:37:07,680
the output of a project Discovery tool

871
00:37:07,680 --> 00:37:10,079
for example and you might want to select

872
00:37:10,079 --> 00:37:11,760
only the objects where a particular

873
00:37:11,760 --> 00:37:14,760
field is equal to a particular value

874
00:37:14,760 --> 00:37:17,420
you can also really easily reshape

875
00:37:17,420 --> 00:37:21,540
objects so it's common for a Json object

876
00:37:21,540 --> 00:37:23,760
to have many many fields in it and you

877
00:37:23,760 --> 00:37:25,560
might only care about three of them

878
00:37:25,560 --> 00:37:28,500
field one field two and field three so

879
00:37:28,500 --> 00:37:31,440
there's a real nice easy way to do that

880
00:37:31,440 --> 00:37:33,780
now Jackie effectively has its own

881
00:37:33,780 --> 00:37:37,440
pipeline kind of like the terminal does

882
00:37:37,440 --> 00:37:40,560
so here we can read an array of items so

883
00:37:40,560 --> 00:37:42,839
there's a field in our input Json object

884
00:37:42,839 --> 00:37:45,060
called an array and this will give us

885
00:37:45,060 --> 00:37:47,460
each item in the array but we might

886
00:37:47,460 --> 00:37:49,920
actually have an array of objects and we

887
00:37:49,920 --> 00:37:51,540
only want one field from each one of

888
00:37:51,540 --> 00:37:55,859
those so the pipes here work a little

889
00:37:55,859 --> 00:37:58,980
bit like the pipes in the shell and let

890
00:37:58,980 --> 00:38:02,339
us extract one field from that object

891
00:38:02,339 --> 00:38:04,260
and really you know for tools that

892
00:38:04,260 --> 00:38:07,079
output Json JQ is like having a ton more

893
00:38:07,079 --> 00:38:10,320
options so uh project discoveries https

894
00:38:10,320 --> 00:38:13,260
tool for example is really useful

895
00:38:13,260 --> 00:38:14,780
um for

896
00:38:14,780 --> 00:38:18,240
fetching URLs and that kind of thing

897
00:38:18,240 --> 00:38:21,060
um and the Json mode makes it output the

898
00:38:21,060 --> 00:38:23,359
Json lines format

899
00:38:23,359 --> 00:38:26,460
with some information about each

900
00:38:26,460 --> 00:38:28,440
response so there's you know the

901
00:38:28,440 --> 00:38:31,619
Response Code URL that was requested the

902
00:38:31,619 --> 00:38:34,140
size of the response and so on and also

903
00:38:34,140 --> 00:38:37,079
the title from any HTML pages that it

904
00:38:37,079 --> 00:38:38,160
encountered

905
00:38:38,160 --> 00:38:41,579
uh so here is an example we'll take a

906
00:38:41,579 --> 00:38:44,700
list of URLs request them using acbx and

907
00:38:44,700 --> 00:38:47,099
output Json and disable the banner

908
00:38:47,099 --> 00:38:48,780
because we don't need it to appear on

909
00:38:48,780 --> 00:38:50,160
the screen

910
00:38:50,160 --> 00:38:53,460
and then we use JQ to slurp that input

911
00:38:53,460 --> 00:38:56,339
nice to take every object and turn it

912
00:38:56,339 --> 00:38:59,160
into an array and then create

913
00:38:59,160 --> 00:39:00,740
take

914
00:39:00,740 --> 00:39:05,579
only those ones that had a unique title

915
00:39:05,579 --> 00:39:08,400
so it might be that you know we have a

916
00:39:08,400 --> 00:39:10,560
hundred URLs and many of them point to

917
00:39:10,560 --> 00:39:12,599
pages that are basically identical and

918
00:39:12,599 --> 00:39:15,119
have the same title and this gives us a

919
00:39:15,119 --> 00:39:17,640
way to figure out to find only one

920
00:39:17,640 --> 00:39:20,040
example of each one or we might for

921
00:39:20,040 --> 00:39:22,800
example want to extract all of the a

922
00:39:22,800 --> 00:39:25,200
records from those responses as well and

923
00:39:25,200 --> 00:39:27,420
use a new to make them unique

924
00:39:27,420 --> 00:39:30,300
and here the dash R stands for raw

925
00:39:30,300 --> 00:39:31,500
output

926
00:39:31,500 --> 00:39:34,800
so by default JQ would output a string

927
00:39:34,800 --> 00:39:36,960
with the double quotes around it and

928
00:39:36,960 --> 00:39:39,300
dash R means that those double quotes

929
00:39:39,300 --> 00:39:41,960
don't appear

930
00:39:42,119 --> 00:39:45,119
now speaking of URLs uh they're actually

931
00:39:45,119 --> 00:39:46,920
remarkably complicated things by

932
00:39:46,920 --> 00:39:48,780
themselves and in particular writing

933
00:39:48,780 --> 00:39:50,820
regular expressions for them is kind of

934
00:39:50,820 --> 00:39:52,920
horrible there's a lot of edge cases

935
00:39:52,920 --> 00:39:54,660
that you need to account for and so on

936
00:39:54,660 --> 00:39:57,180
so I wrote a little tool called unfurl

937
00:39:57,180 --> 00:40:00,359
and that parses URLs and extracts bits

938
00:40:00,359 --> 00:40:02,640
of them so for example the paths queries

939
00:40:02,640 --> 00:40:05,339
string Keys query string parameters key

940
00:40:05,339 --> 00:40:08,760
value pairs ports so on and so forth

941
00:40:08,760 --> 00:40:10,380
so we might for example have a list of

942
00:40:10,380 --> 00:40:13,560
URLs and want to get all of the paths or

943
00:40:13,560 --> 00:40:16,079
all of the unique Apex domains so the

944
00:40:16,079 --> 00:40:19,440
dash U flag outputs only unique items or

945
00:40:19,440 --> 00:40:20,880
I suppose you could pipe to a new

946
00:40:20,880 --> 00:40:22,380
instead

947
00:40:22,380 --> 00:40:23,760
if we were adhering to the Unix

948
00:40:23,760 --> 00:40:26,160
philosophy a little bit more strictly so

949
00:40:26,160 --> 00:40:28,440
an apex domain by the way is the

950
00:40:28,440 --> 00:40:32,760
example.com in blog.example.com

951
00:40:32,780 --> 00:40:35,220
this also supports custom formats so

952
00:40:35,220 --> 00:40:37,079
there's a variety of these format

953
00:40:37,079 --> 00:40:39,800
specifiers which are percent followed by

954
00:40:39,800 --> 00:40:42,480
some character

955
00:40:42,480 --> 00:40:45,359
so here we use present D for domain

956
00:40:45,359 --> 00:40:48,780
percent colon for Echo for the column

957
00:40:48,780 --> 00:40:51,180
before the port if one exists in the

958
00:40:51,180 --> 00:40:54,480
input domain and a percent P for Port if

959
00:40:54,480 --> 00:40:57,680
one exists in the input

960
00:40:57,900 --> 00:41:00,599
um and file also has a Json mode and

961
00:41:00,599 --> 00:41:02,640
couple with JQ you can do some cool

962
00:41:02,640 --> 00:41:04,980
stuff that on Phil can't do by itself so

963
00:41:04,980 --> 00:41:06,839
for example you might want to take a

964
00:41:06,839 --> 00:41:09,380
list of urls

965
00:41:09,380 --> 00:41:13,260
an output only one instance of each path

966
00:41:13,260 --> 00:41:16,440
so you might have the same URL over and

967
00:41:16,440 --> 00:41:18,500
over again with lots of different

968
00:41:18,500 --> 00:41:20,820
permutations of query string parameters

969
00:41:20,820 --> 00:41:22,500
and you only want one instance of each

970
00:41:22,500 --> 00:41:25,200
so here we use the slurp mode and the

971
00:41:25,200 --> 00:41:27,540
raw output mode to say we only want

972
00:41:27,540 --> 00:41:30,680
items that are unique by the path field

973
00:41:30,680 --> 00:41:33,000
uh and then we want to iterate over

974
00:41:33,000 --> 00:41:36,480
those and pipe the objects

975
00:41:36,480 --> 00:41:40,079
um and extract just the URL from those

976
00:41:40,079 --> 00:41:42,599
or maybe you want to look for URLs that

977
00:41:42,599 --> 00:41:44,400
have more than two parameters

978
00:41:44,400 --> 00:41:45,839
that's the kind of thing that's actually

979
00:41:45,839 --> 00:41:46,920
really

980
00:41:46,920 --> 00:41:50,160
tricky and annoying to do with regular

981
00:41:50,160 --> 00:41:52,320
expressions and and that sort of thing

982
00:41:52,320 --> 00:41:56,280
but here we can use on first Json mode

983
00:41:56,280 --> 00:42:01,280
and JQ again to select only those

984
00:42:01,280 --> 00:42:04,800
URLs where they have more than two

985
00:42:04,800 --> 00:42:07,200
parameters so we have the parameters

986
00:42:07,200 --> 00:42:09,480
field piped to the length function which

987
00:42:09,480 --> 00:42:11,460
outputs how long that array of

988
00:42:11,460 --> 00:42:13,859
parameters is and we select only those

989
00:42:13,859 --> 00:42:15,900
that are greater than two and then we

990
00:42:15,900 --> 00:42:18,800
extract the URL

991
00:42:18,800 --> 00:42:22,820
uh HTML is I think kind of the other

992
00:42:22,820 --> 00:42:24,900
structured data format that we come

993
00:42:24,900 --> 00:42:27,599
across a lot as people dealing with the

994
00:42:27,599 --> 00:42:28,440
web

995
00:42:28,440 --> 00:42:30,300
and it's actually super annoying to pass

996
00:42:30,300 --> 00:42:32,579
an extract data from but thankfully

997
00:42:32,579 --> 00:42:35,220
there's kind of an equivalent to JQ for

998
00:42:35,220 --> 00:42:37,579
HTML called HTML key

999
00:42:37,579 --> 00:42:41,160
and it's incredibly useful

1000
00:42:41,160 --> 00:42:44,820
um so we might for example uh combine

1001
00:42:44,820 --> 00:42:49,380
find an X Hogs to run htmlq against a

1002
00:42:49,380 --> 00:42:51,480
lot of HTML files that exist in a

1003
00:42:51,480 --> 00:42:54,720
directory so here we find files

1004
00:42:54,720 --> 00:42:56,760
called.html in the current directory

1005
00:42:56,760 --> 00:43:02,280
pass them to xargs and with one

1006
00:43:02,280 --> 00:43:05,160
HTML file at a time using a placeholder

1007
00:43:05,160 --> 00:43:07,680
we pass them to HTML queue with the dash

1008
00:43:07,680 --> 00:43:12,839
file name and extract the text from the

1009
00:43:12,839 --> 00:43:15,180
title tags that are in the page so here

1010
00:43:15,180 --> 00:43:17,040
we get the page titles

1011
00:43:17,040 --> 00:43:19,260
or perhaps we want to find all of the

1012
00:43:19,260 --> 00:43:20,579
source attributes from all of the script

1013
00:43:20,579 --> 00:43:23,819
tags instead so here we have more or

1014
00:43:23,819 --> 00:43:25,680
less the same thing instead we look for

1015
00:43:25,680 --> 00:43:27,660
script tags and we use Dash a for

1016
00:43:27,660 --> 00:43:33,859
attribute to extract just the SRC value

1017
00:43:33,960 --> 00:43:36,300
for each script tag

1018
00:43:36,300 --> 00:43:38,359
you can also use

1019
00:43:38,359 --> 00:43:41,220
HTML provided on standard input to HTML

1020
00:43:41,220 --> 00:43:43,619
queue so here we might want to get

1021
00:43:43,619 --> 00:43:46,880
unique links from hamcon.com

1022
00:43:46,880 --> 00:43:51,359
so we use the curl tool to request uh

1023
00:43:51,359 --> 00:43:54,180
that URL and get the HTML output pass it

1024
00:43:54,180 --> 00:43:57,540
to HTML queue look for anchor tags and

1025
00:43:57,540 --> 00:44:01,200
specifically the href attribute and we

1026
00:44:01,200 --> 00:44:04,500
pipe to a new to make them unique

1027
00:44:04,500 --> 00:44:08,040
so uh we can put all those things

1028
00:44:08,040 --> 00:44:09,180
together

1029
00:44:09,180 --> 00:44:11,880
um and do some pretty cool things uh and

1030
00:44:11,880 --> 00:44:13,500
I want to leave you with kind of an

1031
00:44:13,500 --> 00:44:15,599
example of the kind of question that you

1032
00:44:15,599 --> 00:44:17,040
might have

1033
00:44:17,040 --> 00:44:20,220
um I'll be perhaps a little contrived uh

1034
00:44:20,220 --> 00:44:21,839
and show you how you could answer that

1035
00:44:21,839 --> 00:44:23,940
question so

1036
00:44:23,940 --> 00:44:26,819
my example question is you know do the

1037
00:44:26,819 --> 00:44:28,500
Twitter accounts linked on the

1038
00:44:28,500 --> 00:44:30,859
hamcon.com have equivalents on

1039
00:44:30,859 --> 00:44:33,780
infosec.exchange and that's the kind of

1040
00:44:33,780 --> 00:44:36,660
thing you can kind of do manually it

1041
00:44:36,660 --> 00:44:38,400
might take a while you know in this

1042
00:44:38,400 --> 00:44:40,260
specific case there only happens to be

1043
00:44:40,260 --> 00:44:41,520
one

1044
00:44:41,520 --> 00:44:43,079
um but it could be in a different

1045
00:44:43,079 --> 00:44:45,660
situation that there was several hundred

1046
00:44:45,660 --> 00:44:47,280
of them and that would be a real pain to

1047
00:44:47,280 --> 00:44:49,380
do and it's not the kind of thing you

1048
00:44:49,380 --> 00:44:51,300
probably want to do very often

1049
00:44:51,300 --> 00:44:52,859
so you probably don't want to write a

1050
00:44:52,859 --> 00:44:54,900
custom tool for it either

1051
00:44:54,900 --> 00:44:56,099
however

1052
00:44:56,099 --> 00:44:57,960
with these tools you can do it pretty

1053
00:44:57,960 --> 00:45:00,780
easily so let's run through it so we use

1054
00:45:00,780 --> 00:45:04,980
Curl to fetch nomcon.com we use htmlq to

1055
00:45:04,980 --> 00:45:07,079
find anchor tags and extract the href

1056
00:45:07,079 --> 00:45:09,720
attributes so that's the links

1057
00:45:09,720 --> 00:45:12,180
we pass the URLs with unfill and output

1058
00:45:12,180 --> 00:45:15,839
Json we pass them to JQ have raw output

1059
00:45:15,839 --> 00:45:20,060
and we select only the domain when

1060
00:45:20,060 --> 00:45:22,800
lowercased matches twitter.com and we

1061
00:45:22,800 --> 00:45:25,260
extract the path from those which is the

1062
00:45:25,260 --> 00:45:29,040
username we use said to replace the

1063
00:45:29,040 --> 00:45:31,079
slash at the beginning of the line with

1064
00:45:31,079 --> 00:45:33,660
an at we pass into a new to make them

1065
00:45:33,660 --> 00:45:37,260
unique we use orc to print a prefix URL

1066
00:45:37,260 --> 00:45:39,839
onto dollar one which is the first field

1067
00:45:39,839 --> 00:45:42,119
in the output which is the username we

1068
00:45:42,119 --> 00:45:44,520
pass them to https with that silent to

1069
00:45:44,520 --> 00:45:46,319
suppress the banner that's Json to get

1070
00:45:46,319 --> 00:45:48,060
jsonline output

1071
00:45:48,060 --> 00:45:50,760
so that requests all of the URLs for

1072
00:45:50,760 --> 00:45:53,040
example infosec exchange dot exchange

1073
00:45:53,040 --> 00:45:56,819
slash at naham Khan or whatever the

1074
00:45:56,819 --> 00:45:58,079
username might be

1075
00:45:58,079 --> 00:46:01,020
and then we finally use JQ with raw

1076
00:46:01,020 --> 00:46:03,180
output to select only the status codes

1077
00:46:03,180 --> 00:46:07,920
that we to 200 and we output the URL and

1078
00:46:07,920 --> 00:46:09,900
the title from the page

1079
00:46:09,900 --> 00:46:11,460
so

1080
00:46:11,460 --> 00:46:13,920
you know I think that's a a really good

1081
00:46:13,920 --> 00:46:16,500
example of the kind of annoying question

1082
00:46:16,500 --> 00:46:19,079
uh that you sometimes wish you could get

1083
00:46:19,079 --> 00:46:21,300
the answer to but it's not quite worth

1084
00:46:21,300 --> 00:46:24,599
writing a full-fledged program in Python

1085
00:46:24,599 --> 00:46:26,579
or something else like that and those

1086
00:46:26,579 --> 00:46:28,740
are the kinds of data wrangling tasks

1087
00:46:28,740 --> 00:46:31,440
that I at least personally come across

1088
00:46:31,440 --> 00:46:35,240
every day maybe you do too and maybe now

1089
00:46:35,240 --> 00:46:39,599
you can help yourself solve them more

1090
00:46:39,599 --> 00:46:41,220
easily

1091
00:46:41,220 --> 00:46:43,879
thank you

