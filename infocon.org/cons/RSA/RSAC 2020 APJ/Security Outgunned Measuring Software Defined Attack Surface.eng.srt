1
00:00:09,080 --> 00:00:12,240
- Hello, and welcome
to Security Outgunned:

2
00:00:12,240 --> 00:00:15,140
Measuring Software Defined Attack Surface.

3
00:00:15,140 --> 00:00:16,470
If you're joining us live, our speaker

4
00:00:16,470 --> 00:00:19,939
is in this slider discussion
now answering your questions.

5
00:00:19,940 --> 00:00:22,080
He will also be participating in a live,

6
00:00:22,080 --> 00:00:25,150
ask the expert round table on this topic,

7
00:00:25,150 --> 00:00:27,110
right after this session.

8
00:00:27,110 --> 00:00:29,110
For audio or video issues,

9
00:00:29,110 --> 00:00:32,070
you can click the technical
support button below,

10
00:00:32,070 --> 00:00:34,500
and now I'd like to turn
it over to Richard Seiersen

11
00:00:34,500 --> 00:00:36,073
for the presentation.

12
00:00:36,073 --> 00:00:36,980
- Thank you,

13
00:00:36,980 --> 00:00:39,290
thank you very much and
yes, I'm Richard Seiersen,

14
00:00:39,290 --> 00:00:41,780
I'm a serial recovering CISO.

15
00:00:41,780 --> 00:00:44,310
I was a CISO for LendingClub

16
00:00:44,310 --> 00:00:47,270
one of the larger FinTech
organizations in the U.S.

17
00:00:47,270 --> 00:00:51,280
part of that I was the CISO
and VP of Trust at Twilio,

18
00:00:51,280 --> 00:00:52,910
which is a cloud native a publicly traded

19
00:00:52,910 --> 00:00:55,010
cloud native company, and part of that

20
00:00:55,010 --> 00:00:57,780
I was CISO at GE Healthcare.

21
00:00:57,780 --> 00:01:02,780
Along the way, I got very
interested in how can I optimize

22
00:01:03,310 --> 00:01:05,790
my finding the bad guys, right?

23
00:01:05,790 --> 00:01:08,940
And what I realized along
the way was the best thing

24
00:01:08,940 --> 00:01:11,429
I can do is make sure I'm
getting the best technology.

25
00:01:11,430 --> 00:01:13,730
This is on top of already
having great teams.

26
00:01:13,730 --> 00:01:15,740
And when it came to having
the best technology,

27
00:01:15,740 --> 00:01:18,580
the question was, how do I optimize that?

28
00:01:18,580 --> 00:01:20,590
How do I go about making
the best decisions?

29
00:01:20,590 --> 00:01:23,580
And what I realized was that it was really

30
00:01:23,580 --> 00:01:25,260
about return on investment.

31
00:01:25,260 --> 00:01:27,700
And what I mean by that
is return on investment

32
00:01:27,700 --> 00:01:29,680
in terms of the spend the dollars,

33
00:01:29,680 --> 00:01:31,540
really in relationship
to the effectiveness

34
00:01:31,540 --> 00:01:33,470
of the products, right?

35
00:01:33,470 --> 00:01:35,740
And then it dawned on
me, how could I do that

36
00:01:35,740 --> 00:01:38,449
as efficiently as possible?

37
00:01:38,450 --> 00:01:42,280
And what I mean by efficiently
was how can I learn

38
00:01:42,280 --> 00:01:45,720
and actually have two products
compete one against another,

39
00:01:45,720 --> 00:01:49,060
and within maybe a month,
maybe a week or sometimes

40
00:01:49,060 --> 00:01:51,940
and you'll see later, maybe
even a day come to a conclusion

41
00:01:51,940 --> 00:01:53,620
with a small amount of data

42
00:01:53,620 --> 00:01:56,220
and honestly a lot of uncertainty.

43
00:01:56,220 --> 00:01:57,880
And so that's what I'm gonna
walk you through today.

44
00:01:57,880 --> 00:02:00,850
How do you control really
software defined attack surface?

45
00:02:00,850 --> 00:02:03,530
And I'll talk more about
that with making the best

46
00:02:03,530 --> 00:02:05,330
technology decisions possible.

47
00:02:05,330 --> 00:02:06,740
So let's talk a little bit about

48
00:02:06,740 --> 00:02:07,920
software defined attack surface

49
00:02:07,920 --> 00:02:09,680
before I get really into the slides.

50
00:02:09,680 --> 00:02:13,830
So, my last two CISO jobs,
I was actually working

51
00:02:13,830 --> 00:02:15,340
in cloud native environments.

52
00:02:15,340 --> 00:02:17,200
So what is cloud native?

53
00:02:17,200 --> 00:02:20,280
Cloud native is what allows developers

54
00:02:20,280 --> 00:02:22,580
to release code really rapidly.

55
00:02:22,580 --> 00:02:26,020
So maybe you were doing
100 or 1000 releases a year

56
00:02:26,020 --> 00:02:28,286
previously, now you're able to do 10,000

57
00:02:28,286 --> 00:02:29,220
or 100,000 or more.

58
00:02:29,220 --> 00:02:31,080
So, the first cloud native
company I worked for

59
00:02:31,080 --> 00:02:34,290
was doing over five years
ago, 30,000 releases a year.

60
00:02:34,290 --> 00:02:35,799
They're a cloud native company,

61
00:02:35,800 --> 00:02:39,470
and what I realized was that
it was absolutely critical

62
00:02:39,470 --> 00:02:41,800
that I had the best
investments in technology,

63
00:02:41,800 --> 00:02:44,270
particularly when it came
to vulnerability management,

64
00:02:44,270 --> 00:02:47,150
specifically dealing with web
application vulnerabilities

65
00:02:47,150 --> 00:02:48,950
and API vulnerabilities.

66
00:02:48,950 --> 00:02:51,750
So the use case I wanna
talk to you today through

67
00:02:51,750 --> 00:02:55,600
is how to go about measuring
and making the best decisions

68
00:02:55,600 --> 00:02:58,579
when you're confronted with
a similar sort of scenario

69
00:02:58,580 --> 00:03:02,680
and how you go about doing
really quick data science

70
00:03:02,680 --> 00:03:04,491
to make the best decisions.

71
00:03:04,491 --> 00:03:06,520
(mumbles) here we go, all right, have fun.

72
00:03:06,520 --> 00:03:09,410
First of all, this talk is
gonna be somewhat technical

73
00:03:09,410 --> 00:03:12,010
and I went ahead and wrote
a whole tutorial for you.

74
00:03:12,010 --> 00:03:13,640
So if you go to this blog post,

75
00:03:13,640 --> 00:03:16,420
you go to the soluble
dot ai site, hit blogs,

76
00:03:16,420 --> 00:03:18,880
you'll see the blog post for this.

77
00:03:18,880 --> 00:03:20,820
It's long, so it's over 3000 words,

78
00:03:20,820 --> 00:03:23,310
so I warn you about that,
but there's code inside

79
00:03:23,310 --> 00:03:25,100
there's a link to a
whole set of code there,

80
00:03:25,100 --> 00:03:25,933
and it's really easy.

81
00:03:25,933 --> 00:03:27,620
You don't need to know
how to use software,

82
00:03:27,620 --> 00:03:29,470
you really don't need
to know how to do math

83
00:03:29,470 --> 00:03:31,840
or data science, I make
it really easy for you.

84
00:03:31,840 --> 00:03:33,770
So again, I'm gonna
give you the highlights,

85
00:03:33,770 --> 00:03:35,230
show you how to think about this,

86
00:03:35,230 --> 00:03:38,690
but you can go ahead and
run this all your self.

87
00:03:38,690 --> 00:03:40,840
So, all right, this is where we start.

88
00:03:40,840 --> 00:03:42,850
There's gonna be three
steps, and the first one

89
00:03:42,850 --> 00:03:45,670
I'm calling believe
therefore I measure, right?

90
00:03:45,670 --> 00:03:47,720
And it's an approach to
reducing attack surface

91
00:03:47,720 --> 00:03:49,430
by reducing errors.

92
00:03:49,430 --> 00:03:52,700
So what do I mean by
believe therefore I measure?

93
00:03:52,700 --> 00:03:53,970
Well, Daniel Kahneman,

94
00:03:53,970 --> 00:03:55,710
I don't know if you guys know who he is,

95
00:03:55,710 --> 00:03:58,690
he won the Nobel Prize in 2003.

96
00:03:58,690 --> 00:04:01,290
He's a decision psychologist,
there's such a thing

97
00:04:01,290 --> 00:04:03,380
decision psychologist, he's one of them.

98
00:04:03,380 --> 00:04:07,690
He won the Nobel Prize in
2003 as an economist though.

99
00:04:07,690 --> 00:04:08,523
Actually he's not an economist,

100
00:04:08,523 --> 00:04:11,990
he's a decision psychologist,
but he won it for work

101
00:04:11,990 --> 00:04:13,620
as related to being an economist

102
00:04:13,620 --> 00:04:16,940
and most of the work he does
in many ways is around beliefs,

103
00:04:16,940 --> 00:04:18,630
around calibrating your beliefs

104
00:04:18,630 --> 00:04:21,240
and being really better
at making decisions

105
00:04:21,240 --> 00:04:23,140
while you're dealing with
a lot of uncertainty.

106
00:04:23,140 --> 00:04:26,039
So that's what we're gonna do here, okay?

107
00:04:26,040 --> 00:04:29,740
So first step, listen,
when you are a CISO,

108
00:04:29,740 --> 00:04:32,280
you are totally outgunned by engineering.

109
00:04:32,280 --> 00:04:34,979
The normal organization you're
talking typically 100:1.

110
00:04:34,980 --> 00:04:36,710
When you get into cloud native scenarios,

111
00:04:36,710 --> 00:04:39,159
you're talking about much more than 100:1,

112
00:04:39,160 --> 00:04:41,170
and you're gonna have a little time

113
00:04:41,170 --> 00:04:43,130
and you're gonna have a little budget

114
00:04:43,130 --> 00:04:44,610
and a little bit of data, right?

115
00:04:44,610 --> 00:04:46,160
You're gonna be working lean.

116
00:04:46,160 --> 00:04:49,310
And so the first steps is, how
do I go about thinking about

117
00:04:49,310 --> 00:04:51,610
reducing my external
facing vulnerabilities.

118
00:04:51,610 --> 00:04:55,580
Again, you're dealing with
100, maybe 200, 500:1.

119
00:04:55,580 --> 00:04:57,789
You have developers who are producing

120
00:04:57,790 --> 00:05:00,750
possibly like my example,
tens of thousands

121
00:05:00,750 --> 00:05:02,220
of releases a year.

122
00:05:02,220 --> 00:05:05,730
So the thing is, how do
you go about deciding on

123
00:05:05,730 --> 00:05:06,730
what's the best solution?

124
00:05:06,730 --> 00:05:08,130
Let's say you're given two opportunities.

125
00:05:08,130 --> 00:05:09,890
You're going to do a
proof of concept, right?

126
00:05:09,890 --> 00:05:12,190
You're gonna take a week or
a month to test two products.

127
00:05:12,190 --> 00:05:14,420
You're gonna point them
at the same solution,

128
00:05:14,420 --> 00:05:17,210
and you're gonna want to
measure the errors, right?

129
00:05:17,210 --> 00:05:18,810
So how do we go about doing that?

130
00:05:18,810 --> 00:05:20,720
So, first of all we're gonna start with

131
00:05:20,720 --> 00:05:22,340
measuring your beliefs.

132
00:05:22,340 --> 00:05:23,369
Now (mumbles).

133
00:05:23,370 --> 00:05:25,830
You may think that that's a strange thing.

134
00:05:25,830 --> 00:05:27,950
If you feel that way, then
you're probably normal,

135
00:05:27,950 --> 00:05:28,830
so don't worry.

136
00:05:28,830 --> 00:05:31,359
But again, we go back to
Kahneman's work and others,

137
00:05:31,360 --> 00:05:33,050
and if you look at my first book actually,

138
00:05:33,050 --> 00:05:34,550
we go about this in detail.

139
00:05:34,550 --> 00:05:36,570
How do you go about measuring your beliefs

140
00:05:36,570 --> 00:05:37,610
and why would we wanna do that?

141
00:05:37,610 --> 00:05:39,680
Well, first of all, you're probably clear

142
00:05:39,680 --> 00:05:43,670
that in terms of errors,
that is false positives

143
00:05:43,670 --> 00:05:45,790
and false negatives, you're
probably pretty clear

144
00:05:45,790 --> 00:05:48,660
that your product or any
product doesn't produce errors

145
00:05:48,660 --> 00:05:51,060
100% of the time all the time.

146
00:05:51,060 --> 00:05:53,270
If that was the case,
nobody would be buying

147
00:05:53,270 --> 00:05:54,710
vulnerability management solutions.

148
00:05:54,710 --> 00:05:57,039
You're also probably
experienced enough to know

149
00:05:57,040 --> 00:06:00,180
that zero is also not use case, right?

150
00:06:00,180 --> 00:06:03,177
You probably have enough
experience to have a vague idea

151
00:06:03,177 --> 00:06:04,480
of the vulnerability rates,

152
00:06:04,480 --> 00:06:05,550
particularly who've been
doing this for a while.

153
00:06:05,550 --> 00:06:07,020
I've been doing it for well over 20 years,

154
00:06:07,020 --> 00:06:08,560
and I have a pretty good idea

155
00:06:08,560 --> 00:06:09,900
of what the vulnerability rates are.

156
00:06:09,900 --> 00:06:11,330
I don't have a perfect idea,

157
00:06:11,330 --> 00:06:13,823
but I have some ideas, all right?

158
00:06:17,750 --> 00:06:20,120
So, we're gonna quantify your beliefs,

159
00:06:20,120 --> 00:06:21,140
and we're gonna require

160
00:06:21,140 --> 00:06:23,419
two probabilities from you, all right?

161
00:06:23,420 --> 00:06:24,570
Now, I'm gonna show you an example,

162
00:06:24,570 --> 00:06:25,960
so I'll use some technical terms here,

163
00:06:25,960 --> 00:06:27,390
but I'll walk you through it.

164
00:06:27,390 --> 00:06:30,159
The first one is your median error rate.

165
00:06:30,160 --> 00:06:32,550
The second one is your 90% boundary rates.

166
00:06:32,550 --> 00:06:34,300
Again, if you don't know what those mean,

167
00:06:34,300 --> 00:06:35,990
don't worry about it, right?

168
00:06:35,990 --> 00:06:39,230
So let's assume we're talking to

169
00:06:39,230 --> 00:06:42,170
a well-informed practitioner,
they're security practitioner,

170
00:06:42,170 --> 00:06:44,030
and they actually know
what these words mean.

171
00:06:44,030 --> 00:06:45,200
What might they say?

172
00:06:45,200 --> 00:06:49,469
They might say, well, our
median error rate is 25%.

173
00:06:49,470 --> 00:06:51,900
And what I mean to say
is that the true rate

174
00:06:51,900 --> 00:06:56,320
is just as likely to be
below 25% or is above.

175
00:06:56,320 --> 00:06:57,460
So what they're kinda saying is,

176
00:06:57,460 --> 00:07:00,280
it kinda teeters around this 25% mark

177
00:07:00,280 --> 00:07:01,116
and it kinda moves around there.

178
00:07:01,117 --> 00:07:03,340
If you don't know exactly what it is,

179
00:07:03,340 --> 00:07:04,340
you're kind of ambivalent,

180
00:07:04,340 --> 00:07:06,580
it's either below or above, all right?

181
00:07:06,580 --> 00:07:08,022
Then the next question is,

182
00:07:09,400 --> 00:07:11,250
in terms of their 90% boundary rate,

183
00:07:11,250 --> 00:07:13,790
and all they're trying
to say here is that,

184
00:07:13,790 --> 00:07:15,040
I'm confident, I'm pretty confident,

185
00:07:15,040 --> 00:07:16,490
it's at 45% or below.

186
00:07:16,490 --> 00:07:18,620
And it could be a little
bit over, I don't know,

187
00:07:18,620 --> 00:07:19,453
but you know what,

188
00:07:19,453 --> 00:07:22,460
I bet you most of the time
it's below that number.

189
00:07:22,460 --> 00:07:25,690
That's all know, I'm not sure, right?

190
00:07:25,690 --> 00:07:28,350
So after all, I have never
in my life experienced

191
00:07:28,350 --> 00:07:31,040
a 50% error rate, by the
way, I have never experienced

192
00:07:31,040 --> 00:07:33,510
in a real product that
I've actually bought

193
00:07:33,510 --> 00:07:35,110
a 50% error rate.

194
00:07:35,110 --> 00:07:37,350
I've seen some error rates
that are pretty close to that

195
00:07:37,350 --> 00:07:40,650
but I've actually never
experienced that myself, all right?

196
00:07:40,650 --> 00:07:44,301
So, if you were to go to my
blog and you were to download

197
00:07:44,302 --> 00:07:47,270
(mumbles) code, which
is all free given to you

198
00:07:47,270 --> 00:07:50,530
and by the way, excuse the
errors if there are any,

199
00:07:50,530 --> 00:07:52,719
you have a very simple
configuration that you just enter

200
00:07:52,720 --> 00:07:54,330
you enter the two numbers, all right?

201
00:07:54,330 --> 00:07:56,380
And don't worry if you don't
know about the exact numbers,

202
00:07:56,380 --> 00:07:58,190
this is not about being exact.

203
00:07:58,190 --> 00:07:59,650
By the way, it's all written in R

204
00:07:59,650 --> 00:08:03,590
that's why you see the R
t-shirt there go R all right?

205
00:08:03,590 --> 00:08:06,690
So if you do that and you
end up writing the code,

206
00:08:06,690 --> 00:08:08,890
you're gonna get a graph
that looks like this, right?

207
00:08:08,890 --> 00:08:11,950
And that graph represents
both our uncertainty

208
00:08:11,950 --> 00:08:12,849
and our certainty.

209
00:08:12,850 --> 00:08:15,370
And we're actually pretty uncertain.

210
00:08:15,370 --> 00:08:16,900
And in fact, if that graph could speak,

211
00:08:16,900 --> 00:08:18,676
it would say something like this,

212
00:08:18,677 --> 00:08:22,260
"Given your beliefs, you should
expect that the true rate

213
00:08:22,260 --> 00:08:26,530
is likely somewhere between 6% and 56%."

214
00:08:26,530 --> 00:08:28,520
We're not saying that it's actually there,

215
00:08:28,520 --> 00:08:30,289
we're saying it's probably there.

216
00:08:30,290 --> 00:08:32,669
And if you were to be
forced to make a bet today,

217
00:08:32,669 --> 00:08:34,549
you'd probably wanna bet
in somewhere in there.

218
00:08:34,549 --> 00:08:36,349
In fact, you probably want
to be betting somewhere

219
00:08:36,350 --> 00:08:39,020
close to where the amount of data

220
00:08:39,020 --> 00:08:41,079
seems to be the densest, all right?

221
00:08:41,080 --> 00:08:43,900
All right, so next,
you've got your beliefs.

222
00:08:43,900 --> 00:08:46,010
Now we're gonna collect real data

223
00:08:46,010 --> 00:08:48,200
and we're gonna munge the belief data

224
00:08:48,200 --> 00:08:51,730
you just created with
your actual empirical data

225
00:08:51,730 --> 00:08:53,140
coming from your tests.

226
00:08:53,140 --> 00:08:55,140
So let's walk through that, all right?

227
00:08:55,140 --> 00:08:56,960
So there's your beliefs, right?

228
00:08:56,960 --> 00:08:59,070
We're gonna take that and
we're gonna actually add it

229
00:08:59,070 --> 00:08:59,903
to some real data.

230
00:08:59,903 --> 00:09:00,736
So let me explain this here.

231
00:09:00,736 --> 00:09:02,319
Again that's R, if you go into the code,

232
00:09:02,320 --> 00:09:03,290
you'll see that there.

233
00:09:03,290 --> 00:09:05,459
Now the first number there at 100,000

234
00:09:05,460 --> 00:09:06,910
that has to do with simulations.

235
00:09:06,910 --> 00:09:08,130
I'll talk about that in a moment,

236
00:09:08,130 --> 00:09:10,570
but we're gonna run this
thing 100,000 times.

237
00:09:10,570 --> 00:09:12,580
It's pretty awesome, you could
do it 1,000,000 times too.

238
00:09:12,580 --> 00:09:15,040
You can change its
configuration, all right?

239
00:09:15,040 --> 00:09:17,339
So you're testing actually two products.

240
00:09:17,340 --> 00:09:18,850
You have them under proof of concept,

241
00:09:18,850 --> 00:09:19,950
and let's say, you're just gonna have them

242
00:09:19,950 --> 00:09:21,310
run the background for a months

243
00:09:21,310 --> 00:09:23,390
against the same set of applications.

244
00:09:23,390 --> 00:09:25,763
In this case, one of the tools

245
00:09:25,763 --> 00:09:28,960
produces 30 critical vulnerabilities,

246
00:09:28,960 --> 00:09:31,060
kinds that you would normally wanna fix.

247
00:09:31,060 --> 00:09:32,310
it thinks there's 30 of them.

248
00:09:32,310 --> 00:09:33,517
The other tool happens to
think there's 37, right?

249
00:09:33,518 --> 00:09:36,110
So again, at the end of the month,

250
00:09:36,110 --> 00:09:38,800
if you collect that, let's
say you're looking for

251
00:09:38,800 --> 00:09:41,270
CVSS10 or whatever it is
that you think is really

252
00:09:41,270 --> 00:09:44,319
important, pick your poison,
you're gonna select that.

253
00:09:44,320 --> 00:09:46,740
One says 3o, one says 37.

254
00:09:46,740 --> 00:09:49,610
You enter that here, all right?

255
00:09:49,610 --> 00:09:51,870
What's gonna happen when you
do the simulations though

256
00:09:51,870 --> 00:09:54,610
is you're gonna create really
what's a virtual reality.

257
00:09:54,610 --> 00:09:57,427
You're gonna create
100,000, actually 200,000,

258
00:09:57,427 --> 00:09:59,420
one for one product, one for other.

259
00:09:59,420 --> 00:10:02,900
So you have 200,000 scenarios, okay?

260
00:10:02,900 --> 00:10:04,199
So what happens next?

261
00:10:04,200 --> 00:10:05,700
You've run this thing a bunch of times,

262
00:10:05,700 --> 00:10:08,210
what is it doing behind the
scenes to (mumbles) the hood?

263
00:10:08,210 --> 00:10:10,690
It's gonna add these things
essentially together.

264
00:10:10,690 --> 00:10:12,120
So what does that look like?

265
00:10:12,120 --> 00:10:14,160
So first of all, your beliefs,

266
00:10:14,160 --> 00:10:16,353
it simulates 100,000 for product a

267
00:10:16,353 --> 00:10:18,390
and 100,000 for product b.

268
00:10:18,390 --> 00:10:20,710
When I say simulates,
it's actually picking out

269
00:10:20,710 --> 00:10:23,220
random values from under
that purple curve, right?

270
00:10:23,220 --> 00:10:24,920
And it's gonna pick more frequently

271
00:10:24,920 --> 00:10:26,170
from where it's most densest.

272
00:10:26,170 --> 00:10:28,569
So there you go, it spits
out a bunch of stuff.

273
00:10:28,570 --> 00:10:31,250
And then what's gonna happen
is you're going to say,

274
00:10:31,250 --> 00:10:34,150
all right, given my beliefs,
given this purple curve

275
00:10:34,150 --> 00:10:37,709
and given, let's say
for product a 30 events,

276
00:10:37,710 --> 00:10:42,540
what does our model think is
potential probable error rates.

277
00:10:42,540 --> 00:10:43,800
And that's what you see here,

278
00:10:43,800 --> 00:10:46,370
there's a model that's
gonna generate 100,000

279
00:10:46,370 --> 00:10:47,750
potential errors, right?

280
00:10:47,750 --> 00:10:49,640
And then some do the
same thing for product B

281
00:10:49,640 --> 00:10:52,610
which actually has 37
events, 37 vulnerabilities

282
00:10:52,610 --> 00:10:54,650
but how much of that is actually errors,

283
00:10:54,650 --> 00:10:57,750
meaning false positives
and false negatives.

284
00:10:57,750 --> 00:10:59,790
Again, it's just simulating.

285
00:10:59,790 --> 00:11:03,882
It's like really low touch,
very naive data science.

286
00:11:03,883 --> 00:11:06,200
Again, the blog post goes into this

287
00:11:06,200 --> 00:11:08,513
in a lot of detail, all right?

288
00:11:09,480 --> 00:11:11,810
So what happens next?

289
00:11:11,810 --> 00:11:14,410
So next, we're actually going to go

290
00:11:14,410 --> 00:11:16,089
and collect our errors, right?

291
00:11:16,090 --> 00:11:17,760
So, it's end of month or of week,

292
00:11:17,760 --> 00:11:20,110
however long your test is
you're gonna have errors,

293
00:11:20,110 --> 00:11:22,260
By the way, you're gonna
be still sort of uncertain

294
00:11:22,260 --> 00:11:23,093
about your errors.

295
00:11:23,093 --> 00:11:24,880
You'll have false
positives, and by the way,

296
00:11:24,880 --> 00:11:26,030
when you look at them,

297
00:11:26,030 --> 00:11:27,140
you'll probably be able to discover them

298
00:11:27,140 --> 00:11:28,396
or maybe development comes back and says,

299
00:11:28,397 --> 00:11:30,270
"Hey, this stuff's unreal."

300
00:11:30,270 --> 00:11:31,569
And you'll have false negatives.

301
00:11:31,570 --> 00:11:34,010
Now, false negatives often times can be

302
00:11:34,010 --> 00:11:36,310
from competing one product from the other.

303
00:11:36,310 --> 00:11:38,560
And the code actually
helps you figure that out,

304
00:11:38,560 --> 00:11:39,849
and sometimes you'll find out about

305
00:11:39,850 --> 00:11:41,970
false negatives later, right?

306
00:11:41,970 --> 00:11:43,750
We're highly uncertain, that's okay.

307
00:11:43,750 --> 00:11:46,910
We're Bayesians what you
learn more about a moment,

308
00:11:46,910 --> 00:11:49,140
we're gonna go ahead
and feel free and easy

309
00:11:49,140 --> 00:11:50,350
with uncertainty.

310
00:11:50,350 --> 00:11:51,890
Again, we're not looking for perfect,

311
00:11:51,890 --> 00:11:53,430
we're looking for better, all right?

312
00:11:53,430 --> 00:11:56,160
So, what happens now is
you have all this data.

313
00:11:56,160 --> 00:11:58,319
Remember the 100,000, what
you're gonna do now is

314
00:11:58,320 --> 00:12:00,000
you're gonna filter away everything

315
00:12:00,000 --> 00:12:03,300
that's not 10 for product a
or 13 for product B, right?

316
00:12:03,300 --> 00:12:04,939
You're gonna be left with several thousand

317
00:12:04,940 --> 00:12:06,500
result sets, right?

318
00:12:06,500 --> 00:12:08,970
And then what's gonna happen
with those results actually

319
00:12:08,970 --> 00:12:10,230
we tell you what you just did here.

320
00:12:10,230 --> 00:12:13,980
This is actually called an
Approximate Bayesian Computation.

321
00:12:13,980 --> 00:12:15,970
That's a really fancy word for something

322
00:12:15,970 --> 00:12:17,060
that's really simple.

323
00:12:17,060 --> 00:12:20,569
Basically all we did is we
filtered away the results sets

324
00:12:20,570 --> 00:12:23,930
that didn't represent the
actual errors sets we got.

325
00:12:23,930 --> 00:12:27,900
So our belief is there's
some random generative model

326
00:12:27,900 --> 00:12:31,500
or generative process that's
operating in the background

327
00:12:31,500 --> 00:12:33,450
and it's producing these results.

328
00:12:33,450 --> 00:12:35,210
We're, highly uncertain, we don't know

329
00:12:35,210 --> 00:12:37,000
but we think there's some vague process.

330
00:12:37,000 --> 00:12:38,650
We're trying to model that process,

331
00:12:38,650 --> 00:12:40,689
we're trying to model
the generative process

332
00:12:40,690 --> 00:12:41,780
that's running the background.

333
00:12:41,780 --> 00:12:44,490
That's Approximate Bayesian Computation.

334
00:12:44,490 --> 00:12:45,560
Look it up.

335
00:12:45,560 --> 00:12:46,780
There's more information on the web

336
00:12:46,780 --> 00:12:48,170
than you can shake a stick at.

337
00:12:48,170 --> 00:12:50,270
All right, so what we end up doing then

338
00:12:50,270 --> 00:12:53,180
from the ABC process, we
then take those results,

339
00:12:53,180 --> 00:12:54,949
we filtered down remember it
might have several hundred,

340
00:12:54,950 --> 00:12:56,320
several thousand that are left.

341
00:12:56,320 --> 00:12:58,090
We're then going to simulate.

342
00:12:58,090 --> 00:12:59,800
Simulation means we're just gonna generate

343
00:12:59,800 --> 00:13:02,727
a bunch of extra data from
the data that we have.

344
00:13:02,727 --> 00:13:04,829
And what we're gonna do
is actually get 10,000

345
00:13:04,830 --> 00:13:06,660
results in each case, right?

346
00:13:06,660 --> 00:13:10,010
So it's gonna end up
being two chunks of data,

347
00:13:10,010 --> 00:13:11,430
really almost thinking of them

348
00:13:11,430 --> 00:13:13,040
is like two separate databases.

349
00:13:13,040 --> 00:13:14,469
And now we're gonna ask some questions.

350
00:13:14,470 --> 00:13:16,420
Again, the question we're
trying to get at is,

351
00:13:16,420 --> 00:13:21,140
what is the underlying probable error rate

352
00:13:21,140 --> 00:13:23,370
for product a product B?

353
00:13:23,370 --> 00:13:24,690
You can see the results here.

354
00:13:24,690 --> 00:13:26,190
Listen, if you want just one number,

355
00:13:26,190 --> 00:13:28,640
apparently the model which is filled with

356
00:13:28,640 --> 00:13:31,760
our assumptions and filled
with tiny uncertain data

357
00:13:31,760 --> 00:13:34,260
the model seems to think that product a

358
00:13:34,260 --> 00:13:36,020
has a 33% error rate.

359
00:13:36,020 --> 00:13:38,020
Again, it's not the correct error rate,

360
00:13:38,020 --> 00:13:39,890
It's just what this model things, right?

361
00:13:39,890 --> 00:13:42,561
And product B seems to think
there's a 34% error rate.

362
00:13:42,561 --> 00:13:44,510
There's some various,
you can see the variance

363
00:13:44,510 --> 00:13:45,950
actually this is a credible interval.

364
00:13:45,950 --> 00:13:47,350
It's actually the highest density,

365
00:13:47,350 --> 00:13:50,070
it's HDI, highest density
in interval for you

366
00:13:50,070 --> 00:13:51,840
statisticians out there, you Bayesians,

367
00:13:51,840 --> 00:13:53,510
but this is what the model things.

368
00:13:53,510 --> 00:13:55,689
So let's take it a step
further, all right?

369
00:13:55,690 --> 00:13:56,670
Let's look at some graphs.

370
00:13:56,670 --> 00:14:00,479
The graph of the product a
data that we just simulated

371
00:14:00,480 --> 00:14:03,140
is on top and product B is on the bottom.

372
00:14:03,140 --> 00:14:06,400
They look almost identical
product a looks like it creates

373
00:14:06,400 --> 00:14:08,360
a little bit less errors.

374
00:14:08,360 --> 00:14:10,370
Let's actually model these
one on top of another.

375
00:14:10,370 --> 00:14:12,200
It's always fun to take
graphs and play with them

376
00:14:12,200 --> 00:14:14,140
and look at them from
different ways, right?

377
00:14:14,140 --> 00:14:15,960
That's different, we
can see some information

378
00:14:15,960 --> 00:14:19,200
that looks again, like product
B may be creating more error.

379
00:14:19,200 --> 00:14:20,530
We're highly uncertain.

380
00:14:20,530 --> 00:14:24,410
They're really overlapping,
and here's another view.

381
00:14:24,410 --> 00:14:27,920
We're actually going to
subtract the rates of error B

382
00:14:27,920 --> 00:14:30,010
from error rate a and what we see

383
00:14:30,010 --> 00:14:31,915
is more negative data, right?

384
00:14:31,916 --> 00:14:33,200
If you look at the
product different events

385
00:14:33,200 --> 00:14:34,900
on the right hand side,
you look at the graph,

386
00:14:34,900 --> 00:14:37,380
you see there's a little more
data shifting to the left

387
00:14:37,380 --> 00:14:39,030
that just tells us that product B seems

388
00:14:39,030 --> 00:14:40,930
to be creating more errors.

389
00:14:40,930 --> 00:14:44,069
Again, it's simulated,
we're highly uncertain,

390
00:14:44,070 --> 00:14:45,750
we're not sure, okay?

391
00:14:45,750 --> 00:14:48,190
So now we're gonna take
that data and we're gonna

392
00:14:48,190 --> 00:14:49,200
munge that data.

393
00:14:49,200 --> 00:14:52,270
Again, we had our beliefs,
we took some empirical data

394
00:14:52,270 --> 00:14:54,120
and now we're gonna munge that together

395
00:14:54,120 --> 00:14:56,453
actually with some financial data.

396
00:14:57,430 --> 00:14:58,599
Isn't this exciting?

397
00:14:58,600 --> 00:15:00,120
All right, here we go.

398
00:15:00,120 --> 00:15:04,320
So this is really me
being lazy, by the way,

399
00:15:04,320 --> 00:15:07,090
I recommend you to be lazy when possible.

400
00:15:07,090 --> 00:15:09,350
Developers are very lazy, I
got my start as a developer

401
00:15:09,350 --> 00:15:14,000
and now I'm a really a lazy
data scientist, CISO CEO, right?

402
00:15:14,000 --> 00:15:18,780
So what we see here is a
model of what I think is

403
00:15:18,780 --> 00:15:22,079
the range of hours that it
takes to address an error.

404
00:15:22,080 --> 00:15:24,700
So when it comes to a
critical, false positive,

405
00:15:24,700 --> 00:15:26,080
we don't know it's a false positive yet,

406
00:15:26,080 --> 00:15:28,090
we need to go through
and do some analysis.

407
00:15:28,090 --> 00:15:30,420
We look at the results,
the security person,

408
00:15:30,420 --> 00:15:32,250
I may need to go talk to a service owner,

409
00:15:32,250 --> 00:15:34,280
I may need to talk to
a developer and again,

410
00:15:34,280 --> 00:15:35,680
if this is a critical vulnerability,

411
00:15:35,680 --> 00:15:37,430
I imagine it's gonna take some time.

412
00:15:37,430 --> 00:15:39,500
I'm kinda thinking it's
roughly around two hours,

413
00:15:39,500 --> 00:15:40,750
it could be as low as one hour,

414
00:15:40,750 --> 00:15:42,160
it could be as much as five, right?

415
00:15:42,160 --> 00:15:44,569
So, but it's, it's kind of fluctuating

416
00:15:44,570 --> 00:15:48,050
and moving around in that space, vaguely

417
00:15:48,050 --> 00:15:49,120
and the same with cost.

418
00:15:49,120 --> 00:15:51,440
model cost here for
California and the Bay area

419
00:15:51,440 --> 00:15:54,020
I'm saying, yeah I believe
it's going to be two people

420
00:15:54,020 --> 00:15:55,530
participating, it's going to be kinda

421
00:15:55,530 --> 00:15:57,100
somewhere around 600 bucks.

422
00:15:57,100 --> 00:15:58,190
This is fully loaded, right?

423
00:15:58,190 --> 00:16:00,150
Like in terms of salaries, right?

424
00:16:00,150 --> 00:16:03,439
With taking into consideration
benefits and real estate

425
00:16:03,440 --> 00:16:05,970
and whatnot and I think
it could be as low as 200

426
00:16:05,970 --> 00:16:08,250
and as high as 2000 give or take, right?

427
00:16:08,250 --> 00:16:12,610
So again, I have some fluctuating,
vague idea of the hours

428
00:16:12,610 --> 00:16:15,400
per incident, be it false
positive, false negative,

429
00:16:15,400 --> 00:16:18,270
and I have some idea of the costs.

430
00:16:18,270 --> 00:16:19,720
All right, so what are we gonna do?

431
00:16:19,720 --> 00:16:21,510
Actually multiply this altogether.

432
00:16:21,510 --> 00:16:23,689
So again, we have those
rates in the left hand side

433
00:16:23,690 --> 00:16:25,210
here, the rates product, a product B.

434
00:16:25,210 --> 00:16:28,620
Again, those are some
variation or distribution

435
00:16:28,620 --> 00:16:30,510
of error rates that we simulate.

436
00:16:30,510 --> 00:16:33,540
We're then gonna multiply
that together with the hours

437
00:16:33,540 --> 00:16:36,380
and with the costs and we
come up with some impacts.

438
00:16:36,380 --> 00:16:40,520
And these are the expected,
value of impacts, right?

439
00:16:40,520 --> 00:16:42,540
It's not the actual impact, right?

440
00:16:42,540 --> 00:16:43,439
This is only a model.

441
00:16:43,440 --> 00:16:45,330
I mean, think about this,
if you have your phone,

442
00:16:45,330 --> 00:16:48,670
you have a map up and
it's a map from your home

443
00:16:48,670 --> 00:16:49,997
to the restaurant you want me to go to

444
00:16:49,997 --> 00:16:52,860
and you were to go outside
and compare that map

445
00:16:52,860 --> 00:16:55,250
to the actual concrete,
you'd be pretty dissatisfied

446
00:16:55,250 --> 00:16:57,150
if your expectation is
that maps supposedly

447
00:16:57,150 --> 00:16:58,430
look like the concrete.

448
00:16:58,430 --> 00:17:00,270
That's not your goal, your
goal is actually to make sure

449
00:17:00,270 --> 00:17:01,770
you go from point a to point B,

450
00:17:01,770 --> 00:17:03,360
and that's what we're trying to do here.

451
00:17:03,360 --> 00:17:05,119
We're trying to be a
little more informed about

452
00:17:05,119 --> 00:17:06,859
how we get from point a to point B.

453
00:17:06,859 --> 00:17:09,899
So we have product a in
parts and product B in parts.

454
00:17:09,900 --> 00:17:11,950
The reality is, we have
a whole distribution

455
00:17:11,950 --> 00:17:13,579
mountain of data for each of these

456
00:17:13,579 --> 00:17:15,939
and we can go ahead and do
all kinds of interesting

457
00:17:15,940 --> 00:17:17,050
analytics that we want.

458
00:17:17,050 --> 00:17:18,780
I'm making it easy for
you, I've picked a number

459
00:17:18,780 --> 00:17:21,020
that's called the expected value.

460
00:17:21,020 --> 00:17:23,819
It's a way to be
mathematically unambiguous

461
00:17:23,819 --> 00:17:26,419
and consistent when we go
about comparing things.

462
00:17:26,420 --> 00:17:28,319
But again, we're not
taking a map and saying

463
00:17:28,319 --> 00:17:30,419
that's the road exactly.

464
00:17:30,420 --> 00:17:33,700
So, let's go ahead and
take those expected values

465
00:17:33,700 --> 00:17:34,810
and compare them to one another.

466
00:17:34,810 --> 00:17:35,643
And guess what?

467
00:17:35,643 --> 00:17:37,650
Hey, they look almost identical.

468
00:17:37,650 --> 00:17:38,870
They're not exactly identical,

469
00:17:38,870 --> 00:17:41,469
but from a visual perspective,
they look pretty darn close.

470
00:17:41,470 --> 00:17:44,020
So, let's go ahead and see
what our month one scenario.

471
00:17:44,020 --> 00:17:45,300
Again, we let these two things

472
00:17:45,300 --> 00:17:47,081
just go at it in the background,

473
00:17:47,082 --> 00:17:49,680
or we can actually run automatically,

474
00:17:49,680 --> 00:17:52,850
the R could be hooked up to
your JIRA system or ServiceNow

475
00:17:52,850 --> 00:17:55,110
it can just run and
give you these results.

476
00:17:55,110 --> 00:17:57,060
It can give you results, by
the way, on a daily basis,

477
00:17:57,060 --> 00:18:00,020
you can do blow by blow if
you want minute by minute.

478
00:18:00,020 --> 00:18:02,920
Dealer's choice, but for product a,

479
00:18:02,920 --> 00:18:06,550
it looks like there's a 98.8%
chance of the total cost

480
00:18:06,550 --> 00:18:09,159
that a is the total cost of product B.

481
00:18:09,160 --> 00:18:12,660
It means a is in terms of costs and errors

482
00:18:12,660 --> 00:18:14,900
is gonna be a little less
than product B, right?

483
00:18:14,900 --> 00:18:16,523
It's not a lot by the way, right?

484
00:18:16,523 --> 00:18:21,523
It's 148, call it 149
versus 164,000, right?

485
00:18:21,970 --> 00:18:24,200
For most large companies,
that's a rounding error.

486
00:18:24,200 --> 00:18:26,380
I don't consider that
to be a real big deal.

487
00:18:26,380 --> 00:18:29,260
And by the way, it's not
reality, it's only a model.

488
00:18:29,260 --> 00:18:30,290
But if we had to make a decision,

489
00:18:30,290 --> 00:18:32,139
if you were forced to make a decision

490
00:18:32,140 --> 00:18:34,650
with all this uncertainty
with a little bit of time

491
00:18:34,650 --> 00:18:36,880
a little data, you might
make a bet this way.

492
00:18:36,880 --> 00:18:39,700
But hey, let's say that you are a company

493
00:18:39,700 --> 00:18:41,320
that's doing cloud native development

494
00:18:41,320 --> 00:18:44,970
and you are producing a lots
of vulnerabilities in a week.

495
00:18:44,970 --> 00:18:47,380
You could run this model, you'd
say it's the same data set,

496
00:18:47,380 --> 00:18:49,650
but instead of data set
that came over a month,

497
00:18:49,650 --> 00:18:52,130
it's a data set that came
actually over one week

498
00:18:52,130 --> 00:18:53,140
or seven days.

499
00:18:53,140 --> 00:18:54,890
In this case, we're starting to see

500
00:18:54,890 --> 00:18:55,890
a little more information.

501
00:18:55,890 --> 00:18:58,860
What we've done is, we've
actually created more data

502
00:18:58,860 --> 00:19:00,070
in a shorter period of time.

503
00:19:00,070 --> 00:19:01,540
By the way, when you have
a lot of uncertainty,

504
00:19:01,540 --> 00:19:03,830
how do you solve that problem typically?

505
00:19:03,830 --> 00:19:05,610
More data, that's kind
of what we've done here.

506
00:19:05,610 --> 00:19:09,973
So now you have an 81% chance
that a is the total cost of B

507
00:19:09,973 --> 00:19:12,520
meaning a is cheaper.

508
00:19:12,520 --> 00:19:16,493
So we're looking at
$372,000 versus $459,000.

509
00:19:17,570 --> 00:19:19,220
That's not real by the way, right?

510
00:19:19,220 --> 00:19:21,150
I don't expect that you're
gonna write a cheque.

511
00:19:21,150 --> 00:19:23,240
By the way, this is
forecasted over a year,

512
00:19:23,240 --> 00:19:24,650
I should have mentioned
that, sorry, I didn't,

513
00:19:24,650 --> 00:19:27,160
but this is forecasted over a year.

514
00:19:27,160 --> 00:19:29,420
I'm not saying that you're
gonna experience this

515
00:19:29,420 --> 00:19:32,150
as some sort of tax
where you write a cheque,

516
00:19:32,150 --> 00:19:33,750
you're looking to optimize.

517
00:19:33,750 --> 00:19:35,600
This is a way for you
to really to understand

518
00:19:35,600 --> 00:19:37,270
how much you're going to
impact your developers

519
00:19:37,270 --> 00:19:39,530
by the way, it's a way
for you to say, okay,

520
00:19:39,530 --> 00:19:41,129
if I'm looking to optimize,

521
00:19:41,130 --> 00:19:43,420
I'm looking to produce less errors

522
00:19:43,420 --> 00:19:45,930
and have overall less financial impact.

523
00:19:45,930 --> 00:19:48,840
I'm really looking to create
less drag from my team,

524
00:19:48,840 --> 00:19:49,673
my developers,

525
00:19:49,673 --> 00:19:51,540
I'm gonna say, "Hey look,
if this is your data,

526
00:19:51,540 --> 00:19:53,500
clearly you should go for product a."

527
00:19:53,500 --> 00:19:55,900
By the way, we're highly
uncertain, it's not the truth,

528
00:19:55,900 --> 00:19:59,010
but given only this
information, your beliefs

529
00:19:59,010 --> 00:20:00,403
I'd go with this, right?

530
00:20:01,380 --> 00:20:05,020
That being said, if you
have a really shiny product

531
00:20:05,020 --> 00:20:07,020
and it costs more but you're
super excited about it

532
00:20:07,020 --> 00:20:08,260
'cause you like to buy shiny things

533
00:20:08,260 --> 00:20:11,200
and the shiny thing
happens to be $460,000,

534
00:20:11,200 --> 00:20:12,460
then go for that.

535
00:20:12,460 --> 00:20:14,710
So let's say you work for one of those

536
00:20:14,710 --> 00:20:18,260
cloud native companies like I
did where they're doing 30,000

537
00:20:18,260 --> 00:20:20,480
releases a year, or
your worked for Airbnb,

538
00:20:20,480 --> 00:20:23,140
or you worked for Facebook or Netflix.

539
00:20:23,140 --> 00:20:25,480
Well, you might be able to
generate the same sort of data

540
00:20:25,480 --> 00:20:26,650
in one day.

541
00:20:26,650 --> 00:20:28,520
I don't think anyone would
ever do a proof of concept

542
00:20:28,520 --> 00:20:30,870
in one day I'd think you'd
probably want to do it

543
00:20:30,870 --> 00:20:32,087
for at least a week or a month,

544
00:20:32,087 --> 00:20:34,017
but if you did that, our model would say,

545
00:20:34,017 --> 00:20:36,490
"Hey, look, based on this air size,

546
00:20:36,490 --> 00:20:40,700
you're looking at this
differential in terms of impact."

547
00:20:40,700 --> 00:20:43,330
It's not real, it's only a model

548
00:20:43,330 --> 00:20:47,300
it's a mathematically
unambiguous and consistent way

549
00:20:47,300 --> 00:20:49,530
of comparing things, right?

550
00:20:49,530 --> 00:20:51,510
I'm not asking you to believe in it,

551
00:20:51,510 --> 00:20:54,400
but I'm asking you to consider
what the alternative is.

552
00:20:54,400 --> 00:20:57,250
The alternative, if the
alternative to something like this

553
00:20:57,250 --> 00:21:02,100
is your gut, your subject
matter expert opinion

554
00:21:02,100 --> 00:21:04,469
which is really your gut
what's going to happen is

555
00:21:04,470 --> 00:21:06,290
typically you're going to
end up probably choosing

556
00:21:06,290 --> 00:21:07,123
the shiny thing.

557
00:21:07,123 --> 00:21:09,020
That might be fine, that
might be your model.

558
00:21:09,020 --> 00:21:11,010
If you're looking for a
bit more, you can use this.

559
00:21:11,010 --> 00:21:12,400
So what have we learned?

560
00:21:12,400 --> 00:21:14,210
We've learned that you
can measure your beliefs.

561
00:21:14,210 --> 00:21:16,570
You can naively measure your beliefs.

562
00:21:16,570 --> 00:21:18,520
I'm gonna say that you know
something about security,

563
00:21:18,520 --> 00:21:19,800
you're a security expert.

564
00:21:19,800 --> 00:21:21,419
I'm gonna believe that you
actually know something

565
00:21:21,420 --> 00:21:23,280
about vulnerability error rates.

566
00:21:23,280 --> 00:21:25,870
If you think that anything
is always possible

567
00:21:25,870 --> 00:21:28,760
all the time is just
likely to be 100%, 0%,

568
00:21:28,760 --> 00:21:30,770
I'm gonna say that's a reflection of you

569
00:21:30,770 --> 00:21:32,820
not actually having any experience.

570
00:21:32,820 --> 00:21:34,340
That's fine.

571
00:21:34,340 --> 00:21:35,590
You shouldn't be doing this right.

572
00:21:35,590 --> 00:21:38,330
Second step is measuring actual errors

573
00:21:38,330 --> 00:21:39,627
and then munching those
together with beliefs.

574
00:21:39,627 --> 00:21:42,120
And we did that using a
simple Bayesian model.

575
00:21:42,120 --> 00:21:43,790
The third step is measuring costs.

576
00:21:43,790 --> 00:21:46,970
I used a hyper naive
model for measuring costs.

577
00:21:46,970 --> 00:21:50,060
We can go into a lot of
complexity for doing that.

578
00:21:50,060 --> 00:21:51,409
We chose not to do that here.

579
00:21:51,410 --> 00:21:53,990
We used some real simple inputs, right?

580
00:21:53,990 --> 00:21:58,630
And then my view or my belief
is lacking anything else,

581
00:21:58,630 --> 00:22:01,700
you can use the results
to inform your beliefs.

582
00:22:01,700 --> 00:22:04,500
You can use this model
for any sort of security

583
00:22:04,500 --> 00:22:05,333
product you like.

584
00:22:05,333 --> 00:22:06,680
I chose multi management,

585
00:22:06,680 --> 00:22:10,040
I chose to deal with
externally facing APIs

586
00:22:10,040 --> 00:22:11,570
and web applications vulnerabilities

587
00:22:11,570 --> 00:22:13,340
because that's something
that I deal with a lot

588
00:22:13,340 --> 00:22:15,090
and I have my whole career.

589
00:22:15,090 --> 00:22:18,000
But any sort of products you're
looking to proof of concept

590
00:22:18,000 --> 00:22:20,700
are gonna have errors, they're
gonna make mistakes again.

591
00:22:20,700 --> 00:22:23,410
You're looking for the
things that go right,

592
00:22:23,410 --> 00:22:24,960
all the stuff that actually works,

593
00:22:24,960 --> 00:22:26,570
that's the cost of doing business.

594
00:22:26,570 --> 00:22:29,560
You're concerned with
the things that go wrong,

595
00:22:29,560 --> 00:22:31,810
the things they miss, which creates risk,

596
00:22:31,810 --> 00:22:34,520
which creates breach,
or the false positives,

597
00:22:34,520 --> 00:22:35,910
which create extra work.

598
00:22:35,910 --> 00:22:37,580
Those are the things you wanna measure,

599
00:22:37,580 --> 00:22:40,699
and you can measure those at
ease using a model like this.

600
00:22:40,700 --> 00:22:42,440
That's all I have, I know I talk fast,

601
00:22:42,440 --> 00:22:46,200
but you have a 3,200
word blog waiting for you

602
00:22:46,200 --> 00:22:48,870
with about 800 lines of code
waiting for you as well.

603
00:22:48,870 --> 00:22:51,229
So between this video, between the blog

604
00:22:51,230 --> 00:22:52,596
and between the free code (mumbles)

605
00:22:52,596 --> 00:22:53,693
you should be good to go.

606
00:22:53,693 --> 00:22:56,243
I really appreciate your
time, thank you very much.

