1
00:00:07,000 --> 00:00:09,833
>> SPEAKER: Please welcome
Corporate Vice President,

2
00:00:09,900 --> 00:00:12,766
Security Compliance,
Identity Management,

3
00:00:12,833 --> 00:00:17,600
and Privacy,
Microsoft, Vasu Jakkal.

4
00:00:30,500 --> 00:00:31,433
>> VASU JAKKAL: All right.

5
00:00:31,500 --> 00:00:33,200
Well, good
afternoon, everyone.

6
00:00:33,266 --> 00:00:35,333
I hope you all
are doing well.

7
00:00:35,399 --> 00:00:40,299
And it is so wonderful to
see you all in real life,

8
00:00:40,366 --> 00:00:43,033
as my kids call it.

9
00:00:43,100 --> 00:00:45,299
Hugs all around, truly.

10
00:00:45,366 --> 00:00:47,666
Well, RSA holds a
special significance for

11
00:00:47,733 --> 00:00:48,933
our defender community.

12
00:00:49,000 --> 00:00:53,233
And a lot has happened in
the last two years, hasn't it?

13
00:00:53,299 --> 00:00:56,266
And as we meet here today,
we are reminded once again

14
00:00:56,333 --> 00:00:59,966
that there's still a lot of
hurt in the world around us,

15
00:01:00,033 --> 00:01:04,132
that life is still very
fragile, and that the work

16
00:01:04,200 --> 00:01:07,633
we do as a
defender community

17
00:01:07,700 --> 00:01:11,233
really, really matters.

18
00:01:11,299 --> 00:01:13,299
This work is critical.

19
00:01:13,366 --> 00:01:16,533
It's critical to the future
of trust, to the future of

20
00:01:16,599 --> 00:01:20,366
technology, and to the
very future of humanity.

21
00:01:20,433 --> 00:01:23,033
So, I look forward to
exploring a little bit of

22
00:01:23,099 --> 00:01:26,866
that future with you here
today, and I thought I'd

23
00:01:26,933 --> 00:01:29,633
start with a quote
which I really like.

24
00:01:29,700 --> 00:01:33,066
It's from American
author William Gibson.

25
00:01:33,133 --> 00:01:35,166
The future is
already here -- it's just

26
00:01:35,233 --> 00:01:37,466
not evenly distributed.

27
00:01:37,533 --> 00:01:41,700
And it alludes to the fact
that what will be the norm

28
00:01:41,766 --> 00:01:45,200
and the everyday of our
future tomorrow exists in

29
00:01:45,266 --> 00:01:48,066
some form shape today.

30
00:01:48,133 --> 00:01:51,066
It's just going to be
more pervasive tomorrow.

31
00:01:51,133 --> 00:01:55,066
And that certainly holds
true in cybersecurity.

32
00:01:55,133 --> 00:01:59,166
If you look around us, the
emerging landscape that we

33
00:01:59,233 --> 00:02:03,700
see will be the
norm in the future.

34
00:02:03,766 --> 00:02:10,533
And we don't have to look
that far to see what that is.

35
00:02:10,598 --> 00:02:14,399
Cyber has become a key
component of war between

36
00:02:14,466 --> 00:02:18,000
nations, as we're
seeing in Ukraine.

37
00:02:18,066 --> 00:02:21,966
Devastating attacks on
supply chain, including

38
00:02:22,033 --> 00:02:24,433
critical infrastructure like
colonial pipeline in the

39
00:02:24,500 --> 00:02:28,000
last two years, have had
profound human consequences

40
00:02:28,066 --> 00:02:30,099
and continue to do so.

41
00:02:30,166 --> 00:02:33,599
And then there's the whole
ransomware gig economy,

42
00:02:33,666 --> 00:02:35,833
alive and thriving.

43
00:02:35,900 --> 00:02:39,300
Human-operated ransomware,
ransomware as a service.

44
00:02:39,366 --> 00:02:43,133
They're reducing the
barriers to entry for

45
00:02:43,199 --> 00:02:46,000
attacks and attackers.

46
00:02:46,066 --> 00:02:48,966
You take that and you
add disinformation,

47
00:02:49,033 --> 00:02:53,833
misinformation, deep
fakes, fraud, I could go on.

48
00:02:53,900 --> 00:02:57,766
And collectively, it's
incredibly challenging.

49
00:02:57,833 --> 00:03:01,000
It's eroding the trust
that we have in the very

50
00:03:01,066 --> 00:03:05,900
technology we need to
work, to play, to live.

51
00:03:05,966 --> 00:03:10,599
And it's not just the
reach and the scale of

52
00:03:10,666 --> 00:03:13,333
cyberattacks
that is daunting.

53
00:03:13,400 --> 00:03:16,966
It's also the rate and pace.

54
00:03:17,033 --> 00:03:23,065
Microsoft protects 785,000
customers across the world,

55
00:03:23,133 --> 00:03:26,000
including our own
digital estate.

56
00:03:26,066 --> 00:03:28,800
And as such, we have a
unique front-row seat on the

57
00:03:28,866 --> 00:03:31,333
front lines of security.

58
00:03:31,400 --> 00:03:33,666
And what we are
seeing is this rapid

59
00:03:33,733 --> 00:03:36,099
acceleration in attacks.

60
00:03:36,166 --> 00:03:41,500
There's 921
attacks per second.

61
00:03:41,566 --> 00:03:43,500
That's 2X what
we saw last year.

62
00:03:43,566 --> 00:03:46,400
That's billions and
billions of attacks.

63
00:03:46,466 --> 00:03:51,133
It takes less than two hours
from when a user clicks on a

64
00:03:51,199 --> 00:03:53,833
phishing link for an
attacker to get access

65
00:03:53,900 --> 00:03:55,333
to their email.

66
00:03:55,400 --> 00:03:59,500
And in just over an hour, an
attacker can start moving

67
00:03:59,566 --> 00:04:02,766
laterally within your
network and system.

68
00:04:02,833 --> 00:04:05,466
So, what does all
this data mean?

69
00:04:05,533 --> 00:04:09,299
It means that, for us,
as defenders and as

70
00:04:09,366 --> 00:04:12,833
organizations defending, we
have, at an average, of two

71
00:04:12,900 --> 00:04:16,666
hours, two hours,
to contain the threat

72
00:04:16,733 --> 00:04:18,800
from getting escalated.

73
00:04:18,866 --> 00:04:22,466
And if an attacker decides
to target you for extortion

74
00:04:22,533 --> 00:04:26,300
or ransomware or pick
your favorite evil, they

75
00:04:26,366 --> 00:04:29,066
can move pretty fast.

76
00:04:29,133 --> 00:04:32,966
In fact, we've seen a steady
decline in dwell times over

77
00:04:33,033 --> 00:04:36,100
the last few years, and that
means defenders are getting

78
00:04:36,166 --> 00:04:39,100
really efficient,
but so are attackers.

79
00:04:39,166 --> 00:04:44,933
So, for our future, our
approach to cybersecurity,

80
00:04:45,000 --> 00:04:48,366
our collective approach to
cybersecurity, together

81
00:04:48,433 --> 00:04:50,966
has to evolve.

82
00:04:51,033 --> 00:04:55,800
We have to push relentlessly
on the borders and the

83
00:04:55,866 --> 00:05:00,166
boundaries of technology
innovation because guess what?

84
00:05:00,233 --> 00:05:02,433
Our adversaries are
definitely pushing

85
00:05:02,500 --> 00:05:04,600
on those boundaries.

86
00:05:04,666 --> 00:05:07,433
We need to redefine and
rethink of that precious

87
00:05:07,500 --> 00:05:10,800
human element, that
cybersecurity expertise.

88
00:05:10,866 --> 00:05:15,133
Human expertise will
always be a precious and

89
00:05:15,199 --> 00:05:18,800
irreplaceable part of cyber
defense, but we have to ask

90
00:05:18,866 --> 00:05:20,399
and answer questions.

91
00:05:20,466 --> 00:05:22,533
How do we scale humans?

92
00:05:22,600 --> 00:05:25,100
How do we leverage human
talent for the most

93
00:05:25,166 --> 00:05:30,000
strategic and the most
creative tasks that are there?

94
00:05:30,066 --> 00:05:32,799
How do we really tap into
the collective, diverse

95
00:05:32,866 --> 00:05:36,265
workforce that we have in
corners we haven't been into

96
00:05:36,333 --> 00:05:41,733
yet to fight against the
diverse attacks we are seeing?

97
00:05:41,800 --> 00:05:46,166
And as we do this, we are
facing an acute talent shortage.

98
00:05:46,233 --> 00:05:50,966
So, we need to rethink about
how do we attract more talent

99
00:05:51,033 --> 00:05:53,666
and then retain that,
and that means we need

100
00:05:53,733 --> 00:05:55,199
to be more inclusive.

101
00:05:55,266 --> 00:05:58,899
We need to create platforms
where every person, no

102
00:05:58,966 --> 00:06:01,866
matter who you are, can do
your best work and thrive.

103
00:06:05,033 --> 00:06:09,566
So, let's start by taking
a look at technology evolution.

104
00:06:09,633 --> 00:06:12,698
Now, there will be many
technologies in our future

105
00:06:12,766 --> 00:06:15,533
-- I'm sure you all have
your favorites -- which will

106
00:06:15,600 --> 00:06:18,433
redefine and reshape
our landscape, and

107
00:06:18,500 --> 00:06:20,533
it's super exciting.

108
00:06:20,600 --> 00:06:24,766
But when it comes to
accelerating the speed of

109
00:06:24,833 --> 00:06:31,133
response, AI will be one
of the most impactful.

110
00:06:31,199 --> 00:06:34,433
I just shared with you a
few moments back how it's

111
00:06:34,500 --> 00:06:38,300
getting faster and faster
for an attacker to penetrate

112
00:06:38,366 --> 00:06:39,566
in the system.

113
00:06:39,633 --> 00:06:43,899
Not a lot of time to contain
that threat, and so we, as a

114
00:06:43,966 --> 00:06:47,699
defender community, need
to move our industry from

115
00:06:47,766 --> 00:06:52,533
defense at human speed to
defending at machine speed.

116
00:06:52,600 --> 00:06:54,399
It's imperative we do that.

117
00:06:54,466 --> 00:06:58,000
And for that reason, I am
excited and hopeful and

118
00:06:58,066 --> 00:07:02,732
inspired by both the promise
and the potential that we've

119
00:07:02,800 --> 00:07:06,766
seen in AI, together with
cloud and machine learning,

120
00:07:06,833 --> 00:07:11,000
to really effectively start
addressing analytical and

121
00:07:11,066 --> 00:07:14,332
predictive capabilities and
use that, whether it's on

122
00:07:14,399 --> 00:07:17,766
machine-trained models
or general reasoning, to

123
00:07:17,833 --> 00:07:19,266
augment human capability.

124
00:07:19,333 --> 00:07:23,600
Now, I also know, as I say
this, that there's been a

125
00:07:23,666 --> 00:07:28,699
lot of hype about AI, and
it's jaded some of us.

126
00:07:28,766 --> 00:07:29,800
And it's true.

127
00:07:29,866 --> 00:07:32,433
For all that hype, to date,
there are relatively few use

128
00:07:32,500 --> 00:07:35,899
cases that we can point to
that are clear and accurate

129
00:07:35,966 --> 00:07:39,399
and apparent and
attributable to AI.

130
00:07:39,466 --> 00:07:44,433
But -- and that's a big but
-- without AI, we simply

131
00:07:44,500 --> 00:07:49,800
cannot scale our defenses
at the rate of attack.

132
00:07:49,866 --> 00:07:52,899
To fight this asymmetric
war, and it's pretty

133
00:07:52,966 --> 00:07:57,166
asymmetric out there,
we have to use AI,

134
00:07:57,233 --> 00:07:59,199
all its superpowers.

135
00:07:59,266 --> 00:08:02,366
So, let's take a look at
what's working in AI today

136
00:08:02,433 --> 00:08:05,966
and what can we reasonably
expect in the next few

137
00:08:06,033 --> 00:08:08,166
years, putting all
that hype aside.

138
00:08:10,666 --> 00:08:13,800
One of the most
effective use cases of AI

139
00:08:13,866 --> 00:08:16,166
today is detection.

140
00:08:16,233 --> 00:08:20,633
AI is incredibly, incredibly
effective and great at

141
00:08:20,699 --> 00:08:24,833
processing large amounts of
data and classifying this

142
00:08:24,899 --> 00:08:28,600
data to determine what
is good and what's bad.

143
00:08:28,666 --> 00:08:33,232
At Microsoft, we process
24 trillion signals

144
00:08:33,299 --> 00:08:36,566
every single day.

145
00:08:36,633 --> 00:08:40,066
That's across identities and
end points and devices and

146
00:08:40,133 --> 00:08:43,366
collaboration tools
and much more.

147
00:08:43,433 --> 00:08:48,165
And without AI, we simply
could not tackle this.

148
00:08:48,233 --> 00:08:52,065
In fact, as you'll see some
of the stats here, almost

149
00:08:52,133 --> 00:08:56,299
80% of our end point-based
detections are powered by

150
00:08:56,366 --> 00:08:57,366
AI machine learning.

151
00:08:57,433 --> 00:09:01,566
And there are more than
2.5 billion cloud-based

152
00:09:01,633 --> 00:09:05,533
detections per day
that we use AI for.

153
00:09:05,600 --> 00:09:06,666
That's pretty powerful.

154
00:09:06,733 --> 00:09:12,833
But yet, today, we are
seeing AI being used in

155
00:09:12,899 --> 00:09:15,666
point use cases.

156
00:09:15,733 --> 00:09:20,299
What I mean by that is AI is
very effective in providing

157
00:09:20,366 --> 00:09:23,000
an email security
program, that split-second

158
00:09:23,066 --> 00:09:26,933
decision-making whether to
block an email or to let it

159
00:09:27,000 --> 00:09:29,333
go to an inbox.

160
00:09:29,399 --> 00:09:30,933
Same thing for end
point security.

161
00:09:31,000 --> 00:09:34,466
AI is extraordinary when
it comes to making that

162
00:09:34,533 --> 00:09:39,500
split-second decision on
whether a file is malicious.

163
00:09:39,566 --> 00:09:45,600
Where the real power of AI
is is end to end when we can

164
00:09:45,666 --> 00:09:47,399
connect across
these domains.

165
00:09:47,466 --> 00:09:51,100
You probably have
heard the word XDR a lot at

166
00:09:51,166 --> 00:09:52,500
RSA this time.

167
00:09:52,566 --> 00:09:55,799
But truly, when you can
connect across those domains

168
00:09:55,866 --> 00:10:01,133
and you can figure out that
entire kill chain, and

169
00:10:01,200 --> 00:10:03,266
that's what I believe
we'll see in the next

170
00:10:03,333 --> 00:10:04,833
one to two years.

171
00:10:04,899 --> 00:10:08,966
Imagine if AI can leverage
its capabilities and tell

172
00:10:09,033 --> 00:10:12,333
you whether that malicious
file or that blocked email

173
00:10:12,399 --> 00:10:17,066
belonged to the same attack
lifecycle, and then use that

174
00:10:17,133 --> 00:10:19,799
capability in real-time
while that attack is

175
00:10:19,866 --> 00:10:23,899
happening to block and
disrupt the attacker to

176
00:10:23,966 --> 00:10:25,700
respond to that.

177
00:10:25,766 --> 00:10:27,733
That is the true
capability of AI.

178
00:10:27,799 --> 00:10:32,165
And you're going to see an
acceleration rapidly on

179
00:10:32,233 --> 00:10:34,032
this maturity curve.

180
00:10:34,100 --> 00:10:37,000
The other thing about AI
that really excites me is

181
00:10:37,066 --> 00:10:39,233
the contextual and
situational advantage

182
00:10:39,299 --> 00:10:41,132
that it provides.

183
00:10:41,200 --> 00:10:42,333
It's pretty good at that.

184
00:10:42,399 --> 00:10:45,233
Now, we all know that
organizations are

185
00:10:45,299 --> 00:10:46,165
in different journeys.

186
00:10:46,233 --> 00:10:47,899
We are in
different industries.

187
00:10:47,966 --> 00:10:50,700
We have different digital
transformation imperatives.

188
00:10:50,766 --> 00:10:51,966
We need different responses.

189
00:10:52,033 --> 00:10:55,233
We have different
productivity requirements.

190
00:10:55,299 --> 00:11:00,333
And AI can be used for that
tailored response based on

191
00:11:00,399 --> 00:11:03,000
your context on
what you need.

192
00:11:03,066 --> 00:11:06,766
And that's going to be
really exciting as well.

193
00:11:06,833 --> 00:11:11,100
So, when you think about AI,
what excites me and what I

194
00:11:11,166 --> 00:11:14,100
think we'll see in the next
one to two years is the

195
00:11:14,166 --> 00:11:19,066
power of AI to understand
the full scope of the attack

196
00:11:19,133 --> 00:11:21,299
while the attack is
happening, not in

197
00:11:21,366 --> 00:11:25,133
retrospect, and using that
information, that complete

198
00:11:25,200 --> 00:11:29,933
incident graph, to disrupt
the attack, to respond to it

199
00:11:30,000 --> 00:11:34,066
in real-time at the rate
of attack, and hopefully

200
00:11:34,133 --> 00:11:34,933
faster than that.

201
00:11:35,000 --> 00:11:37,866
Now, there's true
power in that.

202
00:11:37,933 --> 00:11:40,600
That's the promise
of AI and a real one.

203
00:11:43,600 --> 00:11:46,399
And if we go a little bit
more into the future --

204
00:11:46,466 --> 00:11:47,200
I love the future.

205
00:11:47,266 --> 00:11:50,632
I'm a big sci-fi fan,
so I live in the future.

206
00:11:50,700 --> 00:11:52,899
So, if we push ourselves
a little bit more in the

207
00:11:52,966 --> 00:11:58,799
future, I think AI has the
potential to be a great ally

208
00:11:58,866 --> 00:12:03,633
and partner for all
humans, to be a co-pilot.

209
00:12:03,700 --> 00:12:07,033
And we are seeing these
co-pilot use cases in some

210
00:12:07,100 --> 00:12:12,033
technology domains already
to help coders with code.

211
00:12:12,100 --> 00:12:14,899
Imagine the
possibilities of being a

212
00:12:14,966 --> 00:12:18,200
co-pilot in security.

213
00:12:18,266 --> 00:12:23,665
We can then scale our
humans better, faster.

214
00:12:23,733 --> 00:12:27,299
We can use AI to do some of
the repetitive tasks that

215
00:12:27,366 --> 00:12:30,333
consume human energy today.

216
00:12:30,399 --> 00:12:33,733
We can use AI to collect
disparate and fragmented

217
00:12:33,799 --> 00:12:36,733
pieces of information
fast to form that

218
00:12:36,799 --> 00:12:39,233
incident graph real-time.

219
00:12:39,299 --> 00:12:42,866
We can use AI to start
thinking like humans

220
00:12:42,933 --> 00:12:45,366
using general
reasoning models,

221
00:12:45,433 --> 00:12:47,633
build cognitive
capabilities.

222
00:12:47,700 --> 00:12:50,799
And when we do all that, we
are augmenting that human

223
00:12:50,866 --> 00:12:55,000
talent, saving that precious
human resource to do what we

224
00:12:55,066 --> 00:12:58,666
need best and what humans
do best, is push those

225
00:12:58,733 --> 00:13:01,632
boundaries of
creativity and strategy.

226
00:13:01,700 --> 00:13:05,100
That has enormous potential
to accelerate our mission to

227
00:13:05,166 --> 00:13:05,966
build a safer world.

228
00:13:06,033 --> 00:13:12,833
And there's a lot of
work that we need to do

229
00:13:12,899 --> 00:13:15,166
to get there.

230
00:13:15,233 --> 00:13:16,500
We're going to have
to do it together.

231
00:13:16,566 --> 00:13:19,466
We're going to have to
build on the foundations

232
00:13:19,533 --> 00:13:21,266
that we have.

233
00:13:21,333 --> 00:13:23,399
We're going to have
to learn together.

234
00:13:23,466 --> 00:13:25,633
And there are three things
I want to touch on today,

235
00:13:25,700 --> 00:13:28,299
which I hope you'll
help me with as we march

236
00:13:28,366 --> 00:13:29,899
into the future.

237
00:13:29,966 --> 00:13:31,899
The first one is
more data sharing.

238
00:13:31,966 --> 00:13:37,700
And the reason I say this is
for AI to realize its full

239
00:13:37,766 --> 00:13:40,333
potential, we
need more data.

240
00:13:40,399 --> 00:13:44,533
When we have more data, we
can understand end to end.

241
00:13:44,600 --> 00:13:47,966
Remember, attacks come
across boundaries, whether

242
00:13:48,033 --> 00:13:52,700
it's domain boundaries, end
point email identity, it

243
00:13:52,766 --> 00:13:55,733
is organizational
boundaries, it is

244
00:13:55,799 --> 00:13:57,799
international boundaries.

245
00:13:57,866 --> 00:13:59,699
Attackers don't
have boundaries.

246
00:13:59,766 --> 00:14:02,632
For that, our data
cannot have boundaries.

247
00:14:02,700 --> 00:14:05,399
We need more data
to be effective.

248
00:14:05,466 --> 00:14:09,533
And, yes, absolutely, we
need to be responsible.

249
00:14:09,600 --> 00:14:10,600
We need to be ethical.

250
00:14:10,666 --> 00:14:14,433
We need to have privacy
at its heart and core.

251
00:14:14,500 --> 00:14:17,933
But when we have more data
and then we share more data,

252
00:14:18,000 --> 00:14:19,500
when we come
together for that, AI

253
00:14:19,566 --> 00:14:20,666
can be really effective.

254
00:14:20,733 --> 00:14:25,532
The second thing we're going
to need is AI-trained and

255
00:14:25,600 --> 00:14:27,366
machine learning-
trained models which are

256
00:14:27,433 --> 00:14:29,299
specific to cyber.

257
00:14:29,366 --> 00:14:32,866
Attacker TTPs and indicators
of compromise and even

258
00:14:32,933 --> 00:14:35,333
understanding entire
enterprise system, we're

259
00:14:35,399 --> 00:14:36,633
going to have to build that.

260
00:14:36,700 --> 00:14:39,200
We're going to have to
create that and train that.

261
00:14:39,266 --> 00:14:42,132
And lastly, we're
going to need more

262
00:14:42,200 --> 00:14:43,799
explainability in AI.

263
00:14:43,866 --> 00:14:45,533
And you're probably
wondering what is this word?

264
00:14:45,600 --> 00:14:50,899
Well, it is hard to
trust something when you

265
00:14:50,966 --> 00:14:51,933
don't understand it.

266
00:14:52,000 --> 00:14:55,899
How many times have you
all heard, just trust me?

267
00:14:55,966 --> 00:14:56,799
I get that a lot.

268
00:14:56,866 --> 00:14:59,399
And it's hard, right?

269
00:14:59,466 --> 00:15:01,899
Because if you don't
understand why someone is

270
00:15:01,966 --> 00:15:05,666
making a decision they are,
how are they coming to those

271
00:15:05,733 --> 00:15:07,032
decisions, and
what are they doing?

272
00:15:07,100 --> 00:15:07,966
How do you trust that?

273
00:15:08,033 --> 00:15:13,000
So, it's hard for AI to be
effective if we don't

274
00:15:13,066 --> 00:15:14,200
have explainable AI.

275
00:15:14,266 --> 00:15:20,233
And I think we have a lot of
opportunity to do work here.

276
00:15:20,299 --> 00:15:22,333
And it's not just
AI explainability.

277
00:15:22,399 --> 00:15:24,000
We also need human
explainability.

278
00:15:24,066 --> 00:15:27,966
I mean, cyber is complex.

279
00:15:28,033 --> 00:15:31,866
We need skillsets to take
these very complex tasks and

280
00:15:31,933 --> 00:15:35,165
deconstruct them and
simplify them so that we can

281
00:15:35,233 --> 00:15:39,500
bring the collective, we
can bring along people.

282
00:15:39,566 --> 00:15:42,500
We need different skillsets.

283
00:15:42,566 --> 00:15:46,100
And so, while technology is
awesome for defending at

284
00:15:46,166 --> 00:15:49,833
machine speed, we need
awesome humans, and we need

285
00:15:49,899 --> 00:15:51,899
a variety of
great skillsets.

286
00:15:51,966 --> 00:15:53,333
And I'm not going to talk
to you today about the

287
00:15:53,399 --> 00:15:54,833
traditional cyber skillsets.

288
00:15:54,899 --> 00:15:55,633
You all know that.

289
00:15:55,700 --> 00:15:56,600
You all have that.

290
00:15:56,666 --> 00:15:58,600
Engineers and
computer scientists

291
00:15:58,666 --> 00:16:00,399
and intelligent analysts.

292
00:16:00,466 --> 00:16:05,133
But we need more than that
to understand wars and to

293
00:16:05,200 --> 00:16:07,299
understand cyberattacks.

294
00:16:07,366 --> 00:16:09,833
We need
language specialists.

295
00:16:09,899 --> 00:16:12,733
We need to build responsible
AI, and so we need people

296
00:16:12,799 --> 00:16:15,665
who are
specialized in ethics.

297
00:16:15,733 --> 00:16:17,833
We need people who are
from political science.

298
00:16:17,899 --> 00:16:23,399
We need people who can
design great products and UX

299
00:16:23,466 --> 00:16:25,466
and design specialists.

300
00:16:26,600 --> 00:16:29,200
We need to make sure we have
great teachers who want to

301
00:16:29,266 --> 00:16:32,466
teach about AI, and
great storytellers.

302
00:16:32,533 --> 00:16:34,399
We need social scientists.

303
00:16:34,466 --> 00:16:36,799
And I can go on
and on and on.

304
00:16:36,866 --> 00:16:40,199
But the message here is we
need all kinds of skillsets.

305
00:16:40,266 --> 00:16:41,599
Cyber is for everyone.

306
00:16:41,666 --> 00:16:43,233
It belongs to all of us.

307
00:16:43,299 --> 00:16:47,799
And we need this
variety of skillsets.

308
00:16:47,866 --> 00:16:50,966
And the reason for that is
for us to scale at this

309
00:16:51,033 --> 00:16:56,566
machine speed, we have to be
that community behind that

310
00:16:56,633 --> 00:16:59,299
one security operator.

311
00:16:59,366 --> 00:17:00,333
I love this slide.

312
00:17:00,399 --> 00:17:02,266
I love this visual
because I think that's the

313
00:17:02,333 --> 00:17:04,333
heart of it.

314
00:17:04,400 --> 00:17:07,566
We have to bring the best
minds, all that collective

315
00:17:07,633 --> 00:17:10,766
wisdom, that collective
skillset, and we have to

316
00:17:10,833 --> 00:17:15,200
empower that SOC analyst
so she can do her work

317
00:17:15,266 --> 00:17:18,599
effectively,
at scale, without hiring

318
00:17:18,665 --> 00:17:20,598
an entire village.

319
00:17:20,665 --> 00:17:23,598
And that's why technology
will play a key role here.

320
00:17:23,665 --> 00:17:28,666
And it's not just enough
to have technology.

321
00:17:32,266 --> 00:17:37,799
We also need to attract
and retain great talent.

322
00:17:37,866 --> 00:17:39,833
I'm sure you all
are feeling the pain

323
00:17:39,900 --> 00:17:41,066
of cybersecurity talent.

324
00:17:41,133 --> 00:17:44,266
We certainly are feeling
that pain at Microsoft.

325
00:17:44,333 --> 00:17:48,333
One out of every three jobs
in the United States is

326
00:17:48,400 --> 00:17:51,666
awakened today in
cybersecurity.

327
00:17:51,733 --> 00:17:54,332
And then you think
about diversity.

328
00:17:54,400 --> 00:18:00,133
Our attackers are diverse,
and they exploit the seams.

329
00:18:00,200 --> 00:18:03,666
They exploit the biases
in our systems when we

330
00:18:03,733 --> 00:18:05,533
have homogeneous teams.

331
00:18:05,599 --> 00:18:07,000
And look at the stats.

332
00:18:07,066 --> 00:18:12,433
Just 20% -- 24% of the
global workforce is women,

333
00:18:12,500 --> 00:18:16,533
20% of the workforce
is people of color.

334
00:18:16,599 --> 00:18:18,666
We have a lot of
work to do here.

335
00:18:18,733 --> 00:18:22,200
Because when we represent
the world and we reflect who

336
00:18:22,266 --> 00:18:24,666
the world is, we do
better cybersecurity.

337
00:18:26,799 --> 00:18:29,833
To do that, we also
have to break down the

338
00:18:29,900 --> 00:18:33,266
barriers of cybersecurity.

339
00:18:33,333 --> 00:18:35,333
Think about it.

340
00:18:35,400 --> 00:18:37,666
If you want diverse people
and if you want different

341
00:18:37,733 --> 00:18:40,200
people and different
skillsets, you need to go to

342
00:18:40,266 --> 00:18:42,599
different watering
holes for these people.

343
00:18:42,666 --> 00:18:45,799
You need to rethink
how to skill and train.

344
00:18:45,866 --> 00:18:48,200
We operate in a very
different world today.

345
00:18:48,266 --> 00:18:51,033
The pandemic has
changed a lot.

346
00:18:51,099 --> 00:18:53,799
We need to rethink about
things like cybersecurity

347
00:18:53,866 --> 00:18:55,500
degrees and experience.

348
00:18:55,566 --> 00:18:58,033
Anyone should be able to be
a defender, whether you're

349
00:18:58,099 --> 00:19:00,666
30 years in the industry and
want to reinvent something

350
00:19:00,733 --> 00:19:02,733
or you're just
starting out from school.

351
00:19:02,799 --> 00:19:04,099
Isn't that going
to be wonderful?

352
00:19:04,166 --> 00:19:07,533
We need to
mobilize our community.

353
00:19:07,599 --> 00:19:09,500
Gosh, we have this
incredible resource

354
00:19:09,566 --> 00:19:10,566
of community colleges.

355
00:19:10,633 --> 00:19:14,400
And I'm so, so proud that
Microsoft is partnering with

356
00:19:14,466 --> 00:19:17,332
community colleges, and we
have made a commitment to

357
00:19:17,400 --> 00:19:21,866
train 250,000 people in
cybersecurity by 2025 in the

358
00:19:21,933 --> 00:19:23,966
U.S., and we are
extending that to

359
00:19:24,033 --> 00:19:25,500
internationally as well.

360
00:19:25,566 --> 00:19:29,833
And we need to change
the language of cyber.

361
00:19:29,900 --> 00:19:33,433
And what I mean by that is
today, in many cases, cyber

362
00:19:33,500 --> 00:19:37,400
tends to be dark and
field-based and sometimes as

363
00:19:37,466 --> 00:19:40,933
fud, but that might
not be appealing to

364
00:19:41,000 --> 00:19:42,700
a lot of people.

365
00:19:42,766 --> 00:19:45,799
Shouldn't cyber be
about optimism and

366
00:19:45,866 --> 00:19:48,266
hope and inspiration?

367
00:19:48,333 --> 00:19:50,799
Because ultimately,
cybersecurity is about the

368
00:19:50,866 --> 00:19:52,933
empowerment of humanity.

369
00:19:53,000 --> 00:19:58,066
So, we need to change that
dialogue one heart at a time.

370
00:19:58,133 --> 00:20:01,000
So, as I come to a close
here, I talked about the

371
00:20:01,066 --> 00:20:07,666
three I's: innovation at its
best, human ingenuity and

372
00:20:07,733 --> 00:20:11,099
the essence of who we are,
and being inclusive in

373
00:20:11,166 --> 00:20:13,099
creating those platforms.

374
00:20:13,166 --> 00:20:15,566
And these don't
operate in silos.

375
00:20:15,633 --> 00:20:16,566
They work together.

376
00:20:16,633 --> 00:20:18,099
They are an
interdependent whole.

377
00:20:18,166 --> 00:20:23,099
We know that human ingenuity
has led to innovation for

378
00:20:23,166 --> 00:20:25,299
hundreds of
thousands of years.

379
00:20:25,366 --> 00:20:28,200
We know that when we create
inclusive environments where

380
00:20:28,266 --> 00:20:32,533
everyone feels like they
belong, we do our best work.

381
00:20:32,599 --> 00:20:34,599
That's what being brave
and bold and vulnerable

382
00:20:34,666 --> 00:20:37,466
in cyber looks like.

383
00:20:37,533 --> 00:20:41,132
So, I hope that you will
join me on this incredibly

384
00:20:41,200 --> 00:20:44,466
inspiring journey to do just
that, because we're going to

385
00:20:44,533 --> 00:20:47,366
need our entire village, and
it's an amazing village.

386
00:20:49,966 --> 00:20:54,966
So, as I leave you today,
I'm reminding myself and

387
00:20:55,033 --> 00:20:59,366
hopefully all of us that the
future of security truly

388
00:20:59,433 --> 00:21:01,866
belongs to all of us.

389
00:21:01,933 --> 00:21:07,066
We have to aspire to build
a safer world for all.

390
00:21:07,133 --> 00:21:10,366
And it is us and our
empowerment to create the

391
00:21:10,433 --> 00:21:12,933
future that we aspire to.

392
00:21:13,000 --> 00:21:15,599
So, stay fearless, be
fearless, and I hope to see

393
00:21:15,666 --> 00:21:16,399
you all around.

394
00:21:16,466 --> 00:21:17,666
Thank you so much.

