1
00:00:00,212 --> 00:00:02,795
(upbeat music)

2
00:00:04,330 --> 00:00:08,230
- The World Economic Forum's
Global Risks Report 2020

3
00:00:08,230 --> 00:00:10,750
was recently released in Davos.

4
00:00:10,750 --> 00:00:13,620
It included the global
risk perception survey

5
00:00:13,620 --> 00:00:16,210
to measure which global risks are likely

6
00:00:16,210 --> 00:00:18,310
to increase going forward.

7
00:00:18,310 --> 00:00:21,009
Cyberattacks in the top five.

8
00:00:21,010 --> 00:00:24,730
Now 76% of respondents believes cyber risk

9
00:00:24,730 --> 00:00:27,240
will increase in 2020.

10
00:00:27,240 --> 00:00:32,239
- We have attackers putting
malware into bespoke USB cables.

11
00:00:34,040 --> 00:00:35,769
So you can buy these USB cables

12
00:00:35,770 --> 00:00:39,130
where there's malware
actually, in the cable itself.

13
00:00:39,130 --> 00:00:40,610
It behaves like a normal USB cable

14
00:00:40,610 --> 00:00:42,290
so you could use it to sync your phone

15
00:00:42,290 --> 00:00:43,510
to charge your phone

16
00:00:43,510 --> 00:00:45,089
to charge your computer even.

17
00:00:45,090 --> 00:00:47,200
You have to be tremendously careful.

18
00:00:47,200 --> 00:00:49,550
If you find a USB cable in an airport,

19
00:00:49,550 --> 00:00:52,099
it could be the cable itself attacks you

20
00:00:52,100 --> 00:00:53,230
and think about this.

21
00:00:53,230 --> 00:00:55,150
The persistence is in the wire.

22
00:00:55,150 --> 00:00:57,320
You eradicate the
malware from your system.

23
00:00:57,320 --> 00:00:58,730
The next time you go to charge your phone

24
00:00:58,730 --> 00:00:59,820
or sync your phone,

25
00:00:59,820 --> 00:01:01,620
it reinfects it.

26
00:01:01,620 --> 00:01:04,652
- Our most critical
data lives in the cloud.

27
00:01:05,820 --> 00:01:08,729
Cyber criminals and nation
states can siphon off that data

28
00:01:08,730 --> 00:01:12,330
today and unlock it tomorrow,

29
00:01:12,330 --> 00:01:15,233
when Quantum Cryptanalysis
becomes practical.

30
00:01:16,300 --> 00:01:20,240
But we can't think of quantum
in terms of eventually

31
00:01:20,240 --> 00:01:22,240
or tomorrow,

32
00:01:22,240 --> 00:01:25,490
because quantum is a real risk today.

33
00:01:25,490 --> 00:01:27,179
- As all of you have probably seen,

34
00:01:27,180 --> 00:01:30,450
it is enough to take an image
and change a few pixels,

35
00:01:30,450 --> 00:01:35,040
and then the neural
network is making all kinds

36
00:01:35,040 --> 00:01:37,290
of very strange decisions.

37
00:01:37,290 --> 00:01:39,800
I think that we are now
starting to understand

38
00:01:39,800 --> 00:01:41,119
what is going on.

39
00:01:41,120 --> 00:01:44,370
But until we will solve this problem,

40
00:01:44,370 --> 00:01:46,560
I think that it will be very dangerous

41
00:01:46,560 --> 00:01:50,080
to use deep neural networks
in autonomous vehicles,

42
00:01:50,080 --> 00:01:52,640
for example, in making life

43
00:01:52,640 --> 00:01:56,440
and death decisions in medicine, etc.

44
00:01:56,440 --> 00:01:58,649
- I know this room needs no convincing

45
00:01:58,650 --> 00:02:01,560
that there are virtually
no industries today

46
00:02:01,560 --> 00:02:04,370
that are not vulnerable to cyberattacks.

47
00:02:04,370 --> 00:02:06,723
And the auto industry is no exception.

48
00:02:07,940 --> 00:02:11,200
I think you know, the auto
industry is fiercely competitive.

49
00:02:11,200 --> 00:02:14,549
But cybersecurity is an
area in which we must,

50
00:02:14,550 --> 00:02:18,250
and where we do act as a
united front to collaborate

51
00:02:18,250 --> 00:02:20,190
and share best practices.

52
00:02:20,190 --> 00:02:23,130
- Some of the the
challenges that we're having

53
00:02:23,130 --> 00:02:25,380
or threats that we're
seeing in our environment,

54
00:02:25,380 --> 00:02:26,750
on the IT side of the house,

55
00:02:26,750 --> 00:02:28,650
it's probably what
everyone else is facing,

56
00:02:28,650 --> 00:02:31,060
we get a lot of phishing emails.

57
00:02:31,060 --> 00:02:34,150
You know, we have to try to
educate our team members on

58
00:02:34,150 --> 00:02:35,300
how to protect themselves,

59
00:02:35,300 --> 00:02:36,460
how to not click on the links,

60
00:02:36,460 --> 00:02:38,690
but no matter how many times we tell them,

61
00:02:38,690 --> 00:02:39,730
someone's still going to click,

62
00:02:39,730 --> 00:02:41,590
someone's still gonna
enter their credentials.

63
00:02:41,590 --> 00:02:42,730
So we're hoping that you know,

64
00:02:42,730 --> 00:02:45,810
we have our basic cybersecurity
principles in place

65
00:02:45,810 --> 00:02:48,410
that can help protect our assets

66
00:02:48,410 --> 00:02:50,400
when people do click those links.

67
00:02:50,400 --> 00:02:52,300
- Is easy to get the illusion

68
00:02:52,300 --> 00:02:55,450
working in academic
industrial cryptography,

69
00:02:55,450 --> 00:02:57,920
but there some playing fair

70
00:02:57,920 --> 00:03:00,530
and intelligence is
not about playing fair,

71
00:03:00,530 --> 00:03:02,250
it's about succeeding.

72
00:03:02,250 --> 00:03:05,320
And there's no reason to
be sitting waiting for them

73
00:03:05,320 --> 00:03:07,489
to make up cryptographic algorithms

74
00:03:07,490 --> 00:03:08,520
that maybe you can break,

75
00:03:08,520 --> 00:03:09,990
and maybe you can't.

76
00:03:09,990 --> 00:03:13,090
If instead, you can push one
on them that you can't break.

77
00:03:13,090 --> 00:03:14,811
- Security is about adversaries.

78
00:03:14,811 --> 00:03:17,270
And we have to be cognizant of the fact

79
00:03:17,270 --> 00:03:18,770
we need to design our systems,

80
00:03:18,770 --> 00:03:20,200
to have procedures in place,

81
00:03:20,200 --> 00:03:21,320
their people checking other people

82
00:03:21,320 --> 00:03:22,840
their people checking machines.

83
00:03:22,840 --> 00:03:25,310
- We have to change security

84
00:03:25,310 --> 00:03:27,930
from an authoritarian control model

85
00:03:27,930 --> 00:03:29,683
to a collaboration model.

86
00:03:30,960 --> 00:03:31,970
Now, let me ask you,

87
00:03:31,970 --> 00:03:34,030
do you think that we are
the ultimate authorities

88
00:03:34,030 --> 00:03:35,500
on security?

89
00:03:35,500 --> 00:03:38,003
Should we be making all
the security decisions?

90
00:03:40,160 --> 00:03:40,993
No.

91
00:03:42,120 --> 00:03:45,930
I'm going to put it to you that sometimes,

92
00:03:45,930 --> 00:03:49,180
users can make better security
decisions than we can.

93
00:03:49,180 --> 00:03:52,080
Security should be designed to be adopted,

94
00:03:52,080 --> 00:03:55,030
rather than engineered to be enforced.

95
00:03:55,030 --> 00:03:57,110
- The attackers aren't stupid.

96
00:03:57,110 --> 00:03:58,640
None of them are.

97
00:03:58,640 --> 00:04:02,260
But they fail anticipate
just how innovative,

98
00:04:02,260 --> 00:04:03,519
how ambitious

99
00:04:03,520 --> 00:04:07,970
and how aggressive the problem
solvers, the humans would be.

100
00:04:07,970 --> 00:04:10,500
They underestimated the target

101
00:04:10,500 --> 00:04:13,350
and they underestimated those teams.

102
00:04:13,350 --> 00:04:16,300
They underestimated the creativity

103
00:04:16,300 --> 00:04:18,920
and they underestimated the compassion.

104
00:04:18,920 --> 00:04:22,120
And they fail to anticipate the one thing,

105
00:04:22,120 --> 00:04:25,220
the actual human spirit.

106
00:04:25,220 --> 00:04:28,260
If you take nothing else away
from what I'm saying today,

107
00:04:28,260 --> 00:04:30,360
take it from me that in cybersecurity

108
00:04:30,360 --> 00:04:32,170
investing in the human element

109
00:04:32,170 --> 00:04:35,500
will always give the good guys an edge.

110
00:04:35,500 --> 00:04:37,700
- Tech is being democratized.

111
00:04:37,700 --> 00:04:41,339
And so it is time to democratize security.

112
00:04:41,339 --> 00:04:43,922
(upbeat music)

