1
00:00:06,299 --> 00:00:09,400
>> ANNOUNCER: Please welcome
Dr. Tracy Celaya Brown and

2
00:00:09,466 --> 00:00:10,433
Ira Winkler.

3
00:00:18,800 --> 00:00:20,433
>> DR. TRACY CELAYA
BROWN: Well, hello there.

4
00:00:20,500 --> 00:00:22,333
>> IRA WINKLER: Hi there.
Wow. There are people here.

5
00:00:22,399 --> 00:00:24,733
I don't know about you; I would
have been gone if I didn't have

6
00:00:24,800 --> 00:00:26,833
to be here but thank you.

7
00:00:26,899 --> 00:00:28,500
I'm told there's like, other
people in other rooms.

8
00:00:28,566 --> 00:00:29,599
It's like, cool.

9
00:00:29,666 --> 00:00:32,233
So, anyway, a couple
of different things.

10
00:00:32,299 --> 00:00:36,666
First, I'm told that there are
people transcribing this and

11
00:00:36,733 --> 00:00:39,532
given if you know how fast I
talk, I have to apologize to

12
00:00:39,600 --> 00:00:41,000
them in advance.

13
00:00:41,066 --> 00:00:45,200
And actually, while I'm thinking
of it, they're not sure their

14
00:00:45,266 --> 00:00:49,399
reason for being there and they
don't know why they are no

15
00:00:49,466 --> 00:00:51,433
longer not - never mind.

16
00:00:51,500 --> 00:00:54,000
If they got that right,
give them applause.

17
00:00:54,066 --> 00:00:59,433
But on another note, so, people
always accuse me of trying to

18
00:00:59,500 --> 00:01:02,766
cut Tracy off because I have
the clicker and I'm not giving

19
00:01:02,833 --> 00:01:03,899
it up.

20
00:01:03,966 --> 00:01:07,400
But usually that is because she
takes these long dramatic pauses

21
00:01:07,466 --> 00:01:09,399
and it's completely
unintentional.

22
00:01:09,466 --> 00:01:10,866
So, anyway, there's that.

23
00:01:10,933 --> 00:01:16,400
Let's now talk about the actual
topic of you can stop stupid.

24
00:01:16,466 --> 00:01:17,532
>> DR. TRACY CELAYA BROWN: Yes.

25
00:01:17,599 --> 00:01:18,533
>> IRA WINKLER: Because
here's the thing.

26
00:01:18,599 --> 00:01:19,633
Everybody is like, oh God.

27
00:01:19,700 --> 00:01:22,599
There's another presentation
calling our users stupid.

28
00:01:22,666 --> 00:01:23,899
When are we going to learn?

29
00:01:23,966 --> 00:01:27,133
If you see - if you've ever
heard me talk before, behind

30
00:01:27,200 --> 00:01:31,933
every stupid user is a stupider
security professional and let's

31
00:01:32,000 --> 00:01:34,233
talk a little bit
about why that occurs.

32
00:01:34,299 --> 00:01:38,099
I was once - so, about six
months ago, I was at a

33
00:01:38,166 --> 00:01:39,533
conference in Iowa.

34
00:01:39,599 --> 00:01:41,433
I'll give John a little promo.

35
00:01:41,500 --> 00:01:42,599
Corn Con in Iowa.

36
00:01:42,666 --> 00:01:44,099
Always a good conference.

37
00:01:44,166 --> 00:01:47,966
And I was on the lunch line and
there was like, a table to the

38
00:01:48,033 --> 00:01:51,066
side and they had a bunch of
these stickers that said, oh,

39
00:01:51,133 --> 00:01:52,666
it's a keynote; I can't curse.

40
00:01:52,733 --> 00:01:57,366
But anyway, the actual sticker
said don't click on "stuff."

41
00:01:57,433 --> 00:02:00,566
And what happened was, an admin
guy was walking up in front

42
00:02:00,633 --> 00:02:01,533
of me.

43
00:02:01,599 --> 00:02:03,366
He was like oh, I need a whole
bunch of these stickers.

44
00:02:03,433 --> 00:02:04,200
I'm like, really?

45
00:02:04,266 --> 00:02:05,200
He's like, yeah.

46
00:02:05,266 --> 00:02:07,200
I've got a whole bunch of these
users that keep clicking

47
00:02:07,266 --> 00:02:08,466
on "stuff."

48
00:02:08,532 --> 00:02:09,532
I'm like, wow.

49
00:02:09,598 --> 00:02:11,866
You must give your
users a lot of stuff.

50
00:02:11,933 --> 00:02:12,965
He's like, what do you mean?

51
00:02:13,033 --> 00:02:15,000
I'm like, well, how can they
click on stuff if you're not

52
00:02:15,066 --> 00:02:16,400
giving it to them.

53
00:02:16,466 --> 00:02:18,433
And by the way, if they're going
to click on all of the stuff,

54
00:02:18,500 --> 00:02:21,099
why aren't you like, dealing
with it after they click on it

55
00:02:21,166 --> 00:02:22,433
because you know
they're going to click?

56
00:02:22,500 --> 00:02:23,300
What's wrong with you?

57
00:02:23,366 --> 00:02:24,666
He's like, what do you mean?

58
00:02:24,733 --> 00:02:28,199
I'm like, so you can kind of
see where I'm going with this

59
00:02:28,266 --> 00:02:32,833
because everybody keeps focusing
on the user as the proximity of

60
00:02:32,900 --> 00:02:36,000
the error and the biggest
problem we have in the security

61
00:02:36,066 --> 00:02:38,900
world is we look at the fact
that when a user makes a

62
00:02:38,966 --> 00:02:42,333
mistake, it's the user
that is the issue.

63
00:02:42,400 --> 00:02:45,699
I look at it that when - the
problem is not that users make

64
00:02:45,766 --> 00:02:50,132
mistakes but that we put users
in a position where they can

65
00:02:50,199 --> 00:02:51,400
initiate loss.

66
00:02:51,466 --> 00:02:53,033
They don't cause the loss.

67
00:02:53,099 --> 00:02:56,766
They initiate a chain of events
and that is a really critical

68
00:02:56,833 --> 00:02:57,766
issue to deal with.

69
00:02:57,833 --> 00:02:59,533
I guess I should - okay.

70
00:02:59,599 --> 00:03:00,533
Oh, good.

71
00:03:00,599 --> 00:03:03,533
So, anyway, let's talk
about what is stupid.

72
00:03:03,599 --> 00:03:07,399
There is actually a dictionary
definition of stupid and this is

73
00:03:07,466 --> 00:03:09,666
kind of critical for
us to understand.

74
00:03:09,733 --> 00:03:13,900
So, the dictionary definition is
having or showing a great lack

75
00:03:13,966 --> 00:03:15,966
of intelligence or common sense.

76
00:03:16,033 --> 00:03:18,732
That is literally
what stupid means.

77
00:03:18,800 --> 00:03:19,733
But let's see.

78
00:03:19,800 --> 00:03:22,699
I think Tracy deals
with this next.

79
00:03:22,766 --> 00:03:24,033
>> DR. TRACY CELAYA
BROWN: Oh my. Yes.

80
00:03:24,099 --> 00:03:27,833
So, the question is do we hire
people with a great lack of

81
00:03:27,900 --> 00:03:29,000
common sense?

82
00:03:29,066 --> 00:03:32,099
If that's the case,
then whose fault is it?

83
00:03:32,166 --> 00:03:34,698
If we're hiring people with a
great lack of common sense and

84
00:03:34,766 --> 00:03:37,366
putting them in a position that
we say they're going to be

85
00:03:37,433 --> 00:03:42,933
successful in but they lack the
common sense, I think that's a

86
00:03:43,000 --> 00:03:45,366
question that we need
to do or take a look at.

87
00:03:45,433 --> 00:03:48,733
Likely very not and we also
need to question ourselves.

88
00:03:48,800 --> 00:03:50,733
If we're hiring people with a
lack of common sense, why are we

89
00:03:50,800 --> 00:03:53,566
putting them in a position or
responsibility where they need

90
00:03:53,633 --> 00:03:56,733
to behave, where they need to
act in a certain way or follow

91
00:03:56,800 --> 00:03:59,800
specific instructions
or even make decisions.

92
00:03:59,866 --> 00:04:05,566
And at most, put us in a
position where we may have risk

93
00:04:05,633 --> 00:04:07,166
as a result of their actions.

94
00:04:07,233 --> 00:04:09,366
So, maybe it's the fact
that they might be lacking

95
00:04:09,433 --> 00:04:10,433
common sense.

96
00:04:10,500 --> 00:04:13,366
So, if we go back to college
psychology and we look at common

97
00:04:13,433 --> 00:04:16,233
sense, in order to have
common sense which comes from

98
00:04:16,300 --> 00:04:18,833
experience, we need to
have common knowledge.

99
00:04:18,899 --> 00:04:21,399
So, we need to understand what
it is that we are doing in order

100
00:04:21,466 --> 00:04:23,066
to have common sense, right?

101
00:04:23,133 --> 00:04:25,899
So, we look at ourselves and
determine are we providing

102
00:04:25,966 --> 00:04:27,633
common knowledge to our people?

103
00:04:27,699 --> 00:04:30,133
Are we giving them the training
that they need in order to

104
00:04:30,199 --> 00:04:31,733
be successful?

105
00:04:31,800 --> 00:04:34,766
Or are we assuming that
there is going to be failure?

106
00:04:34,833 --> 00:04:37,500
So, we're hiring people with a
lack of great knowledge, we're

107
00:04:37,566 --> 00:04:40,332
hiring them with a lack of
common sense, we're not

108
00:04:40,399 --> 00:04:42,833
providing them the knowledge
that they need to be successful.

109
00:04:42,899 --> 00:04:46,199
So, apparently we must be
assuming that they are going

110
00:04:46,266 --> 00:04:47,266
to fail.

111
00:04:47,333 --> 00:04:50,733
And if that is the case, what
are we doing preemptively so

112
00:04:50,800 --> 00:04:52,600
that they don't?

113
00:04:52,666 --> 00:04:57,399
So, I'll sum this slide up
really like with a quote from

114
00:04:57,466 --> 00:05:00,066
the great
philosopher of Peggy Bundy.

115
00:05:00,133 --> 00:05:03,899
If you give a monkey a gun and
the monkey shoots somebody, who

116
00:05:03,966 --> 00:05:06,699
do you blame, the monkey or the
person who gave them the gun?

117
00:05:06,766 --> 00:05:10,666
Or perhaps the adults around the
monkey that didn't take the

118
00:05:10,733 --> 00:05:12,933
gun away.

119
00:05:13,000 --> 00:05:15,166
>> IRA WINKLER: So, and now
here's the thing; it's not

120
00:05:15,233 --> 00:05:16,166
really you out there.

121
00:05:16,233 --> 00:05:18,333
Again, everybody is like well,
first he is calling the

122
00:05:18,399 --> 00:05:19,066
user stupid.

123
00:05:19,133 --> 00:05:20,166
Now he's calling me stupid.

124
00:05:20,233 --> 00:05:21,533
It's like no, it's
not really you.

125
00:05:21,600 --> 00:05:24,333
Now let's talk about calling the
awareness professional stupid.

126
00:05:24,399 --> 00:05:27,533
Really make friends with
everybody on this presentation.

127
00:05:27,600 --> 00:05:28,966
So, here is the issue.

128
00:05:29,033 --> 00:05:31,833
When you stop and look at it,
every time we look at user

129
00:05:31,899 --> 00:05:36,033
error, user initiated loss, we
think of everybody looks at the

130
00:05:36,100 --> 00:05:39,500
user as the proximity of the
error and we'll talk about

131
00:05:39,566 --> 00:05:44,299
proximity later, but they think
the error is created by the user

132
00:05:44,366 --> 00:05:48,199
which is where the proximity is
and then of course, let's focus

133
00:05:48,266 --> 00:05:49,166
on that.

134
00:05:49,233 --> 00:05:51,566
You've been fed a bunch of
crap about this whole thing.

135
00:05:51,633 --> 00:05:53,500
They want you to create
the human firewall.

136
00:05:53,566 --> 00:05:56,465
They love to tout, we need to
make the user our last line

137
00:05:56,533 --> 00:05:57,500
of defense.

138
00:05:57,566 --> 00:06:00,198
If you make the user the last
line of defense, you really

139
00:06:00,266 --> 00:06:01,233
should be fired.

140
00:06:01,300 --> 00:06:04,633
You know, the human firewall
- firewalls suck in general.

141
00:06:04,699 --> 00:06:05,866
Let's face it.

142
00:06:05,933 --> 00:06:08,899
Do you really want a human
which is less reliable to be

143
00:06:08,966 --> 00:06:10,199
your firewall?

144
00:06:10,266 --> 00:06:12,266
That is not how it should work.

145
00:06:12,333 --> 00:06:15,666
Users are just the proximity but
all you keep hearing about is we

146
00:06:15,733 --> 00:06:17,899
need to make the users stronger.

147
00:06:17,966 --> 00:06:21,199
We don't need to make the users
stronger; that is the wrong type

148
00:06:21,266 --> 00:06:22,233
of science.

149
00:06:22,300 --> 00:06:25,133
If you ever workout, you know,
they have bro science like

150
00:06:25,199 --> 00:06:27,466
protein bro, you know,
give me my protein.

151
00:06:27,533 --> 00:06:29,199
It's like, that is bro science.

152
00:06:29,266 --> 00:06:30,333
It's like fake science.

153
00:06:30,399 --> 00:06:31,533
It's speciest.

154
00:06:31,600 --> 00:06:34,066
It sounds correct
but it's wrong.

155
00:06:34,133 --> 00:06:36,399
They say we need to
learn from psychology.

156
00:06:36,466 --> 00:06:38,033
We need to learn
from mental models.

157
00:06:38,100 --> 00:06:39,433
We need to learn marketing.

158
00:06:39,500 --> 00:06:40,500
And you know what?

159
00:06:40,566 --> 00:06:44,433
That has a place but that has a
really, really little place

160
00:06:44,500 --> 00:06:45,699
to apply.

161
00:06:45,766 --> 00:06:48,466
So, let's - so, anyway.

162
00:06:48,533 --> 00:06:50,600
Everybody is focusing on
the proximity of error.

163
00:06:50,666 --> 00:06:54,266
Next, here is really the
overall message of this

164
00:06:54,333 --> 00:06:55,766
whole presentation.

165
00:06:55,833 --> 00:06:58,333
Everybody thinks like, if you
take the lessons from the

166
00:06:58,399 --> 00:07:02,133
awareness profession, everybody
thinks that well, a user is

167
00:07:02,199 --> 00:07:03,000
making a mistake.

168
00:07:03,066 --> 00:07:04,765
We need a smarter user.

169
00:07:04,833 --> 00:07:07,866
We need to have the paragon
of virtue in our users.

170
00:07:07,933 --> 00:07:10,766
We just need to give them more
awareness training, better

171
00:07:10,833 --> 00:07:13,366
awareness training, funnier
awareness training, whatever the

172
00:07:13,433 --> 00:07:14,433
case is.

173
00:07:14,500 --> 00:07:17,133
That's like saying if a canary
dies in a coal mine, we need

174
00:07:17,199 --> 00:07:19,066
healthier canaries.

175
00:07:19,133 --> 00:07:21,066
That is not how it should be.

176
00:07:21,133 --> 00:07:24,966
You need to go ahead and
understand that the canary is a

177
00:07:25,033 --> 00:07:26,633
piece of the system.

178
00:07:26,699 --> 00:07:30,566
The canary is just the trigger
to say what do we really - what

179
00:07:30,633 --> 00:07:31,733
is the system for?

180
00:07:31,800 --> 00:07:34,500
The system in theory is to make
sure people don't die in a

181
00:07:34,566 --> 00:07:35,566
coal mine.

182
00:07:35,633 --> 00:07:40,566
Gas, canaries die under less
gas, less concentration of gas

183
00:07:40,633 --> 00:07:41,866
than a person would.

184
00:07:41,933 --> 00:07:44,832
So, when the canary dies, people
know there is something wrong.

185
00:07:44,899 --> 00:07:47,699
The canary is part of
the detection system.

186
00:07:47,766 --> 00:07:51,399
Much like if a user does
something wrong, that user is

187
00:07:51,466 --> 00:07:54,333
just part of the
system that has failed.

188
00:07:54,399 --> 00:07:57,699
So, we need to understand when a
user fails, it is a failure of

189
00:07:57,766 --> 00:08:01,766
the entire system from start to
finish, not just this one little

190
00:08:01,833 --> 00:08:05,800
place where the -
everything can be improved.

191
00:08:05,866 --> 00:08:07,399
>> DR. TRACY CELAYA BROWN: So,
here is this fabulous gif of

192
00:08:07,466 --> 00:08:10,133
Newman from Seinfeld as an
accountant or doing some

193
00:08:10,199 --> 00:08:11,266
accounting processes.

194
00:08:11,333 --> 00:08:14,733
So, with this, we want to take a
look at do we think that a CFO

195
00:08:14,800 --> 00:08:18,500
is going to walk into an office
one day and say you know what?

196
00:08:18,566 --> 00:08:24,265
We kind of lost a lot of money
but humans aren't perfect, they

197
00:08:24,333 --> 00:08:27,199
make some mistakes, they
probably need a little bit more

198
00:08:27,266 --> 00:08:29,699
training, maybe a little
bit more awareness.

199
00:08:29,766 --> 00:08:32,799
Or maybe we just need
brand-new humans in that space.

200
00:08:32,866 --> 00:08:33,899
No.

201
00:08:33,966 --> 00:08:36,566
The CFO's responsibility is to
work with their team to make

202
00:08:36,633 --> 00:08:39,600
sure that there are the right
policies, processes, structures

203
00:08:39,666 --> 00:08:43,899
in place for their people to be
able to behave correctly, that

204
00:08:43,966 --> 00:08:48,833
what those processes are, that
security is inside of it and

205
00:08:48,899 --> 00:08:51,033
woven from start
to finish, right?

206
00:08:51,100 --> 00:08:57,533
So, for example, the CFO is
going to let you know how a

207
00:08:57,600 --> 00:08:59,166
check needs to be distributed.

208
00:08:59,233 --> 00:09:00,699
There's a specific process.

209
00:09:00,766 --> 00:09:03,299
This needs to be done, this
needs to be done, these people

210
00:09:03,366 --> 00:09:04,466
need to be contacted.

211
00:09:04,533 --> 00:09:07,500
We have separation of duties for
signatures and then it goes

212
00:09:07,566 --> 00:09:08,733
out, right?

213
00:09:08,799 --> 00:09:12,500
And if this doesn't happen, then
there are consequences to that.

214
00:09:12,566 --> 00:09:15,200
Either you're not going to get
paid or payment will be delayed.

215
00:09:15,266 --> 00:09:16,799
Something is going to happen.

216
00:09:16,866 --> 00:09:21,299
But our critical functions, our
critical operations are using a

217
00:09:21,366 --> 00:09:25,799
process from start to finish
that is absolute and will

218
00:09:25,866 --> 00:09:26,633
get done.

219
00:09:26,700 --> 00:09:28,566
We need to make
sure that is correct.

220
00:09:28,633 --> 00:09:31,600
So, it is not based off of
just the user, just that one

221
00:09:31,666 --> 00:09:35,633
component or person, alright?

222
00:09:35,700 --> 00:09:39,566
>> IRA WINKLER:
So, what a lot - click.

223
00:09:39,633 --> 00:09:41,566
I'm told this is
actually a fake clicker.

224
00:09:41,633 --> 00:09:45,166
It just sends a signal to
somebody else to advance slides

225
00:09:45,233 --> 00:09:46,565
because they don't trust me.

226
00:09:46,633 --> 00:09:48,033
>> DR. TRACY CELAYA BROWN:
But now we're drowning.

227
00:09:48,100 --> 00:09:49,766
>> IRA WINKLER: Now they
just put the wrong slide.

228
00:09:49,833 --> 00:09:51,299
Oh no, they have
the right slide up.

229
00:09:51,366 --> 00:09:52,699
I have the wrong slide.

230
00:09:52,766 --> 00:09:54,099
So, anyway, here's the thing.

231
00:09:54,166 --> 00:09:57,733
Now, what most people don't
know - I don't tell people.

232
00:09:57,799 --> 00:09:58,699
It's not like you should know.

233
00:09:58,766 --> 00:10:01,933
But I'm certified as a
master scuba diver trainer.

234
00:10:02,000 --> 00:10:03,200
It is just one of my things.

235
00:10:03,266 --> 00:10:04,233
I love scuba diving.

236
00:10:04,299 --> 00:10:06,533
I thought, how do I make it
tax deductible so I could do

237
00:10:06,600 --> 00:10:07,633
it more?

238
00:10:07,700 --> 00:10:09,700
You become an instructor so you
theoretically make money off

239
00:10:09,766 --> 00:10:10,665
of it.

240
00:10:10,733 --> 00:10:13,233
So, anyway, I'm a master
scuba diver instructor and in

241
00:10:13,299 --> 00:10:16,733
training, to be an instructor,
this is where I first heard the

242
00:10:16,799 --> 00:10:19,500
term you can't stop stupid
because the instructor

243
00:10:19,566 --> 00:10:22,333
instructor - I guess that's what
you call them - the instructor

244
00:10:22,399 --> 00:10:25,966
instructor was out there telling
us, for example, oh, you can't

245
00:10:26,033 --> 00:10:29,033
stop stupid because somebody is
going to do something wrong.

246
00:10:29,100 --> 00:10:31,333
I was like, sitting there
thinking you know what?

247
00:10:31,399 --> 00:10:35,633
We're taking like, hundreds
of hours of instruction to

248
00:10:35,700 --> 00:10:37,166
stop stupid.

249
00:10:37,233 --> 00:10:39,699
Because when you think about it
- and how many people in this

250
00:10:39,766 --> 00:10:42,899
room just for my own benefit,
are certified in scuba?

251
00:10:43,899 --> 00:10:44,500
Okay.

252
00:10:44,566 --> 00:10:46,399
About maybe 15% of people.

253
00:10:46,466 --> 00:10:47,066
Awesome.

254
00:10:47,133 --> 00:10:47,966
I like you guys.

255
00:10:48,033 --> 00:10:50,500
Anyway, the rest of
you, get trained. Okay.

256
00:10:50,566 --> 00:10:54,766
But anyway, so the 15% of you,
you know that before you can -

257
00:10:54,833 --> 00:10:57,600
you know, get in the water
scuba-wise, you have to

258
00:10:57,666 --> 00:10:58,299
go ahead.

259
00:10:58,366 --> 00:10:59,266
You have to take a medical.

260
00:10:59,333 --> 00:11:01,199
They put you in a pool to
make sure you're not going to

261
00:11:01,266 --> 00:11:02,299
freak out.

262
00:11:02,366 --> 00:11:04,566
You know, they say oh, we want
you to swim like two hundred

263
00:11:04,633 --> 00:11:07,500
yards but really it's just to
make sure you don't freak out in

264
00:11:07,566 --> 00:11:08,633
the water.

265
00:11:08,700 --> 00:11:11,399
Then you have the medical forms
and before we put you in scuba

266
00:11:11,466 --> 00:11:14,333
equipment, they give you like,
you know, dozens of hours of

267
00:11:14,399 --> 00:11:17,700
training primarily on how not to
kill yourself which is really

268
00:11:17,766 --> 00:11:21,033
the point, and then after that,
then they're like, okay, we'll

269
00:11:21,100 --> 00:11:24,233
put you in a pool and putting
people in a pool for the first

270
00:11:24,299 --> 00:11:26,533
time, we make sure they don't
freak out, that they can do

271
00:11:26,600 --> 00:11:31,266
basic skills that stop stupid
for lack of a better term.

272
00:11:31,333 --> 00:11:34,966
You know, they could do that and
then once they demonstrate that,

273
00:11:35,033 --> 00:11:37,399
then we go ahead and
take them to open water.

274
00:11:37,466 --> 00:11:40,500
Now, the open water, this is a
picture of like, a class on a

275
00:11:40,566 --> 00:11:42,266
dive platform.

276
00:11:42,333 --> 00:11:45,966
This platform is not going to be
more than thirty feet deep and

277
00:11:46,033 --> 00:11:48,233
you know, generally it is hard
to kill yourself in less than

278
00:11:48,299 --> 00:11:48,899
thirty feet.

279
00:11:48,966 --> 00:11:50,733
It can happen but really hard.

280
00:11:50,799 --> 00:11:53,866
But anyway, so there you are in
thirty feet of water or usually

281
00:11:53,933 --> 00:11:57,366
a lot less and you
have a small class.

282
00:11:57,433 --> 00:12:01,200
We get in there and we're - this
class has one instructor and it

283
00:12:01,266 --> 00:12:04,632
looks like four or five students
and then the other part is it's

284
00:12:04,700 --> 00:12:07,566
like the instructor has to pay
attention going one skill to

285
00:12:07,633 --> 00:12:09,933
another from one
student to another.

286
00:12:10,000 --> 00:12:14,233
A smart instructor also brings -
the circle back there - is what

287
00:12:14,299 --> 00:12:17,699
is known as a, like, an
assistant instructor or a dive

288
00:12:17,766 --> 00:12:21,366
master to watch the
people just to make sure.

289
00:12:21,433 --> 00:12:24,799
And there was one time where I
was like, you know, certifying a

290
00:12:24,866 --> 00:12:27,733
class and then all of a sudden,
we're on the dive platform and

291
00:12:27,799 --> 00:12:31,132
one guy on the edge, I notice in
the corner of my eye, he decides

292
00:12:31,200 --> 00:12:34,433
to see what is under
the dive platform.

293
00:12:34,500 --> 00:12:37,299
You know, no matter how many
times we tell them do not get

294
00:12:37,366 --> 00:12:41,000
off the platform once we go
down, he decides to look under.

295
00:12:41,066 --> 00:12:43,966
But anyway, by that point in
time, the assistant instructor I

296
00:12:44,033 --> 00:12:46,633
brought with me started pulling
him up and that was good.

297
00:12:46,700 --> 00:12:49,899
But then you stop and think what
happens if something goes wrong?

298
00:12:49,966 --> 00:12:52,966
What a lot of people don't know
is before we are allowed to take

299
00:12:53,033 --> 00:12:55,700
students somewhere in the
first place, I am insured.

300
00:12:55,766 --> 00:12:57,766
The dive school is insured.

301
00:12:57,833 --> 00:13:00,399
The facility where
we go is insured.

302
00:13:00,466 --> 00:13:02,966
We know where all of the
hyperbaric chambers are in the

303
00:13:03,033 --> 00:13:03,866
local area.

304
00:13:03,933 --> 00:13:06,066
We have first aid
kits and so on.

305
00:13:06,133 --> 00:13:09,100
We know how to call doctors,
ambulances, whatever.

306
00:13:09,166 --> 00:13:12,633
And this is all - and
statistically, diving is safer

307
00:13:12,700 --> 00:13:13,600
than bowling.

308
00:13:13,666 --> 00:13:15,333
At least, that is
what they tell me.

309
00:13:15,399 --> 00:13:18,200
But statistically, diving is
safer than bowling because they

310
00:13:18,266 --> 00:13:21,299
put all of these protections
in place, for lack of a better

311
00:13:21,366 --> 00:13:23,299
term, to stop stupid.

312
00:13:23,366 --> 00:13:25,033
And there is a whole
process to that.

313
00:13:26,333 --> 00:13:29,000
Anyway, so let's talk about
safety science because really

314
00:13:29,066 --> 00:13:32,033
what I just embodied is the
concept of safety science.

315
00:13:32,100 --> 00:13:35,333
A lot of people when they talk
to user awareness, stopping user

316
00:13:35,399 --> 00:13:38,366
error, they always talk you
know, they always love to talk

317
00:13:38,433 --> 00:13:42,033
psychology, marketing,
how to influence users.

318
00:13:42,100 --> 00:13:45,600
I want people to start
thinking safety science.

319
00:13:45,666 --> 00:13:48,366
Everything I described
previously about the scuba thing

320
00:13:48,433 --> 00:13:50,333
is essentially safety science.

321
00:13:50,399 --> 00:13:54,500
Safety science is a well-funded
discipline and what they do is

322
00:13:54,566 --> 00:13:57,533
they look at how people get
injured in the workplace.

323
00:13:57,600 --> 00:14:00,933
And injuries in the workplace
cost companies lots and lots

324
00:14:01,000 --> 00:14:01,766
of money.

325
00:14:01,833 --> 00:14:03,899
Somebody gets injured in
a factory for example.

326
00:14:03,966 --> 00:14:06,799
They might have to stop the
whole factory production,

327
00:14:06,866 --> 00:14:10,199
costing them millions of
dollars a day if not more.

328
00:14:10,266 --> 00:14:13,199
So, what they do is they go
through everything but they look

329
00:14:13,266 --> 00:14:17,766
at the user who gets injured,
not as the proximity of the

330
00:14:17,833 --> 00:14:20,600
error but just as a part
of the entire system.

331
00:14:20,666 --> 00:14:25,466
If that person got injured, it
is a failure of the system from

332
00:14:25,533 --> 00:14:26,566
start to finish.

333
00:14:26,633 --> 00:14:30,600
They look at what enabled that
person to be injured, why was

334
00:14:30,666 --> 00:14:33,233
that person in a
proximity to be injured?

335
00:14:33,299 --> 00:14:34,766
How was the response?

336
00:14:34,833 --> 00:14:38,699
How did we stop it form getting
more injured and so on?

337
00:14:38,766 --> 00:14:41,899
Again, though, the user is just
the proximity of the error

338
00:14:41,966 --> 00:14:44,899
should there be an error
and it is again, a symptom.

339
00:14:44,966 --> 00:14:48,000
I keep repeating that
but it is so critical.

340
00:14:48,066 --> 00:14:50,066
>> DR. TRACY CELAYA BROWN: So,
with that concept, the user and

341
00:14:50,133 --> 00:14:53,366
the proximity of the user to an
error, let's take a look at the

342
00:14:53,433 --> 00:14:56,766
case of the 737 MAX 8 aircraft.

343
00:14:56,833 --> 00:15:01,000
So, with that particular case,
there was a system setup for

344
00:15:01,066 --> 00:15:04,433
error from start in design
through commissioning

345
00:15:04,500 --> 00:15:05,799
and certification.

346
00:15:05,866 --> 00:15:10,100
The design of that particular
engine was lifted above the wing

347
00:15:10,166 --> 00:15:12,799
which changed the
center of gravity for that

348
00:15:12,866 --> 00:15:13,933
particular aircraft.

349
00:15:14,000 --> 00:15:17,600
As a result, there were sensors
at the front of the aircraft

350
00:15:17,666 --> 00:15:22,633
that engaged a new
software program called MCAS.

351
00:15:22,700 --> 00:15:27,433
MCAS would then adjust the lift
of the nose and turn the nose

352
00:15:27,500 --> 00:15:31,333
down in some cases or in this
case when the pilots wanted to

353
00:15:31,399 --> 00:15:32,899
lift it up.

354
00:15:32,966 --> 00:15:37,000
So, in our first unfortunate
and tragic incident, there are

355
00:15:37,066 --> 00:15:40,000
reports that state that they
feel the pilots were in

356
00:15:40,066 --> 00:15:44,299
essentially a fight with the
automated system of the aircraft

357
00:15:44,366 --> 00:15:46,799
because of all of these
different environmental or

358
00:15:46,866 --> 00:15:48,966
components that were
happening at that time.

359
00:15:49,033 --> 00:15:53,600
In the second tragic incident,
we found that it looked like the

360
00:15:53,666 --> 00:15:56,366
pilots were able to
override the system.

361
00:15:56,433 --> 00:16:00,200
Unfortunately, they
did that too late.

362
00:16:00,266 --> 00:16:02,000
As a result, the plane crashed.

363
00:16:02,066 --> 00:16:05,933
Now, when I say a systematic
failure, what we find later on

364
00:16:06,000 --> 00:16:09,899
through reports is that with the
design of the engine, the change

365
00:16:09,966 --> 00:16:14,466
in the center of gravity, the
sensors at the front which also

366
00:16:14,533 --> 00:16:17,799
allowed for an indicator, a
disagree indicator, that the

367
00:16:17,866 --> 00:16:21,100
pilots were used to having to
let them know that there was a

368
00:16:21,166 --> 00:16:23,899
discrepancy in their system or
that the incorrect data was

369
00:16:23,966 --> 00:16:26,933
being sent, they didn't
have that anymore.

370
00:16:27,000 --> 00:16:32,266
Then the faulty sensors were
sending incorrect data and

371
00:16:32,333 --> 00:16:36,833
incorrectly engaging the MCAS
system which caused the fight

372
00:16:36,899 --> 00:16:39,066
between the pilot and the plane.

373
00:16:39,133 --> 00:16:42,899
Now, at the same time in the
background of that environmental

374
00:16:42,966 --> 00:16:49,833
system, we have - or that system
overall - we have a sped-up

375
00:16:49,899 --> 00:16:52,533
process that is fast
tracking the aircraft through

376
00:16:52,600 --> 00:16:56,333
commissioning and
eventually certification.

377
00:16:56,399 --> 00:17:00,299
So, through the second incident,
we're able to see that is it

378
00:17:00,366 --> 00:17:04,032
possible that the pilots
were able to stop this in

379
00:17:04,098 --> 00:17:05,133
the process?

380
00:17:05,200 --> 00:17:08,900
Maybe because eventually they
learned that they could override

381
00:17:08,965 --> 00:17:10,899
the MCAS system.

382
00:17:10,965 --> 00:17:13,065
But there was
everything against them.

383
00:17:13,133 --> 00:17:16,733
They had bad sensors sending
bad data, engaging a system -

384
00:17:16,799 --> 00:17:19,465
engaging a software system
that they didn't know existed.

385
00:17:19,532 --> 00:17:22,098
In the meantime, they were only
provided about two hours' worth

386
00:17:22,165 --> 00:17:24,866
of iPad training prior to ever
getting into the cockpit.

387
00:17:24,933 --> 00:17:28,400
And then you have the fast
tracking of the aircraft

388
00:17:28,465 --> 00:17:30,832
through certification.

389
00:17:30,900 --> 00:17:35,533
So, this is what we mean
by it is not just the pilot

390
00:17:35,599 --> 00:17:36,633
error, right?

391
00:17:36,700 --> 00:17:40,333
The pilots were initially
blamed for the crash.

392
00:17:40,400 --> 00:17:44,033
However, through additional
investigation, we found that

393
00:17:44,099 --> 00:17:47,566
there were multiple points where
there were failures involved

394
00:17:47,633 --> 00:17:48,966
from start to finish.

395
00:17:49,033 --> 00:17:52,366
So, if we take that concept and
apply it to how we look at our

396
00:17:52,433 --> 00:17:56,566
users in security, in our
business functions, what type of

397
00:17:56,633 --> 00:17:59,733
an environment, what type of a
culture are we creating for our

398
00:17:59,799 --> 00:18:02,433
people so that they are
successful, so that they are

399
00:18:02,500 --> 00:18:03,733
mitigating risk?

400
00:18:03,799 --> 00:18:06,500
Are we providing them with the
right processes in place, with

401
00:18:06,566 --> 00:18:07,566
the right regulations?

402
00:18:07,633 --> 00:18:09,066
Are we following our own rules?

403
00:18:09,133 --> 00:18:12,799
How are we as a whole
contributing to that or how are

404
00:18:12,866 --> 00:18:16,933
we as a whole leveraging our
professional skills, our

405
00:18:17,000 --> 00:18:19,500
knowledge and experience in
security and helping our

406
00:18:19,566 --> 00:18:22,666
business so that they are
successful from start to finish?

407
00:18:22,733 --> 00:18:24,500
>> IRA WINKLER: So,
where does blame fall?

408
00:18:24,566 --> 00:18:26,933
Again, going back to safety
science, not all of these bro

409
00:18:27,000 --> 00:18:31,166
sciences but safety science with
hard data, not just well, we

410
00:18:31,233 --> 00:18:33,466
just need users
to be more aware.

411
00:18:33,533 --> 00:18:34,565
Where does the blame fall?

412
00:18:34,633 --> 00:18:39,900
Statistically, they do studies
and show that 90% of injuries of

413
00:18:39,966 --> 00:18:43,799
where - of workplace injuries
are the result of the

414
00:18:43,866 --> 00:18:47,766
environment, not the result of
the people doing something

415
00:18:47,833 --> 00:18:48,733
or other.

416
00:18:48,799 --> 00:18:51,000
In other words, like in a
hardcore factory environment,

417
00:18:51,066 --> 00:18:53,200
like there is one place I think
I might have told this story

418
00:18:53,266 --> 00:18:57,166
before to RSA, but you know, in
one case they were basically

419
00:18:57,233 --> 00:19:01,500
having accidents in a warehouse
where people were being hit

420
00:19:01,566 --> 00:19:02,733
by forklifts.

421
00:19:02,799 --> 00:19:06,666
So, what they ended up deciding
to do was draw a line down the

422
00:19:06,733 --> 00:19:10,566
aisles and say people stay on
one side, forklifts stay on

423
00:19:10,633 --> 00:19:11,500
the other.

424
00:19:11,566 --> 00:19:15,533
That cut down 90% of injuries
from forklift accidents.

425
00:19:15,599 --> 00:19:17,133
What were the last 10%?

426
00:19:17,200 --> 00:19:20,333
People on their iPads wandering
into a forklift or a forklift

427
00:19:20,400 --> 00:19:23,233
driver looking some other
way, driving into a user.

428
00:19:23,299 --> 00:19:25,366
That is where
these things happen.

429
00:19:25,433 --> 00:19:26,500
It happens in the same thing.

430
00:19:26,566 --> 00:19:28,433
Think about phishing messages.

431
00:19:28,500 --> 00:19:30,466
Why do people click
on phishing messages?

432
00:19:30,533 --> 00:19:33,666
It's like, well, 90% of the
problem is that the users have

433
00:19:33,733 --> 00:19:36,166
the phishing message in
their inbox, not that they

434
00:19:36,233 --> 00:19:37,265
actually click.

435
00:19:37,333 --> 00:19:39,400
The pilot error - I mean,
Tracy just went through the

436
00:19:39,466 --> 00:19:40,500
whole thing.

437
00:19:40,566 --> 00:19:45,666
Yeah, maybe 10% of that whole
737 debacle was a result of the

438
00:19:45,733 --> 00:19:51,133
pilots not doing certain things
perfectly, but the other 90% was

439
00:19:51,200 --> 00:19:54,533
causing them, steering them in
the wrong directions most of

440
00:19:54,599 --> 00:19:55,599
the time.

441
00:19:55,666 --> 00:19:57,233
And that is, frankly, what
we're dealing with in the

442
00:19:57,299 --> 00:19:59,200
cybersecurity world as well.

443
00:19:59,266 --> 00:20:02,900
90% of the environment - or the
environment is driving users to

444
00:20:02,966 --> 00:20:08,433
90% of where they make their
error, either because they're in

445
00:20:08,500 --> 00:20:11,433
the wrong position to make the
error or they are put in the

446
00:20:11,500 --> 00:20:14,500
wrong position or they're not
given training or whatever.

447
00:20:14,566 --> 00:20:16,766
But what is the last 10%?

448
00:20:16,833 --> 00:20:18,900
Because again, there is a
purpose for awareness training.

449
00:20:18,966 --> 00:20:20,265
What is the last 10%?

450
00:20:20,333 --> 00:20:24,033
Last 10%, you know, from
accident perspective, safety

451
00:20:24,099 --> 00:20:25,966
perspective, carelessness.

452
00:20:26,033 --> 00:20:28,199
Yes, people do dumb things.

453
00:20:28,266 --> 00:20:29,700
People don't pay attention.

454
00:20:29,766 --> 00:20:30,900
They're on their iPad.

455
00:20:30,966 --> 00:20:33,265
They are trying to listen to
music and open up another

456
00:20:33,333 --> 00:20:34,900
application while
doing their work.

457
00:20:34,966 --> 00:20:35,966
That happens.

458
00:20:36,033 --> 00:20:39,332
Sometimes there is blatant
ignorance where they just don't

459
00:20:39,400 --> 00:20:41,566
know what they are doing,
how they are doing.

460
00:20:41,633 --> 00:20:43,900
I would argue that is a
little bit of training.

461
00:20:43,966 --> 00:20:45,565
Sometimes there is
willful ignorance.

462
00:20:45,633 --> 00:20:47,766
Nothing is going to overcome -
no training is going to

463
00:20:47,833 --> 00:20:48,766
overcome that.

464
00:20:48,833 --> 00:20:51,033
And then here is
another thing we forget.

465
00:20:51,099 --> 00:20:54,332
When we start talking about
awareness to prevent user

466
00:20:54,400 --> 00:20:59,799
created incidents, malice,
sometimes users just want to

467
00:20:59,866 --> 00:21:01,299
create incidents.

468
00:21:01,366 --> 00:21:03,500
They are doing
things purposefully.

469
00:21:03,566 --> 00:21:07,200
The system, frankly, going back
to accounting as an example, the

470
00:21:07,266 --> 00:21:09,799
system doesn't care
why users do something.

471
00:21:09,866 --> 00:21:11,666
Nor should it care
why they do it.

472
00:21:11,733 --> 00:21:15,099
They just care that at some
point, they initiate the loss

473
00:21:15,166 --> 00:21:19,433
and we have to try to overcome
that initiation of the loss.

474
00:21:19,500 --> 00:21:24,433
But anyway, awareness training
might fit in on this 10% but it

475
00:21:24,500 --> 00:21:27,366
is still only 10%
of the problem.

476
00:21:27,433 --> 00:21:30,833
And let's talk about but at the
end of the day, awareness itself

477
00:21:30,900 --> 00:21:34,466
is only going to deal
with 20% of that 10%.

478
00:21:34,533 --> 00:21:37,733
And there is the concept of
applied behavioral science.

479
00:21:37,799 --> 00:21:41,233
Applied behavioral science or
the ABCs of behavioral science

480
00:21:41,299 --> 00:21:42,833
because ABC.

481
00:21:42,900 --> 00:21:45,433
An antecedent is
essentially information.

482
00:21:45,500 --> 00:21:48,066
It is awareness training,
whatever you want to call it.

483
00:21:48,133 --> 00:21:50,000
It is supposed to
drive behaviors.

484
00:21:50,066 --> 00:21:53,000
It is - well, I guess
the better word is it kind of

485
00:21:53,066 --> 00:21:54,466
influences behaviors.

486
00:21:54,533 --> 00:21:58,599
Then, as a result of behavior,
you get a consequence, you know,

487
00:21:58,666 --> 00:22:03,099
and the consequence itself
reinforces the behavior or it

488
00:22:03,166 --> 00:22:04,265
can discourage the behavior.

489
00:22:04,333 --> 00:22:08,333
So, for example, I use the
example if I am in a restaurant,

490
00:22:08,400 --> 00:22:10,833
server comes over, tells
me the place is hot.

491
00:22:10,900 --> 00:22:11,799
I go, I'm a man.

492
00:22:11,866 --> 00:22:12,966
Give me that plate.

493
00:22:13,033 --> 00:22:14,233
I go to grab the plate.

494
00:22:14,299 --> 00:22:15,700
I singe my fingers.

495
00:22:15,766 --> 00:22:17,366
I try to act like I'm cool.

496
00:22:17,433 --> 00:22:18,400
No problem here.

497
00:22:18,466 --> 00:22:19,799
I put the plate down.

498
00:22:19,866 --> 00:22:22,900
I try to pull my skin off
and everything like that.

499
00:22:22,966 --> 00:22:25,366
And then what happens is the
next time the server shows up

500
00:22:25,433 --> 00:22:28,400
with a plate of ice cream, I'm
like oh no, please, right here

501
00:22:28,466 --> 00:22:29,599
for you.

502
00:22:29,666 --> 00:22:30,799
Why?

503
00:22:30,866 --> 00:22:33,433
Because I suffered the
consequence and now here is part

504
00:22:33,500 --> 00:22:35,299
of the issue you
have to understand.

505
00:22:35,366 --> 00:22:38,633
Too often there is a
positive consequence for

506
00:22:38,700 --> 00:22:39,666
negative behavior.

507
00:22:39,733 --> 00:22:44,233
What is the consequence, for
example, for reusing your

508
00:22:44,299 --> 00:22:48,599
password on like, your amazon
account that you would for your

509
00:22:48,666 --> 00:22:49,933
work account?

510
00:22:50,000 --> 00:22:51,266
There is no consequence.

511
00:22:51,333 --> 00:22:53,599
It is actually a positive
consequence because it gives you

512
00:22:53,666 --> 00:22:55,832
one less password to know.

513
00:22:55,900 --> 00:22:59,400
So, you've got to understand
that consequences are much more

514
00:22:59,466 --> 00:23:03,000
impactful, four times
more impactful than just

515
00:23:03,066 --> 00:23:04,599
providing information.

516
00:23:04,666 --> 00:23:07,566
So, anyway, we'll talk about
that a little bit more.

517
00:23:07,633 --> 00:23:09,866
You want to create
the environment.

518
00:23:09,933 --> 00:23:11,799
>> DR. TRACY CELAYA BROWN:
So, with this, we posit this

519
00:23:11,866 --> 00:23:15,533
particular model or a model like
it but we'll start with this.

520
00:23:15,599 --> 00:23:18,366
So, here you've probably seen
something really similar

521
00:23:18,433 --> 00:23:23,066
referred to as boom or flash
boom or flash bang, right?

522
00:23:23,133 --> 00:23:25,799
The moment where an
incident is taking place.

523
00:23:25,866 --> 00:23:26,900
The user is there.

524
00:23:26,966 --> 00:23:29,765
They have got something in front
of them and boom, there is the

525
00:23:29,833 --> 00:23:32,200
action that starts
the chain of events.

526
00:23:32,266 --> 00:23:35,666
But we also have left of boom
which is our preemptive measures

527
00:23:35,733 --> 00:23:38,666
and then our right of boom, our
preemptive measures and our left

528
00:23:38,733 --> 00:23:41,299
of boom, military
right, military left.

529
00:23:41,366 --> 00:23:43,900
And our left of boom, right,
which is our response and what

530
00:23:43,966 --> 00:23:45,533
we do to recover from that.

531
00:23:45,599 --> 00:23:47,832
But we are going
to start with boom.

532
00:23:47,900 --> 00:23:52,000
So, with this particular model,
we got this from military and

533
00:23:52,066 --> 00:23:55,400
counter terrorism
strategy, right?

534
00:23:55,466 --> 00:23:58,966
This was what was conducted in
the military across the board

535
00:23:59,033 --> 00:24:01,132
and we start with
boom here, right?

536
00:24:01,200 --> 00:24:03,933
We start with the user and the
proximity of the user to an

537
00:24:04,000 --> 00:24:09,400
event or the start of
a user-initiated loss.

538
00:24:09,466 --> 00:24:11,733
So, boom, here is the explosion.

539
00:24:11,799 --> 00:24:12,866
>> IRA WINKLER: Okay.

540
00:24:12,933 --> 00:24:16,500
Yeah, so anyway, left of boom on
this slide is what led to the

541
00:24:16,566 --> 00:24:17,933
explosion for example.

542
00:24:18,000 --> 00:24:20,433
You know, like, so if you're
dealing with an explosion at a

543
00:24:20,500 --> 00:24:23,833
high level, it's like, well,
you're - from a counter

544
00:24:23,900 --> 00:24:26,633
terrorism perspective, you're
like, how did the terrorists get

545
00:24:26,700 --> 00:24:28,866
into the position
where they have a bomb?

546
00:24:28,933 --> 00:24:30,266
How did they get trained?

547
00:24:30,333 --> 00:24:31,766
How did they put things there?

548
00:24:31,833 --> 00:24:33,966
Then likewise, from a
terrorism/counter terrorism

549
00:24:34,033 --> 00:24:36,799
perspective, you know, for
example, that they might go

550
00:24:36,866 --> 00:24:40,266
ahead and they might try,
for example, to blow up

551
00:24:40,333 --> 00:24:41,299
the Pentagon.

552
00:24:41,366 --> 00:24:44,599
You know, not to downplay
something like the 9/11 attacks

553
00:24:44,666 --> 00:24:47,633
but what a lot of people don't
know is that the Pentagon

554
00:24:47,700 --> 00:24:50,900
actually went through a series
of hardening in the, like, a

555
00:24:50,966 --> 00:24:54,332
couple years before
the 9/11 attacks.

556
00:24:54,400 --> 00:24:58,233
So, the deaths at the Pentagon
and the damage to the Pentagon

557
00:24:58,299 --> 00:25:01,599
was significantly decreased
because they put a whole bunch

558
00:25:01,666 --> 00:25:04,500
of protection around that,
knowing that at some point the

559
00:25:04,566 --> 00:25:07,099
Pentagon might be
a potential attack.

560
00:25:07,166 --> 00:25:08,733
Then there was the
boom, the actual boom.

561
00:25:08,799 --> 00:25:11,233
Then you have to go ahead and
left of boom is essentially

562
00:25:11,299 --> 00:25:14,799
saying how do we approach
through our reaction?

563
00:25:14,866 --> 00:25:17,599
Do we plan for secondary
explosions, for example, like

564
00:25:17,666 --> 00:25:19,233
the Boston Marathon bombing?

565
00:25:19,299 --> 00:25:22,833
The Boston Marathon bombing, you
know, again, I hate to learn off

566
00:25:22,900 --> 00:25:25,500
tragedies but that is one of
the better places to learn.

567
00:25:25,566 --> 00:25:27,933
One of the problems
with that was that there was a

568
00:25:28,000 --> 00:25:29,366
secondary explosion.

569
00:25:29,433 --> 00:25:30,866
There was the initial explosion.

570
00:25:30,933 --> 00:25:33,799
First responders started going
in and a few minutes later,

571
00:25:33,866 --> 00:25:35,566
there was a secondary explosion.

572
00:25:35,633 --> 00:25:40,099
And first responders and people
preparing for a strategy have to

573
00:25:40,166 --> 00:25:43,966
know how do we mitigate the
likelihood or the damage

574
00:25:44,033 --> 00:25:48,065
resulting from secondary attacks
while we do have to respond?

575
00:25:48,133 --> 00:25:50,166
You know, what happens if
there is poisonous gasses?

576
00:25:50,233 --> 00:25:52,533
How do we deal with
that proactively?

577
00:25:52,599 --> 00:25:55,099
What happens if we have to
shut down a city or something?

578
00:25:55,166 --> 00:25:56,933
>> DR. TRACY CELAYA BROWN: With
the railroad tracks, right, and

579
00:25:57,000 --> 00:25:58,266
derailments as well.

580
00:25:58,333 --> 00:26:01,433
So, we can take lessons
absolutely from terrorist

581
00:26:01,500 --> 00:26:03,566
attacks but we
can also take lessons from

582
00:26:03,633 --> 00:26:05,000
emergency management.

583
00:26:05,066 --> 00:26:08,799
So, if we look at railroad
derailments, what do we do to

584
00:26:08,866 --> 00:26:10,599
the right of boom
in order to prepare?

585
00:26:10,666 --> 00:26:14,000
We have gone through the process
of putting stickers on different

586
00:26:14,066 --> 00:26:16,433
boxcars to make sure that people
understand that there are

587
00:26:16,500 --> 00:26:17,666
hazardous materials.

588
00:26:17,733 --> 00:26:20,566
We have gone through the process
of running these tracks through

589
00:26:20,633 --> 00:26:25,599
less densely populated areas and
then we know that at some point

590
00:26:25,666 --> 00:26:27,299
a boom is going to occur.

591
00:26:27,366 --> 00:26:30,500
So, to the left of boom, what
are we doing to respond to that?

592
00:26:30,566 --> 00:26:33,266
Do we have the right
procedures in place afterwards

593
00:26:33,333 --> 00:26:34,200
for medical care?

594
00:26:34,266 --> 00:26:36,866
Do we know the emergency
responders that need to come

595
00:26:36,933 --> 00:26:39,500
into place to take care
of any chemical spills?

596
00:26:39,566 --> 00:26:45,000
So, the same type of process
or model applies with not only

597
00:26:45,066 --> 00:26:49,400
counterterrorism but with
emergency remediation and even

598
00:26:49,466 --> 00:26:52,866
in our own organizations.

599
00:26:52,933 --> 00:26:55,333
>> IRA WINKLER: So, anyway, this
is where we start the concept of

600
00:26:55,400 --> 00:26:57,900
user-initiated loss and we
really wanted to drill it in

601
00:26:57,966 --> 00:27:02,132
because if you get nothing else
out of this presentation, the

602
00:27:02,200 --> 00:27:04,000
problem is not an unaware user.

603
00:27:04,066 --> 00:27:07,200
The problem is not that
the user causes loss.

604
00:27:07,266 --> 00:27:10,166
The user never causes a loss.

605
00:27:10,233 --> 00:27:11,599
You're enabling that.

606
00:27:11,666 --> 00:27:14,433
They initiate a chain of events.

607
00:27:14,500 --> 00:27:16,533
This is the most
critical thing to take away.

608
00:27:16,599 --> 00:27:20,466
A user should never be able to
click on an email message and

609
00:27:20,533 --> 00:27:24,065
ruin your network because I
said this, wow, almost a dozen

610
00:27:24,133 --> 00:27:25,200
years ago.

611
00:27:25,266 --> 00:27:28,833
If a user can click - if a user
can click on an email and ruin

612
00:27:28,900 --> 00:27:30,799
your network, your
network sucks.

613
00:27:30,866 --> 00:27:36,200
The user can just potentially
initiate a chain of events that

614
00:27:36,266 --> 00:27:39,299
is completely expected
in almost all cases.

615
00:27:39,366 --> 00:27:42,266
So, the user is not
the person who fails.

616
00:27:42,333 --> 00:27:43,833
It's the system that fails.

617
00:27:43,900 --> 00:27:46,966
The user, again, in this case
is just the canary in the

618
00:27:47,033 --> 00:27:47,699
coal mine.

619
00:27:47,766 --> 00:27:50,333
The user is the
proximity of the loss.

620
00:27:50,400 --> 00:27:53,433
So, you want to stop the
potential for user-initiated

621
00:27:53,500 --> 00:27:56,799
loss and then once you stop the
potential for user-initiated

622
00:27:56,866 --> 00:27:59,933
loss, no matter what you do,
something is always going

623
00:28:00,000 --> 00:28:00,866
to happen.

624
00:28:00,933 --> 00:28:03,500
You want to stop the
realization of the loss after

625
00:28:03,566 --> 00:28:05,166
it has been initialized.

626
00:28:05,233 --> 00:28:09,366
So, again, much like - sorry,
I'm bad at this - left of boom,

627
00:28:09,433 --> 00:28:10,666
boom, and right of boom.

628
00:28:10,733 --> 00:28:12,233
I don't know my right
from my left usually.

629
00:28:12,299 --> 00:28:16,166
So, anyway, you want
to mitigate the loss.

630
00:28:16,233 --> 00:28:18,033
So, left of boom, start there.

631
00:28:18,099 --> 00:28:21,233
How do you prevent the user
from being in the position to

632
00:28:21,299 --> 00:28:24,099
initiate the loss because
everybody talks about we want to

633
00:28:24,166 --> 00:28:25,233
empower the users?

634
00:28:25,299 --> 00:28:26,500
I'm like, no you don't.

635
00:28:26,566 --> 00:28:28,400
You really don't want
to empower the users.

636
00:28:28,466 --> 00:28:31,500
You want the users to
have the capability.

637
00:28:31,566 --> 00:28:34,766
You want the users to have the
knowledge, skills, and ability

638
00:28:34,833 --> 00:28:36,533
to do their job properly.

639
00:28:36,599 --> 00:28:40,233
And some people maybe want to
give them the ability to serve

640
00:28:40,299 --> 00:28:41,266
their customers better.

641
00:28:41,333 --> 00:28:44,599
That doesn't mean you keep
throwing on functionality they

642
00:28:44,666 --> 00:28:45,433
don't need.

643
00:28:45,500 --> 00:28:48,099
You don't throw on
accesses they don't need.

644
00:28:48,166 --> 00:28:49,433
You don't do all of this
stuff and give them all of

645
00:28:49,500 --> 00:28:51,000
this capability.

646
00:28:51,066 --> 00:28:54,866
Frankly, what you need to do is
you need to stop them from being

647
00:28:54,933 --> 00:28:56,666
in the position
to initiate loss.

648
00:28:56,733 --> 00:28:58,633
It's not just taking
away capability.

649
00:28:58,700 --> 00:29:00,633
It is also filtering
out the attacks.

650
00:29:00,700 --> 00:29:03,599
So, for example, anti-malware,
anti-phishing software.

651
00:29:03,666 --> 00:29:07,200
That filters out that type of
attack from getting to them.

652
00:29:07,266 --> 00:29:10,033
There is a whole bunch of other
ways, locking the door stops

653
00:29:10,099 --> 00:29:14,933
malicious people from entering
the facilities and getting into

654
00:29:15,000 --> 00:29:18,133
positions where they could steal
things or manipulate users.

655
00:29:18,200 --> 00:29:22,033
Same thing like, for example,
putting like caller ID on

656
00:29:22,099 --> 00:29:25,332
telephone systems so that when
somebody calls in, they can't

657
00:29:25,400 --> 00:29:27,900
pretend to be from
inside the company.

658
00:29:27,966 --> 00:29:30,399
You're going ahead and you're
doing the left of boom

659
00:29:30,466 --> 00:29:35,699
procedures to stop potential
attacks from reaching the user

660
00:29:35,766 --> 00:29:38,466
or I shouldn't say potential
attacks - they might be attacks

661
00:29:38,533 --> 00:29:43,265
but stopping the ability for a
loss to be initiated at the user

662
00:29:43,333 --> 00:29:44,799
once it gets there.

663
00:29:44,866 --> 00:29:47,166
And same thing,
creating a culture.

664
00:29:47,233 --> 00:29:52,000
You know, there was one time
where - so, for example, I was -

665
00:29:52,066 --> 00:29:54,966
when I left the NSA, I went to
work for a government contractor

666
00:29:55,033 --> 00:29:58,433
and I came into the office one
day and it was like my third,

667
00:29:58,500 --> 00:29:59,799
fourth day on the job.

668
00:29:59,866 --> 00:30:01,666
I get a call from
the security manager.

669
00:30:01,733 --> 00:30:04,000
Like, Ira, can you
come into my office?

670
00:30:04,066 --> 00:30:04,700
I'm like, okay.

671
00:30:04,766 --> 00:30:05,833
So, I walk into the office.

672
00:30:05,900 --> 00:30:08,099
Ira, are you missing anything?

673
00:30:08,166 --> 00:30:10,466
I'm like, not that I know of.

674
00:30:10,533 --> 00:30:11,233
He's like, you are.

675
00:30:11,299 --> 00:30:12,366
Want to guess what it is?

676
00:30:12,433 --> 00:30:14,333
I'm like, are we going to play
twenty questions or you want to

677
00:30:14,400 --> 00:30:15,333
tell me what I'm here for?

678
00:30:15,400 --> 00:30:18,366
He's like, where's
your burn bag.

679
00:30:18,433 --> 00:30:21,900
I go, I don't have a clue but
I'm assuming you're going to

680
00:30:21,966 --> 00:30:23,799
hand it to me any moment now.

681
00:30:23,866 --> 00:30:26,299
And he went ahead and he
handed me the burn bag.

682
00:30:26,366 --> 00:30:28,233
He's like, you know you're
supposed to lock it up

683
00:30:28,299 --> 00:30:28,900
every day.

684
00:30:28,966 --> 00:30:29,933
I'm like, no I didn't.

685
00:30:30,000 --> 00:30:31,900
Maybe I did but I forgot.

686
00:30:31,966 --> 00:30:34,166
Never locked up
the burn bag again. Why?

687
00:30:34,233 --> 00:30:37,500
Because there was a culture in
place that everybody locked it

688
00:30:37,566 --> 00:30:40,866
up and he had his guards do
rounds after everybody left and

689
00:30:40,933 --> 00:30:44,333
if there was a burn bag left
unattended and unlocked, he

690
00:30:44,400 --> 00:30:48,166
would have them bring it back
and know where it came from.

691
00:30:48,233 --> 00:30:50,599
Then he would call up and that
was the last time my burn bag

692
00:30:50,666 --> 00:30:51,566
was out.

693
00:30:51,633 --> 00:30:54,799
But that culture created
consequences that had me doing

694
00:30:54,866 --> 00:30:55,900
things right.

695
00:30:55,966 --> 00:30:58,699
So, anyway, that is left of boom
which stopped a whole bunch of

696
00:30:58,766 --> 00:30:59,666
other stuff.

697
00:30:59,733 --> 00:31:01,832
And here's the other
part, governance.

698
00:31:01,900 --> 00:31:04,133
Here is a big problem
with awareness training.

699
00:31:04,200 --> 00:31:05,833
And again, we're
still left of boom.

700
00:31:05,900 --> 00:31:08,466
The biggest problem with
awareness training is we're

701
00:31:08,533 --> 00:31:12,933
training people how to - well,
no, actually, I'm going to cover

702
00:31:13,000 --> 00:31:13,900
that later.

703
00:31:13,966 --> 00:31:17,599
But governance in this
perspective is defining process.

704
00:31:17,666 --> 00:31:20,633
In other words, what is the
process for doing something?

705
00:31:20,700 --> 00:31:23,433
What is the process
for distributing PII?

706
00:31:23,500 --> 00:31:26,533
What is the process for you
know, handling computers?

707
00:31:26,599 --> 00:31:29,166
What is the
process for, for example,

708
00:31:29,233 --> 00:31:30,366
decommissioning computers?

709
00:31:30,433 --> 00:31:32,500
What supply chain processes?

710
00:31:32,566 --> 00:31:35,566
There are a whole bunch of
processes and the problem is in

711
00:31:35,633 --> 00:31:38,566
the cybersecurity world,
we don't outline these

712
00:31:38,633 --> 00:31:39,633
things clearly.

713
00:31:39,700 --> 00:31:42,766
We basically just have these
things and it's like, it kind of

714
00:31:42,833 --> 00:31:45,299
should happen this
way or it does happen.

715
00:31:45,366 --> 00:31:47,500
You know, for example,
mergers and acquisitions.

716
00:31:47,566 --> 00:31:50,966
Luckily lately, people are
establishing clear sets of

717
00:31:51,033 --> 00:31:54,265
processes and how we review
potential companies we're

718
00:31:54,333 --> 00:31:57,933
looking at to join into the
corporate network and so on.

719
00:31:58,000 --> 00:32:00,966
But you know, frequently those
things don't happen and I'm

720
00:32:01,033 --> 00:32:03,132
talking the big things,
but stop and think.

721
00:32:03,200 --> 00:32:06,566
How many of the little user
functions you have are actually

722
00:32:06,633 --> 00:32:10,333
defined by governance
and defined well?

723
00:32:10,400 --> 00:32:12,233
>> DR. TRACY CELAYA BROWN: And
how many of those are actually

724
00:32:12,299 --> 00:32:15,299
written down and provided to
our users so that they can

725
00:32:15,366 --> 00:32:16,400
act appropriately?

726
00:32:16,466 --> 00:32:20,966
If they have an opportunity to
initiate a loss, do they know

727
00:32:21,033 --> 00:32:21,899
what to do?

728
00:32:21,966 --> 00:32:25,065
Do they know how to act
in order to mitigate risk?

729
00:32:25,133 --> 00:32:28,400
Are they prepared to detect
something that could be

730
00:32:28,466 --> 00:32:30,666
potentially malicious
or potentially risky?

731
00:32:30,733 --> 00:32:34,033
If they do detect it, are
they able to prevent it?

732
00:32:34,099 --> 00:32:35,133
Do they know what to do?

733
00:32:35,200 --> 00:32:37,066
Do they have
access to the resources?

734
00:32:37,133 --> 00:32:40,000
Do they know how to sound the
alarm, send out a communication,

735
00:32:40,066 --> 00:32:41,000
or make a phone call?

736
00:32:41,066 --> 00:32:44,633
Have we provided that - them
with the information that

737
00:32:44,700 --> 00:32:45,700
they need?

738
00:32:45,766 --> 00:32:49,500
But also, with the understanding
that our people are going to

739
00:32:49,566 --> 00:32:50,166
act willfully.

740
00:32:50,233 --> 00:32:52,166
Sometimes they
will act maliciously.

741
00:32:52,233 --> 00:32:54,633
Their actions
could be fraudulent.

742
00:32:54,700 --> 00:32:57,299
It could be an
accident at the same time.

743
00:32:57,366 --> 00:33:00,966
But the user is there in the
middle, right there in proximity

744
00:33:01,033 --> 00:33:02,433
to boom.

745
00:33:02,500 --> 00:33:04,166
>> IRA WINKLER: So, here's the
thing and this is where I was

746
00:33:04,233 --> 00:33:05,700
going with the last
set of governance.

747
00:33:05,766 --> 00:33:08,400
Again, governance goes
throughout and in the

748
00:33:08,466 --> 00:33:12,099
cybersecurity world, we do
not use governance like it

749
00:33:12,166 --> 00:33:13,133
should be.

750
00:33:13,200 --> 00:33:17,400
Governance should define every
step and entire process in

751
00:33:17,466 --> 00:33:18,233
the company.

752
00:33:18,299 --> 00:33:19,799
We don't do that
in cybersecurity.

753
00:33:19,866 --> 00:33:22,200
But here is the biggest problem
and especially this is where

754
00:33:22,266 --> 00:33:24,266
awareness training
tends to fail people.

755
00:33:24,333 --> 00:33:27,700
Awareness programs love to train
people to be on the lookout for

756
00:33:27,766 --> 00:33:28,933
wascally wabbit.

757
00:33:29,000 --> 00:33:30,400
They talk about
all of the hackers.

758
00:33:30,466 --> 00:33:33,132
They talk about how bad people
will social engineer you.

759
00:33:33,200 --> 00:33:36,033
They talk about how you
know, there are all of

760
00:33:36,099 --> 00:33:36,866
these incidents.

761
00:33:36,933 --> 00:33:38,500
Somebody will steal
your computer.

762
00:33:38,566 --> 00:33:40,866
Somebody will call you
up and do bad things.

763
00:33:40,933 --> 00:33:44,266
The problem is that they're
training users to just be

764
00:33:44,333 --> 00:33:45,500
Elmer Fudd's.

765
00:33:45,566 --> 00:33:49,299
They are not training users
how to do their job right.

766
00:33:49,366 --> 00:33:53,500
There is - it sounds like a fine
line but I want my users to know

767
00:33:53,566 --> 00:33:57,599
how to do their jobs right, what
is the process to do right.

768
00:33:57,666 --> 00:34:00,966
Just for example, how many of
you in this audience and if you

769
00:34:01,033 --> 00:34:04,500
want to just be funny, in the
other audiences, how many of you

770
00:34:04,566 --> 00:34:08,065
have to submit travel
reimbursement forms out of this?

771
00:34:08,132 --> 00:34:10,000
You know, just about everybody.

772
00:34:10,065 --> 00:34:12,466
You know, when you submit your
travel reimbursement form, let

773
00:34:12,533 --> 00:34:15,065
me ask you; did they say oh
well, here is a mistake you

774
00:34:15,132 --> 00:34:15,732
might make.

775
00:34:15,800 --> 00:34:17,066
Here is a mistake
you might make.

776
00:34:17,132 --> 00:34:19,832
Or did they say you need
receipts for your hotel, you

777
00:34:19,900 --> 00:34:21,400
need receipts for
your restaurant.

778
00:34:21,466 --> 00:34:22,165
You can't have this.

779
00:34:22,233 --> 00:34:23,233
Blah, blah, blah.

780
00:34:23,300 --> 00:34:26,733
They gave you very specific
instructions on how to fill out

781
00:34:26,800 --> 00:34:30,300
travel vouchers right and what
happens if you do not fill that

782
00:34:30,366 --> 00:34:31,300
out right?

783
00:34:31,366 --> 00:34:35,900
You do not get your $20,000
hotel bill reimbursed in this

784
00:34:35,966 --> 00:34:39,400
area, right, because they will
not do it if you don't have the

785
00:34:39,466 --> 00:34:40,766
proper receipts.

786
00:34:40,833 --> 00:34:42,166
That is governance.

787
00:34:42,233 --> 00:34:44,199
Do we do this in cybersecurity?

788
00:34:44,266 --> 00:34:46,699
Or are we training people
to be on the lookout for those

789
00:34:46,766 --> 00:34:47,733
bad people?

790
00:34:47,800 --> 00:34:51,033
As opposed to telling people
here is how you do your job

791
00:34:51,099 --> 00:34:54,966
properly and how you do your job
properly should take care of the

792
00:34:55,033 --> 00:34:56,598
bad things as well.

793
00:34:56,666 --> 00:34:57,966
Will it take care of everything?

794
00:34:58,033 --> 00:34:59,098
No.

795
00:34:59,166 --> 00:35:02,633
But it is going to take care of
99% of the problems a user might

796
00:35:02,699 --> 00:35:06,066
face because at the end of
the day, awareness training,

797
00:35:06,133 --> 00:35:08,799
training people to be on the
lookout for the wascally wabbit,

798
00:35:08,866 --> 00:35:14,133
you're putting your end user in
combat with a sociopath, with a

799
00:35:14,199 --> 00:35:16,099
trained criminal.

800
00:35:16,166 --> 00:35:17,199
Is that a fair fight?

801
00:35:17,266 --> 00:35:18,566
That's not a fair fight.

802
00:35:18,633 --> 00:35:20,966
It's like I saw a funny video
and now that I saw that funny

803
00:35:21,033 --> 00:35:24,066
video, I can take on
the master criminals.

804
00:35:24,133 --> 00:35:25,399
No way.

805
00:35:25,466 --> 00:35:28,098
You want to make sure they know
how to do their job from start

806
00:35:28,166 --> 00:35:30,199
to finish and not
be Elmer Fudd's.

807
00:35:32,300 --> 00:35:33,633
Okay, so now right of boom.

808
00:35:33,699 --> 00:35:36,566
In this case, the loss
has been initiated.

809
00:35:36,633 --> 00:35:39,533
In other words, let's say a user
clicked on a phishing message.

810
00:35:39,599 --> 00:35:42,699
Let's say the user might go
click on a website to give away

811
00:35:42,766 --> 00:35:46,099
their credentials just as an
example and phishing is an easy

812
00:35:46,166 --> 00:35:47,966
one because everybody
is familiar with that.

813
00:35:48,033 --> 00:35:49,333
It's not the only example.

814
00:35:49,400 --> 00:35:51,466
But now the loss
has been initiated.

815
00:35:51,533 --> 00:35:54,232
The user clicked on the message
and they are attempting to go to

816
00:35:54,300 --> 00:35:55,266
a website.

817
00:35:55,333 --> 00:35:58,199
Does your architecture tell
you this is a malicious link?

818
00:35:58,266 --> 00:35:59,599
We're not sending you there.

819
00:35:59,666 --> 00:36:00,599
You can do that.

820
00:36:00,666 --> 00:36:04,166
The architecture is setup
proactively in many cases if you

821
00:36:04,233 --> 00:36:06,766
have the right antivirus
software or whatever the case -

822
00:36:06,833 --> 00:36:09,166
well, not just antivirus
software but web content

823
00:36:09,233 --> 00:36:10,900
filtering and so on.

824
00:36:10,966 --> 00:36:12,400
Does the environment expect it?

825
00:36:12,466 --> 00:36:13,533
Look.

826
00:36:13,599 --> 00:36:16,000
You know, much like that guy who
said, you know, laughing at his

827
00:36:16,066 --> 00:36:19,098
people that he needs stickers
that say don't click on "stuff"

828
00:36:19,166 --> 00:36:21,133
- I'm trying to make
sure I say it right.

829
00:36:21,199 --> 00:36:23,333
Don't click on stuff.

830
00:36:23,400 --> 00:36:26,800
You know, that is not
exactly the environment.

831
00:36:26,866 --> 00:36:29,433
The guy knows people are
going to click on stuff.

832
00:36:29,500 --> 00:36:31,800
Does he setup the environment
so that people have least

833
00:36:31,866 --> 00:36:34,900
privileges so they can't be
infected with - infect the

834
00:36:34,966 --> 00:36:37,266
entire network with ransomware?

835
00:36:37,333 --> 00:36:40,300
Are there the appropriate
protections in place and is

836
00:36:40,366 --> 00:36:43,099
there an analysis of
user-initiated loss?

837
00:36:43,166 --> 00:36:47,766
In other words, what are the
possible actions a user can take

838
00:36:47,833 --> 00:36:51,199
that can initiate a chain of
events and let's figure out

839
00:36:51,266 --> 00:36:53,400
proactively how
to mitigate that.

840
00:36:53,466 --> 00:36:55,199
Again, there are
access controls.

841
00:36:55,266 --> 00:36:56,300
There are permissions.

842
00:36:56,366 --> 00:36:58,599
There are a whole bunch of -
you know, there are

843
00:36:58,666 --> 00:36:59,400
countless things.

844
00:36:59,466 --> 00:37:02,500
Like we just had,
I don't know, 2,300 vendors.

845
00:37:02,566 --> 00:37:03,598
Sorry, I forgot.

846
00:37:03,666 --> 00:37:08,433
A few vendors did not show up so
we had 2,286 vendors this year

847
00:37:08,500 --> 00:37:09,733
or something like that.

848
00:37:09,800 --> 00:37:12,066
But they are people who can
help you deal with this.

849
00:37:12,133 --> 00:37:16,000
But again, you've got to look
both at left of boom, at boom,

850
00:37:16,066 --> 00:37:18,265
and right of boom and figure
out where that all can

851
00:37:18,333 --> 00:37:19,933
be implemented.

852
00:37:20,000 --> 00:37:23,300
Now, most important, after there
is an incident, figure out

853
00:37:23,366 --> 00:37:24,000
what happened.

854
00:37:24,066 --> 00:37:25,000
What went right?

855
00:37:25,066 --> 00:37:26,399
What went wrong?

856
00:37:26,466 --> 00:37:29,199
You know, all too frequently
people just look at oh, we need

857
00:37:29,266 --> 00:37:30,599
better awareness training.

858
00:37:30,666 --> 00:37:33,066
I'm like, that's the last
- that's the least of

859
00:37:33,133 --> 00:37:34,098
your thoughts.

860
00:37:34,166 --> 00:37:36,633
You need to figure out how did
that attack hit that user?

861
00:37:36,699 --> 00:37:39,699
Why did the user make a mistake?

862
00:37:39,766 --> 00:37:43,533
Like, you know, again, there was
like okay, so if you go back a

863
00:37:43,599 --> 00:37:47,633
few years like, I think it
was actually 2013, the Syrian

864
00:37:47,699 --> 00:37:49,666
Electronic Army really hates me.

865
00:37:49,733 --> 00:37:52,333
I don't know if you remember
them but they did a whole series

866
00:37:52,400 --> 00:37:57,099
of hacks against major websites
and they really came after me.

867
00:37:57,166 --> 00:37:58,566
And why?

868
00:37:58,633 --> 00:38:02,000
Because I disclosed their names
and did a whole bunch of other

869
00:38:02,066 --> 00:38:02,933
stuff at RSA.

870
00:38:03,000 --> 00:38:05,633
They hacked the RSA Conference
website because of me.

871
00:38:05,699 --> 00:38:06,866
I was kind of honored.

872
00:38:06,933 --> 00:38:10,966
So, what happened was - true
story - but what happened was

873
00:38:11,033 --> 00:38:13,466
you go back and people
would be hit by these Syrian

874
00:38:13,533 --> 00:38:14,566
Electronic Army.

875
00:38:14,633 --> 00:38:16,698
They would call in all of the
big incident response companies.

876
00:38:16,766 --> 00:38:20,599
The companies would come in and
take away any malware that these

877
00:38:20,666 --> 00:38:23,933
people put in place and then
they would come back and then

878
00:38:24,000 --> 00:38:26,900
what would happen is a week
later, these bad people would be

879
00:38:26,966 --> 00:38:28,500
back in the networks.

880
00:38:28,566 --> 00:38:31,433
And then, so they call me and
they're like, Ira, figure out

881
00:38:31,500 --> 00:38:32,633
why they're back in.

882
00:38:32,699 --> 00:38:33,400
So, I came in.

883
00:38:33,466 --> 00:38:36,533
I said okay, why -
this is a true story.

884
00:38:36,599 --> 00:38:39,500
I was talking to the CFO of a
multi-billion-dollar company.

885
00:38:39,566 --> 00:38:41,933
I go, you're a
smart guy, no offense.

886
00:38:42,000 --> 00:38:44,666
I go, just out of curiosity, why
did you click on this message?

887
00:38:44,733 --> 00:38:45,900
It is clearly a fake.

888
00:38:45,966 --> 00:38:50,933
He's like, well, he's like,
I woke up at 6:00 AM in the

889
00:38:51,000 --> 00:38:53,800
morning and the guy was British,
you know, in New York though but

890
00:38:53,866 --> 00:38:56,500
the guy was British and he's
like, I got a message from our

891
00:38:56,566 --> 00:39:00,399
UK sales rep and the UK sales
rep said we were featured in the

892
00:39:00,466 --> 00:39:04,598
BBC and click on this
link to see the story.

893
00:39:04,666 --> 00:39:06,500
And he clicked on the
link to see the story.

894
00:39:06,566 --> 00:39:10,198
Of course, you know, it ended up
compromising his credentials.

895
00:39:10,266 --> 00:39:11,300
I'm like, okay.

896
00:39:11,366 --> 00:39:14,566
Did anybody ever tell you how to
check for a malicious link on

897
00:39:14,633 --> 00:39:15,332
your iPhone?

898
00:39:15,400 --> 00:39:16,233
He's like, no.

899
00:39:16,300 --> 00:39:17,800
I'm like, really?

900
00:39:17,866 --> 00:39:19,466
And then I'm like, which videos?

901
00:39:19,533 --> 00:39:22,566
Go back and look at your
awareness videos and see how to

902
00:39:22,633 --> 00:39:23,633
check for malicious links.

903
00:39:23,699 --> 00:39:24,766
It's not there.

904
00:39:24,833 --> 00:39:27,333
But anyway, so we went back and
then we started implementing our

905
00:39:27,400 --> 00:39:30,066
emergency awareness programs
just for that attack.

906
00:39:30,133 --> 00:39:31,866
Now, that is just one case.

907
00:39:31,933 --> 00:39:35,133
But again, think about all of
the other times users were put

908
00:39:35,199 --> 00:39:37,400
in the position and they
were neve given this.

909
00:39:37,466 --> 00:39:38,466
So, go back.

910
00:39:38,533 --> 00:39:41,433
Figure out why they did stuff
because your users aren't the

911
00:39:41,500 --> 00:39:42,433
stupid ones.

912
00:39:42,500 --> 00:39:45,599
It's the environment that
enabled them to appear stupid.

913
00:39:45,666 --> 00:39:47,000
>> DR. TRACY CELAYA BROWN:
And it may sound difficult.

914
00:39:47,066 --> 00:39:49,533
It may seem pretty
daunting as well but we see it

915
00:39:49,599 --> 00:39:50,800
in other industries.

916
00:39:50,866 --> 00:39:53,766
We see it in other areas
of our organization.

917
00:39:53,833 --> 00:39:57,233
We see it even in processes that
we do in IT or in security.

918
00:39:57,300 --> 00:40:00,300
So, it is something that we
can implement and as we said

919
00:40:00,366 --> 00:40:03,833
earlier, sometimes we don't care
if the person knows why they are

920
00:40:03,900 --> 00:40:06,800
doing something, just as
long as they do it correctly.

921
00:40:06,866 --> 00:40:10,500
So, it is up to us as the
professionals in security to

922
00:40:10,566 --> 00:40:13,098
work with the business to make
sure that they implement that in

923
00:40:13,166 --> 00:40:16,933
those processes, that they have
security in mind and as a result

924
00:40:17,000 --> 00:40:19,866
of having security in mind when
they create these processes,

925
00:40:19,933 --> 00:40:25,866
that we create systemically a
security culture that is robust.

926
00:40:25,933 --> 00:40:27,199
So, let's consider this.

927
00:40:27,266 --> 00:40:30,199
We have probably beat this one
to death and you have seen it

928
00:40:30,266 --> 00:40:33,833
quite a few times that 90% of
the incidents are a result from

929
00:40:33,900 --> 00:40:36,066
the user being the
single point of entry.

930
00:40:36,133 --> 00:40:39,665
They are the start of a
user-initiated loss, right?

931
00:40:39,733 --> 00:40:44,000
So, we posit this particular
strategy to you with right,

932
00:40:44,066 --> 00:40:48,799
left, and boom to use for your
own organizations but it should

933
00:40:48,866 --> 00:40:50,400
be worth it, right?

934
00:40:50,466 --> 00:40:52,966
So, take a look and see do you
have something in place to

935
00:40:53,033 --> 00:40:56,299
analyze what processes are out
there within your organization?

936
00:40:56,366 --> 00:40:59,400
Do you have something in place
where you can create champions

937
00:40:59,466 --> 00:41:00,433
of security?

938
00:41:00,500 --> 00:41:02,733
Or do you have partnerships
with other people within the

939
00:41:02,800 --> 00:41:06,500
organization so that you can
help them and let them leverage

940
00:41:06,566 --> 00:41:10,098
the expertise that you have
available to them so that we can

941
00:41:10,166 --> 00:41:13,400
create this culture of
security within our companies?

942
00:41:13,466 --> 00:41:15,266
>> IRA WINKLER: So, anyway,
let's use a quick example

943
00:41:15,333 --> 00:41:17,333
because again, I am talking
around, throwing different

944
00:41:17,400 --> 00:41:18,666
examples all over the place.

945
00:41:18,733 --> 00:41:21,633
But let's look at, you know,
we're in the United States, and

946
00:41:21,699 --> 00:41:23,933
we are in the United
States at the moment.

947
00:41:24,000 --> 00:41:27,466
You know, we're looking at W2
fraud season because tax season,

948
00:41:27,533 --> 00:41:31,433
for those of you from outside of
the country, W2s are tax forms

949
00:41:31,500 --> 00:41:34,900
that everybody has to get at the
beginning of the year to prepare

950
00:41:34,966 --> 00:41:37,866
to mail in their processed
tax returns and so on.

951
00:41:37,933 --> 00:41:41,633
So, what happens is the typical
attack is that a bad guy goes

952
00:41:41,699 --> 00:41:46,000
ahead and sends a phishing
message into human resources of

953
00:41:46,066 --> 00:41:48,399
some way and says I'm the CEO.

954
00:41:48,466 --> 00:41:52,000
We just hired a new accounting
firm or whatever it is and we

955
00:41:52,066 --> 00:41:55,799
need you to send out all of
the W2 information to our new

956
00:41:55,866 --> 00:41:58,266
accounting firm and it has to be
done immediately because we're

957
00:41:58,333 --> 00:41:59,133
running late.

958
00:41:59,199 --> 00:42:01,333
Our users are mad and all
of that sort of stuff.

959
00:42:01,400 --> 00:42:03,966
So, then you have this low-level
person sitting there thinking,

960
00:42:04,033 --> 00:42:07,665
is this the wascally wabbit or
is this the CEO or whatever?

961
00:42:07,733 --> 00:42:10,233
So, here is how the process
should work the way we're

962
00:42:10,300 --> 00:42:12,500
describing applying a
boom type of strategy.

963
00:42:12,566 --> 00:42:15,433
First, what should happen
is obviously you have your

964
00:42:15,500 --> 00:42:19,533
anti-spam filters, anti-phishing
filters and so on and that

965
00:42:19,599 --> 00:42:20,533
should filter out attacks.

966
00:42:20,599 --> 00:42:24,000
Likely, you can put the messages
flagged as external and a

967
00:42:24,066 --> 00:42:25,933
variety of other ways to do it.

968
00:42:26,000 --> 00:42:28,766
So, then the message should
never reach the inbox of the

969
00:42:28,833 --> 00:42:32,000
potential, I'll call it the user
in this case or the victim.

970
00:42:32,066 --> 00:42:35,366
And then what happens is when it
gets to the victim, the victim

971
00:42:35,433 --> 00:42:36,766
should think, okay.

972
00:42:36,833 --> 00:42:37,833
Wait a second.

973
00:42:37,900 --> 00:42:40,933
They shouldn't be thinking, I
had awareness training and it

974
00:42:41,000 --> 00:42:43,766
was funny and I learned that
that could be the wascally

975
00:42:43,833 --> 00:42:46,000
wabbit, not the CEO.

976
00:42:46,066 --> 00:42:47,533
That shouldn't enter their mind.

977
00:42:47,599 --> 00:42:49,433
They should say
hey, wait a second.

978
00:42:49,500 --> 00:42:51,933
This is a request for PII.

979
00:42:52,000 --> 00:42:56,833
A request for PII has to be sent
through the head of HR who then

980
00:42:56,900 --> 00:42:59,633
has to have the general
counsel's approval to send out

981
00:42:59,699 --> 00:43:00,833
the information.

982
00:43:00,900 --> 00:43:02,333
Yes, this is the CEO.

983
00:43:02,400 --> 00:43:06,566
The CEO doesn't even know who I
am anyway but either way, my job

984
00:43:06,633 --> 00:43:10,066
is to process requests for PII
by sending it to the head of HR.

985
00:43:10,133 --> 00:43:13,000
So, that is what should
theoretically happen.

986
00:43:13,066 --> 00:43:15,765
They should have the training
on how to do that and so on.

987
00:43:15,833 --> 00:43:20,599
And then let's assume that for
whatever reason, the user fails

988
00:43:20,666 --> 00:43:24,333
to do the proper thing and
escalate or even let's assume

989
00:43:24,400 --> 00:43:27,599
that the head of HR
falls for the trick.

990
00:43:27,666 --> 00:43:30,233
Then what should happen is they
send it out but then it should

991
00:43:30,300 --> 00:43:33,266
be blocked by data leak
prevention software, DLP, and a

992
00:43:33,333 --> 00:43:35,833
whole bunch of other filtering
software that says why are you

993
00:43:35,900 --> 00:43:38,766
sending this file outside of
the company or whatever else?

994
00:43:38,833 --> 00:43:41,433
But that is how the
process should work.

995
00:43:41,500 --> 00:43:44,500
It doesn't just train the
end user to say is this the

996
00:43:44,566 --> 00:43:46,098
wascally wabbit.

997
00:43:46,166 --> 00:43:49,866
There is a whole system in place
that should be trying to stop it

998
00:43:49,933 --> 00:43:54,599
from getting there, trying to
get a process to help the user

999
00:43:54,666 --> 00:43:57,533
make the right decision, and
then the assumption that

1000
00:43:57,599 --> 00:44:01,766
inevitably the user will
fail and proactively protect

1001
00:44:01,833 --> 00:44:04,199
against that.

1002
00:44:04,266 --> 00:44:06,266
So, anyway, also
consider the overlap.

1003
00:44:06,333 --> 00:44:09,599
I just gave the example of W2
handling but couldn't that work

1004
00:44:09,666 --> 00:44:12,266
for any type of request for PII?

1005
00:44:12,333 --> 00:44:13,599
That could work there.

1006
00:44:13,666 --> 00:44:15,366
You know,
anti-phishing technology,

1007
00:44:15,433 --> 00:44:16,733
anti-spam technology.

1008
00:44:16,800 --> 00:44:20,433
Again, that should filter out
any type of attacks in theory.

1009
00:44:20,500 --> 00:44:22,300
Data leak prevention.

1010
00:44:22,366 --> 00:44:25,500
Again, that should filter out
any sort of data accidentally

1011
00:44:25,566 --> 00:44:28,066
being sent out of the
company either maliciously,

1012
00:44:28,133 --> 00:44:31,098
intentionally, via
phishing or whatever else.

1013
00:44:31,166 --> 00:44:33,900
There is a whole bunch of
overlap that if you just look at

1014
00:44:33,966 --> 00:44:37,400
one process, you're going to
stop a litany of attacks.

1015
00:44:37,466 --> 00:44:38,900
Wow, I barely ever
use that word.

1016
00:44:38,966 --> 00:44:39,966
Litany.

1017
00:44:40,033 --> 00:44:41,866
Anyway, it stops a
litany of attacks.

1018
00:44:41,933 --> 00:44:44,900
So, anyway, the whole
thing can stop a lot.

1019
00:44:44,966 --> 00:44:46,232
Now -

1020
00:44:46,300 --> 00:44:47,533
>> DR. TRACY CELAYA BROWN: I
think we beat that one to death.

1021
00:44:47,599 --> 00:44:49,166
>> IRA WINKLER:
Okay. Next slide.

1022
00:44:49,233 --> 00:44:50,233
>> DR. TRACY CELAYA
BROWN: Go ahead.

1023
00:44:50,300 --> 00:44:51,500
>> IRA WINKLER: Okay.
So, here is the thing though.

1024
00:44:51,566 --> 00:44:53,466
Awareness is still mandatory.

1025
00:44:53,533 --> 00:44:57,165
Yes, I beat up on awareness to a
certain extent but the reality

1026
00:44:57,233 --> 00:45:02,033
is awareness is still one of the
tactics in the overall strategy

1027
00:45:02,099 --> 00:45:06,133
and let me just go on for this
because - actually, one quick

1028
00:45:06,199 --> 00:45:07,733
thing back on this slide.

1029
00:45:07,800 --> 00:45:09,166
Here is the thing
with awareness.

1030
00:45:09,233 --> 00:45:12,733
The awareness should not be
focusing on be on the lookout

1031
00:45:12,800 --> 00:45:14,300
for the wascally wabbit.

1032
00:45:14,366 --> 00:45:19,900
Awareness should be focused on
how do you do your job properly?

1033
00:45:19,966 --> 00:45:21,165
What is the process?

1034
00:45:21,233 --> 00:45:23,500
How do you implement
the process properly?

1035
00:45:23,566 --> 00:45:25,866
That is what awareness
should focus on.

1036
00:45:25,933 --> 00:45:28,800
But either way, awareness
is still mandatory because

1037
00:45:28,866 --> 00:45:30,800
awareness is a tactic.

1038
00:45:30,866 --> 00:45:33,300
Too many people in the awareness
field like to think it's a whole

1039
00:45:33,366 --> 00:45:37,366
strategy to be the human
firewall and the last line

1040
00:45:37,433 --> 00:45:38,233
of defense.

1041
00:45:38,300 --> 00:45:39,599
That is not what it's there for.

1042
00:45:39,666 --> 00:45:40,800
It's one tactic.

1043
00:45:40,866 --> 00:45:42,466
It's sort of like having tanks.

1044
00:45:42,533 --> 00:45:46,400
You need armor to win a war
but you can't win the war with

1045
00:45:46,466 --> 00:45:47,633
armor alone.

1046
00:45:47,699 --> 00:45:50,633
You could set a whole bunch of
people and take and blow up a

1047
00:45:50,699 --> 00:45:53,000
city with a whole bunch of
tanks, but you're not going to

1048
00:45:53,066 --> 00:45:56,899
hold the city without infantry,
without air support and a whole

1049
00:45:56,966 --> 00:45:58,165
bunch of other resources.

1050
00:45:58,233 --> 00:46:00,533
Same thing with
awareness training.

1051
00:46:00,599 --> 00:46:05,300
Your user, quote, unquote,
"user" problem is not just being

1052
00:46:05,366 --> 00:46:07,266
- is not an awareness strategy.

1053
00:46:07,333 --> 00:46:10,166
It is awareness as a tactic
among governance, among

1054
00:46:10,233 --> 00:46:13,400
technology, among
process and awareness.

1055
00:46:13,466 --> 00:46:15,000
So, that is the key point.

1056
00:46:15,066 --> 00:46:16,665
Awareness is a tactic.

1057
00:46:16,733 --> 00:46:19,766
Most important takeaway,
you're not trying to create

1058
00:46:19,833 --> 00:46:21,400
healthier canaries.

1059
00:46:21,466 --> 00:46:25,633
You need to look at creating a
system that is not worried about

1060
00:46:25,699 --> 00:46:29,866
lack of user awareness but a
system that is focused on user

1061
00:46:29,933 --> 00:46:34,000
initiated loss and stopping user
initiated loss both from being

1062
00:46:34,066 --> 00:46:37,698
initiated and then from
mitigating it after initiation

1063
00:46:37,766 --> 00:46:41,099
because there is no such
thing as perfect security.

1064
00:46:41,166 --> 00:46:44,300
Much like I was laughing about
that admin who says he needs a

1065
00:46:44,366 --> 00:46:48,666
whole bunch of stickers because
his users keep clicking on

1066
00:46:48,733 --> 00:46:51,066
"stuff," he kept giving his
users stuff to click on.

1067
00:46:51,133 --> 00:46:52,732
That is his fault.

1068
00:46:52,800 --> 00:46:55,566
You need to understand,
likewise, it is - you are

1069
00:46:55,633 --> 00:46:59,165
creating a system to stop
this from start to finish.

1070
00:46:59,233 --> 00:47:02,099
Sorry.
Here is your mandatory slide.

1071
00:47:02,166 --> 00:47:03,800
>> DR. TRACY CELAYA BROWN: In
the end, we actually believe

1072
00:47:03,866 --> 00:47:05,933
that you guys are magic.

1073
00:47:06,000 --> 00:47:07,133
You're fantastic.

1074
00:47:07,199 --> 00:47:11,566
We really believe you are magic.

1075
00:47:11,633 --> 00:47:14,633
Nothing can stand in your way.

1076
00:47:14,699 --> 00:47:17,300
And this right up here will help
you apply that concept when you

1077
00:47:17,366 --> 00:47:18,800
get back to work, right?

1078
00:47:18,866 --> 00:47:21,599
So - thanks.

1079
00:47:21,666 --> 00:47:24,666
Immediately when you get back,
you can analyze your governance

1080
00:47:24,733 --> 00:47:28,733
and see what you currently have
in place in order to put this

1081
00:47:28,800 --> 00:47:30,800
type of a model
into effect, right?

1082
00:47:30,866 --> 00:47:34,699
Do you focus on the proximity of
the user to boom, the proximity

1083
00:47:34,766 --> 00:47:35,300
of the user?

1084
00:47:35,366 --> 00:47:36,633
Is it really the user's fault?

1085
00:47:36,699 --> 00:47:39,566
If it is, what are we doing
preemptively and what are we

1086
00:47:39,633 --> 00:47:42,799
doing in response and how are we
implementing a feedback loop?

1087
00:47:42,866 --> 00:47:46,933
Is there an end to end approach
for that user-initiated loss and

1088
00:47:47,000 --> 00:47:49,733
are you considering what those
gaps are in order to fill them?

1089
00:47:49,800 --> 00:47:52,766
And then within the next three
months, we hope that you choose

1090
00:47:52,833 --> 00:47:57,300
at least a couple of common user
initiated losses within your

1091
00:47:57,366 --> 00:48:00,833
organization and then use this
model or something in order to

1092
00:48:00,900 --> 00:48:04,066
help your business partners
implement the right type of

1093
00:48:04,133 --> 00:48:07,866
strategy so that your users can
do the right thing when they

1094
00:48:07,933 --> 00:48:10,933
need to do it.

1095
00:48:11,000 --> 00:48:12,433
>> IRA WINKLER: So,
anyway, cheap plug.

1096
00:48:12,500 --> 00:48:13,633
I'm doing a book signing.

1097
00:48:13,699 --> 00:48:15,766
I wasn't supposed to but the
bookstore is right there.

1098
00:48:15,833 --> 00:48:17,133
I'll sign my book
if you go there.

1099
00:48:17,199 --> 00:48:21,233
Anyway, Tracy also has a book
and then Tracy and I both have a

1100
00:48:21,300 --> 00:48:21,966
new book.

1101
00:48:22,033 --> 00:48:23,066
We need votes.

1102
00:48:23,133 --> 00:48:24,598
Which do people
like as the cover?

1103
00:48:24,666 --> 00:48:27,833
The one on the - sorry - the one
on the left or the one on

1104
00:48:27,900 --> 00:48:28,566
the right?

1105
00:48:28,633 --> 00:48:29,665
Sorry. We need a quick poll.

1106
00:48:29,733 --> 00:48:30,866
This is actually real.

1107
00:48:30,933 --> 00:48:32,699
How many people like
the one on the left?

1108
00:48:34,833 --> 00:48:35,866
Okay.

1109
00:48:35,933 --> 00:48:38,966
How many people like the one on
the right with the stop sign?

1110
00:48:39,033 --> 00:48:41,299
Wow. We have a winner.

1111
00:48:41,366 --> 00:48:43,766
No offense to you
people who chose wrong.

1112
00:48:43,833 --> 00:48:45,433
It's not like
Indiana Jones though.

1113
00:48:45,500 --> 00:48:49,133
But anyway, otherwise,
so you can email us.

1114
00:48:49,199 --> 00:48:52,933
We have one minute and thirty
seconds exactly for questions

1115
00:48:53,000 --> 00:48:56,000
which I don't think they'll let
us do because they are going to

1116
00:48:56,066 --> 00:48:58,033
kick us out and kill
me if we go long.

1117
00:48:58,099 --> 00:48:59,300
>> DR. TRACY CELAYA
BROWN: Or I will.

1118
00:48:59,366 --> 00:49:00,566
>> IRA WINKLER: Anyway,
but we'll take questions.

1119
00:49:00,633 --> 00:49:02,066
We're not leaving.

1120
00:49:02,133 --> 00:49:03,899
Nobody is behind us anyway since
they gave us the honor of the

1121
00:49:03,966 --> 00:49:06,766
very last session at RSA.

1122
00:49:06,833 --> 00:49:08,099
Thank you so very much.

1123
00:49:08,166 --> 00:49:09,766
Fantastic. Thank you.

1124
00:49:09,833 --> 00:49:10,800
>> DR. TRACY CELAYA
BROWN: Thanks.

1125
00:49:14,166 --> 00:49:15,466
>> IRA WINKLER: So, let us
know if you have questions.

1126
00:49:15,533 --> 00:49:18,066
In the meantime, we hope that
you enjoyed RSA and then we hope

1127
00:49:18,133 --> 00:49:21,165
that you got something out that
was valuable of the session.

1128
00:49:21,233 --> 00:49:22,000
Thanks.

1129
00:49:22,066 --> 00:49:24,332
>> DR. TRACY CELAYA
BROWN: Thanks.

1130
00:49:24,400 --> 00:49:25,733
>> IRA WINKLER:
Oh, you can ask. I don't care.

1131
00:49:25,800 --> 00:49:26,966
>> DR. TRACY CELAYA
BROWN: Either one.

1132
00:49:27,033 --> 00:49:28,232
>> AUDIENCE: Not so much a
question, just a request that

1133
00:49:28,300 --> 00:49:30,533
next year you deliver at least
half of the presentation

1134
00:49:30,599 --> 00:49:31,599
in concert.

1135
00:49:33,800 --> 00:49:35,533
>> DR. TRACY CELAYA BROWN:
Hm, thought provoking.

1136
00:49:35,599 --> 00:49:37,033
>> IRA WINKLER: She
will actually do that. I mean.

1137
00:49:37,099 --> 00:49:38,133
>> AUDIENCE: I hope so.

1138
00:49:38,199 --> 00:49:39,933
>> IRA WINKLER: I've never heard
her do Olivia Newton-John before

1139
00:49:40,000 --> 00:49:41,166
but it worked.

1140
00:49:41,233 --> 00:49:43,333
Anyway. Thank you.

