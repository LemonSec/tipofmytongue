1
00:00:06,266 --> 00:00:08,300
>> SPEAKER: To lead
today's discussion, please

2
00:00:08,366 --> 00:00:11,666
welcome moderator
Rajeev Chand.

3
00:00:13,400 --> 00:00:14,666
>> RAJEEV CHAND:
Hey, everybody.

4
00:00:14,733 --> 00:00:18,199
Good morning and welcome
to the second keynote here

5
00:00:18,266 --> 00:00:20,732
on the south stage at RSA.

6
00:00:20,800 --> 00:00:23,800
It is my honor to be the
moderator for this session.

7
00:00:23,866 --> 00:00:25,766
The topic that we are
going to cover today is

8
00:00:25,833 --> 00:00:29,232
genomics, which one could
clearly argue there is no

9
00:00:29,300 --> 00:00:32,700
more personal data
than your genome.

10
00:00:32,766 --> 00:00:37,533
We are really privileged
to have today four voices,

11
00:00:37,600 --> 00:00:40,366
each from very different
perspectives, to lead this

12
00:00:40,433 --> 00:00:43,700
dialogue on what is the
size of this genomic

13
00:00:43,766 --> 00:00:47,733
opportunity, what are the
privacy considerations,

14
00:00:47,799 --> 00:00:50,366
and what happens when your
or my genome shows up on

15
00:00:50,433 --> 00:00:53,299
the dark web, and so the
privacy, security, and

16
00:00:53,366 --> 00:00:54,866
opportunity sort
of considerations.

17
00:00:54,933 --> 00:00:57,700
We have the voice of the
physician immediately to

18
00:00:57,766 --> 00:01:00,565
my left, Dr.
Patrick Courneya.

19
00:01:00,633 --> 00:01:04,133
We have the voice of the
genomics expert, Kathy

20
00:01:04,200 --> 00:01:07,066
Hibbs, Chief Legal and
Regulatory Officer 23andMe.

21
00:01:07,133 --> 00:01:09,732
And Dr. Courneya, I forgot
to introduce you as Chief

22
00:01:09,799 --> 00:01:12,400
Medical Officer at
Kaiser Permanente.

23
00:01:12,466 --> 00:01:15,065
Immediately to Kathy's
left is the voice of the

24
00:01:15,133 --> 00:01:17,866
patient, the voice of the
consumer, if you would,

25
00:01:17,933 --> 00:01:21,000
Sharon Terry, President
and CEO of the Genetic

26
00:01:21,066 --> 00:01:24,866
Alliance, and immediately
to her left is Mike Wilson

27
00:01:24,933 --> 00:01:26,966
who serves as Chief
Security Officer at Molina

28
00:01:27,033 --> 00:01:29,700
and was Chief Information
Security Officer of McKesson.

29
00:01:29,766 --> 00:01:32,066
Everybody please join me
in welcoming Pat, Kathy,

30
00:01:32,133 --> 00:01:34,098
Sharon, and Mike to RSA.

31
00:01:37,566 --> 00:01:41,766
Before we begin, how many
folks in the audience have

32
00:01:41,833 --> 00:01:43,966
had their genome tested?

33
00:01:46,500 --> 00:01:49,666
Okay, so 20-30%, 20-30%.

34
00:01:49,733 --> 00:01:51,433
Pat, I'm going to
turn to you first.

35
00:01:51,500 --> 00:01:52,366
>> DR. PATRICK
COURNEYA: Sure.

36
00:01:52,433 --> 00:01:55,933
>> RAJEEV CHAND: What is
the size of the impact

37
00:01:56,000 --> 00:01:58,866
that genomics will have
on health outcomes and in

38
00:01:58,933 --> 00:01:59,900
what timeframe?

39
00:01:59,966 --> 00:02:01,433
>> DR. PATRICK COURNEYA:
That's a great question.

40
00:02:01,500 --> 00:02:04,000
In fact, one of the things
that would probably be

41
00:02:04,066 --> 00:02:07,799
wise to do is to have a
common understanding or

42
00:02:07,866 --> 00:02:10,466
level-set on what we mean
by precision medicine and

43
00:02:10,532 --> 00:02:14,232
genomics and how we think
of that as a really

44
00:02:14,300 --> 00:02:16,066
important tool.

45
00:02:16,133 --> 00:02:18,199
When you think about it,
we've been on a march

46
00:02:18,266 --> 00:02:21,566
towards more and more
precise medicine for a

47
00:02:21,633 --> 00:02:22,900
long, long time.

48
00:02:22,966 --> 00:02:27,466
And in this case, what we
think of is genetics as

49
00:02:27,533 --> 00:02:29,632
one of an array of
different tools that we

50
00:02:29,699 --> 00:02:31,833
bring in to consideration
when we're thinking about

51
00:02:31,900 --> 00:02:35,599
how to support and guide
and help our members and

52
00:02:35,666 --> 00:02:38,033
our patients make really
wise decisions, taking

53
00:02:38,099 --> 00:02:40,033
into account their
genomics, taking into

54
00:02:40,099 --> 00:02:41,766
account the environment
that they've lived in,

55
00:02:41,833 --> 00:02:44,800
taking into account
lifestyle and diseases

56
00:02:44,866 --> 00:02:47,000
that they already have,
bringing all that

57
00:02:47,066 --> 00:02:48,966
information together
to help them to better

58
00:02:49,033 --> 00:02:51,732
understand what their
current and future risks

59
00:02:51,800 --> 00:02:54,733
might be, what different
kinds of treatment that we

60
00:02:54,800 --> 00:02:58,933
might have to manage a
disease that they have

61
00:02:59,000 --> 00:03:02,300
right now are best suited
to that array of different

62
00:03:02,366 --> 00:03:04,933
circumstances that they
find themselves in, what

63
00:03:05,000 --> 00:03:08,433
are the genetics of a
tumor that they have that

64
00:03:08,500 --> 00:03:13,433
can guide the therapy that
we put in place, and what

65
00:03:13,500 --> 00:03:16,699
are the implications,
especially very early on,

66
00:03:16,766 --> 00:03:19,866
of having genetic risk
factors for the way they

67
00:03:19,933 --> 00:03:22,766
make their choices going
forward in a way that

68
00:03:22,833 --> 00:03:25,533
helps them to achieve their
own personal health goals.

69
00:03:25,599 --> 00:03:28,000
Those are all really
very, very powerful

70
00:03:28,066 --> 00:03:29,933
opportunities, and they
are opportunities that

71
00:03:30,000 --> 00:03:32,333
we're working with
systematically at Kaiser

72
00:03:32,400 --> 00:03:35,400
Permanente even now.

73
00:03:35,466 --> 00:03:38,366
It does bring forward some
important challenges, too,

74
00:03:38,433 --> 00:03:39,833
that we grapple with.

75
00:03:39,900 --> 00:03:42,900
There are between 800,000
and 900,000 genetic

76
00:03:42,966 --> 00:03:47,699
markers that have been
associated with human disease.

77
00:03:47,766 --> 00:03:52,599
There are north of 75,000
genetic tests available.

78
00:03:52,666 --> 00:03:55,566
It's really a small
fraction of those that

79
00:03:55,633 --> 00:03:59,500
guide decision-making when
it comes to interaction in

80
00:03:59,566 --> 00:04:01,033
the clinical space.

81
00:04:01,099 --> 00:04:05,500
And so understanding what
those genetic markers mean

82
00:04:05,566 --> 00:04:08,900
for the populations that we
serve is critically important.

83
00:04:08,966 --> 00:04:11,099
The obligation, I think,
is actually embedded in

84
00:04:11,166 --> 00:04:13,299
the term precision medicine.

85
00:04:13,366 --> 00:04:16,166
If you don't understand
the implications of all of

86
00:04:16,233 --> 00:04:18,300
those different genetic
markers and you don't

87
00:04:18,366 --> 00:04:20,166
understand how they
apply to the specific

88
00:04:20,233 --> 00:04:22,833
circumstances of the
individual that you're

89
00:04:22,899 --> 00:04:26,699
working with, it's not
precise, and so we need to

90
00:04:26,766 --> 00:04:29,166
be very attentive
to the idea of that.

91
00:04:29,233 --> 00:04:30,966
And there are some things
that are true about the

92
00:04:31,033 --> 00:04:34,733
way the information around
genetics and genomics has

93
00:04:34,800 --> 00:04:37,566
unfolded that we need
to take into account.

94
00:04:37,633 --> 00:04:44,599
The lion's share, the
last I saw, 25 or 75% of

95
00:04:44,666 --> 00:04:47,666
individuals who have
participated in research

96
00:04:47,733 --> 00:04:49,399
that is aimed at
understanding the

97
00:04:49,466 --> 00:04:53,100
implications of genetic
markers are northern

98
00:04:53,166 --> 00:04:57,366
European white population,
and so it's very difficult

99
00:04:57,433 --> 00:05:03,599
to know if things that we
draw from that research

100
00:05:03,666 --> 00:05:05,899
applies to the very
diverse communities that

101
00:05:05,966 --> 00:05:08,433
we are working
to take care of.

102
00:05:08,500 --> 00:05:10,500
And so making sure that
we understand that,

103
00:05:10,566 --> 00:05:12,032
critically important.

104
00:05:12,100 --> 00:05:16,600
The other is as we create
algorithms that support a

105
00:05:16,666 --> 00:05:19,600
very, very complex set
of decisions, are we

106
00:05:19,666 --> 00:05:22,399
embedding those biases
into the algorithms in

107
00:05:22,466 --> 00:05:26,266
ways that does not benefit
or create a more precise

108
00:05:26,333 --> 00:05:28,633
and higher quality
decision in that

109
00:05:28,699 --> 00:05:31,033
interaction between the
patient and all of that

110
00:05:31,100 --> 00:05:34,733
information and
the clinician.

111
00:05:34,800 --> 00:05:38,500
And beyond that, of
course, is does that same

112
00:05:38,566 --> 00:05:42,832
thing apply when an
individual is taking what

113
00:05:42,899 --> 00:05:45,166
they know about their
genomics and exploring

114
00:05:45,233 --> 00:05:47,699
what information is
available on the internet

115
00:05:47,766 --> 00:05:50,266
to try to make decisions
day-to-day without that

116
00:05:50,333 --> 00:05:51,699
interaction with the
clinician, which I think

117
00:05:51,766 --> 00:05:53,633
we have to accept as a
part of day-to-day

118
00:05:53,699 --> 00:05:55,166
reality right now.

119
00:05:55,233 --> 00:05:58,899
At Kaiser Permanente, we
are using these tools to

120
00:05:58,966 --> 00:06:00,600
screen for disease.

121
00:06:00,666 --> 00:06:02,966
We're developing the
technology to be

122
00:06:03,033 --> 00:06:04,266
able to track.

123
00:06:04,333 --> 00:06:06,333
>> RAJEEV CHAND: How
important is it?

124
00:06:06,399 --> 00:06:08,433
I'm going to put on my old
investment banking analyst

125
00:06:08,500 --> 00:06:10,633
hat, and you've got
bullish and bearish.

126
00:06:10,699 --> 00:06:12,933
How important - how
bullish and bearish are

127
00:06:13,000 --> 00:06:14,733
you in what timeframe?

128
00:06:14,800 --> 00:06:15,899
>> DR. PATRICK COURNEYA: Okay.

129
00:06:15,966 --> 00:06:20,066
We're very bullish on this
and in the near term.

130
00:06:20,133 --> 00:06:22,000
In fact, there is really
very important things that

131
00:06:22,066 --> 00:06:24,465
we could do
systematically across an entire

132
00:06:24,533 --> 00:06:27,933
population of 12.3 million
members that we could draw

133
00:06:28,000 --> 00:06:30,066
benefit from even now.

134
00:06:30,133 --> 00:06:32,466
Going forward, I'm also
very bullish about it, but

135
00:06:32,533 --> 00:06:35,166
I also have concerns that
we need to be able to

136
00:06:35,233 --> 00:06:37,833
approach the unfolding
information very

137
00:06:37,899 --> 00:06:40,800
thoughtfully, so that as
we incorporate it into

138
00:06:40,866 --> 00:06:43,566
those interactions, it's
actually adding value.

139
00:06:43,633 --> 00:06:45,233
I think it's a
great opportunity.

140
00:06:45,300 --> 00:06:48,366
It's just that right now
we're in a space where the

141
00:06:48,433 --> 00:06:51,699
hype is well ahead of the
reality and we need to be

142
00:06:51,766 --> 00:06:54,033
able to manage that
journey effectively.

143
00:06:54,100 --> 00:06:56,033
>> RAJEEV CHAND: Kathy,
23andMe is clearly the

144
00:06:56,100 --> 00:06:59,233
pioneer, if not one of the
most important pioneers

145
00:06:59,300 --> 00:07:00,366
in this space.

146
00:07:00,433 --> 00:07:01,933
How do you sort of size
the impact to health

147
00:07:02,000 --> 00:07:03,466
outcomes in
what timeframe?

148
00:07:03,533 --> 00:07:04,566
>> KATHY HIBBS: Yeah.

149
00:07:04,633 --> 00:07:07,032
So what's unique about
23andMe is that we are an

150
00:07:07,100 --> 00:07:10,699
FDA-cleared over-the-counter
genetic test.

151
00:07:10,766 --> 00:07:12,633
Patrick was talking about
the fact that there are

152
00:07:12,699 --> 00:07:15,500
maybe 75,000 genes
that have been

153
00:07:15,566 --> 00:07:17,265
associated with disease.

154
00:07:17,333 --> 00:07:20,266
We test only for a small
fraction of those because

155
00:07:20,333 --> 00:07:23,699
we only test for and
report on the genes that

156
00:07:23,766 --> 00:07:26,766
have been well studied,
there's peer-reviewed

157
00:07:26,833 --> 00:07:29,266
published evidence
that shows that we do

158
00:07:29,333 --> 00:07:32,733
understand that these
diseases have a role in

159
00:07:32,800 --> 00:07:36,233
causing - these genes have
a role in causing diseases

160
00:07:36,300 --> 00:07:39,000
specifically, where
it's been really

161
00:07:39,066 --> 00:07:40,599
well-established,
not withstanding

162
00:07:40,666 --> 00:07:41,966
the ethnicity issue.

163
00:07:42,033 --> 00:07:44,100
We do have to explain to
people, as Patrick pointed

164
00:07:44,166 --> 00:07:46,966
out, that most of those
studies really were in a

165
00:07:47,033 --> 00:07:48,433
European population.

166
00:07:48,500 --> 00:07:51,666
And so while there may be
data that indicates that

167
00:07:51,733 --> 00:07:53,466
the function is the
same in people of other

168
00:07:53,533 --> 00:07:56,333
ethnicities, it
is not as robust.

169
00:07:56,399 --> 00:07:57,766
We do that.

170
00:07:57,833 --> 00:08:00,933
The genes that we
report on are ones that

171
00:08:01,000 --> 00:08:03,100
are well recognized.

172
00:08:03,166 --> 00:08:07,866
If you say to your doctor
23andMe says that I have

173
00:08:07,933 --> 00:08:11,166
the marker for a disease
called hemochromatosis,

174
00:08:11,233 --> 00:08:14,566
your doctor will know what
hemochromatosis is and

175
00:08:14,633 --> 00:08:17,866
then will take other tests
to determine because this

176
00:08:17,933 --> 00:08:21,332
is one that's a very
important preventable

177
00:08:21,399 --> 00:08:24,066
disease if you happen to
have the hemochromatosis

178
00:08:24,133 --> 00:08:26,500
marker and have
hemochromatosis.

179
00:08:26,566 --> 00:08:29,332
It means there's too much
iron in your blood, and

180
00:08:29,399 --> 00:08:32,066
the treatment is to
basically draw your blood,

181
00:08:32,133 --> 00:08:35,033
to do a frequent blood
donation, if you will, to

182
00:08:35,100 --> 00:08:36,433
reduce that iron.

183
00:08:36,500 --> 00:08:39,966
The alternative to
not preventing that

184
00:08:40,033 --> 00:08:41,433
is organ failure.

185
00:08:42,732 --> 00:08:43,665
>> RAJEEV CHAND: That
doesn't sound good.

186
00:08:43,732 --> 00:08:45,065
>> KATHY HIBBS: And
that's not good.

187
00:08:45,133 --> 00:08:47,333
You want to catch
and prevent those.

188
00:08:47,399 --> 00:08:49,966
About 12,000 people a year
in this country still die

189
00:08:50,033 --> 00:08:53,033
of hemochromatosis because
we find out too late.

190
00:08:53,100 --> 00:08:55,299
It's the actual organ
failure that's happening

191
00:08:55,366 --> 00:08:58,333
that causes them to go to
the doctor and it's not

192
00:08:58,399 --> 00:09:01,399
cost-effective to
test everyone for

193
00:09:01,466 --> 00:09:02,500
hemochromatosis.

194
00:09:02,566 --> 00:09:04,466
We wait and see if you
develop it and then we'll

195
00:09:04,533 --> 00:09:05,500
test your family members.

196
00:09:05,566 --> 00:09:07,366
That's how it works.

197
00:09:07,433 --> 00:09:10,500
The advantage of 23andMe
is that people can be

198
00:09:10,566 --> 00:09:13,200
tested even though they
don't have a family health

199
00:09:13,266 --> 00:09:16,366
history and they wouldn't
qualify because they

200
00:09:16,433 --> 00:09:18,899
wouldn't meet the clinical
guidelines to be tested in

201
00:09:18,966 --> 00:09:21,066
a medical context, meaning
their doctor won't

202
00:09:21,133 --> 00:09:22,666
recommend it and their
insurance isn't going to

203
00:09:22,733 --> 00:09:23,699
pay for it.

204
00:09:23,766 --> 00:09:27,000
And so for things like
hemochromatosis, we have

205
00:09:27,066 --> 00:09:30,000
lots of patient stories
and customer stories where

206
00:09:30,066 --> 00:09:33,000
we've identified entire
families that actually

207
00:09:33,066 --> 00:09:35,233
suffer from this and it
hasn't been discovered.

208
00:09:35,299 --> 00:09:38,899
And if we do that, we have
the opportunity to prevent

209
00:09:38,966 --> 00:09:40,633
the onset of that disease.

210
00:09:40,700 --> 00:09:44,299
Another example is about
50% of the people that we

211
00:09:44,366 --> 00:09:47,633
find with a mutation in
the BRCA gene, which is

212
00:09:47,700 --> 00:09:49,899
very associated with
increased breast,

213
00:09:49,966 --> 00:09:52,933
prostate, and ovarian
cancer, about 50% of those

214
00:09:53,000 --> 00:09:55,933
people don't know their
ethnicity, they may not

215
00:09:56,000 --> 00:09:58,033
know that they have an
Ashkenazi heritage which

216
00:09:58,100 --> 00:10:00,299
is important for that
particular marker, and

217
00:10:00,366 --> 00:10:02,733
they don't have a family
health history of a cancer

218
00:10:02,799 --> 00:10:05,033
that would have qualified
them for medicine.

219
00:10:05,100 --> 00:10:08,433
The role that we play is
that we give customers the

220
00:10:08,500 --> 00:10:13,133
opportunity to get a
test that may find those

221
00:10:13,200 --> 00:10:16,133
situations where they are
unlikely to be tested in

222
00:10:16,200 --> 00:10:19,333
the medical system and
then we open up their

223
00:10:19,399 --> 00:10:22,000
entire families to what's
called cascade testing for

224
00:10:22,066 --> 00:10:25,500
the medical system because
we do know that people

225
00:10:25,566 --> 00:10:27,833
with these genetic
conditions, particularly

226
00:10:27,899 --> 00:10:30,266
those ones like I've
mentioned where there is

227
00:10:30,333 --> 00:10:33,100
possibility of at least
mitigation, if not

228
00:10:33,166 --> 00:10:37,166
prevention, get missed in
the health care system.

229
00:10:37,233 --> 00:10:40,799
And so that's really the
advantage of 23andMe.

230
00:10:40,866 --> 00:10:41,766
>> RAJEEV CHAND: Great.

231
00:10:41,833 --> 00:10:43,000
I'm going to jump to kind
of topic number two here,

232
00:10:43,066 --> 00:10:44,533
which is privacy, but
just to also level-set

233
00:10:44,600 --> 00:10:45,566
with the group.

234
00:10:45,633 --> 00:10:46,966
This is going to be
a highly interactive session.

235
00:10:47,033 --> 00:10:49,500
In about 20 minutes, I'm
going to invite everyone

236
00:10:49,566 --> 00:10:50,566
to ask questions.

237
00:10:50,633 --> 00:10:54,066
There are two mics in the
aisles here, so that way

238
00:10:54,133 --> 00:10:55,966
everyone who has had a
test or is considering a

239
00:10:56,033 --> 00:10:58,133
test can even just ask a
question as to kind of the

240
00:10:58,200 --> 00:10:59,266
outcome benefit.

241
00:10:59,333 --> 00:11:00,500
But I think all four of
the speakers here would

242
00:11:00,566 --> 00:11:02,600
probably generally agree
that we're excited about

243
00:11:02,666 --> 00:11:04,433
kind of the opportunity
of genomics, even though

244
00:11:04,500 --> 00:11:06,566
there might be some
kind of hypish kind of

245
00:11:06,633 --> 00:11:07,533
qualities today.

246
00:11:07,600 --> 00:11:09,899
So let's jump to privacy.

247
00:11:09,966 --> 00:11:12,566
And so Sharon is the
person who literally has

248
00:11:12,633 --> 00:11:16,399
driven the landmark
kind of bell in this

249
00:11:16,466 --> 00:11:17,399
space called GINA.

250
00:11:17,466 --> 00:11:19,600
Could you talk for just
a few seconds on what

251
00:11:19,666 --> 00:11:22,033
exactly GINA is, and then
the broader question of

252
00:11:22,100 --> 00:11:24,433
can genomics data be
used for employment

253
00:11:24,500 --> 00:11:27,399
considerations, can
genomics data be used for

254
00:11:27,466 --> 00:11:29,299
health insurance,
pre-existing conditions,

255
00:11:29,366 --> 00:11:32,000
can it be used for life
insurance purposes?

256
00:11:32,066 --> 00:11:34,600
Talk to us a little bit
about kind of the privacy

257
00:11:34,666 --> 00:11:36,566
considerations around
genomics data.

258
00:11:36,633 --> 00:11:37,600
>> SHARON TERRY: Sure.

259
00:11:37,666 --> 00:11:40,033
I have to state that I
led actually a massive

260
00:11:40,100 --> 00:11:42,566
coalition of tens of
thousands of individuals

261
00:11:42,633 --> 00:11:44,500
who helped to get the
Genetic Information

262
00:11:44,566 --> 00:11:47,766
Non-Discrimination
Act passed in 2008.

263
00:11:47,833 --> 00:11:50,333
We spent almost 13 years
fighting to have it passed.

264
00:11:50,399 --> 00:11:54,466
It protects individuals in
both health insurance and

265
00:11:54,533 --> 00:11:56,566
employment from being
discriminated against

266
00:11:56,633 --> 00:11:58,533
based on genetic
information.

267
00:11:58,600 --> 00:11:59,533
>> RAJEEV CHAND: So
it can't be used for

268
00:11:59,600 --> 00:12:00,366
pre-existing conditions.

269
00:12:00,433 --> 00:12:01,700
>> SHARON TERRY: Right.

270
00:12:01,766 --> 00:12:03,699
Well, so an interesting
piece of this is if a

271
00:12:03,766 --> 00:12:05,799
person also has a symptom
- so let's use the

272
00:12:05,866 --> 00:12:08,665
hemochromatosis example -
they have mutations in the

273
00:12:08,733 --> 00:12:11,099
gene associated with
hemochromatosis, the

274
00:12:11,166 --> 00:12:13,166
insurer and the employer
cannot discriminate

275
00:12:13,233 --> 00:12:15,799
against them based on
that genetic information.

276
00:12:15,866 --> 00:12:18,466
However, if they're
symptomatic, they can use

277
00:12:18,533 --> 00:12:20,533
that information, just as
they can about all of our

278
00:12:20,600 --> 00:12:24,433
health, to discriminate or
set premiums, et cetera.

279
00:12:24,500 --> 00:12:27,700
GINA does not cover
long-term care insurance

280
00:12:27,766 --> 00:12:29,132
and life insurance.

281
00:12:29,200 --> 00:12:32,799
While we started out now
20 years ago trying to get

282
00:12:32,866 --> 00:12:35,933
that done, it was
impossible for us to get

283
00:12:36,000 --> 00:12:38,100
those provisions through
because those particular

284
00:12:38,166 --> 00:12:41,533
kinds of insurance really
heavily rely on prediction.

285
00:12:41,600 --> 00:12:43,966
So what we're finding is
that individuals are more

286
00:12:44,033 --> 00:12:46,700
and more interested in
their genetic information.

287
00:12:46,766 --> 00:12:49,899
You can go to the gas
station or a fast food

288
00:12:49,966 --> 00:12:51,566
restaurant and hear people
talking about their

289
00:12:51,633 --> 00:12:55,200
results from DTC consumers
or from the doctor.

290
00:12:55,266 --> 00:12:57,466
What I'm most concerned
about is that we do

291
00:12:57,533 --> 00:12:59,600
protect privacy, but at
the same time that this

292
00:12:59,666 --> 00:13:02,100
information is available
to use for research,

293
00:13:02,166 --> 00:13:03,666
particularly as we're
getting the kind of

294
00:13:03,733 --> 00:13:06,099
porosity that we're seeing
at a place like Kaiser and

295
00:13:06,166 --> 00:13:09,899
others, where clinical and
research integration is

296
00:13:09,966 --> 00:13:12,633
really happening rapidly
and that's very important.

297
00:13:12,700 --> 00:13:14,533
And so I've developed a
system that I've worked on

298
00:13:14,600 --> 00:13:18,000
for years and have a
partner called Luna DNA

299
00:13:18,066 --> 00:13:20,100
whereby we allow
individuals to keep a

300
00:13:20,166 --> 00:13:21,200
string on their data.

301
00:13:21,266 --> 00:13:23,565
So they deposit their
genome, their medical

302
00:13:23,633 --> 00:13:26,833
record, their patient
reported outcomes, and

303
00:13:26,899 --> 00:13:31,333
they get to tell who gets
access to this information.

304
00:13:31,399 --> 00:13:34,000
The data stays in the
repository in multiple

305
00:13:34,066 --> 00:13:37,566
databases with lots of foreign
key structures, et cetera.

306
00:13:37,633 --> 00:13:41,033
And the questions come to
that data, so sandboxes,

307
00:13:41,100 --> 00:13:43,600
virtual compute
environments allow these

308
00:13:43,666 --> 00:13:46,200
questions to be asked
and even spin up whole

309
00:13:46,266 --> 00:13:48,000
communities around
the questions.

310
00:13:48,066 --> 00:13:51,866
For me, trying to drive
a consumer-driven health

311
00:13:51,933 --> 00:13:55,165
care system like we have
now done in ride sharing

312
00:13:55,233 --> 00:13:57,165
and music and other
places, I think we're

313
00:13:57,233 --> 00:13:58,833
going to need to see an
integration of these

314
00:13:58,899 --> 00:14:01,500
systems such that the
consumer is central the

315
00:14:01,566 --> 00:14:03,466
focus and, in fact,
gets rewarded.

316
00:14:03,533 --> 00:14:07,100
In our system, we have SEC
qualified shares given to

317
00:14:07,166 --> 00:14:09,299
individuals for sharing
their information, and

318
00:14:09,366 --> 00:14:11,899
that means we're overseen
by the SEC and that gives

319
00:14:11,966 --> 00:14:14,566
us another level of
accountability and really

320
00:14:14,633 --> 00:14:17,299
moving people from
being subjects or patients

321
00:14:17,366 --> 00:14:18,366
to being partners.

322
00:14:18,433 --> 00:14:21,133
>> RAJEEV CHAND: Would all
four of you agree that my

323
00:14:21,200 --> 00:14:25,533
genome is my
intellectual property?

324
00:14:25,600 --> 00:14:26,500
>> SHARON TERRY: Yes.

325
00:14:26,566 --> 00:14:27,799
>> RAJEEV CHAND: My genome
is - so each person's

326
00:14:27,866 --> 00:14:29,433
genome is their
intellectual property.

327
00:14:29,500 --> 00:14:31,233
>> SHARON TERRY: Yeah.

328
00:14:31,299 --> 00:14:32,100
>> DR. PATRICK COURNEYA: Yeah.

329
00:14:32,166 --> 00:14:34,100
I don't know that I would
even restrict it to

330
00:14:34,166 --> 00:14:36,066
intellectual property.

331
00:14:36,133 --> 00:14:37,433
>> KATHY HIBBS:
Just your property.

332
00:14:37,500 --> 00:14:40,033
>> DR. PATRICK COURNEYA:
I mean, they own it.

333
00:14:40,100 --> 00:14:41,899
>> RAJEEV CHAND: So a
person's genome is their data.

334
00:14:41,966 --> 00:14:42,866
>> DR. PATRICK
COURNEYA: Yeah.

335
00:14:42,933 --> 00:14:43,966
>> RAJEEV CHAND: And
companies are custodians

336
00:14:44,033 --> 00:14:46,633
of that data, not
owners of that data.

337
00:14:46,700 --> 00:14:47,766
>> SHARON TERRY: So, yeah.

338
00:14:47,833 --> 00:14:49,366
But I think, Rajeev,
what's happening a lot of

339
00:14:49,433 --> 00:14:51,633
places, and even in major
medical centers that I

340
00:14:51,700 --> 00:14:54,233
work with, is often the
major medical center will

341
00:14:54,299 --> 00:14:55,933
tell us we own that data.

342
00:14:56,000 --> 00:14:57,200
Now there are laws -

343
00:14:57,266 --> 00:14:58,565
>> RAJEEV CHAND: The major
medical center owns the

344
00:14:58,633 --> 00:14:59,899
data, or the patients
own the data?

345
00:14:59,966 --> 00:15:00,833
>> SHARON TERRY: Yeah.

346
00:15:00,899 --> 00:15:02,600
They'll say lip service
the patient owns the data.

347
00:15:02,666 --> 00:15:04,500
But then when you get
to it and ask for wide

348
00:15:04,566 --> 00:15:08,200
sharing or contributions
of these data to various

349
00:15:08,266 --> 00:15:10,699
databases, there are some
concerns about their

350
00:15:10,766 --> 00:15:12,833
business models,
their restrictions.

351
00:15:12,899 --> 00:15:15,733
Sometimes you need even
HIPAA to kind of cover

352
00:15:15,799 --> 00:15:19,033
what they're doing when,
in fact, HIPAA does not

353
00:15:19,100 --> 00:15:20,799
disallow that
kind of sharing.

354
00:15:20,866 --> 00:15:23,366
And I think - and Kathy
probably can speak to this

355
00:15:23,433 --> 00:15:26,165
better, but there are now
actual provisions in the

356
00:15:26,233 --> 00:15:28,599
law that allow every one
of us to get any data we

357
00:15:28,666 --> 00:15:31,533
want from anyone
who holds that data.

358
00:15:31,600 --> 00:15:33,500
But I don't think we're
finding data as liquid as

359
00:15:33,566 --> 00:15:36,033
we want it to be and we're
finding some disincentives

360
00:15:36,100 --> 00:15:38,333
for sharing, especially
from institutions,

361
00:15:38,399 --> 00:15:40,433
pharmaceutical
companies, et cetera.

362
00:15:40,433 --> 00:15:41,700
>> RAJEEV CHAND: So,
Sharon, the next question

363
00:15:41,766 --> 00:15:42,533
is for you.

364
00:15:42,600 --> 00:15:43,933
Two years ago, I hosted
Facebook at one of my

365
00:15:44,000 --> 00:15:44,666
private seminars.

366
00:15:44,733 --> 00:15:45,933
I asked them about
Cambridge Analytica.

367
00:15:46,000 --> 00:15:48,200
I actually hosted
Cambridge Analytica at my

368
00:15:48,266 --> 00:15:49,466
seminar last year.

369
00:15:49,533 --> 00:15:53,166
Is there - is there a
Cambridge Analytica in the

370
00:15:53,233 --> 00:15:56,532
waiting here with kind
of this ecosystem of

371
00:15:56,600 --> 00:16:01,766
genomics, kind of sourcers,
researchers, monetizers?

372
00:16:01,833 --> 00:16:03,799
Is there a Cambridge
Analytica kind of waiting here?

373
00:16:03,866 --> 00:16:04,633
>> SHARON TERRY: Yeah.

374
00:16:04,700 --> 00:16:06,200
So I think, first of all,
there is already the

375
00:16:06,266 --> 00:16:08,366
monetization of data that
we actually have nothing

376
00:16:08,433 --> 00:16:10,866
to do about, which is why,
in our partnership with

377
00:16:10,933 --> 00:16:13,233
Luna DNA, we made sure
that the people get the

378
00:16:13,299 --> 00:16:15,433
shares rather than
everybody else making

379
00:16:15,500 --> 00:16:17,033
out on the data.

380
00:16:17,100 --> 00:16:18,766
I think there is also
nefarious use of data

381
00:16:18,833 --> 00:16:19,600
happening already.

382
00:16:19,666 --> 00:16:21,299
We've seen that,
especially in medical

383
00:16:21,366 --> 00:16:24,133
record breaks, but also
in genomic information.

384
00:16:24,200 --> 00:16:26,299
I'm very concerned not
so much maybe about an

385
00:16:26,366 --> 00:16:28,633
individual, but that
that individual's genome

386
00:16:28,700 --> 00:16:30,633
actually is a
representation of their

387
00:16:30,700 --> 00:16:32,899
family, their ancestors,
their children.

388
00:16:32,966 --> 00:16:35,566
When I share my genome, I
maybe should be asking my

389
00:16:35,633 --> 00:16:37,366
parents and my children
for permission.

390
00:16:37,433 --> 00:16:38,600
I don't, but I could.

391
00:16:38,666 --> 00:16:40,033
And I think the other
thing we're looking at

392
00:16:40,100 --> 00:16:42,033
here is this is a great
place to actually

393
00:16:42,100 --> 00:16:44,633
discriminate against
populations, so to start

394
00:16:44,700 --> 00:16:47,366
to come out with
information that might be

395
00:16:47,433 --> 00:16:49,933
misinformation about a
group of people based on

396
00:16:50,000 --> 00:16:54,233
what we think is a
population-wide genomic study.

397
00:16:54,299 --> 00:16:56,600
>> DR. PATRICK COURNEYA:
Rajeev, you asked that

398
00:16:56,666 --> 00:17:00,266
question about am I
bullish on the potential

399
00:17:00,333 --> 00:17:03,699
for genomics in helping
people achieve their

400
00:17:03,766 --> 00:17:04,633
health goals.

401
00:17:04,700 --> 00:17:06,299
I'm very bullish on that.

402
00:17:06,366 --> 00:17:09,500
But I think we're already
seeing behavior in the

403
00:17:09,566 --> 00:17:12,266
population that suggests
they've begun to pull back

404
00:17:12,333 --> 00:17:15,266
from the free sharing
of information because

405
00:17:15,333 --> 00:17:17,566
they've seen the
information that they've

406
00:17:17,633 --> 00:17:20,533
put out in the marketplace
used in ways that they

407
00:17:20,598 --> 00:17:23,165
didn't anticipate, that
they are uncomfortable

408
00:17:23,233 --> 00:17:24,433
with at this point.

409
00:17:24,500 --> 00:17:26,766
And as we get further and
further into things that

410
00:17:26,833 --> 00:17:28,633
are more and more
private and from which

411
00:17:28,700 --> 00:17:32,700
deidentification is
incredibly difficult, we

412
00:17:32,766 --> 00:17:35,866
may see circumstances
where populations actually

413
00:17:35,933 --> 00:17:38,000
withdraw from that
opportunity because

414
00:17:38,066 --> 00:17:40,633
they've lost trust that
the system can protect

415
00:17:40,700 --> 00:17:44,000
very, very valuable and
potentially challenging

416
00:17:44,066 --> 00:17:45,299
information for them.

417
00:17:45,366 --> 00:17:46,599
>> KATHY HIBBS: Yeah.

418
00:17:46,666 --> 00:17:49,332
For 23andMe, I think the
point Sharon is making is

419
00:17:49,400 --> 00:17:52,666
really important, that
I don't think we as

420
00:17:52,733 --> 00:17:56,366
consumers or patients
really understand our

421
00:17:56,433 --> 00:17:59,133
health care data and how
that's used in the system.

422
00:17:59,200 --> 00:18:01,700
I frequently point out to
people, many of the folks

423
00:18:01,766 --> 00:18:04,266
in the room, I'm sure, are
familiar with HIPAA, but a

424
00:18:04,333 --> 00:18:06,400
lot of people don't
understand that the P in

425
00:18:06,466 --> 00:18:09,866
HIPAA is for portability;
it is not for privacy.

426
00:18:09,933 --> 00:18:12,099
The amount of information
in your health care

427
00:18:12,166 --> 00:18:16,033
records that HIPAA covers
is a tiny segment called PHI.

428
00:18:16,099 --> 00:18:18,832
It's not most of the
medical outcomes.

429
00:18:18,900 --> 00:18:21,099
To the kind of commerce
point, there very

430
00:18:21,166 --> 00:18:24,633
recently, the CEO of one
of the major software

431
00:18:24,700 --> 00:18:29,200
companies that provides
backbone billing software

432
00:18:29,266 --> 00:18:31,900
to medical providers,
hospitals, and the like

433
00:18:31,966 --> 00:18:36,565
basically said that they
opposed data sharing by patients

434
00:18:36,633 --> 00:18:39,866
because it would impinge
on their business model.

435
00:18:39,933 --> 00:18:43,033
And doing that, of course,
prevents us as individuals

436
00:18:43,099 --> 00:18:46,533
from changing doctors,
getting a second opinion,

437
00:18:46,599 --> 00:18:48,866
keeping track of our
health records, so that

438
00:18:48,933 --> 00:18:51,866
when we do have a disease
or a condition arise, we

439
00:18:51,933 --> 00:18:54,666
can easily say, no, you
know, I've been looked -

440
00:18:54,733 --> 00:18:57,399
I've had this procedure,
or I've never been on that

441
00:18:57,466 --> 00:18:59,565
drug, or here is my
dosage information.

442
00:18:59,633 --> 00:19:04,566
There are real impacts to
people trying to silo data

443
00:19:04,633 --> 00:19:07,000
from the individuals whose
data that is, and there

444
00:19:07,066 --> 00:19:10,099
are commercial reasons
that people are doing that

445
00:19:10,166 --> 00:19:14,166
and are concerned about
keeping that data not just

446
00:19:14,233 --> 00:19:16,666
from researchers, but
from the individuals whose

447
00:19:16,733 --> 00:19:18,200
data that is.

448
00:19:18,266 --> 00:19:22,566
But for 23andMe,
historically, and way back

449
00:19:22,633 --> 00:19:25,133
before Facebook or any
of those other things,

450
00:19:25,200 --> 00:19:27,533
because fundamentally the
purpose of the company has

451
00:19:27,599 --> 00:19:31,832
always been health care,
we have always used

452
00:19:31,900 --> 00:19:34,133
essentially the same
standards that apply to

453
00:19:34,200 --> 00:19:36,633
human subject research
for clinical trials.

454
00:19:36,700 --> 00:19:39,233
There is an external
ethical board called an

455
00:19:39,299 --> 00:19:42,700
IRB or an institutional
review board that reviews

456
00:19:42,766 --> 00:19:45,200
the studies that we do
and they also review the

457
00:19:45,266 --> 00:19:46,733
consent requirements.

458
00:19:46,799 --> 00:19:49,900
You have to get knowing
and informed consent to do

459
00:19:49,966 --> 00:19:51,233
medical research.

460
00:19:51,299 --> 00:19:54,066
And so when folks consent
to research inside of

461
00:19:54,133 --> 00:19:56,799
23andMe, they are
not defaulted.

462
00:19:56,866 --> 00:19:59,900
It's not like the
Cambridge Analytica situation.

463
00:19:59,966 --> 00:20:03,199
They actually have to
proactively consent at

464
00:20:03,266 --> 00:20:07,233
three different levels to
the actual research in a

465
00:20:07,299 --> 00:20:10,766
very, very specific way
so that they - so that we

466
00:20:10,833 --> 00:20:13,599
have knowing and
informed consent.

467
00:20:13,666 --> 00:20:16,500
I think that that is
something - that's an area

468
00:20:16,566 --> 00:20:19,500
where those ethical
standards that apply in

469
00:20:19,566 --> 00:20:23,366
the medical system can be
examples for some of the

470
00:20:23,433 --> 00:20:26,966
other - some of the other
parts of technology, if

471
00:20:27,033 --> 00:20:30,065
you will, that have a kind
of more of an ad tech and

472
00:20:30,133 --> 00:20:33,000
a default consent model to
hopefully prevent that.

473
00:20:33,066 --> 00:20:35,200
Now that comes out of a
background where there

474
00:20:35,266 --> 00:20:38,500
were abuses, you know,
the Tuskegee situation.

475
00:20:38,566 --> 00:20:43,766
It's just that the medical
research, because those

476
00:20:43,833 --> 00:20:47,966
issues arose 70-80 years
ago, there are some

477
00:20:48,033 --> 00:20:50,399
standards there that can
be applied and certainly

478
00:20:50,466 --> 00:20:55,199
we adhere to those that
I think could give some

479
00:20:55,266 --> 00:20:57,400
level of public trust
if we can get people to

480
00:20:57,466 --> 00:21:00,332
understand and then
differentiate and make

481
00:21:00,400 --> 00:21:03,933
informed choices about who
they work with, where they

482
00:21:04,000 --> 00:21:06,433
use their data, and what
they actually consent to.

483
00:21:06,500 --> 00:21:07,799
>> RAJEEV CHAND: This is
actually a question both

484
00:21:07,866 --> 00:21:10,233
for the room and for the
group here is do we feel

485
00:21:10,299 --> 00:21:12,700
that patients are giving
informed consent.

486
00:21:12,766 --> 00:21:14,266
Do we feel like patients
are giving informed

487
00:21:14,333 --> 00:21:16,033
consent here, they
understand how their

488
00:21:16,099 --> 00:21:17,500
genetics data
is being used?

489
00:21:17,566 --> 00:21:18,833
>> KATHY HIBBS: I think
they definitely do in

490
00:21:18,900 --> 00:21:19,900
terms of our customers.

491
00:21:19,966 --> 00:21:22,500
And it's always funny if
there is a kind of very

492
00:21:22,566 --> 00:21:23,633
hyped press article.

493
00:21:23,700 --> 00:21:26,700
If you read the comments -
it will say something like

494
00:21:26,766 --> 00:21:30,333
23andMe is doing research
with GSK, and if you read

495
00:21:30,400 --> 00:21:32,500
the comments, it will be
our users saying, well,

496
00:21:32,566 --> 00:21:33,866
duh, of course
we know that.

497
00:21:33,933 --> 00:21:35,099
We consented to that.

498
00:21:35,166 --> 00:21:38,366
But I don't think that
that's universally the case.

499
00:21:38,433 --> 00:21:41,599
And we know, for example,
on our own website where

500
00:21:41,666 --> 00:21:45,066
customers and potential
customers are, the area of

501
00:21:45,133 --> 00:21:47,466
the website they spend
the most time on is the

502
00:21:47,533 --> 00:21:50,033
privacy and
transparency section.

503
00:21:50,099 --> 00:21:52,500
We know our customers
are looking at that

504
00:21:52,566 --> 00:21:55,099
information as they're
trying to make a decision

505
00:21:55,166 --> 00:21:57,399
about whether they want
to make a purchase and

506
00:21:57,466 --> 00:21:58,765
take a test or not.

507
00:21:58,833 --> 00:22:02,533
But I don't know that, you
know, to I think you said

508
00:22:02,599 --> 00:22:05,533
that - one of you said
that there were how many

509
00:22:05,599 --> 00:22:07,433
tests out there, 75,000.

510
00:22:07,500 --> 00:22:09,066
>> DR. PATRICK COURNEYA:
There are 75,000-plus

511
00:22:09,133 --> 00:22:12,533
tests and 800,000-plus
markers associated

512
00:22:12,599 --> 00:22:13,966
with human disease.

513
00:22:14,033 --> 00:22:16,399
>> KATHY HIBBS: I don't
know that we can say that

514
00:22:16,466 --> 00:22:19,065
there is a standard that's
consistent across that

515
00:22:19,133 --> 00:22:20,700
level of span.

516
00:22:20,766 --> 00:22:23,000
>> RAJEEV CHAND: Sharon,
I see you smiling there.

517
00:22:23,066 --> 00:22:24,933
As the voice of the
patient, let me as you

518
00:22:25,000 --> 00:22:27,733
your thoughts on this
question, not for 23andMe

519
00:22:27,799 --> 00:22:28,666
specifically.

520
00:22:28,733 --> 00:22:30,633
Just in the market, do we
feel like patients and

521
00:22:30,700 --> 00:22:32,266
consumers are giving
informed consent?

522
00:22:32,333 --> 00:22:33,166
>> SHARON TERRY: Yeah.

523
00:22:33,233 --> 00:22:35,366
I think that's a really
hard question that most of

524
00:22:35,433 --> 00:22:37,133
us - I mean, there have
been those sorts of joke

525
00:22:37,200 --> 00:22:39,366
consent forms where one of
the terms is you give away

526
00:22:39,433 --> 00:22:41,700
your first born and
people sign it anyway.

527
00:22:41,766 --> 00:22:43,400
There are both the people
who don't read it, there

528
00:22:43,466 --> 00:22:44,599
are the people who
try to read it and

529
00:22:44,666 --> 00:22:45,599
can't understand it.

530
00:22:45,666 --> 00:22:48,500
There is a complexity of
all the legal issues that

531
00:22:48,566 --> 00:22:50,266
are usually embedded in
them and they're very long.

532
00:22:50,333 --> 00:22:52,533
Ours is only four pages
and we made it really

533
00:22:52,599 --> 00:22:53,666
consumer friendly.

534
00:22:53,733 --> 00:22:56,033
But I think still, like
how does any one of us

535
00:22:56,099 --> 00:22:58,599
know what we're consenting
for for the future and

536
00:22:58,666 --> 00:23:00,500
what we may or may not
find out and how that's

537
00:23:00,566 --> 00:23:01,733
going to strike us then?

538
00:23:01,799 --> 00:23:04,433
I think the best we can
do is more engagement and

539
00:23:04,500 --> 00:23:06,366
process than just a form.

540
00:23:06,433 --> 00:23:08,533
In our case, we really
like to say what does

541
00:23:08,599 --> 00:23:09,733
long-term engagement mean?

542
00:23:09,799 --> 00:23:11,533
How do we embed this in
communities that can

543
00:23:11,599 --> 00:23:12,466
help support you?

544
00:23:12,533 --> 00:23:14,065
And particularly
in underserved and

545
00:23:14,133 --> 00:23:17,366
underrepresented populations,
they are not being given the

546
00:23:17,433 --> 00:23:20,633
same advantage that, for
example, a 23andMe customer.

547
00:23:20,700 --> 00:23:22,333
>> RAJEEV CHAND: Even four
pages feels like too much.

548
00:23:22,400 --> 00:23:24,299
Even four pages feels like
it would be difficult to

549
00:23:24,366 --> 00:23:27,833
have most people
digest four pages.

550
00:23:27,900 --> 00:23:28,766
>> SHARON TERRY: Yep.

551
00:23:30,366 --> 00:23:32,533
>> DR. PATRICK COURNEYA:
I think, you know, our

552
00:23:32,599 --> 00:23:35,166
current infrastructure -
our current structure was

553
00:23:35,233 --> 00:23:39,066
launched by Tuskegee
and other very bad experiences.

554
00:23:39,133 --> 00:23:42,533
That's been a long time
and it has been updated to

555
00:23:42,599 --> 00:23:43,666
be sure.

556
00:23:43,733 --> 00:23:47,966
But the leading edge of
advance is moving much

557
00:23:48,033 --> 00:23:50,565
more rapidly than
regulatory or evidence

558
00:23:50,633 --> 00:23:52,566
associated with that.

559
00:23:52,633 --> 00:23:56,799
And so I would argue that
the consent that I give

560
00:23:56,866 --> 00:24:00,066
today about the use
of my genetics may be

561
00:24:00,133 --> 00:24:02,366
fundamentally different
than I give in a year

562
00:24:02,433 --> 00:24:04,400
because things have
changed so much that I

563
00:24:04,466 --> 00:24:07,632
didn't understand then
what I was signing up for.

564
00:24:07,700 --> 00:24:10,099
And so it is a
moving target.

565
00:24:10,166 --> 00:24:11,799
It is quite challenging.

566
00:24:11,866 --> 00:24:16,766
I think we should not draw
false comfort from the way

567
00:24:16,833 --> 00:24:18,333
the structure is
set up right now.

568
00:24:18,400 --> 00:24:20,500
>> RAJEEV CHAND: So, Mike,
we have this significant

569
00:24:20,566 --> 00:24:23,700
opportunity with sort of
very significant privacy

570
00:24:23,766 --> 00:24:25,066
considerations.

571
00:24:25,133 --> 00:24:28,233
Question for you: What
happens - I think one can

572
00:24:28,299 --> 00:24:30,366
clearly see, even from
this past week with MGM,

573
00:24:30,433 --> 00:24:32,933
every company can get
breached at some point in time.

574
00:24:33,000 --> 00:24:35,066
I don't know if you'd
agree or disagree with that.

575
00:24:35,133 --> 00:24:38,000
But assuming that you
would agree, what happens

576
00:24:38,066 --> 00:24:42,200
when my genomics data gets
breached and gets sort of

577
00:24:42,266 --> 00:24:43,566
revealed on the dark web?

578
00:24:43,633 --> 00:24:44,633
What happens?

579
00:24:44,700 --> 00:24:45,700
>> MIKE WILSON: Yeah.

580
00:24:45,766 --> 00:24:47,266
It's interesting the
security guy gets asked a

581
00:24:47,333 --> 00:24:50,033
privacy question again.

582
00:24:50,099 --> 00:24:53,233
Just as thinking about
this topic, and I'm

583
00:24:53,299 --> 00:24:56,400
finding this dialogue very
interesting, but it's a

584
00:24:56,466 --> 00:24:58,132
little challenging
from a security and

585
00:24:58,200 --> 00:25:01,400
technologist's perspective
because, in my personal

586
00:25:01,466 --> 00:25:06,699
view, privacy - and I mean
this with utmost respect -

587
00:25:06,766 --> 00:25:09,266
almost stands, the P
stands for philosophy.

588
00:25:09,333 --> 00:25:12,099
I mean that respectfully
because it's an ongoing

589
00:25:12,166 --> 00:25:15,265
dialogue and discussion
around some very complex issues.

590
00:25:15,333 --> 00:25:18,366
And so when I - I have a couple
of decades in health care.

591
00:25:18,433 --> 00:25:20,866
Before that, I was in more
financial services and a

592
00:25:20,933 --> 00:25:24,099
few other things, and very
much came to the health

593
00:25:24,166 --> 00:25:26,866
industry with a view of,
okay, do I really care

594
00:25:26,933 --> 00:25:28,566
about what the data is
at the end of the day?

595
00:25:28,633 --> 00:25:30,033
Yes, I do.

596
00:25:30,099 --> 00:25:33,500
But somebody is defining
why I should care.

597
00:25:33,566 --> 00:25:35,299
My colleagues.

598
00:25:35,366 --> 00:25:36,433
I need to protect it.

599
00:25:36,500 --> 00:25:37,433
Right?

600
00:25:37,500 --> 00:25:38,500
And I need to sort of
put it in a vault and do

601
00:25:38,566 --> 00:25:39,866
things to it and
all the rest of it.

602
00:25:39,933 --> 00:25:40,866
How do I protect it?

603
00:25:40,933 --> 00:25:44,000
Interestingly, as I've
sort of unfolded the

604
00:25:44,066 --> 00:25:46,033
conversation, again,
dealing with colleagues

605
00:25:46,099 --> 00:25:47,666
and the philosophical
issues around the data

606
00:25:47,733 --> 00:25:50,765
itself, I've realized that
health care is very unique.

607
00:25:50,833 --> 00:25:54,133
Genomic data in particular is
an example of that uniqueness.

608
00:25:54,200 --> 00:25:56,099
There are terms that
are out there in the

609
00:25:56,166 --> 00:26:00,433
technology setting around
immutability and so forth.

610
00:26:00,500 --> 00:26:02,766
If you think about data
and data persistency,

611
00:26:02,833 --> 00:26:06,500
genomic data is as
relevant 100 years from

612
00:26:06,566 --> 00:26:09,200
now at an individual
level as it is now.

613
00:26:09,266 --> 00:26:10,900
I'm being extreme in
my thought process.

614
00:26:10,966 --> 00:26:14,366
But how then do you think
about then to protect

615
00:26:14,433 --> 00:26:17,400
something where you don't
know what the risks are in

616
00:26:17,466 --> 00:26:18,933
50 to 100 years?

617
00:26:19,000 --> 00:26:21,599
Again, I'm being extreme
in my view for a point.

618
00:26:21,666 --> 00:26:24,265
In terms of the breach
concept, the reality, from

619
00:26:24,333 --> 00:26:27,700
my standpoint as a managed
care organization Chief

620
00:26:27,766 --> 00:26:30,366
Security Officer for
Molina Healthcare which

621
00:26:30,433 --> 00:26:32,900
satisfies government
programs, Medicaid and so

622
00:26:32,966 --> 00:26:36,565
forth, Medi-Cal in
California, similar in

623
00:26:36,633 --> 00:26:42,700
that regard to Kaiser, I
think about health data in

624
00:26:42,766 --> 00:26:44,700
a number of different
ways, and I think about

625
00:26:44,766 --> 00:26:47,200
the risk of theft, of
course, and I think about

626
00:26:47,266 --> 00:26:48,799
insider threats, which you
would have heard a lot

627
00:26:48,866 --> 00:26:52,700
about, and I think about
it in terms of criminals,

628
00:26:52,766 --> 00:26:54,533
and I think about how
they're monetizing it, and

629
00:26:54,599 --> 00:26:56,500
they are, and we can talk
more about that, and I

630
00:26:56,566 --> 00:27:01,666
think about it in terms of
ransomware and in terms of

631
00:27:01,733 --> 00:27:03,799
malware, destructive
malware and such and how

632
00:27:03,866 --> 00:27:05,799
that could interrupt my
processes and the like.

633
00:27:05,866 --> 00:27:07,933
But, interestingly, apart
from certain biomedical

634
00:27:08,000 --> 00:27:12,900
markers and thinking about
that under the context of

635
00:27:12,966 --> 00:27:16,699
HIPAA, which is the
security role which is for

636
00:27:16,766 --> 00:27:19,333
- health professionals
will appreciate that from

637
00:27:19,400 --> 00:27:21,400
a security context sort of
as the guiding arm in this

638
00:27:21,466 --> 00:27:25,500
country, I think about it
similar to how I think, in

639
00:27:25,566 --> 00:27:27,666
fact, literally, how I think
about it as a fingerprint.

640
00:27:27,733 --> 00:27:29,366
I mean, I don't know
if I care that much.

641
00:27:29,433 --> 00:27:30,700
It's a biomarker.

642
00:27:30,766 --> 00:27:32,033
I need to protect it.

643
00:27:32,099 --> 00:27:34,166
Unfortunately, coming back
to this philosophy and

644
00:27:34,233 --> 00:27:36,500
coming back to this
forward view, coming back

645
00:27:36,566 --> 00:27:38,233
to the nature of the data
and what are the risks

646
00:27:38,299 --> 00:27:40,599
that I don't know yet, I
have to know the data just

647
00:27:40,666 --> 00:27:43,265
a little bit more than
that, and then HIPAA and

648
00:27:43,333 --> 00:27:46,966
other regulations and laws
that are coming out, some

649
00:27:47,033 --> 00:27:49,033
of which are coming out at
the state level as well.

650
00:27:49,099 --> 00:27:51,866
I'm thinking about the
data now in ways that are

651
00:27:51,933 --> 00:27:52,966
very unique to
health care.

652
00:27:53,033 --> 00:27:54,799
We hear this term
masking a lot and

653
00:27:54,866 --> 00:27:56,233
de-identification.

654
00:27:56,299 --> 00:27:58,533
Again, we sort of throw it
into the privacy camp, but

655
00:27:58,599 --> 00:28:00,332
then you'll find that the
security chap has to come

656
00:28:00,400 --> 00:28:02,900
along with some techniques
to help out, right, in

657
00:28:02,966 --> 00:28:06,166
terms of applying the
techniques, the black box

658
00:28:06,233 --> 00:28:08,466
scenario in terms of
your solutions, probably

659
00:28:08,533 --> 00:28:10,299
underscored with
cryptography and a variety

660
00:28:10,366 --> 00:28:11,000
of other things.

661
00:28:11,066 --> 00:28:13,900
Those are clearly
security mechanisms

662
00:28:13,966 --> 00:28:15,199
and protection mechanisms.

663
00:28:15,266 --> 00:28:17,900
And then health care, there
is this idea of statistics.

664
00:28:17,966 --> 00:28:22,265
In the art of analytics
and big data, it's

665
00:28:22,333 --> 00:28:24,666
computational statistics
on the whole.

666
00:28:24,733 --> 00:28:26,399
And so you've got
vast amounts of data.

667
00:28:26,466 --> 00:28:28,599
I think about genetic
data maybe a little

668
00:28:28,666 --> 00:28:29,533
differently.

669
00:28:29,599 --> 00:28:30,733
We've got 3.5
billion records.

670
00:28:30,799 --> 00:28:33,166
>> RAJEEV CHAND: Can a
hacker monetize genetic data?

671
00:28:33,233 --> 00:28:37,265
Is a hacker incented to try
to get after genetic data?

672
00:28:37,333 --> 00:28:39,566
>> MIKE WILSON: In and
of itself, probably not.

673
00:28:39,633 --> 00:28:41,000
Combined with
other data, yes.

674
00:28:41,066 --> 00:28:43,500
So it's like the
uniqueness of a medical

675
00:28:43,566 --> 00:28:46,166
record in itself and a
health record and all of

676
00:28:46,233 --> 00:28:48,666
these terms have certain
definitions, but in and of

677
00:28:48,733 --> 00:28:52,265
themselves telemetry.

678
00:28:52,333 --> 00:28:55,533
Can I monetize
packets on a network?

679
00:28:55,599 --> 00:28:58,000
Yeah, probably can given
the context and what the

680
00:28:58,066 --> 00:28:59,833
packets are telling me
and all the rest of it.

681
00:28:59,900 --> 00:29:03,466
Can I monetize
genomic data?

682
00:29:03,533 --> 00:29:05,799
Clearly, yes, but
only with context and

683
00:29:05,866 --> 00:29:08,266
additional information,
information about, for

684
00:29:08,333 --> 00:29:11,033
instance, the
matching of me.

685
00:29:11,099 --> 00:29:14,566
Generic data is
all around us.

686
00:29:14,633 --> 00:29:15,533
Right?

687
00:29:15,599 --> 00:29:17,466
For instance, genetic
data and so forth.

688
00:29:17,533 --> 00:29:20,265
It's no different than my
fingerprint in some respects.

689
00:29:20,333 --> 00:29:23,299
It's no different than a
biomarker from a lipid panel.

690
00:29:23,366 --> 00:29:25,866
However, the context of
that lipid panel is it has

691
00:29:25,933 --> 00:29:27,266
my name against it.

692
00:29:27,333 --> 00:29:30,099
All of a sudden, it
has meaning to me.

693
00:29:30,166 --> 00:29:31,099
Right?

694
00:29:31,166 --> 00:29:33,666
Otherwise, it's just a
lipid panel of some random

695
00:29:33,733 --> 00:29:36,700
patient who is hitting
50 and got a few issues.

696
00:29:36,766 --> 00:29:39,466
And so I think there is
this combination of data

697
00:29:39,533 --> 00:29:42,332
which is unique to health
care, probably different

698
00:29:42,400 --> 00:29:45,200
than financial services,
although some similarities.

699
00:29:45,266 --> 00:29:47,266
And then statistics is
applied in that and

700
00:29:47,333 --> 00:29:49,133
protection and then we
apply cryptography and

701
00:29:49,200 --> 00:29:50,533
other techniques
to mask the data.

702
00:29:50,599 --> 00:29:52,832
But the number of times I
hear the vendor community,

703
00:29:52,900 --> 00:29:55,566
particularly in the halls
that we have here, tell me

704
00:29:55,633 --> 00:29:58,766
that protecting health
data by masking it, and I

705
00:29:58,833 --> 00:30:00,299
don't see - there's
only two ways to do it.

706
00:30:00,366 --> 00:30:01,900
One is you have a
statistician in your back

707
00:30:01,966 --> 00:30:04,632
pocket and you're working
out on the dataset how to

708
00:30:04,700 --> 00:30:06,900
statistically de-identify
it, and it's particularly

709
00:30:06,966 --> 00:30:10,765
difficult with 3.5 billion
records, or you safe

710
00:30:10,833 --> 00:30:13,433
harbor, which is basically
obliterate all data and

711
00:30:13,500 --> 00:30:14,333
it's useless.

712
00:30:14,400 --> 00:30:17,200
And so in the day of
analytics and health care,

713
00:30:17,266 --> 00:30:19,566
and as a security
professional trying to

714
00:30:19,633 --> 00:30:22,000
enable my colleagues to my
right in terms of the use

715
00:30:22,066 --> 00:30:24,799
of this data, it's a
really difficult problem

716
00:30:24,866 --> 00:30:27,466
to think about,
de-identification, the

717
00:30:27,533 --> 00:30:30,000
application of
cryptography, and then to

718
00:30:30,066 --> 00:30:32,599
the next step, how do we
apply that in genomic data

719
00:30:32,666 --> 00:30:34,265
with 3.5 billion records.

720
00:30:34,333 --> 00:30:37,833
Do I selectively
de-identify within it?

721
00:30:37,900 --> 00:30:39,233
And that's where
the research is.

722
00:30:39,299 --> 00:30:40,799
Can we selectively
do things?

723
00:30:40,866 --> 00:30:43,133
Probably some of the
solutions you are thinking

724
00:30:43,200 --> 00:30:44,900
about in terms of how
do we break this apart.

725
00:30:44,966 --> 00:30:48,166
There's 0.5 - and,
again, I'll defer to

726
00:30:48,233 --> 00:30:49,200
my colleagues here.

727
00:30:49,266 --> 00:30:52,133
There's 0.5% of unique
identification within DNA.

728
00:30:52,200 --> 00:30:52,966
Right?

729
00:30:53,033 --> 00:30:55,899
The majority of
it is sheared.

730
00:30:55,966 --> 00:30:58,699
And so when you think
about that, DNA is humanity.

731
00:30:58,766 --> 00:30:59,900
I mean, I'm
philosophical now.

732
00:30:59,966 --> 00:31:03,733
In a way, yes,
there's some very unique

733
00:31:03,799 --> 00:31:05,166
pieces to the data.

734
00:31:05,233 --> 00:31:07,666
But in my view, only
when combined with other

735
00:31:07,733 --> 00:31:11,399
identifiers and contexts,
and then we have to play

736
00:31:11,466 --> 00:31:14,233
that all out and think
about how do we apply it

737
00:31:14,299 --> 00:31:15,599
from a pragmatic
standpoint in terms of

738
00:31:15,666 --> 00:31:19,633
security and controls and
clearly de-identification

739
00:31:19,700 --> 00:31:23,400
and cryptography is going
to be a key part of that.

740
00:31:23,466 --> 00:31:24,733
>> DR. PATRICK COURNEYA:
There are a couple of

741
00:31:24,799 --> 00:31:26,066
dimensions to that that
I think we should

742
00:31:26,133 --> 00:31:26,866
explore a little.

743
00:31:26,933 --> 00:31:28,500
And maybe I disagree.

744
00:31:28,566 --> 00:31:31,000
First of all, 5% of a very
large number is still a

745
00:31:31,066 --> 00:31:32,733
very large number.

746
00:31:32,799 --> 00:31:33,733
>> MIKE WILSON: Sure.

747
00:31:33,799 --> 00:31:35,333
>> DR. PATRICK COURNEYA:
So we have to acknowledge that.

748
00:31:35,400 --> 00:31:38,166
And we've actually all
heard stories, feel-good

749
00:31:38,233 --> 00:31:41,000
stories, actually, where
somebody who did not

750
00:31:41,066 --> 00:31:43,966
submit knowingly their
genetic information was

751
00:31:44,033 --> 00:31:46,599
actually identified
because someone else

752
00:31:46,666 --> 00:31:48,599
freely shared their
information and that

753
00:31:48,666 --> 00:31:50,799
allowed someone, an
investigator, to

754
00:31:50,866 --> 00:31:52,833
triangulate on
an individual.

755
00:31:52,900 --> 00:31:55,766
You can pretty easily see
scenarios where someone is

756
00:31:55,833 --> 00:31:58,066
very interested in finding
someone who doesn't want

757
00:31:58,133 --> 00:32:01,666
to be found, perhaps a
spouse who is worried

758
00:32:01,733 --> 00:32:05,066
about being found by a
stalker or something like

759
00:32:05,133 --> 00:32:08,733
that, where that information
might be quite valuable.

760
00:32:08,799 --> 00:32:11,866
There you're subjected to
individual identification

761
00:32:11,933 --> 00:32:15,233
even though you didn't
submit your own information.

762
00:32:15,299 --> 00:32:16,599
>> MIKE WILSON: You're
absolutely right.

763
00:32:16,666 --> 00:32:19,299
And just to clarify my
point, this is where

764
00:32:19,366 --> 00:32:20,366
statistics comes in.

765
00:32:20,433 --> 00:32:21,200
>> DR. PATRICK COURNEYA: Yep.

766
00:32:21,266 --> 00:32:22,900
>> MIKE WILSON: So the
statistical technique in

767
00:32:22,966 --> 00:32:28,033
de-identifying data is
this: You have a dataset.

768
00:32:28,099 --> 00:32:30,765
If I take that dataset and
it has a certain set of

769
00:32:30,833 --> 00:32:31,666
markers in it.

770
00:32:31,733 --> 00:32:32,933
Let's keep it simple.

771
00:32:33,000 --> 00:32:36,133
It has an area code.

772
00:32:36,200 --> 00:32:37,400
Okay?

773
00:32:37,466 --> 00:32:39,299
And it has a biomarker.

774
00:32:39,366 --> 00:32:41,633
It doesn't have any other
identifying mark in it.

775
00:32:41,700 --> 00:32:44,166
It doesn't have my
name or anything else.

776
00:32:44,233 --> 00:32:47,700
That area code has
100,000 people.

777
00:32:47,766 --> 00:32:53,133
That biomarker could
be down to ten people.

778
00:32:53,200 --> 00:32:57,533
Is that a statistically
de-identified dataset in

779
00:32:57,599 --> 00:33:02,265
the context of if I go out
- to your point - other

780
00:33:02,333 --> 00:33:04,633
datasets, can I
reconstitute the

781
00:33:04,700 --> 00:33:07,133
likelihood and find out
who those ten people are,

782
00:33:07,200 --> 00:33:09,966
even ringing them
all up potentially?

783
00:33:10,033 --> 00:33:11,233
Potentially.

784
00:33:11,299 --> 00:33:13,500
And so this is a challenge
with the dataset is that

785
00:33:13,566 --> 00:33:14,900
it's not by itself.

786
00:33:14,966 --> 00:33:17,699
It's not just the dataset
sitting in Kaiser.

787
00:33:17,766 --> 00:33:22,000
It's just not the dataset
that's sitting in Molina

788
00:33:22,066 --> 00:33:25,400
or sitting in a pharmacy
or sitting within our DNA

789
00:33:25,466 --> 00:33:27,599
or sitting at 23andMe.

790
00:33:27,666 --> 00:33:29,500
It's all over the place
in different contexts.

791
00:33:29,566 --> 00:33:31,366
You come up with this idea
of longitudinal patient

792
00:33:31,433 --> 00:33:34,099
record, which, again, is a
broader concept, but it's

793
00:33:34,166 --> 00:33:36,599
basically all of your
encounters all through

794
00:33:36,666 --> 00:33:41,000
your life collected up in
one whole medical record,

795
00:33:41,066 --> 00:33:42,666
if you will, including
genomic data and all the

796
00:33:42,733 --> 00:33:44,233
other bits and pieces.

797
00:33:44,299 --> 00:33:45,133
That's the holy grail.

798
00:33:45,200 --> 00:33:46,166
I don't know
where that is.

799
00:33:46,233 --> 00:33:47,666
If somebody can find me
my longitudinal patient

800
00:33:47,733 --> 00:33:50,832
record out there, thank
you, because I don't know

801
00:33:50,900 --> 00:33:51,700
where the hell it is.

802
00:33:51,766 --> 00:33:52,500
Right?

803
00:33:52,566 --> 00:33:53,266
And I'm in the field.

804
00:33:53,333 --> 00:33:54,366
Okay?

805
00:33:54,433 --> 00:33:56,033
The likelihood of
reconstituting data - to

806
00:33:56,099 --> 00:33:57,866
your point - is very
valid, and that's why the

807
00:33:57,933 --> 00:33:59,833
statistics involved
are very complicated.

808
00:33:59,900 --> 00:34:02,200
There's maybe four or five
people in the country,

809
00:34:02,266 --> 00:34:05,700
external exports that we
don't have on our own

810
00:34:05,766 --> 00:34:07,866
payroll potentially,
that you can go to as a

811
00:34:07,933 --> 00:34:10,632
consultant, for instance,
and ask questions around this.

812
00:34:10,699 --> 00:34:11,933
>> RAJEEV CHAND: Do you
believe that data can be

813
00:34:12,000 --> 00:34:15,632
de-identified, health care
data can be de-identified?

814
00:34:15,699 --> 00:34:17,400
>> DR. PATRICK COURNEYA:
I think it's a very real

815
00:34:17,466 --> 00:34:21,366
risk that we have
to guard against.

816
00:34:21,433 --> 00:34:23,366
>> KATHY HIBBS: The point
I would make is I want to

817
00:34:23,433 --> 00:34:25,933
make sure we understand
that that's beyond genetics.

818
00:34:26,000 --> 00:34:28,433
To Patrick's point that
people could use genetic

819
00:34:28,500 --> 00:34:30,666
information to
identify subjects,

820
00:34:30,733 --> 00:34:32,433
that actually happened.

821
00:34:32,500 --> 00:34:36,266
Academic researchers in
medical context actually

822
00:34:36,333 --> 00:34:40,000
identified by name
patients in studies from

823
00:34:40,065 --> 00:34:43,033
no genetic information,
simply from the rarity of

824
00:34:43,099 --> 00:34:45,666
the condition and then
other basic demographic

825
00:34:45,733 --> 00:34:48,133
information that is
included in studies.

826
00:34:48,199 --> 00:34:51,766
Those were largely the age
of the person, the number

827
00:34:51,833 --> 00:34:54,633
of siblings they had, and
the general region that

828
00:34:54,699 --> 00:34:56,699
they lived in, which they
were able to conjecture

829
00:34:56,766 --> 00:34:59,599
that a patient who had
been in a study at

830
00:34:59,666 --> 00:35:02,766
Harvard, et cetera, had to
live somewhere in the New

831
00:35:02,833 --> 00:35:05,366
England area, and then
based on the rarity of the

832
00:35:05,433 --> 00:35:08,666
disease, the age of the
subject in the study, and

833
00:35:08,733 --> 00:35:10,466
the number of siblings
that were reported were

834
00:35:10,533 --> 00:35:14,566
really able to figure out
just from that it's this

835
00:35:14,633 --> 00:35:16,366
family in this
town and they suffer

836
00:35:16,433 --> 00:35:17,900
from this condition.

837
00:35:17,966 --> 00:35:19,299
>> SHARON TERRY: Even
not rare disease.

838
00:35:19,366 --> 00:35:21,400
William Weld was
identified by a woman

839
00:35:21,466 --> 00:35:24,066
named Latonia Sweeney
doing research at Harvard

840
00:35:24,133 --> 00:35:26,665
by his medical record and
his zip code and she used

841
00:35:26,733 --> 00:35:29,566
it as an example to show
we could identify anybody.

842
00:35:29,633 --> 00:35:32,366
If we have more than one
dataset is a critical piece.

843
00:35:32,433 --> 00:35:35,000
>> SHARON TERRY: I think
that there is - there is a

844
00:35:35,066 --> 00:35:38,399
focus on genetics that is
important because I think

845
00:35:38,466 --> 00:35:40,665
that that can help us
identify better ways to

846
00:35:40,733 --> 00:35:43,266
protect the information,
but my concern is if

847
00:35:43,333 --> 00:35:47,000
people don't know this
larger issue, that your

848
00:35:47,066 --> 00:35:49,866
health care data, it's
really important, when I

849
00:35:49,933 --> 00:35:52,300
go to the doctor, that the
doctor has my complete

850
00:35:52,366 --> 00:35:54,233
health care record and
doesn't get it confused

851
00:35:54,300 --> 00:35:55,566
with somebody else.

852
00:35:55,633 --> 00:35:57,866
If you just think about
those situations where you

853
00:35:57,933 --> 00:36:00,000
go to the doctor and you
use a credit card to pay

854
00:36:00,066 --> 00:36:02,799
for your copay, you give
them your health insurance

855
00:36:02,866 --> 00:36:05,733
card that has your
information encoded to

856
00:36:05,800 --> 00:36:08,000
your employer, your Social
Security number, all of

857
00:36:08,066 --> 00:36:10,732
that stuff, it's important
that your health

858
00:36:10,800 --> 00:36:14,699
information be associated
to you and that is all

859
00:36:14,766 --> 00:36:17,866
there included in your
health records because

860
00:36:17,933 --> 00:36:19,966
that's how we make sure
that we're actually using

861
00:36:20,033 --> 00:36:21,866
the right information for
the person that's sitting

862
00:36:21,933 --> 00:36:24,433
in front of us, not just
for a random person who

863
00:36:24,500 --> 00:36:26,733
has a very similar name.

864
00:36:26,800 --> 00:36:29,466
This is perhaps an
opportunity to really make

865
00:36:29,533 --> 00:36:32,799
sure people know that and
set some standards that

866
00:36:32,866 --> 00:36:35,599
can protect all of that
information or better protect.

867
00:36:35,666 --> 00:36:37,733
I don't think there is
anything that's ever going

868
00:36:37,800 --> 00:36:40,199
to be perfect because
you do need it to be

869
00:36:40,266 --> 00:36:42,233
associated to the
individual or it becomes

870
00:36:42,300 --> 00:36:43,599
absolutely useless.

871
00:36:43,666 --> 00:36:47,766
But the narrow focus on
genetics assumes that we

872
00:36:47,833 --> 00:36:49,199
couldn't do this before.

873
00:36:49,266 --> 00:36:52,333
It's been proven that
you can do it from that.

874
00:36:52,400 --> 00:36:53,699
>> RAJEEV CHAND: There was
a great New York Times

875
00:36:53,766 --> 00:36:56,566
article in January this
year which had a very -

876
00:36:56,633 --> 00:36:59,098
these journalists had
access to a very small set

877
00:36:59,166 --> 00:37:01,333
of location data, 50
million data points, and

878
00:37:01,400 --> 00:37:03,733
from these 50 million data
points, they were able to

879
00:37:03,800 --> 00:37:06,599
identify individuals who
were having affairs, they

880
00:37:06,666 --> 00:37:08,699
were able to identify
somebody in the Department

881
00:37:08,766 --> 00:37:12,233
of Defense who was in a
rally in DC with his wife,

882
00:37:12,300 --> 00:37:14,233
they were able to - it was
just amazing what was able

883
00:37:14,300 --> 00:37:16,433
to be done with a kind
of very small amount of

884
00:37:16,500 --> 00:37:19,066
location data that was
critically de-identified.

885
00:37:19,133 --> 00:37:20,533
In about one or two
minutes I'm going to open

886
00:37:20,599 --> 00:37:21,800
it up to the group.

887
00:37:21,866 --> 00:37:24,066
Definitely please come
into either of the aisles

888
00:37:24,133 --> 00:37:25,399
and let's definitely
get all your questions.

889
00:37:25,466 --> 00:37:26,732
Mike, I'm going to ask you
kind of the last set of

890
00:37:26,800 --> 00:37:31,133
questions here, which is
year over year - actually,

891
00:37:31,199 --> 00:37:33,400
how many folks in the
group are from the health

892
00:37:33,466 --> 00:37:34,366
care industry?

893
00:37:34,433 --> 00:37:36,000
You may or may not want to
raise your hand, actually,

894
00:37:36,066 --> 00:37:37,832
given the question
I'm about to ask.

895
00:37:37,900 --> 00:37:39,166
We've got a couple from
the health care industry.

896
00:37:39,233 --> 00:37:41,033
We've got Mike, this is
for you, and then for the

897
00:37:41,099 --> 00:37:42,766
other friends who are in
the health care industry.

898
00:37:42,833 --> 00:37:46,099
Year over year, the
industry with the most

899
00:37:46,166 --> 00:37:50,766
reported breaches is the
health care industry.

900
00:37:50,833 --> 00:37:51,933
>> MIKE WILSON: Yay.

901
00:37:53,666 --> 00:37:56,000
>> RAJEEV CHAND:
Why is that?

902
00:37:56,066 --> 00:37:59,165
>> MIKE WILSON:
Multifaceted question.

903
00:37:59,233 --> 00:38:02,966
The reality is health care
is, although changing,

904
00:38:03,033 --> 00:38:04,866
predominantly small
business in this country.

905
00:38:04,933 --> 00:38:06,099
Okay?

906
00:38:06,166 --> 00:38:09,366
If you think about the
likes of Kaiser, even

907
00:38:09,433 --> 00:38:13,000
Molina, Humana, others,
Health Systems, even the

908
00:38:13,066 --> 00:38:15,533
VA, they have very large
organizations, but there's

909
00:38:15,599 --> 00:38:17,699
probably a dozen, maybe
two dozen in this country

910
00:38:17,766 --> 00:38:21,466
that are of scale at
that sort of size.

911
00:38:21,533 --> 00:38:22,500
That's changing.

912
00:38:22,566 --> 00:38:24,732
The dynamics of that
are changing over time,

913
00:38:24,800 --> 00:38:27,833
similar to perhaps how it
changed, in my view, in

914
00:38:27,900 --> 00:38:28,900
financial services.

915
00:38:28,966 --> 00:38:31,098
I think part of this
is attack surface.

916
00:38:31,166 --> 00:38:32,166
Okay?

917
00:38:32,233 --> 00:38:33,633
It's a simple idea.

918
00:38:33,699 --> 00:38:36,566
But the attack surface in
an ecosystem where we're

919
00:38:36,633 --> 00:38:39,066
reliant on providers
and partners.

920
00:38:39,133 --> 00:38:42,399
An example, Molina has a
network of providers that

921
00:38:42,466 --> 00:38:43,299
we work with.

922
00:38:43,366 --> 00:38:44,566
It's a little bit of a
different model than perhaps

923
00:38:44,633 --> 00:38:46,966
a Kaiser model, although
there are some similarities.

924
00:38:47,033 --> 00:38:52,199
And so in that situation,
we manage the outcomes of

925
00:38:52,266 --> 00:38:55,133
our members through
partnerships, through

926
00:38:55,199 --> 00:38:58,866
contracts with providers,
the local hospital in a

927
00:38:58,933 --> 00:39:00,033
particular setting
or whatever.

928
00:39:00,099 --> 00:39:03,400
It's a little challenging.

929
00:39:03,466 --> 00:39:04,366
>> RAJEEV CHAND: It
could be attack -

930
00:39:04,433 --> 00:39:05,266
>> MIKE WILSON: Relying
on that attack surface.

931
00:39:05,333 --> 00:39:06,133
Sorry.

932
00:39:06,199 --> 00:39:07,033
>> RAJEEV CHAND: It
could be attack surface.

933
00:39:07,099 --> 00:39:08,099
>> MIKE WILSON: Right.

934
00:39:08,166 --> 00:39:09,266
>> RAJEEV CHAND: There's
a fragmented ecosystem,

935
00:39:09,333 --> 00:39:10,900
information needs to get
shared very fluidly for

936
00:39:10,966 --> 00:39:12,366
both clinical and billing
purposes, it could

937
00:39:12,433 --> 00:39:13,366
be attack surface.

938
00:39:13,433 --> 00:39:14,366
>> MIKE WILSON: Correct.

939
00:39:14,433 --> 00:39:16,233
Attack surface is
probably, in my view, one

940
00:39:16,300 --> 00:39:17,166
of the biggest areas.

941
00:39:17,233 --> 00:39:18,466
I think you're seeing a
lot of what you'd call

942
00:39:18,533 --> 00:39:20,333
sort of third-party breaches.

943
00:39:20,400 --> 00:39:22,900
We're all somebody's
third-party, I guess.

944
00:39:22,966 --> 00:39:26,500
But that's the
predominant issue.

945
00:39:26,566 --> 00:39:28,466
And then the other piece
of it is I think it does

946
00:39:28,533 --> 00:39:30,732
come a little bit more to
the granularity of the

947
00:39:30,800 --> 00:39:31,733
data itself.

948
00:39:31,800 --> 00:39:34,300
There is this sort of
construct - and, again,

949
00:39:34,366 --> 00:39:36,566
it's sort of more of a
legal privacy construct

950
00:39:36,633 --> 00:39:38,466
around this idea of
covered entities and

951
00:39:38,533 --> 00:39:40,833
business associates and
all this sort of thing.

952
00:39:40,900 --> 00:39:42,199
But at the end of
the day, it comes down

953
00:39:42,266 --> 00:39:43,000
to fit for purpose.

954
00:39:43,066 --> 00:39:45,098
There are some basic
questions that I ask

955
00:39:45,166 --> 00:39:47,166
around, okay, so we're
going to move some data

956
00:39:47,233 --> 00:39:49,666
for very good reason
to a provider.

957
00:39:49,733 --> 00:39:51,699
Why are we doing that and
how much do they need?

958
00:39:51,766 --> 00:39:53,666
That's sort of a privacy
question, too, but it

959
00:39:53,733 --> 00:39:56,166
speaks to security in
terms of, well, if I can

960
00:39:56,233 --> 00:39:58,066
minimize the attack
surface of the data I'm

961
00:39:58,133 --> 00:40:00,098
dealing with, then it's
less I have to protect.

962
00:40:00,166 --> 00:40:02,099
It's simple. Right?

963
00:40:02,166 --> 00:40:03,000
>> RAJEEV CHAND: Awesome.

964
00:40:03,066 --> 00:40:04,265
So, first question, name
and company and then your

965
00:40:04,333 --> 00:40:05,800
question very briefly.

966
00:40:05,866 --> 00:40:06,633
>> GARRRETT SCHUMACHER: Hi.

967
00:40:06,699 --> 00:40:08,800
Garrett Schumacher,
CTO of Geneinfosec.

968
00:40:08,866 --> 00:40:10,766
So, first of all, I'd like
to clarify that genetic

969
00:40:10,833 --> 00:40:13,033
data alone is
identifiable, as was the

970
00:40:13,099 --> 00:40:14,433
case with the
Golden State Killer.

971
00:40:14,500 --> 00:40:17,233
If a BuzzFeed reporter
with no genetics or

972
00:40:17,300 --> 00:40:19,933
statistics background can
identify colleagues based

973
00:40:20,000 --> 00:40:24,333
on DNA alone, then
most people can do it.

974
00:40:24,400 --> 00:40:28,199
My question is: When
it comes to genetic

975
00:40:28,266 --> 00:40:29,966
de-identification, I have
my own opinions, but do

976
00:40:30,033 --> 00:40:32,500
you think it's actually
possible to de-identify,

977
00:40:32,566 --> 00:40:35,133
and what methods are you
taking, what precautions,

978
00:40:35,199 --> 00:40:37,000
therefore, are you taking?

979
00:40:37,066 --> 00:40:38,332
>> KATHY HIBBS: I'll
answer that because I

980
00:40:38,400 --> 00:40:39,699
think it's probably
directed at me.

981
00:40:39,766 --> 00:40:40,366
A couple of things.

982
00:40:40,433 --> 00:40:42,933
It wasn't genetic
information alone.

983
00:40:43,000 --> 00:40:46,500
It was genetic information
plus basically ancestry

984
00:40:46,566 --> 00:40:48,232
records and family trees.

985
00:40:48,300 --> 00:40:50,800
They didn't go like we
have the genetic profile of

986
00:40:50,866 --> 00:40:53,033
the Golden State Killer -
they'd had that for 30

987
00:40:53,099 --> 00:40:56,500
years from the rapes and
killings - and identify them.

988
00:40:56,566 --> 00:40:58,899
If it was that easy, the
police would not have any

989
00:40:58,966 --> 00:41:01,066
unsolved genetic cases.

990
00:41:01,133 --> 00:41:02,466
>> RAJEEV CHAND: But
genetic data was the -

991
00:41:02,533 --> 00:41:05,333
kind of the tipping point,
the important sort of

992
00:41:05,400 --> 00:41:08,866
predica to the Golden
State Killer's identification.

993
00:41:08,933 --> 00:41:09,866
>> KATHY HIBBS:
I would say not.

994
00:41:09,933 --> 00:41:11,500
They had the sample
from the crime scene.

995
00:41:11,566 --> 00:41:15,665
It was plugging it into
a database, which is a

996
00:41:15,733 --> 00:41:17,866
publicly available
database where people put

997
00:41:17,933 --> 00:41:20,366
their information and
build out family trees.

998
00:41:20,433 --> 00:41:24,400
It was this genetic
profile as a degree

999
00:41:24,466 --> 00:41:28,098
related to this other
profile and they've built

1000
00:41:28,166 --> 00:41:30,933
out a family tree from
publicly available

1001
00:41:31,000 --> 00:41:34,066
marriage, birth, death
records, and that's how

1002
00:41:34,133 --> 00:41:35,732
the identity was
actually done.

1003
00:41:35,800 --> 00:41:37,733
It's a perfect example
of a situation where the

1004
00:41:37,800 --> 00:41:41,433
genetic information alone
at this point in time is

1005
00:41:41,500 --> 00:41:43,833
not able to
identify the person.

1006
00:41:43,900 --> 00:41:46,599
I think the issue there as
well, and this is why we

1007
00:41:46,666 --> 00:41:49,633
have a transparency
report, we don't and never

1008
00:41:49,699 --> 00:41:51,933
have given information
to the police.

1009
00:41:52,000 --> 00:41:53,666
There are some legal
challenges that would

1010
00:41:53,733 --> 00:41:56,566
exist in terms of the
police getting records

1011
00:41:56,633 --> 00:41:58,633
from a company like ours
because there is no

1012
00:41:58,699 --> 00:42:02,300
evidence - we don't know
that a customer actually

1013
00:42:02,366 --> 00:42:03,233
spat in the tube.

1014
00:42:03,300 --> 00:42:05,099
There's no chain of
control, if you will.

1015
00:42:05,166 --> 00:42:09,099
Actually, that lack of
identity that exists is

1016
00:42:09,166 --> 00:42:11,800
better protected in a
consumer situation than it

1017
00:42:11,866 --> 00:42:13,266
is in a health
care situation.

1018
00:42:13,333 --> 00:42:15,166
The other thing that's
really important that

1019
00:42:15,233 --> 00:42:19,599
people understand is the
police use medical samples

1020
00:42:19,666 --> 00:42:21,133
and medical records now.

1021
00:42:21,199 --> 00:42:25,033
The BTK killer, the serial
killer in Kansas City, was

1022
00:42:25,099 --> 00:42:28,033
identified using his
daughter's pap smear

1023
00:42:28,099 --> 00:42:32,000
sample that was accessed
by the police at the

1024
00:42:32,066 --> 00:42:34,899
hospital where her pap
smear had been on file

1025
00:42:34,966 --> 00:42:35,766
for five years.

1026
00:42:35,833 --> 00:42:39,166
Again, that's a situation
where I think because of

1027
00:42:39,233 --> 00:42:42,733
the amount of hype in the
press and the lack of a

1028
00:42:42,800 --> 00:42:46,233
greater understanding
about, for example, the

1029
00:42:46,300 --> 00:42:48,300
fact that there were
genealogy records that

1030
00:42:48,366 --> 00:42:51,699
were used or the fact
that medical samples and

1031
00:42:51,766 --> 00:42:53,933
medical information has
been used in a criminal

1032
00:42:54,000 --> 00:42:57,199
context as well, we're
kind of touching the surface.

1033
00:42:57,266 --> 00:42:59,766
It's a really important
issue, but we're kind of

1034
00:42:59,833 --> 00:43:02,733
touching the surface and
leaving undiscussed kind

1035
00:43:02,800 --> 00:43:04,599
of the larger information.

1036
00:43:04,666 --> 00:43:05,599
>> RAJEEV CHAND: What
you're saying is it's

1037
00:43:05,666 --> 00:43:06,433
not just genomics.

1038
00:43:06,500 --> 00:43:07,433
>> KATHY HIBBS: It's not
just genomics and it's

1039
00:43:07,500 --> 00:43:09,166
certainly not just
consumer genomics.

1040
00:43:09,233 --> 00:43:10,800
>> MIKE WILSON: And just
to chime in very quickly,

1041
00:43:10,866 --> 00:43:13,766
yes, you can, but you'll
eradicate the data.

1042
00:43:13,833 --> 00:43:15,266
You obfuscate
it completely.

1043
00:43:15,333 --> 00:43:16,333
That's safe harbor.

1044
00:43:16,400 --> 00:43:17,566
And I guess if you apply
that to the medical

1045
00:43:17,633 --> 00:43:19,765
record, you might
determine an outcome or a

1046
00:43:19,833 --> 00:43:21,800
biomarker and then
eradicate all the source.

1047
00:43:21,866 --> 00:43:24,866
I'm not sure why you'd do
that, but you would or could.

1048
00:43:24,933 --> 00:43:27,333
And if you did that,
then effectively it's

1049
00:43:27,400 --> 00:43:29,166
de-identified completely.

1050
00:43:29,233 --> 00:43:31,199
De-identification,
though, as a term is

1051
00:43:31,266 --> 00:43:32,233
misunderstood.

1052
00:43:32,300 --> 00:43:34,233
It doesn't mean that it's
completely obfuscated.

1053
00:43:34,300 --> 00:43:36,366
It means it's
statistically low

1054
00:43:36,433 --> 00:43:38,266
likelihood of
reconstitution of the data.

1055
00:43:38,333 --> 00:43:41,300
I think that then is
determined by an expert

1056
00:43:41,366 --> 00:43:44,300
when it's generally viewed
in the 1-1.5% range is

1057
00:43:44,366 --> 00:43:45,833
what we use in
the industry.

1058
00:43:45,900 --> 00:43:46,800
>> RAJEEV CHAND: Pat, real
quick, then I'm going to

1059
00:43:46,866 --> 00:43:48,000
jump to the next question.

1060
00:43:48,066 --> 00:43:49,232
>> DR. PATRICK COURNEYA:
Just real quick.

1061
00:43:49,300 --> 00:43:51,466
That's a really nice
explanation of the detail

1062
00:43:51,533 --> 00:43:53,699
behind what happened
in that circumstance.

1063
00:43:53,766 --> 00:43:56,900
That will get lost when it
comes to individuals who

1064
00:43:56,966 --> 00:43:59,098
are wondering whether or
not or deciding whether

1065
00:43:59,166 --> 00:44:01,633
they should trust a
system with their data.

1066
00:44:01,699 --> 00:44:02,966
That's probably
the biggest.

1067
00:44:03,033 --> 00:44:08,433
And if they step back from
sharing that data and lose

1068
00:44:08,500 --> 00:44:10,533
the opportunity that we
discussed earlier to have

1069
00:44:10,599 --> 00:44:12,433
an impact on their
health, that will be

1070
00:44:12,500 --> 00:44:14,133
a significant loss.

1071
00:44:14,199 --> 00:44:17,633
And so I think we have to
take into account also the

1072
00:44:17,699 --> 00:44:20,233
fact that something that
is statistically very

1073
00:44:20,300 --> 00:44:22,599
unlikely, with the
computing power that's

1074
00:44:22,666 --> 00:44:24,800
available out there
now, it's actually

1075
00:44:24,866 --> 00:44:28,133
statistically
possible, doable.

1076
00:44:28,199 --> 00:44:29,133
>> RAJEEV CHAND: Awesome.

1077
00:44:29,199 --> 00:44:31,599
Name, name company, and
then very quick question.

1078
00:44:31,666 --> 00:44:32,566
>> DR. THORNSUND:
Dr. Thornsund,

1079
00:44:32,633 --> 00:44:34,232
physician, researcher.

1080
00:44:34,300 --> 00:44:38,300
Epigenetics, genomics
is going vertical.

1081
00:44:38,366 --> 00:44:39,633
Please, more data.

1082
00:44:39,699 --> 00:44:42,666
What I do worry about
is not the individual.

1083
00:44:42,733 --> 00:44:45,633
I worry about the
population and state actors.

1084
00:44:45,699 --> 00:44:47,599
It won't be long before
you'll be able to profile

1085
00:44:47,666 --> 00:44:50,699
an entire population and
look for vulnerabilities

1086
00:44:50,766 --> 00:44:54,733
within it which could be
useful for antagonistic

1087
00:44:54,800 --> 00:44:56,633
state actors.

1088
00:44:56,699 --> 00:44:58,300
How do we - are we
worried about that, or

1089
00:44:58,366 --> 00:45:00,699
is it unavoidable?

1090
00:45:00,766 --> 00:45:01,633
>> SHARON TERRY: Yeah.

1091
00:45:01,699 --> 00:45:03,133
I think we worry
a lot about that.

1092
00:45:03,199 --> 00:45:04,933
I don't know if it's
unavoidable or not.

1093
00:45:05,000 --> 00:45:06,733
But I think what at least
we're doing is saying to

1094
00:45:06,800 --> 00:45:09,166
various communities, like
Native Americans in the

1095
00:45:09,233 --> 00:45:12,066
U.S. or various countries
that are worried about this

1096
00:45:12,133 --> 00:45:13,832
might happen to them if
they don't start to take

1097
00:45:13,900 --> 00:45:16,133
control themselves, is
what tools can we put in

1098
00:45:16,199 --> 00:45:19,400
place to limit the access
to that information.

1099
00:45:19,466 --> 00:45:21,266
Back to the
de-identification point.

1100
00:45:21,333 --> 00:45:24,000
We can't de-identify
the genome ultimately

1101
00:45:24,066 --> 00:45:27,698
perfectly, but we can
limit access and have the

1102
00:45:27,766 --> 00:45:30,066
people themselves be in
control of those things.

1103
00:45:30,133 --> 00:45:32,399
That said, that is
probably my primary

1104
00:45:32,466 --> 00:45:35,000
concern around genomics
is that whole populations

1105
00:45:35,066 --> 00:45:38,198
will be mischaracterized,
that bad actors and states

1106
00:45:38,266 --> 00:45:40,500
can do it, and we see
it in our country in a

1107
00:45:40,566 --> 00:45:43,198
variety of ways already,
not using genomics per se,

1108
00:45:43,266 --> 00:45:45,766
but certainly that could
start to become part of

1109
00:45:45,833 --> 00:45:49,266
somebody's philosophy
and thought pattern.

1110
00:45:49,333 --> 00:45:54,633
>> RAJEEV CHAND: Sharon's
based in D.C. Great question.

1111
00:45:54,699 --> 00:45:55,633
Next question.

1112
00:45:55,699 --> 00:45:56,900
Name, company, and
very brief question.

1113
00:45:56,966 --> 00:45:59,299
>> CALEB BARLOW: Caleb
Barlow, CEO Cynergistek.

1114
00:45:59,366 --> 00:46:01,766
We're certainly in a
world where nation state

1115
00:46:01,833 --> 00:46:04,199
adversaries, as this
audience will understand,

1116
00:46:04,266 --> 00:46:05,533
are after genomic data.

1117
00:46:05,599 --> 00:46:07,166
They've put it right in
their five-year plan.

1118
00:46:07,233 --> 00:46:09,233
They're actively out,
sending the police out to

1119
00:46:09,300 --> 00:46:10,833
gather genomic
data on individuals,

1120
00:46:10,900 --> 00:46:12,199
and they'll steal it.

1121
00:46:12,266 --> 00:46:13,566
In fact, probably a third
of the people in this room

1122
00:46:13,633 --> 00:46:15,832
have had their health
care records stolen.

1123
00:46:15,900 --> 00:46:18,366
But let's talk about the
legitimate side of this

1124
00:46:18,433 --> 00:46:20,699
because what I think is so
fascinating when we're up

1125
00:46:20,766 --> 00:46:23,166
against the nation state
actors, not only can they

1126
00:46:23,233 --> 00:46:25,633
steal data and get it
nefariously, but they can

1127
00:46:25,699 --> 00:46:27,466
invest in all of your
companies, which they've

1128
00:46:27,533 --> 00:46:29,500
done in several
of you on stage.

1129
00:46:29,566 --> 00:46:32,033
It's pretty hard to find a
genomic testing company, a

1130
00:46:32,099 --> 00:46:34,900
DNA sequencer, or a
laboratory that doesn't

1131
00:46:34,966 --> 00:46:38,732
have some tentacles to
Chinese venture capital.

1132
00:46:38,800 --> 00:46:41,400
How do we deal with that?

1133
00:46:41,466 --> 00:46:43,500
>> KATHY HIBBS: Well, I
think, at the moment, that

1134
00:46:43,566 --> 00:46:48,133
is something that CFIUS,
which is a federal agency

1135
00:46:48,199 --> 00:46:51,900
that looks at the actual
international investment,

1136
00:46:51,966 --> 00:46:54,098
is really taking
a hard line on.

1137
00:46:54,166 --> 00:46:56,466
And so that is something
that in the last several

1138
00:46:56,533 --> 00:46:57,933
years has really reduced.

1139
00:46:58,000 --> 00:47:00,699
And there actually have
been several transactions

1140
00:47:00,766 --> 00:47:03,533
even that were actually
completed and then the

1141
00:47:03,599 --> 00:47:06,466
government actually forced
a disgorgement of the

1142
00:47:06,533 --> 00:47:08,966
asset because of the
concern about that.

1143
00:47:09,033 --> 00:47:12,000
It's something that,
frankly, our CEO said

1144
00:47:12,066 --> 00:47:14,433
several, several years
ago, told people in

1145
00:47:14,500 --> 00:47:17,233
D.C. that they needed
to be concerned about

1146
00:47:17,300 --> 00:47:18,400
this exact issue.

1147
00:47:18,466 --> 00:47:21,533
There are some other
things, though, at the moment.

1148
00:47:21,599 --> 00:47:22,900
>> RAJEEV CHAND: 23andMe
has a Chinese venture

1149
00:47:22,966 --> 00:47:23,799
capitalist or not?

1150
00:47:23,866 --> 00:47:25,766
>> KATHY HIBBS: We have a
tiny - we have a small,

1151
00:47:25,833 --> 00:47:26,699
small fraction.

1152
00:47:26,766 --> 00:47:28,933
We have - so there's -
and we haven't taken any

1153
00:47:29,000 --> 00:47:31,633
Chinese money
recently at all.

1154
00:47:31,699 --> 00:47:35,000
But we have a small
investor in a prior - in

1155
00:47:35,066 --> 00:47:37,198
an old round of a few
hundred thousand dollars.

1156
00:47:37,266 --> 00:47:40,000
We don't have significant
Chinese ownership.

1157
00:47:40,066 --> 00:47:41,098
>> RAJEEV CHAND:
Really good question.

1158
00:47:41,166 --> 00:47:42,933
Name, title, and then
very brief question.

1159
00:47:43,000 --> 00:47:44,366
We're going to run
out of time here.

1160
00:47:44,433 --> 00:47:45,300
>> SHAWN RAY: Shawn Ray.

1161
00:47:45,366 --> 00:47:48,033
I'm a VP at government
programs at Cirdees Networks.

1162
00:47:48,099 --> 00:47:50,466
We're a crypto company.

1163
00:47:50,533 --> 00:47:54,433
I was a member 20 years
ago of the Consumer

1164
00:47:54,500 --> 00:47:56,766
Privacy Exchange
Consortium where we were

1165
00:47:56,833 --> 00:47:58,900
trying to say, hey, all
these websites are coming

1166
00:47:58,966 --> 00:48:01,799
up, all this stuff is going
online, all your CRN data.

1167
00:48:01,866 --> 00:48:04,800
What turned out was
basically the government

1168
00:48:04,866 --> 00:48:07,900
and some other programs
tried to fight off this

1169
00:48:07,966 --> 00:48:09,566
and say you
have to do this.

1170
00:48:09,633 --> 00:48:12,633
But in the news, it says,
oh, yeah, this privacy,

1171
00:48:12,699 --> 00:48:14,466
you should be
worried about it.

1172
00:48:14,533 --> 00:48:16,299
But one of the more
interesting things is how

1173
00:48:16,366 --> 00:48:18,500
do you keep getting the
services that you need if

1174
00:48:18,566 --> 00:48:20,966
you say no? Right?

1175
00:48:21,033 --> 00:48:22,500
We talk about you have
the right to sign this

1176
00:48:22,566 --> 00:48:24,399
document, or you have
the right to do this.

1177
00:48:24,466 --> 00:48:26,366
But in all reality,
anybody who lives in

1178
00:48:26,433 --> 00:48:28,500
California and is here
today and gets on a

1179
00:48:28,566 --> 00:48:30,500
website and says, hey, we
use cookies, you want to do

1180
00:48:30,566 --> 00:48:33,299
the next page, it's the
same thing in the health field.

1181
00:48:33,366 --> 00:48:36,400
I just finished going to
five different of the

1182
00:48:36,466 --> 00:48:38,433
leading cancer
centers in America.

1183
00:48:38,500 --> 00:48:40,800
If you don't sign and say
we can do whatever we want

1184
00:48:40,866 --> 00:48:43,500
with your tissue samples
or with your stuff, we're

1185
00:48:43,566 --> 00:48:44,198
not going to help you.

1186
00:48:44,266 --> 00:48:45,266
Go home.

1187
00:48:45,333 --> 00:48:47,300
>> RAJEEV CHAND: Yeah.
Awesome. Great question.

1188
00:48:47,366 --> 00:48:48,333
>> SHARON TERRY: Yeah.

1189
00:48:48,400 --> 00:48:49,800
That concerns me a great
deal as well because I

1190
00:48:49,866 --> 00:48:51,966
think, both on the
clinical side and that we

1191
00:48:52,033 --> 00:48:54,098
do want research to
continue, we need to

1192
00:48:54,166 --> 00:48:55,933
figure out how to
balance those two things.

1193
00:48:56,000 --> 00:48:58,699
I would love to see better
consumer pressure, though,

1194
00:48:58,766 --> 00:49:01,533
on opening up the black
box that is those medical

1195
00:49:01,599 --> 00:49:03,866
centers and what they do
do with the data and the

1196
00:49:03,933 --> 00:49:05,466
fact that they are
selling it and they're

1197
00:49:05,533 --> 00:49:06,433
not telling anyone.

1198
00:49:06,500 --> 00:49:09,133
That sort of stuff to be
clearer and not as black

1199
00:49:09,199 --> 00:49:12,133
box would make it better
in terms of - at least in

1200
00:49:12,199 --> 00:49:13,133
terms of what I see.

1201
00:49:13,199 --> 00:49:14,733
But you're absolutely
right that I think most

1202
00:49:14,800 --> 00:49:17,000
people, particularly if
they're not well, will go

1203
00:49:17,066 --> 00:49:19,799
right past whatever it
says and give their data

1204
00:49:19,866 --> 00:49:20,699
to whomever.

1205
00:49:20,766 --> 00:49:23,933
I have an example of
taking my Facebook page

1206
00:49:24,000 --> 00:49:26,166
for the disease my kids
have, 4,000 people, and

1207
00:49:26,233 --> 00:49:28,133
saying we're going to
shut it down tomorrow,

1208
00:49:28,199 --> 00:49:30,300
Cambridge Analytica
happened, this is really

1209
00:49:30,366 --> 00:49:32,466
awful, look at the Chinese
government is doing blah,

1210
00:49:32,533 --> 00:49:34,866
blah, blah, and to
a person, all 4,000

1211
00:49:34,933 --> 00:49:37,199
consented again to say
we're staying here.

1212
00:49:37,266 --> 00:49:39,433
It's the only way, in this
rare disease, we see each

1213
00:49:39,500 --> 00:49:41,266
other across the world.

1214
00:49:41,333 --> 00:49:43,233
I think it's up to those
of us who are leading to

1215
00:49:43,300 --> 00:49:45,000
figure out how
do we change.

1216
00:49:45,066 --> 00:49:48,732
I appeal to the CEOs and
the heads of the major

1217
00:49:48,800 --> 00:49:51,500
medical centers to start
to reveal more about what

1218
00:49:51,566 --> 00:49:53,533
they're doing, what is
their business that Google

1219
00:49:53,599 --> 00:49:56,033
and Ascension is
happening, that patients

1220
00:49:56,099 --> 00:49:58,599
like me have been invested
in by the Chinese, that

1221
00:49:58,666 --> 00:50:01,266
that be revealed by the
people that are the

1222
00:50:01,333 --> 00:50:04,500
leaders themselves and not
by some government agency

1223
00:50:04,566 --> 00:50:07,299
coming in and
clapping down on them.

1224
00:50:07,366 --> 00:50:08,366
>> KATHY HIBBS: Yeah.

1225
00:50:08,433 --> 00:50:09,766
>> RAJEEV CHAND: That is a
fantastic close to the session.

1226
00:50:09,833 --> 00:50:11,666
I'd like to very much
thank everyone in the

1227
00:50:11,733 --> 00:50:14,766
group here as well as our
four esteemed speakers,

1228
00:50:14,833 --> 00:50:17,933
Dr. Patrick Courneya,
Kathy Hibbs, Sharon Terry,

1229
00:50:18,000 --> 00:50:19,000
and Mike Wilson.

1230
00:50:19,066 --> 00:50:21,066
Thank you all for
exploring this space.

