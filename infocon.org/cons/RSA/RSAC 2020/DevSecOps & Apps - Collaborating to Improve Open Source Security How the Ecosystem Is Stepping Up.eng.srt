1
00:00:06,099 --> 00:00:09,333
>> ANNOUNCER: Please
welcome Mark Russinovich.

2
00:00:15,500 --> 00:00:16,866
>> MARK RUSSINOVICH:
Good morning, everybody.

3
00:00:16,933 --> 00:00:18,066
Good morning, everybody.

4
00:00:18,133 --> 00:00:19,133
Try that again.

5
00:00:19,199 --> 00:00:20,399
Thanks for coming.

6
00:00:20,466 --> 00:00:22,899
It is Friday morning, a long
week here at RSA conference.

7
00:00:22,966 --> 00:00:24,666
My name is Mark Russinovich.

8
00:00:24,733 --> 00:00:29,600
I'm the Chief Technology Officer
of Microsoft Azure, and I'm here

9
00:00:29,666 --> 00:00:33,866
to talk about -- let's see if I
can make the slide go back here.

10
00:00:36,366 --> 00:00:38,833
About -- okay, title
slide is missing.

11
00:00:38,899 --> 00:00:42,733
I'm here to talk about
open source security.

12
00:00:42,799 --> 00:00:46,966
That might seem an odd thing
to some of you for a Microsoft

13
00:00:47,033 --> 00:00:49,233
person to be coming up here to
talk about open source security,

14
00:00:49,299 --> 00:00:52,066
those of you that haven't been
watching what Microsoft has been

15
00:00:52,133 --> 00:00:53,733
doing with open source security.

16
00:00:54,533 --> 00:00:57,066
Microsoft, for those of you that
haven't been paying attention,

17
00:00:57,133 --> 00:00:59,899
is deeply an open source
company at this point.

18
00:00:59,966 --> 00:01:03,566
But then how does that
relate to me being the CTO of

19
00:01:03,633 --> 00:01:04,633
Microsoft Azure?

20
00:01:04,700 --> 00:01:06,866
Why am I here to talk
about open source security?

21
00:01:06,933 --> 00:01:10,633
The reason is that when we take
a look at Azure as a Cloud

22
00:01:10,700 --> 00:01:14,500
platform, a ton of it is
built on top of open source.

23
00:01:14,566 --> 00:01:16,099
We consume open source.

24
00:01:16,166 --> 00:01:18,966
We also publish open source.

25
00:01:19,033 --> 00:01:23,533
And so when you think about the
Cloud provider's responsibility

26
00:01:23,599 --> 00:01:27,033
to our customers, they don't
really care what we build our

27
00:01:27,099 --> 00:01:28,500
platform on.

28
00:01:28,566 --> 00:01:30,433
What they care about is that
we're keeping them secure.

29
00:01:30,500 --> 00:01:34,666
And that means that with
whatever we use to build that

30
00:01:34,733 --> 00:01:36,599
platform, the buck
stops with us.

31
00:01:36,666 --> 00:01:39,866
If there is a problem in our
own software that we create

32
00:01:39,933 --> 00:01:43,200
internally or a software that
we're consuming or a hardware

33
00:01:43,266 --> 00:01:47,666
we're consuming from third
parties, if there is a problem,

34
00:01:47,733 --> 00:01:51,266
customers expect us to deal
with it and keep them secure.

35
00:01:51,333 --> 00:01:54,966
And so this is very near and
dear to my heart in terms of

36
00:01:55,033 --> 00:01:58,099
what can we do to make
Azure more secure.

37
00:01:58,166 --> 00:02:01,298
It leads into the supply
chain of Azure, which includes

38
00:02:01,366 --> 00:02:04,366
open source.

39
00:02:04,433 --> 00:02:09,099
I'm also here because the
COVID-19 thing hasn't gotten too

40
00:02:09,166 --> 00:02:13,233
crazy yet, so I thought I'd
show up today and risk it.

41
00:02:13,300 --> 00:02:20,033
But imagine a world where a
hugely popular open source

42
00:02:20,099 --> 00:02:25,533
package gets compromised and
people are consuming it and

43
00:02:25,599 --> 00:02:30,000
deploying it and operating
it and the world becomes

44
00:02:30,066 --> 00:02:33,300
compromised because of this
open source dependency.

45
00:02:33,366 --> 00:02:38,400
It sounds like something that is
theoretical, but, in fact, it

46
00:02:38,466 --> 00:02:41,266
has happened and it's happened
multiple times and it continues

47
00:02:41,333 --> 00:02:42,466
to happen.

48
00:02:42,533 --> 00:02:46,632
These are just some of the
examples of open source being

49
00:02:46,699 --> 00:02:48,699
compromised and then
being consumed in that

50
00:02:48,766 --> 00:02:50,099
compromised state.

51
00:02:50,166 --> 00:02:51,433
Some of you might
have seen these.

52
00:02:51,500 --> 00:02:53,133
These are both from
the last two years.

53
00:02:53,199 --> 00:02:58,166
Webmin, an incredibly popular
web portal administration

54
00:02:58,233 --> 00:03:04,000
toolkit, this was compromised
for a whole year with a DDoS

55
00:03:04,066 --> 00:03:06,666
backdoor and a credential
stealing backdoor.

56
00:03:06,733 --> 00:03:11,066
It allowed an attacker to get
into the web server that's being

57
00:03:11,133 --> 00:03:15,300
managed by this thing and deploy
arbitrary software onto it.

58
00:03:15,366 --> 00:03:18,233
Downloaded a million times
during that year that it

59
00:03:18,300 --> 00:03:18,900
was compromised.

60
00:03:18,966 --> 00:03:21,500
Rest-client.

61
00:03:21,566 --> 00:03:27,199
This is a package that a lot of
developers used to authenticate

62
00:03:27,266 --> 00:03:29,833
to rest APIs.

63
00:03:29,900 --> 00:03:34,199
This was backdoored to steal the
credentials that came as part of

64
00:03:34,266 --> 00:03:35,333
that authentication.

65
00:03:35,400 --> 00:03:45,333
Event-Stream, a package that was
downloaded 1,000 times or 1,500

66
00:03:45,400 --> 00:03:46,699
times a week.

67
00:03:46,766 --> 00:03:49,198
This thing was backdoored.

68
00:03:49,266 --> 00:03:52,433
And then finally, VestaCP,
another control panel platform

69
00:03:52,500 --> 00:03:55,966
for managing websites, this was
backdoored in a source control

70
00:03:56,033 --> 00:04:00,333
system and also served as a DDoS
malware distribution platform

71
00:04:00,400 --> 00:04:03,333
for the attackers
that got into it.

72
00:04:03,400 --> 00:04:05,099
These are all examples,
and there are many more.

73
00:04:05,099 --> 00:04:08,766
Here is an example of one
timeline for a very popular open

74
00:04:08,833 --> 00:04:11,099
source package
called Boostrap-sass.

75
00:04:11,166 --> 00:04:13,666
This package has been
downloaded in its lifetime

76
00:04:13,733 --> 00:04:14,699
28 million times.

77
00:04:14,766 --> 00:04:16,033
It was compromised
you see on this date.

78
00:04:16,100 --> 00:04:22,733
The package was compromised in
the MPM repository -- in Ruby.

79
00:04:22,800 --> 00:04:23,833
Sorry, it's a Ruby package.

80
00:04:23,899 --> 00:04:27,566
It was compromised by an
attacker, the package, that got

81
00:04:27,633 --> 00:04:33,433
control of it, removed the last
good one, and then published one

82
00:04:33,500 --> 00:04:36,866
that had an exploit in it.

83
00:04:36,933 --> 00:04:40,733
And you can see that at the time
that it was discovered, at that

84
00:04:40,800 --> 00:04:43,699
point, there was no last known
good to fall back on because

85
00:04:43,766 --> 00:04:45,600
they'd removed it.

86
00:04:45,666 --> 00:04:50,199
And so at this point, the
Ruby package management was

87
00:04:50,266 --> 00:04:53,266
scrambling to figure out how to
get people that knew that they

88
00:04:53,333 --> 00:04:56,766
were compromised to get back
into a secure state and a good

89
00:04:56,833 --> 00:04:58,300
one was eventually published.

90
00:04:58,366 --> 00:05:02,300
But you can see a total of
eight days where really anybody

91
00:05:02,366 --> 00:05:06,532
dependent on the upstream Ruby
package management system was in

92
00:05:06,600 --> 00:05:09,199
a state where they couldn't get
fixed if they downloaded the

93
00:05:09,266 --> 00:05:10,100
vulnerable package.

94
00:05:12,733 --> 00:05:18,866
Event-Stream is an interesting
one because this one has a story

95
00:05:18,933 --> 00:05:22,433
where it shows us we're so
dependent on people that we

96
00:05:22,500 --> 00:05:25,533
don't know producing the
software that we consume.

97
00:05:25,600 --> 00:05:29,366
In the case of Event-Stream, the
maintainer for this Event-Stream

98
00:05:29,433 --> 00:05:32,033
package -- like I said, it's
incredibly popular - just felt

99
00:05:32,100 --> 00:05:33,533
he didn't have time to
maintain it anymore.

100
00:05:33,600 --> 00:05:36,399
He got emailed by somebody
saying, hey, you know what, I

101
00:05:36,466 --> 00:05:37,300
see you're really busy.

102
00:05:37,366 --> 00:05:39,500
I'm really passionate
about this thing.

103
00:05:39,566 --> 00:05:40,832
Why don't you let me help?

104
00:05:40,899 --> 00:05:47,199
The maintainer gave management
control to this volunteer.

105
00:05:47,266 --> 00:05:51,100
This volunteer made some
changes, published an update to

106
00:05:51,166 --> 00:05:55,600
it, everything looked good, and
then they introduced after that

107
00:05:55,666 --> 00:05:59,899
a dependency, that dependency
was a malicious dependency that

108
00:05:59,966 --> 00:06:05,733
was aimed at stealing Bitcoin
for anybody that was at a

109
00:06:05,800 --> 00:06:09,600
company called Copay off of
whatever wallets were sitting

110
00:06:09,666 --> 00:06:11,566
there on the servers that it
happened to get installed on.

111
00:06:11,633 --> 00:06:17,500
That's an example of somebody
trust -- kind of getting trust

112
00:06:17,566 --> 00:06:19,899
inside the open source ecosystem
supply chain and then being able

113
00:06:19,966 --> 00:06:22,033
to infiltrate and
get a backdoor.

114
00:06:22,100 --> 00:06:26,500
Fortunately, like this package
is incredibly popular, but the

115
00:06:26,566 --> 00:06:32,166
fact is that it was only
targeted at this particular

116
00:06:32,233 --> 00:06:33,533
Copay Bitcoin.

117
00:06:33,600 --> 00:06:36,033
It wasn't going after a general
purpose compromise, in which

118
00:06:36,100 --> 00:06:37,666
case the effect would
have been much broader.

119
00:06:40,500 --> 00:06:42,766
Let's talk a little bit about
the agenda because I think the

120
00:06:42,833 --> 00:06:45,633
way that you have to frame the
problem -- and by the way, I

121
00:06:45,699 --> 00:06:49,600
want to make it clear that the
problems that I'm talking about

122
00:06:49,666 --> 00:06:51,766
aren't specific to
open source in many cases.

123
00:06:51,833 --> 00:06:54,800
They're general software
supply chain problems.

124
00:06:54,866 --> 00:06:59,366
The fact is that open source is
such a massive ecosystem that we

125
00:06:59,433 --> 00:07:02,000
need to go after it specifically
and there are some specific

126
00:07:02,066 --> 00:07:06,099
implementation points in the
supply chain that need to be

127
00:07:06,166 --> 00:07:08,066
addressed for open source.

128
00:07:08,133 --> 00:07:11,133
Let me talk by framing the kind
of whole problem about how we

129
00:07:11,199 --> 00:07:14,533
consume software as a supply
chain, and then I'll get into

130
00:07:14,600 --> 00:07:17,833
the various steps of that supply
chain, what the issues are,

131
00:07:17,899 --> 00:07:21,533
examples, and what is happening
for open source ecosystem to

132
00:07:21,600 --> 00:07:24,133
help address those points
in the supply chain.

133
00:07:24,133 --> 00:07:28,000
I'll start here by talking about
supply chain in the context of a

134
00:07:28,066 --> 00:07:30,899
food supply chain, which is one
that we're all familiar with.

135
00:07:30,966 --> 00:07:35,600
A farmer is growing crops, a
buyer is purchasing those crops,

136
00:07:35,666 --> 00:07:39,433
a distributor is taking and
shipping the products into

137
00:07:39,500 --> 00:07:42,300
stores, and then a
customer is buying them.

138
00:07:42,366 --> 00:07:46,300
If you map this onto software,
an open source software, you've

139
00:07:46,366 --> 00:07:49,099
got open source developers,
there are source code

140
00:07:49,166 --> 00:07:52,433
repositories where they are
storing their source code, there

141
00:07:52,500 --> 00:07:55,800
are application developers that
are consuming the output of that

142
00:07:55,866 --> 00:07:59,099
source code, and then they are
providing an end product to

143
00:07:59,166 --> 00:07:59,866
their customers.

144
00:07:59,933 --> 00:08:02,033
This is the simplified form.

145
00:08:02,100 --> 00:08:04,833
It is actually much, much more
complex and this is what makes

146
00:08:04,899 --> 00:08:07,966
the problem especially
challenging because along the

147
00:08:08,033 --> 00:08:12,000
supply chain there could be
dozens, hundreds, or even

148
00:08:12,066 --> 00:08:15,599
thousands of participants at
different points of different

149
00:08:15,666 --> 00:08:17,933
source code repositories,
package management systems,

150
00:08:18,000 --> 00:08:22,166
consumers, products, and
other distribution points.

151
00:08:22,233 --> 00:08:25,699
There are many
loops here as well.

152
00:08:25,766 --> 00:08:29,000
But if you take a look at it
from this framing, then we can

153
00:08:29,066 --> 00:08:30,765
go after specific parts of it.

154
00:08:34,566 --> 00:08:37,500
The question when you're
consuming from the supply chain,

155
00:08:37,566 --> 00:08:41,799
and this one applies to us in
Azure, is how do we prevent

156
00:08:41,866 --> 00:08:44,833
unwanted products from
entering the supply chain.

157
00:08:44,899 --> 00:08:49,966
How do we make sure that only
packages and source that we've

158
00:08:50,033 --> 00:08:52,799
got some assurance are
trustworthy enter our

159
00:08:52,866 --> 00:08:53,766
supply chain?

160
00:08:53,833 --> 00:08:56,233
How do we know what's
in our supply chain?

161
00:08:56,299 --> 00:08:58,766
Kind of that begs the question.

162
00:08:58,833 --> 00:09:02,665
And how do we ensure that what
we know about that supply chain

163
00:09:02,733 --> 00:09:04,000
is reliable?

164
00:09:04,066 --> 00:09:05,899
When somebody says this is
trustworthy, hey, I've done code

165
00:09:05,966 --> 00:09:09,299
reviews on it, I've got MFA in
place for checking the source

166
00:09:09,366 --> 00:09:11,866
code, how do we know that
that's really truly the case?

167
00:09:11,933 --> 00:09:14,433
And then what do we do when
there is a vulnerability?

168
00:09:14,500 --> 00:09:17,066
How do I identify what is
affected by that vulnerability

169
00:09:17,133 --> 00:09:18,966
and how do we roll back
to the good version?

170
00:09:19,033 --> 00:09:20,799
Those are all the kinds of
questions that we've got to

171
00:09:20,866 --> 00:09:22,533
answer when we take a
look at this from a supply

172
00:09:22,600 --> 00:09:23,500
chain perspective.

173
00:09:24,766 --> 00:09:28,599
First, how do we find
vulnerabilities, how do we help

174
00:09:28,666 --> 00:09:31,566
the open source ecosystem find
vulnerabilities in the source

175
00:09:31,633 --> 00:09:34,466
code at the source, kind of
where the crops are being made?

176
00:09:34,533 --> 00:09:36,733
And if you take a look at it
from a crop perspective, this

177
00:09:36,799 --> 00:09:41,266
means how do we end up finding
that there's E.coli somewhere in

178
00:09:41,333 --> 00:09:44,199
those crops before it gets out.

179
00:09:44,266 --> 00:09:45,933
We need to stop it from
even getting in there in the

180
00:09:46,000 --> 00:09:47,000
first place.

181
00:09:47,066 --> 00:09:49,066
Or if it gets in, stopping that
from getting down into the

182
00:09:49,133 --> 00:09:50,066
supply chain.

183
00:09:50,133 --> 00:09:52,899
And when we talk about
vulnerabilities in source code,

184
00:09:52,966 --> 00:09:55,700
this applies to open source and
closed source as well, there

185
00:09:55,766 --> 00:09:58,933
could be credentials in the
code, there could be improper

186
00:09:59,000 --> 00:10:03,000
validation of inputs, there
could be ability for an attacker

187
00:10:03,066 --> 00:10:06,266
to upload arbitrary code and for
that to be executed by the code,

188
00:10:06,333 --> 00:10:09,699
and there could be denial
service opportunities where

189
00:10:09,766 --> 00:10:13,266
you're taking a dependency with
a customer-facing piece of

190
00:10:13,333 --> 00:10:16,833
source code, piece of open
source or closed source, and it

191
00:10:16,899 --> 00:10:19,500
has got a vulnerability that
lets somebody bring down your

192
00:10:19,566 --> 00:10:20,266
whole service.

193
00:10:23,433 --> 00:10:27,233
One of the ways that something
can get into the supply chain

194
00:10:27,299 --> 00:10:29,866
that's malicious is a technique
called typo squatting.

195
00:10:29,933 --> 00:10:37,033
This has been known as a
problem, especially in the Node

196
00:10:37,100 --> 00:10:39,966
ecosystem where package
names are extremely short.

197
00:10:40,033 --> 00:10:42,899
Has anybody ever used one of
these packages in your open

198
00:10:42,966 --> 00:10:44,466
source projects?

199
00:10:44,533 --> 00:10:45,866
Maybe you have.

200
00:10:45,933 --> 00:10:46,966
Maybe you haven't.

201
00:10:47,033 --> 00:10:48,433
But they all kind
of look generic.

202
00:10:48,500 --> 00:10:51,299
They look like, if you're
looking for something specific,

203
00:10:51,366 --> 00:10:55,100
like I'm looking for the
dateutil for Python 3, and you

204
00:10:55,166 --> 00:10:57,700
know that there's a popular one
out there, you might go and pull

205
00:10:57,766 --> 00:10:58,766
this one.

206
00:10:58,833 --> 00:11:04,466
The fact is that these are
variants on well-known packages

207
00:11:04,533 --> 00:11:07,566
that are popular in
the Python community.

208
00:11:07,633 --> 00:11:10,566
You can see cross-env, dateutil
instead of Python 3 dateutil,

209
00:11:10,633 --> 00:11:15,233
and this kind of typo squatting
is a way that we've seen

210
00:11:15,299 --> 00:11:17,899
compromised open source
get into the supply chain.

211
00:11:17,966 --> 00:11:22,166
There have been efforts to go
figure out how we can prevent

212
00:11:22,233 --> 00:11:23,266
typo squatting.

213
00:11:23,333 --> 00:11:27,199
There is something called the
Lichtenstein Delta which looks

214
00:11:27,266 --> 00:11:30,132
at how close words are to each
other and there have been

215
00:11:30,200 --> 00:11:33,166
proposals to say, hey, we don't
let packages come in that are

216
00:11:33,233 --> 00:11:36,465
too close to existing popular
packages in terms of that delta.

217
00:11:36,533 --> 00:11:40,399
But the fact is when it comes to
Python and Node and others where

218
00:11:40,466 --> 00:11:43,799
they've got very short names, it
makes it very difficult because

219
00:11:43,866 --> 00:11:47,766
this graph shows that a huge
number of packages have very

220
00:11:47,833 --> 00:11:51,433
short distances between each
other of well-known packages.

221
00:11:51,500 --> 00:11:55,000
This is a tough, challenging
problem, how do we keep

222
00:11:55,066 --> 00:11:58,233
developers from getting
compromised versions of things

223
00:11:58,299 --> 00:12:00,966
that have names close to
what they're looking for.

224
00:12:03,333 --> 00:12:06,665
Static code analysis is another
very popular way to go and

225
00:12:06,733 --> 00:12:09,799
address vulnerabilities, looking
for the vulnerabilities in the

226
00:12:09,866 --> 00:12:13,233
code, scanning automatically
during a CI/CD pipeline, and

227
00:12:13,299 --> 00:12:15,366
really stopping the
vulnerabilities from getting

228
00:12:15,433 --> 00:12:16,933
into the supply chain
in the first place.

229
00:12:17,000 --> 00:12:23,700
There are a few different open
source efforts or products,

230
00:12:23,766 --> 00:12:28,699
services that open source
publishers can take advantage of

231
00:12:28,766 --> 00:12:31,199
and open source consumers can
take advantage of to make sure

232
00:12:31,266 --> 00:12:34,565
that vulnerabilities haven't
been entering them through this.

233
00:12:34,633 --> 00:12:39,333
One of them is called Synopsys
which looks at every line of

234
00:12:39,399 --> 00:12:42,266
code and execution path
looking for vulnerabilities and

235
00:12:42,333 --> 00:12:43,366
flagging them.

236
00:12:43,433 --> 00:12:45,899
You can see that it's got a huge
number of vulnerabilities you

237
00:12:45,966 --> 00:12:49,500
can see that it will check for.

238
00:12:49,566 --> 00:12:53,600
As is common in many cases,
for open source projects, this

239
00:12:53,666 --> 00:12:55,299
service is completely free.

240
00:12:55,366 --> 00:12:57,665
This is something that's just
easy for somebody developing

241
00:12:57,733 --> 00:12:59,233
open source to
take advantage of.

242
00:12:59,299 --> 00:13:02,132
It's why not do this if
it's going to make your code

243
00:13:02,200 --> 00:13:03,166
more secure.

244
00:13:07,700 --> 00:13:12,066
Microsoft purchased GitHub a
few years ago, and one of the

245
00:13:12,133 --> 00:13:15,000
purchases GitHub has made
since that time is a company

246
00:13:15,066 --> 00:13:16,566
called Semmle.

247
00:13:16,633 --> 00:13:22,266
Semmle is a source code
vulnerability analysis platform

248
00:13:22,333 --> 00:13:24,733
based off of language that's
been called -- renamed the

249
00:13:24,799 --> 00:13:28,899
CodeQL for code query
language that lets you do

250
00:13:28,966 --> 00:13:32,233
variant detection on
common vulnerabilities.

251
00:13:32,299 --> 00:13:36,766
And so the idea here is that if
a vulnerability is detected in a

252
00:13:36,833 --> 00:13:40,000
piece of source code of a
certain pattern that you can

253
00:13:40,066 --> 00:13:43,666
write a CodeQL query that will
find now just that specific

254
00:13:43,733 --> 00:13:46,565
version of the vulnerability but
also variants that are close to

255
00:13:46,633 --> 00:13:50,299
it through the query language
that has regular expression type

256
00:13:50,366 --> 00:13:52,933
syntax as part of it.

257
00:13:53,000 --> 00:13:57,933
One of the services that GitHub
is offering for open source

258
00:13:58,000 --> 00:14:02,733
developers is something called
Security Lab which, for open

259
00:14:02,799 --> 00:14:06,366
source projects, is free, and
for research projects for

260
00:14:06,433 --> 00:14:10,233
research is also free, which
lets you go and scan open source

261
00:14:10,299 --> 00:14:13,665
projects using Semmle queries,
CodeQL queries, a growing

262
00:14:13,733 --> 00:14:15,299
ecosystem of them.

263
00:14:15,366 --> 00:14:19,833
There is a full ecosystem of
CodeQL queries that look for

264
00:14:19,899 --> 00:14:23,666
very common and exist a kind
of vulnerabilities that have

265
00:14:23,733 --> 00:14:26,866
already been seen in source
code and lets you find them.

266
00:14:28,399 --> 00:14:32,466
And then there is snyk which
is a way to stop open source

267
00:14:32,533 --> 00:14:35,500
vulnerabilities from getting
into your supply chain, ones

268
00:14:35,566 --> 00:14:37,500
that you might be
consuming as a developer.

269
00:14:37,566 --> 00:14:40,100
If you're going to pull from a
package and that package has a

270
00:14:40,166 --> 00:14:41,600
known vulnerability,
this will let you know.

271
00:14:41,666 --> 00:14:44,600
It will also scan your source
code repos looking for package

272
00:14:44,666 --> 00:14:46,799
dependencies and let you know
if you've got vulnerabilities.

273
00:14:46,866 --> 00:14:50,266
And, again, this is something
that is completely free for open

274
00:14:50,333 --> 00:14:51,132
source repos.

275
00:14:52,733 --> 00:14:56,199
I want to show you a quick demo
of CodeQL so you get an idea for

276
00:14:56,266 --> 00:15:00,033
the power of this for
open source projects.

277
00:15:00,100 --> 00:15:05,833
I have got a GitHub repo here
for a project called java-test,

278
00:15:05,899 --> 00:15:10,100
and you can see I've made a pull
request on it which is labeled

279
00:15:10,166 --> 00:15:14,366
with a name that describes
just how bad this thing is.

280
00:15:14,433 --> 00:15:16,033
A lot of users
submitted content.

281
00:15:16,100 --> 00:15:19,966
If I click on that pull request,
because I've enabled Semmle

282
00:15:20,033 --> 00:15:23,200
scanning or CodeQL scanning
on this, those scans have

283
00:15:23,266 --> 00:15:25,199
identified a problem.

284
00:15:25,266 --> 00:15:29,299
This pull request introduces one
alert when merging, view it on

285
00:15:29,366 --> 00:15:34,600
lgtm.com, which is where the
free CodeQL service is hosted.

286
00:15:34,666 --> 00:15:38,666
And at this point, what you can
see is it will show me right in

287
00:15:38,733 --> 00:15:43,665
the source code the
vulnerability and the path of

288
00:15:43,733 --> 00:15:45,333
the vulnerability.

289
00:15:45,399 --> 00:15:46,633
I'm not going to spend time
diving into the source code

290
00:15:46,700 --> 00:15:50,333
here, but what is happening here
is that it's taking unsanitized

291
00:15:50,399 --> 00:15:55,333
input from the user,
deserializing that, and then

292
00:15:55,399 --> 00:15:56,899
executing it.

293
00:15:56,966 --> 00:16:04,500
That's this execute right
up here, Mona.dance.

294
00:16:04,566 --> 00:16:07,833
It's basically deserialized
this untrusted input into this

295
00:16:07,899 --> 00:16:08,766
dance method.

296
00:16:08,833 --> 00:16:12,233
This is very obvious,
of course, but just here for

297
00:16:12,299 --> 00:16:13,333
demonstration purposes.

298
00:16:13,399 --> 00:16:18,600
If I say show pass, this takes
me and shows just the snippets

299
00:16:18,666 --> 00:16:22,466
of code from the source here
where you get input stream right

300
00:16:22,533 --> 00:16:26,633
there, which is the untrusted
input, into the deserialization,

301
00:16:26,700 --> 00:16:29,299
and then finally how that gets
packaged up and made part of

302
00:16:29,366 --> 00:16:30,566
that method.

303
00:16:30,633 --> 00:16:32,833
All of that is just right
there at your fingertips.

304
00:16:32,899 --> 00:16:36,033
You can see which queries you've
enabled on your open source

305
00:16:36,100 --> 00:16:40,700
repo, and the built-in java
queries that have been enabled

306
00:16:40,766 --> 00:16:43,665
on this one includes, for
example, character passed to

307
00:16:43,733 --> 00:16:47,333
StringBuffer or
StringBuilder constructor.

308
00:16:47,399 --> 00:16:50,133
This comes with a description of
the type of vulnerability being

309
00:16:50,200 --> 00:16:53,299
scanned for with an example of
it as well as recommendations on

310
00:16:53,366 --> 00:16:55,233
how to avoid or fix
these kinds of problems.

311
00:16:55,299 --> 00:16:57,066
Very powerful tool.

312
00:16:57,133 --> 00:17:00,666
Like I mentioned, it is an
ecosystem of these kinds of

313
00:17:00,733 --> 00:17:01,899
queries that has been built up.

314
00:17:01,966 --> 00:17:05,598
Here is the GitHub repo for
the CodeQL queries that are

315
00:17:05,665 --> 00:17:09,299
available and a bunch of
different languages available

316
00:17:09,366 --> 00:17:11,266
here for CodeQL to go query.

317
00:17:11,333 --> 00:17:14,633
Again, completely free for
open source development.

318
00:17:19,665 --> 00:17:22,399
Let's go back to
the presentation.

319
00:17:27,465 --> 00:17:29,666
One of the other types of
vulnerabilities very common both

320
00:17:29,733 --> 00:17:31,533
in closed and
open source software is

321
00:17:31,599 --> 00:17:32,899
uninitialized variables.

322
00:17:32,966 --> 00:17:35,666
And one of the ways to fall
into the trap of uninitialized

323
00:17:35,733 --> 00:17:41,366
variables is uninitialized heap
and stack, which is come hit,

324
00:17:41,433 --> 00:17:45,033
especially native code, C
and C++ code, very commonly.

325
00:17:45,099 --> 00:17:49,866
Heartbleed is one great example
of it where uninitialized

326
00:17:49,933 --> 00:17:53,333
buffer, you could trick the open
SL server into passing a buffer

327
00:17:53,400 --> 00:17:56,133
back that was longer than it had
been filled in with legitimate

328
00:17:56,200 --> 00:17:58,933
content, and then see what was
beyond it, and what was beyond

329
00:17:59,000 --> 00:18:01,799
it could be information that
would allow you to steal

330
00:18:01,866 --> 00:18:06,633
credentials and keys and
compromise other users of

331
00:18:06,700 --> 00:18:07,766
that site.

332
00:18:07,766 --> 00:18:10,233
There have been efforts
here that have taken place.

333
00:18:10,299 --> 00:18:13,766
The reason that I mention this,
it's going after eliminating

334
00:18:13,833 --> 00:18:16,233
entire bug classes and doing it
in a way that gets to the heart

335
00:18:16,299 --> 00:18:20,000
of open source ecosystem supply
chains, which include compilers

336
00:18:20,066 --> 00:18:21,833
like Clang.

337
00:18:21,900 --> 00:18:24,666
And so this is an effort that's
been supported by Microsoft and

338
00:18:24,733 --> 00:18:29,299
Google and others to go and
modify these to default to

339
00:18:29,366 --> 00:18:30,400
initialization.

340
00:18:30,466 --> 00:18:33,966
One of the reasons why these
compilers historically have no

341
00:18:34,033 --> 00:18:36,366
initialized is because
of performance concerns.

342
00:18:36,433 --> 00:18:39,366
Going and zeroing memory is a
waste if you're going to just

343
00:18:39,433 --> 00:18:41,799
immediately override it,
but then you end up being

344
00:18:41,866 --> 00:18:43,533
susceptible for something
like a Heartbleed.

345
00:18:43,599 --> 00:18:50,533
The goal here is to change the
default to initialize to zeroes,

346
00:18:50,599 --> 00:18:53,966
and then somebody that sees a
performance issue with that

347
00:18:54,033 --> 00:18:57,433
understands that they have not
exposed themselves by disabling

348
00:18:57,500 --> 00:19:01,733
it for particular initialization
buffer can go and disable it if

349
00:19:01,799 --> 00:19:03,266
they need to for
performance reasons.

350
00:19:07,633 --> 00:19:10,133
Here is just an example
of a tweet by one of my

351
00:19:10,200 --> 00:19:11,500
heroes, actually.

352
00:19:11,566 --> 00:19:13,900
Just let me pull it back.

353
00:19:13,966 --> 00:19:18,632
John Carmack himself
getting bit by these things.

354
00:19:18,700 --> 00:19:21,666
Number of days since
uninitialized C++ variable

355
00:19:21,733 --> 00:19:24,099
caused me grief, zero.

356
00:19:24,166 --> 00:19:27,433
This is something that even
professional developers that

357
00:19:27,500 --> 00:19:30,200
have been in the business
for a long time get hit by.

358
00:19:32,833 --> 00:19:35,866
Another way to go find
vulnerabilities is through a

359
00:19:35,933 --> 00:19:37,599
technique called fuzzing that
I'm sure everybody in this room

360
00:19:37,666 --> 00:19:38,666
is aware of.

361
00:19:38,733 --> 00:19:41,332
Lots of different types of
vulnerabilities can be detected

362
00:19:41,400 --> 00:19:42,433
through fuzzing.

363
00:19:42,500 --> 00:19:47,566
The question is how do I get
access to a fuzzer and how do I

364
00:19:47,633 --> 00:19:51,799
get access to the platform that
will fuzz my code automatically.

365
00:19:51,866 --> 00:19:55,566
In the open source world,
they're Google stepped up here,

366
00:19:55,633 --> 00:19:58,833
and it's created a
platform called OSS-Fuzz.

367
00:19:58,900 --> 00:20:00,866
This is a free service
for open source projects.

368
00:20:00,933 --> 00:20:04,099
You go and request access to it.

369
00:20:04,166 --> 00:20:07,166
You provide points to the repo.

370
00:20:07,233 --> 00:20:09,933
You provide an email address
with the maintainer.

371
00:20:10,000 --> 00:20:13,400
And then once you get onboarded
to it, you get -- your code gets

372
00:20:13,466 --> 00:20:15,699
automatically fuzzed by this
service, and you can see that

373
00:20:15,766 --> 00:20:20,933
it's been incredibly successful,
17,000 bugs and 250 open source

374
00:20:21,000 --> 00:20:25,000
projects already detected
through this fuzzing service.

375
00:20:25,066 --> 00:20:27,166
It supports a number of
different fuzzing engines.

376
00:20:27,233 --> 00:20:27,832
It supports C++.

377
00:20:27,900 --> 00:20:30,033
It supports Rust and Go.

378
00:20:30,099 --> 00:20:33,700
This is an example of the kinds
of efforts that we really

379
00:20:33,766 --> 00:20:37,466
support to get the whole
ecosystem in a better place.

380
00:20:39,933 --> 00:20:41,966
Let's talk a little bit about
dependency management now

381
00:20:42,033 --> 00:20:45,899
because we've taken care
of trying to keep the

382
00:20:45,966 --> 00:20:49,000
vulnerabilities from getting
into the supply chain in the

383
00:20:49,066 --> 00:20:54,466
first place in those crops, but
how do we then determine when

384
00:20:54,533 --> 00:20:58,132
there is a vulnerability that's
been exposed, where that came

385
00:20:58,200 --> 00:21:01,599
from, and what's impacted by it.

386
00:21:01,666 --> 00:21:03,166
This is all about supply chain.

387
00:21:03,233 --> 00:21:06,832
Here is a great example of
supply chain in action of open

388
00:21:06,900 --> 00:21:11,066
source ecosystem Electron,
which is the rendering engine

389
00:21:11,133 --> 00:21:13,799
underneath a bunch of popular
products, including Visual

390
00:21:13,866 --> 00:21:16,766
Studio Code, Atom,
Slack, Discord.

391
00:21:16,833 --> 00:21:21,333
This had a vulnerability
introduced into it inadvertently

392
00:21:21,400 --> 00:21:26,000
that allowed the integration
of no JS to be enabled.

393
00:21:29,266 --> 00:21:32,133
By default, when you're running
on one of these platforms like

394
00:21:32,200 --> 00:21:36,366
this, it's disabled, and it's
disabled because enabling it

395
00:21:36,433 --> 00:21:42,833
allows somebody accessing the
interface to deploy arbitrary

396
00:21:42,900 --> 00:21:46,366
node code, JavaScript code,
and executed as system in the

397
00:21:46,433 --> 00:21:48,233
context of that app.

398
00:21:49,099 --> 00:21:51,599
The vulnerability that was
introduced here allowed an

399
00:21:51,666 --> 00:21:56,000
attacker to override that
control and turn the setting to

400
00:21:56,066 --> 00:22:00,466
allow execution of arbitrary
node code and that would then

401
00:22:00,533 --> 00:22:02,166
allow the attacker
to take over the site.

402
00:22:02,233 --> 00:22:04,332
You can see the downstream
dependencies on something

403
00:22:04,400 --> 00:22:05,400
like that.

404
00:22:05,466 --> 00:22:07,099
Every one of these projects
that depended on that upstream

405
00:22:07,166 --> 00:22:11,799
Electron with that vulnerability
now had to go and remediate.

406
00:22:11,866 --> 00:22:14,866
But the first question is: How
do you even know that you've got

407
00:22:14,933 --> 00:22:15,666
this dependency?

408
00:22:15,733 --> 00:22:17,366
How do you know that
there's a vulnerability?

409
00:22:17,433 --> 00:22:21,799
And then how does the whole
supply chain through all the

410
00:22:21,866 --> 00:22:24,933
dependency chains update in
a way that gets everybody as

411
00:22:25,000 --> 00:22:25,866
secure as possible.

412
00:22:27,000 --> 00:22:32,466
And one of the questions this
highlights is -- one of the

413
00:22:32,533 --> 00:22:35,899
issues this highlights is just
how deep dependency chains are

414
00:22:35,966 --> 00:22:37,799
in the open source world.

415
00:22:37,866 --> 00:22:41,733
Here is a little snipped of code
where I am actually depending on

416
00:22:41,799 --> 00:22:44,500
the express web server.

417
00:22:44,566 --> 00:22:47,433
This looks like
I have introduced one

418
00:22:47,500 --> 00:22:48,666
single dependency.

419
00:22:48,733 --> 00:22:52,566
Now all I have to do is monitor
express, and if express is

420
00:22:52,633 --> 00:22:57,066
showing that it's not got any
vulnerabilities, I'm good.

421
00:22:57,133 --> 00:23:00,833
But, actually, the story is a
little bit deeper than that,

422
00:23:00,900 --> 00:23:04,799
because once I import express, I
actually import a whole bunch of

423
00:23:04,866 --> 00:23:07,766
other things with it
that it's dependent on.

424
00:23:07,833 --> 00:23:10,166
In fact, here is the
dependency list for express.

425
00:23:10,233 --> 00:23:15,666
It's got 48 packages that
it imports for its use.

426
00:23:15,733 --> 00:23:17,966
And so what I've just done by
importing express is import all

427
00:23:18,033 --> 00:23:19,065
of these.

428
00:23:19,133 --> 00:23:21,766
I've imported all of the source
code development practices of

429
00:23:21,833 --> 00:23:23,299
all of these packages.

430
00:23:23,366 --> 00:23:25,966
I've imported basically all of
the contributors to all of these

431
00:23:26,033 --> 00:23:30,765
packages as well
and their intentions which are

432
00:23:30,833 --> 00:23:32,333
hopefully benevolent.

433
00:23:32,400 --> 00:23:33,766
Now I'm dependent
on all of that.

434
00:23:37,233 --> 00:23:39,500
I came across this
tweet last month.

435
00:23:39,566 --> 00:23:42,200
This is NPM install, what
somebody likens it to, because

436
00:23:42,266 --> 00:23:47,900
the node ecosystem is one of the
ones that has the deepest and

437
00:23:47,966 --> 00:23:53,033
broadest number of dependencies,
and the reason is because people

438
00:23:53,099 --> 00:23:57,399
just import little snippets,
and so a single project could

439
00:23:57,466 --> 00:24:00,099
literally import thousands or
tens of thousands of these

440
00:24:00,166 --> 00:24:05,099
little node packages to make
up a reasonably sized piece

441
00:24:05,166 --> 00:24:05,832
of software.

442
00:24:07,633 --> 00:24:11,500
In fact, let's
just do a survey here.

443
00:24:11,566 --> 00:24:14,766
What's the average number of
packages trusted by installing

444
00:24:14,833 --> 00:24:16,966
one node package?

445
00:24:17,033 --> 00:24:18,166
Anybody want to take a guess?

446
00:24:20,700 --> 00:24:21,633
Forty?

447
00:24:21,700 --> 00:24:23,066
Anybody else?

448
00:24:23,133 --> 00:24:24,900
Sixty?

449
00:24:24,966 --> 00:24:27,933
The answer is 80,
so not too far off.

450
00:24:32,433 --> 00:24:36,166
The interesting trend we're
seeing with this in these

451
00:24:36,233 --> 00:24:39,233
ecosystems is that when
something gets popular, it gets

452
00:24:39,299 --> 00:24:40,233
even more popular.

453
00:24:40,299 --> 00:24:44,833
This is the average
package reach over time.

454
00:24:44,900 --> 00:24:48,233
You can see the packages in
this ecosystem have gotten

455
00:24:48,299 --> 00:24:49,333
more popular.

456
00:24:49,400 --> 00:24:53,333
The reach of these packages in
terms of the number of services,

457
00:24:53,400 --> 00:24:56,400
other packages that take a
dependency on them has continued

458
00:24:56,466 --> 00:24:57,699
to grow.

459
00:24:57,766 --> 00:25:00,066
Eighty was just the average, but
you can see the tail goes up

460
00:25:00,133 --> 00:25:01,166
into the hundreds.

461
00:25:01,233 --> 00:25:06,633
And here is the top five most
referenced packages in the node

462
00:25:06,700 --> 00:25:07,833
supply chain.

463
00:25:07,900 --> 00:25:12,933
You can see that you're talking
now 150,000 dependent packages

464
00:25:13,000 --> 00:25:14,666
on one of these.

465
00:25:14,733 --> 00:25:17,500
Vulnerability in one of these
and the downstream effect is

466
00:25:17,566 --> 00:25:19,166
pretty monstrous.

467
00:25:21,933 --> 00:25:23,200
Here is another great example.

468
00:25:23,266 --> 00:25:25,500
Do you remember when we
took a picture of a black hole

469
00:25:25,566 --> 00:25:27,633
last year?

470
00:25:27,700 --> 00:25:30,500
That was kind of a cool event,
and it was done all with open

471
00:25:30,566 --> 00:25:32,266
source software.

472
00:25:32,333 --> 00:25:36,200
Here is the project,
ehtim, eht-imaging.

473
00:25:36,266 --> 00:25:39,766
The interesting thing to note
about this is if you take a look

474
00:25:39,833 --> 00:25:42,599
at the number of contributors,
15 contributors on this project

475
00:25:42,666 --> 00:25:45,832
involved with developing a
software that could go analyze

476
00:25:45,900 --> 00:25:50,733
these images and basically
photograph a black hole.

477
00:25:50,799 --> 00:25:54,400
But if you look underneath
the hood, because of all the

478
00:25:54,466 --> 00:25:58,565
dependencies they took on other
packages, there were really

479
00:25:58,633 --> 00:26:02,366
24,500 contributors
to this project.

480
00:26:02,433 --> 00:26:06,500
This truly was a much broader
ecosystem effort, really, if you

481
00:26:06,566 --> 00:26:09,766
take a look at everything
that was used to build this.

482
00:26:09,833 --> 00:26:12,766
It went way beyond the
original 15 contributors.

483
00:26:14,266 --> 00:26:18,333
So how do you know what your
upstream dependencies look like?

484
00:26:18,400 --> 00:26:20,433
It depends on the type of
software that you're using,

485
00:26:20,500 --> 00:26:21,500
of course.

486
00:26:21,566 --> 00:26:26,900
One of the tools in the node
ecosystem for looking at this,

487
00:26:26,966 --> 00:26:31,099
which is a free tool to go use,
it is an interactive tool where

488
00:26:31,166 --> 00:26:33,233
you can go take a look and
get an idea for what you're

489
00:26:33,299 --> 00:26:36,733
dependent on, but there are many
automated tools out there for

490
00:26:36,799 --> 00:26:39,566
the different ecosystems that
you should consider using.

491
00:26:39,633 --> 00:26:41,266
Let's go take a
look at this one.

492
00:26:45,533 --> 00:26:49,666
You can see here the
URL is mpm.broofa.com.

493
00:26:49,733 --> 00:26:53,799
Up here, you can enter a module
name and it will go look at the

494
00:26:53,866 --> 00:26:55,966
dependencies it's got and show
them to you, and it will also

495
00:26:56,033 --> 00:26:58,733
show you the contributors
that were involved in making

496
00:26:58,799 --> 00:26:59,799
those dependencies.

497
00:26:59,866 --> 00:27:01,833
Anybody got a
node pack -- anybody here a

498
00:27:01,900 --> 00:27:03,233
JavaScript developer?

499
00:27:03,299 --> 00:27:04,566
Just raise your hands.

500
00:27:04,633 --> 00:27:05,566
Okay.

501
00:27:05,633 --> 00:27:07,866
Name a package that you use.

502
00:27:07,933 --> 00:27:09,433
Singular?

503
00:27:09,500 --> 00:27:11,133
Angular. Okay. Angular.

504
00:27:19,233 --> 00:27:20,832
I don't know why
that's not coming up.

505
00:27:25,299 --> 00:27:26,099
Zero dependencies.

506
00:27:26,166 --> 00:27:27,033
I don't know.

507
00:27:27,099 --> 00:27:28,200
That doesn't make sense.

508
00:27:28,266 --> 00:27:29,700
Let me try and make
sure this is working.

509
00:27:29,766 --> 00:27:30,799
Yeah.

510
00:27:30,866 --> 00:27:32,266
I don't know why it came up with
zero dependencies for Angular.

511
00:27:32,333 --> 00:27:34,333
Maybe it's fully self-contained.

512
00:27:34,400 --> 00:27:37,599
But Express, which we were
looking at earlier, 48

513
00:27:37,666 --> 00:27:40,099
dependencies, 56 maintainers.

514
00:27:40,166 --> 00:27:44,765
I was curious, like NPM
itself, what that looks like.

515
00:27:44,833 --> 00:27:51,233
When you run NPM for NPM
install, you're actually taking

516
00:27:51,299 --> 00:27:58,766
a huge set of dependencies, 380
dependencies, and the number of

517
00:27:58,833 --> 00:28:01,266
developers, 188 maintainers.

518
00:28:01,333 --> 00:28:05,200
I want to make clear that that's
maintainers, not contributors.

519
00:28:05,266 --> 00:28:07,966
The number of contributors is
probably in the thousands or

520
00:28:08,033 --> 00:28:09,366
tens of thousands.

521
00:28:09,433 --> 00:28:11,266
All of this isn't feeding
into your supply chain.

522
00:28:11,333 --> 00:28:14,766
When you run NPM on your server,
you're dependent on all of that.

523
00:28:16,966 --> 00:28:18,033
All right.

524
00:28:18,099 --> 00:28:19,265
Let's go back to the deck.

525
00:28:25,933 --> 00:28:28,966
The takeaway for this section is
automate your dependency mapping

526
00:28:29,033 --> 00:28:32,433
and your build pipelines, apply
those tools that can go identify

527
00:28:32,500 --> 00:28:35,900
dependencies so you understand
what you're dependent on, which

528
00:28:35,966 --> 00:28:38,399
will come in use when you're
looking for vulnerabilities.

529
00:28:38,466 --> 00:28:41,199
It also becomes useful when
you're looking at importing

530
00:28:41,266 --> 00:28:44,200
things and making sure that
they adhere to the policies you

531
00:28:44,266 --> 00:28:49,166
define and that they're also
being maintained in a way that

532
00:28:49,233 --> 00:28:52,000
doesn't allow vulnerabilities
to get into your supply chain.

533
00:28:54,466 --> 00:28:57,065
Let's take a look now at build
systems and package managers

534
00:28:57,133 --> 00:29:00,766
because this has been another
area where in the open source

535
00:29:00,833 --> 00:29:02,833
ecosystem itself, this is kind
of like going to the grocery

536
00:29:02,900 --> 00:29:06,666
store and compromising the
product there by putting some

537
00:29:06,733 --> 00:29:08,633
chemical on it and now people
are walking away with it.

538
00:29:08,700 --> 00:29:14,533
Because the farmer did the right
thing, made sure there's no

539
00:29:14,599 --> 00:29:18,700
E.coli, the shipper got it to
the store in okay shape, but at

540
00:29:18,766 --> 00:29:21,900
that point now the consumer is
walking in and picking up a bad

541
00:29:21,966 --> 00:29:25,966
product because the attacker
was in the grocery store.

542
00:29:26,033 --> 00:29:27,733
Same thing can happen here.

543
00:29:27,799 --> 00:29:30,966
There have been multiple
examples here of the open source

544
00:29:31,033 --> 00:29:33,500
supply chain getting
compromised at this point in

545
00:29:33,566 --> 00:29:35,900
the supply chain.

546
00:29:35,966 --> 00:29:43,399
Here is an example here where an
account was compromised and this

547
00:29:43,466 --> 00:29:46,866
allowed somebody to put a
backdoor into a specific

548
00:29:46,933 --> 00:29:50,033
package, the rest client
that I talked about earlier.

549
00:29:50,099 --> 00:29:53,533
This rest client,
incredibly popular.

550
00:29:53,599 --> 00:29:56,466
The kind of cool thing about
this is that the developer, the

551
00:29:56,533 --> 00:30:01,366
maintainer of the rest client
package basically lived up and

552
00:30:01,433 --> 00:30:04,766
stepped up and said, hey, this
is my fault, here's the hacker

553
00:30:04,833 --> 00:30:09,533
news thread where they're like,
hey, hey, everybody probably

554
00:30:09,599 --> 00:30:12,366
knows right now that rest client
has been compromised, the reason

555
00:30:12,433 --> 00:30:16,633
why, I was reusing credentials,
it's a project that I started

556
00:30:16,700 --> 00:30:21,599
ten years ago before I had
password manager, and that

557
00:30:21,666 --> 00:30:24,700
password was compromised through
some other site, and I reused

558
00:30:24,766 --> 00:30:27,633
password and so that let
somebody get in and compromise

559
00:30:27,700 --> 00:30:28,599
this rest client.

560
00:30:28,666 --> 00:30:35,233
They were producing good
software, but at this point, the

561
00:30:35,299 --> 00:30:39,099
attacker was able to get in and
compromise the package in the

562
00:30:39,166 --> 00:30:40,366
Ruby-Gems package manager.

563
00:30:40,933 --> 00:30:42,333
Here's another example.

564
00:30:42,400 --> 00:30:44,766
This one, though, goes right to
the heart of the source code

565
00:30:44,833 --> 00:30:48,466
distribution for Ubuntu's
Canonical's Ubuntu.

566
00:30:48,533 --> 00:30:53,265
This isn't a problem just for
the guy that's maintaining

567
00:30:53,333 --> 00:30:57,099
something in their spare time
and kind of not applying best

568
00:30:57,166 --> 00:31:02,033
practices, but even major
companies that are very involved

569
00:31:02,099 --> 00:31:05,233
with the open source ecosystem
have major impacts on it can

570
00:31:05,299 --> 00:31:06,566
make these kinds of mistakes.

571
00:31:08,000 --> 00:31:10,099
How do we help
everybody step up here?

572
00:31:10,166 --> 00:31:12,866
The answer is to step up
and to get into multifactor

573
00:31:12,933 --> 00:31:14,166
authentication.

574
00:31:14,233 --> 00:31:17,466
Now all of the package managers,
the popular package managers

575
00:31:17,533 --> 00:31:19,065
support multifactor
authentication.

576
00:31:19,133 --> 00:31:22,500
All of the popular source code
repositories support multifactor

577
00:31:22,566 --> 00:31:23,799
authentication.

578
00:31:23,866 --> 00:31:26,066
This is something that we
absolutely have to start moving

579
00:31:26,133 --> 00:31:28,866
towards mandatory
enforcement on.

580
00:31:28,933 --> 00:31:32,466
It is just beyond the point
where we can just allow people

581
00:31:32,533 --> 00:31:36,765
to introduce problems through
the supply chain because they

582
00:31:36,833 --> 00:31:40,366
just feel that multifactor is
too onerous for them because

583
00:31:40,433 --> 00:31:45,266
they're having an effect on this
massive downstream ecosystem at

584
00:31:45,333 --> 00:31:46,099
this point.

585
00:31:49,200 --> 00:31:51,500
Another example where
problems can show up is in

586
00:31:51,566 --> 00:31:52,900
build tampering.

587
00:31:52,966 --> 00:31:56,533
The artifacts get produced,
and at that point as the build

588
00:31:56,599 --> 00:32:00,099
system is packaging things up
for release, the attackers

589
00:32:00,166 --> 00:32:03,366
compromise the build servers or
the release management servers

590
00:32:03,433 --> 00:32:04,866
and introduce these problems.

591
00:32:04,933 --> 00:32:08,200
The Webmin case that I talked
about earlier was an example

592
00:32:08,266 --> 00:32:10,333
of this.

593
00:32:10,400 --> 00:32:15,233
The source code in the repo,
the master repo for Webmin and

594
00:32:15,299 --> 00:32:19,466
GitHub was fine, but in
SourceForge, it wasn't, and this

595
00:32:19,533 --> 00:32:24,632
allowed the attacker to get in
and put a script in because they

596
00:32:24,700 --> 00:32:27,233
put a script into the build
server to inject the backdoor

597
00:32:27,299 --> 00:32:29,533
into it.

598
00:32:29,599 --> 00:32:33,099
This is an example of kind of in
the middle of the supply chain

599
00:32:33,166 --> 00:32:36,066
the producer of the software is
doing the right things, but the

600
00:32:36,133 --> 00:32:37,900
server was compromised.

601
00:32:37,966 --> 00:32:40,933
The server could be compromised
even if they were following all

602
00:32:41,000 --> 00:32:43,200
the best practices for
securing that server.

603
00:32:43,266 --> 00:32:45,599
But how do you detect that
is kind of the question.

604
00:32:45,666 --> 00:32:48,799
One of the tools that we've got
at our disposal for detecting

605
00:32:48,866 --> 00:32:51,266
these kinds of problems is
something called reproducible

606
00:32:51,333 --> 00:32:54,533
builds, and this is something
that Microsoft is involved with

607
00:32:54,599 --> 00:32:56,966
pushing the industry towards.

608
00:32:57,033 --> 00:32:59,832
Microsoft has been involved with
reproducible builds for its own

609
00:32:59,900 --> 00:33:01,433
software for some time.

610
00:33:01,500 --> 00:33:04,833
Windows is now reproducible,
or at least large parts of it.

611
00:33:04,900 --> 00:33:08,066
What reproducible builds give
you is the ability to take some

612
00:33:08,133 --> 00:33:14,333
source code, and if somebody can
rebuild it and know that given

613
00:33:14,400 --> 00:33:17,500
the compiler, given the
artifacts that are pulled into

614
00:33:17,566 --> 00:33:21,400
it, that when they do a build,
the artifacts are going to have

615
00:33:21,466 --> 00:33:25,500
specific hashes, then they can
verify that if somebody says

616
00:33:25,566 --> 00:33:29,000
here is a legitimate build,
here's the hashes for it, they

617
00:33:29,066 --> 00:33:33,066
can verify that nothing has been
tampered with by rebuilding from

618
00:33:33,133 --> 00:33:36,000
the source, that nothing got
into the middle of that supply

619
00:33:36,066 --> 00:33:38,466
chain from build to
release management.

620
00:33:40,933 --> 00:33:44,133
Linux itself is moving towards
the reproducible builds itself.

621
00:33:44,200 --> 00:33:47,733
The problem with reproducible
builds is it's a very tough,

622
00:33:47,799 --> 00:33:49,299
challenging technical problem.

623
00:33:49,366 --> 00:33:51,166
The build has to be
entirely deterministic.

624
00:33:51,233 --> 00:33:53,633
One of the challenges Microsoft
had in making reproducible

625
00:33:53,700 --> 00:33:57,400
builds was getting time stamps
out of the Windows binaries that

626
00:33:57,466 --> 00:33:59,933
were signed as part
of the signatures.

627
00:34:00,000 --> 00:34:04,133
And so if you take a look at
the time stamps now in Windows

628
00:34:04,200 --> 00:34:06,833
binaries, they're completely
garbage, and that's because they

629
00:34:06,900 --> 00:34:08,199
needed to be made garbage.

630
00:34:08,266 --> 00:34:12,966
Effectively, they're not time
stamps anymore because we needed

631
00:34:13,033 --> 00:34:14,500
to get to reproducible builds.

632
00:34:14,565 --> 00:34:17,232
And so that's just one example
of the efforts now the whole

633
00:34:17,300 --> 00:34:19,733
ecosystem needs to take to get
to a place where we can have

634
00:34:19,800 --> 00:34:22,900
reproducible builds across all
these different technologies.

635
00:34:24,866 --> 00:34:27,966
Another way that here in the
supply chain problems can go

636
00:34:28,033 --> 00:34:33,699
wrong is somebody yanking or
compromising the distribution

637
00:34:33,766 --> 00:34:35,933
units, the package manager,
and this is a great example of

638
00:34:36,000 --> 00:34:37,599
this one.

639
00:34:37,666 --> 00:34:41,199
This package called left-pad,
that's a node package called

640
00:34:41,266 --> 00:34:42,366
left-pad.

641
00:34:42,433 --> 00:34:45,733
It's just about a dozen lines of
code for left-padding a string,

642
00:34:45,800 --> 00:34:48,566
got incredibly popular.

643
00:34:48,632 --> 00:34:54,132
It's been leveraged by basically
the whole web was dependent on

644
00:34:54,199 --> 00:34:56,199
it at this point back in 2016.

645
00:34:56,266 --> 00:35:01,699
The maintainer of that little
snippet of code was -- had

646
00:35:01,766 --> 00:35:04,933
another package called kick and
there was a product called kick.

647
00:35:05,000 --> 00:35:07,766
The lawyers for that product
said, hey, you're violating

648
00:35:07,833 --> 00:35:09,933
our trademark.

649
00:35:10,000 --> 00:35:14,966
The maintainer of
left-pad said I don't care.

650
00:35:15,033 --> 00:35:18,699
So the lawyers went to node and
said, hey, pull this guy's kick

651
00:35:18,766 --> 00:35:24,833
package off of node with a legal
order to do so in violation of

652
00:35:24,900 --> 00:35:26,000
that trademark.

653
00:35:26,066 --> 00:35:28,732
Node pulled that kick package.

654
00:35:28,800 --> 00:35:31,766
When the maintainer found out
-- left-pad and kick found out

655
00:35:31,833 --> 00:35:35,300
about that, they got upset and
they said, okay, fine, I'm

656
00:35:35,366 --> 00:35:39,266
pulling everything that I've got
off of the node package manager,

657
00:35:39,333 --> 00:35:41,400
and they were
maintaining at that point about

658
00:35:41,466 --> 00:35:42,366
100 different packages.

659
00:35:42,433 --> 00:35:46,000
They pulled them all off,
including left-pad, which ended

660
00:35:46,066 --> 00:35:48,066
up breaking the world.

661
00:35:48,133 --> 00:35:53,366
And so at this point, you can
see that Node took this very

662
00:35:53,433 --> 00:36:01,500
unusual step to unpublish --
un-unpublish that package.

663
00:36:01,566 --> 00:36:03,799
That's down there in
that tweet right there.

664
00:36:03,866 --> 00:36:06,866
We took the unprecedented
step of un-unpublishing.

665
00:36:06,933 --> 00:36:09,099
I think at this point
the maintainer wanted to

666
00:36:09,166 --> 00:36:13,099
un-un-unpublish the package, but
they'd already lost control of

667
00:36:13,166 --> 00:36:15,033
it and so they couldn't
do that, unfortunately.

668
00:36:15,099 --> 00:36:19,633
But this restored people's
build systems now that were so

669
00:36:19,699 --> 00:36:21,699
dependent on this left-pad
little snippet of code.

670
00:36:25,199 --> 00:36:28,699
The lesson here is to
mirror your repositories.

671
00:36:29,666 --> 00:36:31,166
This is an effort that we've
been taking internally at

672
00:36:31,233 --> 00:36:33,866
Microsoft, and this is a very
tough one, to go find all the

673
00:36:33,933 --> 00:36:38,366
places where people are pulling
directly from public repos into

674
00:36:38,433 --> 00:36:43,066
their build systems versus
setting up mirrors and pulling

675
00:36:43,133 --> 00:36:44,098
from the mirrors.

676
00:36:44,166 --> 00:36:49,000
The fact is that mirrors have
a couple of different very

677
00:36:49,066 --> 00:36:49,832
valuable properties.

678
00:36:49,900 --> 00:36:51,766
One of them is availability.

679
00:36:51,833 --> 00:36:57,800
If the upstream package repo
has a problem, it goes down for

680
00:36:57,866 --> 00:37:02,566
availability reasons, or it goes
down because it gets cut off

681
00:37:02,633 --> 00:37:05,633
from your build system for some
reason, you've got a place to

682
00:37:05,699 --> 00:37:06,933
go to.

683
00:37:07,000 --> 00:37:11,966
But the other kind of more
serious reason for security

684
00:37:12,033 --> 00:37:15,199
purposes is if there is a
compromise of that upstream

685
00:37:15,266 --> 00:37:17,533
system, you can
shield yourself from it.

686
00:37:17,599 --> 00:37:20,400
You're one level of a direction
and so you can sever and stop

687
00:37:20,466 --> 00:37:23,366
mirroring the
compromised vulnerability.

688
00:37:23,433 --> 00:37:27,733
In the case of that package that
was pulled, you've got a copy of

689
00:37:27,800 --> 00:37:29,633
it locally.

690
00:37:29,699 --> 00:37:35,666
In the case of that package, the
Bootstrap-saas package that the

691
00:37:35,733 --> 00:37:37,733
developer pulled the last known
good version, you have got a

692
00:37:37,800 --> 00:37:42,066
copy of it, so you can continue
to build securely in the face of

693
00:37:42,133 --> 00:37:43,799
a compromise somewhere
in the supply chain.

694
00:37:43,866 --> 00:37:47,833
It is just a very good best
practice to mirror your repos.

695
00:37:49,500 --> 00:37:53,966
Now this next topic, I think
it really gets to the heart of

696
00:37:54,033 --> 00:37:58,165
addressing this problem because
we've talked about ways that

697
00:37:58,233 --> 00:38:01,300
developers can go scan their
source code for vulnerabilities.

698
00:38:01,366 --> 00:38:05,633
We've talked about the way that
package managers -- the way that

699
00:38:05,699 --> 00:38:08,500
package managers should use
multifactor authentication and

700
00:38:08,566 --> 00:38:10,966
the way that you should be using
mirrors if you're consuming open

701
00:38:11,033 --> 00:38:14,000
source software to insulate
yourself from problems at that

702
00:38:14,066 --> 00:38:15,366
point in the supply chain.

703
00:38:15,433 --> 00:38:19,266
But one of the challenges we
talked about earlier in the

704
00:38:19,333 --> 00:38:22,533
supply chain is really how do
I make sure when I'm consuming

705
00:38:22,599 --> 00:38:26,933
things that it has followed best
practices, that the developers

706
00:38:27,000 --> 00:38:32,566
have used MFA, that there was
vulnerability scanning that

707
00:38:32,633 --> 00:38:35,198
was performed.

708
00:38:35,266 --> 00:38:36,699
How do I check all that?

709
00:38:36,766 --> 00:38:39,733
How do I ensure that it was
done with a reproducible build?

710
00:38:39,800 --> 00:38:42,733
And what were the reproducible
build artifacts that were used

711
00:38:42,800 --> 00:38:43,900
to build this?

712
00:38:43,966 --> 00:38:48,732
All of these questions require
the supply chain together to

713
00:38:48,800 --> 00:38:52,900
cooperate and having this
information flow downstream to

714
00:38:52,966 --> 00:38:54,299
whoever eventually is
going to consume it.

715
00:38:54,300 --> 00:38:59,333
The effort that has started in
this space is something called

716
00:38:59,400 --> 00:39:04,833
software supply chain, software
bill of materials, which lets

717
00:39:04,900 --> 00:39:07,233
you answer these
kinds of questions.

718
00:39:07,300 --> 00:39:08,833
Where do things come from?

719
00:39:11,400 --> 00:39:12,199
Who produced it?

720
00:39:12,266 --> 00:39:14,000
Is there a strong identity?

721
00:39:14,066 --> 00:39:15,133
Do I trust them?

722
00:39:15,199 --> 00:39:18,066
That way I can say I
trust these publishers.

723
00:39:18,133 --> 00:39:20,566
What is the product itself?

724
00:39:20,633 --> 00:39:23,133
This is one of the challenges
in open source ecosystem.

725
00:39:23,199 --> 00:39:25,733
If you've ever seen
vulnerability in package version

726
00:39:25,800 --> 00:39:30,466
blah, what's the source
code that fit into package

727
00:39:30,533 --> 00:39:31,566
version blah?

728
00:39:31,633 --> 00:39:33,765
Maybe I consume that directly.

729
00:39:33,833 --> 00:39:36,733
How do I know that
that's been fixed?

730
00:39:36,800 --> 00:39:41,133
How do I know what other
dependencies that source has,

731
00:39:41,199 --> 00:39:44,633
what other packages depend on
that vulnerable piece of source?

732
00:39:44,699 --> 00:39:49,533
Those are all questions that
having some kind of tracing of

733
00:39:49,599 --> 00:39:52,066
this source was used to build
these things would let you go

734
00:39:52,133 --> 00:39:55,332
back up and answer those
kinds of questions.

735
00:39:55,400 --> 00:39:58,766
Licensing is one of the
questions that enterprises have

736
00:39:58,833 --> 00:40:00,866
around when they're consuming
open source software or when

737
00:40:00,933 --> 00:40:02,966
they're modifying
open source software and then

738
00:40:03,033 --> 00:40:04,333
redistributing it.

739
00:40:04,400 --> 00:40:05,000
Is it MIT?

740
00:40:05,066 --> 00:40:06,000
Is it PSD?

741
00:40:06,066 --> 00:40:08,533
Is it -- what license is it?

742
00:40:08,599 --> 00:40:09,699
Am I violating it?

743
00:40:09,766 --> 00:40:11,599
Am I being conformant with it?

744
00:40:13,766 --> 00:40:16,699
And then, like I mentioned,
how is the product created?

745
00:40:16,766 --> 00:40:18,966
And then what materials were
used to build the product?

746
00:40:19,933 --> 00:40:23,000
Software bill of materials which
tracks all this information as

747
00:40:23,066 --> 00:40:24,633
it flows down the supply chain.

748
00:40:24,699 --> 00:40:28,066
Let me give an example of how it
might defend against an advanced

749
00:40:28,133 --> 00:40:29,799
persistent threat
sitting on a build server.

750
00:40:29,866 --> 00:40:32,766
Developer commits some code,
the build system builds the

751
00:40:32,833 --> 00:40:35,533
artifacts in the normal path,
the release management system

752
00:40:35,599 --> 00:40:39,533
takes those artifacts, packages
them up, and then sticks them in

753
00:40:39,599 --> 00:40:44,066
a package manager or it releases
it as part of a product.

754
00:40:44,133 --> 00:40:47,899
In the malicious case, we have
got somebody that's tampering

755
00:40:47,966 --> 00:40:51,400
with those artifacts
in the build system.

756
00:40:51,466 --> 00:40:55,033
This is like the Webmin
case, for example.

757
00:40:55,099 --> 00:40:58,433
The release management system
creates a malicious build from

758
00:40:58,500 --> 00:41:01,500
that release and then everybody
downstream is compromised

759
00:41:01,566 --> 00:41:02,533
by that.

760
00:41:02,599 --> 00:41:05,066
If we had software bill of
materials in this flow,

761
00:41:05,133 --> 00:41:08,765
developer commits the code, the
build system compiles the code,

762
00:41:08,833 --> 00:41:11,366
it generates and signs the
software bill of materials and

763
00:41:11,433 --> 00:41:13,533
publishes the build artifacts.

764
00:41:13,599 --> 00:41:16,133
The attacker then tampers
with those build artifacts.

765
00:41:16,199 --> 00:41:19,433
The release management creates
a malicious release from

766
00:41:19,500 --> 00:41:20,500
that build.

767
00:41:20,566 --> 00:41:22,732
It's malicious because some of
those have been compromised.

768
00:41:22,800 --> 00:41:26,566
Now, downstream, the release
management system attempts to

769
00:41:26,633 --> 00:41:30,466
verify that the malicious
artifacts was against that

770
00:41:30,533 --> 00:41:34,133
signed SBOM and sees that
the artifacts don't match.

771
00:41:34,199 --> 00:41:36,233
The ones that came from the
build system don't match the

772
00:41:36,300 --> 00:41:38,033
ones that were published
by the release system.

773
00:41:38,099 --> 00:41:40,366
At that point, it says, wait
a minute, something has been

774
00:41:40,433 --> 00:41:43,466
compromised upstream, so I'm
not going to release this.

775
00:41:43,533 --> 00:41:47,000
Another example is just making
sure that there are policy gates

776
00:41:47,066 --> 00:41:48,133
in place.

777
00:41:48,199 --> 00:41:51,233
The software that I'm consuming
had to go through specific code

778
00:41:51,300 --> 00:41:54,000
verification, either static
vulnerability analysis or check

779
00:41:54,066 --> 00:41:55,232
for credentials in the code.

780
00:41:55,300 --> 00:41:57,633
How do I know when I'm
consuming the software that

781
00:41:57,699 --> 00:41:59,099
that's the case?

782
00:41:59,166 --> 00:42:03,400
And, again, with software bill
of materials in the mix here,

783
00:42:03,466 --> 00:42:09,799
along the way, they make sure
that what's being consumed

784
00:42:09,866 --> 00:42:12,000
downstream matches
those policies.

785
00:42:12,066 --> 00:42:15,366
We won't release software
that doesn't adhere to

786
00:42:15,433 --> 00:42:16,099
these policies.

787
00:42:16,166 --> 00:42:19,900
I don't want to
trivialize this effort.

788
00:42:19,966 --> 00:42:24,133
If you take a look at what's
required here, it requires

789
00:42:24,199 --> 00:42:26,766
massive changes to
infrastructure everywhere to

790
00:42:26,833 --> 00:42:28,099
support software
bill of materials.

791
00:42:28,166 --> 00:42:33,433
But the fact is that we,
Microsoft, Google, others, have

792
00:42:33,500 --> 00:42:36,566
all come to the conclusion that
this is absolutely necessary.

793
00:42:36,933 --> 00:42:39,400
And so this massive
industry-wide effort at this

794
00:42:39,466 --> 00:42:44,900
point to first step define a
software bill of materials and

795
00:42:44,966 --> 00:42:46,433
then standardize it.

796
00:42:46,500 --> 00:42:51,800
There are a couple of projects
already in existence for this

797
00:42:51,866 --> 00:42:53,666
that could be suitable for this.

798
00:42:53,733 --> 00:42:58,533
One is called SPDX, Software
Package Data Exchange, which has

799
00:42:58,599 --> 00:42:59,766
declared a format.

800
00:42:59,833 --> 00:43:04,033
It was originally targeted at
licensing, tracking licensing

801
00:43:04,099 --> 00:43:05,733
through supply chain.

802
00:43:05,800 --> 00:43:09,433
But they're now looking at
extending this to support the

803
00:43:09,500 --> 00:43:11,366
requirements for software bill
of materials, including strong

804
00:43:11,433 --> 00:43:15,366
signatures and identity and
policies that can go along

805
00:43:15,433 --> 00:43:16,099
with it.

806
00:43:17,233 --> 00:43:20,599
Another one is called in-toto.

807
00:43:20,666 --> 00:43:25,666
In-toto was created specifically
to address or to target the

808
00:43:25,733 --> 00:43:28,466
security side of the supply
chain with the software bill of

809
00:43:28,533 --> 00:43:31,098
materials where they've got
different personas and those

810
00:43:31,166 --> 00:43:33,766
different personas can apply
policies, can leverage the

811
00:43:33,833 --> 00:43:36,900
in-toto tools through their
build systems or release systems

812
00:43:36,966 --> 00:43:44,165
to augment the artifacts with
in-toto SBOMs, and those SBOMs

813
00:43:44,233 --> 00:43:46,466
then can be verified against
policies using, again, the

814
00:43:46,533 --> 00:43:47,900
in-toto tools.

815
00:43:47,966 --> 00:43:54,266
The goal here with all these
companies looking at this is to

816
00:43:54,333 --> 00:43:58,866
come up with let's come up with
a standard SBOM specification

817
00:43:58,933 --> 00:44:02,266
and let's get that adopted as an
industry standard through this

818
00:44:02,333 --> 00:44:05,666
or some other means, and then
let's have the whole ecosystem

819
00:44:05,733 --> 00:44:08,633
start building tooling
and putting this in their

820
00:44:08,699 --> 00:44:11,266
infrastructure so that we now
have this information flowing

821
00:44:11,333 --> 00:44:12,000
for everybody.

822
00:44:12,900 --> 00:44:16,433
I want to give you a quick demo
of in-toto so you kind of --

823
00:44:16,500 --> 00:44:18,133
what it can do.

824
00:44:18,199 --> 00:44:21,099
So I've got Visual
Studio code here.

825
00:44:21,166 --> 00:44:26,033
I've got a package here
that you can see I'm using the

826
00:44:26,099 --> 00:44:27,099
in-toto run.

827
00:44:27,166 --> 00:44:31,966
I'm going to clone a GitHub repo
called demo project Jekyll.

828
00:44:32,033 --> 00:44:38,266
I'm going to CD into it.

829
00:44:38,333 --> 00:44:41,466
What happened right there, by
the way, when I did that clone,

830
00:44:41,533 --> 00:44:45,598
in-toto, because it was
monitoring it, is keeping track

831
00:44:45,666 --> 00:44:49,933
of every command along the way
and the artifacts that were

832
00:44:50,000 --> 00:44:53,233
produced in that command,
including their hashes.

833
00:44:53,300 --> 00:44:56,099
Detailed tracking.

834
00:44:56,166 --> 00:44:58,433
I'm going to move that into this
folder called verification.

835
00:44:58,500 --> 00:45:06,066
And the next step is I'm going
to run a linter on it right

836
00:45:06,133 --> 00:45:07,598
here, an HTML linter.

837
00:45:07,666 --> 00:45:10,533
This would be me doing a static
code verification on it.

838
00:45:10,599 --> 00:45:19,099
Again, that is going to end up
creating this linker artifact,

839
00:45:19,166 --> 00:45:22,066
linter artifact for that
command, the same kinds of

840
00:45:22,133 --> 00:45:24,566
artifacts there that
we saw annotations.

841
00:45:24,633 --> 00:45:28,500
I'm going to copy that here
into the verification folder.

842
00:45:28,566 --> 00:45:33,098
And then the final step is to do
a docker build on this thing to

843
00:45:33,166 --> 00:45:35,166
build it into a container.

844
00:45:37,599 --> 00:45:44,233
And now I've got my docker build
and I have the one last there

845
00:45:44,300 --> 00:45:48,433
in-toto artifact SBOM artifact
that I'm going to drop into the

846
00:45:48,500 --> 00:45:52,099
verification folder if I
can reach it from here.

847
00:45:52,166 --> 00:45:53,733
There we go.

848
00:45:53,800 --> 00:45:57,033
And now at this point, I've
got all those artifacts there.

849
00:45:57,099 --> 00:46:02,699
What I can do is run
this in-toto verify on the

850
00:46:02,766 --> 00:46:03,800
whole project.

851
00:46:03,866 --> 00:46:07,666
It looks like
I've made a mistake.

852
00:46:10,333 --> 00:46:13,300
What should happen is that
this doesn't find any errors.

853
00:46:13,366 --> 00:46:17,400
I have made some mistake
in the flow here.

854
00:46:17,466 --> 00:46:18,766
But you get the idea.

855
00:46:18,833 --> 00:46:19,933
Really, this is what this
should come back with is the

856
00:46:20,000 --> 00:46:22,833
verification of the artifacts
against those hashes.

857
00:46:22,900 --> 00:46:26,199
I can even have a policy file
that says I want these policies,

858
00:46:26,266 --> 00:46:29,633
which are also signed as part of
those artifacts to be enforced,

859
00:46:29,699 --> 00:46:33,500
and in-toto would ensure
that that's the case.

860
00:46:33,566 --> 00:46:35,832
That's a quick look at in-toto.

861
00:46:39,966 --> 00:46:42,866
Finally, let's talk about
responding to the threats.

862
00:46:42,933 --> 00:46:46,033
Once there has been a compromise
someplace, and there will be

863
00:46:46,099 --> 00:46:48,199
more compromises even
with all of this.

864
00:46:48,266 --> 00:46:51,400
When it comes to food
compromise, everybody gets food

865
00:46:51,466 --> 00:46:52,732
safety alerts.

866
00:46:52,800 --> 00:46:56,633
The goal is to find the
original crop where the E.

867
00:46:56,699 --> 00:46:59,900
coli came from and ban only
everything that came downstream

868
00:46:59,966 --> 00:47:03,966
for that, not just all
lettuce in general, ideally.

869
00:47:04,033 --> 00:47:07,699
Same thing happens here is we
need to understand both this

870
00:47:07,766 --> 00:47:11,033
impact, the severity of the
vulnerability, as well as what

871
00:47:11,099 --> 00:47:13,699
parts of the supply
chain are impacted by it.

872
00:47:14,866 --> 00:47:18,233
This is part of tracking the
contaminants through the

873
00:47:18,300 --> 00:47:19,633
supply chain.

874
00:47:19,699 --> 00:47:22,366
Everything that I talked about
earlier up to this point feeds

875
00:47:22,433 --> 00:47:25,066
into this, especially SBOM.

876
00:47:25,133 --> 00:47:28,633
With SBOM, with the strong
naming, with the hashes, with

877
00:47:28,699 --> 00:47:32,800
the source attribution, we can
-- ideally, in a world where

878
00:47:32,866 --> 00:47:37,966
everything is flowing through
SBOMs, downstream, at your code,

879
00:47:38,033 --> 00:47:40,165
you can check and look at all of
the BOMs that have come with the

880
00:47:40,233 --> 00:47:43,500
things that you've pulled
dependencies on and go all the

881
00:47:43,566 --> 00:47:46,966
way back upstream with
automated tooling back up to

882
00:47:47,033 --> 00:47:47,766
the source files.

883
00:47:47,833 --> 00:47:50,466
I asked that question
a little bit earlier.

884
00:47:50,533 --> 00:47:53,732
When there is a vulnerability in
a package and that vulnerability

885
00:47:53,800 --> 00:47:56,833
came from a piece of source
code, what other packages

886
00:47:56,900 --> 00:48:00,966
depending on that source code,
that is something that SBOMs

887
00:48:01,033 --> 00:48:04,900
ultimately can answer just
through automated walking back

888
00:48:04,966 --> 00:48:07,500
through the chains of
dependencies in the information

889
00:48:07,566 --> 00:48:08,399
in this metadata.

890
00:48:08,400 --> 00:48:12,099
So just want to
emphasize how useful this is.

891
00:48:12,166 --> 00:48:13,900
Now that's not to say that some
of the other things we have

892
00:48:13,966 --> 00:48:15,933
already talked about that are in
place and you can take advantage

893
00:48:16,000 --> 00:48:18,833
of today, like these automated
dependency tools, to say this

894
00:48:18,900 --> 00:48:24,733
package I depend on, what
projects of mine are leveraging

895
00:48:24,800 --> 00:48:28,333
it so that I can go make sure
that they're all patched and

896
00:48:28,400 --> 00:48:32,266
using the latest version, are
useful in the -- today before we

897
00:48:32,333 --> 00:48:34,533
get to this world of
software supply chain.

898
00:48:34,599 --> 00:48:36,699
But at least for the projects
that you start up if you're

899
00:48:36,766 --> 00:48:40,099
producing open source, recommend
that you already start looking

900
00:48:40,166 --> 00:48:43,533
at getting SBOMs just
for your own hygiene.

901
00:48:46,066 --> 00:48:48,232
That's software
bill of materials.

902
00:48:48,233 --> 00:48:54,833
So brings me to one point I want
to make here, and that is the

903
00:48:54,900 --> 00:48:59,099
way that we look at open source
security is this isn't something

904
00:48:59,166 --> 00:49:02,099
that we want to differentiate
on when it comes to Azure.

905
00:49:02,166 --> 00:49:05,933
Really, our goal is to
lift all boats in the whole

906
00:49:06,000 --> 00:49:07,266
ecosystem here.

907
00:49:07,333 --> 00:49:10,533
This is why we're working with
a bunch of other companies,

908
00:49:10,599 --> 00:49:14,733
including some that I mentioned,
on this problem and why I'm here

909
00:49:14,800 --> 00:49:19,933
to socialize this problem and to
tell you that there are growing

910
00:49:20,000 --> 00:49:24,266
efforts across the industry that
you should be on the lookout for

911
00:49:24,333 --> 00:49:26,233
chances to participate in.

912
00:49:26,300 --> 00:49:29,866
The fact is that none of us are
competing on the security of

913
00:49:29,933 --> 00:49:30,766
open source.

914
00:49:30,833 --> 00:49:32,500
We all want to make it better.

915
00:49:32,566 --> 00:49:37,366
Making it better keeps us --
our software more healthy, our

916
00:49:37,433 --> 00:49:40,566
services more healthy, and keeps
our customers secure and healthy

917
00:49:40,633 --> 00:49:42,299
as well.

918
00:49:42,366 --> 00:49:45,599
Now just the concrete things you
should take away from this today

919
00:49:45,666 --> 00:49:48,933
besides the fact, knowledge
and the fact that things are

920
00:49:49,000 --> 00:49:51,666
happening and that you should be
looking out for ways that you

921
00:49:51,733 --> 00:49:53,766
can participate more
deeply in these things, like

922
00:49:53,833 --> 00:49:55,800
the SBOM effort.

923
00:49:55,866 --> 00:49:59,666
If you're producing open source
software -- actually, if you're

924
00:49:59,733 --> 00:50:05,599
doing anything with anything in
software or systems, enabled

925
00:50:05,666 --> 00:50:10,166
multifactor authentication, run
static analysis tools, onboard

926
00:50:10,233 --> 00:50:12,766
your project to
reproducible builds, understand

927
00:50:12,833 --> 00:50:15,266
your dependencies.

928
00:50:15,333 --> 00:50:21,666
And as a consumer, know what
you're consuming, automate the

929
00:50:21,733 --> 00:50:25,099
mapping of your open source
project dependencies, learn more

930
00:50:25,166 --> 00:50:26,466
about software
bill of materials.

931
00:50:26,533 --> 00:50:28,900
And this is a very
critical one, I think.

932
00:50:28,966 --> 00:50:31,033
If you've got a mission-critical
business where you need to be

933
00:50:31,099 --> 00:50:35,000
able to build something at
a moment's notice or you're

934
00:50:35,066 --> 00:50:38,299
building product and you need to
be able to update it regularly

935
00:50:38,366 --> 00:50:40,666
and you're dependent on upstream
open source is mirror those

936
00:50:40,733 --> 00:50:45,800
repos, mirror those
package repositories.

937
00:50:45,866 --> 00:50:47,400
That's one of the big
takeaways from that.

938
00:50:47,400 --> 00:50:51,166
That brings me to the
conclusion of the talk.

939
00:50:51,233 --> 00:50:53,266
I hope you found
this informative.

940
00:50:53,333 --> 00:50:56,633
I hope this opened your eyes if
you hadn't been aware of the

941
00:50:56,699 --> 00:51:01,066
kind of issues here that we need
to go address together, this is

942
00:51:01,133 --> 00:51:04,799
more real for you, and that
now you're walking away with

943
00:51:04,866 --> 00:51:07,933
something concrete to help your
open source security posture and

944
00:51:08,000 --> 00:51:12,500
even proprietary
security posture as well.

945
00:51:12,566 --> 00:51:16,832
But looking for, again, big
takeaway is participation from

946
00:51:16,900 --> 00:51:19,900
the whole ecosystem is required
to get us to a better place.

947
00:51:19,900 --> 00:51:21,833
With that, I want to
thank you very much.

948
00:51:21,900 --> 00:51:23,900
I hope you had a
great RSA conference.

949
00:51:23,966 --> 00:51:26,000
I hope you stay
healthy yourself.

950
00:51:26,066 --> 00:51:27,366
Thanks.

