1
00:00:00,313 --> 00:00:02,896
(upbeat music)

2
00:00:04,120 --> 00:00:06,920
- I believe policy truly
is the next frontier.

3
00:00:06,920 --> 00:00:08,390
I think the tech sector and general

4
00:00:08,390 --> 00:00:10,470
and cybersecurity
industry more specifically

5
00:00:10,470 --> 00:00:12,940
has made a huge mistake
in the last 20 years

6
00:00:12,940 --> 00:00:15,090
by not appreciating the
power of governments.

7
00:00:15,090 --> 00:00:16,440
Not just the power of governments

8
00:00:16,440 --> 00:00:18,210
and doing cyber operations,

9
00:00:18,210 --> 00:00:20,430
but the power of government to regulate us

10
00:00:20,430 --> 00:00:22,810
and make our lives very, very difficult.

11
00:00:22,810 --> 00:00:24,840
- The internet was invented to answer

12
00:00:24,840 --> 00:00:26,160
a very specific question:

13
00:00:26,160 --> 00:00:30,350
can you build a reliable
network out of unreliable parts?

14
00:00:30,350 --> 00:00:32,439
The answer turns out to be yes.

15
00:00:32,439 --> 00:00:33,879
There's a similar question

16
00:00:33,880 --> 00:00:36,320
that would be great if we could answer:

17
00:00:36,320 --> 00:00:38,540
can we build a trustworthy network

18
00:00:38,540 --> 00:00:40,560
out of untrustworthy parts?

19
00:00:40,560 --> 00:00:43,100
And I don't know if the
answer's yes or not,

20
00:00:43,100 --> 00:00:44,230
because we are gonna be living

21
00:00:44,230 --> 00:00:46,419
in a world of untrustworthy parts.

22
00:00:46,420 --> 00:00:49,010
And they might come from China,

23
00:00:49,010 --> 00:00:50,860
they might come from another country,

24
00:00:52,590 --> 00:00:54,973
they might be Swiss crypto equipment.

25
00:00:54,973 --> 00:00:56,190
(laughter)

26
00:00:56,190 --> 00:01:01,099
And yet we have to somehow
get trustworthiness

27
00:01:01,100 --> 00:01:03,810
out of that mishmash, and I think

28
00:01:03,810 --> 00:01:06,530
that's a research question that is

29
00:01:06,530 --> 00:01:09,090
major DARPA funding level,

30
00:01:09,090 --> 00:01:10,850
and something we should think about.

31
00:01:10,850 --> 00:01:13,621
- Watching HIPAA and PCI evolve

32
00:01:13,621 --> 00:01:18,107
that having those standards around data,

33
00:01:18,108 --> 00:01:22,470
having 50 different privacy
laws in 50 different states,

34
00:01:22,470 --> 00:01:25,710
that is not helpful, that
really is not helpful.

35
00:01:25,710 --> 00:01:27,529
And if we could get a standard

36
00:01:27,530 --> 00:01:30,653
around people data or healthcare data,

37
00:01:30,653 --> 00:01:33,640
from my perspective, I'm all in.

38
00:01:33,640 --> 00:01:35,860
- Healthcare is very unique.

39
00:01:35,860 --> 00:01:37,400
But genomic data in particular

40
00:01:37,400 --> 00:01:39,560
is an example of that uniqueness.

41
00:01:39,560 --> 00:01:41,010
And there's terms that are out there

42
00:01:41,010 --> 00:01:43,260
in the technology setting
around immutability

43
00:01:44,500 --> 00:01:46,750
and so forth and if you think about data

44
00:01:46,750 --> 00:01:49,687
and data persistency, genomic data

45
00:01:49,687 --> 00:01:52,399
is as relevant 100 years from now

46
00:01:52,400 --> 00:01:54,430
at an individual level as it is now.

47
00:01:54,430 --> 00:01:56,160
I'm being extreme in my thought process,

48
00:01:56,160 --> 00:01:58,679
but how then, do you think about

49
00:01:58,680 --> 00:02:01,220
to protect something where you don't know

50
00:02:01,220 --> 00:02:04,140
what the risks are in 50 to 100 years?

51
00:02:04,140 --> 00:02:06,340
And again, I'm being extreme
in my view for a point.

52
00:02:06,340 --> 00:02:09,449
- You know, all the concern is frequently

53
00:02:09,449 --> 00:02:10,810
what are they gonna do with my data?

54
00:02:10,810 --> 00:02:11,890
China's gonna take my data.

55
00:02:11,890 --> 00:02:14,119
They're building a database.

56
00:02:14,120 --> 00:02:15,440
We don't know what
they're gonna do with it

57
00:02:15,440 --> 00:02:17,283
and we haven't really talked about,

58
00:02:18,170 --> 00:02:19,850
we haven't had an answer in
the national conversation

59
00:02:19,850 --> 00:02:23,100
about what data constitutes
the national security risk,

60
00:02:23,100 --> 00:02:25,150
and part of the reason we don't know

61
00:02:25,150 --> 00:02:26,270
is because we don't know how data

62
00:02:26,270 --> 00:02:27,680
is gonna be used in the future.

63
00:02:27,680 --> 00:02:29,840
- It's my contention that the worlds

64
00:02:29,840 --> 00:02:31,860
of tech and policy are converging,

65
00:02:31,860 --> 00:02:35,113
that the tax code is now
becoming actual code,

66
00:02:36,190 --> 00:02:38,500
and that what were once purely systems

67
00:02:38,500 --> 00:02:40,853
are increasingly social technical systems.

68
00:02:41,750 --> 00:02:46,140
And as society's systems
become more complex,

69
00:02:46,140 --> 00:02:48,579
as the world looks more like a computer,

70
00:02:48,580 --> 00:02:52,453
our security skills become
more broadly applicable.

71
00:02:53,410 --> 00:02:55,299
This is a way that I think we can blend

72
00:02:55,300 --> 00:02:57,560
tech and policy in a new way.

73
00:02:57,560 --> 00:03:00,143
(upbeat music)

