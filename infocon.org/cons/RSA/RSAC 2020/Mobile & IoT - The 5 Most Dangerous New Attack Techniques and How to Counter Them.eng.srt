1
00:00:06,266 --> 00:00:08,166
>> ANNOUNCER: Please
welcome Research Director

2
00:00:08,233 --> 00:00:12,166
and Founder, SANS
Institute, Alan Paller.

3
00:00:20,166 --> 00:00:21,399
>> ALAN PALLER:
Good afternoon.

4
00:00:21,466 --> 00:00:23,500
This is my favorite
session of the year

5
00:00:23,566 --> 00:00:26,833
because this is the time
when I find out what the

6
00:00:26,899 --> 00:00:29,566
really dangerous new
things are that people are

7
00:00:29,633 --> 00:00:31,366
going to have
to deal with.

8
00:00:31,433 --> 00:00:35,200
And the reason it works is
that the three people you

9
00:00:35,266 --> 00:00:38,299
hear from each year are
the three people in the

10
00:00:38,366 --> 00:00:42,366
best position to actually
know what the new attacks are.

11
00:00:42,433 --> 00:00:47,033
We have Ed Skoudis first
who is the person brought

12
00:00:47,100 --> 00:00:51,799
in after more major
breaches than any other

13
00:00:51,866 --> 00:00:53,600
person in the world.

14
00:00:53,666 --> 00:00:55,632
And he translates -

15
00:00:56,399 --> 00:00:57,466
(Applause)

16
00:00:57,666 --> 00:00:58,233
That's nice.

17
00:00:58,299 --> 00:00:58,933
We don't have time.

18
00:00:59,000 --> 00:00:59,700
Don't clap.

19
00:00:59,766 --> 00:01:01,000
No.

20
00:01:01,066 --> 00:01:04,766
He translates those into
classes on hackers exploits and

21
00:01:04,833 --> 00:01:07,933
penetration testing, but
he also, the cooler part is

22
00:01:08,000 --> 00:01:10,966
he translates them into
ranges that thousands of

23
00:01:11,033 --> 00:01:13,599
military and other people
use, but he also does -

24
00:01:13,666 --> 00:01:16,399
many of you do the
holiday hack challenge.

25
00:01:16,466 --> 00:01:19,765
Fifteen thousand people do
this; free range he does.

26
00:01:19,833 --> 00:01:21,599
Ed knows how attacks work.

27
00:01:21,666 --> 00:01:24,500
Coming in after Ed
is Heather Mahalik.

28
00:01:24,566 --> 00:01:27,233
Heather is the person that
the US government and law

29
00:01:27,299 --> 00:01:29,666
enforcement brings in on
all the cases with the

30
00:01:29,733 --> 00:01:32,533
really hard mobile
forensics problems, what

31
00:01:32,599 --> 00:01:34,433
happened to these phones,
how do we get into the

32
00:01:34,500 --> 00:01:36,000
phones, what is going
on with the phones.

33
00:01:36,066 --> 00:01:39,633
That's what she does and
then she translates those

34
00:01:39,700 --> 00:01:42,766
into classes on mobile
forensics across all of

35
00:01:42,833 --> 00:01:45,099
the arenas and all of
the types of phones.

36
00:01:45,166 --> 00:01:49,098
And then finally,
Johannes Ullrich who is

37
00:01:49,166 --> 00:01:51,200
the head of the
Internet Storm Center.

38
00:01:51,266 --> 00:01:53,766
He is the person who does
that blog every morning

39
00:01:53,833 --> 00:01:56,966
that 11,000 of you listen
to on what the new attacks

40
00:01:57,033 --> 00:01:58,566
were yesterday.

41
00:01:58,633 --> 00:02:01,433
So, this is daily and he's
got sensors - a hundred

42
00:02:01,500 --> 00:02:03,200
thousand sensors
all over the world.

43
00:02:03,266 --> 00:02:05,400
People in lots of
time zones doing it.

44
00:02:05,466 --> 00:02:07,565
So, these are the three
people I know - there are

45
00:02:07,633 --> 00:02:09,299
more I expect, but these
are the three people I

46
00:02:09,366 --> 00:02:12,699
know who know how the
attacks are done.

47
00:02:12,766 --> 00:02:15,266
And so, they're going to
share with you exactly

48
00:02:15,333 --> 00:02:18,266
what they think are the
most dangerous new attacks.

49
00:02:18,333 --> 00:02:21,733
And we're going to start,
I think, with Ed Skoudis.

50
00:02:21,800 --> 00:02:22,400
>> ED SKOUDIS:
Thank you, Alan.

51
00:02:22,466 --> 00:02:24,300
I appreciate your
kind introduction.

52
00:02:24,366 --> 00:02:27,300
I would like to share with
you three specific areas

53
00:02:27,366 --> 00:02:29,666
that I'm increasingly
seeing in the cases that I

54
00:02:29,733 --> 00:02:33,400
work on and the various
incidents that I handle.

55
00:02:33,466 --> 00:02:35,466
Also, we're taking each of
these techniques and we're

56
00:02:35,533 --> 00:02:37,266
modelling it in the
penetration tests that

57
00:02:37,333 --> 00:02:41,133
we're doing, as well as
the red team exercises.

58
00:02:41,199 --> 00:02:42,699
The first of the three
items I would like to

59
00:02:42,766 --> 00:02:45,533
share with you is the
proliferation of command

60
00:02:45,599 --> 00:02:48,033
and control tools
and frameworks.

61
00:02:48,099 --> 00:02:50,232
We have really seen an
explosion in the kinds of

62
00:02:50,300 --> 00:02:52,866
tools available to
attackers as well as

63
00:02:52,933 --> 00:02:55,099
penetration testers
and red team analysts

64
00:02:55,166 --> 00:02:56,533
over the last year.

65
00:02:56,599 --> 00:02:59,366
There are dozens and
dozens of different tools

66
00:02:59,433 --> 00:03:01,900
that attackers can use to
control systems that they

67
00:03:01,966 --> 00:03:04,166
have compromised in
target environments.

68
00:03:04,233 --> 00:03:06,166
There are so many of these
tools, it can be hard to

69
00:03:06,233 --> 00:03:07,466
sort them out.

70
00:03:07,533 --> 00:03:10,000
That is why Jorge
Orchilles and a whole

71
00:03:10,066 --> 00:03:11,800
bunch of other volunteers
put together something

72
00:03:11,866 --> 00:03:13,366
called the C2 Matrix.

73
00:03:13,433 --> 00:03:15,566
The Command and
Control Matrix.

74
00:03:15,633 --> 00:03:19,099
This is a website where
can you go and analyze all

75
00:03:19,166 --> 00:03:21,500
the different command and
control channels that are

76
00:03:21,566 --> 00:03:24,166
publicly and freely
or even commercially

77
00:03:24,233 --> 00:03:27,000
available for attackers to
control their malware in a

78
00:03:27,066 --> 00:03:28,333
target environment.

79
00:03:28,400 --> 00:03:30,933
It lists all the different
tools and has an

80
00:03:31,000 --> 00:03:33,699
interactive display that
you can work your way

81
00:03:33,766 --> 00:03:36,399
through to see the
different feature sets,

82
00:03:36,466 --> 00:03:38,300
including different ways
to communicate across the

83
00:03:38,366 --> 00:03:43,966
network such as HTTPS,
HTTP2, HTTP3, ICMP,

84
00:03:44,033 --> 00:03:47,065
different control elements
like jitter, so it is not

85
00:03:47,133 --> 00:03:50,533
constantly beaconing out
at the same interval but

86
00:03:50,599 --> 00:03:51,533
instead you can adjust it.

87
00:03:51,599 --> 00:03:54,533
It is really a tremendous
learning tool to use

88
00:03:54,599 --> 00:03:56,433
the C2 Matrix.

89
00:03:56,500 --> 00:03:57,833
But how do you defend
against all of these

90
00:03:57,900 --> 00:03:59,933
different command
and control options?

91
00:04:00,000 --> 00:04:01,900
First, we need to
vigorously control

92
00:04:01,966 --> 00:04:04,066
outbound traffic from
our environments.

93
00:04:04,133 --> 00:04:06,533
Last year during the
SANS panel at the RSA

94
00:04:06,599 --> 00:04:08,866
Conference, I talked about
the tremendous free tool

95
00:04:08,933 --> 00:04:10,299
called RITA.

96
00:04:10,366 --> 00:04:12,400
RITA is a great tool from
Black Hills Information

97
00:04:12,466 --> 00:04:15,566
Security that looks at
network traffic to see if

98
00:04:15,633 --> 00:04:17,166
there is beaconing activity.

99
00:04:17,233 --> 00:04:18,699
But this year I want to
draw your attention to

100
00:04:18,766 --> 00:04:21,166
another wonderful free
tool that looks at

101
00:04:21,233 --> 00:04:23,500
activity on the end system
by going through the

102
00:04:23,566 --> 00:04:24,765
Windows event logs.

103
00:04:24,833 --> 00:04:26,899
I'm talking about
DeepBlueCLI by Eric Conrad.

104
00:04:26,966 --> 00:04:31,300
Again, a free tool that you
feed Windows event logs to.

105
00:04:31,366 --> 00:04:33,532
It goes to the tool and
provides heuristic analysts.

106
00:04:33,600 --> 00:04:37,433
Written in PowerShell,
it will tell you these

107
00:04:37,500 --> 00:04:39,833
particular events
look suspicious.

108
00:04:39,899 --> 00:04:42,233
It might be an example of
a password spraying attack

109
00:04:42,300 --> 00:04:43,733
or password
guessing attack.

110
00:04:43,800 --> 00:04:45,733
It might be an indication
of lateral movement

111
00:04:45,800 --> 00:04:47,666
throughout the
target environment.

112
00:04:47,733 --> 00:04:50,199
Additionally, to defend
against this proliferation

113
00:04:50,266 --> 00:04:53,199
of C2 frameworks,
application white listing

114
00:04:53,266 --> 00:04:55,733
goes a long way because it
limits what the attacker

115
00:04:55,800 --> 00:04:57,966
can run on the
target system.

116
00:04:58,033 --> 00:05:00,566
But let's think about this
from the attacker's perspective.

117
00:05:00,633 --> 00:05:02,733
So, as organizations are
increasingly deploying

118
00:05:02,800 --> 00:05:05,899
application white listing
and as their SOC analysts

119
00:05:05,966 --> 00:05:08,866
get more sophisticated,
the attackers want to

120
00:05:08,933 --> 00:05:11,366
evade those kinds
of controls.

121
00:05:11,433 --> 00:05:13,500
This moves to our second
topic that I would like to

122
00:05:13,566 --> 00:05:14,566
share with you.

123
00:05:14,633 --> 00:05:17,032
That is the concept of
living off the land.

124
00:05:17,100 --> 00:05:18,533
If you are an attacker,
what you could do is you

125
00:05:18,600 --> 00:05:21,166
could use the resources
of the operating system

126
00:05:21,233 --> 00:05:25,066
itself to attack that
machine and to spread to

127
00:05:25,133 --> 00:05:26,500
other systems in
the environment.

128
00:05:26,566 --> 00:05:28,399
You're living off the
land, using what is

129
00:05:28,466 --> 00:05:29,300
built in there.

130
00:05:29,366 --> 00:05:31,733
Essentially, you are using
the operating system as a

131
00:05:31,800 --> 00:05:34,800
root kit for the
operating system itself.

132
00:05:34,866 --> 00:05:37,099
There is a tremendous
project that summarizes

133
00:05:37,166 --> 00:05:39,100
the power of the
capabilities with living

134
00:05:39,166 --> 00:05:42,199
off the land attacks
called the LolBaS project,

135
00:05:42,266 --> 00:05:44,533
living off the land
binary and scripts.

136
00:05:44,600 --> 00:05:46,733
What it includes is over
one hundred different

137
00:05:46,800 --> 00:05:50,800
executables in Windows,
Linux and Mac OS that can

138
00:05:50,866 --> 00:05:54,133
be used to attack those
systems right from within.

139
00:05:54,199 --> 00:05:56,600
It is a tremendous
eye-opening thing and I

140
00:05:56,666 --> 00:05:58,332
encourage you to
check that out.

141
00:05:58,399 --> 00:06:00,699
In effect, what attackers
are doing is they're using

142
00:06:00,766 --> 00:06:02,800
the pieces of the
operating system to attack

143
00:06:02,866 --> 00:06:05,933
the operating system,
thinking about what a SOC

144
00:06:06,000 --> 00:06:09,133
analyst will interpret
when a SOC analyst looks

145
00:06:09,199 --> 00:06:10,766
at those events.

146
00:06:10,833 --> 00:06:14,000
In effect, the attacker
is social engineering the

147
00:06:14,066 --> 00:06:16,666
analyst by creating
effects that look like

148
00:06:16,733 --> 00:06:19,866
normal activity on the box
even though they're malicious.

149
00:06:19,933 --> 00:06:21,366
So, how can you
deal with this?

150
00:06:21,433 --> 00:06:22,399
LolBaS defenses.

151
00:06:22,466 --> 00:06:24,966
One of the big items
here is purple teaming.

152
00:06:25,033 --> 00:06:26,733
We have our blue teams
that are designed to

153
00:06:26,800 --> 00:06:29,466
defend our environments,
to detect attacks, to

154
00:06:29,533 --> 00:06:31,600
thwart the bad guys'
activities and to push

155
00:06:31,666 --> 00:06:32,800
them out of the
environment.

156
00:06:32,866 --> 00:06:34,966
We have our red teams
that are emulating our

157
00:06:35,033 --> 00:06:37,366
adversaries, trying to
get into the environment.

158
00:06:37,433 --> 00:06:39,800
The beauty of the purple
team is where we have the

159
00:06:39,866 --> 00:06:42,265
red team applying
activities like these live

160
00:06:42,333 --> 00:06:44,666
off the land attacks and
making sure the blue team

161
00:06:44,733 --> 00:06:47,000
can detect them and
respond to them effectively.

162
00:06:47,066 --> 00:06:48,032
Really tremendous.

163
00:06:48,100 --> 00:06:49,933
We also need to
carefully configure our

164
00:06:50,000 --> 00:06:52,233
application white listing,
going through with a

165
00:06:52,300 --> 00:06:54,699
fine-tooth comb and making
sure that we are only

166
00:06:54,766 --> 00:06:56,933
allowing things to run
that we have a vital

167
00:06:57,000 --> 00:06:59,033
business need for.

168
00:06:59,100 --> 00:07:00,699
The third element I
would like to share with

169
00:07:00,766 --> 00:07:03,333
you is very deep
persistence.

170
00:07:03,399 --> 00:07:05,466
If you go back several
years ago, there was a

171
00:07:05,533 --> 00:07:07,300
tool released called
the rubber ducky.

172
00:07:07,366 --> 00:07:08,933
I'm not talking about
the rubber ducky in your

173
00:07:09,000 --> 00:07:10,266
bathtub or
anything like that.

174
00:07:10,333 --> 00:07:13,833
I'm talking about a
malicious USB device.

175
00:07:13,899 --> 00:07:15,166
It's not a storage device.

176
00:07:15,233 --> 00:07:18,100
Instead, if you take this
device and plug it into

177
00:07:18,166 --> 00:07:20,600
the USB port of a
computer, it actually

178
00:07:20,666 --> 00:07:23,733
emulates a keyboard and
injects keystrokes into

179
00:07:23,800 --> 00:07:27,199
the system to launch a
terminal window, to type

180
00:07:27,266 --> 00:07:30,266
in malware, to save the
malware, and then to

181
00:07:30,333 --> 00:07:31,366
execute the malware.

182
00:07:31,433 --> 00:07:33,800
So, you simply plug this into the system and it infects it.

183
00:07:33,866 --> 00:07:34,466
Fair enough.

184
00:07:34,533 --> 00:07:36,233
That was technology
of years ago.

185
00:07:36,300 --> 00:07:40,866
But it has evolved such
that now we have attackers

186
00:07:40,933 --> 00:07:45,633
putting malware into
bespoke USB cables.

187
00:07:45,699 --> 00:07:48,066
So, you can buy these USB
cables where there is

188
00:07:48,133 --> 00:07:50,733
malware actually in
the cable itself.

189
00:07:50,800 --> 00:07:52,600
It behaves like a normal
USB cable, so you could

190
00:07:52,666 --> 00:07:55,233
use it to sync your phone,
to charge your phone, to

191
00:07:55,300 --> 00:07:56,633
charge your computer even.

192
00:07:56,699 --> 00:07:58,699
But if you plug that
into the computer, it

193
00:07:58,766 --> 00:08:01,233
implements rubber ducky
style functionality.

194
00:08:01,300 --> 00:08:04,300
There is a tool called USB
Ninja that implements this.

195
00:08:04,366 --> 00:08:05,500
Now, let me tell
you a story.

196
00:08:05,566 --> 00:08:08,066
I was walking around in
my front yard about six

197
00:08:08,133 --> 00:08:11,566
months ago and I saw a USB
cable just lying on the ground.

198
00:08:11,633 --> 00:08:12,233
It was a white one.

199
00:08:12,300 --> 00:08:13,633
It looked like it
was from Apple.

200
00:08:13,699 --> 00:08:14,800
And I have an
18-year-old son.

201
00:08:14,866 --> 00:08:16,500
I thought it was him or
maybe one of his friends

202
00:08:16,566 --> 00:08:18,765
that dropped
the USB cable.

203
00:08:18,833 --> 00:08:21,733
So, I picked it up and I
said oh, those darn kids.

204
00:08:21,800 --> 00:08:23,800
And then I thought about
maybe, maybe this is a

205
00:08:23,866 --> 00:08:25,066
malicious USB cable.

206
00:08:25,133 --> 00:08:26,799
So, what do you
do with that?

207
00:08:26,866 --> 00:08:28,933
You have to be
tremendously careful.

208
00:08:29,000 --> 00:08:32,366
If you find a USB cable in
an airport, it could be

209
00:08:32,433 --> 00:08:33,899
the cable itself
that hacks you.

210
00:08:33,966 --> 00:08:36,866
Think about this; the
persistence is in the wire.

211
00:08:36,933 --> 00:08:39,000
You eradicate the
malware from the system.

212
00:08:39,066 --> 00:08:40,766
The next time you go to
charge your phone or sync,

213
00:08:40,832 --> 00:08:44,100
it re-infects it,
persistence in the wire.

214
00:08:44,166 --> 00:08:46,666
And this opens up a much
bigger can of worms here

215
00:08:46,733 --> 00:08:49,065
because this could scale
up to entire supply chain

216
00:08:49,133 --> 00:08:50,866
attacks, right?

217
00:08:50,933 --> 00:08:53,399
There is the individual
issue of you trusting your

218
00:08:53,466 --> 00:08:55,799
wires but then your whole
organization, how can you

219
00:08:55,866 --> 00:08:58,799
trust any of the hardware
that you procure?

220
00:08:58,866 --> 00:09:00,866
From a defensive
perspective on this one,

221
00:09:00,933 --> 00:09:03,233
you need to exercise
personal protection, be

222
00:09:03,299 --> 00:09:06,266
careful with the devices
and even the wires that

223
00:09:06,333 --> 00:09:07,333
you might find.

224
00:09:07,399 --> 00:09:09,299
Make sure you buy them
from trusted sources.

225
00:09:09,366 --> 00:09:11,866
But from an enterprise
perspective, you need to

226
00:09:11,933 --> 00:09:14,233
think about your
supply chain.

227
00:09:14,299 --> 00:09:16,899
And there is a tremendous
work that is available

228
00:09:16,966 --> 00:09:20,399
from the UK and it talks
about strategies and

229
00:09:20,466 --> 00:09:24,433
particular tactics for you
to secure your supply chain.

230
00:09:24,500 --> 00:09:26,333
Now, given all that is
happening in the world

231
00:09:26,399 --> 00:09:30,600
these days, organizations
are very rapidly changing

232
00:09:30,666 --> 00:09:32,100
their supply chain
tactics, right?

233
00:09:32,166 --> 00:09:33,066
It is happening right now.

234
00:09:33,133 --> 00:09:35,000
Many of your organizations
are doing that in light of

235
00:09:35,066 --> 00:09:37,399
the medical conditions and
such that are happening.

236
00:09:37,466 --> 00:09:39,700
You need to do that from a
security perspective and

237
00:09:39,766 --> 00:09:42,399
with a security mindset,
not just kneejerk changing

238
00:09:42,466 --> 00:09:44,299
your supply chain to
something that might even

239
00:09:44,366 --> 00:09:45,333
be more vulnerable.

240
00:09:45,399 --> 00:09:48,233
I urge you to read this
wonderful document from

241
00:09:48,299 --> 00:09:50,433
the UK's National
Cybersecurity Center.

242
00:09:50,500 --> 00:09:52,399
So, that is what I wanted
to share with you.

243
00:09:52,466 --> 00:09:54,433
Let me turn it back
over to Alan Paller.

244
00:09:54,500 --> 00:09:56,266
>> ALAN PALLER:
Give that to Heather.

245
00:09:56,333 --> 00:09:57,132
Thank you, Ed.

246
00:09:57,200 --> 00:10:01,533
We'll give them accolades
at the end, but we have a

247
00:10:01,600 --> 00:10:02,433
question for you.

248
00:10:02,500 --> 00:10:08,000
Given what the danger is
in hardware now, is it at

249
00:10:08,066 --> 00:10:11,633
all possible to be sure
that any device made in a

250
00:10:11,700 --> 00:10:16,000
country with potentially
adversarial stance toward

251
00:10:16,066 --> 00:10:17,466
my country is safe?

252
00:10:17,533 --> 00:10:19,933
Is there any way to know if
I'm dealing with safe hardware?

253
00:10:20,000 --> 00:10:22,100
>> ED SKOUDIS: It is very
difficult in the extreme

254
00:10:22,166 --> 00:10:24,966
to know for sure that you
can trust your hardware.

255
00:10:25,033 --> 00:10:28,100
That said, you can ensure
your supply chain as much

256
00:10:28,166 --> 00:10:30,566
as you can and then have
good defensive controls

257
00:10:30,633 --> 00:10:32,966
and layered defenses so
that even if a given piece

258
00:10:33,033 --> 00:10:34,899
of hardware itself is
malicious and has some

259
00:10:34,966 --> 00:10:38,100
embedded functionality,
you can still detect it as

260
00:10:38,166 --> 00:10:40,000
they pivot to other things
in your environment.

261
00:10:40,066 --> 00:10:41,566
And furthermore,
attackers make mistakes.

262
00:10:41,633 --> 00:10:42,899
They're not perfect
just like we're not

263
00:10:42,966 --> 00:10:43,799
perfect as defenders.

264
00:10:43,866 --> 00:10:46,665
So, we can look for the
attacker's mistakes when

265
00:10:46,733 --> 00:10:47,632
they do that.

266
00:10:47,700 --> 00:10:50,433
>> ALAN PALLER: All right. Heather Mahalik is next.

267
00:10:50,500 --> 00:10:54,833
Heather is, as you know,
the expert on mobile

268
00:10:54,899 --> 00:10:57,766
device forensics
and mobile attacks.

269
00:10:57,833 --> 00:11:01,033
>> HEATHER MAHALIK:
Thank you. All right.

270
00:11:01,100 --> 00:11:03,700
So, before I dig in, I
want an honesty check from

271
00:11:03,766 --> 00:11:04,366
all of you.

272
00:11:04,433 --> 00:11:06,933
We have to set
the stage here.

273
00:11:07,000 --> 00:11:09,233
We are all addicted
to our mobile devices.

274
00:11:09,299 --> 00:11:12,665
This is the fight that I
have in my house every

275
00:11:12,733 --> 00:11:14,699
single day even with
the three-year-old.

276
00:11:14,766 --> 00:11:16,699
She wants to
be on the iPad.

277
00:11:16,766 --> 00:11:18,366
She wants my iPhone.

278
00:11:18,433 --> 00:11:20,000
She begs for you
to unlock it.

279
00:11:20,066 --> 00:11:23,366
My kids will even take my
phone and make me look at it.

280
00:11:23,433 --> 00:11:24,566
This is crazy.

281
00:11:24,633 --> 00:11:25,299
It is really crazy.

282
00:11:25,366 --> 00:11:26,133
But think about it.

283
00:11:26,200 --> 00:11:28,833
At work, at home,
we're entering our

284
00:11:28,899 --> 00:11:30,700
financial information.

285
00:11:30,766 --> 00:11:33,199
I just had to pay a
remaining balance for a

286
00:11:33,266 --> 00:11:34,065
vacation this summer.

287
00:11:34,133 --> 00:11:35,500
How do you think I did it?

288
00:11:35,566 --> 00:11:36,633
On my phone.

289
00:11:36,700 --> 00:11:39,200
It is actually annoying
to have to put down your

290
00:11:39,266 --> 00:11:41,266
phone and go to
your computer.

291
00:11:41,333 --> 00:11:43,333
So, everything we're
doing, taking pictures of

292
00:11:43,399 --> 00:11:45,866
our families, our
children, our vacation, it

293
00:11:45,933 --> 00:11:47,000
is all there.

294
00:11:47,066 --> 00:11:50,233
Now, this is really for
your entertainment.

295
00:11:50,299 --> 00:11:54,933
What I want us to think
about is what do we not do

296
00:11:55,000 --> 00:11:56,500
that involves our phones?

297
00:11:56,566 --> 00:11:57,799
We exercise.

298
00:11:57,866 --> 00:11:59,066
We take pictures of it.

299
00:11:59,133 --> 00:12:01,600
My husband, and he will
kill me for putting this

300
00:12:01,666 --> 00:12:03,933
out there on camera right
now, he will stop working

301
00:12:04,000 --> 00:12:05,600
out and start
calling people.

302
00:12:05,666 --> 00:12:06,466
And it blows my mind.

303
00:12:06,533 --> 00:12:07,899
I'm like, what
are you doing?

304
00:12:07,966 --> 00:12:09,633
Are you not working out?

305
00:12:09,700 --> 00:12:11,166
Or are you on the phone?

306
00:12:11,233 --> 00:12:14,532
People use them on the
go, while you're driving,

307
00:12:14,600 --> 00:12:15,200
obviously.

308
00:12:15,266 --> 00:12:16,733
That's a huge one.

309
00:12:16,799 --> 00:12:18,066
If you really want to
be entertained in the

310
00:12:18,133 --> 00:12:19,766
bathroom, you
know this is true.

311
00:12:19,833 --> 00:12:21,165
It's really gross.

312
00:12:21,233 --> 00:12:24,099
There is lots of hand sanitizer out there for everyone.

313
00:12:24,166 --> 00:12:27,633
But the addiction to
mobile is what makes them

314
00:12:27,700 --> 00:12:29,333
so vulnerable.

315
00:12:29,399 --> 00:12:30,833
Think about this.

316
00:12:30,899 --> 00:12:33,366
If you get into my phone,
you are getting so much

317
00:12:33,433 --> 00:12:35,566
more information than
probably if you got into

318
00:12:35,633 --> 00:12:39,399
my Mac, because I live
on my mobile device.

319
00:12:39,466 --> 00:12:41,466
So, that leads me to the
two attacks I am going to

320
00:12:41,533 --> 00:12:42,866
talk about with you.

321
00:12:42,933 --> 00:12:47,033
The first one, your phone
falls into the wrong hands.

322
00:12:47,100 --> 00:12:48,266
And this can
happen so easily.

323
00:12:48,333 --> 00:12:52,000
This could be that you
genuinely want to upgrade your

324
00:12:52,066 --> 00:12:55,733
phone, you turn it over to
your network service provider.

325
00:12:55,799 --> 00:12:58,299
Well, normally when
someone gets a refurbished

326
00:12:58,366 --> 00:13:02,466
phone - refurbished - what
if it is your old one that

327
00:13:02,533 --> 00:13:04,399
is not properly
reset or given out.

328
00:13:04,466 --> 00:13:06,000
That should be rare.

329
00:13:06,066 --> 00:13:07,866
But think about
the workplace.

330
00:13:07,933 --> 00:13:10,433
What happens if you have
an admin that does not

331
00:13:10,500 --> 00:13:13,600
properly sterilize the
phone after you turn it in

332
00:13:13,666 --> 00:13:15,166
and give it to
someone else?

333
00:13:15,233 --> 00:13:16,933
What can they get from it?

334
00:13:17,000 --> 00:13:19,466
This is where I want
to challenge you.

335
00:13:19,533 --> 00:13:22,866
If I pulled a fire alarm
right now and you had a

336
00:13:22,933 --> 00:13:25,133
choice, you have to leave
your wallet on your chair

337
00:13:25,200 --> 00:13:29,133
or your phone, which one
are you going to leave?

338
00:13:29,200 --> 00:13:31,000
I can guarantee you, I
would leave my entire

339
00:13:31,066 --> 00:13:35,000
backpack before I
would leave my phone.

340
00:13:35,066 --> 00:13:36,700
It is so vulnerable.

341
00:13:36,766 --> 00:13:39,099
And that's where people
don't think about it.

342
00:13:39,166 --> 00:13:42,033
How sure are you that no
one is going to get into

343
00:13:42,100 --> 00:13:43,066
your device?

344
00:13:43,133 --> 00:13:45,000
It's difficult.

345
00:13:45,066 --> 00:13:46,799
And even me, I do
this for a living.

346
00:13:46,866 --> 00:13:48,199
I live for mobile devices.

347
00:13:48,266 --> 00:13:51,099
I have been doing mobile
for eleven years straight.

348
00:13:51,166 --> 00:13:52,766
I would be terrified if
someone was like, let's

349
00:13:52,833 --> 00:13:56,100
try right now, let's see
if we can get into your phone.

350
00:13:56,166 --> 00:13:57,899
Now, why you should
be concerned?

351
00:13:57,966 --> 00:14:01,766
Who here has heard of
checkm8 and checkra1n?

352
00:14:01,833 --> 00:14:02,665
Good.

353
00:14:02,733 --> 00:14:04,266
There is not as many
hands as I thought but

354
00:14:04,333 --> 00:14:05,233
this is my world.

355
00:14:05,299 --> 00:14:09,500
I have been living in the
checkra1n/checkm8 world.

356
00:14:09,566 --> 00:14:12,333
Why this is a shock.

357
00:14:12,399 --> 00:14:16,799
It is the golden age for
attackers on iPhones and iPads.

358
00:14:16,866 --> 00:14:19,933
Most people who have Mac
devices assume they're

359
00:14:20,000 --> 00:14:21,733
really, really safe.

360
00:14:21,799 --> 00:14:23,966
It is known for security.

361
00:14:24,033 --> 00:14:25,233
The issue?

362
00:14:25,299 --> 00:14:29,399
There is a checkm8 exploit
that is in the chip - the

363
00:14:29,466 --> 00:14:30,799
chip of the device.

364
00:14:30,866 --> 00:14:33,566
So, what this means is
Apple would have to go

365
00:14:33,633 --> 00:14:34,899
back and say,
you know what?

366
00:14:34,966 --> 00:14:37,133
Raise your hand if you
have an iPhone 5 through

367
00:14:37,200 --> 00:14:37,966
an iPhone 10.

368
00:14:38,033 --> 00:14:39,299
Please come up here
and turn it in.

369
00:14:39,366 --> 00:14:41,966
We're going to give you
a brand-new iPhone 11.

370
00:14:42,033 --> 00:14:42,633
No.

371
00:14:42,700 --> 00:14:45,700
So, it cannot be patched.

372
00:14:45,766 --> 00:14:51,366
The jailbreak for that
exploit is called checkra1n.

373
00:14:51,433 --> 00:14:52,665
Checkra1n is free.

374
00:14:52,733 --> 00:14:54,333
Checkra1n is for everyone.

375
00:14:54,399 --> 00:14:57,233
All you need is a Mac
OS or Linux and you can

376
00:14:57,299 --> 00:14:59,399
jailbreak the device.

377
00:14:59,466 --> 00:15:02,633
So, this is why it is
really, really bad if your

378
00:15:02,700 --> 00:15:05,266
phone falls into
the wrong hands.

379
00:15:05,333 --> 00:15:08,565
Now, it is access we
haven't seen in a decade.

380
00:15:08,633 --> 00:15:10,700
This excited me
because I'm like yes.

381
00:15:10,766 --> 00:15:12,632
I'm going to get
everything I wanted off

382
00:15:12,700 --> 00:15:13,766
these iPhones.

383
00:15:13,833 --> 00:15:15,933
But it is terrifying
because what if you lose

384
00:15:16,000 --> 00:15:17,266
your device?

385
00:15:17,333 --> 00:15:20,000
So, that's bad
news number one.

386
00:15:20,066 --> 00:15:21,799
Bad news number two.

387
00:15:21,866 --> 00:15:24,799
Last year I stood on this
stage and I told you make

388
00:15:24,866 --> 00:15:26,933
sure you use two-factor
authentication.

389
00:15:27,000 --> 00:15:27,733
Make sure you use it.

390
00:15:27,799 --> 00:15:28,399
It is safe.

391
00:15:28,466 --> 00:15:29,833
It is protecting you.

392
00:15:29,899 --> 00:15:34,500
It is not protecting you
if it is simply just a code.

393
00:15:34,566 --> 00:15:35,466
So, think about this.

394
00:15:35,533 --> 00:15:40,466
This is a bad guy or girl
or woman or whoever it

395
00:15:40,533 --> 00:15:41,766
wants to be with
your device.

396
00:15:41,833 --> 00:15:43,833
It could be my
3-year-old, honestly.

397
00:15:43,899 --> 00:15:47,233
She has your phone and
she's sitting there.

398
00:15:47,299 --> 00:15:48,799
She has your phone number.

399
00:15:48,866 --> 00:15:52,600
All she needs is that code
so you get a simple text.

400
00:15:52,666 --> 00:15:58,133
That text can then go through and literally become you.

401
00:15:58,200 --> 00:15:59,399
So, let's say
this happened.

402
00:15:59,466 --> 00:16:02,933
And this actually happened
in a case a few months ago

403
00:16:03,000 --> 00:16:06,700
and then just three days
ago again I have seen this.

404
00:16:06,766 --> 00:16:08,699
You recycle your
phone number.

405
00:16:08,766 --> 00:16:10,933
So, let's say you move
from the West Coast to

406
00:16:11,000 --> 00:16:12,133
the East Coast.

407
00:16:12,200 --> 00:16:14,933
And your employer requires
you to have a number in

408
00:16:15,000 --> 00:16:16,166
that area code.

409
00:16:16,233 --> 00:16:17,799
So, you get a new device.

410
00:16:17,866 --> 00:16:20,133
Well, maybe Verizon
recycles your phone number

411
00:16:20,200 --> 00:16:21,533
to someone else.

412
00:16:21,600 --> 00:16:24,600
The issue is they
download WhatsApp.

413
00:16:24,666 --> 00:16:26,966
When they download
WhatsApp, they log in with

414
00:16:27,033 --> 00:16:30,100
their phone number which
is your old phone number.

415
00:16:30,166 --> 00:16:31,000
Guess what?

416
00:16:31,066 --> 00:16:33,600
They get the code, they
get all your messages.

417
00:16:33,666 --> 00:16:35,666
It loads completely
on their phone.

418
00:16:35,733 --> 00:16:36,933
It's terrifying.

419
00:16:37,000 --> 00:16:39,100
Maybe the person didn't -
they're not an attacker.

420
00:16:39,166 --> 00:16:41,166
They're not trying to do
it maliciously but what if

421
00:16:41,233 --> 00:16:42,233
they are?

422
00:16:42,299 --> 00:16:44,966
So, you have to be very,
very careful with this.

423
00:16:45,033 --> 00:16:47,899
What you really need
to do is do not use an

424
00:16:47,966 --> 00:16:51,100
application with anything
you care about, especially

425
00:16:51,166 --> 00:16:53,833
banking, that's one that
we have seen, if you also

426
00:16:53,899 --> 00:16:54,799
don't need a password.

427
00:16:54,866 --> 00:16:57,833
So, you want a password
and two-factor

428
00:16:57,899 --> 00:16:59,666
authentication to make
sure you're protected.

429
00:16:59,733 --> 00:17:03,399
If it is just one or the other, it is not a great scenario.

430
00:17:03,466 --> 00:17:05,299
So, what should you do?

431
00:17:05,366 --> 00:17:08,266
Everyone should go
buy an iPhone 11.

432
00:17:08,333 --> 00:17:09,566
I'm just kidding.

433
00:17:09,633 --> 00:17:12,799
And Apple is giving me
money for saying that.

434
00:17:12,866 --> 00:17:13,833
I'm just kidding.

435
00:17:13,900 --> 00:17:15,466
But protect your devices.

436
00:17:15,532 --> 00:17:17,933
They literally are
as important to you

437
00:17:18,000 --> 00:17:19,500
as your wallet.

438
00:17:19,566 --> 00:17:22,733
They are essentially
another extension of your body.

439
00:17:22,799 --> 00:17:25,665
They know everything
about you.

440
00:17:25,733 --> 00:17:29,633
Do not assume that your
data is not important enough.

441
00:17:29,700 --> 00:17:31,733
I used to always joke
I'm so boring, no one

442
00:17:31,799 --> 00:17:33,099
wants my information.

443
00:17:33,166 --> 00:17:34,466
Really?

444
00:17:34,533 --> 00:17:36,132
What about all your
financial stuff that's there?

445
00:17:36,200 --> 00:17:37,733
Lock your phone.

446
00:17:37,799 --> 00:17:39,566
If you do not lock your
phone, it should be taken

447
00:17:39,633 --> 00:17:40,900
away from you.

448
00:17:40,966 --> 00:17:42,966
You are so vulnerable.

449
00:17:43,033 --> 00:17:44,765
Please lock your devices.

450
00:17:44,833 --> 00:17:47,533
Keep remote
access enabled.

451
00:17:47,599 --> 00:17:48,599
So, think about this.

452
00:17:48,666 --> 00:17:51,033
If we did that fire drill
and you left and you chose

453
00:17:51,099 --> 00:17:53,765
to leave your phone and
I got it and then I go

454
00:17:53,833 --> 00:17:56,700
backstage with my friends
here and we're dumping

455
00:17:56,766 --> 00:17:59,433
your devices and putting
exploits on them, at least

456
00:17:59,500 --> 00:18:01,200
you could ping it
and see where it is.

457
00:18:01,266 --> 00:18:04,066
Maybe you could relock
it, try to stop further

458
00:18:04,133 --> 00:18:04,900
attacks from happening.

459
00:18:04,966 --> 00:18:07,099
So, make sure
you can do that.

460
00:18:07,166 --> 00:18:10,200
If you are going to quit
your job, recycle your

461
00:18:10,266 --> 00:18:15,299
device, give it to a
parent, wipe it first.

462
00:18:15,366 --> 00:18:18,233
But before you wipe it,
make sure it is encrypted.

463
00:18:18,299 --> 00:18:20,099
Because then at least all
the data that is wiped

464
00:18:20,166 --> 00:18:22,533
will be in an
encrypted state.

465
00:18:22,599 --> 00:18:25,533
Never, ever, ever dispose
of a device that has not

466
00:18:25,599 --> 00:18:26,533
been wiped.

467
00:18:26,599 --> 00:18:29,166
It blows my mind that
people actually do this.

468
00:18:29,233 --> 00:18:30,966
As far as your apps, and
I know that two-factor

469
00:18:31,033 --> 00:18:33,132
authentication makes
people nervous.

470
00:18:33,200 --> 00:18:35,566
If you are going to get a
new phone number, what I

471
00:18:35,633 --> 00:18:38,500
recommend you do is
log into every single

472
00:18:38,566 --> 00:18:41,500
application that uses
two-factor authentication

473
00:18:41,566 --> 00:18:43,666
and change it to your
brand-new number.

474
00:18:43,733 --> 00:18:46,200
Make sure you use
apps with a passcode.

475
00:18:46,266 --> 00:18:49,099
Be careful on what you are
oversharing - we're all

476
00:18:49,166 --> 00:18:51,733
putting way, way, way too
much out there - because

477
00:18:51,799 --> 00:18:56,366
you do not want to be the
reason you were attacked.

478
00:18:56,433 --> 00:18:57,799
Okay.

479
00:18:57,866 --> 00:18:59,299
Johannes.

480
00:18:59,366 --> 00:19:01,000
>> ALAN PALLER:
Johannes is next. Go ahead.

481
00:19:01,066 --> 00:19:02,133
So, this is
Johannes Ullrich.

482
00:19:02,200 --> 00:19:04,766
He runs the Internet Storm
Center and he is Research

483
00:19:04,833 --> 00:19:07,400
Director for the
SANS College.

484
00:19:07,466 --> 00:19:08,832
Go for it.

485
00:19:08,900 --> 00:19:10,000
>> JOHANNES ULLRICH:
Thank you very much for

486
00:19:10,066 --> 00:19:12,266
everybody coming here
on a Thursday afternoon.

487
00:19:12,333 --> 00:19:15,400
It always great to be here
and for you all to be here

488
00:19:15,466 --> 00:19:17,500
and also for Alan to
introducing and giving all

489
00:19:17,566 --> 00:19:19,033
of us the extra push here.

490
00:19:19,099 --> 00:19:21,265
What I want to talk about
is two attacks, first

491
00:19:21,333 --> 00:19:24,266
about some of the
insecurities we find in

492
00:19:24,333 --> 00:19:26,900
the enterprise perimeter.

493
00:19:26,966 --> 00:19:29,233
Now, what is a perimeter
is of course the first

494
00:19:29,299 --> 00:19:31,633
question, but
simplistically speaking,

495
00:19:31,700 --> 00:19:33,266
perimeter, pretty simple.

496
00:19:33,333 --> 00:19:36,233
It is supposed to let the
good guys in and keep the

497
00:19:36,299 --> 00:19:37,733
bad guys out.

498
00:19:37,799 --> 00:19:40,700
Now, the hard part is how
do you tell who is the

499
00:19:40,766 --> 00:19:42,033
good guy and who
is the bad guy?

500
00:19:42,099 --> 00:19:46,832
My dog always says she's
the best, but anyway.

501
00:19:46,900 --> 00:19:49,033
So, to facilitate this,
they added all of these

502
00:19:49,099 --> 00:19:50,533
features to these
perimeter devices.

503
00:19:50,599 --> 00:19:52,500
They added like, an
identity management.

504
00:19:52,566 --> 00:19:54,433
They added encryption.

505
00:19:54,500 --> 00:19:58,599
They added authentication,
all of the features got added.

506
00:19:58,666 --> 00:20:00,566
And then of course, we
wanted to have a nice

507
00:20:00,633 --> 00:20:03,233
web-based admin
interface and some Cloud

508
00:20:03,299 --> 00:20:05,833
connectivity sprinkled in
there to sort of keep up

509
00:20:05,900 --> 00:20:08,366
with the Jones's and the
competition with other

510
00:20:08,433 --> 00:20:10,133
perimeter devices.

511
00:20:10,200 --> 00:20:11,700
So, what's the problem?

512
00:20:11,766 --> 00:20:15,033
What we saw in particular
last year, that a lot of

513
00:20:15,099 --> 00:20:18,666
the vulnerabilities that
we usually see more sort

514
00:20:18,733 --> 00:20:23,599
of in the Soho realm of
these devices, they creep

515
00:20:23,666 --> 00:20:26,933
into our enterprise devices.

516
00:20:27,000 --> 00:20:29,700
That's really devastating
because yes, we don't

517
00:20:29,766 --> 00:20:32,933
admit it, but a lot of our
networks are still this

518
00:20:33,000 --> 00:20:35,400
crunchy shell,
soft interior.

519
00:20:35,466 --> 00:20:40,265
If I am getting into your
VPN concentrator, I own a

520
00:20:40,333 --> 00:20:42,666
good part of your
network if this happens.

521
00:20:42,733 --> 00:20:44,566
Part of the reason why
there is a renewed

522
00:20:44,633 --> 00:20:48,266
interest in this is Orange
Tsai and Meh Chang,

523
00:20:48,333 --> 00:20:50,833
they're two researchers
that really sort of went

524
00:20:50,900 --> 00:20:53,033
after some of these
vulnerabilities and others

525
00:20:53,099 --> 00:20:54,899
sort of followed them.

526
00:20:54,966 --> 00:20:57,132
It is quite easy
to find them.

527
00:20:57,200 --> 00:20:59,866
A lot of these devices,
they're not available as a

528
00:20:59,933 --> 00:21:02,000
virtual machine because
the vendor wants to be

529
00:21:02,066 --> 00:21:05,233
Cloud inclusive.

530
00:21:05,299 --> 00:21:07,566
So, they're downloading
the virtual machine,

531
00:21:07,633 --> 00:21:11,099
they're running it on
their desktop, and now they

532
00:21:11,166 --> 00:21:14,332
can nicely instrument it and find these vulnerabilities.

533
00:21:14,400 --> 00:21:15,866
Just a couple of examples.

534
00:21:15,933 --> 00:21:17,900
Pulse Connect Secure.

535
00:21:17,966 --> 00:21:19,466
The Pulse Connect
Secure vulnerability was

536
00:21:19,533 --> 00:21:20,733
found in April.

537
00:21:20,799 --> 00:21:23,400
July, the
exploit came out.

538
00:21:23,466 --> 00:21:28,299
It was used as recently as
in January of this year to

539
00:21:28,366 --> 00:21:32,299
install ransomware on
corporate networks.

540
00:21:32,366 --> 00:21:35,066
A very simple directory
traversal vulnerability.

541
00:21:35,133 --> 00:21:35,900
That's the other thing.

542
00:21:35,966 --> 00:21:37,799
A lot of these
vulnerabilities are fairly

543
00:21:37,866 --> 00:21:40,133
straightforward to
exploit, sort of web

544
00:21:40,200 --> 00:21:41,933
application vulnerabilities.

545
00:21:42,000 --> 00:21:44,566
You don't need to learn
like fancy byte code and

546
00:21:44,633 --> 00:21:46,766
stuff like this
Ed will teach you.

547
00:21:46,833 --> 00:21:49,200
All you need is a browser
and a YouTube video

548
00:21:49,266 --> 00:21:53,400
telling you what to type
to really make this work.

549
00:21:53,466 --> 00:21:54,733
Little bit different here.

550
00:21:54,799 --> 00:21:56,666
Palo Alto had a
problem like this.

551
00:21:56,733 --> 00:21:58,399
It started getting
exploited also like

552
00:21:58,466 --> 00:21:59,433
July last year.

553
00:21:59,500 --> 00:22:02,566
It was an old-fashioned
kind of format, string

554
00:22:02,633 --> 00:22:04,366
vulnerability
that they had.

555
00:22:04,433 --> 00:22:06,833
That is sort
of the big one.

556
00:22:06,900 --> 00:22:09,500
Just end of last year or
so, that kept us busy over

557
00:22:09,566 --> 00:22:10,799
the holidays.

558
00:22:10,866 --> 00:22:13,066
That's what security
people want, get away from

559
00:22:13,133 --> 00:22:15,266
the family, good
reason for that.

560
00:22:15,333 --> 00:22:20,900
But I pointed out the
code that was in part

561
00:22:20,966 --> 00:22:22,699
responsible for
this vulnerability.

562
00:22:22,766 --> 00:22:27,766
They commented out the input validation for the username.

563
00:22:30,533 --> 00:22:32,899
Yeah, we don't need to
know the username because

564
00:22:32,966 --> 00:22:35,299
we don't do authentication
actually anyway.

565
00:22:35,366 --> 00:22:37,333
We accept
whatever it takes.

566
00:22:37,400 --> 00:22:40,666
Now, the problem here was
that, that username could

567
00:22:40,733 --> 00:22:42,200
be turned into a file name.

568
00:22:42,266 --> 00:22:46,033
With that file name, I
could write any file.

569
00:22:46,099 --> 00:22:50,633
By writing any file, I can
execute any code on that system.

570
00:22:50,700 --> 00:22:53,466
Jason Lamb, he helped me
a lot, research some of

571
00:22:53,533 --> 00:22:55,666
this, like I said,
over the holidays.

572
00:22:55,733 --> 00:22:57,399
He put together some
videos of walking through

573
00:22:57,466 --> 00:22:59,199
some of this
vulnerability.

574
00:22:59,266 --> 00:23:01,533
Very straightforward
to exploit.

575
00:23:01,599 --> 00:23:04,899
It takes two or three web
requests depending on how

576
00:23:04,966 --> 00:23:09,233
you run it, a little
command line tool, and you

577
00:23:09,299 --> 00:23:12,666
get full access
to this device.

578
00:23:12,733 --> 00:23:16,366
Well, okay, how
do we fix this?

579
00:23:16,433 --> 00:23:20,966
Well, in the Soho world, I
always tell people don't

580
00:23:21,033 --> 00:23:24,033
allow access to the
admin interface.

581
00:23:24,099 --> 00:23:27,700
Great advice also for
enterprise tools but many

582
00:23:27,766 --> 00:23:29,966
of these vulnerabilities
are not linked to the

583
00:23:30,033 --> 00:23:31,000
admin interface.

584
00:23:31,066 --> 00:23:33,366
The Citrix vulnerability,
it is part of

585
00:23:33,433 --> 00:23:35,833
their VPN functionality.

586
00:23:35,900 --> 00:23:36,766
How do you block that?

587
00:23:36,833 --> 00:23:40,166
Well, we have a VPN to get
to the admin interface.

588
00:23:40,233 --> 00:23:43,033
So, I may have to get a
VPN to get to the VPN or

589
00:23:43,099 --> 00:23:45,000
how are we going to
protect ourselves?

590
00:23:45,066 --> 00:23:48,099
Stacking devices are not
always going to work.

591
00:23:48,166 --> 00:23:51,666
The best you can do here
is test this device a

592
00:23:51,733 --> 00:23:53,633
little bit yourself - the
vendors don't do this very

593
00:23:53,700 --> 00:23:59,466
well - and try to limit
your attack surface.

594
00:23:59,533 --> 00:24:02,765
Try to limit what features
you enable, if you can.

595
00:24:02,833 --> 00:24:04,866
At least you will reduce
the probability a little

596
00:24:04,933 --> 00:24:07,533
bit that the feature that
is going to be discovered

597
00:24:07,599 --> 00:24:11,332
to be vulnerable next
is going to be enabled

598
00:24:11,400 --> 00:24:13,400
on your device.

599
00:24:15,033 --> 00:24:18,533
Another issue that I want
to cover here is we have

600
00:24:18,599 --> 00:24:20,566
seen this also last year
pop up over and over.

601
00:24:20,633 --> 00:24:22,733
I observed this happening.

602
00:24:22,799 --> 00:24:27,500
Everything is better with
a web application, right?

603
00:24:27,566 --> 00:24:30,833
So, users love
web applications.

604
00:24:30,900 --> 00:24:33,799
I am going to my tech
support website for my

605
00:24:33,866 --> 00:24:37,299
laptop vendors and that
tech support website needs

606
00:24:37,366 --> 00:24:40,833
to know what process I'm
running, what software I'm

607
00:24:40,900 --> 00:24:41,666
running, all of this.

608
00:24:41,733 --> 00:24:43,733
The web browser doesn't
have access to that.

609
00:24:43,799 --> 00:24:47,666
To fix that, the
manufacturer preinstalled

610
00:24:47,733 --> 00:24:49,866
a little agent
on your laptop.

611
00:24:49,933 --> 00:24:53,000
The agent listens to HTTP
requests, so now the

612
00:24:53,066 --> 00:24:56,433
browser can send a
JavaScript triggered

613
00:24:56,500 --> 00:24:59,366
request to that agent and
request that information

614
00:24:59,433 --> 00:25:02,933
from that native application running on the system.

615
00:25:03,000 --> 00:25:04,033
Great.

616
00:25:04,099 --> 00:25:06,866
And this works but
sometimes even my dog, the

617
00:25:06,933 --> 00:25:12,799
best dog, is chasing cats
and ending up on bad websites.

618
00:25:12,866 --> 00:25:15,900
Those websites can then
load the same JavaScript

619
00:25:15,966 --> 00:25:18,166
that this tech
support website loaded

620
00:25:18,233 --> 00:25:19,599
and send requests.

621
00:25:19,666 --> 00:25:22,200
This has happened.

622
00:25:22,266 --> 00:25:23,733
Well, I'll just mention
the tech support case.

623
00:25:23,799 --> 00:25:27,599
Dell Tech Support Agent
preinstalled on many Dell

624
00:25:27,666 --> 00:25:30,166
computers had that
vulnerability.

625
00:25:30,233 --> 00:25:31,500
Zoom.

626
00:25:31,566 --> 00:25:33,700
Zoom wanted to
be easy to use.

627
00:25:33,766 --> 00:25:37,200
If I invite you to a video
conference, I send you a

628
00:25:37,266 --> 00:25:40,500
website with a link,
you click on the link.

629
00:25:40,566 --> 00:25:42,833
Again, there is a little
agent on your system that

630
00:25:42,900 --> 00:25:45,433
will start Zoom, that
video conferencing

631
00:25:45,500 --> 00:25:49,900
application, and allow you
to connect to my chat.

632
00:25:49,966 --> 00:25:51,866
At the same time, if you
are going to a malicious

633
00:25:51,933 --> 00:25:54,799
website, the malicious
website was about to

634
00:25:54,866 --> 00:25:58,099
connect to that website
via JavaScript and start a

635
00:25:58,166 --> 00:26:00,133
video conference with
you without you really

636
00:26:00,200 --> 00:26:02,966
realizing that someone is
watching you and listening

637
00:26:03,033 --> 00:26:05,332
in on you.

638
00:26:05,366 --> 00:26:07,900
This was a little bit made
worse by the simple fact

639
00:26:07,966 --> 00:26:10,933
that if you uninstalled
Zoom, you forgot to

640
00:26:11,000 --> 00:26:13,366
uninstall that agent.

641
00:26:13,433 --> 00:26:16,033
So, you still had that
software listening for

642
00:26:16,099 --> 00:26:19,466
requests that would
potentially trigger other

643
00:26:19,533 --> 00:26:22,632
software getting
started on your system.

644
00:26:22,700 --> 00:26:24,900
So, how do you fix this?

645
00:26:24,966 --> 00:26:25,765
Know what you are running.

646
00:26:25,833 --> 00:26:27,633
It is really enlightening.

647
00:26:27,700 --> 00:26:30,200
That little net stat, just
look at all the listeners

648
00:26:30,266 --> 00:26:31,666
on your system.

649
00:26:31,733 --> 00:26:33,433
I bet half of them you
don't recognize what

650
00:26:33,500 --> 00:26:35,266
they're doing or
why they're there.

651
00:26:35,333 --> 00:26:36,966
That doesn't mean they're
malicious or they're bad.

652
00:26:37,033 --> 00:26:39,000
Some of them are required
for the system to operate

653
00:26:39,066 --> 00:26:42,233
so don't just kill them
and call tech support.

654
00:26:42,299 --> 00:26:44,133
No, they can't
help you anymore.

655
00:26:44,200 --> 00:26:47,066
That is the first step.

656
00:26:47,133 --> 00:26:50,099
The other thing is if you
are writing software like

657
00:26:50,166 --> 00:26:52,299
this, the software that
receives the request has

658
00:26:52,366 --> 00:26:53,900
to check the origin.

659
00:26:53,966 --> 00:26:55,599
That is super,
super critical.

660
00:26:55,666 --> 00:26:59,433
HTTPS, which fixes all of
our other web application

661
00:26:59,500 --> 00:27:02,766
problems sort of, does
not help you here because

662
00:27:02,833 --> 00:27:04,200
you're dealing
on loop back.

663
00:27:04,266 --> 00:27:06,299
It can actually make
things worse because now

664
00:27:06,366 --> 00:27:08,466
you are putting that
certificate out there that

665
00:27:08,533 --> 00:27:10,199
everybody has on
their system anyway.

666
00:27:10,266 --> 00:27:12,099
That's all I have for you.

667
00:27:12,166 --> 00:27:13,265
And -

668
00:27:13,333 --> 00:27:14,500
>> ALAN PALLER: Keep it.

669
00:27:14,566 --> 00:27:17,900
The special part of this
session partly is hearing

670
00:27:17,966 --> 00:27:20,166
about the new things and
what to do about them.

671
00:27:20,233 --> 00:27:22,166
But the really special
part is your questions.

672
00:27:22,233 --> 00:27:27,265
And we - we - if you can
bring the questions slide up.

673
00:27:27,333 --> 00:27:31,066
We are going to take your
questions and do a blog of

674
00:27:31,133 --> 00:27:33,066
the answers to your
questions, but we wanted

675
00:27:33,133 --> 00:27:34,866
to make sure we had
enough questions.

676
00:27:34,933 --> 00:27:37,233
So, we did some test runs
of this in a couple of

677
00:27:37,299 --> 00:27:39,566
SANS classes and to the
community and we have

678
00:27:39,633 --> 00:27:41,200
gotten some wonderful
questions and I'm going to

679
00:27:41,266 --> 00:27:42,866
go through them and they
are going to answer them

680
00:27:42,933 --> 00:27:44,400
very quickly.

681
00:27:44,466 --> 00:27:47,033
But do send questions that
have come up in your mind

682
00:27:47,099 --> 00:27:48,133
on how do I do this?

683
00:27:48,200 --> 00:27:49,733
Does this
actually fit this?

684
00:27:49,799 --> 00:27:50,866
Will it work here?

685
00:27:50,933 --> 00:27:53,433
That is where the extra
value of their talk is, is

686
00:27:53,500 --> 00:27:56,666
in giving you answers to the questions and how they apply.

687
00:27:56,733 --> 00:27:59,733
Let's start with Heather.

688
00:27:59,799 --> 00:28:02,266
You were talking about some exploits that are really bad.

689
00:28:02,333 --> 00:28:05,466
Can any of them be used by
forensics investigators to

690
00:28:05,533 --> 00:28:08,632
actually make their job -
you guys' job a lot easier.

691
00:28:08,700 --> 00:28:10,833
>> HEATHER MAHALIK:
I'm glad you asked. Absolutely.

692
00:28:10,900 --> 00:28:13,200
This is something that is
hard for a lot of people

693
00:28:13,266 --> 00:28:15,700
to understand; what can be
used for evil can also be

694
00:28:15,766 --> 00:28:16,933
used for good.

695
00:28:17,000 --> 00:28:19,433
So, you have to consider
things like jailbreak can

696
00:28:19,500 --> 00:28:22,299
get you full file system
access to the iPhone which

697
00:28:22,366 --> 00:28:24,500
would then let you be able
to get application usage

698
00:28:24,566 --> 00:28:27,366
logs, different system
logs, and things that we

699
00:28:27,433 --> 00:28:28,233
wouldn't see otherwise.

700
00:28:28,299 --> 00:28:29,200
So, absolutely.

701
00:28:29,266 --> 00:28:32,700
It can be used and it
is being used that way.

702
00:28:32,766 --> 00:28:34,766
>> ALAN PALLER: Johannes,
how do I know when it is

703
00:28:34,833 --> 00:28:36,533
time to patch
the firewall?

704
00:28:36,599 --> 00:28:39,033
We don't pay attention
that often, or the VPN or

705
00:28:39,099 --> 00:28:40,166
load balancer.

706
00:28:40,233 --> 00:28:42,765
How do I keep up to
date enough to know?

707
00:28:42,833 --> 00:28:44,133
>> JOHANNES ULLRICH: What
you definitely need to do,

708
00:28:44,200 --> 00:28:46,200
not just with these
devices, all devices,

709
00:28:46,266 --> 00:28:48,666
figure out how the
vendor will notify you.

710
00:28:48,733 --> 00:28:50,866
So, sign up for the
right mailing list.

711
00:28:50,933 --> 00:28:54,533
They usually have some mailing lists where they do that.

712
00:28:54,599 --> 00:28:57,399
Include it in your
vulnerability management system.

713
00:28:57,466 --> 00:28:59,466
It can be quite tricky
to update some of these

714
00:28:59,533 --> 00:29:01,765
devices because the down
time on the perimeter

715
00:29:01,833 --> 00:29:03,733
means the network
is kind of down.

716
00:29:03,799 --> 00:29:07,033
So, get ready for that.

717
00:29:07,099 --> 00:29:09,099
Run some tests and make
sure that you are able to

718
00:29:09,166 --> 00:29:11,299
respond quickly when
this happens because

719
00:29:11,366 --> 00:29:13,566
particularly, these
easy web application

720
00:29:13,633 --> 00:29:15,766
vulnerabilities, they're
so quickly exploited after

721
00:29:15,833 --> 00:29:17,866
a vulnerability is known.

722
00:29:17,933 --> 00:29:20,099
>> ALAN PALLER: And Ed,
with EC2s, does that mean

723
00:29:20,166 --> 00:29:23,099
companies have to do full
packet inspection of the

724
00:29:23,166 --> 00:29:25,200
proxy level which I don't
think is possible as

725
00:29:25,266 --> 00:29:27,266
everybody is going to
encrypted traffic?

726
00:29:27,333 --> 00:29:29,599
So, are we sort
of life's a bitch?

727
00:29:29,666 --> 00:29:31,066
>> ED SKOUDIS: No,
we're not doomed.

728
00:29:31,133 --> 00:29:32,466
We're not doomed.

729
00:29:32,533 --> 00:29:35,199
So, there are behavioral
patterns that you see on

730
00:29:35,266 --> 00:29:36,833
the network associated
with malware.

731
00:29:36,900 --> 00:29:40,333
So, deep packet inspection
where you can, but often

732
00:29:40,400 --> 00:29:41,833
you can't because
of encryption.

733
00:29:41,900 --> 00:29:44,799
But you can look for other
anomalies on the network

734
00:29:44,866 --> 00:29:46,566
like this beaconing activity.

735
00:29:46,633 --> 00:29:48,599
Also, don't forget there
is log activity, so on the

736
00:29:48,666 --> 00:29:50,433
end systems you can
pull information.

737
00:29:50,500 --> 00:29:52,733
We do have options for
detecting this stuff.

738
00:29:52,799 --> 00:29:54,866
>> ALAN PALLER: Cool.
All right. Back to Heather.

739
00:29:54,933 --> 00:29:57,866
Is my device at risk
if it is up to date?

740
00:29:57,933 --> 00:30:00,500
It has the latest
hardware, latest firmware;

741
00:30:00,566 --> 00:30:02,366
aren't I okay?

742
00:30:02,433 --> 00:30:03,700
>> HEATHER MAHALIK:
You are at risk.

743
00:30:03,766 --> 00:30:04,799
That's unfortunate.

744
00:30:04,866 --> 00:30:07,133
Actually, if you have an
Android that is fully

745
00:30:07,200 --> 00:30:09,900
patched, fully up to date,
you are safer than if you

746
00:30:09,966 --> 00:30:13,832
have an iPhone 10 running
the latest iOS version.

747
00:30:13,900 --> 00:30:16,166
>> ALAN PALLER: And
you heard it here.

748
00:30:16,233 --> 00:30:19,533
Johannes, how about AV,
antivirus, will it protect

749
00:30:19,599 --> 00:30:22,366
against JavaScript attack
to local host APIs?

750
00:30:22,433 --> 00:30:24,633
And if not, what do I
do to protect against

751
00:30:24,700 --> 00:30:27,566
JavaScript attacks
on localhost APIs.

752
00:30:27,633 --> 00:30:30,666
>> JOHANNES ULLRICH: So,
JavaScript is - sometimes

753
00:30:30,733 --> 00:30:34,299
the malicious JavaScript
is sometimes detected by AV.

754
00:30:34,366 --> 00:30:37,299
But typically, fairly
easily also obfuscated

755
00:30:37,366 --> 00:30:39,700
where AV will not
detect it anymore.

756
00:30:39,766 --> 00:30:41,900
Typically, only the types
of the canned exploits

757
00:30:41,966 --> 00:30:44,199
that people sometimes
inject in sites.

758
00:30:44,266 --> 00:30:46,099
Other than that, there is
not really much you can do

759
00:30:46,166 --> 00:30:48,933
other than disable the
APIs that may be running

760
00:30:49,000 --> 00:30:50,000
on your system.

761
00:30:50,066 --> 00:30:51,799
Of course, don't write
software that doesn't

762
00:30:51,866 --> 00:30:53,200
check the origin.

763
00:30:53,266 --> 00:30:55,833
As a consumer, there is not
much you can do about that.

764
00:30:55,900 --> 00:30:58,000
>> ALAN PALLER: Ed, I'm
not sure I agree with this

765
00:30:58,066 --> 00:30:59,366
question, but anyway.

766
00:30:59,433 --> 00:31:01,666
How will application white
listing help when binaries

767
00:31:01,733 --> 00:31:05,200
have to be allowed for
normal function of the system?

768
00:31:05,266 --> 00:31:06,900
>> ED SKOUDIS: So, you do
have to run normal binaries.

769
00:31:06,966 --> 00:31:08,265
I mean, that is why
the system exists.

770
00:31:08,333 --> 00:31:11,466
It is really putting the attacker in a straitjacket.

771
00:31:11,533 --> 00:31:13,466
So, it is limiting what
the attacker can do which

772
00:31:13,533 --> 00:31:17,366
will force the attacker's
hand to maybe cause some

773
00:31:17,433 --> 00:31:19,133
activity to happen on the
system that you'll catch

774
00:31:19,200 --> 00:31:21,466
in the logs or a
user might observe.

775
00:31:21,533 --> 00:31:23,832
So, by limiting what the
attacker can do, it forces

776
00:31:23,900 --> 00:31:24,599
the attacker
sometimes to -

777
00:31:24,666 --> 00:31:26,166
>> ALAN PALLER: To
raise their head over.

778
00:31:26,233 --> 00:31:29,832
>> ED SKOUDIS: Exactly. To behave more aggressively.

779
00:31:29,900 --> 00:31:32,766
>> ALAN PALLER: Heather
oh, that number.

780
00:31:32,833 --> 00:31:35,000
Two-factor authentication
works well until it is

781
00:31:35,066 --> 00:31:36,866
time to get a new
device you said.

782
00:31:36,933 --> 00:31:39,200
Any tips for making it
easier to move two-factor

783
00:31:39,266 --> 00:31:41,733
authentication tokens to
a new device, especially

784
00:31:41,799 --> 00:31:43,799
between Android and iOS?

785
00:31:43,866 --> 00:31:45,599
>> HEATHER MAHALIK: Yeah,
so anytime - if you are

786
00:31:45,666 --> 00:31:49,200
getting a new phone
number, you really need to

787
00:31:49,266 --> 00:31:52,366
factor in the two-factor
that you're using and

788
00:31:52,433 --> 00:31:55,133
literally log out of those
and make sure you associate

789
00:31:55,200 --> 00:31:57,733
your new phone number
and then you should be safe.

790
00:31:57,799 --> 00:32:01,166
Also, make sure you have a
password backing up or the

791
00:32:01,233 --> 00:32:03,700
foreground of the
two-factor authentication.

792
00:32:03,766 --> 00:32:04,933
>> ALAN PALLER: Cool.

793
00:32:05,000 --> 00:32:06,633
What testing - this is for
Johannes - what testing

794
00:32:06,700 --> 00:32:09,966
can an end user perform to
find the vulnerabilities

795
00:32:10,033 --> 00:32:11,466
you were talking about?

796
00:32:11,533 --> 00:32:13,199
>> JOHANNES ULLRICH:
Standard web application

797
00:32:13,266 --> 00:32:14,233
pen testing, essentially.

798
00:32:14,299 --> 00:32:16,133
The nice thing, of course,
is that you typically own

799
00:32:16,200 --> 00:32:19,099
these devices, you run
them in your own network.

800
00:32:19,166 --> 00:32:22,299
So, the risk of performing
these tests is lower if

801
00:32:22,366 --> 00:32:25,733
you do it before you actually deploy the live device.

802
00:32:25,799 --> 00:32:28,299
That is probably something
you can do as a due

803
00:32:28,366 --> 00:32:30,200
diligence, not clear of
course, how much you will

804
00:32:30,266 --> 00:32:33,766
find there, but some of
these vulnerabilities

805
00:32:33,833 --> 00:32:36,799
sadly happen, fairly low
hanging fruit that you may

806
00:32:36,866 --> 00:32:40,366
find with some simple
straightforward web

807
00:32:40,433 --> 00:32:41,833
application pen testing.

808
00:32:41,900 --> 00:32:43,566
>> ALAN PALLER: Would you
recommend they do it?

809
00:32:43,633 --> 00:32:44,666
>> JOHANNES ULLRICH: Sorry?

810
00:32:44,733 --> 00:32:46,033
>> ALAN PALLER: Would you
recommend that they do it?

811
00:32:46,099 --> 00:32:47,000
>> JOHANNES ULLRICH: Oh, I
would absolutely recommend it.

812
00:32:47,066 --> 00:32:48,000
It is a ton of
fun to do that.

813
00:32:49,200 --> 00:32:50,266
(Laughter)

814
00:32:51,266 --> 00:32:52,433
>> ALAN PALLER: All right.

815
00:32:52,500 --> 00:32:56,266
Ed, how useful are
endpoint detection tools,

816
00:32:56,333 --> 00:32:58,900
very big sellers
right now, against C2

817
00:32:58,966 --> 00:33:03,366
communication and abuse of living off the land binaries?

818
00:33:03,433 --> 00:33:05,433
>> ED SKOUDIS: So,
endpoint tools are

819
00:33:05,500 --> 00:33:06,733
increasing their
game there.

820
00:33:06,799 --> 00:33:07,599
They're trying.

821
00:33:07,666 --> 00:33:09,433
It is behavior,
behavior, behavior.

822
00:33:09,500 --> 00:33:11,700
The attackers are getting
so stealthy and you know,

823
00:33:11,766 --> 00:33:13,733
signature-based matching
only goes so far.

824
00:33:13,799 --> 00:33:16,566
But the endpoint security
tools are ramping up their

825
00:33:16,633 --> 00:33:18,900
game by looking for
anomalous behaviors that

826
00:33:18,966 --> 00:33:21,599
the attackers are throwing
through these LolBaS

827
00:33:21,666 --> 00:33:24,466
executables and scripts as
well as all of the other things

828
00:33:24,533 --> 00:33:26,199
that they're manipulating
on the end system.

829
00:33:26,266 --> 00:33:28,033
There are certain things
the attackers are doing,

830
00:33:28,099 --> 00:33:30,200
the behaviors that they're
throwing, and the endpoint

831
00:33:30,266 --> 00:33:31,433
security suites
are really -

832
00:33:31,500 --> 00:33:32,766
>> ALAN PALLER:
You're seeing them?

833
00:33:32,833 --> 00:33:33,733
So, they're
getting better?

834
00:33:33,799 --> 00:33:34,633
>> ED SKOUDIS:
They really are.

835
00:33:34,700 --> 00:33:35,466
>> ALAN PALLER:
Great investment?

836
00:33:35,533 --> 00:33:36,265
>> ED SKOUDIS:
It is. Yeah.

837
00:33:36,333 --> 00:33:37,400
>> ALAN PALLER:
All right. Cool.

838
00:33:37,466 --> 00:33:40,233
I don't want that
page anymore.

839
00:33:40,299 --> 00:33:42,066
Heather, number four.

840
00:33:42,133 --> 00:33:45,966
Is vendor built-in mobile
device encryption, so the

841
00:33:46,033 --> 00:33:49,299
stuff you can buy from
your mobile device vendor,

842
00:33:49,366 --> 00:33:51,700
enough to protect against
everyday attackers?

843
00:33:53,733 --> 00:33:55,200
>> HEATHER MAHALIK: So,
that's where it depends.

844
00:33:55,266 --> 00:33:56,900
When it comes to
encryption, if you're

845
00:33:56,966 --> 00:33:58,832
going with file-based
encryption that comes with

846
00:33:58,900 --> 00:34:01,799
your Android and full disc
encryption or file-based

847
00:34:01,866 --> 00:34:05,900
encryption on iOS, if you
have a password, if you

848
00:34:05,966 --> 00:34:09,033
keep that device in your
control, if you make sure

849
00:34:09,099 --> 00:34:11,400
you have remote access
to it, it is good enough

850
00:34:11,466 --> 00:34:12,665
unless you lose it.

851
00:34:12,733 --> 00:34:15,333
That is where you
really are at risk.

852
00:34:15,400 --> 00:34:17,433
>> ALAN PALLER:
That makes sense. Okay.

853
00:34:17,500 --> 00:34:21,065
Johannes, what should the
vendors do to avoid the

854
00:34:21,132 --> 00:34:22,933
problems you have
been talking about?

855
00:34:23,000 --> 00:34:24,199
Not the users
but the vendors.

856
00:34:24,266 --> 00:34:25,900
>> JOHANNES ULLRICH: I
think the vendors, one of

857
00:34:25,966 --> 00:34:29,033
the big problems, that is
what we all have in IT,

858
00:34:29,099 --> 00:34:30,666
is legacy code.

859
00:34:30,733 --> 00:34:32,800
When I look at some of
the code that I have seen

860
00:34:32,866 --> 00:34:35,433
there and I sort of quoted
up here, that looks pretty

861
00:34:35,500 --> 00:34:39,199
much like code that I
wrote twenty years ago and

862
00:34:39,266 --> 00:34:41,566
the mistakes I
made back then.

863
00:34:41,632 --> 00:34:46,198
So, you can't just keep
building on top of those

864
00:34:46,266 --> 00:34:47,566
fairly weak and
old foundations.

865
00:34:47,632 --> 00:34:50,966
You have to go back and
redo thorough code reviews

866
00:34:51,033 --> 00:34:53,033
occasionally
of the legacy.

867
00:34:53,099 --> 00:34:53,900
It is hard.

868
00:34:53,966 --> 00:34:55,933
It is a hard problem
that a lot of software

869
00:34:56,000 --> 00:34:59,833
developers have is how
to deal with that legacy code.

870
00:34:59,900 --> 00:35:01,566
But it's something you
have to do in order to

871
00:35:01,633 --> 00:35:04,500
really keep the security
of these devices up to date.

872
00:35:04,566 --> 00:35:06,000
>> ALAN PALLER: Okay.

873
00:35:06,066 --> 00:35:08,533
Ed, for smaller
organizations - and if you

874
00:35:08,599 --> 00:35:09,933
are thinking about
questions and you really

875
00:35:10,000 --> 00:35:12,966
want the answers,
q@sans.org and we'll get

876
00:35:13,033 --> 00:35:14,366
it in the blog.

877
00:35:14,433 --> 00:35:17,233
So, please, because we're not asking all the good questions.

878
00:35:17,300 --> 00:35:19,800
Ed, for smaller
organizations, how much

879
00:35:19,866 --> 00:35:23,333
tuning is required to
detect the C2 channels

880
00:35:23,400 --> 00:35:26,033
well or is this something
a vendor can package up if

881
00:35:26,099 --> 00:35:28,500
you don't have the internal resources to management?

882
00:35:28,566 --> 00:35:30,566
Do the MSSPs do it well?

883
00:35:30,633 --> 00:35:31,665
Where do I get this?

884
00:35:31,733 --> 00:35:32,933
>> ED SKOUDIS: Things are
getting better but those

885
00:35:33,000 --> 00:35:34,666
tools, the one that I
mentioned last year and

886
00:35:34,733 --> 00:35:36,433
the one that I mentioned
this year are free tools

887
00:35:36,500 --> 00:35:38,833
that even small
organizations can use and

888
00:35:38,900 --> 00:35:41,133
they are looking heuristically for these anomalies.

889
00:35:41,199 --> 00:35:43,800
I'm talking about the RITA
tool which looks at the

890
00:35:43,866 --> 00:35:46,166
network traffic and some
logs to see what is

891
00:35:46,233 --> 00:35:49,599
happening as well as
that DeepBlueCLI tool.

892
00:35:49,666 --> 00:35:51,933
They're really tremendous
and you don't tune them.

893
00:35:52,000 --> 00:35:53,800
You just run them and
they tell you, hey,

894
00:35:53,866 --> 00:35:55,833
this looks suspicious.

895
00:35:55,900 --> 00:35:57,733
>> ALAN PALLER: Sometimes
people like you say you

896
00:35:57,800 --> 00:35:59,900
can run the tool but you
have to be a wizard to

897
00:35:59,966 --> 00:36:02,066
read the output of it.

898
00:36:02,133 --> 00:36:04,133
>> ED SKOUDIS: Right. I specifically bring up those

899
00:36:04,199 --> 00:36:07,366
tools because the output
is very clear and easily

900
00:36:07,433 --> 00:36:08,699
understood by a
technical person.

901
00:36:08,766 --> 00:36:10,366
I mean, they're not
designed for nontechnical

902
00:36:10,433 --> 00:36:12,033
people but that said,
they're really quite

903
00:36:12,099 --> 00:36:15,333
simple to use and there
are wonderful tutorials

904
00:36:15,400 --> 00:36:18,233
released to walk you
through the use of RITA or

905
00:36:18,300 --> 00:36:20,666
through the use
of DeepBlueCLI.

906
00:36:20,733 --> 00:36:22,866
>> ALAN PALLER: On YouTube
or with the product?

907
00:36:22,933 --> 00:36:25,733
>> ED SKOUDIS: With the tools themselves, yeah, written.

908
00:36:25,800 --> 00:36:29,533
>> ALAN PALLER: Heather,
my employer has a bring

909
00:36:29,599 --> 00:36:31,000
your own device program.

910
00:36:31,066 --> 00:36:34,198
How much access are they
legally able to demand

911
00:36:34,266 --> 00:36:35,466
of my phone?

912
00:36:35,533 --> 00:36:37,066
My personal phone?

913
00:36:37,133 --> 00:36:38,265
Did I do that right?

914
00:36:38,333 --> 00:36:39,866
>> HEATHER MAHALIK: Yes,
yeah. That's a tricky one.

915
00:36:39,933 --> 00:36:42,199
So, I would say what
have you signed?

916
00:36:42,266 --> 00:36:43,666
What have you signed
in an agreement?

917
00:36:43,733 --> 00:36:46,199
I have worked places where
people have paid for my

918
00:36:46,266 --> 00:36:49,666
phone every month, but I
signed nothing saying they

919
00:36:49,733 --> 00:36:51,666
had any rights to it which
I can guarantee you, if

920
00:36:51,733 --> 00:36:53,733
they wanted it, I would
wipe it and then say

921
00:36:53,800 --> 00:36:54,833
here you go.

922
00:36:54,900 --> 00:36:57,300
But if you signed that
your employer has rights

923
00:36:57,366 --> 00:37:00,000
to your personal device,
I would keep business and

924
00:37:00,066 --> 00:37:02,000
personal completely
separate and assume that

925
00:37:02,066 --> 00:37:03,198
they can see anything.

926
00:37:03,266 --> 00:37:04,966
>> ALAN PALLER: Okay.

927
00:37:05,033 --> 00:37:07,133
Johannes, there are some
efforts underway to give

928
00:37:07,199 --> 00:37:10,433
JavaScript more and more
power over hardware

929
00:37:10,500 --> 00:37:11,933
like the USB.

930
00:37:12,000 --> 00:37:14,233
Will this avoid some
of the need for these

931
00:37:14,300 --> 00:37:17,366
insecure APIs or does
it just introduce a new

932
00:37:17,433 --> 00:37:18,833
class of problem?

933
00:37:18,900 --> 00:37:21,300
>> JOHANNES ULLRICH: Yeah,
so what is happening, a

934
00:37:21,366 --> 00:37:23,199
little bit of a trend
where the trend where the

935
00:37:23,266 --> 00:37:24,833
browser becomes a new
operating system.

936
00:37:24,900 --> 00:37:26,833
Of course, Google Chrome
is sort of baked - with

937
00:37:26,900 --> 00:37:28,266
Chrome OS and such.

938
00:37:28,333 --> 00:37:30,033
Of course, with that, the
browser needs to have

939
00:37:30,099 --> 00:37:32,566
access to like USB and
a lot of the sensors.

940
00:37:32,633 --> 00:37:35,933
This is actually
going forth and back.

941
00:37:36,000 --> 00:37:38,166
And vendors have
started to remove some

942
00:37:38,233 --> 00:37:40,199
functionality from
browsers again.

943
00:37:40,266 --> 00:37:41,099
Tilt sensors.

944
00:37:41,166 --> 00:37:43,733
If anybody was in the
session I had this morning

945
00:37:43,800 --> 00:37:46,466
about some mobile
authentication, there was

946
00:37:46,533 --> 00:37:48,766
one problem where I
told you about that.

947
00:37:48,833 --> 00:37:51,300
The tilt sensor on iOS,
you had access to it from

948
00:37:51,366 --> 00:37:52,766
the browser.

949
00:37:52,833 --> 00:37:54,699
Well, no longer in
the latest update.

950
00:37:54,766 --> 00:37:57,233
Apple removed that
capability just because of

951
00:37:57,300 --> 00:38:00,400
these problems because
if JavaScript has native

952
00:38:00,466 --> 00:38:03,566
access to a lot of the
hardware on your system,

953
00:38:03,633 --> 00:38:07,533
then you even lose that
API layer that could possibly

954
00:38:07,599 --> 00:38:10,533
apply some restrictions
here to your phone.

955
00:38:10,599 --> 00:38:13,733
Now, in many cases you
will still get some pop up

956
00:38:13,800 --> 00:38:16,800
asking for permission, but
we all know, users click

957
00:38:16,866 --> 00:38:21,666
on whatever moves and that's
not really all that great.

958
00:38:21,733 --> 00:38:24,400
And sometimes even some
real interesting issue is

959
00:38:24,466 --> 00:38:26,866
where you may be aware,
a lot of mobile phones,

960
00:38:26,933 --> 00:38:29,233
mobile devices has a
sensor that dims the

961
00:38:29,300 --> 00:38:35,366
screen whenever the light
is dark to save power.

962
00:38:35,433 --> 00:38:38,566
Browsers allowed access to
that sensor that tells it

963
00:38:38,633 --> 00:38:41,533
what's the light level
in the room and actually

964
00:38:41,599 --> 00:38:43,900
researchers have been able
to use that sensor then to

965
00:38:43,966 --> 00:38:45,933
read partial
screen content.

966
00:38:46,000 --> 00:38:49,800
So, that is why this is
sort of a pendulum that

967
00:38:49,866 --> 00:38:52,733
swings forth and back and
doesn't really ultimately

968
00:38:52,800 --> 00:38:53,433
solve the problem.

969
00:38:53,500 --> 00:38:54,766
Probably makes it worse.

970
00:38:54,833 --> 00:38:56,333
>> ALAN PALLER: Great.

971
00:38:56,400 --> 00:38:58,266
Ed, you talked about
the importance of

972
00:38:58,333 --> 00:38:59,900
application whitelisting.

973
00:38:59,966 --> 00:39:03,000
Is there a great source
of an application

974
00:39:03,066 --> 00:39:05,332
whitelisting template that
provides a good level?

975
00:39:05,400 --> 00:39:07,733
Meaning, how do I know
what I need to whitelist

976
00:39:07,800 --> 00:39:11,533
and I don't want to look
at 260,000 binaries on my

977
00:39:11,599 --> 00:39:12,966
PC which is the
real number.

978
00:39:13,033 --> 00:39:14,466
>> ED SKOUDIS: It doe
vary organization by

979
00:39:14,533 --> 00:39:16,299
organization, but there
are some really good

980
00:39:16,366 --> 00:39:20,500
resources for helping tune it
to your specific enterprise.

981
00:39:20,566 --> 00:39:24,765
One of these is NIS
special publication 800-167.

982
00:39:24,833 --> 00:39:26,333
Came out a few years ago.

983
00:39:26,400 --> 00:39:28,699
But it walks you through
different considerations

984
00:39:28,766 --> 00:39:30,199
in application
whitelisting.

985
00:39:30,266 --> 00:39:32,966
Another really great
source for insight in how

986
00:39:33,033 --> 00:39:34,766
to do application
whitelisting right is

987
00:39:34,833 --> 00:39:36,566
actually in the
SANS reading room.

988
00:39:36,633 --> 00:39:39,198
These are students of
Johannes who have written

989
00:39:39,266 --> 00:39:42,033
up papers on how
to do this well.

990
00:39:42,099 --> 00:39:43,500
They are tremendous,
really good.

991
00:39:43,566 --> 00:39:44,598
>> ALAN PALLER:
Cool. All right.

992
00:39:44,666 --> 00:39:48,133
Heather, the -
where are we?

993
00:39:48,199 --> 00:39:51,099
Will mobile antimalware
protect against all

994
00:39:51,166 --> 00:39:52,633
of these issues?

995
00:39:52,699 --> 00:39:54,133
>> HEATHER MAHALIK: So,
an antivirus essentially?

996
00:39:54,199 --> 00:39:55,500
>> ALAN PALLER: Yeah.

997
00:39:55,566 --> 00:39:56,633
>> HEATHER MAHALIK:
Antivirus software, if it

998
00:39:56,699 --> 00:39:58,900
is legitimate and not
really malware because we

999
00:39:58,966 --> 00:40:02,165
know that that is commonly
what it is, it definitely can.

1000
00:40:02,233 --> 00:40:04,366
What I do recommend is
mobile device management

1001
00:40:04,433 --> 00:40:07,333
will actually detect
a jailbreak that is

1002
00:40:07,400 --> 00:40:11,733
attempting to root your device or get root level access.

1003
00:40:11,800 --> 00:40:14,133
So, if you did have mobile
device management on your

1004
00:40:14,199 --> 00:40:16,400
iPhone and someone tried
to checkra1n it, you would

1005
00:40:16,466 --> 00:40:19,033
actually be alerted and
protected if it was set

1006
00:40:19,099 --> 00:40:19,933
to stop it.

1007
00:40:20,000 --> 00:40:21,633
So, I would recommend
mobile device management.

1008
00:40:21,699 --> 00:40:23,099
>> ALAN PALLER:
It's worth it?

1009
00:40:23,166 --> 00:40:23,866
>> HEATHER MAHALIK: For sure.

1010
00:40:23,933 --> 00:40:24,833
>> ALAN PALLER: Okay.

1011
00:40:24,900 --> 00:40:26,699
Johannes, what additional
security controls can

1012
00:40:26,766 --> 00:40:29,933
someone implement to
prevent or detect attacks

1013
00:40:30,000 --> 00:40:32,533
on the enterprise
perimeter since the

1014
00:40:32,599 --> 00:40:35,400
examples you show appear
to be actually simple

1015
00:40:35,466 --> 00:40:37,533
vulnerabilities that
they're exploiting?

1016
00:40:37,599 --> 00:40:39,733
>> JOHANNES ULLRICH: So,
sometimes of course you

1017
00:40:39,800 --> 00:40:42,699
could sort of stack additional security devices here.

1018
00:40:42,766 --> 00:40:44,599
I'm not really a big fan
of it because that can

1019
00:40:44,666 --> 00:40:46,933
also add more
vulnerabilities in some cases.

1020
00:40:47,000 --> 00:40:50,566
But some solid, good,
passive monitoring, some

1021
00:40:50,633 --> 00:40:53,232
network IDS and such
probably is the best

1022
00:40:53,300 --> 00:40:56,800
control you have there for
some of these vulnerabilities.

1023
00:40:57,900 --> 00:40:59,666
>> ALAN PALLER: All right.

1024
00:40:59,733 --> 00:41:02,933
Can jailbreaks be
exploited automatically?

1025
00:41:03,000 --> 00:41:05,800
Meaning, if a user
accesses a website with a

1026
00:41:05,866 --> 00:41:09,833
fully updated device, can
that website just take

1027
00:41:09,900 --> 00:41:11,366
over the machine, take
over your device?

1028
00:41:11,433 --> 00:41:12,733
>> HEATHER MAHALIK: No,
so, it's actually - you

1029
00:41:12,800 --> 00:41:15,300
have to install the
jailbreak onto the iPhone.

1030
00:41:15,366 --> 00:41:16,633
It is a process to do it.

1031
00:41:16,699 --> 00:41:18,599
You have to put the phone
into a certain state

1032
00:41:18,666 --> 00:41:20,699
called DFU mode and
actually inject it.

1033
00:41:20,766 --> 00:41:22,099
>> ALAN PALLER: You can't just click, click, click, click.

1034
00:41:22,166 --> 00:41:23,133
>> HEATHER MAHALIK: You
can't just click it.

1035
00:41:23,199 --> 00:41:25,666
It is kind of idiot proof.

1036
00:41:25,733 --> 00:41:27,000
>> ALAN PALLER: And while
I've got you, most mobile

1037
00:41:27,066 --> 00:41:29,500
devices connect to
Cloud accounts, right?

1038
00:41:29,566 --> 00:41:31,799
Is that a bigger risk as
the content in the Cloud

1039
00:41:31,866 --> 00:41:34,266
is not usually encrypted
or irrelevant?

1040
00:41:34,333 --> 00:41:35,599
>> HEATHER MAHALIK: Not
necessarily because you

1041
00:41:35,666 --> 00:41:38,766
should have a password and
two-factor authentication

1042
00:41:38,833 --> 00:41:40,666
protecting it and it
is usually dual so you

1043
00:41:40,733 --> 00:41:41,866
should be safe.

1044
00:41:41,933 --> 00:41:43,400
>> ALAN PALLER: Cool.

1045
00:41:43,466 --> 00:41:44,732
And Ed, you get
the last question.

1046
00:41:44,800 --> 00:41:46,066
We're going to give each
of the three speakers - I

1047
00:41:46,133 --> 00:41:48,000
will tell you in advance
the order so you will

1048
00:41:48,066 --> 00:41:52,000
know, Johannes and then
Heather and then Ed, give

1049
00:41:52,066 --> 00:41:55,866
one minute of what's the
one big idea that they

1050
00:41:55,933 --> 00:41:57,933
would love for you to
leave the room with.

1051
00:41:58,000 --> 00:41:59,766
So, I want you to be
thinking about that one.

1052
00:41:59,833 --> 00:42:02,366
But Ed, one question for
you which is why you are last.

1053
00:42:02,433 --> 00:42:06,099
Does it ever make sense
for an organization that

1054
00:42:06,166 --> 00:42:10,233
isn't an antivirus company
to reverse engineer malware?

1055
00:42:10,300 --> 00:42:11,266
>> ED SKOUDIS:
Oh, absolutely.

1056
00:42:11,333 --> 00:42:13,599
Because there is
customized malware or

1057
00:42:13,666 --> 00:42:16,766
variations that you might
face, you can't depend

1058
00:42:16,833 --> 00:42:18,699
entirely on your antivirus
vendor to be able to do

1059
00:42:18,766 --> 00:42:19,699
that for you.

1060
00:42:19,766 --> 00:42:21,599
If something special is
presented to you, you

1061
00:42:21,666 --> 00:42:23,833
need, at least for large
enterprises, the ability

1062
00:42:23,900 --> 00:42:25,666
to look and see
what this thing is.

1063
00:42:25,733 --> 00:42:27,066
If you're a smaller
enterprise, you still

1064
00:42:27,133 --> 00:42:29,433
might be getting hit with
some customized or very

1065
00:42:29,500 --> 00:42:31,966
specialized malware
and you can reach out.

1066
00:42:32,033 --> 00:42:34,299
There are providers, maybe
your own antivirus vendor,

1067
00:42:34,366 --> 00:42:36,699
that can help you analyze
the special stuff that

1068
00:42:36,766 --> 00:42:37,633
might be hitting you.

1069
00:42:37,699 --> 00:42:38,866
>> ALAN PALLER: Yeah,
but it does matter.

1070
00:42:38,933 --> 00:42:40,133
>> ED SKOUDIS: It does.
It really does.

1071
00:42:40,199 --> 00:42:42,033
>> ALAN PALLER: We have a
little more than three minutes.

1072
00:42:42,099 --> 00:42:43,599
We never have this much
time, so I want to just

1073
00:42:43,666 --> 00:42:45,466
tell you about something,
an answer to the question

1074
00:42:45,533 --> 00:42:47,598
I get all of the time and
because you're all in the

1075
00:42:47,666 --> 00:42:49,699
cybersecurity world, you
get it all of the time.

1076
00:42:49,766 --> 00:42:51,866
It's somebody comes up to
you and says oh, you're in

1077
00:42:51,933 --> 00:42:52,800
cybersecurity.

1078
00:42:52,866 --> 00:42:55,300
How do I get into
cybersecurity?

1079
00:42:55,366 --> 00:42:56,800
So, we'll do a blog
on it but there was an

1080
00:42:56,866 --> 00:43:00,166
announcement last night of
a new collegiate program

1081
00:43:00,233 --> 00:43:03,199
called Cyber Fast Track
for kids who were really

1082
00:43:03,266 --> 00:43:06,599
talented, that they can
get in, demonstrate their

1083
00:43:06,666 --> 00:43:08,500
talent, and win
scholarships, millions of

1084
00:43:08,566 --> 00:43:09,433
dollars of scholarships.

1085
00:43:09,500 --> 00:43:11,833
So, if you're looking - if
you've got people coming

1086
00:43:11,900 --> 00:43:13,900
up to you and saying how
do I get into the field?

1087
00:43:13,966 --> 00:43:16,466
If they're in college,
tell them to go look at

1088
00:43:16,533 --> 00:43:18,000
the Cyber Fast
Track Program.

1089
00:43:18,066 --> 00:43:20,332
It's free so it's
not a cost thing.

1090
00:43:20,400 --> 00:43:21,400
But it's a way in.

1091
00:43:21,466 --> 00:43:24,533
But we'll try to do a blog
on the answers to how do I

1092
00:43:24,599 --> 00:43:25,699
get into the field.

1093
00:43:25,766 --> 00:43:29,400
And with that, let's give
each of our speakers the last

1094
00:43:29,466 --> 00:43:35,299
word; what should we leave
the room doing or knowing?

1095
00:43:35,366 --> 00:43:36,633
>> JOHANNES ULLRICH:
Usually I always say

1096
00:43:36,699 --> 00:43:38,699
share, share, share,
and I stay with that.

1097
00:43:38,766 --> 00:43:41,866
But very specifically
to one of the threats I

1098
00:43:41,933 --> 00:43:44,599
talked about as enterprise
security advisors, ask

1099
00:43:44,666 --> 00:43:47,166
your vendors for
security test report.

1100
00:43:47,233 --> 00:43:49,766
Even if they make
it up, ask again.

1101
00:43:49,833 --> 00:43:51,966
Maybe it will at least
trigger them to run the

1102
00:43:52,033 --> 00:43:54,000
security test themselves
and fix some of these

1103
00:43:54,066 --> 00:43:56,433
problems before
others find them.

1104
00:43:56,500 --> 00:43:57,566
>> ALAN PALLER:
Which vendors?

1105
00:43:57,633 --> 00:43:58,698
Vendors of any
application?

1106
00:43:58,766 --> 00:43:59,766
>> JOHANNES ULLRICH:
Vendors of any application,

1107
00:43:59,833 --> 00:44:01,133
any hardware, software.

1108
00:44:01,199 --> 00:44:02,533
>> ALAN PALLER: This
is a really big idea.

1109
00:44:02,599 --> 00:44:05,099
A lot of people think they
are going to buy it and

1110
00:44:05,166 --> 00:44:06,866
test it after they get it.

1111
00:44:06,933 --> 00:44:08,300
That's bad.

1112
00:44:08,366 --> 00:44:11,199
Good is make the vendor
test it and give you the

1113
00:44:11,266 --> 00:44:12,366
artifacts of the test.

1114
00:44:12,433 --> 00:44:15,199
Have a short list of
application testing tools

1115
00:44:15,266 --> 00:44:16,500
that you're
willing to accept.

1116
00:44:16,566 --> 00:44:19,533
Make them give it to you
and get yourself together

1117
00:44:19,599 --> 00:44:21,866
with everybody else in the
industry so that you force

1118
00:44:21,933 --> 00:44:24,333
the vendors to do this
because when that thing

1119
00:44:24,400 --> 00:44:25,833
shows up, they'll fix it.

1120
00:44:25,900 --> 00:44:29,099
But if you find it later,
they somehow forgot your name.

1121
00:44:29,166 --> 00:44:30,766
So, anyway, Heather?

1122
00:44:30,833 --> 00:44:32,199
>> HEATHER MAHALIK: I am
kind of going to go with

1123
00:44:32,266 --> 00:44:34,166
the share, share,
share thing.

1124
00:44:34,233 --> 00:44:35,933
Everyone obviously
has a voice.

1125
00:44:36,000 --> 00:44:37,966
If you see something that
piques your interest, do

1126
00:44:38,033 --> 00:44:39,699
not just hide
in your shell.

1127
00:44:39,766 --> 00:44:42,500
Be aggressive, research
it, put the word out there

1128
00:44:42,566 --> 00:44:45,000
and share because you are
your own advocate and

1129
00:44:45,066 --> 00:44:48,165
honestly, we need younger
people in cybersecurity.

1130
00:44:48,233 --> 00:44:50,199
We need people that want
to chase things, that

1131
00:44:50,266 --> 00:44:54,500
switch fields, that find
something that impacts the

1132
00:44:54,566 --> 00:44:56,165
world and switch
to forensics.

1133
00:44:56,233 --> 00:44:59,333
Do whatever matters
to you, but share it.

1134
00:44:59,400 --> 00:45:01,166
Definitely share back.

1135
00:45:01,233 --> 00:45:02,500
>> ALAN PALLER:
And the last word.

1136
00:45:02,566 --> 00:45:03,366
>> ED SKOUDIS: Sure.

1137
00:45:03,433 --> 00:45:04,933
The theme of this year's
RSA conference is the

1138
00:45:05,000 --> 00:45:06,233
human element.

1139
00:45:06,300 --> 00:45:07,733
You are the human element.

1140
00:45:07,800 --> 00:45:09,766
So, I challenge
you this way.

1141
00:45:09,833 --> 00:45:11,500
You are going to be
heading back from the RSA

1142
00:45:11,566 --> 00:45:12,198
Conference shortly.

1143
00:45:12,266 --> 00:45:14,133
It will finish
up tomorrow.

1144
00:45:14,199 --> 00:45:17,966
On your way back, make a
list of things that you

1145
00:45:18,033 --> 00:45:20,466
learned here at the RSA
conference this year as

1146
00:45:20,533 --> 00:45:22,699
well as things that you
want to follow up with.

1147
00:45:22,766 --> 00:45:25,500
And I challenge you to
spend time, invest in

1148
00:45:25,566 --> 00:45:27,098
yourself, the
human element.

1149
00:45:27,166 --> 00:45:30,433
Spend time mastering some
of the ideas that you've

1150
00:45:30,500 --> 00:45:33,066
learned this year at RSA
Conference and build on

1151
00:45:33,133 --> 00:45:35,133
that so when you come back
next year, you will be

1152
00:45:35,199 --> 00:45:38,366
even more prepared to
engage and share ideas.

1153
00:45:38,433 --> 00:45:39,800
>> ALAN PALLER: Let's
give the panel a hand.

1154
00:45:40,400 --> 00:45:41,699
Thank you.

