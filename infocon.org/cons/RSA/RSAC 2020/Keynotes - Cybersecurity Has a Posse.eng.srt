1
00:00:06,099 --> 00:00:08,866
>> ANNOUNCER: Please welcome
Director Cybersecurity and

2
00:00:08,933 --> 00:00:13,399
Infrastructure Security Agency,
Chris Krebs and Executive

3
00:00:13,466 --> 00:00:18,000
Director and CEO of the Sovrin
Foundation, Heather Dahl.

4
00:00:24,733 --> 00:00:25,466
>> CHRISTOPHER KREBS: Heather.

5
00:00:25,533 --> 00:00:26,733
>> HEATHER DAHL: Hello. Welcome.

6
00:00:26,800 --> 00:00:27,633
>> CHRISTOPHER
KREBS: Good morning.

7
00:00:27,699 --> 00:00:28,533
>> HEATHER DAHL: Sit down.

8
00:00:29,733 --> 00:00:32,633
It's good to sit down with you
this morning and four thousand

9
00:00:32,700 --> 00:00:34,266
of our closest friends.

10
00:00:34,333 --> 00:00:38,565
I think in order to make this
interesting, let's start with

11
00:00:38,633 --> 00:00:39,833
the lightning round.

12
00:00:39,899 --> 00:00:40,799
>> CHRISTOPHER KREBS: Okay.

13
00:00:40,866 --> 00:00:42,899
>> HEATHER DAHL:
We'll warm you up. Okay? Ready?

14
00:00:42,966 --> 00:00:45,100
Exit row or aisle?

15
00:00:45,166 --> 00:00:48,333
>> CHRISTOPHER KREBS: I
am an exit row window.

16
00:00:48,399 --> 00:00:53,299
>> HEATHER DAHL: Okay. Exit
row, do you have a strategy?

17
00:00:53,366 --> 00:00:55,000
>> CHRISTOPHER KREBS:
Pay attention to the

18
00:00:55,066 --> 00:00:56,833
preflight briefing.

19
00:00:56,899 --> 00:00:57,899
Know what you are going to do.

20
00:00:57,966 --> 00:00:58,966
Have a plan.

21
00:00:59,033 --> 00:01:00,133
>> HEATHER DAHL: Now, let's hit
you with the most difficult

22
00:01:00,200 --> 00:01:02,166
question of this
entire thirty minutes.

23
00:01:02,233 --> 00:01:07,765
How do I explain what CISA
does to my 14-year-old?

24
00:01:07,833 --> 00:01:09,399
>> CHRISTOPHER KREBS: Oh boy.

25
00:01:09,466 --> 00:01:12,866
The easiest way, the way we
describe the agency, so it is

26
00:01:12,933 --> 00:01:15,133
the Cybersecurity and
Infrastructure Security Agency

27
00:01:15,200 --> 00:01:16,833
at the Department of
Homeland Security.

28
00:01:16,900 --> 00:01:20,400
We like security so much
it's in our name twice.

29
00:01:20,466 --> 00:01:24,133
A little vaguery of the
congressional legislation

30
00:01:24,200 --> 00:01:25,733
drafting process.

31
00:01:26,700 --> 00:01:28,133
We're the nation's risk advisor.

32
00:01:28,200 --> 00:01:29,299
That's the way we see it.

33
00:01:29,366 --> 00:01:34,766
We were established in
2018 by an act of Congress.

34
00:01:34,833 --> 00:01:38,433
And it took an element of the
Department of Homeland Security

35
00:01:38,500 --> 00:01:42,666
that you probably have heard
of, US-CERT or the N-Kick and

36
00:01:42,733 --> 00:01:47,066
elevated it into a standalone
agency like TSA or FEMA.

37
00:01:47,133 --> 00:01:50,666
>> HEATHER DAHL: Right. And
it's still fairly a young agency.

38
00:01:50,733 --> 00:01:52,599
>> CHRISTOPHER KREBS: Youngest
in the federal government.

39
00:01:52,666 --> 00:01:57,133
>> HEATHER DAHL: What have been
the challenges in sharing threat

40
00:01:57,200 --> 00:02:01,099
and attack information among the
government agencies and also the

41
00:02:01,166 --> 00:02:02,633
private sector?

42
00:02:02,700 --> 00:02:04,933
>> CHRISTOPHER KREBS: So, we
have an interesting set of

43
00:02:05,000 --> 00:02:06,866
responsibilities
and authorities.

44
00:02:06,933 --> 00:02:11,500
So, the department was
established in 2003, right, and

45
00:02:11,566 --> 00:02:14,300
my part of the department was
established principally to bring

46
00:02:14,366 --> 00:02:16,366
industry and government
together, to understand what the

47
00:02:16,433 --> 00:02:18,866
threat landscape looks
like and share information.

48
00:02:19,066 --> 00:02:20,633
With that though, I
have a different set of

49
00:02:20,699 --> 00:02:24,066
responsibilities for
the federal agencies.

50
00:02:24,133 --> 00:02:29,133
So, we develop a series of
capabilities that we then deploy

51
00:02:29,199 --> 00:02:32,333
across the civilian, the
ninety-nine civilian agencies.

52
00:02:32,400 --> 00:02:36,266
Intrusion detection system and
intrusion prevention system and

53
00:02:36,333 --> 00:02:40,233
also continuous diagnostics
and mitigation capabilities to

54
00:02:40,300 --> 00:02:42,333
really understand what
is happening internal to

55
00:02:42,400 --> 00:02:43,233
the network.

56
00:02:43,300 --> 00:02:44,599
>> HEATHER DAHL: So, help
me understand; how do the

57
00:02:44,666 --> 00:02:47,466
intelligence communities
fit into all this?

58
00:02:47,466 --> 00:02:48,500
>> CHRISTOPHER KREBS: Yeah.

59
00:02:48,566 --> 00:02:52,033
So, that is - that's, again,
that interesting space where we

60
00:02:52,099 --> 00:02:56,733
sit at the intersection of
government and industry.

61
00:02:56,800 --> 00:03:00,199
So, we are an all source
agency effectively.

62
00:03:00,266 --> 00:03:03,465
So, I can take information from
the intelligence community, from

63
00:03:03,533 --> 00:03:06,433
the private sector threat
intelligence groups, and fuse

64
00:03:06,500 --> 00:03:08,333
together the bigger picture.

65
00:03:08,333 --> 00:03:12,133
In fact, that's what we
did last summer, June 22nd.

66
00:03:12,199 --> 00:03:15,000
I released an alert that was
cobbled together from the

67
00:03:15,066 --> 00:03:17,800
intelligence community,
classified information, from the

68
00:03:17,866 --> 00:03:20,566
information we saw across the
civilian agencies from our

69
00:03:20,633 --> 00:03:22,800
monitoring capabilities,
and then from the threat

70
00:03:22,866 --> 00:03:26,800
intelligence community,
companies that said hey, we're

71
00:03:26,866 --> 00:03:30,199
seeing an increase in Iranian
activity, spear phishing, cred

72
00:03:30,266 --> 00:03:32,799
stuffing, password
spraying, something's up.

73
00:03:32,866 --> 00:03:34,266
There was a hockey stick effect.

74
00:03:34,333 --> 00:03:36,666
So, we took that, pulled it
all together in an all source

75
00:03:36,733 --> 00:03:40,199
bulletin and sent it out on a
Saturday afternoon which I know

76
00:03:40,266 --> 00:03:43,066
all the CISOs in the room, the
network defenders hate getting

77
00:03:43,133 --> 00:03:44,066
weekend alerts.

78
00:03:44,133 --> 00:03:45,599
But it was just that time.

79
00:03:45,666 --> 00:03:46,833
The time was right.

80
00:03:46,900 --> 00:03:50,533
We sent this out and we provided
a series of recommendations

81
00:03:50,599 --> 00:03:54,433
highlighting the fact that the
Iranian actors, particularly the

82
00:03:54,500 --> 00:03:59,599
IRGC, were prone to destructive
attacks and that this is a thing

83
00:03:59,666 --> 00:04:00,933
that everybody needs
to pay attention to.

84
00:04:01,000 --> 00:04:03,500
>> HEATHER DAHL: So, how common
is it that you can issue those

85
00:04:03,566 --> 00:04:05,199
types of alerts?

86
00:04:05,266 --> 00:04:06,733
What was the
significance of that?

87
00:04:06,733 --> 00:04:10,300
>> CHRISTOPHER KREBS: That one
specifically, this statement

88
00:04:10,366 --> 00:04:14,533
was, again, it was this fusing
together of different sources

89
00:04:14,599 --> 00:04:15,599
of information.

90
00:04:15,666 --> 00:04:19,166
But, you know, through our
US-CERT brand, we tend to issue

91
00:04:19,233 --> 00:04:22,699
- I think today alone we're
issuing four or five industrial

92
00:04:22,766 --> 00:04:24,266
control systems related alerts.

93
00:04:24,333 --> 00:04:25,533
We issued one last week.

94
00:04:25,533 --> 00:04:29,433
There - we issue alerts on a
daily basis and this is actually

95
00:04:29,500 --> 00:04:33,100
a great example of why industry
and government, why we need to

96
00:04:33,166 --> 00:04:37,300
work with our industry partners
because if you see something,

97
00:04:37,366 --> 00:04:40,433
you can share it with us
and then we can amplify

98
00:04:40,500 --> 00:04:41,300
that information.

99
00:04:41,366 --> 00:04:43,466
We can validate and
then we amplify it.

100
00:04:43,466 --> 00:04:45,366
>> HEATHER DAHL: So, let
me be a skeptic on that.

101
00:04:45,433 --> 00:04:46,332
>> CHRISTOPHER KREBS: Okay.

102
00:04:46,399 --> 00:04:47,466
>> HEATHER DAHL:
I'm in the industry.

103
00:04:47,533 --> 00:04:52,633
My company is - suffers an
attack breach and it's not

104
00:04:52,699 --> 00:04:53,699
public news.

105
00:04:53,766 --> 00:04:54,899
I know about it.

106
00:04:54,966 --> 00:04:59,233
Does it make sense that I
would want to disclose that

107
00:04:59,300 --> 00:05:02,166
information if no one
else really knows?

108
00:05:02,233 --> 00:05:06,533
And first of all, do I put
myself at more risk by making

109
00:05:06,600 --> 00:05:07,566
that disclosure?

110
00:05:07,633 --> 00:05:11,000
And second of all, am I not
just helping my competition?

111
00:05:11,066 --> 00:05:14,265
Because A, they're going to
learn from my experience and, B,

112
00:05:14,333 --> 00:05:17,266
maybe it would be good if they
did suffer the same thing I did.

113
00:05:17,333 --> 00:05:20,600
How do you address that
point of view with industry?

114
00:05:20,699 --> 00:05:22,033
>> CHRISTOPHER KREBS: So,
that latter point I'm not going

115
00:05:22,100 --> 00:05:23,166
to touch.

116
00:05:23,233 --> 00:05:28,066
But generally, we do - so there
are a series of authorities that

117
00:05:28,133 --> 00:05:31,299
we have that provide
liability protection.

118
00:05:31,366 --> 00:05:32,899
So, if you provide
information to us,

119
00:05:32,966 --> 00:05:33,766
we protect it.

120
00:05:33,833 --> 00:05:34,666
We anonymize it.

121
00:05:34,733 --> 00:05:35,766
We share it.

122
00:05:35,833 --> 00:05:39,666
When our alerts go out, it's not
that company X suffered a breach

123
00:05:39,733 --> 00:05:41,933
and here are the
characteristics of the event.

124
00:05:42,000 --> 00:05:46,199
It is a company in this sector
or segment had an event, they

125
00:05:46,266 --> 00:05:49,899
had this industrial control
system related activity or

126
00:05:49,966 --> 00:05:53,033
incident, so we send it out in
an anonymized way because really

127
00:05:53,100 --> 00:05:56,666
what we're trying to do here
is understand the landscape,

128
00:05:56,733 --> 00:06:00,133
understand the conditions on top
of it and what the adversary

129
00:06:00,199 --> 00:06:03,800
might be doing, and get that
out so the next victim might

130
00:06:03,866 --> 00:06:04,633
not happen.

131
00:06:04,699 --> 00:06:07,566
And this is particularly
important in the broader

132
00:06:07,633 --> 00:06:09,066
ransomware conversation.

133
00:06:09,500 --> 00:06:12,133
>> HEATHER DAHL: So, let's talk
about that in the sense of the

134
00:06:12,199 --> 00:06:13,866
geopolitical risk.

135
00:06:13,933 --> 00:06:18,832
What is the geopolitical risk of
the US government collaborating

136
00:06:18,899 --> 00:06:22,766
in a more open way with
industry and government

137
00:06:22,833 --> 00:06:24,800
agencies together?

138
00:06:24,866 --> 00:06:27,566
Is it, you know, the same
argument from a skeptic point of

139
00:06:27,633 --> 00:06:31,832
view, well, any adversary or
enemy can just go on the website

140
00:06:31,899 --> 00:06:33,300
and learn what we know?

141
00:06:33,966 --> 00:06:36,433
>> CHRISTOPHER KREBS: Yeah so,
I'm not a big fan of security

142
00:06:36,500 --> 00:06:37,366
by obscurity.

143
00:06:37,433 --> 00:06:38,500
I don't think it works.

144
00:06:38,566 --> 00:06:42,433
I think that we need to get
ahead of the curve and a

145
00:06:42,500 --> 00:06:46,500
collective defense approach
where, you know, the historical

146
00:06:46,566 --> 00:06:49,933
cliché or whatever is the enemy
has only got to be right once

147
00:06:50,000 --> 00:06:51,366
and we've got to be
right every single time.

148
00:06:51,433 --> 00:06:54,000
I'm not really - I think through
layered defense, I'm not sure

149
00:06:54,066 --> 00:06:55,799
that holds true.

150
00:06:55,800 --> 00:06:59,000
But if everybody does work
together, everybody pulls

151
00:06:59,066 --> 00:07:03,799
together as a team and shares
information rapidly enough that

152
00:07:03,866 --> 00:07:05,599
we can build up better defenses.

153
00:07:05,666 --> 00:07:09,266
And that's really the unique
thing, again, about my agency is

154
00:07:09,333 --> 00:07:13,833
that we are not - in that role
of the nation's risk advisor,

155
00:07:13,899 --> 00:07:15,199
we're not the
nation's risk manager.

156
00:07:15,266 --> 00:07:17,133
You own and
operate your systems.

157
00:07:17,199 --> 00:07:18,300
You own the risk.

158
00:07:18,366 --> 00:07:21,566
But what we do is we get an
understanding, again, across

159
00:07:21,633 --> 00:07:24,265
federal networks, across the
private sector, we pull together

160
00:07:24,333 --> 00:07:26,733
that broader understanding and
then we facilitate a knowledge

161
00:07:26,800 --> 00:07:29,600
transfer from the
haves to the have nots.

162
00:07:30,066 --> 00:07:33,566
So, yes there are the big banks
that spend a whole lot of money

163
00:07:33,633 --> 00:07:34,633
on security.

164
00:07:34,699 --> 00:07:38,100
I'm probably not going to be
able to help them on a day to

165
00:07:38,166 --> 00:07:42,199
day vulnerability
scanning sort of assistance.

166
00:07:42,266 --> 00:07:44,699
We can help them on the
intelligence side but they are

167
00:07:44,766 --> 00:07:49,500
learning things that I can push
to, you know, down that XY axis,

168
00:07:49,566 --> 00:07:51,933
that folks that don't have the
investment, that may not be

169
00:07:52,000 --> 00:07:52,966
as sophisticated.

170
00:07:53,266 --> 00:07:56,399
>> HEATHER DAHL: So, when we
talk about the larger landscape

171
00:07:56,466 --> 00:08:00,366
and the world that we're in, we
live in a GDPR world, we live in

172
00:08:00,433 --> 00:08:01,699
a CCPA world.

173
00:08:01,766 --> 00:08:06,699
We also live in a world where a
lot of the calculations on the

174
00:08:06,766 --> 00:08:13,399
cost of breaches are made from
downtime, from the data that was

175
00:08:13,466 --> 00:08:17,399
lost, and it's not
necessarily focused on the

176
00:08:17,466 --> 00:08:19,166
personal information.

177
00:08:19,666 --> 00:08:24,699
What is your advice, in the role
as the nation's advisor, to

178
00:08:24,766 --> 00:08:28,300
organizations who are trying
to make that risk/reward

179
00:08:28,366 --> 00:08:32,566
calculation on do I change my
mindset in how I think about

180
00:08:32,633 --> 00:08:37,000
security like sharing
information with others versus

181
00:08:37,066 --> 00:08:39,566
the legacy let's stay in the
same mindset and keep the same

182
00:08:39,633 --> 00:08:40,533
technology in place?

183
00:08:41,100 --> 00:08:42,100
>> CHRISTOPHER KREBS: Yeah.

184
00:08:42,166 --> 00:08:44,200
So, I mean, I'm going to answer
the question in the context

185
00:08:44,265 --> 00:08:45,299
of ransomware.

186
00:08:45,366 --> 00:08:49,766
That is, you know, for years and
years and years, particularly in

187
00:08:49,833 --> 00:08:53,100
the federal government, we've
been focused on the nation state

188
00:08:53,166 --> 00:08:56,200
adversary, the highly capable,
the big four, Russia, China,

189
00:08:56,266 --> 00:08:57,333
Iran, North Korea.

190
00:08:57,799 --> 00:09:01,366
And I think we've been a
little bit late to the game on

191
00:09:01,433 --> 00:09:04,100
ransomware which is, you know,
my Deputy calls it a menace

192
00:09:04,166 --> 00:09:04,899
to society.

193
00:09:04,966 --> 00:09:06,600
I call it the
scourge of the internet.

194
00:09:06,666 --> 00:09:08,733
This is the thing that I
think the average American

195
00:09:08,799 --> 00:09:10,000
has experienced.

196
00:09:10,066 --> 00:09:13,399
So, that is the thing that they
see in their schools, their

197
00:09:13,466 --> 00:09:16,266
hospitals, their
municipal agencies.

198
00:09:16,333 --> 00:09:21,565
And so, the challenge here is
the question of do you pay and

199
00:09:21,633 --> 00:09:22,366
do you report?

200
00:09:22,966 --> 00:09:25,366
What I've said, and this is
an individual risk management

201
00:09:25,433 --> 00:09:28,933
decision at this point for each
organization, is don't pay.

202
00:09:29,000 --> 00:09:33,200
For one reason, you are
validating the business model.

203
00:09:33,266 --> 00:09:36,266
The second is the
keys don't always work.

204
00:09:36,333 --> 00:09:39,600
Maybe, what, 20% to 50% of the
time does a recovery key work on

205
00:09:39,666 --> 00:09:40,899
a ransomware attack.

206
00:09:40,966 --> 00:09:43,666
You know, third is you - what
are you going to do if it

207
00:09:43,733 --> 00:09:44,399
doesn't work?

208
00:09:44,466 --> 00:09:46,333
You pay it out.

209
00:09:46,399 --> 00:09:50,233
Are you going to sue them in
small claims court or whatever?

210
00:09:50,299 --> 00:09:51,266
It just doesn't work.

211
00:09:51,333 --> 00:09:53,500
>> HEATHER DAHL: The majority
of businesses are small to

212
00:09:53,566 --> 00:09:54,633
mid-sized businesses.

213
00:09:54,700 --> 00:09:58,100
What is your role in providing
advice to businesses of those

214
00:09:58,166 --> 00:10:01,500
size because for them, some of
them may think a good strategy

215
00:10:01,566 --> 00:10:02,666
is paying it out?

216
00:10:02,733 --> 00:10:06,699
What kind of resources,
information is available to

217
00:10:06,766 --> 00:10:09,065
those sized companies and do
they have anything to offer?

218
00:10:09,066 --> 00:10:10,733
>> CHRISTOPHER KREBS: So,
we're hoping to engage across,

219
00:10:10,799 --> 00:10:13,233
particularly with small and
medium-sized businesses, with

220
00:10:13,299 --> 00:10:15,733
state and local
governments left of boom.

221
00:10:15,799 --> 00:10:18,632
We want to get there before
they have an incident.

222
00:10:18,700 --> 00:10:21,000
Again, you know, we're not naïve
to understand that we're going

223
00:10:21,066 --> 00:10:24,466
to get everybody but to the
extent that we can engage, do

224
00:10:24,533 --> 00:10:27,466
this knowledge transfer, share
information, help them update

225
00:10:27,533 --> 00:10:30,000
their systems, help them
implement multifactor

226
00:10:30,066 --> 00:10:32,766
authentication, have an incident
response plan, recoverable

227
00:10:32,833 --> 00:10:35,466
backups that are tested, then
they're going to be better off

228
00:10:35,533 --> 00:10:36,799
for when that bad thing happens.

229
00:10:36,866 --> 00:10:40,600
When that bad thing does happen,
we can provide some advisory

230
00:10:40,666 --> 00:10:42,100
assistance on getting back up.

231
00:10:42,100 --> 00:10:45,000
>> HEATHER DAHL: I want to pick
up on the thread about Iran.

232
00:10:45,066 --> 00:10:48,700
You had just talked about
previously January 3rd of

233
00:10:48,766 --> 00:10:49,866
this year.

234
00:10:49,933 --> 00:10:52,299
Very interesting day for you.

235
00:10:52,366 --> 00:10:55,566
The US launched the
strike against the Iranian

236
00:10:55,633 --> 00:10:57,066
military leader.

237
00:10:57,133 --> 00:10:59,233
And then your vacation ended.

238
00:10:59,299 --> 00:11:02,566
Tell us a little bit more
about that and its connection

239
00:11:02,633 --> 00:11:03,866
to ransomware.

240
00:11:04,266 --> 00:11:07,500
>> CHRISTOPHER KREBS: So, when
you look back at the summer,

241
00:11:07,566 --> 00:11:12,033
June 22nd, we were already in
enhanced posture with respect to

242
00:11:12,100 --> 00:11:13,066
threats from Iran.

243
00:11:13,133 --> 00:11:16,200
So, we'd had a plan,
an internal plan ready to go

244
00:11:16,266 --> 00:11:19,065
that if anything were to change
across - you mentioned earlier,

245
00:11:19,133 --> 00:11:20,133
geopolitical risks.

246
00:11:20,200 --> 00:11:22,700
If anything were to change
across that landscape, we could

247
00:11:22,766 --> 00:11:25,833
snap into place a number of
engagement mechanisms for

248
00:11:25,899 --> 00:11:27,033
our partners.

249
00:11:27,033 --> 00:11:30,000
So, January 2nd, I'm pulling in
the driveway after a week down

250
00:11:30,066 --> 00:11:31,433
in the Outer Banks.

251
00:11:31,500 --> 00:11:35,000
Roll in and boom, we get a
notification of the strike.

252
00:11:35,066 --> 00:11:38,933
So, immediately pull together a
series of calls in coordination

253
00:11:39,000 --> 00:11:40,033
with industry.

254
00:11:40,100 --> 00:11:42,466
Over the course of a week, we
were able to share information.

255
00:11:42,533 --> 00:11:45,299
We were able to stand up
calls with our critical

256
00:11:45,366 --> 00:11:48,299
infrastructure, state, local and
federal agency partners, about

257
00:11:48,366 --> 00:11:51,500
26,000 individuals is
the math that we've done.

258
00:11:51,866 --> 00:11:55,866
And, at the same time, using
our insight of what the Iranian

259
00:11:55,933 --> 00:11:59,799
actors are capable of and
emerging trends in industry like

260
00:11:59,866 --> 00:12:03,133
the MITRE ATT&CK Framework and
pushed out what we know about

261
00:12:03,200 --> 00:12:06,633
the TTPs, the Iranian actor with
detections and mitigations, and

262
00:12:06,700 --> 00:12:07,833
got that out to our partners.

263
00:12:07,833 --> 00:12:12,966
Now, we also understand that at
that point, if they were going

264
00:12:13,033 --> 00:12:15,899
to do something, they were
probably already in the systems

265
00:12:15,966 --> 00:12:18,600
that they would want to achieve
their strategic objectives.

266
00:12:18,666 --> 00:12:24,333
But connecting all back to
your ransomware point, when

267
00:12:24,399 --> 00:12:28,299
everything kind of died down at
the end of the next week, we

268
00:12:28,366 --> 00:12:32,100
didn't want to take our foot
off the gas because we had the

269
00:12:32,166 --> 00:12:33,533
nation's attention.

270
00:12:33,600 --> 00:12:34,899
We had leadership's attention.

271
00:12:34,966 --> 00:12:37,000
I feel like we
have three audiences.

272
00:12:37,066 --> 00:12:38,266
One is the network defenders.

273
00:12:38,333 --> 00:12:41,233
The second is the C suite and
the executive decisionmakers and

274
00:12:41,299 --> 00:12:42,632
the third is the general public.

275
00:12:43,233 --> 00:12:45,433
My job is to help
everyone in this room.

276
00:12:45,500 --> 00:12:47,166
If you are in the network
defense community, if you are a

277
00:12:47,233 --> 00:12:51,199
CISO, my job is to help you and
take down some barriers as you

278
00:12:51,266 --> 00:12:54,299
go into the boardroom, as you go
into the C suite, as you engage

279
00:12:54,366 --> 00:12:56,899
your general counsels to
give authoritative, credible

280
00:12:56,966 --> 00:12:59,333
information on what the threat
landscape looks like and the

281
00:12:59,399 --> 00:13:00,666
actions that you need to take.

282
00:13:01,100 --> 00:13:05,200
So, if I can say, look, Iran,
their capable data destruction

283
00:13:05,266 --> 00:13:09,933
attack, a destructive attack
looks a lot like ransomware.

284
00:13:10,000 --> 00:13:12,733
So, let's go ahead and defend
against these ransomware

285
00:13:12,799 --> 00:13:16,966
capabilities and so that when
Iran, if they come back six

286
00:13:17,033 --> 00:13:19,000
months from now, we're
in a better position.

287
00:13:19,433 --> 00:13:22,633
>> HEATHER DAHL: So, and this
was a great example of using

288
00:13:22,700 --> 00:13:25,433
something that was going on at
the time, this case around it,

289
00:13:25,500 --> 00:13:28,100
to bring up an issue that
was continuously happening

290
00:13:28,166 --> 00:13:28,966
like ransomware.

291
00:13:29,366 --> 00:13:33,000
The other news of the
day right now, elections.

292
00:13:33,066 --> 00:13:36,533
What are the technical
challenges that the US electoral

293
00:13:36,600 --> 00:13:40,766
system faces right now going
into this fall's elections?

294
00:13:41,066 --> 00:13:42,633
>> CHRISTOPHER KREBS: So, In the
cryptographer's panel you just

295
00:13:42,700 --> 00:13:45,133
heard from Ron Rivest who talked
about some of the progress that

296
00:13:45,200 --> 00:13:47,799
has been made but also the
vulnerabilities in the system.

297
00:13:47,833 --> 00:13:51,799
So, the technical challenges
are actually underpinned by the

298
00:13:51,866 --> 00:13:53,966
broader administrative
challenges of elections.

299
00:13:54,033 --> 00:13:56,466
In the United States, Article 1
Section 4 of the Constitution

300
00:13:56,533 --> 00:14:00,100
says the states will conduct -
determine the time, place and

301
00:14:00,166 --> 00:14:02,433
manner of conducting of
the federal elections.

302
00:14:02,500 --> 00:14:06,833
And that has manifested
into about 8,800 election

303
00:14:06,899 --> 00:14:08,433
jurisdictions
across the country.

304
00:14:08,433 --> 00:14:13,299
It's also an area that prior to
2016, I'm not sure it was on

305
00:14:13,366 --> 00:14:16,866
anybody's radar that this was
in play for geopolitical risk.

306
00:14:16,933 --> 00:14:22,033
Ron talked a little bit about
the election machines and the

307
00:14:22,100 --> 00:14:23,500
requirement for paper ballots.

308
00:14:23,566 --> 00:14:25,866
What we've done over the last
couple years is put a lot of

309
00:14:25,933 --> 00:14:29,733
attention on risk assessments
across the system, all the way

310
00:14:29,799 --> 00:14:32,966
from registering to vote to
certification of the vote

311
00:14:33,033 --> 00:14:36,033
process, and trying to figure
out where the risk really is

312
00:14:36,100 --> 00:14:37,200
across these systems.

313
00:14:37,200 --> 00:14:41,000
I think what we've discovered,
not surprisingly, is the areas

314
00:14:41,066 --> 00:14:45,633
where information is centralized
and it's highly networked,

315
00:14:45,700 --> 00:14:47,466
that's where a lot
of the risk is.

316
00:14:47,533 --> 00:14:48,333
And what is that?

317
00:14:48,399 --> 00:14:50,200
Voter registration databases.

318
00:14:50,266 --> 00:14:54,366
So, over the last year, again,
ransomware thinking through some

319
00:14:54,433 --> 00:14:57,600
threat modeling of what an
adversary might do, not even a

320
00:14:57,666 --> 00:15:01,166
nation state adversary but a
criminal that understands we

321
00:15:01,233 --> 00:15:04,500
care about election security, we
got a big election coming up.

322
00:15:04,566 --> 00:15:07,799
I bet I can go pop that database
and ask for two million dollars

323
00:15:07,866 --> 00:15:08,566
and I bet they'll pay.

324
00:15:09,399 --> 00:15:12,433
>> HEATHER DAHL: So, what
happens if this - what does your

325
00:15:12,500 --> 00:15:16,500
organization do if come late
October/November we learn

326
00:15:16,566 --> 00:15:17,166
this happened?

327
00:15:17,233 --> 00:15:18,433
Is there a rule?

328
00:15:18,433 --> 00:15:21,333
>> CHRISTOPHER KREBS: So, we've
been, again, since about last

329
00:15:21,399 --> 00:15:24,299
year we've put a lot of focus
on providing vulnerability

330
00:15:24,366 --> 00:15:28,600
management capabilities and
assistance to the fifty states

331
00:15:28,666 --> 00:15:31,100
and local jurisdictions
to get ahead of this.

332
00:15:31,166 --> 00:15:32,866
So, we can harden
as much as possible.

333
00:15:32,866 --> 00:15:36,600
But we also recognize that 100%
security is not achievable.

334
00:15:36,666 --> 00:15:39,366
So, we're focusing on
increasing resilience.

335
00:15:39,433 --> 00:15:42,665
So, again, it's just like
any other ransomware event.

336
00:15:42,733 --> 00:15:46,099
You have an offline back up that
you test and you practice and

337
00:15:46,166 --> 00:15:48,000
you have a plan, know what you
are going to say to the voting

338
00:15:48,066 --> 00:15:52,133
public, the press,
the political parties.

339
00:15:52,200 --> 00:15:54,600
But also have an analog back up.

340
00:15:54,666 --> 00:15:56,866
Have your paper voter rolls.

341
00:15:56,933 --> 00:16:01,000
And just not at the state
level but at the individual

342
00:16:01,066 --> 00:16:01,799
precinct level.

343
00:16:02,200 --> 00:16:05,966
>> HEATHER DAHL: So, what can
CISA do to assure the American

344
00:16:06,033 --> 00:16:08,366
public about the
integrity of the elections?

345
00:16:08,766 --> 00:16:10,500
>> CHRISTOPHER KREBS: So, this
is kind of the - what I've been

346
00:16:10,566 --> 00:16:15,200
saying is 2016 was a wakeup
call, front to back wakeup call

347
00:16:15,266 --> 00:16:16,632
across the federal government.

348
00:16:16,700 --> 00:16:19,500
There's no single issue that I
am involved in that I've seen

349
00:16:19,566 --> 00:16:22,966
this level of engagement and
clarity of purpose and jointness

350
00:16:23,033 --> 00:16:23,966
of mission.

351
00:16:24,033 --> 00:16:26,733
The intelligence community,
federal law enforcement, my

352
00:16:26,799 --> 00:16:30,833
team, and the election
administration folks, the

353
00:16:30,899 --> 00:16:34,200
Election Assistance Commission,
everybody is at this issue as

354
00:16:34,266 --> 00:16:35,799
hard as any
other issue I've seen.

355
00:16:36,733 --> 00:16:39,532
At the same time, state and
locals in 2016, they, again,

356
00:16:39,600 --> 00:16:45,866
they didn't realize they were
on the front lines of this

357
00:16:45,933 --> 00:16:47,566
geopolitical conflict.

358
00:16:47,633 --> 00:16:49,733
And they now are all aboard.

359
00:16:49,799 --> 00:16:53,533
We have a dedicated information
sharing and analysis center for

360
00:16:53,600 --> 00:16:55,866
state and locals; all fifty
states and about 2,500

361
00:16:55,933 --> 00:16:57,533
jurisdictions are engaged.

362
00:16:58,899 --> 00:17:01,366
The American people need to
understand that we are taking

363
00:17:01,433 --> 00:17:01,966
this seriously.

364
00:17:02,033 --> 00:17:02,899
We're engaged on it.

365
00:17:02,966 --> 00:17:06,400
But 100% security is not
going to be the outcome.

366
00:17:06,465 --> 00:17:10,532
So, you as the voter have to
have a plan for voting as well.

367
00:17:10,598 --> 00:17:12,965
>> HEATHER DAHL: And the other
part you want is yes, attacks on

368
00:17:13,032 --> 00:17:16,366
the databases, but the other one
we've heard a lot about here at

369
00:17:16,433 --> 00:17:21,165
RSA and Solutions are around
fake news and deep fakes on one

370
00:17:21,233 --> 00:17:26,598
hand, was the real damage to
the 2016 election, when it -

371
00:17:26,665 --> 00:17:29,533
basically when it comes to these
issues and introducing this as

372
00:17:29,599 --> 00:17:31,099
part of our election.

373
00:17:31,099 --> 00:17:32,832
>> CHRISTOPHER KREBS: So,
what Ron was talking about was

374
00:17:32,900 --> 00:17:33,500
paper ballots.

375
00:17:33,566 --> 00:17:35,400
Why are paper ballots important?

376
00:17:35,466 --> 00:17:36,966
So that you have an
auditable record.

377
00:17:37,033 --> 00:17:39,565
That's just a core tenant of IT
security that you can audit the

378
00:17:39,633 --> 00:17:41,099
process and look
back at the log.

379
00:17:41,166 --> 00:17:42,700
The same thing goes for voting.

380
00:17:42,766 --> 00:17:45,166
If there's any question, you can
go back to the paper, you have

381
00:17:45,233 --> 00:17:49,966
the receipts and you can check
it and get to that outcome

382
00:17:50,033 --> 00:17:50,699
you want.

383
00:17:51,000 --> 00:17:52,433
At the same time,
you have to think about the

384
00:17:52,500 --> 00:17:53,500
strategic objectives.

385
00:17:53,566 --> 00:17:56,766
This is my view of strategic
objectives of the adversary.

386
00:17:56,833 --> 00:18:00,700
To be able to change the vote at
scale in an undetected manner

387
00:18:00,766 --> 00:18:03,900
given the de centralized nature
of the individual voting

388
00:18:03,966 --> 00:18:06,866
machines in the United
States is really complicated.

389
00:18:06,933 --> 00:18:08,066
It's a high investment.

390
00:18:08,133 --> 00:18:10,766
There's a lot of risk with it
and it's going to be difficult

391
00:18:10,833 --> 00:18:11,533
to achieve.

392
00:18:12,633 --> 00:18:15,599
On the other hand, what if
you just targeted one or two

393
00:18:15,666 --> 00:18:19,433
jurisdictions in key
spaces and then got caught?

394
00:18:19,500 --> 00:18:21,000
And then you amplify that.

395
00:18:21,366 --> 00:18:24,966
So, what we've got to be able to
do is work with our partners in

396
00:18:25,033 --> 00:18:28,899
state and local, work with our
Department of Defense and the

397
00:18:28,966 --> 00:18:31,099
intelligence community partners
so that they can go disrupt over

398
00:18:31,166 --> 00:18:34,566
there, but here we have time
right now to understand what the

399
00:18:34,633 --> 00:18:38,266
threats are and then inoculate
the public in part and that we

400
00:18:38,333 --> 00:18:41,033
can share this is what they're
going to try to say, this is

401
00:18:41,099 --> 00:18:42,966
what they might try to do.

402
00:18:43,033 --> 00:18:48,733
This is the point though, that
it's not about a single outcome

403
00:18:48,799 --> 00:18:53,966
of an individual race; it's
about a broader destabilizing of

404
00:18:54,033 --> 00:18:56,099
the public, of our
confidence in the system.

405
00:18:56,099 --> 00:18:59,133
And that's what was so
shocking, I think, about 2016.

406
00:18:59,200 --> 00:19:01,900
I've said it's like
the sputnik moment.

407
00:19:01,966 --> 00:19:03,332
What do I mean by that?

408
00:19:03,400 --> 00:19:07,666
So, in 1957 when the Soviets put
sputnik in space, beat us to low

409
00:19:07,733 --> 00:19:09,166
earth orbit, that
was shocking enough.

410
00:19:09,233 --> 00:19:11,200
But the fact that they had an
intercontinental ballistic

411
00:19:11,266 --> 00:19:13,933
missile that could
geographically overcome oceans

412
00:19:14,000 --> 00:19:16,400
and reach out and touch
us, that was a big deal.

413
00:19:16,733 --> 00:19:21,466
2016 was the first time, I
think, for the elected officials

414
00:19:21,533 --> 00:19:25,632
for the American public to
truly understand that cyber

415
00:19:25,700 --> 00:19:28,133
could destabilize a democracy.

416
00:19:28,200 --> 00:19:29,533
And that's where
we are right now.

417
00:19:29,666 --> 00:19:31,166
>> HEATHER DAHL: So, I want
to shift the conversation a

418
00:19:31,233 --> 00:19:32,233
little bit.

419
00:19:32,299 --> 00:19:34,433
You have brought up two key
components, the decentralization

420
00:19:34,500 --> 00:19:38,233
of the election system and the
central data repositories.

421
00:19:38,299 --> 00:19:41,366
To ask you a question more
for those who are working on

422
00:19:41,433 --> 00:19:43,166
emerging tech side of thing.

423
00:19:43,233 --> 00:19:47,433
When it comes to blockchain and
decentralized networks that are

424
00:19:47,500 --> 00:19:52,166
being developed, what is CISA's
role in providing advice to

425
00:19:52,233 --> 00:19:53,899
those types of technologies?

426
00:19:54,066 --> 00:19:57,900
>> CHRISTOPHER KREBS: So,
again, I can use the concept

427
00:19:57,966 --> 00:19:59,033
within elections.

428
00:19:59,099 --> 00:20:06,000
Ron talked about a couple other
researchers that worked with the

429
00:20:06,066 --> 00:20:09,400
National Academy of Sciences to
talk about internet voting and

430
00:20:09,466 --> 00:20:12,599
there have been concepts that
would use the blockchain to

431
00:20:12,666 --> 00:20:14,200
transmit a vote.

432
00:20:14,266 --> 00:20:18,500
And that's fine, but if it's
garbage in, it's garbage out.

433
00:20:18,799 --> 00:20:22,633
So, we still are not in a
position, I think, on the actual

434
00:20:22,700 --> 00:20:26,133
mobile devices and the computing
space, the personal computers

435
00:20:26,200 --> 00:20:28,966
and whatnot, where we have
confidence that those systems

436
00:20:29,033 --> 00:20:33,332
are clean enough, so to speak,
that you are going to get the

437
00:20:33,400 --> 00:20:37,466
authentic, credible piece of
information in there relative to

438
00:20:37,533 --> 00:20:40,832
the vote and then transmit it
into the tabulation system.

439
00:20:40,900 --> 00:20:42,333
>> HEATHER DAHL: So,
it's interesting, garbage in,

440
00:20:42,400 --> 00:20:43,400
garbage out.

441
00:20:43,466 --> 00:20:46,000
Which brings up the point that
we're now living in a world

442
00:20:46,066 --> 00:20:50,799
where we trust every site, every
app, every platform to be in our

443
00:20:50,866 --> 00:20:54,133
homes, to be in our offices,
rifling through our drawers,

444
00:20:54,200 --> 00:20:55,700
through our files.

445
00:20:55,766 --> 00:20:59,099
And aside from the creepiness
factor in some of this, it seems

446
00:20:59,166 --> 00:21:02,799
to be a risk that personal data
is out there for anyone who

447
00:21:02,866 --> 00:21:04,733
wants to go buy it.

448
00:21:04,799 --> 00:21:07,700
It seems like that could also
be a national security risk.

449
00:21:07,766 --> 00:21:10,533
So, if the role of the
government is to protect

450
00:21:10,599 --> 00:21:15,765
citizens, what do you think
CISA's role is in protecting

451
00:21:15,833 --> 00:21:16,833
personal data?

452
00:21:17,266 --> 00:21:18,833
>> CHRISTOPHER KREBS: So,
this is part of that knowledge

453
00:21:18,900 --> 00:21:19,900
transfer piece.

454
00:21:19,966 --> 00:21:24,366
It's helping organizations
update, defend their systems to

455
00:21:24,433 --> 00:21:26,066
get to a better
security outcome.

456
00:21:26,133 --> 00:21:29,966
If you talk about the broader
vision or mission of the agency,

457
00:21:30,033 --> 00:21:32,399
it's to improve
American cybersecurity.

458
00:21:32,466 --> 00:21:36,533
And that gets to the point of
helping organizations secure the

459
00:21:36,599 --> 00:21:37,265
data they have.

460
00:21:37,666 --> 00:21:40,533
Now, that's today.

461
00:21:40,599 --> 00:21:41,700
What about tomorrow?

462
00:21:41,766 --> 00:21:42,799
And that's our motto.

463
00:21:42,866 --> 00:21:45,000
It's defend today,
secure tomorrow.

464
00:21:45,066 --> 00:21:48,333
So, what are the things that we
can do down the road to help

465
00:21:48,400 --> 00:21:51,400
ensure that we have a
more secure identity?

466
00:21:51,466 --> 00:21:56,533
Move away from the social
security number as an

467
00:21:56,599 --> 00:21:57,733
identification element.

468
00:21:57,733 --> 00:22:03,399
So, we work with a range
of partners, including the

469
00:22:03,466 --> 00:22:06,265
President's National Security
Telecommunications Advisory

470
00:22:06,333 --> 00:22:12,366
Council, to look at what are
alternative identity management

471
00:22:12,433 --> 00:22:13,366
opportunities.

472
00:22:13,366 --> 00:22:15,066
>> HEATHER DAHL: Well, one
of those would be Sovrin.

473
00:22:15,133 --> 00:22:18,233
We'll have to
talk after this more.

474
00:22:18,299 --> 00:22:19,299
But exactly.

475
00:22:19,366 --> 00:22:22,599
You know, as we close out our
conversation here, you know,

476
00:22:22,666 --> 00:22:25,933
we've really talked about a lot
of top down security approaches

477
00:22:26,000 --> 00:22:28,333
and there's no one
who can do business without

478
00:22:28,400 --> 00:22:29,366
touching technology.

479
00:22:29,433 --> 00:22:32,466
You look at farmers using data
to maximize their yields.

480
00:22:32,533 --> 00:22:35,366
Even my daughter is
selling her drawings on Etsy.

481
00:22:35,433 --> 00:22:39,466
What is the responsibility to
educate at the grassroots level?

482
00:22:40,299 --> 00:22:43,233
>> CHRISTOPHER KREBS: This
is - much like that tension I

483
00:22:43,299 --> 00:22:47,066
mentioned earlier, that balance
between nation state adversaries

484
00:22:47,133 --> 00:22:49,533
but at the same time making sure
that we're dressing the threats

485
00:22:49,599 --> 00:22:52,933
that the average American people
see in ransomware, same thing

486
00:22:53,000 --> 00:22:53,666
goes here.

487
00:22:53,733 --> 00:22:56,000
We tend to really
focus on systemic risk.

488
00:22:56,066 --> 00:22:59,000
What are those things that can
undermine the economy, national

489
00:22:59,066 --> 00:23:00,533
security, public
health and safety?

490
00:23:00,933 --> 00:23:04,133
But at the same time, we've got
to be able to ensure that the

491
00:23:04,200 --> 00:23:08,166
underlying, the grassroots
doesn't get to a position where

492
00:23:08,233 --> 00:23:10,666
it in and of itself is
no longer functional.

493
00:23:10,733 --> 00:23:14,000
So, that broader public, we've
historically done the National

494
00:23:14,066 --> 00:23:15,833
Cybersecurity Awareness Month
piece, but we're not - we

495
00:23:15,900 --> 00:23:17,166
haven't gone far enough.

496
00:23:17,166 --> 00:23:20,933
So, it's about working with
organizations to help tech

497
00:23:21,000 --> 00:23:25,266
companies, to help them ensure
better security by design and

498
00:23:25,333 --> 00:23:28,700
deployment, but also put -
educate, you know, help educate

499
00:23:28,766 --> 00:23:29,933
the American public.

500
00:23:30,000 --> 00:23:32,633
>> HEATHER DAHL: So, one could
say we haven't gone far enough

501
00:23:32,700 --> 00:23:35,366
and there's a responsibility on
the tech industry also to help

502
00:23:35,433 --> 00:23:37,099
educate at the grassroots level.

503
00:23:37,166 --> 00:23:40,299
Do you think one of the reasons
we may not have gone far enough

504
00:23:40,366 --> 00:23:44,099
is because it inhibits the
growth of the data economy if we

505
00:23:44,166 --> 00:23:47,066
educate more people about what's
happening with their data?

506
00:23:47,066 --> 00:23:53,433
>> CHRISTOPHER KREBS: Oh, I - I
am not sure that's a risk that

507
00:23:53,500 --> 00:23:59,033
I would be too concerned about
because innovation will happen

508
00:23:59,099 --> 00:24:00,066
depending on how you shape it.

509
00:24:00,133 --> 00:24:03,966
It's - data wants to be free
in some respects, but so does

510
00:24:04,033 --> 00:24:06,565
innovation want to
stay ahead of it.

511
00:24:06,566 --> 00:24:11,133
So, we are going to continue to
help organizations get better

512
00:24:11,200 --> 00:24:14,333
security by design and
deployment and that's across a

513
00:24:14,400 --> 00:24:21,266
range of systems including,
you know, IoT and, you know,

514
00:24:21,333 --> 00:24:23,266
particularly as we move into 5G.

515
00:24:23,333 --> 00:24:25,299
If anybody is filling out a
bingo card, I think I probably

516
00:24:25,366 --> 00:24:26,266
filled one out for you.

517
00:24:29,099 --> 00:24:32,633
>> HEATHER DAHL: Taking this
back to our theme, cybersecurity

518
00:24:32,700 --> 00:24:33,666
needing a posse.

519
00:24:33,733 --> 00:24:36,033
What does this
theme mean to you?

520
00:24:36,099 --> 00:24:37,500
What does that mean to you?

521
00:24:37,566 --> 00:24:39,400
>> CHRISTOPHER KREBS: This is
both the imagery and the words.

522
00:24:39,466 --> 00:24:41,866
The imagery -
this is an inside joke.

523
00:24:41,933 --> 00:24:45,966
So, Andre the Giant has a
posse, it is an inside joke.

524
00:24:46,033 --> 00:24:49,699
For us, pineapple has been
adopted as our election security

525
00:24:49,766 --> 00:24:51,666
spirit animal or mascot.

526
00:24:51,733 --> 00:24:55,066
And also, for the cybersecurity
community, Wi-Fi pineapples, all

527
00:24:55,133 --> 00:24:56,500
of that,
so it means something to us.

528
00:24:56,566 --> 00:25:00,833
But the words cybersecurity has
a posse, we're only going to be

529
00:25:00,900 --> 00:25:02,733
able to do this together.

530
00:25:02,799 --> 00:25:06,200
The African proverb if you
want to go fast, go alone.

531
00:25:06,266 --> 00:25:07,700
If you want to go
far, go together.

532
00:25:07,766 --> 00:25:09,599
This is what we have
to achieve here.

533
00:25:09,666 --> 00:25:10,633
Common purpose.

534
00:25:10,700 --> 00:25:11,400
Working together.

535
00:25:11,466 --> 00:25:12,666
Industry, government.

536
00:25:12,733 --> 00:25:14,233
Please, work with me.

537
00:25:14,299 --> 00:25:15,833
Check us out online.

538
00:25:15,900 --> 00:25:17,633
Go to CISA.gov.

539
00:25:17,700 --> 00:25:19,533
We can figure out how
to do this together.

540
00:25:19,599 --> 00:25:21,700
You can see all the resources
we have available but more

541
00:25:21,766 --> 00:25:23,566
importantly, we're hiring.

542
00:25:23,633 --> 00:25:24,566
Come work with us.

543
00:25:24,633 --> 00:25:26,700
We've got plenty - we have
hundreds of opportunities to

544
00:25:26,766 --> 00:25:27,766
work with folks.

545
00:25:27,833 --> 00:25:30,766
So, thank you for the
opportunity to speak with you.

546
00:25:30,833 --> 00:25:31,966
>> HEATHER DAHL: Thank you.

547
00:25:32,033 --> 00:25:33,599
Thank you for spending
this time together with me.

548
00:25:33,666 --> 00:25:35,666
Thank you for spending
this time together with us.

549
00:25:35,733 --> 00:25:36,733
Thank you.

550
00:25:36,799 --> 00:25:38,000
(Applause)

