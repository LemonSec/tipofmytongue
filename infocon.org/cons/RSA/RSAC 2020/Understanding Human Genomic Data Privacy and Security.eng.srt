1
00:00:00,183 --> 00:00:02,766
(upbeat music)

2
00:00:04,130 --> 00:00:05,770
- Individuals are more and more interested

3
00:00:05,770 --> 00:00:07,729
in their genetic information.

4
00:00:07,730 --> 00:00:11,480
You can go to the gas station
or fast food restaurant

5
00:00:11,480 --> 00:00:13,090
and hear people talking
about their results

6
00:00:13,090 --> 00:00:16,730
from DTC consumers or from the doctor.

7
00:00:16,730 --> 00:00:19,430
What I'm most concerned about
is that we do protect privacy,

8
00:00:19,430 --> 00:00:22,100
but at the same time that
this information is available

9
00:00:22,100 --> 00:00:24,350
to use for research,
particularly, we're getting

10
00:00:24,350 --> 00:00:25,910
the kind of porosity that we're seeing

11
00:00:25,910 --> 00:00:27,770
in a place like Kaiser and others

12
00:00:27,770 --> 00:00:30,860
where clinical and research integration

13
00:00:30,860 --> 00:00:33,560
is really happening rapidly,
and that's very important.

14
00:00:33,560 --> 00:00:36,220
And so I've developed a system
that I've worked on for years

15
00:00:36,220 --> 00:00:39,120
and have a partner called LunaDNA

16
00:00:39,120 --> 00:00:42,300
whereby we allow individuals
to keep a string on their data.

17
00:00:42,300 --> 00:00:45,169
So they deposit their
genome, their medical record,

18
00:00:45,170 --> 00:00:47,500
their patient reported outcomes,

19
00:00:47,500 --> 00:00:51,650
and they get to tell who gets
access to this information.

20
00:00:51,650 --> 00:00:55,860
And the data stays in the
repository and multiple databases

21
00:00:55,860 --> 00:00:58,490
with lots of foreign key
structures, et cetera.

22
00:00:58,490 --> 00:01:01,130
And the questions come to that data,

23
00:01:01,130 --> 00:01:03,600
so sandboxes, virtual
compute environments,

24
00:01:03,600 --> 00:01:06,010
allow these questions to be asked

25
00:01:06,010 --> 00:01:09,060
and even spin up whole
communities around the questions.

26
00:01:09,060 --> 00:01:14,060
For me trying to drive a
consumer-driven health care system

27
00:01:14,300 --> 00:01:16,770
like we have now done in
ride sharing and music

28
00:01:16,770 --> 00:01:18,679
and other places, I think we're gonna need

29
00:01:18,680 --> 00:01:20,430
to see an integration of these systems

30
00:01:20,430 --> 00:01:23,310
such that the consumer
is central, the focus,

31
00:01:23,310 --> 00:01:24,490
and in fact gets rewarded.

32
00:01:24,490 --> 00:01:27,789
So in our system, we
have SEC qualified shares

33
00:01:27,790 --> 00:01:30,110
given to individuals for
sharing their information.

34
00:01:30,110 --> 00:01:32,410
And that means we're overseen by the SEC.

35
00:01:32,410 --> 00:01:34,869
And that gives us another
level of accountability

36
00:01:34,870 --> 00:01:38,390
and really moving people from
being subjects or patients

37
00:01:38,390 --> 00:01:39,320
to being partners.

38
00:01:39,320 --> 00:01:41,520
- If I'm an academic, and I do a study,

39
00:01:41,520 --> 00:01:43,880
and I'm at a university,
I'm doing something

40
00:01:43,880 --> 00:01:44,880
that's federally funded,

41
00:01:44,880 --> 00:01:47,399
I got to go through an
independent review board

42
00:01:47,400 --> 00:01:50,127
that says, "Well, did you
get the proper permission?

43
00:01:50,127 --> 00:01:51,607
"Is there some risk here?

44
00:01:51,607 --> 00:01:53,227
"Is what you're doing
likely to be helpful?

45
00:01:53,227 --> 00:01:54,327
"Is it gonna harm the people

46
00:01:54,327 --> 00:01:55,960
"who are part of the experiment?"

47
00:01:55,960 --> 00:01:58,669
But what if I'm a company and
I'm doing that same research,

48
00:01:58,670 --> 00:02:01,630
or I'm an academic and I'm
working with corporate data

49
00:02:01,630 --> 00:02:04,399
and it's not a federally funded project.

50
00:02:04,400 --> 00:02:06,910
I don't have that same review process.

51
00:02:06,910 --> 00:02:09,859
We need those done in a credible way

52
00:02:09,860 --> 00:02:12,440
so that we can rely that these
sorts of things get vetted.

53
00:02:12,440 --> 00:02:14,140
- How do we apply that in genome data

54
00:02:14,140 --> 00:02:15,750
of three and a half billion records?

55
00:02:15,750 --> 00:02:19,370
Do I selectively de-identify within it?

56
00:02:19,370 --> 00:02:20,750
And that's where the research is.

57
00:02:20,750 --> 00:02:22,530
Can we selectively do things?

58
00:02:22,530 --> 00:02:26,090
0.5% of unique identification
within the DNA, right?

59
00:02:26,090 --> 00:02:29,070
The majority of it is shared.

60
00:02:29,070 --> 00:02:31,820
And so when you think
about that DNA as humanity.

61
00:02:31,820 --> 00:02:33,579
I mean, I'm philosophical now.

62
00:02:33,580 --> 00:02:38,070
So, why yes, there's some very
unique pieces to the data,

63
00:02:38,070 --> 00:02:42,640
but in my view, only when
combined with other identifiers

64
00:02:42,640 --> 00:02:43,809
and context.

65
00:02:43,810 --> 00:02:46,580
And then we have to play that
all out, and think about it.

66
00:02:46,580 --> 00:02:48,420
Well, how do we apply from
a pragmatic standpoint

67
00:02:48,420 --> 00:02:50,040
in terms of security and controls?

68
00:02:50,040 --> 00:02:53,440
And clearly de-identification
and cryptography

69
00:02:53,440 --> 00:02:55,960
is gonna be key part of that.(murmurs)

70
00:02:55,960 --> 00:02:58,110
- First of all, 5% of a very large number

71
00:02:58,110 --> 00:02:59,580
is still a very large number.

72
00:02:59,580 --> 00:03:00,413
- Sure.

73
00:03:00,413 --> 00:03:01,560
- So we have to acknowledge that.

74
00:03:01,560 --> 00:03:04,140
And we've actually all heard stories,

75
00:03:04,140 --> 00:03:06,100
feel good stories actually,

76
00:03:06,100 --> 00:03:08,829
where somebody who did
not submit knowingly

77
00:03:08,830 --> 00:03:11,290
their genetic information
was actually identified

78
00:03:11,290 --> 00:03:14,510
because someone else freely
shared their information.

79
00:03:14,510 --> 00:03:16,890
And that allowed someone, an investigator

80
00:03:16,890 --> 00:03:19,049
to triangulate on an individual.

81
00:03:19,050 --> 00:03:21,250
And you can pretty easily see scenarios

82
00:03:21,250 --> 00:03:22,790
where someone is very interested

83
00:03:22,790 --> 00:03:24,890
in finding someone who
doesn't want to be found.

84
00:03:24,890 --> 00:03:26,809
- I think there's also
a nefarious use of data

85
00:03:26,810 --> 00:03:28,450
happening already, we've seen that,

86
00:03:28,450 --> 00:03:30,079
especially in medical record breaks,

87
00:03:30,080 --> 00:03:31,740
but also in genomic information.

88
00:03:31,740 --> 00:03:34,120
And I'm very concerned not so much maybe

89
00:03:34,120 --> 00:03:36,810
about an individual, but
that that individual's genome

90
00:03:36,810 --> 00:03:39,220
actually is a representation
of their family,

91
00:03:39,220 --> 00:03:40,750
their ancestors, their children.

92
00:03:40,750 --> 00:03:42,440
So when I share my genome,

93
00:03:42,440 --> 00:03:44,640
I maybe should be asking
my parents and my children

94
00:03:44,640 --> 00:03:46,480
for permission, I don't, but I could.

95
00:03:46,480 --> 00:03:49,179
- There are a lot of very
technically interesting solutions

96
00:03:49,180 --> 00:03:51,550
that are things like, oh, here's a way

97
00:03:51,550 --> 00:03:54,380
in which you can use powerful cryptography

98
00:03:54,380 --> 00:03:57,130
in such a way that an
insurance company for example,

99
00:03:57,130 --> 00:03:59,359
could query your doctor's database,

100
00:03:59,360 --> 00:04:04,040
not learn any of the plain text
information about your DNA,

101
00:04:04,040 --> 00:04:05,670
but nonetheless be able to compute

102
00:04:05,670 --> 00:04:06,910
what it is they want to compute.

103
00:04:06,910 --> 00:04:08,750
For example, it might be things like

104
00:04:08,750 --> 00:04:10,800
how to set your insurance pricing again

105
00:04:10,800 --> 00:04:13,410
in a potentially discriminatory way?

106
00:04:13,410 --> 00:04:14,490
Now, what have we done here?

107
00:04:14,490 --> 00:04:16,230
This is a very cool technology,

108
00:04:16,230 --> 00:04:18,269
but it doesn't actually
address the concern

109
00:04:18,269 --> 00:04:19,140
that people have.

110
00:04:19,140 --> 00:04:20,930
It actually enables the very thing

111
00:04:20,930 --> 00:04:23,600
that they're worried about,
which is discriminatory pricing

112
00:04:23,600 --> 00:04:26,060
using your genetic information, right?

113
00:04:26,060 --> 00:04:28,520
So I wanted to just give
that note of caution,

114
00:04:28,520 --> 00:04:31,620
when people say privacy,
they often mean fairness,

115
00:04:31,620 --> 00:04:33,500
and so we should take that into account.

116
00:04:33,500 --> 00:04:35,460
And cryptography is very powerful,

117
00:04:35,460 --> 00:04:38,120
but only if we use it in the right way.

118
00:04:38,120 --> 00:04:40,730
- It's gonna be a wild ride,

119
00:04:40,730 --> 00:04:43,720
because these issues are
messy, and guess what?

120
00:04:43,720 --> 00:04:45,870
We haven't figured them
out in the rest of life.

121
00:04:45,870 --> 00:04:48,710
There's no way we're gonna
solve them easily online.

122
00:04:48,710 --> 00:04:51,150
We haven't figured out the
balance of free speech.

123
00:04:51,150 --> 00:04:52,340
We haven't figured out,

124
00:04:52,340 --> 00:04:56,210
what is and what isn't
the right discrimination?

125
00:04:56,210 --> 00:04:58,320
When am I discriminating
in a positive way?

126
00:04:58,320 --> 00:04:59,400
When is it a negative way?

127
00:04:59,400 --> 00:05:01,440
Who gets protected?

128
00:05:01,440 --> 00:05:04,320
When is it relevant to
treat people differently?

129
00:05:04,320 --> 00:05:05,180
When is it economic?

130
00:05:05,180 --> 00:05:07,400
We haven't solved these
problems elsewhere.

131
00:05:07,400 --> 00:05:08,289
It's messy.

132
00:05:08,290 --> 00:05:09,890
It's different in every country.

133
00:05:09,890 --> 00:05:13,360
It's gonna be messy and
uncomfortable and hard.

134
00:05:13,360 --> 00:05:16,000
But we have no choice and
if you're optimist like I am

135
00:05:16,000 --> 00:05:18,290
about what can be done with tech and data,

136
00:05:18,290 --> 00:05:19,655
hang on for the ride.

137
00:05:19,655 --> 00:05:22,238
(upbeat music)

