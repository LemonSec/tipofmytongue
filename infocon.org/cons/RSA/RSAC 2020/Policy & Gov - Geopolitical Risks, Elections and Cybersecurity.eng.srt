1
00:00:06,233 --> 00:00:08,633
>> ANNOUNCER: Please
welcome Admiral James

2
00:00:08,699 --> 00:00:11,500
Stavridis and
Juliette Kayyem.

3
00:00:28,366 --> 00:00:29,399
>> JULIETTE KAYYEM: Good
afternoon, everyone.

4
00:00:29,466 --> 00:00:31,833
I am Juliette Kayyem and
I'm thrilled to be here

5
00:00:31,899 --> 00:00:35,166
with the Admiral
discussing cybersecurity.

6
00:00:35,233 --> 00:00:36,933
We know it has been a long
conference and we know

7
00:00:37,000 --> 00:00:38,500
we're at the end of it,
so we're grateful that

8
00:00:38,566 --> 00:00:39,500
you're all here.

9
00:00:40,399 --> 00:00:41,899
>> JAMES STAVRIDIS:
Yeah. Wow. Thank you.

10
00:00:41,966 --> 00:00:43,533
Great to see
everybody here.

11
00:00:43,600 --> 00:00:46,500
The main reason I get
invited is because every

12
00:00:46,566 --> 00:00:49,899
year, the organizers want
one person who is willing

13
00:00:49,966 --> 00:00:53,966
to put on a necktie
besides the security force.

14
00:00:54,033 --> 00:00:55,633
It is just me and
the security people.

15
00:00:55,700 --> 00:00:58,100
So, that tie is for you.

16
00:00:58,166 --> 00:00:59,500
It is great to be here.

17
00:00:59,566 --> 00:01:00,966
Thank you for having me.

18
00:01:01,033 --> 00:01:02,233
>> JULIETTE KAYYEM: So,
this is a little bit of a

19
00:01:02,299 --> 00:01:03,533
different kind of keynote.

20
00:01:03,600 --> 00:01:05,733
We figured you guys have
all - and gals have all

21
00:01:05,799 --> 00:01:07,799
been keynoted out and so
we thought we would just

22
00:01:07,866 --> 00:01:08,966
take the opportunity.

23
00:01:09,033 --> 00:01:10,799
The Admiral and I have
known each other a long

24
00:01:10,866 --> 00:01:13,866
time, both in government
and outside of government.

25
00:01:13,933 --> 00:01:15,333
We thought we would
take the opportunity to

26
00:01:15,400 --> 00:01:17,799
actually just have a
conversation about major

27
00:01:17,866 --> 00:01:19,866
themes around cybersecurity.

28
00:01:19,933 --> 00:01:23,166
Cybersecurity is a big
topic, we know, and so

29
00:01:23,233 --> 00:01:25,766
we're going to focus today
on the topics that you

30
00:01:25,833 --> 00:01:28,233
know really well around
national security,

31
00:01:28,299 --> 00:01:31,466
military security, and I
will chime in on Homeland

32
00:01:31,533 --> 00:01:33,566
Security which is
where my background is.

33
00:01:33,633 --> 00:01:35,232
So, that's how we're sort
of going to play it out

34
00:01:35,299 --> 00:01:36,333
the next fifty minutes.

35
00:01:36,400 --> 00:01:38,566
Just want to thank you
for being here and your

36
00:01:38,633 --> 00:01:42,265
service now in the private
sector, but in academia

37
00:01:42,333 --> 00:01:44,000
and in the public sector.

38
00:01:44,066 --> 00:01:45,099
>> JAMES STAVRIDIS:
Well, thanks, and I'll

39
00:01:45,166 --> 00:01:46,500
return the compliment.

40
00:01:46,566 --> 00:01:48,599
There are a lot of ways
to serve the country.

41
00:01:48,666 --> 00:01:52,200
Your work as Assistant
Secretary at Homeland

42
00:01:52,266 --> 00:01:54,566
Security helped make
this country safe.

43
00:01:54,633 --> 00:01:55,833
It is pleasure
to be with you.

44
00:01:55,900 --> 00:01:56,799
>> JULIETTE KAYYEM:
Thank you.

45
00:01:56,866 --> 00:01:59,799
Let's start with the big
themes or the big problems

46
00:01:59,866 --> 00:02:01,866
which is essentially
nation state aggression

47
00:02:01,933 --> 00:02:05,933
against the United States
and this low warfare,

48
00:02:06,000 --> 00:02:09,966
cheap kind of attacks
on our critical

49
00:02:10,032 --> 00:02:11,500
infrastructure and
cybersecurity.

50
00:02:11,566 --> 00:02:13,866
One of the challenges, I
think, when we talk about

51
00:02:13,933 --> 00:02:15,500
it, it is very
hard to prioritize.

52
00:02:15,566 --> 00:02:17,500
So, when you think about
it, is it - should we

53
00:02:17,566 --> 00:02:20,233
prioritize it by country
or is there another way to

54
00:02:20,300 --> 00:02:22,199
think about those
kinds of risks?

55
00:02:22,266 --> 00:02:23,333
>> JAMES STAVRIDIS:
That's a great question.

56
00:02:23,400 --> 00:02:26,833
I think I'm going to
organize it by country to

57
00:02:26,900 --> 00:02:30,233
just kind of very quickly
hit the four principle

58
00:02:30,300 --> 00:02:33,966
countries that are
involved geopolitically in

59
00:02:34,033 --> 00:02:36,198
mounting threat to the
United States in this

60
00:02:36,266 --> 00:02:38,632
sphere, and none of them
are going to surprise you.

61
00:02:38,699 --> 00:02:40,966
Let's start with Russia.

62
00:02:41,033 --> 00:02:43,833
Russia comes at us in kind
of three vectors, right.

63
00:02:43,900 --> 00:02:47,699
Number one, they are
developing and increasing

64
00:02:47,766 --> 00:02:51,433
their ability in offensive
cyber capability that, as

65
00:02:51,500 --> 00:02:55,666
you know very well, has a
precision guided component to

66
00:02:55,733 --> 00:02:58,466
it that looks at our national
critical infrastructure.

67
00:02:58,533 --> 00:03:03,799
Number two, most of the
moment is the fact that

68
00:03:03,866 --> 00:03:08,133
Russia is going to interfere
in our election in 2020.

69
00:03:08,199 --> 00:03:10,966
They did interfere in
our election in 2016.

70
00:03:11,033 --> 00:03:14,366
So, that's a particular,
specific niche and I hope

71
00:03:14,433 --> 00:03:15,933
we can come back to that.

72
00:03:16,000 --> 00:03:19,666
Number three, Russia, and
this is very different

73
00:03:19,733 --> 00:03:22,300
than the other two,
Russia operates a kind of

74
00:03:22,366 --> 00:03:27,133
public/private partnership
with black hat

75
00:03:27,199 --> 00:03:31,766
cyber-criminal gangs and
effectively issues letters

76
00:03:31,833 --> 00:03:35,300
of mark to these black
hatters, much like Queen

77
00:03:35,366 --> 00:03:38,199
Elizabeth did to
Sir Francis Drake.

78
00:03:38,266 --> 00:03:41,799
Go forth and commit piracy
on behalf of England.

79
00:03:41,866 --> 00:03:45,000
Today it is go forth and
do cyber-criminal activity.

80
00:03:45,066 --> 00:03:47,766
We are going to tax you.

81
00:03:47,833 --> 00:03:49,599
And it is kind of
like the Godfather.

82
00:03:49,666 --> 00:03:54,500
At some point, we will
come and ask of you a favor.

83
00:03:54,566 --> 00:03:56,266
It is a very
clever construct.

84
00:03:56,333 --> 00:03:58,966
So, that's Russia
as a package.

85
00:03:59,033 --> 00:04:01,166
Secondly, Juliette, it has
been a big topic of the

86
00:04:01,233 --> 00:04:04,666
conversation here at RSA,
of course, is China.

87
00:04:04,733 --> 00:04:07,866
Here it is a different
basket of threat vector.

88
00:04:07,933 --> 00:04:12,132
I think what I worry about
the most is obviously

89
00:04:12,199 --> 00:04:15,099
intellectual property
theft, but not if you

90
00:04:15,166 --> 00:04:19,266
will, garden variety, but
when it entails high end

91
00:04:19,333 --> 00:04:21,899
military stealth
capabilities or

92
00:04:21,966 --> 00:04:24,800
propulsion, jet engines.

93
00:04:24,866 --> 00:04:27,800
Increasingly it might
go after artificial

94
00:04:27,866 --> 00:04:31,032
intelligence and other
really high-end crown jewels.

95
00:04:31,100 --> 00:04:35,833
China does very effective
job there and they do it

96
00:04:35,899 --> 00:04:40,733
with a very sophisticated,
blended, almost

97
00:04:40,800 --> 00:04:43,433
interagency kind of
approach that brings

98
00:04:43,500 --> 00:04:47,699
together civilian hackers,
much like in Russia.

99
00:04:47,766 --> 00:04:50,766
It involves their
cyber force.

100
00:04:50,833 --> 00:04:52,633
They have a cyber force.

101
00:04:52,699 --> 00:04:55,933
You know, we have an Army,
a Navy, a Marine Corp and

102
00:04:56,000 --> 00:04:56,766
an Air Force.

103
00:04:56,833 --> 00:04:59,066
We don't have
a cyber force.

104
00:04:59,133 --> 00:05:00,399
I think we should.

105
00:05:00,466 --> 00:05:02,566
That's part of this.

106
00:05:02,633 --> 00:05:06,000
And as well, they also
use Chinese commercial

107
00:05:06,066 --> 00:05:08,832
capability and finally,
they use good old fashioned

108
00:05:08,899 --> 00:05:11,233
humans, insider threat.

109
00:05:11,300 --> 00:05:13,266
We have seen some folks
recently indicted as a

110
00:05:13,333 --> 00:05:14,133
result of this.

111
00:05:14,199 --> 00:05:17,133
So, it is a sophisticated
and very clever model.

112
00:05:17,199 --> 00:05:18,699
So, that's kind of China.

113
00:05:18,766 --> 00:05:22,166
And then very quickly,
North Korea, it is your

114
00:05:22,233 --> 00:05:25,133
garden variety thugocracy.

115
00:05:25,199 --> 00:05:28,000
It is all about the
money for Kim Jong-Un.

116
00:05:28,066 --> 00:05:31,500
He wants his cyber
capability to generate cash.

117
00:05:31,566 --> 00:05:35,366
That's why WannaCry,
ransomware, it came

118
00:05:35,433 --> 00:05:36,399
out of North Korea.

119
00:05:36,466 --> 00:05:39,466
It was a funding stream
for the young leader.

120
00:05:39,533 --> 00:05:42,500
And then secondly,
occasionally, he will unleash

121
00:05:42,566 --> 00:05:47,500
these cyberattack dogs
when he's irritated or annoyed.

122
00:05:47,566 --> 00:05:49,465
You may have seen this
really terrible movie that

123
00:05:49,533 --> 00:05:52,266
came out several years
ago called The Interview.

124
00:05:52,333 --> 00:05:55,300
It's one of the worst movies
in the history of movies.

125
00:05:55,366 --> 00:05:57,899
I talk about it and as
an act of professional

126
00:05:57,966 --> 00:05:59,733
diligence, I say to
myself, you know, I really

127
00:05:59,800 --> 00:06:01,199
ought to watch that movie.

128
00:06:01,266 --> 00:06:04,199
Made it through about
fourteen minutes, but

129
00:06:04,266 --> 00:06:07,233
believe me, Kim Jong-Un
watched the whole movie

130
00:06:07,300 --> 00:06:09,966
because it makes him
look kind of stupid.

131
00:06:10,033 --> 00:06:12,699
So, he unleashed a
cyberattack against Sony

132
00:06:12,766 --> 00:06:16,333
Pictures, an America -
large America company and

133
00:06:16,399 --> 00:06:19,199
did hundreds of millions
of dollars in kinetic damage.

134
00:06:19,266 --> 00:06:23,199
So, that's kind of North
Korea, ego driven and money.

135
00:06:23,266 --> 00:06:24,633
Lastly, Iran.

136
00:06:24,699 --> 00:06:27,333
We have to be very careful
here and you know this

137
00:06:27,399 --> 00:06:29,866
very well from your days
in the department and I

138
00:06:29,933 --> 00:06:32,233
would love to hear how
it looks like from the

139
00:06:32,300 --> 00:06:33,399
domestic side
at the moment.

140
00:06:33,466 --> 00:06:38,199
But Iran is nudging into
the big leagues in their

141
00:06:38,266 --> 00:06:42,333
ability to start targeting
key sectors and they're

142
00:06:42,399 --> 00:06:45,500
very interested in our big
banks, our financial sector,

143
00:06:45,566 --> 00:06:52,232
and they're also quite
interested in dams, water.

144
00:06:52,300 --> 00:06:54,133
I'm on the Board of
American Water, a large

145
00:06:54,199 --> 00:06:55,466
public utility.

146
00:06:55,533 --> 00:06:57,333
We see them edging around.

147
00:06:57,399 --> 00:07:01,766
So, they are not so much
about money as they are

148
00:07:01,833 --> 00:07:05,399
about learning how to be
a threat to the United

149
00:07:05,466 --> 00:07:08,766
States and I'll conclude
here, they also take those

150
00:07:08,833 --> 00:07:12,699
cyber means and use them
against Israel, against

151
00:07:12,766 --> 00:07:15,500
Saudi Arabia, against the
Gulf states, our allies,

152
00:07:15,566 --> 00:07:16,965
partners, and friends
in the Middle East.

153
00:07:17,033 --> 00:07:19,166
So, that's a quick sketch.

154
00:07:19,233 --> 00:07:21,000
How about from the
domestic perspective

155
00:07:21,066 --> 00:07:22,066
looking at that?

156
00:07:22,133 --> 00:07:23,166
>> JULIETTE KAYYEM:
So, you know, from the

157
00:07:23,233 --> 00:07:26,833
Homeland Security side,
the perpetrator was of

158
00:07:26,899 --> 00:07:30,000
less interest simply
because we didn't have the

159
00:07:30,066 --> 00:07:32,166
means to respond to it,
whether it was Russia, Iran.

160
00:07:32,233 --> 00:07:34,533
I mean, I think the
challenges that we

161
00:07:34,600 --> 00:07:38,166
experienced were two-fold.

162
00:07:38,233 --> 00:07:40,000
One, it is just the
governance challenge.

163
00:07:40,066 --> 00:07:43,965
We tend to think of
cybersecurity as oh, the

164
00:07:44,033 --> 00:07:45,533
dot MIL, dot GOV domain.

165
00:07:45,600 --> 00:07:48,233
The critical
infrastructure is owned

166
00:07:48,300 --> 00:07:52,866
60% to 70% by the private
sector and state and local

167
00:07:52,933 --> 00:07:56,133
governments retain a lot
of information about you

168
00:07:56,199 --> 00:07:59,733
and about whether it is
your driver's licenses or

169
00:07:59,800 --> 00:08:03,100
this new real ID that
could be easily accessed too.

170
00:08:03,166 --> 00:08:05,733
So, the challenge, I often
say in Homeland Security,

171
00:08:05,800 --> 00:08:07,466
it's the security
is the easy part.

172
00:08:07,533 --> 00:08:10,333
The homeland is the hard
part because without

173
00:08:10,399 --> 00:08:12,399
standards about what
kind of cybersecurity

174
00:08:12,466 --> 00:08:16,033
protections, even outside
of elections where there's

175
00:08:16,100 --> 00:08:19,766
been a lot of focus and
we'll get to that, that is

176
00:08:19,833 --> 00:08:22,199
of concern to me as sort
of the state and local

177
00:08:22,266 --> 00:08:24,433
aspects of those
vulnerabilities.

178
00:08:24,500 --> 00:08:26,666
We tend to focus on the
dot MIL and the federal

179
00:08:26,733 --> 00:08:27,833
dot GOV domain.

180
00:08:27,899 --> 00:08:30,866
I think the second issue -
it is funny you brought up Sony.

181
00:08:30,933 --> 00:08:32,765
I actually assign that
movie for my class.

182
00:08:32,832 --> 00:08:34,065
It is awful.

183
00:08:34,133 --> 00:08:36,399
It is awful on
the seventh time.

184
00:08:36,466 --> 00:08:41,500
But the reason why, it is
a perfect example of one

185
00:08:41,566 --> 00:08:43,700
of the challenges we had
in the public/private

186
00:08:43,765 --> 00:08:47,799
partnership aspect, and
this applies to a lot of

187
00:08:47,866 --> 00:08:52,366
you, is for companies that
don't view themselves as

188
00:08:52,433 --> 00:08:55,933
security companies, for
them to take seriously

189
00:08:56,000 --> 00:08:57,399
their cyber
vulnerabilities.

190
00:08:57,466 --> 00:08:59,500
So, if you're a critical
infrastructure, you were

191
00:08:59,566 --> 00:09:01,299
saying - if you're a
critical infrastructure

192
00:09:01,366 --> 00:09:04,633
entity, your - I mean,
you know that you're

193
00:09:04,700 --> 00:09:07,700
vulnerable, especially
if you're PG&E or you're

194
00:09:07,766 --> 00:09:08,565
a water company.

195
00:09:08,633 --> 00:09:10,000
You know you are
vulnerable and you're

196
00:09:10,066 --> 00:09:11,933
going to have to sort of
commit the resources.

197
00:09:12,000 --> 00:09:15,100
Sony is a perfect example,
a Japanese company with an

198
00:09:15,166 --> 00:09:18,366
American distribution
on this side.

199
00:09:18,433 --> 00:09:23,200
It had cybersecurity but
one wouldn't have called

200
00:09:23,266 --> 00:09:25,833
it particularly
sophisticated.

201
00:09:25,899 --> 00:09:27,866
When we looked back at
how it happened, it was

202
00:09:27,933 --> 00:09:30,100
essentially a single
point of failure.

203
00:09:30,166 --> 00:09:31,966
It was a system
administrator's password

204
00:09:32,033 --> 00:09:35,700
got the North Koreans
into the entire system.

205
00:09:35,766 --> 00:09:38,766
And Sony, you know,
they'll say they never

206
00:09:38,833 --> 00:09:40,899
sort of envisioned
themselves as a national

207
00:09:40,966 --> 00:09:43,366
security threat but I
think that there is no

208
00:09:43,433 --> 00:09:46,066
distinction now, that you
could go after - in the

209
00:09:46,133 --> 00:09:48,100
same way that terrorists
could go after Disneyland

210
00:09:48,166 --> 00:09:51,166
and that would be the same as
if they went after the Pentagon.

211
00:09:51,233 --> 00:09:56,065
Cyber - you know, a
foreign country could do

212
00:09:56,133 --> 00:09:58,000
the same with a private
company that does not see

213
00:09:58,066 --> 00:10:00,899
itself as in critical
infrastructure, so getting

214
00:10:00,966 --> 00:10:03,933
that group of companies to
the level that you would

215
00:10:04,000 --> 00:10:06,100
feel good about
is difficult.

216
00:10:06,166 --> 00:10:07,299
>> JAMES STAVRIDIS: Yeah.

217
00:10:07,366 --> 00:10:10,533
I think this opens just a
gut question which is what

218
00:10:10,600 --> 00:10:14,399
are the responsibilities
of the US government to

219
00:10:14,466 --> 00:10:18,399
defend all of us
in the cyber world?

220
00:10:18,466 --> 00:10:23,399
If I ask you, well, let's
imagine a scenario where

221
00:10:23,466 --> 00:10:27,733
there's a brand new US
cruise ship and let's say

222
00:10:27,799 --> 00:10:30,165
it got built in Korea
which builds really,

223
00:10:30,233 --> 00:10:33,632
really nice cruise ships,
and that cruise ship had

224
00:10:33,700 --> 00:10:36,200
no passengers on it, it
was just being effectively

225
00:10:36,266 --> 00:10:38,165
ferried back to
the United States.

226
00:10:38,233 --> 00:10:40,233
Those cruise ships
cost a couple of

227
00:10:40,299 --> 00:10:41,566
hundred million dollars.

228
00:10:41,633 --> 00:10:45,766
If I said to you, well,
what do you think the US

229
00:10:45,833 --> 00:10:49,866
response would be and who
is responsible if the

230
00:10:49,933 --> 00:10:51,899
North Koreans sent a
submarine out, put a

231
00:10:51,966 --> 00:10:53,933
torpedo in the
side, and sank it?

232
00:10:54,000 --> 00:10:56,766
You would all say the
Department of Defense.

233
00:10:56,833 --> 00:10:58,366
Of course, the military
is going to do that.

234
00:10:58,433 --> 00:11:01,633
Just like Juliette's
point, if Disneyland were

235
00:11:01,700 --> 00:11:05,166
under attack, it would be
send the marines to Disneyland.

236
00:11:05,233 --> 00:11:07,433
That's obvious.

237
00:11:07,500 --> 00:11:11,200
But in this cyber world,
we just haven't worked

238
00:11:11,266 --> 00:11:12,733
this out yet.

239
00:11:12,799 --> 00:11:15,933
And so when something
happens like the Sony

240
00:11:16,000 --> 00:11:18,733
attack, and I would call
that an attack, it was a

241
00:11:18,799 --> 00:11:21,566
couple hundred million
dollars of kinetic damage

242
00:11:21,633 --> 00:11:23,899
and a couple hundred
million dollars of

243
00:11:23,966 --> 00:11:28,633
business capital that are
lost and to me, that looks

244
00:11:28,700 --> 00:11:32,299
a lot like an attack but
you know, the Department

245
00:11:32,366 --> 00:11:34,000
of Defense
wasn't called in.

246
00:11:34,066 --> 00:11:36,133
There was kind of - the
response was very mild.

247
00:11:36,200 --> 00:11:38,866
It was kind of let's
flicker the internet in

248
00:11:38,933 --> 00:11:41,066
North Korea to show
them that we can do it.

249
00:11:41,133 --> 00:11:46,566
You know, if they had sunk
a US asset like that, it

250
00:11:46,633 --> 00:11:50,100
would have been line
up the B2 bombers.

251
00:11:50,166 --> 00:11:53,133
So, I'm not advocating
that by the way.

252
00:11:53,200 --> 00:11:56,399
What I do think we
need to do, and you and I

253
00:11:56,466 --> 00:11:58,933
are a pretty good tag
team on this, military,

254
00:11:59,000 --> 00:12:02,666
Homeland Security, is
where are those lines and

255
00:12:02,733 --> 00:12:04,665
what are the responsibilities
for the government?

256
00:12:04,733 --> 00:12:08,599
I think the government
needs to pick up more of this.

257
00:12:08,666 --> 00:12:10,566
We're putting too much of
this burden on the private

258
00:12:10,633 --> 00:12:11,766
sector, in my view.

259
00:12:11,833 --> 00:12:13,132
>> JULIETTE KAYYEM: I
think that's absolutely

260
00:12:13,200 --> 00:12:17,899
right just because their
access to intelligence

261
00:12:17,966 --> 00:12:19,133
will be very
different as well.

262
00:12:19,200 --> 00:12:23,233
So, and you know, the
countries that may be a

263
00:12:23,299 --> 00:12:26,333
threat are probably
well-known to these

264
00:12:26,399 --> 00:12:28,533
companies, but how they
might go about it and the

265
00:12:28,600 --> 00:12:31,233
vulnerability that these
companies might have is,

266
00:12:31,299 --> 00:12:33,266
you know, something that's
unique to them, unlike,

267
00:12:33,333 --> 00:12:34,766
you know, most of the
companies represented

268
00:12:34,833 --> 00:12:36,799
here, they're
sophisticated in this stuff.

269
00:12:36,866 --> 00:12:39,766
I want to move though
because we have so many

270
00:12:39,833 --> 00:12:42,433
things we want to talk
about, and obviously, the

271
00:12:42,500 --> 00:12:45,700
election and
election security.

272
00:12:45,766 --> 00:12:46,766
>> JAMES STAVRIDIS: Sure.

273
00:12:46,833 --> 00:12:47,899
>> JULIETTE KAYYEM:
I want to just try to

274
00:12:47,966 --> 00:12:51,066
disaggregate from the
homeland side, three

275
00:12:51,133 --> 00:12:53,666
different issues and I
want to just focus on one

276
00:12:53,733 --> 00:12:55,065
with the Admiral.

277
00:12:55,133 --> 00:12:57,100
So, there is
disinformation which is

278
00:12:57,166 --> 00:13:01,433
you know, that's the sort
of lies and other things

279
00:13:01,500 --> 00:13:03,866
put on websites and the
responsibility of social

280
00:13:03,933 --> 00:13:05,833
media platforms and
the use by the Russians

281
00:13:05,899 --> 00:13:08,000
of those platforms.

282
00:13:08,066 --> 00:13:10,399
That's not really - it is
not really a cyber issue but

283
00:13:10,466 --> 00:13:12,833
that is an election issue
and sort of their obligation.

284
00:13:12,899 --> 00:13:16,000
So, you know, the idea
that the number one story

285
00:13:16,066 --> 00:13:19,233
in Pennsylvania, areas
- Catholic areas of

286
00:13:19,299 --> 00:13:21,933
Pennsylvania on Facebook
leading up to the election

287
00:13:22,000 --> 00:13:25,799
in 2016 was that the Pope had
indeed endorsed Donald Trump.

288
00:13:25,866 --> 00:13:27,266
You know, that is
something that we know -

289
00:13:27,333 --> 00:13:29,665
you and I all know is a
lie, but for people who

290
00:13:29,733 --> 00:13:32,632
may not get their information
from other sources, didn't.

291
00:13:32,700 --> 00:13:33,899
So, that's the
disinformation, that

292
00:13:33,966 --> 00:13:35,866
continues to happen,
that's the debate you're

293
00:13:35,933 --> 00:13:37,966
hearing about the
social media platforms.

294
00:13:38,033 --> 00:13:42,633
The second is Iowa which
is just technology is bad

295
00:13:42,700 --> 00:13:43,799
sometimes, right?

296
00:13:43,866 --> 00:13:45,966
I mean, it's just that was
a stupid use of an app,

297
00:13:46,033 --> 00:13:47,966
you didn't even need to
use an app, and we'll get

298
00:13:48,033 --> 00:13:51,000
better at if we need to
use an app, not deploying

299
00:13:51,066 --> 00:13:53,633
it on the day of the most
watched election and

300
00:13:53,700 --> 00:13:55,633
caucus of our time.

301
00:13:55,700 --> 00:13:58,333
Right, so that was just
sort of - but it did

302
00:13:58,399 --> 00:14:01,333
raise, I think, the third
issue, which is the

303
00:14:01,399 --> 00:14:04,500
vulnerabilities, whether
it is through technology

304
00:14:04,566 --> 00:14:08,666
or an outside actor, of
our election system.

305
00:14:08,733 --> 00:14:12,599
And so, when you think
about 2018 happened,

306
00:14:12,666 --> 00:14:14,600
2020 is soon.

307
00:14:14,666 --> 00:14:19,700
When you think about your
confidence level, where is

308
00:14:19,766 --> 00:14:22,266
it right now in terms
of election security?

309
00:14:22,333 --> 00:14:26,199
Are we - have we ran out
of time though in the

310
00:14:26,266 --> 00:14:27,433
sense that it's started?

311
00:14:27,500 --> 00:14:30,266
>> JAMES STAVRIDIS: Yeah.
My confidence level is very high.

312
00:14:30,333 --> 00:14:34,533
My confidence is high that
the Russians are going to intrude.

313
00:14:34,600 --> 00:14:38,866
My confidence is high that
they will have impact doing so.

314
00:14:38,933 --> 00:14:40,500
I like your construct.

315
00:14:40,566 --> 00:14:46,200
I think the social media
deep fake, fake news, I

316
00:14:46,266 --> 00:14:49,333
think of that as kind of
the strategic level, and

317
00:14:49,399 --> 00:14:52,033
then I think there's an
operational level which

318
00:14:52,100 --> 00:14:52,899
you didn't mention.

319
00:14:52,966 --> 00:14:54,466
I just want to
throw it out there.

320
00:14:54,533 --> 00:14:57,833
It is the vulnerability
of the campaigns.

321
00:14:57,899 --> 00:15:02,000
If you think back to 2016,
I think a lot of sand in

322
00:15:02,066 --> 00:15:05,066
the gears in this case
for the Democrats was the

323
00:15:05,133 --> 00:15:09,000
hacking of John Podesta,
the campaign chief for

324
00:15:09,066 --> 00:15:12,200
Hillary Clinton, and the
distribution of a great

325
00:15:12,266 --> 00:15:13,933
many embarrassing emails.

326
00:15:14,000 --> 00:15:15,833
It kind of
undermined confidence.

327
00:15:15,899 --> 00:15:18,799
So, the vulnerability of
those campaigns who are

328
00:15:18,866 --> 00:15:20,665
not even using WhatsApp.

329
00:15:20,733 --> 00:15:23,500
I mean, they are just
using Gmail, sending a lot

330
00:15:23,566 --> 00:15:25,666
of sensitive material.

331
00:15:25,733 --> 00:15:29,065
Here I mean both the Trump
campaign and all of the

332
00:15:29,133 --> 00:15:30,566
current democratic campaigns.

333
00:15:30,633 --> 00:15:33,366
I think we better
up our game there.

334
00:15:33,433 --> 00:15:35,899
To do that, you need
things like end to end

335
00:15:35,966 --> 00:15:38,399
encryption which I'm on
the board of a small

336
00:15:38,466 --> 00:15:40,833
company, PreVeil,
which is doing this.

337
00:15:40,899 --> 00:15:43,299
It is one example of how
we need to harden these

338
00:15:43,366 --> 00:15:44,699
kinds of things.

339
00:15:44,766 --> 00:15:46,500
And then I think this is
where you were going,

340
00:15:46,566 --> 00:15:50,166
Juliette, is down at the
level of precincts and

341
00:15:50,233 --> 00:15:54,199
municipalities and cities
and counties and states,

342
00:15:54,266 --> 00:15:57,433
will the Russians
drill into those?

343
00:15:57,500 --> 00:15:58,566
I think they will.

344
00:15:58,633 --> 00:16:01,700
I don't think they're
sophisticated enough, the

345
00:16:01,766 --> 00:16:06,033
Russians, to figure out
the six most important

346
00:16:06,100 --> 00:16:11,533
counties in Ohio and twist
the ballots just enough to

347
00:16:11,600 --> 00:16:12,866
flip a state.

348
00:16:12,933 --> 00:16:14,299
I don't think
that's the game.

349
00:16:14,366 --> 00:16:17,033
I think what they will
want to do is destroy

350
00:16:17,100 --> 00:16:19,833
confidence in the process
and make our national

351
00:16:19,899 --> 00:16:22,799
election look like
Iowa, your point.

352
00:16:22,866 --> 00:16:24,633
We need to guard
against that.

353
00:16:24,700 --> 00:16:26,966
That means more
resources, more training

354
00:16:27,033 --> 00:16:27,966
for local officials.

355
00:16:28,033 --> 00:16:31,133
And hey, news flash,
the clock is ticking.

356
00:16:31,200 --> 00:16:33,633
We have got 250
days to get it done.

357
00:16:33,700 --> 00:16:34,799
>> JULIETTE KAYYEM: Yeah.
I mean, one of the things that

358
00:16:34,866 --> 00:16:37,199
you're seeing just on the
defense of Homeland

359
00:16:37,266 --> 00:16:40,199
Security side, so if you
thought, just picking up

360
00:16:40,266 --> 00:16:42,333
on the point, the confidence
level, although this could

361
00:16:42,399 --> 00:16:46,000
impact the act
of voting itself.

362
00:16:46,066 --> 00:16:48,299
So, if you're the Russians
and you're thinking, and

363
00:16:48,366 --> 00:16:49,799
this is all just
hypothetical, but you've

364
00:16:49,866 --> 00:16:52,665
been reading the newspaper
in terms of briefings

365
00:16:52,733 --> 00:16:55,599
about sort of the
Russians' interests and

366
00:16:55,666 --> 00:16:57,500
the Bernie Sanders
campaign and the

367
00:16:57,566 --> 00:16:58,733
Donald Trump campaign.

368
00:16:58,799 --> 00:17:02,665
So, if you're the Russians
and you want Michigan to

369
00:17:02,733 --> 00:17:08,366
go to a certain candidate,
how do you swing 20,000 votes?

370
00:17:08,433 --> 00:17:11,833
That's really hard
to do undetected by

371
00:17:11,900 --> 00:17:13,500
switching 20,000 votes.

372
00:17:13,566 --> 00:17:14,366
Right?

373
00:17:14,433 --> 00:17:15,500
In Detroit.

374
00:17:15,566 --> 00:17:18,266
But what you could do is,
and this gets back to our

375
00:17:18,333 --> 00:17:22,366
first point, is you
could somehow impact the

376
00:17:22,433 --> 00:17:24,366
apparatus that
supports voting.

377
00:17:24,433 --> 00:17:26,066
So, one of the things
you're starting to hear

378
00:17:26,133 --> 00:17:27,966
the intelligence community
talk about publicly in

379
00:17:28,032 --> 00:17:31,265
their most recent sort of
election brief, public

380
00:17:31,333 --> 00:17:35,833
briefing, it is you could,
you know, sort of impact

381
00:17:35,900 --> 00:17:39,233
the signals in Detroit
so that African American

382
00:17:39,299 --> 00:17:41,500
communities could not get
to the polls quickly and

383
00:17:41,566 --> 00:17:44,299
if people can't afford to
spend four hours voting,

384
00:17:44,366 --> 00:17:47,233
or you get into the
reverse 9/11 system and

385
00:17:47,299 --> 00:17:49,799
say there is an
active shooter or you

386
00:17:49,866 --> 00:17:51,966
impact the electricity.

387
00:17:52,033 --> 00:17:55,966
If you can hit ten
precincts in Detroit, you

388
00:17:56,033 --> 00:17:58,966
significantly change the
African American - you know,

389
00:17:59,033 --> 00:18:00,733
it is voter suppression
of a different kind.

390
00:18:00,799 --> 00:18:03,933
So, I think it is not just
the, you know, the sort of

391
00:18:04,000 --> 00:18:06,833
ballot box, right,
which it is hard to do

392
00:18:06,900 --> 00:18:09,166
undetected and there are
ways that we're beginning

393
00:18:09,233 --> 00:18:11,666
to be able to detect it
and we also have paper

394
00:18:11,733 --> 00:18:13,332
ballots now in
many places.

395
00:18:13,400 --> 00:18:17,233
It is that infrastructure
that supports the voting,

396
00:18:17,299 --> 00:18:19,766
and it gets to your point
which is confidence.

397
00:18:19,833 --> 00:18:23,266
STAVRIDIS: Exactly, and I think
just to put a line under what

398
00:18:23,333 --> 00:18:26,299
Juliette just said, at the
end of the day, I think

399
00:18:26,366 --> 00:18:29,400
the Russians are less
interested in exactly who

400
00:18:29,466 --> 00:18:31,433
the president is and who
the vice president is.

401
00:18:31,500 --> 00:18:34,066
What they want, what
they relish is this

402
00:18:34,133 --> 00:18:37,500
polarization in this
society, this distrust of

403
00:18:37,566 --> 00:18:40,233
government itself,
this acrimony.

404
00:18:40,299 --> 00:18:43,599
We're in such an angry
political season and the

405
00:18:43,666 --> 00:18:45,899
reason the Russians
want that is because

406
00:18:45,966 --> 00:18:47,433
it distracts us.

407
00:18:47,500 --> 00:18:50,233
It distracts us from
what Russia is doing

408
00:18:50,299 --> 00:18:51,666
geopolitically
in the world.

409
00:18:51,733 --> 00:18:55,633
It gives them a freer hand
to continue to occupy

410
00:18:55,700 --> 00:18:59,666
Ukraine, to support a
war criminal like Bashar

411
00:18:59,733 --> 00:19:05,433
al-Assad in Syria, to lean
into Eastern Europe and do

412
00:19:05,500 --> 00:19:08,766
these same kinds of things
to try to manipulate and

413
00:19:08,833 --> 00:19:10,299
drive down confidence.

414
00:19:10,366 --> 00:19:13,766
So, we are playing the
home game but believe me,

415
00:19:13,833 --> 00:19:17,066
it has impacted - our away
game is impacted when we

416
00:19:17,133 --> 00:19:20,500
have to put resources and
attention here in the country.

417
00:19:20,566 --> 00:19:22,366
>> JULIETTE KAYYEM: Just
picking up on that point,

418
00:19:22,433 --> 00:19:24,966
the sort of fissures
in our society.

419
00:19:25,033 --> 00:19:27,866
We see the Russians
very engaged with the

420
00:19:27,933 --> 00:19:31,133
anti-vaccination movement,
so those fissures about

421
00:19:31,200 --> 00:19:32,900
sort of public health, and
now you're starting to see

422
00:19:32,966 --> 00:19:35,866
disinformation campaigns
with support of the

423
00:19:35,933 --> 00:19:39,799
Russians as well, those
fissures around the coronavirus.

424
00:19:39,866 --> 00:19:40,733
Those fissures.

425
00:19:40,799 --> 00:19:43,666
Is it are the Chinese
hiding a bioterrorism attack?

426
00:19:43,733 --> 00:19:46,000
No one in the field
actually believes that.

427
00:19:46,066 --> 00:19:50,000
You know, these fissures
that make us distracted

428
00:19:50,066 --> 00:19:53,166
from what we need to
do which is protect US

429
00:19:53,233 --> 00:19:55,866
society from a
potential pandemic.

430
00:19:55,933 --> 00:19:59,866
>> JAMES STAVRIDIS: Absolutely.
The latest strain of that, not

431
00:19:59,933 --> 00:20:03,266
to make a bad pun on
medicine, but the latest

432
00:20:03,333 --> 00:20:05,966
strain of disinformation
that I have seen over the

433
00:20:06,033 --> 00:20:08,933
last couple of days is
very chilling and it is

434
00:20:09,000 --> 00:20:12,200
starting to pop in a
variety of social networks

435
00:20:12,266 --> 00:20:16,200
which is that coronavirus is
going to be so bad that

436
00:20:16,266 --> 00:20:19,200
we are going to
postpone our election.

437
00:20:19,266 --> 00:20:20,633
Think about that.

438
00:20:20,700 --> 00:20:22,666
It never happened in
American history.

439
00:20:22,733 --> 00:20:28,500
And yet I feel the Russian
voice in that, and talk

440
00:20:28,566 --> 00:20:31,700
about an instantly
polarizing issue because

441
00:20:31,766 --> 00:20:35,466
on the left people will
say, oh, conspiracy, this is

442
00:20:35,533 --> 00:20:39,299
a way to just kind of prolong
the current administration.

443
00:20:39,366 --> 00:20:42,266
On the right, they will
say that this is going to -

444
00:20:42,333 --> 00:20:45,033
this is being done to
undermine the legitimacy

445
00:20:45,099 --> 00:20:48,066
of the election, the
reelection in their view

446
00:20:48,133 --> 00:20:49,166
of President Trump.

447
00:20:49,233 --> 00:20:53,066
So, the Russians see this
again as a wedge issue and

448
00:20:53,133 --> 00:20:57,333
it is a really dark corner
of the coronavirus that

449
00:20:57,400 --> 00:20:59,366
unfortunately I think
you'll hear more of,

450
00:20:59,433 --> 00:21:00,833
another example of.

451
00:21:00,900 --> 00:21:02,233
>> JULIETTE KAYYEM: I
wanted to add, so the

452
00:21:02,299 --> 00:21:04,466
military, you spent your
career in the military,

453
00:21:04,533 --> 00:21:10,533
spends a lot of time
thinking about training

454
00:21:10,599 --> 00:21:13,666
and education and when I
- when we talk about this

455
00:21:13,733 --> 00:21:16,633
issue, you can get so
frustrated because we act

456
00:21:16,700 --> 00:21:18,900
like the American public
doesn't sort of have a

457
00:21:18,966 --> 00:21:21,666
responsibility to sort
of educate ourselves, so

458
00:21:21,733 --> 00:21:24,366
getting to the are
their solutions.

459
00:21:24,433 --> 00:21:28,933
When you think about what
the Russians are likely to

460
00:21:29,000 --> 00:21:32,466
do in 2020 and the
confidence, how can we

461
00:21:32,533 --> 00:21:36,199
begin to prepare ourselves for
essentially an enemy attack?

462
00:21:36,266 --> 00:21:37,700
Are we too divided?

463
00:21:37,766 --> 00:21:39,766
That's the sort of - I
don't want you to say yes

464
00:21:39,833 --> 00:21:41,166
to that last question.

465
00:21:41,233 --> 00:21:42,633
>> JAMES STAVRIDIS: And I
think the answer is no.

466
00:21:42,700 --> 00:21:43,666
We're not.

467
00:21:43,733 --> 00:21:47,133
In the history of our
country, of our culture

468
00:21:47,200 --> 00:21:51,299
tells us that we have
divisive moments, right?

469
00:21:51,366 --> 00:21:54,333
We have 1968 which believe
me, I'm old enough to

470
00:21:54,400 --> 00:21:57,266
remember and we
were more divided.

471
00:21:57,333 --> 00:21:59,633
There was more political
anger in the network in

472
00:21:59,700 --> 00:22:02,400
1968 even than
there is today.

473
00:22:02,466 --> 00:22:08,000
We had a Civil War, news
flash, in 1860 to 1864

474
00:22:08,066 --> 00:22:12,233
that killed millions
of Americans.

475
00:22:12,299 --> 00:22:15,099
So, we have had very
divided moments before

476
00:22:15,166 --> 00:22:18,033
and, Juliette, we tend to
rise above those moments

477
00:22:18,099 --> 00:22:18,966
and come back.

478
00:22:19,033 --> 00:22:22,733
I'm cautiously optimistic
that this will be the case.

479
00:22:22,799 --> 00:22:26,700
So, the question is, what
can we do that helps that?

480
00:22:26,766 --> 00:22:29,166
You touched on one
and it is education.

481
00:22:29,233 --> 00:22:32,500
This is not just cyber
but let's keep it in

482
00:22:32,566 --> 00:22:33,833
the cyber context.

483
00:22:33,900 --> 00:22:37,799
It is recognizing that
right now we are teaching

484
00:22:37,866 --> 00:22:41,166
our children a great deal
these days in the schools

485
00:22:41,233 --> 00:22:43,299
about many important
life skills.

486
00:22:43,366 --> 00:22:45,766
Are we really teaching
them about the

487
00:22:45,833 --> 00:22:48,166
supercomputer that
they're carrying around?

488
00:22:48,233 --> 00:22:51,433
Are we teaching them -
important point here - how

489
00:22:51,500 --> 00:22:54,900
to differentiate between
fake news and real news?

490
00:22:54,966 --> 00:22:57,733
There are a dozen good
techniques that can be

491
00:22:57,799 --> 00:22:59,166
taught to do that.

492
00:22:59,233 --> 00:23:01,666
Education is a
fundamental part.

493
00:23:01,733 --> 00:23:06,733
Number two is we ought
to, in my view, consider

494
00:23:06,799 --> 00:23:10,500
strongly the idea of a
national service that

495
00:23:10,566 --> 00:23:13,033
could include cyber
service, and finding

496
00:23:13,099 --> 00:23:14,832
the Cyber talent.

497
00:23:14,900 --> 00:23:18,099
You are going to see a
very important report come

498
00:23:18,166 --> 00:23:19,733
out in the next
couple of weeks.

499
00:23:19,799 --> 00:23:23,166
It is called the Solarium
Report, commissioned by

500
00:23:23,233 --> 00:23:26,265
Congress, and it is about
how to reorganize the

501
00:23:26,333 --> 00:23:30,266
government in sensible ways
to focus us more on cyber.

502
00:23:30,333 --> 00:23:32,133
I think the
recommendations there are

503
00:23:32,200 --> 00:23:34,400
quite good and we
ought to consider them.

504
00:23:34,466 --> 00:23:37,466
Third and finally, in
terms of protecting

505
00:23:37,533 --> 00:23:40,733
ourselves as we go
forward, again, back to a

506
00:23:40,799 --> 00:23:43,766
conversation we had a
moment ago, Department of

507
00:23:43,833 --> 00:23:47,066
Defense and its role, I
think that currently we

508
00:23:47,133 --> 00:23:50,466
have kind of a pickup team
in the Department of Defense.

509
00:23:50,533 --> 00:23:53,866
Each of the services
contributes to US Cyber Command.

510
00:23:53,933 --> 00:23:55,733
I think it is time to
start thinking about a

511
00:23:55,799 --> 00:23:57,900
cyber force just like
we have an Air Force.

512
00:23:57,966 --> 00:23:59,166
There are three ideas.

513
00:23:59,233 --> 00:24:01,166
>> JULIETTE KAYYEM: Can
I draw down on this?

514
00:24:01,233 --> 00:24:03,366
What do you mean by
cyber force as compared

515
00:24:03,433 --> 00:24:04,599
to cyber command?

516
00:24:04,666 --> 00:24:06,066
People - if you don't
understand the difference

517
00:24:06,133 --> 00:24:07,166
in the terminology?

518
00:24:07,233 --> 00:24:08,200
>> JAMES STAVRIDIS: Yeah.

519
00:24:08,266 --> 00:24:11,700
So, what currently exists
is not bad and it is a

520
00:24:11,766 --> 00:24:13,833
four-star officer who
is the commander of

521
00:24:13,900 --> 00:24:16,500
US Cyber Command.

522
00:24:16,566 --> 00:24:19,033
His name is General
Paul Nakasone.

523
00:24:19,099 --> 00:24:21,033
Before him it was
Admiral Mike Rogers.

524
00:24:21,099 --> 00:24:23,500
Before him it was
General Keith Alexander.

525
00:24:23,566 --> 00:24:25,133
Four-star
military officer.

526
00:24:25,200 --> 00:24:28,066
That officer goes to each
of the services, Army,

527
00:24:28,133 --> 00:24:31,200
Navy, Air Force, Marine
Corps, and says send me

528
00:24:31,266 --> 00:24:34,066
some folks who could
come work for me.

529
00:24:34,133 --> 00:24:36,533
I'm going to kind of
integrate them and train

530
00:24:36,599 --> 00:24:40,966
them and they will be the
nation's military cyber force.

531
00:24:41,033 --> 00:24:41,966
That's what we have now.

532
00:24:42,033 --> 00:24:43,500
It is kind of
a pickup team.

533
00:24:43,566 --> 00:24:47,533
It is not terrible but
it should be obvious to

534
00:24:47,599 --> 00:24:50,799
everybody that it would be
much better if what we had

535
00:24:50,866 --> 00:24:54,400
instead was a small force,
and I would say, Juliette,

536
00:24:54,466 --> 00:24:57,033
this could be as small
as 15,000 people.

537
00:24:57,099 --> 00:25:00,033
Department of Defense has
two million people in it.

538
00:25:00,099 --> 00:25:05,633
So, 15,000 highly trained,
very smart people who are

539
00:25:05,700 --> 00:25:07,500
focused from the
moment they take their

540
00:25:07,566 --> 00:25:09,700
commission, the moment
they raise their hand and

541
00:25:09,766 --> 00:25:11,900
swear allegiance to the
constitution of the United

542
00:25:11,966 --> 00:25:15,099
States, they're focused on
cyber and cybersecurity.

543
00:25:15,166 --> 00:25:18,265
They're not a marine
rifleman who comes in for

544
00:25:18,333 --> 00:25:20,733
three glorious years into
cyber and then goes back

545
00:25:20,799 --> 00:25:21,933
to being a
marine rifleman.

546
00:25:22,000 --> 00:25:23,033
That's not a good model.

547
00:25:23,099 --> 00:25:26,700
A better model is we bring
the best and the brightest

548
00:25:26,766 --> 00:25:30,433
into this and we have an
example of having done this.

549
00:25:30,500 --> 00:25:33,833
It is called the
US Air Force.

550
00:25:33,900 --> 00:25:37,200
You may recall that for
the first almost two

551
00:25:37,266 --> 00:25:39,233
hundred years of our
history, we had an Army, a

552
00:25:39,299 --> 00:25:41,000
Navy, and a Marine Corps.

553
00:25:41,066 --> 00:25:43,500
We didn't have an Air
Force, largely because we

554
00:25:43,566 --> 00:25:46,400
didn't fly airplanes until
the end of the period.

555
00:25:46,466 --> 00:25:48,366
But from the time we
started to fly airplanes

556
00:25:48,433 --> 00:25:52,633
just like now, we're in a
world where cyber really

557
00:25:52,700 --> 00:25:54,400
matters, we
figured it out.

558
00:25:54,466 --> 00:25:55,799
We created an Air Force.

559
00:25:55,866 --> 00:25:59,599
I think it is time to put
the basics out there to start.

560
00:25:59,666 --> 00:26:00,966
>> JULIETTE KAYYEM: So, I
mean, talking about the

561
00:26:01,033 --> 00:26:04,866
military, one of the
concerns, and we talked

562
00:26:04,933 --> 00:26:06,299
about this at the
beginning, the sort of

563
00:26:06,366 --> 00:26:10,933
vulnerability of the network
around the dot MIL domain.

564
00:26:11,000 --> 00:26:13,066
So, from the - I would say
in the beginning, from the

565
00:26:13,133 --> 00:26:15,633
Homeland Security
perspective, one, we have

566
00:26:15,700 --> 00:26:17,633
no jurisdiction over the
dot MIL domain but you

567
00:26:17,700 --> 00:26:19,966
kind of think the Pentagon
has got their act together.

568
00:26:20,033 --> 00:26:22,366
There is almost no
resource that DHS could

569
00:26:22,433 --> 00:26:25,366
help DOD with and they
have got a lot of

570
00:26:25,433 --> 00:26:26,666
incentive to protect.

571
00:26:26,733 --> 00:26:28,933
I think one of the things
that we're seeing when you

572
00:26:29,000 --> 00:26:31,466
see there is no real
distinction between public

573
00:26:31,533 --> 00:26:35,166
and private anymore,
what a lot of you do is

574
00:26:35,233 --> 00:26:36,866
quasi-public
sector, right?

575
00:26:36,933 --> 00:26:39,633
You are supporting a
public mission or a public

576
00:26:39,700 --> 00:26:43,033
good by supporting DOD
or Department of Energy

577
00:26:43,099 --> 00:26:44,599
or whoever else.

578
00:26:44,666 --> 00:26:49,966
That network though, seems
to me to be a rather large

579
00:26:50,033 --> 00:26:53,000
vulnerability and there's
been a lot of changes in

580
00:26:53,066 --> 00:26:55,000
the way that the Pentagon
is thinking about it and

581
00:26:55,066 --> 00:26:57,233
the same way, you know,
that we have to get Sony

582
00:26:57,299 --> 00:26:58,400
to think about it.

583
00:26:58,466 --> 00:26:59,799
You have been
involved with that.

584
00:26:59,866 --> 00:27:01,233
I just thought it would
be helpful to have people

585
00:27:01,299 --> 00:27:03,466
sort of understand what is
that looking like now and

586
00:27:03,533 --> 00:27:04,832
what changes
can they expect?

587
00:27:04,900 --> 00:27:08,133
>> JAMES STAVRIDIS: Yeah.
Let's start with acquisitions,

588
00:27:08,200 --> 00:27:12,500
which is buying stuff
and buying services.

589
00:27:12,566 --> 00:27:14,433
So, buying things
and buying services.

590
00:27:14,500 --> 00:27:18,000
That's a lot of what the
Department of Defense does.

591
00:27:18,066 --> 00:27:19,866
The budget of the
Department of Defense is

592
00:27:19,933 --> 00:27:22,166
like $780 billion.

593
00:27:22,233 --> 00:27:25,466
A big chunk of that goes
to personnel but an awful

594
00:27:25,533 --> 00:27:28,332
lot of it acquires both
services and goods.

595
00:27:28,400 --> 00:27:31,500
How many companies do you
think are involved in

596
00:27:31,566 --> 00:27:34,266
that, what's called
technically the defense

597
00:27:34,333 --> 00:27:36,133
industrial base?

598
00:27:36,200 --> 00:27:38,966
The answer is 300,000.

599
00:27:39,033 --> 00:27:42,233
There are 300,000 separate
entities who provide goods

600
00:27:42,299 --> 00:27:44,533
and services to the
Department of Defense.

601
00:27:44,599 --> 00:27:48,466
They range from massive
prime contractors like

602
00:27:48,533 --> 00:27:52,832
Lockheed Martin, Northrop
Grumman, to tiny little

603
00:27:52,900 --> 00:27:57,700
wonderful innovative, hip,
cool companies who come to

604
00:27:57,766 --> 00:28:03,000
RSA for the popcorn and
they are here doing great

605
00:28:03,066 --> 00:28:06,366
things for the country with
nine people working for them.

606
00:28:06,433 --> 00:28:08,700
Now, up here, the primes,
they have a lot of

607
00:28:08,766 --> 00:28:11,866
resources to put at this
idea of cybersecurity.

608
00:28:11,933 --> 00:28:16,766
Those little small cool
hip companies, not so much.

609
00:28:16,833 --> 00:28:19,466
Some of them, of course,
they're in cybersecurity.

610
00:28:19,533 --> 00:28:20,866
Those are pretty
well defended.

611
00:28:20,933 --> 00:28:23,700
But the ones who are
making special alloys for

612
00:28:23,766 --> 00:28:27,633
the knife edges on a J35
joint strike fighter,

613
00:28:27,700 --> 00:28:30,233
they're not so
strong in this area.

614
00:28:30,299 --> 00:28:33,666
Many of you, I hope, had a
chance to hear from Katie

615
00:28:33,733 --> 00:28:36,566
Arrington yesterday who is
leading a charge at the

616
00:28:36,633 --> 00:28:40,633
Department of Defense to
create a set of standards

617
00:28:40,700 --> 00:28:43,733
so that before you get
that contract, before you

618
00:28:43,799 --> 00:28:46,799
join the defense
industrial base, you have

619
00:28:46,866 --> 00:28:49,700
to - let me shift
metaphors for a minute,

620
00:28:49,766 --> 00:28:51,133
you have to karate.

621
00:28:51,200 --> 00:28:52,400
It is like a
series of belts.

622
00:28:52,466 --> 00:28:53,832
There are five belts.

623
00:28:53,900 --> 00:28:57,433
The white belt, like when
your kid is in the dojo

624
00:28:57,500 --> 00:29:00,599
for the first time, the
white belt, it is the

625
00:29:00,666 --> 00:29:01,700
very basic stuff.

626
00:29:01,766 --> 00:29:04,500
You know what a phishing
attack is, you have some

627
00:29:04,566 --> 00:29:09,033
level of point defense, you
have kind of a resilience plan.

628
00:29:09,099 --> 00:29:13,866
It graduates to a green
belt, yellow belt, brown

629
00:29:13,933 --> 00:29:15,866
belt, like a black belt.

630
00:29:15,933 --> 00:29:17,866
That's pretty
serious stuff.

631
00:29:17,933 --> 00:29:21,366
To do classified material,
you've got to have

632
00:29:21,433 --> 00:29:23,266
that level 3.

633
00:29:23,333 --> 00:29:27,200
So, for the first time,
the department is trying

634
00:29:27,266 --> 00:29:31,233
to create some standards,
and at each level it

635
00:29:31,299 --> 00:29:34,966
describes exactly what you
have to do to achieve that

636
00:29:35,033 --> 00:29:37,099
level, just
like in karate.

637
00:29:37,166 --> 00:29:40,599
And so, I think that's a big
step in the right direction.

638
00:29:40,666 --> 00:29:44,000
Katie Arrington is just
a force of nature and is

639
00:29:44,066 --> 00:29:46,799
driving this thing forward
and I'll close by saying,

640
00:29:46,866 --> 00:29:49,200
Juliette, that I think
this is a pretty good

641
00:29:49,266 --> 00:29:51,866
example of where the
government can do

642
00:29:51,933 --> 00:29:55,700
something reasonable, set
up those standards, and

643
00:29:55,766 --> 00:29:58,866
then I would say the
government has another

644
00:29:58,933 --> 00:30:01,833
level of responsibility on
the security side, which

645
00:30:01,900 --> 00:30:04,533
is to provide some
resources, particularly to

646
00:30:04,599 --> 00:30:06,633
help these small
innovative companies,

647
00:30:06,700 --> 00:30:08,900
because otherwise they're
going to kind of die on

648
00:30:08,966 --> 00:30:11,099
the vine of cybersecurity.

649
00:30:11,166 --> 00:30:13,866
So, this is big casino,
what's happening.

650
00:30:13,933 --> 00:30:16,900
I think the quicker
we get to a set

651
00:30:16,966 --> 00:30:18,366
of standards, the better.

652
00:30:18,433 --> 00:30:21,000
>> JULIETTE KAYYEM: Those
standards will be - this

653
00:30:21,066 --> 00:30:22,500
is the CMMC program.

654
00:30:22,566 --> 00:30:23,533
>> JAMES STAVRIDIS: It is.

655
00:30:23,599 --> 00:30:25,633
>> JULIETTE KAYYEM: The
cybersecurity model, do we -

656
00:30:25,700 --> 00:30:26,866
now I'm forgetting.

657
00:30:26,933 --> 00:30:28,733
>> JAMES STAVRIDIS:
Cybersecurity Maturity

658
00:30:28,799 --> 00:30:30,933
Model Certification.

659
00:30:31,000 --> 00:30:33,200
Again, the belt system
is the certification.

660
00:30:33,266 --> 00:30:36,866
>> JULIETTE KAYYEM: To the
extent that CMMC, it is

661
00:30:36,933 --> 00:30:39,000
likely to impact a lot
of people in this room.

662
00:30:39,066 --> 00:30:40,000
>> JAMES STAVRIDIS: Sure.

663
00:30:40,066 --> 00:30:43,666
>> JULIETTE KAYYEM: In
terms of sort of creating

664
00:30:43,733 --> 00:30:47,366
at least a baseline of
what they're supposed to do.

665
00:30:47,433 --> 00:30:50,933
What's the bare minimum of
what they're supposed to

666
00:30:51,000 --> 00:30:52,933
do because if you think
about the supply chain

667
00:30:53,000 --> 00:30:55,233
servicing the Department
of Defense, and we'll get

668
00:30:55,299 --> 00:30:58,866
into this later, this is,
you know, if DOD does this

669
00:30:58,933 --> 00:31:02,866
and does it well, it
will have other - other

670
00:31:02,933 --> 00:31:05,033
agencies are going to
look at it and go, well,

671
00:31:05,099 --> 00:31:06,599
we are important too.

672
00:31:06,666 --> 00:31:07,765
>> JAMES STAVRIDIS:
Big time.

673
00:31:07,833 --> 00:31:13,433
So, the first thing to
know about it is that you

674
00:31:13,500 --> 00:31:16,799
will not, if you're one of
these small companies or a

675
00:31:16,866 --> 00:31:19,433
large company, you can't
simply raise your hand and

676
00:31:19,500 --> 00:31:21,633
say, okay, we're all done.

677
00:31:21,700 --> 00:31:23,233
I'm level 5.

678
00:31:23,299 --> 00:31:26,266
And you also can't raise
your hand and say we're

679
00:31:26,333 --> 00:31:29,400
all done, I'm level 5 and
here is my documentation.

680
00:31:29,466 --> 00:31:30,866
That's an improvement.

681
00:31:30,933 --> 00:31:34,433
What you're going to have
to have is a certification

682
00:31:34,500 --> 00:31:37,433
from an outside authority.

683
00:31:37,500 --> 00:31:40,566
And so, the department is
also in the business of

684
00:31:40,633 --> 00:31:45,366
creating mechanisms for
these outside authorities

685
00:31:45,433 --> 00:31:47,133
who will be the certifiers.

686
00:31:47,200 --> 00:31:50,733
So, step one, if you're a
small business or a large

687
00:31:50,799 --> 00:31:54,033
business, step one is
understand exactly what

688
00:31:54,099 --> 00:31:57,332
the requirements are at
every level and figure out

689
00:31:57,400 --> 00:32:02,133
where you need to be based
on your level of ambition

690
00:32:02,200 --> 00:32:04,433
in dealing with the
Department of Defense.

691
00:32:04,500 --> 00:32:07,200
It's a no-brainer that
Northrop Grumman, Lockheed

692
00:32:07,266 --> 00:32:10,433
Martin, General Dynamics,
BAE, et cetera, they have

693
00:32:10,500 --> 00:32:11,633
got to be black belts.

694
00:32:11,700 --> 00:32:13,266
They have got to be
up there at level 5.

695
00:32:13,333 --> 00:32:15,099
But for a lot of
companies, you may be

696
00:32:15,166 --> 00:32:18,832
quite comfortable being a
level 3 and I don't think

697
00:32:18,900 --> 00:32:20,966
we have time to unpack
each of - all of the

698
00:32:21,033 --> 00:32:22,033
specifics here.

699
00:32:22,099 --> 00:32:23,733
But there are five levels.

700
00:32:23,799 --> 00:32:28,833
There are thirteen domains
where you find various

701
00:32:28,900 --> 00:32:31,966
ideas and there are
about 173 requirements.

702
00:32:32,033 --> 00:32:35,500
It a government program so
there are going to be that

703
00:32:35,566 --> 00:32:36,666
level of detail to it.

704
00:32:36,733 --> 00:32:40,399
But having looked at it as
an outsider at the moment,

705
00:32:40,466 --> 00:32:44,099
I think it is a pretty
sensible lay down and I

706
00:32:44,166 --> 00:32:46,633
think it is one that most
here in the room would

707
00:32:46,700 --> 00:32:48,733
agree with if they had
a chance to look at it.

708
00:32:48,799 --> 00:32:50,633
>> JULIETTE KAYYEM: Have
you been you surprised - I

709
00:32:50,700 --> 00:32:53,166
mean, I'm always
surprised at the sort of

710
00:32:53,233 --> 00:32:58,033
vulnerabilities that exist
sort of right next to

711
00:32:58,099 --> 00:33:00,033
something that's
incredibly fortified.

712
00:33:00,099 --> 00:33:04,500
So, we think about layer
defenses in say, airports.

713
00:33:04,566 --> 00:33:06,200
This is what I
think about, right?

714
00:33:06,266 --> 00:33:10,500
So, you - the moment
you're at the TSA line,

715
00:33:10,566 --> 00:33:14,500
you - so much has already
happened so that physical

716
00:33:14,566 --> 00:33:16,299
check, we already
know who you are.

717
00:33:16,366 --> 00:33:19,366
You have already - there
is now burdened and

718
00:33:19,433 --> 00:33:20,799
unburdened classes.

719
00:33:20,866 --> 00:33:22,366
Those of you who have
TSA precheck, you're

720
00:33:22,433 --> 00:33:24,733
unburdened so you can
go through quicker.

721
00:33:24,799 --> 00:33:26,733
So, there are so many
layers of it, but there is

722
00:33:26,799 --> 00:33:30,166
a moment when you go
from hard to soft.

723
00:33:30,233 --> 00:33:35,399
For airports, that tends to
be the public entranceway.

724
00:33:35,466 --> 00:33:36,433
>> JAMES STAVRIDIS:
When you walk in.

725
00:33:36,500 --> 00:33:37,666
>> JULIETTE KAYYEM: There
is just no way you can

726
00:33:37,733 --> 00:33:40,066
fortify it, the baggage
claim areas and things

727
00:33:40,133 --> 00:33:41,166
like that.

728
00:33:41,233 --> 00:33:45,066
Have you been surprised
at how this entire

729
00:33:45,133 --> 00:33:47,133
infrastructure has built
and you just - you have

730
00:33:47,200 --> 00:33:49,766
the hardened right next
to the oh, we're going to

731
00:33:49,833 --> 00:33:53,033
send you our - you know,
we're going to enter the

732
00:33:53,099 --> 00:33:55,399
supply chain through
unencrypted Gmail?

733
00:33:55,466 --> 00:33:56,265
>> JAMES STAVRIDIS: Yeah.

734
00:33:56,333 --> 00:33:57,733
I have been.

735
00:33:57,799 --> 00:34:00,633
I think the analogy
pertains in cyber.

736
00:34:00,700 --> 00:34:01,866
I will make a point.

737
00:34:01,933 --> 00:34:05,299
I was looking at a company
the other day, by the way,

738
00:34:05,366 --> 00:34:09,400
which is coming up with a
technology that actually

739
00:34:09,466 --> 00:34:12,565
can scan large crowds.

740
00:34:12,632 --> 00:34:16,866
The challenge you illicit
occurs not only at airports.

741
00:34:16,933 --> 00:34:20,300
Think about football
stadiums, large gathering

742
00:34:20,366 --> 00:34:22,000
places, our schools.

743
00:34:22,065 --> 00:34:25,132
There are technologies
that are coming out that

744
00:34:25,199 --> 00:34:28,633
are kind of hyper spectral
analysis techniques that

745
00:34:28,699 --> 00:34:33,066
will be able to scan
large crowds of people as

746
00:34:33,132 --> 00:34:34,098
they move along.

747
00:34:34,166 --> 00:34:38,866
To the cyber world, you
can't do that without the

748
00:34:38,933 --> 00:34:42,466
artificial intelligence
that can drive it, that

749
00:34:42,533 --> 00:34:45,598
can instantly do that
hyper spectral analysis,

750
00:34:45,666 --> 00:34:48,199
and say yes, that
individual has something

751
00:34:48,266 --> 00:34:50,633
metallic or has
something that looks

752
00:34:50,699 --> 00:34:54,266
like a can of gasoline.
All of these are possible.

753
00:34:54,333 --> 00:34:58,233
So, part of the answer to
the question is technology

754
00:34:58,300 --> 00:35:01,433
that will help us
move the barrier out.

755
00:35:01,500 --> 00:35:06,199
But I think your point is
it is unsettling that we

756
00:35:06,266 --> 00:35:09,733
have these gaps and we
ought to address them.

757
00:35:09,800 --> 00:35:12,366
I think in the world of
cyber, what this comes

758
00:35:12,433 --> 00:35:18,666
down to is having both
point security solutions,

759
00:35:18,733 --> 00:35:21,599
think the hazmat suit that
you walk around in to make

760
00:35:21,666 --> 00:35:24,733
sure you don't get
coronavirus, but you also

761
00:35:24,800 --> 00:35:27,800
have to have the vaccine,
if you will, in this metaphor.

762
00:35:27,866 --> 00:35:30,833
You have to have - inside,
you have to be able to

763
00:35:30,900 --> 00:35:35,366
protect that data, that
life system in each of you

764
00:35:35,433 --> 00:35:38,533
as an individual and this
gets back to this idea for

765
00:35:38,599 --> 00:35:40,633
example of end to
end encryption.

766
00:35:40,699 --> 00:35:46,199
Currently, your data is
unencrypted on the servers.

767
00:35:46,266 --> 00:35:48,233
That is the life
system inside of you.

768
00:35:48,300 --> 00:35:51,300
If we could move to a
system that has encryption

769
00:35:51,366 --> 00:35:53,633
end to end, that would be
an example of what you

770
00:35:53,699 --> 00:35:56,833
could do and I think we
have got to go in that

771
00:35:56,900 --> 00:36:00,900
direction, and all of it
is really technology and

772
00:36:00,966 --> 00:36:04,466
the government can help by
facilitating that, by R&D,

773
00:36:04,533 --> 00:36:07,165
doing grants,
energizing, for example, the

774
00:36:07,233 --> 00:36:09,366
Department of Defense
which ought to have a high

775
00:36:09,433 --> 00:36:11,599
level of interest in the
technology I mentioned a

776
00:36:11,666 --> 00:36:14,900
moment ago of
scanning large crowds.

777
00:36:14,966 --> 00:36:17,333
Would that be useful,
say, in Afghanistan?

778
00:36:17,400 --> 00:36:19,066
Yeah, you bet.

779
00:36:19,133 --> 00:36:22,332
So, technology and
government policy,

780
00:36:22,400 --> 00:36:23,866
I think, are the
answers here.

781
00:36:23,933 --> 00:36:25,466
>> JULIETTE KAYYEM:
You've avoided - it's so

782
00:36:25,533 --> 00:36:27,500
interesting - not avoided,
maybe not purposefully,

783
00:36:27,566 --> 00:36:30,633
but this idea of
sort of sanctioning.

784
00:36:30,699 --> 00:36:33,300
I mean, so we have been
talking about carrots and

785
00:36:33,366 --> 00:36:34,900
not sticks for government.

786
00:36:34,966 --> 00:36:38,732
But the kind of
responsibility that say

787
00:36:38,800 --> 00:36:42,366
these companies have in
terms of both supplying

788
00:36:42,433 --> 00:36:44,833
the defense department
or any other agency with

789
00:36:44,900 --> 00:36:50,066
information, but also
being a vulnerable single

790
00:36:50,133 --> 00:36:53,000
point of failure for
the defense department.

791
00:36:53,066 --> 00:36:54,866
I mean, do you see, when
you think about the

792
00:36:54,933 --> 00:36:58,533
regulatory sense, do you
see, you know, government

793
00:36:58,599 --> 00:37:03,333
coming in much stronger
in terms of beyond mere

794
00:37:03,400 --> 00:37:04,766
certification?

795
00:37:04,833 --> 00:37:06,533
>> JAMES STAVRIDIS: Well,
first of all, we have got

796
00:37:06,599 --> 00:37:10,866
to recognize that there is
a philosophical gap here

797
00:37:10,933 --> 00:37:12,366
between the two parties.

798
00:37:12,433 --> 00:37:15,699
And so, part of the answer
to the question lies in

799
00:37:15,766 --> 00:37:16,900
the election in November.

800
00:37:16,966 --> 00:37:20,900
I think historically the
Democrats obviously have

801
00:37:20,966 --> 00:37:23,799
been much more oriented to
regulation across every

802
00:37:23,866 --> 00:37:28,233
sphere, and so if there's
a Democrat president, look

803
00:37:28,300 --> 00:37:30,400
for more regulation
on this side.

804
00:37:30,466 --> 00:37:33,266
If it is a Republican,
if the president wins

805
00:37:33,333 --> 00:37:36,800
reelection, the chances are
there will be less incline.

806
00:37:36,866 --> 00:37:38,099
Here is my argument.

807
00:37:38,166 --> 00:37:41,900
In this world, in cyber,
we have got to get more

808
00:37:41,966 --> 00:37:45,232
regulated, and we tend
to think, again, back to

809
00:37:45,300 --> 00:37:47,866
these wonderful
supercomputers, we tend to

810
00:37:47,933 --> 00:37:50,333
think, oh, we
are so advanced.

811
00:37:50,400 --> 00:37:51,733
This is incredible.

812
00:37:51,800 --> 00:37:53,900
This thing, it is
incredible, right.

813
00:37:53,966 --> 00:37:56,799
It can communicate point to
point anywhere in the world.

814
00:37:56,866 --> 00:37:59,233
It can access all of
the world's knowledge.

815
00:37:59,300 --> 00:38:01,533
It can play any
symphony ever recorded.

816
00:38:01,599 --> 00:38:04,000
It is measuring my
heartbeat right now.

817
00:38:04,066 --> 00:38:06,066
I can look at a really
funny video of a basset

818
00:38:06,133 --> 00:38:07,698
hound right now.

819
00:38:07,766 --> 00:38:13,333
But it is in a system, it
is in an ecosystem that is

820
00:38:13,400 --> 00:38:14,666
very primitive still.

821
00:38:14,733 --> 00:38:19,633
To switch metaphors, we're
still on the beach at

822
00:38:19,699 --> 00:38:22,366
Kitty Hawk in a
lot of ways here.

823
00:38:22,433 --> 00:38:25,866
In a Maritime metaphor,
we're sailing a cyber sea

824
00:38:25,933 --> 00:38:28,366
and there aren't a lot of
buoys out there and there

825
00:38:28,433 --> 00:38:29,933
aren't a lot of
lighthouses.

826
00:38:30,000 --> 00:38:31,833
And that means
regulations.

827
00:38:31,900 --> 00:38:35,933
So, to stay on the seas as
analogy, for centuries the

828
00:38:36,000 --> 00:38:39,666
seas were largely
unregulated until we

829
00:38:39,733 --> 00:38:43,566
created a massive global
law of the sea treaty.

830
00:38:43,633 --> 00:38:46,466
At some point we're going
to have to drive more

831
00:38:46,533 --> 00:38:48,566
regulation into
this ecosystem.

832
00:38:48,633 --> 00:38:50,165
>> JULIETTE KAYYEM: So,
it seems like CMMC, the

833
00:38:50,233 --> 00:38:51,833
program that we were
talking about before,

834
00:38:51,900 --> 00:38:53,366
might be the beginning.

835
00:38:53,433 --> 00:38:55,166
It is a certification.

836
00:38:55,233 --> 00:38:56,800
You know, you could be
this level, you could be

837
00:38:56,866 --> 00:38:58,500
that level, you have
to be some level.

838
00:38:58,566 --> 00:38:59,933
We're not just going to
take your word for it.

839
00:39:00,000 --> 00:39:02,733
It could be the beginning
of people - of the

840
00:39:02,800 --> 00:39:06,699
government demanding of
the supply chain and at

841
00:39:06,766 --> 00:39:10,199
the very least, encryption
and end to end encryption

842
00:39:10,266 --> 00:39:13,366
on all things, right, not
just communication like

843
00:39:13,433 --> 00:39:16,099
most of us use WhatsApp
but on documents and other

844
00:39:16,166 --> 00:39:17,133
things like that.

845
00:39:17,199 --> 00:39:18,566
>> JAMES STAVRIDIS:
Absolutely correct.

846
00:39:18,633 --> 00:39:21,066
And what I am also seeing,
because in the end,

847
00:39:21,133 --> 00:39:24,466
cybersecurity is the
ultimate team sport, it is

848
00:39:24,533 --> 00:39:26,000
the ultimate
private/public

849
00:39:26,066 --> 00:39:28,566
partnership, what's
encouraging to me,

850
00:39:28,633 --> 00:39:32,299
Juliette, is the number of
industries that are moving

851
00:39:32,366 --> 00:39:34,466
towards self-regulation
in this regard.

852
00:39:34,533 --> 00:39:35,533
I'll give you an example.

853
00:39:35,599 --> 00:39:40,000
The eight biggest banks in
the country got together,

854
00:39:40,066 --> 00:39:43,566
pooled quite a bit of
capital, and created an

855
00:39:43,633 --> 00:39:47,366
organization, small but
very capable organization

856
00:39:47,433 --> 00:39:51,633
called the FSARC,
Financial Service Analysis

857
00:39:51,699 --> 00:39:53,900
and Resilience Center.

858
00:39:53,966 --> 00:39:56,766
Hired an absolute
topflight cybersecurity

859
00:39:56,833 --> 00:39:59,099
leader and then went
around and hired people

860
00:39:59,166 --> 00:40:03,900
from DHS, from CIA, from
DOJ, from other forms of

861
00:40:03,966 --> 00:40:07,366
law enforcement and they
hired high end technologists.

862
00:40:07,433 --> 00:40:09,566
Still a small
organization, but its

863
00:40:09,633 --> 00:40:14,000
mission is to look at all
of these attack surfaces

864
00:40:14,066 --> 00:40:17,000
coming after the banks,
make recommendations, and

865
00:40:17,066 --> 00:40:20,098
then go to the big banks
and through them, to the

866
00:40:20,166 --> 00:40:22,666
entire banking industry
and say here's what we're

867
00:40:22,733 --> 00:40:25,233
seeing, here are the
dangers, here is how you

868
00:40:25,300 --> 00:40:28,900
harden yourself against
it, and as an industry,

869
00:40:28,966 --> 00:40:32,466
they're starting to talk
about something like CMMC

870
00:40:32,533 --> 00:40:34,433
for the financial sector.

871
00:40:34,500 --> 00:40:38,099
I'm seeing the edges of
the same thing in the

872
00:40:38,166 --> 00:40:41,099
electric grid, in the
electric industry.

873
00:40:41,166 --> 00:40:42,733
You're probably
seeing that.

874
00:40:42,800 --> 00:40:47,000
I'm seeing conversations
beginning in the water industry.

875
00:40:47,066 --> 00:40:49,665
And you know, we tend to
think a little bit less

876
00:40:49,733 --> 00:40:51,666
about water as critical
infrastructure.

877
00:40:51,733 --> 00:40:54,966
News flash, you can
live a long time without

878
00:40:55,033 --> 00:40:58,199
electricity, you know,
like thirty, sixty, your

879
00:40:58,266 --> 00:40:59,866
whole life if you have to.

880
00:40:59,933 --> 00:41:03,099
How long can you live
without clean potable water?

881
00:41:03,166 --> 00:41:04,766
Three days.

882
00:41:04,833 --> 00:41:08,866
So, there are significant
challenges from cyber in

883
00:41:08,933 --> 00:41:11,166
that world as
well, for example.

884
00:41:11,233 --> 00:41:13,500
In addition to your
excellent point of the

885
00:41:13,566 --> 00:41:16,966
government beginning to do
more and more here, we're

886
00:41:17,033 --> 00:41:19,665
now starting to see the
industries themselves

887
00:41:19,733 --> 00:41:21,533
become more self-policing.

888
00:41:21,599 --> 00:41:22,633
>> JULIETTE KAYYEM: Which
is incredible when you

889
00:41:22,699 --> 00:41:24,666
think about the inherent
competition amongst

890
00:41:24,733 --> 00:41:25,500
all of them.

891
00:41:25,566 --> 00:41:29,265
But it is true that
beginning with our first

892
00:41:29,333 --> 00:41:32,366
points about peoples'
confidence in institutions

893
00:41:32,433 --> 00:41:35,833
right now and if the
institution seems

894
00:41:35,900 --> 00:41:37,566
vulnerable, whether
it is physically

895
00:41:37,633 --> 00:41:39,265
vulnerable, so your
sense of confidence after

896
00:41:39,333 --> 00:41:41,966
9/11 was low because
we seem physically

897
00:41:42,033 --> 00:41:46,232
vulnerable, or vulnerable
because someone or some

898
00:41:46,300 --> 00:41:48,333
country was able to get
into a system that they

899
00:41:48,400 --> 00:41:51,166
ought not to have gotten
into, that will apply to

900
00:41:51,233 --> 00:41:52,900
the military as
much as banking.

901
00:41:52,966 --> 00:41:56,598
I have to ask you, as we
are seeing - I teach at

902
00:41:56,666 --> 00:41:57,666
the Kennedy School.

903
00:41:57,733 --> 00:42:00,333
You were the Dean of
the Fletcher School.

904
00:42:00,400 --> 00:42:04,599
Do you - in the education
space, it would seem that

905
00:42:04,666 --> 00:42:08,733
- how do you get people to
think about cybersecurity

906
00:42:08,800 --> 00:42:12,199
as a policy issue, right,
but also educational

907
00:42:12,266 --> 00:42:15,266
institutions as public
vulnerabilities?

908
00:42:15,333 --> 00:42:16,500
>> JAMES STAVRIDIS: Yeah,
let me take the first

909
00:42:16,566 --> 00:42:17,698
part of that.

910
00:42:17,766 --> 00:42:21,933
So, educationally, I
started coding when I was

911
00:42:22,000 --> 00:42:25,933
in my 20s all the way back
in the 1970s, also known

912
00:42:26,000 --> 00:42:29,566
as 1.2 million years ago.

913
00:42:29,633 --> 00:42:32,533
I was actually in a
classroom with Rear

914
00:42:32,599 --> 00:42:35,366
Admiral Grace Hopper,
"Amazing Grace," the

915
00:42:35,433 --> 00:42:37,266
mother of COBOL.

916
00:42:37,333 --> 00:42:40,266
I trained in electrical
engineering in Annapolis

917
00:42:40,333 --> 00:42:44,566
and because the term
computer scientist didn't

918
00:42:44,633 --> 00:42:48,500
exist, so I'm a lifelong
engaged in this sphere.

919
00:42:48,566 --> 00:42:50,732
When I got to be the Dean
of the Fletcher School, I

920
00:42:50,800 --> 00:42:53,866
found lots of really smart
people who wanted to talk

921
00:42:53,933 --> 00:42:56,833
about policy and all of
the policy issues and the

922
00:42:56,900 --> 00:43:00,300
deterrence issues and the
geopolitics and so on.

923
00:43:00,366 --> 00:43:05,099
I found almost nobody who
wanted to marry up the

924
00:43:05,166 --> 00:43:08,366
policy issues with
the technical issues.

925
00:43:08,433 --> 00:43:12,833
So, we created a master's
degree at the Fletcher

926
00:43:12,900 --> 00:43:16,666
School jointly with Tufts
University's computer

927
00:43:16,733 --> 00:43:17,933
science department.

928
00:43:18,000 --> 00:43:21,033
So, it's a master's in
cybersecurity but before

929
00:43:21,099 --> 00:43:23,800
you graduate, you've got
to know how to code.

930
00:43:23,866 --> 00:43:26,766
You've got to understand
how that email gets from

931
00:43:26,833 --> 00:43:31,066
that supercomputer to my
grandmother's iPhone down

932
00:43:31,133 --> 00:43:33,366
in Florida technically.

933
00:43:33,433 --> 00:43:34,800
You've got to be able to
describe it, understand

934
00:43:34,866 --> 00:43:35,933
the vulnerabilities.

935
00:43:36,000 --> 00:43:41,599
So, I think that we are
overweight in the academy,

936
00:43:41,666 --> 00:43:45,699
in the Harvard's, in the
Tufts', in a variety of

937
00:43:45,766 --> 00:43:47,766
other really high-end
institutions.

938
00:43:47,833 --> 00:43:49,933
We're overweight
on the policy side.

939
00:43:50,000 --> 00:43:52,033
We're underweight on
the technical side.

940
00:43:52,099 --> 00:43:54,433
Creating degree programs
that bring those

941
00:43:54,500 --> 00:43:56,866
disciplines together,
I think, is crucial.

942
00:43:56,933 --> 00:44:00,066
>> JULIETTE KAYYEM: Yes,
and that's exactly right

943
00:44:00,133 --> 00:44:03,866
that you - people will ask
me about my career and I

944
00:44:03,933 --> 00:44:07,233
always say, you know, get
your hands dirty for some

945
00:44:07,300 --> 00:44:08,099
period of time.

946
00:44:08,166 --> 00:44:09,800
People who sort of go
through policy schools,

947
00:44:09,866 --> 00:44:12,266
you know, don't - if you
don't know how the wires

948
00:44:12,333 --> 00:44:15,233
connect or you don't know
what it means to run an

949
00:44:15,300 --> 00:44:17,766
incident command in a
crisis or whatever it is,

950
00:44:17,833 --> 00:44:19,833
you're not going to
understand essentially

951
00:44:19,900 --> 00:44:23,166
what people are doing
for you if you're in a

952
00:44:23,233 --> 00:44:24,566
leadership position
or something.

953
00:44:24,633 --> 00:44:27,866
It does - what you were
saying though, this idea

954
00:44:27,933 --> 00:44:31,533
that what people in
cybersecurity do is

955
00:44:31,599 --> 00:44:34,333
technical and I'm the
policy thinker and there

956
00:44:34,400 --> 00:44:35,900
is no - there is a
gap between them.

957
00:44:35,966 --> 00:44:39,033
I often tell an
anecdote that I get.

958
00:44:39,099 --> 00:44:41,866
I do a lot of preparedness
consulting, even if it is

959
00:44:41,933 --> 00:44:44,699
cybersecurity, that
I had a conversation

960
00:44:44,766 --> 00:44:46,733
with a CEO once.

961
00:44:46,800 --> 00:44:49,033
A lot of you probably
struggle with this, those

962
00:44:49,099 --> 00:44:50,500
of you who are in
companies that do not view

963
00:44:50,566 --> 00:44:52,533
themselves as security
companies, but you're the

964
00:44:52,599 --> 00:44:55,400
security person
or the CISO.

965
00:44:55,466 --> 00:44:58,933
I asked the CEO, I said,
how often do you meet your

966
00:44:59,000 --> 00:45:00,400
COO?

967
00:45:00,466 --> 00:45:03,299
He goes, oh, you know,
multiple times a day, right?

968
00:45:03,366 --> 00:45:05,433
And then how often do
you meet with your CFO?

969
00:45:05,500 --> 00:45:07,066
Well, no less than two
times a week, we have a

970
00:45:07,133 --> 00:45:08,000
scheduled meeting.

971
00:45:08,066 --> 00:45:11,098
So, what about your Chief
Security Officer or your

972
00:45:11,166 --> 00:45:12,833
Chief Information
Security Officer?

973
00:45:12,900 --> 00:45:15,466
He literally said this to me;
he goes, he's former FBI.

974
00:45:15,533 --> 00:45:17,433
He knows what he's doing.

975
00:45:17,500 --> 00:45:20,066
You just could not imagine
a CEO saying that about

976
00:45:20,133 --> 00:45:22,332
their CFO or COO, right?

977
00:45:22,400 --> 00:45:23,900
You take a responsibility.

978
00:45:23,966 --> 00:45:25,966
But this idea that well,
that's something that

979
00:45:26,033 --> 00:45:29,033
experts know and I have no
responsibility to know it,

980
00:45:29,099 --> 00:45:31,666
you just, you couldn't imagine
that in any other space.

981
00:45:31,733 --> 00:45:32,666
>> JAMES STAVRIDIS:
You cannot.

982
00:45:32,733 --> 00:45:36,133
I'm on the board of a
large financial institution.

983
00:45:36,199 --> 00:45:37,633
It is called
Neuberger Berman.

984
00:45:37,699 --> 00:45:41,666
It is kind of like T. Rowe Price
or Fidelity, manages a bunch of

985
00:45:41,733 --> 00:45:43,233
different investments.

986
00:45:43,300 --> 00:45:45,333
A pretty good size,
Wallstreet firm.

987
00:45:45,400 --> 00:45:49,666
And we - as a board
member, my mission has

988
00:45:49,733 --> 00:45:51,400
been exactly that point.

989
00:45:51,466 --> 00:45:55,699
Now our CISO comes to
every board meeting and

990
00:45:55,766 --> 00:45:58,766
believe me, if the CISO is
talking to the board, the

991
00:45:58,833 --> 00:46:01,933
CEO is highly interested
in that conversation.

992
00:46:02,000 --> 00:46:07,800
I think, Juliette, that
the FEC, the Federal

993
00:46:07,866 --> 00:46:11,433
Exchange Commission that
oversees governance in the

994
00:46:11,500 --> 00:46:14,433
United States, I think
before too long will

995
00:46:14,500 --> 00:46:17,033
mandate that public
boards have at least one

996
00:46:17,099 --> 00:46:21,433
individual with real
provable expertise in

997
00:46:21,500 --> 00:46:25,300
cyber and cybersecurity
just like public boards

998
00:46:25,366 --> 00:46:27,400
are required to have
people who have auditing

999
00:46:27,466 --> 00:46:30,400
experience, who had
the audit committee.

1000
00:46:30,466 --> 00:46:32,833
If you're going to run a
risk committee on a public

1001
00:46:32,900 --> 00:46:36,366
or a big private firm, my
view, there ought to be a

1002
00:46:36,433 --> 00:46:40,566
cybersecurity expert on
the board that increases

1003
00:46:40,633 --> 00:46:43,433
the level of interest and
attention that the C-suite

1004
00:46:43,500 --> 00:46:44,533
has to this.

1005
00:46:44,599 --> 00:46:47,066
I think that
light is going on.

1006
00:46:47,133 --> 00:46:51,633
It is back to how business
is increasingly addressing

1007
00:46:51,699 --> 00:46:53,233
this and figuring it out.

1008
00:46:53,300 --> 00:46:54,933
>> JULIETTE KAYYEM: So,
we are, shockingly,

1009
00:46:55,000 --> 00:46:56,199
down to three minutes.

1010
00:46:56,266 --> 00:46:59,766
So, I just want to give
you an opportunity about

1011
00:46:59,833 --> 00:47:01,733
your thoughts when you
look at - and we went from

1012
00:47:01,800 --> 00:47:04,566
sort of global threats to
the very tactical threats

1013
00:47:04,633 --> 00:47:05,765
and board rooms.

1014
00:47:05,833 --> 00:47:09,400
Is there something that
when you look at the

1015
00:47:09,466 --> 00:47:11,533
threats that we face
in both the public and

1016
00:47:11,599 --> 00:47:14,733
private sector from both
governments, outside

1017
00:47:14,800 --> 00:47:16,699
governments, and
individual actors, is

1018
00:47:16,766 --> 00:47:19,366
there - you know, is there
a through line we could be

1019
00:47:19,433 --> 00:47:20,166
thinking about?

1020
00:47:20,233 --> 00:47:22,566
Is there a connective
tissue or any advice that

1021
00:47:22,633 --> 00:47:25,433
you can give as people
read headlines and, you

1022
00:47:25,500 --> 00:47:26,833
know, you have been in
this field a long time?

1023
00:47:26,900 --> 00:47:27,833
I have been in
it a long time.

1024
00:47:27,900 --> 00:47:30,833
You know, we know how
to process noise and

1025
00:47:30,900 --> 00:47:33,733
prioritize threats, so.

1026
00:47:33,800 --> 00:47:35,466
>> JAMES STAVRIDIS: This
may or may not surprise

1027
00:47:35,533 --> 00:47:38,098
you; as you have heard the
conversation unfold, you

1028
00:47:38,166 --> 00:47:40,900
know that I worry a great
deal about cybersecurity

1029
00:47:40,966 --> 00:47:41,933
and I do.

1030
00:47:42,000 --> 00:47:45,033
I worry a lot about Syria,
Afghanistan, Libya, the

1031
00:47:45,099 --> 00:47:47,333
Balkans, and I have
touched all of those

1032
00:47:47,400 --> 00:47:50,900
crises and many more
in a long-misspent youth

1033
00:47:50,966 --> 00:47:52,266
in the Navy.

1034
00:47:52,333 --> 00:47:55,699
Here is my point to your
question; I think the

1035
00:47:55,766 --> 00:47:58,666
number one threat to the
United States of America,

1036
00:47:58,733 --> 00:48:01,533
and we have touched on
it, is polarization.

1037
00:48:01,599 --> 00:48:04,466
It is this angry
political season in which

1038
00:48:04,533 --> 00:48:05,900
we find ourselves.

1039
00:48:05,966 --> 00:48:07,633
And I'm a centrist.

1040
00:48:07,699 --> 00:48:10,366
I'm a registered
independent.

1041
00:48:10,433 --> 00:48:12,366
I was vetted for vice
president by Hillary

1042
00:48:12,433 --> 00:48:16,000
Clinton, one of six people
actually vetted, and then

1043
00:48:16,066 --> 00:48:19,433
I was offered a cabinet
post by Donald Trump.

1044
00:48:19,500 --> 00:48:20,800
I think of that, by the
way, as kind of two

1045
00:48:20,866 --> 00:48:23,266
bullets whizzing
by my head.

1046
00:48:27,699 --> 00:48:30,699
So, we ought to be asking
ourselves as Americans how

1047
00:48:30,766 --> 00:48:32,066
do we get out of this?

1048
00:48:32,133 --> 00:48:33,966
We have touched on a
couple of different ideas,

1049
00:48:34,033 --> 00:48:35,699
including education.

1050
00:48:35,766 --> 00:48:40,166
I want to go back to the
idea of service as I close.

1051
00:48:40,233 --> 00:48:43,400
And my observation
is as follows.

1052
00:48:43,466 --> 00:48:46,133
And here, by the way,
I'm talking to you.

1053
00:48:46,199 --> 00:48:50,133
Whether you are a Fox News
watching, you get up in

1054
00:48:50,199 --> 00:48:51,933
the morning and you watch
Fox and Friends and the

1055
00:48:52,000 --> 00:48:54,333
folks on the white couch
and you can't imagine an

1056
00:48:54,400 --> 00:48:56,866
evening where you haven't
heard from Sean Hannity by

1057
00:48:56,933 --> 00:49:01,800
the end of the night, or
if you are an MSNBC, got

1058
00:49:01,866 --> 00:49:04,199
to watch Morning Joe, and
the last thing you hear

1059
00:49:04,266 --> 00:49:07,000
before you nod off is
Rachel Maddow, I'm talking

1060
00:49:07,066 --> 00:49:09,732
to you across that
whole spectrum.

1061
00:49:09,800 --> 00:49:13,033
We have got to find a way
to have conversations

1062
00:49:13,099 --> 00:49:16,066
where we can disagree
without being intensely

1063
00:49:16,133 --> 00:49:19,433
disagreeable, without
personalizing everything,

1064
00:49:19,500 --> 00:49:22,666
without lying about
things, we have got to

1065
00:49:22,733 --> 00:49:24,000
find our way back.

1066
00:49:24,066 --> 00:49:28,866
So, I'll close with a
thought in which a portion

1067
00:49:28,933 --> 00:49:30,033
of that can happen.

1068
00:49:30,099 --> 00:49:32,400
It is the idea of service.

1069
00:49:32,466 --> 00:49:33,598
As follows:

1070
00:49:33,666 --> 00:49:36,133
People say to me all the
time, and I appreciate it,

1071
00:49:36,199 --> 00:49:38,166
Admiral, thank you
for your service.

1072
00:49:38,233 --> 00:49:40,866
I spent thirty-seven
years in the Navy and

1073
00:49:40,933 --> 00:49:41,900
I'm proud of that.

1074
00:49:41,966 --> 00:49:43,165
People say that a lot.

1075
00:49:43,233 --> 00:49:45,033
Here is my point.

1076
00:49:45,099 --> 00:49:48,133
There are so many ways
to serve this country.

1077
00:49:48,199 --> 00:49:51,366
Our civil servants, like
Assistant Secretary

1078
00:49:51,433 --> 00:49:53,633
sitting right
here to my left.

1079
00:49:53,699 --> 00:49:58,033
How about our diplomats,
CIA officers, NSA

1080
00:49:58,099 --> 00:50:02,366
officers, our Peace
Corps volunteers?

1081
00:50:02,433 --> 00:50:05,333
How about our
police, our firemen?

1082
00:50:05,400 --> 00:50:09,566
How about teachers,
teachers in rural South

1083
00:50:09,633 --> 00:50:13,866
Carolina teaching a packed
classroom for $36,000 a year.

1084
00:50:13,933 --> 00:50:15,833
You think they're
serving the country?

1085
00:50:15,900 --> 00:50:17,433
I do.

1086
00:50:17,500 --> 00:50:20,466
And I'll tell you as I
close, we have got to

1087
00:50:20,533 --> 00:50:24,333
think about service as
something we can agree on.

1088
00:50:24,400 --> 00:50:28,300
Service is bipartisan,
service is nonpartisan.

1089
00:50:28,366 --> 00:50:33,166
So, my ask of you is when
you meet people who are

1090
00:50:33,233 --> 00:50:36,599
serving the country in a
positive, significant way,

1091
00:50:36,666 --> 00:50:38,400
thank them.

1092
00:50:38,466 --> 00:50:41,533
Thank a teacher
for his service.

1093
00:50:41,599 --> 00:50:44,500
Thank a police officer
for her service.

1094
00:50:44,566 --> 00:50:49,198
Service is part of the
path from this angry

1095
00:50:49,266 --> 00:50:50,466
political season.

1096
00:50:50,533 --> 00:50:51,598
Last thought.

1097
00:50:51,666 --> 00:50:55,599
Don't for a minute believe
that what you are doing

1098
00:50:55,666 --> 00:51:01,333
for cybersecurity is not
service to the nation

1099
00:51:01,400 --> 00:51:04,866
because it is, because we
are vulnerable as Juliette

1100
00:51:04,933 --> 00:51:07,766
and I have talked about
for almost an hour.

1101
00:51:07,833 --> 00:51:10,599
You are part of
defending the country.

1102
00:51:10,666 --> 00:51:13,166
You are serving
the country.

1103
00:51:13,233 --> 00:51:16,099
So, I will close our
wonderful hour together

1104
00:51:16,166 --> 00:51:19,066
with gracious thanks to
the Assistant Secretary.

1105
00:51:19,133 --> 00:51:22,598
I'll close by saying to
all of you, thank you for

1106
00:51:22,666 --> 00:51:25,433
your service in keeping
this country safe.

1107
00:51:25,500 --> 00:51:26,400
Thank you very much.

1108
00:51:26,466 --> 00:51:27,598
A pleasure to
meet with you.

1109
00:51:27,666 --> 00:51:28,533
>> JULIETTE KAYYEM:
Thank you all.

1110
00:51:28,599 --> 00:51:30,266
>> JAMES STAVRIDIS:
Thank you.

1111
00:51:30,333 --> 00:51:31,599
Thank you very much.

