1
00:00:06,500 --> 00:00:09,033
>> ANNOUNCER: Please
welcome Katie Moussouris and

2
00:00:09,099 --> 00:00:10,800
Chris Wysopal.

3
00:00:20,566 --> 00:00:21,566
>> KATIE MOUSSOURIS:
Good morning!

4
00:00:21,633 --> 00:00:24,698
And thank you all so much for
joining us on this early morning

5
00:00:24,766 --> 00:00:26,465
on the last day of RSA.

6
00:00:26,533 --> 00:00:28,766
We are so happy
to be here today.

7
00:00:28,833 --> 00:00:31,665
Today we're going to talk to you
about Coordinated Vulnerability

8
00:00:31,733 --> 00:00:34,399
Disclosure: You've
Come a Long Way, Baby.

9
00:00:34,466 --> 00:00:38,066
But first, we want to get
through some vocabulary because

10
00:00:38,133 --> 00:00:42,100
we've seen a lot of words in
this space used interchangeably

11
00:00:42,166 --> 00:00:43,833
and it turns out words matter.

12
00:00:43,899 --> 00:00:46,799
Before we have this discussion
weaving in some history with

13
00:00:46,866 --> 00:00:49,666
some current data about
vulnerability disclosure,

14
00:00:49,733 --> 00:00:51,965
we really wanted to
settle on some terms.

15
00:00:52,399 --> 00:00:54,733
What is vulnerability
disclosure in the first place?

16
00:00:54,799 --> 00:00:57,566
Well, it is the process by which
you receive a vulnerability

17
00:00:57,633 --> 00:01:01,533
report from the outside, decide
to do something with it or not,

18
00:01:01,600 --> 00:01:05,533
and then release guidance
or a patch or something.

19
00:01:05,599 --> 00:01:09,799
That process is governed by two
ISO standards that Art Bannon

20
00:01:09,866 --> 00:01:12,700
from CERT CC&I
co-authored and co-edited.

21
00:01:12,766 --> 00:01:16,966
Those are ISO 29147
and ISO 30111.

22
00:01:17,033 --> 00:01:21,866
Think of 29147 as the mouth, and
the other end, and 30111 as the

23
00:01:21,933 --> 00:01:24,433
digestive system of the bugs.

24
00:01:24,500 --> 00:01:25,666
That's vuln disclosure.

25
00:01:25,733 --> 00:01:28,400
Penetration testing, on the
other hand, is inviting

26
00:01:28,466 --> 00:01:31,798
professional outside hackers to
take a look at your security

27
00:01:31,866 --> 00:01:35,500
controls, try to find some
vulnerabilities, and really

28
00:01:35,566 --> 00:01:38,400
ideally tell you how to fix them
and prevent them in the future.

29
00:01:38,466 --> 00:01:43,399
That's done under contract under
NDA and it's a profession that

30
00:01:43,466 --> 00:01:47,466
WeldPond, I mean Chris Wysopal
and I both started out in a long

31
00:01:47,533 --> 00:01:50,166
time ago at the very beginning
of the penetration testing

32
00:01:50,233 --> 00:01:51,966
industry about 20 years ago.

33
00:01:52,766 --> 00:01:54,566
Finally, we've got
bug bounty programs.

34
00:01:54,633 --> 00:01:57,098
A lot of people use
them interchangeably with

35
00:01:57,166 --> 00:01:58,298
pen testing.

36
00:01:58,366 --> 00:02:01,433
And a lot of people try to put
non-disclosure agreements on bug

37
00:02:01,500 --> 00:02:04,466
bounties, which is a little
funny because it's sort of a

38
00:02:04,533 --> 00:02:07,666
blend between coordinated vuln
disclosure where people were

39
00:02:07,733 --> 00:02:11,766
reporting bugs for free and
waiting to get them fixed and

40
00:02:11,833 --> 00:02:14,333
penetration testing where
you get paid for bugs.

41
00:02:14,400 --> 00:02:17,500
But even some of the bugs that
are deemed out of scope in some

42
00:02:17,566 --> 00:02:21,166
of these bug bounty programs
are not allowed to be released.

43
00:02:21,233 --> 00:02:24,866
It's a little bit like asking
someone to work for the exposure

44
00:02:24,933 --> 00:02:26,400
without the exposure.

45
00:02:26,466 --> 00:02:29,333
Now that we've got the terms
right, we're going to go into

46
00:02:29,400 --> 00:02:30,133
some data.

47
00:02:32,733 --> 00:02:35,866
>> CHRIS WYSOPAL: Veracode
conducted a study last year on

48
00:02:35,933 --> 00:02:37,366
coordinated
vulnerability disclosure.

49
00:02:37,433 --> 00:02:42,500
We worked with 451 group to
shape the study and actually

50
00:02:42,566 --> 00:02:45,400
execute the survey
with respondents.

51
00:02:45,466 --> 00:02:48,233
And we wanted it to be broad
enough that we weren't just

52
00:02:48,300 --> 00:02:52,133
talking to software companies
or just talking to researchers.

53
00:02:52,199 --> 00:02:56,099
We wanted to talk to people that
were in charge of information

54
00:02:56,166 --> 00:02:57,299
security at organizations.

55
00:02:57,366 --> 00:03:02,000
We wanted to talk to
professional penetration testers

56
00:03:02,066 --> 00:03:04,033
and infrastructure
security people.

57
00:03:04,099 --> 00:03:06,232
It was fairly broad.

58
00:03:06,300 --> 00:03:08,666
There were about 1,000
participants in Europe and in

59
00:03:08,733 --> 00:03:09,966
the United States.

60
00:03:10,033 --> 00:03:13,132
And there was a requirement
that you actually had to have a

61
00:03:13,199 --> 00:03:16,366
medium to high
awareness of vulnerability

62
00:03:16,433 --> 00:03:17,799
disclosure policies.

63
00:03:17,866 --> 00:03:20,966
You had to have some knowledge
about it in order for your

64
00:03:21,033 --> 00:03:22,366
opinion to be valid.

65
00:03:22,433 --> 00:03:25,198
On the slide there, you'll see
that's actually the link to the

66
00:03:25,266 --> 00:03:27,698
full study, but we're going
to be picking out some of the

67
00:03:27,766 --> 00:03:32,399
interesting data from the survey
and sharing it with you today.

68
00:03:36,066 --> 00:03:37,466
>> KATIE MOUSSOURIS: Well,
first, let's start with a

69
00:03:37,533 --> 00:03:38,565
little history.

70
00:03:38,633 --> 00:03:41,933
When Chris asked me to do this
talk with him, we were trying to

71
00:03:42,000 --> 00:03:44,266
think back of how long
we've known each other.

72
00:03:44,333 --> 00:03:47,500
We don't remember, so
it's been that long.

73
00:03:47,566 --> 00:03:50,566
Since we have been through
some of the evolutionary, core

74
00:03:50,633 --> 00:03:53,033
evolutionary points, and
sometimes driven some of them

75
00:03:53,099 --> 00:03:56,198
ourselves along with our friends
and colleagues, we thought we

76
00:03:56,266 --> 00:03:57,899
would give you a
little piece of history.

77
00:03:58,599 --> 00:03:59,698
>> CHRIS WYSOPAL: Yeah.

78
00:03:59,766 --> 00:04:02,799
Some of these learning
experiences are what drove

79
00:04:02,866 --> 00:04:05,733
modern day coordinated
vulnerability disclosure.

80
00:04:05,800 --> 00:04:08,533
You sort of had to
learn along the way.

81
00:04:08,599 --> 00:04:13,899
One of those learnings was doing
disclosure without coordination.

82
00:04:13,966 --> 00:04:20,333
There was a time before CVD that
vulnerability researchers would

83
00:04:20,399 --> 00:04:24,666
just publish things to
mailing lists like BUGtrack.

84
00:04:24,733 --> 00:04:29,066
I was part of the L0pht back in
the '90s and we did quite a bit

85
00:04:29,133 --> 00:04:33,166
of vulnerability research
and publishing of research.

86
00:04:33,233 --> 00:04:35,899
The only thing in the '90s that
really existed, especially in

87
00:04:35,966 --> 00:04:41,699
the early to mid '90s, that
existed that even approached

88
00:04:41,766 --> 00:04:47,033
coordination was sending an
email to CERT and giving them

89
00:04:47,100 --> 00:04:51,633
the vulnerability information
and saying can you contact

90
00:04:51,699 --> 00:04:52,966
the vender?

91
00:04:53,033 --> 00:04:55,733
CERT would happily take the
vulnerability information and

92
00:04:55,800 --> 00:04:58,666
say, yes, we'll contact the
vender, and that was the end of

93
00:04:58,733 --> 00:05:00,066
the process.

94
00:05:00,133 --> 00:05:01,765
You didn't hear from them again.

95
00:05:01,833 --> 00:05:04,000
You didn't know if the
vulnerability got fixed, what

96
00:05:04,066 --> 00:05:05,198
version it got fixed in.

97
00:05:05,266 --> 00:05:07,733
You didn't know when you
could start talking about it.

98
00:05:07,800 --> 00:05:09,966
Maybe the bug had
already been fixed.

99
00:05:10,033 --> 00:05:11,399
It wasn't really coordinated.

100
00:05:11,466 --> 00:05:15,899
We tried that a little bit at
the L0pht and we decided that,

101
00:05:15,966 --> 00:05:18,433
you know, that didn't really
help the general public

102
00:05:18,500 --> 00:05:21,000
understand that their software
was vulnerable, that kind

103
00:05:21,066 --> 00:05:21,799
of process.

104
00:05:21,866 --> 00:05:25,666
We would just publish
the things publicly.

105
00:05:25,733 --> 00:05:32,866
So in November '97, Dildog, or
also real name Christian Riu, my

106
00:05:32,933 --> 00:05:36,866
cofounder at Veracode, was part
of the L0pht, and he found a

107
00:05:36,933 --> 00:05:42,733
particularly interesting remote
code execution bug in IE4 where

108
00:05:42,800 --> 00:05:46,166
he could generate a link, put
it on a webpage, and if someone

109
00:05:46,233 --> 00:05:49,966
clinked on that, you could
execute code on their machine.

110
00:05:50,033 --> 00:05:54,333
He published this with a proof
of concept code so other people

111
00:05:54,399 --> 00:05:56,000
could understand it.

112
00:05:56,066 --> 00:05:58,566
This was actually kind of a
new kind of vulnerability.

113
00:05:58,633 --> 00:06:00,500
Now we understand
these pretty well now.

114
00:06:00,566 --> 00:06:04,198
And one of the fun things that
he did was he created a proof of

115
00:06:04,266 --> 00:06:06,699
concept on the
L0pht.com website.

116
00:06:06,766 --> 00:06:12,300
I don't know if anyone remembers
back in '97, Intel Pentium had a

117
00:06:12,366 --> 00:06:17,599
bug where if you executed the
F00F instruction, it locked up

118
00:06:17,666 --> 00:06:19,366
the CPU.

119
00:06:19,433 --> 00:06:21,199
We did a really
simple proof of concept.

120
00:06:21,266 --> 00:06:24,266
We actually called it the FOOF
of concept because it was

121
00:06:24,333 --> 00:06:28,100
F-O-O-F, and you could like on a
link on the Veracode page if you

122
00:06:28,166 --> 00:06:31,500
were running IE4 and it would
lock up your whole machine.

123
00:06:31,566 --> 00:06:32,899
We put a lot of
warnings around that.

124
00:06:33,699 --> 00:06:35,899
This kind of got in the press
and people were like look at

125
00:06:35,966 --> 00:06:38,166
this, IE4 is vulnerable.

126
00:06:38,233 --> 00:06:43,266
For the first time, Microsoft
actually reached out and sent us

127
00:06:43,333 --> 00:06:47,033
an email to our contact address
and said, you know what, guys,

128
00:06:47,100 --> 00:06:52,366
if you send us the vulnerability
information before releasing it

129
00:06:52,433 --> 00:06:55,699
to the public, we'll fix it and
we'll get back to you when we

130
00:06:55,766 --> 00:06:59,466
fix it, and then you should
release the information.

131
00:06:59,533 --> 00:07:02,699
We said, you know, if you're
really going to fix it and get

132
00:07:02,766 --> 00:07:05,266
back to us and tell us you fixed
it and you have no problem with

133
00:07:05,333 --> 00:07:07,766
us releasing the information
after you've fixed it, then

134
00:07:07,833 --> 00:07:09,000
let's try that.

135
00:07:09,066 --> 00:07:10,066
Right? Let's try that.

136
00:07:10,133 --> 00:07:13,466
That was really kind of
the birth of coordinated

137
00:07:13,533 --> 00:07:15,333
vulnerability disclosure at
least between the L0pht

138
00:07:15,399 --> 00:07:16,366
and Microsoft.

139
00:07:16,433 --> 00:07:22,699
It was also the birth of the
first haiku published in a

140
00:07:22,766 --> 00:07:23,833
vulnerability report.

141
00:07:23,899 --> 00:07:27,033
I believe Dildog
wrote Microsoft IE.

142
00:07:27,100 --> 00:07:28,666
Is there no security?

143
00:07:28,733 --> 00:07:30,133
Not if you ask me.

144
00:07:30,199 --> 00:07:31,933
A little bit of a poet also.

145
00:07:31,933 --> 00:07:37,832
But then after that incident,
people started to do a little

146
00:07:37,899 --> 00:07:40,366
bit of this coordination,
but it was very ad hoc.

147
00:07:40,433 --> 00:07:43,066
It was kind of like you had to
come up with an agreement with

148
00:07:43,133 --> 00:07:46,899
each vender, like what
would a vender accept?

149
00:07:46,966 --> 00:07:49,100
And, really, only Microsoft
was one of the only ones

150
00:07:49,166 --> 00:07:50,633
sophisticated enough to do this.

151
00:07:50,699 --> 00:07:55,300
Rain Forest Puppy, that was his
actual hacker name, so everyone

152
00:07:55,366 --> 00:07:58,832
called him RFP because that's
quite a mouthful, was finding a

153
00:07:58,899 --> 00:08:01,300
lot of vulnerabilities and
reporting them, and he took it

154
00:08:01,366 --> 00:08:06,500
upon himself to say I want to
have a rules of engagement that

155
00:08:06,566 --> 00:08:11,599
when I send a vulnerability to a
vender what my expectations are.

156
00:08:11,666 --> 00:08:16,899
He codified that up in
what he called RF policy.

157
00:08:16,966 --> 00:08:19,633
One of the first things he put
in there that was really kind of

158
00:08:19,699 --> 00:08:24,766
a breakthrough was I'm going to
give you X number of days to fix

159
00:08:24,833 --> 00:08:28,000
it or I'm going to go
ahead and release anyway.

160
00:08:28,066 --> 00:08:30,465
I'm not sure how many days,
if you remember how many days

161
00:08:30,533 --> 00:08:31,566
it was.

162
00:08:31,633 --> 00:08:32,500
>> KATIE MOUSSOURIS: I think
originally it was five and then

163
00:08:32,566 --> 00:08:34,166
he bumped it up to 30.

164
00:08:34,166 --> 00:08:35,433
>> CHRIS WYSOPAL:
Five is kind of short.

165
00:08:35,500 --> 00:08:37,366
We're going to talk
about timeframes, too.

166
00:08:39,466 --> 00:08:44,033
And then a further evolution
of that was, in 2000, I got

167
00:08:44,100 --> 00:08:49,266
together, Steve Christy, who is
the father of CWE - I think he

168
00:08:49,333 --> 00:08:54,165
might be the grandfather because
CWE has children now - he came

169
00:08:54,233 --> 00:08:58,099
to me and said, you know, Chris,
why don't we actually make a

170
00:08:58,166 --> 00:08:59,766
real standard around this?

171
00:08:59,833 --> 00:09:04,600
Why don't we submit an RFC to
the IETF and actually have

172
00:09:04,666 --> 00:09:07,966
something that is documented
that you can point to and it is

173
00:09:08,033 --> 00:09:10,666
not just something that a
security researcher did;

174
00:09:10,733 --> 00:09:13,266
a standards body
actually accepted it.

175
00:09:13,266 --> 00:09:19,000
A couple things happened
that it didn't go very well.

176
00:09:19,066 --> 00:09:22,566
One thing was the IETF thought
this was kind of a hot potato

177
00:09:22,633 --> 00:09:24,100
and just didn't want
to deal with it.

178
00:09:24,166 --> 00:09:25,966
They said it is
not in our purview.

179
00:09:26,033 --> 00:09:28,299
We don't want to deal with
this kind of standard.

180
00:09:28,366 --> 00:09:32,433
The second problem was when we
released the standard, we called

181
00:09:32,500 --> 00:09:35,466
it the responsible
disclosure policy.

182
00:09:35,533 --> 00:09:40,600
In hindsight, that was a mistake
because that word responsible is

183
00:09:40,666 --> 00:09:43,566
very loaded, and the fact that
it was a modifier on the word

184
00:09:43,633 --> 00:09:47,466
disclosure kind of meant that
the researcher, if they weren't

185
00:09:47,533 --> 00:09:51,600
going to follow this policy,
could be deemed irresponsible.

186
00:09:52,433 --> 00:09:53,500
>> KATIE MOUSSOURIS: Yeah.

187
00:09:53,566 --> 00:09:56,600
Unfortunately, it became a tool
and a hammer that is still used

188
00:09:56,666 --> 00:10:01,633
today to essentially intimidate
researchers into doing what the

189
00:10:01,700 --> 00:10:03,433
vender thinks is
the right thing.

190
00:10:03,500 --> 00:10:05,933
Reasonable people will
disagree about the best way to

191
00:10:06,000 --> 00:10:07,133
protect users.

192
00:10:07,200 --> 00:10:11,666
Sometimes the researchers find
that waiting forever is not

193
00:10:11,733 --> 00:10:13,699
actually the best
way to protect users.

194
00:10:13,700 --> 00:10:18,100
This next story is one where
Chris and I had worked on the

195
00:10:18,166 --> 00:10:24,133
disclosure of an issue that I
and my boyfriend at the time

196
00:10:24,200 --> 00:10:25,166
had found.

197
00:10:25,233 --> 00:10:28,333
How many of you have seen
this Lexar JumpDrive thing?

198
00:10:28,399 --> 00:10:29,000
Right?

199
00:10:29,066 --> 00:10:30,733
This is a little USB drive.

200
00:10:30,799 --> 00:10:33,733
And at the time, they had a
regular jump drive and then they

201
00:10:33,799 --> 00:10:36,165
had one that was
branded as secure.

202
00:10:36,233 --> 00:10:40,532
The advertising basically said
that if this drive were out of

203
00:10:40,600 --> 00:10:44,066
your possession, because you
have the capacity to secure a

204
00:10:44,133 --> 00:10:47,799
partition of it with a password
and it's encrypted, that it is

205
00:10:47,866 --> 00:10:50,165
safe even if
it gets lost. Right?

206
00:10:50,233 --> 00:10:54,266
That was their security model,
which they promptly broke by

207
00:10:54,333 --> 00:10:56,065
their implementation.

208
00:10:56,133 --> 00:10:58,700
My boyfriend at the time, Luis
Matos, and I took a look at

209
00:10:58,766 --> 00:11:00,000
this thing.

210
00:11:00,066 --> 00:11:02,566
We attached a debugger to the
application that came with the

211
00:11:02,633 --> 00:11:05,266
drive that would partition it
for you and allow you to set

212
00:11:05,333 --> 00:11:06,299
a password.

213
00:11:06,366 --> 00:11:09,633
Well, this isn't the real dump
of the memory there, but you

214
00:11:09,700 --> 00:11:10,833
can imagine.

215
00:11:10,899 --> 00:11:14,466
The application itself
did the work for us.

216
00:11:14,533 --> 00:11:18,733
All we needed to do was set a
password and then come into the

217
00:11:18,799 --> 00:11:22,199
application again with the
debugger attached and we could

218
00:11:22,266 --> 00:11:26,766
see that the application
helpfully decrypted the stored

219
00:11:26,833 --> 00:11:30,632
password for us, showed it to us
in clear text in memory, so any

220
00:11:30,700 --> 00:11:33,066
password attempt with the
debugger attached, you'd be able

221
00:11:33,133 --> 00:11:36,166
to see the stored password and
then just subsequently get in.

222
00:11:36,166 --> 00:11:40,266
Obviously, this was a problem.

223
00:11:40,333 --> 00:11:43,500
We tried to follow our
vulnerability disclosure policy

224
00:11:43,566 --> 00:11:46,033
because, at the time, we were
both the artists formally known

225
00:11:46,100 --> 00:11:48,666
AtStake, you know,
early application security

226
00:11:48,733 --> 00:11:49,933
penetration testers.

227
00:11:50,000 --> 00:11:53,799
We had a policy for disclosure
based largely on RF policy.

228
00:11:53,866 --> 00:11:58,500
And so we attempted contact
through every means we could.

229
00:11:58,566 --> 00:12:02,399
I think we skipped faxing them,
but we did everything else.

230
00:12:02,466 --> 00:12:04,233
We even called them.

231
00:12:04,299 --> 00:12:07,899
We exceeded our own timeframe
for what we would normally wait,

232
00:12:07,966 --> 00:12:09,166
which was 30 days.

233
00:12:09,233 --> 00:12:13,065
We kept giving them
chances to just say anything.

234
00:12:13,133 --> 00:12:14,333
Nothing at all.

235
00:12:14,399 --> 00:12:16,700
So we did what we
were going to do.

236
00:12:16,766 --> 00:12:20,500
Chris' role in all of this was
to help us coordinate this

237
00:12:20,566 --> 00:12:24,299
vulnerability and make sure
that we were also following the

238
00:12:24,366 --> 00:12:27,133
company's policy which we had
set ourselves as researchers.

239
00:12:27,200 --> 00:12:31,666
But, you know, also to gut check
us when it was like, look, these

240
00:12:31,733 --> 00:12:35,866
guys haven't even acknowledged
our email or phone calls or

241
00:12:35,933 --> 00:12:37,933
other emails or
other phone calls.

242
00:12:38,000 --> 00:12:39,899
How long are we
going to give them?

243
00:12:39,966 --> 00:12:41,200
Forever? Probably not.

244
00:12:42,200 --> 00:12:46,299
What we did was we
dropped Zero-day. Right?

245
00:12:46,366 --> 00:12:48,333
We did redact some
of the details.

246
00:12:48,399 --> 00:12:50,966
We didn't release any proof of
concept, but we still wanted

247
00:12:51,033 --> 00:12:55,000
users to be protected and
understand that this thing, it

248
00:12:55,066 --> 00:12:59,233
doesn't do what it
was marketed to do.

249
00:12:59,299 --> 00:13:02,665
We wanted people to understand
that if the drive were lost and

250
00:13:02,733 --> 00:13:06,065
outside of their possession that
someone could actually see their

251
00:13:06,133 --> 00:13:08,333
encrypted data.

252
00:13:08,399 --> 00:13:11,533
I don't speak any
other human languages.

253
00:13:11,600 --> 00:13:15,500
But as soon as that advisory
dropped, we got phone calls and

254
00:13:15,566 --> 00:13:18,100
there were swear words
that I had never heard in my

255
00:13:18,166 --> 00:13:19,266
entire life.

256
00:13:19,333 --> 00:13:22,000
What's funny about this is some
of the very same people who were

257
00:13:22,066 --> 00:13:25,799
on those email lists were coming
back at us saying I don't

258
00:13:25,866 --> 00:13:29,433
understand how you can call
yourselves responsible when you

259
00:13:29,500 --> 00:13:30,633
did this.

260
00:13:30,700 --> 00:13:33,399
And we thought, well, you could
have just answered our email.

261
00:13:33,466 --> 00:13:37,533
We told you what our policy was,
and we gave you all this time.

262
00:13:37,600 --> 00:13:40,666
But I guess they figured that if
they just ignored it, it might

263
00:13:40,733 --> 00:13:41,766
go away.

264
00:13:41,833 --> 00:13:46,733
Unfortunately, there is a lot
of that still going on, but

265
00:13:46,799 --> 00:13:48,933
hopefully some of this data is
going to show that things are

266
00:13:49,000 --> 00:13:49,899
going to get better.

267
00:13:50,566 --> 00:13:53,233
Here is some of the data from
the Veracode report they did

268
00:13:53,299 --> 00:13:54,733
with 451 Research.

269
00:13:54,799 --> 00:13:57,899
This is sort of -- of the
respondents, these are the

270
00:13:57,966 --> 00:13:59,366
actions that
researchers take now.

271
00:13:59,433 --> 00:14:03,866
What's good about it is that the
majority of researchers actually

272
00:14:03,933 --> 00:14:07,033
report vulnerabilities to the
affected vendor, they try to do

273
00:14:07,100 --> 00:14:10,399
it in a coordinated way, either
directly through a coordinator

274
00:14:10,466 --> 00:14:13,033
at like CERT/CC or through
a bug bounty program.

275
00:14:13,100 --> 00:14:15,899
But, you know, you can see
9% of them do release the

276
00:14:15,966 --> 00:14:18,066
vulnerability to the public.

277
00:14:18,133 --> 00:14:22,233
For us, that was a last resort
-- last, last resort, and

278
00:14:22,299 --> 00:14:23,966
hackers still have
to do this today.

279
00:14:28,100 --> 00:14:30,000
>> CHRIS WYSOPAL: I mentioned a
little bit about the timeline

280
00:14:30,066 --> 00:14:34,066
issue that was really
introduced in RF policy.

281
00:14:34,133 --> 00:14:36,933
This is probably the thing that
is still the most controversial

282
00:14:37,000 --> 00:14:39,100
part of any kind of CVD.

283
00:14:39,166 --> 00:14:42,866
I think most of the other
aspects of CVD we've learned

284
00:14:42,933 --> 00:14:46,399
lessons of the past, but the
timeframe issue still becomes

285
00:14:46,466 --> 00:14:48,166
a challenge.

286
00:14:48,233 --> 00:14:53,065
I think the biggest reason is
there is a vast diversity in

287
00:14:53,133 --> 00:14:56,166
technology and
capability to fix things.

288
00:14:56,233 --> 00:14:59,933
Think of a SAS company where
they control both building the

289
00:15:00,000 --> 00:15:04,000
software and deploying the
software, and a lot of times SAS

290
00:15:04,066 --> 00:15:07,433
companies are working with a
release schedule that's agile or

291
00:15:07,500 --> 00:15:10,633
DevOps, which could
be days or weeks.

292
00:15:10,700 --> 00:15:14,299
A lot of SAS companies can fix a
security bug and push it out in

293
00:15:14,366 --> 00:15:17,633
a few days and it's not even
that much burden on them.

294
00:15:18,399 --> 00:15:21,033
All the way on the other end of
the spectrum, you have things

295
00:15:21,100 --> 00:15:25,100
that are deployed in hardware,
right, where you have - someone

296
00:15:25,166 --> 00:15:31,500
might have to actually
physically go and use arcane

297
00:15:31,566 --> 00:15:34,200
processes to patch things.

298
00:15:34,266 --> 00:15:37,433
They're on systems that don't
get updated very often.

299
00:15:37,500 --> 00:15:40,899
Maybe they haven't been updated
in years, so it's difficult for

300
00:15:40,966 --> 00:15:44,799
the vendor to update and go
through the testing process.

301
00:15:44,866 --> 00:15:48,000
You could see how that might
take a few months to do that,

302
00:15:48,066 --> 00:15:49,399
even if you're
working hard on it.

303
00:15:49,399 --> 00:15:54,666
We asked the survey -- we asked
our participants what they

304
00:15:54,733 --> 00:15:57,299
thought was a reasonable
timeframe, and you can see the

305
00:15:57,366 --> 00:16:01,066
majority are in that sort of
30 to 60 days, or less than

306
00:16:01,133 --> 00:16:02,299
30 days.

307
00:16:02,366 --> 00:16:07,199
So people think maybe 60 days
is kind of a good timeframe.

308
00:16:07,266 --> 00:16:11,599
But there's 8% that think that
we should wait until the vender

309
00:16:11,666 --> 00:16:12,566
fixes it.

310
00:16:12,633 --> 00:16:16,233
You should just keep
waiting until that happens.

311
00:16:16,299 --> 00:16:19,233
I want to do a couple of
shows of hands here to see what

312
00:16:19,299 --> 00:16:21,433
people think.

313
00:16:21,500 --> 00:16:24,033
My first question is, if you
could raise your hand if you

314
00:16:24,100 --> 00:16:28,100
agree, how many think vendors
should be able to ask the

315
00:16:28,166 --> 00:16:31,266
researcher for more time
and the researcher respects

316
00:16:31,333 --> 00:16:32,699
those requests?

317
00:16:32,766 --> 00:16:33,899
How many people think that?

318
00:16:33,966 --> 00:16:37,933
About a third of
the group, maybe.

319
00:16:38,000 --> 00:16:39,533
I have a second question here.

320
00:16:39,600 --> 00:16:43,566
How many agree that vendors
should be given less than 30

321
00:16:43,633 --> 00:16:45,233
days to fix a vulnerability?

322
00:16:45,299 --> 00:16:47,533
Thirty days is enough time?

323
00:16:47,600 --> 00:16:48,799
Show of hands.

324
00:16:48,866 --> 00:16:50,100
>> KATIE MOUSSOURIS: There's
two, three, four people in

325
00:16:50,166 --> 00:16:51,333
this audience.

326
00:16:51,399 --> 00:16:52,799
>> CHRIS WYSOPAL: Maybe five.

327
00:16:52,866 --> 00:16:54,633
So, yeah, not many people
think 30 days is reasonable.

328
00:16:54,700 --> 00:16:55,933
>> KATIE MOUSSOURIS: Okay.

329
00:16:56,000 --> 00:17:00,266
So how many agree with the tenet
that one must never disclose

330
00:17:00,333 --> 00:17:04,200
vulnerability details if
there is no fix available?

331
00:17:04,266 --> 00:17:05,933
Oh, there are a couple of those.

332
00:17:06,000 --> 00:17:07,366
Okay. All right.

333
00:17:07,433 --> 00:17:09,133
No, raise your hands if
you're proud about that.

334
00:17:09,200 --> 00:17:10,333
All right.

335
00:17:10,400 --> 00:17:14,099
And then how many of you know
that even Microsoft has dropped

336
00:17:14,165 --> 00:17:16,366
Zero-day?

337
00:17:16,433 --> 00:17:17,465
Really? Okay.

338
00:17:17,532 --> 00:17:18,500
There we go.

339
00:17:18,566 --> 00:17:19,400
>> CHRIS WYSOPAL:
Some people know.

340
00:17:19,465 --> 00:17:20,632
>> KATIE MOUSSOURIS:
Some people know.

341
00:17:20,700 --> 00:17:22,200
I created Microsoft
vulnerability research back in

342
00:17:22,266 --> 00:17:25,566
2008 to assist with the
multiparty vulnerability

343
00:17:25,633 --> 00:17:30,666
coordination of Dan Kaminsky's
DNS world-ending internet fire

344
00:17:30,733 --> 00:17:32,399
-- dumpster fire bug.

345
00:17:32,466 --> 00:17:35,966
One of the things that was
interesting about that process

346
00:17:36,033 --> 00:17:39,500
was bringing together different
vendors who had to implement a

347
00:17:39,566 --> 00:17:44,033
change and ideally coordinate
their release altogether.

348
00:17:44,099 --> 00:17:47,566
In that process, Microsoft was
the slow one in that group and

349
00:17:47,633 --> 00:17:51,599
we had to work to persuade the
other vendors to please hold

350
00:17:51,666 --> 00:17:54,666
their patches so that
we could get ours ready.

351
00:17:54,733 --> 00:17:59,466
But in other cases, certainly we
would see things where we were

352
00:17:59,533 --> 00:18:02,933
worried about -- we as Microsoft
at the time -- were worried

353
00:18:03,000 --> 00:18:04,333
about our customer's safety.

354
00:18:04,400 --> 00:18:07,766
And especially if we saw
evidence of exploitation in the

355
00:18:07,833 --> 00:18:11,533
wild of a vulnerability we found
using our telemetry, then it was

356
00:18:11,599 --> 00:18:14,799
absolutely appropriate
for us to release details.

357
00:18:14,799 --> 00:18:18,566
There is another case back
in 2010 when Active Template

358
00:18:18,633 --> 00:18:22,000
Library, which was compiled into
every single active X control

359
00:18:22,066 --> 00:18:24,666
that was made at the time,
had a vulnerability in it.

360
00:18:24,733 --> 00:18:28,233
We could fix the library, but
every single active X control

361
00:18:28,299 --> 00:18:31,000
that hadn't been recompiled
would still be vulnerability.

362
00:18:31,066 --> 00:18:35,433
How to deal with all of those
secondary affected vendors?

363
00:18:35,500 --> 00:18:41,200
Well, we chose the top 10 or
15 vendors with the biggest

364
00:18:41,266 --> 00:18:44,099
overlapping customer base to
Microsoft to try and protect as

365
00:18:44,166 --> 00:18:45,799
many customers as possible.

366
00:18:45,866 --> 00:18:49,033
We let them into the multiparty
vulnerability disclosure circle,

367
00:18:49,099 --> 00:18:52,433
gave them the updated library,
so that on the day we released

368
00:18:52,500 --> 00:18:55,700
it, they could release their
updated active X controls at the

369
00:18:55,766 --> 00:18:56,933
same time.

370
00:18:57,000 --> 00:18:59,966
Trust me, one of those was
Facebook and their affected

371
00:19:00,033 --> 00:19:04,033
active X control component was
written by some dude in Romania

372
00:19:04,099 --> 00:19:07,000
and I had to call him up on the
phone and say, yeah, so there's

373
00:19:07,066 --> 00:19:09,066
a problem in the library
and it causes this.

374
00:19:09,133 --> 00:19:11,233
He said, well, we
don't use that library.

375
00:19:11,299 --> 00:19:13,799
It was a challenge all around.

376
00:19:13,866 --> 00:19:17,933
But that was the order of
operations that we did.

377
00:19:18,000 --> 00:19:21,599
Only those vendors of all
of the affected vendors got

378
00:19:21,666 --> 00:19:25,799
pre-disclosure and we dropped
oh day on everybody else.

379
00:19:25,866 --> 00:19:26,799
Couldn't be helped.

380
00:19:29,799 --> 00:19:32,733
Sentiment has changed
over the years. Right?

381
00:19:32,799 --> 00:19:34,233
This is also data
from the survey.

382
00:19:34,299 --> 00:19:38,000
Ninety percent of respondents,
and that's on any side of the

383
00:19:38,066 --> 00:19:40,866
vulnerability disclosure
equation, actually view

384
00:19:40,933 --> 00:19:44,200
vulnerability disclosure as
something of a public good.

385
00:19:44,266 --> 00:19:47,033
This sentiment has grown over
time and that's a positive

386
00:19:47,099 --> 00:19:48,133
thing. Right?

387
00:19:48,200 --> 00:19:51,299
And then the majority of them,
which is interesting, think that

388
00:19:51,366 --> 00:19:56,233
you do not need permission to
go ahead and test and find

389
00:19:56,299 --> 00:19:57,799
a vulnerability.

390
00:19:57,866 --> 00:20:00,733
That gets interesting because,
as you know, there are a lot of

391
00:20:00,799 --> 00:20:04,166
laws having to do with hacking,
not just the Computer Fraud

392
00:20:04,233 --> 00:20:10,200
Abuse Act in the United States,
CFAA, or the DMCA, but also

393
00:20:10,266 --> 00:20:13,500
there are increasing numbers of
data protection and privacy laws

394
00:20:13,566 --> 00:20:15,500
which gets complicated. Right?

395
00:20:15,566 --> 00:20:19,933
You're thinking to yourself,
well, can't we just have a bug

396
00:20:20,000 --> 00:20:23,400
bounty or a vuln disclosure
program, make them sign NDAs and

397
00:20:23,466 --> 00:20:28,565
all of this stuff, well, and
avoid a data breach if they find

398
00:20:28,633 --> 00:20:32,633
data or encounter data before
asking for permission and before

399
00:20:32,700 --> 00:20:34,000
asking for authorization.

400
00:20:34,066 --> 00:20:37,400
That turns out to
not really work out. Right?

401
00:20:37,466 --> 00:20:40,033
It is not the equivalent as
hiring a penetration testing

402
00:20:40,099 --> 00:20:43,233
company which is then acting
as an extension of your

403
00:20:43,299 --> 00:20:44,366
own organization.

404
00:20:44,433 --> 00:20:48,200
Even if you find all of the data
that's protected classes of

405
00:20:48,266 --> 00:20:51,500
data, it is still not
categorized as a breach because,

406
00:20:51,566 --> 00:20:55,033
ideally, your company in hiring
the pen test company has vetted

407
00:20:55,099 --> 00:20:58,000
that they have appropriate data
segmentation and that they will

408
00:20:58,066 --> 00:20:59,633
destroy any data
and all of that.

409
00:20:59,700 --> 00:21:03,166
When I was the first pen tester
of the Gates Foundation and I

410
00:21:03,233 --> 00:21:06,000
got Warren Buffet's Social
Security Number, if he's

411
00:21:06,066 --> 00:21:09,766
watching, eventually,
I don't still have it. Okay?

412
00:21:09,833 --> 00:21:12,566
Because we got rid of it.

413
00:21:12,633 --> 00:21:16,200
Now, what happened
recently, in recent history?

414
00:21:16,266 --> 00:21:20,000
This is pictures of me
testifying before Congress in

415
00:21:20,066 --> 00:21:24,766
the Uber data breach case that
their bug bounty program paid

416
00:21:24,833 --> 00:21:30,000
$100,000 to extortionists and
made them sign an NDA to say

417
00:21:30,066 --> 00:21:32,433
they were going to delete the
57 million records they had

418
00:21:32,500 --> 00:21:35,833
downloaded and tell no
one of what had happened.

419
00:21:35,900 --> 00:21:39,466
Now, Congress was obviously
interested in Uber's handling of

420
00:21:39,533 --> 00:21:42,866
this because Uber had already
been in trouble with the FTC for

421
00:21:42,933 --> 00:21:44,533
a different data breach.

422
00:21:44,599 --> 00:21:46,133
So they were in trouble.

423
00:21:46,200 --> 00:21:48,599
And what was interesting
about it was the researchers

424
00:21:48,666 --> 00:21:51,466
themselves, you know, they
thought, well, we complied with

425
00:21:51,533 --> 00:21:52,565
the NDA.

426
00:21:52,633 --> 00:21:56,000
We got our money through
this bug bounty program.

427
00:21:56,066 --> 00:22:00,966
And they tried the same
thing on another company.

428
00:22:01,033 --> 00:22:02,933
They were promptly indicted.

429
00:22:03,000 --> 00:22:06,333
It goes to show that things
right now are complicated.

430
00:22:06,400 --> 00:22:09,233
Asking for permission ahead of
time is still the safest thing.

431
00:22:09,299 --> 00:22:13,433
But the survey respondents, you
know, certainly thought that a

432
00:22:13,500 --> 00:22:16,266
lot more could be done without
asking for permission.

433
00:22:19,033 --> 00:22:22,132
Well, okay, so what happens when
CVD goes mainstream, which is

434
00:22:22,200 --> 00:22:23,166
kind of where we are today?

435
00:22:23,233 --> 00:22:25,832
Ideally, you have got a bunch
of friendly folks coming and

436
00:22:25,900 --> 00:22:27,466
reporting
vulnerabilities to you.

437
00:22:27,533 --> 00:22:29,733
What could possibly go wrong?

438
00:22:29,799 --> 00:22:32,033
Remember I said that
digestive system of bugs is

439
00:22:32,099 --> 00:22:33,332
pretty important?

440
00:22:33,400 --> 00:22:36,466
Well, it turns out it's
especially important if you

441
00:22:36,533 --> 00:22:39,599
start dangling money in front
of that equation and doing a

442
00:22:39,666 --> 00:22:40,599
bug bounty.

443
00:22:42,099 --> 00:22:47,599
>> CHRIS WYSOPAL: In the
timeframe 2005 to 2010 and a

444
00:22:47,666 --> 00:22:51,633
little beyond, we start seeing
bug bounties crop up at a lot of

445
00:22:51,700 --> 00:22:52,733
the larger companies.

446
00:22:52,799 --> 00:22:56,366
They got used to the coordinated
vulnerability disclosure, so now

447
00:22:56,433 --> 00:22:59,033
they want to sort of turn on the
faucet a little bit more and

448
00:22:59,099 --> 00:23:03,265
actually incense people outside
researchers to come in.

449
00:23:06,000 --> 00:23:09,900
At Veracode, we wanted to do an
infographic to kind of explain

450
00:23:09,966 --> 00:23:14,033
who has bug bounty programs,
what is a bug bounty program,

451
00:23:14,099 --> 00:23:18,866
just to publicize things, and we
came up with this fun graphic.

452
00:23:18,933 --> 00:23:21,766
And, actually, the original
graphic did not have Microsoft

453
00:23:21,833 --> 00:23:25,566
on it because Microsoft didn't
have a bug bounty program until

454
00:23:25,633 --> 00:23:27,266
June of 2013.

455
00:23:27,333 --> 00:23:29,366
We had created this a
couple of years earlier.

456
00:23:29,433 --> 00:23:32,099
But when Microsoft came out with
a bug bounty program, it was

457
00:23:32,166 --> 00:23:35,332
such a big event because they'd
held off for so long and they

458
00:23:35,400 --> 00:23:37,933
were the largest
software company, we updated

459
00:23:38,000 --> 00:23:39,033
our infographic.

460
00:23:39,099 --> 00:23:43,599
You can see here in the bottom
left there we put a new knight

461
00:23:43,666 --> 00:23:48,700
in shining armor, I guess, to
represent Microsoft, and then

462
00:23:48,766 --> 00:23:52,799
promptly we got an email
from this lady over here.

463
00:23:54,466 --> 00:23:57,366
>> KATIE MOUSSOURIS: Since
Microsoft had publicly said that

464
00:23:57,433 --> 00:24:00,333
they would never pay for
vulnerability information, their

465
00:24:00,400 --> 00:24:04,066
executives had gone on the
record, and I, of course, was

466
00:24:04,133 --> 00:24:07,766
diligently working inside as
only a hacker does changing

467
00:24:07,833 --> 00:24:11,166
hearts and minds and trying to
create a viable process for

468
00:24:11,233 --> 00:24:15,666
Microsoft, when this thing
finally launched, it had taken

469
00:24:15,733 --> 00:24:20,233
three years of hard-won economic
research, game theory research,

470
00:24:20,299 --> 00:24:24,033
all of these things to be able
to shape the funnel that was

471
00:24:24,099 --> 00:24:26,366
already the biggest funnel
in the world for intaking

472
00:24:26,433 --> 00:24:27,466
vulnerabilities.

473
00:24:27,533 --> 00:24:32,500
Over 200,000 non-spam email
messages a year come in to

474
00:24:32,566 --> 00:24:33,900
secure at Microsoft.

475
00:24:33,966 --> 00:24:36,500
You can understand why they
would have said, please,

476
00:24:36,566 --> 00:24:37,400
no more.

477
00:24:37,466 --> 00:24:38,565
We're good.

478
00:24:38,633 --> 00:24:40,799
We don't need to add
money to this equation.

479
00:24:40,866 --> 00:24:46,466
I was quite upset that a white
man was used to represent what I

480
00:24:46,533 --> 00:24:50,332
had created through flesh,
bones, and tears, so I sent them

481
00:24:50,400 --> 00:24:53,866
an updated graphic
that I made myself.

482
00:24:53,933 --> 00:24:58,099
>> CHRIS WYSOPAL: And we did
update the graphic, of course.

483
00:24:58,166 --> 00:25:00,099
What is that graphic, Katie?

484
00:25:00,166 --> 00:25:01,866
>> KATIE MOUSSOURIS: I mean,
I think I'm a wizard, Harry.

485
00:25:01,933 --> 00:25:03,133
But here is the thing.

486
00:25:03,200 --> 00:25:05,033
You might be confused by the
hair color on that, that it

487
00:25:05,099 --> 00:25:08,666
doesn't match my current hair
color, but the internet's memory

488
00:25:08,733 --> 00:25:10,066
is that of a goldfish.

489
00:25:10,133 --> 00:25:11,866
I've only had pink
hair for three years.

490
00:25:11,933 --> 00:25:15,666
That was my natural hair color
with a little blue streak in it

491
00:25:15,733 --> 00:25:18,566
and it was an accurate
representation of who was really

492
00:25:18,633 --> 00:25:20,166
behind the Microsoft bug bounty.

493
00:25:20,233 --> 00:25:21,233
Representation matters.

494
00:25:21,299 --> 00:25:22,533
I made sure of it.

495
00:25:22,599 --> 00:25:25,599
And these guys had a great sense
of humor with my, I don't know,

496
00:25:25,666 --> 00:25:28,899
really, really bad
photoshop -- photoshopping of

497
00:25:28,966 --> 00:25:30,166
their infographic.

498
00:25:32,766 --> 00:25:34,400
Let's talk about these
Microsoft bug bounties.

499
00:25:34,466 --> 00:25:36,166
I said it was hard-won.

500
00:25:36,233 --> 00:25:39,265
Well, you know, years of
preparation, all these studies,

501
00:25:39,333 --> 00:25:41,099
going up my chain of command.

502
00:25:41,166 --> 00:25:43,765
My chain of command certainly
didn't want to handle more than

503
00:25:43,833 --> 00:25:47,266
200,000 email messages
a year as it was. Right?

504
00:25:47,333 --> 00:25:51,900
I think 2008 was the year that
Popular Science called Microsoft

505
00:25:51,966 --> 00:25:55,565
security grunt in the top
ten worst jobs in science.

506
00:25:55,633 --> 00:25:58,900
We were between like
elephant vasectomist and whale

507
00:25:58,966 --> 00:25:59,899
feces researcher.

508
00:25:59,966 --> 00:26:01,866
We were right in there.

509
00:26:01,933 --> 00:26:03,633
And it was true. Right?

510
00:26:03,700 --> 00:26:07,900
Why tempt fate and get more bugs
potentially when we could get

511
00:26:07,966 --> 00:26:10,933
all these bugs for free,
high-quality bugs, bugs that

512
00:26:11,000 --> 00:26:13,566
could go for hundreds of
thousands of dollars on the

513
00:26:13,633 --> 00:26:15,366
offense market at the time?

514
00:26:15,433 --> 00:26:18,066
Well, what you're looking at
here is, on the left, you see

515
00:26:18,133 --> 00:26:19,133
the graph.

516
00:26:19,200 --> 00:26:22,799
That was the actual slide and
the actual data that was used by

517
00:26:22,866 --> 00:26:26,266
me to convince the head of
Internet Explorer at the time to

518
00:26:26,333 --> 00:26:28,266
pay for his own bugs.

519
00:26:28,333 --> 00:26:31,766
And what you're seeing there is,
in the white graph, that is the

520
00:26:31,833 --> 00:26:35,466
actual number of bugs we
received during the IE10

521
00:26:35,533 --> 00:26:36,733
beta period.

522
00:26:36,733 --> 00:26:40,500
The big old white spike is the
spike of submissions we got

523
00:26:40,566 --> 00:26:42,000
after the beta
period was closed.

524
00:26:42,066 --> 00:26:44,599
Now why would these friendly
hackers do this to us?

525
00:26:44,666 --> 00:26:47,099
It was kind of the worst
time ever to hear about it.

526
00:26:47,166 --> 00:26:49,099
Clearly, they were doing
research the whole time.

527
00:26:49,166 --> 00:26:53,033
But remember, at the time, there
were no bug bounties, and so the

528
00:26:53,099 --> 00:26:57,765
only thing they could get was a
hope at 12-point aerial font and

529
00:26:57,833 --> 00:26:59,933
their name in a bulletin. Right?

530
00:27:00,000 --> 00:27:01,466
That was credit.

531
00:27:01,533 --> 00:27:05,166
And so what I said was, look, we
could shape the traffic if we

532
00:27:05,233 --> 00:27:08,299
put a bug bounty at the
beginning of the IE11 beta

533
00:27:08,366 --> 00:27:11,666
period and we projected that we
would get the majority of the

534
00:27:11,733 --> 00:27:12,433
bugs at the beginning.

535
00:27:12,500 --> 00:27:14,866
That maximizes
success for everybody.

536
00:27:14,933 --> 00:27:18,900
You know, a little bit of money,
put their name up in lights on

537
00:27:18,966 --> 00:27:22,000
our webpage, get it fixed during
the beta period, hopefully

538
00:27:22,066 --> 00:27:25,500
identify other related
issues and fix those, too.

539
00:27:25,566 --> 00:27:27,066
I mean, it was pretty
much win, win, win.

540
00:27:27,133 --> 00:27:30,533
And then the customers would
have less to patch once the

541
00:27:30,599 --> 00:27:33,633
actual code was
released out of beta.

542
00:27:34,533 --> 00:27:37,565
We got 18 bulletin class
vulnerabilities for a total

543
00:27:37,633 --> 00:27:39,700
expenditure of about $28,000.

544
00:27:39,766 --> 00:27:42,200
It was a huge success.

545
00:27:42,266 --> 00:27:46,133
What you see on the right is
a giant check because James

546
00:27:46,200 --> 00:27:50,533
Forshaw, the recipient of the
very first $100,000 mitigation

547
00:27:50,599 --> 00:27:54,566
bypass bounty, had told me that
he envisioned me surprising him

548
00:27:54,633 --> 00:27:56,533
on stage at Blue Hat
with a giant check.

549
00:27:56,599 --> 00:27:59,832
We called it James and the giant
check, and we gave him a giant

550
00:27:59,900 --> 00:28:02,566
check on stage,
a novelty check which somehow

551
00:28:02,633 --> 00:28:03,666
disappeared afterwards.

552
00:28:03,733 --> 00:28:05,066
How do you lose one
of those things?

553
00:28:05,133 --> 00:28:07,900
But here is the thing.

554
00:28:07,966 --> 00:28:13,699
We all work for a complementary
set of motivations. Right?

555
00:28:13,766 --> 00:28:17,433
It is a blend of motivations,
compensation, recognition,

556
00:28:17,500 --> 00:28:19,166
pursuit of
intellectual happiness.

557
00:28:19,233 --> 00:28:23,832
The recognition part was
actually tied to compensation in

558
00:28:23,900 --> 00:28:25,299
a lot of cases. Right?

559
00:28:25,299 --> 00:28:28,633
>> CHRIS WYSOPAL: When we were
at AtStake and, you know, we're

560
00:28:28,700 --> 00:28:33,833
a small consulting company, I
had to convince our CEO that

561
00:28:33,900 --> 00:28:36,400
having a vulnerability
disclosure policy, continuing to

562
00:28:36,466 --> 00:28:40,599
do vulnerability research and
publish it, even publish it if

563
00:28:40,666 --> 00:28:44,733
the vendor didn't respond and
didn't fix it, you can imagine

564
00:28:44,799 --> 00:28:46,133
how those conversations went.

565
00:28:46,200 --> 00:28:49,299
He's like what is the benefit,
what is the benefit to AtStake

566
00:28:49,366 --> 00:28:50,433
to do this?

567
00:28:50,500 --> 00:28:54,066
I remember having conversations
with our CEO, and the thing that

568
00:28:54,133 --> 00:28:57,266
really kind of flipped him
over the side was the 12-point

569
00:28:57,333 --> 00:28:59,033
aerial font.

570
00:28:59,099 --> 00:29:03,433
I said, look, Microsoft and
their webpage is going to thank

571
00:29:03,500 --> 00:29:07,933
-- I'm going to say Veracode
again -- an AtStake researcher

572
00:29:08,000 --> 00:29:10,966
by name and it's going
to say from AtStake.

573
00:29:11,033 --> 00:29:14,299
They're going to recognize that
we're contributing to securing

574
00:29:14,366 --> 00:29:17,000
Microsoft's customer base.

575
00:29:17,066 --> 00:29:20,833
He said, okay, that makes sense.

576
00:29:20,900 --> 00:29:24,599
If they're going to give us that
recognition, then I think that

577
00:29:24,666 --> 00:29:25,933
it's acceptable that we do that.

578
00:29:27,666 --> 00:29:30,866
Without that little 12-point
font, we probably wouldn't have

579
00:29:30,933 --> 00:29:32,766
been able to even do the
vulnerability research and

580
00:29:32,833 --> 00:29:33,866
release it.

581
00:29:33,933 --> 00:29:36,233
>> KATIE MOUSSOURIS: It was
not just good for business.

582
00:29:36,299 --> 00:29:37,533
It was good for recruiting.

583
00:29:37,599 --> 00:29:40,700
It meant that if you came to
work with us, you could continue

584
00:29:40,766 --> 00:29:43,900
your research and get it
published and that we weren't

585
00:29:43,966 --> 00:29:47,632
all going to be just doing pen
testing under NDA and that you

586
00:29:47,700 --> 00:29:50,599
would never be able to develop
your career if you came to work

587
00:29:50,666 --> 00:29:51,299
with us.

588
00:29:51,366 --> 00:29:52,766
It was super important.

589
00:29:52,833 --> 00:29:57,166
Now, is going to talk about
another disclosure event that he

590
00:29:57,233 --> 00:30:00,133
had the privilege of
helping to coordinate.

591
00:30:01,366 --> 00:30:02,666
>> CHRIS WYSOPAL: Yeah.

592
00:30:02,733 --> 00:30:09,599
I was involved on the researcher
side of the Facebook bug bounty,

593
00:30:09,666 --> 00:30:12,466
and this time it was actually
with another woman and that

594
00:30:12,533 --> 00:30:15,199
woman happened
to be my daughter.

595
00:30:15,266 --> 00:30:18,700
My daughter was interning
at Veracode when she was

596
00:30:18,766 --> 00:30:19,933
in college.

597
00:30:20,000 --> 00:30:25,366
I think this was about five
years ago or six years ago.

598
00:30:25,433 --> 00:30:30,200
She said we have these
Hack-a-thons at Veracode twice a

599
00:30:30,266 --> 00:30:33,066
year where people would team up
together in groups and write

600
00:30:33,133 --> 00:30:35,866
some software, figure
something out, maybe do some

601
00:30:35,933 --> 00:30:36,900
security testing.

602
00:30:36,966 --> 00:30:40,366
She came to me and said,
Dad, let's do one together.

603
00:30:40,433 --> 00:30:42,133
I said that's a great idea.

604
00:30:42,200 --> 00:30:43,599
What do you want to do?

605
00:30:43,666 --> 00:30:45,466
She said let's
find a vulnerability in a

606
00:30:45,533 --> 00:30:47,765
popular website.

607
00:30:47,833 --> 00:30:51,299
I said, okay, that
sounds like fun.

608
00:30:51,366 --> 00:30:55,066
She was actually a political
science major, by the way.

609
00:30:55,133 --> 00:30:56,700
She wasn't an engineer.

610
00:30:56,766 --> 00:31:02,533
And so I said what website
do you know a lot about?

611
00:31:02,599 --> 00:31:04,799
What website do you know
how to use, you know the

612
00:31:04,866 --> 00:31:05,700
functionalities?

613
00:31:05,766 --> 00:31:09,366
She said I know a
lot about Facebook.

614
00:31:09,433 --> 00:31:13,400
I had these visions of teaching
her how to use a web proxy,

615
00:31:13,466 --> 00:31:17,666
showing her how to look at
JavaScript and all this.

616
00:31:17,733 --> 00:31:20,366
She just went off on her
own and did her own thing.

617
00:31:20,433 --> 00:31:21,433
Right?

618
00:31:21,500 --> 00:31:23,333
I didn't actually do --
I got busy and I didn't do

619
00:31:23,400 --> 00:31:24,700
any testing.

620
00:31:24,766 --> 00:31:28,733
She came up with the idea that
there was a recently implemented

621
00:31:28,799 --> 00:31:32,666
feature in Facebook where you
could block a user, then you

622
00:31:32,733 --> 00:31:34,066
wouldn't see that user anymore.

623
00:31:34,133 --> 00:31:35,433
They couldn't interact with you.

624
00:31:35,500 --> 00:31:36,366
They couldn't post.

625
00:31:36,433 --> 00:31:39,799
They couldn't see
anything you were doing.

626
00:31:39,866 --> 00:31:42,033
She said, well, let's see if
they implemented it in all the

627
00:31:42,099 --> 00:31:45,533
places that you would because
there's all kinds of little edge

628
00:31:45,599 --> 00:31:49,000
cases around user interaction.

629
00:31:49,066 --> 00:31:51,599
She's going through, looking
through all the places in

630
00:31:51,666 --> 00:31:56,832
Facebook where users interact,
and she finds out that after you

631
00:31:56,900 --> 00:32:00,866
block a user, they can still
send you a message through

632
00:32:00,933 --> 00:32:04,433
Facebook Messenger,
which seems kind of odd. Right?

633
00:32:04,500 --> 00:32:07,400
Like how could they miss that?

634
00:32:07,466 --> 00:32:11,832
We reported the bug to the bug
bounty program, and they came

635
00:32:11,900 --> 00:32:17,599
back and said, well, we did some
testing and we actually found

636
00:32:17,666 --> 00:32:20,866
that it takes 24 hours
for messages to start to

637
00:32:20,933 --> 00:32:22,666
get blocked.

638
00:32:22,733 --> 00:32:25,533
Because they eventually get
blocked, we don't see this as

639
00:32:25,599 --> 00:32:26,733
a bug.

640
00:32:26,799 --> 00:32:28,200
We're not going to
pay you a bounty.

641
00:32:28,266 --> 00:32:29,466
Have a nice day.

642
00:32:29,533 --> 00:32:31,166
>> KATIE MOUSSOURIS: Bye-bye.

643
00:32:31,233 --> 00:32:32,633
>> CHRIS WYSOPAL: I have a
little bit of experience with

644
00:32:32,700 --> 00:32:36,400
reporting bugs to big companies
and I said, you know what, I

645
00:32:36,466 --> 00:32:39,433
think what you should write back
is if you don't consider it a

646
00:32:39,500 --> 00:32:43,633
bug, then you have no problem
with us writing a blog post

647
00:32:43,700 --> 00:32:48,966
about what we did to find this
and the problem that's there.

648
00:32:49,033 --> 00:32:51,299
They came back the next day and
said, actually, we're going to

649
00:32:51,366 --> 00:32:53,366
fix it.

650
00:32:53,433 --> 00:32:55,000
We consider it a bug.

651
00:32:55,066 --> 00:32:59,266
My daughter got $1,100 bug
bounty out of it, which was

652
00:32:59,333 --> 00:33:00,433
pretty awesome.

653
00:33:02,599 --> 00:33:05,233
One of the things I learned by
doing this, and I have to give

654
00:33:05,299 --> 00:33:08,333
kudos to Facebook, not only for
actually fixing the bug, but

655
00:33:08,400 --> 00:33:12,366
they had set up a separate
instance of their software where

656
00:33:12,433 --> 00:33:16,799
security researchers could look
for problems without potentially

657
00:33:16,866 --> 00:33:21,566
impacting the live site and the
live -- and the privacy of other

658
00:33:21,633 --> 00:33:23,799
users because a lot of things
are going to be authorization

659
00:33:23,866 --> 00:33:24,766
problems. Right?

660
00:33:24,833 --> 00:33:26,833
Think of how complex the
authorization is in Facebook.

661
00:33:26,900 --> 00:33:27,733
I can't even imagine.

662
00:33:27,799 --> 00:33:31,599
But you could actually
get at private data.

663
00:33:31,666 --> 00:33:36,033
Their bug bounty program rules
say go ahead and interact with

664
00:33:36,099 --> 00:33:38,866
the test instance,
not the live instance.

665
00:33:38,933 --> 00:33:44,966
But Katie is going to tell us
why that is, why there is that

666
00:33:45,033 --> 00:33:45,765
second instance.

667
00:33:45,833 --> 00:33:47,099
How do they come
up with this idea?

668
00:33:47,166 --> 00:33:51,799
>> KATIE MOUSSOURIS: Well, you
know, back in 2013, a researcher

669
00:33:51,866 --> 00:33:55,633
had submitted a bug where you
could post on another user's

670
00:33:55,700 --> 00:34:01,166
page who didn't allow posting
from non-friends and basically

671
00:34:01,233 --> 00:34:03,265
tried to report it, but there
was a little bit of a language

672
00:34:03,333 --> 00:34:04,633
barrier issue.

673
00:34:04,700 --> 00:34:10,233
And so the triage team there at
the time at Facebook closed it

674
00:34:10,300 --> 00:34:13,366
and said, you know, sorry, come
back with more information or

675
00:34:13,433 --> 00:34:15,565
something that we can
kind of take action on.

676
00:34:15,632 --> 00:34:18,565
That was closed in error. Right?

677
00:34:18,632 --> 00:34:21,765
So the researchers said, well, I
didn't do a good enough job of

678
00:34:21,833 --> 00:34:22,833
explaining it.

679
00:34:22,900 --> 00:34:26,099
Let me just post on Mark
Zuckerberg's page to show.

680
00:34:26,166 --> 00:34:28,966
Right? That happened.

681
00:34:29,033 --> 00:34:31,533
And, of course, they said,
ah, yes, that is a bug.

682
00:34:31,599 --> 00:34:34,000
But because the terms of their
program -- and they did not yet

683
00:34:34,065 --> 00:34:36,799
have this separate test instance
-- the terms of their bug bounty

684
00:34:36,866 --> 00:34:40,632
program said we'll thank you,
but if you violate another

685
00:34:40,699 --> 00:34:43,866
user's privacy without their
permission, then we're not going

686
00:34:43,933 --> 00:34:46,166
to pay a bug bounty.

687
00:34:46,233 --> 00:34:51,400
The internet became outraged
and crowdfunded this guy.

688
00:34:51,466 --> 00:34:56,366
I think it ended up at
over $12,000 of a bounty.

689
00:34:56,433 --> 00:35:01,566
With that black eye of triage
implementation, Facebook decided

690
00:35:01,633 --> 00:35:04,732
that, you know what, they do
want the bugs, they do want to

691
00:35:04,800 --> 00:35:07,500
know about privacy violating
bugs, but they don't want to

692
00:35:07,566 --> 00:35:11,566
risk anyone Zucking it up again,
so they decided to make this

693
00:35:11,633 --> 00:35:13,732
other instance.

694
00:35:13,800 --> 00:35:16,666
Things really,
really improved that way.

695
00:35:16,733 --> 00:35:20,233
But a lot of organizations don't
have that massive capability to

696
00:35:20,300 --> 00:35:23,733
throw up another instance and
all of that and really model and

697
00:35:23,800 --> 00:35:25,666
keep in sync two versions.

698
00:35:25,733 --> 00:35:28,199
While that's a great idea,
sometimes it is harder

699
00:35:28,266 --> 00:35:28,966
to implement.

700
00:35:30,133 --> 00:35:33,566
Now, let's talk for a minute
about hard to implement bug

701
00:35:33,633 --> 00:35:34,566
bounty programs.

702
00:35:34,633 --> 00:35:38,066
How many of you have heard
of Hack the Pentagon? Okay.

703
00:35:38,133 --> 00:35:40,133
I hope some of you have
heard of Hack the Pentagon.

704
00:35:40,199 --> 00:35:47,000
When I was at Microsoft, you
know, I was giving talks about

705
00:35:47,066 --> 00:35:50,466
the thinking that went into the
creation of the Microsoft bug

706
00:35:50,533 --> 00:35:55,232
bounty programs, and one was a
guest lecture I got to do at MIT

707
00:35:55,300 --> 00:35:57,500
Sloan School, Harvard Kennedy
School, and sitting in that

708
00:35:57,566 --> 00:36:01,232
small room was my friend
Michael Sulmeyer, Sultan of

709
00:36:01,300 --> 00:36:02,433
Cyber on Twitter.

710
00:36:02,500 --> 00:36:04,800
Great Twitter handle.

711
00:36:04,866 --> 00:36:09,266
He actually was, at the time,
the Director of Cybersecurity

712
00:36:09,333 --> 00:36:11,933
Policy for the Office of
the Secretary of Defense.

713
00:36:12,000 --> 00:36:15,300
And so that was the first time
I was invited to the Pentagon.

714
00:36:15,366 --> 00:36:17,000
I was pretty excited.

715
00:36:17,066 --> 00:36:19,633
Over the years,
they had a lot of questions

716
00:36:19,699 --> 00:36:21,099
about implementation.

717
00:36:21,166 --> 00:36:23,666
How do you take a complex
organization that was having

718
00:36:23,733 --> 00:36:25,666
trouble keeping up with the
vulnerabilities they already

719
00:36:25,733 --> 00:36:29,366
knew about and experiment with
doing some of this interactive

720
00:36:29,433 --> 00:36:32,199
research coordinated vuln
disclosure with hackers?

721
00:36:32,266 --> 00:36:35,699
When they called me up right
before RSA, I think it was about

722
00:36:35,766 --> 00:36:39,966
four years ago, they said,
good news, we're ready to do a

723
00:36:40,033 --> 00:36:40,833
bug bounty.

724
00:36:40,900 --> 00:36:42,266
I said why are you
starting with a bug bounty?

725
00:36:42,333 --> 00:36:44,199
I just told you you need to
start with vuln disclosure.

726
00:36:44,266 --> 00:36:46,300
They said, well, you know, we
think it's going to be a really

727
00:36:46,366 --> 00:36:49,800
nice way to show off the new
digital defense service and

728
00:36:49,866 --> 00:36:53,433
we're being more agile in
adopting outside technologies

729
00:36:53,500 --> 00:36:54,800
and best practices.

730
00:36:54,866 --> 00:36:56,666
There we had it.

731
00:36:56,733 --> 00:36:58,633
Hack the Pentagon.

732
00:36:58,699 --> 00:37:04,166
We launched it in April of
2016, and, my goodness, have

733
00:37:04,233 --> 00:37:05,366
things changed.

734
00:37:05,433 --> 00:37:07,233
So I'm going to call your
attention to a little bit of

735
00:37:07,300 --> 00:37:08,800
data here.

736
00:37:08,866 --> 00:37:11,866
One, when we launched it, you
know, they were cautious, and

737
00:37:11,933 --> 00:37:14,466
they wanted people to
preregister and they had to be

738
00:37:14,533 --> 00:37:16,533
U.S. taxpaying persons.

739
00:37:16,599 --> 00:37:19,633
They could be U.S. citizens or
somebody authorized to receive

740
00:37:19,699 --> 00:37:21,333
money in the United States.

741
00:37:21,400 --> 00:37:24,133
You had to preregister if you
were interested and give your

742
00:37:24,199 --> 00:37:25,066
Social Security Number.

743
00:37:25,133 --> 00:37:28,000
You can imagine, there
was a lot of paranoia.

744
00:37:28,066 --> 00:37:30,500
But what was funny about it was
a lot of the hackers were like

745
00:37:30,566 --> 00:37:32,366
I'm not going to
give the government my Social

746
00:37:32,433 --> 00:37:33,333
Security Number.

747
00:37:33,400 --> 00:37:37,366
I'm like, psst, hey, they
gave you that number.

748
00:37:37,433 --> 00:37:39,066
It's like but they
don't know my real name.

749
00:37:39,133 --> 00:37:42,000
I went, no, that's not
how that number works.

750
00:37:42,066 --> 00:37:44,299
Anyway.

751
00:37:44,366 --> 00:37:45,533
But they don't
know I'm a hacker.

752
00:37:45,599 --> 00:37:47,466
You're tweeting
about it right now.

753
00:37:47,533 --> 00:37:51,333
Luckily, after sending out a
few tinfoil hats and reminding

754
00:37:51,400 --> 00:37:55,900
hackers that, hey, at least
you're good at hacking, an

755
00:37:55,966 --> 00:37:58,598
overwhelming number of
hackers preregistered.

756
00:37:58,666 --> 00:37:59,733
We were hoping
for a few hundred.

757
00:37:59,800 --> 00:38:01,400
We got over 1,400.

758
00:38:01,466 --> 00:38:04,665
But look at the cruelty that
we imposed upon ourselves.

759
00:38:04,733 --> 00:38:07,666
Number one, never start a bug
bounty program at midnight.

760
00:38:07,733 --> 00:38:11,033
Do not do because we received
the first vulnerability report

761
00:38:11,099 --> 00:38:13,599
at 13 minutes past the hour.

762
00:38:13,666 --> 00:38:18,099
Also, that number of researchers
and that target that hadn't

763
00:38:18,166 --> 00:38:21,099
really been hit by outsiders
before, there were a lot of

764
00:38:21,166 --> 00:38:22,233
duplicate reports.

765
00:38:22,300 --> 00:38:23,566
Look at the signal to noise.

766
00:38:23,633 --> 00:38:25,665
Not so good.

767
00:38:25,733 --> 00:38:28,099
The number of reports
received versus valid bugs,

768
00:38:28,166 --> 00:38:29,366
not a great number.

769
00:38:29,433 --> 00:38:31,833
What did we do in the second
instance, which was Hack

770
00:38:31,900 --> 00:38:33,099
the Army?

771
00:38:33,166 --> 00:38:35,800
One, we didn't just
launch Hack the Army alone.

772
00:38:35,866 --> 00:38:39,366
We also launched it at the same
time as what I told them to do

773
00:38:39,433 --> 00:38:42,300
in the first place, which is the
vulnerability disclosure program

774
00:38:42,366 --> 00:38:43,800
for all of DoD.

775
00:38:43,866 --> 00:38:46,466
And so those launched
in November of 2016.

776
00:38:46,533 --> 00:38:48,098
And you notice the numbers.

777
00:38:48,166 --> 00:38:49,699
The signal to noise
is a lot better.

778
00:38:49,766 --> 00:38:51,699
We also started it at noon.

779
00:38:51,766 --> 00:38:53,099
Civilized.

780
00:38:53,166 --> 00:38:56,666
But we capped the number of
researchers, and that was

781
00:38:56,733 --> 00:39:00,366
basically just to manage the
influx of traffic to not make

782
00:39:00,433 --> 00:39:05,400
the DoD triage team's job as bad
as whale feces researcher or

783
00:39:05,466 --> 00:39:08,066
et cetera.

784
00:39:08,133 --> 00:39:11,598
It couldn't have continued,
really, without the ongoing

785
00:39:11,666 --> 00:39:14,533
coordinated vulnerability
disclosure program because

786
00:39:14,599 --> 00:39:17,933
people were excited that they
were finally able to, if they

787
00:39:18,000 --> 00:39:20,500
see something, say something to
the United States government.

788
00:39:20,566 --> 00:39:23,633
It was previously illegal, and
they would have definitely been

789
00:39:23,699 --> 00:39:27,766
considered for prosecution,
if not actually prosecuted.

790
00:39:30,000 --> 00:39:33,000
What do researchers expect?

791
00:39:33,066 --> 00:39:35,765
>> CHRIS WYSOPAL: Now we'll
talk a little bit about bug

792
00:39:35,833 --> 00:39:37,133
bounty programs.

793
00:39:37,199 --> 00:39:39,300
I want to remind everyone
that there is still a lot of

794
00:39:39,366 --> 00:39:41,500
coordinated vulnerability
disclosure that's going on

795
00:39:41,566 --> 00:39:44,000
that's not part of a
bug bounty program.

796
00:39:44,066 --> 00:39:45,265
Back to some data here.

797
00:39:45,333 --> 00:39:47,833
What are researcher
expectations?

798
00:39:47,900 --> 00:39:51,533
If you look down there towards
the bottom, I expect payment for

799
00:39:51,599 --> 00:39:56,833
my services is only 18% of
researchers responded with

800
00:39:56,900 --> 00:39:58,166
that data.

801
00:39:58,233 --> 00:40:01,099
If you look at the top, the
things that they said were

802
00:40:01,166 --> 00:40:04,699
checked off as their
expectations, they're all around

803
00:40:04,766 --> 00:40:06,733
making sure that bug gets fixed.

804
00:40:06,800 --> 00:40:08,533
That's really the
motivation here.

805
00:40:08,599 --> 00:40:11,133
They expect to be
told when it's fixed.

806
00:40:11,199 --> 00:40:14,833
They expect regular updates
on the correction of the

807
00:40:14,900 --> 00:40:15,900
vulnerabilities.

808
00:40:15,966 --> 00:40:17,433
They kind of want to know are
you working on it or are you

809
00:40:17,500 --> 00:40:19,099
just blowing me off?

810
00:40:19,166 --> 00:40:22,300
They expect the timeframe,
right, that's not -- they don't

811
00:40:22,366 --> 00:40:23,666
want it to take forever.

812
00:40:23,733 --> 00:40:26,533
They expect it to be -- they
found the flaw; they want you to

813
00:40:26,599 --> 00:40:28,199
fix it and protect your users.

814
00:40:28,266 --> 00:40:32,866
This one was surprising, 37%
said I want to be able to

815
00:40:32,933 --> 00:40:34,000
validate the fix.

816
00:40:34,066 --> 00:40:36,698
I thought that was quite
interesting that there was an

817
00:40:36,766 --> 00:40:39,633
expectation that they would be
given an opportunity to validate

818
00:40:39,699 --> 00:40:40,300
the fix.

819
00:40:40,366 --> 00:40:42,566
Over a third said that.

820
00:40:42,633 --> 00:40:46,165
And then the other thing that
was actually surprising, it's

821
00:40:46,233 --> 00:40:50,466
down there at 16% towards the
bottom, is I expect recognition.

822
00:40:50,533 --> 00:40:54,533
There wasn't really a lot of
researchers who even wanted the

823
00:40:54,599 --> 00:40:58,033
recognition, but they all
expected it to be fixed in a

824
00:40:58,099 --> 00:41:01,233
timely way and to be told and
updated about the process.

825
00:41:01,933 --> 00:41:03,000
>> KATIE MOUSSOURIS: Right.

826
00:41:03,066 --> 00:41:05,966
The most attractive incentives,
it turns out, is having a

827
00:41:06,033 --> 00:41:10,033
friendly open front door, not
threatening legal action, and

828
00:41:10,099 --> 00:41:11,966
actually fixing the bug.

829
00:41:12,033 --> 00:41:13,633
Amazing. Human nature.

830
00:41:13,699 --> 00:41:14,766
>> CHRIS WYSOPAL: Shocking.

831
00:41:14,833 --> 00:41:16,199
>> KATIE MOUSSOURIS:
Who would have thought?

832
00:41:16,266 --> 00:41:19,633
So 47% of the participants
had actually worked with bug

833
00:41:19,699 --> 00:41:23,666
bounties, and that's either on
the receiving end or on perhaps

834
00:41:23,733 --> 00:41:27,866
having to implement a fix or
actually participating in

835
00:41:27,933 --> 00:41:29,800
hacking and bug
bounties themselves.

836
00:41:29,866 --> 00:41:32,966
While the majority in the survey
thought, yes, this is a useful

837
00:41:33,033 --> 00:41:35,266
way to leverage, you know,
security research and

838
00:41:35,333 --> 00:41:40,099
everything, which is great, over
a third of them didn't have such

839
00:41:40,166 --> 00:41:41,500
a rosy experience.

840
00:41:41,566 --> 00:41:47,098
That 26% tried it, didn't like
it, didn't meet expectations.

841
00:41:47,166 --> 00:41:48,266
Right?

842
00:41:48,333 --> 00:41:50,233
And that could be on either side
of the equation because of the

843
00:41:50,300 --> 00:41:52,966
breadth of the
security respondents.

844
00:41:53,033 --> 00:41:56,133
And 7% really just thought
it was a PR exercise.

845
00:41:56,199 --> 00:41:58,966
That's the one that I
call bug bounty Botox.

846
00:41:59,033 --> 00:42:02,066
If you haven't done any of your
homework internally and you're

847
00:42:02,133 --> 00:42:04,765
just looking to slap a bug
bounty out there to say that we

848
00:42:04,833 --> 00:42:07,300
take your security very
seriously, but you're not

849
00:42:07,366 --> 00:42:09,766
actually planning to fix it,
well, you're not pretty on

850
00:42:09,833 --> 00:42:10,566
the inside.

851
00:42:10,633 --> 00:42:12,066
It is bug bounty Botox.

852
00:42:13,800 --> 00:42:16,599
Knowing about bugs, it turns
out, is like 1/1,000th of

853
00:42:16,666 --> 00:42:17,699
the battle.

854
00:42:17,766 --> 00:42:21,400
Nearly half of the organizations
had implemented these bug bounty

855
00:42:21,466 --> 00:42:25,333
programs or implemented a bug
bounty, but only 19% of the

856
00:42:25,400 --> 00:42:28,099
reports came from an
actual bug bounty program, a

857
00:42:28,166 --> 00:42:29,699
managed program.

858
00:42:29,766 --> 00:42:32,300
What's interesting here, in
terms of the equation, is in

859
00:42:32,366 --> 00:42:35,766
open source, who is responsible
for fixing the vulnerabilities?

860
00:42:35,833 --> 00:42:37,166
Well, it is the maintainers.

861
00:42:37,233 --> 00:42:41,033
And in the survey, 63% of open
source vulnerabilities reported

862
00:42:41,099 --> 00:42:42,733
are not being fixed. Why?

863
00:42:42,800 --> 00:42:44,866
Because a lot of the
maintainers are overwhelmed.

864
00:42:44,933 --> 00:42:48,433
There might be one person
working on an incredibly popular

865
00:42:48,500 --> 00:42:52,166
package that got really popular
and had a vulnerability.

866
00:42:52,233 --> 00:42:54,900
Open SSL was in that
category for a long time

867
00:42:54,966 --> 00:42:56,266
before Heartbleed.

868
00:42:56,333 --> 00:42:59,500
But resources still aren't
being poured into that half of

869
00:42:59,566 --> 00:43:00,665
the equation.

870
00:43:00,733 --> 00:43:03,699
The European Commission said,
good news, everyone, we've

871
00:43:03,766 --> 00:43:06,666
decided to sponsor bug bounties
against the most commonly open

872
00:43:06,733 --> 00:43:09,599
source deployed across
the European government.

873
00:43:09,666 --> 00:43:11,233
They didn't even
tell the maintainers.

874
00:43:11,300 --> 00:43:15,199
I contacted the Apache server
core guys and was like, hey, the

875
00:43:15,266 --> 00:43:18,333
three of you who were paid to do
this, did you know about this,

876
00:43:18,400 --> 00:43:20,466
and they said, oh, no,
thanks for the heads up.

877
00:43:20,533 --> 00:43:22,066
>> CHRIS WYSOPAL: If they're
going to turn on the fire hose,

878
00:43:22,133 --> 00:43:24,098
you might want to
get ready for it.

879
00:43:24,099 --> 00:43:25,366
>> KATIE MOUSSOURIS: Yeah.
Someone painting a bounty

880
00:43:25,433 --> 00:43:27,433
bullseye on your back.
And, well, anyway.

881
00:43:27,500 --> 00:43:31,300
I just said why aren't we
actually pouring money into the

882
00:43:31,366 --> 00:43:34,666
folks who have to fix it and
ideally prevent vulnerabilities

883
00:43:34,733 --> 00:43:35,766
in the future.

884
00:43:35,833 --> 00:43:39,900
Unbalancing the equation here is
a little bit of a problem with

885
00:43:39,966 --> 00:43:43,400
this bug bounty fever that we
have all been getting into in

886
00:43:43,466 --> 00:43:44,732
the last few years.

887
00:43:47,533 --> 00:43:49,699
>> CHRIS WYSOPAL: We have talked
about some horror stories and

888
00:43:49,766 --> 00:43:52,699
some problems, but, in general,
if you look at the survey

889
00:43:52,766 --> 00:43:56,133
results, we have
come a long way.

890
00:43:56,199 --> 00:43:59,933
Things are actually in really,
really good shape than they were

891
00:44:00,000 --> 00:44:02,199
10 years, 15, 20 years ago.

892
00:44:06,000 --> 00:44:09,199
And so I wanted to show up with
some final data from the survey

893
00:44:09,266 --> 00:44:13,300
which gives us a
good positive picture.

894
00:44:13,366 --> 00:44:15,099
We found out -- and I was
actually surprised how good

895
00:44:15,166 --> 00:44:16,033
it was.

896
00:44:16,099 --> 00:44:19,533
It was three out of four
organizations had actually an

897
00:44:19,599 --> 00:44:21,099
established CVD.

898
00:44:21,166 --> 00:44:22,199
They had something.

899
00:44:22,266 --> 00:44:25,866
They had -- they had an
address and said please send

900
00:44:25,933 --> 00:44:28,866
vulnerability reports to us.

901
00:44:28,933 --> 00:44:33,466
It was a small bar to reach, but
the fact that three out of four

902
00:44:33,533 --> 00:44:36,266
organizations had done
that is really good news.

903
00:44:36,933 --> 00:44:42,433
The other good news is for those
in the survey who dealt with an

904
00:44:42,500 --> 00:44:48,233
unsolicited vulnerability
disclosure report, 90% said it

905
00:44:48,300 --> 00:44:50,666
was handled in a
coordinated fashion.

906
00:44:50,733 --> 00:44:51,666
>> KATIE MOUSSOURIS: Yeah!

907
00:44:51,733 --> 00:44:53,066
>> CHRIS WYSOPAL:
Ninety percent. That's great.

908
00:44:53,133 --> 00:44:57,066
That's even more happening in a
coordinated fashion than people

909
00:44:57,133 --> 00:45:00,366
who have an established method
for receiving vulnerabilities.

910
00:45:00,433 --> 00:45:04,333
That means that the researchers
were schooling the organization

911
00:45:04,400 --> 00:45:07,099
and saying this is how you
do coordinated vulnerability

912
00:45:07,166 --> 00:45:09,966
disclosure, even when the
organization didn't have that.

913
00:45:10,033 --> 00:45:14,232
That's a little bit different
than it was 22 years ago when we

914
00:45:14,300 --> 00:45:18,166
were dealing with Microsoft, so
I see this as a huge success.

915
00:45:18,233 --> 00:45:20,733
It only took 22 years
to get to where we are.

916
00:45:20,800 --> 00:45:21,966
Things move slowly.

917
00:45:23,633 --> 00:45:26,765
Finally, one last point I
wanted to make here is there is

918
00:45:26,833 --> 00:45:29,833
actually a lot of unsolicited
vulnerability disclosure

919
00:45:29,900 --> 00:45:31,000
going on.

920
00:45:31,066 --> 00:45:33,966
If you don't even have a
bug bounty program, 37% of

921
00:45:34,033 --> 00:45:37,232
organizations said they received
something in the last 12 months.

922
00:45:37,300 --> 00:45:42,366
That should tell you that if you
don't have a way of receiving

923
00:45:42,433 --> 00:45:46,366
vulnerabilities from
researchers, that you should put

924
00:45:46,433 --> 00:45:47,433
one in place.

925
00:45:47,500 --> 00:45:49,666
That's going to be one
of my recommendations.

926
00:45:52,199 --> 00:45:54,166
>> KATIE MOUSSOURIS: It is a
22-year overnight success.

927
00:45:54,233 --> 00:45:55,066
Right?

928
00:45:55,133 --> 00:45:56,133
>> CHRIS WYSOPAL: Exactly.

929
00:45:56,199 --> 00:45:57,166
>> KATIE MOUSSOURIS:
It's totally working.

930
00:45:57,233 --> 00:45:58,400
>> CHRIS WYSOPAL: Exactly.
We did it, Katie.

931
00:45:58,466 --> 00:46:00,033
>> KATIE MOUSSOURIS: Yeah.

932
00:46:00,099 --> 00:46:01,666
>> CHRIS WYSOPAL: I just
want to give some takeaways.

933
00:46:01,733 --> 00:46:02,800
We gave you a lot of data.

934
00:46:02,866 --> 00:46:04,599
We talked about
some war stories.

935
00:46:04,666 --> 00:46:07,400
What are our recommendations
from what we've learned over

936
00:46:07,466 --> 00:46:08,598
the years?

937
00:46:08,666 --> 00:46:11,533
The number one thing that you
can do really easily next week

938
00:46:11,599 --> 00:46:14,599
when you get back to your
organization is find out if you

939
00:46:14,666 --> 00:46:16,166
have a contact address.

940
00:46:16,233 --> 00:46:18,800
Does your organization -- is
your organization able to

941
00:46:18,866 --> 00:46:23,766
receive a vulnerability from the
outside world and do something

942
00:46:23,833 --> 00:46:24,900
with it?

943
00:46:24,966 --> 00:46:26,433
>> KATIE MOUSSOURIS: But
remember, you can't just put up

944
00:46:26,500 --> 00:46:29,333
a contact address and a
scope page and call it good.

945
00:46:29,400 --> 00:46:31,766
That's like saying, you know,
my grandmother makes the

946
00:46:31,833 --> 00:46:32,833
best lasagna.

947
00:46:32,900 --> 00:46:35,833
I'm going to invite everyone
in the world over for dinner.

948
00:46:35,900 --> 00:46:38,433
She's going to get a little
backed up in the kitchen.

949
00:46:38,500 --> 00:46:41,766
So making sure that you have a
process internally to handle

950
00:46:41,833 --> 00:46:45,033
unsolicited bug reports, this
is different from your regular

951
00:46:45,099 --> 00:46:49,099
vulnerability management process
or your pen test vulnerability

952
00:46:49,166 --> 00:46:52,633
addressing process that you can
address at your own leisure.

953
00:46:52,699 --> 00:46:54,566
This is very different.

954
00:46:54,633 --> 00:46:57,433
Making sure that you have that
digestive system of bugs ensures

955
00:46:57,500 --> 00:47:01,566
that you will not go to the bug
buffet and get bug indigestion.

956
00:47:02,233 --> 00:47:04,033
>> CHRIS WYSOPAL: And then
finally, and this will take some

957
00:47:04,099 --> 00:47:07,133
time, we highly, highly
recommend doing your own

958
00:47:07,199 --> 00:47:11,199
security testing as part of your
development lifecycle before you

959
00:47:11,266 --> 00:47:15,033
release it, either using
automation or manual testing, so

960
00:47:15,099 --> 00:47:18,300
that you can actually find and
fix these bugs in a much cheaper

961
00:47:18,366 --> 00:47:21,766
way than waiting for an external
researcher to find them.

962
00:47:21,833 --> 00:47:25,533
We still think CVDs are a great
idea and bug bounties could be

963
00:47:25,599 --> 00:47:26,599
appropriate.

964
00:47:26,666 --> 00:47:29,466
But without actually trying to
fix the stuff yourself, it is

965
00:47:29,533 --> 00:47:31,133
just going to be a
more expensive and more

966
00:47:31,199 --> 00:47:32,766
time-consuming process.

967
00:47:33,966 --> 00:47:34,866
>> KATIE MOUSSOURIS: Well,
we have shared a lot with

968
00:47:34,933 --> 00:47:36,099
you today.

969
00:47:36,166 --> 00:47:38,533
We are so grateful
that you joined us.

970
00:47:38,599 --> 00:47:42,233
And I believe that we'll have
some resources and links in the

971
00:47:42,300 --> 00:47:44,566
final versions of the
slide that are posted.

972
00:47:44,633 --> 00:47:48,533
Right now, we have got actually
room for a couple of questions.

973
00:47:48,599 --> 00:47:51,699
There are two microphones as
I flight attendant you in.

974
00:47:51,766 --> 00:47:53,066
There are two
microphones on either side.

975
00:47:53,133 --> 00:47:55,265
If you have questions,
please come to the mics.

976
00:47:55,333 --> 00:48:00,199
But otherwise, coordinated vuln
disclosure as driven by hackers

977
00:48:00,266 --> 00:48:03,766
who then became C-level
executives, hopefully we have

978
00:48:03,833 --> 00:48:06,466
done a little bit to help the
world become a better place.

979
00:48:06,533 --> 00:48:09,333
We have come a long way,
baby, but we need your help.

980
00:48:09,400 --> 00:48:10,233
Thank you.

981
00:48:10,300 --> 00:48:11,533
>> CHRIS WYSOPAL:
Thanks so much.

982
00:48:26,133 --> 00:48:28,098
>> KATIE MOUSSOURIS: Out in the
audience, Steve, Christy, please

983
00:48:28,166 --> 00:48:29,166
raise your hand.

984
00:48:29,233 --> 00:48:30,866
This wonderful
person right here.

985
00:48:30,933 --> 00:48:34,333
Inventor CVE and co-conspirator.

986
00:48:34,400 --> 00:48:37,066
We can't remember how long we've
known each other, but dear

987
00:48:37,133 --> 00:48:39,265
friend and ally of
coordinated vuln disclosure.

988
00:48:39,333 --> 00:48:40,599
Please, your question.

989
00:48:40,666 --> 00:48:41,599
>> BEN SPEAER: Hi. Thanks.

990
00:48:41,666 --> 00:48:42,766
My name is Ben Spear.

991
00:48:42,833 --> 00:48:44,599
I'm the director of the
Elections Infrastructure ISAC

992
00:48:44,666 --> 00:48:47,433
that's been established to help
protect the election offices,

993
00:48:47,500 --> 00:48:50,466
and we're looking at
establishing a CBD and things

994
00:48:50,533 --> 00:48:51,732
like that.

995
00:48:51,800 --> 00:48:54,033
I'm sure you guys have seen the
ongoing discussion about the

996
00:48:54,099 --> 00:48:56,333
recent Blockchain voting
app and the vulnerability

997
00:48:56,400 --> 00:48:57,633
disclosure there.

998
00:48:57,699 --> 00:49:00,933
One of the arguments that they
had made as to why they went

999
00:49:01,000 --> 00:49:04,599
forth the way they did was
because they felt that the

1000
00:49:04,666 --> 00:49:08,633
vendor had previously had
a negative response to

1001
00:49:08,699 --> 00:49:11,733
vulnerability disclosure and
that they didn't use the bug

1002
00:49:11,800 --> 00:49:15,633
bounty program because they
didn't feel that they could do

1003
00:49:15,699 --> 00:49:18,166
the work that they needed to do
to address the vulnerabilities

1004
00:49:18,233 --> 00:49:19,900
they were concerned about within
the constraints that were

1005
00:49:19,966 --> 00:49:21,232
provided by that.

1006
00:49:21,300 --> 00:49:24,866
And so I was wondering your
thoughts on that and how that

1007
00:49:24,933 --> 00:49:30,199
can be addressed or how the
researchers should behave in

1008
00:49:30,266 --> 00:49:31,366
that sort of context.

1009
00:49:31,433 --> 00:49:34,033
>> KATIE MOUSSOURIS: Well, you
know, I have opinions about

1010
00:49:34,099 --> 00:49:35,199
this. Yeah.

1011
00:49:35,266 --> 00:49:38,900
I think that it is interesting
because the commercialization of

1012
00:49:38,966 --> 00:49:42,366
bug bounties and coordinated
vuln disclosure platforms we all

1013
00:49:42,433 --> 00:49:43,933
thought was a great idea. Right?

1014
00:49:44,000 --> 00:49:48,266
Facilitate this process and
reduce friction between the

1015
00:49:48,333 --> 00:49:51,133
researcher and the
organization receiving.

1016
00:49:51,199 --> 00:49:54,566
But, unfortunately, because
they have a business model and

1017
00:49:54,633 --> 00:49:57,966
they're kind of selling control,
they have these sort of

1018
00:49:58,033 --> 00:49:59,900
nondisclosure terms.

1019
00:49:59,966 --> 00:50:03,732
Jonathan who found the Zoom bug
last year encountered this on

1020
00:50:03,800 --> 00:50:05,533
all the major bug
bounty platforms.

1021
00:50:05,599 --> 00:50:08,166
He said, look, I just want
to see the bug fixed within

1022
00:50:08,233 --> 00:50:09,166
90 days.

1023
00:50:09,233 --> 00:50:10,333
It's important to me.

1024
00:50:10,400 --> 00:50:12,133
I don't even need the bounty.

1025
00:50:12,199 --> 00:50:15,433
And I don't want to have to go
through your platform to be able

1026
00:50:15,500 --> 00:50:16,566
to do it.

1027
00:50:16,633 --> 00:50:20,332
I will, but I keep getting these
nasty grams from the platform

1028
00:50:20,400 --> 00:50:23,199
manager saying, yeah, but you
can't disclose unless they give

1029
00:50:23,266 --> 00:50:25,433
permission or we'll kick
you off the platform.

1030
00:50:25,500 --> 00:50:28,366
So, unfortunately, the
commercialization pressures of

1031
00:50:28,433 --> 00:50:32,199
the bug bounty programs are now
driving friction and wedges

1032
00:50:32,266 --> 00:50:34,933
between security researchers and
the organizations that they're

1033
00:50:35,000 --> 00:50:36,866
supposed to be trying to get to.

1034
00:50:36,933 --> 00:50:38,099
We don't need any of that.

1035
00:50:38,166 --> 00:50:40,000
We don't need to
regress on this timeline.

1036
00:50:40,066 --> 00:50:42,133
Yes, I have strong
opinions about this.

1037
00:50:42,199 --> 00:50:44,966
This is why I think that bug
bounty should not actually come

1038
00:50:45,033 --> 00:50:46,266
with non-disclosure.

1039
00:50:46,333 --> 00:50:49,699
And, in fact, Microsoft's
original bug bounties had no

1040
00:50:49,766 --> 00:50:54,066
non-disclosure agreement,
meaning we were paying $100,000

1041
00:50:54,133 --> 00:50:56,633
on a wink and a handshake.

1042
00:50:56,699 --> 00:50:58,333
Do you have anything
else to add to that one?

1043
00:50:58,400 --> 00:50:59,433
>> CHRIS WYSOPAL: No.

1044
00:50:59,500 --> 00:51:01,466
I think sometimes you have to go
outside of a bug bounty program

1045
00:51:01,533 --> 00:51:05,133
because of restrictions.

1046
00:51:05,199 --> 00:51:09,233
That's just going to be part of
the decision-making process that

1047
00:51:09,300 --> 00:51:12,266
the researcher is going
to have to do sometimes.

1048
00:51:12,333 --> 00:51:15,333
I don't know the exact details
of that case, but there are

1049
00:51:15,400 --> 00:51:19,300
definitely going to be times
when you're going to have to

1050
00:51:19,366 --> 00:51:22,066
release or you're not going to
be able to follow the rules

1051
00:51:22,133 --> 00:51:22,799
of engagement.

1052
00:51:23,666 --> 00:51:25,000
>> KATIE MOUSSOURIS:
Unfortunately, that's all the

1053
00:51:25,066 --> 00:51:26,033
time we have.

1054
00:51:26,099 --> 00:51:28,366
We'll take your question when
we see you some other time.

1055
00:51:28,433 --> 00:51:29,866
Thank you all so much.

1056
00:51:29,933 --> 00:51:31,900
Enjoy the last day of RSA.

