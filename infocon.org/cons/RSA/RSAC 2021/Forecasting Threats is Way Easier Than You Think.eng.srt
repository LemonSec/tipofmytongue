1
00:00:01,300 --> 00:00:03,960
- Hi, I'm Chris Cronin
from HALOCK Security Labs.

2
00:00:03,960 --> 00:00:04,890
Today I'm gonna be talking

3
00:00:04,890 --> 00:00:07,770
to you about forecasting threats.

4
00:00:07,770 --> 00:00:09,629
It's way easier than you think.

5
00:00:09,630 --> 00:00:12,570
This is a topic that has
some controversy behind it,

6
00:00:12,570 --> 00:00:15,810
some organizations and some
people say that we really need

7
00:00:15,810 --> 00:00:18,450
to evaluate the likelihood of threats

8
00:00:18,450 --> 00:00:20,780
using classic probability modeling

9
00:00:20,780 --> 00:00:22,660
and some say there's no
use in doing it at all.

10
00:00:22,660 --> 00:00:24,400
I'm gonna show you
today that it's actually

11
00:00:24,400 --> 00:00:26,808
fairly easy to think about likelihood

12
00:00:26,808 --> 00:00:29,880
once we have access to some public data.

13
00:00:29,880 --> 00:00:32,040
So let's jump right into it.

14
00:00:32,040 --> 00:00:34,320
What we're using as a premise here

15
00:00:34,320 --> 00:00:38,200
is that we're predicting not
so we can know the future

16
00:00:38,200 --> 00:00:40,210
but so that we can change it.

17
00:00:40,210 --> 00:00:41,850
That's the idea of what we're going for.

18
00:00:41,850 --> 00:00:44,270
So let's forecast your threats

19
00:00:44,270 --> 00:00:46,843
so that you can change your
future to the one you want.

20
00:00:48,060 --> 00:00:48,958
Knowing your future threats

21
00:00:48,958 --> 00:00:52,530
means securing your
likeliest threat factors.

22
00:00:52,530 --> 00:00:54,470
It means prioritizing
the likeliest threats

23
00:00:54,470 --> 00:00:57,157
that create the most harm
and then spending no more

24
00:00:57,157 --> 00:00:59,940
than you need to secure your organization

25
00:00:59,940 --> 00:01:03,320
which is exactly the
definition for risk management.

26
00:01:03,320 --> 00:01:07,090
So let's come to a common
agreement on what we mean by risk.

27
00:01:07,090 --> 00:01:08,870
So however you evaluate risk

28
00:01:08,870 --> 00:01:10,890
and there are many
different ways to do that.

29
00:01:10,890 --> 00:01:12,580
There are at least two components,

30
00:01:12,580 --> 00:01:13,899
there's some aspect of likelihood

31
00:01:13,900 --> 00:01:15,493
and some aspect of impact.

32
00:01:16,360 --> 00:01:18,640
Risk management means we're reducing risk

33
00:01:18,640 --> 00:01:21,410
by reducing either likelihood or impact.

34
00:01:21,410 --> 00:01:24,381
Today we're focusing
primarily on likelihood.

35
00:01:24,382 --> 00:01:28,060
Now I'm most known for focusing on impact.

36
00:01:28,060 --> 00:01:30,680
I invented the Duty of
Care Risk Analysis method,

37
00:01:30,680 --> 00:01:34,240
DoCRA standard and wrote CIS RAMs,

38
00:01:34,240 --> 00:01:38,360
CIS risk assessment method,
which both use this way

39
00:01:38,360 --> 00:01:41,130
of looking at impacts not just to you

40
00:01:41,130 --> 00:01:42,613
but to others who might be harmed,

41
00:01:42,613 --> 00:01:45,850
to be sure that any security
controls you're having

42
00:01:45,850 --> 00:01:49,020
in place create a burden that's
in balance with the risk.

43
00:01:49,020 --> 00:01:51,300
That's what regulators
and litigators look for.

44
00:01:51,300 --> 00:01:54,009
So we focus a lot on impact but people ask

45
00:01:54,010 --> 00:01:55,340
what do you do for likelihood?

46
00:01:55,340 --> 00:01:58,060
So that's what we're focusing on today.

47
00:01:58,060 --> 00:02:01,270
Keep in mind too, that the
CIS risk assessment method

48
00:02:01,270 --> 00:02:03,940
it's got version 2.0 coming
out in a couple of months,

49
00:02:03,940 --> 00:02:07,200
we're estimating June, keep your eye on,

50
00:02:07,200 --> 00:02:09,830
the work we're doing
here in this presentation

51
00:02:10,770 --> 00:02:12,960
putting data together
and using it to automate

52
00:02:12,960 --> 00:02:16,400
the way we calculate
likelihood will be packaged

53
00:02:16,400 --> 00:02:19,090
in this CIS RAM tool for free.

54
00:02:19,090 --> 00:02:20,910
Now CIS RAM tool that I was starting

55
00:02:20,910 --> 00:02:23,890
with an implementation
group one usage so it's

56
00:02:23,890 --> 00:02:26,390
organizations that don't
have a lot of resources.

57
00:02:26,390 --> 00:02:28,970
It's a very simplified risk analysis

58
00:02:28,970 --> 00:02:30,530
but you'll be able to see exactly

59
00:02:30,530 --> 00:02:33,350
how what we're doing here, the
mechanics of it and the data

60
00:02:33,350 --> 00:02:35,980
behind it actually works
inside a risk analysis.

61
00:02:35,980 --> 00:02:39,880
So keep your eye out for
CIS RAM 2.0 June 2021

62
00:02:39,880 --> 00:02:42,660
is when it looks like that's coming out.

63
00:02:42,660 --> 00:02:44,609
So how do we use likelihood
and risk analysis?

64
00:02:44,610 --> 00:02:46,660
Well, whenever we consider the potential

65
00:02:46,660 --> 00:02:49,600
of harm of an incident,
we think both of impact

66
00:02:49,600 --> 00:02:52,220
and likelihood of foreseeable threats.

67
00:02:52,220 --> 00:02:55,910
How do we estimate likelihood
of foreseeable threats though?

68
00:02:55,910 --> 00:02:59,220
Well, what if we think about a likelihood

69
00:02:59,220 --> 00:03:02,260
as an aspect of tendency not probability,

70
00:03:02,260 --> 00:03:05,186
I know that 2.7% chance
of having this much

71
00:03:05,187 --> 00:03:08,490
of an impact is what I'm
facing for this risk.

72
00:03:08,490 --> 00:03:10,310
But what if you look at
things like tendencies

73
00:03:10,310 --> 00:03:12,920
like what kinds of breaches tend to happen

74
00:03:12,920 --> 00:03:15,170
in organizations like mine?

75
00:03:15,170 --> 00:03:17,299
If you can do that you need the data.

76
00:03:17,300 --> 00:03:20,800
So where do you get the data
about tendencies of impacts?

77
00:03:20,800 --> 00:03:22,160
Well, today we're gonna talk

78
00:03:22,160 --> 00:03:23,730
about the various community database.

79
00:03:23,730 --> 00:03:28,200
There are other sources of
public data for threat analysis

80
00:03:28,200 --> 00:03:31,000
but what the various
community database is,

81
00:03:31,000 --> 00:03:33,240
it's a publicly available data set.

82
00:03:33,240 --> 00:03:35,830
It's provided by Verizon,
the same team who created

83
00:03:35,830 --> 00:03:39,010
the data breach investigation report

84
00:03:39,010 --> 00:03:40,590
but they create a subset of that data,

85
00:03:40,590 --> 00:03:43,870
a representative set that
allows us to use that data

86
00:03:43,870 --> 00:03:48,140
as we want, it's updated
periodically around twice a year.

87
00:03:48,140 --> 00:03:49,970
And it's very, very rich in data.

88
00:03:49,970 --> 00:03:52,880
I don't know if you've seen
this thing, it's a monster.

89
00:03:52,880 --> 00:03:54,799
If you look in the CSV version of it

90
00:03:54,800 --> 00:03:57,240
you're gonna see almost 9,000 records.

91
00:03:57,240 --> 00:03:59,790
And you're gonna see
more than 2000 columns.

92
00:03:59,790 --> 00:04:02,277
Each record is an incident
and of those columns

93
00:04:02,277 --> 00:04:05,500
is a whole lot of data about
the things that are featured

94
00:04:05,500 --> 00:04:08,270
about each of the reported breaches.

95
00:04:08,270 --> 00:04:09,880
Now you can be intimidated looking

96
00:04:09,880 --> 00:04:12,799
at more than 2000 columns of data

97
00:04:12,800 --> 00:04:15,060
but what Verizon has
done is they created sort

98
00:04:15,060 --> 00:04:18,110
of a language that allows
us to look at clusters

99
00:04:18,110 --> 00:04:21,593
of these columns that
have certain meanings,

100
00:04:22,510 --> 00:04:24,550
interesting things about
the attack vectors.

101
00:04:24,550 --> 00:04:26,110
How did the bad guys get in?

102
00:04:26,110 --> 00:04:29,180
Attack methods, what
did they do to get in?

103
00:04:29,180 --> 00:04:31,230
Assets, what assets did they hit?

104
00:04:31,230 --> 00:04:33,730
The victims, characteristics
about the victims,

105
00:04:33,730 --> 00:04:34,930
what kind of industry were they in?

106
00:04:34,930 --> 00:04:36,260
Where were they?

107
00:04:36,260 --> 00:04:37,870
Attackers, who were they?

108
00:04:37,870 --> 00:04:38,920
Where were they from?

109
00:04:39,790 --> 00:04:41,240
Lots of information about this.

110
00:04:41,240 --> 00:04:43,930
So once you think about
the data in these clusters

111
00:04:43,930 --> 00:04:46,503
the columns become easier
and easier to understand.

112
00:04:48,060 --> 00:04:51,660
So how do you find tendency
in a database that is huge?

113
00:04:51,660 --> 00:04:54,020
Well, you start by asking questions.

114
00:04:54,020 --> 00:04:55,900
The questions I find really good answers

115
00:04:55,900 --> 00:04:57,844
for it in the various
community database are,

116
00:04:57,844 --> 00:05:00,060
how common are certain threat vectors,

117
00:05:00,060 --> 00:05:03,020
the way that bad guys get it?

118
00:05:03,020 --> 00:05:05,409
What is the commonality
of certain attack methods?

119
00:05:05,410 --> 00:05:07,960
The things that they do to get in.

120
00:05:07,960 --> 00:05:10,863
And what is the commonality
of certain compromised assets?

121
00:05:12,030 --> 00:05:15,549
If we can find patterns and
we're going to find patterns

122
00:05:15,550 --> 00:05:17,670
and we can start to
filter out by industry.

123
00:05:17,670 --> 00:05:21,230
We start to see that
threats happen differently

124
00:05:21,230 --> 00:05:24,700
depending on the industry
that's being attacked.

125
00:05:24,700 --> 00:05:26,610
And we can find even patterns over time

126
00:05:26,610 --> 00:05:28,650
because the various
data also has the years

127
00:05:28,650 --> 00:05:29,929
that breach has happened.

128
00:05:29,930 --> 00:05:33,260
So we can start to look at
trends, very interesting

129
00:05:33,260 --> 00:05:36,710
but it allows us to have a new
kind of likelihood question.

130
00:05:36,710 --> 00:05:39,190
We don't have to be locked
into this question of asking

131
00:05:39,190 --> 00:05:41,850
when will we be breached and how?

132
00:05:41,850 --> 00:05:43,530
And then move towards formalized

133
00:05:43,530 --> 00:05:46,539
and sometimes for some
organizations is difficult

134
00:05:46,540 --> 00:05:51,150
to use probability analysis,
but we can ask questions like

135
00:05:51,150 --> 00:05:54,130
what is the likeliest
way I will be breached?

136
00:05:54,130 --> 00:05:56,900
Assuming that we will
have a security incident,

137
00:05:56,900 --> 00:06:00,250
how do organizations like
mine tend to be breached?

138
00:06:00,250 --> 00:06:03,940
That helps me prioritize the
things that are most likely

139
00:06:03,940 --> 00:06:07,770
to happen because we find probabilities

140
00:06:07,770 --> 00:06:09,810
very difficult for people to implement.

141
00:06:09,810 --> 00:06:12,920
And it's fairly controversial,
stolen information security

142
00:06:12,920 --> 00:06:15,550
and because formatting
or forecasting based

143
00:06:15,550 --> 00:06:18,160
on these tendencies is fairly
easy once you see the data

144
00:06:18,160 --> 00:06:19,110
I'm gonna show you.

145
00:06:20,020 --> 00:06:20,853
There are those who say

146
00:06:20,853 --> 00:06:23,237
you can't predict cybersecurity threats.

147
00:06:23,237 --> 00:06:26,590
But we don't wanna predict,
we're not going for accuracy.

148
00:06:26,590 --> 00:06:29,130
What we want is to forecast,
we want to estimate

149
00:06:29,130 --> 00:06:32,310
based on tendency so we can
prepare for those common events.

150
00:06:32,310 --> 00:06:34,280
When you look at regulations and laws

151
00:06:34,280 --> 00:06:35,929
and information security standards,

152
00:06:35,930 --> 00:06:38,650
they want us to think
about foreseeable threats.

153
00:06:38,650 --> 00:06:40,599
You're not saying you must be accurate.

154
00:06:41,480 --> 00:06:43,710
And frankly we don't expect
that we will be accurate

155
00:06:43,710 --> 00:06:45,710
but let's think about forecasting.

156
00:06:45,710 --> 00:06:48,450
And besides cybersecurity does innovate

157
00:06:48,450 --> 00:06:50,140
but not very much year over year.

158
00:06:50,140 --> 00:06:52,469
There's a lot of
commonality year over year

159
00:06:52,470 --> 00:06:53,570
and we'll discuss why.

160
00:06:55,410 --> 00:06:58,350
In fact, if we were going
for accurate prediction

161
00:06:58,350 --> 00:06:59,640
here's what our outcome would be.

162
00:06:59,640 --> 00:07:02,990
Tell me if you like being
accurate with your risk analysis.

163
00:07:02,990 --> 00:07:05,210
We were breached this year
and lost a million records

164
00:07:05,210 --> 00:07:08,270
just as we predicted, that's accurate.

165
00:07:08,270 --> 00:07:09,700
I don't know if I want accurate.

166
00:07:09,700 --> 00:07:12,690
I want results from
risk managed forecasts.

167
00:07:12,690 --> 00:07:15,910
Here's how that reads, we
saw that personnel tend

168
00:07:15,910 --> 00:07:18,890
to breach data by
accident in our industry.

169
00:07:18,890 --> 00:07:20,840
So we remove their access
to the Crown Jewels.

170
00:07:20,840 --> 00:07:22,416
Their eventual error
released much less data

171
00:07:22,416 --> 00:07:24,530
than we originally estimated,

172
00:07:24,530 --> 00:07:27,024
that's thinking in terms of forecasting,

173
00:07:27,024 --> 00:07:29,520
in terms of a risk management idea.

174
00:07:29,520 --> 00:07:31,719
I want to think about how
to reduce the likelihood

175
00:07:31,720 --> 00:07:35,120
of the bad impact by looking
at how common in organizations

176
00:07:35,120 --> 00:07:37,420
that are shaped like mine
have the kinds of problems

177
00:07:37,420 --> 00:07:39,510
they should be addressing.

178
00:07:39,510 --> 00:07:41,300
I'm gonna show you how we
pull this data together

179
00:07:41,300 --> 00:07:42,560
and how we found it.

180
00:07:42,560 --> 00:07:45,600
But before I show you the how
I'm gonna show you the result

181
00:07:46,730 --> 00:07:50,840
this beautiful picture is all of the data

182
00:07:50,840 --> 00:07:52,840
inside the various community database

183
00:07:52,840 --> 00:07:55,479
of all industries and
all threatened vectors

184
00:07:55,480 --> 00:08:00,480
and methods, attack
factors and attack methods.

185
00:08:00,730 --> 00:08:04,310
What you see here is up to the top-left

186
00:08:04,310 --> 00:08:07,070
personnel error and personnel misuse.

187
00:08:07,070 --> 00:08:09,165
These are what HALOCK Security Labs,

188
00:08:09,165 --> 00:08:12,410
My company calls a
cluster, a threat cluster.

189
00:08:12,410 --> 00:08:13,650
When we see hit index

190
00:08:13,650 --> 00:08:16,489
that's just HALOCK use of the
various community database.

191
00:08:16,490 --> 00:08:19,740
We blend the data and
melded in certain ways

192
00:08:19,740 --> 00:08:22,080
but personnel error as a cluster

193
00:08:22,080 --> 00:08:25,173
and personnel misuse
have component threats.

194
00:08:26,170 --> 00:08:28,670
Carelessness is a personnel error,

195
00:08:28,670 --> 00:08:30,650
misdelivery is a personnel error,

196
00:08:30,650 --> 00:08:32,970
device immediate loss
is a personnel error.

197
00:08:32,970 --> 00:08:34,909
Personnel misuses, privilege abuse,

198
00:08:34,909 --> 00:08:36,949
that's someone breaking a rule on purpose,

199
00:08:36,950 --> 00:08:41,053
LAN misuse, data misuse,
misuse of the facility.

200
00:08:42,250 --> 00:08:44,650
When you see this you're
gonna see undetermined vector

201
00:08:44,650 --> 00:08:47,620
and undetermined method
but we see this a lot

202
00:08:47,620 --> 00:08:48,730
in the various community database.

203
00:08:48,730 --> 00:08:50,660
Don't let that disappoint you.

204
00:08:50,660 --> 00:08:52,230
When people are doing forensic analysis

205
00:08:52,230 --> 00:08:55,400
and sending their data to
the Verizon team for Veris.

206
00:08:55,400 --> 00:08:57,209
If they don't have data it's very likely

207
00:08:57,210 --> 00:08:59,540
because the organization that was hit

208
00:08:59,540 --> 00:09:01,260
didn't have good log management.

209
00:09:01,260 --> 00:09:02,790
Didn't have good log correlation.

210
00:09:02,790 --> 00:09:04,040
Didn't have good alerting.

211
00:09:04,040 --> 00:09:07,260
So organizations never
knew what the cause was.

212
00:09:07,260 --> 00:09:09,670
So the forensics folks
send records up saying,

213
00:09:09,670 --> 00:09:11,671
we don't know because
we don't have the data.

214
00:09:11,672 --> 00:09:14,680
So that stands in as a very good proxy

215
00:09:14,680 --> 00:09:16,186
for organizations that don't
have good log management,

216
00:09:16,187 --> 00:09:20,340
good log correlation,
good situational awareness

217
00:09:20,340 --> 00:09:23,550
or good forensics, so keep that
in mind as you look at that.

218
00:09:23,550 --> 00:09:26,010
But again, this is all
industry is all time.

219
00:09:26,010 --> 00:09:28,019
That's kind of interesting, but let's look

220
00:09:28,019 --> 00:09:31,610
at what happens when they
look at a specific industry.

221
00:09:31,610 --> 00:09:34,150
Now, retail looks different
from everybody else.

222
00:09:34,150 --> 00:09:36,000
Again, this is retail over all times.

223
00:09:37,310 --> 00:09:41,500
Physical facility is the leading
issue as a threat cluster

224
00:09:41,500 --> 00:09:45,122
and then hacking systems and
then physical asset loss.

225
00:09:45,122 --> 00:09:46,870
And then we get the personnel misuse,

226
00:09:46,870 --> 00:09:49,210
people breaking rules on purpose

227
00:09:49,210 --> 00:09:53,210
and in personnel error,
making mistakes accidentally.

228
00:09:53,210 --> 00:09:56,320
Why is physical facilities
such a big deal in retail?

229
00:09:56,320 --> 00:09:58,310
Well, let's take a look at
what the component threats are,

230
00:09:58,310 --> 00:10:00,000
tampering, disabled controls,

231
00:10:00,000 --> 00:10:02,090
victim at facility, public facility.

232
00:10:02,090 --> 00:10:05,950
These are all aspects of
point of sale scammers

233
00:10:05,950 --> 00:10:07,800
which happened quite a lot at retail.

234
00:10:08,640 --> 00:10:09,550
You're gonna say, well, wait a minute

235
00:10:09,550 --> 00:10:10,382
isn't that double-counting
I got schema here

236
00:10:10,383 --> 00:10:12,260
and I've got schema here.

237
00:10:12,260 --> 00:10:13,860
Yes, it is double counting.

238
00:10:13,860 --> 00:10:15,480
And it's very important to
double count when you're looking

239
00:10:15,480 --> 00:10:17,700
for tendencies because
you're looking at causes

240
00:10:17,700 --> 00:10:20,210
and methods and we can get rid of a cause

241
00:10:20,210 --> 00:10:21,910
but the methods might still exist.

242
00:10:22,950 --> 00:10:24,480
We're gonna have a
conversation after this,

243
00:10:24,480 --> 00:10:26,620
it will be Q and A after this session

244
00:10:26,620 --> 00:10:28,620
if you wanna have a conversation
about the appropriateness

245
00:10:28,620 --> 00:10:31,510
of double counting, let's
have that conversation.

246
00:10:31,510 --> 00:10:33,620
But now we start to see
that physical facility

247
00:10:33,620 --> 00:10:37,620
matters a lot and then hacking
system matters a lot too

248
00:10:37,620 --> 00:10:40,113
because retail has quite
a bit going on online.

249
00:10:41,480 --> 00:10:42,630
What does it look like when we look

250
00:10:42,630 --> 00:10:44,670
at public institutions over time?

251
00:10:44,670 --> 00:10:46,750
Personnel error is really big.

252
00:10:46,750 --> 00:10:47,910
Why is that?

253
00:10:47,910 --> 00:10:49,930
Well, because public institutions,

254
00:10:49,930 --> 00:10:54,930
government organizations are
an intensely person-to-person

255
00:10:55,210 --> 00:10:58,582
one-on-one people handling
information about people business

256
00:10:58,582 --> 00:11:02,130
People are handling a lot
of business information

257
00:11:02,130 --> 00:11:07,130
about tax collection,
about property values,

258
00:11:07,810 --> 00:11:10,099
about actions, about research.

259
00:11:10,100 --> 00:11:11,780
Public institutions
have a lot of this data

260
00:11:11,780 --> 00:11:14,199
but it's a lot of people
handling a lot of this data.

261
00:11:14,200 --> 00:11:16,348
There's a lot of opportunity
for people to make mistakes.

262
00:11:16,348 --> 00:11:19,400
Look how big misdelivery, what is that?

263
00:11:19,400 --> 00:11:21,650
Those are things like tax bills.

264
00:11:21,650 --> 00:11:23,472
Those are billing for VA,

265
00:11:23,472 --> 00:11:26,840
it's a lot of people just making mistakes.

266
00:11:26,840 --> 00:11:29,260
But when you have a lot of
person-to-person business

267
00:11:29,260 --> 00:11:31,230
you have a lot of opportunity
to personnel error,

268
00:11:31,230 --> 00:11:34,090
that's where the common
attacks are gonna be.

269
00:11:34,090 --> 00:11:35,780
And malware, but that tells you something

270
00:11:35,780 --> 00:11:38,579
about the systems that are
being operated in number one

271
00:11:38,580 --> 00:11:40,590
or number two, the methods
that are being used

272
00:11:40,590 --> 00:11:42,700
by state actors who are trying to get

273
00:11:42,700 --> 00:11:45,233
into our government systems, right?

274
00:11:46,380 --> 00:11:48,220
So we have a couple of glimpses

275
00:11:48,220 --> 00:11:53,220
of what we mean by looking
at that data to see trends

276
00:11:53,560 --> 00:11:56,890
and to see tendencies and threats.

277
00:11:56,890 --> 00:11:58,699
So how do we actually
put that data together?

278
00:11:58,700 --> 00:12:00,930
Well, we start by knowing
how our business operates.

279
00:12:00,930 --> 00:12:03,339
What do we mean by how
our business operates?

280
00:12:03,340 --> 00:12:06,280
And that turns into this
concept of a threat landscape

281
00:12:06,280 --> 00:12:08,601
because the way we do
business, where we do business

282
00:12:08,601 --> 00:12:10,820
is where we get attacked.

283
00:12:10,820 --> 00:12:13,090
Then we get threat data
we'll show you how to do that

284
00:12:13,090 --> 00:12:15,060
from the various community database.

285
00:12:15,060 --> 00:12:17,160
We aligned threat data
to our threat landscape

286
00:12:17,160 --> 00:12:18,377
and then we organize the data to see where

287
00:12:18,377 --> 00:12:20,160
the threats have recently been.

288
00:12:20,160 --> 00:12:23,030
So we get a sense of where
to look at next, all right?

289
00:12:23,030 --> 00:12:24,540
So we're gonna walk you
through all those steps

290
00:12:24,540 --> 00:12:27,050
starting with knowing how
your business operates.

291
00:12:27,050 --> 00:12:29,310
So we're gonna look at a
couple of examples here.

292
00:12:29,310 --> 00:12:32,479
What we're looking at here
is in terms of hospitals

293
00:12:32,480 --> 00:12:35,543
where do we expect the
sensitive data to be?

294
00:12:36,620 --> 00:12:38,768
Well, quite a bit of physical
because in healthcare

295
00:12:38,768 --> 00:12:43,330
you go to a place, you go to a
hospital, you go to a dentist

296
00:12:43,330 --> 00:12:46,247
you go to a pharmacy, you go
to places for your healthcare

297
00:12:46,247 --> 00:12:49,219
and you physically need to
be there for the most part.

298
00:12:49,220 --> 00:12:50,510
Well, how about systems?

299
00:12:50,510 --> 00:12:51,343
There are definite systems

300
00:12:51,343 --> 00:12:54,319
and we're not talking about the
number of records somewhere.

301
00:12:54,320 --> 00:12:55,882
We're talking about the interfaces

302
00:12:55,882 --> 00:12:58,199
that the business has with the world.

303
00:12:58,200 --> 00:13:01,050
The opportunities to be a breached based

304
00:13:01,050 --> 00:13:02,979
on the opportunities
are based on the amount

305
00:13:02,980 --> 00:13:05,162
of work you do at a kind of asset.

306
00:13:05,162 --> 00:13:09,100
Personnel, lots of personnel
at hospitals, the doctors,

307
00:13:09,100 --> 00:13:13,210
the nurses, the clinicians,
the pharmacists, the lab techs

308
00:13:13,210 --> 00:13:15,140
the people who are doing
billing and collection.

309
00:13:15,140 --> 00:13:17,740
A lot of people handling a
lot of individual records.

310
00:13:17,740 --> 00:13:19,630
This is tremendous opportunity

311
00:13:19,630 --> 00:13:21,680
for personnel error in healthcare.

312
00:13:21,680 --> 00:13:23,219
How about for banking?

313
00:13:23,220 --> 00:13:24,760
Well, physical is pretty big.

314
00:13:24,760 --> 00:13:26,560
We tend to think about
banks a lot more and more

315
00:13:26,560 --> 00:13:29,880
being finance tech, a lot of systems

316
00:13:29,880 --> 00:13:32,850
but think about what your
interfaces are with banks.

317
00:13:32,850 --> 00:13:35,475
ATM's are everywhere, the ubiquitous,

318
00:13:35,475 --> 00:13:37,510
bank branches everywhere.

319
00:13:37,510 --> 00:13:39,430
Personnel, this is still a very big

320
00:13:39,430 --> 00:13:41,359
person-to-person kind of business.

321
00:13:41,360 --> 00:13:43,179
Yes, systems have the most records

322
00:13:43,179 --> 00:13:45,829
but we interface with
the systems in banking

323
00:13:45,830 --> 00:13:50,170
much less than we do with the
physical and the personnel

324
00:13:50,170 --> 00:13:54,130
just because of where those interfaces

325
00:13:54,130 --> 00:13:57,500
are with the public and their customers.

326
00:13:57,500 --> 00:13:59,910
Information services is
very different from those.

327
00:13:59,910 --> 00:14:04,410
I have never been to an
AWS office in my life

328
00:14:04,410 --> 00:14:08,449
but I've been in AWS systems
a lot without even knowing.

329
00:14:08,450 --> 00:14:11,020
Systems are tremendously predominant.

330
00:14:11,020 --> 00:14:12,970
And the personnel who manage those systems

331
00:14:12,970 --> 00:14:14,880
are tremendous and predominant.

332
00:14:14,880 --> 00:14:16,064
So information services

333
00:14:16,064 --> 00:14:19,020
has a very different business profile

334
00:14:19,020 --> 00:14:21,760
than the other businesses we looked at.

335
00:14:21,760 --> 00:14:23,640
What does the data teach
us when we look at.

336
00:14:23,640 --> 00:14:26,610
Well, as you're about to
see your threat landscape

337
00:14:26,610 --> 00:14:28,473
is where you conduct your business.

338
00:14:30,090 --> 00:14:32,010
So let's understand what
our threat landscape

339
00:14:32,010 --> 00:14:34,000
is now that we've looked at our business.

340
00:14:34,000 --> 00:14:36,280
Hospitals personnel took the lead

341
00:14:36,280 --> 00:14:38,260
and then physical facility and systems

342
00:14:38,260 --> 00:14:40,660
because that's where the business is done.

343
00:14:40,660 --> 00:14:43,040
Let's look at clinical
healthcare of all time

344
00:14:43,040 --> 00:14:45,099
from the various community database.

345
00:14:45,100 --> 00:14:48,283
Personnel misuse is in the lead, right?

346
00:14:49,720 --> 00:14:50,870
And then personnel error.

347
00:14:50,870 --> 00:14:52,190
There's a lot of opportunity

348
00:14:52,190 --> 00:14:54,030
for people to have sensitive information

349
00:14:54,030 --> 00:14:57,060
and now physical asset
loss, data, immediate theft

350
00:14:57,060 --> 00:14:58,180
and then undetermined factor

351
00:14:58,180 --> 00:15:00,130
because the hospitals were not aware

352
00:15:00,130 --> 00:15:01,439
of how people lost those assets

353
00:15:01,440 --> 00:15:03,600
because they were not
connected to anything.

354
00:15:03,600 --> 00:15:08,600
There was no RSA connection
to a device, the USB device

355
00:15:09,944 --> 00:15:14,280
on the system to track it, they're just

356
00:15:14,280 --> 00:15:17,189
there's just an inability to
track a lot of this stuff.

357
00:15:17,190 --> 00:15:18,990
And then only in social engineering

358
00:15:18,990 --> 00:15:20,170
which is tremendously personnel

359
00:15:20,170 --> 00:15:22,140
and only after that, did we
get the physical facility

360
00:15:22,140 --> 00:15:24,900
where we have a patient files?

361
00:15:24,900 --> 00:15:27,579
So what's the issue that
we're getting to here

362
00:15:27,580 --> 00:15:30,900
that we see with clinical healthcare.

363
00:15:30,900 --> 00:15:34,920
The incidents happened
with the business, right?

364
00:15:34,920 --> 00:15:35,969
How about banking?

365
00:15:35,970 --> 00:15:37,870
Physical took the leave
here with personnel

366
00:15:37,870 --> 00:15:42,190
is a lot of predominance
of ATM's and bank branches

367
00:15:42,190 --> 00:15:44,070
and certainly physical facility.

368
00:15:44,070 --> 00:15:46,160
And the reason for physical
facility being predominant

369
00:15:46,160 --> 00:15:48,610
is similar to retail, take a look,

370
00:15:48,610 --> 00:15:51,030
again, tampering, disabled controls

371
00:15:51,030 --> 00:15:52,819
victim of facility surveillance.

372
00:15:52,820 --> 00:15:55,903
This is just like card skimming at retail.

373
00:15:56,960 --> 00:16:00,464
Retail banks look much
more like retail stores

374
00:16:00,464 --> 00:16:03,540
than retail banks look like
other financial services firms

375
00:16:03,540 --> 00:16:05,420
even though they got a lot of money, why?

376
00:16:05,420 --> 00:16:08,900
Because the interfaces with
the public are so similar.

377
00:16:08,900 --> 00:16:13,480
It's the conduits by which
we interface with the public.

378
00:16:13,480 --> 00:16:15,480
It's the presence of the asset

379
00:16:15,480 --> 00:16:17,030
that becomes the threat vector.

380
00:16:18,200 --> 00:16:21,050
This is something that
statisticians jokingly call

381
00:16:21,050 --> 00:16:25,209
interocular, meaning you
don't need complex analysis

382
00:16:25,210 --> 00:16:28,010
it hits you between the
eyes when you see it.

383
00:16:28,010 --> 00:16:31,290
This is the commonality of a banking

384
00:16:31,290 --> 00:16:34,670
because the banking assets
are this much common

385
00:16:34,670 --> 00:16:37,319
to the public, information services,

386
00:16:37,320 --> 00:16:39,520
you can guess what's gonna happen next.

387
00:16:39,520 --> 00:16:43,020
Hacking system, hacking
web are taking the lead

388
00:16:43,020 --> 00:16:45,360
because that's where the opportunity is.

389
00:16:45,360 --> 00:16:48,260
That's where the largest
presence of that business is.

390
00:16:48,260 --> 00:16:49,819
And then after that personnel error

391
00:16:49,819 --> 00:16:53,170
by things like misconfiguration
and carelessness.

392
00:16:53,170 --> 00:16:54,839
The people who are configuring the systems

393
00:16:54,840 --> 00:16:56,290
that end up getting attacked.

394
00:16:57,730 --> 00:17:00,257
So if you're an information
systems organization

395
00:17:00,257 --> 00:17:01,930
and you're trying to think
about where are we gonna

396
00:17:01,931 --> 00:17:05,420
get hit most, I'm gonna pay less attention

397
00:17:05,420 --> 00:17:06,720
to my physical presence,

398
00:17:06,720 --> 00:17:08,450
which is barely an issue

399
00:17:08,450 --> 00:17:10,589
and a whole lot of attention to my system.

400
00:17:10,589 --> 00:17:13,869
And I better come to a
determination very quickly

401
00:17:13,869 --> 00:17:16,109
that I've got to get good
log management in place

402
00:17:16,109 --> 00:17:19,359
because most people in my
position do not know the causes

403
00:17:19,359 --> 00:17:21,589
of the breaches that happened
in their organization,

404
00:17:21,589 --> 00:17:24,540
because they're log management,
log correlation alerting,

405
00:17:24,540 --> 00:17:26,262
forensics were not up to snuff.

406
00:17:27,810 --> 00:17:29,590
So this is what we mean by interocular.

407
00:17:29,590 --> 00:17:31,620
It just hits you between the eyes.

408
00:17:31,620 --> 00:17:34,000
The threats are happening
with the businesses.

409
00:17:34,000 --> 00:17:35,480
If you look at the various
community database,

410
00:17:35,480 --> 00:17:38,190
you'll see a lot of interesting things

411
00:17:38,190 --> 00:17:39,650
but you're gonna see a lot of industries.

412
00:17:39,650 --> 00:17:42,230
You'll very likely find
yourself in there somewhere.

413
00:17:42,230 --> 00:17:43,500
This is just a sample of them,

414
00:17:43,500 --> 00:17:44,970
but if you think of an industry

415
00:17:44,970 --> 00:17:48,500
they had a breach there in the
various community database.

416
00:17:48,500 --> 00:17:49,990
So let's test this hypothesis.

417
00:17:49,990 --> 00:17:51,360
I've been leading you down a path

418
00:17:51,360 --> 00:17:52,240
I've been telling you,

419
00:17:52,240 --> 00:17:54,612
well, here's the kind of business it is.

420
00:17:54,612 --> 00:17:56,710
And here are the kinds of threats,

421
00:17:56,710 --> 00:17:58,750
but let's try this out yourself.

422
00:17:58,750 --> 00:18:00,940
I'm not telling you what business this is.

423
00:18:00,940 --> 00:18:03,030
I'm just telling you what kinds of threats

424
00:18:03,030 --> 00:18:05,860
are most common and least
common in this business.

425
00:18:05,860 --> 00:18:06,699
And then we'll quiz you tell me.

426
00:18:06,700 --> 00:18:09,300
You tell me what you think this is?

427
00:18:09,300 --> 00:18:12,030
So personnel error is a big deal.

428
00:18:12,030 --> 00:18:13,670
They don't know what causes most of them

429
00:18:13,670 --> 00:18:15,880
but there's a lot of
misdelivery which means

430
00:18:15,880 --> 00:18:18,110
there are people handling
a lot of sensitive data

431
00:18:18,110 --> 00:18:21,060
that they're supposed to
be sending to other people

432
00:18:21,060 --> 00:18:23,560
and they're doing it
wrong, personal misuse.

433
00:18:23,560 --> 00:18:26,659
People have a lot of
access to a lot of data.

434
00:18:26,660 --> 00:18:28,260
What kind of business is that?

435
00:18:28,260 --> 00:18:29,190
Let's take a look at something

436
00:18:29,190 --> 00:18:31,890
that's very, very uncommon, skimming.

437
00:18:31,890 --> 00:18:34,570
So there isn't a lot of on-site purchasing

438
00:18:34,570 --> 00:18:36,520
going on in that business.

439
00:18:36,520 --> 00:18:38,220
So what kind of business is that?

440
00:18:38,220 --> 00:18:39,733
Is that a fast food chain?

441
00:18:41,410 --> 00:18:45,483
Is it a financial advisor
or is it a hotel chain?

442
00:18:46,890 --> 00:18:48,823
think about where the risks are?

443
00:18:49,790 --> 00:18:51,510
Well, it's a financial advisor

444
00:18:51,510 --> 00:18:54,040
because there's lots of
one-on-one contact with customers.

445
00:18:54,040 --> 00:18:57,580
So there's lots of opportunity
for misuse and error.

446
00:18:57,580 --> 00:18:59,980
Most employees are handling
personal information.

447
00:18:59,980 --> 00:19:01,540
There's lots of delivery and distribution

448
00:19:01,540 --> 00:19:03,970
of personal information
that's just being misdelivered

449
00:19:03,970 --> 00:19:06,900
and there's very rare
on-site transactions.

450
00:19:06,900 --> 00:19:09,090
So you can actually look
at a trend landscape

451
00:19:09,090 --> 00:19:11,050
and guess what kind of organization it is.

452
00:19:11,050 --> 00:19:12,560
Even if you don't know
the name of the company,

453
00:19:12,560 --> 00:19:15,869
you can say this looks like
an X kind of organization

454
00:19:15,869 --> 00:19:19,199
because the information is
that well tied to the industry

455
00:19:20,515 --> 00:19:22,070
which brings me to this idea.

456
00:19:22,070 --> 00:19:22,903
One of my favorite quotes,

457
00:19:22,903 --> 00:19:25,850
history doesn't repeat
itself but it rhymes

458
00:19:25,850 --> 00:19:27,939
what's happening is that organizations

459
00:19:27,940 --> 00:19:30,440
because they have certain business methods

460
00:19:30,440 --> 00:19:32,390
they have certain business processes

461
00:19:32,390 --> 00:19:35,980
their assets pretty much
your stable year after year,

462
00:19:35,980 --> 00:19:37,570
retail took a long time to go

463
00:19:37,570 --> 00:19:39,120
from brick and mortar to online

464
00:19:40,421 --> 00:19:43,360
They eventually got
there, but it was slow.

465
00:19:43,360 --> 00:19:46,649
Hospitals took a long time
to go from paper to systems.

466
00:19:46,650 --> 00:19:49,070
It took a long time, but they got there.

467
00:19:49,070 --> 00:19:51,110
It just takes a long time for an industry

468
00:19:51,110 --> 00:19:52,560
to change the way it's shaped.

469
00:19:52,560 --> 00:19:54,633
So your risks from a
previous year look a lot like

470
00:19:54,633 --> 00:19:56,490
your risks from the following year

471
00:19:56,490 --> 00:19:57,943
but there are some things
that actually give you

472
00:19:57,943 --> 00:20:01,523
a reason to watch trends.

473
00:20:02,440 --> 00:20:04,430
Let's get the threat data,
where do we get it from?

474
00:20:04,430 --> 00:20:06,510
Well, I'm talking to the
various community database

475
00:20:06,510 --> 00:20:08,110
but there are other ways to get data

476
00:20:08,110 --> 00:20:10,240
that's sourced from the public.

477
00:20:10,240 --> 00:20:11,910
I've got some listed here that are good

478
00:20:11,910 --> 00:20:13,013
for tactical prep and response.

479
00:20:13,013 --> 00:20:17,120
What I mean by that is looking
at things going on wire.

480
00:20:17,120 --> 00:20:18,860
So you're gonna have a lot of variation

481
00:20:18,860 --> 00:20:21,350
day over day, sometimes hour over hour.

482
00:20:21,350 --> 00:20:23,817
What threats are happening a
lot in environments right now,

483
00:20:23,817 --> 00:20:27,430
and how do they correlate
to our operations?

484
00:20:27,430 --> 00:20:29,330
There's some good public data sources

485
00:20:29,330 --> 00:20:32,162
and some good commercial tools
that allow this to happen.

486
00:20:32,162 --> 00:20:34,960
I'm using Veris because
it's good for planning.

487
00:20:34,960 --> 00:20:36,210
It's good for sketching out

488
00:20:36,210 --> 00:20:37,380
what your budget should be this year

489
00:20:37,380 --> 00:20:38,213
or next year or next year.

490
00:20:38,213 --> 00:20:39,572
What are you focused on most?

491
00:20:40,690 --> 00:20:43,240
Privacy rights clearing
house has a very skinny

492
00:20:43,240 --> 00:20:45,170
set of data, very good
data, but much skinnier

493
00:20:45,170 --> 00:20:47,510
than what you've seen in the
various community database.

494
00:20:47,510 --> 00:20:48,560
And if you belong to an ISAC

495
00:20:48,560 --> 00:20:49,740
you really should be involved

496
00:20:49,740 --> 00:20:52,040
in threat information exchange.

497
00:20:52,040 --> 00:20:53,500
But these are just some other places

498
00:20:53,500 --> 00:20:56,990
where you can get public
data about these threats.

499
00:20:56,990 --> 00:20:59,840
Now let's align threat data
to our threat landscape.

500
00:20:59,840 --> 00:21:00,980
How do we do that?

501
00:21:00,980 --> 00:21:03,470
Well, remember this is the
Veris Community Database

502
00:21:03,470 --> 00:21:05,840
and the CSV format 2000

503
00:21:05,840 --> 00:21:09,520
or more columns wide, 9,000 rows deep.

504
00:21:09,520 --> 00:21:12,110
What we're gonna do is ask
them the questions, right?

505
00:21:12,110 --> 00:21:14,570
Now the questions that I find most helpful

506
00:21:14,570 --> 00:21:16,909
are the ones that I have here in red.

507
00:21:16,910 --> 00:21:19,315
Industries and sub-industries,
threat actions,

508
00:21:19,315 --> 00:21:21,260
threat vectors and assets.

509
00:21:21,260 --> 00:21:23,253
I can ask questions about size of breach

510
00:21:23,253 --> 00:21:25,919
and financial impact but
you're gonna see very little

511
00:21:25,920 --> 00:21:27,920
to correlate in, it is
very little information,

512
00:21:27,920 --> 00:21:29,530
very little consistency.

513
00:21:29,530 --> 00:21:31,550
There's a lot of very useful information

514
00:21:31,550 --> 00:21:33,193
about what happens to whom.

515
00:21:35,270 --> 00:21:36,889
And again, we're gonna questions.

516
00:21:36,890 --> 00:21:38,510
We're not gonna dive into the data

517
00:21:38,510 --> 00:21:40,010
before asking good questions.

518
00:21:40,010 --> 00:21:44,390
We're gonna ask, how common
are certain threat vectors,

519
00:21:44,390 --> 00:21:46,760
the way people get in, the commonality

520
00:21:46,760 --> 00:21:49,400
of certain attack methods,
what they're doing to get in?

521
00:21:49,400 --> 00:21:51,600
The commonality of certain
compromised assets,

522
00:21:51,600 --> 00:21:53,929
what's being hit, what should I protect?

523
00:21:53,930 --> 00:21:55,075
And then we're gonna
ask, how does this apply

524
00:21:55,075 --> 00:21:58,400
to certain industries and
pluck mine out with a filter.

525
00:21:58,400 --> 00:22:00,690
And then I'm gonna look
for patterns over time

526
00:22:00,690 --> 00:22:02,313
and I'll show you how to do that.

527
00:22:03,560 --> 00:22:07,820
I recommend if you're not
agile in probability analysis,

528
00:22:07,820 --> 00:22:10,010
statistical analysis,
you're not using programs

529
00:22:10,010 --> 00:22:12,310
like R to do this kind of analysis.

530
00:22:12,310 --> 00:22:14,966
You're gonna want to pull
in the CSV file from Veris

531
00:22:14,967 --> 00:22:18,380
and not the raw JSON files
but you're also gonna have

532
00:22:18,380 --> 00:22:19,980
to get used to pivot tables in Excel

533
00:22:19,980 --> 00:22:21,770
if you're not already proficient.

534
00:22:21,770 --> 00:22:23,810
Pivot tables are ways to aggregate data.

535
00:22:23,810 --> 00:22:26,090
So you can ask a question
like we have here

536
00:22:26,090 --> 00:22:28,250
toward the middle denial of service.

537
00:22:28,250 --> 00:22:30,827
You can look at a whole lot of
data, 9,000 records and say,

538
00:22:30,827 --> 00:22:32,590
"how many times does the denial of service

539
00:22:32,590 --> 00:22:33,830
come up from my industry?"

540
00:22:33,830 --> 00:22:36,820
You get an answer 48,
pivot tables help you

541
00:22:36,820 --> 00:22:38,770
do that kind of aggregation when you ask

542
00:22:38,770 --> 00:22:40,730
certain questions about data types.

543
00:22:40,730 --> 00:22:42,718
So get proficient with
those in pulling the CSV

544
00:22:42,718 --> 00:22:47,233
if you're not capable and
good with statistics in R.

545
00:22:48,960 --> 00:22:50,290
Now let's see where threats have been.

546
00:22:50,290 --> 00:22:51,780
This gets very interesting.

547
00:22:51,780 --> 00:22:54,379
Remember we looked at
clinical health over all time.

548
00:22:54,380 --> 00:22:56,337
We sought a personnel misuse of a leader

549
00:22:56,337 --> 00:22:58,580
and personnel error was next.

550
00:22:58,580 --> 00:23:00,699
There are those of you in the audience

551
00:23:00,700 --> 00:23:04,090
who would have said, I heard news

552
00:23:04,090 --> 00:23:05,949
that ransomware is big in healthcare.

553
00:23:05,950 --> 00:23:10,460
So why is malware and ransomware so small?

554
00:23:10,460 --> 00:23:13,390
Well, this is overall
time and what we wanna do

555
00:23:13,390 --> 00:23:14,640
and we're analyzing this data

556
00:23:14,640 --> 00:23:16,350
because there's so much
data in that database.

557
00:23:16,350 --> 00:23:18,199
We can do this kind of thing,

558
00:23:18,200 --> 00:23:20,970
let's look at what happens year over year.

559
00:23:20,970 --> 00:23:23,140
So we're gonna look at a five-year trend

560
00:23:23,140 --> 00:23:26,463
of threat vectors in
healthcare environments.

561
00:23:27,633 --> 00:23:32,520
2016 what we see is personnel
error taking the lead

562
00:23:32,520 --> 00:23:33,750
just like we saw with that mass group

563
00:23:33,750 --> 00:23:35,780
but then personnel misuses next

564
00:23:35,780 --> 00:23:38,620
and then malware very common, right?

565
00:23:38,620 --> 00:23:41,409
Now in 2017 keep an eye on personnel error

566
00:23:41,410 --> 00:23:44,110
it went to second spot
and personnel misuse

567
00:23:44,110 --> 00:23:45,919
to sort of switch rows 'cause
there are a lot of people

568
00:23:45,920 --> 00:23:47,810
there is a lot of opportunity for people

569
00:23:47,810 --> 00:23:51,169
to do the wrong thing on
purpose or by accident.

570
00:23:51,170 --> 00:23:53,640
Malware stays in this third position.

571
00:23:53,640 --> 00:23:56,110
In 2018, something interesting happens

572
00:23:56,110 --> 00:24:00,000
while personnel error remains
up top malware drops down.

573
00:24:00,000 --> 00:24:02,480
We don't know exactly why,
it's worth saying people

574
00:24:02,480 --> 00:24:06,740
figured out that when you put
certain ransomware software in

575
00:24:06,740 --> 00:24:09,430
you lay low, you take a
look at what's going on.

576
00:24:09,430 --> 00:24:10,540
We think what we're seeing here

577
00:24:10,540 --> 00:24:12,840
when we look at the data is the shift

578
00:24:12,840 --> 00:24:16,429
of the very efficient ransomware
business, which it is now.

579
00:24:16,430 --> 00:24:18,000
It's a whole industry that functions

580
00:24:18,000 --> 00:24:20,550
in the business started to figure out

581
00:24:20,550 --> 00:24:22,409
what to do in hospitals because watch

582
00:24:22,410 --> 00:24:26,683
what happens in 2019, it rises to the top.

583
00:24:26,683 --> 00:24:30,730
Ransomware takes over as the
leading cause of breaches

584
00:24:30,730 --> 00:24:33,640
but personnel error stays in second place

585
00:24:33,640 --> 00:24:36,280
because the people are
still handling this data

586
00:24:36,280 --> 00:24:38,379
and they're still making mistakes with it.

587
00:24:39,300 --> 00:24:43,040
Now we see that the
ransomware business maintains

588
00:24:43,040 --> 00:24:45,790
its position because it works
as an efficient industry.

589
00:24:45,790 --> 00:24:48,357
It maintains its tie, at
least in lead position

590
00:24:48,357 --> 00:24:50,730
and personnel error remains upfront.

591
00:24:50,730 --> 00:24:52,050
What are we seeing?

592
00:24:52,050 --> 00:24:55,149
Yes, we did see a very quick innovation

593
00:24:55,150 --> 00:24:58,840
but what we're also seeing
is a real clear message.

594
00:24:58,840 --> 00:25:02,399
If we're in healthcare, we have
to realize we're targeting.

595
00:25:02,400 --> 00:25:04,640
We have to see that this
is now the new pattern.

596
00:25:04,640 --> 00:25:07,330
Malware is going to be
the continuing issue.

597
00:25:07,330 --> 00:25:09,300
Personnel error is not to be neglected

598
00:25:09,300 --> 00:25:13,010
because that's a constant
issue to be faced with.

599
00:25:13,010 --> 00:25:15,650
Packing hacking web is starting
to become a bigger deal.

600
00:25:15,650 --> 00:25:17,750
And we're starting to see that correlated

601
00:25:17,750 --> 00:25:19,420
with a lot of other malware attacks.

602
00:25:19,420 --> 00:25:21,700
And again, personnel misuse is almost high

603
00:25:21,700 --> 00:25:22,533
with these other things.

604
00:25:22,533 --> 00:25:23,500
It's very significant still

605
00:25:23,500 --> 00:25:26,803
because people have access
to this personal information.

606
00:25:28,720 --> 00:25:30,410
So now that we've taken a look at this,

607
00:25:30,410 --> 00:25:31,570
we've got to ask a question,

608
00:25:31,570 --> 00:25:33,850
how do I use this data
in a risk assessment?

609
00:25:33,850 --> 00:25:35,600
I can't just say my risk is great

610
00:25:35,600 --> 00:25:37,270
because the commonality is great

611
00:25:37,270 --> 00:25:39,870
because I have to take care
of take into consideration

612
00:25:39,870 --> 00:25:43,030
two other things how
capable are my controls

613
00:25:43,030 --> 00:25:45,980
to fight those common attacks
and what is the impact

614
00:25:45,980 --> 00:25:47,710
if something goes wrong?

615
00:25:47,710 --> 00:25:48,610
Let's take a look at this.

616
00:25:48,610 --> 00:25:51,407
When we see the data in the
various community database

617
00:25:51,407 --> 00:25:54,822
and this beautiful tree
chart, it looks very nice.

618
00:25:56,013 --> 00:25:59,080
that means there are
numbers behind it, right?

619
00:25:59,080 --> 00:26:01,500
So this data at these threat clusters

620
00:26:01,500 --> 00:26:03,500
there's one threat cluster per row.

621
00:26:03,500 --> 00:26:05,940
It's associated with a great title boxes.

622
00:26:05,940 --> 00:26:07,710
And we actually see the number of records

623
00:26:07,710 --> 00:26:09,295
and we see the percentage
of representation.

624
00:26:09,295 --> 00:26:11,750
How common are they in breaches?

625
00:26:11,750 --> 00:26:15,280
You'll notice that these
percentages add up to more

626
00:26:15,280 --> 00:26:17,805
than a 100% that's because
when you look at the data

627
00:26:17,805 --> 00:26:21,060
in aggregate, you're
gonna see that an attack

628
00:26:21,060 --> 00:26:23,310
has multiple threats occurring.

629
00:26:23,310 --> 00:26:26,081
So someone made a mistake and
they misconfigured a system.

630
00:26:26,081 --> 00:26:28,000
And the system was attacked.

631
00:26:28,000 --> 00:26:29,280
There are multiple threats

632
00:26:29,280 --> 00:26:32,190
and multiple threat vectors engaged.

633
00:26:32,190 --> 00:26:34,830
So you're gonna get a higher than a 100%.

634
00:26:34,830 --> 00:26:36,100
That's perfectly fine

635
00:26:36,100 --> 00:26:38,149
because you wanna see where the noise is.

636
00:26:39,020 --> 00:26:40,889
Now let's consider this.

637
00:26:40,890 --> 00:26:42,330
If I'm looking at likelihood,

638
00:26:42,330 --> 00:26:45,080
I should be looking the forecast

639
00:26:45,080 --> 00:26:46,949
and I should be considering
control strength,

640
00:26:46,950 --> 00:26:48,523
the stronger my control

641
00:26:48,523 --> 00:26:51,719
the more it should mitigate the forecasts.

642
00:26:51,720 --> 00:26:54,860
So if I have a way to say, look
at the maturity of controls

643
00:26:54,860 --> 00:26:56,120
and I think about maturity of controls

644
00:26:56,120 --> 00:26:59,139
in terms of how reliable that control is,

645
00:26:59,140 --> 00:27:01,290
how much can I expect
that control the function

646
00:27:01,290 --> 00:27:02,770
when they need it most?

647
00:27:02,770 --> 00:27:06,190
And that's how we define
this maturity model.

648
00:27:06,190 --> 00:27:09,200
Then that should mitigate controls.

649
00:27:09,200 --> 00:27:12,350
If I were analyzing just
off the top of my head

650
00:27:12,350 --> 00:27:16,090
and I'd say there's a very
common issue of personnel error,

651
00:27:16,090 --> 00:27:19,590
and my ability to protect
that as inconsistent.

652
00:27:19,590 --> 00:27:20,523
That's not good.

653
00:27:21,490 --> 00:27:24,080
I clearly know I had to address that.

654
00:27:24,080 --> 00:27:26,939
It might be overkill for me to innovate

655
00:27:26,940 --> 00:27:29,190
and do root cause analysis
and continual improvement

656
00:27:29,190 --> 00:27:32,930
over something that is rarely
present in reporting breaches

657
00:27:32,930 --> 00:27:34,630
that might be overkill.

658
00:27:34,630 --> 00:27:36,180
And it's important to
know where overkill is.

659
00:27:36,180 --> 00:27:38,110
We don't wanna over-invest.

660
00:27:38,110 --> 00:27:40,338
And in fact, when you look
at regulations and laws,

661
00:27:40,338 --> 00:27:42,930
and I'll guide you into that
in a little bit in a moment,

662
00:27:42,930 --> 00:27:44,430
you're not supposed to over-invest,

663
00:27:44,430 --> 00:27:47,030
that's actually bad for you
in the public if you do,

664
00:27:47,950 --> 00:27:52,150
it seems right to have
tested and corrected controls

665
00:27:52,150 --> 00:27:53,600
for things that are as common as you know,

666
00:27:53,600 --> 00:27:56,562
they happen say one in
every five breaches,

667
00:27:58,390 --> 00:27:59,880
but now how do we correlate that?

668
00:27:59,880 --> 00:28:02,190
So this is just a suggestion.

669
00:28:02,190 --> 00:28:05,523
Now this is just conceptual,
there's no math behind it.

670
00:28:07,130 --> 00:28:08,850
We'll call it a likelihood slide rule,

671
00:28:08,850 --> 00:28:11,923
this is for the sake of this presentation.

672
00:28:12,970 --> 00:28:16,050
What we're doing here is
looking at the percentages

673
00:28:16,050 --> 00:28:19,090
on the top row, the
percentages of the commonality

674
00:28:19,090 --> 00:28:20,320
of any one threat.

675
00:28:20,320 --> 00:28:22,730
And then we're comparing those percentages

676
00:28:22,730 --> 00:28:25,603
in groups of 20% chunks quintiles,

677
00:28:26,440 --> 00:28:28,240
and we're associating each quintiles

678
00:28:28,240 --> 00:28:30,030
with the maturity of the control.

679
00:28:30,030 --> 00:28:32,280
So quintiles went through five associated

680
00:28:32,280 --> 00:28:34,260
with maturity control one

681
00:28:34,260 --> 00:28:37,143
Quintiles of one through five
with material control two,

682
00:28:38,110 --> 00:28:39,719
and on for three, four, and five.

683
00:28:39,720 --> 00:28:41,720
And what we're trying to say is,

684
00:28:41,720 --> 00:28:44,930
if I can look at the
commonality of a certain attack

685
00:28:44,930 --> 00:28:46,680
in my preparation for that,

686
00:28:46,680 --> 00:28:50,170
I should be able to
prioritize a likelihood.

687
00:28:50,170 --> 00:28:51,090
Now I'm not saying

688
00:28:51,090 --> 00:28:54,350
I think this is probability
three out of five.

689
00:28:54,350 --> 00:28:57,129
I'm saying in terms of my likelihood,

690
00:28:57,130 --> 00:28:59,300
it's the third most likely
thing considering things

691
00:28:59,300 --> 00:29:01,010
that might happen more commonly.

692
00:29:01,010 --> 00:29:04,400
So this is a conceptual model.

693
00:29:04,400 --> 00:29:07,410
There isn't a likelihood or
a probabilistic, I'm sorry,

694
00:29:07,410 --> 00:29:10,640
there isn't a probabilistic
risk statistical model here.

695
00:29:10,640 --> 00:29:11,710
It can be implemented.

696
00:29:11,710 --> 00:29:13,570
You can use a log normal distribution

697
00:29:13,570 --> 00:29:17,270
or a bell-curve distribution
depends on a few things.

698
00:29:17,270 --> 00:29:19,560
And you can ask me when you would use each

699
00:29:19,560 --> 00:29:22,020
in our discussion after this.

700
00:29:22,020 --> 00:29:25,400
But if you're in an organization
where you have a control

701
00:29:25,400 --> 00:29:30,400
against the threat that
happens in the fifth quintile,

702
00:29:30,870 --> 00:29:32,729
it's the most common kind of attack.

703
00:29:32,730 --> 00:29:36,760
And you only have a level
two maturity of the control.

704
00:29:36,760 --> 00:29:38,650
You can expect that to
be a very common thing.

705
00:29:38,650 --> 00:29:42,010
You're not saying this
risk is this likely occur,

706
00:29:42,010 --> 00:29:45,350
you're saying this risk
when we have an incident,

707
00:29:45,350 --> 00:29:47,719
it's most likely to happen this way.

708
00:29:47,720 --> 00:29:49,890
And that's what we mean by tendencies.

709
00:29:49,890 --> 00:29:52,240
If I'm well-prepared for something
that doesn't happen often

710
00:29:52,240 --> 00:29:53,440
I've got a low tendency,

711
00:29:53,440 --> 00:29:56,162
I've got a high tendency for it to occur

712
00:29:56,162 --> 00:29:59,310
if I've got a very immature control

713
00:29:59,310 --> 00:30:01,453
against a very common threat, right?

714
00:30:02,560 --> 00:30:04,090
So now how do we bring it all together?

715
00:30:04,090 --> 00:30:07,580
Well, I've talked earlier about
duty of care risk analysis

716
00:30:07,580 --> 00:30:10,169
where you're looking at both
impacts and likelihoods,

717
00:30:10,170 --> 00:30:12,530
but you're looking at the
impacts and likelihoods

718
00:30:12,530 --> 00:30:14,860
that you could suffer and the impacts

719
00:30:14,860 --> 00:30:18,740
and likelihoods of risks
that others might suffer.

720
00:30:18,740 --> 00:30:22,250
There's a new definition
now for reasonable security.

721
00:30:22,250 --> 00:30:23,490
It's something that
people have been clamoring

722
00:30:23,490 --> 00:30:25,910
for it for years because regulations

723
00:30:25,910 --> 00:30:27,420
and information security standards say

724
00:30:27,420 --> 00:30:29,140
get to a reasonable control,

725
00:30:29,140 --> 00:30:31,250
but lawyers and regulators and judges

726
00:30:31,250 --> 00:30:33,810
have not come to agreement
on what this word means.

727
00:30:33,810 --> 00:30:36,117
There's a paper released in
February that lays all this out.

728
00:30:36,117 --> 00:30:38,350
And it asks us to look at the likelihood

729
00:30:38,350 --> 00:30:40,469
of perceivable threats,
and the potential harm

730
00:30:40,470 --> 00:30:43,090
that might come to ourselves and others.

731
00:30:43,090 --> 00:30:44,510
And what we're doing in that case

732
00:30:44,510 --> 00:30:48,830
is we're comparing one
state versus another to say

733
00:30:48,830 --> 00:30:51,830
is the burden of a control
worth it given the difference

734
00:30:51,830 --> 00:30:54,520
of the benefit so do
you wanna see something

735
00:30:54,520 --> 00:30:56,441
whether there's a talk tomorrow called

736
00:30:56,441 --> 00:30:59,420
your breach controls
may have been reasonable

737
00:30:59,420 --> 00:31:02,573
where we talk about this
paper, it's very important.

738
00:31:03,650 --> 00:31:05,470
If you're familiar with CIS RAM

739
00:31:05,470 --> 00:31:09,000
you'll recognize that's you're gonna apply

740
00:31:09,000 --> 00:31:12,430
duty of care risk analysis
to evaluate a risk by saying

741
00:31:12,430 --> 00:31:14,320
what are the impacts to me and others?

742
00:31:14,320 --> 00:31:16,070
And how likely would this be?

743
00:31:16,070 --> 00:31:18,139
If you were reading CIS Ram and saying

744
00:31:18,140 --> 00:31:20,940
but I'm frustrated and knowing
how to estimate likelihood

745
00:31:20,940 --> 00:31:22,820
you now have the guidance for doing that.

746
00:31:22,820 --> 00:31:26,950
And again, in CIS RAM 2.0,
you're gonna be able to use

747
00:31:26,950 --> 00:31:28,530
an automated way to do like we had

748
00:31:28,530 --> 00:31:30,410
from the various community data,

749
00:31:30,410 --> 00:31:32,290
using the methods that I showed you,

750
00:31:32,290 --> 00:31:35,420
and to compare a current
risk with a different risk

751
00:31:35,420 --> 00:31:36,970
after a safe card to determine

752
00:31:36,970 --> 00:31:39,237
whether it's a reasonable control.

753
00:31:39,237 --> 00:31:41,450
So what are you gonna do next week

754
00:31:41,450 --> 00:31:42,910
now that you know how to do this?

755
00:31:42,910 --> 00:31:45,460
I recommend that you get into the data,

756
00:31:45,460 --> 00:31:48,340
go to veriscommunity.net,
and download the CSV

757
00:31:48,340 --> 00:31:50,300
again if you're not
doing statistical work.

758
00:31:50,300 --> 00:31:52,007
And if you're very
comfortable with statistics

759
00:31:52,007 --> 00:31:52,980
and you're using R,

760
00:31:52,980 --> 00:31:57,010
then download the JSON
files and work back.

761
00:31:57,010 --> 00:32:00,050
You're gonna want to be
proficient with pivots,

762
00:32:00,050 --> 00:32:01,470
if you're using Excel,

763
00:32:01,470 --> 00:32:03,750
it doesn't take a whole
lot of time to do that,

764
00:32:03,750 --> 00:32:05,807
but it's really a good idea to use that.

765
00:32:05,807 --> 00:32:06,780
You gonna start to see

766
00:32:06,780 --> 00:32:08,830
where you can do aggregations and filters

767
00:32:09,871 --> 00:32:13,200
Three months from now,
what should you be doing?

768
00:32:13,200 --> 00:32:14,840
Well again, I highly
recommend that you use

769
00:32:14,840 --> 00:32:17,370
this likelihood data
for your risk analysis.

770
00:32:17,370 --> 00:32:22,290
We talked about a way to do
that with that slide rule.

771
00:32:22,290 --> 00:32:25,520
If you look at CIS RAM
2.0 when it comes out

772
00:32:25,520 --> 00:32:29,415
for implementation group
one in about June of 2021,

773
00:32:29,415 --> 00:32:30,965
so a couple of months from now.

774
00:32:31,990 --> 00:32:34,840
What you're gonna see is how
all of this stuff is automated,

775
00:32:34,840 --> 00:32:36,790
and you should be able to use
it in your whole environment

776
00:32:36,790 --> 00:32:38,580
to see if that works for you.

777
00:32:38,580 --> 00:32:40,710
You can extrapolate a lot
once you see that information

778
00:32:40,710 --> 00:32:43,530
it's for all, all breaches of all time,

779
00:32:43,530 --> 00:32:44,588
but it'll give you a
sense of how you can use

780
00:32:44,588 --> 00:32:47,639
that slide rule method
in your environment.

781
00:32:47,640 --> 00:32:49,350
Don't worry about being exactly correct.

782
00:32:49,350 --> 00:32:51,409
You're estimating using
a consistent method

783
00:32:51,410 --> 00:32:53,702
and that's really important not just

784
00:32:53,702 --> 00:32:56,110
for getting good management,

785
00:32:56,110 --> 00:32:58,072
but showing that you applying to care.

786
00:32:59,100 --> 00:33:00,760
You may want to work with a statistician

787
00:33:00,760 --> 00:33:03,490
if you wanna get that slide
rule to be based on evidence,

788
00:33:03,490 --> 00:33:04,323
there are ways to do that.

789
00:33:04,323 --> 00:33:05,480
Again, I'm happy to talk to you

790
00:33:05,480 --> 00:33:07,800
about that after this session.

791
00:33:07,800 --> 00:33:10,000
What should you be doing in six months?

792
00:33:10,000 --> 00:33:12,020
Well, you need to make risk analysis

793
00:33:12,020 --> 00:33:13,310
a regular part of what you're doing

794
00:33:13,310 --> 00:33:15,580
because those regulations
that you're operating under

795
00:33:15,580 --> 00:33:17,399
are telling you to do exactly that.

796
00:33:17,400 --> 00:33:19,990
You need risk-based
risk-based ways to look

797
00:33:19,990 --> 00:33:21,870
at for the foreseeable threats

798
00:33:21,870 --> 00:33:24,739
to be sure that what you're
paying attention to matters.

799
00:33:24,740 --> 00:33:26,423
And also to be sure that whatever controls

800
00:33:26,423 --> 00:33:28,700
you're putting in place are reasonable,

801
00:33:28,700 --> 00:33:30,280
the burden is reasonable given the rest

802
00:33:30,280 --> 00:33:32,139
of that you're facing.

803
00:33:32,140 --> 00:33:34,700
And check the various
community database periodically

804
00:33:34,700 --> 00:33:36,360
because it changes a
couple of times per year.

805
00:33:36,360 --> 00:33:38,620
And it'll help you keep up to date.

806
00:33:38,620 --> 00:33:40,669
I wanna thank you for taking part in this,

807
00:33:40,670 --> 00:33:42,260
and watching the presentation.

808
00:33:42,260 --> 00:33:43,330
I would really enjoy it,

809
00:33:43,330 --> 00:33:46,560
if you come talk to me about
this immediately after,

810
00:33:46,560 --> 00:33:47,919
we've got about 40 minutes in the chat,

811
00:33:47,920 --> 00:33:50,570
then I welcome you, look
forward to seeing you there.

