1
00:00:01,290 --> 00:00:03,740
- Hi, my name's Randall Brooks.

2
00:00:03,740 --> 00:00:05,480
I'm a Principal Engineering Fellow

3
00:00:05,480 --> 00:00:07,730
from Raytheon Technologies.

4
00:00:07,730 --> 00:00:12,410
And I am here with my good friend,

5
00:00:12,410 --> 00:00:15,240
Jon-Michael and he'll
introduce himself in a second

6
00:00:15,240 --> 00:00:17,170
to talk to you guys about,

7
00:00:17,170 --> 00:00:20,320
threat modeling from
architecture design application.

8
00:00:20,320 --> 00:00:25,320
I get to work a lot in what
we call software assurance

9
00:00:25,350 --> 00:00:29,190
and we focus on building
security into products,

10
00:00:29,190 --> 00:00:31,810
including threat modeling and
all those wonderful things

11
00:00:31,810 --> 00:00:33,650
that we're gonna talk about today.

12
00:00:33,650 --> 00:00:35,900
In fact, I actually do cyber learning

13
00:00:35,900 --> 00:00:37,809
and cyber training across the company.

14
00:00:37,810 --> 00:00:40,420
And it's, I'm very happy to be here

15
00:00:40,420 --> 00:00:44,190
and talk to you guys
today about this topic.

16
00:00:44,190 --> 00:00:46,690
- Excellent, and I'm Jon-Michael Brook.

17
00:00:46,690 --> 00:00:48,559
I'm a principal architect at Starbucks

18
00:00:48,560 --> 00:00:50,960
and a Cloud Research Fellow

19
00:00:50,960 --> 00:00:52,350
with the Cloud Security Alliance.

20
00:00:52,350 --> 00:00:55,740
I also share our top
Brett's working group.

21
00:00:55,740 --> 00:00:59,430
And one of the recent
projects that we've worked on

22
00:00:59,430 --> 00:01:02,570
within that group is cloud threat model.

23
00:01:02,570 --> 00:01:05,830
- All right, so what were the
things we're gonna focus on is

24
00:01:05,830 --> 00:01:07,450
what is threat modeling,

25
00:01:07,450 --> 00:01:09,760
how does this really apply to what you do

26
00:01:09,760 --> 00:01:11,840
in your day in day life?

27
00:01:11,840 --> 00:01:14,510
You know how to go about it,
sometimes it's very hard.

28
00:01:14,510 --> 00:01:17,830
In fact, I've been teaching
folks how to do threat modeling

29
00:01:17,830 --> 00:01:18,740
for a long time.

30
00:01:18,740 --> 00:01:22,390
And sometimes it's just
not for certain folks

31
00:01:22,390 --> 00:01:25,400
but we're gonna hopefully
give you things to think about

32
00:01:25,400 --> 00:01:28,910
as you go through looking
at the applications

33
00:01:28,910 --> 00:01:31,009
that you're basically migrating

34
00:01:31,010 --> 00:01:33,750
or things that you wanna
target for the cloud.

35
00:01:33,750 --> 00:01:36,440
How might you go about thinking about that

36
00:01:36,440 --> 00:01:38,730
with respect to threat modeling?

37
00:01:38,730 --> 00:01:40,860
Now, for me, I have to,

38
00:01:40,860 --> 00:01:45,100
I get to work in a government type work.

39
00:01:45,100 --> 00:01:49,449
So we focus on things such as the NIST,

40
00:01:49,450 --> 00:01:52,060
of Special Publication 800 series

41
00:01:52,060 --> 00:01:55,330
and in the recent revision of five,

42
00:01:55,330 --> 00:01:58,220
which is focusing on
their security controls

43
00:01:58,220 --> 00:01:59,700
and we're talking about clouds.

44
00:01:59,700 --> 00:02:01,690
So we're gonna talk about
the Cloud Controls Matrix

45
00:02:01,690 --> 00:02:05,270
which is a similar set of
controls that's out there.

46
00:02:05,270 --> 00:02:07,080
But one of the things they have in there

47
00:02:07,080 --> 00:02:10,570
is the System and Services Acquisition 11,

48
00:02:10,570 --> 00:02:12,730
developer testing and evaluation.

49
00:02:12,730 --> 00:02:16,638
And this is focusing
on really understanding

50
00:02:16,639 --> 00:02:19,340
your attack surface.

51
00:02:19,340 --> 00:02:22,620
How might your systems be attacked,

52
00:02:22,620 --> 00:02:26,600
how might you go about
validating that and so forth?

53
00:02:26,600 --> 00:02:29,549
Then one of the things
specifically as they call out here

54
00:02:29,550 --> 00:02:32,510
is threat modeling and
vulnerability analysis.

55
00:02:32,510 --> 00:02:35,380
Now, one of the things that they call out

56
00:02:35,380 --> 00:02:37,720
which I think folks really struggle on

57
00:02:37,720 --> 00:02:42,140
is conducting threat analysis
to a certain level of rigor.

58
00:02:42,140 --> 00:02:44,820
And that level of rigor is very difficult

59
00:02:44,820 --> 00:02:46,630
for folks to really understand

60
00:02:46,630 --> 00:02:50,049
and how far do I keep going
with my threat modeling?

61
00:02:50,050 --> 00:02:52,470
And we're hopefully
gonna have a good example

62
00:02:52,470 --> 00:02:56,810
for you guys upcoming that'll
help you really understand

63
00:02:56,810 --> 00:02:58,530
what's really meant by that

64
00:02:58,530 --> 00:03:01,760
and how you be able to
apply this and what you do.

65
00:03:01,760 --> 00:03:03,799
One of the things about threat modeling is

66
00:03:03,800 --> 00:03:06,870
you wanna focus on really a system centric

67
00:03:06,870 --> 00:03:10,420
or a defensive way of looking at a system.

68
00:03:10,420 --> 00:03:13,410
You really as a someone
who creates systems

69
00:03:13,410 --> 00:03:15,150
you wanna think about

70
00:03:15,150 --> 00:03:17,490
any ways that the system can be interacted

71
00:03:17,490 --> 00:03:20,420
what potential threats
that might be, how likely,

72
00:03:20,420 --> 00:03:23,179
you know, what means what they
might go about attacking you

73
00:03:23,180 --> 00:03:25,000
maybe you have an external interface

74
00:03:25,000 --> 00:03:26,780
or something along that line.

75
00:03:26,780 --> 00:03:30,370
You know, what avenues
would they be going through

76
00:03:30,370 --> 00:03:33,220
maybe that you have a partner network

77
00:03:33,220 --> 00:03:34,780
that you communicate to

78
00:03:34,780 --> 00:03:38,010
and that partner network gives access into

79
00:03:38,010 --> 00:03:40,100
some of your backend systems.

80
00:03:40,100 --> 00:03:42,510
Then start to think about prioritizing

81
00:03:43,370 --> 00:03:45,810
the risks and to start to mitigate those

82
00:03:45,810 --> 00:03:48,420
and then design that system out,

83
00:03:48,420 --> 00:03:52,130
model it, start to decompose
it, step through each section

84
00:03:52,130 --> 00:03:54,010
and then look ways

85
00:03:54,010 --> 00:03:56,750
for various different
attacks against that.

86
00:03:56,750 --> 00:03:59,760
One of the fun things we also get to do is

87
00:03:59,760 --> 00:04:03,829
think about what an
attacker really might do.

88
00:04:03,830 --> 00:04:05,130
You know, what is their techniques

89
00:04:05,130 --> 00:04:07,370
that they might go about
attacking a system.

90
00:04:07,370 --> 00:04:10,610
And you're really gonna start to kind of,

91
00:04:10,610 --> 00:04:13,420
and I use this term a lot,
and it's in one of the slides

92
00:04:13,420 --> 00:04:15,459
it's like building your think evil gene

93
00:04:15,460 --> 00:04:18,149
and thinking about how can you go about

94
00:04:18,149 --> 00:04:19,570
bringing the system down,

95
00:04:19,570 --> 00:04:23,240
thinking about how might
attacker might subvert a system

96
00:04:23,240 --> 00:04:27,650
and really bring it to its knees.

97
00:04:27,650 --> 00:04:29,659
So there's gonna be certain
goals that you'll wanna do.

98
00:04:29,660 --> 00:04:31,420
Maybe it's going to be,

99
00:04:31,420 --> 00:04:35,570
you know, spoof a certain entity type or,

100
00:04:35,570 --> 00:04:37,700
you know, reproduce certain credentials

101
00:04:37,700 --> 00:04:39,760
or something along that line.

102
00:04:39,760 --> 00:04:42,810
But there are certain goals
that folks will wanna get to.

103
00:04:42,810 --> 00:04:44,930
And as they break down those goals

104
00:04:44,930 --> 00:04:46,677
they'll really understand how might that,

105
00:04:46,677 --> 00:04:49,500
you know, what might be
their avenue of attack

106
00:04:49,500 --> 00:04:51,480
and how it goes through.

107
00:04:51,480 --> 00:04:53,210
Now, a lot of times

108
00:04:53,210 --> 00:04:56,020
the actual attack portion of the modeling

109
00:04:56,020 --> 00:04:58,520
happens as an output of the threat models.

110
00:04:58,520 --> 00:05:01,630
So folks might present their threat model

111
00:05:01,630 --> 00:05:04,530
and folks kind of skilled in the arts

112
00:05:04,530 --> 00:05:06,380
a lot of Def Con attenders,

113
00:05:06,380 --> 00:05:08,700
those types of folks
might take a look at that

114
00:05:08,700 --> 00:05:11,150
and say, you know I can
do this, this and this

115
00:05:11,150 --> 00:05:12,859
and I can attack your system

116
00:05:12,860 --> 00:05:15,950
and maybe potentially bring it down.

117
00:05:15,950 --> 00:05:19,370
And so you'll look at all
of those likely responses

118
00:05:19,370 --> 00:05:22,200
and what might the application go about

119
00:05:22,200 --> 00:05:24,620
to do to defend against that?

120
00:05:24,620 --> 00:05:26,120
Now, as you do this

121
00:05:26,120 --> 00:05:28,460
you're going to actually
produce something.

122
00:05:28,460 --> 00:05:30,430
And one of the things you'll produce is

123
00:05:30,430 --> 00:05:32,050
certain attack patterns.

124
00:05:32,050 --> 00:05:36,330
You might extend and
come out with use cases,

125
00:05:36,330 --> 00:05:39,520
abuse cases, misuse cases
however, you want to describe it

126
00:05:39,520 --> 00:05:41,340
but basically all the bad things

127
00:05:41,340 --> 00:05:44,690
that could be done to
a system and so forth.

128
00:05:44,690 --> 00:05:47,040
And one of the things
we're gonna delve into

129
00:05:47,040 --> 00:05:49,710
is attack trees and attack graphs.

130
00:05:49,710 --> 00:05:51,620
And so we're gonna graph out a system,

131
00:05:51,620 --> 00:05:53,370
we're gonna walk through that

132
00:05:53,370 --> 00:05:56,900
and talk about those types of attacks.

133
00:05:56,900 --> 00:06:00,710
Now, this is one of my favorite slides

134
00:06:00,710 --> 00:06:04,599
and it really simplifies threat modeling

135
00:06:04,600 --> 00:06:07,580
into some specific ideas,

136
00:06:07,580 --> 00:06:09,940
in that what is it that you wanna protect,

137
00:06:09,940 --> 00:06:11,920
who do you wanna protect it from,

138
00:06:11,920 --> 00:06:13,760
how likely we need to protect it?

139
00:06:13,760 --> 00:06:14,740
And that's always a hard one

140
00:06:14,740 --> 00:06:17,810
'cause that tends to go to
probability of occurrence, right?

141
00:06:17,810 --> 00:06:20,600
And then how bad is it if you fail,

142
00:06:20,600 --> 00:06:22,580
and then off course, how
much money do you have,

143
00:06:22,580 --> 00:06:25,169
how likely are you to go about the spend

144
00:06:25,170 --> 00:06:27,160
that kind of money to defend?

145
00:06:27,160 --> 00:06:28,900
I can't defend against everything

146
00:06:28,900 --> 00:06:31,299
so that's why threat
modeling is so important.

147
00:06:31,300 --> 00:06:33,930
You can't defend everything, right?

148
00:06:33,930 --> 00:06:35,813
So if you can focus on what's,

149
00:06:36,710 --> 00:06:38,919
you know, the highest probable thing

150
00:06:38,920 --> 00:06:41,330
that could potentially cause damage

151
00:06:41,330 --> 00:06:43,270
to your system or application

152
00:06:43,270 --> 00:06:44,900
then that's what you wanna focus on.

153
00:06:44,900 --> 00:06:48,359
So these are the core things
you really want to think about.

154
00:06:48,360 --> 00:06:51,890
Now, I originally got this from MIT

155
00:06:51,890 --> 00:06:53,280
course that was online

156
00:06:53,280 --> 00:06:56,929
but I've seen it reproduced
in many different subjects.

157
00:06:56,930 --> 00:07:01,130
So I do really like this
kind of simple thought

158
00:07:01,130 --> 00:07:02,100
of what do you wanna protect,

159
00:07:02,100 --> 00:07:03,200
who do you wanna protect it from,

160
00:07:03,200 --> 00:07:04,610
and how much money do you have,

161
00:07:04,610 --> 00:07:07,853
how likely will you need
to protect that system?

162
00:07:08,720 --> 00:07:13,000
Now, Microsoft has done
a great service really

163
00:07:13,000 --> 00:07:16,240
to the industry and really
thought about threat modeling.

164
00:07:16,240 --> 00:07:19,930
In fact, they have a whole
tool to do threat modeling.

165
00:07:19,930 --> 00:07:22,960
So they came up with five steps

166
00:07:22,960 --> 00:07:25,390
really to go through with respect to that,

167
00:07:25,390 --> 00:07:29,700
because it's not just the
diagramming and really,

168
00:07:29,700 --> 00:07:31,630
you know, thinking about the system

169
00:07:31,630 --> 00:07:35,380
but there's a lot more
things to really consider.

170
00:07:35,380 --> 00:07:37,020
And one of the things that you wanna do

171
00:07:37,020 --> 00:07:38,950
is really kind of think
about your requirements

172
00:07:38,950 --> 00:07:42,240
that you might have, define
all those and lay them out

173
00:07:42,240 --> 00:07:43,840
maybe track them,

174
00:07:43,840 --> 00:07:47,640
in some sort of tracking
requirements, tracking database.

175
00:07:47,640 --> 00:07:52,590
And then as you create that application

176
00:07:52,590 --> 00:07:55,652
then you can diagram it out,

177
00:07:56,600 --> 00:07:58,530
you know, take an architecture,

178
00:07:58,530 --> 00:08:02,222
lay it out, model the
system, come up with,

179
00:08:03,080 --> 00:08:04,800
you know, particular threats

180
00:08:04,800 --> 00:08:06,250
that might go against the system.

181
00:08:06,250 --> 00:08:08,110
Now, off course, a lot of the stuff

182
00:08:08,110 --> 00:08:10,520
we're gonna emphasize later is on the work

183
00:08:10,520 --> 00:08:12,490
that the cloud security lines does.

184
00:08:12,490 --> 00:08:15,790
And so that'll really help
with the identifying of threats

185
00:08:15,790 --> 00:08:19,920
and then coming up with
ways to mitigating threats

186
00:08:19,920 --> 00:08:22,610
with respect to that, and then validating

187
00:08:22,610 --> 00:08:26,500
that those threats have
been mitigated over time.

188
00:08:26,500 --> 00:08:29,010
And we have a link down
there to Microsoft's work

189
00:08:29,010 --> 00:08:30,223
in threat modeling.

190
00:08:31,710 --> 00:08:35,870
This is always, also another
good one we have overlaid here.

191
00:08:35,870 --> 00:08:38,900
Some of the work that the
MITRE corporation has done

192
00:08:38,900 --> 00:08:43,459
with respect to what they call
making a security measurable

193
00:08:43,460 --> 00:08:46,170
and one of the things they
have in there is CAPEC

194
00:08:46,170 --> 00:08:48,459
their common attack, pattern, enumeration

195
00:08:48,460 --> 00:08:49,910
and classification.

196
00:08:49,910 --> 00:08:50,742
So the kind of,

197
00:08:50,743 --> 00:08:52,990
so what you're looking here
is you're thinking about

198
00:08:52,990 --> 00:08:54,270
known threat actors.

199
00:08:54,270 --> 00:08:55,689
These are the guys that you know

200
00:08:55,690 --> 00:08:59,140
may potentially be targeting your system.

201
00:08:59,140 --> 00:09:01,750
What attacks might they go through

202
00:09:01,750 --> 00:09:03,620
and CAPECs really good
at helping you that.

203
00:09:03,620 --> 00:09:06,360
Also the MITRE attack framework

204
00:09:06,360 --> 00:09:07,620
is something to also consider

205
00:09:07,620 --> 00:09:10,540
and we'll talk a little
bit about that later.

206
00:09:10,540 --> 00:09:14,219
And then as you code your application

207
00:09:14,220 --> 00:09:15,520
you'll have,

208
00:09:15,520 --> 00:09:18,520
what we like to call
Common Weakness Enumeration

209
00:09:18,520 --> 00:09:19,670
And those are,

210
00:09:19,670 --> 00:09:22,420
potential things that you
may become vulnerabilities,

211
00:09:22,420 --> 00:09:24,370
they're not yet vulnerabilities right now

212
00:09:24,370 --> 00:09:27,290
but an attacker might
be able to leverage that

213
00:09:27,290 --> 00:09:30,050
and create a specific vulnerability.

214
00:09:30,050 --> 00:09:33,640
Now, of course, you'll have other impacts

215
00:09:33,640 --> 00:09:35,319
other controls that you'll apply

216
00:09:35,320 --> 00:09:37,350
and that will have a resultant impact

217
00:09:37,350 --> 00:09:39,870
based on how you've
applied those controls.

218
00:09:39,870 --> 00:09:42,460
And so we're trying to
kind of get you think about

219
00:09:42,460 --> 00:09:45,370
you know, attacker does
this bad thing to my code

220
00:09:45,370 --> 00:09:47,870
but I've got this wonderful
thing to protect it.

221
00:09:47,870 --> 00:09:50,240
Or I'm in a defense in depth scenario

222
00:09:50,240 --> 00:09:52,700
where I've got more
than one layered control

223
00:09:52,700 --> 00:09:55,710
to mitigate that risk and mitigate that

224
00:09:55,710 --> 00:09:57,173
as we go through time.

225
00:09:58,390 --> 00:10:02,560
All right, so we talked
about attack models.

226
00:10:02,560 --> 00:10:06,189
So let's give an example really here on

227
00:10:06,190 --> 00:10:07,890
what would this look like.

228
00:10:07,890 --> 00:10:09,720
Now, attack modeling's fun.

229
00:10:09,720 --> 00:10:11,990
You get to assume the role of attacker,

230
00:10:11,990 --> 00:10:16,990
you know, you get to take a
look at each kind of threat

231
00:10:18,550 --> 00:10:21,969
and then apply those against
your particular target.

232
00:10:21,970 --> 00:10:24,650
You know, you don't need
to go through the firewall

233
00:10:24,650 --> 00:10:27,230
if you can trick someone
to do something, right?

234
00:10:27,230 --> 00:10:30,680
So however, someone might
go about getting their goals

235
00:10:30,680 --> 00:10:32,729
so go step one, step two, step three

236
00:10:32,730 --> 00:10:35,570
and what's depicted here
is from a Microsoft article

237
00:10:35,570 --> 00:10:39,450
on basically how to obtain
credentials over the network

238
00:10:39,450 --> 00:10:42,510
but you'll go through various different,

239
00:10:42,510 --> 00:10:46,350
steps that you'll go
through trying to achieve

240
00:10:46,350 --> 00:10:48,300
what you would like to do.

241
00:10:48,300 --> 00:10:50,170
Now, there's a lot of products out there

242
00:10:50,170 --> 00:10:52,760
that will help you walk
through these types of things.

243
00:10:52,760 --> 00:10:55,960
And to be honest, I've
seen Visio, PowerPoint

244
00:10:55,960 --> 00:11:00,610
you know, basically box and
arrow and problem and so forth.

245
00:11:00,610 --> 00:11:05,110
Now, the hard part is getting
to the kind of the end state

246
00:11:05,110 --> 00:11:07,200
like how do I understand that end state,

247
00:11:07,200 --> 00:11:09,030
where do I need to stop?

248
00:11:09,030 --> 00:11:11,050
And that's what we're gonna focus on here

249
00:11:11,050 --> 00:11:13,109
with this next example.

250
00:11:13,110 --> 00:11:17,150
So, we're gonna pretend
it's Christmas time

251
00:11:17,150 --> 00:11:20,770
and it's time to watch a
wonderful Christmas movie

252
00:11:20,770 --> 00:11:22,217
called "Home Alone."

253
00:11:22,217 --> 00:11:25,140
In it, surprisingly, you
probably didn't know this,

254
00:11:25,140 --> 00:11:29,069
and at least we'll make the
assertion is an attack tree.

255
00:11:29,070 --> 00:11:33,380
And so we'll go through this
example here and talk about

256
00:11:33,380 --> 00:11:36,280
how each step that was done

257
00:11:36,280 --> 00:11:38,480
in this particular set of attacks

258
00:11:38,480 --> 00:11:42,290
and how things went from
a defensive perspective

259
00:11:42,290 --> 00:11:44,480
and how Kevin McCallister,

260
00:11:44,480 --> 00:11:47,310
who's going to defend his family home

261
00:11:47,310 --> 00:11:49,369
because he was left home alone.

262
00:11:49,370 --> 00:11:51,010
How is he gonna go about to do that?

263
00:11:51,010 --> 00:11:55,590
So the way it's depicted here
is really an attack defense

264
00:11:55,590 --> 00:11:57,240
or you might use the word countermeasure

265
00:11:57,240 --> 00:12:00,040
whichever is your appropriate
term that you'd like to use.

266
00:12:00,040 --> 00:12:01,730
So an attack countermeasure,

267
00:12:01,730 --> 00:12:03,410
attack countermeasure

268
00:12:03,410 --> 00:12:07,093
and what's depicted
over on the right there

269
00:12:07,094 --> 00:12:09,500
is really the whole graph laid out.

270
00:12:09,500 --> 00:12:13,683
But one of the things that
started off the folks really,

271
00:12:15,690 --> 00:12:18,940
Harry and Marv they went
and kind of looked out

272
00:12:18,940 --> 00:12:20,420
and kind of knocked on every door

273
00:12:20,420 --> 00:12:21,839
and said, hey you know where the police,

274
00:12:21,840 --> 00:12:23,170
you know, wanna find out

275
00:12:23,170 --> 00:12:26,236
which kind of mechanisms you've got to,

276
00:12:26,236 --> 00:12:29,220
you know, defend your house
during this Christmas season

277
00:12:29,220 --> 00:12:31,430
we'd hate for you to get
robbed or something like that.

278
00:12:31,430 --> 00:12:34,069
So they're out there already,

279
00:12:34,070 --> 00:12:36,770
you know, figuring out what's out there,

280
00:12:36,770 --> 00:12:40,540
looking at the infrastructure
and trying to understand,

281
00:12:40,540 --> 00:12:42,819
you know, what kind of
defenses are in place

282
00:12:42,820 --> 00:12:44,660
and their expectation is

283
00:12:44,660 --> 00:12:48,850
that no one's there, there'll
be able to bust right in,

284
00:12:48,850 --> 00:12:52,127
you know, there is no actual
alarm, there's a sign that says

285
00:12:52,127 --> 00:12:54,930
you know, security system and so forth

286
00:12:54,930 --> 00:12:56,550
but there's no actual alarm, right?

287
00:12:56,550 --> 00:13:00,620
So as they kind of start
through their little steps,

288
00:13:00,620 --> 00:13:01,490
they have this goal.

289
00:13:01,490 --> 00:13:03,040
Off course, this is the attacker's goal

290
00:13:03,040 --> 00:13:05,250
is to rob the McCallister's house.

291
00:13:05,250 --> 00:13:06,630
So the first thing they do

292
00:13:06,630 --> 00:13:08,860
they actually do find
out that Kevin is there.

293
00:13:08,860 --> 00:13:11,360
So they actually go to a side door,

294
00:13:11,360 --> 00:13:14,420
it's towards the back,
it's right by the kitchen

295
00:13:14,420 --> 00:13:15,252
and they kind of trick Kevin.

296
00:13:15,253 --> 00:13:18,930
He's like, you know, hey, we
got some candy opened the door

297
00:13:18,930 --> 00:13:21,959
you know, we're the good
guys, let us in the house.

298
00:13:21,960 --> 00:13:25,350
And Kevin has already
kind of thought about ways

299
00:13:25,350 --> 00:13:29,090
that he might be attacked and
he's laid out his defenses

300
00:13:29,090 --> 00:13:33,560
to mitigate any potential
incursion by Harry and Marv.

301
00:13:33,560 --> 00:13:34,780
So the first thing he does

302
00:13:34,780 --> 00:13:37,490
is shoot Harry and Marv with the BB gun.

303
00:13:37,490 --> 00:13:40,640
Now, off course, that does help them learn

304
00:13:40,640 --> 00:13:42,819
that was a huge mistake on their part.

305
00:13:42,820 --> 00:13:45,440
And they decide that, you
know what we're gonna do.

306
00:13:45,440 --> 00:13:48,500
We're going to really
double up our attack.

307
00:13:48,500 --> 00:13:52,100
Harry is going to go
around to the front door.

308
00:13:52,100 --> 00:13:55,040
Well, Marv is going to go
down to the basement door

309
00:13:55,040 --> 00:13:57,260
which was actually right next to the door

310
00:13:57,260 --> 00:13:58,703
in which they started at.

311
00:13:59,870 --> 00:14:02,920
Now, Kevin has really thought this out

312
00:14:02,920 --> 00:14:04,130
and he's laid out his defense.

313
00:14:04,130 --> 00:14:07,550
He's put water on all the
steps so he's iced them up.

314
00:14:07,550 --> 00:14:09,589
They fall, they get hurt,

315
00:14:09,590 --> 00:14:11,210
you know, they're limping after this,

316
00:14:11,210 --> 00:14:15,410
they're both trying to
reel from this event.

317
00:14:15,410 --> 00:14:19,500
But now what they do is they
slowly walk up the stairs

318
00:14:19,500 --> 00:14:22,310
and kind of think about
how they're going to attack

319
00:14:22,310 --> 00:14:23,979
as they go on.

320
00:14:23,980 --> 00:14:27,390
Now, Marv has actually
fell all the way downstairs

321
00:14:27,390 --> 00:14:29,960
at this point, he's in
the basement floor now.

322
00:14:29,960 --> 00:14:32,710
And he uses a crowbar
and he has some success

323
00:14:32,710 --> 00:14:35,740
and he enters the McCallister's house.

324
00:14:35,740 --> 00:14:37,280
Unfortunately, he hasn't won yet.

325
00:14:37,280 --> 00:14:40,490
He's got a lot more to go,
but he's making some success.

326
00:14:40,490 --> 00:14:43,641
And that does happen
sometimes in threat models.

327
00:14:43,641 --> 00:14:46,010
You'll come out with an attack defense,

328
00:14:46,010 --> 00:14:48,380
attack defense and your,

329
00:14:48,380 --> 00:14:49,939
the person exploiting you

330
00:14:49,940 --> 00:14:51,610
might come up with maybe something

331
00:14:51,610 --> 00:14:53,140
that is a little bit successful

332
00:14:53,140 --> 00:14:57,750
and as such you wanna keep
going with your attack tree.

333
00:15:00,270 --> 00:15:03,810
Now, as a defense Kevin

334
00:15:05,020 --> 00:15:07,530
against for Harry

335
00:15:07,530 --> 00:15:10,459
as he's trying to enter the front door,

336
00:15:10,460 --> 00:15:15,460
he uses an electric grill
starter in burns Harry's hand.

337
00:15:15,684 --> 00:15:19,016
So that kind of stops Harry at that point.

338
00:15:19,017 --> 00:15:20,450
And one of the things you'll notice

339
00:15:20,450 --> 00:15:23,030
we'll have an end of attack.

340
00:15:23,030 --> 00:15:25,850
There are certain things
you might do as defender

341
00:15:25,850 --> 00:15:29,060
that might cause the
defender to just give up

342
00:15:29,060 --> 00:15:31,800
this avenue is not gonna work.

343
00:15:31,800 --> 00:15:34,189
Maybe they're trying to fuzz the system

344
00:15:34,190 --> 00:15:37,060
or launch various different
attacks, or they're trying

345
00:15:37,060 --> 00:15:40,329
to brute force your
authentication strategy.

346
00:15:40,330 --> 00:15:42,430
You know, they're trying
to denial our service

347
00:15:42,430 --> 00:15:45,400
your cloud service provider whoever it is,

348
00:15:45,400 --> 00:15:47,860
you know, they're trying to stop.

349
00:15:47,860 --> 00:15:48,990
And then there's a point in which

350
00:15:48,990 --> 00:15:51,510
that attack is just no longer gonna work.

351
00:15:51,510 --> 00:15:54,200
But like I said for Marv,
he's had some success.

352
00:15:54,200 --> 00:15:57,980
And so Marv is entering the house.

353
00:15:57,980 --> 00:15:59,640
He's coming through the basement

354
00:15:59,640 --> 00:16:04,600
and Kevin drops a iron on Marv's head.

355
00:16:04,600 --> 00:16:08,430
He rigged it up and it
burns Marv off course,

356
00:16:08,430 --> 00:16:11,489
but now he's still making some success.

357
00:16:11,490 --> 00:16:14,500
So he's going to attempt to
climb the basement stairs.

358
00:16:14,500 --> 00:16:16,750
Now, finishing out Marv,

359
00:16:16,750 --> 00:16:18,560
one of the things that Kevin has done

360
00:16:18,560 --> 00:16:22,310
is besides destroyed his
entire house at this point,

361
00:16:22,310 --> 00:16:25,060
has put tar on the ground

362
00:16:25,060 --> 00:16:27,900
and that this causes
things get very sticky.

363
00:16:27,900 --> 00:16:31,030
He pulls, you know, loses
his shoes and so forth.

364
00:16:31,030 --> 00:16:33,890
Just like if you're using
things like honeypots

365
00:16:33,890 --> 00:16:35,990
you might have tarping technology

366
00:16:35,990 --> 00:16:38,340
that might slow down your attacker

367
00:16:38,340 --> 00:16:42,380
and cause them to maybe reveal
themselves and so forth.

368
00:16:42,380 --> 00:16:45,390
Now, he's going to put a tar on there

369
00:16:45,390 --> 00:16:46,949
and he ends up stepping on a nail.

370
00:16:46,950 --> 00:16:49,780
And for some reason, he
actually gives up at this point

371
00:16:49,780 --> 00:16:52,270
and his end of attack ends at that point,

372
00:16:52,270 --> 00:16:55,290
he's given up on the basement,
he leaves and actually

373
00:16:56,930 --> 00:16:59,120
comes up with a new attack.

374
00:16:59,120 --> 00:17:02,590
Now, Harry starting his new attack.

375
00:17:02,590 --> 00:17:03,990
He comes back around

376
00:17:03,990 --> 00:17:07,069
to that kitchen door where
they first met Kevin.

377
00:17:07,069 --> 00:17:08,849
They knocked down that door.

378
00:17:08,849 --> 00:17:12,569
And, but as he does open it up

379
00:17:12,569 --> 00:17:16,143
there's a flame thrower and
it burns Harry on the hand.

380
00:17:16,143 --> 00:17:20,990
Now, he's leased inside the
house and he sees Kevin,

381
00:17:20,990 --> 00:17:23,710
he yells at him, he
enters the dining room.

382
00:17:23,710 --> 00:17:27,829
Now, at the same time Marv
has, went around to a window,

383
00:17:27,829 --> 00:17:29,220
opened the window.

384
00:17:29,220 --> 00:17:32,450
Kevin has laid out broken glass ornaments

385
00:17:34,235 --> 00:17:38,919
for him to step on and of
course he hurts his feet

386
00:17:38,920 --> 00:17:42,380
which he lost his shoes
at the tar and so forth.

387
00:17:42,380 --> 00:17:44,383
But for Harry,

388
00:17:45,270 --> 00:17:48,530
Kevin actually has a thing
where he runs chasing Kevin,

389
00:17:48,530 --> 00:17:51,660
he runs through, gets
saran wrap all over him

390
00:17:51,660 --> 00:17:53,890
and he blows feathers on him.

391
00:17:53,890 --> 00:17:54,723
At that point,

392
00:17:54,723 --> 00:17:57,190
they've decided that
they're two separate attacks

393
00:17:57,190 --> 00:17:58,700
is not gonna work.

394
00:17:58,700 --> 00:18:02,390
And so they're gonna join
forces, double up on the defense

395
00:18:02,390 --> 00:18:05,930
and attempt to go up the stairs.

396
00:18:05,930 --> 00:18:08,680
Well, Kevin has placed micro mini machines

397
00:18:08,680 --> 00:18:10,510
a great toy from the 80's

398
00:18:10,510 --> 00:18:12,943
something in the 90's too what,

399
00:18:14,210 --> 00:18:16,330
they fall hurt themselves as so forth

400
00:18:16,330 --> 00:18:18,919
but there's still, you know, determined.

401
00:18:18,920 --> 00:18:22,720
They are going to compromise
this particular facility

402
00:18:22,720 --> 00:18:24,550
there's house, they want it.

403
00:18:24,550 --> 00:18:26,530
They're going to,

404
00:18:26,530 --> 00:18:28,790
you know, keep following
Kevin up the stairs.

405
00:18:28,790 --> 00:18:30,780
Now, he's gonna swing cans.

406
00:18:30,780 --> 00:18:33,139
He actually swings them
individually, misses one

407
00:18:33,140 --> 00:18:36,880
but then hits them later when
he thinks he's dodged it.

408
00:18:36,880 --> 00:18:39,550
Now, they're very wary of
what Kevin's going to do.

409
00:18:39,550 --> 00:18:44,250
And as Kevin tries to
defend against their attack

410
00:18:44,250 --> 00:18:46,320
now they're slowly coming up the stairs

411
00:18:46,320 --> 00:18:48,689
definitely moving slower,
looking for things

412
00:18:48,690 --> 00:18:51,360
like they're always kind of
like, you know, looking out

413
00:18:51,360 --> 00:18:53,550
you know, what's gonna get me next.

414
00:18:53,550 --> 00:18:55,460
So Kevin has set up a trip wire

415
00:18:55,460 --> 00:18:58,810
and he calls the police
to a neighbor's house

416
00:18:58,810 --> 00:19:01,030
not actually to his own
house, but a neighbor's house

417
00:19:01,030 --> 00:19:03,580
because Kevin is part of
Kevin's defensive plan.

418
00:19:03,580 --> 00:19:06,520
That is the avenue in
which he's decided to take.

419
00:19:06,520 --> 00:19:11,520
Now, the attack Marv does
a dive grab Kevin's foot

420
00:19:12,910 --> 00:19:15,000
does get ahold of him,

421
00:19:15,000 --> 00:19:19,170
but luckily for Kevin his
brother's tarantula is available

422
00:19:19,170 --> 00:19:22,680
and he places that
tarantula on Marv's head.

423
00:19:22,680 --> 00:19:25,030
Now, the attack

424
00:19:26,060 --> 00:19:28,909
they basically wanna
follow Kevin upstairs.

425
00:19:28,910 --> 00:19:31,690
Kevin has a defense where
he's already set up a zip line

426
00:19:31,690 --> 00:19:34,690
to zip over to the tree house.

427
00:19:34,690 --> 00:19:37,670
And of course they wanna
follow that zip line

428
00:19:37,670 --> 00:19:40,740
but Kevin's defense has got
already got the scissors

429
00:19:40,740 --> 00:19:45,050
there are sheers to cut down
that zip line and so forth.

430
00:19:45,050 --> 00:19:49,210
So they see Kevin going over
to the neighbor's house.

431
00:19:49,210 --> 00:19:52,120
Now, since they have knowledge
of this particular home

432
00:19:52,120 --> 00:19:54,860
since they've already
compromised it themselves

433
00:19:54,860 --> 00:19:58,770
they actually evade as Kevin
enters through the basement

434
00:20:00,120 --> 00:20:02,969
they end up capturing
Kevin as he comes upstairs

435
00:20:02,970 --> 00:20:06,500
'cause they already knew
that he would be there.

436
00:20:06,500 --> 00:20:10,150
So the question is did they win,

437
00:20:10,150 --> 00:20:13,493
did they achieve what they intended to do?

438
00:20:15,370 --> 00:20:17,810
Now, unfortunately, not

439
00:20:18,670 --> 00:20:21,150
a neighbor actually comes to the rescue

440
00:20:21,150 --> 00:20:24,900
hits Harry and Marv on
the head with a shovel,

441
00:20:24,900 --> 00:20:26,480
the police arrive

442
00:20:26,480 --> 00:20:29,070
and at that point it's
really the end of attack.

443
00:20:29,070 --> 00:20:31,740
But so a question you might have is

444
00:20:31,740 --> 00:20:33,290
I just spent five minutes

445
00:20:33,290 --> 00:20:35,670
and you told me about a Christmas movie

446
00:20:35,670 --> 00:20:39,500
again, what does that have
to do with cybersecurity?

447
00:20:39,500 --> 00:20:43,050
Now it's attack a defend, attack defend

448
00:20:43,050 --> 00:20:44,990
and you'll go through this little steps

449
00:20:44,990 --> 00:20:47,670
as you lay out your
defensive infrastructure

450
00:20:47,670 --> 00:20:51,930
and how you deal and mitigate
with potential attacks.

451
00:20:51,930 --> 00:20:55,610
But the key thing that
certainly happened here

452
00:20:55,610 --> 00:20:58,250
is that all of these sequences

453
00:20:58,250 --> 00:21:02,060
really have delayed the
usefulness of their attack.

454
00:21:02,060 --> 00:21:03,476
Now, they might,

455
00:21:03,477 --> 00:21:08,380
the attacker might achieve
some level of footprint

456
00:21:08,380 --> 00:21:09,520
onto your system.

457
00:21:09,520 --> 00:21:12,360
Maybe they've compromised
one of your nodes,

458
00:21:12,360 --> 00:21:15,350
you know, maybe you have a
certain cluster and so forth.

459
00:21:15,350 --> 00:21:20,350
But it's taking them so long
and they're able to defend

460
00:21:20,550 --> 00:21:24,730
and detect what's being done
here that it's no longer useful

461
00:21:24,730 --> 00:21:27,670
or maybe the data is
out of date or so forth.

462
00:21:27,670 --> 00:21:30,000
But one of the things you wanna try to do

463
00:21:30,000 --> 00:21:32,620
with attack modeling is figure
out that level of rigor.

464
00:21:32,620 --> 00:21:34,560
And if you can come up
with that point, like,

465
00:21:34,560 --> 00:21:36,550
oh my gosh, they have to break encryption

466
00:21:36,550 --> 00:21:41,135
or to do so we kind of lay out
a software defined perimeter

467
00:21:41,135 --> 00:21:42,900
implementing zero trust

468
00:21:42,900 --> 00:21:46,730
which is a classic good way of
defending cloud architecture

469
00:21:46,730 --> 00:21:48,810
you know, for them to
get access to that system

470
00:21:48,810 --> 00:21:51,659
it's going to be really, really
hard for them to do that.

471
00:21:52,520 --> 00:21:56,550
All right, so getting back
to one of my favorites

472
00:21:56,550 --> 00:21:58,030
and I do this a lot.

473
00:21:58,030 --> 00:22:01,320
This is actually an homage
to the Batman Threat Model.

474
00:22:01,320 --> 00:22:03,760
I do encourage folks to
search on the internet

475
00:22:03,760 --> 00:22:05,730
for the Batman Threat Model.

476
00:22:05,730 --> 00:22:09,210
So this is a time to emulate that,

477
00:22:09,210 --> 00:22:14,210
but as a defender and as an
kind of a software person myself

478
00:22:14,270 --> 00:22:17,680
I know my system and I don't
always know the evil things

479
00:22:17,680 --> 00:22:19,980
that attacker might do to my system.

480
00:22:19,980 --> 00:22:23,947
So I wanna think that out
and I wanna think about,

481
00:22:23,947 --> 00:22:26,350
you know, what is they want to protect,

482
00:22:26,350 --> 00:22:28,219
who do I want to protect it from,

483
00:22:28,220 --> 00:22:30,380
how willing am I going
about to protect this,

484
00:22:30,380 --> 00:22:31,940
and really what's the consequences?

485
00:22:31,940 --> 00:22:34,010
And that's what we've
gone at drawn out here.

486
00:22:34,010 --> 00:22:36,300
And in this particular case,

487
00:22:36,300 --> 00:22:40,260
this is the trojan threat model.

488
00:22:40,260 --> 00:22:45,260
And in this case, Paris has
Helen in his City of Troy

489
00:22:46,160 --> 00:22:49,990
and he is under siege
under attack by the Greeks

490
00:22:49,990 --> 00:22:54,710
or very much upset with the
fact that Helen has been taken.

491
00:22:54,710 --> 00:22:59,710
And so King Agamemnon's
army is coming to fight

492
00:23:00,081 --> 00:23:05,081
and armies that would be
pretty one for one, right?

493
00:23:06,167 --> 00:23:07,550
And in this particular case,

494
00:23:07,550 --> 00:23:09,723
they've got these walls protecting them,

495
00:23:11,290 --> 00:23:12,550
they've got provisions,

496
00:23:12,550 --> 00:23:17,090
you know, they can hold up to
a siege for a very long time.

497
00:23:17,090 --> 00:23:20,870
Now, unfortunate, for them they have,

498
00:23:20,870 --> 00:23:21,919
the Greeks have Achilles.

499
00:23:21,920 --> 00:23:24,620
And if you add Achilles to the army

500
00:23:24,620 --> 00:23:26,929
it really becomes really a moderate level

501
00:23:26,930 --> 00:23:31,930
or a medium level risk with
respect to what's going on here.

502
00:23:32,330 --> 00:23:35,270
Unfortunately for them, they did not know

503
00:23:35,270 --> 00:23:38,400
about the threat and the gift

504
00:23:38,400 --> 00:23:39,930
that's going to be coming for them,

505
00:23:39,930 --> 00:23:41,530
which is the Trojan horse.

506
00:23:41,530 --> 00:23:45,530
And it's always that one thing
we did not forget think about

507
00:23:45,530 --> 00:23:49,310
and that is the thing that ends
up becoming the high threat

508
00:23:49,310 --> 00:23:53,763
really allowing folks to
compromise our situation.

509
00:23:55,720 --> 00:23:59,440
Now, as folks start to
think about this and like,

510
00:23:59,440 --> 00:24:01,950
okay, I know, maybe I
know what I wanna protect

511
00:24:01,950 --> 00:24:03,450
and who do I am protected from

512
00:24:03,450 --> 00:24:04,960
and I have an idea of how willing

513
00:24:04,960 --> 00:24:06,540
am I going about protected.

514
00:24:06,540 --> 00:24:08,879
What's a good way for me
to think about doing this.

515
00:24:08,880 --> 00:24:12,170
Now, this comes from the
Microsoft Threat Modeling

516
00:24:12,170 --> 00:24:13,570
way of thinking about it.

517
00:24:13,570 --> 00:24:15,520
And it's the stride methodology.

518
00:24:15,520 --> 00:24:16,680
In this particular case,

519
00:24:16,680 --> 00:24:19,430
you'll look at ways things can be spoofed.

520
00:24:19,430 --> 00:24:22,450
Maybe someone might tamper with data

521
00:24:22,450 --> 00:24:25,390
as that data transmit
from certain objects.

522
00:24:25,390 --> 00:24:27,860
So if you have an application and a server

523
00:24:27,860 --> 00:24:30,229
or a service that you're interacting with,

524
00:24:30,230 --> 00:24:31,300
you know, can someone spoof it?

525
00:24:31,300 --> 00:24:33,139
Someone can tamper with that data.

526
00:24:33,140 --> 00:24:35,960
Is there a way for them to
cryptographically say that

527
00:24:35,960 --> 00:24:37,450
there's someone who they are not

528
00:24:37,450 --> 00:24:39,840
and violate repudiation.

529
00:24:39,840 --> 00:24:42,899
Will I be giving up any
kind of particular data,

530
00:24:42,900 --> 00:24:46,453
any information disclosure and so forth.

531
00:24:47,330 --> 00:24:49,730
You know, will I have denial of service

532
00:24:49,730 --> 00:24:51,913
or elevation of privilege.

533
00:24:55,140 --> 00:24:58,090
Now, as we really think about

534
00:24:58,090 --> 00:25:00,240
or what all this threat modeling is

535
00:25:00,240 --> 00:25:02,160
we're starting to move the cloud.

536
00:25:02,160 --> 00:25:03,990
Is there any difference,

537
00:25:03,990 --> 00:25:07,450
you know, how does this
affect our attackers,

538
00:25:07,450 --> 00:25:10,870
software, assets and so forth.

539
00:25:10,870 --> 00:25:12,012
- Thanks Randall.

540
00:25:12,012 --> 00:25:13,710
So Randall is gonna be available

541
00:25:13,710 --> 00:25:16,120
for any questions that we have,

542
00:25:16,120 --> 00:25:18,872
that you have during the
next few minutes here.

543
00:25:20,170 --> 00:25:23,870
So as you mentioned, we're
moving to the cloud, right?

544
00:25:23,870 --> 00:25:28,040
We're now dealing with
attackers, software, assets

545
00:25:28,040 --> 00:25:31,940
that we don't necessarily completely own.

546
00:25:31,940 --> 00:25:34,090
And so I wanna talk a little bit about

547
00:25:34,090 --> 00:25:35,810
the Cloud Security Alliance

548
00:25:35,810 --> 00:25:40,230
and the Top Threats Working
Group that I'm involved with.

549
00:25:40,230 --> 00:25:44,060
And here you see a couple of the products

550
00:25:44,060 --> 00:25:45,409
on the right hand side

551
00:25:45,410 --> 00:25:47,460
that the Top Threats
Working Group has put out.

552
00:25:47,460 --> 00:25:50,670
So the Cloud Security Alliance, 2010

553
00:25:50,670 --> 00:25:53,787
they just had their 11th anniversary.

554
00:25:53,787 --> 00:25:57,060
COVID was a great time for having a party.

555
00:25:57,060 --> 00:26:01,960
So 92,000 members, over 300 organizations.

556
00:26:01,960 --> 00:26:04,350
And there are a ton of products

557
00:26:04,350 --> 00:26:06,870
that have come out of that
particular organization,

558
00:26:06,870 --> 00:26:08,860
Cloud Controls Matrix,

559
00:26:08,860 --> 00:26:12,709
the Enterprise Architecture,
Privacy Level Agreements.

560
00:26:12,710 --> 00:26:14,734
We'll talk about,

561
00:26:14,734 --> 00:26:17,330
you know, we won't talk
about the CAIQ and the CCSK

562
00:26:17,330 --> 00:26:21,270
but we will talk about
the collaboration site.

563
00:26:21,270 --> 00:26:22,660
You can go on to circle

564
00:26:22,660 --> 00:26:25,830
and see everything for the
Top Threats Community, right?

565
00:26:25,830 --> 00:26:29,540
And so we put out several
surveys across the years,

566
00:26:29,540 --> 00:26:31,480
and yes they all have cute little names.

567
00:26:31,480 --> 00:26:32,820
The notorious nine,

568
00:26:32,820 --> 00:26:35,240
there was a treacherous
seven, treacherous 12

569
00:26:35,240 --> 00:26:37,930
and most recently the egregious 11.

570
00:26:37,930 --> 00:26:40,490
So that's part of a survey
that we put out there

571
00:26:40,490 --> 00:26:44,220
and we send it out to cloud participants

572
00:26:44,220 --> 00:26:46,450
and we say, hey, what do you see

573
00:26:46,450 --> 00:26:51,450
as the biggest risks to
well, to cloud security?

574
00:26:52,360 --> 00:26:55,740
And so we get those, you see
that deep dive case studies.

575
00:26:55,740 --> 00:26:57,290
We'll talk about that a little bit more.

576
00:26:57,290 --> 00:26:59,330
There've been two of those
that we've published.

577
00:26:59,330 --> 00:27:02,520
And then that Cloud
Penetration Testing Playbook

578
00:27:03,510 --> 00:27:05,090
that is something that would have caught

579
00:27:05,090 --> 00:27:08,010
the Capital One breach
if it had been used.

580
00:27:08,010 --> 00:27:10,910
So all great research.

581
00:27:10,910 --> 00:27:13,610
Most recently, we've
been working on something

582
00:27:13,610 --> 00:27:17,030
this cloud threat modeling aspect.

583
00:27:17,030 --> 00:27:19,440
And then there's something
about a deeper dive

584
00:27:19,440 --> 00:27:22,010
partnership effort that
we have enough time

585
00:27:22,010 --> 00:27:24,343
I'll try to cover off on it a little bit.

586
00:27:25,350 --> 00:27:30,350
So all of this we get into
this Cloud Controls Matrix

587
00:27:30,620 --> 00:27:34,270
basically a matrix of
controls for the cloud.

588
00:27:34,270 --> 00:27:36,110
And this is one of the bigger products

589
00:27:36,110 --> 00:27:38,100
that the CSA puts out.

590
00:27:38,100 --> 00:27:39,959
You see, there are 17 domains

591
00:27:39,960 --> 00:27:43,233
for their Cloud Controls
Matrix version 4.0.

592
00:27:43,233 --> 00:27:46,919
That came out, and I wanna
say maybe three months ago,

593
00:27:46,920 --> 00:27:49,950
and so fresh hot off the press,

594
00:27:49,950 --> 00:27:52,030
you see on the right hand side there,

595
00:27:52,030 --> 00:27:55,370
that the application
and interface security,

596
00:27:55,370 --> 00:27:56,649
I believe it's seven.

597
00:27:56,650 --> 00:27:59,550
And that particular domain,

598
00:27:59,550 --> 00:28:01,639
that particular control

599
00:28:01,640 --> 00:28:04,060
you start getting into

600
00:28:04,060 --> 00:28:06,810
some of the aspects of threat modeling

601
00:28:06,810 --> 00:28:09,730
and where you would put
those into your organization

602
00:28:09,730 --> 00:28:11,610
and where you would control for those

603
00:28:11,610 --> 00:28:12,959
within a cloud environment.

604
00:28:14,360 --> 00:28:18,100
So, as I mentioned, the Top
Threats Working Group, well,

605
00:28:18,100 --> 00:28:22,240
we put together a fun little paper here,

606
00:28:22,240 --> 00:28:23,410
cloud threat modeling

607
00:28:23,410 --> 00:28:27,740
anybody that can call out
what that is on the side

608
00:28:27,740 --> 00:28:30,823
there we'll get some
definite kudos from us.

609
00:28:32,330 --> 00:28:35,909
So as far as the move to cloud goes

610
00:28:35,910 --> 00:28:39,000
we've got a shared
responsibilities, right?

611
00:28:39,000 --> 00:28:41,230
And the real proposition,

612
00:28:41,230 --> 00:28:43,560
you know, the crux comes down to this

613
00:28:43,560 --> 00:28:48,240
is it possible to allow
developers to develop, right?

614
00:28:48,240 --> 00:28:49,380
They don't have to worry about

615
00:28:49,380 --> 00:28:51,260
which cloud service providers cheapest,

616
00:28:51,260 --> 00:28:53,820
they don't have to
worry about CSP lock-in,

617
00:28:53,820 --> 00:28:56,970
they don't have to worry
about any of those aspects.

618
00:28:56,970 --> 00:29:00,440
Is it possible just to allow them to go

619
00:29:00,440 --> 00:29:02,670
do their thing in the security team

620
00:29:02,670 --> 00:29:04,810
and the governance risk
and compliance team

621
00:29:04,810 --> 00:29:09,169
will take care of all of the
security protections, right?

622
00:29:09,170 --> 00:29:11,690
All of the controls that are necessary,

623
00:29:11,690 --> 00:29:16,690
is that a possibility if they
wanna put it into Azure or AWS

624
00:29:16,700 --> 00:29:20,000
if they wanted to put it on
and do an IS or to a SAS,

625
00:29:20,000 --> 00:29:22,980
doesn't matter, it's just taken care of.

626
00:29:22,980 --> 00:29:25,230
And that's the ultimate goal.

627
00:29:25,230 --> 00:29:27,100
Can that happen?

628
00:29:27,100 --> 00:29:27,959
We'll see.

629
00:29:27,960 --> 00:29:31,980
But we laid out methodology
there you see those four steps,

630
00:29:31,980 --> 00:29:34,690
developers do what they do, right?

631
00:29:34,690 --> 00:29:37,160
And so part of this came out

632
00:29:37,160 --> 00:29:40,610
we started looking at
this threat modeling.

633
00:29:40,610 --> 00:29:42,649
We came with a set of cards, right?

634
00:29:42,650 --> 00:29:44,830
We wanted to figure out

635
00:29:44,830 --> 00:29:47,310
between the threats,
vulnerabilities, assets,

636
00:29:47,310 --> 00:29:50,669
you know, what kind of
controls, what kind of threats,

637
00:29:50,670 --> 00:29:53,340
what kind of vulnerabilities
we should be looking at

638
00:29:53,340 --> 00:29:54,970
how we can describe them,

639
00:29:54,970 --> 00:29:57,620
how we can convey that information quickly

640
00:29:57,620 --> 00:29:59,370
so that you can use a technique,

641
00:29:59,370 --> 00:30:04,370
like what Randall laid out
in the previous section.

642
00:30:05,120 --> 00:30:07,209
And so all of that "Home Alone,"

643
00:30:07,210 --> 00:30:09,180
you know, he talked about
the vulnerabilities,

644
00:30:09,180 --> 00:30:12,417
he talked about the threats
and the countermeasures, right?

645
00:30:12,417 --> 00:30:14,780
All those would go back into the controls

646
00:30:14,780 --> 00:30:17,510
we know the impact low and behold,

647
00:30:17,510 --> 00:30:21,240
they get in, they steal
everything and they hurt Kevin.

648
00:30:21,240 --> 00:30:26,240
So all right, as far as the
threat modeling cards go

649
00:30:27,140 --> 00:30:29,070
we put quite a bit of time into this

650
00:30:29,070 --> 00:30:32,700
but we didn't wanna
define everything, right?

651
00:30:32,700 --> 00:30:36,360
The whole idea is there's a
lot of extra work out there.

652
00:30:36,360 --> 00:30:39,060
You know, you've got stuff
that came out of NIST,

653
00:30:39,060 --> 00:30:41,260
Randall mentioned MITRE
a little bit earlier.

654
00:30:41,260 --> 00:30:45,040
You've got their CVE and
their attack framework.

655
00:30:45,040 --> 00:30:49,379
Carnegie Mellon has done quite
a bit of good work in this.

656
00:30:49,380 --> 00:30:52,460
And there's some other products

657
00:30:52,460 --> 00:30:56,630
from the cloud security lines there, CCAK

658
00:30:56,630 --> 00:30:59,290
which is an auditor
knowledge certification.

659
00:30:59,290 --> 00:31:01,810
You know, there's an impact identification

660
00:31:01,810 --> 00:31:04,460
and a method of using low and behold.

661
00:31:04,460 --> 00:31:07,870
Some of the other Top Threats
Working Group materials

662
00:31:07,870 --> 00:31:11,050
to help you threat modeling.

663
00:31:11,050 --> 00:31:15,300
And so all of this started
with our deep dive,

664
00:31:15,300 --> 00:31:19,810
which was an effort to better quantify,

665
00:31:19,810 --> 00:31:24,010
you know, better express the
risks that were associated

666
00:31:24,010 --> 00:31:28,030
that we were coming up
with in these surveys.

667
00:31:28,030 --> 00:31:30,769
Or how do we show what that really is

668
00:31:30,769 --> 00:31:35,769
in a true threat,
vulnerability matter, right?

669
00:31:36,930 --> 00:31:40,300
Threats has a very real definition.

670
00:31:40,300 --> 00:31:43,720
And you know, it wasn't
being used quite properly

671
00:31:43,720 --> 00:31:45,750
in the Top Threats Working Group.

672
00:31:45,750 --> 00:31:47,880
Our team knew that was the case,

673
00:31:47,880 --> 00:31:51,110
and really wanting to figure
out how to clean that up.

674
00:31:51,110 --> 00:31:56,110
So here, you've got this Dow
Jones case, you've got AWS.

675
00:31:56,220 --> 00:31:59,640
I said, you can have whichever
service provider it is.

676
00:31:59,640 --> 00:32:01,940
We can still threat model against it.

677
00:32:01,940 --> 00:32:04,210
We have an Elasticsearch database.

678
00:32:04,210 --> 00:32:09,210
Okay, well, those are aspects
that we're going to look into.

679
00:32:10,230 --> 00:32:12,520
If I were to go take care of,

680
00:32:12,520 --> 00:32:14,340
you know, do a certain search

681
00:32:14,340 --> 00:32:18,250
and take a look at a couple of products

682
00:32:18,250 --> 00:32:20,080
that are out there low and behold,

683
00:32:20,080 --> 00:32:23,699
hey I can find a couple of
servers that are in Amazon,

684
00:32:23,700 --> 00:32:24,950
that are in Azure.

685
00:32:24,950 --> 00:32:28,840
These are both in the
US and start modeling.

686
00:32:28,840 --> 00:32:30,889
It started coming up with assets

687
00:32:30,890 --> 00:32:33,190
and descriptions that go along with them.

688
00:32:33,190 --> 00:32:36,540
Both of them have that same
Elasticsearch capability.

689
00:32:36,540 --> 00:32:39,360
One's built on maybe a
corporate image, right?

690
00:32:39,360 --> 00:32:41,300
CIS hardened on AWS,

691
00:32:41,300 --> 00:32:44,733
whereas the other is a
self-managed Elasticsearch.

692
00:32:45,990 --> 00:32:50,870
Maybe it's an IaaS image that
comes from the vendor, right?

693
00:32:50,870 --> 00:32:54,010
These are all things that go back into

694
00:32:54,010 --> 00:32:59,010
the overall threats that
are potentially successful

695
00:33:00,380 --> 00:33:02,900
against the systems, because
there are vulnerabilities

696
00:33:02,900 --> 00:33:06,210
that will be associated
specific to those assets.

697
00:33:06,210 --> 00:33:09,070
Again, we want our developers to develop

698
00:33:09,070 --> 00:33:11,720
we don't want them to have
to worry about the assets,

699
00:33:11,720 --> 00:33:13,410
we don't want them to have to worry about

700
00:33:13,410 --> 00:33:16,720
the vulnerabilities that
go with each one, right?

701
00:33:16,720 --> 00:33:21,660
So at that point we can start
looking at these assets,

702
00:33:21,660 --> 00:33:24,120
what's the provenance,
what's the pedigree,

703
00:33:24,120 --> 00:33:26,399
where did they come from, who owns them,

704
00:33:26,400 --> 00:33:29,860
who puts them together, what
do we have to worry about?

705
00:33:29,860 --> 00:33:32,360
Within each one of these assets,

706
00:33:32,360 --> 00:33:35,830
within each one of these systems,

707
00:33:35,830 --> 00:33:38,530
you know, within each one of
these cloud service providers.

708
00:33:38,530 --> 00:33:43,090
So we look at things like connected

709
00:33:43,090 --> 00:33:45,199
versus disconnected systems.

710
00:33:45,200 --> 00:33:48,280
If I have an express route

711
00:33:48,280 --> 00:33:52,660
or a direct connect back into
my infrastructure, right?

712
00:33:52,660 --> 00:33:54,810
Back into my corporate data center

713
00:33:54,810 --> 00:33:57,610
because I am running
some sort of hybrid cloud

714
00:33:57,610 --> 00:34:00,090
that's going to have a
different set of controls

715
00:34:00,090 --> 00:34:01,530
that I need to put in place

716
00:34:01,530 --> 00:34:05,500
in order to keep my
overall security posture

717
00:34:05,500 --> 00:34:08,283
for risks in general, alright?

718
00:34:09,690 --> 00:34:13,280
Here we've got a couple of
examples we will drill in.

719
00:34:13,280 --> 00:34:17,440
You've got the hosted
Elasticsearch and a corporate image

720
00:34:17,440 --> 00:34:20,190
that we're looking at
so it's SaaS and IaaS.

721
00:34:20,190 --> 00:34:23,790
And we'll start considering
these against vulnerabilities.

722
00:34:23,790 --> 00:34:26,440
And these vulnerabilities
are going to be well,

723
00:34:26,440 --> 00:34:27,620
across the board.

724
00:34:27,620 --> 00:34:29,920
Some of them are going to be very specific

725
00:34:29,920 --> 00:34:32,460
to a very specific
service provider, right?

726
00:34:32,460 --> 00:34:34,739
If I have a misconfiguration that goes in

727
00:34:34,739 --> 00:34:39,669
and will affect the SaaS, the
PaaS and the IaaS, fantastic,

728
00:34:39,670 --> 00:34:41,760
but some of them are only
going to be appropriate

729
00:34:41,760 --> 00:34:43,659
for SaaS environments.

730
00:34:43,659 --> 00:34:46,080
And I can start marrying those up

731
00:34:46,080 --> 00:34:48,473
against the assets that I have.

732
00:34:49,590 --> 00:34:51,250
And eventually I'm going to come up with

733
00:34:51,250 --> 00:34:55,440
a year a couple of examples, here's a SPI,

734
00:34:55,440 --> 00:34:58,420
you know, we've got SaaS,
PaaS, and IaaS in there

735
00:34:58,420 --> 00:35:02,090
and maybe they aren't appropriate, right?

736
00:35:02,090 --> 00:35:05,140
We see that in the
middle of there that IaaS

737
00:35:05,140 --> 00:35:08,370
isn't going to work
against a PaaS environment.

738
00:35:08,370 --> 00:35:11,200
So from that standpoint,
we can start whittling down

739
00:35:11,200 --> 00:35:14,540
which of these vulnerabilities
we need to worry about.

740
00:35:14,540 --> 00:35:17,190
So one of the things that we've noticed

741
00:35:17,190 --> 00:35:19,670
that we noticed in creating this document

742
00:35:19,670 --> 00:35:22,773
and creating this threat
modeling guide, right?

743
00:35:23,730 --> 00:35:25,660
We noticed that there were some issues

744
00:35:25,660 --> 00:35:28,080
as far as the naming convention

745
00:35:28,080 --> 00:35:30,630
so that threat modeling consistency.

746
00:35:30,630 --> 00:35:31,840
We were able to use,

747
00:35:31,840 --> 00:35:34,520
you know, as far as the assets go,

748
00:35:34,520 --> 00:35:36,780
as far as the vulnerabilities go,

749
00:35:36,780 --> 00:35:38,580
you know, been a lot of great work

750
00:35:38,580 --> 00:35:40,210
against those other pieces.

751
00:35:40,210 --> 00:35:42,760
Controls you've got the
CCM, you've got NIST,

752
00:35:42,760 --> 00:35:45,370
you've got the International
Standards Organization.

753
00:35:45,370 --> 00:35:49,240
Know all of them are out there
they've defined all of this.

754
00:35:49,240 --> 00:35:51,720
In our past top threats documents,

755
00:35:51,720 --> 00:35:54,270
we're looking at things
like downloading bad code

756
00:35:54,270 --> 00:35:56,770
versus falling victim
to social engineering

757
00:35:56,770 --> 00:36:00,470
versus business email compromise fraud.

758
00:36:00,470 --> 00:36:02,600
None of those have any
sort of consistency.

759
00:36:02,600 --> 00:36:05,620
So what we put a little bit of a time in

760
00:36:05,620 --> 00:36:08,420
and effort in, and we
said, all right, look,

761
00:36:08,420 --> 00:36:10,890
here's something that
we could put together.

762
00:36:10,890 --> 00:36:14,710
You know, you define a type,
an actor, some sort of verb

763
00:36:14,710 --> 00:36:17,720
and an object, and then what
it's going to result in.

764
00:36:17,720 --> 00:36:22,299
And so this is something
that will propose in

765
00:36:22,300 --> 00:36:26,390
going forward in the future
Top Threats Working Group,

766
00:36:26,390 --> 00:36:28,170
activities and outputs.

767
00:36:28,170 --> 00:36:31,230
We'll actually be coming
up with another survey here

768
00:36:31,230 --> 00:36:35,470
coming out, and that will
replace the agregious 11

769
00:36:35,470 --> 00:36:36,850
moving forward.

770
00:36:36,850 --> 00:36:41,250
So from that, you see a couple of examples

771
00:36:41,250 --> 00:36:45,140
on the right there, malicious,
bot, injects, SQL code

772
00:36:45,140 --> 00:36:47,259
and a passwords breached, right?

773
00:36:47,260 --> 00:36:50,120
So going back, we can start cataloging

774
00:36:50,120 --> 00:36:52,460
this overall list of threats

775
00:36:52,460 --> 00:36:55,920
and well move forward from there.

776
00:36:55,920 --> 00:36:59,490
So with that again, any questions

777
00:36:59,490 --> 00:37:02,270
please feel free to
include those in the chat

778
00:37:02,270 --> 00:37:06,150
we'll definitely be answering
those as quickly as possible

779
00:37:06,150 --> 00:37:08,340
and Randall, if you will bring it home

780
00:37:08,340 --> 00:37:11,800
and tell everyone what they can do next.

781
00:37:11,800 --> 00:37:14,027
- All right, so over the next week one,

782
00:37:14,027 --> 00:37:17,260
you know, really think
about what we've said here

783
00:37:17,260 --> 00:37:20,870
with respect to threat
modeling, pick a system,

784
00:37:20,870 --> 00:37:24,450
pick something that you're
going to be moving to the cloud.

785
00:37:24,450 --> 00:37:26,649
However you're going to be doing that.

786
00:37:28,193 --> 00:37:30,270
You're gonna be moving to
a cloud service provider,

787
00:37:30,270 --> 00:37:33,250
start to really think
about how might I go about,

788
00:37:33,250 --> 00:37:34,300
you know, creating a threat model,

789
00:37:34,300 --> 00:37:35,399
think about what you wanna protect,

790
00:37:35,399 --> 00:37:36,600
who do you wanna protect it from

791
00:37:36,600 --> 00:37:39,603
and how likely would
you need to protect it.

792
00:37:40,930 --> 00:37:43,210
- So in the first three months

793
00:37:43,210 --> 00:37:45,940
following this presentation, look,

794
00:37:45,940 --> 00:37:50,020
there's a very nice layout
of next steps, right?

795
00:37:50,020 --> 00:37:53,950
And hopefully if you guys are
already involved with the CSA,

796
00:37:53,950 --> 00:37:56,799
or you are familiar with
that Cloud Controls Matrix,

797
00:37:56,800 --> 00:37:59,820
go ahead and see if you
can start utilizing that

798
00:37:59,820 --> 00:38:02,673
to create some mitigations
against those threats.

799
00:38:04,380 --> 00:38:05,410
- And then definitely think about,

800
00:38:05,410 --> 00:38:08,040
as you get into six months
further down the road,

801
00:38:08,040 --> 00:38:10,960
as you thought about those mitigations,

802
00:38:10,960 --> 00:38:12,050
thought about your threat models

803
00:38:12,050 --> 00:38:13,900
go back and validate that threat model.

804
00:38:13,900 --> 00:38:15,410
Make sure it's still valid,

805
00:38:15,410 --> 00:38:18,123
it's still current with
what's going on today.

806
00:38:19,450 --> 00:38:21,129
- And last but not least look,

807
00:38:21,130 --> 00:38:23,010
the Top Threats Working Group,

808
00:38:23,010 --> 00:38:26,010
we're putting out a lot of good work,

809
00:38:26,010 --> 00:38:28,120
a lot of good research.

810
00:38:28,120 --> 00:38:30,730
You see that 2021 survey,

811
00:38:30,730 --> 00:38:33,320
that'll be coming out by
black hat of this year

812
00:38:33,320 --> 00:38:35,230
at least estimated.

813
00:38:35,230 --> 00:38:38,750
I would expect that that
will become the next

814
00:38:38,750 --> 00:38:41,400
whatever the replacement
is for the egregious 11.

815
00:38:41,400 --> 00:38:44,040
We're also looking at game of gamification

816
00:38:44,040 --> 00:38:47,040
of the threat modeling
so how you can quantify,

817
00:38:47,040 --> 00:38:49,259
how you can put some scorecards together.

818
00:38:49,260 --> 00:38:52,390
And then the last would
be another deep dive

819
00:38:52,390 --> 00:38:55,230
that comes out as well as some additional

820
00:38:55,230 --> 00:38:58,107
maybe even deeper, like
Mariana's trench style

821
00:38:58,107 --> 00:39:02,410
deep dive work that will be going forward.

822
00:39:02,410 --> 00:39:05,399
So with that, we definitely
appreciate your time

823
00:39:05,400 --> 00:39:07,160
it's been an absolute pleasure.

824
00:39:07,160 --> 00:39:09,109
And if you have any more questions

825
00:39:09,110 --> 00:39:11,540
please feel free to reach out to us.

826
00:39:11,540 --> 00:39:15,580
And if not happy that
you attended our session

827
00:39:15,580 --> 00:39:17,779
and we look forward to
meeting you in the future,

828
00:39:17,780 --> 00:39:20,343
hopefully, in meet space, right?

829
00:39:22,070 --> 00:39:23,020
- Right, thank you.

830
00:39:23,990 --> 00:39:24,852
- Thanks again.

