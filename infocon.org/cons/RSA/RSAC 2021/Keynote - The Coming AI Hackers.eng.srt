1
00:00:00,000 --> 00:00:02,750
(dramatic music)

2
00:00:16,911 --> 00:00:19,494
(upbeat music)

3
00:00:25,336 --> 00:00:28,753
(soft transition music)

4
00:00:32,020 --> 00:00:33,850
- In case you don't have
enough to worry about,

5
00:00:33,850 --> 00:00:36,360
I wanna talk about AI hackers.

6
00:00:36,360 --> 00:00:38,560
Artificial intelligence
will hack humanity,

7
00:00:38,560 --> 00:00:41,020
unlike anything that's come before.

8
00:00:41,020 --> 00:00:42,870
AIs will find vulnerabilities in all sorts

9
00:00:42,870 --> 00:00:45,339
of social, economic,
and political systems,

10
00:00:45,340 --> 00:00:48,030
and exploit them at an
unprecedented speed,

11
00:00:48,030 --> 00:00:49,710
scale, and scope.

12
00:00:49,710 --> 00:00:51,360
This isn't just a difference in degree,

13
00:00:51,360 --> 00:00:52,920
it's a difference in kind.

14
00:00:52,920 --> 00:00:56,180
It'll culminate in AI systems
hacking other AI systems,

15
00:00:56,180 --> 00:00:59,180
with humans being a little
more than collateral damage.

16
00:00:59,180 --> 00:01:01,550
Okay, maybe this is a bit of hyperbole,

17
00:01:01,550 --> 00:01:02,900
but none of it requires

18
00:01:02,900 --> 00:01:05,530
far future, science-fiction technology.

19
00:01:05,530 --> 00:01:07,860
I'm not postulating any singularity,

20
00:01:07,860 --> 00:01:10,140
I'm not assuming intelligent Androids,

21
00:01:10,140 --> 00:01:13,660
I'm not even assuming evil
intent on the part of anyone.

22
00:01:13,660 --> 00:01:16,200
Most of the hacks I will
discuss don't even require

23
00:01:16,200 --> 00:01:18,450
major research breakthroughs in AI.

24
00:01:18,450 --> 00:01:20,890
They'll improve as AI
gets more sophisticated,

25
00:01:20,890 --> 00:01:24,150
but we can see the hints
of them in operation today.

26
00:01:24,150 --> 00:01:25,830
This hacking will come naturally,

27
00:01:25,830 --> 00:01:28,810
as AIs become more advanced
in learning, understanding,

28
00:01:28,810 --> 00:01:29,810
and problem solving.

29
00:01:30,670 --> 00:01:32,913
First, let's generalize the term, hacking.

30
00:01:33,860 --> 00:01:35,750
Think about the tax code.

31
00:01:35,750 --> 00:01:37,260
It's not computer code,

32
00:01:37,260 --> 00:01:38,730
but it is code.

33
00:01:38,730 --> 00:01:40,180
It's a series of algorithms

34
00:01:40,180 --> 00:01:41,540
with inputs and outputs.

35
00:01:41,540 --> 00:01:43,640
Those are the tax rules.

36
00:01:43,640 --> 00:01:45,270
It has vulnerabilities,

37
00:01:45,270 --> 00:01:47,330
we call them tax loopholes.

38
00:01:47,330 --> 00:01:48,770
It has exploits,

39
00:01:48,770 --> 00:01:51,369
we call them tax avoidance strategies.

40
00:01:51,370 --> 00:01:54,750
And there's an entire industry
of black hat hackers looking

41
00:01:54,750 --> 00:01:57,700
for exploitable vulnerabilities
in the tax code.

42
00:01:57,700 --> 00:01:59,190
We call them tax accountants

43
00:01:59,190 --> 00:02:00,253
and tax attorneys.

44
00:02:01,240 --> 00:02:03,610
So, hack, here's the definition:

45
00:02:03,610 --> 00:02:05,830
something that a system permits,

46
00:02:05,830 --> 00:02:07,929
but is unanticipated and unwanted

47
00:02:07,930 --> 00:02:09,539
by the designers.

48
00:02:09,539 --> 00:02:10,810
Here's another one:

49
00:02:10,810 --> 00:02:14,070
a clever, unintended
exploitation of a system

50
00:02:14,070 --> 00:02:16,549
which, one, subverts
the rules of the system,

51
00:02:16,550 --> 00:02:18,850
two, at the expense of some other part

52
00:02:18,850 --> 00:02:20,190
of the system.

53
00:02:20,190 --> 00:02:22,100
But this is a subjective term.

54
00:02:22,100 --> 00:02:25,090
It encompasses a notion
of novelty and cleverness.

55
00:02:25,090 --> 00:02:26,370
It's a subversion

56
00:02:26,370 --> 00:02:28,010
or an exploitation.

57
00:02:28,010 --> 00:02:30,436
It's unintended and unanticipated.

58
00:02:30,437 --> 00:02:32,960
The hacks follow the rules of a system,

59
00:02:32,960 --> 00:02:34,903
but subvert its goal or intent.

60
00:02:36,090 --> 00:02:39,140
Now, all systems of rules can be hacked.

61
00:02:39,140 --> 00:02:41,809
You can find hacks in professional sports,

62
00:02:41,810 --> 00:02:43,460
in consumer award programs,

63
00:02:43,460 --> 00:02:46,300
in the financial systems, in politics,

64
00:02:46,300 --> 00:02:49,120
in lots of economic,
political, and social systems

65
00:02:49,120 --> 00:02:50,863
against our cognitive functions.

66
00:02:51,760 --> 00:02:53,980
A curved hockey stick is a hack,

67
00:02:53,980 --> 00:02:55,920
and we know the name of the hacker

68
00:02:55,920 --> 00:02:57,019
who invented it.

69
00:02:57,020 --> 00:03:00,310
Mileage runs and frequent
flyer programs are a hack.

70
00:03:00,310 --> 00:03:02,800
The filibuster was originally a hack,

71
00:03:02,800 --> 00:03:05,080
back in Roman times when it was invented.

72
00:03:05,080 --> 00:03:07,930
Hedge funds are full of hacks.

73
00:03:07,930 --> 00:03:10,220
A system is just a set of rules.

74
00:03:10,220 --> 00:03:11,210
Or they could be norm;

75
00:03:11,210 --> 00:03:13,520
it's like the rules are always formal.

76
00:03:13,520 --> 00:03:15,970
And even the best
thought-out sets of rules

77
00:03:15,970 --> 00:03:17,880
will be incomplete or inconsistent.

78
00:03:17,880 --> 00:03:19,700
They'll have ambiguities

79
00:03:19,700 --> 00:03:22,230
and things that designers
haven't thought of.

80
00:03:22,230 --> 00:03:23,420
And as long as there are people

81
00:03:23,420 --> 00:03:25,709
who want to subvert the goals of a system,

82
00:03:25,710 --> 00:03:26,923
there will be hacks.

83
00:03:27,900 --> 00:03:30,780
And AIs are becoming hackers.

84
00:03:30,780 --> 00:03:34,690
In 2016, DARPA held an AI
Capture The Flag event.

85
00:03:34,690 --> 00:03:35,650
You know this game,

86
00:03:35,650 --> 00:03:38,730
it's a staple at hacker
conferences around the world.

87
00:03:38,730 --> 00:03:41,209
100 AI teams competed,

88
00:03:41,210 --> 00:03:45,130
seven finalists faced off at Defcon 2016.

89
00:03:45,130 --> 00:03:46,620
And for 10 hours,

90
00:03:46,620 --> 00:03:48,500
the AIs were on a network,

91
00:03:48,500 --> 00:03:50,820
attacking other computers' teams

92
00:03:50,820 --> 00:03:52,840
and defending their own,

93
00:03:52,840 --> 00:03:54,390
in an AI called Mayhem 1.

94
00:03:56,160 --> 00:04:00,140
AIs are also finding
vulnerabilities in software.

95
00:04:00,140 --> 00:04:01,250
It's ongoing research,

96
00:04:01,250 --> 00:04:02,420
it's pretty promising.

97
00:04:02,420 --> 00:04:04,030
And if you think about it,

98
00:04:04,030 --> 00:04:06,490
it's the sort of thing
an AI will be good at;

99
00:04:06,490 --> 00:04:08,100
its pattern matching,

100
00:04:08,100 --> 00:04:11,760
it's looking through
millions of lines of code,

101
00:04:11,760 --> 00:04:13,692
and trying to find vulnerabilities.

102
00:04:14,880 --> 00:04:16,620
Now, the implications of this go far

103
00:04:16,620 --> 00:04:18,459
beyond computer networks.

104
00:04:18,459 --> 00:04:20,579
Vulnerabilities in the tax code,

105
00:04:20,579 --> 00:04:22,919
vulnerabilities in the
financial regulations,

106
00:04:22,920 --> 00:04:24,270
vulnerabilities in all sorts

107
00:04:24,270 --> 00:04:27,260
of social, economic,
and political systems.

108
00:04:27,260 --> 00:04:29,990
And there are really two
different issues here.

109
00:04:29,990 --> 00:04:32,030
The first is that an
AI might be instructed

110
00:04:32,030 --> 00:04:33,922
to hack one of those systems,

111
00:04:33,923 --> 00:04:36,690
and someone might feed an
AI, the world's tax codes,

112
00:04:36,690 --> 00:04:38,360
or the world's financial regulations

113
00:04:38,360 --> 00:04:40,810
with the intent of it
having to create a slew

114
00:04:40,810 --> 00:04:42,093
of profitable hacks.

115
00:04:43,255 --> 00:04:45,890
And the other is that
an AI might naturally,

116
00:04:45,890 --> 00:04:47,793
or be an inadvertently hacker system.

117
00:04:48,650 --> 00:04:50,020
Both are dangerous,

118
00:04:50,020 --> 00:04:51,680
but the second is more dangerous

119
00:04:51,680 --> 00:04:53,940
because we might never know what happened.

120
00:04:53,940 --> 00:04:56,390
And that's because of the
explainability problem.

121
00:04:57,560 --> 00:04:59,680
In "The Hitchhiker's Guide to the Galaxy,"

122
00:04:59,680 --> 00:05:02,760
a race of hyper-intelligent
pan-dimensional beings

123
00:05:02,760 --> 00:05:06,090
build the universe's most
powerful computer, Deep Thought,

124
00:05:06,090 --> 00:05:07,960
to answer the ultimate question

125
00:05:07,960 --> 00:05:10,620
of life, the universe, and everything.

126
00:05:10,620 --> 00:05:12,500
The answer was 42.

127
00:05:12,500 --> 00:05:15,040
And Deep Thought was unable
to explain its answer

128
00:05:15,040 --> 00:05:17,140
or even what the question was.

129
00:05:17,140 --> 00:05:19,490
That is the explainability problem.

130
00:05:19,490 --> 00:05:22,770
Modern AIs are essentially black boxes.

131
00:05:22,770 --> 00:05:24,479
Data goes one in one end,

132
00:05:24,480 --> 00:05:26,320
and the answer comes out the other.

133
00:05:26,320 --> 00:05:28,280
And it can be impossible to understand

134
00:05:28,280 --> 00:05:30,349
how a system reaches its conclusion,

135
00:05:30,350 --> 00:05:31,690
even if you are a programmer

136
00:05:31,690 --> 00:05:32,740
and look at the code.

137
00:05:33,600 --> 00:05:36,830
And AIs don't solve
problems like humans do.

138
00:05:36,830 --> 00:05:38,870
Their limitations are different than ours.

139
00:05:38,870 --> 00:05:41,620
They'll consider more possible
solutions than we might.

140
00:05:41,620 --> 00:05:45,060
More importantly, they'll look
at more types of solutions.

141
00:05:45,060 --> 00:05:46,120
They'll go down paths

142
00:05:46,120 --> 00:05:48,280
that we simply have not considered;

143
00:05:48,280 --> 00:05:50,210
paths more complex than
the sorts of things,

144
00:05:50,210 --> 00:05:51,712
humans generally keep in mind.

145
00:05:52,800 --> 00:05:55,340
2016, the AI program, AlphaGo,

146
00:05:55,340 --> 00:05:56,869
won a five-game match against one

147
00:05:56,870 --> 00:05:58,560
of the world's best Go players.

148
00:05:58,560 --> 00:05:59,997
This actually shocked both the AI

149
00:05:59,997 --> 00:06:02,040
and the Go playing worlds.

150
00:06:02,040 --> 00:06:05,920
AI's most famous move
was move 37 in game two.

151
00:06:05,920 --> 00:06:07,970
And it's hard to explain
without diving deep

152
00:06:07,970 --> 00:06:09,220
into Go strategy,

153
00:06:09,220 --> 00:06:10,053
but it was a move

154
00:06:10,053 --> 00:06:12,533
that no human would have
ever chosen to make.

155
00:06:13,660 --> 00:06:17,270
2015, a research group fed
an AI system, medical data,

156
00:06:17,270 --> 00:06:19,109
from about 700,000 people

157
00:06:19,110 --> 00:06:22,550
and tested whether or not
it could predict diseases.

158
00:06:22,550 --> 00:06:24,240
The result was a success,

159
00:06:24,240 --> 00:06:27,270
but the patient provides no explanation

160
00:06:27,270 --> 00:06:28,609
for its diagnosis.

161
00:06:28,610 --> 00:06:30,310
And the researchers have no idea

162
00:06:30,310 --> 00:06:32,260
how it reaches its conclusions.

163
00:06:32,260 --> 00:06:33,780
So a doctor can either trust

164
00:06:33,780 --> 00:06:34,969
or ignore the computer,

165
00:06:34,970 --> 00:06:36,663
but can't query it for more info.

166
00:06:37,970 --> 00:06:40,680
Now, researchers are
working on explainable AI.

167
00:06:40,680 --> 00:06:42,750
And well, there are advances in this field

168
00:06:42,750 --> 00:06:44,820
that seems to be a
trade-off between capability

169
00:06:44,820 --> 00:06:46,236
and explainability.

170
00:06:46,237 --> 00:06:49,110
Explanations are actually
a cognitive shorthand used

171
00:06:49,110 --> 00:06:50,090
by humans.

172
00:06:50,090 --> 00:06:52,880
Suited for the way humans make decisions.

173
00:06:52,880 --> 00:06:53,950
Forcing an AI

174
00:06:53,950 --> 00:06:56,780
to produce a human
understandable explanation

175
00:06:56,780 --> 00:06:58,559
is additional constraint,

176
00:06:58,560 --> 00:07:01,250
and it could affect the
quality of its decisions.

177
00:07:01,250 --> 00:07:02,670
And certainly, in the near term,

178
00:07:02,670 --> 00:07:04,210
AI is becoming more opaque

179
00:07:04,210 --> 00:07:05,363
and less explainable.

180
00:07:06,770 --> 00:07:09,469
So now, let's talk about reward hacking.

181
00:07:09,470 --> 00:07:11,450
Again, AIs don't solve problems,

182
00:07:11,450 --> 00:07:13,070
the way people do.

183
00:07:13,070 --> 00:07:16,370
They will invariably stumble on solutions

184
00:07:16,370 --> 00:07:18,890
that we humans might
have never anticipated.

185
00:07:18,890 --> 00:07:20,570
And some of them will subvert the intent

186
00:07:20,570 --> 00:07:21,969
of the system.

187
00:07:21,970 --> 00:07:24,330
And that's because AIs
don't think in the terms

188
00:07:24,330 --> 00:07:27,729
of the implications,
contexts, norms, and values,

189
00:07:27,730 --> 00:07:30,300
that we humans share and take for granted.

190
00:07:30,300 --> 00:07:31,910
This is a reward hacking.

191
00:07:31,910 --> 00:07:33,700
It involves achieving a goal,

192
00:07:33,700 --> 00:07:37,710
but in a way the AI designers
either wanted nor intended.

193
00:07:37,710 --> 00:07:39,409
And the examples are pretty great.

194
00:07:40,260 --> 00:07:41,590
There's a soccer simulation

195
00:07:41,590 --> 00:07:42,739
where an AI figured out

196
00:07:42,740 --> 00:07:44,770
that if it kicked a ball out of bounds,

197
00:07:44,770 --> 00:07:46,870
the goalie will have to
throw the ball back in

198
00:07:46,870 --> 00:07:49,030
and leave the goal undefended.

199
00:07:49,030 --> 00:07:50,690
There's a stacking simulation

200
00:07:50,690 --> 00:07:52,360
where an AI learned to flip a ball,

201
00:07:52,360 --> 00:07:53,670
block upside down,

202
00:07:53,670 --> 00:07:55,900
rather than stack it.

203
00:07:55,900 --> 00:07:57,700
There's an evolution simulation

204
00:07:57,700 --> 00:07:59,039
where an AI figured out

205
00:07:59,040 --> 00:08:00,690
that instead of running,

206
00:08:00,690 --> 00:08:02,980
it could grow itself tall enough

207
00:08:02,980 --> 00:08:04,810
to cross a distance finish line

208
00:08:04,810 --> 00:08:06,800
by falling over it.

209
00:08:06,800 --> 00:08:09,030
These are all hacks.

210
00:08:09,030 --> 00:08:12,059
You can blame them on poorly
specified goals or rewards,

211
00:08:12,060 --> 00:08:13,970
and you'd be correct.

212
00:08:13,970 --> 00:08:14,803
You can point out

213
00:08:14,803 --> 00:08:17,504
that they all occurred in
a simulated environment,

214
00:08:17,504 --> 00:08:19,500
and you'd also be correct.

215
00:08:19,500 --> 00:08:21,397
But here's the problem.

216
00:08:21,397 --> 00:08:25,760
AIs will inadvertently hack
systems in ways we won't expect

217
00:08:25,760 --> 00:08:27,360
all the time.

218
00:08:27,360 --> 00:08:28,780
There's a story of a researcher trying

219
00:08:28,780 --> 00:08:30,380
to teach a robot vacuum cleaner

220
00:08:30,380 --> 00:08:32,320
not to bump into things.

221
00:08:32,320 --> 00:08:34,380
And instead of learning
not to bump into things,

222
00:08:34,380 --> 00:08:35,919
it learned to drive backwards

223
00:08:35,919 --> 00:08:37,762
because it got sensors back there.

224
00:08:38,880 --> 00:08:42,370
Any good AI system will
naturally find hacks.

225
00:08:42,370 --> 00:08:44,470
If there are problems, inconsistencies,

226
00:08:44,470 --> 00:08:45,940
and loopholes in the rules,

227
00:08:45,940 --> 00:08:48,590
and if those properties lead
to an acceptable solution

228
00:08:48,590 --> 00:08:50,050
as defined by the rules,

229
00:08:50,050 --> 00:08:51,603
then AIs will find them.

230
00:08:52,625 --> 00:08:54,407
You might look at what the AI did and say,

231
00:08:54,407 --> 00:08:56,890
"Well, technically, it
followed the rules,"

232
00:08:56,890 --> 00:09:01,500
yet we humans would know it's
a deviation, a cheat, a hack,

233
00:09:01,500 --> 00:09:03,410
because we understand context

234
00:09:03,410 --> 00:09:05,010
and have different expectations.

235
00:09:05,920 --> 00:09:08,510
So we all learned about
this problem as children,

236
00:09:08,510 --> 00:09:09,810
like the King Midas story.

237
00:09:10,690 --> 00:09:12,980
After the God Dionysus grants him a wish,

238
00:09:12,980 --> 00:09:16,030
Midas asked if everything
he touches turned gold.

239
00:09:16,030 --> 00:09:18,560
And Midas ends up starving and miserable,

240
00:09:18,560 --> 00:09:20,250
but his food, drink, and daughter,

241
00:09:20,250 --> 00:09:22,040
all turned to gold.

242
00:09:22,040 --> 00:09:23,719
It's a specification problem.

243
00:09:23,720 --> 00:09:26,493
Midas programed the wrong
goal into the system.

244
00:09:27,500 --> 00:09:30,620
We also know that genies are very precise

245
00:09:30,620 --> 00:09:32,070
about the wording of wishes,

246
00:09:32,070 --> 00:09:35,030
and can be maliciously
pedantic when granting them.

247
00:09:35,030 --> 00:09:36,199
But here's the thing.

248
00:09:36,200 --> 00:09:38,720
There's no way to outsmart the genie.

249
00:09:38,720 --> 00:09:40,190
Whatever you wish for,

250
00:09:40,190 --> 00:09:42,570
he will always be able
to grant it in a way

251
00:09:42,570 --> 00:09:44,160
that you wish he hadn't.

252
00:09:44,160 --> 00:09:47,560
The genie will always be
able to hack your wish.

253
00:09:47,560 --> 00:09:50,949
The general problem is that
in human language and thought,

254
00:09:50,950 --> 00:09:54,900
goals and desires are
always underspecified.

255
00:09:54,900 --> 00:09:57,130
We never describe all the options.

256
00:09:57,130 --> 00:09:59,840
We never include all the
caveats and exceptions

257
00:09:59,840 --> 00:10:00,830
to provide those.

258
00:10:00,830 --> 00:10:03,410
We never close off all
the avenues for hacking.

259
00:10:03,410 --> 00:10:04,579
We can't.

260
00:10:04,580 --> 00:10:08,333
Any goal we specify will
necessarily be incomplete.

261
00:10:09,310 --> 00:10:11,890
And this is largely okay
in human interactions

262
00:10:11,890 --> 00:10:13,730
because people understand context

263
00:10:13,730 --> 00:10:15,850
and usually act in good faith.

264
00:10:15,850 --> 00:10:17,580
We are all socialized.

265
00:10:17,580 --> 00:10:19,500
And in the process of becoming so,

266
00:10:19,500 --> 00:10:21,560
we acquire common sense about how people

267
00:10:21,560 --> 00:10:22,969
and the world works.

268
00:10:22,970 --> 00:10:25,230
We fill in any gaps in our understanding

269
00:10:25,230 --> 00:10:27,200
with that context.

270
00:10:27,200 --> 00:10:29,480
So if I asked you to get me some coffee,

271
00:10:29,480 --> 00:10:31,290
you would probably go to
the nearest coffee pot

272
00:10:31,290 --> 00:10:32,780
and pour me a cup,

273
00:10:32,780 --> 00:10:34,520
or maybe walk to the corner coffee shop

274
00:10:34,520 --> 00:10:35,760
and buy one.

275
00:10:35,760 --> 00:10:38,250
You would not bring me
a pound of raw beans.

276
00:10:38,250 --> 00:10:40,850
You would not buy a coffee plantation.

277
00:10:40,850 --> 00:10:42,000
You would also not look

278
00:10:42,000 --> 00:10:43,920
for the closest person
holding a cup of coffee

279
00:10:43,920 --> 00:10:46,000
and rip it out of their hands.

280
00:10:46,000 --> 00:10:48,360
You wouldn't bring me week-old cold coffee

281
00:10:48,360 --> 00:10:49,510
or use paper towel

282
00:10:49,510 --> 00:10:51,390
that had wiped up a coffee spill.

283
00:10:51,390 --> 00:10:53,560
I wouldn't have to specify any of that,

284
00:10:53,560 --> 00:10:54,733
you would just know.

285
00:10:55,820 --> 00:10:58,490
Similarly, if I asked you
to develop a technology

286
00:10:58,490 --> 00:11:00,380
that would turn things into gold on touch,

287
00:11:00,380 --> 00:11:01,620
you wouldn't build it

288
00:11:01,620 --> 00:11:03,783
so that it starve the person using it.

289
00:11:04,730 --> 00:11:06,530
I wouldn't have to specify that,

290
00:11:06,530 --> 00:11:07,813
you would just know.

291
00:11:08,930 --> 00:11:12,180
We can't completely
specify goals to an AI,

292
00:11:12,180 --> 00:11:13,239
and AIs won't be able

293
00:11:13,240 --> 00:11:15,003
to completely understand context.

294
00:11:15,930 --> 00:11:18,180
2015, Volkswagen was caught cheating

295
00:11:18,180 --> 00:11:20,300
on emission control test.

296
00:11:20,300 --> 00:11:22,849
Now, this Volkswagen
story doesn't involve AI.

297
00:11:22,850 --> 00:11:25,940
Human engineers programed a
regular computer to cheat,

298
00:11:25,940 --> 00:11:27,490
but it illustrates the problem.

299
00:11:28,680 --> 00:11:30,109
They programed their engine

300
00:11:30,110 --> 00:11:31,970
to detect emission control testing

301
00:11:31,970 --> 00:11:34,120
and to behave differently
when being tested

302
00:11:34,120 --> 00:11:35,980
to pass those tests.

303
00:11:35,980 --> 00:11:38,640
And their cheat remain
undetected for years

304
00:11:38,640 --> 00:11:39,939
because it's hard to figure out

305
00:11:39,940 --> 00:11:41,290
what the software is doing.

306
00:11:42,240 --> 00:11:43,320
Now, if I asked you

307
00:11:43,320 --> 00:11:46,010
to design a car's engine control software

308
00:11:46,010 --> 00:11:47,600
to maximize performance

309
00:11:47,600 --> 00:11:49,980
while still passing
emission control tests,

310
00:11:49,980 --> 00:11:52,450
you wouldn't design that software to cheat

311
00:11:52,450 --> 00:11:54,700
without understanding
that you were cheating.

312
00:11:55,650 --> 00:11:57,970
This simply isn't true for an AI.

313
00:11:57,970 --> 00:11:59,810
It will think out of the box

314
00:11:59,810 --> 00:12:02,170
because it won't have a
conception of the box.

315
00:12:02,170 --> 00:12:03,810
It won't understand

316
00:12:03,810 --> 00:12:06,130
that the Volkswagen solution harms others.

317
00:12:06,130 --> 00:12:08,730
That it undermines the intent
of emission control laws

318
00:12:08,730 --> 00:12:10,163
or that is breaking the law.

319
00:12:11,240 --> 00:12:14,150
Unless the programmer specify the goal

320
00:12:14,150 --> 00:12:16,730
of not behaving differently
when being tested,

321
00:12:16,730 --> 00:12:18,940
an AI might inadvertently come up

322
00:12:18,940 --> 00:12:20,650
with the same hack.

323
00:12:20,650 --> 00:12:22,449
The program is (indistinct) satisfied,

324
00:12:22,450 --> 00:12:24,510
the accounts will be ecstatic,

325
00:12:24,510 --> 00:12:26,450
and because of the explainability problem,

326
00:12:26,450 --> 00:12:28,583
no one will realize what the AI did.

327
00:12:29,420 --> 00:12:31,800
And yes, now that we know
the Volkswagen story,

328
00:12:31,800 --> 00:12:33,609
we can explicitly set the goal

329
00:12:33,610 --> 00:12:36,010
to avoid that particular hack.

330
00:12:36,010 --> 00:12:37,170
But there are other hacks,

331
00:12:37,170 --> 00:12:39,599
the programmers will not anticipate.

332
00:12:39,600 --> 00:12:42,510
The lesson of the genie is that
there will always be hacks,

333
00:12:42,510 --> 00:12:44,310
the programmers will not anticipate.

334
00:12:45,816 --> 00:12:47,740
And the worry isn't limited
to the obvious hacks.

335
00:12:47,740 --> 00:12:49,060
We'll see them.

336
00:12:49,060 --> 00:12:51,890
The greatest worry lies in
the hacks that are subtle,

337
00:12:51,890 --> 00:12:53,233
like the Volkswagen hack.

338
00:12:54,630 --> 00:12:57,439
We're already seeing the
first generation of this.

339
00:12:57,440 --> 00:12:59,590
Much has been written about
recommendation engines

340
00:12:59,590 --> 00:13:02,110
and how they push people
towards extreme content.

341
00:13:02,110 --> 00:13:03,820
They weren't programmed to do this.

342
00:13:03,820 --> 00:13:05,980
It's a property that naturally emerged.

343
00:13:05,980 --> 00:13:08,340
The algorithms learned
to push extreme content

344
00:13:08,340 --> 00:13:10,660
because that's what people respond to.

345
00:13:10,660 --> 00:13:11,680
This is important.

346
00:13:11,680 --> 00:13:13,219
It didn't take a bad actor

347
00:13:13,220 --> 00:13:14,670
to create this hack.

348
00:13:14,670 --> 00:13:17,652
A pretty basic automated
system founded it on its own.

349
00:13:19,240 --> 00:13:20,750
And nothing I'm saying here will be news

350
00:13:20,750 --> 00:13:22,040
to AI researchers.

351
00:13:22,040 --> 00:13:25,140
And there are many people
currently working on ways

352
00:13:25,140 --> 00:13:28,650
to defend against golden
reward hacking, right?

353
00:13:28,650 --> 00:13:31,949
One solution is to teach the AIs, context.

354
00:13:31,950 --> 00:13:34,640
General term for this sort of
research is value alignment.

355
00:13:34,640 --> 00:13:37,280
How can we create AIs
that mirror our values?

356
00:13:37,280 --> 00:13:39,839
And you think about solutions
in terms of two extremes.

357
00:13:39,840 --> 00:13:42,810
The first is to explicitly
specify those values,

358
00:13:42,810 --> 00:13:44,060
and the other is to create AIs

359
00:13:44,060 --> 00:13:45,280
that learn our values,

360
00:13:45,280 --> 00:13:47,893
possibly by observing humans in action.

361
00:13:49,640 --> 00:13:52,230
So how realistic is
anything I've said so far?

362
00:13:52,230 --> 00:13:53,977
The answer is, it depends.

363
00:13:53,977 --> 00:13:57,420
But the feasibility of
any AI hacking depends

364
00:13:57,420 --> 00:13:59,382
on the specific system being modeled.

365
00:14:00,220 --> 00:14:03,370
For an AI to even start
on optimizing a problem,

366
00:14:03,370 --> 00:14:06,140
let alone hacking a
completely novel solution,

367
00:14:06,140 --> 00:14:08,810
all the rules of the
environment must be formalized

368
00:14:08,810 --> 00:14:10,959
in a way the computer can understand.

369
00:14:10,960 --> 00:14:12,170
Goals.

370
00:14:12,170 --> 00:14:13,930
An AI that (indistinct)
objective functions

371
00:14:13,930 --> 00:14:15,410
need to be established.

372
00:14:15,410 --> 00:14:17,579
And the AI need some sort of feedback

373
00:14:17,580 --> 00:14:18,440
on how well it's doing

374
00:14:18,440 --> 00:14:20,333
so it can improve its performance.

375
00:14:21,520 --> 00:14:23,750
Sometimes this is a trivial matter.

376
00:14:23,750 --> 00:14:26,130
And for a game like Go, it's easy.

377
00:14:26,130 --> 00:14:27,970
The rules, objective, and feedback;

378
00:14:27,970 --> 00:14:29,060
did you win or lose?

379
00:14:29,060 --> 00:14:31,430
Are all precisely specified.

380
00:14:31,430 --> 00:14:32,959
And there's nothing
outside of those things

381
00:14:32,960 --> 00:14:33,960
to muddy the waters.

382
00:14:35,050 --> 00:14:36,709
This is why most of the current examples

383
00:14:36,710 --> 00:14:39,990
of golden reward hacking come
from simulated environments.

384
00:14:39,990 --> 00:14:42,070
These are artificial and constrained

385
00:14:42,070 --> 00:14:45,063
with all the rules specified to the AI.

386
00:14:46,430 --> 00:14:48,479
What matters is the ambiguity in a system

387
00:14:49,340 --> 00:14:53,120
where we can imagine feeding
the world's tax laws into an AI

388
00:14:53,120 --> 00:14:55,950
because the tax code consists of formulas.

389
00:14:55,950 --> 00:14:59,260
But ambiguity still exists
in some of those laws.

390
00:14:59,260 --> 00:15:01,810
That ambiguity is difficult
to translate into code,

391
00:15:01,810 --> 00:15:05,020
which means that an AI will
have trouble dealing with it.

392
00:15:05,020 --> 00:15:07,800
Most human systems are
even more ambiguous.

393
00:15:07,800 --> 00:15:09,839
It's hard to imagine an AI coming up

394
00:15:09,840 --> 00:15:13,093
with a real world sports hack
like curving a hockey stick.

395
00:15:14,145 --> 00:15:15,750
An AI would have to
understand not just the rules

396
00:15:15,750 --> 00:15:16,870
of the game,

397
00:15:16,870 --> 00:15:18,730
but the physiology of the players,

398
00:15:18,730 --> 00:15:20,600
the aerodynamics of
the stick and the puck,

399
00:15:20,600 --> 00:15:22,260
and on.

400
00:15:22,260 --> 00:15:24,210
And this ambiguity ends up being

401
00:15:24,210 --> 00:15:26,913
a near-term security
defense against AI hacking.

402
00:15:27,930 --> 00:15:31,010
It'll be a long time
before AIs will be capable

403
00:15:31,010 --> 00:15:33,120
of modeling and simulating the ways

404
00:15:33,120 --> 00:15:34,400
that people work,

405
00:15:34,400 --> 00:15:36,550
and before they are capable of coming up

406
00:15:36,550 --> 00:15:40,160
with novel ways to hack
legislative processes.

407
00:15:40,160 --> 00:15:43,089
We won't have AI generated sports hacks,

408
00:15:43,090 --> 00:15:45,380
(indistinct) Androids
actually play the sports.

409
00:15:45,380 --> 00:15:47,763
Well, maybe until generalized AI appears.

410
00:15:48,780 --> 00:15:51,000
Probably the first place
to look for AI hacking

411
00:15:51,000 --> 00:15:52,560
is in financial systems,

412
00:15:52,560 --> 00:15:53,939
since those rules are designed

413
00:15:53,940 --> 00:15:56,090
to be algorithm retractable.

414
00:15:56,090 --> 00:15:57,780
We can imagine equipping an AI

415
00:15:57,780 --> 00:16:00,120
with all the world's financial laws,

416
00:16:00,120 --> 00:16:02,830
plus all the world's news
and financial information,

417
00:16:02,830 --> 00:16:06,180
and then giving it the
goal of maximize profits.

418
00:16:06,180 --> 00:16:08,459
My guess is that this isn't very far off,

419
00:16:08,460 --> 00:16:11,750
and that the result will be
all sorts of novel hacks.

420
00:16:11,750 --> 00:16:13,700
But here's the thing about AI.

421
00:16:13,700 --> 00:16:16,100
Advances are discontinuous
and counterintuitive.

422
00:16:17,030 --> 00:16:18,470
Things that seem to be easy

423
00:16:18,470 --> 00:16:19,660
to not to be hard,

424
00:16:19,660 --> 00:16:20,819
and things that seem to be hard

425
00:16:20,820 --> 00:16:21,910
to not to be easy.

426
00:16:21,910 --> 00:16:22,770
And we don't know

427
00:16:22,770 --> 00:16:24,370
until a breakthrough occurs.

428
00:16:24,370 --> 00:16:26,770
When I was a college
student in the early '80s,

429
00:16:26,770 --> 00:16:29,060
we learned that the game of
Go would never be mastered

430
00:16:29,060 --> 00:16:29,892
by a computer

431
00:16:29,893 --> 00:16:31,620
because of its enormous complexity.

432
00:16:31,620 --> 00:16:32,640
Not the rules,

433
00:16:32,640 --> 00:16:34,670
but the number of rules.

434
00:16:34,670 --> 00:16:38,160
And now, a computer has
beaten a human world champion.

435
00:16:38,160 --> 00:16:40,637
Some of it was due to
advances in the science of AI,

436
00:16:40,637 --> 00:16:42,239
but most of the improvement was just

437
00:16:42,240 --> 00:16:45,350
by throwing more computing
power at the problem.

438
00:16:45,350 --> 00:16:47,350
So while a world filled with AI hackers

439
00:16:47,350 --> 00:16:48,910
is still science fiction,

440
00:16:48,910 --> 00:16:50,653
it's not stupid science fiction.

441
00:16:51,590 --> 00:16:54,433
And we had better start thinking
about these implications.

442
00:16:56,070 --> 00:16:58,330
Hacking is as old as humanity.

443
00:16:58,330 --> 00:17:00,210
We are creative problem solvers,

444
00:17:00,210 --> 00:17:02,390
we are loophole exploiters,

445
00:17:02,390 --> 00:17:04,619
we manipulate systems
that serve our interests.

446
00:17:04,619 --> 00:17:06,699
We strive for more influence,

447
00:17:06,700 --> 00:17:08,230
more power, more wealth,

448
00:17:08,230 --> 00:17:11,119
and hacking has forever
been a part of that.

449
00:17:11,119 --> 00:17:13,750
Still, no humans maximize
their own interest

450
00:17:13,750 --> 00:17:14,920
without constraint.

451
00:17:14,920 --> 00:17:16,760
Even sociopaths are constrained

452
00:17:16,760 --> 00:17:18,200
by the complexity of society

453
00:17:18,200 --> 00:17:20,430
and their own contradictory impulses

454
00:17:20,430 --> 00:17:22,900
that concern about their
reputation or punishment,

455
00:17:22,900 --> 00:17:24,260
they have limited time.

456
00:17:24,260 --> 00:17:27,022
And these are very human
qualities limit hacking.

457
00:17:27,940 --> 00:17:31,330
Hacking changed when
everything became computerized.

458
00:17:31,330 --> 00:17:33,320
Because of their formalism and complexity,

459
00:17:33,320 --> 00:17:35,280
computers are uniquely hackable.

460
00:17:35,280 --> 00:17:37,860
And today, everything is a computer.

461
00:17:37,860 --> 00:17:39,520
Cars, appliances, phones,

462
00:17:39,520 --> 00:17:41,200
they're all computers.

463
00:17:41,200 --> 00:17:44,250
All our social systems:
taxation, finance, elections,

464
00:17:44,250 --> 00:17:47,873
are complex socio-technical
systems involving computers.

465
00:17:48,880 --> 00:17:52,540
To date, hacking has exclusively
been a human activity.

466
00:17:52,540 --> 00:17:55,050
Searching for new hacks
requires expertise,

467
00:17:55,050 --> 00:17:57,253
creativity, time, and luck.

468
00:17:58,560 --> 00:18:00,010
But when AI start hacking,

469
00:18:00,010 --> 00:18:01,860
everything will change again.

470
00:18:01,860 --> 00:18:04,020
They won't be constrained in the same ways

471
00:18:04,020 --> 00:18:05,910
or have the same limits as people,

472
00:18:05,910 --> 00:18:08,100
they'll think like aliens.

473
00:18:08,100 --> 00:18:11,293
And they'll change hacking
speed, scale, and scope.

474
00:18:12,280 --> 00:18:13,270
Speed is easy.

475
00:18:13,270 --> 00:18:15,790
Computers are much faster than people.

476
00:18:15,790 --> 00:18:18,360
A human creative process that
might take months or years,

477
00:18:18,360 --> 00:18:20,159
could get compressed to days, hours,

478
00:18:20,160 --> 00:18:21,940
or even seconds.

479
00:18:21,940 --> 00:18:24,110
And what might happen when you feed an AI,

480
00:18:24,110 --> 00:18:26,560
the entire U.S. tax code.

481
00:18:26,560 --> 00:18:28,669
Or in the case of a
multinational corporation,

482
00:18:28,670 --> 00:18:31,300
the entire world's tax codes.

483
00:18:31,300 --> 00:18:33,470
Will it figure out without being told

484
00:18:33,470 --> 00:18:35,690
that it's smart to incorporate in Delaware

485
00:18:35,690 --> 00:18:37,920
and register a ship in Panama?

486
00:18:37,920 --> 00:18:39,360
How many loopholes will it find

487
00:18:39,360 --> 00:18:40,909
that we don't already know about?

488
00:18:40,910 --> 00:18:43,440
Dozens, hundreds, thousands?

489
00:18:43,440 --> 00:18:44,523
We have no idea.

490
00:18:45,490 --> 00:18:46,530
And it's not just speed,

491
00:18:46,530 --> 00:18:48,000
but scale as well.

492
00:18:48,000 --> 00:18:50,910
Once AI systems start discovering hacks,

493
00:18:50,910 --> 00:18:52,480
they'll be able to exploit them

494
00:18:52,480 --> 00:18:54,093
at a scale we're not ready for.

495
00:18:55,180 --> 00:18:56,870
We're already seeing shadows of this

496
00:18:56,870 --> 00:18:58,572
with AI generated text.

497
00:18:59,610 --> 00:19:03,169
Soon, AI text generation
bots will be replicated

498
00:19:03,170 --> 00:19:04,993
in the millions across social media.

499
00:19:05,840 --> 00:19:08,159
There'll be able to engage on
the issues around the clock,

500
00:19:08,160 --> 00:19:10,640
posting billions of messages.

501
00:19:10,640 --> 00:19:13,920
They will overwhelm any
actual online discussions.

502
00:19:13,920 --> 00:19:16,300
What we see as boisterous political debate

503
00:19:16,300 --> 00:19:18,639
will be bots arguing the other bots.

504
00:19:18,640 --> 00:19:19,870
They'll artificially influence

505
00:19:19,870 --> 00:19:21,209
what we think is normal

506
00:19:21,210 --> 00:19:22,760
and what we think others think.

507
00:19:24,070 --> 00:19:26,439
The increase in scope of
AI systems also makes hacks

508
00:19:26,440 --> 00:19:27,333
more dangerous.

509
00:19:28,300 --> 00:19:29,950
AIs are already making important decisions

510
00:19:29,950 --> 00:19:31,130
that affect our lives.

511
00:19:31,130 --> 00:19:32,820
Decisions that we used to believe

512
00:19:32,820 --> 00:19:35,470
with the exclusive purview of humans:

513
00:19:35,470 --> 00:19:37,560
AIs make bail and parole decisions,

514
00:19:37,560 --> 00:19:39,629
they help decide who receives bank loans,

515
00:19:39,630 --> 00:19:41,090
they screen job candidates,

516
00:19:41,090 --> 00:19:42,610
applicants for college,

517
00:19:42,610 --> 00:19:45,080
and people who apply
for government services.

518
00:19:45,080 --> 00:19:47,300
As AI systems get more capable,

519
00:19:47,300 --> 00:19:48,980
society will see more

520
00:19:48,980 --> 00:19:50,830
and more important decisions to them.

521
00:19:51,720 --> 00:19:53,820
This means that hacks of
those systems will become

522
00:19:53,820 --> 00:19:54,653
more damaging.

523
00:19:55,490 --> 00:19:57,160
And these hacks will be perpetrated

524
00:19:57,160 --> 00:19:58,853
by the powerful against us.

525
00:19:59,710 --> 00:20:01,240
And while we have societal systems

526
00:20:01,240 --> 00:20:03,010
that deal with hacks,

527
00:20:03,010 --> 00:20:07,020
they were developed when
the hackers were human,

528
00:20:07,020 --> 00:20:09,490
and reflect the pace of human hackers.

529
00:20:09,490 --> 00:20:11,390
We don't have any system of governance

530
00:20:11,390 --> 00:20:12,860
that can deal with hundreds,

531
00:20:12,860 --> 00:20:14,310
let alone thousands,

532
00:20:14,310 --> 00:20:16,393
of newly discovered tax loopholes.

533
00:20:17,390 --> 00:20:18,223
We won't be able

534
00:20:18,223 --> 00:20:21,290
to recover from an AI
figuring out unanticipated,

535
00:20:21,290 --> 00:20:23,203
but legal hacks of financial systems.

536
00:20:24,280 --> 00:20:26,540
At computer speed, scale, and scope,

537
00:20:26,540 --> 00:20:27,960
hacking becomes a problem

538
00:20:27,960 --> 00:20:30,223
that we society can no longer manage.

539
00:20:31,550 --> 00:20:33,842
All right, finally,
let's talk about defense.

540
00:20:35,200 --> 00:20:36,460
When AIs are able

541
00:20:36,460 --> 00:20:40,320
to discover new software
vulnerabilities in computer code,

542
00:20:40,320 --> 00:20:43,540
it will be an incredible
boon to hackers everywhere.

543
00:20:43,540 --> 00:20:45,420
They'll be able to use
those vulnerabilities

544
00:20:45,420 --> 00:20:47,370
to hack networks around the world.

545
00:20:47,370 --> 00:20:48,803
It will put us all at risk.

546
00:20:49,830 --> 00:20:52,179
But that same technology will be useful

547
00:20:52,180 --> 00:20:53,920
to the defense as well.

548
00:20:53,920 --> 00:20:56,680
But imagine how a software
company might deploy

549
00:20:56,680 --> 00:21:00,130
a vulnerability finding
AI on its own code.

550
00:21:00,130 --> 00:21:01,000
It could identify,

551
00:21:01,000 --> 00:21:02,390
and then patch all,

552
00:21:02,390 --> 00:21:03,223
or at least all

553
00:21:03,223 --> 00:21:05,830
of the automatically
discoverable vulnerabilities

554
00:21:05,830 --> 00:21:06,663
in this products,

555
00:21:06,663 --> 00:21:07,710
before releasing them.

556
00:21:08,670 --> 00:21:09,840
The feature might even be built

557
00:21:09,840 --> 00:21:11,199
into the software development tools

558
00:21:11,200 --> 00:21:13,060
and happen automatically.

559
00:21:13,060 --> 00:21:16,330
We can imagine a future with
software vulnerabilities,

560
00:21:16,330 --> 00:21:17,663
are a thing of the past.

561
00:21:18,590 --> 00:21:21,379
Of course, the transition
period will be dangerous.

562
00:21:21,380 --> 00:21:22,940
New code might be secure,

563
00:21:22,940 --> 00:21:24,780
but legacy code will still be vulnerable.

564
00:21:24,780 --> 00:21:27,210
There, the attackers have an advantage.

565
00:21:27,210 --> 00:21:28,780
But over the long run,

566
00:21:28,780 --> 00:21:31,970
an AI technology that finds
software vulnerabilities,

567
00:21:31,970 --> 00:21:33,193
favors the defense.

568
00:21:34,350 --> 00:21:35,340
It's the same when we turned

569
00:21:35,340 --> 00:21:37,260
to hacking broader social systems.

570
00:21:37,260 --> 00:21:40,450
Sure, AI hackers might find
hundreds of vulnerabilities

571
00:21:40,450 --> 00:21:42,220
in the existing tax code,

572
00:21:42,220 --> 00:21:44,180
but that same technology can be used

573
00:21:44,180 --> 00:21:47,290
to evaluate any potential vulnerabilities

574
00:21:47,290 --> 00:21:49,433
in a new tax law or tax ruling.

575
00:21:50,280 --> 00:21:52,920
And imagine a new tax law
being tested this way.

576
00:21:52,920 --> 00:21:56,140
Someone, it could be a
legislator, a watchdog group,

577
00:21:56,140 --> 00:21:57,130
the press,

578
00:21:57,130 --> 00:21:58,870
could take the text of a bill

579
00:21:58,870 --> 00:22:02,129
and find all the
exploitable vulnerabilities.

580
00:22:02,130 --> 00:22:04,670
This doesn't mean the tax
loopholes will get fixed,

581
00:22:04,670 --> 00:22:06,210
but it does mean they'll become public

582
00:22:06,210 --> 00:22:08,000
and part of the policy debate.

583
00:22:08,000 --> 00:22:10,160
And they can in theory, be patched,

584
00:22:10,160 --> 00:22:12,670
before the rich and powerful exploit them.

585
00:22:12,670 --> 00:22:16,140
Here too, the transition
period will be dangerous.

586
00:22:16,140 --> 00:22:18,030
But while AI hackers can be employed

587
00:22:18,030 --> 00:22:20,139
by both the offense and the defense,

588
00:22:20,140 --> 00:22:21,990
in the end, the defense will prevail.

589
00:22:23,630 --> 00:22:25,460
Ensuring that the defense prevails,

590
00:22:25,460 --> 00:22:28,060
also requires building
resilient governing structures

591
00:22:28,060 --> 00:22:31,399
that can quickly and
effectively respond to hacks.

592
00:22:31,400 --> 00:22:33,070
It won't do any good if it takes years

593
00:22:33,070 --> 00:22:34,639
to update the tax code,

594
00:22:34,640 --> 00:22:36,710
or if a legislative hack
becomes so entrenched

595
00:22:36,710 --> 00:22:39,110
that it can't politically be patched.

596
00:22:39,110 --> 00:22:41,580
Modern software is continually patched.

597
00:22:41,580 --> 00:22:44,679
You know how often you update
your computers and phones.

598
00:22:44,680 --> 00:22:46,380
We need society's rules and laws

599
00:22:46,380 --> 00:22:48,660
to be similarly patchable.

600
00:22:48,660 --> 00:22:50,700
This is a hard problem
in modern governance,

601
00:22:50,700 --> 00:22:52,703
and well beyond the scope of this talk.

602
00:22:53,540 --> 00:22:55,899
It also isn't a substantially
different problem

603
00:22:55,900 --> 00:22:57,330
than building governing structures

604
00:22:57,330 --> 00:22:59,409
that can operate at the
speed and complexity

605
00:22:59,410 --> 00:23:00,633
of the information age.

606
00:23:01,940 --> 00:23:04,490
The overarching solution here is people.

607
00:23:04,490 --> 00:23:07,250
What I've been describing is
the interplay between humans

608
00:23:07,250 --> 00:23:08,440
and computer systems,

609
00:23:08,440 --> 00:23:10,990
and the risks inherent when
the computers start doing

610
00:23:10,990 --> 00:23:12,920
the part of humans.

611
00:23:12,920 --> 00:23:16,220
This too is a more general
problem than AI hackers.

612
00:23:16,220 --> 00:23:17,690
And it's also one that technologists

613
00:23:17,690 --> 00:23:19,920
and futurists are writing about.

614
00:23:19,920 --> 00:23:22,160
And while it's easy to
let technology lead us

615
00:23:22,160 --> 00:23:23,320
into the future,

616
00:23:23,320 --> 00:23:26,260
we're much better off if
we as a society decide

617
00:23:26,260 --> 00:23:28,660
what technology's role
in our futures should be.

618
00:23:29,520 --> 00:23:32,300
This is something we
need to figure out now

619
00:23:32,300 --> 00:23:34,280
before these AIs come in line

620
00:23:34,280 --> 00:23:36,420
and start hacking our world.

621
00:23:36,420 --> 00:23:37,673
Thank you.

622
00:23:37,673 --> 00:23:40,256
(upbeat music)

