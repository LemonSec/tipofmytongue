1
00:00:00,334 --> 00:00:03,417
(music)

2
00:00:23,440 --> 00:00:28,340
- Welcome to the 2021 Most
Dangerous New Attack Techniques.

3
00:00:28,340 --> 00:00:32,720
This panel has had a remarkable
record over the last decade

4
00:00:32,720 --> 00:00:37,010
of figuring out exactly
which types of techniques

5
00:00:37,010 --> 00:00:40,930
are going to be and are
immediately the most damaging,

6
00:00:40,930 --> 00:00:43,640
and that's because they're
all on the front edge

7
00:00:43,640 --> 00:00:44,800
of the field.

8
00:00:44,800 --> 00:00:46,949
Ed Skoudis is the world's expert

9
00:00:46,950 --> 00:00:51,950
on how attacks are accomplished
and what to do about them,

10
00:00:52,310 --> 00:00:53,730
and that's because he gets called in

11
00:00:53,730 --> 00:00:56,019
on just about every one
of the major attacks.

12
00:00:56,020 --> 00:00:58,010
When the White House
decided they were gonna put

13
00:00:58,010 --> 00:00:59,720
a new trusted internet connection

14
00:00:59,720 --> 00:01:01,260
around the whole civilian government,

15
00:01:01,260 --> 00:01:02,839
it was Ed they called in to figure out

16
00:01:02,840 --> 00:01:04,580
how the attackers were gonna break it.

17
00:01:04,580 --> 00:01:06,080
So, he's first.

18
00:01:06,080 --> 00:01:08,360
Second is Heather Mahalik.

19
00:01:08,360 --> 00:01:12,050
Heather is on the handheld devices end.

20
00:01:12,050 --> 00:01:14,920
She's the FBI's go-to person,

21
00:01:14,920 --> 00:01:18,400
expert on cases, the big cases.

22
00:01:18,400 --> 00:01:22,910
And you'll hear some wonderful,
wonderful attack techniques

23
00:01:22,910 --> 00:01:26,600
from her world and very
personal ones for most of us.

24
00:01:26,600 --> 00:01:28,369
Third will be Johannes Ullrich.

25
00:01:28,370 --> 00:01:29,500
I think you all know him.

26
00:01:29,500 --> 00:01:31,380
He runs the Internet Storm Center,

27
00:01:31,380 --> 00:01:33,410
the early warning system for the internet.

28
00:01:33,410 --> 00:01:36,420
His 30 handlers, incident
handlers around the world

29
00:01:36,420 --> 00:01:38,700
are the first to see almost everything.

30
00:01:38,700 --> 00:01:42,730
And his five-minute summary
of what happened yesterday

31
00:01:42,730 --> 00:01:45,970
is listened to by more than
30,000 people every morning

32
00:01:45,970 --> 00:01:47,410
at the Internet Storm Center.

33
00:01:47,410 --> 00:01:48,450
What you don't know about him

34
00:01:48,450 --> 00:01:50,700
is he's also the head of research

35
00:01:50,700 --> 00:01:53,700
at the fastest growing
college in cybersecurity,

36
00:01:53,700 --> 00:01:56,210
and that's SANS.edu.

37
00:01:56,210 --> 00:01:59,619
And his papers, the papers
of his research people,

38
00:01:59,620 --> 00:02:01,390
are read by more than a
million people a year.

39
00:02:01,390 --> 00:02:03,340
So, that's Johannes.

40
00:02:03,340 --> 00:02:05,800
And finally, is Katie Nickels.

41
00:02:05,800 --> 00:02:08,449
Katie is the go-to person

42
00:02:08,449 --> 00:02:10,869
across the world, actually, on threats.

43
00:02:10,870 --> 00:02:12,160
What are the main threats?

44
00:02:12,160 --> 00:02:15,650
What's real, what's not real?

45
00:02:15,650 --> 00:02:18,270
I didn't know her very well,
but I was in a conference

46
00:02:18,270 --> 00:02:21,240
on the future of threat analysis in London

47
00:02:21,240 --> 00:02:23,830
and every speaker was a famous person

48
00:02:23,830 --> 00:02:26,660
and she blew them all away,
so you've got a treat coming.

49
00:02:26,660 --> 00:02:28,722
Let's get started with Ed Skoudis.

50
00:02:31,970 --> 00:02:32,803
- Thank you, Alan.

51
00:02:32,803 --> 00:02:34,713
I appreciate your kind introduction.

52
00:02:35,710 --> 00:02:38,860
I'd like to share with you one
of the biggest attack vectors

53
00:02:38,860 --> 00:02:40,120
that we're seeing today,

54
00:02:40,120 --> 00:02:43,610
and it's based on undermining
the integrity of software.

55
00:02:43,610 --> 00:02:47,760
You've probably heard about
software supply chain attacks.

56
00:02:47,760 --> 00:02:50,600
That's one example of a bigger problem

57
00:02:50,600 --> 00:02:52,900
that we're facing in cybersecurity.

58
00:02:52,900 --> 00:02:54,570
Now, this problem goes back many years.

59
00:02:54,570 --> 00:02:56,859
In fact, in 1984,

60
00:02:56,860 --> 00:02:59,300
Ken Thompson published a white paper

61
00:02:59,300 --> 00:03:01,740
as part of his Turing Award lecture.

62
00:03:01,740 --> 00:03:03,790
It's only three pages long
and if you haven't read it,

63
00:03:03,790 --> 00:03:05,090
I recommend that you do.

64
00:03:05,090 --> 00:03:08,040
It's called "Reflections
on Trusting Trust,"

65
00:03:08,040 --> 00:03:09,940
and his conclusion is profound.

66
00:03:09,940 --> 00:03:13,387
Ken Thompson said, "No amount
of source-level verification

67
00:03:13,387 --> 00:03:18,250
"or scrutiny will protect you
from using untrusted code."

68
00:03:18,250 --> 00:03:20,140
You see, our software development

69
00:03:20,140 --> 00:03:24,040
and distribution processes
today are focused on speed,

70
00:03:24,040 --> 00:03:26,420
getting new code and features out faster.

71
00:03:26,420 --> 00:03:29,170
They're not focused on
trust and cybersecurity.

72
00:03:29,170 --> 00:03:31,070
And this is a pretty profound problem

73
00:03:31,070 --> 00:03:34,530
because it makes me think
about Zero Trust architectures.

74
00:03:34,530 --> 00:03:36,450
Zero Trust is a great concept.

75
00:03:36,450 --> 00:03:40,829
The idea is that every user,
every system, every device,

76
00:03:40,830 --> 00:03:44,390
and every transaction that
our organization will process

77
00:03:44,390 --> 00:03:48,250
has to be authenticated and
validated and authorized

78
00:03:48,250 --> 00:03:49,480
or else we'll block it.

79
00:03:49,480 --> 00:03:52,149
It's a great architecture,
but how do you implement that?

80
00:03:52,150 --> 00:03:53,530
You do it via software.

81
00:03:53,530 --> 00:03:56,440
And if you update that
software using mechanisms

82
00:03:56,440 --> 00:03:59,020
that don't ensure the
integrity of that software,

83
00:03:59,020 --> 00:04:00,160
you've got a problem.

84
00:04:00,160 --> 00:04:01,829
Your Zero Trust architecture

85
00:04:01,830 --> 00:04:05,310
is trusting software
that's not trustworthy.

86
00:04:05,310 --> 00:04:07,280
Now, we've seen several attacks

87
00:04:07,280 --> 00:04:08,890
over the last year based on this,

88
00:04:08,890 --> 00:04:10,619
and I think we're gonna see many attacks

89
00:04:10,620 --> 00:04:12,150
in years to come on it.

90
00:04:12,150 --> 00:04:14,680
Surely you're familiar
with the SolarWinds Attack.

91
00:04:14,680 --> 00:04:16,829
There are other RSA
sessions going on this week

92
00:04:16,829 --> 00:04:18,779
about that specific attack.

93
00:04:18,779 --> 00:04:22,190
But in synopsis, a
nation-state-level attacker

94
00:04:22,190 --> 00:04:25,070
was able to undermine
the software development

95
00:04:25,070 --> 00:04:27,150
and packaging process for SolarWinds,

96
00:04:27,150 --> 00:04:29,099
software used to manage environments.

97
00:04:29,100 --> 00:04:30,830
And that attacker, by doing that,

98
00:04:30,830 --> 00:04:33,030
was able to get malware installed

99
00:04:33,030 --> 00:04:35,280
in tens of thousands of environments.

100
00:04:35,280 --> 00:04:37,969
And we're still cleaning up
against that attack today,

101
00:04:37,970 --> 00:04:41,330
even though it was discovered
back in December of 2020.

102
00:04:41,330 --> 00:04:43,780
You know, there was another
paper that came out last year

103
00:04:43,780 --> 00:04:45,500
that was really quite profound

104
00:04:45,500 --> 00:04:48,910
about undermining the
integrity of software

105
00:04:48,910 --> 00:04:51,110
that's developed in an
open-source paradigm.

106
00:04:51,110 --> 00:04:54,440
The paper was called "The
Backstabber's Knife Collection."

107
00:04:54,440 --> 00:04:57,410
It's a pretty amazing name,
and it's a paper by Marc Ohm

108
00:04:57,410 --> 00:04:59,160
and several other security researchers.

109
00:04:59,160 --> 00:05:01,830
And they talk about several
dozen different ways

110
00:05:01,830 --> 00:05:04,280
attackers could exploit vulnerabilities

111
00:05:04,280 --> 00:05:07,700
or infiltrate malware
into open-source projects.

112
00:05:07,700 --> 00:05:10,599
And one example of this kind of attack

113
00:05:10,600 --> 00:05:12,630
was actually documented in detail

114
00:05:12,630 --> 00:05:16,270
by Alex Berson in February 2021.

115
00:05:16,270 --> 00:05:19,750
Alex talks about a
dependency confusion attack

116
00:05:19,750 --> 00:05:21,480
and how he was able to leverage this

117
00:05:21,480 --> 00:05:23,620
as a legitimate security researcher

118
00:05:23,620 --> 00:05:26,960
to be able to trick large
software development environments

119
00:05:26,960 --> 00:05:30,810
to create packages that had the same name

120
00:05:30,810 --> 00:05:32,260
for public packages

121
00:05:32,260 --> 00:05:35,830
as packages that are private
inside the organization.

122
00:05:35,830 --> 00:05:38,919
So, he was able to trick the
package management solutions

123
00:05:38,920 --> 00:05:41,160
into pulling in his code.

124
00:05:41,160 --> 00:05:44,190
And using this technique, he
was able to get code execution

125
00:05:44,190 --> 00:05:46,180
inside the software
development environments

126
00:05:46,180 --> 00:05:48,950
of Apple, Microsoft, and PayPal.

127
00:05:48,950 --> 00:05:52,310
This truly is a big and
foundational problem.

128
00:05:52,310 --> 00:05:55,010
So, what can you do to try to manage this?

129
00:05:55,010 --> 00:05:56,490
There's no single solution

130
00:05:56,490 --> 00:05:58,420
to the problem of software integrity

131
00:05:58,420 --> 00:06:01,310
and software supply chain management,

132
00:06:01,310 --> 00:06:03,660
but there's a lotta different
things that we can apply.

133
00:06:03,660 --> 00:06:05,620
First, we need to know what software

134
00:06:05,620 --> 00:06:08,970
we have in our environments
so that we can defend it.

135
00:06:08,970 --> 00:06:11,170
So, you need to have a
good software inventory.

136
00:06:11,170 --> 00:06:14,330
If you look at the Center for
Internet Security's controls,

137
00:06:14,330 --> 00:06:16,169
control number two

138
00:06:16,170 --> 00:06:18,070
is the one about having
software inventory.

139
00:06:18,070 --> 00:06:19,020
It's so important.

140
00:06:19,020 --> 00:06:21,049
If you don't know what's
there, you can't defend it.

141
00:06:21,050 --> 00:06:23,200
But even if you have a
good software inventory,

142
00:06:23,200 --> 00:06:24,349
you're still gonna come up lacking

143
00:06:24,350 --> 00:06:26,750
'cause you don't know
what's inside the software.

144
00:06:26,750 --> 00:06:28,520
That's we see the rise

145
00:06:28,520 --> 00:06:31,859
of software bill of
materials requirements.

146
00:06:31,860 --> 00:06:34,347
What that is is it essentially
says, "Here's the ingredients

147
00:06:34,347 --> 00:06:36,570
"that go into making your software."

148
00:06:36,570 --> 00:06:40,340
And organizations should and
are increasingly demanding

149
00:06:40,340 --> 00:06:42,150
that they get a software bill of materials

150
00:06:42,150 --> 00:06:44,979
associated with all the
software in their environment.

151
00:06:44,980 --> 00:06:47,120
So, your vendor will tell
you that this software

152
00:06:47,120 --> 00:06:49,350
includes these specific open-source

153
00:06:49,350 --> 00:06:51,440
and maybe other commercial packages.

154
00:06:51,440 --> 00:06:54,230
Now, this won't solve the
problem with software integrity,

155
00:06:54,230 --> 00:06:56,550
but it'll shine some sunlight on it

156
00:06:56,550 --> 00:06:58,890
so we have a better chance
at finding vulnerabilities

157
00:06:58,890 --> 00:07:03,110
and potential malware inserted
into the development process.

158
00:07:03,110 --> 00:07:06,320
Also, we need file integrity
management solutions.

159
00:07:06,320 --> 00:07:08,460
These solutions have been
available for decades,

160
00:07:08,460 --> 00:07:11,820
but not every organization
has thoroughly deployed them.

161
00:07:11,820 --> 00:07:14,349
I've been involved in several
cases in just the last year

162
00:07:14,350 --> 00:07:16,980
where attackers were able to find systems

163
00:07:16,980 --> 00:07:18,790
that didn't have file integrity management

164
00:07:18,790 --> 00:07:22,140
and put traditional root
kits on those machines.

165
00:07:22,140 --> 00:07:24,130
Now, if you have very
sophisticated attackers

166
00:07:24,130 --> 00:07:25,860
that are flying under the radar screen,

167
00:07:25,860 --> 00:07:28,590
you really should employ threat hunting.

168
00:07:28,590 --> 00:07:31,400
Threat hunting is where we
take humans with experience

169
00:07:31,400 --> 00:07:34,549
and apply them looking through
our most sensitive systems

170
00:07:34,550 --> 00:07:36,430
to see if they've been compromised.

171
00:07:36,430 --> 00:07:38,570
It's a really good idea
to do threat hunting

172
00:07:38,570 --> 00:07:40,940
on a periodic and regular basis

173
00:07:40,940 --> 00:07:43,190
to look for things that
our automated tools

174
00:07:43,190 --> 00:07:45,370
haven't detected or discovered.

175
00:07:45,370 --> 00:07:47,010
Now, if you do threat hunting,

176
00:07:47,010 --> 00:07:48,300
you might find that there's a threat

177
00:07:48,300 --> 00:07:50,400
and therefore you have to
do some incident handling.

178
00:07:50,400 --> 00:07:52,099
But what if you do threat hunting

179
00:07:52,100 --> 00:07:54,130
and your threat hunters
don't discover anything?

180
00:07:54,130 --> 00:07:55,900
Now, that could be because
there's no active threat

181
00:07:55,900 --> 00:07:57,979
in your environment,
and that's great news.

182
00:07:57,980 --> 00:07:59,770
But it also could be
that your threat hunters

183
00:07:59,770 --> 00:08:01,460
aren't able to detect them.

184
00:08:01,460 --> 00:08:03,070
So, what do you do when that happens?

185
00:08:03,070 --> 00:08:07,280
Well, I call this BYOT,
bring your own threat.

186
00:08:07,280 --> 00:08:10,760
That is have your red
team or hire a red team

187
00:08:10,760 --> 00:08:13,530
and have an assumed breach exercise

188
00:08:13,530 --> 00:08:14,890
where the red team is given access

189
00:08:14,890 --> 00:08:16,340
to systems inside your environment,

190
00:08:16,340 --> 00:08:19,330
and then you're measuring how
quickly your threat hunters

191
00:08:19,330 --> 00:08:22,690
on your blue team can detect
that and block the attack.

192
00:08:22,690 --> 00:08:24,910
This essentially gives
rise to purple teaming,

193
00:08:24,910 --> 00:08:27,190
where blue is helping red get better

194
00:08:27,190 --> 00:08:28,543
and red is helping blue.

195
00:08:30,130 --> 00:08:32,960
With that, I'd like to
turn things over now

196
00:08:32,960 --> 00:08:34,429
to Heather Mahalick.

197
00:08:34,429 --> 00:08:35,380
She's gonna be presenting

198
00:08:35,380 --> 00:08:37,730
some really interesting
attack vectors as well.

199
00:08:41,690 --> 00:08:42,683
- Thank you, Ed.

200
00:08:44,130 --> 00:08:48,180
I have the pleasure this year
of doing two actual threats,

201
00:08:48,180 --> 00:08:50,329
and I wanna start with the first one,

202
00:08:50,330 --> 00:08:52,080
which is improper session handling.

203
00:08:52,920 --> 00:08:54,670
Let's think about the
world we live in now.

204
00:08:54,670 --> 00:08:56,990
Last year, the stage at
RSA looked very different

205
00:08:56,990 --> 00:09:00,930
and we were standing up in
front of thousands of you.

206
00:09:00,930 --> 00:09:04,020
We have changed our
environments on the dime.

207
00:09:04,020 --> 00:09:06,699
We are literally working from home,

208
00:09:06,700 --> 00:09:08,520
accessing so many things.

209
00:09:08,520 --> 00:09:10,910
The sessions must be handled properly.

210
00:09:10,910 --> 00:09:12,060
So, when you think about this,

211
00:09:12,060 --> 00:09:14,469
think about how you access your networks.

212
00:09:14,470 --> 00:09:16,770
We generally use tokens.

213
00:09:16,770 --> 00:09:19,370
When we use these tokens,
how are they created?

214
00:09:19,370 --> 00:09:21,870
They're created with mobile applications.

215
00:09:21,870 --> 00:09:24,290
We all are attached to our devices.

216
00:09:24,290 --> 00:09:26,959
And as Alan said, I am
always attached to my device

217
00:09:26,960 --> 00:09:28,440
and that's what I'm known for.

218
00:09:28,440 --> 00:09:29,590
But we have to consider

219
00:09:29,590 --> 00:09:32,810
how are we securing these applications?

220
00:09:32,810 --> 00:09:34,329
How much are we relying on them?

221
00:09:34,330 --> 00:09:35,913
And are they actually safe?

222
00:09:37,280 --> 00:09:41,530
When we think of authorizations,
the fewer authorizations

223
00:09:41,530 --> 00:09:44,339
that are required by
your work environments,

224
00:09:44,340 --> 00:09:45,830
that is dangerous.

225
00:09:45,830 --> 00:09:47,840
I know as humans, it's annoying.

226
00:09:47,840 --> 00:09:50,610
We wanna be able to
just log into our email.

227
00:09:50,610 --> 00:09:52,610
We don't want to have to get a code

228
00:09:52,610 --> 00:09:54,750
and then enter our username and password.

229
00:09:54,750 --> 00:09:55,583
But if you think about it,

230
00:09:55,583 --> 00:09:57,829
we're actually safer because of that.

231
00:09:57,830 --> 00:10:01,440
So, these actual implementations
need to be in place.

232
00:10:01,440 --> 00:10:04,810
It keeps us safer and prevents disasters

233
00:10:04,810 --> 00:10:06,443
that are an actual threat.

234
00:10:07,580 --> 00:10:09,240
Single sign-on.

235
00:10:09,240 --> 00:10:12,060
Think of that name, single sign-on.

236
00:10:12,060 --> 00:10:13,920
How safe is it?

237
00:10:13,920 --> 00:10:15,459
Is it good enough for your networks?

238
00:10:15,460 --> 00:10:19,270
And honestly, this goes
back to what Ed just said.

239
00:10:19,270 --> 00:10:21,370
There's no single solution.

240
00:10:21,370 --> 00:10:25,400
How good is the employee
behind that single sign-on?

241
00:10:25,400 --> 00:10:27,810
What cautions are they having in place

242
00:10:27,810 --> 00:10:31,142
to make sure that their
devices are not compromised?

243
00:10:33,050 --> 00:10:35,079
What about the attacks I
talked about last year?

244
00:10:35,080 --> 00:10:37,110
So, do you see single sign-on MFA,

245
00:10:37,110 --> 00:10:38,920
multi-factor authentication?

246
00:10:38,920 --> 00:10:40,870
Last year, I want you to review my attack

247
00:10:40,870 --> 00:10:42,580
because it's still in place.

248
00:10:42,580 --> 00:10:45,110
The wrong devices are
falling into the wrong hands

249
00:10:45,110 --> 00:10:46,820
and people are getting your codes.

250
00:10:46,820 --> 00:10:48,490
Think about the persistence.

251
00:10:48,490 --> 00:10:49,970
If you keep getting a message

252
00:10:49,970 --> 00:10:52,010
saying someone's trying
to get into your account,

253
00:10:52,010 --> 00:10:53,650
are you going to say yes?

254
00:10:53,650 --> 00:10:55,396
Are you going to get
annoyed by it thinking,

255
00:10:55,397 --> 00:10:58,617
"Oh, it may be, you know
what, it may be my son.

256
00:10:58,617 --> 00:11:00,357
"He may be trying to
buy something on Amazon.

257
00:11:00,357 --> 00:11:01,890
"I will select yes."

258
00:11:01,890 --> 00:11:02,723
Don't do that.

259
00:11:02,723 --> 00:11:05,969
You need to control these
sessions and these tokens.

260
00:11:05,970 --> 00:11:09,470
And then, finally, what if
the sessions aren't secure?

261
00:11:09,470 --> 00:11:13,630
What if your token is not
secure and your data is leaked?

262
00:11:13,630 --> 00:11:16,590
This is how it's so easy
for someone to become us

263
00:11:16,590 --> 00:11:18,900
and manipulate the situation.

264
00:11:18,900 --> 00:11:21,079
I wanna walk you through an example.

265
00:11:21,080 --> 00:11:23,400
So, this is me; I'm using single sign-on.

266
00:11:23,400 --> 00:11:25,380
I wanna get access to my networks.

267
00:11:25,380 --> 00:11:26,840
The very first thing
that's going to happen

268
00:11:26,840 --> 00:11:29,280
is a code is going to be sent to my phone.

269
00:11:29,280 --> 00:11:31,189
I get the code from my phone.

270
00:11:31,190 --> 00:11:32,760
It is sent back to me.

271
00:11:32,760 --> 00:11:36,740
It is what I actually wanted,
and then I am granted access

272
00:11:36,740 --> 00:11:40,440
to everything from cloud
environments, your Teams,

273
00:11:40,440 --> 00:11:41,970
the way you communicate with one another,

274
00:11:41,970 --> 00:11:45,230
your email, cloud storage, your HR.

275
00:11:45,230 --> 00:11:49,050
It's honestly at the mercy of
that single sign-on control.

276
00:11:49,050 --> 00:11:53,740
This is fine as long as I
am a responsible employee,

277
00:11:53,740 --> 00:11:56,940
I control it, and I manage
those sessions properly.

278
00:11:56,940 --> 00:11:59,390
Because what if my face changes?

279
00:11:59,390 --> 00:12:02,060
What if an attacker has my device?

280
00:12:02,060 --> 00:12:04,553
And that's what I want you
to consider at this point.

281
00:12:05,980 --> 00:12:09,090
The other threat, the
crypto could be broken.

282
00:12:09,090 --> 00:12:10,890
We are impatient humans.

283
00:12:10,890 --> 00:12:12,569
This is something that I think has become

284
00:12:12,570 --> 00:12:14,520
even more prevalent during COVID

285
00:12:14,520 --> 00:12:16,210
and our new-world environments.

286
00:12:16,210 --> 00:12:19,110
Developers are under pressure
to provide us what we want.

287
00:12:19,110 --> 00:12:22,630
We want things faster,
better, more frequently.

288
00:12:22,630 --> 00:12:25,300
The issue is there are
known vulnerabilities,

289
00:12:25,300 --> 00:12:27,459
and we talk about this every single year.

290
00:12:27,460 --> 00:12:29,920
So, what happens if the
application you rely upon

291
00:12:29,920 --> 00:12:33,040
is using crypto that is known to be broken

292
00:12:33,040 --> 00:12:36,959
in order to provide you
access to a service faster?

293
00:12:36,960 --> 00:12:39,900
All of these token generators,

294
00:12:39,900 --> 00:12:41,520
they want to be the one-stop shop.

295
00:12:41,520 --> 00:12:44,689
They want you to use them, and you should.

296
00:12:44,690 --> 00:12:46,610
The issue is you just have to verify

297
00:12:46,610 --> 00:12:49,100
and ensure crypto is not broken.

298
00:12:49,100 --> 00:12:51,550
That is the responsibility of us.

299
00:12:51,550 --> 00:12:53,689
That is the responsibility
of our employers,

300
00:12:53,690 --> 00:12:57,190
to ensure that proper
quality assurance is taken

301
00:12:57,190 --> 00:13:00,450
and measured on the things that
we truly rely upon every day

302
00:13:00,450 --> 00:13:02,480
to access our most confidential

303
00:13:02,480 --> 00:13:05,270
and precious information and our casework.

304
00:13:05,270 --> 00:13:07,949
Alan was saying I work
on really important cases

305
00:13:07,950 --> 00:13:10,420
and I do have the luxury
of picking and choosing,

306
00:13:10,420 --> 00:13:12,610
but I would never want
that data to be leaked.

307
00:13:12,610 --> 00:13:14,880
I would never want data to
fall into the wrong hands,

308
00:13:14,880 --> 00:13:16,740
so I am extremely cautious

309
00:13:16,740 --> 00:13:19,120
with how I leverage my
tokens and my sessions.

310
00:13:19,120 --> 00:13:20,990
And I am huge on validation

311
00:13:20,990 --> 00:13:23,173
and verification of applications.

312
00:13:25,210 --> 00:13:26,710
Mitigation considerations,

313
00:13:26,710 --> 00:13:29,080
because I always like to
end on a positive note.

314
00:13:29,080 --> 00:13:31,310
Keep your session safe.

315
00:13:31,310 --> 00:13:32,359
Always log out.

316
00:13:32,360 --> 00:13:35,090
And again, I know we
don't like to do this.

317
00:13:35,090 --> 00:13:37,370
Many of us like to leave our screen open.

318
00:13:37,370 --> 00:13:40,130
We like to leave our devices available.

319
00:13:40,130 --> 00:13:41,427
We will check the box saying,

320
00:13:41,427 --> 00:13:43,350
"Use this for the next seven days."

321
00:13:43,350 --> 00:13:45,030
That's not secure.

322
00:13:45,030 --> 00:13:47,949
Developers, I encourage you,
make tokens that expire.

323
00:13:47,950 --> 00:13:49,710
Kick your people off the network.

324
00:13:49,710 --> 00:13:50,860
Kick them out.

325
00:13:50,860 --> 00:13:53,130
Make them get refreshed tokens.

326
00:13:53,130 --> 00:13:55,480
Single sign-on, everyone
has to protect it.

327
00:13:55,480 --> 00:13:57,610
We have to be responsible.

328
00:13:57,610 --> 00:14:02,610
For applications, trust but
verify, validate, test it,

329
00:14:02,800 --> 00:14:05,099
try to break it, see if you can crack it.

330
00:14:05,100 --> 00:14:07,550
See if any traces are left behind.

331
00:14:07,550 --> 00:14:10,719
And something I wanna leave
you all with, permissions.

332
00:14:10,720 --> 00:14:12,500
Make sure you look at the permissions

333
00:14:12,500 --> 00:14:13,950
for what you're installing.

334
00:14:13,950 --> 00:14:18,280
The permission landscape keeps
growing and I wanna know why.

335
00:14:18,280 --> 00:14:20,480
If we're not getting more
from these applications,

336
00:14:20,480 --> 00:14:23,660
why is this landscape
continuing to spread?

337
00:14:23,660 --> 00:14:25,353
Think about it and be smart.

338
00:14:28,240 --> 00:14:30,890
It is now my honor to hand the mic over

339
00:14:30,890 --> 00:14:33,253
to the brilliant Johannes Ullrich.

340
00:14:36,850 --> 00:14:40,340
- Thank you very much for
this introduction, Heather.

341
00:14:40,340 --> 00:14:44,330
Now, one theme that I'm sort
of seeing with Ed and Heather

342
00:14:44,330 --> 00:14:47,330
is that you have these more
and more complex systems

343
00:14:47,330 --> 00:14:48,520
that we need to trust,

344
00:14:48,520 --> 00:14:51,130
and these systems are built by developers.

345
00:14:51,130 --> 00:14:53,439
These developers also need to understand

346
00:14:53,440 --> 00:14:56,370
the security implications
of these systems.

347
00:14:56,370 --> 00:14:58,360
And of course, they need to understand

348
00:14:58,360 --> 00:15:02,050
all the complexities that
these systems involve.

349
00:15:02,050 --> 00:15:04,469
What I'm going to talk about
is a little bit different,

350
00:15:04,470 --> 00:15:09,470
but it still involves complex
systems that we need to trust.

351
00:15:09,630 --> 00:15:14,630
So, historically, when we
speak about malware detection,

352
00:15:15,050 --> 00:15:17,010
we usually talked about signatures,

353
00:15:17,010 --> 00:15:20,750
and of course we all know
signatures don't work.

354
00:15:20,750 --> 00:15:24,140
In this example, we do have two samples.

355
00:15:24,140 --> 00:15:27,150
We all know dogs are good and cats,

356
00:15:27,150 --> 00:15:29,240
well, usually not up to much good.

357
00:15:29,240 --> 00:15:31,100
So, now we try to develop a signature

358
00:15:31,100 --> 00:15:33,260
to figure out what's a dog, what's a cat.

359
00:15:33,260 --> 00:15:36,240
And based on this limited sample,

360
00:15:36,240 --> 00:15:39,470
we now know that with
one ear up, it's a dog,

361
00:15:39,470 --> 00:15:41,870
with two ears up, it's a cat.

362
00:15:41,870 --> 00:15:45,060
But along comes a new sample.

363
00:15:45,060 --> 00:15:46,930
And all of a sudden, of course,

364
00:15:46,930 --> 00:15:49,540
now we end up with false
positives, false negatives.

365
00:15:49,540 --> 00:15:54,140
Now we have a real good
dog, but it has two ears up,

366
00:15:54,140 --> 00:15:57,949
so our signature wouldn't work here.

367
00:15:57,950 --> 00:16:02,540
What this led to is that we
had these huge malware zoos

368
00:16:02,540 --> 00:16:05,410
that we used to create signatures

369
00:16:05,410 --> 00:16:07,620
and we had to constantly update them.

370
00:16:07,620 --> 00:16:09,310
So, in order to find better

371
00:16:09,310 --> 00:16:13,199
and more automated ways
of maintaining this,

372
00:16:13,200 --> 00:16:16,850
well, in the last few years,
we had machine learning

373
00:16:16,850 --> 00:16:21,370
being applied to this problem
or artificial intelligence.

374
00:16:21,370 --> 00:16:24,050
So, now we've fed this large malware zoo

375
00:16:24,050 --> 00:16:27,150
into these algorithms
and developed models,

376
00:16:27,150 --> 00:16:29,560
developed classifiers to figure out

377
00:16:29,560 --> 00:16:31,949
what's good and what's bad.

378
00:16:31,950 --> 00:16:34,210
Now, when it comes to machine learning,

379
00:16:34,210 --> 00:16:37,010
there are a number of known threats

380
00:16:37,010 --> 00:16:39,439
that adversaries may use against us.

381
00:16:39,440 --> 00:16:41,320
If this machine learning

382
00:16:41,320 --> 00:16:45,012
is used to protect us
from these adversaries,

383
00:16:45,012 --> 00:16:48,530
then of course we have to
be particularly careful.

384
00:16:48,530 --> 00:16:53,329
And my talk will be
about how is an attacker

385
00:16:53,330 --> 00:16:55,260
possibly able to use the fact

386
00:16:55,260 --> 00:16:58,300
that they're using machine
learning against us.

387
00:16:58,300 --> 00:17:00,280
Now, one of the most basic threats

388
00:17:00,280 --> 00:17:02,227
when it comes to machine learning is,

389
00:17:02,227 --> 00:17:06,416
"Hey, what if the attacker
actually is able to influence

390
00:17:06,416 --> 00:17:10,349
"the samples that we are
using to train our models?"

391
00:17:10,349 --> 00:17:12,790
So, the attacker has access

392
00:17:12,790 --> 00:17:17,790
and is able to manipulate our
samples, our training data.

393
00:17:18,800 --> 00:17:20,790
And I have bad news for you,

394
00:17:20,790 --> 00:17:24,379
because what are we using to
train a malware classifier?

395
00:17:24,380 --> 00:17:29,380
Well, malware by definition
comes from the attacker.

396
00:17:29,410 --> 00:17:33,110
Let's consider a little bit
more sophisticated attacker.

397
00:17:33,110 --> 00:17:36,587
This attacker could now
have two tracks of malware

398
00:17:36,587 --> 00:17:38,480
that they are developing.

399
00:17:38,480 --> 00:17:41,350
The first track, well, office macros.

400
00:17:41,350 --> 00:17:43,500
Office documents, macros,

401
00:17:43,500 --> 00:17:45,940
they're sending you a
couple of hundred of them

402
00:17:45,940 --> 00:17:49,930
to random email addresses
in your organization.

403
00:17:49,930 --> 00:17:52,110
They may carry some crypto coin miners,

404
00:17:52,110 --> 00:17:56,043
some ransomware, and other
random kind of malware.

405
00:17:56,974 --> 00:18:00,200
You're, of course, using that
to train your classifiers

406
00:18:00,200 --> 00:18:02,920
because, well, after all
these are real threats.

407
00:18:02,920 --> 00:18:05,980
Occasionally a user is clicking on them

408
00:18:05,980 --> 00:18:07,580
and you're in trouble.

409
00:18:07,580 --> 00:18:11,860
So, now your classifier
is becoming really good

410
00:18:11,860 --> 00:18:15,669
at detecting malicious office macros.

411
00:18:15,670 --> 00:18:17,820
But the second track

412
00:18:17,820 --> 00:18:20,870
that the attacker is
developing malware for

413
00:18:20,870 --> 00:18:23,179
may be attacking parameter devices,

414
00:18:23,180 --> 00:18:25,120
emails being sent to administrators

415
00:18:25,120 --> 00:18:27,370
that tricks them into clicking on links

416
00:18:27,370 --> 00:18:28,840
in order to, for example,

417
00:18:28,840 --> 00:18:32,673
exploit some obscure cross-site
scripting vulnerability.

418
00:18:33,920 --> 00:18:35,560
Well...

419
00:18:35,560 --> 00:18:40,129
Your classifier has now
become really focused

420
00:18:40,130 --> 00:18:44,350
on these office macros and
is missing these new samples.

421
00:18:44,350 --> 00:18:49,350
The attacker was successful
in training your model

422
00:18:49,370 --> 00:18:52,290
to classify malware that's still malware

423
00:18:52,290 --> 00:18:54,889
but doesn't really matter.

424
00:18:54,890 --> 00:18:57,050
Now, another attack, of course,

425
00:18:57,050 --> 00:19:00,330
is the attacker using
machine learning themself.

426
00:19:00,330 --> 00:19:01,790
Why not?

427
00:19:01,790 --> 00:19:04,230
And the attacker could now use samples

428
00:19:04,230 --> 00:19:05,640
that the attacker develops,

429
00:19:05,640 --> 00:19:09,300
run 'em through your
algorithm, through your model,

430
00:19:09,300 --> 00:19:13,020
and figure out, well, which artifacts,

431
00:19:13,020 --> 00:19:15,600
which characteristics are
detected as malicious,

432
00:19:15,600 --> 00:19:17,959
which are not detected as malicious,

433
00:19:17,960 --> 00:19:19,570
and then develop malware

434
00:19:19,570 --> 00:19:23,379
that evades the particular characteristics

435
00:19:23,380 --> 00:19:25,990
that are being used to detect

436
00:19:25,990 --> 00:19:28,310
a particular sample as malicious.

437
00:19:28,310 --> 00:19:30,790
So, essentially here, it's
being used against you

438
00:19:30,790 --> 00:19:33,740
and the attack has one big advantage.

439
00:19:33,740 --> 00:19:35,777
We are all using these malware zoos,

440
00:19:35,777 --> 00:19:39,230
and this has been long,
outstanding issues.

441
00:19:39,230 --> 00:19:44,080
I think Ed and Tom Liston,
actually, back 10, 15 years ago

442
00:19:44,080 --> 00:19:46,149
wrote a nice paper about that.

443
00:19:46,150 --> 00:19:49,280
And the attacker has the big advantage

444
00:19:49,280 --> 00:19:51,360
that they have the current malware.

445
00:19:51,360 --> 00:19:53,199
You have the old malware.

446
00:19:53,200 --> 00:19:56,860
So, here again, the attacker
is somewhat at an advantage.

447
00:19:56,860 --> 00:20:00,510
And lastly, well, brute force.

448
00:20:00,510 --> 00:20:04,990
An attacker may just be able
to throw some data at you

449
00:20:04,990 --> 00:20:06,750
and see what works.

450
00:20:06,750 --> 00:20:09,160
And we have seen this against signatures.

451
00:20:09,160 --> 00:20:11,070
There have been some successes now

452
00:20:11,070 --> 00:20:13,679
using this against some of
these machine learning models

453
00:20:13,680 --> 00:20:16,200
where we take something that's well-known,

454
00:20:16,200 --> 00:20:18,000
benign, like Notepad,

455
00:20:18,000 --> 00:20:21,690
and just attach some little
bit of malicious code

456
00:20:21,690 --> 00:20:24,883
that now of course is not detected.

457
00:20:25,980 --> 00:20:28,820
So, in summary, what
you've learned from this,

458
00:20:28,820 --> 00:20:30,520
your training data matters

459
00:20:30,520 --> 00:20:33,710
and you need to understand these models.

460
00:20:33,710 --> 00:20:36,070
If you don't understand what protects you,

461
00:20:36,070 --> 00:20:37,980
then you can't really evaluate

462
00:20:37,980 --> 00:20:42,030
the efficacy of these
techniques and these tools.

463
00:20:42,030 --> 00:20:44,670
So, figure out what they're doing

464
00:20:44,670 --> 00:20:47,210
and figure out how to tune them.

465
00:20:47,210 --> 00:20:50,000
And with that, let me hand it over

466
00:20:50,000 --> 00:20:55,000
to the newest member
here of our panel, Katie.

467
00:20:56,160 --> 00:21:00,343
So, Katie, please take it
away, and be nice to Katie.

468
00:21:03,010 --> 00:21:04,980
- Wonderful; thank you so much, Johannes,

469
00:21:04,980 --> 00:21:06,290
for your kind introduction

470
00:21:06,290 --> 00:21:08,940
and thanks for having me on the panel.

471
00:21:08,940 --> 00:21:10,950
Let's dive right in.

472
00:21:10,950 --> 00:21:13,494
Let's talk ransomware.

473
00:21:13,494 --> 00:21:14,327
Now, you might be thinking,

474
00:21:14,327 --> 00:21:17,317
"Katie this is new attack
techniques and trends.

475
00:21:17,317 --> 00:21:19,600
"Why are we talking about ransomware?"

476
00:21:19,600 --> 00:21:22,830
Well, there's been a change
that we need to anticipate,

477
00:21:22,830 --> 00:21:25,620
but first let's think about historically

478
00:21:25,620 --> 00:21:27,833
how we've discussed ransomware.

479
00:21:27,834 --> 00:21:31,640
We've thought about it as an
availability problem, right?

480
00:21:31,640 --> 00:21:32,880
Your data's encrypted

481
00:21:32,880 --> 00:21:35,850
and so you wanna make sure
you can get it decrypted.

482
00:21:35,850 --> 00:21:37,283
It's an availability thing.

483
00:21:38,240 --> 00:21:41,190
But we can't just think
about that anymore.

484
00:21:41,190 --> 00:21:44,103
We have to think about
it in a broader way.

485
00:21:44,103 --> 00:21:47,060
In late-2019, a somewhat infamous group

486
00:21:47,060 --> 00:21:49,610
you might be familiar with called Maze

487
00:21:49,610 --> 00:21:53,550
started the trend of
exfiltrating data from victims

488
00:21:53,550 --> 00:21:56,570
and then using that to extort them.

489
00:21:56,570 --> 00:22:00,860
Like any bad idea that
adversaries have, this caught on.

490
00:22:00,860 --> 00:22:05,490
And since late-2019, all
of these different groups,

491
00:22:05,490 --> 00:22:09,500
Clop, Egregor, Conti, Dopplepaymer,

492
00:22:09,500 --> 00:22:11,167
so many different groups have realized,

493
00:22:11,167 --> 00:22:14,970
"Hey, this extortion thing works."

494
00:22:14,970 --> 00:22:18,430
In fact, in the fourth quarter of 2020,

495
00:22:18,430 --> 00:22:22,750
Coveware found that over
70% of ransomware cases

496
00:22:22,750 --> 00:22:26,400
involved some kind of exfil and extortion.

497
00:22:26,400 --> 00:22:29,070
And this is one of the most
dangerous new attack techniques

498
00:22:29,070 --> 00:22:31,592
because this is the new normal,

499
00:22:32,800 --> 00:22:35,270
thinking about not just the availability

500
00:22:35,270 --> 00:22:38,520
but also the confidentiality of your data

501
00:22:38,520 --> 00:22:42,150
and realizing that
adversaries are very likely

502
00:22:42,150 --> 00:22:45,083
to exfiltrate and then extort your data.

503
00:22:46,210 --> 00:22:48,920
Let's take a look at an
average ransomware attack chain

504
00:22:48,920 --> 00:22:51,973
and how this exfiltration
thing changes that.

505
00:22:52,840 --> 00:22:55,500
The good news about this
typical ransomware attack chain

506
00:22:55,500 --> 00:22:59,210
is that defenders have lots
of detection opportunities

507
00:22:59,210 --> 00:23:02,660
along the way, whether
it's that initial access,

508
00:23:02,660 --> 00:23:06,020
whether it's reconnaissance
or lateral movement.

509
00:23:06,020 --> 00:23:09,370
But the new stage that we
need to focus on going forward

510
00:23:09,370 --> 00:23:11,293
is this exfiltration phase.

511
00:23:12,140 --> 00:23:14,020
This can be really tough to catch

512
00:23:14,020 --> 00:23:18,980
because adversaries will use
tools like RClone and Mega

513
00:23:18,980 --> 00:23:21,540
that are legitimate file-sharing tools.

514
00:23:21,540 --> 00:23:24,780
They'll just use them for
their malicious purposes.

515
00:23:24,780 --> 00:23:27,560
The good news is there's
always a detection opportunity,

516
00:23:27,560 --> 00:23:31,340
and so I have a little mask
icon on the slide for you

517
00:23:31,340 --> 00:23:36,000
to think about the
technique of masquerading.

518
00:23:36,000 --> 00:23:37,600
Adversaries don't want you to know

519
00:23:37,600 --> 00:23:39,620
if they're using a tool like RClone,

520
00:23:39,620 --> 00:23:42,523
and so a natural thing
they do is they rename it.

521
00:23:43,550 --> 00:23:46,210
Well, in them trying to hide from you,

522
00:23:46,210 --> 00:23:48,150
actually gives us a detection opportunity.

523
00:23:48,150 --> 00:23:51,340
So, a simple way that you
can detect this exfiltration,

524
00:23:51,340 --> 00:23:54,822
just looking for renamed
file-sharing tools like RClone.

525
00:23:55,750 --> 00:23:57,150
The key thing to focus on, though,

526
00:23:57,150 --> 00:23:59,560
is that exfiltration usually happens

527
00:23:59,560 --> 00:24:02,090
before the last phase of encryption.

528
00:24:02,090 --> 00:24:05,000
And once you get to encryption,
it's often too late.

529
00:24:05,000 --> 00:24:07,360
That exfil has already happened.

530
00:24:07,360 --> 00:24:10,229
And so, we as defenders
have to be thinking about

531
00:24:10,230 --> 00:24:13,413
how this exfil and
extortion is the new normal.

532
00:24:14,950 --> 00:24:17,850
This trend also makes it more challenging

533
00:24:17,850 --> 00:24:20,580
for us to figure out
how should we respond.

534
00:24:20,580 --> 00:24:22,980
Because, of course, we
can never trust criminals,

535
00:24:22,980 --> 00:24:26,257
but I think there used to be
an old way of thinking that,

536
00:24:26,257 --> 00:24:29,037
"Hey, if I just pay an adversary,

537
00:24:29,037 --> 00:24:32,557
"I get the decryption
key and my data is back.

538
00:24:32,557 --> 00:24:33,750
"Great!"

539
00:24:33,750 --> 00:24:37,410
Well, except now, if the
adversary has your data,

540
00:24:37,410 --> 00:24:39,750
you don't know if they've
really destroyed it.

541
00:24:39,750 --> 00:24:41,260
We've seen multiple cases where,

542
00:24:41,260 --> 00:24:45,920
for example, Sodinokibi
operators re-extorted victims.

543
00:24:45,920 --> 00:24:48,730
They said, "Pay us and we
won't release your data."

544
00:24:48,730 --> 00:24:51,790
Okay, we paid you, and then
months later they came back

545
00:24:51,790 --> 00:24:53,129
and asked for more money.

546
00:24:53,130 --> 00:24:58,060
Netwalker, Conti, other groups
have done the same thing.

547
00:24:58,060 --> 00:25:00,669
And so, it's so important
that people realize

548
00:25:00,670 --> 00:25:02,880
this is a trend amongst adversaries

549
00:25:02,880 --> 00:25:05,440
because you can gain
the decision advantage

550
00:25:05,440 --> 00:25:08,260
by knowing to expect the unexpected

551
00:25:08,260 --> 00:25:10,913
and, of course, that there's
no honor among thieves.

552
00:25:13,120 --> 00:25:14,199
That's the bad news.

553
00:25:14,200 --> 00:25:15,230
This is happening.

554
00:25:15,230 --> 00:25:17,630
It's happening a lotta the
time in these ransomware cases.

555
00:25:17,630 --> 00:25:20,800
But the good news is
you can change things up

556
00:25:20,800 --> 00:25:24,610
in how you prevent, detect,
and respond to ransomware.

557
00:25:24,610 --> 00:25:27,110
The first one, prevention.

558
00:25:27,110 --> 00:25:29,006
I still sometimes see guidance that,

559
00:25:29,007 --> 00:25:31,447
"Hey, just go ahead
and use offline backups

560
00:25:31,447 --> 00:25:35,689
"and you'll be all set,
protected against ransomware."

561
00:25:35,690 --> 00:25:37,770
Of course, you should
still have offline backups,

562
00:25:37,770 --> 00:25:40,280
but that's not sufficient.

563
00:25:40,280 --> 00:25:42,540
You also should be taking
preventative measures

564
00:25:42,540 --> 00:25:45,820
like disallowing any file-sharing tools

565
00:25:45,820 --> 00:25:47,970
that aren't needed in your network.

566
00:25:47,970 --> 00:25:50,850
It's a great, simple way
you can try to prevent

567
00:25:50,850 --> 00:25:52,562
some of this exfil from happening.

568
00:25:53,580 --> 00:25:57,947
On the detection side, me and
my team sometimes joke that,

569
00:25:57,947 --> 00:26:00,847
"Well, the easiest thing
to detect out of any threat

570
00:26:00,847 --> 00:26:03,837
"is ransomware because
when you see a ransom note,

571
00:26:03,837 --> 00:26:06,340
"you know you have ransomware."

572
00:26:06,340 --> 00:26:09,300
You can't just rely on
that file encryption

573
00:26:09,300 --> 00:26:11,960
and that ransom note to alert
you something is going on

574
00:26:11,960 --> 00:26:13,970
because, as we talked about,

575
00:26:13,970 --> 00:26:17,060
that exfil happens before the encryption.

576
00:26:17,060 --> 00:26:18,460
So, now you have to assume

577
00:26:18,460 --> 00:26:21,260
there's a possibility of exfiltration

578
00:26:21,260 --> 00:26:24,430
and look for that in your environments.

579
00:26:24,430 --> 00:26:27,330
And last but not least, in response.

580
00:26:27,330 --> 00:26:28,970
Again, we can never trust criminals,

581
00:26:28,970 --> 00:26:32,200
but we have to move forward
from this way of thinking

582
00:26:32,200 --> 00:26:34,860
and assuming that we'll get our data back.

583
00:26:34,860 --> 00:26:37,030
You have to realize these are adversaries.

584
00:26:37,030 --> 00:26:38,990
These are criminals we're talking about.

585
00:26:38,990 --> 00:26:42,650
Don't trust them, because
they don't always do

586
00:26:42,650 --> 00:26:44,823
what they say they will do, of course.

587
00:26:45,700 --> 00:26:49,300
With that, that's all I have,
but you all need to know

588
00:26:49,300 --> 00:26:51,520
you need to update your defenses, right?

589
00:26:51,520 --> 00:26:54,070
Ransomware, it's not
just encryption anymore.

590
00:26:54,070 --> 00:26:56,703
It's also exfiltration and extortion.

591
00:26:57,700 --> 00:26:59,950
And with that, let's bring
the team back together.

592
00:26:59,950 --> 00:27:01,820
I'd like to welcome my fellow panelists

593
00:27:01,820 --> 00:27:04,620
and turn it back over to Alan
for questions and answers.

594
00:27:07,460 --> 00:27:08,293
- Thanks, Katie.

595
00:27:08,293 --> 00:27:10,290
We're gonna start with you
with the first question.

596
00:27:10,290 --> 00:27:15,290
But before I ask it, I just
wanna tell you guys thank you.

597
00:27:15,520 --> 00:27:19,253
The joy of listening to
you teaching this way,

598
00:27:20,220 --> 00:27:21,850
you're amazing teachers.

599
00:27:21,850 --> 00:27:23,370
And I know from your students

600
00:27:23,370 --> 00:27:25,909
we get these phenomenal thank yous,

601
00:27:25,910 --> 00:27:27,970
and I think it's because you actually care

602
00:27:27,970 --> 00:27:29,210
about the audience learning,

603
00:27:29,210 --> 00:27:31,860
rather than just being the
expert, so it sets you apart.

604
00:27:31,860 --> 00:27:33,590
So, thank you for doing that.

605
00:27:33,590 --> 00:27:34,949
Katie, you're first.

606
00:27:34,950 --> 00:27:38,410
Isn't it easier to detect extortionware

607
00:27:38,410 --> 00:27:41,340
because it has to exfiltrate the data,

608
00:27:41,340 --> 00:27:45,270
causing more network
traffic versus ransomware?

609
00:27:45,270 --> 00:27:47,040
- Yeah, and how's this for an answer:

610
00:27:47,040 --> 00:27:49,570
yes and no at the same time.

611
00:27:49,570 --> 00:27:52,310
I would say yes because
like we talked about,

612
00:27:52,310 --> 00:27:55,530
it's an additional stage

613
00:27:55,530 --> 00:27:57,590
where you can look for
data leaving the network,

614
00:27:57,590 --> 00:28:01,810
but no, in part because
a lot of this exfil

615
00:28:01,810 --> 00:28:04,669
is designed to look like real traffic,

616
00:28:04,670 --> 00:28:07,920
like legitimate file-sharing
services being used.

617
00:28:07,920 --> 00:28:09,570
And the other reason I would say no

618
00:28:09,570 --> 00:28:11,501
is because like I mentioned,

619
00:28:11,501 --> 00:28:14,899
ransomware itself is one of
the easiest things to detect.

620
00:28:14,900 --> 00:28:16,700
You have encrypted files.

621
00:28:16,700 --> 00:28:20,650
And with exfiltration, that's
often stealthy by design.

622
00:28:20,650 --> 00:28:24,120
And so, yeah, you have more
detection opportunities,

623
00:28:24,120 --> 00:28:25,306
but it's a little stealthy,

624
00:28:25,307 --> 00:28:28,240
and so it can be can be tough to catch.

625
00:28:28,240 --> 00:28:29,130
- Great.

626
00:28:29,130 --> 00:28:31,530
By the way, these questions,
for you in the audience,

627
00:28:31,530 --> 00:28:35,080
we've been testing these new developments

628
00:28:35,080 --> 00:28:36,260
over the last three or four weeks

629
00:28:36,260 --> 00:28:38,350
and we've asked each
group we've tested them on

630
00:28:38,350 --> 00:28:39,409
to give us questions,

631
00:28:39,410 --> 00:28:41,500
and these are the best
of the ones they gave us.

632
00:28:41,500 --> 00:28:43,400
Let me switch to Heather.

633
00:28:43,400 --> 00:28:45,750
Do you leverage single sign-on yourself

634
00:28:45,750 --> 00:28:47,260
for apps for accessing data?

635
00:28:47,260 --> 00:28:49,440
How do you keep your information safe?

636
00:28:49,440 --> 00:28:51,570
Since you're the big expert.

637
00:28:51,570 --> 00:28:52,669
- I actually do.

638
00:28:52,670 --> 00:28:57,670
And two words on keeping it safe: log out.

639
00:28:57,710 --> 00:28:59,440
Seriously, you have to log out.

640
00:28:59,440 --> 00:29:02,190
I make sure also that I
don't leave any tokens

641
00:29:02,190 --> 00:29:05,540
that would remain open as
a screenshot on my device

642
00:29:05,540 --> 00:29:07,520
because that can definitely be accessible

643
00:29:07,520 --> 00:29:09,610
if it falls into the wrong hands.

644
00:29:09,610 --> 00:29:10,543
Always log out.

645
00:29:11,490 --> 00:29:12,800
- Yeah, I actually find it easier

646
00:29:12,800 --> 00:29:14,190
to log out on my mobile device.

647
00:29:14,190 --> 00:29:16,693
I just remember that versus my computer.

648
00:29:17,530 --> 00:29:19,260
I'll log into some e-commerce site

649
00:29:19,260 --> 00:29:20,920
and I just close the browser window

650
00:29:20,920 --> 00:29:22,530
or leave it in the background
and I forget about it.

651
00:29:22,530 --> 00:29:24,340
So, I think mobile, I don't
know, at least for me,

652
00:29:24,340 --> 00:29:27,649
psychologically, I'm much
more likely to log out.

653
00:29:27,650 --> 00:29:29,550
- Yeah, and for developers, don't forget,

654
00:29:29,550 --> 00:29:31,409
if you implement
two-factor authentication,

655
00:29:31,410 --> 00:29:33,983
make sure each token only works once.

656
00:29:35,280 --> 00:29:37,270
They have to work for a certain timeframe

657
00:29:37,270 --> 00:29:40,620
that's longer than the
token it's displayed for,

658
00:29:40,620 --> 00:29:42,350
but some bad implementation

659
00:29:42,350 --> 00:29:44,209
allowed to use the same token twice.

660
00:29:44,210 --> 00:29:46,960
And then, if your timeframe
is like five minutes,

661
00:29:46,960 --> 00:29:48,580
then there's a real threat here

662
00:29:48,580 --> 00:29:50,970
where someone could copy the token.

663
00:29:50,970 --> 00:29:53,190
- Yeah, and one thought I have on this is,

664
00:29:53,190 --> 00:29:55,980
well, we're not saying don't
use SSO, right, Heather?

665
00:29:55,980 --> 00:29:56,813
Heather still uses it.
- Correct.

666
00:29:56,813 --> 00:29:58,070
- I use SSO.

667
00:29:58,070 --> 00:30:00,439
I think it's just pointing
out that it's not perfect

668
00:30:00,440 --> 00:30:01,850
and how do you use it better?

669
00:30:01,850 --> 00:30:04,350
But I think we'd all agree,
SSO is a heck of a lot better

670
00:30:04,350 --> 00:30:06,240
than a lot of other worse options,

671
00:30:06,240 --> 00:30:08,340
so one thing to add there.

672
00:30:08,340 --> 00:30:09,790
- Johannes, while we got you,

673
00:30:11,120 --> 00:30:12,939
everybody thinks machine
learning is wonderful.

674
00:30:12,940 --> 00:30:14,990
You're pointing out that it's wonderful

675
00:30:14,990 --> 00:30:16,270
but it may have flaws.

676
00:30:16,270 --> 00:30:18,040
Are there open-source tools,

677
00:30:18,040 --> 00:30:20,480
free open-source tools that people can use

678
00:30:20,480 --> 00:30:22,370
that implement machine learning techniques

679
00:30:22,370 --> 00:30:25,479
for detecting or blocking malware?

680
00:30:25,480 --> 00:30:27,090
- Yeah, and actually the
great thing about this

681
00:30:27,090 --> 00:30:28,949
is that most machine learning

682
00:30:28,950 --> 00:30:32,080
is done using open-source tools.

683
00:30:32,080 --> 00:30:35,830
Python is of the lingua
franca of machine learning.

684
00:30:35,830 --> 00:30:38,649
You have all these
libraries like TensorFlow

685
00:30:38,650 --> 00:30:42,410
and NumPy and such that are open-source.

686
00:30:42,410 --> 00:30:44,840
Lots of sort of Jupiter
Notebooks out there

687
00:30:44,840 --> 00:30:46,179
that you can use.

688
00:30:46,180 --> 00:30:49,075
So, it's really a whole library,

689
00:30:49,075 --> 00:30:52,940
an entire universe of open-source tools

690
00:30:52,940 --> 00:30:56,300
and learning tools too that
allow you to become familiar

691
00:30:56,300 --> 00:30:57,330
with some of these techniques

692
00:30:57,330 --> 00:31:01,590
and maybe take it a little bit
sort of the black box magic

693
00:31:04,730 --> 00:31:08,560
out of machine learning and
make it more real for you.

694
00:31:08,560 --> 00:31:11,510
- Thank you; Ed, the
problems you're talking about

695
00:31:11,510 --> 00:31:16,510
seem to affect Python or NPM
ecosystem more than others.

696
00:31:17,030 --> 00:31:18,740
Is it safer to use a different language?

697
00:31:18,740 --> 00:31:20,250
Should I just skip Python?

698
00:31:20,250 --> 00:31:22,170
- So, no, Python's wonderful.

699
00:31:22,170 --> 00:31:27,170
But it's actually not just
Python and node.js, that's NPM.

700
00:31:27,320 --> 00:31:31,149
It's also Ruby with its gems
distribution and so forth.

701
00:31:31,150 --> 00:31:34,420
And the issue with these is
that they're so easy to use

702
00:31:34,420 --> 00:31:38,240
and so dynamic in
reaching out for packages

703
00:31:38,240 --> 00:31:41,640
that attackers might be able
to insert malicious packages.

704
00:31:41,640 --> 00:31:43,470
I don't think you're
gonna make your choice

705
00:31:43,470 --> 00:31:45,510
on software development environments

706
00:31:45,510 --> 00:31:48,720
based on this kind of attack, honestly.

707
00:31:48,720 --> 00:31:52,910
That said, you can configure
your package management

708
00:31:52,910 --> 00:31:56,670
for internal private packages
so that it's less likely

709
00:31:56,670 --> 00:31:58,520
to be subject to this kind of attack.

710
00:31:58,520 --> 00:32:01,300
Microsoft actually
published a tremendous paper

711
00:32:01,300 --> 00:32:03,956
called "Three Ways to Mitigate

712
00:32:03,957 --> 00:32:08,410
"Against the Risks of
Package Management Tools."

713
00:32:08,410 --> 00:32:12,040
It's a really tremendous paper
that gives specific advice.

714
00:32:12,040 --> 00:32:13,180
The bottom line here

715
00:32:13,180 --> 00:32:16,780
is if you have a private
development environment inside

716
00:32:16,780 --> 00:32:20,629
and it's dependent on private
packages that you've created,

717
00:32:20,630 --> 00:32:22,930
you wanna configure your
package management tool

718
00:32:22,930 --> 00:32:26,420
so that it will not search
for those private packages

719
00:32:26,420 --> 00:32:28,200
in public environments.

720
00:32:28,200 --> 00:32:29,770
- Cool; Katie.

721
00:32:29,770 --> 00:32:33,200
This one, everybody jump in
if you think Katie's wrong.

722
00:32:33,200 --> 00:32:34,570
No, that's not what I said.

723
00:32:34,570 --> 00:32:38,040
Are there any trends you're
hearing the community discuss

724
00:32:38,040 --> 00:32:39,760
that you don't think are as dangerous

725
00:32:39,760 --> 00:32:41,467
as they may first appear?

726
00:32:42,370 --> 00:32:44,689
- Yeah, one that I'm
actually gonna disagree

727
00:32:44,690 --> 00:32:46,440
with part of what Johannes said.

728
00:32:46,440 --> 00:32:49,580
So, I think there is a risk of adversaries

729
00:32:49,580 --> 00:32:52,990
trying to defeat defenders'
machine learning.

730
00:32:52,990 --> 00:32:55,170
But what I haven't quite
seen an example of,

731
00:32:55,170 --> 00:32:58,550
and Johannes, I'd love if you
contradict me on this one,

732
00:32:58,550 --> 00:33:01,960
is adversaries themselves using AI

733
00:33:01,960 --> 00:33:03,870
or machine learning in their attacks.

734
00:33:03,870 --> 00:33:05,409
I think it's possible.

735
00:33:05,410 --> 00:33:08,780
But as a threat intel person,
my challenge is always

736
00:33:08,780 --> 00:33:10,840
how do I balance what's
possible and likely?

737
00:33:10,840 --> 00:33:13,919
And so, Johannes, I'm curious
actually if you have had

738
00:33:13,920 --> 00:33:16,030
any experience where you've seen

739
00:33:16,030 --> 00:33:20,080
a likely AI- or ML-fueled
adversary attack.

740
00:33:20,080 --> 00:33:22,720
- I haven't, and I'm not really sure

741
00:33:22,720 --> 00:33:24,960
how you would be able to tell

742
00:33:24,960 --> 00:33:27,450
because the machine learning
happens on the attacker's side;

743
00:33:27,450 --> 00:33:29,800
doesn't happen on your side.

744
00:33:29,800 --> 00:33:34,330
So, the attacker would present
a more sophisticated attack,

745
00:33:34,330 --> 00:33:35,850
a more targeted attack.

746
00:33:35,850 --> 00:33:37,260
Whether it was machine learning

747
00:33:37,260 --> 00:33:41,690
or just an intelligent attacker
that was smart by themselves

748
00:33:41,690 --> 00:33:44,103
without actually using machine learning,

749
00:33:45,720 --> 00:33:47,380
I think that would be hard to tell.

750
00:33:47,380 --> 00:33:48,750
- Yeah, I agree.

751
00:33:48,750 --> 00:33:50,410
Now, I do think that machine learning

752
00:33:50,410 --> 00:33:53,170
can be used by adversaries
in a lotta different ways.

753
00:33:53,170 --> 00:33:55,210
One of them is password cracking, right?

754
00:33:55,210 --> 00:33:57,730
Rather than having a word list

755
00:33:57,730 --> 00:33:59,390
and then having various filter rules

756
00:33:59,390 --> 00:34:01,580
on the word list for doing word mangling,

757
00:34:01,580 --> 00:34:03,929
what you could do, and I
have seen some projects,

758
00:34:03,930 --> 00:34:05,500
open-source projects that do this,

759
00:34:05,500 --> 00:34:08,830
is you'll take a word
list of actual passwords

760
00:34:08,830 --> 00:34:10,799
that maybe were breached
or something like that,

761
00:34:10,800 --> 00:34:14,260
train up a neural network
with machine learning

762
00:34:14,260 --> 00:34:17,719
so that it understands how
humans formulate their passwords,

763
00:34:17,719 --> 00:34:20,319
and then have that neural network

764
00:34:20,320 --> 00:34:21,820
that learned through machine learning

765
00:34:21,820 --> 00:34:24,420
start generating additional
guesses for you to use

766
00:34:24,420 --> 00:34:27,460
in your guess/encrypt/compare
cycle of password cracking.

767
00:34:27,460 --> 00:34:31,909
And the irony of this is the
machine-trained neural network

768
00:34:31,909 --> 00:34:34,670
might be able to predict what
humans will use as passwords

769
00:34:34,670 --> 00:34:36,590
better than humans will, right?

770
00:34:36,590 --> 00:34:38,210
It's kind of interesting,
'cause it's learned

771
00:34:38,210 --> 00:34:40,389
from millions-
- Ed, stop now.

772
00:34:40,389 --> 00:34:41,350
You can stop now.

773
00:34:41,350 --> 00:34:45,670
That's why Ed and his two cohorts

774
00:34:45,670 --> 00:34:48,600
are known as the top offensive
trainers in the world.

775
00:34:48,600 --> 00:34:49,886
I think you should stop now.

776
00:34:49,886 --> 00:34:54,886
- Okay.
(all laughing)

777
00:34:55,110 --> 00:34:58,580
- Heather, any crypto
can be broken eventually.

778
00:34:58,580 --> 00:35:00,840
How do I decide what's good enough?

779
00:35:00,840 --> 00:35:01,860
- Ooh!

780
00:35:01,860 --> 00:35:04,760
Is anything ever good enough, honestly?

781
00:35:04,760 --> 00:35:07,340
I would say obviously
you have to validate.

782
00:35:07,340 --> 00:35:10,650
Hire good pen testers to
try to break any application

783
00:35:10,650 --> 00:35:12,060
that you're relying upon,

784
00:35:12,060 --> 00:35:17,060
but also be willing and
malleable, and you need to adjust.

785
00:35:17,880 --> 00:35:20,347
And I've worked in many
organizations where they're like,

786
00:35:20,347 --> 00:35:22,707
"It has been this way
since the beginning of time

787
00:35:22,707 --> 00:35:24,520
"and we are not willing to change it."

788
00:35:24,520 --> 00:35:26,030
That is a threat right there.

789
00:35:26,030 --> 00:35:28,560
So, you have to understand
the vulnerabilities,

790
00:35:28,560 --> 00:35:32,600
listen to whoever you hire
to actually attack it,

791
00:35:32,600 --> 00:35:36,218
hear what they have to
say, mitigate, and adjust.

792
00:35:36,218 --> 00:35:37,250
- Cool.

793
00:35:37,250 --> 00:35:40,650
Ed, back to you, since I was so rude.

794
00:35:40,650 --> 00:35:42,500
Are there any tools that can help create

795
00:35:42,500 --> 00:35:43,800
a software bill of materials?

796
00:35:43,800 --> 00:35:44,960
'Cause you talked about the need for this.

797
00:35:44,960 --> 00:35:46,300
- Sure, sure.

798
00:35:46,300 --> 00:35:49,670
So, essentially, it's a
software composition analysis,

799
00:35:49,670 --> 00:35:51,270
and there's a bunch of
commercial tools that do it.

800
00:35:51,270 --> 00:35:52,850
There's also some free tools.

801
00:35:52,850 --> 00:35:55,690
OWASP, the Open Web
Application Security Project,

802
00:35:55,690 --> 00:35:58,130
has one called Dependency Check.

803
00:35:58,130 --> 00:36:00,640
There's one from a company
called White Source.

804
00:36:00,640 --> 00:36:01,779
It's a free tool.

805
00:36:01,780 --> 00:36:03,220
The tool's called Bolt.

806
00:36:03,220 --> 00:36:04,209
And essentially what it does

807
00:36:04,210 --> 00:36:06,290
is it analyzes your software programs

808
00:36:06,290 --> 00:36:08,500
and looks to what open-source packages

809
00:36:08,500 --> 00:36:09,910
have been included in them.

810
00:36:09,910 --> 00:36:12,259
It's a really useful thing
for software developers to do,

811
00:36:12,260 --> 00:36:13,940
but also people buying that software

812
00:36:13,940 --> 00:36:15,820
can run that kinda tool.

813
00:36:15,820 --> 00:36:17,324
- Yeah, didn't know that; Johannes-

814
00:36:17,324 --> 00:36:19,460
- Actually, there's a real
interesting code I like

815
00:36:19,460 --> 00:36:21,840
and it's so amazingly simple.

816
00:36:21,840 --> 00:36:24,063
It doesn't do that much, but Retire JS.

817
00:36:25,572 --> 00:36:28,220
You can install it in your
browser and you go to a website,

818
00:36:28,220 --> 00:36:31,390
will list all the out-of-date
JavaScript libraries

819
00:36:31,390 --> 00:36:34,839
that this website uses.

820
00:36:34,840 --> 00:36:38,880
Kind of interesting to see
that just as you're browsing,

821
00:36:38,880 --> 00:36:41,650
to see what the these
websites may be vulnerable to.

822
00:36:41,650 --> 00:36:46,650
Don't exploit it, but
(laughing) it's that simple,

823
00:36:47,190 --> 00:36:49,543
it's free, and it's
just a browser plug in.

824
00:36:51,275 --> 00:36:52,108
- Johannes, while we got you,

825
00:36:52,108 --> 00:36:54,250
do you have any sense of how frequently

826
00:36:54,250 --> 00:36:58,130
adversaries may be using
these machine learning?

827
00:36:58,130 --> 00:36:59,090
Oh, we already did that one.

828
00:36:59,090 --> 00:37:01,850
Let's skip that one 'cause
that's where Katie took you down.

829
00:37:01,850 --> 00:37:05,210
How can end users evaluate
machine learning models

830
00:37:05,210 --> 00:37:07,270
being presented to them by vendors,

831
00:37:07,270 --> 00:37:09,100
research teams from universities?

832
00:37:09,100 --> 00:37:12,009
Everybody's got the best,
newest, wonderfulest,

833
00:37:12,010 --> 00:37:13,268
but how do you evaluate it.

834
00:37:13,268 --> 00:37:14,180
- And that's a little bit

835
00:37:14,180 --> 00:37:17,060
where you have to question the vendor,

836
00:37:17,060 --> 00:37:19,363
and don't buy black boxes.

837
00:37:20,280 --> 00:37:22,260
20 years ago when I got
started with all of this,

838
00:37:22,260 --> 00:37:25,363
it was the IDS systems that
sort of did that there.

839
00:37:26,210 --> 00:37:29,640
Every vendor had this magic
box that detected attacks

840
00:37:29,640 --> 00:37:31,640
with low false positives

841
00:37:31,640 --> 00:37:35,509
and you don't need to
worry about how it does it.

842
00:37:35,510 --> 00:37:37,600
They had the proprietary algorithms.

843
00:37:37,600 --> 00:37:39,950
You don't see a lot of these
vendors around anymore,

844
00:37:39,950 --> 00:37:42,323
and I think that's a
good thing in some ways.

845
00:37:43,380 --> 00:37:45,290
In order to use these systems,

846
00:37:45,290 --> 00:37:47,029
you have to be able to tune 'em.

847
00:37:47,030 --> 00:37:49,860
You have to be able to
second-guess those systems

848
00:37:49,860 --> 00:37:51,270
because they are not perfect

849
00:37:51,270 --> 00:37:53,470
and they have to work
with your environment.

850
00:37:54,550 --> 00:37:56,910
I think the longest experience we have

851
00:37:56,910 --> 00:37:59,299
with these sort of
machine-learning-style techniques

852
00:37:59,300 --> 00:38:00,623
is spam filtering.

853
00:38:01,520 --> 00:38:04,350
I know the good old basin filters

854
00:38:04,350 --> 00:38:05,870
that you had back in the day,

855
00:38:05,870 --> 00:38:07,460
15 years ago it was the big thing

856
00:38:07,460 --> 00:38:10,810
where it's going to
solve our spam problem.

857
00:38:10,810 --> 00:38:11,830
I think it helped.

858
00:38:11,830 --> 00:38:15,529
But, yeah, so don't accept the black box.

859
00:38:15,530 --> 00:38:18,010
Learn how machine learning
works, experiment with it,

860
00:38:18,010 --> 00:38:21,470
and definitely riddle
with your own malware

861
00:38:21,470 --> 00:38:25,200
and see how the system works with that.

862
00:38:25,200 --> 00:38:28,069
Don't just accept these
malware collections

863
00:38:28,070 --> 00:38:30,530
that people are offering for testing

864
00:38:30,530 --> 00:38:32,070
and definitely no collection

865
00:38:32,070 --> 00:38:34,330
that the vendor gives
you to test a system.

866
00:38:34,330 --> 00:38:38,410
- Thank you; Katie, is
extortion an empty threat

867
00:38:38,410 --> 00:38:40,589
at this point or is the data

868
00:38:40,590 --> 00:38:42,460
actually exfiltrated and made public?

869
00:38:42,460 --> 00:38:44,280
I mean, do they actually make it public

870
00:38:44,280 --> 00:38:45,580
if the victim doesn't pay?

871
00:38:46,500 --> 00:38:48,180
- Yes, there are multiple cases

872
00:38:48,180 --> 00:38:50,220
where these ransomware operators,

873
00:38:50,220 --> 00:38:53,419
extortionware operators
have made data public.

874
00:38:53,420 --> 00:38:56,980
The challenge is, though,
that there isn't great data

875
00:38:56,980 --> 00:38:58,600
on how often that happens,

876
00:38:58,600 --> 00:39:01,690
and in part that's because
people don't really wanna share

877
00:39:01,690 --> 00:39:03,590
when they've been victims
of this kind of thing.

878
00:39:03,590 --> 00:39:05,300
And so, it does happen.

879
00:39:05,300 --> 00:39:07,010
How often, how frequent?

880
00:39:07,010 --> 00:39:08,690
I'd call that an intelligence gap

881
00:39:08,690 --> 00:39:12,180
that ideally by sharing more
we can kind of figure that out

882
00:39:12,180 --> 00:39:13,069
and try to help each other

883
00:39:13,070 --> 00:39:15,290
in making these really tough decisions.

884
00:39:15,290 --> 00:39:18,900
- Cool, let's move to the
religious from the technical.

885
00:39:18,900 --> 00:39:21,650
Heather, do you find that Android or iOS

886
00:39:21,650 --> 00:39:25,553
is a safer platform in
regard to apps being safe?

887
00:39:26,490 --> 00:39:28,109
- You realize I could be crucified

888
00:39:28,110 --> 00:39:30,280
if I made an improper choice
here, because these are-

889
00:39:30,280 --> 00:39:32,520
- Right, we're getting all the religious-

890
00:39:32,520 --> 00:39:34,580
- Yes, people live in
these different worlds.

891
00:39:34,580 --> 00:39:37,590
Honestly, it depends on your device.

892
00:39:37,590 --> 00:39:40,810
So, Android, for example,
has moved greatly

893
00:39:40,810 --> 00:39:43,279
from full-disk encryption
to file-based encryption.

894
00:39:43,280 --> 00:39:45,130
File-based encryption is more secure.

895
00:39:46,180 --> 00:39:49,540
On Apple devices, the iPhone
has file-based encryption,

896
00:39:49,540 --> 00:39:51,110
so it's extremely secure.

897
00:39:51,110 --> 00:39:55,170
As long as you have a
fully-patched up-to-date device

898
00:39:55,170 --> 00:39:58,210
and you have a password
on it, you are safe.

899
00:39:58,210 --> 00:40:00,620
The issue is when you have older devices.

900
00:40:00,620 --> 00:40:02,509
I feel bad saying this, but my dad,

901
00:40:02,510 --> 00:40:05,050
he gets a lotta hand-me-down devices,

902
00:40:05,050 --> 00:40:08,790
so his Samsung Galaxy S5 is not sufficient

903
00:40:08,790 --> 00:40:11,440
and it's probably running a
really old version of Android.

904
00:40:11,440 --> 00:40:13,300
But as long as you are up-to-date,

905
00:40:13,300 --> 00:40:14,860
secure, and fully patched,

906
00:40:14,860 --> 00:40:17,140
Androids are actually
extremely secure devices

907
00:40:17,140 --> 00:40:19,720
and they've always had a bad reputation,

908
00:40:19,720 --> 00:40:22,200
but they are more difficult to access.

909
00:40:22,200 --> 00:40:26,069
- The other politically
incorrect question comes for Ed.

910
00:40:26,070 --> 00:40:28,620
Ed, is the problem of
software dependencies worse

911
00:40:28,620 --> 00:40:32,160
for open-source versus
closed-source software?

912
00:40:32,160 --> 00:40:35,700
- So, the answer to that
is we don't really know

913
00:40:35,700 --> 00:40:36,700
because we can only see

914
00:40:36,700 --> 00:40:39,339
the open-source side of things, right?

915
00:40:39,340 --> 00:40:41,250
And if you look at closed-source software,

916
00:40:41,250 --> 00:40:43,640
it'll have dependencies
often that's open-source

917
00:40:43,640 --> 00:40:44,620
and we can see that.

918
00:40:44,620 --> 00:40:47,850
We can use inventory tools
to take an analysis of it.

919
00:40:47,850 --> 00:40:49,790
But when a closed-source project

920
00:40:49,790 --> 00:40:52,350
has dependencies on other
closed-source projects,

921
00:40:52,350 --> 00:40:54,029
that's much harder for us to see.

922
00:40:54,030 --> 00:40:56,400
Yeah, there are some
references so we can see that,

923
00:40:56,400 --> 00:40:58,680
but it's a much more opaque problem.

924
00:40:58,680 --> 00:41:01,310
So, it's an unknown answer.

925
00:41:01,310 --> 00:41:02,310
And because it's unknown,

926
00:41:02,310 --> 00:41:05,630
I wanna go with what I can see
and look at, and I do prefer

927
00:41:05,630 --> 00:41:08,087
the open-source model.
- Okay.

928
00:41:08,087 --> 00:41:09,350
- The software bill of materials

929
00:41:09,350 --> 00:41:13,060
is a lot easier in the open-source model.

930
00:41:13,060 --> 00:41:15,370
- Exactly, yeah.

931
00:41:15,370 --> 00:41:16,830
- Johannes, while you're on,

932
00:41:16,830 --> 00:41:19,660
although training data's important,

933
00:41:19,660 --> 00:41:22,509
machine learning
ultimately is a new field.

934
00:41:22,510 --> 00:41:25,020
Many organizations could
find it challenging

935
00:41:25,020 --> 00:41:28,270
to assess ML solutions.

936
00:41:28,270 --> 00:41:30,120
Does this suggest that organizations

937
00:41:30,120 --> 00:41:32,370
looking to adopt machine learning

938
00:41:32,370 --> 00:41:35,529
should ideally have staff of
a certain level of expertise

939
00:41:35,530 --> 00:41:36,670
and can test these

940
00:41:36,670 --> 00:41:39,623
or can you get away with
just being a dumb buyer?

941
00:41:40,640 --> 00:41:42,259
- Well, sadly, you can.

942
00:41:42,260 --> 00:41:45,790
Now, I hate to throw
yet another requirement

943
00:41:45,790 --> 00:41:48,830
into a job description you can't fill,

944
00:41:48,830 --> 00:41:51,900
but it's certainly something

945
00:41:51,900 --> 00:41:54,360
you should encourage your
staff to experiment with

946
00:41:54,360 --> 00:41:58,360
and provide them maybe some
training in that direction.

947
00:41:58,360 --> 00:42:02,350
It is a new field, so you
have to do what you can do.

948
00:42:02,350 --> 00:42:05,410
Don't expect too much from staff.

949
00:42:05,410 --> 00:42:08,750
You're not going to find
that machine learning expert

950
00:42:08,750 --> 00:42:10,890
right now that also
knows intrusion detection

951
00:42:10,890 --> 00:42:14,160
and knows malware reverse analysis.

952
00:42:14,160 --> 00:42:18,520
So, give them the time, give
them the tools to experiment.

953
00:42:18,520 --> 00:42:19,353
I think that's, at this point,

954
00:42:19,353 --> 00:42:23,490
probably the best way
to solve this problem.

955
00:42:23,490 --> 00:42:25,250
- Good; I wanna just warn you guys,

956
00:42:25,250 --> 00:42:28,000
in about a minute I'm
gonna ask each of you

957
00:42:28,000 --> 00:42:30,110
to just leave the audience

958
00:42:30,110 --> 00:42:34,070
with one leave-behind, something important

959
00:42:34,070 --> 00:42:36,150
you think they oughta get outta the panel.

960
00:42:36,150 --> 00:42:38,530
I just wanna add to
something you were saying

961
00:42:38,530 --> 00:42:41,420
about jobs you can't
fill in cybersecurity.

962
00:42:41,420 --> 00:42:42,900
One of the new things I'm doing

963
00:42:42,900 --> 00:42:44,190
in the Cyber Talent Institute

964
00:42:44,190 --> 00:42:48,910
is we've been assessing the
level of technical expertise

965
00:42:48,910 --> 00:42:52,009
in people who call themselves
cybersecurity people,

966
00:42:52,010 --> 00:42:55,080
and there is a phenomenal lack of people

967
00:42:55,080 --> 00:42:58,259
who know networking or operating systems

968
00:42:58,260 --> 00:43:01,210
or how a computer works or
how to write a Python program.

969
00:43:01,210 --> 00:43:03,050
It's as if they never went to school.

970
00:43:03,050 --> 00:43:04,980
We're not sure where they got in.

971
00:43:04,980 --> 00:43:06,370
But one of the, I think,

972
00:43:06,370 --> 00:43:08,640
the big changes everyone's
gonna see over the next year

973
00:43:08,640 --> 00:43:09,987
is employers are gonna say,

974
00:43:09,987 --> 00:43:11,857
"Hey, if you wanna work in cybersecurity,

975
00:43:11,857 --> 00:43:13,257
"you at least have to know anatomy.

976
00:43:13,257 --> 00:43:15,647
"We expect surgeons to know anatomy

977
00:43:15,647 --> 00:43:17,123
"before they start cutting.

978
00:43:17,987 --> 00:43:20,337
"We expect cybersecurity
people to know the basics

979
00:43:20,337 --> 00:43:23,627
"before they get into having

980
00:43:23,627 --> 00:43:26,730
"any responsibility for
systems that matter."

981
00:43:26,730 --> 00:43:28,950
But with that, let me go
backwards through the group.

982
00:43:28,950 --> 00:43:31,210
We started with Ed;
let's start with Katie.

983
00:43:31,210 --> 00:43:34,730
Give everybody kind of
a one-minute summary

984
00:43:34,730 --> 00:43:37,950
of a leave-behind for them.

985
00:43:37,950 --> 00:43:39,220
- Excellent.

986
00:43:39,220 --> 00:43:40,609
A quote that I really love

987
00:43:40,610 --> 00:43:43,360
and that has resonated
with me this past year

988
00:43:43,360 --> 00:43:45,327
is from Theodore Roosevelt, and it's,

989
00:43:45,327 --> 00:43:49,020
"Do what you can, with what
you have, where you are."

990
00:43:49,020 --> 00:43:52,070
And I think that applies to
all of our attack techniques

991
00:43:52,070 --> 00:43:55,023
we've talked about, but with
ransomware, machine learning,

992
00:43:56,160 --> 00:43:57,750
you may not be able to solve everything.

993
00:43:57,750 --> 00:43:59,580
You may not be able to
solve every challenge,

994
00:43:59,580 --> 00:44:01,009
but don't get overwhelmed.

995
00:44:01,010 --> 00:44:03,670
There are these attack
techniques we've shared for you,

996
00:44:03,670 --> 00:44:05,360
but start somewhere.

997
00:44:05,360 --> 00:44:07,130
Start with improving your detections,

998
00:44:07,130 --> 00:44:08,980
however that means for your organization.

999
00:44:08,980 --> 00:44:12,660
Even if you can't reach for
the stars and know everything

1000
00:44:12,660 --> 00:44:15,230
and detect everything, do what you can,

1001
00:44:15,230 --> 00:44:16,930
with what you have, where you are,

1002
00:44:16,930 --> 00:44:19,423
whether it's in cybersecurity or in life.

1003
00:44:20,290 --> 00:44:21,410
- Thank you.

1004
00:44:21,410 --> 00:44:22,569
Johannes?

1005
00:44:22,570 --> 00:44:24,890
- Yeah, let me actually
take what Katie just said

1006
00:44:24,890 --> 00:44:27,460
a little bit further, and
it also applies to yourself

1007
00:44:27,460 --> 00:44:28,740
and your personal development.

1008
00:44:28,740 --> 00:44:33,490
There are so many shiny
new objects always to learn

1009
00:44:33,490 --> 00:44:37,000
and to explore when it
comes to cybersecurity.

1010
00:44:37,000 --> 00:44:40,120
Set some time aside to actually do it.

1011
00:44:40,120 --> 00:44:44,410
Don't get so caught up in
running from alert to alert

1012
00:44:44,410 --> 00:44:46,490
that you don't really have the time

1013
00:44:46,490 --> 00:44:48,240
to learn about new interesting stuff,

1014
00:44:48,240 --> 00:44:50,560
because that's actually a lot of fun

1015
00:44:50,560 --> 00:44:52,580
just playing with things.

1016
00:44:52,580 --> 00:44:56,670
And don't forget the
fundamentals while you're at it.

1017
00:44:56,670 --> 00:44:58,670
So, question some of the assumptions

1018
00:44:58,670 --> 00:45:01,530
that you're making about
these complex systems,

1019
00:45:01,530 --> 00:45:04,520
because any assumption
that you don't verify

1020
00:45:04,520 --> 00:45:06,500
is really a vulnerability.

1021
00:45:06,500 --> 00:45:09,320
And, yeah, with that,
let me hand it off to,

1022
00:45:09,320 --> 00:45:10,700
I guess, Heather next.

1023
00:45:10,700 --> 00:45:12,109
- Before you do, just quickly,

1024
00:45:12,110 --> 00:45:17,110
I mentioned that Johannes has
a morning five-minute briefing

1025
00:45:17,110 --> 00:45:20,220
on what happened yesterday in cyberspace

1026
00:45:20,220 --> 00:45:21,490
from the Internet Storm Center.

1027
00:45:21,490 --> 00:45:24,910
Katie also, I forgot to mention,
has something called STAR.

1028
00:45:24,910 --> 00:45:26,240
I don't know exactly what it stands for,

1029
00:45:26,240 --> 00:45:29,589
but it's a threat assessment
or something, I think.

1030
00:45:29,590 --> 00:45:31,420
Is it every two weeks or every four weeks?

1031
00:45:31,420 --> 00:45:34,134
- Yeah, every month, the
Sans Threat Analysis Rundown,

1032
00:45:34,134 --> 00:45:36,290
talking about threats
people need to know about.

1033
00:45:36,290 --> 00:45:38,990
- Cool, so that's how you
keep up with those areas.

1034
00:45:38,990 --> 00:45:39,973
Heather, you're on.

1035
00:45:41,060 --> 00:45:43,520
- I would, this year more than ever,

1036
00:45:43,520 --> 00:45:45,820
we are all tied to our electronics.

1037
00:45:45,820 --> 00:45:47,690
We know that is the only
way we can communicate.

1038
00:45:47,690 --> 00:45:49,710
It's how we're presenting
to you right now.

1039
00:45:49,710 --> 00:45:51,440
Consider your digital footprint.

1040
00:45:51,440 --> 00:45:54,970
Always assume everything you write or say

1041
00:45:54,970 --> 00:45:57,850
is recorded or screenshotted in some way

1042
00:45:57,850 --> 00:46:00,410
and it could come back to haunt you.

1043
00:46:00,410 --> 00:46:01,470
Be professional.

1044
00:46:01,470 --> 00:46:03,720
This was a very political year.

1045
00:46:03,720 --> 00:46:04,990
This was a hard year with COVID.

1046
00:46:04,990 --> 00:46:09,240
It's a hard year with
vaccinations and lots of opinions.

1047
00:46:09,240 --> 00:46:11,180
But consider how you look to the world

1048
00:46:11,180 --> 00:46:12,740
and the footprint you leave behind,

1049
00:46:12,740 --> 00:46:14,040
and make sure your children

1050
00:46:14,040 --> 00:46:15,690
and your loved ones are doing the same.

1051
00:46:15,690 --> 00:46:18,290
I know my son is always on his school iPad

1052
00:46:18,290 --> 00:46:20,540
and it's terrifying that he has access

1053
00:46:20,540 --> 00:46:23,127
all these hours of the day
where his teacher tells us,

1054
00:46:23,127 --> 00:46:24,740
"Stand to the side."

1055
00:46:24,740 --> 00:46:27,770
The teacher says we are the
cheerleader, she is the coach.

1056
00:46:27,770 --> 00:46:29,380
She doesn't want us interacting.

1057
00:46:29,380 --> 00:46:32,213
So, keep an eye on your
kids and consider yourself

1058
00:46:32,213 --> 00:46:35,000
because your digital
footprint is a big one

1059
00:46:35,000 --> 00:46:37,390
and a lotta people don't consider it.

1060
00:46:37,390 --> 00:46:39,990
- And Ed, the last word?
- Sure.

1061
00:46:39,990 --> 00:46:41,540
Last year, during this panel

1062
00:46:41,540 --> 00:46:45,300
at RSA Conference in San
Francisco, I challenged people,

1063
00:46:45,300 --> 00:46:48,667
in my last little minute
of the session, I said,

1064
00:46:48,667 --> 00:46:52,460
"Document what you've learned
at RSA Conference this year."

1065
00:46:52,460 --> 00:46:55,477
And I said to you last year,
"I wanna see you next year

1066
00:46:55,477 --> 00:46:57,926
"to hear what you learned
at RSA Conference last year

1067
00:46:57,927 --> 00:47:00,427
"and how you're applying
that in your environment.

1068
00:47:00,427 --> 00:47:02,497
"And then I'm gonna
challenge you again next year

1069
00:47:02,497 --> 00:47:03,730
"to write down what you learned."

1070
00:47:03,730 --> 00:47:04,950
So, here we are next year.

1071
00:47:04,950 --> 00:47:07,100
Unfortunately, I can't
meet with you face-to-face.

1072
00:47:07,100 --> 00:47:09,650
So, I'm going to renew
my challenge to you.

1073
00:47:09,650 --> 00:47:10,920
Write down what you've learned

1074
00:47:10,920 --> 00:47:13,070
in all the different
RSA Conference sessions

1075
00:47:13,070 --> 00:47:15,410
that you've watched so far and
that you're going to watch.

1076
00:47:15,410 --> 00:47:17,770
Jot that down so it'll jog your memory.

1077
00:47:17,770 --> 00:47:20,120
Then, when we're all together next year

1078
00:47:20,120 --> 00:47:22,470
at RSA Conference 2022,

1079
00:47:22,470 --> 00:47:24,330
come up to me, find me, I'll be there,

1080
00:47:24,330 --> 00:47:26,509
and let's talk about all
the stuff that you learned

1081
00:47:26,509 --> 00:47:27,700
and then how you've applied it

1082
00:47:27,700 --> 00:47:29,589
to improve your own capabilities

1083
00:47:29,590 --> 00:47:31,200
as a cybersecurity professional.

1084
00:47:31,200 --> 00:47:33,100
That's what I want you to do.

1085
00:47:33,100 --> 00:47:34,730
- Thank you, guys.

1086
00:47:34,730 --> 00:47:36,290
I'd like to stand up and clap,

1087
00:47:36,290 --> 00:47:40,623
but we don't do that
online, but thank you.

1088
00:47:41,550 --> 00:47:43,840
It's just wonderful to learn from people

1089
00:47:43,840 --> 00:47:46,000
who have this depth of understanding,

1090
00:47:46,000 --> 00:47:47,410
but also are great teachers.

1091
00:47:47,410 --> 00:47:51,879
So, appreciate you all, and
I hope the audience got a lot

1092
00:47:51,880 --> 00:47:54,320
from what you shared with them.

1093
00:47:54,320 --> 00:47:57,800
With that, thank you all for
being part of RSA this year.

1094
00:47:57,800 --> 00:47:59,760
It was challenging for the people

1095
00:47:59,760 --> 00:48:02,450
who run the program beyond belief,

1096
00:48:02,450 --> 00:48:04,210
and they've done an extraordinary job.

1097
00:48:04,210 --> 00:48:06,930
So, all of us speakers wanna say thank you

1098
00:48:06,930 --> 00:48:10,000
to the people behind the scenes at RSA

1099
00:48:10,000 --> 00:48:11,470
who made this all work.

1100
00:48:11,470 --> 00:48:13,433
Thanks very much, and goodbye.

