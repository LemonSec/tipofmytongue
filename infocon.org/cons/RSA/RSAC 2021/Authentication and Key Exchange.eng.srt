1
00:00:07,380 --> 00:00:08,213
- Hey, hi everyone.

2
00:00:08,213 --> 00:00:09,410
My name is Paul Rosler

3
00:00:09,410 --> 00:00:11,990
and the paper that I
present today has the title

4
00:00:11,990 --> 00:00:13,880
of systematization of knowledge

5
00:00:13,880 --> 00:00:17,550
for game-based security
models of group key exchange.

6
00:00:17,550 --> 00:00:20,050
And this is joint work together
with Bertram Poettering,

7
00:00:20,050 --> 00:00:23,180
Jorg Schwenk and Douglas Stebila

8
00:00:23,180 --> 00:00:26,700
and we directly start
with the core of our paper

9
00:00:26,700 --> 00:00:29,300
which is the idea of group key change.

10
00:00:29,300 --> 00:00:32,210
And we can motivate
group key exchange easily

11
00:00:32,210 --> 00:00:36,560
by the most recent and
most prominent use case

12
00:00:36,560 --> 00:00:38,700
which is a group messaging.

13
00:00:38,700 --> 00:00:39,820
So we can think

14
00:00:39,820 --> 00:00:43,560
of group messaging being
split in modern applications

15
00:00:43,560 --> 00:00:47,190
into a first group key exchange
phase where the members

16
00:00:47,190 --> 00:00:48,980
of a group exchange a key,

17
00:00:48,980 --> 00:00:50,419
and then this key is used

18
00:00:50,420 --> 00:00:54,170
to encrypt every group
message exactly only once

19
00:00:54,170 --> 00:00:55,330
instead of encrypting

20
00:00:55,330 --> 00:00:57,930
every message multiple times individually

21
00:00:57,930 --> 00:00:59,700
to all the receivers in the group,

22
00:00:59,700 --> 00:01:02,650
which is for example, done in signal.

23
00:01:02,650 --> 00:01:06,560
Now we look only at the key
exchange component here.

24
00:01:06,560 --> 00:01:09,510
So multiple users exchange a key,

25
00:01:09,510 --> 00:01:11,670
possibly in dynamic groups.

26
00:01:11,670 --> 00:01:14,570
So maybe users are added to the group

27
00:01:14,570 --> 00:01:19,570
and these users can then exchange new keys

28
00:01:19,960 --> 00:01:21,570
with the new members say,

29
00:01:21,570 --> 00:01:24,440
maybe users are added simultaneously.

30
00:01:24,440 --> 00:01:28,270
And eventually all the users compute

31
00:01:28,270 --> 00:01:32,670
in a group, the same shared
group key, but we are looking

32
00:01:32,670 --> 00:01:35,130
at the security of group
key exchange, which means,

33
00:01:35,130 --> 00:01:37,670
that we also have to consider adversaries

34
00:01:37,670 --> 00:01:42,670
that can maybe reveal key
material or that can introduce

35
00:01:42,880 --> 00:01:45,899
and add malicious users
and control the traffic

36
00:01:45,900 --> 00:01:49,200
between all the members
while exchanging the keys.

37
00:01:49,200 --> 00:01:51,850
And the ultimate goal
against such an adversary is

38
00:01:51,850 --> 00:01:54,399
of course that the keys are secure

39
00:01:54,400 --> 00:01:56,810
meaning that they look
random to the advisory

40
00:01:56,810 --> 00:02:00,110
even though they are
exchanged between these users.

41
00:02:00,110 --> 00:02:02,640
And now I will look at the
literature of group key change.

42
00:02:02,640 --> 00:02:06,180
We see that there are many
even hundreds of papers

43
00:02:07,283 --> 00:02:09,860
on this topic, specifically if we look

44
00:02:09,860 --> 00:02:13,400
at a DBLP paper repository,
we see that there are

45
00:02:13,400 --> 00:02:16,440
more than 150 papers with
a title group key exchange

46
00:02:16,440 --> 00:02:18,070
or group key agreement.

47
00:02:18,070 --> 00:02:20,209
And we can split this literature

48
00:02:20,210 --> 00:02:21,780
into three different phases.

49
00:02:21,780 --> 00:02:24,540
The first one started in the early 80s

50
00:02:24,540 --> 00:02:27,840
where researchers proposed new protocols

51
00:02:27,840 --> 00:02:29,230
for group key change

52
00:02:29,230 --> 00:02:32,350
but they only provided heuristic
security arguments instead

53
00:02:32,350 --> 00:02:34,480
of rigorous security proofs.

54
00:02:34,480 --> 00:02:37,299
And these rigorous security
proves were only introduced

55
00:02:37,300 --> 00:02:38,360
in the second phase

56
00:02:38,360 --> 00:02:40,733
which roughly started in the early 2000s,

57
00:02:41,650 --> 00:02:45,400
leading to the final current phase

58
00:02:45,400 --> 00:02:48,770
on group key exchange research.

59
00:02:48,770 --> 00:02:51,900
Well, researchers try to
understand which properties

60
00:02:51,900 --> 00:02:54,250
are relevant and important

61
00:02:54,250 --> 00:02:57,530
for the specific use case
that I mentioned earlier

62
00:02:57,530 --> 00:02:59,080
which is group messaging.

63
00:02:59,080 --> 00:03:02,300
For example, synchronicity is one

64
00:03:02,300 --> 00:03:05,260
of the properties relevant right now.

65
00:03:05,260 --> 00:03:10,260
And since our main core
consideration is the modeling

66
00:03:12,917 --> 00:03:15,980
and the definition of security
for group key exchange,

67
00:03:15,980 --> 00:03:18,989
we ignore the rather vague

68
00:03:18,990 --> 00:03:22,750
and not really rigorous security analysis

69
00:03:22,750 --> 00:03:25,010
from our consideration, but still we see

70
00:03:25,010 --> 00:03:27,769
that there are more than
30 different definitions

71
00:03:27,770 --> 00:03:30,000
of security for group key exchange

72
00:03:30,000 --> 00:03:33,360
in the literature phases of research.

73
00:03:33,360 --> 00:03:34,400
And this brings us

74
00:03:35,604 --> 00:03:38,890
to the core question and
problem that we investigate

75
00:03:38,890 --> 00:03:43,890
in our paper here, which is
systematization and unifying

76
00:03:43,950 --> 00:03:47,363
the ideas and security definitions
for group key exchange.

77
00:03:48,300 --> 00:03:50,330
Now with this goal in mind

78
00:03:50,330 --> 00:03:53,340
we have to understand what
is group key exchange,

79
00:03:53,340 --> 00:03:55,790
what are the generic definitions of it

80
00:03:55,790 --> 00:03:58,000
and how can we define security for it?

81
00:03:58,000 --> 00:04:00,400
And for this in the literature

82
00:04:00,400 --> 00:04:03,750
of key exchange or in the
literature of any cryptography,

83
00:04:03,750 --> 00:04:06,010
we, first of all, start with syntax,

84
00:04:06,010 --> 00:04:09,149
which describes the abstract interfaces

85
00:04:09,150 --> 00:04:11,030
that capture the inputs

86
00:04:11,030 --> 00:04:15,040
and outputs of group key
exchange algorithms in general.

87
00:04:15,040 --> 00:04:17,243
And for this, we look at one user here

88
00:04:17,244 --> 00:04:22,244
in this picture and this user,
as well as all other users

89
00:04:22,450 --> 00:04:24,180
run on their local devices

90
00:04:24,180 --> 00:04:27,070
the group key exchange algorithms
and these algorithms have

91
00:04:27,070 --> 00:04:29,390
of course, interfaces
to their environments.

92
00:04:29,390 --> 00:04:32,440
For example, to the
upper layer application,

93
00:04:32,440 --> 00:04:33,570
we have to keep in mind

94
00:04:33,570 --> 00:04:36,420
that group key exchange is
never a standalone application

95
00:04:36,420 --> 00:04:39,680
but always serves with
the exchange group keys

96
00:04:39,680 --> 00:04:43,050
to an application that uses these keys.

97
00:04:43,050 --> 00:04:44,570
But this application, in addition

98
00:04:44,570 --> 00:04:47,960
to obtaining these keys
also wants to control

99
00:04:49,060 --> 00:04:51,710
the group key exchange
algorithms by for example

100
00:04:51,710 --> 00:04:55,599
changing the members site,
and many other things.

101
00:04:55,600 --> 00:04:59,230
There are also other interfaces
like the network interfaces

102
00:04:59,230 --> 00:05:00,660
that helps these algorithms

103
00:05:00,660 --> 00:05:05,200
to communicate the information
necessary to exchange keys

104
00:05:05,200 --> 00:05:07,400
between all the members of a group.

105
00:05:07,400 --> 00:05:09,940
Also the storage interface

106
00:05:09,940 --> 00:05:14,590
for saving key material
for these algorithms

107
00:05:14,590 --> 00:05:18,760
on the local devices are important.

108
00:05:18,760 --> 00:05:20,440
Now there are different properties

109
00:05:20,440 --> 00:05:23,530
that these abstract
interfaces have to fulfill.

110
00:05:23,530 --> 00:05:27,840
The first one being, that
is that these interfaces

111
00:05:27,840 --> 00:05:32,280
have to have the algorithms
to become useful, such that,

112
00:05:32,280 --> 00:05:35,059
the environment can use these algorithms

113
00:05:35,060 --> 00:05:36,670
for their different purposes.

114
00:05:36,670 --> 00:05:39,310
For example, sending the cipher text

115
00:05:39,310 --> 00:05:42,720
or exchanging keys for the
upper layer application.

116
00:05:42,720 --> 00:05:46,960
The second property being
that these interfaces

117
00:05:46,960 --> 00:05:49,060
should be defined as generic as possible

118
00:05:49,060 --> 00:05:53,351
such that different
constructions can be captured

119
00:05:53,351 --> 00:05:54,500
by this framework.

120
00:05:54,500 --> 00:05:57,460
This helps us on the one hand
to compare different types

121
00:05:57,460 --> 00:05:59,840
of constructions in the same framework.

122
00:05:59,840 --> 00:06:03,479
It helps us on the other hand in practice

123
00:06:03,480 --> 00:06:05,710
if a group key exchange is deployed

124
00:06:06,885 --> 00:06:08,349
along an application

125
00:06:08,350 --> 00:06:10,460
that this group key exchange construction

126
00:06:10,460 --> 00:06:12,729
can be replaced by another construction

127
00:06:12,730 --> 00:06:15,900
if the former turns out to be insecure.

128
00:06:15,900 --> 00:06:19,679
And lastly, a property is that we want

129
00:06:19,680 --> 00:06:23,340
that these interfaces as
little restrictive as possible

130
00:06:23,340 --> 00:06:27,320
such the construction that
implement these interfaces

131
00:06:27,320 --> 00:06:30,550
can be very efficient and can also

132
00:06:31,460 --> 00:06:34,159
be as functional as possible.

133
00:06:34,160 --> 00:06:38,130
Now, turning to the security
perspective, we have to look

134
00:06:38,130 --> 00:06:42,460
at which security goals
do we want to be fulfilled

135
00:06:42,460 --> 00:06:45,830
and which types of advisories
do we want to capture?

136
00:06:45,830 --> 00:06:48,703
So in the presence of these adversaries,

137
00:06:49,830 --> 00:06:52,979
a good idea for defining security is

138
00:06:52,980 --> 00:06:55,940
that the security goal
is defined intuitive.

139
00:06:55,940 --> 00:06:59,080
And one type of security
definition could be

140
00:06:59,080 --> 00:07:01,460
that the keys look
random to everyone except

141
00:07:01,460 --> 00:07:06,190
for designated members
specifically for the adversary.

142
00:07:06,190 --> 00:07:07,070
On the other hand,

143
00:07:07,070 --> 00:07:09,920
we have to capture those adversaries

144
00:07:09,920 --> 00:07:12,990
as realistically as possible, for example,

145
00:07:12,990 --> 00:07:16,470
an advisory should be able
to control the interface,

146
00:07:16,470 --> 00:07:18,910
specifically the public inputs

147
00:07:18,910 --> 00:07:20,660
controlling the members side,

148
00:07:20,660 --> 00:07:24,030
controlling also the communication

149
00:07:24,030 --> 00:07:26,609
of the algorithms by other network

150
00:07:26,610 --> 00:07:31,230
and also probably corrupt
the secrets that are stored

151
00:07:31,230 --> 00:07:33,743
on the local devices at least temporarily.

152
00:07:34,590 --> 00:07:37,960
Okay. So these are the overall ideas

153
00:07:37,960 --> 00:07:40,810
that we think have to be
considered when defining

154
00:07:40,810 --> 00:07:43,780
and modeling the security
of group key exchange.

155
00:07:43,780 --> 00:07:45,619
And now what we did was looking

156
00:07:45,620 --> 00:07:49,240
at the literature that I
introduced at the very beginning,

157
00:07:49,240 --> 00:07:52,400
but we saw that there is
a very large literature.

158
00:07:52,400 --> 00:07:55,270
So we reduced the considered papers based

159
00:07:55,270 --> 00:07:57,580
on the properties that on the one hand,

160
00:07:57,580 --> 00:08:01,289
we only considered papers that
appeared at Tier conferences.

161
00:08:01,290 --> 00:08:02,210
And on the other hand,

162
00:08:02,210 --> 00:08:05,080
we considered papers that did not appear

163
00:08:05,080 --> 00:08:08,020
on Tier one conferences,
but contributed new insights

164
00:08:08,020 --> 00:08:10,090
to the modeling of group key exchange

165
00:08:10,090 --> 00:08:14,770
which resulted in a set
of 12 different papers.

166
00:08:14,770 --> 00:08:17,400
Now for these 12 different papers,

167
00:08:17,400 --> 00:08:19,539
we defined a framework with which

168
00:08:20,820 --> 00:08:23,950
we characterized the different types

169
00:08:23,950 --> 00:08:27,770
of definitions that we see when modeling

170
00:08:28,690 --> 00:08:30,120
group key exchange.

171
00:08:30,120 --> 00:08:33,210
You see here, the
characteristics that we think

172
00:08:33,210 --> 00:08:37,950
are relevant when defining the
syntax for a group key change

173
00:08:37,950 --> 00:08:41,360
and with this framework,
we then analyzed how

174
00:08:41,360 --> 00:08:45,270
the different papers implemented
these characteristics

175
00:08:45,270 --> 00:08:48,319
or features of the syntax.

176
00:08:48,320 --> 00:08:52,000
And we also try to
understand what we think

177
00:08:52,000 --> 00:08:55,910
are desirable implementations
of all these features.

178
00:08:55,910 --> 00:08:59,430
We continued to do this for
the security definition,

179
00:08:59,430 --> 00:09:01,680
for the partnering or matching definitions

180
00:09:01,680 --> 00:09:03,689
and also for the correctness definitions.

181
00:09:03,690 --> 00:09:06,350
And the result of our analysis was

182
00:09:06,350 --> 00:09:08,930
that none of the papers that we looked at

183
00:09:08,930 --> 00:09:13,930
provided a generic standard
model for group key exchange.

184
00:09:14,320 --> 00:09:15,680
And we can also say this

185
00:09:15,680 --> 00:09:18,180
for the papers that we did not look at

186
00:09:18,180 --> 00:09:20,949
in the many details that we looked at

187
00:09:20,950 --> 00:09:25,776
for the 12 papers that we
considered in our systematization.

188
00:09:25,776 --> 00:09:27,510
The reasons for this are

189
00:09:27,510 --> 00:09:28,810
on the one hand that many

190
00:09:28,810 --> 00:09:30,979
of the definitions are too informal

191
00:09:30,980 --> 00:09:34,070
or unresponsive because the definitions

192
00:09:34,070 --> 00:09:36,830
are not clear enough to
understand what exactly

193
00:09:36,830 --> 00:09:39,453
the requirements are that
are captured in those.

194
00:09:41,150 --> 00:09:45,220
Secondly, we saw that many
of the models are over fitted

195
00:09:45,220 --> 00:09:48,790
meaning that many of
these models were designed

196
00:09:48,790 --> 00:09:52,360
for the analysis of one
specific construction,

197
00:09:52,360 --> 00:09:56,250
and thereby, these
models are not applicable

198
00:09:56,250 --> 00:09:57,340
to other constructions

199
00:09:57,340 --> 00:10:00,603
and cannot be generalized appropriately.

200
00:10:02,050 --> 00:10:03,810
Lastly, the shortcomings are that

201
00:10:03,810 --> 00:10:07,859
many of the external environment
properties or requirement

202
00:10:07,860 --> 00:10:10,750
were ignored in the literature before.

203
00:10:10,750 --> 00:10:14,850
For example, many of these models

204
00:10:14,850 --> 00:10:18,570
required that a public key
infrastructure is deployed along

205
00:10:18,570 --> 00:10:20,880
these group key exchange constructions

206
00:10:20,880 --> 00:10:25,680
or many of the models did not allow us

207
00:10:25,680 --> 00:10:29,120
to generically compose
group key exchange according

208
00:10:29,120 --> 00:10:33,030
to these models with other
upper layer applications.

209
00:10:33,030 --> 00:10:36,630
So our result was that we
came up with a new model

210
00:10:36,630 --> 00:10:40,090
and you may now ask that this
is just yet another model.

211
00:10:40,090 --> 00:10:41,420
And we think, no,

212
00:10:41,420 --> 00:10:44,560
it is a good model because
we learned from the past,

213
00:10:44,560 --> 00:10:47,849
we concentrated on what
modeling should fulfill.

214
00:10:47,850 --> 00:10:50,860
And we thought what group key exchange

215
00:10:50,860 --> 00:10:55,510
in general is, so we came up
with a new syntax definition,

216
00:10:55,510 --> 00:10:58,679
the insecurity definition
that is both precise

217
00:10:58,679 --> 00:11:01,970
and compact because we are independent

218
00:11:01,970 --> 00:11:03,540
of previous constructions

219
00:11:03,540 --> 00:11:07,170
and we give a compact
pseudo-code game definitions

220
00:11:07,170 --> 00:11:09,372
both for correctness and security.

221
00:11:10,600 --> 00:11:12,290
Along other properties,

222
00:11:12,290 --> 00:11:16,410
our model is indifference
to membership operations.

223
00:11:16,410 --> 00:11:17,569
So we fulfill

224
00:11:17,570 --> 00:11:21,370
or we can capture many different
types of constructions.

225
00:11:21,370 --> 00:11:25,210
The ultimate results of our model is

226
00:11:25,210 --> 00:11:27,720
that we can handle different
real-world settings

227
00:11:27,720 --> 00:11:29,593
within one model framework.

228
00:11:30,550 --> 00:11:33,709
On the one hand, we can capture
asynchronous communication.

229
00:11:33,710 --> 00:11:36,270
We can consider different means

230
00:11:36,270 --> 00:11:39,620
of authentication for the group
key exchange constructions

231
00:11:39,620 --> 00:11:41,830
and our model is easily extendable

232
00:11:41,830 --> 00:11:44,143
and as I mentioned, compact and precise.

233
00:11:45,350 --> 00:11:48,120
So you see here are my overall agenda

234
00:11:48,120 --> 00:11:51,210
or the overall contributions
that we provided

235
00:11:51,210 --> 00:11:55,200
on the one hand, developing
a new and fresh understanding

236
00:11:55,200 --> 00:11:57,240
of what group key exchange is,

237
00:11:57,240 --> 00:11:59,250
then deriving from this understanding

238
00:11:59,250 --> 00:12:01,310
a systematization framework

239
00:12:01,310 --> 00:12:05,430
with which we then compared
and analyzed the literature

240
00:12:05,430 --> 00:12:08,719
basically the models that were
proposed in the literature.

241
00:12:08,720 --> 00:12:12,530
And we came up at the end with
a new generic, compact model

242
00:12:12,530 --> 00:12:16,350
with which we think we can
help the future research

243
00:12:16,350 --> 00:12:19,041
on group key to change to understand

244
00:12:19,041 --> 00:12:21,046
what the basic properties

245
00:12:21,046 --> 00:12:22,810
for a group key exchange model should be.

246
00:12:22,810 --> 00:12:26,270
All the details are in
our print publication

247
00:12:26,270 --> 00:12:28,730
and you can contact me via Twitter.

248
00:12:28,730 --> 00:12:31,530
I thank you very much for your intention.

249
00:12:31,530 --> 00:12:32,829
Yeah. Thank you very much.

250
00:12:36,170 --> 00:12:39,390
- [Jacques] I'm Jacques Poway
and I will present the results

251
00:12:39,390 --> 00:12:44,390
of our paper entitled EPID
with malicious revocation.

252
00:12:44,770 --> 00:12:47,939
In this paper, we revisit
the security model

253
00:12:47,940 --> 00:12:50,643
of an animal signature
schemes called EPID,

254
00:12:51,480 --> 00:12:55,133
which has been introduced
by Brickle and Lee in 2007.

255
00:12:56,516 --> 00:12:58,752
This is a joint work with Olivia Sanders.

256
00:13:00,984 --> 00:13:04,740
Enhanced Privacy ID, EPID for short

257
00:13:04,740 --> 00:13:08,043
is a digital signature
scheme supporting anonymity,

258
00:13:09,050 --> 00:13:11,490
just like a group signature,

259
00:13:11,490 --> 00:13:15,562
an EPID signature attests a
legitimate signer belonging

260
00:13:15,562 --> 00:13:19,562
(crackling drowns out speaker)

261
00:13:21,530 --> 00:13:26,350
we mean here, for example,
a group of eligible voters

262
00:13:26,350 --> 00:13:29,550
who are allowed to participate

263
00:13:29,550 --> 00:13:33,740
to a given elections
or a group of customers

264
00:13:33,740 --> 00:13:37,843
who subscribed to the services
of a given service provider.

265
00:13:38,940 --> 00:13:41,185
Anyone can check the validity

266
00:13:41,185 --> 00:13:44,416
of an EPID signature using a
so-called group public key.

267
00:13:45,870 --> 00:13:47,860
EPID signatures are anonymous.

268
00:13:47,860 --> 00:13:51,610
We don't know who among
the group of signers

269
00:13:52,470 --> 00:13:57,470
generated with a signature and
contrary to group signatures,

270
00:13:58,770 --> 00:14:03,770
they are entrustable that no
one can open an EPID signature

271
00:14:04,770 --> 00:14:07,403
and identify a signer.

272
00:14:08,450 --> 00:14:12,270
EPID private signing keys
can, however, be revoked

273
00:14:12,270 --> 00:14:17,270
given the signatures created
by that EPID is standardized.

274
00:14:17,490 --> 00:14:20,140
It is included in the ISO standard

275
00:14:21,370 --> 00:14:25,433
2008 dash two anonymous
digital signatures.

276
00:14:26,503 --> 00:14:28,670
EPID is widely deployed.

277
00:14:28,670 --> 00:14:31,920
It is embedded in billion of devices

278
00:14:31,920 --> 00:14:36,920
as is closed by Intel in
the RSA conference in 2016.

279
00:14:40,800 --> 00:14:45,747
Three types of entities are
involved in an EPID scheme,

280
00:14:47,000 --> 00:14:49,930
an issuer is a member of the group

281
00:14:49,930 --> 00:14:53,416
of the signers and verifiers.

282
00:14:53,417 --> 00:14:58,417
The role of the issuer is to
manage the group of signers

283
00:14:59,720 --> 00:15:03,320
and to ensure to legitimate
member is private

284
00:15:03,320 --> 00:15:08,320
with this private sign-in key,
a member can sign a message

285
00:15:09,590 --> 00:15:14,590
on behalf of the group and any verifiers

286
00:15:15,520 --> 00:15:17,185
can verify the validity

287
00:15:17,185 --> 00:15:20,719
of his signature using a
group public key published

288
00:15:20,720 --> 00:15:21,743
by the issuer.

289
00:15:23,470 --> 00:15:25,143
How does it work in practice?

290
00:15:26,550 --> 00:15:29,319
So in the joint protocol,
the member will have

291
00:15:29,320 --> 00:15:34,150
to choose a secret S which
will be his private key

292
00:15:34,150 --> 00:15:39,150
and then execute with
the issuer a blank thing

293
00:15:39,180 --> 00:15:43,079
at your protocol in order to
obtain a blind certificate

294
00:15:43,080 --> 00:15:44,183
on his secret S.

295
00:15:46,140 --> 00:15:48,100
To sign your message in,

296
00:15:48,100 --> 00:15:49,770
it just has to compute

297
00:15:49,770 --> 00:15:52,410
a non interactive zero-knowledge proof

298
00:15:52,410 --> 00:15:57,319
proving that he knows a secret
S that has been certified

299
00:15:57,320 --> 00:15:59,207
by is an issuer.

300
00:15:59,207 --> 00:16:01,563
The verifier can verify the validity

301
00:16:01,563 --> 00:16:04,460
of this non interactive
zero-knowledge proofs

302
00:16:04,460 --> 00:16:06,237
by using the group public key.

303
00:16:08,830 --> 00:16:10,610
The private signing key

304
00:16:10,610 --> 00:16:12,370
can be reworked

305
00:16:16,334 --> 00:16:21,334
using a signature that has
been generated with that key.

306
00:16:23,600 --> 00:16:27,920
So to this end, the member just has to add

307
00:16:27,920 --> 00:16:29,390
to his signatures

308
00:16:29,390 --> 00:16:33,530
or revocation tag, that
can be computed as follows.

309
00:16:33,530 --> 00:16:37,089
So we just have to
choose a random value H,

310
00:16:37,090 --> 00:16:39,530
and compute the relocation tag

311
00:16:39,530 --> 00:16:42,771
which is a core to H to the power,

312
00:16:42,772 --> 00:16:44,022
S is private signing key.

313
00:16:46,130 --> 00:16:47,700
Before signing a message,

314
00:16:47,700 --> 00:16:51,930
you just have to retrieve the
signatures revocation needs,

315
00:16:51,930 --> 00:16:54,469
which contains revocation tags

316
00:16:54,470 --> 00:16:56,863
of old revoked signatures.

317
00:16:57,960 --> 00:16:59,363
To sign a message,

318
00:17:00,623 --> 00:17:02,226
you then have to compute

319
00:17:02,226 --> 00:17:04,859
(crackling drowns out speaker)

320
00:17:04,859 --> 00:17:07,500
proving that you know S

321
00:17:07,500 --> 00:17:10,450
and the blind certificate on S,

322
00:17:10,450 --> 00:17:12,930
a proof that the revocation tag

323
00:17:12,930 --> 00:17:15,550
has been correctly computing,

324
00:17:15,550 --> 00:17:17,339
that is key is equal

325
00:17:17,339 --> 00:17:21,169
to H to the power S is private sign-in key

326
00:17:21,170 --> 00:17:25,293
and that it did not produce
any of the revocation tag RTI

327
00:17:27,400 --> 00:17:30,330
including in the signatures revocation.

328
00:17:30,330 --> 00:17:35,330
It has to add a proof of
knowledge that PI is different

329
00:17:36,224 --> 00:17:38,173
to the power S.

330
00:17:41,370 --> 00:17:43,679
From a security point of view,

331
00:17:43,680 --> 00:17:46,790
if it's in your choose should
be unforgivable, which means

332
00:17:46,790 --> 00:17:50,770
that an adversary should not
be able to forge a signature

333
00:17:50,770 --> 00:17:54,280
either by framing and an
end user that is signing

334
00:17:54,280 --> 00:17:58,649
on behalf of this honest
user, or by using forge key,

335
00:17:58,650 --> 00:18:00,553
that is key that has not been obtained

336
00:18:00,553 --> 00:18:03,391
during the joint session.

337
00:18:03,391 --> 00:18:04,970
(crackling drowns out speaker)

338
00:18:04,970 --> 00:18:09,340
I may corrupt users and
then own their private keys.

339
00:18:09,340 --> 00:18:12,020
So how to detect in this case,

340
00:18:12,020 --> 00:18:14,803
that the forgery is non-trivial,

341
00:18:14,803 --> 00:18:19,803
the signature has not been generated

342
00:18:19,940 --> 00:18:21,513
using a corrupt key.

343
00:18:23,246 --> 00:18:25,670
The solution to this issue

344
00:18:25,670 --> 00:18:29,520
would be to recover all
the corrupt keys owned

345
00:18:29,520 --> 00:18:30,773
by user adversary.

346
00:18:31,700 --> 00:18:34,200
In current EPID constructions,

347
00:18:34,200 --> 00:18:37,970
this is done by requiring
a zero knowledge proof

348
00:18:37,970 --> 00:18:41,556
of the secret S during joint session.

349
00:18:41,556 --> 00:18:43,043
This has two main drawbacks.

350
00:18:44,210 --> 00:18:45,043
The first one,

351
00:18:45,043 --> 00:18:49,479
if we use classical rewinding
techniques to extract

352
00:18:49,480 --> 00:18:53,470
as corrupt keys, this
really limits the number

353
00:18:53,470 --> 00:18:58,427
of concurrent joint session
that can be done virtually.

354
00:18:59,442 --> 00:19:03,040
On the other hand, if
we use online extractor

355
00:19:03,040 --> 00:19:06,240
is we get heavily impacts the performance

356
00:19:06,240 --> 00:19:07,493
of the joint protocol.

357
00:19:10,203 --> 00:19:14,203
(crackling drowns out speaker)

358
00:19:17,380 --> 00:19:19,590
that there are private signing keys

359
00:19:19,590 --> 00:19:22,062
are not revoked.

360
00:19:23,120 --> 00:19:25,929
A natural question that comes

361
00:19:25,930 --> 00:19:30,930
to mind is we should manage
the signature for revocation.

362
00:19:32,338 --> 00:19:35,245
(crackling drowns out speaker)

363
00:19:35,246 --> 00:19:38,172
it is assumed that this revocation

364
00:19:38,172 --> 00:19:42,520
(crackling drowns out speaker)

365
00:19:42,520 --> 00:19:43,900
So this would lead

366
00:19:43,900 --> 00:19:47,760
to a centralized and not
very practical solutions.

367
00:19:47,760 --> 00:19:52,070
So it would be more
convenient for the verifier

368
00:19:52,070 --> 00:19:55,592
if they could manage
themselves this revocation key.

369
00:19:56,740 --> 00:20:00,300
We should also emphasize
that in the ISO standards,

370
00:20:00,300 --> 00:20:03,919
it is only recommended
to have a trusted entity

371
00:20:03,920 --> 00:20:07,097
for updating the signature revocations.

372
00:20:08,477 --> 00:20:10,470
It is not a requirement.

373
00:20:10,470 --> 00:20:13,300
So another natural questions that comes

374
00:20:13,300 --> 00:20:18,070
to mind is what can be
achieved in terms of security

375
00:20:18,070 --> 00:20:23,003
if this revocation needs are
generated by a malicious.

376
00:20:25,670 --> 00:20:30,670
We observed that if such
revocation is managed

377
00:20:31,120 --> 00:20:32,870
by a malicious entity,

378
00:20:32,870 --> 00:20:35,209
this entity could easily win

379
00:20:36,120 --> 00:20:39,520
the current anonymity
gains by simply adding

380
00:20:39,520 --> 00:20:42,920
to the revocation needs
randomized versions

381
00:20:42,920 --> 00:20:45,240
of the revocation tags

382
00:20:45,240 --> 00:20:48,433
instead of the original revocation tags.

383
00:20:54,190 --> 00:20:56,550
So we revisit the security model

384
00:20:56,550 --> 00:21:01,370
of EPID by removing some
limitations of previous work.

385
00:21:01,370 --> 00:21:04,669
We propose a new unforgeability

386
00:21:04,670 --> 00:21:09,030
where this time, we task
the adversary to produce

387
00:21:09,030 --> 00:21:11,300
N plus one one valid signatures

388
00:21:11,300 --> 00:21:15,633
if it owns N corrupt keys
that have been opened

389
00:21:16,710 --> 00:21:19,150
during successful joint sessions.

390
00:21:19,150 --> 00:21:23,760
We however put in the revocation
needs each new signatures

391
00:21:23,760 --> 00:21:26,480
that it produces in order to ensure

392
00:21:26,480 --> 00:21:31,140
that the N plus one output
signatures were generated

393
00:21:31,140 --> 00:21:36,140
with N plus one distinct keys,
which means that at least one

394
00:21:36,272 --> 00:21:40,112
of these output signatures
is a non-trivial forger.

395
00:21:41,090 --> 00:21:46,090
So we do not require to
recover all the corrupt keys.

396
00:21:48,790 --> 00:21:53,210
We also proposed a new
anonymity game where we stand

397
00:21:53,210 --> 00:21:57,550
where this time we give to the
re-address rate total control

398
00:21:57,550 --> 00:21:58,753
on the revocation.

399
00:22:01,720 --> 00:22:04,860
We also proposed two new EPID schemes

400
00:22:04,860 --> 00:22:08,003
that satisfies our new security
and functional requirements.

401
00:22:09,520 --> 00:22:13,629
In both constructions,
we modified the structure

402
00:22:13,630 --> 00:22:18,150
of the relocation packs
in our constructions,

403
00:22:18,150 --> 00:22:20,420
they are non-millennial goals

404
00:22:20,420 --> 00:22:23,810
in order to prevent their re optimizations

405
00:22:23,810 --> 00:22:27,800
and to prevent the attacks

406
00:22:27,800 --> 00:22:32,183
that I just mentioned in
one of my previous slides.

407
00:22:35,420 --> 00:22:37,090
So to summarize,

408
00:22:37,090 --> 00:22:40,240
EPIDs are standardized,
anonymous signature schemes,

409
00:22:40,240 --> 00:22:42,630
which is widely deployed, it is embedded

410
00:22:42,630 --> 00:22:45,060
in billion of chips.

411
00:22:45,060 --> 00:22:48,332
We have proposed a new
security model for EPID,

412
00:22:49,180 --> 00:22:51,800
which addresses several limitations

413
00:22:51,800 --> 00:22:54,060
of previous models.

414
00:22:54,060 --> 00:22:55,929
Our new unforgeability property

415
00:22:55,930 --> 00:22:59,890
remove the need to extract
corrupt signing keys

416
00:22:59,890 --> 00:23:03,430
which will make our enrollment
of new members simpler

417
00:23:03,430 --> 00:23:07,750
and which will alert concurrent joins.

418
00:23:07,750 --> 00:23:12,690
Our new anonymity property
allows a decentralized management

419
00:23:12,690 --> 00:23:14,350
of revocation list

420
00:23:14,350 --> 00:23:18,503
which we believe better
captures the spirit of EPID.

421
00:23:20,230 --> 00:23:24,390
Finally, we have introduced
two new efficient EPID schemes

422
00:23:24,390 --> 00:23:26,280
that satisfies this new security

423
00:23:27,240 --> 00:23:29,590
and functionality requirements.

424
00:23:29,590 --> 00:23:30,423
Thank you.

425
00:23:33,650 --> 00:23:35,670
- Hi, my name is Magnus Ringerud.

426
00:23:35,670 --> 00:23:38,270
I'm a PhD student at
the Norwegian University

427
00:23:38,270 --> 00:23:41,190
of Science and Technology,
and I'll be talking

428
00:23:41,190 --> 00:23:44,320
about our paper signed
Diffie-Hellman key exchange

429
00:23:44,320 --> 00:23:45,763
with tight security.

430
00:23:46,610 --> 00:23:50,080
This is joint work with
Josh and Pam and Jen

431
00:23:50,080 --> 00:23:52,129
also here at the university.

432
00:23:52,130 --> 00:23:56,320
So a brief outline of this
talk, I'll give an introduction

433
00:23:56,320 --> 00:24:00,100
and try to establish some
context for our work.

434
00:24:00,100 --> 00:24:04,120
Then I'll move into some
technical aspects and finally

435
00:24:04,120 --> 00:24:06,100
some real-world relevance,

436
00:24:06,100 --> 00:24:08,909
as in why is this important for you.

437
00:24:08,910 --> 00:24:11,700
So to start off, we
have to mention the TLS,

438
00:24:11,700 --> 00:24:13,960
the Transport Layer Security.

439
00:24:13,960 --> 00:24:16,810
TLS is used everywhere

440
00:24:16,810 --> 00:24:21,673
and it is dependent on
a key exchange algorithm

441
00:24:23,390 --> 00:24:26,740
for establishing shared key material.

442
00:24:26,740 --> 00:24:28,910
And when I say everywhere in particular

443
00:24:28,910 --> 00:24:32,710
it's used as the security layer in HTTPs

444
00:24:32,710 --> 00:24:35,323
which is used on the
RSA conference webpage.

445
00:24:36,830 --> 00:24:39,480
Now, signed Diffie-Hellman is a core part

446
00:24:39,480 --> 00:24:41,880
of TLS and is one of the algorithms used

447
00:24:41,880 --> 00:24:46,880
in this handshake where you
have two players, Alice and Bob

448
00:24:46,940 --> 00:24:51,410
which is just trying to
create shared key material.

449
00:24:51,410 --> 00:24:54,530
And there are many other versions
of signed Diffie-Hellman.

450
00:24:54,530 --> 00:24:56,530
The point is you have
a Diffie-Hellman share

451
00:24:56,530 --> 00:25:00,753
and you sign it to get
authentication and integrity.

452
00:25:01,610 --> 00:25:03,560
So this is our version

453
00:25:03,560 --> 00:25:06,560
of the protocol where we at the end,

454
00:25:06,560 --> 00:25:09,610
have this is context where
you have the public keys

455
00:25:09,610 --> 00:25:12,310
and you have the, both
the messages, and then,

456
00:25:12,310 --> 00:25:15,970
you hash this together with
the shared key material

457
00:25:15,970 --> 00:25:19,733
which is this Y to the
X term, X to the Y term.

458
00:25:20,640 --> 00:25:23,610
You hash all this to get the final key

459
00:25:23,610 --> 00:25:26,110
and this is important and
we'll get into it later.

460
00:25:27,890 --> 00:25:32,340
So previously, the previous security bound

461
00:25:32,340 --> 00:25:35,035
for signed Diffie-Hellman was made

462
00:25:35,036 --> 00:25:38,614
(crackling drowns out speaker)

463
00:25:38,614 --> 00:25:42,148
As you can see from the
equation it's dependent

464
00:25:42,148 --> 00:25:45,010
on breaking the decisional
Diffie-Hellman problem

465
00:25:45,010 --> 00:25:48,800
and the multi-use security off
a digital signature scheme.

466
00:25:48,800 --> 00:25:52,149
The important part here
is this S squared term.

467
00:25:52,150 --> 00:25:54,150
Now S is the number of sessions.

468
00:25:54,150 --> 00:25:54,983
And hence we say

469
00:25:54,983 --> 00:25:59,350
that this is a security
loss that is quadratic

470
00:25:59,350 --> 00:26:00,570
in the number of sessions.

471
00:26:00,570 --> 00:26:05,570
So S squared, and I would
mention security loss.

472
00:26:05,777 --> 00:26:07,970
And that brings us to tightness.

473
00:26:07,970 --> 00:26:10,520
Why is tightness important?

474
00:26:10,520 --> 00:26:14,210
Well, security loss reduces
the guaranteed security level

475
00:26:14,210 --> 00:26:18,313
that security proof gives you anaive proof

476
00:26:19,800 --> 00:26:22,129
or easy proofs for signed Diffie-Hellman

477
00:26:22,130 --> 00:26:24,910
and many authenticated key exchanges

478
00:26:24,910 --> 00:26:27,623
have this S square security loss.

479
00:26:29,840 --> 00:26:31,610
What this means in practice

480
00:26:31,610 --> 00:26:35,780
you can consider a case
where S is two to the 30

481
00:26:35,780 --> 00:26:39,530
then according to such a
naive proof, if you implement

482
00:26:39,530 --> 00:26:43,660
for 128 bit security, then in reality,

483
00:26:43,660 --> 00:26:46,320
we obtained 68 bits of security.

484
00:26:46,320 --> 00:26:49,793
This is not a safe margin
for large scale applications.

485
00:26:51,600 --> 00:26:54,260
So our contribution is
that nice tight reduction

486
00:26:54,260 --> 00:26:57,030
to the strong computational
Diffie-Hellman assumption.

487
00:26:57,030 --> 00:27:00,810
So we get rid of the security
loss and we abstract ideas

488
00:27:00,810 --> 00:27:03,683
from reasons tight proofs
for the TLS protocol.

489
00:27:04,860 --> 00:27:06,036
So to mention

490
00:27:06,037 --> 00:27:10,430
(crackling drowns out speaker)

491
00:27:10,430 --> 00:27:11,640
there are a variance

492
00:27:11,640 --> 00:27:13,850
of scientific element,
which has been proposed

493
00:27:13,850 --> 00:27:16,473
but most Lewis, this factor of S squared.

494
00:27:17,414 --> 00:27:20,120
(crackling drowns out speaker)

495
00:27:20,120 --> 00:27:21,053
proposed by us

496
00:27:21,054 --> 00:27:23,360
(crackling drowns out speaker)

497
00:27:23,360 --> 00:27:26,500
But this is since it's a
three message it's not back

498
00:27:26,500 --> 00:27:29,350
and forth, but it's that way,
that way and that way again.

499
00:27:29,350 --> 00:27:31,399
So it's an additional message

500
00:27:31,400 --> 00:27:34,850
which of course increases
the communication complexity.

501
00:27:34,850 --> 00:27:37,399
It is also proven in the multi bit model

502
00:27:37,400 --> 00:27:40,320
which does not automatically
give you a tight composition

503
00:27:40,320 --> 00:27:43,020
with symmetric primitives like AEs

504
00:27:43,020 --> 00:27:45,580
which is what you will want for TLS.

505
00:27:45,580 --> 00:27:48,452
There was also a recent, tight, secure AKE

506
00:27:48,452 --> 00:27:51,330
(crackling drowns out speaker)

507
00:27:51,330 --> 00:27:52,460
which use some more

508
00:27:52,460 --> 00:27:55,710
sophisticated techniques
to obtain tightness

509
00:27:55,710 --> 00:28:00,710
which ours is very simple
and straightforward.

510
00:28:01,310 --> 00:28:03,903
And the protocol is very well known.

511
00:28:05,840 --> 00:28:10,840
So some technical details,
this is a sketch of the model

512
00:28:11,900 --> 00:28:13,470
and it's going to be a very simplified

513
00:28:13,470 --> 00:28:15,640
but it'll suit our purpose.

514
00:28:15,640 --> 00:28:16,842
So the idea is

515
00:28:16,842 --> 00:28:20,750
that you have an initiator
which generates a message

516
00:28:20,750 --> 00:28:24,490
and internal state, it sends
the message over and then

517
00:28:24,490 --> 00:28:27,828
you have a responder who
generates his response message.

518
00:28:27,828 --> 00:28:31,670
And now, since he has
all the necessary details

519
00:28:31,670 --> 00:28:34,700
he can also compute the S key

520
00:28:34,700 --> 00:28:38,650
and sends the response message
back and initiated computes.

521
00:28:38,650 --> 00:28:40,173
Hopefully the same key.

522
00:28:41,360 --> 00:28:43,040
Now, the idea here is

523
00:28:43,040 --> 00:28:46,540
that the adversary can
learn these messages

524
00:28:46,540 --> 00:28:49,120
and transcripts as we call them.

525
00:28:49,120 --> 00:28:54,030
And in our very simplified
model, we can say

526
00:28:54,030 --> 00:28:57,540
that Denver's really wants
to be able to compute a key

527
00:28:57,540 --> 00:29:00,710
and the real model, it's
a bit more sophisticated

528
00:29:00,710 --> 00:29:03,643
but the ISM model will
suffice for our purposes.

529
00:29:04,890 --> 00:29:09,430
So why is tightness for AKE here?

530
00:29:09,430 --> 00:29:12,330
Well, we have this thing
called the commitment problem

531
00:29:12,330 --> 00:29:15,800
and a reduction or security
proof is just a way

532
00:29:15,800 --> 00:29:18,190
to relate mathematical problems

533
00:29:18,190 --> 00:29:20,410
or a scheme to another scheme.

534
00:29:20,410 --> 00:29:21,690
And then you have challenges

535
00:29:21,690 --> 00:29:24,260
or you have a reduction and
you have your adversity.

536
00:29:24,260 --> 00:29:27,350
And the reduction wants
to use the adversary

537
00:29:27,350 --> 00:29:28,973
to solve the challenge.

538
00:29:30,360 --> 00:29:32,870
That means that you need
to embed your challenge

539
00:29:32,870 --> 00:29:35,939
in some way, if you
don't, then you could just

540
00:29:35,940 --> 00:29:38,120
attack the scheme without
using the adversary at all

541
00:29:38,120 --> 00:29:41,760
then you have a more of a
direct proof than a reduction

542
00:29:41,760 --> 00:29:45,850
some sense, but this
brings about a problem

543
00:29:45,850 --> 00:29:49,899
because if you am bad,
the challenge everywhere

544
00:29:49,900 --> 00:29:53,280
you're not able to compute
everything anymore.

545
00:29:53,280 --> 00:29:57,770
And in particular, for AKE,
you have to be able to respond

546
00:29:57,770 --> 00:30:00,410
to what's called a key reveal query,

547
00:30:00,410 --> 00:30:02,670
which is a model of what happens

548
00:30:02,670 --> 00:30:04,970
if a session key is leaked,
somebody gets hacked.

549
00:30:04,970 --> 00:30:07,830
You need to be able to model this

550
00:30:07,830 --> 00:30:10,580
and then make sure that the
protocol doesn't break down

551
00:30:11,960 --> 00:30:15,150
but you can't answer this unless you

552
00:30:15,150 --> 00:30:17,760
or if you can't compute the relevant key.

553
00:30:17,760 --> 00:30:19,270
So this is a problem.

554
00:30:19,270 --> 00:30:21,973
If you want to just use the naive,

555
00:30:23,650 --> 00:30:24,590
so I'm betting it everywhere.

556
00:30:24,590 --> 00:30:25,840
It doesn't work

557
00:30:25,840 --> 00:30:29,169
but simply guessing which
sessions are important

558
00:30:29,170 --> 00:30:30,560
than trying to embed them

559
00:30:30,560 --> 00:30:33,460
means that you have to
guess correctly twice

560
00:30:33,460 --> 00:30:37,330
out of S times, which gives
you this at square loss.

561
00:30:37,330 --> 00:30:40,723
So the naive solution leads
to highly non tight groups.

562
00:30:42,520 --> 00:30:45,620
So our approach is then this random Oracle

563
00:30:45,620 --> 00:30:49,209
because instead of actually
computing this Y to X

564
00:30:49,210 --> 00:30:52,810
X to Y term is simply
assimilate the random Oracle.

565
00:30:52,810 --> 00:30:54,773
And then you patch them later on.

566
00:30:55,690 --> 00:30:58,887
This means that you can
now and a consistent way

567
00:30:58,887 --> 00:31:00,693
answer these key reveal queries.

568
00:31:01,560 --> 00:31:02,929
So everything seems good

569
00:31:04,290 --> 00:31:07,420
but that's then still
one challenge remaining.

570
00:31:07,420 --> 00:31:10,640
And that is since we are
in the random Oracle model,

571
00:31:10,640 --> 00:31:14,970
the anniversary can also query
the random Oracle itself.

572
00:31:14,970 --> 00:31:19,500
And if it happens to query
on this particular context

573
00:31:19,500 --> 00:31:23,633
and then wit some element
upended at the end,

574
00:31:24,800 --> 00:31:27,320
we need to be able to
distinguish this element,

575
00:31:27,320 --> 00:31:30,590
the key that you would
compute from this context

576
00:31:30,590 --> 00:31:32,220
or is it just random?

577
00:31:32,220 --> 00:31:34,060
And the answer to that should determine

578
00:31:34,060 --> 00:31:36,560
if he gets what the response

579
00:31:36,560 --> 00:31:39,530
from the random Oracle is the actual key

580
00:31:39,530 --> 00:31:41,210
or just something random.

581
00:31:41,210 --> 00:31:44,000
So in short, we need to
be able to distinguish

582
00:31:44,000 --> 00:31:46,460
is this element a key

583
00:31:46,460 --> 00:31:49,730
that you would compute from a
context or something random?

584
00:31:49,730 --> 00:31:52,270
And then our solution is then what we call

585
00:31:52,270 --> 00:31:54,060
verifiable key exchange.

586
00:31:54,060 --> 00:31:56,090
So you have a key exchange protocol

587
00:31:56,090 --> 00:32:00,730
but you also have a verification
Oracle that can verify

588
00:32:00,730 --> 00:32:03,410
with a given transcript and a key

589
00:32:03,410 --> 00:32:06,653
if this key matches this transcript.

590
00:32:08,150 --> 00:32:11,620
And for signed Diffie-Hellman,
we use the Oracle provided

591
00:32:11,620 --> 00:32:14,659
by the strong computational
Diffie-Hellman assumption.

592
00:32:14,660 --> 00:32:18,049
So how does this affect you and good news,

593
00:32:18,049 --> 00:32:19,120
(crackling drowns out speaker)

594
00:32:19,120 --> 00:32:21,540
supports the current implementations based

595
00:32:21,540 --> 00:32:23,830
on this strong CDX assumption.

596
00:32:23,830 --> 00:32:28,320
So most implementations today
simply ignore security loss

597
00:32:28,320 --> 00:32:31,889
and implement everything as it fit tight.

598
00:32:31,890 --> 00:32:33,690
And our analysis supports

599
00:32:33,690 --> 00:32:38,280
that these implementations
should still be secure

600
00:32:38,280 --> 00:32:39,230
which is good news

601
00:32:40,170 --> 00:32:45,110
if you're able to have a
slightly stronger assumption

602
00:32:46,790 --> 00:32:50,560
and then you have the model
and performance table.

603
00:32:50,560 --> 00:32:53,460
So we compare with some of these others,

604
00:32:53,460 --> 00:32:57,740
other AKE's I've mentioned,
this table is obtained

605
00:32:57,740 --> 00:33:00,660
with a tightly secure moldier
succinct, just scheme.

606
00:33:00,660 --> 00:33:03,070
So all the schemes get the same amount

607
00:33:03,070 --> 00:33:06,090
of extra group elements, et cetera.

608
00:33:06,090 --> 00:33:09,040
So we are communication
efficient, and we are

609
00:33:09,040 --> 00:33:11,570
in the correct single bit model

610
00:33:12,413 --> 00:33:15,170
and one drawback to our work is

611
00:33:16,074 --> 00:33:20,870
that we do not allow state
reveals like this JKRs work does.

612
00:33:20,870 --> 00:33:25,520
However, TLS itself does not
allow state reveals either.

613
00:33:25,520 --> 00:33:28,081
One of the reasons is that

614
00:33:28,081 --> 00:33:30,060
(crackling drowns out speaker)

615
00:33:30,060 --> 00:33:33,320
they are in general not resistant

616
00:33:33,320 --> 00:33:35,760
to state reveals like snore,

617
00:33:35,760 --> 00:33:40,100
for instance, if the secret state leaks,

618
00:33:40,100 --> 00:33:42,023
then your sign in key,

619
00:33:42,950 --> 00:33:45,523
it's open for grabs, which is bad.

620
00:33:47,640 --> 00:33:52,640
So to conclude, we have a tight production

621
00:33:53,140 --> 00:33:55,690
for signed Diffie-Hellman key exchange

622
00:33:55,690 --> 00:33:57,830
where we have improved the security loss

623
00:33:57,830 --> 00:34:00,975
from this S squared to a constant.

624
00:34:00,975 --> 00:34:04,639
(crackling drowns out speaker)

625
00:34:04,640 --> 00:34:06,530
because signed Diffie-Hellman

626
00:34:06,530 --> 00:34:09,900
is one of the core components of TLS.

627
00:34:09,900 --> 00:34:11,810
We have a new key technique

628
00:34:11,810 --> 00:34:16,400
which is verifiable key
exchange, which is an abstraction

629
00:34:16,400 --> 00:34:20,040
of many tight security proofs
who use different kinds

630
00:34:20,040 --> 00:34:23,070
of Oracles to respond exactly as we would

631
00:34:23,070 --> 00:34:26,810
especially this last one
here, Mark for the star.

632
00:34:26,810 --> 00:34:29,460
This protocol is not entirely tight,

633
00:34:29,460 --> 00:34:31,860
but it is exactly, they use exactly

634
00:34:31,860 --> 00:34:35,179
the same Oracle simulation as us.

635
00:34:35,179 --> 00:34:37,062
So it seems fitting to include it.

636
00:34:38,090 --> 00:34:40,590
And finally, the extension of this

637
00:34:40,590 --> 00:34:45,590
or our ongoing work is to extend
this to group key exchange.

638
00:34:45,670 --> 00:34:47,320
So we want to have group key exchange

639
00:34:47,320 --> 00:34:51,603
with tight security through
this verifiable key exchange.

640
00:34:53,270 --> 00:34:55,590
And that is my talk.

641
00:34:55,590 --> 00:34:57,463
Thank you for listening.

