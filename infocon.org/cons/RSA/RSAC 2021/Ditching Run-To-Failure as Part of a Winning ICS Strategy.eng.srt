1
00:00:01,220 --> 00:00:03,120
- Hello, my name's Marty Edwards.

2
00:00:03,120 --> 00:00:05,330
And today I'll be presenting on

3
00:00:05,330 --> 00:00:09,793
Ditching Run-To-Failure as
Part of a Winning ICS Strategy.

4
00:00:10,740 --> 00:00:12,270
Little bit about myself.

5
00:00:12,270 --> 00:00:13,990
I'm currently the Vice President

6
00:00:13,990 --> 00:00:17,750
of Operational Technology
Security at Tenable.

7
00:00:17,750 --> 00:00:20,040
My Twitter handle is ICS Marty.

8
00:00:20,040 --> 00:00:22,782
So if you wanna follow me
on Twitter you can do that.

9
00:00:24,060 --> 00:00:25,903
From a background perspective.

10
00:00:27,150 --> 00:00:29,430
I started as a control systems engineer.

11
00:00:29,430 --> 00:00:31,500
So I have designed, built

12
00:00:31,500 --> 00:00:35,010
maintained these industrial control system

13
00:00:35,010 --> 00:00:39,320
and operational technology
environments over the past.

14
00:00:39,320 --> 00:00:42,650
I'm embarrassed to say 30 to 35 years.

15
00:00:42,650 --> 00:00:46,305
And got recruited into the US government

16
00:00:46,305 --> 00:00:49,307
about 20 years ago.

17
00:00:49,307 --> 00:00:51,530
Worked for the Department of Energy

18
00:00:51,530 --> 00:00:55,700
at the Idaho National Laboratory
as a program manager there

19
00:00:55,700 --> 00:00:58,810
running some of their
industrial security programs.

20
00:00:58,810 --> 00:01:03,300
And then probably the most
notable piece of my career prior

21
00:01:03,300 --> 00:01:08,300
to joining Tenable is I was
the longest serving director

22
00:01:08,810 --> 00:01:11,050
of what was called the ICS CERT,

23
00:01:11,050 --> 00:01:15,360
the Industrial control System
Cyber Emergency Response Team

24
00:01:15,360 --> 00:01:17,940
at the US Department of Homeland Security.

25
00:01:17,940 --> 00:01:21,020
So kind of a little bit
of a unique perspective.

26
00:01:21,020 --> 00:01:22,330
I've worked for the vendor.

27
00:01:22,330 --> 00:01:23,840
I've worked for the asset owner.

28
00:01:23,840 --> 00:01:25,140
I've worked for the government.

29
00:01:25,140 --> 00:01:26,590
I've worked for a contractor.

30
00:01:26,590 --> 00:01:29,480
And now I'm working for a Tenable

31
00:01:29,480 --> 00:01:33,160
which of course is a security
provider in this space.

32
00:01:33,160 --> 00:01:35,820
So I've got some thoughts on

33
00:01:35,820 --> 00:01:37,850
things that we should be looking at

34
00:01:37,850 --> 00:01:41,088
especially in the
operational technology world,

35
00:01:41,088 --> 00:01:45,759
as far as how do we
build a security program

36
00:01:45,760 --> 00:01:47,370
in these environments.

37
00:01:47,370 --> 00:01:50,910
And how do we talk to these
operational technology people

38
00:01:50,910 --> 00:01:53,610
in a language that they understand.

39
00:01:53,610 --> 00:01:56,750
Because quite often there's a disconnect

40
00:01:56,750 --> 00:01:59,790
between how the information
technology people

41
00:01:59,790 --> 00:02:01,900
talk about cybersecurity

42
00:02:01,900 --> 00:02:05,080
and how the boots on the ground engineers

43
00:02:05,080 --> 00:02:06,649
talk about security.

44
00:02:06,650 --> 00:02:10,110
These are the men and women
that run the power grid

45
00:02:10,110 --> 00:02:13,230
or run the water treatment facility

46
00:02:13,230 --> 00:02:18,230
or manage the factory that
makes the goods and services

47
00:02:19,120 --> 00:02:20,470
that we depend on.

48
00:02:20,470 --> 00:02:22,560
And they really speak
two different languages.

49
00:02:22,560 --> 00:02:26,390
So I'm going to try a
new approach with this

50
00:02:26,390 --> 00:02:29,339
and we'll see how it goes.

51
00:02:29,340 --> 00:02:31,489
I'm going to do my best
to answer questions

52
00:02:31,489 --> 00:02:34,545
through the chat function
as we go along here.

53
00:02:34,545 --> 00:02:37,220
So I really encourage
you to take advantage

54
00:02:37,220 --> 00:02:40,220
of the chat function and
type all those questions in

55
00:02:40,220 --> 00:02:43,230
and we'll see if we can get
a good dialogue going here.

56
00:02:43,230 --> 00:02:45,280
And I'm hoping this will be a lot of fun.

57
00:02:46,414 --> 00:02:50,480
So if you look at operational technology

58
00:02:50,480 --> 00:02:52,179
or industrial control systems,

59
00:02:52,180 --> 00:02:56,300
a lot of people don't
actually know what that means.

60
00:02:56,300 --> 00:03:00,250
So these are the computers, the systems

61
00:03:00,250 --> 00:03:03,900
that operate all of our
critical infrastructure.

62
00:03:03,900 --> 00:03:06,850
So if you look at something
like a power grid,

63
00:03:06,850 --> 00:03:09,720
there's these little black box computers

64
00:03:09,720 --> 00:03:12,940
that they tell the
breakers and the switches

65
00:03:12,940 --> 00:03:14,500
on the power grid what to do.

66
00:03:14,500 --> 00:03:17,770
Or they tell the pumps in
the water treatment facility

67
00:03:17,770 --> 00:03:20,580
what to do and how to
turn them on and off.

68
00:03:20,580 --> 00:03:23,220
There's really complicated control rooms

69
00:03:23,220 --> 00:03:27,109
with many, many screens that
operators sit in front of,

70
00:03:27,110 --> 00:03:30,000
and and control these environments.

71
00:03:30,000 --> 00:03:32,498
And they're all reliant on computers.

72
00:03:32,498 --> 00:03:35,297
It's very specialized computers.

73
00:03:35,297 --> 00:03:38,820
Now, in some of these factories,

74
00:03:38,820 --> 00:03:43,820
we spend tens of millions of
dollars in capital expenditures

75
00:03:44,880 --> 00:03:46,519
on the systems.

76
00:03:46,520 --> 00:03:49,210
So you have $10 million worth

77
00:03:49,210 --> 00:03:51,880
of very specialized computer equipment

78
00:03:51,880 --> 00:03:55,570
that you're using to run
these factories with.

79
00:03:55,570 --> 00:03:59,870
And I maintain, and it's a pun intended.

80
00:03:59,870 --> 00:04:01,870
I maintain that we're not maintaining

81
00:04:01,870 --> 00:04:04,040
these environments properly.

82
00:04:04,040 --> 00:04:05,900
We do the capital expenditure

83
00:04:05,900 --> 00:04:09,230
and it has a depreciation
schedule, et cetera,

84
00:04:09,230 --> 00:04:11,179
but we're not really thinking

85
00:04:11,180 --> 00:04:15,440
about what kind of cyber
maintenance do these systems need.

86
00:04:15,440 --> 00:04:20,233
What do we need to do to these
systems day in and day out

87
00:04:20,233 --> 00:04:22,370
to make sure they stay running?

88
00:04:22,370 --> 00:04:25,300
And, I'm going to talk
about that specifically

89
00:04:25,300 --> 00:04:30,300
from a cybersecurity
perspective for maintenance.

90
00:04:31,470 --> 00:04:34,680
So this is not a new technology.

91
00:04:34,680 --> 00:04:36,920
This is not a new field of study.

92
00:04:36,920 --> 00:04:41,890
People have been studying
maintenance and reliability

93
00:04:45,182 --> 00:04:48,070
and how to best invest your
meager maintenance resources

94
00:04:48,070 --> 00:04:49,793
for a long time.

95
00:04:49,793 --> 00:04:54,430
They've also been assigning
risk to the system.

96
00:04:54,430 --> 00:04:59,190
So you have some systems
that are highly critical.

97
00:04:59,190 --> 00:05:02,633
That you have very
significant consequences

98
00:05:02,633 --> 00:05:07,240
if there's a breach of the
system, the system fails.

99
00:05:07,240 --> 00:05:09,000
And you've got other systems perhaps

100
00:05:09,000 --> 00:05:13,330
that have lesser consequences
if there's a failure.

101
00:05:13,330 --> 00:05:17,450
And so it's not a broad brush approach

102
00:05:17,450 --> 00:05:20,690
or there's not one solution that fits all.

103
00:05:20,690 --> 00:05:24,010
You really need to tailor
your security controls

104
00:05:24,010 --> 00:05:27,360
for the risk that particular environment,

105
00:05:27,360 --> 00:05:29,613
that particular system has.

106
00:05:30,770 --> 00:05:34,380
In any case, if you lose
one of these systems,

107
00:05:34,380 --> 00:05:38,030
if if one of these highly
specialized computer systems

108
00:05:38,030 --> 00:05:42,253
stops operating, really
significant things happen.

109
00:05:42,253 --> 00:05:44,700
I mean, you do have consequences

110
00:05:44,700 --> 00:05:47,659
where your factory stops making product

111
00:05:47,660 --> 00:05:49,680
or the power grid goes down,

112
00:05:49,680 --> 00:05:52,880
or there's some sort of
consequences based on that.

113
00:05:52,880 --> 00:05:57,880
So, we need to plan through
these systems and environments

114
00:05:58,930 --> 00:06:03,020
and make sure we're doing
the sort of the right size

115
00:06:03,020 --> 00:06:04,293
of solution.

116
00:06:05,180 --> 00:06:06,260
So let's look at this

117
00:06:06,260 --> 00:06:10,010
from a maintenance perspective
or from the perspective

118
00:06:10,010 --> 00:06:14,080
of these different styles of maintenance.

119
00:06:14,080 --> 00:06:16,530
And if you look at the
chart that I've got there.

120
00:06:17,780 --> 00:06:21,515
In the old days, in a plant

121
00:06:21,515 --> 00:06:26,515
we basically did maintenance
in a reactive fashion.

122
00:06:26,800 --> 00:06:30,250
So let's look at this as
if it's your automobile.

123
00:06:30,250 --> 00:06:31,915
So you drive your car

124
00:06:31,915 --> 00:06:35,570
and you just keep driving it
and you don't change the oil.

125
00:06:35,570 --> 00:06:37,849
And you don't look at the
pressure in the tires,

126
00:06:37,850 --> 00:06:39,030
you just drive it

127
00:06:39,030 --> 00:06:41,630
And you drive it till it it breaks.

128
00:06:41,630 --> 00:06:43,590
You drive it till you get a flat tire.

129
00:06:43,590 --> 00:06:45,900
You drive it until the
check engine light comes on

130
00:06:45,900 --> 00:06:48,500
or you drive it until something happens

131
00:06:48,500 --> 00:06:50,920
and you have to go get it repaired.

132
00:06:50,920 --> 00:06:55,900
That's reactive maintenance,
or this run to failure concept.

133
00:06:55,900 --> 00:06:57,849
And most maintenance people,

134
00:06:57,850 --> 00:07:01,340
and I fully disclose, I'm
not a maintenance engineer,

135
00:07:01,340 --> 00:07:03,390
most maintenance people will tell you

136
00:07:03,390 --> 00:07:04,789
that's very inefficient.

137
00:07:04,790 --> 00:07:07,530
It costs you a lot of money
to make those repairs.

138
00:07:07,530 --> 00:07:10,130
You typically damage the system worse off

139
00:07:10,130 --> 00:07:13,435
than if you would have
put some thought into it.

140
00:07:13,435 --> 00:07:17,977
The next type of maintenance is to go

141
00:07:17,977 --> 00:07:19,750
to a schedule driven maintenance.

142
00:07:19,750 --> 00:07:24,750
So you take your car every 3000
miles or every three months

143
00:07:24,800 --> 00:07:27,870
you take it to the local oil change place.

144
00:07:27,870 --> 00:07:31,220
No matter what, you take
it in, they change the oil

145
00:07:32,299 --> 00:07:35,370
and you are making sure that

146
00:07:35,370 --> 00:07:39,140
you've got a well-maintained
vehicle because of that.

147
00:07:39,140 --> 00:07:42,729
Well, is it necessary to do that?

148
00:07:42,730 --> 00:07:46,269
Is your oil really worn
out after 3000 miles?

149
00:07:46,269 --> 00:07:47,623
How do you know?

150
00:07:48,529 --> 00:07:53,529
Well, the more modern
maintenance type of schedules

151
00:07:54,340 --> 00:07:58,231
especially with regards to
lubrication and that is it.

152
00:07:58,231 --> 00:08:00,020
They will test the oil.

153
00:08:00,020 --> 00:08:03,380
So you take a sample of the oil.

154
00:08:03,380 --> 00:08:04,810
It's in this big machine.

155
00:08:04,810 --> 00:08:06,620
You might have a million dollar piece

156
00:08:06,620 --> 00:08:08,810
of machinery in your factory.

157
00:08:08,810 --> 00:08:10,717
They sample the oil, and they go,

158
00:08:10,717 --> 00:08:12,440
"Oh yeah, this oil is still in good shape

159
00:08:12,440 --> 00:08:13,730
we can keep running."

160
00:08:13,730 --> 00:08:14,563
Or they go,

161
00:08:14,563 --> 00:08:17,570
"Oh this oil is starting to
show signs of breaking down."

162
00:08:17,570 --> 00:08:19,290
So what we should do

163
00:08:19,290 --> 00:08:24,290
is we should schedule the next
time we have some downtime

164
00:08:25,481 --> 00:08:27,690
to change the oil in this machine.

165
00:08:27,690 --> 00:08:30,540
So we don't have to shut
the whole factory down.

166
00:08:30,540 --> 00:08:32,809
We have another reason the
factory is gonna be down

167
00:08:32,809 --> 00:08:35,179
to change products or do something else.

168
00:08:35,179 --> 00:08:36,709
We'll change all at the same time.

169
00:08:36,710 --> 00:08:39,533
So we minimize the impact
to the organization.

170
00:08:41,830 --> 00:08:45,710
My premise is that, organizations
in the physical world

171
00:08:45,710 --> 00:08:49,210
are moving more towards this
sort of planned proactive,

172
00:08:49,210 --> 00:08:50,660
predictive maintenance.

173
00:08:50,660 --> 00:08:53,530
And then it's a much more
cost-effective method.

174
00:08:53,530 --> 00:08:58,530
So if you at the run to
failure sort of methodology,

175
00:08:59,270 --> 00:09:01,510
I maintain that that's expensive.

176
00:09:01,510 --> 00:09:04,660
I mean, things happen
in an unscheduled way.

177
00:09:04,660 --> 00:09:06,670
So it's unpredictable.

178
00:09:06,670 --> 00:09:09,199
You don't know when
something's gonna fail.

179
00:09:09,200 --> 00:09:11,900
I think it's actually
really, really stressful

180
00:09:11,900 --> 00:09:13,189
on the people.

181
00:09:13,190 --> 00:09:16,340
So if you look at this from
a human factors perspective,

182
00:09:16,340 --> 00:09:19,670
your personnel, they don't
know when it's gonna fail.

183
00:09:19,670 --> 00:09:23,390
So when it does, it's kind
of like all hands on deck,

184
00:09:23,390 --> 00:09:26,290
it's stressful, it's costly.

185
00:09:26,290 --> 00:09:28,944
The other thing is that
this type of failure,

186
00:09:28,945 --> 00:09:33,945
this type of method, isn't good
at a sophisticated adversary

187
00:09:34,170 --> 00:09:36,608
or common mode type failures.

188
00:09:36,609 --> 00:09:38,570
So it's not good if you have some sort

189
00:09:38,570 --> 00:09:41,700
of electrical disturbance
that burns out all your motors

190
00:09:41,700 --> 00:09:45,230
at the same time when you
don't have enough spare parts

191
00:09:45,230 --> 00:09:46,140
to fix it.

192
00:09:46,140 --> 00:09:50,747
So, very spendy and costly,
not very effective at all.

193
00:09:56,280 --> 00:10:00,163
Let's look at cybersecurity
sort of examples of this.

194
00:10:01,370 --> 00:10:05,610
I maintain that if you sort
of do nothing proactively

195
00:10:05,610 --> 00:10:09,040
in the cybersecurity area, and you wait

196
00:10:09,040 --> 00:10:11,579
until you have some sort of
incident, and in this case

197
00:10:11,580 --> 00:10:14,950
I'm articulating a ransomware incident.

198
00:10:14,950 --> 00:10:16,740
That's the same as run to failure.

199
00:10:16,740 --> 00:10:18,470
You're ignoring your cyber security

200
00:10:18,470 --> 00:10:20,680
until you have some sort of incident.

201
00:10:20,680 --> 00:10:22,979
And then you're paying through the nose

202
00:10:22,980 --> 00:10:25,430
to an incident response company

203
00:10:25,430 --> 00:10:28,050
to come back in and try to fix things.

204
00:10:28,050 --> 00:10:31,479
Back when I was with Homeland
security and the ICA CERT,

205
00:10:31,480 --> 00:10:34,260
my team was the team
that would fly away to go

206
00:10:34,260 --> 00:10:37,240
and investigate these types of things.

207
00:10:37,240 --> 00:10:42,240
And we heard from everybody
that in the numbers may differ

208
00:10:42,280 --> 00:10:45,670
but I think it's at least
an order of magnitude

209
00:10:45,670 --> 00:10:49,520
more expensive to try to
fix something after the fact

210
00:10:49,520 --> 00:10:51,800
from an incident response perspective

211
00:10:51,800 --> 00:10:55,459
than if you invested in
that security ahead of time.

212
00:10:55,460 --> 00:10:57,890
So very costly.

213
00:10:57,890 --> 00:11:00,390
And I think that that correlates well

214
00:11:00,390 --> 00:11:03,939
to the data that I've seen
in the cybersecurity world.

215
00:11:03,940 --> 00:11:06,300
And I like the little sign
I've got there on the bottom

216
00:11:06,300 --> 00:11:07,939
that says, it says,

217
00:11:07,940 --> 00:11:10,300
if you don't schedule time for maintenance

218
00:11:10,300 --> 00:11:12,599
your equipment's going
to schedule it for you,

219
00:11:13,577 --> 00:11:15,413
which I think is absolutely true.

220
00:11:17,800 --> 00:11:20,209
So we talked a little bit

221
00:11:20,210 --> 00:11:25,210
about these other maintenance
schemes, not run to failure.

222
00:11:25,590 --> 00:11:30,480
So the predictive methods
or the schedule methods

223
00:11:30,480 --> 00:11:33,100
or this testing of the lube oil.

224
00:11:33,100 --> 00:11:37,630
So let's take a look at what
do these methods look like

225
00:11:37,630 --> 00:11:40,260
in cybersecurity.

226
00:11:40,260 --> 00:11:44,740
So think about this, physical machinery.

227
00:11:44,740 --> 00:11:49,740
But how do we extrapolate some
of these maintenance methods

228
00:11:51,432 --> 00:11:54,300
and sort of planning methods?

229
00:11:54,300 --> 00:11:57,219
How do we extrapolate that over to cyber?

230
00:11:57,220 --> 00:11:58,320
Is there the equivalent

231
00:11:58,320 --> 00:12:01,380
of kind of preventative
maintenance for cyber?

232
00:12:01,380 --> 00:12:03,570
And I'll talk through some of that.

233
00:12:03,570 --> 00:12:07,272
And again, I encourage
you to ask questions

234
00:12:07,272 --> 00:12:10,070
as we go through the chat

235
00:12:10,070 --> 00:12:15,070
and I'll do my best to try
to keep up and answer them.

236
00:12:15,570 --> 00:12:18,890
So I look at preventative maintenance

237
00:12:18,890 --> 00:12:21,470
which would be like a
schedule based maintenance.

238
00:12:21,470 --> 00:12:26,150
So changing your oil every
3000 miles or 5,000 kilometers

239
00:12:26,150 --> 00:12:29,793
if you're a Canadian,
or if you're in Europe.

240
00:12:29,793 --> 00:12:34,793
I look at that as kind of
similar to the compliance folks.

241
00:12:35,530 --> 00:12:39,189
So these are the folks that
bring in an assessment team.

242
00:12:39,190 --> 00:12:43,357
So you come in and your
compliance officer says,

243
00:12:43,357 --> 00:12:46,510
"Thou shalt do a risk
assessment once a year

244
00:12:46,510 --> 00:12:50,020
or once every two years,
or you shall do a pen test

245
00:12:50,020 --> 00:12:51,810
every year, every two years.'

246
00:12:51,810 --> 00:12:54,300
So on some sort of
calendar or schedule basis.

247
00:12:54,300 --> 00:12:59,300
So you are encouraged to bring
in some experts and do that.

248
00:13:00,300 --> 00:13:03,410
And there's certainly a lot of consultants

249
00:13:03,410 --> 00:13:06,350
and a lot of organizations
that will do that for you.

250
00:13:06,350 --> 00:13:09,160
So you come in and you do a sort of a

251
00:13:09,160 --> 00:13:13,189
a point in time, snapshot of
what's the security look like

252
00:13:13,190 --> 00:13:14,810
in this organizations.

253
00:13:14,810 --> 00:13:17,219
So you take a tool in the IT world.

254
00:13:17,220 --> 00:13:18,850
We would take a tool like Nessus.

255
00:13:18,850 --> 00:13:20,849
We would scan the IT assets.

256
00:13:20,849 --> 00:13:23,785
We would provide you
with a report that says,

257
00:13:23,785 --> 00:13:25,788
'Here are the assets

258
00:13:25,788 --> 00:13:29,110
and here are the known
vulnerabilities in those assets."

259
00:13:29,110 --> 00:13:32,020
Or you could scrub through
the different log files

260
00:13:32,020 --> 00:13:32,939
and things.

261
00:13:32,940 --> 00:13:35,500
So my problem with that

262
00:13:35,500 --> 00:13:38,310
is that it's useful as a
point in time reference.

263
00:13:38,310 --> 00:13:40,640
And it's certainly useful to tick the box

264
00:13:40,640 --> 00:13:42,939
from a compliance perspective,

265
00:13:42,940 --> 00:13:45,060
but I've seen way too many of those things

266
00:13:45,060 --> 00:13:48,229
where they basically take the report.

267
00:13:48,230 --> 00:13:50,649
The report comes from the consultant,

268
00:13:50,649 --> 00:13:53,540
somebody flips through it,
and it gets put in the safe

269
00:13:53,540 --> 00:13:56,420
or it gets put on the bookshelf
or in a filing cabinet.

270
00:13:56,420 --> 00:13:59,079
And nobody ever really
addresses the issues

271
00:13:59,080 --> 00:14:00,980
that are in that report.

272
00:14:00,980 --> 00:14:02,590
It's kind of done

273
00:14:02,590 --> 00:14:05,721
because somebody said we
had to have a report done.

274
00:14:05,721 --> 00:14:08,370
Somebody said that to be compliant,

275
00:14:08,370 --> 00:14:10,720
we had to have a risk assessment done,

276
00:14:10,720 --> 00:14:14,380
but it's really still just
a point in time solution.

277
00:14:14,380 --> 00:14:19,380
It doesn't give you a good
understanding of the long-term

278
00:14:19,860 --> 00:14:24,860
continuous improvement type of process.

279
00:14:26,980 --> 00:14:29,110
So let's look at proactive maintenance.

280
00:14:29,110 --> 00:14:33,170
So how do we take things
from the preventative,

281
00:14:33,170 --> 00:14:36,130
schedule based type of approach

282
00:14:36,130 --> 00:14:39,689
into more of a proactive,

283
00:14:39,690 --> 00:14:43,110
continuous real time based security?

284
00:14:43,110 --> 00:14:46,520
So how do you how do you make sure that

285
00:14:46,520 --> 00:14:48,350
you completely understand

286
00:14:48,350 --> 00:14:50,350
what's happening on your networks?

287
00:14:50,350 --> 00:14:53,350
How do you know what's
happening with your devices?

288
00:14:53,350 --> 00:14:57,610
Is the logic inside your
programmable logic controller

289
00:14:57,610 --> 00:15:00,600
or the device that's
controlling the factory?

290
00:15:00,600 --> 00:15:03,560
Is somebody making changes to that?

291
00:15:03,560 --> 00:15:08,282
Is there some sort of
malware or other activity

292
00:15:08,283 --> 00:15:12,820
that you don't approve of that
is outside of your policy,

293
00:15:12,820 --> 00:15:14,900
that's moving around
within these networks.

294
00:15:14,900 --> 00:15:19,900
And do you have the
mechanisms in place to be able

295
00:15:19,957 --> 00:15:22,036
to detect those changes.

296
00:15:22,036 --> 00:15:23,892
To see what's happening.

297
00:15:27,662 --> 00:15:30,340
So in the maintenance world,

298
00:15:30,340 --> 00:15:34,710
like in the electrical
maintenance world, especially,

299
00:15:34,710 --> 00:15:38,790
I kind of look at that
like thermal imaging.

300
00:15:38,790 --> 00:15:43,790
So you've heard of a FLIR
camera forward-looking infrared.

301
00:15:44,100 --> 00:15:48,790
So back in the day, when I
ran crews of electricians,

302
00:15:48,790 --> 00:15:53,790
we had some cameras that these
cameras cost maybe $50,000.

303
00:15:54,980 --> 00:15:58,130
So an electrician or an
engineer, electrical engineer

304
00:15:58,130 --> 00:16:01,260
would go get this really
specialized camera

305
00:16:01,260 --> 00:16:03,610
and they would take pictures

306
00:16:03,610 --> 00:16:07,640
of either electrical switch
gear or a running motor

307
00:16:07,640 --> 00:16:09,319
or they would take some pictures

308
00:16:09,320 --> 00:16:11,720
of these things to try to find a hotspot,

309
00:16:11,720 --> 00:16:13,140
try to find,

310
00:16:13,140 --> 00:16:17,630
is this piece of equipment
running within specifications.

311
00:16:17,630 --> 00:16:21,330
And in this case, this picture
is of a pump and of a motor.

312
00:16:21,330 --> 00:16:25,310
And you can see on the
motor, it looks red,

313
00:16:25,310 --> 00:16:26,989
which probably isn't a good thing

314
00:16:26,990 --> 00:16:29,220
from a temperature perspective.

315
00:16:29,220 --> 00:16:32,240
But of especial special concern

316
00:16:32,240 --> 00:16:35,613
is that the portion of
the motor that's white.

317
00:16:38,930 --> 00:16:41,199
So that portion of the motor that's white

318
00:16:41,200 --> 00:16:44,660
is a part of the windings
it's really, really hot.

319
00:16:44,660 --> 00:16:47,699
So in this particular case

320
00:16:47,700 --> 00:16:50,710
I believe what they found
is they found that the fan,

321
00:16:50,710 --> 00:16:52,890
the cooling fan on the back
of the motor had broken.

322
00:16:52,890 --> 00:16:56,140
And so the motor wasn't
being cooled properly.

323
00:16:56,140 --> 00:16:58,640
But you can take a picture of the motor

324
00:16:58,640 --> 00:17:00,090
while the motors running.

325
00:17:00,090 --> 00:17:01,610
So the factory still running,

326
00:17:01,610 --> 00:17:05,020
but whatever this motor
and pump is pumping around

327
00:17:05,020 --> 00:17:05,853
is still running.

328
00:17:05,853 --> 00:17:07,660
You're still making product.

329
00:17:07,660 --> 00:17:09,690
You take this picture.

330
00:17:09,690 --> 00:17:11,710
Well, now you can schedule, you can say,

331
00:17:11,710 --> 00:17:16,619
okay, Jim, or, okay, Lisa,

332
00:17:16,619 --> 00:17:20,760
we need to schedule some time to replace

333
00:17:20,760 --> 00:17:22,660
or to repair this motor

334
00:17:22,660 --> 00:17:24,670
the next time that area of the plant

335
00:17:24,670 --> 00:17:26,960
is shut down for cleaning.

336
00:17:26,960 --> 00:17:30,580
Maybe this particular plant
has to shut down every week,

337
00:17:30,580 --> 00:17:32,980
and every week they take a cleaning run.

338
00:17:32,980 --> 00:17:36,110
And they can schedule
the time to repair that.

339
00:17:36,110 --> 00:17:38,820
So that's good because
you don't lose time.

340
00:17:38,820 --> 00:17:40,730
And then in the OT world

341
00:17:40,730 --> 00:17:43,530
and in the factory and production world,

342
00:17:43,530 --> 00:17:47,860
I have drilled into my head
that there's 1,440 minutes.

343
00:17:48,840 --> 00:17:52,127
There's 1,440 minutes in every single day.

344
00:17:52,127 --> 00:17:55,100
And the reason I know that is because

345
00:17:55,100 --> 00:17:59,949
if the control system was
responsible for one minute

346
00:17:59,950 --> 00:18:02,410
of downtime on some machine,

347
00:18:02,410 --> 00:18:05,140
Marty had to stand up in
front of the mill manager

348
00:18:05,140 --> 00:18:08,050
or the production staff
and explain how that

349
00:18:08,050 --> 00:18:10,550
never was gonna ever, ever happen again.

350
00:18:10,550 --> 00:18:12,770
And what measures we put in place

351
00:18:12,770 --> 00:18:14,200
to prevent it from happening.

352
00:18:14,200 --> 00:18:16,250
And some of those measures
on the electrical side

353
00:18:16,250 --> 00:18:17,090
where things like this.

354
00:18:17,090 --> 00:18:20,149
Take a picture of the
machinery while it's running,

355
00:18:20,150 --> 00:18:23,270
find out where the hotspots
are and then set it up

356
00:18:23,270 --> 00:18:27,100
so that you can fix it in a
time that's convenient to you.

357
00:18:27,100 --> 00:18:29,423
And it costs you less money that way.

358
00:18:30,790 --> 00:18:33,860
So let's look at how we
look inside these devices.

359
00:18:33,860 --> 00:18:36,169
Wouldn't it be neat to
be able to see inside

360
00:18:36,170 --> 00:18:39,800
of your OT devices, to be able to tell

361
00:18:39,800 --> 00:18:42,840
if these networks are
running in the right way

362
00:18:42,840 --> 00:18:47,317
to tell if this device is
having the right parameters

363
00:18:48,620 --> 00:18:51,270
and things, or is there
anything changing here?

364
00:18:51,270 --> 00:18:56,010
So we do that through
a variety of mechanisms

365
00:18:56,010 --> 00:18:59,379
and this isn't a product pitch per se

366
00:18:59,380 --> 00:19:02,130
but I don't think that you can look

367
00:19:02,130 --> 00:19:05,860
at these environments
with one singular lens.

368
00:19:05,860 --> 00:19:08,979
I think you have to use
a whole suite of tools

369
00:19:08,980 --> 00:19:11,310
to be able to look at these devices

370
00:19:11,310 --> 00:19:14,653
and understand what's
going on in front of them.

371
00:19:15,550 --> 00:19:18,000
The first one I would say would be,

372
00:19:18,000 --> 00:19:21,330
you need to passively
monitor these networks

373
00:19:21,330 --> 00:19:25,300
to see what traffic is
going on and look at

374
00:19:26,320 --> 00:19:28,750
the changes that are
going on in the network.

375
00:19:28,750 --> 00:19:33,230
But we found that simply wasn't enough.

376
00:19:33,230 --> 00:19:37,080
You didn't get enough
information out of these devices.

377
00:19:37,080 --> 00:19:41,329
A lot of these devices are quiet.

378
00:19:41,329 --> 00:19:44,570
They're designed for low
bandwidth environments.

379
00:19:44,570 --> 00:19:48,229
And they're designed to
only speak when spoken to.

380
00:19:48,229 --> 00:19:51,480
Request response types of communications.

381
00:19:51,480 --> 00:19:56,480
So passive only detection
technology, doesn't really cut it.

382
00:19:57,150 --> 00:20:01,361
So within Tenable, we
develop the technology

383
00:20:01,361 --> 00:20:05,380
to look at these devices
from an active perspective.

384
00:20:05,380 --> 00:20:07,470
And a lot of people in the OT

385
00:20:07,470 --> 00:20:09,340
and industrial control system world

386
00:20:09,340 --> 00:20:12,149
get completely freaked out or scared

387
00:20:12,150 --> 00:20:14,830
when we say the word active.

388
00:20:14,830 --> 00:20:17,320
And I wanna make sure
that you understand that

389
00:20:17,320 --> 00:20:19,270
this is not active scanning.

390
00:20:19,270 --> 00:20:22,170
We're not going out with Nessus or Nmap

391
00:20:22,170 --> 00:20:25,170
and spraying the network with packets,

392
00:20:25,170 --> 00:20:26,650
and hammering these devices

393
00:20:26,650 --> 00:20:29,120
to try to figure out what they're doing.

394
00:20:29,120 --> 00:20:31,429
When we say active querying,

395
00:20:31,430 --> 00:20:36,430
what we mean is we are using
the OEM equipment vendors

396
00:20:37,200 --> 00:20:41,820
own protocols in a very
safe and reliable way

397
00:20:41,820 --> 00:20:45,280
to ask the device, what are you?

398
00:20:45,280 --> 00:20:46,740
What do you do?

399
00:20:46,740 --> 00:20:49,190
What firmware level are you at?

400
00:20:49,190 --> 00:20:52,800
What logic changes have been
made in the past 24 hours?

401
00:20:52,800 --> 00:20:56,290
Or can you provide me
with a copy of your logic?

402
00:20:56,290 --> 00:20:58,320
What position is the key

403
00:20:58,320 --> 00:21:02,340
on the front of your
programmable logic controller?

404
00:21:02,340 --> 00:21:04,629
Or is somebody allowed to make changes?

405
00:21:04,630 --> 00:21:07,440
Is it in program mode or is it in run mode

406
00:21:07,440 --> 00:21:10,173
where it's locked out where
no changes can be made?

407
00:21:11,220 --> 00:21:14,810
The vendors themselves have
used this method for decades?

408
00:21:14,810 --> 00:21:17,810
So this is how the vendor
actually makes the changes

409
00:21:17,810 --> 00:21:19,700
in the system itself.

410
00:21:19,700 --> 00:21:23,200
We're just replicating or
emulating that it's very safe.

411
00:21:23,200 --> 00:21:24,573
It's very reliable.

412
00:21:24,573 --> 00:21:28,460
And they gives us an incredible amount of

413
00:21:28,460 --> 00:21:30,953
device situational awareness,

414
00:21:30,953 --> 00:21:31,930
or an incredible amount of information

415
00:21:31,930 --> 00:21:34,713
about what is that device doing?

416
00:21:34,713 --> 00:21:36,720
How is it doing it?

417
00:21:36,720 --> 00:21:41,170
And can we monitor that for
any deviation or any problems?

418
00:21:41,170 --> 00:21:45,470
So that level of active device querying

419
00:21:45,470 --> 00:21:49,280
gives us that visibility
like the thermal imaging

420
00:21:49,280 --> 00:21:52,240
to see what's happening
inside that device.

421
00:21:52,240 --> 00:21:53,230
And you quite frankly

422
00:21:53,230 --> 00:21:56,570
you cannot get that through
passive means alone.

423
00:21:56,570 --> 00:21:58,500
So one of the biggest takeaways

424
00:21:58,500 --> 00:22:01,950
is I encourage you to
look into active querying.

425
00:22:01,950 --> 00:22:05,480
It's safe, it's reliable,
and it's well-trusted

426
00:22:05,480 --> 00:22:07,380
in a lot of our customer environments.

427
00:22:09,890 --> 00:22:12,290
So the next part that you get here.

428
00:22:12,290 --> 00:22:14,700
Is kind of like this lube oil thing

429
00:22:14,700 --> 00:22:17,570
where we test the lube oil for the machine

430
00:22:18,830 --> 00:22:21,970
and look at all the different parameters.

431
00:22:21,970 --> 00:22:25,380
If you have a complex operational
technology environment

432
00:22:25,380 --> 00:22:28,130
and industrial control system environment,

433
00:22:28,130 --> 00:22:33,130
I guarantee you that you have
alerts and data coming in

434
00:22:33,680 --> 00:22:35,320
just by the truckload.

435
00:22:35,320 --> 00:22:36,780
There's SIS log events

436
00:22:36,780 --> 00:22:38,920
There's detection events on the network.

437
00:22:38,920 --> 00:22:41,260
There's new devices being added.

438
00:22:41,260 --> 00:22:44,055
There's signatures that are tripping.

439
00:22:44,055 --> 00:22:46,809
You really need to take a look at

440
00:22:46,809 --> 00:22:51,809
the tuning and the fine tuning
of how to mine that data

441
00:22:52,156 --> 00:22:54,409
to get the benefit out of it.

442
00:22:54,410 --> 00:22:56,500
And here's where I'm
going to put in a pitch.

443
00:22:56,500 --> 00:22:59,340
Just like Tenable is a technology company,

444
00:22:59,340 --> 00:23:04,340
no questions about that,
but you need to have people,

445
00:23:04,670 --> 00:23:08,730
you need to have process and
you need to have technology.

446
00:23:08,730 --> 00:23:11,950
And I'll argue that you
need to have people first.

447
00:23:11,950 --> 00:23:14,030
You need to have the right people.

448
00:23:14,030 --> 00:23:17,210
They need to be the right
skill set of people.

449
00:23:17,210 --> 00:23:21,010
And you need to have the
right number of headcount,

450
00:23:21,010 --> 00:23:23,550
quite frankly, to manage the security

451
00:23:23,550 --> 00:23:26,082
in one of these operational
technology systems.

452
00:23:27,619 --> 00:23:30,669
And way too often I see control
system engineering people

453
00:23:30,670 --> 00:23:33,322
that are also saddled with security.

454
00:23:33,322 --> 00:23:35,520
And quite frankly, we
have to get beyond that

455
00:23:35,520 --> 00:23:36,360
as a community.

456
00:23:36,360 --> 00:23:37,800
And as an industry

457
00:23:37,800 --> 00:23:40,649
we need to be hiring the
right people to do the job.

458
00:23:40,650 --> 00:23:42,580
We need to have the
governance and the policy

459
00:23:42,580 --> 00:23:45,710
and the procedure in
place to tell those people

460
00:23:45,710 --> 00:23:48,180
and let them do their
jobs in the right way.

461
00:23:48,180 --> 00:23:50,880
Then we need the
technology to support that.

462
00:23:50,880 --> 00:23:52,210
So you need all three.

463
00:23:52,210 --> 00:23:54,900
You need people, process and technology.

464
00:23:54,900 --> 00:23:56,620
So once you have that all in place,

465
00:23:56,620 --> 00:24:00,379
you can really fine tune
the data you're looking for.

466
00:24:00,380 --> 00:24:03,340
And you can tell with a
high degree of accuracy

467
00:24:03,340 --> 00:24:07,169
what's going on in these networks
and how to flag any issues

468
00:24:07,170 --> 00:24:09,463
or anomalies that are better there.

469
00:24:10,610 --> 00:24:13,209
So we do that our product

470
00:24:13,210 --> 00:24:14,900
and other products are very similar.

471
00:24:14,900 --> 00:24:18,140
But we do that through
three primary mechanisms.

472
00:24:18,140 --> 00:24:22,300
So we do that where we're
passively ingesting the data

473
00:24:22,300 --> 00:24:23,590
on the network.

474
00:24:23,590 --> 00:24:25,740
We're running that
through a policy engine.

475
00:24:25,740 --> 00:24:28,300
So you state what's in and out of bounds.

476
00:24:28,300 --> 00:24:30,950
So I don't want to see anything like this.

477
00:24:30,950 --> 00:24:32,610
It's a black list.

478
00:24:32,610 --> 00:24:34,469
I only want to see things like this.

479
00:24:34,470 --> 00:24:37,890
You have a white list of traffic.

480
00:24:37,890 --> 00:24:40,680
And I've been told I need
to come up with better terms

481
00:24:40,680 --> 00:24:42,830
for a whitelist and blacklist.

482
00:24:42,830 --> 00:24:47,320
So I apologize there that
that's not a very proper way

483
00:24:47,320 --> 00:24:48,610
for me to explain that.

484
00:24:48,610 --> 00:24:51,840
Let's just say we have a list
of things that are allowed

485
00:24:51,840 --> 00:24:54,270
and we have a list of
things that aren't allowed.

486
00:24:54,270 --> 00:24:57,050
And you can flag against
that using policies.

487
00:24:57,050 --> 00:24:59,970
So a very powerful engine
to help you maintain

488
00:24:59,970 --> 00:25:02,130
that you're in compliance
with those policies

489
00:25:02,130 --> 00:25:03,370
and procedures.

490
00:25:03,370 --> 00:25:06,010
We also run that through
an anomaly based engine.

491
00:25:06,010 --> 00:25:10,270
So for example, we know all
of the protocols and ports

492
00:25:10,270 --> 00:25:12,400
and things that are
talking on your network.

493
00:25:12,400 --> 00:25:16,060
If we see a new protocol
or we see a new device

494
00:25:16,060 --> 00:25:19,570
or we see a device that should
be there, that drops off,

495
00:25:19,570 --> 00:25:21,110
we can give you an alert.

496
00:25:21,110 --> 00:25:24,169
So we can do some anomaly
detection on there.

497
00:25:24,170 --> 00:25:27,280
The last one is we do a
signature-based detection.

498
00:25:27,280 --> 00:25:30,940
So we run the network traffic

499
00:25:30,940 --> 00:25:35,940
through a known signature
method that we use right now.

500
00:25:35,960 --> 00:25:37,960
We happen to use Suricata.

501
00:25:37,960 --> 00:25:40,550
And so you can see known malware strains

502
00:25:40,550 --> 00:25:42,620
or known badness, known file hash.

503
00:25:42,620 --> 00:25:44,919
As if they're on your network,
we'll give you an alert.

504
00:25:44,920 --> 00:25:48,690
So very comprehensive analysis
of the passive traffic

505
00:25:48,690 --> 00:25:49,523
that's on there.

506
00:25:49,523 --> 00:25:52,810
And so that's kind of like
the lubrication oil analysis.

507
00:25:52,810 --> 00:25:56,070
We're looking at the network
traffic as it goes by.

508
00:25:56,070 --> 00:25:57,266
And if there's something that goes,

509
00:25:57,267 --> 00:25:59,120
"Oh, well this shouldn't be here."

510
00:25:59,120 --> 00:26:00,350
We should take a look at that.

511
00:26:00,350 --> 00:26:04,080
You need to fix this because
the oil is wearing out.

512
00:26:04,080 --> 00:26:05,669
The network is wearing out.

513
00:26:05,670 --> 00:26:07,440
The network has too much traffic,

514
00:26:07,440 --> 00:26:09,650
or there's another kind of a protocol

515
00:26:09,650 --> 00:26:11,040
that shouldn't be there.

516
00:26:11,040 --> 00:26:12,909
Somebody needs to take action.

517
00:26:12,910 --> 00:26:17,095
So you're doing that kind
of preventative maintenance

518
00:26:17,095 --> 00:26:18,543
in that way.

519
00:26:19,860 --> 00:26:22,800
One of the last things that
I think is really unique

520
00:26:22,800 --> 00:26:26,190
and I really like it because
I'm a control system engineer

521
00:26:26,190 --> 00:26:30,980
is because we're doing this
active device querying,

522
00:26:30,980 --> 00:26:33,670
we're able to take an extract,

523
00:26:33,670 --> 00:26:36,860
a copy of the configuration
from the controller.

524
00:26:36,860 --> 00:26:39,659
So the actual programmable
logic controller

525
00:26:39,660 --> 00:26:43,260
has ladder logic and it's
executing instructions.

526
00:26:43,260 --> 00:26:45,440
Well, what happens if
somebody changes that

527
00:26:45,440 --> 00:26:47,120
in the middle of the night?

528
00:26:47,120 --> 00:26:51,761
Was that an approved change
from an approved workstation

529
00:26:51,761 --> 00:26:55,290
by an electrician who perhaps
was executing the work order

530
00:26:55,290 --> 00:26:58,100
to change this rung of ladder logic?

531
00:26:58,100 --> 00:26:59,810
Well, you can look into that.

532
00:26:59,810 --> 00:27:04,063
Or was this a disgruntled
employee or malicious insider

533
00:27:04,064 --> 00:27:09,064
that was making a change
like planting a logic bomb

534
00:27:09,070 --> 00:27:10,100
or something like that?

535
00:27:10,100 --> 00:27:12,179
Well, you can check into that.

536
00:27:12,180 --> 00:27:15,210
Or was this malware on the network?

537
00:27:15,210 --> 00:27:17,840
So was there a laptop
that was on the network

538
00:27:17,840 --> 00:27:21,530
that the actual malware on
it was trying to make changes

539
00:27:21,530 --> 00:27:23,500
to the logic, think to try it and try.

540
00:27:23,500 --> 00:27:25,400
So this sort of situation.

541
00:27:25,400 --> 00:27:28,200
Was there actual changes
trying to be done to the logic?

542
00:27:29,410 --> 00:27:33,740
Well, what you can do is
you can take a snapshot

543
00:27:33,740 --> 00:27:37,530
of the running configuration
and then you can compare it

544
00:27:37,530 --> 00:27:39,720
to the previous or the gold image.

545
00:27:39,720 --> 00:27:43,600
You can compare it to the known
good running configuration.

546
00:27:43,600 --> 00:27:45,230
And this can really help you

547
00:27:45,230 --> 00:27:46,840
from a troubleshooting perspective.

548
00:27:46,840 --> 00:27:51,840
So this has a high amount
of value for the engineering

549
00:27:52,400 --> 00:27:54,090
and the production folks

550
00:27:54,090 --> 00:27:57,600
because this helps them
troubleshoot the running process.

551
00:27:57,600 --> 00:28:00,100
So this this is kind of
one of those features

552
00:28:00,100 --> 00:28:01,980
that it's a security feature

553
00:28:01,980 --> 00:28:04,254
but it's not a security feature.

554
00:28:04,254 --> 00:28:05,810
So you can use it to troubleshoot the plan

555
00:28:05,810 --> 00:28:08,760
to help you get back up
and running properly.

556
00:28:08,760 --> 00:28:11,250
Or you can use it as a forensics tool

557
00:28:11,250 --> 00:28:13,787
from a security perspective to go,

558
00:28:13,787 --> 00:28:16,420
"Oh there was these things
happening on the network

559
00:28:16,420 --> 00:28:18,330
and we saw these alarms."

560
00:28:18,330 --> 00:28:20,590
Were there any changes in the logic

561
00:28:20,590 --> 00:28:23,090
or any changes in the device configuration

562
00:28:23,090 --> 00:28:25,689
that were done at the same time.

563
00:28:25,690 --> 00:28:28,023
Hugely powerful forensics tool.

564
00:28:29,210 --> 00:28:33,410
So in a in summary, I guess
what I would like to say is,

565
00:28:33,410 --> 00:28:35,010
is what I've tried to do is,

566
00:28:35,010 --> 00:28:36,590
I've tried to correlate

567
00:28:36,590 --> 00:28:40,770
some fairly well-known
maintenance types of activities

568
00:28:40,770 --> 00:28:44,149
in the real sort of
factory or production world

569
00:28:44,149 --> 00:28:45,889
to things that you should be doing

570
00:28:45,890 --> 00:28:47,930
on the cybersecurity space.

571
00:28:47,930 --> 00:28:52,930
And I maintain that installing
your operational technology

572
00:28:53,720 --> 00:28:56,910
or installing your millions
and millions of dollars

573
00:28:56,910 --> 00:28:58,560
worth of control system equipment,

574
00:28:58,560 --> 00:29:00,010
and then kind of ignoring it

575
00:29:00,010 --> 00:29:03,290
and running it, driving
that car until it fails,

576
00:29:03,290 --> 00:29:06,050
and then calling the vendor
to come in and fix it,

577
00:29:06,050 --> 00:29:08,720
or calling the incident
response team to come in

578
00:29:08,720 --> 00:29:10,870
and try to figure it out,

579
00:29:10,870 --> 00:29:12,580
they got to reverse engineer everything

580
00:29:12,580 --> 00:29:14,600
and troubleshoot everything.

581
00:29:14,600 --> 00:29:16,369
That's not the right approach.

582
00:29:16,369 --> 00:29:18,870
Take a proactive approach.

583
00:29:18,870 --> 00:29:22,290
Look into proper asset inventories

584
00:29:22,290 --> 00:29:24,409
and asset management systems.

585
00:29:24,410 --> 00:29:27,840
Look into detection mechanisms
to see what's happening

586
00:29:27,840 --> 00:29:29,699
inside of these devices.

587
00:29:29,700 --> 00:29:31,670
And what's happening on your network.

588
00:29:31,670 --> 00:29:34,190
Get the right people in place to be able

589
00:29:34,190 --> 00:29:39,040
to look at these things
on a daily or weekly basis

590
00:29:39,040 --> 00:29:40,810
so that you can take action

591
00:29:40,810 --> 00:29:43,820
before you get to that incident response.

592
00:29:43,820 --> 00:29:45,550
And I guarantee you

593
00:29:45,550 --> 00:29:49,746
that it will cost you
much, much less over time.

594
00:29:49,747 --> 00:29:53,950
Get to that sweet spot on that curve.

595
00:29:53,950 --> 00:29:56,380
And once you get to that sweet spot,

596
00:29:56,380 --> 00:29:58,840
I think you'll be in a much better place.

597
00:29:58,840 --> 00:30:01,750
And hopefully you'll be
able to prevent things

598
00:30:01,750 --> 00:30:03,930
like ransomware or things like

599
00:30:03,930 --> 00:30:07,530
a commodity based malware
doing too much damage.

600
00:30:07,530 --> 00:30:09,629
I mean, you can't prevent everything.

601
00:30:09,630 --> 00:30:12,300
Something bad will happen eventually,

602
00:30:12,300 --> 00:30:13,760
but you're going to have the data

603
00:30:13,760 --> 00:30:15,080
to be able to troubleshoot it,

604
00:30:15,080 --> 00:30:18,860
get back to normal state
as soon as possible.

605
00:30:18,860 --> 00:30:21,580
And over time it will save you money.

606
00:30:21,580 --> 00:30:25,470
So I think that the most critical thing,

607
00:30:25,470 --> 00:30:28,360
and when I talked to chief
information security officers

608
00:30:28,360 --> 00:30:30,354
or I talked to security teams,

609
00:30:30,355 --> 00:30:33,257
they come to me and they go,

610
00:30:33,257 --> 00:30:35,909
"Marty, we have no idea what we have

611
00:30:35,909 --> 00:30:39,860
as far as inventory on the OT side.

612
00:30:39,860 --> 00:30:41,889
we know we've got all these devices.

613
00:30:41,890 --> 00:30:44,160
We know we've got all
these micro segmented

614
00:30:44,160 --> 00:30:47,750
or segmented or semi segmented
networks, but guess what?

615
00:30:47,750 --> 00:30:49,710
We also know, they're all converged.

616
00:30:49,710 --> 00:30:51,860
Everything's talking to everything.

617
00:30:51,860 --> 00:30:53,389
So we need visibility.

618
00:30:53,390 --> 00:30:56,070
We need to see into those systems.

619
00:30:56,070 --> 00:30:59,070
We need to see into the
protocols and sort of

620
00:30:59,070 --> 00:31:03,370
the purpose built esoteric
vendor specific protocols

621
00:31:03,370 --> 00:31:04,760
and implementations.

622
00:31:04,760 --> 00:31:06,920
So we need help there."

623
00:31:06,920 --> 00:31:11,130
And I guess, I maintain that
the best time to do that

624
00:31:11,130 --> 00:31:13,630
is before an incident occurs.

625
00:31:13,630 --> 00:31:17,270
Go in, properly instrument
these environments,

626
00:31:17,270 --> 00:31:18,820
get the data out,

627
00:31:18,820 --> 00:31:22,550
combine that data with the
data on your enterprise side.

628
00:31:22,550 --> 00:31:25,760
So it's of no use to see only the data

629
00:31:25,760 --> 00:31:28,040
that lives in your OT system,

630
00:31:28,040 --> 00:31:31,290
and only the data that lives
in your enterprise system.

631
00:31:31,290 --> 00:31:33,740
The chief information security officer

632
00:31:33,740 --> 00:31:37,149
who has to give that report
to the board of directors

633
00:31:37,149 --> 00:31:41,139
who have fiduciary
responsibility for the company,

634
00:31:41,140 --> 00:31:44,840
they need to evaluate risk
across all of those platforms.

635
00:31:44,840 --> 00:31:48,010
So pick a good partner,

636
00:31:48,010 --> 00:31:52,190
get the information that you
need and take action on it.

637
00:31:52,190 --> 00:31:55,310
Ask as many questions as
you want in the chat window.

638
00:31:55,310 --> 00:31:58,330
I hope this was a
valuable session for you.

639
00:31:58,330 --> 00:32:03,320
Again, my Twitter handle
is ICS underscore Marty.

640
00:32:03,320 --> 00:32:05,010
Look me up and be a follower

641
00:32:05,010 --> 00:32:07,160
and we'll have a great conversation.

642
00:32:07,160 --> 00:32:10,950
With that good luck with
the rest of your sessions.

643
00:32:10,950 --> 00:32:13,020
And I hope you enjoyed my session.

644
00:32:13,020 --> 00:32:14,017
Bye-bye for now.

