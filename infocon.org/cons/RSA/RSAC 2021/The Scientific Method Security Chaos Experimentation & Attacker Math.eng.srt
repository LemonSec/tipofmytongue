1
00:00:01,600 --> 00:00:03,120
- Thanks so much for having me here today

2
00:00:03,120 --> 00:00:05,689
and welcome to The Scientific Method,

3
00:00:05,690 --> 00:00:08,733
Security Chaos Experimentation
& Attacker Math.

4
00:00:09,670 --> 00:00:10,530
I'm Kelly Shortridge.

5
00:00:10,530 --> 00:00:13,590
You may know me for the
recent O'Reilly report

6
00:00:13,590 --> 00:00:15,210
on security chaos engineering,

7
00:00:15,210 --> 00:00:17,090
which you can download for free.

8
00:00:17,090 --> 00:00:19,270
You may also know me from my research

9
00:00:19,270 --> 00:00:22,860
into the intersection of
behavioral economics and infosec.

10
00:00:22,860 --> 00:00:25,200
I was most recently VP
of product management

11
00:00:25,200 --> 00:00:28,009
and product strategy at Capsule8,
which is a startup based

12
00:00:28,010 --> 00:00:30,260
in New York city,
providing Linux monitoring

13
00:00:30,260 --> 00:00:32,670
and detection board production systems.

14
00:00:32,670 --> 00:00:33,753
I'm actually going to be joining a super

15
00:00:33,753 --> 00:00:35,690
exciting Cloud competing company

16
00:00:35,690 --> 00:00:37,440
as a senior principal
product technologists

17
00:00:37,440 --> 00:00:39,253
this summer, stay tuned.

18
00:00:40,710 --> 00:00:41,543
Why are we here today?

19
00:00:41,543 --> 00:00:42,749
What's the problem?

20
00:00:42,749 --> 00:00:45,490
The problem is that information
security, as it's largely

21
00:00:45,490 --> 00:00:47,850
conducted today among
enterprise defenders,

22
00:00:47,850 --> 00:00:49,333
isn't actually a science.

23
00:00:50,580 --> 00:00:52,753
I would argue also as
an art, infosec is more

24
00:00:52,753 --> 00:00:55,153
finger painting than masterpiece to.

25
00:00:56,703 --> 00:00:58,410
Thing is we can't secure our systems

26
00:00:58,410 --> 00:01:00,029
with macaroni art, right?

27
00:01:00,030 --> 00:01:01,610
We need experiments.

28
00:01:01,610 --> 00:01:03,543
Ultimately we need science.

29
00:01:04,540 --> 00:01:07,330
So the question here today,
and what we'll be exploring

30
00:01:07,330 --> 00:01:11,023
is, how can we science our way
to better security outcomes?

31
00:01:12,810 --> 00:01:15,310
Today, we're gonna explore
one particularly promising way

32
00:01:15,310 --> 00:01:16,660
that I certainly spouse,

33
00:01:16,660 --> 00:01:20,372
which is decision trees and
security chaos engineering.

34
00:01:21,640 --> 00:01:24,020
So first we're gonna start
with security chaos engineering

35
00:01:24,020 --> 00:01:27,160
and how it blends and ties
into the scientific method.

36
00:01:27,160 --> 00:01:29,619
We're gonna walk through
a decision tree case study

37
00:01:29,620 --> 00:01:31,370
as we'll be building one ourselves.

38
00:01:31,370 --> 00:01:32,450
Finally, we're going to discuss

39
00:01:32,450 --> 00:01:34,313
how to make incidents boring.

40
00:01:35,740 --> 00:01:37,369
So let's get started.

41
00:01:37,370 --> 00:01:38,880
Let's talk about the scientific method

42
00:01:38,880 --> 00:01:41,729
and how security chaos
engineering actually harnesses it.

43
00:01:42,770 --> 00:01:44,550
First things first,
just how do you science

44
00:01:44,550 --> 00:01:45,600
in the first place?

45
00:01:45,600 --> 00:01:47,039
Use the scientific method,

46
00:01:47,040 --> 00:01:48,730
which you should think of
more of as a feedback loop

47
00:01:48,730 --> 00:01:51,683
rather than a finite sequence of steps.

48
00:01:52,660 --> 00:01:54,110
So to start your sciencing,

49
00:01:54,110 --> 00:01:56,218
you have to ask a question of reality.

50
00:01:56,218 --> 00:01:58,110
I think most of you are probably familiar

51
00:01:58,110 --> 00:02:01,520
with Isaac Newton and the whole
famed case with the apple.

52
00:02:01,520 --> 00:02:03,592
What he had as far as the question was

53
00:02:03,593 --> 00:02:05,700
why did this apple fall from the tree

54
00:02:05,700 --> 00:02:07,120
and bunk me on the head?

55
00:02:07,120 --> 00:02:09,150
Why did it fall vertically
downwards rather

56
00:02:09,150 --> 00:02:10,733
than upwards or sideways?

57
00:02:11,870 --> 00:02:14,060
Second step is a with
that question in mind

58
00:02:14,060 --> 00:02:15,980
you develop a hypothesis.

59
00:02:15,980 --> 00:02:18,790
A hypothesis is basically
a proposed explanation

60
00:02:18,790 --> 00:02:20,859
for the question that you had in mind.

61
00:02:20,860 --> 00:02:23,890
Which we use as a starting
point for investigation.

62
00:02:23,890 --> 00:02:26,070
So hypothesis this could
be there's some kind

63
00:02:26,070 --> 00:02:27,638
of invisible force pulling the apple

64
00:02:27,638 --> 00:02:30,583
and other falling objects
straight to the ground.

65
00:02:32,560 --> 00:02:34,670
The third step is we
pursue this investigation

66
00:02:34,670 --> 00:02:36,309
by conducting an experiment

67
00:02:36,310 --> 00:02:38,330
which allows us to make
observations that serve

68
00:02:38,330 --> 00:02:40,943
as evidence of our reality.

69
00:02:40,943 --> 00:02:42,960
In Newton's case with the apple

70
00:02:42,960 --> 00:02:45,650
his experiments required him
to actually invent calculus,

71
00:02:45,650 --> 00:02:47,720
which trust me you're
probably not gonna have to do

72
00:02:47,720 --> 00:02:50,100
with security chaos engineering.

73
00:02:50,100 --> 00:02:52,660
Step four is we then carefully
compare our observations

74
00:02:52,660 --> 00:02:53,850
from our experiments

75
00:02:53,850 --> 00:02:56,090
with the predictions from our hypothesis

76
00:02:56,090 --> 00:02:57,976
trying to stay as objective as possible.

77
00:02:57,976 --> 00:03:00,410
For instance could find
that a range of objects

78
00:03:00,410 --> 00:03:03,870
like a feather and apple, or
even like a sword indeed do end

79
00:03:03,870 --> 00:03:05,050
up falling straight to the ground.

80
00:03:05,050 --> 00:03:06,460
As in our hypothesis,

81
00:03:06,460 --> 00:03:09,645
then maybe we discovered that
they fall at different speeds.

82
00:03:09,645 --> 00:03:11,800
And finally you want
to report your findings

83
00:03:11,800 --> 00:03:13,040
and then iterate.

84
00:03:13,040 --> 00:03:15,739
So after this, analysis of our evidence

85
00:03:15,740 --> 00:03:17,890
we can report and document our findings

86
00:03:17,890 --> 00:03:21,390
and use them then to refine
our understanding of reality.

87
00:03:21,390 --> 00:03:23,489
Then we iterate by asking new questions

88
00:03:23,490 --> 00:03:26,580
that lead to new hypothesis
and new experiments.

89
00:03:26,580 --> 00:03:28,240
Isaac Newton actually did just this.

90
00:03:28,240 --> 00:03:29,840
It wasn't like a one-time thing

91
00:03:29,840 --> 00:03:31,510
and he discovered gravity, right?

92
00:03:31,510 --> 00:03:33,703
He refined his hypothesis
over and over and over

93
00:03:33,703 --> 00:03:35,940
until he derived a conclusion supported

94
00:03:35,940 --> 00:03:37,427
by this wealth of evidence.

95
00:03:37,427 --> 00:03:40,523
And that led to his
universal law of gravitation.

96
00:03:42,410 --> 00:03:44,520
So this process really
is rightfully revered

97
00:03:44,520 --> 00:03:47,520
across scientific disciplines,
because it keeps you honest

98
00:03:47,520 --> 00:03:48,510
and also in the mindset

99
00:03:48,510 --> 00:03:51,700
of continually revising
your knowledge of reality.

100
00:03:51,700 --> 00:03:53,732
We should probably be doing it too, right?

101
00:03:54,620 --> 00:03:57,020
And we should, so security
chaos engineering,

102
00:03:57,020 --> 00:03:59,713
which it's also referred to as SCE,

103
00:03:59,713 --> 00:04:02,156
applies the scientific method to infosec.

104
00:04:02,157 --> 00:04:05,813
That's a really kind of
TLDR way to think about it.

105
00:04:06,900 --> 00:04:09,400
Understanding how our systems are behaving

106
00:04:09,400 --> 00:04:11,280
drives good system security.

107
00:04:11,280 --> 00:04:14,250
And it's really difficult to
actually drive those outcomes

108
00:04:14,250 --> 00:04:15,673
without this understanding.

109
00:04:16,860 --> 00:04:19,180
Security chaos engineering
creates a learning culture

110
00:04:19,180 --> 00:04:21,370
with planned empirical experimentation.

111
00:04:21,370 --> 00:04:23,623
Just like really any
other type of science.

112
00:04:24,661 --> 00:04:27,210
One of the kind of like
uncomfortable truths

113
00:04:27,210 --> 00:04:29,169
for some people about
security chaos engineering

114
00:04:29,170 --> 00:04:31,900
is that you intentionally
introduce failure

115
00:04:31,900 --> 00:04:34,560
because it helps you
uncover the system reality.

116
00:04:34,560 --> 00:04:36,330
Failure feels scary for a lot of people

117
00:04:36,330 --> 00:04:37,240
but that's the only way

118
00:04:37,240 --> 00:04:39,263
you can uncover the truth ultimately.

119
00:04:40,510 --> 00:04:42,210
Of course, we're talking
about experiments already,

120
00:04:42,210 --> 00:04:46,210
but those come after hypothesis
is how do we develop those?

121
00:04:46,210 --> 00:04:47,349
We have to make assumptions

122
00:04:47,350 --> 00:04:49,400
about our reality to
inform our experiments.

123
00:04:49,400 --> 00:04:51,120
This case our security reality.

124
00:04:51,120 --> 00:04:54,090
And thinking about kind
of the infosec reality

125
00:04:54,090 --> 00:04:56,049
involves attackers and defenders.

126
00:04:56,050 --> 00:04:58,010
It's ultimately like a
conflict scenario drawing

127
00:04:58,010 --> 00:04:59,880
on game theory lingo.

128
00:04:59,880 --> 00:05:02,030
And in conflict scenarios
no matter the type

129
00:05:02,030 --> 00:05:04,280
we have to make assumptions
about our adversaries

130
00:05:04,280 --> 00:05:06,342
because they're a core
part of our reality.

131
00:05:07,888 --> 00:05:09,909
Turns out humans are pretty bad at this.

132
00:05:09,910 --> 00:05:11,130
We're pretty bad at understanding

133
00:05:11,130 --> 00:05:13,280
kind of like our opponents perspective.

134
00:05:13,280 --> 00:05:15,659
However, decision trees actually

135
00:05:15,660 --> 00:05:19,003
are kind of like novel device
studied in the behavioral game

136
00:05:19,003 --> 00:05:22,280
theory roles that help
humans improve assumptions.

137
00:05:22,280 --> 00:05:24,400
It what's known as belief prompting.

138
00:05:24,400 --> 00:05:25,760
Seeing some of my other talks,

139
00:05:25,760 --> 00:05:28,159
you're already familiar
with this but a belief,

140
00:05:28,160 --> 00:05:29,800
a prompting as a tactic from the realm

141
00:05:29,800 --> 00:05:33,050
of behavioral game theory,
to foster strategic thinking

142
00:05:33,050 --> 00:05:35,830
not kind of ad hoc, thinking
that we're used to an infosec,

143
00:05:35,830 --> 00:05:38,270
by encouraging people in any
sort of competitive setting

144
00:05:38,270 --> 00:05:40,419
including like attackers and defenders,

145
00:05:40,420 --> 00:05:43,717
to state their beliefs about
their opponents likely actions.

146
00:05:43,717 --> 00:05:45,570
And the experimental evidence from a bunch

147
00:05:45,570 --> 00:05:47,849
of different studies suggest
that by thinking about how

148
00:05:47,850 --> 00:05:49,680
your opponents will
respond to whatever move

149
00:05:49,680 --> 00:05:50,730
you're about to make,

150
00:05:50,730 --> 00:05:53,410
you're actually gonna make
a significantly savvy choice

151
00:05:53,410 --> 00:05:55,400
and more rational choice.

152
00:05:55,400 --> 00:05:57,049
Decision trees help you visualize

153
00:05:57,050 --> 00:05:59,320
and articulate exactly
this line of thinking.

154
00:05:59,320 --> 00:06:02,950
Their conflict, the visual
counterpart to believe bumping.

155
00:06:02,950 --> 00:06:06,260
In infosec decision trees help
us navigate attacker math.

156
00:06:06,261 --> 00:06:08,803
So let's attack them now,
just like any other project

157
00:06:08,803 --> 00:06:10,860
an attack campaign is expected to generate

158
00:06:10,860 --> 00:06:13,080
a positive return on investment.

159
00:06:13,080 --> 00:06:15,219
And this attacker ROI
is colloquially referred

160
00:06:15,220 --> 00:06:16,713
to as attacker math.

161
00:06:17,674 --> 00:06:19,849
So it's still venable spaciously stated

162
00:06:19,850 --> 00:06:21,409
all the way back in 2014,

163
00:06:21,409 --> 00:06:23,780
attackers have bosses and budgets too.

164
00:06:23,780 --> 00:06:26,659
A lot of times it is like
a nine to five sort of job

165
00:06:26,660 --> 00:06:27,910
for these people.

166
00:06:27,910 --> 00:06:29,880
So understanding the attacker math related

167
00:06:29,880 --> 00:06:31,880
to your individual systems and services

168
00:06:31,880 --> 00:06:34,456
is absolutely invaluable
in helping you prioritize

169
00:06:34,456 --> 00:06:36,920
what security controls
you need to implement

170
00:06:36,920 --> 00:06:39,210
and what your security
strategy ultimately should be

171
00:06:39,210 --> 00:06:40,159
in the first place.

172
00:06:41,080 --> 00:06:43,159
So in the context of
security chaos engineering,

173
00:06:43,160 --> 00:06:45,355
attacker math additionally
provides a blueprint

174
00:06:45,355 --> 00:06:46,780
for the types of experiments

175
00:06:46,780 --> 00:06:49,250
that we should be
conducting in our systems.

176
00:06:49,250 --> 00:06:51,780
So when you think through
kind of like the highest ROI

177
00:06:51,780 --> 00:06:53,119
options for the attacker,

178
00:06:53,120 --> 00:06:54,810
you're discovering which
actions they're more

179
00:06:54,810 --> 00:06:56,320
likely to take.

180
00:06:56,320 --> 00:06:57,740
And thus you eliminate the types

181
00:06:57,740 --> 00:06:59,987
of failure that you should
inject into your systems.

182
00:06:59,987 --> 00:07:02,663
These are the experiments
to test your hypothesis

183
00:07:02,663 --> 00:07:06,163
and test your assumptions
about your systems resilience.

184
00:07:07,310 --> 00:07:08,910
So what are we building towards?

185
00:07:08,910 --> 00:07:11,447
This is actually, an
example of a decision tree,

186
00:07:11,447 --> 00:07:13,308
that I have in a recent blog post

187
00:07:13,308 --> 00:07:14,800
about creating the with graphist

188
00:07:14,800 --> 00:07:16,520
which we're gonna use today.

189
00:07:16,520 --> 00:07:17,390
And it looks complicated

190
00:07:17,390 --> 00:07:20,890
but it's actually surprisingly
straightforward to build.

191
00:07:20,890 --> 00:07:21,820
This is another view of it.

192
00:07:21,820 --> 00:07:24,640
This is how it looks in the O'Reilly ebook

193
00:07:24,640 --> 00:07:26,740
on a security gas engineering.

194
00:07:26,740 --> 00:07:28,430
So ultimately there's flexibility

195
00:07:28,430 --> 00:07:29,970
in how you can make it look.

196
00:07:29,970 --> 00:07:32,590
We're gonna get there with
our own examples today.

197
00:07:32,590 --> 00:07:34,780
So let's get started, right?

198
00:07:34,780 --> 00:07:35,700
Let's build one together

199
00:07:35,700 --> 00:07:39,022
so we can understand how it
helps us generate hypothesis.

200
00:07:40,060 --> 00:07:44,253
So two, let's dig into this
case study on decision trees.

201
00:07:45,330 --> 00:07:47,320
So for our decision tree today our reality

202
00:07:47,320 --> 00:07:49,590
is that the attacker school
is running a crypto miner

203
00:07:49,590 --> 00:07:52,099
in one of our Cloud hosts containers.

204
00:07:52,100 --> 00:07:54,210
So I'm aware of the popular opinion

205
00:07:54,210 --> 00:07:56,330
is that crypto miners
are mostly a nuisance

206
00:07:56,330 --> 00:07:58,260
but honestly that's wrong.

207
00:07:58,260 --> 00:07:59,969
They reflect remote code execution

208
00:07:59,970 --> 00:08:01,750
in some of your production systems

209
00:08:01,750 --> 00:08:04,110
and they need to be taken
way, way, way more seriously.

210
00:08:04,110 --> 00:08:07,304
So, this really serves as
a fantastic example for us

211
00:08:07,304 --> 00:08:09,159
of a very serious attack goal

212
00:08:09,160 --> 00:08:11,870
with potentially high
impact in our systems.

213
00:08:11,870 --> 00:08:13,460
That's gonna be useful for us to explore

214
00:08:13,460 --> 00:08:15,243
and generate some hypothesis.

215
00:08:16,490 --> 00:08:18,740
So the first branch of your decision tree

216
00:08:18,740 --> 00:08:21,590
should really reflect the
lowest cost path for attackers.

217
00:08:21,590 --> 00:08:24,200
Like what's the easiest
thing for them to do.

218
00:08:24,200 --> 00:08:26,176
And I like to very
affectionately call this

219
00:08:26,176 --> 00:08:29,760
the yolosec branch, since it
usually involves the attacker

220
00:08:29,760 --> 00:08:32,220
taking advantage of some
sort of like lack of defense

221
00:08:32,220 --> 00:08:36,539
or some sort of like, careless
implementation of a system.

222
00:08:36,539 --> 00:08:38,699
Hence the yellow part.

223
00:08:38,700 --> 00:08:42,080
So skidiots it's is, one
of my friends calls them

224
00:08:42,080 --> 00:08:44,370
and professional attackers
alike will absolutely

225
00:08:44,370 --> 00:08:47,750
try something like showed in
or port scanning, if it works,

226
00:08:47,750 --> 00:08:51,570
I think, it's always about
working smarter, not harder so

227
00:08:51,570 --> 00:08:53,643
lazy can be actually super smart.

228
00:08:54,670 --> 00:08:56,150
So the yolosec action or really

229
00:08:56,150 --> 00:08:58,189
I guess it's technically inaction here

230
00:08:58,190 --> 00:09:01,690
is a leaving your Docker
socket publicly exposed.

231
00:09:01,690 --> 00:09:03,410
You kind of have to pay a certain sense

232
00:09:03,410 --> 00:09:05,069
like huffing glue for that to happen.

233
00:09:05,070 --> 00:09:09,470
But in a case that's
decidedly yolosec here.

234
00:09:09,470 --> 00:09:11,830
And another form of yolosec could actually

235
00:09:11,830 --> 00:09:13,440
be exposing your Kubernetes socket,

236
00:09:13,440 --> 00:09:15,270
that could also be discovered

237
00:09:15,270 --> 00:09:17,240
through chardan showed in report scanning,

238
00:09:17,240 --> 00:09:19,490
since an orchestrator is
actually very tempting way

239
00:09:19,490 --> 00:09:22,920
for attackers to access
the underlying host.

240
00:09:22,920 --> 00:09:24,839
We're not gonna cover the
orchestrator branch today

241
00:09:24,840 --> 00:09:27,903
for simplicity sake, keep that in mind.

242
00:09:28,930 --> 00:09:30,530
So, okay, we have yolosec,

243
00:09:30,530 --> 00:09:32,520
attackers are gonna
take advantage of that.

244
00:09:32,520 --> 00:09:35,360
So once they get access to the
host to be the docker socket,

245
00:09:35,360 --> 00:09:37,540
the easiest thing for them
to do to reach for goal

246
00:09:37,540 --> 00:09:40,416
is to schedule a container
that includes a crypto miner.

247
00:09:40,417 --> 00:09:43,280
I'd like to think of this
instead of like BYOB,

248
00:09:43,280 --> 00:09:47,040
it's bring your own container
sort of like hot option,

249
00:09:47,040 --> 00:09:49,959
for like brunch time for attackers, right?

250
00:09:49,960 --> 00:09:51,930
So we can see, we can build this first,

251
00:09:51,930 --> 00:09:54,719
very, very simplistic branch,
where we have reality.

252
00:09:54,720 --> 00:09:57,340
Then we have the attacker
using like shodan

253
00:09:57,340 --> 00:09:58,820
or port scanning tool.

254
00:09:58,820 --> 00:10:02,210
And then because we yolosec
rather than actually defended

255
00:10:02,210 --> 00:10:04,410
the attacker can find our publicly exposed

256
00:10:04,410 --> 00:10:06,319
Docker socket whoops.

257
00:10:06,320 --> 00:10:08,500
And then from there they can
schedule their own container

258
00:10:08,500 --> 00:10:11,730
and then run a crypto miner in
that Cloud hosted container.

259
00:10:11,730 --> 00:10:13,730
Then you attackers win.

260
00:10:13,730 --> 00:10:16,100
See here at differentiates
some of these with colors

261
00:10:16,100 --> 00:10:18,270
can you check out a blog post
from more about formatting

262
00:10:18,270 --> 00:10:20,170
this we're not gonna cover that today.

263
00:10:21,270 --> 00:10:23,290
The obvious mitigation here,
'cause now we need to think

264
00:10:23,290 --> 00:10:25,550
about like, okay, the
attacker's gonna do this.

265
00:10:25,550 --> 00:10:27,380
How do we respond right?

266
00:10:27,380 --> 00:10:29,860
So the obvious mitigation
is to not publicly

267
00:10:29,860 --> 00:10:33,470
expose the Docker Socket,
adding auth as another option.

268
00:10:33,470 --> 00:10:35,280
Won't cover that today.

269
00:10:35,280 --> 00:10:36,930
Unfortunately, what I've seen in practice

270
00:10:36,930 --> 00:10:38,459
is a lot of defenders kind of stop there

271
00:10:38,460 --> 00:10:39,293
with their thinking.

272
00:10:39,293 --> 00:10:41,950
They think like, yep, job, well done.

273
00:10:41,950 --> 00:10:43,800
But that's not how reality works.

274
00:10:43,800 --> 00:10:45,780
Attackers have a goal and
they're going to escalate

275
00:10:45,780 --> 00:10:47,490
their investment is necessary.

276
00:10:47,490 --> 00:10:50,450
Again, depending on kind of
the value of the goal to them.

277
00:10:50,450 --> 00:10:53,600
So, after each mitigation that you assume

278
00:10:53,600 --> 00:10:55,830
or you put in place,
you always need to think

279
00:10:55,830 --> 00:10:58,190
about and ask yourself and your team

280
00:10:58,190 --> 00:11:00,563
how is the attacker
going to respond to this?

281
00:11:01,427 --> 00:11:03,540
In this case, like if
we don't publicly expose

282
00:11:03,540 --> 00:11:05,439
the Docker socket the attack could respond

283
00:11:05,440 --> 00:11:06,990
to the few different ways.

284
00:11:06,990 --> 00:11:07,890
So obviously attempting

285
00:11:07,890 --> 00:11:09,910
that the attacker would
escalate to like throwing O'Day

286
00:11:09,910 --> 00:11:13,209
at us, but honestly that mostly
serves to flatter ourselves.

287
00:11:13,210 --> 00:11:17,520
And we're probably not that
important for the most part.

288
00:11:17,520 --> 00:11:20,210
Realistically though the
attacker will consider the next

289
00:11:20,210 --> 00:11:22,510
easiest or least expensive option.

290
00:11:22,510 --> 00:11:24,040
And in this case it's probably scanning

291
00:11:24,040 --> 00:11:27,829
for vulnerable web apps,
something like WordPress.

292
00:11:27,830 --> 00:11:29,860
So anticipating the attacker's response

293
00:11:29,860 --> 00:11:34,060
to our response response allows
us to preemptively respond.

294
00:11:34,060 --> 00:11:35,569
This is really the magic of belief

295
00:11:35,570 --> 00:11:39,940
prompting, character thinking
and action and decision trees.

296
00:11:39,940 --> 00:11:42,026
So we now have that first yolosec branch.

297
00:11:42,026 --> 00:11:44,640
That's a accompanied now
by the second branch.

298
00:11:44,640 --> 00:11:47,630
We have our first mitigation
not exposing the Docker sockets

299
00:11:47,630 --> 00:11:49,260
kind of the flow from there.

300
00:11:49,260 --> 00:11:51,430
So you can see we've
introduced this new sub path

301
00:11:51,430 --> 00:11:52,790
due to the mitigation.

302
00:11:52,790 --> 00:11:55,030
And because we anticipate
the attacker will scan

303
00:11:55,030 --> 00:11:58,069
for vulnerable web apps next,
we can perform phone scanning

304
00:11:58,070 --> 00:11:59,460
during software development.

305
00:11:59,460 --> 00:12:01,000
That's another mitigation.

306
00:12:01,000 --> 00:12:03,160
Of course, it's safe to
say that not all bugs

307
00:12:03,160 --> 00:12:05,510
will be caught before
software is deployed to prod.

308
00:12:05,510 --> 00:12:08,310
So a WAF can generally catch exploitation

309
00:12:08,310 --> 00:12:09,770
of known vulnerabilities.

310
00:12:09,770 --> 00:12:11,742
So we put that in this branch as well.

311
00:12:13,110 --> 00:12:15,770
Again, of course the
game doesn't end here.

312
00:12:15,770 --> 00:12:18,100
We have to consider how the
attacker is likely to respond

313
00:12:18,100 --> 00:12:19,440
to all of this too.

314
00:12:19,440 --> 00:12:22,760
Even when they encounter
a seeming dead end.

315
00:12:22,760 --> 00:12:24,569
In this case, they may switch tactics

316
00:12:24,570 --> 00:12:26,120
and venture onto a new branch

317
00:12:26,120 --> 00:12:29,433
like trying to find our Cloud
keys in public repositories.

318
00:12:30,560 --> 00:12:32,469
So to make things a little simpler

319
00:12:32,470 --> 00:12:33,690
you can see I've outlined here

320
00:12:33,690 --> 00:12:35,730
in this kind of like teal color.

321
00:12:35,730 --> 00:12:36,563
The third brain shows

322
00:12:36,563 --> 00:12:38,810
that the tackle would
likely scan our GitHub repos

323
00:12:38,810 --> 00:12:41,589
for AWS, GCP or Azure keys in response

324
00:12:41,590 --> 00:12:43,150
to our whack mitigation.

325
00:12:43,150 --> 00:12:45,150
We can actually indicate
that kind of relationship

326
00:12:45,150 --> 00:12:46,900
with a dotted blue line can see those

327
00:12:46,900 --> 00:12:50,500
from up to scanning the publicly exposed.

328
00:12:50,500 --> 00:12:53,050
That's a way to kind of
visually illustrate some

329
00:12:53,050 --> 00:12:54,599
of these flows.

330
00:12:54,600 --> 00:12:56,310
So once they get those
clem keys that allows them

331
00:12:56,310 --> 00:12:59,040
to authenticate into the
hosted container service

332
00:12:59,040 --> 00:13:00,699
which then lets them schedule a container

333
00:13:00,700 --> 00:13:03,050
with a crypto miner and win again

334
00:13:04,350 --> 00:13:07,500
so it's this assumption of our
adversaries behavior in hand,

335
00:13:07,500 --> 00:13:09,500
we can think of ways to
block off their moves

336
00:13:09,500 --> 00:13:12,560
and anticipate their
alternative tactics too.

337
00:13:12,560 --> 00:13:15,099
This case scanning our code
repos for things that look

338
00:13:15,100 --> 00:13:17,960
like keys ourselves, it's
really useful as of something

339
00:13:17,960 --> 00:13:21,820
like key rotation or IAM
roles that ensure that keys

340
00:13:21,820 --> 00:13:22,940
even if they're compromised,

341
00:13:22,940 --> 00:13:25,750
only allow for limited access is the whole

342
00:13:25,750 --> 00:13:27,410
least privilege thing
that we've talked about

343
00:13:27,410 --> 00:13:29,002
for like 20 or more years.

344
00:13:30,510 --> 00:13:33,110
Also, as I mentioned in
my a 2019 Blackhat talk

345
00:13:33,110 --> 00:13:36,060
with Dr. Nicole Forsgren,
billing alerts actually

346
00:13:36,060 --> 00:13:38,869
can be a surprising
source of security signal,

347
00:13:38,870 --> 00:13:41,040
that can actually help
tip us off to the fact

348
00:13:41,040 --> 00:13:43,020
that let's say an attacker
is scheduling a ton

349
00:13:43,020 --> 00:13:45,293
of their own containers via auto-scaling.

350
00:13:46,320 --> 00:13:49,210
So see, we are getting a
little more complex here.

351
00:13:49,210 --> 00:13:53,130
You can see in teal, this
new resulting flow in action.

352
00:13:53,130 --> 00:13:55,110
Can even make some lines to mitigations

353
00:13:55,110 --> 00:13:57,570
like here with key rotation dotted.

354
00:13:57,570 --> 00:13:59,620
If that's a mitigation
that you think would work

355
00:13:59,620 --> 00:14:01,250
but maybe you haven't implemented yet

356
00:14:01,250 --> 00:14:02,843
to be able to see your options.

357
00:14:03,800 --> 00:14:05,979
The beauty here is also thinking
through all the mitigations

358
00:14:05,980 --> 00:14:09,180
for particular attacker booth,
can actually help you kind of

359
00:14:09,180 --> 00:14:12,170
compare the costs relative
to what should be probably

360
00:14:12,170 --> 00:14:14,010
a very similar benefit.

361
00:14:14,010 --> 00:14:16,360
Of course, this kind of picture
we have here is actually

362
00:14:16,360 --> 00:14:18,720
assuming a pretty rosy view of reality

363
00:14:18,720 --> 00:14:21,070
in which our mitigation
work is anticipated.

364
00:14:21,070 --> 00:14:24,210
Which is frankly countered and
most complex system thinking

365
00:14:24,210 --> 00:14:26,880
which says that failure is inevitable.

366
00:14:26,880 --> 00:14:28,710
Realistically like an
attacker authenticating

367
00:14:28,710 --> 00:14:31,590
to the hosted container service
will actually want more bang

368
00:14:31,590 --> 00:14:34,823
for their buck, given all
the effort they've put in.

369
00:14:36,060 --> 00:14:37,729
So this is a really
important point when you're

370
00:14:37,730 --> 00:14:39,880
building your decision
trees, we have to think

371
00:14:39,880 --> 00:14:42,450
about what's going to allow
for greater ongoing value

372
00:14:42,450 --> 00:14:44,300
'cause that's how the
attacker is going to think.

373
00:14:44,300 --> 00:14:47,550
Not just short-term
realization of the goal too.

374
00:14:47,550 --> 00:14:50,689
Doesn't mean that attackers
are unlike a lot of humans

375
00:14:50,690 --> 00:14:52,710
and they can absolutely be myopic

376
00:14:52,710 --> 00:14:54,630
and kind of short-term oriented.

377
00:14:54,630 --> 00:14:57,911
But we need to think about all
of their potential options.

378
00:14:57,911 --> 00:15:00,079
In the case of a crypto
miner, the ideal scenario

379
00:15:00,080 --> 00:15:02,440
for the attackers, being
able to run the crypto miner

380
00:15:02,440 --> 00:15:06,560
basically 24/7 and persist
across restarts too.

381
00:15:06,560 --> 00:15:09,219
So even if you don't have
anything creative to do

382
00:15:09,220 --> 00:15:11,100
in infrastructure today as an attacker,

383
00:15:11,100 --> 00:15:12,640
there's actually a financial incentive

384
00:15:12,640 --> 00:15:14,640
to keep the command and control running.

385
00:15:15,870 --> 00:15:18,000
Generally attackers are
going to want to monetize

386
00:15:18,000 --> 00:15:19,980
their persistence not
just like leave it there,

387
00:15:19,980 --> 00:15:22,460
especially in cases where
an organized criminal group

388
00:15:22,460 --> 00:15:25,410
is frequently called upon
by their local nation state.

389
00:15:25,410 --> 00:15:27,339
Just like, hello, knock, knock,

390
00:15:27,340 --> 00:15:28,690
please hand over whatever access

391
00:15:28,690 --> 00:15:30,560
you have to a target organization.

392
00:15:30,560 --> 00:15:32,300
Otherwise we're gonna break your knees,

393
00:15:32,300 --> 00:15:33,790
something like that.

394
00:15:33,790 --> 00:15:37,400
So how can the attacker get
to these sorts of requirements

395
00:15:37,400 --> 00:15:38,250
and achieve them?

396
00:15:39,140 --> 00:15:41,660
Privileged container
is one potential answer

397
00:15:41,660 --> 00:15:43,199
for the attacker.

398
00:15:43,200 --> 00:15:44,820
Generally a regular container is trapped

399
00:15:44,820 --> 00:15:45,800
within resource limits.

400
00:15:45,800 --> 00:15:48,650
So of course the attacker
could escape resource limits

401
00:15:48,650 --> 00:15:50,220
through auto-scaling.

402
00:15:50,220 --> 00:15:51,646
Let's talk for another time.

403
00:15:51,646 --> 00:15:53,540
So today we're gonna think of it really

404
00:15:53,540 --> 00:15:56,500
as a privileged container
offers a few key benefits

405
00:15:56,500 --> 00:15:58,500
for attackers over the regular container.

406
00:15:58,500 --> 00:16:01,180
Specifically that they can
use the privilege capabilities

407
00:16:01,180 --> 00:16:03,439
to escape out of the container.

408
00:16:03,440 --> 00:16:06,430
This helps the attacker avoid
any container monitoring

409
00:16:06,430 --> 00:16:08,760
system and the risk of
the container being killed

410
00:16:08,760 --> 00:16:10,520
or restarted to.

411
00:16:10,520 --> 00:16:13,069
So if the attacker
needs to maintain access

412
00:16:13,070 --> 00:16:15,920
to the targeted organization for use later

413
00:16:15,920 --> 00:16:18,280
the privileged containers
helps the maintain the access

414
00:16:18,280 --> 00:16:20,560
And it can also actually serve as a canary

415
00:16:20,560 --> 00:16:22,670
for whether or not they
are being detected.

416
00:16:22,670 --> 00:16:24,150
And whether or not it's kind of this good

417
00:16:24,150 --> 00:16:25,453
like resting point.

418
00:16:26,570 --> 00:16:28,610
So once the attacker uses
the privileged containers

419
00:16:28,610 --> 00:16:30,530
to escape the host as you can see here

420
00:16:30,530 --> 00:16:31,870
getting outlined in teal,

421
00:16:31,870 --> 00:16:33,830
they can create a new system in daemon

422
00:16:33,830 --> 00:16:36,060
and asked system D to run the cyrptominer,

423
00:16:36,060 --> 00:16:38,162
again resulting in the win.

424
00:16:39,550 --> 00:16:41,199
Obviously that, we're
not gonna just roll over

425
00:16:41,200 --> 00:16:43,410
and play demo response, we're defenders,

426
00:16:43,410 --> 00:16:45,120
at least we're supposed to be.

427
00:16:45,120 --> 00:16:47,290
So we can implement something
like security policies

428
00:16:47,290 --> 00:16:49,892
your orchestrator, like
Kubernetes, that restricts

429
00:16:49,893 --> 00:16:52,895
the ability to run privilege containers.

430
00:16:52,895 --> 00:16:55,460
And that same 2019
Blackhat talk I mentioned,

431
00:16:55,460 --> 00:16:59,090
I referenced studios use DIE triad

432
00:16:59,090 --> 00:17:02,590
which includes amenability
actually is a security property.

433
00:17:02,590 --> 00:17:04,270
In this case, in a
mutable host, which means

434
00:17:04,270 --> 00:17:06,810
it can't be changed or
modified after it's deployed,

435
00:17:06,810 --> 00:17:09,050
means the attacker can't
actually write disk.

436
00:17:09,050 --> 00:17:11,050
So it counts as a mitigation.

437
00:17:11,050 --> 00:17:13,649
And the attack and the
activity that the attacker

438
00:17:13,650 --> 00:17:16,540
could perform on the host to abuse it,

439
00:17:16,540 --> 00:17:18,010
could actually be caught by some sort

440
00:17:18,010 --> 00:17:19,849
of host security monitoring tool.

441
00:17:19,849 --> 00:17:22,852
That's looking for something
like new files executed.

442
00:17:24,310 --> 00:17:26,780
So, okay we've implemented
those mitigations.

443
00:17:26,780 --> 00:17:29,410
And now the attacker's just
like super stressed out.

444
00:17:29,410 --> 00:17:30,770
They're on their like 12th matcha.

445
00:17:30,770 --> 00:17:31,603
They're trying to like power through this

446
00:17:31,603 --> 00:17:34,660
and you're really really
feeling bad vibes.

447
00:17:34,660 --> 00:17:36,040
We haven't made it easy for them.

448
00:17:36,040 --> 00:17:38,463
And that's precisely the point here.

449
00:17:39,770 --> 00:17:42,350
Of course again, they're
now super caffeinated

450
00:17:42,350 --> 00:17:44,429
and they're gonna think
like, what can we do to get

451
00:17:44,430 --> 00:17:47,970
around this final host
monitoring mitigation

452
00:17:47,970 --> 00:17:50,330
that we implemented as defenders?

453
00:17:50,330 --> 00:17:53,220
And requires more of an
investment, but as the attacker,

454
00:17:53,220 --> 00:17:54,830
they could deploy a fileless cryptominer

455
00:17:54,830 --> 00:17:56,653
that doesn't require disk access.

456
00:17:57,620 --> 00:18:00,550
This is certainly fancier,
but certainly in the realm

457
00:18:00,550 --> 00:18:02,639
of capability for like an
organized criminal group

458
00:18:02,640 --> 00:18:04,523
and definitely a nation state.

459
00:18:05,910 --> 00:18:08,580
This means they haven't made
it easiest easy for us either.

460
00:18:08,580 --> 00:18:11,300
We're also like just down
in coffees and matches.

461
00:18:11,300 --> 00:18:13,190
There's actually a very
clever mitigation here

462
00:18:13,190 --> 00:18:15,320
that we can borrow from SREs.

463
00:18:15,320 --> 00:18:17,860
Which is monitoring resource usage.

464
00:18:17,860 --> 00:18:20,270
This is also why I've been
proselytizing the importance

465
00:18:20,270 --> 00:18:22,840
of security teams caring
about availability

466
00:18:22,840 --> 00:18:24,110
more than they currently do.

467
00:18:24,110 --> 00:18:26,659
Remember it's part of
the original CIA triad

468
00:18:26,660 --> 00:18:30,680
since availability signals
actually are a really

469
00:18:30,680 --> 00:18:33,870
good indicator that something's
amiss security wise.

470
00:18:33,870 --> 00:18:35,120
They shouldn't just be considered

471
00:18:35,120 --> 00:18:37,673
like ops concerns or SRE concerns.

472
00:18:38,900 --> 00:18:40,690
So I've crop this so we
can take a closer look

473
00:18:40,690 --> 00:18:43,300
at this part of the tree
that we just flushed out.

474
00:18:43,300 --> 00:18:45,070
So we can see our new mitigations as far

475
00:18:45,070 --> 00:18:48,230
as looking at stability,
monitoring both host security

476
00:18:48,230 --> 00:18:51,110
and see the attacker
response with cryptominers.

477
00:18:51,110 --> 00:18:54,312
Then we show a resource usage monitoring.

478
00:18:55,180 --> 00:18:56,980
So again if we're seeing these flows

479
00:18:56,980 --> 00:18:59,550
of like we do something,
the attacker responds,

480
00:18:59,550 --> 00:19:00,653
we respond to that.

481
00:19:02,120 --> 00:19:05,090
Yay, we're in the attacker's
day, week, maybe even

482
00:19:05,090 --> 00:19:09,659
possibly a month, remember
attackers aren't automatons,

483
00:19:09,660 --> 00:19:11,430
they're humans that have emotions

484
00:19:11,430 --> 00:19:14,060
and egos too, definitely egos.

485
00:19:14,060 --> 00:19:15,570
So you can absolutely frustrate

486
00:19:15,570 --> 00:19:18,780
and disappoint them and
maybe even make them angry.

487
00:19:18,780 --> 00:19:20,450
Of course, anything emotion driven

488
00:19:20,450 --> 00:19:22,190
like they're not just gonna give up

489
00:19:22,190 --> 00:19:23,970
their ego's been bruised.

490
00:19:23,970 --> 00:19:25,273
It's not over yet.

491
00:19:26,640 --> 00:19:28,260
So this brings us in any decision tree

492
00:19:28,260 --> 00:19:30,260
to the creation of the hardest tech path.

493
00:19:30,260 --> 00:19:32,550
This is the one that
requires the most investment

494
00:19:32,550 --> 00:19:34,720
on the part of the attacker.

495
00:19:34,720 --> 00:19:37,100
Realistically, for most organizations

496
00:19:37,100 --> 00:19:40,209
this branch is largely going
to be out of their control.

497
00:19:40,210 --> 00:19:42,170
And until you've invested in mitigations

498
00:19:42,170 --> 00:19:45,070
for the easier branches
in your decision tree

499
00:19:45,070 --> 00:19:48,620
it's obviously like a huge,
just like colossal waste

500
00:19:48,620 --> 00:19:51,810
of time and budget to
implement mitigations for it.

501
00:19:51,810 --> 00:19:54,330
Even if it feels cool to do it right.

502
00:19:54,330 --> 00:19:58,490
I usually call this hardest
cost branch, the O'Day branch

503
00:19:58,490 --> 00:20:02,810
like they all the way down,
like O'Day chains Kobeck style.

504
00:20:02,810 --> 00:20:03,730
So it could include things

505
00:20:03,730 --> 00:20:05,800
like upstream backdoors
in your supply chain

506
00:20:05,800 --> 00:20:08,750
physically local sites,
attacks and data centers

507
00:20:08,750 --> 00:20:11,740
compromising AWS or GCPs
control plane and so forth.

508
00:20:11,740 --> 00:20:14,010
Again, these are very expensive attacks

509
00:20:14,010 --> 00:20:16,370
that are probably things
you just shouldn't worry

510
00:20:16,370 --> 00:20:19,830
about until you've covered
literally everything else.

511
00:20:19,830 --> 00:20:22,270
So in our case, attacker is out of blood,

512
00:20:22,270 --> 00:20:24,580
they want to own all of our Cloud now.

513
00:20:24,580 --> 00:20:26,689
So we need to really brainstorm.

514
00:20:26,690 --> 00:20:28,730
What's the most ruthless attack scenario

515
00:20:28,730 --> 00:20:32,463
that they'll come up with for
them to own all of our Cloud.

516
00:20:33,620 --> 00:20:37,780
Naturally, it's a maple syrup
heist paired with blackmail.

517
00:20:37,780 --> 00:20:40,280
Of course that's gonna be
the hardest cost branch.

518
00:20:41,480 --> 00:20:43,560
So step one, the attacker steals

519
00:20:43,560 --> 00:20:45,929
a least amount of maple syrup.

520
00:20:45,930 --> 00:20:48,120
I'll leave it to y'all to
decide whether that's Vermont

521
00:20:48,120 --> 00:20:51,060
or Canadian maple syrup, I'm
staying out of that beef.

522
00:20:51,060 --> 00:20:53,510
Step two attackers break into the house

523
00:20:53,510 --> 00:20:57,170
or vacation home of our organization, CFO.

524
00:20:57,170 --> 00:21:00,020
But wait, we do have a surprise
mitigation up our sleeves

525
00:21:00,020 --> 00:21:01,540
or out in the yard.

526
00:21:01,540 --> 00:21:04,500
CFO has a very good boy in their home.

527
00:21:04,500 --> 00:21:06,300
So the dog beautifully mitts a pleaser,

528
00:21:06,300 --> 00:21:08,120
a workbook sort of alerts.

529
00:21:08,120 --> 00:21:11,322
And that serves as a very fine
form of intrusion detection.

530
00:21:12,180 --> 00:21:15,490
But we're smart attackers,
we could anticipate this.

531
00:21:15,490 --> 00:21:17,660
Maybe we see through
reconnaissance that the seafoam

532
00:21:17,660 --> 00:21:20,790
maintains an instant page,
their dog, which is very cute

533
00:21:20,790 --> 00:21:23,700
but also has refueled
critical intelligence.

534
00:21:23,700 --> 00:21:25,700
So they bring a bone with
them to distract the dog.

535
00:21:25,700 --> 00:21:28,580
So it all mounds rather than pork forks.

536
00:21:28,580 --> 00:21:30,577
So step four, they plant the maple syrup

537
00:21:30,577 --> 00:21:33,070
and the CFO's basement,
which conveniently fits all

538
00:21:33,070 --> 00:21:35,230
of those barrels of maple syrup.

539
00:21:35,230 --> 00:21:37,910
Then finally with this
illicit contraband planted

540
00:21:37,910 --> 00:21:41,180
and CFOs property, attackers
can now blackmail the CFO

541
00:21:41,180 --> 00:21:43,370
into sharing the organization's
Cloud owner level

542
00:21:43,370 --> 00:21:44,919
credentials with them.

543
00:21:44,920 --> 00:21:48,290
So now the attackers can just
eat around the entire Cloud.

544
00:21:48,290 --> 00:21:49,610
So if they wanna run a cryptominer

545
00:21:49,610 --> 00:21:52,322
they can absolutely do so now.

546
00:21:53,850 --> 00:21:55,800
So again, we've now cropped it here

547
00:21:55,800 --> 00:21:58,500
to this kind of like teal section here.

548
00:21:58,500 --> 00:22:00,730
So just like some of the
fancier nation state attacks

549
00:22:00,730 --> 00:22:04,010
that capture our attention
and imagination, like c'mon,

550
00:22:04,010 --> 00:22:06,930
you would invest in mitigation
for this first, right?

551
00:22:06,930 --> 00:22:08,940
It's ridiculous, so keep that in mind,

552
00:22:08,940 --> 00:22:10,990
the next time you hear
about some vendor offering

553
00:22:10,990 --> 00:22:12,850
like niche protection against a risk

554
00:22:12,850 --> 00:22:15,010
that's largely out of your control.

555
00:22:15,010 --> 00:22:16,810
The fallacious feeling
of control isn't worth

556
00:22:16,810 --> 00:22:19,240
sacrificing your ability to raise the cost

557
00:22:19,240 --> 00:22:21,723
of attack on other branches, I promise.

558
00:22:22,970 --> 00:22:25,380
So now we can zoom out
to see our decision tree

559
00:22:25,380 --> 00:22:28,040
that we built today in full
and admire our hard work

560
00:22:28,040 --> 00:22:31,329
before moving on to the
next phase of sciencing.

561
00:22:31,329 --> 00:22:33,300
So can see this beautiful tree

562
00:22:33,300 --> 00:22:34,680
and it looks really complex.

563
00:22:34,680 --> 00:22:36,050
But when we broke it down into steps,

564
00:22:36,050 --> 00:22:37,760
you can see it's actually
really buildable,

565
00:22:37,760 --> 00:22:40,020
should build it collaboratively too.

566
00:22:40,020 --> 00:22:43,879
I also recommend not
having, your decision tree

567
00:22:43,880 --> 00:22:46,950
in PowerPoint like this,
put it as a PDF if you can.

568
00:22:46,950 --> 00:22:48,670
Talk about this again, relatively recently

569
00:22:48,670 --> 00:22:51,090
in a blog post, but it really
helps us navigate ability

570
00:22:51,090 --> 00:22:53,290
if you can like zoom in and pan around.

571
00:22:53,290 --> 00:22:55,510
But as you can see,
ultimately, we have this lovely

572
00:22:55,510 --> 00:22:57,730
visualization now that
documents our assumptions

573
00:22:57,730 --> 00:23:00,570
about likely attacker
actions and also how we

574
00:23:00,570 --> 00:23:02,293
can successfully respond to them.

575
00:23:03,560 --> 00:23:06,350
Yet a cryptominer it's just
one common attack goal.

576
00:23:06,350 --> 00:23:08,270
Should really create
decision trees for all goals

577
00:23:08,270 --> 00:23:10,590
attackers might have
against your organization.

578
00:23:10,590 --> 00:23:14,510
Even if a tax success would
need to, well only actually

579
00:23:14,510 --> 00:23:16,300
if attack success could lead to some sort

580
00:23:16,300 --> 00:23:19,253
of material erosion of
your organization's value.

581
00:23:20,160 --> 00:23:22,300
So a lot of people tend to ask me like

582
00:23:22,300 --> 00:23:23,930
how should we prioritize these trees?

583
00:23:23,930 --> 00:23:24,900
So this is an example

584
00:23:24,900 --> 00:23:29,080
prioritization matrix that's
from the O'Reilly SCE ebook

585
00:23:29,080 --> 00:23:31,840
and it's comparing attacker
value with organizational value.

586
00:23:31,840 --> 00:23:34,659
So for instance, a stackmoji
database doesn't matter

587
00:23:34,660 --> 00:23:36,630
to attackers and it doesn't matter to you.

588
00:23:36,630 --> 00:23:38,430
Don't create a decision tree for them.

589
00:23:38,430 --> 00:23:42,680
But a production revenue
generating service, yeah,

590
00:23:42,680 --> 00:23:44,580
that's gonna be really
important to the attacker

591
00:23:44,580 --> 00:23:46,159
and also would important to you.

592
00:23:46,160 --> 00:23:48,500
Same thing with just
general compute resources

593
00:23:48,500 --> 00:23:49,823
like in this case today.

594
00:23:51,410 --> 00:23:54,370
So now we can move on to using science

595
00:23:54,370 --> 00:23:56,750
to make incidents boring.

596
00:23:56,750 --> 00:23:58,360
Which I know you're
probably very skeptical

597
00:23:58,360 --> 00:23:59,622
at the moment about that.

598
00:24:01,410 --> 00:24:03,130
So remember our goal,

599
00:24:03,130 --> 00:24:05,320
like when we look at traditional security

600
00:24:05,320 --> 00:24:07,220
it's important to ask
ourselves the question

601
00:24:07,220 --> 00:24:08,680
like what if instead

602
00:24:08,680 --> 00:24:10,700
of like all this stuff
we're currently doing,

603
00:24:10,700 --> 00:24:13,520
we proactively and purposefully
initiated incidents

604
00:24:13,520 --> 00:24:16,120
expressly to learn about the impacts

605
00:24:16,120 --> 00:24:17,770
that they would have in our systems

606
00:24:17,770 --> 00:24:21,879
and design very like
graceful automated responses.

607
00:24:21,880 --> 00:24:23,730
We have to assume failure
and design the system

608
00:24:23,730 --> 00:24:26,003
to expect failure and
handle them gracefully.

609
00:24:27,210 --> 00:24:28,400
And we can do this

610
00:24:28,400 --> 00:24:31,670
with the power of science
specifically to scientific method.

611
00:24:31,670 --> 00:24:33,540
That's what SCE does.

612
00:24:33,540 --> 00:24:35,000
So now that we have our hypothesis

613
00:24:35,000 --> 00:24:36,810
from our decision tree we created

614
00:24:36,810 --> 00:24:39,163
we can now proceed to experimentation.

615
00:24:40,070 --> 00:24:42,300
So experimentation, really,
when you think about it

616
00:24:42,300 --> 00:24:44,409
like seeks to derive new insights

617
00:24:44,410 --> 00:24:46,500
and information that
was previously unknown

618
00:24:46,500 --> 00:24:48,280
about our reality.

619
00:24:48,280 --> 00:24:50,350
These insights really
complete that feedback loop

620
00:24:50,350 --> 00:24:52,469
we talked about with
the scientific method.

621
00:24:52,470 --> 00:24:54,190
And ultimately that is what drives

622
00:24:54,190 --> 00:24:56,880
scientific process progress.

623
00:24:56,880 --> 00:24:58,990
So also feedback loops
are really just essential

624
00:24:58,990 --> 00:25:02,090
for continual learning, which
is the only way as defenders.

625
00:25:02,090 --> 00:25:04,447
We can keep up with ever changing context.

626
00:25:04,448 --> 00:25:07,950
Constantly hear about like,
security is always evolving.

627
00:25:07,950 --> 00:25:09,643
Like this is how you keep up.

628
00:25:10,750 --> 00:25:13,000
So security chaos engineering
introduces security

629
00:25:13,000 --> 00:25:15,070
observability into your defensive program

630
00:25:15,070 --> 00:25:17,040
through this rigorous experimentation

631
00:25:17,040 --> 00:25:18,550
that helps eliminate the security

632
00:25:18,550 --> 00:25:21,342
of a system in reality,
not just in theory.

633
00:25:22,700 --> 00:25:25,640
So big question is how do
you conceptualize these

634
00:25:25,640 --> 00:25:27,910
security chaos experiments anyway?

635
00:25:27,910 --> 00:25:30,400
Where the useful template
for defining experiments is,

636
00:25:30,400 --> 00:25:32,240
in the event of a condition X,

637
00:25:32,240 --> 00:25:35,580
we are confident that the
system will respond with Y.

638
00:25:35,580 --> 00:25:36,560
So let's take a look at some

639
00:25:36,560 --> 00:25:39,600
of the ones that bubble up
from our decision tree today.

640
00:25:39,600 --> 00:25:41,490
So in the event of a
misconfigured Docker socket,

641
00:25:41,490 --> 00:25:44,585
we are confident, it will be
detected, logged and killed.

642
00:25:44,585 --> 00:25:47,270
You can see the case
study and the security

643
00:25:47,270 --> 00:25:50,220
chaos engineering ebook about
Kslinger to learn about how

644
00:25:50,220 --> 00:25:51,660
Aaron my co-author conducted

645
00:25:51,660 --> 00:25:53,530
a real security chaos experiments

646
00:25:53,530 --> 00:25:57,043
for misconfigured port,
excuse me misconfigured ports.

647
00:25:58,050 --> 00:25:59,450
Another one is in the event

648
00:25:59,450 --> 00:26:02,160
an attacker autoscales their
containers for your confidence.

649
00:26:02,160 --> 00:26:04,970
A billing alert will be generated.

650
00:26:04,970 --> 00:26:08,330
And as a final example, the
event that a cryptominer payload

651
00:26:08,330 --> 00:26:09,730
is downloaded onto a host,

652
00:26:09,730 --> 00:26:12,060
we are confident our
host security monitoring

653
00:26:12,060 --> 00:26:12,893
will detect it.

654
00:26:14,480 --> 00:26:19,103
So big caveat first is experiments
require careful planning.

655
00:26:19,103 --> 00:26:22,210
Aaron wrote a chapter on how
to properly conduct these kinds

656
00:26:22,210 --> 00:26:25,080
of experiments in the
ebook, so please read it.

657
00:26:25,080 --> 00:26:26,620
For the sake of time now we're gonna see

658
00:26:26,620 --> 00:26:27,580
that you're planning carefully

659
00:26:27,580 --> 00:26:29,996
and move on to the next step of sciencing.

660
00:26:30,930 --> 00:26:33,280
So step four, the scientific
method where we are now

661
00:26:33,280 --> 00:26:35,780
which is comparing our
observations to our predictions.

662
00:26:35,780 --> 00:26:38,420
Once we've conducted the experiments,

663
00:26:38,420 --> 00:26:40,310
a scientists which is what we are now

664
00:26:40,310 --> 00:26:41,940
using security chaos engineering.

665
00:26:41,940 --> 00:26:44,275
We have to analyze our results to validate

666
00:26:44,275 --> 00:26:47,010
and refine our hypothesis.

667
00:26:47,010 --> 00:26:48,220
In the case of decision trees

668
00:26:48,220 --> 00:26:49,480
you want to conduct experiments

669
00:26:49,480 --> 00:26:51,890
for each branch of the
decision tree, ideally

670
00:26:51,890 --> 00:26:54,650
against starting with more
of those low-hanging fruits.

671
00:26:54,650 --> 00:26:56,290
And then with this evidence in hand,

672
00:26:56,290 --> 00:26:57,409
you should validate each

673
00:26:57,410 --> 00:26:59,823
of the assumptions that
you had in the tree.

674
00:27:01,283 --> 00:27:03,040
One of the ways you can
do this is conducting

675
00:27:03,040 --> 00:27:04,720
a post-mortem to discuss what did

676
00:27:04,720 --> 00:27:06,600
or didn't work as intended.

677
00:27:06,600 --> 00:27:09,010
This is true for both the
attack and defense side.

678
00:27:09,010 --> 00:27:10,850
You want to examine the
experimental results

679
00:27:10,850 --> 00:27:11,980
from all facets

680
00:27:11,980 --> 00:27:15,340
in order to more deeply
understand your systems.

681
00:27:15,340 --> 00:27:18,360
Importantly, this post-mortem
has to be blameless.

682
00:27:18,360 --> 00:27:20,490
So finger pointing at
humans is the fastest way

683
00:27:20,490 --> 00:27:21,910
to kill a learning culture.

684
00:27:21,910 --> 00:27:24,010
So finger point at the
decision tree instead

685
00:27:24,010 --> 00:27:25,510
that's kind of why it's there.

686
00:27:26,610 --> 00:27:28,300
So this post-mortem is
really when you should be

687
00:27:28,300 --> 00:27:30,340
in this point of the kind
of scientific method.

688
00:27:30,340 --> 00:27:32,290
It's when you should be
asking a lot of questions

689
00:27:32,290 --> 00:27:34,600
like where were your hypothesis, correct?

690
00:27:34,600 --> 00:27:36,139
What did you overlook or miss?

691
00:27:36,140 --> 00:27:37,900
Like maybe one attack step required

692
00:27:37,900 --> 00:27:40,370
another step in order
to reach the attack goal

693
00:27:40,370 --> 00:27:42,110
maybe didn't anticipate that.

694
00:27:42,110 --> 00:27:43,810
Maybe the policy controls that you thought

695
00:27:43,810 --> 00:27:46,693
were being enforced actually
seemed to be taking a nap.

696
00:27:47,880 --> 00:27:50,380
Once you've analyzed your
experimental evidence

697
00:27:50,380 --> 00:27:52,330
it's time to document your findings

698
00:27:52,330 --> 00:27:53,830
and iterate on the experiment.

699
00:27:53,830 --> 00:27:57,330
And this is how you really
complete that feedback loop

700
00:27:57,330 --> 00:27:59,610
the report you're finding
it's really useful

701
00:27:59,610 --> 00:28:02,399
to update your decision
tree, ideally with versioning

702
00:28:02,400 --> 00:28:03,450
by incorporating all of your

703
00:28:03,450 --> 00:28:06,122
new found experimental evidence.

704
00:28:06,122 --> 00:28:08,194
Honestly like who likes
doing documentation.

705
00:28:08,194 --> 00:28:10,500
But it's super-duper essential

706
00:28:10,500 --> 00:28:12,154
to sustain a learning culture.

707
00:28:12,154 --> 00:28:14,820
Remember it scientific
progress just as a whole

708
00:28:14,820 --> 00:28:17,179
whether you're looking
at physics or chemistry,

709
00:28:17,180 --> 00:28:19,568
or like, the creation
of the recent vaccine

710
00:28:19,568 --> 00:28:23,180
like it's always a result of
building upon prior knowledge.

711
00:28:23,180 --> 00:28:25,970
So without those prior findings
being documented progress

712
00:28:25,970 --> 00:28:28,763
which has been much more
limited even in our world.

713
00:28:29,960 --> 00:28:31,950
So hopefully you get it now.

714
00:28:31,950 --> 00:28:34,000
So you've dutifully reported your findings

715
00:28:34,000 --> 00:28:36,390
and now we can iterate
on your experiments.

716
00:28:36,390 --> 00:28:38,240
The more you conduct your experiments

717
00:28:39,240 --> 00:28:41,790
that specifically reflecting
the potential security failures

718
00:28:41,790 --> 00:28:43,909
in your tree, the more
your teams can actually

719
00:28:43,910 --> 00:28:46,853
build new muscle memory for
responding to incidents.

720
00:28:47,700 --> 00:28:48,630
The repeated practice

721
00:28:48,630 --> 00:28:50,650
of these experiments can
make incidents actually

722
00:28:50,650 --> 00:28:53,210
feel boring instead of
scary and stressful.

723
00:28:53,210 --> 00:28:55,630
We all know how much like
burnout and stress plains

724
00:28:55,630 --> 00:28:58,610
our industry among incident responders.

725
00:28:58,610 --> 00:29:00,250
So the security chaos experimentation

726
00:29:00,250 --> 00:29:01,670
can transform incidents

727
00:29:01,670 --> 00:29:04,730
into problems with known
processes, for solving them.

728
00:29:04,730 --> 00:29:06,670
Which directly leads to faster

729
00:29:06,670 --> 00:29:08,593
and higher quality security outcomes.

730
00:29:09,810 --> 00:29:11,734
Defenders somewhat ironically
often feel insecure

731
00:29:11,734 --> 00:29:13,610
about their ability to handle incidents

732
00:29:13,610 --> 00:29:16,469
both in terms of human
and systems resilience.

733
00:29:16,470 --> 00:29:18,900
So they repeated experimentation
that's actually born

734
00:29:18,900 --> 00:29:20,510
from security chaos engineering,

735
00:29:20,510 --> 00:29:23,090
can help us grow confidence
in our systems resilience

736
00:29:23,090 --> 00:29:26,822
in the face of failure and
the resilience of our teams.

737
00:29:27,970 --> 00:29:29,872
This cruel collected confidence also comes

738
00:29:29,872 --> 00:29:33,314
from using our experimental
evidence to inform refinements

739
00:29:33,314 --> 00:29:35,070
in our system design.

740
00:29:35,070 --> 00:29:37,470
That's true, whether that's
architecture mitigations,

741
00:29:37,470 --> 00:29:40,070
processes, policies, and so forth.

742
00:29:40,070 --> 00:29:42,542
So if we continue using
decision trees is our blueprints

743
00:29:42,542 --> 00:29:44,860
for our hypothesis.

744
00:29:44,860 --> 00:29:47,330
We can continually
improve our systems safety

745
00:29:47,330 --> 00:29:49,210
instead of succumbing to cognitive bias.

746
00:29:49,210 --> 00:29:51,290
And this frenetic whack-a-mole tactic

747
00:29:51,290 --> 00:29:53,310
that we've been doing for decades,

748
00:29:53,310 --> 00:29:56,033
when designing our defensive strategy.

749
00:29:57,490 --> 00:30:01,223
So in conclusion on art science journey,

750
00:30:02,220 --> 00:30:04,850
scientific method is basically
just super duper legit.

751
00:30:04,850 --> 00:30:06,639
And security chaos engineering

752
00:30:06,640 --> 00:30:08,820
very eagerly copies its homework.

753
00:30:08,820 --> 00:30:10,950
After all the scientific
method has served us well

754
00:30:10,950 --> 00:30:13,570
for centuries and lent
us scientific discoveries

755
00:30:13,570 --> 00:30:16,429
beyond our wildest imaginations.

756
00:30:16,430 --> 00:30:19,570
Decision trees specifically
help us formulate hypotheses

757
00:30:19,570 --> 00:30:20,879
about our security reality

758
00:30:20,880 --> 00:30:23,540
and begin that invaluable feedback loop.

759
00:30:23,540 --> 00:30:25,960
So we saw in this case study,
it can serve as a blueprint

760
00:30:25,960 --> 00:30:28,473
for what types of experiments
we want to conduct.

761
00:30:29,500 --> 00:30:31,310
Security chaos engineering experiments,

762
00:30:31,310 --> 00:30:33,389
just like other forms of
scientific experiments,

763
00:30:33,390 --> 00:30:34,980
help us validate our hypothesis

764
00:30:34,980 --> 00:30:37,320
and uncover important truths.

765
00:30:37,320 --> 00:30:40,232
It helps us de bias our
understanding of our system safety

766
00:30:40,232 --> 00:30:42,280
and we can make decisions based

767
00:30:42,280 --> 00:30:44,983
on evidence rather than guesswork.

768
00:30:46,040 --> 00:30:46,940
So with these ingredients

769
00:30:46,940 --> 00:30:49,060
we can start to make incidents boring.

770
00:30:49,060 --> 00:30:51,230
And after enough practice
incidents can start to feel

771
00:30:51,230 --> 00:30:54,560
like live wild experimentation,
which is kind of cool,

772
00:30:54,560 --> 00:30:57,830
rather than these rare
confounding disasters.

773
00:30:57,830 --> 00:30:59,909
As far as how you can apply this knowledge

774
00:30:59,910 --> 00:31:01,374
to your jobs today, next week

775
00:31:01,374 --> 00:31:04,560
I want you to identify the
three most relevant tackles

776
00:31:04,560 --> 00:31:07,690
to your org using that
matrix for its attacker value

777
00:31:07,690 --> 00:31:10,270
and organizational value
for the next three months

778
00:31:10,270 --> 00:31:11,960
you should create a decision tree

779
00:31:11,960 --> 00:31:15,700
and collaboratively for each
of those three attack goals.

780
00:31:15,700 --> 00:31:18,530
The next six months, you
can choose a hypothesis

781
00:31:18,530 --> 00:31:20,820
and then plan and conduct
an experiment for it.

782
00:31:20,820 --> 00:31:23,053
Again, start small and grow from there.

783
00:31:24,280 --> 00:31:25,910
So this again was only a surface dive

784
00:31:25,910 --> 00:31:28,740
into some of this stuff around
security chaos engineering.

785
00:31:28,740 --> 00:31:30,220
So check out the O'Reilly report

786
00:31:30,220 --> 00:31:32,150
that I wrote with my
co-author, Aaron Reinhart,

787
00:31:32,150 --> 00:31:34,430
which is available for
the lovely price of free,

788
00:31:34,430 --> 00:31:36,590
what could be better than that.

789
00:31:36,590 --> 00:31:38,010
So with that thank you very much

790
00:31:38,010 --> 00:31:39,080
for your time and attention.

791
00:31:39,080 --> 00:31:41,592
And now go so some chaos.

