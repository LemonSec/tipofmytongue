1
00:00:00,560 --> 00:00:01,393
- Hi everyone.

2
00:00:01,393 --> 00:00:02,429
My name is Younghoo Lee.

3
00:00:02,430 --> 00:00:05,890
I'm a Senior Data Scientist at Sophos AI.

4
00:00:05,890 --> 00:00:08,780
In this talk, I will present how to create

5
00:00:08,780 --> 00:00:11,629
novel spam samples and
how to catching them

6
00:00:11,630 --> 00:00:14,023
with a text generating AI model.

7
00:00:16,020 --> 00:00:19,070
Let me start with simple questions.

8
00:00:19,070 --> 00:00:23,530
The first one is, we have
two spam messages here,

9
00:00:23,530 --> 00:00:25,230
which one is a spam?

10
00:00:25,230 --> 00:00:28,600
The first one, Santa calling and blah blah

11
00:00:28,600 --> 00:00:31,680
and call the number to book your time.

12
00:00:31,680 --> 00:00:34,310
Yeah, the first one is
obvious spam message.

13
00:00:34,310 --> 00:00:36,250
How about next one?

14
00:00:36,250 --> 00:00:38,720
A lot of this sickness and take it easy.

15
00:00:38,720 --> 00:00:39,820
Hope you feel better.

16
00:00:39,820 --> 00:00:42,363
Yeah, obviously it's not the spam.

17
00:00:43,830 --> 00:00:45,832
And the next one.

18
00:00:45,832 --> 00:00:47,630
Which one is spam?

19
00:00:47,630 --> 00:00:49,780
The first one, Santa calling.

20
00:00:49,780 --> 00:00:51,703
And something about premium service.

21
00:00:52,870 --> 00:00:55,683
And yeah, it's highly likely another spam.

22
00:00:55,683 --> 00:00:58,130
And how about the next one?

23
00:00:58,130 --> 00:01:02,390
Santa calling and something
about photo and cat.

24
00:01:02,390 --> 00:01:05,260
So probably, it's another spam message.

25
00:01:05,260 --> 00:01:07,580
So we can say the first
one is highly likely

26
00:01:07,580 --> 00:01:10,133
and the second one is less likely spam.

27
00:01:11,530 --> 00:01:13,900
Okay, let's move on to the final quiz.

28
00:01:14,840 --> 00:01:18,680
So which one is AI generated spam message?

29
00:01:18,680 --> 00:01:19,950
Can you guess?

30
00:01:19,950 --> 00:01:22,240
The first one and the second one,

31
00:01:22,240 --> 00:01:24,699
also has the same first five words

32
00:01:24,700 --> 00:01:27,683
but you can see these are different.

33
00:01:29,320 --> 00:01:33,770
So, actually, both of them
are generated by our AI model.

34
00:01:33,770 --> 00:01:37,553
We will talk about how we can
generate these spam messages.

35
00:01:40,260 --> 00:01:42,323
What is spam?

36
00:01:43,200 --> 00:01:46,600
Spam messages are irrelevant
or unsolicited messages

37
00:01:46,600 --> 00:01:51,282
sent over the internet to
a large number of users.

38
00:01:51,282 --> 00:01:55,490
Their main purpose are
advertising or phishing

39
00:01:55,490 --> 00:01:58,273
or spreading malware software.

40
00:02:00,650 --> 00:02:02,930
In spam ecosystem,
there are many different

41
00:02:04,458 --> 00:02:09,458
players but we are a detective today.

42
00:02:09,680 --> 00:02:13,010
We have a small training dataset.

43
00:02:13,010 --> 00:02:17,959
In our case, which we have
only a few hundred messages.

44
00:02:17,960 --> 00:02:19,820
That's our evidence.

45
00:02:19,820 --> 00:02:23,469
And our goal is to build a
strong machine learning model

46
00:02:23,469 --> 00:02:24,963
for spam detection.

47
00:02:24,963 --> 00:02:28,160
Also we want to generate new spam messages

48
00:02:28,160 --> 00:02:30,560
to augment the small dataset.

49
00:02:30,560 --> 00:02:33,210
So, finally, we are going to improve

50
00:02:33,210 --> 00:02:37,433
our model's performance
with the generated dataset.

51
00:02:41,080 --> 00:02:43,960
And the first step is we are going to

52
00:02:45,030 --> 00:02:47,063
train a spam detection model.

53
00:02:50,260 --> 00:02:52,750
There are several ways to achieve that.

54
00:02:52,750 --> 00:02:56,313
The simple approach is
signature-based one.

55
00:02:57,280 --> 00:03:01,951
The spam messages here, we
can add some text for example,

56
00:03:01,951 --> 00:03:06,951
Santa calling and then the
call number as one list.

57
00:03:07,460 --> 00:03:09,883
And also, another way is we can,

58
00:03:11,210 --> 00:03:14,080
edit the sender's number for example,

59
00:03:14,080 --> 00:03:16,490
sender's ID as one list.

60
00:03:16,490 --> 00:03:19,640
This way we can detect
exactly the same one.

61
00:03:19,640 --> 00:03:23,140
However, this method is not scalable.

62
00:03:23,140 --> 00:03:25,373
Or it will like detect new ones.

63
00:03:26,390 --> 00:03:30,313
So the next approach will be
a machine learning based one.

64
00:03:32,290 --> 00:03:36,840
Many machine learning models
need to convert the raw text

65
00:03:36,840 --> 00:03:39,160
into a numerical format.

66
00:03:39,160 --> 00:03:44,160
An open Term Frequency-IDF
is most susceptible for

67
00:03:44,850 --> 00:03:46,853
toys promotion learning features.

68
00:03:47,830 --> 00:03:51,540
The TFIDF can tell us
the how important a word

69
00:03:51,540 --> 00:03:55,150
is to a document, for
example Santa and calling,

70
00:03:55,150 --> 00:03:59,523
we can assign a specific
number for the text.

71
00:04:00,570 --> 00:04:04,870
We trained two ML models
with this features,

72
00:04:04,871 --> 00:04:07,940
Naive Bayes and Random Forest model

73
00:04:07,940 --> 00:04:10,523
trained with this features.

74
00:04:12,580 --> 00:04:14,917
And then also we can utilize the modern

75
00:04:14,917 --> 00:04:17,610
neural network approaches.

76
00:04:17,610 --> 00:04:19,608
Deep neural approach can use,

77
00:04:19,608 --> 00:04:23,804
the raw text as it is, so
we can consider the text

78
00:04:23,804 --> 00:04:27,320
a sequence of words, so Santa calling

79
00:04:27,320 --> 00:04:30,313
these are the input to the
features input to the models.

80
00:04:31,370 --> 00:04:33,700
And for example LSTM.

81
00:04:33,700 --> 00:04:35,729
Long Short-term Memory,

82
00:04:35,730 --> 00:04:40,310
can learn the temporal
relationship between tokens.

83
00:04:40,310 --> 00:04:44,540
And also we can use
Convolution Neural Network.

84
00:04:44,540 --> 00:04:45,983
Open CNN models.

85
00:04:46,851 --> 00:04:50,940
Are trained to recognize
images but also we can consider

86
00:04:50,940 --> 00:04:53,300
the text at the sequence 1D.

87
00:04:53,300 --> 00:04:56,480
One dimensional data.

88
00:04:56,480 --> 00:05:00,400
And also we can use the
same mechanism from the CNN.

89
00:05:00,400 --> 00:05:04,289
Finally, we can train a Transformer-based

90
00:05:04,290 --> 00:05:06,975
natural language training
processing models.

91
00:05:06,975 --> 00:05:11,080
These models are so
powerful and they learn,

92
00:05:11,080 --> 00:05:14,460
complicated attentional
weight between tokens.

93
00:05:14,460 --> 00:05:19,226
And GPT and BERT are the most successful

94
00:05:19,226 --> 00:05:22,030
the state-of-the-art of NLP models.

95
00:05:22,030 --> 00:05:23,929
Based on the transformer architecture.

96
00:05:27,570 --> 00:05:30,940
This table summarize
the previous approaches

97
00:05:30,940 --> 00:05:33,640
and it shows pros and cons.

98
00:05:33,640 --> 00:05:36,469
The simple signature is phase one.

99
00:05:36,470 --> 00:05:39,150
We only require small data for,

100
00:05:39,150 --> 00:05:43,169
the right signatures
however, their detection

101
00:05:43,169 --> 00:05:46,390
coverage is quite limited,
because this method

102
00:05:46,390 --> 00:05:49,200
only can detect exact matching ones.

103
00:05:49,200 --> 00:05:52,550
Also the signatures need
to be frequently re-written

104
00:05:52,550 --> 00:05:55,100
to detect new ones.

105
00:05:55,100 --> 00:05:58,080
And the second simple ML models,

106
00:05:58,080 --> 00:06:00,870
requires a large size dateset.

107
00:06:01,940 --> 00:06:05,310
Also this method can detect not just exact

108
00:06:05,310 --> 00:06:08,160
but similar ones can be
detected with this method,

109
00:06:08,160 --> 00:06:12,547
however, the training is
frequently required to detect

110
00:06:12,547 --> 00:06:13,480
the new ones.

111
00:06:13,480 --> 00:06:16,810
And finally, pre-trained
natural language models,

112
00:06:16,810 --> 00:06:20,280
for example GPT-2, only
requires small data

113
00:06:20,280 --> 00:06:23,844
for fine tuning and it can
detect on similar as well

114
00:06:23,845 --> 00:06:25,423
as unseen samples.

115
00:06:26,350 --> 00:06:29,010
So this method also
require the pre-training

116
00:06:29,010 --> 00:06:32,286
but pre-training is
required less frequently

117
00:06:32,286 --> 00:06:34,343
compared to other methods.

118
00:06:37,990 --> 00:06:42,990
We use GPT-2 as our text
generating AI model.

119
00:06:44,355 --> 00:06:47,860
So GPT-2 is one of the state-of-the-art

120
00:06:47,860 --> 00:06:50,920
Natural language processing models

121
00:06:50,920 --> 00:06:52,389
from open AI.

122
00:06:52,389 --> 00:06:56,610
It is Generative, which
means the model can generate

123
00:06:56,610 --> 00:07:01,300
coherent text from a short input text.

124
00:07:01,300 --> 00:07:03,550
Also it's a Pre-trained model.

125
00:07:03,550 --> 00:07:07,360
The model was pre-trained
to predict next word

126
00:07:07,360 --> 00:07:10,390
from a large scale dataset.

127
00:07:10,390 --> 00:07:13,270
The dataset was created from Wikipedea,

128
00:07:13,271 --> 00:07:17,640
or many different website,
also many different books.

129
00:07:17,640 --> 00:07:22,640
And the model use modern
Transformer-based architecture.

130
00:07:23,830 --> 00:07:25,520
This architecture brings

131
00:07:25,521 --> 00:07:29,293
attentional weight between tokens.

132
00:07:30,270 --> 00:07:33,060
This training process allows the model to,

133
00:07:33,060 --> 00:07:36,083
generate a long coherent text.

134
00:07:37,730 --> 00:07:41,572
The GPT has several different versions.

135
00:07:41,572 --> 00:07:45,663
The first, the GPT1 was released in 2018.

136
00:07:46,796 --> 00:07:50,650
And then next year, the next version GPT2,

137
00:07:50,650 --> 00:07:53,570
was released but the
next version, two version

138
00:07:53,570 --> 00:07:56,673
has 10 times large parameter size.

139
00:07:57,590 --> 00:08:02,590
And then GPT3, is the
latest version was released

140
00:08:02,632 --> 00:08:07,632
in 2020, but the model size was huge so,

141
00:08:08,110 --> 00:08:12,810
actually the model cannot be
loaded into a single machine

142
00:08:12,810 --> 00:08:17,810
but we can access the GTP3
from the Microsoft Cloud APIs.

143
00:08:20,060 --> 00:08:24,063
That's why we are going GPT2 for our work.

144
00:08:27,370 --> 00:08:32,347
Also the GPT2 has many
different sizes for example GPT2

145
00:08:33,470 --> 00:08:36,852
small has 12 transfer blocks.

146
00:08:36,852 --> 00:08:39,206
And the largest one,

147
00:08:39,206 --> 00:08:43,580
extra large has 48
transformer blocks in it.

148
00:08:43,580 --> 00:08:46,680
However we choose to use
the smallest one called

149
00:08:46,680 --> 00:08:51,520
DistilGPT2, which has only
six transformer blocks

150
00:08:51,520 --> 00:08:55,100
however we obtained very impressive result

151
00:08:55,100 --> 00:08:56,253
in our experiments.

152
00:09:01,460 --> 00:09:06,460
The next diagram shows
GPT's internal architecture.

153
00:09:07,680 --> 00:09:11,585
GPT2 has been trained
to predict next word,

154
00:09:11,586 --> 00:09:15,230
for example here the input text is,

155
00:09:15,230 --> 00:09:19,030
a robot must obey the orders given.

156
00:09:19,030 --> 00:09:20,220
That's the input.

157
00:09:20,220 --> 00:09:23,837
And the model was trained
to predict next word.

158
00:09:23,837 --> 00:09:26,430
The next word is it.

159
00:09:26,430 --> 00:09:31,132
So it is away GPT2 can
have a really to generate

160
00:09:31,132 --> 00:09:36,132
a long and coherent text.

161
00:09:39,590 --> 00:09:43,974
How we can convert the
text generating AI model

162
00:09:43,974 --> 00:09:47,630
to a classification model.

163
00:09:47,630 --> 00:09:50,833
GPT2 has emanated from headers.

164
00:09:51,830 --> 00:09:56,710
For natural language processing task,

165
00:09:56,710 --> 00:09:58,670
they use a language header,

166
00:09:58,670 --> 00:10:01,670
which has the number of vocabulary size

167
00:10:01,670 --> 00:10:04,930
as the output, so usually
the English model has

168
00:10:04,930 --> 00:10:07,420
about 30,000 outputs,

169
00:10:07,420 --> 00:10:10,709
as final layer.

170
00:10:10,710 --> 00:10:15,710
For example here, the final
layer will generate it

171
00:10:15,971 --> 00:10:20,500
as a 70%, so we can take
the it as a final output

172
00:10:20,500 --> 00:10:23,050
for this language header.

173
00:10:23,050 --> 00:10:25,219
For our classification problem,

174
00:10:25,220 --> 00:10:28,850
we remove the language header and we

175
00:10:28,850 --> 00:10:32,910
can insert a different
header classification header

176
00:10:32,910 --> 00:10:34,459
which will have two outputs,

177
00:10:34,460 --> 00:10:36,820
because we will whether,

178
00:10:36,820 --> 00:10:38,950
the input text is a spam or ham.

179
00:10:38,950 --> 00:10:43,340
For example, if the output spam is 95%,

180
00:10:43,340 --> 00:10:47,350
then we can take the text
as the ham messaging.

181
00:10:47,350 --> 00:10:52,210
This way we can train the
model as classification

182
00:10:52,210 --> 00:10:54,283
model also text erasing model.

183
00:10:59,313 --> 00:11:03,620
For our experiment we use a small dataset.

184
00:11:03,620 --> 00:11:08,600
Spam, SMS Spam dataset
from UCI ML Repository.

185
00:11:08,600 --> 00:11:13,600
The repository has about 5000 SMS samples,

186
00:11:13,900 --> 00:11:16,000
that we keep either the samples into three

187
00:11:16,000 --> 00:11:17,690
different datasets.

188
00:11:17,690 --> 00:11:20,640
The first set is Train_200.

189
00:11:20,640 --> 00:11:23,170
This one has only 200 examples

190
00:11:23,170 --> 00:11:26,150
and then we have 1000 training set,

191
00:11:26,150 --> 00:11:29,199
which has 1000 training data set.

192
00:11:29,200 --> 00:11:32,893
And we use the remaining
samples as our test dataset.

193
00:11:34,527 --> 00:11:38,397
For experiment we trained
five different ML models,

194
00:11:39,851 --> 00:11:41,936
for neural network models,

195
00:11:41,936 --> 00:11:45,673
we have GPT and CNN and LSTM models.

196
00:11:45,673 --> 00:11:48,980
Also we have two Conventional models,

197
00:11:48,980 --> 00:11:52,583
which include Random Forest
and Naive Bayes models.

198
00:11:57,470 --> 00:12:01,450
This diagram compares our GPT2 model with

199
00:12:02,600 --> 00:12:04,793
other four baseline models.

200
00:12:06,400 --> 00:12:11,130
The ROC curve shows the
X-axis as positive rate

201
00:12:11,130 --> 00:12:14,328
and Y as true positive rate.

202
00:12:14,328 --> 00:12:19,103
The figure A shows the result
when we trained the models

203
00:12:19,104 --> 00:12:21,760
with only 200 samples.

204
00:12:21,760 --> 00:12:26,760
The third one, blue one
is the GPT's arrow score.

205
00:12:26,910 --> 00:12:31,100
And the bottom green
one is LSTM arrow score.

206
00:12:31,100 --> 00:12:35,200
As you can see GPT2
have opened all baseline

207
00:12:35,200 --> 00:12:37,100
model significantly.

208
00:12:37,100 --> 00:12:41,900
Specifically the GPT
model achieve 90% through

209
00:12:41,900 --> 00:12:46,900
a positive rate at first
positive one in 100.

210
00:12:49,890 --> 00:12:54,657
The pink RV shows that,
performance when we train the

211
00:12:54,657 --> 00:12:57,780
automated data to be 100 samples.

212
00:12:57,780 --> 00:13:00,600
As you can see, we can see significant

213
00:13:00,600 --> 00:13:04,163
performance improvement
with large dataset size.

214
00:13:05,240 --> 00:13:09,810
However we can see that, still
the GPT achieved the best.

215
00:13:09,810 --> 00:13:12,839
And consistent result in both cases.

216
00:13:12,840 --> 00:13:14,983
Also interestingly the LSTM model,

217
00:13:16,913 --> 00:13:19,720
does not work with some more 200 samples,

218
00:13:19,720 --> 00:13:23,270
but we can see significant
performance improvement

219
00:13:23,270 --> 00:13:26,853
with 100 sample size.

220
00:13:29,690 --> 00:13:33,330
From the previous
experience, we noticed that

221
00:13:33,330 --> 00:13:38,050
the size of a training dataset matters.

222
00:13:38,050 --> 00:13:42,170
As we can have more data, we
can improve the proper ones.

223
00:13:42,170 --> 00:13:44,780
Specifically Deep neural
networks are hungry

224
00:13:44,780 --> 00:13:46,213
for a large dataset.

225
00:13:47,380 --> 00:13:49,580
Training deep neural network however,

226
00:13:49,580 --> 00:13:53,100
with small data does not
always guarantee better result

227
00:13:53,100 --> 00:13:54,257
as you can see.

228
00:13:54,257 --> 00:13:58,660
The LSTM was opened by
conventional numbers

229
00:13:58,660 --> 00:14:01,928
when the training dataset is quite small.

230
00:14:01,928 --> 00:14:05,120
Also we noticed that,
the pre-trained model

231
00:14:05,120 --> 00:14:08,760
and then fine training the
model with some more data

232
00:14:08,760 --> 00:14:11,020
apart from the baseline model.

233
00:14:11,020 --> 00:14:16,020
So GPT2 is a quite strong
model for our experiment.

234
00:14:20,350 --> 00:14:23,980
We know that the data size is important,

235
00:14:23,980 --> 00:14:28,433
however the cost of data
labeling is very expensive.

236
00:14:29,530 --> 00:14:32,870
Your data science and engineering team

237
00:14:32,870 --> 00:14:34,770
are not cheap at all,

238
00:14:34,770 --> 00:14:37,960
if you wanted to do
data labeling manually,

239
00:14:37,960 --> 00:14:41,880
probably 80% or what your
valuable time will be spent

240
00:14:41,880 --> 00:14:44,893
in data cleaning and manual labeling.

241
00:14:45,940 --> 00:14:50,210
Also you can't guarantee the data quality

242
00:14:50,210 --> 00:14:53,120
even with the manual work.

243
00:14:53,120 --> 00:14:55,480
So comes in, comes out.

244
00:14:55,480 --> 00:14:59,283
A model is a good as the
data used to build the model.

245
00:15:01,893 --> 00:15:06,893
Alternatively we can use,
crowdsourcing or outsourcing,

246
00:15:07,140 --> 00:15:09,210
for the data labeling.

247
00:15:09,210 --> 00:15:12,193
However, this method is also expensive.

248
00:15:13,220 --> 00:15:15,450
So high quality data augmentation

249
00:15:15,450 --> 00:15:18,263
is the key to success any ML project.

250
00:15:22,110 --> 00:15:26,223
The next section is how
to generate new spams.

251
00:15:30,040 --> 00:15:34,233
There are several ways to
enlarge your training dataset.

252
00:15:35,850 --> 00:15:37,220
There are simple approaches,

253
00:15:37,220 --> 00:15:41,260
for example we can replace
words with synonyms

254
00:15:41,260 --> 00:15:46,260
also we can insert or remove
random words in text data,

255
00:15:46,570 --> 00:15:49,689
however, this method has
limitations to generate

256
00:15:49,689 --> 00:15:53,079
a variety of high quality samples,

257
00:15:53,080 --> 00:15:56,927
open the synonym in one
sentence doesn't allow work

258
00:15:56,927 --> 00:15:59,440
in another sentence.

259
00:15:59,440 --> 00:16:02,493
Another approach is to utilize modern,

260
00:16:03,530 --> 00:16:05,620
generative language models.

261
00:16:05,620 --> 00:16:10,620
For example GPT can generate
wrong coherent text data,

262
00:16:10,900 --> 00:16:14,374
however we don't have
the control to the style

263
00:16:14,374 --> 00:16:17,307
or contents of the GPT's offer.

264
00:16:22,339 --> 00:16:25,750
To tackle those technical problems,

265
00:16:25,750 --> 00:16:30,283
researchers introduced controlled
text generation message.

266
00:16:31,281 --> 00:16:36,281
PPLM, plug and play language
mode is one of them.

267
00:16:36,670 --> 00:16:40,520
This approach train to
learn a classification model

268
00:16:40,520 --> 00:16:45,410
which can control the style
or contents of the output.

269
00:16:45,410 --> 00:16:48,540
And then we can update the final output,

270
00:16:48,540 --> 00:16:49,620
with this model.

271
00:16:49,620 --> 00:16:54,170
So our implementation is
based on PPLM approach.

272
00:16:54,170 --> 00:16:57,650
And there is another called control.

273
00:16:57,650 --> 00:17:02,650
This approach train to
condition on a control code

274
00:17:02,728 --> 00:17:04,879
that govern the style of the content.

275
00:17:04,880 --> 00:17:08,363
For example to control,
we can use always the best

276
00:17:08,363 --> 00:17:12,771
big copy words for example
with two generators

277
00:17:12,771 --> 00:17:16,247
supposed to create it
text we can always use,

278
00:17:16,247 --> 00:17:19,413
some supposed created words.

279
00:17:24,130 --> 00:17:28,183
This figure shows the
PPLM high level over view.

280
00:17:29,050 --> 00:17:33,730
PPLM use GPT-2 x is internal

281
00:17:33,730 --> 00:17:36,183
text generating AI model.

282
00:17:37,210 --> 00:17:40,463
But it also train a small attribute model.

283
00:17:41,640 --> 00:17:46,640
The attribute model, can
drive the description of text

284
00:17:46,733 --> 00:17:50,500
related power to the desired direction.

285
00:17:50,500 --> 00:17:51,333
For example,

286
00:17:53,940 --> 00:17:56,410
we can apply the activity model to

287
00:17:56,410 --> 00:17:59,000
predict the input text.

288
00:17:59,000 --> 00:18:02,720
Input is the spam one not then
we can change the direction

289
00:18:02,720 --> 00:18:05,773
to change desired spam message.

290
00:18:08,880 --> 00:18:12,523
PPLM has three steps in training.

291
00:18:13,460 --> 00:18:16,160
This diagram shows each step.

292
00:18:16,160 --> 00:18:20,640
For example here, the
input data is the chicken

293
00:18:21,480 --> 00:18:26,080
taste and we are going to
generate the next word.

294
00:18:26,080 --> 00:18:30,187
In step one, the pod pass
will learn the original GPT-2

295
00:18:34,140 --> 00:18:36,830
and the output is okay, this case.

296
00:18:36,830 --> 00:18:39,230
So the chicken taste okay,

297
00:18:39,230 --> 00:18:43,250
however our attribute model can give us

298
00:18:43,250 --> 00:18:47,310
signal whether the input
really positive one output,

299
00:18:47,310 --> 00:18:50,120
because the model has
been trained to give us

300
00:18:50,120 --> 00:18:52,689
whether the input is positive one.

301
00:18:52,690 --> 00:18:56,620
However okay is not a positive so we can,

302
00:18:56,620 --> 00:19:01,310
change the direction
slightly towards delicious.

303
00:19:01,310 --> 00:19:05,790
So finally we can get the
delicious as our final output.

304
00:19:05,790 --> 00:19:08,853
So the final text will
be the chicken taste,

305
00:19:11,090 --> 00:19:13,102
delicious instead of okay.

306
00:19:15,620 --> 00:19:17,683
Also we can see the same,

307
00:19:18,657 --> 00:19:22,939
the direction from the optimization steps.

308
00:19:22,940 --> 00:19:27,090
For example the chicken
taste, the top left top

309
00:19:27,090 --> 00:19:32,090
is the current point and we
are going to move the direction

310
00:19:32,410 --> 00:19:37,410
toward to improved probability
of the attribute model

311
00:19:37,723 --> 00:19:40,553
as well the length model.

312
00:19:40,553 --> 00:19:45,553
So actually we move to the right and up

313
00:19:46,550 --> 00:19:51,533
so we will get delicious as
a final word instead of okay.

314
00:19:56,670 --> 00:20:00,370
For spam generation task, we use the same

315
00:20:01,350 --> 00:20:03,030
SMS spam data.

316
00:20:03,030 --> 00:20:06,720
We have 200 training dataset.

317
00:20:06,720 --> 00:20:11,430
And we the same 3000
samples as our test data.

318
00:20:13,660 --> 00:20:18,490
We are going to generate
1000 samples out of 200

319
00:20:18,490 --> 00:20:21,850
so our approach is to generate 5 samples

320
00:20:21,850 --> 00:20:23,453
from each training center.

321
00:20:25,030 --> 00:20:29,440
But we also needed to use
some of the tokens as input

322
00:20:29,440 --> 00:20:32,580
to generate melogont text.

323
00:20:32,580 --> 00:20:37,580
So we use the first five
words that input text.

324
00:20:37,960 --> 00:20:41,430
And also we assign the same label as input

325
00:20:41,430 --> 00:20:43,310
to the attribute model.

326
00:20:43,310 --> 00:20:45,673
For example we generate this spam,

327
00:20:46,660 --> 00:20:50,630
data from the spam also we generate ham,

328
00:20:50,630 --> 00:20:53,313
from the ham messages.

329
00:20:57,690 --> 00:21:00,900
Let's have a look at some of the examples,

330
00:21:00,900 --> 00:21:03,393
generated by the PPLM model.

331
00:21:04,566 --> 00:21:07,759
Guess one which generate spam samples,

332
00:21:07,759 --> 00:21:09,950
from the original spam.

333
00:21:09,950 --> 00:21:12,530
The original spam is the top one.

334
00:21:12,530 --> 00:21:16,100
And each one has the first words are same.

335
00:21:16,100 --> 00:21:18,310
Santa calling, would your little one.

336
00:21:18,310 --> 00:21:22,389
And as you can see spam
one, you can see some

337
00:21:22,389 --> 00:21:25,157
the premium of the one.

338
00:21:25,157 --> 00:21:26,783
Christmas obviously, a
spam message and also

339
00:21:30,300 --> 00:21:31,570
the second one,

340
00:21:31,570 --> 00:21:35,188
so it's about another payment service,

341
00:21:35,189 --> 00:21:40,047
so the model generated,

342
00:21:40,047 --> 00:21:43,223
generated spam message
all over the original one.

343
00:21:46,810 --> 00:21:50,659
Next we will see whether
we can generate ham samples

344
00:21:50,660 --> 00:21:53,833
from the same spam.

345
00:21:54,987 --> 00:21:56,800
To generate ham one.

346
00:21:56,800 --> 00:22:00,004
Let's look Santa calling, but this case,

347
00:22:00,005 --> 00:22:02,563
doesn't know about advertisement.

348
00:22:03,880 --> 00:22:08,230
Something interesting
text and spam too also.

349
00:22:08,230 --> 00:22:12,500
It's about photo and
the cat so we can say,

350
00:22:12,500 --> 00:22:15,810
it's not actually it
is spam but less likely

351
00:22:16,660 --> 00:22:21,660
yeah spam, we can call it
this or another ham message

352
00:22:21,910 --> 00:22:24,140
from the original one.

353
00:22:25,882 --> 00:22:30,882
Also we can analyze our GPT
models internal representation

354
00:22:32,720 --> 00:22:36,180
using a LIME analysis.

355
00:22:36,180 --> 00:22:39,700
LIME is a Local Interpret
Model-Agnostic Explanation

356
00:22:39,700 --> 00:22:44,280
method which can tell us
which tokens are highlighted

357
00:22:44,280 --> 00:22:48,553
in the GPT-2 representation, for example,

358
00:22:51,060 --> 00:22:54,113
the A generated spam message,

359
00:22:55,770 --> 00:23:00,150
the text in orange shows suspicious tokens

360
00:23:00,150 --> 00:23:04,123
and text in blue is non suspicious tokens.

361
00:23:05,380 --> 00:23:08,770
The PPLM shows the
highlighted tokens for example

362
00:23:08,770 --> 00:23:13,770
premium, online, one remembers
something about premium

363
00:23:14,330 --> 00:23:19,330
service and the second generated ham,

364
00:23:19,480 --> 00:23:24,153
we don't see highlighted tokens here.

365
00:23:26,380 --> 00:23:30,271
Okay let's have a look at
some of the different samples

366
00:23:30,271 --> 00:23:33,710
ham samples from the ham.

367
00:23:33,710 --> 00:23:36,680
So from the original ham message,

368
00:23:36,680 --> 00:23:41,680
we generated two new ham, samples here.

369
00:23:42,750 --> 00:23:47,750
So ham one, yeah it's about eating avocado

370
00:23:47,800 --> 00:23:51,746
and the second one is
about eating vegetable

371
00:23:51,747 --> 00:23:55,620
so we can say it's not spam
but something interesting

372
00:23:55,620 --> 00:23:58,433
copy about yeah sickness.

373
00:24:01,080 --> 00:24:05,159
And then, we will see whether
we can turn the original

374
00:24:05,160 --> 00:24:07,253
ham into spam messages.

375
00:24:08,400 --> 00:24:12,760
The spam one, has about
phone date service.

376
00:24:12,760 --> 00:24:16,720
It's something Edward High
thought we can say that.

377
00:24:16,720 --> 00:24:19,100
Also the spam two.

378
00:24:19,100 --> 00:24:21,230
It's going to be about into the some

379
00:24:21,230 --> 00:24:24,500
yeah service rate you think here.

380
00:24:24,500 --> 00:24:29,280
So our model can generate
ham from ham also

381
00:24:29,280 --> 00:24:31,653
generate spam from ham as well.

382
00:24:34,784 --> 00:24:37,360
Lets have a look at the
LIME on this for USM first.

383
00:24:38,910 --> 00:24:42,327
The first one generated
ham, spam actually.

384
00:24:42,327 --> 00:24:45,360
And we can see phone service on weekly,

385
00:24:45,360 --> 00:24:47,889
yeah those one highlighted,

386
00:24:47,890 --> 00:24:51,030
so we can say that spam.

387
00:24:51,030 --> 00:24:54,720
And next one, generate ham.

388
00:24:54,720 --> 00:24:58,363
We don't see any highlight or tokens here.

389
00:25:02,311 --> 00:25:05,290
To the next step is how improve our,

390
00:25:05,290 --> 00:25:07,683
models classification performance.

391
00:25:11,748 --> 00:25:14,520
Okay we use the same data set.

392
00:25:14,520 --> 00:25:16,850
SMS spam dataset.

393
00:25:16,850 --> 00:25:20,850
Our original dataset has 200 samples

394
00:25:20,850 --> 00:25:25,850
which include about 175
ham and 25 spam samples

395
00:25:27,337 --> 00:25:31,087
and then we generate
1000 samples out of 200.

396
00:25:32,505 --> 00:25:36,172
And then we use the
same 3000 test data set.

397
00:25:40,788 --> 00:25:45,370
We can use our samples
but it better to assign

398
00:25:45,370 --> 00:25:48,000
a different way, simple way because

399
00:25:48,000 --> 00:25:52,050
the our original sample has high quality

400
00:25:52,050 --> 00:25:57,050
as the samples maybe will
have the same quality

401
00:25:57,630 --> 00:26:01,110
so we assign the 2x higher
weight for the original

402
00:26:01,110 --> 00:26:03,293
samples for our training.

403
00:26:06,260 --> 00:26:10,250
With the new samples and
the different sample rate,

404
00:26:10,250 --> 00:26:12,980
we trained three models.

405
00:26:12,980 --> 00:26:16,686
And these ROC curves
compares the performance.

406
00:26:16,686 --> 00:26:18,256
The platform green one is original model,

407
00:26:20,097 --> 00:26:22,597
only trained with 200 samples.

408
00:26:23,950 --> 00:26:27,000
And then the second orange one,

409
00:26:27,000 --> 00:26:31,073
we trained the model with
original 1000 samples.

410
00:26:31,970 --> 00:26:35,931
And then finally the green
one is the model trained with

411
00:26:35,931 --> 00:26:40,931
200 plus augmented 1000 samples.

412
00:26:40,990 --> 00:26:44,180
As you can see, we achieved
comparable performance

413
00:26:44,180 --> 00:26:47,916
with the PPLM approach
which we can the model

414
00:26:47,916 --> 00:26:52,023
only can be achieved
with the DL 1000 samples.

415
00:26:56,720 --> 00:27:00,460
In summary, still the
size of the training data

416
00:27:00,460 --> 00:27:01,293
is important.

417
00:27:03,150 --> 00:27:05,966
First off we notice that,
if we train the model

418
00:27:05,966 --> 00:27:08,815
out put on the baseline models,
with only with small data

419
00:27:13,030 --> 00:27:18,030
and high quality data orientation matters.

420
00:27:19,240 --> 00:27:23,380
The synthetic samples
were as good as using

421
00:27:23,380 --> 00:27:26,643
very expensive hand-labeled samples.

422
00:27:31,550 --> 00:27:36,550
In conclusion GPT, text
generating AI model

423
00:27:36,670 --> 00:27:41,117
can be trained to detect spam
also it can be re-trained

424
00:27:41,117 --> 00:27:44,260
to generate novel samples

425
00:27:45,410 --> 00:27:48,583
and augment small labeled data set.

426
00:27:49,470 --> 00:27:53,330
GPT-2 spam detection
performance can be improved by

427
00:27:53,330 --> 00:27:57,510
the constant battle
within the text generating

428
00:27:57,510 --> 00:27:59,263
and detecting GPT.

429
00:28:03,160 --> 00:28:06,950
You can apply what you have learned today.

430
00:28:06,950 --> 00:28:11,056
Next week you should
able to identify a small

431
00:28:11,056 --> 00:28:15,580
but very important data
within your organization.

432
00:28:15,580 --> 00:28:20,580
If you don't have you can
start creating the data.

433
00:28:20,790 --> 00:28:24,399
In the first three
months, you will be able

434
00:28:25,260 --> 00:28:30,140
to fine tune a pre-trained
GPT-2 model to build

435
00:28:30,140 --> 00:28:33,450
a classification model to meet your goal

436
00:28:34,350 --> 00:28:37,659
and you can improve the classic model

437
00:28:37,660 --> 00:28:39,210
with data augmentation.

438
00:28:39,210 --> 00:28:44,210
We introduced this, based
on the PPLM approach here.

439
00:28:44,230 --> 00:28:46,466
Within the six months,
you can monitor model's

440
00:28:46,466 --> 00:28:51,466
performance and then deplete
the old data augmentation

441
00:28:51,630 --> 00:28:56,630
and you can see, the
performance improvement.

442
00:29:01,960 --> 00:29:04,884
You have learned very
interesting topic here

443
00:29:04,884 --> 00:29:08,670
but also you can learn
more from our website,

444
00:29:08,670 --> 00:29:12,553
from Sophos AI, they have several,

445
00:29:14,071 --> 00:29:16,719
research paper created with this one,

446
00:29:16,720 --> 00:29:21,290
CATBERT and also we have many
different research projects.

447
00:29:21,290 --> 00:29:24,430
You can find information from our website.

448
00:29:24,430 --> 00:29:27,100
If you have any questions you can send,

449
00:29:27,100 --> 00:29:30,330
you can send the question
to my email address.

450
00:29:32,760 --> 00:29:33,593
Thank you.

