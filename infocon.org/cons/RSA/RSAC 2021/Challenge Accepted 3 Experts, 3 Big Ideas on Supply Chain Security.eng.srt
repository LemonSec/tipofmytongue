1
00:00:00,020 --> 00:00:01,500
- Thank you everybody
for joining, it looks

2
00:00:01,500 --> 00:00:03,950
like we've got a really
robust crowd today.

3
00:00:03,950 --> 00:00:08,183
And so I'm excited to host this event.

4
00:00:10,210 --> 00:00:13,163
Welcome to the RSAConference
lightning talk,

5
00:00:14,010 --> 00:00:17,990
Challenge Accepted: 3 Experts 3 Big Ideas

6
00:00:17,990 --> 00:00:19,779
on Supply Chain Security.

7
00:00:19,780 --> 00:00:22,900
In this session, we're gonna
hear from three experts

8
00:00:22,900 --> 00:00:24,840
some of whom you see on screen now.

9
00:00:24,840 --> 00:00:28,880
Each will have seven minutes
to share their big idea.

10
00:00:28,880 --> 00:00:31,320
And at the end of that time,

11
00:00:31,320 --> 00:00:35,680
we will have about five
minutes each for Q & A.

12
00:00:35,680 --> 00:00:36,930
Now, while they're speaking

13
00:00:36,930 --> 00:00:38,600
you can add your questions into the chat,

14
00:00:38,600 --> 00:00:40,430
you can be thinking of them and

15
00:00:40,430 --> 00:00:43,190
I'll throw those out as time allows.

16
00:00:43,190 --> 00:00:45,169
So let's get started.

17
00:00:45,170 --> 00:00:47,110
First I'd like to
introduce Matt Wyckhouse.

18
00:00:47,110 --> 00:00:49,790
Matt is the founder
and CEO of Finite State

19
00:00:49,790 --> 00:00:52,217
where they focused on automating

20
00:00:52,217 --> 00:00:56,129
the security testing and
risk assessment process

21
00:00:56,130 --> 00:00:59,200
for connected devices
and their supply chains.

22
00:00:59,200 --> 00:01:01,100
Before that, Matt was the CTO

23
00:01:01,100 --> 00:01:03,820
of the Cybersecurity
Business Unit at Patel.

24
00:01:03,820 --> 00:01:06,130
where he supported national
security programs relating

25
00:01:06,130 --> 00:01:09,710
to cyber and supply chain
security for more than a decade.

26
00:01:09,710 --> 00:01:11,842
So Matt, I will throw it over to you.

27
00:01:13,520 --> 00:01:15,773
- Thanks Beau, hi everyone.

28
00:01:18,000 --> 00:01:19,290
So we can go ahead and jump

29
00:01:19,290 --> 00:01:21,683
to the next slide here.

30
00:01:24,160 --> 00:01:27,206
So most of us have
probably heard the phrase

31
00:01:27,206 --> 00:01:31,053
the S in IOT stands for security.

32
00:01:32,210 --> 00:01:35,009
It's kind of a fun phrase there

33
00:01:35,010 --> 00:01:37,640
but the bottom line is that
everyone instinctively believes

34
00:01:37,640 --> 00:01:40,370
that IOT devices are insecure.

35
00:01:40,370 --> 00:01:42,990
But what about other types
of connected devices?

36
00:01:42,990 --> 00:01:44,789
The ones that make up more than 50%

37
00:01:44,790 --> 00:01:47,070
of the end points on most networks today.

38
00:01:47,070 --> 00:01:49,820
Everything from OT devices
to networking equipment

39
00:01:49,820 --> 00:01:52,589
and physical access and security systems.

40
00:01:52,590 --> 00:01:54,310
They're all embedded systems

41
00:01:54,310 --> 00:01:58,500
with the same security challenges as well.

42
00:01:58,500 --> 00:02:00,010
And they've all been affected

43
00:02:00,010 --> 00:02:01,670
by a slew of vulnerabilities lately

44
00:02:01,670 --> 00:02:06,610
from URGENT/11 and Ripple20
to AMNESIA:33 and Bad Alec.

45
00:02:06,610 --> 00:02:09,830
It seems like hundreds
of millions of devices

46
00:02:09,830 --> 00:02:13,840
are found to be severely
vulnerable every few months.

47
00:02:13,840 --> 00:02:17,470
And that's not even factoring in

48
00:02:17,470 --> 00:02:19,780
the potential for malicious
supply chain compromise

49
00:02:19,780 --> 00:02:21,690
which is part of the reason
that we're all here talking

50
00:02:21,690 --> 00:02:23,620
about supply chain today.

51
00:02:23,620 --> 00:02:27,260
So our big idea is
actually probably a pretty

52
00:02:27,260 --> 00:02:31,890
simple and obvious idea,
which is that the reason

53
00:02:31,890 --> 00:02:34,970
for a lot of these issues
and insecurity and perception

54
00:02:34,970 --> 00:02:37,410
of insecurity is that we just
aren't doing enough testing

55
00:02:37,410 --> 00:02:39,410
and verification throughout the process.

56
00:02:40,920 --> 00:02:42,489
In our experience, working with a lot

57
00:02:42,490 --> 00:02:43,990
of vendors who are
building connected products

58
00:02:43,990 --> 00:02:45,350
I can say very concretely

59
00:02:45,350 --> 00:02:49,250
that most vendors actually do
want to build secure devices,

60
00:02:49,250 --> 00:02:51,540
but it's challenging to do that.

61
00:02:51,540 --> 00:02:54,810
And most of the existing
application security tools

62
00:02:54,810 --> 00:02:58,900
and approaches for AppSec
out there tend to fail to

63
00:02:58,900 --> 00:03:02,060
comprehensively assess the
risk and find vulnerabilities

64
00:03:02,060 --> 00:03:05,360
across an entire embedded
system, which is a bit different

65
00:03:05,360 --> 00:03:08,050
than what you'd see
with a traditional app.

66
00:03:08,050 --> 00:03:12,360
And also the users of these
devices need some level

67
00:03:12,360 --> 00:03:13,590
of visibility into the testing

68
00:03:13,590 --> 00:03:14,880
and the results of that testing so

69
00:03:14,880 --> 00:03:17,570
that they can feel comfortable
in understanding the risks

70
00:03:17,570 --> 00:03:20,170
and seeing whether they
meet their risk tolerance.

71
00:03:20,170 --> 00:03:25,170
So what we are looking at
here is that vendors need

72
00:03:26,187 --> 00:03:28,947
to incorporate appropriate
security testing

73
00:03:28,947 --> 00:03:30,310
and supply chain risk management

74
00:03:30,310 --> 00:03:31,920
into their development process.

75
00:03:31,920 --> 00:03:33,209
So that's the traditional kind

76
00:03:33,210 --> 00:03:35,779
of DevSecOps process
that we've thought about

77
00:03:35,779 --> 00:03:37,590
and looked at for a long time,

78
00:03:37,590 --> 00:03:41,500
except for it needs to be
tuned to support the needs

79
00:03:41,500 --> 00:03:44,250
of connected and embedded
device development.

80
00:03:44,250 --> 00:03:46,770
So this is what we call DeviceSecOps

81
00:03:46,770 --> 00:03:48,820
where we're working today,

82
00:03:48,820 --> 00:03:52,269
and that means you need
really robust testing

83
00:03:52,270 --> 00:03:54,930
across both first and
third party components.

84
00:03:54,930 --> 00:03:57,530
One of the things that's
really challenging

85
00:03:57,530 --> 00:03:59,340
with embedded devices is usually more

86
00:03:59,340 --> 00:04:00,960
than 80% of the software

87
00:04:00,960 --> 00:04:03,630
inside of there is coming
from third parties.

88
00:04:03,630 --> 00:04:05,960
And so you need to have a robust software

89
00:04:05,960 --> 00:04:08,720
composition analysis, static
application, security testing

90
00:04:08,720 --> 00:04:12,609
dynamic analysis, some
manual penetration testing,

91
00:04:12,610 --> 00:04:13,840
all of that needs to be incorporated

92
00:04:13,840 --> 00:04:15,350
into a product security program

93
00:04:15,350 --> 00:04:18,040
and testing program and whatever you use

94
00:04:18,040 --> 00:04:20,450
it needs to work on your embedded systems

95
00:04:20,450 --> 00:04:23,479
architectures, programming
languages, and tool chains.

96
00:04:23,480 --> 00:04:25,990
Additionally, with physical products

97
00:04:25,990 --> 00:04:28,840
there's a couple other things
that are unique that need to

98
00:04:28,840 --> 00:04:29,969
be accounted for.

99
00:04:29,970 --> 00:04:31,260
The first is that you have system

100
00:04:31,260 --> 00:04:33,219
and operating system level risks

101
00:04:33,220 --> 00:04:35,410
that can stem from misconfigurations.

102
00:04:35,410 --> 00:04:37,220
Things like hard-coded credentials,

103
00:04:37,220 --> 00:04:39,943
misconfigured and vulnerable services,

104
00:04:40,810 --> 00:04:43,140
traditional tools don't
necessarily find those sorts

105
00:04:43,140 --> 00:04:44,560
of things, and they
need to be investigated

106
00:04:44,560 --> 00:04:46,590
as part of the product
security life cycle.

107
00:04:46,590 --> 00:04:47,560
You need to be collecting

108
00:04:47,560 --> 00:04:49,620
and generating your Software
Bill of Materials and Hardware

109
00:04:49,620 --> 00:04:51,660
Bill of Materials that you
can provide that information

110
00:04:51,660 --> 00:04:52,493
to your customers,

111
00:04:52,493 --> 00:04:55,950
and so that you can manage your
supply chain, the providence

112
00:04:55,950 --> 00:05:00,060
of your supply chain and
map that to any compliance

113
00:05:00,060 --> 00:05:02,200
and regulatory frameworks
that you might have.

114
00:05:02,200 --> 00:05:05,030
And finally, you probably
wanna do some level of testing

115
00:05:05,030 --> 00:05:08,059
of the final bill to make
sure that nothing has changed

116
00:05:08,060 --> 00:05:10,070
from the point of time
testing, to the point

117
00:05:10,070 --> 00:05:12,563
of time that you're delivering this.

118
00:05:13,500 --> 00:05:17,250
Moving forward, when the
vendor sells that product

119
00:05:17,250 --> 00:05:19,883
and delivers it to a
customer at procurement time,

120
00:05:20,780 --> 00:05:24,169
the asset owners can request
this data, and they should.

121
00:05:24,170 --> 00:05:27,260
And it should be entered
into a risk repository.

122
00:05:27,260 --> 00:05:29,500
Similar to how we handle
third party risks for vendors

123
00:05:29,500 --> 00:05:31,180
but doing this for products

124
00:05:31,180 --> 00:05:34,350
and software that we're
bringing into our networks.

125
00:05:34,350 --> 00:05:37,020
And then finally, some
asset owners, especially

126
00:05:37,020 --> 00:05:38,960
in high security
environments might need to

127
00:05:38,960 --> 00:05:40,560
do some additional verification.

128
00:05:41,600 --> 00:05:43,970
They might need to do, in the OT world

129
00:05:43,970 --> 00:05:46,260
what's called a Site Acceptance
Test, testing that device

130
00:05:46,260 --> 00:05:48,599
once it comes into the organization,

131
00:05:48,600 --> 00:05:50,010
they can run a penetration test,

132
00:05:50,010 --> 00:05:52,890
they can analyze firmware and software,

133
00:05:52,890 --> 00:05:54,010
whatever they need to do.

134
00:05:54,010 --> 00:05:55,219
If we do this well

135
00:05:55,220 --> 00:05:57,170
and kind of incorporate
these multiple test points

136
00:05:57,170 --> 00:05:59,940
throughout the life of the device,

137
00:05:59,940 --> 00:06:03,870
that Supply Chain Risk
Repository will provide a wealth

138
00:06:03,870 --> 00:06:05,930
of information that can
be used to support the

139
00:06:05,930 --> 00:06:09,050
overall security life cycle of the device.

140
00:06:09,050 --> 00:06:11,300
You can map the risk
data that you generate

141
00:06:11,300 --> 00:06:13,170
from those test results,

142
00:06:13,170 --> 00:06:15,890
to a risk model that's
appropriate to your organization.

143
00:06:15,890 --> 00:06:20,260
You can factor in things
like how much you care

144
00:06:20,260 --> 00:06:22,300
about the providence of the
components that are coming in.

145
00:06:22,300 --> 00:06:25,160
How much you care about
open source issues.

146
00:06:25,160 --> 00:06:27,560
How much you care about specific
types of vulnerabilities.

147
00:06:27,560 --> 00:06:31,809
All of that can be custom
tuned to your risk tolerance.

148
00:06:31,809 --> 00:06:35,350
And then probably the best part is when

149
00:06:35,350 --> 00:06:37,640
you have this level of
intelligence about the devices

150
00:06:37,640 --> 00:06:40,469
and software coming
into your organization,

151
00:06:40,470 --> 00:06:43,660
you can use that for the rest
of your security life cycle.

152
00:06:43,660 --> 00:06:46,530
So you can arm your
vulnerability management team,

153
00:06:46,530 --> 00:06:49,669
with the Software Bill of
Materials for those end points

154
00:06:49,670 --> 00:06:52,290
so that you can start to find

155
00:06:52,290 --> 00:06:55,330
and mitigate vulnerabilities quickly.

156
00:06:55,330 --> 00:06:58,550
Your threat detection team now
has a little bit more insight

157
00:06:58,550 --> 00:07:00,650
into what's going on
inside of those devices,

158
00:07:00,650 --> 00:07:03,140
what services they're supposed to be using

159
00:07:03,140 --> 00:07:06,219
so they can better
detect issues with them.

160
00:07:06,220 --> 00:07:07,810
So the bottom line is that

161
00:07:07,810 --> 00:07:10,560
we really think that every

162
00:07:10,560 --> 00:07:12,240
organization has a
different risk tolerance.

163
00:07:12,240 --> 00:07:14,530
Every organization should
have their own kind

164
00:07:14,530 --> 00:07:16,830
of risk framework for how to look

165
00:07:16,830 --> 00:07:19,010
at what they're willing to accept

166
00:07:19,010 --> 00:07:21,080
from a supply chain risk standpoint.

167
00:07:21,080 --> 00:07:23,750
But you should be able to
make risk based decisions

168
00:07:23,750 --> 00:07:26,770
and more verification and
testing and data exchange

169
00:07:26,770 --> 00:07:31,770
across the asset owners and
suppliers will enable that.

170
00:07:32,610 --> 00:07:36,030
So that's the quick, big idea,

171
00:07:36,030 --> 00:07:38,292
and I think now it's time for questions.

172
00:07:39,630 --> 00:07:43,580
- A very big idea in
seven minutes or less.

173
00:07:43,580 --> 00:07:46,810
That was great, Matt, thank
you very much for that.

174
00:07:46,810 --> 00:07:49,450
We've got a couple of
questions that folks sent me,

175
00:07:49,450 --> 00:07:53,250
and if you have other
questions and you're waiting

176
00:07:53,250 --> 00:07:55,960
to ask them, drop them
down below and we will get

177
00:07:55,960 --> 00:07:58,902
to them in the priority that they come in.

178
00:08:00,190 --> 00:08:02,193
So first question that I have,

179
00:08:03,260 --> 00:08:05,870
there's an entire AppSec industry focused

180
00:08:05,870 --> 00:08:07,540
on security testing.

181
00:08:07,540 --> 00:08:09,790
Why can't existing tools

182
00:08:09,790 --> 00:08:13,290
and approaches handle embedded devices?

183
00:08:13,290 --> 00:08:16,620
- Yeah, the short answer is devices are

184
00:08:16,620 --> 00:08:18,020
quite a bit different than apps.

185
00:08:18,020 --> 00:08:21,049
A device will actually
oftentimes have thousands

186
00:08:21,050 --> 00:08:23,110
of different software
applications inside of it.

187
00:08:23,110 --> 00:08:25,380
And a lot of the issues
that we see for example

188
00:08:25,380 --> 00:08:27,219
hard-coded credentials are

189
00:08:27,220 --> 00:08:29,040
something that are unique
to embedded devices.

190
00:08:29,040 --> 00:08:32,990
So we see a lot of
vulnerabilities that stem

191
00:08:32,990 --> 00:08:34,700
from the configuration of that device

192
00:08:34,700 --> 00:08:37,030
rather than just the
software inside of it.

193
00:08:37,030 --> 00:08:39,400
The other issue we see with a lot of

194
00:08:39,400 --> 00:08:42,689
apps and products is they may
not support the tool chains

195
00:08:42,690 --> 00:08:45,480
and the programming
languages that are being used

196
00:08:45,480 --> 00:08:47,020
all the time in embedded systems,

197
00:08:47,020 --> 00:08:49,939
so you just may not have
coverage from the existing tools

198
00:08:49,940 --> 00:08:51,140
and so it's important that

199
00:08:51,140 --> 00:08:52,910
you have some sort of tooling, some sort

200
00:08:52,910 --> 00:08:56,449
of testing that you can
incorporate, even if it's manual.

201
00:08:56,450 --> 00:08:59,930
- Great, and we've got
a question from Duncan,

202
00:08:59,930 --> 00:09:02,089
where does SBOM and the other aspects

203
00:09:02,090 --> 00:09:04,240
of the executive order
fit into your framework?

204
00:09:04,240 --> 00:09:06,570
And maybe just for those
parts where it fits

205
00:09:06,570 --> 00:09:08,320
refresh people's memory

206
00:09:08,320 --> 00:09:12,130
if in case they don't have
the EO in top of mind.

207
00:09:12,130 --> 00:09:14,080
- Yeah, so the executive order

208
00:09:14,080 --> 00:09:16,100
on supply chain included a provision

209
00:09:16,100 --> 00:09:20,590
around supply chain security,
which effectively says that

210
00:09:20,590 --> 00:09:22,720
from a procurement standpoint,
the federal government

211
00:09:22,720 --> 00:09:26,570
or other federal agencies
can request things

212
00:09:26,570 --> 00:09:28,680
like a Software Bill of
Materials, along with

213
00:09:28,680 --> 00:09:33,290
any software that they're
buying, probably devices as well.

214
00:09:33,290 --> 00:09:35,709
And they can also request testing results.

215
00:09:35,710 --> 00:09:37,370
So this is actually pretty consistent

216
00:09:37,370 --> 00:09:39,530
with what the executive
order is asking for.

217
00:09:39,530 --> 00:09:42,030
So our view, and Allan's gonna talk a lot

218
00:09:42,030 --> 00:09:43,410
about this here shortly,

219
00:09:43,410 --> 00:09:45,390
is Software Bill of Materials is great.

220
00:09:45,390 --> 00:09:48,423
It's really important, and it
can arm your security team.

221
00:09:49,600 --> 00:09:52,310
If you do robust testing as
part of the development process,

222
00:09:52,310 --> 00:09:54,489
the SBOM is a by-product of that testing,

223
00:09:54,490 --> 00:09:57,230
it can be produced and supported

224
00:09:57,230 --> 00:09:59,090
and sent to your customers very easily

225
00:09:59,090 --> 00:10:00,500
as part of that testing.

226
00:10:00,500 --> 00:10:03,490
If you're thinking about doing
SBOM generation manually,

227
00:10:03,490 --> 00:10:05,920
you're probably going to
have a rough road ahead.

228
00:10:05,920 --> 00:10:10,729
And so we recommend to use
tools as much as possible.

229
00:10:10,730 --> 00:10:12,860
- That's great, and then
I think this is gonna be

230
00:10:12,860 --> 00:10:14,203
the final question.

231
00:10:15,150 --> 00:10:16,620
Ty says, this is a great idea

232
00:10:16,620 --> 00:10:18,340
but how do we get the world to pay for it?

233
00:10:18,340 --> 00:10:21,400
Which part of the world,
is it gonna be buyers,

234
00:10:21,400 --> 00:10:24,520
sellers, will the government step in?

235
00:10:24,520 --> 00:10:27,370
- Yeah, that's a really great question.

236
00:10:27,370 --> 00:10:28,630
So our view is that

237
00:10:28,630 --> 00:10:30,770
what we're already seeing is a shift where

238
00:10:30,770 --> 00:10:32,590
buyers are starting to ask more questions

239
00:10:32,590 --> 00:10:34,390
about the security of products.

240
00:10:34,390 --> 00:10:37,150
And that is putting pressure
on the device manufacturers

241
00:10:37,150 --> 00:10:39,370
which is driving investments in security

242
00:10:39,370 --> 00:10:40,390
in a way that I think

243
00:10:40,390 --> 00:10:43,730
is really on a pretty significant
upward trend right now.

244
00:10:43,730 --> 00:10:44,850
Which is great for everyone.

245
00:10:44,850 --> 00:10:46,780
That's gonna raise the bar.

246
00:10:46,780 --> 00:10:50,579
From there, I think that
certain critical industries

247
00:10:50,580 --> 00:10:52,040
and governments might wanna invest

248
00:10:52,040 --> 00:10:56,524
in additional verification,
post-deployment, post-purchase,

249
00:10:56,524 --> 00:10:59,170
and that'll be the cost of doing business

250
00:10:59,170 --> 00:11:00,260
we wanna make sure that we continue

251
00:11:00,260 --> 00:11:01,540
to make those security investments

252
00:11:01,540 --> 00:11:03,733
especially in the critical networks.

253
00:11:05,274 --> 00:11:08,920
- Excellent, Matt, thank
you very much for your time.

254
00:11:08,920 --> 00:11:10,780
And if you have other questions for Matt,

255
00:11:10,780 --> 00:11:11,790
you can continue to put them

256
00:11:11,790 --> 00:11:13,812
down in the chat window
and Matt, if you're game,

257
00:11:13,812 --> 00:11:16,093
you can just answer those as we go.

258
00:11:18,660 --> 00:11:23,660
Next up, very excited to
present Miss Alyssa Feola.

259
00:11:23,770 --> 00:11:26,800
Alyssa is the cybersecurity advisor,

260
00:11:26,800 --> 00:11:29,140
working on supply chain cybersecurity

261
00:11:29,140 --> 00:11:31,883
for the US Government
Services Agency, GSA.

262
00:11:32,780 --> 00:11:35,670
Including running their
bug bounty program.

263
00:11:35,670 --> 00:11:37,640
Before that, she worked for the Air Force

264
00:11:37,640 --> 00:11:40,960
on Hack the Pentagon as
well as other projects.

265
00:11:40,960 --> 00:11:44,110
And in addition to all of
that, she was instrumental

266
00:11:44,110 --> 00:11:46,870
in helping to pull together
the RSA Conferences

267
00:11:46,870 --> 00:11:48,730
Supply Chain Sandbox.

268
00:11:48,730 --> 00:11:51,670
So thank you very much,
Alyssa, and I will turn it

269
00:11:51,670 --> 00:11:54,622
over to you for your
seven minutes of glory.

270
00:11:59,546 --> 00:12:03,030
- Awesome, thank you so
much, I appreciate it.

271
00:12:03,030 --> 00:12:06,199
So what I'm gonna be
talking to you folks about

272
00:12:06,200 --> 00:12:09,603
is and can you all see me on the screen?

273
00:12:11,830 --> 00:12:14,580
- You're in one of the little
boxes not in the big box.

274
00:12:15,470 --> 00:12:17,610
- It's okay, I like to say I have a big

275
00:12:17,610 --> 00:12:21,310
personality so (laughs)

276
00:12:21,310 --> 00:12:25,109
Matt, if you'll just make the
appropriate facial expressions

277
00:12:25,110 --> 00:12:28,974
as I speak, I'd appreciate it.

278
00:12:28,974 --> 00:12:31,146
(laughs)

279
00:12:31,146 --> 00:12:35,589
So yeah, so awesome,
now my big personality

280
00:12:35,590 --> 00:12:37,530
is front and center.

281
00:12:37,530 --> 00:12:42,000
So I'm gonna be chatting
with y'all about the 7 steps

282
00:12:42,000 --> 00:12:45,943
of setting up a Cyber Supply
Chain Risk Management Program.

283
00:12:47,300 --> 00:12:51,439
And so within, supply
chain risk management

284
00:12:51,440 --> 00:12:53,730
is all about logistics, right?

285
00:12:53,730 --> 00:12:56,840
Making sure you have what you want,

286
00:12:56,840 --> 00:13:00,040
where you want it at the right time.

287
00:13:00,040 --> 00:13:01,209
And that's awesome

288
00:13:02,300 --> 00:13:06,040
but there's other aspects,
where when you're talking

289
00:13:06,040 --> 00:13:08,349
about typical supply chain,

290
00:13:08,350 --> 00:13:11,650
you're really thinking about
availability most of the time.

291
00:13:11,650 --> 00:13:13,740
And then in the cyber
world, when you're talking

292
00:13:13,740 --> 00:13:17,680
about information,
technology and communication,

293
00:13:17,680 --> 00:13:20,199
it really is about integrity.

294
00:13:20,200 --> 00:13:22,972
You care about the
providence and making sure

295
00:13:22,972 --> 00:13:26,370
that what you have,
from what you've bought

296
00:13:26,370 --> 00:13:30,720
or what you've created, really
has what you want in it.

297
00:13:30,720 --> 00:13:34,560
So in order to do that, I
have some seven quick steps

298
00:13:34,560 --> 00:13:38,790
of making sure that
that happens at the end

299
00:13:38,790 --> 00:13:41,000
in some ways that you might want tips

300
00:13:41,000 --> 00:13:42,950
and tricks to get there.

301
00:13:42,950 --> 00:13:47,930
So within an organization,
if you're a startup

302
00:13:47,930 --> 00:13:51,370
or if you're a large enterprise, a company

303
00:13:51,370 --> 00:13:55,630
you really do have a
couple of different layers.

304
00:13:55,630 --> 00:13:57,850
And that's at the enterprise, at the top,

305
00:13:57,850 --> 00:14:02,190
your C-suites and then you
typically deliver something.

306
00:14:02,190 --> 00:14:03,980
And that's the product.

307
00:14:03,980 --> 00:14:05,840
So that's at the system.

308
00:14:05,840 --> 00:14:09,870
But very rarely do you
ever have the top talking

309
00:14:09,870 --> 00:14:13,880
to the bottom, and you wanna
make sure at the middle layer,

310
00:14:13,880 --> 00:14:18,320
the organizational layer,
you also have some plans.

311
00:14:18,320 --> 00:14:20,010
So what that might look like is

312
00:14:20,010 --> 00:14:24,950
that you might be a
business that you do both

313
00:14:27,330 --> 00:14:31,560
delivering software,
transformational products

314
00:14:31,560 --> 00:14:33,979
or you manage buildings.

315
00:14:33,980 --> 00:14:37,010
So you want to have
something at the top layer

316
00:14:37,010 --> 00:14:42,010
that the executives have a
plan, for managing supply chain,

317
00:14:42,300 --> 00:14:44,650
but then you also wanna
have something specific

318
00:14:44,650 --> 00:14:48,531
to your particular mission
within that business,

319
00:14:48,532 --> 00:14:52,750
and then for the actual
system, you wanna know

320
00:14:52,750 --> 00:14:54,180
how am I going to mitigate

321
00:14:54,180 --> 00:14:57,699
the supply chain threads, and plan for it.

322
00:14:57,700 --> 00:15:01,790
So in order to do that, you
need to know what you're doing.

323
00:15:01,790 --> 00:15:04,349
And how critical it is.

324
00:15:04,350 --> 00:15:06,340
So that's where figuring
out what is critical

325
00:15:06,340 --> 00:15:09,970
and what is disposal, comes into play,

326
00:15:09,970 --> 00:15:14,970
because your system might
be super important to you.

327
00:15:15,000 --> 00:15:19,230
And to your customers, but it
might not be extra critical

328
00:15:19,230 --> 00:15:21,850
in mission essential,

329
00:15:21,850 --> 00:15:25,163
to the organization or the enterprise.

330
00:15:26,100 --> 00:15:27,330
And let's admit it,

331
00:15:27,330 --> 00:15:29,680
each business only has a finite number

332
00:15:29,680 --> 00:15:32,084
of resources that they can spend

333
00:15:32,085 --> 00:15:35,860
for protecting what they have.

334
00:15:35,860 --> 00:15:38,000
So they have to choose wisely

335
00:15:38,000 --> 00:15:40,880
and make sure that they're
spending the appropriate amount

336
00:15:40,880 --> 00:15:45,500
of money for what is actually critical.

337
00:15:45,500 --> 00:15:49,987
And understand that not all
things are equally critical.

338
00:15:49,987 --> 00:15:52,630
And some things might be disposable.

339
00:15:52,630 --> 00:15:55,750
But the catch here is making sure you know

340
00:15:55,750 --> 00:15:57,690
what connects to what,

341
00:15:57,690 --> 00:16:02,690
so that you're protecting the
components all the way down,

342
00:16:02,920 --> 00:16:05,247
so that something that connects

343
00:16:05,248 --> 00:16:08,740
to a critical system is also thought of

344
00:16:08,740 --> 00:16:11,573
and also protected appropriately.

345
00:16:12,598 --> 00:16:15,410
And the major component for this

346
00:16:15,410 --> 00:16:18,757
is making sure you know
what you're buying,

347
00:16:18,757 --> 00:16:22,340
and this is a key point
that I cannot stress enough,

348
00:16:22,341 --> 00:16:25,484
keep track of it after you've bought it.

349
00:16:25,484 --> 00:16:30,484
Because things change and
a Shadow IT does exist,

350
00:16:30,810 --> 00:16:35,270
so you want to be able
to respond and react very

351
00:16:35,270 --> 00:16:39,810
quickly when a supply
chain threat is in play.

352
00:16:39,810 --> 00:16:42,219
And if you don't know what you've bought

353
00:16:42,220 --> 00:16:46,240
and you aren't able to be
able to keep track of it

354
00:16:46,240 --> 00:16:48,300
then it's gonna be extra hard

355
00:16:48,300 --> 00:16:53,109
and that time after that
threat happens is very vital.

356
00:16:53,110 --> 00:16:55,810
So you don't wanna have to
be scrambling at this time.

357
00:16:57,559 --> 00:17:00,363
Also consider the threats
and the trade-offs.

358
00:17:01,580 --> 00:17:03,770
Play those scenario building games,

359
00:17:03,770 --> 00:17:05,810
do some chaos engineering,

360
00:17:05,810 --> 00:17:10,780
do some what's called the role play,

361
00:17:10,780 --> 00:17:15,000
and make sure that you know
that like the likelihood

362
00:17:15,000 --> 00:17:19,010
and consequences, if something
could actually happen,

363
00:17:19,010 --> 00:17:24,010
and that you say, it could happen,

364
00:17:24,640 --> 00:17:28,079
but I'm willing to accept that risk.

365
00:17:28,079 --> 00:17:32,780
Some things you are going to,
some things you shouldn't.

366
00:17:32,780 --> 00:17:36,280
So just have that in mind
as you're doing this.

367
00:17:36,280 --> 00:17:41,050
And most importantly,
how a path to communicate

368
00:17:42,140 --> 00:17:44,460
throughout the organization.

369
00:17:44,460 --> 00:17:48,620
The people during a
cybersecurity incident,

370
00:17:48,620 --> 00:17:50,510
especially supply chain

371
00:17:50,510 --> 00:17:53,760
that want to know are gonna be the CEOs,

372
00:17:53,760 --> 00:17:55,090
the business owners.

373
00:17:55,090 --> 00:17:58,439
They have the question,
does this affect us?

374
00:17:58,440 --> 00:18:01,940
Those folks that are
actually triaging and going

375
00:18:01,940 --> 00:18:05,790
through the effort to know
that, need to have a clear path

376
00:18:05,790 --> 00:18:09,990
of communication to go from their logs

377
00:18:09,990 --> 00:18:14,990
up to the CEO in a way that
is digestible for them.

378
00:18:15,640 --> 00:18:18,140
So the first time that
you're going through that

379
00:18:18,140 --> 00:18:23,140
should not be when an incident
actually is occurring.

380
00:18:23,470 --> 00:18:26,170
Also there's countermeasures.

381
00:18:26,170 --> 00:18:28,070
You have to be aware of them.

382
00:18:28,070 --> 00:18:29,270
Does this affect you?

383
00:18:29,270 --> 00:18:31,000
Sometimes, yes.

384
00:18:31,000 --> 00:18:34,020
Does it actually really impact us?

385
00:18:34,020 --> 00:18:35,680
A lot of times, no.

386
00:18:35,680 --> 00:18:36,910
And that reason is

387
00:18:36,910 --> 00:18:40,358
because of the countermeasures
that you've put in place

388
00:18:40,358 --> 00:18:43,600
prior to the attack happening.

389
00:18:43,600 --> 00:18:48,600
And finally, share your
information, it's worth it,

390
00:18:49,206 --> 00:18:54,206
and it gets y'all to a
better resolution quicker.

391
00:18:59,050 --> 00:19:01,483
So I'm ready for the questions now, Beau.

392
00:19:02,610 --> 00:19:06,112
- Alright, thank you very much,
Alyssa, that was excellent.

393
00:19:08,815 --> 00:19:11,390
Alright, so diving into the questions,

394
00:19:11,390 --> 00:19:13,623
a couple of folks sent
them directly to me.

395
00:19:15,808 --> 00:19:20,808
So Alyssa, tell me how can
security organization ensure

396
00:19:21,240 --> 00:19:24,350
that the procurement office
understands the requirements

397
00:19:24,350 --> 00:19:27,812
and can implement them on the suppliers?

398
00:19:28,700 --> 00:19:31,210
- Yeah, so we highly suggest

399
00:19:31,210 --> 00:19:34,390
that you have some standard
procurement language

400
00:19:34,390 --> 00:19:37,340
that you put in to all of your contracts,

401
00:19:37,340 --> 00:19:39,230
and it's kind of the easy button way

402
00:19:39,230 --> 00:19:43,740
to have these templatized language

403
00:19:43,740 --> 00:19:47,710
so that the people
actually doing the buying

404
00:19:47,710 --> 00:19:52,410
don't have to start and anything

405
00:19:52,410 --> 00:19:54,453
from brand new or from scratch.

406
00:19:56,380 --> 00:19:59,170
- And are there available resources,

407
00:19:59,170 --> 00:20:01,740
template procurement buying guidance.

408
00:20:01,740 --> 00:20:04,070
- There is on our website,

409
00:20:04,070 --> 00:20:08,803
obviously, supplychainsandbox.org.

410
00:20:09,870 --> 00:20:11,693
And go to the resource section.

411
00:20:14,640 --> 00:20:16,900
- I'm just dropping
that in the notes here.

412
00:20:16,900 --> 00:20:17,733
- Thank you.

413
00:20:19,130 --> 00:20:22,460
- Excellent, alright, drop
other questions for Alyssa

414
00:20:22,460 --> 00:20:24,193
down in the chat, if you have them.

415
00:20:25,070 --> 00:20:28,665
So Alyssa, tell me what
are some characteristics

416
00:20:28,665 --> 00:20:32,409
of a successful supply chain

417
00:20:32,410 --> 00:20:35,903
risk management programs that you've seen?

418
00:20:37,050 --> 00:20:42,050
- It's typically ones that have a standard

419
00:20:43,860 --> 00:20:47,530
enterprise buying program in place

420
00:20:47,530 --> 00:20:51,190
and then before people buy components,

421
00:20:51,190 --> 00:20:54,040
that they do some sort of review

422
00:20:54,040 --> 00:20:55,770
and supply chain risk management

423
00:20:55,770 --> 00:20:59,033
ends up just being one
of the review factors.

424
00:21:00,051 --> 00:21:05,051
So it should be normalized,
and a part of the process,

425
00:21:05,450 --> 00:21:10,063
and incorporated into the
larger buying apparatus.

426
00:21:11,054 --> 00:21:16,000
So somethings is sharing
the knowledge, having a CMDB

427
00:21:18,090 --> 00:21:21,110
and typically one that also connects

428
00:21:21,110 --> 00:21:24,270
into your overall governance risk

429
00:21:24,270 --> 00:21:26,550
and compliance program as well.

430
00:21:27,860 --> 00:21:30,510
- Okay, and those reviews,

431
00:21:30,510 --> 00:21:33,690
that's sounds like reviewing
checklists or is it actually

432
00:21:33,690 --> 00:21:37,533
acquiring products doing
some security testing or?

433
00:21:38,470 --> 00:21:39,690
- I'm so happy you asked.

434
00:21:39,690 --> 00:21:41,450
It really varies depending

435
00:21:41,450 --> 00:21:44,920
on the criticality of what
you're actually buying.

436
00:21:44,920 --> 00:21:49,920
So for something that is not
going into a nuke system,

437
00:21:51,860 --> 00:21:54,219
yeah, you might just
wanna do a vendor review,

438
00:21:54,220 --> 00:21:59,050
and the more you can do it risk-based,

439
00:21:59,050 --> 00:22:03,600
and instead of compliance and
checkbox based the better.

440
00:22:03,600 --> 00:22:07,377
But if something is going
into a very critical mission

441
00:22:08,960 --> 00:22:12,110
you might want to test
it out objectively first

442
00:22:12,110 --> 00:22:16,352
before you put it into your
actual production system.

443
00:22:17,730 --> 00:22:22,690
- Okay, great, thank
you very much, Alyssa.

444
00:22:22,690 --> 00:22:24,253
We appreciate your time here.

445
00:22:24,253 --> 00:22:27,030
And again, if you have
any questions for Alyssa

446
00:22:27,030 --> 00:22:29,220
you can drop them down in the chat,

447
00:22:29,220 --> 00:22:32,083
and she can answer them as we go.

448
00:22:33,012 --> 00:22:36,883
Next, that brings up Dr. Allan Friedman.

449
00:22:38,670 --> 00:22:43,670
Dr. Friedman is the director
of Cybersecurity Initiatives

450
00:22:46,090 --> 00:22:47,643
at the National Telecommunications

451
00:22:47,643 --> 00:22:51,300
and Information Administration

452
00:22:51,300 --> 00:22:53,460
in the US Department of Commerce.

453
00:22:53,460 --> 00:22:55,510
That is the NTIA.

454
00:22:55,510 --> 00:22:57,879
There, he leads the Software
Bill of Materials process

455
00:22:57,880 --> 00:22:59,740
convening private sector expertise

456
00:22:59,740 --> 00:23:02,441
to collect effective practices.

457
00:23:02,441 --> 00:23:05,195
And in addition to that, he
will be hosting a Sippping Bill

458
00:23:05,195 --> 00:23:09,230
of Materials in just about an
hour and a half, I believe.

459
00:23:09,230 --> 00:23:13,913
So if you go to
supplychainsandbox.org/sbom,

460
00:23:14,900 --> 00:23:16,370
you will see the ingredients list

461
00:23:16,370 --> 00:23:19,429
and you can put your last
minute drizzly order and

462
00:23:19,430 --> 00:23:21,493
Allan take it away.

463
00:23:21,493 --> 00:23:23,234
- Thanks so much, Beau.

464
00:23:23,234 --> 00:23:26,810
And thank you to Beau
and Alyssa and Duncan

465
00:23:26,810 --> 00:23:28,200
and so many others for doing all the work

466
00:23:28,200 --> 00:23:32,260
to get this Supply Chain
Sandbox off the ground.

467
00:23:32,260 --> 00:23:36,340
So SBOM is hopefully an
idea that doesn't sound

468
00:23:36,340 --> 00:23:38,453
completely unfamiliar to folks today.

469
00:23:39,300 --> 00:23:40,822
And in fact, this morning,

470
00:23:41,780 --> 00:23:43,960
the Deputy National Security
Advisor in Newberg, Endeavour

471
00:23:43,960 --> 00:23:47,320
talked some important things
that we need to promote

472
00:23:47,320 --> 00:23:48,537
in the software ecosystem.

473
00:23:48,537 --> 00:23:51,430
And she highlighted that
not all of them are events,

474
00:23:51,430 --> 00:23:55,670
some of them are, she said
basic and maybe even obvious.

475
00:23:55,670 --> 00:23:57,350
And I think that's really
how we should think

476
00:23:57,350 --> 00:23:59,869
about Transparency in the Supply Chain.

477
00:23:59,869 --> 00:24:03,530
This is the basics,
this is the table stakes

478
00:24:03,530 --> 00:24:05,500
for understanding what's
in our supply chain.

479
00:24:05,500 --> 00:24:07,700
It's just saying, what do we have?

480
00:24:07,700 --> 00:24:09,100
It won't solve everything.

481
00:24:09,100 --> 00:24:11,179
And I wanna be sort of
very clear about that.

482
00:24:11,180 --> 00:24:13,500
This isn't gonna magically
solve all of our problems.

483
00:24:13,500 --> 00:24:16,170
But it is going to serve as the foundation

484
00:24:16,170 --> 00:24:20,050
for enabling a wide range
of risk-based decisions.

485
00:24:20,050 --> 00:24:22,639
So how it's going to help
is gonna depend a little bit

486
00:24:22,640 --> 00:24:24,160
on what hat you wear.

487
00:24:24,160 --> 00:24:25,810
Some of us make software.

488
00:24:25,810 --> 00:24:26,854
Some of us are like Alyssa

489
00:24:26,854 --> 00:24:29,400
and involved in choosing software,

490
00:24:29,400 --> 00:24:31,040
and many of us operate software

491
00:24:31,040 --> 00:24:35,020
and in fact, a lot of us
wear all of those tags.

492
00:24:35,020 --> 00:24:36,930
We're all in the supply chain.

493
00:24:36,930 --> 00:24:38,610
Most of us are in the middle.

494
00:24:38,610 --> 00:24:41,409
And SBOM really can support
different approaches.

495
00:24:41,410 --> 00:24:43,860
If you make software,
it just going to say,

496
00:24:43,860 --> 00:24:46,510
Hey is the stuff I'm shipping good

497
00:24:46,510 --> 00:24:49,660
or bad even before it leaves my network

498
00:24:49,660 --> 00:24:51,320
once before I build it?

499
00:24:51,320 --> 00:24:54,070
If you were in the process
of choosing software, well

500
00:24:54,070 --> 00:24:57,760
that builds on all the great
points that Alyssa just made.

501
00:24:57,760 --> 00:25:00,490
Which is, Hey, is this
something that's there?

502
00:25:00,490 --> 00:25:04,100
And in fact, I would
argue even knowing whether

503
00:25:04,100 --> 00:25:06,480
or not you have someone to
produce it as well, right?

504
00:25:06,480 --> 00:25:08,200
While we're still, all still fairly novel.

505
00:25:08,200 --> 00:25:10,540
If you could choose between one product

506
00:25:10,540 --> 00:25:12,050
with a spawn and one
product without any spawn.

507
00:25:12,050 --> 00:25:15,240
What does it say about the organization

508
00:25:15,240 --> 00:25:16,320
that's building the software

509
00:25:16,320 --> 00:25:17,620
if they can't produce an SBOM?

510
00:25:17,620 --> 00:25:19,419
But hopefully by the end of this,

511
00:25:19,420 --> 00:25:22,150
I'll convince you that
it's not that complicated.

512
00:25:22,150 --> 00:25:24,135
And of course, on the operation side.

513
00:25:24,135 --> 00:25:27,002
The hard work should be in
finding new vulnerabilities.

514
00:25:27,002 --> 00:25:30,280
That's what great security
researchers and hackers do.

515
00:25:30,280 --> 00:25:32,120
Once someone has done all of us

516
00:25:32,120 --> 00:25:35,379
the favor of saying,
Hey, this thing is bad.

517
00:25:35,380 --> 00:25:36,740
There's a vulnerability here.

518
00:25:36,740 --> 00:25:38,890
Or someone tried to attack us.

519
00:25:38,890 --> 00:25:41,050
The easy part should be figuring

520
00:25:41,050 --> 00:25:43,060
out whether or not it
affects our products.

521
00:25:43,060 --> 00:25:44,649
And that's really one of the goals here.

522
00:25:44,650 --> 00:25:46,370
So what is an SBOM?

523
00:25:46,370 --> 00:25:48,580
Well, there's a little
picture here on the slide.

524
00:25:48,580 --> 00:25:51,320
We've got our toy model
of Acme Application

525
00:25:51,320 --> 00:25:53,379
which has exactly two dependencies,

526
00:25:53,380 --> 00:25:55,180
Bingo Buffer and Bob's Browser.

527
00:25:55,180 --> 00:25:58,763
Bob's browser in turn depends
on Carol's Compression Engine.

528
00:25:59,720 --> 00:26:01,010
For each of these components,

529
00:26:01,010 --> 00:26:04,160
we don't need that much data.

530
00:26:04,160 --> 00:26:07,380
The minimum SBOM approach
just basically says, Hey

531
00:26:07,380 --> 00:26:09,590
what's the component, what's the supplier,

532
00:26:09,590 --> 00:26:10,540
what's the version?

533
00:26:11,390 --> 00:26:14,310
Having a hash so that we can be sure

534
00:26:14,310 --> 00:26:16,700
that it's not some back door copy.

535
00:26:16,700 --> 00:26:18,340
And then where'd the data come from?

536
00:26:18,340 --> 00:26:19,830
Did this come from the supplier?

537
00:26:19,830 --> 00:26:23,128
Did it come from an expert like Matt

538
00:26:23,128 --> 00:26:27,070
or did it come from the
further upstream originator?

539
00:26:27,070 --> 00:26:28,110
That's the basics.

540
00:26:28,110 --> 00:26:29,909
The other thing we wanna flag here is

541
00:26:29,910 --> 00:26:32,930
that we wanna document known unknowns.

542
00:26:32,930 --> 00:26:34,300
Especially as we start this,

543
00:26:34,300 --> 00:26:36,940
we may not be able to have the full graph.

544
00:26:36,940 --> 00:26:40,610
So in this case, for
example, Bingo Buffer,

545
00:26:40,610 --> 00:26:42,669
we may say, Hey, we don't know

546
00:26:42,670 --> 00:26:44,030
if are any dependencies there.

547
00:26:44,030 --> 00:26:46,899
Could be the very end of our tree,

548
00:26:46,900 --> 00:26:49,490
or it could be the top
of very dark branch.

549
00:26:49,490 --> 00:26:52,530
And again, as long as we can
convey that known unknown

550
00:26:52,530 --> 00:26:54,780
then we have the ability

551
00:26:54,780 --> 00:26:57,250
for someone like Alyssa
to come along and say

552
00:26:57,250 --> 00:27:00,140
this is enough information,
or, Hey, I need more.

553
00:27:00,140 --> 00:27:03,706
So the good news is that
we have ways of doing this.

554
00:27:03,706 --> 00:27:06,136
There are three data formats out there

555
00:27:06,136 --> 00:27:08,610
that can convey this data.

556
00:27:08,610 --> 00:27:11,300
SPDX does which is analytics foundation,

557
00:27:11,300 --> 00:27:14,669
CycloneDX, which is affiliated
with the OWASP community,

558
00:27:14,670 --> 00:27:17,960
and SWID Tag, which is something that my

559
00:27:17,960 --> 00:27:20,242
commerce colleagues at
NIST had been playing with.

560
00:27:20,242 --> 00:27:22,920
And our focus has been to make sure

561
00:27:22,920 --> 00:27:25,450
that we can have
interoperability between them.

562
00:27:25,450 --> 00:27:29,160
So folks can do this today,
and they are doing this today.

563
00:27:29,160 --> 00:27:31,720
We have their organizations
in different corners

564
00:27:31,720 --> 00:27:34,040
of the world that are producing this.

565
00:27:34,040 --> 00:27:36,050
So (indistinct) just gave a great talk

566
00:27:36,050 --> 00:27:38,270
with Josh Corman, one of
the first things he did

567
00:27:38,270 --> 00:27:39,730
when he went to his new company,

568
00:27:39,730 --> 00:27:40,563
say, Hey, do we have an SBOM?

569
00:27:40,563 --> 00:27:42,230
And then just went and published it.

570
00:27:42,230 --> 00:27:43,190
Because you know what?

571
00:27:43,190 --> 00:27:44,320
It shouldn't be that hard

572
00:27:44,320 --> 00:27:46,875
if you have a good process already.

573
00:27:46,875 --> 00:27:48,729
And we also have a lot

574
00:27:48,729 --> 00:27:51,460
of work trying to show
that this is important

575
00:27:51,460 --> 00:27:54,280
and possible in less than
mature organizations.

576
00:27:54,280 --> 00:27:56,560
So started off in the healthcare world

577
00:27:56,560 --> 00:27:59,220
not exactly a famous for being

578
00:27:59,220 --> 00:28:03,115
at the true Vanguard of security
and advanced technology.

579
00:28:03,115 --> 00:28:04,699
And for the last two
years, they've been working

580
00:28:04,699 --> 00:28:08,610
on bringing together the people
that make medical devices

581
00:28:08,610 --> 00:28:11,590
and the people that use medical
devices in hospitals to show

582
00:28:11,590 --> 00:28:13,993
that SBOM can be created and consumed.

583
00:28:14,890 --> 00:28:17,440
We're working with folks
in the automotive sector

584
00:28:17,440 --> 00:28:18,640
through the Auto-ISAC,

585
00:28:18,640 --> 00:28:22,490
and we're just starting some
work in the energy sector

586
00:28:22,490 --> 00:28:23,940
and the bulk power community

587
00:28:23,940 --> 00:28:25,610
partnering with the Department of Energy

588
00:28:25,610 --> 00:28:28,110
and Idaho National Labs for that front.

589
00:28:28,110 --> 00:28:31,030
So there's a lot of great
ongoing work to show

590
00:28:31,030 --> 00:28:32,870
that this stuff can be implemented.

591
00:28:32,870 --> 00:28:35,820
I also wanna say that there
are some challenges, right?

592
00:28:35,820 --> 00:28:39,260
This stuff can be done
today, but to make it scale

593
00:28:39,260 --> 00:28:40,810
we're still working on some

594
00:28:40,810 --> 00:28:43,690
of these smaller details
such as how do we have good

595
00:28:43,690 --> 00:28:47,050
robust global scaling solutions
for software identity?

596
00:28:47,050 --> 00:28:48,770
We don't have a namespace for that.

597
00:28:48,770 --> 00:28:51,000
How do we think about sharing this data?

598
00:28:51,000 --> 00:28:52,480
This is another area
where there isn't gonna

599
00:28:52,480 --> 00:28:54,420
be a one size fits all approach.

600
00:28:54,420 --> 00:28:57,670
If it's traditional, shipped software

601
00:28:57,670 --> 00:28:59,390
of a binary on a platter,
well, that's great.

602
00:28:59,390 --> 00:29:01,150
Let's put the metadata next to it.

603
00:29:01,150 --> 00:29:03,890
If it's a cloud service
or an embedded system

604
00:29:03,890 --> 00:29:05,220
like what Matt was talking about,

605
00:29:05,220 --> 00:29:06,470
we need to find some other approaches.

606
00:29:06,470 --> 00:29:08,730
There are solutions out there today.

607
00:29:08,730 --> 00:29:13,210
So the core takeaway
is that SBOM is coming.

608
00:29:13,210 --> 00:29:14,760
It was part of the executive order

609
00:29:14,760 --> 00:29:16,660
that a lot of folks have
been talking about today,

610
00:29:16,660 --> 00:29:18,440
and there's a great line
from that executive order

611
00:29:18,440 --> 00:29:19,580
that I'm gonna quote.

612
00:29:19,580 --> 00:29:22,210
Which is, "In the end, the trust we place

613
00:29:22,210 --> 00:29:24,450
in our digital infrastructure
should be proportional

614
00:29:24,450 --> 00:29:28,730
to how trustworthy and transparent
that infrastructure is".

615
00:29:28,730 --> 00:29:30,680
So the goal here is to say SBOM is

616
00:29:30,680 --> 00:29:33,979
gonna be the foundation of transparency.

617
00:29:33,979 --> 00:29:35,874
And the goal is to
integrate it into the future

618
00:29:35,874 --> 00:29:39,650
of supply chain management,
so that we can build on it,

619
00:29:39,650 --> 00:29:41,630
and bring together more tools,

620
00:29:41,630 --> 00:29:43,280
and bring together resiliency

621
00:29:43,280 --> 00:29:45,050
so that as we learn about threats

622
00:29:45,050 --> 00:29:46,960
and there are always gonna be threats.

623
00:29:46,960 --> 00:29:48,890
Transparency will allow
us to react and make

624
00:29:48,890 --> 00:29:50,380
good decisions in response.

625
00:29:50,380 --> 00:29:52,166
So that some of the basics

626
00:29:52,166 --> 00:29:55,149
of SBOM in seven minutes,
if you wanna know more,

627
00:29:55,150 --> 00:30:00,150
there are tons of
resources at ntia.gov/sbom,

628
00:30:00,150 --> 00:30:01,440
it's an open process,

629
00:30:01,440 --> 00:30:04,610
we've got folks from around
the world participating.

630
00:30:04,610 --> 00:30:07,340
It's not too late to get involved
and help shape the future.

631
00:30:07,340 --> 00:30:10,020
So please join us and I'll
paste some information

632
00:30:10,020 --> 00:30:12,370
and my contact information
in the chat as well.

633
00:30:13,420 --> 00:30:16,297
- Allan, thank you very much for that.

634
00:30:16,297 --> 00:30:19,200
And just so you know,
I have my shaker here,

635
00:30:19,200 --> 00:30:21,380
you can't see it because
of the screen overlay

636
00:30:21,380 --> 00:30:23,120
but I've got my shaker here ready

637
00:30:23,120 --> 00:30:27,379
for 3:00 PM Pacific Time for
these seven building materials.

638
00:30:27,380 --> 00:30:28,990
So we have some questions

639
00:30:28,990 --> 00:30:32,170
for you, as you probably anticipated.

640
00:30:32,170 --> 00:30:36,560
First question, this is
what I've heard a few times

641
00:30:36,560 --> 00:30:38,679
since SBOM is such a novel concept

642
00:30:38,680 --> 00:30:40,680
shouldn't we wait for all
the details to be worked

643
00:30:40,680 --> 00:30:42,710
out before organizations begin asking

644
00:30:42,710 --> 00:30:44,423
for a Software Bill of Materials?

645
00:30:45,990 --> 00:30:47,350
- It's a great question, and
I think there are a couple

646
00:30:47,350 --> 00:30:50,250
of different ways of
approaching technical change.

647
00:30:50,250 --> 00:30:52,050
One of them is to go off

648
00:30:52,050 --> 00:30:55,690
and spend six years in
hotel conference rooms

649
00:30:55,690 --> 00:30:57,400
trying to build the perfect solution

650
00:30:57,400 --> 00:30:58,870
and then hoping that it works.

651
00:30:58,870 --> 00:31:00,949
And often that's how
we get great standards

652
00:31:00,950 --> 00:31:03,630
but it's also how we waste a lot of time.

653
00:31:03,630 --> 00:31:06,000
The approach that the
community has taken to say, Hey

654
00:31:06,000 --> 00:31:08,730
we are already doing this
in certain parts, right?

655
00:31:08,730 --> 00:31:09,910
This is something that is part

656
00:31:09,910 --> 00:31:12,800
of a standard top quality DevOps approach.

657
00:31:12,800 --> 00:31:14,710
There are tools that will do this

658
00:31:14,710 --> 00:31:17,460
in the SCA marketplace today,

659
00:31:17,460 --> 00:31:19,240
and this is something
that we can integrate.

660
00:31:19,240 --> 00:31:21,530
So let's build on what we have

661
00:31:21,530 --> 00:31:25,010
and sort of follow a
crawl, walk, run mantra.

662
00:31:25,010 --> 00:31:27,990
So that's why the
minimum approach the core

663
00:31:27,990 --> 00:31:31,687
baseline SBOM doesn't
require too much data

664
00:31:31,687 --> 00:31:33,090
and we can start building it.

665
00:31:33,090 --> 00:31:36,590
And we've also designed it
so that partial gets us there

666
00:31:36,590 --> 00:31:38,949
because knowing something about what's

667
00:31:38,950 --> 00:31:41,850
in your supply chain is a lot
better than knowing nothing.

668
00:31:42,770 --> 00:31:44,010
- Great, thank you.

669
00:31:44,010 --> 00:31:45,010
We got a lot of questions

670
00:31:45,010 --> 00:31:46,773
so we might not get to all of them.

671
00:31:47,720 --> 00:31:48,920
But let me ask this one.

672
00:31:49,755 --> 00:31:54,050
Can you talk about issues related

673
00:31:54,050 --> 00:31:56,960
to developing a Hardware
Bill of Materials?

674
00:31:56,960 --> 00:31:59,697
And is that different from a
Software Bill of Materials?

675
00:31:59,697 --> 00:32:04,120
- I'd argue that it is, and
this is an area where folks

676
00:32:04,120 --> 00:32:07,179
like Matt are much more qualified to talk.

677
00:32:07,180 --> 00:32:09,260
But I'll give you one example
about why they're different.

678
00:32:09,260 --> 00:32:10,890
Which is if I wanna show

679
00:32:10,890 --> 00:32:13,210
that I'm using a certain
cryptographic library,

680
00:32:13,210 --> 00:32:14,260
I can take the hash

681
00:32:14,260 --> 00:32:16,230
and then we can follow
that down the stream.

682
00:32:16,230 --> 00:32:18,550
How do I take a hash of a dim?

683
00:32:18,550 --> 00:32:22,240
So, we talk about having
namespace challenges.

684
00:32:22,240 --> 00:32:23,773
In the software world,

685
00:32:25,510 --> 00:32:26,830
there's a lot that we need to work

686
00:32:26,830 --> 00:32:29,780
out in different parts of the
hardware world in some places.

687
00:32:29,780 --> 00:32:33,330
So for example, chips with baked
in identity, that's easier,

688
00:32:33,330 --> 00:32:35,260
in other cases, especially
if you're trying to show

689
00:32:35,260 --> 00:32:37,360
that something hasn't been tampered with,

690
00:32:37,360 --> 00:32:38,810
it gets a little trickier.

691
00:32:38,810 --> 00:32:41,149
I think the approach should
be rather than trying to

692
00:32:41,150 --> 00:32:45,140
build a single model for all
supply chain data management,

693
00:32:45,140 --> 00:32:47,810
it's better to design
things in a modular fashion.

694
00:32:47,810 --> 00:32:51,409
Because that way we can start
to add and layer as we go.

695
00:32:51,410 --> 00:32:53,460
And that's what we've tried to do for SBOM

696
00:32:53,460 --> 00:32:55,610
is to say, Hey, this data,

697
00:32:55,610 --> 00:32:57,649
we shouldn't wait until we
can have everything together

698
00:32:57,650 --> 00:32:58,483
we should sort of focus

699
00:32:58,483 --> 00:33:01,240
on saying what data that we
have now, and then how do we add

700
00:33:01,240 --> 00:33:04,470
to it and layer in incrementing
non-disruptive fashion?

701
00:33:04,470 --> 00:33:05,823
So forward compatibility.

702
00:33:06,670 --> 00:33:11,010
- Great, alright, so how do you recommend

703
00:33:11,010 --> 00:33:14,010
organizations handle a library dependency

704
00:33:14,010 --> 00:33:15,530
with a vulnerability where

705
00:33:15,530 --> 00:33:18,021
the dependency doesn't have an update

706
00:33:18,021 --> 00:33:21,470
and where the vulnerability
isn't exploitable based

707
00:33:21,470 --> 00:33:23,220
on the specific use of the library?

708
00:33:24,080 --> 00:33:26,350
- This is a great
question because it's one

709
00:33:26,350 --> 00:33:29,129
of the things that matured, good faith

710
00:33:29,130 --> 00:33:30,676
security people often look at SBOM

711
00:33:30,676 --> 00:33:32,649
and say, Hey, wait a minute,

712
00:33:32,649 --> 00:33:35,820
I'm shipping software that
has a known vulnerability

713
00:33:35,820 --> 00:33:37,990
but I've got a lot to do on my team.

714
00:33:37,990 --> 00:33:40,570
And so, yes, we eventually
wanna fix something

715
00:33:40,570 --> 00:33:42,530
or maybe there isn't an update available,

716
00:33:42,530 --> 00:33:43,820
so we're gonna swap this library out

717
00:33:43,820 --> 00:33:47,669
but for the moment, we're
confident that our customers

718
00:33:47,670 --> 00:33:49,790
and their users aren't effected.

719
00:33:49,790 --> 00:33:53,033
And so part of this
process is gonna say, Hey

720
00:33:53,033 --> 00:33:55,679
in addition to SBOM, we want to be able to

721
00:33:55,680 --> 00:33:58,750
convey what we can think of as
a negative security advisory.

722
00:33:58,750 --> 00:34:00,420
The ability, and we're calling this VEX,

723
00:34:00,420 --> 00:34:02,890
or the Vulnerability
Exploitability Exchange.

724
00:34:02,890 --> 00:34:05,750
The ability for a supplier
to communicate downstream,

725
00:34:05,750 --> 00:34:07,600
we're not affected by this.

726
00:34:07,600 --> 00:34:12,600
So for example, the recent
DNS bugs that Forescout found

727
00:34:14,163 --> 00:34:17,980
in a bunch of connected
devices, the Linux foundation

728
00:34:17,980 --> 00:34:20,889
process Zephyr, wanting to
communicate to anyone who

729
00:34:20,889 --> 00:34:24,232
was using their IOT oriented
operating system to say, Hey

730
00:34:24,232 --> 00:34:26,130
we're not affected by this.

731
00:34:26,130 --> 00:34:28,219
That's a useful piece of
information that we're gonna

732
00:34:28,219 --> 00:34:30,759
wanna integrate into the community.

733
00:34:30,760 --> 00:34:32,880
And for those who are
interested, we're implementing

734
00:34:32,880 --> 00:34:35,960
that through something
called CSAF, C-S-A-F

735
00:34:35,960 --> 00:34:37,322
which is an Oasis standard.

736
00:34:38,159 --> 00:34:41,879
- Great, is having a full

737
00:34:41,880 --> 00:34:45,460
Software Bill of Materials
gonna create issues?

738
00:34:45,460 --> 00:34:47,580
So if there's some vulnerability

739
00:34:47,580 --> 00:34:50,313
at the seventh level of
a transitive dependency,

740
00:34:51,500 --> 00:34:54,989
is that gonna create a
roadmap for adversaries?

741
00:34:54,989 --> 00:34:57,819
And I realize that there's a
lot packed into that question.

742
00:34:57,820 --> 00:34:59,980
- Sure, so one is depth,

743
00:34:59,980 --> 00:35:01,910
and then two is the
roadmap for the attacker.

744
00:35:01,910 --> 00:35:02,743
Let's talk about the roadmap

745
00:35:02,743 --> 00:35:04,610
for the attacker question first.

746
00:35:04,610 --> 00:35:06,180
Because those of you who are in security

747
00:35:06,180 --> 00:35:08,940
for while have come across the idea

748
00:35:08,940 --> 00:35:12,280
that security through obscurity,
not the best strategy.

749
00:35:12,280 --> 00:35:14,700
And so, but I say, it's
2021 we threat model.

750
00:35:14,700 --> 00:35:17,470
So threat modeling in 20 seconds.

751
00:35:17,470 --> 00:35:18,339
On one hand,

752
00:35:18,340 --> 00:35:21,150
the advanced adversaries
probably don't need this, right?

753
00:35:21,150 --> 00:35:22,340
They wanna know what's in your product.

754
00:35:22,340 --> 00:35:23,380
They'll figure it out.

755
00:35:23,380 --> 00:35:26,940
Anyone with a master's
degree can build an SCA tool.

756
00:35:26,940 --> 00:35:29,610
At the other end, you
have automated attacks.

757
00:35:29,610 --> 00:35:31,810
People that are just
building scanning tools.

758
00:35:31,810 --> 00:35:33,620
And there, the solution is

759
00:35:33,620 --> 00:35:35,450
that we need to give the
roadmap to the defender

760
00:35:35,450 --> 00:35:36,830
because they don't know what they have

761
00:35:36,830 --> 00:35:38,310
on their own network today.

762
00:35:38,310 --> 00:35:40,270
They're lucky to have asset management

763
00:35:40,270 --> 00:35:42,210
but this is getting below there.

764
00:35:42,210 --> 00:35:44,280
So the question of depth,

765
00:35:44,280 --> 00:35:46,570
that's something that we do
need some better science on

766
00:35:46,570 --> 00:35:48,520
where the attackers are looking.

767
00:35:48,520 --> 00:35:51,690
I think a lot of it as it
higher up in the stack,

768
00:35:51,690 --> 00:35:55,620
but then we hear great examples
of just lack of resiliency

769
00:35:55,620 --> 00:35:58,190
and my favorite story
here is left pad where

770
00:35:58,190 --> 00:35:59,730
there was a vulnerability,

771
00:35:59,730 --> 00:36:01,560
but that everyone was dependent

772
00:36:01,560 --> 00:36:04,540
on a library without realizing

773
00:36:04,540 --> 00:36:08,290
that one person could have
broken this entire approach.

774
00:36:08,290 --> 00:36:10,740
And so having visibility
in the supply chain is

775
00:36:10,740 --> 00:36:13,729
going to not just help us
defend against active attacks,

776
00:36:13,730 --> 00:36:15,760
but give us a better sense of resiliency.

777
00:36:15,760 --> 00:36:18,093
How much of my software is dependent

778
00:36:18,093 --> 00:36:21,700
on one person remembering
to look both ways,

779
00:36:21,700 --> 00:36:23,779
or one person deciding not to take

780
00:36:23,780 --> 00:36:26,730
up the ukulele and sticking
with their open source project.

781
00:36:27,660 --> 00:36:30,805
- Great, this is a slightly different one.

782
00:36:30,805 --> 00:36:34,620
What's been the most interesting part

783
00:36:34,620 --> 00:36:39,283
of hosting the SBOM process
for the last several years?

784
00:36:40,652 --> 00:36:43,960
- It has been a true
honor to be able to work

785
00:36:43,960 --> 00:36:45,820
with such an amazing community.

786
00:36:45,820 --> 00:36:46,880
Personally, I love it

787
00:36:46,880 --> 00:36:49,079
because I've gotten so
many different perspectives

788
00:36:49,079 --> 00:36:53,160
on how rich and complex the
software supply chain is.

789
00:36:53,160 --> 00:36:55,480
So on this very issue

790
00:36:55,480 --> 00:36:58,297
we have folks who have come
from the cloud native world

791
00:36:58,297 --> 00:36:59,850
who say, SBOM won't help

792
00:36:59,850 --> 00:37:01,799
because we already have this information.

793
00:37:01,800 --> 00:37:03,890
And then we've got folks in the

794
00:37:03,890 --> 00:37:06,683
serious embedded world who say, oh my God,

795
00:37:07,680 --> 00:37:09,859
My network, the software
doesn't exist anymore

796
00:37:09,860 --> 00:37:13,260
in source, we only have
binaries, how do we get this?

797
00:37:13,260 --> 00:37:15,100
And that those are the
challenges that we need to

798
00:37:15,100 --> 00:37:17,910
bring together and make
sure that we can solve it

799
00:37:17,910 --> 00:37:22,290
and address it without having
a one size fits all approach

800
00:37:22,290 --> 00:37:23,610
but still having enough

801
00:37:23,610 --> 00:37:25,890
of a common solution so that suppliers

802
00:37:25,890 --> 00:37:28,643
and customers don't have to
do a million different things.

803
00:37:29,584 --> 00:37:32,049
- Great, and then probably
the last one of the day,

804
00:37:32,050 --> 00:37:35,290
very serious question
for those who don't know,

805
00:37:35,290 --> 00:37:37,085
what does your shirt say?

806
00:37:37,085 --> 00:37:38,783
(laughs)

807
00:37:38,783 --> 00:37:41,610
- This is the joy of
running a small project

808
00:37:41,610 --> 00:37:42,483
without a budget

809
00:37:42,483 --> 00:37:43,890
you gotta do everything
you can to promote it.

810
00:37:43,890 --> 00:37:44,750
So a couple of years ago

811
00:37:44,750 --> 00:37:47,340
at DEFCON I decided we needed an SBOM

812
00:37:47,340 --> 00:37:49,130
not f-bombs shirt.

813
00:37:49,130 --> 00:37:50,570
We have an SBOM logo

814
00:37:50,570 --> 00:37:55,200
and folks who wanna know
and want to participate,

815
00:37:55,200 --> 00:37:56,520
when we get back into the world

816
00:37:56,520 --> 00:37:58,550
in the conference world,
we'll make some t-shirts,

817
00:37:58,550 --> 00:38:00,160
we'll get some stickers for your laptops

818
00:38:00,160 --> 00:38:01,330
and your water bottles,

819
00:38:01,330 --> 00:38:04,040
and we'll build a movement.

820
00:38:04,040 --> 00:38:05,623
So please come and join us.

