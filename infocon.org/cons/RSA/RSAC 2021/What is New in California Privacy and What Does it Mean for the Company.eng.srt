1
00:00:01,990 --> 00:00:02,823
- Good morning.

2
00:00:02,823 --> 00:00:04,290
Today we are here to talk about

3
00:00:04,290 --> 00:00:06,110
what is new in California privacy

4
00:00:06,110 --> 00:00:08,070
and what does this mean for the company.

5
00:00:08,070 --> 00:00:09,950
In particular we are gonna be focusing

6
00:00:09,950 --> 00:00:12,482
on the new CPRA in California.

7
00:00:13,320 --> 00:00:14,830
My name is Carla J. Utter.

8
00:00:14,830 --> 00:00:16,370
I go by CJ Utter.

9
00:00:16,370 --> 00:00:19,440
I am registered in house
counsel and director of privacy

10
00:00:19,440 --> 00:00:21,340
and data protection at Masimo.

11
00:00:21,340 --> 00:00:22,640
And I am being joined today

12
00:00:22,640 --> 00:00:25,880
by my colleague Lothar
Determann who is a partner

13
00:00:25,880 --> 00:00:30,338
at Baker McKenzie up
in Northern California.

14
00:00:30,338 --> 00:00:34,020
So we are happy to speak
about this with you today.

15
00:00:34,020 --> 00:00:36,660
Just a few announcements to make.

16
00:00:36,660 --> 00:00:39,449
First of all, the views shared here in

17
00:00:39,450 --> 00:00:41,240
are our own personal views.

18
00:00:41,240 --> 00:00:42,970
We're not representing our company

19
00:00:42,970 --> 00:00:45,870
and this does not constitute
a legal relationship

20
00:00:45,870 --> 00:00:47,790
or legal advice with us.

21
00:00:47,790 --> 00:00:51,089
Certainly you should, you
know, talk to your own lawyer

22
00:00:51,090 --> 00:00:53,678
or professional about
this, with your company

23
00:00:53,678 --> 00:00:55,010
and your jurisdiction.

24
00:00:55,010 --> 00:00:57,699
There's no warranties or
representations here in

25
00:00:57,700 --> 00:01:01,390
and we are not gonna share
anything that's proprietary

26
00:01:01,390 --> 00:01:03,870
or confidential in nature.

27
00:01:03,870 --> 00:01:06,670
And we are just representing
ourselves, not our company.

28
00:01:08,260 --> 00:01:09,093
- Thanks, CJ.

29
00:01:09,093 --> 00:01:10,220
Good points.

30
00:01:10,220 --> 00:01:13,780
I actually speak on behalf of
all the 12,000 professionals

31
00:01:13,780 --> 00:01:15,360
that pay for McKenzie
all around the world.

32
00:01:15,360 --> 00:01:18,460
They always agree with me
on every single thing I say

33
00:01:18,460 --> 00:01:20,963
or think or joke about.

34
00:01:22,110 --> 00:01:25,321
As you said, the biggest new thing

35
00:01:25,321 --> 00:01:30,321
is the California privacy rights act.

36
00:01:30,570 --> 00:01:35,570
Which amends the California
consumer privacy act CCPA

37
00:01:35,630 --> 00:01:38,020
and it remains a moving target.

38
00:01:38,020 --> 00:01:43,020
We've covered it together
at RSA in previous years.

39
00:01:45,840 --> 00:01:49,380
And it is a big shift the way
from California privacy laws.

40
00:01:49,380 --> 00:01:53,580
You see the cover page of
my California privacy book

41
00:01:54,476 --> 00:01:56,890
here, 600 pages covers hundreds
of different privacy laws

42
00:01:56,890 --> 00:01:59,080
in California and on a federal level.

43
00:01:59,080 --> 00:02:02,313
These old stay in place but on top

44
00:02:02,313 --> 00:02:05,820
of these harm specific
laws, that are very specific

45
00:02:05,820 --> 00:02:10,430
from children, on privacy
supermarket, club cards,

46
00:02:10,430 --> 00:02:14,140
revenge porn, Paparazzi, all
these different little topics

47
00:02:14,140 --> 00:02:18,670
on top of it we now have also
rigid regulation of portal

48
00:02:18,670 --> 00:02:21,809
data processing similar as in the EU.

49
00:02:21,810 --> 00:02:25,940
It started in June, 2018
when the first initiative

50
00:02:25,940 --> 00:02:29,450
of Californians for privacy
resulted in legislative actions

51
00:02:29,450 --> 00:02:33,170
it hammered out a compromised
bill, that was the CCPA

52
00:02:34,340 --> 00:02:38,030
and because that was
passed by the legislature

53
00:02:38,030 --> 00:02:41,014
the legislature could
also make changes to it.

54
00:02:41,014 --> 00:02:42,909
There were a flurry of
bills at some point,

55
00:02:42,909 --> 00:02:45,470
there were 50 different
bills in our parliament

56
00:02:45,470 --> 00:02:47,090
in Sacramento.

57
00:02:47,090 --> 00:02:49,300
And the California's for privacy led

58
00:02:49,300 --> 00:02:50,740
by Alastair MacTaggart held

59
00:02:50,740 --> 00:02:52,750
that there was too much watering down

60
00:02:52,750 --> 00:02:56,370
and so they ended up doing
a second ballot initiative

61
00:02:56,370 --> 00:02:59,730
which was on the general
ballot in November 2020

62
00:02:59,730 --> 00:03:03,260
and was accepted by a
relatively wide margins

63
00:03:03,260 --> 00:03:05,277
of Californians, it's 56%.

64
00:03:05,277 --> 00:03:08,578
The reason why it didn't
pass in San Francisco

65
00:03:08,579 --> 00:03:12,500
for example, was that people
felt it didn't go far enough.

66
00:03:12,500 --> 00:03:15,633
They wanted even more privacy regulation.

67
00:03:17,660 --> 00:03:20,310
Now, that's why we're
focusing today very much

68
00:03:20,310 --> 00:03:23,300
on this particular law, but
we want to remind everyone

69
00:03:23,300 --> 00:03:25,980
there are literally hundreds of other laws

70
00:03:25,980 --> 00:03:28,016
that are still on the book.

71
00:03:28,016 --> 00:03:29,030
They're not preempted by this

72
00:03:29,030 --> 00:03:31,010
and conflicts between the existing

73
00:03:31,010 --> 00:03:33,959
and the new laws aren't
really addressed yet

74
00:03:33,960 --> 00:03:34,973
by the legislature.

75
00:03:36,606 --> 00:03:40,850
In parallel, there are numerous
initiatives for federal law

76
00:03:40,850 --> 00:03:43,190
but I think most specialists agree

77
00:03:43,190 --> 00:03:46,130
that there is no clear
winner or front runner

78
00:03:46,130 --> 00:03:51,130
because in the Federal Congress
the politicians cannot agree

79
00:03:52,780 --> 00:03:54,880
on whether the new
Federal law should be just

80
00:03:54,880 --> 00:03:58,019
the baseline and States can
continue to pass hundreds

81
00:03:58,020 --> 00:04:01,093
of different laws, or whether
they should be preemption.

82
00:04:02,170 --> 00:04:06,280
Also, a big sticking point
is whether private attorneys

83
00:04:06,280 --> 00:04:08,170
should be able to bring
private lawsuits on it

84
00:04:08,170 --> 00:04:10,589
or whether this should only
be enforced by the government

85
00:04:10,590 --> 00:04:14,300
as it is, for example, largely enforced

86
00:04:14,300 --> 00:04:16,310
by data protection authorities

87
00:04:16,310 --> 00:04:18,450
and that is the right of private action.

88
00:04:18,450 --> 00:04:20,820
That's a big discussion
point that has been holding

89
00:04:20,820 --> 00:04:23,490
up a compromise on federal privacy law.

90
00:04:23,490 --> 00:04:27,540
In the meantime, the other
States are firing away

91
00:04:27,540 --> 00:04:32,030
with their own laws, Nevada
passed one already while back,

92
00:04:32,030 --> 00:04:33,320
that is in effect.

93
00:04:33,320 --> 00:04:34,719
Virginia just passed one

94
00:04:34,720 --> 00:04:38,080
that will take effect January one, 2023,

95
00:04:38,080 --> 00:04:40,520
and New York, State of Washington

96
00:04:40,520 --> 00:04:42,940
and others are working on
their own legislation, all

97
00:04:42,940 --> 00:04:45,510
with different varieties,
different definitions and so on.

98
00:04:45,510 --> 00:04:50,010
So companies are in for a
difficult period of adjusting

99
00:04:50,010 --> 00:04:53,210
to these laws and they
will benchmark typically

100
00:04:53,210 --> 00:04:55,520
in my practice, the new laws against

101
00:04:55,520 --> 00:04:56,460
what they're already doing

102
00:04:56,460 --> 00:04:59,609
under the general data
protection regulation

103
00:04:59,610 --> 00:05:02,750
in Europe and the California
consumer privacy act

104
00:05:02,750 --> 00:05:05,763
which are still the most
comprehensive in the world.

105
00:05:07,420 --> 00:05:10,340
So this California privacy rights act

106
00:05:10,340 --> 00:05:13,630
is not a standalone loss, or
you're not trying to comply

107
00:05:13,630 --> 00:05:18,400
with the CPRA, but you're
complying with an amended version

108
00:05:18,400 --> 00:05:21,580
of the California
consumer privacy act CCPA

109
00:05:21,580 --> 00:05:23,282
which is amended by this law.

110
00:05:24,160 --> 00:05:27,740
This law will be fully
effective January one, 2023

111
00:05:27,740 --> 00:05:29,510
two years transition time.

112
00:05:29,510 --> 00:05:33,460
However, some of the provisions
already took effect when

113
00:05:33,460 --> 00:05:38,082
the initiative was certified
which was in November 20.

114
00:05:42,339 --> 00:05:46,040
The law can be amended by
the California legislature

115
00:05:46,040 --> 00:05:49,200
with simple majority, but
only if it is consistent

116
00:05:49,200 --> 00:05:52,190
with and furthers the CPRA and many hope

117
00:05:52,190 --> 00:05:54,570
that this will put an end to the lobbying

118
00:05:54,570 --> 00:05:57,440
and the wrangling where
something is tweaked a little bit

119
00:05:57,440 --> 00:06:00,432
in favor of companies
only to find something

120
00:06:00,432 --> 00:06:05,432
in favor of private attorneys
or private plaintiffs.

121
00:06:06,660 --> 00:06:11,660
And because this can only go
one directional now, presumably

122
00:06:12,170 --> 00:06:14,716
there will be less amendments.

123
00:06:14,716 --> 00:06:16,630
There were actually a number of amendments

124
00:06:16,630 --> 00:06:19,930
in the legislator in 2020

125
00:06:19,930 --> 00:06:23,630
but the ballot initiative
said anything that was changed

126
00:06:23,630 --> 00:06:26,150
after January one, 2020 will be on them.

127
00:06:26,150 --> 00:06:27,960
At the same time we have regulations

128
00:06:27,960 --> 00:06:30,763
from the California Attorney General.

129
00:06:31,670 --> 00:06:34,550
They were finalized in August, 2020.

130
00:06:34,550 --> 00:06:38,141
They were already amended in October

131
00:06:38,141 --> 00:06:39,460
and the new rules took effect in March.

132
00:06:39,460 --> 00:06:41,830
So there's a lot of
different things to look at

133
00:06:41,830 --> 00:06:45,080
and we want to cover them for
you now, boiling them down

134
00:06:45,080 --> 00:06:47,180
a little bit, high level messages

135
00:06:47,180 --> 00:06:50,280
and refer you to additional publications

136
00:06:50,280 --> 00:06:53,359
that we'd be happy to
share with more detail.

137
00:06:53,360 --> 00:06:56,770
The first big question, and
I'm giving that to you, CJ.

138
00:06:56,770 --> 00:07:00,193
Who and what data is
protected by this law?

139
00:07:02,912 --> 00:07:04,650
- So this law is pretty broad.

140
00:07:04,650 --> 00:07:06,489
First of all, it relates

141
00:07:06,490 --> 00:07:10,000
to any California
resident, natural persons.

142
00:07:10,000 --> 00:07:13,460
This does not include a
corporation or business.

143
00:07:13,460 --> 00:07:17,000
It's defined as the
residency in tax regulations.

144
00:07:17,000 --> 00:07:18,590
So that's a good definition to use.

145
00:07:18,590 --> 00:07:22,539
And it includes patients,
tenants, students, parents

146
00:07:22,540 --> 00:07:26,800
children, employees, candidates,
contractors, directors

147
00:07:28,040 --> 00:07:29,360
all the above.

148
00:07:29,360 --> 00:07:33,750
And until January, 2023,
there are less protections

149
00:07:33,750 --> 00:07:36,030
for business representatives and employees

150
00:07:36,030 --> 00:07:38,133
and your candidates, your contractors,

151
00:07:38,134 --> 00:07:41,560
your owners, directors,
medical staff members,

152
00:07:41,560 --> 00:07:44,300
and individuals that would fall

153
00:07:44,300 --> 00:07:46,720
within those classifications.

154
00:07:46,720 --> 00:07:49,050
So it is quite broad and
covers everybody here

155
00:07:49,050 --> 00:07:51,073
in California in one form or another.

156
00:07:52,652 --> 00:07:54,700
- Very important point CJ,

157
00:07:54,700 --> 00:07:59,700
the employees have a delayed
time until January one 2023.

158
00:07:59,700 --> 00:08:00,533
There was some idea

159
00:08:00,533 --> 00:08:04,020
that may be a special employee
Privacy law would be passed,

160
00:08:04,020 --> 00:08:06,280
whether that will happen
is kind of unclear.

161
00:08:06,280 --> 00:08:10,559
Right now thinking maybe it'll
just be whatever's in CCPA

162
00:08:10,560 --> 00:08:12,570
as amended by CPRA right now.

163
00:08:12,570 --> 00:08:17,270
But one thing to note when
the initiative was certified

164
00:08:17,270 --> 00:08:22,270
the effective date of that was
actually December 16, 2020.

165
00:08:22,270 --> 00:08:25,039
At that point, new privacy
notices had to be given

166
00:08:25,040 --> 00:08:27,930
to California employees
and they already have to be

167
00:08:27,930 --> 00:08:30,820
in the style of CPRA, which might've been

168
00:08:30,820 --> 00:08:34,230
an unintended consequences,
how these approvals were done

169
00:08:34,230 --> 00:08:38,260
but important to note
employees and business context

170
00:08:38,260 --> 00:08:40,913
are not completely excluded from this law.

171
00:08:40,913 --> 00:08:44,030
There's just a number of
provisions don't take effect yet.

172
00:08:44,030 --> 00:08:46,593
So what data is protected CJ?

173
00:08:48,460 --> 00:08:51,700
- This once again, as I
mentioned is super broad as well

174
00:08:51,700 --> 00:08:56,180
and it's basically intended to
relate to a specific person.

175
00:08:56,180 --> 00:08:58,589
If the information is supposed to relate

176
00:08:58,590 --> 00:09:00,580
to a specific person,
then you have to assume

177
00:09:00,580 --> 00:09:02,410
that it's personal information.

178
00:09:02,410 --> 00:09:07,180
The formal definition
means basically information

179
00:09:07,180 --> 00:09:09,969
that identifies, describes, relates to

180
00:09:09,970 --> 00:09:13,866
or is reasonably capable of
being associated with a person

181
00:09:13,866 --> 00:09:16,684
or could be reasonably associated linked

182
00:09:16,684 --> 00:09:18,560
with this particular consumer

183
00:09:18,560 --> 00:09:22,140
or household, would be
personal information.

184
00:09:22,140 --> 00:09:25,037
And it could be a direct
link or an indirect link,

185
00:09:25,037 --> 00:09:27,570
but all that, as long as you can assume

186
00:09:27,570 --> 00:09:31,700
that it's supposed to
be to a specific person

187
00:09:31,700 --> 00:09:33,693
then it is personal information.

188
00:09:35,330 --> 00:09:37,060
- I think that's the way to go

189
00:09:37,060 --> 00:09:38,770
for designing a compliance program.

190
00:09:38,770 --> 00:09:40,948
I get a lot of questions from clients,

191
00:09:40,948 --> 00:09:44,540
is a name, address, personal identify

192
00:09:44,540 --> 00:09:46,980
is that person information
biometric information,

193
00:09:46,980 --> 00:09:48,130
internet activity.

194
00:09:48,130 --> 00:09:50,430
All of those things are
listed in this statute

195
00:09:50,430 --> 00:09:53,079
because you have to
call them out separately

196
00:09:53,080 --> 00:09:55,840
in the privacy notice on your website

197
00:09:55,840 --> 00:09:58,250
and you have to update those once a year

198
00:09:58,250 --> 00:10:01,740
and they have to go back to the beginning

199
00:10:01,740 --> 00:10:05,520
of the last calendar year,
and so you, it makes sense

200
00:10:05,520 --> 00:10:08,300
to list them all in the
statute but the rule of thumb

201
00:10:08,300 --> 00:10:10,439
that CJ just gave, is
really the way to look at.

202
00:10:10,440 --> 00:10:12,880
If you think that something refers

203
00:10:12,880 --> 00:10:15,760
to an individual person,
you have to assume

204
00:10:15,760 --> 00:10:17,060
it's personal information.

205
00:10:17,990 --> 00:10:22,290
And internet IP address as
such will have to be presumed

206
00:10:22,290 --> 00:10:23,250
to be personal information.

207
00:10:23,250 --> 00:10:27,950
There may be some that are
relate to a printer that is used

208
00:10:27,950 --> 00:10:31,010
by many different people in a
company that ultimately turns

209
00:10:31,010 --> 00:10:32,680
out may not be personal information,

210
00:10:32,680 --> 00:10:35,760
If nobody can tell whose
we're using it at a given time

211
00:10:35,760 --> 00:10:38,610
but more likely than not,
especially here when we speak

212
00:10:38,610 --> 00:10:41,380
to the RSA audience with
security professionals,

213
00:10:41,380 --> 00:10:45,070
you can often find out, with
the help of other companies

214
00:10:45,070 --> 00:10:48,610
or other people who at a given
time was using the device.

215
00:10:48,610 --> 00:10:51,490
And therefore, probably
even that would typically

216
00:10:51,490 --> 00:10:52,690
be personal information.

217
00:10:53,810 --> 00:10:55,792
Now, who has to comply with this law?

218
00:10:58,324 --> 00:10:59,890
Where the definition of consumers

219
00:10:59,890 --> 00:11:01,917
on the California residence,

220
00:11:01,917 --> 00:11:06,063
the definition of a business
is any company worldwide.

221
00:11:07,670 --> 00:11:10,033
It has to be a for-profit company,

222
00:11:12,470 --> 00:11:17,300
and it has to exceed certain
thresholds that are intended

223
00:11:17,300 --> 00:11:19,030
to carve out smaller companies.

224
00:11:19,030 --> 00:11:20,939
Annual gross revenue of 25 million.

225
00:11:20,940 --> 00:11:23,796
It's not clear that that's
only California revenue

226
00:11:23,796 --> 00:11:26,700
because the statute
doesn't say even the way

227
00:11:26,700 --> 00:11:29,338
and we have some statutes
that say expressly,

228
00:11:29,338 --> 00:11:31,689
it's global revenue.

229
00:11:31,690 --> 00:11:33,390
And we have some that says expressly

230
00:11:33,390 --> 00:11:34,590
it's California revenue.

231
00:11:35,680 --> 00:11:39,329
And therefore, in this
particular law, I think

232
00:11:39,330 --> 00:11:41,960
for a compliance program, it's best

233
00:11:41,960 --> 00:11:45,034
to assume once you cross
25 million, you're in,

234
00:11:45,034 --> 00:11:48,960
even though if you're
litigating this, you might

235
00:11:48,960 --> 00:11:53,220
be able to claim that only
California revenue counts

236
00:11:53,220 --> 00:11:54,790
and then of course, we'll have to decide

237
00:11:54,790 --> 00:11:56,990
that the attorney general
was not willing to decide

238
00:11:56,990 --> 00:12:00,250
in the regulations, because
it would have been overriding

239
00:12:00,250 --> 00:12:02,363
this statutory board.

240
00:12:04,120 --> 00:12:07,170
The second threshold would be
even if you have less revenue

241
00:12:07,170 --> 00:12:11,510
if you have more than 50,000 records,

242
00:12:11,510 --> 00:12:13,450
this will actually go
up to a hundred thousand

243
00:12:13,450 --> 00:12:18,020
as of January one, 2023
,because people have pointed out

244
00:12:18,950 --> 00:12:22,065
that that is a really small number.

245
00:12:22,065 --> 00:12:24,610
If you get 137 hits on your website a day

246
00:12:24,610 --> 00:12:27,300
that adds up for 50,000 a year.

247
00:12:27,300 --> 00:12:30,079
And so that will be increased a little bit

248
00:12:30,080 --> 00:12:33,270
but also open a lot of
companies given the definition

249
00:12:33,270 --> 00:12:35,840
of personal information is so broad.

250
00:12:35,840 --> 00:12:38,560
And then 50% or more annual revenue

251
00:12:38,560 --> 00:12:42,949
from selling California
residents person information.

252
00:12:42,950 --> 00:12:45,500
This definition of selling
we'll come back to in a minute,

253
00:12:45,500 --> 00:12:49,710
is very counterintuitive
and some say designed

254
00:12:49,710 --> 00:12:51,920
to be misleading, to trick people

255
00:12:51,920 --> 00:12:55,507
at the ballot initiative,
popular initiative

256
00:12:55,508 --> 00:12:59,010
by giving the impression
this is cash for data.

257
00:12:59,010 --> 00:13:00,790
That's much broader definition.

258
00:13:00,790 --> 00:13:02,110
We'll get to that in a second,

259
00:13:02,110 --> 00:13:04,210
but this could open very small companies

260
00:13:04,210 --> 00:13:06,030
that even have very little data,

261
00:13:06,030 --> 00:13:07,740
but they want to make a business

262
00:13:07,740 --> 00:13:10,160
out of sharing information
for consideration.

263
00:13:10,160 --> 00:13:13,310
Last not least, pointing
out that parent companies

264
00:13:13,310 --> 00:13:15,300
and subsidiaries sharing the same branding

265
00:13:15,300 --> 00:13:16,772
are the same business.

266
00:13:18,080 --> 00:13:21,880
They may be roped into the law
which is possibly perceived

267
00:13:21,880 --> 00:13:24,733
to be a bad thing, if you
have a parent company out

268
00:13:24,733 --> 00:13:25,953
in Japan or Germany or some other place

269
00:13:25,953 --> 00:13:30,170
that is not otherwise paying
attention to California laws.

270
00:13:30,170 --> 00:13:31,140
But it could be a good thing

271
00:13:31,140 --> 00:13:33,900
in the sense that I believe
those companies can share

272
00:13:33,900 --> 00:13:36,279
with each other without the
restrictions of this law

273
00:13:36,279 --> 00:13:39,610
because they are the business
and not a third party

274
00:13:39,610 --> 00:13:43,000
and only selling to
third parties qualifies

275
00:13:43,000 --> 00:13:46,893
for the various triggers on how to comply.

276
00:13:49,070 --> 00:13:53,350
Now, when we look at
what the law requires you

277
00:13:53,350 --> 00:13:57,180
to do, we will find a large laundry list

278
00:13:57,180 --> 00:13:59,459
of things that companies have to do.

279
00:13:59,460 --> 00:14:02,520
But many of the requirements are triggered

280
00:14:02,520 --> 00:14:04,937
by whether the company's selling

281
00:14:04,937 --> 00:14:09,070
and then under CPRA, also
sharing personal information.

282
00:14:09,070 --> 00:14:12,205
And these definitions
are somewhat confusing.

283
00:14:12,205 --> 00:14:16,180
And I think intentionally
picked to be misleading

284
00:14:17,210 --> 00:14:19,960
because these were valid
initiatives that were to

285
00:14:19,960 --> 00:14:21,826
be decided by voters.

286
00:14:21,826 --> 00:14:23,220
They were made to think
this is a consumer law

287
00:14:23,220 --> 00:14:26,676
and it's about companies,
evil, getting cash for data

288
00:14:26,676 --> 00:14:29,660
which is only a part of it.

289
00:14:29,660 --> 00:14:32,660
So selling is defined to be any exchange

290
00:14:32,660 --> 00:14:33,550
of person information

291
00:14:33,550 --> 00:14:35,853
for any consideration that is valuable.

292
00:14:37,130 --> 00:14:39,431
Every contract by destination

293
00:14:39,431 --> 00:14:43,703
under US law involves consideration,
exchange for promises.

294
00:14:44,870 --> 00:14:46,480
So data sharing information

295
00:14:46,480 --> 00:14:49,243
for receiving information is don't.

296
00:14:50,810 --> 00:14:55,540
A company that is getting
some other benefit

297
00:14:55,540 --> 00:14:57,130
from giving information,

298
00:14:57,130 --> 00:14:59,290
let's say providing contact information

299
00:14:59,290 --> 00:15:00,900
to resellers so that they market

300
00:15:00,900 --> 00:15:05,040
to somebody would be selling
personal information.

301
00:15:05,040 --> 00:15:07,956
Even giving personal information
to a service provider

302
00:15:07,956 --> 00:15:10,820
would be selling personal information

303
00:15:10,820 --> 00:15:12,880
unless an exception applies.

304
00:15:12,880 --> 00:15:14,797
There are some exceptions.

305
00:15:14,797 --> 00:15:17,250
One is that if the service provider agrees

306
00:15:17,250 --> 00:15:18,430
that they will not sell it

307
00:15:18,430 --> 00:15:21,410
that they'll only use it to
provide a service and a number

308
00:15:21,410 --> 00:15:24,709
of other requirements, then
that would not be selling.

309
00:15:24,710 --> 00:15:26,540
But otherwise the default is,

310
00:15:26,540 --> 00:15:28,800
if you're sharing
information your selling,

311
00:15:28,800 --> 00:15:31,188
that is intended, and that is one

312
00:15:31,188 --> 00:15:33,900
of the key focus areas of
the statute, not the only one

313
00:15:33,900 --> 00:15:35,399
but that is a key one.

314
00:15:35,399 --> 00:15:38,858
And in the future they will be added

315
00:15:38,858 --> 00:15:41,069
a definition of sharing.

316
00:15:41,070 --> 00:15:42,910
Now, sharing sounds super broad

317
00:15:43,910 --> 00:15:46,660
but it's defined extremely narrowly

318
00:15:46,660 --> 00:15:50,060
to mean, sharing, disclosing

319
00:15:50,060 --> 00:15:52,569
for cross context behavioral advertising.

320
00:15:52,570 --> 00:15:54,100
I think that was a reaction

321
00:15:54,100 --> 00:15:57,440
to some industry bodies taken the position

322
00:15:57,440 --> 00:16:00,927
that somehow sharing personal
information, IP address,

323
00:16:00,927 --> 00:16:05,050
and so on for ad networks,
with double blind hashing

324
00:16:05,050 --> 00:16:08,890
and so on wasn't gonna be covered by CCPA.

325
00:16:08,890 --> 00:16:10,699
I'm not sure that that was even true

326
00:16:10,700 --> 00:16:13,480
and therefore that this
addition is necessary

327
00:16:13,480 --> 00:16:16,730
but whatever it is that
is now also in the law

328
00:16:16,730 --> 00:16:18,120
and if you're doing it,

329
00:16:18,120 --> 00:16:19,530
then you have to put a link,

330
00:16:19,530 --> 00:16:21,089
do not sell my personal information

331
00:16:21,090 --> 00:16:23,500
or after January one 2023, do not sell

332
00:16:23,500 --> 00:16:26,120
or share my personal information.

333
00:16:26,120 --> 00:16:28,043
And if somebody clicks on that link

334
00:16:28,043 --> 00:16:29,680
there has to be an opt out page

335
00:16:29,680 --> 00:16:33,290
and people can basically say

336
00:16:33,290 --> 00:16:34,920
that they don't want this to be happening

337
00:16:34,920 --> 00:16:36,229
to their data anymore.

338
00:16:36,230 --> 00:16:38,610
If they do it, then you
as a company still have

339
00:16:38,610 --> 00:16:40,130
to offer the same kind of service,

340
00:16:40,130 --> 00:16:42,716
you can't punish people,
discriminate against them

341
00:16:42,716 --> 00:16:46,960
if they're opting out, that
means any sharing that is going

342
00:16:46,960 --> 00:16:49,130
on in your business that
is necessary, let's say

343
00:16:49,130 --> 00:16:51,470
with your cloud provider infrastructure

344
00:16:51,470 --> 00:16:54,230
other things where you
don't have any alternatives,

345
00:16:54,230 --> 00:16:56,700
you have to make sure
that that doesn't qualify

346
00:16:56,700 --> 00:16:59,270
as something that people
can opt out subject

347
00:16:59,270 --> 00:17:01,130
to anti-discrimination prohibitions

348
00:17:01,130 --> 00:17:03,420
because if they're opting
out, you still have

349
00:17:03,420 --> 00:17:05,889
to provide the same service to them.

350
00:17:05,890 --> 00:17:08,210
Also, wherever you're doing this

351
00:17:08,210 --> 00:17:10,606
that you think qualifies
the selling, you have

352
00:17:10,606 --> 00:17:12,280
to make sure that you're
getting opt in consent

353
00:17:12,280 --> 00:17:14,453
from children under 16.

354
00:17:16,040 --> 00:17:21,040
Kids between 13 and not yet
16, you can get the consent

355
00:17:21,540 --> 00:17:23,200
from them.

356
00:17:23,200 --> 00:17:25,560
Anybody under 13 you have
to get parental consent

357
00:17:25,560 --> 00:17:27,772
which is already required
in a federal law.

358
00:17:29,160 --> 00:17:31,160
But that is a pretty tough requirement

359
00:17:31,160 --> 00:17:33,490
for example, for companies that work

360
00:17:33,490 --> 00:17:38,490
on automated, autonomous driving,

361
00:17:38,560 --> 00:17:41,040
where cameras capture
whoever's in the traffic,

362
00:17:41,040 --> 00:17:42,786
and there may be some children

363
00:17:42,786 --> 00:17:45,170
and it would be very
difficult to get their consent

364
00:17:45,170 --> 00:17:47,100
in writing and with all the requirements

365
00:17:47,100 --> 00:17:50,179
that the CCPA imposes on people.

366
00:17:50,180 --> 00:17:51,770
Which probably has as a consequence

367
00:17:51,770 --> 00:17:53,910
that certain technologies
can't be developed

368
00:17:53,910 --> 00:17:55,630
or used in California anymore

369
00:17:55,630 --> 00:17:58,900
and we'll have to go elsewhere
in order to be successful

370
00:17:58,900 --> 00:18:02,943
in engaging in those kind
of innovation activities.

371
00:18:05,390 --> 00:18:10,310
Now, the big question now is
for companies how do you stop

372
00:18:10,310 --> 00:18:12,909
this selling so broadly
defined, we're living

373
00:18:12,910 --> 00:18:14,575
in a sharing economy.

374
00:18:14,575 --> 00:18:17,940
America is all about free
speech, freedom of information

375
00:18:17,940 --> 00:18:21,880
collaboration, competition,
open networks, open society,

376
00:18:21,880 --> 00:18:24,620
open data, open source,
software licensing.

377
00:18:24,620 --> 00:18:29,310
CJ, what do you do in a company
in order to get everybody

378
00:18:29,310 --> 00:18:33,300
on board with the decision
to either engage in selling

379
00:18:33,300 --> 00:18:34,409
and offering this link

380
00:18:34,410 --> 00:18:36,640
and supporting all this opt out rights

381
00:18:36,640 --> 00:18:39,500
or cutting out any kind of selling

382
00:18:39,500 --> 00:18:40,820
or sharing of information.

383
00:18:40,820 --> 00:18:42,312
What do you do practically?

384
00:18:44,030 --> 00:18:46,560
- Well, I think as a
company you need to sit down

385
00:18:46,560 --> 00:18:51,300
with your executives or your
board or your management team

386
00:18:51,300 --> 00:18:54,340
and discuss with them
what the pros and cons are

387
00:18:54,340 --> 00:18:57,600
with selling or not selling
the personal information.

388
00:18:57,600 --> 00:18:59,389
Once your company has made a decision

389
00:18:59,390 --> 00:19:02,930
on how they use the data
and which avenue they wish

390
00:19:02,930 --> 00:19:06,640
to pursue, given the business
needs and the business usage

391
00:19:06,640 --> 00:19:09,720
then you need to work with
your different business teams

392
00:19:09,720 --> 00:19:11,888
or your business units to make sure

393
00:19:11,888 --> 00:19:16,000
that there's proper
contract provisions in place

394
00:19:16,000 --> 00:19:18,640
that makes sure that you
are reviewing the vendors

395
00:19:18,640 --> 00:19:21,700
that are being used for
service providers to make sure

396
00:19:21,700 --> 00:19:24,510
that you have the proper
precautions in place

397
00:19:24,510 --> 00:19:25,560
for whether you sell

398
00:19:25,560 --> 00:19:28,474
or do not sell the personal information.

399
00:19:28,474 --> 00:19:31,159
You need to train the
different business units

400
00:19:31,160 --> 00:19:32,240
or business teams.

401
00:19:32,240 --> 00:19:34,594
However, you refer to
them in your company.

402
00:19:34,594 --> 00:19:39,594
As to the importance of this
and why you need to review it

403
00:19:39,720 --> 00:19:42,280
and you need to work with
them to make sure that they

404
00:19:42,280 --> 00:19:46,260
are following which choice the
company has made to pursue.

405
00:19:46,260 --> 00:19:49,500
And, you know, just training
all around just awareness

406
00:19:49,500 --> 00:19:52,020
and training is a big
factor in making sure

407
00:19:52,020 --> 00:19:54,520
that people understand that
this is an important aspect

408
00:19:54,520 --> 00:19:55,353
of the law.

409
00:19:57,770 --> 00:20:00,730
- I think this is very important takeaway

410
00:20:00,730 --> 00:20:03,100
from our session here today.

411
00:20:03,100 --> 00:20:06,209
This threshold is the company gonna engage

412
00:20:06,210 --> 00:20:07,240
in selling or not?

413
00:20:07,240 --> 00:20:11,253
Put this link on every
single page, website,

414
00:20:11,253 --> 00:20:14,760
mobile app download page and so on.

415
00:20:14,760 --> 00:20:17,600
And then support all this opting
out without discrimination

416
00:20:17,600 --> 00:20:20,580
without being able to
charge people requires a lot

417
00:20:20,580 --> 00:20:22,497
of effort within the company.

418
00:20:22,498 --> 00:20:25,208
My sense is that it's still
easier for most companies.

419
00:20:25,208 --> 00:20:28,840
I worked for about 200
companies, some really large

420
00:20:28,840 --> 00:20:30,790
some really small, some are international,

421
00:20:30,790 --> 00:20:33,290
some are California headquartered,

422
00:20:33,290 --> 00:20:36,170
and of my clients, less than 10 decided

423
00:20:36,170 --> 00:20:37,600
to put this link on their website.

424
00:20:37,600 --> 00:20:39,050
And they worked along the lines

425
00:20:39,050 --> 00:20:42,340
of what CJ is saying and
trying to eliminate selling.

426
00:20:42,340 --> 00:20:44,669
I think that it's still
the easier way to go.

427
00:20:44,670 --> 00:20:47,900
But some companies can't
do that because some form

428
00:20:47,900 --> 00:20:50,792
of digital advertising
retargeting your site

429
00:20:50,792 --> 00:20:53,793
is really considered miscritical,
or that is their business

430
00:20:53,794 --> 00:20:57,500
and they will have to work
into this different direction.

431
00:20:57,500 --> 00:21:00,680
But, it absolutely
doesn't make sense to turn

432
00:21:00,680 --> 00:21:02,660
to all these other compliance requirements

433
00:21:02,660 --> 00:21:04,210
before you made that decision.

434
00:21:04,210 --> 00:21:08,750
And before you have the
executive support for that

435
00:21:08,750 --> 00:21:11,023
because it will be painful either way.

436
00:21:12,152 --> 00:21:14,040
And if you're changing
course halfway through

437
00:21:14,040 --> 00:21:16,222
it will become unmanageable.

438
00:21:16,222 --> 00:21:18,250
Particularly since we pointed
out, this is one of hundreds

439
00:21:18,250 --> 00:21:20,630
of different privacy laws that
every company has to comply

440
00:21:20,630 --> 00:21:24,400
with in California in other countries.

441
00:21:24,400 --> 00:21:27,760
And what you develop for
Europe will not work exactly

442
00:21:27,760 --> 00:21:29,823
one-on-one for this California law.

443
00:21:30,660 --> 00:21:32,790
So here's some other things
that need to be done.

444
00:21:32,790 --> 00:21:35,300
You have to give privacy notices.

445
00:21:35,300 --> 00:21:40,020
And the California consumer
privacy act is trying

446
00:21:40,020 --> 00:21:44,443
to standardize this by
telling companies pretty

447
00:21:44,443 --> 00:21:47,200
prescriptively what they have to say

448
00:21:47,200 --> 00:21:48,460
in their privacy notices.

449
00:21:48,460 --> 00:21:51,590
I think that is a lot of objective

450
00:21:51,590 --> 00:21:53,350
because people are confused

451
00:21:53,350 --> 00:21:55,149
and you get all these
different privacy notices

452
00:21:55,150 --> 00:21:57,538
and they're kind of hard
to compare to each other.

453
00:21:57,538 --> 00:21:58,990
Everybody uses different terminology.

454
00:21:58,990 --> 00:22:02,950
And so if California was
the government of the world

455
00:22:02,950 --> 00:22:07,950
and not one of 50 States in
one country of 192 countries,

456
00:22:08,890 --> 00:22:10,060
then it would make sense to

457
00:22:10,060 --> 00:22:13,720
tell everybody privacy notices
have to look comparably

458
00:22:13,720 --> 00:22:14,820
and to be the same,

459
00:22:14,820 --> 00:22:18,669
of course, California
is just one state one

460
00:22:18,670 --> 00:22:20,390
of the largest economies in the world

461
00:22:20,390 --> 00:22:22,900
but it's just one state and
companies have to still comply

462
00:22:22,900 --> 00:22:25,460
with all these other requirements.

463
00:22:25,460 --> 00:22:27,770
And unfortunately, Nevada, Virginia

464
00:22:27,770 --> 00:22:30,850
and other States will not
follow California One-on-one

465
00:22:30,850 --> 00:22:32,939
on this, fortunately, or unfortunately.

466
00:22:32,940 --> 00:22:34,910
In the sense that there will be variety.

467
00:22:34,910 --> 00:22:37,370
So I recommend the
companies develop separate

468
00:22:37,370 --> 00:22:39,610
supplemental privacy
notices for California

469
00:22:39,610 --> 00:22:40,770
where you exactly worked

470
00:22:40,770 --> 00:22:43,200
through what the California law requires.

471
00:22:43,200 --> 00:22:46,650
And don't try to update
your general privacy notice.

472
00:22:46,650 --> 00:22:49,430
That will be confusing
for people in other States

473
00:22:49,430 --> 00:22:51,890
because the California terminology selling

474
00:22:51,890 --> 00:22:55,290
for example, means something
different, pretty much

475
00:22:55,290 --> 00:22:57,036
anywhere else in the world.

476
00:22:57,036 --> 00:22:58,780
Even under, under California statutes.

477
00:22:58,780 --> 00:23:02,899
If you write into your
general privacy notice, we

478
00:23:02,900 --> 00:23:06,190
do not sell and will not
sell personal information

479
00:23:06,190 --> 00:23:08,570
and then you engage in
an M and A transaction

480
00:23:08,570 --> 00:23:11,399
or lo and behold, an insolvency,

481
00:23:11,400 --> 00:23:13,090
and you have to transfer data.

482
00:23:13,090 --> 00:23:15,169
You would probably be
prohibited from doing that.

483
00:23:15,170 --> 00:23:17,200
In California, there is an exception

484
00:23:17,200 --> 00:23:18,980
for reorganization bankruptcy

485
00:23:18,980 --> 00:23:21,240
in this very lengthy and complex law

486
00:23:21,240 --> 00:23:22,955
but that wouldn't be implied

487
00:23:22,955 --> 00:23:25,460
under the law of Virginia or other States.

488
00:23:25,460 --> 00:23:28,490
And therefore you'd have to
look at the local definitions

489
00:23:28,490 --> 00:23:30,060
and I think the best way to deal with

490
00:23:30,060 --> 00:23:33,165
that is to post supplemental
privacy notices.

491
00:23:33,165 --> 00:23:35,481
Same is true for privacy
notice to employees.

492
00:23:35,481 --> 00:23:38,680
RSA is very much focused on security

493
00:23:38,680 --> 00:23:42,400
and I think it's important
that you preserve the ability

494
00:23:42,400 --> 00:23:44,270
for companies to monitor employees.

495
00:23:44,270 --> 00:23:47,310
And so you don't want to
create privacy expectations

496
00:23:47,310 --> 00:23:49,780
that the employees would then use

497
00:23:49,780 --> 00:23:53,970
to thwart internally
investigations, deployment

498
00:23:53,970 --> 00:23:56,820
of monitoring software
and other technologies.

499
00:23:56,820 --> 00:23:59,700
And so I wouldn't give
the same privacy notices

500
00:23:59,700 --> 00:24:02,010
to Americans and other States,

501
00:24:02,010 --> 00:24:04,330
and you can't even get
the same privacy notices

502
00:24:04,330 --> 00:24:05,540
to people in other countries.

503
00:24:05,540 --> 00:24:08,023
They have to do supplemental
privacy notices.

504
00:24:09,220 --> 00:24:10,690
Here is a long list of other things.

505
00:24:10,690 --> 00:24:12,860
We won't cover all of them

506
00:24:12,860 --> 00:24:17,860
but we want to give you
this as a working checklist

507
00:24:18,350 --> 00:24:20,270
and jump to the last one,

508
00:24:20,270 --> 00:24:22,980
Implement reasonable security measures.

509
00:24:22,980 --> 00:24:27,480
Now, this is not
prescribed by the statute.

510
00:24:27,480 --> 00:24:30,730
It doesn't say anywhere
in CCPA specific you must

511
00:24:30,730 --> 00:24:32,780
have reasonable security measures.

512
00:24:32,780 --> 00:24:36,100
It's possible that the
new California privacy

513
00:24:36,100 --> 00:24:38,639
protection agency, that is something that

514
00:24:38,640 --> 00:24:42,490
is created right now,
the initial board members

515
00:24:42,490 --> 00:24:43,420
have been named.

516
00:24:43,420 --> 00:24:46,520
That they will put some
requirements on companies

517
00:24:46,520 --> 00:24:48,100
and there are other California laws

518
00:24:48,100 --> 00:24:50,416
that already required reasonable security

519
00:24:50,416 --> 00:24:54,399
and when Kamala Harris
was the attorney general

520
00:24:54,400 --> 00:24:59,400
in her 2016 data breach
report, she suggested

521
00:25:00,210 --> 00:25:02,210
what reasonable security
means, and I think

522
00:25:02,210 --> 00:25:04,830
that's what the California
attorney general would also refer

523
00:25:04,830 --> 00:25:06,840
to in connection with this law.

524
00:25:06,840 --> 00:25:09,270
But there's no positive obligation yet,

525
00:25:09,270 --> 00:25:11,900
it is severe liability for companies

526
00:25:11,900 --> 00:25:14,730
that have a security breach,
unless they can prove

527
00:25:14,730 --> 00:25:16,710
they have reasonable security.

528
00:25:16,710 --> 00:25:19,755
So it's very important to
have that and to document that

529
00:25:19,755 --> 00:25:22,220
and make sure, and CJ
and I were just talking

530
00:25:22,220 --> 00:25:24,830
about, I have a number of clients now

531
00:25:24,830 --> 00:25:29,830
that engage cyber security or
data security professionals

532
00:25:31,610 --> 00:25:32,780
to audit the company,

533
00:25:32,780 --> 00:25:35,230
but they want that to be
attorney client privilege

534
00:25:35,230 --> 00:25:38,710
in case something horrible
is being uncovered.

535
00:25:38,710 --> 00:25:42,890
And so I'm working through with
some clients that want to go

536
00:25:42,890 --> 00:25:47,440
and prevent creating a
roadmap for private plaintiff

537
00:25:47,440 --> 00:25:50,640
or a regulator by doing a gap assessment,

538
00:25:50,640 --> 00:25:51,850
which then sits around

539
00:25:52,827 --> 00:25:54,470
and if a breach happens
would prove basically

540
00:25:54,470 --> 00:25:56,840
the company didn't have
reasonable security.

541
00:25:56,840 --> 00:26:00,419
And so the way we're
doing it is I'm directing

542
00:26:00,420 --> 00:26:02,830
the forensic investigators

543
00:26:02,830 --> 00:26:05,000
or the cybersecurity experts

544
00:26:05,000 --> 00:26:07,300
to create a positive description

545
00:26:07,300 --> 00:26:10,528
of technic and organization
security measures.

546
00:26:10,528 --> 00:26:14,610
And this would be a
measure that we could show

547
00:26:14,610 --> 00:26:17,240
as a defense and say, Hey,
we had all these good things.

548
00:26:17,240 --> 00:26:19,620
Of course, there will be
some gaps and vulnerabilities

549
00:26:19,620 --> 00:26:23,260
and I'm asking the professionals
to report those to me.

550
00:26:23,260 --> 00:26:26,660
I would then provide attorney
client privilege legal advice

551
00:26:26,660 --> 00:26:27,950
to the company to say

552
00:26:27,950 --> 00:26:31,230
here's some recommendations
that should probably be fixed.

553
00:26:31,230 --> 00:26:34,600
And if the company is just
saying, yeah, let's do it.

554
00:26:34,600 --> 00:26:38,330
Then we would create a work stream where

555
00:26:38,330 --> 00:26:39,370
this is being worked on.

556
00:26:39,370 --> 00:26:41,010
That wouldn't be privileged obviously,

557
00:26:41,010 --> 00:26:42,797
that would just be work

558
00:26:42,797 --> 00:26:45,104
and the consultants
would advise what to do.

559
00:26:45,104 --> 00:26:47,940
If the company says no way,
we don't have money for this

560
00:26:47,940 --> 00:26:50,742
then it's probably better
not to have it in writing

561
00:26:50,742 --> 00:26:54,930
and maybe have a
conversation with the board

562
00:26:54,930 --> 00:26:56,710
or with the executive
management to impress

563
00:26:56,710 --> 00:26:58,662
on them how important that is

564
00:26:58,662 --> 00:27:00,300
and then start reducing
things dividing once

565
00:27:00,300 --> 00:27:01,840
there's a willingness to address it.

566
00:27:01,840 --> 00:27:06,149
Unfortunately, I have some
clients that didn't follow this

567
00:27:06,150 --> 00:27:07,430
and then we have a breach

568
00:27:07,430 --> 00:27:10,695
and then the plaintiffs are
demanding to see these reports

569
00:27:10,695 --> 00:27:14,000
and a number of courts have now held

570
00:27:14,000 --> 00:27:15,730
that the courts won't be privileged just

571
00:27:15,730 --> 00:27:18,220
because when lawyer was
somehow involved in that

572
00:27:18,220 --> 00:27:20,990
if this was created as an
order it means business,

573
00:27:20,990 --> 00:27:25,160
then the company typically has to produce

574
00:27:25,160 --> 00:27:26,210
those kinds of reports.

575
00:27:26,210 --> 00:27:28,460
CJ, you're a very experienced

576
00:27:28,460 --> 00:27:31,610
long term security professional.

577
00:27:31,610 --> 00:27:35,514
How does that process that
I'm describing here sound

578
00:27:35,514 --> 00:27:39,090
to you in terms from a practical
implementation perspective?

579
00:27:39,090 --> 00:27:41,560
- It sounds like a reasonable practice.

580
00:27:41,560 --> 00:27:43,659
However, I do think the audit reports

581
00:27:43,660 --> 00:27:45,426
are a double-edged sword.

582
00:27:45,426 --> 00:27:47,760
They could, you know, help the company

583
00:27:47,760 --> 00:27:49,250
but they could also hurt the company.

584
00:27:49,250 --> 00:27:53,020
And that, first of all, I
do think the gaps do need

585
00:27:53,020 --> 00:27:53,950
to be identified.

586
00:27:53,950 --> 00:27:56,790
I do believe they need to
be in writing for the teams

587
00:27:56,790 --> 00:27:59,754
and for the executives or the
management teams to understand

588
00:27:59,754 --> 00:28:03,919
because a lot of individuals
do not have the IT background

589
00:28:03,920 --> 00:28:06,550
or the IT security awareness.

590
00:28:06,550 --> 00:28:08,649
So I think they need to be in writing.

591
00:28:08,650 --> 00:28:10,680
And then, I think it also should come

592
00:28:10,680 --> 00:28:12,220
from like an auditing firm

593
00:28:12,220 --> 00:28:14,192
or the cybersecurity professionals

594
00:28:14,192 --> 00:28:19,192
so that there's more
cybersecurity bite to it.

595
00:28:19,456 --> 00:28:22,350
And I also think that once
you have that, you can use

596
00:28:22,350 --> 00:28:25,780
that report or that gap analysis
to go to your executives

597
00:28:25,780 --> 00:28:29,024
and your management team to
justify spending the money

598
00:28:29,024 --> 00:28:32,964
for the upgrades or to remediate
any gaps that you find.

599
00:28:32,964 --> 00:28:35,790
Now, if the executive team decides not

600
00:28:35,790 --> 00:28:39,270
to remediate those gaps,
this audit report showing

601
00:28:39,270 --> 00:28:41,660
those gaps and the action or inaction

602
00:28:41,660 --> 00:28:44,620
that they decided upon
would be a bad thing.

603
00:28:44,620 --> 00:28:48,330
However, on the flip side,
if your executive team

604
00:28:48,330 --> 00:28:51,639
or your management team
decides, let's fix those gaps

605
00:28:51,640 --> 00:28:54,190
here's the funding and then even goes

606
00:28:54,190 --> 00:28:56,630
and gets a subsequent audit report done.

607
00:28:56,630 --> 00:28:58,690
It could really exonerate a company

608
00:28:58,690 --> 00:29:01,810
and really show that the company
has taken the sensitivity

609
00:29:01,810 --> 00:29:05,240
of the data seriously and
looked at these gap reports done

610
00:29:05,240 --> 00:29:09,710
by an outside party or an
outside firm to really shore

611
00:29:09,710 --> 00:29:12,793
up their reasonable,
secure security measures.

612
00:29:13,630 --> 00:29:15,510
And they did what was
considered reasonable

613
00:29:15,510 --> 00:29:17,003
by the outside auditors.

614
00:29:17,901 --> 00:29:18,920
So it could really go
either way for the company

615
00:29:18,920 --> 00:29:21,010
but I do think it would
help justify the funding

616
00:29:21,010 --> 00:29:23,473
for the gap assessment remediation.

617
00:29:26,660 --> 00:29:29,100
- I agree my own impression is it makes

618
00:29:29,100 --> 00:29:32,330
the process very bulky or
can make the process bulky.

619
00:29:32,330 --> 00:29:34,060
Also, depending on who's involved

620
00:29:34,060 --> 00:29:36,220
by having the legal department involved.

621
00:29:36,220 --> 00:29:40,510
I try not to be ever a
bottleneck or delayed things

622
00:29:40,510 --> 00:29:43,510
and I'm trying to mitigate that risk

623
00:29:43,510 --> 00:29:45,637
but there is an additional
cost to the company

624
00:29:45,637 --> 00:29:48,389
and there is an additional delay possibly

625
00:29:48,390 --> 00:29:51,430
and some companies want to skip that.

626
00:29:51,430 --> 00:29:53,820
And I think if they don't have a breach

627
00:29:53,820 --> 00:29:56,100
or by the time they
have a breach, they have

628
00:29:56,100 --> 00:29:58,510
the gaps all remedied and
everything is in good order.

629
00:29:58,510 --> 00:30:00,510
Then it probably would have been a waste

630
00:30:00,510 --> 00:30:03,610
of time and a distraction to
involve the lawyers so much.

631
00:30:03,610 --> 00:30:06,790
But if there is a risk that
the board will not approve

632
00:30:06,790 --> 00:30:09,620
whatever spending is deemed necessary

633
00:30:09,620 --> 00:30:12,694
by the outside firm, or if
the outside firm overreaches

634
00:30:12,694 --> 00:30:17,694
or uses, let's say unhelpful
wording in order to try

635
00:30:18,550 --> 00:30:20,889
to impress the urgency on a company

636
00:30:20,890 --> 00:30:22,220
then this could be a time bomb

637
00:30:22,220 --> 00:30:23,650
and could cost the company millions

638
00:30:23,650 --> 00:30:25,930
of dollars later in litigation

639
00:30:25,930 --> 00:30:29,050
and we've had unfortunately
some experiences with that.

640
00:30:29,050 --> 00:30:31,760
So I think that's a
great takeaway from you.

641
00:30:31,760 --> 00:30:34,990
I'll mention a few things
on sanction real quick here

642
00:30:34,990 --> 00:30:38,910
but then once we get some
more takeaways from you, CJ.

643
00:30:38,910 --> 00:30:42,390
So any violation of this
complex law could be sanctioned

644
00:30:42,390 --> 00:30:46,260
by 7,500 per intentional violation.

645
00:30:46,260 --> 00:30:48,610
Most violations will be
intentional in the sense

646
00:30:48,610 --> 00:30:50,310
that the company knew
what they were doing.

647
00:30:50,310 --> 00:30:52,557
It may not appreciate it,
that's a violation of law

648
00:30:52,557 --> 00:30:54,810
but they acted intentionally only

649
00:30:54,810 --> 00:30:56,820
a negligent violation would be where

650
00:30:56,820 --> 00:30:59,980
the company accidentally,
I dunno, didn't post

651
00:30:59,980 --> 00:31:01,380
the link, even though they'd tried

652
00:31:01,380 --> 00:31:03,870
and somebody made a technical error.

653
00:31:03,870 --> 00:31:07,760
The money goes into the
California consumer privacy fund

654
00:31:07,760 --> 00:31:12,760
which will fund further
expansion of enforcement effort.

655
00:31:13,414 --> 00:31:14,840
It will fund this new agency

656
00:31:14,840 --> 00:31:19,840
and it will also give 3% to
nonprofits who are advocating

657
00:31:19,990 --> 00:31:23,140
for privacy to make sure
there continues to be a drive

658
00:31:23,140 --> 00:31:26,203
for more enforcement, more
legislation more data regulation.

659
00:31:27,490 --> 00:31:30,157
There's also a very limited
right of private action just

660
00:31:30,157 --> 00:31:31,460
for security beaches.

661
00:31:31,460 --> 00:31:34,280
If a breach happens and
the company can't prove

662
00:31:34,280 --> 00:31:36,430
that they have reasonable
security procedures,

663
00:31:36,430 --> 00:31:39,053
which is always hard once
you've suffered a breach.

664
00:31:39,980 --> 00:31:43,150
Then, every California resident gets

665
00:31:43,150 --> 00:31:47,410
between 100 to 750 depending
on how severe the violation

666
00:31:47,410 --> 00:31:50,510
or the negligence of the company was.

667
00:31:50,510 --> 00:31:55,510
And that will be putting cost
action lawsuits on steroids

668
00:31:55,750 --> 00:31:59,030
because it solves a number
of problems that the lawyers

669
00:31:59,030 --> 00:32:02,512
so far had with class actions
such as showing any harm

670
00:32:02,512 --> 00:32:05,990
or commonality of the classroom showing

671
00:32:05,990 --> 00:32:07,490
that everybody's harmed in a similar way

672
00:32:07,490 --> 00:32:09,150
and all that is solved with this.

673
00:32:09,150 --> 00:32:11,660
And so we've seen a huge
uptick and litigation.

674
00:32:11,660 --> 00:32:13,810
I'm happy anybody reaching out to me

675
00:32:13,810 --> 00:32:16,040
to share an article where
we gave a little update

676
00:32:16,040 --> 00:32:18,100
on what the litigation has been.

677
00:32:18,100 --> 00:32:20,719
But let's even look at the positive

678
00:32:20,720 --> 00:32:23,180
and see what can we
prevent the half litigation

679
00:32:23,180 --> 00:32:24,013
in the first place?

680
00:32:24,013 --> 00:32:26,570
What are some practical
takeaways from this CJ

681
00:32:26,570 --> 00:32:28,169
that you recommend to companies?

682
00:32:29,720 --> 00:32:31,770
- Well, let's start with
some short-term goals

683
00:32:31,770 --> 00:32:35,910
that practitioners and
professionals should consider.

684
00:32:35,910 --> 00:32:38,120
First of all, you need to
look at your company look

685
00:32:38,120 --> 00:32:39,833
at your data usage and see

686
00:32:39,834 --> 00:32:42,653
if you have what is
considered reasonable security

687
00:32:42,653 --> 00:32:45,650
for the data that your
company is handling.

688
00:32:45,650 --> 00:32:48,380
Especially personal
information, personal data.

689
00:32:48,380 --> 00:32:51,090
This requires you to know the sensitivity

690
00:32:51,090 --> 00:32:52,679
of the personal information that is

691
00:32:52,680 --> 00:32:55,254
in your company's possession.

692
00:32:55,254 --> 00:32:58,073
Another avenue you should
think about is looking

693
00:32:58,074 --> 00:33:01,770
at consumer log-in
credentials and making sure

694
00:33:01,770 --> 00:33:03,480
that the consumer login credentials

695
00:33:03,480 --> 00:33:07,469
and the prompting questions
that go with those

696
00:33:07,469 --> 00:33:11,690
are secure as well because
that's considered a breach.

697
00:33:11,690 --> 00:33:15,193
If those are breached or are disclosed.

698
00:33:16,120 --> 00:33:16,953
You also need to look

699
00:33:16,953 --> 00:33:19,070
at your company's policies, procedures

700
00:33:19,070 --> 00:33:22,250
and security controls
around the handling of data,

701
00:33:22,250 --> 00:33:25,710
the safe data handling, data hygiene.

702
00:33:25,710 --> 00:33:30,120
To make sure that you have all
your aspects covered as far

703
00:33:30,120 --> 00:33:32,943
as the sensitive data
and where it's located.

704
00:33:34,060 --> 00:33:36,399
Also, you have to get involved
in your risk management

705
00:33:36,400 --> 00:33:37,891
with your third parties

706
00:33:37,891 --> 00:33:40,210
or your vendor risk management,

707
00:33:40,210 --> 00:33:42,180
however, it's set up with your company.

708
00:33:42,180 --> 00:33:44,810
You must exercise due
diligence in this regard

709
00:33:44,810 --> 00:33:47,419
and that in the contract
terms, you need to flow through

710
00:33:47,420 --> 00:33:49,670
the requirements for
the security obligations

711
00:33:49,670 --> 00:33:53,164
and the privacy obligations
as necessary under the law.

712
00:33:53,164 --> 00:33:55,770
And to make sure that
there's no selling going on

713
00:33:55,770 --> 00:33:59,344
if that is the goal that
your company has taken.

714
00:33:59,344 --> 00:34:04,344
So moving on to short and
more intermediate term goals.

715
00:34:04,830 --> 00:34:06,550
You need to make sure your data mapping

716
00:34:06,550 --> 00:34:08,650
or your data inventory is up to date.

717
00:34:08,650 --> 00:34:11,100
This way you know, the
sensitivity of the data,

718
00:34:11,100 --> 00:34:13,969
where it's going, what
service providers are involved

719
00:34:13,969 --> 00:34:16,009
and in what form the data is transferred

720
00:34:16,010 --> 00:34:18,040
to your service providers.

721
00:34:18,040 --> 00:34:19,920
You also need to sit
down with your executives

722
00:34:19,920 --> 00:34:21,730
or your management team and talk to them

723
00:34:21,730 --> 00:34:24,960
about these new changes in
the law, what is required

724
00:34:24,960 --> 00:34:27,560
and to really drive the point
home, what the sanctions are

725
00:34:27,560 --> 00:34:29,489
for non-compliance.

726
00:34:29,489 --> 00:34:31,270
A lot of times the dollar symbols

727
00:34:31,270 --> 00:34:34,060
or the money involved really impresses

728
00:34:34,060 --> 00:34:38,799
upon your management team, the
importance of these actions.

729
00:34:38,800 --> 00:34:39,780
You also need to sit down

730
00:34:39,780 --> 00:34:41,620
with your information technology teams

731
00:34:41,620 --> 00:34:43,219
or your IT security team

732
00:34:43,219 --> 00:34:46,290
or however it's structured
within your company to talk

733
00:34:46,290 --> 00:34:49,167
to them about security
controls and protections

734
00:34:49,167 --> 00:34:51,980
and to really discuss with them the type

735
00:34:51,980 --> 00:34:54,199
of data you have, where it's located

736
00:34:54,199 --> 00:34:55,460
and the sensitivity of it

737
00:34:55,460 --> 00:34:57,923
or the classification that
you use for your data.

738
00:34:58,820 --> 00:35:01,480
Also to be mentioned, the right of cure

739
00:35:01,480 --> 00:35:04,205
was effectively dissolved with CPRA

740
00:35:04,205 --> 00:35:07,950
and Lothar will talk
about that in one second.

741
00:35:07,950 --> 00:35:10,430
And you also just need to
examine your privacy notice

742
00:35:10,430 --> 00:35:12,740
to make sure it's accurate and up-to-date.

743
00:35:12,740 --> 00:35:15,419
So, Lothar could you
discuss the right to cure

744
00:35:15,420 --> 00:35:17,543
and what happened with it with CPRA?

745
00:35:19,020 --> 00:35:21,570
- I mean, the idea of
this right to cure was

746
00:35:21,570 --> 00:35:25,610
for the more formal violations.

747
00:35:25,610 --> 00:35:30,610
And because this was a originally
valid initiative in 2018

748
00:35:31,260 --> 00:35:34,400
and then in a very rushed
legislative process turned

749
00:35:34,400 --> 00:35:35,910
into law.

750
00:35:35,910 --> 00:35:38,020
It wasn't changed and so it looked like

751
00:35:38,020 --> 00:35:41,400
the right to cure would
apply in security breaches

752
00:35:41,400 --> 00:35:43,670
and people were asking you
to say like how do you cure

753
00:35:43,670 --> 00:35:48,120
after you already suffered a breach?

754
00:35:48,120 --> 00:35:51,660
And so this was basically
corrected, which means

755
00:35:53,610 --> 00:35:57,570
if you have a security breach,
then the damage has happened

756
00:35:57,570 --> 00:35:59,980
then you'll have to deal
with the notifications

757
00:35:59,980 --> 00:36:03,173
and at that point you
probably can't cure anymore.

758
00:36:05,340 --> 00:36:07,130
- That's a good point.

759
00:36:07,130 --> 00:36:09,230
So moving on to some more action items

760
00:36:09,230 --> 00:36:11,010
for your intermediate goals.

761
00:36:11,010 --> 00:36:13,560
You must provide training
for your stakeholders

762
00:36:13,560 --> 00:36:15,870
and for your business
units, on how to respond

763
00:36:15,870 --> 00:36:18,220
to consumer requests that come in

764
00:36:18,220 --> 00:36:22,500
and what is required under CCPA/CPRA?

765
00:36:22,500 --> 00:36:26,290
You also need to think
ahead about employees

766
00:36:26,290 --> 00:36:28,410
and business to business.

767
00:36:28,410 --> 00:36:30,990
And have you briefed your
leadership on the changes

768
00:36:30,990 --> 00:36:33,870
for these employees and business
to business transactions

769
00:36:33,870 --> 00:36:36,699
and have you prepared your
processes accordingly?

770
00:36:36,699 --> 00:36:39,930
Once again I commented earlier
on the vendor contracts

771
00:36:39,930 --> 00:36:43,100
to make sure you are updating
your contracts to flow

772
00:36:43,100 --> 00:36:45,430
through the service provider
security requirements

773
00:36:45,430 --> 00:36:48,027
as well as your seller,
do not sell requirements.

774
00:36:48,027 --> 00:36:51,882
And also just to review
other state privacy laws

775
00:36:51,882 --> 00:36:54,830
as they are passed, or
as they come through such

776
00:36:54,830 --> 00:36:57,319
as Virginia, to determine
if your company is

777
00:36:57,320 --> 00:37:00,163
in scope for that law
and the jurisdiction.

778
00:37:02,050 --> 00:37:04,880
And here is just a few more
intermediate and long-term goals

779
00:37:04,880 --> 00:37:07,640
that you should be working
towards in your company.

780
00:37:07,640 --> 00:37:09,850
You need to work towards data minimization

781
00:37:09,850 --> 00:37:12,200
and purpose limitation with your data.

782
00:37:12,200 --> 00:37:16,180
In other words, make sure your
company is not data hoarding.

783
00:37:16,180 --> 00:37:18,089
And that's a huge undertaking

784
00:37:18,089 --> 00:37:21,740
that is probably gonna take
a long time to get into place

785
00:37:21,740 --> 00:37:24,368
and to make sure that you
are following through with.

786
00:37:24,368 --> 00:37:26,390
This could include the beginning

787
00:37:26,390 --> 00:37:30,750
of a data retention policy and process

788
00:37:30,750 --> 00:37:32,950
and then just working towards making sure

789
00:37:32,950 --> 00:37:35,220
that you're using the data
for the purpose that you state

790
00:37:35,220 --> 00:37:36,689
that you're using the data for,

791
00:37:36,690 --> 00:37:38,180
and that your company does not retain it

792
00:37:38,180 --> 00:37:41,540
for longer than you state or is necessary.

793
00:37:41,540 --> 00:37:43,453
Just to eliminate the data hoarding.

794
00:37:45,550 --> 00:37:47,550
- Now, the data hoarding

795
00:37:48,680 --> 00:37:53,654
for the privacy advocates
is creating valuable assets

796
00:37:53,654 --> 00:37:56,450
for the data scientists.

797
00:37:56,450 --> 00:37:59,250
At a time when we're really shifting

798
00:37:59,250 --> 00:38:04,250
from programming computers with
the directional instructions

799
00:38:05,490 --> 00:38:07,279
to machine learning.

800
00:38:07,280 --> 00:38:09,453
We need huge amounts of data sets.

801
00:38:10,420 --> 00:38:15,420
And I find in practice
companies are suffering a lot

802
00:38:16,778 --> 00:38:19,830
of harm right now, where they
hiring separate privacy teams

803
00:38:19,830 --> 00:38:22,810
who may not be as in tune with the needs

804
00:38:22,810 --> 00:38:25,560
of the company long term for innovation

805
00:38:25,560 --> 00:38:28,080
and make promises about data minimization

806
00:38:28,080 --> 00:38:31,870
or fail to handle what the purposes

807
00:38:31,870 --> 00:38:34,759
of their data collection is practically

808
00:38:34,760 --> 00:38:37,000
and find themselves at real conflict

809
00:38:37,000 --> 00:38:40,230
where they actually have
a good amount of data

810
00:38:40,230 --> 00:38:42,530
but then they made some promises
that they would delete it

811
00:38:42,530 --> 00:38:44,442
after a short period of time.

812
00:38:44,442 --> 00:38:47,660
Maybe then the data
scientists have the upper hand

813
00:38:47,660 --> 00:38:48,493
and don't delete it.

814
00:38:48,493 --> 00:38:50,070
So it sits there and then it comes out

815
00:38:50,070 --> 00:38:52,610
in the data security beach,
10 years worth of data

816
00:38:52,610 --> 00:38:55,220
that should have been long
deleted turns out there

817
00:38:55,220 --> 00:38:58,082
or it really is deleted
and then not available

818
00:38:58,083 --> 00:39:02,560
in order to do training of
algorithms, make things more safe

819
00:39:02,560 --> 00:39:03,393
and secure.

820
00:39:03,393 --> 00:39:05,820
So I think companies need
to do a lot of planning here

821
00:39:05,820 --> 00:39:10,820
with all these conflicting
objectives requirements on them.

822
00:39:11,130 --> 00:39:14,180
And we wanted to just give a overview

823
00:39:14,180 --> 00:39:16,560
of what is new in California.

824
00:39:16,560 --> 00:39:21,560
We have from the RSA conference,
a focus of what the amount

825
00:39:22,890 --> 00:39:25,170
of time that we have for
our session can cover.

826
00:39:25,170 --> 00:39:27,750
We would love to answer more questions.

827
00:39:27,750 --> 00:39:29,610
I put my email address here.

828
00:39:29,610 --> 00:39:31,490
We have a number of articles written

829
00:39:31,490 --> 00:39:33,759
on the subject that
would be happy to share.

830
00:39:33,760 --> 00:39:36,060
And if there's a particular
hard question I'll make sure

831
00:39:36,060 --> 00:39:39,173
to pass it on to CJ so that
she can answer the hard ones.

