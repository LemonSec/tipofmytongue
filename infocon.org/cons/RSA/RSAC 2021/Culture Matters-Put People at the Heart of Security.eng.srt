1
00:00:01,090 --> 00:00:04,070
- Welcome everybody,
my name is Jinan Budge,

2
00:00:04,070 --> 00:00:05,810
and I am the principal analyst

3
00:00:05,810 --> 00:00:09,260
leading security and risk
research in Asia Pacific.

4
00:00:09,260 --> 00:00:10,990
And globally our research

5
00:00:10,990 --> 00:00:13,800
on people and culture and security.

6
00:00:13,800 --> 00:00:16,059
I've been a practitioner
as well as an analyst

7
00:00:16,059 --> 00:00:19,119
as well as a consultant
for the last 20 years.

8
00:00:19,120 --> 00:00:24,100
And I feel like I've seen all
sides of our amazing industry.

9
00:00:24,100 --> 00:00:26,520
But today I'm going to be talking to you

10
00:00:26,520 --> 00:00:28,300
about my number one priority

11
00:00:28,300 --> 00:00:30,650
and number one passion insecurity,

12
00:00:30,650 --> 00:00:32,850
and that is people and culture.

13
00:00:32,850 --> 00:00:34,840
And I'm hoping that by
the end of this session,

14
00:00:34,840 --> 00:00:39,140
that you're going to be as
motivated and excited as I am

15
00:00:39,140 --> 00:00:42,530
to always prioritize people and culture.

16
00:00:42,530 --> 00:00:46,540
Which I know may sound like
a strange idea in a field

17
00:00:46,540 --> 00:00:49,519
as technical and analytical as ours.

18
00:00:49,520 --> 00:00:52,630
But I believe it is so important

19
00:00:52,630 --> 00:00:55,070
because it's that cultural journey

20
00:00:55,070 --> 00:00:56,900
that's going to make you shine

21
00:00:56,900 --> 00:00:59,379
and achieve your full potential.

22
00:00:59,380 --> 00:01:00,410
But first of all,

23
00:01:00,410 --> 00:01:03,882
lemme start with my own cultural journey.

24
00:01:05,770 --> 00:01:08,410
And it begins back in 1988,

25
00:01:08,410 --> 00:01:11,990
when my parents took the bold
decision to move themselves

26
00:01:11,990 --> 00:01:15,210
and their three daughters
from Syria to Australia

27
00:01:15,210 --> 00:01:17,140
for the Australian dream.

28
00:01:17,140 --> 00:01:19,180
And for those of you non Australians

29
00:01:19,180 --> 00:01:21,110
in the audience who are
wondering what that is,

30
00:01:21,110 --> 00:01:22,820
it's very similar to the American dream

31
00:01:22,820 --> 00:01:26,190
or the Canadian dream or
any other of those dreams

32
00:01:26,190 --> 00:01:29,620
that newly immigrants have in their minds.

33
00:01:29,620 --> 00:01:31,420
And this is what transpired.

34
00:01:31,420 --> 00:01:33,310
This is me by the way.

35
00:01:33,310 --> 00:01:35,820
I equally accepted the challenge,

36
00:01:35,820 --> 00:01:37,740
I was 13 years old,

37
00:01:37,740 --> 00:01:42,020
I spoke fluent Arabic, some
French, excellent maths,

38
00:01:42,020 --> 00:01:43,880
and three words of English,

39
00:01:43,880 --> 00:01:47,350
which were egg, orange and water.

40
00:01:47,350 --> 00:01:50,720
And I also had piggy tails and a mano brow

41
00:01:50,720 --> 00:01:55,360
and did not understand any of
the 1980s cultural nuances.

42
00:01:55,360 --> 00:01:58,460
I had four years to
make it a to university.

43
00:01:58,460 --> 00:02:00,440
We moved to the Arabic hub of Australia

44
00:02:00,440 --> 00:02:04,110
to safety familiarity and to comfort.

45
00:02:04,110 --> 00:02:05,880
Why am I telling you a story

46
00:02:05,880 --> 00:02:09,109
about myself in the
middle of RSA conference?

47
00:02:09,110 --> 00:02:12,150
I am suggesting to you that my challenges

48
00:02:12,150 --> 00:02:17,150
as a teenager trying to decipher
my new Australian culture

49
00:02:17,470 --> 00:02:21,050
a very similar to yours
actually as a security leader,

50
00:02:21,050 --> 00:02:22,870
as a security professional

51
00:02:22,870 --> 00:02:26,400
when you step into the
organization and you try

52
00:02:26,400 --> 00:02:29,640
and achieve your security aspirations.

53
00:02:29,640 --> 00:02:31,339
I spoke three words of English.

54
00:02:31,340 --> 00:02:33,180
At a very practical level, this meant,

55
00:02:33,180 --> 00:02:36,220
I couldn't understand what my
teachers and peers were saying

56
00:02:36,220 --> 00:02:38,440
and nearly burnt out of science lab.

57
00:02:38,440 --> 00:02:41,290
I was painfully shy,
making it very difficult

58
00:02:41,290 --> 00:02:43,590
for me to make friends.

59
00:02:43,590 --> 00:02:44,610
Life on the playground

60
00:02:44,610 --> 00:02:47,190
certainly wasn't pleasant
in those early days

61
00:02:47,190 --> 00:02:49,740
for all of the reasons described above.

62
00:02:49,740 --> 00:02:52,787
And I had one view of the Australian dream

63
00:02:52,787 --> 00:02:55,270
and that was my parents be good at math,

64
00:02:55,270 --> 00:02:58,840
science and computing,
technical, analytical.

65
00:02:58,840 --> 00:03:02,460
And the temptation to stay
in the multicultural hub

66
00:03:02,460 --> 00:03:05,230
in Sydney with an abundance
of Arabic groceries

67
00:03:05,230 --> 00:03:08,030
and familiar sense was overwhelming.

68
00:03:08,030 --> 00:03:12,260
I know from hundreds of
conversations with many of you

69
00:03:12,260 --> 00:03:15,030
that you security professionals,

70
00:03:15,030 --> 00:03:19,720
security leaders actually
face very similar challenges.

71
00:03:19,720 --> 00:03:22,790
We insecurity do not naturally come out

72
00:03:22,790 --> 00:03:26,519
speaking the language of the
business as our first language.

73
00:03:26,520 --> 00:03:29,150
I know when I interviewed board members,

74
00:03:29,150 --> 00:03:30,880
one board member told me

75
00:03:30,880 --> 00:03:34,840
as directors realized this
is a complicated topic,

76
00:03:34,840 --> 00:03:37,590
we need security leaders
to use terminology

77
00:03:37,590 --> 00:03:40,760
that makes sense to
experts in the business.

78
00:03:40,760 --> 00:03:42,090
We are also shy,

79
00:03:42,090 --> 00:03:44,200
we shy away from politics.

80
00:03:44,200 --> 00:03:46,530
And I'm going to talk about
politics a little bit later

81
00:03:46,530 --> 00:03:48,620
and I'm going to want your
comments and perspectives

82
00:03:48,620 --> 00:03:49,820
in the chat.

83
00:03:49,820 --> 00:03:51,920
This reluctance to engage in politics

84
00:03:51,920 --> 00:03:54,399
has actually put us in a position

85
00:03:54,400 --> 00:03:57,980
where we can not influence
key business decisions.

86
00:03:57,980 --> 00:04:01,700
We are not always well
received or perceived

87
00:04:01,700 --> 00:04:05,709
as a chief operating officer
of a large tech company told me

88
00:04:05,710 --> 00:04:10,380
the perception is still that
security is an impediment

89
00:04:10,380 --> 00:04:12,780
and the bane of convenience.

90
00:04:12,780 --> 00:04:15,800
And something I'm going to
raise with you all today.

91
00:04:15,800 --> 00:04:19,170
Toxicity, security teams
are actually played

92
00:04:19,170 --> 00:04:20,510
with a hidden problem

93
00:04:20,510 --> 00:04:24,190
that we don't yet know how
to talk about toxicity.

94
00:04:24,190 --> 00:04:26,330
And we try to hold on
firmly to what we know,

95
00:04:26,330 --> 00:04:28,683
security technology and tools.

96
00:04:29,600 --> 00:04:32,040
If any or all of these sound familiar,

97
00:04:32,040 --> 00:04:33,030
that's great news.

98
00:04:33,030 --> 00:04:36,260
I'm here to help and to
overcome these challenges.

99
00:04:36,260 --> 00:04:38,800
What I'm suggesting in this presentation

100
00:04:38,800 --> 00:04:41,740
is that your focus needs to shift

101
00:04:41,740 --> 00:04:44,970
to prioritize human
interaction and culture.

102
00:04:44,970 --> 00:04:49,400
And I know one CISO in a
research interview told me

103
00:04:49,400 --> 00:04:51,950
you as a security leader,

104
00:04:51,950 --> 00:04:54,780
you're not going to be
doing security anymore.

105
00:04:54,780 --> 00:04:57,049
So get that off the table.

106
00:04:57,050 --> 00:05:01,200
Your job is now all about
people, business and strategy.

107
00:05:01,200 --> 00:05:03,760
And as though we have the
data to magically prove this,

108
00:05:03,760 --> 00:05:06,240
this is from our survey at forest stuff.

109
00:05:06,240 --> 00:05:09,420
And you can see that
actually security leaders

110
00:05:09,420 --> 00:05:12,880
specifically spend so little time

111
00:05:12,880 --> 00:05:15,100
on the analytical and technical.

112
00:05:15,100 --> 00:05:18,210
The rest of the time is
spent managing stakeholders,

113
00:05:18,210 --> 00:05:21,419
building awareness,
developing business cases

114
00:05:21,420 --> 00:05:23,790
and setting the strategy.

115
00:05:23,790 --> 00:05:27,430
All of these things require a significant

116
00:05:27,430 --> 00:05:31,683
amount of human interaction
and hence this conversation.

117
00:05:32,520 --> 00:05:35,560
And something that a CISO

118
00:05:35,560 --> 00:05:39,210
reminded me of during
a research interview,

119
00:05:39,210 --> 00:05:42,789
security is actually a
very emotional subject.

120
00:05:42,790 --> 00:05:43,960
I know we forget that.

121
00:05:43,960 --> 00:05:45,770
I know we forget this as
security professionals,

122
00:05:45,770 --> 00:05:47,599
this is what we live and breathe.

123
00:05:47,600 --> 00:05:50,230
But people have very specific feelings

124
00:05:50,230 --> 00:05:52,040
about security actually.

125
00:05:52,040 --> 00:05:56,650
So, it's really important to
understand those stakeholders,

126
00:05:56,650 --> 00:06:00,179
understand those feelings
and learn how to manage them.

127
00:06:00,180 --> 00:06:02,520
Because the thing with failings is,

128
00:06:02,520 --> 00:06:04,359
I mean you can ignore them if you like

129
00:06:04,360 --> 00:06:06,170
but actually you won't be successful.

130
00:06:06,170 --> 00:06:09,080
So you need to tackle them head on.

131
00:06:09,080 --> 00:06:12,520
And all of this human interaction
that I'm talking about,

132
00:06:12,520 --> 00:06:13,700
Absolutely we can,

133
00:06:13,700 --> 00:06:14,979
and we do, I've seen it.

134
00:06:14,980 --> 00:06:17,450
I've seen us leaving it to chance,

135
00:06:17,450 --> 00:06:20,440
But whether you are aware of this or not,

136
00:06:20,440 --> 00:06:23,010
actually every single
interaction that we have,

137
00:06:23,010 --> 00:06:25,950
we are creating some sort of a culture.

138
00:06:25,950 --> 00:06:28,330
And what you don't want to do

139
00:06:28,330 --> 00:06:31,890
is you don't want to be
sleepwalking into this culture.

140
00:06:31,890 --> 00:06:35,969
You actually want to be
intentional for how you create it.

141
00:06:35,970 --> 00:06:38,060
So what I'm going to show you today

142
00:06:38,060 --> 00:06:41,400
is the four or four components of culture

143
00:06:41,400 --> 00:06:45,359
that I think you need to prioritize.

144
00:06:45,360 --> 00:06:47,350
And I'm going to start with

145
00:06:47,350 --> 00:06:50,430
feeding supporters and detractors.

146
00:06:50,430 --> 00:06:53,300
Insecurity, as we all know,

147
00:06:53,300 --> 00:06:56,890
we have a lot of
initiatives to push through.

148
00:06:56,890 --> 00:07:01,110
We have got zero trust
inside threat programs,

149
00:07:01,110 --> 00:07:04,720
privacy, phishing simulation exercises,

150
00:07:04,720 --> 00:07:06,850
with all of these initiatives,

151
00:07:06,850 --> 00:07:08,610
you're introducing change.

152
00:07:08,610 --> 00:07:10,700
And guess what?

153
00:07:10,700 --> 00:07:13,270
People generally don't like change.

154
00:07:13,270 --> 00:07:15,229
They're not comfortable with that.

155
00:07:15,230 --> 00:07:18,710
And it's only natural with those scenarios

156
00:07:18,710 --> 00:07:19,840
that you're going to have people

157
00:07:19,840 --> 00:07:23,810
who love what you're doing and
people who hate the change.

158
00:07:23,810 --> 00:07:25,780
So your job is actually

159
00:07:25,780 --> 00:07:28,869
to bring all of these different
people on the journey.

160
00:07:28,870 --> 00:07:32,030
So to do that, build your stakeholder map,

161
00:07:32,030 --> 00:07:33,770
work out who's who,

162
00:07:33,770 --> 00:07:36,919
who needs to be on board with
your strategy or initiatives.

163
00:07:36,920 --> 00:07:41,920
What role are they going to
assume in your transformation?

164
00:07:43,146 --> 00:07:45,560
Take the time to develop
a deep understanding

165
00:07:45,560 --> 00:07:48,140
of each one of those players perspectives.

166
00:07:48,140 --> 00:07:52,000
I've got several personas
he for you to consider.

167
00:07:52,000 --> 00:07:54,280
They're going to be different
for every initiative,

168
00:07:54,280 --> 00:07:56,219
every organization but typically

169
00:07:56,220 --> 00:07:59,240
in a large cybersecurity program,

170
00:07:59,240 --> 00:08:03,290
your CEO is going to be the
ultimate decision point.

171
00:08:03,290 --> 00:08:05,410
You're going to have visionary,

172
00:08:05,410 --> 00:08:07,260
visionaries in the organization.

173
00:08:07,260 --> 00:08:10,240
You will need to align to their vision.

174
00:08:10,240 --> 00:08:13,050
Otherwise, you're not going to succeed.

175
00:08:13,050 --> 00:08:15,110
You're going to have champions,

176
00:08:15,110 --> 00:08:16,980
you're going to have budget holders

177
00:08:16,980 --> 00:08:18,790
and you'll have to have
different conversations

178
00:08:18,790 --> 00:08:20,890
with all of these people.

179
00:08:20,890 --> 00:08:22,909
One thing that I've learned in my career

180
00:08:22,910 --> 00:08:27,090
is to never ever surprise
those stakeholders

181
00:08:27,090 --> 00:08:28,599
with a strategy.

182
00:08:28,600 --> 00:08:33,600
Successful professionals,
successful leaders plant the seed

183
00:08:33,620 --> 00:08:36,390
for the need of change and its benefit.

184
00:08:36,390 --> 00:08:39,449
And really a cultural change happens

185
00:08:39,450 --> 00:08:42,409
one conversation at a time.

186
00:08:42,409 --> 00:08:44,839
And you're having these
conversations actually

187
00:08:44,840 --> 00:08:46,850
because you want to understand the remit

188
00:08:46,850 --> 00:08:48,660
of the stakeholders.

189
00:08:48,660 --> 00:08:51,050
What is their level of
awareness of security?

190
00:08:51,050 --> 00:08:54,199
What's their level of
support for security?

191
00:08:54,200 --> 00:08:57,370
And all of this involve a
lot of talking on your part

192
00:08:57,370 --> 00:09:01,510
but actually also it needs to
involve a lot of listening.

193
00:09:01,510 --> 00:09:04,250
Because once you've
listened and understood

194
00:09:04,250 --> 00:09:07,750
how people are likely to
react to your strategy,

195
00:09:07,750 --> 00:09:11,260
then and only then can you steer them

196
00:09:11,260 --> 00:09:13,750
towards the correct outcome.

197
00:09:13,750 --> 00:09:17,970
And I know when I've presented
some of this in the past,

198
00:09:17,970 --> 00:09:20,130
people like half of this is political.

199
00:09:20,130 --> 00:09:21,180
Yes, you're right.

200
00:09:21,180 --> 00:09:22,810
This is politic.

201
00:09:22,810 --> 00:09:26,339
And this is where I'd love
you to jump into the chat

202
00:09:26,340 --> 00:09:27,480
and give me some feedback.

203
00:09:27,480 --> 00:09:30,410
Because when I say politics,

204
00:09:30,410 --> 00:09:32,550
I want to know what do you think of.

205
00:09:32,550 --> 00:09:35,150
Do you think of politics as a dirty word?

206
00:09:35,150 --> 00:09:36,699
Does it make you squirm?

207
00:09:36,700 --> 00:09:38,820
Does it make you block your ears?

208
00:09:38,820 --> 00:09:41,760
Or do you welcome and tackle it?

209
00:09:41,760 --> 00:09:45,500
I know that when I was doing interviews

210
00:09:45,500 --> 00:09:48,130
for this particular piece of
research on change management,

211
00:09:48,130 --> 00:09:50,530
I interviewed a whole bunch of leaders

212
00:09:50,530 --> 00:09:53,520
from more long standing professions,

213
00:09:53,520 --> 00:09:55,793
such as CRO, CIO, CEOs.

214
00:09:56,930 --> 00:10:01,439
And they all told me about
that moment in their career

215
00:10:01,440 --> 00:10:04,180
when they changed their
mind about politics.

216
00:10:04,180 --> 00:10:07,510
When they went from thinking
of politics as this dirty word

217
00:10:07,510 --> 00:10:10,050
to something that they embraced.

218
00:10:10,050 --> 00:10:12,030
And they will often tell me

219
00:10:12,030 --> 00:10:14,520
that this coincided with the moment

220
00:10:14,520 --> 00:10:19,000
when they made the internal
decision to become a leader.

221
00:10:19,000 --> 00:10:22,370
People play politics every
time they send an email

222
00:10:22,370 --> 00:10:24,090
or chat at the water cooler.

223
00:10:24,090 --> 00:10:27,580
So, my suggestion on that
one is get with a program.

224
00:10:27,580 --> 00:10:31,860
You can absolutely be
political with ethics,

225
00:10:31,860 --> 00:10:34,763
transparency and integrity.

226
00:10:35,760 --> 00:10:37,850
Now I'm gonna give you a couple of tools

227
00:10:37,850 --> 00:10:38,750
for your toolkit.

228
00:10:38,750 --> 00:10:40,000
Once you've done all your listening,

229
00:10:40,000 --> 00:10:41,520
you've adjusted your course,

230
00:10:41,520 --> 00:10:42,890
you're in a good place.

231
00:10:42,890 --> 00:10:45,520
So you need to work
out your next maneuver.

232
00:10:45,520 --> 00:10:48,360
You need to actually persuade.

233
00:10:48,360 --> 00:10:51,320
And the theme with persuasion is,

234
00:10:51,320 --> 00:10:54,320
again, don't mistake it
for a situation of begging

235
00:10:54,320 --> 00:10:56,980
on your knees, type of influence.

236
00:10:56,980 --> 00:11:00,530
Persuasion is actually a
process of professional

237
00:11:01,510 --> 00:11:04,700
political maneuvering and its very finest.

238
00:11:04,700 --> 00:11:07,470
It is ethical, it is acceptable.

239
00:11:07,470 --> 00:11:11,740
There's some tools for you for
example, collective momentum,

240
00:11:11,740 --> 00:11:14,490
you are doing a whole bunch of socializing

241
00:11:14,490 --> 00:11:16,290
and building the momentum

242
00:11:16,290 --> 00:11:18,630
so that when you finally present your idea

243
00:11:18,630 --> 00:11:21,689
or you finally present your
strategy or your initiative,

244
00:11:21,690 --> 00:11:23,500
you can list all those engaged

245
00:11:23,500 --> 00:11:25,750
sponsors that you have spoken to.

246
00:11:25,750 --> 00:11:29,970
Authority, one to be used
carefully but super-important.

247
00:11:29,970 --> 00:11:31,910
Influence comes from the top down.

248
00:11:31,910 --> 00:11:35,360
If your CEO believes that
something is important,

249
00:11:35,360 --> 00:11:39,850
most of the other staff, most
likely to fall into line.

250
00:11:39,850 --> 00:11:42,650
You've got things such as
of course relationships,

251
00:11:42,650 --> 00:11:45,819
building positive
relationships ahead of time,

252
00:11:45,820 --> 00:11:49,330
highlighting commonalities
that you have with people.

253
00:11:49,330 --> 00:11:51,880
Then, you can use this relationship

254
00:11:51,880 --> 00:11:53,930
to influence the program.

255
00:11:53,930 --> 00:11:58,030
And vice vasa you can with
things like mutual exchange

256
00:11:58,030 --> 00:12:02,020
you can provide some service,
resource, assistance,

257
00:12:02,020 --> 00:12:04,730
in the hope that at
some point in the future

258
00:12:04,730 --> 00:12:08,003
you will receive some of them back.

259
00:12:09,360 --> 00:12:12,430
Now, everything that I
have just talked about

260
00:12:12,430 --> 00:12:14,030
is super important.

261
00:12:14,030 --> 00:12:15,900
You are creating change,

262
00:12:15,900 --> 00:12:18,900
you're creating culture
that isn't your vision.

263
00:12:18,900 --> 00:12:23,840
But take care because sometimes
you can get so caught up

264
00:12:23,840 --> 00:12:25,290
in managing upwards

265
00:12:25,290 --> 00:12:29,120
and engaging with stakeholders
whilst internally,

266
00:12:29,120 --> 00:12:33,300
a toxic security team culture festers,

267
00:12:33,300 --> 00:12:36,469
and you end up with infighting,
unhappiness and aggression

268
00:12:36,470 --> 00:12:38,960
between the security team members

269
00:12:38,960 --> 00:12:41,800
and inevitably what I've
seen over and over again,

270
00:12:41,800 --> 00:12:44,050
a brilliant jerk comes out of the woodwork

271
00:12:44,050 --> 00:12:46,469
and causes dissent.

272
00:12:46,470 --> 00:12:51,470
Welcome to security's dirty
secret workplace toxicity.

273
00:12:51,910 --> 00:12:55,160
This is a hidden and
often undiscussed problem

274
00:12:55,160 --> 00:12:56,699
for us within cybersecurity.

275
00:12:56,700 --> 00:12:58,170
Although I have to tell you,

276
00:12:58,170 --> 00:13:00,329
I have been talking about it extensively

277
00:13:00,330 --> 00:13:01,660
in the last 12 months.

278
00:13:01,660 --> 00:13:04,680
Because nothing prepared
me for what happened

279
00:13:04,680 --> 00:13:07,959
when I asked the question on
LinkedIn, very innocently,

280
00:13:07,960 --> 00:13:11,630
what do you think causes
toxicity with insecurity?

281
00:13:11,630 --> 00:13:16,630
I received it analyzed 200
contributions from the community.

282
00:13:18,220 --> 00:13:21,650
And builds a research and
a word all around that,

283
00:13:21,650 --> 00:13:23,890
which will hopefully help you.

284
00:13:23,890 --> 00:13:26,300
The number one cause of toxicity

285
00:13:26,300 --> 00:13:29,670
is actually lack of
organizational support.

286
00:13:29,670 --> 00:13:31,069
As somebody said,

287
00:13:31,070 --> 00:13:34,330
it's really hard for the
security team to be happy

288
00:13:34,330 --> 00:13:38,050
if security is viewed
as a negative or tax,

289
00:13:38,050 --> 00:13:40,349
this culture for security team members

290
00:13:40,350 --> 00:13:41,903
will always be difficult.

291
00:13:42,750 --> 00:13:46,350
Eager was something that
was repeated multiple times.

292
00:13:46,350 --> 00:13:50,400
And something else, the hero
complex or the brilliant jerk.

293
00:13:50,400 --> 00:13:53,290
The Messiahs, the rock stars,
the broilers, the invisible.

294
00:13:53,290 --> 00:13:57,740
This came to me as so many
different names and words.

295
00:13:57,740 --> 00:14:00,660
Some of which I'd never heard of before.

296
00:14:00,660 --> 00:14:04,680
But what it describes is those people

297
00:14:04,680 --> 00:14:07,810
in security teams who are not team players

298
00:14:07,810 --> 00:14:10,079
and we all know at least one

299
00:14:10,080 --> 00:14:13,450
and they feel that they and only they

300
00:14:13,450 --> 00:14:16,090
can solve the problem
and they beat their own

301
00:14:16,090 --> 00:14:17,860
chest about it.

302
00:14:17,860 --> 00:14:20,310
Now, in doing all of this research

303
00:14:20,310 --> 00:14:23,619
and talking publicly about it for a while,

304
00:14:23,620 --> 00:14:28,350
one of the questions that
kept on coming back to me was,

305
00:14:28,350 --> 00:14:30,990
what happens if the security leader

306
00:14:30,990 --> 00:14:32,990
is actually the one
who's the brilliant jerk?

307
00:14:32,990 --> 00:14:35,700
What happens if it is the size though?

308
00:14:35,700 --> 00:14:38,270
And we had to take that very seriously.

309
00:14:38,270 --> 00:14:42,530
And some if I ever get
a chance to go deeper

310
00:14:42,530 --> 00:14:44,579
in some of these calls is actually eight

311
00:14:44,580 --> 00:14:46,780
out of the top 10 causes,

312
00:14:46,780 --> 00:14:51,780
relate to a lack of
leadership at some level.

313
00:14:52,620 --> 00:14:55,180
Based on that and a
number of other factors,

314
00:14:55,180 --> 00:14:57,569
we made the prediction.

315
00:14:57,570 --> 00:14:59,940
We make it for us to five

316
00:14:59,940 --> 00:15:02,400
cybersecurity predictions every year.

317
00:15:02,400 --> 00:15:07,400
And one of those is that a
CISO from a global 500 firm

318
00:15:08,090 --> 00:15:10,620
is going to be fired for instilling

319
00:15:10,620 --> 00:15:12,880
a toxic security culture.

320
00:15:12,880 --> 00:15:15,230
And why do we think
that this could happen?

321
00:15:15,230 --> 00:15:17,440
There's actually a few factors.

322
00:15:17,440 --> 00:15:20,050
Number one is social media.

323
00:15:20,050 --> 00:15:23,959
I know I've been insecurity as
I mentioned for 20 plus years

324
00:15:23,960 --> 00:15:28,370
and sharing lists of serial toxic Pes,

325
00:15:28,370 --> 00:15:30,570
used to be the domain of private networks.

326
00:15:30,570 --> 00:15:32,380
My friends and I are like,

327
00:15:32,380 --> 00:15:34,720
should we hire this person,

328
00:15:34,720 --> 00:15:36,660
she like accepted job with this person.

329
00:15:36,660 --> 00:15:39,110
And we'd all exchange this ideas.

330
00:15:39,110 --> 00:15:43,660
But what's happening now with
the prevails of social media.

331
00:15:43,660 --> 00:15:47,180
Employees understand that
they can take to social media

332
00:15:47,180 --> 00:15:48,870
if their concerns are discarded.

333
00:15:48,870 --> 00:15:52,310
So that was number one reason
why we made the prediction.

334
00:15:52,310 --> 00:15:54,079
The second reason is,

335
00:15:54,080 --> 00:15:58,990
we are seeing a huge move
towards values paced decisions

336
00:15:58,990 --> 00:16:03,520
for consumers, shareholders and employees.

337
00:16:03,520 --> 00:16:06,560
A couple of examples there for you.

338
00:16:06,560 --> 00:16:11,560
78% of millennials are strongly
attracted to innovative

339
00:16:12,050 --> 00:16:15,079
and purpose driven companies.

340
00:16:15,080 --> 00:16:18,440
In 2019, we saw employees at Amazon,

341
00:16:18,440 --> 00:16:21,120
Facebook, Google, Microsoft Twitter,

342
00:16:21,120 --> 00:16:25,640
go on strike to protest
their employers inaction

343
00:16:25,640 --> 00:16:27,100
on climate change.

344
00:16:27,100 --> 00:16:30,720
Again, values-based employees specifically

345
00:16:30,720 --> 00:16:34,930
are collectively bargaining
on ethics and morals.

346
00:16:34,930 --> 00:16:38,630
In Australia a couple of examples,

347
00:16:38,630 --> 00:16:41,350
AMP shareholders pressured the firing

348
00:16:41,350 --> 00:16:45,650
of a trio of executives
for harassment claims.

349
00:16:45,650 --> 00:16:48,620
This is, again, this is not something

350
00:16:48,620 --> 00:16:51,090
that happened only by the employees,

351
00:16:51,090 --> 00:16:53,400
but the shareholders are driving this.

352
00:16:53,400 --> 00:16:55,520
The Ellen DeGeneres show,

353
00:16:55,520 --> 00:16:58,199
definitely not something
you're expecting to hear about

354
00:16:58,200 --> 00:17:00,950
in a security presentation,

355
00:17:00,950 --> 00:17:03,900
but that show snag the
spotlight for bullying issues

356
00:17:03,900 --> 00:17:08,869
with three producers being
ousted as a result of bullying.

357
00:17:08,869 --> 00:17:12,409
Many of us it seems are
voting with our feet

358
00:17:12,410 --> 00:17:15,760
as either consumers,
employees or shareholders.

359
00:17:15,760 --> 00:17:17,440
So some of those behaviors

360
00:17:17,440 --> 00:17:19,390
that have been tolerated in the past

361
00:17:19,390 --> 00:17:22,040
and not going to any more.

362
00:17:22,040 --> 00:17:23,899
And it's really interesting for me

363
00:17:23,900 --> 00:17:26,550
when I dig into and try and understand

364
00:17:26,550 --> 00:17:28,899
what are organizations doing about it,

365
00:17:28,900 --> 00:17:31,200
yeah, not much it seems.

366
00:17:31,200 --> 00:17:33,840
We actually found this data

367
00:17:33,840 --> 00:17:36,570
that showed that 53% of employees

368
00:17:36,570 --> 00:17:39,389
say their firm does not
address toxicity issues.

369
00:17:39,390 --> 00:17:41,010
So whilst people are telling us,

370
00:17:41,010 --> 00:17:43,113
this is a really big deal,

371
00:17:44,640 --> 00:17:47,430
no one is doing much about it.

372
00:17:47,430 --> 00:17:50,750
48% say that their firms
don't allocate funding

373
00:17:50,750 --> 00:17:53,253
to promote a healthy workspace.

374
00:17:54,150 --> 00:17:57,753
And one of the things I wanted
to explore in my research is,

375
00:17:59,140 --> 00:18:01,060
so are we speaking out about it,

376
00:18:01,060 --> 00:18:03,179
is the prediction likely to come true?

377
00:18:03,180 --> 00:18:05,090
Is there enough of a speak up culture?

378
00:18:05,090 --> 00:18:09,209
And again, I asked the
question of my LinkedIn network

379
00:18:09,210 --> 00:18:12,940
and the responses were overwhelming.

380
00:18:12,940 --> 00:18:15,480
Hundreds of comments with people having

381
00:18:15,480 --> 00:18:17,360
very strong views about,

382
00:18:17,360 --> 00:18:20,490
yes, you absolutely must
speak out about this.

383
00:18:20,490 --> 00:18:24,400
And no, it's a really terrible idea.

384
00:18:24,400 --> 00:18:26,920
So it's the percentage is effectively

385
00:18:26,920 --> 00:18:30,740
from the data we analyzed 35% to 65%.

386
00:18:30,740 --> 00:18:31,910
On the yes side,

387
00:18:31,910 --> 00:18:35,900
people have moistly noted
that it's really important

388
00:18:35,900 --> 00:18:37,910
so that we can change the culture,

389
00:18:37,910 --> 00:18:42,560
so that we can make this
better for future generations.

390
00:18:42,560 --> 00:18:43,943
The ones who said no,

391
00:18:45,170 --> 00:18:47,420
have said the repercussions
is not worth it.

392
00:18:47,420 --> 00:18:49,570
There are mental health challenges,

393
00:18:49,570 --> 00:18:52,580
career implications, personal impacts,

394
00:18:52,580 --> 00:18:55,060
so it's a no.

395
00:18:55,060 --> 00:18:57,560
So what do we do about this?

396
00:18:57,560 --> 00:19:01,610
I think from your perspective
if you are not a leader,

397
00:19:01,610 --> 00:19:04,969
then it's really important
for you to decide

398
00:19:04,970 --> 00:19:06,800
whether or not you want to speak out.

399
00:19:06,800 --> 00:19:09,330
If you decide to speak
out, how do you speak out?

400
00:19:09,330 --> 00:19:11,899
That's actually going to
be part of my research

401
00:19:11,900 --> 00:19:13,100
for this coming year.

402
00:19:13,100 --> 00:19:17,582
And I can't wait to share it
with people moving forward.

403
00:19:18,530 --> 00:19:20,550
I think it's really
important for all of us

404
00:19:20,550 --> 00:19:23,129
and for leaders especially to acknowledge

405
00:19:23,130 --> 00:19:26,010
and deal with toxicity.

406
00:19:26,010 --> 00:19:30,560
That means, correcting culture problems

407
00:19:30,560 --> 00:19:32,060
before they met us to size,

408
00:19:32,060 --> 00:19:34,139
I find that with toxicity,

409
00:19:34,140 --> 00:19:37,823
if you bury your head in
the sand and let it fester,

410
00:19:39,415 --> 00:19:41,720
it just becomes quite the situation.

411
00:19:41,720 --> 00:19:43,910
So it's really important
to call it actually

412
00:19:43,910 --> 00:19:45,500
putting labels and things,

413
00:19:45,500 --> 00:19:48,570
calling things out is really important.

414
00:19:48,570 --> 00:19:50,439
Understanding all perspectives.

415
00:19:50,440 --> 00:19:53,030
Is that person's behavior toxic

416
00:19:53,030 --> 00:19:58,030
because they are exhibiting
symptoms of the brilliant jerk

417
00:19:58,650 --> 00:20:02,020
or have they actually had
a really tough time at home

418
00:20:02,020 --> 00:20:04,460
and they potentially need some counseling

419
00:20:04,460 --> 00:20:05,920
and some help.

420
00:20:05,920 --> 00:20:07,640
Fix the hero complex.

421
00:20:07,640 --> 00:20:10,080
And you do that by coaching empathy,

422
00:20:10,080 --> 00:20:13,540
encouraging and modeling
positive behavior.

423
00:20:13,540 --> 00:20:16,070
And what I've learned through my research

424
00:20:16,070 --> 00:20:17,610
and my own personal experience,

425
00:20:17,610 --> 00:20:21,030
is sometimes as a leader in particular,

426
00:20:21,030 --> 00:20:23,030
you've got to make the tough calls,

427
00:20:23,030 --> 00:20:25,080
you do have to let people go

428
00:20:25,080 --> 00:20:30,080
if you cannot find a space
where they stop being toxic.

429
00:20:30,820 --> 00:20:35,820
And going back to the theme
of international women's day

430
00:20:35,990 --> 00:20:38,010
this year which I absolutely love,

431
00:20:38,010 --> 00:20:39,290
choose to challenge,

432
00:20:39,290 --> 00:20:43,210
we all whether we are
leaders or not leaders,

433
00:20:43,210 --> 00:20:46,440
we all have the responsibility,

434
00:20:46,440 --> 00:20:48,740
we all have opportunity to challenge.

435
00:20:48,740 --> 00:20:51,140
And again, I think in this day and age,

436
00:20:51,140 --> 00:20:53,973
it is absolutely the right thing to do.

437
00:20:55,540 --> 00:20:57,879
I'm now going to change tact

438
00:20:57,880 --> 00:21:00,760
and go outside of security teams again

439
00:21:00,760 --> 00:21:03,680
and engaging with organizations.

440
00:21:03,680 --> 00:21:08,680
In 2018, only 19% of sizes
said the lack of visibility

441
00:21:11,050 --> 00:21:12,750
and influence within the organization

442
00:21:12,750 --> 00:21:14,690
is one of their top challenges.

443
00:21:14,690 --> 00:21:18,930
This is done, I'm mentioning
this figure, sorry, 2019,

444
00:21:18,930 --> 00:21:23,930
because back in 2010, that
figure used to be 51%.

445
00:21:24,650 --> 00:21:27,430
51% of us used to struggle

446
00:21:27,430 --> 00:21:30,500
with visibility and influence of security.

447
00:21:30,500 --> 00:21:33,500
We've come a really long way.

448
00:21:33,500 --> 00:21:37,390
But while this apparent increase
in visibility of security

449
00:21:37,390 --> 00:21:39,800
and influence is a great sign,

450
00:21:39,800 --> 00:21:43,000
I'm not convinced that
we've actually increased

451
00:21:43,000 --> 00:21:46,130
people's understanding
of what security is.

452
00:21:46,130 --> 00:21:49,490
And I think you still have
a huge task ahead of you

453
00:21:49,490 --> 00:21:52,370
particularly in managing the human risk.

454
00:21:52,370 --> 00:21:55,050
Now, sadly traditional approaches

455
00:21:55,050 --> 00:21:56,500
to managing the human breasts

456
00:21:56,500 --> 00:22:01,420
have been limited to perfunctory
one-off security awareness

457
00:22:01,420 --> 00:22:03,220
and training session.

458
00:22:03,220 --> 00:22:04,730
And quite often,

459
00:22:04,730 --> 00:22:07,530
some of those security
awareness and training

460
00:22:08,450 --> 00:22:11,300
completely disengaged the
employees from the topic actually,

461
00:22:11,300 --> 00:22:14,260
because they're so long,
they're so disengaging.

462
00:22:14,260 --> 00:22:16,050
And it ends up resulting

463
00:22:16,050 --> 00:22:19,419
in little long-term behavioral change.

464
00:22:19,420 --> 00:22:22,850
So I want to share with
you a couple of pieces

465
00:22:22,850 --> 00:22:26,020
from our research on
managing the human brisk.

466
00:22:26,020 --> 00:22:28,760
And suggesting that to
manage the human risk

467
00:22:28,760 --> 00:22:33,760
actually you need to build a
human centric security program.

468
00:22:35,520 --> 00:22:36,750
You will have the slides,

469
00:22:36,750 --> 00:22:39,590
so you can look at this in
a little bit more detailed,

470
00:22:39,590 --> 00:22:43,560
but effectively you have
got four simple steps,

471
00:22:43,560 --> 00:22:45,350
simple but not really so simple

472
00:22:45,350 --> 00:22:47,480
because most people don't do it.

473
00:22:47,480 --> 00:22:51,830
Step number one is identifying
your key stakeholders.

474
00:22:51,830 --> 00:22:55,929
Step number two, determining
what are some of the behaviors

475
00:22:55,930 --> 00:22:57,510
that you'd like to change.

476
00:22:57,510 --> 00:23:00,620
Step number three, it then becomes

477
00:23:00,620 --> 00:23:02,520
about creating the security awareness

478
00:23:02,520 --> 00:23:04,080
and training initiative

479
00:23:04,080 --> 00:23:06,520
or initiatives and building your plan.

480
00:23:06,520 --> 00:23:09,940
Step number four,
measuring and continuously

481
00:23:09,940 --> 00:23:10,830
improving the plan.

482
00:23:10,830 --> 00:23:14,040
So I wanna go to the stakeholders a bit.

483
00:23:14,040 --> 00:23:16,070
The trick with the stakeholders

484
00:23:16,070 --> 00:23:20,189
is getting in a lot of
depth and a lot of detail

485
00:23:20,190 --> 00:23:24,070
about understanding who
your stakeholders are.

486
00:23:24,070 --> 00:23:25,750
Because what you want to do,

487
00:23:25,750 --> 00:23:29,910
is you want to focus your
culture efforts up, down,

488
00:23:29,910 --> 00:23:33,260
across and even outside
of the organization.

489
00:23:33,260 --> 00:23:35,930
So if you imagine this being a triangle

490
00:23:35,930 --> 00:23:37,920
and you're starting at the top,

491
00:23:37,920 --> 00:23:39,560
you've got your executives,

492
00:23:39,560 --> 00:23:40,770
you've got your boards,

493
00:23:40,770 --> 00:23:44,560
you've got your group
management committees.

494
00:23:44,560 --> 00:23:46,110
So what do you need from them?

495
00:23:46,110 --> 00:23:48,899
Yes, you need them to change
some security behaviors.

496
00:23:48,900 --> 00:23:51,560
But I think moisty potently

497
00:23:51,560 --> 00:23:54,889
what you need from them
actually is advocacy

498
00:23:54,890 --> 00:23:57,620
because we that the executive support,

499
00:23:57,620 --> 00:24:00,379
security initiatives are going to fail.

500
00:24:00,380 --> 00:24:02,550
Security budgets will get cut

501
00:24:02,550 --> 00:24:06,940
and therefore critical risks
are going to be elevated.

502
00:24:06,940 --> 00:24:09,540
Those executives more than ever

503
00:24:09,540 --> 00:24:13,770
need education and need engagement.

504
00:24:13,770 --> 00:24:16,750
Number two, moving down the triangle.

505
00:24:16,750 --> 00:24:18,500
Business and technology leaders,

506
00:24:18,500 --> 00:24:20,840
again, some behaviors to change.

507
00:24:20,840 --> 00:24:22,850
But also you need their buy-in,

508
00:24:22,850 --> 00:24:24,780
you need their support,

509
00:24:24,780 --> 00:24:28,129
and you need them to be
engaged at project levels.

510
00:24:28,130 --> 00:24:32,670
For that to occur, security
has to act as a team player,

511
00:24:32,670 --> 00:24:35,380
as a facilitator and an advisor,

512
00:24:35,380 --> 00:24:37,530
and to work with the business

513
00:24:37,530 --> 00:24:40,879
to deliver those projects that they need

514
00:24:40,880 --> 00:24:43,200
without compromising security.

515
00:24:43,200 --> 00:24:44,780
And really that can only happen

516
00:24:44,780 --> 00:24:47,863
through that process of
buying and listening.

517
00:24:48,770 --> 00:24:51,379
And then of course,
you've got the end users.

518
00:24:51,380 --> 00:24:54,540
And that is where you need
to raise that awareness

519
00:24:54,540 --> 00:24:56,159
and change their behaviors.

520
00:24:56,160 --> 00:24:58,410
We know that organizations are as strong

521
00:24:58,410 --> 00:25:02,290
as their weakest link and those end users

522
00:25:02,290 --> 00:25:06,070
need to be an essential
part of your strategy.

523
00:25:06,070 --> 00:25:08,550
They are your human firewall.

524
00:25:08,550 --> 00:25:10,899
The thing with the end-users is that,

525
00:25:10,900 --> 00:25:12,810
the messages to them,

526
00:25:12,810 --> 00:25:15,159
we've got to change the way
that we're doing it guys,

527
00:25:15,160 --> 00:25:16,580
we need to be a lot more relevant,

528
00:25:16,580 --> 00:25:18,780
engaging and consistent.

529
00:25:18,780 --> 00:25:22,000
And one more trend that
I'd like to share with you

530
00:25:22,000 --> 00:25:23,970
up down across the organization,

531
00:25:23,970 --> 00:25:27,070
yes, but we also need to step outside

532
00:25:27,070 --> 00:25:29,330
and we need to build trust

533
00:25:29,330 --> 00:25:33,449
with external stakeholders
security has to engage

534
00:25:33,450 --> 00:25:36,250
their customer community and
exceed their expectations.

535
00:25:36,250 --> 00:25:39,680
I know in many parts of the
world and some industries

536
00:25:39,680 --> 00:25:43,270
such as financial services in particular,

537
00:25:43,270 --> 00:25:47,639
they are using their security and privacy

538
00:25:47,640 --> 00:25:52,560
and trust programs actually
as a competitive advantage.

539
00:25:52,560 --> 00:25:55,800
So it's really important to engage

540
00:25:55,800 --> 00:25:59,560
with those customers also
externally and regulators

541
00:25:59,560 --> 00:26:03,230
and all sorts of external stakeholders.

542
00:26:03,230 --> 00:26:06,560
Now, I've got a very long story short,

543
00:26:06,560 --> 00:26:08,120
I'm really conscious of this.

544
00:26:08,120 --> 00:26:11,110
But I wanted to share
something else with you.

545
00:26:11,110 --> 00:26:12,830
Because this is usually,

546
00:26:12,830 --> 00:26:14,520
this is a step that people start with.

547
00:26:14,520 --> 00:26:16,050
People start with a step off

548
00:26:16,050 --> 00:26:19,330
less push out security
awareness and training program.

549
00:26:19,330 --> 00:26:20,310
But you really needed

550
00:26:20,310 --> 00:26:22,360
to have done that
stakeholder analysis first,

551
00:26:22,360 --> 00:26:25,699
understand the behavior,
understand what you need from them.

552
00:26:25,700 --> 00:26:28,230
But even when you get to
the security awareness

553
00:26:28,230 --> 00:26:29,990
and training initiatives,

554
00:26:29,990 --> 00:26:32,070
what you could either choose to do

555
00:26:32,070 --> 00:26:33,530
a tick in the box exercise

556
00:26:33,530 --> 00:26:35,210
and push something out

557
00:26:35,210 --> 00:26:38,730
or you can do something
really transformational,

558
00:26:38,730 --> 00:26:43,280
something that's going to win
people's hearts and minds.

559
00:26:43,280 --> 00:26:47,560
And to do that, our
research showed there's 10,

560
00:26:47,560 --> 00:26:50,850
what I'm going to call
for you design principles

561
00:26:50,850 --> 00:26:52,629
that you need to consider

562
00:26:52,630 --> 00:26:55,360
that are going to take your
security awareness training

563
00:26:55,360 --> 00:26:57,979
from that very boring perfunctory

564
00:27:00,247 --> 00:27:03,230
to something that wins
people's hearts and minds.

565
00:27:03,230 --> 00:27:06,850
So these such as having the
cars to use humor and fun

566
00:27:06,850 --> 00:27:09,689
on a very serious topic,

567
00:27:09,690 --> 00:27:11,640
don't be scared of that.

568
00:27:11,640 --> 00:27:14,910
Using experiential
learning and gamification,

569
00:27:14,910 --> 00:27:16,580
I've got a couple of examples

570
00:27:16,580 --> 00:27:18,580
of that for you coming up.

571
00:27:18,580 --> 00:27:20,710
Using micro and nano learning,

572
00:27:20,710 --> 00:27:23,360
nobody has the attention span right now

573
00:27:23,360 --> 00:27:25,100
to spend more than

574
00:27:25,100 --> 00:27:27,730
a couple of minutes consuming information,

575
00:27:27,730 --> 00:27:30,010
repeating the information frequently

576
00:27:30,010 --> 00:27:32,230
to make sure that people understand it.

577
00:27:32,230 --> 00:27:36,650
So, just be aware that
there's some design principles

578
00:27:36,650 --> 00:27:38,200
that you need to incorporate.

579
00:27:38,200 --> 00:27:40,740
And here's some examples actually,

580
00:27:40,740 --> 00:27:45,500
board members executives
using them as an example.

581
00:27:45,500 --> 00:27:48,990
One of the questions that
I get asked by inquiry,

582
00:27:48,990 --> 00:27:52,030
one of my most frequently
asked questions is,

583
00:27:52,030 --> 00:27:55,090
what are the best board
presentations to give,

584
00:27:55,090 --> 00:27:57,520
or what are some of the best metrics

585
00:27:57,520 --> 00:27:59,360
we need to give our boards?

586
00:27:59,360 --> 00:28:02,129
And whilst these are
super important topics,

587
00:28:02,130 --> 00:28:04,450
I just want to note metrics

588
00:28:04,450 --> 00:28:06,650
and presentations and not enough,

589
00:28:06,650 --> 00:28:09,410
we can and should go above and beyond

590
00:28:09,410 --> 00:28:11,580
and engage those executives.

591
00:28:11,580 --> 00:28:13,889
So a couple of examples there for you.

592
00:28:13,890 --> 00:28:17,030
I've seen some of my
clients use gamification

593
00:28:17,030 --> 00:28:19,340
to simulate a company breach.

594
00:28:19,340 --> 00:28:22,399
The executives end up playing
the role of the attacker

595
00:28:22,400 --> 00:28:23,310
or the executives,

596
00:28:23,310 --> 00:28:26,010
and they have to make
on the spot decisions

597
00:28:26,010 --> 00:28:28,110
in every stage of that tech.

598
00:28:28,110 --> 00:28:29,830
So cool, so much energy.

599
00:28:29,830 --> 00:28:31,389
It just gives them a completely

600
00:28:31,390 --> 00:28:34,290
different perspective of security.

601
00:28:34,290 --> 00:28:38,790
Another client of mine placed
their senior executive group

602
00:28:38,790 --> 00:28:41,409
in the spotlight and
they conducted research

603
00:28:41,410 --> 00:28:45,530
into their personal cyber digital profile.

604
00:28:45,530 --> 00:28:47,080
What that ended up doing

605
00:28:47,080 --> 00:28:49,639
is it showed those executives,

606
00:28:49,640 --> 00:28:54,380
their personal, how the risks
of their personal behavior,

607
00:28:54,380 --> 00:28:58,300
and how information
found about them online

608
00:28:58,300 --> 00:29:00,003
can be used against them.

609
00:29:01,640 --> 00:29:04,060
Some other examples back in the days

610
00:29:04,060 --> 00:29:06,020
when I used to be able to travel,

611
00:29:06,020 --> 00:29:07,466
I was traveling in India,

612
00:29:07,467 --> 00:29:10,850
and I stumbled across
this beautiful Rangoli,

613
00:29:10,850 --> 00:29:13,139
and Rangoli, I'm sorry.

614
00:29:13,140 --> 00:29:15,130
And for those of you
who like me did not know

615
00:29:15,130 --> 00:29:16,230
what Rangoli is,

616
00:29:16,230 --> 00:29:18,970
it's this beautiful art using rice.

617
00:29:18,970 --> 00:29:22,530
And it was to celebrate
computer security day

618
00:29:22,530 --> 00:29:24,620
outside of the State Bank of India.

619
00:29:24,620 --> 00:29:27,939
What a beautiful way to attract customers

620
00:29:27,940 --> 00:29:30,160
and employees to that conversation.

621
00:29:30,160 --> 00:29:32,280
Back when I used to leave in the UK

622
00:29:32,280 --> 00:29:34,120
a very long time ago,

623
00:29:34,120 --> 00:29:36,520
one of my clients were having issues

624
00:29:36,520 --> 00:29:39,430
with identity and access
management behaviors.

625
00:29:39,430 --> 00:29:43,610
So instead of lecturing
their employees about it,

626
00:29:43,610 --> 00:29:45,560
they invited a famous comedian

627
00:29:45,560 --> 00:29:47,270
to talk about identity theft

628
00:29:47,270 --> 00:29:48,910
in a comedian kind of a way.

629
00:29:48,910 --> 00:29:52,610
Again, building the hearts
and minds engagements.

630
00:29:52,610 --> 00:29:54,379
And I know I've shared a lot with you,

631
00:29:54,380 --> 00:29:57,320
there's obviously a lot more
depth we could have gone into

632
00:29:57,320 --> 00:30:00,590
and please just don't
let this be overwhelming.

633
00:30:00,590 --> 00:30:01,980
This is all a journey,

634
00:30:01,980 --> 00:30:03,580
it's not a miracle,

635
00:30:03,580 --> 00:30:05,860
you don't have to do it by yourself,

636
00:30:05,860 --> 00:30:07,919
you can share the load.

637
00:30:07,920 --> 00:30:09,940
And one of the ways by which

638
00:30:09,940 --> 00:30:11,600
I've seen my clients share the load

639
00:30:11,600 --> 00:30:14,740
is creating security champions networks

640
00:30:14,740 --> 00:30:17,190
to help create that engagement.

641
00:30:17,190 --> 00:30:20,100
So I've got a couple of steps for you here

642
00:30:20,100 --> 00:30:22,030
on the slides that you can take away

643
00:30:22,030 --> 00:30:27,030
for how specifically to build
that network of influences.

644
00:30:27,430 --> 00:30:29,850
I'm getting towards the end now.

645
00:30:29,850 --> 00:30:32,260
And I want to talk about possibly

646
00:30:32,260 --> 00:30:35,450
the most important part of
this presentation for me.

647
00:30:35,450 --> 00:30:36,780
All of the above,

648
00:30:36,780 --> 00:30:38,030
everything that we've just talked

649
00:30:38,030 --> 00:30:41,570
and spoken about need skills.

650
00:30:41,570 --> 00:30:45,730
They are skills that we were
not necessarily born web

651
00:30:45,730 --> 00:30:46,760
and nor should we have.

652
00:30:46,760 --> 00:30:48,110
We've all had different trainings,

653
00:30:48,110 --> 00:30:49,870
different backgrounds,
different experiences.

654
00:30:49,870 --> 00:30:54,780
That's what makes our industry
so special and so unique.

655
00:30:54,780 --> 00:30:56,490
But there are skills
that we need to develop.

656
00:30:56,490 --> 00:30:57,940
And at some point,

657
00:30:57,940 --> 00:31:00,400
all of us in our careers
need to make a decision

658
00:31:00,400 --> 00:31:01,750
to build on those skills.

659
00:31:01,750 --> 00:31:04,830
So I'm gonna give you a
few leadership skills,

660
00:31:04,830 --> 00:31:07,010
people skills, so important,

661
00:31:07,010 --> 00:31:08,500
particularly if you're a leader obviously,

662
00:31:08,500 --> 00:31:10,040
but even if you're not,

663
00:31:10,040 --> 00:31:13,310
it's really important that
you develop unfamiliar skills

664
00:31:13,310 --> 00:31:16,490
and you can do so by
engaging with members,

665
00:31:16,490 --> 00:31:19,200
executive coaches, sponsors,

666
00:31:19,200 --> 00:31:22,343
acquire communications and
public speaking skills.

667
00:31:23,570 --> 00:31:25,899
I've had too, a lot of people have too,

668
00:31:25,900 --> 00:31:29,910
you don't want your
first board presentation

669
00:31:29,910 --> 00:31:34,630
to be your first ever
public speaking engagement.

670
00:31:34,630 --> 00:31:37,070
So start building on that.

671
00:31:37,070 --> 00:31:40,053
And if you are a leader specifically,

672
00:31:41,200 --> 00:31:44,650
it is unlikely that you're
going to develop and perfect

673
00:31:44,650 --> 00:31:45,930
all of the skills that you need

674
00:31:45,930 --> 00:31:47,140
fill this leadership positions.

675
00:31:47,140 --> 00:31:49,460
So, recruit those skills

676
00:31:49,460 --> 00:31:52,500
and those resources that you don't have.

677
00:31:52,500 --> 00:31:54,270
And it's really important

678
00:31:54,270 --> 00:31:57,389
for me almost at every talk track

679
00:31:57,390 --> 00:31:58,933
and presentation that I do,

680
00:32:01,620 --> 00:32:04,209
that I raise this issue of mental health,

681
00:32:04,210 --> 00:32:05,820
particularly as we are still

682
00:32:05,820 --> 00:32:08,663
in the middle of this global pandemic,

683
00:32:10,334 --> 00:32:13,590
you need to have the mental
space and the clarity.

684
00:32:13,590 --> 00:32:17,100
Burnout is life in our security industry.

685
00:32:17,100 --> 00:32:19,879
And managing this burnout
needs to be a priority.

686
00:32:19,880 --> 00:32:21,690
A couple of tips for you,

687
00:32:21,690 --> 00:32:26,380
make sure at all times that you
put on your own oxygen mask,

688
00:32:26,380 --> 00:32:27,840
lead with purpose.

689
00:32:27,840 --> 00:32:30,290
When things get really overwhelming,

690
00:32:30,290 --> 00:32:32,350
go back to the purpose

691
00:32:32,350 --> 00:32:34,679
of why you're doing what you're doing.

692
00:32:34,680 --> 00:32:36,760
I find that industry in particular

693
00:32:36,760 --> 00:32:39,200
is extremely purpose driven.

694
00:32:39,200 --> 00:32:42,640
We do this for the good of society.

695
00:32:42,640 --> 00:32:46,440
Communicate with each
other, with your boss,

696
00:32:46,440 --> 00:32:50,330
with your teams, at the
appropriate frequency

697
00:32:50,330 --> 00:32:53,260
with empathy and clarity
and be vulnerable.

698
00:32:53,260 --> 00:32:54,750
And I'm not talking about walking

699
00:32:54,750 --> 00:32:57,650
around the office so
virtual meetings crying.

700
00:32:57,650 --> 00:33:01,660
No, I'm talking about being
able to share parts of yourself

701
00:33:01,660 --> 00:33:04,410
to make sure that others
understand that you're human,

702
00:33:04,410 --> 00:33:05,980
that you're going through challenges,

703
00:33:05,980 --> 00:33:09,080
which will in turn help them to open up.

704
00:33:09,080 --> 00:33:10,949
And as the old adage says,

705
00:33:10,950 --> 00:33:12,740
people don't care how much you know

706
00:33:12,740 --> 00:33:14,890
until they know how much you care.

707
00:33:14,890 --> 00:33:18,810
You empathy on funding

708
00:33:18,810 --> 00:33:22,450
is something that's coming
up in so many leadership

709
00:33:22,450 --> 00:33:25,570
and organizational
conversations at the moment.

710
00:33:25,570 --> 00:33:27,389
Now I want to close with this.

711
00:33:27,390 --> 00:33:29,320
I talked about my own cultural Jen,

712
00:33:29,320 --> 00:33:32,980
and I want to introduce
you to the new generation.

713
00:33:32,980 --> 00:33:34,240
This is my daughter.

714
00:33:34,240 --> 00:33:37,800
Her name is Mia, and
she's now 12 years old,

715
00:33:37,800 --> 00:33:42,159
her challenges and mine
as a young immigrant,

716
00:33:42,160 --> 00:33:43,530
they're not even comparable.

717
00:33:43,530 --> 00:33:47,490
Mia as born and raised in Australia.

718
00:33:47,490 --> 00:33:49,830
She never owned a mano brow.

719
00:33:49,830 --> 00:33:51,679
And as you can see from this picture,

720
00:33:51,680 --> 00:33:54,150
she's always on trend.

721
00:33:54,150 --> 00:33:58,610
She's a very easy person
to receive and to be liked.

722
00:33:58,610 --> 00:34:01,449
One of the things that I admire about Mia

723
00:34:01,450 --> 00:34:04,950
is that she has been raised

724
00:34:04,950 --> 00:34:07,860
with the importance of
the skills of empathy,

725
00:34:07,860 --> 00:34:09,659
influence and politics.

726
00:34:09,659 --> 00:34:12,870
So for example, when Mia wants an iPhone

727
00:34:12,870 --> 00:34:16,083
or an app to make receiving
her pocket money easier,

728
00:34:18,799 --> 00:34:19,980
she goes through a process.

729
00:34:19,980 --> 00:34:21,670
She goes through a political process

730
00:34:21,670 --> 00:34:25,100
and that political process
happens to be exactly

731
00:34:25,100 --> 00:34:28,380
the same takeaways that I
want you to take with you.

732
00:34:28,380 --> 00:34:31,139
She will start by planting a seed

733
00:34:31,139 --> 00:34:34,159
well ahead of once she wants that iPhone.

734
00:34:34,159 --> 00:34:36,920
She will document her
requirements quite often,

735
00:34:36,920 --> 00:34:38,850
she's written me business cases,

736
00:34:38,850 --> 00:34:42,150
I've seen more business
cases come out of that child

737
00:34:42,150 --> 00:34:45,803
than I have from some of my team members.

738
00:34:47,219 --> 00:34:49,540
She will explain in her business case,

739
00:34:49,540 --> 00:34:53,300
not how the iPhone is going to help her,

740
00:34:53,300 --> 00:34:55,880
but how it's going to be easy,

741
00:34:55,880 --> 00:34:59,340
you're for me to track and
monitor what she's doing

742
00:34:59,340 --> 00:35:00,720
for her safety.

743
00:35:00,720 --> 00:35:02,080
And in parallel to all of these,

744
00:35:02,080 --> 00:35:05,080
she's going to enlist
my sister, my father,

745
00:35:05,080 --> 00:35:06,750
she'll message my best friends,

746
00:35:06,750 --> 00:35:08,280
she'll message my mother,

747
00:35:08,280 --> 00:35:10,160
she builds a coalition.

748
00:35:10,160 --> 00:35:13,920
She understands the concept
of collective momentum.

749
00:35:13,920 --> 00:35:15,870
She has a growth mindset,

750
00:35:15,870 --> 00:35:18,350
always willing to listen and change course

751
00:35:18,350 --> 00:35:19,880
based on the feedback.

752
00:35:19,880 --> 00:35:24,290
Feel us, full of empathy,
vulnerability, and possibilities.

753
00:35:24,290 --> 00:35:28,759
I wish for all of us to be
like that next generation.

754
00:35:28,760 --> 00:35:30,290
Thank you very much for your time,

755
00:35:30,290 --> 00:35:33,550
I'm really looking
forward to engaging more

756
00:35:33,550 --> 00:35:34,670
with you on the chat.

757
00:35:34,670 --> 00:35:36,800
If you've got any questions,

758
00:35:36,800 --> 00:35:40,773
also welcome, hit me up
on LinkedIn, on Twitter,

759
00:35:41,760 --> 00:35:43,972
and thank you very much.

760
00:35:43,972 --> 00:35:46,139
(silence)

