1
00:00:00,730 --> 00:00:03,550
- Welcome, and thank you
so much for joining me

2
00:00:03,550 --> 00:00:05,869
as I walk through this case study

3
00:00:05,870 --> 00:00:08,773
on information security dashboards.

4
00:00:10,350 --> 00:00:13,540
Now I understand there have been hundreds

5
00:00:13,540 --> 00:00:15,620
or more presentations at RSA

6
00:00:15,620 --> 00:00:18,680
and other conferences
on security dashboards,

7
00:00:18,680 --> 00:00:20,270
and I wanna be upfront and let you know

8
00:00:20,270 --> 00:00:22,570
that this is not a metric session.

9
00:00:22,570 --> 00:00:27,370
This is a real life example
of how I built a dashboard

10
00:00:27,370 --> 00:00:29,573
and then it failed and how I recovered.

11
00:00:30,720 --> 00:00:33,360
And to tell the story, I
turned to one of the most

12
00:00:33,360 --> 00:00:36,230
recognized slogans in advertising.

13
00:00:36,230 --> 00:00:39,430
When you care enough
to send the very best,

14
00:00:39,430 --> 00:00:42,820
this was born on a three
by five inch note card

15
00:00:42,820 --> 00:00:46,033
in 1944 by Ed Goodman.

16
00:00:46,940 --> 00:00:49,019
I mean, Ed was a Sales
and Marketing Executive

17
00:00:49,020 --> 00:00:51,700
at the Hallmark company and he
just jotted down his thoughts

18
00:00:51,700 --> 00:00:56,700
on what Hallmark stood for,
caring, quality and the best.

19
00:00:56,980 --> 00:01:00,772
And now it's number 15 on the
top 50 slogans of all time.

20
00:01:01,940 --> 00:01:05,030
And it's my standard disclaimer
that this information

21
00:01:05,030 --> 00:01:08,073
does not necessarily reflect
current or past employers.

22
00:01:09,040 --> 00:01:12,110
And lastly, I hope that you will learn

23
00:01:12,110 --> 00:01:14,560
that they didn't tell
me at least in college

24
00:01:14,560 --> 00:01:16,660
that storytelling would be so important

25
00:01:16,660 --> 00:01:18,210
as a security leader.

26
00:01:18,210 --> 00:01:19,259
And so hopefully that's something

27
00:01:19,260 --> 00:01:21,160
you learn out of this as well.

28
00:01:21,160 --> 00:01:23,610
I'll also encourage you
to type your questions

29
00:01:23,610 --> 00:01:25,040
into the chat window at any time,

30
00:01:25,040 --> 00:01:26,740
and I'll be happy to answer those.

31
00:01:29,490 --> 00:01:31,740
So when I started at this company,

32
00:01:31,740 --> 00:01:35,850
they had a good security
foundation all ready in place.

33
00:01:35,850 --> 00:01:37,850
I was actually hired to re-imagine

34
00:01:37,850 --> 00:01:39,592
the program and mature it.

35
00:01:40,700 --> 00:01:44,290
The company had just made a
change to a pure SAS model.

36
00:01:44,290 --> 00:01:46,780
And so that certainly
impacted some of our policies

37
00:01:46,780 --> 00:01:49,350
and procedures and controls.

38
00:01:49,350 --> 00:01:51,270
So when I stepped in, I performed

39
00:01:51,270 --> 00:01:55,130
a NIST CSF self-assessment
which highlighted the areas

40
00:01:55,130 --> 00:01:57,210
of highest risk and from this,

41
00:01:57,210 --> 00:02:00,253
I was able to create
that multi-year roadmap.

42
00:02:03,060 --> 00:02:04,500
So similar to Hallmark,

43
00:02:04,500 --> 00:02:07,783
how do you build your security
brand at your company?

44
00:02:08,699 --> 00:02:11,880
I mean, building a roadmap
with clear measurements

45
00:02:11,880 --> 00:02:15,220
from the self-assessment, that
was pretty straightforward.

46
00:02:15,220 --> 00:02:18,690
However, how do we
ensure the prioritization

47
00:02:18,690 --> 00:02:21,150
of the items in the
roadmap that that's align

48
00:02:21,150 --> 00:02:23,233
with the goals of the leadership team?

49
00:02:24,930 --> 00:02:26,270
So this is how I approach this.

50
00:02:26,270 --> 00:02:28,540
First, I took an
inventory of the policies,

51
00:02:28,540 --> 00:02:32,200
procedures and tools that
were all ready in place.

52
00:02:32,200 --> 00:02:34,269
I mean, many of the
tools, they were turned on

53
00:02:34,270 --> 00:02:35,730
and had one or two features running,

54
00:02:35,730 --> 00:02:37,882
but they needed a major health check.

55
00:02:38,920 --> 00:02:42,030
The SIEM had to be totally rebuilt.

56
00:02:42,030 --> 00:02:45,170
The outsource SOC was not
being held accountable.

57
00:02:45,170 --> 00:02:49,070
The EDR tool was over
seven versions behind,

58
00:02:49,070 --> 00:02:50,660
the vulnerability scanner was there

59
00:02:50,660 --> 00:02:52,890
just to check the PCI box

60
00:02:52,890 --> 00:02:55,950
and it wasn't performing
authenticated scans.

61
00:02:55,950 --> 00:02:59,733
So it had many false
positives and this caused

62
00:02:59,734 --> 00:03:03,210
the infrastructure team
to not trust the tool

63
00:03:03,210 --> 00:03:07,283
and thus not patch critical
items such as Microsoft Office.

64
00:03:08,410 --> 00:03:11,329
And remember, these are all
behind the scenes activities

65
00:03:11,330 --> 00:03:13,690
to build your brand and
the maturity of the program

66
00:03:13,690 --> 00:03:15,293
without any additional funding.

67
00:03:16,590 --> 00:03:19,040
If you come to your
first board presentation

68
00:03:19,040 --> 00:03:20,769
or major leadership presentation,

69
00:03:20,770 --> 00:03:23,270
and you can show what
you've all ready done

70
00:03:23,270 --> 00:03:26,220
without their knowledge
or permission to improve

71
00:03:26,220 --> 00:03:28,150
the security of the enterprise

72
00:03:28,150 --> 00:03:30,060
and without additional funding,

73
00:03:30,060 --> 00:03:32,700
they're gonna be much more apt to trust

74
00:03:32,700 --> 00:03:33,750
and to listen to you.

75
00:03:37,440 --> 00:03:41,050
So my next question is
how do I show the value

76
00:03:41,050 --> 00:03:43,440
that the executives really
care about regardless

77
00:03:43,440 --> 00:03:45,800
of how relevant I think
it may or may not be

78
00:03:45,800 --> 00:03:47,373
to actual cybersecurity?

79
00:03:49,100 --> 00:03:51,560
So for me, when I look at this,

80
00:03:51,560 --> 00:03:54,920
I tend to offer personalized
security awareness training

81
00:03:54,920 --> 00:03:58,100
for different teams based on the risks

82
00:03:58,100 --> 00:04:00,010
such as your HRS team.

83
00:04:00,010 --> 00:04:02,049
Maybe if they've made
direct deposit changes

84
00:04:02,050 --> 00:04:05,180
for the bad guys, you can
target training to them,

85
00:04:05,180 --> 00:04:07,490
or the finance team after they've paid out

86
00:04:07,490 --> 00:04:10,810
a business email compromise,
and didn't realize it.

87
00:04:10,810 --> 00:04:13,513
Again, this helps you gain
that additional trust.

88
00:04:14,400 --> 00:04:18,280
Then, taking the always
fun cyber insurance calls

89
00:04:19,170 --> 00:04:22,710
with many underwriters
and using your dark web

90
00:04:22,710 --> 00:04:25,830
monitoring company to search
for personal information

91
00:04:25,830 --> 00:04:28,430
on each of the executives
on their families.

92
00:04:28,430 --> 00:04:31,630
Again, you are building trust
that money just can't buy

93
00:04:31,630 --> 00:04:35,343
and you're not costing the
business any additional funds.

94
00:04:36,808 --> 00:04:40,690
And how many of you are involved
with your industry ISACs

95
00:04:40,690 --> 00:04:44,660
I mean, these are invaluable
if you are actively involved

96
00:04:44,660 --> 00:04:46,743
and actively sharing information.

97
00:04:47,770 --> 00:04:50,490
And I don't just mean
sharing hashes from attacks,

98
00:04:50,490 --> 00:04:54,320
but information specific to
tools that you are using,

99
00:04:54,320 --> 00:04:56,840
how they may or may not
be working web attacks

100
00:04:56,840 --> 00:04:58,260
that you're fighting.

101
00:04:58,260 --> 00:05:00,610
I mean, when I think of threat intel

102
00:05:00,610 --> 00:05:03,250
I think of yet other feed into the SIEM,

103
00:05:03,250 --> 00:05:06,730
which may or may not provide
value to our organization.

104
00:05:06,730 --> 00:05:09,250
But for me, the real value of the ISAC

105
00:05:09,250 --> 00:05:12,150
is the sharing of specific
tools and third parties

106
00:05:12,150 --> 00:05:13,453
and their vulnerability.

107
00:05:19,250 --> 00:05:21,720
So now that we have built the brand,

108
00:05:21,720 --> 00:05:23,453
how do we create this dashboard?

109
00:05:26,941 --> 00:05:29,380
I think the easiest way
to build a dashboard

110
00:05:29,380 --> 00:05:32,230
is directly from your
audits and framework.

111
00:05:32,230 --> 00:05:34,053
I mean, why reinvent the wheel?

112
00:05:35,480 --> 00:05:37,650
So for us again, and many of you,

113
00:05:37,650 --> 00:05:39,890
if you and your teams and your enterprises

114
00:05:39,890 --> 00:05:42,700
are aligned with the NIST
cybersecurity framework,

115
00:05:42,700 --> 00:05:44,729
you can look at each of those five pillars

116
00:05:44,730 --> 00:05:46,530
when you're building your dashboard.

117
00:05:47,720 --> 00:05:49,900
I mean, think about the identified pillar.

118
00:05:49,900 --> 00:05:52,640
Certainly you have some sort
of change management meetings

119
00:05:52,640 --> 00:05:53,860
and you're tracking metrics

120
00:05:53,860 --> 00:05:55,710
from your change management meetings,

121
00:05:56,550 --> 00:06:00,180
with the approved and
unapproved, and emergency changes

122
00:06:00,180 --> 00:06:02,640
or your vulnerability
management program, right?

123
00:06:02,640 --> 00:06:06,729
Where you can show the
number of unpatched machines

124
00:06:06,730 --> 00:06:10,173
or non-standard configurations.

125
00:06:12,090 --> 00:06:13,479
Moving on to the protect pillar

126
00:06:13,480 --> 00:06:16,440
when you have your
security awareness program,

127
00:06:16,440 --> 00:06:20,180
or your patching program,
you can show metrics

128
00:06:20,180 --> 00:06:23,540
from the success of each
security awareness campaign

129
00:06:23,540 --> 00:06:26,330
that you're launching and
track that on your dashboard,

130
00:06:26,330 --> 00:06:27,820
your patching metrics.

131
00:06:27,820 --> 00:06:30,080
And if you're doing full
disk encryption across

132
00:06:30,080 --> 00:06:31,530
the enterprise, those metrics

133
00:06:33,870 --> 00:06:36,510
Moving on to the detect pillar,

134
00:06:36,510 --> 00:06:39,330
certainly you have an employee
detection and response tool

135
00:06:39,330 --> 00:06:41,960
a SIEM you should be producing

136
00:06:41,960 --> 00:06:43,820
some sort of metrics from those.

137
00:06:43,820 --> 00:06:48,820
Again, only measure what is
valuable to you and the team.

138
00:06:49,220 --> 00:06:51,480
There's many things that
reports those tools have,

139
00:06:51,480 --> 00:06:54,040
they're not valuable that
are more on the techie side.

140
00:06:54,040 --> 00:06:57,003
We're looking for more
measurable, valuable metrics.

141
00:06:58,700 --> 00:07:01,539
If you have a SOC whether
it's insourced or outsourced

142
00:07:01,540 --> 00:07:03,910
certainly they're providing you
some sort of monthly reports

143
00:07:03,910 --> 00:07:06,780
on your number of cases, the
criticality of the cases,

144
00:07:06,780 --> 00:07:08,289
time to resolve.

145
00:07:08,290 --> 00:07:10,363
And so you can track those as well.

146
00:07:12,100 --> 00:07:14,420
And lastly, the recover pillar,

147
00:07:14,420 --> 00:07:17,030
your quarterly, your
annual disaster recovery

148
00:07:17,030 --> 00:07:18,770
and business continuity testing

149
00:07:18,770 --> 00:07:21,240
to show the value of that
maybe your tabletop drills

150
00:07:21,240 --> 00:07:23,720
that you're doing all monitoring that,

151
00:07:23,720 --> 00:07:26,103
and putting those numbers
onto your dashboard.

152
00:07:29,500 --> 00:07:33,130
So now you're ready for your
first board presentation

153
00:07:33,130 --> 00:07:34,890
at the new company.

154
00:07:34,890 --> 00:07:37,250
Now this is no matter
what meeting you're in,

155
00:07:37,250 --> 00:07:40,100
but especially in a board
meeting, they're very bright,

156
00:07:40,100 --> 00:07:42,700
very smart, very busy individuals.

157
00:07:42,700 --> 00:07:45,289
And like anything else
after three to five minutes

158
00:07:45,290 --> 00:07:47,060
if you haven't captured their attention,

159
00:07:47,060 --> 00:07:48,910
they're gonna revert to their phones.

160
00:07:49,990 --> 00:07:51,740
So what we need to do is, when we come in,

161
00:07:51,740 --> 00:07:52,940
we need to ask for their help

162
00:07:52,940 --> 00:07:55,337
because as you and I all
know, technology alone

163
00:07:55,337 --> 00:07:57,832
cannot and will not
protect us from everything.

164
00:07:59,530 --> 00:08:01,750
So how do we keep it
relevant and captivating?

165
00:08:01,750 --> 00:08:04,850
We need to ask them how
they've been personally

166
00:08:04,850 --> 00:08:08,300
impacted by cyber security,
with identity theft,

167
00:08:08,300 --> 00:08:11,743
and email scams and
phishing and their kids.

168
00:08:13,420 --> 00:08:16,220
But remember also, our board
members really are smart,

169
00:08:16,220 --> 00:08:18,400
but they probably don't
understand our jargon.

170
00:08:18,400 --> 00:08:21,030
So again, making it personal is key.

171
00:08:21,030 --> 00:08:23,080
And one of the ways we can do that,

172
00:08:23,080 --> 00:08:25,163
is by building common ground.

173
00:08:27,070 --> 00:08:28,570
This is something that I've used

174
00:08:28,570 --> 00:08:31,420
in many of my work presentations
and it really seems

175
00:08:31,420 --> 00:08:33,669
to get very positive feedback.

176
00:08:33,669 --> 00:08:37,000
And that is comparing cyber
health to human health.

177
00:08:37,000 --> 00:08:39,409
I mean, they really are similar.

178
00:08:39,409 --> 00:08:42,073
Think about why do
computer systems get sick?

179
00:08:43,080 --> 00:08:46,300
We observed some of the same
causes and stages of disease

180
00:08:46,300 --> 00:08:48,089
as we do in the human body.

181
00:08:48,090 --> 00:08:51,500
And attackers do go where
security is the weakest.

182
00:08:51,500 --> 00:08:54,800
So if you think about bad
genes that folks have,

183
00:08:54,800 --> 00:08:58,839
well in the cyber world, we
have software or configurations

184
00:08:58,840 --> 00:09:00,830
that could be, you know have unreliable

185
00:09:00,830 --> 00:09:02,620
or obsolete components.

186
00:09:02,620 --> 00:09:05,540
And these are some technical
security vulnerabilities

187
00:09:05,540 --> 00:09:08,392
that internal flaw that
these software programs have.

188
00:09:09,330 --> 00:09:12,490
Or failure to practice basic hygiene.

189
00:09:12,490 --> 00:09:14,070
We talk about washing our hands

190
00:09:14,070 --> 00:09:16,460
and how that can help prevent infection.

191
00:09:16,460 --> 00:09:20,240
Similarly, we allow our team members

192
00:09:20,240 --> 00:09:22,480
to go to unreliable or risky websites

193
00:09:22,480 --> 00:09:25,760
or use unapproved software
products or components.

194
00:09:25,760 --> 00:09:28,660
Then this can lead to infection
or create a security hole.

195
00:09:30,650 --> 00:09:32,949
Think about unbalanced, nutrition,

196
00:09:32,950 --> 00:09:35,730
I mean the diet of our organization

197
00:09:35,730 --> 00:09:37,393
and its business processes.

198
00:09:38,620 --> 00:09:41,220
Think if you have disorder
in your documentation,

199
00:09:41,220 --> 00:09:43,940
or you don't have a clear
responsibility matrix.

200
00:09:43,940 --> 00:09:46,720
Maybe you don't have an
inventory asset tracking system

201
00:09:46,720 --> 00:09:49,780
or you don't really do change management.

202
00:09:49,780 --> 00:09:53,593
These leads to all sorts of
losses and security incidents.

203
00:09:54,810 --> 00:09:55,642
But on the other hand,

204
00:09:55,643 --> 00:09:57,600
you can have excessive red tape, right?

205
00:09:57,600 --> 00:10:00,530
And bureaucracies and authorization levels

206
00:10:00,530 --> 00:10:01,620
that will inhibit the business.

207
00:10:01,620 --> 00:10:04,853
And so you have to have balance
there just like nutrition.

208
00:10:07,450 --> 00:10:08,670
Lastly, stress.

209
00:10:08,670 --> 00:10:10,790
I mean our bodies certainly we can do

210
00:10:10,790 --> 00:10:12,099
to stressful conditions.

211
00:10:12,100 --> 00:10:14,490
And if your staff are always overworked

212
00:10:14,490 --> 00:10:16,663
or overburdened with red tape,

213
00:10:17,730 --> 00:10:20,960
they're probably gonna neglect
your security procedures.

214
00:10:20,960 --> 00:10:24,190
And just like with a healthy lifestyle,

215
00:10:24,190 --> 00:10:25,900
the effects of these precautions

216
00:10:25,900 --> 00:10:28,180
that sometimes they can't
be seen immediately.

217
00:10:28,180 --> 00:10:31,443
And therefore they often
really go underestimated.

218
00:10:35,490 --> 00:10:38,420
The next question that I get
very common, very frequent

219
00:10:38,420 --> 00:10:41,689
is what's the magic number of slides

220
00:10:41,690 --> 00:10:44,040
you put in your board presentations?

221
00:10:44,040 --> 00:10:47,189
And I hope you know, there
really truly is no right or wrong

222
00:10:47,190 --> 00:10:48,633
number of slides.

223
00:10:49,698 --> 00:10:52,910
You just need to use the
least amount of slides

224
00:10:52,910 --> 00:10:55,709
that can convey the message accurately

225
00:10:55,710 --> 00:10:58,283
in a way that everyone in
the room can understand.

226
00:10:59,600 --> 00:11:02,330
To do this, you really need to present

227
00:11:02,330 --> 00:11:04,530
to your CIO and CFO first.

228
00:11:04,530 --> 00:11:07,050
And this is regardless
of reporting structures.

229
00:11:07,050 --> 00:11:09,240
It doesn't matter who you report to,

230
00:11:09,240 --> 00:11:11,890
you should, in my experience,
and my recommendation

231
00:11:11,890 --> 00:11:14,930
is always to present to
the CIO and the CFO first

232
00:11:14,930 --> 00:11:16,089
for their feedback.

233
00:11:16,090 --> 00:11:21,090
They are usually very, very
valuable with their feedback.

234
00:11:21,270 --> 00:11:23,670
They've been in these
presentations before,

235
00:11:23,670 --> 00:11:24,569
and they can give you

236
00:11:24,570 --> 00:11:26,733
some really great
information and pointers.

237
00:11:30,770 --> 00:11:33,300
You need to keep your
report in your dashboard

238
00:11:33,300 --> 00:11:35,992
simple and free from acronyms.

239
00:11:38,040 --> 00:11:39,209
Many of the board members,

240
00:11:39,210 --> 00:11:41,540
they understand accounting frameworks,

241
00:11:41,540 --> 00:11:43,550
even if they're not an accountant,

242
00:11:43,550 --> 00:11:46,380
board members tend to really
understand the numbers

243
00:11:46,380 --> 00:11:49,510
and because they've come
from other industries

244
00:11:49,510 --> 00:11:52,250
where they use that same
accounting framework.

245
00:11:52,250 --> 00:11:55,620
And so we need explain the what
and why behind our framework

246
00:11:55,620 --> 00:11:58,820
and compared to other
frameworks, just like accounting,

247
00:11:58,820 --> 00:12:01,420
and tell them why it's important

248
00:12:01,420 --> 00:12:03,219
that we're following this framework.

249
00:12:04,420 --> 00:12:09,420
Lastly, our board members they
love having benchmark data

250
00:12:10,000 --> 00:12:10,907
and asking the question,

251
00:12:10,907 --> 00:12:14,620
"Why would we be doing something
if our competitors aren't?"

252
00:12:14,620 --> 00:12:17,030
And so again, this is where
you can really heavily rely

253
00:12:17,030 --> 00:12:20,550
on your ISACs in trying to
get that de-identified data

254
00:12:20,550 --> 00:12:23,209
of how many of our peer organizations

255
00:12:23,210 --> 00:12:26,410
are also using the NIST
cybersecurity framework.

256
00:12:26,410 --> 00:12:27,640
It's probably pretty high.

257
00:12:27,640 --> 00:12:30,120
And again, that's gonna
help you build that trust.

258
00:12:30,120 --> 00:12:32,530
You didn't go out and
invent this framework,

259
00:12:32,530 --> 00:12:35,569
it's something that can come
in and be independently audited

260
00:12:35,570 --> 00:12:38,063
and that really will
help you gain that trust.

261
00:12:41,300 --> 00:12:44,740
So when I presented first to our CFO,

262
00:12:44,740 --> 00:12:48,700
he told me, in line of the
NIST cybersecurity framework

263
00:12:48,700 --> 00:12:50,890
after I explained what that was,

264
00:12:50,890 --> 00:12:52,923
and gave the background of the industry,

265
00:12:53,770 --> 00:12:55,930
he told me he really wanted us to focus

266
00:12:55,930 --> 00:12:58,992
on the protect aspect of the framework.

267
00:12:59,900 --> 00:13:04,214
And that was the exact
feedback that I needed.

268
00:13:04,214 --> 00:13:07,860
He said, "let's assume the bad
guys are all ready inside."

269
00:13:07,860 --> 00:13:10,860
And so with those clear
set of instructions

270
00:13:10,860 --> 00:13:13,520
that it helped me group our
initiatives in the buckets

271
00:13:13,520 --> 00:13:17,347
with dollar amounts to show
the true cost of our program

272
00:13:17,347 --> 00:13:19,090
and the cost over the next few years

273
00:13:19,090 --> 00:13:21,250
as we mature the program.

274
00:13:21,250 --> 00:13:23,920
Going from maybe a one to a three or four

275
00:13:23,920 --> 00:13:26,223
on the NIST maturity scale.

276
00:13:28,030 --> 00:13:30,250
And since phishing was the number one

277
00:13:30,250 --> 00:13:31,860
and continues to be the number one way

278
00:13:31,860 --> 00:13:35,970
that ransomware is deployed,
we had our marching orders.

279
00:13:35,970 --> 00:13:37,353
We said, let's go phish.

280
00:13:40,340 --> 00:13:43,100
But, before we can go phishing,

281
00:13:43,100 --> 00:13:46,060
we need to focus on another P word.

282
00:13:46,060 --> 00:13:48,209
I mean, you can't go to
a security presentation

283
00:13:48,210 --> 00:13:52,150
in the last 20 or 30 years
without talking about patching.

284
00:13:52,150 --> 00:13:54,860
And typically patching is handled
by the infrastructure team

285
00:13:54,860 --> 00:13:58,050
but reported on by the security team.

286
00:13:58,050 --> 00:13:59,030
I mean, this is like

287
00:13:59,030 --> 00:14:01,637
the perfect tattletale situation, right?

288
00:14:01,638 --> 00:14:05,250
And as a result, most security
and infrastructure teams

289
00:14:05,250 --> 00:14:07,000
just don't get along.

290
00:14:07,000 --> 00:14:08,991
I mean, just think about
your brothers and sisters,

291
00:14:08,991 --> 00:14:10,683
or even your kids.

292
00:14:14,210 --> 00:14:16,400
So here was the backstory.

293
00:14:16,400 --> 00:14:19,990
And when I came in, again,
a patching tools in place

294
00:14:21,730 --> 00:14:25,260
and vulnerability scans were
run but they were inaccurate

295
00:14:25,260 --> 00:14:27,913
because they were running
without authentication.

296
00:14:29,210 --> 00:14:32,070
And the real focus of
those scans had always been

297
00:14:32,070 --> 00:14:34,720
to only scan and patch PCI assets

298
00:14:34,720 --> 00:14:37,103
that fall into the PCI scope.

299
00:14:39,870 --> 00:14:41,120
So I had to take a step back

300
00:14:41,120 --> 00:14:43,550
and how do I approach this delicately?

301
00:14:43,550 --> 00:14:46,199
I mean, the bad guys don't
care if it's a PCI asset

302
00:14:46,200 --> 00:14:49,703
or not it's all on the network,
it's all network-connected.

303
00:14:51,310 --> 00:14:53,959
How can I approach this
so that the infrastructure

304
00:14:53,960 --> 00:14:57,590
and the security team actually
get along and collaborate?

305
00:14:57,590 --> 00:15:00,213
And let me tell you, I didn't
do it right the first time.

306
00:15:02,490 --> 00:15:05,730
So the way I like to solve
these type of challenges

307
00:15:05,730 --> 00:15:08,310
is just like performing
a root cause analysis

308
00:15:08,310 --> 00:15:10,750
when you have an incident,
when you have an outage.

309
00:15:10,750 --> 00:15:13,720
And this is really how I
try to attack these issues,

310
00:15:13,720 --> 00:15:16,690
let's get in a room, let's
take out the emotions

311
00:15:16,690 --> 00:15:19,540
and the finger-pointing and
just write down the facts.

312
00:15:19,540 --> 00:15:22,400
And so here's the facts to our situation.

313
00:15:22,400 --> 00:15:25,939
Too much effort was being
placed on testing the patches.

314
00:15:25,940 --> 00:15:27,780
I don't know if you've experienced this.

315
00:15:27,780 --> 00:15:31,020
Some companies have an entire
team that that's all they do.

316
00:15:31,020 --> 00:15:33,810
Five days a week is test the patches

317
00:15:33,810 --> 00:15:35,550
of all their different systems ongoing.

318
00:15:35,550 --> 00:15:36,859
And as soon as they stopped,

319
00:15:36,860 --> 00:15:38,583
it starts over for the next month.

320
00:15:40,510 --> 00:15:43,393
Is that really a good use of your team?

321
00:15:45,210 --> 00:15:47,360
The next fact was, well
things have changed

322
00:15:47,360 --> 00:15:51,090
since I came into the
company, we have no customer

323
00:15:51,090 --> 00:15:54,170
on-prem applications, we
are fully cloud-based.

324
00:15:54,170 --> 00:15:55,699
So what are you testing?

325
00:15:55,700 --> 00:15:57,000
What is there really to test?

326
00:15:57,000 --> 00:15:59,513
What are you testing with
the patches each month?

327
00:16:01,060 --> 00:16:04,689
So we decided that we are
going to patch everything now

328
00:16:04,690 --> 00:16:07,300
every month, but roll it out in groups.

329
00:16:07,300 --> 00:16:08,949
And maybe some of you
are all ready doing this,

330
00:16:08,950 --> 00:16:11,050
again, it's not rocket science,

331
00:16:11,050 --> 00:16:13,223
it was a real light bulb moment for us.

332
00:16:14,710 --> 00:16:17,060
We're gonna roll it out to a group of 10,

333
00:16:17,060 --> 00:16:20,410
and wait a few days, not
a week, but a few days,

334
00:16:20,410 --> 00:16:22,640
roll it out to 20 or 30 more workstations,

335
00:16:22,640 --> 00:16:24,040
roll it out to 50.

336
00:16:24,040 --> 00:16:26,060
And after that, it's been two weeks,

337
00:16:26,060 --> 00:16:28,183
we're gonna roll it out
to the whole company.

338
00:16:29,680 --> 00:16:32,520
And now when we run those
vulnerability scans,

339
00:16:32,520 --> 00:16:34,610
each month after the
patching has been done,

340
00:16:34,610 --> 00:16:37,590
we're gonna give that report
to the infrastructure team

341
00:16:37,590 --> 00:16:39,820
one week prior to
publishing in our dashboard,

342
00:16:39,820 --> 00:16:42,720
that was something that I did
not do right the first time.

343
00:16:43,777 --> 00:16:46,080
We never wanna go into a
meeting and can be blindsided

344
00:16:46,080 --> 00:16:47,500
by something that's shared.

345
00:16:47,500 --> 00:16:49,880
And yet I did that without
even realizing it, right?

346
00:16:49,880 --> 00:16:52,750
I was so excited to put
up our first dashboard.

347
00:16:52,750 --> 00:16:54,980
They had never had a security dashboard,

348
00:16:54,980 --> 00:16:56,500
and I didn't think anything

349
00:16:56,500 --> 00:16:57,980
that it was gonna hurt anyone out there.

350
00:16:57,980 --> 00:17:00,720
And I published this dashboard
and the patching metrics

351
00:17:00,720 --> 00:17:03,390
were horrible and the infrastructure team

352
00:17:03,390 --> 00:17:05,040
really felt thrown under the bus.

353
00:17:05,930 --> 00:17:08,540
So by giving it to them a week prior,

354
00:17:08,540 --> 00:17:12,000
we can weed out any false
positives, and we can collaborate

355
00:17:12,000 --> 00:17:13,460
on maybe some of the stories

356
00:17:13,460 --> 00:17:16,390
of why some of the
vulnerabilities are where they are

357
00:17:16,390 --> 00:17:17,380
in the report.

358
00:17:17,380 --> 00:17:20,720
And so it's more of
collaboration, less name calling.

359
00:17:20,720 --> 00:17:22,770
So if you're not doing
something like this,

360
00:17:22,770 --> 00:17:25,160
again regardless of reporting structure,

361
00:17:25,160 --> 00:17:26,560
I would highly encourage it.

362
00:17:28,618 --> 00:17:32,332
So now that we can actually
move on to phishing,

363
00:17:34,193 --> 00:17:38,280
again at this company, we
had a program in place,

364
00:17:38,280 --> 00:17:43,280
but it was being run infrequently,
maybe only quarterly,

365
00:17:43,320 --> 00:17:45,800
and with very limited
visibility in the results,

366
00:17:45,800 --> 00:17:47,649
they really weren't shared with anyone

367
00:17:47,650 --> 00:17:52,650
except the security team and
the same campaign was being run

368
00:17:52,840 --> 00:17:53,919
for the entire company.

369
00:17:53,920 --> 00:17:58,260
So the entire company would
get the exact same email.

370
00:17:58,260 --> 00:18:00,780
And, you can just lean over the cube

371
00:18:00,780 --> 00:18:02,450
or I guess virtually, right?

372
00:18:02,450 --> 00:18:04,190
Chat someone, "Hey,
they're testing us today.

373
00:18:04,190 --> 00:18:05,840
Be sure you don't click on that."

374
00:18:06,870 --> 00:18:11,209
In addition, that email was
so specifically crafted.

375
00:18:11,210 --> 00:18:14,570
It had to go through 10 levels
of approval from HR to legal,

376
00:18:14,570 --> 00:18:16,560
all these different teams to make sure

377
00:18:16,560 --> 00:18:19,210
it didn't offend anyone
before it was being sent out.

378
00:18:20,160 --> 00:18:21,210
Again, there's balance there,

379
00:18:21,210 --> 00:18:23,370
but the bad guys don't
get those approvals.

380
00:18:23,370 --> 00:18:26,993
They just send it out again.

381
00:18:28,320 --> 00:18:29,500
The results were not being shared

382
00:18:29,500 --> 00:18:31,083
outside of the security team.

383
00:18:32,090 --> 00:18:35,899
And there wasn't a wall of
shame which is a good thing,

384
00:18:35,900 --> 00:18:39,080
but there also weren't
like recognition or prizes

385
00:18:39,080 --> 00:18:42,230
for the best catch for those
that didn't click on it.

386
00:18:42,230 --> 00:18:44,460
So you kinda think of the
positive reinforcement.

387
00:18:44,460 --> 00:18:46,610
There was really nothing,
it was all really done

388
00:18:46,610 --> 00:18:49,392
in a vacuum, again more
as just a checkbox.

389
00:18:52,427 --> 00:18:54,043
So did we catch anything?

390
00:18:55,650 --> 00:18:59,410
To report on that, to put
this in your dashboard,

391
00:18:59,410 --> 00:19:01,660
you really need to know
your industry average

392
00:19:01,660 --> 00:19:03,490
'cause that's the first
question you're gonna be asked

393
00:19:03,490 --> 00:19:05,690
when you report on this at any level is?

394
00:19:05,690 --> 00:19:06,530
What's normal?

395
00:19:06,530 --> 00:19:08,473
What's average? What's right?

396
00:19:09,340 --> 00:19:13,429
As security professionals, we
all know that one is too many,

397
00:19:13,430 --> 00:19:15,720
but we have to be realistic
and we have to set a target

398
00:19:15,720 --> 00:19:18,270
because we're all humans
and it's going to happen.

399
00:19:18,270 --> 00:19:20,920
And so, again, going back to your ISAC,

400
00:19:20,920 --> 00:19:24,260
and checking with other
peers in your industry,

401
00:19:24,260 --> 00:19:25,440
there's a lot that goes into it

402
00:19:25,440 --> 00:19:26,730
because you can have an organization

403
00:19:26,730 --> 00:19:28,680
that may still be sending
that same campaign

404
00:19:28,680 --> 00:19:30,120
out to the whole company, so their numbers

405
00:19:30,120 --> 00:19:31,080
are gonna look great

406
00:19:31,080 --> 00:19:32,879
because once the first few people get it,

407
00:19:32,880 --> 00:19:34,620
they do share with everyone else.

408
00:19:34,620 --> 00:19:36,629
And so to me, that's
not an accurate metric,

409
00:19:36,630 --> 00:19:39,640
but again you have to take
all of those and average them

410
00:19:39,640 --> 00:19:43,510
to see what your industry
average should be for click rate

411
00:19:43,510 --> 00:19:45,713
or respond rate or failure rate.

412
00:19:47,200 --> 00:19:49,470
So for us, it was 3%.

413
00:19:49,470 --> 00:19:53,760
We found out at the time, in
our industry of our peers,

414
00:19:53,760 --> 00:19:58,170
similar organizations that
about 3% of the team members

415
00:19:58,170 --> 00:20:01,110
were failing their regular
phishing exercises.

416
00:20:01,110 --> 00:20:04,030
So we had a very clear defined target,

417
00:20:04,030 --> 00:20:06,443
and we were ready to go phishing.

418
00:20:09,920 --> 00:20:14,520
So we published, talking about
visibility and transparency,

419
00:20:14,520 --> 00:20:16,480
and something that's huge for me.

420
00:20:16,480 --> 00:20:17,800
And it had never been done before,

421
00:20:17,800 --> 00:20:21,129
we published the monthly report
to all directors and above

422
00:20:21,130 --> 00:20:25,140
again, this is for each department
they got to see the names

423
00:20:25,140 --> 00:20:28,060
of their team members and
whether they passed or failed

424
00:20:28,930 --> 00:20:31,110
their phishing tests for that month.

425
00:20:31,110 --> 00:20:33,350
Let me tell you, when you
do something like that,

426
00:20:33,350 --> 00:20:35,629
you better get ready for
the fallout and be ready

427
00:20:35,630 --> 00:20:37,090
to defend yourself.

428
00:20:37,090 --> 00:20:38,510
We would spend our entire team

429
00:20:38,510 --> 00:20:40,310
would spend at least a week

430
00:20:40,310 --> 00:20:41,710
every time we sent the report out

431
00:20:41,710 --> 00:20:43,360
doing nothing but research,

432
00:20:43,360 --> 00:20:46,189
we would research logs
from our web filters,

433
00:20:46,190 --> 00:20:49,880
the mobile device system,
our email gateway,

434
00:20:49,880 --> 00:20:52,000
EDR, all of our systems

435
00:20:52,000 --> 00:20:55,720
because we constantly
heard responses like,

436
00:20:55,720 --> 00:20:58,650
I didn't click on that and
you can't even prove it.

437
00:20:58,650 --> 00:21:01,140
Or I was out of the office on that day,

438
00:21:01,140 --> 00:21:02,790
there's no way I clicked on that.

439
00:21:04,200 --> 00:21:05,680
Even better, we would hear that employee

440
00:21:05,680 --> 00:21:07,590
is on extended leave,

441
00:21:07,590 --> 00:21:09,959
or the best response that person

442
00:21:09,960 --> 00:21:11,833
doesn't even work here anymore.

443
00:21:13,020 --> 00:21:15,700
What these team members and
directors didn't realize

444
00:21:15,700 --> 00:21:19,360
was that according to our
identity access management policy

445
00:21:19,360 --> 00:21:21,689
when a team member exits the organization,

446
00:21:21,690 --> 00:21:23,930
their email is disabled,

447
00:21:23,930 --> 00:21:27,260
it's forwarded to their direct manager.

448
00:21:27,260 --> 00:21:29,460
And so the manager would get the emails,

449
00:21:29,460 --> 00:21:30,500
and click on the links.

450
00:21:30,500 --> 00:21:32,800
And of course, as you all
know the phishing programs

451
00:21:32,800 --> 00:21:34,840
still report that back as a failure

452
00:21:34,840 --> 00:21:37,112
for the intended recipient.

453
00:21:38,630 --> 00:21:40,862
Something else we
learned is that employees

454
00:21:40,862 --> 00:21:43,190
do check their mail on their days off,

455
00:21:43,190 --> 00:21:44,960
even if they're hourly and
they aren't supposed to,

456
00:21:44,960 --> 00:21:46,720
unless you have some way to prevent that

457
00:21:46,720 --> 00:21:48,420
with a mobile device management system

458
00:21:48,420 --> 00:21:51,473
or identity access privileged system.

459
00:21:57,740 --> 00:22:00,970
So we publish those
reports, we've defended them

460
00:22:01,920 --> 00:22:04,093
and we see the numbers continue to rise.

461
00:22:05,100 --> 00:22:07,899
And so with that, how did we
convince our executive team

462
00:22:07,900 --> 00:22:12,763
to tie those phishing metrics,
those dashboards to bonuses?

463
00:22:15,620 --> 00:22:18,000
It was through some hard conversations

464
00:22:19,590 --> 00:22:24,030
in all seriousness, I had conversations

465
00:22:24,030 --> 00:22:26,260
with our leadership team and
just really let them know

466
00:22:26,260 --> 00:22:30,930
that I don't need another
dime for my security budget

467
00:22:30,930 --> 00:22:33,180
if we can't get our phishing numbers down.

468
00:22:33,180 --> 00:22:37,040
I mean, we are spending
millions on technical controls,

469
00:22:37,040 --> 00:22:40,993
but our team members just keep
clicking on anything we sent.

470
00:22:42,270 --> 00:22:44,870
And this was really eye-opening to our CIO

471
00:22:44,870 --> 00:22:46,070
and the entire leadership team.

472
00:22:46,070 --> 00:22:48,919
They had never had someone seriously say

473
00:22:48,920 --> 00:22:51,150
that they didn't need any more budget.

474
00:22:51,150 --> 00:22:53,650
And then follow that up with
the suggestion to hit others

475
00:22:53,650 --> 00:22:56,683
where it impacts the
most, in their salaries.

476
00:22:57,580 --> 00:22:58,560
Now don't get me wrong.

477
00:22:58,560 --> 00:23:00,240
I understand there's many different areas

478
00:23:00,240 --> 00:23:01,403
of risk to a company.

479
00:23:02,480 --> 00:23:05,020
And our team members are very busy,

480
00:23:05,020 --> 00:23:06,660
but they weren't motivated to slow down

481
00:23:06,660 --> 00:23:08,260
and read their emails carefully.

482
00:23:09,140 --> 00:23:12,213
And as we all know,
money really does talk.

483
00:23:13,090 --> 00:23:17,480
And so we set this policy
that for each director,

484
00:23:17,480 --> 00:23:20,140
they are now responsible for their teams

485
00:23:20,140 --> 00:23:23,760
and any team with an average
above a 3% failure rate

486
00:23:23,760 --> 00:23:28,093
in a 12-month calendar, well,
will have a reduced bonus.

487
00:23:31,990 --> 00:23:36,990
So we've rolled that out
and something changed.

488
00:23:37,860 --> 00:23:40,370
Now, remember the purpose
of security awareness

489
00:23:40,370 --> 00:23:43,810
is not to shame, but to educate.

490
00:23:43,810 --> 00:23:46,560
And we were using a best-of-breed

491
00:23:46,560 --> 00:23:51,560
industry-recognized solutions,
but our numbers just continue

492
00:23:51,670 --> 00:23:53,530
to trustingly increase each month.

493
00:23:53,530 --> 00:23:56,770
And we thought, wow,
we've done the training,

494
00:23:56,770 --> 00:23:57,860
we've tied it to bonus,

495
00:23:57,860 --> 00:23:59,530
and the numbers just continue to go up.

496
00:23:59,530 --> 00:24:01,303
Where is the breakdown?

497
00:24:02,670 --> 00:24:07,130
So we started sending test
messages amongst just our team.

498
00:24:07,130 --> 00:24:09,290
We saw that a high number
of the test messages

499
00:24:09,290 --> 00:24:12,720
were being blocked by 0365.

500
00:24:12,720 --> 00:24:16,630
We also saw that no attempt
at safe-listing worked,

501
00:24:16,630 --> 00:24:18,303
the messages were being blocked.

502
00:24:22,250 --> 00:24:25,400
In addition, the messages
showed being opened and clicked

503
00:24:25,400 --> 00:24:27,100
within seconds of being delivered.

504
00:24:27,100 --> 00:24:28,909
We thought, well we've got
some great team members

505
00:24:28,910 --> 00:24:32,163
and all that, I think this
is statistically impossible.

506
00:24:33,470 --> 00:24:37,510
So we set up multiple test
scenarios to prove out

507
00:24:37,510 --> 00:24:41,483
that the sandboxing was the
root of some of these issues.

508
00:24:43,600 --> 00:24:46,959
With that, we set up multiple
calls with Microsoft,

509
00:24:46,960 --> 00:24:50,580
with our email security vendor
and our phishing test vendor.

510
00:24:50,580 --> 00:24:55,260
And after weeks of making
changes and tests and calls,

511
00:24:55,260 --> 00:24:58,523
we decided, unfortunately it
was just time for a change.

512
00:25:01,054 --> 00:25:02,760
This really was hard,

513
00:25:02,760 --> 00:25:05,730
we really did like our
phishing test vendor.

514
00:25:05,730 --> 00:25:10,450
They provided great reporting
and great customer service.

515
00:25:10,450 --> 00:25:13,290
And me personally, I really liked layers,

516
00:25:13,290 --> 00:25:15,240
I do not like to use the same vendor

517
00:25:16,100 --> 00:25:17,840
for multiple security services,

518
00:25:17,840 --> 00:25:21,320
but because of all of
our research and testing,

519
00:25:21,320 --> 00:25:23,480
we had to make a change,

520
00:25:23,480 --> 00:25:26,213
and we had to really embrace the change.

521
00:25:28,280 --> 00:25:30,463
So we did, and the results are in.

522
00:25:36,610 --> 00:25:40,830
So with all of this said,
we think how in the world,

523
00:25:40,830 --> 00:25:44,470
are we gonna regain the
trust of our leadership team?

524
00:25:44,470 --> 00:25:46,847
Because we've had to go
back to them and tell them,

525
00:25:46,847 --> 00:25:49,270
"Hey, this solution that we're using

526
00:25:49,270 --> 00:25:53,370
through a long chain series
of events is not accurate.

527
00:25:53,370 --> 00:25:55,929
The results we're seeing
each month are not accurate

528
00:25:55,930 --> 00:26:00,087
for multiple reasons, and
so we need to start over."

529
00:26:01,260 --> 00:26:05,980
So we did, we stopped all
reporting for two months,

530
00:26:05,980 --> 00:26:10,130
we stopped all testing for two
months of our team members.

531
00:26:10,130 --> 00:26:13,800
Instead we internally tested
and deployed a new system.

532
00:26:13,800 --> 00:26:17,399
And this time, the system that we use

533
00:26:17,400 --> 00:26:19,650
was with the same vendor
that we currently use

534
00:26:19,650 --> 00:26:21,293
for our email security gateway.

535
00:26:24,230 --> 00:26:27,900
We couldn't get any false
positives to fire off,

536
00:26:27,900 --> 00:26:31,300
everything that we said came
through and showed accurately.

537
00:26:31,300 --> 00:26:33,399
Some that we clicked, some that we didn't.

538
00:26:34,450 --> 00:26:35,970
And so we thought, how will we start this?

539
00:26:35,970 --> 00:26:38,040
We wanna start off on a positive foot

540
00:26:38,040 --> 00:26:39,100
for the entire company.

541
00:26:39,100 --> 00:26:41,469
And so why not take
this new platform again?

542
00:26:41,470 --> 00:26:44,140
Remember, our goal is
education, not shaming.

543
00:26:44,140 --> 00:26:46,950
And so why don't we
launch this new system,

544
00:26:46,950 --> 00:26:49,910
and do the employee, the
annual training with it first,

545
00:26:49,910 --> 00:26:52,570
instead of just straight
to phishing testing.

546
00:26:52,570 --> 00:26:54,980
So again, not the hour-long
PowerPoint that everyone

547
00:26:54,980 --> 00:26:56,460
clicks through while they're
drinking their coffee,

548
00:26:56,460 --> 00:27:00,560
watching a TV show, but a
five to seven to 15-minute

549
00:27:00,560 --> 00:27:03,929
at the most humorous interactive video

550
00:27:03,930 --> 00:27:05,520
with a short quiz at the end.

551
00:27:05,520 --> 00:27:09,530
And so we launched that
across the board and after all

552
00:27:09,530 --> 00:27:11,840
or at least a high majority
of our team members

553
00:27:11,840 --> 00:27:13,600
had completed that training.

554
00:27:13,600 --> 00:27:16,983
We sent our first campaign
and we crossed our fingers.

555
00:27:21,404 --> 00:27:24,940
And with a sigh of relief,
we were back to normal.

556
00:27:24,940 --> 00:27:27,050
The test results were back to normal.

557
00:27:27,050 --> 00:27:29,389
Actually they were much better.

558
00:27:29,390 --> 00:27:31,550
The first round failure rate was less,

559
00:27:31,550 --> 00:27:35,730
we had less than 1% of our
team members fail the test.

560
00:27:35,730 --> 00:27:38,202
And we thought, well, this could
be because of COVID, right?

561
00:27:38,202 --> 00:27:40,139
A lot of people are on edge,

562
00:27:40,139 --> 00:27:44,348
Maybe that they're just
being extra paranoid,

563
00:27:44,348 --> 00:27:47,280
but it gets even better,
the new service that we used

564
00:27:47,280 --> 00:27:49,500
was a managed phishing test service.

565
00:27:49,500 --> 00:27:52,130
And so they could do
all the research for us

566
00:27:52,130 --> 00:27:54,110
when we did have people complained back

567
00:27:54,110 --> 00:27:55,860
that if there was a false positive.

568
00:27:56,750 --> 00:27:59,210
And so with this trust was reestablished.

569
00:27:59,210 --> 00:28:01,300
I mean the executives would even call

570
00:28:01,300 --> 00:28:03,180
when they accidentally click on a test

571
00:28:03,180 --> 00:28:04,680
and let me know ahead of time.

572
00:28:08,470 --> 00:28:12,268
So how can you take all of
this and apply it positively

573
00:28:12,268 --> 00:28:15,940
in your environment, in
your day-to-day work?

574
00:28:15,940 --> 00:28:18,250
I would really encourage you

575
00:28:18,250 --> 00:28:20,920
when you go back to your
organization after this,

576
00:28:20,920 --> 00:28:22,980
that you would review the
accuracy of the metrics

577
00:28:22,980 --> 00:28:23,813
in your dashboard.

578
00:28:23,813 --> 00:28:26,330
Maybe it's one of those
things where you've got

579
00:28:26,330 --> 00:28:29,330
all these different inputs
from all these different teams,

580
00:28:29,330 --> 00:28:33,490
and maybe you've got some
great BI system or something

581
00:28:33,490 --> 00:28:35,500
that's putting these together for you.

582
00:28:35,500 --> 00:28:38,100
I would really encourage
you to review the accuracy,

583
00:28:38,100 --> 00:28:42,770
do some very targeted
testing amongst a group

584
00:28:42,770 --> 00:28:44,710
and test the clicks on the not clicks

585
00:28:44,710 --> 00:28:47,900
or the failures in the past
and see if your metrics

586
00:28:47,900 --> 00:28:50,050
that you're presenting
really are accurate.

587
00:28:51,760 --> 00:28:53,940
I would also encourage
you, and this unfortunately

588
00:28:53,940 --> 00:28:56,470
has to be done on at
least a monthly basis,

589
00:28:56,470 --> 00:29:00,830
because as we know, as we
embrace cloud and SAS systems,

590
00:29:00,830 --> 00:29:03,460
those rules with our
SAS providers can change

591
00:29:03,460 --> 00:29:04,970
without us even knowing.

592
00:29:04,970 --> 00:29:07,360
And so I would encourage
you to inspect those rules

593
00:29:07,360 --> 00:29:10,229
that you have in place,
safe-listing rules,

594
00:29:10,230 --> 00:29:11,777
blocking rules between
your phishing vendor

595
00:29:11,777 --> 00:29:15,120
and your email security
gateway on a regular basis.

596
00:29:15,120 --> 00:29:16,909
This should be unfortunately
like it's almost

597
00:29:16,910 --> 00:29:19,690
like patching where
something you have to inspect

598
00:29:19,690 --> 00:29:20,840
and check once a month

599
00:29:23,120 --> 00:29:24,959
After you've done that,
I would encourage you

600
00:29:24,960 --> 00:29:29,470
to set up a time where
you can verify your brand

601
00:29:29,470 --> 00:29:31,190
among your C-Suite.

602
00:29:31,190 --> 00:29:33,770
Do they truly understand the value

603
00:29:33,770 --> 00:29:35,883
that you're bringing to the organization?

604
00:29:36,730 --> 00:29:39,170
It can be through current or future,

605
00:29:39,170 --> 00:29:40,730
even non-project initiatives.

606
00:29:40,730 --> 00:29:43,270
So again, it's always great
when security can come

607
00:29:43,270 --> 00:29:46,470
into something that's not
a security-focused project,

608
00:29:46,470 --> 00:29:49,420
then provide value maybe
through a single sign

609
00:29:49,420 --> 00:29:52,250
on initiative or something
that can save the business time

610
00:29:52,250 --> 00:29:54,770
or reduce some steps in a process

611
00:29:54,770 --> 00:29:56,633
and add security at the same time.

612
00:29:58,250 --> 00:30:02,140
And then within six months,
you really should be updating

613
00:30:02,140 --> 00:30:04,310
your dashboard to reflect and align

614
00:30:04,310 --> 00:30:05,580
with your security framework.

615
00:30:05,580 --> 00:30:08,330
And whether it's the ISO
framework, the PCI framework,

616
00:30:08,330 --> 00:30:11,520
HIPAA framework, a high-trust NIST,

617
00:30:11,520 --> 00:30:14,110
you really need to make
sure your security dashboard

618
00:30:14,110 --> 00:30:16,322
aligns with your security framework.

619
00:30:16,322 --> 00:30:18,651
And then always, always, always question

620
00:30:18,652 --> 00:30:21,540
the parameters around your
security awareness program.

621
00:30:21,540 --> 00:30:26,540
Are you rewarding those members
that are constantly passing,

622
00:30:26,760 --> 00:30:29,042
they're constantly reporting the phishes,

623
00:30:29,042 --> 00:30:31,389
are you doing the best catch
every week or every month

624
00:30:31,390 --> 00:30:33,810
where you're giving out
a gift card or something,

625
00:30:33,810 --> 00:30:35,500
or are you just putting up a wall of shame

626
00:30:35,500 --> 00:30:36,450
of those that fail?

627
00:30:39,960 --> 00:30:41,620
Again, I thank you so much for listening.

628
00:30:41,620 --> 00:30:43,810
I would encourage you to put
questions in the chat window

629
00:30:43,810 --> 00:30:45,550
and I'm happy to answer those for you.

630
00:30:45,550 --> 00:30:48,100
Again, hope you have a
great conference, thank you.

