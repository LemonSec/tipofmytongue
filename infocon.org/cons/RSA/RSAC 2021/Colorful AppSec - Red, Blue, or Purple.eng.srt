1
00:00:00,312 --> 00:00:01,650
- Hello everyone,

2
00:00:01,650 --> 00:00:04,290
and welcome to the RSA Conference

3
00:00:04,290 --> 00:00:07,490
Enlightning Talk, Colorful
AppSec, Red, Blue or Purple.

4
00:00:07,490 --> 00:00:09,220
My name is Erez Yalon.

5
00:00:09,220 --> 00:00:11,550
I'm the founder and Mayor
of the AppSec Village

6
00:00:11,550 --> 00:00:14,920
and I'll be the moderator here today.

7
00:00:14,920 --> 00:00:17,850
In this session, we will
hear from three experts.

8
00:00:17,850 --> 00:00:20,590
Each expert will speak
for up to seven minutes

9
00:00:20,590 --> 00:00:25,360
to share their perspective of
their idea one after another.

10
00:00:25,360 --> 00:00:26,900
Following all three presentations,

11
00:00:26,900 --> 00:00:30,060
we will have a QA session
for the remaining time.

12
00:00:30,060 --> 00:00:33,010
You can write the question
in the chat at any time,

13
00:00:33,010 --> 00:00:34,129
feel free to do that.

14
00:00:34,130 --> 00:00:36,950
We like questions,
especially the good ones.

15
00:00:36,950 --> 00:00:38,360
Please specify if your questions

16
00:00:38,360 --> 00:00:40,793
should be directed to a specific speaker.

17
00:00:41,765 --> 00:00:44,000
Okay, let's get started.

18
00:00:44,000 --> 00:00:47,970
So first thing line we
have Pedro Umbelino.

19
00:00:47,970 --> 00:00:50,830
He's a security researcher,
(indistinct) maker,

20
00:00:50,830 --> 00:00:53,730
software breaker, right
to the bones hacker.

21
00:00:53,730 --> 00:00:55,330
And actually a good friend.

22
00:00:55,330 --> 00:00:58,610
Pedro will share with
us his Red perspective.

23
00:00:58,610 --> 00:01:00,580
Take it away, Pedro.

24
00:01:00,580 --> 00:01:01,660
- Hello everyone.

25
00:01:01,660 --> 00:01:04,810
It's great to be here at RSA 2021.

26
00:01:04,810 --> 00:01:06,740
I know the conditions are less than ideal,

27
00:01:06,740 --> 00:01:07,990
but still it's great to see

28
00:01:07,990 --> 00:01:10,199
conferences going above and beyond,

29
00:01:10,200 --> 00:01:12,340
deliver meaningful content.

30
00:01:12,340 --> 00:01:14,450
My name is Pedro Umbelino, as Erez talked,

31
00:01:14,450 --> 00:01:16,680
and I've come to talk to you
about Red Teams exercises

32
00:01:16,680 --> 00:01:18,580
in the focus on AppSec.

33
00:01:18,580 --> 00:01:21,039
Now, I've done my share
of Red Team exercises

34
00:01:21,040 --> 00:01:21,873
throughout the years.

35
00:01:21,873 --> 00:01:23,860
Everything from Hollywood style,

36
00:01:23,860 --> 00:01:26,670
social engineering, designing
and placing custom implants

37
00:01:26,670 --> 00:01:28,260
inside organizations,

38
00:01:28,260 --> 00:01:31,220
to less elaborate but not
necessarily less time consuming

39
00:01:31,220 --> 00:01:34,330
network assessments, pentesting
code reviewing software,

40
00:01:34,330 --> 00:01:37,399
reverse engineering and
exploitation and so forth.

41
00:01:37,400 --> 00:01:39,870
What I really want to
stress in this short talk

42
00:01:39,870 --> 00:01:43,460
is the following red teams and
or general offensive security

43
00:01:43,460 --> 00:01:47,039
exercises are should be
the most realistic exercise

44
00:01:47,040 --> 00:01:49,677
that your company can make
the stress test the ability

45
00:01:49,677 --> 00:01:53,380
to withstand or recover from real attacks.

46
00:01:53,380 --> 00:01:56,910
Let me rephrase this regular
offensive security exercises

47
00:01:56,910 --> 00:01:59,130
are the most realistic security exercise

48
00:01:59,130 --> 00:02:01,000
your company can make.

49
00:02:01,000 --> 00:02:03,900
It does not matter how solid
you think your defenses are.

50
00:02:03,900 --> 00:02:05,970
It does not matter how
expensive is your software

51
00:02:05,970 --> 00:02:07,696
or equipment, it does not
matter how many issues

52
00:02:07,696 --> 00:02:10,180
you solve in your SAS report,

53
00:02:10,180 --> 00:02:13,570
does not matter if it is
your devsecops implemented.

54
00:02:13,570 --> 00:02:15,920
And it does not matter
how much money you put

55
00:02:15,920 --> 00:02:17,750
in your bug bounty program.

56
00:02:17,750 --> 00:02:20,570
I mean, all of those things
they help in they matter.

57
00:02:20,570 --> 00:02:24,194
But none of those matters
if you don't actually test

58
00:02:24,194 --> 00:02:27,780
all your defenses in
a real world scenario.

59
00:02:27,780 --> 00:02:29,690
Because attackers won't play nice.

60
00:02:29,690 --> 00:02:32,150
Attackers won't respect
your rules of engagement,

61
00:02:32,150 --> 00:02:34,290
nor your very well defined scope.

62
00:02:34,290 --> 00:02:36,730
Attackers for sure want
focus only on your Android

63
00:02:36,730 --> 00:02:40,090
application and just leave
the API servers alone.

64
00:02:40,090 --> 00:02:42,180
Attackers won't leave the
database server untested

65
00:02:42,180 --> 00:02:44,750
because it's off scope, that won't happen.

66
00:02:44,750 --> 00:02:47,090
And that's why you should care.

67
00:02:47,090 --> 00:02:50,530
Now, this is where I think retting shine.

68
00:02:50,530 --> 00:02:53,470
We think like attackers,
we go beyond cbss,

69
00:02:53,470 --> 00:02:56,390
the high low impact
vulnerability classifications

70
00:02:56,390 --> 00:02:58,709
or bug bounty scores and rewards.

71
00:02:58,710 --> 00:03:00,960
We know malicious attackers are always

72
00:03:00,960 --> 00:03:03,470
innovating figuring
out new attack vectors,

73
00:03:03,470 --> 00:03:05,940
and so are we, they constantly search for

74
00:03:05,940 --> 00:03:08,087
new vulnerabilities, how to exploit them,

75
00:03:08,087 --> 00:03:10,280
how to stay undetected, new ways to deploy

76
00:03:10,280 --> 00:03:11,440
phishing campaigns.

77
00:03:11,440 --> 00:03:15,140
And so are we, as a Red
team, we will be hopefully

78
00:03:15,140 --> 00:03:18,859
your first wave of highly
motivated and skilled attackers.

79
00:03:18,860 --> 00:03:22,800
Now, in appsec, Red Team
exercises are often viewed

80
00:03:22,800 --> 00:03:25,940
as you know, some form of
code auditing or review,

81
00:03:25,940 --> 00:03:28,280
application testing and in some cases,

82
00:03:28,280 --> 00:03:33,280
a bug bounty program that that
is limited in scope and time.

83
00:03:33,320 --> 00:03:35,940
But it can be and should
be much more than that.

84
00:03:35,940 --> 00:03:38,470
Because as red teamers, we became users

85
00:03:38,470 --> 00:03:40,660
and we gain for administrators,

86
00:03:40,660 --> 00:03:43,470
we exploring that your
application ecosystems

87
00:03:43,470 --> 00:03:45,700
and all the pieces
interconnect the potential

88
00:03:45,700 --> 00:03:47,829
vulnerabilities and risks associated

89
00:03:47,830 --> 00:03:49,461
with those vulnerabilities.

90
00:03:49,461 --> 00:03:52,570
Because some risk may not
even have a cbss score

91
00:03:52,570 --> 00:03:54,269
would have mentioned but the PR costs

92
00:03:54,270 --> 00:03:55,150
would just be too much.

93
00:03:55,150 --> 00:03:57,990
For example, and this is
something you probably will not

94
00:03:57,990 --> 00:04:00,750
get you on a bug bounty
or cause cause review.

95
00:04:00,750 --> 00:04:03,470
We are attackers that care
about your organization

96
00:04:03,470 --> 00:04:05,730
and try to figure out how to inflict harm

97
00:04:05,730 --> 00:04:08,609
in every possible way before others do.

98
00:04:08,610 --> 00:04:10,810
Now, I'm not trying to remove value

99
00:04:10,810 --> 00:04:14,300
from bug bounty programs, they
have their intrinsic value.

100
00:04:14,300 --> 00:04:17,269
In my case, in my case, sometimes
even between engagements,

101
00:04:17,269 --> 00:04:18,640
I occasionally participate

102
00:04:18,640 --> 00:04:20,870
in bug bounties for fun and profit.

103
00:04:20,870 --> 00:04:22,480
But here's the thing.

104
00:04:22,480 --> 00:04:26,160
I received bugs, I received
bounties on critical issues

105
00:04:26,160 --> 00:04:27,000
more than once.

106
00:04:27,000 --> 00:04:29,570
And until this day, I still had no idea

107
00:04:29,570 --> 00:04:31,760
what the application was really for.

108
00:04:31,760 --> 00:04:33,900
I just knew I shouldn't be able to perform

109
00:04:33,900 --> 00:04:37,580
certain operations without
ever even being authenticated,

110
00:04:37,580 --> 00:04:41,050
like delete all users, or
forward everything reports

111
00:04:41,050 --> 00:04:43,400
to the internal network, for example,

112
00:04:43,400 --> 00:04:46,159
but I never really understood
what I was attacking,

113
00:04:46,160 --> 00:04:48,830
nor I had the perspective of
the company core businesses

114
00:04:48,830 --> 00:04:51,090
are the risks they prioritize.

115
00:04:51,090 --> 00:04:54,500
So in the sense, I was
not actually worried

116
00:04:54,500 --> 00:04:55,950
about the organization.

117
00:04:55,950 --> 00:04:58,570
I just wanted a quick and nice bounty

118
00:04:58,570 --> 00:05:00,690
and this is where I think
red teams differentiate,

119
00:05:00,690 --> 00:05:03,700
at least in my conception of
what the red team should be.

120
00:05:03,700 --> 00:05:05,620
We become users of your applications

121
00:05:05,620 --> 00:05:07,780
and exploring them from all angles.

122
00:05:07,780 --> 00:05:10,419
We try to understand your user race,

123
00:05:10,420 --> 00:05:14,160
and business models to have a
clear view of what's at stake.

124
00:05:14,160 --> 00:05:15,960
And we strive to make your company safer

125
00:05:15,960 --> 00:05:19,080
while understanding your
organization values and cultures.

126
00:05:19,080 --> 00:05:21,923
And that goes on and on of engagement.

127
00:05:23,100 --> 00:05:25,940
readiness assessments for
organizations are clear,

128
00:05:25,940 --> 00:05:27,790
they can have a snapshot in time

129
00:05:27,790 --> 00:05:29,640
on how secure they are at that moment,

130
00:05:29,640 --> 00:05:31,479
they can measure how well dev sec ops

131
00:05:31,480 --> 00:05:33,210
is benefiting their code,

132
00:05:33,210 --> 00:05:35,830
they can compare different
system code analysis tools

133
00:05:35,830 --> 00:05:37,900
for performance in real world.

134
00:05:37,900 --> 00:05:41,419
And importantly, organizations
can identify new risks

135
00:05:41,420 --> 00:05:44,410
that were not in the original
threat and attack models.

136
00:05:44,410 --> 00:05:47,870
So in this way, they
can rely reliably assess

137
00:05:47,870 --> 00:05:49,990
their state of readiness
when attacked actor

138
00:05:49,990 --> 00:05:51,700
decides to attack.

139
00:05:51,700 --> 00:05:53,740
And all of this, it's critical information

140
00:05:53,740 --> 00:05:56,730
for decision makers to
properly plan for the future,

141
00:05:56,730 --> 00:05:58,760
and can hardly be obtained by other means,

142
00:05:58,760 --> 00:06:01,323
except for realistic attack exercises.

143
00:06:02,820 --> 00:06:05,050
Red Team exercise is not
just about discovering

144
00:06:05,050 --> 00:06:06,600
the organization weaknesses.

145
00:06:06,600 --> 00:06:09,970
And it's really an attempt
to employ lead lateral

146
00:06:09,970 --> 00:06:11,820
and outside of the box thinking regarding

147
00:06:11,820 --> 00:06:14,890
the overall security of the
organization and its business.

148
00:06:14,890 --> 00:06:16,510
In a way it's a statement.

149
00:06:16,510 --> 00:06:18,450
And it's a clear effort
from the organization

150
00:06:18,450 --> 00:06:20,969
to understand their
current security stance

151
00:06:20,970 --> 00:06:24,150
and to continuously improve
it while going going forward.

152
00:06:24,150 --> 00:06:26,299
It's a commitment to secure development

153
00:06:26,300 --> 00:06:27,773
now and for the future.

154
00:06:29,070 --> 00:06:31,360
If you take anything along
with you regarding the stock,

155
00:06:31,360 --> 00:06:33,458
I hope it's the following ratings.

156
00:06:33,458 --> 00:06:36,450
And the right lower offensive
security engagements

157
00:06:36,450 --> 00:06:38,570
are the most realistic security exercises

158
00:06:38,570 --> 00:06:40,670
your company can make security wise,

159
00:06:40,670 --> 00:06:43,059
and in my opinion, one of
the best ways to measure

160
00:06:43,059 --> 00:06:46,623
and prepare for real world
attack with all its implications.

161
00:06:47,740 --> 00:06:49,640
And that's my presentation. Thank you.

162
00:06:52,160 --> 00:06:53,750
- Excellent.

163
00:06:53,750 --> 00:06:58,470
Thank you so much fellow
that was concise and clear.

164
00:06:58,470 --> 00:07:01,253
I think we see our
personal perspective now.

165
00:07:02,100 --> 00:07:05,433
So our next speaker is a Luis Luis gumps.

166
00:07:06,560 --> 00:07:10,040
Lewis is the is the one
that got away from appsec

167
00:07:10,040 --> 00:07:13,440
to the Baldwin was born
in a security fanatic.

168
00:07:13,440 --> 00:07:15,610
Now he's a CSO by night,

169
00:07:15,610 --> 00:07:20,050
with 14 years in big tech
and thinking blue teams.

170
00:07:20,050 --> 00:07:23,010
Moving now to a more managed focused role.

171
00:07:23,010 --> 00:07:26,787
Lewis will share his blue perspective

172
00:07:26,787 --> 00:07:29,792
for this for this lightning
talk. No head looks.

173
00:07:31,480 --> 00:07:33,560
- First of all, thank
you so much for joining.

174
00:07:33,560 --> 00:07:38,180
So like Eric says this
transition from being Pedro

175
00:07:38,180 --> 00:07:41,500
in the in the last slide to
being this guy that is worried

176
00:07:41,500 --> 00:07:44,830
about red teams that I pay
in red teams that are paid

177
00:07:44,830 --> 00:07:47,560
for themselves with
ransomware is something

178
00:07:47,560 --> 00:07:52,373
that keeps me up at night at
various degrees of creativity.

179
00:07:54,190 --> 00:07:57,070
Moving forward, I'm going
to try to present to you

180
00:07:57,070 --> 00:07:59,469
the advances that we made on blue team

181
00:07:59,470 --> 00:08:02,960
and why should we care
about this precious exercise

182
00:08:02,960 --> 00:08:04,330
that we are doing as of now

183
00:08:05,380 --> 00:08:07,870
in our companies of
keeping our data secure?

184
00:08:07,870 --> 00:08:12,220
And our really seriously
can we take the blue team,

185
00:08:12,220 --> 00:08:15,420
as of now that we are
approaching a multi layered,

186
00:08:15,420 --> 00:08:18,670
more AI focused driven security, right.

187
00:08:18,670 --> 00:08:21,200
So as you can see, the
evolution was pretty clear,

188
00:08:21,200 --> 00:08:24,280
when we started this
this exercise of routine,

189
00:08:24,280 --> 00:08:27,549
we were very basic in terms
of perimeter security,

190
00:08:27,550 --> 00:08:31,010
we would leak logs the
entire day, and watch events.

191
00:08:31,010 --> 00:08:35,100
So we still believe
that even if we targeted

192
00:08:35,100 --> 00:08:39,049
by somebody like red teams,
or the the general hacker,

193
00:08:39,049 --> 00:08:40,760
we would be able to react faster,

194
00:08:40,760 --> 00:08:42,159
then he's able to breach us,

195
00:08:43,210 --> 00:08:45,580
we then move to a scenario where there is

196
00:08:45,580 --> 00:08:48,980
more than just computers on the desk,

197
00:08:48,980 --> 00:08:51,160
we have laptops and we have computers

198
00:08:51,160 --> 00:08:53,360
that travel with us at various degrees.

199
00:08:53,360 --> 00:08:56,800
So we needed to have with
with an increase of data,

200
00:08:56,800 --> 00:08:58,660
we needed to have an approach

201
00:08:58,660 --> 00:09:03,120
that would single out a more concise view

202
00:09:03,120 --> 00:09:06,840
over so many events happening
per second, with this time,

203
00:09:06,840 --> 00:09:09,870
the what we know today
as a CMS orchestration,

204
00:09:09,870 --> 00:09:11,380
the threat sharing.

205
00:09:11,380 --> 00:09:14,400
And that was still I would say basic

206
00:09:14,400 --> 00:09:16,420
because up until this point

207
00:09:16,420 --> 00:09:19,160
where you see the third
finger to the fourth finger.

208
00:09:19,160 --> 00:09:20,600
And even to the fifth one,

209
00:09:20,600 --> 00:09:24,880
we still are perceived as
a reactive security. Right.

210
00:09:24,880 --> 00:09:27,890
So one of the things that stuck
with me from what Pedro said

211
00:09:27,890 --> 00:09:30,960
was that this is a real engagement.

212
00:09:30,960 --> 00:09:35,000
This gives you a snapshot in
time of what is being secure

213
00:09:35,000 --> 00:09:36,080
at certain degree.

214
00:09:36,080 --> 00:09:41,080
And that is important for
us in one specific point,

215
00:09:41,540 --> 00:09:44,410
which is can we see blue team without

216
00:09:44,410 --> 00:09:46,620
the word stopping attackers, right?

217
00:09:46,620 --> 00:09:48,950
Why are we always reacting to something

218
00:09:48,950 --> 00:09:52,542
or prepared for something
but we are not a step ahead.

219
00:09:52,542 --> 00:09:54,560
And when I mean a step ahead,

220
00:09:54,560 --> 00:09:58,099
it's not just using leveraging
red teams or purple teams

221
00:09:58,100 --> 00:10:00,250
is more can we pray

222
00:10:00,250 --> 00:10:02,740
Let's consciously what are our risks

223
00:10:02,740 --> 00:10:04,090
and move in that direction

224
00:10:04,090 --> 00:10:06,680
with multi layer
orchestration that you see

225
00:10:06,680 --> 00:10:07,819
on the last picture?

226
00:10:07,820 --> 00:10:12,140
What I mean is, can we
build on top of not only AI,

227
00:10:12,140 --> 00:10:15,810
but on the creativity
side of the defense team,

228
00:10:15,810 --> 00:10:18,824
to engage the defense layer in,

229
00:10:18,825 --> 00:10:21,680
the attackers need to understand us,

230
00:10:21,680 --> 00:10:24,829
and therefore they need
to prepare for the unknown

231
00:10:24,830 --> 00:10:26,960
versus us the blue team that is prepared

232
00:10:26,960 --> 00:10:29,440
for the unknowns of the attackers.

233
00:10:29,440 --> 00:10:30,700
This happens a lot of times.

234
00:10:30,700 --> 00:10:32,400
And you can see this, for example,

235
00:10:32,400 --> 00:10:33,990
in the world that we see today.

236
00:10:33,990 --> 00:10:36,830
ransomware is still using the old tricks,

237
00:10:36,830 --> 00:10:39,430
but is abusing the fact
that we are not doing

238
00:10:39,430 --> 00:10:42,760
either the basics right,
or we don't react in time.

239
00:10:42,760 --> 00:10:46,920
That's why you see regulatory
measures such as GDPR,

240
00:10:46,920 --> 00:10:49,060
and others, that forced us
to have a certain amount

241
00:10:49,060 --> 00:10:50,939
of time to declare a breach,

242
00:10:50,940 --> 00:10:53,330
because they want us to
do whether as blue team,

243
00:10:53,330 --> 00:10:57,730
and our blue team is dependent
on one specific factor

244
00:10:57,730 --> 00:11:02,490
as of now, are we able to
sustain the advances of AI

245
00:11:02,490 --> 00:11:05,560
and become the creative
part of security apparatus,

246
00:11:05,560 --> 00:11:08,609
up until this point was
only red teams creating

247
00:11:08,610 --> 00:11:11,360
the I would say the new things right,

248
00:11:11,360 --> 00:11:13,470
so it's our time to create a new things

249
00:11:13,470 --> 00:11:17,300
by measuring patterns in
humans are just that like

250
00:11:17,300 --> 00:11:19,250
we can measure our patterns,

251
00:11:19,250 --> 00:11:22,160
having the leverage of
purple and red teams

252
00:11:22,160 --> 00:11:24,348
and creating our own unknowns.

253
00:11:24,349 --> 00:11:27,000
And leveraging creativity from humans

254
00:11:27,000 --> 00:11:30,610
will be what bridge the gap
between what we are doing today,

255
00:11:30,610 --> 00:11:32,920
and slowly making making bad decisions

256
00:11:32,920 --> 00:11:36,310
or just being reactive to
not only shifting left,

257
00:11:36,310 --> 00:11:38,339
but to shifting to the
unknown where the attackers

258
00:11:38,340 --> 00:11:41,420
don't even understand
the security measures

259
00:11:41,420 --> 00:11:42,935
that will be applied. Right?

260
00:11:42,936 --> 00:11:46,400
I guess that there is an autopia.

261
00:11:46,400 --> 00:11:49,510
But it's a it's a reality
that I see building

262
00:11:49,510 --> 00:11:51,561
on many companies, such as Netflix

263
00:11:51,561 --> 00:11:55,010
and others are really building
these types of scenarios

264
00:11:55,010 --> 00:11:58,030
where we can see people
when they are trying

265
00:11:58,030 --> 00:12:01,350
to measure the security of
companies at that scale.

266
00:12:01,350 --> 00:12:03,690
They try to reach at one point,

267
00:12:03,690 --> 00:12:06,570
but then they are they are
prepared for the basics

268
00:12:06,570 --> 00:12:08,690
in there prepare for the nose.

269
00:12:08,690 --> 00:12:10,930
And I would I would

270
00:12:10,930 --> 00:12:13,150
if you have to keep something
from this conversation,

271
00:12:13,150 --> 00:12:15,949
I would strongly emphasize that keep

272
00:12:15,950 --> 00:12:17,790
creative creativity with us

273
00:12:17,790 --> 00:12:20,033
the blue team versus with everybody else.

274
00:12:23,145 --> 00:12:25,579
- Thank you loose.

275
00:12:25,580 --> 00:12:26,950
- [Luis] Yes.

276
00:12:26,950 --> 00:12:28,923
- We will take that with us.

277
00:12:30,524 --> 00:12:33,100
Okay, so now it is my
pleasure to introduce

278
00:12:33,100 --> 00:12:36,380
our field expert Tanya Tanya Janka.

279
00:12:36,380 --> 00:12:39,070
Tanya, is the CEO and founder of wiac.

280
00:12:39,070 --> 00:12:43,950
Purple, and to unite us
all in one common goal.

281
00:12:43,950 --> 00:12:46,450
And shall her purple perspective.

282
00:12:46,450 --> 00:12:47,940
Please go ahead.

283
00:12:47,940 --> 00:12:51,140
- Awesome. Could you put
up my slide, please, Amber.

284
00:12:51,140 --> 00:12:53,569
Thank you. Hi, I'm Tanya Janka.

285
00:12:53,570 --> 00:12:55,270
And I'm going to talk about purple team,

286
00:12:55,270 --> 00:12:59,040
which I consider collaborative security.

287
00:12:59,040 --> 00:13:01,793
So when I started in
security as a pen tester,

288
00:13:02,780 --> 00:13:04,360
I had been a software developer,

289
00:13:04,360 --> 00:13:05,930
I became a pen tester.

290
00:13:05,930 --> 00:13:10,270
And then I discovered
that application security

291
00:13:10,270 --> 00:13:12,780
was sort of the umbrella that goes over

292
00:13:12,780 --> 00:13:16,160
the entire thing to make sure
that your software is secure.

293
00:13:16,160 --> 00:13:18,949
So I could not only do security testing,

294
00:13:18,950 --> 00:13:21,190
not as advanced as maybe
our friend over here

295
00:13:21,190 --> 00:13:24,380
on the red team, but
verifying all the basics,

296
00:13:24,380 --> 00:13:27,110
and that there's nothing
grossly incorrect,

297
00:13:27,110 --> 00:13:28,430
that should not be there.

298
00:13:28,430 --> 00:13:30,459
And then also on the other side,

299
00:13:30,460 --> 00:13:34,230
that I could defend, again,
like our blue team or friend,

300
00:13:34,230 --> 00:13:35,990
that I would be able to, you know,

301
00:13:35,990 --> 00:13:39,770
implement different security
tools, different defenses,

302
00:13:39,770 --> 00:13:41,590
work with the devs to teach them

303
00:13:41,590 --> 00:13:43,750
this is the better way to do this thing,

304
00:13:43,750 --> 00:13:46,320
so that I don't catch you
further down the line.

305
00:13:46,320 --> 00:13:49,270
Or by the time our red
team friend shows up,

306
00:13:49,270 --> 00:13:52,319
we make them work very, very hard

307
00:13:52,320 --> 00:13:54,040
on their engagement to find things

308
00:13:54,040 --> 00:13:56,410
because any red Teamer will tell you,

309
00:13:56,410 --> 00:13:57,620
they got to find something.

310
00:13:57,620 --> 00:13:58,930
And if they don't find something,

311
00:13:58,930 --> 00:14:01,093
they get really stressed out.

312
00:14:01,094 --> 00:14:03,350
Awesome. my slides are coming.

313
00:14:03,350 --> 00:14:06,500
So if you could show all of the things

314
00:14:06,500 --> 00:14:08,920
if you could press the Next button, amor.

315
00:14:08,920 --> 00:14:12,310
So in order to be good at appsec,

316
00:14:12,310 --> 00:14:16,040
you have to actually be good
at empathy and advocacy.

317
00:14:16,040 --> 00:14:17,959
I know that that sounds
a little bit weird.

318
00:14:17,960 --> 00:14:19,700
And people might object a little bit.

319
00:14:19,700 --> 00:14:21,750
They're like, it's not about soft skills.

320
00:14:21,750 --> 00:14:23,750
But it actually is.

321
00:14:23,750 --> 00:14:25,500
So when you're red
Teamer, you can come in,

322
00:14:25,500 --> 00:14:29,500
and you can just destroy
things, and do an amazing job.

323
00:14:29,500 --> 00:14:33,470
And then you have to articulate
super clearly what you did,

324
00:14:33,470 --> 00:14:35,600
and hopefully help them fix it.

325
00:14:35,600 --> 00:14:38,750
But if you're doing like
blue team and red team,

326
00:14:38,750 --> 00:14:40,450
you not only have to explain

327
00:14:40,450 --> 00:14:43,350
and articulate super
clearly what's going on,

328
00:14:43,350 --> 00:14:44,980
you actually have to empathize.

329
00:14:44,980 --> 00:14:46,060
So you have to look at

330
00:14:46,060 --> 00:14:49,790
Okay, so the devs have this
deadline of next Friday.

331
00:14:49,790 --> 00:14:53,219
I want them to fix the
57 things that we found

332
00:14:53,220 --> 00:14:54,860
and implement this new tool.

333
00:14:54,860 --> 00:14:57,960
However, there still have
to meet the deadline.

334
00:14:57,960 --> 00:15:02,020
So where can I find sort
of like space in between,

335
00:15:02,020 --> 00:15:03,620
is it possible to move their deadline?

336
00:15:03,620 --> 00:15:05,610
Is it possible to take out one feature

337
00:15:05,610 --> 00:15:08,870
from this deadline and then add
in the security that I need.

338
00:15:08,870 --> 00:15:11,320
So there's not only empathy between like

339
00:15:11,320 --> 00:15:13,610
the security team and
getting what they're done,

340
00:15:13,610 --> 00:15:16,270
but also what the devs need to get done.

341
00:15:16,270 --> 00:15:19,069
And then advocacy is
actually convincing them

342
00:15:19,070 --> 00:15:21,390
to put up with all of security's things

343
00:15:21,390 --> 00:15:23,160
that we're trying to tell them to do.

344
00:15:23,160 --> 00:15:26,459
So the devs are like, I
want to make cool features,

345
00:15:26,460 --> 00:15:30,910
and release awesome stuff,
and make my customers happy

346
00:15:30,910 --> 00:15:34,319
and excited and loving this thing I built.

347
00:15:34,320 --> 00:15:37,240
And it's not that they don't
want to create secure software,

348
00:15:37,240 --> 00:15:38,880
they definitely do.

349
00:15:38,880 --> 00:15:41,580
But us advocating for the things

350
00:15:41,580 --> 00:15:45,130
that we need on the security
team is really important,

351
00:15:45,130 --> 00:15:47,000
whether it be like to the project manager,

352
00:15:47,000 --> 00:15:48,860
whether it be to the client, etc,

353
00:15:48,860 --> 00:15:51,650
we're that person, that helps make sure

354
00:15:51,650 --> 00:15:53,730
that everyone understands
where we're coming from,

355
00:15:53,730 --> 00:15:55,730
and everyone gets the things they need.

356
00:15:55,730 --> 00:15:57,070
And we don't release software

357
00:15:57,070 --> 00:16:02,070
that is a giant pile of
steaming vulnerabilities.

358
00:16:02,380 --> 00:16:05,900
So I consider app sack or
purple team specifically

359
00:16:05,900 --> 00:16:08,630
to be that bridge between
security and devs.

360
00:16:08,630 --> 00:16:10,745
So you can have an
amazing Blue Team person

361
00:16:10,745 --> 00:16:14,490
and they work with the devs a lot.

362
00:16:14,490 --> 00:16:16,740
They also work on their own a lot.

363
00:16:16,740 --> 00:16:18,840
I feel that the purple team person,

364
00:16:18,840 --> 00:16:21,650
not only are we hopefully trying to hire

365
00:16:21,650 --> 00:16:23,760
and recruit an awesome
red Teamer to come in

366
00:16:23,760 --> 00:16:25,438
and do an engagement, we're hoping

367
00:16:25,438 --> 00:16:27,580
that we have blue team people,

368
00:16:27,580 --> 00:16:31,170
either on our team or that
work closely with our team.

369
00:16:31,170 --> 00:16:34,140
But we are trying to make
sure we build that gap.

370
00:16:34,140 --> 00:16:36,590
Or that we fill that gap
that there's no longer

371
00:16:36,590 --> 00:16:38,890
two different silos, Dev and security,

372
00:16:38,890 --> 00:16:40,470
but that we have this person in between

373
00:16:40,470 --> 00:16:43,833
that make sure that we actually
get things done together.

374
00:16:44,797 --> 00:16:48,900
Number three is people process and tools.

375
00:16:48,900 --> 00:16:50,610
You can't do a good job of app sec,

376
00:16:50,610 --> 00:16:52,580
if you have no tools.

377
00:16:52,580 --> 00:16:53,660
You just can't.

378
00:16:53,660 --> 00:16:54,860
Whenever I hear someone say well,

379
00:16:54,860 --> 00:16:55,930
you could just write your own.

380
00:16:55,930 --> 00:16:56,762
I'm like, yeah,

381
00:16:56,763 --> 00:16:59,230
if you want to reinvent
the wheel constantly,

382
00:16:59,230 --> 00:17:01,550
sometimes you do write
scripts, or you adjust things,

383
00:17:01,550 --> 00:17:04,510
or you customize things, so
they're just right for you.

384
00:17:04,510 --> 00:17:08,599
But tools, and people feel
like nothing gets done

385
00:17:08,599 --> 00:17:09,929
without people obviously.

386
00:17:09,930 --> 00:17:12,670
And then processes that actually work.

387
00:17:12,670 --> 00:17:15,500
This is a part that sometimes
the security team misses

388
00:17:15,500 --> 00:17:17,640
like it might sometimes they mean I see it

389
00:17:17,640 --> 00:17:20,830
a lot in a way that is almost like

390
00:17:22,339 --> 00:17:23,569
I don't want to say negligence,

391
00:17:23,569 --> 00:17:26,200
but like they just haven't had the empathy

392
00:17:26,200 --> 00:17:29,710
to think about a dev can't do 23 steps

393
00:17:29,710 --> 00:17:32,400
to get a scan approved
that they don't give a crap

394
00:17:32,400 --> 00:17:33,233
about having done right,

395
00:17:33,233 --> 00:17:36,200
we need to make these processes

396
00:17:36,200 --> 00:17:40,110
that actually work,
provide tools that again,

397
00:17:40,110 --> 00:17:42,179
work and that the devs actually understand

398
00:17:42,180 --> 00:17:44,420
how to use whether that be
because we've trained them

399
00:17:44,420 --> 00:17:46,920
or because the tool is
actually really easy to use.

400
00:17:46,920 --> 00:17:50,020
And then we need to enable
these people to get these

401
00:17:50,020 --> 00:17:52,587
things done that we want from them.

402
00:17:52,587 --> 00:17:55,930
And then the last one,
if you want to be good

403
00:17:55,930 --> 00:17:58,460
at purple team, or if you
want to be good at Red team,

404
00:17:58,460 --> 00:18:00,290
or if you want to be good at Blue team

405
00:18:00,290 --> 00:18:02,260
is you have to keep learning.

406
00:18:02,260 --> 00:18:04,410
So you all of you right now watching this,

407
00:18:04,410 --> 00:18:06,540
you're attending RSA,
so that as you're doing

408
00:18:06,540 --> 00:18:09,810
continuous learning like
you continuing to perfect

409
00:18:09,810 --> 00:18:11,173
and hone your skills.

410
00:18:12,170 --> 00:18:15,124
continuous learning for
the purple Teamer means,

411
00:18:15,124 --> 00:18:18,000
if the devs are bringing
in a new technology,

412
00:18:18,000 --> 00:18:21,240
and they're gonna get a
training on it, you go to it.

413
00:18:21,240 --> 00:18:22,300
You want to know what's up,

414
00:18:22,300 --> 00:18:23,580
you want to know what they're doing.

415
00:18:23,580 --> 00:18:26,409
And you want to make sure
that you are on board

416
00:18:26,410 --> 00:18:28,060
with everything that's happening.

417
00:18:29,310 --> 00:18:31,570
You want to make sure
that you are well aware

418
00:18:31,570 --> 00:18:34,179
of not only the new tech job analogies

419
00:18:34,180 --> 00:18:35,950
that are coming in, but
you also have to learn

420
00:18:35,950 --> 00:18:38,200
how to secure them and what
the best practices are.

421
00:18:38,200 --> 00:18:40,660
And then you have to help the devs

422
00:18:41,550 --> 00:18:44,899
learn those best practices for security,

423
00:18:44,900 --> 00:18:47,520
you need to help the blue team person,

424
00:18:47,520 --> 00:18:50,310
make sure that so like
this new things coming in,

425
00:18:50,310 --> 00:18:51,669
Hey, could you help me make sure

426
00:18:51,670 --> 00:18:53,570
we lock it down correctly.

427
00:18:53,570 --> 00:18:55,960
This means with the red
Teamer when they come in,

428
00:18:55,960 --> 00:18:58,330
and they present this
really kick ass report,

429
00:18:58,330 --> 00:19:00,082
that's super amazing and awesome.

430
00:19:01,130 --> 00:19:04,670
That the devs understand
how to fix those things

431
00:19:04,670 --> 00:19:06,390
and hopefully understand how to make sure

432
00:19:06,390 --> 00:19:09,680
those specific issues
don't happen ever again.

433
00:19:09,680 --> 00:19:11,950
And that is what I believe

434
00:19:11,950 --> 00:19:14,050
the purple team's responsibility is

435
00:19:14,050 --> 00:19:15,760
and it's pretty complicated.

436
00:19:15,760 --> 00:19:17,150
I know a lot of people will talk about

437
00:19:17,150 --> 00:19:21,260
purple team exercises when you
bring a you know, a red team.

438
00:19:21,260 --> 00:19:22,540
And so not just one person,

439
00:19:22,540 --> 00:19:24,956
usually a bunch of them and a blue team

440
00:19:24,957 --> 00:19:27,540
and to defend and you
have basically like a huge

441
00:19:29,260 --> 00:19:31,200
an exercise that's really, really cool.

442
00:19:31,200 --> 00:19:32,420
And that's awesome.

443
00:19:32,420 --> 00:19:36,407
However, I believe the purple team

444
00:19:36,407 --> 00:19:39,526
has a lot more to do than range,

445
00:19:39,527 --> 00:19:42,390
one purple team exercise per year.

446
00:19:42,390 --> 00:19:44,576
I believe there's just so much more that

447
00:19:44,576 --> 00:19:47,200
they can provide as value.

448
00:19:47,200 --> 00:19:49,420
And I know that you know empathy

449
00:19:49,420 --> 00:19:52,930
and advocacy a lot of people
are like, they're like

450
00:19:52,930 --> 00:19:54,700
this isn't to talk about soft skills,

451
00:19:54,700 --> 00:19:57,530
but you're gonna suck at appsec

452
00:19:57,530 --> 00:19:59,830
if you can't understand where
the devs are coming from.

453
00:19:59,830 --> 00:20:02,639
If you I can't understand
where the red team person

454
00:20:02,640 --> 00:20:04,680
or blue team persons coming from like,

455
00:20:04,680 --> 00:20:07,550
Listen, we can only afford one tool.

456
00:20:07,550 --> 00:20:09,780
So you have to pick wisely.

457
00:20:09,780 --> 00:20:13,500
If you can't empathize with
that, you're gonna fail.

458
00:20:13,500 --> 00:20:14,910
I'm seeing that there's some questions

459
00:20:14,910 --> 00:20:17,530
and I'm not sure how
much time I have left.

460
00:20:17,530 --> 00:20:19,870
If someone could put in the
chat how much time I have left,

461
00:20:19,870 --> 00:20:21,820
I will or will not address that question.

462
00:20:21,820 --> 00:20:25,649
But 30 seconds remaining. Okay, so no.

463
00:20:25,650 --> 00:20:26,830
So I'm trying to Janka

464
00:20:26,830 --> 00:20:28,649
I'm super obsessed with the idea of

465
00:20:28,650 --> 00:20:30,810
how we can create secure software.

466
00:20:30,810 --> 00:20:32,780
I'm really excited to be here.

467
00:20:32,780 --> 00:20:35,930
I'm really excited that the
apsic village travels now

468
00:20:35,930 --> 00:20:37,690
to different conferences.

469
00:20:37,690 --> 00:20:38,960
Thank you so much for having me.

470
00:20:38,960 --> 00:20:42,220
And thank you, not only to
the person running this era's,

471
00:20:42,220 --> 00:20:44,420
but the two other amazing speakers

472
00:20:44,420 --> 00:20:46,573
who had so much awesome stuff to say.

473
00:20:48,680 --> 00:20:50,260
- Thank you so much done.

474
00:20:50,260 --> 00:20:54,250
So let's move to our QA and QA session.

475
00:20:54,250 --> 00:20:57,840
I think we have some time
to get some good questions

476
00:20:57,840 --> 00:21:00,223
and to get the discussion going.

477
00:21:01,410 --> 00:21:03,320
Tanya, we can start with you.

478
00:21:03,320 --> 00:21:07,633
And with the question that we
got from Mr. David Sokol here.

479
00:21:08,920 --> 00:21:12,283
So let's talk about
security champion programs.

480
00:21:13,450 --> 00:21:16,980
Is it something that you
think can help educate people

481
00:21:18,339 --> 00:21:22,370
- 100%. So I'm super
obsessed with the idea

482
00:21:22,370 --> 00:21:25,139
of security champions,
I personally believe

483
00:21:25,140 --> 00:21:27,890
that there's never gonna
be enough security people

484
00:21:27,890 --> 00:21:30,440
to get done all the things that we need.

485
00:21:30,440 --> 00:21:31,990
And we're never going to be able to be

486
00:21:31,990 --> 00:21:34,150
in every single dev meeting.

487
00:21:34,150 --> 00:21:38,470
And so asking for volunteers
and recruiting people

488
00:21:38,470 --> 00:21:39,740
who are interested in security,

489
00:21:39,740 --> 00:21:42,890
preferably one from each team,

490
00:21:42,890 --> 00:21:44,520
and then teaching them all the stuff

491
00:21:44,520 --> 00:21:45,460
that you wish they would know.

492
00:21:45,460 --> 00:21:48,380
So all of the policies,
all of the processes,

493
00:21:48,380 --> 00:21:50,900
all of like, if if you, for instance,

494
00:21:50,900 --> 00:21:52,440
can afford a trainer to come in,

495
00:21:52,440 --> 00:21:53,980
but can't afford to train everyone,

496
00:21:53,980 --> 00:21:55,640
you train those security champions,

497
00:21:55,640 --> 00:21:57,640
you meet with them once a
month, you talk to them.

498
00:21:57,640 --> 00:21:59,910
So what are what have you been working on?

499
00:21:59,910 --> 00:22:01,740
What are you going to work
on? Do you have any problems?

500
00:22:01,740 --> 00:22:05,560
How can I help you, and they
will tell you all the secrets.

501
00:22:05,560 --> 00:22:08,770
(laughing) It's really helpful.

502
00:22:08,770 --> 00:22:11,810
And then they proliferate
and share your message.

503
00:22:11,810 --> 00:22:14,860
So they become a securities advocate.

504
00:22:14,860 --> 00:22:16,590
There'll be that person
in the meeting that says,

505
00:22:16,590 --> 00:22:20,193
You know what, maybe we
shouldn't roll our own crypto.

506
00:22:20,193 --> 00:22:22,190
(woman laughing)

507
00:22:22,190 --> 00:22:24,623
Tonya told me that that's bad.

508
00:22:25,830 --> 00:22:27,899
And so yeah, I definitely agree

509
00:22:27,900 --> 00:22:30,730
that security champions
would be so helpful

510
00:22:30,730 --> 00:22:32,970
to educate people,
educating the champions,

511
00:22:32,970 --> 00:22:35,410
and then having them educate for sure.

512
00:22:35,410 --> 00:22:37,630
I totally agree, David.

513
00:22:37,630 --> 00:22:38,740
- Okay, thank you for that,

514
00:22:38,740 --> 00:22:41,542
I'm going to take this
question and move it

515
00:22:41,542 --> 00:22:44,780
to noise with some small change.

516
00:22:44,780 --> 00:22:49,580
So out of your experience
with not the big,

517
00:22:49,580 --> 00:22:52,270
the big companies and
security teams you've been to,

518
00:22:52,270 --> 00:22:56,420
if we look at security
champions, or blue things,

519
00:22:56,420 --> 00:22:59,390
doesn't need to make a situation
where developers say, okay,

520
00:22:59,390 --> 00:23:02,320
security is not me, it's the
problem of the of the champion,

521
00:23:02,320 --> 00:23:04,200
or it's the problem of the blue team,

522
00:23:04,200 --> 00:23:05,700
that we just do my stuff here.

523
00:23:06,680 --> 00:23:07,730
- Yeah, absolutely.

524
00:23:07,730 --> 00:23:11,960
Like, that is all out,
the conversation starts.

525
00:23:11,960 --> 00:23:14,690
It's how tenure is amplified.

526
00:23:14,690 --> 00:23:18,173
People tend to thinking think
in silos in the beginning,

527
00:23:19,350 --> 00:23:21,780
they think, Okay, I will do
code and then somebody else,

528
00:23:21,780 --> 00:23:24,110
even now we are more advanced,

529
00:23:24,110 --> 00:23:26,909
they will think that somebody
else will check the code,

530
00:23:26,910 --> 00:23:29,130
we'll put something in JIRA

531
00:23:29,130 --> 00:23:30,690
and tell me what I need to fix, right.

532
00:23:30,690 --> 00:23:34,060
But that takes time and time
costs money for the company.

533
00:23:34,060 --> 00:23:36,110
And if we are everybody's on board

534
00:23:36,110 --> 00:23:39,929
with making SOC secure
software from the gate,

535
00:23:39,930 --> 00:23:41,870
then you should be a concern of everybody.

536
00:23:41,870 --> 00:23:45,526
But it's it's a conversation
that takes time,

537
00:23:45,527 --> 00:23:48,880
and you need to accommodate different ways

538
00:23:48,880 --> 00:23:52,850
of of telling the developers
out there, how they can win.

539
00:23:52,850 --> 00:23:56,550
In the past, we had a lot
of failures in our end,

540
00:23:56,550 --> 00:23:58,870
which was the wall of shame,

541
00:23:58,870 --> 00:24:02,320
like you had this amount of
security vulnerabilities.

542
00:24:02,320 --> 00:24:05,290
Now moving forward, what
the blue teams are doing is

543
00:24:06,800 --> 00:24:08,460
like in my organization,

544
00:24:08,460 --> 00:24:11,510
what we are doing currently
is we every Monday,

545
00:24:11,510 --> 00:24:13,850
we create a report based on on

546
00:24:13,850 --> 00:24:16,250
the vulnerabilities
introduced on the code,

547
00:24:16,250 --> 00:24:18,230
and we call it road to success.

548
00:24:18,230 --> 00:24:21,650
And we measure how much
time would you take

549
00:24:21,650 --> 00:24:24,570
to watch these videos, the
content that are appropriate

550
00:24:24,570 --> 00:24:26,149
to the type of vulnerabilities that

551
00:24:26,150 --> 00:24:27,720
you are introducing on the code.

552
00:24:27,720 --> 00:24:31,050
And if you watch this video
of five to three minute video,

553
00:24:31,050 --> 00:24:32,330
how much time would save you

554
00:24:32,330 --> 00:24:34,199
because now with acquiring knowledge,

555
00:24:34,200 --> 00:24:35,560
you will no longer introduce

556
00:24:35,560 --> 00:24:37,560
the type of vulnerabilities on the code.

557
00:24:39,140 --> 00:24:41,830
- Okay, let's, let's Yeah,

558
00:24:41,830 --> 00:24:44,153
that this is actually
part of what you mentioned

559
00:24:44,153 --> 00:24:45,350
the evolution on your part.

560
00:24:45,350 --> 00:24:47,870
And I think the time you have the same

561
00:24:47,870 --> 00:24:50,830
thread of evolution
throughout her talk as well.

562
00:24:50,830 --> 00:24:54,139
So that's really nice to
hear from the both of you.

563
00:24:54,140 --> 00:24:55,810
Better, I'm going to take you a bit,

564
00:24:55,810 --> 00:24:58,990
a bit hands on if you don't mind.

565
00:24:58,990 --> 00:25:03,360
What are? Well, I want
to talk about challenges.

566
00:25:03,360 --> 00:25:05,090
I'm not sure if I want to
talk about the challenges

567
00:25:05,090 --> 00:25:07,260
for the red team or the organization.

568
00:25:07,260 --> 00:25:08,690
Let's start with you, the red team,

569
00:25:08,690 --> 00:25:10,953
what are your challenges as a red team?

570
00:25:12,510 --> 00:25:16,300
- I mean, there are a lot
of different challenges

571
00:25:16,300 --> 00:25:17,301
to overcome.

572
00:25:17,301 --> 00:25:19,770
Many of them if you are writing

573
00:25:19,770 --> 00:25:22,379
or you're familiar with
the issue of scope,

574
00:25:22,380 --> 00:25:24,680
definition and rules of engagement.

575
00:25:24,680 --> 00:25:28,530
But I would like to talk about
a slightly different topic

576
00:25:28,530 --> 00:25:31,270
with this quite draining
on the news lately,

577
00:25:31,270 --> 00:25:33,553
which is ethics while fishing.

578
00:25:35,032 --> 00:25:36,790
There have been some fishing campaigns

579
00:25:36,790 --> 00:25:40,000
that the context of the emails

580
00:25:40,000 --> 00:25:42,640
while phishing was salary,
bonuses or promotions.

581
00:25:42,640 --> 00:25:45,070
And then on the news, it was discussed

582
00:25:45,070 --> 00:25:48,620
if this was an ethical thing to do or not.

583
00:25:48,620 --> 00:25:52,033
And I think ethics is a real challenge.

584
00:25:52,034 --> 00:25:57,034
But so the entire exercise, so
the exercise should be valid.

585
00:25:57,670 --> 00:26:00,050
And if you think about
the phishing campaign,

586
00:26:00,050 --> 00:26:03,159
like only sending an email to an user,

587
00:26:03,160 --> 00:26:06,590
and see who falls for it
for so to speak, yeah,

588
00:26:06,590 --> 00:26:10,250
that's not not, that's
not a real, real thing.

589
00:26:10,250 --> 00:26:12,050
But if you think about
the phishing campaign,

590
00:26:12,050 --> 00:26:14,570
under the umbrella of social engineering,

591
00:26:14,570 --> 00:26:16,896
and red team exercise,

592
00:26:16,896 --> 00:26:20,889
then this is much more
because awareness, sessions

593
00:26:20,890 --> 00:26:22,700
should be promoted.

594
00:26:22,700 --> 00:26:24,620
success metrics should be analyzed,

595
00:26:24,620 --> 00:26:26,699
the fences should be evaluated.

596
00:26:26,700 --> 00:26:29,090
This should never be
about who actually clicked

597
00:26:29,090 --> 00:26:30,283
the malicious link.

598
00:26:31,170 --> 00:26:33,290
We should be empathetic
with those persons,

599
00:26:33,290 --> 00:26:34,780
because it's, it's in the end,

600
00:26:34,780 --> 00:26:36,889
it's the company that's failing.

601
00:26:36,890 --> 00:26:40,370
And it's not only about that,
it's about how that email

602
00:26:40,370 --> 00:26:42,659
ended up in the user's
mailbox in the first place,

603
00:26:42,660 --> 00:26:47,180
and what defenses are in place
to limit that those events?

604
00:26:47,180 --> 00:26:49,250
And even even if the user clicks the link

605
00:26:49,250 --> 00:26:54,100
out to that is your
infrastructure are segmented it is

606
00:26:54,100 --> 00:26:55,780
resistant to attacks it is.

607
00:26:55,780 --> 00:26:59,920
So it's about how many users
were driven to click the links.

608
00:26:59,920 --> 00:27:04,040
And how many of you reduced as
a company from previous year?

609
00:27:04,040 --> 00:27:07,149
Are you promoting the right
security mindset in people?

610
00:27:07,150 --> 00:27:09,950
Are you are you doing training programs?

611
00:27:09,950 --> 00:27:14,950
So this I think this is one of
the trendiest challenges now,

612
00:27:15,330 --> 00:27:19,100
ethics, we're waiting, at
least for the red teamers part

613
00:27:19,100 --> 00:27:24,100
to actually, you know, design
a proper exercise that doesn't

614
00:27:24,897 --> 00:27:28,716
fail on the Ethics Commission (laughing).

615
00:27:29,720 --> 00:27:33,480
- So, so if I need to
bring another another twist

616
00:27:33,480 --> 00:27:35,480
to that question, do you think the problem

617
00:27:35,480 --> 00:27:39,610
with with ethics is that
we always want a bit more,

618
00:27:39,610 --> 00:27:44,219
even if we know that we are,
you know, crossing the line?

619
00:27:44,220 --> 00:27:46,490
Or maybe even beyond crossing the line?

620
00:27:46,490 --> 00:27:48,970
Is it something that is
how fast to stop and say,

621
00:27:48,970 --> 00:27:50,740
Okay, I had enough?

622
00:27:50,740 --> 00:27:53,280
Or is it something that you
learn to do as you mature?

623
00:27:53,280 --> 00:27:55,050
As an aptamer?

624
00:27:55,050 --> 00:27:58,530
- For sure, for sure,
because this discussion

625
00:27:58,530 --> 00:28:02,700
was was not so widely on the internet?

626
00:28:02,700 --> 00:28:07,640
And yes, of course, you
mature, it's about your lack,

627
00:28:07,640 --> 00:28:09,763
or your sense or lack of it.

628
00:28:10,600 --> 00:28:14,980
But I don't think the
problem is the things that

629
00:28:14,980 --> 00:28:18,630
you actually say, how do you
drive people to take action?

630
00:28:18,630 --> 00:28:21,860
The problem is that people
shouldn't actually feel bad

631
00:28:21,860 --> 00:28:23,270
about it afterwards.

632
00:28:23,270 --> 00:28:25,780
Of course, there are limits,
there are some legalities

633
00:28:25,780 --> 00:28:27,899
and things that you should not address.

634
00:28:27,900 --> 00:28:31,090
But for example, the salary bonus example,

635
00:28:31,090 --> 00:28:33,330
it's a good example, because people is

636
00:28:33,330 --> 00:28:36,600
you are giving false
hopes and expectations.

637
00:28:36,600 --> 00:28:41,021
But in the end, if that's
explained, or even before,

638
00:28:41,021 --> 00:28:44,629
if that's explained as
potential attack vector,

639
00:28:44,630 --> 00:28:47,062
and people feel like
they are part of making

640
00:28:47,062 --> 00:28:48,770
the organization more secure,

641
00:28:48,770 --> 00:28:52,470
because they understand how attackers were

642
00:28:52,470 --> 00:28:55,730
they I don't think people
actually feel that bad.

643
00:28:55,730 --> 00:28:59,453
If they ended up clicking a
link because they already knew.

644
00:29:01,310 --> 00:29:04,210
They already knew the types of exercises

645
00:29:04,210 --> 00:29:06,243
there were going to be in place.

646
00:29:07,560 --> 00:29:08,393
As Tonya said,

647
00:29:08,393 --> 00:29:09,870
it's all about being empathetic

648
00:29:09,870 --> 00:29:14,783
and having soft skills to
explain our core workers,

649
00:29:15,740 --> 00:29:18,550
what what happens in
these kinds of exercises?

650
00:29:18,550 --> 00:29:23,370
What should we expect, instead
of ending up feeling bad or,

651
00:29:23,370 --> 00:29:27,610
or feeling like the guy that
actually clicked the link

652
00:29:27,610 --> 00:29:31,209
being ended up being
responsible in the eyes

653
00:29:31,210 --> 00:29:34,030
of the of the upper
management, which by the way,

654
00:29:34,030 --> 00:29:35,080
it should never happen?

655
00:29:35,080 --> 00:29:36,713
It's always the company's fault.

656
00:29:37,650 --> 00:29:39,185
- Yeah.

657
00:29:39,185 --> 00:29:42,471
This is something that the terms

658
00:29:42,471 --> 00:29:44,097
are locked in conversation.

659
00:29:44,097 --> 00:29:47,129
And I think that a lot
of professionals agree

660
00:29:47,130 --> 00:29:49,960
that it's actually the company's fault,

661
00:29:49,960 --> 00:29:54,460
or challenge or job to make
sure that it does not happen.

662
00:29:54,460 --> 00:29:55,420
- [Pedro] Yeah.

663
00:29:55,420 --> 00:29:57,940
- So there are a couple of questions.

664
00:29:57,940 --> 00:30:00,200
Elsa, from the from the chat.

665
00:30:00,200 --> 00:30:04,400
around education and training.

666
00:30:04,400 --> 00:30:07,100
And also a question about loose

667
00:30:07,100 --> 00:30:08,602
let me let me give it to you.

668
00:30:10,520 --> 00:30:15,030
Can you be productive, in
your case, blue Teamer?

669
00:30:15,030 --> 00:30:17,139
If you don't have much
development experience,

670
00:30:17,140 --> 00:30:18,700
does one have to start with plenty

671
00:30:18,700 --> 00:30:19,990
of development experience?

672
00:30:19,990 --> 00:30:21,270
And obviously we're talking

673
00:30:21,270 --> 00:30:24,389
our focuses is appsec. But

674
00:30:24,390 --> 00:30:27,550
- [Luis] Hm-hm. yeah, for sure.

675
00:30:27,550 --> 00:30:30,370
I mean, I did some other presentations,

676
00:30:30,370 --> 00:30:32,379
where I think that people should look

677
00:30:32,380 --> 00:30:34,860
at Blue team for appsec
as an abstract layer,

678
00:30:34,860 --> 00:30:37,899
like you don't need to know everything.

679
00:30:37,900 --> 00:30:40,600
Of course, you being
familiar with the application

680
00:30:40,600 --> 00:30:44,030
allows you to have way
more assumptions, then.

681
00:30:44,030 --> 00:30:46,713
I mean, way more certainties
than assumptions.

682
00:30:47,560 --> 00:30:49,340
But you should know the flow.

683
00:30:49,340 --> 00:30:51,840
Like if you understand
what the user can do,

684
00:30:51,840 --> 00:30:54,524
then you can define apps
and upscale what the user

685
00:30:54,524 --> 00:30:59,524
should be doing, then you
already set to be, I would say,

686
00:30:59,840 --> 00:31:03,439
a minimum two basic good to blue defender.

687
00:31:03,440 --> 00:31:05,110
The reason why I say that is that

688
00:31:06,990 --> 00:31:09,330
attackers or people like
better will find ways

689
00:31:09,330 --> 00:31:12,590
to mimic the normal behavior,

690
00:31:12,590 --> 00:31:15,659
depending on the level
of skill of the attacker

691
00:31:15,660 --> 00:31:17,970
is able to mimic exactly what you expect

692
00:31:17,970 --> 00:31:19,340
to see on the application

693
00:31:19,340 --> 00:31:21,723
and still pass the security measures.

694
00:31:22,700 --> 00:31:26,460
And your ability to
detect what is the outside

695
00:31:26,460 --> 00:31:29,417
of norm pattern of usage in
the application is not defined,

696
00:31:29,417 --> 00:31:31,560
but how good you are as a developer,

697
00:31:31,560 --> 00:31:33,943
meaning how much do you
know about the product

698
00:31:33,943 --> 00:31:36,600
that you are using that you are defending?

699
00:31:36,600 --> 00:31:40,360
And can you be the first layer of defense?

700
00:31:40,360 --> 00:31:41,560
This happens?

701
00:31:41,560 --> 00:31:43,870
A lot of times like we have
customer support centers

702
00:31:43,870 --> 00:31:46,770
that tell us look, I was
able to I don't know,

703
00:31:46,770 --> 00:31:50,350
push push on credits, without
the proper authorization

704
00:31:50,350 --> 00:31:52,820
Is this normal? And they
are not developers at all.

705
00:31:52,820 --> 00:31:56,010
They just like this is outside
of the normal behavior.

706
00:31:56,010 --> 00:31:58,780
And we like, right, let me just put this

707
00:31:58,780 --> 00:32:00,553
on the on the on the roadmap. Yeah.

708
00:32:01,890 --> 00:32:04,200
- Yeah. That's a good.

709
00:32:04,200 --> 00:32:07,080
That's a good scenario,

710
00:32:07,080 --> 00:32:08,928
because I know it happens all the time.

711
00:32:08,929 --> 00:32:10,530
We call it Beginner's luck,

712
00:32:10,530 --> 00:32:12,139
but it's not really Beginner's luck.

713
00:32:12,140 --> 00:32:16,740
And I think that you said it correctly.

714
00:32:16,740 --> 00:32:19,590
Sometimes you need someone
with kind of new eyes

715
00:32:19,590 --> 00:32:21,600
or a new perspective.

716
00:32:21,600 --> 00:32:25,080
Sometimes being a newbie
actually helps you

717
00:32:25,080 --> 00:32:27,020
to clear all the biases.

718
00:32:27,020 --> 00:32:29,714
And that's, that's really interesting.

719
00:32:29,714 --> 00:32:32,510
So when we get to more
more questions, today,

720
00:32:32,510 --> 00:32:36,360
I want to get you to the back
to the beginning of your talk.

721
00:32:36,360 --> 00:32:38,820
You mentioned processes and Dev

722
00:32:38,820 --> 00:32:42,013
and second ops and soft
skills and everything.

723
00:32:43,010 --> 00:32:45,670
It used to be very, very
clear to me what opsec is

724
00:32:45,670 --> 00:32:47,490
what Application Security means.

725
00:32:47,490 --> 00:32:48,811
How do you define it?

726
00:32:48,811 --> 00:32:51,761
What is what is done is definition
to application security.

727
00:32:53,400 --> 00:32:55,860
- Every single thing that you do to ensure

728
00:32:55,860 --> 00:32:57,800
that your software is secure,

729
00:32:57,800 --> 00:33:00,320
I consider to be part of app sec.

730
00:33:00,320 --> 00:33:02,290
So that can mean a dev that listened

731
00:33:02,290 --> 00:33:04,409
to a podcast on the weekend.

732
00:33:04,410 --> 00:33:06,680
And they're like, Yeah,
apparently there's this

733
00:33:06,680 --> 00:33:08,880
vulnerability in this
framework we're using

734
00:33:08,880 --> 00:33:10,170
I heard it's really scary.

735
00:33:10,170 --> 00:33:13,290
Like, maybe we should update. Right?

736
00:33:13,290 --> 00:33:15,180
It could be that it could be running

737
00:33:15,180 --> 00:33:17,170
a formal app sack program,

738
00:33:17,170 --> 00:33:19,720
where you have a secure
system development lifecycle,

739
00:33:19,720 --> 00:33:22,270
every single phase, you
have a security activity,

740
00:33:22,270 --> 00:33:24,020
at least one.

741
00:33:24,020 --> 00:33:27,240
It could be, you know,
the devs, taking over

742
00:33:27,240 --> 00:33:29,210
and deciding to add security themselves

743
00:33:29,210 --> 00:33:32,460
because the security
team mostly ignores them.

744
00:33:32,460 --> 00:33:34,763
It can be something the
security team do to the devs

745
00:33:34,763 --> 00:33:37,990
that the devs don't
appreciate, like, here's NIST,

746
00:33:37,990 --> 00:33:40,104
I expect you to memorize it.

747
00:33:40,104 --> 00:33:40,937
(man laughing)

748
00:33:40,937 --> 00:33:43,169
Or here's asvs from o OS,

749
00:33:43,170 --> 00:33:46,130
the application security
verification standard,

750
00:33:46,130 --> 00:33:50,250
I expect you to somehow
memorize those 87 pages,

751
00:33:50,250 --> 00:33:52,720
all of the entire
spreadsheet and then apply it

752
00:33:52,720 --> 00:33:54,450
to every single app you're doing.

753
00:33:54,450 --> 00:33:56,640
And the devs are like
I don't even understand

754
00:33:56,640 --> 00:33:57,830
what this says,

755
00:33:57,830 --> 00:33:59,659
How am I supposed to do this? Right.

756
00:33:59,660 --> 00:34:02,140
And so there's app sec, that goes better

757
00:34:02,140 --> 00:34:03,750
and app sec, that does not go as well,

758
00:34:03,750 --> 00:34:06,350
but I consider it the field
within computer science

759
00:34:06,350 --> 00:34:09,393
of ensuring that you're
building secure software.

760
00:34:11,290 --> 00:34:14,896
- Interesting. Okay, we're
just a few minutes left.

761
00:34:14,896 --> 00:34:15,728
(woman speaking softly)

762
00:34:15,728 --> 00:34:16,562
Oh, sorry.

763
00:34:16,562 --> 00:34:18,658
- [Tanya] We get to hear your definition.

764
00:34:18,658 --> 00:34:23,658
- It's, it's in progress at the moment.

765
00:34:24,326 --> 00:34:27,159
(people laughing)

766
00:34:28,152 --> 00:34:31,489
definitions and the reason is that

767
00:34:31,489 --> 00:34:33,639
I used to be very traditional

768
00:34:33,639 --> 00:34:37,929
and my mind was split
open to the entire idea

769
00:34:37,929 --> 00:34:41,594
of infrastructures, code
and everything around it.

770
00:34:41,594 --> 00:34:45,919
I think I'm evolving in a
way I'm just not sure to what

771
00:34:45,920 --> 00:34:49,120
so I promise next sandbox next time I say

772
00:34:49,120 --> 00:34:50,612
let's do this again, I will have something

773
00:34:50,612 --> 00:34:55,460
- [Luis] I would like to
just give this last thought

774
00:34:55,460 --> 00:34:57,510
as the guy that is representing blue team

775
00:34:57,510 --> 00:34:59,770
which sometimes is the most silent one

776
00:34:59,770 --> 00:35:02,339
normally The guys that get
the medals are red teams,

777
00:35:02,339 --> 00:35:05,070
because they are the guys
that break what we do

778
00:35:05,070 --> 00:35:06,950
in the purple team are the people that

779
00:35:06,950 --> 00:35:10,919
are conveying ideas and making
this more seamless approach.

780
00:35:10,920 --> 00:35:14,370
And the blue team normally has
like a big thing on the wall.

781
00:35:14,370 --> 00:35:16,388
That is security is always too much

782
00:35:16,389 --> 00:35:18,858
until the day that was not enough.

783
00:35:18,858 --> 00:35:23,150
And I will just want to
let let you leave the talk

784
00:35:23,150 --> 00:35:24,760
with the sense that we are evolving.

785
00:35:24,760 --> 00:35:27,960
So this is for the red teamers.

786
00:35:27,960 --> 00:35:32,362
just expect the unexpected from
us. It's all I have to say.

787
00:35:32,362 --> 00:35:33,230
- This is excellent.

788
00:35:33,230 --> 00:35:36,245
And by the way, I want maybe
the last sentence from you

789
00:35:36,245 --> 00:35:40,230
with a quick question of how
do I know that my organization

790
00:35:40,230 --> 00:35:43,300
is ready for a red team in my queue?

791
00:35:43,300 --> 00:35:44,513
to punch me in the face?

792
00:35:47,219 --> 00:35:49,800
- Do you know it's ready?
Well, that's really

793
00:35:49,800 --> 00:35:52,800
- [Erez] I'll tell you why
because many people tell me no,

794
00:35:52,800 --> 00:35:54,975
I cannot bring a team because

795
00:35:54,975 --> 00:35:59,130
I know that a lot of low
hanging fruit are not fixed yet.

796
00:35:59,130 --> 00:36:00,360
So Shouldn't we wait?

797
00:36:00,360 --> 00:36:02,600
Should we get your from the beginning?

798
00:36:02,600 --> 00:36:05,060
- No, we get a red team

799
00:36:05,060 --> 00:36:07,299
is not just an on off and engagement.

800
00:36:07,300 --> 00:36:10,520
It should be it's something
that you build for the future

801
00:36:10,520 --> 00:36:13,386
and you do regularly so
you better start doing it.

802
00:36:13,386 --> 00:36:18,386
Because otherwise, how do
you measure your own success

803
00:36:20,180 --> 00:36:22,129
while fixing your stuff? Right?

804
00:36:22,130 --> 00:36:25,030
So there's there's there's really not

805
00:36:25,030 --> 00:36:29,610
a waiting period, maturity period.

806
00:36:29,610 --> 00:36:33,230
So you should do writing
exercises, you should do that soon,

807
00:36:33,230 --> 00:36:38,230
as soon as possible, in my
opinion, so so the more measures

808
00:36:39,480 --> 00:36:41,590
you get from past exercises,

809
00:36:41,590 --> 00:36:43,770
the better for you to understand how

810
00:36:43,770 --> 00:36:46,963
you are evolving in terms of security.

811
00:36:48,670 --> 00:36:49,503
- Excellent.

812
00:36:50,714 --> 00:36:51,980
I'm really happy about this discussion.

813
00:36:51,980 --> 00:36:54,640
To be honest, I think
I learned a lot myself,

814
00:36:54,640 --> 00:36:57,522
I hope that our attendees learned as well.

815
00:36:58,660 --> 00:37:00,210
I think that the similarities

816
00:37:00,210 --> 00:37:04,990
between the perspective
agendas wherever much greater

817
00:37:04,990 --> 00:37:06,459
than the differences.

818
00:37:06,460 --> 00:37:08,730
And I think that, you know,

819
00:37:08,730 --> 00:37:11,283
the philosophy behind it
of everyone leaving to

820
00:37:11,283 --> 00:37:14,923
to be involved and involved.

821
00:37:15,860 --> 00:37:20,090
Just want to leave you with
something tiny that that I have,

822
00:37:20,090 --> 00:37:21,720
from my experience.

823
00:37:21,720 --> 00:37:25,580
I find myself a lot of
times talking to, you know,

824
00:37:25,580 --> 00:37:29,080
to organizations, and when
they come in the entire r&d

825
00:37:29,080 --> 00:37:30,150
is in front of me.

826
00:37:30,150 --> 00:37:32,090
My first question, sometimes this is

827
00:37:32,090 --> 00:37:34,030
when I do these exercises,

828
00:37:34,030 --> 00:37:36,180
Who here is in charge of security.

829
00:37:36,180 --> 00:37:38,586
And then I have two or three arms,

830
00:37:38,586 --> 00:37:41,312
usually going up and they can explain why.

831
00:37:42,620 --> 00:37:45,650
By the time I end my
talk, I usually ask again,

832
00:37:45,650 --> 00:37:48,430
so who is here in charge of security?

833
00:37:48,430 --> 00:37:49,890
Usually around this time,

834
00:37:49,890 --> 00:37:53,490
about 95 to 99% of the hands go up?

835
00:37:53,490 --> 00:37:56,000
So. So this is a success.

836
00:37:56,000 --> 00:38:01,000
And even if you're a breakout
maker, a developer QA,

837
00:38:02,200 --> 00:38:06,040
finance, no matter what I
think all of us have some blue,

838
00:38:06,040 --> 00:38:08,350
some red and some purple in us.

839
00:38:08,350 --> 00:38:11,343
And I think this is our
way to win, basically.

840
00:38:13,850 --> 00:38:16,130
So thank you so much for our guests.

841
00:38:16,130 --> 00:38:19,430
That was a real pleasure.
Thank you for the attendees.

842
00:38:19,430 --> 00:38:22,879
Thank you for the RSA conference sandbox,

843
00:38:22,880 --> 00:38:27,880
hosting the appsec village
and see you in future events.

844
00:38:29,480 --> 00:38:31,110
Hopefully face to face.

845
00:38:31,110 --> 00:38:32,470
Thank you, everyone.

846
00:38:32,470 --> 00:38:33,303
Bye bye.

