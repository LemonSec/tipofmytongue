1
00:00:01,140 --> 00:00:04,040
- Hello, today's session will be about

2
00:00:04,040 --> 00:00:07,730
applying artificial intelligence
to incident response,

3
00:00:07,730 --> 00:00:10,280
and we're actually gonna
teach you how to do that

4
00:00:10,280 --> 00:00:13,730
in the different stages
of incident response.

5
00:00:13,730 --> 00:00:16,129
The agenda will include what is AI,

6
00:00:16,129 --> 00:00:20,380
and we'll then talk more
about how is AI related to IR?

7
00:00:20,380 --> 00:00:22,250
What is the theme,

8
00:00:22,250 --> 00:00:24,710
when is it important
and how to implement it?

9
00:00:24,710 --> 00:00:26,660
We're gonna touch about investigation,

10
00:00:26,660 --> 00:00:28,950
gonna touch about how to
apply this to response,

11
00:00:28,950 --> 00:00:32,500
and of course harnessing all
of the above into the cloud,

12
00:00:32,500 --> 00:00:34,750
and we'll end up with takeaways.

13
00:00:34,750 --> 00:00:37,570
So briefing into AI.

14
00:00:37,570 --> 00:00:41,400
So AI is definitely
than a buzz word today.

15
00:00:41,400 --> 00:00:46,400
And there's a lot of items and
buzz that are related to it.

16
00:00:46,410 --> 00:00:49,620
But machine learning is a subset
of artificial intelligence.

17
00:00:49,620 --> 00:00:52,099
Not all artificial intelligence
has machine learning.

18
00:00:52,100 --> 00:00:53,450
And the machine learning itself

19
00:00:53,450 --> 00:00:55,660
we're gonna talk about the
different learning mechanism

20
00:00:55,660 --> 00:00:57,620
but as a subset of machine learning,

21
00:00:57,620 --> 00:01:00,430
we're also gonna talk about deep learning

22
00:01:00,430 --> 00:01:02,853
which is gonna be part
of our session today.

23
00:01:04,242 --> 00:01:06,300
To understand machine
learning in a high level,

24
00:01:06,300 --> 00:01:09,149
you need to understand
how does it actually work.

25
00:01:09,150 --> 00:01:10,830
From a general point of view,

26
00:01:10,830 --> 00:01:13,500
the idea is to feed a
system with datasets.

27
00:01:13,500 --> 00:01:14,850
Datasets could be positive,

28
00:01:14,850 --> 00:01:16,429
datasets could be negative.

29
00:01:16,430 --> 00:01:18,390
But we need to know the features

30
00:01:18,390 --> 00:01:20,327
that we wanna extract out of the datasets,

31
00:01:20,327 --> 00:01:23,853
the one that we actually gonna
be the junctions, the ideas,

32
00:01:24,810 --> 00:01:27,710
that's gonna determine
the algorithm later on.

33
00:01:27,710 --> 00:01:29,300
And once we have those datasets,

34
00:01:29,300 --> 00:01:32,920
and we understand the feature
extract out of those datasets,

35
00:01:32,920 --> 00:01:34,970
we've gotta teach the system the algorithm

36
00:01:34,970 --> 00:01:37,730
and create a model that from now on

37
00:01:37,730 --> 00:01:41,290
will be able to distinguish
resembled datasets

38
00:01:41,290 --> 00:01:42,920
and be able to set them

39
00:01:42,920 --> 00:01:47,193
to the result that is
required by those datasets.

40
00:01:49,160 --> 00:01:50,090
When we're talking about

41
00:01:50,090 --> 00:01:53,660
the methods of the machine learning,

42
00:01:53,660 --> 00:01:56,140
usually we are referring

43
00:01:56,140 --> 00:01:59,100
to two different aspects
of learning modes,

44
00:01:59,100 --> 00:02:00,780
supervised and unsupervised.

45
00:02:00,780 --> 00:02:03,410
Supervised, and as you can see

46
00:02:03,410 --> 00:02:05,860
on the left hand side of the screen,

47
00:02:05,860 --> 00:02:10,139
we gave Next Generation
Antivirus as an example.

48
00:02:10,139 --> 00:02:12,519
Supervise means that
you're giving a dataset

49
00:02:12,520 --> 00:02:13,870
as you can see in the example

50
00:02:13,870 --> 00:02:18,250
that could be benign or
malicious as a malware,

51
00:02:18,250 --> 00:02:20,270
and we're trying to teach a function,

52
00:02:20,270 --> 00:02:22,000
which is gonna become the model

53
00:02:22,000 --> 00:02:25,920
into distinguishing between
a malware versus a good file.

54
00:02:25,920 --> 00:02:28,750
And that is exactly the supervised model.

55
00:02:28,750 --> 00:02:32,000
So in the later stage,
once the model is trained,

56
00:02:32,000 --> 00:02:34,150
we will push a dataset that is unknown,

57
00:02:34,150 --> 00:02:36,250
and the idea is that the function,

58
00:02:36,250 --> 00:02:38,530
the model will know how to set that

59
00:02:38,530 --> 00:02:42,170
and associate it into a
malware or a benign file,

60
00:02:42,170 --> 00:02:46,679
where an unsupervised is more
of a reference or a pointer

61
00:02:46,680 --> 00:02:50,650
into a specific kind of class or cluster.

62
00:02:50,650 --> 00:02:53,060
And then what we would
like the machine to do

63
00:02:53,060 --> 00:02:55,657
is basically to be able to
put the different datasets

64
00:02:55,657 --> 00:02:59,380
that's gonna be set in
into those classificators,

65
00:02:59,380 --> 00:03:01,450
into those datasets clusters,

66
00:03:01,450 --> 00:03:03,910
and that's the idea about the unsupervised

67
00:03:03,910 --> 00:03:05,100
providing reference

68
00:03:05,100 --> 00:03:08,972
and associating to the different
references or families.

69
00:03:10,670 --> 00:03:11,802
Let's talk a little bit about

70
00:03:11,802 --> 00:03:15,590
another big term in machine learning.

71
00:03:15,590 --> 00:03:18,170
After we learn the learning models,

72
00:03:18,170 --> 00:03:19,630
the reinforcement learning.

73
00:03:19,630 --> 00:03:20,980
What is a reinforcement learning?

74
00:03:20,980 --> 00:03:23,359
Basically there are four different stages

75
00:03:23,360 --> 00:03:24,830
that I'm gonna discuss here.

76
00:03:24,830 --> 00:03:27,010
But it all comes down from an agent

77
00:03:27,010 --> 00:03:30,600
which is the tool that
actually takes the action

78
00:03:30,600 --> 00:03:31,540
upon the environment.

79
00:03:31,540 --> 00:03:34,010
In our case it's gonna be the enforcer,

80
00:03:34,010 --> 00:03:36,120
and the environment is
gonna be the incident

81
00:03:36,120 --> 00:03:38,090
that we want to deal with.

82
00:03:38,090 --> 00:03:40,030
Then what's gonna happen is that

83
00:03:40,030 --> 00:03:42,400
the action that's gonna
be taken by the agent

84
00:03:42,400 --> 00:03:45,740
is gonna be be then
interpreted by an interpreter.

85
00:03:45,740 --> 00:03:47,900
The interpreter will
try to better understand

86
00:03:47,900 --> 00:03:50,920
whether the action as
taken on the environment

87
00:03:50,920 --> 00:03:53,489
was what we expected it to be or not.

88
00:03:53,490 --> 00:03:56,680
If it was the expected
action, it will reward.

89
00:03:56,680 --> 00:03:58,260
That's why we like to call this model

90
00:03:58,260 --> 00:03:59,890
the stick and the carrot model.

91
00:03:59,890 --> 00:04:03,190
So it will reward the agent
for doing the right thing,

92
00:04:03,190 --> 00:04:05,440
and of course there is a penalty

93
00:04:05,440 --> 00:04:08,740
in case that was not the
right action to take.

94
00:04:08,740 --> 00:04:13,327
And the state is actually
the action that was taken,

95
00:04:13,327 --> 00:04:15,607
after the action was taken,
the impact on the environment.

96
00:04:19,740 --> 00:04:21,970
When we're talking about how to implement

97
00:04:21,970 --> 00:04:23,400
and how does it look for the internals,

98
00:04:23,400 --> 00:04:26,674
we'll talk a lot about trees and forests.

99
00:04:26,675 --> 00:04:29,160
And trees and forests,
and in this example,

100
00:04:29,160 --> 00:04:31,970
for example, how to classify a file

101
00:04:31,970 --> 00:04:34,853
in a very high level and simplified model.

102
00:04:36,560 --> 00:04:39,700
The idea here is that what you
see is the nodes that you see

103
00:04:39,700 --> 00:04:42,340
are basically the features
that we discussed before.

104
00:04:42,340 --> 00:04:45,859
Those are the one that we wanna follow.

105
00:04:45,860 --> 00:04:49,040
And each and every one of
those features has a threshold.

106
00:04:49,040 --> 00:04:51,650
The threshold are the decisions, idea.

107
00:04:51,650 --> 00:04:53,380
So if the threshold can define

108
00:04:54,401 --> 00:04:56,360
what is gonna be the left-hand of it,

109
00:04:56,360 --> 00:04:57,740
and what is gonna be the right hand of it

110
00:04:57,740 --> 00:04:59,130
is we're gonna move around the tree

111
00:04:59,130 --> 00:05:00,690
until we're gonna get to the leaf,

112
00:05:00,690 --> 00:05:04,469
which stands for the end result
that we wanna get the idea.

113
00:05:04,470 --> 00:05:06,350
If you're looking at the right-hand side

114
00:05:06,350 --> 00:05:10,050
is to have as many trees as you can.

115
00:05:10,050 --> 00:05:11,640
And that's why we call it the forest,

116
00:05:11,640 --> 00:05:15,049
where we can actually average
and weight those trees.

117
00:05:15,049 --> 00:05:18,260
Sometimes within machine learning itself,

118
00:05:18,260 --> 00:05:20,450
to be able to get ourselves a better

119
00:05:20,450 --> 00:05:22,203
and more factored results.

120
00:05:23,980 --> 00:05:27,610
Another big buzz in the learning
and the models out there

121
00:05:27,610 --> 00:05:31,140
is using neural networks
or deep neural networks,

122
00:05:31,140 --> 00:05:33,530
so DNNs and shallow network

123
00:05:33,530 --> 00:05:37,239
are the models that you're
gonna see there more and more

124
00:05:37,240 --> 00:05:39,450
when, again if you're
looking at the left hand

125
00:05:39,450 --> 00:05:41,370
the inputs are the features

126
00:05:41,370 --> 00:05:43,410
and the idea itself within the DNN

127
00:05:44,760 --> 00:05:49,409
is to try and imitate
a human brain activity.

128
00:05:49,410 --> 00:05:52,310
And so the idea is that
as an input feature,

129
00:05:52,310 --> 00:05:54,430
we're going into an inner tree.

130
00:05:54,430 --> 00:05:58,080
And the idea is to move
between the layers,

131
00:05:58,080 --> 00:05:59,070
if you have more than one

132
00:05:59,070 --> 00:06:00,690
and you're more than just a shallow

133
00:06:00,690 --> 00:06:04,420
and have a full and it can have
a lot of those, the layers,

134
00:06:04,420 --> 00:06:05,410
but the idea is to move

135
00:06:05,410 --> 00:06:07,660
between the features within the trees

136
00:06:07,660 --> 00:06:11,660
and move forward through
the right next inner trees,

137
00:06:11,660 --> 00:06:13,470
to be able to take the best decision.

138
00:06:13,470 --> 00:06:16,430
The more layers that you're
gonna have in most cases,

139
00:06:16,430 --> 00:06:17,480
the better output,

140
00:06:17,480 --> 00:06:20,073
the more accurate the output is gonna be.

141
00:06:20,920 --> 00:06:22,360
So just to summarize

142
00:06:22,360 --> 00:06:25,510
what we kind of went
very quickly through here

143
00:06:25,510 --> 00:06:27,780
on a high level, we talked about datasets

144
00:06:27,780 --> 00:06:30,849
which is the data that we
wanna teach that model.

145
00:06:30,850 --> 00:06:33,230
We talked about feature
set and feature reduction,

146
00:06:33,230 --> 00:06:36,660
which is the one that we want
to actually learn the model.

147
00:06:36,660 --> 00:06:38,300
We talked about learning methods,

148
00:06:38,300 --> 00:06:41,640
so we were covering the
supervised, the Next Gen AV,

149
00:06:41,640 --> 00:06:45,729
or the unsupervised as more
of a classifying to families,

150
00:06:45,730 --> 00:06:48,630
we talked about reinforcement
the carrots model,

151
00:06:48,630 --> 00:06:51,400
and the models to use as implementation,

152
00:06:51,400 --> 00:06:54,479
we talked about the deep
neural and random forest

153
00:06:54,480 --> 00:06:56,300
which are very common to use.

154
00:06:56,300 --> 00:06:58,220
Each one of them of course
will have its own challenge

155
00:06:58,220 --> 00:06:59,230
and we'll talk about that.

156
00:06:59,230 --> 00:07:02,150
So you need to know what
is needed to use forest,

157
00:07:02,150 --> 00:07:04,330
you to understand that
it's gonna be an impact

158
00:07:04,330 --> 00:07:06,560
on CPU and memory and others.

159
00:07:06,560 --> 00:07:08,010
But now we're gonna talk more about

160
00:07:08,010 --> 00:07:10,223
how to apply those into IR.

161
00:07:11,670 --> 00:07:15,410
So AI based IR, what exactly
are we talking about here?

162
00:07:15,410 --> 00:07:17,030
Incident Response Process,

163
00:07:17,030 --> 00:07:19,640
let's go through the stages
of the incident response.

164
00:07:19,640 --> 00:07:22,880
The incident response is
built, as we broke it here,

165
00:07:22,880 --> 00:07:25,200
into five different stages.

166
00:07:25,200 --> 00:07:27,370
The first part is it's preparation.

167
00:07:27,370 --> 00:07:29,600
What do we wanna have, what is the,

168
00:07:29,600 --> 00:07:31,130
I would say the best practice

169
00:07:31,130 --> 00:07:35,000
or the pre-key concept
that we wanna follow.

170
00:07:35,000 --> 00:07:36,370
And then are we're gonna
have the detection.

171
00:07:36,370 --> 00:07:39,970
So that's the initial incident
that we're gonna track.

172
00:07:39,970 --> 00:07:42,720
Once we have that, we'll move
to an investigation analysis

173
00:07:42,720 --> 00:07:45,700
in order to better understand
what are we facing here.

174
00:07:45,700 --> 00:07:46,990
And once we understood that,

175
00:07:46,990 --> 00:07:50,320
we'll need to take an
immediate containment

176
00:07:50,320 --> 00:07:53,349
and maybe sometimes a micro containment

177
00:07:53,350 --> 00:07:56,060
just to slow down of what we've seen.

178
00:07:56,060 --> 00:07:59,430
And then when we have that clear idea,

179
00:07:59,430 --> 00:08:02,840
we'll take a post-incident
activity across the board

180
00:08:02,840 --> 00:08:05,140
and of course, feed it
back to the preparation.

181
00:08:05,140 --> 00:08:07,830
So for the next time
we'll be more adjusted

182
00:08:07,830 --> 00:08:10,163
and more tuned to what we need to have.

183
00:08:11,010 --> 00:08:13,210
Let's start now with the investigation,

184
00:08:13,210 --> 00:08:15,450
and then we'll touch the containment part

185
00:08:15,450 --> 00:08:18,270
and see how AI can actually apply to it.

186
00:08:18,270 --> 00:08:19,880
What is our goals here?

187
00:08:19,880 --> 00:08:22,969
The goal is first to
understand and better classify

188
00:08:22,970 --> 00:08:24,070
what are we facing here?

189
00:08:24,070 --> 00:08:24,920
Is it a good one,

190
00:08:24,920 --> 00:08:27,810
did we catch the needle and the malware,

191
00:08:27,810 --> 00:08:30,440
or are we looking into false positive

192
00:08:30,440 --> 00:08:32,000
or anything that is

193
00:08:32,000 --> 00:08:34,409
still has not matured to become something.

194
00:08:34,409 --> 00:08:35,610
we need to scope it.

195
00:08:35,610 --> 00:08:36,929
What was affected,

196
00:08:36,929 --> 00:08:39,750
which artifacts are related
to the effect of what?

197
00:08:39,750 --> 00:08:41,530
We need to try as the source

198
00:08:41,530 --> 00:08:45,209
of where and how did it all start?

199
00:08:45,210 --> 00:08:46,640
So we need to have a better picture

200
00:08:46,640 --> 00:08:48,810
of what are we facing here,

201
00:08:48,810 --> 00:08:52,290
and we need to understand how
fast do we need to remediate

202
00:08:52,290 --> 00:08:53,420
what's gonna be the next stage,

203
00:08:53,420 --> 00:08:55,000
and what are we using as a data source

204
00:08:55,000 --> 00:08:58,470
almost anything that can serve
us within the environment.

205
00:08:58,470 --> 00:09:01,060
That means endpoint data, network data,

206
00:09:01,060 --> 00:09:05,280
intelligence, sandboxes,
reputations, and of course humans.

207
00:09:05,280 --> 00:09:06,939
We'll talk a lot about the fact that

208
00:09:06,940 --> 00:09:10,720
humans are needed in order
to keep on tuning the system.

209
00:09:10,720 --> 00:09:12,980
Moving forward to containment.

210
00:09:12,980 --> 00:09:16,210
And that's of course already
part of the immediate

211
00:09:16,210 --> 00:09:17,560
or part of the response.

212
00:09:17,560 --> 00:09:19,089
What are our goals?

213
00:09:19,090 --> 00:09:20,797
Our goals is to remediate,

214
00:09:20,797 --> 00:09:23,530
to remediate by meaning
removing all traces

215
00:09:23,530 --> 00:09:26,900
of an activity that has
consequences on the attack,

216
00:09:26,900 --> 00:09:29,530
then recover, meaning go back to normal,

217
00:09:29,530 --> 00:09:30,959
go back to business.

218
00:09:30,960 --> 00:09:34,010
When the input is our
investigation results,

219
00:09:34,010 --> 00:09:35,530
which could be a lot of things there,

220
00:09:35,530 --> 00:09:39,290
and of course the tools
that we're gonna use

221
00:09:39,290 --> 00:09:42,930
are related more to endpoints, network,

222
00:09:42,930 --> 00:09:45,280
physical again, of what are
we gonna do with the machine.

223
00:09:45,280 --> 00:09:48,240
Sometimes you need to
physically intervene in that,

224
00:09:48,240 --> 00:09:50,220
and mark false positive

225
00:09:50,220 --> 00:09:52,670
and other misleading artifacts as one

226
00:09:52,670 --> 00:09:54,800
so we can actually do that better

227
00:09:54,800 --> 00:09:58,609
in the next cycle of an incident.

228
00:09:58,610 --> 00:10:00,330
So why do we actually need this,

229
00:10:00,330 --> 00:10:02,170
I think that goes without saying.

230
00:10:02,170 --> 00:10:05,890
We need to make a more
automated incident response.

231
00:10:05,890 --> 00:10:08,280
We have a shortage in
cyber security personnel

232
00:10:08,280 --> 00:10:10,470
and time to response is critical.

233
00:10:10,470 --> 00:10:13,760
We all understand how fast
consequences are happening

234
00:10:13,760 --> 00:10:15,430
especially in a ransomware.

235
00:10:15,430 --> 00:10:19,510
but we need to move to
a quicker and faster,

236
00:10:19,510 --> 00:10:24,240
and also a scalable across
the board incident response.

237
00:10:24,240 --> 00:10:26,970
And when we talk about how to do this.

238
00:10:26,970 --> 00:10:29,310
So I think when you're
trying to coordinate

239
00:10:29,310 --> 00:10:32,579
the AI based IR, you would
need to understand first

240
00:10:32,580 --> 00:10:35,320
how to collect real world attacks.

241
00:10:35,320 --> 00:10:39,460
So that's of course, one dataset
that we'll need to train,

242
00:10:39,460 --> 00:10:40,400
but of course with that,

243
00:10:40,400 --> 00:10:44,130
we also need to have the
day-to-day normal datasets

244
00:10:44,130 --> 00:10:46,100
that are working and are not malicious

245
00:10:46,100 --> 00:10:48,980
so we can train the other
side of that as well.

246
00:10:48,980 --> 00:10:51,770
We need experts, humans, again,

247
00:10:51,770 --> 00:10:53,610
to help to teach the machine.

248
00:10:53,610 --> 00:10:56,400
Not everything is gonna
be done automatically

249
00:10:56,400 --> 00:10:57,233
from end to end,

250
00:10:57,233 --> 00:10:58,065
and the machine learning

251
00:10:58,066 --> 00:10:59,410
is not always gonna be that tuned,

252
00:10:59,410 --> 00:11:02,890
and therefore we'll need
people to tune down the models

253
00:11:02,890 --> 00:11:05,580
and tune down the inputs.

254
00:11:05,580 --> 00:11:07,763
And that brings me to the last point of,

255
00:11:08,790 --> 00:11:11,689
just don't, I don't want
anybody to expect that

256
00:11:11,690 --> 00:11:15,240
AI or machine learning in specific

257
00:11:15,240 --> 00:11:16,840
are gonna do a black magic here

258
00:11:16,840 --> 00:11:20,490
and completely replace our
incident response analyst,

259
00:11:20,490 --> 00:11:21,323
it is not.

260
00:11:21,323 --> 00:11:22,156
So, as you can see

261
00:11:22,156 --> 00:11:25,300
a lot of human intervening
is still needed.

262
00:11:25,300 --> 00:11:26,380
And then when going back

263
00:11:26,380 --> 00:11:29,800
to the data collection that we need to do.

264
00:11:29,800 --> 00:11:32,520
So we talked about building good datasets,

265
00:11:32,520 --> 00:11:34,100
these are the day-to-day,

266
00:11:34,100 --> 00:11:35,690
and these are the hardest to do

267
00:11:35,690 --> 00:11:38,960
because malwares and IOCs
and all the rest of those

268
00:11:38,960 --> 00:11:40,960
are very available,

269
00:11:40,960 --> 00:11:42,270
but good scenarios

270
00:11:42,270 --> 00:11:45,199
that also could be related to
one environment or the other

271
00:11:45,200 --> 00:11:46,730
are hard to collect.

272
00:11:46,730 --> 00:11:48,350
Different artifact type of course,

273
00:11:48,350 --> 00:11:50,500
when it comes to URL and behaviors,

274
00:11:50,500 --> 00:11:54,340
but to benign one,
combination within real life,

275
00:11:54,340 --> 00:11:56,490
real world attacks and emulator

276
00:11:56,490 --> 00:12:01,323
are the main one to collect
and feed the machine learning.

277
00:12:02,550 --> 00:12:04,849
Now we're gonna move to
teaching to investigate,

278
00:12:04,850 --> 00:12:06,410
I'll move that to you Yavo.

279
00:12:07,300 --> 00:12:10,390
- Okay, next up, teaching
the machine to investigate.

280
00:12:10,390 --> 00:12:14,560
So this is the process that we have built

281
00:12:14,560 --> 00:12:19,410
to automate the investigation
stage using machine learning.

282
00:12:19,410 --> 00:12:20,969
So it all starts with detection.

283
00:12:20,970 --> 00:12:24,050
Basically, we are getting
some kind of information

284
00:12:24,050 --> 00:12:26,663
from endpoint or firewall

285
00:12:26,663 --> 00:12:29,143
that indicates that
some incident occurred.

286
00:12:30,650 --> 00:12:33,130
The next phase is to normalize this data.

287
00:12:33,130 --> 00:12:36,210
So we will have it in a unified
form for the next stage,

288
00:12:36,210 --> 00:12:38,620
where we extract the different artifacts

289
00:12:38,620 --> 00:12:40,930
whether it's processes, files,

290
00:12:40,930 --> 00:12:42,933
behavioral chains, or whatnot.

291
00:12:43,980 --> 00:12:46,910
Next, we will try to scope the incident.

292
00:12:46,910 --> 00:12:50,170
Scoping means that we
will try to see everything

293
00:12:50,170 --> 00:12:52,530
that was affected by the incident.

294
00:12:52,530 --> 00:12:53,850
And the better we do that,

295
00:12:53,850 --> 00:12:56,432
the more accurate the response will be,

296
00:12:56,432 --> 00:12:59,580
and more on that will be discussed later.

297
00:12:59,580 --> 00:13:01,030
Next step is enrichment.

298
00:13:01,030 --> 00:13:03,680
During the enrichment phase,

299
00:13:03,680 --> 00:13:06,229
we will execute sandbox,
check intelligence,

300
00:13:06,230 --> 00:13:10,380
and basically leverage
everything in our disposal

301
00:13:10,380 --> 00:13:12,189
to get as much information as we can

302
00:13:12,190 --> 00:13:13,723
on each of the artifact.

303
00:13:15,080 --> 00:13:17,510
The next stage is where machine learning

304
00:13:17,510 --> 00:13:19,470
or AI comes into play.

305
00:13:19,470 --> 00:13:23,640
And basically we will
classify each artifact

306
00:13:23,640 --> 00:13:27,090
and move on to another scoping phase,

307
00:13:27,090 --> 00:13:29,010
where we will either remove

308
00:13:29,010 --> 00:13:33,260
or expand the scope of the incident

309
00:13:33,260 --> 00:13:35,050
based on the classifications.

310
00:13:35,050 --> 00:13:37,079
And I'll explain what I mean later,

311
00:13:37,080 --> 00:13:40,170
but basically if we have
new items we need to add,

312
00:13:40,170 --> 00:13:42,670
we will need to go back
to the enrichment phase,

313
00:13:42,670 --> 00:13:45,770
and again, to classify the artifacts.

314
00:13:45,770 --> 00:13:49,360
If we are done in the are
normal artifacts to analyze,

315
00:13:49,360 --> 00:13:51,100
then we are pretty much done,

316
00:13:51,100 --> 00:13:53,973
and we have classified
artifacts we can work from.

317
00:13:57,680 --> 00:14:00,099
Normalization, so as mentioned,

318
00:14:00,100 --> 00:14:03,280
the goal is to have data in a unified way.

319
00:14:03,280 --> 00:14:05,250
For example if we have two SIEMS

320
00:14:05,250 --> 00:14:07,520
that we are using as data sources,

321
00:14:07,520 --> 00:14:12,520
we need to be able to use them
both for the investigation.

322
00:14:14,380 --> 00:14:17,880
So the idea is that the rest
of the system won't be affected

323
00:14:17,880 --> 00:14:20,433
by the way the data looks.

324
00:14:21,460 --> 00:14:23,740
AI is not really needed for this stage,

325
00:14:23,740 --> 00:14:28,100
and if you have your own
systems or very specific systems

326
00:14:28,100 --> 00:14:29,800
you probably don't need it at all.

327
00:14:32,140 --> 00:14:37,140
Extraction, so for extractions
AI may be beneficial.

328
00:14:39,230 --> 00:14:42,991
For example, getting URLs out
of command line may be useful

329
00:14:42,991 --> 00:14:45,520
or registry keys form text,

330
00:14:45,520 --> 00:14:48,593
and identifying those kinds of artifacts.

331
00:14:49,520 --> 00:14:52,660
We will not dive into these
models due to lack of time

332
00:14:52,660 --> 00:14:55,980
but just FYI simple pattern matchers

333
00:14:55,980 --> 00:14:58,930
can probably do a very
good job at this stage.

334
00:14:58,930 --> 00:15:03,113
And many times there is no
really need for fancy models.

335
00:15:08,090 --> 00:15:10,620
Okay, scoping, so, as I mentioned

336
00:15:10,620 --> 00:15:14,460
there's two main goals
and stages in a way.

337
00:15:14,460 --> 00:15:19,460
First, the goal is to find
what the incident affected.

338
00:15:21,140 --> 00:15:23,880
This will also allow
us to triage the source

339
00:15:23,880 --> 00:15:25,823
and we will see how it works later.

340
00:15:26,807 --> 00:15:27,910
And at this stage,

341
00:15:27,910 --> 00:15:29,430
we will also collect and remove artifacts

342
00:15:29,430 --> 00:15:33,900
which will allow us to get
a better classification

343
00:15:33,900 --> 00:15:35,122
for the entire incident.

344
00:15:36,395 --> 00:15:39,290
As mentioned, it is executed
before every analysis,

345
00:15:39,290 --> 00:15:41,099
and it is critical to ensure

346
00:15:41,100 --> 00:15:44,573
that we get the right
context for the incident.

347
00:15:46,290 --> 00:15:49,300
So this is an example
of adding an artifact

348
00:15:49,300 --> 00:15:51,349
to the investigation process.

349
00:15:51,350 --> 00:15:53,990
Let's say that we have
identified a malicious process

350
00:15:53,990 --> 00:15:58,043
of one of the devices,
device A in that example.

351
00:15:59,090 --> 00:16:02,630
And we witness it connecting
to some malicious IP.

352
00:16:02,630 --> 00:16:06,730
Now, using some other data
source EDI or whatnot,

353
00:16:06,730 --> 00:16:09,510
we also know that process B from device B

354
00:16:09,510 --> 00:16:11,560
also connected to that IP.

355
00:16:11,560 --> 00:16:13,660
So it is very likely that this process

356
00:16:13,660 --> 00:16:16,250
is also related to the investigation.

357
00:16:16,250 --> 00:16:18,860
And so it will be added to the incident

358
00:16:18,860 --> 00:16:22,203
and the investigation process
will work on it as well.

359
00:16:24,330 --> 00:16:28,050
As an example for removal,
we can see another situation

360
00:16:28,050 --> 00:16:33,050
where a suspicious process
makes some malicious behaviors.

361
00:16:33,060 --> 00:16:35,229
So normally we will also want

362
00:16:35,230 --> 00:16:37,570
to flow in the parent for analysis

363
00:16:37,570 --> 00:16:39,970
because the parent might
be interesting as well

364
00:16:39,970 --> 00:16:44,430
and might be the the actual
source of the incident.

365
00:16:44,430 --> 00:16:47,449
But let's say that reputation,

366
00:16:47,450 --> 00:16:50,360
already know this file
and we know it is good,

367
00:16:50,360 --> 00:16:52,840
so we can move it out of
the scope of the incident

368
00:16:52,840 --> 00:16:56,340
and we won't analyze it or
look anything according to it.

369
00:16:56,340 --> 00:17:00,280
So this is a way to reduce
the scope of the incident

370
00:17:00,280 --> 00:17:01,693
and focus on what matters.

371
00:17:05,971 --> 00:17:06,971
Enrichments.

372
00:17:08,060 --> 00:17:12,720
So here we pretty much use
every data source we can

373
00:17:12,720 --> 00:17:15,383
to make the investigation
as accurate as possible.

374
00:17:16,329 --> 00:17:19,929
YARA rules, environment specific data

375
00:17:19,930 --> 00:17:23,839
like when a file was first
introduced and stuff like that.

376
00:17:23,839 --> 00:17:26,209
It can also involve getting unknown files

377
00:17:26,210 --> 00:17:28,329
from endpoints memory dumps.

378
00:17:28,329 --> 00:17:30,580
But one of the most important point here

379
00:17:30,580 --> 00:17:34,399
is that we should also be able

380
00:17:34,400 --> 00:17:38,103
to add rule engine at this stage.

381
00:17:39,560 --> 00:17:41,110
The idea is that

382
00:17:41,110 --> 00:17:43,040
machine learning is as
good as it's gonna get,

383
00:17:43,040 --> 00:17:45,050
it's never gonna be able to handle

384
00:17:45,050 --> 00:17:48,960
all the unknown behaviors out
there, and emerging threats

385
00:17:48,960 --> 00:17:53,960
and having a rule engine
that a human can tweak

386
00:17:54,080 --> 00:17:57,530
will allow us to overcome such issues

387
00:17:57,530 --> 00:17:59,490
by quickly adding new rules

388
00:17:59,490 --> 00:18:02,110
that indicate that
something bad is going on.

389
00:18:02,110 --> 00:18:04,669
I think that the recent exchange exploit

390
00:18:04,670 --> 00:18:07,990
is a very good example of that.

391
00:18:07,990 --> 00:18:11,070
I'm pretty sure now,
pretty much every vendor

392
00:18:11,070 --> 00:18:15,300
added the dropping of new ESPX files

393
00:18:15,300 --> 00:18:19,793
as a suspicious behavior to the EDLs.

394
00:18:21,220 --> 00:18:26,220
Okay, all of those will be
added as features to the models.

395
00:18:30,150 --> 00:18:33,631
Okay, so classifying artifacts.

396
00:18:33,631 --> 00:18:35,500
In this presentation,

397
00:18:35,500 --> 00:18:37,690
we will focus on static file classifier

398
00:18:37,690 --> 00:18:40,020
and process behavior classifiers.

399
00:18:40,020 --> 00:18:42,680
Other common classifiers are a domain name

400
00:18:42,680 --> 00:18:45,000
or user-activity classifiers,

401
00:18:45,000 --> 00:18:47,970
which are used for UABA products.

402
00:18:47,970 --> 00:18:50,220
But due to lack of time,
we won't cover them.

403
00:18:52,090 --> 00:18:53,929
Other artifacts like IP,

404
00:18:53,930 --> 00:18:55,890
don't necessarily need classifiers,

405
00:18:55,890 --> 00:18:59,000
stuff like intelligence is
probably good enough for them.

406
00:19:01,390 --> 00:19:05,240
Okay, static file analysis
or classification.

407
00:19:05,240 --> 00:19:09,050
We touched on that a
bit on the first slides.

408
00:19:09,050 --> 00:19:11,690
So basically we take
malicious files, good files,

409
00:19:11,690 --> 00:19:13,797
extract features, and train the model.

410
00:19:14,700 --> 00:19:16,767
One good thing about files is that

411
00:19:16,767 --> 00:19:19,830
there are a lot of sources

412
00:19:19,830 --> 00:19:22,100
and variable starter is a very good one.

413
00:19:22,100 --> 00:19:23,969
You have a lot of flavored data,

414
00:19:23,970 --> 00:19:26,453
which you can use to train the models.

415
00:19:29,090 --> 00:19:33,753
Some feature example,
entropy, is it signed or not,

416
00:19:36,917 --> 00:19:38,929
imported BARs and so on.

417
00:19:38,930 --> 00:19:40,460
But the key thing here

418
00:19:40,460 --> 00:19:43,900
is to also have the main
knowledge experts in these stages

419
00:19:43,900 --> 00:19:46,330
to be able to choose the features right,

420
00:19:46,330 --> 00:19:49,082
and to do a feature selection.

421
00:19:50,210 --> 00:19:52,100
We won't dive into the process,

422
00:19:52,100 --> 00:19:57,100
but it is important to note that as well.

423
00:19:59,080 --> 00:20:01,460
So, our strategy was to
build two models actually,

424
00:20:01,460 --> 00:20:03,550
one for the endpoints,

425
00:20:03,550 --> 00:20:05,100
where we used a random forest,

426
00:20:05,100 --> 00:20:07,679
very small, less than 10 megs in size,

427
00:20:07,680 --> 00:20:09,400
and also super fast,

428
00:20:09,400 --> 00:20:11,743
less than 10th of a
seconds on average scan.

429
00:20:13,090 --> 00:20:15,280
A few updates are needed once per quarter,

430
00:20:15,280 --> 00:20:16,993
and it's quite accurate, 93%.

431
00:20:18,600 --> 00:20:21,159
The cloud model is using
deep neural networks.

432
00:20:21,160 --> 00:20:23,230
It's over one gigabyte in size,

433
00:20:23,230 --> 00:20:26,730
and is constantly being trained
for millions of samples.

434
00:20:26,730 --> 00:20:30,830
And while the difference in percentages

435
00:20:30,830 --> 00:20:32,350
doesn't seem like much,

436
00:20:32,350 --> 00:20:35,439
consider how many files
you have in an organization

437
00:20:35,440 --> 00:20:38,200
and how much 1% really mean.

438
00:20:38,200 --> 00:20:41,137
It's actually real world accuracy

439
00:20:41,137 --> 00:20:44,840
and also something that was fetched

440
00:20:44,840 --> 00:20:47,667
from some learning algorithm.

441
00:20:49,910 --> 00:20:54,650
Okay, so process behavior classifier.

442
00:20:54,650 --> 00:20:58,510
Here we need a more
complex learning algorithm,

443
00:20:58,510 --> 00:21:02,010
and we use pseudo
labeling for first stage.

444
00:21:02,010 --> 00:21:05,500
So the idea is to take both
good and bad behaviors,

445
00:21:05,500 --> 00:21:08,197
we got them from angulators and sandboxes.

446
00:21:08,197 --> 00:21:09,780
And train the first model,

447
00:21:09,780 --> 00:21:13,893
very similar to the way we
did in static file analysis.

448
00:21:15,310 --> 00:21:17,830
Next, what we do is take unlabeled data.

449
00:21:17,830 --> 00:21:20,570
We have tons of data in
real life environments,

450
00:21:20,570 --> 00:21:21,919
and we feed it to the model,

451
00:21:21,920 --> 00:21:25,057
out of which we get new data.

452
00:21:28,820 --> 00:21:31,850
Actually not new data but new label data.

453
00:21:31,850 --> 00:21:34,546
Some labeled with high confidence
according to our models

454
00:21:34,547 --> 00:21:37,740
and some labeled with low confidence.

455
00:21:37,740 --> 00:21:41,370
We take the data that is
labeled with high confidence

456
00:21:41,370 --> 00:21:44,719
either as good or bad and
add it to the dataset.

457
00:21:44,720 --> 00:21:48,290
Obviously human is part of that cycle too,

458
00:21:48,290 --> 00:21:50,940
just to make sure that what we
are adding really makes sense

459
00:21:50,940 --> 00:21:53,780
and whatever is added as good is good,

460
00:21:53,780 --> 00:21:56,857
and whatever is added as bad is bad.

461
00:21:58,310 --> 00:21:59,620
So once we have that,

462
00:21:59,620 --> 00:22:02,729
we basically have much bigger dataset

463
00:22:02,730 --> 00:22:07,590
where we can train again
and create our final models.

464
00:22:07,590 --> 00:22:09,280
Obviously, there are many iterations

465
00:22:09,280 --> 00:22:11,240
it's not a single iteration,

466
00:22:11,240 --> 00:22:14,820
but that way we are capable of building

467
00:22:14,820 --> 00:22:18,423
a much more accurate
machine learning model.

468
00:22:19,680 --> 00:22:22,790
Another technique we use is called GAN.

469
00:22:22,790 --> 00:22:25,750
Basically what we have is adversary model

470
00:22:25,750 --> 00:22:29,713
that tries to generate behaviors

471
00:22:29,713 --> 00:22:32,490
that will make our initial models fail.

472
00:22:32,490 --> 00:22:37,490
Either by making the wrong
decisions on malicious behaviors,

473
00:22:38,660 --> 00:22:41,220
or on good behaviors.

474
00:22:41,220 --> 00:22:43,390
And doing many iterations of that

475
00:22:43,390 --> 00:22:47,303
and training both the
adversary and our models

476
00:22:47,303 --> 00:22:50,780
that means to classify
good and bad behaviors,

477
00:22:50,780 --> 00:22:52,300
ensure that we are getting

478
00:22:52,300 --> 00:22:55,260
much more accurate results in the end.

479
00:22:59,967 --> 00:23:02,690
The different features
for behaviors, injections,

480
00:23:02,690 --> 00:23:05,940
dropping of files and
caption of data and so on.

481
00:23:05,940 --> 00:23:07,743
But the general idea is the same.

482
00:23:11,802 --> 00:23:13,949
Here we also use the cloud model,

483
00:23:13,950 --> 00:23:16,970
again very big over a gig in size,

484
00:23:16,970 --> 00:23:19,540
which is constantly being
trained from the live data

485
00:23:19,540 --> 00:23:21,263
and from emulated data.

486
00:23:22,920 --> 00:23:24,520
And also just specialized model,

487
00:23:24,520 --> 00:23:28,152
for example for processors
like Powershell.

488
00:23:28,152 --> 00:23:31,650
And the accuracy here is
really hard to measure,

489
00:23:31,650 --> 00:23:34,290
and the reason I didn't put like 99% here

490
00:23:34,290 --> 00:23:35,690
or something like that,

491
00:23:35,690 --> 00:23:40,553
is because you will always
get a kick in the face kind of

492
00:23:44,300 --> 00:23:46,780
when facing real-world environments.

493
00:23:46,780 --> 00:23:49,740
And you'll find new things that are good,

494
00:23:49,740 --> 00:23:51,720
that are doing things
that look very malicious,

495
00:23:51,720 --> 00:23:54,370
and things that are bad that
you haven't seen before,

496
00:23:54,370 --> 00:23:57,092
and no one saw before,
and might be missed.

497
00:24:01,639 --> 00:24:04,120
Okay, so a bit about triaging.

498
00:24:04,120 --> 00:24:07,439
So if we have a very good investigation,

499
00:24:07,440 --> 00:24:09,930
we will also have a very good triage.

500
00:24:09,930 --> 00:24:12,750
And as an example, let's
consider a scenario

501
00:24:12,750 --> 00:24:17,750
where we detected some zero
log on exploitation attempt

502
00:24:17,980 --> 00:24:20,430
on one of the active directory service.

503
00:24:20,430 --> 00:24:22,060
From that point it is also possible

504
00:24:22,060 --> 00:24:23,820
to trace it back to a connection

505
00:24:23,820 --> 00:24:27,543
to the machine where the
attacks started from.

506
00:24:28,870 --> 00:24:31,620
And it's also possible
to identify the session

507
00:24:31,620 --> 00:24:34,370
and from there move to another server

508
00:24:34,370 --> 00:24:39,370
that was before that logged
in by an attacker using RDP.

509
00:24:43,470 --> 00:24:46,070
All that is possible if
you have the evidence.

510
00:24:46,070 --> 00:24:47,520
The more data sources you have,

511
00:24:47,520 --> 00:24:50,220
whether it's from the
endpoint or firewall,

512
00:24:50,220 --> 00:24:53,113
the better triage and scoping is possible.

513
00:24:57,180 --> 00:24:58,930
Okay, so to sum this part up,

514
00:24:58,930 --> 00:25:03,900
automated investigation is
complex and humans are needed.

515
00:25:03,900 --> 00:25:08,900
But obviously if done well,
it will save endless man hour.

516
00:25:10,620 --> 00:25:13,139
You don't have to develop
everything at once,

517
00:25:13,140 --> 00:25:14,930
you can deploy it gradually.

518
00:25:14,930 --> 00:25:18,313
And as we will see, it is
the key for good responses.

519
00:25:21,320 --> 00:25:25,010
Okay, but remediation is mostly easy

520
00:25:25,010 --> 00:25:28,270
because let's say you have
a bad file, delete it.

521
00:25:28,270 --> 00:25:31,260
If you have a bad IP,
block it in the firewall,

522
00:25:31,260 --> 00:25:33,420
but the process can be
terminated or suspended

523
00:25:33,420 --> 00:25:35,340
maybe remove the files too.

524
00:25:35,340 --> 00:25:36,959
And if you find infected device,

525
00:25:36,960 --> 00:25:39,210
we can always just quarantine it.

526
00:25:40,340 --> 00:25:43,909
But, it is not always that trivial

527
00:25:43,910 --> 00:25:46,910
because maybe randomness is introduced.

528
00:25:46,910 --> 00:25:50,379
For example, let's say the attacker

529
00:25:50,379 --> 00:25:53,189
is using a legitimate website.

530
00:25:53,190 --> 00:25:56,800
Then we don't want to block the domain.

531
00:25:56,800 --> 00:26:00,780
And if we have another case

532
00:26:00,780 --> 00:26:04,420
where randomness is introduced to the URL,

533
00:26:04,420 --> 00:26:07,730
we don't want to block
it based on the full URL,

534
00:26:07,730 --> 00:26:10,750
because in that case, we
won't really block anything

535
00:26:10,750 --> 00:26:14,910
because the next binary
will have a different number

536
00:26:14,910 --> 00:26:16,450
and it will still work.

537
00:26:17,580 --> 00:26:20,111
And generally machine learning and AI

538
00:26:20,112 --> 00:26:24,770
will easily be able to handle
the easy cases as well.

539
00:26:24,770 --> 00:26:28,823
So adding those capabilities
will only improve the response.

540
00:26:31,260 --> 00:26:33,910
So this is the process we
have built, it's quite simple.

541
00:26:33,910 --> 00:26:37,280
We get the classified artifacts
from the investigation,

542
00:26:37,280 --> 00:26:39,180
put it into the response model

543
00:26:39,180 --> 00:26:42,090
which generates recommendations

544
00:26:42,090 --> 00:26:47,090
or actions that should be executed.

545
00:26:48,900 --> 00:26:50,886
Based on certainty thresholds,

546
00:26:50,886 --> 00:26:55,450
the machine will decide whether
to execute it immediately

547
00:26:55,450 --> 00:26:57,600
or just recommend to the analyst.

548
00:26:57,600 --> 00:26:59,080
And then the analyst

549
00:26:59,080 --> 00:27:01,419
can provide feedback back to the machine

550
00:27:01,420 --> 00:27:03,880
by either approving or disapproving

551
00:27:04,930 --> 00:27:06,670
the actions and recommendations

552
00:27:06,670 --> 00:27:11,670
which will enable learning of
better models in the future.

553
00:27:13,640 --> 00:27:18,640
So using semi or fully automated response.

554
00:27:18,920 --> 00:27:21,300
So it is hard to tell

555
00:27:21,300 --> 00:27:24,350
and a lot of tuning needs to take place

556
00:27:24,350 --> 00:27:27,250
in order to get it right.

557
00:27:27,250 --> 00:27:30,280
Since some actions can
be extremely destructive

558
00:27:30,280 --> 00:27:32,800
for example, quarantining a server

559
00:27:32,800 --> 00:27:34,370
because some POPs running

560
00:27:34,370 --> 00:27:37,590
is probably gonna cause
more damage than good,

561
00:27:40,070 --> 00:27:41,710
which means that we will probably need

562
00:27:41,710 --> 00:27:42,960
some rules there as well,

563
00:27:42,960 --> 00:27:46,423
like never quarantine some machines.

564
00:27:48,371 --> 00:27:52,927
And some of the models will
probably needs to also control,

565
00:27:54,290 --> 00:27:56,940
whether how fast we
need to execute actions.

566
00:27:56,940 --> 00:28:00,250
For example, if we see
that it is a ransomware,

567
00:28:00,250 --> 00:28:02,920
we need to take actions
as fast as possible

568
00:28:02,920 --> 00:28:05,357
in order to contain the threat.

569
00:28:08,670 --> 00:28:11,900
So we won't be able to dive
into the executor model,

570
00:28:11,900 --> 00:28:13,960
again, due to lack of time,

571
00:28:13,960 --> 00:28:17,370
but the sources are pretty much similar.

572
00:28:17,370 --> 00:28:21,082
We use real world scenarios,
sandbox data and emulators,

573
00:28:22,240 --> 00:28:26,333
and also DNS and URL
data from intelligence,

574
00:28:27,840 --> 00:28:30,240
and there are multiple models here

575
00:28:30,240 --> 00:28:35,240
but some examples that we're
using is URL response models

576
00:28:35,550 --> 00:28:39,290
which tries to decide

577
00:28:39,290 --> 00:28:41,770
which part of the URL
needs to be blacklisted

578
00:28:41,770 --> 00:28:43,343
or whitelisted if needed.

579
00:28:45,196 --> 00:28:50,196
And also another one to
decide what needs to be done

580
00:28:51,740 --> 00:28:52,940
to remediate the threat.

581
00:28:56,920 --> 00:28:59,010
Okay, to summarize,

582
00:28:59,010 --> 00:29:01,580
the key to good response
is good investigation.

583
00:29:01,580 --> 00:29:04,733
It highly depends on how good
the investigation models are.

584
00:29:05,750 --> 00:29:07,770
And the feedback design is critical,

585
00:29:07,770 --> 00:29:11,253
and then I will dive into
that in that following slide.

586
00:29:12,870 --> 00:29:15,822
So how do we apply all that to the cloud?

587
00:29:17,440 --> 00:29:19,820
So this is the architecture we were using.

588
00:29:19,820 --> 00:29:22,620
So we have all kinds of data sources,

589
00:29:22,620 --> 00:29:25,120
the firewall, EDR, and so on.

590
00:29:25,120 --> 00:29:28,213
And we push that data into data queues.

591
00:29:29,746 --> 00:29:31,910
And those queues lead to our normalizer

592
00:29:31,910 --> 00:29:35,450
which pushes the data into
a big data repository.

593
00:29:35,450 --> 00:29:38,910
And once we get there,
investigation can begin.

594
00:29:38,910 --> 00:29:42,170
The investigation leverages
sandboxes, the classifiers,

595
00:29:42,170 --> 00:29:45,730
intelligence, and
everything in our disposal

596
00:29:45,730 --> 00:29:49,600
to get a good classification
and scoping for the incident,

597
00:29:49,600 --> 00:29:51,793
which is later fed into the response,

598
00:29:51,793 --> 00:29:54,239
the automated response model,

599
00:29:54,240 --> 00:29:59,240
which will orchestrate
the deletion of files,

600
00:30:01,900 --> 00:30:04,163
quarantine of devices and so on.

601
00:30:05,130 --> 00:30:08,820
But this is also fully
integrated to MDR console,

602
00:30:08,820 --> 00:30:11,840
which allows humans to
interact with the response

603
00:30:11,840 --> 00:30:15,040
and also create feedback

604
00:30:15,040 --> 00:30:20,040
for either bad or good responses
and investigation results.

605
00:30:21,960 --> 00:30:25,763
And therefore allowing us to
keep improving the system.

606
00:30:28,110 --> 00:30:30,121
So some quick recommendations.

607
00:30:30,122 --> 00:30:32,793
Kubernetes is awesome for scale.

608
00:30:34,080 --> 00:30:39,080
You can go big as you need
to handle more and more data.

609
00:30:42,050 --> 00:30:44,710
You should streamline
the execution for queues

610
00:30:44,710 --> 00:30:47,210
RabbitMQ or Kafka are good,

611
00:30:47,210 --> 00:30:49,160
so you'll be able to control priorities

612
00:30:51,130 --> 00:30:53,410
and also to reduce data reduction

613
00:30:53,410 --> 00:30:57,050
in case something breaks down.

614
00:30:57,050 --> 00:30:59,690
Also use existing tools where possible,

615
00:30:59,690 --> 00:31:04,420
stuff like redis for caching and so on.

616
00:31:04,420 --> 00:31:07,003
And how all this relates
to AI, you may ask.

617
00:31:08,670 --> 00:31:10,330
So, as I mentioned

618
00:31:10,330 --> 00:31:12,770
we also need to be able
to constantly improve.

619
00:31:12,770 --> 00:31:17,133
So ML Ops is the key to that.

620
00:31:18,690 --> 00:31:23,690
And the way we did it is
to take extracted items

621
00:31:24,210 --> 00:31:26,680
each time a new investigation
is being handled,

622
00:31:26,680 --> 00:31:29,070
and not only send it to the current models

623
00:31:29,070 --> 00:31:31,439
which actually handle the automation.

624
00:31:31,440 --> 00:31:34,053
We will also send this
data to the new models

625
00:31:34,053 --> 00:31:36,743
we are trying to build and measure them.

626
00:31:37,720 --> 00:31:39,670
And each time we get new results,

627
00:31:39,670 --> 00:31:42,560
we can compare them based on
the feedback we are getting

628
00:31:42,560 --> 00:31:44,230
to what we actually got

629
00:31:44,230 --> 00:31:46,880
in the automated process
we currently have.

630
00:31:46,880 --> 00:31:49,670
And now when we manage

631
00:31:49,670 --> 00:31:52,780
to create a new and better model

632
00:31:52,780 --> 00:31:54,160
and replace the current one,

633
00:31:54,160 --> 00:31:56,610
and this cycle goes on and on

634
00:31:56,610 --> 00:31:58,320
and allows us to create

635
00:31:58,320 --> 00:32:02,453
a much better response and investigations.

636
00:32:04,880 --> 00:32:09,240
Some tips conduct full
research on the infrastructure.

637
00:32:09,240 --> 00:32:10,983
It will bite you if you don't.

638
00:32:11,890 --> 00:32:16,000
ML Ops needs to be
planned from the get go,

639
00:32:16,000 --> 00:32:19,913
and be sure that your first
models will probably be bad.

640
00:32:20,870 --> 00:32:25,159
Thus the ability to constantly
improve them is the key here,

641
00:32:25,160 --> 00:32:28,350
and being able to measure
everything is another key

642
00:32:28,350 --> 00:32:33,350
to make sure you're able to
build the best possible machine.

643
00:32:37,100 --> 00:32:41,199
Also, you must use a mix domain
experts and data scientists.

644
00:32:41,200 --> 00:32:44,670
Only one will not do, simply because

645
00:32:44,670 --> 00:32:49,330
the best way to build great
features are the domain experts.

646
00:32:49,330 --> 00:32:52,260
And obviously all the learning algorithms

647
00:32:52,260 --> 00:32:53,730
and models and measurements

648
00:32:53,730 --> 00:32:56,173
are better being done by scientists.

649
00:32:57,900 --> 00:33:02,650
So takeaways, machine
learning is a hot subject

650
00:33:02,650 --> 00:33:05,000
and is being applied

651
00:33:05,000 --> 00:33:08,510
to more and more domains
in the cybersecurity

652
00:33:08,510 --> 00:33:11,853
but it's not gonna replace
humans anytime soon at least.

653
00:33:13,530 --> 00:33:15,990
That said, it is a great tool

654
00:33:15,990 --> 00:33:20,990
to compliment IR and save human resources,

655
00:33:22,420 --> 00:33:23,500
but it's also complex

656
00:33:23,500 --> 00:33:25,290
and requires a lot of domain knowledge.

657
00:33:25,290 --> 00:33:30,253
And it's very hard to do
as a typical organization.

658
00:33:31,710 --> 00:33:34,830
And the end goal should be
not to automate everything,

659
00:33:34,830 --> 00:33:36,929
but to automate what's possible

660
00:33:36,930 --> 00:33:39,300
and to provide the incident responders

661
00:33:39,300 --> 00:33:42,570
as much data as possible
to take co-correct actions

662
00:33:42,570 --> 00:33:44,320
when it's not possible to automate.

663
00:33:45,518 --> 00:33:47,610
There are obviously other ways to do that.

664
00:33:47,610 --> 00:33:49,820
What we provided is how we did it,

665
00:33:49,820 --> 00:33:53,543
and the experiences we had
when building such a system.

666
00:33:55,750 --> 00:33:59,000
Also some other sources
you might find interesting

667
00:34:00,780 --> 00:34:01,843
and that's it.

