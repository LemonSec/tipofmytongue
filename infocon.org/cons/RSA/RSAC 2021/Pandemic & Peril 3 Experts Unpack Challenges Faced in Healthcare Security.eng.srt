1
00:00:01,140 --> 00:00:04,180
- So it is 35 minutes
after the hour for me,

2
00:00:04,180 --> 00:00:06,300
so I am going to go ahead
and get this started

3
00:00:06,300 --> 00:00:07,479
so hi everyone,

4
00:00:07,480 --> 00:00:10,330
welcome to the Biohacking
Village Sandbox at RSA

5
00:00:10,330 --> 00:00:11,580
today we have three speakers

6
00:00:11,580 --> 00:00:15,210
discussing the different
pandemic and peril situations

7
00:00:15,210 --> 00:00:18,100
and unpacking the
challenges facing healthcare

8
00:00:18,100 --> 00:00:19,810
and biomedical security.

9
00:00:19,810 --> 00:00:22,689
So each person is going to
have seven minutes on the clock

10
00:00:22,690 --> 00:00:25,780
to do what is the fastest
talk of their life

11
00:00:25,780 --> 00:00:28,470
followed by five minutes of Q and A,

12
00:00:28,470 --> 00:00:30,770
and I'm going to start with a Vidya.

13
00:00:30,770 --> 00:00:33,240
Vidya will be talking about the economy...

14
00:00:33,240 --> 00:00:34,190
I can do English.

15
00:00:34,190 --> 00:00:36,410
Economics of a cyber security

16
00:00:36,410 --> 00:00:38,480
and just the fastest bio about her,

17
00:00:38,480 --> 00:00:41,160
Vidya Murthy is passionate
about actually making change

18
00:00:41,160 --> 00:00:44,029
in the healthcare ecosystem and
is trying to move the needle

19
00:00:44,030 --> 00:00:46,720
every day with her work at MedCrypt,

20
00:00:46,720 --> 00:00:50,760
her talk is titled
economics and cybersecurity

21
00:00:50,760 --> 00:00:55,410
and seven minutes on the clock, go.

22
00:00:55,410 --> 00:00:56,389
- Thank you for the time

23
00:00:56,390 --> 00:00:59,060
and I appreciate those who are attending.

24
00:00:59,060 --> 00:01:00,020
So when you saw the topic

25
00:01:00,020 --> 00:01:02,760
of economics of security
and medical devices,

26
00:01:02,760 --> 00:01:04,410
what first came to your mind?

27
00:01:04,410 --> 00:01:07,759
I'd imagine a government
violation of some sort

28
00:01:07,760 --> 00:01:11,200
whether it's HIPAA, whether it's GDPR,

29
00:01:11,200 --> 00:01:13,671
whether it's IP leaks,
something like that, right.

30
00:01:13,671 --> 00:01:17,530
And sure we're seeing
unprecedented fines being levied

31
00:01:17,530 --> 00:01:20,040
there's lawsuits pretty
much across the globe

32
00:01:20,040 --> 00:01:22,240
in every sector of healthcare.

33
00:01:22,240 --> 00:01:23,820
But what I think we need to think about

34
00:01:23,820 --> 00:01:26,929
is that we're changing the paradigm

35
00:01:26,930 --> 00:01:29,220
and actually shifting
how we spend our money

36
00:01:29,220 --> 00:01:31,713
to be more proactive with
our security posture.

37
00:01:32,650 --> 00:01:33,990
So let's take a step back,

38
00:01:33,990 --> 00:01:36,410
cyber attacks are relatively cheap

39
00:01:36,410 --> 00:01:37,840
and pretty easy to access.

40
00:01:37,840 --> 00:01:40,530
The attacker's business plan
is really quite expansive

41
00:01:40,530 --> 00:01:43,230
and the profit margins are quite generous.

42
00:01:43,230 --> 00:01:46,080
And recent studies shows that the losses

43
00:01:46,080 --> 00:01:48,920
as a result of these cyber
attacks are in the trillions

44
00:01:48,920 --> 00:01:51,180
and growing in multiples every year.

45
00:01:51,180 --> 00:01:55,160
Now contrast that against spend
how do we defend ourselves?

46
00:01:55,160 --> 00:01:58,460
Healthcare especially is
about a generation behind

47
00:01:58,460 --> 00:02:00,369
in what attackers are doing,

48
00:02:00,370 --> 00:02:02,860
it's really hard to show
a return on investment

49
00:02:02,860 --> 00:02:04,900
for attacks that never happened,

50
00:02:04,900 --> 00:02:08,009
and law enforcement is
effectively non-existent

51
00:02:08,009 --> 00:02:11,899
something like 0.3% of all
cyber crime that's reported

52
00:02:11,900 --> 00:02:13,920
is actually prosecuted,

53
00:02:13,920 --> 00:02:15,559
and security investment while large

54
00:02:15,560 --> 00:02:18,920
in the round a $100 billion
has only been growing

55
00:02:18,920 --> 00:02:21,920
at a rate of about 10% year over year.

56
00:02:21,920 --> 00:02:22,940
That doesn't really compete

57
00:02:22,940 --> 00:02:24,600
from a dollars and cents perspective

58
00:02:24,600 --> 00:02:27,530
with what our attackers have access to.

59
00:02:27,530 --> 00:02:30,820
Recent news of SolarWinds gives
us a perfect example here.

60
00:02:30,820 --> 00:02:34,940
It was estimated by Microsoft
that it took a 1,000 engineers

61
00:02:34,940 --> 00:02:36,780
to have that be pulled off.

62
00:02:36,780 --> 00:02:39,960
Is there any organization,
even in healthcare

63
00:02:39,960 --> 00:02:43,230
or elsewhere that has a
1,000 security engineers

64
00:02:43,230 --> 00:02:45,119
it's pretty inconceivable,

65
00:02:45,120 --> 00:02:48,370
but this imbalance is
exactly what's exacerbated,

66
00:02:48,370 --> 00:02:51,930
and the fact that our
technology in business practices

67
00:02:51,930 --> 00:02:54,650
are what drive corporate
growth in healthcare

68
00:02:54,650 --> 00:02:56,710
and it drives innovation and profitability

69
00:02:56,710 --> 00:03:00,930
at the end of the day it also
undermines cybersecurity.

70
00:03:00,930 --> 00:03:04,330
Technologies like interoperability
or cloud computing

71
00:03:04,330 --> 00:03:06,870
they give us these amazing
clinical advancements

72
00:03:06,870 --> 00:03:09,850
but they're also dramatically complicate

73
00:03:09,850 --> 00:03:12,269
how we can do security even.

74
00:03:12,270 --> 00:03:15,070
And those tasked with managing
the security and devices

75
00:03:15,070 --> 00:03:18,410
are faced with this conundrum
of really trying to balance

76
00:03:18,410 --> 00:03:20,760
the growth that they get from technology

77
00:03:20,760 --> 00:03:25,030
with the reality of potential
risks that they're gonna take.

78
00:03:25,030 --> 00:03:28,130
So what's someone attending
RSACs supposed to do about this,

79
00:03:28,130 --> 00:03:29,890
go back and propose to your organization

80
00:03:29,890 --> 00:03:32,899
that we secure everything,
that the budget be unchecked

81
00:03:32,900 --> 00:03:34,900
and business profits be damned.

82
00:03:34,900 --> 00:03:37,170
I think the reality is the
economics of trying to do

83
00:03:37,170 --> 00:03:40,320
comprehensive security
are possibly limitless.

84
00:03:40,320 --> 00:03:43,890
So we have to ask ourselves
what happens if we do nothing.

85
00:03:43,890 --> 00:03:46,290
And there's several well
cited studies out there

86
00:03:46,290 --> 00:03:47,920
demonstrating that patient outcomes

87
00:03:47,920 --> 00:03:51,600
are as a result of cybersecurity
incidents are always worse.

88
00:03:51,600 --> 00:03:53,730
We know that things are
worse when things go wrong

89
00:03:53,730 --> 00:03:55,453
from a cybersecurity perspective.

90
00:03:56,400 --> 00:03:58,690
But the reality is is
that the core competency

91
00:03:58,690 --> 00:04:01,070
of healthcare is healthcare.

92
00:04:01,070 --> 00:04:03,079
Whether we're coming up
with new clinical treatments

93
00:04:03,080 --> 00:04:05,320
or enhancing data sharing across the team

94
00:04:05,320 --> 00:04:07,480
or novel ways for quality of life,

95
00:04:07,480 --> 00:04:10,200
healthcare knows how to
deliver clinical care

96
00:04:10,200 --> 00:04:12,040
and it's unrealistic to expect them

97
00:04:12,040 --> 00:04:15,209
to become experts in
cybersecurity overnight,

98
00:04:15,210 --> 00:04:17,410
so that's exactly the challenge.

99
00:04:17,410 --> 00:04:19,269
One of the things that
we can think about though

100
00:04:19,269 --> 00:04:23,219
is how can we prioritize
making device based security

101
00:04:23,220 --> 00:04:26,150
something that is focal to healthcare.

102
00:04:26,150 --> 00:04:29,359
And the thought is the
buyers of medical devices

103
00:04:29,360 --> 00:04:32,940
have not historically pushed
for this to be a core criteria

104
00:04:32,940 --> 00:04:34,760
in their purchasing decision.

105
00:04:34,760 --> 00:04:37,980
Imagine a head of
surgery choosing a device

106
00:04:37,980 --> 00:04:40,940
that is sub-par from a
clinical perspective,

107
00:04:40,940 --> 00:04:43,990
just because it's more cyber secure,

108
00:04:43,990 --> 00:04:45,300
that's pretty inconceivable

109
00:04:45,300 --> 00:04:47,920
it would never really happen that way.

110
00:04:47,920 --> 00:04:49,350
And there's many devices

111
00:04:49,350 --> 00:04:51,840
that as a result of this buying process

112
00:04:51,840 --> 00:04:54,000
ended up being reactively secure.

113
00:04:54,000 --> 00:04:56,300
A powerful buyer comes to the party

114
00:04:56,300 --> 00:04:59,350
and says, hey we need a
specific feature resolve

115
00:04:59,350 --> 00:05:01,580
for our specific use case.

116
00:05:01,580 --> 00:05:03,770
It then gets resolved by
the device manufacturer

117
00:05:03,770 --> 00:05:07,157
who says, hey for us to close
this contract we will do that.

118
00:05:07,157 --> 00:05:08,820
And the aggregate result of this

119
00:05:08,820 --> 00:05:11,530
is that you have a series
of kind of one-off decisions

120
00:05:11,530 --> 00:05:13,799
that are addressing specific use cases

121
00:05:13,800 --> 00:05:17,150
and there's no real
cohesive strategy in place.

122
00:05:17,150 --> 00:05:19,210
At the end of the day that
means that these devices

123
00:05:19,210 --> 00:05:21,760
have a high level of security debt

124
00:05:21,760 --> 00:05:24,473
and most often incomplete
security strategies.

125
00:05:25,440 --> 00:05:28,440
So how could we ever be
prioritizing security

126
00:05:28,440 --> 00:05:31,010
when we're dealing with
it in this one-off way?

127
00:05:31,010 --> 00:05:32,650
Now obviously there are some institutions

128
00:05:32,650 --> 00:05:34,630
that have done a lot of
work had been very vocal

129
00:05:34,630 --> 00:05:35,980
about their progress today.

130
00:05:35,980 --> 00:05:37,860
And there's several
health systems out there

131
00:05:37,860 --> 00:05:40,700
that have been speaking about
cybersecurity for a long time

132
00:05:40,700 --> 00:05:43,090
have stood up labs and been really vocal

133
00:05:43,090 --> 00:05:44,239
about having requirements

134
00:05:44,240 --> 00:05:45,780
as part of their purchasing process,

135
00:05:45,780 --> 00:05:48,710
and that's great and we're
making good progress,

136
00:05:48,710 --> 00:05:50,739
but we have to critically
look at ourselves today

137
00:05:50,740 --> 00:05:53,700
and say has our strategy
today really worked?

138
00:05:53,700 --> 00:05:55,113
And are we being effective?

139
00:05:55,990 --> 00:05:58,080
Like all businesses device manufacturers

140
00:05:58,080 --> 00:05:59,940
determine the features they build

141
00:05:59,940 --> 00:06:02,760
based on what their
customers tell them to do.

142
00:06:02,760 --> 00:06:05,170
So how do we get markets
and incentives aligned

143
00:06:05,170 --> 00:06:08,180
and make sure our devices
are secure by design?

144
00:06:08,180 --> 00:06:11,080
Taking a page from a more advanced field

145
00:06:11,080 --> 00:06:13,909
or more regulated field,
the financial sector

146
00:06:13,910 --> 00:06:16,580
what do we think maybe the
regulator should be the person

147
00:06:16,580 --> 00:06:20,330
and the FDA has rapidly developed,
deployed and disseminated

148
00:06:20,330 --> 00:06:23,440
their pre and post-market
cybersecurity guidance.

149
00:06:23,440 --> 00:06:25,250
With expected enforcement

150
00:06:25,250 --> 00:06:28,160
coming at the end of
this year if not sooner

151
00:06:28,160 --> 00:06:30,160
maybe that'll force device manufacturers

152
00:06:30,160 --> 00:06:32,660
to really get their
cybersecurity posture into place.

153
00:06:32,660 --> 00:06:35,110
It calls for critical
things like cryptography,

154
00:06:35,110 --> 00:06:37,660
behavior monitoring and
vulnerability management

155
00:06:37,660 --> 00:06:40,000
and those will all make security integral

156
00:06:40,000 --> 00:06:42,220
to the development life cycle.

157
00:06:42,220 --> 00:06:43,490
The danger I see though

158
00:06:43,490 --> 00:06:46,030
is that healthcare
constantly blames the user

159
00:06:46,030 --> 00:06:48,780
or the patient, whether
it's patient adherence

160
00:06:48,780 --> 00:06:52,570
or user log-in managements
or fishing failures.

161
00:06:52,570 --> 00:06:54,880
This isn't an industry
that historically optimized

162
00:06:54,880 --> 00:06:56,770
for easing the user experience,

163
00:06:56,770 --> 00:06:58,080
and that goes to my earlier point,

164
00:06:58,080 --> 00:07:00,210
healthcare knows healthcare.

165
00:07:00,210 --> 00:07:02,989
So we need to secure our devices by design

166
00:07:02,990 --> 00:07:04,970
and make that device
something that's usable

167
00:07:04,970 --> 00:07:07,653
from inception with how
these devices operate.

168
00:07:08,640 --> 00:07:10,130
So you wanna learn more

169
00:07:10,130 --> 00:07:11,750
there are several guidance
documents out there,

170
00:07:11,750 --> 00:07:16,360
there's the HSCC, the JSP,
tons of acronyms, NCCoE, TIR57,

171
00:07:17,750 --> 00:07:19,260
you can pursue any one of these,

172
00:07:19,260 --> 00:07:20,789
but the important thing to remember

173
00:07:20,790 --> 00:07:23,820
is that there is no one
standard to rule them all.

174
00:07:23,820 --> 00:07:26,440
And we've seen idiosyncratic
progress to date

175
00:07:26,440 --> 00:07:28,100
but it's not sufficient.

176
00:07:28,100 --> 00:07:31,530
Device development has
to go a systemic change

177
00:07:31,530 --> 00:07:33,349
about how cybersecurity can fit

178
00:07:33,350 --> 00:07:35,780
into every facet of development.

179
00:07:35,780 --> 00:07:37,876
And there's great books out there one name

180
00:07:37,877 --> 00:07:39,370
"Medical Device Cybersecurity

181
00:07:39,370 --> 00:07:41,050
for Engineers and Manufacturers"

182
00:07:41,050 --> 00:07:43,480
that breaks down every step of development

183
00:07:43,480 --> 00:07:46,010
to say what is a
developer centric strategy

184
00:07:46,010 --> 00:07:47,763
for having security devices?

185
00:07:48,650 --> 00:07:51,750
Cybersecurity cost is only
going to be effectively managed

186
00:07:51,750 --> 00:07:53,250
and integrated when it's part

187
00:07:53,250 --> 00:07:55,710
of core decision making processes

188
00:07:55,710 --> 00:07:57,729
and more of for an
efficient economy to work

189
00:07:57,730 --> 00:07:59,420
access to cybersecurity expertise

190
00:07:59,420 --> 00:08:01,960
is the only way to really
ensure that it scales

191
00:08:01,960 --> 00:08:05,000
and lives throughout the
lifetime of a device,

192
00:08:05,000 --> 00:08:07,640
but for our-
- 30 seconds.

193
00:08:07,640 --> 00:08:09,099
- One last line on that,

194
00:08:09,100 --> 00:08:11,010
there's a good way we can do more

195
00:08:11,010 --> 00:08:12,200
but we have to do things differently

196
00:08:12,200 --> 00:08:13,400
than we have in the past.

197
00:08:13,400 --> 00:08:14,940
Thank you.

198
00:08:14,940 --> 00:08:16,280
- Oh, that was the perfect segue.

199
00:08:16,280 --> 00:08:18,830
So what are your thoughts
on doing the differently?

200
00:08:19,810 --> 00:08:23,530
- I think if we aren't
incentivizing to be proactive,

201
00:08:23,530 --> 00:08:25,010
you can't actually keep saying,

202
00:08:25,010 --> 00:08:26,870
hey we're making idiosyncratic progress

203
00:08:26,870 --> 00:08:29,300
and we're fixing a single implementation.

204
00:08:29,300 --> 00:08:30,920
We're solving specific subsets

205
00:08:30,920 --> 00:08:32,700
because that's an easy
way to break it down

206
00:08:32,700 --> 00:08:34,000
but we're not actually looking

207
00:08:34,000 --> 00:08:36,380
at the holistic hospital situation,

208
00:08:36,380 --> 00:08:39,000
we have to think about
who is bearing the burden,

209
00:08:39,000 --> 00:08:40,130
are the device manufacturers,

210
00:08:40,130 --> 00:08:41,929
is the hospital
disproportionately weighing it

211
00:08:41,929 --> 00:08:42,780
what's happening.

212
00:08:44,740 --> 00:08:47,370
- So you didn't mention HIPAA, no HITECH

213
00:08:47,370 --> 00:08:49,820
none of the laws, rules,
regulations, standards,

214
00:08:49,820 --> 00:08:51,870
out off those metrics that are going on,

215
00:08:51,870 --> 00:08:55,690
so how are you proposing
that we take lessons

216
00:08:55,690 --> 00:08:59,420
from ClinSeq into MedSeq?

217
00:08:59,420 --> 00:09:02,380
- [Vidya] This is exactly
where economy comes into play,

218
00:09:02,380 --> 00:09:03,230
so we talk about money

219
00:09:03,230 --> 00:09:05,140
because at the end of the
day these are businesses,

220
00:09:05,140 --> 00:09:08,199
the businesses will do what
their customers ask them to do.

221
00:09:08,200 --> 00:09:10,860
If they keep hearing it from
patients, from hospitals,

222
00:09:10,860 --> 00:09:13,730
from providers, from those
involved in this community

223
00:09:13,730 --> 00:09:15,750
to demonstrate that there
really is an interest

224
00:09:15,750 --> 00:09:17,970
in solving this, I think
that moves the needle.

225
00:09:17,970 --> 00:09:20,020
It's the same reason
IoT has failed really.

226
00:09:20,020 --> 00:09:22,280
Like IoT has it because
nobody's really advocating

227
00:09:22,280 --> 00:09:23,860
for your fridge to be more secure.

228
00:09:23,860 --> 00:09:26,090
They're not really thinking
about it from what the risks are

229
00:09:26,090 --> 00:09:28,010
you really have to have
people that are impacted

230
00:09:28,010 --> 00:09:29,360
by this speaking up for it.

231
00:09:32,070 --> 00:09:35,470
- So what can be the
regulators current state do?

232
00:09:35,470 --> 00:09:38,930
Because we are in the middle
of a pandemic in peril,

233
00:09:38,930 --> 00:09:40,053
things are happening,

234
00:09:40,898 --> 00:09:43,640
how do we get them to do more or better?

235
00:09:43,640 --> 00:09:47,560
- So I think our regulators
have to be given solutions.

236
00:09:47,560 --> 00:09:49,329
We can't tell them, hey
here are all the problems

237
00:09:49,330 --> 00:09:52,640
and why we're not able to
monitor our device in the field.

238
00:09:52,640 --> 00:09:54,069
I think we have to say, hey here's a way

239
00:09:54,070 --> 00:09:56,380
to work within our
complicated delivery system

240
00:09:56,380 --> 00:09:59,040
and there is a technology
that can make it easier.

241
00:09:59,040 --> 00:10:01,040
It doesn't require a person sitting there

242
00:10:01,040 --> 00:10:02,620
and pouring over logs

243
00:10:02,620 --> 00:10:05,010
that they're physically
going out to site to get.

244
00:10:05,010 --> 00:10:06,130
I think trying to solve this

245
00:10:06,130 --> 00:10:08,580
with human manpower is not feasible

246
00:10:08,580 --> 00:10:11,180
we have to leverage the
technology we have in place.

247
00:10:12,220 --> 00:10:13,770
- So have you ever been to any of my talks

248
00:10:13,770 --> 00:10:16,220
I always have the call to action.

249
00:10:16,220 --> 00:10:19,080
So from your talk, from
your knowledge base,

250
00:10:19,080 --> 00:10:21,680
from MedCrypt what is your call to action?

251
00:10:21,680 --> 00:10:23,229
- I think my call to action is different

252
00:10:23,230 --> 00:10:26,400
depending on who you are
but at the core of it

253
00:10:26,400 --> 00:10:29,370
I think understand that
cybersecurity is something that

254
00:10:29,370 --> 00:10:32,340
yes we are all communally responsible for

255
00:10:32,340 --> 00:10:34,110
but we can't keep blaming each other

256
00:10:34,110 --> 00:10:36,820
for having inadequately
enabled us to be successful

257
00:10:36,820 --> 00:10:38,590
like own your component of it,

258
00:10:38,590 --> 00:10:40,210
be clear about what your expectations are

259
00:10:40,210 --> 00:10:41,890
from whoever you're partnering with

260
00:10:41,890 --> 00:10:43,960
and help that partner
actually be successful

261
00:10:43,960 --> 00:10:45,200
if they don't know where to start

262
00:10:45,200 --> 00:10:46,360
point them in the right direction

263
00:10:46,360 --> 00:10:48,240
and say, we will not pursue in partnering

264
00:10:48,240 --> 00:10:50,083
until we see X demonstrated.

265
00:10:52,810 --> 00:10:54,719
- Is that contractual?

266
00:10:54,720 --> 00:10:55,560
- I think it can be.

267
00:10:55,560 --> 00:10:57,020
There's no reason why not to be,

268
00:10:57,020 --> 00:10:58,620
I mean I'm the warden MBA here,

269
00:10:58,620 --> 00:11:00,740
everything is driven by dollars and cents.

270
00:11:00,740 --> 00:11:03,770
So I think if for us to see change

271
00:11:03,770 --> 00:11:04,910
there's a lot that can be done

272
00:11:04,910 --> 00:11:07,160
from the business side of the house.

273
00:11:07,160 --> 00:11:10,699
- Then that said, most hospitals
work at a zero balance.

274
00:11:10,700 --> 00:11:15,090
How do we engage in them
in an economic function

275
00:11:15,090 --> 00:11:17,210
to be better and to do all of these things

276
00:11:17,210 --> 00:11:19,060
with the resources that they have?

277
00:11:19,060 --> 00:11:20,569
- Coming out of the year of the pandemic

278
00:11:20,570 --> 00:11:22,670
it's a very hard question to answer,

279
00:11:22,670 --> 00:11:23,839
there's gonna be a lot of losses,

280
00:11:23,840 --> 00:11:25,410
there's gonna be a lot of prioritization

281
00:11:25,410 --> 00:11:27,420
that's not going to be cybersecurity.

282
00:11:27,420 --> 00:11:30,800
But I think that if anything
demonstrates even further

283
00:11:30,800 --> 00:11:33,240
the hospital is not where
this money needs to be spent.

284
00:11:33,240 --> 00:11:34,690
We've tried the hospital strategy

285
00:11:34,690 --> 00:11:36,230
for more than 10 years now,

286
00:11:36,230 --> 00:11:38,000
have we made sufficient progress?

287
00:11:38,000 --> 00:11:40,860
I think there's a lot of
indicators that tell us we haven't.

288
00:11:40,860 --> 00:11:41,860
So maybe that means

289
00:11:41,860 --> 00:11:43,830
hospitals don't need to spend more money,

290
00:11:43,830 --> 00:11:44,880
they need to demand more

291
00:11:44,880 --> 00:11:46,780
of those that they're partnering with.

292
00:11:48,950 --> 00:11:51,890
- So I love when people
talk about business plans

293
00:11:51,890 --> 00:11:54,030
and remembered something else
that you brought up use cases,

294
00:11:54,030 --> 00:11:56,060
there I am a big fan of these things,

295
00:11:56,060 --> 00:11:57,459
but we have 30 seconds left.

296
00:11:57,460 --> 00:12:00,480
So on that note, how do you propose

297
00:12:00,480 --> 00:12:02,010
making use of these cases

298
00:12:02,010 --> 00:12:05,420
and business proposals, business plan?

299
00:12:05,420 --> 00:12:07,810
- So I think in today's state,

300
00:12:07,810 --> 00:12:10,810
so I think there is a
finite amount of buying

301
00:12:10,810 --> 00:12:11,959
that every hospital goes through.

302
00:12:11,960 --> 00:12:13,430
You can't say I wanna buy a new device

303
00:12:13,430 --> 00:12:16,250
just because you want to, but
there is a plan in most cases

304
00:12:16,250 --> 00:12:18,220
that they will have a
certain amount of spend,

305
00:12:18,220 --> 00:12:19,870
be intentional with that spend,

306
00:12:19,870 --> 00:12:21,960
don't go with the lowest
common denominator,

307
00:12:21,960 --> 00:12:24,470
expect more from your device manufacturers

308
00:12:24,470 --> 00:12:26,240
and you'll probably be
pleasantly surprised

309
00:12:26,240 --> 00:12:28,350
by options that are available
from these manufacturers

310
00:12:28,350 --> 00:12:31,100
that don't really shift the
economic spend requirement.

311
00:12:33,090 --> 00:12:35,410
- Perfect, thank you Vidya.

312
00:12:35,410 --> 00:12:39,110
So next stop we have Mr. Caleb Barlow

313
00:12:39,110 --> 00:12:40,157
and he is going to talk about

314
00:12:40,157 --> 00:12:44,920
the pandemic and peril
of DNA data collection

315
00:12:44,920 --> 00:12:49,750
and I am putting seven
minutes on the clock, go.

316
00:12:49,750 --> 00:12:51,620
- Since the fifth century BC

317
00:12:51,620 --> 00:12:53,820
the Hippocratic Oath has
governed the relationship

318
00:12:53,820 --> 00:12:55,390
between patients and their physicians.

319
00:12:55,390 --> 00:12:58,010
Now, this oath is a promise for a doctor

320
00:12:58,010 --> 00:12:59,390
to uphold the art of medicine

321
00:12:59,390 --> 00:13:01,240
and act in their patient's best interests.

322
00:13:01,240 --> 00:13:03,590
But as the world has become more digital

323
00:13:03,590 --> 00:13:06,500
cracks in this promise
are starting to emerge

324
00:13:06,500 --> 00:13:09,440
but those fissures are not
with a medical procedure

325
00:13:09,440 --> 00:13:11,940
or a drug they're with investment,

326
00:13:11,940 --> 00:13:13,470
the carer and the approach

327
00:13:13,470 --> 00:13:15,930
the clinicians and medical practices make

328
00:13:15,930 --> 00:13:18,859
in securing patient's data, our data.

329
00:13:18,860 --> 00:13:21,250
You see healthcare data
is now a whole lot more

330
00:13:21,250 --> 00:13:24,320
than our prescriptions, ailment
and psychological history.

331
00:13:24,320 --> 00:13:25,860
It might now include fitness data,

332
00:13:25,860 --> 00:13:29,530
location data from applications,
and COVID tracing data.

333
00:13:29,530 --> 00:13:33,709
That includes information
on who we associate with

334
00:13:33,710 --> 00:13:36,950
not just where we've been,
but who we hang out with.

335
00:13:36,950 --> 00:13:39,120
Now that's got family and friends in it

336
00:13:39,120 --> 00:13:42,290
but also lovers, teachers, drug dealers.

337
00:13:42,290 --> 00:13:44,560
It's what we call immutable data.

338
00:13:44,560 --> 00:13:46,130
And unlike our credit card number

339
00:13:46,130 --> 00:13:50,320
if we lose our healthcare
data, we cannot change it.

340
00:13:50,320 --> 00:13:53,680
Our medical history, whether
a life-threatening allergy

341
00:13:53,680 --> 00:13:57,069
a propensity for addiction
or a high risk for disease.

342
00:13:57,070 --> 00:14:00,530
These are things that are
with us well for a lifetime.

343
00:14:00,530 --> 00:14:04,260
Now, since 2009 it's
estimated that over 80%

344
00:14:04,260 --> 00:14:07,380
of the US population has
lost their healthcare records

345
00:14:07,380 --> 00:14:10,350
either lost, stolen or
impermissibly disclosed.

346
00:14:10,350 --> 00:14:12,090
But this gets even more interesting

347
00:14:12,090 --> 00:14:15,610
when we start to look
at DNA sequencing data

348
00:14:15,610 --> 00:14:18,170
because the bad guys aren't stealing it

349
00:14:18,170 --> 00:14:19,689
like they usually do.

350
00:14:19,690 --> 00:14:21,960
People are giving it to them freely

351
00:14:21,960 --> 00:14:24,910
through legitimate
companies that nation states

352
00:14:24,910 --> 00:14:27,329
have actually invested it.

353
00:14:27,330 --> 00:14:29,020
Now the first thing we've got to recognize

354
00:14:29,020 --> 00:14:33,490
is our DNA is unique only to
you and to your identical twin.

355
00:14:33,490 --> 00:14:36,170
And it holds the most
intimate details of the past,

356
00:14:36,170 --> 00:14:39,870
the present and the future
for both you personally

357
00:14:39,870 --> 00:14:43,530
and the people you're
immediately related to,

358
00:14:43,530 --> 00:14:47,660
even your close relatives
that aren't even born yet.

359
00:14:47,660 --> 00:14:50,480
Now DNA data can be used
for medical research,

360
00:14:50,480 --> 00:14:51,980
genealogical study

361
00:14:51,980 --> 00:14:54,180
or even for determining
if you're at a high risk

362
00:14:54,180 --> 00:14:56,040
for a life-threatening disease.

363
00:14:56,040 --> 00:14:58,319
Research has even underway
working on things like

364
00:14:58,320 --> 00:15:02,470
reconstructing what a face
might look like from the DNA

365
00:15:02,470 --> 00:15:03,800
and what do you need to do it?

366
00:15:03,800 --> 00:15:06,099
Well, just enough DNA.

367
00:15:06,100 --> 00:15:09,490
But DNA can also be used for
more questionable purposes

368
00:15:09,490 --> 00:15:13,050
like things like targeted bio-weapons.

369
00:15:13,050 --> 00:15:15,729
Now this is a tough thing to rationalize

370
00:15:15,730 --> 00:15:20,120
but future forms of genocide,
future forms of discrimination

371
00:15:20,120 --> 00:15:23,730
are likely to be based on
the data within your genome.

372
00:15:23,730 --> 00:15:26,460
Now people freely give their
up their DNA for testing

373
00:15:26,460 --> 00:15:29,840
to understand there ancestry lineage

374
00:15:29,840 --> 00:15:31,900
and have a connection with their past

375
00:15:31,900 --> 00:15:34,470
or relatives they may have never met.

376
00:15:34,470 --> 00:15:36,370
The challenge however,

377
00:15:36,370 --> 00:15:39,740
is we have no concept
of who owns your DNA,

378
00:15:39,740 --> 00:15:42,450
who owns that scan of your face,

379
00:15:42,450 --> 00:15:46,590
who determines how this
can and should be used.

380
00:15:46,590 --> 00:15:49,220
What's worse is nation state actors

381
00:15:49,220 --> 00:15:52,670
are actively trying to
assemble this information.

382
00:15:52,670 --> 00:15:54,620
They steal our healthcare records,

383
00:15:54,620 --> 00:15:58,100
they invest in businesses
that do genomic sequencing

384
00:15:58,100 --> 00:15:59,780
and there's very little regulation

385
00:15:59,780 --> 00:16:02,490
on what country in which
this sequencing occurs

386
00:16:02,490 --> 00:16:07,040
or how it might be used even
generations into the future.

387
00:16:07,040 --> 00:16:10,180
And the thing with DNA is it
really can't be de-anonymized,

388
00:16:10,180 --> 00:16:12,870
in fact by searching in one of any number

389
00:16:12,870 --> 00:16:14,970
of genealogical databases

390
00:16:14,970 --> 00:16:17,400
all I need to do is find a close relative

391
00:16:17,400 --> 00:16:21,260
and I can de-anonymize the
data enough to identify you

392
00:16:21,260 --> 00:16:24,080
through a close match
to one of your cousins,

393
00:16:24,080 --> 00:16:28,950
but it's not all stealing data,
sometimes they just buy it.

394
00:16:28,950 --> 00:16:31,810
FBI agent Ed You has
been warning for years

395
00:16:31,810 --> 00:16:34,119
about investments that Chinese entities

396
00:16:34,120 --> 00:16:37,080
are making in the field
of genomic sequencing.

397
00:16:37,080 --> 00:16:39,250
Now China has gained significant access

398
00:16:39,250 --> 00:16:42,820
to Western genomic data
and biological samples

399
00:16:42,820 --> 00:16:46,150
through research
partnerships, investments,

400
00:16:46,150 --> 00:16:47,890
mergers and acquisitions.

401
00:16:47,890 --> 00:16:52,890
This includes US accreditations,
work with many US hospitals

402
00:16:53,300 --> 00:16:56,370
and even investment in 23andMe.

403
00:16:56,370 --> 00:17:00,290
Point is if you're going
to do genomic sequencing

404
00:17:00,290 --> 00:17:02,839
there is a very good
chance that the equipment,

405
00:17:02,840 --> 00:17:06,040
the laboratory or the
foundational research

406
00:17:06,040 --> 00:17:09,740
or the companies involved
have a Chinese access.

407
00:17:09,740 --> 00:17:12,700
So let me give you a bit of
a case study, BGI Genomics.

408
00:17:12,700 --> 00:17:17,630
Now BGI is the Chinese
genomic sequencing powerhouse,

409
00:17:17,630 --> 00:17:21,329
they were offering COVID-19
testing capabilities globally,

410
00:17:21,329 --> 00:17:22,470
they solely gave away

411
00:17:22,470 --> 00:17:25,430
35 million rapid COVID-19 testing kits,

412
00:17:25,430 --> 00:17:27,500
they were sold in 180 countries.

413
00:17:27,500 --> 00:17:30,170
They even been built 58
COVID testing laboratories

414
00:17:30,170 --> 00:17:31,810
in 18 countries.

415
00:17:31,810 --> 00:17:36,360
But in addition to the
tests and laboratories

416
00:17:36,360 --> 00:17:39,010
they were also requesting that researchers

417
00:17:39,010 --> 00:17:40,450
using their equipment,

418
00:17:40,450 --> 00:17:43,320
send the data generated on their equipment

419
00:17:43,320 --> 00:17:45,580
as well as the patient's samples,

420
00:17:45,580 --> 00:17:47,370
so they could be sequenced and shared

421
00:17:47,370 --> 00:17:50,459
in China's government funded GeneBank.

422
00:17:50,460 --> 00:17:54,550
Now for storing this data,
BGI had a partnership

423
00:17:54,550 --> 00:17:58,200
with a company you may have
heard of before, Huawei.

424
00:17:58,200 --> 00:18:01,300
So this data was then
stored in a Huawei cloud.

425
00:18:01,300 --> 00:18:04,860
Again, this is legitimate,
above-board work

426
00:18:04,860 --> 00:18:06,889
but it does raise some questions

427
00:18:06,890 --> 00:18:09,630
including even a warning in February, 2020

428
00:18:09,630 --> 00:18:12,240
from the National Counterintelligence
and Security Center

429
00:18:12,240 --> 00:18:15,640
which resulted in a whole
flurry of media reports

430
00:18:15,640 --> 00:18:16,960
including coverage in Reuters,

431
00:18:16,960 --> 00:18:19,130
60 Minutes, The Hill and many others.

432
00:18:19,130 --> 00:18:22,250
So my point here is we
need to think differently.

433
00:18:22,250 --> 00:18:25,380
The security posture of your private data

434
00:18:25,380 --> 00:18:28,000
is as important as your pulse,

435
00:18:28,000 --> 00:18:30,200
your cholesterol level and your weight.

436
00:18:30,200 --> 00:18:32,280
And it's time for medical practitioners

437
00:18:32,280 --> 00:18:34,200
to start to realize this.

438
00:18:34,200 --> 00:18:37,620
More than anyone else we trust our doctors

439
00:18:37,620 --> 00:18:40,510
for advice, for diagnosis, for our health.

440
00:18:40,510 --> 00:18:44,110
We're at the point where
a bad password policy,

441
00:18:44,110 --> 00:18:46,360
poor storage of our genomic history

442
00:18:46,360 --> 00:18:50,510
can have an as adverse event
effect and impact on our lives

443
00:18:50,510 --> 00:18:52,940
as let's say living with high cholesterol.

444
00:18:52,940 --> 00:18:56,550
We must treat patient data differently.

445
00:18:56,550 --> 00:18:58,260
It's part of your health

446
00:18:58,260 --> 00:19:01,800
and if your data isn't
healthily, you are not healthy.

447
00:19:01,800 --> 00:19:04,050
Thank you, I'm Caleb
Barlow from CynergisTek.

448
00:19:06,350 --> 00:19:08,409
- I am so ready for this
because this is legit

449
00:19:08,410 --> 00:19:09,580
so much of my talk.

450
00:19:09,580 --> 00:19:13,350
So, I have notes, you talked
about the Hippocratic Oath

451
00:19:13,350 --> 00:19:15,639
and there's a paper out there,

452
00:19:15,640 --> 00:19:18,510
it was started by a couple of the folks

453
00:19:18,510 --> 00:19:19,629
from the I and the cavalry

454
00:19:19,630 --> 00:19:23,530
and what's the last lines
on there is my quote of

455
00:19:23,530 --> 00:19:25,480
but shouldn't the
hospitals also have to take

456
00:19:25,480 --> 00:19:27,650
the Hippocratic Oath for hospitals

457
00:19:27,650 --> 00:19:29,670
and then at the Biohacking Village,

458
00:19:29,670 --> 00:19:31,700
one of the things that we
do at the device line base

459
00:19:31,700 --> 00:19:33,680
we have a Hippocratic Oath for hackers

460
00:19:33,680 --> 00:19:34,640
where if they find something

461
00:19:34,640 --> 00:19:36,380
they automatically have to report it back.

462
00:19:36,380 --> 00:19:39,390
So do you have any thoughts,
feelings about that so far?

463
00:19:39,390 --> 00:19:41,480
- I mean here's two
things to keep in mind,

464
00:19:41,480 --> 00:19:43,820
it's not that hospitals
aren't investing in security,

465
00:19:43,820 --> 00:19:46,139
they are, they're just
not investing fast enough.

466
00:19:46,140 --> 00:19:49,610
In fact, 66% of America's hospitals

467
00:19:49,610 --> 00:19:52,129
cannot meet a level three on a NIST Score

468
00:19:52,130 --> 00:19:55,620
that is utterly unacceptable.

469
00:19:55,620 --> 00:20:00,620
66%, so they have the data,
they're highly vulnerable

470
00:20:00,730 --> 00:20:03,290
and the investments need to catch up

471
00:20:03,290 --> 00:20:04,690
with where the bad guys are.

472
00:20:07,300 --> 00:20:08,133
- [Interviewer] So the other thing

473
00:20:08,133 --> 00:20:09,460
that I push like constantly

474
00:20:09,460 --> 00:20:11,980
is who owns the data if
you go into the hospital.

475
00:20:11,980 --> 00:20:14,460
If I take a blood test that
blood is technically still mine

476
00:20:14,460 --> 00:20:16,500
but there it is in the
possession of the hospital.

477
00:20:16,500 --> 00:20:17,515
So where in line...

478
00:20:17,515 --> 00:20:18,610
- But the data isn't necessarily yours

479
00:20:18,610 --> 00:20:22,669
and in fact, if a lot of
folks may not be aware

480
00:20:22,670 --> 00:20:24,630
of a concept called interoperability.

481
00:20:24,630 --> 00:20:29,510
Now, remember one of the
aspects in HIPAA is portability.

482
00:20:29,510 --> 00:20:33,290
Now portability in this
case originally meant

483
00:20:33,290 --> 00:20:35,409
portability between insurance carriers

484
00:20:35,410 --> 00:20:39,210
but you can actually request now access

485
00:20:39,210 --> 00:20:43,410
to patient's healthcare
records for doing research,

486
00:20:43,410 --> 00:20:46,900
and the healthcare institutions

487
00:20:46,900 --> 00:20:50,320
cannot deny that access for data

488
00:20:50,320 --> 00:20:52,770
unless there are legitimate
reasons to deny it

489
00:20:52,770 --> 00:20:54,620
for the purposes of research,

490
00:20:54,620 --> 00:20:57,439
or let's say I've got a fitness app

491
00:20:57,440 --> 00:20:59,680
that I wanna connect to
my healthcare record.

492
00:20:59,680 --> 00:21:02,210
They pretty much have
to allow that nowadays

493
00:21:02,210 --> 00:21:04,610
except for a very small list of criteria

494
00:21:04,610 --> 00:21:05,990
in which they can deny it.

495
00:21:05,990 --> 00:21:08,080
So the problem here is,

496
00:21:08,080 --> 00:21:11,439
because of the desire
to help the public good,

497
00:21:11,440 --> 00:21:14,960
because of the desire to
make healthcare electronic,

498
00:21:14,960 --> 00:21:17,380
what we've done inadvertently

499
00:21:17,380 --> 00:21:19,570
is we've made it easier for bad guys

500
00:21:19,570 --> 00:21:20,899
to get access to this data.

501
00:21:20,900 --> 00:21:23,060
Frankly I'm just waiting for a bad guy

502
00:21:23,060 --> 00:21:25,210
to go set up a research institution

503
00:21:25,210 --> 00:21:27,870
and request access through the
interoperability standards,

504
00:21:27,870 --> 00:21:28,783
why steal it?

505
00:21:31,580 --> 00:21:33,572
- [Interviewer] So being with that said

506
00:21:33,573 --> 00:21:35,154
do you have any feelings about FHIR

507
00:21:35,154 --> 00:21:36,515
because I have other questions

508
00:21:36,515 --> 00:21:38,584
about asymmetric warfare for you.

509
00:21:38,584 --> 00:21:41,757
- Do I have any questions about what?

510
00:21:41,757 --> 00:21:45,594
- [Interviewer] Do you have
any feelings about FHIR F-H-I-R

511
00:21:45,594 --> 00:21:48,160
the interoperability of next standard?

512
00:21:48,160 --> 00:21:51,530
- You know I actually don't
at this point it's so early on

513
00:21:51,530 --> 00:21:54,910
that I think we're all kinda
looking at where is this going

514
00:21:54,910 --> 00:21:57,200
and more importantly
getting our arms around,

515
00:21:57,200 --> 00:21:58,583
what's already legislated.

516
00:22:00,480 --> 00:22:01,670
- So you were talking about

517
00:22:01,670 --> 00:22:04,430
targeted parts of healthcare before

518
00:22:04,430 --> 00:22:09,430
and I've been in the military
and I do government stuff.

519
00:22:09,440 --> 00:22:11,470
So I consider healthcare

520
00:22:11,470 --> 00:22:13,750
to be an asymmetric piece of warfare,

521
00:22:13,750 --> 00:22:15,840
and there's a lot of pushback on that

522
00:22:15,840 --> 00:22:17,370
whenever I have those conversations,

523
00:22:17,370 --> 00:22:19,120
because there's so much belief that

524
00:22:20,190 --> 00:22:22,670
warfare should only be kinetic

525
00:22:22,670 --> 00:22:25,000
where right now we are in
the middle of the warfare

526
00:22:25,000 --> 00:22:26,020
because of healthcare.

527
00:22:26,020 --> 00:22:28,014
So what are your thoughts
on the Hippocratic Oath?

528
00:22:28,014 --> 00:22:29,570
- Well I'll actually
take it a step further.

529
00:22:29,570 --> 00:22:31,159
I think if you look at what's going on

530
00:22:31,160 --> 00:22:32,490
in America's hospitals right now

531
00:22:32,490 --> 00:22:35,510
it is the bridge between
cyber and kinetic warfare.

532
00:22:35,510 --> 00:22:38,310
In that in November of last year

533
00:22:38,310 --> 00:22:41,220
a dozen hospitals went down

534
00:22:41,220 --> 00:22:43,700
after there was an attempted take-down

535
00:22:43,700 --> 00:22:45,420
of the TrickBot botnet.

536
00:22:45,420 --> 00:22:47,460
Now I don't know if that
was retaliatory or not

537
00:22:47,460 --> 00:22:50,170
but the timing sure is
how it looks like it was.

538
00:22:50,170 --> 00:22:54,430
The fact that an adversary
can knowingly knowingly

539
00:22:54,430 --> 00:22:57,360
with intent to not just
take down a hospital

540
00:22:57,360 --> 00:23:00,080
but take down entire systems.

541
00:23:00,080 --> 00:23:03,622
I don't know what else you call
that if not kinetic warfare.

542
00:23:05,810 --> 00:23:07,730
Now the difference in this case though,

543
00:23:07,730 --> 00:23:11,810
is your adversary we
view them as criminals

544
00:23:11,810 --> 00:23:13,230
as ransomware operators

545
00:23:13,230 --> 00:23:15,370
'cause there may be state associated

546
00:23:15,370 --> 00:23:19,129
but we need a new definition
of who these folks are

547
00:23:19,130 --> 00:23:21,400
because they're not traditional criminals

548
00:23:21,400 --> 00:23:23,980
if we can't bring them to
court in law enforcement,

549
00:23:23,980 --> 00:23:26,610
they're also not traditional terrorists

550
00:23:26,610 --> 00:23:28,510
but there's something in between

551
00:23:28,510 --> 00:23:30,780
and we've got to think
about a new definition

552
00:23:30,780 --> 00:23:32,973
and an associated proportional response.

553
00:23:35,100 --> 00:23:35,933
- [Interviewer] I love that

554
00:23:35,933 --> 00:23:37,090
and I think they're actually working

555
00:23:37,090 --> 00:23:39,721
on something very similar in that vail.

556
00:23:39,721 --> 00:23:41,490
I have 10 seconds left with you,

557
00:23:41,490 --> 00:23:42,890
what is your call to action?

558
00:23:43,730 --> 00:23:46,080
- Look my call to action
at end of the day,

559
00:23:46,080 --> 00:23:49,939
get a security assessment and
start to actually go beyond it

560
00:23:49,940 --> 00:23:53,110
and validate your security
posture if you're in healthcare.

561
00:23:53,110 --> 00:23:56,320
Because if you're not
keeping up with the bad guys

562
00:23:56,320 --> 00:23:59,620
you're falling behind and now
it can have a kinetic impact

563
00:23:59,620 --> 00:24:02,419
on your organization and your
ability to treat patients.

564
00:24:03,540 --> 00:24:05,980
- [Interviewer] Very good and
I'm gonna segue this perfectly

565
00:24:05,980 --> 00:24:07,870
because you talked about
disinformation a little bit

566
00:24:07,870 --> 00:24:10,860
and Sharka is going to talk about

567
00:24:12,580 --> 00:24:14,300
misinformation and disinformation

568
00:24:14,300 --> 00:24:16,000
in the times of the pandemic.

569
00:24:16,000 --> 00:24:19,533
So Sharka seven minutes on the clock, go.

570
00:24:21,110 --> 00:24:26,110
- So I come from sort of
social engineering background,

571
00:24:26,130 --> 00:24:28,910
but misinformation, disinformation

572
00:24:28,910 --> 00:24:31,290
is something that I've
been speaking about a lot

573
00:24:31,290 --> 00:24:34,639
because it's actually something
that has a huge impact

574
00:24:34,640 --> 00:24:36,150
and it could save life

575
00:24:37,299 --> 00:24:40,670
if you want to see it
from that perspective.

576
00:24:40,670 --> 00:24:44,210
So I will now tell you
about the infodemic.

577
00:24:44,210 --> 00:24:45,850
What is infodemic?

578
00:24:45,850 --> 00:24:50,360
It's actually been defined
by World Health Organization

579
00:24:50,360 --> 00:24:52,899
as an overabundance of information,

580
00:24:52,900 --> 00:24:56,530
some accurate, some not that
makes it harder for people

581
00:24:56,530 --> 00:24:58,610
to find trustworthy sources

582
00:24:58,610 --> 00:25:01,399
and reliable guidance when needed.

583
00:25:01,400 --> 00:25:03,750
I think it's important here to mention

584
00:25:04,810 --> 00:25:08,710
the difference between
disinformation and misinformation.

585
00:25:08,710 --> 00:25:13,020
Disinformation it's on purpose
wrong incorrect information

586
00:25:13,020 --> 00:25:18,020
while misinformation is unwittingly
let's shared information

587
00:25:18,340 --> 00:25:21,379
that's the difference it's
in that intent, right?

588
00:25:21,380 --> 00:25:24,670
So where we are right now

589
00:25:24,670 --> 00:25:27,140
or what is it that we can actually see.

590
00:25:27,140 --> 00:25:29,529
This is actually a research that was done.

591
00:25:29,529 --> 00:25:32,020
So there was a research that was published

592
00:25:32,020 --> 00:25:36,550
by the American Journal of
Tropical Medicine and Hygiene

593
00:25:36,550 --> 00:25:38,550
that said that in the first three months

594
00:25:38,550 --> 00:25:41,260
of the pandemic at least 800 people

595
00:25:41,260 --> 00:25:43,360
may have died around the world

596
00:25:43,360 --> 00:25:47,270
because of the coronavirus
related misinformation,

597
00:25:47,270 --> 00:25:50,820
let that sink, and that's
only first three months.

598
00:25:50,820 --> 00:25:52,639
And obviously that was only

599
00:25:52,640 --> 00:25:57,183
specific misinformation
campaigns that were followed.

600
00:25:58,240 --> 00:26:02,290
Another case what we are actually seeing

601
00:26:02,290 --> 00:26:05,200
it's all these that were
injured, hospitalized

602
00:26:05,200 --> 00:26:08,300
or actually died as a
result of raising racist

603
00:26:08,300 --> 00:26:11,730
and xenophobic violence and discrimination

604
00:26:11,730 --> 00:26:14,950
linked to the coronavirus
misinformation and disinformation.

605
00:26:14,950 --> 00:26:19,500
Again, this is something that
you could see that so clearly

606
00:26:21,530 --> 00:26:24,760
in the world and it's linked to the wrong

607
00:26:24,760 --> 00:26:27,400
and incorrect information
that's being shared

608
00:26:27,400 --> 00:26:29,560
either intentionally or not.

609
00:26:29,560 --> 00:26:33,423
So what is it that we can do?

610
00:26:34,980 --> 00:26:39,410
Let's flatten the infodemic
curve and what I mean by that?

611
00:26:39,410 --> 00:26:41,730
There are simple, well simple,

612
00:26:41,730 --> 00:26:43,600
there are at least seven steps

613
00:26:44,460 --> 00:26:47,470
from what the World Health
Organization is saying.

614
00:26:47,470 --> 00:26:51,500
So as the source

615
00:26:51,500 --> 00:26:54,160
you need to understand
where does it come from?

616
00:26:54,160 --> 00:26:56,110
Are you the person that is trying to share

617
00:26:56,110 --> 00:26:58,330
some piece of information?

618
00:26:58,330 --> 00:27:02,120
Do you know who is the person
that you're sharing it from?

619
00:27:02,120 --> 00:27:03,830
Who is the person that...

620
00:27:04,670 --> 00:27:06,420
How well do you know them?

621
00:27:06,420 --> 00:27:11,130
What's their maybe history of sharing

622
00:27:12,006 --> 00:27:13,970
other pieces of information?

623
00:27:13,970 --> 00:27:17,090
The second one is go beyond the headline.

624
00:27:17,090 --> 00:27:21,379
Actually sometimes going
through the actual article

625
00:27:21,380 --> 00:27:23,470
makes you understand little bit better

626
00:27:23,470 --> 00:27:25,430
because lots of articles are written

627
00:27:25,430 --> 00:27:29,483
in the way for you to have a reaction,

628
00:27:30,995 --> 00:27:33,610
lots of people are
sharing just for the likes

629
00:27:33,610 --> 00:27:35,580
and that can be dangerous

630
00:27:35,580 --> 00:27:37,993
and not only in a pandemic obviously.

631
00:27:39,280 --> 00:27:40,113
Identify the author,

632
00:27:40,113 --> 00:27:45,113
have a look is the author
a renown journalist?

633
00:27:45,220 --> 00:27:49,683
Is that person actually
sharing their sources?

634
00:27:50,530 --> 00:27:54,040
Are they linking to a another research?

635
00:27:54,040 --> 00:27:56,620
That all could tell you
or point you towards

636
00:27:56,620 --> 00:27:59,562
it being perhaps incorrect information.

637
00:28:00,670 --> 00:28:02,090
Check the data,

638
00:28:02,090 --> 00:28:06,659
so again, that's going to the resources

639
00:28:06,660 --> 00:28:11,660
and the authors and all the
research that's been done

640
00:28:12,310 --> 00:28:14,800
around this specific topic.

641
00:28:14,800 --> 00:28:18,649
Do you feel like the information
that's being represented

642
00:28:18,650 --> 00:28:22,393
was well researched in their actual data.

643
00:28:23,380 --> 00:28:25,940
Date is another part of this.

644
00:28:25,940 --> 00:28:29,180
We've been seeing this with images.

645
00:28:29,180 --> 00:28:32,620
So sometimes some journalists
are putting images

646
00:28:32,620 --> 00:28:36,159
that are not relevant to the
actual piece of information

647
00:28:36,160 --> 00:28:37,563
so that's another part.

648
00:28:38,420 --> 00:28:41,020
Examine the supporting evidence.

649
00:28:41,020 --> 00:28:46,020
So again perhaps is the medium
where you're reading it from,

650
00:28:46,990 --> 00:28:51,990
or you're trying to share,
is their affiliation

651
00:28:52,140 --> 00:28:54,340
perhaps political to certain side?

652
00:28:54,340 --> 00:28:58,580
well you need to understand
where is this coming from,

653
00:28:58,580 --> 00:29:00,230
when it's trying to inform you

654
00:29:00,230 --> 00:29:01,943
about something in a certain way.

655
00:29:02,950 --> 00:29:04,040
Check your biases.

656
00:29:04,040 --> 00:29:06,070
This is little bit tricky obviously

657
00:29:06,070 --> 00:29:10,100
because we need to look at
ourselves and how we think

658
00:29:10,100 --> 00:29:12,290
and what might be some of the things

659
00:29:12,290 --> 00:29:14,040
or actions that we are doing.

660
00:29:14,040 --> 00:29:16,649
But what's the better the
time to do it than now

661
00:29:16,650 --> 00:29:18,853
when it could actually save lives.

662
00:29:20,040 --> 00:29:22,810
Then the last one is
turned to fact checkers.

663
00:29:22,810 --> 00:29:25,760
So there I think that we're
seeing it more and more

664
00:29:25,760 --> 00:29:30,410
on social media, but there
are actually specific websites

665
00:29:30,410 --> 00:29:32,893
where you can go to check facts.

666
00:29:34,390 --> 00:29:37,810
If you find let's say you're on Facebook

667
00:29:37,810 --> 00:29:41,419
and you find that this
article is not correct,

668
00:29:41,420 --> 00:29:43,040
you can report it.

669
00:29:43,040 --> 00:29:47,857
So you can do a little bit of
of flattening the infodemic.

670
00:29:49,500 --> 00:29:54,170
And how it looks like,
here you can actually see,

671
00:29:54,170 --> 00:29:56,240
this is sort of a good representation.

672
00:29:56,240 --> 00:29:59,530
So let's say first is a group chat

673
00:29:59,530 --> 00:30:03,470
that one person may be was
not part of the group chat

674
00:30:03,470 --> 00:30:07,460
or didn't decided that
it's perhaps just a rumor.

675
00:30:07,460 --> 00:30:09,680
So then we go to the next part

676
00:30:09,680 --> 00:30:13,340
where people are actually
looking at sources

677
00:30:14,210 --> 00:30:16,650
and decide that it's
not trustworthy source

678
00:30:16,650 --> 00:30:19,870
and the other person
checked some of the facts.

679
00:30:19,870 --> 00:30:23,719
Then it could be someone
who just asked themselves

680
00:30:23,720 --> 00:30:26,400
how do you know that it's true

681
00:30:26,400 --> 00:30:31,080
and it's sort of cascading
this way in the end

682
00:30:31,080 --> 00:30:34,423
flattening the infodemic curve hopefully.

683
00:30:36,600 --> 00:30:40,053
And that is me I finished ahead of time.

684
00:30:42,830 --> 00:30:43,949
- [Interviewer] You have 40 seconds,

685
00:30:43,950 --> 00:30:46,290
do you wanna say anything else?

686
00:30:46,290 --> 00:30:47,930
- I think that it was short and sweet

687
00:30:47,930 --> 00:30:49,830
and said everything that I needed to,

688
00:30:49,830 --> 00:30:51,393
hit me with your questions.

689
00:30:54,272 --> 00:30:58,189
- So how can healthcare stay ahead

690
00:30:58,190 --> 00:31:01,620
of the dismiss-information?

691
00:31:01,620 --> 00:31:04,056
The pandemic has shown the lack of trust

692
00:31:04,057 --> 00:31:05,570
and or understanding of science

693
00:31:05,570 --> 00:31:07,639
so how do we get back to that place

694
00:31:07,640 --> 00:31:10,340
of having a normalized conversation

695
00:31:10,340 --> 00:31:12,372
about all of these things?

696
00:31:14,510 --> 00:31:18,290
- So, one thing it's the fact

697
00:31:18,290 --> 00:31:19,760
that you're mentioning the trust

698
00:31:19,760 --> 00:31:22,000
I would say that we need to teach

699
00:31:22,000 --> 00:31:25,710
actually people not to blindly trust

700
00:31:25,710 --> 00:31:29,150
and recognize that maybe everything

701
00:31:29,150 --> 00:31:31,380
that's what I teach in
a social engineering,

702
00:31:31,380 --> 00:31:33,810
everything that you're seeing or hearing

703
00:31:33,810 --> 00:31:35,352
it's perhaps not the reality.

704
00:31:36,220 --> 00:31:39,780
Let people start to think outside the box.

705
00:31:39,780 --> 00:31:42,080
So what they are hearing and seeing

706
00:31:42,080 --> 00:31:45,703
it's perhaps something that
they need to think about.

707
00:31:46,610 --> 00:31:50,550
There was actually a study
that was asking people

708
00:31:50,550 --> 00:31:54,690
if they think that the
headline is accurate

709
00:31:54,690 --> 00:31:59,380
for the article itself and
people were three times

710
00:31:59,380 --> 00:32:02,070
more likely to spot misinformation

711
00:32:02,070 --> 00:32:05,020
if they were asked this question.

712
00:32:05,020 --> 00:32:09,767
So it's to teach people how
to think outside the box

713
00:32:10,650 --> 00:32:13,370
and maybe lose the trust

714
00:32:13,370 --> 00:32:17,783
but build a trust in themselves
in their own judgment.

715
00:32:21,480 --> 00:32:24,190
- [Interviewer] How can the
healthcare industry itself

716
00:32:24,190 --> 00:32:26,627
better influence media

717
00:32:26,627 --> 00:32:28,726
and the messages that are going out there.

718
00:32:29,980 --> 00:32:34,970
- So I think it's infodemic
is as the pandemic.

719
00:32:34,970 --> 00:32:36,610
So we need to treat it as such.

720
00:32:36,610 --> 00:32:40,832
So we need to understand
the virus, how to treat it?

721
00:32:41,826 --> 00:32:45,220
I think part of it would be to...

722
00:32:45,220 --> 00:32:48,820
I think it's what we are trying
to do at Biohacking Village,

723
00:32:48,820 --> 00:32:53,149
to have the hackers work
hand in hand with healthcare

724
00:32:53,150 --> 00:32:55,030
and medical device makers.

725
00:32:55,030 --> 00:32:59,410
But it's also use more of tools such as

726
00:32:59,410 --> 00:33:02,070
I'm a big fan of Benford's law,

727
00:33:02,070 --> 00:33:04,520
which is sort of a anomaly detection.

728
00:33:04,520 --> 00:33:09,520
So there is so much of how
we can detect misinformation

729
00:33:09,650 --> 00:33:12,640
because lots of it in
order to spread really fast

730
00:33:12,640 --> 00:33:17,290
is just bots and this
is quite easily done by,

731
00:33:17,290 --> 00:33:19,600
for example the Benford's law.

732
00:33:19,600 --> 00:33:22,709
And then obviously there
has to be regulation

733
00:33:22,710 --> 00:33:27,350
of all of this, and that goes
into laws and regulations

734
00:33:27,350 --> 00:33:30,709
and I think people should
be held accountable.

735
00:33:30,710 --> 00:33:34,950
So are you a doctor that
spreading misinformation

736
00:33:34,950 --> 00:33:37,700
you should be held accountable for this

737
00:33:39,720 --> 00:33:41,570
but it goes also back to,

738
00:33:41,570 --> 00:33:44,919
I think that what you and Caleb mentioned

739
00:33:44,920 --> 00:33:47,350
is tallying manual.

740
00:33:47,350 --> 00:33:52,350
So that goes back to cyber warfare,

741
00:33:54,470 --> 00:33:57,920
but I am sort of missing
the healthcare part of it

742
00:33:57,920 --> 00:34:02,920
and while we are quite far
away from it being implemented

743
00:34:03,210 --> 00:34:06,630
I think it's what we
seeing during the pandemic

744
00:34:06,630 --> 00:34:11,360
is a scary scenario
that didn't go too bad,

745
00:34:13,360 --> 00:34:15,783
but we should be thinking ahead of time.

746
00:34:19,820 --> 00:34:22,500
- [Interviewer] So how do we
create better adaptability

747
00:34:22,500 --> 00:34:25,150
for both the healthcare industry

748
00:34:25,150 --> 00:34:27,450
and for the patients
that are in the industry.

749
00:34:29,420 --> 00:34:31,113
- Adaptability to what?

750
00:34:32,469 --> 00:34:35,259
- [Interviewer] To better
understanding the message

751
00:34:35,260 --> 00:34:38,550
and being able to pivot easier off of,

752
00:34:38,550 --> 00:34:40,370
I know this isn't right,
I know this isn't real,

753
00:34:40,370 --> 00:34:41,569
I can move away from it.

754
00:34:42,670 --> 00:34:46,949
- So I think it's partially
who are the people

755
00:34:46,949 --> 00:34:48,699
that are most vulnerable.

756
00:34:48,699 --> 00:34:51,199
It would be people that are older

757
00:34:52,130 --> 00:34:55,070
that are usually lacking
the social media literacy.

758
00:34:55,070 --> 00:34:56,890
So it's teaching them socially

759
00:34:57,881 --> 00:35:02,881
and they are also those that
ended up being perhaps victims.

760
00:35:04,510 --> 00:35:08,510
So it's social media literacy
together with health literacy

761
00:35:10,184 --> 00:35:13,930
which is the capacity to obtain process

762
00:35:13,930 --> 00:35:17,089
and understand some basic
healthcare information

763
00:35:17,090 --> 00:35:20,963
for you to take the right
decision about your own health.

764
00:35:23,710 --> 00:35:25,780
- So we had about three minutes left.

765
00:35:25,780 --> 00:35:28,170
I'm going to leave it
open for three of you

766
00:35:28,170 --> 00:35:29,870
do any of you have
questions for each other

767
00:35:29,870 --> 00:35:30,703
or final thoughts.

768
00:35:30,703 --> 00:35:31,560
Actually before I do that

769
00:35:31,560 --> 00:35:34,190
what's your call to action, Sharka?

770
00:35:34,190 --> 00:35:38,570
- My call to action is are
you someone a lawmaker,

771
00:35:38,570 --> 00:35:42,130
reach out to Biohacking
Village, let's work it out,

772
00:35:42,130 --> 00:35:45,360
let's work at all those
laws and regulations.

773
00:35:45,360 --> 00:35:50,360
Are you a person that is just
observing everything like me?

774
00:35:51,930 --> 00:35:53,790
You need to talk to everyone around you.

775
00:35:53,790 --> 00:35:56,870
I speak to my family and
I speak to my loved ones

776
00:35:56,870 --> 00:36:00,569
and my friends and it's
sometimes exhausting

777
00:36:00,570 --> 00:36:04,370
because we are not seeing
that much of a difference,

778
00:36:04,370 --> 00:36:07,009
but take time, be patient

779
00:36:07,010 --> 00:36:10,540
and start explaining to
the people around you

780
00:36:10,540 --> 00:36:15,540
and karma it's gonna reward
you, I surely believe in that.

781
00:36:18,020 --> 00:36:20,633
- I love statistics, I'm
gonna throw one thing down.

782
00:36:22,892 --> 00:36:26,060
The generations that we are building for

783
00:36:26,060 --> 00:36:28,180
are primarily current
state the Baby Boomers.

784
00:36:28,180 --> 00:36:30,259
So the greatest, I think they're called

785
00:36:30,260 --> 00:36:32,150
great, greater generation
that came before them,

786
00:36:32,150 --> 00:36:35,050
and then the Baby Boomers,
and then Gen X and Z

787
00:36:35,050 --> 00:36:36,860
and millennials and
everybody else in there,

788
00:36:36,860 --> 00:36:39,130
and the Greatest Generation

789
00:36:39,130 --> 00:36:43,000
and the Baby Boomers are
believed going to be about 43%

790
00:36:43,000 --> 00:36:45,330
of the population in the United States.

791
00:36:45,330 --> 00:36:48,930
So when we build for technology
and security and privacy

792
00:36:48,930 --> 00:36:51,250
and all of the new cool
things that are coming out

793
00:36:51,250 --> 00:36:53,170
we have to take into account

794
00:36:53,170 --> 00:36:55,720
that they may not be our main person

795
00:36:55,720 --> 00:36:57,529
that we are producing for

796
00:36:57,530 --> 00:36:59,920
but they may be people that
are taking advantage of it

797
00:36:59,920 --> 00:37:02,830
because I want to see if my mother falls

798
00:37:02,830 --> 00:37:03,990
or how her heart rate is

799
00:37:03,990 --> 00:37:06,709
or how my father is doing
whatever he's doing.

800
00:37:06,710 --> 00:37:10,900
So me I might give them
something to hold on to

801
00:37:10,900 --> 00:37:12,750
so that I can monitor them.

802
00:37:12,750 --> 00:37:14,380
So there's a huge disparity

803
00:37:14,380 --> 00:37:16,870
of people that did not
grow up with technology

804
00:37:16,870 --> 00:37:19,200
versus the generations that are coming

805
00:37:19,200 --> 00:37:22,250
that have the iPads and
phones in their hands.

806
00:37:22,250 --> 00:37:24,820
So are there any final thoughts

807
00:37:24,820 --> 00:37:29,820
or any words that you
folks would like to bestow

808
00:37:29,890 --> 00:37:31,080
upon the listeners?

809
00:37:31,080 --> 00:37:32,910
- The only thing I'd add to that

810
00:37:32,910 --> 00:37:34,370
it's always going to be we're designing

811
00:37:34,370 --> 00:37:37,970
for the folks that aren't as
tech savvy it's gonna continue,

812
00:37:37,970 --> 00:37:39,669
this is gonna be future generations

813
00:37:39,670 --> 00:37:41,420
so we need to not solve it

814
00:37:41,420 --> 00:37:43,840
by trying to have these
one-off conversations.

815
00:37:43,840 --> 00:37:45,100
I'm not saying there's not utility there

816
00:37:45,100 --> 00:37:46,980
but we have to systemically change things

817
00:37:46,980 --> 00:37:49,380
otherwise it's never gonna
actually reach scale.

818
00:37:51,720 --> 00:37:53,339
- [Interviewer] I feel
like Caleb has something

819
00:37:53,340 --> 00:37:55,800
I can see it happening,
what is that Caleb?

820
00:37:55,800 --> 00:37:57,490
- I mean I think at the end of the day

821
00:37:57,490 --> 00:38:01,939
what we've really got to do
is we've got to recognize

822
00:38:01,940 --> 00:38:04,140
that healthcare is under attack right now

823
00:38:04,140 --> 00:38:06,930
in a variety of different sources.

824
00:38:06,930 --> 00:38:08,759
It is an industry that
hasn't traditionally

825
00:38:08,760 --> 00:38:10,860
have the technical
sophistication to deal with it,

826
00:38:10,860 --> 00:38:12,580
and we've really got to rally around this

827
00:38:12,580 --> 00:38:14,040
because at the end of the day,

828
00:38:14,040 --> 00:38:16,373
we all lose when healthcare gets hacked.

829
00:38:19,151 --> 00:38:20,210
- I'm gonna add something to that.

830
00:38:20,210 --> 00:38:22,610
I think a lot of folks
don't recognize how much

831
00:38:22,610 --> 00:38:26,010
of the other parts of industry
are embedded in healthcare

832
00:38:26,010 --> 00:38:27,130
'cause it's not just healthcare,

833
00:38:27,130 --> 00:38:29,273
it's all of the things, Sharka.

834
00:38:30,830 --> 00:38:32,960
- Yeah, that plays into the article

835
00:38:32,960 --> 00:38:34,360
that I wrote just last week

836
00:38:34,360 --> 00:38:39,060
about industrial control
systems in healthcare.

837
00:38:39,060 --> 00:38:44,060
So I believe as you're
saying it's a huge ecosystem

838
00:38:44,490 --> 00:38:46,250
that goes and it's obviously

839
00:38:46,250 --> 00:38:48,000
not on the industrial control systems,

840
00:38:48,000 --> 00:38:51,970
but it's the payment
systems, it's everything

841
00:38:51,970 --> 00:38:55,013
and it's humans, it's technology,

842
00:38:55,900 --> 00:39:00,600
and it's so complex where
we need to work together,

843
00:39:00,600 --> 00:39:04,790
and that seems to have
been an issue all along.

844
00:39:04,790 --> 00:39:09,210
So I think that we need to
be better at joining hands

845
00:39:09,210 --> 00:39:14,210
and talking to each other and
not treat issues separately.

846
00:39:16,630 --> 00:39:17,650
- [Caleb] The other thing
I would throw in here

847
00:39:17,650 --> 00:39:19,400
is don't forget-
- [Interviewer] 30 seconds.

848
00:39:19,400 --> 00:39:21,610
- [Caleb] Healthcare is over 17%

849
00:39:21,610 --> 00:39:24,230
of the US gross domestic product.

850
00:39:24,230 --> 00:39:27,640
I mean, forget about just the data,

851
00:39:27,640 --> 00:39:29,830
this is our economy at the end of the day,

852
00:39:29,830 --> 00:39:31,023
we have to protect it.

853
00:39:32,970 --> 00:39:33,939
- [Interviewer] I love that,

854
00:39:33,940 --> 00:39:34,773
that's where we're gonna end it.

855
00:39:34,773 --> 00:39:37,680
Thank you everyone for coming,
thank you for speaking.

856
00:39:37,680 --> 00:39:39,129
I feel like we should do this more often

857
00:39:39,130 --> 00:39:41,113
as fireside chats between all of us.

858
00:39:42,050 --> 00:39:43,059
- Thank you.

859
00:39:43,059 --> 00:39:44,473
- [Vidya] Thank you.

