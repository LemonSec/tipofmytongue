1
00:00:01,640 --> 00:00:04,590
- Good afternoon, cyber
security enthusiasts.

2
00:00:04,590 --> 00:00:06,050
My name is Boyden Rohner,

3
00:00:06,050 --> 00:00:08,923
and I'm here today with
my colleague, Tom Ruoff,

4
00:00:09,870 --> 00:00:12,669
and we work in the Cyber
Security Division at the

5
00:00:12,670 --> 00:00:17,130
Cybersecurity and Infrastructure
Security Agency, CISA.

6
00:00:17,130 --> 00:00:18,910
If you're not familiar with CISA,

7
00:00:18,910 --> 00:00:21,750
we are the newest component of the

8
00:00:21,750 --> 00:00:23,580
Department of Homeland Security

9
00:00:23,580 --> 00:00:27,369
and we serve as the Nation's risk advisor.

10
00:00:27,370 --> 00:00:30,270
We are responsible for understanding cyber

11
00:00:30,270 --> 00:00:33,780
and physical risks to the
nation's critical infrastructure

12
00:00:33,780 --> 00:00:36,930
and providing risk advice
to help our partners

13
00:00:36,930 --> 00:00:40,320
build their own capabilities which in turn

14
00:00:40,320 --> 00:00:43,790
strengthens national resilience.

15
00:00:43,790 --> 00:00:46,760
Specifically, Tom and I work on

16
00:00:46,760 --> 00:00:49,420
cyber vulnerability management portfolio.

17
00:00:49,420 --> 00:00:52,350
This means we work to
understand vulnerabilities

18
00:00:52,350 --> 00:00:55,090
and devise strategies to manage them.

19
00:00:55,090 --> 00:00:58,050
So naturally we are
obsessive about learning

20
00:00:58,050 --> 00:01:00,410
the latest information
about vulnerabilities

21
00:01:00,410 --> 00:01:01,699
that actors are exploiting

22
00:01:01,700 --> 00:01:04,379
in the nation's critical infrastructure.

23
00:01:04,379 --> 00:01:06,310
Over the course of the
last couple of years,

24
00:01:06,310 --> 00:01:09,600
we've uncovered some new
trends in vulnerabilities,

25
00:01:09,600 --> 00:01:12,050
and today it's our goal to share with you

26
00:01:12,050 --> 00:01:14,899
what we've learned, what
we plan to do about it,

27
00:01:14,900 --> 00:01:16,033
and how you can help.

28
00:01:17,070 --> 00:01:18,559
We're going to be answering questions

29
00:01:18,560 --> 00:01:22,060
all throughout this
presentation via the chat.

30
00:01:22,060 --> 00:01:23,630
So if you've got a question for us,

31
00:01:23,630 --> 00:01:26,053
head on over the chat
and we'll respond there.

32
00:01:27,920 --> 00:01:30,300
To get us started, I wanna take us back

33
00:01:30,300 --> 00:01:32,673
to my sixth grade science project.

34
00:01:33,750 --> 00:01:36,830
For my science project,
I studied icebergs.

35
00:01:36,830 --> 00:01:38,490
If you aren't familiar with icebergs,

36
00:01:38,490 --> 00:01:40,190
they are composed of fresh water

37
00:01:40,190 --> 00:01:42,870
which is less dense
than southeast seawater.

38
00:01:42,870 --> 00:01:46,870
And so thanks to Archimedes,
principle of buoyancy,

39
00:01:46,870 --> 00:01:50,660
only a fraction of the
iceberg is above water

40
00:01:50,660 --> 00:01:52,283
and visible to the human eye.

41
00:01:53,370 --> 00:01:55,120
Over the past couple of years,

42
00:01:55,120 --> 00:01:57,260
as we've spoken to security researchers,

43
00:01:57,260 --> 00:01:58,540
done our own analysis,

44
00:01:58,540 --> 00:02:01,110
and responded to incidents
across the country,

45
00:02:01,110 --> 00:02:03,310
we have come to the conclusion that

46
00:02:03,310 --> 00:02:05,770
software presents an illusion.

47
00:02:05,770 --> 00:02:07,923
An illusion similar to an iceberg.

48
00:02:08,830 --> 00:02:12,053
What you might be getting is
more than what meets the eye.

49
00:02:13,270 --> 00:02:16,280
In cybersecurity we spend
the majority of our time

50
00:02:16,280 --> 00:02:20,570
observing, analyzing, and
responding to vulnerabilities

51
00:02:20,570 --> 00:02:23,553
in operating systems and
at the application layer.

52
00:02:24,490 --> 00:02:27,900
And yes there are categories
of vulnerabilities

53
00:02:27,900 --> 00:02:30,760
lurking beneath the proverbial surface

54
00:02:30,760 --> 00:02:32,093
that we are dealing with.

55
00:02:33,200 --> 00:02:36,160
Through our vulnerability research efforts

56
00:02:36,160 --> 00:02:38,710
and our incident response activities,

57
00:02:38,710 --> 00:02:41,660
we have come to realize
there are vulnerabilities

58
00:02:41,660 --> 00:02:43,680
below the operating system,

59
00:02:43,680 --> 00:02:47,470
a term we're pointing here today, VBOS,

60
00:02:47,470 --> 00:02:49,830
that we must deal with too.

61
00:02:49,830 --> 00:02:51,210
If you're like me and Tom,

62
00:02:51,210 --> 00:02:53,230
and you work in the
vulnerability management space

63
00:02:53,230 --> 00:02:55,760
of cybersecurity, you're
probably thinking to yourself,

64
00:02:55,760 --> 00:02:59,049
oh, please no, not more
vulnerabilities CISA.

65
00:02:59,050 --> 00:03:01,310
US-CERT are texting every day

66
00:03:01,310 --> 00:03:03,200
about something critical to fix.

67
00:03:03,200 --> 00:03:04,519
Well, this is a quick plug,

68
00:03:04,520 --> 00:03:06,720
but if you're not getting
those texts everyday

69
00:03:06,720 --> 00:03:08,820
from US-CERT telling you what to fix,

70
00:03:08,820 --> 00:03:11,540
to head on over to the US-CERT
or CISA website right now

71
00:03:11,540 --> 00:03:14,453
and sign up for those alerts,
they'll change your life.

72
00:03:15,630 --> 00:03:18,380
But, if you're starting to
think about a career change

73
00:03:18,380 --> 00:03:19,920
because you've only been dealing

74
00:03:19,920 --> 00:03:23,010
with a tip of the vulnerability iceberg,

75
00:03:23,010 --> 00:03:26,470
don't get discouraged,
because we think that

76
00:03:26,470 --> 00:03:28,150
some of the work that's already been done

77
00:03:28,150 --> 00:03:29,840
on software bill of materials,

78
00:03:29,840 --> 00:03:32,390
that initiative can be the answer.

79
00:03:32,390 --> 00:03:36,500
To the uninitiated, Software
Bill of Materials or SBOM,

80
00:03:36,500 --> 00:03:39,260
is effectively a nested inventory,

81
00:03:39,260 --> 00:03:43,292
a list of ingredients that
makes up software components.

82
00:03:46,250 --> 00:03:49,440
So before we get ahead of
ourselves and get to the solution,

83
00:03:49,440 --> 00:03:51,030
let's talk about the problem.

84
00:03:51,030 --> 00:03:52,460
I'm gonna turn it over to Tom,

85
00:03:52,460 --> 00:03:54,170
to help us define the problem.

86
00:03:54,170 --> 00:03:55,003
Tom?

87
00:03:55,003 --> 00:03:56,559
- Thank you, Boyden.

88
00:03:56,560 --> 00:03:59,880
So carrying on with the
analogy of the iceberg,

89
00:03:59,880 --> 00:04:04,250
and by the way, I did read
Boyden's sixth grade report

90
00:04:04,250 --> 00:04:07,020
on icebergs, it is fascinating,

91
00:04:07,020 --> 00:04:09,800
and I recommend it to those
who can find it online.

92
00:04:09,800 --> 00:04:13,464
But for those who can't,
what I would suggest is that

93
00:04:13,464 --> 00:04:15,580
you take a look at some of the material

94
00:04:15,580 --> 00:04:18,220
that we're gonna be putting out shortly,

95
00:04:18,220 --> 00:04:21,899
and this taxonomy and
the reports we've put out

96
00:04:21,899 --> 00:04:24,489
will be probably, although,
probably not as interesting,

97
00:04:24,490 --> 00:04:27,490
but a little more germane to the topic.

98
00:04:27,490 --> 00:04:29,750
So what we've done is we've taken

99
00:04:31,450 --> 00:04:33,610
the concept of the vulnerability

100
00:04:33,610 --> 00:04:36,180
or the material of all
the operating system,

101
00:04:36,180 --> 00:04:40,540
and of course that software
which awakes the hardware

102
00:04:40,540 --> 00:04:42,280
back to the operating system.

103
00:04:42,280 --> 00:04:46,039
And it's those specialty areas of code

104
00:04:46,040 --> 00:04:50,020
which is the focus of
our work in the past,

105
00:04:50,020 --> 00:04:51,859
and we'll be talking about here today.

106
00:04:51,860 --> 00:04:54,840
And so if we think about the graphic here,

107
00:04:54,840 --> 00:04:57,652
and again the details we've
gone into in our reports,

108
00:04:58,560 --> 00:04:59,970
for the techies out there,

109
00:04:59,970 --> 00:05:01,870
think about this as our resilient system.

110
00:05:01,870 --> 00:05:05,030
We had to organize our
thoughts as to what resides in

111
00:05:05,030 --> 00:05:08,500
the software and the
organization construct of that,

112
00:05:08,500 --> 00:05:11,700
and this is how we see
the world in terms of

113
00:05:11,700 --> 00:05:14,250
the software that's
accessible to the users,

114
00:05:14,250 --> 00:05:17,040
that's the operating system,
the applications and the data,

115
00:05:17,040 --> 00:05:19,867
and that which connects
the operating system

116
00:05:19,867 --> 00:05:22,810
and the applications to
the firm, to the hardware,

117
00:05:22,810 --> 00:05:24,010
again, firmware.

118
00:05:24,010 --> 00:05:28,409
So we're concerned with this
realm, and how we organize it,

119
00:05:28,410 --> 00:05:32,030
it's actually very crafty, and
my hats off to our partners

120
00:05:32,030 --> 00:05:34,580
if you could see them
and any AIS who helped us

121
00:05:34,580 --> 00:05:36,003
with this decomposition.

122
00:05:37,050 --> 00:05:39,530
And again, there's many
views of this topic area,

123
00:05:39,530 --> 00:05:42,130
but we chose this one
because we think it captures

124
00:05:42,130 --> 00:05:45,913
in bundle some of these topics uniquely.

125
00:05:48,030 --> 00:05:51,070
But before we get into the
depths of the topic area,

126
00:05:51,070 --> 00:05:53,099
we'd like to go through
just a couple of examples

127
00:05:53,100 --> 00:05:54,850
of exploits, Boyden?

128
00:05:54,850 --> 00:05:56,340
- Perfect, yes.

129
00:05:56,340 --> 00:05:59,750
So the first example
illustrating a vulnerability

130
00:05:59,750 --> 00:06:03,090
below the operating system
attack, is the infamous attack

131
00:06:03,090 --> 00:06:06,419
on the Ukrainian power
grid from December, 2015.

132
00:06:06,420 --> 00:06:08,770
Attackers installed malicious firmware

133
00:06:08,770 --> 00:06:11,400
on the serial to internet gateway devices,

134
00:06:11,400 --> 00:06:13,590
so that in the event
that the power companies

135
00:06:13,590 --> 00:06:15,590
couldn't recover operator workstations,

136
00:06:15,590 --> 00:06:18,210
remote commands would not be able to bring

137
00:06:18,210 --> 00:06:19,962
those substations back online.

138
00:06:20,950 --> 00:06:23,760
The second example of an attack on

139
00:06:23,760 --> 00:06:26,090
a vulnerability below the
operating system or VBOS

140
00:06:26,090 --> 00:06:28,219
happened in 2018.

141
00:06:28,220 --> 00:06:33,220
A threat actor created a
UEFI rootkit called LoJax

142
00:06:33,590 --> 00:06:36,739
that affected the legitimate
anti-theft software

143
00:06:36,740 --> 00:06:41,740
called LoJack, which is
used as a UEFI BIOS module

144
00:06:42,100 --> 00:06:45,520
to survive an operating
system reinstallation

145
00:06:45,520 --> 00:06:47,780
or replacement of the hard drive.

146
00:06:47,780 --> 00:06:52,590
As a refresher that attack,
a rootkit dropper arrived

147
00:06:52,590 --> 00:06:56,219
via just standard fishing
vector via an attachment

148
00:06:56,220 --> 00:06:58,710
or a link and then the
adversaries established

149
00:06:58,710 --> 00:07:00,969
and made a control channel to download

150
00:07:00,970 --> 00:07:05,350
a second stage malware
including a UEFI rootkit

151
00:07:05,350 --> 00:07:09,053
that provided consistent and
remote access to the software.

152
00:07:11,090 --> 00:07:12,340
Tom.

153
00:07:12,340 --> 00:07:13,173
- Thank you.

154
00:07:14,540 --> 00:07:16,470
Let's take a little bit of
time here and talk about

155
00:07:16,470 --> 00:07:18,280
the problem, the size of the problem,

156
00:07:18,280 --> 00:07:20,700
and some of the details of the problem.

157
00:07:20,700 --> 00:07:22,510
So this next section of
the talk is going to be

158
00:07:22,510 --> 00:07:25,120
a decomposition of our thoughts about

159
00:07:25,120 --> 00:07:27,730
why we think it's problem,
the details of the problem,

160
00:07:27,730 --> 00:07:30,270
and in fact, problem definition.

161
00:07:30,270 --> 00:07:33,969
So what we've shown here is
kind of our beginning thoughts.

162
00:07:33,970 --> 00:07:36,390
And what we do see is
although the percentage of the

163
00:07:36,390 --> 00:07:40,419
overall vulnerabilities
identified per year is low,

164
00:07:40,420 --> 00:07:41,920
we're seeing the growth trend.

165
00:07:42,840 --> 00:07:45,440
And in particular we see
the noticeable increase

166
00:07:45,440 --> 00:07:49,080
in the activity and frequency
associated with incidents,

167
00:07:49,080 --> 00:07:51,490
and we start asking ourselves, well, why?

168
00:07:51,490 --> 00:07:54,810
Well, we think this is kind of the starter

169
00:07:54,810 --> 00:07:56,183
because the actor said,

170
00:07:58,087 --> 00:08:02,130
that is currently exporting
these vulnerabilities,

171
00:08:02,130 --> 00:08:06,170
are using kits that were
created by nation state actors

172
00:08:06,170 --> 00:08:07,800
several years ago.

173
00:08:07,800 --> 00:08:10,400
Of course, you can't keep
some of the best kits out,

174
00:08:11,420 --> 00:08:12,910
you can't keep them out of the market,

175
00:08:12,910 --> 00:08:14,760
and so they become popularized.

176
00:08:14,760 --> 00:08:18,039
As a consequence, what
used to be in the realm

177
00:08:18,040 --> 00:08:20,180
of the nation state actors have now become

178
00:08:20,180 --> 00:08:22,170
in the realm of the commercial actors.

179
00:08:22,170 --> 00:08:24,610
And as a consequence
we're beginning to see

180
00:08:24,610 --> 00:08:27,230
an uptake in those, therefore,

181
00:08:27,230 --> 00:08:29,230
the interest in the vulnerability space.

182
00:08:30,180 --> 00:08:35,180
Now, this doesn't mean that
because they had the rootkits

183
00:08:35,330 --> 00:08:38,429
that was the sole cause, of
course, it's the persistence

184
00:08:38,429 --> 00:08:43,229
and the difficulty of
detecting any of these attacks

185
00:08:43,230 --> 00:08:45,400
that are down or the vulnerability

186
00:08:45,400 --> 00:08:47,100
down below the operating system.

187
00:08:47,100 --> 00:08:48,780
And as Boyden pointed out,

188
00:08:48,780 --> 00:08:51,720
in the case of the Ukrainian exercise,

189
00:08:51,720 --> 00:08:53,790
they were crafty enough to be able to open

190
00:08:53,790 --> 00:08:57,410
the circuit breakers, but then
they burnt the bridge back

191
00:08:57,410 --> 00:09:02,262
when they installed that
malware with the serial kits,

192
00:09:04,900 --> 00:09:08,730
serial gateways, because it
didn't allow for remote access,

193
00:09:08,730 --> 00:09:10,190
really smart idea.

194
00:09:10,190 --> 00:09:13,640
Well, okay, what this means
is, it's really difficult

195
00:09:13,640 --> 00:09:16,960
to be able to recover
from and the persistence

196
00:09:16,960 --> 00:09:21,300
is what seems to be the
motivation factor here.

197
00:09:21,300 --> 00:09:22,990
Now, let's get a little more deep

198
00:09:22,990 --> 00:09:24,340
into the details here then.

199
00:09:26,020 --> 00:09:27,870
So let's start with a good news story.

200
00:09:27,870 --> 00:09:32,323
The good news story is that
we see that above the OS

201
00:09:34,090 --> 00:09:36,830
there's an increase in use of

202
00:09:36,830 --> 00:09:39,160
vulnerability mitigation techniques,

203
00:09:39,160 --> 00:09:42,579
and those are the five that
are listed on the right.

204
00:09:42,580 --> 00:09:43,500
Well, that's great, right?

205
00:09:43,500 --> 00:09:46,840
So now we're seeing code that inherently

206
00:09:46,840 --> 00:09:51,258
is becoming stronger or less
risky because we're seeing

207
00:09:51,258 --> 00:09:54,360
vulnerability negation
techniques employed,

208
00:09:54,360 --> 00:09:55,510
and they're on the upkeep.

209
00:09:55,510 --> 00:09:57,143
Yay, that's great.

210
00:09:59,210 --> 00:10:00,950
That's probably the good news story,

211
00:10:00,950 --> 00:10:03,220
but that's the good part
of the good news story.

212
00:10:03,220 --> 00:10:07,920
The bad news story is we
look at the focus of these,

213
00:10:07,920 --> 00:10:09,010
and if we go back and say,

214
00:10:09,010 --> 00:10:11,790
well, what's the percentage of successful

215
00:10:11,790 --> 00:10:13,930
invitation commercial products?

216
00:10:13,930 --> 00:10:18,794
DEP, the Data Execution
Prevention techniques,

217
00:10:18,794 --> 00:10:20,250
almost at 90%.

218
00:10:20,250 --> 00:10:24,988
Almost at 90% of the address
space away out randomization.

219
00:10:24,988 --> 00:10:25,920
That's really good.

220
00:10:25,920 --> 00:10:29,110
But as we see then, the mitigation
of those vulnerabilities

221
00:10:29,110 --> 00:10:33,210
across the 10 or so
capabilities we've got here,

222
00:10:33,210 --> 00:10:36,327
actually nine, what we're seeing is that

223
00:10:36,327 --> 00:10:39,110
they're really focused
percentage-wise on the first four.

224
00:10:39,110 --> 00:10:41,080
Well, that's again a good news story

225
00:10:41,080 --> 00:10:44,440
that there are mitigations
being taken place.

226
00:10:44,440 --> 00:10:48,070
The bad news is they're focused

227
00:10:48,070 --> 00:10:50,510
and they're not spread
across the spectrum.

228
00:10:50,510 --> 00:10:52,550
Well, okay, but we're seeing an uptake,

229
00:10:52,550 --> 00:10:55,439
and that's pursuing uptake
in this and that's good.

230
00:10:55,440 --> 00:10:59,610
Now, the bad news is that all of those

231
00:10:59,610 --> 00:11:01,250
vulnerability mitigation techniques

232
00:11:01,250 --> 00:11:05,780
we saw before in the earlier
slide, they're not applicable

233
00:11:05,780 --> 00:11:09,060
to a great deal of the areas
we've been talking about here,

234
00:11:09,060 --> 00:11:11,319
in particular, the UEFI.

235
00:11:11,320 --> 00:11:13,350
And so what this means is that,

236
00:11:13,350 --> 00:11:15,990
although this is good
that there has been...

237
00:11:15,990 --> 00:11:18,550
We're trying to write
enclosed vulnerability

238
00:11:18,550 --> 00:11:20,469
that are current enclosed vulnerabilities,

239
00:11:20,470 --> 00:11:24,360
the bad news is that the
techniques aren't applicable.

240
00:11:24,360 --> 00:11:26,330
Okay, so we have some work to do.

241
00:11:26,330 --> 00:11:28,800
Again, the more bad news,
as we spoke earlier,

242
00:11:28,800 --> 00:11:33,449
is that the bad guys seem to
be concentrating on the UEFI

243
00:11:33,450 --> 00:11:35,380
as an area of interest,

244
00:11:35,380 --> 00:11:39,830
predominantly because
of the growing place.

245
00:11:39,830 --> 00:11:43,627
But even the worst is, and
this gets kind of tricky here,

246
00:11:43,627 --> 00:11:48,030
And that is that we
gotta be thinking about

247
00:11:48,030 --> 00:11:51,089
the work that needs to
be done to be able to

248
00:11:52,810 --> 00:11:57,479
bring in vulnerability
mitigation techniques.

249
00:11:57,480 --> 00:12:02,180
Because today, unfortunately, the vendors

250
00:12:02,180 --> 00:12:04,833
are disabling the security
mechanisms by default.

251
00:12:06,156 --> 00:12:07,660
And the reason for that is because

252
00:12:07,660 --> 00:12:09,781
they don't feel it's important,

253
00:12:09,781 --> 00:12:12,358
or they don't feel it's
an operational capability

254
00:12:12,358 --> 00:12:13,949
they wanna put into
play that it may chew up

255
00:12:13,950 --> 00:12:15,700
some of the cycle time.

256
00:12:15,700 --> 00:12:18,600
But we need the cooperation
of developers and integrators

257
00:12:18,600 --> 00:12:23,350
to install capability
implicitly that's enabled

258
00:12:23,350 --> 00:12:24,630
like the NX.

259
00:12:24,630 --> 00:12:28,200
And so again, the NX is
just an example of this,

260
00:12:28,200 --> 00:12:30,410
and this means there's
insufficient cooperation

261
00:12:30,410 --> 00:12:32,420
with the vendors in this area,

262
00:12:32,420 --> 00:12:34,640
and we have to turn that around.

263
00:12:34,640 --> 00:12:39,640
So in turning around,
we're hoping that this talk

264
00:12:41,660 --> 00:12:43,410
will encourage those to get others.

265
00:12:45,050 --> 00:12:48,949
This is the conclusion
of that part of the talk

266
00:12:51,640 --> 00:12:55,350
where we talk about why we're
enthusiastic in our areas.

267
00:12:55,350 --> 00:12:57,950
And I'm gonna turn it over
to Boyden to talk about

268
00:12:57,950 --> 00:13:00,470
what this means and where
we think we're going.

269
00:13:00,470 --> 00:13:01,680
- Thanks Tom.

270
00:13:01,680 --> 00:13:04,829
All that talk about bad,
really bad, and worst

271
00:13:04,830 --> 00:13:07,000
leads us back to our title slide.

272
00:13:07,000 --> 00:13:09,330
If you came to our talk
hoping to see vendors

273
00:13:09,330 --> 00:13:11,910
named and shamed as the worst offender,

274
00:13:11,910 --> 00:13:14,490
I'm afraid we're gonna disappoint you

275
00:13:14,490 --> 00:13:16,180
'cause that's not what this is about.

276
00:13:16,180 --> 00:13:20,689
Instead, we're positing that
the UEFI is the worst offender

277
00:13:20,690 --> 00:13:22,770
in terms of vulnerability management.

278
00:13:22,770 --> 00:13:26,300
The core nature of UEFI, it's ubiquity,

279
00:13:26,300 --> 00:13:29,380
and its lack of memory
protection enforcement

280
00:13:29,380 --> 00:13:33,000
leads us to the conclusion
that as it is done today,

281
00:13:33,000 --> 00:13:36,240
it is the worst offender
below the operating system.

282
00:13:36,240 --> 00:13:37,760
I'm making this bold claim,

283
00:13:37,760 --> 00:13:40,550
our goal is to attract
attention to the issue

284
00:13:40,550 --> 00:13:42,719
that the software
mitigations that are applied

285
00:13:42,720 --> 00:13:45,530
above the operating system need to expand

286
00:13:45,530 --> 00:13:46,930
to encompass the vulnerabilities

287
00:13:46,930 --> 00:13:49,300
that are below the
operating system as well,

288
00:13:49,300 --> 00:13:51,603
especially the UEFI.

289
00:13:52,960 --> 00:13:55,000
In order to understand how
we're gonna get ourselves

290
00:13:55,000 --> 00:13:57,630
as a community out of this conundrum,

291
00:13:57,630 --> 00:14:00,493
we're could turn our eyes towards food.

292
00:14:05,120 --> 00:14:10,120
Enter the often used Twinkie analogy.

293
00:14:11,310 --> 00:14:13,150
Someone gives you a Twinkie.

294
00:14:13,150 --> 00:14:15,939
You read the label, you
see the ingredients.

295
00:14:15,940 --> 00:14:18,920
Curiously, most of them
are unpronounceable.

296
00:14:18,920 --> 00:14:20,530
What do you do?

297
00:14:20,530 --> 00:14:24,410
You wanna make a decision
based on your risk tolerance.

298
00:14:24,410 --> 00:14:27,490
For example, if you're
Tom, you might think,

299
00:14:27,490 --> 00:14:30,390
FDA has done the testing and
they called this human food,

300
00:14:30,390 --> 00:14:31,720
I haven't read the lab reports,

301
00:14:31,720 --> 00:14:34,310
but I'm okay with assuming
the risk of eating

302
00:14:34,310 --> 00:14:36,680
one of these Twinkies once in a while.

303
00:14:36,680 --> 00:14:38,699
- Well, on the other hand,

304
00:14:38,700 --> 00:14:41,310
no matter how much FDA testing is going on

305
00:14:41,310 --> 00:14:43,709
and how many reports are out there,

306
00:14:43,710 --> 00:14:46,060
there's no way that we're
going to convince Boyden

307
00:14:46,060 --> 00:14:48,420
to be eating Twinkie, and
make that risk decision,

308
00:14:48,420 --> 00:14:49,519
it's not gonna happen.

309
00:14:49,519 --> 00:14:50,352
(Boyden laughs)

310
00:14:50,352 --> 00:14:51,620
- That's right but we digress.

311
00:14:51,620 --> 00:14:54,650
Imagine a world where the
contents of the stuff we eat

312
00:14:54,650 --> 00:14:55,650
is not labeled.

313
00:14:55,650 --> 00:14:59,000
No USDA food grade, no list of contents.

314
00:14:59,000 --> 00:15:01,560
Folks would be confusing
dog food with human food

315
00:15:01,560 --> 00:15:03,599
and ingesting risky content.

316
00:15:03,600 --> 00:15:05,890
But thanks to the FDA, we have food labels

317
00:15:05,890 --> 00:15:09,569
that disclose ingredients
and testing can differentiate

318
00:15:09,570 --> 00:15:11,770
between human food and dog food.

319
00:15:11,770 --> 00:15:15,220
Disclosing ingredients through
labels is a great start,

320
00:15:15,220 --> 00:15:17,590
but unless you read the testing reports

321
00:15:17,590 --> 00:15:20,830
that describe the attributes
of those unpronounceable

322
00:15:20,830 --> 00:15:24,670
ingredients on that Twinkie
label you are still only making

323
00:15:24,670 --> 00:15:28,300
a partially informed risky decision.

324
00:15:28,300 --> 00:15:30,370
For example, would you eat a Twinkie

325
00:15:30,370 --> 00:15:32,410
if the label said it could kill you?

326
00:15:32,410 --> 00:15:34,110
Like the label says on cigarettes.

327
00:15:35,020 --> 00:15:40,020
Now think about that when it
comes to the IT and OT devices

328
00:15:40,220 --> 00:15:42,880
that you purchase, do
you know what's in it?

329
00:15:42,880 --> 00:15:45,490
Do you know what code you're inheriting?

330
00:15:45,490 --> 00:15:49,850
What is the lab report detailing
the effects of the software

331
00:15:49,850 --> 00:15:51,943
that you might have in your system say?

332
00:15:52,960 --> 00:15:54,380
Over to you, Tom.

333
00:15:54,380 --> 00:15:55,400
- Thank you, Boyden.

334
00:15:55,400 --> 00:15:57,860
Well with every project,
you really need to get

335
00:15:57,860 --> 00:16:01,570
a clear defined and
comprehensive problem statement.

336
00:16:01,570 --> 00:16:05,080
And it took us awhile as we
will do here to get to that.

337
00:16:05,080 --> 00:16:08,200
But we think this is what we arrived at.

338
00:16:08,200 --> 00:16:11,410
So in a nutshell, we
think the problem is that

339
00:16:11,410 --> 00:16:14,550
IT and OT systems are being compromised

340
00:16:15,476 --> 00:16:20,476
by vulnerable software that
we don't have visibility into

341
00:16:21,430 --> 00:16:24,530
by actors using
commercially available tools

342
00:16:24,530 --> 00:16:27,490
that exploit the software that we have few

343
00:16:27,490 --> 00:16:29,943
mitigation capabilities to address.

344
00:16:30,920 --> 00:16:34,630
And as a consequence of
that we really think that

345
00:16:34,630 --> 00:16:38,670
we wanna start with and begin
our exploration of success

346
00:16:38,670 --> 00:16:42,819
or getting better with the
addressing the UEFI code.

347
00:16:42,820 --> 00:16:46,140
And again, the majority that is,

348
00:16:46,140 --> 00:16:49,080
the majority of issues we're
concerned about not all

349
00:16:49,080 --> 00:16:51,630
are focused at the UEFI
and as a consequence

350
00:16:51,630 --> 00:16:53,720
that's really our starting point.

351
00:16:53,720 --> 00:16:55,900
And so we wanna talk to you now about

352
00:16:55,900 --> 00:16:59,360
what success looks like
for the CISA viewpoint.

353
00:16:59,360 --> 00:17:04,040
So first we think that the...

354
00:17:04,040 --> 00:17:05,750
And we've talked about the SBOM,

355
00:17:05,750 --> 00:17:08,700
but we think the idea of
the SBOM, which is great,

356
00:17:08,700 --> 00:17:12,500
is a good place to begin and is addressed

357
00:17:12,500 --> 00:17:14,010
in the executive order.

358
00:17:14,010 --> 00:17:16,310
So I would strongly
encourage people who have not

359
00:17:16,310 --> 00:17:19,240
to read the executive order,
particularly those sections

360
00:17:19,240 --> 00:17:22,069
dealing with the SBOM.

361
00:17:22,069 --> 00:17:25,099
Now getting the SBOM components is great

362
00:17:26,000 --> 00:17:27,910
and it's how we get the ingredients,

363
00:17:27,910 --> 00:17:32,100
but it's necessary but really
not a sufficient condition

364
00:17:32,100 --> 00:17:34,310
to make those risk-based decisions.

365
00:17:34,310 --> 00:17:36,793
And we'll go through
what is required as well.

366
00:17:37,830 --> 00:17:40,500
But once you get the ingredients
you need to understand

367
00:17:40,500 --> 00:17:42,510
what the ingredients are supposed to do

368
00:17:42,510 --> 00:17:44,310
in terms of those behaviors.

369
00:17:44,310 --> 00:17:47,110
So again, we want the disclosure of

370
00:17:47,110 --> 00:17:50,050
what the ingredients are and we also like

371
00:17:50,050 --> 00:17:53,020
the manufacturers to tell
us what it's supposed to do.

372
00:17:53,020 --> 00:17:56,290
And by the same talk that gives
us a constraint well layer.

373
00:17:56,290 --> 00:18:00,420
So we know that this is
the SBOM is moving along

374
00:18:00,420 --> 00:18:02,380
but we want to be able to tag
it along to something else,

375
00:18:02,380 --> 00:18:06,770
which again is what the
manufacturers think it's gonna do.

376
00:18:06,770 --> 00:18:08,653
So, Boyden?

377
00:18:09,590 --> 00:18:12,040
- Secondly, we want the community to adopt

378
00:18:12,040 --> 00:18:15,000
the vulnerability
mitigation for all software

379
00:18:15,000 --> 00:18:18,830
within special focus on software
below the operating system

380
00:18:18,830 --> 00:18:20,980
and new UEFI code.

381
00:18:20,980 --> 00:18:23,770
Just like the FDA
recognizes Twinkies as food

382
00:18:23,770 --> 00:18:27,620
we want Reeboks to be recognized
as vulnerabilities too.

383
00:18:27,620 --> 00:18:29,820
There are tools and
techniques we can apply

384
00:18:29,820 --> 00:18:32,250
and together we need to
ask for adoption of those

385
00:18:32,250 --> 00:18:35,510
across the code base, because
neglecting one of these

386
00:18:35,510 --> 00:18:38,471
below the operating system
leaves the adversary's

387
00:18:38,471 --> 00:18:42,280
a playground and we can't afford.

388
00:18:42,280 --> 00:18:45,350
- Progressing along we
think that the capability

389
00:18:45,350 --> 00:18:47,933
to understand what the software can do,

390
00:18:49,168 --> 00:18:52,419
what the software can do and
what it is capable of doing

391
00:18:52,420 --> 00:18:56,640
we need to be able to put
together and we're realistic.

392
00:18:56,640 --> 00:18:59,560
We understand that not all
code can be examined in detail.

393
00:18:59,560 --> 00:19:00,510
This is really tough.

394
00:19:00,510 --> 00:19:02,780
And so we're not asking to boil the ocean.

395
00:19:02,780 --> 00:19:05,700
We're thinking what is
the first set of teacups

396
00:19:05,700 --> 00:19:08,500
that we can start taking our
big lighter and warming up?

397
00:19:08,500 --> 00:19:11,823
So we wanna start with
software and devices

398
00:19:11,823 --> 00:19:14,663
that are fairly well
constrained or purpose-built,

399
00:19:16,090 --> 00:19:19,419
like PLCs and medical
devices is a good start.

400
00:19:19,420 --> 00:19:21,100
Those are not general purpose devices.

401
00:19:21,100 --> 00:19:23,419
And we know that the
software is built to them

402
00:19:23,420 --> 00:19:25,040
was built specifically to exhibit

403
00:19:25,040 --> 00:19:27,139
a limited number of behavior.

404
00:19:27,140 --> 00:19:31,990
So once you remember that
UEFI, the firmware, the BIOS

405
00:19:31,990 --> 00:19:34,680
should be able to do a
defined set of behaviors

406
00:19:35,940 --> 00:19:37,980
like establishing external connections,

407
00:19:37,980 --> 00:19:41,790
early memory locations sometimes but not

408
00:19:41,790 --> 00:19:43,780
as a general course of behavior.

409
00:19:43,780 --> 00:19:45,639
And as a consequence we
need to be able to do

410
00:19:45,640 --> 00:19:48,630
the software analysis
to be able to determine

411
00:19:48,630 --> 00:19:51,260
what the software is capable of doing.

412
00:19:51,260 --> 00:19:53,620
Now, again, like I talked about initially

413
00:19:54,640 --> 00:19:58,400
we're not trying to boil the
ocean and we know this is hard,

414
00:19:58,400 --> 00:20:01,973
but we think if we start in a
constrained environment area,

415
00:20:03,015 --> 00:20:05,130
let's define our problem set
then we're gonna be able to

416
00:20:05,130 --> 00:20:06,830
start making progress.

417
00:20:06,830 --> 00:20:09,500
And we think that these
purpose-built devices

418
00:20:09,500 --> 00:20:13,370
and how we would examine
those at scale to determine

419
00:20:13,370 --> 00:20:15,973
capable behavior is a
real good place to start.

420
00:20:17,670 --> 00:20:19,300
So what do we want next?

421
00:20:19,300 --> 00:20:23,030
Well, the challenge in this next activity

422
00:20:23,030 --> 00:20:26,639
is trying to get some sort of
a high level risk indicator

423
00:20:26,640 --> 00:20:28,160
or an indicator scoring.

424
00:20:28,160 --> 00:20:29,510
And I know the word scoring

425
00:20:30,739 --> 00:20:31,950
is gonna cause a lot of problems,

426
00:20:31,950 --> 00:20:35,320
but if we think about level
at a risk indicator index,

427
00:20:35,320 --> 00:20:38,110
but we wanted to go out on a
whim and talk about a scoring

428
00:20:38,110 --> 00:20:40,429
because we think that
being ambitious and putting

429
00:20:40,430 --> 00:20:44,053
that marker ahead would
motivate the community to do so.

430
00:20:44,970 --> 00:20:47,210
And in this case we think the challenge is

431
00:20:47,210 --> 00:20:50,090
coupling the SBOM, the designer notes,

432
00:20:50,090 --> 00:20:53,090
That's what the manufacturer's
telling us we should do.

433
00:20:53,090 --> 00:20:55,300
the software capabilities
test can determine

434
00:20:55,300 --> 00:20:56,659
the difference between the intent

435
00:20:56,660 --> 00:20:59,110
and the capability at scale.

436
00:20:59,110 --> 00:21:04,110
So for example, we know that
if we're able to determine

437
00:21:04,720 --> 00:21:09,620
if the software vendor
says that the device

438
00:21:09,620 --> 00:21:12,060
should exhibit five behaviors let's say

439
00:21:12,060 --> 00:21:15,310
and we think that those five
behaviors are well articulated

440
00:21:15,310 --> 00:21:18,100
and now if we test against
it and we determined that

441
00:21:18,100 --> 00:21:22,553
the behaviors that can
exhibit are four, well, okay.

442
00:21:22,553 --> 00:21:25,500
As long as it's the same four of the five

443
00:21:25,500 --> 00:21:28,453
then that's not a risk,
it's just a poor product.

444
00:21:29,773 --> 00:21:32,409
Okay, so it said it's supposed
to do five, it does four.

445
00:21:32,410 --> 00:21:34,870
Okay, it's got an incomplete feature set

446
00:21:34,870 --> 00:21:36,453
not a problem from our view.

447
00:21:37,510 --> 00:21:40,920
Then let's take an example
where the product manufacturer

448
00:21:40,920 --> 00:21:43,860
says it's supposed to have
five behaviors and it exhibits

449
00:21:43,860 --> 00:21:46,362
the same five behaviors
regardless of the input.

450
00:21:47,580 --> 00:21:52,580
That's good code, that's
classic definition of good code.

451
00:21:52,630 --> 00:21:54,820
Well, now let's take the
other end of the spectrum

452
00:21:54,820 --> 00:21:57,300
where that same manufacturer
says it's supposed to do

453
00:21:57,300 --> 00:22:00,810
five behaviors and with
the same capability,

454
00:22:00,810 --> 00:22:03,570
both probably statically
and perhaps dynamical

455
00:22:03,570 --> 00:22:04,980
in certain rare cases.

456
00:22:04,980 --> 00:22:09,090
And we find it can do say
25 of those behaviors,

457
00:22:09,090 --> 00:22:11,209
wait a minute, five is
what's supposed to do

458
00:22:11,210 --> 00:22:12,963
and yet they can exhibit 25.

459
00:22:13,940 --> 00:22:17,640
What other 20 is it doing
that we manufactured

460
00:22:17,640 --> 00:22:20,670
didn't expect to do
more we as the consumer?

461
00:22:20,670 --> 00:22:23,520
Well, we think that's where
we start to look at how

462
00:22:23,520 --> 00:22:25,500
we can think about those as a

463
00:22:25,500 --> 00:22:28,123
risk indicator scoring algorithm,

464
00:22:29,170 --> 00:22:31,940
behavior that it was not intended to do

465
00:22:31,940 --> 00:22:34,010
it is capable of doing.

466
00:22:34,010 --> 00:22:37,080
And again, we know we're being realistic

467
00:22:37,080 --> 00:22:40,649
but we also understand
this is really hard.

468
00:22:40,650 --> 00:22:43,550
And so as we get our ambitions together

469
00:22:43,550 --> 00:22:45,860
and we all get the research we're doing

470
00:22:45,860 --> 00:22:49,209
we wanna be able to start
again in that constraint area.

471
00:22:49,210 --> 00:22:50,043
Boyden.

472
00:22:51,010 --> 00:22:53,010
- Well, the devil is in the details.

473
00:22:53,010 --> 00:22:54,870
So everybody wants to see the details.

474
00:22:54,870 --> 00:22:58,439
We need to have readily
available detailed test reports

475
00:22:58,440 --> 00:23:02,120
to substantiate indicators
of risks at scale.

476
00:23:02,120 --> 00:23:06,070
These need to be available
to never miss to access them.

477
00:23:06,070 --> 00:23:08,550
The risk indicators will
be backed up with tests

478
00:23:08,550 --> 00:23:11,230
that provide integrity
and make risk decisions,

479
00:23:11,230 --> 00:23:15,133
data-driven moving us as a
community from hope to knowledge.

480
00:23:15,990 --> 00:23:20,990
And finally, we are advocating,

481
00:23:21,710 --> 00:23:23,520
promoting policies that discourage

482
00:23:23,520 --> 00:23:26,050
the procurement of the worst offenders of

483
00:23:26,050 --> 00:23:28,730
vulnerabilities below
the operating system.

484
00:23:28,730 --> 00:23:32,470
We want policy that helps consumers make

485
00:23:32,470 --> 00:23:34,220
risk informed decisions.

486
00:23:34,220 --> 00:23:37,160
Buying a product with lots
of code with risk indicators

487
00:23:37,160 --> 00:23:39,870
is not a bad move if it's
a conscious decision,

488
00:23:39,870 --> 00:23:43,679
but if you take the same action
out of a place of ignorance

489
00:23:43,680 --> 00:23:47,510
that's what we wanna change.

490
00:23:47,510 --> 00:23:50,090
So Tom, why don't we do a role play

491
00:23:50,090 --> 00:23:51,439
to illustrate these points?

492
00:23:52,330 --> 00:23:53,163
- Sure, Boyden.

493
00:23:54,060 --> 00:23:57,610
So let's pretend you're a CIO or CSO

494
00:23:57,610 --> 00:23:59,959
and you're trying to make
a risk-based decision

495
00:24:00,870 --> 00:24:02,169
about what product to buy.

496
00:24:03,040 --> 00:24:06,860
What questions would you be asking?

497
00:24:06,860 --> 00:24:09,389
- Well, first I'd be saying show me the

498
00:24:09,390 --> 00:24:10,940
Software Bill of Materials.

499
00:24:10,940 --> 00:24:12,290
Can you provide that to me?

500
00:24:13,330 --> 00:24:16,189
Secondly, I might be
asking can you tell me

501
00:24:16,190 --> 00:24:18,250
what the software is intended to do?

502
00:24:18,250 --> 00:24:20,250
And finally, I'd probably be asking

503
00:24:20,250 --> 00:24:22,540
what vulnerability mitigation techniques

504
00:24:22,540 --> 00:24:25,010
have been included in the software?

505
00:24:25,010 --> 00:24:26,410
- Well, those are great questions.

506
00:24:26,410 --> 00:24:30,920
So what do you do Boyden if
you can't get answers to those?

507
00:24:30,920 --> 00:24:32,330
- Well, if you start to make a decision

508
00:24:32,330 --> 00:24:35,136
then you're probably making
a faith-based decision

509
00:24:35,136 --> 00:24:36,851
and not a risk-based one.

510
00:24:36,852 --> 00:24:39,861
- Oh, well, we know that
nobody wants to be doing that.

511
00:24:39,861 --> 00:24:41,880
And as cybersecurity professionals
we ought to be making

512
00:24:41,880 --> 00:24:44,290
risk-based, data-driven decisions.

513
00:24:44,290 --> 00:24:48,690
So let's now talk about
what CISA can do to create

514
00:24:48,690 --> 00:24:49,763
this paradigm shift.

515
00:24:50,860 --> 00:24:52,330
- Absolutely.

516
00:24:52,330 --> 00:24:55,629
First as a Nation's risk advisor
CISA at the cross section

517
00:24:55,630 --> 00:24:58,080
of all 16 critical infrastructure sectors,

518
00:24:58,080 --> 00:25:01,659
industry and government and we
use our unique vantage point

519
00:25:01,660 --> 00:25:04,270
to make sense of the
risks facing our country.

520
00:25:04,270 --> 00:25:07,680
Therefore we can do our part
to convene the community

521
00:25:07,680 --> 00:25:09,190
or reaching out to the public.

522
00:25:09,190 --> 00:25:12,330
Yes, you audience members
to try and get your ideas

523
00:25:12,330 --> 00:25:13,720
and solicit your support.

524
00:25:13,720 --> 00:25:15,770
We're especially interested
in getting the vendor

525
00:25:15,770 --> 00:25:19,700
and the UEFI coding community
involved then we can put

526
00:25:19,700 --> 00:25:21,950
a strategy in place that
works for everybody.

527
00:25:22,850 --> 00:25:24,949
In fact, if you're really
eager to get interested

528
00:25:24,950 --> 00:25:28,620
you can head on over NTIA site right now

529
00:25:28,620 --> 00:25:33,139
and check out NTIA/SBOM and
get information about SBOM

530
00:25:33,140 --> 00:25:35,030
and how you can join the next virtual

531
00:25:35,030 --> 00:25:36,483
multi-stakeholder meeting.

532
00:25:37,620 --> 00:25:42,620
Second, CISA can continue
to evolve our services

533
00:25:42,740 --> 00:25:45,620
to help our critical
infrastructure owners and operators

534
00:25:45,620 --> 00:25:49,110
get the visibility they need
to make risk-based decisions

535
00:25:49,110 --> 00:25:52,459
in turn that brings CISA information.

536
00:25:52,460 --> 00:25:55,740
It brings back information
to CISA to help us

537
00:25:55,740 --> 00:25:59,690
make a better judgment about
the risk posed to the nations

538
00:25:59,690 --> 00:26:02,940
and advocate for better practices.

539
00:26:02,940 --> 00:26:06,970
Finally, CISA can work
with researchers to develop

540
00:26:06,970 --> 00:26:10,350
automated code analysis to
verify vendor code claims

541
00:26:10,350 --> 00:26:12,253
and explore getting risks for it.

542
00:26:16,820 --> 00:26:18,399
Tom, you wanna tell people
how to get involved?

543
00:26:18,400 --> 00:26:19,560
- Absolutely.

544
00:26:19,560 --> 00:26:23,649
Well, first off, go read
the executive order.

545
00:26:23,650 --> 00:26:26,570
A lot of work went into that
and a lot of great thought

546
00:26:26,570 --> 00:26:29,590
and we think that there's content in there

547
00:26:29,590 --> 00:26:31,490
that is bookable to everybody.

548
00:26:31,490 --> 00:26:35,510
So first, so read it and then
do some googling to find out

549
00:26:35,510 --> 00:26:39,980
about efforts to implement
the EO sections and about SBOM

550
00:26:39,980 --> 00:26:41,740
and what that means to you,

551
00:26:41,740 --> 00:26:44,010
because this is pretty
revolutionary and again,

552
00:26:44,010 --> 00:26:46,640
a lot of people have spent
a lot of number of years

553
00:26:46,640 --> 00:26:49,780
getting that piece of work put together.

554
00:26:49,780 --> 00:26:53,540
Second, get some more on
SBOM and make it a practice

555
00:26:53,540 --> 00:26:57,570
to require SBOM in all your procurements.

556
00:26:57,570 --> 00:26:59,562
So make it personal, make it real.

557
00:27:01,210 --> 00:27:04,390
And when you're making an IT purchase

558
00:27:04,390 --> 00:27:09,390
specifically ask if there's
any CVEs related to the product

559
00:27:09,520 --> 00:27:11,663
and how the manufacturers addressed those.

560
00:27:13,140 --> 00:27:16,020
Further you can ask what
vulnerability mitigation techniques

561
00:27:16,020 --> 00:27:19,930
have been applied to the software
as we talked about before

562
00:27:19,930 --> 00:27:23,600
there are those four that
are in great use above

563
00:27:23,600 --> 00:27:26,060
and now we wanna be able
to get that done below.

564
00:27:26,060 --> 00:27:28,000
So if you wanna look really, really smart

565
00:27:28,000 --> 00:27:31,070
ask what are the vulnerability
mitigation techniques

566
00:27:31,070 --> 00:27:35,950
that have been applied in
the code in the UEFI layer.

567
00:27:35,950 --> 00:27:38,550
If you really, really wanna be an informed

568
00:27:38,550 --> 00:27:43,300
and proactive consumer
ask for the designer notes

569
00:27:43,300 --> 00:27:48,300
from your manufacturer
ask, what is this code?

570
00:27:48,390 --> 00:27:49,890
What is it supposed to do?

571
00:27:49,890 --> 00:27:52,200
And is there any testing
reports that tell me

572
00:27:52,200 --> 00:27:55,193
the differences between what
it can do and what it can't?

573
00:27:56,550 --> 00:27:59,860
Last, start implementing
compensating controls

574
00:27:59,860 --> 00:28:02,750
around devices with vulnerabilities

575
00:28:02,750 --> 00:28:04,280
both the operating system,

576
00:28:04,280 --> 00:28:07,620
until you get a sense that you
can replace or mitigate them.

577
00:28:07,620 --> 00:28:12,620
And again, this is just
grand old common sense

578
00:28:13,480 --> 00:28:17,620
systems engineering
cybersecurity practices.

579
00:28:17,620 --> 00:28:22,620
So again, until we get the
controls we want in places

580
00:28:22,870 --> 00:28:25,889
we've listed before think
about what vulnerabilities

581
00:28:25,890 --> 00:28:28,030
you're able to find out in your systems

582
00:28:28,030 --> 00:28:31,490
or systems that you're about to acquire

583
00:28:31,490 --> 00:28:33,430
and putting those compensating controls

584
00:28:33,430 --> 00:28:36,723
using again systems engineering
cybersecurity techniques.

585
00:28:37,770 --> 00:28:38,603
Boyden?

586
00:28:40,210 --> 00:28:41,330
- Thank you, Tom.

587
00:28:41,330 --> 00:28:44,129
Well, that brings us to the
end of our presentation today.

588
00:28:44,130 --> 00:28:46,380
We hope that we've whetted your
appetite to learn more about

589
00:28:46,380 --> 00:28:48,000
vulnerabilities below the operating system

590
00:28:48,000 --> 00:28:49,063
and get involved.

591
00:28:49,940 --> 00:28:51,880
If you wanna continue to work with us

592
00:28:51,880 --> 00:28:56,880
please go to the CISA website
or go to checkout NTIA/SBOM

593
00:28:57,040 --> 00:29:02,040
and register your thoughts,
your feedback and your comments.

594
00:29:02,510 --> 00:29:04,070
So we look forward to working with you

595
00:29:04,070 --> 00:29:07,879
to (indistinct) a secure
tomorrow, take care.

