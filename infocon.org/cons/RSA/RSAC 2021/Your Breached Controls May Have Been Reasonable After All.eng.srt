1
00:00:01,360 --> 00:00:03,740
- Hello, it's nice to be here at RSA

2
00:00:03,740 --> 00:00:06,800
to talk with you about
the law of data security,

3
00:00:06,800 --> 00:00:09,120
and specifically about how to determine

4
00:00:09,120 --> 00:00:13,549
whether the security controls
that you or someone else

5
00:00:13,550 --> 00:00:16,790
may have applied to personal information

6
00:00:16,790 --> 00:00:19,890
were reasonable under the law.

7
00:00:19,890 --> 00:00:22,540
For the Sedona Conference,
an influential think tank

8
00:00:22,540 --> 00:00:25,640
that provides technical
guidance for the law,

9
00:00:25,640 --> 00:00:27,860
this exploration of reasonableness began

10
00:00:27,860 --> 00:00:31,850
nearly three years ago, when
members of Working Group 11

11
00:00:31,850 --> 00:00:36,140
observed that the law was all
over the place on this point.

12
00:00:36,140 --> 00:00:39,580
Regulators and the courts and
industry all had experience

13
00:00:39,580 --> 00:00:42,320
with reasonableness and that standard.

14
00:00:42,320 --> 00:00:45,660
Agencies commonly use
reasonableness in their regulations

15
00:00:45,660 --> 00:00:47,459
and in their injunctions.

16
00:00:47,460 --> 00:00:50,500
Reasonableness was a
staple in the industry,

17
00:00:50,500 --> 00:00:53,660
and the courts used it regularly as well.

18
00:00:53,660 --> 00:00:55,559
But there was real uncertainty

19
00:00:55,560 --> 00:00:58,360
about what the word reasonable means

20
00:00:58,360 --> 00:01:02,060
and equal uncertainty
about how to apply it.

21
00:01:02,060 --> 00:01:03,390
This was especially the case

22
00:01:03,390 --> 00:01:07,480
for the orders of administrative
agencies, like the FTC.

23
00:01:07,480 --> 00:01:10,570
Two appellate decisions pointed this out.

24
00:01:10,570 --> 00:01:13,960
In Wyndham, the circuit court
of appeals was able to find

25
00:01:13,960 --> 00:01:16,830
an acceptable definition
for reasonableness,

26
00:01:16,830 --> 00:01:19,960
against which to test
the applicable statute,

27
00:01:19,960 --> 00:01:24,259
the FTC Act and the
hotel security controls.

28
00:01:24,260 --> 00:01:26,770
But the court had to look for it.

29
00:01:26,770 --> 00:01:31,229
In Lab MD, the court was not
able to find a definition

30
00:01:31,230 --> 00:01:35,540
for reasonable and it
rejected the FTCs order.

31
00:01:35,540 --> 00:01:37,880
The Sedona Conference decided it would try

32
00:01:37,880 --> 00:01:40,800
to develop a test for reasonableness.

33
00:01:40,800 --> 00:01:43,259
And it began by taking a look around

34
00:01:43,260 --> 00:01:45,560
to see what was already out there.

35
00:01:45,560 --> 00:01:47,960
One task force looked at the law,

36
00:01:47,960 --> 00:01:49,990
another looked at the regulators

37
00:01:49,990 --> 00:01:52,809
and a third looked at industry.

38
00:01:52,810 --> 00:01:56,060
From the legal task force, is David Cohen,

39
00:01:56,060 --> 00:01:57,770
a lawyer who defends clients

40
00:01:57,770 --> 00:02:00,800
and who practices with
Orrick, in New York city.

41
00:02:00,800 --> 00:02:02,380
David.

42
00:02:02,380 --> 00:02:03,490
- Thanks Bill.

43
00:02:03,490 --> 00:02:06,640
I focus on defending
companies that have suffered

44
00:02:06,640 --> 00:02:08,770
data breaches against litigation

45
00:02:08,770 --> 00:02:12,550
and government enforcement
actions that frequently ensue.

46
00:02:12,550 --> 00:02:16,710
And the issue of reasonable
security comes up regularly

47
00:02:16,710 --> 00:02:20,070
in the cases that I defend,
class-action plaintiffs

48
00:02:20,070 --> 00:02:24,160
and regulators always argue
that our clients fell short

49
00:02:24,160 --> 00:02:25,690
of a reasonableness standard.

50
00:02:25,690 --> 00:02:28,340
So one of the key
responsibilities that I have

51
00:02:28,340 --> 00:02:32,230
is to defend the reasonableness
of our client security

52
00:02:32,230 --> 00:02:35,649
among many other arguments
that we raise in these cases.

53
00:02:35,650 --> 00:02:39,250
And I was part of the team
that defended both Wyndham

54
00:02:39,250 --> 00:02:42,930
and Lab MD in the cases that
Bill mentioned just now,

55
00:02:42,930 --> 00:02:44,910
which has given me the opportunity

56
00:02:44,910 --> 00:02:47,247
to do a lot of thinking over the years

57
00:02:47,247 --> 00:02:50,800
about the issues involved
in defining reasonableness.

58
00:02:50,800 --> 00:02:52,720
- Thank you very much.

59
00:02:52,720 --> 00:02:55,130
The Regulatory Task Force looked at state

60
00:02:55,130 --> 00:02:57,600
and federal administrative agencies,

61
00:02:57,600 --> 00:02:59,650
and we're pleased that Jim Trilling,

62
00:02:59,650 --> 00:03:01,820
a lawyer with the Division of Privacy

63
00:03:01,820 --> 00:03:05,030
and Identity Protection at
the Federal Trade Commission

64
00:03:05,030 --> 00:03:08,620
in Washington D.C. is with us today, Jim.

65
00:03:08,620 --> 00:03:11,350
- Thanks Bill and hello everyone.

66
00:03:11,350 --> 00:03:14,340
I am an attorney in the
Federal Trade Commission's

67
00:03:14,340 --> 00:03:17,200
division of privacy and
identity protection,

68
00:03:17,200 --> 00:03:19,799
which is the group within the FTC

69
00:03:19,800 --> 00:03:22,500
that investigates often settles.

70
00:03:22,500 --> 00:03:25,770
And as David mentioned
sometimes litigate cases

71
00:03:25,770 --> 00:03:29,120
involving data security issues.

72
00:03:29,120 --> 00:03:32,680
Our interest in data security
is on protecting consumers

73
00:03:32,680 --> 00:03:36,780
from harm that can occur due
to a company's unreasonable

74
00:03:36,780 --> 00:03:40,470
or otherwise unlawful
data security practices.

75
00:03:40,470 --> 00:03:42,520
Among other things, as Bill mentioned,

76
00:03:42,520 --> 00:03:45,740
we enforce section five of the
Federal Trade Commission Act,

77
00:03:45,740 --> 00:03:49,930
which prohibits deceptive
or unfair acts or practices.

78
00:03:49,930 --> 00:03:53,660
Having unreasonable
data security practices

79
00:03:53,660 --> 00:03:55,270
can be a deceptive practice.

80
00:03:55,270 --> 00:03:58,090
For example, it is deceptive for a company

81
00:03:58,090 --> 00:04:00,920
to promise consumers that it reasonably

82
00:04:00,920 --> 00:04:05,920
secures consumer data if the
company does not in fact do so.

83
00:04:06,200 --> 00:04:09,670
Under the FTC Act,
unfair acts or practices

84
00:04:09,670 --> 00:04:12,970
are those that cause
or are likely to cause

85
00:04:12,970 --> 00:04:17,260
substantial consumer harm that
is not reasonably avoidable

86
00:04:17,260 --> 00:04:20,050
and is not outweighed by
countervailing benefits

87
00:04:20,050 --> 00:04:23,200
to consumers or competition.

88
00:04:23,200 --> 00:04:26,710
A company's failure to
reasonably secure consumer data

89
00:04:26,710 --> 00:04:28,849
can be an unfair practice.

90
00:04:28,850 --> 00:04:32,720
We also enforce other laws
that require businesses

91
00:04:32,720 --> 00:04:36,460
to reasonably secure
particular types of data

92
00:04:36,460 --> 00:04:37,729
covered by those laws

93
00:04:37,730 --> 00:04:40,470
and the Children's Online
Privacy Protection Act

94
00:04:40,470 --> 00:04:42,640
is one example.

95
00:04:42,640 --> 00:04:43,527
- Jim, thank you.

96
00:04:44,450 --> 00:04:48,570
Part of the industry task
force here is Chris Cronin

97
00:04:48,570 --> 00:04:51,370
a partner with HAYLOCK who
deals with reasonableness,

98
00:04:51,370 --> 00:04:54,530
from the risk managers perspective, Chris.

99
00:04:54,530 --> 00:04:56,119
- Hi, so I'm Chris Cronin.

100
00:04:56,120 --> 00:04:57,230
I'm a partner at HAYLOCK.

101
00:04:57,230 --> 00:05:02,003
As Bill said, I help companies determine

102
00:05:02,880 --> 00:05:05,070
whether or not they're using
reasonable security controls

103
00:05:05,070 --> 00:05:07,700
through risk assessments
and risk management.

104
00:05:07,700 --> 00:05:10,610
And sometimes work with
those organizations

105
00:05:10,610 --> 00:05:12,560
when they have to have conversations

106
00:05:12,560 --> 00:05:15,113
with litigators or regulators.

107
00:05:16,760 --> 00:05:19,020
I've worked with Center
for Internet Security

108
00:05:19,020 --> 00:05:21,390
and Phyllis who you'll be
meeting in a few moments,

109
00:05:21,390 --> 00:05:25,479
to develop the CIS' risk assessment method

110
00:05:25,480 --> 00:05:27,210
that helps people demonstrate

111
00:05:27,210 --> 00:05:29,870
that their security
controls are reasonable.

112
00:05:29,870 --> 00:05:33,640
When I saw that I was defining reasonable

113
00:05:33,640 --> 00:05:35,000
in a way it was very similar,

114
00:05:35,000 --> 00:05:38,980
to some of the work that
people on this call were doing.

115
00:05:38,980 --> 00:05:40,610
It made good sense for us to work together

116
00:05:40,610 --> 00:05:42,210
in the Sedona Conference
to work on the paper

117
00:05:42,210 --> 00:05:43,950
that we're discussing today.

118
00:05:43,950 --> 00:05:45,260
Turns out we had a lot in common,

119
00:05:45,260 --> 00:05:46,789
which Bill will be
talking about in a moment.

120
00:05:46,790 --> 00:05:50,300
But today I'll be playing
the role of one of my clients

121
00:05:50,300 --> 00:05:53,270
who gets into a little trouble
and we'll see how it is

122
00:05:53,270 --> 00:05:55,219
I fare when I use the test.

123
00:05:55,220 --> 00:05:56,350
- Chris thanks.

124
00:05:56,350 --> 00:05:58,600
And finally, meet Phyllis Lee,

125
00:05:58,600 --> 00:06:01,670
senior director of CIS Control.

126
00:06:01,670 --> 00:06:04,940
Phyllis will represent the
center for internet security

127
00:06:04,940 --> 00:06:07,750
and talk with you about the role it plays

128
00:06:07,750 --> 00:06:10,483
in cybersecurity risk management, Phyllis.

129
00:06:11,660 --> 00:06:13,800
- Hello, my name is Phyllis Lee.

130
00:06:13,800 --> 00:06:15,730
Like everyone's mentioned,
I'm the senior director

131
00:06:15,730 --> 00:06:17,860
for the CIS Controls.

132
00:06:17,860 --> 00:06:20,560
If you're unfamiliar, the CIS Controls

133
00:06:20,560 --> 00:06:23,180
our list of activities
supported by safeguards

134
00:06:23,180 --> 00:06:25,550
or sub controls that enterprises

135
00:06:25,550 --> 00:06:27,250
can implement across their networks

136
00:06:27,250 --> 00:06:29,960
in support of their
cyber security program.

137
00:06:29,960 --> 00:06:33,219
The controls and their
corresponding safeguards

138
00:06:33,220 --> 00:06:35,550
are chosen based on
their ability to mitigate

139
00:06:35,550 --> 00:06:39,640
as well as detect the most
common real-world threats,

140
00:06:39,640 --> 00:06:40,909
or cyber attacks.

141
00:06:40,910 --> 00:06:42,980
That is to say, all our controls

142
00:06:42,980 --> 00:06:45,290
are backed by real-world data.

143
00:06:45,290 --> 00:06:48,030
However, even as security experts,

144
00:06:48,030 --> 00:06:50,849
we realize that not all organizations can

145
00:06:50,850 --> 00:06:53,550
or must implement every safeguard.

146
00:06:53,550 --> 00:06:56,210
That's why we provide
a prioritization scheme

147
00:06:56,210 --> 00:06:58,239
called Implementation Groups.

148
00:06:58,240 --> 00:07:00,620
We believe that implementation group one

149
00:07:00,620 --> 00:07:03,760
or basic cyber hygiene,
consists of safeguards

150
00:07:03,760 --> 00:07:06,670
that any and all enterprises
should implement.

151
00:07:06,670 --> 00:07:09,300
Even still, we have to acknowledge

152
00:07:09,300 --> 00:07:11,970
that there may be safeguards in IG1

153
00:07:11,970 --> 00:07:14,230
that an organization will not have to

154
00:07:14,230 --> 00:07:16,220
or be able to implement.

155
00:07:16,220 --> 00:07:18,020
It may also be the case,

156
00:07:18,020 --> 00:07:21,620
where there are additional
safeguards outside of IG1,

157
00:07:21,620 --> 00:07:24,100
that an organization must implement first

158
00:07:24,100 --> 00:07:26,610
due to their risk profile.

159
00:07:26,610 --> 00:07:31,220
This is why we provide the CIS
risk assessment methodology

160
00:07:31,220 --> 00:07:34,580
that we worked on with
Chris at HAYLOCK or CIS RAM.

161
00:07:34,580 --> 00:07:38,991
CIS RAM enables organizations
to use a risk-based approach

162
00:07:38,992 --> 00:07:40,840
of the reasonableness test

163
00:07:40,840 --> 00:07:42,479
which we'll be talking about today.

164
00:07:42,480 --> 00:07:43,313
- Very good.

165
00:07:43,313 --> 00:07:44,800
Thanks Phyllis.

166
00:07:44,800 --> 00:07:48,670
We talked about the task force
and when they reported in,

167
00:07:48,670 --> 00:07:51,680
we were sure of a couple things,

168
00:07:51,680 --> 00:07:54,380
reasonableness was in
fact a common standard

169
00:07:54,380 --> 00:07:56,600
in data security for the industry

170
00:07:56,600 --> 00:07:58,310
for statutes and regulations

171
00:07:58,310 --> 00:08:01,020
and for the handling of legal claims.

172
00:08:01,020 --> 00:08:05,979
And determining reasonableness
was in fact elusive.

173
00:08:05,980 --> 00:08:08,920
But we also discovered
widespread familiarity

174
00:08:08,920 --> 00:08:11,540
with cost benefit analysis.

175
00:08:11,540 --> 00:08:15,530
We reacquainted ourselves
with an old piece of algebra,

176
00:08:15,530 --> 00:08:19,349
first stated by an influential
judge named Learned Hand,

177
00:08:19,350 --> 00:08:21,400
and that's his real name.

178
00:08:21,400 --> 00:08:23,979
Judge Hand invented a cost benefit formula

179
00:08:23,980 --> 00:08:27,820
for assessing reasonableness
in a litigation context.

180
00:08:27,820 --> 00:08:31,370
And we found it out, well
we decided judge Hand

181
00:08:31,370 --> 00:08:36,370
consideration of only the
financial burden on the defendant,

182
00:08:36,620 --> 00:08:39,712
for us we call that person,
the information steward.

183
00:08:40,730 --> 00:08:44,080
Only the financial burden
of adding the control,

184
00:08:44,080 --> 00:08:48,010
and on the other hand,
the loss to the claimant

185
00:08:48,010 --> 00:08:52,840
from the absence of the
control was missing something.

186
00:08:52,840 --> 00:08:57,040
What was missing we decided
was what we called Utility,

187
00:08:57,040 --> 00:09:01,560
namely, any benefit that the
unimproved conduct at risk

188
00:09:01,560 --> 00:09:03,959
created for others.

189
00:09:03,960 --> 00:09:07,900
A hospital's utility for
example is healing patients.

190
00:09:07,900 --> 00:09:11,500
A school's utility is educating students.

191
00:09:11,500 --> 00:09:15,240
Having that utility and
trying to increase it

192
00:09:15,240 --> 00:09:17,520
are why we take risks with information

193
00:09:17,520 --> 00:09:19,540
and systems to begin with.

194
00:09:19,540 --> 00:09:22,900
So the others that we
thought were important

195
00:09:22,900 --> 00:09:26,490
included the public, other constituencies

196
00:09:26,490 --> 00:09:28,270
and even the claim.

197
00:09:28,270 --> 00:09:30,689
We added utility to the burden side

198
00:09:30,690 --> 00:09:33,050
of the cost benefit analysis.

199
00:09:33,050 --> 00:09:35,550
At the end, the entire
working group was comfortable

200
00:09:35,550 --> 00:09:40,077
proposing a test for reasonableness
that reads as follows,

201
00:09:40,077 --> 00:09:43,310
"An information stewards
information security controls

202
00:09:43,310 --> 00:09:47,209
for personal information,
are not reasonable

203
00:09:47,210 --> 00:09:51,240
when implementation of
one or more additional

204
00:09:51,240 --> 00:09:54,640
and or different controls would burden

205
00:09:54,640 --> 00:09:59,400
the information steward
and others by less than,

206
00:09:59,400 --> 00:10:02,360
the implementation of such
controls would benefit

207
00:10:02,360 --> 00:10:04,800
the claimant and others.

208
00:10:04,800 --> 00:10:07,760
And viewed graphically as you can see,

209
00:10:07,760 --> 00:10:10,120
the test looks like this.

210
00:10:10,120 --> 00:10:13,253
And if you're familiar
with Judge Hands decision,

211
00:10:14,110 --> 00:10:17,003
this is very similar to
what he came up with.

212
00:10:18,160 --> 00:10:21,610
So, to try to make all this concrete,

213
00:10:21,610 --> 00:10:25,540
we're going next to a
hypothetical breach case

214
00:10:25,540 --> 00:10:29,719
where the hacking was enabled
by the failure of one control

215
00:10:29,720 --> 00:10:32,573
and arguably by the abscence of another.

216
00:10:33,550 --> 00:10:36,870
Once we present it, our
panel we'll talk about

217
00:10:36,870 --> 00:10:39,360
providing their different perspectives

218
00:10:39,360 --> 00:10:43,510
about how the task can be used
to determine reasonableness.

219
00:10:43,510 --> 00:10:45,253
So here's the hypothetical.

220
00:10:46,190 --> 00:10:50,590
A social media health
app collects health data

221
00:10:50,590 --> 00:10:52,963
and diaries from senior citizens.

222
00:10:53,970 --> 00:10:56,570
The data comes from wearable devices

223
00:10:56,570 --> 00:10:59,853
and from the web browsers
on the user's computers.

224
00:11:00,710 --> 00:11:04,110
The app recommends
changes in user's habits

225
00:11:04,110 --> 00:11:07,120
based on the health improvements it sees

226
00:11:07,120 --> 00:11:08,783
in the user database.

227
00:11:09,910 --> 00:11:13,600
Hackers appear to have
acquired the user's credentials

228
00:11:13,600 --> 00:11:16,400
by fishing the users.

229
00:11:16,400 --> 00:11:20,423
The app did not use,
Multi-factor Authentication.

230
00:11:21,290 --> 00:11:25,219
The hackers have grabbed most
of the health apps user data

231
00:11:25,220 --> 00:11:27,803
and have sold it on the dark web.

232
00:11:28,690 --> 00:11:31,080
And the fraudsters who bought the data

233
00:11:31,080 --> 00:11:35,530
are now using it, either to
exploit what they already have

234
00:11:35,530 --> 00:11:40,530
or to target the health apps
users, for additional scams.

235
00:11:41,070 --> 00:11:43,190
So that's the hypothetical.

236
00:11:43,190 --> 00:11:47,350
And again, what we're going
to do is bring to bear

237
00:11:47,350 --> 00:11:51,350
the expertise of all of our
panelist to talk about it.

238
00:11:51,350 --> 00:11:53,410
And talk about it in light of this test.

239
00:11:53,410 --> 00:11:55,350
So let's start with Phyllis,

240
00:11:55,350 --> 00:11:59,300
just how important Phyllis, is
Multi-factor Authentication?

241
00:11:59,300 --> 00:12:02,630
Does CIS for example, have
any guidance for us on that?

242
00:12:02,630 --> 00:12:03,689
- Yeah great, thank you.

243
00:12:03,690 --> 00:12:06,140
Yeah, so most users are familiar

244
00:12:06,140 --> 00:12:09,670
with authenticating via
username and password.

245
00:12:09,670 --> 00:12:12,189
MFA or Multi-factor Authentication

246
00:12:12,190 --> 00:12:14,730
adds an additional layer
of protection and security

247
00:12:14,730 --> 00:12:16,810
against one of the most common attacks,

248
00:12:16,810 --> 00:12:21,810
which we just heard about, which
is compromised credentials.

249
00:12:21,810 --> 00:12:24,560
In fact, Google reported recently

250
00:12:24,560 --> 00:12:29,270
that MFA prevents more than
96% of bulk phishing attempts

251
00:12:29,270 --> 00:12:33,569
as well as more than
76% of targeted attacks.

252
00:12:33,570 --> 00:12:37,640
So due to this overwhelming
data about the efficacy of MFA

253
00:12:37,640 --> 00:12:40,040
to defend against cyber attacks,

254
00:12:40,040 --> 00:12:44,420
we updated Controls version
8 being released this week

255
00:12:44,420 --> 00:12:47,800
to support the latest research on MFA.

256
00:12:47,800 --> 00:12:51,479
So for example, our updated
password policy guidance

257
00:12:51,480 --> 00:12:54,180
is going to say you can use
an eight character password,

258
00:12:54,180 --> 00:12:56,969
as long as you're using MFA.

259
00:12:56,970 --> 00:12:59,230
The studies have shown
that having long passwords

260
00:12:59,230 --> 00:13:02,390
really don't provide you any
more randomness or entropy

261
00:13:02,390 --> 00:13:05,949
and users fall into
bad password practices.

262
00:13:05,950 --> 00:13:07,910
That's why MFA's better.

263
00:13:07,910 --> 00:13:11,530
Additionally, we're going
to, we have safeguards

264
00:13:11,530 --> 00:13:13,410
that say MFA should be used

265
00:13:13,410 --> 00:13:15,510
for internet facing applications,

266
00:13:15,510 --> 00:13:17,640
similar to what this health app would be,

267
00:13:17,640 --> 00:13:19,720
as well as given the pandemic

268
00:13:19,720 --> 00:13:21,730
and our current working conditions

269
00:13:21,730 --> 00:13:25,800
MFA should be required
for remote network access.

270
00:13:25,800 --> 00:13:27,949
Additionally, training is always important

271
00:13:27,950 --> 00:13:30,480
and we've updated our guidance to include

272
00:13:30,480 --> 00:13:33,110
training the workforce on MFA.

273
00:13:33,110 --> 00:13:37,600
I would say we had an editorial
panel of around 20 folks

274
00:13:37,600 --> 00:13:39,520
security experts and everyone touted

275
00:13:39,520 --> 00:13:44,510
the importance of MFA being
implemented across the networks.

276
00:13:44,510 --> 00:13:47,439
- Let me ask a real
quick follow-up Phyllis,

277
00:13:47,440 --> 00:13:52,440
what about cost, is MFA really expensive?

278
00:13:52,480 --> 00:13:56,970
Is it modestly expensive or is
it not very expensive at all?

279
00:13:56,970 --> 00:14:00,280
- So it really depends on how
you choose to implement it.

280
00:14:00,280 --> 00:14:03,329
MFA is something you
have, something you know

281
00:14:03,330 --> 00:14:04,900
and something you are.

282
00:14:04,900 --> 00:14:07,439
So that includes your
password, which of course,

283
00:14:07,440 --> 00:14:11,050
everyone is used to
authenticating with today.

284
00:14:11,050 --> 00:14:15,829
Additionally, MFA has provided free

285
00:14:15,830 --> 00:14:17,810
by some service providers such as Google.

286
00:14:17,810 --> 00:14:22,500
So for example, they can email
you an additional password

287
00:14:22,500 --> 00:14:27,140
or you could get a text
message via your cell SMS

288
00:14:27,140 --> 00:14:30,480
to provide you an additional
MFA authentication code.

289
00:14:30,480 --> 00:14:32,900
Or it can get pricey
where you will actually

290
00:14:32,900 --> 00:14:35,510
have a separate hardware token

291
00:14:35,510 --> 00:14:38,730
and that's how you will get access to data

292
00:14:38,730 --> 00:14:40,450
or to an additional application.

293
00:14:40,450 --> 00:14:42,330
So it really runs the gamut.

294
00:14:42,330 --> 00:14:45,970
There are pluses and minuses,
as far as security goes.

295
00:14:45,970 --> 00:14:47,410
For some of the different solutions,

296
00:14:47,410 --> 00:14:50,949
however, we do believe strongly that MFA,

297
00:14:50,950 --> 00:14:54,340
even the ones that perhaps some folks

298
00:14:54,340 --> 00:14:56,530
would consider less secure is better

299
00:14:56,530 --> 00:14:58,089
than just username and password.

300
00:14:58,090 --> 00:15:00,270
So we do believe that it's achievable

301
00:15:00,270 --> 00:15:02,390
for most organizations.

302
00:15:02,390 --> 00:15:03,370
- All right, thanks.

303
00:15:03,370 --> 00:15:08,370
Chris, I don't plan to call
on everybody separately

304
00:15:08,820 --> 00:15:11,550
from this point forward but
I do wanted to look to you

305
00:15:11,550 --> 00:15:15,180
next at least, we're going to assume

306
00:15:15,180 --> 00:15:18,780
that you are the consultant
to the app builders,

307
00:15:18,780 --> 00:15:20,439
so to speak.

308
00:15:20,440 --> 00:15:23,460
What do you have to say
about the suggestion,

309
00:15:23,460 --> 00:15:26,440
that Multi-factor Authentication,

310
00:15:26,440 --> 00:15:27,880
really should have been used here?

311
00:15:27,880 --> 00:15:31,890
- Yeah well, yeah and to prevent myself

312
00:15:31,890 --> 00:15:33,956
from playing too many roles,

313
00:15:33,956 --> 00:15:35,620
I'm gonna put myself in the position

314
00:15:35,620 --> 00:15:38,270
of the actual application architect here.

315
00:15:38,270 --> 00:15:40,884
And I'm gonna act as normally

316
00:15:40,884 --> 00:15:42,810
the position my clients are in.

317
00:15:42,810 --> 00:15:44,587
I'll say, everything I'm saying now

318
00:15:44,587 --> 00:15:47,290
I see people having challenges like this.

319
00:15:47,290 --> 00:15:50,130
But in the case of this hypothetical,

320
00:15:50,130 --> 00:15:52,810
the application that we just described,

321
00:15:52,810 --> 00:15:55,077
it's a health tracking app

322
00:15:55,077 --> 00:15:58,730
and it's very useful for our customers.

323
00:15:58,730 --> 00:16:01,530
And what they do is they wear a watch

324
00:16:01,530 --> 00:16:04,233
and they got a desktop
application they can use

325
00:16:04,233 --> 00:16:08,130
with their browser and it's taking,

326
00:16:08,130 --> 00:16:11,660
their watch is taking vital
health information from them

327
00:16:11,660 --> 00:16:13,510
and sending the data up

328
00:16:13,510 --> 00:16:16,310
and then allowing algorithms to work.

329
00:16:16,310 --> 00:16:18,060
And then values comes back.

330
00:16:18,060 --> 00:16:20,569
So it says, "Hey, we're noticing
your blood pressure's up.

331
00:16:20,570 --> 00:16:21,530
And we're also noticing

332
00:16:21,530 --> 00:16:23,920
that you're very active before bedtime.

333
00:16:23,920 --> 00:16:25,199
Why don't you take 90 minutes,

334
00:16:25,200 --> 00:16:27,310
because it seems to be
working for everyone else."

335
00:16:27,310 --> 00:16:29,780
They take 90 minutes
before bedtime to relax,

336
00:16:29,780 --> 00:16:31,260
their blood pressure improves.

337
00:16:31,260 --> 00:16:34,550
So there's a lot of
health benefit to people.

338
00:16:34,550 --> 00:16:37,240
The challenge that we had with
Multi-factor Authentication,

339
00:16:37,240 --> 00:16:41,470
why it's not on the
application, is because,

340
00:16:41,470 --> 00:16:44,150
we had difficulty with
our implementation of it.

341
00:16:44,150 --> 00:16:45,689
It slowed stuff down.

342
00:16:45,690 --> 00:16:49,250
And the method we were
using was a soft cert

343
00:16:49,250 --> 00:16:51,093
on the watch device.

344
00:16:52,110 --> 00:16:56,780
And it was causing difficulty,
approving and affirming

345
00:16:56,780 --> 00:16:59,319
that the user was who they were.

346
00:16:59,320 --> 00:17:01,680
Our red team was also able to subvert

347
00:17:01,680 --> 00:17:04,750
the use of the soft certs on the browser.

348
00:17:04,750 --> 00:17:07,010
So we weren't really
happy with that solution

349
00:17:07,010 --> 00:17:10,980
and we removed it, but we
replaced it with something else

350
00:17:10,980 --> 00:17:13,440
where the seniors could use a gesture

351
00:17:13,440 --> 00:17:15,140
on their watch to validate the STEM.

352
00:17:15,140 --> 00:17:18,210
So they're ready to start their day,

353
00:17:18,210 --> 00:17:20,540
they have a gesture that
they put on their watch

354
00:17:20,540 --> 00:17:23,190
and then they move forward with their day.

355
00:17:23,190 --> 00:17:26,593
But we found that, reduced
usability quite a lot,

356
00:17:28,326 --> 00:17:29,810
a large percentage of our users

357
00:17:29,810 --> 00:17:31,100
stopped using the application,

358
00:17:31,100 --> 00:17:32,610
stopped getting the utility of it,

359
00:17:32,610 --> 00:17:34,780
stopped getting the benefit of it.

360
00:17:34,780 --> 00:17:37,120
So we realized that wasn't a solution.

361
00:17:37,120 --> 00:17:40,223
So then we turned to CIS and
said, "What else can we do?

362
00:17:41,280 --> 00:17:44,480
So what other alternatives do we have?"

363
00:17:44,480 --> 00:17:46,690
That's my question now to Phyllis.

364
00:17:46,690 --> 00:17:47,523
- Yeah sure.

365
00:17:47,523 --> 00:17:51,770
So there's something called
Risk-based Authentication.

366
00:17:51,770 --> 00:17:55,430
And so you'll see that many
applications do this already.

367
00:17:55,430 --> 00:17:59,460
So for example, if you were to
log in to your bank account,

368
00:17:59,460 --> 00:18:01,110
many of us do online banking,

369
00:18:01,110 --> 00:18:03,270
typically it's with username and password.

370
00:18:03,270 --> 00:18:05,580
I use my same device every day.

371
00:18:05,580 --> 00:18:07,960
If for some reason I updated my device

372
00:18:07,960 --> 00:18:10,870
with a patch or I
decided I was on vacation

373
00:18:10,870 --> 00:18:15,870
and I was using, a library
workstation, the app will,

374
00:18:16,580 --> 00:18:18,297
most likely the banking
app will say to me,

375
00:18:18,297 --> 00:18:21,410
"Hey this is, an unrecognized device.

376
00:18:21,410 --> 00:18:23,860
I wanna verify that this is really you.

377
00:18:23,860 --> 00:18:26,959
How would you like to get
your additional access code?

378
00:18:26,960 --> 00:18:30,530
Via email, via text or via voice?"

379
00:18:30,530 --> 00:18:33,270
Whatever data you put in,

380
00:18:33,270 --> 00:18:34,770
when you first set up your bank account,

381
00:18:34,770 --> 00:18:36,340
it'll prompt you for that.

382
00:18:36,340 --> 00:18:38,659
And then I can respond accordingly

383
00:18:38,660 --> 00:18:41,800
and then I will get my
additional access code

384
00:18:41,800 --> 00:18:43,149
and I can type that in.

385
00:18:43,150 --> 00:18:47,420
Many applications do this,
either via perhaps time of day.

386
00:18:47,420 --> 00:18:50,610
They note when you are
actually using the application

387
00:18:50,610 --> 00:18:53,949
or area code or location
device, et cetera.

388
00:18:53,950 --> 00:18:55,330
- Okay, that's very helpful.

389
00:18:55,330 --> 00:18:57,659
So then what I do is I take that idea

390
00:18:57,660 --> 00:19:00,520
and I put it into my
risk assessment method

391
00:19:00,520 --> 00:19:03,200
to see if the alternative
you just described

392
00:19:03,200 --> 00:19:05,027
gives me a reasonable level of security.

393
00:19:05,027 --> 00:19:10,027
And CIS RAM evaluates the
reasonableness of security

394
00:19:10,080 --> 00:19:12,360
in a way that's very similar to the test

395
00:19:12,360 --> 00:19:14,510
and the Sedona Conference.

396
00:19:14,510 --> 00:19:17,379
But while I have no
Multi-factor Authentication,

397
00:19:17,380 --> 00:19:21,423
I removed it because seniors
weren't using the gestures,

398
00:19:22,650 --> 00:19:25,680
I got hacked and there were complaints.

399
00:19:25,680 --> 00:19:27,970
And that's when I heard from Jim.

400
00:19:27,970 --> 00:19:32,290
- Indeed, and I was
remiss in my introduction.

401
00:19:32,290 --> 00:19:36,060
I do need to state that views
I express today are my own

402
00:19:36,060 --> 00:19:39,399
and not necessarily those of
the Federal Trade Commission

403
00:19:39,400 --> 00:19:41,350
or any of the individual commissioners.

404
00:19:42,580 --> 00:19:45,770
This is a scenario where Chris

405
00:19:45,770 --> 00:19:50,317
would be likely to hear from the FTC.

406
00:19:51,760 --> 00:19:55,510
And one of the reasons for
that is we're talking about

407
00:19:56,530 --> 00:20:01,530
health related data that in
the FTCs view is going to be,

408
00:20:03,620 --> 00:20:08,620
on the continuum of requiring,

409
00:20:09,110 --> 00:20:12,350
potentially requiring
heightened protection

410
00:20:12,350 --> 00:20:14,360
because of the sensitivity of the data

411
00:20:14,360 --> 00:20:19,360
and the harm that can cause,
can be caused to consumers,

412
00:20:20,110 --> 00:20:25,040
if the data is breached in some way.

413
00:20:25,040 --> 00:20:30,040
It also stood out to me that,
the discussion has indicated

414
00:20:30,370 --> 00:20:35,370
that a lot of seniors are
using this particular app.

415
00:20:35,780 --> 00:20:39,270
And one of the consequences of the breach

416
00:20:39,270 --> 00:20:41,220
that has been noted is that the seniors

417
00:20:41,220 --> 00:20:46,220
have been subjected to
particular types of scams.

418
00:20:48,190 --> 00:20:53,070
The app developers knowledge,
that it's user based

419
00:20:53,070 --> 00:20:57,870
included a substantial
percentage of seniors

420
00:20:57,870 --> 00:21:00,330
is gonna raise questions in the FTCs mind

421
00:21:00,330 --> 00:21:05,330
about how the app developer accounted

422
00:21:05,760 --> 00:21:08,660
for that characteristic of its user base

423
00:21:08,660 --> 00:21:13,660
in assessing risks including
the risk of not having

424
00:21:14,060 --> 00:21:17,373
Multi-factor Authentication.

425
00:21:18,610 --> 00:21:21,469
And we've seen based on the fact pattern

426
00:21:21,470 --> 00:21:23,360
that's been described that this data

427
00:21:23,360 --> 00:21:27,669
is actually on the dark web.

428
00:21:27,670 --> 00:21:31,780
So we're going to have concerns

429
00:21:31,780 --> 00:21:36,160
about significant harm being caused.

430
00:21:36,160 --> 00:21:38,620
That said, I wanna stress
that the mere occurrence

431
00:21:38,620 --> 00:21:40,770
of the breach does not necessarily mean

432
00:21:40,770 --> 00:21:42,830
that the commission would conclude

433
00:21:42,830 --> 00:21:47,830
that the app developer failed
to employ reasonable security

434
00:21:48,950 --> 00:21:52,830
to determine whether the app developer

435
00:21:52,830 --> 00:21:56,169
did fail to act reasonably.

436
00:21:56,170 --> 00:22:00,690
The FTC would ask
questions designed to learn

437
00:22:00,690 --> 00:22:05,260
why the app developer didn't use MFA.

438
00:22:05,260 --> 00:22:09,750
We would want to consider whether
it is an industry standard

439
00:22:09,750 --> 00:22:12,120
or custom to use MFA.

440
00:22:12,120 --> 00:22:14,689
And, in drilling down on that,

441
00:22:14,690 --> 00:22:18,080
again we're gonna
consider the type of data

442
00:22:18,080 --> 00:22:23,080
that's at issue here and
are going to be looking

443
00:22:24,150 --> 00:22:28,050
for the app developers risk analysis

444
00:22:28,050 --> 00:22:33,050
to have accounted for the
sensitivity of the data.

445
00:22:33,670 --> 00:22:36,980
We would also wanna know
why the app developer

446
00:22:36,980 --> 00:22:40,720
and how the app developer
decided that the use of soft cert

447
00:22:40,720 --> 00:22:42,630
would be a suitable alternative

448
00:22:42,630 --> 00:22:46,330
to manual Multi-factor Authentication

449
00:22:46,330 --> 00:22:50,240
and would ask questions
designed to assess,

450
00:22:50,240 --> 00:22:52,740
whether the app developers decision

451
00:22:52,740 --> 00:22:56,040
to rely on the soft cert was reasonable.

452
00:22:56,040 --> 00:22:59,560
Then because Chris has
mentioned that a pen test showed

453
00:22:59,560 --> 00:23:01,740
a vulnerability with the soft cert,

454
00:23:01,740 --> 00:23:05,240
we're gonna wanna know what, if anything,

455
00:23:05,240 --> 00:23:09,953
the app developer did to
address the vulnerability

456
00:23:09,953 --> 00:23:12,260
with respect to the soft cert

457
00:23:12,260 --> 00:23:15,013
instead of just turning it off.

458
00:23:15,970 --> 00:23:20,970
Including for example whether,
and what the analysis was

459
00:23:23,260 --> 00:23:25,760
when the app developer
considered things like

460
00:23:25,760 --> 00:23:27,993
enhanced monitoring of log-ins.

461
00:23:30,000 --> 00:23:33,240
Perhaps consideration of doing things

462
00:23:33,240 --> 00:23:35,600
like monitoring the IP addresses

463
00:23:35,600 --> 00:23:37,350
from which logins were occurring

464
00:23:37,350 --> 00:23:41,240
or limiting the number
of logins per IP address.

465
00:23:41,240 --> 00:23:44,990
As Phyllis indicated,
there are a number of ways

466
00:23:44,990 --> 00:23:49,990
of getting at, what as
Phyllis described are,

467
00:23:50,100 --> 00:23:55,100
very well-known risks having to do

468
00:23:55,410 --> 00:23:57,780
with compromised credentials.

469
00:23:57,780 --> 00:24:01,970
And running into a
problem with one control

470
00:24:01,970 --> 00:24:06,860
that was put in place,
doesn't alleviate the need

471
00:24:06,860 --> 00:24:08,919
to make sure that those risks

472
00:24:08,920 --> 00:24:12,450
are still being addressed
in a reasonable way.

473
00:24:12,450 --> 00:24:16,470
And having a long-term plan
for addressing the risks,

474
00:24:16,470 --> 00:24:19,410
doesn't alleviate the
need to address the risks

475
00:24:19,410 --> 00:24:20,870
in the short term.

476
00:24:20,870 --> 00:24:22,489
So we'll have a lot of questions

477
00:24:22,490 --> 00:24:26,580
to ask Chris on the app developer.

478
00:24:26,580 --> 00:24:29,668
- Jim, let me jump in
and ask a question of you

479
00:24:29,669 --> 00:24:34,347
because we're there in
the presentation so far.

480
00:24:35,237 --> 00:24:38,290
And you helped develop this test

481
00:24:38,290 --> 00:24:40,240
that the Sedona Conference came up with.

482
00:24:40,240 --> 00:24:44,540
In your view, does this test help,

483
00:24:44,540 --> 00:24:46,870
either the FTC or in this case,

484
00:24:46,870 --> 00:24:49,300
the app developer or both of them

485
00:24:49,300 --> 00:24:53,810
communicate with one another
about whether the work

486
00:24:53,810 --> 00:24:56,423
by the app developer was reasonable?

487
00:24:57,870 --> 00:25:02,870
- It does, to the extent
that the test makes it clear

488
00:25:03,850 --> 00:25:07,080
that cost benefit analysis,

489
00:25:07,080 --> 00:25:11,570
is the way to assess reasonableness.

490
00:25:11,570 --> 00:25:15,970
And it makes it clear
as from my perspective,

491
00:25:15,970 --> 00:25:17,650
I think it's always been clear

492
00:25:17,650 --> 00:25:20,510
that reasonableness is not the same thing

493
00:25:20,510 --> 00:25:25,404
as strict liability for having
a breach as I mentioned.

494
00:25:25,404 --> 00:25:30,404
And it's not, it doesn't presume that,

495
00:25:34,630 --> 00:25:39,630
all potential further investments
in security are warranted

496
00:25:43,560 --> 00:25:47,970
in order to act reasonably.

497
00:25:47,970 --> 00:25:52,373
Where I think I differed
from some of the people

498
00:25:53,570 --> 00:25:56,000
that were part of this
collaborative process is,

499
00:25:56,000 --> 00:25:57,930
I start from a different premise

500
00:25:57,930 --> 00:26:02,310
that I believe that there are many

501
00:26:02,310 --> 00:26:06,340
external markers of reasonableness

502
00:26:07,290 --> 00:26:10,853
such as industry standards,
best practice recommendations,

503
00:26:11,690 --> 00:26:15,810
guidance that is published by
Civil Law Enforcement Agencies

504
00:26:15,810 --> 00:26:18,139
or regulatory agencies like the FTC,

505
00:26:18,140 --> 00:26:20,580
state attorneys general offices,

506
00:26:20,580 --> 00:26:24,449
organizations like the
Center for Internet Security.

507
00:26:24,450 --> 00:26:28,140
And there actually is
substantial commonality

508
00:26:28,140 --> 00:26:30,950
in all of that guidance in terms of

509
00:26:30,950 --> 00:26:34,200
what types of risks should be addressed.

510
00:26:34,200 --> 00:26:37,150
What there is not, and what
I don't think there can be,

511
00:26:37,150 --> 00:26:40,510
and I think the Sedona test,
the Sedona proposed test

512
00:26:40,510 --> 00:26:43,990
is consistent with this view is that,

513
00:26:43,990 --> 00:26:46,200
that can't boil down to a checklist

514
00:26:46,200 --> 00:26:50,040
of telling everybody
who is collecting data

515
00:26:50,940 --> 00:26:52,440
that you should implement

516
00:26:52,440 --> 00:26:55,290
this particular control
in your environment.

517
00:26:55,290 --> 00:26:58,280
It's always going to be
about the sensitivity

518
00:26:58,280 --> 00:27:01,430
of the data that's being collected.

519
00:27:01,430 --> 00:27:06,200
The nature of the particular
businesses, operations

520
00:27:08,110 --> 00:27:12,139
and the complexity of its data operations,

521
00:27:12,140 --> 00:27:16,290
as well as the cost and
availability of tools

522
00:27:17,390 --> 00:27:21,693
to reduce known risks.

523
00:27:23,630 --> 00:27:28,630
But I think that any discourse
that the Sedona Conference

524
00:27:29,510 --> 00:27:34,510
can advance on
reasonableness is warranted.

525
00:27:34,640 --> 00:27:37,980
One other thing I want to mention briefly

526
00:27:37,980 --> 00:27:41,680
is that I also differ a little bit

527
00:27:41,680 --> 00:27:46,680
with some of my colleagues who were

528
00:27:47,740 --> 00:27:51,190
part of the drafting team
for the Sedona Paper.

529
00:27:51,190 --> 00:27:54,180
And by colleagues, I
mean non FTC colleagues,

530
00:27:54,180 --> 00:27:59,180
in that the reasonableness test,

531
00:27:59,910 --> 00:28:02,320
when it comes to what
is an unfair practice

532
00:28:02,320 --> 00:28:06,379
under the FTC Act, I don't
think has been difficult

533
00:28:06,380 --> 00:28:10,170
to ascertain that the statute sets forth

534
00:28:11,250 --> 00:28:13,716
the particular criteria that I mentioned

535
00:28:13,716 --> 00:28:16,209
in my opening remarks.

536
00:28:16,210 --> 00:28:20,630
And that's going to be the
criteria that the FTC evaluates

537
00:28:20,630 --> 00:28:23,140
or that a court is going to evaluate

538
00:28:23,140 --> 00:28:28,140
in determining whether a business entity

539
00:28:28,750 --> 00:28:31,500
has committed an unfair practice

540
00:28:31,500 --> 00:28:35,310
by having unreasonable
data security practices.

541
00:28:35,310 --> 00:28:36,960
- All right.

542
00:28:36,960 --> 00:28:40,193
Chris, I'm gonna turn briefly back to you.

543
00:28:41,140 --> 00:28:45,023
We've heard, or you've
heard now, from the FTC,

544
00:28:45,920 --> 00:28:48,010
they're interested in what's going on.

545
00:28:48,010 --> 00:28:50,523
They want to have a conversation with you,

546
00:28:51,510 --> 00:28:54,710
perhaps this is a moment
where you engage David.

547
00:28:54,710 --> 00:28:56,990
- You bet, you bet and
he's been very successful

548
00:28:56,990 --> 00:28:58,260
at defending people in my spot.

549
00:28:58,260 --> 00:28:59,960
So I'm not gonna say another word.

550
00:29:01,930 --> 00:29:04,120
- All right, well, I think
it's my turn to chime in,

551
00:29:04,120 --> 00:29:04,953
it sounds like.

552
00:29:06,088 --> 00:29:08,240
Yeah, so I come at this
from the perspective

553
00:29:08,240 --> 00:29:11,690
of a defense attorney who is charged

554
00:29:11,690 --> 00:29:14,989
with defending the reasonableness

555
00:29:14,989 --> 00:29:18,210
of our clients security measures.

556
00:29:18,210 --> 00:29:22,750
And thinking about this
in terms of the test

557
00:29:22,750 --> 00:29:25,170
that the Sedona Conference put out,

558
00:29:25,170 --> 00:29:30,110
that balances the costs of
the proposed security measure

559
00:29:30,110 --> 00:29:31,862
versus the benefits.

560
00:29:33,767 --> 00:29:36,630
So let's talk about that in the context

561
00:29:36,630 --> 00:29:41,390
of this particular hypothetical
and what I would say is,

562
00:29:43,030 --> 00:29:47,410
it's really critical for
me as a defense lawyer,

563
00:29:47,410 --> 00:29:51,520
to help make sure that
whether it's a regulator

564
00:29:51,520 --> 00:29:56,520
or plaintiff's lawyers, that the benefits

565
00:29:56,960 --> 00:30:00,160
of this proposed measure
are not being overstated.

566
00:30:00,160 --> 00:30:03,850
And also that the costs
are not being understated.

567
00:30:03,850 --> 00:30:05,409
So let's think about the benefits.

568
00:30:05,410 --> 00:30:07,880
Here it's, the proposed measure

569
00:30:07,880 --> 00:30:11,003
that's being thrown out there is MFA.

570
00:30:12,260 --> 00:30:16,210
And even if there are benefits to MFA,

571
00:30:16,210 --> 00:30:18,550
in the sense of lowering the risk,

572
00:30:18,550 --> 00:30:23,360
that this personal
information could be stolen,

573
00:30:23,360 --> 00:30:26,959
it's important not to
overstate those risks.

574
00:30:26,960 --> 00:30:31,700
In particular, you have to look
at what measures the company

575
00:30:31,700 --> 00:30:35,150
already had in place, which
forms kind of the baseline.

576
00:30:35,150 --> 00:30:40,050
And it's not as if companies never have,

577
00:30:40,050 --> 00:30:41,520
don't have anything in place,

578
00:30:41,520 --> 00:30:45,100
they already have substantial
measures in most cases.

579
00:30:45,100 --> 00:30:47,300
And in this case, Chris mentioned

580
00:30:47,300 --> 00:30:52,300
that the company already had
a soft cert security measure

581
00:30:54,800 --> 00:30:56,853
that was in place at least for a time.

582
00:30:57,930 --> 00:31:02,050
And so the question is, how much would MFA

583
00:31:02,050 --> 00:31:04,000
really have decreased the risk of that,

584
00:31:04,910 --> 00:31:07,870
that data getting stolen,
when you keep in mind

585
00:31:07,870 --> 00:31:09,800
that the company already had

586
00:31:09,800 --> 00:31:12,510
other security measures in place.

587
00:31:12,510 --> 00:31:16,940
It's not as if the risk,
without MFA was like 100%

588
00:31:16,940 --> 00:31:17,773
or anything like that.

589
00:31:17,773 --> 00:31:20,040
You have to look at what
is the risk without MFA.

590
00:31:20,040 --> 00:31:22,763
Compare that to the risk with MFA.

591
00:31:23,980 --> 00:31:26,983
And then you also have to
think about the fact that,

592
00:31:28,680 --> 00:31:30,420
just because data is stolen,

593
00:31:30,420 --> 00:31:33,070
and I'm sure Jim is gonna
disagree with me on this,

594
00:31:33,070 --> 00:31:37,020
but not every case in which data is stolen

595
00:31:37,020 --> 00:31:39,590
automatically results in consumer harm.

596
00:31:39,590 --> 00:31:43,199
You also have to look at the risk,

597
00:31:43,200 --> 00:31:47,330
what is the likelihood that
after data has been stolen,

598
00:31:47,330 --> 00:31:49,620
that the criminals are going to be able

599
00:31:49,620 --> 00:31:52,409
to successfully misuse that data

600
00:31:52,410 --> 00:31:56,170
and thereby cause harm to consumers.

601
00:31:56,170 --> 00:31:58,020
Now that kind of raises a thorny issue

602
00:31:58,020 --> 00:32:01,620
of what is the definition
of harm, et cetera.

603
00:32:01,620 --> 00:32:04,649
But you have to think about
that, because for instance,

604
00:32:04,650 --> 00:32:06,710
if we're talking about harm in terms of

605
00:32:08,130 --> 00:32:13,130
the hackers scamming these
consumers into losing money,

606
00:32:17,000 --> 00:32:18,070
you have to keep in mind,

607
00:32:18,070 --> 00:32:21,370
they're not always gonna be
successful in doing that.

608
00:32:21,370 --> 00:32:25,169
The risk is not 100%, that the
criminals are gonna be able

609
00:32:25,170 --> 00:32:28,250
to scam consumers into losing money.

610
00:32:28,250 --> 00:32:30,540
So you have to think about,

611
00:32:30,540 --> 00:32:33,113
there has to be a rigorous analysis of,

612
00:32:34,610 --> 00:32:39,459
what is the actual likelihood
of harm, if there's a breach.

613
00:32:39,460 --> 00:32:42,950
And then you also have to look
at the threshold question of

614
00:32:43,840 --> 00:32:47,929
how much would MFA really
have decreased the risk

615
00:32:47,930 --> 00:32:49,440
of the data being stolen?

616
00:32:49,440 --> 00:32:51,980
And until there's been a
really rigorous analysis

617
00:32:51,980 --> 00:32:53,540
of those two questions,

618
00:32:53,540 --> 00:32:56,680
you can't really say what
the benefits of MFA are

619
00:32:56,680 --> 00:32:59,170
for purposes of the test.

620
00:32:59,170 --> 00:33:02,243
And then when you get over to
the cost side of the analysis,

621
00:33:03,780 --> 00:33:06,399
I heard Phyllis mention
that there are costs

622
00:33:06,400 --> 00:33:11,400
associated with MFA and
those cannot be ignored

623
00:33:12,010 --> 00:33:14,540
under the test.

624
00:33:14,540 --> 00:33:18,480
There are all sorts of costs
to be taken into account.

625
00:33:18,480 --> 00:33:22,033
A key one that Chris
mentioned is lost utility.

626
00:33:23,077 --> 00:33:27,990
When consumer, when they had
tried certain forms of MFA

627
00:33:27,990 --> 00:33:30,870
and were considering other forms of MFA,

628
00:33:30,870 --> 00:33:35,870
they realized that having
another factor of authentication

629
00:33:37,400 --> 00:33:40,660
was causing these consumers not to be able

630
00:33:40,660 --> 00:33:44,370
to use the app properly.

631
00:33:44,370 --> 00:33:48,600
And that was a lost
benefit to the consumer

632
00:33:48,600 --> 00:33:51,760
and that lost utility,
both to the consumer

633
00:33:51,760 --> 00:33:55,370
and to the public in terms
of the scientific value

634
00:33:55,370 --> 00:33:58,092
of this data, has to
be taken into account.

635
00:33:58,990 --> 00:34:01,050
There are also costs to the company

636
00:34:01,050 --> 00:34:02,610
that have to be taken into account

637
00:34:02,610 --> 00:34:04,510
that are associated with MFA.

638
00:34:04,510 --> 00:34:07,430
Phyllis, you mentioned
that MFA can be pricey,

639
00:34:07,430 --> 00:34:09,679
depending on how it's implemented, right?

640
00:34:09,679 --> 00:34:13,819
And you have to think not
just about the cost of the,

641
00:34:13,820 --> 00:34:16,620
the out of pocket cost
to obtain the technology,

642
00:34:16,620 --> 00:34:18,380
although that's one of the costs,

643
00:34:18,380 --> 00:34:21,060
but you also have to think
about all the other costs.

644
00:34:21,060 --> 00:34:23,529
You have to think about
the labor costs involved

645
00:34:23,530 --> 00:34:28,530
in maintaining the
technical aspects of MFA.

646
00:34:30,060 --> 00:34:32,400
You have to think about
the customer service

647
00:34:32,400 --> 00:34:35,650
and customer support costs
that are going to arise

648
00:34:35,650 --> 00:34:40,320
from dealing with problems
that consumers have

649
00:34:40,320 --> 00:34:42,530
using the MFA.

650
00:34:42,530 --> 00:34:46,090
You have to think about
lost revenue to the company,

651
00:34:46,090 --> 00:34:50,990
if these consumers are getting
fed up with using the MFA

652
00:34:51,889 --> 00:34:54,370
and just stop using the service.

653
00:34:54,370 --> 00:34:57,529
Keep in mind these are
frequently elderly consumers

654
00:34:57,530 --> 00:35:00,530
who may not be as
technologically sophisticated

655
00:35:00,530 --> 00:35:02,150
as younger consumers.

656
00:35:02,150 --> 00:35:06,590
So all of those costs, in my mind,

657
00:35:06,590 --> 00:35:10,780
especially as defense counsel
have to be taken into account.

658
00:35:10,780 --> 00:35:14,120
And in a, a key role that I would play

659
00:35:14,120 --> 00:35:19,120
is making sure that those
costs are not being understated

660
00:35:19,520 --> 00:35:23,890
and that the benefits of MFA
are not being overstated.

661
00:35:23,890 --> 00:35:26,319
- So, David let me ask a question,

662
00:35:26,320 --> 00:35:28,990
also going back to Chris.
- Yep.

663
00:35:28,990 --> 00:35:33,069
- How would the Sedona Conference
test for reasonableness

664
00:35:33,070 --> 00:35:36,830
facilitate your conversation with Chris,

665
00:35:36,830 --> 00:35:40,390
your client in this case?

666
00:35:40,390 --> 00:35:43,450
And then after that conversation,

667
00:35:43,450 --> 00:35:47,859
how would the test facilitate
your engaging the FTC,

668
00:35:47,860 --> 00:35:51,163
who wants to know all about your client?

669
00:35:52,070 --> 00:35:55,580
- Yeah well I think, one of the
things that's really helpful

670
00:35:55,580 --> 00:35:57,940
about the Sedona test is that

671
00:35:57,940 --> 00:36:02,060
it identifies a lot of the key facts

672
00:36:02,060 --> 00:36:06,957
that need to be developed in
both working with the client

673
00:36:09,180 --> 00:36:14,180
to understand why they had the
measures they had in place,

674
00:36:15,040 --> 00:36:17,404
and didn't have other measures in place.

675
00:36:17,404 --> 00:36:22,400
And understanding how
that can be assessed,

676
00:36:22,400 --> 00:36:24,223
from a reasonableness perspective.

677
00:36:25,400 --> 00:36:27,920
So just for instance, lost utility

678
00:36:27,920 --> 00:36:30,680
that's something that
needs to be investigated.

679
00:36:30,680 --> 00:36:34,683
What loss of subscriber base would occur?

680
00:36:36,249 --> 00:36:37,759
And what difficulty,

681
00:36:37,760 --> 00:36:40,090
what other difficulties
would consumers have

682
00:36:40,090 --> 00:36:41,770
with these additional security measures?

683
00:36:41,770 --> 00:36:43,240
That's something that
needs to be investigated.

684
00:36:43,240 --> 00:36:46,040
And that's something that would,

685
00:36:46,040 --> 00:36:48,712
that in my conversations with Jim,

686
00:36:48,712 --> 00:36:52,759
and if necessary, if it
went into litigation,

687
00:36:52,760 --> 00:36:54,800
the conversations that Jim
and I would both be having

688
00:36:54,800 --> 00:36:59,800
with the court, would
involve those types of facts,

689
00:37:00,010 --> 00:37:03,280
lost utility, other costs, labor
costs, out of pocket costs.

690
00:37:03,280 --> 00:37:07,527
I would be making sure, with
the assistance of the tasks,

691
00:37:11,760 --> 00:37:16,030
the Sedona conference
developed, that I'm pointing out

692
00:37:16,030 --> 00:37:18,660
that these facts matter,
that these facts are relevant

693
00:37:18,660 --> 00:37:21,700
to the test and that they
have to be taken into account.

694
00:37:21,700 --> 00:37:23,549
- So Jim, they come back to you

695
00:37:23,550 --> 00:37:26,800
and they have this presentation

696
00:37:26,800 --> 00:37:28,463
that they'd like to make to you.

697
00:37:29,660 --> 00:37:31,040
And let's just let's suppose

698
00:37:31,040 --> 00:37:35,870
that they begin the conversation
by making this proposition.

699
00:37:35,870 --> 00:37:38,950
Why don't we have our conversation

700
00:37:40,400 --> 00:37:44,660
based on the Sedona Conference
test for reasonableness?

701
00:37:44,660 --> 00:37:49,018
Is that okay with you, Mr. FTC?

702
00:37:49,018 --> 00:37:52,010
- We can certainly have the
conversation on that basis?

703
00:37:52,010 --> 00:37:57,010
And they're, under the task, I
think there is plenty of room

704
00:37:59,340 --> 00:38:04,340
to debate and perhaps come
to different points of view

705
00:38:04,410 --> 00:38:09,330
as to what is a relatively simple task,

706
00:38:11,560 --> 00:38:14,009
goes on which side of the equation.

707
00:38:14,010 --> 00:38:18,420
And, one of the areas where I imagine

708
00:38:18,420 --> 00:38:22,430
we would be having a
fairly robust discussion

709
00:38:22,430 --> 00:38:27,430
is on the sort of loss
of utility arguments

710
00:38:30,870 --> 00:38:35,870
that David highlighted
and how relevant they are

711
00:38:37,710 --> 00:38:42,710
and how much they would
weigh into the FTCs

712
00:38:44,900 --> 00:38:48,500
assessment of reasonableness.

713
00:38:48,500 --> 00:38:51,800
While David seems confident

714
00:38:51,800 --> 00:38:56,800
that there would have been a
substantial loss of utility

715
00:38:59,070 --> 00:39:04,070
because consumers and some
senior consumers in particular

716
00:39:05,500 --> 00:39:10,500
wouldn't have used the
app if MFA were required.

717
00:39:12,070 --> 00:39:15,963
I'm probably gonna have
substantial questions about what,

718
00:39:17,800 --> 00:39:20,840
about the loss of utility by consumers

719
00:39:20,840 --> 00:39:22,530
who never used this app

720
00:39:22,530 --> 00:39:25,970
because they weren't going
to entrust this type of data

721
00:39:25,970 --> 00:39:29,680
to an app that wasn't using MFA.

722
00:39:29,680 --> 00:39:33,220
So my frame of reference
for loss of utility

723
00:39:33,220 --> 00:39:37,270
may be quite different than David's.

724
00:39:37,270 --> 00:39:41,170
And I'm also going to want to know,

725
00:39:41,170 --> 00:39:44,340
whether choices were
presented to consumers

726
00:39:44,340 --> 00:39:46,223
and if so, why not?

727
00:39:47,230 --> 00:39:52,230
And how that factors into,
the general statement

728
00:39:53,800 --> 00:39:57,350
that consumers wouldn't have used the app

729
00:39:57,350 --> 00:40:01,460
and the benefits that
otherwise could have inured

730
00:40:01,460 --> 00:40:06,210
to consumers at large,
wouldn't have occurred

731
00:40:06,210 --> 00:40:11,210
if MFA were part of the app.

732
00:40:11,750 --> 00:40:14,693
And then also, it sounds like we may be,

733
00:40:15,820 --> 00:40:19,340
whatever information the
company may be relying on

734
00:40:19,340 --> 00:40:21,700
to say that there would
have been a loss of utility

735
00:40:21,700 --> 00:40:25,810
may have resulted from
information asymmetries.

736
00:40:25,810 --> 00:40:30,810
Did the company do
anything to warn consumers

737
00:40:31,340 --> 00:40:34,520
about the trade-off from
the company's decision

738
00:40:34,520 --> 00:40:36,053
not to use MFA?

739
00:40:37,203 --> 00:40:40,530
And, did the company revisit that decision

740
00:40:40,530 --> 00:40:44,010
when it determined that
there was a vulnerability

741
00:40:44,010 --> 00:40:48,933
in the soft cert that the
company was relying on,

742
00:40:50,070 --> 00:40:54,050
as a alternative way of addressing

743
00:40:54,050 --> 00:40:59,050
some of the risk associated
with compromised credentials?

744
00:41:01,310 --> 00:41:05,470
So I think, yes that the
framework that's laid out

745
00:41:05,470 --> 00:41:10,470
in the test could help
facilitate a useful discussion.

746
00:41:11,670 --> 00:41:15,350
And I think that the
framework probably is going to

747
00:41:16,220 --> 00:41:21,220
allow for, disparate views to be exchanged

748
00:41:22,340 --> 00:41:26,030
and in terms of what fits where

749
00:41:26,030 --> 00:41:27,840
and how much weight to give to what.

750
00:41:27,840 --> 00:41:30,280
- Okay let me turn to
Phyllis for a second.

751
00:41:30,280 --> 00:41:34,680
And because of something
that Jim has just raised.

752
00:41:34,680 --> 00:41:39,680
Where do we go for data on consumer use

753
00:41:39,990 --> 00:41:43,180
in the face of the presence
or absence of a given control,

754
00:41:43,180 --> 00:41:46,069
such as Multi-factor Authentication?

755
00:41:46,070 --> 00:41:48,670
Is there helpful research out there?

756
00:41:48,670 --> 00:41:51,584
Is there helpful commentary out there?

757
00:41:51,584 --> 00:41:53,180
And is this something that CIS

758
00:41:53,180 --> 00:41:56,230
can help people get a hold of?

759
00:41:56,230 --> 00:41:58,730
- So there's always this tension

760
00:41:58,730 --> 00:42:00,380
between what we would call usability,

761
00:42:00,380 --> 00:42:03,170
which I think we're
referring to as utility here

762
00:42:03,170 --> 00:42:04,180
and security, right.

763
00:42:04,180 --> 00:42:08,616
There's always that tension,
less usable, more secure.

764
00:42:08,617 --> 00:42:11,200
"Why do I have to memorize
a longer password?

765
00:42:11,200 --> 00:42:14,500
Why do I have to get an SMS
message on my cell phone?

766
00:42:14,500 --> 00:42:18,090
I only wanna just do the one
click, buy my Amazon thing."

767
00:42:18,090 --> 00:42:19,690
There's always that tension.

768
00:42:19,690 --> 00:42:20,831
Microsoft did a--

769
00:42:20,831 --> 00:42:22,131
- (indistinct) by the way.

770
00:42:23,990 --> 00:42:26,770
- So Microsoft did do a big study,

771
00:42:26,770 --> 00:42:30,610
arguably, an organization
that has hundreds of millions

772
00:42:30,610 --> 00:42:33,070
if not over a billion
points of, data points

773
00:42:33,070 --> 00:42:36,790
around authentication, authorization,

774
00:42:36,790 --> 00:42:38,810
Multi-factor Authentication.

775
00:42:38,810 --> 00:42:43,549
And they did say that,
you should be using MFA.

776
00:42:43,550 --> 00:42:45,723
Now as far as the usability of it,

777
00:42:47,455 --> 00:42:49,870
they made claims around
of course their product

778
00:42:49,870 --> 00:42:52,740
and the usability of
enabling that in Microsoft.

779
00:42:52,740 --> 00:42:56,689
However, I will say the
data overwhelmingly says,

780
00:42:56,690 --> 00:43:00,960
that MFA is doable and something
that you should implement.

781
00:43:00,960 --> 00:43:05,800
Having said that, I will say,
that when we talked about MFA

782
00:43:06,730 --> 00:43:08,390
in Creating Controls Version 8,

783
00:43:08,390 --> 00:43:11,569
we had representatives
from small organizations

784
00:43:11,570 --> 00:43:14,780
as well as NGOs,
non-government organizations

785
00:43:14,780 --> 00:43:15,957
who are always thinking,

786
00:43:15,957 --> 00:43:18,319
"Well, how am I going to implement this?"

787
00:43:18,320 --> 00:43:21,400
And an example would be,
outside of this case is,

788
00:43:21,400 --> 00:43:23,960
if you're, for example
doing disaster relief

789
00:43:23,960 --> 00:43:25,820
in a third world country,

790
00:43:25,820 --> 00:43:29,920
are you obligated to provide MFA,

791
00:43:29,920 --> 00:43:32,090
if the infrastructure is not there

792
00:43:32,090 --> 00:43:33,840
if all these other things are not there?

793
00:43:33,840 --> 00:43:37,830
And that's not necessarily
usability or utility per se,

794
00:43:37,830 --> 00:43:39,440
well, I guess it is, but it's more,

795
00:43:39,440 --> 00:43:42,680
if you physically cannot do
it because it's not reliable

796
00:43:42,680 --> 00:43:43,710
do you have to do it?

797
00:43:43,710 --> 00:43:47,770
And so what I would say
is, there are some studies

798
00:43:47,770 --> 00:43:50,440
talking about the efficacy of MFA

799
00:43:50,440 --> 00:43:52,453
and some about the usability.

800
00:43:53,410 --> 00:43:56,230
Additionally, I like this
idea around reasonableness

801
00:43:56,230 --> 00:43:58,890
and using also what we have the CIS RAM

802
00:43:58,890 --> 00:44:01,500
where you can document it and really show

803
00:44:01,500 --> 00:44:04,400
why you made the choices that you made

804
00:44:04,400 --> 00:44:06,900
and hopefully make them defensible.

805
00:44:06,900 --> 00:44:11,900
- I really think it has to be assessed,

806
00:44:12,700 --> 00:44:16,100
in terms of the feasibility
and the cost and the benefit.

807
00:44:16,100 --> 00:44:21,100
It has to be, in my mind
on a case by case basis,

808
00:44:21,240 --> 00:44:25,439
based on the specific facts

809
00:44:25,440 --> 00:44:27,573
at the particular company in question.

810
00:44:29,120 --> 00:44:32,160
I think even if there
are studies out there,

811
00:44:32,160 --> 00:44:36,772
that as a general, talking about
the general benefits of MFA

812
00:44:38,020 --> 00:44:41,938
you have to look at the
specific company in question

813
00:44:41,938 --> 00:44:46,400
and find out what feasibility

814
00:44:46,400 --> 00:44:49,100
and cost issues would
they have experienced

815
00:44:49,100 --> 00:44:51,623
based on their particular business.

816
00:44:52,650 --> 00:44:55,190
And also based on how their network,

817
00:44:55,190 --> 00:44:58,700
how their specific network was set up

818
00:44:58,700 --> 00:45:00,620
and how their business operated.

819
00:45:00,620 --> 00:45:05,250
What would the extent of the
benefits of MFA actually be,

820
00:45:05,250 --> 00:45:07,480
when you take into a consideration

821
00:45:07,480 --> 00:45:09,270
the specific security measures

822
00:45:09,270 --> 00:45:11,340
that they already had in place?

823
00:45:11,340 --> 00:45:16,340
So I would, as a defense
lawyer kind of try to make sure

824
00:45:17,090 --> 00:45:19,870
that the conversation is
focused on the specific facts

825
00:45:19,870 --> 00:45:24,390
of the case as much as possible.

826
00:45:24,390 --> 00:45:29,390
- David, on that point, let's say

827
00:45:29,490 --> 00:45:33,640
that you've heard a mouthful
so to speak, from Jim Trilling

828
00:45:33,640 --> 00:45:35,819
how about everybody uses MFA

829
00:45:35,820 --> 00:45:38,270
and why on earth don't you use it?

830
00:45:38,270 --> 00:45:40,990
And so now you turn back to Chris Cronin

831
00:45:40,990 --> 00:45:43,526
and you say to Chris,

832
00:45:43,527 --> 00:45:46,830
"We gotta come up with an answer here."

833
00:45:46,830 --> 00:45:51,290
We got this, the Sedona Conference
test for reasonableness,

834
00:45:51,290 --> 00:45:53,980
does this help us in any way

835
00:45:53,980 --> 00:45:57,660
to counter the arguments of the FTC

836
00:45:57,660 --> 00:46:01,009
that Multi-factor Authentication

837
00:46:01,010 --> 00:46:04,060
was a minimum in this context.

838
00:46:04,060 --> 00:46:05,753
Chris, what do you think?

839
00:46:06,726 --> 00:46:09,200
- In the couple minutes we have left,

840
00:46:09,200 --> 00:46:11,470
what I'll do is quickly say,

841
00:46:11,470 --> 00:46:14,803
to address David's point
about the architecture.

842
00:46:16,100 --> 00:46:19,133
This is based on things
that I've seen in real life.

843
00:46:20,350 --> 00:46:24,160
The application's designed so
that when someone gets access

844
00:46:24,160 --> 00:46:28,200
to an account they can only
see the essential records

845
00:46:28,200 --> 00:46:29,790
of that one account.

846
00:46:29,790 --> 00:46:32,560
And our risk analysis
looked at the possibility

847
00:46:32,560 --> 00:46:35,090
of one account being hijacked.

848
00:46:35,090 --> 00:46:37,010
And we thought that we measured

849
00:46:37,010 --> 00:46:40,070
that one account being
hijacked versus the entire,

850
00:46:40,070 --> 00:46:41,900
well, a significant part of the population

851
00:46:41,900 --> 00:46:44,857
not using the application
with an intrusive MFA.

852
00:46:46,110 --> 00:46:50,660
We did not foresee the risk
of a very large attack,

853
00:46:50,660 --> 00:46:53,299
like what we have in this scenario.

854
00:46:53,300 --> 00:46:58,300
So still using the test, using CIS RAM,

855
00:46:58,340 --> 00:47:00,960
we'd done the risk analysis,

856
00:47:00,960 --> 00:47:03,570
we just didn't actually see what came.

857
00:47:03,570 --> 00:47:06,130
And then David, we'd
probably have a conversation

858
00:47:06,130 --> 00:47:08,130
about how to present, whether I was doing

859
00:47:08,130 --> 00:47:10,530
what I believe was
foreseeably appropriate.

860
00:47:10,530 --> 00:47:13,793
- Why don't we take this time left,

861
00:47:14,630 --> 00:47:16,200
we've got two minutes left.

862
00:47:16,200 --> 00:47:17,930
We got time for a fast wrap up.

863
00:47:17,930 --> 00:47:20,669
So Jim, let's start with you.

864
00:47:20,670 --> 00:47:22,550
Why don't everybody take 30 seconds

865
00:47:22,550 --> 00:47:25,080
and just make whatever closing
comments you'd like to make.

866
00:47:25,080 --> 00:47:26,799
Jim go ahead and start.

867
00:47:26,800 --> 00:47:29,850
- Well, I think that the discussion today

868
00:47:29,850 --> 00:47:34,029
has showed that there
is a lot of agreement

869
00:47:34,030 --> 00:47:37,440
as to what the considerations
are for reasonableness

870
00:47:37,440 --> 00:47:42,440
including what types of
standards and customs may exist

871
00:47:46,180 --> 00:47:51,180
and the paramount of importance
of taking into account

872
00:47:51,420 --> 00:47:53,890
the nature and sensitivity of the data

873
00:47:53,890 --> 00:47:56,680
that your talking about

874
00:47:56,680 --> 00:48:00,190
securing in the particular environment.

875
00:48:00,190 --> 00:48:02,840
- Okay, Phyllis, how about you.

876
00:48:02,840 --> 00:48:04,490
- Yeah, it's been a great discussion.

877
00:48:04,490 --> 00:48:07,060
I will say, when we do
create controls documents

878
00:48:07,060 --> 00:48:09,540
for the most part here at CIS,

879
00:48:09,540 --> 00:48:11,720
we believe that the bulk of organizations

880
00:48:11,720 --> 00:48:15,319
can implement all those safeguards.

881
00:48:15,320 --> 00:48:16,600
And that we've done the research

882
00:48:16,600 --> 00:48:18,500
and the data to show the efficacy of that.

883
00:48:18,500 --> 00:48:22,340
However, the reason why we
provide something like a CIS RAM

884
00:48:22,340 --> 00:48:26,340
is so organizations can
make individual decisions

885
00:48:26,340 --> 00:48:31,220
'cause at times there are
exceptions to the rule.

886
00:48:31,220 --> 00:48:32,053
- David.

887
00:48:33,750 --> 00:48:38,750
- I would just say that
the costs and benefits

888
00:48:39,300 --> 00:48:44,227
of a proposed measure have
to be analyzed rigorously

889
00:48:45,780 --> 00:48:49,593
from the perspective of the
specific company at issue.

890
00:48:50,480 --> 00:48:55,290
And every company is gonna
be differently situated.

891
00:48:55,290 --> 00:48:57,090
And I think that that is something

892
00:48:57,090 --> 00:48:59,810
that has to be taken into account.

893
00:48:59,810 --> 00:49:02,540
And I would just always caution

894
00:49:02,540 --> 00:49:07,009
that that no security measure is costless.

895
00:49:07,010 --> 00:49:09,750
You have to take into
account all the costs

896
00:49:09,750 --> 00:49:11,050
that come associated with that,

897
00:49:11,050 --> 00:49:14,490
both to the company and to the
consumer and to the public.

898
00:49:14,490 --> 00:49:17,229
And also we have to be
careful not to be overstating

899
00:49:18,260 --> 00:49:23,170
the benefits of whatever security
measure's being proposed.

900
00:49:23,170 --> 00:49:26,900
- And Chris, we'll let
you wrap things up for us.

901
00:49:26,900 --> 00:49:28,670
- I'm just pleased that
we've reached a milestone

902
00:49:28,670 --> 00:49:31,790
in the industry where the
regulators, litigators

903
00:49:31,790 --> 00:49:33,020
and information security people

904
00:49:33,020 --> 00:49:35,620
have come to agreement on
what reasonableness means.

905
00:49:35,620 --> 00:49:37,270
So I'm happy we're at this point.

906
00:49:38,690 --> 00:49:41,550
- Well, thanks to all of
you and thanks to the RSA

907
00:49:41,550 --> 00:49:44,250
for letting us have this
opportunity to talk with you.

908
00:49:44,250 --> 00:49:46,100
It's been a lot of fun for all of us.

