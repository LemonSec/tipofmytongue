1
00:00:01,440 --> 00:00:04,210
- Hi everyone, I'm Chris Wysopal,

2
00:00:04,210 --> 00:00:07,370
I'm the Co-founder and CTO of Veracode.

3
00:00:07,370 --> 00:00:12,370
I started out my career
in software security

4
00:00:12,940 --> 00:00:14,639
as a vulnerability researcher,

5
00:00:14,640 --> 00:00:16,210
actually as a hobbyist.

6
00:00:16,210 --> 00:00:18,050
And then I changed my career

7
00:00:18,050 --> 00:00:19,730
to application security,

8
00:00:19,730 --> 00:00:21,470
became a consultant,

9
00:00:21,470 --> 00:00:23,410
and then 15 years ago, in 2006,

10
00:00:23,410 --> 00:00:28,410
I founded Veracode to automate
application security testing.

11
00:00:28,490 --> 00:00:31,049
So I'm very happy to talk to you today

12
00:00:31,050 --> 00:00:32,728
about AppSec's Future and the Rise

13
00:00:32,728 --> 00:00:35,323
of the Chief Product Security Officer.

14
00:00:36,900 --> 00:00:38,070
- Hi, I'm Josh Corman,

15
00:00:38,070 --> 00:00:39,730
I wear a lot of hats.

16
00:00:39,730 --> 00:00:41,959
My current one is what I did not expect,

17
00:00:41,960 --> 00:00:43,959
but I'm currently serving for one year

18
00:00:43,959 --> 00:00:46,580
to help drive the COVID response

19
00:00:46,580 --> 00:00:48,790
and the pandemic response for CISA.

20
00:00:48,790 --> 00:00:51,450
Our nation's newest
agency, the cybersecurity,

21
00:00:51,450 --> 00:00:53,200
and infrastructure security agency.

22
00:00:54,060 --> 00:00:55,730
A lot of what we're gonna be talking today

23
00:00:55,730 --> 00:00:59,360
about draws from much
of the career that Chris

24
00:00:59,360 --> 00:01:02,080
and I have been on a journey
for application security

25
00:01:02,080 --> 00:01:03,086
and product security,

26
00:01:03,086 --> 00:01:06,630
including significant
chunks of this come from

27
00:01:06,630 --> 00:01:09,705
the increased demand for
product security officers

28
00:01:09,706 --> 00:01:13,472
or an elevated role for
some of the elevated risks

29
00:01:13,472 --> 00:01:16,399
that associate with what
we used to do as hobbies,

30
00:01:16,400 --> 00:01:19,013
or maybe application-specific work.

31
00:01:19,940 --> 00:01:22,910
And also from some of the work I've done

32
00:01:22,910 --> 00:01:25,429
as the founder of iamthecavalry.org,

33
00:01:25,430 --> 00:01:27,790
a grassroots volunteer
effort focused where bits

34
00:01:27,790 --> 00:01:28,920
and bytes meet flesh and blood.

35
00:01:28,920 --> 00:01:31,120
And some of these high
consequence failures

36
00:01:31,120 --> 00:01:32,710
as the world increasingly depends

37
00:01:32,710 --> 00:01:35,300
on connected digital infrastructure.

38
00:01:35,300 --> 00:01:36,223
So let's jump in.

39
00:01:40,410 --> 00:01:42,809
Between the time we submitted this talk

40
00:01:42,809 --> 00:01:46,110
in the face of significant
technical disruptions

41
00:01:46,110 --> 00:01:49,060
and opportunities and in
the face of significant

42
00:01:49,060 --> 00:01:52,240
public policy changes and
higher consequence failures,

43
00:01:52,240 --> 00:01:53,963
significantly more has happened.

44
00:01:55,230 --> 00:01:57,450
Software trustworthiness, or rather

45
00:01:57,450 --> 00:02:00,180
the lack of trustworthiness
is on the forefront

46
00:02:00,180 --> 00:02:02,770
of everyone's mind right now.

47
00:02:02,770 --> 00:02:07,053
In fact even just now we're
seeing an executive order

48
00:02:07,053 --> 00:02:11,350
from the White House
putting significant effort

49
00:02:11,350 --> 00:02:13,989
and investment across
several government agencies

50
00:02:13,990 --> 00:02:17,008
to improve the trustworthiness
of digital infrastructure

51
00:02:17,008 --> 00:02:20,877
and software where compromises
have dramatically affected

52
00:02:20,877 --> 00:02:25,877
both the executive branch
and other federal agencies

53
00:02:26,023 --> 00:02:28,100
but also the private sector.

54
00:02:28,100 --> 00:02:30,890
With this increased dependence
on connected technology,

55
00:02:30,890 --> 00:02:34,790
the impact is becoming unacceptably high.

56
00:02:34,790 --> 00:02:37,489
So whether it's solar
winds-related activities,

57
00:02:37,490 --> 00:02:39,002
whether it's the exchange exploitation,

58
00:02:39,002 --> 00:02:41,863
whether it's rampant,
ransomware on hospitals,

59
00:02:41,863 --> 00:02:45,680
impeding healthcare
delivery during a pandemic

60
00:02:45,680 --> 00:02:47,351
with life and blood in line,

61
00:02:47,351 --> 00:02:51,500
this is a time for somber
reflection and bold action.

62
00:02:51,500 --> 00:02:56,500
And it reminded me of the seminal
trustworthy computing memo

63
00:02:56,880 --> 00:02:59,109
from Bill Gates at Microsoft

64
00:02:59,110 --> 00:03:00,549
that ultimately led to the formation

65
00:03:00,549 --> 00:03:04,060
of their market-leading
software development life cycle

66
00:03:04,060 --> 00:03:06,270
for Agile, their SDLA.

67
00:03:06,270 --> 00:03:08,520
And sometimes you kind of
have to be sick and tired

68
00:03:08,520 --> 00:03:10,210
of being sick and tired or hit rock bottom

69
00:03:10,210 --> 00:03:13,528
and realize that if you
don't make your software

70
00:03:13,528 --> 00:03:15,720
and digital infrastructure trustworthy,

71
00:03:15,720 --> 00:03:17,590
you're going to have a significant harm,

72
00:03:17,590 --> 00:03:19,570
but also you're gonna lose market share.

73
00:03:19,570 --> 00:03:23,019
And I wonder if we're now in
the cusp of a trustworthy,

74
00:03:23,020 --> 00:03:25,800
critical infrastructure competing memo,

75
00:03:25,800 --> 00:03:28,860
and this has certainly
become a top-line issue.

76
00:03:28,860 --> 00:03:30,410
It's gonna stop for supply chains

77
00:03:30,410 --> 00:03:33,890
and transparency will be much
hotter than they were even

78
00:03:33,890 --> 00:03:36,959
when we submitted this
talk in the first place.

79
00:03:36,960 --> 00:03:39,338
So that begs the question
is their kind of a pathos

80
00:03:39,338 --> 00:03:40,313
for software engineering.

81
00:03:40,313 --> 00:03:42,290
We'd like to use the term engineering,

82
00:03:42,290 --> 00:03:44,140
but we don't often apply engineering rigor

83
00:03:44,140 --> 00:03:47,179
or accountability, or a pathos.

84
00:03:47,180 --> 00:03:51,010
Just like doctors take a
Hippocratic Oath to do no harm,

85
00:03:51,010 --> 00:03:53,079
and physical engineers also understand

86
00:03:53,080 --> 00:03:55,480
the awesome responsibility
that comes with creating things

87
00:03:55,480 --> 00:03:57,040
out of steel and concrete.

88
00:03:57,040 --> 00:04:00,396
We haven't really found our
footing, and in that vacuum,

89
00:04:00,396 --> 00:04:04,279
we have maybe some alternatives.

90
00:04:04,280 --> 00:04:06,980
So one of them might be
move fast and break things.

91
00:04:06,980 --> 00:04:11,570
Unfortunately, that might
also include democracies.

92
00:04:11,570 --> 00:04:14,010
If you've seen films or takes

93
00:04:14,010 --> 00:04:16,952
and movements coming out of
things like the social dilemma,

94
00:04:18,120 --> 00:04:21,579
we haven't fully
internalized the consequences

95
00:04:21,579 --> 00:04:23,820
of some of the actions
we take with our software

96
00:04:23,820 --> 00:04:25,630
and adoption of technology.

97
00:04:25,630 --> 00:04:28,460
Perhaps it's other exemplars
from the VC community.

98
00:04:28,460 --> 00:04:30,520
If you're not embarrassed
by the first version

99
00:04:30,520 --> 00:04:31,353
of your product,

100
00:04:31,353 --> 00:04:32,190
you've launched too late, right?

101
00:04:32,190 --> 00:04:34,050
These are the things
on the hearts and minds

102
00:04:34,050 --> 00:04:36,610
of engineering students
that come out of college

103
00:04:36,610 --> 00:04:38,540
or open-source projects.

104
00:04:38,540 --> 00:04:40,920
And want to start creating
that digital infrastructure

105
00:04:40,920 --> 00:04:42,710
that we all depend upon.

106
00:04:42,710 --> 00:04:44,707
But picture, if the
people who built a bridge

107
00:04:44,708 --> 00:04:46,640
or a skyscraper thought,

108
00:04:46,640 --> 00:04:48,940
if you're not embarrassed by the riveting

109
00:04:48,940 --> 00:04:50,150
and the construction of the bridge,

110
00:04:50,150 --> 00:04:52,929
the day you opened it,
then you waited too long.

111
00:04:52,930 --> 00:04:56,010
And we have learned through
high consequence failures

112
00:04:56,010 --> 00:04:57,860
in physical engineering.

113
00:04:57,860 --> 00:05:00,509
And I'm hoping we will find our footing

114
00:05:00,509 --> 00:05:04,290
in our pathos for what it's gonna take

115
00:05:04,290 --> 00:05:06,200
for digital infrastructure.

116
00:05:06,200 --> 00:05:07,719
Because as the world increasingly depends

117
00:05:07,720 --> 00:05:08,930
on that digital infrastructure

118
00:05:08,930 --> 00:05:10,860
they're increasingly depending on you,

119
00:05:10,860 --> 00:05:13,777
and this area of application
and product security

120
00:05:13,777 --> 00:05:15,633
that we've been foraging.

121
00:05:16,740 --> 00:05:19,446
Now, we attempted to do
something during RSA conference,

122
00:05:19,446 --> 00:05:22,148
I think it was 2008 at a Greylock party.

123
00:05:22,148 --> 00:05:24,250
I got sick of the fact
that the agile manifesto

124
00:05:24,250 --> 00:05:26,429
didn't mention attackers or threat or risk

125
00:05:26,429 --> 00:05:28,909
or security or anything.

126
00:05:28,910 --> 00:05:30,680
So we said we should come
up with a replacement

127
00:05:30,680 --> 00:05:33,070
like the rugged software manifesto.

128
00:05:33,070 --> 00:05:34,880
And without reading the whole thing,

129
00:05:34,880 --> 00:05:37,370
the idea was to have
a personal recognition

130
00:05:37,370 --> 00:05:39,970
of I recognize my code will be used

131
00:05:39,970 --> 00:05:41,840
in ways I cannot anticipate in ways it

132
00:05:41,840 --> 00:05:45,039
was not designed and for longer
than it was ever intended,

133
00:05:45,040 --> 00:05:46,890
or that my code would
be attacked by talented

134
00:05:46,890 --> 00:05:48,880
and persistent adversaries.

135
00:05:48,880 --> 00:05:51,690
And while it didn't take off initially,

136
00:05:51,690 --> 00:05:54,630
it did eventually find some
purchase in the DevOps community

137
00:05:54,630 --> 00:05:56,240
who wanted to be mean to their code

138
00:05:56,240 --> 00:05:59,870
and be more nimble and
agile and faster and better.

139
00:05:59,870 --> 00:06:01,970
So one of my coauthors that David Rice,

140
00:06:01,970 --> 00:06:03,520
who had written a book
called "Geekonomics."

141
00:06:03,520 --> 00:06:06,229
He said the one line he
wished he put into his book,

142
00:06:06,230 --> 00:06:07,870
so I put it here now,

143
00:06:07,870 --> 00:06:09,410
is that the problem in
software engineering

144
00:06:09,410 --> 00:06:11,360
is sometimes we treat it like engineering,

145
00:06:11,360 --> 00:06:12,240
like we're building bridges.

146
00:06:12,240 --> 00:06:14,430
And sometimes we treat
it like an art project,

147
00:06:14,430 --> 00:06:16,230
like put something on
the canvas, you know,

148
00:06:16,230 --> 00:06:19,118
you'll figure it out later, be creative.

149
00:06:19,118 --> 00:06:21,440
And it's really both its art,

150
00:06:21,440 --> 00:06:23,040
but with engineering consequences

151
00:06:23,040 --> 00:06:25,210
and we've not fully
come to terms with that.

152
00:06:25,210 --> 00:06:27,890
And as such software
and application security

153
00:06:27,890 --> 00:06:30,926
is a tiny minority of the
overall cybersecurity spend

154
00:06:30,926 --> 00:06:33,219
and certainly a tiny minority

155
00:06:33,220 --> 00:06:34,960
of the software engineering discipline.

156
00:06:34,960 --> 00:06:36,950
But that's gonna change.

157
00:06:36,950 --> 00:06:38,349
And through a lot of my testimonies

158
00:06:38,350 --> 00:06:39,880
and work through I am The Cavalry,

159
00:06:39,880 --> 00:06:41,897
I've kind of honed on this,

160
00:06:41,897 --> 00:06:44,159
and it was painstakingly worded over time.

161
00:06:44,160 --> 00:06:46,873
But through that overdependence
on undependable IT,

162
00:06:47,740 --> 00:06:49,410
we created the conditions
such that the actions

163
00:06:49,410 --> 00:06:51,926
of any single one outlier
any accident or adversary

164
00:06:51,926 --> 00:06:54,460
can have a profound and asymmetric impact

165
00:06:54,460 --> 00:06:57,430
on human life, economic
and national security.

166
00:06:57,430 --> 00:07:01,100
And this is something
that's, unfortunately,

167
00:07:01,100 --> 00:07:02,653
revealing itself more recently.

168
00:07:03,950 --> 00:07:05,520
Now when we founded the Cavalry,

169
00:07:05,520 --> 00:07:07,560
we met a law professor, Andrea Matushen,

170
00:07:07,560 --> 00:07:09,190
she's very active in the policy community,

171
00:07:09,190 --> 00:07:11,387
worked with both Chris
and I, and she said,

172
00:07:11,387 --> 00:07:12,937
"Josh, no one's gonna listen to you

173
00:07:12,937 --> 00:07:15,456
"until there's literally
a burning river on fire."

174
00:07:15,456 --> 00:07:19,220
She said we had so much
pollution in the Cuyahoga river

175
00:07:19,220 --> 00:07:22,270
that it had to catch on
fire, not once, not twice,

176
00:07:22,270 --> 00:07:27,270
but this river caught on fire
21 times across 70 years,

177
00:07:27,290 --> 00:07:29,900
before there was a
public "enough is enough.

178
00:07:29,900 --> 00:07:32,060
And they instituted the clean water act

179
00:07:32,060 --> 00:07:34,430
and eventually the EPA.

180
00:07:34,430 --> 00:07:37,357
And so we talked about
the cyber Cuyahoga river

181
00:07:37,357 --> 00:07:38,810
on fire moment,

182
00:07:38,810 --> 00:07:43,001
and whether it's a single
attack on Ukrainian power plants

183
00:07:43,001 --> 00:07:45,950
or whether it's some of
these more damaging attacks

184
00:07:45,950 --> 00:07:48,635
on US hospitals during
the pandemic response.

185
00:07:48,636 --> 00:07:51,080
These fires have happened enough,

186
00:07:51,080 --> 00:07:54,020
and I think solar wind
and its related activity

187
00:07:54,020 --> 00:07:57,645
really captivated the
attention and political will

188
00:07:57,646 --> 00:08:00,593
of many stakeholders in government.

189
00:08:02,030 --> 00:08:07,030
So in response when we're
over-trusting of software,

190
00:08:07,410 --> 00:08:09,830
perhaps the trust we place upon software

191
00:08:09,830 --> 00:08:14,450
should be proportional to
the trustworthiness of it

192
00:08:14,450 --> 00:08:16,789
and the consequences of failure

193
00:08:16,790 --> 00:08:18,910
if it were to prove untrustworthy.

194
00:08:18,910 --> 00:08:20,380
So if you're a Game of Thrones fan,

195
00:08:20,380 --> 00:08:21,770
I've been saying for a few years now,

196
00:08:21,770 --> 00:08:25,719
that transparency is coming
because one of the core pillars

197
00:08:25,720 --> 00:08:28,049
of trust and trustworthiness
is greater levels

198
00:08:28,049 --> 00:08:31,849
of transparency across the board.

199
00:08:31,850 --> 00:08:34,049
And if you've been
following some of the work

200
00:08:34,049 --> 00:08:35,790
that many of us have been doing for,

201
00:08:35,791 --> 00:08:38,033
I think now eight years,

202
00:08:38,960 --> 00:08:40,140
SBOM is coming.

203
00:08:40,140 --> 00:08:42,199
In fact, SBOM is here,
and to spell that out,

204
00:08:42,200 --> 00:08:44,484
it's the software bill
of materials concept.

205
00:08:44,484 --> 00:08:48,180
It's already been a
requirement for medical devices

206
00:08:48,180 --> 00:08:49,739
through the US Food and
Drug Administration.

207
00:08:49,740 --> 00:08:52,610
There's been almost three-year
process with the software

208
00:08:52,610 --> 00:08:54,315
and transparency project,

209
00:08:54,315 --> 00:08:56,420
under the National Telecommunications

210
00:08:56,420 --> 00:08:59,211
and Information Administration
under Allan Friedman.

211
00:08:59,211 --> 00:09:02,670
But now it's, looks like
it's like table stakes

212
00:09:02,670 --> 00:09:04,625
for selling a high consequence software

213
00:09:04,625 --> 00:09:06,023
to the federal government.

214
00:09:06,880 --> 00:09:09,030
- Okay, so you know,

215
00:09:09,030 --> 00:09:11,555
I think Mark Andreessen was obviously

216
00:09:11,556 --> 00:09:13,467
very patient when he said

217
00:09:13,467 --> 00:09:16,197
"Software continues to eat the world,"

218
00:09:16,197 --> 00:09:18,437
"Software is everywhere,"

219
00:09:18,437 --> 00:09:20,398
"Everyone is online."

220
00:09:20,398 --> 00:09:22,736
We have new hardware
and software solutions

221
00:09:22,736 --> 00:09:27,523
that didn't exist 10 years
ago when Mark said this.

222
00:09:28,510 --> 00:09:31,500
The other thing is the software
that's eating the world now

223
00:09:31,500 --> 00:09:35,430
is different than the
software we had in the past.

224
00:09:35,430 --> 00:09:38,810
Software in the past was
really first started off

225
00:09:38,810 --> 00:09:43,410
as ways to automate manual
processes in the back office

226
00:09:43,410 --> 00:09:46,709
of a business, you know, think
of the bank teller software.

227
00:09:46,710 --> 00:09:49,470
So the teller is not writing in a ledger,

228
00:09:49,470 --> 00:09:51,500
the bank teller is using software.

229
00:09:51,500 --> 00:09:53,546
But that's back-office automation

230
00:09:53,546 --> 00:09:56,340
and the risks are different for things

231
00:09:56,340 --> 00:09:59,500
that are just applications
in the back office

232
00:09:59,500 --> 00:10:03,110
versus things which we
would now call products.

233
00:10:03,110 --> 00:10:07,232
Products that are delivering
value to a customer, right?

234
00:10:07,232 --> 00:10:10,365
It could be just an online banking app,

235
00:10:10,365 --> 00:10:13,080
which makes it more
convenient to do something

236
00:10:13,080 --> 00:10:17,170
that's traditional or
something completely new,

237
00:10:17,170 --> 00:10:20,059
like an Alexa IoT device.

238
00:10:20,059 --> 00:10:22,329
Which really can't even
work without the internet

239
00:10:22,330 --> 00:10:23,520
connected to it.

240
00:10:23,520 --> 00:10:26,616
So this continuing to eat the world

241
00:10:26,616 --> 00:10:29,560
is just not just more software,

242
00:10:29,560 --> 00:10:31,239
it's different kind of software.

243
00:10:31,240 --> 00:10:33,810
And that's one of the
reasons we're talking about

244
00:10:33,810 --> 00:10:37,560
a chief product security officer today,

245
00:10:37,560 --> 00:10:41,560
as opposed to just a CSO that might be,

246
00:10:41,560 --> 00:10:43,446
you know, worrying about, you know,

247
00:10:43,447 --> 00:10:47,373
compliance and protecting
a business's brand.

248
00:10:48,360 --> 00:10:49,460
If you go to the next one here.

249
00:10:49,460 --> 00:10:54,183
So I put this in here because you know,

250
00:10:55,210 --> 00:10:57,170
you might've played Oregon Trail,

251
00:10:57,170 --> 00:10:59,939
you may have ended the game this way.

252
00:10:59,940 --> 00:11:02,619
And the thing about,
software eating the world is,

253
00:11:02,619 --> 00:11:07,619
it's taking over processes
that may be used to be manual

254
00:11:07,980 --> 00:11:09,700
or used to be back-office software

255
00:11:09,700 --> 00:11:11,830
and adding a lot of risk to them.

256
00:11:11,830 --> 00:11:15,977
You know, like that mobile
banking app is riskier

257
00:11:15,977 --> 00:11:18,838
than going into the bank
and talking to the teller,

258
00:11:18,838 --> 00:11:22,020
using the back-office software,

259
00:11:22,020 --> 00:11:23,449
the attack surface is bigger.

260
00:11:23,450 --> 00:11:25,693
Anyone perhaps in the
world can download that

261
00:11:25,693 --> 00:11:28,620
or connect to the APIs on the backend.

262
00:11:28,620 --> 00:11:30,410
So this kind of software
we're building now

263
00:11:30,410 --> 00:11:34,135
is actually adding a lot
more risk to the world.

264
00:11:34,135 --> 00:11:37,263
And we have to be careful
about how we're doing it.

265
00:11:38,310 --> 00:11:41,786
So why do we need a Chief
Product Security Officer?

266
00:11:41,786 --> 00:11:46,068
I used beast here because
my original superhero

267
00:11:46,068 --> 00:11:48,329
turned out to be a supervillain

268
00:11:48,330 --> 00:11:51,270
and Josh had to correct
me being the expert he is.

269
00:11:51,270 --> 00:11:53,583
You can tell by his back wall there.

270
00:11:54,630 --> 00:11:59,140
But the idea is we need
this new individual

271
00:12:00,020 --> 00:12:05,020
to do something that spans
many different departments now.

272
00:12:05,453 --> 00:12:07,720
It spans engineering,

273
00:12:07,720 --> 00:12:09,355
it spans compliance,

274
00:12:09,355 --> 00:12:14,355
it might span your supplier management.

275
00:12:15,020 --> 00:12:17,981
It certainly spans information risk,

276
00:12:17,981 --> 00:12:19,739
but it's changing.

277
00:12:19,739 --> 00:12:23,990
And we're not sure that
the CISO model really fits

278
00:12:23,990 --> 00:12:26,360
for what's needed for the future.

279
00:12:26,360 --> 00:12:30,023
So that's why we're really
calling for a CPSO now.

280
00:12:31,240 --> 00:12:34,161
- Yeah, and because the problems
are increasingly a beast,

281
00:12:34,161 --> 00:12:37,454
we need you to become a
beast of the best kind,

282
00:12:37,454 --> 00:12:40,423
Heroic Beast from the X-Men.

283
00:12:41,600 --> 00:12:44,140
And there's significant market evolution

284
00:12:44,140 --> 00:12:45,420
and it's naturally observable.

285
00:12:45,420 --> 00:12:48,560
Many of these safety-critical
product lines,

286
00:12:48,560 --> 00:12:51,410
and highly regulated lines
like medical device makers

287
00:12:51,410 --> 00:12:54,557
and industrial environments
have already been adding,

288
00:12:54,557 --> 00:12:56,890
whether it's a chief
product security officer

289
00:12:56,890 --> 00:12:58,750
or a head of product security

290
00:12:58,750 --> 00:13:03,750
that is often appear to or
even a superior to the CISO

291
00:13:03,890 --> 00:13:05,630
who's doing more enterprise security

292
00:13:05,630 --> 00:13:08,330
or operational risk management.

293
00:13:08,330 --> 00:13:10,610
And in part is because
the software failure

294
00:13:10,610 --> 00:13:13,173
has been growing in
volume variety and impact.

295
00:13:15,060 --> 00:13:16,869
I didn't think I'd ever be saying this,

296
00:13:16,870 --> 00:13:20,180
but we are in fact, seeing
national security level

297
00:13:20,180 --> 00:13:23,300
cybersecurity failures from a series

298
00:13:23,300 --> 00:13:26,130
of accidents and adversaries
in nation-states.

299
00:13:26,130 --> 00:13:28,627
And regulators, of course,
domestically, internationally,

300
00:13:28,627 --> 00:13:30,819
and in the private
sector are taking notice

301
00:13:30,820 --> 00:13:32,100
and taking action.

302
00:13:32,100 --> 00:13:34,929
So, at least in my last
pro-government role,

303
00:13:34,929 --> 00:13:37,500
I was a Chief Security Officer,

304
00:13:37,500 --> 00:13:40,070
but with a heavy bent to product security.

305
00:13:40,070 --> 00:13:43,490
And it was in addition
to our traditional CPSO

306
00:13:43,490 --> 00:13:46,930
and governance teams.

307
00:13:46,930 --> 00:13:49,270
So, we had pretty much every board meeting

308
00:13:49,270 --> 00:13:52,170
had an update on some level
of this program and evolution.

309
00:13:53,500 --> 00:13:55,828
And to further speak to signal,

310
00:13:55,828 --> 00:13:59,480
one of those hats I wear
is, I've been with the CMU.

311
00:13:59,480 --> 00:14:03,720
It's CPSO Certificate
Program in their grad school,

312
00:14:03,720 --> 00:14:04,840
since its inception.

313
00:14:04,840 --> 00:14:08,840
And we were asked to
change an entire module,

314
00:14:08,840 --> 00:14:11,070
to the rise of the Chief
Product Security Officer.

315
00:14:11,070 --> 00:14:12,380
And this is a snapshot.

316
00:14:12,380 --> 00:14:14,439
We will not be going
through this entire outline

317
00:14:14,440 --> 00:14:19,370
using many, many, many hours
of chunks of lessons here.

318
00:14:19,370 --> 00:14:22,210
But, while they compliment
and they relate to

319
00:14:22,210 --> 00:14:23,870
a lot of your traditional AppSec,

320
00:14:23,870 --> 00:14:25,280
they're significantly different.

321
00:14:25,280 --> 00:14:27,410
More programmatic involve
a lot of third-party

322
00:14:27,410 --> 00:14:30,125
risk management, and risk prioritization,

323
00:14:30,125 --> 00:14:33,120
and introductions of things like PSIRT

324
00:14:33,120 --> 00:14:35,693
and vulnerability disclosure
programs and the like.

325
00:14:37,120 --> 00:14:39,350
And part of this we both speak to

326
00:14:39,350 --> 00:14:42,660
is this also requires someone.

327
00:14:42,660 --> 00:14:44,102
If you're thinking of your career path,

328
00:14:44,102 --> 00:14:46,709
you can go down the path of more hands-on

329
00:14:46,709 --> 00:14:50,688
and more pen testing or more
security product evaluation.

330
00:14:50,688 --> 00:14:52,455
You can get more into risk.

331
00:14:52,455 --> 00:14:56,320
It often requires someone
who can be bimodal

332
00:14:56,320 --> 00:14:58,680
and think of this both
as a forest and the trees

333
00:14:58,680 --> 00:15:00,120
kind of an issue.

334
00:15:00,120 --> 00:15:02,570
And maybe you have a hundred applications,

335
00:15:02,570 --> 00:15:04,282
they're not all equal risk.

336
00:15:04,282 --> 00:15:07,790
Some sort of objective
repeatable criterion

337
00:15:07,790 --> 00:15:10,010
can help you decide which ones need

338
00:15:10,010 --> 00:15:11,960
which level of rigor and why.

339
00:15:11,960 --> 00:15:14,452
And Socratically going
from executive stakeholders

340
00:15:14,452 --> 00:15:16,700
to help determine those criteria

341
00:15:16,700 --> 00:15:20,330
and get them to advocate
champion and back the investments

342
00:15:20,330 --> 00:15:22,240
that may be required here.

343
00:15:22,240 --> 00:15:23,670
But also, we're in the face

344
00:15:23,670 --> 00:15:26,490
of significant turbulent
technological changes.

345
00:15:26,490 --> 00:15:29,620
And these may be either
threats to your old program,

346
00:15:29,620 --> 00:15:31,820
or maybe even opportunities
for you to insert

347
00:15:31,820 --> 00:15:34,513
and up-level your game and
find a new career path.

348
00:15:36,130 --> 00:15:38,910
- Yeah, there are a lot
of people that might be

349
00:15:38,910 --> 00:15:42,170
in the middle of this
with their skill set.

350
00:15:42,170 --> 00:15:44,099
And essentially you have to,

351
00:15:44,100 --> 00:15:46,180
if you're gonna be the
CPSO, you have to go

352
00:15:46,180 --> 00:15:47,479
in both directions, right?

353
00:15:47,480 --> 00:15:50,910
You have to engage with
the individual developer

354
00:15:50,910 --> 00:15:54,900
and get that individual
developer to, you know,

355
00:15:54,900 --> 00:15:57,510
find and fix the
vulnerabilities in the code

356
00:15:57,510 --> 00:15:58,500
that they're doing.

357
00:15:58,500 --> 00:16:03,230
That's very, very focused on simple things

358
00:16:03,230 --> 00:16:07,930
basically in the code and
that needs to be enabled.

359
00:16:07,930 --> 00:16:10,532
But on the other hand, you
need to take a bigger picture.

360
00:16:10,533 --> 00:16:14,712
A lot of things in the view of risk.

361
00:16:14,712 --> 00:16:17,650
If I think about, you know,
some of the work I've done

362
00:16:17,650 --> 00:16:19,783
in the past for software companies,

363
00:16:20,750 --> 00:16:22,080
you know, it was all about like,

364
00:16:22,080 --> 00:16:23,780
just get rid of the high-risk bugs.

365
00:16:23,780 --> 00:16:25,620
Get rid of the critical bugs,

366
00:16:25,620 --> 00:16:26,990
get rid of the SQL injections,

367
00:16:26,990 --> 00:16:29,000
get rid of the buffer overflows.

368
00:16:29,000 --> 00:16:32,515
Without really thinking
about the broader picture of,

369
00:16:32,515 --> 00:16:34,319
what is the actual risk,

370
00:16:34,320 --> 00:16:38,430
if there is a vulnerability
in this application?

371
00:16:38,430 --> 00:16:40,280
How does it impact our customers?

372
00:16:40,280 --> 00:16:42,520
Whether our customers are, you know,

373
00:16:42,520 --> 00:16:45,689
using on-premise software or
they're like a mobile app.

374
00:16:45,690 --> 00:16:47,683
Or our customers are using,

375
00:16:48,830 --> 00:16:50,790
you know a SAS application

376
00:16:50,790 --> 00:16:52,810
that we're essentially giving them.

377
00:16:52,810 --> 00:16:54,497
The Enterprise Risk
Management is something that,

378
00:16:54,497 --> 00:16:57,640
you know, CPSOs know a lot about.

379
00:16:57,640 --> 00:17:01,260
And that's kind of the way
that they view the world,

380
00:17:01,260 --> 00:17:04,329
but it's not the way a lot
of product security teams

381
00:17:04,329 --> 00:17:07,520
have traditionally viewed
the world in the past.

382
00:17:07,520 --> 00:17:11,619
So, the CPSO is going to need to bulk up

383
00:17:11,619 --> 00:17:13,652
in both of these areas.

384
00:17:16,470 --> 00:17:20,410
I wanna talk about the attack
surface growing exponentially

385
00:17:20,410 --> 00:17:24,240
because I really think that
this is one of the key things,

386
00:17:24,240 --> 00:17:27,680
that's making product security more risky.

387
00:17:27,680 --> 00:17:31,380
Because, products are
exposed right by default,

388
00:17:31,380 --> 00:17:34,488
like on the left there,
we have an IoT device.

389
00:17:34,488 --> 00:17:39,488
That IoT device could
be 5G, it could be wifi,

390
00:17:39,680 --> 00:17:41,970
it's just hanging out there
on the internet exposed.

391
00:17:41,970 --> 00:17:45,747
It has to secure its own attack surface.

392
00:17:45,747 --> 00:17:50,747
And that's an increasing
model for a piece of code,

393
00:17:51,200 --> 00:17:54,300
that it has to be on a
device like this exposed.

394
00:17:54,300 --> 00:17:55,580
Same thing with APIs,

395
00:17:55,580 --> 00:17:57,830
if you're exposing an API, you know,

396
00:17:57,830 --> 00:17:59,290
a back end for a mobile app,

397
00:17:59,290 --> 00:18:02,990
or maybe you're a SAS
company that exposes an API

398
00:18:02,990 --> 00:18:04,262
to their customers.

399
00:18:04,262 --> 00:18:06,860
Obviously, that needs to be secured.

400
00:18:06,860 --> 00:18:09,439
But the thing is the way we're
constructing applications

401
00:18:09,440 --> 00:18:12,650
now APIs are now the way,

402
00:18:12,650 --> 00:18:16,940
our sort of the bloodstream
of an application.

403
00:18:16,940 --> 00:18:21,700
They pervade all the app, all
inside of a piece of software,

404
00:18:21,700 --> 00:18:26,700
and each microservice or
serverless or container

405
00:18:26,750 --> 00:18:31,160
or public API is more attack surface

406
00:18:31,160 --> 00:18:33,313
that needs to be thought about.

407
00:18:34,720 --> 00:18:39,720
Social networking is a way
that we are interacting

408
00:18:39,730 --> 00:18:40,963
with applications now.

409
00:18:40,963 --> 00:18:45,480
Applications and products are sending,

410
00:18:45,480 --> 00:18:47,780
they're communicating to social media

411
00:18:47,780 --> 00:18:50,240
and social media is also
going the other way.

412
00:18:50,240 --> 00:18:53,256
So, it's just another
piece of attack surface

413
00:18:53,256 --> 00:18:54,960
that is growing.

414
00:18:54,960 --> 00:18:56,470
And finally, on the right there,

415
00:18:56,470 --> 00:18:58,750
I just show a picture of a website,

416
00:18:58,750 --> 00:19:01,250
but the idea is so old software,

417
00:19:01,250 --> 00:19:03,910
never seems to be deprecated.

418
00:19:03,910 --> 00:19:05,583
And it just hangs around

419
00:19:05,583 --> 00:19:08,360
and its attack surface never goes away.

420
00:19:08,360 --> 00:19:10,370
So, we build something new,

421
00:19:10,370 --> 00:19:11,679
we leave something old around.

422
00:19:11,680 --> 00:19:14,621
You know, how many
organizations have moved to

423
00:19:14,621 --> 00:19:17,470
office 365 for their email,

424
00:19:17,470 --> 00:19:19,880
but still have an exchange
server running somewhere

425
00:19:19,880 --> 00:19:22,200
for some reason, for a few mailboxes

426
00:19:22,200 --> 00:19:23,950
or something internally?

427
00:19:23,950 --> 00:19:26,810
You have the attack surface of both 365

428
00:19:26,810 --> 00:19:29,827
and exchange because you migrated.

429
00:19:29,827 --> 00:19:33,633
So, that's definitely something
that needs to be tackled.

430
00:19:35,670 --> 00:19:37,730
Obviously, we wanna understand,

431
00:19:37,730 --> 00:19:41,060
if breaches are coming
through applications,

432
00:19:41,060 --> 00:19:41,899
and they certainly are.

433
00:19:41,900 --> 00:19:45,480
Verizon said 43% of
single-page applications

434
00:19:45,480 --> 00:19:49,020
would represent, we're
the cause of breaches.

435
00:19:49,020 --> 00:19:50,490
And that is, you know,

436
00:19:50,490 --> 00:19:54,390
that's sort of the
mainstay of how we interact

437
00:19:54,390 --> 00:19:56,133
with applications these days.

438
00:19:57,670 --> 00:20:02,670
And 70% of all applications
have a security flaw in them

439
00:20:02,700 --> 00:20:05,370
that has been inherited by open source.

440
00:20:05,370 --> 00:20:07,840
So, these are just some of the
ways the world is changing,

441
00:20:07,840 --> 00:20:10,290
that Product Security
Officers need to deal with.

442
00:20:12,850 --> 00:20:17,300
So, there are technology
trends are impacting the CPSO.

443
00:20:17,300 --> 00:20:19,980
These are technology
trends that developers

444
00:20:19,980 --> 00:20:21,420
are all taking advantage of

445
00:20:21,420 --> 00:20:23,620
because they allow them to go faster

446
00:20:23,620 --> 00:20:27,822
and build better applications
more inexpensively.

447
00:20:28,690 --> 00:20:33,134
But they are also something
that CPOSs need to learn about

448
00:20:33,134 --> 00:20:34,992
and can take advantage of.

449
00:20:34,992 --> 00:20:38,034
Upskill yourself and
understand these trends

450
00:20:38,035 --> 00:20:39,730
to get ahead of them.

451
00:20:39,730 --> 00:20:43,560
And some of these trends
actually make security better.

452
00:20:43,560 --> 00:20:45,679
A lot of times we look at what developers

453
00:20:45,680 --> 00:20:48,100
are doing using new
things like serverless,

454
00:20:48,100 --> 00:20:50,100
and we, or infrastructure's code.

455
00:20:50,100 --> 00:20:54,820
And we start worrying like,
"Oh no, now, it's added risk."

456
00:20:54,820 --> 00:20:57,030
Well, actually a lot of
these new technologies

457
00:20:57,030 --> 00:20:58,818
can benefit security,

458
00:20:58,818 --> 00:21:01,133
which I think is an awesome thing.

459
00:21:02,560 --> 00:21:05,200
So, if we think about
Ubiquitous Connectivity,

460
00:21:05,200 --> 00:21:09,056
this is just the standard
mode for any product now.

461
00:21:09,056 --> 00:21:13,358
It's likely that products
are not are communicating

462
00:21:13,358 --> 00:21:16,292
to multiple sites on the internet.

463
00:21:16,292 --> 00:21:20,270
I looked at a healthcare mobile app

464
00:21:20,270 --> 00:21:22,000
that was written by a major hospital,

465
00:21:22,000 --> 00:21:24,624
and it was communicating
with seven back-end APIs,

466
00:21:24,624 --> 00:21:26,530
including one in China.

467
00:21:26,530 --> 00:21:28,226
So, the conductivity is great.

468
00:21:28,227 --> 00:21:31,640
It allows us to quickly add a lot of value

469
00:21:31,640 --> 00:21:33,968
to say something like a mobile app.

470
00:21:33,968 --> 00:21:37,135
But it also means that there's
a lot more attack surface

471
00:21:37,135 --> 00:21:42,135
that's persistent, and there's
a lot more pieces to secure.

472
00:21:44,415 --> 00:21:49,415
The other big trend abstraction
and componentization

473
00:21:49,743 --> 00:21:53,840
is where we're using
instead of writing code,

474
00:21:53,840 --> 00:21:55,699
we're using a library.

475
00:21:55,700 --> 00:21:58,550
Or we are writing a script

476
00:21:58,550 --> 00:22:02,007
that is instructing
something else to be built,

477
00:22:02,007 --> 00:22:04,230
or we are calling an API.

478
00:22:04,230 --> 00:22:06,160
And who knows what's behind that API,

479
00:22:06,160 --> 00:22:08,210
it's abstracted away from us.

480
00:22:08,210 --> 00:22:10,320
And this abstraction and componentization

481
00:22:10,320 --> 00:22:13,139
is great to build apps more quickly,

482
00:22:13,140 --> 00:22:16,850
but it changes the way you
have to think about security.

483
00:22:16,850 --> 00:22:20,510
There's much more thinking
about supply chain.

484
00:22:20,510 --> 00:22:22,213
So, picking your suppliers,

485
00:22:22,213 --> 00:22:26,230
whether they're open source
suppliers or API suppliers,

486
00:22:26,230 --> 00:22:29,180
your cloud provider is
gonna be giving you APIs.

487
00:22:29,180 --> 00:22:30,900
That starts to be a supply chain issue.

488
00:22:30,900 --> 00:22:32,940
It's nothing an individual developer

489
00:22:32,940 --> 00:22:34,770
is typically gonna worry about.

490
00:22:34,770 --> 00:22:38,023
This is something that needs
to be thought of by the CPSO.

491
00:22:41,330 --> 00:22:43,730
And just, here's an
example of how we've always

492
00:22:43,730 --> 00:22:48,160
had supply chain security concerns.

493
00:22:48,160 --> 00:22:50,490
But it really, in the last, you know,

494
00:22:50,490 --> 00:22:54,213
five-plus years has radically changed

495
00:22:54,213 --> 00:22:56,430
what it means to be an application.

496
00:22:56,430 --> 00:22:59,890
You know, a legacy application
might have a few libraries

497
00:22:59,890 --> 00:23:01,610
and called a couple APIs.

498
00:23:01,610 --> 00:23:04,840
Modern applications can be 95% libraries,

499
00:23:04,840 --> 00:23:07,040
and be calling 100s of APIs

500
00:23:07,040 --> 00:23:09,649
from dozens of different providers.

501
00:23:09,650 --> 00:23:12,970
So, it just radically is
changing the way you have

502
00:23:12,970 --> 00:23:15,663
to think about securing that code.

503
00:23:16,820 --> 00:23:19,460
- And, yeah, one of those
innovations that came out

504
00:23:19,460 --> 00:23:21,920
of the Bill Gates'
Trustworthy Competing memo,

505
00:23:21,920 --> 00:23:26,344
was Howard, doing the seminal
work on Microsoft SDL.

506
00:23:26,344 --> 00:23:28,177
Then I often use it as a framework,

507
00:23:28,177 --> 00:23:31,811
perhaps you like, oh,
some other chain here.

508
00:23:31,811 --> 00:23:34,139
But to talk about the different activities

509
00:23:34,140 --> 00:23:35,690
as you shift, right, or shift left,

510
00:23:35,690 --> 00:23:38,420
all the way from threat
modeling and secure architecture

511
00:23:38,420 --> 00:23:39,490
and requirements through.

512
00:23:39,490 --> 00:23:41,670
Maybe your coordinated vulnerability

513
00:23:41,670 --> 00:23:43,780
response program and PSIRT.

514
00:23:43,780 --> 00:23:45,992
But, as we talk this
and we try to make sure

515
00:23:45,992 --> 00:23:49,538
that we're meeting acceptable
levels of due care,

516
00:23:49,538 --> 00:23:52,168
especially as if we're selling
high consequence software.

517
00:23:52,168 --> 00:23:54,179
Or software that touches regulated data,

518
00:23:54,180 --> 00:23:57,061
or your customer's intellectual property,

519
00:23:57,061 --> 00:24:00,716
as these are more
productized versus just apps.

520
00:24:00,717 --> 00:24:03,640
They bear more responsibility
and many of you have tried

521
00:24:03,640 --> 00:24:06,600
to be very diligent about,

522
00:24:06,600 --> 00:24:09,140
doing at least industry
standard practices here.

523
00:24:09,141 --> 00:24:13,870
Including things that Chris
and others have pioneered.

524
00:24:13,870 --> 00:24:15,790
But, what we haven't
really thought about is,

525
00:24:15,790 --> 00:24:17,906
if you're in the software
supply chain land

526
00:24:17,906 --> 00:24:19,879
the world of SBOM,

527
00:24:19,880 --> 00:24:22,441
blink and you'll miss
this beautiful animation.

528
00:24:22,441 --> 00:24:24,670
With all these different parts

529
00:24:24,670 --> 00:24:26,546
this notion of a software
bill of materials

530
00:24:26,546 --> 00:24:29,877
is really stolen from Deming
and Toyota supply chains

531
00:24:29,877 --> 00:24:32,950
in the 40s and bombs themselves.

532
00:24:32,950 --> 00:24:36,160
Or building materials are
pretty necessary productivity,

533
00:24:36,160 --> 00:24:37,620
and profit enhancer

534
00:24:37,620 --> 00:24:40,219
for most of these manufacturing
chemical companies

535
00:24:40,220 --> 00:24:43,540
in the world, over the
last several decades.

536
00:24:43,540 --> 00:24:45,450
The idea of a Software Bill of Materials

537
00:24:45,450 --> 00:24:47,830
and Software Supply Chain Hygiene

538
00:24:47,830 --> 00:24:49,492
and Software Risk Management

539
00:24:49,492 --> 00:24:51,970
is that we're all in a supply chain.

540
00:24:51,970 --> 00:24:53,224
Most of us are in the middle.

541
00:24:53,224 --> 00:24:56,320
This graphic was made for
the NTA process with Audi

542
00:24:56,320 --> 00:24:58,230
and myself and others.

543
00:24:58,230 --> 00:24:59,610
And that's a bedside infusion pumps.

544
00:24:59,610 --> 00:25:01,197
So, if you're the Product Officer

545
00:25:01,197 --> 00:25:04,050
or Chief Product Security
Officer for a medical device,

546
00:25:04,050 --> 00:25:06,879
that can pump drugs into
somebody and maybe give them

547
00:25:06,880 --> 00:25:07,760
a lethal dose.

548
00:25:07,760 --> 00:25:10,825
Just like the first recall in
history for medical device,

549
00:25:10,825 --> 00:25:13,292
without authorization
could empty the contents

550
00:25:13,292 --> 00:25:17,268
of a bolus in three seconds
instead of three hours.

551
00:25:17,268 --> 00:25:19,990
That product you're selling
is sold in hospitals

552
00:25:19,990 --> 00:25:21,560
and operational risk environments.

553
00:25:21,560 --> 00:25:23,690
But, while you make the product,

554
00:25:23,690 --> 00:25:24,950
you have a supply chain.

555
00:25:24,950 --> 00:25:26,520
Your supply chain has a supply chain.

556
00:25:26,520 --> 00:25:28,840
It's turtles on turtles all the way down.

557
00:25:28,840 --> 00:25:30,720
And risks anywhere in that supply chain,

558
00:25:30,720 --> 00:25:32,180
even if they're opaque to you,

559
00:25:32,180 --> 00:25:34,890
can still cause a disruption.

560
00:25:34,890 --> 00:25:39,040
This was really punctuated to
DEFCON ago with original11.

561
00:25:39,040 --> 00:25:41,840
There was a vulnerability
announced in some

562
00:25:41,840 --> 00:25:44,419
WindView VxWorks code.

563
00:25:44,420 --> 00:25:45,967
And everyone's, "Okay, do I use that?

564
00:25:45,967 --> 00:25:47,900
"Nope, I don't, I'm safe."

565
00:25:47,900 --> 00:25:50,170
But it was later
subsequently revealed to be

566
00:25:50,170 --> 00:25:52,670
in Interpeak IPnet stack,

567
00:25:52,670 --> 00:25:54,870
which was deeper in the supply chain.

568
00:25:54,870 --> 00:25:57,631
And used by tons of other
real-time operating systems

569
00:25:57,632 --> 00:26:00,150
and high safety assurance devices.

570
00:26:00,150 --> 00:26:02,560
So, a flaw way down in the bowels there

571
00:26:02,560 --> 00:26:04,620
may manifest and create attacks

572
00:26:04,620 --> 00:26:05,959
or exploitable attack surface

573
00:26:05,960 --> 00:26:08,220
that can harm people downstream.

574
00:26:08,220 --> 00:26:10,663
So, if it's daunting enough
for all the great work

575
00:26:10,663 --> 00:26:14,840
you've done in AppSec to drive an SDLC.

576
00:26:14,840 --> 00:26:16,370
Chris and I had this moment of dread,

577
00:26:16,370 --> 00:26:17,530
where we realized, wow,

578
00:26:17,530 --> 00:26:19,260
not only do you need a
software bill of materials

579
00:26:19,260 --> 00:26:20,930
to tell you what's in it.

580
00:26:20,930 --> 00:26:23,670
Do we actually know the
rigor or lack thereof

581
00:26:23,670 --> 00:26:26,169
or the SDLC for every part and project

582
00:26:26,169 --> 00:26:27,900
that you're building?

583
00:26:27,900 --> 00:26:29,400
And of course, you don't.

584
00:26:29,400 --> 00:26:32,540
And of course, there's ways to
mitigate against less visible

585
00:26:32,540 --> 00:26:34,080
and less known risks.

586
00:26:34,080 --> 00:26:37,179
But this is going to lead
to an era where we can start

587
00:26:37,180 --> 00:26:39,790
to scrutinize the quality caliber.

588
00:26:39,790 --> 00:26:42,920
More like Deming, we
focused on SBOM on the,

589
00:26:42,920 --> 00:26:43,753
am I affected?

590
00:26:43,753 --> 00:26:45,423
Where am I affected?

591
00:26:45,423 --> 00:26:48,410
Parts of a manifest, but
part of his brilliance

592
00:26:48,410 --> 00:26:51,810
was using fewer and
better suppliers of parts.

593
00:26:51,810 --> 00:26:53,610
The higher quality parts, the buyers,

594
00:26:53,610 --> 00:26:56,560
and the least vulnerable
versions of those.

595
00:26:56,560 --> 00:26:59,610
So, this epiphany means
that as we're gonna try

596
00:26:59,610 --> 00:27:01,030
to make sure that we can meet the needs

597
00:27:01,030 --> 00:27:02,430
of our regulatory requirements.

598
00:27:02,430 --> 00:27:04,910
We're also gonna have to pay
a little bit more attention

599
00:27:04,910 --> 00:27:07,100
to the only using the
freshest of ingredients,

600
00:27:07,100 --> 00:27:09,810
in the food that we produce, so to speak.

601
00:27:09,810 --> 00:27:12,062
And you can learn a ton
more about SBOM elsewhere,

602
00:27:12,063 --> 00:27:15,430
but we're not talking about
revolutionary things here

603
00:27:15,430 --> 00:27:17,780
that they're the minimum
baseline component information

604
00:27:17,780 --> 00:27:19,840
identified from the consensus documents

605
00:27:19,840 --> 00:27:22,569
were essentially seven
fields that can be spit out

606
00:27:22,569 --> 00:27:25,252
as an automated by-product
of your build process

607
00:27:25,252 --> 00:27:27,988
with most modern tools and plugins.

608
00:27:27,988 --> 00:27:30,906
And the goal here is that
this machine-readable

609
00:27:30,906 --> 00:27:33,725
machine-generated artifact
follows code along

610
00:27:33,725 --> 00:27:36,310
for a number of stakeholders and use cases

611
00:27:36,310 --> 00:27:38,639
up and down that supply chain.

612
00:27:38,640 --> 00:27:39,880
And many of those materials,

613
00:27:39,880 --> 00:27:41,774
including some brand new ones yesterday,

614
00:27:41,774 --> 00:27:43,918
had been added to nta.gov/SBOM

615
00:27:43,918 --> 00:27:47,773
with your taxpayer dollars
funding that project.

616
00:27:50,400 --> 00:27:52,214
- So I wanna talk a little bit about

617
00:27:52,214 --> 00:27:56,659
some of these changes in the way products

618
00:27:56,660 --> 00:27:58,560
are being built and deployed.

619
00:27:58,560 --> 00:28:02,429
Because they, you know,
could be introducing risk.

620
00:28:02,430 --> 00:28:07,430
But they also can be used to
help us secure the product.

621
00:28:12,270 --> 00:28:14,930
So if you think about, you know,

622
00:28:14,930 --> 00:28:17,040
a lot of the cloud-native technology.

623
00:28:17,040 --> 00:28:21,249
It's essentially compartmentalizing
pieces of an application

624
00:28:21,249 --> 00:28:26,126
to, you know, in a container or serverless

625
00:28:26,126 --> 00:28:28,892
or as other composable infrastructure

626
00:28:28,892 --> 00:28:31,520
that's provided by your cloud provider.

627
00:28:31,520 --> 00:28:34,450
And it's all driven by
infrastructure as code.

628
00:28:34,450 --> 00:28:38,560
So infrastructure as
code is able to describe

629
00:28:38,560 --> 00:28:40,870
what the environment is.

630
00:28:40,871 --> 00:28:45,871
That the code that you're
writing will be running in.

631
00:28:46,270 --> 00:28:48,521
And what this means is
we can start to secure

632
00:28:48,521 --> 00:28:52,081
all these things that used
to only have a known state

633
00:28:52,081 --> 00:28:53,379
in deployment.

634
00:28:53,380 --> 00:28:55,631
We had to scan it in deployment.

635
00:28:55,631 --> 00:28:58,240
And people could change
that in deployment.

636
00:28:58,240 --> 00:29:01,810
We can start to scan that upstream

637
00:29:01,810 --> 00:29:04,200
back in the development process.

638
00:29:04,200 --> 00:29:09,200
Which should make it a cheaper to deploy,

639
00:29:09,642 --> 00:29:13,163
you know, secure
infrastructure in production.

640
00:29:14,190 --> 00:29:18,790
So what you can do is
you can scan your IAC,

641
00:29:18,790 --> 00:29:22,560
your Terraform, your
cloud formation scripts.

642
00:29:22,560 --> 00:29:24,370
And that can give you the context

643
00:29:24,370 --> 00:29:26,280
that all your code is running in.

644
00:29:26,280 --> 00:29:29,928
And this should help you
eliminate false positives, right?

645
00:29:29,928 --> 00:29:32,306
If you're just scanning
the code, you know,

646
00:29:32,306 --> 00:29:33,799
I do this at work all the time.

647
00:29:33,799 --> 00:29:37,020
We say, "Okay, you have
a SQL injection here."

648
00:29:37,020 --> 00:29:41,117
And the developer will say,
"Yeah, but that database,

649
00:29:41,117 --> 00:29:42,337
"you know, is trusted.

650
00:29:42,337 --> 00:29:44,763
"It's not reachable by anything else.

651
00:29:44,763 --> 00:29:47,419
"There's no vulnerability there."

652
00:29:47,420 --> 00:29:49,570
And that's because just
by looking at the code,

653
00:29:49,570 --> 00:29:52,270
you can't understand the
environment the code is running in.

654
00:29:52,270 --> 00:29:53,840
Now we can see that,

655
00:29:53,840 --> 00:29:55,759
and we can decide not to fix some flaws

656
00:29:55,759 --> 00:30:00,330
because the environment
is protecting them.

657
00:30:00,330 --> 00:30:02,230
The other thing is it allows you

658
00:30:02,230 --> 00:30:05,119
to maybe configure the
environment differently

659
00:30:05,119 --> 00:30:10,119
to block attack surface
from getting to a flaw.

660
00:30:10,410 --> 00:30:13,903
So this, once we start understanding
infrastructure as code,

661
00:30:13,903 --> 00:30:17,095
it allows us to go
faster and actually build

662
00:30:17,095 --> 00:30:18,763
a more secure product.

663
00:30:20,420 --> 00:30:22,740
The other big trend that
we need to take advantage

664
00:30:22,740 --> 00:30:27,100
of the CSPO or CPSO, I'll
get this right someday.

665
00:30:27,100 --> 00:30:30,699
Is developers are hyper
automating everything.

666
00:30:30,700 --> 00:30:33,620
Everything is a script,
everything is code.

667
00:30:33,620 --> 00:30:36,739
Everything is running in
a fully automated way.

668
00:30:36,740 --> 00:30:38,619
And any manual process is, you know,

669
00:30:38,619 --> 00:30:41,370
damaged that needs to be routed around.

670
00:30:41,370 --> 00:30:44,790
So as a product security officer,

671
00:30:44,790 --> 00:30:47,330
you can start to take advantage of this.

672
00:30:47,330 --> 00:30:50,460
And move you, what you
need to do as part of the

673
00:30:50,460 --> 00:30:53,703
software life cycle into this
everything is code world.

674
00:30:57,570 --> 00:31:00,120
So, you know, here are some examples

675
00:31:00,120 --> 00:31:01,443
of what you can do.

676
00:31:01,443 --> 00:31:05,700
The policy that you have for, you know,

677
00:31:05,700 --> 00:31:08,530
whether a defect that's
found should break the build

678
00:31:08,530 --> 00:31:11,190
and not allow a push to production.

679
00:31:11,190 --> 00:31:13,100
That should be written as code.

680
00:31:13,100 --> 00:31:16,976
That can be a text file,
that's analyzed in the pipeline

681
00:31:16,977 --> 00:31:20,140
as it's running.

682
00:31:20,140 --> 00:31:22,780
You know, we can check these policies in.

683
00:31:22,780 --> 00:31:25,129
And we can modify them and
maintain them over time

684
00:31:25,130 --> 00:31:30,110
the way developers will modify
and maintain configuration

685
00:31:30,110 --> 00:31:32,610
of their containers or their Kubernetes.

686
00:31:32,610 --> 00:31:35,830
So we can start to take
our security tooling

687
00:31:35,830 --> 00:31:39,060
that used to be disparate processes

688
00:31:39,060 --> 00:31:40,560
that sometimes were manual.

689
00:31:40,560 --> 00:31:43,000
Sometimes we're driven by an API.

690
00:31:43,000 --> 00:31:46,070
And actually, just make
them another developer tool.

691
00:31:46,070 --> 00:31:47,320
That's part of the process.

692
00:31:47,320 --> 00:31:49,330
This is something that's very exciting

693
00:31:49,330 --> 00:31:51,418
that product security
can leverage to go faster

694
00:31:51,418 --> 00:31:54,899
and make it cheaper to fix bugs.

695
00:31:54,900 --> 00:31:58,260
The other thing we can do in
this everything is code world

696
00:31:58,260 --> 00:32:01,370
is we can understand what's deployed.

697
00:32:01,370 --> 00:32:03,126
We can read all those configuration files.

698
00:32:03,126 --> 00:32:05,260
We can read the infrastructure as code,

699
00:32:05,260 --> 00:32:08,150
and we don't need to
scan production anymore

700
00:32:08,150 --> 00:32:11,761
to keep it up to date and
configured and patched properly.

701
00:32:11,761 --> 00:32:15,379
We can just monitor the
threat information space.

702
00:32:15,380 --> 00:32:18,050
Monitor if a new patch is available.

703
00:32:18,050 --> 00:32:20,688
Or if an open-source component
has a vulnerability in it.

704
00:32:20,689 --> 00:32:22,979
And we can just like update that

705
00:32:22,979 --> 00:32:25,910
and then run our pipeline.

706
00:32:25,910 --> 00:32:28,820
And we, the no more scanning
of production anymore.

707
00:32:28,820 --> 00:32:31,560
And should be faster and cheaper, yeah.

708
00:32:31,560 --> 00:32:34,191
- So we should in and often,
do you automate everything,

709
00:32:34,191 --> 00:32:36,510
the whole idea of rugged DevOps

710
00:32:36,510 --> 00:32:39,400
or what is now DevSecOps and the like.

711
00:32:39,400 --> 00:32:41,750
Tools like breakband
from the Twitter guys.

712
00:32:41,750 --> 00:32:45,327
Tools like gauntlet from
James wicket and others.

713
00:32:45,327 --> 00:32:48,968
If you know the Chaos
Monkey concept from Netflix.

714
00:32:48,968 --> 00:32:50,960
They asked a bunch of
us to help them write

715
00:32:50,960 --> 00:32:53,080
Evil Weaponized, Chaos
Monkeys, and the like,

716
00:32:53,080 --> 00:32:54,929
to be mean to their code.

717
00:32:54,930 --> 00:32:58,060
And those types of things
are useful where you can't,

718
00:32:58,060 --> 00:32:59,950
there's still some need for human talent

719
00:32:59,950 --> 00:33:01,250
and tabletop exercises.

720
00:33:01,250 --> 00:33:02,170
And this is what I often,

721
00:33:02,170 --> 00:33:03,780
I usually when I teach threat modeling,

722
00:33:03,780 --> 00:33:05,930
I make people play Tower
Defense games for a little bit

723
00:33:05,930 --> 00:33:07,210
before the course starts.

724
00:33:07,210 --> 00:33:09,460
So whether it's a simple linear one,

725
00:33:09,460 --> 00:33:11,820
like plants vs zombies or something else.

726
00:33:11,820 --> 00:33:13,649
We talk an awful lot
about threat modeling.

727
00:33:13,650 --> 00:33:15,830
We don't do a whole
lot of threat modeling.

728
00:33:15,830 --> 00:33:17,149
And that became painfully clear

729
00:33:17,150 --> 00:33:21,170
when the USFDA required a
threat model to be published

730
00:33:21,170 --> 00:33:23,440
with every new pre-market
submission for a medical device.

731
00:33:23,440 --> 00:33:25,260
And we realized, Oh my goodness,

732
00:33:25,260 --> 00:33:28,129
there's 10,000 medical device makers.

733
00:33:28,130 --> 00:33:30,250
And there are not 10,000 Adam Shaw stacks.

734
00:33:30,250 --> 00:33:32,450
So while there's great books
and there's great games,

735
00:33:32,450 --> 00:33:34,210
and there's been some
pioneering work here.

736
00:33:34,210 --> 00:33:36,550
We often talk about it more than we do it.

737
00:33:36,550 --> 00:33:38,490
And one of the things I found I had to do

738
00:33:38,490 --> 00:33:41,140
in my last corporate role
was instead of hiring

739
00:33:41,140 --> 00:33:44,340
maybe more breakers or
more security analysts,

740
00:33:44,340 --> 00:33:46,137
I hired security architects.

741
00:33:46,137 --> 00:33:49,128
People who spoke the
language of the architecture

742
00:33:49,128 --> 00:33:52,260
and software development team
who had street cred with them.

743
00:33:52,260 --> 00:33:54,379
But could also get them accustomed

744
00:33:54,380 --> 00:33:56,640
to talking through alternative designs

745
00:33:56,640 --> 00:33:58,310
before we're committed to a bad project

746
00:33:58,310 --> 00:34:00,629
and indefensible architecture.

747
00:34:00,630 --> 00:34:02,410
And these were things of
just whether it's using

748
00:34:02,410 --> 00:34:04,620
the free tools like Microsoft
threat modeling things.

749
00:34:04,620 --> 00:34:06,600
Or some commercial ones.

750
00:34:06,600 --> 00:34:08,639
And having a way to really
easily drag and drop

751
00:34:08,639 --> 00:34:10,851
and visualize alternative trust boundaries

752
00:34:10,851 --> 00:34:13,877
instead of using buzzwords
and marketing terms

753
00:34:13,877 --> 00:34:15,029
like zero trust.

754
00:34:15,030 --> 00:34:17,969
Actually implementing some
of the ideas behind them,

755
00:34:17,969 --> 00:34:20,283
like least privilege and trust boundaries,

756
00:34:20,284 --> 00:34:23,275
and blast radius and things like that.

757
00:34:23,275 --> 00:34:26,199
And these have a double opportunity.

758
00:34:26,199 --> 00:34:28,491
One as you're starting
to design these things

759
00:34:28,492 --> 00:34:30,340
with increased unknowns,

760
00:34:30,340 --> 00:34:32,347
like APIs and ad hoc mashups.

761
00:34:32,347 --> 00:34:34,181
And software-defined networking.

762
00:34:34,181 --> 00:34:36,610
You can try your best to have some sort of

763
00:34:36,610 --> 00:34:40,719
architectural intent to
avoid elective complexity.

764
00:34:40,719 --> 00:34:43,649
But also when you
ultimately make a mistake

765
00:34:43,650 --> 00:34:46,000
or fail, there is a flaw in your buried,

766
00:34:46,000 --> 00:34:47,909
in your software supply chain somewhere.

767
00:34:47,909 --> 00:34:49,366
Impact analysis in your PCR

768
00:34:49,366 --> 00:34:51,280
or it can be quite important.

769
00:34:51,280 --> 00:34:53,159
If you find there's a new flaw,

770
00:34:53,159 --> 00:34:54,109
how bad is it?

771
00:34:54,110 --> 00:34:55,851
Where in my trust model is I?

772
00:34:55,851 --> 00:34:58,352
And is it gonna change
the color of my font,

773
00:34:58,352 --> 00:35:02,410
or is it gonna have a really bad outcome?

774
00:35:02,410 --> 00:35:04,319
So understanding that the relative impact

775
00:35:04,320 --> 00:35:06,670
after you design it
well, such that a flaw,

776
00:35:06,670 --> 00:35:08,680
a leak in any compartment
of your submarine

777
00:35:08,680 --> 00:35:10,879
does not sink the whole ship.

778
00:35:10,880 --> 00:35:12,712
And as the after-mentioned,

779
00:35:12,712 --> 00:35:15,750
one of the things because
we're gonna all systems fail.

780
00:35:15,750 --> 00:35:19,105
We wanna be able to make
ourselves put out the welcome mat

781
00:35:19,105 --> 00:35:21,363
to invite good-faith researchers.

782
00:35:23,208 --> 00:35:25,470
Have the opportunity
to report issues to us

783
00:35:25,470 --> 00:35:27,899
that they find without
fear of legal reprisal.

784
00:35:27,900 --> 00:35:29,900
And I'm so thrilled to see
over the last several years.

785
00:35:29,900 --> 00:35:31,280
A lot of the work that Katie Missouri

786
00:35:31,280 --> 00:35:34,310
and others have done on the ISO standards

787
00:35:34,310 --> 00:35:36,270
and pioneering vulnerability, disclosures,

788
00:35:36,270 --> 00:35:37,780
and bug bounty programs.

789
00:35:37,780 --> 00:35:38,760
Have really taken root,

790
00:35:38,760 --> 00:35:41,220
but these programs are
increasingly present

791
00:35:41,220 --> 00:35:42,879
in safety-critical regulated areas.

792
00:35:42,880 --> 00:35:45,460
There's now a binding
operational directive from CySA

793
00:35:45,460 --> 00:35:47,870
that all the federal
agencies have to do it.

794
00:35:47,870 --> 00:35:50,850
And things like this were
encouraged in the IoT laws

795
00:35:50,850 --> 00:35:51,910
and the like.

796
00:35:51,910 --> 00:35:54,899
So putting out a welcome mat
means wouldn't you rather

797
00:35:54,900 --> 00:35:56,820
find out about a flaw from a friendly

798
00:35:56,820 --> 00:35:59,100
than maybe from an adversary
as you're in the news

799
00:35:59,100 --> 00:36:03,029
and maybe the subject
of congressional action.

800
00:36:03,030 --> 00:36:05,580
So these are just skimming the treetops

801
00:36:05,580 --> 00:36:10,060
of a lot of the topics
covered in a larger discussion

802
00:36:10,060 --> 00:36:12,440
on the shifting roles
and relative priorities

803
00:36:12,440 --> 00:36:13,900
of a chief product security officer.

804
00:36:13,900 --> 00:36:15,680
Again, pause this, if you like,

805
00:36:15,680 --> 00:36:17,700
and look at some of that content,

806
00:36:17,700 --> 00:36:19,520
there's lots of bodies of work here

807
00:36:19,520 --> 00:36:21,610
and they're not all equally important.

808
00:36:21,610 --> 00:36:24,257
And they are not always done in quote

809
00:36:24,257 --> 00:36:27,120
"Best practices for traditional AppSec."

810
00:36:27,120 --> 00:36:29,359
But we hope to have showed
at least contextualize

811
00:36:29,360 --> 00:36:30,780
a little bit of how you might be able

812
00:36:30,780 --> 00:36:32,700
to elevate your game, your career

813
00:36:32,700 --> 00:36:34,633
and help protect your companies.

814
00:36:36,310 --> 00:36:40,173
- So just to wrap it all up,

815
00:36:41,070 --> 00:36:43,242
get a blue suit and a mask

816
00:36:43,242 --> 00:36:46,760
but also take these immediate actions.

817
00:36:46,760 --> 00:36:49,592
You know, read the
cybersecurity executive order.

818
00:36:49,592 --> 00:36:52,004
Get fluent on some of the
things we talked about,

819
00:36:52,004 --> 00:36:56,020
like digital transformation,
supply chain, risk SBOM,

820
00:36:56,020 --> 00:36:57,730
and everything is code movement.

821
00:36:57,730 --> 00:37:00,453
'Cause, you're gonna
need to use those things.

822
00:37:01,362 --> 00:37:04,234
- And then longer-term
if this is a career path

823
00:37:04,234 --> 00:37:05,299
you're interested in.

824
00:37:05,300 --> 00:37:07,394
Or if you've already started,

825
00:37:07,394 --> 00:37:09,080
you can't do everything everywhere.

826
00:37:09,080 --> 00:37:10,590
You can't sprinkle penicillin

827
00:37:10,590 --> 00:37:11,960
vest over all the sick patients.

828
00:37:11,960 --> 00:37:13,540
So one of the most important things I did

829
00:37:13,540 --> 00:37:15,430
both for executive buy-in.

830
00:37:15,430 --> 00:37:18,359
And to make sure that we had
a repeatable objective process

831
00:37:18,360 --> 00:37:22,580
that wasn't swayed by the
winds or climate change.

832
00:37:22,580 --> 00:37:25,380
Or different attitudes or
different executive changeover

833
00:37:25,380 --> 00:37:28,970
is really try to come up
with some objective criteria.

834
00:37:28,970 --> 00:37:31,259
To risk to your things
like what's, you know,

835
00:37:31,260 --> 00:37:35,110
the potential inflict loss
of life or physical harm,

836
00:37:35,110 --> 00:37:36,690
what's touching regulated data with

837
00:37:36,690 --> 00:37:39,010
such as a material amount of our revenue?

838
00:37:39,010 --> 00:37:41,270
Get the top-level concerns
of either your board,

839
00:37:41,270 --> 00:37:42,880
your chief executive,

840
00:37:42,880 --> 00:37:46,511
or your C-suite into a
risk ranking metaphor.

841
00:37:46,511 --> 00:37:48,660
I actually found was the exact opposite

842
00:37:48,660 --> 00:37:49,629
of what I expected.

843
00:37:49,630 --> 00:37:52,120
If you, I thought people would be begging

844
00:37:52,120 --> 00:37:53,359
not to get additional regular.

845
00:37:53,360 --> 00:37:55,250
They were fighting to
get on a higher-tiered

846
00:37:55,250 --> 00:37:56,450
importance list.

847
00:37:56,450 --> 00:37:58,109
So come up with some good criteria

848
00:37:58,110 --> 00:38:00,963
so you can eat the elephant
one bite at a time.

849
00:38:01,950 --> 00:38:04,600
It's gonna have to involve some sort

850
00:38:04,600 --> 00:38:06,860
of third-party risks, education curve.

851
00:38:06,860 --> 00:38:09,270
And there's lots of
schools on this outside

852
00:38:09,270 --> 00:38:11,460
of cybersecurity you can
borrow and steal from.

853
00:38:11,460 --> 00:38:13,630
And there's an increasing
body of work there.

854
00:38:13,630 --> 00:38:15,480
But you're really also
gonna have to find champions

855
00:38:15,480 --> 00:38:17,440
because you're not going to
get a massive team for this.

856
00:38:17,440 --> 00:38:18,400
You're going to have to inspire,

857
00:38:18,400 --> 00:38:21,804
inform and activate the team
of vendors to help you do this.

858
00:38:21,804 --> 00:38:25,440
And that's why executive
sponsorship is so important.

859
00:38:25,440 --> 00:38:27,610
And architecture teams
and engineering leadership

860
00:38:27,610 --> 00:38:29,000
is table stakes.

861
00:38:29,000 --> 00:38:31,394
And depending on the kind
of software or application

862
00:38:31,394 --> 00:38:36,100
you're talking about, IT on
operational leadership as well.

863
00:38:36,100 --> 00:38:39,209
And then start small, introduce
pilots on some of those

864
00:38:39,209 --> 00:38:42,649
top tier or brand new projects instead of

865
00:38:42,650 --> 00:38:44,310
some of the legacy thornier ones.

866
00:38:44,310 --> 00:38:46,366
To maybe introduce threat modeling

867
00:38:46,367 --> 00:38:48,230
SBOM procurement language.

868
00:38:48,230 --> 00:38:49,760
So you can buy more defensible

869
00:38:49,760 --> 00:38:51,953
or procure more defensible
platforms as part

870
00:38:51,953 --> 00:38:54,410
of your overall product attack surface.

871
00:38:54,410 --> 00:38:56,259
But also you're gonna be
expected to produce them.

872
00:38:56,260 --> 00:38:57,960
Remember we're all in the supply chain.

873
00:38:57,960 --> 00:38:59,030
Most of us are in the middle.

874
00:38:59,030 --> 00:39:02,520
We're gonna be both
consuming and producing them.

875
00:39:02,520 --> 00:39:04,540
The vulnerability disclosure
programs are getting traction.

876
00:39:04,540 --> 00:39:07,120
Sometimes you can graduate
with incentives to bounties.

877
00:39:07,120 --> 00:39:10,040
And then automated security as code

878
00:39:10,040 --> 00:39:12,250
is a really great opportunity to take

879
00:39:12,250 --> 00:39:13,730
some of the manual error,

880
00:39:13,730 --> 00:39:17,130
prone and slow process out of
things to liberate your time,

881
00:39:17,130 --> 00:39:19,124
energy, and political capital.

882
00:39:19,124 --> 00:39:22,939
To things that are gonna be
a little bit harder or novel.

883
00:39:22,940 --> 00:39:25,283
So we hope that you start your journey.

884
00:39:26,130 --> 00:39:27,020
Whether you're gonna become

885
00:39:27,020 --> 00:39:28,240
a Chief Product Security Officer.

886
00:39:28,240 --> 00:39:29,209
You're gonna work with one,

887
00:39:29,210 --> 00:39:30,860
or you're really going to perform a subset

888
00:39:30,860 --> 00:39:32,350
of those functions.

889
00:39:32,350 --> 00:39:33,720
The increased regulatory scrutiny,

890
00:39:33,720 --> 00:39:36,221
the increased market demand.

891
00:39:36,222 --> 00:39:39,060
Gives you an opportunity to maybe redefine

892
00:39:39,060 --> 00:39:41,160
and forge another career path

893
00:39:41,160 --> 00:39:43,549
than you've had thus far.

894
00:39:43,550 --> 00:39:46,580
And if Chris or I can be a
resource now or in the future,

895
00:39:46,580 --> 00:39:48,360
we'd love to be, thank you.

896
00:39:48,360 --> 00:39:49,310
- Thanks, everyone.

