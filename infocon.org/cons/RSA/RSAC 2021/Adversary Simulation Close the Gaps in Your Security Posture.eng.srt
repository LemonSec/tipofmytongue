1
00:00:01,070 --> 00:00:02,969
- [Don] Greetings ladies and
gentlemen, this is Don Murdoch

2
00:00:02,970 --> 00:00:05,070
and I'm going to be doing
a talk this afternoon here

3
00:00:05,070 --> 00:00:07,960
at the RSA conference
on adversary simulation.

4
00:00:07,960 --> 00:00:10,170
We're going to go through this process

5
00:00:10,170 --> 00:00:11,645
and what we want to be able to do

6
00:00:11,645 --> 00:00:13,100
throughout this presentation
has help you close the gaps

7
00:00:13,100 --> 00:00:15,070
in your security posture.

8
00:00:15,070 --> 00:00:17,480
So, by way of introduction,
I've been in IT

9
00:00:17,480 --> 00:00:20,260
for well over 25 years, about 17 years

10
00:00:20,260 --> 00:00:21,860
in information security.

11
00:00:21,860 --> 00:00:24,050
And I received what I would affectionately

12
00:00:24,050 --> 00:00:25,550
call my digital combat training

13
00:00:25,550 --> 00:00:28,368
in the Wild, Wild, West
of Academic Computing.

14
00:00:28,368 --> 00:00:31,529
Over that 17 year period
though I spent several years

15
00:00:31,530 --> 00:00:34,550
in there and only had a
brief stint out of InfoSec

16
00:00:34,550 --> 00:00:38,309
where I did strategy and planning
for a larger organization.

17
00:00:38,310 --> 00:00:42,830
A lot of experience in
commercial defense, nonprofit

18
00:00:42,830 --> 00:00:46,489
and I ran a cyber range
for a major university.

19
00:00:46,490 --> 00:00:50,080
I am a SANS instructor,
and also I'm the author

20
00:00:50,080 --> 00:00:51,470
of something you may have heard called

21
00:00:51,470 --> 00:00:52,879
the "Blue Team Handbook"

22
00:00:52,880 --> 00:00:55,050
kind of a well-known
information security book

23
00:00:55,050 --> 00:00:56,852
out there in the space.

24
00:00:58,090 --> 00:00:59,050
I'm currently functioning

25
00:00:59,050 --> 00:01:01,363
as a principal security architect for RSA.

26
00:01:02,290 --> 00:01:04,980
So, the first thing I want to go over

27
00:01:06,230 --> 00:01:09,290
is what is your value chain?

28
00:01:09,290 --> 00:01:13,490
And this is not the
typical IT security topic.

29
00:01:13,490 --> 00:01:15,220
I wanted to begin with this discussion

30
00:01:15,220 --> 00:01:18,060
because we need to be business relevant

31
00:01:18,060 --> 00:01:20,940
in the IT security space
and the business owners

32
00:01:20,940 --> 00:01:23,670
the people that we work
for senior management,

33
00:01:23,670 --> 00:01:25,450
really want to understand how each one

34
00:01:25,450 --> 00:01:28,130
of their departments are
being business relevant.

35
00:01:28,130 --> 00:01:30,320
So, by definition, a formal definition

36
00:01:30,320 --> 00:01:31,916
I put this here to kind of focus us in.

37
00:01:31,917 --> 00:01:35,210
So, value chain are
whatever the activities

38
00:01:35,210 --> 00:01:37,800
that your organization does

39
00:01:37,800 --> 00:01:40,660
in a specific industry in order to

40
00:01:40,660 --> 00:01:43,759
either transform raw materials
into a goods and service,

41
00:01:43,760 --> 00:01:46,760
or have the right staff and
the right service offerings

42
00:01:46,760 --> 00:01:50,730
in order to offer a service in
your industry in the market.

43
00:01:50,730 --> 00:01:53,420
Michael Porter is the
creating or of this term.

44
00:01:53,420 --> 00:01:55,480
So why do we care a
way, why are we starting

45
00:01:55,480 --> 00:01:57,970
off with a business specific term?

46
00:01:57,970 --> 00:02:01,405
First and foremost, if you
understand your value chain,

47
00:02:01,405 --> 00:02:04,530
it's a ready-made catalog
of the possible points

48
00:02:04,530 --> 00:02:07,110
of exposure in your organization.

49
00:02:07,110 --> 00:02:10,026
It also gives you a roadmap or the

50
00:02:10,026 --> 00:02:13,710
for the systems that interact
with the value chain,

51
00:02:13,710 --> 00:02:15,130
the systems that store the data

52
00:02:15,130 --> 00:02:17,490
and the value chain, and perhaps today

53
00:02:17,490 --> 00:02:19,350
especially where the value chain interacts

54
00:02:19,350 --> 00:02:21,579
with other organizations through some kind

55
00:02:21,580 --> 00:02:25,363
of web service or information
exchange, anything like that.

56
00:02:26,290 --> 00:02:29,390
When you understand and you can do things

57
00:02:29,390 --> 00:02:30,709
that understand the value chain,

58
00:02:30,710 --> 00:02:33,140
you're proving that you're
being relevant to your business

59
00:02:33,140 --> 00:02:35,440
or you're being business relevant.

60
00:02:35,440 --> 00:02:38,800
And lastly, it also really tells you

61
00:02:38,800 --> 00:02:40,750
as you look in your environment,

62
00:02:40,750 --> 00:02:41,870
the systems that you're going to

63
00:02:41,870 --> 00:02:44,253
perform adversary simulation on or with

64
00:02:44,253 --> 00:02:48,410
what you can absolutely
not adversely affect.

65
00:02:48,410 --> 00:02:50,070
It helps you to define that

66
00:02:50,070 --> 00:02:53,733
if you are a manufacturing
firm that has some automation

67
00:02:53,733 --> 00:02:56,870
in your manufacturing space,
say robotics or something

68
00:02:56,870 --> 00:02:59,063
along those lines, you
would want to know that

69
00:02:59,063 --> 00:03:02,679
that industrial control
equipment is probably not a good

70
00:03:02,680 --> 00:03:05,853
safe target for your
adversary simulation activity.

71
00:03:06,740 --> 00:03:09,260
So, remember that the blue team defends it

72
00:03:09,260 --> 00:03:11,429
while the red team emulate the tax

73
00:03:11,430 --> 00:03:14,760
who tried to do these
things every single day.

74
00:03:14,760 --> 00:03:16,310
Where can you get some
of this information?

75
00:03:16,310 --> 00:03:19,290
Your business continuity
team is a great partner

76
00:03:19,290 --> 00:03:21,670
in understanding the
components of your value chain

77
00:03:21,670 --> 00:03:24,390
and application and asset priority.

78
00:03:24,390 --> 00:03:26,869
Your disaster recovery
team probably has a lot

79
00:03:26,870 --> 00:03:28,010
of those details to help you.

80
00:03:28,010 --> 00:03:29,660
So, always start with value chain

81
00:03:30,650 --> 00:03:32,250
and our security architecture

82
00:03:32,250 --> 00:03:35,160
and what we're going to
be testing or exercising

83
00:03:35,160 --> 00:03:37,650
through an adversary
simple simulation process

84
00:03:37,650 --> 00:03:39,570
protects that value chain.

85
00:03:39,570 --> 00:03:41,410
You have to think like an adversary,

86
00:03:41,410 --> 00:03:42,942
a red team to find the threats

87
00:03:42,943 --> 00:03:46,600
and you have to act blue to
design and test the defenses.

88
00:03:46,600 --> 00:03:48,540
You'll see this in a few times

89
00:03:48,540 --> 00:03:49,690
in my talk here.

90
00:03:49,690 --> 00:03:51,410
By the way, as I'm going through this,

91
00:03:51,410 --> 00:03:52,366
I forgot to mention.

92
00:03:52,366 --> 00:03:54,140
As you have questions,

93
00:03:54,140 --> 00:03:57,040
please make sure that you ask
those questions in the chat

94
00:03:57,040 --> 00:03:58,410
because I'll be able
to answer them for you

95
00:03:58,410 --> 00:04:00,500
real time during the talk

96
00:04:00,500 --> 00:04:02,362
and when it's given live.

97
00:04:02,362 --> 00:04:06,609
People and processes in your
arbitrary simulation process

98
00:04:06,610 --> 00:04:09,320
you may really want to find out, are you

99
00:04:09,320 --> 00:04:11,530
is there a people or process
that you're going to test

100
00:04:11,530 --> 00:04:14,120
or is there a lot of technology
that you're going to test?

101
00:04:14,120 --> 00:04:16,260
You could look at this and say,

102
00:04:16,260 --> 00:04:18,253
you know, one of the
processes that we have

103
00:04:18,253 --> 00:04:21,550
is creating service desk
tickets for application access.

104
00:04:21,550 --> 00:04:24,274
And maybe I could, in my
adversary simulation, perhaps

105
00:04:24,274 --> 00:04:27,810
I'm doing an insider threat
adversary simulation activity.

106
00:04:27,810 --> 00:04:29,914
Maybe I actually want
to test the ability to

107
00:04:29,914 --> 00:04:34,409
manipulate access control
requests and possibly gain access

108
00:04:34,410 --> 00:04:38,110
to a system that way, rather
than using a technical exploit.

109
00:04:38,110 --> 00:04:40,020
The other half of the
security architecture

110
00:04:40,020 --> 00:04:41,400
that protects our value chain

111
00:04:41,400 --> 00:04:43,479
are all the various technologies that we

112
00:04:43,480 --> 00:04:45,714
use proxies DNS protection,

113
00:04:45,714 --> 00:04:48,390
endpoint detection and response agents,

114
00:04:48,390 --> 00:04:51,753
application firewalls,
application aware firewalls,

115
00:04:51,754 --> 00:04:53,970
how our networks are built what's

116
00:04:53,970 --> 00:04:54,850
in our cloud systems.

117
00:04:54,850 --> 00:04:56,760
So, these things protect the value chain

118
00:04:56,760 --> 00:04:59,921
and they're all in scope for performance,

119
00:04:59,922 --> 00:05:02,420
for integrating them into
an adversary simulation.

120
00:05:02,420 --> 00:05:05,140
Historically, a lot of these activities

121
00:05:05,140 --> 00:05:06,729
were really performed in isolation.

122
00:05:06,730 --> 00:05:08,783
Today, we tend to integrate

123
00:05:08,783 --> 00:05:10,810
when we're performing these activities.

124
00:05:10,810 --> 00:05:12,750
Historically, you have red team performing

125
00:05:12,750 --> 00:05:13,810
an offensive operation.

126
00:05:13,810 --> 00:05:16,200
They tend to do that in isolation in silos

127
00:05:16,200 --> 00:05:18,270
while blue teams are defending.

128
00:05:18,270 --> 00:05:20,200
You'll see a lot of these activities

129
00:05:20,200 --> 00:05:22,050
and we call them purple teaming today.

130
00:05:22,050 --> 00:05:24,463
That's kind of the invoke term.

131
00:05:24,463 --> 00:05:26,450
So, purple teaming is where you perform

132
00:05:26,450 --> 00:05:28,530
a red action and a blue action,

133
00:05:28,530 --> 00:05:31,890
right after it with a goal
of looking at attack defense,

134
00:05:31,890 --> 00:05:33,390
can you detect, can you do,

135
00:05:33,390 --> 00:05:37,250
can you approve defenses
based on a particular attack?

136
00:05:37,250 --> 00:05:38,930
and it's very short cycle.

137
00:05:38,930 --> 00:05:40,910
That's not really what
adversary simulation is about.

138
00:05:40,910 --> 00:05:43,030
And I have a definition on the next slide.

139
00:05:43,030 --> 00:05:44,270
You'll also see here

140
00:05:44,270 --> 00:05:46,330
two things I put in yellow to call out.

141
00:05:46,330 --> 00:05:48,229
We have to understand that today,

142
00:05:48,230 --> 00:05:52,554
Attackers think at graphs
and defenders think in lists.

143
00:05:52,554 --> 00:05:55,840
We have the defense side, think
about the list of resources,

144
00:05:55,840 --> 00:05:58,609
the list of networks, the
list of elevated accounts,

145
00:05:58,610 --> 00:06:01,400
the list of users who we have to protect

146
00:06:01,400 --> 00:06:03,030
Attackers don't think that way

147
00:06:03,030 --> 00:06:04,762
they gain some kind of a toehold

148
00:06:04,762 --> 00:06:06,830
and when they have that toehold,

149
00:06:06,830 --> 00:06:10,010
they figured out where they
can go from that toehold.

150
00:06:10,010 --> 00:06:12,670
And if so, they go to
system A look at system A

151
00:06:12,670 --> 00:06:16,090
talk to system B system B
can talk to system C, D E

152
00:06:16,090 --> 00:06:18,359
and they have to map your network out.

153
00:06:18,360 --> 00:06:20,440
So, remember that we think differently

154
00:06:20,440 --> 00:06:22,800
and that should be incorporated.

155
00:06:22,800 --> 00:06:24,683
From a formal definition,

156
00:06:25,640 --> 00:06:27,930
And this is from a colleague
of mine, Jake Williams

157
00:06:27,930 --> 00:06:30,071
who runs Rendition InfoSec.

158
00:06:30,071 --> 00:06:32,734
An adversary simulation,
we're a red team member

159
00:06:32,734 --> 00:06:36,150
or designated attacker and approved person

160
00:06:36,150 --> 00:06:38,190
is conducting some kind of assessment

161
00:06:39,490 --> 00:06:42,690
and making every effort
to try to use the tools

162
00:06:42,690 --> 00:06:46,420
and techniques by a specific
adversary, a named adversary

163
00:06:46,420 --> 00:06:49,380
someone where that we have
some description about there.

164
00:06:49,380 --> 00:06:51,980
This is different than
"threat emulation" red teams.

165
00:06:51,980 --> 00:06:53,900
They could use anything they want.

166
00:06:53,900 --> 00:06:56,270
So, adversary emulation
and simulation is behaving

167
00:06:56,270 --> 00:06:58,703
like a particular attacker,
probably some an organization

168
00:06:58,703 --> 00:07:01,152
that is specifically
targeting here in adversary.

169
00:07:02,000 --> 00:07:03,940
And purple, it's a different ball of wax.

170
00:07:03,940 --> 00:07:05,870
I just wanted to make sure
that we had these definitions

171
00:07:05,870 --> 00:07:07,280
because you'll see them a lot

172
00:07:07,280 --> 00:07:09,469
and they sound somewhat similar.

173
00:07:09,470 --> 00:07:11,679
So, if you break it down, you know

174
00:07:11,679 --> 00:07:13,820
are now in as our opponent.

175
00:07:13,820 --> 00:07:16,080
And that helps us to focus our attention

176
00:07:16,080 --> 00:07:19,150
in a dispute, an antagonist,
someone coming against us.

177
00:07:19,150 --> 00:07:21,270
If you are a government
military organization

178
00:07:21,270 --> 00:07:22,270
and you're listening to this talk

179
00:07:22,270 --> 00:07:26,090
you have obvious they are
governmental organizations

180
00:07:26,090 --> 00:07:27,609
and militaries that would be imposed

181
00:07:27,610 --> 00:07:30,130
in opposition to your foreign policy.

182
00:07:30,130 --> 00:07:31,690
If you're a commercial entity

183
00:07:31,690 --> 00:07:34,570
maybe another organization
in your commercial sector

184
00:07:35,440 --> 00:07:38,973
and to emulate two is a
verb to strive to be equal.

185
00:07:40,000 --> 00:07:43,760
So therefore, you know, think
red test blue act blue is

186
00:07:43,760 --> 00:07:45,400
if you're simultaneously attacking

187
00:07:45,400 --> 00:07:46,700
and defending the network.

188
00:07:47,689 --> 00:07:49,410
I have a brief diversion here

189
00:07:49,410 --> 00:07:52,140
for the term breach and
attack simulation software.

190
00:07:52,140 --> 00:07:53,390
When you read about these things

191
00:07:53,390 --> 00:07:56,383
you may come across BAS
software applications out there.

192
00:07:57,510 --> 00:08:00,670
BAS is not true adversary simulation,

193
00:08:00,670 --> 00:08:02,970
any of these tools that do BAS

194
00:08:02,970 --> 00:08:04,730
or breach and attack simulation,

195
00:08:04,730 --> 00:08:06,650
exercise of particular part

196
00:08:06,650 --> 00:08:08,940
of your active security apparatus.

197
00:08:08,940 --> 00:08:11,440
So, if you think about phishing testing

198
00:08:11,440 --> 00:08:12,730
and phishing techniques, testing

199
00:08:12,730 --> 00:08:15,240
where there's a number of
vendors that have tools

200
00:08:15,240 --> 00:08:18,400
that will test your anti-phishing defenses

201
00:08:18,400 --> 00:08:19,539
or test your stuff

202
00:08:19,540 --> 00:08:22,340
or see if your anti-virus
things can pick stuff up.

203
00:08:22,340 --> 00:08:24,116
Those are mission specific tools.

204
00:08:24,117 --> 00:08:28,230
So, they're not specific to
humans behaving like red teams.

205
00:08:28,230 --> 00:08:30,450
Just be aware of that as
you're going and doing research

206
00:08:30,450 --> 00:08:33,450
and determining how to
build your program out.

207
00:08:33,450 --> 00:08:35,337
So, you have to have a plan.

208
00:08:35,337 --> 00:08:37,689
First thing is your plan.

209
00:08:37,690 --> 00:08:39,950
When you build an
adversary simulation event

210
00:08:39,950 --> 00:08:42,000
think about a learning outcome.

211
00:08:42,000 --> 00:08:44,550
You want to test and have a use case

212
00:08:44,550 --> 00:08:46,267
where you're testing an insider threat

213
00:08:46,268 --> 00:08:49,120
or an enemy, excuse me, a company

214
00:08:49,120 --> 00:08:51,610
an opposition to you who may gain action

215
00:08:51,610 --> 00:08:53,630
who wants to seal the secret sauce.

216
00:08:53,630 --> 00:08:56,620
If you are Pepsi, maybe you
pretend to be Coke or vice versa

217
00:08:56,620 --> 00:08:59,650
or if you're an architectural company,

218
00:08:59,650 --> 00:09:01,790
maybe another architectural
company may borrow

219
00:09:01,790 --> 00:09:02,829
and invade your network,

220
00:09:02,830 --> 00:09:06,510
but you have to have some
kind of an outline and a plan.

221
00:09:06,510 --> 00:09:08,360
So, we want to achieve an outcome.

222
00:09:08,360 --> 00:09:11,068
We want to improve the
knowledge of our environment

223
00:09:11,068 --> 00:09:12,727
and improve the skills of our staff

224
00:09:12,727 --> 00:09:14,579
and improve improve the
ability of the red team

225
00:09:14,580 --> 00:09:16,070
to perform technical attacks

226
00:09:16,070 --> 00:09:18,610
and the blue team to defend
the technical attacks.

227
00:09:18,610 --> 00:09:20,910
So, we have very specific outcomes.

228
00:09:20,910 --> 00:09:23,068
It is really worth it to
think about your writing

229
00:09:23,068 --> 00:09:25,489
a big picture lab or a big lab.

230
00:09:25,489 --> 00:09:27,080
Come up with your scenario.

231
00:09:27,080 --> 00:09:28,240
Write out the objectives.

232
00:09:28,240 --> 00:09:29,110
Do the outline.

233
00:09:29,110 --> 00:09:32,370
Figure out what controls
are going to be tested.

234
00:09:32,370 --> 00:09:34,230
What your written outcomes are.

235
00:09:34,230 --> 00:09:37,400
You know, make sure that
you have a scoring vehicle.

236
00:09:37,400 --> 00:09:40,360
Did the red team perform
all 20, 30, 40 steps?

237
00:09:40,360 --> 00:09:41,920
Do they gain the expected result?

238
00:09:41,920 --> 00:09:44,530
Did the blue team detect all 40 steps?

239
00:09:44,530 --> 00:09:47,949
Maybe they only detect 10,
which made maybe that meant

240
00:09:47,950 --> 00:09:50,160
that the red team was very effective.

241
00:09:50,160 --> 00:09:52,317
Unless of course they happen
to have been the first 10

242
00:09:52,317 --> 00:09:54,720
and the blue team was actually monitoring.

243
00:09:54,720 --> 00:09:57,447
You know, so where blue
team engages is also

244
00:09:57,447 --> 00:09:59,337
something that you want to achieve

245
00:09:59,337 --> 00:10:01,780
and understanding when you're done.

246
00:10:01,780 --> 00:10:04,370
You should include some
things ahead of time.

247
00:10:04,370 --> 00:10:05,900
Your own fearless knowledge, skills

248
00:10:05,900 --> 00:10:07,870
and ability assessment.

249
00:10:07,870 --> 00:10:09,360
Do you have enough knowledge to do this?

250
00:10:09,360 --> 00:10:11,100
Do you need to go get some more help?

251
00:10:11,100 --> 00:10:13,380
Can you cook up an adversary simulation?

252
00:10:13,380 --> 00:10:15,570
And then they would use
a third party to actually

253
00:10:15,570 --> 00:10:17,410
conduct it who may have
more technical skill.

254
00:10:17,410 --> 00:10:20,480
They may be doing those
sorts of things more often

255
00:10:20,480 --> 00:10:23,550
and fearlessly look at your
people process and technology.

256
00:10:23,550 --> 00:10:24,834
Start small too.

257
00:10:24,835 --> 00:10:26,305
Don't think about,

258
00:10:26,305 --> 00:10:29,410
for our first adversary simulation product

259
00:10:29,410 --> 00:10:30,719
we're going to try and then come up

260
00:10:30,720 --> 00:10:33,560
with something really
grandiose, just start small.

261
00:10:33,560 --> 00:10:37,719
These are skills and muscles
that you're going to develop.

262
00:10:37,720 --> 00:10:39,550
On the other point here,
I wanted to point out

263
00:10:39,550 --> 00:10:42,469
is that sometimes these
things are not as simple

264
00:10:42,470 --> 00:10:43,964
as you would think.

265
00:10:43,964 --> 00:10:47,390
So, if you kind of compare
this to adult education

266
00:10:47,390 --> 00:10:50,120
maybe you're creating a
complex security course

267
00:10:50,120 --> 00:10:52,950
and you want to have a
really great adversary lab

268
00:10:52,950 --> 00:10:54,320
if you will.

269
00:10:54,320 --> 00:10:56,660
There's a lot of professional
education organizations

270
00:10:56,660 --> 00:11:00,304
that tell us to develop a
solid hour of adult content

271
00:11:00,304 --> 00:11:02,579
and lab exercises that go with that

272
00:11:02,580 --> 00:11:06,465
can be anywhere from 23
to 143 labor hours to make

273
00:11:06,465 --> 00:11:09,795
that lab exercise a really useful one.

274
00:11:09,795 --> 00:11:12,395
So, that's kind of something
that we can kind of use

275
00:11:13,290 --> 00:11:14,490
in our planning and thinking

276
00:11:14,490 --> 00:11:16,760
about how much time we have to commit.

277
00:11:16,760 --> 00:11:18,980
If you are an organization
that uses time sheets

278
00:11:18,980 --> 00:11:21,320
it really might be a good idea to actually

279
00:11:21,320 --> 00:11:23,153
have a time sheet charge for this so

280
00:11:23,153 --> 00:11:26,530
that you can know how much one
of these things takes place.

281
00:11:26,530 --> 00:11:28,370
How and where do you start?

282
00:11:28,370 --> 00:11:30,770
So, the first thing that
you want to understand is

283
00:11:30,770 --> 00:11:32,853
the MITRE att&ck framework well-known

284
00:11:32,853 --> 00:11:35,617
provides a really good outline for us

285
00:11:35,617 --> 00:11:37,670
and a really good structured process

286
00:11:37,671 --> 00:11:41,100
to understand the attack
sequence, you know

287
00:11:41,100 --> 00:11:43,660
exploring the network, finding,
try attempting privileges,

288
00:11:43,660 --> 00:11:46,010
escalation, all those sorts of things.

289
00:11:46,010 --> 00:11:47,400
The next thing from that

290
00:11:47,400 --> 00:11:50,970
is you have to have an emulation plan

291
00:11:50,970 --> 00:11:55,410
and I'm going to show
you, the MITRE APT3 plan

292
00:11:55,410 --> 00:11:57,030
which they provide on their website.

293
00:11:57,030 --> 00:12:00,839
So, the APT3 plan is a Excel document.

294
00:12:00,840 --> 00:12:03,700
And when you look at this particular plan

295
00:12:03,700 --> 00:12:05,985
they give you and the plan commands

296
00:12:05,985 --> 00:12:09,380
that's particular adversity group runs

297
00:12:09,380 --> 00:12:11,030
and a sense of order.

298
00:12:11,030 --> 00:12:11,980
And there's different ways

299
00:12:11,980 --> 00:12:13,380
to perform these types of commits.

300
00:12:13,380 --> 00:12:16,189
They've given you a commercial
tool, a cobalt strike.

301
00:12:16,190 --> 00:12:18,606
They've given you a
command to use it an open

302
00:12:18,606 --> 00:12:20,540
source tool called Metasploit, I'm sorry

303
00:12:20,540 --> 00:12:22,300
and a built-in windows commands.

304
00:12:22,300 --> 00:12:24,146
There's a description
on the right hand side.

305
00:12:24,147 --> 00:12:26,670
And there's quite a bit
of information in here

306
00:12:26,670 --> 00:12:27,860
that goes on and on and on

307
00:12:27,860 --> 00:12:30,040
privilege escalation, what would they do?

308
00:12:30,040 --> 00:12:31,740
credential theft, what
are the kinds of things

309
00:12:31,740 --> 00:12:33,563
this particular tab group does?

310
00:12:34,470 --> 00:12:36,307
And then we've got this last one here

311
00:12:36,307 --> 00:12:38,600
maintaining persistence.

312
00:12:38,600 --> 00:12:40,960
So, in understanding what's going on,

313
00:12:40,960 --> 00:12:42,970
this is a very, very useful tool for you.

314
00:12:42,970 --> 00:12:44,840
And it's a great place to start.

315
00:12:44,840 --> 00:12:46,540
Once you've developed some kind of a plan,

316
00:12:46,540 --> 00:12:49,439
how are you going to gain
support for doing this?

317
00:12:49,440 --> 00:12:53,278
First and foremost, as
you build an exercise

318
00:12:53,278 --> 00:12:56,570
and adversary simulation
plan, you're going to end up

319
00:12:56,570 --> 00:12:58,370
maximizing your security spend

320
00:12:58,370 --> 00:13:00,550
and you're going to be
able to test lots of things

321
00:13:00,550 --> 00:13:02,329
in your security spent.

322
00:13:02,330 --> 00:13:05,461
Well-structured events
should not exceed exercise

323
00:13:05,461 --> 00:13:09,040
most of the security and
the technology stack.

324
00:13:09,040 --> 00:13:11,020
All of your stakeholders
are brought together,

325
00:13:11,020 --> 00:13:13,430
your defensive teams or IT support,

326
00:13:13,430 --> 00:13:14,859
your internal red team functions,

327
00:13:14,860 --> 00:13:17,860
your application security
teams for your AppSec folks,

328
00:13:17,860 --> 00:13:19,290
your vulnerability management teams.

329
00:13:19,290 --> 00:13:21,187
They can all be brought together

330
00:13:21,187 --> 00:13:22,740
through one of these exercises.

331
00:13:22,740 --> 00:13:25,366
You want to ensure that
all of your controls

332
00:13:25,366 --> 00:13:29,110
process technical stack
monitoring blue team,

333
00:13:29,110 --> 00:13:32,020
all those operational
controls are working.

334
00:13:32,020 --> 00:13:33,366
Are they configured well?

335
00:13:33,366 --> 00:13:36,090
You want to find errors and weaknesses

336
00:13:36,090 --> 00:13:38,830
before anyone else finds
those errors and weaknesses

337
00:13:38,830 --> 00:13:42,210
especially if that person who
could be finding your weakness

338
00:13:42,210 --> 00:13:45,090
or attacking your network
is in fact an insider.

339
00:13:45,090 --> 00:13:46,780
And you know, that is a real thing.

340
00:13:46,780 --> 00:13:49,260
Doesn't happen as much as we think

341
00:13:49,260 --> 00:13:51,939
but it's common enough to
have an insider of that.

342
00:13:51,940 --> 00:13:54,580
Having an insider threat
simulation scenario

343
00:13:54,580 --> 00:13:56,070
would be very very useful.

344
00:13:56,070 --> 00:13:58,680
I created one of these
for a company recently

345
00:13:58,680 --> 00:14:00,270
and we ran the exercise

346
00:14:00,270 --> 00:14:01,990
and we actually had a willing partner

347
00:14:01,990 --> 00:14:05,715
in the organization who
pretended to be the manager of a

348
00:14:05,715 --> 00:14:07,300
of an intern.

349
00:14:07,300 --> 00:14:09,530
And we had the scenario
that we've hired an intern

350
00:14:09,530 --> 00:14:11,766
but we don't know them too well.

351
00:14:11,766 --> 00:14:14,150
Maybe if there are bad
apples and they came

352
00:14:14,150 --> 00:14:16,680
into the organization, can
we detect them earlier?

353
00:14:16,680 --> 00:14:18,620
How would we go about finding the intern

354
00:14:18,620 --> 00:14:20,140
and where is the intern?

355
00:14:20,140 --> 00:14:23,240
So, we took a person in our organization

356
00:14:23,240 --> 00:14:25,475
and we got them to help us out

357
00:14:25,475 --> 00:14:28,309
emulate kind of an insider threat.

358
00:14:28,309 --> 00:14:30,670
MITRE provides a solid framework.

359
00:14:30,670 --> 00:14:32,490
And other thing I wanted
to tell you is that

360
00:14:32,490 --> 00:14:34,850
with a little bit of documentation effort,

361
00:14:34,850 --> 00:14:36,650
you can create some really nice, you know

362
00:14:36,650 --> 00:14:38,550
audit or compliance, supporting artifacts.

363
00:14:38,550 --> 00:14:40,939
Many of the audit compliance
standards out there

364
00:14:40,940 --> 00:14:43,150
and the auditing process is looking

365
00:14:43,150 --> 00:14:45,579
to determine is your
organization improving

366
00:14:45,580 --> 00:14:47,320
its security posture every year

367
00:14:47,320 --> 00:14:49,540
or on a year over year basis?

368
00:14:49,540 --> 00:14:50,810
Did you do something to

369
00:14:50,810 --> 00:14:52,904
to test her incident response plan.

370
00:14:52,904 --> 00:14:55,300
Going down one of these program paths

371
00:14:55,300 --> 00:14:57,150
could be very very helpful with that.

372
00:14:58,800 --> 00:15:00,973
So, if you want to run an AdSim project,

373
00:15:00,973 --> 00:15:04,120
what's the next thing
that you need to know?

374
00:15:04,120 --> 00:15:06,290
You have to have the roles.

375
00:15:06,290 --> 00:15:09,140
You have to know who's playing
red, white, blue, green.

376
00:15:09,140 --> 00:15:11,420
Willing partners are very helpful.

377
00:15:11,420 --> 00:15:13,150
Define the use cases.

378
00:15:13,150 --> 00:15:15,370
Look at MITRE attack is a good example

379
00:15:15,370 --> 00:15:17,690
to figure out what
skills do you to develop

380
00:15:17,690 --> 00:15:20,373
whether or not you have
right pooling knowledge.

381
00:15:20,373 --> 00:15:22,920
Is there something that
you're going to retire

382
00:15:22,920 --> 00:15:25,401
in your organization
and you want to test it

383
00:15:25,402 --> 00:15:27,320
or you're going to retire
something as a result.

384
00:15:27,320 --> 00:15:28,880
Proof of technical controls.

385
00:15:28,880 --> 00:15:31,189
So, you want to know
that the firewall works

386
00:15:31,190 --> 00:15:33,710
for instance is a really good example.

387
00:15:33,710 --> 00:15:36,110
Many next generation firewall rules today.

388
00:15:36,110 --> 00:15:40,802
Now can use, I have a capability
to detect DNS exfiltration

389
00:15:40,802 --> 00:15:42,430
with a variety of there's a variety

390
00:15:42,430 --> 00:15:44,010
of tools that can do that.

391
00:15:44,010 --> 00:15:45,720
So, you would actually want to say

392
00:15:45,720 --> 00:15:47,770
as a proof of technical control,

393
00:15:47,770 --> 00:15:49,874
we want to exfiltrate data using a number

394
00:15:49,874 --> 00:15:52,133
of different DNS exfiltration tools.

395
00:15:52,133 --> 00:15:53,960
Does this actually work

396
00:15:53,960 --> 00:15:55,923
and did our tool catch that capability?

397
00:15:56,900 --> 00:15:58,069
There's another business term

398
00:15:58,070 --> 00:16:00,530
on the right hand side that
I wanted to bring out here

399
00:16:00,530 --> 00:16:02,750
and it's called SWOT analysis.

400
00:16:02,750 --> 00:16:04,300
SWOT analysis is something that we do

401
00:16:04,300 --> 00:16:05,569
for business side we look at.

402
00:16:05,570 --> 00:16:07,890
Whatever it is we want to work on

403
00:16:07,890 --> 00:16:10,410
whether it's a market or
developing a new product,

404
00:16:10,410 --> 00:16:12,863
we try to identify our
organization's strengths,

405
00:16:12,864 --> 00:16:15,944
we want to identify
organization's weaknesses,

406
00:16:15,944 --> 00:16:18,880
what are the opportunities
that we can exploit

407
00:16:18,880 --> 00:16:20,620
and what are the threats?

408
00:16:20,620 --> 00:16:22,413
So, a little bit of SWOT analysis

409
00:16:22,413 --> 00:16:24,590
and the adversary simulation world

410
00:16:24,590 --> 00:16:26,440
you can apply this way.

411
00:16:26,440 --> 00:16:28,950
You know, our team is really, really good

412
00:16:28,950 --> 00:16:31,680
with using that EDR tool that
we put in place last year.

413
00:16:31,680 --> 00:16:32,870
So maybe we need to figure out

414
00:16:32,870 --> 00:16:36,010
some other way of
getting onto the network.

415
00:16:36,010 --> 00:16:37,722
Maybe there's an opportunity there.

416
00:16:37,722 --> 00:16:40,890
The Linux machines are
covered with the EDR tool.

417
00:16:40,890 --> 00:16:43,481
Maybe, if we get our
establish our initial foothold

418
00:16:43,481 --> 00:16:46,230
and we don't do anything
really bad, but we gain access

419
00:16:46,230 --> 00:16:49,320
to a Linux machine because we
don't have an EDR tool there.

420
00:16:49,320 --> 00:16:51,890
That might be a great way for us to gain

421
00:16:51,890 --> 00:16:54,130
further access to our network.

422
00:16:54,130 --> 00:16:56,145
So, use that a little bit.

423
00:16:56,145 --> 00:16:59,970
I'm a big fan of isolated labs
for doing these activities.

424
00:16:59,970 --> 00:17:01,610
Detection lab is a great tool.

425
00:17:01,610 --> 00:17:04,319
As an example, with just one script

426
00:17:04,319 --> 00:17:06,566
you can install a variety of tools.

427
00:17:06,566 --> 00:17:09,920
About a day later, you get
a pretty good environment

428
00:17:09,920 --> 00:17:11,675
of security Onion has a really nice

429
00:17:11,675 --> 00:17:13,450
detection tool set for you.

430
00:17:13,450 --> 00:17:15,733
It doesn't cost hardly anything to install

431
00:17:15,733 --> 00:17:17,030
and it's well supported,

432
00:17:17,030 --> 00:17:19,379
if you want to commercial
support for that too.

433
00:17:22,079 --> 00:17:26,359
You have to think of these
things as you know your scenario

434
00:17:26,359 --> 00:17:28,159
and your information will flow

435
00:17:28,160 --> 00:17:30,400
during your scenario that you're running.

436
00:17:30,400 --> 00:17:33,167
You want to be as repeatable and reusable

437
00:17:33,167 --> 00:17:37,379
so that you can use this
simulation next year and improve.

438
00:17:37,380 --> 00:17:38,213
Record keeping is really important using

439
00:17:38,213 --> 00:17:42,610
a team of two approach to
make sure that as things occur

440
00:17:42,610 --> 00:17:44,439
one person makes note of things,

441
00:17:44,440 --> 00:17:46,690
notes the time notes, the result.

442
00:17:46,690 --> 00:17:48,000
So those are very very important

443
00:17:48,000 --> 00:17:49,840
for meeting your scenario objectives.

444
00:17:49,840 --> 00:17:52,159
Also, if you list it out,

445
00:17:52,160 --> 00:17:55,003
say we use that APT3 plan
and we tried to exercise all,

446
00:17:55,003 --> 00:17:58,429
I think it's 80 or 90 items in that plan.

447
00:17:58,430 --> 00:18:02,820
Did you actually try all 80
or 90 or 80 or 90 detected?

448
00:18:02,820 --> 00:18:03,860
And when did you try them?

449
00:18:03,860 --> 00:18:07,590
So, making notes in these
activities is really, really good.

450
00:18:07,590 --> 00:18:10,129
You'll also see on this
term of phrase there

451
00:18:10,130 --> 00:18:13,014
to be aware of the
investigation labyrinth.

452
00:18:13,014 --> 00:18:16,483
Each step in the blue team defense process

453
00:18:16,483 --> 00:18:20,865
provides a natural pivot
point for the investigator.

454
00:18:20,865 --> 00:18:23,400
One of my colleagues in
the field, Per Saunders

455
00:18:23,400 --> 00:18:25,500
has done a lot of research in this space.

456
00:18:25,500 --> 00:18:26,875
And what he's found is

457
00:18:26,875 --> 00:18:30,430
after observing a lot of security analysts

458
00:18:30,430 --> 00:18:33,614
is people that pivot
to packet capture data,

459
00:18:33,614 --> 00:18:37,093
or what we call data on the wire

460
00:18:37,093 --> 00:18:41,930
are take 40% longer to close a case

461
00:18:41,930 --> 00:18:44,280
than people that use other data sources

462
00:18:44,280 --> 00:18:46,190
when they're investigating a case.

463
00:18:46,190 --> 00:18:49,950
So, that the natural tendency is to

464
00:18:49,950 --> 00:18:53,450
use the richest contextual
data that we can

465
00:18:53,450 --> 00:18:55,500
and that tends to be packet capture data.

466
00:18:57,000 --> 00:19:00,670
Categorically, that takes
longer to solve the case.

467
00:19:00,670 --> 00:19:04,140
Instead, people who naturally
pivot to other sources

468
00:19:04,140 --> 00:19:08,980
to validate whether a single
event of interest is, or is not

469
00:19:08,980 --> 00:19:11,477
an actual contributing
component to the simulation.

470
00:19:11,477 --> 00:19:14,090
And they prove that out, yes or no.

471
00:19:14,090 --> 00:19:16,810
It help those folks
determine if something is

472
00:19:16,810 --> 00:19:20,560
or is not an issue or readily
and a third of the time.

473
00:19:20,560 --> 00:19:22,899
So, your folks that are
doing the defensive side

474
00:19:22,900 --> 00:19:26,010
of these things need to be
really aware of cognitive bias.

475
00:19:26,010 --> 00:19:26,950
And it's one of those things

476
00:19:26,950 --> 00:19:28,470
that really hurts the blue team.

477
00:19:28,470 --> 00:19:30,650
So, you want to make
sure that the blue team

478
00:19:30,650 --> 00:19:32,350
can solve that case and understand

479
00:19:32,350 --> 00:19:34,399
the thought processes that they're going.

480
00:19:35,320 --> 00:19:38,010
You may implement a change as a result

481
00:19:38,010 --> 00:19:40,137
of this to contain the
breach or the attack.

482
00:19:40,137 --> 00:19:41,780
You may have to make sure

483
00:19:41,780 --> 00:19:45,240
that when you're going through
your adversary simulation,

484
00:19:45,240 --> 00:19:47,690
if you have a material
change to your network

485
00:19:47,690 --> 00:19:49,910
to remediate something that may require

486
00:19:49,910 --> 00:19:50,920
a change control of that.

487
00:19:50,920 --> 00:19:53,440
So, in terms of planning ahead of time,

488
00:19:53,440 --> 00:19:56,119
be aware that's something
that you want to do

489
00:19:56,119 --> 00:19:58,303
or plan for, I'm sorry.

490
00:19:59,340 --> 00:20:01,270
Make sure at the end that you can perform

491
00:20:01,270 --> 00:20:02,760
some root cause analysis.

492
00:20:02,760 --> 00:20:05,620
And oftentimes for these events

493
00:20:05,620 --> 00:20:07,199
you want to produce a formal CAP

494
00:20:07,200 --> 00:20:09,230
or a Corrective Action Plan.

495
00:20:09,230 --> 00:20:11,530
Those are usually measurable targets

496
00:20:11,530 --> 00:20:14,908
of things that you need to
do in your organization.

497
00:20:14,909 --> 00:20:19,130
A couple of axioms here
that we want to think about

498
00:20:19,130 --> 00:20:21,650
when we're measuring
the success of a product

499
00:20:21,650 --> 00:20:24,730
what cannot be measured,
cannot be managed.

500
00:20:24,730 --> 00:20:27,190
If you're trying to assess an aspect

501
00:20:27,190 --> 00:20:30,370
of your program and you don't
have a way to measure it

502
00:20:30,370 --> 00:20:32,360
you really can't manage it.

503
00:20:32,360 --> 00:20:33,639
And another thing is, you know

504
00:20:33,640 --> 00:20:36,650
not everything that counts can be counted.

505
00:20:36,650 --> 00:20:39,670
You may think that there's
a particular aspect

506
00:20:39,670 --> 00:20:42,437
of how your organization,
you're operating at your cooling

507
00:20:42,437 --> 00:20:44,000
your staff, how they work on that.

508
00:20:44,000 --> 00:20:46,370
Maybe very, very difficult to measure.

509
00:20:46,370 --> 00:20:47,929
So just know, be aware of that

510
00:20:47,930 --> 00:20:50,063
walking into the end of the scenario.

511
00:20:51,461 --> 00:20:54,370
I have a variety of metrics
and the blue team handbook.

512
00:20:54,370 --> 00:20:55,669
I thought, I'd give you some of these.

513
00:20:55,670 --> 00:20:58,820
We're going to spell some of
these out in a few minutes.

514
00:20:58,820 --> 00:21:01,010
One of the things that's
kind of really important

515
00:21:01,010 --> 00:21:04,359
to test every time you do an
adversary simulation activity

516
00:21:04,359 --> 00:21:07,149
is your time to sweep the enterprise.

517
00:21:07,150 --> 00:21:09,150
And that really is testing your network.

518
00:21:10,492 --> 00:21:13,610
If you are capable of delivering a binary

519
00:21:13,610 --> 00:21:15,409
to an end user system,

520
00:21:15,410 --> 00:21:19,420
you want to know how hard
or how quickly can we search

521
00:21:19,420 --> 00:21:21,530
every single computer on the network

522
00:21:21,530 --> 00:21:24,690
for that particular binary
there particularly file.

523
00:21:24,690 --> 00:21:25,710
And that's something that you want

524
00:21:25,710 --> 00:21:27,750
to be improving over time.

525
00:21:27,750 --> 00:21:29,440
You say, you're in an organization

526
00:21:29,440 --> 00:21:31,970
and you have 2000 nodes in your network,

527
00:21:31,970 --> 00:21:34,685
maybe 200 servers, nine 1800 workstations

528
00:21:34,685 --> 00:21:37,753
or maybe 1700 workstations
and five shared rooms

529
00:21:37,753 --> 00:21:40,699
that are used for training
or something like that.

530
00:21:40,700 --> 00:21:44,150
You know, the composition of
all of your networks change.

531
00:21:44,150 --> 00:21:47,010
How long does it take you
to check all those machines?

532
00:21:47,010 --> 00:21:50,020
How long does it take you
to check machines that went

533
00:21:50,020 --> 00:21:51,930
out of the network and
came back in the network

534
00:21:51,930 --> 00:21:53,840
for that test, for that particular binary

535
00:21:53,840 --> 00:21:55,260
that you're searching for?

536
00:21:55,260 --> 00:21:58,030
So, these are a variety
of metrics, and I kind

537
00:21:58,030 --> 00:22:00,413
of wanted to highlight time
to sweep the enterprise

538
00:22:00,413 --> 00:22:02,565
because every time you're performing

539
00:22:02,565 --> 00:22:05,971
an adversary simulation event,
you want to exercise that.

540
00:22:05,971 --> 00:22:09,940
There's a couple of key things
you want to measure the MTTD

541
00:22:09,940 --> 00:22:13,510
or the meantime to decision
that is all also people

542
00:22:13,510 --> 00:22:15,140
also say meantime to detection.

543
00:22:15,140 --> 00:22:16,870
That's usually very small because you know

544
00:22:16,870 --> 00:22:19,159
we have SIEM platforms
will tell us things,

545
00:22:19,160 --> 00:22:21,340
you could measure that if you want it to.

546
00:22:21,340 --> 00:22:24,879
But the meantime to decision
is how long it takes an analyst

547
00:22:24,880 --> 00:22:27,070
or a SOC person or a SOC analyst

548
00:22:27,070 --> 00:22:29,610
or some other person involved in defense

549
00:22:29,610 --> 00:22:32,699
to take any event could be an alarm,

550
00:22:32,700 --> 00:22:34,485
could be a particular piece of trace data

551
00:22:34,485 --> 00:22:37,139
and determine if that's
true, meaning it's something

552
00:22:37,140 --> 00:22:39,670
to pay attention to or
it's a false positive.

553
00:22:39,670 --> 00:22:41,720
How long do those decisions take?

554
00:22:41,720 --> 00:22:43,480
The next thing that you want
to be able to measure is

555
00:22:43,480 --> 00:22:47,773
how long does it take to
actually compromise a box

556
00:22:47,773 --> 00:22:51,740
from the minute that the
red team activity initiate

557
00:22:51,740 --> 00:22:54,390
or starts your attack, the
how long they are capable

558
00:22:54,390 --> 00:22:56,522
of actually compromising an end target.

559
00:22:56,522 --> 00:22:58,510
If they're coming in from the web,

560
00:22:58,510 --> 00:23:00,390
it may take them several hours

561
00:23:00,390 --> 00:23:03,170
to actually find an inroad to the network.

562
00:23:03,170 --> 00:23:04,300
That could be a very long time.

563
00:23:04,300 --> 00:23:05,500
It could be two minutes.

564
00:23:06,690 --> 00:23:08,630
So, we want to know
that these are measures

565
00:23:08,630 --> 00:23:10,640
and we want to know how
long these things took.

566
00:23:10,640 --> 00:23:12,560
Because as a result of this

567
00:23:12,560 --> 00:23:15,110
we can figure out if we
need to improve defenses.

568
00:23:15,110 --> 00:23:17,921
The next thing you have, or
the kind of makes a difference

569
00:23:17,922 --> 00:23:19,932
as meantime to privilege escalation.

570
00:23:19,932 --> 00:23:22,252
So how long does it actually take someone

571
00:23:22,252 --> 00:23:25,103
when they gain some kind of a toehold

572
00:23:25,103 --> 00:23:28,090
and go all the way to full compromise

573
00:23:28,090 --> 00:23:31,060
where they have elevated
access to a target?

574
00:23:31,060 --> 00:23:32,850
This is not necessarily immediate.

575
00:23:32,850 --> 00:23:35,280
When we, when you pop a box

576
00:23:35,280 --> 00:23:38,470
you don't necessarily get
domain administrative rights

577
00:23:38,470 --> 00:23:40,870
or membership in an elevated group.

578
00:23:40,870 --> 00:23:41,969
So, you do want to be aware

579
00:23:41,970 --> 00:23:44,511
that that's a measure
that you want to attain.

580
00:23:44,511 --> 00:23:46,830
There's a number of prerequisites you have

581
00:23:46,830 --> 00:23:49,750
to have to successfully
measure your program.

582
00:23:49,750 --> 00:23:52,092
Make sure that you have
good centralized logging.

583
00:23:52,092 --> 00:23:53,890
Some of you may or may not have that

584
00:23:53,890 --> 00:23:56,530
but if you're going to
test a particular control

585
00:23:56,530 --> 00:23:58,383
or a particular technical system,

586
00:23:58,383 --> 00:24:00,480
make sure that you've
actually got that turned

587
00:24:00,480 --> 00:24:03,082
on and it works because
you do want to know.

588
00:24:03,082 --> 00:24:06,960
We do want to avoid what we
call the coffee break SIEM

589
00:24:06,960 --> 00:24:09,692
by my colleague, Justin
Henderson talks about this,

590
00:24:09,692 --> 00:24:12,050
it's a great phase for the
kind of security platform

591
00:24:12,050 --> 00:24:14,430
where you instrument a search

592
00:24:14,430 --> 00:24:16,460
and then you push the button
to go start the search,

593
00:24:16,460 --> 00:24:20,230
so you're looking for something
over the last 24 hours and

594
00:24:20,230 --> 00:24:22,620
you know, behavioral, you
have enough time to walk down

595
00:24:22,620 --> 00:24:24,949
to the other end of the
building, get a cup of Joe,

596
00:24:24,950 --> 00:24:28,220
doctored up with the
appropriate amount of Splenda

597
00:24:28,220 --> 00:24:30,391
the pink stuff, or sugar and creamer.

598
00:24:30,391 --> 00:24:33,450
Couple of stirs, say hi to
somebody at the water cooler

599
00:24:33,450 --> 00:24:34,600
and come back.

600
00:24:34,600 --> 00:24:37,695
If it takes your SIEM that
long to give you that answer

601
00:24:37,695 --> 00:24:41,629
that's something that you
want to work and avoid

602
00:24:41,630 --> 00:24:44,480
and kind of figure out what
you can do to, to solve that.

603
00:24:46,000 --> 00:24:48,610
You may or may not have a
luxury of an EDR platform.

604
00:24:48,610 --> 00:24:50,760
Not many, not necessarily
organization does

605
00:24:50,760 --> 00:24:52,510
but there's some really great tools

606
00:24:52,510 --> 00:24:55,050
from Microsoft that have
come out that you could use

607
00:24:55,050 --> 00:24:58,080
to better instrument detection
on your windows platform,

608
00:24:58,080 --> 00:25:00,633
sysmon is that tool, has
a lot of great visibility.

609
00:25:00,633 --> 00:25:03,440
And if you, if you don't own EDR platform,

610
00:25:03,440 --> 00:25:05,250
one of the great things you could do

611
00:25:05,250 --> 00:25:07,830
is use windows event
collection, or when does event

612
00:25:07,830 --> 00:25:11,710
forwarding and Microsoft
sysmon to go centrally collect

613
00:25:11,710 --> 00:25:13,084
some data onto a central system.

614
00:25:13,084 --> 00:25:15,943
So, you do have to be
aware that your end point,

615
00:25:15,943 --> 00:25:18,764
your individual workstation,
your windows machine

616
00:25:18,764 --> 00:25:21,810
will probably need some
extra instrumentation

617
00:25:21,810 --> 00:25:25,010
to give you a really good
view of what actually happened

618
00:25:25,010 --> 00:25:26,710
on the machine.

619
00:25:26,710 --> 00:25:29,055
Network device logs, if you don't have

620
00:25:29,055 --> 00:25:31,743
a perimeter packet capture system,

621
00:25:31,743 --> 00:25:35,129
Zeek is an open source
tool, you can deploy it

622
00:25:35,130 --> 00:25:37,874
on a medium class machine
with a mirror port

623
00:25:37,874 --> 00:25:39,623
and collect really good data

624
00:25:39,623 --> 00:25:43,340
to have perimeter NIDS or for
not those sorts of things.

625
00:25:43,340 --> 00:25:45,020
And you gotta have people power.

626
00:25:45,020 --> 00:25:46,800
One of the things that
you need to make these

627
00:25:46,800 --> 00:25:49,575
programs really successful is
a lot of natural curiosity.

628
00:25:49,575 --> 00:25:51,703
People have to be kind of inquisitive.

629
00:25:51,703 --> 00:25:54,084
You want to have a lot of patients.

630
00:25:54,084 --> 00:25:57,700
That person has to be patient,
not every red team tool

631
00:25:57,700 --> 00:26:01,101
or attack tool works
correctly every single time.

632
00:26:01,101 --> 00:26:02,800
If you think that's the case

633
00:26:02,800 --> 00:26:03,960
you probably haven't used enough.

634
00:26:03,960 --> 00:26:06,150
Sometimes they work only half the time.

635
00:26:06,150 --> 00:26:07,683
Sometimes they only work 10% of the time

636
00:26:07,683 --> 00:26:10,030
and you have to have patience.

637
00:26:10,030 --> 00:26:11,543
You also have to question yourself

638
00:26:11,543 --> 00:26:14,600
is this technique working or not working?

639
00:26:14,600 --> 00:26:16,870
Am I actually detecting
what I think I'm detecting?

640
00:26:16,870 --> 00:26:20,340
How can I in the moment improves
produce a better detection?

641
00:26:20,340 --> 00:26:23,081
So, I think low ego really
helps for person power.

642
00:26:23,082 --> 00:26:24,970
Attention to detail makes a lot

643
00:26:24,970 --> 00:26:26,284
of difference of the blue team

644
00:26:26,284 --> 00:26:29,170
One of my colleagues, John
Hubbard mentioned that

645
00:26:29,170 --> 00:26:33,160
his best blue teamer and the
SOC that he ran was a librarian

646
00:26:33,160 --> 00:26:35,203
because she had great attention to detail

647
00:26:35,203 --> 00:26:36,821
and had very structured thinking.

648
00:26:36,821 --> 00:26:40,213
And a solid IT background
is also, very, very helpful.

649
00:26:42,693 --> 00:26:44,660
Since the other half of
performing the attack

650
00:26:44,660 --> 00:26:46,830
is exercising the defense, you know,

651
00:26:46,830 --> 00:26:49,021
be aware that there's
a variety of services

652
00:26:49,021 --> 00:26:52,069
that the SOC will hopefully
engage in these process.

653
00:26:52,069 --> 00:26:55,750
As you look at this list,
there's a few of these

654
00:26:55,750 --> 00:27:00,597
that may cause a financial
opportunity for you.

655
00:27:00,597 --> 00:27:02,800
As part of your incident response plan

656
00:27:02,800 --> 00:27:05,517
is to always capture a
machine or capture a machine.

657
00:27:05,517 --> 00:27:08,220
If the attack looks like it's going to be

658
00:27:08,220 --> 00:27:10,964
particularly successful and
perform a forensic analysis

659
00:27:10,964 --> 00:27:13,550
that could be a significant
amount of labor.

660
00:27:13,550 --> 00:27:15,860
If you've outsourced forensics and say

661
00:27:15,860 --> 00:27:18,000
your have your willing partner

662
00:27:18,000 --> 00:27:20,536
and the defense team comes
up and grabs his laptop

663
00:27:20,536 --> 00:27:22,400
it's just, there's something suspicious,

664
00:27:22,400 --> 00:27:24,770
we have to go and they take that laptop

665
00:27:24,770 --> 00:27:25,670
and they're going to send it off

666
00:27:25,670 --> 00:27:27,723
to a forensics company immediately.

667
00:27:29,160 --> 00:27:30,720
You may or may not want to achieve

668
00:27:30,720 --> 00:27:32,800
that as part of your adversary simulation

669
00:27:32,800 --> 00:27:34,450
because that could be an expense.

670
00:27:35,505 --> 00:27:36,430
Now, as you're looking
at the, at this list

671
00:27:36,430 --> 00:27:38,737
these are typical security
operations services.

672
00:27:38,737 --> 00:27:40,820
You're aware of what
you're actually going to

673
00:27:40,820 --> 00:27:42,919
be exercising and know
if there's something

674
00:27:42,920 --> 00:27:44,877
that they have a cost component

675
00:27:44,877 --> 00:27:46,603
because you may want to head that off.

676
00:27:48,640 --> 00:27:51,390
As your program matures, meaning
as you've done your first,

677
00:27:51,390 --> 00:27:53,980
second, third, fourth
test, you know, make sure

678
00:27:53,980 --> 00:27:57,260
that you use the right
adversary group data

679
00:27:57,260 --> 00:27:59,600
and make sure that you
can map your effectiveness

680
00:27:59,600 --> 00:28:01,439
against the MITRE ATT&CK process.

681
00:28:01,440 --> 00:28:02,800
And I'm going to show you one

682
00:28:02,800 --> 00:28:04,530
of these groups structures right now.

683
00:28:04,530 --> 00:28:06,960
So, MITRE's put together
a lot of information

684
00:28:06,960 --> 00:28:08,600
on various groups empirically.

685
00:28:08,600 --> 00:28:10,040
They figured a lot of things out

686
00:28:10,040 --> 00:28:12,320
as they've been doing
this for quite some time.

687
00:28:12,320 --> 00:28:15,030
And for this particular
one, this is the APT3.

688
00:28:15,030 --> 00:28:17,399
It goes hand-in-hand with
the spreadsheet I showed you.

689
00:28:17,400 --> 00:28:19,680
Think about the techniques that they use.

690
00:28:19,680 --> 00:28:21,210
This is what what's been observed

691
00:28:21,210 --> 00:28:23,225
by this particular attack group.

692
00:28:23,225 --> 00:28:26,514
You can look at it at an
individual tool and say,

693
00:28:26,514 --> 00:28:30,580
what does that organization
use for software packing?

694
00:28:30,580 --> 00:28:32,129
And do I want to build that into my plan?

695
00:28:32,130 --> 00:28:34,290
So, you could click on software packing

696
00:28:34,290 --> 00:28:36,909
and see what are examples
of it who uses it

697
00:28:36,910 --> 00:28:39,240
and what types of tools are out there

698
00:28:39,240 --> 00:28:40,970
and see if there's a
mitigation or a defense.

699
00:28:40,970 --> 00:28:43,210
So, this is another really useful tool

700
00:28:43,210 --> 00:28:46,212
that MITRE's put together
when we're helping to design.

701
00:28:46,212 --> 00:28:48,379
And we can use this tool to help design

702
00:28:48,380 --> 00:28:51,125
our adversary processes.

703
00:28:51,125 --> 00:28:53,970
There's a number of candidates
for your tool inventory

704
00:28:53,970 --> 00:28:56,270
and I'm going to swap to the next slide

705
00:28:56,270 --> 00:28:57,190
and show you a chart.

706
00:28:57,190 --> 00:28:59,330
And then I'm going to
come back to this one.

707
00:28:59,330 --> 00:29:02,404
The folks that PenTestIT
maintain a pretty good list

708
00:29:02,404 --> 00:29:04,366
of some of the major tools out there.

709
00:29:04,366 --> 00:29:08,760
And they can tell you
which tool actually goes

710
00:29:08,760 --> 00:29:11,210
with which part of the
MITRE attack process.

711
00:29:11,210 --> 00:29:12,760
I'm going to go back
to the previous slide.

712
00:29:12,760 --> 00:29:15,830
So what are some
candidates, APT Simulator,

713
00:29:15,830 --> 00:29:17,732
Microsoft Caldera, really good tools.

714
00:29:17,732 --> 00:29:22,322
Atomic red team, Red Team
Automation (RTA), DumpsterFire.

715
00:29:23,350 --> 00:29:25,129
There's a lot of these tools out there

716
00:29:25,130 --> 00:29:27,246
and there's a lot more red team tools

717
00:29:27,246 --> 00:29:29,854
than there are blue team tools.

718
00:29:29,854 --> 00:29:32,460
There's a couple of detection tools though

719
00:29:32,460 --> 00:29:33,490
that you should be aware of

720
00:29:33,490 --> 00:29:36,126
and really should use in your apparatus.

721
00:29:36,126 --> 00:29:40,810
If you don't have a packet
capture or an analysis tool

722
00:29:40,810 --> 00:29:43,960
or a network intrusion detection,
maybe you're a small shop.

723
00:29:43,960 --> 00:29:46,010
Security onion is a phenomenal package.

724
00:29:46,010 --> 00:29:48,564
I'm going to be able to show
you what some of the output

725
00:29:48,564 --> 00:29:50,620
of that looks like when I
show you the example tool

726
00:29:50,620 --> 00:29:52,270
then we're going to show you at the end

727
00:29:52,270 --> 00:29:53,879
of the presentation here.

728
00:29:53,880 --> 00:29:55,890
On your build environment, you be aware

729
00:29:55,890 --> 00:29:58,890
that you do have to have
a variety of things set up

730
00:29:58,890 --> 00:30:00,980
and you don't want to be
doing this in production.

731
00:30:00,980 --> 00:30:03,463
So, detection lab is a nice tool

732
00:30:03,463 --> 00:30:05,389
that you can get Chris Long created.

733
00:30:05,390 --> 00:30:07,470
It's a script that runs

734
00:30:07,470 --> 00:30:09,450
and it builds an active directory for you

735
00:30:09,450 --> 00:30:12,220
sets up a Splunk server, sets up a couple

736
00:30:12,220 --> 00:30:15,087
of windows clients, downloads
the MITRE Caldera tool

737
00:30:15,087 --> 00:30:16,810
and implements OSQuery.

738
00:30:16,810 --> 00:30:19,970
So, it's basically a all in one tool set.

739
00:30:19,970 --> 00:30:22,960
So, if you want to try
to test out a technique

740
00:30:22,960 --> 00:30:25,610
on a windows machine against
an active directory domain

741
00:30:25,610 --> 00:30:28,250
or something like that,
you have most of the things

742
00:30:28,250 --> 00:30:31,030
that you would need and
it becomes disposable.

743
00:30:31,030 --> 00:30:33,311
Just rerun the script by
four or five hours later

744
00:30:33,311 --> 00:30:34,639
you'll have a new one,

745
00:30:34,640 --> 00:30:37,310
runs for both Bash and PowerShell.

746
00:30:38,330 --> 00:30:40,129
And I mentioned this before earlier,

747
00:30:41,040 --> 00:30:41,873
Game day.

748
00:30:41,873 --> 00:30:44,290
You've got everything, you've figured out,

749
00:30:44,290 --> 00:30:46,810
you've got your support,
you're going to go ahead

750
00:30:46,810 --> 00:30:48,860
and actually, you know
do your attack, right?

751
00:30:48,860 --> 00:30:50,938
Make sure you have air cover.

752
00:30:50,939 --> 00:30:53,840
You're probably gonna
use adversary simulation

753
00:30:53,840 --> 00:30:56,091
in a contained environment where

754
00:30:56,091 --> 00:30:57,879
you're going to be authorized to do it.

755
00:30:57,880 --> 00:30:59,590
You've got your VP, your, you know

756
00:30:59,590 --> 00:31:01,760
your authorizing party, your Cisco

757
00:31:01,760 --> 00:31:05,379
and you've given him or her
your plan, they've approved it.

758
00:31:05,380 --> 00:31:07,280
And you want to make
sure that you're capable

759
00:31:07,280 --> 00:31:09,739
of telling that that
authorizer or approver

760
00:31:09,739 --> 00:31:11,180
we've rehearsed this.

761
00:31:11,180 --> 00:31:12,013
We've run the steps.

762
00:31:12,013 --> 00:31:13,250
We can do this under control

763
00:31:13,250 --> 00:31:15,170
And we know what we're doing.

764
00:31:15,170 --> 00:31:17,530
Make sure that you have a willing partner.

765
00:31:17,530 --> 00:31:19,049
It's a phenomenal useful tool.

766
00:31:19,049 --> 00:31:21,950
I think I mentioned
earlier, the intern example

767
00:31:21,950 --> 00:31:24,190
we came for our insider threat scenario.

768
00:31:24,190 --> 00:31:26,481
Our willing partner
was really good at that

769
00:31:26,481 --> 00:31:28,851
because our, we had our willing partner

770
00:31:28,851 --> 00:31:31,339
just responding via text message

771
00:31:31,339 --> 00:31:34,050
and he was kind of playing
dumb on our behalf.

772
00:31:34,050 --> 00:31:35,860
So, it really set the
blue team through the loop

773
00:31:35,860 --> 00:31:38,277
figuring out what is
this kid doing? you know.

774
00:31:38,278 --> 00:31:40,250
Make sure that your record results

775
00:31:40,250 --> 00:31:41,403
with a full time stamp.

776
00:31:42,290 --> 00:31:43,310
Your blue team,

777
00:31:43,310 --> 00:31:44,470
are you going to an ask

778
00:31:44,470 --> 00:31:47,290
the adversary simulation activity or not?

779
00:31:47,290 --> 00:31:49,070
Be aware of the Hawthorne Effect.

780
00:31:49,070 --> 00:31:51,760
The Hawthorne Effect,
another business term

781
00:31:51,760 --> 00:31:55,470
is a study that was done
and basically the study

782
00:31:55,470 --> 00:31:57,709
found out that even when

783
00:31:57,709 --> 00:31:58,542
people

784
00:31:58,542 --> 00:32:02,250
were not being directly
observed, if they thought

785
00:32:02,250 --> 00:32:04,268
that they were being observed

786
00:32:04,268 --> 00:32:08,900
they behaved in a better manner,
in a more productive manner

787
00:32:08,900 --> 00:32:11,073
So, that the study goes
that they were doing,

788
00:32:11,073 --> 00:32:12,420
they were trying to determine

789
00:32:12,420 --> 00:32:15,500
how to make an a particular
environment better

790
00:32:15,500 --> 00:32:17,630
and they told staff members
what they were doing

791
00:32:17,630 --> 00:32:21,130
was observing the amount
of light in the room,

792
00:32:21,130 --> 00:32:23,201
it's kind of a big manufacturing facility.

793
00:32:23,201 --> 00:32:27,050
So, they had folks on
a catwalk, walked in,

794
00:32:27,050 --> 00:32:28,180
looking at people.

795
00:32:28,180 --> 00:32:31,130
And just because people thought
they were being observed

796
00:32:31,130 --> 00:32:33,449
they performed differently than they do

797
00:32:33,449 --> 00:32:35,650
in regular circumstances.

798
00:32:35,650 --> 00:32:37,890
So, you know, be aware that
human behavior changes,

799
00:32:37,890 --> 00:32:40,650
if they are knowing that being observed.

800
00:32:40,650 --> 00:32:43,090
You probably want to do this
in an unannounced fashion

801
00:32:43,090 --> 00:32:45,790
make sure that your normal
processes are working.

802
00:32:45,790 --> 00:32:47,090
Have your detection event.

803
00:32:48,530 --> 00:32:50,180
You do want to make sure that

804
00:32:50,180 --> 00:32:53,270
your IR commander is not really aware

805
00:32:53,270 --> 00:32:54,860
that you're doing an incident response act

806
00:32:54,860 --> 00:32:57,467
or excuse me an adversary
simulation activity.

807
00:32:57,468 --> 00:32:58,670
So, they're trying to behave

808
00:32:58,670 --> 00:33:00,700
and collect the data and
they don't get lackadaisical.

809
00:33:00,700 --> 00:33:02,380
And realized that an outcome

810
00:33:02,380 --> 00:33:05,683
from your blue team should be
the actual end product report.

811
00:33:07,060 --> 00:33:08,960
You may have a green team, a green team

812
00:33:08,960 --> 00:33:10,650
or some people call it a white team.

813
00:33:10,650 --> 00:33:13,220
The green team is actively
listening and observing.

814
00:33:13,220 --> 00:33:14,840
If you were to do this in conjunction

815
00:33:14,840 --> 00:33:16,520
with your internal audit division,

816
00:33:16,520 --> 00:33:18,060
may or may not want to do that

817
00:33:18,060 --> 00:33:20,889
they would be the active,
disinterested observer.

818
00:33:20,890 --> 00:33:24,260
Their goal is to protect
the integrity of the event.

819
00:33:24,260 --> 00:33:25,180
They will grade both teams

820
00:33:25,180 --> 00:33:27,290
and produce an outcome briefing for you.

821
00:33:27,290 --> 00:33:29,290
That's kind of what the green team does.

822
00:33:30,707 --> 00:33:33,860
You'll have an after action
event, information exchange.

823
00:33:33,860 --> 00:33:35,669
Make sure that you have objective criteria

824
00:33:35,670 --> 00:33:37,280
for your grading and your timeline.

825
00:33:37,280 --> 00:33:39,060
Make sure people know what they did.

826
00:33:39,060 --> 00:33:41,870
People wrote down their
observations in writing.

827
00:33:41,870 --> 00:33:43,919
It's really good to have
people just take an hour

828
00:33:43,920 --> 00:33:46,610
and make some notes because
it's not in your memory

829
00:33:46,610 --> 00:33:48,606
they could test the notes they took.

830
00:33:48,606 --> 00:33:51,160
I, are very much, it's an
a response can very much

831
00:33:51,160 --> 00:33:52,870
like a tree with many,
many different approaches

832
00:33:52,870 --> 00:33:54,320
that many different branches

833
00:33:54,320 --> 00:33:56,500
and what I did cyber range stuff

834
00:33:56,500 --> 00:33:58,398
with various folks at the university,

835
00:33:58,398 --> 00:34:01,167
I probably had easily 150,

836
00:34:01,167 --> 00:34:03,070
200 people go through
a variety of scenarios.

837
00:34:03,070 --> 00:34:07,253
I rarely had two people solve
a scenario the same way.

838
00:34:08,870 --> 00:34:11,759
But incident response is
a very much a team sport.

839
00:34:11,760 --> 00:34:14,627
This is the other side
of the adversary event.

840
00:34:14,627 --> 00:34:15,460
This is the blue team defense side.

841
00:34:15,460 --> 00:34:17,580
Make sure you're documenting as you go.

842
00:34:17,580 --> 00:34:19,219
A template makes a difference.

843
00:34:19,219 --> 00:34:20,850
You can choose your format.

844
00:34:20,850 --> 00:34:22,860
You could follow the SANS
format, which, you know

845
00:34:22,860 --> 00:34:26,699
pick on a row, preparation,
identification, containment

846
00:34:26,699 --> 00:34:28,799
another cover lessons
learned, or you could use more

847
00:34:28,800 --> 00:34:31,909
of an executive, a business
type format of state

848
00:34:31,909 --> 00:34:34,690
your executive summary upfront.

849
00:34:34,690 --> 00:34:36,639
Describe the case, read your root cause

850
00:34:36,639 --> 00:34:37,529
and give the timeline data.

851
00:34:37,530 --> 00:34:39,027
But what's important is

852
00:34:39,027 --> 00:34:40,560
that you have a template to follow it.

853
00:34:40,560 --> 00:34:42,920
You do want to make sure that your

854
00:34:42,920 --> 00:34:44,460
your after-action is blameless

855
00:34:44,460 --> 00:34:47,210
and encourage everyone
to contribute and talk.

856
00:34:47,210 --> 00:34:48,940
You may have some folks
who may not be happy

857
00:34:48,940 --> 00:34:49,773
with their performance

858
00:34:49,773 --> 00:34:51,870
and you may have to kind of tease them out

859
00:34:51,870 --> 00:34:53,839
or encourage them to talk
and share their experience.

860
00:34:53,840 --> 00:34:56,659
Just be aware from a human
behavior perspective.

861
00:34:56,659 --> 00:34:59,883
You may have to be a really
good facilitator in the outcome.

862
00:35:00,787 --> 00:35:03,220
Another thing that you want to think about

863
00:35:03,220 --> 00:35:05,129
or is this a really good activity

864
00:35:05,130 --> 00:35:06,630
for these adversaries simulations?

865
00:35:06,630 --> 00:35:08,320
This was an article I picked up

866
00:35:08,320 --> 00:35:10,240
and doing research for
this PenTest magazine.

867
00:35:10,240 --> 00:35:13,383
The story goes that
they're doing an activity.

868
00:35:14,540 --> 00:35:17,350
And because the blue team had access

869
00:35:17,350 --> 00:35:19,040
to a red team pentest person,

870
00:35:19,040 --> 00:35:20,750
and they were dealing with a case,

871
00:35:20,750 --> 00:35:23,177
they brought the red
teamer in and they said,

872
00:35:23,177 --> 00:35:25,230
"This is what's going on
and we have this event"

873
00:35:25,230 --> 00:35:27,750
and the red teamer in
the moment, look at that.

874
00:35:27,750 --> 00:35:31,250
Look at the live attack
and kind of made a plan.

875
00:35:31,250 --> 00:35:34,480
And what the team did was
in real time that red team

876
00:35:34,480 --> 00:35:36,450
or that pen tester did a scan

877
00:35:36,450 --> 00:35:38,960
because they saw where the
attacker was first going.

878
00:35:38,960 --> 00:35:40,100
They found that weakness

879
00:35:40,100 --> 00:35:42,250
they coordinated a change that

880
00:35:42,250 --> 00:35:43,640
the blue team then put in place

881
00:35:43,640 --> 00:35:46,480
with emergency change
control within an hour.

882
00:35:46,480 --> 00:35:48,880
Their adversary was
actually attempting to very

883
00:35:48,880 --> 00:35:50,620
same thing that the red teamer had done.

884
00:35:50,620 --> 00:35:54,270
So, you know, it may
be a interesting thing

885
00:35:54,270 --> 00:35:56,170
for your adversary simulation exercise

886
00:35:57,164 --> 00:35:58,775
to bring in a pentest person

887
00:35:58,775 --> 00:36:01,030
and inject that into the scenario.

888
00:36:01,030 --> 00:36:03,330
It may, it made you do
an interesting dynamic.

889
00:36:04,300 --> 00:36:06,090
So, we have some takeaways here.

890
00:36:06,090 --> 00:36:08,370
I want to hit before I show you a tool

891
00:36:08,370 --> 00:36:09,500
that may be helpful for you.

892
00:36:09,500 --> 00:36:11,390
That's a very low cost tool.

893
00:36:11,390 --> 00:36:13,223
First thing is think 30 days.

894
00:36:13,224 --> 00:36:14,915
Identify your value chain.

895
00:36:14,915 --> 00:36:17,683
Talk to your business continuity, DRP plan

896
00:36:17,684 --> 00:36:20,180
Perform a threat analysis
that should really help

897
00:36:20,180 --> 00:36:21,790
to inform your simulation plan.

898
00:36:21,790 --> 00:36:24,060
Determine what you're going
to do now, what you have

899
00:36:24,060 --> 00:36:25,750
and what you can't break.

900
00:36:25,750 --> 00:36:27,080
That's important.

901
00:36:27,080 --> 00:36:28,759
60 days, you should have enough

902
00:36:28,760 --> 00:36:31,290
of an environment to build out stage.

903
00:36:31,290 --> 00:36:32,201
Do some testing.

904
00:36:32,201 --> 00:36:34,690
Get things that look
like your environment.

905
00:36:34,690 --> 00:36:36,780
Maybe, if you use the detection lab model

906
00:36:36,780 --> 00:36:39,480
you could then go pull
all of your policies

907
00:36:39,480 --> 00:36:41,510
from your active directory
domain and use that

908
00:36:41,510 --> 00:36:44,270
in the active directory, in
a detection lab environment.

909
00:36:44,270 --> 00:36:46,650
So, that your windows PC,
that you're going to use

910
00:36:46,650 --> 00:36:48,950
in that environment is
instrumented exactly the same

911
00:36:48,950 --> 00:36:50,279
at your production domain.

912
00:36:50,280 --> 00:36:52,369
You got to think about your tooling

913
00:36:52,369 --> 00:36:54,603
and you really do want
a test. Plan your event.

914
00:36:55,470 --> 00:36:59,100
Practice makes perfect
is a very much a truth.

915
00:36:59,100 --> 00:37:00,230
And then you want to make sure

916
00:37:00,230 --> 00:37:02,530
that you have your air
cover and line that up.

917
00:37:04,370 --> 00:37:06,870
As a goal, as an aspirational goal

918
00:37:06,870 --> 00:37:09,140
think about performing
one of these activities

919
00:37:09,140 --> 00:37:10,770
once a quarter or four times a year.

920
00:37:10,770 --> 00:37:12,033
If you could do that.

921
00:37:13,120 --> 00:37:15,359
On your game day, you run the simulation.

922
00:37:15,360 --> 00:37:16,810
Observe your blue team.

923
00:37:16,810 --> 00:37:18,090
Grade folks.

924
00:37:18,090 --> 00:37:19,070
Determine what you're doing.

925
00:37:19,070 --> 00:37:20,860
Remember you want to move the needle.

926
00:37:20,860 --> 00:37:22,321
So, I want to end with

927
00:37:22,321 --> 00:37:24,290
we don't necessarily do demos in these,

928
00:37:24,290 --> 00:37:25,650
but I thought it'd be a really good idea

929
00:37:25,650 --> 00:37:27,570
to give you an example of one of the tools

930
00:37:27,570 --> 00:37:28,600
that could be right effective.

931
00:37:28,600 --> 00:37:30,029
It's called the BT3.

932
00:37:30,030 --> 00:37:32,219
It's an inexpensive tool.

933
00:37:32,219 --> 00:37:34,360
You can integrate this
into your environment.

934
00:37:34,360 --> 00:37:35,910
Very easy to implement.

935
00:37:35,910 --> 00:37:38,859
Get Linux, register for an API key.

936
00:37:38,859 --> 00:37:41,650
It's got a few tilt tools built into it

937
00:37:41,650 --> 00:37:44,710
that generate real packet
data for you on the network.

938
00:37:44,710 --> 00:37:46,730
As a way to make things look

939
00:37:46,730 --> 00:37:48,990
like they're malicious by
handling a hash condition.

940
00:37:48,990 --> 00:37:50,359
It's very low risk.

941
00:37:50,360 --> 00:37:53,800
It's very low risk
because it's Python code

942
00:37:53,800 --> 00:37:57,470
and it has a a Metasploit
like user interface.

943
00:37:57,470 --> 00:37:59,980
So, your adversary
simulation side is similar

944
00:37:59,980 --> 00:38:01,870
to using best point, you know.

945
00:38:01,870 --> 00:38:05,430
Set your LHOST option,
generate the PO Python code,

946
00:38:05,430 --> 00:38:06,629
get the output.

947
00:38:06,630 --> 00:38:09,868
And then what you can do
is go get that Python code.

948
00:38:09,868 --> 00:38:12,560
Run that particular agent and it's Python.

949
00:38:12,560 --> 00:38:13,650
You can run it on a windows.

950
00:38:13,650 --> 00:38:16,310
If the libraries are there,
you can run it on Linux.

951
00:38:16,310 --> 00:38:19,070
You can instrument it a
variety of ways on Linux box.

952
00:38:19,070 --> 00:38:21,161
Like you could add it
to an install package.

953
00:38:21,161 --> 00:38:22,760
You could put it in a cron job.

954
00:38:22,760 --> 00:38:25,260
You have a lot of flexibility
because it's Python.

955
00:38:26,840 --> 00:38:28,240
So, I mentioned security onion.

956
00:38:28,240 --> 00:38:29,990
This is another tool that if deployed

957
00:38:29,990 --> 00:38:32,209
on your network can detect
that particular activity.

958
00:38:32,210 --> 00:38:34,800
So here we picked a tool, tested the tool,

959
00:38:34,800 --> 00:38:37,100
determined if we can
actually detect the tool.

960
00:38:37,100 --> 00:38:40,002
So, we have at least
one detection mechanism.

961
00:38:41,360 --> 00:38:43,320
If you're looking at seeing what this tool

962
00:38:43,320 --> 00:38:45,500
produces longitudinally
over a period of time

963
00:38:45,500 --> 00:38:47,990
I ran a simulation with
a couple of machines.

964
00:38:47,990 --> 00:38:51,149
We got a variety of events that happened.

965
00:38:51,150 --> 00:38:53,210
And if you look at what
happens when you run this tool

966
00:38:53,210 --> 00:38:56,530
over a day, you generate 31,000 events.

967
00:38:56,530 --> 00:38:58,080
I want to thank you for your time here

968
00:38:58,080 --> 00:38:59,069
with this presentation.

969
00:38:59,070 --> 00:39:00,670
And I really hope that
I've helped you move

970
00:39:00,670 --> 00:39:03,043
the needle for your
adversary simulation program.

