1
00:00:01,780 --> 00:00:03,450
- Hi, my name's Mike Bursell.

2
00:00:03,450 --> 00:00:06,910
I am a Chief Security Architecture

3
00:00:06,910 --> 00:00:09,750
as part of the office
of the CTO at Red Hat

4
00:00:09,750 --> 00:00:13,043
and I'm here with Nathaniel McCallum.

5
00:00:14,360 --> 00:00:15,370
- Hello, everyone.

6
00:00:15,370 --> 00:00:17,599
My name is, as Mike said,
is Nathaniel McCallum

7
00:00:17,600 --> 00:00:21,810
and I'm the Virtualization
Security Architect at Red Hat.

8
00:00:21,810 --> 00:00:24,189
- And we are co-founders
of the Enarx project.

9
00:00:24,190 --> 00:00:25,850
And we're here to talk to you today

10
00:00:25,850 --> 00:00:28,240
about confidential computing
across multiple clouds

11
00:00:28,240 --> 00:00:31,979
and platforms, which is project Enarx.

12
00:00:31,980 --> 00:00:34,870
We really welcome
questions as we go through.

13
00:00:34,870 --> 00:00:37,419
Please put stuff in the chat

14
00:00:37,420 --> 00:00:39,000
and we'll try and answer those as we go.

15
00:00:39,000 --> 00:00:41,530
I'm sure you can find us elsewhere

16
00:00:41,530 --> 00:00:42,580
if you need to get a hold of us.

17
00:00:42,580 --> 00:00:45,312
So without any further
ado, let's carry on.

18
00:00:46,180 --> 00:00:49,440
So first of all, we've
introduced ourselves.

19
00:00:49,440 --> 00:00:52,680
We should be clear that
Enarx is a team project.

20
00:00:52,680 --> 00:00:54,623
It's an open source security project.

21
00:00:55,850 --> 00:00:59,610
Although Nathaniel and I are the founders,

22
00:00:59,610 --> 00:01:03,030
lots of it has been contributed,

23
00:01:03,030 --> 00:01:05,830
coded and documented
by other folks as well.

24
00:01:05,830 --> 00:01:08,330
And we should also say, it's open source.

25
00:01:08,330 --> 00:01:10,050
Uses trusted execution environments

26
00:01:10,050 --> 00:01:12,770
is not the basis for product yet.

27
00:01:12,770 --> 00:01:14,380
Hopefully that'll change.

28
00:01:14,380 --> 00:01:16,089
And this is not a product pitch.

29
00:01:16,090 --> 00:01:18,160
We're not trying to sell you a product

30
00:01:18,160 --> 00:01:20,440
because this is a technical session

31
00:01:20,440 --> 00:01:22,600
and we hate product pitches at conferences

32
00:01:22,600 --> 00:01:23,759
and we think you deserve better.

33
00:01:23,760 --> 00:01:27,150
And of course, it's not a product anyway.

34
00:01:27,150 --> 00:01:30,643
So let's get on and explain
what we're talking about.

35
00:01:33,880 --> 00:01:35,800
First of all, what is the problem

36
00:01:35,800 --> 00:01:38,119
that we're trying to solve?

37
00:01:38,120 --> 00:01:39,750
Well, it's about risk.

38
00:01:39,750 --> 00:01:42,003
It's about trust and about it's isolation.

39
00:01:43,362 --> 00:01:44,195
Another way to look at it is

40
00:01:44,195 --> 00:01:46,603
not everything in the
cloud is a good thing.

41
00:01:48,940 --> 00:01:52,200
Nathaniel, why don't you
talk a bit about workloads?

42
00:01:52,200 --> 00:01:55,310
- So there's been a lot of excitement

43
00:01:55,310 --> 00:01:56,980
about moving to the cloud in recent years.

44
00:01:56,980 --> 00:01:59,860
Of course, Mike and I
share this excitement,

45
00:01:59,860 --> 00:02:01,660
but it also brings a lot of challenges,

46
00:02:01,660 --> 00:02:05,350
particularly for the type of workloads

47
00:02:05,350 --> 00:02:07,089
where you have to have

48
00:02:07,090 --> 00:02:09,840
either sensitive data
or sensitive algorithms

49
00:02:09,840 --> 00:02:14,840
or where you have to make sure
that you are managing risk

50
00:02:15,095 --> 00:02:18,433
or are handled by governance
or regulatory environments.

51
00:02:19,550 --> 00:02:23,630
So this is basically
what we are targeting.

52
00:02:23,630 --> 00:02:25,210
Examples of sensitive data might be things

53
00:02:25,210 --> 00:02:28,273
like credit card data, firewall configs,

54
00:02:29,160 --> 00:02:33,910
administrative passwords
or CEO compensation.

55
00:02:33,910 --> 00:02:36,760
All of these kinds of
things are sensitive data

56
00:02:36,760 --> 00:02:39,260
that you don't necessarily
want anyone looking at.

57
00:02:40,270 --> 00:02:41,650
There comes additional risk

58
00:02:41,650 --> 00:02:43,740
if we try to put this in the cloud.

59
00:02:43,740 --> 00:02:45,640
We also have sensitive algorithms.

60
00:02:45,640 --> 00:02:48,440
For example, this is really big right now

61
00:02:48,440 --> 00:02:52,690
in the AI and machine
learning disciplines.

62
00:02:52,690 --> 00:02:55,123
We have a lot of new
algorithms being generated.

63
00:02:57,370 --> 00:02:59,940
It would be risky to expose these

64
00:02:59,940 --> 00:03:02,020
to other competitors, for example.

65
00:03:02,020 --> 00:03:04,580
But other examples of
this include things like

66
00:03:04,580 --> 00:03:07,360
financial models or
pharmaceutical research.

67
00:03:07,360 --> 00:03:09,300
All of these are sensitive algorithms

68
00:03:09,300 --> 00:03:12,380
and you don't necessarily want
to disclose the actual code

69
00:03:12,380 --> 00:03:14,903
that you're running in
a cloud environment.

70
00:03:15,940 --> 00:03:20,400
And then finally, when you
do have a risk managing

71
00:03:20,400 --> 00:03:24,460
in government or regulatory sectors,

72
00:03:24,460 --> 00:03:27,400
we need to be able to provide
cryptographic evidence

73
00:03:27,400 --> 00:03:29,690
that the environments
that we are attempting

74
00:03:29,690 --> 00:03:34,690
to run our workloads are
protected against tempering.

75
00:03:34,940 --> 00:03:39,180
And these include things
like in the GDPR space,

76
00:03:39,180 --> 00:03:44,180
telco space, HIPAA, or really
any healthcare regulation,

77
00:03:46,240 --> 00:03:49,163
even things like
Sarbanes-Oxley, for example.

78
00:03:50,282 --> 00:03:52,300
And then a lot of this
just also boils down

79
00:03:52,300 --> 00:03:53,690
to your reputation.

80
00:03:53,690 --> 00:03:56,070
So if you have an important reputation

81
00:03:56,070 --> 00:03:59,630
or an important brand that
you don't wanna tarnish

82
00:03:59,630 --> 00:04:01,350
with an accidental disclosure

83
00:04:01,350 --> 00:04:03,920
of sensitive data or algorithms,

84
00:04:03,920 --> 00:04:06,480
then this is a concern for you.

85
00:04:06,480 --> 00:04:07,850
Mike.

86
00:04:07,850 --> 00:04:08,683
- Yeah, sure.

87
00:04:09,860 --> 00:04:12,500
Let's talk briefly about isolation.

88
00:04:12,500 --> 00:04:16,959
So let's imagine a simple
case where you are a tenant

89
00:04:16,959 --> 00:04:20,859
and you are deploying a workload to a host

90
00:04:20,860 --> 00:04:23,350
and the host is in a public cloud;

91
00:04:23,350 --> 00:04:27,600
AWS or Google or IBM or
Azure or Alibaba, whatever.

92
00:04:27,600 --> 00:04:30,010
But you're running a workload

93
00:04:30,010 --> 00:04:32,700
and there may be other
workloads on the same host.

94
00:04:32,700 --> 00:04:35,800
So you really do not want
those other workloads

95
00:04:35,800 --> 00:04:38,730
interfering with your workload.

96
00:04:38,730 --> 00:04:41,830
So luckily, that's something
that we know how to do.

97
00:04:41,830 --> 00:04:45,030
The industry has been doing
this for 15 years or so,

98
00:04:45,030 --> 00:04:50,030
maybe more with blocking
workload from workload attacks,

99
00:04:51,660 --> 00:04:56,031
confidentiality, integrity,
all those sorts of things.

100
00:04:56,031 --> 00:04:57,850
We know how to do that
with the hypervisors

101
00:04:57,850 --> 00:05:00,090
and containers and those sorts of things.

102
00:05:00,090 --> 00:05:03,222
The second type is hosts
from workload isolation.

103
00:05:04,650 --> 00:05:08,659
The cloud service
provider running your host

104
00:05:08,660 --> 00:05:10,850
really doesn't want you breaking out

105
00:05:10,850 --> 00:05:12,360
and attacking their host

106
00:05:12,360 --> 00:05:13,193
'cause once you've done that,

107
00:05:13,193 --> 00:05:14,570
you can attack the rest
of their infrastructure

108
00:05:14,570 --> 00:05:16,150
or other workloads.

109
00:05:16,150 --> 00:05:17,380
And again, actually this is something

110
00:05:17,380 --> 00:05:19,240
that the industry has been dealing with

111
00:05:19,240 --> 00:05:20,520
for quite a long time.

112
00:05:20,520 --> 00:05:24,233
Same sort of things, hypervisors, SELinux,

113
00:05:25,590 --> 00:05:28,049
a number of ways of dealing with those.

114
00:05:28,050 --> 00:05:29,720
But there's a third type,

115
00:05:29,720 --> 00:05:32,510
and that's workload from host isolation.

116
00:05:32,510 --> 00:05:33,780
And this is exactly where
we were talking about,

117
00:05:33,780 --> 00:05:38,780
where you need to protect your
data from the host itself.

118
00:05:40,040 --> 00:05:42,260
You may not trust your cloud provider,

119
00:05:42,260 --> 00:05:44,330
or you may be running on an edge machine

120
00:05:44,330 --> 00:05:45,680
where it may be vulnerable.

121
00:05:45,680 --> 00:05:49,520
So how do you protect the
workload from the host?

122
00:05:49,520 --> 00:05:53,500
Well, in current computing
models, you just can't.

123
00:05:53,500 --> 00:05:57,280
Memory pages are mapped by the host OS,

124
00:05:57,280 --> 00:06:00,429
by the hypervisor, by
the container runtime

125
00:06:00,430 --> 00:06:02,993
and you can't protect against them.

126
00:06:04,290 --> 00:06:09,290
So we came across a while ago
an excellent XKCD cartoon,

127
00:06:11,280 --> 00:06:14,272
where it looks at all the
different levels of the stack.

128
00:06:15,245 --> 00:06:17,600
And to be aware that
hopefully not all of them

129
00:06:17,600 --> 00:06:20,020
will be compromised, but
there are opportunities

130
00:06:20,020 --> 00:06:22,890
for compromise all up and down the stack.

131
00:06:22,890 --> 00:06:23,723
And the problem is that

132
00:06:23,723 --> 00:06:26,520
once a level of the stack
below you is compromised

133
00:06:26,520 --> 00:06:29,270
in the current model of computing,

134
00:06:29,270 --> 00:06:31,700
there's very little you can do about it.

135
00:06:31,700 --> 00:06:35,950
And in the cloud, you need to
worry about other workloads

136
00:06:35,950 --> 00:06:39,870
your admins, the CSPs, CIS admins,

137
00:06:39,870 --> 00:06:41,380
OS compromises government agencies,

138
00:06:41,380 --> 00:06:43,870
all those sorts of things on the edge.

139
00:06:43,870 --> 00:06:48,330
You still got similar folks
you need to worry about.

140
00:06:48,330 --> 00:06:49,830
So what's the answer?

141
00:06:49,830 --> 00:06:51,680
Well, the answer or part of it

142
00:06:51,680 --> 00:06:53,630
is trusted execution environments.

143
00:06:53,630 --> 00:06:55,393
Do you wanna talk about this Nathaniel?

144
00:06:56,310 --> 00:06:57,513
- Sure.

145
00:06:57,513 --> 00:07:00,200
So the major development that
we've seen in recent years

146
00:07:00,200 --> 00:07:02,420
regarding trusted execution environments

147
00:07:02,420 --> 00:07:07,420
is the ability to isolate
and usually encrypt memory

148
00:07:08,530 --> 00:07:09,919
when an application is running.

149
00:07:09,920 --> 00:07:11,480
So an application is able to run,

150
00:07:11,480 --> 00:07:13,480
its memory pages are able to be encrypted

151
00:07:13,480 --> 00:07:16,640
while it's running so
that you can theoretically

152
00:07:16,640 --> 00:07:18,840
not have disclosure of your data.

153
00:07:18,840 --> 00:07:21,340
And there are a number
of hardware providers

154
00:07:21,340 --> 00:07:24,229
that are providing
technologies in this realm.

155
00:07:24,230 --> 00:07:29,230
For example, one of the
earliest ones was Arm TrustZone

156
00:07:29,330 --> 00:07:32,620
and that was targeted towards
the mobile device markets.

157
00:07:32,620 --> 00:07:37,197
And then Intel responded
with a technology called SGX,

158
00:07:39,510 --> 00:07:41,530
and then others have been developing

159
00:07:41,530 --> 00:07:43,190
as things have gone along.

160
00:07:43,190 --> 00:07:46,030
We've seen, for example, a shift for

161
00:07:46,030 --> 00:07:47,669
at least a part of the market

162
00:07:47,670 --> 00:07:50,580
into encrypted virtual machines.

163
00:07:50,580 --> 00:07:53,650
The examples of this
are AMD's SEV technology

164
00:07:53,650 --> 00:07:56,539
which is the most well-known
and is broadly available today

165
00:07:56,540 --> 00:08:01,010
at least in Silicon and TDX from Intel

166
00:08:01,010 --> 00:08:02,560
which has been announced,

167
00:08:02,560 --> 00:08:04,440
but it's not publicly available yet,

168
00:08:04,440 --> 00:08:08,433
as well as PEF from the IBM power group.

169
00:08:09,470 --> 00:08:11,910
Similar to that as the RISC V Sanctum

170
00:08:11,910 --> 00:08:15,940
which has a similar profile
as TrustZone and SGX.

171
00:08:17,150 --> 00:08:19,299
And so there's been significant
amount of work in this

172
00:08:19,300 --> 00:08:21,830
including the creation of a consortium

173
00:08:21,830 --> 00:08:22,760
in the Linux foundation

174
00:08:22,760 --> 00:08:25,010
called the Confidential
Computing Consortium.

175
00:08:27,250 --> 00:08:29,090
They have defined this problem set

176
00:08:29,090 --> 00:08:30,609
as the confidential computing

177
00:08:30,610 --> 00:08:33,320
is the protection of data in
use by performing computation

178
00:08:33,320 --> 00:08:36,190
in a hardware based trusted
execution environment.

179
00:08:36,190 --> 00:08:39,220
And the features for
this may include things

180
00:08:39,220 --> 00:08:42,610
like integrity and
confidentiality protection

181
00:08:42,610 --> 00:08:46,960
of the memory pages of the
application at runtime.

182
00:08:46,960 --> 00:08:51,186
This includes the data and the
code that are in those pages

183
00:08:51,186 --> 00:08:52,690
or that are therefore protected.

184
00:08:52,690 --> 00:08:53,930
And then very importantly,

185
00:08:53,930 --> 00:08:56,800
and this is something
that we to emphasize a lot

186
00:08:56,800 --> 00:08:58,382
is attestation.

187
00:08:58,383 --> 00:09:01,000
An attestation is a cryptographic process

188
00:09:01,000 --> 00:09:04,370
where we can validate with
cryptographic evidence

189
00:09:04,370 --> 00:09:07,150
that a computing
environment has been set up

190
00:09:07,150 --> 00:09:10,520
according to the specifications
that we have requested.

191
00:09:10,520 --> 00:09:13,850
And so this gives us
measured cryptographic proof

192
00:09:15,036 --> 00:09:17,359
that a cloud environment
has not been tampered with

193
00:09:17,360 --> 00:09:22,360
and that only the desired
actors can have access to it.

194
00:09:23,700 --> 00:09:26,560
A key point here is that
the memory page access

195
00:09:26,560 --> 00:09:28,660
is protected by the hardware.

196
00:09:28,660 --> 00:09:31,319
So that may include things like denying it

197
00:09:31,320 --> 00:09:34,310
or only providing access of ciphertext.

198
00:09:34,310 --> 00:09:36,310
Different hardware technologies

199
00:09:36,310 --> 00:09:38,880
take different strategies here,

200
00:09:38,880 --> 00:09:42,330
although everyone is sort of moving slowly

201
00:09:42,330 --> 00:09:46,070
towards denying access to
the protected pages as well.

202
00:09:46,070 --> 00:09:47,830
So we'll see some more maturity in that

203
00:09:47,830 --> 00:09:50,490
as the market itself matures.

204
00:09:50,490 --> 00:09:53,050
But this is essentially
an overview of the players

205
00:09:53,050 --> 00:09:55,089
and what they are
attempting to accomplish.

206
00:09:55,090 --> 00:09:56,100
Mike.

207
00:09:56,100 --> 00:09:58,380
- And so this is exactly
what we're talking about

208
00:09:58,380 --> 00:10:00,450
in that third type of isolation

209
00:10:00,450 --> 00:10:03,780
where we are isolating
the workload from the host

210
00:10:03,780 --> 00:10:05,949
because what this technologies allow

211
00:10:05,950 --> 00:10:07,680
is for you to run your workload

212
00:10:07,680 --> 00:10:11,030
in such a way that the
host, the hypervisor,

213
00:10:11,030 --> 00:10:14,980
the kernel, super admins, administrator

214
00:10:14,980 --> 00:10:18,560
cannot look inside and
see what you're doing.

215
00:10:18,560 --> 00:10:20,260
So TEEs sound great.

216
00:10:20,260 --> 00:10:22,140
These trusted execution
environments sound great,

217
00:10:22,140 --> 00:10:24,150
but there are some problems with them.

218
00:10:24,150 --> 00:10:25,880
The first one is that,

219
00:10:25,880 --> 00:10:28,300
we listed several platforms
on the previous page

220
00:10:28,300 --> 00:10:31,370
and in order to create an application

221
00:10:31,370 --> 00:10:34,270
or make your application run in those,

222
00:10:34,270 --> 00:10:36,390
you need to be developing it differently.

223
00:10:36,390 --> 00:10:38,699
There are different libraries,

224
00:10:38,700 --> 00:10:41,750
there are different
models for how that works

225
00:10:41,750 --> 00:10:42,900
and that's a real pain.

226
00:10:45,320 --> 00:10:46,590
In order to try and deal with that,

227
00:10:46,590 --> 00:10:48,390
people have written SDKs,

228
00:10:48,390 --> 00:10:53,390
but those SDKs restrict what
languages you can write in?

229
00:10:54,710 --> 00:10:56,530
So if you've got something
which is already written,

230
00:10:56,530 --> 00:10:59,560
but in a language which isn't supported,

231
00:10:59,560 --> 00:11:03,020
or you have a preferred
language in your organization

232
00:11:03,020 --> 00:11:04,860
and that's not one of
the ones that support it,

233
00:11:04,860 --> 00:11:06,160
you've got a real problem.

234
00:11:07,110 --> 00:11:09,190
The other thing is this
issue about attestation

235
00:11:09,190 --> 00:11:11,940
that the Nathaniel mentioned a moment ago.

236
00:11:11,940 --> 00:11:13,340
You need to be absolutely sure

237
00:11:13,340 --> 00:11:17,660
that you are deploying
your workloads to a place

238
00:11:17,660 --> 00:11:21,563
which is a real and not
a spoofed environment.

239
00:11:23,180 --> 00:11:24,800
And that's really tricky.

240
00:11:24,800 --> 00:11:28,030
And all of the different technologies

241
00:11:28,030 --> 00:11:30,002
have different ways of doing it.

242
00:11:31,310 --> 00:11:33,280
And last thing of course is that

243
00:11:33,280 --> 00:11:34,742
you've got different vendors.

244
00:11:36,090 --> 00:11:38,260
Obviously, there's gotta
be some vulnerabilities

245
00:11:38,260 --> 00:11:39,093
discovered in these.

246
00:11:39,093 --> 00:11:40,770
We've seen a bunch of these published

247
00:11:40,770 --> 00:11:42,610
over the last 18 months or so.

248
00:11:42,610 --> 00:11:43,610
These will keep happening.

249
00:11:43,610 --> 00:11:46,253
They'll keep being mitigated
and patched, et cetera.

250
00:11:48,085 --> 00:11:51,200
You need to worry about how
you're going to address these

251
00:11:53,656 --> 00:11:55,973
with applications that
you've actually deployed.

252
00:11:57,010 --> 00:11:59,350
What happens if you just
want to deploy workloads.

253
00:11:59,350 --> 00:12:01,700
You don't have to worry
about all of these things.

254
00:12:01,700 --> 00:12:02,870
You don't have to worry about these things

255
00:12:02,870 --> 00:12:06,820
if you're writing a VM or
a container at the moment.

256
00:12:06,820 --> 00:12:11,820
Why would you complicate your
life when you moved to TEEs.

257
00:12:13,050 --> 00:12:16,469
So one way to solve a problem is to

258
00:12:17,910 --> 00:12:20,242
let your CSP solve it for you.

259
00:12:22,990 --> 00:12:24,540
There's a number of ways of doing this.

260
00:12:24,540 --> 00:12:27,339
Why don't you talk about
what they are, Nathaniel.

261
00:12:28,230 --> 00:12:30,460
- I think it's important to note that

262
00:12:30,460 --> 00:12:33,920
these are all real-world examples

263
00:12:33,920 --> 00:12:36,170
of how existing cloud providers

264
00:12:36,170 --> 00:12:38,510
are attempting to solve the problem

265
00:12:38,510 --> 00:12:43,100
of making trusted execution
environments usable,

266
00:12:43,100 --> 00:12:45,460
and they all have a number of problems.

267
00:12:45,460 --> 00:12:49,660
So for example, there are mechanisms

268
00:12:49,660 --> 00:12:51,410
which allow you to take an app

269
00:12:51,410 --> 00:12:54,273
and then it will recompile
or rebundle your app.

270
00:12:55,390 --> 00:12:58,540
So it basically modifies your
app before you deploy it.

271
00:12:58,540 --> 00:13:00,980
This has a significant
downside for attestation

272
00:13:00,980 --> 00:13:05,160
because how do you know that
they're modifying your app

273
00:13:05,160 --> 00:13:06,770
in a way that's trustworthy

274
00:13:06,770 --> 00:13:09,960
and how can you validate
that through attestation?

275
00:13:09,960 --> 00:13:11,270
So that's a difficult problem.

276
00:13:11,270 --> 00:13:13,710
And it means that you have
to trust your cloud provider

277
00:13:13,710 --> 00:13:16,030
which one of the entire points of TEEs

278
00:13:16,030 --> 00:13:18,699
is to actually remove
the host operating system

279
00:13:18,700 --> 00:13:19,830
from the trust chain,

280
00:13:19,830 --> 00:13:22,620
remove the host provider
from the trust chain.

281
00:13:22,620 --> 00:13:24,233
So this puts them right back in.

282
00:13:26,640 --> 00:13:28,223
That's the attestation piece.

283
00:13:29,640 --> 00:13:32,199
But one other problem
with attestation is that

284
00:13:32,200 --> 00:13:33,270
a number of cloud providers

285
00:13:33,270 --> 00:13:35,689
are also building attestation services.

286
00:13:35,690 --> 00:13:38,240
And so they wanna make it easy for you

287
00:13:38,240 --> 00:13:40,570
to consume their attestation model.

288
00:13:40,570 --> 00:13:41,840
And the way that they do this

289
00:13:41,840 --> 00:13:44,740
is by building an attestation service.

290
00:13:44,740 --> 00:13:46,220
Now you can run your code

291
00:13:46,220 --> 00:13:48,350
and the attestation
service will deploy it.

292
00:13:48,350 --> 00:13:50,070
And if you ask the attestation service,

293
00:13:50,070 --> 00:13:52,420
it'll say, oh yeah, I
checked the attestation.

294
00:13:52,420 --> 00:13:54,140
It's great.

295
00:13:54,140 --> 00:13:56,060
And we think that this is insufficient.

296
00:13:56,060 --> 00:13:58,510
So we don't want the cloud provider

297
00:13:58,510 --> 00:14:00,689
to be doing attestation on our behalf.

298
00:14:00,690 --> 00:14:03,200
Again, one of our goals is to remove

299
00:14:04,105 --> 00:14:06,680
the cloud host from the trust model.

300
00:14:06,680 --> 00:14:11,599
Another problem is the question
of how you prepare your VM.

301
00:14:11,600 --> 00:14:15,200
Today, there is not a
virtualization product

302
00:14:19,252 --> 00:14:20,370
which has a stable interface

303
00:14:20,370 --> 00:14:22,650
between the virtual machine manager

304
00:14:22,650 --> 00:14:25,329
or hypervisor and the guest kernel.

305
00:14:25,330 --> 00:14:28,730
So even though you as a
tenant may provide a kernel,

306
00:14:28,730 --> 00:14:29,940
you can't provide the bios.

307
00:14:29,940 --> 00:14:31,770
The bios comes from the host side,

308
00:14:31,770 --> 00:14:34,600
which again allows the host a footprint

309
00:14:34,600 --> 00:14:36,210
inside of your trust model.

310
00:14:36,210 --> 00:14:37,170
And this is the very thing

311
00:14:37,170 --> 00:14:39,319
that we are trying to get away from

312
00:14:39,320 --> 00:14:42,993
and is going to be difficult
with virtual machines.

313
00:14:43,860 --> 00:14:46,560
And then finally, there's another set

314
00:14:48,348 --> 00:14:50,229
of CSP deployment mechanisms

315
00:14:50,230 --> 00:14:52,090
where essentially they will build

316
00:14:52,090 --> 00:14:55,010
their own parallel root
of trust on top of this,

317
00:14:55,010 --> 00:14:58,980
which again, requires you to
trust the hosting provider

318
00:14:58,980 --> 00:15:02,320
in order to have this solid root of trust

319
00:15:02,320 --> 00:15:03,320
all the way through.

320
00:15:03,320 --> 00:15:04,153
But we already have a root of trust

321
00:15:04,153 --> 00:15:05,670
and we have it directly to the hardware.

322
00:15:05,670 --> 00:15:07,349
So what we wanna do is
we wanna go directly

323
00:15:07,350 --> 00:15:08,960
from the hardware root of trust.

324
00:15:08,960 --> 00:15:11,320
We want the host operating system

325
00:15:11,320 --> 00:15:13,550
to be completely out of the trust model.

326
00:15:13,550 --> 00:15:15,640
And then we want the tenants code

327
00:15:15,640 --> 00:15:18,790
and data to be the very next thing

328
00:15:18,790 --> 00:15:20,997
that's part of the attestation.

329
00:15:23,830 --> 00:15:25,580
This is why we have this problem

330
00:15:25,580 --> 00:15:27,360
that it also completely misses the point

331
00:15:27,360 --> 00:15:29,470
because if we're solving these problems

332
00:15:29,470 --> 00:15:33,310
by just adding the additional footprint

333
00:15:33,310 --> 00:15:37,020
for the cloud service
provider into the trust model,

334
00:15:37,020 --> 00:15:39,400
we've just essentially broken what TEEs

335
00:15:40,310 --> 00:15:42,670
are actually promising us that we can do,

336
00:15:42,670 --> 00:15:45,569
which is run code on someone else's system

337
00:15:45,570 --> 00:15:47,563
without having to trust that party.

338
00:15:51,243 --> 00:15:53,690
So Mike, would you
advance it one more time?

339
00:15:53,690 --> 00:15:56,880
And of course, as soon as we allow the CSP

340
00:15:56,880 --> 00:15:58,770
into that hosting space,

341
00:15:58,770 --> 00:16:00,230
the problem that we have is lock-in.

342
00:16:00,230 --> 00:16:02,060
And this time has cryptographic lock-in

343
00:16:02,060 --> 00:16:04,510
because every time that we want to deploy

344
00:16:04,510 --> 00:16:06,439
workload onto a host,

345
00:16:06,440 --> 00:16:08,020
it's going to be a different measurement

346
00:16:08,020 --> 00:16:10,960
because it's a different
cloud service provider.

347
00:16:10,960 --> 00:16:12,200
And we want portability.

348
00:16:12,200 --> 00:16:13,540
We want to be able to take a workload.

349
00:16:13,540 --> 00:16:15,170
We want to be able to have it on one host,

350
00:16:15,170 --> 00:16:17,099
move it to another host dynamically.

351
00:16:17,100 --> 00:16:20,650
We want this to be able
to be done in minutes

352
00:16:20,650 --> 00:16:23,563
rather than days or weeks or even months.

353
00:16:25,092 --> 00:16:28,213
So we want to avoid
this problem of lock-in.

354
00:16:28,213 --> 00:16:29,045
Mike.

355
00:16:29,046 --> 00:16:30,630
- So I kind of think of this like,

356
00:16:30,630 --> 00:16:32,400
when you need your car serviced,

357
00:16:32,400 --> 00:16:34,319
you wanna make sure it's roadworthy.

358
00:16:34,320 --> 00:16:38,053
You take it to a garage and
they say, yeah, I fixed it.

359
00:16:39,320 --> 00:16:41,400
But I've used all of my own stuff

360
00:16:41,400 --> 00:16:44,850
and I've used my own wrenches and spanner.

361
00:16:44,850 --> 00:16:47,930
So you have to come back to
me and yeah, you trust me.

362
00:16:47,930 --> 00:16:49,020
I tell you, it's fine.

363
00:16:49,020 --> 00:16:50,980
But you have no way of checking.

364
00:16:50,980 --> 00:16:52,630
Because everything is in their hands

365
00:16:52,630 --> 00:16:54,360
and they sealed everything up.

366
00:16:54,360 --> 00:16:55,950
And that's the opposite of the way

367
00:16:55,950 --> 00:16:57,870
we think we should be doing things.

368
00:16:57,870 --> 00:17:01,670
So let's introduce Enarx which
is an open-source project,

369
00:17:01,670 --> 00:17:05,223
which aims to fix many
if not all of these.

370
00:17:06,109 --> 00:17:06,943
What does it do?

371
00:17:06,943 --> 00:17:09,859
Well, it uses trusted
execution environments.

372
00:17:09,859 --> 00:17:11,510
We try to make it easy.

373
00:17:11,510 --> 00:17:13,160
It has a very strong security model.

374
00:17:13,160 --> 00:17:16,393
It's cloud-native, and it's open source.

375
00:17:18,650 --> 00:17:22,190
We plan to support as many of the

376
00:17:22,190 --> 00:17:25,630
trusted execution environment
platforms as we can.

377
00:17:25,630 --> 00:17:28,283
We wanna make it easy
to deploy and develop.

378
00:17:29,320 --> 00:17:32,990
It's part of the Confidential
Computer Consortium.

379
00:17:32,990 --> 00:17:34,600
And as I said, this is a project.

380
00:17:34,600 --> 00:17:36,372
It's not production ready yet.

381
00:17:37,580 --> 00:17:40,470
So here are design
principles and Nathaniel,

382
00:17:40,470 --> 00:17:41,510
this is your slide.

383
00:17:41,510 --> 00:17:42,463
Go for it.

384
00:17:44,270 --> 00:17:46,940
- One of the things we aim to
do when we set up this project

385
00:17:46,940 --> 00:17:51,020
was to put a stake in the
ground philosophically

386
00:17:51,020 --> 00:17:52,660
that we wanted to commit to

387
00:17:52,660 --> 00:17:56,260
a very high set of design principles

388
00:17:56,260 --> 00:17:58,150
that we did not see being implemented

389
00:17:58,150 --> 00:17:59,860
elsewhere in the industry.

390
00:17:59,860 --> 00:18:02,290
And we have these 10 principles.

391
00:18:02,290 --> 00:18:05,720
So number one is the minimal
trusted computing base.

392
00:18:05,720 --> 00:18:10,650
We want your workload plus
any hardware enablement code

393
00:18:10,650 --> 00:18:11,850
that gets bundled with Enarx,

394
00:18:11,850 --> 00:18:12,986
which again is all open source

395
00:18:12,987 --> 00:18:14,733
and is provided by the tenant.

396
00:18:16,930 --> 00:18:18,920
We want the host CPU and firmware.

397
00:18:18,920 --> 00:18:21,780
That's all that we want in
the trusted computing base.

398
00:18:21,780 --> 00:18:24,129
So we're aiming for
something that is very small.

399
00:18:24,130 --> 00:18:27,540
We also want a minimum number
of trust relationships.

400
00:18:27,540 --> 00:18:29,550
If you're deploying any sort of workload,

401
00:18:29,550 --> 00:18:31,520
you have to trust your CPU manufacturer.

402
00:18:31,520 --> 00:18:33,070
There's simply no way around it.

403
00:18:33,070 --> 00:18:35,370
You also have to trust the
firmware that they provide,

404
00:18:35,370 --> 00:18:39,350
because it's essentially a
part of the CPU these days.

405
00:18:39,350 --> 00:18:43,270
So this is the very minimum
set of trust that you can have

406
00:18:43,270 --> 00:18:46,810
to do any computing in a
first principles design.

407
00:18:46,810 --> 00:18:48,820
So what we don't wanna trust
is we don't wanna trust

408
00:18:48,820 --> 00:18:51,100
things like the host operating system.

409
00:18:51,100 --> 00:18:53,500
We want the tenants to be able to provide

410
00:18:53,500 --> 00:18:57,250
all of the bits that are part
of the execution environment.

411
00:18:57,250 --> 00:18:59,430
And therefore the tenants
can validate these

412
00:18:59,430 --> 00:19:02,100
according to his or her own policies,

413
00:19:02,100 --> 00:19:04,562
whether individual or corporate policies.

414
00:19:05,630 --> 00:19:06,610
And we don't want to involve

415
00:19:06,610 --> 00:19:10,719
lots of other trust relationships
in this and other parties.

416
00:19:10,720 --> 00:19:12,633
We don't want complex certificate chains

417
00:19:12,633 --> 00:19:14,950
that are signed by lots
of different people.

418
00:19:14,950 --> 00:19:16,900
We want it to be as simple as possible.

419
00:19:16,900 --> 00:19:19,610
So number three is that we want
deployment time portability.

420
00:19:19,610 --> 00:19:21,290
So when you take an application

421
00:19:21,290 --> 00:19:23,680
and you compile it and you deploy it,

422
00:19:23,680 --> 00:19:26,530
we wanna be able to take the
same compilation artifact

423
00:19:26,530 --> 00:19:28,000
and we wanna be able to redeploy it

424
00:19:28,000 --> 00:19:31,430
across a number of CPU architectures.

425
00:19:31,430 --> 00:19:33,080
This is particularly as important

426
00:19:34,112 --> 00:19:38,090
as we invest additional trust in the CPU.

427
00:19:38,090 --> 00:19:41,850
So for example, if meeting
my regulatory guidelines,

428
00:19:41,850 --> 00:19:46,580
whether they're GDPR or
Sarbanes-Oxley or PCI DSS.

429
00:19:47,550 --> 00:19:49,800
If meeting those requirements

430
00:19:49,800 --> 00:19:52,010
is a matter of doing my business

431
00:19:52,010 --> 00:19:54,750
and not getting very large fines,

432
00:19:54,750 --> 00:19:56,780
then what are the things we need to do is

433
00:19:56,780 --> 00:20:00,470
we need to be able to take a
workload from a vulnerable CPU

434
00:20:00,470 --> 00:20:03,020
and move it to a CPU
that's not vulnerable.

435
00:20:03,020 --> 00:20:07,540
And so this is why deployment-time
portability is important,

436
00:20:07,540 --> 00:20:10,100
not only for being able
to migrate a workload

437
00:20:10,100 --> 00:20:11,250
to where it's the lowest cost,

438
00:20:11,250 --> 00:20:14,490
but it also protects
you from vulnerabilities

439
00:20:14,490 --> 00:20:15,893
in this new age of TEEs.

440
00:20:17,140 --> 00:20:20,600
Number four, we want the
network stack outside the TCB.

441
00:20:20,600 --> 00:20:23,980
If you look for example,
at the Linux kernel.

442
00:20:23,980 --> 00:20:25,730
And I'm not picking on anyone here.

443
00:20:25,730 --> 00:20:28,190
If you look at pretty much any kernel

444
00:20:28,190 --> 00:20:30,450
or low-level embedded infrastructure,

445
00:20:30,450 --> 00:20:32,270
you'll see that a large number

446
00:20:32,270 --> 00:20:37,080
of the serious vulnerabilities
come from the network stack.

447
00:20:37,080 --> 00:20:39,260
And one of the things
that we are aiming to do

448
00:20:39,260 --> 00:20:41,379
is we're aiming to move all the parsing

449
00:20:41,380 --> 00:20:45,460
for all of that network
IO outside of the TCB,

450
00:20:45,460 --> 00:20:47,800
so that a vulnerability not result

451
00:20:47,800 --> 00:20:50,070
in a compromise of the TEE.

452
00:20:50,070 --> 00:20:53,870
Number five, we want to
ensure security of our data

453
00:20:53,870 --> 00:20:56,500
and code at rest in transit and in use.

454
00:20:56,500 --> 00:20:58,600
So this is something
that's difficult to do

455
00:20:58,600 --> 00:21:00,010
in today's environments.

456
00:21:00,010 --> 00:21:02,250
While it's true applications

457
00:21:02,250 --> 00:21:04,330
depend on libraries like OpenSSL

458
00:21:04,330 --> 00:21:06,480
and can bring up TLS connections,

459
00:21:06,480 --> 00:21:11,480
while it's true that
a deployer of software

460
00:21:12,150 --> 00:21:15,630
can try to enforce things
like data encryption at rest.

461
00:21:15,630 --> 00:21:17,210
These are all piecemeal solutions

462
00:21:17,210 --> 00:21:19,820
and they depend upon
multiple different parties

463
00:21:19,820 --> 00:21:21,310
integrating them correctly.

464
00:21:21,310 --> 00:21:24,429
And then you have to have
complex management of the keys

465
00:21:24,430 --> 00:21:26,810
for everything that's
involved on top of this,

466
00:21:26,810 --> 00:21:28,510
even though you're
using different products

467
00:21:28,510 --> 00:21:30,050
for different things.

468
00:21:30,050 --> 00:21:32,500
But one of the things that
we recognized with TEES

469
00:21:32,500 --> 00:21:35,210
is that because we can
encrypt the application

470
00:21:35,210 --> 00:21:37,300
as it runs in its memory pages,

471
00:21:37,300 --> 00:21:39,360
if we have a way to also enforce

472
00:21:39,360 --> 00:21:41,209
that all of the persistent storage

473
00:21:41,210 --> 00:21:44,060
and all of the network
traffic is also encrypted,

474
00:21:44,060 --> 00:21:45,690
then basically we have a system

475
00:21:45,690 --> 00:21:47,220
that once the data enters it,

476
00:21:47,220 --> 00:21:49,970
it stays encrypted through the
entire lifetime of the system

477
00:21:49,970 --> 00:21:51,460
and it's never decrypted.

478
00:21:51,460 --> 00:21:56,460
And this we think is an
important security property.

479
00:21:57,200 --> 00:21:59,850
So number six is the
principle of auditability.

480
00:21:59,850 --> 00:22:02,260
Everything that we do,
all the code we write,

481
00:22:02,260 --> 00:22:05,280
we aim to be easy to read and auditable.

482
00:22:05,280 --> 00:22:06,620
We want it to be simple,

483
00:22:06,620 --> 00:22:08,070
we want it to be straightforward,

484
00:22:08,070 --> 00:22:10,250
and of course that leads
us to number seven,

485
00:22:10,250 --> 00:22:11,880
we want it to be open source.

486
00:22:11,880 --> 00:22:14,870
We believe that a significant
amount of the trust

487
00:22:14,870 --> 00:22:17,300
that you have when you're deploying code,

488
00:22:17,300 --> 00:22:19,930
it depends on your ability
to evaluate the code

489
00:22:19,930 --> 00:22:22,740
or to submit it for
third party evaluation.

490
00:22:22,740 --> 00:22:24,330
And so six and seven,

491
00:22:24,330 --> 00:22:27,280
audibility and open source
are incredibly important.

492
00:22:27,280 --> 00:22:29,270
Number eight, we don't want you developing

493
00:22:29,270 --> 00:22:31,490
applications to Enarx APIs.

494
00:22:31,490 --> 00:22:32,590
We're not interested in that.

495
00:22:32,590 --> 00:22:35,250
What we do care a lot
about is open standards.

496
00:22:35,250 --> 00:22:36,430
So what we want you to do

497
00:22:36,430 --> 00:22:38,330
is we want you to write an application

498
00:22:38,330 --> 00:22:39,810
in the language you care about.

499
00:22:39,810 --> 00:22:41,690
We want you to compile it to WebAssembly,

500
00:22:41,690 --> 00:22:45,600
which is a neutral compile target

501
00:22:45,600 --> 00:22:49,199
which can be just-in-time
compiled for any CPU architecture.

502
00:22:49,200 --> 00:22:52,390
And we want you to use the
Waze APIs that are a part

503
00:22:52,390 --> 00:22:55,033
and currently being
standardized for WebAssembly.

504
00:22:56,220 --> 00:22:58,570
All of this is just simply
standards compliance.

505
00:22:58,570 --> 00:23:00,746
You're not building something on Enarx,

506
00:23:00,747 --> 00:23:01,850
you're just using Enarx to deploy

507
00:23:01,850 --> 00:23:04,580
a standards compliant application.

508
00:23:04,580 --> 00:23:06,620
Number nine, memory safety.

509
00:23:06,620 --> 00:23:08,433
We care a lot about memory safety.

510
00:23:11,150 --> 00:23:13,190
All of our code is written in Rust.

511
00:23:13,190 --> 00:23:14,430
We do have to have a
little bit of assembly

512
00:23:14,430 --> 00:23:16,220
because we have to get
the hardware to work,

513
00:23:16,220 --> 00:23:18,310
but almost all of it is written in Rust

514
00:23:18,310 --> 00:23:20,970
and we take a strong
emphasis on memory safety.

515
00:23:20,970 --> 00:23:23,510
So we limit the number of unsafe blocks,

516
00:23:23,510 --> 00:23:26,550
and we try to do things
as safely as possible

517
00:23:26,550 --> 00:23:28,169
with a memory safe language.

518
00:23:28,170 --> 00:23:31,060
And number 10, we have a commitment

519
00:23:31,060 --> 00:23:33,379
to no back doors in the project.

520
00:23:33,380 --> 00:23:35,340
We will never merge a code

521
00:23:37,572 --> 00:23:39,171
that has some kind of a backdoor

522
00:23:40,160 --> 00:23:41,790
from any sort of third-party.

523
00:23:41,790 --> 00:23:44,810
So those are essentially
our design principles.

524
00:23:44,810 --> 00:23:47,010
We hope we've hit all the right points.

525
00:23:47,010 --> 00:23:49,040
And if you'd like to offer us feedback,

526
00:23:49,040 --> 00:23:50,709
we'd love to hear it.

527
00:23:50,709 --> 00:23:51,542
Mike.

528
00:23:54,430 --> 00:23:56,993
- You've hit everything already.

529
00:23:56,993 --> 00:23:57,943
I won't go on this.

530
00:23:58,950 --> 00:24:01,720
WebAssembly, that's
the runtime we provide.

531
00:24:01,720 --> 00:24:06,720
It's all in Rust and we go
with various types of TEEs.

532
00:24:06,750 --> 00:24:07,970
So it's time for a demo.

533
00:24:07,970 --> 00:24:12,970
Let's do a brief demo and
let's see what we have here.

534
00:24:16,590 --> 00:24:18,900
I need to go from the beginning.

535
00:24:18,901 --> 00:24:22,910
So I'm gonna show you deploying
an actual application.

536
00:24:22,910 --> 00:24:25,130
First of all, we need an
application to deploy.

537
00:24:25,130 --> 00:24:29,420
So I'm just gonna clone
a very simple application

538
00:24:29,420 --> 00:24:30,960
and show it to you.

539
00:24:30,960 --> 00:24:32,373
So it's written in Rust.

540
00:24:33,500 --> 00:24:34,333
Here we go.

541
00:24:34,333 --> 00:24:36,049
It's very simple.

542
00:24:36,049 --> 00:24:37,470
It creates a random number.

543
00:24:37,470 --> 00:24:40,660
It puts in a string
and it waits 20 seconds

544
00:24:40,660 --> 00:24:41,740
before showing it.

545
00:24:41,740 --> 00:24:42,830
That's all it does.

546
00:24:42,830 --> 00:24:44,290
It's very, very simple.

547
00:24:44,290 --> 00:24:45,210
We're gonna build it.

548
00:24:45,210 --> 00:24:47,080
But we're gonna build it

549
00:24:47,080 --> 00:24:51,149
to become a WebAssembly application.

550
00:24:51,150 --> 00:24:52,310
So as we said,

551
00:24:52,310 --> 00:24:55,290
that's what we want to be
running with a WebAssembly.

552
00:24:55,290 --> 00:24:57,582
So now we need to deploy it.

553
00:24:58,920 --> 00:25:01,420
This is as if we're on a client machine

554
00:25:01,420 --> 00:25:03,080
and we want to deploy it to a server.

555
00:25:03,080 --> 00:25:05,409
So that's the deploy vue there.

556
00:25:05,410 --> 00:25:07,370
Where are we gonna deploy it to?

557
00:25:07,370 --> 00:25:09,040
First of all, we need to
decide what to deploy.

558
00:25:09,040 --> 00:25:11,440
And that's the thing we've just created,

559
00:25:11,440 --> 00:25:13,610
that as the target that we've just done.

560
00:25:13,610 --> 00:25:16,800
The .wasm file. There we go.

561
00:25:16,800 --> 00:25:19,889
And we're gonna deploy
it to a machine called

562
00:25:20,969 --> 00:25:23,690
rome.sev.lab.ernax.dev.

563
00:25:23,690 --> 00:25:28,100
And there should be hopefully
something running on 3030

564
00:25:28,100 --> 00:25:28,933
ready to accept it.

565
00:25:28,933 --> 00:25:29,850
So there we go.

566
00:25:29,850 --> 00:25:32,439
We're running that machine,

567
00:25:32,440 --> 00:25:35,010
that server on that machine.

568
00:25:35,010 --> 00:25:36,150
So before we do that,

569
00:25:36,150 --> 00:25:38,660
we're gonna need some way
to look at the output.

570
00:25:38,660 --> 00:25:42,693
We're gonna run this low
level in general catalog.

571
00:25:43,620 --> 00:25:46,310
But also we've got a nasty little thing

572
00:25:46,310 --> 00:25:47,820
which is gonna try and do a bad thing.

573
00:25:47,820 --> 00:25:49,723
So we're gonna run the application.

574
00:25:50,900 --> 00:25:51,900
It's been deployed now.

575
00:25:51,900 --> 00:25:53,845
Excellent. It's been sent.

576
00:25:53,845 --> 00:25:56,610
And if we look here, we
have created that secret.

577
00:25:56,610 --> 00:25:59,149
So now we've got this other application

578
00:25:59,150 --> 00:26:00,560
which is gonna try and look at it,

579
00:26:00,560 --> 00:26:02,300
and it's actually found it.

580
00:26:02,300 --> 00:26:04,090
Let me just stop for a moment.

581
00:26:04,090 --> 00:26:07,639
The application on the bottom
right is an evil application

582
00:26:07,640 --> 00:26:10,920
which sits on the host,
sits on the rome machine.

583
00:26:10,920 --> 00:26:12,660
You can see it says rome there,

584
00:26:12,660 --> 00:26:14,910
and it searches the memory pages

585
00:26:14,910 --> 00:26:18,160
associated with that application.

586
00:26:18,160 --> 00:26:19,880
So this is not a good thing.

587
00:26:19,880 --> 00:26:22,540
It's found that sensitive information.

588
00:26:22,540 --> 00:26:25,930
It's found those firewall rules

589
00:26:25,930 --> 00:26:30,070
or those cryptographic keys
or your CEO's information,

590
00:26:30,070 --> 00:26:31,429
and that's a bad thing.

591
00:26:31,430 --> 00:26:33,160
So how did that happen?

592
00:26:33,160 --> 00:26:36,370
Well, the answer to that
is we didn't send it.

593
00:26:36,370 --> 00:26:37,699
We didn't deploy it to TEE.

594
00:26:37,700 --> 00:26:42,200
We deployed it just as a
standard WebAssembly workload

595
00:26:42,200 --> 00:26:44,053
running as a standard binary.

596
00:26:45,230 --> 00:26:46,300
And that's what we found.

597
00:26:46,300 --> 00:26:49,233
We found that because
it was not protected.

598
00:26:51,040 --> 00:26:52,970
- And this is what you get by the way,

599
00:26:52,970 --> 00:26:55,200
with every workload
you're deploying today.

600
00:26:55,200 --> 00:26:56,740
Every workload you've deployed today

601
00:26:56,740 --> 00:26:59,760
with sufficient privileges
on the server side.

602
00:26:59,760 --> 00:27:03,323
An attacker can scan the memory
and extract those secrets.

603
00:27:05,335 --> 00:27:07,743
So this is the state of
the arts before Enarx.

604
00:27:08,580 --> 00:27:09,413
- Absolutely.

605
00:27:09,413 --> 00:27:12,560
What we're gonna try now is
deploying it to KVM in a VM

606
00:27:12,560 --> 00:27:16,320
and see if the VM gives
us any more protection.

607
00:27:16,320 --> 00:27:17,429
So we've done that.

608
00:27:17,430 --> 00:27:19,270
It's created the secrets

609
00:27:19,270 --> 00:27:22,370
and it's running in a
KVM, a virtual machine,

610
00:27:22,370 --> 00:27:23,867
and now we're searching for it.

611
00:27:23,867 --> 00:27:26,740
And let's hope on this
occasion that the KVM,

612
00:27:26,740 --> 00:27:28,300
the VM will give us some more protection.

613
00:27:28,300 --> 00:27:30,540
Is it gonna give us any more protection?

614
00:27:30,540 --> 00:27:33,320
Well, I have my doubts.

615
00:27:33,320 --> 00:27:34,153
Let's see.

616
00:27:34,153 --> 00:27:37,550
It's waiting for those 20
seconds and it found the secrets.

617
00:27:37,550 --> 00:27:42,550
So this shows us that the VMs
do not provide that isolation.

618
00:27:42,910 --> 00:27:45,570
Now we're going to deploy it to an SEV,

619
00:27:45,570 --> 00:27:48,919
trusted execution environment, keep.

620
00:27:48,920 --> 00:27:50,770
We call it a keep where we run stuff.

621
00:27:50,770 --> 00:27:51,603
So we deployed it.

622
00:27:51,603 --> 00:27:52,720
There we go.

623
00:27:52,720 --> 00:27:54,830
You can see it's being
created on the top right.

624
00:27:54,830 --> 00:27:59,560
It's been sent on the bottom left.

625
00:27:59,560 --> 00:28:00,550
Let's see this time

626
00:28:00,550 --> 00:28:03,620
whether our evil secret
search can find it.

627
00:28:03,620 --> 00:28:06,629
I should be very clear that
we've run this fully attested.

628
00:28:06,630 --> 00:28:09,510
We did all the cryptographic checks

629
00:28:09,510 --> 00:28:11,670
before we even sent the workload.

630
00:28:11,670 --> 00:28:16,140
And once having done those
checks, we sent it encrypted.

631
00:28:16,140 --> 00:28:21,140
So at no point was it visible
to the host and it's worked.

632
00:28:21,280 --> 00:28:23,879
The secret search was not able to find it

633
00:28:23,880 --> 00:28:28,880
because it was protected by
the trust of execution from it

634
00:28:28,880 --> 00:28:31,060
which is exactly what we hope for.

635
00:28:31,060 --> 00:28:33,710
So what you've just seen there

636
00:28:33,710 --> 00:28:38,710
was an Enarx taking a workload

637
00:28:38,920 --> 00:28:42,030
and deploying it first unprotected at all,

638
00:28:42,030 --> 00:28:44,940
and showing that indeed
it wasn't protected,

639
00:28:44,940 --> 00:28:47,600
second deploying in a VM

640
00:28:47,600 --> 00:28:49,810
which is the standard where you generally

641
00:28:49,810 --> 00:28:52,020
deploy stuff in a cloud or the container.

642
00:28:52,020 --> 00:28:53,930
It makes no difference in this case.

643
00:28:53,930 --> 00:28:56,780
And showing again, it wasn't
sufficiently protected.

644
00:28:56,780 --> 00:28:59,550
And the third one was when
we actually deployed it

645
00:28:59,550 --> 00:29:02,909
into a keep using Enarx, atttested,

646
00:29:02,910 --> 00:29:04,740
and using a trust execution environment.

647
00:29:04,740 --> 00:29:07,033
And there we saw that it was protected.

648
00:29:08,580 --> 00:29:10,879
We're running pretty short on time.

649
00:29:10,880 --> 00:29:14,193
Nathaniel, do you want to quickly
just talk about the stack.

650
00:29:15,240 --> 00:29:17,210
- So this is basically
an architectural stack

651
00:29:17,210 --> 00:29:18,350
of our various layers.

652
00:29:18,350 --> 00:29:21,770
On the bottom side, we have
different kinds of keeps.

653
00:29:21,770 --> 00:29:24,370
Keeps are what we call our
trusted execution environments.

654
00:29:24,370 --> 00:29:26,429
On the left, we have SGX.

655
00:29:26,430 --> 00:29:28,240
We don't currently support RISC V Sanctum,

656
00:29:28,240 --> 00:29:30,330
but we're showing that it could go there.

657
00:29:30,330 --> 00:29:32,879
On the right, we currently support SEV

658
00:29:32,880 --> 00:29:36,743
and we are working towards PEF and TDX.

659
00:29:38,350 --> 00:29:40,766
On top of that, you get a
WebAssembly layer with Waze,

660
00:29:40,767 --> 00:29:42,280
and these are your standards

661
00:29:43,860 --> 00:29:46,503
that are being built as the base API.

662
00:29:47,410 --> 00:29:48,910
And then above this, you
get your language bindings

663
00:29:48,910 --> 00:29:50,380
and your applications to pretty much

664
00:29:50,380 --> 00:29:52,150
whatever language you want to run in.

665
00:29:52,150 --> 00:29:55,003
All of that is built on
top of open standards.

666
00:29:55,850 --> 00:29:57,590
- And the key thing here is that

667
00:29:57,590 --> 00:29:59,620
the application doesn't
care what it's running on.

668
00:29:59,620 --> 00:30:03,219
We talked about deploy
time provisioning time,

669
00:30:03,220 --> 00:30:05,710
neutrality and portability.

670
00:30:05,710 --> 00:30:06,640
It doesn't care.

671
00:30:06,640 --> 00:30:09,670
You write the same application,
you deploy it to whichever,

672
00:30:09,670 --> 00:30:13,423
and Enarx handles all of
the messy stuff underneath.

673
00:30:14,260 --> 00:30:16,950
So this isn't the only
way you could do it.

674
00:30:16,950 --> 00:30:20,120
Let's just quickly discuss
these, I guess, Nathaniel.

675
00:30:21,380 --> 00:30:23,610
- So there's a variety
of other approaches.

676
00:30:23,610 --> 00:30:26,169
Like Mike said, Enarx is not the only one.

677
00:30:26,170 --> 00:30:28,870
For example, there's
a SDK-based approaches

678
00:30:28,870 --> 00:30:33,870
like Fortanix and OpenSDK,
there are ELF-based.

679
00:30:34,320 --> 00:30:36,820
They're focused on running Linux binaries.

680
00:30:36,820 --> 00:30:40,179
These also go under the
name LibOS sometimes.

681
00:30:40,180 --> 00:30:44,140
But the idea is basically like
with Graphene and Mysteros

682
00:30:44,140 --> 00:30:47,330
which was recently announced by Azure.

683
00:30:47,330 --> 00:30:50,639
The goal here is to run
existing Linux binaries

684
00:30:50,640 --> 00:30:52,860
and there's various trade offs for that.

685
00:30:52,860 --> 00:30:56,729
And then finally, there's
various LibOS methods

686
00:30:56,730 --> 00:31:00,350
like for example, Rust
has like native support

687
00:31:00,350 --> 00:31:04,849
for running or for compiling
applications on top of SGX,

688
00:31:04,849 --> 00:31:06,860
and that's just built in
part of the standard library.

689
00:31:06,860 --> 00:31:09,520
So it allows you to sort of do that

690
00:31:09,520 --> 00:31:11,830
on a language specific basis.

691
00:31:11,830 --> 00:31:12,663
Michael.

692
00:31:16,110 --> 00:31:16,943
- Again to the end now.

693
00:31:16,943 --> 00:31:18,879
What do you do having watched this?

694
00:31:18,880 --> 00:31:21,030
Well, hopefully you've
been asking us questions.

695
00:31:21,030 --> 00:31:22,670
You can always find us.

696
00:31:22,670 --> 00:31:23,550
We'd love to talk to you,

697
00:31:23,550 --> 00:31:27,190
but what can you do get
involved in the community?

698
00:31:27,190 --> 00:31:28,160
Try Enarx.

699
00:31:28,160 --> 00:31:29,730
It's the stage where it's very close

700
00:31:29,730 --> 00:31:32,270
to being something you can try.

701
00:31:32,270 --> 00:31:35,879
By the time this is going
live, hopefully you can.

702
00:31:35,880 --> 00:31:37,510
Get involved in the development.

703
00:31:37,510 --> 00:31:39,510
And if you're interested

704
00:31:39,510 --> 00:31:42,610
in confidential computing more widely,

705
00:31:42,610 --> 00:31:44,979
you can join the Confidential
Computer Consortium

706
00:31:44,980 --> 00:31:46,090
or just attend the meetings.

707
00:31:46,090 --> 00:31:50,407
You don't need to be a member
of the Linux foundation

708
00:31:50,407 --> 00:31:52,270
or the consortium to attend meetings.

709
00:31:52,270 --> 00:31:53,910
You are very welcome to the technical

710
00:31:53,910 --> 00:31:55,920
or any of the other meetings.

711
00:31:55,920 --> 00:31:58,210
From a business point of view,

712
00:31:58,210 --> 00:32:02,380
think about what your organizations
sensitive workloads are.

713
00:32:02,380 --> 00:32:05,580
What are they, what do they
need in terms of resources

714
00:32:05,580 --> 00:32:07,800
and what things do they trust,

715
00:32:07,800 --> 00:32:11,510
and what should they be
trusting as you deploy them.

716
00:32:11,510 --> 00:32:14,260
At the same time, you could
think about the impact

717
00:32:14,260 --> 00:32:18,490
of your GRC and think about,

718
00:32:18,490 --> 00:32:20,300
you've got these three workloads,

719
00:32:20,300 --> 00:32:23,250
maybe two of them are financial

720
00:32:23,250 --> 00:32:26,880
and the third one has a HIPAA requirement.

721
00:32:26,880 --> 00:32:29,930
Think about the different
requirements they meet.

722
00:32:29,930 --> 00:32:30,910
And then tell us.

723
00:32:30,910 --> 00:32:34,280
We want to hear how you would
like to use this technology,

724
00:32:34,280 --> 00:32:35,649
how it could help you.

725
00:32:35,650 --> 00:32:38,763
We've got lots of use cases,
but we absolutely want more.

726
00:32:39,920 --> 00:32:42,960
Last slide is how to get in touch with us.

727
00:32:42,960 --> 00:32:45,980
Well, first of all if you go to enarx.dev,

728
00:32:45,980 --> 00:32:47,930
you will find all of the code.

729
00:32:47,930 --> 00:32:50,943
You will find a Wiki all about it.

730
00:32:54,128 --> 00:32:57,620
There's loads of
information, design documents

731
00:32:57,620 --> 00:32:59,570
and we'd love to see you.

732
00:32:59,570 --> 00:33:01,679
And of course, you can join us on our chat

733
00:33:01,680 --> 00:33:04,430
as a rocket chat at chat.enarx.dev.

734
00:33:04,430 --> 00:33:07,780
Very friendly, join us
and we'll chat with you.

735
00:33:07,780 --> 00:33:09,030
And as I said before,

736
00:33:09,030 --> 00:33:11,889
we're part of the Confidential
Computing Consortium.

737
00:33:11,890 --> 00:33:16,890
So please join us and
come to the meetings there

738
00:33:17,010 --> 00:33:18,773
and find out more about the broader work

739
00:33:18,773 --> 00:33:20,173
that the consortium's doing.

740
00:33:21,630 --> 00:33:22,463
That's it from me.

741
00:33:22,463 --> 00:33:25,030
Anything you wanna finish with, Nathaniel?

742
00:33:25,030 --> 00:33:27,383
I think we've covered
quite a lot pretty quickly.

743
00:33:28,510 --> 00:33:29,900
- I know it's been a bit of a fire hose,

744
00:33:29,900 --> 00:33:32,070
but thanks for attending the presentation

745
00:33:32,070 --> 00:33:35,200
and we hope we've given
you something interesting.

746
00:33:35,200 --> 00:33:36,770
It's always a pleasure to present these.

747
00:33:36,770 --> 00:33:38,940
So thank you very much for your attending

748
00:33:40,345 --> 00:33:41,490
and we wish you best of luck.

749
00:33:41,490 --> 00:33:42,323
- Thank you.

