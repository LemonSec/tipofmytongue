1
00:00:00,080 --> 00:00:02,913
(music)

2
00:00:14,660 --> 00:00:17,703
- Hi, I'm Steve Grobman, CTO of McAfee,

3
00:00:18,540 --> 00:00:19,963
and I'm afraid of snakes.

4
00:00:21,030 --> 00:00:22,250
I'm not the only one.

5
00:00:22,250 --> 00:00:25,380
About half of Americans
are afraid of snakes.

6
00:00:25,380 --> 00:00:26,950
I'm also a believer in data,

7
00:00:26,950 --> 00:00:30,550
and the data tells us this
is an irrational fear.

8
00:00:30,550 --> 00:00:31,880
At least in the United States,

9
00:00:31,880 --> 00:00:35,460
where only around five people
a year die of snake bites.

10
00:00:35,460 --> 00:00:37,340
The number of deaths from stinging insects

11
00:00:37,340 --> 00:00:39,390
is 20 times that amount.

12
00:00:39,390 --> 00:00:41,720
And the number of people
who die in auto accidents,

13
00:00:41,720 --> 00:00:43,699
a thousand times.

14
00:00:43,700 --> 00:00:45,750
So why don't we think twice
about getting in a car

15
00:00:45,750 --> 00:00:48,690
and driving at 70 miles
an hour on the highway,

16
00:00:48,690 --> 00:00:52,530
but are petrified when a snake
crosses the hiking trail.

17
00:00:52,530 --> 00:00:54,530
The answer in this case is evolution.

18
00:00:54,530 --> 00:00:58,410
The studies have shown that
humans, even small children,

19
00:00:58,410 --> 00:01:01,900
are instinctively able to
quickly identify snakes.

20
00:01:01,900 --> 00:01:04,610
Researchers believe this
evolutionary ability

21
00:01:04,610 --> 00:01:08,713
allowed humans to survive by
avoiding threats in the wild.

22
00:01:09,560 --> 00:01:11,880
Our perception of other
risks in the physical world

23
00:01:11,880 --> 00:01:15,920
are also miscalibrated, not
due to biology or evolution,

24
00:01:15,920 --> 00:01:17,900
but rather the way that they're portrayed

25
00:01:17,900 --> 00:01:19,320
in media and culture.

26
00:01:19,320 --> 00:01:20,449
In Texas, where I live,

27
00:01:20,450 --> 00:01:23,360
we have a great example
of this. tornadoes.

28
00:01:23,360 --> 00:01:26,700
We have tornado sirens, tornado shelters.

29
00:01:26,700 --> 00:01:29,030
And when a destructive tornado does occur,

30
00:01:29,030 --> 00:01:30,620
it makes a top story on the news

31
00:01:30,620 --> 00:01:34,103
with graphic images of
catastrophic destruction.

32
00:01:35,040 --> 00:01:38,450
In reality, very few
people die from tornadoes.

33
00:01:38,450 --> 00:01:43,083
In 2020, 24 tornadoes killed
76 people in the United States.

34
00:01:44,000 --> 00:01:48,513
Seven times at number, 529,
died falling off ladders.

35
00:01:49,370 --> 00:01:52,120
If only there was a scientific
approach we could use

36
00:01:52,120 --> 00:01:56,083
to measure risk, to help
counteract or bias perceptions.

37
00:01:56,980 --> 00:01:57,970
There is.

38
00:01:57,970 --> 00:02:00,880
I'd like to introduce
you to the micromort.

39
00:02:00,880 --> 00:02:04,000
The micromort, or micro
probability of death,

40
00:02:04,000 --> 00:02:06,550
is a unit of risk that represents

41
00:02:06,550 --> 00:02:09,620
a one-in-a-million chance of sudden death.

42
00:02:09,620 --> 00:02:12,710
This concept was first
introduced by Stanford professor

43
00:02:12,710 --> 00:02:14,503
Ronald Howard in 1980.

44
00:02:15,340 --> 00:02:17,630
Everything we do has some level of risk.

45
00:02:17,630 --> 00:02:19,049
Take driving.

46
00:02:19,050 --> 00:02:21,730
Statistically, there's a one
in a million chance of dying

47
00:02:21,730 --> 00:02:25,940
in an accident when you
travel 230 miles by car.

48
00:02:25,940 --> 00:02:30,420
Therefore, driving 230 miles
exposes you to one micromort.

49
00:02:30,420 --> 00:02:34,890
Driving 460 miles exposes
you to two, and so on.

50
00:02:34,890 --> 00:02:38,079
We can use the micromort
to challenge our intuition

51
00:02:38,080 --> 00:02:41,720
on what is actually risky and what is not.

52
00:02:41,720 --> 00:02:44,690
For example, scuba diving
is surprisingly safe

53
00:02:44,690 --> 00:02:47,400
and only three micromorts per dive.

54
00:02:47,400 --> 00:02:50,683
And skydiving exposes you
to only 10 micromorts.

55
00:02:51,530 --> 00:02:53,750
I'm talking about
parachuting from a plane,

56
00:02:53,750 --> 00:02:58,023
not base jumping, which
expose you to way more, 430.

57
00:02:59,240 --> 00:03:01,990
This also allows us to
much better understand

58
00:03:01,990 --> 00:03:05,710
how risky some very
dangerous activities are.

59
00:03:05,710 --> 00:03:09,020
A single attempt to summit
Mount Everest, for example,

60
00:03:09,020 --> 00:03:12,970
exposes the climber to 38,000 micromorts.

61
00:03:12,970 --> 00:03:16,070
Or think of that as the
same risk as performing

62
00:03:16,070 --> 00:03:18,870
almost 4,000 parachute jumps.

63
00:03:18,870 --> 00:03:21,290
What does this have to do with cyber?

64
00:03:21,290 --> 00:03:24,100
Many of our perceptions
about risk in the cyber world

65
00:03:24,100 --> 00:03:25,570
are also miscalibrated,

66
00:03:25,570 --> 00:03:29,200
and we need to use the moral
equivalent of the micromort

67
00:03:29,200 --> 00:03:32,459
in the way we think about cyber risk.

68
00:03:32,460 --> 00:03:34,240
Just as we do in the physical world,

69
00:03:34,240 --> 00:03:36,640
we need to use science based on data

70
00:03:36,640 --> 00:03:40,269
to counteract the influence of
social and traditional media

71
00:03:40,270 --> 00:03:42,750
and our raw emotions.

72
00:03:42,750 --> 00:03:46,570
Organizations worry about
all sorts of threats.

73
00:03:46,570 --> 00:03:49,400
Mass malware, we see every hour.

74
00:03:49,400 --> 00:03:51,730
Spear phishing attacks
on critical employees

75
00:03:51,730 --> 00:03:52,903
we see every day.

76
00:03:54,010 --> 00:03:56,359
And the rare nation-state directed attacks

77
00:03:56,360 --> 00:03:59,210
that have the potential to be devastating.

78
00:03:59,210 --> 00:04:02,410
One observation is that
the frequency of an event

79
00:04:02,410 --> 00:04:05,810
is inversely proportional to its impact.

80
00:04:05,810 --> 00:04:08,160
We see the exact same thing in nature,

81
00:04:08,160 --> 00:04:10,500
whether we're talking about tornadoes,

82
00:04:10,500 --> 00:04:13,130
earthquakes, or asteroid impacts.

83
00:04:13,130 --> 00:04:14,620
For example, with tornadoes,

84
00:04:14,620 --> 00:04:17,860
the Enhanced Fujita Scale
goes from zero to five,

85
00:04:17,860 --> 00:04:22,640
with five being the most severe,
yet 89% are EF1 or lower,

86
00:04:22,640 --> 00:04:26,073
and only 11% are two,
three, four, or five.

87
00:04:27,100 --> 00:04:31,610
The impact of a cyber event
has multiple levels of nuance.

88
00:04:31,610 --> 00:04:35,090
We need to consider the lethality
to impacted organizations

89
00:04:35,090 --> 00:04:38,330
independently from the global impact.

90
00:04:38,330 --> 00:04:41,500
For example, we see some
events that are high impact,

91
00:04:41,500 --> 00:04:44,660
even devastating to a single organization

92
00:04:44,660 --> 00:04:46,810
but have limited global impact.

93
00:04:46,810 --> 00:04:50,483
Sony, Target, Marriott,
just to name a few.

94
00:04:51,600 --> 00:04:53,470
Other events such as WannaCry and NotPetya

95
00:04:53,470 --> 00:04:58,180
were catastrophic to numerous
organizations around the world

96
00:04:58,180 --> 00:04:59,500
because they spread fast

97
00:04:59,500 --> 00:05:02,313
and were indiscriminately destructive.

98
00:05:03,540 --> 00:05:07,360
We also need to analyze the
different aspects of the damage

99
00:05:07,360 --> 00:05:08,983
resulting from a cyber event.

100
00:05:10,100 --> 00:05:13,230
For example, a human-operated intrusion

101
00:05:13,230 --> 00:05:15,380
with minimal direct impact,

102
00:05:15,380 --> 00:05:17,890
such as stealing internal
planning documents,

103
00:05:17,890 --> 00:05:20,870
still leaves the potential for any number

104
00:05:20,870 --> 00:05:23,710
of residual back doors and implants.

105
00:05:23,710 --> 00:05:27,900
The indirect cost regaining
environmental integrity

106
00:05:27,900 --> 00:05:29,152
can be immense.

107
00:05:30,710 --> 00:05:33,859
Another area of focus is
whether the risk we face

108
00:05:33,860 --> 00:05:35,510
is passive or active.

109
00:05:35,510 --> 00:05:38,310
What risks are we exposed
to by simply operating

110
00:05:38,310 --> 00:05:40,370
in a technologically advanced world?

111
00:05:40,370 --> 00:05:44,980
And what additional risk do
we expose our organizations to

112
00:05:44,980 --> 00:05:48,180
as a result of our business decisions?

113
00:05:48,180 --> 00:05:50,340
We need to minimize risk
from passive threats

114
00:05:50,340 --> 00:05:52,669
such as cloud-based productivity apps.

115
00:05:52,670 --> 00:05:56,800
We also need to understand
the risk-reward benefit

116
00:05:56,800 --> 00:06:00,340
when we choose to engage
in high-risk areas.

117
00:06:00,340 --> 00:06:02,700
Just as a hiker may
willingly climb a mountain

118
00:06:02,700 --> 00:06:05,360
even though they know
it's inherently risky,

119
00:06:05,360 --> 00:06:08,000
your business might invest
in a new technology,

120
00:06:08,000 --> 00:06:11,250
such as the next generation
container capability

121
00:06:11,250 --> 00:06:14,440
whose threat surface is
not yet fully understood

122
00:06:14,440 --> 00:06:16,113
if the return is significant.

123
00:06:16,960 --> 00:06:18,539
Let's build a model that takes

124
00:06:18,540 --> 00:06:21,480
all these factors into consideration.

125
00:06:21,480 --> 00:06:25,770
The principle components boil
down to these three vectors.

126
00:06:25,770 --> 00:06:27,490
The potential lethality of an event

127
00:06:27,490 --> 00:06:29,960
to an individual organization.

128
00:06:29,960 --> 00:06:32,890
The number of organizations
that could be impacted

129
00:06:32,890 --> 00:06:35,320
and the likelihood of occurrence.

130
00:06:35,320 --> 00:06:38,020
This model is all about risk.

131
00:06:38,020 --> 00:06:41,500
But remember, risk is the
potential for negative outcome,

132
00:06:41,500 --> 00:06:44,300
while an event is the historical record

133
00:06:44,300 --> 00:06:46,170
of what has occurred.

134
00:06:46,170 --> 00:06:49,520
Past events don't predict future outcomes,

135
00:06:49,520 --> 00:06:53,159
but they can provide data
to scientifically assess

136
00:06:53,160 --> 00:06:55,390
the likelihood of future scenarios.

137
00:06:55,390 --> 00:06:56,650
Think of it this way.

138
00:06:56,650 --> 00:06:58,900
Just as we don't know exactly

139
00:06:58,900 --> 00:07:02,000
what natural disasters
will impact us next year,

140
00:07:02,000 --> 00:07:05,010
we can prepare for
different types of events

141
00:07:05,010 --> 00:07:07,560
based on historical frequencies.

142
00:07:07,560 --> 00:07:11,330
Similarly, we don't know exactly
what type of cyber events

143
00:07:11,330 --> 00:07:14,690
will occur in the future, but
we can look at frequencies

144
00:07:14,690 --> 00:07:18,360
of different scenarios along
the vectors we discussed

145
00:07:18,360 --> 00:07:20,893
to understand how to prepare our defenses.

146
00:07:21,990 --> 00:07:24,880
So how does what we should worry about

147
00:07:24,880 --> 00:07:27,810
align with what we do worry about?

148
00:07:27,810 --> 00:07:31,840
To answer this, we analyze
traditional and social media

149
00:07:31,840 --> 00:07:34,260
along with the web
activity of McAfee sites

150
00:07:34,260 --> 00:07:37,030
related to campaigns and threats.

151
00:07:37,030 --> 00:07:41,190
We found that many of the
high-profile targeted attacks

152
00:07:41,190 --> 00:07:43,820
that received much
attention were carried out

153
00:07:43,820 --> 00:07:45,659
against one organization.

154
00:07:45,660 --> 00:07:48,540
Memorable examples include the DNC hack,

155
00:07:48,540 --> 00:07:52,260
Equifax, Ashley Madison and OPM.

156
00:07:52,260 --> 00:07:55,360
Should we focus this much
attention on high-profile,

157
00:07:55,360 --> 00:07:57,430
single organization incidents?

158
00:07:57,430 --> 00:07:58,690
Yes and no.

159
00:07:58,690 --> 00:08:00,900
Clearly some of these
attacks are newsworthy

160
00:08:00,900 --> 00:08:03,690
because they relate to national security,

161
00:08:03,690 --> 00:08:05,150
cyber impact to elections,

162
00:08:05,150 --> 00:08:08,880
or the impact to the
organization's customers.

163
00:08:08,880 --> 00:08:11,440
Additionally, from a
defender's perspective,

164
00:08:11,440 --> 00:08:13,950
how a lethal targeted attack occurs

165
00:08:13,950 --> 00:08:17,450
is important to understand so
that we know how to prepare

166
00:08:17,450 --> 00:08:19,743
for a custom human-operated attack.

167
00:08:20,760 --> 00:08:23,930
But, we need to be careful
not to overemphasize

168
00:08:23,930 --> 00:08:28,030
the exact playbook that is
executed in these scenarios.

169
00:08:28,030 --> 00:08:30,770
Yes, it's important to ensure
that you're not running

170
00:08:30,770 --> 00:08:33,250
a vulnerable version of Apache Struts

171
00:08:33,250 --> 00:08:35,630
on your external facing web servers,

172
00:08:35,630 --> 00:08:37,850
but it's as important to ensure

173
00:08:37,850 --> 00:08:40,590
that no external vulnerabilities exist

174
00:08:40,590 --> 00:08:42,703
that could lead to similar exploitation.

175
00:08:43,710 --> 00:08:47,110
Conversely, some
campaigns such as TrickBot

176
00:08:47,110 --> 00:08:48,750
get little media coverage,

177
00:08:48,750 --> 00:08:51,783
but organizations need to pay
greater attention to them.

178
00:08:52,630 --> 00:08:54,870
They act as the catalyst for secondary

179
00:08:54,870 --> 00:08:56,880
high-attack scenarios.

180
00:08:56,880 --> 00:09:00,140
For example, a human-operated
ransomware attack

181
00:09:00,140 --> 00:09:03,143
engineered to hold the most
valuable asset for ransom.

182
00:09:04,030 --> 00:09:07,930
TrickBot changes its implementation
frequently and impacts

183
00:09:07,930 --> 00:09:11,630
an extraordinarily large
number of organizations.

184
00:09:11,630 --> 00:09:14,770
Why does SolarWinds get
so much more attention

185
00:09:14,770 --> 00:09:18,400
when they both enable
human-operated secondary attacks?

186
00:09:18,400 --> 00:09:20,579
Media coverage can inform us

187
00:09:20,580 --> 00:09:23,040
about emerging global cyber events,

188
00:09:23,040 --> 00:09:25,880
but we need a more science-based approach

189
00:09:25,880 --> 00:09:27,633
to optimize our defenses.

190
00:09:28,550 --> 00:09:31,300
We need to comprehensively evaluate

191
00:09:31,300 --> 00:09:33,772
all events that impact organizations.

192
00:09:36,360 --> 00:09:40,550
If we simplify our three vector
model by dropping frequency,

193
00:09:40,550 --> 00:09:45,069
we can examine the relationship
between impact and scale.

194
00:09:45,070 --> 00:09:47,900
A starting point is to look
at the high-profile events

195
00:09:47,900 --> 00:09:51,079
that we've seen over the last few years

196
00:09:51,080 --> 00:09:54,970
in combination with the cyber
threats we see every day.

197
00:09:54,970 --> 00:09:57,010
We can then map their impact

198
00:09:57,010 --> 00:09:59,073
to the number of organizations affected.

199
00:09:59,970 --> 00:10:02,180
Let's break things into
three simple elements

200
00:10:02,180 --> 00:10:04,050
we've dealt with for decades.

201
00:10:04,050 --> 00:10:07,252
Targeted attacks that affect
a single organization,

202
00:10:08,260 --> 00:10:11,010
indiscriminate malware
such as password stealers

203
00:10:11,010 --> 00:10:14,420
and ransomware, and nuisance threats,

204
00:10:14,420 --> 00:10:16,360
such as PUPs and adware.

205
00:10:16,360 --> 00:10:17,990
One of the things that stands out

206
00:10:17,990 --> 00:10:22,173
is the inverse relationship
between impact and breadth.

207
00:10:23,960 --> 00:10:25,600
But in the last few years,

208
00:10:25,600 --> 00:10:28,920
we've also seen the sophistication
of attacks increase,

209
00:10:28,920 --> 00:10:31,459
which adds new elements to our chart.

210
00:10:31,460 --> 00:10:32,793
Supply chain attacks.

211
00:10:33,740 --> 00:10:35,960
Human-operated ransomware.

212
00:10:35,960 --> 00:10:39,440
And one of my favorites, the mega-worms.

213
00:10:39,440 --> 00:10:43,160
In this last case, this
is not a new innovation.

214
00:10:43,160 --> 00:10:46,589
We've dealt with mass-spreading
worms since the '90s.

215
00:10:46,590 --> 00:10:50,070
The ability for an attacker to
use a wormable vulnerability

216
00:10:50,070 --> 00:10:52,700
to convert victims into attackers,

217
00:10:52,700 --> 00:10:54,400
remains one of the most powerful

218
00:10:54,400 --> 00:10:56,980
adversarial innovations of all time.

219
00:10:56,980 --> 00:11:00,460
These additional elements
have the same relationship

220
00:11:00,460 --> 00:11:04,560
where impact and breadth
are inversely correlated,

221
00:11:04,560 --> 00:11:07,142
but we can see the slope has flattened.

222
00:11:08,660 --> 00:11:11,199
Innovation has provided adversaries

223
00:11:11,200 --> 00:11:14,100
with greater levels of efficiency

224
00:11:14,100 --> 00:11:16,753
to deliver lethality to their victims.

225
00:11:18,360 --> 00:11:19,510
What do we do about it?

226
00:11:20,500 --> 00:11:22,920
How do we defend our organizations?

227
00:11:22,920 --> 00:11:25,310
Unfortunately, there's not
a single set of actions

228
00:11:25,310 --> 00:11:28,859
or solutions that cover
all of these areas.

229
00:11:28,860 --> 00:11:30,780
While it's critical to
focus on the top left

230
00:11:30,780 --> 00:11:33,449
and not become the victim
of a targeted attack,

231
00:11:33,450 --> 00:11:36,180
we also have to ensure
that critical data files

232
00:11:36,180 --> 00:11:39,109
aren't stolen by indiscriminate malware,

233
00:11:39,110 --> 00:11:41,810
or that productivity
doesn't grind to a halt

234
00:11:41,810 --> 00:11:44,770
due to a deluge of nuisance threats.

235
00:11:44,770 --> 00:11:49,060
We need good cyber hygiene
along with user education

236
00:11:49,060 --> 00:11:51,599
to prevent everyday threats,

237
00:11:51,600 --> 00:11:53,650
good threat and artificial intelligence

238
00:11:53,650 --> 00:11:55,760
for indiscriminate and zero-day malware.

239
00:11:55,760 --> 00:11:58,530
And when there's a human
attacker on the other side,

240
00:11:58,530 --> 00:12:03,300
we need a combination of
technology and cyber operators

241
00:12:03,300 --> 00:12:07,030
to defeat the adversary because
no technology on its own

242
00:12:07,030 --> 00:12:10,540
can outsmart or outplay
an advanced attacker.

243
00:12:10,540 --> 00:12:13,180
But we shouldn't forget
that these are overlapping.

244
00:12:13,180 --> 00:12:16,829
For example, even in an
advanced attack scenario

245
00:12:16,830 --> 00:12:19,240
driven by a human actor,

246
00:12:19,240 --> 00:12:22,280
good cyber hygiene such as
a well-patched environment

247
00:12:22,280 --> 00:12:26,160
will make it harder to find
exploitable vulnerabilities.

248
00:12:26,160 --> 00:12:28,500
And good threat and
artificial intelligence

249
00:12:28,500 --> 00:12:31,380
limits the attack tools at their disposal.

250
00:12:31,380 --> 00:12:32,720
We have limited budgets

251
00:12:32,720 --> 00:12:35,990
and our cyber professionals
can't do everything.

252
00:12:35,990 --> 00:12:38,940
So it's critical that
we understand and ensure

253
00:12:38,940 --> 00:12:42,540
that the investments we do
make have the strongest benefit

254
00:12:42,540 --> 00:12:45,053
as compared to the risk
that they're mitigating.

255
00:12:45,930 --> 00:12:47,810
Here's the bottom line.

256
00:12:47,810 --> 00:12:51,223
We can't defend our organizations
by acting on gut instinct.

257
00:12:52,320 --> 00:12:55,460
Just as is counterintuitive
that in the physical world,

258
00:12:55,460 --> 00:12:58,850
an investment in $6
anti-slip bathtub stickers

259
00:12:58,850 --> 00:13:01,800
provides a higher return
on risk mitigation

260
00:13:01,800 --> 00:13:04,620
than a $4,000 tornado shelter.

261
00:13:04,620 --> 00:13:08,020
Implementing multifactor
authentication likely reduces

262
00:13:08,020 --> 00:13:12,090
more risk than mandating
third-party code audits

263
00:13:12,090 --> 00:13:14,433
in an attempt to address
supply chain attacks.

264
00:13:15,310 --> 00:13:17,859
My call to action for you is this,

265
00:13:17,860 --> 00:13:21,990
let's make the best cyber
defense decisions possible.

266
00:13:21,990 --> 00:13:25,480
Yes, watch the news and
monitor your Twitter feed,

267
00:13:25,480 --> 00:13:28,550
but be hyper-conscious to
counterbalance natural instincts

268
00:13:28,550 --> 00:13:31,293
and reactions driven by media and hype.

269
00:13:32,140 --> 00:13:34,860
Ensure that every trade-off
and decision you make

270
00:13:34,860 --> 00:13:36,640
to defend your organization

271
00:13:36,640 --> 00:13:39,853
is based on data and objectivity.

