1
00:00:01,480 --> 00:00:04,470
- Hello, I'm Josiah
Dykstra, a technical fellow

2
00:00:04,470 --> 00:00:06,960
at the US National Security Agency.

3
00:00:06,960 --> 00:00:09,310
It is great to be here at RSA.

4
00:00:09,310 --> 00:00:10,900
I am more than happy to take questions

5
00:00:10,900 --> 00:00:14,730
throughout the presentation
and also, at the end today.

6
00:00:14,730 --> 00:00:18,450
NSA has a mission to prevent
and eradicate cyber threats

7
00:00:18,450 --> 00:00:20,650
to national security systems.

8
00:00:20,650 --> 00:00:23,880
This talk is about them,
but it also applies to you

9
00:00:23,880 --> 00:00:27,220
and to other groups that I'll
describe throughout the talk.

10
00:00:27,220 --> 00:00:29,820
In this presentation, I
want to describe an approach

11
00:00:29,820 --> 00:00:32,619
to helping to protect a very specific kind

12
00:00:32,619 --> 00:00:34,809
of user or organization.

13
00:00:34,810 --> 00:00:38,100
And the premise is built
on two fundamental ideas.

14
00:00:38,100 --> 00:00:41,360
One, that users are still
being compromised today

15
00:00:41,360 --> 00:00:44,830
even though we've had decades
of research and development,

16
00:00:44,830 --> 00:00:47,760
lots of technology and usability advances,

17
00:00:47,760 --> 00:00:51,163
and a very strong human
cybersecurity community.

18
00:00:52,280 --> 00:00:55,240
The second premise is that
there are some users out there

19
00:00:55,240 --> 00:00:57,620
who just won't devote the resources

20
00:00:57,620 --> 00:01:00,500
that they probably should
to doing the best practices

21
00:01:00,500 --> 00:01:02,010
in cybersecurity.

22
00:01:02,010 --> 00:01:04,929
So given those two
realities, what can we do

23
00:01:04,930 --> 00:01:06,093
to protect people?

24
00:01:08,490 --> 00:01:11,380
For more than half a
century, lots of people

25
00:01:11,380 --> 00:01:13,479
including you and I,
have devoted ourselves

26
00:01:13,480 --> 00:01:17,970
to protecting users and
computers using cryptography

27
00:01:17,970 --> 00:01:21,700
and captions, and all kinds
of other technologies.

28
00:01:21,700 --> 00:01:23,760
And some of those things have provided

29
00:01:23,760 --> 00:01:27,200
a lot of real measurable,
tangible benefits

30
00:01:27,200 --> 00:01:30,850
reducing risk to those
systems and to those people.

31
00:01:30,850 --> 00:01:33,300
This is my career too, and I love it,

32
00:01:33,300 --> 00:01:34,610
and I think it is very important

33
00:01:34,610 --> 00:01:37,720
even though we haven't
achieved the ultimate goals

34
00:01:37,720 --> 00:01:40,140
that we all strive for every day.

35
00:01:40,140 --> 00:01:43,130
As just one example,
there are significant,

36
00:01:43,130 --> 00:01:47,670
sometimes even mandatory campaigns
at schools and businesses

37
00:01:47,670 --> 00:01:51,260
to educate users about
cyber threats and risks,

38
00:01:51,260 --> 00:01:54,770
and ways to protect themselves,
right, countermeasures.

39
00:01:54,770 --> 00:01:57,100
And yet, as you see on this screen,

40
00:01:57,100 --> 00:02:01,589
the most common passwords
rarely change a year over year,

41
00:02:01,590 --> 00:02:04,040
and the choices that
you see here illustrate

42
00:02:04,040 --> 00:02:06,460
that lots of users are picking convenience

43
00:02:06,460 --> 00:02:07,713
over good security.

44
00:02:08,650 --> 00:02:12,290
Now, the takeaway is not,
"Oh, those silly users."

45
00:02:12,290 --> 00:02:14,810
That isn't what I want
you to take away today,

46
00:02:14,810 --> 00:02:16,410
but I want you to take away the reality

47
00:02:16,410 --> 00:02:20,109
that security is a burden
for lots and lots of people.

48
00:02:20,110 --> 00:02:22,560
And it feels more like a loss than a gain

49
00:02:22,560 --> 00:02:25,483
when they have to do
cumbersome security measures.

50
00:02:28,580 --> 00:02:30,210
I also wanna give a hat tip

51
00:02:30,210 --> 00:02:32,420
to the field of usable security.

52
00:02:32,420 --> 00:02:34,940
This is a group of community
that I know and love,

53
00:02:34,940 --> 00:02:38,570
have contributed to, and
they are doing terrific work

54
00:02:38,570 --> 00:02:41,250
to make security more usable.

55
00:02:41,250 --> 00:02:44,790
When I use that phrase, I
mean the capacity of a system,

56
00:02:44,790 --> 00:02:48,019
of a program, to provide
the conditions where a user

57
00:02:48,020 --> 00:02:51,060
can make a choice, and to
make that choice safely

58
00:02:51,060 --> 00:02:54,340
and effectively, and
efficiently, and ideally,

59
00:02:54,340 --> 00:02:57,820
with the user being happy
with high satisfaction.

60
00:02:57,820 --> 00:03:00,730
And so, the screen like
you see here where a user

61
00:03:00,730 --> 00:03:02,820
is presented an option that says,

62
00:03:02,820 --> 00:03:04,912
you have an opportunity to make a choice.

63
00:03:06,620 --> 00:03:08,300
Software vendors are always trying to make

64
00:03:08,300 --> 00:03:10,790
that choice understandable and easy to use

65
00:03:10,790 --> 00:03:14,100
to help the user make
an informed decision.

66
00:03:14,100 --> 00:03:16,820
Now, what I'm gonna propose
is not contradictory

67
00:03:16,820 --> 00:03:19,269
to usable security, at least in my mind.

68
00:03:19,270 --> 00:03:23,270
I actually think we need both
usable security in many cases

69
00:03:23,270 --> 00:03:25,750
even though it doesn't
always seem to be enough

70
00:03:25,750 --> 00:03:26,823
just on it's own.

71
00:03:29,380 --> 00:03:30,750
So what I'm advocating for

72
00:03:30,750 --> 00:03:33,780
is what I am calling invisible security.

73
00:03:33,780 --> 00:03:37,780
And this is a different kind
of paradigm of protection

74
00:03:37,780 --> 00:03:41,700
where I mean that it involves
little or no user interaction

75
00:03:41,700 --> 00:03:43,019
or attention.

76
00:03:43,020 --> 00:03:44,860
So even if a user knows that there's

77
00:03:44,860 --> 00:03:47,700
an invisible security
mechanism on their system,

78
00:03:47,700 --> 00:03:49,810
they're absolved from action.

79
00:03:49,810 --> 00:03:52,830
Maybe it means they don't
have to do any installation.

80
00:03:52,830 --> 00:03:55,660
They don't have to do any configuration.

81
00:03:55,660 --> 00:03:57,579
They don't have to do
updates or maintenance

82
00:03:57,580 --> 00:04:01,450
for that invisible security
mechanism, but they are also,

83
00:04:01,450 --> 00:04:04,730
they also achieve the benefit
afforded by that mechanism.

84
00:04:04,730 --> 00:04:06,440
And I'm gonna tell you about
a couple of examples here

85
00:04:06,440 --> 00:04:07,930
in a second.

86
00:04:07,930 --> 00:04:11,160
But again, to an unwitting
user, to an average person

87
00:04:11,160 --> 00:04:14,270
who doesn't have special considerations,

88
00:04:14,270 --> 00:04:16,540
those invisible components
are out of sight,

89
00:04:16,540 --> 00:04:17,733
they're out of mind.

90
00:04:19,200 --> 00:04:22,500
I will acknowledge that this
concept is not 100% new.

91
00:04:22,500 --> 00:04:25,750
It has been talked about
in literature, in research,

92
00:04:25,750 --> 00:04:28,947
and the examples that I'm
gonna give you, I think,

93
00:04:28,947 --> 00:04:31,460
.2 ideas in invisible security.

94
00:04:31,460 --> 00:04:34,440
What I want is to push
this idea further along.

95
00:04:34,440 --> 00:04:36,950
I wanna highlight those
existing implementations

96
00:04:36,950 --> 00:04:39,380
and why I think they work in an effort

97
00:04:39,380 --> 00:04:43,550
to spur more innovation, more
technology just like that.

98
00:04:43,550 --> 00:04:45,550
So let me give you a couple of examples.

99
00:04:47,890 --> 00:04:51,460
The first idea that occurs to
me that I think is consistent

100
00:04:51,460 --> 00:04:53,219
with what I mean and invisible security

101
00:04:53,220 --> 00:04:55,880
are automatic software updates.

102
00:04:55,880 --> 00:04:58,969
You probably are well familiar
with this kind of technology,

103
00:04:58,970 --> 00:05:01,670
and I've seen these
kinds of choices before.

104
00:05:01,670 --> 00:05:04,960
Automatic updates give a great example

105
00:05:04,960 --> 00:05:07,239
of what I mean by being invisible.

106
00:05:07,240 --> 00:05:11,510
It can be enabled by default
like an operating system update

107
00:05:11,510 --> 00:05:14,950
and users have some degree of
control when it's necessary

108
00:05:14,950 --> 00:05:18,190
or when automatic updates
might be dangerous

109
00:05:18,190 --> 00:05:20,910
in some environment like a hospital.

110
00:05:20,910 --> 00:05:24,180
But the goal is not to
make updates usable,

111
00:05:24,180 --> 00:05:27,740
it actually is just to
automatically do the right thing.

112
00:05:27,740 --> 00:05:30,890
Now, this has turned out
to be wildly successful,

113
00:05:30,890 --> 00:05:33,130
especially in operating systems.

114
00:05:33,130 --> 00:05:34,960
But I'll be the first to acknowledge,

115
00:05:34,960 --> 00:05:37,359
there's perfectly good
reasons why certain people

116
00:05:37,360 --> 00:05:41,870
or certain businesses, or
contexts might need more control,

117
00:05:41,870 --> 00:05:44,640
but I'm talking about here
are the broad swaths of people

118
00:05:44,640 --> 00:05:46,830
that don't want to think about security,

119
00:05:46,830 --> 00:05:50,260
can't afford the time
or the money to do it,

120
00:05:50,260 --> 00:05:52,170
they don't wanna hire an IT professional

121
00:05:52,170 --> 00:05:54,400
to keep their systems updated.

122
00:05:54,400 --> 00:05:56,599
Automatic updates is one way

123
00:05:56,600 --> 00:05:58,540
that they just don't have to do anything,

124
00:05:58,540 --> 00:06:01,470
the software is continually
keeping itself up to date.

125
00:06:01,470 --> 00:06:04,010
And as we know, software
updates are the number one

126
00:06:04,010 --> 00:06:07,690
most important mechanism
to keeping people safe.

127
00:06:07,690 --> 00:06:09,140
So that's example number one.

128
00:06:11,690 --> 00:06:14,040
The second example I
wanna talk to you about

129
00:06:14,040 --> 00:06:17,350
of invisible security is protective DNS.

130
00:06:17,350 --> 00:06:19,660
If you're not aware, we are all consumers

131
00:06:19,660 --> 00:06:20,810
of the domain name service,

132
00:06:20,810 --> 00:06:23,090
whether we acknowledge it or not.

133
00:06:23,090 --> 00:06:26,880
When any of us queries
google.com or nsa.gov

134
00:06:26,880 --> 00:06:28,840
for that matter, behind the scenes,

135
00:06:28,840 --> 00:06:30,979
the computer does a
whole series of lookups

136
00:06:30,980 --> 00:06:33,550
to try and figure out how your computer

137
00:06:33,550 --> 00:06:36,200
can talk to the web server
somewhere on the internet.

138
00:06:37,330 --> 00:06:40,310
So protective DNS is a
service that is compatible

139
00:06:40,310 --> 00:06:42,440
with that traditional DNS system,

140
00:06:42,440 --> 00:06:45,350
except it has an additional
feature, which is,

141
00:06:45,350 --> 00:06:48,900
it has some sense for
known bad domain names.

142
00:06:48,900 --> 00:06:51,590
And when you query something
that might be malicious,

143
00:06:51,590 --> 00:06:55,770
it can prevent your browser
from resolving that domain

144
00:06:55,770 --> 00:06:58,120
by simply redirecting you to a site

145
00:06:58,120 --> 00:07:01,060
or not allowing the browser to go there.

146
00:07:01,060 --> 00:07:04,310
A lot of malware does the same thing.

147
00:07:04,310 --> 00:07:07,110
It needs to resolve command
and control domains,

148
00:07:07,110 --> 00:07:08,110
for example.

149
00:07:08,110 --> 00:07:11,720
And this sort of a system
can understand that risk.

150
00:07:11,720 --> 00:07:13,190
But again, the user doesn't have

151
00:07:13,190 --> 00:07:15,620
to take any explicit action.

152
00:07:15,620 --> 00:07:18,710
DNS is often configured for
our computers automatically.

153
00:07:18,710 --> 00:07:23,169
DHCP in your home or in your
business tells your computer

154
00:07:23,170 --> 00:07:25,690
what domain name servers to use.

155
00:07:25,690 --> 00:07:29,680
And protective DNS allows
this to happen transparently

156
00:07:29,680 --> 00:07:30,963
for average users.

157
00:07:32,390 --> 00:07:35,280
This past year, the NSA actually conducted

158
00:07:35,280 --> 00:07:37,099
a protective DNS pilot

159
00:07:37,100 --> 00:07:39,990
with several Defense
Industrial Base companies.

160
00:07:39,990 --> 00:07:44,140
And these companies wouldn't
otherwise have probably known

161
00:07:44,140 --> 00:07:46,520
about the malicious
domains or had any ability

162
00:07:46,520 --> 00:07:50,760
to block them, and it turned
out to be wildly successful.

163
00:07:50,760 --> 00:07:54,830
In the evaluation afterwards,
we found that protected DNS

164
00:07:54,830 --> 00:07:56,440
probably would have reduced the ability

165
00:07:56,440 --> 00:07:59,550
for 92% of malware attacks.

166
00:07:59,550 --> 00:08:02,030
And now, we're looking at
ways that this technology

167
00:08:02,030 --> 00:08:05,179
can scale to tens or hundreds of thousands

168
00:08:05,180 --> 00:08:10,180
of defense companies that allow
all of them to be protected,

169
00:08:10,620 --> 00:08:14,930
again, without any explicit
interactive action required

170
00:08:14,930 --> 00:08:15,920
from the user.

171
00:08:15,920 --> 00:08:17,920
So that seems like a really great thing.

172
00:08:20,200 --> 00:08:23,159
The third example I wanna
give of invisible security

173
00:08:23,160 --> 00:08:26,300
is facial recognition authentication.

174
00:08:26,300 --> 00:08:29,810
Now, I believe that users hate passwords.

175
00:08:29,810 --> 00:08:31,670
And as we saw on that earlier slide,

176
00:08:31,670 --> 00:08:34,350
they're really terrible at creating them.

177
00:08:34,350 --> 00:08:37,400
Facial recognition is
one way, a very fast way

178
00:08:37,400 --> 00:08:39,980
to authenticate a user when she just looks

179
00:08:39,980 --> 00:08:40,970
at the phone, right?

180
00:08:40,970 --> 00:08:44,020
Just looks at a device
and the face is recognized

181
00:08:44,020 --> 00:08:48,360
and the authorized user gets
access to that, to that device.

182
00:08:48,360 --> 00:08:52,090
Often a phone, now,
often computers as well.

183
00:08:52,090 --> 00:08:54,970
And we see this feature
gaining momentum, right?

184
00:08:54,970 --> 00:08:57,060
If you're familiar with Apple's face ID

185
00:08:57,060 --> 00:08:59,689
or Android facial recognition,

186
00:08:59,690 --> 00:09:02,360
It is more and more commonplace.

187
00:09:02,360 --> 00:09:04,430
And I think that shows a lot,

188
00:09:04,430 --> 00:09:07,079
the adoption there shows
a lot of potential.

189
00:09:07,080 --> 00:09:10,490
And again, the user has to do
very little to authenticate.

190
00:09:10,490 --> 00:09:12,050
They don't have to remember anything,

191
00:09:12,050 --> 00:09:14,949
they just have to look at the phone.

192
00:09:14,950 --> 00:09:19,503
Now, there are clear trade-offs
in this particular example.

193
00:09:20,530 --> 00:09:23,819
It is very easy to change a
password in most circumstances

194
00:09:23,820 --> 00:09:27,170
and it is nearly impossible
to change biometrics, right?

195
00:09:27,170 --> 00:09:30,680
You can't change your
fingerprint or that face.

196
00:09:30,680 --> 00:09:34,130
And if the mechanism
breaks down in some way,

197
00:09:34,130 --> 00:09:36,970
then we end up in a
really tough situation.

198
00:09:36,970 --> 00:09:40,330
But again, for average
users in many cases,

199
00:09:40,330 --> 00:09:42,687
I think facial recognition authentication

200
00:09:42,687 --> 00:09:46,680
,is a great way to help
not only improve security,

201
00:09:46,680 --> 00:09:50,530
it's better than no
authentication, but also making it

202
00:09:50,530 --> 00:09:54,403
very, very usable, nearly
invisible for the user.

203
00:09:57,480 --> 00:10:02,020
Now, invisible security is
quite a high-level idea,

204
00:10:02,020 --> 00:10:03,579
and all acknowledged that there are lots

205
00:10:03,580 --> 00:10:06,900
of considerations when thinking about

206
00:10:06,900 --> 00:10:08,530
whether it should be adopted

207
00:10:08,530 --> 00:10:11,750
or how to even build
more solutions like it.

208
00:10:11,750 --> 00:10:13,040
I wanna spend a couple of minutes

209
00:10:13,040 --> 00:10:15,730
highlighting one of these
attributes and invite you

210
00:10:15,730 --> 00:10:18,890
to think about others or ask
them to meet in the Q and A.

211
00:10:18,890 --> 00:10:21,240
I've also written a paper
that describes these in more,

212
00:10:21,240 --> 00:10:23,490
sort of explicit detail.

213
00:10:23,490 --> 00:10:24,740
But the one what I wanna talk about

214
00:10:24,740 --> 00:10:26,143
is the transfer of trust.

215
00:10:27,100 --> 00:10:31,740
I think trust is a keystone
component of invisible security

216
00:10:31,740 --> 00:10:34,400
and for that matter,
for all cyber security,

217
00:10:34,400 --> 00:10:36,270
but it's especially important.

218
00:10:36,270 --> 00:10:38,770
It seems to me when users are outsourcing

219
00:10:38,770 --> 00:10:42,449
some of their decisions to
software on their computer

220
00:10:42,450 --> 00:10:45,563
or a third party like a
protective DNS provider.

221
00:10:46,550 --> 00:10:48,640
Users, I think, might be reluctant,

222
00:10:48,640 --> 00:10:51,319
they might not embrace invisible security

223
00:10:51,320 --> 00:10:53,100
if they don't trust it,

224
00:10:53,100 --> 00:10:55,690
and that will be very, very important.

225
00:10:55,690 --> 00:10:58,210
It also means that bad experiences,

226
00:10:58,210 --> 00:11:01,600
maybe an automatic
update crashed a computer

227
00:11:01,600 --> 00:11:03,560
or something else went awry,

228
00:11:03,560 --> 00:11:07,030
that is really difficult to
overcome, to rebuild that trust

229
00:11:07,030 --> 00:11:10,353
after such, after trust has been breached.

230
00:11:11,940 --> 00:11:14,360
Of course, we also have
to extend the possibility

231
00:11:14,360 --> 00:11:17,040
that the invisible
security mechanism itself

232
00:11:17,040 --> 00:11:19,110
has to be trustworthy.

233
00:11:19,110 --> 00:11:21,187
As a security professional,
we're probably thinking,

234
00:11:21,187 --> 00:11:23,790
"Well, how might a malicious actor

235
00:11:23,790 --> 00:11:26,680
commandeer this protection mechanism?"

236
00:11:26,680 --> 00:11:29,020
We always have to be thinking about that.

237
00:11:29,020 --> 00:11:34,020
And being able to build
resilient, robust services

238
00:11:34,070 --> 00:11:37,030
to provide invisible
security is very important.

239
00:11:37,030 --> 00:11:40,483
I don't want them to become
distrusted or mistrusted.

240
00:11:43,420 --> 00:11:45,709
The last thing I'll say
about the transfer of trust

241
00:11:45,710 --> 00:11:48,270
is that because users
are giving up control,

242
00:11:48,270 --> 00:11:51,430
particularly where the computer
seems to be making decisions

243
00:11:51,430 --> 00:11:54,800
for them, I found that users often expect

244
00:11:54,800 --> 00:11:58,010
an outsized benefit from that technology

245
00:11:58,010 --> 00:12:01,830
even when it is just a little
bit better than a human.

246
00:12:01,830 --> 00:12:04,930
We see this, for example,
in self-driving cars

247
00:12:04,930 --> 00:12:08,660
where the user expects it
to be perfect every time,

248
00:12:08,660 --> 00:12:10,189
to make no mistakes.

249
00:12:10,190 --> 00:12:15,040
And even if it's 1%, 5% better
than what a human would do,

250
00:12:15,040 --> 00:12:19,780
the users won't adopt that
technology just for small gains.

251
00:12:19,780 --> 00:12:21,870
They want it to be amazing.

252
00:12:21,870 --> 00:12:24,350
They want it to be nearly perfect.

253
00:12:24,350 --> 00:12:26,450
There's a lot of human psychology in that.

254
00:12:27,476 --> 00:12:29,200
And a lot of research I think to be done

255
00:12:29,200 --> 00:12:33,440
about how do we compensate
for those decisions?

256
00:12:33,440 --> 00:12:37,480
So the transfer of trust, very
important one to consider.

257
00:12:37,480 --> 00:12:39,340
I will say, I think it is working well

258
00:12:39,340 --> 00:12:41,750
in the three examples that I gave.

259
00:12:41,750 --> 00:12:44,560
Lots of users seem to
have accepted the trust

260
00:12:44,560 --> 00:12:46,560
of automatic updates.

261
00:12:46,560 --> 00:12:48,290
There have been notable exceptions,

262
00:12:48,290 --> 00:12:50,630
not every update goes smoothly,

263
00:12:50,630 --> 00:12:53,360
but I think users are
finding the trade-off

264
00:12:53,360 --> 00:12:55,480
to be in their favor.

265
00:12:55,480 --> 00:12:59,010
They feel safer. Their
computers are safer.

266
00:12:59,010 --> 00:13:01,990
The cybersecurity
community has measured them

267
00:13:02,840 --> 00:13:05,040
through research and scientific studies

268
00:13:05,040 --> 00:13:08,270
and show that the ecosystem is safer

269
00:13:08,270 --> 00:13:10,020
because those things are turned on.

270
00:13:11,250 --> 00:13:13,090
Again, lots of other considerations,

271
00:13:13,090 --> 00:13:15,483
transfer of trust, a big important one.

272
00:13:18,600 --> 00:13:21,420
I'd like to talk about three
groups that I think benefit

273
00:13:21,420 --> 00:13:24,670
from the, the adoption
of invisible security,

274
00:13:24,670 --> 00:13:26,800
three specific audiences.

275
00:13:26,800 --> 00:13:28,900
The first one I touched on in the pilot

276
00:13:28,900 --> 00:13:32,579
that I said NSA did is the
Defense Industrial Base.

277
00:13:32,580 --> 00:13:36,320
So the DIB is a complex
ecosystem of companies.

278
00:13:36,320 --> 00:13:38,990
In the United States,
it's estimated to contain

279
00:13:38,990 --> 00:13:41,900
around 300,000 companies.

280
00:13:41,900 --> 00:13:44,959
And if we think about that
like a supply chain pyramid,

281
00:13:44,960 --> 00:13:47,130
most of those companies are quite small

282
00:13:47,130 --> 00:13:49,210
or mid-sized companies.

283
00:13:49,210 --> 00:13:53,180
And further than that, each
company and their employees

284
00:13:53,180 --> 00:13:56,040
introduces risk to national
security in some way

285
00:13:56,040 --> 00:13:58,730
because of their
involvement in the defense,

286
00:13:58,730 --> 00:14:00,563
in the defense ecosystem.

287
00:14:01,540 --> 00:14:03,920
I'll also say that small
businesses in general

288
00:14:03,920 --> 00:14:07,040
including those in the
Defense Industrial Base,

289
00:14:07,040 --> 00:14:08,939
have tight profit margins.

290
00:14:08,940 --> 00:14:13,450
They're small companies
and they need that,

291
00:14:13,450 --> 00:14:15,160
so any amount of time or money

292
00:14:15,160 --> 00:14:16,890
that they have to put into security,

293
00:14:16,890 --> 00:14:20,260
cuts away at that tight
profit margin already.

294
00:14:20,260 --> 00:14:23,390
In some cases, it might risk
putting them out of business

295
00:14:23,390 --> 00:14:26,240
if they have to devote a lot
of time or a lot of money

296
00:14:26,240 --> 00:14:27,833
to doing good cybersecurity.

297
00:14:28,770 --> 00:14:30,439
So I think for this kind of community,

298
00:14:30,440 --> 00:14:32,690
particularly, the small,
mid-sized companies

299
00:14:32,690 --> 00:14:36,040
in this ecosystem, invisible
security can help lower

300
00:14:36,040 --> 00:14:38,949
their risk while also being respectful

301
00:14:38,950 --> 00:14:40,430
of those resource limitations

302
00:14:40,430 --> 00:14:42,043
that they, that they experience.

303
00:14:45,470 --> 00:14:48,500
The second beneficiary that I think

304
00:14:48,500 --> 00:14:51,453
invisible security is very
helpful to is healthcare.

305
00:14:52,920 --> 00:14:55,760
It's important to realize
that for most users,

306
00:14:55,760 --> 00:14:56,757
for most people that we think about

307
00:14:56,757 --> 00:14:58,770
in the cyber security ecosystem,

308
00:14:58,770 --> 00:15:01,390
security is not the goal, right?

309
00:15:01,390 --> 00:15:03,150
This is pretty evident in healthcare

310
00:15:03,150 --> 00:15:05,823
where health is the primary task.

311
00:15:06,830 --> 00:15:09,960
Even though health data
is very valuable, right?

312
00:15:09,960 --> 00:15:11,750
And they're quite vulnerable,

313
00:15:11,750 --> 00:15:13,550
we have laws to help protect it

314
00:15:13,550 --> 00:15:16,453
because it is recognized
to be very valuable.

315
00:15:17,410 --> 00:15:20,949
Now, a big business, a big hospital,

316
00:15:20,950 --> 00:15:23,530
a big university clinic, they might have

317
00:15:23,530 --> 00:15:27,560
a dedicated IT staff and a
dedicated cybersecurity budget

318
00:15:27,560 --> 00:15:30,423
that makes their cybersecurity very good,

319
00:15:32,090 --> 00:15:33,500
but there are lots and lots

320
00:15:33,500 --> 00:15:35,320
of various small healthcare providers

321
00:15:35,320 --> 00:15:38,300
with one doctor or two nurses.

322
00:15:38,300 --> 00:15:41,160
And those are the situations
where there are probably

323
00:15:41,160 --> 00:15:44,100
is not dedicated IT staff or budget.

324
00:15:44,100 --> 00:15:47,700
And they experienced the same
risk to health information

325
00:15:47,700 --> 00:15:52,250
without the aid that they would
get from invisible security,

326
00:15:52,250 --> 00:15:53,840
and that's the subset of healthcare

327
00:15:53,840 --> 00:15:56,913
that I think would benefit
very strongly from this.

328
00:15:58,150 --> 00:16:02,030
Again, it's just one component,
but if that allows them

329
00:16:02,030 --> 00:16:04,900
to better protect your
protected health information

330
00:16:04,900 --> 00:16:07,880
to make sure it's secure, compliant,

331
00:16:07,880 --> 00:16:11,140
it seems like a benefit
not only to the provider,

332
00:16:11,140 --> 00:16:13,063
but also to us as patients.

333
00:16:17,550 --> 00:16:19,630
Third group is kind of a catch all,

334
00:16:19,630 --> 00:16:22,330
but I think it is a benefit
to the general public,

335
00:16:22,330 --> 00:16:24,520
to everyday people.

336
00:16:24,520 --> 00:16:28,010
Lots of people in my
family, in my community

337
00:16:28,010 --> 00:16:31,770
and in our world manage
their own technology.

338
00:16:31,770 --> 00:16:34,460
And they don't have an IT professional

339
00:16:34,460 --> 00:16:37,980
or a lot of money or
time to sort of consider

340
00:16:37,980 --> 00:16:41,290
how to do really, really
amazing cyber security.

341
00:16:41,290 --> 00:16:44,699
But they also have stuff
that needs protecting, right?

342
00:16:44,700 --> 00:16:48,620
Your bank account, your
email, your personal photos

343
00:16:48,620 --> 00:16:50,180
and information.

344
00:16:50,180 --> 00:16:53,849
So for people that are not
on average very tech savvy,

345
00:16:53,850 --> 00:16:56,170
how can we still protect them, right?

346
00:16:56,170 --> 00:16:58,750
They want to be safe,
but they also don't want

347
00:16:58,750 --> 00:17:00,820
to be inconvenienced.

348
00:17:00,820 --> 00:17:03,120
And this is the group that
I think benefits the most

349
00:17:03,120 --> 00:17:04,609
from invisible security.

350
00:17:04,609 --> 00:17:08,209
And I think it's why we see
such great adoption of things

351
00:17:08,210 --> 00:17:09,410
like automatic updates

352
00:17:09,410 --> 00:17:12,323
and the facial recognition
authentication on phones.

353
00:17:17,089 --> 00:17:20,530
I wanna step aside a second
and acknowledge the limits,

354
00:17:20,530 --> 00:17:23,899
the limitations of invisible security.

355
00:17:23,900 --> 00:17:26,290
First, let me say that invisible security

356
00:17:26,290 --> 00:17:30,050
is not about absolving users
of all of their responsibility

357
00:17:30,050 --> 00:17:33,800
or them giving up complete control.

358
00:17:33,800 --> 00:17:35,940
Even if this was wildly successful,

359
00:17:35,940 --> 00:17:40,210
users are not gonna be magically
immune to cyber attacks.

360
00:17:40,210 --> 00:17:42,110
If that was true, we
would have adopted this

361
00:17:42,110 --> 00:17:43,513
a long time ago, I think.

362
00:17:44,950 --> 00:17:47,370
By analogy, for example, an automobile

363
00:17:47,370 --> 00:17:52,209
has a lot of automatic features,
dozens, hundreds, maybe.

364
00:17:52,210 --> 00:17:55,460
But the driver still has to
take deliberate action, right?

365
00:17:55,460 --> 00:17:57,610
Still has to buckle their safety belt.

366
00:17:57,610 --> 00:18:00,233
Still has to press the
brake pedal in some cases.

367
00:18:01,240 --> 00:18:03,860
We're not absolving drivers
have all the responsibility

368
00:18:03,860 --> 00:18:06,959
and we can't do the same for cyber either.

369
00:18:06,960 --> 00:18:10,500
I think designers of invisible
security technologies

370
00:18:10,500 --> 00:18:12,830
need to take that, we need to respect that

371
00:18:12,830 --> 00:18:14,600
that there's an appropriate balance here

372
00:18:14,600 --> 00:18:19,340
between the desires for user
autonomy where it's appropriate

373
00:18:19,340 --> 00:18:24,092
and where that trade-offs
for good or worst security?

374
00:18:25,340 --> 00:18:27,010
Another thing I want to understand

375
00:18:27,010 --> 00:18:29,040
are what are called mental models

376
00:18:29,040 --> 00:18:31,980
or how a user understands what's happening

377
00:18:31,980 --> 00:18:34,480
on their computer inside their own brain.

378
00:18:34,480 --> 00:18:36,943
What is their mental model
for what is going on?

379
00:18:39,995 --> 00:18:42,489
And the area where I would like
to see more research in this

380
00:18:42,490 --> 00:18:46,593
is about how people feel
safe when they see security.

381
00:18:48,460 --> 00:18:51,540
It might be possible just to notify a user

382
00:18:51,540 --> 00:18:54,240
that perhaps, the computer
has taken an action

383
00:18:54,240 --> 00:18:57,220
even though the user doesn't
have to make any choice

384
00:18:57,220 --> 00:18:59,030
or do any intervention.

385
00:18:59,030 --> 00:19:01,310
And I see this in some antivirus products

386
00:19:01,310 --> 00:19:04,830
that just alert the user
that they have been protected

387
00:19:04,830 --> 00:19:08,510
or some browsers that say,
"We have limited your access

388
00:19:08,510 --> 00:19:11,520
to this website because
we know it is malicious."

389
00:19:11,520 --> 00:19:14,820
And so, that notification
might be the right way

390
00:19:14,820 --> 00:19:16,500
to let the user know what's happening,

391
00:19:16,500 --> 00:19:18,920
that the computer has taken an action

392
00:19:18,920 --> 00:19:22,220
without them still having to understand

393
00:19:22,220 --> 00:19:24,720
that this button is the
button they should click

394
00:19:24,720 --> 00:19:27,153
or this is the action
that they should take.

395
00:19:30,710 --> 00:19:32,910
Many of you might be familiar
with a concept called

396
00:19:32,910 --> 00:19:34,120
the visible policing.

397
00:19:34,120 --> 00:19:38,320
And this goes into that, that
mental model argument as well.

398
00:19:38,320 --> 00:19:41,030
And what visible policing
is, is that the presence

399
00:19:41,030 --> 00:19:44,940
of the police or guards
or uniformed officers

400
00:19:44,940 --> 00:19:49,700
is thought to make people
feel feelings of safety.

401
00:19:49,700 --> 00:19:51,760
Now, this is actually a different goal

402
00:19:51,760 --> 00:19:54,629
than actually being safe,
but I think it's important,

403
00:19:54,630 --> 00:19:57,100
nonetheless, that users of their computer

404
00:19:57,100 --> 00:19:59,780
not only need to be safe,
but they need to feel it.

405
00:19:59,780 --> 00:20:03,693
And so that mental model, I
think, plays into that a lot.

406
00:20:04,860 --> 00:20:07,750
You might also be asking yourself
the question on the right

407
00:20:07,750 --> 00:20:10,380
which is, "Well, if invisible
security is so good,

408
00:20:10,380 --> 00:20:13,840
why is there so much
attention even evidence

409
00:20:13,840 --> 00:20:15,486
about multi-factor authentication?" right?

410
00:20:15,487 --> 00:20:17,370
"Or two factor authentication?"

411
00:20:17,370 --> 00:20:20,080
And the way that that
better protects accounts

412
00:20:20,080 --> 00:20:22,010
than just having a password.

413
00:20:22,010 --> 00:20:23,890
And you might say,
"Well, isn't multi-factor

414
00:20:23,890 --> 00:20:26,673
better than just facial
recognition?" for example.

415
00:20:27,580 --> 00:20:29,110
I would like to see more research here.

416
00:20:29,110 --> 00:20:31,173
I think this is a great topic for,

417
00:20:32,040 --> 00:20:34,120
for some academic research.

418
00:20:34,120 --> 00:20:36,000
It's possible that the second factor

419
00:20:36,000 --> 00:20:38,170
can also be more invisible.

420
00:20:38,170 --> 00:20:41,790
Instead of requiring the
user to put their thumbprint

421
00:20:41,790 --> 00:20:44,240
on a fingerprint reader,
or to press a button

422
00:20:44,240 --> 00:20:46,060
that pops up on their phone,

423
00:20:46,060 --> 00:20:49,580
what if that second
could be behavior-based?

424
00:20:49,580 --> 00:20:51,770
Keys, the way that you
type your keystrokes

425
00:20:51,770 --> 00:20:53,660
could be the second factor.

426
00:20:53,660 --> 00:20:57,120
Continuous authentication is
now being built into websites

427
00:20:57,120 --> 00:21:00,479
like some banks that
continually try to evaluate

428
00:21:00,480 --> 00:21:02,960
every few seconds, is it still the user?

429
00:21:02,960 --> 00:21:05,430
I think it is based on their behavior.

430
00:21:05,430 --> 00:21:08,570
And so, behavior might offer us a way

431
00:21:08,570 --> 00:21:11,389
to have an invisible
second factor as well.

432
00:21:11,390 --> 00:21:12,990
I think that's kind of exciting.

433
00:21:17,640 --> 00:21:19,826
So what comes next?

434
00:21:19,826 --> 00:21:22,326
I said that there's already
some examples of this.

435
00:21:23,660 --> 00:21:25,900
I think there's a lot of work to be done.

436
00:21:25,900 --> 00:21:28,270
First is to acknowledge that the disparate

437
00:21:28,270 --> 00:21:30,389
sort of technologies
that I have highlighted,

438
00:21:30,390 --> 00:21:33,440
things like auto updates, protective DNS,

439
00:21:33,440 --> 00:21:35,850
that they all fall under an umbrella.

440
00:21:35,850 --> 00:21:38,389
Recognizing that I think
will help push the boundaries

441
00:21:38,390 --> 00:21:40,940
a little bit farther than, than otherwise,

442
00:21:40,940 --> 00:21:45,260
just having individual disparate
sort of research efforts

443
00:21:45,260 --> 00:21:47,070
or features that could that rollout.

444
00:21:47,070 --> 00:21:49,280
If we think of them all
together, I think that gives us

445
00:21:49,280 --> 00:21:52,562
a better picture and a better
way to advocate for them.

446
00:21:53,870 --> 00:21:57,239
In addition to that, I think
there's a lot of technology

447
00:21:57,240 --> 00:22:01,150
that will emerge on the
horizon relatively soon.

448
00:22:01,150 --> 00:22:03,080
I will say, I don't
know what the answer is,

449
00:22:03,080 --> 00:22:04,899
I don't know what the next thing is,

450
00:22:04,900 --> 00:22:07,350
and so, my invitation is for all of us

451
00:22:07,350 --> 00:22:09,459
to do more thinking about this.

452
00:22:09,460 --> 00:22:12,130
One, though, I think authentication trends

453
00:22:12,130 --> 00:22:14,090
will continue to evolve.

454
00:22:14,090 --> 00:22:17,730
The same way that we saw
an evolution from passwords

455
00:22:17,730 --> 00:22:22,730
to biometrics, to behavioral analysis,

456
00:22:23,330 --> 00:22:26,040
I suspect there will continue to be

457
00:22:26,040 --> 00:22:29,350
usable security evolution
in authentication.

458
00:22:29,350 --> 00:22:32,679
I don't think we've quite
hit the end of that yet.

459
00:22:32,680 --> 00:22:36,110
Two, I think there's a lot of opportunity

460
00:22:36,110 --> 00:22:38,753
for high-quality reputation services.

461
00:22:39,770 --> 00:22:42,100
These threat reputation
services can give you,

462
00:22:42,100 --> 00:22:45,389
can give us timely, dynamic, and honestly,

463
00:22:45,390 --> 00:22:49,790
hands-free defenses for
new threats as they emerge.

464
00:22:49,790 --> 00:22:54,430
So not only do we not have to
wait for threat intelligence

465
00:22:54,430 --> 00:22:58,220
to come to us very
manually or very slowly,

466
00:22:58,220 --> 00:23:01,150
but if we can trust and if we can build

467
00:23:02,020 --> 00:23:04,620
low false positive reputation services,

468
00:23:04,620 --> 00:23:07,530
and then have the computer
automatically enforce them,

469
00:23:07,530 --> 00:23:09,960
that would be a new way
for invisible security

470
00:23:09,960 --> 00:23:11,863
to help yet another area.

471
00:23:12,810 --> 00:23:16,810
The third one, and I am not
always the forefront advocate

472
00:23:16,810 --> 00:23:19,590
of machine learning, but
I think this is one place

473
00:23:19,590 --> 00:23:23,169
where machine learning or AI
could eventually contribute

474
00:23:23,170 --> 00:23:24,523
to invisible security.

475
00:23:25,420 --> 00:23:28,000
In particular, machine
learning is quite good

476
00:23:28,000 --> 00:23:29,580
at anomaly detection.

477
00:23:29,580 --> 00:23:31,960
And so, if we applied
that to user behavior

478
00:23:31,960 --> 00:23:35,790
or machine behavior, and the ability to,

479
00:23:35,790 --> 00:23:38,860
behind the scenes have the computer notice

480
00:23:38,860 --> 00:23:43,129
that the machine is acting
differently than it did before,

481
00:23:43,130 --> 00:23:45,730
we've had that kind of
intrusion detection,

482
00:23:45,730 --> 00:23:48,730
but I think there's a lot more
opportunities on the horizon

483
00:23:48,730 --> 00:23:52,700
for those systems to, to take
action, to make decisions,

484
00:23:52,700 --> 00:23:57,700
to inform humans about how to
better protect their systems.

485
00:23:57,710 --> 00:24:01,020
So I actually see a
lot of future potential

486
00:24:01,020 --> 00:24:03,010
for machine learning in this field.

487
00:24:03,010 --> 00:24:05,280
And I'm probably sure I can't envision

488
00:24:05,280 --> 00:24:08,080
all the creative ways that
people will also go about it.

489
00:24:11,490 --> 00:24:14,200
So let's talk for a minute
about how to put this idea

490
00:24:14,200 --> 00:24:15,460
into action.

491
00:24:15,460 --> 00:24:18,520
One, I think it's important
to look for opportunities

492
00:24:18,520 --> 00:24:23,520
to transition from traditional
intrusive cybersecurity

493
00:24:24,060 --> 00:24:26,543
to proposals for invisible.

494
00:24:27,820 --> 00:24:30,770
It isn't the panacea, it isn't
gonna solve every problem,

495
00:24:30,770 --> 00:24:32,580
I will be the first to acknowledge,

496
00:24:32,580 --> 00:24:34,909
but I think we should
look for opportunities

497
00:24:34,910 --> 00:24:38,000
about where can those
trade-offs occurred today

498
00:24:38,000 --> 00:24:41,450
and where are opportunities
to develop them in the future.

499
00:24:41,450 --> 00:24:44,220
What new technology could help alleviate

500
00:24:44,220 --> 00:24:47,260
some really cumbersome, burdenful tasks

501
00:24:47,260 --> 00:24:50,353
that the users have today
and make that more invisible.

502
00:24:52,090 --> 00:24:54,240
I don't want you to
just take my word for it

503
00:24:54,240 --> 00:24:55,660
that this is a good idea.

504
00:24:55,660 --> 00:24:59,460
I think metrics and measurements
will let you try things out

505
00:24:59,460 --> 00:25:01,720
and to measure whether they work or not.

506
00:25:01,720 --> 00:25:04,280
I'm a big fan of doing this
where you measure how well

507
00:25:04,280 --> 00:25:05,760
the environment is working.

508
00:25:05,760 --> 00:25:08,010
What are the security metrics today?

509
00:25:08,010 --> 00:25:10,570
How happy are your users with them?

510
00:25:10,570 --> 00:25:12,379
And then to make a small change, right?

511
00:25:12,380 --> 00:25:17,090
Turn on automatic updates,
or introduce protected DNS

512
00:25:17,090 --> 00:25:19,470
into your environment, and
do the measurement again

513
00:25:19,470 --> 00:25:22,760
and find out, is it better
than what you had before?

514
00:25:22,760 --> 00:25:25,170
For some meaningful metric, right?

515
00:25:25,170 --> 00:25:28,610
Do you have less malware
propagating on your network

516
00:25:28,610 --> 00:25:30,142
after the protective DNS?

517
00:25:31,200 --> 00:25:33,900
That's a good way to,
to prove, to show that

518
00:25:33,900 --> 00:25:35,633
that mechanism is working.

519
00:25:36,980 --> 00:25:39,750
In the long-term, I think we
need to push the envelope.

520
00:25:39,750 --> 00:25:42,760
We need to get ourselves
involved as practitioners

521
00:25:42,760 --> 00:25:44,720
with the research community.

522
00:25:44,720 --> 00:25:47,480
They want to hear our real pain points.

523
00:25:47,480 --> 00:25:50,540
And if security is too burdensome,

524
00:25:50,540 --> 00:25:53,050
the research community loves
those kinds of problems.

525
00:25:53,050 --> 00:25:56,070
I've been in the research
community for a long time.

526
00:25:56,070 --> 00:25:59,360
We are, we're always looking
in that regard toward problems

527
00:25:59,360 --> 00:26:00,479
that people cared about,

528
00:26:00,480 --> 00:26:02,900
things that we could
really sink our teeth into,

529
00:26:02,900 --> 00:26:05,360
that aren't just engineering challenges.

530
00:26:05,360 --> 00:26:08,550
It's not just, we need to
code the software this way

531
00:26:08,550 --> 00:26:10,300
and the problem will be solved.

532
00:26:10,300 --> 00:26:11,909
This is a great area for research

533
00:26:11,910 --> 00:26:14,620
because we don't actually
know what the solutions

534
00:26:14,620 --> 00:26:15,850
will look like.

535
00:26:15,850 --> 00:26:18,070
We have some, I think, good examples,

536
00:26:18,070 --> 00:26:19,860
the ones that we've talked about here,

537
00:26:19,860 --> 00:26:22,209
and going and talking to communities.

538
00:26:22,210 --> 00:26:25,130
If we go to the hospital
and talk to the staff

539
00:26:25,130 --> 00:26:28,270
and say, "How much time are
you spending on security?"

540
00:26:28,270 --> 00:26:32,510
Or do observational studies
about how many times

541
00:26:32,510 --> 00:26:35,150
people use a shared password.

542
00:26:35,150 --> 00:26:38,210
We can get a better sense for
where the invisible security

543
00:26:38,210 --> 00:26:40,530
will have the most impact.

544
00:26:40,530 --> 00:26:42,820
And those are the ones
we can really focus on

545
00:26:42,820 --> 00:26:44,260
moving forward.

546
00:26:44,260 --> 00:26:45,640
But even if you're not a researcher,

547
00:26:45,640 --> 00:26:48,370
keep your eye out for
this kind of technology.

548
00:26:48,370 --> 00:26:51,409
When you see it and people
don't always call it

549
00:26:51,410 --> 00:26:54,140
under the umbrella that
I'm sort of proposing,

550
00:26:54,140 --> 00:26:55,840
now, if hopefully, you'll be able to keep

551
00:26:55,840 --> 00:26:59,360
in the back of your mind
that one benefit of the thing

552
00:26:59,360 --> 00:27:01,969
that a vendor is trying
to sell you might be,

553
00:27:01,970 --> 00:27:04,360
it's a low burden on our users.

554
00:27:04,360 --> 00:27:08,240
And we might be able to
replace an intrusive,

555
00:27:08,240 --> 00:27:11,180
sort of very hands-on choice for users

556
00:27:11,180 --> 00:27:13,680
to one that happens more automatically

557
00:27:13,680 --> 00:27:16,570
or alleviate some burden that the users

558
00:27:16,570 --> 00:27:19,240
are making the wrong
choice or taking too long

559
00:27:19,240 --> 00:27:20,470
to make a choice.

560
00:27:20,470 --> 00:27:22,270
So I very much look forward to that.

561
00:27:24,470 --> 00:27:26,380
So I look forward to your questions now.

562
00:27:26,380 --> 00:27:28,810
I will invite you to send
them to me at any time.

563
00:27:28,810 --> 00:27:30,690
We will have some time here to chat.

564
00:27:30,690 --> 00:27:32,960
My email is always open to you.

565
00:27:32,960 --> 00:27:35,120
And I look forward to
hearing your thoughts

566
00:27:35,120 --> 00:27:37,020
about limitations, but especially,

567
00:27:37,020 --> 00:27:39,080
how we can push this field forward,

568
00:27:39,080 --> 00:27:42,860
and really, how invisible
security can help protect users

569
00:27:42,860 --> 00:27:46,490
who have little resources,
have no time to spare.

570
00:27:46,490 --> 00:27:47,323
Thank you.

