1
00:00:01,310 --> 00:00:02,710
- Hi, everybody.

2
00:00:02,710 --> 00:00:06,470
Thanks so much for joining
us today on our presentation

3
00:00:06,470 --> 00:00:11,210
on Trans-Atlantic Data
Flows Post-Schrems II.

4
00:00:11,210 --> 00:00:14,110
So we're gonna be focusing on

5
00:00:14,110 --> 00:00:15,639
the transfer of data from Europe

6
00:00:15,640 --> 00:00:17,750
to the United States and around the world.

7
00:00:17,750 --> 00:00:18,610
I'm Bret Cohen.

8
00:00:18,610 --> 00:00:19,919
I'm a partner in the privacy,

9
00:00:19,920 --> 00:00:21,940
and cybersecurity
practice at the law firm,

10
00:00:21,940 --> 00:00:24,710
Hogan Lovells based in Washington,

11
00:00:24,710 --> 00:00:28,690
and I'm pleased to be here
today with Alexandra Ross,

12
00:00:28,690 --> 00:00:30,160
Director of Global Privacy,

13
00:00:30,160 --> 00:00:32,890
and Data Security Council at Autodesk,

14
00:00:32,890 --> 00:00:36,030
and Dr. Gabriela Zanfir-Fortuna,

15
00:00:36,030 --> 00:00:37,810
Senior Council for Global Privacy

16
00:00:37,810 --> 00:00:39,393
at the Future of Privacy Forum.

17
00:00:41,570 --> 00:00:45,440
So, jumping right into it,

18
00:00:45,440 --> 00:00:47,849
we're gonna get into the complex world

19
00:00:47,850 --> 00:00:50,060
of international data transfers.

20
00:00:50,060 --> 00:00:53,070
And we're gonna start
with a little background

21
00:00:53,070 --> 00:00:58,070
on where we are today with
Trans-Atlantic Data Flows.

22
00:00:58,530 --> 00:01:03,110
So I'm gonna take it a little
ways back to Edward Snowden.

23
00:01:03,110 --> 00:01:08,110
If you recall back in 2013 is
when he revealed to the world,

24
00:01:10,200 --> 00:01:12,770
what the US intelligence community

25
00:01:12,770 --> 00:01:15,130
was doing with access to data,

26
00:01:15,130 --> 00:01:19,830
and this actually caused
a fair amount of churn

27
00:01:19,830 --> 00:01:22,563
and consternation in the privacy world,

28
00:01:23,568 --> 00:01:28,568
due to US government access
to data of Europeans.

29
00:01:29,170 --> 00:01:34,170
And so there was a significant
back and forth discussion.

30
00:01:35,320 --> 00:01:38,993
We throw a quote up here
from the European commission,

31
00:01:40,070 --> 00:01:42,050
where there's been this I would say,

32
00:01:42,050 --> 00:01:46,090
long simmering sort of
debate or discussion

33
00:01:46,090 --> 00:01:48,433
about the appropriate privacy framework,

34
00:01:49,450 --> 00:01:52,210
for commercial access to
data, whether in Europe

35
00:01:52,210 --> 00:01:53,220
or in the United States,

36
00:01:53,220 --> 00:01:55,240
there are different privacy standards.

37
00:01:55,240 --> 00:01:58,309
And this just added some fuel to the fire,

38
00:01:58,310 --> 00:02:02,350
with European bodies taking note of this,

39
00:02:02,350 --> 00:02:04,240
and saying, "Wait a
second, we're talking about

40
00:02:04,240 --> 00:02:05,957
different layers of privacy protection,

41
00:02:05,957 --> 00:02:09,477
"perhaps personal information of Europeans

42
00:02:09,477 --> 00:02:12,939
"isn't as safe in the United States,

43
00:02:12,939 --> 00:02:13,772
"because it isn't subject

44
00:02:13,772 --> 00:02:16,357
"to as many due process protections,

45
00:02:16,357 --> 00:02:19,297
"when the US government seeks to access

46
00:02:19,297 --> 00:02:22,170
"the information for
intelligence purposes."

47
00:02:22,170 --> 00:02:25,670
So this led to a number of
other discussions and debates.

48
00:02:25,670 --> 00:02:27,589
And what's popping up here is a picture

49
00:02:27,590 --> 00:02:29,970
of the Court of Justice of the EU,

50
00:02:29,970 --> 00:02:34,760
which is the highest court
to interpret European

51
00:02:35,630 --> 00:02:38,760
constitutional and privacy rights.

52
00:02:38,760 --> 00:02:43,690
And we have this framework
called the US-EU Safe Harbor.

53
00:02:43,690 --> 00:02:45,883
Some of you may remember this,

54
00:02:47,530 --> 00:02:51,730
where under European law,
there is a baseline requirement

55
00:02:51,730 --> 00:02:54,910
that to transfer personal
information outside of Europe,

56
00:02:54,910 --> 00:02:57,799
dating back 20 plus years or so,

57
00:02:57,800 --> 00:03:00,680
that it needs to go to jurisdiction

58
00:03:00,680 --> 00:03:03,240
that has appropriate privacy protections.

59
00:03:03,240 --> 00:03:05,520
The US and the European Union negotiated

60
00:03:05,520 --> 00:03:08,510
the Safe Harbor framework,
through which US companies

61
00:03:08,510 --> 00:03:11,170
would certify to treat information

62
00:03:11,170 --> 00:03:13,220
with certain privacy protections,

63
00:03:13,220 --> 00:03:17,740
and would enable transfers
from Europe to the US,

64
00:03:17,740 --> 00:03:20,550
with what the European authorities

65
00:03:20,550 --> 00:03:23,000
considered appropriate
privacy protections.

66
00:03:23,000 --> 00:03:25,456
Well, after the Snowden revelations,

67
00:03:25,456 --> 00:03:30,456
due to this feature or
factor of US government

68
00:03:30,820 --> 00:03:33,250
access to data, the Court of Justice

69
00:03:33,250 --> 00:03:38,250
of the EU overruled or
invalidated Safe Harbor.

70
00:03:38,490 --> 00:03:40,970
It said it wasn't appropriately considered

71
00:03:40,970 --> 00:03:44,080
to cover transfers from
Europe to the United States.

72
00:03:44,080 --> 00:03:46,620
And this left the 5,000 or so US companies

73
00:03:46,620 --> 00:03:50,580
who were working under Safe
Harbor in alert, what do we do?

74
00:03:50,580 --> 00:03:52,973
And so for those of you in this world,

75
00:03:54,030 --> 00:03:55,870
a number of companies immediately went

76
00:03:55,870 --> 00:03:59,510
to go enact what we call the
standard contractual clauses,

77
00:03:59,510 --> 00:04:03,845
which was a set of pre-set
contractual clauses

78
00:04:03,845 --> 00:04:07,480
that were pre-approved by
the European commission

79
00:04:07,480 --> 00:04:09,600
to serve a similar function to provide

80
00:04:09,600 --> 00:04:12,549
appropriate privacy
protections for information.

81
00:04:12,550 --> 00:04:17,100
Except where the issues
with data transfers

82
00:04:17,100 --> 00:04:19,860
were fundamentally with
what the US government

83
00:04:19,860 --> 00:04:21,560
was doing with access to information.

84
00:04:21,560 --> 00:04:23,570
There was some question of whether

85
00:04:23,570 --> 00:04:27,400
a different mechanism
would even move the needle

86
00:04:27,400 --> 00:04:30,400
at all from a legal perspective in Europe.

87
00:04:30,400 --> 00:04:33,239
And we throw a quote in here from

88
00:04:33,240 --> 00:04:35,560
the Irish Data Protection Authority,

89
00:04:35,560 --> 00:04:39,040
who was evaluating the case,
that cast doubt on the use

90
00:04:39,040 --> 00:04:42,280
of the standard contractual
clauses, even back then.

91
00:04:42,280 --> 00:04:44,760
So what happened after that?

92
00:04:44,760 --> 00:04:48,500
The US and European Commission
negotiated a new framework

93
00:04:48,500 --> 00:04:50,840
to replace Safe Harbor
called Privacy Shield,

94
00:04:50,840 --> 00:04:52,909
some of you may be familiar with this,

95
00:04:52,910 --> 00:04:56,453
which took effect about
a year or so later.

96
00:04:57,549 --> 00:05:00,179
And companies could once again sign up

97
00:05:00,180 --> 00:05:02,560
to this framework, make
privacy commitments,

98
00:05:02,560 --> 00:05:06,500
and lawfully import personal
information from Europe.

99
00:05:06,500 --> 00:05:09,850
However, in comes Max Schrems,

100
00:05:09,850 --> 00:05:11,150
which is a picture of him.

101
00:05:12,770 --> 00:05:17,580
And so the story goes is he
was a in a law school class,

102
00:05:17,580 --> 00:05:22,539
heard someone from a US
tech company talk about

103
00:05:22,540 --> 00:05:25,230
the collection and use of
European personal information,

104
00:05:25,230 --> 00:05:28,460
didn't think that it conformed
to European standards,

105
00:05:28,460 --> 00:05:31,609
and that set him off on
his series of lawsuits

106
00:05:36,060 --> 00:05:40,220
to challenge European
to US data transfers.

107
00:05:40,220 --> 00:05:43,420
And hence the name of the Schrems II sets

108
00:05:43,420 --> 00:05:45,363
or Schrems series of cases.

109
00:05:47,220 --> 00:05:48,270
It goes a little farther back,

110
00:05:48,270 --> 00:05:49,750
because he was the first challenger,

111
00:05:49,750 --> 00:05:53,770
so the invalidation of
Safe Harbor was Schrems I.

112
00:05:53,770 --> 00:05:58,560
Now we're challenging privacy
shield, and he has to go up

113
00:05:58,560 --> 00:06:01,000
to the Irish Data Protection
Commissioner again,

114
00:06:01,000 --> 00:06:03,030
goes back to the Court
of Justice of the EU,

115
00:06:03,030 --> 00:06:04,900
who invalidates Privacy Shield.

116
00:06:04,900 --> 00:06:07,390
That's a lot of legal background,
the whole point of this

117
00:06:07,390 --> 00:06:10,550
is there's lots of moving parts going on,

118
00:06:10,550 --> 00:06:15,270
and it's really this sort
of complex legal environment

119
00:06:15,270 --> 00:06:17,560
that's really leaving a
lot of companies in alert.

120
00:06:17,560 --> 00:06:20,250
So we'll get a little more
practical going forward.

121
00:06:20,250 --> 00:06:22,290
There's Privacy Shield going away.

122
00:06:22,290 --> 00:06:24,910
So what we wanted to do was really focus

123
00:06:24,910 --> 00:06:26,660
on what the court said in Schrems II,

124
00:06:26,660 --> 00:06:28,650
which will help you focus on what

125
00:06:28,650 --> 00:06:30,849
you have to do in response to it.

126
00:06:30,850 --> 00:06:33,700
And what the court said is recall

127
00:06:33,700 --> 00:06:36,930
that we're talking about this
baseline level of protection

128
00:06:36,930 --> 00:06:39,850
that companies who are
handling European data,

129
00:06:39,850 --> 00:06:42,260
or data that subject to the European

130
00:06:42,260 --> 00:06:43,909
General Data Protection Regulation,

131
00:06:43,910 --> 00:06:48,900
or GDPR have to when
transferring information

132
00:06:48,900 --> 00:06:51,039
to a jurisdiction outside of Europe,

133
00:06:51,040 --> 00:06:55,240
have to use a data transfer mechanism.

134
00:06:55,240 --> 00:06:58,070
Currently the primary
means are these standard

135
00:06:58,070 --> 00:07:00,293
contractual clauses, since Privacy Shield,

136
00:07:01,519 --> 00:07:03,730
and safe Harbor are no longer effective.

137
00:07:03,730 --> 00:07:06,870
So what the court said when
striking down Privacy Shield

138
00:07:06,870 --> 00:07:09,490
was that data transfer
mechanisms must afford

139
00:07:09,490 --> 00:07:12,410
essentially equivalent privacy protections

140
00:07:12,410 --> 00:07:15,620
to EU residents taking into account,

141
00:07:15,620 --> 00:07:18,790
whether the transfer is lawful under GDPR,

142
00:07:18,790 --> 00:07:20,980
and the ability for law enforcement

143
00:07:20,980 --> 00:07:23,580
to access data in that third country.

144
00:07:23,580 --> 00:07:28,580
And that is the key piece that
is caused a lot of upheaval

145
00:07:29,020 --> 00:07:31,409
in what companies have
been doing since then.

146
00:07:31,410 --> 00:07:34,140
This decision by the way
came down last summer,

147
00:07:34,140 --> 00:07:35,840
and so there's been this state

148
00:07:35,840 --> 00:07:37,560
of uncertainty with what to do about

149
00:07:37,560 --> 00:07:40,263
Trans-Atlantic Data
Transfers since last summer.

150
00:07:43,230 --> 00:07:45,130
The main conclusion of the court is

151
00:07:45,130 --> 00:07:48,300
that Privacy Shield was
immediately no longer lawful

152
00:07:48,300 --> 00:07:51,790
for EU personal data transfers to the US.

153
00:07:51,790 --> 00:07:54,150
Going on to this piece focusing

154
00:07:54,150 --> 00:07:56,810
on US law enforcement access to data.

155
00:07:56,810 --> 00:08:01,530
The court concluded that US surveillance,

156
00:08:01,530 --> 00:08:03,770
particularly national
security surveillance

157
00:08:03,770 --> 00:08:05,659
did not limit data collection to

158
00:08:05,660 --> 00:08:08,250
that which is strictly necessary.

159
00:08:08,250 --> 00:08:11,050
And in particular surveillance

160
00:08:11,050 --> 00:08:13,390
under the Foreign
Intelligence Surveillance Act

161
00:08:13,390 --> 00:08:17,700
section 702, as well as
surveillance occurring

162
00:08:17,700 --> 00:08:19,883
under executive order 12333,

163
00:08:21,370 --> 00:08:23,500
which is an order that
gives the US government

164
00:08:23,500 --> 00:08:27,010
certain authorities to
surveil communications,

165
00:08:27,010 --> 00:08:31,270
or other networks outside
of the United States.

166
00:08:31,270 --> 00:08:33,990
And then separately, the court concluded

167
00:08:33,990 --> 00:08:36,929
that EU data subjects don't
have actionable redress

168
00:08:36,929 --> 00:08:41,929
before US courts, particularly
in these national security

169
00:08:42,347 --> 00:08:44,880
and foreign intelligence cases.

170
00:08:44,880 --> 00:08:48,850
Now, this was a pretty severe implication,

171
00:08:48,850 --> 00:08:52,160
because we're not easily changing US

172
00:08:52,160 --> 00:08:54,363
National Security Surveillance Laws.

173
00:08:56,980 --> 00:08:58,660
And the other really key piece

174
00:08:58,660 --> 00:09:00,520
of this is this is a decision by

175
00:09:00,520 --> 00:09:03,010
the Court of Justice of
the EU, the highest court

176
00:09:03,010 --> 00:09:05,960
in interpreting European
constitutional law.

177
00:09:05,960 --> 00:09:08,760
So at the end of the day, if this is what

178
00:09:08,760 --> 00:09:11,970
the European charter
its constitution says,

179
00:09:11,970 --> 00:09:15,010
it's gonna be very difficult
to craft a solution that try

180
00:09:15,010 --> 00:09:18,423
and go, accommodates,
or meets that standard.

181
00:09:19,560 --> 00:09:23,010
The real sort of key piece to take away

182
00:09:23,010 --> 00:09:25,880
for what companies should
do next from this opinion,

183
00:09:25,880 --> 00:09:29,000
is what it said about the
Standard Contractual Clauses,

184
00:09:29,000 --> 00:09:31,220
again which are these model contracts,

185
00:09:31,220 --> 00:09:33,220
that a number of companies entered into,

186
00:09:35,287 --> 00:09:38,040
to approximate Privacy Shield,

187
00:09:38,040 --> 00:09:40,230
or for transfers to jurisdictions outside

188
00:09:40,230 --> 00:09:44,100
of the United States to meet
the European privacy standard.

189
00:09:44,100 --> 00:09:47,120
The court said that they
continue to be lawful,

190
00:09:47,120 --> 00:09:51,760
but only if the data export
or which is the company

191
00:09:51,760 --> 00:09:55,590
that is transferring
GDPR personal information

192
00:09:55,590 --> 00:09:59,440
to a country outside of
Europe undertakes a case

193
00:09:59,440 --> 00:10:02,980
by case assessment that the
standard contractual clauses

194
00:10:02,980 --> 00:10:05,550
can be complied within
the receiving country,

195
00:10:05,550 --> 00:10:09,290
such that privacy rights
are equivalent to the EU.

196
00:10:09,290 --> 00:10:11,880
So again, that means evaluating

197
00:10:11,880 --> 00:10:14,750
national security
surveillance in all countries

198
00:10:14,750 --> 00:10:16,240
that are receiving data,

199
00:10:16,240 --> 00:10:18,220
and then separately taking into account,

200
00:10:18,220 --> 00:10:19,960
and this is the saving grace

201
00:10:19,960 --> 00:10:21,650
which we're gonna talk about a bit,

202
00:10:21,650 --> 00:10:23,110
or at least so far the saving grace,

203
00:10:23,110 --> 00:10:25,980
taking into account supplementary measures

204
00:10:25,980 --> 00:10:28,080
that can help meet this privacy standard.

205
00:10:28,080 --> 00:10:30,103
And we'll talk about that in a little bit.

206
00:10:32,380 --> 00:10:37,380
So the sort of the takeaways for this,

207
00:10:38,220 --> 00:10:41,160
that we took away from this opinion,

208
00:10:41,160 --> 00:10:43,569
the bottom lines are that
standard contractual clauses

209
00:10:43,570 --> 00:10:46,180
for the time being continued to be lawful

210
00:10:46,180 --> 00:10:48,609
for EU personal data transfers to the US,

211
00:10:48,610 --> 00:10:50,980
and other countries that weren't deemed

212
00:10:50,980 --> 00:10:54,950
to have adequate privacy
protections by the EU.

213
00:10:54,950 --> 00:10:59,770
But you have to do these
individualized country assessments,

214
00:10:59,770 --> 00:11:02,290
to determine whether your data transfers

215
00:11:03,820 --> 00:11:06,340
provided essentially
equivalent privacy protection.

216
00:11:06,340 --> 00:11:10,040
So basically, you had
to do this assessment

217
00:11:10,040 --> 00:11:14,370
of receiving country law enforcement

218
00:11:14,370 --> 00:11:17,280
national security surveillance laws,

219
00:11:17,280 --> 00:11:20,709
to determine whether they unduly

220
00:11:20,710 --> 00:11:23,320
infringed on European rights.

221
00:11:23,320 --> 00:11:27,410
And so the permissibility of
this transferred personal data

222
00:11:27,410 --> 00:11:29,930
on the basis of standard
contractual clauses will depend

223
00:11:29,930 --> 00:11:32,050
on the results of your assessment.

224
00:11:32,050 --> 00:11:35,349
And it's really a fact-based assessment,

225
00:11:35,350 --> 00:11:37,400
and they didn't give a ton
of guidance right away.

226
00:11:37,400 --> 00:11:41,180
So, it's something where
companies were left

227
00:11:41,180 --> 00:11:43,229
to their devices, at least initially,

228
00:11:43,230 --> 00:11:45,840
to look at their technical administrative

229
00:11:45,840 --> 00:11:49,750
and contractual measures that
applied to how they handled,

230
00:11:49,750 --> 00:11:52,350
and disclosed European
personal information

231
00:11:52,350 --> 00:11:55,380
to government authorities to perhaps make

232
00:11:55,380 --> 00:11:57,730
this argument that,
yes, we can still comply

233
00:11:57,730 --> 00:12:00,700
with the requirements of European law.

234
00:12:00,700 --> 00:12:04,210
And just one quote to throw up there,

235
00:12:04,210 --> 00:12:05,110
this is actually a quote

236
00:12:05,110 --> 00:12:07,210
from the European data protection board,

237
00:12:07,210 --> 00:12:10,010
which is a group comprised primarily

238
00:12:10,010 --> 00:12:14,270
of the head privacy regulators in Europe,

239
00:12:14,270 --> 00:12:17,300
that issued an opinion interpreting

240
00:12:17,300 --> 00:12:19,099
the court's decision right afterwards.

241
00:12:19,100 --> 00:12:21,330
And I won't read the whole thing

242
00:12:21,330 --> 00:12:23,080
but this really drives home at the end,

243
00:12:23,080 --> 00:12:25,880
if you take a look to say you have

244
00:12:25,880 --> 00:12:28,240
to do this case by case assessment,

245
00:12:28,240 --> 00:12:31,070
you have to put in place
the supplementary measures

246
00:12:31,070 --> 00:12:32,620
to the standard contractual clauses.

247
00:12:32,620 --> 00:12:33,640
You can't just rely on

248
00:12:33,640 --> 00:12:35,870
the standard contractual clauses anymore.

249
00:12:35,870 --> 00:12:39,990
If your assessment of the
receiving law indicates

250
00:12:39,990 --> 00:12:44,570
that the law is not sufficient
from a European perspective,

251
00:12:44,570 --> 00:12:47,530
and newsflash the US law was not

252
00:12:47,530 --> 00:12:50,589
considered sufficient by the court itself.

253
00:12:50,590 --> 00:12:54,470
So, which means that
everyone evaluating transfers

254
00:12:54,470 --> 00:12:56,060
are trying to continue to do business,

255
00:12:56,060 --> 00:12:58,949
to transfer data to the US pretty much,

256
00:12:58,950 --> 00:13:00,640
most companies were operating under

257
00:13:00,640 --> 00:13:02,590
these standard contractual clauses,

258
00:13:02,590 --> 00:13:04,840
and you had to do this
case by case assessment

259
00:13:04,840 --> 00:13:09,050
to take into account the
circumstances of the transfers,

260
00:13:09,050 --> 00:13:11,209
and possible supplementary measures.

261
00:13:11,210 --> 00:13:12,340
And you can see at the end,

262
00:13:12,340 --> 00:13:14,440
if you didn't conclude that you had

263
00:13:14,440 --> 00:13:18,610
a sufficient supplementary
protections in place,

264
00:13:18,610 --> 00:13:21,920
you had to suspend or end the
transfers of personal data.

265
00:13:21,920 --> 00:13:25,469
And that takes us to where we are today,

266
00:13:25,470 --> 00:13:30,080
where there's a obligation or
responsibility of companies

267
00:13:30,080 --> 00:13:32,220
that if you don't think
you can meet the standard,

268
00:13:32,220 --> 00:13:34,310
you can no longer engage
in these transfers,

269
00:13:34,310 --> 00:13:37,963
which has led to a lot of
confusion in the market.

270
00:13:39,470 --> 00:13:42,100
So we'll turn it over at this point.

271
00:13:42,100 --> 00:13:43,350
- Thank you so much Bret,

272
00:13:45,934 --> 00:13:47,780
you did a wonderful job with the summary

273
00:13:47,780 --> 00:13:52,053
of this very, very complicated
and complex matter.

274
00:13:52,940 --> 00:13:55,280
And at this point of the presentation,

275
00:13:55,280 --> 00:13:59,540
we want to highlight why
is this relevant to you?

276
00:13:59,540 --> 00:14:02,550
Why is this relevant to
literally all businesses

277
00:14:02,550 --> 00:14:05,540
that actually do business in Europe,

278
00:14:05,540 --> 00:14:08,370
transfer data of personal data

279
00:14:08,370 --> 00:14:11,550
of individuals from Europe to the US?

280
00:14:11,550 --> 00:14:14,449
Well, earlier this year,
the Future of Privacy Forum,

281
00:14:14,450 --> 00:14:17,120
published an infographic
that actually shows

282
00:14:17,120 --> 00:14:22,120
the complexity of even
the most mundane operation

283
00:14:23,710 --> 00:14:27,200
of a day-to-day life of a modern person.

284
00:14:27,200 --> 00:14:30,530
So we actually looked at two scenarios,

285
00:14:30,530 --> 00:14:33,860
one of them being the
retail data ecosystem,

286
00:14:33,860 --> 00:14:37,620
and we took the example
of an online purchase.

287
00:14:37,620 --> 00:14:42,530
So just purchasing something
from an online shop.

288
00:14:42,530 --> 00:14:47,530
And then we also look at
a scenario very much used

289
00:14:48,940 --> 00:14:52,250
particularly in the past year
and a half, online learning.

290
00:14:52,250 --> 00:14:54,740
I'm not going to talk
about the second one.

291
00:14:54,740 --> 00:14:55,987
You can find it in the infographic

292
00:14:55,987 --> 00:14:58,670
and the I'll be happy to
share a link in the chat,

293
00:14:58,670 --> 00:15:02,935
but when we're looking at
the retail data ecosystem,

294
00:15:02,935 --> 00:15:07,935
the amount of data flows,
is just staggering,

295
00:15:08,540 --> 00:15:10,480
because you have to take into account,

296
00:15:10,480 --> 00:15:13,790
we are not only talking
about the simple act

297
00:15:13,790 --> 00:15:18,230
of purchasing and sharing
your contact information.

298
00:15:18,230 --> 00:15:22,750
But also we are talking
about an individual making

299
00:15:22,750 --> 00:15:25,360
that purchase with a credit card,

300
00:15:25,360 --> 00:15:28,830
this particular merchant,
then we need to take

301
00:15:28,830 --> 00:15:31,070
into account authentication checking

302
00:15:31,070 --> 00:15:33,320
before the payment is authorized,

303
00:15:33,320 --> 00:15:36,700
whereby the card issuer has a role,

304
00:15:36,700 --> 00:15:38,520
because they need to authenticate

305
00:15:38,520 --> 00:15:42,449
that the card belongs to the person

306
00:15:42,450 --> 00:15:44,850
that actually makes the purchase.

307
00:15:44,850 --> 00:15:47,880
Then we also have one
authorization processing

308
00:15:47,880 --> 00:15:52,880
going on for that transaction
from the card holders bank,

309
00:15:53,360 --> 00:15:56,015
that needs to play a role in this too,

310
00:15:56,015 --> 00:15:59,523
and that also it requires personal data.

311
00:16:00,590 --> 00:16:05,570
We have the facilitating of
the routing of the payment,

312
00:16:05,570 --> 00:16:09,070
and all the actors involved there,

313
00:16:09,070 --> 00:16:11,590
there's also global fraud detection.

314
00:16:11,590 --> 00:16:15,120
And then think about all
these actors possibly

315
00:16:15,120 --> 00:16:18,140
being situated in different jurisdictions,

316
00:16:18,140 --> 00:16:21,319
and all of this data needing to flow

317
00:16:21,320 --> 00:16:26,320
between jurisdictions
for a very simple act,

318
00:16:27,310 --> 00:16:31,160
a very simple transaction if
you get to think about it.

319
00:16:31,160 --> 00:16:35,600
So the fact of the
international data transfers

320
00:16:35,600 --> 00:16:40,250
actually touches upon most
of the current economic,

321
00:16:40,250 --> 00:16:43,570
and other types of interactions online,

322
00:16:43,570 --> 00:16:46,610
or that rely on cloud-based services.

323
00:16:46,610 --> 00:16:48,610
If you can go to the next slide, please.

324
00:16:51,860 --> 00:16:55,500
One point that I would
like to be very clear about

325
00:16:55,500 --> 00:16:59,330
is that the European data
protection authorities

326
00:16:59,330 --> 00:17:04,170
consider access, simple
access to personal data

327
00:17:04,170 --> 00:17:09,170
of European data subjects in
a cloud as a form of transfer.

328
00:17:09,280 --> 00:17:13,760
This means that even if
all of your operations

329
00:17:13,760 --> 00:17:17,300
and staff are actually located in the US,

330
00:17:17,300 --> 00:17:20,480
if you access data of individuals

331
00:17:20,480 --> 00:17:23,319
that are located in European Union,

332
00:17:23,319 --> 00:17:25,240
that is going to be considered,

333
00:17:25,240 --> 00:17:29,300
from a legal point of view
a transfer of personal data.

334
00:17:29,300 --> 00:17:32,570
So this is why this entire debate

335
00:17:32,570 --> 00:17:36,030
has such wide ranging implications.

336
00:17:36,030 --> 00:17:38,170
And then to give you other examples

337
00:17:38,170 --> 00:17:42,790
from the day-to-day life that are impacted

338
00:17:42,790 --> 00:17:46,770
by this requirements
and by this new reality

339
00:17:46,770 --> 00:17:48,500
of international data transfers,

340
00:17:48,500 --> 00:17:51,250
think of the global collaboration

341
00:17:51,250 --> 00:17:53,740
to combat the COVID-19 pandemic.

342
00:17:53,740 --> 00:17:57,800
When those large scale
clinical trials were set up

343
00:17:59,306 --> 00:18:02,470
the actually collaborations
from many countries,

344
00:18:02,470 --> 00:18:05,740
there was a real question
and an assessment needed

345
00:18:05,740 --> 00:18:10,200
to be done on what are the
lawful grounds that permit

346
00:18:10,200 --> 00:18:13,150
the data of patients in
Europe to be transferred

347
00:18:13,150 --> 00:18:17,423
to those conducted clinical
trials, perhaps based in the US.

348
00:18:18,477 --> 00:18:21,420
There is also the example of
customer service operations,

349
00:18:21,420 --> 00:18:23,600
that I'm sure is very familiar

350
00:18:23,600 --> 00:18:26,810
to many of you listening to us right now.

351
00:18:26,810 --> 00:18:30,450
And we know that such
customer support systems

352
00:18:30,450 --> 00:18:33,890
are implemented by many organizations.

353
00:18:33,890 --> 00:18:37,300
And we also know that
they actually need access

354
00:18:37,300 --> 00:18:39,570
to data from the cloud.

355
00:18:39,570 --> 00:18:43,040
And as I was saying, the mere access,

356
00:18:43,040 --> 00:18:46,770
actually counts as an
international data transfers,

357
00:18:46,770 --> 00:18:47,603
Alexandra.

358
00:18:50,210 --> 00:18:52,633
- The next slide, I think, yes,

359
00:18:53,550 --> 00:18:55,740
so we've talked a little bit about

360
00:18:55,740 --> 00:18:57,640
the legal background for this,

361
00:18:57,640 --> 00:19:00,230
and why it matters to global companies.

362
00:19:00,230 --> 00:19:02,233
So just to touch on a couple of things,

363
00:19:03,150 --> 00:19:06,160
when companies are setting
up their infrastructure

364
00:19:06,160 --> 00:19:09,140
and we're trying to do this
in the most efficient way,

365
00:19:09,140 --> 00:19:11,610
we look at global sourcing.

366
00:19:11,610 --> 00:19:14,909
So we're looking at how we
can as Gabriela mentioned,

367
00:19:14,910 --> 00:19:16,650
set up customer service centers

368
00:19:16,650 --> 00:19:19,650
that might support the entire enterprise.

369
00:19:19,650 --> 00:19:21,070
So if you have a global company

370
00:19:21,070 --> 00:19:23,679
with customers and employees worldwide,

371
00:19:23,680 --> 00:19:26,500
we likely have customer service hubs

372
00:19:26,500 --> 00:19:29,380
in certain jurisdictions
that provide services

373
00:19:29,380 --> 00:19:30,660
to all of your customers.

374
00:19:30,660 --> 00:19:34,230
You don't have a customer
service center in every country

375
00:19:34,230 --> 00:19:36,280
or jurisdiction where
you upgrade that just

376
00:19:36,280 --> 00:19:39,639
would be costly and inefficient.

377
00:19:39,640 --> 00:19:43,810
So when we think about kind
of the backdrop of this

378
00:19:43,810 --> 00:19:46,190
from a practical perspective for companies

379
00:19:46,190 --> 00:19:50,019
that are trying to follow the cases,

380
00:19:50,019 --> 00:19:53,480
and follow the political
wrangling that's happening

381
00:19:53,480 --> 00:19:56,630
with the potential
re-negotiation of Privacy Shield,

382
00:19:56,630 --> 00:19:59,250
we're looking at ways that we can operate

383
00:19:59,250 --> 00:20:00,800
on a day-to-day basis.

384
00:20:00,800 --> 00:20:02,610
And one of the things that I'm sure

385
00:20:02,610 --> 00:20:07,290
some of you on the on the
call will resonate with

386
00:20:07,290 --> 00:20:09,560
is these myths and misconceptions

387
00:20:09,560 --> 00:20:12,310
of how onward data transfers work,

388
00:20:12,310 --> 00:20:14,659
and what are some potential solutions.

389
00:20:14,660 --> 00:20:17,640
So in the absence of
a political solutions,

390
00:20:17,640 --> 00:20:21,010
in the absence of a Privacy Shield 3.0,

391
00:20:21,010 --> 00:20:24,510
or if your company decides not

392
00:20:24,510 --> 00:20:26,210
to implement supplemental measures,

393
00:20:26,210 --> 00:20:29,150
or not to do those transfer
impact assessments,

394
00:20:29,150 --> 00:20:32,060
or if your customers are not satisfied

395
00:20:32,060 --> 00:20:35,750
with the legal mechanisms
that you are in fact putting

396
00:20:35,750 --> 00:20:38,080
in place, what are some of your options?

397
00:20:38,080 --> 00:20:39,730
So you may be getting questions

398
00:20:39,730 --> 00:20:41,810
from your internal business stakeholders

399
00:20:41,810 --> 00:20:45,280
and sales, or some of
your European colleagues,

400
00:20:45,280 --> 00:20:47,740
asking questions about, well why don't

401
00:20:47,740 --> 00:20:49,770
we just build a data center in Europe,

402
00:20:49,770 --> 00:20:53,639
or why can't we host our
authentication center in Europe?

403
00:20:53,640 --> 00:20:56,540
And the reason that that's difficult is

404
00:20:56,540 --> 00:20:58,820
because of the very broad definition

405
00:20:58,820 --> 00:21:02,570
of processing under the
GDPR, which Gabriela spoke to

406
00:21:02,570 --> 00:21:04,700
in her example and her infographics.

407
00:21:04,700 --> 00:21:08,230
So any type of collection, use,

408
00:21:08,230 --> 00:21:11,010
access storage is processing.

409
00:21:11,010 --> 00:21:13,640
So global companies that are working

410
00:21:13,640 --> 00:21:18,380
with an architecture and a
tech stack that's likely global

411
00:21:18,380 --> 00:21:20,677
and not siloed country by country,

412
00:21:20,677 --> 00:21:24,179
have a very difficult challenge ahead,

413
00:21:24,180 --> 00:21:26,330
if there is no political solution,

414
00:21:26,330 --> 00:21:31,290
and if the legal uncertainties
aren't sorted out.

415
00:21:31,290 --> 00:21:34,000
So building a data center
in Europe, for example

416
00:21:34,970 --> 00:21:37,530
think about what type of data

417
00:21:37,530 --> 00:21:39,990
you would be potentially
hosting in Europe.

418
00:21:39,990 --> 00:21:41,750
Would it just be customer data,

419
00:21:41,750 --> 00:21:45,050
and content, project files for example,

420
00:21:45,050 --> 00:21:48,510
that your customers might be
storing in your SAS solution,

421
00:21:48,510 --> 00:21:50,710
or are you talking
about every single piece

422
00:21:50,710 --> 00:21:54,160
of personal data that must be collected

423
00:21:54,160 --> 00:21:56,890
and stored, processed, and accessed only

424
00:21:56,890 --> 00:21:58,730
in France for example.

425
00:21:58,730 --> 00:22:00,270
If that were to be the case,

426
00:22:00,270 --> 00:22:03,100
a company would likely
have to re-architect

427
00:22:03,100 --> 00:22:06,909
its entire infrastructure,
have dedicated vendors

428
00:22:06,910 --> 00:22:08,440
that only work in France.

429
00:22:08,440 --> 00:22:12,030
Because if you have a customer
service center in Texas,

430
00:22:12,030 --> 00:22:14,129
that customer service
center would not be able

431
00:22:14,130 --> 00:22:17,810
to access the French data
that's hosted in France.

432
00:22:17,810 --> 00:22:20,620
If you're gonna truly
have a dedicated personal

433
00:22:20,620 --> 00:22:24,800
data processing and storage
data center in Europe.

434
00:22:24,800 --> 00:22:26,470
The same thing with authentication,

435
00:22:26,470 --> 00:22:29,250
if you think about security controls,

436
00:22:29,250 --> 00:22:32,800
and how we run most security programs,

437
00:22:32,800 --> 00:22:36,850
there's benefits from seeing
global trends and diagnostics.

438
00:22:36,850 --> 00:22:41,020
And if you're only capturing
security vulnerabilities

439
00:22:41,020 --> 00:22:43,520
in one jurisdiction in which you operate,

440
00:22:43,520 --> 00:22:45,960
you're potentially not
seeing the whole picture

441
00:22:45,960 --> 00:22:47,770
of the threats to your organization.

442
00:22:47,770 --> 00:22:50,700
So that's another myth and misconception

443
00:22:50,700 --> 00:22:52,320
that we're concerned about in terms

444
00:22:52,320 --> 00:22:55,450
of resolving some of the chaos,

445
00:22:55,450 --> 00:22:57,570
and uncertainty that we see currently

446
00:22:57,570 --> 00:23:00,480
with the political and
legal underpinnings,

447
00:23:00,480 --> 00:23:03,163
in the reality of what we're facing today.

448
00:23:04,168 --> 00:23:07,699
I also want to mention one company

449
00:23:07,700 --> 00:23:11,410
that has taken a kind of bold stance.

450
00:23:11,410 --> 00:23:16,050
Microsoft, earlier this
month made a statement

451
00:23:16,050 --> 00:23:20,649
from Brad Smith that
they would be pursuing

452
00:23:21,610 --> 00:23:24,582
a data center option in Europe,

453
00:23:25,486 --> 00:23:29,740
and in their statement
which was geared towards,

454
00:23:29,740 --> 00:23:33,040
in my opinion, kind of a PR customer

455
00:23:33,040 --> 00:23:37,483
demand perspective in terms of seeing

456
00:23:38,540 --> 00:23:40,649
this legal uncertainty
that we see out there,

457
00:23:40,650 --> 00:23:44,860
but also customer sensitivities
that Bret spoke about

458
00:23:44,860 --> 00:23:47,060
in terms of government access to data.

459
00:23:47,060 --> 00:23:51,600
A lot of the tech lash
and mistrust of companies,

460
00:23:51,600 --> 00:23:52,850
they're acknowledging that,

461
00:23:52,850 --> 00:23:56,949
and they've reported that they
will be pursuing solutions

462
00:23:56,950 --> 00:24:01,070
and offerings for their
Azure and 360 products,

463
00:24:01,070 --> 00:24:05,800
their commercial products to
have all data stored in Europe.

464
00:24:05,800 --> 00:24:07,480
Now the devils in the details,

465
00:24:07,480 --> 00:24:08,750
and they said that they'll be working

466
00:24:08,750 --> 00:24:11,300
on this for the next year or two,

467
00:24:11,300 --> 00:24:14,270
to figure out what
exactly is the offering.

468
00:24:14,270 --> 00:24:16,850
And if technically all data is

469
00:24:16,850 --> 00:24:19,939
in fact stored in Europe or
some of it still comes back

470
00:24:19,940 --> 00:24:23,120
to the US for some storage and processing.

471
00:24:23,120 --> 00:24:26,550
But I think this really is
an interesting development,

472
00:24:26,550 --> 00:24:30,159
where we're seeing a
very large company take

473
00:24:30,160 --> 00:24:35,160
this sort of bold move in going beyond

474
00:24:35,180 --> 00:24:37,020
what's legally required,

475
00:24:37,020 --> 00:24:41,230
and attempting to satisfy
customer demand in this area.

476
00:24:41,230 --> 00:24:44,650
It'll be interesting to
see the follow on effect,

477
00:24:44,650 --> 00:24:48,450
if companies like AWS
or other companies start

478
00:24:48,450 --> 00:24:51,040
approaching this in a similar way,

479
00:24:51,040 --> 00:24:55,639
and offering additional types
of local data processing

480
00:24:55,640 --> 00:24:58,950
in Europe beyond what's legally required.

481
00:24:58,950 --> 00:25:01,270
- So Alexandra, we got
a question in the chat

482
00:25:01,270 --> 00:25:04,820
that's on point here that
came in before this slide.

483
00:25:04,820 --> 00:25:08,419
So it was a great question,
it says we deliver services

484
00:25:08,420 --> 00:25:11,790
for other companies from delivery
centers across the globe.

485
00:25:11,790 --> 00:25:14,370
This seems to state that we
have to provide all of this

486
00:25:14,370 --> 00:25:16,770
even for the users in a delivery center.

487
00:25:16,770 --> 00:25:19,200
Is that your interpretation?

488
00:25:19,200 --> 00:25:21,480
- So I think you have to take
a look at your data flows

489
00:25:21,480 --> 00:25:25,170
and figure out sort of is
that a a vendor solution,

490
00:25:25,170 --> 00:25:27,650
or is that part of your entire company?

491
00:25:27,650 --> 00:25:29,870
So I think, yes, you
certainly have to look

492
00:25:29,870 --> 00:25:33,159
at whether that's part of your enterprise,

493
00:25:33,160 --> 00:25:34,660
and whether that would be covered

494
00:25:34,660 --> 00:25:38,430
under transfer as Gabriela worked through

495
00:25:38,430 --> 00:25:42,760
that definition as processing
as you see in the slide here.

496
00:25:42,760 --> 00:25:47,120
So just because it's not
the bulk of your business,

497
00:25:47,120 --> 00:25:49,080
or it's an ancillary service provider,

498
00:25:49,080 --> 00:25:51,949
or ancillary to your
core service offering,

499
00:25:51,950 --> 00:25:55,180
it's something that you need
to take into consideration.

500
00:25:55,180 --> 00:25:56,510
And you could put, if it's a vendor,

501
00:25:56,510 --> 00:25:59,870
you could potentially put
some contractual terms

502
00:25:59,870 --> 00:26:02,223
in place that would
resolve that issue for you.

503
00:26:04,540 --> 00:26:06,889
Should we go to the next slide?

504
00:26:06,890 --> 00:26:09,433
So here, in terms of regulatory risk,

505
00:26:10,830 --> 00:26:15,830
what we're seeing here is
the transfer to information

506
00:26:16,400 --> 00:26:19,070
without the adequate transfer mechanisms.

507
00:26:19,070 --> 00:26:21,332
So this again is a
challenge for companies,

508
00:26:22,290 --> 00:26:24,470
understanding what your data flows are

509
00:26:24,470 --> 00:26:27,140
and where, and how, and to which countries

510
00:26:27,140 --> 00:26:29,300
you're actually transferring data,

511
00:26:29,300 --> 00:26:31,240
so that you can in fact do

512
00:26:31,240 --> 00:26:33,473
those transfer impact assessments.

513
00:26:34,523 --> 00:26:37,330
And what is it that we
need to put in place

514
00:26:37,330 --> 00:26:40,377
in terms of these supplemental measures?

515
00:26:40,377 --> 00:26:43,820
And we're seeing some cases,
I think Gabriela's gonna speak

516
00:26:43,820 --> 00:26:48,820
to where certain regulators
are striking down transfers,

517
00:26:49,000 --> 00:26:50,600
because either the company didn't

518
00:26:50,600 --> 00:26:52,399
have supplementary measures in place,

519
00:26:52,400 --> 00:26:55,633
or those supplementary
measures were found inadequate.

520
00:26:56,510 --> 00:26:58,879
So I think in terms of regulatory risk,

521
00:26:58,880 --> 00:27:03,467
there is either the
threat, the sensitivity

522
00:27:04,730 --> 00:27:08,700
that customers are
raising, the uncertainty

523
00:27:08,700 --> 00:27:11,530
about what types of data transfers

524
00:27:11,530 --> 00:27:14,243
will remain to be permissible.

525
00:27:15,112 --> 00:27:18,330
The court decisions says one thing,

526
00:27:18,330 --> 00:27:20,270
and then what's happening in practice

527
00:27:20,270 --> 00:27:22,129
is sort of another thing.

528
00:27:22,130 --> 00:27:24,360
And then also what types of case law

529
00:27:24,360 --> 00:27:27,030
we see is another data
point that companies need

530
00:27:27,030 --> 00:27:29,980
to take into account as they're evaluating

531
00:27:29,980 --> 00:27:34,900
how we're going to continue
to offer global services,

532
00:27:34,900 --> 00:27:38,600
for those customers that are worldwide.

533
00:27:38,600 --> 00:27:41,310
- If I can add here, indeed Alexandra

534
00:27:41,310 --> 00:27:43,909
on some of the cases
we're seeing in practice.

535
00:27:43,910 --> 00:27:47,170
So what's happening is
that as Bret was mentioning

536
00:27:47,170 --> 00:27:49,860
at the beginning, this judgment,

537
00:27:49,860 --> 00:27:54,860
that annulled the Privacy Shield,
came in July of last year.

538
00:27:55,150 --> 00:28:00,150
Then for many months, we have
not seen regulatory action,

539
00:28:00,330 --> 00:28:02,955
because also data protection authorities,

540
00:28:02,955 --> 00:28:04,199
the European Data Protection Board,

541
00:28:04,200 --> 00:28:08,410
are trying to figure out how
to transpose it in practice,

542
00:28:08,410 --> 00:28:11,900
and what type of guidelines
to give companies.

543
00:28:11,900 --> 00:28:14,520
There's already a set of draft guidelines

544
00:28:14,520 --> 00:28:16,740
out there for which the EDPB,

545
00:28:16,740 --> 00:28:19,210
the European Data Protection
Board received input.

546
00:28:19,210 --> 00:28:22,263
And we're now waiting
to see the last version,

547
00:28:23,160 --> 00:28:25,200
the final version of those guidelines

548
00:28:25,200 --> 00:28:26,883
on supplementary measures.

549
00:28:28,070 --> 00:28:31,040
But what we've seen in recent months,

550
00:28:31,040 --> 00:28:34,330
I would say in the last two months or so

551
00:28:34,330 --> 00:28:36,929
is that data protection
authorities started

552
00:28:36,930 --> 00:28:41,730
to actually implement
the Schrems II decision

553
00:28:41,730 --> 00:28:44,190
and to actually issue decisions,

554
00:28:44,190 --> 00:28:47,300
and take regulatory action
against some companies.

555
00:28:47,300 --> 00:28:51,659
There is one very relevant
case from about two weeks ago

556
00:28:51,660 --> 00:28:54,420
from Portugal where the
Data Protection Authority

557
00:28:54,420 --> 00:28:57,484
of Portugal issued a decision against

558
00:28:57,484 --> 00:29:01,449
the National Institute of Statistics

559
00:29:01,450 --> 00:29:04,000
that was conducting the census

560
00:29:04,000 --> 00:29:05,750
for the Portuguese population,

561
00:29:05,750 --> 00:29:08,070
and was relying on data storage,

562
00:29:08,070 --> 00:29:12,980
and some data processing with the services

563
00:29:12,980 --> 00:29:15,893
provided by CloudFlare based in the US,

564
00:29:16,730 --> 00:29:21,580
and the Portuguese DPA actually ordered

565
00:29:21,580 --> 00:29:25,949
this National Institute to stop using

566
00:29:25,950 --> 00:29:28,260
the services of CloudFlare,

567
00:29:28,260 --> 00:29:33,260
because there were not
sufficient measures in place

568
00:29:33,910 --> 00:29:37,410
to ensure that the data of the
entire Portuguese population

569
00:29:37,410 --> 00:29:40,510
was sufficiently protected
against government access

570
00:29:40,510 --> 00:29:42,610
to data here in the US.

571
00:29:42,610 --> 00:29:45,870
So that was very interesting to see.

572
00:29:45,870 --> 00:29:48,409
There are also a couple of other cases,

573
00:29:48,410 --> 00:29:51,730
one that's very relevant,
that might provide a bit

574
00:29:51,730 --> 00:29:55,100
of hope for companies trying
to continue data flows

575
00:29:55,100 --> 00:30:00,100
is one from France where
a company Dr. Leeb,

576
00:30:01,270 --> 00:30:06,210
was actually brought
into judicial proceedings

577
00:30:06,210 --> 00:30:10,940
by several complainants saying that

578
00:30:11,840 --> 00:30:14,567
it relies on the services of AWS,

579
00:30:15,630 --> 00:30:20,550
and that it stores very
sensitive data with AWS,

580
00:30:20,550 --> 00:30:25,550
because this was about data
on vaccination scheduling

581
00:30:25,810 --> 00:30:30,810
of the French population, COVID
19 vaccination scheduling.

582
00:30:32,870 --> 00:30:37,870
However, the court, at
least in first instance said

583
00:30:37,890 --> 00:30:41,260
that the safeguards put in place by AWS

584
00:30:41,260 --> 00:30:43,860
on top of the standard
contractual clauses,

585
00:30:43,860 --> 00:30:47,350
the technical safeguards
were actually sufficient

586
00:30:47,350 --> 00:30:51,770
to ensure that the transfer to the US,

587
00:30:51,770 --> 00:30:55,810
if a transfer occurred was actually lawful

588
00:30:55,810 --> 00:30:58,149
under the Schrems II criteria.

589
00:30:58,150 --> 00:31:00,490
Bret for the next slide, please.

590
00:31:00,490 --> 00:31:03,040
- Sure. I mean the interesting thing here

591
00:31:03,040 --> 00:31:06,450
is you're hearing names that
are very familiar to you,

592
00:31:06,450 --> 00:31:10,200
AWS, CloudFlare, Microsoft,

593
00:31:10,200 --> 00:31:14,660
this is not just transfers
to your affiliates

594
00:31:14,660 --> 00:31:17,160
or smaller vendors, this is every

595
00:31:17,160 --> 00:31:19,543
cloud infrastructure that you use.

596
00:31:20,993 --> 00:31:22,350
And some of the big players are thinking

597
00:31:22,350 --> 00:31:25,219
about this a bit more, but that's just one

598
00:31:25,220 --> 00:31:26,840
of the reasons why there are

599
00:31:26,840 --> 00:31:30,903
so many implications from this ruling.

600
00:31:32,120 --> 00:31:35,949
You can see on the slide
here in terms of the stakes,

601
00:31:35,950 --> 00:31:40,310
we're talking about the full
potential scope of GDPR fines,

602
00:31:40,310 --> 00:31:44,673
which is 20 million euros or
4% of worldwide annual revenue.

603
00:31:45,610 --> 00:31:47,860
We're ordering the
suspension of data transfers,

604
00:31:47,860 --> 00:31:52,860
which is what was bandied
about in the Portuguese case.

605
00:31:53,930 --> 00:31:58,910
So this is real impact, maybe there are

606
00:31:58,910 --> 00:32:03,330
some helpfulness that
everyone's in a similar boat

607
00:32:03,330 --> 00:32:05,629
at this point, but someone
has to be the first one

608
00:32:05,630 --> 00:32:07,143
off the boat, I suppose.

609
00:32:08,060 --> 00:32:10,750
And so there's a lot
of hand-wringing about

610
00:32:10,750 --> 00:32:13,013
hopefully it's not your company first,

611
00:32:13,853 --> 00:32:15,960
and hopefully we come to
a solution before that,

612
00:32:15,960 --> 00:32:17,590
but maybe some light at
the end of the tunnel

613
00:32:17,590 --> 00:32:18,463
as we'll get to.

614
00:32:20,690 --> 00:32:24,520
And just as a signal to some
of the regulatory risks,

615
00:32:24,520 --> 00:32:27,680
before some of these cases
that Gabriela mentioned,

616
00:32:27,680 --> 00:32:29,900
here's a quote from the Berlin DPA.

617
00:32:29,900 --> 00:32:32,581
So in Germany, each of the German states

618
00:32:32,581 --> 00:32:35,913
has their own DPA, Data
Protection Authority,

619
00:32:36,784 --> 00:32:38,410
(laughs) very foreboding,

620
00:32:38,410 --> 00:32:40,760
right after the Schrems case came down,

621
00:32:40,760 --> 00:32:42,629
the times when personal
data could be transferred

622
00:32:42,630 --> 00:32:44,920
to the USA for convenience or cost savings

623
00:32:44,920 --> 00:32:46,900
are over after this verdict.

624
00:32:46,900 --> 00:32:49,660
It is now the hour of
Europe's digital independence.

625
00:32:49,660 --> 00:32:52,360
And you might be reading
into that some sort

626
00:32:52,360 --> 00:32:57,360
of local protectionism or
support of local industry.

627
00:32:58,350 --> 00:33:01,810
And I would posit that
that's probably a factor

628
00:33:01,810 --> 00:33:03,040
in some of this as well,

629
00:33:03,040 --> 00:33:05,770
even though it's obviously
not part of the legal case.

630
00:33:05,770 --> 00:33:07,570
There are certainly some
of those who are seizing

631
00:33:07,570 --> 00:33:10,050
on this as a benefit for local industry.

632
00:33:10,050 --> 00:33:13,750
And so you have not only legal factors,

633
00:33:13,750 --> 00:33:18,403
but political and economic
factors in the squirrel as well.

634
00:33:20,710 --> 00:33:23,750
One other thing that I wanted to mention

635
00:33:23,750 --> 00:33:25,310
is business partner requests.

636
00:33:25,310 --> 00:33:27,760
Some of you may have
been dealing with these.

637
00:33:27,760 --> 00:33:30,900
So after this decision if you recall,

638
00:33:30,900 --> 00:33:32,800
this decision requires you to undertake

639
00:33:32,800 --> 00:33:34,620
a case by case assessment of all of

640
00:33:34,620 --> 00:33:38,120
your data transfers outside to to vendors

641
00:33:38,120 --> 00:33:41,120
who are located or to third
parties who are not located

642
00:33:41,120 --> 00:33:44,100
in Europe or another
adequate jurisdiction.

643
00:33:44,100 --> 00:33:46,230
And so what this means is you actually

644
00:33:46,230 --> 00:33:47,623
have to do an assessment.

645
00:33:48,890 --> 00:33:52,900
And in order to comply with this standard

646
00:33:52,900 --> 00:33:56,920
in the court opinion,
which was far from clear,

647
00:33:56,920 --> 00:33:58,550
you had a wide variety of approaches.

648
00:33:58,550 --> 00:33:59,879
So many of you may have dealt with

649
00:33:59,880 --> 00:34:04,040
this getting questionnaires or requests

650
00:34:04,040 --> 00:34:07,049
from your customers,
your service providers,

651
00:34:07,049 --> 00:34:08,810
even affiliates asking how

652
00:34:08,810 --> 00:34:10,770
you're handling personal information,

653
00:34:10,770 --> 00:34:13,780
and what laws you're
handling a personal data

654
00:34:13,780 --> 00:34:17,940
are subject to which in complex countries

655
00:34:17,940 --> 00:34:19,520
like the United States, there's many many

656
00:34:19,520 --> 00:34:21,790
potential laws that you
might be subject to,

657
00:34:21,790 --> 00:34:23,750
or you might be compelled
to turn information

658
00:34:23,750 --> 00:34:26,482
over to the the United States government,

659
00:34:26,482 --> 00:34:30,509
and what due process protections

660
00:34:30,510 --> 00:34:33,190
are in place and are those
essentially equivalent,

661
00:34:33,190 --> 00:34:34,453
if you go back to the standard

662
00:34:34,453 --> 00:34:37,940
that we talked about before
to protections in Europe.

663
00:34:37,940 --> 00:34:41,260
And that's not a trivial exercise,

664
00:34:41,260 --> 00:34:43,389
but this is what's been happening

665
00:34:43,389 --> 00:34:45,250
over the course of the past year.

666
00:34:45,250 --> 00:34:48,408
And what we've been
advising clients is look,

667
00:34:48,408 --> 00:34:50,730
your obligation under this opinion

668
00:34:50,730 --> 00:34:53,960
is to do this assessment,
we don't know the form.

669
00:34:53,960 --> 00:34:56,730
The court did not specify the exact form

670
00:34:56,730 --> 00:34:58,460
of assessment that needs to be done,

671
00:34:58,460 --> 00:34:59,970
but if you don't do this assessment

672
00:34:59,970 --> 00:35:02,270
then you're clearly in
violation of the standard.

673
00:35:02,270 --> 00:35:04,130
So you need to do an assessment.

674
00:35:04,130 --> 00:35:06,500
Here's our thoughts on how
this assessment should go,

675
00:35:06,500 --> 00:35:09,640
but you should at least ask
some questions (chuckles).

676
00:35:09,640 --> 00:35:10,990
Obviously it goes a little more

677
00:35:10,990 --> 00:35:13,200
of it goes into it than that.

678
00:35:13,200 --> 00:35:15,970
But as a result, you've got
a lot of questionnaires,

679
00:35:15,970 --> 00:35:18,220
and a lot of requests
for how are you handling

680
00:35:18,220 --> 00:35:20,759
information that is subject to the GDPR.

681
00:35:20,760 --> 00:35:25,500
And I have seen it has
included delayed deals

682
00:35:25,500 --> 00:35:26,450
and lost business.

683
00:35:26,450 --> 00:35:28,960
And I'm sure some of
you have seen this too,

684
00:35:28,960 --> 00:35:32,440
where privacy questions are the ones

685
00:35:32,440 --> 00:35:34,260
that keep the negotiation going,

686
00:35:34,260 --> 00:35:37,547
or are the ones where someone might say,

687
00:35:37,547 --> 00:35:39,027
"I'm gonna go with this European vendor

688
00:35:39,027 --> 00:35:42,190
"instead of you American based company."

689
00:35:42,190 --> 00:35:45,510
And so there's real world impacts to this.

690
00:35:45,510 --> 00:35:49,110
So you get these diligence requests.

691
00:35:49,110 --> 00:35:51,060
And as an example we have here,

692
00:35:51,060 --> 00:35:54,320
so Max Schrems in addition to in bringing

693
00:35:54,320 --> 00:35:55,720
these court cases has set up

694
00:35:56,833 --> 00:35:59,830
a non-governmental organization where

695
00:35:59,830 --> 00:36:04,830
he has created among other
things, a model request

696
00:36:05,080 --> 00:36:07,960
to send to your service providers,

697
00:36:07,960 --> 00:36:10,620
and other third parties to assess

698
00:36:10,620 --> 00:36:12,009
their compliance with the opinion,

699
00:36:12,010 --> 00:36:13,640
and it's quite strict.

700
00:36:13,640 --> 00:36:16,960
And so we have seen this one gets sent

701
00:36:16,960 --> 00:36:19,017
around by a number of businesses who said,

702
00:36:19,017 --> 00:36:20,997
"Hey, great, this was already written

703
00:36:20,997 --> 00:36:22,730
"and this is how I do my assessment,"

704
00:36:22,730 --> 00:36:23,980
and they've sent it out.

705
00:36:23,980 --> 00:36:26,360
And it's quite difficult to answer

706
00:36:26,360 --> 00:36:28,820
those questions in that assessment.

707
00:36:28,820 --> 00:36:30,560
So that's just one example of it.

708
00:36:30,560 --> 00:36:31,870
And you may have seen this it comes

709
00:36:31,870 --> 00:36:34,799
from his NGO called NOYB,

710
00:36:34,800 --> 00:36:36,850
which is short for None Of Your Business.

711
00:36:37,970 --> 00:36:41,178
So, at the end of the day,

712
00:36:41,178 --> 00:36:43,790
these requests can be difficult to answer,

713
00:36:43,790 --> 00:36:46,330
and you have to do some
sort of assessment.

714
00:36:46,330 --> 00:36:48,460
Let's say you're a US-based company,

715
00:36:48,460 --> 00:36:50,590
you're asked about what is the ability

716
00:36:50,590 --> 00:36:53,543
of the US government to
access your information?

717
00:36:56,840 --> 00:36:59,030
Are you subject to a potential order

718
00:36:59,030 --> 00:37:02,940
under the Foreign Intelligence
Surveillance Act section 702,

719
00:37:02,940 --> 00:37:07,060
which requires a
non-trivial legal analysis

720
00:37:07,060 --> 00:37:08,390
actually determined whether

721
00:37:08,390 --> 00:37:11,343
you're a covered electronic
communication service provider.

722
00:37:12,370 --> 00:37:15,190
And these are adding
costs to doing business

723
00:37:15,190 --> 00:37:17,170
in the proposed Schrems age.

724
00:37:17,170 --> 00:37:19,480
- Bret, can I add just a couple kind of--

725
00:37:19,480 --> 00:37:20,888
- Please.

726
00:37:20,888 --> 00:37:23,410
- Practical considerations for companies

727
00:37:23,410 --> 00:37:24,779
that are dealing with this

728
00:37:24,780 --> 00:37:27,107
'cause that's part of my job (laughs).

729
00:37:28,130 --> 00:37:31,440
So the standard questionnaires that

730
00:37:31,440 --> 00:37:34,540
we're starting to see so
yes, they are challenging

731
00:37:34,540 --> 00:37:36,300
to answer and find the content,

732
00:37:36,300 --> 00:37:39,100
but I think it's also just
think about the administration

733
00:37:39,100 --> 00:37:40,900
and sort of the internal communication,

734
00:37:40,900 --> 00:37:45,090
and the process by which your
responding to these requests.

735
00:37:45,090 --> 00:37:48,150
So if you have a
dedicated privacy program,

736
00:37:48,150 --> 00:37:50,020
a legal team that's working on these,

737
00:37:50,020 --> 00:37:52,370
make sure you have consistent responses,

738
00:37:52,370 --> 00:37:54,870
and you have a process for intake,

739
00:37:54,870 --> 00:37:57,240
and review of these and responding

740
00:37:57,240 --> 00:37:58,990
within the adequate time period,

741
00:37:58,990 --> 00:38:02,819
and so forth so that you're not causing

742
00:38:02,820 --> 00:38:06,600
more legal problems for
yourself potentially,

743
00:38:06,600 --> 00:38:09,180
or for your sales organization

744
00:38:09,180 --> 00:38:12,370
by not responding adequately
or in a timely fashion,

745
00:38:12,370 --> 00:38:16,799
or by having confusion or
inconsistent statement.

746
00:38:16,800 --> 00:38:21,450
So have a plan, have a
standard set of responses

747
00:38:21,450 --> 00:38:25,339
and an intake process
by which you can manage

748
00:38:25,340 --> 00:38:26,690
these requests that are coming in.

749
00:38:26,690 --> 00:38:29,590
- Well that's a good segue
into practical ways forward.

750
00:38:29,590 --> 00:38:31,360
So why don't you continue?

751
00:38:31,360 --> 00:38:35,010
- Sure. Yeah, so a couple
of other things just,

752
00:38:35,010 --> 00:38:37,713
from the in-house
perspective that I can bring.

753
00:38:39,029 --> 00:38:42,430
And a lot of this is
basic (chuckles) blocking,

754
00:38:42,430 --> 00:38:44,509
and tackling that we all need to do

755
00:38:44,510 --> 00:38:46,360
for development of a privacy program,

756
00:38:46,360 --> 00:38:47,910
and it definitely comes into play

757
00:38:47,910 --> 00:38:51,180
with ordering data transfer
and data localization issues.

758
00:38:51,180 --> 00:38:56,180
So understanding your data transfer,

759
00:38:56,380 --> 00:38:59,340
so, what are your data flows like

760
00:38:59,340 --> 00:39:02,270
to which countries are
you transferring data?

761
00:39:02,270 --> 00:39:04,860
What vendors are you using, understanding

762
00:39:04,860 --> 00:39:08,580
sort of how you're
operating as a business,

763
00:39:08,580 --> 00:39:10,890
so that you can make some decisions about

764
00:39:10,890 --> 00:39:12,580
where you're going to conduct

765
00:39:12,580 --> 00:39:14,237
those transfer impact assessments,

766
00:39:14,237 --> 00:39:16,420
are you going to do it on all countries?

767
00:39:16,420 --> 00:39:19,270
Are you going to try to
prioritize high risk countries

768
00:39:19,270 --> 00:39:22,580
where you have more of a presence?

769
00:39:22,580 --> 00:39:26,040
Those are all things that
you can take into account.

770
00:39:26,040 --> 00:39:27,680
What are these additional safeguards

771
00:39:27,680 --> 00:39:28,899
that you can put in place?

772
00:39:28,900 --> 00:39:32,960
So the court decision
has some information,

773
00:39:32,960 --> 00:39:35,970
I've actually found benchmarking
to be much more useful.

774
00:39:35,970 --> 00:39:40,330
So looking at what companies
have publicly acknowledged,

775
00:39:40,330 --> 00:39:42,779
or posted in their data
processing agreement,

776
00:39:42,780 --> 00:39:45,250
or other privacy materials that

777
00:39:45,250 --> 00:39:47,760
are their supplementary measures,

778
00:39:47,760 --> 00:39:50,130
and making some considerations

779
00:39:50,130 --> 00:39:53,030
about what works for you,
what level of encryption,

780
00:39:53,030 --> 00:39:55,120
what level of security standards,

781
00:39:55,120 --> 00:39:57,560
whether you have a transparency report,

782
00:39:57,560 --> 00:40:01,330
whether you have a
policy of how you respond

783
00:40:01,330 --> 00:40:03,427
to government access requests for data,

784
00:40:03,427 --> 00:40:07,050
and how aggressively you might resist

785
00:40:07,050 --> 00:40:09,950
or fight those, or how you deal with

786
00:40:09,950 --> 00:40:10,960
those when they come in.

787
00:40:10,960 --> 00:40:14,560
So taking into account
what other companies

788
00:40:14,560 --> 00:40:15,970
in your space are offering,

789
00:40:15,970 --> 00:40:19,890
I think is very useful information to see

790
00:40:19,890 --> 00:40:21,680
from a competitive pressure,

791
00:40:21,680 --> 00:40:23,960
competitive differentiator perspective,

792
00:40:23,960 --> 00:40:26,320
what is it that you
might consider offering

793
00:40:26,320 --> 00:40:28,040
and what's possible for you to offer

794
00:40:28,040 --> 00:40:32,240
because some of these
additional security safeguards,

795
00:40:32,240 --> 00:40:35,939
require some development
or some choices about

796
00:40:35,940 --> 00:40:39,003
how you're offering your
services and your systems.

797
00:40:40,500 --> 00:40:42,660
I think I spoke a little bit about this

798
00:40:42,660 --> 00:40:45,379
in terms of your communication protocols,

799
00:40:45,380 --> 00:40:49,940
and FAQ's and how your messaging standard.

800
00:40:49,940 --> 00:40:52,160
They're sort of the internal communication

801
00:40:52,160 --> 00:40:54,259
to make sure that there's consistency

802
00:40:54,260 --> 00:40:57,700
among your legal team,
among your privacy team,

803
00:40:57,700 --> 00:40:59,460
among your security team,

804
00:40:59,460 --> 00:41:03,930
and among your sales team,
how you're responding,

805
00:41:03,930 --> 00:41:06,299
and what is sort of the company's line

806
00:41:06,300 --> 00:41:08,750
and statement on some of these questions,

807
00:41:08,750 --> 00:41:10,860
and then externally what are you saying

808
00:41:10,860 --> 00:41:12,440
on your trust center, for example,

809
00:41:12,440 --> 00:41:15,010
what are you posting if you make

810
00:41:15,010 --> 00:41:17,560
your data protection agreement public.

811
00:41:17,560 --> 00:41:20,420
And then how are you responding
to customer requests,

812
00:41:20,420 --> 00:41:22,240
either through an RFI process,

813
00:41:22,240 --> 00:41:25,640
or escalation and negotiation
of your customer deals?

814
00:41:25,640 --> 00:41:29,970
Having some standard set of responses

815
00:41:29,970 --> 00:41:31,839
helps from a consistency point of view,

816
00:41:31,840 --> 00:41:34,210
but also just administrative efficiencies,

817
00:41:34,210 --> 00:41:36,530
so you're not sort of
always creating the wheel

818
00:41:36,530 --> 00:41:38,410
and recreating the wheel and always

819
00:41:38,410 --> 00:41:41,140
sort of in a last minute fire drill

820
00:41:41,140 --> 00:41:45,290
to run down a response
to a customer question.

821
00:41:45,290 --> 00:41:50,290
So this onward data transfer uncertainty

822
00:41:50,650 --> 00:41:54,330
has created a lot of
extra work for companies.

823
00:41:54,330 --> 00:41:56,680
I'll be perfectly honest,
since last summer,

824
00:41:56,680 --> 00:42:00,649
there's been a lot of work to shore up.

825
00:42:00,650 --> 00:42:03,793
Some of our contracts, some
of our security protocols,

826
00:42:04,971 --> 00:42:06,760
there are some things that are within

827
00:42:06,760 --> 00:42:09,700
the company's control,
some things that we can do

828
00:42:09,700 --> 00:42:12,609
making sure we have these
safeguards in place,

829
00:42:12,610 --> 00:42:14,360
contractual provisions in place,

830
00:42:14,360 --> 00:42:16,900
communication plans in place,

831
00:42:16,900 --> 00:42:20,080
but many of us are waiting
for a political solution,

832
00:42:20,080 --> 00:42:23,740
Privacy Shield, 3.0, to
take some of the burden

833
00:42:23,740 --> 00:42:27,886
off of the companies so that we have

834
00:42:27,887 --> 00:42:32,670
the standard political
solutions so we can continue

835
00:42:32,670 --> 00:42:36,530
to transfer data out of Europe
to maintain our business.

836
00:42:36,530 --> 00:42:38,600
So in terms of the legal safeguards,

837
00:42:38,600 --> 00:42:42,779
so contractual provisions looking at

838
00:42:44,410 --> 00:42:47,700
the non-EU government authority
access to personal data.

839
00:42:47,700 --> 00:42:51,020
So these are controls
that you can put in place

840
00:42:51,020 --> 00:42:55,220
in terms of just general
access controls to your data.

841
00:42:55,220 --> 00:42:57,100
But what are you thinking about in terms

842
00:42:57,100 --> 00:43:01,140
of policies for government
requests for data?

843
00:43:01,140 --> 00:43:02,960
Do you have a transparency report?

844
00:43:02,960 --> 00:43:05,503
Do you require a subpoena,
things like that.

845
00:43:06,565 --> 00:43:08,170
Again, you can look at
some of the benchmarking

846
00:43:08,170 --> 00:43:11,280
of companies that publish these.

847
00:43:11,280 --> 00:43:13,900
I think it's also very
important to consider

848
00:43:13,900 --> 00:43:18,697
how aggressively you want to
resist or fight these requests.

849
00:43:21,950 --> 00:43:24,850
And also what are the
requests or the access to data

850
00:43:24,850 --> 00:43:28,040
that companies just don't
know about (chuckles),

851
00:43:28,040 --> 00:43:31,400
because the government may
or may not be accessing data

852
00:43:31,400 --> 00:43:35,263
without asking for the
company's permission.

853
00:43:36,945 --> 00:43:41,300
And then what other types
of contractual provisions

854
00:43:41,300 --> 00:43:43,410
can you put in place,
and also thinking about

855
00:43:43,410 --> 00:43:47,450
those downstream contractual
terms with your vendors.

856
00:43:47,450 --> 00:43:49,509
So the contractual terms that

857
00:43:49,510 --> 00:43:51,970
you have in place with your customers,

858
00:43:51,970 --> 00:43:53,620
but how are you replicating that

859
00:43:53,620 --> 00:43:56,620
into the privacy and security obligations

860
00:43:56,620 --> 00:43:58,230
that you've put in
place with your vendors,

861
00:43:58,230 --> 00:44:00,610
that sort of pass through downstream

862
00:44:00,610 --> 00:44:02,760
due diligence of your vendor base

863
00:44:02,760 --> 00:44:05,540
to make sure that they are in fact,

864
00:44:05,540 --> 00:44:08,270
including some sort of
supplementary measures,

865
00:44:08,270 --> 00:44:11,310
if you, the enterprise
company are putting those

866
00:44:11,310 --> 00:44:13,860
in your contractual
commitments to customers.

867
00:44:13,860 --> 00:44:16,170
- Yeah, I got a direct message question

868
00:44:16,170 --> 00:44:18,750
that's on point here too,
which is how do you know

869
00:44:18,750 --> 00:44:20,640
when a vendor is transferring your data

870
00:44:20,640 --> 00:44:22,009
since they own the data flows,

871
00:44:22,010 --> 00:44:24,620
and some are not open to
sharing that information.

872
00:44:24,620 --> 00:44:27,290
How do you make sure
that they're compliant?

873
00:44:27,290 --> 00:44:28,310
- So I think that's part of

874
00:44:28,310 --> 00:44:30,200
your vendor management due diligence.

875
00:44:30,200 --> 00:44:33,279
So if you have contractual
provisions in place,

876
00:44:33,280 --> 00:44:36,570
if you require some responses to that

877
00:44:36,570 --> 00:44:39,530
as part of your vendor
due diligence process,

878
00:44:39,530 --> 00:44:41,150
either in a security questionnaire

879
00:44:41,150 --> 00:44:43,680
or other discussions you
have with the vendor,

880
00:44:43,680 --> 00:44:46,859
I mean, you're entitled to some answers

881
00:44:46,860 --> 00:44:49,247
from your vendors about what
they're doing with your data,

882
00:44:49,247 --> 00:44:52,049
and what security controls
they have in place.

883
00:44:52,050 --> 00:44:53,530
- So I'm gonna talk for a moment

884
00:44:53,530 --> 00:44:56,014
about administrative safeguards.

885
00:44:56,014 --> 00:44:56,847
(Alexandra coughs)

886
00:44:56,847 --> 00:45:00,667
So part and parcel with
the contractual provisions

887
00:45:02,170 --> 00:45:06,470
that require you to take certain steps

888
00:45:06,470 --> 00:45:09,529
before complying with third party

889
00:45:09,530 --> 00:45:11,523
or government requests for information,

890
00:45:12,810 --> 00:45:15,070
you may wanna actually
put in place a policy

891
00:45:15,070 --> 00:45:16,470
that clearly describes how you're going

892
00:45:16,470 --> 00:45:18,470
to respond to these government requests.

893
00:45:20,507 --> 00:45:22,710
And this policy might include
the specific legal basis

894
00:45:22,710 --> 00:45:25,520
that compel or allow the
disclosure of information.

895
00:45:25,520 --> 00:45:28,310
So you and your team know when something

896
00:45:28,310 --> 00:45:33,130
is required by law or
are able to assess it,

897
00:45:33,130 --> 00:45:35,950
before releasing the
information as opposed to

898
00:45:35,950 --> 00:45:39,049
perhaps a non mandatory
request for information

899
00:45:39,050 --> 00:45:41,570
where you might not
automatically disclose it,

900
00:45:41,570 --> 00:45:43,270
and the conditions that have to be met

901
00:45:43,270 --> 00:45:44,960
in order to make a disclosure.

902
00:45:44,960 --> 00:45:46,880
Put in place a process, for example,

903
00:45:46,880 --> 00:45:49,330
on who will be responsible
for implementing this,

904
00:45:49,330 --> 00:45:52,049
for example is it going to
be your litigation team?

905
00:45:52,050 --> 00:45:53,450
Do you have a special department

906
00:45:53,450 --> 00:45:55,470
for handling government requests,

907
00:45:55,470 --> 00:45:57,363
if you get a number of these?

908
00:45:58,360 --> 00:46:00,900
One of the subtexts of this is

909
00:46:00,900 --> 00:46:03,780
the forthcoming standard
contractual clauses.

910
00:46:03,780 --> 00:46:07,063
So the standard contractual
clauses we talked about,

911
00:46:08,043 --> 00:46:10,530
there's two forms of them depending on

912
00:46:10,530 --> 00:46:12,550
whether you're transferring
to a controller

913
00:46:12,550 --> 00:46:14,230
or processor currently,

914
00:46:14,230 --> 00:46:15,600
and the last versions of those

915
00:46:15,600 --> 00:46:18,333
were adopted in 2010 and 2004.

916
00:46:19,985 --> 00:46:23,850
And so they didn't take into account

917
00:46:23,850 --> 00:46:25,589
the Schrems II decision,

918
00:46:25,590 --> 00:46:28,420
they didn't even take
into account the GDPR.

919
00:46:28,420 --> 00:46:32,820
And so these have been
under process for revision

920
00:46:32,820 --> 00:46:37,210
for awhile, and drafts of them
were published in November.

921
00:46:37,210 --> 00:46:38,810
The European commission took comments,

922
00:46:38,810 --> 00:46:43,100
and we hear any day
now, a matter of weeks,

923
00:46:43,100 --> 00:46:45,089
couple months, sometimes the wheels

924
00:46:45,090 --> 00:46:49,050
of the European Bureaucracy move slowly,

925
00:46:49,050 --> 00:46:51,560
but we know at some point there's going

926
00:46:51,560 --> 00:46:54,440
to be an updated set of
standard contractual clauses,

927
00:46:54,440 --> 00:46:56,733
that are going to be
rolled out with likely

928
00:46:56,733 --> 00:46:59,690
a one year grace period
for implementation.

929
00:46:59,690 --> 00:47:02,500
Which will kick off another data,

930
00:47:02,500 --> 00:47:05,260
sorry another contracting exercise.

931
00:47:05,260 --> 00:47:06,620
But one of the features of these is

932
00:47:06,620 --> 00:47:08,960
there's a whole section on all of this,

933
00:47:08,960 --> 00:47:12,170
about how a recipient outside of Europe

934
00:47:14,130 --> 00:47:16,920
or subject to the standard
contractual clauses,

935
00:47:16,920 --> 00:47:19,160
has to push back on government requests.

936
00:47:19,160 --> 00:47:20,670
So you're going to have to put in place

937
00:47:20,670 --> 00:47:22,670
if you're going to comply with them,

938
00:47:22,670 --> 00:47:24,170
this type of process eventually.

939
00:47:24,170 --> 00:47:27,693
So it's probably worth starting
to have those discussions.

940
00:47:28,920 --> 00:47:31,660
A second administrative
safeguard or process

941
00:47:31,660 --> 00:47:35,600
to put in place is publication
of transparency reports

942
00:47:35,600 --> 00:47:38,319
about the scope and
extent of the provision

943
00:47:38,320 --> 00:47:40,090
of personal data to public authorities,

944
00:47:40,090 --> 00:47:42,450
and this can serve a couple of purposes.

945
00:47:42,450 --> 00:47:44,482
One of them is just being transparent.

946
00:47:45,330 --> 00:47:50,210
So European regulators,
your customers know exactly

947
00:47:51,330 --> 00:47:53,293
what types of requests you're getting.

948
00:47:55,100 --> 00:47:56,839
Sunlight is the best disinfectant,

949
00:47:56,840 --> 00:47:59,240
they can see how things are going,

950
00:47:59,240 --> 00:48:01,439
but also if you're one of the companies

951
00:48:01,440 --> 00:48:02,740
that's fortunate not to get

952
00:48:02,740 --> 00:48:05,629
too many national security
requests for information,

953
00:48:05,630 --> 00:48:07,910
this can also be a pretty good signal,

954
00:48:07,910 --> 00:48:12,790
that you're not a high risk
recipient of information.

955
00:48:12,790 --> 00:48:14,740
And Alexandra I know
you have some thoughts

956
00:48:14,740 --> 00:48:16,589
on transparency reports.

957
00:48:16,590 --> 00:48:18,583
- To echo what you just said, yes.

958
00:48:18,583 --> 00:48:20,760
I think putting the process in place

959
00:48:20,760 --> 00:48:23,210
to make sure you have a dedicated team

960
00:48:23,210 --> 00:48:25,640
that's working in ease and you've aligned

961
00:48:25,640 --> 00:48:27,730
on what is your process for reviewing

962
00:48:27,730 --> 00:48:28,820
and what's your criteria,

963
00:48:28,820 --> 00:48:33,670
and how aggressively are
you going to review them,

964
00:48:33,670 --> 00:48:36,987
subject to all the legal requirements,

965
00:48:36,987 --> 00:48:39,340
and the benchmarking that
you may have conducted.

966
00:48:39,340 --> 00:48:43,440
But I do think the range
of transparency reports

967
00:48:43,440 --> 00:48:45,510
out there is interesting
to take a look at,

968
00:48:45,510 --> 00:48:47,090
because there are certain companies

969
00:48:47,090 --> 00:48:49,250
that get hundreds of these a year,

970
00:48:49,250 --> 00:48:51,410
and they report them in
their transparency report.

971
00:48:51,410 --> 00:48:53,160
There's some companies that get zero

972
00:48:53,160 --> 00:48:54,970
to one or two of these a year.

973
00:48:54,970 --> 00:48:58,209
So there are certain
social media companies,

974
00:48:58,210 --> 00:49:00,750
or email providers that have more data

975
00:49:00,750 --> 00:49:03,970
of interest apparently
to government requests

976
00:49:03,970 --> 00:49:05,129
than other companies.

977
00:49:05,130 --> 00:49:07,680
So if you are one of the, as Bret said,

978
00:49:07,680 --> 00:49:09,200
the potentially lucky companies

979
00:49:09,200 --> 00:49:10,680
that are getting few of these,

980
00:49:10,680 --> 00:49:13,330
you could potentially use that
in your sales negotiation,

981
00:49:13,330 --> 00:49:16,029
that you are potentially less at risk,

982
00:49:16,030 --> 00:49:17,610
and your data is safe and secure.

983
00:49:17,610 --> 00:49:21,620
You have all of these other
security protocols in place.

984
00:49:21,620 --> 00:49:26,620
So there's less potential
concern that a European customer

985
00:49:26,870 --> 00:49:29,160
may have with dealing with you,

986
00:49:29,160 --> 00:49:32,049
and having their data stored
and processed in the US.

987
00:49:32,050 --> 00:49:33,470
- So going back into this slide,

988
00:49:33,470 --> 00:49:36,259
we have been talking a lot
about supplementary measures

989
00:49:36,260 --> 00:49:39,500
and also about technical
supplementary measures.

990
00:49:39,500 --> 00:49:42,030
And a quick note here that even after

991
00:49:42,030 --> 00:49:44,620
the European commission
publishes this new set

992
00:49:44,620 --> 00:49:46,509
of standard contractual clauses,

993
00:49:46,510 --> 00:49:50,030
you will still need to
actually put in place

994
00:49:50,030 --> 00:49:52,880
additional supplementary measures.

995
00:49:52,880 --> 00:49:55,670
Some of them are of the legal nature.

996
00:49:55,670 --> 00:49:58,817
Some of them are of
administrative nature as Bret

997
00:49:58,817 --> 00:50:02,960
and Alexandra were saying, but a key type

998
00:50:02,960 --> 00:50:07,693
of supplementary measures
are technical measures.

999
00:50:08,910 --> 00:50:11,700
The EDPB published the draft guidelines

1000
00:50:11,700 --> 00:50:13,180
as I was mentioning before.

1001
00:50:13,180 --> 00:50:16,990
And in those draft guidelines
on supplementary measures

1002
00:50:16,990 --> 00:50:21,120
you will see already a
number of specific use cases

1003
00:50:21,120 --> 00:50:24,252
for specific types of
technology that can be used.

1004
00:50:25,150 --> 00:50:28,030
And I would say, they don't (chuckles)

1005
00:50:28,030 --> 00:50:33,030
actually leave a lot of
scope for moving forward

1006
00:50:33,460 --> 00:50:36,060
with a lot of the transfers just to give

1007
00:50:36,060 --> 00:50:38,650
you a flavor of it, when we're
talking about encryption,

1008
00:50:38,650 --> 00:50:42,520
encryption is considered in
detail in these guidelines.

1009
00:50:42,520 --> 00:50:46,770
And indeed the EDPB says
that encryption works

1010
00:50:46,770 --> 00:50:49,570
for data storage, for backup,

1011
00:50:49,570 --> 00:50:51,650
and other purposes that do not require

1012
00:50:51,650 --> 00:50:53,550
access to data in the clear.

1013
00:50:53,550 --> 00:50:55,960
It also works for encrypted data

1014
00:50:55,960 --> 00:50:58,500
merely transiting third countries,

1015
00:50:58,500 --> 00:51:02,420
and transferring data to
protected recipients such as;

1016
00:51:02,420 --> 00:51:06,780
lawyers or doctors just in
those very specific cases.

1017
00:51:06,780 --> 00:51:09,800
However, encryption
does not generally work

1018
00:51:09,800 --> 00:51:12,340
for transfers to cloud service providers,

1019
00:51:12,340 --> 00:51:14,680
or other processes which require

1020
00:51:14,680 --> 00:51:17,020
access to data in the clear.

1021
00:51:17,020 --> 00:51:20,170
And it also does not
work for remote access

1022
00:51:20,170 --> 00:51:22,150
to data for business purposes.

1023
00:51:22,150 --> 00:51:24,850
And we already talked a lot about

1024
00:51:24,850 --> 00:51:27,373
this remote access scenario.

1025
00:51:28,210 --> 00:51:30,710
The EDPPB also looks at pseudonymization

1026
00:51:30,710 --> 00:51:33,690
as a potential technical
measure to put in place,

1027
00:51:33,690 --> 00:51:36,900
and indeed pseudonymization
can also be used.

1028
00:51:36,900 --> 00:51:39,040
It could work in general when I say

1029
00:51:39,040 --> 00:51:43,070
pseudonymization think of key coding data.

1030
00:51:43,070 --> 00:51:45,970
And there's a lot about keeping the key

1031
00:51:45,970 --> 00:51:50,419
within Europe ensuring
somehow that access to the key

1032
00:51:50,420 --> 00:51:55,420
is not easy in keeping it
perhaps with European entities

1033
00:51:56,530 --> 00:51:59,750
have that it escapes the US cloud act.

1034
00:51:59,750 --> 00:52:02,220
There's a lot of debate around that,

1035
00:52:02,220 --> 00:52:04,540
however, also for pseudonymization,

1036
00:52:04,540 --> 00:52:07,620
as you can imagine there are big caveats

1037
00:52:07,620 --> 00:52:09,180
of when it can be used,

1038
00:52:09,180 --> 00:52:10,930
and when it can not be used.

1039
00:52:10,930 --> 00:52:14,200
Other type of measure that
the EDPB is considering

1040
00:52:14,200 --> 00:52:18,210
is multi-party computation, which again,

1041
00:52:18,210 --> 00:52:20,050
could work in some scenarios,

1042
00:52:20,050 --> 00:52:22,780
but there are caveats there as well.

1043
00:52:22,780 --> 00:52:25,130
And all of these scenarios
are actually described

1044
00:52:25,130 --> 00:52:28,633
in quite a bit of a
detail in the guidelines.

1045
00:52:29,780 --> 00:52:32,200
I would say that it was precisely

1046
00:52:32,200 --> 00:52:34,890
those recommendations for
supplementary measures,

1047
00:52:34,890 --> 00:52:37,410
that made all of us think in the end,

1048
00:52:37,410 --> 00:52:38,623
a political solution is (chuckles softly)

1049
00:52:38,623 --> 00:52:41,390
the one that will solve all this,

1050
00:52:41,390 --> 00:52:46,390
because businesses can do what
they can do on their side,

1051
00:52:46,560 --> 00:52:49,560
but in the end, a political
agreement is needed.

1052
00:52:49,560 --> 00:52:54,020
And there's perhaps a need to push

1053
00:52:54,020 --> 00:52:56,660
the department of commerce,
a need to push a bit

1054
00:52:56,660 --> 00:53:00,149
your representatives in
Congress to take action

1055
00:53:00,150 --> 00:53:03,313
on some of the political
measures that are needed.

1056
00:53:04,965 --> 00:53:07,010
- I would echo that as well, Gabriela,

1057
00:53:07,010 --> 00:53:11,760
and just to add one other
point, I think the security

1058
00:53:12,840 --> 00:53:15,310
and technical measures in a lot of cases,

1059
00:53:15,310 --> 00:53:17,320
track what companies already have in place

1060
00:53:17,320 --> 00:53:18,480
with their security program,

1061
00:53:18,480 --> 00:53:20,260
and track some of their
requirements for SOC II

1062
00:53:20,260 --> 00:53:22,270
and other security certifications.

1063
00:53:22,270 --> 00:53:25,810
Some of those are so strict,

1064
00:53:25,810 --> 00:53:30,350
and so unworkable as to
really prevent companies

1065
00:53:30,350 --> 00:53:32,470
from providing the services,

1066
00:53:32,470 --> 00:53:35,069
because they need access
to unencrypted data

1067
00:53:35,070 --> 00:53:39,170
or they need to have, some
of these are preventative

1068
00:53:39,170 --> 00:53:42,480
from actually being
able to access the data

1069
00:53:42,480 --> 00:53:43,790
in a way that's workable.

1070
00:53:43,790 --> 00:53:45,870
So I think that's sort of the tension

1071
00:53:45,870 --> 00:53:48,470
that we're seeing is the intent

1072
00:53:48,470 --> 00:53:50,209
behind the safeguards makes sense.

1073
00:53:50,210 --> 00:53:52,560
But I think sometimes the
way that they're drafted,

1074
00:53:52,560 --> 00:53:54,750
isn't very practical in terms of

1075
00:53:54,750 --> 00:53:56,793
what works for companies on the ground.

1076
00:53:59,950 --> 00:54:02,740
- So we already talked about responding

1077
00:54:02,740 --> 00:54:04,160
to diligence requests.

1078
00:54:04,160 --> 00:54:07,720
You need to respond to
this type of request,

1079
00:54:07,720 --> 00:54:11,160
and Bret and Alexandra
already gave you a lot

1080
00:54:11,160 --> 00:54:15,670
of guidance on this particular question,

1081
00:54:15,670 --> 00:54:18,380
I would say I cannot emphasize enough

1082
00:54:18,380 --> 00:54:20,190
how important it is not only to do

1083
00:54:20,190 --> 00:54:22,770
your due diligence as it
was highlighted already,

1084
00:54:22,770 --> 00:54:26,408
but also to have those
standard contractual clauses

1085
00:54:26,408 --> 00:54:29,450
in place, and to give you another example

1086
00:54:29,450 --> 00:54:33,419
from a case earlier this year from Spain,

1087
00:54:33,420 --> 00:54:35,320
the Spanish Data Protection Authority

1088
00:54:35,320 --> 00:54:39,590
sanctioned Vodafone for a transfer of data

1089
00:54:39,590 --> 00:54:43,460
not to the US but to, it
was either Peru or Chile,

1090
00:54:43,460 --> 00:54:47,033
one of the two countries in South America.

1091
00:54:48,480 --> 00:54:50,760
One of these two countries
I can't remember correctly,

1092
00:54:50,760 --> 00:54:54,510
but the Vodafone actually did not have

1093
00:54:54,510 --> 00:54:56,440
any safeguard in place.

1094
00:54:56,440 --> 00:55:00,570
And that was the ground for
issuing a fine immediately.

1095
00:55:00,570 --> 00:55:03,410
There was actually no room to argue that,

1096
00:55:03,410 --> 00:55:06,859
look we have contractual safeguards,

1097
00:55:06,860 --> 00:55:09,580
and we also thought about
these additional measures.

1098
00:55:09,580 --> 00:55:12,180
All of this are mitigating factors

1099
00:55:12,180 --> 00:55:14,490
in this type of decisions.

1100
00:55:14,490 --> 00:55:17,062
And perhaps the last slides.

1101
00:55:21,080 --> 00:55:23,529
Here we were supposed
to each of us (chuckles)

1102
00:55:23,530 --> 00:55:27,410
to say a type of concluding remark.

1103
00:55:27,410 --> 00:55:32,410
I think I already ended mine,

1104
00:55:32,520 --> 00:55:34,480
have something in places I was saying.

1105
00:55:34,480 --> 00:55:37,900
And if there's one of the
things that you can do

1106
00:55:37,900 --> 00:55:42,230
from my point of view, as a policy person

1107
00:55:42,230 --> 00:55:44,847
really push your
congressperson (chuckles),

1108
00:55:45,800 --> 00:55:48,260
knock on their door, give them a call

1109
00:55:48,260 --> 00:55:50,150
and say, look this is a serious problem.

1110
00:55:50,150 --> 00:55:52,400
We are losing business because of this,

1111
00:55:52,400 --> 00:55:54,030
and we need a political solution.

1112
00:55:54,030 --> 00:55:55,900
We need some changes in the law,

1113
00:55:55,900 --> 00:55:58,680
engage with your partners in Europe,

1114
00:55:58,680 --> 00:56:00,232
and find a solution to this.

1115
00:56:01,310 --> 00:56:03,560
- And my final takeaway would be,

1116
00:56:03,560 --> 00:56:07,430
make sure you're clear
about what is your approach

1117
00:56:07,430 --> 00:56:10,259
to manage the legal uncertainty,

1118
00:56:10,260 --> 00:56:12,780
and what are you doing in response

1119
00:56:12,780 --> 00:56:15,750
to your legal mechanisms
for data transfer,

1120
00:56:15,750 --> 00:56:18,510
but also recognizing that with Microsoft,

1121
00:56:18,510 --> 00:56:20,030
and other companies that are starting

1122
00:56:20,030 --> 00:56:24,340
to offer data localizations solutions,

1123
00:56:24,340 --> 00:56:25,830
that the ground is shifting,

1124
00:56:25,830 --> 00:56:29,060
and competitive pressure may change

1125
00:56:29,060 --> 00:56:31,549
what companies are expected to offer above

1126
00:56:31,550 --> 00:56:33,643
and beyond these legal requirements.

1127
00:56:35,330 --> 00:56:37,850
- So with that, we have
a couple minutes left

1128
00:56:37,850 --> 00:56:41,480
maybe I'll pose a couple questions.

1129
00:56:41,480 --> 00:56:43,610
We had actually a really good question.

1130
00:56:43,610 --> 00:56:45,260
Gabriela, I'll pose it to you.

1131
00:56:45,260 --> 00:56:47,990
What about companies who
have binding corporate rules

1132
00:56:47,990 --> 00:56:50,899
as an alternative to
standard contractual clauses.

1133
00:56:50,900 --> 00:56:52,870
Are they required to undertake

1134
00:56:52,870 --> 00:56:55,743
this assessment under Schrems II?

1135
00:56:56,850 --> 00:57:01,850
- Yes, they are also required
to undertake the assessment,

1136
00:57:01,940 --> 00:57:04,980
and the EDPB was quite clear that

1137
00:57:04,980 --> 00:57:07,250
there are supplementary
measures guidelines

1138
00:57:07,250 --> 00:57:10,120
are actually applicable
across the safeguards

1139
00:57:10,120 --> 00:57:12,500
in article 46 of the GDPR,

1140
00:57:12,500 --> 00:57:16,730
which includes VCRs,
includes codes of conduct,

1141
00:57:16,730 --> 00:57:19,220
even though I don't think we're soon going

1142
00:57:19,220 --> 00:57:22,230
to see a code of conduct
for transfers unfortunately,

1143
00:57:22,230 --> 00:57:24,360
because it's such a burdensome,

1144
00:57:24,360 --> 00:57:27,283
and bureaucratic process
to get one adopted.

1145
00:57:28,290 --> 00:57:32,980
So this assessment will be
needed for VCRs as well.

1146
00:57:32,980 --> 00:57:34,340
But I would dare say you are

1147
00:57:34,340 --> 00:57:36,070
in a bit of a better place given

1148
00:57:36,070 --> 00:57:39,430
that you already obtained an approval

1149
00:57:39,430 --> 00:57:42,113
from your lead DPA for the VCRs.

1150
00:57:43,150 --> 00:57:45,810
- Alexandra, one last question for you.

1151
00:57:45,810 --> 00:57:49,591
If there's a vendor who wants
to analyze users' emails

1152
00:57:49,591 --> 00:57:51,890
in order to provide email
writing suggestions,

1153
00:57:51,890 --> 00:57:53,500
and they say they can't discard

1154
00:57:53,500 --> 00:57:55,580
sensitive personal information,

1155
00:57:55,580 --> 00:57:57,090
but ultimately it depends on how

1156
00:57:57,090 --> 00:57:59,060
they design their application.

1157
00:57:59,060 --> 00:58:02,160
Does that cover you
from not having to deal

1158
00:58:02,160 --> 00:58:06,540
with any of this with
respect to this vendor,

1159
00:58:06,540 --> 00:58:09,910
or is that a data transfer,
a data access point,

1160
00:58:09,910 --> 00:58:12,910
where you have to go through
your vendor diligence process

1161
00:58:12,910 --> 00:58:14,823
and making sure everything works?

1162
00:58:15,710 --> 00:58:19,030
- So I think it depends
on what type of data

1163
00:58:19,030 --> 00:58:21,150
the vendor has access to.

1164
00:58:21,150 --> 00:58:23,950
If it's non-personal
data that they're using

1165
00:58:23,950 --> 00:58:26,129
for their analysis, it
might be out of scope,

1166
00:58:26,130 --> 00:58:27,910
but I would argue you still want to have

1167
00:58:27,910 --> 00:58:30,149
some sort of contract in
place with that vendor

1168
00:58:30,150 --> 00:58:33,190
to manage some of the other legal issues.

1169
00:58:33,190 --> 00:58:35,410
But if there is personal data at play,

1170
00:58:35,410 --> 00:58:38,060
then I think most companies would require

1171
00:58:38,060 --> 00:58:41,330
security reviews, some
sort of contractual terms

1172
00:58:41,330 --> 00:58:42,610
related to privacy.

1173
00:58:42,610 --> 00:58:44,885
and you would wanna make sure that

1174
00:58:44,885 --> 00:58:48,550
you had those sort of
downstream controls in place,

1175
00:58:48,550 --> 00:58:50,740
related to onward data transfer.

1176
00:58:50,740 --> 00:58:55,740
So it depends on what
that vendor has access to,

1177
00:58:55,790 --> 00:58:58,009
the data elements and
whether that's personal data

1178
00:58:58,010 --> 00:59:00,133
or not would be my initial take.

1179
00:59:01,450 --> 00:59:02,589
- So I think we're out time.

1180
00:59:02,590 --> 00:59:05,120
Thank you everyone for joining us today.

1181
00:59:05,120 --> 00:59:08,183
And we hope to talk to you
about this topic again.

1182
00:59:10,467 --> 00:59:12,050
- Goodbye everyone.

