1
00:00:01,140 --> 00:00:02,769
- All right, hello everyone.

2
00:00:02,770 --> 00:00:03,700
Glad you could join me.

3
00:00:03,700 --> 00:00:05,130
My name is Jeff McJunkin.

4
00:00:05,130 --> 00:00:06,060
Today we're gonna be talking about

5
00:00:06,060 --> 00:00:09,719
some top active directory
attacks and by the way,

6
00:00:09,720 --> 00:00:10,960
feel free to ask questions

7
00:00:10,960 --> 00:00:12,630
throughout the entire presentation.

8
00:00:12,630 --> 00:00:14,300
You're listening to past Jeff

9
00:00:14,300 --> 00:00:16,530
and present Jeff will be following along

10
00:00:16,530 --> 00:00:18,530
and happy to help you with some questions.

11
00:00:18,530 --> 00:00:21,250
All right, so let's go
ahead and get started.

12
00:00:21,250 --> 00:00:22,720
Hi, I'm Jeff.

13
00:00:22,720 --> 00:00:25,700
I have a slide at the actual
end to talk more about me

14
00:00:25,700 --> 00:00:28,009
if I've earned your attention by then.

15
00:00:28,010 --> 00:00:31,010
So today when I'm gonna
be talking about framing,

16
00:00:31,010 --> 00:00:33,350
what defenders have to do, right,

17
00:00:33,350 --> 00:00:35,630
for real-world realistic breaches,

18
00:00:35,630 --> 00:00:37,480
what do things actually look like?

19
00:00:37,480 --> 00:00:39,040
What's our goal for today?

20
00:00:39,040 --> 00:00:40,660
Where are we honing in?

21
00:00:40,660 --> 00:00:41,848
Then the bulk of the presentation

22
00:00:41,848 --> 00:00:46,018
on active directory
attacks and the application

23
00:00:46,018 --> 00:00:48,770
what you can do the moment
you get back to work.

24
00:00:48,770 --> 00:00:52,780
And then of course, some
dedicated time for Q&A as well.

25
00:00:52,780 --> 00:00:55,330
So first let's talk about different ways

26
00:00:55,330 --> 00:00:58,738
of conceptualizing end-to-end breaches.

27
00:00:58,738 --> 00:01:01,290
It's obligatory at some point to have

28
00:01:01,290 --> 00:01:04,470
the MITRE Enterprise
ATT&CK Matrix onscreen,

29
00:01:04,470 --> 00:01:05,590
and don't get me wrong,

30
00:01:05,590 --> 00:01:08,210
MITRE ATT&CK Matrix is very useful

31
00:01:08,210 --> 00:01:13,210
for having a common language
to describe attacker actions,

32
00:01:13,720 --> 00:01:15,660
but for the vast majority of breaches,

33
00:01:15,660 --> 00:01:17,679
it's gonna be a very small subset

34
00:01:17,680 --> 00:01:21,140
of these attacker techniques
that are going to be in use.

35
00:01:21,140 --> 00:01:23,370
So I love MITRE ATT&CK,

36
00:01:23,370 --> 00:01:26,150
I don't think it's a
great way to visualize

37
00:01:26,150 --> 00:01:28,690
a normal end-to-end breach.

38
00:01:28,690 --> 00:01:30,860
Similarly, there's the Lockheed Martin

39
00:01:30,860 --> 00:01:32,780
Cyber Kill Chain trademark,

40
00:01:32,780 --> 00:01:36,655
all right, and this is
useful for conceptualizing,

41
00:01:36,655 --> 00:01:38,950
maybe from the attacker's perspective,

42
00:01:38,950 --> 00:01:42,410
but I think less so from
the defender's perspective.

43
00:01:42,410 --> 00:01:44,649
So let's keep things simple.

44
00:01:44,650 --> 00:01:48,640
Here are four things that
pretty much every attacker

45
00:01:48,640 --> 00:01:50,630
or attack needs.

46
00:01:50,630 --> 00:01:52,960
You're gonna need some
kind of internal access

47
00:01:52,960 --> 00:01:54,539
for reasons we'll get into,

48
00:01:54,540 --> 00:01:57,520
you're gonna need some privileges
to accomplish your attack

49
00:01:57,520 --> 00:02:01,354
and then probably the
most discounted step,

50
00:02:01,355 --> 00:02:04,920
finding the actual right data if the goal

51
00:02:04,920 --> 00:02:08,639
is copying exfiltrating data
and then the actual copy,

52
00:02:08,639 --> 00:02:11,109
the actual exfiltration to work with.

53
00:02:11,110 --> 00:02:16,110
So for internal access, it's
almost always via phishing.

54
00:02:16,710 --> 00:02:19,980
For real-world breaches
of the best data we have,

55
00:02:19,980 --> 00:02:23,590
says 90 plus percent of
known public breaches

56
00:02:23,590 --> 00:02:26,980
started off with
email-based phishing, right?

57
00:02:26,980 --> 00:02:30,299
But there's only the five ways
listed on screen in practice.

58
00:02:30,300 --> 00:02:33,210
We have phishing for code execution,

59
00:02:33,210 --> 00:02:35,220
exploitable public-facing services.

60
00:02:35,220 --> 00:02:39,590
This is the classic example of
exploit something on the DMZ,

61
00:02:39,590 --> 00:02:42,420
touching the internet and
then pivot internally.

62
00:02:42,420 --> 00:02:44,634
There's normal authentication,

63
00:02:44,634 --> 00:02:49,029
remote desktop VPN,
virtual desktop, et cetera.

64
00:02:49,030 --> 00:02:50,720
There is inserting rogue devices

65
00:02:50,720 --> 00:02:54,130
like a good old Raspberry PI left behind.

66
00:02:54,130 --> 00:02:56,903
And then we have supply
chain attacks, solar ones.

67
00:02:57,810 --> 00:03:00,480
So there's only so many ways internally

68
00:03:00,480 --> 00:03:02,209
or to get inside the target environment

69
00:03:02,210 --> 00:03:04,330
and yes, hat tip to Tim MalcolmVetter

70
00:03:04,330 --> 00:03:06,030
who wrote a great article and linked,

71
00:03:06,030 --> 00:03:08,080
and by the way, there's plenty of links

72
00:03:08,080 --> 00:03:09,350
throughout the presentation

73
00:03:09,350 --> 00:03:11,970
and slide notes that you can access,

74
00:03:11,970 --> 00:03:14,640
'cause I'll be sharing
these slides as well.

75
00:03:14,640 --> 00:03:18,149
So as far as external versus internal,

76
00:03:18,150 --> 00:03:21,220
why do we need internal
access as an attacker?

77
00:03:21,220 --> 00:03:22,840
Right, from the outside perspective,

78
00:03:22,840 --> 00:03:26,360
using the very common
analogy of castle, right?

79
00:03:26,360 --> 00:03:29,030
There's only so many ways
to approach the castle,

80
00:03:29,030 --> 00:03:32,360
to storm the castle and
people are very careful

81
00:03:32,360 --> 00:03:34,347
about what they expose
to the outside world,

82
00:03:34,347 --> 00:03:36,030
to the public internet,

83
00:03:36,030 --> 00:03:39,290
but once you're inside,
right there's an actual view

84
00:03:39,290 --> 00:03:41,370
from inside a modern day castle,

85
00:03:41,370 --> 00:03:43,860
there is a lot you can
just kind of wander around

86
00:03:43,860 --> 00:03:45,770
and gain access to.

87
00:03:45,770 --> 00:03:49,940
You can think very similarly
for a larger campuses, right?

88
00:03:49,940 --> 00:03:52,710
For a Microsoft campus,
getting in the door,

89
00:03:52,710 --> 00:03:53,840
it might be rather difficult,

90
00:03:53,840 --> 00:03:56,720
but once you're inside a
general office building,

91
00:03:56,720 --> 00:03:59,580
most doors are open,
you can wander around.

92
00:03:59,580 --> 00:04:02,940
And to make this a little
bit more technical as well,

93
00:04:02,940 --> 00:04:06,780
let's talk about a
10,000 employee company.

94
00:04:06,780 --> 00:04:09,570
You might have, to an order of magnitude,

95
00:04:09,570 --> 00:04:12,170
about 100 externally available services

96
00:04:12,170 --> 00:04:15,220
and those are tend to be
chosen rather carefully,

97
00:04:15,220 --> 00:04:17,740
you have your classic email VPNs,

98
00:04:17,740 --> 00:04:20,649
mini websites, DNS servers perhaps,

99
00:04:20,649 --> 00:04:23,140
but internally, again
to order of magnitude,

100
00:04:23,140 --> 00:04:25,770
you have way, way more services

101
00:04:25,770 --> 00:04:27,630
than you have employees.

102
00:04:27,630 --> 00:04:31,270
Between employees' desktops or
laptops or virtual desktops,

103
00:04:31,270 --> 00:04:32,979
but also the networking infrastructure,

104
00:04:32,980 --> 00:04:34,950
also the servers inside,

105
00:04:34,950 --> 00:04:37,357
so it's just the tip of
the iceberg on the outside

106
00:04:37,357 --> 00:04:41,730
and of course attackers want
internal network access.

107
00:04:41,730 --> 00:04:44,760
All things being equal,
each particular service

108
00:04:44,760 --> 00:04:46,310
only has so much chance

109
00:04:46,310 --> 00:04:50,600
of having some un-patched vulnerability.

110
00:04:50,600 --> 00:04:54,874
If taking advantage of exploitable flaws

111
00:04:54,874 --> 00:04:56,450
is the attackers' way in,

112
00:04:56,450 --> 00:04:58,530
'cause I've done lots of
successful penetration tests

113
00:04:58,530 --> 00:05:02,289
by the way, never taking
advantage of patchable flaws

114
00:05:02,290 --> 00:05:05,960
and instead taking advantage
of features, but I digress.

115
00:05:05,960 --> 00:05:08,140
So we know why we need internal access.

116
00:05:08,140 --> 00:05:11,380
There's just a lot more
attack surface to work with,

117
00:05:11,380 --> 00:05:14,650
but we also need a lot more
in the way of privileges

118
00:05:14,650 --> 00:05:17,200
to take out or to accomplish

119
00:05:17,200 --> 00:05:20,840
on most common attacker actions, right?

120
00:05:20,840 --> 00:05:25,810
So speaking of a rather famous
Twitter breach last year,

121
00:05:25,810 --> 00:05:27,490
July-June timeframe.

122
00:05:27,490 --> 00:05:30,300
Look, there's around 5,000 employees,

123
00:05:30,300 --> 00:05:33,930
only 100 or so allegedly have access

124
00:05:33,930 --> 00:05:35,540
to the admin Twitter console

125
00:05:35,540 --> 00:05:39,190
where they could in fact,
hijack popular Twitter accounts.

126
00:05:39,190 --> 00:05:40,560
For your on-prem world,

127
00:05:40,560 --> 00:05:43,310
going back to that
10,000 employee example,

128
00:05:43,310 --> 00:05:46,390
there's probably, on
the order of magnitude,

129
00:05:46,390 --> 00:05:49,090
about 10 domain admins to work with,

130
00:05:49,090 --> 00:05:50,799
right, hopefully 10 or fewer,

131
00:05:50,800 --> 00:05:52,720
but I've seen organizations
that get closer

132
00:05:52,720 --> 00:05:56,800
to 100 domain admins, which
is terrifying by the way.

133
00:05:58,290 --> 00:06:02,260
Anyway, once we have
some privileges, right,

134
00:06:02,260 --> 00:06:03,870
often on a penetration test,

135
00:06:03,870 --> 00:06:05,640
it doesn't take long to
get those privileges,

136
00:06:05,640 --> 00:06:09,409
but actually like looking up
and saying, oh, now where am I

137
00:06:09,410 --> 00:06:12,010
and where's the data I
want to go for, right?

138
00:06:12,010 --> 00:06:14,219
Even though we have those permissions,

139
00:06:14,220 --> 00:06:17,440
finding the right data on
the right server is hard.

140
00:06:17,440 --> 00:06:19,400
Now, if we have a generic goal,

141
00:06:19,400 --> 00:06:21,840
like gain access to credit card data,

142
00:06:21,840 --> 00:06:24,159
which we could sell online.

143
00:06:24,160 --> 00:06:28,710
Well, people have used
or abused, I should say,

144
00:06:28,710 --> 00:06:30,840
software used for searching

145
00:06:30,840 --> 00:06:34,750
for this sensitive data
internally for attacker purposes.

146
00:06:34,750 --> 00:06:36,820
In my head, that's a little
bit of an endorsement

147
00:06:36,820 --> 00:06:40,340
for the specific software
ground labs, enterprise recon,

148
00:06:40,340 --> 00:06:43,659
but I have no commercial
relationship with them,

149
00:06:43,660 --> 00:06:46,060
but every time you start looking for,

150
00:06:46,060 --> 00:06:48,300
this is the data, this is
the pattern that we know

151
00:06:48,300 --> 00:06:49,980
and here's where it's supposed to be,

152
00:06:49,980 --> 00:06:51,780
you almost always end up finding,

153
00:06:51,780 --> 00:06:54,340
oh, that data ends up
here because of staging

154
00:06:54,340 --> 00:06:55,570
and the developer brought it over

155
00:06:55,570 --> 00:06:57,630
to this dev environment over here

156
00:06:57,630 --> 00:06:58,727
and we have another copy over here

157
00:06:58,727 --> 00:07:01,460
and we don't know why it's here,
because the person involved

158
00:07:01,460 --> 00:07:03,409
has since left, right?

159
00:07:03,410 --> 00:07:06,200
So this is why we want to
proactively start looking

160
00:07:06,200 --> 00:07:08,530
for this data internally.

161
00:07:08,530 --> 00:07:10,840
And then actually copying that data,

162
00:07:10,840 --> 00:07:13,840
actually stealing that
information, exfiltration,

163
00:07:13,840 --> 00:07:16,400
this doesn't take very long, right?

164
00:07:16,400 --> 00:07:17,233
And by the way,

165
00:07:17,233 --> 00:07:19,511
it could be not just
affecting confidentiality,

166
00:07:19,511 --> 00:07:22,710
but integrity or availability, right?

167
00:07:22,710 --> 00:07:25,270
Encrypting or destroying in place

168
00:07:25,270 --> 00:07:27,659
or changing some of your data.

169
00:07:27,660 --> 00:07:30,260
It depends on what the attacker is doing,

170
00:07:30,260 --> 00:07:32,330
but normally by the time the attacker

171
00:07:32,330 --> 00:07:35,510
has gained privileges and found the data,

172
00:07:35,510 --> 00:07:39,849
it's a really tough game, nigh
impossible to kick them out

173
00:07:39,850 --> 00:07:42,500
at that point before
they're able to accomplish

174
00:07:42,500 --> 00:07:44,120
their last bit of their goal,

175
00:07:44,120 --> 00:07:45,940
copying and stealing that data.

176
00:07:45,940 --> 00:07:47,558
And sometimes, by the way,

177
00:07:47,558 --> 00:07:50,550
steps three and four could
just be deploying ransomware.

178
00:07:50,550 --> 00:07:55,550
And this can be a terrifyingly
quick operation, right?

179
00:07:58,130 --> 00:08:03,130
So on the right, we have a
report from the DFIR Report,

180
00:08:03,230 --> 00:08:05,670
referring to a ransomware case.

181
00:08:05,670 --> 00:08:10,670
So essentially the DFIR Report
builds up fake enterprises

182
00:08:10,950 --> 00:08:14,420
and purposefully gets them compromised.

183
00:08:14,420 --> 00:08:17,290
It might be clicking on links in email,

184
00:08:17,290 --> 00:08:19,200
it might be opening some
malicious attachment,

185
00:08:19,200 --> 00:08:22,099
it might be having a remote
desktop server exposed

186
00:08:22,100 --> 00:08:24,690
to the outside world with
a guessable password.

187
00:08:24,690 --> 00:08:25,523
But in this case,

188
00:08:25,523 --> 00:08:28,810
the net locker ransomware
took all of one hour,

189
00:08:28,810 --> 00:08:31,560
65 minutes, if you want to be precise,

190
00:08:31,560 --> 00:08:35,370
to go from initial access
to ransomware is deployed

191
00:08:35,370 --> 00:08:37,683
to all domain joined machines.

192
00:08:38,780 --> 00:08:41,159
It gets tough, right?

193
00:08:41,159 --> 00:08:44,520
So here's the big high level picture,

194
00:08:44,520 --> 00:08:46,480
to prevent successful breaches, right,

195
00:08:46,480 --> 00:08:49,160
the attacker accomplishing their goal,

196
00:08:49,160 --> 00:08:53,360
defenders need to both detect
and respond to attackers

197
00:08:53,360 --> 00:08:55,460
before they accomplish their goal.

198
00:08:55,460 --> 00:08:58,300
So on the left I have, well the defenders

199
00:08:58,300 --> 00:09:01,839
and the defenders might
have a very long path

200
00:09:01,840 --> 00:09:03,968
when you think of initial access,

201
00:09:03,968 --> 00:09:07,160
may have been noticed by the
security operation center,

202
00:09:07,160 --> 00:09:09,530
and maybe they need to
hand things off internally

203
00:09:09,530 --> 00:09:12,319
to do host-based forensics on that box

204
00:09:12,320 --> 00:09:14,250
before they find out that the attacker

205
00:09:14,250 --> 00:09:15,780
has already moved, right?

206
00:09:15,780 --> 00:09:19,640
Sometimes the defense
timeline takes a lot longer

207
00:09:19,640 --> 00:09:21,550
than the attacker timeline,

208
00:09:21,550 --> 00:09:24,859
especially if you have some
of these pretty common ways

209
00:09:24,860 --> 00:09:27,350
for attackers to gain privileges, right?

210
00:09:27,350 --> 00:09:28,877
So if the attacker's timeline

211
00:09:28,877 --> 00:09:30,859
is shorter than the defender's,

212
00:09:30,860 --> 00:09:33,810
that's not a great
situation to be in, right?

213
00:09:33,810 --> 00:09:37,000
So you have two goals as a defender.

214
00:09:37,000 --> 00:09:41,150
You want to shorten down
your timeline to detect

215
00:09:41,150 --> 00:09:46,150
and respond and eradicate the
attacker's presence, right?

216
00:09:46,150 --> 00:09:50,550
You also wanna make it take
longer for the attacker to win.

217
00:09:50,550 --> 00:09:51,920
All right.

218
00:09:51,920 --> 00:09:53,839
So you want to take their short timeline

219
00:09:53,840 --> 00:09:55,970
and lengthen things,

220
00:09:55,970 --> 00:09:59,400
because prevention sure is ideal,

221
00:09:59,400 --> 00:10:04,100
but you cannot prevent
100% of initial incidents.

222
00:10:04,100 --> 00:10:05,240
It just can't happen, right?

223
00:10:05,240 --> 00:10:08,230
So I suppose the filter on
the right side of the screen

224
00:10:08,230 --> 00:10:11,350
is referring to preventive controls.

225
00:10:11,350 --> 00:10:13,330
So this is why we want to prevent

226
00:10:13,330 --> 00:10:15,210
as many incidents as possible,

227
00:10:15,210 --> 00:10:18,620
but really hone down on
detecting what's left.

228
00:10:18,620 --> 00:10:19,827
So we minimize those incidents,

229
00:10:19,827 --> 00:10:23,540
but we detect and we
accelerate our response,

230
00:10:23,540 --> 00:10:24,765
because I mean in the physical world

231
00:10:24,765 --> 00:10:28,540
with a safe, for example,
safes are not rated

232
00:10:28,540 --> 00:10:30,640
to keep attackers out forever, right?

233
00:10:30,640 --> 00:10:33,630
They keep attackers of
a certain capability,

234
00:10:33,630 --> 00:10:36,410
here a hammer weight
less than three pounds,

235
00:10:36,410 --> 00:10:40,850
a pry bar less than 18 inches,
for five minutes or more

236
00:10:40,850 --> 00:10:43,110
and I mean, that's a pretty low bar,

237
00:10:43,110 --> 00:10:47,770
but it means that you're
not having 100% prevention

238
00:10:47,770 --> 00:10:48,819
to work with.

239
00:10:48,820 --> 00:10:51,340
The goal is to slow down an attacker

240
00:10:51,340 --> 00:10:52,740
and gain you some access.

241
00:10:52,740 --> 00:10:55,230
So if an attacker can gain initial access,

242
00:10:55,230 --> 00:10:57,350
internal access and privileges

243
00:10:57,350 --> 00:10:59,703
in less than an hour, let's say.

244
00:11:00,680 --> 00:11:04,290
That's a really tough game
as a defender to detect

245
00:11:04,290 --> 00:11:06,980
and respond and eradicate the adversary,

246
00:11:06,980 --> 00:11:09,960
because the game gets a whole lot harder

247
00:11:09,960 --> 00:11:12,140
when the attacker has
already gained privileges

248
00:11:12,140 --> 00:11:15,860
and persisted in multiple ways
throughout your environment.

249
00:11:15,860 --> 00:11:18,760
So let's remove some of these easy wins

250
00:11:18,760 --> 00:11:21,730
from the attacker perspective
and make it take longer

251
00:11:21,730 --> 00:11:24,540
and when they're looking
for these easy wins,

252
00:11:24,540 --> 00:11:26,969
that is behavior that is
fundamentally different

253
00:11:26,970 --> 00:11:28,830
than your normal network users,

254
00:11:28,830 --> 00:11:32,410
so it can be a way to detect
the adversary as well.

255
00:11:32,410 --> 00:11:35,140
The defenders do have
a home court advantage

256
00:11:35,140 --> 00:11:37,800
if and only if, they use it.

257
00:11:37,800 --> 00:11:41,810
So today's goal is honing
in specifically on step two

258
00:11:41,810 --> 00:11:44,800
where the attackers
gain privileges, right?

259
00:11:44,800 --> 00:11:48,790
The Assume Breach model is
a far more interesting type

260
00:11:48,790 --> 00:11:50,160
of penetration test,

261
00:11:50,160 --> 00:11:53,740
where we assume some
amount of initial access

262
00:11:53,740 --> 00:11:56,190
from the attacker perspective,
it's going to happen,

263
00:11:56,190 --> 00:11:58,710
statistically it is inevitable, all right?

264
00:11:58,710 --> 00:12:01,930
So after attackers have
that initial access,

265
00:12:01,930 --> 00:12:04,459
then things are heck of
a lot more interesting.

266
00:12:04,460 --> 00:12:08,150
In my hot take, right, to
have a chance as a defender,

267
00:12:08,150 --> 00:12:11,449
the attacker cannot
win in less than a day,

268
00:12:11,450 --> 00:12:13,870
especially for most environments where,

269
00:12:13,870 --> 00:12:16,830
let's be honest, you
probably cannot get the alert

270
00:12:16,830 --> 00:12:19,490
in front of the right human
being in less than a minute.

271
00:12:19,490 --> 00:12:22,130
You can probably not
take corrective actions

272
00:12:22,130 --> 00:12:26,420
in less than 10 minutes and
that makes it much harder.

273
00:12:26,420 --> 00:12:28,180
You need more time for your detective

274
00:12:28,180 --> 00:12:32,030
and responsive controls to
have some time to work with.

275
00:12:32,030 --> 00:12:36,000
All right, so a realistic
threat model therefore,

276
00:12:36,000 --> 00:12:38,810
is assuming breach,
assuming that the attackers

277
00:12:38,810 --> 00:12:41,900
will phish for code execution

278
00:12:41,900 --> 00:12:45,449
and gain internal network
access as an authenticated user

279
00:12:45,450 --> 00:12:47,850
with non administrative access.

280
00:12:47,850 --> 00:12:50,340
And that quote, by the
way about 90 plus percent

281
00:12:50,340 --> 00:12:52,720
of the of breaches being
email-based phishing

282
00:12:52,720 --> 00:12:53,710
at the beginning

283
00:12:53,710 --> 00:12:56,900
is from Verizon Data Breach
Investigation reports.

284
00:12:56,900 --> 00:12:58,160
It's pretty good data to work with.

285
00:12:58,160 --> 00:13:00,980
So now let's get into the
meat of the presentation

286
00:13:00,980 --> 00:13:04,080
on the top active directory attacks.

287
00:13:04,080 --> 00:13:07,240
One is password spraying.

288
00:13:07,240 --> 00:13:10,530
The year is 2021 and the
average user authenticates

289
00:13:10,530 --> 00:13:13,470
to the average machine using a username

290
00:13:13,470 --> 00:13:15,710
and a password, all right?

291
00:13:15,710 --> 00:13:17,910
And if a user chooses their own password,

292
00:13:17,910 --> 00:13:19,440
humans are rather famously bad

293
00:13:19,441 --> 00:13:22,680
at generating pure
randomness, pure entropy,

294
00:13:22,680 --> 00:13:27,180
so my bet and my experience
is that between half a percent

295
00:13:27,180 --> 00:13:31,160
and 1% of user accounts
will use one of a variation

296
00:13:31,160 --> 00:13:33,992
of the word password or
variation of the word welcome,

297
00:13:33,993 --> 00:13:35,500
a variation of the company name

298
00:13:35,500 --> 00:13:39,360
or a variation of the
season and year, right?

299
00:13:39,360 --> 00:13:41,010
Because many people are required

300
00:13:41,010 --> 00:13:43,610
to rotate their credentials periodically.

301
00:13:43,610 --> 00:13:46,220
Let's say every 90 days and hey look,

302
00:13:46,220 --> 00:13:47,700
unless you live in the Bay area,

303
00:13:47,700 --> 00:13:50,850
you can tell seasons by looking outside.

304
00:13:50,850 --> 00:13:52,820
So as far as single factor
authentication services,

305
00:13:52,820 --> 00:13:57,000
those are external and
internal and my goodness,

306
00:13:57,000 --> 00:13:59,590
have you tested the phishing success rate

307
00:13:59,590 --> 00:14:02,330
of your organization comma?

308
00:14:02,330 --> 00:14:05,690
When the attacker is using
an internal email address,

309
00:14:05,690 --> 00:14:08,750
right, phishing rates
go up way, way higher

310
00:14:08,750 --> 00:14:12,140
when the attacker is sending
an internal email address

311
00:14:12,140 --> 00:14:13,160
and there's all sorts

312
00:14:13,160 --> 00:14:16,319
of single factor authentication services,

313
00:14:16,320 --> 00:14:19,360
perhaps most notably, internally SMB,

314
00:14:19,360 --> 00:14:23,020
Windows file sharing internally, right?

315
00:14:23,020 --> 00:14:27,050
So related, but separate
to password spraying

316
00:14:27,050 --> 00:14:29,229
is something called credential stuffing.

317
00:14:29,230 --> 00:14:30,310
It's still password guessing,

318
00:14:30,310 --> 00:14:33,300
I'm still authenticating
to an online system,

319
00:14:33,300 --> 00:14:35,770
but it's using compromised passwords

320
00:14:35,770 --> 00:14:37,199
associated with that email address

321
00:14:37,200 --> 00:14:39,850
or with that human being, right?

322
00:14:39,850 --> 00:14:42,210
So lots of organizations
have been compromised

323
00:14:42,210 --> 00:14:44,050
in the past, unfortunately,

324
00:14:44,050 --> 00:14:47,630
and many times it hackers
have revealed email address,

325
00:14:47,630 --> 00:14:51,939
colon password or password
hash from that organization.

326
00:14:51,940 --> 00:14:55,630
And most of your users, yes, your users,

327
00:14:55,630 --> 00:14:57,980
probably only have so many passwords

328
00:14:57,980 --> 00:15:00,710
and let's be honest, it's
probably closer to one

329
00:15:00,710 --> 00:15:01,900
than we would like.

330
00:15:01,900 --> 00:15:03,199
So the idea of credential stuffing

331
00:15:03,200 --> 00:15:06,490
is taking these known breached
credentials and stuffing them

332
00:15:06,490 --> 00:15:09,750
into some single factor
authentication service.

333
00:15:09,750 --> 00:15:11,810
There's a whole other
presentation I've done

334
00:15:11,810 --> 00:15:12,642
on credential stuffing,

335
00:15:12,643 --> 00:15:15,180
so I have the link in
the slide notes for that

336
00:15:15,180 --> 00:15:17,630
which has a video associated as well.

337
00:15:17,630 --> 00:15:19,830
Another major problem
when I come across in it,

338
00:15:19,830 --> 00:15:22,710
literally every penetration test I do,

339
00:15:22,710 --> 00:15:25,230
is some publicly accessible file share

340
00:15:25,230 --> 00:15:28,670
that has some very sensitive
information inside.

341
00:15:28,670 --> 00:15:30,160
Why does this happen?

342
00:15:30,160 --> 00:15:32,630
Well, we have departments

343
00:15:32,630 --> 00:15:35,840
that have their own
departmental shares, of course,

344
00:15:35,840 --> 00:15:37,960
but you have this issue of I need to share

345
00:15:37,960 --> 00:15:40,960
across multiple departments
and you might think,

346
00:15:40,960 --> 00:15:43,380
okay, so every pairing of departments,

347
00:15:43,380 --> 00:15:45,730
we're gonna create a file share for them.

348
00:15:45,730 --> 00:15:47,377
Oh, but wait, sometimes
we need three departments

349
00:15:47,377 --> 00:15:49,180
to share some files.

350
00:15:49,180 --> 00:15:50,109
So in practice,

351
00:15:50,110 --> 00:15:52,820
what happens in every
penetration test I've done,

352
00:15:52,820 --> 00:15:57,820
is there's some number of
company-wide file shares

353
00:15:58,070 --> 00:16:00,450
that everyone can access

354
00:16:00,450 --> 00:16:02,640
and people start treating this file share

355
00:16:02,640 --> 00:16:04,750
as if it was fairly protected

356
00:16:04,750 --> 00:16:07,257
and have things like credentials inside,

357
00:16:07,257 --> 00:16:09,530
sometimes I've seen organizations treat it

358
00:16:09,530 --> 00:16:13,689
as your user's home directory,
your redirected profile,

359
00:16:13,690 --> 00:16:15,057
but it's not actually redirected,

360
00:16:15,057 --> 00:16:18,090
it's just that everyone
makes their own folder

361
00:16:18,090 --> 00:16:20,110
under some share to work with.

362
00:16:20,110 --> 00:16:22,370
So I'll talk through some of the defenses,

363
00:16:22,370 --> 00:16:24,780
some of how I will search for these

364
00:16:24,780 --> 00:16:27,600
when we get to the apply
section, don't you worry.

365
00:16:27,600 --> 00:16:31,390
All right, next up DNS Fallback Abuse.

366
00:16:31,390 --> 00:16:34,330
So we look up host names, right?

367
00:16:34,330 --> 00:16:38,220
I wanna connect to the
file share on file one

368
00:16:38,220 --> 00:16:40,360
or whatever the computer name is,

369
00:16:40,360 --> 00:16:42,410
but your computer does
not connect to names,

370
00:16:42,410 --> 00:16:45,860
it connects to IP, B4 or V6 addresses.

371
00:16:45,860 --> 00:16:48,970
And DNS is what we use
to look up those names,

372
00:16:48,970 --> 00:16:51,260
resolve an address and connect,

373
00:16:51,260 --> 00:16:53,840
but if there's a failed DNS request

374
00:16:53,840 --> 00:16:56,230
from any of your machines,

375
00:16:56,230 --> 00:16:59,070
then Windows, before just giving up,

376
00:16:59,070 --> 00:17:02,130
will actually do one of a
couple of different protocols

377
00:17:02,130 --> 00:17:04,480
and essentially broadcast,

378
00:17:04,480 --> 00:17:08,050
hey, has anybody heard
of this old server name?

379
00:17:08,050 --> 00:17:11,300
'Cause plenty of endpoint agents
will try to look things up

380
00:17:11,300 --> 00:17:13,780
while running as the
user, trying to get access

381
00:17:13,780 --> 00:17:16,629
to that old server or typos,

382
00:17:16,630 --> 00:17:18,540
typos certainly happen as well,

383
00:17:18,540 --> 00:17:20,109
from the user perspective.

384
00:17:20,109 --> 00:17:22,839
You don't get prompted for
your credentials every time

385
00:17:22,839 --> 00:17:25,709
you try to log on to some
internal file server.

386
00:17:25,710 --> 00:17:28,170
No, that's what single sign-on is for.

387
00:17:28,170 --> 00:17:30,770
Well, single sign-on can also be abused

388
00:17:30,770 --> 00:17:32,300
from the attacker perspective.

389
00:17:32,300 --> 00:17:36,169
So once the attacker has
gained internal network access,

390
00:17:36,170 --> 00:17:38,520
they can abuse this DNS fallback

391
00:17:38,520 --> 00:17:40,430
and there's a number of
tools to help us with this

392
00:17:40,430 --> 00:17:45,240
as an attacker between an
invade and responder as well.

393
00:17:45,240 --> 00:17:49,530
Another common issue is
look, printers in general

394
00:17:49,530 --> 00:17:52,350
and all the IT people
groan simultaneously,

395
00:17:52,350 --> 00:17:55,169
and yeah, these MFPs,
multi-function printers.

396
00:17:55,170 --> 00:17:58,370
Oftentimes they're
configured to, for example,

397
00:17:58,370 --> 00:18:01,340
share or save your scanned document

398
00:18:01,340 --> 00:18:03,550
to some file share, right?

399
00:18:03,550 --> 00:18:07,240
Or maybe send an email out from this MFP.

400
00:18:07,240 --> 00:18:09,860
That means in practice,
they are configured

401
00:18:09,860 --> 00:18:11,467
with some credentials, some valid,

402
00:18:11,468 --> 00:18:14,350
active directory credentials.

403
00:18:14,350 --> 00:18:18,070
Problem is, these MFPs have web servers

404
00:18:18,070 --> 00:18:22,629
that anyone with internal
network access can reach.

405
00:18:22,630 --> 00:18:24,330
So there's a number of ways to abuse this.

406
00:18:24,330 --> 00:18:27,710
Sometimes you can just unhide
the asterisks of the password

407
00:18:27,710 --> 00:18:31,490
or export the backup
or worst case scenario,

408
00:18:31,490 --> 00:18:33,700
as an attacker is point to the server,

409
00:18:33,700 --> 00:18:36,920
the LDAP server, active
directory server at yourself

410
00:18:36,920 --> 00:18:41,560
and the hijack that inbound
authentication request, right?

411
00:18:41,560 --> 00:18:43,730
So next issue is Kerberoasting.

412
00:18:43,730 --> 00:18:46,210
Wait, Kerberoasting is hard.

413
00:18:46,210 --> 00:18:47,480
Let's talk about normal

414
00:18:47,480 --> 00:18:50,060
active directory login process first,

415
00:18:50,060 --> 00:18:52,770
because there's a lot of moving parts.

416
00:18:52,770 --> 00:18:56,290
So first Kerberos itself
is named after Cerberus.

417
00:18:56,290 --> 00:18:58,500
That's the three-headed guard dog of Hades

418
00:18:58,500 --> 00:19:01,240
and I like that Cerberus as the name,

419
00:19:01,240 --> 00:19:04,230
because each of those
three heads of Kerberos

420
00:19:04,230 --> 00:19:06,690
represent one of the three major roles

421
00:19:06,690 --> 00:19:09,430
we have to work with
inside of Kerberos actions.

422
00:19:09,430 --> 00:19:11,544
And by the way, Kerberos exists outside

423
00:19:11,544 --> 00:19:14,860
of active directory
directory services, right?

424
00:19:14,860 --> 00:19:16,439
There's MIT Kerberos.

425
00:19:16,440 --> 00:19:18,720
But for the most part,
when you hear Kerberos,

426
00:19:18,720 --> 00:19:21,950
you're probably talking about
on-prem active directory

427
00:19:21,950 --> 00:19:25,760
whose full name is active
directory, directory services.

428
00:19:25,760 --> 00:19:28,560
Inside of active directory
inside of Kerberos,

429
00:19:28,560 --> 00:19:30,929
the most common scenario
we're gonna talk about

430
00:19:30,930 --> 00:19:33,720
is a client who wants to gain access

431
00:19:33,720 --> 00:19:36,020
to a service of some kind

432
00:19:36,020 --> 00:19:39,600
and they both trust some domain controller

433
00:19:39,600 --> 00:19:40,860
and these services, right,

434
00:19:40,860 --> 00:19:43,570
each computer could have
multiple services registered

435
00:19:43,570 --> 00:19:46,280
like a Microsoft SQL
server and a file server

436
00:19:46,280 --> 00:19:48,480
on the same box or a print server,

437
00:19:48,480 --> 00:19:50,770
as well as a file server, et cetera.

438
00:19:50,770 --> 00:19:54,020
But yes, you connect to
a service, not a server.

439
00:19:54,020 --> 00:19:57,060
So let's talk about each
of those three roles

440
00:19:57,060 --> 00:20:00,379
and each of those three
roles has a secret.

441
00:20:00,380 --> 00:20:03,520
The client's secret like username, Jeff,

442
00:20:03,520 --> 00:20:06,379
is derived from Jeff's password.

443
00:20:06,380 --> 00:20:08,910
Specifically, we use the
actual password hash.

444
00:20:08,910 --> 00:20:10,070
There are a few forms of it,

445
00:20:10,070 --> 00:20:13,530
but your password hash is a
thing that authenticates you,

446
00:20:13,530 --> 00:20:14,790
not the password.

447
00:20:14,790 --> 00:20:17,927
This is why as the hash
works, I digress, right?

448
00:20:17,927 --> 00:20:20,889
Domain controllers have a
very special secret account

449
00:20:20,890 --> 00:20:24,160
and that's the krbtgt.

450
00:20:24,160 --> 00:20:25,260
You may hear this pronounced

451
00:20:25,260 --> 00:20:29,670
as KRBtgt account password hash, right?

452
00:20:29,670 --> 00:20:33,050
So it encrypts a portion of
this ticket granting ticket.

453
00:20:33,050 --> 00:20:36,060
Don't worry, we'll talk about
that here shortly, all right?

454
00:20:36,060 --> 00:20:38,600
And the service's secret is derived

455
00:20:38,600 --> 00:20:40,879
from whatever the service's user

456
00:20:40,880 --> 00:20:43,240
or computer account password is.

457
00:20:43,240 --> 00:20:46,120
Yes, computer accounts
are domain accounts.

458
00:20:46,120 --> 00:20:48,459
They aren't a member of domain users,

459
00:20:48,460 --> 00:20:50,100
but they're a member of domain computers

460
00:20:50,100 --> 00:20:52,500
and they are authenticated users.

461
00:20:52,500 --> 00:20:55,160
They really do have associated passwords

462
00:20:55,160 --> 00:20:56,600
and password hashes.

463
00:20:56,600 --> 00:20:59,408
So if I connect to a service

464
00:20:59,408 --> 00:21:03,388
associated with a computer
then I'm connecting to

465
00:21:03,388 --> 00:21:07,510
a service whose computer
password forms that secret.

466
00:21:07,510 --> 00:21:10,129
Let's see how those
secrets are used first.

467
00:21:10,130 --> 00:21:13,320
First of all, this is the normal flow.

468
00:21:13,320 --> 00:21:16,290
Don't worry, I just felt you
freaking out for a moment.

469
00:21:16,290 --> 00:21:17,680
We'll talk through each step.

470
00:21:17,680 --> 00:21:20,020
We have three major flows to work with.

471
00:21:20,020 --> 00:21:22,560
The first one is circled on this slide,

472
00:21:22,560 --> 00:21:24,990
the initial log on, right?

473
00:21:24,990 --> 00:21:26,170
And by the way, this is coming

474
00:21:26,170 --> 00:21:29,481
from a great YouTube video
linked at the bottom,

475
00:21:29,481 --> 00:21:32,860
it's a great explanation, but
let's give some analogies.

476
00:21:32,860 --> 00:21:35,129
I love a good analogy.

477
00:21:35,130 --> 00:21:37,730
All right, steps one and
two from that prior slide

478
00:21:37,730 --> 00:21:40,260
are logging on, right?

479
00:21:40,260 --> 00:21:43,107
You prove that you have
access to some user account

480
00:21:43,107 --> 00:21:45,220
and this is what happens behind the scenes

481
00:21:45,220 --> 00:21:49,000
when you connect to a
domain joined machine,

482
00:21:49,000 --> 00:21:50,030
CONTROL + ALT + DELETE,

483
00:21:50,030 --> 00:21:52,170
enter your username and your password.

484
00:21:52,170 --> 00:21:56,320
Behind the scenes your computer
is doing this step one,

485
00:21:56,320 --> 00:21:59,879
proving access to your password hash.

486
00:21:59,880 --> 00:22:01,792
Technically it's encrypting a user,

487
00:22:01,792 --> 00:22:04,570
a timestamp with your hash,

488
00:22:04,570 --> 00:22:07,439
presenting that to the domain controller.

489
00:22:07,440 --> 00:22:08,920
And from the domain controller,

490
00:22:08,920 --> 00:22:12,730
you get this thing called
a ticket granting ticket.

491
00:22:12,730 --> 00:22:14,710
And this is where I'm
gonna introduce the analogy

492
00:22:14,710 --> 00:22:16,570
of the magic band, right?

493
00:22:16,570 --> 00:22:19,429
At Disney World, you do
not prove your identity

494
00:22:19,430 --> 00:22:23,740
for each and every transaction,
you prove your identity once

495
00:22:23,740 --> 00:22:25,710
when you're checking in at the first day

496
00:22:25,710 --> 00:22:29,730
and you get this token,
this magic band that you use

497
00:22:29,730 --> 00:22:30,870
for everything inside,

498
00:22:30,870 --> 00:22:32,610
whether you're walking up to a ride

499
00:22:32,610 --> 00:22:35,530
or trying to purchase something
internally, all right?

500
00:22:35,530 --> 00:22:37,910
So by the way, that means if I gain access

501
00:22:37,910 --> 00:22:39,760
to someone's magic band,

502
00:22:39,760 --> 00:22:43,220
I can take actions as them, right?

503
00:22:43,220 --> 00:22:46,670
So let's look through
the next steps, right?

504
00:22:46,670 --> 00:22:47,770
Steps three and four.

505
00:22:47,770 --> 00:22:49,940
These are repeated multiple times.

506
00:22:49,940 --> 00:22:52,460
Like for example, if I logged on,

507
00:22:52,460 --> 00:22:55,800
continue that analogy of,
well CONTROL + ALT + DELETE,

508
00:22:55,800 --> 00:22:59,510
username and password and you've logged on

509
00:22:59,510 --> 00:23:03,620
and you find out that you
have a redirected profile.

510
00:23:03,620 --> 00:23:05,360
So even though you've logged on talking

511
00:23:05,360 --> 00:23:06,429
to a domain controller,

512
00:23:06,430 --> 00:23:08,340
you need to go talk to a file server

513
00:23:08,340 --> 00:23:10,790
to load that mapped drive letter,

514
00:23:10,790 --> 00:23:13,590
that redirected profile, right?

515
00:23:13,590 --> 00:23:16,629
And in the physical
world at Magic Kingdom,

516
00:23:16,630 --> 00:23:20,660
in order to go on a ride, you
would present your magic band,

517
00:23:20,660 --> 00:23:22,959
your ticket granting
ticket equivalent, right,

518
00:23:22,959 --> 00:23:25,900
'cause it's a ticket that
grants other tickets.

519
00:23:25,900 --> 00:23:29,130
It's a ticket that grants ride tickets,

520
00:23:29,130 --> 00:23:31,308
service tickets, it's how it's node inside

521
00:23:31,308 --> 00:23:34,000
of active directory in Kerberos, right?

522
00:23:34,000 --> 00:23:34,892
And usually you hear this referred

523
00:23:34,892 --> 00:23:38,390
to just as a service ticket
and this service ticket,

524
00:23:38,390 --> 00:23:42,060
by the way, you're still just
talking between yourself,

525
00:23:42,060 --> 00:23:43,730
the client and the domain controller,

526
00:23:43,730 --> 00:23:46,690
but the file server, in this example,

527
00:23:46,690 --> 00:23:51,690
the service ticket can be
validated by that file server,

528
00:23:52,270 --> 00:23:56,139
because the domain controller
has everybody's secrets.

529
00:23:56,140 --> 00:23:59,300
That's how we could log in
in step one, by the way,

530
00:23:59,300 --> 00:24:01,690
because I prove access to a password

531
00:24:01,690 --> 00:24:03,470
or password hash more properly

532
00:24:03,470 --> 00:24:06,740
and the domain controller
has my secret as well.

533
00:24:06,740 --> 00:24:09,430
Domain controllers have
everybody's secrets.

534
00:24:09,430 --> 00:24:11,710
So that service ticket that you get

535
00:24:11,710 --> 00:24:13,540
has a portion that's encrypted

536
00:24:13,540 --> 00:24:17,020
with these services owned
account password hash,

537
00:24:17,020 --> 00:24:18,889
so that the service can verify it.

538
00:24:18,890 --> 00:24:21,430
But let's get into that, right?

539
00:24:21,430 --> 00:24:24,650
Now, the domain controller
is happy to hand you

540
00:24:24,650 --> 00:24:27,300
a service ticket for every service, right?

541
00:24:27,300 --> 00:24:31,780
Your magic band doesn't fail
to let you walk up to any ride,

542
00:24:31,780 --> 00:24:35,920
but authorization, right,
what you're allowed to do,

543
00:24:35,920 --> 00:24:38,970
does depend on that target service.

544
00:24:38,970 --> 00:24:40,740
Domain controllers for the most part

545
00:24:40,740 --> 00:24:43,980
care about authentication, who you are,

546
00:24:43,980 --> 00:24:45,910
not authorization, right?

547
00:24:45,910 --> 00:24:48,030
This is built for scalability

548
00:24:48,030 --> 00:24:52,270
and everything in Kerberos
is designed for scalability.

549
00:24:52,270 --> 00:24:56,060
So that service ticket,
that ride ticket that I got,

550
00:24:56,060 --> 00:24:58,770
I can then present that to the file server

551
00:24:58,770 --> 00:25:01,920
when I'm actually using the service

552
00:25:01,920 --> 00:25:03,400
and the service can validate,

553
00:25:03,400 --> 00:25:06,570
yup, this must've come
from the domain controller,

554
00:25:06,570 --> 00:25:10,463
'cause it's signed with my
own account password hash.

555
00:25:11,490 --> 00:25:13,270
So they can validate that it's correct,

556
00:25:13,270 --> 00:25:16,540
because again, the domain
controller has everybody's secrets

557
00:25:16,540 --> 00:25:19,300
and you, of course couldn't
forge your own magic band

558
00:25:19,300 --> 00:25:21,286
or your service to get
because that involves secrets

559
00:25:21,286 --> 00:25:23,500
that you don't have.

560
00:25:23,500 --> 00:25:28,290
Oh, wait, if you had that
very special account, krbtgt,

561
00:25:29,340 --> 00:25:32,740
that's the shared secret
that domain controllers use

562
00:25:32,740 --> 00:25:35,710
to create and validate magic bands,

563
00:25:35,710 --> 00:25:37,290
tickets granting tickets.

564
00:25:37,290 --> 00:25:40,330
So if you've already compromised
that environment, right,

565
00:25:40,330 --> 00:25:42,129
gain a domain admin,

566
00:25:42,130 --> 00:25:44,940
dumped those credentials
via a DC sync or gain access

567
00:25:44,940 --> 00:25:48,970
to a improperly secured
domain controller backup

568
00:25:48,970 --> 00:25:51,540
if you've gained access to that password

569
00:25:51,540 --> 00:25:53,149
or properly, password hash,

570
00:25:53,150 --> 00:25:54,880
you can make your own
ticket granting tickets,

571
00:25:54,880 --> 00:25:57,330
you're skipping the log-on

572
00:25:57,330 --> 00:26:00,149
and just moving on to service
tickets and using services.

573
00:26:00,150 --> 00:26:03,080
You can claim to be
whoever you want to be.

574
00:26:03,080 --> 00:26:05,949
You can forge your own magic bands

575
00:26:05,950 --> 00:26:08,264
and look, golden tickets
seems to be more valuable

576
00:26:08,264 --> 00:26:12,590
than a silver ticket, but a silver ticket

577
00:26:12,590 --> 00:26:15,240
is printing your own service ticket,

578
00:26:15,240 --> 00:26:17,847
'cause we said that a service ticket

579
00:26:17,847 --> 00:26:20,500
has a portion that is encrypted,

580
00:26:20,500 --> 00:26:22,910
but with these services
owned account password

581
00:26:22,910 --> 00:26:24,370
is their own secret.

582
00:26:24,370 --> 00:26:27,000
So if I've already
compromised that server,

583
00:26:27,000 --> 00:26:30,530
I can walk up to that service
sometime in the future

584
00:26:30,530 --> 00:26:35,280
and forge whatever service
ticket I want, all right.

585
00:26:35,280 --> 00:26:38,149
And by default, servers don't validate

586
00:26:38,150 --> 00:26:39,580
their service tickets back to the domain,

587
00:26:39,580 --> 00:26:41,590
'cause they wanna ask if it's legit.

588
00:26:41,590 --> 00:26:42,597
So you don't actually need

589
00:26:42,597 --> 00:26:45,850
the KRBtgt account password
hash for a silver ticket.

590
00:26:45,850 --> 00:26:47,311
You just need to have
previously compromised

591
00:26:47,311 --> 00:26:49,600
that one server.

592
00:26:49,600 --> 00:26:52,040
And this finally brings
us to Kerberoasting.

593
00:26:52,040 --> 00:26:55,790
And I start off with the
Kerberoasting tl;dr, right?

594
00:26:55,790 --> 00:26:59,740
Any user account with a registered service

595
00:26:59,740 --> 00:27:02,270
has effectively no lockout policy,

596
00:27:02,270 --> 00:27:03,870
which is rather terrifying, right?

597
00:27:03,870 --> 00:27:05,739
A lockout policy is what stops people

598
00:27:05,740 --> 00:27:09,020
from doing hundreds or
thousands of guesses,

599
00:27:09,020 --> 00:27:11,600
because out of my top million guesses,

600
00:27:11,600 --> 00:27:14,090
it's pretty likely that I'll
get a significant number

601
00:27:14,090 --> 00:27:17,459
of user accounts or
their passwords, right?

602
00:27:17,460 --> 00:27:21,720
So these user accounts
with a registered service

603
00:27:21,720 --> 00:27:23,910
are called Kerberoastable,

604
00:27:23,910 --> 00:27:26,209
because remember, domain
controllers will happily

605
00:27:26,209 --> 00:27:30,010
give you a service ticket
for any registered service

606
00:27:30,010 --> 00:27:31,120
in the domain.

607
00:27:31,120 --> 00:27:33,739
Now, there's lots of ways
to register services.

608
00:27:33,740 --> 00:27:36,450
Each computer account gets a file service,

609
00:27:36,450 --> 00:27:38,760
essentially registered by default,

610
00:27:38,760 --> 00:27:42,260
user accounts do not have
registered services by default,

611
00:27:42,260 --> 00:27:44,020
but there's all sorts of ways

612
00:27:44,020 --> 00:27:46,840
that admins will install services

613
00:27:46,840 --> 00:27:49,179
or register services to active directory.

614
00:27:49,180 --> 00:27:52,000
Easy example is Microsoft SQL server.

615
00:27:52,000 --> 00:27:54,707
When you're installing it, the
SQL server wants to register

616
00:27:54,707 --> 00:27:57,700
an active directory, so that
people know where to find it

617
00:27:57,700 --> 00:27:59,430
and can get a service ticket for it

618
00:27:59,430 --> 00:28:01,090
and the easiest way to do that,

619
00:28:01,090 --> 00:28:04,000
is the user account who
installed Microsoft SQL server

620
00:28:04,000 --> 00:28:06,230
can register it using
their own user account,

621
00:28:06,230 --> 00:28:08,360
which is likely domain admin.

622
00:28:08,360 --> 00:28:10,870
If I can take unlimited guesses

623
00:28:10,870 --> 00:28:15,010
as to a domain admin's account
out of the first few billion,

624
00:28:15,010 --> 00:28:17,390
I have a significant chance of guessing.

625
00:28:17,390 --> 00:28:20,700
Now, the only problem with
the Kerberoasting tl;dr,

626
00:28:20,700 --> 00:28:23,930
no lockout policy, is that
the lockout policy implies

627
00:28:23,930 --> 00:28:26,490
that it's online password guessing.

628
00:28:26,490 --> 00:28:27,323
This is actually,

629
00:28:27,323 --> 00:28:31,270
Kerberoasting is an
offline password cracking.

630
00:28:31,270 --> 00:28:33,100
So once I have that service ticket,

631
00:28:33,100 --> 00:28:35,409
I can take a guess as to the password,

632
00:28:35,410 --> 00:28:38,257
get the hash for that
guess as to the password,

633
00:28:38,257 --> 00:28:41,250
and attempt to decrypt that one portion

634
00:28:41,250 --> 00:28:43,530
of the service tickets that has,

635
00:28:43,530 --> 00:28:44,976
what it has been encrypted with,

636
00:28:44,977 --> 00:28:47,210
the services owned password hash.

637
00:28:47,210 --> 00:28:49,696
If I'm successful and
then I had to have guessed

638
00:28:49,696 --> 00:28:53,010
the right password, derive
the right password hash,

639
00:28:53,010 --> 00:28:54,440
otherwise I can just repeat

640
00:28:54,440 --> 00:28:56,580
and that's all on my own hardware,

641
00:28:56,580 --> 00:28:58,649
my own password cracking rig.

642
00:28:58,650 --> 00:29:02,640
It's an offline attack after
that initial service attack.

643
00:29:02,640 --> 00:29:05,460
So there's been plenty of people

644
00:29:05,460 --> 00:29:09,384
who will point out this latest
craze and don't get me wrong,

645
00:29:09,384 --> 00:29:13,140
I've fallen for the shiny
blinking box a time or two,

646
00:29:13,140 --> 00:29:14,430
but I love the analogy,

647
00:29:14,430 --> 00:29:16,620
David Weston over at
Microsoft made this one,

648
00:29:16,620 --> 00:29:20,330
that people want some
magical cure-all pill.

649
00:29:20,330 --> 00:29:23,330
I'm sorry, preventive
and detective controls

650
00:29:23,330 --> 00:29:26,060
are the equivalent of diet and exercise.

651
00:29:26,060 --> 00:29:28,800
We're still looking for a
magical pill that you can take

652
00:29:28,800 --> 00:29:30,430
and replace diet and exercise

653
00:29:30,430 --> 00:29:34,050
and we're still back down
to the fundamentals work,

654
00:29:34,050 --> 00:29:36,060
preventive and detective controls.

655
00:29:36,060 --> 00:29:38,330
So let's get into the application.

656
00:29:38,330 --> 00:29:41,300
For Kerberoasting, it's
really easy to search

657
00:29:41,300 --> 00:29:44,020
your environment for user services,

658
00:29:44,020 --> 00:29:45,660
with sorry, user accounts,

659
00:29:45,660 --> 00:29:48,620
with registered services,
there's a utility called Rubius,

660
00:29:48,620 --> 00:29:50,300
that can do exactly that.

661
00:29:50,300 --> 00:29:53,137
It can even give you a
crackable output format.

662
00:29:53,137 --> 00:29:57,590
A lot of attackers are using
that tool or very similar.

663
00:29:57,590 --> 00:29:59,189
The issue as we discussed,

664
00:29:59,190 --> 00:30:00,962
is that attackers can
take unlimited guesses

665
00:30:00,962 --> 00:30:04,017
as to the password, so you
want a really good password,

666
00:30:04,017 --> 00:30:05,770
it's what it comes down to.

667
00:30:05,770 --> 00:30:08,389
You can make a fine-grained
password policy.

668
00:30:08,390 --> 00:30:12,040
If it's random, 15 plus characters
is good, mathematically.

669
00:30:12,040 --> 00:30:16,629
If it's human generated, add
some more, 20 plus at least

670
00:30:16,630 --> 00:30:19,780
and then apply that
fine-grained password policy.

671
00:30:19,780 --> 00:30:21,740
This means you can have specific users

672
00:30:21,740 --> 00:30:24,800
or groups with their own
password policy, by the way.

673
00:30:24,800 --> 00:30:28,360
And look, you can audit these
Kerberoastable password hashes

674
00:30:28,360 --> 00:30:31,197
and prioritize the ones
that are crackable,

675
00:30:31,198 --> 00:30:34,800
but that gets a little bit
more complicated, right?

676
00:30:34,800 --> 00:30:36,560
And then over a longer period of time,

677
00:30:36,560 --> 00:30:38,100
let's say the next six months,

678
00:30:38,100 --> 00:30:41,240
figuring out where these services
are actually used, right,

679
00:30:41,240 --> 00:30:45,220
looking for event log 4624.

680
00:30:45,220 --> 00:30:48,020
Look, if it's not used over
a longer period of time,

681
00:30:48,020 --> 00:30:50,389
you can remove that registered service.

682
00:30:50,390 --> 00:30:53,010
That user account is no
longer Kerberoastable.

683
00:30:53,010 --> 00:30:54,650
Problem solved, right?

684
00:30:54,650 --> 00:30:56,820
And if it was used and something breaks,

685
00:30:56,820 --> 00:30:58,810
you can re-register
the exact same service.

686
00:30:58,810 --> 00:31:01,320
It's easy to back off from that.

687
00:31:01,320 --> 00:31:04,450
Otherwise, if you do need that
Kerberoastable user account

688
00:31:04,450 --> 00:31:05,760
and the associated service,

689
00:31:05,760 --> 00:31:07,400
then you could have reset the password

690
00:31:07,400 --> 00:31:10,220
to meet the new
fine-grained password policy

691
00:31:10,220 --> 00:31:15,040
or you can migrate to a
managed service account.

692
00:31:15,040 --> 00:31:16,780
This is something where
a active directory,

693
00:31:16,780 --> 00:31:19,250
domain controllers, manage the password,

694
00:31:19,250 --> 00:31:22,347
have really good entropy and
rotate them automatically,

695
00:31:22,347 --> 00:31:24,750
essentially computer accounts gain access

696
00:31:24,750 --> 00:31:28,478
to a given associated
password for a user account.

697
00:31:28,478 --> 00:31:30,960
If your password spraying,
four words, right,

698
00:31:30,960 --> 00:31:35,260
Azure AD Password Protection
is an amazing capability

699
00:31:35,260 --> 00:31:36,770
that Microsoft has introduced.

700
00:31:36,770 --> 00:31:39,440
So they have their own
list of banned passwords,

701
00:31:39,440 --> 00:31:41,720
essentially passwords that
have already been known

702
00:31:41,720 --> 00:31:44,230
to be compromised, which
NIST requires you to check,

703
00:31:44,230 --> 00:31:47,250
by the way and you can
also add your own list

704
00:31:47,250 --> 00:31:50,680
of up to 1000 custom banned passwords,

705
00:31:50,680 --> 00:31:52,500
like variations of the word password

706
00:31:52,500 --> 00:31:56,430
or welcome or seasons or
the company name itself.

707
00:31:56,430 --> 00:31:58,420
So what is the actual steps behind it?

708
00:31:58,420 --> 00:32:00,750
You install that small agent

709
00:32:00,750 --> 00:32:03,590
that you probably already have installed

710
00:32:03,590 --> 00:32:06,280
on your domain controllers,
all of them on prem.

711
00:32:06,280 --> 00:32:08,420
You start in audit mode
where you get a warning.

712
00:32:08,420 --> 00:32:11,040
This password would have
been blocked for a while

713
00:32:11,040 --> 00:32:14,940
and then you make the switch
at some point to enforced mode

714
00:32:14,940 --> 00:32:17,115
where users trying to set a known,

715
00:32:17,115 --> 00:32:21,270
bad known compromised
password will get a warning,

716
00:32:21,270 --> 00:32:23,889
right and not be able
to set that password.

717
00:32:23,890 --> 00:32:25,540
So for printers,

718
00:32:25,540 --> 00:32:28,480
this is one where I've
gone a little bit further,

719
00:32:28,480 --> 00:32:32,550
because step one is find all
of your internal subnets.

720
00:32:32,550 --> 00:32:34,139
You may know some of them offhand

721
00:32:34,140 --> 00:32:37,080
and your network admins
for each physical location

722
00:32:37,080 --> 00:32:39,720
or each subsidiary may
know some of theirs,

723
00:32:39,720 --> 00:32:42,340
but here's the methods I use.

724
00:32:42,340 --> 00:32:45,800
I look for domain registered DHCP servers

725
00:32:45,800 --> 00:32:47,970
and I get their ranges, right?

726
00:32:47,970 --> 00:32:50,310
And there's a PowerShell
script that I've shared

727
00:32:50,310 --> 00:32:52,840
in the slide notes here
called, get internal subnets,

728
00:32:52,840 --> 00:32:57,840
that does that and I
also find the IP address

729
00:32:57,920 --> 00:33:01,140
associated with every
single domain joined host

730
00:33:01,140 --> 00:33:05,060
and take the slash 24
side rotation of that.

731
00:33:05,060 --> 00:33:07,120
So even if 1 and 2168,

732
00:33:07,120 --> 00:33:11,280
1.100 was never mentioned in a DHCP range.

733
00:33:11,280 --> 00:33:13,810
If I find one system with that IP,

734
00:33:13,810 --> 00:33:18,280
I'll still scan one and 2168 1.0/24.

735
00:33:18,280 --> 00:33:22,310
And then scan using and
map each of those subnets,

736
00:33:22,310 --> 00:33:24,970
looking for web servers.

737
00:33:24,970 --> 00:33:27,360
Then we take a screenshot,
'cause there's gonna be a lot

738
00:33:27,360 --> 00:33:30,510
of them and triaging is much easier

739
00:33:30,510 --> 00:33:33,440
with Chris Tuncer's
utility called, Eyewitness.

740
00:33:33,440 --> 00:33:35,053
And I have the exact instructions

741
00:33:35,053 --> 00:33:37,890
and links again in these slide notes,

742
00:33:37,890 --> 00:33:41,490
and then you review and
triage those results.

743
00:33:41,490 --> 00:33:44,042
Maybe you can password
protect a given web server,

744
00:33:44,042 --> 00:33:45,861
maybe you can reduce the permissions,

745
00:33:45,862 --> 00:33:50,040
so yes, this user account
that can save to a file share,

746
00:33:50,040 --> 00:33:52,620
maybe it can just save
to the one file share

747
00:33:52,620 --> 00:33:53,760
and not have credentials

748
00:33:53,760 --> 00:33:56,360
that are way more powerful than they need.

749
00:33:56,360 --> 00:33:57,870
And by the way, you're going to find

750
00:33:57,870 --> 00:34:00,770
that a lot of random web servers

751
00:34:00,770 --> 00:34:02,070
throughout your organization,

752
00:34:02,070 --> 00:34:05,020
that you probably don't
have great visibility into,

753
00:34:05,020 --> 00:34:08,969
because I mean, they're not
necessarily domain joined.

754
00:34:08,969 --> 00:34:10,679
They're not necessarily phoning home

755
00:34:10,679 --> 00:34:12,692
to your normal reporting.

756
00:34:13,600 --> 00:34:16,069
All right, so over a
longer period of time,

757
00:34:16,070 --> 00:34:19,460
I'd like you to consider
is also separating out

758
00:34:19,460 --> 00:34:23,100
your printers, your MFPs
to a dedicated VLAN,

759
00:34:23,100 --> 00:34:26,810
dedicated sub-net where
only the print server

760
00:34:26,810 --> 00:34:30,259
can access those print
servers, there's MFPs.

761
00:34:30,260 --> 00:34:31,770
It's really, really nice.

762
00:34:31,770 --> 00:34:35,090
We can just remove some
attack surface entirely,

763
00:34:35,090 --> 00:34:37,940
and even if you have to
allow the print servers

764
00:34:37,940 --> 00:34:40,429
and also this IT subnet over here,

765
00:34:40,429 --> 00:34:42,889
that's still a heck of a
lot better than the default,

766
00:34:42,889 --> 00:34:47,520
which is every internal user
can access all of those MFPs.

767
00:34:47,520 --> 00:34:49,766
All right, next up the file shares

768
00:34:49,766 --> 00:34:52,449
that have some sensitive
information inside.

769
00:34:52,449 --> 00:34:54,089
First of all, just next week,

770
00:34:54,090 --> 00:34:55,290
as soon as you get back,

771
00:34:55,290 --> 00:34:58,310
you can look at a
utility called, Snaffler.

772
00:34:58,310 --> 00:35:00,520
Funny name, amazing results.

773
00:35:00,520 --> 00:35:03,820
So Snaffler searches
for known bad patterns,

774
00:35:03,820 --> 00:35:07,800
like web.config files for IAS web servers

775
00:35:07,800 --> 00:35:09,770
with embedded credentials, right?

776
00:35:09,770 --> 00:35:12,330
There's all sorts of known bad formats

777
00:35:12,330 --> 00:35:14,480
that end up having credentials embedded

778
00:35:14,480 --> 00:35:16,705
or some sensitive information

779
00:35:16,705 --> 00:35:18,319
and then you can start removing

780
00:35:18,320 --> 00:35:21,870
or moving to a secure location
or locking down in place

781
00:35:21,870 --> 00:35:25,109
those sensitive results, all right?

782
00:35:25,110 --> 00:35:27,830
Now, that's the short-term
action you could do.

783
00:35:27,830 --> 00:35:30,330
Long-term, this is gonna
take a little bit longer,

784
00:35:30,330 --> 00:35:33,049
but it's a really good use of your time.

785
00:35:33,050 --> 00:35:35,035
Find open file shares.

786
00:35:35,035 --> 00:35:38,359
Here, I have a screenshot of our view.

787
00:35:38,360 --> 00:35:43,360
That's the find domain share
command, as it's known.

788
00:35:43,520 --> 00:35:44,955
And I have an actual command that I use

789
00:35:44,955 --> 00:35:47,937
for penetration tests to find file shares

790
00:35:47,937 --> 00:35:50,009
that I have access to

791
00:35:50,010 --> 00:35:53,390
and then output them in the
double backslash computer name,

792
00:35:53,390 --> 00:35:55,509
backslash share format

793
00:35:55,510 --> 00:35:56,770
and then I can start looking through them.

794
00:35:56,770 --> 00:35:58,220
Certainly I do some manual,

795
00:35:58,220 --> 00:36:01,089
but there's probably gonna
be a lot to search through.

796
00:36:01,090 --> 00:36:02,790
So one thing I love doing,

797
00:36:02,790 --> 00:36:05,610
is using desktop search applications,

798
00:36:05,610 --> 00:36:08,960
adding those file shares and
have them start to an index.

799
00:36:08,960 --> 00:36:11,837
So you can take local guesses
using your search index

800
00:36:11,837 --> 00:36:14,509
and that indexing process
might take a long time,

801
00:36:14,510 --> 00:36:17,260
it might take a few days,
it might take several weeks.

802
00:36:17,260 --> 00:36:19,310
That's okay, it's going
to be useful for you

803
00:36:19,310 --> 00:36:21,090
for a long time period of time

804
00:36:21,090 --> 00:36:23,350
and you can start to search for patterns

805
00:36:23,350 --> 00:36:26,450
that are more sensitive to
your organization in particular

806
00:36:26,450 --> 00:36:29,649
and by the way, if you
have a template internally,

807
00:36:29,650 --> 00:36:32,370
like not to be shared
outside of this company,

808
00:36:32,370 --> 00:36:34,450
that's a great thing to search for,

809
00:36:34,450 --> 00:36:37,540
'cause an exact string match
is pretty easy to work with.

810
00:36:37,540 --> 00:36:40,070
All right, next up DNS Fallback Abuse.

811
00:36:40,070 --> 00:36:43,230
This is the essentially
broadcast protocols.

812
00:36:43,230 --> 00:36:44,310
You can spot check.

813
00:36:44,310 --> 00:36:49,310
Open up Wireshark, have the
filter LLMNR or NBNS or mDNS.

814
00:36:50,000 --> 00:36:51,940
Link local multicast name resolution

815
00:36:51,940 --> 00:36:55,290
or net bios names service
or a multicast DNS.

816
00:36:55,290 --> 00:36:58,520
Look for those and find
out that when you disable

817
00:36:58,520 --> 00:37:01,140
on a few random IT work stations,

818
00:37:01,140 --> 00:37:03,270
everything works as normal.

819
00:37:03,270 --> 00:37:05,520
It's not going to make a difference.

820
00:37:05,520 --> 00:37:06,353
I'm saying start with IT,

821
00:37:06,353 --> 00:37:09,000
'cause it's usually easiest
to start off with there

822
00:37:09,000 --> 00:37:12,100
and I have some resources in
the slide notes here, as well

823
00:37:12,100 --> 00:37:13,710
as far as fallback abuse.

824
00:37:13,710 --> 00:37:16,820
Next, I mean you can disable,

825
00:37:16,820 --> 00:37:18,720
expand disabling these protocols.

826
00:37:18,720 --> 00:37:20,450
You probably don't need them,

827
00:37:20,450 --> 00:37:22,810
because remember, DNS Fallback means

828
00:37:22,810 --> 00:37:24,970
that DNS has already failed.

829
00:37:24,970 --> 00:37:28,200
So why has DNS failed
and why you're depending

830
00:37:28,200 --> 00:37:29,919
on this fallback protocol?

831
00:37:29,920 --> 00:37:31,920
That's where I think you
should spend your effort,

832
00:37:31,920 --> 00:37:34,350
while you're at it, disabled WPAD,

833
00:37:34,350 --> 00:37:36,317
Windows Proxy Auto Discovery.

834
00:37:36,318 --> 00:37:38,200
It's a bad protocol, right?

835
00:37:38,200 --> 00:37:40,710
Essentially it looks
for the host name, WPAD,

836
00:37:40,710 --> 00:37:43,350
and sends the web traffic
there, that's bad.

837
00:37:43,350 --> 00:37:47,529
Another thing you can add,
is enable SMB sign-in.

838
00:37:47,530 --> 00:37:49,800
It's enabled by the fault
on domain controllers.

839
00:37:49,800 --> 00:37:51,750
It has not been much of an issue

840
00:37:51,750 --> 00:37:53,550
on your domain controllers, right?

841
00:37:53,550 --> 00:37:54,620
You can expand that out

842
00:37:54,620 --> 00:37:57,620
and it protects against SMB relay attacks.

843
00:37:57,620 --> 00:38:01,240
Again, more links to work
with in the slide notes

844
00:38:01,240 --> 00:38:03,390
and lessons learned,

845
00:38:03,390 --> 00:38:05,960
every time the attacker
gains that initial access,

846
00:38:05,960 --> 00:38:08,330
they have internal networks access.

847
00:38:08,330 --> 00:38:09,500
It starts your race.

848
00:38:09,500 --> 00:38:11,910
Your job as a defender is to detect

849
00:38:11,910 --> 00:38:13,799
and eradicate the attacker's presence

850
00:38:13,800 --> 00:38:16,580
before they are able to persist,

851
00:38:16,580 --> 00:38:20,049
gain privileges and accomplish
whatever their goal is.

852
00:38:20,050 --> 00:38:22,180
So you need to understand your own timing.

853
00:38:22,180 --> 00:38:23,950
How long does it take you to detect

854
00:38:23,950 --> 00:38:25,480
and eradicate the attacker?

855
00:38:25,480 --> 00:38:27,800
This type of unit testing
is sometimes referred to

856
00:38:27,800 --> 00:38:30,370
as purple teaming and you'll
also wanna figure out,

857
00:38:30,370 --> 00:38:32,549
how long does it take an attacker to win

858
00:38:32,550 --> 00:38:34,780
and increase that timeframe.

859
00:38:34,780 --> 00:38:36,580
We call that penetration testing

860
00:38:36,580 --> 00:38:39,200
and remediating that low hanging fruit.

861
00:38:39,200 --> 00:38:41,799
So I have some dedicated
time for questions,

862
00:38:41,800 --> 00:38:44,350
but as promised, hi, I'm Jeff McJunkin.

863
00:38:44,350 --> 00:38:46,220
I'm a consultant, a little
bit of a generalist,

864
00:38:46,220 --> 00:38:47,959
but I do have some specialties.

865
00:38:47,960 --> 00:38:49,590
I also teach for the SANS Institute

866
00:38:49,590 --> 00:38:51,370
and own a small class there

867
00:38:51,370 --> 00:38:54,718
and I try very hard to
help companies understand

868
00:38:54,718 --> 00:38:58,089
and then reduce their own realistic risks

869
00:38:58,090 --> 00:38:59,600
from real world breaches.

870
00:38:59,600 --> 00:39:01,720
These slides are online at the URL below.

871
00:39:01,720 --> 00:39:04,850
My email address and
Twitter are online as well.

872
00:39:04,850 --> 00:39:07,330
And I'll leave it on the
questions and answers

873
00:39:07,330 --> 00:39:08,549
for the remainder of my time,

874
00:39:08,550 --> 00:39:12,420
so we can finish out and
present Jeff, not this past Jeff

875
00:39:12,420 --> 00:39:15,810
can start and continue
answering your questions there.

876
00:39:15,810 --> 00:39:17,500
All right, thank you all for joining.

877
00:39:17,500 --> 00:39:18,550
Have a wonderful day.

