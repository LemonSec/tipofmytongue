1
00:00:01,150 --> 00:00:04,380
- Welcome to our talk about
"Leveraging Human Risk Data

2
00:00:04,380 --> 00:00:07,680
to Strengthen Cybersecurity Resilience."

3
00:00:07,680 --> 00:00:09,760
My name is Michelle Valdez.

4
00:00:09,760 --> 00:00:12,290
and I am the chief
information security officer

5
00:00:12,290 --> 00:00:13,703
at OneMain Financial.

6
00:00:14,870 --> 00:00:17,180
- Hi everybody, thank you so
much for being at our talk.

7
00:00:17,180 --> 00:00:18,530
My name is Masha Sedova,

8
00:00:18,530 --> 00:00:21,600
and I am the co-founder
at Elevate Security,

9
00:00:21,600 --> 00:00:24,890
a company focused on helping organizations

10
00:00:24,890 --> 00:00:28,840
measure and influence their
employer risk population

11
00:00:28,840 --> 00:00:29,760
in their organization.

12
00:00:29,760 --> 00:00:31,840
Really excited to talk to you today

13
00:00:31,840 --> 00:00:35,772
about one of my favorite
subjects, which is human risk.

14
00:00:37,640 --> 00:00:39,490
One of the things that
we're gonna be talking

15
00:00:39,490 --> 00:00:43,373
with you today about, is first of all,

16
00:00:45,350 --> 00:00:49,010
what is the role of an
employee in cyber resiliency?

17
00:00:49,010 --> 00:00:52,989
The theme of the conference this year.

18
00:00:52,990 --> 00:00:55,890
And what does it mean to have
a cyber resilient workforce?

19
00:00:57,530 --> 00:01:01,520
And we're also gonna dive
into, how do we get left of?

20
00:01:01,520 --> 00:01:05,489
Shift left of the employee
risk in our organizations,

21
00:01:05,489 --> 00:01:08,000
reducing incidents before they happen,

22
00:01:08,000 --> 00:01:10,883
so that we can actually
create systemic change

23
00:01:10,883 --> 00:01:13,160
in our organizations.

24
00:01:13,160 --> 00:01:14,580
And I already said this
word a couple of times,

25
00:01:14,580 --> 00:01:16,550
we're actually gonna
define what is human risk

26
00:01:16,550 --> 00:01:17,693
and how to measure it.

27
00:01:18,980 --> 00:01:20,820
And one of the things I'm really excited

28
00:01:20,820 --> 00:01:21,779
to share with you all today,

29
00:01:21,780 --> 00:01:24,420
is some new cutting edge research

30
00:01:24,420 --> 00:01:27,670
that we've been able to pull together

31
00:01:27,670 --> 00:01:30,340
through millions of data points

32
00:01:30,340 --> 00:01:31,980
around trends and human risks

33
00:01:31,980 --> 00:01:34,760
that you can apply in your
organizations tomorrow.

34
00:01:34,760 --> 00:01:39,110
And we're also gonna
talk to how organizations

35
00:01:39,110 --> 00:01:41,300
like OneMain Financial,

36
00:01:41,300 --> 00:01:43,240
and Michelle and her team have applied

37
00:01:43,240 --> 00:01:45,190
some of these findings in
their own organization.

38
00:01:45,190 --> 00:01:48,902
So, packed agenda, let's get started.

39
00:01:49,920 --> 00:01:52,100
- There's really not anything that I like

40
00:01:52,100 --> 00:01:54,259
to talk about more than resiliency,

41
00:01:54,260 --> 00:01:56,430
something that I'm
really passionate about.

42
00:01:56,430 --> 00:01:57,660
So, let's talk a little bit

43
00:01:57,660 --> 00:02:00,453
about what we mean about cyber resiliency.

44
00:02:02,410 --> 00:02:06,119
So, resiliency essentially
means minimizing the impact

45
00:02:06,120 --> 00:02:07,650
of any disruption event.

46
00:02:07,650 --> 00:02:09,289
And this starts with ensuring

47
00:02:09,289 --> 00:02:12,970
that you have core cyber
security fundamentals,

48
00:02:12,970 --> 00:02:14,220
which become the foundation

49
00:02:14,220 --> 00:02:16,490
that you build everything else on.

50
00:02:16,490 --> 00:02:20,460
Resiliency is the key to an
effective cybersecurity program,

51
00:02:20,460 --> 00:02:22,950
especially, when that's gonna
bring value to the business.

52
00:02:22,950 --> 00:02:25,679
And one of the most important
critical assets needed

53
00:02:25,680 --> 00:02:29,840
for a solid foundation,
is a strong cyber culture.

54
00:02:29,840 --> 00:02:32,790
This starts with your company's employees.

55
00:02:32,790 --> 00:02:35,390
Don't be with the company
that builds the castle

56
00:02:35,390 --> 00:02:37,950
on shifting sand, because if you do,

57
00:02:37,950 --> 00:02:39,813
it will inevitably fail.

58
00:02:41,420 --> 00:02:43,329
- Yeah. I definitely
don't wanna be that house

59
00:02:43,330 --> 00:02:44,883
on shifting sand.

60
00:02:46,150 --> 00:02:50,090
But one of the things that
I've come to see in my career

61
00:02:50,090 --> 00:02:51,670
and working with dozens of organizations,

62
00:02:51,670 --> 00:02:56,010
is that employee risk, human
risk really is a problem

63
00:02:56,010 --> 00:02:57,929
that we are facing today.

64
00:02:57,930 --> 00:03:00,830
The skittles you on the screen right now,

65
00:03:00,830 --> 00:03:04,620
are from the latest
Verizon data breach report

66
00:03:04,620 --> 00:03:08,470
that took a look at some
of the most common ways

67
00:03:08,470 --> 00:03:09,770
that attackers have been successful

68
00:03:09,770 --> 00:03:11,790
in getting into organizations.

69
00:03:11,790 --> 00:03:13,150
And what they discovered,

70
00:03:13,150 --> 00:03:15,470
was that nearly two thirds of breaches,

71
00:03:15,470 --> 00:03:18,260
tie back directly to human factors,

72
00:03:18,260 --> 00:03:20,160
through attack vectors, like phishing,

73
00:03:20,160 --> 00:03:22,620
password security compromised, malware,

74
00:03:22,620 --> 00:03:24,300
and other categories.

75
00:03:24,300 --> 00:03:29,300
So, yes, it is a problem,
because it is one of the area...

76
00:03:29,870 --> 00:03:32,870
Because ultimately, in
each of these components

77
00:03:32,870 --> 00:03:33,840
that we look at,

78
00:03:33,840 --> 00:03:36,080
there is a human being associated

79
00:03:36,080 --> 00:03:38,170
with making decisions around this.

80
00:03:38,170 --> 00:03:42,923
And as long as we continue
to not address employee risk

81
00:03:42,923 --> 00:03:45,560
and the human component of security,

82
00:03:45,560 --> 00:03:49,250
this will forever be our
soft underbelly of security,

83
00:03:49,250 --> 00:03:51,830
but it is also our greatest opportunity

84
00:03:51,830 --> 00:03:53,390
of transforming the landscape

85
00:03:53,390 --> 00:03:56,003
of how we tackle this threat today.

86
00:03:56,950 --> 00:04:00,089
So, this is one of the most critical areas

87
00:04:00,090 --> 00:04:03,693
I believe of innovating on security today.

88
00:04:06,550 --> 00:04:10,230
- I imagine that everybody
who's in the audience

89
00:04:10,230 --> 00:04:12,269
has felt like this at some point in time,

90
00:04:12,270 --> 00:04:15,700
particularly, as a
cybersecurity organization,

91
00:04:15,700 --> 00:04:18,440
we often can feel at odds with employees.

92
00:04:18,440 --> 00:04:20,250
Like as if we're playing tug of war

93
00:04:20,250 --> 00:04:22,317
on what we allow them to do,

94
00:04:22,317 --> 00:04:24,160
and what they want to do,

95
00:04:24,160 --> 00:04:26,230
and how we enable that.

96
00:04:26,230 --> 00:04:28,680
It's our job as
cybersecurity professionals

97
00:04:28,680 --> 00:04:30,390
to ensure we're protecting the company,

98
00:04:30,390 --> 00:04:32,330
but we cannot do it alone.

99
00:04:32,330 --> 00:04:36,030
So, the only way that you get
to, instead of tug of war,

100
00:04:36,030 --> 00:04:40,729
everybody rowing in the same
direction, is understanding

101
00:04:40,730 --> 00:04:45,400
that these employees are
actually your best asset.

102
00:04:45,400 --> 00:04:47,260
I know a lot of people say that employees

103
00:04:47,260 --> 00:04:50,250
are the biggest risk, but
I actually really believe

104
00:04:50,250 --> 00:04:52,500
that if you take the time to help them

105
00:04:52,500 --> 00:04:55,420
understand what their role
is in protecting the company,

106
00:04:55,420 --> 00:04:58,240
and how everything that
they do on a daily basis

107
00:04:58,240 --> 00:04:59,660
can make a difference,

108
00:04:59,660 --> 00:05:01,180
that can transform our company

109
00:05:01,180 --> 00:05:04,170
to have a strong cyber
resilient workforce.

110
00:05:04,170 --> 00:05:06,590
However, it does take a lot of time,

111
00:05:06,590 --> 00:05:10,099
it takes investment from
you and from your teams,

112
00:05:10,100 --> 00:05:11,400
and it takes measurement,

113
00:05:11,400 --> 00:05:13,900
so that you know that the
things that you're doing,

114
00:05:13,900 --> 00:05:14,733
are the right things,

115
00:05:14,733 --> 00:05:17,560
and that you're putting
the right tools to task,

116
00:05:17,560 --> 00:05:20,720
the right resources going
after the best problems

117
00:05:20,720 --> 00:05:22,420
and the best return on investment.

118
00:05:23,950 --> 00:05:26,670
So, what does it mean to have
a cyber resilient workforce?

119
00:05:26,670 --> 00:05:29,840
It starts with ensuring that
each employee understands

120
00:05:29,840 --> 00:05:32,169
the positive impact that
they can make on the company

121
00:05:32,170 --> 00:05:34,823
when they make good
cybersecurity decisions.

122
00:05:35,820 --> 00:05:38,130
This is something that is
often a mystery employees.

123
00:05:38,130 --> 00:05:39,850
They think that they don't understand

124
00:05:39,850 --> 00:05:41,500
other than what they hear in the news

125
00:05:41,500 --> 00:05:44,050
on any given day of the latest breach,

126
00:05:44,050 --> 00:05:47,250
or how their data has
yet again been stolen

127
00:05:47,250 --> 00:05:50,220
because of information that's been leaked.

128
00:05:50,220 --> 00:05:51,950
But it really isn't a complex thing

129
00:05:51,950 --> 00:05:55,740
if you can break it down in
terms that makes sense to them.

130
00:05:55,740 --> 00:05:57,910
Make it about the things
that they do everyday,

131
00:05:57,910 --> 00:05:59,400
like reading email,

132
00:05:59,400 --> 00:06:02,960
help them understand what a
good this security decision is.

133
00:06:02,960 --> 00:06:05,419
This way, your employees can switch

134
00:06:05,420 --> 00:06:07,650
from being the root of the problem

135
00:06:07,650 --> 00:06:10,400
to an extension of your
cybersecurity team.

136
00:06:10,400 --> 00:06:13,849
And that way, your experts and your team

137
00:06:13,850 --> 00:06:16,300
can shift from focusing on under...

138
00:06:16,300 --> 00:06:20,020
Shift to focusing on understanding
and preventing threats,

139
00:06:20,020 --> 00:06:22,513
not just cleaning up
after employee mistakes.

140
00:06:23,760 --> 00:06:25,840
- So, that's a really critical point

141
00:06:25,840 --> 00:06:26,857
that Michelle just brought up,

142
00:06:26,857 --> 00:06:28,540
and we wanna unpack a little bit more,

143
00:06:28,540 --> 00:06:33,540
because we see this as shifting left

144
00:06:34,540 --> 00:06:37,950
of human risk to actually
create a resilient workforce.

145
00:06:37,950 --> 00:06:40,950
And while that may be a bit of a buzzword

146
00:06:40,950 --> 00:06:42,409
in our industry today,

147
00:06:42,410 --> 00:06:45,930
I wanna pass around a little
bit around what that means,

148
00:06:45,930 --> 00:06:49,200
and how this is incredibly transformative.

149
00:06:49,200 --> 00:06:53,110
So, we all have in our organizations,

150
00:06:53,110 --> 00:06:56,110
employees who make risky
decisions sometimes,

151
00:06:56,110 --> 00:07:01,110
often, benign well intention,
they just may not know better.

152
00:07:01,840 --> 00:07:03,560
And these decisions can include things

153
00:07:03,560 --> 00:07:05,500
like clicking on phishing links,

154
00:07:05,500 --> 00:07:08,603
or accidentally navigating
to risky websites,

155
00:07:09,450 --> 00:07:11,520
downloading pieces of
software that they shouldn't.

156
00:07:11,520 --> 00:07:13,740
And a subset of these decisions,

157
00:07:13,740 --> 00:07:16,130
then ultimately lead to an incident

158
00:07:16,130 --> 00:07:18,740
like account takeover, credential theft,

159
00:07:18,740 --> 00:07:19,930
phishing, ransomware,

160
00:07:19,930 --> 00:07:22,480
things that your incident response team

161
00:07:23,440 --> 00:07:27,660
is then tasked with triaging, cleaning up,

162
00:07:27,660 --> 00:07:29,480
and it starts putting us on this loop

163
00:07:29,480 --> 00:07:32,420
where once we have this
triage, and we're cleaning up,

164
00:07:32,420 --> 00:07:35,170
we're barely keeping up with the incidents

165
00:07:35,170 --> 00:07:36,640
we have coming in.

166
00:07:36,640 --> 00:07:38,900
When a recent report came
out that said something,

167
00:07:38,900 --> 00:07:43,900
44% of all incidents aren't
addressed in the day,

168
00:07:44,260 --> 00:07:45,510
they come in because

169
00:07:47,355 --> 00:07:49,650
there's such a huge backlog.

170
00:07:49,650 --> 00:07:52,080
And we further go down
the list where we find

171
00:07:52,080 --> 00:07:54,270
that we're spending
more and more technology

172
00:07:54,270 --> 00:07:58,849
adding to already a really,
really hefty bloated tech stack,

173
00:07:58,850 --> 00:08:00,710
so there's increased spend.

174
00:08:00,710 --> 00:08:03,549
And what that does is create more alerts

175
00:08:03,550 --> 00:08:07,160
and noise without
actually giving us insight

176
00:08:07,160 --> 00:08:10,490
and signals into where these
incidents are coming from.

177
00:08:10,490 --> 00:08:13,830
And it creates this no end
cycle for our security teams

178
00:08:13,830 --> 00:08:15,909
that is incredibly hard to get out of,

179
00:08:15,910 --> 00:08:17,100
because fundamentally,

180
00:08:17,100 --> 00:08:20,860
when we focus on this
problem at the tail end,

181
00:08:20,860 --> 00:08:23,000
right on the detect and respond,

182
00:08:23,000 --> 00:08:24,830
we're already coming into late.

183
00:08:24,830 --> 00:08:28,010
We're already spending time
on the place, on the cleanup

184
00:08:28,010 --> 00:08:29,750
instead of the prevention,

185
00:08:29,750 --> 00:08:33,159
where a dollar at the beginning
would actually help us

186
00:08:33,159 --> 00:08:35,140
prevent this whole cycle from happening.

187
00:08:35,140 --> 00:08:38,409
And so, the question that we were posing,

188
00:08:38,409 --> 00:08:41,620
is well, how do we stop this
chain reaction from the start?

189
00:08:41,620 --> 00:08:44,490
So, that we understand
which employees are risky,

190
00:08:44,490 --> 00:08:47,720
and how do we minimize the impact

191
00:08:47,720 --> 00:08:50,903
that we can have further down the chain?

192
00:08:53,970 --> 00:08:57,630
- Like Masha said, you
have to shift to the left.

193
00:08:57,630 --> 00:09:01,790
I'm sure that everybody in
here has had to defend budget

194
00:09:01,790 --> 00:09:04,230
or defend asking for budget.

195
00:09:04,230 --> 00:09:06,730
And then asked how do they
get the return on investment?

196
00:09:06,730 --> 00:09:09,450
And that becomes something
that's really a struggle.

197
00:09:09,450 --> 00:09:10,560
Forever, if you edu...

198
00:09:10,560 --> 00:09:12,650
If you invest in educating your employees

199
00:09:12,650 --> 00:09:14,270
and taking the time to teach them

200
00:09:14,270 --> 00:09:16,829
about good security decisions,

201
00:09:16,830 --> 00:09:19,130
you actually can start
to see that value add.

202
00:09:19,130 --> 00:09:21,050
And that's something you can articulate

203
00:09:21,050 --> 00:09:23,109
and share with your executives.

204
00:09:23,110 --> 00:09:26,170
The value add we're seeing,
in making this shift,

205
00:09:26,170 --> 00:09:28,490
is that we're now starting
to spend more of our time

206
00:09:28,490 --> 00:09:31,830
on tuning and tooling, so
that we can defend forward,

207
00:09:31,830 --> 00:09:33,280
and less time on cleaning up.

208
00:09:35,640 --> 00:09:38,170
The way you can
successfully defend forward,

209
00:09:38,170 --> 00:09:40,819
is to take time to understand the risks

210
00:09:40,820 --> 00:09:43,400
your employees are introducing
to your environment,

211
00:09:43,400 --> 00:09:46,819
both at the individual
level and at the team level.

212
00:09:46,820 --> 00:09:48,810
It's with that information,

213
00:09:48,810 --> 00:09:52,609
you can focus your efforts and
reinforce the good behavior

214
00:09:52,610 --> 00:09:54,480
with recognition programs,

215
00:09:54,480 --> 00:09:56,830
and addressed those areas of improvement

216
00:09:56,830 --> 00:09:58,363
with targeted training.

217
00:09:59,380 --> 00:10:01,939
This way, you're teaching
the people who need

218
00:10:01,940 --> 00:10:04,680
to understand what actions
they should be taking

219
00:10:04,680 --> 00:10:06,709
and the impact of those actions,

220
00:10:06,710 --> 00:10:08,570
you're spending your time on them.

221
00:10:08,570 --> 00:10:10,730
And you're giving recognition to those

222
00:10:10,730 --> 00:10:13,040
who are actually taking the right actions

223
00:10:13,040 --> 00:10:15,853
and are actually making
your company more secure.

224
00:10:17,000 --> 00:10:19,410
Also, you gotta put the
right tools in place,

225
00:10:19,410 --> 00:10:22,439
and not just the right tools,
but the right controls,

226
00:10:22,440 --> 00:10:24,480
to help control those riskiest areas.

227
00:10:24,480 --> 00:10:27,490
We're gonna talk about
ways that you can identify

228
00:10:27,490 --> 00:10:30,880
how to best identify your
strengths and improvements

229
00:10:30,880 --> 00:10:32,550
and also help us to do...

230
00:10:32,550 --> 00:10:34,400
Take that information for your tools.

231
00:10:35,250 --> 00:10:39,110
For my company, this is
actually already paid off.

232
00:10:39,110 --> 00:10:43,050
Just an improvement that we've
seen with our phishing tests,

233
00:10:43,050 --> 00:10:47,339
and using that data to give
targeted real-time training

234
00:10:47,340 --> 00:10:51,010
has resulted in not only a
major increase in the reporting

235
00:10:51,010 --> 00:10:52,670
of the phishing tests,

236
00:10:52,670 --> 00:10:55,319
but also a major increase in the reporting

237
00:10:55,320 --> 00:10:57,710
that we're getting on
phishing every single day,

238
00:10:57,710 --> 00:10:59,260
which is making us more secure.

239
00:11:01,620 --> 00:11:04,530
- So, we've mentioned the term human risk

240
00:11:04,530 --> 00:11:05,699
a couple of times already,

241
00:11:05,700 --> 00:11:08,510
and I want to just take a
step back and define it,

242
00:11:08,510 --> 00:11:10,319
because as Michelle just said,

243
00:11:10,320 --> 00:11:13,950
one of the key ways for us to shift left

244
00:11:13,950 --> 00:11:17,800
of responding to incidents,
is to start measuring it.

245
00:11:17,800 --> 00:11:20,599
You can't fix what you don't measure,

246
00:11:20,600 --> 00:11:24,020
nor can you give tailored
feedback, or tailored controls

247
00:11:24,020 --> 00:11:26,140
if you don't understand people's
strengths and weaknesses.

248
00:11:26,140 --> 00:11:29,390
So, let's start with the first definition

249
00:11:29,390 --> 00:11:30,622
of what is human risk.

250
00:11:32,220 --> 00:11:36,530
Risk is defined as the
chance that something has had

251
00:11:36,530 --> 00:11:39,363
the likelihood times the
impact of something happening.

252
00:11:40,672 --> 00:11:43,090
And that's a broad definition.

253
00:11:43,090 --> 00:11:45,770
So, when we take it one
step deeper and understand,

254
00:11:45,770 --> 00:11:47,750
well, what is human risk?

255
00:11:47,750 --> 00:11:49,900
Human risk is the probability,

256
00:11:49,900 --> 00:11:51,540
the likelihood that someone

257
00:11:51,540 --> 00:11:53,760
is going to make a security decision

258
00:11:53,760 --> 00:11:55,530
that might increase your
attack surface service,

259
00:11:55,530 --> 00:11:57,410
might jeopardize your organization,

260
00:11:57,410 --> 00:11:59,543
and multiplying it by the impact.

261
00:12:00,430 --> 00:12:04,780
An intern, leaking their
credentials may be less risky

262
00:12:04,780 --> 00:12:07,270
than your CEO leaking credentials.

263
00:12:07,270 --> 00:12:10,023
So, those are two incredibly,

264
00:12:11,190 --> 00:12:13,410
critical pieces of understanding

265
00:12:13,410 --> 00:12:17,310
what your level of exposure
is in your organization.

266
00:12:17,310 --> 00:12:20,010
Now, when we think about measuring risk

267
00:12:20,010 --> 00:12:22,693
in your organization, what
should you be measuring?

268
00:12:23,780 --> 00:12:26,300
When I work with a lot of organizations,

269
00:12:26,300 --> 00:12:30,930
most people start with measuring mindset.

270
00:12:30,930 --> 00:12:35,280
How many people are
successfully completing quizzes

271
00:12:35,280 --> 00:12:37,770
at the end of a security training.

272
00:12:37,770 --> 00:12:40,960
And while knowledge is
important, it's not enough.

273
00:12:40,960 --> 00:12:44,320
It's what your employees do
in the wild, if you will,

274
00:12:44,320 --> 00:12:46,930
that is the area that really matters.

275
00:12:46,930 --> 00:12:49,089
We don't grant people a driver's licenses

276
00:12:49,090 --> 00:12:51,900
just by how well they
pass their driver's exam,

277
00:12:51,900 --> 00:12:53,079
we actually wait to see

278
00:12:53,080 --> 00:12:56,280
that they're able to drive on the road.

279
00:12:56,280 --> 00:13:01,140
And it is the understanding
of what people actually do,

280
00:13:01,140 --> 00:13:04,160
not just what they know, that
is the biggest difference,

281
00:13:04,160 --> 00:13:08,110
and that truly measuring this effectively.

282
00:13:08,110 --> 00:13:09,903
So, what do you measure?

283
00:13:11,674 --> 00:13:14,470
Your employees on a regular basis,

284
00:13:14,470 --> 00:13:17,380
are putting out information
about how they interact

285
00:13:17,380 --> 00:13:19,770
with decision, with security,

286
00:13:19,770 --> 00:13:21,380
based on the decisions that they make

287
00:13:21,380 --> 00:13:23,150
hundreds of times a day.

288
00:13:23,150 --> 00:13:25,420
Do they navigate to
websites that are blocked

289
00:13:25,420 --> 00:13:27,540
by your web browsing technologies?

290
00:13:27,540 --> 00:13:29,800
Do they try to click on links,

291
00:13:29,800 --> 00:13:32,520
real mock phishing or real phishing?

292
00:13:32,520 --> 00:13:34,040
Are they reporting?

293
00:13:34,040 --> 00:13:35,959
How are they handling sensitive data?

294
00:13:35,960 --> 00:13:38,500
Are you having to clean up after them

295
00:13:38,500 --> 00:13:39,973
around different incidents?

296
00:13:40,830 --> 00:13:44,580
So, there's a lot of telemetry
around every individual

297
00:13:44,580 --> 00:13:46,330
that helps paint a picture.

298
00:13:46,330 --> 00:13:48,700
And so, based on past performance,

299
00:13:48,700 --> 00:13:51,440
you can begin to understand
what it might look like

300
00:13:53,470 --> 00:13:54,673
in your future case.

301
00:13:55,630 --> 00:13:58,330
And when we take a look
around the holistic view

302
00:13:58,330 --> 00:14:00,930
of what it means to measure human risk,

303
00:14:00,930 --> 00:14:02,400
it's not just phishing,

304
00:14:02,400 --> 00:14:05,670
although, phishing is a
really critical piece.

305
00:14:05,670 --> 00:14:10,140
There are key components that
paint a really full picture

306
00:14:10,140 --> 00:14:14,000
around what a human risks
looks like per individual.

307
00:14:14,000 --> 00:14:16,153
And you can see there's
lots of small decisions

308
00:14:16,153 --> 00:14:21,140
that we just talked about,
that can help flush out

309
00:14:21,140 --> 00:14:22,790
this understanding.

310
00:14:22,790 --> 00:14:25,079
And so, by understanding the decisions

311
00:14:25,080 --> 00:14:26,820
that every employee is making,

312
00:14:26,820 --> 00:14:30,580
we're able to get
essentially a credit score

313
00:14:30,580 --> 00:14:31,413
for every employee,

314
00:14:31,413 --> 00:14:33,490
if you think about this as a concept.

315
00:14:33,490 --> 00:14:37,300
And it allows us to understand

316
00:14:37,300 --> 00:14:39,670
what an employee is good at and bad at,

317
00:14:39,670 --> 00:14:43,089
and quickly understand how much trust

318
00:14:43,090 --> 00:14:45,060
we should put into an individual

319
00:14:45,060 --> 00:14:46,089
from a controls perspective,

320
00:14:46,090 --> 00:14:47,640
but also how much training?

321
00:14:47,640 --> 00:14:49,470
How many resources?

322
00:14:49,470 --> 00:14:51,100
And this is not to say that everyone

323
00:14:51,100 --> 00:14:55,910
who is on the tail, the
straggler is a bad employee.

324
00:14:55,910 --> 00:14:58,050
There might be fantastic contributions

325
00:14:58,050 --> 00:14:59,109
in sales and marketing.

326
00:14:59,110 --> 00:15:01,400
There's just a certain
amount of security trust

327
00:15:01,400 --> 00:15:05,240
that they need to be allotted to.

328
00:15:05,240 --> 00:15:08,163
And we don't have to stop
at the individual level,

329
00:15:09,210 --> 00:15:10,610
we can pull an HR data

330
00:15:10,610 --> 00:15:12,550
and start mapping this organizationally

331
00:15:12,550 --> 00:15:15,579
and seeing where your
trends are by department,

332
00:15:15,580 --> 00:15:18,010
by leader, by manager.

333
00:15:18,010 --> 00:15:20,370
And I'm gonna show you in a little bit

334
00:15:20,370 --> 00:15:24,220
around findings that
we've seen around trends

335
00:15:24,220 --> 00:15:26,070
for different department areas.

336
00:15:26,070 --> 00:15:29,620
And this helps you focus
your efforts and time

337
00:15:29,620 --> 00:15:32,140
on departments that may
need it more than others.

338
00:15:32,140 --> 00:15:34,260
In this case, it sounds like marketing

339
00:15:34,260 --> 00:15:35,270
might need a little bit help

340
00:15:35,270 --> 00:15:37,622
around passwords and
sensitive data handling.

341
00:15:40,250 --> 00:15:42,220
As I just alluded to,

342
00:15:42,220 --> 00:15:44,870
one of the things that
Elevate Security has done,

343
00:15:44,870 --> 00:15:47,340
is worked with organizations like OMF

344
00:15:47,340 --> 00:15:51,590
to help them map their human risks.

345
00:15:51,590 --> 00:15:54,070
And we've had the
opportunity of collecting

346
00:15:54,070 --> 00:15:57,770
the largest dataset
around security decisions

347
00:15:57,770 --> 00:15:59,819
that employees are making globally.

348
00:15:59,820 --> 00:16:02,220
It's a data set that I'm
incredibly excited about

349
00:16:02,220 --> 00:16:04,490
because it's the first of its kind

350
00:16:04,490 --> 00:16:06,290
to truly paint this picture,

351
00:16:06,290 --> 00:16:08,410
and it's one of the things that we found,

352
00:16:08,410 --> 00:16:11,060
is a series of findings in partnership

353
00:16:11,060 --> 00:16:13,560
with a research institute called Scientia,

354
00:16:13,560 --> 00:16:17,920
observed over 4.5 million
decisions made by,

355
00:16:17,920 --> 00:16:20,270
about 114,000 employees.

356
00:16:20,270 --> 00:16:22,310
So, not just in OneMain Financial,

357
00:16:22,310 --> 00:16:24,949
but across dozens of companies.

358
00:16:24,950 --> 00:16:27,500
And so, some of the
trends that we have found,

359
00:16:27,500 --> 00:16:30,730
is that demographics actually matter.

360
00:16:30,730 --> 00:16:34,980
We have found that non
contractors are more likely

361
00:16:36,382 --> 00:16:39,930
than contractors to click
on a phishing links,

362
00:16:39,930 --> 00:16:43,660
click and compromise
themselves on phishing links.

363
00:16:43,660 --> 00:16:47,969
And managers, surprisingly
were more likely

364
00:16:49,120 --> 00:16:50,040
than non managers,

365
00:16:50,040 --> 00:16:54,140
non-managers being like
frontline employees.

366
00:16:54,140 --> 00:16:57,870
And so, this ladder piece
we actually unpacked

367
00:16:57,870 --> 00:16:59,040
a little bit further,

368
00:16:59,040 --> 00:17:03,199
we wanted to see where someone
sat in the organization.

369
00:17:03,200 --> 00:17:04,740
If we could predict how likely

370
00:17:04,740 --> 00:17:06,300
they were to click on a phishing link.

371
00:17:06,300 --> 00:17:10,280
And what we found was
that you can quantify

372
00:17:10,280 --> 00:17:12,730
something that I call the
squishy middle, right?

373
00:17:12,730 --> 00:17:15,700
It's not your CEO that's clicking on link,

374
00:17:15,700 --> 00:17:19,329
nor your CPs, nor is it
your front line employees,

375
00:17:19,329 --> 00:17:20,909
it's the middle managers.

376
00:17:20,910 --> 00:17:23,910
And usually it's the
first line of managers

377
00:17:23,910 --> 00:17:27,710
that are some of the riskiest
in your organization.

378
00:17:27,710 --> 00:17:29,830
We've seen this trend, not
just for phishing and malware

379
00:17:29,830 --> 00:17:32,439
but all sort of phishing
clicked are compromise,

380
00:17:32,440 --> 00:17:34,763
but also for malware
infection rates as well.

381
00:17:36,748 --> 00:17:41,053
So, where someone sits as as
it turns out, actually matters.

382
00:17:42,740 --> 00:17:46,123
And from there, we wanted to see,

383
00:17:47,224 --> 00:17:52,070
how do we organize our training campaigns,

384
00:17:52,070 --> 00:17:54,429
and more specifically, our mock phishing?

385
00:17:54,430 --> 00:17:57,580
So, we wanted to compare
some trends on mock

386
00:17:57,580 --> 00:17:59,340
versus real-world phishing.

387
00:17:59,340 --> 00:18:04,340
So, we're able to map the times

388
00:18:04,780 --> 00:18:09,780
when employees received a
simulated phishing event,

389
00:18:10,331 --> 00:18:13,860
clicked on the phishing
event and reported it.

390
00:18:13,860 --> 00:18:17,729
And as you can see that most of the time

391
00:18:17,730 --> 00:18:20,520
when we phish our employees,
we do it in spurts,

392
00:18:20,520 --> 00:18:22,410
probably, because it's an automated system

393
00:18:22,410 --> 00:18:24,210
that says launch this phishing email

394
00:18:26,030 --> 00:18:27,730
right at the beginning of the next day.

395
00:18:27,730 --> 00:18:28,990
So, midnight or one o'clock,

396
00:18:28,990 --> 00:18:32,003
or at the beginning of my
work day, 9 or 10 o'clock.

397
00:18:33,430 --> 00:18:35,410
Most employees tend to click it

398
00:18:35,410 --> 00:18:38,670
when they receive it at 9:00
am, and that's about it.

399
00:18:38,670 --> 00:18:41,030
I mean, there's obviously
dis-distribution,

400
00:18:41,030 --> 00:18:42,830
but that's clearly the largest spike

401
00:18:44,760 --> 00:18:47,390
when they were both clicking
and reporting on it.

402
00:18:47,390 --> 00:18:50,240
So, how does this compare to
the actually the real world?

403
00:18:51,650 --> 00:18:54,433
It doesn't actually look very similar.

404
00:18:56,070 --> 00:18:59,730
Real world phishing gets
delivered at all times of day,

405
00:18:59,730 --> 00:19:03,000
just not as right as probably
what I would have guessed.

406
00:19:03,000 --> 00:19:05,640
But our employees are clicking on it,

407
00:19:05,640 --> 00:19:08,630
very early in the morning, around 6:00 am,

408
00:19:08,630 --> 00:19:12,450
and at the end of their day,
the very end of their workday,

409
00:19:12,450 --> 00:19:14,680
so 5:00 pm and 7:00 pm.

410
00:19:14,680 --> 00:19:17,830
And there's a lot of really
interesting ideas around this,

411
00:19:17,830 --> 00:19:20,169
probably because we're
most tired, (chuckles)

412
00:19:20,170 --> 00:19:22,820
and our spidey senses aren't up,

413
00:19:22,820 --> 00:19:27,110
which helps us understand that
if we need to look at this

414
00:19:27,110 --> 00:19:29,860
as a human problem, and not
just as a security problem.

415
00:19:30,710 --> 00:19:34,760
And people tend to report
this pretty ubiquitously

416
00:19:34,760 --> 00:19:35,710
throughout the day,

417
00:19:36,570 --> 00:19:38,530
if they are able to report it.

418
00:19:38,530 --> 00:19:42,180
So, when we compare those two,
just to quickly take a look,

419
00:19:42,180 --> 00:19:45,380
we see that we don't phish,

420
00:19:45,380 --> 00:19:47,380
we don't train our employees

421
00:19:47,380 --> 00:19:49,920
to match what real-world attackers do.

422
00:19:49,920 --> 00:19:51,720
And so, by understanding,

423
00:19:51,720 --> 00:19:55,320
again, the data sets of how our employees

424
00:19:55,320 --> 00:19:58,120
are actually getting attacked
and how we're training,

425
00:19:58,120 --> 00:20:00,830
we can start organizing our programs

426
00:20:02,068 --> 00:20:04,670
to be more resilient against
the way our attackers

427
00:20:04,670 --> 00:20:06,503
are testing our employees.

428
00:20:08,480 --> 00:20:11,370
Two more exciting findings
I wanted to share with you.

429
00:20:11,370 --> 00:20:13,070
One of them about the fact that...

430
00:20:15,210 --> 00:20:19,230
The culture that your department has,

431
00:20:19,230 --> 00:20:20,720
actually matters quite a bit,

432
00:20:20,720 --> 00:20:23,560
the norms that people hold
each other accountable to.

433
00:20:23,560 --> 00:20:25,659
So, let me explain what you're looking at.

434
00:20:26,860 --> 00:20:29,570
The bubble sizes are how many emails,

435
00:20:29,570 --> 00:20:31,530
phishing emails a department received,

436
00:20:31,530 --> 00:20:34,417
and the X-axis is how
big this department is.

437
00:20:34,417 --> 00:20:38,649
And so, you can see that
it doesn't actually matter

438
00:20:38,650 --> 00:20:40,610
the size of the department,

439
00:20:40,610 --> 00:20:43,169
There are departments
who are smallest size

440
00:20:43,170 --> 00:20:45,610
that clicking phishing links,
and small in size that don't.

441
00:20:45,610 --> 00:20:47,600
And there are departments
that are large phishing size,

442
00:20:47,600 --> 00:20:48,669
and some that don't.

443
00:20:48,670 --> 00:20:51,390
And so, that means it's
actually not the size

444
00:20:51,390 --> 00:20:55,170
of the department or the strength
of the leader necessarily,

445
00:20:55,170 --> 00:20:58,190
or the fact that you report
up to an SVP, for example,

446
00:20:58,190 --> 00:21:01,400
that determines whether or not
you're gonna click on a link.

447
00:21:01,400 --> 00:21:03,450
There's something about the norms,

448
00:21:03,450 --> 00:21:05,823
the way that people are
held accountable to,

449
00:21:07,060 --> 00:21:09,100
either themselves or their peers,

450
00:21:09,100 --> 00:21:10,909
some of the security culture

451
00:21:10,910 --> 00:21:12,330
and their positive reinforcement

452
00:21:12,330 --> 00:21:14,040
that Michelle was talking about earlier,

453
00:21:14,040 --> 00:21:16,710
that starts driving this norm

454
00:21:16,710 --> 00:21:19,620
of behavior across organizations.

455
00:21:19,620 --> 00:21:22,629
And the last finding I
wanted to share with you,

456
00:21:22,630 --> 00:21:27,630
is that it's possible to
correlate a couple of behaviors.

457
00:21:27,800 --> 00:21:30,620
So, how you show up in one way,

458
00:21:30,620 --> 00:21:32,899
can help under help us understand

459
00:21:32,900 --> 00:21:37,000
how you might respond to
other security incidents

460
00:21:37,000 --> 00:21:39,180
that might happen a little
bit less frequently.

461
00:21:39,180 --> 00:21:41,300
So, in this case, we wanted
to take a look at training,

462
00:21:41,300 --> 00:21:43,780
because training completion
happens regularly,

463
00:21:43,780 --> 00:21:46,970
consistently across all departments.

464
00:21:46,970 --> 00:21:49,480
But we wanted to see how that would react

465
00:21:49,480 --> 00:21:52,340
to responding to real-world
phishing and reporting.

466
00:21:52,340 --> 00:21:55,870
So, we found that people
who were regularly late

467
00:21:55,870 --> 00:21:58,179
on completing their security training,

468
00:21:58,180 --> 00:22:02,610
were also statistically
significantly less likely

469
00:22:02,610 --> 00:22:05,409
to report and more likely
to click on a phishing link

470
00:22:05,410 --> 00:22:07,283
by almost 5%.

471
00:22:09,780 --> 00:22:12,350
So, taking a look at the people

472
00:22:12,350 --> 00:22:14,639
who are regularly clicking
on links, maybe...

473
00:22:14,640 --> 00:22:17,000
Sorry, regularly taking late training,

474
00:22:17,000 --> 00:22:20,890
middle managers, non contractors,

475
00:22:20,890 --> 00:22:23,610
you can start pulling
together some insights

476
00:22:23,610 --> 00:22:25,629
around where to actually
focus your time and energy,

477
00:22:25,630 --> 00:22:30,630
because not everyone in your
organization is created equal.

478
00:22:31,040 --> 00:22:34,530
So, with that, I wanted to
hand it over to Michelle

479
00:22:34,530 --> 00:22:38,360
to talk through how you can
use and apply some of this data

480
00:22:38,360 --> 00:22:39,280
in the real world

481
00:22:41,250 --> 00:22:42,083
- And, Masha, I can't...

482
00:22:42,083 --> 00:22:46,180
I mean, I can't tell you how
valuable data like that is,

483
00:22:46,180 --> 00:22:49,470
and being able to understand,

484
00:22:49,470 --> 00:22:52,810
not just what is
happening across the board

485
00:22:52,810 --> 00:22:55,590
and the research that you
present and you shared with us,

486
00:22:55,590 --> 00:22:59,209
but also how do you gather
this kind of information

487
00:22:59,210 --> 00:23:00,603
for your own environment?

488
00:23:00,603 --> 00:23:02,650
I mean, I find some of it...

489
00:23:02,650 --> 00:23:05,920
I really was surprised by some of it.

490
00:23:05,920 --> 00:23:07,640
Some of it, I wasn't surprised at all by,

491
00:23:07,640 --> 00:23:10,150
particularly the time
of day of real phishing,

492
00:23:10,150 --> 00:23:13,230
'cause I know that I do
emails before I go to bed

493
00:23:13,230 --> 00:23:15,230
and I do emails first
thing when I wake up,

494
00:23:15,230 --> 00:23:17,930
and neither one of those
times is that the best time

495
00:23:17,930 --> 00:23:19,770
for me to be making the best of decisions,

496
00:23:19,770 --> 00:23:22,670
'cause I'm a little foggy
at both periods of time.

497
00:23:22,670 --> 00:23:24,980
So, how do you now take these insights

498
00:23:24,980 --> 00:23:28,113
and really strengthen
your cyber resiliency?

499
00:23:29,480 --> 00:23:33,080
One example is I get emails all the time

500
00:23:33,080 --> 00:23:34,540
from a variety of partnerships,

501
00:23:34,540 --> 00:23:37,120
like the financial services,
information sharing,

502
00:23:37,120 --> 00:23:38,560
and analysis center,

503
00:23:38,560 --> 00:23:42,110
who shares an incredible amount
of intel with each other.

504
00:23:42,110 --> 00:23:43,729
Although all of the different members,

505
00:23:43,730 --> 00:23:46,000
share about what's going
in their environment,

506
00:23:46,000 --> 00:23:48,210
and particularly, phishing campaigns

507
00:23:48,210 --> 00:23:49,800
and what they look like.

508
00:23:49,800 --> 00:23:52,950
We take those actual phishing campaigns,

509
00:23:52,950 --> 00:23:55,220
and use those to shape the campaigns

510
00:23:55,220 --> 00:23:56,810
that we run in our environment,

511
00:23:56,810 --> 00:23:58,730
that way they're more realistic.

512
00:23:58,730 --> 00:24:01,820
You also can use this data,
like we were talking about,

513
00:24:01,820 --> 00:24:03,750
of when are these emails clicked?

514
00:24:03,750 --> 00:24:06,700
And put out targeted tips and tricks

515
00:24:06,700 --> 00:24:09,010
on telling your team members,

516
00:24:09,010 --> 00:24:12,520
do you really need to read
emails at the end of the day,

517
00:24:12,520 --> 00:24:13,460
or first thing in the morning?

518
00:24:13,460 --> 00:24:16,220
And if so, maybe just real those emails

519
00:24:16,220 --> 00:24:17,290
you know the senders,

520
00:24:17,290 --> 00:24:19,430
and leave the rest of them in the inbox

521
00:24:19,430 --> 00:24:20,980
until you get into the office,

522
00:24:20,980 --> 00:24:24,000
or in front of your video.

523
00:24:24,000 --> 00:24:26,550
- Or after you had your
morning coffee. (laughs)

524
00:24:26,550 --> 00:24:28,299
- After you'd had your morning coffee.

525
00:24:28,299 --> 00:24:29,312
(laughs) Exactly.

526
00:24:30,750 --> 00:24:31,880
- Another thing that you can do,

527
00:24:31,880 --> 00:24:35,360
is just find ways to
communicate to the employees

528
00:24:35,360 --> 00:24:36,370
what they're doing,

529
00:24:36,370 --> 00:24:39,629
like celebrate when they'd
make it make good decisions,

530
00:24:39,630 --> 00:24:41,870
celebrate the things
that they're doing well.

531
00:24:41,870 --> 00:24:45,100
And also, provide them
with meaningful insights

532
00:24:45,100 --> 00:24:49,000
that are specific to them,
specific to their role,

533
00:24:49,000 --> 00:24:51,960
and help them understand
the impact of their actions.

534
00:24:51,960 --> 00:24:54,047
No perfect example of Paris last task.

535
00:24:54,047 --> 00:24:58,490
And we rolled our last pass
out to our employees last year

536
00:24:58,490 --> 00:25:00,300
and being able to really understand

537
00:25:00,300 --> 00:25:03,340
how is that being adopted,
how is that helping,

538
00:25:03,340 --> 00:25:06,850
is an incredibly valuable,
you know, insight

539
00:25:06,850 --> 00:25:09,540
but it's also, we can use this,

540
00:25:09,540 --> 00:25:12,027
you know, ability to communicate
with our employees to say,

541
00:25:12,027 --> 00:25:15,290
"Hey, I know that you
haven't done last pass yet.

542
00:25:15,290 --> 00:25:16,500
Let me tell you why.

543
00:25:16,500 --> 00:25:18,890
You know, take a few
minutes and do that now."

544
00:25:18,890 --> 00:25:21,360
And more importantly, give
them the link right there

545
00:25:21,360 --> 00:25:23,240
to go and sign up.

546
00:25:23,240 --> 00:25:26,380
All of these things just
provide meaningful insights

547
00:25:26,380 --> 00:25:29,150
and help employees to
think about their actions

548
00:25:29,150 --> 00:25:31,420
and the impact of their behaviors.

549
00:25:31,420 --> 00:25:34,670
- I have a similar experience
when my fitness tracker

550
00:25:34,670 --> 00:25:38,110
tells me about my performance
as compares to my peers.

551
00:25:38,110 --> 00:25:40,899
I'm much more likely to
go out run or workout

552
00:25:40,900 --> 00:25:42,740
than just generic best practices.

553
00:25:42,740 --> 00:25:47,740
And so, personalized means the
whole world of communication

554
00:25:48,330 --> 00:25:52,270
that is much more
motivating to an individual.

555
00:25:52,270 --> 00:25:54,950
And we see it from advertising
to fitness tracker,

556
00:25:54,950 --> 00:25:56,623
so why not security?

557
00:25:58,060 --> 00:26:00,200
- Yeah. And a great example of that,

558
00:26:00,200 --> 00:26:03,740
is one of the things that we
do with our phishing tests,

559
00:26:03,740 --> 00:26:06,040
is if somebody takes the right action,

560
00:26:06,040 --> 00:26:08,523
we send them a congratulations
email right away.

561
00:26:09,410 --> 00:26:12,620
It is so surprising, how
well that is received,

562
00:26:12,620 --> 00:26:15,340
and how people actually tell
each other whether or not,

563
00:26:15,340 --> 00:26:17,730
they got the congratulations email.

564
00:26:17,730 --> 00:26:21,360
But in particular, our
executives, they love to share,

565
00:26:21,360 --> 00:26:23,429
that whether or not they
got it right or not.

566
00:26:23,430 --> 00:26:25,460
Heck, they're even telling us
when they didn't get it right,

567
00:26:25,460 --> 00:26:28,760
'cause they're like, I didn't
get the congratulations email.

568
00:26:28,760 --> 00:26:31,560
So, you can also use
contests, you can use swag,

569
00:26:31,560 --> 00:26:33,800
there's all sorts of ways to spotlight,

570
00:26:33,800 --> 00:26:37,710
and really incentivize, and
reward employees who are making

571
00:26:37,710 --> 00:26:39,390
and taking the right action,

572
00:26:39,390 --> 00:26:42,560
whether it's with them
directly or recognizing them

573
00:26:42,560 --> 00:26:43,940
to their leadership,

574
00:26:43,940 --> 00:26:46,220
or putting them in
competition with each other.

575
00:26:46,220 --> 00:26:47,980
There's a lot of different
ways you can do that.

576
00:26:47,980 --> 00:26:52,350
And I agree, that competition
for fitness is no joke.

577
00:26:52,350 --> 00:26:54,580
So, why not apply it to security?

578
00:26:54,580 --> 00:26:55,562
- [Masha] Why not?

579
00:26:57,020 --> 00:27:00,120
- Especially since we all
have limited resources.

580
00:27:00,120 --> 00:27:04,729
And as much as talked
about, a one size fits all,

581
00:27:04,730 --> 00:27:06,340
it's limiting.

582
00:27:06,340 --> 00:27:09,639
If you can find a way to
target the individuals

583
00:27:09,640 --> 00:27:10,473
and the teams,

584
00:27:10,473 --> 00:27:12,129
and like here you can see

585
00:27:12,130 --> 00:27:15,030
the teams that need additional assistance,

586
00:27:15,030 --> 00:27:17,149
well, maybe public relations needs

587
00:27:17,150 --> 00:27:18,990
a little bit of time spent with them.

588
00:27:18,990 --> 00:27:22,010
You can tailor the training,

589
00:27:22,010 --> 00:27:23,960
you can tailor events with those teams,

590
00:27:23,960 --> 00:27:26,690
go talk to one of their staff meetings.

591
00:27:26,690 --> 00:27:30,070
Give them specific training opportunity,

592
00:27:30,070 --> 00:27:31,500
bring them into your program

593
00:27:31,500 --> 00:27:33,020
and help them understand
what they're doing,

594
00:27:33,020 --> 00:27:35,220
and give them a piece to do for it.

595
00:27:35,220 --> 00:27:37,780
But focus your time on
the people that need it.

596
00:27:37,780 --> 00:27:39,840
In addition, you can use this data

597
00:27:39,840 --> 00:27:42,220
to also identify champions.

598
00:27:42,220 --> 00:27:45,360
So, those champions
become force multipliers.

599
00:27:45,360 --> 00:27:48,357
And I think I might reach out
to the data team here and say,

600
00:27:48,357 --> 00:27:51,410
"I would love to make you guys champions

601
00:27:51,410 --> 00:27:54,970
for our entire enterprise
and help people understand,

602
00:27:54,970 --> 00:27:57,150
why do you make the decisions that you do?

603
00:27:57,150 --> 00:27:59,270
And why should others do the same?"

604
00:27:59,270 --> 00:28:01,840
This way, you also can recognize top teams

605
00:28:01,840 --> 00:28:03,300
because like we've been talking

606
00:28:03,300 --> 00:28:05,139
about nothing breeds improvement,

607
00:28:05,140 --> 00:28:07,190
like a little bit of healthy competition.

608
00:28:10,780 --> 00:28:14,910
So, it's not just about
what you do with the people,

609
00:28:14,910 --> 00:28:16,980
you can also use this data

610
00:28:16,980 --> 00:28:21,123
to make your technology
investments more effective,

611
00:28:22,050 --> 00:28:24,460
make it based upon individual identities,

612
00:28:24,460 --> 00:28:27,260
and the risk behaviors
that they've exhibited.

613
00:28:27,260 --> 00:28:30,140
I mean, here's some examples
of things you can do.

614
00:28:30,140 --> 00:28:32,050
If you've got an individual,

615
00:28:32,050 --> 00:28:35,000
who is clicking on phishing links a lot,

616
00:28:35,000 --> 00:28:37,060
or going out to sites that they don't,

617
00:28:37,060 --> 00:28:39,470
you can implement preventative controls.

618
00:28:39,470 --> 00:28:42,450
You can increase the monitoring
for those individuals,

619
00:28:42,450 --> 00:28:45,200
especially those who are
showing risky behaviors.

620
00:28:45,200 --> 00:28:49,510
You don't need to deploy those
resource intensive controls

621
00:28:49,510 --> 00:28:51,450
to the entire enterprise,

622
00:28:51,450 --> 00:28:53,340
because that can decrease performance.

623
00:28:53,340 --> 00:28:55,080
How many times have you
heard people complain

624
00:28:55,080 --> 00:28:57,500
about this new security tool,

625
00:28:57,500 --> 00:29:00,230
is making it impossible
for me to do my work?

626
00:29:00,230 --> 00:29:03,570
So, what if you instead just
target to those controls

627
00:29:03,570 --> 00:29:06,950
only to those who are making
the bad risk decisions.

628
00:29:06,950 --> 00:29:09,280
Relaxing controls, relaxing training,

629
00:29:09,280 --> 00:29:13,160
saving time on monitoring,
this is a huge benefit

630
00:29:13,160 --> 00:29:16,560
for security, and a way
that you can use this data

631
00:29:16,560 --> 00:29:19,883
to prevent the blast radius
of risky decision-making.

632
00:29:20,860 --> 00:29:24,939
One example, a specific
example, is like social media.

633
00:29:24,940 --> 00:29:27,510
Instead of blocking social media

634
00:29:27,510 --> 00:29:29,400
for everybody in the company,

635
00:29:29,400 --> 00:29:31,610
how about if you just blocked it for those

636
00:29:31,610 --> 00:29:33,570
who are going and doing things

637
00:29:33,570 --> 00:29:35,230
that they shouldn't be
doing out in the internet,

638
00:29:35,230 --> 00:29:37,080
or taking other risky behaviors

639
00:29:37,080 --> 00:29:38,820
because if they're doing risky behaviors

640
00:29:38,820 --> 00:29:40,560
across other security things,

641
00:29:40,560 --> 00:29:42,950
they are also likely to do some things

642
00:29:42,950 --> 00:29:44,070
in the social media place

643
00:29:44,070 --> 00:29:46,639
that you may not want them to be doing.

644
00:29:46,640 --> 00:29:50,370
The key is that you can apply
this to all sorts of settings,

645
00:29:50,370 --> 00:29:52,010
all sorts of controls that you have,

646
00:29:52,010 --> 00:29:54,460
whether it is email filtering,

647
00:29:54,460 --> 00:29:57,823
what you're allowing your
employees to go to or not go to,

648
00:29:58,901 --> 00:30:01,020
what control are you giving your employees

649
00:30:01,020 --> 00:30:02,170
for their machines?

650
00:30:02,170 --> 00:30:06,340
Whether it's from soft software
execution or data sharing,

651
00:30:06,340 --> 00:30:10,419
all of this information
can really help to refine,

652
00:30:10,420 --> 00:30:12,210
and make the tools that you're putting

653
00:30:12,210 --> 00:30:15,200
heavy investments in, far more successful,

654
00:30:15,200 --> 00:30:18,463
and also make your security
team far more successful.

655
00:30:19,520 --> 00:30:20,830
- I love that idea.

656
00:30:20,830 --> 00:30:22,750
It's like you're getting
to the root cause,

657
00:30:22,750 --> 00:30:24,700
by the training and the culture,

658
00:30:24,700 --> 00:30:27,077
but at the same time,
you're reducing the risk

659
00:30:27,077 --> 00:30:29,343
and the exposure of your organization.

660
00:30:30,200 --> 00:30:32,840
And when you talk about
competition and carrots,

661
00:30:32,840 --> 00:30:35,340
if you let me go to social media,

662
00:30:35,340 --> 00:30:40,080
because I am a trustworthy
employee, that seems great.

663
00:30:40,080 --> 00:30:41,720
And if you block it
because you let me know

664
00:30:41,720 --> 00:30:42,720
that I'm a risky employee,

665
00:30:42,720 --> 00:30:45,413
I have the understanding
of why you're doing that.

666
00:30:46,590 --> 00:30:49,453
And it treats employees like adults,

667
00:30:51,225 --> 00:30:54,840
instead of third graders
that need more care

668
00:30:54,840 --> 00:30:56,760
and attention than empowers employees

669
00:30:57,995 --> 00:31:00,669
to make their own choices and actions

670
00:31:00,670 --> 00:31:02,550
around how much privilege do they,

671
00:31:02,550 --> 00:31:04,220
might want in the organization,

672
00:31:04,220 --> 00:31:08,983
or with security tools and
access like social media.

673
00:31:10,070 --> 00:31:12,830
- And what better way to
like have that conversation

674
00:31:12,830 --> 00:31:14,447
than an employee reaching out saying,

675
00:31:14,447 --> 00:31:17,080
"Why can't I get to social media?"

676
00:31:17,080 --> 00:31:20,649
And now, you have another
targeted treading opportunity.

677
00:31:20,650 --> 00:31:21,483
- Yep.

678
00:31:21,483 --> 00:31:24,550
- So, we've talked about
a lot here in an area

679
00:31:24,550 --> 00:31:26,270
that I'm sure you can tell Masha and I

680
00:31:26,270 --> 00:31:29,500
are both particularly passionate about.

681
00:31:29,500 --> 00:31:32,930
So, we do wanna leave you with
a couple of key takeaways.

682
00:31:32,930 --> 00:31:36,700
First, like I said, that
foundation is so important,

683
00:31:36,700 --> 00:31:38,240
and you hear it all the time.

684
00:31:38,240 --> 00:31:40,682
You know, if you have a dollar to invest,

685
00:31:40,682 --> 00:31:44,330
invest it in building out
your core fundamentals.

686
00:31:44,330 --> 00:31:46,399
And one of those core fundamentals

687
00:31:46,400 --> 00:31:49,370
is every employee in your company.

688
00:31:49,370 --> 00:31:53,520
Invest in how can you make
each one of those an assets

689
00:31:53,520 --> 00:31:55,570
instead of a risk.

690
00:31:55,570 --> 00:31:59,060
Understand the decisions that
these employees are making,

691
00:31:59,060 --> 00:32:01,409
and measure the risk of those decisions.

692
00:32:01,410 --> 00:32:04,190
Measure the risks that, that
is bringing to your environment

693
00:32:04,190 --> 00:32:06,400
specific to your environment.

694
00:32:06,400 --> 00:32:09,050
And then leverage the
insights from that measurement

695
00:32:09,050 --> 00:32:11,250
to tailor your engagement.

696
00:32:11,250 --> 00:32:13,910
There's so many ways that you can build

697
00:32:13,910 --> 00:32:16,840
and improve engagement with
each of your employees,

698
00:32:16,840 --> 00:32:20,600
particularly, in building a
coalition of security champions

699
00:32:20,600 --> 00:32:23,540
across your company, which
is how you're gonna drive

700
00:32:23,540 --> 00:32:26,330
a strong cyber security culture.

701
00:32:26,330 --> 00:32:29,050
It's also how you're going
to make your technology

702
00:32:29,050 --> 00:32:30,092
more effective.

703
00:32:32,210 --> 00:32:34,840
- And as we talked about,

704
00:32:34,840 --> 00:32:37,909
this is such an incredible
and exciting opportunity

705
00:32:37,910 --> 00:32:39,800
for us as a security industry,

706
00:32:39,800 --> 00:32:44,580
because we can actually
stop this hamster wheel

707
00:32:44,580 --> 00:32:48,320
of just cleaning up and
use this type of insight

708
00:32:48,320 --> 00:32:50,200
to defend forward.

709
00:32:50,200 --> 00:32:52,180
So, we're not just reacting,

710
00:32:52,180 --> 00:32:54,330
we're actually getting proactive

711
00:32:54,330 --> 00:32:57,189
and tackling one of the largest

712
00:32:57,190 --> 00:32:58,760
and most ubiquitous problem

713
00:32:58,760 --> 00:33:01,180
that affects almost every organization.

714
00:33:01,180 --> 00:33:04,540
So, we can get ahead of this...

715
00:33:04,540 --> 00:33:08,840
Of just treading water and
actually reduce this risk

716
00:33:08,840 --> 00:33:12,419
in a meaningful way, that
also brings our employees

717
00:33:12,420 --> 00:33:15,380
along for the ride to
help us drive this change

718
00:33:15,380 --> 00:33:17,003
in our organization.

719
00:33:18,400 --> 00:33:21,780
I want to leave you
with one last resource.

720
00:33:21,780 --> 00:33:23,399
We talked about some of the findings

721
00:33:23,400 --> 00:33:25,700
that we published recently

722
00:33:25,700 --> 00:33:29,280
alongside with Scientia
Research Institute.

723
00:33:29,280 --> 00:33:32,360
But if you'd like a copy of
our full set of findings,

724
00:33:32,360 --> 00:33:33,530
there's a lot of stuff we didn't get

725
00:33:33,530 --> 00:33:35,520
to cover in this presentation,

726
00:33:35,520 --> 00:33:37,650
you can download the report at this link

727
00:33:38,929 --> 00:33:40,887
and dive in even deeper.

