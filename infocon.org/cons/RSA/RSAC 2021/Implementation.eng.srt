1
00:00:02,630 --> 00:00:04,973
- Hello the audience of City RSA 2021.

2
00:00:06,480 --> 00:00:09,320
First of all I want to
thank the conference

3
00:00:09,320 --> 00:00:13,510
and it is my honor to give
this presentation titled

4
00:00:13,510 --> 00:00:17,173
a framework to optimize
implementations of matrices.

5
00:00:18,220 --> 00:00:21,500
This is a joint with Zejun
Xiang, Xiangyong Zeng,

6
00:00:21,500 --> 00:00:22,503
and Shasha Zhang.

7
00:00:24,520 --> 00:00:27,509
The (indistinct) efficient implementation

8
00:00:27,510 --> 00:00:30,863
of servers and resource
constraint devices.

9
00:00:32,100 --> 00:00:36,380
As we know the implementation
performance can be evaluated

10
00:00:36,380 --> 00:00:40,720
according to the circuit
size, latency, and so on.

11
00:00:40,720 --> 00:00:42,629
For S-box there are many tools

12
00:00:42,630 --> 00:00:45,363
to find these optimized implementations

13
00:00:45,363 --> 00:00:48,550
such as the business technology

14
00:00:48,550 --> 00:00:52,022
and the SAT based method
and the tool LIGHTER.

15
00:00:53,650 --> 00:00:56,220
We focus on linear layers this paper.

16
00:00:56,220 --> 00:00:59,780
For linear layer we always
treat it as a binary matrix

17
00:00:59,780 --> 00:01:02,260
of (indistinct) and implements the matrix

18
00:01:02,260 --> 00:01:05,310
with the minimal number of xor gates.

19
00:01:05,310 --> 00:01:08,590
Since this is (indistinct) many heuristics

20
00:01:08,590 --> 00:01:12,680
have been proposed to find
the optimize implementation

21
00:01:12,680 --> 00:01:14,240
of binary metrics.

22
00:01:14,240 --> 00:01:17,323
I will introduce several heuristics later.

23
00:01:19,160 --> 00:01:22,702
Here I would like to introduce
the metrics of xor first.

24
00:01:22,702 --> 00:01:27,060
The D-xor counts the number
of 1s within a binary metrics

25
00:01:27,060 --> 00:01:30,550
and G-xor counts the number
of operations like this

26
00:01:30,550 --> 00:01:35,550
and the S-xor counts the number
of S, operations like these.

27
00:01:38,430 --> 00:01:40,022
This is an example.

28
00:01:40,022 --> 00:01:44,180
The D-xor implements the matrix directly

29
00:01:44,180 --> 00:01:47,420
according to the
expression of outputs bits

30
00:01:47,420 --> 00:01:52,420
and the G-xor stores the
results in registry step

31
00:01:54,760 --> 00:01:58,670
and we can notice that
in S-xor implementation

32
00:01:58,670 --> 00:02:02,690
the results will be stored
in one of the operants

33
00:02:02,690 --> 00:02:05,023
and without introducing any register.

34
00:02:07,750 --> 00:02:11,340
We designed a framework to find
the optimized implementation

35
00:02:11,340 --> 00:02:13,270
of the matrices according

36
00:02:13,270 --> 00:02:17,360
to the several existing heuristics.

37
00:02:17,360 --> 00:02:19,970
The first one we used is Paar1

38
00:02:19,970 --> 00:02:22,510
which is proposed by Paar.

39
00:02:22,510 --> 00:02:26,540
This method exhaustively choose
two corners from the metrics

40
00:02:26,540 --> 00:02:28,192
and the computers their end.

41
00:02:29,170 --> 00:02:31,690
(indistinct) candidates pair of columns

42
00:02:33,530 --> 00:02:36,640
who the resulting factor
of the end operation

43
00:02:36,640 --> 00:02:38,792
with the maximum (indistinct) weight.

44
00:02:38,793 --> 00:02:42,530
In this example the first
two columns will be chosen

45
00:02:42,530 --> 00:02:47,530
and at their end one, one,
zero, zero will be added into

46
00:02:47,656 --> 00:02:51,193
the last column of the matrix.

47
00:02:52,390 --> 00:02:56,859
And before we choose the next operations

48
00:02:56,860 --> 00:03:01,040
we show the X or the one, one,
zero, zero with the columns

49
00:03:01,040 --> 00:03:06,040
we choose before and
update the matrices, matrix

50
00:03:06,040 --> 00:03:11,040
and repeat this procedure
and (indistinct) of each row

51
00:03:11,250 --> 00:03:13,253
of the matrix is one.

52
00:03:15,621 --> 00:03:18,650
BP algorithm is proposed
by Foyer and (indistinct).

53
00:03:19,550 --> 00:03:22,993
They defined two factors
the base and the distance.

54
00:03:23,965 --> 00:03:28,910
(indistinct) exhaustively shows
two elements from the base

55
00:03:28,910 --> 00:03:30,609
and it calculates their xor

56
00:03:31,488 --> 00:03:33,833
and the re-evaluators
of the distance factor.

57
00:03:35,516 --> 00:03:38,649
This method selects the
candidates that minimize

58
00:03:38,650 --> 00:03:42,250
the sum of distance and
add it into the base.

59
00:03:42,250 --> 00:03:46,280
But if they are multiple
candidates, they choose the,

60
00:03:46,280 --> 00:03:49,000
choose the one that
maximizes the Euclidean norm

61
00:03:49,000 --> 00:03:50,150
of the distance factor.

62
00:03:52,041 --> 00:03:53,410
Here is example.

63
00:03:53,410 --> 00:03:58,290
We first to put the inputs
of the metrics into base

64
00:03:58,290 --> 00:04:01,220
and then initialize the distance factor

65
00:04:01,220 --> 00:04:04,060
as the minimum number of xor (indistinct)

66
00:04:04,060 --> 00:04:05,410
needed to calculate

67
00:04:05,410 --> 00:04:09,220
the output beads according to
the elements from the base.

68
00:04:09,220 --> 00:04:13,340
Since the choose of the nest
operations is time-consuming

69
00:04:13,340 --> 00:04:18,310
so BP take the strategy of preemptive.

70
00:04:18,310 --> 00:04:23,040
It means that the xor of
two elements from the base

71
00:04:23,040 --> 00:04:27,270
is equal to the output beads
we can (indistinct) choose

72
00:04:27,270 --> 00:04:32,032
these two elements as the
operants of the nest operation.

73
00:04:33,738 --> 00:04:36,020
The BP algorithm will end it

74
00:04:36,020 --> 00:04:39,543
until the distance factor
becomes the zero one.

75
00:04:41,670 --> 00:04:45,170
The following algorithm
is the variance of BP

76
00:04:45,170 --> 00:04:48,480
so I just introduced them briefly.

77
00:04:48,480 --> 00:04:53,480
This method multiply two
permutation matrices with M

78
00:04:53,620 --> 00:04:58,620
and thus rearrange the inputs
and outputs of the matrix M.

79
00:04:58,871 --> 00:05:02,195
The new matrix M prime is cost

80
00:05:02,195 --> 00:05:06,500
the same xor (indistinct) as M.

81
00:05:06,500 --> 00:05:11,500
This method take the M
prime as the inputs of BP

82
00:05:11,550 --> 00:05:16,030
and defines the improvements
of the implementation

83
00:05:16,030 --> 00:05:18,167
and in our framework we modify this method

84
00:05:18,167 --> 00:05:21,087
and take the M prime as the inputs of

85
00:05:21,087 --> 00:05:25,712
all the other heuristics we
adopt, not only BPO algorithm.

86
00:05:27,630 --> 00:05:31,719
Tan and Peyrin proposed
several improved method

87
00:05:31,720 --> 00:05:33,220
according to Paar and BP.

88
00:05:33,220 --> 00:05:37,080
RPaar1 is the special case of Paar, Paar1

89
00:05:37,080 --> 00:05:41,810
and RNBP A1 and A2 are variance of BP.

90
00:05:41,810 --> 00:05:44,513
Limited by time here I don't
introduce them further.

91
00:05:46,636 --> 00:05:50,380
The heuristic reintroduced
just now are based on the G-xor

92
00:05:50,380 --> 00:05:53,650
so I will study the
outputs of these methods

93
00:05:53,650 --> 00:05:55,900
and proposed several reduction rules

94
00:05:57,150 --> 00:06:00,553
for further reducing the
implementation costs.

95
00:06:01,730 --> 00:06:04,100
Take the rule nine and
10 and 11 for example.

96
00:06:04,100 --> 00:06:07,530
Suppose that this is a
part of implementation

97
00:06:07,530 --> 00:06:10,890
and we can find that the
TW is equal to TS, SOTV

98
00:06:13,682 --> 00:06:17,277
and it can be also writing as TBSOTC.

99
00:06:18,280 --> 00:06:21,469
The rule nine means that
if TU is only used once

100
00:06:22,317 --> 00:06:24,920
we can delete it and the safe one xor.

101
00:06:24,920 --> 00:06:28,043
The rule 10 means that
if TV is only used once

102
00:06:28,043 --> 00:06:32,712
we can delete it (indistinct)
and save one xor gate.

103
00:06:32,712 --> 00:06:36,604
The rule 11 means that's
the, if both TU and TC

104
00:06:36,605 --> 00:06:39,207
only use the ones we can delete them both

105
00:06:39,207 --> 00:06:41,957
and thus we can save 2 xor gates.

106
00:06:44,537 --> 00:06:47,960
Based on the heuristics and
the laws introduced just now

107
00:06:47,960 --> 00:06:49,907
we designed the framework (indistinct).

108
00:06:51,120 --> 00:06:54,230
M is the given matrix and the way,

109
00:06:54,230 --> 00:06:57,410
first we implement this implementation

110
00:06:57,410 --> 00:07:02,410
and then we take
continuous segments from it

111
00:07:02,490 --> 00:07:07,140
and the this part can be also
expressed as a binary matrix

112
00:07:07,140 --> 00:07:10,053
and we can use the existing heuristics

113
00:07:10,053 --> 00:07:14,000
to implement it as the green part

114
00:07:14,000 --> 00:07:16,173
and this part is equivalent to this part.

115
00:07:17,390 --> 00:07:22,390
And this is also an
implementation of the matrix M

116
00:07:23,680 --> 00:07:28,630
and we apply our reduction rules to it

117
00:07:28,630 --> 00:07:31,380
and to get the final implementation

118
00:07:31,380 --> 00:07:34,340
and this final implementation
is equivalent to

119
00:07:34,340 --> 00:07:35,212
the original one.

120
00:07:36,170 --> 00:07:37,730
So this caused two questions.

121
00:07:37,730 --> 00:07:40,130
The first one is how to implement M

122
00:07:40,130 --> 00:07:43,659
and the first, the second
one is how to recover M prime

123
00:07:43,660 --> 00:07:44,653
and implement it.

124
00:07:46,890 --> 00:07:50,469
First we explained the
how to recover M prime.

125
00:07:50,470 --> 00:07:52,730
It goes to find the real inputs of,

126
00:07:52,730 --> 00:07:56,293
inputs and the rare
outputs of these matrix.

127
00:07:57,408 --> 00:07:58,741
Here is an example.

128
00:07:58,741 --> 00:08:02,840
So this is a given matrix implementation

129
00:08:02,840 --> 00:08:06,530
and what we should do is to
recover our matrix M prime

130
00:08:06,530 --> 00:08:10,500
according to operations in the red box.

131
00:08:10,500 --> 00:08:13,640
The first step is to
find this real outputs

132
00:08:13,640 --> 00:08:17,530
the T5 and T6 have never been used

133
00:08:17,530 --> 00:08:22,530
outside of this parts so T5 and T6

134
00:08:22,890 --> 00:08:26,560
are not the real outputs of the M prime.

135
00:08:26,560 --> 00:08:28,770
The second step is to find the real inputs

136
00:08:28,770 --> 00:08:33,049
according to the expression of T7 and T8.

137
00:08:33,049 --> 00:08:37,510
We can spend the expression
of T7, T5, and T6

138
00:08:37,510 --> 00:08:42,510
and get the expression
of T7 and T8 like this.

139
00:08:42,717 --> 00:08:46,300
And this is the real inputs of the M prime

140
00:08:46,300 --> 00:08:51,300
and it's our output bits and
this is the matrix we recover.

141
00:08:57,220 --> 00:09:00,556
Advantages of this
heuristics in our framework

142
00:09:00,556 --> 00:09:04,389
we can implement these
methods to compute the,

143
00:09:05,435 --> 00:09:08,536
we can use this heuristics to comp,

144
00:09:08,537 --> 00:09:11,370
to implement the matrix randomly

145
00:09:11,370 --> 00:09:16,370
and if the implementation is
the inputs of our framework

146
00:09:20,110 --> 00:09:24,330
we can start here and go on
the procedure step by step.

147
00:09:24,330 --> 00:09:27,690
But if the matrix is the
input of our framework

148
00:09:27,690 --> 00:09:32,440
we can start here and implement by it,

149
00:09:32,440 --> 00:09:35,530
by one of the methods we use

150
00:09:35,530 --> 00:09:38,449
we embedded in our framework randomly

151
00:09:38,450 --> 00:09:42,140
and this our framework
provides a lot of flexibility

152
00:09:43,010 --> 00:09:46,763
within the self 'cause we do not fix the,

153
00:09:48,950 --> 00:09:53,950
the method to implement the
metrics each time here and here

154
00:09:54,550 --> 00:09:59,550
and cost each heuristics
has its own advantages

155
00:10:00,100 --> 00:10:05,100
and the heuristics proposed in the future

156
00:10:05,640 --> 00:10:08,323
can be also embedded in
your (indistinct) framework.

157
00:10:11,480 --> 00:10:15,883
We apply our framework
to various matrices.

158
00:10:15,883 --> 00:10:19,320
This is the percentage of
the best implementation

159
00:10:19,320 --> 00:10:20,870
produced by various algorithms.

160
00:10:22,000 --> 00:10:25,090
We can find that our framework can find

161
00:10:25,090 --> 00:10:27,533
better implementation
than other heuristics.

162
00:10:29,140 --> 00:10:34,000
For the applications to cipher matrices

163
00:10:34,000 --> 00:10:37,070
we can find an implementation
with 91 (indistinct)

164
00:10:37,070 --> 00:10:39,330
for AES columns and
this is the (indistinct)

165
00:10:39,330 --> 00:10:43,653
currently the shortest
implementation of AES mixed column.

166
00:10:44,560 --> 00:10:46,132
Okay. That's all. Thank you.

167
00:10:48,910 --> 00:10:49,742
- Hello everyone.

168
00:10:49,743 --> 00:10:52,290
This is improvements to RSA key generation

169
00:10:52,290 --> 00:10:54,670
and Chinese remainder
theorem on embedded devices.

170
00:10:54,670 --> 00:10:56,380
I'm Mike Hamburg with Rambus Labs

171
00:10:56,380 --> 00:10:59,343
and this is joint work with
Mike Tunstall and Qinglai Xiao.

172
00:11:03,580 --> 00:11:06,000
So this is a sort of a grab bag paper

173
00:11:06,000 --> 00:11:08,390
and so it'll be a little
bit of a grab bag talk.

174
00:11:08,390 --> 00:11:11,830
So I'll first go into how
to generate prime numbers

175
00:11:11,830 --> 00:11:14,470
for RSA keys both previous work

176
00:11:14,470 --> 00:11:16,410
and our two improvements on this work

177
00:11:17,390 --> 00:11:20,069
and then how to do the
Chinese remainder theorem

178
00:11:20,070 --> 00:11:22,590
without pre-computed Q inverse mod P

179
00:11:22,590 --> 00:11:26,023
and then combine those for RSA
with compressed private keys.

180
00:11:27,020 --> 00:11:28,613
So prime generation first.

181
00:11:29,886 --> 00:11:34,886
So as I expect you know
RSA keys are of the form

182
00:11:35,930 --> 00:11:39,630
N equals PQ where P and Q
are random prime numbers.

183
00:11:39,630 --> 00:11:41,910
And this process of
generating the prime numbers

184
00:11:41,910 --> 00:11:45,930
is why RSA key generation
is slow and complicated.

185
00:11:45,930 --> 00:11:48,620
There are also other uses
in crypto for random primes

186
00:11:48,620 --> 00:11:50,323
but we're focusing on RSA here.

187
00:11:51,377 --> 00:11:54,420
So in some sense generating
random numbers is really easy.

188
00:11:54,420 --> 00:11:56,270
You just choose a random number

189
00:11:56,270 --> 00:11:58,610
and then check if it's
prime using for example

190
00:11:58,610 --> 00:12:00,340
the Miller-Rabin primality test

191
00:12:00,340 --> 00:12:01,300
and then you keep doing that

192
00:12:01,300 --> 00:12:03,439
until you find a number that's prime.

193
00:12:03,440 --> 00:12:05,730
The problem with this is
that Miller-Rabin is itself

194
00:12:05,730 --> 00:12:08,360
a little bit slow and
only a small fraction

195
00:12:08,360 --> 00:12:10,645
of randomly chosen large numbers are prime

196
00:12:10,645 --> 00:12:14,670
so all in all this takes sort of a log X

197
00:12:14,670 --> 00:12:19,670
to the fourth time give or
take and overall it's too slow

198
00:12:20,370 --> 00:12:21,963
to be super practical.

199
00:12:23,040 --> 00:12:26,699
So what is instead typically
done by RSA libraries

200
00:12:26,700 --> 00:12:29,580
is trial division where
you choose a random number

201
00:12:29,580 --> 00:12:31,840
and then you first check
that it's not like even

202
00:12:31,840 --> 00:12:34,450
or a multiple of three or
a multiple of any other

203
00:12:34,450 --> 00:12:36,760
small prime number and then you test it

204
00:12:36,760 --> 00:12:40,163
with your slower primality
tests like with Miller-Rabin.

205
00:12:40,163 --> 00:12:42,960
So this reduces the number
of calls to Miller-Rabin

206
00:12:42,960 --> 00:12:45,930
and speeds you up but
you can do even better

207
00:12:45,930 --> 00:12:49,353
if you can generate a
number that is not divisible

208
00:12:49,354 --> 00:12:52,340
by the first however many
primes by construction

209
00:12:52,340 --> 00:12:55,300
so then it will automatically
pass the trial division step

210
00:12:55,300 --> 00:12:57,229
and you don't have to do that.

211
00:12:57,230 --> 00:13:00,120
Or another way to say
this is that it's co prime

212
00:13:00,120 --> 00:13:04,350
to the product M of the first
however many prime numbers.

213
00:13:04,350 --> 00:13:06,160
So what we wanna do is
generate a random number

214
00:13:06,160 --> 00:13:08,327
that's co prime to M, test if it's prime,

215
00:13:08,327 --> 00:13:11,390
and if so we're done and if not try again

216
00:13:11,390 --> 00:13:13,890
and this will be faster
than the naive method

217
00:13:13,890 --> 00:13:17,390
by a factor of M over 5M
which is about 10 or 12

218
00:13:17,390 --> 00:13:20,370
for RSA size numbers because
this is sort of the ratio

219
00:13:20,370 --> 00:13:23,220
of composite numbers that you
weed out using this method.

220
00:13:24,420 --> 00:13:26,300
Of course, you know, in some sense

221
00:13:26,300 --> 00:13:27,500
I've just kicked the can down the road.

222
00:13:27,500 --> 00:13:30,320
How do I choose a random
number that's co prime to M?

223
00:13:30,320 --> 00:13:33,320
So a method suggested by
(indistinct) and (indistinct)

224
00:13:33,320 --> 00:13:35,400
is to use the Chinese remainder theorem.

225
00:13:35,400 --> 00:13:37,760
So a random number that's co prime to M

226
00:13:37,760 --> 00:13:41,680
or that's not divisible
by the first K primes

227
00:13:41,680 --> 00:13:44,880
is the same thing says the
Chinese remainder theorem

228
00:13:44,880 --> 00:13:47,570
as a number that's random and not zero

229
00:13:47,570 --> 00:13:49,794
mod all of those primes.

230
00:13:49,794 --> 00:13:51,600
So you just choose what X is going to be

231
00:13:51,600 --> 00:13:54,280
mod each of these small prime numbers QI

232
00:13:54,280 --> 00:13:57,089
and then you solve the
equation that X is congruent to

233
00:13:57,090 --> 00:14:00,050
XI mod QI using the
Chinese remainder theorem.

234
00:14:00,050 --> 00:14:02,702
So you would do this by
calculating the sum of

235
00:14:02,702 --> 00:14:06,560
XI times theta I where theta
I is a pre-computed value

236
00:14:06,560 --> 00:14:09,392
that's like one mod QI and
zero mod the other ones.

237
00:14:10,820 --> 00:14:14,660
The problem with this
is you need like maybe

238
00:14:14,660 --> 00:14:17,790
100 of these theta I
and they're kind of big

239
00:14:17,790 --> 00:14:20,880
and so at least on a smart
card or small embedded device

240
00:14:20,880 --> 00:14:24,200
you're not going to be able to
afford the storage for them.

241
00:14:24,200 --> 00:14:26,690
But in some sense this
is solving a problem

242
00:14:26,690 --> 00:14:28,910
that's stronger than we need it to be.

243
00:14:28,910 --> 00:14:32,913
So we don't actually care
what X is exactly mod QI.

244
00:14:33,760 --> 00:14:35,770
We only needed it to
be random and not zero

245
00:14:35,770 --> 00:14:38,620
so we don't need it to be XI mod QI.

246
00:14:38,620 --> 00:14:41,830
It can be some multiple of XI mod QI.

247
00:14:41,830 --> 00:14:45,253
So with that observation we
notice that you can replace

248
00:14:45,253 --> 00:14:48,350
theta I with M over QI since M over QI

249
00:14:48,350 --> 00:14:50,690
is not divisible by QI
but it's divisible by

250
00:14:50,690 --> 00:14:51,740
all the other primes.

251
00:14:53,303 --> 00:14:57,150
So this, it seems like we've
improved this a little bit

252
00:14:57,150 --> 00:14:58,569
but now you have to implement division

253
00:14:58,570 --> 00:15:00,110
on your tiny processor.

254
00:15:00,110 --> 00:15:02,260
But in fact you can
compute this expression

255
00:15:02,260 --> 00:15:06,230
sum of XI times M over QI
iteratively building up the value

256
00:15:06,230 --> 00:15:08,900
M over QI over loop iterations.

257
00:15:08,900 --> 00:15:13,100
And so this enables a
simple and quite fast loop

258
00:15:13,100 --> 00:15:17,810
that allows you to calculate
random candidate values

259
00:15:17,810 --> 00:15:19,609
using the Chinese remainder theorem.

260
00:15:20,560 --> 00:15:22,260
A completely different
method that we found

261
00:15:22,260 --> 00:15:24,290
uses quadratic residueosity.

262
00:15:24,290 --> 00:15:27,520
So a value U is called
a quadratic nonresidue

263
00:15:27,520 --> 00:15:31,210
if it's not equivalent to
the square of any number

264
00:15:31,210 --> 00:15:33,083
mod some prime.

265
00:15:34,100 --> 00:15:36,940
And so you can precompute again

266
00:15:36,940 --> 00:15:39,840
using the Chinese remainder
theorem a single value U

267
00:15:39,840 --> 00:15:43,000
that's a quadratic nonresidue
or such that minus U

268
00:15:43,000 --> 00:15:46,873
is a quadratic nonresidue mod
any of these small primes.

269
00:15:48,770 --> 00:15:52,610
And in that case, the
expression Y squared plus U

270
00:15:52,610 --> 00:15:56,230
for integers Y is not divisible
by any of these small primes

271
00:15:56,230 --> 00:15:58,720
it's co prime to M for all Y.

272
00:15:58,720 --> 00:16:01,800
So you could imagine
choosing your candidate prime

273
00:16:01,800 --> 00:16:05,589
as just R squared plus U
where R as a random number.

274
00:16:05,590 --> 00:16:07,140
Now that itself doesn't work

275
00:16:08,090 --> 00:16:10,250
because while it does
give you a random prime

276
00:16:10,250 --> 00:16:12,270
it doesn't give you a
uniformly random prime.

277
00:16:12,270 --> 00:16:15,329
Only a very small fraction
of numbers are of this form

278
00:16:15,330 --> 00:16:17,170
so you might be worried that it would have

279
00:16:17,170 --> 00:16:18,632
subtle security problems.

280
00:16:19,770 --> 00:16:22,689
However, if you take a number of these

281
00:16:22,690 --> 00:16:26,470
and multiply them together mod
M the product of two values

282
00:16:26,470 --> 00:16:29,342
that are co prime to M
is again co prime to M

283
00:16:29,342 --> 00:16:33,430
then the more of these
that you multiply together

284
00:16:33,430 --> 00:16:35,099
the closer you'll get to uniform

285
00:16:35,100 --> 00:16:37,260
so we have a theorem to this
effect and we suggest that

286
00:16:37,260 --> 00:16:38,830
if you multiply six of them together

287
00:16:38,830 --> 00:16:40,950
it's probably close enough.

288
00:16:40,950 --> 00:16:44,000
So this gives you a
very fast and simple way

289
00:16:44,000 --> 00:16:46,850
to choose random numbers
that are not divisible

290
00:16:46,850 --> 00:16:48,630
by any small primes.

291
00:16:48,630 --> 00:16:52,360
And while it's a little bit slower than

292
00:16:52,360 --> 00:16:55,300
the Chinese remainder theorem
method, it's also simpler

293
00:16:55,300 --> 00:16:57,290
and it only uses large random numbers

294
00:16:57,290 --> 00:17:00,242
which mitigate certain
side channel attacks.

295
00:17:02,570 --> 00:17:06,290
So that's for how you
generate a RSA private key

296
00:17:06,290 --> 00:17:08,742
so next step, how do you use them?

297
00:17:09,700 --> 00:17:13,393
So this is RSA Chinese remainder
theorem without Q inverse.

298
00:17:14,490 --> 00:17:17,960
So the RSA decryption
equation is well known.

299
00:17:17,960 --> 00:17:21,609
If you take a cipher text C you
just raise it to the D power

300
00:17:21,609 --> 00:17:24,990
where D is the secret exponent mod N.

301
00:17:24,990 --> 00:17:28,400
But it's much faster by
a factor of about four

302
00:17:28,400 --> 00:17:31,400
to compute this equation
separately mod P and mod Q

303
00:17:31,400 --> 00:17:33,610
because they're smaller
and then combine them

304
00:17:33,610 --> 00:17:35,139
using the Chinese remainder theorem

305
00:17:35,140 --> 00:17:37,390
using this third equation
shown on the slide.

306
00:17:38,940 --> 00:17:41,050
However this equation
requires that you have

307
00:17:41,050 --> 00:17:43,270
pre-computed the value Q inverse mod P

308
00:17:43,270 --> 00:17:45,129
which is not terribly difficult to compute

309
00:17:45,130 --> 00:17:46,526
but it's a little bit slow.

310
00:17:46,526 --> 00:17:49,310
And that means that to do this efficiently

311
00:17:49,310 --> 00:17:51,200
you'll have to store Q inverse mod P

312
00:17:51,200 --> 00:17:52,623
as part of your private key.

313
00:17:54,540 --> 00:17:57,060
In order to avoid this
we turned to a batching,

314
00:17:57,060 --> 00:18:00,470
a batched in version
method that I invented

315
00:18:00,470 --> 00:18:02,780
for elliptic curves some while ago.

316
00:18:02,780 --> 00:18:05,889
And the idea is that instead
of computing C to the D

317
00:18:05,890 --> 00:18:07,980
or you might call it C to the one over E

318
00:18:07,980 --> 00:18:12,050
'cause that's what D is,
times Q inverse mod P

319
00:18:12,050 --> 00:18:15,120
by calculating those two terms separately

320
00:18:15,120 --> 00:18:18,320
you will want to calculate
them together as a batch.

321
00:18:18,320 --> 00:18:23,320
And then if you can calculate
this mod P and then mod Q

322
00:18:23,980 --> 00:18:26,310
you can combine them using
this more symmetric version

323
00:18:26,310 --> 00:18:30,393
of the Chinese remainder theorem
shown on on the left here.

324
00:18:31,240 --> 00:18:34,550
So how do you compute C to
the one over E Q inverse?

325
00:18:34,550 --> 00:18:38,360
The idea is to consider a
sort of grid of the values

326
00:18:38,360 --> 00:18:42,439
that you can get by multiplying
powers of C by powers of Q

327
00:18:42,440 --> 00:18:44,620
where you can easily go up into the right

328
00:18:44,620 --> 00:18:47,120
just by multiplying numbers together.

329
00:18:47,120 --> 00:18:49,459
But it's harder to go
down and to the left.

330
00:18:49,460 --> 00:18:53,190
However if you calculate this
value C to the E minus one

331
00:18:53,190 --> 00:18:57,690
Q to the E then in one
expensive exponentiation

332
00:18:57,690 --> 00:19:00,770
raise it to the minus D power,

333
00:19:00,770 --> 00:19:02,800
the P minus one minus D power

334
00:19:02,800 --> 00:19:07,580
then you'll get C to the one
over N minus one Q inverse

335
00:19:07,580 --> 00:19:10,639
which you can then multiply
up to get C to the one over E

336
00:19:10,640 --> 00:19:11,980
Q inverse.

337
00:19:11,980 --> 00:19:14,075
So this is only slightly slower

338
00:19:14,075 --> 00:19:16,510
than what you would have
done in the first place

339
00:19:16,510 --> 00:19:18,510
'cause it has that one expensive step.

340
00:19:18,510 --> 00:19:21,090
It additionally has a somewhat
cheaper step of computing

341
00:19:21,090 --> 00:19:24,149
C to the E minus one Q to
the E and this costs you

342
00:19:24,150 --> 00:19:26,280
maybe a few percent and for RSA-3072.

343
00:19:29,410 --> 00:19:32,000
The other thing to note about this is that

344
00:19:32,000 --> 00:19:33,900
it sort of dovetails into

345
00:19:33,900 --> 00:19:36,700
existing side channel
countermeasures for RSA

346
00:19:36,700 --> 00:19:39,090
in which case it's almost free.

347
00:19:39,090 --> 00:19:39,923
Furthermore there are

348
00:19:39,923 --> 00:19:41,913
a number of generalizations in the paper.

349
00:19:44,440 --> 00:19:47,170
So finally we can combine
these two techniques to do

350
00:19:47,170 --> 00:19:49,200
RSA with compressed private keys.

351
00:19:49,200 --> 00:19:50,880
So what's compressed private keys about?

352
00:19:50,880 --> 00:19:53,970
So if you imagine the
trade-offs between ECC and RSA

353
00:19:53,970 --> 00:19:56,470
on an embedded device while
you should be using ECC

354
00:19:56,470 --> 00:19:57,900
because it has a number of advantages

355
00:19:57,900 --> 00:19:59,920
but one of them is that
the private key is just

356
00:19:59,920 --> 00:20:02,020
a small random number
so it's easy to generate

357
00:20:02,020 --> 00:20:03,410
and easy to store.

358
00:20:03,410 --> 00:20:06,924
Whereas the RSA private key
is a much larger structure

359
00:20:06,924 --> 00:20:10,860
and it's very slow to
generate so it's harder to,

360
00:20:10,860 --> 00:20:13,310
for example, choose a pseudorandom seed,

361
00:20:13,310 --> 00:20:14,770
generate the private key from seed,

362
00:20:14,770 --> 00:20:15,940
and then just store the seed

363
00:20:15,940 --> 00:20:17,270
and then regenerate it when needed

364
00:20:17,270 --> 00:20:20,060
because the regeneration process is slow.

365
00:20:20,060 --> 00:20:21,810
But if you consider what the components

366
00:20:21,810 --> 00:20:24,399
of the RSA private key are for CRT

367
00:20:24,400 --> 00:20:27,270
'cause you want things
to be reasonably fast

368
00:20:27,270 --> 00:20:30,300
you have P and Q and
then D mod P minus one

369
00:20:30,300 --> 00:20:34,230
and mod Q minus one and Q inverse mod P.

370
00:20:34,230 --> 00:20:38,500
So this, using this
work plus previous work

371
00:20:38,500 --> 00:20:39,960
can all be sort of bypassed.

372
00:20:39,960 --> 00:20:43,151
So for P and Q, you can
choose a random seed

373
00:20:43,151 --> 00:20:45,330
and then run the prime
generation algorithm

374
00:20:45,330 --> 00:20:48,280
until you find a prime number
and then you record a hint,

375
00:20:48,280 --> 00:20:51,910
that's what iteration
you found the prime on,

376
00:20:51,910 --> 00:20:54,570
and in that case you don't need to rerun

377
00:20:54,570 --> 00:20:57,080
the prime generation algorithm again.

378
00:20:57,080 --> 00:20:59,919
You can just rerun the sampling
algorithm which is fast.

379
00:20:59,920 --> 00:21:03,523
It's just those, you know, six
multiplications or whatever,

380
00:21:04,630 --> 00:21:07,870
to regenerate P and then to regenerate Q.

381
00:21:07,870 --> 00:21:11,570
For D, sub P and D sub Q,
(indistinct) and (indistinct)

382
00:21:11,570 --> 00:21:13,500
show how to calculate this efficiently

383
00:21:13,500 --> 00:21:15,960
using Hensel's lema and Arazi's lema

384
00:21:15,960 --> 00:21:18,810
and then for Q inverse mod
P we can avoid that entirely

385
00:21:18,810 --> 00:21:21,300
using the new RSA CRT method.

386
00:21:21,300 --> 00:21:23,169
So the upshot of this is that if you have

387
00:21:23,170 --> 00:21:25,930
an RSA-3072 private key
and you want to store it

388
00:21:25,930 --> 00:21:28,370
on an embedded device in
like fuses or something

389
00:21:28,370 --> 00:21:30,409
instead of using seven and a half kilobits

390
00:21:30,410 --> 00:21:33,660
you can store it in only about 160 bits.

391
00:21:33,660 --> 00:21:35,360
This comes with a small performance loss

392
00:21:35,360 --> 00:21:38,330
but if you're in a
device that's constrained

393
00:21:38,330 --> 00:21:40,129
by the size of its fuse array

394
00:21:40,130 --> 00:21:42,923
then this could definitely
be worth the trade off.

395
00:21:44,710 --> 00:21:48,973
So that's all for my talk.
Thanks for listening.

396
00:21:51,410 --> 00:21:53,600
- Hello my name is Mustapha Khairalla

397
00:21:53,600 --> 00:21:57,189
and today I will be presenting
the paper on the cost

398
00:21:57,190 --> 00:22:01,200
of ASIC hardware crackers,
a SHA-1 case study.

399
00:22:01,200 --> 00:22:04,087
This is a joint work with
Arupam Chattopadhyay,

400
00:22:04,087 --> 00:22:07,047
Gaetan Leuernt, Zakaria
Najm, Thomas Peyrin,

401
00:22:07,047 --> 00:22:09,133
and Vesselin Velichkov.

402
00:22:11,560 --> 00:22:15,100
So SHA-1 is a hash function
that has been widely used

403
00:22:15,100 --> 00:22:18,570
for many years and recently
there has been several attacks

404
00:22:18,570 --> 00:22:23,100
against it and in this
paper we just talk about

405
00:22:23,100 --> 00:22:24,750
the following research questions.

406
00:22:26,201 --> 00:22:29,560
The first thing is can we
reduce the financial cost

407
00:22:29,560 --> 00:22:31,970
of such attacks that have
been recently proposed

408
00:22:31,970 --> 00:22:33,320
against SHA-1?

409
00:22:33,320 --> 00:22:36,610
And also what is the
difference between the cost

410
00:22:36,610 --> 00:22:39,149
of implementing generic
attacks that's working

411
00:22:39,150 --> 00:22:40,400
against any hash functions

412
00:22:40,400 --> 00:22:42,320
versus the attacks that are specific

413
00:22:42,320 --> 00:22:44,439
for the SHA-1 hash function?

414
00:22:44,440 --> 00:22:47,067
And finally we address the question of

415
00:22:47,067 --> 00:22:50,680
what is the practicality
of applying attacks

416
00:22:50,680 --> 00:22:53,730
against an 80 bit collision
resistant hash function

417
00:22:53,730 --> 00:22:54,763
in practice?

418
00:22:57,310 --> 00:22:59,800
So some history about SHA-1.

419
00:22:59,800 --> 00:23:03,240
SHA-1 was selected as a
replacement to SHA-0 in 1995

420
00:23:04,200 --> 00:23:08,330
after some vulnerabilities
were discovered in SHA-0.

421
00:23:08,330 --> 00:23:12,320
SHA-1 itself was broken
in 2005 by Wang et al.

422
00:23:13,230 --> 00:23:18,230
It was practically broken
in 2017 by Stevens et al

423
00:23:18,620 --> 00:23:21,030
using a GPU cluster.

424
00:23:21,030 --> 00:23:23,290
This was done using what is known as

425
00:23:23,290 --> 00:23:25,193
the identical-prefix collusion.

426
00:23:26,240 --> 00:23:30,950
Then later again in 2019 a
more sophisticated attack

427
00:23:30,950 --> 00:23:33,550
or the chosen-prefix
attack was implemented by

428
00:23:33,550 --> 00:23:37,203
Leurent and Peyrin,
again using GPU clusters.

429
00:23:38,480 --> 00:23:41,590
And the complexity of
such attacks, both attacks

430
00:23:41,590 --> 00:23:46,590
was about two to the power
63 hash function operations.

431
00:23:48,410 --> 00:23:51,650
So what's a hash function
and what do we mean

432
00:23:51,650 --> 00:23:53,880
by collision resistance?

433
00:23:53,880 --> 00:23:58,880
Hash function is a function
that takes binary input strings

434
00:23:58,900 --> 00:24:03,900
of any length and outputs
a fixed length tag

435
00:24:04,120 --> 00:24:06,560
that is related to such inputs.

436
00:24:06,560 --> 00:24:07,812
It's like a fingerprint.

437
00:24:08,900 --> 00:24:12,630
And by collision resistance
we mean that we cannot

438
00:24:12,630 --> 00:24:15,200
find two (indistinct),
two different messages

439
00:24:15,200 --> 00:24:16,623
that lead to the same tag.

440
00:24:17,950 --> 00:24:21,673
By that we can use the tag as
an identifier of the message.

441
00:24:24,470 --> 00:24:27,390
The SHA-1 hash function
is based on what is called

442
00:24:27,390 --> 00:24:32,100
the Merkle-Damgard construction
which use a block cipher

443
00:24:32,100 --> 00:24:34,490
and uses the structure in the figure

444
00:24:34,490 --> 00:24:36,480
to implement a hash function.

445
00:24:36,480 --> 00:24:39,240
And it should be secure if the BlockCypher

446
00:24:39,240 --> 00:24:43,200
has block size of N then
the collision resistance

447
00:24:43,200 --> 00:24:45,563
should be N over two,
two to the N over two.

448
00:24:47,790 --> 00:24:50,030
The Merkle-Damgard
construction can be attacked

449
00:24:50,030 --> 00:24:54,680
by differential cryptanalysis
if we have like a prefix

450
00:24:54,680 --> 00:24:58,000
like certain number of dockcypher calls

451
00:24:58,000 --> 00:25:00,990
we can introduce a difference
and then after some blocks

452
00:25:00,990 --> 00:25:02,740
we can cancel the difference again.

453
00:25:04,000 --> 00:25:07,300
Ideally the complexity of such attacks

454
00:25:07,300 --> 00:25:10,770
should be higher than
the collision resistance

455
00:25:10,770 --> 00:25:13,173
but in case of SHA-1 this is not true.

456
00:25:15,460 --> 00:25:18,890
A more sophisticated attack
is the chosen-prefix attack

457
00:25:18,890 --> 00:25:22,950
where it works in a similar
way but instead of having

458
00:25:22,950 --> 00:25:25,160
zero different blocks at the beginning

459
00:25:25,160 --> 00:25:27,450
we have completely different blocks

460
00:25:27,450 --> 00:25:30,930
in each branch of the collision

461
00:25:30,930 --> 00:25:33,510
and then we use the
differential cryptanalysis

462
00:25:33,510 --> 00:25:36,093
to make such messages collide at the end.

463
00:25:38,390 --> 00:25:41,940
One way to find collisions
is that we represent

464
00:25:41,940 --> 00:25:44,702
the hash function using functional graphs

465
00:25:44,702 --> 00:25:49,702
where like each input
leads to an output vertex

466
00:25:51,230 --> 00:25:54,690
and we searched for
collisions in such graphs

467
00:25:54,690 --> 00:25:58,870
and there are efficient algorithms
to find these collisions

468
00:25:58,870 --> 00:26:02,169
with the collision resistance complexity

469
00:26:02,170 --> 00:26:05,780
two to the N over two
but with very low memory

470
00:26:05,780 --> 00:26:08,543
and other requirements required.

471
00:26:11,070 --> 00:26:12,830
The differential cryptanalysis of SHA-1

472
00:26:12,830 --> 00:26:14,530
works in a different way.

473
00:26:14,530 --> 00:26:18,970
In SHA-1 we have an internal
state A and message M

474
00:26:18,970 --> 00:26:23,970
and the message is 512 bits
but it consists of (indistinct)

475
00:26:25,520 --> 00:26:30,520
like 16, 32 bit words and we
can control the difference

476
00:26:30,800 --> 00:26:34,000
in such shorts such that we
can lead to zero differences

477
00:26:34,000 --> 00:26:35,633
in the internal state.

478
00:26:36,640 --> 00:26:40,800
And what happens is we find
two messages and we partially

479
00:26:40,800 --> 00:26:44,020
find a solution that satisfies
a certain differential path

480
00:26:44,870 --> 00:26:47,530
that is computer-generated.

481
00:26:47,530 --> 00:26:51,490
And after we do that we
have to probabilistically

482
00:26:51,490 --> 00:26:53,810
satisfy the rest of the
bits and we see the bits

483
00:26:53,810 --> 00:26:57,510
that are (indistinct), are
bits that are unconstrained.

484
00:26:57,510 --> 00:27:01,150
And in this bit that are free
to choose their (indistinct)

485
00:27:01,150 --> 00:27:03,240
there is something called neutral bits.

486
00:27:03,240 --> 00:27:05,300
These neutral bits have a high probability

487
00:27:05,300 --> 00:27:09,290
that by changing them the
solution is not affected

488
00:27:09,290 --> 00:27:12,530
so we can brute force
over these neutral bits

489
00:27:12,530 --> 00:27:14,253
until we find a valid solution.

490
00:27:16,570 --> 00:27:19,939
And basically it's like
searching in a tree.

491
00:27:19,940 --> 00:27:23,020
So we keep changing
some of the neutral bits

492
00:27:23,020 --> 00:27:26,110
according to certain conditions
and if they work we go on

493
00:27:26,110 --> 00:27:29,293
and start changing more
neutral bits and so on.

494
00:27:31,000 --> 00:27:33,660
So the goal is to compare
the cost of building

495
00:27:33,660 --> 00:27:37,500
a SHA-1 attack cluster using ASIC and GPU

496
00:27:37,500 --> 00:27:40,510
according to the following
three attack scenarios.

497
00:27:40,510 --> 00:27:45,510
Generic 128 bit collision,
generic 160 bit collision,

498
00:27:47,270 --> 00:27:50,210
and implementing the chosen prefix-attack

499
00:27:50,210 --> 00:27:52,253
that was already implemented on GPU.

500
00:27:54,760 --> 00:27:58,450
To do that we design
two hardware circuits.

501
00:27:58,450 --> 00:28:01,860
The first one applies the
neutral bit search algorithm

502
00:28:01,860 --> 00:28:05,790
that I briefly mentioned
where we have two SHA-1 cores

503
00:28:06,680 --> 00:28:09,550
and then we upload a base solution

504
00:28:09,550 --> 00:28:13,820
and we upload some conditions
about the neutral bits

505
00:28:13,820 --> 00:28:17,879
and then we have an
enumerator that search through

506
00:28:17,880 --> 00:28:20,130
the neutral bits and compares whether

507
00:28:20,130 --> 00:28:23,190
it satisfies certain
differential path or not

508
00:28:23,190 --> 00:28:24,750
and reports the result.

509
00:28:24,750 --> 00:28:28,010
And after that the computer
will handle the rest

510
00:28:28,010 --> 00:28:29,960
and find the collision.

511
00:28:29,960 --> 00:28:33,210
The other circuit that we present is

512
00:28:33,210 --> 00:28:38,210
a birthday collision
circuit where we start with

513
00:28:38,550 --> 00:28:41,840
a random point in the
functional graph of SHA-1

514
00:28:41,840 --> 00:28:45,310
and then we search for a
certain condition in the graph

515
00:28:45,310 --> 00:28:48,970
and this leads to a trace in the graph

516
00:28:48,970 --> 00:28:52,020
and then this trace is
uploaded to the computer

517
00:28:52,020 --> 00:28:55,133
and the computer analyze the
trace and finds the collision.

518
00:28:57,460 --> 00:29:01,720
Once we have these two cores,
we'll call them NP and BD,

519
00:29:01,720 --> 00:29:05,610
we built a chip from them
like by having many cores

520
00:29:05,610 --> 00:29:09,990
and having a SPI interface
and the control unit

521
00:29:09,990 --> 00:29:13,770
and then this chip is connected to an FVGA

522
00:29:13,770 --> 00:29:17,700
or a Raspberry Pi which
connects through Ethernet

523
00:29:17,700 --> 00:29:20,724
to a computer and we have many such chips

524
00:29:20,724 --> 00:29:22,377
working in (indistinct).

525
00:29:24,420 --> 00:29:29,420
We design these circuits
using hardware design

526
00:29:29,890 --> 00:29:34,700
and we implemented the shape up to layout

527
00:29:34,700 --> 00:29:36,823
using the cadence design flow.

528
00:29:38,180 --> 00:29:42,160
And we have analyzed the area
and performance of the chip

529
00:29:42,160 --> 00:29:44,963
and the power consumption
using simulations.

530
00:29:47,670 --> 00:29:50,840
So what are the results that we got?

531
00:29:50,840 --> 00:29:53,870
Here we look at the cost
for the three attacks.

532
00:29:53,870 --> 00:29:56,580
What we're doing is that we
are, we are assuming that

533
00:29:56,580 --> 00:30:00,530
we are running a cluster of
such machines over three years

534
00:30:00,530 --> 00:30:04,430
and when that happens we
estimate the cost of one attack.

535
00:30:04,430 --> 00:30:07,680
So for example maybe the
effect takes one month

536
00:30:07,680 --> 00:30:12,680
and we run it for three years
so we divide the overall cost

537
00:30:13,300 --> 00:30:17,810
by 36 or the number of
months in three years.

538
00:30:17,810 --> 00:30:21,030
So when we have a 128 bit collision

539
00:30:21,030 --> 00:30:24,790
basically we're taking
SHA-1 which outputs 160 bits

540
00:30:24,790 --> 00:30:28,659
and we're truncated
the output to 128 bits.

541
00:30:28,660 --> 00:30:33,660
Using ASIC the cost can be
between almost $1,000 and $8,000.

542
00:30:36,287 --> 00:30:38,460
And for GPU we have two cases.

543
00:30:38,460 --> 00:30:42,170
First we can rent GPUs which
was actually done in practice

544
00:30:42,170 --> 00:30:45,130
or we can buy a GPU like a lot of GPUs

545
00:30:45,130 --> 00:30:46,840
and build our own cluster.

546
00:30:46,840 --> 00:30:51,840
And the cost is between
$43,000 and $61,000.

547
00:30:51,990 --> 00:30:54,710
For the differential
cryptanalysis collision

548
00:30:54,710 --> 00:30:59,360
the cost for ASIC is
between $1.6K and $32K

549
00:30:59,360 --> 00:31:01,060
depending on the speed of the attack

550
00:31:01,060 --> 00:31:04,419
and how many attacks we
want over three years.

551
00:31:04,420 --> 00:31:07,540
Renting the GPUs is the same, $43K

552
00:31:07,540 --> 00:31:10,463
while buying GPU is $26K.

553
00:31:12,740 --> 00:31:17,740
For the full generic
collision on SHA-1, 160 bits,

554
00:31:18,100 --> 00:31:21,490
the cost for ASIC is $51 million,

555
00:31:21,490 --> 00:31:23,750
the cost for renting GPU is $4 billion,

556
00:31:23,750 --> 00:31:27,740
and for buying the GPUs is $2.5 billion.

557
00:31:27,740 --> 00:31:32,340
Now we see that the cost for
the low complexity attacks

558
00:31:32,340 --> 00:31:35,699
that are dominated by two
to the power 64 complexity

559
00:31:35,700 --> 00:31:40,700
should be used under ASIC
are not that far off.

560
00:31:40,860 --> 00:31:44,909
For the generic attack
ASIC is cheaper than GPU

561
00:31:44,910 --> 00:31:48,540
but for the differential
cryptanalysis the GPU is cheaper.

562
00:31:48,540 --> 00:31:52,879
While when we go to like higher
complexity two to the 80,

563
00:31:52,880 --> 00:31:55,960
which is related to the 160 bit collision

564
00:31:55,960 --> 00:31:57,823
ASIC is much more competitive.

565
00:32:02,720 --> 00:32:06,237
Now this is the cost of
building the overall machine

566
00:32:07,820 --> 00:32:11,409
which doesn't include
the running costs such as

567
00:32:11,410 --> 00:32:13,240
the energy consumption.

568
00:32:13,240 --> 00:32:16,420
And we estimate the energy
consumption in the paper

569
00:32:16,420 --> 00:32:18,230
and it's included in the previous cost

570
00:32:18,230 --> 00:32:20,860
but the estimation is based only on the

571
00:32:20,860 --> 00:32:23,510
cheap energy consumption
so we are aware that

572
00:32:23,510 --> 00:32:27,280
some details are missing
but we have seen that

573
00:32:27,280 --> 00:32:31,100
the energy consumption while
it's a significant value

574
00:32:31,100 --> 00:32:35,560
it's dominated by the
manufacturing costs still

575
00:32:35,560 --> 00:32:40,560
so we just provide estimations
but the results show that

576
00:32:41,320 --> 00:32:45,149
using $11 million we can
basically build an ASIC cluster

577
00:32:45,150 --> 00:32:48,440
that can break 160 bit hash functions.

578
00:32:48,440 --> 00:32:51,470
But this means that even
if SHA-1 was not broken

579
00:32:51,470 --> 00:32:55,781
that Y differential cryptanalysis
it can still be broken

580
00:32:55,781 --> 00:32:58,503
by a high budget cluster.

581
00:32:59,920 --> 00:33:02,693
So these are the answers to
the questions we presented.

582
00:33:03,950 --> 00:33:06,600
Can the financial cost
for the current attacks

583
00:33:06,600 --> 00:33:08,669
against SHA-1 be reduced?

584
00:33:08,670 --> 00:33:11,020
The answer is yes but only when you have

585
00:33:11,020 --> 00:33:13,379
a big initial investment at the beginning

586
00:33:13,380 --> 00:33:15,280
because to build such ASIC clusters

587
00:33:15,280 --> 00:33:17,480
you need a big initial cost

588
00:33:17,480 --> 00:33:20,283
and then the amortized cost will be lower.

589
00:33:22,500 --> 00:33:25,710
Now we also show that implementing

590
00:33:25,710 --> 00:33:30,650
a generic 128 bit
collision is cheaper than

591
00:33:30,650 --> 00:33:34,550
implementing a 128 bit collision using

592
00:33:37,320 --> 00:33:38,450
differential cryptanalysis.

593
00:33:38,450 --> 00:33:41,540
While both attacks have similar complexity

594
00:33:42,400 --> 00:33:44,963
the generic attack in practice is cheaper.

595
00:33:46,290 --> 00:33:49,030
We also show that an entity

596
00:33:49,030 --> 00:33:50,930
with maybe a billion dollar budget

597
00:33:50,930 --> 00:33:54,550
in the near future can break
80 bit collision resistance

598
00:33:54,550 --> 00:33:56,600
with a generic attack in a month or less.

599
00:33:57,840 --> 00:33:58,899
That's it from me today.

600
00:33:58,900 --> 00:34:03,010
Thanks for watching and I
am happy to take questions

601
00:34:03,010 --> 00:34:04,060
in the conference.

602
00:34:04,060 --> 00:34:04,893
Thanks.

