1
00:00:01,240 --> 00:00:02,331
- Hey everybody.

2
00:00:02,331 --> 00:00:03,250
Great to be here.

3
00:00:03,250 --> 00:00:04,250
Thanks for joining.

4
00:00:04,250 --> 00:00:07,364
My name's Mark Wojtasiak, aka Woj.

5
00:00:07,364 --> 00:00:11,763
I lead the Research and
Strategy Team at Code42.

6
00:00:12,830 --> 00:00:14,530
Thanks again, for taking the time.

7
00:00:15,370 --> 00:00:17,210
We're gonna run through,
I'm gonna try and keep this.

8
00:00:17,210 --> 00:00:18,050
I know it's Wednesday.

9
00:00:18,050 --> 00:00:20,420
So we're gonna keep this as

10
00:00:21,320 --> 00:00:23,710
quick paced and light as possible.

11
00:00:23,710 --> 00:00:27,070
And I always like to start with a quote.

12
00:00:27,070 --> 00:00:29,520
This is a real, I love this quote

13
00:00:29,520 --> 00:00:30,489
Dan Rather actually said this.

14
00:00:30,489 --> 00:00:32,140
He actually tweeted this

15
00:00:33,380 --> 00:00:36,677
and he was obviously talking
about journalism and he said,

16
00:00:36,677 --> 00:00:39,302
"How do we find the signals
of truth amidst the noise

17
00:00:39,302 --> 00:00:42,700
of disinformation and propaganda?"

18
00:00:42,700 --> 00:00:44,330
And when I first saw
that quote, I was like,

19
00:00:44,330 --> 00:00:47,300
wow, that's applicable to a lot of

20
00:00:47,300 --> 00:00:49,360
what we're gonna be talking about today.

21
00:00:49,360 --> 00:00:53,190
And in this session,
we're gonna dive in deep

22
00:00:53,190 --> 00:00:55,080
into a few areas

23
00:00:56,300 --> 00:00:59,125
and it's largely centered
and I think the title

24
00:00:59,125 --> 00:01:00,844
of this presentation is insider risk,

25
00:01:00,844 --> 00:01:02,850
a data protection problem.

26
00:01:02,850 --> 00:01:05,055
We're gonna talk about that
data protection problem.

27
00:01:05,055 --> 00:01:08,070
We're also gonna talk a little bit about

28
00:01:08,070 --> 00:01:12,539
a pragmatic contextual
approach to that problem

29
00:01:12,540 --> 00:01:14,743
that's largely outcomes driven.

30
00:01:15,620 --> 00:01:18,110
So get your buzzword bingo cards out

31
00:01:18,110 --> 00:01:21,560
because I might throw
a few of your favorite

32
00:01:21,560 --> 00:01:23,440
security buzzwords out,

33
00:01:23,440 --> 00:01:26,399
but the image you see on the right here

34
00:01:26,400 --> 00:01:31,209
we use this often to describe
how employees work today.

35
00:01:31,209 --> 00:01:34,690
It's no longer linear, it's a mess.

36
00:01:34,690 --> 00:01:36,390
It's a mess of activity.

37
00:01:36,390 --> 00:01:38,213
And in that mess of activity,

38
00:01:39,310 --> 00:01:42,483
what you ultimately
end up with is what we,

39
00:01:43,720 --> 00:01:45,130
what we call insider risk,

40
00:01:45,130 --> 00:01:50,130
and insider risk, we consider
a data protection problem.

41
00:01:50,430 --> 00:01:55,430
So a little bit of a level
set before we jump into,

42
00:01:55,610 --> 00:01:58,814
you know, the best way to
understand this problem

43
00:01:58,814 --> 00:02:03,814
to manage this problem,
to mitigate risk to data,

44
00:02:04,160 --> 00:02:06,610
let's level set on some definitions,

45
00:02:06,610 --> 00:02:08,940
just so we're all on the same page, right?

46
00:02:08,940 --> 00:02:12,150
So at Code42, we think of it this way.

47
00:02:12,150 --> 00:02:15,281
We think there's two
different dichotomies here.

48
00:02:15,281 --> 00:02:16,830
You've got an insider risk problem

49
00:02:16,830 --> 00:02:18,963
and you've got an insider threat problem.

50
00:02:19,880 --> 00:02:22,480
An insider threat, you
know, everyone kind of jumps

51
00:02:22,480 --> 00:02:25,608
to the kind of definition
of malicious user.

52
00:02:25,609 --> 00:02:27,694
It's the 1% of employees

53
00:02:27,694 --> 00:02:29,709
that are doing bad things, right?

54
00:02:29,710 --> 00:02:31,500
Malicious intent,

55
00:02:31,500 --> 00:02:35,820
they could be, you know,
stealing data, sabotaging,

56
00:02:35,820 --> 00:02:38,293
you know, deleting whatever it might be.

57
00:02:39,490 --> 00:02:41,270
And in an insider threat world

58
00:02:41,270 --> 00:02:45,530
you focus on specific users
committing isolated acts

59
00:02:45,530 --> 00:02:47,153
of exfiltration with malicious intent.

60
00:02:47,153 --> 00:02:51,003
That's how we define kind
of an insider threat.

61
00:02:52,020 --> 00:02:54,640
What we're talking about
today is a bigger problem,

62
00:02:54,640 --> 00:02:56,560
insider risk, and we coin it more

63
00:02:56,561 --> 00:02:59,023
as a data protection
problem not a user problem

64
00:02:59,023 --> 00:03:01,593
but a data problem.

65
00:03:01,593 --> 00:03:06,593
And it just is naturally comes
with the way people work,

66
00:03:06,720 --> 00:03:08,283
the way employees work.

67
00:03:09,130 --> 00:03:11,783
It doesn't focus on any
explicit set of users.

68
00:03:11,783 --> 00:03:15,410
It doesn't focus on any
explicit set of data.

69
00:03:15,410 --> 00:03:16,470
It looks at all users.

70
00:03:16,470 --> 00:03:17,303
We gotta look at all data.

71
00:03:17,303 --> 00:03:19,530
We gotta look at all possible vectors

72
00:03:19,530 --> 00:03:21,346
in which that data is moving

73
00:03:21,346 --> 00:03:25,160
no matter the intent of of the employee.

74
00:03:25,160 --> 00:03:26,620
And how do you manage this?

75
00:03:26,620 --> 00:03:29,390
How do you manage this magnitude of risk

76
00:03:29,390 --> 00:03:33,319
that is largely pervasive
across organizations

77
00:03:33,319 --> 00:03:37,600
no matter size, scope,
industry, whatever it may be.

78
00:03:37,600 --> 00:03:40,210
So our contention is can we
solve for this problem first?

79
00:03:40,210 --> 00:03:41,252
Can we solve for insider risk

80
00:03:41,252 --> 00:03:44,090
'cause if we solve for insider risk,

81
00:03:44,090 --> 00:03:49,090
we can solve for inevitably
solve for any malicious actors

82
00:03:49,120 --> 00:03:53,050
inside the organization,
aka insider threat.

83
00:03:53,050 --> 00:03:54,610
So just that initial level set

84
00:03:54,610 --> 00:03:59,018
on definitions and what
we're talking about.

85
00:03:59,018 --> 00:04:01,523
We see them as two distinct problems.

86
00:04:02,460 --> 00:04:05,410
So where does the problem come from?

87
00:04:05,410 --> 00:04:08,390
I'm gonna hit since I'm in
research and strategy of course,

88
00:04:08,390 --> 00:04:11,220
what would a slide deck be without stats?

89
00:04:11,220 --> 00:04:12,930
And I'm not gonna pummel
you with too much.

90
00:04:12,930 --> 00:04:15,670
We'll get into the practical application

91
00:04:15,670 --> 00:04:18,599
of insider risk management in a minute,

92
00:04:18,600 --> 00:04:20,915
but let me just level
set with some context

93
00:04:20,915 --> 00:04:24,280
around what we see and
hear in the marketplace.

94
00:04:24,280 --> 00:04:27,599
So this is going to be familiar to,

95
00:04:27,600 --> 00:04:29,280
I'm gonna say all of you, right?

96
00:04:29,280 --> 00:04:34,280
So you think about what
security teams have to deal with

97
00:04:35,850 --> 00:04:38,980
right now, thousands of end points

98
00:04:38,980 --> 00:04:40,820
connected to thousands of users

99
00:04:41,970 --> 00:04:44,163
with access to millions of files.

100
00:04:44,163 --> 00:04:45,647
All those files are being created,

101
00:04:45,647 --> 00:04:47,349
where they're being modified,

102
00:04:47,350 --> 00:04:49,240
where they're being deleted

103
00:04:49,240 --> 00:04:53,480
and now you overlay with
remote work hybrid workforce,

104
00:04:53,480 --> 00:04:56,750
you overlay them the
multitude of productivity

105
00:04:56,750 --> 00:04:59,800
and collaboration tools that
employees have access to

106
00:04:59,800 --> 00:05:01,770
both sanctioned and unsanctioned,

107
00:05:01,770 --> 00:05:05,240
means you literally
have hundreds of vectors

108
00:05:05,240 --> 00:05:08,563
of potential data exposure,
data exfiltration,

109
00:05:09,400 --> 00:05:13,780
data loss, data theft, whatever it may be.

110
00:05:13,780 --> 00:05:17,419
Now you compound that with the impact of

111
00:05:17,420 --> 00:05:19,788
of work from home over the
course of the last year

112
00:05:19,788 --> 00:05:22,800
and the COVID effect as

113
00:05:23,641 --> 00:05:24,822
we call it,

114
00:05:24,822 --> 00:05:27,550
and we did some research
on this in the last year

115
00:05:27,550 --> 00:05:29,440
of what that impact was

116
00:05:29,440 --> 00:05:32,850
and security leaders are saying, well,

117
00:05:32,850 --> 00:05:36,290
what we're seeing is employees
are nearly twice as likely

118
00:05:36,290 --> 00:05:38,720
to have leaked data than
they were pre-COVID.

119
00:05:38,720 --> 00:05:40,849
And that's not surprising given
they're working from home,

120
00:05:40,849 --> 00:05:42,156
they're using different devices,

121
00:05:42,156 --> 00:05:45,468
they're accessing the
clouds tools that they want,

122
00:05:45,468 --> 00:05:47,421
whether it's a personal productivity tool,

123
00:05:47,421 --> 00:05:50,010
whether it's whatever it may be, right?

124
00:05:50,010 --> 00:05:53,803
So how do you begin to
deal with this problem?

125
00:05:53,803 --> 00:05:56,536
How do you begin to deal with
the magnitude of this noise,

126
00:05:56,536 --> 00:06:00,256
this image we show of like how people work

127
00:06:00,256 --> 00:06:03,840
and truly understand where risk exists,

128
00:06:03,840 --> 00:06:07,280
where meaningful risk
exists within this sea

129
00:06:08,464 --> 00:06:10,963
of noise and how employees work?

130
00:06:12,050 --> 00:06:16,660
Well, we asked what makes it so hard?

131
00:06:16,660 --> 00:06:18,570
Why is it so hard to manage?

132
00:06:18,570 --> 00:06:23,570
Why is it so hard to detect
risk that is of material meaning

133
00:06:23,740 --> 00:06:25,170
to the business.

134
00:06:25,170 --> 00:06:28,532
And two thirds of the security
teams we talked to said,

135
00:06:28,532 --> 00:06:31,490
we just can't prioritize
the ones that matter.

136
00:06:31,490 --> 00:06:33,690
We don't have the context.

137
00:06:33,690 --> 00:06:37,710
We don't understand what
is everyday collaboration

138
00:06:37,710 --> 00:06:39,609
and what is exfiltration.

139
00:06:39,610 --> 00:06:43,910
We don't understand in a sea of

140
00:06:43,910 --> 00:06:46,034
alerts to triage within their SIM

141
00:06:46,034 --> 00:06:49,500
or whatever their operational process is

142
00:06:49,500 --> 00:06:51,250
what are the things to focus on?

143
00:06:51,250 --> 00:06:53,220
And a lot of times they're relying on

144
00:06:53,220 --> 00:06:54,420
putting pieces together.

145
00:06:54,420 --> 00:06:57,000
A lot of times they're
relying on their own intuition

146
00:06:57,000 --> 00:06:59,950
to prioritize the risks that matter.

147
00:06:59,950 --> 00:07:02,560
And then you, what you
end up with is a lot of,

148
00:07:02,560 --> 00:07:06,710
you know, shall I say,
a lot fatigue, right?

149
00:07:06,710 --> 00:07:08,332
Noise, whatever it might be.

150
00:07:10,810 --> 00:07:11,920
Why is the context missing?

151
00:07:11,920 --> 00:07:14,490
Why don't you have the context for

152
00:07:14,490 --> 00:07:16,453
to manage the insider risk problem?

153
00:07:17,350 --> 00:07:20,947
And this was shocking that that 91% said,

154
00:07:20,947 --> 00:07:22,600
"We just don't have the tech.

155
00:07:22,600 --> 00:07:24,860
We don't have the tech
that's purpose built

156
00:07:24,860 --> 00:07:27,094
for this problem."

157
00:07:27,094 --> 00:07:29,760
The new way people work,

158
00:07:29,760 --> 00:07:32,055
the hybrid workforce,
the remote workforce,

159
00:07:32,055 --> 00:07:33,290
whatever it may be.

160
00:07:33,290 --> 00:07:36,290
We're piecing together tech that we have

161
00:07:36,290 --> 00:07:39,095
to try and understand
where we need to focus,

162
00:07:39,095 --> 00:07:41,098
how we manage this problem,

163
00:07:41,098 --> 00:07:43,837
where we assign additional
security training,

164
00:07:43,837 --> 00:07:45,880
what security training should we focus on,

165
00:07:45,880 --> 00:07:47,839
et cetera, et cetera.

166
00:07:47,839 --> 00:07:50,907
And we start to peel back this onion,

167
00:07:50,907 --> 00:07:53,310
well, what are they using?

168
00:07:53,310 --> 00:07:54,640
Like what are they trying to do?

169
00:07:54,640 --> 00:07:57,390
How are they trying to
piece together technology

170
00:07:57,390 --> 00:07:58,675
in order to manage this problem?

171
00:07:58,675 --> 00:08:01,297
And if you think of that at its core,

172
00:08:01,297 --> 00:08:05,620
insider risk is fundamentally different

173
00:08:05,620 --> 00:08:08,702
than the way we've done data
protection in the past, right?

174
00:08:08,702 --> 00:08:12,300
We've followed this tried and true of,

175
00:08:12,300 --> 00:08:15,200
let's identify where our
sensitive files are, right?

176
00:08:15,200 --> 00:08:17,710
So now that's like the use
classification and tags

177
00:08:18,773 --> 00:08:21,420
to tag those files as sensitive,

178
00:08:21,420 --> 00:08:25,410
then let's create a policy to
monitor that file movement,

179
00:08:25,410 --> 00:08:27,500
and then inevitably
block that file movement

180
00:08:27,500 --> 00:08:29,490
should that policy be broken.

181
00:08:29,490 --> 00:08:32,610
This compliance centric
approach is very linear based.

182
00:08:32,610 --> 00:08:34,870
It's very rules-based and
we're all familiar with this.

183
00:08:34,870 --> 00:08:38,360
It was largely built
when we were all On-prem.

184
00:08:38,360 --> 00:08:42,020
You converse that with
the insider risk problem

185
00:08:42,020 --> 00:08:43,210
where you've got

186
00:08:44,530 --> 00:08:47,050
this sea of activity,

187
00:08:47,050 --> 00:08:48,512
user activity, you get out
there again and go back

188
00:08:48,512 --> 00:08:50,604
to that thousands of end
points, thousands of users,

189
00:08:50,605 --> 00:08:52,483
millions of files,

190
00:08:53,330 --> 00:08:56,216
hundreds of exfiltration
factors or destinations

191
00:08:56,216 --> 00:08:59,690
that these files can move
largely in the cloud.

192
00:08:59,690 --> 00:09:01,260
And what do you end up with?

193
00:09:01,260 --> 00:09:02,740
You end up with more exposure.

194
00:09:02,740 --> 00:09:04,330
You end up with more data exposure.

195
00:09:04,330 --> 00:09:05,952
You end up with this lack of context

196
00:09:05,952 --> 00:09:08,470
and ability to prioritize,

197
00:09:08,470 --> 00:09:10,865
and inevitably you end up with
coming to the realization,

198
00:09:10,865 --> 00:09:14,510
we just don't have the tools
or the purpose-built tech

199
00:09:14,510 --> 00:09:16,423
to manage this problem.

200
00:09:19,312 --> 00:09:20,920
And the approach is different.

201
00:09:20,920 --> 00:09:22,010
So when we think about it,

202
00:09:22,010 --> 00:09:23,656
we think about this terms of like,

203
00:09:23,656 --> 00:09:25,207
I tweeted,

204
00:09:25,207 --> 00:09:29,850
put this out on Twitter a few
weeks ago around what's the,

205
00:09:29,850 --> 00:09:32,231
is there anything that's
static about data risk anymore?

206
00:09:32,231 --> 00:09:35,501
And it was, there were
some commentary like, no

207
00:09:35,501 --> 00:09:38,709
the risk is all dynamic these days.

208
00:09:38,710 --> 00:09:41,057
But when you think about static risk

209
00:09:41,057 --> 00:09:43,309
and how we've managed
the problem in the past

210
00:09:43,309 --> 00:09:45,823
and still currently manage the problem

211
00:09:45,823 --> 00:09:49,890
from a compliance standpoint
is that whole identify

212
00:09:49,890 --> 00:09:52,615
classify policy block mentality.

213
00:09:52,615 --> 00:09:56,700
And the outcome is rooted
in preventing a data breach.

214
00:09:56,700 --> 00:09:59,950
And that that outcome is obviously true.

215
00:09:59,950 --> 00:10:02,500
But in this new world of,

216
00:10:02,500 --> 00:10:05,714
you know, insider risk and
how you manage insider risk,

217
00:10:05,714 --> 00:10:10,714
you gotta have the contextual
information behind that.

218
00:10:10,870 --> 00:10:13,090
Those millions of files moving around,

219
00:10:13,090 --> 00:10:14,500
those thousands of users,

220
00:10:14,500 --> 00:10:18,034
those thousands of endpoints
and hundreds of vectors

221
00:10:18,034 --> 00:10:20,689
and how to use that context
to better prioritize

222
00:10:20,689 --> 00:10:24,257
what risks matter to the business.

223
00:10:24,258 --> 00:10:26,507
And then the faster you can do that,

224
00:10:26,507 --> 00:10:29,280
the faster you can remediate.

225
00:10:29,280 --> 00:10:32,410
The outcome is still the
same, prevent a data breach,

226
00:10:32,410 --> 00:10:34,930
but the methodology and the
process by which we do that

227
00:10:34,931 --> 00:10:39,931
has to be different than the
way we've always done it before

228
00:10:39,968 --> 00:10:42,349
as a security industry.

229
00:10:42,350 --> 00:10:44,970
So we start to think
about what is that way,

230
00:10:44,970 --> 00:10:46,107
what is the better way?

231
00:10:46,107 --> 00:10:48,132
And it comes down to three things.

232
00:10:49,092 --> 00:10:52,810
How aware are you of
where data is exposed?

233
00:10:52,810 --> 00:10:54,619
Where is the data exposure?

234
00:10:54,620 --> 00:10:55,720
Where is it happening?

235
00:10:57,070 --> 00:11:00,189
Within that exposure, what
are the things that matter?

236
00:11:00,189 --> 00:11:04,540
Contextually how do I prioritize
what leak matters most?

237
00:11:04,540 --> 00:11:05,372
'Cause data's leak,

238
00:11:05,373 --> 00:11:06,757
we're all gonna admit
data is leaking every day.

239
00:11:06,757 --> 00:11:09,239
It's just the nature
of how employees work,

240
00:11:09,240 --> 00:11:10,780
but what are the leaks that matter

241
00:11:10,780 --> 00:11:14,339
that I need to prioritize
that impact the business.

242
00:11:14,340 --> 00:11:15,950
And then what are the steps that I take

243
00:11:15,950 --> 00:11:18,905
to prevent that from
becoming a data breach?

244
00:11:18,905 --> 00:11:23,630
How do I stop that leak from
manifesting itself as a breach

245
00:11:23,630 --> 00:11:27,770
of information and how do
you do this contextually

246
00:11:27,770 --> 00:11:32,233
and then not only prevent the
breach or stop the breach,

247
00:11:32,233 --> 00:11:35,906
but how do you learn, how
do you continually measure

248
00:11:35,906 --> 00:11:39,400
and optimize and improve

249
00:11:39,400 --> 00:11:42,730
your insider risk posture over time?

250
00:11:42,730 --> 00:11:44,670
Because there's one
thing about insider risk

251
00:11:44,670 --> 00:11:48,256
in the nature of it being dynamic,

252
00:11:48,256 --> 00:11:50,890
is it's ever changing, it's ever evolving.

253
00:11:50,890 --> 00:11:52,584
There's going to be new
exfiltration vectors,

254
00:11:52,584 --> 00:11:54,900
there is going to be new ways people work.

255
00:11:54,900 --> 00:11:58,760
There's going to be things that happen

256
00:11:58,760 --> 00:12:01,290
in terms of how employees
get their jobs done

257
00:12:01,290 --> 00:12:03,410
that are gonna introduce
new risks to the company.

258
00:12:03,410 --> 00:12:05,810
So you've got to continually
measure and optimize

259
00:12:05,811 --> 00:12:09,853
and improve your approach to the problem.

260
00:12:11,540 --> 00:12:12,860
So we're gonna talk
about that a little bit.

261
00:12:12,860 --> 00:12:15,220
We're gonna talk about a little bit about

262
00:12:15,220 --> 00:12:17,290
a contextual approach.

263
00:12:17,290 --> 00:12:22,290
We call it insider risk
management, and it's completely,

264
00:12:22,850 --> 00:12:24,800
it's a pragmatic view.

265
00:12:24,800 --> 00:12:27,343
You know, like my job
in research and strategy

266
00:12:27,344 --> 00:12:29,510
is to take super complex issues

267
00:12:29,510 --> 00:12:30,856
and try to distill them down

268
00:12:30,856 --> 00:12:34,381
into what's the simplest
way to solve this problem.

269
00:12:34,381 --> 00:12:36,640
Because the last thing security needs

270
00:12:36,640 --> 00:12:40,030
is more complex solutions
to complex problems.

271
00:12:40,030 --> 00:12:42,949
So when we peel back the onion,
we think about ultimately

272
00:12:42,950 --> 00:12:44,273
what are we trying to do?

273
00:12:45,130 --> 00:12:48,807
And we think about this as a
framework of thinking, right?

274
00:12:48,807 --> 00:12:50,926
So there's five kinds of areas of thinking

275
00:12:50,926 --> 00:12:53,360
around this framework, is first of all,

276
00:12:53,360 --> 00:12:54,870
where are we exposed?

277
00:12:54,870 --> 00:12:57,922
You've got to identify where
you have data risk exposure

278
00:12:57,922 --> 00:13:00,560
across the organization.

279
00:13:00,560 --> 00:13:03,164
You've got to be able
to determine and define

280
00:13:03,164 --> 00:13:06,040
what will you accept,
what will you tolerate?

281
00:13:06,040 --> 00:13:09,579
Which risk exposure is
tolerable and which isn't

282
00:13:09,580 --> 00:13:12,039
to the business and to
the different constituents

283
00:13:12,039 --> 00:13:13,540
within the business?

284
00:13:13,540 --> 00:13:15,560
And I'll talk about that in a minute.

285
00:13:15,560 --> 00:13:19,930
You've gotta be able to have
the context to prioritize

286
00:13:19,930 --> 00:13:22,877
or what are the risk
indicators that will be

287
00:13:22,877 --> 00:13:25,329
that you wanna be alerted on,

288
00:13:25,330 --> 00:13:26,610
because I'll tell you right now,

289
00:13:26,610 --> 00:13:30,420
and you'll probably see this
in an insider risk world,

290
00:13:30,420 --> 00:13:33,709
there are literally thousands
of alerts being fired

291
00:13:33,710 --> 00:13:36,700
because of the nature and
the way employees work.

292
00:13:36,700 --> 00:13:39,450
So how do you cut through all that noise

293
00:13:39,450 --> 00:13:42,343
and be alerted on only the
things that matter most

294
00:13:42,343 --> 00:13:45,490
to the business, the things
that you just won't tolerate

295
00:13:45,490 --> 00:13:48,260
as you've defined in the previous step.

296
00:13:48,260 --> 00:13:50,590
And then how do you respond?

297
00:13:50,590 --> 00:13:52,030
How do you remediate?

298
00:13:52,030 --> 00:13:53,903
Blocking is one methodology of response.

299
00:13:53,903 --> 00:13:55,582
That's the old way we used to do it,

300
00:13:55,582 --> 00:13:57,550
but there are other methodologies

301
00:13:57,550 --> 00:14:00,280
what we call right-size response

302
00:14:00,280 --> 00:14:03,550
to different levels of
severity of data leak

303
00:14:04,514 --> 00:14:06,386
or data misuse or whatever it may be,

304
00:14:06,386 --> 00:14:10,199
and we'll talk about
right-size response in a bit.

305
00:14:10,200 --> 00:14:12,131
And then why do we care?

306
00:14:12,131 --> 00:14:15,238
At the end of the day,
following a framework like this,

307
00:14:15,238 --> 00:14:18,870
answering these five
fundamental questions,

308
00:14:18,870 --> 00:14:22,060
you've got to be able to
prove is what we're doing,

309
00:14:22,060 --> 00:14:24,829
are the practices we're putting in place

310
00:14:24,830 --> 00:14:28,710
improving the organization's
risk posture over time.

311
00:14:28,710 --> 00:14:30,747
And we'll talk about best practices

312
00:14:30,747 --> 00:14:32,627
around measuring that risk posture,

313
00:14:32,627 --> 00:14:34,865
a, defining it within your organization,

314
00:14:34,865 --> 00:14:37,250
but then also measuring against it

315
00:14:37,250 --> 00:14:38,586
and continuously measuring it

316
00:14:38,586 --> 00:14:40,980
and looking where you need to optimize.

317
00:14:40,980 --> 00:14:43,880
So fundamentally, we're gonna
go through these five things

318
00:14:44,820 --> 00:14:46,750
at a relatively high level

319
00:14:46,750 --> 00:14:48,830
just so you have some understanding.

320
00:14:48,830 --> 00:14:51,513
Step one, where are we exposed?

321
00:14:52,760 --> 00:14:55,240
Look across all activity.

322
00:14:55,240 --> 00:14:56,530
That's gonna sound super noisy

323
00:14:56,530 --> 00:15:01,399
but you need the understanding
of all of the activity

324
00:15:01,399 --> 00:15:05,130
happening across all the files,

325
00:15:05,130 --> 00:15:08,810
all the vectors and
all the signals, right?

326
00:15:08,810 --> 00:15:10,229
All the user signals.

327
00:15:10,230 --> 00:15:12,030
So file, vector, and user.

328
00:15:12,030 --> 00:15:14,598
And when you take this contextual approach

329
00:15:14,599 --> 00:15:16,939
and you're grabbing all of this activity

330
00:15:16,939 --> 00:15:19,509
and that activity can surface
itself and file signal

331
00:15:19,509 --> 00:15:23,285
as file name file all this
metadata that you can,

332
00:15:23,285 --> 00:15:26,339
that you can collect,
file name, file category,

333
00:15:26,340 --> 00:15:28,750
the file type of volume of files moving,

334
00:15:28,750 --> 00:15:31,380
the sizes of files moving, the hash.

335
00:15:31,380 --> 00:15:32,689
Is that file new?

336
00:15:32,690 --> 00:15:33,523
Is it been modified?

337
00:15:33,523 --> 00:15:34,356
Has it been deleted?

338
00:15:34,356 --> 00:15:36,048
Who's the owner of that file,

339
00:15:36,048 --> 00:15:39,570
the creator the originator of the file.

340
00:15:39,570 --> 00:15:43,210
What paths has that file taken
over the course of the last

341
00:15:43,210 --> 00:15:46,070
30 days, 60 days, 90 days?

342
00:15:46,070 --> 00:15:48,200
Are there any mismatches in that file?

343
00:15:48,200 --> 00:15:51,220
Does the file type not
match the mind type?

344
00:15:51,220 --> 00:15:53,820
So these are all signals you can derive

345
00:15:53,820 --> 00:15:57,300
from collecting and
monitoring file activity.

346
00:15:57,300 --> 00:15:58,525
Same with vectors.

347
00:15:58,525 --> 00:16:01,263
What end point does this file sit on?

348
00:16:02,690 --> 00:16:05,391
What domain is this file moving to?

349
00:16:05,391 --> 00:16:08,449
Web domains, whatever it might be.

350
00:16:08,450 --> 00:16:12,280
Browser uploads, browser use,
media, like removal media use.

351
00:16:12,280 --> 00:16:15,078
So there's all of this context
and activity around vectors

352
00:16:15,078 --> 00:16:20,078
that you can pull into your
contextual risk exposure.

353
00:16:20,523 --> 00:16:22,290
And then finally users,

354
00:16:22,290 --> 00:16:25,520
both user activity and user attributes.

355
00:16:25,520 --> 00:16:27,209
What's their role at the organization?

356
00:16:27,209 --> 00:16:28,920
Are they privileged?

357
00:16:28,920 --> 00:16:30,469
What department are they in?

358
00:16:30,470 --> 00:16:32,120
What's their employment status?

359
00:16:32,120 --> 00:16:33,030
Are they on a PIP?

360
00:16:33,030 --> 00:16:36,718
And then you can pull this
data in from HRC systems.

361
00:16:36,718 --> 00:16:38,329
You can pull some of the data in

362
00:16:38,330 --> 00:16:40,640
from identity access management systems.

363
00:16:40,640 --> 00:16:43,920
You can also do it inherent
in the end point agent

364
00:16:43,920 --> 00:16:47,620
that we monitor file and
vectors with as well.

365
00:16:47,620 --> 00:16:49,120
What hours are they working?

366
00:16:49,120 --> 00:16:52,363
What hours are they typically
active versus inactive?

367
00:16:53,490 --> 00:16:54,534
Where are they in their life cycle,

368
00:16:54,534 --> 00:16:57,729
their history, their usage
patterns, things like this?

369
00:16:57,729 --> 00:16:59,916
So this is all signal that we pull in.

370
00:16:59,916 --> 00:17:01,530
It probably sounds familiar to you

371
00:17:01,530 --> 00:17:04,389
'cause you might be pumping
a lot of this data into a SIM

372
00:17:04,390 --> 00:17:05,686
but you can pull this all contextually

373
00:17:05,686 --> 00:17:09,770
into a single platform
and begin to look at

374
00:17:09,770 --> 00:17:11,280
where are we exposed?

375
00:17:11,280 --> 00:17:15,260
Where's their files of this type going,

376
00:17:15,260 --> 00:17:17,790
being uploaded via a web
browser to a destination

377
00:17:17,790 --> 00:17:19,362
we don't trust.

378
00:17:20,400 --> 00:17:22,980
And who's doing that and
when are they doing that?

379
00:17:22,980 --> 00:17:24,270
And I'm gonna talk a little bit

380
00:17:24,270 --> 00:17:27,123
about what we call insider
risk indicators in a second.

381
00:17:27,123 --> 00:17:29,699
So once you've got a general understanding

382
00:17:29,699 --> 00:17:33,545
of where data exposure
exists, you begin to have,

383
00:17:33,545 --> 00:17:36,820
you can begin to have conversations.

384
00:17:36,820 --> 00:17:38,250
You can begin to have conversations

385
00:17:38,250 --> 00:17:40,460
around what do we accept and not accept?

386
00:17:40,460 --> 00:17:41,710
What do we tolerate?

387
00:17:41,710 --> 00:17:45,250
And these will differ from
one department to the next

388
00:17:45,250 --> 00:17:46,910
and it will differ from one industry

389
00:17:46,910 --> 00:17:49,120
or company type or
company size to the next,

390
00:17:49,120 --> 00:17:50,731
but you start thinking
about the conversations

391
00:17:50,731 --> 00:17:53,830
you can start having with
line of business leaders,

392
00:17:53,830 --> 00:17:55,236
and engineering leader might say,

393
00:17:55,237 --> 00:17:58,050
"I won't ever tolerate source code

394
00:17:58,050 --> 00:18:00,139
going off a trusted domain

395
00:18:00,140 --> 00:18:03,100
by anyone of my developers, right?"

396
00:18:03,100 --> 00:18:05,266
And you move into sales, and they say,

397
00:18:05,267 --> 00:18:06,460
"I won't tolerate."

398
00:18:06,460 --> 00:18:07,967
This Chief Revenue Officer might say,

399
00:18:07,967 --> 00:18:10,740
"I won't tolerate customer lists

400
00:18:10,740 --> 00:18:14,493
being downloaded from
our Salesforce instance,

401
00:18:14,493 --> 00:18:17,847
especially if that
sales rep is the party."

402
00:18:19,410 --> 00:18:20,653
Finance will have a different thing.

403
00:18:20,653 --> 00:18:24,132
You know, any financial
data that originates

404
00:18:24,132 --> 00:18:26,663
in the finance department
going to an untrusted domain,

405
00:18:26,663 --> 00:18:29,567
marketing might have a
different level of tolerance.

406
00:18:29,567 --> 00:18:31,987
HR might have a different
level of tolerance.

407
00:18:31,987 --> 00:18:35,042
And once you understand the
departmental level tolerance,

408
00:18:35,042 --> 00:18:40,042
you can begin to define what
you wanna be alerted on,

409
00:18:40,210 --> 00:18:41,863
what you prioritize.

410
00:18:42,780 --> 00:18:44,940
In that sea of employee activity,

411
00:18:44,940 --> 00:18:47,568
what are the things that
you absolutely positively

412
00:18:47,568 --> 00:18:52,568
have to be alerted on, so that
you can take action on them

413
00:18:52,630 --> 00:18:56,263
in representation of
these business leaders.

414
00:18:57,250 --> 00:18:59,530
And you do that largely
through what we call

415
00:18:59,530 --> 00:19:00,740
insider risk indicators.

416
00:19:00,740 --> 00:19:02,230
So step three,

417
00:19:02,230 --> 00:19:06,340
here's the prioritization
process or approach.

418
00:19:06,340 --> 00:19:09,060
As you begin to take all that signal

419
00:19:09,060 --> 00:19:12,240
that we gathered in step one,

420
00:19:12,240 --> 00:19:15,331
which is the data exposure
where is has exposed files,

421
00:19:15,331 --> 00:19:17,649
vectors, and users,

422
00:19:17,650 --> 00:19:21,110
you overlay your risk
tolerance conversations,

423
00:19:21,110 --> 00:19:23,673
and step two, now you can begin to measure

424
00:19:23,673 --> 00:19:25,983
what we call machine your intuition.

425
00:19:27,120 --> 00:19:30,739
How can I chain together
different activities

426
00:19:31,580 --> 00:19:34,040
in sequence or in bundles

427
00:19:34,040 --> 00:19:36,750
that will be a high level of indication

428
00:19:36,750 --> 00:19:40,160
that this is of a material
risk to the business?

429
00:19:40,160 --> 00:19:42,897
And you can do any number
of combinations of this.

430
00:19:42,897 --> 00:19:44,629
We can do it, you know,

431
00:19:44,630 --> 00:19:47,760
some of these IRIs are out of
the box within our solution,

432
00:19:47,760 --> 00:19:52,470
but then you can also
develop your own chains of,

433
00:19:52,470 --> 00:19:54,480
you could machine your own intuition

434
00:19:54,480 --> 00:19:57,510
through queries and searches and alerting.

435
00:19:57,510 --> 00:20:02,510
So for example, an employee
puts in their two weeks notice

436
00:20:05,110 --> 00:20:08,389
that triggers HRC system
to send a feed into

437
00:20:08,390 --> 00:20:12,770
your IRM platform,

438
00:20:12,770 --> 00:20:14,910
in our case insider or product

439
00:20:14,910 --> 00:20:18,030
does an immediate 90 day look back.

440
00:20:18,030 --> 00:20:22,053
And 60 days ago we saw this
employee created a zip file.

441
00:20:23,500 --> 00:20:28,220
59 days ago that employee
uploaded that zip file to Dropbox.

442
00:20:28,220 --> 00:20:31,310
That sequence of events
or combination of events

443
00:20:31,310 --> 00:20:34,110
may trigger an insider risk indicator.

444
00:20:34,110 --> 00:20:36,879
This needs to be investigated.

445
00:20:36,880 --> 00:20:39,950
A, we don't sanction the use of Dropbox.

446
00:20:39,950 --> 00:20:43,470
B, zip file creation is suspicious.

447
00:20:43,470 --> 00:20:45,283
C, this employee is leading.

448
00:20:46,760 --> 00:20:48,520
Drill that something to investigate.

449
00:20:48,520 --> 00:20:51,442
That's something that requires
some sort of remediation

450
00:20:51,442 --> 00:20:55,960
or investigation and quite
possibly remediation.

451
00:20:55,960 --> 00:20:57,695
You might have a large
volume of file activity

452
00:20:57,695 --> 00:20:59,740
moving to a thumb drive on a Saturday

453
00:20:59,740 --> 00:21:02,060
at three o'clock in the morning.

454
00:21:02,060 --> 00:21:04,850
You might have a contract employee who is

455
00:21:06,670 --> 00:21:09,610
putting his Apple ID into into a Mac book

456
00:21:09,610 --> 00:21:11,344
and all of a sudden your
files, your corporate files

457
00:21:11,345 --> 00:21:14,829
are sinking to an iCloud,
a personal iCloud.

458
00:21:14,829 --> 00:21:17,760
Maybe that contract employee
downloaded a bunch of stuff

459
00:21:17,760 --> 00:21:22,495
from Salesforce, or, you know,
marketing his Google Drive

460
00:21:22,495 --> 00:21:24,830
with all the marketing
strategy stuff in it,

461
00:21:24,830 --> 00:21:27,813
and now that stuff is being
synced to a personal cloud.

462
00:21:27,814 --> 00:21:30,510
When is that contractor's term up?

463
00:21:30,510 --> 00:21:34,210
Again, you can begin to chain
these sorts of things together

464
00:21:34,210 --> 00:21:37,357
in order to cut through that
scribble that I showed you

465
00:21:37,357 --> 00:21:40,157
of all that activity to
surface only the things

466
00:21:40,157 --> 00:21:43,371
that have a material that
the line of business leaders

467
00:21:43,372 --> 00:21:45,480
that the business will not tolerate.

468
00:21:45,480 --> 00:21:47,060
And then you get alerted on that.

469
00:21:47,060 --> 00:21:49,290
It's based on your intuition.

470
00:21:49,290 --> 00:21:50,903
And then you know when to act.

471
00:21:52,200 --> 00:21:54,940
So step three, that's
the prioritization model

472
00:21:56,293 --> 00:21:58,162
of IRM.

473
00:21:58,163 --> 00:22:01,310
Step four, determine how to respond.

474
00:22:01,310 --> 00:22:04,500
This is where processes and policies

475
00:22:04,500 --> 00:22:05,770
and people come into place, right?

476
00:22:05,770 --> 00:22:09,580
There are occasions where
an IRA might be triggered

477
00:22:09,580 --> 00:22:11,129
where you do nothing.

478
00:22:11,130 --> 00:22:13,360
You jump in, all of this
employee is departing.

479
00:22:13,360 --> 00:22:15,570
Actually they zipped a bunch of

480
00:22:16,420 --> 00:22:20,200
photos that they had on their device.

481
00:22:20,200 --> 00:22:22,891
So there may be instances
that you do nothing.

482
00:22:22,891 --> 00:22:25,103
There may be instances that you know what,

483
00:22:25,103 --> 00:22:29,560
this employee has open file
shares in Google Drive.

484
00:22:29,560 --> 00:22:33,129
I'm just gonna nudge
them via Slack message.

485
00:22:33,130 --> 00:22:35,420
And you can automate that, right?

486
00:22:35,420 --> 00:22:38,546
You can assign more training,

487
00:22:38,546 --> 00:22:40,100
the security awareness training

488
00:22:40,100 --> 00:22:42,043
or different security awareness training

489
00:22:42,044 --> 00:22:44,590
or you can audit your
security awareness training,

490
00:22:44,590 --> 00:22:46,770
say, "Hey, we don't have
enough training on this

491
00:22:46,770 --> 00:22:50,010
because we see this risk perpetuating

492
00:22:50,010 --> 00:22:51,290
across the organization,

493
00:22:51,290 --> 00:22:54,590
or we see this risk
perpetuating with new employees

494
00:22:54,590 --> 00:22:58,679
or tenured employees or employees
in a certain department.

495
00:22:58,680 --> 00:23:01,081
You can get smarter about which
security training you build

496
00:23:01,081 --> 00:23:04,740
and which security training
you prioritize and assign.

497
00:23:04,740 --> 00:23:06,358
You might put that
identity or that employee

498
00:23:06,358 --> 00:23:08,253
on some sort of watch list.

499
00:23:09,420 --> 00:23:11,870
Maybe it's a, there's pending litigation.

500
00:23:11,870 --> 00:23:13,540
Maybe who knows you can...

501
00:23:13,540 --> 00:23:17,080
That's one another, you get
form of right sized response.

502
00:23:17,080 --> 00:23:19,760
You might start a case or an investigation

503
00:23:19,760 --> 00:23:22,435
and you can do this inside
of our product insider

504
00:23:22,435 --> 00:23:26,870
but you might need to gather
more intel, do some work

505
00:23:26,870 --> 00:23:30,100
and pull pieces together that you then

506
00:23:30,100 --> 00:23:33,689
might have to use to notify
a manager, HR, legal.

507
00:23:33,690 --> 00:23:35,380
You might have to escalate in some way,

508
00:23:35,380 --> 00:23:37,250
shape or form to an
incident response team.

509
00:23:37,250 --> 00:23:41,701
So when you think about
insider risk and managing it,

510
00:23:41,701 --> 00:23:42,940
you're gonna, you know,

511
00:23:42,940 --> 00:23:46,020
based on the prioritization
alerts you get,

512
00:23:46,020 --> 00:23:47,349
there is a different way to respond,

513
00:23:47,349 --> 00:23:50,615
based on the another way of
calling a right-sized response

514
00:23:50,615 --> 00:23:53,094
is contextual response.

515
00:23:53,094 --> 00:23:55,490
I'll think about contextual detection,

516
00:23:55,490 --> 00:23:57,040
contextual investigation.

517
00:23:57,040 --> 00:24:00,266
Now you have contextual response,
right size to the severity

518
00:24:00,266 --> 00:24:02,350
of that alert

519
00:24:02,350 --> 00:24:05,223
or that insider's behavior.

520
00:24:07,530 --> 00:24:11,450
Put it together and you
begin to get to step five.

521
00:24:11,450 --> 00:24:12,662
So assess it now.

522
00:24:12,662 --> 00:24:13,643
We're going to go back,

523
00:24:13,643 --> 00:24:15,960
are you assessing your data risk exposure,

524
00:24:15,960 --> 00:24:17,791
you're prioritizing what data leaks matter

525
00:24:17,791 --> 00:24:19,629
to the organization.

526
00:24:19,630 --> 00:24:21,149
You're taking the right sized response

527
00:24:21,149 --> 00:24:25,040
to prevent those data leaks
from turning into breaches.

528
00:24:25,040 --> 00:24:28,629
And you begin to say,
"Okay, I'm gonna measure

529
00:24:28,630 --> 00:24:31,140
our insider risk data exposure on day one

530
00:24:31,140 --> 00:24:34,120
and then I'm gonna measure
it again on day 90."

531
00:24:34,120 --> 00:24:35,719
Has it improved?

532
00:24:35,720 --> 00:24:37,637
And I'm gonna measure it again on day 180.

533
00:24:37,637 --> 00:24:38,812
Has it improved?

534
00:24:39,875 --> 00:24:41,430
One year in,

535
00:24:41,430 --> 00:24:43,010
and you're constantly looking at

536
00:24:43,010 --> 00:24:45,790
are we improving the risk
posture of the organization?

537
00:24:45,790 --> 00:24:47,570
Not only is this valuable to the

538
00:24:47,570 --> 00:24:50,490
to the executives and the board,

539
00:24:50,490 --> 00:24:54,170
but it also informs you on the

540
00:24:54,170 --> 00:24:55,260
are you doing the right things.

541
00:24:55,260 --> 00:24:56,656
Is the team focused on the right areas

542
00:24:56,656 --> 00:24:59,050
and are they improving the risk posture

543
00:24:59,050 --> 00:25:03,669
and controlling the insider risk problem?

544
00:25:03,670 --> 00:25:05,207
You can also measure your time to detect

545
00:25:05,207 --> 00:25:08,422
and remediate the tried
and true security metrics,

546
00:25:08,422 --> 00:25:11,085
but that assessing and
improving your risk posture

547
00:25:11,085 --> 00:25:15,680
is probably the single biggest outcome of

548
00:25:15,680 --> 00:25:18,323
of taking an insider
risk management approach.

549
00:25:19,530 --> 00:25:23,060
Speaking of outcomes,
what are the outcomes?

550
00:25:23,060 --> 00:25:25,435
And when we think about
insider risk management,

551
00:25:25,435 --> 00:25:28,298
we think about the
magnitude of this problem

552
00:25:28,298 --> 00:25:29,810
and how to manage it.

553
00:25:29,810 --> 00:25:31,168
You've got to be outcomes driven.

554
00:25:31,168 --> 00:25:35,739
And we think about comes in
kind of three distinct pillars,

555
00:25:35,740 --> 00:25:38,131
productivity, security, and value.

556
00:25:38,131 --> 00:25:41,525
And obviously, yes, employee productivity,

557
00:25:41,525 --> 00:25:44,101
you're doing all this without disrupting

558
00:25:44,101 --> 00:25:46,940
employee collaboration or productivity

559
00:25:46,940 --> 00:25:48,974
but we also think about it in terms of

560
00:25:48,974 --> 00:25:52,122
the security team's productivity.

561
00:25:52,123 --> 00:25:55,137
How do you begin to in this,

562
00:25:55,137 --> 00:25:56,615
in the insider risk problem,

563
00:25:56,615 --> 00:25:59,530
how do you begin to think
about, you know, what

564
00:25:59,530 --> 00:26:03,760
how do we improve security analysts,

565
00:26:03,760 --> 00:26:05,140
security, you know,

566
00:26:05,140 --> 00:26:08,970
security team members
productivity themselves?

567
00:26:08,970 --> 00:26:13,670
How do you get them out of
maintaining existing tech

568
00:26:13,670 --> 00:26:16,570
that may take months, weeks, months,

569
00:26:16,570 --> 00:26:20,250
sometimes years to deploy
constantly modifying

570
00:26:20,250 --> 00:26:24,720
and tuning it based on what's
going on in the environment

571
00:26:24,720 --> 00:26:26,760
but not really measuring its impact,

572
00:26:26,760 --> 00:26:30,020
not really being able
to measure the outcome

573
00:26:30,020 --> 00:26:32,761
from an information security
or data security perspective.

574
00:26:32,761 --> 00:26:36,850
How do you shift that
formula or that focus

575
00:26:36,850 --> 00:26:39,043
from a security productivity perspective

576
00:26:39,044 --> 00:26:41,710
to more of maturity mode?

577
00:26:41,710 --> 00:26:43,628
We call this maintenance
mode versus maturity mode.

578
00:26:43,628 --> 00:26:46,000
How do you shift the time and attention

579
00:26:46,000 --> 00:26:50,079
to not maintaining tech but
defining and prioritizing

580
00:26:50,079 --> 00:26:53,644
the risks that matter,
machining your intuition,

581
00:26:53,644 --> 00:26:56,708
automating and improving how you respond

582
00:26:56,708 --> 00:26:59,520
and to remediate to the
different types of data risks

583
00:26:59,520 --> 00:27:01,470
that exists inside an organization?

584
00:27:01,470 --> 00:27:03,870
The more time spent here,

585
00:27:03,870 --> 00:27:06,484
the more apt and the more
value you're gonna deliver

586
00:27:06,484 --> 00:27:09,327
to the organization from a
security risk posture perspective

587
00:27:09,327 --> 00:27:11,377
and an insider risk posture perspective,

588
00:27:11,377 --> 00:27:14,158
and specifically.

589
00:27:14,158 --> 00:27:17,235
So security productivity
is a big focused outcome

590
00:27:17,235 --> 00:27:20,183
of taking an insider
risk management approach.

591
00:27:21,280 --> 00:27:23,850
The second, is a number of things.

592
00:27:23,850 --> 00:27:25,790
Obviously, some check
the box type of stuff.

593
00:27:25,790 --> 00:27:27,100
Yes.

594
00:27:27,100 --> 00:27:29,129
You know, here's some different use cases

595
00:27:29,130 --> 00:27:31,684
of truly understanding
where risk presents itself

596
00:27:31,684 --> 00:27:33,399
in the organization.

597
00:27:33,400 --> 00:27:38,400
You might develop remote
employee and contractor workflows

598
00:27:38,950 --> 00:27:42,427
for risk that surfaces they're
departing employee processes.

599
00:27:42,427 --> 00:27:45,161
You might be looking closely
at high risk employees.

600
00:27:45,162 --> 00:27:47,090
You might be audit is, you know,

601
00:27:47,090 --> 00:27:48,884
are you at comp...

602
00:27:48,884 --> 00:27:52,360
Is there compliance risk that

603
00:27:52,360 --> 00:27:56,219
and policy audits that you need to assess

604
00:27:57,090 --> 00:27:59,590
the effectiveness of?

605
00:27:59,590 --> 00:28:01,330
I talked about security awareness training

606
00:28:01,330 --> 00:28:03,116
and assessing where we
need to focus more training

607
00:28:03,116 --> 00:28:05,700
or less training or more focused training

608
00:28:05,700 --> 00:28:09,204
on specific people or departments
or whatever it might be.

609
00:28:09,204 --> 00:28:13,330
We also start to think about
where risk manifests itself

610
00:28:13,330 --> 00:28:15,460
at an organizational level.

611
00:28:15,460 --> 00:28:18,352
So risk tolerance will ebb and flow.

612
00:28:18,352 --> 00:28:20,999
It's as dynamic as the
insider risk itself.

613
00:28:20,999 --> 00:28:25,070
So when you're an
organization that's pre-IPO,

614
00:28:25,070 --> 00:28:29,060
your risk tolerance is
going to be extremely low.

615
00:28:29,060 --> 00:28:32,091
We can't have IP leaving our organization

616
00:28:32,092 --> 00:28:34,550
because it could impact our valuation.

617
00:28:34,550 --> 00:28:37,242
We cannot have this financial
data leaving our organization.

618
00:28:37,242 --> 00:28:40,600
We cannot lose this competitive
bid for this customer

619
00:28:40,600 --> 00:28:44,564
or lose this customer pre per IPO,

620
00:28:44,565 --> 00:28:46,893
same with a merger and acquisition.

621
00:28:48,370 --> 00:28:51,229
In the process of of companies merging

622
00:28:51,230 --> 00:28:53,000
or acquiring another company,

623
00:28:53,000 --> 00:28:56,500
you're acquiring that company
for IP, for customers,

624
00:28:56,500 --> 00:28:57,630
for whatever.

625
00:28:57,630 --> 00:29:02,630
Your risk tolerance is lower
in that in those events.

626
00:29:02,740 --> 00:29:05,350
And then organizational
change is always a big one.

627
00:29:05,350 --> 00:29:09,040
Changes in policy changes in culture,

628
00:29:09,040 --> 00:29:12,255
changes in restructuring
in Oregon, in layoffs

629
00:29:12,256 --> 00:29:14,370
and whatever it might be.

630
00:29:14,370 --> 00:29:16,247
So just having greater
visibility and understanding

631
00:29:16,248 --> 00:29:19,070
of risk as it happens across these

632
00:29:19,070 --> 00:29:22,350
organizational milestones.

633
00:29:22,350 --> 00:29:24,622
And then finally business outcomes.

634
00:29:26,310 --> 00:29:28,730
How do you check the box and ensure that

635
00:29:28,730 --> 00:29:30,830
your data use policies are being compliant

636
00:29:30,830 --> 00:29:33,480
or your compliance employees
are compliant with those?

637
00:29:33,480 --> 00:29:36,341
How do you do that without
disrupting their productivity?

638
00:29:36,341 --> 00:29:39,530
How do you speed security's time to value?

639
00:29:39,530 --> 00:29:43,430
Again, shifting that
mode is to maturity mode.

640
00:29:43,430 --> 00:29:46,773
And overall, how do you prove
that you're helping build

641
00:29:46,773 --> 00:29:50,573
a more risk aware culture
by constantly measuring

642
00:29:50,574 --> 00:29:53,109
and improving that risk posture.

643
00:29:53,109 --> 00:29:57,090
How you get there is
you start to think about

644
00:29:58,380 --> 00:29:59,703
routes to outcomes.

645
00:30:01,170 --> 00:30:04,100
Step one, assess that maturity.

646
00:30:04,100 --> 00:30:06,053
Assess that risk exposure.

647
00:30:07,010 --> 00:30:08,120
How mature are you?

648
00:30:08,120 --> 00:30:12,189
This is a new world order
of remote work hybrid work,

649
00:30:12,190 --> 00:30:13,853
collaboration tools, productivity tools,

650
00:30:13,853 --> 00:30:16,763
as organizations moving extremely fast.

651
00:30:17,710 --> 00:30:19,900
Take a step back and assess where are we?

652
00:30:19,900 --> 00:30:22,150
Where is the data exposure today?

653
00:30:22,150 --> 00:30:25,410
Do we need to build a program, right?

654
00:30:25,410 --> 00:30:27,803
What's it gonna take to build
a program and processes?

655
00:30:27,803 --> 00:30:29,057
Do I need dedicated people?

656
00:30:29,057 --> 00:30:32,450
Can I leverage certain security analysts?

657
00:30:32,450 --> 00:30:35,023
Can I leverage the technology I have?

658
00:30:36,220 --> 00:30:37,952
You begin to put these pieces together.

659
00:30:37,952 --> 00:30:39,526
Like, what technology is it gonna take?

660
00:30:39,526 --> 00:30:41,740
How long does it take to implement?

661
00:30:41,740 --> 00:30:44,810
How does it integrate
with my existing stack?

662
00:30:44,810 --> 00:30:46,810
How do I pull in more contextual data?

663
00:30:46,810 --> 00:30:48,202
How do I correlate, et cetera, et cetera?

664
00:30:48,202 --> 00:30:52,530
How I'd automate everything
so that it isn't all on me

665
00:30:52,530 --> 00:30:55,310
to come in every day and manage,

666
00:30:55,310 --> 00:30:56,710
you know, alert after alert,

667
00:30:56,710 --> 00:31:00,220
have some of that remediation
and response automated.

668
00:31:00,220 --> 00:31:03,260
And then finally, what are the
metrics and how do I measure?

669
00:31:03,260 --> 00:31:04,728
So that I can continue building

670
00:31:04,728 --> 00:31:08,090
and improving the risk
posture of the organization.

671
00:31:08,090 --> 00:31:10,493
So you think about the
magnitude of this problem

672
00:31:10,493 --> 00:31:12,470
and you think about, okay, what am I,

673
00:31:12,470 --> 00:31:13,667
what do I do with this information?

674
00:31:13,667 --> 00:31:17,110
There's fundamentally kind
of three questions that

675
00:31:18,290 --> 00:31:19,678
we begin to ask ourselves, right?

676
00:31:19,678 --> 00:31:21,850
And we're doing additional
research on this

677
00:31:21,850 --> 00:31:26,062
in terms of, you know, people
process and technology, right?

678
00:31:26,062 --> 00:31:28,349
So where do you start?

679
00:31:28,349 --> 00:31:29,778
We always start at people,

680
00:31:29,778 --> 00:31:33,140
and it's like insider risk is
a different kind of problem.

681
00:31:33,140 --> 00:31:36,722
Do we have the right people
to help manage this problem?

682
00:31:36,722 --> 00:31:37,555
Right?

683
00:31:37,555 --> 00:31:38,388
Are they trained?

684
00:31:38,388 --> 00:31:40,125
Are we equipped with a higher people?

685
00:31:40,125 --> 00:31:42,230
Do we have to kindly move bodies around?

686
00:31:42,230 --> 00:31:44,310
What's our processes look like?

687
00:31:44,310 --> 00:31:47,169
You know, it's no longer block first,

688
00:31:47,170 --> 00:31:48,870
it's right size response.

689
00:31:48,870 --> 00:31:51,162
Do we have processes documented

690
00:31:51,163 --> 00:31:54,300
for the type of risk and
the severity of the risk

691
00:31:54,300 --> 00:31:56,490
and the based on the risk tolerance

692
00:31:56,490 --> 00:31:57,780
of our business partners?

693
00:31:57,780 --> 00:32:00,270
What is that incident response process

694
00:32:00,270 --> 00:32:01,896
when our coworkers put data at risk?

695
00:32:01,896 --> 00:32:03,790
And then finally technology.

696
00:32:03,790 --> 00:32:06,360
You know, where do we need
purpose-built technology?

697
00:32:06,360 --> 00:32:08,754
Where can we leverage existing technology

698
00:32:08,754 --> 00:32:12,570
to help feed and improve
and streamline that

699
00:32:14,050 --> 00:32:15,220
those people and processes

700
00:32:15,220 --> 00:32:17,730
and it helps security be more productive

701
00:32:17,730 --> 00:32:20,453
and deliver real value
to the organization.

702
00:32:21,900 --> 00:32:25,420
So and again, I wanna go back to that.

703
00:32:25,420 --> 00:32:27,266
I love that first quote by Dan Rather,

704
00:32:27,266 --> 00:32:29,550
because what we're ultimately trying to do

705
00:32:29,550 --> 00:32:30,853
is the same sort of thing.

706
00:32:31,960 --> 00:32:35,410
How do we find in the midst
of the way people work,

707
00:32:35,410 --> 00:32:39,203
how do we find the signals of
risk amidst all this noise?

708
00:32:40,680 --> 00:32:41,820
Where is it surfaced?

709
00:32:41,820 --> 00:32:46,820
Contextually across files,
across factors, across users.

710
00:32:47,010 --> 00:32:51,300
How do we prioritize
based on those signals?

711
00:32:51,300 --> 00:32:56,300
So that we can take swift
action and continuously improve

712
00:32:57,890 --> 00:33:01,503
the insider risk posture
of the organization.

713
00:33:02,910 --> 00:33:05,113
And with that, thank you.

714
00:33:06,190 --> 00:33:07,023
You know,

715
00:33:08,718 --> 00:33:11,870
if you're at all ever interested
in diving in deeper in here

716
00:33:11,870 --> 00:33:14,330
please reach out to me
on LinkedIn, Twitter.

717
00:33:14,330 --> 00:33:17,419
You have my, I think my
email is in my bio as well.

718
00:33:17,420 --> 00:33:20,190
We have a number of
resources that go in deeper

719
00:33:20,190 --> 00:33:22,324
into insider risk management.

720
00:33:22,324 --> 00:33:26,220
We actually wrote a book
on this last year in 2020.

721
00:33:26,220 --> 00:33:30,620
So I appreciate the time, I
appreciate you reaching out.

722
00:33:30,620 --> 00:33:32,629
And I think we'll look and chat

723
00:33:32,630 --> 00:33:34,670
and see if there's any questions.

724
00:33:34,670 --> 00:33:35,503
Thank you.

