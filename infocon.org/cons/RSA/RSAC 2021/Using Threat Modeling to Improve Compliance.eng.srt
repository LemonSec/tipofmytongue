1
00:00:01,770 --> 00:00:03,546
- Hello, and welcome to,

2
00:00:03,547 --> 00:00:06,430
"Using Threat Modeling
To Improve Compliance."

3
00:00:06,430 --> 00:00:09,379
I'm Adam Shostack, and
before we get started

4
00:00:09,380 --> 00:00:11,969
let me tell you a little bit about myself.

5
00:00:11,969 --> 00:00:15,010
I'm often known

6
00:00:15,010 --> 00:00:17,240
for having written a
book on threat modeling,

7
00:00:17,240 --> 00:00:18,950
done a lot of work in threat modeling

8
00:00:18,950 --> 00:00:22,570
including creating the "Elevation
Of Privilege" card game,

9
00:00:22,571 --> 00:00:26,880
advising a company area's
risk that's in this space.

10
00:00:26,880 --> 00:00:31,692
I created earlier the Microsoft
SDL threat modeling tool,

11
00:00:31,693 --> 00:00:34,060
monitor review board for Black Hat.

12
00:00:34,060 --> 00:00:36,670
I helped to create the CVA,
and I run a little company

13
00:00:36,670 --> 00:00:41,257
that helps people improve the
security of their systems.

14
00:00:41,257 --> 00:00:46,157
And so let me tell you
what this talk is about.

15
00:00:46,157 --> 00:00:48,410
What it's really about,

16
00:00:48,410 --> 00:00:53,410
is that compliance is
painful for many reasons.

17
00:00:53,680 --> 00:00:57,150
The reasons that it is so painful,

18
00:00:57,150 --> 00:00:59,513
some of them are self-inflicting.

19
00:00:59,514 --> 00:01:04,514
The, some of them are result
of engineering constraints.

20
00:01:05,090 --> 00:01:08,605
The standards have to be
both precise and flexible,

21
00:01:08,605 --> 00:01:12,809
but almost no standard
really starts with why

22
00:01:12,809 --> 00:01:15,340
in a meaningful way.

23
00:01:15,340 --> 00:01:19,250
And that creates a tremendous
problem for all of us.

24
00:01:19,250 --> 00:01:20,770
And we're gonna talk about it today,

25
00:01:20,770 --> 00:01:22,860
and I'll give you some examples.

26
00:01:22,860 --> 00:01:24,814
And then we'll close out by talking about

27
00:01:24,814 --> 00:01:26,470
how we can make it better,

28
00:01:26,470 --> 00:01:29,914
for both companies and
for standards bodies.

29
00:01:29,914 --> 00:01:32,956
So the way in which
we're gonna do that is,

30
00:01:32,956 --> 00:01:37,323
we'll start out with level
set, understand the compliance.

31
00:01:37,323 --> 00:01:40,312
We'll talk about the PCI standard,

32
00:01:40,312 --> 00:01:42,410
we'll talk about threat modeling.

33
00:01:42,410 --> 00:01:44,420
I'll give you a quick introduction to it

34
00:01:44,420 --> 00:01:48,083
in case you're not familiar
with how to threat model.

35
00:01:49,450 --> 00:01:53,545
I will show you a threat
model that I created from PCI

36
00:01:53,545 --> 00:01:57,700
and explain how it
relates to the standard.

37
00:01:57,700 --> 00:01:58,840
And then we'll talk about

38
00:01:58,840 --> 00:02:00,760
how to make the world a better place,

39
00:02:00,760 --> 00:02:02,333
one threat model at a time.

40
00:02:03,290 --> 00:02:06,274
So, let's start out with compliance.

41
00:02:06,274 --> 00:02:10,220
And what I mean, when I say compliance is

42
00:02:10,220 --> 00:02:13,656
work to demonstrably, meet some standard.

43
00:02:13,656 --> 00:02:17,610
And insecurity we often deride this

44
00:02:17,610 --> 00:02:21,550
as checklists security, okay

45
00:02:21,550 --> 00:02:23,463
Yes, that's true we do.

46
00:02:24,583 --> 00:02:27,910
But I believe we can do better than that.

47
00:02:27,910 --> 00:02:31,607
And that's really why we're here today,

48
00:02:31,607 --> 00:02:35,700
is to move beyond that
checklist to something

49
00:02:35,700 --> 00:02:37,414
that's higher value.

50
00:02:37,414 --> 00:02:39,897
Now compliance requires a standard,

51
00:02:39,897 --> 00:02:41,816
it can be set by law.

52
00:02:41,817 --> 00:02:45,111
Something like the California privacy act,

53
00:02:45,111 --> 00:02:49,500
by regulation that comes from an agency

54
00:02:49,500 --> 00:02:52,080
by industry practice or by contract.

55
00:02:52,080 --> 00:02:55,750
All of these impose on
you some requirement

56
00:02:55,750 --> 00:02:58,210
to comply with something.

57
00:02:58,210 --> 00:03:00,919
And these standards tend
to be written by experts

58
00:03:00,919 --> 00:03:03,607
and we'll come back to that.

59
00:03:03,607 --> 00:03:08,607
And lastly, they require some
degree of assurance work,

60
00:03:09,000 --> 00:03:11,769
some demonstration that
you're meeting the standard.

61
00:03:11,769 --> 00:03:15,508
Now the PCI data security standard,

62
00:03:15,508 --> 00:03:18,367
was created by the payment card companies

63
00:03:18,367 --> 00:03:21,434
and it's imposed by contract.

64
00:03:21,434 --> 00:03:23,621
Before you can get paid by credit card

65
00:03:23,621 --> 00:03:25,540
it's checked by these companies.

66
00:03:25,540 --> 00:03:28,983
These QSAs, these qualified
security advisors.

67
00:03:30,123 --> 00:03:31,364
Let's be honest,

68
00:03:31,365 --> 00:03:35,906
arguments with your QSA
are pretty darn common.

69
00:03:35,906 --> 00:03:40,324
And the PCI DSS standard
has had a number of effects

70
00:03:40,324 --> 00:03:44,527
since it was promulgated,

71
00:03:44,527 --> 00:03:48,453
demands for new laws have fallen away.

72
00:03:48,454 --> 00:03:50,530
And this gives us some simplification.

73
00:03:50,530 --> 00:03:53,100
We don't have to worry
about complying with one law

74
00:03:53,100 --> 00:03:55,200
in the US for credit card security,

75
00:03:55,200 --> 00:03:57,489
one law in the UK, one law Germany,

76
00:03:57,490 --> 00:03:59,320
one law in China.

77
00:03:59,320 --> 00:04:01,180
We have a single set of standards

78
00:04:01,180 --> 00:04:04,193
that we can comply with
globally, and that's useful.

79
00:04:05,367 --> 00:04:09,399
PCI assigns both liability and cost

80
00:04:09,399 --> 00:04:11,577
and the people to whom it's assigned

81
00:04:11,577 --> 00:04:13,363
often don't like that.

82
00:04:14,588 --> 00:04:19,587
The last effect of PCI is the
creation of new companies.

83
00:04:20,300 --> 00:04:23,150
It used to be 10, 15 years
ago that small companies

84
00:04:23,150 --> 00:04:25,142
would process credit cards themselves,

85
00:04:25,142 --> 00:04:26,918
and that was a source of problem.

86
00:04:26,918 --> 00:04:30,220
Now, by and large, it gets
outsourced to companies

87
00:04:30,220 --> 00:04:34,550
like Stripe and Square who
can make bigger investments

88
00:04:34,550 --> 00:04:37,540
in security to protect the card numbers.

89
00:04:37,540 --> 00:04:42,510
And that's an effect of PCI
coming out and being imposed.

90
00:04:42,510 --> 00:04:47,510
I'm looking at PCI today,
because it's a useful example.

91
00:04:47,688 --> 00:04:50,750
If I were to talk about
a medical device standard

92
00:04:50,750 --> 00:04:53,090
many of you would tune out now.

93
00:04:53,090 --> 00:04:55,390
You're not in the medical device space,

94
00:04:55,390 --> 00:04:56,840
what does this have to do with me.

95
00:04:56,840 --> 00:05:00,190
So PCI is useful 'cause it's broad.

96
00:05:00,190 --> 00:05:02,510
It's useful because it's broad,

97
00:05:02,510 --> 00:05:04,486
it's also a source of frustration.

98
00:05:04,486 --> 00:05:06,980
And lastly, it's useful because

99
00:05:06,980 --> 00:05:09,130
it is relatively freely available.

100
00:05:09,130 --> 00:05:11,130
There are many standards
that you have to pay,

101
00:05:11,130 --> 00:05:14,130
hundreds or thousands
of dollars to get a copy

102
00:05:14,130 --> 00:05:16,544
of PCI is not one of them.

103
00:05:16,544 --> 00:05:21,544
And what I'm going to say
may sound like I'm here

104
00:05:22,540 --> 00:05:26,830
to criticize the PCI council
and that is not my intent.

105
00:05:26,830 --> 00:05:28,380
Those folks have a hard job,

106
00:05:28,380 --> 00:05:31,710
and they're working to
deal with the challenges

107
00:05:31,710 --> 00:05:33,180
that they face.

108
00:05:33,180 --> 00:05:36,589
And I'm using PCI respectfully

109
00:05:36,589 --> 00:05:41,050
because of its familiarity
and its accessibility,

110
00:05:41,050 --> 00:05:45,320
rather than to be here to
criticize the PCI council.

111
00:05:45,320 --> 00:05:47,243
The things I'm going to point out

112
00:05:47,243 --> 00:05:51,260
apply to a great many standards

113
00:05:51,260 --> 00:05:53,453
because of the nature of standards.

114
00:05:54,680 --> 00:05:56,780
So what is PCI,

115
00:05:56,780 --> 00:06:00,510
PCI as you probably know
has 12 main requirements.

116
00:06:00,510 --> 00:06:02,530
Like install and maintain a firewall,

117
00:06:02,530 --> 00:06:05,409
and avoid default passwords.

118
00:06:05,410 --> 00:06:10,190
And it has 129 pages that look like this,

119
00:06:10,190 --> 00:06:11,930
and let's dig in.

120
00:06:11,930 --> 00:06:14,790
So this is our randomly
chosen page of PCI.

121
00:06:14,790 --> 00:06:16,282
It's got three columns.

122
00:06:16,282 --> 00:06:19,609
You've got your description
of groups or excuse me,

123
00:06:19,610 --> 00:06:20,950
you've got your requirements.

124
00:06:20,950 --> 00:06:23,680
For example, description of groups,

125
00:06:23,680 --> 00:06:25,130
roles and responsibilities

126
00:06:25,130 --> 00:06:26,890
for management of network components,

127
00:06:26,890 --> 00:06:29,756
and documentation of
business justification.

128
00:06:29,756 --> 00:06:33,837
You have testing procedures
that are associated with this

129
00:06:33,838 --> 00:06:35,913
and you have some guidance.

130
00:06:37,410 --> 00:06:40,410
And the guidance is
the closest that we get

131
00:06:40,410 --> 00:06:42,040
to why is this here.

132
00:06:42,040 --> 00:06:43,960
And sometimes it actually
comes pretty close.

133
00:06:43,960 --> 00:06:45,832
It's pretty explanatory.

134
00:06:45,833 --> 00:06:48,393
For example, on this page, we can see

135
00:06:48,393 --> 00:06:51,114
sort of on the lower right compromises

136
00:06:51,114 --> 00:06:53,200
often happen due to unused

137
00:06:53,200 --> 00:06:57,510
or insecure services in ports et cetera.

138
00:06:57,510 --> 00:07:00,560
This is the reason, this is the why

139
00:07:00,560 --> 00:07:02,200
and it's not always present.

140
00:07:02,200 --> 00:07:03,763
This page happens to have it.

141
00:07:04,775 --> 00:07:08,412
So let me shift gears
from here for a moment

142
00:07:08,412 --> 00:07:10,849
and talk about software development.

143
00:07:10,850 --> 00:07:14,900
A context in which the conflict occurs.

144
00:07:14,900 --> 00:07:17,448
And so if you're a software engineer,

145
00:07:17,449 --> 00:07:20,171
you want to be doing this work

146
00:07:20,171 --> 00:07:22,650
because you have to solve
some customer problems.

147
00:07:22,650 --> 00:07:25,539
You write code, you build some cool stuff,

148
00:07:25,540 --> 00:07:27,773
you change the world, it's awesome.

149
00:07:29,074 --> 00:07:30,510
That's the ideal,

150
00:07:30,510 --> 00:07:34,303
that's why people get into
software engineering but,

151
00:07:35,160 --> 00:07:40,080
in practice, what it entails
is dealing with cost risk

152
00:07:40,080 --> 00:07:42,030
and mitigation is accessibility,

153
00:07:42,030 --> 00:07:44,202
compatibility, configurability,

154
00:07:44,202 --> 00:07:48,600
manageability, all of this
stuff that we have to do.

155
00:07:48,600 --> 00:07:50,662
And by the way, this is from a product

156
00:07:50,662 --> 00:07:53,448
that I've worked on, that you've used

157
00:07:53,449 --> 00:07:56,980
from the specification framework

158
00:07:56,980 --> 00:07:59,150
that every developer had to work on.

159
00:07:59,150 --> 00:08:04,150
It's not a random list that I created

160
00:08:04,200 --> 00:08:06,969
and this stuff gets pretty overwhelming

161
00:08:06,970 --> 00:08:08,778
if you're a software developer.

162
00:08:08,778 --> 00:08:12,471
I just wanna write some code,
I wanna build some cool stuff.

163
00:08:12,471 --> 00:08:17,471
And so what happens is
that when the developer

164
00:08:18,028 --> 00:08:20,618
tries to work with security,

165
00:08:20,618 --> 00:08:25,280
security often act as
an inhibitor, a blocker.

166
00:08:25,280 --> 00:08:28,416
There's some standard
that's put in the way

167
00:08:28,416 --> 00:08:31,468
of the work that they're trying to do.

168
00:08:31,468 --> 00:08:34,460
Why is it the standard, bots are standard,

169
00:08:34,460 --> 00:08:37,123
you've got to comply, comply now.

170
00:08:38,809 --> 00:08:41,169
And then they ask why
do I have to do that,

171
00:08:41,169 --> 00:08:45,199
and there's this bunch of
folks over on the side here

172
00:08:45,200 --> 00:08:46,700
who are sort of anonymous.

173
00:08:46,700 --> 00:08:48,986
We don't know a lot about them,

174
00:08:48,986 --> 00:08:52,960
and there's this opaque stuff

175
00:08:52,960 --> 00:08:56,170
is happening in a standards process.

176
00:08:56,170 --> 00:08:58,410
And this produces a standard

177
00:08:58,410 --> 00:09:00,880
which sort of falls on
the developer to go do,

178
00:09:00,880 --> 00:09:05,100
it falls on the ops
engineer to go do, and.

179
00:09:09,590 --> 00:09:10,920
I just wanna write some code,

180
00:09:10,920 --> 00:09:12,599
I just wanna to develop my features.

181
00:09:12,600 --> 00:09:15,523
I wanna, I wanna get through
this sprints requirements.

182
00:09:16,700 --> 00:09:19,880
Oh, compliance creates conflict.

183
00:09:19,880 --> 00:09:23,320
It creates conflict between
security and operations,

184
00:09:23,320 --> 00:09:27,710
where operations wants
to leave things open

185
00:09:27,710 --> 00:09:30,910
for availability or performance reasons.

186
00:09:30,910 --> 00:09:33,380
And security says, "No,
you have to configure this,

187
00:09:33,380 --> 00:09:36,490
and you have to configure that,
and you have to check this."

188
00:09:36,490 --> 00:09:40,160
Compliance creates conflict
with security priorities.

189
00:09:40,160 --> 00:09:41,839
There may be things that you,

190
00:09:41,840 --> 00:09:44,950
as a security professional
here at the RSA conference

191
00:09:44,950 --> 00:09:46,841
want to go do,

192
00:09:46,841 --> 00:09:51,240
but your time and energy is absorbed

193
00:09:51,240 --> 00:09:53,380
by the compliance demands.

194
00:09:53,380 --> 00:09:54,470
I'll tell you a little story.

195
00:09:54,470 --> 00:09:57,507
I was working on one of my startups,

196
00:09:57,507 --> 00:09:59,857
and I called buddy, and I said,

197
00:09:59,857 --> 00:10:02,240
"Dave, I've got this great idea.

198
00:10:02,240 --> 00:10:04,877
I'm really excited about
it, I wanna do this and that

199
00:10:04,877 --> 00:10:06,810
and the other thing."

200
00:10:06,810 --> 00:10:10,526
And he said, "Adam, let me
walk you through my budget."

201
00:10:11,900 --> 00:10:13,360
And he walked me through his budget,

202
00:10:13,360 --> 00:10:15,542
sort of line item by line item.

203
00:10:15,542 --> 00:10:18,940
And at the end, he said, "I have about,"

204
00:10:18,940 --> 00:10:23,040
and by the way he had a
budget that was in the,

205
00:10:23,040 --> 00:10:26,449
I don't know, eight, nine figure range.

206
00:10:26,450 --> 00:10:29,979
And at the end of it, he said,

207
00:10:29,979 --> 00:10:34,420
"Adam, I've got $50,000
of discretionary budget.

208
00:10:34,420 --> 00:10:36,479
Do you think this is the best use of it?"

209
00:10:36,480 --> 00:10:38,330
I said, "Wow,

210
00:10:38,330 --> 00:10:40,560
I didn't realize your life was that

211
00:10:40,560 --> 00:10:43,719
constrained by compliance.

212
00:10:43,720 --> 00:10:47,033
I thought you had more discretion
in what you were doing."

213
00:10:47,033 --> 00:10:51,390
But this is the reality in which
a lot of us find ourselves,

214
00:10:51,390 --> 00:10:53,803
is these demands,

215
00:10:54,665 --> 00:10:58,560
push priorities onto us that
might not be the priorities

216
00:10:58,560 --> 00:11:00,489
that we think are the most important.

217
00:11:00,490 --> 00:11:03,148
But it's compliance first, right.

218
00:11:03,148 --> 00:11:05,333
It's, it's terrible stakes.

219
00:11:07,660 --> 00:11:12,660
And this creates conflict
within the organization

220
00:11:13,162 --> 00:11:16,140
because people have different goals,

221
00:11:16,140 --> 00:11:17,830
they have different prioritization.

222
00:11:17,830 --> 00:11:20,212
And you might say, we all
work for the same company,

223
00:11:20,212 --> 00:11:22,310
but the bonuses are different.

224
00:11:22,310 --> 00:11:23,723
The developer's bonus,

225
00:11:24,668 --> 00:11:27,180
excuse me, the developer's bonus

226
00:11:27,180 --> 00:11:29,159
comes from shipping the cool features.

227
00:11:29,159 --> 00:11:33,430
Security's bonus might come
from not being breached.

228
00:11:33,430 --> 00:11:35,400
And that creates conflict

229
00:11:35,400 --> 00:11:37,893
in what we're trying to accomplish.

230
00:11:37,893 --> 00:11:42,581
Now, compliance is imposing
these different goals.

231
00:11:42,581 --> 00:11:45,390
This can be important for an ecosystem

232
00:11:45,390 --> 00:11:46,963
like the payment ecosystem.

233
00:11:46,963 --> 00:11:49,120
It can be important for society.

234
00:11:49,120 --> 00:11:53,300
For example, the way the
Europeans have imposed GDPR

235
00:11:53,300 --> 00:11:57,008
because they say privacy is
important to us as a society.

236
00:11:57,009 --> 00:12:00,110
Even if your company has a different view,

237
00:12:00,110 --> 00:12:02,320
even if your company is somewhere else

238
00:12:02,320 --> 00:12:05,140
you're imposing this on
our European citizens.

239
00:12:05,140 --> 00:12:08,920
It's easy to lose sight of
that, if you're in the weeds.

240
00:12:08,920 --> 00:12:11,240
This never ending stream of demands

241
00:12:11,240 --> 00:12:13,828
really draws us away from,

242
00:12:13,828 --> 00:12:17,242
yeah, there actually
are reasons to do this.

243
00:12:19,122 --> 00:12:21,530
And so with that,

244
00:12:21,530 --> 00:12:25,670
let me build the next piece in our setup,

245
00:12:25,670 --> 00:12:27,550
which is an introduction
to threat modeling.

246
00:12:27,550 --> 00:12:28,990
And I'm gonna talk about threat modeling

247
00:12:28,990 --> 00:12:30,949
versus threat intelligence,

248
00:12:30,949 --> 00:12:33,939
because people often get
a little confused there.

249
00:12:33,940 --> 00:12:36,160
And then I'll talk about
what is threat modeling

250
00:12:36,160 --> 00:12:38,913
and give you a two-minute
introduction to how to do it.

251
00:12:39,860 --> 00:12:42,782
So threat modeling versus
threat intelligence.

252
00:12:42,782 --> 00:12:45,349
First, what do we mean by threat,

253
00:12:45,349 --> 00:12:48,883
in threat modeling it's the
promise of future violence.

254
00:12:48,883 --> 00:12:52,180
He said he would beat me
up if I didn't give him

255
00:12:52,180 --> 00:12:53,848
my lunch money.

256
00:12:53,848 --> 00:12:57,819
There's a problem that the
API could be overwhelmed

257
00:12:57,820 --> 00:12:59,620
by a brute force attack.

258
00:12:59,620 --> 00:13:01,600
These are promises of future violence,

259
00:13:01,600 --> 00:13:04,600
that's the meaning of
threat in threat modeling.

260
00:13:04,600 --> 00:13:07,110
In threat intelligence,
we're talking about

261
00:13:07,110 --> 00:13:10,081
attackers or attacker groups.

262
00:13:10,081 --> 00:13:13,539
Threat modeling often happens very early

263
00:13:13,539 --> 00:13:15,270
in the development process,

264
00:13:15,270 --> 00:13:17,660
sometimes before there's even a design,

265
00:13:17,660 --> 00:13:19,656
when it's on an whiteboard.

266
00:13:19,657 --> 00:13:24,070
Threat intelligence is once the
system is built and deployed

267
00:13:24,070 --> 00:13:25,993
we're finding attacks against it.

268
00:13:25,993 --> 00:13:29,470
The goal of threat
modeling is to find issues,

269
00:13:29,470 --> 00:13:32,750
the goal of threat intelligence
is to find attackers.

270
00:13:32,750 --> 00:13:35,130
And then the vendor
support is very different,

271
00:13:35,130 --> 00:13:37,000
in threat modeling it's consulting,

272
00:13:37,000 --> 00:13:39,040
it's training, it's software.

273
00:13:39,040 --> 00:13:42,180
In threat intelligence it's
much more focused around

274
00:13:42,180 --> 00:13:44,250
feeds of information.

275
00:13:44,250 --> 00:13:48,225
And so we're focused on threat
modeling, that middle column.

276
00:13:48,225 --> 00:13:50,560
What we're going to do

277
00:13:50,560 --> 00:13:54,109
is apply threat modeling to compliance.

278
00:13:54,110 --> 00:13:55,963
And when I talk about threat modeling,

279
00:13:55,963 --> 00:13:58,190
there's a lot of ways to threat model

280
00:13:58,191 --> 00:14:01,185
and I focus in on four key questions.

281
00:14:01,185 --> 00:14:03,380
Those questions are,
what are we working on,

282
00:14:03,380 --> 00:14:04,840
what can go wrong,

283
00:14:04,840 --> 00:14:06,180
what are we going to do about it,

284
00:14:06,180 --> 00:14:08,390
and did we do a good job?

285
00:14:08,390 --> 00:14:09,824
And we can ask those questions

286
00:14:09,825 --> 00:14:12,821
at that incredibly simple level.

287
00:14:12,821 --> 00:14:16,570
We can apply tools and I'll
show you some in just a second

288
00:14:16,570 --> 00:14:20,600
that help us think about
each of these questions.

289
00:14:20,600 --> 00:14:25,600
But these questions
allow us to be systematic

290
00:14:25,840 --> 00:14:28,114
in the way in which we
think about the question

291
00:14:28,114 --> 00:14:31,216
of what are we working
on and what can go wrong,

292
00:14:31,216 --> 00:14:35,210
so that we can be
structured and comprehensive

293
00:14:35,210 --> 00:14:37,889
in the security design of our systems.

294
00:14:37,889 --> 00:14:41,210
And that is a really powerful tool set.

295
00:14:41,210 --> 00:14:44,070
It's why I do what I do,

296
00:14:44,070 --> 00:14:47,160
is because these four questions unlock

297
00:14:47,160 --> 00:14:51,033
a more strategic approach to security.

298
00:14:53,130 --> 00:14:55,100
So how do we do this?

299
00:14:55,100 --> 00:14:59,370
Often we'll use data flow
diagrams to represent our systems.

300
00:14:59,370 --> 00:15:03,660
And for this talk, I'm not
going to delve really deeply

301
00:15:03,660 --> 00:15:06,760
into what a data flow diagram is,

302
00:15:06,760 --> 00:15:09,810
but you'll see diagrams like this

303
00:15:09,810 --> 00:15:13,392
as ways to represent
what we're working on.

304
00:15:14,340 --> 00:15:16,270
As we talk about what can go wrong

305
00:15:16,270 --> 00:15:17,990
we often talk about stride.

306
00:15:17,990 --> 00:15:19,180
Stride stands for spoofing,

307
00:15:19,180 --> 00:15:21,010
tampering, repudiation,
information disclosure,

308
00:15:21,010 --> 00:15:23,340
denial of service and
elevation of privilege.

309
00:15:23,340 --> 00:15:24,860
I say it a lot.

310
00:15:24,860 --> 00:15:27,227
And people will say the stride methodology

311
00:15:27,227 --> 00:15:29,579
or the stride taxonomy.

312
00:15:29,580 --> 00:15:32,684
It's not a taxonomy or
methodology in and of itself.

313
00:15:32,684 --> 00:15:36,695
It's a structure that helps
us think about the question,

314
00:15:36,696 --> 00:15:39,120
what can go wrong?

315
00:15:39,120 --> 00:15:44,120
And in doing so, we get to
a set of things we're going

316
00:15:44,210 --> 00:15:46,290
to do about these, the threats.

317
00:15:46,290 --> 00:15:50,360
We get to a set of controls to mitigations

318
00:15:50,360 --> 00:15:52,468
that help us address the problem.

319
00:15:52,468 --> 00:15:54,836
And so threat modeling works

320
00:15:54,836 --> 00:15:59,698
as a framework for
thinking about the threats,

321
00:15:59,698 --> 00:16:01,980
and how we deal with them

322
00:16:01,980 --> 00:16:04,163
that we can apply to compliance.

323
00:16:06,530 --> 00:16:08,549
So how do we do that,

324
00:16:08,549 --> 00:16:12,900
this diagram is something I
created while I was working

325
00:16:12,900 --> 00:16:14,620
on my threat modeling book.

326
00:16:14,620 --> 00:16:17,472
And there's an interplay
between each of the elements,

327
00:16:17,472 --> 00:16:20,516
the requirements, threats, and controls.

328
00:16:20,517 --> 00:16:22,946
So if we say, for example

329
00:16:22,946 --> 00:16:26,577
we need to protect the confidentiality

330
00:16:26,577 --> 00:16:29,000
of a credit card number,

331
00:16:29,000 --> 00:16:31,620
then that, then that can inform a threat.

332
00:16:31,620 --> 00:16:34,700
We're worried about the threat
of information disclosure.

333
00:16:34,700 --> 00:16:36,300
Or we can go the other way,

334
00:16:36,300 --> 00:16:38,544
the threat can inform the requirement.

335
00:16:38,544 --> 00:16:40,480
If I'm thinking about a threat,

336
00:16:40,480 --> 00:16:41,850
say the threat that someone's going

337
00:16:41,850 --> 00:16:44,830
to walk through my front
door, I have a control,

338
00:16:44,830 --> 00:16:46,720
I put a lock on it.

339
00:16:46,720 --> 00:16:48,790
And that control comes under threat.

340
00:16:48,790 --> 00:16:51,880
Someone could pick the
lock, they could drill it,

341
00:16:51,880 --> 00:16:53,689
they could kick the door down.

342
00:16:53,689 --> 00:16:56,480
And so I could start by
thinking about the control

343
00:16:56,480 --> 00:16:58,070
and what can go wrong with the control,

344
00:16:58,070 --> 00:16:59,427
or I can think about the threat and say,

345
00:16:59,427 --> 00:17:00,810
"Oh, I need to control here."

346
00:17:00,810 --> 00:17:02,880
And so there's a back and forth.

347
00:17:02,880 --> 00:17:04,343
And then we've got,

348
00:17:06,550 --> 00:17:10,050
we've got a dotted line from
requirements to control.

349
00:17:10,050 --> 00:17:14,829
And when I talk about threat
modeling I'll often joke that

350
00:17:16,040 --> 00:17:17,409
the dotted line is is there

351
00:17:17,410 --> 00:17:20,160
'cause it doesn't make a lot of sense.

352
00:17:20,160 --> 00:17:22,900
What, what's the point of a
requirement to have a control

353
00:17:22,900 --> 00:17:25,290
if there's no threat involved?

354
00:17:25,290 --> 00:17:27,598
Sounds like a good
definition of compliance.

355
00:17:27,598 --> 00:17:28,510
(Adams laughing)

356
00:17:28,510 --> 00:17:30,373
Let's all poke fun at compliance.

357
00:17:31,970 --> 00:17:34,656
It's also sorta true, funny, not funny.

358
00:17:34,656 --> 00:17:39,656
And this talk is really about this line

359
00:17:40,550 --> 00:17:42,572
and this relationship.

360
00:17:42,572 --> 00:17:47,110
Were compliance regimes

361
00:17:47,110 --> 00:17:49,919
require that we put controls in place

362
00:17:49,920 --> 00:17:52,200
without going through the threat.

363
00:17:52,200 --> 00:17:56,130
And I think that that
creates needless conflict,

364
00:17:56,130 --> 00:18:00,970
needless ambiguity, needless anxiety

365
00:18:00,970 --> 00:18:05,359
and leaves us less secure than we would be

366
00:18:05,359 --> 00:18:08,783
if we talk about the threat models.

367
00:18:10,490 --> 00:18:12,387
So what I want to do,

368
00:18:12,387 --> 00:18:13,970
and what we'll do in just a minute

369
00:18:13,970 --> 00:18:16,600
is we'll take that
opaque box that you saw.

370
00:18:16,600 --> 00:18:19,919
The stuff happens here box,
and make it transparent.

371
00:18:19,920 --> 00:18:22,124
We'll make it more explicit.

372
00:18:22,124 --> 00:18:25,320
So, let's go do this.

373
00:18:25,320 --> 00:18:28,105
Let's delve in and ask the question,

374
00:18:28,105 --> 00:18:31,110
what is PCI's threat model.

375
00:18:31,110 --> 00:18:34,790
And let me start off.

376
00:18:34,790 --> 00:18:37,629
And this, this was sort
of a funny accident

377
00:18:37,630 --> 00:18:41,010
and I'm really glad that
the reviewer made this.

378
00:18:41,010 --> 00:18:44,892
One of the reviewers at the RSA
conference made this comment

379
00:18:44,892 --> 00:18:47,730
in looking at an early draft of this deck.

380
00:18:47,730 --> 00:18:49,147
And they said,

381
00:18:49,147 --> 00:18:51,759
"The standard is concerned
with a single threat actor,

382
00:18:51,759 --> 00:18:55,106
generally sophisticated and
motivated organized crime,

383
00:18:55,106 --> 00:18:58,434
wanting to affect a single
factor confidentiality

384
00:18:58,434 --> 00:19:00,970
or a single asset payment cards."

385
00:19:00,970 --> 00:19:03,480
And we'll, we'll come back to this

386
00:19:03,480 --> 00:19:06,053
'cause I think it illustrates
a point really well.

387
00:19:07,542 --> 00:19:11,513
Before we get into what I'm going to say,

388
00:19:11,513 --> 00:19:15,570
what I'm gonna show you is my best effort

389
00:19:15,570 --> 00:19:19,960
to understand PCI, but
I don't represent PCI,

390
00:19:19,960 --> 00:19:22,720
I don't work for them, I'm not a QSA.

391
00:19:22,720 --> 00:19:26,483
So please, this is not official.

392
00:19:27,340 --> 00:19:29,490
Thank you for understanding.

393
00:19:29,490 --> 00:19:32,190
So what I went, what I went and did

394
00:19:32,190 --> 00:19:34,530
is I took my knowledge of threat modeling

395
00:19:34,530 --> 00:19:37,260
and I went through the PCI standard,

396
00:19:37,260 --> 00:19:40,802
and I looked at each and
every line, and I said

397
00:19:40,802 --> 00:19:44,780
"What is the, what does this line mean?

398
00:19:44,780 --> 00:19:47,168
Going to imagine a threat here."

399
00:19:47,168 --> 00:19:50,699
And when I got to something
like this description of groups,

400
00:19:50,700 --> 00:19:52,190
roles and responsibilities

401
00:19:52,190 --> 00:19:54,397
for management of network components,

402
00:19:54,397 --> 00:19:57,703
I tried to integrate it
into the threat list.

403
00:19:59,400 --> 00:20:01,770
I'm telling you this story politely

404
00:20:01,770 --> 00:20:04,334
let me tell you what I actually did.

405
00:20:04,334 --> 00:20:07,617
I jumped up and down
and I yelled and I said,

406
00:20:07,617 --> 00:20:10,167
"This isn't a threat, what is this?"

407
00:20:11,240 --> 00:20:14,080
It was frustrating because this

408
00:20:15,000 --> 00:20:18,230
doesn't relate to that promise

409
00:20:18,230 --> 00:20:22,602
of a future problem, it's okay.

410
00:20:22,602 --> 00:20:26,943
So where does this play in?

411
00:20:28,590 --> 00:20:31,990
And so eventually what I got to

412
00:20:31,990 --> 00:20:35,840
was a realization, that
there are process issues

413
00:20:35,840 --> 00:20:38,639
and there are technology
issues represented.

414
00:20:38,640 --> 00:20:42,730
And instead of just
building out a threats list

415
00:20:42,730 --> 00:20:45,200
I realized what I really needed

416
00:20:45,200 --> 00:20:50,170
was a set of models representing
what PCI was thinking

417
00:20:50,170 --> 00:20:53,582
or what the PCI experts
were thinking about.

418
00:20:53,582 --> 00:20:56,900
And so I started integrating on both

419
00:20:56,900 --> 00:20:59,600
these system models and a threats list.

420
00:20:59,600 --> 00:21:01,699
And that led me to something

421
00:21:01,700 --> 00:21:04,163
that I think is actually very interesting.

422
00:21:05,850 --> 00:21:10,530
And so the, the threats or the controls,

423
00:21:10,530 --> 00:21:15,070
the mitigations in PCI,
the things you have to do

424
00:21:15,070 --> 00:21:17,070
the answers to these questions

425
00:21:17,070 --> 00:21:18,620
of what are we gonna do about it,

426
00:21:18,620 --> 00:21:20,854
that's part of threat modeling

427
00:21:20,855 --> 00:21:22,690
are a broad set.

428
00:21:22,690 --> 00:21:26,150
They prevent detect respond controls,

429
00:21:26,150 --> 00:21:29,440
they're often threats of
information disclosure

430
00:21:29,440 --> 00:21:34,440
but they're also unusually
threats to management

431
00:21:34,830 --> 00:21:37,179
or threats to the
management of the system.

432
00:21:37,180 --> 00:21:40,070
They're not threats
directed at management.

433
00:21:40,070 --> 00:21:42,590
Or they're threats to
our ability to comply

434
00:21:42,590 --> 00:21:43,659
with the standard.

435
00:21:43,660 --> 00:21:46,151
And this is an unusual thing.

436
00:21:46,151 --> 00:21:50,134
It compared to how we
often threat model systems

437
00:21:50,134 --> 00:21:52,200
as we ask what can go wrong,

438
00:21:52,200 --> 00:21:56,065
as we ask what are we working
and what can go wrong.

439
00:21:56,065 --> 00:21:59,740
We don't often come to the answer.

440
00:21:59,740 --> 00:22:04,590
What can go wrong, is lacks a
days ago management oversight

441
00:22:04,590 --> 00:22:07,129
or insufficiently applied processes.

442
00:22:07,130 --> 00:22:09,798
We much more often come to,

443
00:22:09,798 --> 00:22:13,311
an attacker could send in an exploit

444
00:22:13,311 --> 00:22:16,889
that takes over my computer.

445
00:22:16,890 --> 00:22:21,580
Or the attacker could engage
in a denial of service attack,

446
00:22:21,580 --> 00:22:23,470
et cetera, et cetera.

447
00:22:23,470 --> 00:22:28,470
And so, the process model,
which I created for PCI

448
00:22:29,354 --> 00:22:33,300
is up on the top right,

449
00:22:33,300 --> 00:22:35,794
there's a set of change
management activities.

450
00:22:35,795 --> 00:22:38,370
Some of these are interrupted driven,

451
00:22:38,370 --> 00:22:40,892
when this occurs do this.

452
00:22:41,920 --> 00:22:45,060
Some of them are timer driven,
once a quarter do that.

453
00:22:45,060 --> 00:22:47,710
And that feeds into a
set of review processes,

454
00:22:47,710 --> 00:22:50,010
approval and execution,

455
00:22:50,010 --> 00:22:53,060
which influences your technical systems.

456
00:22:53,060 --> 00:22:54,590
And there's a tracking database.

457
00:22:54,590 --> 00:22:56,580
You knew about that
tracking database, right.

458
00:22:56,580 --> 00:22:58,643
But there's a tracking database.

459
00:22:58,643 --> 00:23:01,950
Where all of this stuff
is supposed to flow to

460
00:23:01,950 --> 00:23:04,319
so that it can be audited.

461
00:23:04,319 --> 00:23:08,760
There's a set of standards,
for system deployment

462
00:23:08,760 --> 00:23:10,403
there's a set of standards.

463
00:23:11,484 --> 00:23:14,850
And those standards drive
configuration and deployment

464
00:23:14,850 --> 00:23:18,543
and the, the gray numbers, the C1, the C7.

465
00:23:18,544 --> 00:23:21,800
Our system element identifiers

466
00:23:21,800 --> 00:23:23,970
to help us relate the tables of threats

467
00:23:23,970 --> 00:23:27,630
which I'll show you in a
minute, to the system models.

468
00:23:27,630 --> 00:23:29,693
So this is their process model.

469
00:23:32,320 --> 00:23:33,760
And this is their system model.

470
00:23:33,760 --> 00:23:36,960
And their system model, starts
with a credit card number

471
00:23:36,960 --> 00:23:38,570
over on the far left.

472
00:23:38,570 --> 00:23:41,290
That talks to a point of sale system.

473
00:23:41,290 --> 00:23:46,290
Which in their model connects
via a wireless network to

474
00:23:46,320 --> 00:23:49,156
the current data environment
that trust boundary

475
00:23:49,156 --> 00:23:51,970
with the eight C D E M F,

476
00:23:51,970 --> 00:23:54,980
is where all the processing happens.

477
00:23:54,980 --> 00:23:56,508
And then from there,

478
00:23:56,508 --> 00:24:00,830
data flows out to an
acquirer credit card jargon.

479
00:24:00,830 --> 00:24:04,070
The acquire is the bank that acquires

480
00:24:04,070 --> 00:24:05,790
the charges from a merchant,

481
00:24:05,790 --> 00:24:07,970
and sends them to the issuing bank.

482
00:24:07,970 --> 00:24:12,210
That's gives you as an
individual, your credit card.

483
00:24:12,210 --> 00:24:15,871
And so this is my, and again we've got

484
00:24:15,871 --> 00:24:19,310
the gray numbers here.

485
00:24:19,310 --> 00:24:24,310
And I did this model first
before I realized we also needed

486
00:24:25,104 --> 00:24:28,490
a model of the process.

487
00:24:28,490 --> 00:24:32,680
And based on these models
and based on the standard,

488
00:24:32,680 --> 00:24:37,340
we can create a set of
threats to processes.

489
00:24:37,340 --> 00:24:39,169
So for example,

490
00:24:39,170 --> 00:24:41,360
we've got a threat that
the firewall rule set

491
00:24:41,360 --> 00:24:44,330
will go out of date,
some management threat.

492
00:24:44,330 --> 00:24:48,439
And this is a threat which is
managed, which is addressed

493
00:24:48,440 --> 00:24:53,410
controlled, mitigated by
PCI requirement 1.1.7.

494
00:24:54,680 --> 00:24:58,000
There's a threat that
old data isn't deleted,

495
00:24:58,000 --> 00:25:01,060
which is covered by 3.1 bullet 2.

496
00:25:01,060 --> 00:25:05,610
And so we can go through the PCI standard,

497
00:25:05,610 --> 00:25:07,520
and I'll give you a link at the end,

498
00:25:07,520 --> 00:25:10,773
by the way to this whole set of lists.

499
00:25:11,638 --> 00:25:13,709
But right now, I don't wanna focus

500
00:25:13,710 --> 00:25:18,710
on a line by line analysis,
in the interest of time.

501
00:25:19,530 --> 00:25:21,580
What I wanna say is we
have threats to process

502
00:25:21,580 --> 00:25:23,970
and we have threats to technology.

503
00:25:23,970 --> 00:25:27,603
And a couple of interesting
things come out here.

504
00:25:27,603 --> 00:25:32,603
One, is that in the PCI standard itself,

505
00:25:34,600 --> 00:25:38,050
there are no threats to your credit card.

506
00:25:38,050 --> 00:25:40,120
Your credit card in your wallet

507
00:25:40,990 --> 00:25:44,710
is not something that is
addressed by the standard.

508
00:25:44,710 --> 00:25:45,990
Come back to that.

509
00:25:45,990 --> 00:25:48,740
The other thing that came
out, I was talking to someone

510
00:25:50,570 --> 00:25:54,956
about this work and he said,

511
00:25:54,957 --> 00:25:58,770
"Storing authentication
data isn't a threat."

512
00:25:58,770 --> 00:26:00,629
I said, "You're right, it's not."

513
00:26:00,629 --> 00:26:04,639
It's, it's an enabler of a future problem.

514
00:26:04,640 --> 00:26:07,379
If you don't store the
data, you can't leak it.

515
00:26:07,379 --> 00:26:12,379
And so PCI's approach is a little unusual

516
00:26:12,960 --> 00:26:16,390
in that they consider the
storage to be the problem.

517
00:26:16,390 --> 00:26:18,360
It's a violation of the requirements

518
00:26:18,360 --> 00:26:21,949
even if it never leaks.

519
00:26:21,950 --> 00:26:25,820
And getting to that
understanding helps us understand

520
00:26:25,820 --> 00:26:29,370
the why behind PCI.

521
00:26:29,370 --> 00:26:31,830
So that we can actually address it better

522
00:26:31,830 --> 00:26:34,990
so that we can communicate
with our colleagues

523
00:26:34,990 --> 00:26:38,710
when there's conflict
over what we need to do

524
00:26:38,710 --> 00:26:40,860
and why we need to do it.

525
00:26:40,860 --> 00:26:44,030
So let me come back to
what that reviewer said,

526
00:26:44,030 --> 00:26:48,430
and what they said was
that the PCI standard

527
00:26:48,430 --> 00:26:51,902
is about a single factor confidentiality.

528
00:26:51,902 --> 00:26:56,310
And it turns out when we
go through this exercise,

529
00:26:56,310 --> 00:26:59,710
integrity is important,
auditability is important,

530
00:26:59,710 --> 00:27:01,320
repudiation is important.

531
00:27:01,320 --> 00:27:03,350
And I was talking to a friend who's close

532
00:27:03,350 --> 00:27:05,342
to the whole process,

533
00:27:05,343 --> 00:27:07,950
and they told me that

534
00:27:09,240 --> 00:27:13,340
actually, you know the logs are not there

535
00:27:13,340 --> 00:27:16,550
for the victim of the break-in.

536
00:27:16,550 --> 00:27:18,700
They're there for the card companies,

537
00:27:18,700 --> 00:27:22,001
when they go in and do an
analysis of the big breaches

538
00:27:22,001 --> 00:27:25,580
they were finding a lack of logs.

539
00:27:25,580 --> 00:27:29,300
And that didn't even
come out as I was reading

540
00:27:29,300 --> 00:27:33,639
the PCI standard, it came
out of a later conversation.

541
00:27:33,640 --> 00:27:37,200
But it's important to
understand why we're storing

542
00:27:37,200 --> 00:27:40,250
and protecting these logs in this way.

543
00:27:40,250 --> 00:27:41,930
The other thing they said,

544
00:27:41,930 --> 00:27:45,390
the other thing the reviewer said is that,

545
00:27:45,390 --> 00:27:47,460
there's the standard is concerned

546
00:27:47,460 --> 00:27:49,280
with a single threat actor.

547
00:27:49,280 --> 00:27:52,979
That's not something that
I saw reading the standard.

548
00:27:52,979 --> 00:27:57,979
Now, does that matter?

549
00:27:58,410 --> 00:28:03,410
Well, if we're trying to
reduce conflict and help people

550
00:28:04,435 --> 00:28:08,280
get value out of doing this work,

551
00:28:08,280 --> 00:28:12,300
then the problem is not me disagreeing

552
00:28:12,300 --> 00:28:14,790
collegialy with a reviewer,

553
00:28:14,790 --> 00:28:18,970
the problem is that we have
that space in which to disagree.

554
00:28:18,970 --> 00:28:23,313
The opportunity for
disagreement between myself

555
00:28:23,313 --> 00:28:27,340
and one of the smart folks
who serves as a member

556
00:28:27,340 --> 00:28:31,830
of the RSA conference program
committee, that is a problem.

557
00:28:31,830 --> 00:28:34,639
We, as smart people,
ought to be in agreement

558
00:28:34,640 --> 00:28:36,623
about what it is we're doing.

559
00:28:41,680 --> 00:28:46,680
And so I believe that
we can improve security

560
00:28:47,137 --> 00:28:51,399
by your organization doing
better threat modeling.

561
00:28:51,400 --> 00:28:54,240
By definition outside
standards are not going

562
00:28:54,240 --> 00:28:57,040
to address your unique needs.

563
00:28:57,040 --> 00:28:58,950
You've got a whole bunch of standards

564
00:28:58,950 --> 00:29:00,610
that you have to look at.

565
00:29:00,610 --> 00:29:02,500
You have to look at PCI DSS,

566
00:29:02,500 --> 00:29:05,510
you have to look at the NIST
cybersecurity framework.

567
00:29:05,510 --> 00:29:08,290
Some are very specific,
some are very broad.

568
00:29:08,290 --> 00:29:10,860
If you pick up all of these standards

569
00:29:10,860 --> 00:29:12,409
and you threat model and you say,

570
00:29:12,410 --> 00:29:15,155
these are the threats
we're going to address.

571
00:29:15,155 --> 00:29:18,035
You get to the point where
you can be structured,

572
00:29:18,035 --> 00:29:22,300
systematic and comprehensive
in what you address.

573
00:29:22,300 --> 00:29:26,803
And then you can tie your
mitigations back to the standards.

574
00:29:26,803 --> 00:29:30,190
And this is really important,

575
00:29:30,190 --> 00:29:32,010
in limiting the run-around,

576
00:29:32,010 --> 00:29:34,890
limiting the treadmill that you're on

577
00:29:34,890 --> 00:29:37,443
by understanding where you're going.

578
00:29:39,500 --> 00:29:43,830
Threat modeling shines
a into this opaque box.

579
00:29:43,830 --> 00:29:47,399
And in shining that light, what we do

580
00:29:47,400 --> 00:29:52,390
is we improve security because
we're focused on the threats

581
00:29:52,390 --> 00:29:55,050
and we're focused on
making sure we're not just

582
00:29:55,050 --> 00:29:57,790
picking up controls and slapping them in,

583
00:29:57,790 --> 00:30:00,470
but we're picking up
controls and using them

584
00:30:00,470 --> 00:30:03,470
to address in understood threat,

585
00:30:03,470 --> 00:30:07,573
we're using them to
mitigate a real problem.

586
00:30:08,560 --> 00:30:13,301
This informs our prioritization,
which of these we do first.

587
00:30:13,301 --> 00:30:18,030
It can also, reduce
conflict between teams,

588
00:30:18,030 --> 00:30:20,399
reduce conflict with auditors, maybe,

589
00:30:20,400 --> 00:30:22,000
but it's a little a lot of work.

590
00:30:24,080 --> 00:30:29,080
So, the conflict comes
from different goals

591
00:30:29,400 --> 00:30:31,310
and different priority.

592
00:30:31,310 --> 00:30:34,860
And when compliance is imposing these new

593
00:30:34,860 --> 00:30:36,760
and different goals,

594
00:30:36,760 --> 00:30:39,362
there's no understanding of the why.

595
00:30:39,362 --> 00:30:42,131
Threat modeling gives us a language,

596
00:30:42,131 --> 00:30:45,929
what are we working on, what can go wrong?

597
00:30:45,929 --> 00:30:50,929
The line by line controls

598
00:30:51,000 --> 00:30:54,709
that the compliance
standards demand of us,

599
00:30:54,709 --> 00:30:59,270
are informed by this a joint understanding

600
00:30:59,270 --> 00:31:02,340
of what we're working
on and what can go wrong

601
00:31:02,340 --> 00:31:05,183
and therefore what we need to do about it.

602
00:31:06,515 --> 00:31:11,230
So threat modeling also gives us a vehicle

603
00:31:11,230 --> 00:31:14,370
to create collaborative spaces.

604
00:31:14,370 --> 00:31:16,860
And here the journey is really the reward.

605
00:31:16,860 --> 00:31:19,284
I want you to think about threat modeling

606
00:31:19,285 --> 00:31:23,060
more than I want you to
think about threat models.

607
00:31:23,060 --> 00:31:25,590
And I want you to think
about these in terms

608
00:31:25,590 --> 00:31:28,227
of teams working together,

609
00:31:28,228 --> 00:31:31,860
across organizational boundaries

610
00:31:31,860 --> 00:31:34,324
to generate the shared understanding,

611
00:31:34,325 --> 00:31:37,317
and a space for listening to the concerns

612
00:31:37,317 --> 00:31:39,950
of the other teams.

613
00:31:39,950 --> 00:31:41,360
Look, I get it.

614
00:31:41,360 --> 00:31:46,139
Security teams are almost always too busy.

615
00:31:46,140 --> 00:31:48,620
It's hard to make the time to listen

616
00:31:48,620 --> 00:31:51,666
but listening is so important.

617
00:31:51,666 --> 00:31:55,200
It creates space for the
people you're working with

618
00:31:55,200 --> 00:31:57,720
to help you discover solutions,

619
00:31:57,720 --> 00:32:00,040
to make smarter solutions to the problems

620
00:32:00,040 --> 00:32:01,909
that are in front of you.

621
00:32:01,910 --> 00:32:04,930
And when you found that solution together

622
00:32:04,930 --> 00:32:08,200
there's a joint ownership
of what the solution is

623
00:32:08,200 --> 00:32:09,380
and why you're doing it.

624
00:32:09,380 --> 00:32:12,671
And so security gets
built in not bolted on.

625
00:32:12,671 --> 00:32:15,930
Doesn't get left behind on the shelf

626
00:32:15,930 --> 00:32:17,963
because you made time to listen.

627
00:32:19,530 --> 00:32:24,240
So, I also think that
there's work to be done

628
00:32:24,240 --> 00:32:25,740
by standards bodies.

629
00:32:25,740 --> 00:32:28,500
Why is every organization
doing this analysis?

630
00:32:28,500 --> 00:32:31,796
This was really hard work,
this was challenging work.

631
00:32:31,796 --> 00:32:34,036
I think we ought to demand

632
00:32:34,036 --> 00:32:37,430
that standards bodies
show their threat models,

633
00:32:37,430 --> 00:32:40,530
and I'm talking to some and
I'd be happy to talk to more

634
00:32:40,530 --> 00:32:42,420
about exactly how to do this.

635
00:32:42,420 --> 00:32:44,700
This will improve the standards.

636
00:32:44,700 --> 00:32:47,362
It will improve the
impact of the standards

637
00:32:47,362 --> 00:32:50,438
because when their model
doesn't represent your system

638
00:32:50,438 --> 00:32:52,370
it's more visible.

639
00:32:52,370 --> 00:32:55,889
So the controls are going to get adjusted.

640
00:32:55,890 --> 00:32:58,960
They'll get invalidated in
that creates some tension

641
00:32:58,960 --> 00:33:02,499
that we need to deal with and
think about intelligently.

642
00:33:02,499 --> 00:33:04,767
There's some complexity here.

643
00:33:04,767 --> 00:33:07,350
People might gain the standard,

644
00:33:07,350 --> 00:33:08,959
the cost of assessment will change.

645
00:33:08,960 --> 00:33:10,870
We'll need to retrain the assessors

646
00:33:10,870 --> 00:33:14,453
about what to do in these
situations, but that's worthwhile.

647
00:33:15,980 --> 00:33:20,980
So again the review process
was really interesting.

648
00:33:21,110 --> 00:33:23,127
One of the reviewers asked,

649
00:33:23,127 --> 00:33:24,820
"Can we create a single threat model,

650
00:33:24,820 --> 00:33:26,367
independent of details?"

651
00:33:27,360 --> 00:33:29,860
Well, it's a great question,

652
00:33:29,860 --> 00:33:33,840
but the one size fits all PCI standard

653
00:33:33,840 --> 00:33:37,030
covers the very largest e-commerce stores.

654
00:33:37,030 --> 00:33:38,889
It covers a very small retailer

655
00:33:38,890 --> 00:33:40,480
using something like Shopify.

656
00:33:40,480 --> 00:33:43,557
It covers a brick and mortar store.

657
00:33:43,557 --> 00:33:48,140
And so my answer to
the reviewer who asked,

658
00:33:48,140 --> 00:33:50,743
this great question was,

659
00:33:51,854 --> 00:33:54,847
yeah, the PCI standard
says they've created

660
00:33:54,847 --> 00:33:58,964
a single threat model
independent of these details.

661
00:33:58,964 --> 00:34:03,503
And I think that that has
created some problems.

662
00:34:05,240 --> 00:34:07,050
So some short-term wins.

663
00:34:07,050 --> 00:34:10,116
Go learn a little threat
modeling, I'll talk about how

664
00:34:10,117 --> 00:34:12,000
on the next slide.

665
00:34:12,000 --> 00:34:13,929
And I want you to focus in on what

666
00:34:13,929 --> 00:34:16,243
you're working on right now.

667
00:34:16,244 --> 00:34:18,885
What are the CEO's key priorities?

668
00:34:18,885 --> 00:34:23,150
And frankly, today in
2021 that is pandemic

669
00:34:23,150 --> 00:34:25,170
and coming out of the pandemic.

670
00:34:25,170 --> 00:34:29,860
Focus on things that are
being changed right now

671
00:34:29,860 --> 00:34:34,020
because that is where the fluidity exists.

672
00:34:34,020 --> 00:34:35,929
It makes change easier.

673
00:34:35,929 --> 00:34:40,929
There's a trap of falling
into the high risk areas.

674
00:34:41,110 --> 00:34:44,000
Areas where you've been fighting.

675
00:34:44,000 --> 00:34:46,940
Don't go there, you will
mess up your threat modeling

676
00:34:46,940 --> 00:34:48,739
initiative before it starts.

677
00:34:48,739 --> 00:34:51,620
Go to what is being changed now

678
00:34:51,620 --> 00:34:54,942
and use threat modeling to
frame a new conversation.

679
00:34:55,980 --> 00:34:59,360
When we learn to threat model,
the four question framework

680
00:34:59,360 --> 00:35:01,410
what are we working on, what can go wrong,

681
00:35:01,410 --> 00:35:02,560
what are we going to do about it,

682
00:35:02,560 --> 00:35:05,907
did we do a good job, is super useful.

683
00:35:05,907 --> 00:35:09,580
"Elevation Of Privilege",
is a card game I created.

684
00:35:09,580 --> 00:35:12,700
Microsoft has released it
under creative commons license.

685
00:35:12,700 --> 00:35:14,638
You can buy copies on Amazon now.

686
00:35:14,639 --> 00:35:17,748
Use it as a conversation starter.

687
00:35:17,748 --> 00:35:22,339
Lastly, a group of 15 of us
experts in threat modeling

688
00:35:22,339 --> 00:35:25,070
have released a manifesto,

689
00:35:25,070 --> 00:35:27,570
which is all about how to get going.

690
00:35:27,570 --> 00:35:31,060
The four questions
there, they're so simple,

691
00:35:31,060 --> 00:35:32,730
they fit on a wallet card.

692
00:35:32,730 --> 00:35:35,240
They are the way to get started.

693
00:35:35,240 --> 00:35:36,977
So go learn threat modeling.

694
00:35:36,978 --> 00:35:39,892
In the next week go
build some threat models,

695
00:35:39,892 --> 00:35:43,830
demonstrate that having threat
models helps share them out.

696
00:35:43,830 --> 00:35:46,036
Showcase these new ways of working

697
00:35:46,036 --> 00:35:48,300
and demand that your standards bodies

698
00:35:48,300 --> 00:35:49,540
show their threat models.

699
00:35:49,540 --> 00:35:51,529
And that is gonna take some time

700
00:35:51,530 --> 00:35:54,710
but it's a worthwhile
thing to go invest in.

701
00:35:54,710 --> 00:35:57,392
With that, I wanna say thank you.

702
00:35:57,392 --> 00:35:59,520
If everything went as planned,

703
00:35:59,520 --> 00:36:01,120
I'd been answering some of your questions

704
00:36:01,120 --> 00:36:02,683
in the chat box here.

705
00:36:03,900 --> 00:36:05,760
If you're watching this later on,

706
00:36:05,760 --> 00:36:10,760
my email address,
adam@shostack.org is right there.

707
00:36:11,760 --> 00:36:15,670
And so again, thank you for
your time and attention.

708
00:36:15,670 --> 00:36:18,279
I wanna close out with some resources.

709
00:36:18,279 --> 00:36:20,650
Again, the manifesto,

710
00:36:20,650 --> 00:36:24,504
my threat modeling book website
has a set of free resources.

711
00:36:24,504 --> 00:36:27,299
There's elevation of privilege links

712
00:36:27,300 --> 00:36:29,314
and copies of it on GitHub.

713
00:36:29,314 --> 00:36:32,290
Last but not least on

714
00:36:32,290 --> 00:36:35,320
associates.shostack.org/threatmodeling

715
00:36:35,320 --> 00:36:38,190
is a copy of a white paper I did,

716
00:36:38,190 --> 00:36:40,400
freely no large wall,

717
00:36:40,400 --> 00:36:42,990
that shows this PCI threat model

718
00:36:42,990 --> 00:36:44,470
that we've been talking about.

719
00:36:44,470 --> 00:36:45,629
So with that again,

720
00:36:45,630 --> 00:36:47,810
thank you for your time and attention

721
00:36:47,810 --> 00:36:49,490
and have a great day.

722
00:36:49,490 --> 00:36:50,323
Thank you.

