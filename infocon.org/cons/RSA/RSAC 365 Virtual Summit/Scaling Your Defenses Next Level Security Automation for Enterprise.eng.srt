1
00:00:00,110 --> 00:00:02,780
- Hello everyone, my name is Tomasz Bania

2
00:00:02,780 --> 00:00:04,410
and here at the RSA summit today,

3
00:00:04,410 --> 00:00:07,050
we're gonna be talking about
how to scale your defenses;

4
00:00:07,050 --> 00:00:09,660
next level security
automation for the enterprise.

5
00:00:09,660 --> 00:00:11,570
A quick introduction about myself.

6
00:00:11,570 --> 00:00:13,300
I am the cyber defense manager

7
00:00:13,300 --> 00:00:15,070
in the information
security group at Dolby.

8
00:00:15,070 --> 00:00:17,960
I've been here for about
just over four years now.

9
00:00:17,960 --> 00:00:20,540
Formerly was cyber
defense center lead at HP.

10
00:00:20,540 --> 00:00:22,720
I've been in the IT
space for about 10 years,

11
00:00:22,720 --> 00:00:24,860
eight of those being in
the cybersecurity space.

12
00:00:24,860 --> 00:00:26,520
And I've worked in a number of verticals,

13
00:00:26,520 --> 00:00:28,460
from government to
education and now of course,

14
00:00:28,460 --> 00:00:30,480
in the enterprise space.

15
00:00:30,480 --> 00:00:33,470
So, let's start off with
a few quick questions.

16
00:00:33,470 --> 00:00:34,680
And the first thing is gonna be,

17
00:00:34,680 --> 00:00:36,100
what are we looking to do today

18
00:00:36,100 --> 00:00:37,890
as part of this presentation?

19
00:00:37,890 --> 00:00:40,076
The thing we're looking at is,

20
00:00:40,076 --> 00:00:42,700
how we transition
security operations teams

21
00:00:42,700 --> 00:00:44,480
from manual coordination to focusing

22
00:00:44,480 --> 00:00:46,970
on more complex threats.

23
00:00:46,970 --> 00:00:48,640
So why is this important?

24
00:00:48,640 --> 00:00:51,893
Well, for many of you have seen
security operations centers.

25
00:00:53,617 --> 00:00:56,570
The people really look at the
alerts and then sometimes,

26
00:00:56,570 --> 00:00:58,740
they really get to a point where

27
00:00:58,740 --> 00:01:00,710
they get tired of
looking at the same thing

28
00:01:00,710 --> 00:01:02,610
over and over and over again.

29
00:01:02,610 --> 00:01:05,840
And this is really an
opportunity where we can

30
00:01:05,840 --> 00:01:08,210
automate the monotonous and bring things

31
00:01:08,210 --> 00:01:09,669
that are much more interesting to them,

32
00:01:09,670 --> 00:01:11,870
so that they're more
engaged and feel more valued

33
00:01:11,870 --> 00:01:13,650
within the organization.

34
00:01:13,650 --> 00:01:15,760
And among the other
reasons that we need it,

35
00:01:15,760 --> 00:01:17,580
the alert volumes that we're getting in

36
00:01:17,580 --> 00:01:19,280
because we're bringing
in new technologies,

37
00:01:19,280 --> 00:01:21,650
we're looking at new
techniques, those alert volumes

38
00:01:21,650 --> 00:01:23,920
are increasing without
really a matching growth

39
00:01:23,920 --> 00:01:27,090
in the skilled technical resources
that are available to us.

40
00:01:27,090 --> 00:01:29,770
And again, the more we
can keep people engaged

41
00:01:29,770 --> 00:01:32,979
and increase the job
satisfaction of the things

42
00:01:32,980 --> 00:01:35,560
that are being looked at,
that allows us to retain

43
00:01:35,560 --> 00:01:37,283
those skilled technical resources.

44
00:01:38,180 --> 00:01:42,170
So what do these quote/unquote
automations look like today?

45
00:01:42,170 --> 00:01:45,600
So if we look at the
broader industry as a whole,

46
00:01:45,600 --> 00:01:49,160
a lot is focused around these
single request orchestrations

47
00:01:49,160 --> 00:01:51,640
that are initiated by an analyst.

48
00:01:51,640 --> 00:01:53,860
And this would be things like

49
00:01:53,860 --> 00:01:57,090
in-taking an alert, conducting a check

50
00:01:57,090 --> 00:01:58,860
against an intelligence feed

51
00:01:58,860 --> 00:02:01,179
or initiating a remediation flow

52
00:02:01,180 --> 00:02:02,713
to remediate a given threat.

53
00:02:03,790 --> 00:02:07,180
Some organizations have
certainly moved on past this,

54
00:02:07,180 --> 00:02:10,259
but this is really where
a lot of the things

55
00:02:10,259 --> 00:02:12,220
within existing automation platforms

56
00:02:12,220 --> 00:02:16,160
are tailored to these single
requests orchestrations.

57
00:02:16,160 --> 00:02:17,510
So, how can I measure

58
00:02:17,510 --> 00:02:20,030
my organization's automation capabilities?

59
00:02:20,030 --> 00:02:21,590
And at level one, we're really gonna be

60
00:02:21,590 --> 00:02:23,220
looking at manual processing.

61
00:02:23,220 --> 00:02:26,220
So this is gonna be an
analyst in-taking an alert

62
00:02:26,220 --> 00:02:28,930
and conducting a series of
actions until remediation.

63
00:02:28,930 --> 00:02:30,940
Level two is focusing on what we discussed

64
00:02:30,940 --> 00:02:31,910
just a moment ago.

65
00:02:31,910 --> 00:02:33,549
And this is gonna be things like

66
00:02:33,550 --> 00:02:34,930
a threat intelligence check.

67
00:02:34,930 --> 00:02:37,240
So limited orchestration with not really

68
00:02:37,240 --> 00:02:39,280
any automation being involved.

69
00:02:39,280 --> 00:02:42,030
Level three I classify as
a significant orchestration

70
00:02:42,030 --> 00:02:43,150
with some automation.

71
00:02:43,150 --> 00:02:45,020
And this is where we're
really striking the point

72
00:02:45,020 --> 00:02:48,810
between how much you want to
automate as an organization,

73
00:02:48,810 --> 00:02:50,970
versus how much you want to still have

74
00:02:50,970 --> 00:02:53,930
that manual manual action taking place.

75
00:02:53,930 --> 00:02:56,440
Level four is gonna be full orchestration

76
00:02:56,440 --> 00:02:57,780
with significant automation.

77
00:02:57,780 --> 00:03:00,720
And the example that I
leverage to describe this

78
00:03:00,720 --> 00:03:04,240
is vulnerability management
analysis and patching.

79
00:03:04,240 --> 00:03:05,970
So what we're doing in this scenario

80
00:03:05,970 --> 00:03:10,280
is a vulnerability gets
announced by the industry.

81
00:03:10,280 --> 00:03:12,100
What we can do is we can
leverage an automation

82
00:03:12,100 --> 00:03:13,040
to take a look at

83
00:03:14,054 --> 00:03:18,100
where that vulnerability may
exist within our environment.

84
00:03:18,100 --> 00:03:20,430
Leveraging tools, such as RPA

85
00:03:20,430 --> 00:03:23,010
to deploy a patch onto a test system,

86
00:03:23,010 --> 00:03:27,329
initiate a series of test
scripts to run applications.

87
00:03:27,330 --> 00:03:29,070
And then, let's check;

88
00:03:29,070 --> 00:03:32,477
have any errors been identified

89
00:03:32,477 --> 00:03:34,320
in running those test scripts?

90
00:03:34,320 --> 00:03:37,620
And if nothing came up of concern,

91
00:03:37,620 --> 00:03:40,020
we can then have the next
step of that automation

92
00:03:40,020 --> 00:03:42,490
actually deploy the patch
within our environment.

93
00:03:42,490 --> 00:03:45,230
This can very much shorten the timeline

94
00:03:45,230 --> 00:03:47,756
from identification of a new vulnerability

95
00:03:47,756 --> 00:03:51,270
to having your environment fully patched.

96
00:03:51,270 --> 00:03:52,840
And the fifth level, which is really where

97
00:03:52,840 --> 00:03:54,290
we're gonna be getting into today.

98
00:03:54,290 --> 00:03:57,662
And that's gonna be the full
end to end SOAR implementation.

99
00:03:58,620 --> 00:04:00,330
So now that we're looking at level five,

100
00:04:00,330 --> 00:04:02,150
what can these automations look like

101
00:04:02,150 --> 00:04:03,570
and where do we really start?

102
00:04:03,570 --> 00:04:06,519
So for the purposes of this presentation,

103
00:04:06,520 --> 00:04:08,520
we're really gonna be covering the full

104
00:04:08,520 --> 00:04:10,653
end to end incident response workflow.

105
00:04:11,690 --> 00:04:13,320
This will allow us to leverage automation

106
00:04:13,320 --> 00:04:14,920
throughout the entire process,

107
00:04:14,920 --> 00:04:16,950
from the point of initial identification

108
00:04:16,950 --> 00:04:20,329
all the way down to the
automated handling and reporting.

109
00:04:20,329 --> 00:04:22,099
And the first one we're
gonna jump into here

110
00:04:22,100 --> 00:04:24,883
is component number one; alert ingestion.

111
00:04:26,210 --> 00:04:28,739
What kind of alerts can I bring in?

112
00:04:28,740 --> 00:04:30,380
What I would say is, we
really want to start off

113
00:04:30,380 --> 00:04:32,659
with AV/EDR alerts, as well as those

114
00:04:32,660 --> 00:04:34,863
proxy web gateway firewall alerts.

115
00:04:36,790 --> 00:04:40,100
These feeds anecdotally tend to provide

116
00:04:40,100 --> 00:04:43,080
the highest value as they tend
to have the highest fidelity

117
00:04:44,080 --> 00:04:46,159
for the information that they provide.

118
00:04:46,160 --> 00:04:47,940
What alerts should we be keeping out

119
00:04:47,940 --> 00:04:50,090
of this initial part of our journey?

120
00:04:50,090 --> 00:04:52,500
Well, it's really gonna
be those raw alert feeds.

121
00:04:52,500 --> 00:04:55,900
And the reason is because
one, we may not have the scale

122
00:04:55,900 --> 00:04:57,799
or capacity to address those.

123
00:04:57,800 --> 00:05:00,560
But more importantly,
unless you have a reason

124
00:05:00,560 --> 00:05:03,080
to leverage that data, such as processing

125
00:05:03,080 --> 00:05:05,590
for tertiary data analysis

126
00:05:05,590 --> 00:05:07,429
or machine learning and
deep learning models

127
00:05:07,430 --> 00:05:10,453
as we'll touch on a little
bit later in the presentation,

128
00:05:11,550 --> 00:05:13,630
you don't really want to boil the ocean

129
00:05:13,630 --> 00:05:15,730
as they say in the industry.

130
00:05:15,730 --> 00:05:17,390
The next component we're gonna be covering

131
00:05:17,390 --> 00:05:18,633
is data collection.

132
00:05:20,504 --> 00:05:24,010
From a broader perspective;
what data matters to me?

133
00:05:24,010 --> 00:05:25,590
And the first one we're gonna cover here

134
00:05:25,590 --> 00:05:27,369
is an anomalous system activity.

135
00:05:27,370 --> 00:05:30,170
The example I have outlined as
MITRE ATTACK framework hits.

136
00:05:30,170 --> 00:05:31,530
So I'm sure many of you are familiar.

137
00:05:31,530 --> 00:05:33,330
The MITRE ATTACK framework outlines

138
00:05:33,330 --> 00:05:35,560
specific types of activities that

139
00:05:37,295 --> 00:05:41,203
could be tied to a malicious
actor or a malicious activity.

140
00:05:42,230 --> 00:05:47,100
Being able to see one indicator
from a MITRE ATTACK hit

141
00:05:47,100 --> 00:05:48,380
may not necessarily tell us;

142
00:05:48,380 --> 00:05:49,213
Oh, you know what?

143
00:05:49,213 --> 00:05:50,610
Something really bad is going on.

144
00:05:50,610 --> 00:05:53,300
But if we can tie down
a pattern of behavior

145
00:05:53,300 --> 00:05:55,890
upon multiple hits, this will allow us

146
00:05:57,360 --> 00:05:59,283
after we conduct the data collection,

147
00:05:59,283 --> 00:06:01,340
to really dive in deeper

148
00:06:01,340 --> 00:06:05,210
and confirm whether there's a
malicious or benign activity.

149
00:06:05,210 --> 00:06:06,460
The second thing we're gonna be looking at

150
00:06:06,460 --> 00:06:08,120
is anomalous user activity.

151
00:06:08,120 --> 00:06:11,020
And this is gonna be things
like suspicious users logins.

152
00:06:11,020 --> 00:06:12,870
Because of course, if the user is not

153
00:06:13,880 --> 00:06:15,740
in front of their system
at a given point in time

154
00:06:15,740 --> 00:06:17,690
but they're conducting
some sort of activity,

155
00:06:17,690 --> 00:06:19,150
we're really going to wanna look into that

156
00:06:19,150 --> 00:06:20,099
quite a bit deeper.

157
00:06:21,510 --> 00:06:23,099
Last but not least, is gonna be our

158
00:06:23,100 --> 00:06:25,010
indicator of compromise information.

159
00:06:25,010 --> 00:06:26,909
And this can come from
a number of sources.

160
00:06:26,910 --> 00:06:28,960
This could be our threat intel feed data,

161
00:06:28,960 --> 00:06:31,320
whether it be commercially or open source.

162
00:06:31,320 --> 00:06:33,450
As well as things like
our sandbox analysis.

163
00:06:33,450 --> 00:06:35,000
So let's say, within your environment,

164
00:06:35,000 --> 00:06:37,550
you have things like
your phishing analysis

165
00:06:39,671 --> 00:06:44,300
or you have malware that's
identified on your end points,

166
00:06:44,300 --> 00:06:47,030
processed through an
internal or external sandbox.

167
00:06:47,030 --> 00:06:49,940
Taking that information and correlating it

168
00:06:49,940 --> 00:06:51,750
as part of your data collection process

169
00:06:51,750 --> 00:06:54,290
could also be of great value to you.

170
00:06:54,290 --> 00:06:55,840
So for the moment, we're gonna jump over

171
00:06:55,840 --> 00:06:57,440
to component three analysis

172
00:06:57,440 --> 00:07:00,660
and we're gonna jump into
alert remediation itself.

173
00:07:00,660 --> 00:07:03,040
So, what steps do we take to eradicate

174
00:07:03,040 --> 00:07:04,490
a threat from our environment?

175
00:07:04,490 --> 00:07:06,020
Depending on if this is a network threat

176
00:07:06,020 --> 00:07:08,030
or an endpoint threat,
we could be leveraging

177
00:07:08,030 --> 00:07:09,809
firewall blocks or we could
be leveraging something

178
00:07:09,810 --> 00:07:12,080
like automated re-imaging.

179
00:07:12,080 --> 00:07:13,919
Now let's say we have a critical asset

180
00:07:13,920 --> 00:07:16,440
within our environment
that has been compromised

181
00:07:16,440 --> 00:07:18,360
for one reason or another.

182
00:07:18,360 --> 00:07:19,750
Maybe we need to get approvals

183
00:07:19,750 --> 00:07:22,730
from business unit leaders or otherwise.

184
00:07:22,730 --> 00:07:25,870
And we can integrate as part
of the automation process,

185
00:07:25,870 --> 00:07:29,060
contacting those end
users, getting the approval

186
00:07:29,060 --> 00:07:30,957
and being able to initiate the next steps

187
00:07:30,957 --> 00:07:33,180
within the remediation process.

188
00:07:33,180 --> 00:07:35,290
Alternatively, let's say
within your organization,

189
00:07:35,290 --> 00:07:36,630
you don't have an automated

190
00:07:36,630 --> 00:07:39,270
re-imaging process for end points.

191
00:07:39,270 --> 00:07:42,700
So the next step in this
scenario would be contacting

192
00:07:42,700 --> 00:07:44,659
your service desk, your field team,

193
00:07:44,660 --> 00:07:47,160
whoever may be the end resource
within your organization

194
00:07:47,160 --> 00:07:48,730
that may be able to assist

195
00:07:48,730 --> 00:07:52,740
your end users in conducting
the remediation process.

196
00:07:52,740 --> 00:07:54,520
So now we're gonna jump
into the last component

197
00:07:54,520 --> 00:07:57,169
of this process and that's
really going to be the reporting.

198
00:07:57,170 --> 00:08:00,670
So some organizations do a
really great job at reporting,

199
00:08:00,670 --> 00:08:03,300
reporting their outcomes
to executive management

200
00:08:03,300 --> 00:08:05,016
down to their technical teams.

201
00:08:05,016 --> 00:08:08,420
And one of the things that
I find is when we leverage

202
00:08:08,420 --> 00:08:10,072
these automation frameworks

203
00:08:10,072 --> 00:08:13,240
and really dive into full
end to end automation,

204
00:08:13,240 --> 00:08:16,020
one of the things that we can
gain significant value out of

205
00:08:16,020 --> 00:08:19,652
is truly properly reporting
to all of the stakeholders.

206
00:08:20,500 --> 00:08:22,630
But one of the questions we
need to ask ourselves is;

207
00:08:22,630 --> 00:08:24,790
who needs to know what?

208
00:08:24,790 --> 00:08:26,470
So from a management perspective,

209
00:08:26,470 --> 00:08:27,880
when we're reporting to higher management

210
00:08:27,880 --> 00:08:30,710
or executive management, one
of the things that would be

211
00:08:30,710 --> 00:08:32,970
of great value to them is to report;

212
00:08:32,970 --> 00:08:35,200
what is the state of risk?

213
00:08:35,200 --> 00:08:36,270
What are the things that are being

214
00:08:36,270 --> 00:08:37,809
targeted with our organization?

215
00:08:37,809 --> 00:08:39,869
What are the things that we
need to be concerned about,

216
00:08:39,870 --> 00:08:43,020
based on what we're seeing
from these malicious actors?

217
00:08:43,020 --> 00:08:44,819
Are we seeing things like

218
00:08:44,820 --> 00:08:46,600
social engineering attempts,

219
00:08:46,600 --> 00:08:50,310
where we should be making
our end users more aware

220
00:08:50,310 --> 00:08:54,319
of potential communications
that may not be legitimate?

221
00:08:54,320 --> 00:08:56,930
Or we're seeing an increase
in phishing campaigns,

222
00:08:56,930 --> 00:08:58,810
with malware attached to them.

223
00:08:58,810 --> 00:09:02,020
So we want to implement some
further upstream controls

224
00:09:02,020 --> 00:09:03,720
or tightened existing controls

225
00:09:03,720 --> 00:09:05,720
to ensure that things don't get through.

226
00:09:06,960 --> 00:09:08,820
And secondly, findings of interests.

227
00:09:08,820 --> 00:09:11,550
So if there's very specific
things that may have occurred

228
00:09:11,550 --> 00:09:13,800
over the course of your reporting period,

229
00:09:13,800 --> 00:09:16,880
you may wanna communicate
those to your management.

230
00:09:16,880 --> 00:09:17,930
So moving down further,

231
00:09:17,930 --> 00:09:20,170
we're gonna talk about technical teams.

232
00:09:20,170 --> 00:09:22,709
And depending on how your team operates,

233
00:09:22,710 --> 00:09:25,000
this may work in a number of ways.

234
00:09:25,000 --> 00:09:26,830
On one hand, there are some organizations

235
00:09:26,830 --> 00:09:29,460
that report things like how many threats

236
00:09:29,460 --> 00:09:31,470
or how many systems have been remediated.

237
00:09:31,470 --> 00:09:33,880
And then on the other hand, you'll have

238
00:09:33,880 --> 00:09:36,110
situations where the
organization likes to focus

239
00:09:36,110 --> 00:09:37,970
on incidents of importance.

240
00:09:37,970 --> 00:09:40,140
This will be things like a threat actor

241
00:09:40,140 --> 00:09:42,060
and a given set of behaviors.

242
00:09:42,060 --> 00:09:44,680
So that your analysts, as
they're as they're going through

243
00:09:44,680 --> 00:09:46,780
these alerts on a day-to-day basis

244
00:09:46,780 --> 00:09:49,660
can take a look and maybe
potentially correlate

245
00:09:49,660 --> 00:09:53,319
to previous activities
and have a running start

246
00:09:53,320 --> 00:09:55,610
at what they're looking at
versus having to come up

247
00:09:55,610 --> 00:09:57,610
with a new hypothesis every single time.

248
00:09:58,760 --> 00:10:00,370
The last thing I have listed here

249
00:10:00,370 --> 00:10:04,090
and again, this depends on
the level of your security,

250
00:10:04,090 --> 00:10:07,030
security strategy and maturity

251
00:10:07,030 --> 00:10:10,100
is gonna be threat hunters
within your organization.

252
00:10:10,100 --> 00:10:11,730
So the things that they're
gonna be interested in

253
00:10:11,730 --> 00:10:13,750
is things like suspect findings.

254
00:10:13,750 --> 00:10:16,180
So the things that your
analysts have taken a look at,

255
00:10:16,180 --> 00:10:19,589
they've really dive deep into
it and they're not quite sure

256
00:10:19,590 --> 00:10:20,950
what may be the issue.

257
00:10:20,950 --> 00:10:22,536
They're not sure if it's malicious,

258
00:10:22,536 --> 00:10:23,699
they're not sure it's benign.

259
00:10:23,700 --> 00:10:25,680
Well, this is really
where your threat hunters

260
00:10:25,680 --> 00:10:28,603
can help out and and potentially
dive a little bit deeper.

261
00:10:30,020 --> 00:10:32,140
And another thing that
you want to potentially

262
00:10:32,140 --> 00:10:34,970
tie into that reporting is
the results of previous hunts

263
00:10:34,970 --> 00:10:37,890
that may have been conducted
by your threat hunting team.

264
00:10:37,890 --> 00:10:41,060
So if they've looked at a
specific type of activity

265
00:10:41,060 --> 00:10:43,449
and now we're seeing this type of activity

266
00:10:43,450 --> 00:10:44,840
actually taking place

267
00:10:45,980 --> 00:10:47,930
within our alerting and our environment,

268
00:10:47,930 --> 00:10:50,680
then maybe they wanna take
another look and go back and see,

269
00:10:50,680 --> 00:10:52,130
maybe is there something they missed?

270
00:10:52,130 --> 00:10:53,630
Or maybe there's something

271
00:10:53,630 --> 00:10:55,563
that they should look into further.

272
00:10:57,080 --> 00:10:59,650
So as I mentioned, we skipped
over the third component

273
00:10:59,650 --> 00:11:02,750
and that is automated alert analysis.

274
00:11:02,750 --> 00:11:07,540
Now, how do I leverage this
automation to analyze the data?

275
00:11:07,540 --> 00:11:09,620
Again, I'm breaking it
down to the five levels

276
00:11:09,620 --> 00:11:11,700
and we're gonna cover the
first three here today.

277
00:11:11,700 --> 00:11:14,810
And the first one is
singular indicator scoring.

278
00:11:14,810 --> 00:11:17,079
The second one is heuristic analysis.

279
00:11:17,080 --> 00:11:19,590
The third one is the
machine learning models.

280
00:11:19,590 --> 00:11:21,490
And two additional levels

281
00:11:21,490 --> 00:11:23,360
that we won't be covering here today

282
00:11:23,360 --> 00:11:26,980
are either leveraging single
purpose, deep learning models

283
00:11:26,980 --> 00:11:29,210
or leveraging a combination
of deep learning

284
00:11:29,210 --> 00:11:33,000
and machine learning models
for a neural net analysis.

285
00:11:33,000 --> 00:11:34,870
But let's jump right into the level one.

286
00:11:34,870 --> 00:11:36,080
And that's gonna be reviewing

287
00:11:36,080 --> 00:11:39,140
the manual analysis process
for indicator scoring.

288
00:11:39,140 --> 00:11:41,080
So as I mentioned earlier,

289
00:11:41,080 --> 00:11:43,440
if you have analysts looking at an alert,

290
00:11:43,440 --> 00:11:46,430
they see an indicator
and they go reach out

291
00:11:46,430 --> 00:11:47,930
and they try to take a look at

292
00:11:49,062 --> 00:11:51,380
what may be behind that indicator.

293
00:11:51,380 --> 00:11:53,500
So when we wanna look at that

294
00:11:53,500 --> 00:11:55,540
from an automation perspective,

295
00:11:55,540 --> 00:12:00,540
let's say we have a threat
intel hit, on an IP address.

296
00:12:01,080 --> 00:12:02,760
Well, so for every single
one of those searches

297
00:12:02,760 --> 00:12:04,810
that we're conducting as part of that

298
00:12:04,810 --> 00:12:06,900
intel analysis process,

299
00:12:06,900 --> 00:12:10,160
we can assign a static
or a weighted score.

300
00:12:10,160 --> 00:12:13,060
If something is malicious, we
can assign it a score of one.

301
00:12:13,060 --> 00:12:16,739
If something is benign, we
can assign it a score zero.

302
00:12:16,740 --> 00:12:18,500
Let's make that a little more complex now,

303
00:12:18,500 --> 00:12:20,470
with a sample scoring use case.

304
00:12:20,470 --> 00:12:22,440
So I'm gonna be using
Virustotal a few times

305
00:12:22,440 --> 00:12:24,870
for this presentation,
because I think it's most

306
00:12:24,870 --> 00:12:27,950
ubiquitously used across
the security industry

307
00:12:27,950 --> 00:12:30,590
for these kind of intel checks.

308
00:12:30,590 --> 00:12:33,303
And let's look specifically
at Virustotal's

309
00:12:34,253 --> 00:12:36,150
file and URL reputation.

310
00:12:36,150 --> 00:12:40,199
So let's say you're doing
a check on a file or a URL.

311
00:12:40,200 --> 00:12:41,610
When you do that in Virustotal,

312
00:12:41,610 --> 00:12:44,230
you get a number that indicates how many

313
00:12:44,230 --> 00:12:46,223
Virustotal detections have taken place.

314
00:12:47,070 --> 00:12:50,720
So for example, for each
one of those detections,

315
00:12:50,720 --> 00:12:53,300
if you have Virustotal detections over 20,

316
00:12:53,300 --> 00:12:55,469
let's say you'd give it
a value of four points.

317
00:12:55,470 --> 00:12:58,210
10 to 19, you give it a
value of three points.

318
00:12:58,210 --> 00:13:00,963
Or one to 10, you give
it a value of two points.

319
00:13:04,160 --> 00:13:05,920
How does that look in practice?

320
00:13:05,920 --> 00:13:09,150
So here I have an example
domain website; theme.com.

321
00:13:09,150 --> 00:13:12,560
And it's got a virus total
score of 9 out of 88.

322
00:13:12,560 --> 00:13:15,599
In that scoring model, we
give it an analysis value

323
00:13:15,600 --> 00:13:18,300
of two points because the
number of Virustotal detections

324
00:13:18,300 --> 00:13:20,060
is less than 10.

325
00:13:20,060 --> 00:13:22,410
So now that we know how
we're going to score

326
00:13:22,410 --> 00:13:25,863
the single indicator, what's the next step

327
00:13:25,863 --> 00:13:29,050
in this automated analysis process?

328
00:13:29,050 --> 00:13:31,209
And that's gonna be implementing
something along the lines

329
00:13:31,210 --> 00:13:33,540
of a heuristic analysis for scoring.

330
00:13:33,540 --> 00:13:37,010
What this allows us to do is
gather a collective scoring

331
00:13:37,010 --> 00:13:39,840
from each of those
individual indicator checks,

332
00:13:39,840 --> 00:13:41,933
to develop a finalized scoring output.

333
00:13:43,170 --> 00:13:45,040
As an example, let's say we're using

334
00:13:45,040 --> 00:13:48,599
that original methodology of
malicious gets a score of one,

335
00:13:48,600 --> 00:13:50,920
benign gets a score zero.

336
00:13:50,920 --> 00:13:54,430
So if the total malicious
hits is higher than five,

337
00:13:54,430 --> 00:13:56,439
so let's say we're looking
across all the indicators

338
00:13:56,440 --> 00:13:59,090
for a given alert and we
get more than five hits

339
00:14:00,519 --> 00:14:01,660
within that analysis,

340
00:14:01,660 --> 00:14:03,709
let's mark the entire alert as malicious.

341
00:14:04,710 --> 00:14:07,560
On the other hand, if
the total number of hits

342
00:14:07,560 --> 00:14:10,010
is less than five for
the primary indicator

343
00:14:10,010 --> 00:14:12,540
and more than zero for
a secondary indicator,

344
00:14:12,540 --> 00:14:15,079
maybe we wanna mark that
alert for manual review.

345
00:14:15,080 --> 00:14:18,760
And what we mean here by primary
versus secondary indicator,

346
00:14:18,760 --> 00:14:20,600
primary indicator is
gonna be that first thing

347
00:14:20,600 --> 00:14:22,930
that's really coming
out to you and saying;

348
00:14:22,930 --> 00:14:24,569
this is a potential issue.

349
00:14:24,570 --> 00:14:27,290
Whereas your secondary indicator
is going to be the things

350
00:14:27,290 --> 00:14:29,550
that have occurred afterwards,

351
00:14:29,550 --> 00:14:32,770
that we are tying back
to the first occurrence

352
00:14:32,770 --> 00:14:34,319
that set off our initial alert.

353
00:14:35,340 --> 00:14:37,500
Now, one of the very important
things you're gonna wanna do

354
00:14:37,500 --> 00:14:40,100
in this process, and that's
why we're gonna cover

355
00:14:40,100 --> 00:14:42,360
not just using zeros and ones per se,

356
00:14:42,360 --> 00:14:44,560
is you wanna be able to balance for trust.

357
00:14:44,560 --> 00:14:46,959
So if you have a source of information

358
00:14:46,960 --> 00:14:49,360
that is known to provide
a reliable outcome

359
00:14:49,360 --> 00:14:53,230
or reliable data, you
wanna be able to increase

360
00:14:53,230 --> 00:14:55,160
and decrease that scoring accordingly.

361
00:14:55,160 --> 00:14:57,569
So let's say you have
a commercial intel feed

362
00:14:57,570 --> 00:15:00,550
that you feel provides you a lot of value,

363
00:15:00,550 --> 00:15:04,099
make sure that you can
increase the scoring on that

364
00:15:04,100 --> 00:15:06,590
so that if it sees a threat,

365
00:15:06,590 --> 00:15:09,530
it is automatically escalated
to you much more quickly

366
00:15:09,530 --> 00:15:10,923
compared to let's say,

367
00:15:12,035 --> 00:15:13,985
a lower fidelity source of information.

368
00:15:15,860 --> 00:15:18,570
So diving into this a little further,

369
00:15:18,570 --> 00:15:21,000
let's look at a detailed scoring use case.

370
00:15:21,000 --> 00:15:22,713
And for this example, we're gonna use

371
00:15:22,713 --> 00:15:25,599
Virustotal's domain reputation.

372
00:15:25,600 --> 00:15:28,520
And here I have outlined
a number of the various

373
00:15:28,520 --> 00:15:30,680
checks that Virustotal conducts

374
00:15:30,680 --> 00:15:33,532
as part of these detailed
domain reputation checks.

375
00:15:34,600 --> 00:15:36,370
They leverage a number of vendors

376
00:15:36,370 --> 00:15:38,570
and this is an example of that scoring.

377
00:15:38,570 --> 00:15:40,963
So I'm just gonna pull out a few here.

378
00:15:42,650 --> 00:15:46,250
For Webutation, there's
an info.verdict value.

379
00:15:46,250 --> 00:15:48,010
And if that value is set to malicious,

380
00:15:48,010 --> 00:15:50,730
maybe we assign it a score of five points.

381
00:15:50,730 --> 00:15:54,470
We look at trend micro-categories
and it has a category

382
00:15:54,470 --> 00:15:58,480
that we believe is of significant concern.

383
00:15:58,480 --> 00:16:00,680
We can also assign a score of five points

384
00:16:00,680 --> 00:16:02,680
or three points depending on what it is.

385
00:16:03,520 --> 00:16:07,130
Or if we look at things
like at the end here,

386
00:16:07,130 --> 00:16:09,930
Webutation domain and info.safety score.

387
00:16:09,930 --> 00:16:12,040
If it's greater than 50,

388
00:16:12,040 --> 00:16:13,170
let's give it 10 points.

389
00:16:13,170 --> 00:16:16,510
If it's less than 50,
let's give it five points.

390
00:16:16,510 --> 00:16:19,550
So this is a lot of
information, but let's see

391
00:16:19,550 --> 00:16:22,402
how that actually boils down
into an example use case.

392
00:16:23,810 --> 00:16:26,760
So in this example, we're gonna use

393
00:16:26,760 --> 00:16:31,010
a scoring greater than 20, lets
mark the alert as malicious.

394
00:16:31,010 --> 00:16:33,310
Less than 20, let's mark
the alert has benign.

395
00:16:34,220 --> 00:16:38,140
So let's say we have a
domain, malicious sample.io.

396
00:16:38,140 --> 00:16:41,510
And for this domain, we have three hits.

397
00:16:41,510 --> 00:16:44,350
And the first one being threat
secret categories Botnet.

398
00:16:44,350 --> 00:16:46,730
So we assign it a value of 10 points.

399
00:16:46,730 --> 00:16:51,160
Webutation domain info.safety score is 73.

400
00:16:51,160 --> 00:16:53,430
We assign that a value of 10 points.

401
00:16:53,430 --> 00:16:56,160
And then let's say we seek

402
00:16:57,756 --> 00:16:59,050
the secondary source of information

403
00:16:59,050 --> 00:17:01,569
and the domain appears
on the phish tank list.

404
00:17:01,570 --> 00:17:04,510
So let's assign that a
value of five points.

405
00:17:04,510 --> 00:17:07,010
In total, we have an
alert total of 25 points,

406
00:17:07,010 --> 00:17:09,800
which is greater than the 20
point threshold that we've set.

407
00:17:09,800 --> 00:17:11,260
And therefore, in this scenario,

408
00:17:11,260 --> 00:17:14,173
we could mark this particular
alert as malicious.

409
00:17:15,290 --> 00:17:18,450
So now that we have defined

410
00:17:18,450 --> 00:17:21,310
everything from a single indicator check

411
00:17:21,310 --> 00:17:24,290
to combining a series of
single indicator checks,

412
00:17:24,290 --> 00:17:26,690
to conduct as a heuristic analysis,

413
00:17:26,690 --> 00:17:28,510
how can we tie all that data into actually

414
00:17:28,510 --> 00:17:30,310
leveraging a machine learning model?

415
00:17:33,360 --> 00:17:36,350
Let's use a very, very
basic example and say;

416
00:17:36,350 --> 00:17:40,562
test.com has a score of zero
in our initial analysis.

417
00:17:41,720 --> 00:17:45,640
Well, what other metadata
could we potentially leverage

418
00:17:45,640 --> 00:17:47,530
to gather further context

419
00:17:47,530 --> 00:17:51,060
on whether or not may
be malicious or benign?

420
00:17:51,060 --> 00:17:53,710
Well, we can look at things
like the geolocation.

421
00:17:53,710 --> 00:17:55,660
We can look at the IP range.

422
00:17:55,660 --> 00:17:56,700
We can look at the frequency

423
00:17:56,700 --> 00:17:58,950
the site is visited in your network.

424
00:17:58,950 --> 00:18:01,010
We can look at its site ranking.

425
00:18:01,010 --> 00:18:03,210
And if you really wanna get
creative, one of the examples

426
00:18:03,210 --> 00:18:06,110
I have listed here, is how
often does a given domain,

427
00:18:06,110 --> 00:18:10,879
IP, URL appear within your
corporate files or documents?

428
00:18:10,880 --> 00:18:14,033
So once again, let's say
we're taking that domain.

429
00:18:15,060 --> 00:18:17,970
How do we actually train
and develop a model

430
00:18:17,970 --> 00:18:19,653
that ties into that value?

431
00:18:21,170 --> 00:18:23,040
What we're gonna do is we're
gonna take the data set

432
00:18:23,040 --> 00:18:26,332
of the things that you've
conducted previously.

433
00:18:26,333 --> 00:18:28,860
You've done your single indicator checks.

434
00:18:28,860 --> 00:18:30,659
You've conducted a heuristic analysis

435
00:18:30,660 --> 00:18:32,090
and developed the final scoring

436
00:18:32,090 --> 00:18:35,783
for each of those alerts that
you've processed historically.

437
00:18:36,770 --> 00:18:38,960
So we take that data set.

438
00:18:38,960 --> 00:18:43,100
We take that metadata that we mentioned

439
00:18:43,100 --> 00:18:45,620
and we start inputting that
data into a training set

440
00:18:45,620 --> 00:18:47,360
for your machine learning model.

441
00:18:47,360 --> 00:18:51,219
So the example I have outlined
here is sample.security.

442
00:18:51,220 --> 00:18:52,933
It was added on a certain day.

443
00:18:53,920 --> 00:18:57,933
It's been searched by our
analysts or automations 31 times.

444
00:18:59,030 --> 00:19:04,030
That domain resolves to
an IP address in ASN 8402.

445
00:19:04,590 --> 00:19:08,090
There are three corporate
findings within our organization.

446
00:19:08,090 --> 00:19:10,503
It has a geographic mapping of Russia.

447
00:19:12,670 --> 00:19:14,830
Based on this information

448
00:19:14,830 --> 00:19:17,439
and historical analysis of this indicator,

449
00:19:17,440 --> 00:19:20,093
we've given it a mouse score of 0.575.

450
00:19:21,780 --> 00:19:24,510
So, that's a single example

451
00:19:24,510 --> 00:19:27,040
but how do I use that to then

452
00:19:27,040 --> 00:19:28,860
integrate into a machine learning model

453
00:19:28,860 --> 00:19:30,842
and analyze the next thing?

454
00:19:33,540 --> 00:19:35,970
Once we use a model based
on these parameters,

455
00:19:35,970 --> 00:19:37,650
we're able to provide the new model

456
00:19:37,650 --> 00:19:39,200
or we're able to provide this new model

457
00:19:39,200 --> 00:19:41,570
or a completely random domain

458
00:19:41,570 --> 00:19:43,450
with the corresponding indicator values,

459
00:19:43,450 --> 00:19:45,650
with the corresponding metadata.

460
00:19:45,650 --> 00:19:48,800
And once that data is inputted,
the model will generate

461
00:19:48,800 --> 00:19:50,840
a malicious analysis score

462
00:19:50,840 --> 00:19:53,659
without the need for
any external analysis.

463
00:19:53,660 --> 00:19:58,110
So here we have another
example of bad domain.space.

464
00:19:58,110 --> 00:19:59,979
It was found a little bit later.

465
00:19:59,980 --> 00:20:02,780
We've never searched for
it within our organization.

466
00:20:02,780 --> 00:20:06,430
But, sorry, we've never searched
for in our organization.

467
00:20:06,430 --> 00:20:08,500
We've never had a corporate finding

468
00:20:08,500 --> 00:20:13,500
for that indicator, but it
sits within the same ASN space

469
00:20:13,500 --> 00:20:16,340
and it sits within the
same geographic region.

470
00:20:16,340 --> 00:20:19,399
Well, we have an overall malicious score

471
00:20:19,400 --> 00:20:21,890
that's lower at a 0.376.

472
00:20:21,890 --> 00:20:26,220
But it gives us a nice base
for us to be able to then take

473
00:20:26,220 --> 00:20:29,480
that external analysis that we can perform

474
00:20:30,370 --> 00:20:33,870
and actually raise or lower
the overall threat value

475
00:20:33,870 --> 00:20:35,463
to us as an organization.

476
00:20:36,550 --> 00:20:39,070
So let's say bad domain.space doesn't hit

477
00:20:39,070 --> 00:20:41,710
on any external indicators,

478
00:20:41,710 --> 00:20:46,710
but we know through our
historic alert history

479
00:20:47,300 --> 00:20:48,863
that within our organization,

480
00:20:50,145 --> 00:20:53,440
the place that hosts bad domain.space

481
00:20:53,440 --> 00:20:57,400
is something we've actually
seen targeting our organization.

482
00:20:57,400 --> 00:21:00,100
This may be a good scenario
where you send it over

483
00:21:00,100 --> 00:21:02,600
to an analyst for further manual review,

484
00:21:02,600 --> 00:21:05,679
but depending on how you're
able to develop this out,

485
00:21:05,680 --> 00:21:07,440
you may be able to get to a point

486
00:21:07,440 --> 00:21:09,580
where this specific indicator check

487
00:21:09,580 --> 00:21:12,689
may be all you need to
then pursue remediation.

488
00:21:12,690 --> 00:21:14,360
Again, it depends on the level of comfort

489
00:21:14,360 --> 00:21:16,370
within your organization.

490
00:21:16,370 --> 00:21:18,179
But I can tell you from
personal experience,

491
00:21:18,180 --> 00:21:19,780
it's one of those things that over time,

492
00:21:19,780 --> 00:21:21,100
you're just gonna notice the patterns

493
00:21:21,100 --> 00:21:22,909
and you're gonna be able to leverage it,

494
00:21:22,910 --> 00:21:24,300
to provide a lot of value

495
00:21:24,300 --> 00:21:26,490
before you even get to the next steps.

496
00:21:26,490 --> 00:21:29,250
So now let's jump into tuning
the automations themselves.

497
00:21:29,250 --> 00:21:30,500
And one of the most important things

498
00:21:30,500 --> 00:21:32,560
you're gonna wanna
focus on is tuning based

499
00:21:32,560 --> 00:21:35,720
on the organization's risk
and disruption tolerances.

500
00:21:35,720 --> 00:21:37,360
For example, if no risk is acceptable

501
00:21:37,360 --> 00:21:38,790
within your organization,

502
00:21:38,790 --> 00:21:40,822
tune the automation towards remediation.

503
00:21:41,700 --> 00:21:43,290
If on the other hand,

504
00:21:43,290 --> 00:21:46,220
the disruption tolerance is not preferred

505
00:21:46,220 --> 00:21:49,760
within your organization,
then maybe you need to shift

506
00:21:49,760 --> 00:21:52,640
to more manual review if
something is discovered

507
00:21:53,830 --> 00:21:56,090
as part of these automation processes.

508
00:21:56,090 --> 00:21:57,370
So the next thing we're gonna cover is,

509
00:21:57,370 --> 00:22:00,219
don't worry if you're not 100% automated.

510
00:22:00,220 --> 00:22:02,380
This is a really nice
target but the reality is,

511
00:22:02,380 --> 00:22:03,880
it's not particularly realistic,

512
00:22:03,880 --> 00:22:05,670
especially when you're starting off.

513
00:22:05,670 --> 00:22:07,020
So make sure that you leverage things

514
00:22:07,020 --> 00:22:08,860
like manual validation checks,

515
00:22:08,860 --> 00:22:10,459
where you deem it to be prudent.

516
00:22:11,370 --> 00:22:14,060
And lastly and most importantly,

517
00:22:14,060 --> 00:22:16,250
make sure to collect
that statistical data.

518
00:22:16,250 --> 00:22:17,930
Because as you start
developing these things

519
00:22:17,930 --> 00:22:21,150
like this heuristic analysis,
the machine learning models,

520
00:22:21,150 --> 00:22:22,930
this data is gonna be paramount

521
00:22:22,930 --> 00:22:26,343
to be able to deliver you a
nice base to start off from.

522
00:22:27,560 --> 00:22:30,050
So now that we've covered

523
00:22:30,050 --> 00:22:33,070
where we can go with automating

524
00:22:33,070 --> 00:22:35,280
all of these steps of the process,

525
00:22:35,280 --> 00:22:37,629
how do we calculate the
return of investment

526
00:22:37,630 --> 00:22:39,820
that we're getting from
creating, developing

527
00:22:39,820 --> 00:22:43,020
and integrating these automations?

528
00:22:43,020 --> 00:22:45,100
So the first thing is,
you're gonna wanna document

529
00:22:45,100 --> 00:22:46,449
the steps of your workflow.

530
00:22:47,670 --> 00:22:50,900
This will allow you to understand
what's actually involved

531
00:22:50,900 --> 00:22:53,180
in the automations that you're creating.

532
00:22:53,180 --> 00:22:54,500
Determine the amount of time needed

533
00:22:54,500 --> 00:22:56,290
to manually complete each step.

534
00:22:56,290 --> 00:22:58,190
So of course, as we covered
at the very beginning

535
00:22:58,190 --> 00:22:59,220
of the presentation,

536
00:22:59,220 --> 00:23:01,800
level one is completely manual processing.

537
00:23:01,800 --> 00:23:04,889
So if someone is taking
in, by hand, that alert

538
00:23:04,890 --> 00:23:06,900
and they're conducting
every single automate

539
00:23:06,900 --> 00:23:08,410
or every single thing that you would have

540
00:23:08,410 --> 00:23:10,973
within your automation,
step-by-step, manually.

541
00:23:11,900 --> 00:23:14,400
So determine how much time that takes.

542
00:23:14,400 --> 00:23:15,290
The next thing you can do

543
00:23:15,290 --> 00:23:17,690
is use a normalized salary to calculate

544
00:23:20,242 --> 00:23:21,566
how much time each one of these

545
00:23:21,566 --> 00:23:24,210
automations takes to complete.

546
00:23:24,210 --> 00:23:26,350
So of course, when you have an automation,

547
00:23:26,350 --> 00:23:28,889
you don't really need to
factor in things like downtime

548
00:23:28,890 --> 00:23:30,990
unless your organization chooses to do so.

549
00:23:32,370 --> 00:23:34,639
Next thing you can do is
document the time needed

550
00:23:34,640 --> 00:23:38,050
to complete that action using automation.

551
00:23:38,050 --> 00:23:41,450
And lastly, you're gonna want
to take all that information

552
00:23:41,450 --> 00:23:43,600
regarding the automation
and how much it takes

553
00:23:43,600 --> 00:23:45,510
or how long it takes to do manually

554
00:23:45,510 --> 00:23:47,020
and compare the time and cost

555
00:23:47,020 --> 00:23:49,483
between manual and automated processing.

556
00:23:50,320 --> 00:23:53,659
All right, so let's dive in and
let me cover real quick here

557
00:23:53,660 --> 00:23:56,320
how that actually looked
like in our organization.

558
00:23:56,320 --> 00:23:58,023
So at the end of 2017,

559
00:23:59,102 --> 00:24:00,550
we focused on the very basics

560
00:24:00,550 --> 00:24:05,230
and that was about 50 to 100
of these automated events a day

561
00:24:05,230 --> 00:24:07,560
with about five active playbooks.

562
00:24:07,560 --> 00:24:09,260
We had a pretty decent
return on investment

563
00:24:09,260 --> 00:24:10,943
of up to $75,000.

564
00:24:12,250 --> 00:24:14,951
When we got to 2019, we really
wanted to close the loop

565
00:24:14,951 --> 00:24:17,520
on that initial development of the base

566
00:24:17,520 --> 00:24:19,660
of our automation strategy.

567
00:24:19,660 --> 00:24:22,470
So at that point, we had
about 25 active playbooks

568
00:24:22,470 --> 00:24:24,290
and that really allowed
us to get to a point

569
00:24:24,290 --> 00:24:26,050
where we were processing about 25,000

570
00:24:26,050 --> 00:24:27,669
of these automated events a day.

571
00:24:27,670 --> 00:24:30,330
Now of course, just so we're
clear, that doesn't mean

572
00:24:30,330 --> 00:24:31,899
that someone within the security team

573
00:24:31,900 --> 00:24:34,360
was looking at 25,000 alerts a day.

574
00:24:34,360 --> 00:24:38,370
What that means is that
25,000 things were processed.

575
00:24:38,370 --> 00:24:40,469
And then the person who
is actually receiving

576
00:24:40,470 --> 00:24:43,180
the information was only responsible

577
00:24:43,180 --> 00:24:46,520
for reviewing five, 10, 15, 20 things.

578
00:24:46,520 --> 00:24:50,420
Which obviously lowers
the burden on your analyst

579
00:24:50,420 --> 00:24:53,220
and at the end of the day,
the analyst was presented

580
00:24:53,220 --> 00:24:55,170
with much more interesting information.

581
00:24:56,650 --> 00:25:00,370
Now we're moving towards
here, towards the end of 2021

582
00:25:00,370 --> 00:25:03,362
is really scaling those existing
automation capabilities.

583
00:25:04,210 --> 00:25:07,500
We're on deck for about
41 active playbooks.

584
00:25:07,500 --> 00:25:10,590
And this should allow us
to process about 100,000

585
00:25:10,590 --> 00:25:12,163
automated events per day.

586
00:25:13,490 --> 00:25:17,540
So as I noted at the bottom,
because I have ROI values here.

587
00:25:17,540 --> 00:25:19,270
But really after phase one,

588
00:25:19,270 --> 00:25:23,030
ROI from a monetary
perspective is not completely

589
00:25:23,030 --> 00:25:25,180
an applicable metric
because at this point,

590
00:25:25,180 --> 00:25:28,200
you're effectively
developing applications.

591
00:25:28,200 --> 00:25:32,050
But because I want to
provide a nice sample set

592
00:25:32,050 --> 00:25:33,389
across the timeline,

593
00:25:33,390 --> 00:25:35,773
I've included it for your consideration.

594
00:25:38,610 --> 00:25:40,379
Now that we've covered
all this information,

595
00:25:40,380 --> 00:25:42,930
how do I implement this in my environment?

596
00:25:42,930 --> 00:25:46,070
So over the next 30 days,
you could try to validate

597
00:25:46,070 --> 00:25:48,620
your existing manual IR processes.

598
00:25:48,620 --> 00:25:50,610
If you're holding this
as tribal knowledge,

599
00:25:50,610 --> 00:25:51,939
you may wanna start documenting out

600
00:25:51,940 --> 00:25:53,223
what those processes are.

601
00:25:54,070 --> 00:25:57,950
But once you've completed
the validation process,

602
00:25:57,950 --> 00:26:01,510
develop your first single or
heuristic scoring algorithm.

603
00:26:01,510 --> 00:26:04,250
So I've outlined a few
samples in this presentation.

604
00:26:04,250 --> 00:26:06,970
But really you're gonna
wanna tailor and drive it to;

605
00:26:06,970 --> 00:26:09,540
what matters to your organization?

606
00:26:09,540 --> 00:26:12,790
If you're focusing more on
fraud, you may be more interested

607
00:26:12,790 --> 00:26:16,030
in looking at fraud-based
detections and scoring.

608
00:26:16,030 --> 00:26:18,055
If you're looking at things like

609
00:26:18,055 --> 00:26:20,600
malicious threat actors,

610
00:26:20,600 --> 00:26:22,570
commercial and open
source threat intel feeds

611
00:26:22,570 --> 00:26:25,780
may likely be able to
assist you in that process.

612
00:26:25,780 --> 00:26:27,250
So after you've developed your single

613
00:26:27,250 --> 00:26:29,960
or heuristic scoring algorithm,
you're gonna wanna validate

614
00:26:29,960 --> 00:26:32,760
your scoring efficacy
using manual analysis.

615
00:26:32,760 --> 00:26:34,620
So basically what you're
gonna be doing here,

616
00:26:34,620 --> 00:26:36,879
is you're gonna be running
through a series of alerts

617
00:26:36,880 --> 00:26:39,600
completely manually and you're
gonna run through a series

618
00:26:39,600 --> 00:26:41,820
of alerts, those same alerts,

619
00:26:41,820 --> 00:26:43,960
leveraging your automated analysis.

620
00:26:43,960 --> 00:26:46,780
Do a comparison between between the two

621
00:26:46,780 --> 00:26:49,800
and if they're generally
on the same level,

622
00:26:49,800 --> 00:26:51,149
you can move forward to developing

623
00:26:51,150 --> 00:26:52,883
your first machine learning model.

624
00:26:54,050 --> 00:26:56,070
Once you develop your
machine learning model,

625
00:26:56,070 --> 00:26:58,530
one of the very important
things you're gonna want to do

626
00:26:58,530 --> 00:27:01,000
is between your training, your testing

627
00:27:01,000 --> 00:27:03,890
and your production sets,
conduct a back test of that model

628
00:27:03,890 --> 00:27:05,870
against your pre automation data sets

629
00:27:05,870 --> 00:27:07,929
if you have them available.

630
00:27:07,930 --> 00:27:09,980
So as I mentioned earlier
in the presentation,

631
00:27:09,980 --> 00:27:12,090
the earlier you can start documenting

632
00:27:12,090 --> 00:27:15,080
the alerts, the events, the metadata

633
00:27:15,080 --> 00:27:18,230
and collecting that for future analysis,

634
00:27:18,230 --> 00:27:21,400
the better chance you have of developing

635
00:27:21,400 --> 00:27:24,543
this machine learning model
quickly and effectively.

636
00:27:26,090 --> 00:27:28,570
At this point, I thank you
everyone for your time.

637
00:27:28,570 --> 00:27:30,266
And I'll be sticking around
for any questions you may have

638
00:27:30,267 --> 00:27:32,563
in the Q and A, thank you.

