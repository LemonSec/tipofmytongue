1
00:00:00,000 --> 00:00:02,310
hello everyone they went from the vein and I

2
00:00:02,310 --> 00:00:08,250
present to you wiki data and linke data ok what is

3
00:00:08,250 --> 00:00:10,920
wiki data wiki data

4
00:00:10,920 --> 00:00:13,200
let's say a fondation leaflet that

5
00:00:13,200 --> 00:00:16,139
aims to move from single

6
00:00:16,139 --> 00:00:19,020
text wikis to a single database with

7
00:00:19,020 --> 00:00:20,640
information collected in a

8
00:00:20,640 --> 00:00:21,930
structured way then  like the other

9
00:00:21,930 --> 00:00:23,310
wiki projects it is free

10
00:00:23,310 --> 00:00:26,130
here is the extra work is committed suicide

11
00:00:26,130 --> 00:00:27,660
encouraged collaboration

12
00:00:27,660 --> 00:00:29,189
by bots therefore the tools I

13
00:00:29,189 --> 00:00:33,270
found information is multilingual so

14
00:00:33,270 --> 00:00:35,370
unlike the individual wikio of commons

15
00:00:35,370 --> 00:00:38,190
drawn up collectively there is a single wiki

16
00:00:38,190 --> 00:00:41,300
given for all  languages and

17
00:00:41,300 --> 00:00:43,379
information are addressed so there is

18
00:00:43,379 --> 00:00:45,270
a source for each information or information frameworks

19
00:00:45,270 --> 00:00:48,840
are structured and the idea

20
00:00:48,840 --> 00:00:50,550
of myths given at least first moment

21
00:00:50,550 --> 00:00:51,750
is to support the

22
00:00:51,750 --> 00:00:53,550
individual so avoid side boxes

23
00:00:53,550 --> 00:00:55,710
you see in the guides in theory to curtains  to

24
00:00:55,710 --> 00:00:59,399
be all made with information that

25
00:00:59,399 --> 00:01:03,690
comes from wiki data as

26
00:01:03,690 --> 00:01:05,339
structured vicky data let's say that the

27
00:01:05,339 --> 00:01:10,470
center of g data is the p the ent  ity a

28
00:01:10,470 --> 00:01:12,630
qu is a concept let's say a concept

29
00:01:12,630 --> 00:01:15,210
this is a person in case a famous

30
00:01:15,210 --> 00:01:17,580
Italian politician or it can be

31
00:01:17,580 --> 00:01:18,550


32
00:01:18,550 --> 00:01:20,950
anything else a war a battle

33
00:01:20,950 --> 00:01:24,700
rather than a language and in this

34
00:01:24,700 --> 00:01:27,700
case in the case of the politician and this to

35
00:01:27,700 --> 00:01:29,590
be agnostic from points if  the language

36
00:01:29,590 --> 00:01:31,930
is called quantified va unique

37
00:01:31,930 --> 00:01:35,970
therefore iq and then a number are assigned

38
00:01:35,970 --> 00:01:41,440
of the torn entities of the languages and

39
00:01:41,440 --> 00:01:42,870
this is the most interesting part

40
00:01:42,870 --> 00:01:46,030
because there are properties every

41
00:01:46,030 --> 00:01:48,130
entity skyrocketing properties and this life

42
00:01:48,130 --> 00:01:50,490
of objects

43
00:01:50,770 --> 00:01:52,660
so in this case ilona staller is

44
00:01:52,660 --> 00:01:55,000
a  'instance of human human in turn

45
00:01:55,000 --> 00:01:57,280
identity and therefore to references

46
00:01:57,280 --> 00:01:59,320
let's say that in this way you can

47
00:01:59,320 --> 00:02:01,330
hook one entity to another that you have

48
00:02:01,330 --> 00:02:04,480
structured data in particular what

49
00:02:04,480 --> 00:02:07,030
the references mean means that

50
00:02:07,030 --> 00:02:08,649
for each property there are

51
00:02:08,649 --> 00:02:10,780
so-called qualifiers  and

52
00:02:10,780 --> 00:02:12,730
qualifier symbols we say that they go to give

53
00:02:12,730 --> 00:02:15,190
more information about the entity in the

54
00:02:15,190 --> 00:02:16,960
specific case ilona staller was a

55
00:02:16,960 --> 00:02:22,360
ca  Many years ago 1976 and 1989 and instead

56
00:02:22,360 --> 00:02:24,400
in the case of a politician there is no

57
00:02:24,400 --> 00:02:26,560
reference instead she was a film actress

58
00:02:26,560 --> 00:02:26,950


59
00:02:26,950 --> 00:02:30,040
according to the second engineer according to the source

60
00:02:30,040 --> 00:02:35,760
of the wii you see yourself English and let's say that

61
00:02:35,760 --> 00:02:38,590
committed suicide that continues to become there

62
00:02:38,590 --> 00:02:41,260
are no  only newborn entities a

63
00:02:41,260 --> 00:02:43,090
new type of entity for those who

64
00:02:43,090 --> 00:02:45,640
linguistically test these dreams the seeds is a

65
00:02:45,640 --> 00:02:49,180
new type of ta but I fly over but if you are

66
00:02:49,180 --> 00:02:51,030
interested in an interesting idea

67
00:02:51,030 --> 00:02:53,890
what is the use of this type of database

68
00:02:53,890 --> 00:02:55,840
so large so generalist that it aggregates

69
00:02:55,840 --> 00:02:57,900
practically every cultural dress  human

70
00:02:57,900 --> 00:03:01,000
any type of project can be

71
00:03:01,000 --> 00:03:02,890
betrayed type of project you can stay the

72
00:03:02,890 --> 00:03:04,810
names of people lists of goats that

73
00:03:04,810 --> 00:03:07,330
have lived in the world the

74
00:03:07,330 --> 00:03:09,400
interesting part are the

75
00:03:09,400 --> 00:03:11,200
taxonomy stations classifications because from which they

76
00:03:11,200 --> 00:03:13,270
are structured therefore selection of

77
00:03:13,270 --> 00:03:14,890
my specific skeins in a

78
00:03:14,890 --> 00:03:16,810
specific field  that to the skilled that through a

79
00:03:16,810 --> 00:03:19,739
query on yahoo.it data you can extract it

80
00:03:19,739 --> 00:03:22,030
possible to make bizarre queries such as

81
00:03:22,030 --> 00:03:23,280
the distribution of c  eye color

82
00:03:23,280 --> 00:03:26,890
why can i do i can ask what

83
00:03:26,890 --> 00:03:28,510
are the eye colors of all

84
00:03:28,510 --> 00:03:29,100
those

85
00:03:29,100 --> 00:03:31,470
are inscribed on wiki data since wiki

86
00:03:31,470 --> 00:03:33,090
data was born very recently it was

87
00:03:33,090 --> 00:03:34,830
possible to see for this query that the

88
00:03:34,830 --> 00:03:37,320
color of the eyes has gone from 50 to 50

89
00:03:37,320 --> 00:03:40,950
dark blues in reality  over time to

90
00:03:40,950 --> 00:03:42,450
see that dark complained more and more

91
00:03:42,450 --> 00:03:44,520
because the data has increased and therefore the

92
00:03:44,520 --> 00:03:47,040
buyer's of 9 or

93
00:03:47,040 --> 00:03:50,910
American people has decreased and the color for the

94
00:03:50,910 --> 00:03:52,110
dysfunction in mind closest to

95
00:03:52,110 --> 00:03:55,920
the real one and other interesting are

96
00:03:55,920 --> 00:03:58,950
for example is a list  of cities with

97
00:03:58,950 --> 00:04:00,420
female mayor tiers per inhabitants

98
00:04:00,420 --> 00:04:01,740
usually this information is not

99
00:04:01,740 --> 00:04:04,140
contained in a single database

100
00:04:04,140 --> 00:04:06,120
instead here it is possible among these

101
00:04:06,120 --> 00:04:08,130
those that cross multiple areas and more

102
00:04:08,130 --> 00:04:10,370
aspects

103
00:04:10,830 --> 00:04:13,860
this is that point therefore given

104
00:04:13,860 --> 00:04:15,870
org point that we say and interface of those

105
00:04:15,870 --> 00:04:19,649
doubts that  data visual and helps you a lot

106
00:04:19,649 --> 00:04:23,100
in the queries I will gloss over this

107
00:04:23,100 --> 00:04:23,550
interface

108
00:04:23,550 --> 00:04:26,600
but interesting thing is that while the

109
00:04:26,600 --> 00:04:29,790
infrastructure refuses  te based on a

110
00:04:29,790 --> 00:04:32,520
relational database and one is

111
00:04:32,520 --> 00:04:33,660
also exposed in point sparkle

112
00:04:33,660 --> 00:04:35,790
what is a bit in sparkle sparkle the

113
00:04:35,790 --> 00:04:37,560
language of which and retail in what date

114
00:04:37,560 --> 00:04:40,530
they are let's say in the way you

115
00:04:40,530 --> 00:04:41,970
insert wiki date through this in

116
00:04:41,970 --> 00:04:46,050
point then the link is  data are based on

117
00:04:46,050 --> 00:04:47,640
a particular stylization front that

118
00:04:47,640 --> 00:04:51,450
rdf pdf a data activation format

119
00:04:51,450 --> 00:04:54,780
that atomic and is based first

120
00:04:54,780 --> 00:04:57,840
of all on urri then each entity to

121
00:04:57,840 --> 00:05:01,470
a unique identifier typically a

122
00:05:01,470 --> 00:05:03,420
web address because the domain has

123
00:05:03,420 --> 00:05:06,060
marked a person and let's say that in 30

124
00:05:06,060 --> 00:05:07,650
domain 1 and manages pad so it is

125
00:05:07,650 --> 00:05:12,810
let's say unique and through these walls

126
00:05:12,810 --> 00:05:15,210
and if there are 30 versions and between

127
00:05:15,210 --> 00:05:18,170
entities it is dated

128
00:05:18,170 --> 00:05:23,130
and raw data then string the numbers the

129
00:05:23,130 --> 00:05:25,980
knowledge io pata in triples so it is

130
00:05:25,980 --> 00:05:27,870
as if it were all dedicated sentences the

131
00:05:27,870 --> 00:05:33,150
subject predicate  object and this type

132
00:05:33,150 --> 00:05:34,530
of sentence structure of then of

133
00:05:34,530 --> 00:05:36,360
directional relations that is furie

134
00:05:36,360 --> 00:05:40,860
ntato then we can see represented

135
00:05:40,860 --> 00:05:44,250
for example is the entity bob is  interested

136
00:05:44,250 --> 00:05:46,290
in lenta monna lisa who has a creator

137
00:05:46,290 --> 00:05:49,470
that liarda entity wins but a slow bob

138
00:05:49,470 --> 00:05:51,300
also associated with himself through

139
00:05:51,300 --> 00:05:53,970
an athlete a number a a string that

140
00:05:53,970 --> 00:05:56,580
is actually a date type and is a

141
00:05:56,580 --> 00:06:03,330
specific date but what are the links data links

142
00:06:03,330 --> 00:06:05,070
and  ata are commanded to expose from the data

143
00:06:05,070 --> 00:06:07,740
that are based on rdf but not only in

144
00:06:07,740 --> 00:06:10,650
reality they assume that the jury that

145
00:06:10,650 --> 00:06:12,150
make up the requests are also

146
00:06:12,150 --> 00:06:14,250
links to the url and web

147
00:06:14,250 --> 00:06:16,440
and if you view these walls you will find

148
00:06:16,440 --> 00:06:18,300
information regarding the entities

149
00:06:18,300 --> 00:06:21,720
that have here and correspond  that url and

150
00:06:21,720 --> 00:06:25,860
this must ferenze action is

151
00:06:25,860 --> 00:06:28,680
actually assumed on the fact that within

152
00:06:28,680 --> 00:06:31,040
each database some given the

153
00:06:31,040 --> 00:06:34,080
rdf example there are links that say

154
00:06:34,080 --> 00:06:35,370
what are the entity relationships

155
00:06:35,370 --> 00:06:37,410
described in this date with other

156
00:06:37,410 --> 00:06:39,300
databases for example if a database  of

157
00:06:39,300 --> 00:06:43,110
proteins it is interesting that I with the former

158
00:06:43,110 --> 00:06:45,300
database for example a database of genes

159
00:06:45,300 --> 00:06:47,580
that maybe sequence those that generate

160
00:06:47,580 --> 00:06:48,300
those proteins

161
00:06:48,300 --> 00:06:50,039
this is this in order to have from

162
00:06:50,039 --> 00:06:52,979
trav  is compact verticals that, however, is worth

163
00:06:52,979 --> 00:06:54,360
the other of them and that can be questioned

164
00:06:54,360 --> 00:06:58,110
together because because the dream of

165
00:06:58,110 --> 00:07:00,600
link and data is that everyone is a man and

166
00:07:00,600 --> 00:07:02,220
decentralized in reality in which everyone

167
00:07:02,220 --> 00:07:06,330
hosts his information and let's say that

168
00:07:06,330 --> 00:07:08,520
date they are connected are connected

169
00:07:08,520 --> 00:07:10,289
had these relations and therefore I

170
00:07:10,289 --> 00:07:13,470
can jump from one database to another

171
00:07:13,470 --> 00:07:18,660
let's say in an automatic way

172
00:07:18,660 --> 00:07:20,160
both through the manual ones that

173
00:07:20,160 --> 00:07:23,310
depressed the bots and then I can go to

174
00:07:23,310 --> 00:07:24,480
seize the phone assen where they are where they

175
00:07:24,480 --> 00:07:26,430
are where they were inserted

176
00:07:26,430 --> 00:07:28,320
so I do not  I have to host everything I

177
00:07:28,320 --> 00:07:30,000
know from but I can get to

178
00:07:30,000 --> 00:07:31,650
know from whoever exposes it therefore, as

179
00:07:31,650 --> 00:07:33,750
opposed to sql, this type of

180
00:07:33,750 --> 00:07:35,160
dough is designed for you databases

181
00:07:35,160 --> 00:07:37,050
exposed to the outside information that

182
00:07:37,050 --> 00:07:39,810
people can ask me and do not miss that they

183
00:07:39,810 --> 00:07:41,490
remain closed inside back  end

184
00:07:41,490 --> 00:07:45,180
and you cannot see how it is done sparkle

185
00:07:45,180 --> 00:07:47,190
briefly let's say that

186
00:07:47,190 --> 00:07:50,010
sparkle unlike sql does not go on the

187
00:07:50,010 --> 00:07:51,510
match of lines that have the same

188
00:07:51,510 --> 00:07:53,430
identifiers  wings but it is based on a

189
00:07:53,430 --> 00:07:55,710
month of pattern so in this case I

190
00:07:55,710 --> 00:08:00,180
want the hicks entities to

191
00:08:00,180 --> 00:08:02,870
start the action city so both

192
00:08:02,870 --> 00:08:06,120
the entity that postpones the relationship

193
00:08:06,120 --> 00:08:10,380
lives with object city is however called hicks

194
00:08:10,380 --> 00:08:12,300
must also have the relationship capita

195
00:08:12,300 --> 00:08:14,610
it happens love the relationship realizes it b

196
00:08:14,610 --> 00:08:16,800
to the reaction it has no relations it happens

197
00:08:16,800 --> 00:08:18,630
love and therefore I'm putting let's say

198
00:08:18,630 --> 00:08:21,270
this pattern in addition

199
00:08:21,270 --> 00:08:22,860
I join stearic instead this pattern

200
00:08:22,860 --> 00:08:25,890
so let's say that contrary to how

201
00:08:25,890 --> 00:08:27,960
we usually think they are not those

202
00:08:27,960 --> 00:08:30,330
lines that are composed but  we

203
00:08:30,330 --> 00:08:31,979
think of the patterns that are rejected

204
00:08:31,979 --> 00:08:36,000
in this oriented graph is a little different

205
00:08:36,000 --> 00:08:38,590
but there are notable similarities in

206
00:08:38,590 --> 00:08:39,909
fact what comes out of this

207
00:08:39,909 --> 00:08:42,460
query is a two-column table and

208
00:08:42,460 --> 00:08:47,260
therefore it can be reused and summarizing

209
00:08:47,260 --> 00:08:50,470
a little let's say how to configure

210
00:08:50,470 --> 00:08:53,320
wiki data  in the world of links and ata

211
00:08:53,320 --> 00:08:55,080
we say that every generalist data knowledge based

212
00:08:55,080 --> 00:08:56,350


213
00:08:56,350 --> 00:08:57,970
certainly quality human knowledge

214
00:08:57,970 --> 00:08:59,680
and is also an excellent point in

215
00:08:59,680 --> 00:09:01,030
which  if I want to let you know that you give me

216
00:09:01,030 --> 00:09:03,310
it exists and it sets my

217
00:09:03,310 --> 00:09:05,440
identity database in turmoil which also contains

218
00:09:05,440 --> 00:09:07,480
my database so it is for sure

219
00:09:07,480 --> 00:09:08,590
a place that helps to find

220
00:09:08,590 --> 00:09:10,300
information

221
00:09:10,300 --> 00:09:14,470
well to one like every wiki project to a

222
00:09:14,470 --> 00:09:16,570
huge community that collaborates so  there is

223
00:09:16,570 --> 00:09:18,010
a side that jean not only automatic

224
00:09:18,010 --> 00:09:19,990
but also manual so

225
00:09:19,990 --> 00:09:21,940
formal validations are made over time which

226
00:09:21,940 --> 00:09:23,110
are then solved manually and

227
00:09:23,110 --> 00:09:24,910
manual validations of individual

228
00:09:24,910 --> 00:09:28,240
people and everything you study data and

229
00:09:28,240 --> 00:09:29,850
also the public domain

230
00:09:29,850 --> 00:09:32,170
this is also a negative side because it will

231
00:09:32,170 --> 00:09:33,490
allow  things you who date

232
00:09:33,490 --> 00:09:34,660
stars already in the public domain

233
00:09:34,660 --> 00:09:36,400
so if I want to lend a

234
00:09:36,400 --> 00:09:39,510
suicide database that of encyclopedic interest

235
00:09:39,510 --> 00:09:41,410
must be public domain

236
00:09:41,410 --> 00:09:43,630
the present the Italian population

237
00:09:43,630 --> 00:09:45,700
cannot commit suicide because it has been

238
00:09:45,700 --> 00:09:46,960
released not the public domain

239
00:09:46,960 --> 00:09:50,830
this is a famous example  of that the

240
00:09:50,830 --> 00:09:52,090
bad of vichy given to the bad in

241
00:09:52,090 --> 00:09:53,560
trustworthy and in general to what date is

242
00:09:53,560 --> 00:09:56,650
that the you  modern technology and not

243
00:09:56,650 --> 00:09:58,630
used for commercial purposes and

244
00:09:58,630 --> 00:10:01,600
therefore we say that the software is not

245
00:10:01,600 --> 00:10:03,850
mature and those overdone listed

246
00:10:03,850 --> 00:10:07,840
often does not end many queries and as

247
00:10:07,840 --> 00:10:09,280
time passes less and less here for

248
00:10:09,280 --> 00:10:11,650
example had come to the bottom ago

249
00:10:11,650 --> 00:10:13,300
nintendo is worth in time out because the

250
00:10:13,300 --> 00:10:16,000
quantity you  is too big and this is

251
00:10:16,000 --> 00:10:18,670
a technological limitation that of those

252
00:10:18,670 --> 00:10:20,590
badly made in the sense that time itself

253
00:10:20,590 --> 00:10:23,260
is a bit inefficient and cooking them

254
00:10:23,260 --> 00:10:26,590
as software is the biggest problem

255
00:10:26,590 --> 00:10:29,980
in my opinion is that wiki data respects the

256
00:10:29,980 --> 00:10:32,590
tendency to take care of centralizing the

257
00:10:32,590 --> 00:10:35,230
platforms and  so like all

258
00:10:35,230 --> 00:10:36,640
platforms sides can not eat the

259
00:10:36,640 --> 00:10:38,770
rest mystical people parry that link

260
00:10:38,770 --> 00:10:41,050
data cloud then to create its

261
00:10:41,050 --> 00:10:42,610
database that exposes according to the

262
00:10:42,610 --> 00:10:45,040
formalism tends to pour data only

263
00:10:45,040 --> 00:10:46,870
suffered data and this makes assumed or

264
00:10:46,870 --> 00:10:47,570
guided

265
00:10:47,570 --> 00:10:50,600
if dominant typical of facebook typical

266
00:10:50,600 --> 00:10:52,640
nothing  centralized platform a bit

267
00:10:52,640 --> 00:10:54,740
like it happened with wikipedia it does not serve any

268
00:10:54,740 --> 00:10:56,330
more harm because it is to create community

269
00:10:56,330 --> 00:11:00,830
though  in my opinion it is not a

270
00:11:00,830 --> 00:11:04,490
critical thing the date i blacks consideration

271
00:11:04,490 --> 00:11:06,260
i end with two examples on how to use

272
00:11:06,260 --> 00:11:08,810
wiki data because given to you is not just a

273
00:11:08,810 --> 00:11:11,270
source of raw information so a

274
00:11:11,270 --> 00:11:13,370
list of names to do perhaps from a

275
00:11:13,370 --> 00:11:15,560
dictionary rather than a list  of

276
00:11:15,560 --> 00:11:17,570
cities but you can cheer on machine

277
00:11:17,570 --> 00:11:18,220
learning

278
00:11:18,220 --> 00:11:20,810
I give two examples an example of the same

279
00:11:20,810 --> 00:11:22,850
free vision given the large amount of

280
00:11:22,850 --> 00:11:24,290
structured training it is possible

281
00:11:24,290 --> 00:11:26,840
through thesaurus and

282
00:11:26,840 --> 00:11:29,870
guided david generate a corpus

283
00:11:29,870 --> 00:11:32,330
then he noticed a series of a text

284
00:11:32,330 --> 00:11:35,540
that I already know  what corresponds what to

285
00:11:35,540 --> 00:11:37,070
be able to train classifiers that

286
00:11:37,070 --> 00:11:39,080
recognize detention the text is

287
00:11:39,080 --> 00:11:40,490
called said supervision and the other

288
00:11:40,490 --> 00:11:42,500
example I actually give was to

289
00:11:42,500 --> 00:11:44,030
also effect a way of embedding

290
00:11:44,030 --> 00:11:46,580
instead of words to make the inside

291
00:11:46,580 --> 00:11:47,930
of the graph so let's say that  it gives the

292
00:11:47,930 --> 00:11:49,970
entity similarity metrics not

293
00:11:49,970 --> 00:11:52,220
so much in the vicinity of the words

294
00:11:52,220 --> 00:11:55,030
in the test as it can be white black but

295
00:11:55,030 --> 00:11:59,000
in the context of the contest  or words but

296
00:11:59,000 --> 00:12:00,470
it does it presents context within

297
00:12:00,470 --> 00:12:06,530
the graph of limits given the eyes there

298
00:12:06,530 --> 00:12:08,740
are questions

299
00:12:10,500 --> 00:12:17,080
[Applause]

300
00:12:17,080 --> 00:12:19,640
I was curious to know if in your work you

301
00:12:19,640 --> 00:12:23,810
use e age wikis how does my

302
00:12:23,810 --> 00:12:25,820
company use enough wikis d  'age

303
00:12:25,820 --> 00:12:28,880
we make tg prevail so it is our

304
00:12:28,880 --> 00:12:31,149
project it

305
00:12:31,560 --> 00:12:34,590
is an aggregator of cataldi libraries

306
00:12:34,590 --> 00:12:36,540
because the link data are good also they

307
00:12:36,540 --> 00:12:39,890
are excellent also beats integration and

308
00:12:39,890 --> 00:12:42,180
by making the match for the authors who are

309
00:12:42,180 --> 00:12:43,980
in the biotech catalog and is guided it is

310
00:12:43,980 --> 00:12:46,110
possible to make web pages  who

311
00:12:46,110 --> 00:12:47,820
means to the page because information

312
00:12:47,820 --> 00:12:50,220
from multiple sources then in the page there is

313
00:12:50,220 --> 00:12:53,630
information for example the title

314
00:12:53,630 --> 00:12:55,680
best label of the name taken from

315
00:12:55,680 --> 00:12:58,140
wiki date and best description taken

316
00:12:58,140 --> 00:13:01,260
from div pedia it is possible to put

317
00:13:01,260 --> 00:13:03,000
unique initiatives then the links to

318
00:13:03,000 --> 00:13:04,650
high biotech and national

319
00:13:04,650 --> 00:13:06,540
this is the way  maybe more that is

320
00:13:06,540 --> 00:13:08,850
accomplished city of age at work

321
00:13:08,850 --> 00:13:12,900
another thing I noticed is aperi it

322
00:13:12,900 --> 00:13:15,600
was silly but how do I know

323
00:13:15,600 --> 00:13:18,029
which are all the regions  that with ends

324
00:13:18,029 --> 00:13:20,910
also a certain region place with which I

325
00:13:20,910 --> 00:13:23,310
record and if I am capable I can do it by

326
00:13:23,310 --> 00:13:24,779
hand I choose each region

327
00:13:24,779 --> 00:13:26,430
I am called gone for those

328
00:13:26,430 --> 00:13:27,839
neighboring regions or as they do to those

329
00:13:27,839 --> 00:13:29,700
sparkle aged that contains this

330
00:13:29,700 --> 00:13:32,040
information and in a minute if I know

331
00:13:32,040 --> 00:13:35,390
sparkle or this information

332
00:13:37,220 --> 00:13:39,870
there are practical examples on how I am

333
00:13:39,870 --> 00:13:42,720
used the from the wikimedia set to make

334
00:13:42,720 --> 00:13:45,360
three machine learning nests nothing of the

335
00:13:45,360 --> 00:13:48,720
certainly paratic papers

336
00:13:48,720 --> 00:13:51,010


337
00:13:51,010 --> 00:13:53,620
I have seen maybe use or how it went

338
00:13:53,620 --> 00:13:56,710
how it worked many papers that use it

339
00:13:56,710 --> 00:13:59,200
but I have not seen  examples

340
00:13:59,200 --> 00:14:00,910
[Music]

341
00:14:00,910 --> 00:14:03,340
in detail it is a bit

342
00:14:03,340 --> 00:14:05,760
academic

343
00:14:18,070 --> 00:14:22,629
[Applause]

