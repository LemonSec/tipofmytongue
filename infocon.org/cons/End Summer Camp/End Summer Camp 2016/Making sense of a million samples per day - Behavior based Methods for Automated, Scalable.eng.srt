1
00:00:02,029 --> 00:00:06,689
so is the real pleasure and an honor to

2
00:00:06,690 --> 00:00:10,139
introduce the next speaker here at and

3
00:00:10,139 --> 00:00:15,120
summer camp he is a PhD at politecnico

4
00:00:15,120 --> 00:00:18,240
di milano nand circuit professor now his

5
00:00:18,240 --> 00:00:22,980
research is malware analysis and is the

6
00:00:22,980 --> 00:00:26,730
board of black hat right and he is

7
00:00:26,730 --> 00:00:28,980
definite the narrow you probably know

8
00:00:28,980 --> 00:00:33,890
him already so please welcome him and

9
00:00:33,890 --> 00:00:40,020
here we are you so in the spirit of

10
00:00:40,020 --> 00:00:41,850
having at least one english speaker in

11
00:00:41,850 --> 00:00:44,280
the audience i will speak in English if

12
00:00:44,280 --> 00:00:46,379
you if you don't understand me which is

13
00:00:46,379 --> 00:00:48,539
perfectly understandable just to raise

14
00:00:48,539 --> 00:00:50,309
your hand and I will repeat myself in

15
00:00:50,309 --> 00:00:56,100
Italian so my name is so my name is

16
00:00:56,100 --> 00:00:58,739
Stefan yeah yeah like be lucky all right

17
00:00:58,739 --> 00:01:06,360
sure you're just the one so um okay so I

18
00:01:06,360 --> 00:01:08,340
have way too many friends and way too

19
00:01:08,340 --> 00:01:10,350
many enemies in this in this room and

20
00:01:10,350 --> 00:01:12,270
it's always difficult to tell which is

21
00:01:12,270 --> 00:01:16,470
which so um my name is Stefano I work at

22
00:01:16,470 --> 00:01:17,970
politecnico di milano and this is

23
00:01:17,970 --> 00:01:21,540
actually what I'm going to present is

24
00:01:21,540 --> 00:01:23,909
actually join work with my with my keep

25
00:01:23,909 --> 00:01:25,470
of colleagues and friends that I will

26
00:01:25,470 --> 00:01:28,860
list at the end of the talk we are

27
00:01:28,860 --> 00:01:30,780
working on different things one of the

28
00:01:30,780 --> 00:01:33,479
things we are working on is how to make

29
00:01:33,479 --> 00:01:36,150
sense of a million samples per day I

30
00:01:36,150 --> 00:01:37,770
ought to make sense of a lot of malware

31
00:01:37,770 --> 00:01:41,280
that is getting thrown at us so this is

32
00:01:41,280 --> 00:01:44,790
a this in the framework of an activity

33
00:01:44,790 --> 00:01:46,970
that is called threat intelligence

34
00:01:46,970 --> 00:01:49,829
threat intelligence is not new enough in

35
00:01:49,829 --> 00:01:51,930
fact it has been winning or losing

36
00:01:51,930 --> 00:01:54,420
battles since five hundred years before

37
00:01:54,420 --> 00:01:59,520
Christ this is a famous quote from the

38
00:01:59,520 --> 00:02:02,280
pin fuh the art of war by Masterson's

39
00:02:02,280 --> 00:02:04,890
which has written it about 500 years

40
00:02:04,890 --> 00:02:08,758
before Christ and he said that if you

41
00:02:08,758 --> 00:02:10,709
know the enemy if you know yourself

42
00:02:10,709 --> 00:02:13,620
you're going to win every battle then

43
00:02:13,620 --> 00:02:17,340
of course this is one of the most often

44
00:02:17,340 --> 00:02:20,549
quoted and most and least often applied

45
00:02:20,549 --> 00:02:24,209
quotes in human history but basically

46
00:02:24,209 --> 00:02:26,879
knowing our enemy is always important

47
00:02:26,879 --> 00:02:29,610
for for fighting the cybersecurity Bell

48
00:02:29,610 --> 00:02:32,190
and here we have a significant issue

49
00:02:32,190 --> 00:02:34,799
which is the evolution the evolution of

50
00:02:34,799 --> 00:02:36,420
the threat the evolution of malware so

51
00:02:36,420 --> 00:02:38,610
if you have been in security long enough

52
00:02:38,610 --> 00:02:41,069
and know that some of you have been in

53
00:02:41,069 --> 00:02:43,530
security long enough a particular pila

54
00:02:43,530 --> 00:02:45,269
has been in security for a very long

55
00:02:45,269 --> 00:02:47,430
time is kind of the grandfather all of

56
00:02:47,430 --> 00:02:53,970
us so so if you've been a security for

57
00:02:53,970 --> 00:02:55,560
long enough you will remember that in

58
00:02:55,560 --> 00:02:58,349
the 80s and 90s most of the malware that

59
00:02:58,349 --> 00:03:00,450
we had to deal with was self-replicating

60
00:03:00,450 --> 00:03:02,340
malware it was malware that was

61
00:03:02,340 --> 00:03:04,799
self-similar by construction it created

62
00:03:04,799 --> 00:03:07,909
a lot of copies of itself so it made

63
00:03:07,909 --> 00:03:11,549
almost sense the idea of just looking at

64
00:03:11,549 --> 00:03:13,319
each of these samples and understanding

65
00:03:13,319 --> 00:03:14,700
what they were doing and kind of

66
00:03:14,700 --> 00:03:16,769
creating a capital of malware which is

67
00:03:16,769 --> 00:03:19,260
what antivirus is basically our catalogs

68
00:03:19,260 --> 00:03:22,319
of malwa um there's also another

69
00:03:22,319 --> 00:03:24,329
significant feature of the malware of

70
00:03:24,329 --> 00:03:26,130
written in the 80s and the 90s that most

71
00:03:26,130 --> 00:03:28,079
of the malware that was written in those

72
00:03:28,079 --> 00:03:32,760
ages so the state suit of limitations in

73
00:03:32,760 --> 00:03:34,769
Italy as expired most of knowledge that

74
00:03:34,769 --> 00:03:39,000
we've wrote in those times was basically

75
00:03:39,000 --> 00:03:42,180
aimed at demonstrating skill we didn't

76
00:03:42,180 --> 00:03:45,540
really want malware to be destructive

77
00:03:45,540 --> 00:03:47,400
there were some destructive samples of

78
00:03:47,400 --> 00:03:48,870
course there's always been destructive

79
00:03:48,870 --> 00:03:51,569
things but most of the malware back then

80
00:03:51,569 --> 00:03:54,569
was destructive only by chance because

81
00:03:54,569 --> 00:03:59,040
somebody made a mistake this has changed

82
00:03:59,040 --> 00:04:00,989
over the years and in particular this

83
00:04:00,989 --> 00:04:03,359
has changed a lot between the two

84
00:04:03,359 --> 00:04:05,400
thousand two thousand four you will

85
00:04:05,400 --> 00:04:08,639
remember the ages of the worms the word

86
00:04:08,639 --> 00:04:11,579
is enormously a diffusive explosive

87
00:04:11,579 --> 00:04:14,010
malware that would propagate and create

88
00:04:14,010 --> 00:04:15,900
damage just because of how fast they

89
00:04:15,900 --> 00:04:19,649
were propagating and in 2004 we were all

90
00:04:19,649 --> 00:04:22,740
basically betting that malware that was

91
00:04:22,740 --> 00:04:26,889
propagating as um as at

92
00:04:26,889 --> 00:04:30,610
worms would become worse and worse that

93
00:04:30,610 --> 00:04:32,830
the internet would become warmer and

94
00:04:32,830 --> 00:04:36,729
warmer I even have like I'm sorry that I

95
00:04:36,729 --> 00:04:38,770
wasn't wasn't able to find it for today

96
00:04:38,770 --> 00:04:41,469
but I even have a t-shirt which was by I

97
00:04:41,469 --> 00:04:43,900
defense a few years back that on the

98
00:04:43,900 --> 00:04:45,849
back of the t-shirt like it had the

99
00:04:45,849 --> 00:04:47,770
dates of the worms like the dates of

100
00:04:47,770 --> 00:04:50,590
concerts of rock bands right was maybe

101
00:04:50,590 --> 00:04:53,770
the same way so um we were all betting

102
00:04:53,770 --> 00:04:56,469
on the next one but the next one then

103
00:04:56,469 --> 00:05:02,020
never appeared from 2005 till today what

104
00:05:02,020 --> 00:05:04,990
we have seen is the malware author shift

105
00:05:04,990 --> 00:05:09,490
focus to actually monetizing through

106
00:05:09,490 --> 00:05:12,550
diffusive stealth malware that is not

107
00:05:12,550 --> 00:05:14,949
actually a clone of itself and this

108
00:05:14,949 --> 00:05:18,219
change as script has been fueled by the

109
00:05:18,219 --> 00:05:19,569
growth of the underground economy

110
00:05:19,569 --> 00:05:21,759
so-called crime as a service where

111
00:05:21,759 --> 00:05:24,759
people actually buy a code for doing

112
00:05:24,759 --> 00:05:26,499
malicious things instead of writing it

113
00:05:26,499 --> 00:05:28,089
themselves so there's criminal rings

114
00:05:28,089 --> 00:05:30,219
that are running different portions of

115
00:05:30,219 --> 00:05:34,689
the malware food chain but what happened

116
00:05:34,689 --> 00:05:37,360
in there in that shift is that we

117
00:05:37,360 --> 00:05:39,610
shifted from malware that was always the

118
00:05:39,610 --> 00:05:43,240
same many copies of the same thing to

119
00:05:43,240 --> 00:05:46,089
malware that was basically always

120
00:05:46,089 --> 00:05:51,539
different right now we get between

121
00:05:51,539 --> 00:05:55,469
500,000 and a million new different

122
00:05:55,469 --> 00:06:02,289
binary samples per day in all that lot

123
00:06:02,289 --> 00:06:04,509
of malware which is mostly the same

124
00:06:04,509 --> 00:06:07,569
thing really but just slightly different

125
00:06:07,569 --> 00:06:11,229
in all that malware there's also other

126
00:06:11,229 --> 00:06:14,379
people that are riding so for instance

127
00:06:14,379 --> 00:06:17,620
from 2010 on we have been witness to an

128
00:06:17,620 --> 00:06:19,659
enormous increase in what we call

129
00:06:19,659 --> 00:06:22,810
state-sponsored attacks in the middle of

130
00:06:22,810 --> 00:06:26,469
all that that is thrown at has over

131
00:06:26,469 --> 00:06:28,800
time all that half a million new malware

132
00:06:28,800 --> 00:06:32,289
there's one two three per month or per

133
00:06:32,289 --> 00:06:34,839
year these are actually more interesting

134
00:06:34,839 --> 00:06:38,919
and what we need to do is figure out a

135
00:06:38,919 --> 00:06:40,129
way to filter

136
00:06:40,129 --> 00:06:42,739
out all of those 500,000 that we don't

137
00:06:42,739 --> 00:06:47,539
care about to sift out that one to ten

138
00:06:47,539 --> 00:06:54,769
that carry information there's another

139
00:06:54,769 --> 00:06:57,589
issue that we need to deal with and the

140
00:06:57,589 --> 00:06:59,389
issue is the issue of so-called

141
00:06:59,389 --> 00:07:02,239
attribution which doesn't mean saying oh

142
00:07:02,239 --> 00:07:06,259
this malware has been written by X not

143
00:07:06,259 --> 00:07:09,229
really it means these malware comes from

144
00:07:09,229 --> 00:07:12,949
that area that family that threat actor

145
00:07:12,949 --> 00:07:17,839
and this is difficult it's always been

146
00:07:17,839 --> 00:07:20,860
difficult the produce that right now

147
00:07:20,860 --> 00:07:23,360
instead of it being difficult in the

148
00:07:23,360 --> 00:07:25,159
sense that we wanted to know which

149
00:07:25,159 --> 00:07:27,830
hacker group was responsible for that

150
00:07:27,830 --> 00:07:29,809
specific cool piece of malware that we

151
00:07:29,809 --> 00:07:32,179
were looking at and most hacker groups

152
00:07:32,179 --> 00:07:34,849
in the 90s with actually embed in the

153
00:07:34,849 --> 00:07:37,459
code of the malware their own signature

154
00:07:37,459 --> 00:07:40,039
to just let you know hey this is cool I

155
00:07:40,039 --> 00:07:44,529
vivid right now we have the issue of

156
00:07:44,529 --> 00:07:46,879
actually trying to understand who is

157
00:07:46,879 --> 00:07:50,269
done it because sooner or later the

158
00:07:50,269 --> 00:07:54,110
answer to that specific entity doing it

159
00:07:54,110 --> 00:07:58,819
may be a well-placed missile so we need

160
00:07:58,819 --> 00:08:02,240
a way to figure out very well what man

161
00:08:02,240 --> 00:08:04,459
where does which malware is interesting

162
00:08:04,459 --> 00:08:06,050
and when we find the mower that is

163
00:08:06,050 --> 00:08:10,099
interesting to find out whose is that or

164
00:08:10,099 --> 00:08:18,769
ma'am so um the issue that we are

165
00:08:18,769 --> 00:08:20,240
dealing with is that we have a lot of

166
00:08:20,240 --> 00:08:25,519
code and we have a few analysts and do

167
00:08:25,519 --> 00:08:27,740
not mistake me I'm a professor and

168
00:08:27,740 --> 00:08:31,159
training people and I'd love to train as

169
00:08:31,159 --> 00:08:34,759
many analysts as I can but we will never

170
00:08:34,759 --> 00:08:37,458
be able to train enough analysts to

171
00:08:37,458 --> 00:08:40,309
analyze millions of samples per day by

172
00:08:40,309 --> 00:08:44,600
hand those this analysts need we need

173
00:08:44,600 --> 00:08:46,519
more analysts we need more people

174
00:08:46,519 --> 00:08:48,740
skilled at that but we need a better way

175
00:08:48,740 --> 00:08:50,480
to analyze malgor than looking at this

176
00:08:50,480 --> 00:08:53,300
code in order to understand what it's

177
00:08:53,300 --> 00:08:53,930
that what

178
00:08:53,930 --> 00:08:55,970
us in order to what to understand if

179
00:08:55,970 --> 00:08:59,300
it's new in order to understand where it

180
00:08:59,300 --> 00:09:03,290
comes from so um the people that are

181
00:09:03,290 --> 00:09:05,839
already aware of malware analysis

182
00:09:05,839 --> 00:09:07,490
techniques and I see quite a few in the

183
00:09:07,490 --> 00:09:09,560
room will excuse me if I go back to the

184
00:09:09,560 --> 00:09:12,110
basics but for anybody that has never

185
00:09:12,110 --> 00:09:14,570
done anything in a malware analysis area

186
00:09:14,570 --> 00:09:17,480
there's two ways that we can analyze

187
00:09:17,480 --> 00:09:20,180
malware and they're not like the wrong

188
00:09:20,180 --> 00:09:21,680
in the right way there are just two

189
00:09:21,680 --> 00:09:25,850
complementary ways so one way is doing

190
00:09:25,850 --> 00:09:28,339
static analysis taking it apart looking

191
00:09:28,339 --> 00:09:30,459
at the code disassembling it

192
00:09:30,459 --> 00:09:32,959
reassembling it trying to understand

193
00:09:32,959 --> 00:09:34,390
what it does what the specific

194
00:09:34,390 --> 00:09:36,560
functionalities are by looking at the

195
00:09:36,560 --> 00:09:40,070
code that's what we used to do with

196
00:09:40,070 --> 00:09:42,770
malware in the 80s and 90s look at it by

197
00:09:42,770 --> 00:09:48,050
hand it works perfectly but it takes a

198
00:09:48,050 --> 00:09:54,290
lot of time it takes a lot of skill so

199
00:09:54,290 --> 00:09:55,760
which is the difficult to extract

200
00:09:55,760 --> 00:09:58,400
semantic slide over there there's also

201
00:09:58,400 --> 00:10:00,320
another issue which is obfuscated most

202
00:10:00,320 --> 00:10:03,670
malware nowadays is obfuscated or packed

203
00:10:03,670 --> 00:10:06,320
which means that it's not easy to

204
00:10:06,320 --> 00:10:10,430
extract its meaning so for most malware

205
00:10:10,430 --> 00:10:12,860
we actually employ also a dynamic

206
00:10:12,860 --> 00:10:14,810
approach which means basically you

207
00:10:14,810 --> 00:10:16,670
create a sandbox a virtual machine which

208
00:10:16,670 --> 00:10:18,830
has been cut off from the rest of the

209
00:10:18,830 --> 00:10:21,290
internet and throw it in and so see what

210
00:10:21,290 --> 00:10:24,650
it does it's very big at the very least

211
00:10:24,650 --> 00:10:28,400
let it unpack itself let it uncompress

212
00:10:28,400 --> 00:10:30,170
itself so that you can look at its code

213
00:10:30,170 --> 00:10:32,810
and then look at the ad what it does

214
00:10:32,810 --> 00:10:36,140
look at its behavior and this is

215
00:10:36,140 --> 00:10:38,450
actually easy because it makes it easy

216
00:10:38,450 --> 00:10:41,089
to see behaviors you can actually figure

217
00:10:41,089 --> 00:10:43,370
out what the matter is doing in a very

218
00:10:43,370 --> 00:10:47,959
automated way that's what basically most

219
00:10:47,959 --> 00:10:50,390
malware analysis systems in the in the

220
00:10:50,390 --> 00:10:55,850
world do as a first basic measure um but

221
00:10:55,850 --> 00:10:57,890
this is a major issue when you run the

222
00:10:57,890 --> 00:11:00,050
malware you only see the behavior that

223
00:11:00,050 --> 00:11:02,209
the malware is showing to you so you

224
00:11:02,209 --> 00:11:04,700
have the issue of dormant code

225
00:11:04,700 --> 00:11:06,470
of code that has not been executed to

226
00:11:06,470 --> 00:11:09,860
learn that specific execution of our so

227
00:11:09,860 --> 00:11:13,720
how do you solve this symmetric

228
00:11:13,720 --> 00:11:15,790
weaknesses of these two approaches

229
00:11:15,790 --> 00:11:18,740
usually use them together you know so

230
00:11:18,740 --> 00:11:21,800
the results that we are doing is in I

231
00:11:21,800 --> 00:11:24,290
bread analysis techniques where you mix

232
00:11:24,290 --> 00:11:26,930
dynamic and static analysis in order to

233
00:11:26,930 --> 00:11:29,570
try to figure out more about the sample

234
00:11:29,570 --> 00:11:31,880
and one thing that we actually found is

235
00:11:31,880 --> 00:11:37,940
that why is there so much malware answer

236
00:11:37,940 --> 00:11:40,910
because people reuse code they cannot

237
00:11:40,910 --> 00:11:44,020
write 500 thousand samples per day all

238
00:11:44,020 --> 00:11:47,300
from scratch they're just reusing code

239
00:11:47,300 --> 00:11:50,990
over and over so let's turn the tables

240
00:11:50,990 --> 00:11:53,930
let's use this code reuse against the

241
00:11:53,930 --> 00:11:58,460
malware authors as much as we can so um

242
00:11:58,460 --> 00:12:02,840
I will present three different things

243
00:12:02,840 --> 00:12:05,150
that we did based on this concept just

244
00:12:05,150 --> 00:12:07,700
to try to let you understand how

245
00:12:07,700 --> 00:12:09,170
powerful it is and how it can be applied

246
00:12:09,170 --> 00:12:11,480
so the first is a prototype that we

247
00:12:11,480 --> 00:12:13,360
called reanimator this is actually

248
00:12:13,360 --> 00:12:16,250
reasonably old research because this was

249
00:12:16,250 --> 00:12:19,670
presented in 2010 it's kind of the basic

250
00:12:19,670 --> 00:12:22,370
idea behind everything so I thought to

251
00:12:22,370 --> 00:12:25,490
start from here so in reality what we do

252
00:12:25,490 --> 00:12:29,530
is this we run a sample into a sandbox

253
00:12:29,530 --> 00:12:33,470
this sample shows some behaviors these

254
00:12:33,470 --> 00:12:36,020
behaviors are sometimes interesting for

255
00:12:36,020 --> 00:12:38,660
instance I see the sample running an

256
00:12:38,660 --> 00:12:41,600
attack and exploit that I have not

257
00:12:41,600 --> 00:12:44,600
observed before so this behavior is

258
00:12:44,600 --> 00:12:47,360
interesting for me I can track that

259
00:12:47,360 --> 00:12:51,170
behavior to a specific model of the

260
00:12:51,170 --> 00:12:53,990
underlying code that is resilient to

261
00:12:53,990 --> 00:12:56,810
recompilation and that tracks back that

262
00:12:56,810 --> 00:12:59,330
code as far as much as possible to the

263
00:12:59,330 --> 00:13:03,920
source then with that model I can go

264
00:13:03,920 --> 00:13:07,220
thru my set of samples that I have

265
00:13:07,220 --> 00:13:09,620
collected over the years and I can see

266
00:13:09,620 --> 00:13:10,850
if there is another sample that

267
00:13:10,850 --> 00:13:13,160
implements the same the same capability

268
00:13:13,160 --> 00:13:16,190
and that's it has not shown it to me

269
00:13:16,190 --> 00:13:17,970
because resource

270
00:13:17,970 --> 00:13:22,560
whatever so basically well identifying

271
00:13:22,560 --> 00:13:24,120
the behavior is simple you run the

272
00:13:24,120 --> 00:13:26,370
malware instrumented sandbox you used to

273
00:13:26,370 --> 00:13:28,019
be able to run it into a new base I'm

274
00:13:28,019 --> 00:13:29,759
still able to run it into a dubious but

275
00:13:29,759 --> 00:13:31,410
you may not be able to because they have

276
00:13:31,410 --> 00:13:34,560
pulled an obvious from open access but

277
00:13:34,560 --> 00:13:36,509
you can do this with any sandbox you

278
00:13:36,509 --> 00:13:39,269
like we did it with a new base but it's

279
00:13:39,269 --> 00:13:41,879
not necessarily tied to that the only

280
00:13:41,879 --> 00:13:43,560
thing that you need is to be able to

281
00:13:43,560 --> 00:13:46,439
basically arrive to a set of API calls

282
00:13:46,439 --> 00:13:48,269
that the malware is executed that

283
00:13:48,269 --> 00:13:52,350
implement a certain behavior and this

284
00:13:52,350 --> 00:13:54,029
behavior can be something as generic as

285
00:13:54,029 --> 00:13:57,259
sending spam or something as specific at

286
00:13:57,259 --> 00:13:59,790
attentive as specific exploit against

287
00:13:59,790 --> 00:14:03,990
something so once you are you've

288
00:14:03,990 --> 00:14:07,730
extracted that behavior from the malware

289
00:14:07,730 --> 00:14:10,649
you can go and try to Matt and this is

290
00:14:10,649 --> 00:14:12,300
actually the difficult part the rest of

291
00:14:12,300 --> 00:14:14,790
the the rest of this is is actually just

292
00:14:14,790 --> 00:14:17,069
an exercise but the difficult part is

293
00:14:17,069 --> 00:14:19,350
out do you map that to code to binary

294
00:14:19,350 --> 00:14:21,319
code in such a way that you can

295
00:14:21,319 --> 00:14:24,629
basically go and match that binary code

296
00:14:24,629 --> 00:14:27,329
across a collection and see if there are

297
00:14:27,329 --> 00:14:30,110
other malware that they've implemented

298
00:14:30,110 --> 00:14:32,850
the same behavior starting from the same

299
00:14:32,850 --> 00:14:37,110
source code so here the problem is that

300
00:14:37,110 --> 00:14:39,089
you want to basically include all of the

301
00:14:39,089 --> 00:14:40,860
code that has implemented the behavior

302
00:14:40,860 --> 00:14:44,009
but you don't want to include code that

303
00:14:44,009 --> 00:14:46,410
is supporting features or is not

304
00:14:46,410 --> 00:14:50,699
specific to that behavior so we have a

305
00:14:50,699 --> 00:14:52,589
process for this and the process is this

306
00:14:52,589 --> 00:14:56,569
we start from the API calls so from the

307
00:14:56,569 --> 00:15:00,720
from this lies of API calls we created

308
00:15:00,720 --> 00:15:03,209
empty slice and we include in that slice

309
00:15:03,209 --> 00:15:04,800
all of the instructions that either

310
00:15:04,800 --> 00:15:06,809
prepare the inputs for the calls so

311
00:15:06,809 --> 00:15:08,519
basically we follow data dependencies

312
00:15:08,519 --> 00:15:12,180
backwards and we process the output of

313
00:15:12,180 --> 00:15:14,930
the calls so follow the data flow

314
00:15:14,930 --> 00:15:18,809
forward here we make a major assumption

315
00:15:18,809 --> 00:15:22,439
because of course any I see Meredith as

316
00:15:22,439 --> 00:15:25,470
stating in the back so any computer side

317
00:15:25,470 --> 00:15:26,610
is the best dealt with this problem

318
00:15:26,610 --> 00:15:28,259
knows that there are a series of

319
00:15:28,259 --> 00:15:30,660
challenges in this one of the challenges

320
00:15:30,660 --> 00:15:31,860
is of course counter flow

321
00:15:31,860 --> 00:15:34,529
dependences but the cool thing is that

322
00:15:34,529 --> 00:15:38,089
most malware does not really have that

323
00:15:38,089 --> 00:15:40,680
significant set of control dependencies

324
00:15:40,680 --> 00:15:43,829
so we kind of take the shortcut and

325
00:15:43,829 --> 00:15:51,300
simply simplify that so at this point we

326
00:15:51,300 --> 00:15:52,769
have an issue which is that this life is

327
00:15:52,769 --> 00:15:55,200
not precise it includes also sorts of

328
00:15:55,200 --> 00:15:57,990
supporting codes and our purpose utility

329
00:15:57,990 --> 00:16:01,910
functions and so on and so forth so and

330
00:16:01,910 --> 00:16:04,980
also actually if you go backwards licen

331
00:16:04,980 --> 00:16:07,410
and you do it very well at some point

332
00:16:07,410 --> 00:16:09,890
you may you may basically hit the

333
00:16:09,890 --> 00:16:12,300
initialization in the unpacking routines

334
00:16:12,300 --> 00:16:13,709
and at that point you're screwed because

335
00:16:13,709 --> 00:16:15,060
you basically matched all the code of

336
00:16:15,060 --> 00:16:19,290
the malware so we basically try to

337
00:16:19,290 --> 00:16:22,470
filter this and the idea of filtering is

338
00:16:22,470 --> 00:16:26,970
that we use exclusive we basically look

339
00:16:26,970 --> 00:16:30,540
at exclusive instructions which means we

340
00:16:30,540 --> 00:16:33,360
have multiple runs of the malware the

341
00:16:33,360 --> 00:16:35,220
malware sometimes exhibits the behavior

342
00:16:35,220 --> 00:16:37,230
sometimes it doesn't so if you know

343
00:16:37,230 --> 00:16:39,360
instructions that has been patched both

344
00:16:39,360 --> 00:16:40,949
when the malware has executed the

345
00:16:40,949 --> 00:16:43,140
behavior and when the malware has not

346
00:16:43,140 --> 00:16:45,480
exhibited the behavior it's probably a

347
00:16:45,480 --> 00:16:48,180
nativity function if only if a function

348
00:16:48,180 --> 00:16:51,570
is manipulating the data every time it's

349
00:16:51,570 --> 00:16:53,910
executed then it's specific to that

350
00:16:53,910 --> 00:16:55,199
month to that malicious behavior

351
00:16:55,199 --> 00:16:57,420
otherwise it's an utility for it maybe

352
00:16:57,420 --> 00:17:03,000
an utility function we can also um in

353
00:17:03,000 --> 00:17:06,030
theory we could use wireless so we could

354
00:17:06,030 --> 00:17:08,040
basically map like libraries and

355
00:17:08,040 --> 00:17:10,319
whitelist code but this is not really

356
00:17:10,319 --> 00:17:12,240
necessary because if you apply these two

357
00:17:12,240 --> 00:17:14,520
techniques you are basically discarding

358
00:17:14,520 --> 00:17:17,579
every type of library at this point this

359
00:17:17,579 --> 00:17:19,260
lies that you are left with is obviously

360
00:17:19,260 --> 00:17:20,429
not complete because you have thrown

361
00:17:20,429 --> 00:17:23,910
away lots of stuff so um what you do is

362
00:17:23,910 --> 00:17:25,530
you start from those instructions and

363
00:17:25,530 --> 00:17:27,059
you basically complete the basic blocks

364
00:17:27,059 --> 00:17:33,210
around it and you end up with a sub sub

365
00:17:33,210 --> 00:17:35,130
portion of the control flow graph of the

366
00:17:35,130 --> 00:17:38,730
malware that then you need to somehow

367
00:17:38,730 --> 00:17:42,059
match to other samples in a way that is

368
00:17:42,059 --> 00:17:45,950
resilient to a compilation but not

369
00:17:45,950 --> 00:17:49,680
22 lacks in order to do this there is

370
00:17:49,680 --> 00:17:51,180
actually a technique that has been used

371
00:17:51,180 --> 00:17:53,880
over and over in the years which works

372
00:17:53,880 --> 00:17:56,070
reasonably well it's been developed by

373
00:17:56,070 --> 00:17:59,370
Chris Kruger few years back for matching

374
00:17:59,370 --> 00:18:02,400
polymorphic malware and the technique is

375
00:18:02,400 --> 00:18:05,520
based on the idea of coloring the

376
00:18:05,520 --> 00:18:08,760
control flow graph according to some

377
00:18:08,760 --> 00:18:11,100
instruction classes basically you can

378
00:18:11,100 --> 00:18:14,640
divide x86 instructions into buckets

379
00:18:14,640 --> 00:18:17,670
where to in order to substitute one of

380
00:18:17,670 --> 00:18:19,920
the functions with equivalence you

381
00:18:19,920 --> 00:18:22,380
really need one of the other functions

382
00:18:22,380 --> 00:18:26,340
in that bucket so if you color the

383
00:18:26,340 --> 00:18:27,930
control flow graphs based on those

384
00:18:27,930 --> 00:18:31,650
instruction classes it turns out that if

385
00:18:31,650 --> 00:18:34,200
you go and match all of the sub graphs

386
00:18:34,200 --> 00:18:38,120
of a certain size between two different

387
00:18:38,120 --> 00:18:41,270
control flow graphs if there are matches

388
00:18:41,270 --> 00:18:44,700
those two control flow graphs those two

389
00:18:44,700 --> 00:18:49,860
executables are very very likely for a

390
00:18:49,860 --> 00:18:54,120
high value of very very likely to come

391
00:18:54,120 --> 00:18:56,520
from the same source code or two at

392
00:18:56,520 --> 00:18:58,050
least include a part of the same source

393
00:18:58,050 --> 00:19:00,950
code so then the question obviously is

394
00:19:00,950 --> 00:19:04,680
how much very very likely they are to be

395
00:19:04,680 --> 00:19:06,390
from the same source code so if this is

396
00:19:06,390 --> 00:19:10,350
accurate and how insightful it is so for

397
00:19:10,350 --> 00:19:12,870
accuracy of course you need to have like

398
00:19:12,870 --> 00:19:15,750
a ground truth so we started from a data

399
00:19:15,750 --> 00:19:17,970
set of couple of Android malware samples

400
00:19:17,970 --> 00:19:19,920
that come from University of Michigan

401
00:19:19,920 --> 00:19:22,680
that they have collected malware samples

402
00:19:22,680 --> 00:19:26,070
and the relative source code and so we

403
00:19:26,070 --> 00:19:28,230
tested that by basically running these

404
00:19:28,230 --> 00:19:31,110
our approach on one sample and then

405
00:19:31,110 --> 00:19:32,370
matching it against the remaining

406
00:19:32,370 --> 00:19:35,010
binaries and seeing where the match is

407
00:19:35,010 --> 00:19:38,750
where of course even with source

408
00:19:38,750 --> 00:19:41,490
manually verifying messes and in

409
00:19:41,490 --> 00:19:46,410
particular non messes is kind of long so

410
00:19:46,410 --> 00:19:50,310
it's it's basically years of PhD student

411
00:19:50,310 --> 00:19:52,230
time which is a very precious resource

412
00:19:52,230 --> 00:19:54,119
that should not be wasted

413
00:19:54,119 --> 00:19:57,629
so we basically use that attract we use

414
00:19:57,629 --> 00:19:59,219
the moss which is a very well-known

415
00:19:59,219 --> 00:20:02,159
called plagiarism detector that most

416
00:20:02,159 --> 00:20:04,229
professors used to the text students

417
00:20:04,229 --> 00:20:06,149
that sheet attack Samson copy the same

418
00:20:06,149 --> 00:20:10,439
code we fed the mouse to the source code

419
00:20:10,439 --> 00:20:11,909
corresponding to decided to the

420
00:20:11,909 --> 00:20:14,219
behaviors method it against the other

421
00:20:14,219 --> 00:20:20,069
sources and basically we expect our tool

422
00:20:20,069 --> 00:20:23,279
to match in cases where most returns

423
00:20:23,279 --> 00:20:27,959
high similarity discuss so this is kind

424
00:20:27,959 --> 00:20:30,149
of the most useless graph that they've

425
00:20:30,149 --> 00:20:32,759
ever drawn in my career so every time we

426
00:20:32,759 --> 00:20:34,679
present this graph I realize that it

427
00:20:34,679 --> 00:20:38,489
sucks so basically the blue bar is the

428
00:20:38,489 --> 00:20:41,459
result returned by moss on in a

429
00:20:41,459 --> 00:20:44,749
percentage of match against the couple's

430
00:20:44,749 --> 00:20:48,629
behavior bought so basically what we

431
00:20:48,629 --> 00:20:50,639
would expect is that reanimator returns

432
00:20:50,639 --> 00:20:55,109
exactly the same levels of match but it

433
00:20:55,109 --> 00:20:57,359
doesn't obviously always happen so in

434
00:20:57,359 --> 00:21:01,229
this graph the difference here is the

435
00:21:01,229 --> 00:21:03,239
most likely things to be false negatives

436
00:21:03,239 --> 00:21:06,749
most says these matches I say this

437
00:21:06,749 --> 00:21:09,659
doesn't match these things here are the

438
00:21:09,659 --> 00:21:11,609
most likely was to be false negative or

439
00:21:11,609 --> 00:21:14,879
positive so Moss says no this thing is

440
00:21:14,879 --> 00:21:17,939
not the same and I say no this thing is

441
00:21:17,939 --> 00:21:21,209
the same so we and when i say we i

442
00:21:21,209 --> 00:21:23,039
intend the first author of the paper

443
00:21:23,039 --> 00:21:24,869
with a PhD student that was a PhD

444
00:21:24,869 --> 00:21:28,229
student at the hem um manually

445
00:21:28,229 --> 00:21:29,729
investigated false positives and

446
00:21:29,729 --> 00:21:32,129
negatives and found out that we have a

447
00:21:32,129 --> 00:21:34,859
false negative rate of course we do it's

448
00:21:34,859 --> 00:21:37,079
a completely unsupervised way of

449
00:21:37,079 --> 00:21:40,069
matching things but it's relatively low

450
00:21:40,069 --> 00:21:43,619
it turned out to be about 1.5 percent on

451
00:21:43,619 --> 00:21:47,069
our data set so few tens of of

452
00:21:47,069 --> 00:21:52,279
mismatches which mostly relates to small

453
00:21:52,279 --> 00:21:55,769
genotypes small pieces of code that are

454
00:21:55,769 --> 00:21:57,869
so small that they do not really work

455
00:21:57,869 --> 00:21:59,609
well with the idea of creating sub

456
00:21:59,609 --> 00:22:05,939
graphs of size x the cool thing is that

457
00:22:05,939 --> 00:22:07,950
we found no false positives

458
00:22:07,950 --> 00:22:11,039
near neither here nor by running other

459
00:22:11,039 --> 00:22:13,769
tests nor by for instance running a test

460
00:22:13,769 --> 00:22:16,799
where we try to match that code on an

461
00:22:16,799 --> 00:22:19,080
enormous code base of a Windows computer

462
00:22:19,080 --> 00:22:21,210
we've installed all of the software that

463
00:22:21,210 --> 00:22:23,639
we could think of just to see if these

464
00:22:23,639 --> 00:22:30,899
with match somewhere randomly this is

465
00:22:30,899 --> 00:22:33,480
partially robust when recompiling from

466
00:22:33,480 --> 00:22:35,730
the same source its robust against

467
00:22:35,730 --> 00:22:38,070
trying to change the compilation options

468
00:22:38,070 --> 00:22:40,649
or compiler versions or by embedding

469
00:22:40,649 --> 00:22:44,880
code in different pieces of programs but

470
00:22:44,880 --> 00:22:46,649
for instance it's not really robust

471
00:22:46,649 --> 00:22:48,029
against the completely different

472
00:22:48,029 --> 00:22:49,799
compiler because calling conventions

473
00:22:49,799 --> 00:22:52,260
because different instructions actually

474
00:22:52,260 --> 00:22:55,470
this difference is mostly due to the way

475
00:22:55,470 --> 00:22:59,220
we extract things than to the approach

476
00:22:59,220 --> 00:23:02,970
itself but still that's data and that's

477
00:23:02,970 --> 00:23:06,750
what I've show it so I'm they will just

478
00:23:06,750 --> 00:23:09,720
accelerate and leave you to go through

479
00:23:09,720 --> 00:23:12,179
the whole data set if you if you're

480
00:23:12,179 --> 00:23:13,590
interested the paper is called

481
00:23:13,590 --> 00:23:15,419
reanimator you find it in i triple e

482
00:23:15,419 --> 00:23:19,110
security and privacy 2010 but basically

483
00:23:19,110 --> 00:23:23,159
um you will if you browse through the

484
00:23:23,159 --> 00:23:26,159
paper you will find that this actually

485
00:23:26,159 --> 00:23:28,679
discovers a number of instances where a

486
00:23:28,679 --> 00:23:31,529
behavior is implemented in BOTS and it's

487
00:23:31,529 --> 00:23:33,179
not be shared but this is obvious

488
00:23:33,179 --> 00:23:34,889
because but of course our command and

489
00:23:34,889 --> 00:23:36,899
control things if you don't have the

490
00:23:36,899 --> 00:23:39,120
comments coming in from the CNC they

491
00:23:39,120 --> 00:23:42,750
will not show a behavior then we decided

492
00:23:42,750 --> 00:23:45,299
that we wanted to use the same idea to

493
00:23:45,299 --> 00:23:47,159
track the malware evolution over time so

494
00:23:47,159 --> 00:23:49,370
once again for those that are not really

495
00:23:49,370 --> 00:23:54,539
really proficient with malware spider

496
00:23:54,539 --> 00:23:59,850
than water so most malware nowadays

497
00:23:59,850 --> 00:24:03,299
automatically updates it has an update

498
00:24:03,299 --> 00:24:05,399
mechanism just like the windows update

499
00:24:05,399 --> 00:24:08,120
mechanism only differences that it works

500
00:24:08,120 --> 00:24:13,440
and basically what we did was we

501
00:24:13,440 --> 00:24:15,269
collected the number of malware families

502
00:24:15,269 --> 00:24:17,730
the food safe update collected all of

503
00:24:17,730 --> 00:24:20,580
the updates and try to understand

504
00:24:20,580 --> 00:24:23,130
how they were updated why they were

505
00:24:23,130 --> 00:24:27,390
updated what they were changing so the

506
00:24:27,390 --> 00:24:29,730
idea is that we have a our malware

507
00:24:29,730 --> 00:24:31,740
sample we let it connect to the update

508
00:24:31,740 --> 00:24:33,929
server over time collect all of the

509
00:24:33,929 --> 00:24:36,240
variants perform a binary curr a

510
00:24:36,240 --> 00:24:37,890
comparison to see what are the code

511
00:24:37,890 --> 00:24:41,510
changes but also perform a behavioral

512
00:24:41,510 --> 00:24:43,590
instruction with our with the same

513
00:24:43,590 --> 00:24:45,960
technique that i showed before matching

514
00:24:45,960 --> 00:24:47,720
the code and the behavior together and

515
00:24:47,720 --> 00:24:50,429
try to figure out how this binary

516
00:24:50,429 --> 00:24:53,309
changes map or not to behavior changes

517
00:24:53,309 --> 00:24:56,940
so the idea the question is do these

518
00:24:56,940 --> 00:24:59,340
people change things because they are

519
00:24:59,340 --> 00:25:01,590
just patching stuff or maybe they are

520
00:25:01,590 --> 00:25:04,049
just changing stuff just to screw up

521
00:25:04,049 --> 00:25:06,690
with signatures or do they actually

522
00:25:06,690 --> 00:25:11,960
change things implement new things so um

523
00:25:11,960 --> 00:25:14,370
besides some global results which

524
00:25:14,370 --> 00:25:16,289
actually say that for instance there are

525
00:25:16,289 --> 00:25:20,850
families that from one day to the next f

526
00:25:20,850 --> 00:25:24,750
as much as twelve percent or twenty

527
00:25:24,750 --> 00:25:26,600
percent of their code added or removed

528
00:25:26,600 --> 00:25:29,490
so with significant changes from one

529
00:25:29,490 --> 00:25:33,000
sample to the next but this is a kind of

530
00:25:33,000 --> 00:25:35,190
analysis that you can do very simply by

531
00:25:35,190 --> 00:25:37,500
just comparing the binaries what you can

532
00:25:37,500 --> 00:25:39,299
do by using our techniques is that you

533
00:25:39,299 --> 00:25:42,019
can break down that changes over the

534
00:25:42,019 --> 00:25:45,750
behaviors so for instance we know that

535
00:25:45,750 --> 00:25:49,169
the running a DNS query is such a

536
00:25:49,169 --> 00:25:51,990
standard thing that from one sample to

537
00:25:51,990 --> 00:25:54,840
the next the average is that the two

538
00:25:54,840 --> 00:25:57,809
code sets are always the same nobody

539
00:25:57,809 --> 00:26:00,179
changes that but there is one sample

540
00:26:00,179 --> 00:26:03,389
over demands of observation which is a

541
00:26:03,389 --> 00:26:05,909
completely different behavior and then

542
00:26:05,909 --> 00:26:08,039
the behavior remains implemented in that

543
00:26:08,039 --> 00:26:09,779
completely different way for the

544
00:26:09,779 --> 00:26:13,700
subsequent samples if I'm an analyst

545
00:26:13,700 --> 00:26:17,639
this may be interesting out of all those

546
00:26:17,639 --> 00:26:20,220
samples this one and the specific

547
00:26:20,220 --> 00:26:22,830
behavior I may want to look at why did

548
00:26:22,830 --> 00:26:24,630
they change the way that the resolve DNS

549
00:26:24,630 --> 00:26:27,830
which doesn't make that lot of sense um

550
00:26:27,830 --> 00:26:32,460
or if I have a generator of UDP traffic

551
00:26:32,460 --> 00:26:34,020
and there is one sin

552
00:26:34,020 --> 00:26:36,000
where these UDP traffic generator has

553
00:26:36,000 --> 00:26:38,910
been changed why did they change it

554
00:26:38,910 --> 00:26:40,860
because maybe they changed it because

555
00:26:40,860 --> 00:26:44,370
they needed a different set of options

556
00:26:44,370 --> 00:26:46,440
for an exploit that they were running or

557
00:26:46,440 --> 00:26:48,240
maybe they changed it because they patch

558
00:26:48,240 --> 00:26:51,090
the bag or a vulnerability of some sort

559
00:26:51,090 --> 00:26:52,830
and I may be interested in looking at

560
00:26:52,830 --> 00:26:55,860
that so the paper is actually much

561
00:26:55,860 --> 00:26:57,780
longer than this and that's being

562
00:26:57,780 --> 00:27:00,270
published the toxic so you can go and

563
00:27:00,270 --> 00:27:04,050
and fetch it online but the insight that

564
00:27:04,050 --> 00:27:06,330
we add is that well of course there are

565
00:27:06,330 --> 00:27:08,100
families that are more actively

566
00:27:08,100 --> 00:27:09,660
developed than others there are younger

567
00:27:09,660 --> 00:27:12,270
families and older families but even in

568
00:27:12,270 --> 00:27:14,070
families that are not really actively

569
00:27:14,070 --> 00:27:16,320
developed there are some specific points

570
00:27:16,320 --> 00:27:18,180
in time where people deploy a new

571
00:27:18,180 --> 00:27:24,060
version of some behaviors the effort

572
00:27:24,060 --> 00:27:25,710
behind this is difficult to actually

573
00:27:25,710 --> 00:27:27,600
estimate because we have blocks in

574
00:27:27,600 --> 00:27:30,390
assembly not really line of code but

575
00:27:30,390 --> 00:27:32,970
since for instance for well for

576
00:27:32,970 --> 00:27:35,250
europeans and italians those four

577
00:27:35,250 --> 00:27:41,490
non-europeans zeus we have different we

578
00:27:41,490 --> 00:27:44,700
have also the source code we estimate

579
00:27:44,700 --> 00:27:46,830
that for instance for the average day to

580
00:27:46,830 --> 00:27:50,550
day update of some sales variance we are

581
00:27:50,550 --> 00:27:52,380
around the 200 lines of code that have

582
00:27:52,380 --> 00:27:53,520
been edited so every day there's

583
00:27:53,520 --> 00:27:55,620
somebody that patches and commits and

584
00:27:55,620 --> 00:27:58,470
compiles 200 lines of code but there are

585
00:27:58,470 --> 00:28:01,650
pics of nine thousand lines of code this

586
00:28:01,650 --> 00:28:05,330
is a significant engineering effort so

587
00:28:05,330 --> 00:28:07,830
there's a there's a significant amount

588
00:28:07,830 --> 00:28:10,620
of money and of time of people spent in

589
00:28:10,620 --> 00:28:15,000
developing malwa actually one of the

590
00:28:15,000 --> 00:28:19,220
side effects of this research was this

591
00:28:19,220 --> 00:28:22,620
with a really matter we were specifying

592
00:28:22,620 --> 00:28:24,510
an interesting behavior and we were

593
00:28:24,510 --> 00:28:26,340
going and tracking it across the data

594
00:28:26,340 --> 00:28:29,100
set and we were doing that manually this

595
00:28:29,100 --> 00:28:33,390
is interesting tell me all about it with

596
00:28:33,390 --> 00:28:36,540
this approach we actually wanted to

597
00:28:36,540 --> 00:28:38,160
track the changes across the whole

598
00:28:38,160 --> 00:28:40,830
malware for some of them we could

599
00:28:40,830 --> 00:28:43,320
manually say that this was this specific

600
00:28:43,320 --> 00:28:44,880
behavior as in the tables that I've

601
00:28:44,880 --> 00:28:46,040
shown you

602
00:28:46,040 --> 00:28:47,840
but we wanted to do this in general

603
00:28:47,840 --> 00:28:49,940
overall the malware so we wanted to find

604
00:28:49,940 --> 00:28:52,190
a general definition of what could

605
00:28:52,190 --> 00:28:55,550
constitute a behavior I unit of behavior

606
00:28:55,550 --> 00:28:58,760
of an hour and the pacification that we

607
00:28:58,760 --> 00:29:01,970
found its cheek you can challenge it but

608
00:29:01,970 --> 00:29:03,200
the best definition that we found is

609
00:29:03,200 --> 00:29:09,860
this that basically a behavior in a

610
00:29:09,860 --> 00:29:12,770
mother in a windows malwa is so in

611
00:29:12,770 --> 00:29:18,730
malware is a collection of API calls

612
00:29:18,730 --> 00:29:22,910
that are connected between each other by

613
00:29:22,910 --> 00:29:26,230
exchange of parameters by tainting and

614
00:29:26,230 --> 00:29:29,600
that are repeated that happen all over

615
00:29:29,600 --> 00:29:33,380
the time so they don't happen casually

616
00:29:33,380 --> 00:29:36,590
just once but they kind of keep being

617
00:29:36,590 --> 00:29:39,920
repeated so it began thinking about it a

618
00:29:39,920 --> 00:29:43,040
living and thinking okay then maybe we

619
00:29:43,040 --> 00:29:45,560
can automatically extract from a large

620
00:29:45,560 --> 00:29:49,040
body of malware the description of

621
00:29:49,040 --> 00:29:51,470
behaviors of common malware behaviors

622
00:29:51,470 --> 00:29:55,520
and take care not necessarily malicious

623
00:29:55,520 --> 00:29:58,970
behaviors common malware behaviors they

624
00:29:58,970 --> 00:30:02,630
could be resolving dns but they are

625
00:30:02,630 --> 00:30:04,900
common behavior found in malware and

626
00:30:04,900 --> 00:30:07,310
this is actually a game changer because

627
00:30:07,310 --> 00:30:09,950
you can pick up these data set of

628
00:30:09,950 --> 00:30:11,510
malware and instead of analyzing the

629
00:30:11,510 --> 00:30:14,180
single samples you can go and tell the

630
00:30:14,180 --> 00:30:16,070
Machine okay generate me the description

631
00:30:16,070 --> 00:30:17,780
of the behaviors that are in here and

632
00:30:17,780 --> 00:30:20,240
then you can look at the behaviors and

633
00:30:20,240 --> 00:30:22,250
give a name to the specific behaviors if

634
00:30:22,250 --> 00:30:24,260
you recognize them and once you tag the

635
00:30:24,260 --> 00:30:27,290
behavior that name that tag is going to

636
00:30:27,290 --> 00:30:29,630
back propagate throughout the bed the

637
00:30:29,630 --> 00:30:31,700
database to all of these samples

638
00:30:31,700 --> 00:30:35,750
implementing that so um this is the

639
00:30:35,750 --> 00:30:39,080
intuition to go to data flow analysis

640
00:30:39,080 --> 00:30:40,760
I'm skipping over slides because

641
00:30:40,760 --> 00:30:45,140
otherwise I will go over time but

642
00:30:45,140 --> 00:30:48,290
basically we we are doing this by doing

643
00:30:48,290 --> 00:30:51,830
a major clustering analysis where what

644
00:30:51,830 --> 00:30:55,550
we cluster is not malware we are not

645
00:30:55,550 --> 00:30:57,140
clustering malware for instance to try

646
00:30:57,140 --> 00:30:58,780
to find the families we

647
00:30:58,780 --> 00:31:01,090
are clustering pieces of malware in

648
00:31:01,090 --> 00:31:04,120
order to find common behaviors which is

649
00:31:04,120 --> 00:31:05,710
kind of the thing that we had to explain

650
00:31:05,710 --> 00:31:08,020
four or five different times at four or

651
00:31:08,020 --> 00:31:10,030
five different sets of reviewers before

652
00:31:10,030 --> 00:31:12,250
this paper was accepted because it was

653
00:31:12,250 --> 00:31:13,810
actually kind of difficult to get this

654
00:31:13,810 --> 00:31:21,100
trip so we were there with our kind of

655
00:31:21,100 --> 00:31:22,930
models automatically extracted from

656
00:31:22,930 --> 00:31:25,000
malware and we were thinking okay can we

657
00:31:25,000 --> 00:31:27,910
do something more like automatically

658
00:31:27,910 --> 00:31:30,970
tagging this with not with a description

659
00:31:30,970 --> 00:31:34,600
that's for humans but with some tags

660
00:31:34,600 --> 00:31:41,200
some descriptors and we type that's the

661
00:31:41,200 --> 00:31:43,030
app that we've abused web know something

662
00:31:43,030 --> 00:31:44,740
something a little more semantic than a

663
00:31:44,740 --> 00:31:47,440
type actually but yeah but that's that's

664
00:31:47,440 --> 00:31:49,420
of obviously well that actually goes

665
00:31:49,420 --> 00:31:51,780
back to the connection between api's

666
00:31:51,780 --> 00:31:54,430
there's there's a lot of inference on

667
00:31:54,430 --> 00:31:56,170
types that I skipping but you may

668
00:31:56,170 --> 00:31:57,610
actually be interested in looking at

669
00:31:57,610 --> 00:32:05,890
that so um the we were saying okay so we

670
00:32:05,890 --> 00:32:08,700
have a list of api's of Windows api's

671
00:32:08,700 --> 00:32:11,410
how do we extract from a list of Windows

672
00:32:11,410 --> 00:32:14,590
API is a human description of what are

673
00:32:14,590 --> 00:32:18,940
they related to first first hot windows

674
00:32:18,940 --> 00:32:22,110
API is what documents windows API is

675
00:32:22,110 --> 00:32:26,680
technet go to tecnico cumin tation try

676
00:32:26,680 --> 00:32:29,380
to pause it worst idea in the world I

677
00:32:29,380 --> 00:32:31,960
presented the same thing at blue hat at

678
00:32:31,960 --> 00:32:34,000
Microsoft's internal security conference

679
00:32:34,000 --> 00:32:35,830
and there were like the windows people

680
00:32:35,830 --> 00:32:38,320
in front of music go there you don't

681
00:32:38,320 --> 00:32:42,970
want to do that technet sucks so so we

682
00:32:42,970 --> 00:32:45,100
went to the second best documentation of

683
00:32:45,100 --> 00:32:48,400
Windows API stack overflow

684
00:32:48,400 --> 00:32:51,460
and in Stack Overflow there's these

685
00:32:51,460 --> 00:32:52,840
interesting things that you tag your

686
00:32:52,840 --> 00:32:57,580
posts when you post so if we look at the

687
00:32:57,580 --> 00:33:01,000
posts related to a set of api's and we

688
00:33:01,000 --> 00:33:03,370
look at the tags and we do some semantic

689
00:33:03,370 --> 00:33:04,840
filtering on the tax so we throw away

690
00:33:04,840 --> 00:33:08,470
things that are useless we can extract

691
00:33:08,470 --> 00:33:11,200
descriptions so for instance this is an

692
00:33:11,200 --> 00:33:13,720
automatically extracted behavior which

693
00:33:13,720 --> 00:33:18,040
is basically opening a URL hmm don't

694
00:33:18,040 --> 00:33:20,890
open this if it's active because that's

695
00:33:20,890 --> 00:33:25,150
a malicious URL and these are the

696
00:33:25,150 --> 00:33:27,850
automatically extracted pag if you run

697
00:33:27,850 --> 00:33:29,800
this through stack overflow and you see

698
00:33:29,800 --> 00:33:32,800
how the posts that contain the same API

699
00:33:32,800 --> 00:33:35,350
is are tagged and of course there are

700
00:33:35,350 --> 00:33:36,550
some things that are not really

701
00:33:36,550 --> 00:33:38,230
interesting like Microsoft foundation

702
00:33:38,230 --> 00:33:40,870
classes but there are some things that

703
00:33:40,870 --> 00:33:43,630
describe that pretty well HTTP file

704
00:33:43,630 --> 00:33:48,100
internet file download so when we tag

705
00:33:48,100 --> 00:33:50,380
automatically the behaviors no of course

706
00:33:50,380 --> 00:33:53,980
not but we can give them some tags that

707
00:33:53,980 --> 00:33:56,230
are useful for an analyst that has in

708
00:33:56,230 --> 00:33:58,090
front of them like 3,000 and tagged

709
00:33:58,090 --> 00:33:59,740
behavior and that only interested in

710
00:33:59,740 --> 00:34:02,950
HTTP related ones to filter out the HTTP

711
00:34:02,950 --> 00:34:07,660
related ones fast then one of the things

712
00:34:07,660 --> 00:34:11,710
that we were asked by a nice reviewer

713
00:34:11,710 --> 00:34:14,409
that rejected our paper was yeah but how

714
00:34:14,409 --> 00:34:16,840
do you show that this does not only

715
00:34:16,840 --> 00:34:19,000
happen because you add your bunch of

716
00:34:19,000 --> 00:34:23,409
malware with your families in it and if

717
00:34:23,409 --> 00:34:24,909
you add a new family that you have never

718
00:34:24,909 --> 00:34:27,429
seen this family is probably not going

719
00:34:27,429 --> 00:34:30,639
to be covered by your bio research well

720
00:34:30,639 --> 00:34:32,800
we showed that by basically extracting

721
00:34:32,800 --> 00:34:34,719
one family at a time from our data set

722
00:34:34,719 --> 00:34:37,270
and showing that they were all covered

723
00:34:37,270 --> 00:34:39,340
because even the families are different

724
00:34:39,340 --> 00:34:40,929
and so the code implementing the

725
00:34:40,929 --> 00:34:42,909
behaviors is different the behaviors

726
00:34:42,909 --> 00:34:45,550
themselves are very self similar when

727
00:34:45,550 --> 00:34:47,380
you look at them at the generalized API

728
00:34:47,380 --> 00:34:52,630
level also we found that for instance by

729
00:34:52,630 --> 00:34:57,130
having experts out manually described to

730
00:34:57,130 --> 00:35:00,280
us behaviors that they would they knew

731
00:35:00,280 --> 00:35:02,290
some families will display

732
00:35:02,290 --> 00:35:06,760
a we had 45 description generated

733
00:35:06,760 --> 00:35:09,430
manually by analysts and the system

734
00:35:09,430 --> 00:35:12,300
automatically generated 43 of those

735
00:35:12,300 --> 00:35:15,160
hobbies early this is the ground truth

736
00:35:15,160 --> 00:35:18,130
behavior and the automatic behavior if

737
00:35:18,130 --> 00:35:20,230
you look at them at the hype a bi-level

738
00:35:20,230 --> 00:35:22,120
it's going to be it's going to be true

739
00:35:22,120 --> 00:35:25,420
but sometimes what happens here is that

740
00:35:25,420 --> 00:35:27,600
since the automatic extraction is

741
00:35:27,600 --> 00:35:29,860
automatic the machine does not

742
00:35:29,860 --> 00:35:32,080
understand what is the core component of

743
00:35:32,080 --> 00:35:34,600
a AP a set of API calls and what is just

744
00:35:34,600 --> 00:35:37,630
an accident and so here you may have an

745
00:35:37,630 --> 00:35:41,260
over specification which decreases over

746
00:35:41,260 --> 00:35:44,500
time depending on how many families you

747
00:35:44,500 --> 00:35:52,600
show 2d to the system so the conclusions

748
00:35:52,600 --> 00:35:55,450
on this are that you can combine dynamic

749
00:35:55,450 --> 00:35:57,850
and static analysis in order to tag and

750
00:35:57,850 --> 00:35:59,170
analyze them and clothed in malware

751
00:35:59,170 --> 00:36:01,630
connections to track the evolution of

752
00:36:01,630 --> 00:36:04,270
model of the time to automatically

753
00:36:04,270 --> 00:36:06,300
stratton also up to a certain point

754
00:36:06,300 --> 00:36:09,700
automatically tag behaviors we are now

755
00:36:09,700 --> 00:36:12,400
building this last system that is called

756
00:36:12,400 --> 00:36:14,500
Jack though so that it can be used in a

757
00:36:14,500 --> 00:36:16,870
crowdsourced fashion so you can use a

758
00:36:16,870 --> 00:36:19,630
plug-in in ida to basically analyze the

759
00:36:19,630 --> 00:36:22,240
malware that you're looking at see the

760
00:36:22,240 --> 00:36:24,490
components of behaviors automatically

761
00:36:24,490 --> 00:36:26,050
tag them if there is already a

762
00:36:26,050 --> 00:36:27,550
specification or write your own

763
00:36:27,550 --> 00:36:29,860
specification and propagate through the

764
00:36:29,860 --> 00:36:32,620
data set of malware and you can do this

765
00:36:32,620 --> 00:36:34,840
in a very agnostic way because since we

766
00:36:34,840 --> 00:36:36,460
are not transmitting the code of the

767
00:36:36,460 --> 00:36:39,400
sample but only the recognizing features

768
00:36:39,400 --> 00:36:41,860
of those sets of API calls you are not

769
00:36:41,860 --> 00:36:43,510
sharing a sample that you may not be

770
00:36:43,510 --> 00:36:45,250
able legally to share with someone else

771
00:36:45,250 --> 00:36:48,430
but only your analysis and using a

772
00:36:48,430 --> 00:36:53,110
crowdsourced analysis of data sets um in

773
00:36:53,110 --> 00:36:55,090
the bigger picture what this can help to

774
00:36:55,090 --> 00:36:56,680
do is to characterize the nursery's

775
00:36:56,680 --> 00:36:59,170
based on the artifacts because of course

776
00:36:59,170 --> 00:37:01,480
you create a map of behaviors and then

777
00:37:01,480 --> 00:37:03,550
for each behavior you create a set of

778
00:37:03,550 --> 00:37:05,950
different implementations the

779
00:37:05,950 --> 00:37:07,570
implementation actually actually

780
00:37:07,570 --> 00:37:11,350
characterizes the author you can extract

781
00:37:11,350 --> 00:37:13,420
actionable intelligence because you can

782
00:37:13,420 --> 00:37:15,920
see the new same view

783
00:37:15,920 --> 00:37:18,530
you behaviors instead of the new samples

784
00:37:18,530 --> 00:37:21,490
because the new samples are too many and

785
00:37:21,490 --> 00:37:24,440
we hope to provide a community-oriented

786
00:37:24,440 --> 00:37:28,400
methodology to improve malware analysis

787
00:37:28,400 --> 00:37:32,329
in this way so with this I am done you

788
00:37:32,329 --> 00:37:35,210
can send me feedback Stefano Dotson edit

789
00:37:35,210 --> 00:37:37,700
poly me that I t is my email or you can

790
00:37:37,700 --> 00:37:41,359
tweet at me I like it the 12 depends on

791
00:37:41,359 --> 00:37:44,660
what you treated me better still most of

792
00:37:44,660 --> 00:37:46,640
the work presented is not my own only

793
00:37:46,640 --> 00:37:50,150
it's been done with Chris Google at UCSB

794
00:37:50,150 --> 00:37:53,240
with Paolo Madonna comparative now

795
00:37:53,240 --> 00:37:55,160
senior engineer at last line used to be

796
00:37:55,160 --> 00:37:57,140
a PhD student in Vienna when we did work

797
00:37:57,140 --> 00:37:59,930
together I'm hanging here that was now

798
00:37:59,930 --> 00:38:02,890
professor at no.15 University in Boston

799
00:38:02,890 --> 00:38:05,690
Martina Lindor fur was recently left the

800
00:38:05,690 --> 00:38:08,230
technical university of vienna and

801
00:38:08,230 --> 00:38:10,299
people from politecnico di milano

802
00:38:10,299 --> 00:38:13,430
alessandro di federico mario paulino

803
00:38:13,430 --> 00:38:15,190
andres court he was now working

804
00:38:15,190 --> 00:38:19,220
somewhere in Dubai we dissolve an excuse

805
00:38:19,220 --> 00:38:23,270
now a darkness that and Federico Mataji

806
00:38:23,270 --> 00:38:26,930
who's now with trend micro of course if

807
00:38:26,930 --> 00:38:30,740
all over this oh and Mario is shortly

808
00:38:30,740 --> 00:38:32,630
going to be a former polym students

809
00:38:32,630 --> 00:38:35,119
because i'm going to hand him over is is

810
00:38:35,119 --> 00:38:39,369
very much well earned doctorate soon so

811
00:38:39,369 --> 00:38:42,890
I'm of course there's good things in

812
00:38:42,890 --> 00:38:46,490
here their work there's arrows in here

813
00:38:46,490 --> 00:38:50,119
it's my fault and there's an XKCD

814
00:38:50,119 --> 00:38:52,400
cartoon here that I really like there's

815
00:38:52,400 --> 00:38:54,530
foot pulling a lever getting and Zod

816
00:38:54,530 --> 00:38:57,410
then the normal person says whoops maybe

817
00:38:57,410 --> 00:38:59,450
you should not do that again and instead

818
00:38:59,450 --> 00:39:00,829
the scientist says let's see if it

819
00:39:00,829 --> 00:39:05,530
happens every time and that's me

820
00:39:16,620 --> 00:39:26,830
questions sir oky playful and italiano

821
00:39:26,830 --> 00:39:31,840
pilot repetto you English a comb it

822
00:39:31,840 --> 00:39:34,390
hasn't even got to see that was josh is

823
00:39:34,390 --> 00:39:36,550
Constance a comedian sistema destrucción

824
00:39:36,550 --> 00:39:39,880
it just ishe off who's coming to Posada

825
00:39:39,880 --> 00:39:41,800
the same pezuela live women don't wanna

826
00:39:41,800 --> 00:39:44,050
represent an assembly complimentary

827
00:39:44,050 --> 00:39:47,470
bersama funciona meant equivalent so so

828
00:39:47,470 --> 00:39:49,180
the question is about to station in

829
00:39:49,180 --> 00:39:53,200
particular about llvm the real answer is

830
00:39:53,200 --> 00:39:55,450
we don't that's not the focus of our

831
00:39:55,450 --> 00:39:59,590
research actually if you I don't know if

832
00:39:59,590 --> 00:40:02,230
you have seen it at blackhat but in

833
00:40:02,230 --> 00:40:05,530
Vegas a couple of my students presented

834
00:40:05,530 --> 00:40:08,230
a very generic and Parker extractor that

835
00:40:08,230 --> 00:40:11,080
is actually the prepended to this system

836
00:40:11,080 --> 00:40:13,090
but it doesn't deal with what you are

837
00:40:13,090 --> 00:40:16,870
describing so we are yeah precisely

838
00:40:16,870 --> 00:40:20,170
precisely precisely but yeah and the

839
00:40:20,170 --> 00:40:22,090
same thing happens for instance if you

840
00:40:22,090 --> 00:40:24,970
have malware that uses what was the name

841
00:40:24,970 --> 00:40:27,400
a row tulum i think the the thing where

842
00:40:27,400 --> 00:40:29,440
you basically were designing a different

843
00:40:29,440 --> 00:40:31,930
virtual machine and writing the code in

844
00:40:31,930 --> 00:40:34,870
a different assembly that that's all I

845
00:40:34,870 --> 00:40:37,540
mean those extreme tricks we don't deal

846
00:40:37,540 --> 00:40:39,280
because that's not the business of this

847
00:40:39,280 --> 00:40:41,770
specific system but that's that's kind

848
00:40:41,770 --> 00:40:43,660
of a limitation because if we are not

849
00:40:43,660 --> 00:40:46,800
able to get to and x86 in this case

850
00:40:46,800 --> 00:40:49,630
representation we cannot really do this

851
00:40:49,630 --> 00:40:52,240
work through the other limitation which

852
00:40:52,240 --> 00:40:54,670
is majoring this work is that this is

853
00:40:54,670 --> 00:40:57,160
obviously meant as it is right now it's

854
00:40:57,160 --> 00:40:59,650
meant for windows because that's where

855
00:40:59,650 --> 00:41:01,690
the majority of malware is with the

856
00:41:01,690 --> 00:41:03,400
possible exception of Android for which

857
00:41:03,400 --> 00:41:05,290
we have another whole line of research

858
00:41:05,290 --> 00:41:09,730
that is that is completely separated but

859
00:41:09,730 --> 00:41:11,950
there's no reason why this should be in

860
00:41:11,950 --> 00:41:14,530
theory limited to windows the only major

861
00:41:14,530 --> 00:41:16,960
conceptual issue is what you define as

862
00:41:16,960 --> 00:41:19,240
behavior on the other platform here its

863
00:41:19,240 --> 00:41:20,010
collections

864
00:41:20,010 --> 00:41:23,340
system of API calls maybe on unix it

865
00:41:23,340 --> 00:41:25,440
would be collections of system calls or

866
00:41:25,440 --> 00:41:27,900
maybe not we would need to test it and I

867
00:41:27,900 --> 00:41:32,640
cannot say it is but conceptually like I

868
00:41:32,640 --> 00:41:35,550
know but in theory but and unless I

869
00:41:35,550 --> 00:41:37,950
build it and they tested i cannot i can

870
00:41:37,950 --> 00:41:43,279
okay perfect awesome other questions

871
00:41:43,940 --> 00:41:47,400
well okay i hope it was because i was

872
00:41:47,400 --> 00:41:49,080
clear not because it was completely

873
00:41:49,080 --> 00:41:51,630
unintelligible but thank you very much

874
00:41:51,630 --> 00:41:53,250
and if you have any other questions that

875
00:41:53,250 --> 00:41:54,930
pops up you will find me near the bear

876
00:41:54,930 --> 00:41:57,259
stand

