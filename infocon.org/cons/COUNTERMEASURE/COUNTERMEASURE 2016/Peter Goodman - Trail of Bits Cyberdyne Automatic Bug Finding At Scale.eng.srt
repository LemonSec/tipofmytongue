1
00:00:00,210 --> 00:00:06,320
[Music]

2
00:00:17,060 --> 00:00:23,890
[Music]

3
00:00:21,070 --> 00:00:25,570
my objective today is that you should

4
00:00:23,890 --> 00:00:28,420
come out of this talk having an

5
00:00:25,570 --> 00:00:31,779
understanding of how automated bug

6
00:00:28,420 --> 00:00:36,190
finding systems work our bug finding

7
00:00:31,779 --> 00:00:38,800
system deploys two approaches symbolic

8
00:00:36,190 --> 00:00:39,940
execution and coverage guided fuzzing if

9
00:00:38,800 --> 00:00:42,010
you're not familiar with these

10
00:00:39,940 --> 00:00:47,559
approaches we're going to take baby

11
00:00:42,010 --> 00:00:51,760
steps up to them and there's sort of two

12
00:00:47,559 --> 00:00:55,120
running themes there is how do we layout

13
00:00:51,760 --> 00:00:57,099
the system so that if you know a fancy

14
00:00:55,120 --> 00:01:00,578
new bug signing approach comes along we

15
00:00:57,100 --> 00:01:02,739
can integrate it and how can we kind of

16
00:01:00,579 --> 00:01:05,619
architect it all to work so that we can

17
00:01:02,739 --> 00:01:08,860
take independent bug finding systems and

18
00:01:05,619 --> 00:01:10,060
actually get them to cooperate even if

19
00:01:08,860 --> 00:01:13,240
the systems weren't designed to

20
00:01:10,060 --> 00:01:15,790
cooperate in the first place so before

21
00:01:13,240 --> 00:01:19,449
we get into this let's have a bit of

22
00:01:15,790 --> 00:01:22,180
history we created Cyberdyne for the

23
00:01:19,450 --> 00:01:26,530
DARPA cyber grand challenge this was a

24
00:01:22,180 --> 00:01:28,869
multi-year competition there was seven

25
00:01:26,530 --> 00:01:31,659
finalists we weren't one of the

26
00:01:28,869 --> 00:01:34,479
finalists however Cyberdyne itself was

27
00:01:31,659 --> 00:01:37,689
the bug finding system in the team that

28
00:01:34,479 --> 00:01:41,340
placed force the cyber grand challenge

29
00:01:37,689 --> 00:01:43,658
it is a capture the flag competition

30
00:01:41,340 --> 00:01:46,240
this means that you have a number of

31
00:01:43,659 --> 00:01:48,369
competitors and they are given binary

32
00:01:46,240 --> 00:01:51,039
programs they know nothing about these

33
00:01:48,369 --> 00:01:53,680
programs ahead of time they have to

34
00:01:51,040 --> 00:01:56,740
discover bugs in these programs they

35
00:01:53,680 --> 00:01:59,890
have to develop exploits for these bugs

36
00:01:56,740 --> 00:02:02,350
and they also need to patch the programs

37
00:01:59,890 --> 00:02:05,229
so that they are invulnerable to these

38
00:02:02,350 --> 00:02:06,969
bugs and the interesting thing about the

39
00:02:05,229 --> 00:02:09,429
DARPA cyber Grand Challenge is that the

40
00:02:06,969 --> 00:02:13,090
competitors themselves are machines

41
00:02:09,429 --> 00:02:17,049
there is no human intervention they have

42
00:02:13,090 --> 00:02:19,959
to do this all automatically and the way

43
00:02:17,049 --> 00:02:23,049
they score points is that they actually

44
00:02:19,959 --> 00:02:23,739
attack each other when you develop an

45
00:02:23,049 --> 00:02:27,940
exploit

46
00:02:23,739 --> 00:02:30,519
you attack competitor the attack works

47
00:02:27,940 --> 00:02:32,769
on their patched binaries if your attack

48
00:02:30,519 --> 00:02:34,930
succeeds you get points if you're

49
00:02:32,769 --> 00:02:38,470
patched binaries perform well you get

50
00:02:34,930 --> 00:02:40,450
points and so the competition itself it

51
00:02:38,470 --> 00:02:41,950
really shaped the design of Cyberdyne

52
00:02:40,450 --> 00:02:44,679
you know it had to be an automated

53
00:02:41,950 --> 00:02:45,250
system it has to be able to find bugs on

54
00:02:44,680 --> 00:02:47,860
its own

55
00:02:45,250 --> 00:02:49,629
it had to be robust against you know any

56
00:02:47,860 --> 00:02:51,519
type of program we didn't know what type

57
00:02:49,629 --> 00:02:56,140
of programs would get ahead of time

58
00:02:51,519 --> 00:02:57,549
obviously no human intervention and one

59
00:02:56,140 --> 00:03:00,700
of the things that it actually had to do

60
00:02:57,549 --> 00:03:03,519
is scale in the final event we had a

61
00:03:00,700 --> 00:03:07,030
large cluster of computers available to

62
00:03:03,519 --> 00:03:12,489
us and we want to make Matt like really

63
00:03:07,030 --> 00:03:14,950
maximize a usage of those computers so

64
00:03:12,489 --> 00:03:16,900
let's go see how we laid out Cyberdyne

65
00:03:14,950 --> 00:03:19,720
you know what is what is a bug finding

66
00:03:16,900 --> 00:03:22,840
system in general look like Cyberdyne is

67
00:03:19,720 --> 00:03:25,390
the running example and so I'll always

68
00:03:22,840 --> 00:03:26,950
tie it back to that but I will also talk

69
00:03:25,390 --> 00:03:31,418
about more generic tools that are

70
00:03:26,950 --> 00:03:35,018
available so our goal with with creating

71
00:03:31,419 --> 00:03:37,180
a bug finding system is that you know it

72
00:03:35,019 --> 00:03:39,549
should actually find bugs you know

73
00:03:37,180 --> 00:03:42,639
otherwise it's not a bug finding system

74
00:03:39,549 --> 00:03:45,819
it's just a system it should work on

75
00:03:42,639 --> 00:03:48,459
real programs and most importantly it

76
00:03:45,819 --> 00:03:50,108
should scale and I have a few

77
00:03:48,459 --> 00:03:53,319
definitions for what I mean by

78
00:03:50,109 --> 00:03:56,799
scalability first it should scale to

79
00:03:53,319 --> 00:03:59,560
real programs big programs you know it

80
00:03:56,799 --> 00:04:01,629
shouldn't just get stuck trying to find

81
00:03:59,560 --> 00:04:03,310
bugs at the beginning of a program when

82
00:04:01,629 --> 00:04:07,209
really those bugs are somewhere deep in

83
00:04:03,310 --> 00:04:09,910
the execution the other idea I have for

84
00:04:07,209 --> 00:04:12,519
scalability is that you should be able

85
00:04:09,910 --> 00:04:14,918
to take advantage of as many cpu

86
00:04:12,519 --> 00:04:17,079
resources as you are given you know

87
00:04:14,919 --> 00:04:19,978
first you should be able to take

88
00:04:17,079 --> 00:04:22,330
advantage of one computer and I mean

89
00:04:19,978 --> 00:04:24,729
complete advantage of one computer and

90
00:04:22,330 --> 00:04:27,250
once you can prove to me that you can

91
00:04:24,729 --> 00:04:30,490
use one computer effectively then you

92
00:04:27,250 --> 00:04:33,400
can have two and more and so we want to

93
00:04:30,490 --> 00:04:35,449
develop system that can actually scale

94
00:04:33,400 --> 00:04:38,568
out to as many computers as you

95
00:04:35,449 --> 00:04:41,419
as you have available to you and it

96
00:04:38,569 --> 00:04:43,370
should just work on big programs so

97
00:04:41,419 --> 00:04:45,378
we're going to actually work up to what

98
00:04:43,370 --> 00:04:48,439
a bug finding system in a large works

99
00:04:45,379 --> 00:04:50,479
looks like we're going to start small in

100
00:04:48,439 --> 00:04:53,569
fact we're going to smart with start

101
00:04:50,479 --> 00:04:56,330
with a very simple fuzzing setup if

102
00:04:53,569 --> 00:04:59,479
you're not familiar with fuzzing then

103
00:04:56,330 --> 00:05:03,409
the idea is this you have a program it

104
00:04:59,479 --> 00:05:07,610
has been written in such a way that it

105
00:05:03,409 --> 00:05:10,039
is expecting good valid input it's not

106
00:05:07,610 --> 00:05:12,469
expecting arbitrary input random input

107
00:05:10,039 --> 00:05:14,839
and so it's possible that this program

108
00:05:12,469 --> 00:05:18,099
will just crash if you give it random

109
00:05:14,839 --> 00:05:21,979
input but random input itself is usually

110
00:05:18,099 --> 00:05:24,498
not a very good way to find kind of deep

111
00:05:21,979 --> 00:05:26,930
bugs in a program to find logic bugs in

112
00:05:24,499 --> 00:05:30,409
the program and so ideally you want to

113
00:05:26,930 --> 00:05:33,379
give it mostly valid inputs like inputs

114
00:05:30,409 --> 00:05:35,899
that get the program into sort of a deep

115
00:05:33,379 --> 00:05:39,139
programs state and then you give it

116
00:05:35,899 --> 00:05:41,689
something slightly unexpected and so the

117
00:05:39,139 --> 00:05:43,520
way you a simple way of going about

118
00:05:41,689 --> 00:05:47,899
doing this is with something called a

119
00:05:43,520 --> 00:05:50,659
mutation engine it takes these realistic

120
00:05:47,899 --> 00:05:52,969
inputs or real inputs and then it just

121
00:05:50,659 --> 00:05:56,240
starts a flipping bits or flipping bytes

122
00:05:52,969 --> 00:05:59,479
it does a number of operations on those

123
00:05:56,240 --> 00:06:01,490
inputs and the hope is that when you've

124
00:05:59,479 --> 00:06:03,409
sort of corrupted these valid inputs

125
00:06:01,490 --> 00:06:07,009
something interesting is going to happen

126
00:06:03,409 --> 00:06:09,438
and if you don't feel like creating a

127
00:06:07,009 --> 00:06:11,180
mutation engine on your own there's some

128
00:06:09,439 --> 00:06:13,490
really really great ones out there for

129
00:06:11,180 --> 00:06:17,800
danza's one of them we actually use it

130
00:06:13,490 --> 00:06:21,169
in Cyberdyne as these off is another one

131
00:06:17,800 --> 00:06:24,800
so this is sort of the process of a

132
00:06:21,169 --> 00:06:28,279
simple fuzzing campaign we need eight

133
00:06:24,800 --> 00:06:30,589
inputs you know this we can do as many

134
00:06:28,279 --> 00:06:33,110
mutations as we want generate millions

135
00:06:30,589 --> 00:06:35,599
or billions of inputs and we spend a bit

136
00:06:33,110 --> 00:06:38,930
of time doing this we can execute those

137
00:06:35,599 --> 00:06:41,149
inputs hopefully one of these inputs or

138
00:06:38,930 --> 00:06:43,039
more than is going to cause crash we

139
00:06:41,149 --> 00:06:44,449
don't really know though and luckily

140
00:06:43,039 --> 00:06:47,159
these two steps they can be done

141
00:06:44,449 --> 00:06:49,110
concurrently you know we can

142
00:06:47,160 --> 00:06:50,610
we can very easily scale the mutation

143
00:06:49,110 --> 00:06:55,260
execution they're completely independent

144
00:06:50,610 --> 00:06:56,940
tasks and so we're waiting we're waiting

145
00:06:55,260 --> 00:07:00,030
hopefully bugs are going to find a fall

146
00:06:56,940 --> 00:07:03,330
out you know that's the whole point of

147
00:07:00,030 --> 00:07:05,669
this of this fuzzing campaign but what

148
00:07:03,330 --> 00:07:07,740
if bugs don't fall out you know we we've

149
00:07:05,670 --> 00:07:08,490
wasted our time or we might have wasted

150
00:07:07,740 --> 00:07:11,190
our time

151
00:07:08,490 --> 00:07:13,200
those GPU resources we can't we didn't

152
00:07:11,190 --> 00:07:17,219
we have no way of really justifying our

153
00:07:13,200 --> 00:07:19,710
use and the problem is that you know

154
00:07:17,220 --> 00:07:22,740
this simple bug signing set up with

155
00:07:19,710 --> 00:07:25,489
sizing there was no accountability we

156
00:07:22,740 --> 00:07:28,620
didn't have a metric to show that our

157
00:07:25,490 --> 00:07:31,640
bug signing process was actually making

158
00:07:28,620 --> 00:07:35,490
progress you know if you think of

159
00:07:31,640 --> 00:07:37,919
deploying a fuzzing campaign into the

160
00:07:35,490 --> 00:07:39,960
cloud you should be able to justify at

161
00:07:37,920 --> 00:07:42,060
the end of the day that it has made

162
00:07:39,960 --> 00:07:45,180
progress that you are potentially

163
00:07:42,060 --> 00:07:48,000
getting closer to finding a bug and so

164
00:07:45,180 --> 00:07:51,210
the sort of most common way of measuring

165
00:07:48,000 --> 00:07:54,210
progress is to kind of ask yourself has

166
00:07:51,210 --> 00:07:57,780
something new happened have we created a

167
00:07:54,210 --> 00:08:01,500
mutated input that has generated some

168
00:07:57,780 --> 00:08:04,349
new event that we can measure and the

169
00:08:01,500 --> 00:08:07,070
sort of industry-wide and academia wide

170
00:08:04,350 --> 00:08:09,600
approach to this is called code coverage

171
00:08:07,070 --> 00:08:11,940
it's also you know there's other ways of

172
00:08:09,600 --> 00:08:15,419
doing it like branch coverage but the

173
00:08:11,940 --> 00:08:17,969
basic idea is we have produced an input

174
00:08:15,419 --> 00:08:20,669
that causes you know some line or some

175
00:08:17,970 --> 00:08:25,310
instruction of code to be executed that

176
00:08:20,669 --> 00:08:27,990
no other input has executed before and

177
00:08:25,310 --> 00:08:31,169
you know this is great you know we can

178
00:08:27,990 --> 00:08:33,810
now run our fuzzing campaign we can

179
00:08:31,169 --> 00:08:35,699
measure code coverage we can produce a

180
00:08:33,809 --> 00:08:37,348
fancy little graph that shows like okay

181
00:08:35,700 --> 00:08:39,539
we got code coverage we got more code

182
00:08:37,349 --> 00:08:41,760
coverage we got more code coverage now

183
00:08:39,539 --> 00:08:44,520
we've got this accountability but

184
00:08:41,760 --> 00:08:47,790
eventually we're going to see decreasing

185
00:08:44,520 --> 00:08:50,220
marginal returns the code coverage you

186
00:08:47,790 --> 00:08:52,650
know it might just sort of top out and

187
00:08:50,220 --> 00:08:54,780
go flat and then we're stuck twiddling

188
00:08:52,650 --> 00:08:58,050
our thumbs again like before we're not

189
00:08:54,780 --> 00:09:00,360
showing progress and so the most common

190
00:08:58,050 --> 00:09:03,059
way of getting around this

191
00:09:00,360 --> 00:09:06,480
is to use something called coverage

192
00:09:03,059 --> 00:09:08,509
guided fuzzing and so the idealist

193
00:09:06,480 --> 00:09:11,730
coverage guided fuzzing is we say okay

194
00:09:08,509 --> 00:09:14,639
we've got this metric this metric says

195
00:09:11,730 --> 00:09:17,069
that some input has has caused a new

196
00:09:14,639 --> 00:09:19,739
event happened that must be an

197
00:09:17,069 --> 00:09:22,349
interesting input so let's send it back

198
00:09:19,739 --> 00:09:25,049
around send it back into the fuzzer and

199
00:09:22,350 --> 00:09:27,839
tell the fuzzer to start mutating that

200
00:09:25,049 --> 00:09:30,689
input and I think the best analogy for

201
00:09:27,839 --> 00:09:33,209
why this is a useful approach is hill

202
00:09:30,689 --> 00:09:36,689
climbing you know the we started with a

203
00:09:33,209 --> 00:09:39,299
seed input we mutated it it got new code

204
00:09:36,689 --> 00:09:42,269
coverage it's kind of like we we went up

205
00:09:39,299 --> 00:09:44,610
some steps and now we want to go higher

206
00:09:42,269 --> 00:09:47,970
up on the mountain and so we mutated

207
00:09:44,610 --> 00:09:50,069
again and hopefully we're going to build

208
00:09:47,970 --> 00:09:53,939
on the progress that we got based on the

209
00:09:50,069 --> 00:09:57,019
first mutation and so this simple set up

210
00:09:53,939 --> 00:10:00,089
we've got that original kind of pipeline

211
00:09:57,019 --> 00:10:02,610
take inputs mutate them execute them

212
00:10:00,089 --> 00:10:05,850
hopefully crashes fall out otherwise

213
00:10:02,610 --> 00:10:11,100
measure code coverage send them back

214
00:10:05,850 --> 00:10:14,009
around there is a great open source tool

215
00:10:11,100 --> 00:10:17,249
for that already does this for you it's

216
00:10:14,009 --> 00:10:19,739
called ASL I believe that if possible it

217
00:10:17,249 --> 00:10:21,629
should be integrated into sort of your

218
00:10:19,739 --> 00:10:24,059
daily testing system or your weekly

219
00:10:21,629 --> 00:10:26,129
testing system it can be put into a

220
00:10:24,059 --> 00:10:29,329
continuous integration system it is

221
00:10:26,129 --> 00:10:32,669
great try to use it

222
00:10:29,329 --> 00:10:36,779
so in Cyberdyne we sort of taken this

223
00:10:32,669 --> 00:10:39,629
coverage guided fuzzing layout and we're

224
00:10:36,779 --> 00:10:42,269
just extending it we've done a few

225
00:10:39,629 --> 00:10:45,660
things differently for example that

226
00:10:42,269 --> 00:10:47,939
small fuzzing pipeline we've got a mini

227
00:10:45,660 --> 00:10:49,709
loop in there and we do a lot of that

228
00:10:47,939 --> 00:10:52,248
stuff sort of in line in a single

229
00:10:49,709 --> 00:10:55,319
program and we've tried to do it all in

230
00:10:52,249 --> 00:11:00,600
sort of a scalable way that we can kind

231
00:10:55,319 --> 00:11:03,209
of just run in parallel so let's

232
00:11:00,600 --> 00:11:05,129
actually see how we took just this

233
00:11:03,209 --> 00:11:07,669
simple coverage adding fuzzing

234
00:11:05,129 --> 00:11:10,079
architecture and started extending it

235
00:11:07,669 --> 00:11:12,100
let's let's sort of look into the skin

236
00:11:10,079 --> 00:11:15,689
of Cyberdyne

237
00:11:12,100 --> 00:11:17,080
this is sort of our layout now we've got

238
00:11:15,690 --> 00:11:19,990
the buzzer

239
00:11:17,080 --> 00:11:22,480
it's called ger this is an open-source

240
00:11:19,990 --> 00:11:25,660
tool you can find it on github comm

241
00:11:22,480 --> 00:11:28,600
slash drill a bit slash ger grr

242
00:11:25,660 --> 00:11:34,839
not to be confused with Google rapid

243
00:11:28,600 --> 00:11:37,690
response and what ger does is it just

244
00:11:34,840 --> 00:11:40,030
takes inputs mutates them runs them

245
00:11:37,690 --> 00:11:42,280
calculates code coverage and it does

246
00:11:40,030 --> 00:11:46,660
this with really high throughput it Emil

247
00:11:42,280 --> 00:11:49,780
eights all i/o in memory and it can

248
00:11:46,660 --> 00:11:52,449
repeatedly spawn sort of emulated

249
00:11:49,780 --> 00:11:55,150
processes just over and over and over

250
00:11:52,450 --> 00:11:58,480
it's able to skip lots of redundant set

251
00:11:55,150 --> 00:12:01,240
up code very easy to scale you just run

252
00:11:58,480 --> 00:12:03,250
mordor's the one thing it doesn't do is

253
00:12:01,240 --> 00:12:05,740
it doesn't do orchestration like AFL

254
00:12:03,250 --> 00:12:09,430
does it is just sort of a cog in this

255
00:12:05,740 --> 00:12:12,340
larger machine the next thing that we

256
00:12:09,430 --> 00:12:17,020
have is paisa menu it is a binary

257
00:12:12,340 --> 00:12:19,390
symbolic executor it is slightly harder

258
00:12:17,020 --> 00:12:23,680
to scale most symbolic executors are I'm

259
00:12:19,390 --> 00:12:26,699
going to go into sort of the scalability

260
00:12:23,680 --> 00:12:32,229
challenges of symbolic executors later

261
00:12:26,700 --> 00:12:34,510
but it's possible to do this and this is

262
00:12:32,230 --> 00:12:36,220
a you know it's a simple program it's

263
00:12:34,510 --> 00:12:39,280
written in Python and we will be

264
00:12:36,220 --> 00:12:43,420
releasing a variant of it in the first

265
00:12:39,280 --> 00:12:45,730
quarter of 2017 the last sort of tool

266
00:12:43,420 --> 00:12:48,310
that we integrated into the system it's

267
00:12:45,730 --> 00:12:49,180
a completely third-party tool that came

268
00:12:48,310 --> 00:12:51,569
out of academia

269
00:12:49,180 --> 00:12:54,670
it's called Klee it's hard to use

270
00:12:51,570 --> 00:12:58,450
there's never been a time where I felt

271
00:12:54,670 --> 00:13:02,110
like my investment into modifying it was

272
00:12:58,450 --> 00:13:05,380
worth it but but you know it can

273
00:13:02,110 --> 00:13:06,850
sometimes find bugs and hard to scale

274
00:13:05,380 --> 00:13:09,730
and so I'm just not going to talk about

275
00:13:06,850 --> 00:13:14,830
again I can complain about it offline

276
00:13:09,730 --> 00:13:16,810
and so the next system is what I call

277
00:13:14,830 --> 00:13:19,420
the Oracle and we have all these bug

278
00:13:16,810 --> 00:13:20,859
finding tools they you know they're

279
00:13:19,420 --> 00:13:23,079
independent they're not really

280
00:13:20,860 --> 00:13:24,240
communicating with each other they feed

281
00:13:23,080 --> 00:13:26,430
into

282
00:13:24,240 --> 00:13:27,870
basically your operating system where

283
00:13:26,430 --> 00:13:30,599
you're just running the input on the

284
00:13:27,870 --> 00:13:32,850
program hopefully if you're crashing

285
00:13:30,600 --> 00:13:35,250
inputs will fall out if they don't fall

286
00:13:32,850 --> 00:13:39,300
out then you send the non crashing

287
00:13:35,250 --> 00:13:42,260
inputs off to the inset and so this

288
00:13:39,300 --> 00:13:45,479
means that is is exactly that coverage

289
00:13:42,260 --> 00:13:48,930
coverage meant measuring system before

290
00:13:45,480 --> 00:13:51,780
and it is the key to cooperation the key

291
00:13:48,930 --> 00:13:54,449
to making it possible for completely

292
00:13:51,780 --> 00:13:56,220
independent bug tools to actually work

293
00:13:54,450 --> 00:14:00,900
together and we're going to see why this

294
00:13:56,220 --> 00:14:04,050
is later so let's go down to a bit lower

295
00:14:00,900 --> 00:14:05,850
level into our system to start by

296
00:14:04,050 --> 00:14:09,150
looking at the min set and how its

297
00:14:05,850 --> 00:14:12,930
enabling collaboration the min set

298
00:14:09,150 --> 00:14:16,350
itself stands for the minimum set of

299
00:14:12,930 --> 00:14:20,430
inputs that produce the maximum amount

300
00:14:16,350 --> 00:14:23,100
of code coverage and we want to minimize

301
00:14:20,430 --> 00:14:27,540
the set of inputs that produce code

302
00:14:23,100 --> 00:14:31,170
coverage because the fewer inputs you

303
00:14:27,540 --> 00:14:32,760
have supplies to seed to analyze the

304
00:14:31,170 --> 00:14:35,550
more resources you can bring to bear for

305
00:14:32,760 --> 00:14:37,980
input if you have a lot of computational

306
00:14:35,550 --> 00:14:41,880
resources great maybe you want to have

307
00:14:37,980 --> 00:14:44,460
bigger sets of code coverage producing

308
00:14:41,880 --> 00:14:46,890
inputs but sometimes you know you're

309
00:14:44,460 --> 00:14:50,400
like me might only have your laptop and

310
00:14:46,890 --> 00:14:52,500
you want to run the system the purpose

311
00:14:50,400 --> 00:14:54,689
of it though as we said before is just

312
00:14:52,500 --> 00:14:56,010
to identify these interesting inputs

313
00:14:54,690 --> 00:14:58,670
they get your code coverage they're

314
00:14:56,010 --> 00:15:02,160
interesting we send them back around and

315
00:14:58,670 --> 00:15:04,500
so I'm going to show you the process of

316
00:15:02,160 --> 00:15:06,660
how the min set works we're going to

317
00:15:04,500 --> 00:15:07,770
start with just four inputs let's say

318
00:15:06,660 --> 00:15:10,319
they've come from the fuzzer

319
00:15:07,770 --> 00:15:13,920
and so there were originally some nice

320
00:15:10,320 --> 00:15:16,470
program inputs and we've mutated them so

321
00:15:13,920 --> 00:15:18,630
we have the first input it comes into

322
00:15:16,470 --> 00:15:21,750
the min set we try to measure it for

323
00:15:18,630 --> 00:15:23,189
code coverage as the first input being

324
00:15:21,750 --> 00:15:24,900
measured it's sort of setting the

325
00:15:23,190 --> 00:15:27,630
baseline of code coverage so it's

326
00:15:24,900 --> 00:15:30,390
guaranteed entry into the min side and

327
00:15:27,630 --> 00:15:34,170
we can see by that sort of white that

328
00:15:30,390 --> 00:15:36,600
red circle up there that is sort of a an

329
00:15:34,170 --> 00:15:37,079
image representing what the code

330
00:15:36,600 --> 00:15:40,350
coverage

331
00:15:37,080 --> 00:15:43,260
produced by the first input is if we run

332
00:15:40,350 --> 00:15:46,290
the second input it comes through we

333
00:15:43,260 --> 00:15:48,780
measure it for coverage and we compare

334
00:15:46,290 --> 00:15:50,400
that coverage to the first input and we

335
00:15:48,780 --> 00:15:52,770
can see that we've got substantially

336
00:15:50,400 --> 00:15:55,530
more code coverage than the first input

337
00:15:52,770 --> 00:15:58,770
got us you know when we ran the second

338
00:15:55,530 --> 00:16:01,290
input a lot more code was executed you

339
00:15:58,770 --> 00:16:03,270
know we we we touched a lot more we got

340
00:16:01,290 --> 00:16:06,709
a lot more programmed state to be

341
00:16:03,270 --> 00:16:10,350
explored and so we add it to the min set

342
00:16:06,710 --> 00:16:13,650
the third input we run it and it got

343
00:16:10,350 --> 00:16:16,890
more coverage than the first but the

344
00:16:13,650 --> 00:16:19,740
total code coverage that we measured for

345
00:16:16,890 --> 00:16:22,290
the third input is subsumed by the first

346
00:16:19,740 --> 00:16:23,370
in the second inputs and so we're

347
00:16:22,290 --> 00:16:25,319
actually going to kick that out of

348
00:16:23,370 --> 00:16:28,950
lumens we're just not going to include

349
00:16:25,320 --> 00:16:32,400
it and you know this is this is

350
00:16:28,950 --> 00:16:33,720
something where you know it's adding

351
00:16:32,400 --> 00:16:35,670
stuff into the min set it's a heuristic

352
00:16:33,720 --> 00:16:38,160
and so you run the risk of throwing

353
00:16:35,670 --> 00:16:41,010
interesting things out but the idea is

354
00:16:38,160 --> 00:16:42,390
that hopefully we're eventually we're

355
00:16:41,010 --> 00:16:45,360
going to keep the most interesting

356
00:16:42,390 --> 00:16:47,370
things in and then finally we get to the

357
00:16:45,360 --> 00:16:49,110
fourth input it gets us new code

358
00:16:47,370 --> 00:16:51,270
coverage above and beyond all the others

359
00:16:49,110 --> 00:16:55,410
you know it goes out that way

360
00:16:51,270 --> 00:16:59,130
and you know this is great we've we've

361
00:16:55,410 --> 00:17:01,560
taken four inputs and we compress them

362
00:16:59,130 --> 00:17:02,130
down into three inputs but there's a few

363
00:17:01,560 --> 00:17:04,708
problems here

364
00:17:02,130 --> 00:17:07,199
there can be redundancy in the min set

365
00:17:04,709 --> 00:17:09,390
and one of the sort of ways you can

366
00:17:07,199 --> 00:17:11,160
think about this is you know over time

367
00:17:09,390 --> 00:17:12,690
we're doing that sort of stair stepping

368
00:17:11,160 --> 00:17:14,250
where we're trying to increase our

369
00:17:12,690 --> 00:17:18,270
coverage we're trying to walk higher up

370
00:17:14,250 --> 00:17:20,760
this mountain and so what if when we get

371
00:17:18,270 --> 00:17:22,639
up to say you know a certain a certain

372
00:17:20,760 --> 00:17:25,319
height a certain amount of code coverage

373
00:17:22,640 --> 00:17:27,180
what if you know all that coverage

374
00:17:25,319 --> 00:17:30,179
covered kind of something that an

375
00:17:27,180 --> 00:17:32,730
earlier case did we saw that with input

376
00:17:30,180 --> 00:17:36,570
to it got a huge amount of code coverage

377
00:17:32,730 --> 00:17:39,150
and it included the code coverage that

378
00:17:36,570 --> 00:17:41,970
input one got us and so actually input

379
00:17:39,150 --> 00:17:45,300
one is now redundant but it but it's in

380
00:17:41,970 --> 00:17:48,270
arm inside the other problem again with

381
00:17:45,300 --> 00:17:50,580
input one is it's at the base line of

382
00:17:48,270 --> 00:17:53,070
code coverage you know we guarantee

383
00:17:50,580 --> 00:17:55,980
heed entry into the mint set of the

384
00:17:53,070 --> 00:17:57,870
first input we tested what if that input

385
00:17:55,980 --> 00:18:00,510
is just totally uninteresting what if it

386
00:17:57,870 --> 00:18:03,330
just quickly exits the program you know

387
00:18:00,510 --> 00:18:06,840
we have now sent this input back around

388
00:18:03,330 --> 00:18:09,480
our cycle we were dedicating CPU

389
00:18:06,840 --> 00:18:11,820
resources to it and it might not be you

390
00:18:09,480 --> 00:18:14,429
know getting us to any interesting state

391
00:18:11,820 --> 00:18:17,220
it might be bringing us further from

392
00:18:14,429 --> 00:18:21,570
interesting program states and so that

393
00:18:17,220 --> 00:18:24,260
is a problem so the idea is actually you

394
00:18:21,570 --> 00:18:26,460
know we've created this minimal set of

395
00:18:24,260 --> 00:18:28,260
inputs that have produced the maximum

396
00:18:26,460 --> 00:18:29,610
amount of code coverage we need to

397
00:18:28,260 --> 00:18:31,919
compress it we need to even make it

398
00:18:29,610 --> 00:18:35,370
smaller when we want to remove the

399
00:18:31,919 --> 00:18:37,710
redundancy and the idea on doing this I

400
00:18:35,370 --> 00:18:39,689
think the simplest way to do this is to

401
00:18:37,710 --> 00:18:43,409
sort of fold them in set over on itself

402
00:18:39,690 --> 00:18:45,750
let's reconstruct it and do it sort of

403
00:18:43,409 --> 00:18:47,760
in a reverse order there's other there's

404
00:18:45,750 --> 00:18:51,269
other orders to do it but reverse is

405
00:18:47,760 --> 00:18:54,389
simplest to see so we had added inputs

406
00:18:51,269 --> 00:18:56,279
one two and four to the min set so let's

407
00:18:54,389 --> 00:18:58,469
flip them around let's start with input

408
00:18:56,279 --> 00:19:00,389
four we're going to run it through the

409
00:18:58,470 --> 00:19:02,730
program we're going to measure its

410
00:19:00,389 --> 00:19:04,168
coverage because it's the first thing

411
00:19:02,730 --> 00:19:07,610
we're measuring it's setting the

412
00:19:04,169 --> 00:19:09,960
baseline and so I think a simple way of

413
00:19:07,610 --> 00:19:14,549
deciding that you know just flipping it

414
00:19:09,960 --> 00:19:17,399
around is the right approach is that the

415
00:19:14,549 --> 00:19:20,460
most recently produced input input for

416
00:19:17,399 --> 00:19:22,709
is probably one of the ones that gets us

417
00:19:20,460 --> 00:19:25,649
the deepest in the program so let's use

418
00:19:22,710 --> 00:19:27,659
that as our baseline we run the second

419
00:19:25,649 --> 00:19:29,760
input again it gets us a lot of code

420
00:19:27,659 --> 00:19:33,090
coverage so we're going to add it into

421
00:19:29,760 --> 00:19:36,210
this new folded min set that's great and

422
00:19:33,090 --> 00:19:38,250
now we run the first input that one set

423
00:19:36,210 --> 00:19:40,470
the original baseline it might have been

424
00:19:38,250 --> 00:19:42,779
very uninteresting and it doesn't get us

425
00:19:40,470 --> 00:19:46,860
in your code coverage when we compare it

426
00:19:42,779 --> 00:19:49,110
to one two four and two and so now we

427
00:19:46,860 --> 00:19:52,408
can kick it out we've shrunk the size of

428
00:19:49,110 --> 00:19:54,840
our min set and now that gets us more

429
00:19:52,409 --> 00:19:57,539
resources like fuzzing resources

430
00:19:54,840 --> 00:20:00,840
mutation resources that we can apply to

431
00:19:57,539 --> 00:20:03,899
the smaller set of inputs

432
00:20:00,840 --> 00:20:06,029
there's a few things though that I've

433
00:20:03,899 --> 00:20:07,620
kind of shoved under the rug you know

434
00:20:06,029 --> 00:20:10,080
code coverage I've said let's just

435
00:20:07,620 --> 00:20:12,090
measure code coverage it's great how you

436
00:20:10,080 --> 00:20:14,158
measure this and what you measure is

437
00:20:12,090 --> 00:20:16,789
very important and it can be really

438
00:20:14,159 --> 00:20:18,659
finicky actually you can have

439
00:20:16,789 --> 00:20:21,059
coarse-grained measurements and you can

440
00:20:18,659 --> 00:20:22,620
have fine grain measurements in my

441
00:20:21,059 --> 00:20:25,740
experience of coarse grain measurement

442
00:20:22,620 --> 00:20:28,080
like you know measuring basic blocks

443
00:20:25,740 --> 00:20:30,509
executed measuring functions executed

444
00:20:28,080 --> 00:20:33,240
these can be okay if what you want to

445
00:20:30,509 --> 00:20:35,580
find is shallow bugs you know if the

446
00:20:33,240 --> 00:20:37,950
coarser grained the measurement you have

447
00:20:35,580 --> 00:20:41,009
the smaller humans that's going to be

448
00:20:37,950 --> 00:20:43,529
the more redundant you discover but if

449
00:20:41,009 --> 00:20:46,559
you have a small min set you have you

450
00:20:43,529 --> 00:20:49,169
know more fuzzers per per input in the

451
00:20:46,559 --> 00:20:52,559
mid set you have more static analysis

452
00:20:49,169 --> 00:20:53,940
more symbolic execution and so more

453
00:20:52,559 --> 00:20:55,769
resources you have it's just a

454
00:20:53,940 --> 00:20:58,259
brute-force problem more things going to

455
00:20:55,769 --> 00:21:00,809
fall out if you have a very fine grained

456
00:20:58,259 --> 00:21:03,059
metric like branch coverage or the last

457
00:21:00,809 --> 00:21:05,820
n branches then you're going to have a

458
00:21:03,059 --> 00:21:08,129
bigger min set and this is you know this

459
00:21:05,820 --> 00:21:09,869
can be good and it can be bad if you've

460
00:21:08,129 --> 00:21:11,850
got lots of you know if you've got a big

461
00:21:09,869 --> 00:21:15,869
cluster availability available to you

462
00:21:11,850 --> 00:21:17,580
then great and sometimes and this was

463
00:21:15,869 --> 00:21:19,949
the case in the DARPA Cyber grand

464
00:21:17,580 --> 00:21:21,899
challenge you you don't know what

465
00:21:19,950 --> 00:21:24,179
program you're going to be operating on

466
00:21:21,899 --> 00:21:26,248
ahead of time you know if you're doing

467
00:21:24,179 --> 00:21:28,049
like a code audit you can start to

468
00:21:26,249 --> 00:21:30,230
tailor your coverage metric to that

469
00:21:28,049 --> 00:21:32,490
program and that's usually a good idea

470
00:21:30,230 --> 00:21:34,470
but in the case of the cyber Grand

471
00:21:32,490 --> 00:21:36,450
Challenge we didn't know what programs

472
00:21:34,470 --> 00:21:39,960
we were getting ahead of time it's just

473
00:21:36,450 --> 00:21:42,210
whatever DARPA sends us and so you know

474
00:21:39,960 --> 00:21:44,610
there is no one-size-fits-all code

475
00:21:42,210 --> 00:21:46,529
coverage metric sometimes we want to

476
00:21:44,610 --> 00:21:49,619
measure one feature like branch coverage

477
00:21:46,529 --> 00:21:52,559
another time we want we might want to

478
00:21:49,619 --> 00:21:55,980
measure a different feature like you

479
00:21:52,559 --> 00:21:58,950
know the depth of the call stack or what

480
00:21:55,980 --> 00:22:00,990
what call stacks we've seen and in fact

481
00:21:58,950 --> 00:22:02,490
maybe at the beginning we want just a

482
00:22:00,990 --> 00:22:04,980
coarse-grained measurement we want to

483
00:22:02,490 --> 00:22:07,889
see if we can shake out these these you

484
00:22:04,980 --> 00:22:10,320
know shallow bugs because we just need

485
00:22:07,889 --> 00:22:11,840
to find an exploit and maybe there's an

486
00:22:10,320 --> 00:22:15,649
exploit early on in the program

487
00:22:11,840 --> 00:22:18,050
and so one way that you can go about

488
00:22:15,650 --> 00:22:20,780
this is that you can just measure all

489
00:22:18,050 --> 00:22:22,879
the things at once and the more things

490
00:22:20,780 --> 00:22:25,340
you measure the more fine-grained metric

491
00:22:22,880 --> 00:22:27,830
becomes the bigger you min sets and the

492
00:22:25,340 --> 00:22:29,629
more resources you need another approach

493
00:22:27,830 --> 00:22:31,970
that you can do and this is what we did

494
00:22:29,630 --> 00:22:34,610
in which have a grand challenge is that

495
00:22:31,970 --> 00:22:37,910
you can change how you measure coverage

496
00:22:34,610 --> 00:22:40,699
over time if we want to start by

497
00:22:37,910 --> 00:22:42,800
measuring feature one like branch

498
00:22:40,700 --> 00:22:45,520
coverage we can do that for a little

499
00:22:42,800 --> 00:22:48,470
while and then maybe we want to say of

500
00:22:45,520 --> 00:22:53,270
those inputs that we have in our min set

501
00:22:48,470 --> 00:22:56,330
which ones you know you know execute

502
00:22:53,270 --> 00:22:59,480
certain call stacks which ones get us

503
00:22:56,330 --> 00:23:01,730
this other metric maximize this other

504
00:22:59,480 --> 00:23:04,250
metric and so that's where this folding

505
00:23:01,730 --> 00:23:07,010
process sort of comes in and it's really

506
00:23:04,250 --> 00:23:09,710
nice we can build one min set with one

507
00:23:07,010 --> 00:23:11,570
metric folded over with the other metric

508
00:23:09,710 --> 00:23:14,150
and we can just sort of do this at

509
00:23:11,570 --> 00:23:16,790
regular intervals it can be over the

510
00:23:14,150 --> 00:23:22,610
course minutes of the course of hours or

511
00:23:16,790 --> 00:23:25,610
over the course of days and so the nice

512
00:23:22,610 --> 00:23:27,979
thing to see here is that you know we we

513
00:23:25,610 --> 00:23:30,199
had the min set as the sort of

514
00:23:27,980 --> 00:23:32,900
gatekeeper of what goes around to the

515
00:23:30,200 --> 00:23:35,390
other bug finding systems and it really

516
00:23:32,900 --> 00:23:37,040
didn't care who was sending inputs it

517
00:23:35,390 --> 00:23:38,780
could be the father sending it inputs it

518
00:23:37,040 --> 00:23:41,810
could be a symbolic executor sending

519
00:23:38,780 --> 00:23:44,360
inputs it doesn't care and so there's no

520
00:23:41,810 --> 00:23:46,730
sort of collaboration problems with the

521
00:23:44,360 --> 00:23:50,750
min set it's not actually finding bugs

522
00:23:46,730 --> 00:23:53,480
it's just filtering out inputs and so

523
00:23:50,750 --> 00:23:56,350
the real challenge with making a bug

524
00:23:53,480 --> 00:23:59,870
finding system that is automated is

525
00:23:56,350 --> 00:24:02,899
plugging in tools you know if if we

526
00:23:59,870 --> 00:24:05,360
suddenly there's a new open source tool

527
00:24:02,900 --> 00:24:07,220
that's great it finds bugs we want to be

528
00:24:05,360 --> 00:24:10,969
able to plug it in even though it was

529
00:24:07,220 --> 00:24:12,800
never designed for our system and so we

530
00:24:10,970 --> 00:24:15,320
need to find a way to integrate these

531
00:24:12,800 --> 00:24:17,419
things the min set is sending good

532
00:24:15,320 --> 00:24:20,510
inputs around how do we give those good

533
00:24:17,420 --> 00:24:24,140
inputs to other programs the easiest is

534
00:24:20,510 --> 00:24:25,200
the father so here's an example where

535
00:24:24,140 --> 00:24:27,060
we're going to see

536
00:24:25,200 --> 00:24:28,830
the symbolic eggs here it's going to

537
00:24:27,060 --> 00:24:31,860
produce an input it's going to go around

538
00:24:28,830 --> 00:24:33,540
we're going to see it first you're going

539
00:24:31,860 --> 00:24:36,090
to talk more about symbolic institution

540
00:24:33,540 --> 00:24:39,210
later but to start off with we have an

541
00:24:36,090 --> 00:24:42,600
input those S's in the input represent

542
00:24:39,210 --> 00:24:45,420
symbols the sort of simplest way to

543
00:24:42,600 --> 00:24:48,419
think of this is that that initial input

544
00:24:45,420 --> 00:24:50,700
with the SS they really represent any

545
00:24:48,420 --> 00:24:53,700
possible input that could be anything

546
00:24:50,700 --> 00:24:56,310
and it is the symbolic executor that

547
00:24:53,700 --> 00:24:59,640
discovers a kind of instantiation of

548
00:24:56,310 --> 00:25:01,919
that file it discovers that you know one

549
00:24:59,640 --> 00:25:05,490
of these sort of initial inputs can be

550
00:25:01,920 --> 00:25:07,800
this sort of blue input and it can spit

551
00:25:05,490 --> 00:25:11,490
out lots and lots of inputs it discovers

552
00:25:07,800 --> 00:25:13,590
lots of inputs and so we see that the

553
00:25:11,490 --> 00:25:15,060
Simplot goes through our system we

554
00:25:13,590 --> 00:25:17,669
measure it for coverage and let's just

555
00:25:15,060 --> 00:25:20,280
say it's added to our min set and so we

556
00:25:17,670 --> 00:25:24,480
send it around it goes into the fuzzer

557
00:25:20,280 --> 00:25:26,970
the fuzzer is going to run its mutaters

558
00:25:24,480 --> 00:25:29,130
it's going to mutate them and then we're

559
00:25:26,970 --> 00:25:31,980
going to see mutated inputs come in

560
00:25:29,130 --> 00:25:36,180
we've got little squares on that

561
00:25:31,980 --> 00:25:38,490
representing the mutations it passes

562
00:25:36,180 --> 00:25:40,920
through goes into our min set this is

563
00:25:38,490 --> 00:25:43,290
great we have now gotten collaboration

564
00:25:40,920 --> 00:25:46,260
but you know collaborate collaborating

565
00:25:43,290 --> 00:25:48,300
with a fuzzer it's trivial buzzers they

566
00:25:46,260 --> 00:25:49,800
don't care who sends them inputs they

567
00:25:48,300 --> 00:25:53,070
don't care where their seed inputs come

568
00:25:49,800 --> 00:25:55,379
from so you know integrating third party

569
00:25:53,070 --> 00:25:57,830
fuzzers into your system integrating

570
00:25:55,380 --> 00:26:00,240
third party mutaters it's pretty trivial

571
00:25:57,830 --> 00:26:03,480
but what if we want to send that input

572
00:26:00,240 --> 00:26:06,870
to a symbolic executor you know before

573
00:26:03,480 --> 00:26:08,580
we had that executor taking files that

574
00:26:06,870 --> 00:26:10,469
could represent anything and now we're

575
00:26:08,580 --> 00:26:14,370
giving in a file that's only one thing

576
00:26:10,470 --> 00:26:17,640
how do we make the symbolic executor

577
00:26:14,370 --> 00:26:20,939
work with some sort of arbitrary inputs

578
00:26:17,640 --> 00:26:23,390
and I've said that integrating third

579
00:26:20,940 --> 00:26:25,890
party tools can be challenging and

580
00:26:23,390 --> 00:26:28,800
integrating symbolic executors in

581
00:26:25,890 --> 00:26:33,210
particular and making them cooperate is

582
00:26:28,800 --> 00:26:35,399
challenging and the way we went about it

583
00:26:33,210 --> 00:26:37,830
is what I thought was the simplest

584
00:26:35,400 --> 00:26:38,970
approach you know you just say here's

585
00:26:37,830 --> 00:26:41,159
part of an input

586
00:26:38,970 --> 00:26:43,680
the rest of it do your normal thing

587
00:26:41,160 --> 00:26:45,810
treat it a symbolic and this is very

588
00:26:43,680 --> 00:26:47,850
simplistic but I'm going to try to

589
00:26:45,810 --> 00:26:51,270
convince you that this simple approach

590
00:26:47,850 --> 00:26:54,840
is the right approach because symbolic

591
00:26:51,270 --> 00:26:56,550
executors themselves there they're not

592
00:26:54,840 --> 00:27:00,389
easy to work with they're they're not

593
00:26:56,550 --> 00:27:02,669
simple programs they are monolithic they

594
00:27:00,390 --> 00:27:07,980
they do a lot of things internally and

595
00:27:02,670 --> 00:27:09,600
we want to fit them in and and in fact

596
00:27:07,980 --> 00:27:11,100
they're not the easiest programs to

597
00:27:09,600 --> 00:27:13,379
scale there's lots of scalability

598
00:27:11,100 --> 00:27:15,030
challenges in them and so if we can

599
00:27:13,380 --> 00:27:18,270
integrate them in the simplest way

600
00:27:15,030 --> 00:27:21,330
possible then then then we can kind of

601
00:27:18,270 --> 00:27:24,330
break through these scaling barriers we

602
00:27:21,330 --> 00:27:26,939
can take a problem in the case of

603
00:27:24,330 --> 00:27:29,699
symbolic execution that is really really

604
00:27:26,940 --> 00:27:32,520
hard and we can sort of turn it into a

605
00:27:29,700 --> 00:27:35,040
trivially parallelizable problem we can

606
00:27:32,520 --> 00:27:37,200
take we can just run independent

607
00:27:35,040 --> 00:27:42,360
symbolic executors and make them work

608
00:27:37,200 --> 00:27:44,880
and that's going to be our our way of

609
00:27:42,360 --> 00:27:47,490
scaling them up and so let's let's go

610
00:27:44,880 --> 00:27:50,370
learn about symbolic acute execution at

611
00:27:47,490 --> 00:27:52,340
a pretty high level and see where the

612
00:27:50,370 --> 00:27:55,320
scalability challenges are with it and

613
00:27:52,340 --> 00:27:57,570
hopefully this will justify why our

614
00:27:55,320 --> 00:28:01,800
simplistic solution of sending in

615
00:27:57,570 --> 00:28:05,820
partial inputs is the easiest path to

616
00:28:01,800 --> 00:28:07,560
scalability so symbolic executors I said

617
00:28:05,820 --> 00:28:10,950
they take in these files fill up Isis

618
00:28:07,560 --> 00:28:12,899
full of symbols these these initial

619
00:28:10,950 --> 00:28:14,940
inputs these symbols could represent

620
00:28:12,900 --> 00:28:19,380
anything you don't know what they

621
00:28:14,940 --> 00:28:21,720
represent ahead of time and so over time

622
00:28:19,380 --> 00:28:23,970
the symbolic executor is going through

623
00:28:21,720 --> 00:28:26,340
the program it's sort of emulating the

624
00:28:23,970 --> 00:28:27,570
execution of the program and every time

625
00:28:26,340 --> 00:28:31,350
it comes to a branch like an

626
00:28:27,570 --> 00:28:35,179
if-then-else branch it says okay I want

627
00:28:31,350 --> 00:28:38,159
to explore both paths down the true path

628
00:28:35,180 --> 00:28:39,570
the condition tested must be true so

629
00:28:38,160 --> 00:28:41,930
let's log that condition

630
00:28:39,570 --> 00:28:45,360
let's assert that it must be true and

631
00:28:41,930 --> 00:28:47,580
down a false path let's just assert that

632
00:28:45,360 --> 00:28:51,090
it must be false and so it's going to

633
00:28:47,580 --> 00:28:52,010
try to fork and and explore I'm going to

634
00:28:51,090 --> 00:28:56,149
make concrete

635
00:28:52,010 --> 00:28:59,180
sample of this so you can see and I said

636
00:28:56,150 --> 00:29:01,850
that pison mu our symbolic executor is

637
00:28:59,180 --> 00:29:04,730
binary is a binary symbolic executor it

638
00:29:01,850 --> 00:29:06,770
works on program binaries and so this is

639
00:29:04,730 --> 00:29:09,530
sort of similar to just a real program

640
00:29:06,770 --> 00:29:12,950
it's just a CPU emulator a bit of a

641
00:29:09,530 --> 00:29:16,760
special one it's got registers it's got

642
00:29:12,950 --> 00:29:18,770
memory and it operates on bytes as well

643
00:29:16,760 --> 00:29:21,500
as on symbols and sort of these

644
00:29:18,770 --> 00:29:24,080
expressions of symbols if we have two

645
00:29:21,500 --> 00:29:27,280
symbolic input bytes and we add them

646
00:29:24,080 --> 00:29:30,860
together that is a symbolic expression

647
00:29:27,280 --> 00:29:32,770
it's it's as an emulator it's just got

648
00:29:30,860 --> 00:29:35,360
software implementations of every

649
00:29:32,770 --> 00:29:37,639
instruction or every practical

650
00:29:35,360 --> 00:29:41,889
instruction that most programs use in

651
00:29:37,640 --> 00:29:45,860
the case of Pi so menu we've got

652
00:29:41,890 --> 00:29:49,160
implementations of most x86 and AMD 64

653
00:29:45,860 --> 00:29:52,429
instructions so let's see an actual

654
00:29:49,160 --> 00:29:56,710
concrete example this is a picture from

655
00:29:52,430 --> 00:30:00,740
the great disassembler binary ninja

656
00:29:56,710 --> 00:30:04,670
check it out it's usable and it's fast

657
00:30:00,740 --> 00:30:07,370
and up there this is actually it's sort

658
00:30:04,670 --> 00:30:12,110
of intermediate representation for some

659
00:30:07,370 --> 00:30:14,530
x86 code what we're seeing is we read in

660
00:30:12,110 --> 00:30:17,659
an input symbol it could be anything

661
00:30:14,530 --> 00:30:20,720
we're going to compare it against 10 and

662
00:30:17,660 --> 00:30:22,370
so what I want you to think about is if

663
00:30:20,720 --> 00:30:24,770
you're familiar with the C language or

664
00:30:22,370 --> 00:30:27,020
Java or something we have a switch

665
00:30:24,770 --> 00:30:30,260
statement it's basically a whole bunch

666
00:30:27,020 --> 00:30:32,629
of v analysis and we have ten possible

667
00:30:30,260 --> 00:30:35,360
cases in this or nine possible cases in

668
00:30:32,630 --> 00:30:38,510
the switch statement okay zero do this

669
00:30:35,360 --> 00:30:41,929
case one do this cetera etc all the way

670
00:30:38,510 --> 00:30:45,290
up to case nine and so we want to say

671
00:30:41,930 --> 00:30:47,210
okay we've got this input and it should

672
00:30:45,290 --> 00:30:49,129
match one of the cases so we're going

673
00:30:47,210 --> 00:30:52,400
going to compare it to the upper bound

674
00:30:49,130 --> 00:30:53,030
of ten if if it's greater than or equal

675
00:30:52,400 --> 00:30:54,950
to ten

676
00:30:53,030 --> 00:30:56,300
we've got the false branch we're just

677
00:30:54,950 --> 00:30:59,780
going to return from the function

678
00:30:56,300 --> 00:31:02,870
it's an unhandled case otherwise we're

679
00:30:59,780 --> 00:31:04,460
going to go down the false branch and we

680
00:31:02,870 --> 00:31:07,820
are going to jump to the

681
00:31:04,460 --> 00:31:11,090
code that handles this case so our input

682
00:31:07,820 --> 00:31:13,340
symbol is an index into a table that is

683
00:31:11,090 --> 00:31:17,389
telling us where the code is that

684
00:31:13,340 --> 00:31:18,980
handles the case so let's see what the

685
00:31:17,390 --> 00:31:22,160
symbolic eggs here is going to do on

686
00:31:18,980 --> 00:31:24,680
this code it's going to fork it's going

687
00:31:22,160 --> 00:31:27,770
to say okay we've got this input symbol

688
00:31:24,680 --> 00:31:31,070
we've stored it in EAX we now do a

689
00:31:27,770 --> 00:31:34,970
conditional branch on EAX down the path

690
00:31:31,070 --> 00:31:38,139
here on your left we see that the value

691
00:31:34,970 --> 00:31:41,210
is greater than or equal to 10 and so

692
00:31:38,140 --> 00:31:46,250
the possible values of that input symbol

693
00:31:41,210 --> 00:31:49,490
are anywhere from 10 to 2 to the power

694
00:31:46,250 --> 00:31:52,610
of 32 or 2 to the power of 31 you know

695
00:31:49,490 --> 00:31:55,790
all those positive numbers in that 32

696
00:31:52,610 --> 00:31:59,300
bit range and down the path on your

697
00:31:55,790 --> 00:32:01,430
right we see that you know this is this

698
00:31:59,300 --> 00:32:04,100
is the case where we're going to handle

699
00:32:01,430 --> 00:32:05,420
our 10 possible indexes but there's

700
00:32:04,100 --> 00:32:07,730
something that's funny about this you

701
00:32:05,420 --> 00:32:12,500
know we're actually handling negative

702
00:32:07,730 --> 00:32:14,360
numbers as well as our 0 1 2 up to 9 you

703
00:32:12,500 --> 00:32:16,880
know this is where we're saying let's go

704
00:32:14,360 --> 00:32:18,979
handle one of the cases and we see that

705
00:32:16,880 --> 00:32:20,240
the constraints are are bringing in this

706
00:32:18,980 --> 00:32:21,740
sort of corner case that we didn't

707
00:32:20,240 --> 00:32:24,950
originally think about when you

708
00:32:21,740 --> 00:32:28,370
programmed this and so again the next

709
00:32:24,950 --> 00:32:31,120
step of the symbolic executors fork you

710
00:32:28,370 --> 00:32:33,919
know on that original path where we

711
00:32:31,120 --> 00:32:35,959
where we were out of bounds on the case

712
00:32:33,920 --> 00:32:38,240
we just return we don't care about it

713
00:32:35,960 --> 00:32:41,300
that's like an early exit of our program

714
00:32:38,240 --> 00:32:43,910
but down this other path we now have to

715
00:32:41,300 --> 00:32:46,430
fork to handle all the cases and more

716
00:32:43,910 --> 00:32:48,590
you know we can handle each of those 10

717
00:32:46,430 --> 00:32:51,170
cases but what about that big negative

718
00:32:48,590 --> 00:32:53,510
range where are we going to jump in our

719
00:32:51,170 --> 00:32:56,360
program we don't know you know that's

720
00:32:53,510 --> 00:33:00,260
undefined behavior that is GABA bleah

721
00:32:56,360 --> 00:33:03,379
going to be a bug and so what we can

722
00:33:00,260 --> 00:33:04,790
kind of see here is that you know we're

723
00:33:03,380 --> 00:33:07,550
going to fork a lot you know how many

724
00:33:04,790 --> 00:33:09,740
how many possible places could that jump

725
00:33:07,550 --> 00:33:12,919
has gone not just 10 it could have gone

726
00:33:09,740 --> 00:33:14,990
to 2 to the power of 31

727
00:33:12,920 --> 00:33:17,390
or number of cases it can go anywhere

728
00:33:14,990 --> 00:33:19,820
and so this is really the scalability

729
00:33:17,390 --> 00:33:21,800
challenge of symbolic execution is it's

730
00:33:19,820 --> 00:33:22,939
going to fork and fork and fork you've

731
00:33:21,800 --> 00:33:24,560
got a bunch of branches

732
00:33:22,940 --> 00:33:26,960
let's fork down them if you've got a

733
00:33:24,560 --> 00:33:29,600
loop every time around the loop that's a

734
00:33:26,960 --> 00:33:32,240
fork branches and loops you know this is

735
00:33:29,600 --> 00:33:33,379
going to really explode and so the

736
00:33:32,240 --> 00:33:35,870
problem that you have with these

737
00:33:33,380 --> 00:33:39,350
symbolic executors is that it's hard to

738
00:33:35,870 --> 00:33:41,060
get them deep into a program you know

739
00:33:39,350 --> 00:33:43,429
they're monolithic they they have been

740
00:33:41,060 --> 00:33:44,540
they're kind of they're doing all sorts

741
00:33:43,430 --> 00:33:46,400
of complicated stuff

742
00:33:44,540 --> 00:33:49,399
and a lot of times they will implement

743
00:33:46,400 --> 00:33:52,100
implement different heuristics that that

744
00:33:49,400 --> 00:33:54,200
the implementers hoped would get them

745
00:33:52,100 --> 00:33:56,629
deep in a program one of those is like

746
00:33:54,200 --> 00:33:58,700
the symbolic executor could follow the

747
00:33:56,630 --> 00:34:00,760
Forks that get them new coverage but

748
00:33:58,700 --> 00:34:03,620
these are religious band-aids you know

749
00:34:00,760 --> 00:34:05,990
you can throw a number of PhD students

750
00:34:03,620 --> 00:34:08,000
at this and they'll produce theses for

751
00:34:05,990 --> 00:34:10,010
their favorite metrics but not going to

752
00:34:08,000 --> 00:34:11,810
solve the fundamental problem and in

753
00:34:10,010 --> 00:34:14,929
fact I would say there is no solution or

754
00:34:11,810 --> 00:34:18,889
no generic solution to this problem it's

755
00:34:14,929 --> 00:34:20,690
a my my my idea is like let's just let's

756
00:34:18,889 --> 00:34:22,009
just skip over this problem let's sweep

757
00:34:20,690 --> 00:34:23,780
it under the rug let's pretend it

758
00:34:22,010 --> 00:34:26,600
doesn't exist and let's find a way to

759
00:34:23,780 --> 00:34:29,360
sort of massage the symbolic executors

760
00:34:26,600 --> 00:34:32,179
to do what we want and so that's where

761
00:34:29,360 --> 00:34:35,450
that initial picture got us we said

762
00:34:32,179 --> 00:34:37,639
let's just take an input let's chop off

763
00:34:35,449 --> 00:34:40,819
part of it treat the rest of symbolic

764
00:34:37,639 --> 00:34:42,830
send it into the symbolic executor this

765
00:34:40,820 --> 00:34:45,350
is now a trivially parallelizable

766
00:34:42,830 --> 00:34:47,270
problem we haven't solved the

767
00:34:45,350 --> 00:34:49,730
fundamental scalability problem of

768
00:34:47,270 --> 00:34:51,590
symbolic execution but we have found a

769
00:34:49,730 --> 00:34:55,340
way to jump the symbolic executors

770
00:34:51,590 --> 00:34:57,140
deeper into the program you know maybe

771
00:34:55,340 --> 00:34:59,660
it's going to explore sort of shallowly

772
00:34:57,139 --> 00:35:01,670
there there but it's still deeper it's

773
00:34:59,660 --> 00:35:04,759
still got access to more program State

774
00:35:01,670 --> 00:35:06,380
this is an improvement there's a number

775
00:35:04,760 --> 00:35:09,260
of different ways that we can you know

776
00:35:06,380 --> 00:35:11,540
we've got new heuristics to choose where

777
00:35:09,260 --> 00:35:13,670
to jump in but that's something that you

778
00:35:11,540 --> 00:35:18,410
can kind of tune to the program in your

779
00:35:13,670 --> 00:35:22,100
analyzing and so we're finally coming to

780
00:35:18,410 --> 00:35:24,049
the end and we've seen the high-level

781
00:35:22,100 --> 00:35:26,060
architecture of

782
00:35:24,050 --> 00:35:29,150
five or nine we can see now the sort of

783
00:35:26,060 --> 00:35:31,460
communication around the system we've

784
00:35:29,150 --> 00:35:33,380
got the symbolic executors there's the

785
00:35:31,460 --> 00:35:35,650
initial one that's taking completely

786
00:35:33,380 --> 00:35:38,270
symbolic in but producing outputs

787
00:35:35,650 --> 00:35:40,880
there's sort of these partial symbolic

788
00:35:38,270 --> 00:35:42,790
executors and that's our approach is

789
00:35:40,880 --> 00:35:46,160
sort of massaging symbolic execution

790
00:35:42,790 --> 00:35:49,460
into a trivially parallelizable problem

791
00:35:46,160 --> 00:35:51,589
and it's taking partial inputs sending

792
00:35:49,460 --> 00:35:53,630
things out these inputs they're all

793
00:35:51,590 --> 00:35:56,060
going around they're being exposed and

794
00:35:53,630 --> 00:35:59,090
we've now got collaboration where there

795
00:35:56,060 --> 00:36:00,830
was none before we've taken independent

796
00:35:59,090 --> 00:36:02,690
things they are working together and

797
00:36:00,830 --> 00:36:04,430
they don't even realize that they're

798
00:36:02,690 --> 00:36:09,200
working together and this is the nice

799
00:36:04,430 --> 00:36:12,109
thing about this approach so what we've

800
00:36:09,200 --> 00:36:15,560
seen is that we started with a very

801
00:36:12,110 --> 00:36:19,130
simple fuzzing campaign setup we started

802
00:36:15,560 --> 00:36:21,680
with just taking seed inputs we mutate

803
00:36:19,130 --> 00:36:24,140
them we hope to we hope that crashes

804
00:36:21,680 --> 00:36:26,540
will follow the other end and then we

805
00:36:24,140 --> 00:36:29,029
observed that the problem was that we

806
00:36:26,540 --> 00:36:31,460
could just spend our whole lives waiting

807
00:36:29,030 --> 00:36:35,210
for those to find bugs and we would

808
00:36:31,460 --> 00:36:38,540
never know if progress was being made so

809
00:36:35,210 --> 00:36:40,910
we tried to find a way to sort of make

810
00:36:38,540 --> 00:36:43,160
these systems accountable we tried to

811
00:36:40,910 --> 00:36:45,560
find a way of measuring progress and we

812
00:36:43,160 --> 00:36:47,839
use sort of the industry standard code

813
00:36:45,560 --> 00:36:49,910
coverage metric there's lots of ways in

814
00:36:47,840 --> 00:36:52,130
my dream code coverage there's lots of

815
00:36:49,910 --> 00:36:53,450
different metrics that we can use but

816
00:36:52,130 --> 00:36:57,350
we've now got a way of measuring

817
00:36:53,450 --> 00:36:58,819
progress we integrated that into a kind

818
00:36:57,350 --> 00:37:01,640
of a higher level approach where we

819
00:36:58,820 --> 00:37:05,480
added this cycle coverage guided fuzzing

820
00:37:01,640 --> 00:37:07,790
and that gets us sort of more you know

821
00:37:05,480 --> 00:37:09,770
more inputs it's it's a it's a system

822
00:37:07,790 --> 00:37:13,310
that's hopefully always pushing the

823
00:37:09,770 --> 00:37:16,130
boundaries the min set the thing that

824
00:37:13,310 --> 00:37:19,549
the service set measures code coverage

825
00:37:16,130 --> 00:37:22,040
it was the key to distilling a corpus it

826
00:37:19,550 --> 00:37:26,630
was the key to deciding what we send

827
00:37:22,040 --> 00:37:28,820
around and then we saw that we could

828
00:37:26,630 --> 00:37:31,430
start adding independent tools the

829
00:37:28,820 --> 00:37:33,920
fuzzer it collaborates with anyone then

830
00:37:31,430 --> 00:37:36,470
we had the symbolic executors and we

831
00:37:33,920 --> 00:37:37,370
wanted to find a way to make those scale

832
00:37:36,470 --> 00:37:39,109
even

833
00:37:37,370 --> 00:37:42,380
so fundamentally they're hard to scale

834
00:37:39,110 --> 00:37:45,230
so we took the simplest approach we made

835
00:37:42,380 --> 00:37:47,510
we just ran multiple symbolic executors

836
00:37:45,230 --> 00:37:52,640
we turned a hard problem into a

837
00:37:47,510 --> 00:37:55,160
trivially parallelizable problem and so

838
00:37:52,640 --> 00:37:57,890
now you've kind of seen how you can

839
00:37:55,160 --> 00:38:01,430
architect a bug finding system it's

840
00:37:57,890 --> 00:38:03,440
simpler than you think you can take AFL

841
00:38:01,430 --> 00:38:05,990
and you can add to it you can make your

842
00:38:03,440 --> 00:38:08,120
own system and add ASL to it when

843
00:38:05,990 --> 00:38:10,459
academia publishes their new fancy bug

844
00:38:08,120 --> 00:38:13,549
finding system you just add it on to

845
00:38:10,460 --> 00:38:15,620
this and you find a way to send your it

846
00:38:13,550 --> 00:38:19,070
like to take your inputs send them in

847
00:38:15,620 --> 00:38:23,359
add this collaboration and so Cyberdyne

848
00:38:19,070 --> 00:38:26,530
finds bugs now you can - i'm beauty

849
00:38:23,360 --> 00:38:28,880
ribbon thanks for listening to talk

850
00:38:26,530 --> 00:38:34,749
[Applause]

851
00:38:28,880 --> 00:38:34,749
[Music]

