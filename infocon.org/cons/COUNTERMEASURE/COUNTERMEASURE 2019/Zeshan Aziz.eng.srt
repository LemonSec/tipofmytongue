1
00:00:00,230 --> 00:00:02,299
[Music]

2
00:00:05,870 --> 00:00:08,730
so today's talk will be talking about a

3
00:00:08,730 --> 00:00:10,830
brexit and the work I did

4
00:00:10,830 --> 00:00:13,380
analyzing BOTS talking about bricks so

5
00:00:13,380 --> 00:00:14,070
us

6
00:00:14,070 --> 00:00:15,990
I know it's lunch so I'm going to try to

7
00:00:15,990 --> 00:00:18,240
wake you up but by show of hands how

8
00:00:18,240 --> 00:00:22,619
many of you guys heard of brexit ok but

9
00:00:22,619 --> 00:00:25,099
what about a camera general it Iike

10
00:00:25,099 --> 00:00:31,460
close close to everyone aggregate IQ

11
00:00:31,460 --> 00:00:33,870
Aaron Kelly did a really good talk on

12
00:00:33,870 --> 00:00:35,360
that last year I kind of measure

13
00:00:35,360 --> 00:00:39,140
internet research agency

14
00:00:39,420 --> 00:00:41,790
what about like general Iranian distant

15
00:00:41,790 --> 00:00:44,579
vote campaigns or Chinese disinformation

16
00:00:44,579 --> 00:00:48,120
campaigns so hopefully by the end of

17
00:00:48,120 --> 00:00:49,500
this talk you'll understand a bit about

18
00:00:49,500 --> 00:00:52,920
how these influence operations work how

19
00:00:52,920 --> 00:00:55,890
they operate and my talk is mainly on

20
00:00:55,890 --> 00:00:58,170
brexit but there's some Canadian stuff

21
00:00:58,170 --> 00:01:01,140
I'll talk about as well so if you're

22
00:01:01,140 --> 00:01:02,940
here in the morning Rene actually

23
00:01:02,940 --> 00:01:05,400
brought up a report that I cited as well

24
00:01:05,400 --> 00:01:09,630
Oxford did a really good research on the

25
00:01:09,630 --> 00:01:11,280
global disinformation order they came

26
00:01:11,280 --> 00:01:13,470
out last month and they say the

27
00:01:13,470 --> 00:01:15,320
following quote that pretty much

28
00:01:15,320 --> 00:01:17,100
governments all around the world are

29
00:01:17,100 --> 00:01:19,439
running influence operations some

30
00:01:19,439 --> 00:01:21,600
something like 26 plus countries have

31
00:01:21,600 --> 00:01:22,890
been attributed to dissing fill

32
00:01:22,890 --> 00:01:25,170
campaigns and that's only nation-states

33
00:01:25,170 --> 00:01:26,820
there's a lot of private companies doing

34
00:01:26,820 --> 00:01:29,310
this and if any of you would like to

35
00:01:29,310 --> 00:01:30,960
read the report after I can show you the

36
00:01:30,960 --> 00:01:32,579
printed copy I have already email you

37
00:01:32,579 --> 00:01:39,659
the actual one in a nutshell

38
00:01:39,659 --> 00:01:41,759
I'm gonna be talking about how I use

39
00:01:41,759 --> 00:01:44,880
brain space which is a software that six

40
00:01:44,880 --> 00:01:48,000
your owns to look at this information

41
00:01:48,000 --> 00:01:51,329
campaigns and use new data sign Sciences

42
00:01:51,329 --> 00:01:53,460
scientific ways of analyzing

43
00:01:53,460 --> 00:01:55,079
disinformation and social media data in

44
00:01:55,079 --> 00:01:57,600
ways that other companies and research

45
00:01:57,600 --> 00:02:00,240
agencies have not we're gonna be going

46
00:02:00,240 --> 00:02:02,729
beyond basic statistics which is what

47
00:02:02,729 --> 00:02:05,460
mainly everyone does and we're going to

48
00:02:05,460 --> 00:02:07,140
be using machine learning natural

49
00:02:07,140 --> 00:02:08,550
language processing and sentiment

50
00:02:08,550 --> 00:02:13,360
analysis to uncover influence ops

51
00:02:13,360 --> 00:02:14,890
I chose to do my research when I was at

52
00:02:14,890 --> 00:02:16,930
immunity on brexit because unlike the

53
00:02:16,930 --> 00:02:19,450
2016 election it was written about but a

54
00:02:19,450 --> 00:02:21,130
lot of the analysis was a pretty

55
00:02:21,130 --> 00:02:23,920
rudimentary so I thought it was a good

56
00:02:23,920 --> 00:02:29,800
topic to to work on and just some

57
00:02:29,800 --> 00:02:30,870
background brain space is a

58
00:02:30,870 --> 00:02:32,980
traditionally made for ediscovery which

59
00:02:32,980 --> 00:02:35,260
is like a legal thing people use you

60
00:02:35,260 --> 00:02:37,750
ingest typically like case files from

61
00:02:37,750 --> 00:02:40,420
from from a lawsuit and it'll we'll do a

62
00:02:40,420 --> 00:02:42,160
bunch of statistical analysis it will

63
00:02:42,160 --> 00:02:43,900
group individuals phone numbers

64
00:02:43,900 --> 00:02:46,480
everything together most of the clients

65
00:02:46,480 --> 00:02:48,580
that purchased it today I use it for the

66
00:02:48,580 --> 00:02:50,260
legal industry but there's other

67
00:02:50,260 --> 00:02:52,560
applications of it that we'll see today

68
00:02:52,560 --> 00:02:55,090
this is a general breakdown of my

69
00:02:55,090 --> 00:02:56,260
presentation so you know what to expect

70
00:02:56,260 --> 00:02:59,650
I'm not gonna talk about I'm gonna talk

71
00:02:59,650 --> 00:03:00,820
about all these but I'm not gonna read

72
00:03:00,820 --> 00:03:05,230
them because we will see them so in

73
00:03:05,230 --> 00:03:08,860
general but people that run influence

74
00:03:08,860 --> 00:03:11,260
operations constantly change their TTP's

75
00:03:11,260 --> 00:03:12,510
techniques tactics and procedures

76
00:03:12,510 --> 00:03:14,560
because there's always a catch-up game

77
00:03:14,560 --> 00:03:16,450
between the people running these

78
00:03:16,450 --> 00:03:18,730
disinformation campaigns and the people

79
00:03:18,730 --> 00:03:20,320
combating them like the people that I

80
00:03:20,320 --> 00:03:21,940
report just like this like the people

81
00:03:21,940 --> 00:03:23,830
like Renee that work on uncovering

82
00:03:23,830 --> 00:03:25,989
what's happening so some of the

83
00:03:25,989 --> 00:03:27,549
historical ways that we've been able to

84
00:03:27,549 --> 00:03:29,140
detect bots these are some

85
00:03:29,140 --> 00:03:32,140
characteristics the Internet research

86
00:03:32,140 --> 00:03:34,180
agency and and bots similar to it well

87
00:03:34,180 --> 00:03:36,820
they would post you know 24/7 at hour

88
00:03:36,820 --> 00:03:39,549
hours like Moscow time pretending to be

89
00:03:39,549 --> 00:03:41,830
Americans those accounts on Twitter

90
00:03:41,830 --> 00:03:44,170
would have extremely high amounts of

91
00:03:44,170 --> 00:03:46,180
interactions but they're only like

92
00:03:46,180 --> 00:03:48,070
retweet people they're not gonna post

93
00:03:48,070 --> 00:03:51,610
anything original at the beginning they

94
00:03:51,610 --> 00:03:53,560
used pictures pulled from random

95
00:03:53,560 --> 00:03:55,660
websites that were easily reverse image

96
00:03:55,660 --> 00:03:58,630
searchable sometimes it would have

97
00:03:58,630 --> 00:04:03,070
handles with a like like Jeff Smith zero

98
00:04:03,070 --> 00:04:05,200
zero six nine four through three which

99
00:04:05,200 --> 00:04:07,030
is like not a normal handle that someone

100
00:04:07,030 --> 00:04:09,370
would use on Twitter and sometimes they

101
00:04:09,370 --> 00:04:10,989
would use third-party applications to

102
00:04:10,989 --> 00:04:14,470
post tweets and you could see that in a

103
00:04:14,470 --> 00:04:16,630
lot of the previous work other people

104
00:04:16,630 --> 00:04:19,930
have done what people are not good at is

105
00:04:19,930 --> 00:04:21,880
looking at sock puppet accounts so

106
00:04:21,880 --> 00:04:24,280
accounts that pretend to be someone that

107
00:04:24,280 --> 00:04:26,260
they're not there might be operated by I

108
00:04:26,260 --> 00:04:27,190
think

109
00:04:27,190 --> 00:04:30,070
Rene called it a cyborg like as a person

110
00:04:30,070 --> 00:04:32,770
running it but uh they're not they're

111
00:04:32,770 --> 00:04:34,740
semi-automatic or not automated at all

112
00:04:34,740 --> 00:04:39,100
and there are tools like bottle meter

113
00:04:39,100 --> 00:04:41,830
that can find a lot of the old ways of

114
00:04:41,830 --> 00:04:47,320
detecting BOTS so the goal of my

115
00:04:47,320 --> 00:04:49,900
research was to to look at BOTS that are

116
00:04:49,900 --> 00:04:52,480
highly ideological on Twitter so they're

117
00:04:52,480 --> 00:04:54,160
talking about politics but they're very

118
00:04:54,160 --> 00:04:57,760
like Pro this anti that very Pro this

119
00:04:57,760 --> 00:05:00,850
ideology and he that ideology and I want

120
00:05:00,850 --> 00:05:02,650
to do it in a way that's very scientific

121
00:05:02,650 --> 00:05:06,190
and data science driven so the target

122
00:05:06,190 --> 00:05:08,290
for a research was Theresa May at the

123
00:05:08,290 --> 00:05:10,180
time that we were doing this research

124
00:05:10,180 --> 00:05:12,220
she was the prime minister of the UK and

125
00:05:12,220 --> 00:05:15,730
she has a public Twitter account what we

126
00:05:15,730 --> 00:05:19,390
did was we ran a Python script that

127
00:05:19,390 --> 00:05:22,210
would scrape her most recent hundred

128
00:05:22,210 --> 00:05:25,840
thousand followers and from that from

129
00:05:25,840 --> 00:05:27,880
each of those accounts take their two

130
00:05:27,880 --> 00:05:30,400
hundred tweets retweets and who they're

131
00:05:30,400 --> 00:05:32,230
interacting with we would also take

132
00:05:32,230 --> 00:05:35,169
attributes of those tweets like what

133
00:05:35,169 --> 00:05:36,820
time of day they sent it what

134
00:05:36,820 --> 00:05:38,410
application they use to post the tweets

135
00:05:38,410 --> 00:05:41,980
and we ingested that onto brain space

136
00:05:41,980 --> 00:05:43,930
this is a technology stack of how the

137
00:05:43,930 --> 00:05:48,630
research looks from the back end we have

138
00:05:48,630 --> 00:05:53,380
Python using using some some open source

139
00:05:53,380 --> 00:05:56,169
software we pulled all the data we did

140
00:05:56,169 --> 00:05:57,550
some data engineering to clean it and

141
00:05:57,550 --> 00:05:59,740
then we ingest it into brain space as

142
00:05:59,740 --> 00:06:01,990
the DAT file and we mapped all the

143
00:06:01,990 --> 00:06:04,500
fields to their appropriate uh

144
00:06:04,500 --> 00:06:07,720
attributes and we made sure and brain

145
00:06:07,720 --> 00:06:10,060
space there's a lot of work by itself

146
00:06:10,060 --> 00:06:13,360
when you ingest data like natural

147
00:06:13,360 --> 00:06:15,669
language processing translating and a

148
00:06:15,669 --> 00:06:19,270
lot of search tools so before you do any

149
00:06:19,270 --> 00:06:20,980
data science project you really want to

150
00:06:20,980 --> 00:06:22,690
understand what you're working on

151
00:06:22,690 --> 00:06:23,669
you just want don't want to throw

152
00:06:23,669 --> 00:06:25,720
garbage data into a neural net and

153
00:06:25,720 --> 00:06:27,730
expect good quality results because

154
00:06:27,730 --> 00:06:29,650
you're not going to get that at the

155
00:06:29,650 --> 00:06:30,790
beginning this project there was a lot

156
00:06:30,790 --> 00:06:32,440
of data exploration work that had to be

157
00:06:32,440 --> 00:06:34,540
done so me as an analyst can understand

158
00:06:34,540 --> 00:06:36,640
what's going on brain space has this

159
00:06:36,640 --> 00:06:38,950
really cool feature where if you look up

160
00:06:38,950 --> 00:06:41,020
a search term like like wine

161
00:06:41,020 --> 00:06:43,300
you're not just gonna get tweets that

162
00:06:43,300 --> 00:06:46,360
say wine brain space using a lot of like

163
00:06:46,360 --> 00:06:47,979
math and does the whole data science

164
00:06:47,979 --> 00:06:50,500
team behind this they can find terms

165
00:06:50,500 --> 00:06:53,680
that are related to the word wine like I

166
00:06:53,680 --> 00:06:55,060
don't drink but I know like these are

167
00:06:55,060 --> 00:06:57,370
some of the types of a wine types there

168
00:06:57,370 --> 00:06:59,139
are and this is a guy that maybe makes

169
00:06:59,139 --> 00:07:01,930
wine so if you have a limited set of

170
00:07:01,930 --> 00:07:03,610
keywords that you know as an analyst or

171
00:07:03,610 --> 00:07:07,479
search terms it'll find using it it's a

172
00:07:07,479 --> 00:07:09,789
the way it works it'll find similar

173
00:07:09,789 --> 00:07:12,990
terms that will help you find suspicious

174
00:07:12,990 --> 00:07:19,210
documents or tweets so we're looking at

175
00:07:19,210 --> 00:07:23,620
a tweet behavior in that I like BOTS

176
00:07:23,620 --> 00:07:25,240
they operate like marketing BOTS there

177
00:07:25,240 --> 00:07:26,710
they're tweeting out they're trying to

178
00:07:26,710 --> 00:07:29,349
push a message out and they're doing

179
00:07:29,349 --> 00:07:33,430
that to stay relevant and we're looking

180
00:07:33,430 --> 00:07:35,830
at content and behavior as opposed to

181
00:07:35,830 --> 00:07:40,020
just like languages so we're looking for

182
00:07:40,020 --> 00:07:43,539
more of the inherent behaviors that

183
00:07:43,539 --> 00:07:46,960
these accounts have one of the first

184
00:07:46,960 --> 00:07:50,190
things I did when I did this research is

185
00:07:50,190 --> 00:07:54,250
we in the in the data set you might be

186
00:07:54,250 --> 00:07:56,349
wondering why Trump is here on Twitter

187
00:07:56,349 --> 00:07:57,639
Trump is one of the most mentioned

188
00:07:57,639 --> 00:08:00,279
people on Twitter people at him sub

189
00:08:00,279 --> 00:08:01,870
tweeted him talk about him all the time

190
00:08:01,870 --> 00:08:05,590
and coincidentally like a lot of his

191
00:08:05,590 --> 00:08:08,469
data was in our data set as well so if

192
00:08:08,469 --> 00:08:11,020
you click on his node in brain space you

193
00:08:11,020 --> 00:08:13,389
have this beautiful UI and I'll show you

194
00:08:13,389 --> 00:08:15,069
the top accounts interacting with him

195
00:08:15,069 --> 00:08:17,050
and if you can see there's a there's

196
00:08:17,050 --> 00:08:20,169
burst patterns here they're there

197
00:08:20,169 --> 00:08:23,199
they're everywhere so this is kind of

198
00:08:23,199 --> 00:08:25,599
indicative of a bot it's tweeting

199
00:08:25,599 --> 00:08:27,130
outwards now how many people are

200
00:08:27,130 --> 00:08:28,659
tweeting to it

201
00:08:28,659 --> 00:08:30,039
you can kind of tell us trying to push a

202
00:08:30,039 --> 00:08:32,140
message a normal person when they're

203
00:08:32,140 --> 00:08:33,789
talking on Twitter imagine like one of

204
00:08:33,789 --> 00:08:35,409
these tables just like five six of you

205
00:08:35,409 --> 00:08:36,789
there you're gonna be talking to each

206
00:08:36,789 --> 00:08:38,200
other it's gonna be more like a mesh

207
00:08:38,200 --> 00:08:41,578
network this is more like just stars if

208
00:08:41,578 --> 00:08:45,339
we're gonna look at a this suspected bot

209
00:08:45,339 --> 00:08:50,470
right here and as you can see it only

210
00:08:50,470 --> 00:08:52,870
tweets outwards

211
00:08:52,870 --> 00:08:54,750
it's n96 tweets every

212
00:08:54,750 --> 00:08:57,270
zero this Twitter account is so active

213
00:08:57,270 --> 00:08:58,800
and if ever you guys want to look it up

214
00:08:58,800 --> 00:09:02,760
right now this is a bio it's talking to

215
00:09:02,760 --> 00:09:06,680
State Department Trump Sean Hannity

216
00:09:06,680 --> 00:09:09,630
Liana Trump Netanyahu State Department

217
00:09:09,630 --> 00:09:13,080
and the bio is really suspicious it's

218
00:09:13,080 --> 00:09:15,360
like I'm a woman I'm a judge and

219
00:09:15,360 --> 00:09:17,610
Anchorage there's like unicode

220
00:09:17,610 --> 00:09:20,220
characters that aren't like being trans

221
00:09:20,220 --> 00:09:22,500
they're not showing up correctly and I

222
00:09:22,500 --> 00:09:24,270
went through her followers and this was

223
00:09:24,270 --> 00:09:25,980
one of them who has a very similar bio

224
00:09:25,980 --> 00:09:27,930
they have a lot of followers and

225
00:09:27,930 --> 00:09:30,600
followings and I reverse image search a

226
00:09:30,600 --> 00:09:33,030
lot of her pictures it seems to be

227
00:09:33,030 --> 00:09:34,380
pulling from some private Instagram

228
00:09:34,380 --> 00:09:37,290
account it's still active today if you

229
00:09:37,290 --> 00:09:39,860
want to look at it

230
00:09:42,410 --> 00:09:45,330
this is using the UI again we're looking

231
00:09:45,330 --> 00:09:47,550
at an account that talks that tweets at

232
00:09:47,550 --> 00:09:50,330
Trump and tweets at Jacob reef Moss

233
00:09:50,330 --> 00:09:53,270
Nigel Farage and Theresa May it's this

234
00:09:53,270 --> 00:09:54,840
one in the corner

235
00:09:54,840 --> 00:09:57,390
it's tweeting out words we can see that

236
00:09:57,390 --> 00:09:59,700
it falls the same pattern as the

237
00:09:59,700 --> 00:10:02,550
previous count does receive some tweets

238
00:10:02,550 --> 00:10:04,470
but most of the search terms associated

239
00:10:04,470 --> 00:10:06,930
with this account you can see it's like

240
00:10:06,930 --> 00:10:10,170
get paid to retweet get paid to like get

241
00:10:10,170 --> 00:10:13,970
paid to post this is a one of those uh

242
00:10:13,970 --> 00:10:15,960
accounts that you can interact with and

243
00:10:15,960 --> 00:10:18,570
you paid money and it'll push a certain

244
00:10:18,570 --> 00:10:21,660
hashtag or give you likes but

245
00:10:21,660 --> 00:10:23,280
interestingly this account was talk of

246
00:10:23,280 --> 00:10:25,950
doing a lot of political work to I was

247
00:10:25,950 --> 00:10:27,330
talking to Nigel Farage or at least

248
00:10:27,330 --> 00:10:30,170
retweeting him a lot

249
00:10:37,450 --> 00:10:41,380
so the methodology we use for this for

250
00:10:41,380 --> 00:10:43,410
this research is we wanted to make four

251
00:10:43,410 --> 00:10:46,120
buckets of ideologies to look at we

252
00:10:46,120 --> 00:10:48,910
wants to look at Pro brexit people anti

253
00:10:48,910 --> 00:10:52,030
brexit people Pro Trump people and anti

254
00:10:52,030 --> 00:10:53,830
Trump people and we want to see how

255
00:10:53,830 --> 00:10:56,290
these groups interacted either

256
00:10:56,290 --> 00:10:58,200
independently in their own ideology or

257
00:10:58,200 --> 00:11:00,280
talking about different ideologies at

258
00:11:00,280 --> 00:11:02,350
the same time this is a screenshot from

259
00:11:02,350 --> 00:11:05,560
brain space on the number of tweets I

260
00:11:05,560 --> 00:11:08,260
trained the pro brexit classifier on the

261
00:11:08,260 --> 00:11:10,300
number of tweets I trained the pro Trump

262
00:11:10,300 --> 00:11:14,050
classifier on and this pretty much

263
00:11:14,050 --> 00:11:16,210
eliminates having to manually go through

264
00:11:16,210 --> 00:11:17,770
thousands of accounts or thousands of

265
00:11:17,770 --> 00:11:20,580
tweets and labeling them individually

266
00:11:20,580 --> 00:11:23,470
Clemson University did a did a really

267
00:11:23,470 --> 00:11:24,880
cool research on the internet research

268
00:11:24,880 --> 00:11:27,960
agency and they looked at manually about

269
00:11:27,960 --> 00:11:30,940
3,800 accounts and they classified each

270
00:11:30,940 --> 00:11:33,250
as like pro-trump conservative-liberal

271
00:11:33,250 --> 00:11:36,640
etc but 3,800 accounts look at is

272
00:11:36,640 --> 00:11:40,000
insanely time consuming and FTE

273
00:11:40,000 --> 00:11:42,130
consuming so we don't want to do that

274
00:11:42,130 --> 00:11:43,570
because that doesn't scale and we're

275
00:11:43,570 --> 00:11:46,750
smart people we can utilize meds as

276
00:11:46,750 --> 00:11:48,550
we've learned in data science to help us

277
00:11:48,550 --> 00:11:52,870
solve these problems so we have this

278
00:11:52,870 --> 00:11:55,360
feature in in brain space called CM ml

279
00:11:55,360 --> 00:11:57,370
which stands for continuous multimodal

280
00:11:57,370 --> 00:12:00,870
learning which is pretty much how our

281
00:12:00,870 --> 00:12:05,440
program will classify tweets based off

282
00:12:05,440 --> 00:12:07,960
of an ideology so I trained this one to

283
00:12:07,960 --> 00:12:11,080
look for Pro brexit tweets I only needed

284
00:12:11,080 --> 00:12:13,420
to look find like six around 60 tweets

285
00:12:13,420 --> 00:12:16,960
and once you train it it'll go through

286
00:12:16,960 --> 00:12:18,970
the four point eight million tweets that

287
00:12:18,970 --> 00:12:20,710
we have in the data set it will find

288
00:12:20,710 --> 00:12:24,370
accounts that talk about brexit five

289
00:12:24,370 --> 00:12:26,590
times or more so we considered these

290
00:12:26,590 --> 00:12:28,810
like highly political accounts but

291
00:12:28,810 --> 00:12:30,520
they're also highly highly ideological

292
00:12:30,520 --> 00:12:32,800
when it comes to a brexit and it would

293
00:12:32,800 --> 00:12:35,500
give each of these accounts each of

294
00:12:35,500 --> 00:12:37,990
these tweets in the 4.8 million a score

295
00:12:37,990 --> 00:12:41,110
from zero one after how ideologic what

296
00:12:41,110 --> 00:12:43,860
is being pro brexit

297
00:12:43,860 --> 00:12:47,050
this is the process so at the beginning

298
00:12:47,050 --> 00:12:49,600
it's doing the data exploration then

299
00:12:49,600 --> 00:12:51,160
it's training the model

300
00:12:51,160 --> 00:12:52,779
then you run them all on data set to

301
00:12:52,779 --> 00:12:54,879
give every kind of score and then we use

302
00:12:54,879 --> 00:12:57,970
brain spaces API using a small Python

303
00:12:57,970 --> 00:13:01,629
script to give each tweet and each

304
00:13:01,629 --> 00:13:03,940
account well each account holder a score

305
00:13:03,940 --> 00:13:06,310
between 0 1 then we're gonna filter do

306
00:13:06,310 --> 00:13:08,230
that list and look for the top 30 in

307
00:13:08,230 --> 00:13:10,149
each ideology so we're looking at the

308
00:13:10,149 --> 00:13:13,540
top 30 and pro-trump anti-trump probe

309
00:13:13,540 --> 00:13:17,139
exit auntie practice this is manual Oh

310
00:13:17,139 --> 00:13:20,139
sent work to detect and classify their

311
00:13:20,139 --> 00:13:23,560
BOTS doing the Oh sent on individual

312
00:13:23,560 --> 00:13:24,699
counts these are some of the tools I

313
00:13:24,699 --> 00:13:27,160
used if any of you guys do reverse image

314
00:13:27,160 --> 00:13:28,870
searching for your work and

315
00:13:28,870 --> 00:13:31,269
investigations Google Image Search is

316
00:13:31,269 --> 00:13:32,709
the most common one that people have

317
00:13:32,709 --> 00:13:34,810
heard of you feed it an image it will

318
00:13:34,810 --> 00:13:36,879
find if there's any variations of that

319
00:13:36,879 --> 00:13:38,769
image online however there's another

320
00:13:38,769 --> 00:13:41,319
program that the Russians built in a and

321
00:13:41,319 --> 00:13:44,649
X that's so much more accurate when it

322
00:13:44,649 --> 00:13:46,269
comes to facial recognition and image

323
00:13:46,269 --> 00:13:48,550
detection I use that to being uncover a

324
00:13:48,550 --> 00:13:50,920
lot of people that I couldn't find with

325
00:13:50,920 --> 00:13:52,329
Google Image Search for example like I

326
00:13:52,329 --> 00:13:54,819
found a suspicious account and it was

327
00:13:54,819 --> 00:13:59,230
just a guy with a with the webcam and I

328
00:13:59,230 --> 00:14:00,189
was like hey look this is kind of

329
00:14:00,189 --> 00:14:01,750
weird-looking I reverse image search

330
00:14:01,750 --> 00:14:03,490
setting Yandex and it came up with this

331
00:14:03,490 --> 00:14:04,870
dating profile on some other website

332
00:14:04,870 --> 00:14:06,970
with a different image not even the same

333
00:14:06,970 --> 00:14:09,519
image so with that I can tell like hey

334
00:14:09,519 --> 00:14:11,230
maybe this guy is very proactive but

335
00:14:11,230 --> 00:14:13,329
he's a real person and his I did some

336
00:14:13,329 --> 00:14:15,550
Olson on him and I seek which is like a

337
00:14:15,550 --> 00:14:18,339
psycho Google with like a buckets and

338
00:14:18,339 --> 00:14:20,350
pretty much if you have with the the

339
00:14:20,350 --> 00:14:23,709
real name of a target you can find out

340
00:14:23,709 --> 00:14:26,170
if they're actually real because you can

341
00:14:26,170 --> 00:14:28,620
find documents that relate to them I

342
00:14:28,620 --> 00:14:32,259
also used borrow meter as a eyeball

343
00:14:32,259 --> 00:14:34,360
weather account was suspicious so bottle

344
00:14:34,360 --> 00:14:36,069
meter is something that I think Indiana

345
00:14:36,069 --> 00:14:38,319
University created it's free you feed it

346
00:14:38,319 --> 00:14:41,319
a handle and I'll give it a score and a

347
00:14:41,319 --> 00:14:43,000
percentage of like what it thinks if

348
00:14:43,000 --> 00:14:45,790
it's a bot or not I use that pretty much

349
00:14:45,790 --> 00:14:48,370
just to check my work but it's not

350
00:14:48,370 --> 00:14:50,800
always accurate but it is a good tool

351
00:14:50,800 --> 00:14:53,790
and our tool set

352
00:14:57,770 --> 00:15:01,860
so these are some more results in the

353
00:15:01,860 --> 00:15:05,430
pro-trump bucket we saw that a 50% of

354
00:15:05,430 --> 00:15:08,400
them that were highly ideological in our

355
00:15:08,400 --> 00:15:11,070
data set were BOTS and the probe brexit

356
00:15:11,070 --> 00:15:13,050
we saw that 66 percent of them were BOTS

357
00:15:13,050 --> 00:15:15,270
and then we looked at the intersection

358
00:15:15,270 --> 00:15:19,530
of these two lists and the top accounts

359
00:15:19,530 --> 00:15:21,690
in this list 38 percent of them were

360
00:15:21,690 --> 00:15:24,900
BOTS while the rest were were not BOTS

361
00:15:24,900 --> 00:15:28,170
but well this may imply it's not

362
00:15:28,170 --> 00:15:29,640
guaranteed is that whoever's running

363
00:15:29,640 --> 00:15:33,660
these BOTS may feel a use to reuse their

364
00:15:33,660 --> 00:15:36,750
pro-trump accounts also to push Pro

365
00:15:36,750 --> 00:15:41,040
brexit tweets we looked at the anti

366
00:15:41,040 --> 00:15:42,750
brexit and anti-trump site as well and

367
00:15:42,750 --> 00:15:46,290
the anti-trump individually we saw that

368
00:15:46,290 --> 00:15:49,050
about 17% were bots in the anti brags

369
00:15:49,050 --> 00:15:51,540
that we saw that around 17% were bots as

370
00:15:51,540 --> 00:15:53,610
well and accounts talking about both

371
00:15:53,610 --> 00:15:57,900
were slightly more at 23% so there's

372
00:15:57,900 --> 00:15:59,730
someone or some organization or some

373
00:15:59,730 --> 00:16:00,690
nation-state I mean

374
00:16:00,690 --> 00:16:02,340
attribution is not in my scope of

375
00:16:02,340 --> 00:16:04,590
research but there are some groups that

376
00:16:04,590 --> 00:16:07,170
are pushing bot messages when it comes

377
00:16:07,170 --> 00:16:09,390
to these two ideologies and their

378
00:16:09,390 --> 00:16:12,960
combination then I figured like what

379
00:16:12,960 --> 00:16:14,370
kind of person is Pro brexit and

380
00:16:14,370 --> 00:16:16,170
anti-trump people tend to if their

381
00:16:16,170 --> 00:16:17,880
right-wing in one country they tend to

382
00:16:17,880 --> 00:16:19,140
ally with the right-wing in another

383
00:16:19,140 --> 00:16:20,940
country just because ideologically it's

384
00:16:20,940 --> 00:16:21,830
it's similar

385
00:16:21,830 --> 00:16:24,440
there was an intersection between

386
00:16:24,440 --> 00:16:28,860
anti-trump and pro brexit and 23 percent

387
00:16:28,860 --> 00:16:31,080
of them were BOTS and to me that's

388
00:16:31,080 --> 00:16:35,280
really interesting it may be people are

389
00:16:35,280 --> 00:16:36,930
actually like that well a large portion

390
00:16:36,930 --> 00:16:39,210
of them are real but there are bots in

391
00:16:39,210 --> 00:16:41,100
this and it backs a question who are

392
00:16:41,100 --> 00:16:43,230
running who is running an operation like

393
00:16:43,230 --> 00:16:45,330
this that benefits to being both of

394
00:16:45,330 --> 00:16:48,570
these ideologies similarly we did it

395
00:16:48,570 --> 00:16:51,060
also with anti brexit and pro-trump

396
00:16:51,060 --> 00:16:53,430
so you can see that 10% of them were

397
00:16:53,430 --> 00:16:57,120
extremely Pro krump but for some reason

398
00:16:57,120 --> 00:16:58,470
they don't have good things to say about

399
00:16:58,470 --> 00:17:02,760
braking again this is strange to me I

400
00:17:02,760 --> 00:17:05,220
haven't met anyone that is like that but

401
00:17:05,220 --> 00:17:07,439
then again I don't live in the UK which

402
00:17:07,439 --> 00:17:10,819
was the topic with focus of our research

403
00:17:10,819 --> 00:17:13,549
so we also looked at a bottle meter and

404
00:17:13,549 --> 00:17:15,919
how how we used bottle meter as a

405
00:17:15,919 --> 00:17:19,250
benchmark to see how's it doing compared

406
00:17:19,250 --> 00:17:21,349
to the what we built and we saw that 78

407
00:17:21,349 --> 00:17:23,059
percent of the time it agreed with our

408
00:17:23,059 --> 00:17:25,669
analysis but bottom idea was really bad

409
00:17:25,669 --> 00:17:28,369
at finding sock puppets and cyborgs and

410
00:17:28,369 --> 00:17:30,679
telling us if there are BOTS because

411
00:17:30,679 --> 00:17:33,279
they're acting more like humans but uh

412
00:17:33,279 --> 00:17:36,799
but yeah that's just one more evidence

413
00:17:36,799 --> 00:17:38,210
that's just another piece of evidence to

414
00:17:38,210 --> 00:17:40,159
suggest that the tools we built to look

415
00:17:40,159 --> 00:17:42,679
at the 2016 election and how BOTS used

416
00:17:42,679 --> 00:17:45,559
to operate aren't as relevant anymore so

417
00:17:45,559 --> 00:17:48,620
what's the takeaway from this we know

418
00:17:48,620 --> 00:17:52,580
that pro-trump and and pro brexit that

419
00:17:52,580 --> 00:17:56,259
subsection is heavily driven by BOTS and

420
00:17:56,259 --> 00:17:58,669
we want to try to find out who runs

421
00:17:58,669 --> 00:18:00,559
these or it's just interesting to know

422
00:18:00,559 --> 00:18:04,009
that there's someone interested in

423
00:18:04,009 --> 00:18:06,769
pushing this message we also saw that

424
00:18:06,769 --> 00:18:09,139
BOTS push these combinations of

425
00:18:09,139 --> 00:18:12,110
ideologies so this may imply reuse of

426
00:18:12,110 --> 00:18:15,230
accounts between whoever's running these

427
00:18:15,230 --> 00:18:18,379
operations or it may imply that you know

428
00:18:18,379 --> 00:18:19,970
humans hold multiple ideologies at the

429
00:18:19,970 --> 00:18:22,210
same time you know we're sophisticated

430
00:18:22,210 --> 00:18:24,190
animals like we're gonna have

431
00:18:24,190 --> 00:18:26,990
simultaneously be allied with one

432
00:18:26,990 --> 00:18:28,730
government in one country and be a live

433
00:18:28,730 --> 00:18:29,659
with another government in another

434
00:18:29,659 --> 00:18:31,039
country even though their ideologies

435
00:18:31,039 --> 00:18:33,950
don't match the other takeaway is that

436
00:18:33,950 --> 00:18:37,190
uh you know bod makers are constantly

437
00:18:37,190 --> 00:18:38,929
changing the way that they do their work

438
00:18:38,929 --> 00:18:41,360
they're constantly changing being

439
00:18:41,360 --> 00:18:44,419
detected by by by the Metz's researchers

440
00:18:44,419 --> 00:18:47,149
are writing about so in fact my work

441
00:18:47,149 --> 00:18:49,340
might be an underestimation of how bots

442
00:18:49,340 --> 00:18:51,169
are actually talking about politics

443
00:18:51,169 --> 00:18:54,730
online and breaks it online

444
00:18:56,110 --> 00:18:59,960
so within comes to Canada we saw before

445
00:18:59,960 --> 00:19:02,509
the election Canada was work very

446
00:19:02,509 --> 00:19:03,830
concerned about Twitter being used for

447
00:19:03,830 --> 00:19:05,809
misinformation like it was used during

448
00:19:05,809 --> 00:19:08,809
the 2016 election in the US I'm not

449
00:19:08,809 --> 00:19:10,580
terribly familiar with Canadian politics

450
00:19:10,580 --> 00:19:12,320
but we had a government official called

451
00:19:12,320 --> 00:19:14,600
Gould saying that Twitter needs to be

452
00:19:14,600 --> 00:19:17,570
more responsible about the way it deals

453
00:19:17,570 --> 00:19:20,510
with the misinformation and it needs to

454
00:19:20,510 --> 00:19:21,940
work with the Canadian government to

455
00:19:21,940 --> 00:19:24,580
find ways of mitigate

456
00:19:24,580 --> 00:19:28,450
the risk we also saw the Canada

457
00:19:28,450 --> 00:19:30,340
Declaration on electoral integrity

458
00:19:30,340 --> 00:19:33,070
online which had a subsection that

459
00:19:33,070 --> 00:19:35,710
talked about BOTS and there were some

460
00:19:35,710 --> 00:19:37,870
articles on how Facebook said it

461
00:19:37,870 --> 00:19:39,820
wouldn't remove this information or

462
00:19:39,820 --> 00:19:44,770
doctored tweets or posts during the

463
00:19:44,770 --> 00:19:45,880
Canadian election which is very

464
00:19:45,880 --> 00:19:47,380
concerning to a lot of you in the crowd

465
00:19:47,380 --> 00:19:54,430
being from the Canadian government after

466
00:19:54,430 --> 00:19:57,240
the election election just happened

467
00:19:57,240 --> 00:20:00,280
research takes some time to complete but

468
00:20:00,280 --> 00:20:01,780
from the from the get-go there are some

469
00:20:01,780 --> 00:20:03,850
people like Marco and Jones that did

470
00:20:03,850 --> 00:20:06,250
some preliminary research finding

471
00:20:06,250 --> 00:20:08,580
misinformation and disinformation and

472
00:20:08,580 --> 00:20:11,230
election discourse online he looked at

473
00:20:11,230 --> 00:20:13,420
prototype accounts that are pushing

474
00:20:13,420 --> 00:20:16,180
entry trudeau hashtags and he did a

475
00:20:16,180 --> 00:20:18,790
great Twitter thread on this and later

476
00:20:18,790 --> 00:20:20,770
came into a Washington Post article

477
00:20:20,770 --> 00:20:24,610
which I would suggest you look up the

478
00:20:24,610 --> 00:20:26,500
first draft also did a similar research

479
00:20:26,500 --> 00:20:30,550
on how Boris Johnson was a being boosted

480
00:20:30,550 --> 00:20:32,830
by suspicious accounts when I came to

481
00:20:32,830 --> 00:20:35,890
brexit both of these both of these

482
00:20:35,890 --> 00:20:38,800
research is not as data sciency as you

483
00:20:38,800 --> 00:20:40,900
would you would think when it comes to

484
00:20:40,900 --> 00:20:42,430
Marco and Jones research he does great

485
00:20:42,430 --> 00:20:46,660
work but his research classified a pro

486
00:20:46,660 --> 00:20:48,550
Trump account as an account that had

487
00:20:48,550 --> 00:20:50,500
pro-trump hash tags and keywords and its

488
00:20:50,500 --> 00:20:53,620
bio that doesn't take into account like

489
00:20:53,620 --> 00:20:55,720
people on Twitter that that may be pro

490
00:20:55,720 --> 00:20:59,380
Trump you know anteater Gro that don't

491
00:20:59,380 --> 00:21:00,790
have anything relate to Trump in there

492
00:21:00,790 --> 00:21:03,100
and they're in their bio because they

493
00:21:03,100 --> 00:21:05,740
want to hide so I think that marco means

494
00:21:05,740 --> 00:21:08,860
jones work underestimates the influence

495
00:21:08,860 --> 00:21:10,330
of bots during the Canadian election and

496
00:21:10,330 --> 00:21:13,470
when it comes to the Boris Johnson

497
00:21:13,470 --> 00:21:16,120
research he only looked at about a

498
00:21:16,120 --> 00:21:18,370
hundred thousand accounts we're looking

499
00:21:18,370 --> 00:21:20,020
at a hundred thousand tweets we're

500
00:21:20,020 --> 00:21:21,070
looking at four point eight million

501
00:21:21,070 --> 00:21:26,380
tweets so his and and the first draft

502
00:21:26,380 --> 00:21:28,300
only the basic statistical analysis when

503
00:21:28,300 --> 00:21:31,540
it came to this research so I think that

504
00:21:31,540 --> 00:21:33,130
the work these people will do is great

505
00:21:33,130 --> 00:21:34,420
because it's a start and these are all

506
00:21:34,420 --> 00:21:36,100
people that do it in the private sector

507
00:21:36,100 --> 00:21:37,270
they're not they're not related to the

508
00:21:37,270 --> 00:21:38,050
government

509
00:21:38,050 --> 00:21:41,470
it requires more research we uh we know

510
00:21:41,470 --> 00:21:43,840
that a Canada has a lot of tensions with

511
00:21:43,840 --> 00:21:46,570
the the country of China right now back

512
00:21:46,570 --> 00:21:48,550
when I was doing this research a huawei

513
00:21:48,550 --> 00:21:52,320
CFO was arrested here in Canada

514
00:21:52,320 --> 00:21:54,460
pressured by the US government is

515
00:21:54,460 --> 00:21:57,250
pressuring Canada to deport her to the

516
00:21:57,250 --> 00:21:59,650
US where she I think is being indicted

517
00:21:59,650 --> 00:22:01,870
for violating sanctions or some some

518
00:22:01,870 --> 00:22:04,360
rules really to fall way but but

519
00:22:04,360 --> 00:22:06,310
coincidentally I when I went on brain

520
00:22:06,310 --> 00:22:07,930
space I did this I want to look at

521
00:22:07,930 --> 00:22:09,250
Chinese bots and see if they were in my

522
00:22:09,250 --> 00:22:13,120
in my dataset so I looked up show me all

523
00:22:13,120 --> 00:22:15,940
the tweets that say Chinese and I found

524
00:22:15,940 --> 00:22:18,430
this cluster around Trudeau and then I

525
00:22:18,430 --> 00:22:20,710
was like show me all the tweets in

526
00:22:20,710 --> 00:22:24,550
Chinese that say the CFOs name in

527
00:22:24,550 --> 00:22:28,480
Chinese and I found this one tweet by

528
00:22:28,480 --> 00:22:32,500
the handle is a love gal main which

529
00:22:32,500 --> 00:22:35,200
actually I noticed today it has the the

530
00:22:35,200 --> 00:22:37,540
lady's name in it and it was tweeting it

531
00:22:37,540 --> 00:22:39,280
was subtweeting Justin Trudeau and I

532
00:22:39,280 --> 00:22:41,620
said in Chinese we want the immediate

533
00:22:41,620 --> 00:22:44,020
release of her and if you go this

534
00:22:44,020 --> 00:22:45,460
account is live as well you can look it

535
00:22:45,460 --> 00:22:46,510
up right now on your phone if you want

536
00:22:46,510 --> 00:22:48,250
it to if you go through its following a

537
00:22:48,250 --> 00:22:50,290
followers there's an entire network of

538
00:22:50,290 --> 00:22:53,920
bots that are also Pro Huawei talking

539
00:22:53,920 --> 00:22:57,670
about mangas and how so even though my

540
00:22:57,670 --> 00:23:00,430
dataset had one tweet because the tool

541
00:23:00,430 --> 00:23:02,560
allows me as an analyst to dive deeper

542
00:23:02,560 --> 00:23:04,510
into Twitter data I was able to use this

543
00:23:04,510 --> 00:23:06,850
look at more Chinese sweets that wasn't

544
00:23:06,850 --> 00:23:08,860
the focus of my research so I'm just

545
00:23:08,860 --> 00:23:10,540
gonna let you guys look into that if you

546
00:23:10,540 --> 00:23:12,580
choose to but I think it's very

547
00:23:12,580 --> 00:23:16,000
interesting that a Canada may be facing

548
00:23:16,000 --> 00:23:18,370
a you know influence operations at the

549
00:23:18,370 --> 00:23:20,560
very least when it comes to kwame there

550
00:23:20,560 --> 00:23:22,960
is a possibility it also happened during

551
00:23:22,960 --> 00:23:25,210
the federal election more research needs

552
00:23:25,210 --> 00:23:29,380
to be done to look at that so we're

553
00:23:29,380 --> 00:23:31,900
going to talk about attribution this is

554
00:23:31,900 --> 00:23:34,990
a very difficult problem there's a

555
00:23:34,990 --> 00:23:37,060
according to the Oxford report there's

556
00:23:37,060 --> 00:23:39,820
over 29 countries nation states that are

557
00:23:39,820 --> 00:23:41,470
active in doing influence operations on

558
00:23:41,470 --> 00:23:43,000
facebook twitter and other social media

559
00:23:43,000 --> 00:23:47,710
websites and that's only nation states

560
00:23:47,710 --> 00:23:49,390
there's also private companies that can

561
00:23:49,390 --> 00:23:51,730
do this work

562
00:23:51,730 --> 00:23:53,260
such a massive list that we don't know

563
00:23:53,260 --> 00:23:55,360
and without backend Twitter data on like

564
00:23:55,360 --> 00:23:57,340
login IP addresses well phone numbers

565
00:23:57,340 --> 00:23:59,410
were related to accounts when they were

566
00:23:59,410 --> 00:24:00,040
created

567
00:24:00,040 --> 00:24:03,520
we can't attribute this data I would

568
00:24:03,520 --> 00:24:05,050
love to work with Twitter and see if I

569
00:24:05,050 --> 00:24:07,420
can get that when we're talking about

570
00:24:07,420 --> 00:24:09,340
national security or threats is a

571
00:24:09,340 --> 00:24:12,120
combination of capability and intent

572
00:24:12,120 --> 00:24:14,020
those countries in the world I think

573
00:24:14,020 --> 00:24:16,090
have an intent to have a positive image

574
00:24:16,090 --> 00:24:18,400
about either the country or whatever

575
00:24:18,400 --> 00:24:20,470
political party is in control at that

576
00:24:20,470 --> 00:24:23,530
moment the capability might have been a

577
00:24:23,530 --> 00:24:26,140
little difficult in 2016 and we know the

578
00:24:26,140 --> 00:24:27,970
internet research agency worked on it

579
00:24:27,970 --> 00:24:29,500
but since then people have written so

580
00:24:29,500 --> 00:24:31,960
many papers on it there's so many bots

581
00:24:31,960 --> 00:24:33,550
there's so many marketing tools you can

582
00:24:33,550 --> 00:24:35,500
use to you know push a product or

583
00:24:35,500 --> 00:24:37,780
soundcloud music that uh the

584
00:24:37,780 --> 00:24:40,030
capabilities is is it's so easy that you

585
00:24:40,030 --> 00:24:41,260
can go and get up and probably find a

586
00:24:41,260 --> 00:24:42,640
bunch of tools that can help you with

587
00:24:42,640 --> 00:24:44,410
your work other people have written

588
00:24:44,410 --> 00:24:46,150
about how propaganda as a service is

589
00:24:46,150 --> 00:24:50,740
another another economy rising up in the

590
00:24:50,740 --> 00:24:53,380
dark web economy and cybercrime economy

591
00:24:53,380 --> 00:24:55,690
and that's also not the focus of my

592
00:24:55,690 --> 00:24:59,050
research but people nation states can

593
00:24:59,050 --> 00:25:00,460
have probable deniability if they

594
00:25:00,460 --> 00:25:01,960
launder their influence operations

595
00:25:01,960 --> 00:25:12,070
through private companies so Rene as a

596
00:25:12,070 --> 00:25:14,740
group at Stanford released a report that

597
00:25:14,740 --> 00:25:16,330
was published in The Washington Post and

598
00:25:16,330 --> 00:25:18,550
a white paper on how Russia was

599
00:25:18,550 --> 00:25:21,490
influencing this information in Africa

600
00:25:21,490 --> 00:25:23,650
and I had found a really interesting

601
00:25:23,650 --> 00:25:28,060
account when I was doing my research it

602
00:25:28,060 --> 00:25:31,360
was on the list of accounts that tweeted

603
00:25:31,360 --> 00:25:33,550
at Donald Trump a lot and it's called

604
00:25:33,550 --> 00:25:37,000
us-africa president it kind of

605
00:25:37,000 --> 00:25:38,620
masquerades as an official US government

606
00:25:38,620 --> 00:25:41,290
account it masquerades as like a State

607
00:25:41,290 --> 00:25:42,940
Department type account if you go

608
00:25:42,940 --> 00:25:44,890
through the timeline it retweets like US

609
00:25:44,890 --> 00:25:47,200
aid and other organizations is related

610
00:25:47,200 --> 00:25:49,060
to the United States and what the United

611
00:25:49,060 --> 00:25:52,330
States is around the world but the but

612
00:25:52,330 --> 00:25:55,840
the bio they have a a website that is

613
00:25:55,840 --> 00:25:57,700
not a US government website it's like a

614
00:25:57,700 --> 00:26:00,490
kind of like a WordPress website and it

615
00:26:00,490 --> 00:26:02,500
was marked as suspicious by Twitter when

616
00:26:02,500 --> 00:26:05,530
I was looking at it and

617
00:26:05,530 --> 00:26:07,360
I went down the time line it has about

618
00:26:07,360 --> 00:26:09,400
like six thousand tweets seven thousand

619
00:26:09,400 --> 00:26:12,250
tweets and and one weird retweet from

620
00:26:12,250 --> 00:26:13,900
this account was the Ministry of Foreign

621
00:26:13,900 --> 00:26:16,360
Affairs from Russia there's no business

622
00:26:16,360 --> 00:26:19,420
for a US government account to be

623
00:26:19,420 --> 00:26:23,140
retweeting mfa Russia so there is a

624
00:26:23,140 --> 00:26:25,390
possibility that Renee's research

625
00:26:25,390 --> 00:26:28,180
focused on Facebook data the Russians

626
00:26:28,180 --> 00:26:29,530
may have also been doing stuff on

627
00:26:29,530 --> 00:26:31,810
Twitter because that's used a lot in

628
00:26:31,810 --> 00:26:38,920
Africa so we have bad news when it comes

629
00:26:38,920 --> 00:26:41,400
to brexit Boris Johnson talked about how

630
00:26:41,400 --> 00:26:44,260
he well there's reports that he's

631
00:26:44,260 --> 00:26:48,340
holding back a report on election

632
00:26:48,340 --> 00:26:49,810
interference from the Russians and other

633
00:26:49,810 --> 00:26:53,710
foreign nations into brexit and he wants

634
00:26:53,710 --> 00:26:55,630
to hold it on hold it off until the

635
00:26:55,630 --> 00:26:58,600
election happens in the UK and I think

636
00:26:58,600 --> 00:27:00,610
that's a bad idea because uh we are not

637
00:27:00,610 --> 00:27:04,360
we don't know the impact that this may

638
00:27:04,360 --> 00:27:06,130
have in the US we had the the Senate

639
00:27:06,130 --> 00:27:08,440
report sending Tom's report on the IRA

640
00:27:08,440 --> 00:27:10,960
that opened the doors for researchers to

641
00:27:10,960 --> 00:27:13,090
dig through those handles dig through

642
00:27:13,090 --> 00:27:16,150
that data and dude the great analysis

643
00:27:16,150 --> 00:27:18,670
they did after the election Facebook is

644
00:27:18,670 --> 00:27:21,220
also not doing I don't in my personal

645
00:27:21,220 --> 00:27:22,150
opinion I don't think they're doing the

646
00:27:22,150 --> 00:27:24,760
best in combating this I love this

647
00:27:24,760 --> 00:27:28,360
picture of Mark Zuckerberg because

648
00:27:28,360 --> 00:27:31,540
pretty much he said when he in response

649
00:27:31,540 --> 00:27:34,660
to Elizabeth Warren's that politicians

650
00:27:34,660 --> 00:27:36,520
are allowed to post fake news on on

651
00:27:36,520 --> 00:27:39,760
Facebook and most people are like that's

652
00:27:39,760 --> 00:27:41,380
messed up like if something's not

653
00:27:41,380 --> 00:27:43,450
truthful you know you shouldn't be able

654
00:27:43,450 --> 00:27:45,520
to pay for it and amplify it and spread

655
00:27:45,520 --> 00:27:48,310
it among normal people on Facebook those

656
00:27:48,310 --> 00:27:50,890
in fact a person in a in a California

657
00:27:50,890 --> 00:27:54,460
who ran for a local election just so he

658
00:27:54,460 --> 00:27:56,710
can legally be considered a politician

659
00:27:56,710 --> 00:27:59,260
and he said his intent was to put fake

660
00:27:59,260 --> 00:28:01,000
news just to prove a point then Facebook

661
00:28:01,000 --> 00:28:03,180
said hey you can't do that because

662
00:28:03,180 --> 00:28:05,140
that's a violation of our Terms of

663
00:28:05,140 --> 00:28:09,190
Service so we see is kind of this is a

664
00:28:09,190 --> 00:28:11,920
bit of hypocrisy when it comes to

665
00:28:11,920 --> 00:28:15,730
Facebook dealing with misinformation on

666
00:28:15,730 --> 00:28:19,350
their website especially paid posts

667
00:28:22,230 --> 00:28:24,700
the good news is I think Twitter is

668
00:28:24,700 --> 00:28:26,350
being a lot more proactive about this

669
00:28:26,350 --> 00:28:28,269
problem because from Twitter's point of

670
00:28:28,269 --> 00:28:30,730
view they want the the quality of their

671
00:28:30,730 --> 00:28:32,289
product to be very very good among

672
00:28:32,289 --> 00:28:35,830
normal people so Jack said uh back in

673
00:28:35,830 --> 00:28:37,090
October he made this big announcement

674
00:28:37,090 --> 00:28:38,379
you can see a hundred thousand retweets

675
00:28:38,379 --> 00:28:40,600
that hey we're not gonna allow any

676
00:28:40,600 --> 00:28:43,389
political advertising globally that is a

677
00:28:43,389 --> 00:28:46,710
very big deal because there's so many

678
00:28:46,710 --> 00:28:49,960
campaigns and politicians and think

679
00:28:49,960 --> 00:28:52,179
tanks that push messages on Twitter and

680
00:28:52,179 --> 00:28:55,870
now he's saying like politicians should

681
00:28:55,870 --> 00:28:58,720
earn impact offline as opposed to just

682
00:28:58,720 --> 00:29:01,960
paying for that exposure on Twitter

683
00:29:01,960 --> 00:29:05,110
Twitter also did an amazing job when the

684
00:29:05,110 --> 00:29:07,870
rise of Isis happened in 2015 2014 2016

685
00:29:07,870 --> 00:29:11,049
on because universally people agreed

686
00:29:11,049 --> 00:29:12,580
that Isis should not have a platform to

687
00:29:12,580 --> 00:29:14,950
spread propaganda and media on their

688
00:29:14,950 --> 00:29:18,100
site so they did a lot of cleanup it's

689
00:29:18,100 --> 00:29:19,120
what are used to be that you can find

690
00:29:19,120 --> 00:29:20,500
Isis propaganda beheading videos

691
00:29:20,500 --> 00:29:23,919
everywhere and now it's did much more

692
00:29:23,919 --> 00:29:26,019
difficult to find that and they brought

693
00:29:26,019 --> 00:29:27,669
all sorts of algorithms and they had all

694
00:29:27,669 --> 00:29:29,710
sorts of teams focus on that we know

695
00:29:29,710 --> 00:29:32,139
that these companies have the capability

696
00:29:32,139 --> 00:29:35,559
to combat these issues if they choose to

697
00:29:35,559 --> 00:29:36,909
do so they have pressure from their

698
00:29:36,909 --> 00:29:44,500
users and/or governments some of the

699
00:29:44,500 --> 00:29:46,269
lessons learned from my personal project

700
00:29:46,269 --> 00:29:48,909
is since this was mainly like an open

701
00:29:48,909 --> 00:29:50,320
source intelligence and data science

702
00:29:50,320 --> 00:29:52,330
project when you're dealing with a lot

703
00:29:52,330 --> 00:29:55,299
of data and accounts your problems are

704
00:29:55,299 --> 00:29:58,809
hundreds of accounts per week and it's

705
00:29:58,809 --> 00:30:00,789
hard to backtrack and look at what you

706
00:30:00,789 --> 00:30:02,740
found like a week ago if you didn't take

707
00:30:02,740 --> 00:30:05,200
a screenshot there's a there's a program

708
00:30:05,200 --> 00:30:08,289
made by a Canadian Justin sites called

709
00:30:08,289 --> 00:30:10,480
hunch Lee which archives everything as

710
00:30:10,480 --> 00:30:12,700
you do your investigation and you

711
00:30:12,700 --> 00:30:13,690
couldn't make it to the conference this

712
00:30:13,690 --> 00:30:15,669
year but I would if I was to redo this

713
00:30:15,669 --> 00:30:17,259
work I would definitely use hunch Lee to

714
00:30:17,259 --> 00:30:20,110
record all my evidence and read better

715
00:30:20,110 --> 00:30:22,629
reports at the end of the day also when

716
00:30:22,629 --> 00:30:23,440
doing open source intelligence

717
00:30:23,440 --> 00:30:25,990
investigations you want to use a virtual

718
00:30:25,990 --> 00:30:28,360
machine dedicated for that specific

719
00:30:28,360 --> 00:30:30,009
project because you don't want whoever

720
00:30:30,009 --> 00:30:31,990
is if it's a nation state that doing

721
00:30:31,990 --> 00:30:33,670
that's doing this influencer operation

722
00:30:33,670 --> 00:30:35,260
you don't want them to know that hey

723
00:30:35,260 --> 00:30:37,510
like the Parliament building or like the

724
00:30:37,510 --> 00:30:39,190
intelligence community IP address is

725
00:30:39,190 --> 00:30:42,460
like going to my websites like that is a

726
00:30:42,460 --> 00:30:45,970
major obstacle ation using dedicated VMs

727
00:30:45,970 --> 00:30:48,790
would protect from that and you also

728
00:30:48,790 --> 00:30:49,930
want to build your own tools for

729
00:30:49,930 --> 00:30:51,430
automation so you're not doing a lot of

730
00:30:51,430 --> 00:30:53,650
manual analysis like Clemson did with

731
00:30:53,650 --> 00:30:56,020
the IRA research or first draft did or

732
00:30:56,020 --> 00:30:58,030
Marco and Jones did it's just more

733
00:30:58,030 --> 00:30:59,470
efficient you know we're smart people we

734
00:30:59,470 --> 00:31:04,620
can code to get better results

735
00:31:04,620 --> 00:31:06,730
additionally you want to use a clean

736
00:31:06,730 --> 00:31:09,070
Twitter accounts when you're doing this

737
00:31:09,070 --> 00:31:10,480
research Twitter has a way of

738
00:31:10,480 --> 00:31:12,430
recommending accounts similar what

739
00:31:12,430 --> 00:31:14,920
you're following so if I follow like one

740
00:31:14,920 --> 00:31:17,170
or two Chinese propaganda accounts that

741
00:31:17,170 --> 00:31:19,270
I suspect are like ran by the

742
00:31:19,270 --> 00:31:21,760
nation-state Twitter might recommend me

743
00:31:21,760 --> 00:31:23,500
like people that they're following or

744
00:31:23,500 --> 00:31:25,990
followers of them so it'll get a lot of

745
00:31:25,990 --> 00:31:27,820
work done for you but if you haven't

746
00:31:27,820 --> 00:31:29,710
your personal conjurer using or another

747
00:31:29,710 --> 00:31:30,940
account you're using to do this research

748
00:31:30,940 --> 00:31:33,670
is going to be dirty with all the noise

749
00:31:33,670 --> 00:31:35,290
of all the people you legitimately

750
00:31:35,290 --> 00:31:37,990
follow additionally I did see that some

751
00:31:37,990 --> 00:31:40,990
of the accounts I was following they had

752
00:31:40,990 --> 00:31:43,600
blocked me because they suspected that I

753
00:31:43,600 --> 00:31:45,490
was researching them which is not good

754
00:31:45,490 --> 00:31:48,340
for my OPSEC so you want to keep it

755
00:31:48,340 --> 00:31:51,970
clean and these actors are sophisticated

756
00:31:51,970 --> 00:31:53,470
you know they have a lot of money behind

757
00:31:53,470 --> 00:31:56,290
them don't expect your job to be done

758
00:31:56,290 --> 00:31:58,240
there's no one solution for taking care

759
00:31:58,240 --> 00:31:59,590
of misinformation it's a constantly

760
00:31:59,590 --> 00:32:01,720
evolving threat and I think like the

761
00:32:01,720 --> 00:32:03,210
country of Estonia is like really a

762
00:32:03,210 --> 00:32:04,930
forward facing when it comes to

763
00:32:04,930 --> 00:32:06,400
combating misinformation not only do

764
00:32:06,400 --> 00:32:09,100
they have a digital team that tracks

765
00:32:09,100 --> 00:32:11,110
misinformation they also educate their

766
00:32:11,110 --> 00:32:14,290
civil society as to you know don't

767
00:32:14,290 --> 00:32:15,940
believe exactly what you see online

768
00:32:15,940 --> 00:32:19,240
because where they are in geopolitically

769
00:32:19,240 --> 00:32:21,550
there's a big chance of what they're

770
00:32:21,550 --> 00:32:23,770
seeing is it's meant for them to see to

771
00:32:23,770 --> 00:32:25,780
change public perception specific

772
00:32:25,780 --> 00:32:32,020
sensitive issues so brain space is not

773
00:32:32,020 --> 00:32:34,720
only for for propaganda and bought

774
00:32:34,720 --> 00:32:36,550
detection there's a lot of other cool

775
00:32:36,550 --> 00:32:39,250
things you can use previously before I

776
00:32:39,250 --> 00:32:40,780
joined immunity

777
00:32:40,780 --> 00:32:44,290
we had revisited the internet research

778
00:32:44,290 --> 00:32:45,700
agency

779
00:32:45,700 --> 00:32:48,190
data set we looked at a Clemson's

780
00:32:48,190 --> 00:32:49,750
research and we were like what can we do

781
00:32:49,750 --> 00:32:52,139
that and what else can do so we have a

782
00:32:52,139 --> 00:32:54,610
look up this blog post and look at the

783
00:32:54,610 --> 00:32:57,940
video on Vimeo that is associated with

784
00:32:57,940 --> 00:33:00,250
it one thing we found with the internet

785
00:33:00,250 --> 00:33:02,470
research agency tweets was a there was a

786
00:33:02,470 --> 00:33:05,289
specific apostrophe that the a lot of

787
00:33:05,289 --> 00:33:06,940
the accounts were using to tweet and

788
00:33:06,940 --> 00:33:08,710
it's an apostrophe that's unique to

789
00:33:08,710 --> 00:33:11,169
Russian language keyboards so even

790
00:33:11,169 --> 00:33:13,269
though like you're the tweet may say

791
00:33:13,269 --> 00:33:18,460
like don't vote for Hillary that

792
00:33:18,460 --> 00:33:20,980
apostrophe looks normal to like a person

793
00:33:20,980 --> 00:33:23,080
reading it but when when a computer is

794
00:33:23,080 --> 00:33:25,960
parsing that those characters it knows

795
00:33:25,960 --> 00:33:28,120
that the ASCII code for that character

796
00:33:28,120 --> 00:33:29,649
is different than the ASCII code on an

797
00:33:29,649 --> 00:33:32,049
English language keyboard so with that

798
00:33:32,049 --> 00:33:33,940
small nugget you can filter through

799
00:33:33,940 --> 00:33:37,210
entire data set and find accounts

800
00:33:37,210 --> 00:33:38,950
tweeting with characters that may be

801
00:33:38,950 --> 00:33:42,210
found only on Russian keyboards the

802
00:33:42,210 --> 00:33:44,880
other work I did at immunity was a

803
00:33:44,880 --> 00:33:47,740
computational counterterrorism stuff

804
00:33:47,740 --> 00:33:50,500
finding Harris and extremists using a

805
00:33:50,500 --> 00:33:51,909
brain space and big data and machine

806
00:33:51,909 --> 00:33:53,080
learning

807
00:33:53,080 --> 00:33:55,570
Dave 8'o our CEO gave a really good talk

808
00:33:55,570 --> 00:33:57,880
at the International counterterrorism

809
00:33:57,880 --> 00:33:59,590
conference in Israel I think about a

810
00:33:59,590 --> 00:34:02,769
month two months ago and he went through

811
00:34:02,769 --> 00:34:04,840
using a lot of those features that we

812
00:34:04,840 --> 00:34:08,440
didn't use for our project specifically

813
00:34:08,440 --> 00:34:11,469
but can be used for other projects and

814
00:34:11,469 --> 00:34:13,449
if you're interested in this deafening

815
00:34:13,449 --> 00:34:14,949
code you to look that up for that

816
00:34:14,949 --> 00:34:17,500
project we used Google as a vision API

817
00:34:17,500 --> 00:34:19,349
which can automatically translate

818
00:34:19,349 --> 00:34:24,730
reverse image search do image labeling

819
00:34:24,730 --> 00:34:26,550
and it can do optical character

820
00:34:26,550 --> 00:34:31,179
recognition on images on the fly so like

821
00:34:31,179 --> 00:34:33,069
for example this picture it's very hard

822
00:34:33,069 --> 00:34:35,649
to see but it's a eulogy through to

823
00:34:35,649 --> 00:34:37,960
Osama bin Laden and the tweet doesn't

824
00:34:37,960 --> 00:34:39,219
have any text it just has that picture

825
00:34:39,219 --> 00:34:43,389
but in the India in that image it says

826
00:34:43,389 --> 00:34:46,690
his name in Turkish it doesn't just say

827
00:34:46,690 --> 00:34:48,760
Osama bin Laden it says Sheikh Osama bin

828
00:34:48,760 --> 00:34:50,980
Laden and you know that uh when people

829
00:34:50,980 --> 00:34:53,829
tweet these are these words like shake

830
00:34:53,829 --> 00:34:57,069
or like the great it implies a sort of

831
00:34:57,069 --> 00:34:58,480
reverence towards these characters and

832
00:34:58,480 --> 00:34:59,500
using the

833
00:34:59,500 --> 00:35:01,780
that kind of sentiment analysis you can

834
00:35:01,780 --> 00:35:04,420
uh you can filter to just like

835
00:35:04,420 --> 00:35:06,070
researchers talking about bin Laden that

836
00:35:06,070 --> 00:35:08,650
are legitimately doing that just for for

837
00:35:08,650 --> 00:35:09,670
research on Twitter and talking to

838
00:35:09,670 --> 00:35:12,520
people to people that are potentially

839
00:35:12,520 --> 00:35:14,620
extremists or extremist sympathizers

840
00:35:14,620 --> 00:35:17,860
there on the platform this is not an

841
00:35:17,860 --> 00:35:20,220
exhaustive list if I want to make a

842
00:35:20,220 --> 00:35:22,780
document of all the people doing

843
00:35:22,780 --> 00:35:24,850
disinformation research it would be

844
00:35:24,850 --> 00:35:26,770
massive and it would be like a 30 page

845
00:35:26,770 --> 00:35:29,770
Google Doc but before before this

846
00:35:29,770 --> 00:35:31,480
conference I'm like hey what are some of

847
00:35:31,480 --> 00:35:33,820
the coolest research I saw that isn't

848
00:35:33,820 --> 00:35:34,960
going to take you too long to read

849
00:35:34,960 --> 00:35:36,850
that's going to get you up to space on

850
00:35:36,850 --> 00:35:40,050
up to speed on misinformation happening

851
00:35:40,050 --> 00:35:42,970
and how do you find it Belem cat this is

852
00:35:42,970 --> 00:35:45,250
did this really good research on pro

853
00:35:45,250 --> 00:35:47,740
Indonesian propaganda bots and that's

854
00:35:47,740 --> 00:35:50,110
the URL for it first draft even though I

855
00:35:50,110 --> 00:35:51,370
disagree with the way they do their

856
00:35:51,370 --> 00:35:53,620
analysis they have a lot of projects and

857
00:35:53,620 --> 00:35:54,970
reading through it you can get some

858
00:35:54,970 --> 00:35:57,510
really great ideas on how to how to

859
00:35:57,510 --> 00:36:01,710
model your own research in a good way

860
00:36:02,940 --> 00:36:07,810
this is a the Stanford center that deals

861
00:36:07,810 --> 00:36:10,720
with digital issues that's the one that

862
00:36:10,720 --> 00:36:12,340
Renee works at they also have a lot of

863
00:36:12,340 --> 00:36:14,500
white papers on predominately Facebook

864
00:36:14,500 --> 00:36:16,570
misinformation disinformation campaigns

865
00:36:16,570 --> 00:36:20,800
and a trend micro had a really good blog

866
00:36:20,800 --> 00:36:22,780
post it's a massive blog post on how

867
00:36:22,780 --> 00:36:24,280
they used twins

868
00:36:24,280 --> 00:36:26,920
which is a Twitter data scraper to -

869
00:36:26,920 --> 00:36:29,290
similar to what we did scrape a large

870
00:36:29,290 --> 00:36:32,860
amount of tweets and filter through for

871
00:36:32,860 --> 00:36:35,680
looking for hackers looking for CVEs and

872
00:36:35,680 --> 00:36:38,770
looking for discourse on those topics if

873
00:36:38,770 --> 00:36:40,330
you want to replicate this research

874
00:36:40,330 --> 00:36:42,640
using free tools I would definitely say

875
00:36:42,640 --> 00:36:51,310
check out that blog post the the last

876
00:36:51,310 --> 00:36:52,720
thing I want to talk about since most of

877
00:36:52,720 --> 00:36:56,590
you were in the in the keynote by Renee

878
00:36:56,590 --> 00:36:59,050
is a Renee brought up some stuff that I

879
00:36:59,050 --> 00:37:01,120
don't necessarily disagree with but I

880
00:37:01,120 --> 00:37:03,010
think I could expand on I think it's

881
00:37:03,010 --> 00:37:04,480
great that we both refer to the same

882
00:37:04,480 --> 00:37:06,850
paper it's a great paper by Oxford so if

883
00:37:06,850 --> 00:37:08,770
in you guys want it please contact me

884
00:37:08,770 --> 00:37:11,380
and I'll email you a copy but there was

885
00:37:11,380 --> 00:37:13,420
a gentleman in a blue striped shirt

886
00:37:13,420 --> 00:37:16,530
asked can you use sentiment analysis to

887
00:37:16,530 --> 00:37:19,869
uncover a disinformation right there my

888
00:37:19,869 --> 00:37:22,900
man and she was like we're not there yet

889
00:37:22,900 --> 00:37:26,079
with brain space we are that's the crux

890
00:37:26,079 --> 00:37:27,400
of what I did we we used natural

891
00:37:27,400 --> 00:37:29,710
language processing sentiment analysis

892
00:37:29,710 --> 00:37:32,680
to filter through what we had and find

893
00:37:32,680 --> 00:37:36,549
accounts that were similar to it and the

894
00:37:36,549 --> 00:37:39,099
workload the FTEs you take is a lot less

895
00:37:39,099 --> 00:37:41,440
because your training it on very clean

896
00:37:41,440 --> 00:37:43,599
data well you want to Train it on as

897
00:37:43,599 --> 00:37:45,849
clean as you can get data and it'll do

898
00:37:45,849 --> 00:37:48,160
the work for you

899
00:37:48,160 --> 00:37:51,130
the other way that we used sentiment

900
00:37:51,130 --> 00:37:52,990
analysis is one of the pet projects we

901
00:37:52,990 --> 00:37:55,210
had before I got here at immunity

902
00:37:55,210 --> 00:37:58,750
was a we looked at Ted Cruz's Twitter

903
00:37:58,750 --> 00:38:01,210
account and what kind of people were

904
00:38:01,210 --> 00:38:03,549
very Pro Second Amendment an anti Second

905
00:38:03,549 --> 00:38:06,250
Amendment and if the pro or anti groups

906
00:38:06,250 --> 00:38:08,650
had BOTS among them and I think we have

907
00:38:08,650 --> 00:38:11,500
a Vimeo video on that if I find it I'll

908
00:38:11,500 --> 00:38:13,599
tweet it but that was another

909
00:38:13,599 --> 00:38:17,410
application of of this research that we

910
00:38:17,410 --> 00:38:19,329
had done before and there were a lot of

911
00:38:19,329 --> 00:38:21,940
BOTS found in that data set if you guys

912
00:38:21,940 --> 00:38:24,040
use Twitter and you're interested do

913
00:38:24,040 --> 00:38:26,920
follow the the Grug he is one of the

914
00:38:26,920 --> 00:38:28,780
most awesome generalist when it comes to

915
00:38:28,780 --> 00:38:29,740
the field of propaganda and

916
00:38:29,740 --> 00:38:31,930
disinformation and influencer operations

917
00:38:31,930 --> 00:38:34,329
I learned so much every week just by

918
00:38:34,329 --> 00:38:38,319
going down his feed I think you guys

919
00:38:38,319 --> 00:38:39,549
should follow I mean he kind of

920
00:38:39,549 --> 00:38:41,079
aggregates a lot of this data on your

921
00:38:41,079 --> 00:38:44,290
rights blog post on it if you guys want

922
00:38:44,290 --> 00:38:46,030
to get the slides so I'm gonna put them

923
00:38:46,030 --> 00:38:48,549
up on my website in a few days just

924
00:38:48,549 --> 00:38:49,990
follow me on Twitter and I'll tweet it

925
00:38:49,990 --> 00:38:53,500
out or when I get back to Miami if you

926
00:38:53,500 --> 00:38:54,880
want to contact me directly you can

927
00:38:54,880 --> 00:38:57,309
email me at me at Zeeshan disease calm

928
00:38:57,309 --> 00:38:58,720
or you can connect with me on LinkedIn

929
00:38:58,720 --> 00:39:01,210
or you can just pull me aside here if

930
00:39:01,210 --> 00:39:02,980
you want to talk more details or if you

931
00:39:02,980 --> 00:39:05,109
have specific questions but it's time

932
00:39:05,109 --> 00:39:06,320
for Q&A

933
00:39:06,320 --> 00:39:07,560
[Applause]

934
00:39:07,560 --> 00:39:21,578
[Music]

