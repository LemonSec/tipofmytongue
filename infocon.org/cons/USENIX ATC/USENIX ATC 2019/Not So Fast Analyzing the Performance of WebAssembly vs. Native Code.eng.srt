1
00:00:10,600 --> 00:00:15,549
hello everyone thank you for the

2
00:00:12,010 --> 00:00:17,290
introduction so replication these days

3
00:00:15,549 --> 00:00:18,599
are ubiquitous and one of the reasons

4
00:00:17,290 --> 00:00:21,009
there are a big uterus is because

5
00:00:18,599 --> 00:00:23,099
javascript is supported by all major

6
00:00:21,009 --> 00:00:25,390
browsers all major platforms

7
00:00:23,099 --> 00:00:27,970
unfortunately there is an issue with

8
00:00:25,390 --> 00:00:29,590
JavaScript and that is it is slow for

9
00:00:27,970 --> 00:00:31,810
example this graph here shows that

10
00:00:29,590 --> 00:00:33,940
inference times of a noodle network in

11
00:00:31,810 --> 00:00:36,399
tensorflow jeaious is actually 2x slower

12
00:00:33,940 --> 00:00:39,699
as compared to influence times in 10

13
00:00:36,399 --> 00:00:41,260
surfer native so what's the solution one

14
00:00:39,700 --> 00:00:43,180
solution that has been explored in past

15
00:00:41,260 --> 00:00:44,769
is to actually execute the native code

16
00:00:43,180 --> 00:00:46,870
directly inside the browser instead

17
00:00:44,770 --> 00:00:48,310
instead of JavaScript and one of the

18
00:00:46,870 --> 00:00:51,669
earliest technologies to do that was

19
00:00:48,310 --> 00:00:53,770
ActiveX it would take a C++ code compile

20
00:00:51,670 --> 00:00:56,560
it down to a code send binary which can

21
00:00:53,770 --> 00:00:59,560
be executed in Internet Explorer unfor

22
00:00:56,560 --> 00:01:03,190
so it was fast but it was not secure and

23
00:00:59,560 --> 00:01:04,659
not portable then Google also tried to

24
00:01:03,190 --> 00:01:06,329
solve this problem with its Native

25
00:01:04,659 --> 00:01:09,610
Client and portability blind

26
00:01:06,329 --> 00:01:13,270
these are sandbox environment over LLVM

27
00:01:09,610 --> 00:01:14,620
AR and x86 code and these are fast safe

28
00:01:13,270 --> 00:01:18,190
but they were not portable to other

29
00:01:14,620 --> 00:01:20,710
browsers in 2011 another technology came

30
00:01:18,190 --> 00:01:22,780
out known as Emscripten which would take

31
00:01:20,710 --> 00:01:24,970
these native languages and compile it

32
00:01:22,780 --> 00:01:28,690
down to a subset of JavaScript known as

33
00:01:24,970 --> 00:01:30,400
SMGs that SMGs is faster than JavaScript

34
00:01:28,690 --> 00:01:33,100
because it uses type coercion to get

35
00:01:30,400 --> 00:01:35,440
away with dynamic text of JavaScript it

36
00:01:33,100 --> 00:01:36,880
is safe and portable unfortunately it

37
00:01:35,440 --> 00:01:39,220
was slower than native and since

38
00:01:36,880 --> 00:01:43,839
JavaScript does not have 64-bit integers

39
00:01:39,220 --> 00:01:46,570
SMGs also does not support it in 2017

40
00:01:43,840 --> 00:01:49,510
webassembly rolled out webassembly is a

41
00:01:46,570 --> 00:01:51,460
new low-level language to which you can

42
00:01:49,510 --> 00:01:53,470
compile these native languages and

43
00:01:51,460 --> 00:01:55,080
execute it direct execute the

44
00:01:53,470 --> 00:01:58,030
application directly inside the browser

45
00:01:55,080 --> 00:02:01,179
so it is safe and portable but the

46
00:01:58,030 --> 00:02:03,610
question was if it is first to answer

47
00:02:01,180 --> 00:02:05,470
this question the paper that introduced

48
00:02:03,610 --> 00:02:07,900
webOS M they did some evaluation on poly

49
00:02:05,470 --> 00:02:10,119
Bansi benchmarks and they find that

50
00:02:07,900 --> 00:02:14,319
webassembly is only 26 percent slower

51
00:02:10,119 --> 00:02:16,360
than native not only that if we actually

52
00:02:14,319 --> 00:02:17,649
see the implementations of web assembly

53
00:02:16,360 --> 00:02:20,769
they have been continuously being

54
00:02:17,650 --> 00:02:23,200
improved over in on these benchmarks for

55
00:02:20,769 --> 00:02:24,370
example in 2017

56
00:02:23,200 --> 00:02:26,349
they were only

57
00:02:24,370 --> 00:02:30,450
seven benchmarks within 10% of native

58
00:02:26,349 --> 00:02:33,010
which increased to 15 benchmarks in 2019

59
00:02:30,450 --> 00:02:34,929
so one thing to note here is that

60
00:02:33,010 --> 00:02:36,549
webassembly is the future and one of the

61
00:02:34,930 --> 00:02:39,190
ways that webassembly can be used is

62
00:02:36,550 --> 00:02:41,260
with the with an application back-end

63
00:02:39,190 --> 00:02:43,390
which is fast written in web assembly

64
00:02:41,260 --> 00:02:45,489
and an application front-end which is

65
00:02:43,390 --> 00:02:48,010
written in JavaScript which is

66
00:02:45,489 --> 00:02:50,799
programmer friendly but the question is

67
00:02:48,010 --> 00:02:52,709
are those poly Bansi benchmarks really

68
00:02:50,799 --> 00:02:54,690
representative of FSM but for

69
00:02:52,709 --> 00:02:56,980
applications web assembly is being used

70
00:02:54,690 --> 00:02:59,560
we actually tried spec benchmarks and

71
00:02:56,980 --> 00:03:05,828
find that web assemblies instead of 26

72
00:02:59,560 --> 00:03:08,829
percent it's 55 percent slower so we

73
00:03:05,829 --> 00:03:10,900
also tried also analyze the performance

74
00:03:08,829 --> 00:03:12,790
counter data and find that webassembly

75
00:03:10,900 --> 00:03:14,290
slower because of several reasons and

76
00:03:12,790 --> 00:03:17,530
these reasons are some missing

77
00:03:14,290 --> 00:03:18,609
optimizations some of the design issues

78
00:03:17,530 --> 00:03:20,860
inherent webassembly

79
00:03:18,610 --> 00:03:22,269
and some of the restrictions that are

80
00:03:20,860 --> 00:03:25,000
applied by the browser browser

81
00:03:22,269 --> 00:03:26,440
environment due to which the these

82
00:03:25,000 --> 00:03:30,639
implementation cannot do good

83
00:03:26,440 --> 00:03:32,049
optimizations so let's look at a brief

84
00:03:30,639 --> 00:03:35,680
overview of web assembly before we get

85
00:03:32,049 --> 00:03:38,380
into the details so web assembly is code

86
00:03:35,680 --> 00:03:40,780
is a stack machine and the H web

87
00:03:38,380 --> 00:03:42,190
assembly module contains this code and a

88
00:03:40,780 --> 00:03:43,599
function table that function table

89
00:03:42,190 --> 00:03:45,639
represents what are the functions

90
00:03:43,599 --> 00:03:48,220
defined in that code webassembly can

91
00:03:45,639 --> 00:03:51,760
interoperate with JavaScript it is safe

92
00:03:48,220 --> 00:03:54,340
due to its type system and due to two

93
00:03:51,760 --> 00:03:56,679
explicit checks that it provides so

94
00:03:54,340 --> 00:03:58,150
first a stack overflow check at every

95
00:03:56,680 --> 00:04:00,220
function call it will check whether the

96
00:03:58,150 --> 00:04:02,799
function call stack that has been

97
00:04:00,220 --> 00:04:05,769
allocated goes beyond the brown grows

98
00:04:02,799 --> 00:04:08,680
beyond the boundary of maximum sex toys

99
00:04:05,769 --> 00:04:11,739
and if that happens then an exception is

100
00:04:08,680 --> 00:04:13,660
thrown the other one is indirect

101
00:04:11,739 --> 00:04:15,970
function call check so every indirect

102
00:04:13,660 --> 00:04:19,238
function instruction is represented by a

103
00:04:15,970 --> 00:04:21,010
function pointer which which has to be

104
00:04:19,238 --> 00:04:22,840
checked whether it is valid or not that

105
00:04:21,010 --> 00:04:25,450
is point to a valid function and the

106
00:04:22,840 --> 00:04:27,580
function it points to is actually is

107
00:04:25,450 --> 00:04:30,099
same as has the same signature as a

108
00:04:27,580 --> 00:04:32,979
function as a signature specified in an

109
00:04:30,099 --> 00:04:35,509
instruction so there are two checks for

110
00:04:32,979 --> 00:04:37,400
every indirect function call

111
00:04:35,509 --> 00:04:39,289
so let's look at but can be the good

112
00:04:37,400 --> 00:04:40,520
benchmarks webassembly and when there

113
00:04:39,289 --> 00:04:42,169
were similar designers designed

114
00:04:40,520 --> 00:04:44,089
webassembly they had some use cases in

115
00:04:42,169 --> 00:04:45,799
mind and these are the use cases

116
00:04:44,089 --> 00:04:46,610
scientific applications image media

117
00:04:45,800 --> 00:04:48,139
processing

118
00:04:46,610 --> 00:04:51,409
compilers debuggers and POSIX

119
00:04:48,139 --> 00:04:53,539
applications so question to ask is are

120
00:04:51,409 --> 00:04:55,219
the spawn even C benchmarks used are

121
00:04:53,539 --> 00:04:57,860
they good representative of these use

122
00:04:55,219 --> 00:04:59,419
cases so these are poly when C

123
00:04:57,860 --> 00:05:01,189
benchmarks these are 24 scientific

124
00:04:59,419 --> 00:05:05,240
kernels there are around hundred lines

125
00:05:01,189 --> 00:05:07,400
of code and the use the examples that

126
00:05:05,240 --> 00:05:08,689
shown a are doing some matrix

127
00:05:07,400 --> 00:05:12,469
multiplication on matrix vector

128
00:05:08,689 --> 00:05:13,819
multiplication so it's obvious that

129
00:05:12,469 --> 00:05:15,680
these are not representative because

130
00:05:13,819 --> 00:05:18,650
they are scientific kernels and can only

131
00:05:15,680 --> 00:05:22,909
represent a small set of scientific

132
00:05:18,650 --> 00:05:25,099
applications on the other hand the spec

133
00:05:22,909 --> 00:05:27,740
CPU benchmark suite is actually a better

134
00:05:25,099 --> 00:05:29,060
representative for example eight of

135
00:05:27,740 --> 00:05:29,749
these applications are scientific

136
00:05:29,060 --> 00:05:31,550
applications

137
00:05:29,749 --> 00:05:33,919
all of them are police applications and

138
00:05:31,550 --> 00:05:35,569
they are large in the sense that they

139
00:05:33,919 --> 00:05:39,498
are around one thousand to three hundred

140
00:05:35,569 --> 00:05:41,089
thousand lines of code but we just

141
00:05:39,499 --> 00:05:43,219
cannot compile spec benchmarks and

142
00:05:41,089 --> 00:05:46,249
execute them in a browser because these

143
00:05:43,219 --> 00:05:49,479
spec benchmarks require a system call

144
00:05:46,249 --> 00:05:52,879
interface which browsers does not have

145
00:05:49,479 --> 00:05:55,128
so we use bra six projects appeared in

146
00:05:52,879 --> 00:05:56,870
Esprit 2017 and it provides such an

147
00:05:55,129 --> 00:05:59,779
interface for JavaScript applications

148
00:05:56,870 --> 00:06:03,589
running in web browser it has a kernel

149
00:05:59,779 --> 00:06:05,810
running and in a process and each of the

150
00:06:03,589 --> 00:06:08,599
other browsers processes there are in a

151
00:06:05,810 --> 00:06:10,520
web worker and communicate with the

152
00:06:08,599 --> 00:06:14,479
kernel with a with the help of system

153
00:06:10,520 --> 00:06:16,219
calls and messages great but we cannot

154
00:06:14,479 --> 00:06:18,349
use browsers to execute their assembly

155
00:06:16,219 --> 00:06:21,289
benchmarks because it supports

156
00:06:18,349 --> 00:06:22,789
JavaScript and the way the communication

157
00:06:21,289 --> 00:06:25,659
between each process and the kernel

158
00:06:22,789 --> 00:06:27,620
happens is using shared array buffer

159
00:06:25,659 --> 00:06:30,259
unfortunately wherever assembly does not

160
00:06:27,620 --> 00:06:32,899
support the sheer data buffer so we

161
00:06:30,259 --> 00:06:34,729
develop projects versum which provides

162
00:06:32,899 --> 00:06:39,139
the same system call interface for web

163
00:06:34,729 --> 00:06:40,669
assembly programs so how the the to

164
00:06:39,139 --> 00:06:42,469
chain of bodies resume it will take a

165
00:06:40,669 --> 00:06:44,779
C++ file and compile it down to a

166
00:06:42,469 --> 00:06:47,149
JavaScript file that JavaScript file but

167
00:06:44,779 --> 00:06:48,919
contain the web assembly module of that

168
00:06:47,149 --> 00:06:50,569
C++ file and a runtime

169
00:06:48,919 --> 00:06:53,049
a certain time the Buddhist wisdom

170
00:06:50,569 --> 00:06:56,289
renton provides celebrity and

171
00:06:53,050 --> 00:06:59,300
communication with brother spasm conduct

172
00:06:56,289 --> 00:07:01,520
so now remember that that shared area

173
00:06:59,300 --> 00:07:03,229
buffer was being used by brawl 6 which

174
00:07:01,520 --> 00:07:06,740
unfortunately is not supported by their

175
00:07:03,229 --> 00:07:08,180
assembly so how can we how can we solve

176
00:07:06,740 --> 00:07:09,949
that problem and that is one way to

177
00:07:08,180 --> 00:07:12,499
solve this problem is to have a shadow

178
00:07:09,949 --> 00:07:14,300
copy of that shader of the assembly

179
00:07:12,499 --> 00:07:16,460
memory in the form of shaded area buffer

180
00:07:14,300 --> 00:07:18,620
whenever system what happens we are

181
00:07:16,460 --> 00:07:21,489
going to copy that memory from

182
00:07:18,620 --> 00:07:23,599
webassembly memory Shadow Copy

183
00:07:21,490 --> 00:07:26,990
unfortunately it has high copying

184
00:07:23,599 --> 00:07:30,169
overhead and to West memory usage so we

185
00:07:26,990 --> 00:07:32,539
instead have another approach in that we

186
00:07:30,169 --> 00:07:34,818
have only a small 64 MB of shared area

187
00:07:32,539 --> 00:07:37,279
buffer which is an auxilary buffer and

188
00:07:34,819 --> 00:07:40,250
whatever that system called references

189
00:07:37,279 --> 00:07:42,080
to way copy only that part and if that

190
00:07:40,250 --> 00:07:44,509
system called requires the size of more

191
00:07:42,080 --> 00:07:48,139
than 64 MB where to split that system

192
00:07:44,509 --> 00:07:50,479
call into several messages so this has

193
00:07:48,139 --> 00:07:54,259
minimal execution overhead and minimum

194
00:07:50,479 --> 00:07:55,909
memory requirements fine we developed

195
00:07:54,259 --> 00:07:59,300
bogus wisdom but unfortunately he will

196
00:07:55,909 --> 00:08:00,919
find we actually found some some of the

197
00:07:59,300 --> 00:08:03,199
performance issues for example the graph

198
00:08:00,919 --> 00:08:05,899
here shows that power a benchmark has

199
00:08:03,199 --> 00:08:08,899
around 10% of time of pabre benchmark is

200
00:08:05,899 --> 00:08:10,759
spent in BA this was a and we had this

201
00:08:08,899 --> 00:08:11,960
performance issues in file system system

202
00:08:10,759 --> 00:08:13,729
implementation and pipes

203
00:08:11,960 --> 00:08:15,770
I am going to talk about one of those

204
00:08:13,729 --> 00:08:17,779
issues so these three benchmarks were

205
00:08:15,770 --> 00:08:19,758
doing a lot of appends smaller pens and

206
00:08:17,779 --> 00:08:22,520
these smaller pens are in a file buffer

207
00:08:19,759 --> 00:08:25,099
so when you do an append to a file

208
00:08:22,520 --> 00:08:27,649
before it has to copy everything and

209
00:08:25,099 --> 00:08:30,560
relocate the memory and we solve this

210
00:08:27,649 --> 00:08:32,870
issue with the help by making sure that

211
00:08:30,560 --> 00:08:35,120
whenever an append happens we are going

212
00:08:32,870 --> 00:08:39,409
to grow the buffer by at least a page

213
00:08:35,120 --> 00:08:41,120
size many other performance issues were

214
00:08:39,409 --> 00:08:42,919
solved and if actually improved the

215
00:08:41,120 --> 00:08:46,790
performance of process was owned by 5x

216
00:08:42,919 --> 00:08:48,079
around five times the overhead of

217
00:08:46,790 --> 00:08:50,230
Baathist was and finally was brought

218
00:08:48,079 --> 00:08:53,209
down to around at maximum 1.1 percent

219
00:08:50,230 --> 00:08:55,459
and an average overhead was about 0.2

220
00:08:53,209 --> 00:08:57,890
percent over the spec benchmarks so in

221
00:08:55,459 --> 00:08:59,329
summary browses wasn't provide system

222
00:08:57,890 --> 00:09:02,420
call interface for webassembly

223
00:08:59,329 --> 00:09:05,339
applications with low overhead

224
00:09:02,420 --> 00:09:08,729
we also need a harness a benchmark

225
00:09:05,340 --> 00:09:10,350
harness to actually execute this spec

226
00:09:08,730 --> 00:09:13,650
benchmarks automatically and we

227
00:09:10,350 --> 00:09:16,320
developed a broad specialist the way it

228
00:09:13,650 --> 00:09:18,090
works is for for a given benchmark it

229
00:09:16,320 --> 00:09:21,690
will launch the browser and the kernel

230
00:09:18,090 --> 00:09:23,220
inside it and a harness or JS file that

231
00:09:21,690 --> 00:09:26,520
will launch the spec in work return it

232
00:09:23,220 --> 00:09:29,250
inspects benchmark suite which given a

233
00:09:26,520 --> 00:09:31,290
benchmark will load the correct web

234
00:09:29,250 --> 00:09:33,570
assembly module and inside the file

235
00:09:31,290 --> 00:09:37,800
system of the browser and when that

236
00:09:33,570 --> 00:09:39,570
happens we ask the browser spec to to

237
00:09:37,800 --> 00:09:43,050
launch the perf utility of Linux to get

238
00:09:39,570 --> 00:09:44,850
some performance counter data when the

239
00:09:43,050 --> 00:09:46,949
perf is attached the main thread is

240
00:09:44,850 --> 00:09:49,440
launched and when the benchmark X 8 will

241
00:09:46,950 --> 00:09:51,090
stop the puff and at the end we can

242
00:09:49,440 --> 00:09:52,680
download the benchmark results and the

243
00:09:51,090 --> 00:09:56,580
perf results and we also check the

244
00:09:52,680 --> 00:09:58,109
benchmark results for the correctness so

245
00:09:56,580 --> 00:10:00,990
finally we are able to execute web

246
00:09:58,110 --> 00:10:05,700
assembly in Google Chrome it is 55%

247
00:10:00,990 --> 00:10:09,510
slower now look at now let us look at

248
00:10:05,700 --> 00:10:11,430
why and before we look into why let's

249
00:10:09,510 --> 00:10:14,100
look at what other challenges for a JIT

250
00:10:11,430 --> 00:10:16,349
compiler so JIT compiler has to provide

251
00:10:14,100 --> 00:10:17,940
portability and to provide portability

252
00:10:16,350 --> 00:10:20,430
the note generates the code at runtime

253
00:10:17,940 --> 00:10:22,170
to generate the code at runtime it has

254
00:10:20,430 --> 00:10:23,849
to generate this code within some time

255
00:10:22,170 --> 00:10:26,490
constraints and while doing this it

256
00:10:23,850 --> 00:10:28,500
might be missing some optimizations so

257
00:10:26,490 --> 00:10:32,250
the question is if webassembly suffered

258
00:10:28,500 --> 00:10:34,020
from these time constraints also as we

259
00:10:32,250 --> 00:10:37,110
saw earlier webassembly provides

260
00:10:34,020 --> 00:10:38,400
explicit checks and the question is

261
00:10:37,110 --> 00:10:41,880
whether webassembly suffer from these

262
00:10:38,400 --> 00:10:43,680
checks or not to answer these questions

263
00:10:41,880 --> 00:10:46,770
let's look at a very small as a small

264
00:10:43,680 --> 00:10:48,479
benchmark of matrix multiplication and

265
00:10:46,770 --> 00:10:52,579
as you can see it always performs around

266
00:10:48,480 --> 00:10:56,190
2.5 x slower for different metric sizes

267
00:10:52,580 --> 00:10:58,590
on one hand on the on one hand we have

268
00:10:56,190 --> 00:11:00,930
Kleinjan hit code on the other hand we

269
00:10:58,590 --> 00:11:02,430
have chrome generated code and we can

270
00:11:00,930 --> 00:11:04,560
see that the chrome generate code is

271
00:11:02,430 --> 00:11:08,040
around two times more as compared to

272
00:11:04,560 --> 00:11:09,869
climb now let us look at one of the

273
00:11:08,040 --> 00:11:12,000
let's look at the reasons and one of the

274
00:11:09,870 --> 00:11:13,650
reasons is because the Clank generates

275
00:11:12,000 --> 00:11:15,900
this add instruction which is able to

276
00:11:13,650 --> 00:11:18,360
take x86 memory

277
00:11:15,900 --> 00:11:21,780
address as one of its operand on the

278
00:11:18,360 --> 00:11:25,620
other hand chrome takes chrome allocates

279
00:11:21,780 --> 00:11:27,630
an explicit register for it so this not

280
00:11:25,620 --> 00:11:33,720
only adds extra instructions this also

281
00:11:27,630 --> 00:11:35,970
adds extra register pressure chrome even

282
00:11:33,720 --> 00:11:37,740
though it takes three extra registers in

283
00:11:35,970 --> 00:11:40,860
plan it is still generating three

284
00:11:37,740 --> 00:11:43,920
register splits and this is because of

285
00:11:40,860 --> 00:11:45,420
its fast but unfortunately poor nearly a

286
00:11:43,920 --> 00:11:49,349
scale register allocator as compared to

287
00:11:45,420 --> 00:11:51,060
clanks in the ad register allocator now

288
00:11:49,350 --> 00:11:52,860
since its generating space and it also

289
00:11:51,060 --> 00:11:54,479
has an information that in the first

290
00:11:52,860 --> 00:11:56,760
iteration of the loop the data is

291
00:11:54,480 --> 00:11:58,260
already in the registers so I load it

292
00:11:56,760 --> 00:12:03,990
again it will also generate some extra

293
00:11:58,260 --> 00:12:05,670
loops so in summary we saw that matrix

294
00:12:03,990 --> 00:12:08,760
multiply slower because of several

295
00:12:05,670 --> 00:12:10,349
reasons but the question is if the spec

296
00:12:08,760 --> 00:12:12,480
benchmarks suffer from these slowdowns

297
00:12:10,350 --> 00:12:15,270
or not and we will answer this question

298
00:12:12,480 --> 00:12:20,220
using performance counter data generated

299
00:12:15,270 --> 00:12:21,510
using perfect ality so the first two

300
00:12:20,220 --> 00:12:24,660
data that we are looking at are loads

301
00:12:21,510 --> 00:12:27,630
and stores executed and for example in B

302
00:12:24,660 --> 00:12:29,520
zip to benchmark around three times more

303
00:12:27,630 --> 00:12:32,460
loads are executed in webassembly as

304
00:12:29,520 --> 00:12:34,199
compared to native and around 6x more

305
00:12:32,460 --> 00:12:36,660
stores are executed in webassembly as

306
00:12:34,200 --> 00:12:40,560
compared to native so why is that the

307
00:12:36,660 --> 00:12:43,589
reason the first thing is these JIT

308
00:12:40,560 --> 00:12:45,479
compilers has to know where does the DC

309
00:12:43,590 --> 00:12:47,100
roots point to so that they can start

310
00:12:45,480 --> 00:12:49,110
the developers collection and the only

311
00:12:47,100 --> 00:12:51,270
way that they can know is it is using by

312
00:12:49,110 --> 00:12:53,400
reserving at a specific register so they

313
00:12:51,270 --> 00:12:55,560
reserve the Arterton register and now

314
00:12:53,400 --> 00:12:57,030
one less register is available for the

315
00:12:55,560 --> 00:13:00,689
code generation for the code generator

316
00:12:57,030 --> 00:13:02,130
and as we have seen earlier it does it

317
00:13:00,690 --> 00:13:06,030
uses a linear scan register allocator

318
00:13:02,130 --> 00:13:08,340
which performs poorly and since it was

319
00:13:06,030 --> 00:13:10,140
not using oil x86 addressing modes it

320
00:13:08,340 --> 00:13:14,970
has to allocate it has to use another

321
00:13:10,140 --> 00:13:18,630
register to to in its instruction set in

322
00:13:14,970 --> 00:13:21,150
so all of this adds up increases the

323
00:13:18,630 --> 00:13:22,590
register pressure which actually

324
00:13:21,150 --> 00:13:24,990
increase the number of register spills

325
00:13:22,590 --> 00:13:27,530
and that could actually lead to more

326
00:13:24,990 --> 00:13:27,530
loads and stores

327
00:13:27,910 --> 00:13:32,270
the other counter there two counters

328
00:13:30,260 --> 00:13:33,830
that we are seeing a branch instruction

329
00:13:32,270 --> 00:13:35,140
and conditional branch instructions and

330
00:13:33,830 --> 00:13:37,880
we can see that

331
00:13:35,140 --> 00:13:42,110
webassembly executes indiamain it

332
00:13:37,880 --> 00:13:44,600
executes around 1.5 x around 1.75 X

333
00:13:42,110 --> 00:13:47,180
branch instructions and conditional

334
00:13:44,600 --> 00:13:49,160
branch instructions so remember there

335
00:13:47,180 --> 00:13:52,040
were two checks one was the one was to

336
00:13:49,160 --> 00:13:54,439
ensure that the number the stack over

337
00:13:52,040 --> 00:13:56,030
does not overflow and the other was to

338
00:13:54,440 --> 00:13:59,660
ensure that the indirect function calls

339
00:13:56,030 --> 00:14:01,730
are valid the other check that we have

340
00:13:59,660 --> 00:14:03,380
seen earlier is to is some extra jumps

341
00:14:01,730 --> 00:14:06,800
that are added to a word the register

342
00:14:03,380 --> 00:14:09,110
spilling and these these three reasons

343
00:14:06,800 --> 00:14:11,780
leads to a increased number of

344
00:14:09,110 --> 00:14:13,520
conditional branches and branches so

345
00:14:11,780 --> 00:14:15,050
combine all this with some porn

346
00:14:13,520 --> 00:14:18,020
instruction selection we get the effect

347
00:14:15,050 --> 00:14:20,449
of larger code size and hence more

348
00:14:18,020 --> 00:14:22,550
instructions are being executed but this

349
00:14:20,450 --> 00:14:23,750
has another effect this can actually

350
00:14:22,550 --> 00:14:26,329
lead to a larger instruction cache

351
00:14:23,750 --> 00:14:28,790
misses and with a large instruction

352
00:14:26,330 --> 00:14:31,310
cache misses the CPU cycles the CPU has

353
00:14:28,790 --> 00:14:35,060
to wait and spend some idle cycles while

354
00:14:31,310 --> 00:14:39,319
waiting for the instruction to occur so

355
00:14:35,060 --> 00:14:41,689
in somebody we had we developed both a

356
00:14:39,320 --> 00:14:43,580
spasm and all this spec which performed

357
00:14:41,690 --> 00:14:46,970
which enables execution of spec

358
00:14:43,580 --> 00:14:49,520
benchmarks in browsers and we performed

359
00:14:46,970 --> 00:14:51,590
the study on web assembly and find that

360
00:14:49,520 --> 00:14:53,660
web assembly is around 55 percent slower

361
00:14:51,590 --> 00:14:56,900
in Google Chrome 45 percent slower in

362
00:14:53,660 --> 00:14:59,630
Mozilla Firefox and the reasons are it

363
00:14:56,900 --> 00:15:02,590
has that these implementations does not

364
00:14:59,630 --> 00:15:06,860
do some optimizations they are missing

365
00:15:02,590 --> 00:15:09,140
it and the restrictions applied by the

366
00:15:06,860 --> 00:15:11,900
browser environment due to which there

367
00:15:09,140 --> 00:15:13,430
are some reserved registers and some of

368
00:15:11,900 --> 00:15:15,620
the design issues inherent to grab

369
00:15:13,430 --> 00:15:17,089
assembly which includes this stack

370
00:15:15,620 --> 00:15:20,620
overflow and indirect function call

371
00:15:17,090 --> 00:15:20,620
checks thank you

372
00:15:24,629 --> 00:15:37,529
Christian's not so fast

373
00:15:30,059 --> 00:15:40,629
okay a quick question about guess the

374
00:15:37,529 --> 00:15:42,309
point of using speck in this context is

375
00:15:40,629 --> 00:15:44,319
that you don't want to rewrite the

376
00:15:42,309 --> 00:15:46,230
benchmarks and so you want to enrich the

377
00:15:44,319 --> 00:15:48,099
system in order to run the benchmarks so

378
00:15:46,230 --> 00:15:51,639
I'm just thinking about the spec

379
00:15:48,100 --> 00:15:54,279
benchmarks and you know I feel like it

380
00:15:51,639 --> 00:15:57,550
might be the wrong benchmark for for

381
00:15:54,279 --> 00:15:58,869
webassembly like why do you want to use

382
00:15:57,550 --> 00:16:00,309
browse X in this context when

383
00:15:58,869 --> 00:16:02,769
webassembly was never designed to

384
00:16:00,309 --> 00:16:06,309
support a rich set of system calls is

385
00:16:02,769 --> 00:16:08,259
this really the right thing to do so the

386
00:16:06,309 --> 00:16:10,779
goal of assembly is to take a C++

387
00:16:08,259 --> 00:16:13,600
program compile it down so that it can

388
00:16:10,779 --> 00:16:15,610
be executed on on the interpreter right

389
00:16:13,600 --> 00:16:18,399
and the kind of applications at web

390
00:16:15,610 --> 00:16:19,749
assembly is being used for is these kind

391
00:16:18,399 --> 00:16:21,999
of applications like you can actually

392
00:16:19,749 --> 00:16:23,889
find some scientific simulations being

393
00:16:21,999 --> 00:16:25,629
written in for web assembly you can also

394
00:16:23,889 --> 00:16:28,420
find some compilers and debugger speed

395
00:16:25,629 --> 00:16:30,370
eater for web assembly so yeah so the

396
00:16:28,420 --> 00:16:32,050
spec benchmarks are actually a better

397
00:16:30,370 --> 00:16:34,209
alternative at least a better or 10 you

398
00:16:32,050 --> 00:16:35,949
to that poly Bansi benchmarks doesn't

399
00:16:34,209 --> 00:16:38,319
seem like webassembly natively supports

400
00:16:35,949 --> 00:16:40,029
back and you have to go like way out of

401
00:16:38,319 --> 00:16:43,540
your way to actually be able to run them

402
00:16:40,029 --> 00:16:45,490
so so doesn't seem out of balance web

403
00:16:43,540 --> 00:16:47,349
assim so when you combine these spec

404
00:16:45,490 --> 00:16:49,120
benchmarks we do not have to add need to

405
00:16:47,350 --> 00:16:50,410
add any extra instructions we need to

406
00:16:49,120 --> 00:16:52,089
provide an interface over the web

407
00:16:50,410 --> 00:16:55,110
assemblies so that it will be able to

408
00:16:52,089 --> 00:16:57,939
execute it so yeah so web assembly

409
00:16:55,110 --> 00:17:01,240
instruction set does does support it but

410
00:16:57,939 --> 00:17:03,279
it needs it needs a little bit of an

411
00:17:01,240 --> 00:17:05,230
interface around it - so - so that we

412
00:17:03,279 --> 00:17:06,909
will able to benchmark them so we really

413
00:17:05,230 --> 00:17:09,209
wanted to use as benchmark suite which

414
00:17:06,909 --> 00:17:12,069
has been tested and used for the last

415
00:17:09,209 --> 00:17:16,569
decades or so instead of developing a

416
00:17:12,069 --> 00:17:18,369
new benchmark suite - quick question

417
00:17:16,569 --> 00:17:20,799
someone is did you try any other

418
00:17:18,369 --> 00:17:24,938
architecture with a less erasto nature

419
00:17:20,799 --> 00:17:26,319
register pressure problem like power did

420
00:17:24,939 --> 00:17:27,939
you try any other instructions that

421
00:17:26,319 --> 00:17:29,980
other than Intel where the register

422
00:17:27,939 --> 00:17:33,760
pressure was not such a big issue

423
00:17:29,980 --> 00:17:35,840
you mean 64 bit arm for example did you

424
00:17:33,760 --> 00:17:37,759
try any other instruction set for your

425
00:17:35,840 --> 00:17:40,249
test bed instead of in okay yeah it's

426
00:17:37,759 --> 00:17:42,440
x86 there's there's what we tried it I

427
00:17:40,249 --> 00:17:45,740
suggest tried on something else another

428
00:17:42,440 --> 00:17:47,870
curiosity would be if you were to give

429
00:17:45,740 --> 00:17:52,399
more time to the optimizer yeah then

430
00:17:47,870 --> 00:17:53,899
then how what the numbers would be the

431
00:17:52,399 --> 00:17:56,029
users that can tolerate the longer

432
00:17:53,899 --> 00:17:59,748
compile time yeah maybe the equivalent

433
00:17:56,029 --> 00:18:01,370
of a - oh fast yeah definitely see these

434
00:17:59,749 --> 00:18:03,139
are as I said these are some missing

435
00:18:01,370 --> 00:18:05,059
optimizations that that can be added

436
00:18:03,139 --> 00:18:08,119
with better engineering effort so this

437
00:18:05,059 --> 00:18:09,740
was one of one of the things other three

438
00:18:08,119 --> 00:18:11,178
are like you cannot do anything about

439
00:18:09,740 --> 00:18:13,429
the browser restriction that'll be with

440
00:18:11,179 --> 00:18:15,259
you being applied to it if you have to a

441
00:18:13,429 --> 00:18:17,059
secure web assembly in a browser or the

442
00:18:15,259 --> 00:18:19,450
design issues that are inherent to web

443
00:18:17,059 --> 00:18:19,450
assembly

444
00:18:20,710 --> 00:18:24,740
hi John crucible University of Rochester

445
00:18:23,419 --> 00:18:27,470
nice work

446
00:18:24,740 --> 00:18:29,629
one question I have is that there's a

447
00:18:27,470 --> 00:18:31,669
tension between generating good code and

448
00:18:29,629 --> 00:18:33,350
jittering code quickly all right and so

449
00:18:31,669 --> 00:18:34,970
you've identified the problem that that

450
00:18:33,350 --> 00:18:37,610
you're generating code quickly but not

451
00:18:34,970 --> 00:18:39,860
high quality code have you thought about

452
00:18:37,610 --> 00:18:41,479
what sort of algorithms for instruction

453
00:18:39,860 --> 00:18:43,908
selection and register allocation so

454
00:18:41,480 --> 00:18:46,850
forth and so on might hit that sweet

455
00:18:43,909 --> 00:18:48,529
spot between being fast enough for use

456
00:18:46,850 --> 00:18:50,509
in just-in-time compilation and yet

457
00:18:48,529 --> 00:18:53,869
still generate you know efficient

458
00:18:50,509 --> 00:18:57,230
efficient code yeah so we have not

459
00:18:53,869 --> 00:18:59,389
thought about that they're like the main

460
00:18:57,230 --> 00:19:01,639
purpose of this work was to you know to

461
00:18:59,389 --> 00:19:04,189
find what other issues are and we find

462
00:19:01,639 --> 00:19:08,209
these issues we have shared our results

463
00:19:04,190 --> 00:19:11,690
with like other the teams of Google v8

464
00:19:08,210 --> 00:19:14,179
and all and well if we actually think

465
00:19:11,690 --> 00:19:16,789
about it then we can have maybe use

466
00:19:14,179 --> 00:19:20,240
better parallelism to to decrease the

467
00:19:16,789 --> 00:19:24,080
amount of course that these these phases

468
00:19:20,240 --> 00:19:25,549
has like for example okay

469
00:19:24,080 --> 00:19:28,759
maybe we should head offline thank you

470
00:19:25,549 --> 00:19:31,820
thank you any other questions

471
00:19:28,759 --> 00:19:34,020
alright so that finishes the session and

472
00:19:31,820 --> 00:19:36,080
thanks the speaker again thank you

473
00:19:34,020 --> 00:19:36,080
you

