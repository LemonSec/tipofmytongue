1
00:00:10,730 --> 00:00:15,610
I'll talk about a patch demo a framework

2
00:00:13,099 --> 00:00:18,189
for building distributed therefore

3
00:00:15,610 --> 00:00:21,939
policies this is a joint work with

4
00:00:18,189 --> 00:00:26,169
cheongyang coal nutrient sauna tango 1

5
00:00:21,939 --> 00:00:28,029
okay my advisor Cheon Guang Shan so

6
00:00:26,169 --> 00:00:30,910
let's think about the execution of a

7
00:00:28,029 --> 00:00:33,190
distributed word count this application

8
00:00:30,910 --> 00:00:35,469
is expressed using a high-level

9
00:00:33,190 --> 00:00:37,510
programming model so here we map each

10
00:00:35,469 --> 00:00:40,000
word to a pair of word and a count of

11
00:00:37,510 --> 00:00:44,050
one and for each word we sum up the

12
00:00:40,000 --> 00:00:46,300
count and this application will be

13
00:00:44,050 --> 00:00:50,530
converted to a runtime directed acyclic

14
00:00:46,300 --> 00:00:52,300
graph or a dag by a compiler so the map

15
00:00:50,530 --> 00:00:54,550
function will be copied to the map

16
00:00:52,300 --> 00:00:56,650
vertices and the reduced function will

17
00:00:54,550 --> 00:00:58,510
be copied to the reduce vertices and the

18
00:00:56,650 --> 00:01:02,589
data dependencies will be specified by

19
00:00:58,510 --> 00:01:05,829
the edges then this dag will be executed

20
00:01:02,590 --> 00:01:08,470
by a distributed runtime with the master

21
00:01:05,829 --> 00:01:12,130
and executor processes so let's look at

22
00:01:08,470 --> 00:01:14,408
this runtime more closely and we see

23
00:01:12,130 --> 00:01:17,920
that master has a scheduler with the

24
00:01:14,409 --> 00:01:20,409
runtime director scheduled then it

25
00:01:17,920 --> 00:01:23,409
acquires the data center resources and

26
00:01:20,409 --> 00:01:25,799
then deploys executor processes and

27
00:01:23,409 --> 00:01:29,320
distributes the mapper receives first

28
00:01:25,799 --> 00:01:33,360
these memories will process their

29
00:01:29,320 --> 00:01:36,548
portions of data and output the data

30
00:01:33,360 --> 00:01:41,070
partitions to a data channel abstraction

31
00:01:36,549 --> 00:01:43,780
in this case disks and the reduce

32
00:01:41,070 --> 00:01:46,899
vertices will be scheduled next and they

33
00:01:43,780 --> 00:01:51,130
will fetch the partitions effectively

34
00:01:46,900 --> 00:01:54,240
shuffling the data so in this setup our

35
00:01:51,130 --> 00:01:56,920
observations are on resources and data

36
00:01:54,240 --> 00:01:58,798
so the current trend is that these

37
00:01:56,920 --> 00:02:01,060
resources and data are becoming

38
00:01:58,799 --> 00:02:03,330
diversified the examples are

39
00:02:01,060 --> 00:02:06,670
geographically distributed resources

40
00:02:03,330 --> 00:02:09,179
cheap transient resources and also the

41
00:02:06,670 --> 00:02:12,970
data are becoming large and skewed and

42
00:02:09,179 --> 00:02:16,799
in this talk I'll just talk about cheap

43
00:02:12,970 --> 00:02:21,220
transient resources and large-scale data

44
00:02:16,799 --> 00:02:23,800
so let's consider using cheap transient

45
00:02:21,220 --> 00:02:26,400
resources suppose one of the executors

46
00:02:23,800 --> 00:02:29,050
is running on transient resources and

47
00:02:26,400 --> 00:02:29,460
the problem with these resources is that

48
00:02:29,050 --> 00:02:31,710
they are

49
00:02:29,460 --> 00:02:35,430
cheap and also frequently evicted and

50
00:02:31,710 --> 00:02:38,070
this causes a lot of recomputation that

51
00:02:35,430 --> 00:02:40,110
degrade the performance and let's look

52
00:02:38,070 --> 00:02:42,290
at the second case of large scale data

53
00:02:40,110 --> 00:02:45,000
shuffle so with large input data

54
00:02:42,290 --> 00:02:47,640
naturally we have many map and reduce

55
00:02:45,000 --> 00:02:49,590
vertices and that naturally lead to many

56
00:02:47,640 --> 00:02:53,609
data partitions that need to be shuffled

57
00:02:49,590 --> 00:02:56,490
and you know shuffling a lot of these

58
00:02:53,610 --> 00:03:00,110
partitions cause a lot of many disk

59
00:02:56,490 --> 00:03:02,940
seats that degrade the performance so

60
00:03:00,110 --> 00:03:05,010
there are these various issues and the

61
00:03:02,940 --> 00:03:07,200
question we ask is how to optimize

62
00:03:05,010 --> 00:03:11,010
distributed execution for these

63
00:03:07,200 --> 00:03:13,589
different scenarios and the existing

64
00:03:11,010 --> 00:03:16,769
approach is mostly direct specialization

65
00:03:13,590 --> 00:03:19,920
of the runtime so mostly just write a

66
00:03:16,770 --> 00:03:22,680
specialized scheduler for this optimal

67
00:03:19,920 --> 00:03:24,480
scheduling or write implement

68
00:03:22,680 --> 00:03:27,980
specialized data channels for more

69
00:03:24,480 --> 00:03:30,989
optimal data communication and so on

70
00:03:27,980 --> 00:03:33,959
however this approach makes it hard to

71
00:03:30,990 --> 00:03:35,790
ensure these properties so first is

72
00:03:33,960 --> 00:03:37,740
correctin is how can we ensure that the

73
00:03:35,790 --> 00:03:40,500
optimized execution after the

74
00:03:37,740 --> 00:03:43,410
specialization produces the same result

75
00:03:40,500 --> 00:03:45,840
as the original execution second is

76
00:03:43,410 --> 00:03:47,850
reusability how can we ensure that the

77
00:03:45,840 --> 00:03:50,670
single specialization works across

78
00:03:47,850 --> 00:03:52,760
different applications and third is

79
00:03:50,670 --> 00:03:55,200
composability so we have these different

80
00:03:52,760 --> 00:03:59,730
specialized component how can we compose

81
00:03:55,200 --> 00:04:02,690
these to deal with cases with combined

82
00:03:59,730 --> 00:04:06,119
resource and data characteristics and

83
00:04:02,690 --> 00:04:08,850
our goal here is to make it easy to

84
00:04:06,120 --> 00:04:13,760
optimize distributed execution by

85
00:04:08,850 --> 00:04:16,769
providing such properties so our idea is

86
00:04:13,760 --> 00:04:20,219
an intermediate representation or our on

87
00:04:16,769 --> 00:04:21,659
IR so given these different applications

88
00:04:20,220 --> 00:04:25,110
written using different programming

89
00:04:21,660 --> 00:04:26,700
models we convert this up convert an

90
00:04:25,110 --> 00:04:29,300
application to an intermediate

91
00:04:26,700 --> 00:04:31,920
representation dag with the vertices

92
00:04:29,300 --> 00:04:33,780
representing logical operations and the

93
00:04:31,920 --> 00:04:36,120
edges representing communication

94
00:04:33,780 --> 00:04:40,380
patterns so here we have a shuffle

95
00:04:36,120 --> 00:04:43,150
dependency and then we introduce this

96
00:04:40,380 --> 00:04:45,820
abstraction called optimization path

97
00:04:43,150 --> 00:04:48,940
which is simply a function for me from

98
00:04:45,820 --> 00:04:51,190
an IR deck to a new IR deck and our

99
00:04:48,940 --> 00:04:53,170
claim is that writing these passes are

100
00:04:51,190 --> 00:04:55,120
much easier than the direct

101
00:04:53,170 --> 00:04:57,760
specialization because you just think in

102
00:04:55,120 --> 00:05:02,530
terms of how to transform this IR deck

103
00:04:57,760 --> 00:05:04,599
and then our system will reflect the

104
00:05:02,530 --> 00:05:09,250
optimizations in the distributed

105
00:05:04,600 --> 00:05:12,400
execution so a Putsch demo is our system

106
00:05:09,250 --> 00:05:16,420
and I'll first described the its overall

107
00:05:12,400 --> 00:05:19,539
workflow so name-o user job submission

108
00:05:16,420 --> 00:05:21,550
parameters are simple and easy you have

109
00:05:19,540 --> 00:05:24,100
this existing application for example a

110
00:05:21,550 --> 00:05:26,740
spark or beam application and then you

111
00:05:24,100 --> 00:05:28,930
additionally specify a list of compiled

112
00:05:26,740 --> 00:05:32,800
time passes here we have three passes

113
00:05:28,930 --> 00:05:35,350
and then a set of run time passes so

114
00:05:32,800 --> 00:05:37,900
here we just have one pass and one time

115
00:05:35,350 --> 00:05:40,810
passes are invoked during the execution

116
00:05:37,900 --> 00:05:44,560
of the IR deck so these are the

117
00:05:40,810 --> 00:05:46,630
parameters and the system first apply

118
00:05:44,560 --> 00:05:49,810
the compile time passes so the

119
00:05:46,630 --> 00:05:52,630
application first becomes the IR dag the

120
00:05:49,810 --> 00:05:55,030
initial IR deck and then we apply the

121
00:05:52,630 --> 00:05:57,430
passes in the list order so the c1 is

122
00:05:55,030 --> 00:06:01,960
applied and we check the correctness of

123
00:05:57,430 --> 00:06:04,030
the output IR deck and then c2 is

124
00:06:01,960 --> 00:06:07,450
applied and we check again correctness

125
00:06:04,030 --> 00:06:12,130
and we also check that c2 does not undo

126
00:06:07,450 --> 00:06:13,960
any of the optimizations that c1 did so

127
00:06:12,130 --> 00:06:18,450
we check for these conflicts between the

128
00:06:13,960 --> 00:06:22,630
passes and then we apply the next c3 and

129
00:06:18,450 --> 00:06:24,820
similarly with the checkers and if all

130
00:06:22,630 --> 00:06:27,520
checks pass then we are good to go and

131
00:06:24,820 --> 00:06:29,920
we convert this IR dragged into a

132
00:06:27,520 --> 00:06:32,500
runtime deck and the runtime will

133
00:06:29,920 --> 00:06:37,270
execute this while reflecting all the

134
00:06:32,500 --> 00:06:39,910
optimizations and then comes the run

135
00:06:37,270 --> 00:06:41,979
time passes so during job execution a

136
00:06:39,910 --> 00:06:44,260
Nemo message can be produced from the

137
00:06:41,980 --> 00:06:49,080
runtime and forward it to the compiler

138
00:06:44,260 --> 00:06:52,380
to invoke a corresponding runtime pass

139
00:06:49,080 --> 00:06:54,849
to further optimize the IR dag and

140
00:06:52,380 --> 00:06:56,560
because the IR dag and the runtime dag

141
00:06:54,850 --> 00:06:59,080
are decoupled we can

142
00:06:56,560 --> 00:07:02,440
lately update this new runtime tag to a

143
00:06:59,080 --> 00:07:07,359
to the existing runtime running runtime

144
00:07:02,440 --> 00:07:09,400
dag to ensure correctness so that was it

145
00:07:07,360 --> 00:07:11,710
for the overall workflow of Nemo and

146
00:07:09,400 --> 00:07:15,270
we'll talk a little bit more in detail

147
00:07:11,710 --> 00:07:18,520
some of the optimization past examples

148
00:07:15,270 --> 00:07:21,430
hey what a path does is typically it

149
00:07:18,520 --> 00:07:23,889
traverses the input IR deck and it

150
00:07:21,430 --> 00:07:28,060
inserts utility vertices and annotate

151
00:07:23,889 --> 00:07:31,389
execution properties so a utility vertex

152
00:07:28,060 --> 00:07:33,070
applies a specific function and an

153
00:07:31,389 --> 00:07:35,290
extraction property configures a

154
00:07:33,070 --> 00:07:39,969
specific scheduling or communication

155
00:07:35,290 --> 00:07:43,150
method we've implemented various passes

156
00:07:39,970 --> 00:07:44,979
for different deployment scenarios but

157
00:07:43,150 --> 00:07:46,570
in this talk I'll just talk about large

158
00:07:44,979 --> 00:07:48,520
shuffle paths and transient resource

159
00:07:46,570 --> 00:07:50,919
path since they are the ones that I've

160
00:07:48,520 --> 00:07:55,090
been talking about and both of these are

161
00:07:50,919 --> 00:07:57,880
compiled time passes so first pass is

162
00:07:55,090 --> 00:08:00,849
large of a pass our goal is to avoid on

163
00:07:57,880 --> 00:08:03,580
disk data shuffle so we aim to shuffle

164
00:08:00,850 --> 00:08:06,160
data in memory right shuffle data to

165
00:08:03,580 --> 00:08:09,780
disks and read from disk sequentially

166
00:08:06,160 --> 00:08:12,160
and a related worker is riffled and

167
00:08:09,780 --> 00:08:15,760
here's the algorithm for the past

168
00:08:12,160 --> 00:08:18,039
so for each shuffle edge II we insert a

169
00:08:15,760 --> 00:08:20,500
relay vertex which is a utility vertex

170
00:08:18,039 --> 00:08:23,860
so given this initial I our dag on the

171
00:08:20,500 --> 00:08:26,169
Left this pass produces the optimized IR

172
00:08:23,860 --> 00:08:28,539
deck with the relay vertex inserted and

173
00:08:26,169 --> 00:08:30,130
this relay vertex applies an identity

174
00:08:28,539 --> 00:08:34,838
function simply forwarding the data

175
00:08:30,130 --> 00:08:37,630
downstream and then we set we annotate

176
00:08:34,839 --> 00:08:41,110
three extreme properties on the incoming

177
00:08:37,630 --> 00:08:42,969
edge of relay so we annotate push which

178
00:08:41,110 --> 00:08:47,650
means that we execute em and relay

179
00:08:42,969 --> 00:08:49,720
concurrently and then we shuffle data in

180
00:08:47,650 --> 00:08:51,640
memory without persisting the data in

181
00:08:49,720 --> 00:08:55,570
memory so with a push based in-memory

182
00:08:51,640 --> 00:08:58,300
data shuffle with M and relay and then

183
00:08:55,570 --> 00:09:01,330
we annotate the outgoing edge of relay

184
00:08:58,300 --> 00:09:04,180
with this a line of code so we annotate

185
00:09:01,330 --> 00:09:07,330
pool which means that our execute after

186
00:09:04,180 --> 00:09:10,329
my relay finish and then we annotate

187
00:09:07,330 --> 00:09:12,879
disk so that our data handoff is

188
00:09:10,329 --> 00:09:14,979
done via disk and because this is a

189
00:09:12,879 --> 00:09:19,899
one-to-one dependency we do sequential

190
00:09:14,980 --> 00:09:23,559
disk reads okay so the pass produces

191
00:09:19,899 --> 00:09:25,149
this optimized IR dag and Mo compares

192
00:09:23,559 --> 00:09:27,579
the origin IR there with the optimized

193
00:09:25,149 --> 00:09:29,679
IR deck to check for correctness and by

194
00:09:27,579 --> 00:09:32,290
simply looking at this real utility

195
00:09:29,679 --> 00:09:34,059
vertices and the exigent properties demo

196
00:09:32,290 --> 00:09:36,368
is able to confirm that they are

197
00:09:34,059 --> 00:09:41,339
equivalent and thus this optimization is

198
00:09:36,369 --> 00:09:44,170
correct so hence the execution so we

199
00:09:41,339 --> 00:09:48,339
scheduled the relay and M map vertices

200
00:09:44,170 --> 00:09:51,998
concurrently with to honor the push data

201
00:09:48,339 --> 00:09:55,480
flow and then we do they do this in

202
00:09:51,999 --> 00:09:57,699
memory discard shuffle and then the the

203
00:09:55,480 --> 00:10:02,679
shuffle data from relay will be written

204
00:09:57,699 --> 00:10:05,139
to disks then the relay at no sorry the

205
00:10:02,679 --> 00:10:07,540
reduce vertices will be scheduled and

206
00:10:05,139 --> 00:10:10,209
they will fetch the data shuffle data

207
00:10:07,540 --> 00:10:13,959
sequentially so this reduces that this

208
00:10:10,209 --> 00:10:16,089
see overheads that we had with the large

209
00:10:13,959 --> 00:10:17,949
data shuffle the second pass is changing

210
00:10:16,089 --> 00:10:21,419
resource pass the goal is to minimize

211
00:10:17,949 --> 00:10:23,410
three computations so we aim to place

212
00:10:21,419 --> 00:10:26,319
computations on transient and reserve

213
00:10:23,410 --> 00:10:28,480
resources judiciously and we push data

214
00:10:26,319 --> 00:10:32,469
from transient to reserve so the related

215
00:10:28,480 --> 00:10:36,399
work is puddle and this is the algorithm

216
00:10:32,470 --> 00:10:38,589
so here we visit each vertex and if a

217
00:10:36,399 --> 00:10:41,410
vertex has an incoming edge there is a

218
00:10:38,589 --> 00:10:44,019
shuffle then it is costly to recompute

219
00:10:41,410 --> 00:10:46,059
so we place that on reserved resources

220
00:10:44,019 --> 00:10:49,509
and the others on transient resources so

221
00:10:46,059 --> 00:10:52,719
we have this placement with the end in

222
00:10:49,509 --> 00:10:56,799
the optimized IR deck and then we

223
00:10:52,720 --> 00:10:59,980
annotate a data flow push for the edges

224
00:10:56,799 --> 00:11:02,470
that are from transient to reserved so

225
00:10:59,980 --> 00:11:07,509
we have this additional annotation on

226
00:11:02,470 --> 00:11:09,910
the IR dag so again the past produces

227
00:11:07,509 --> 00:11:12,189
desired egg and again we demo can check

228
00:11:09,910 --> 00:11:17,009
for correctness and confirm that they

229
00:11:12,189 --> 00:11:18,789
are they produce equivalent output so

230
00:11:17,009 --> 00:11:22,419
it's good to go

231
00:11:18,789 --> 00:11:24,069
so we execute this new IR dag and we

232
00:11:22,419 --> 00:11:25,540
place the memories is this

233
00:11:24,070 --> 00:11:28,060
on trends and resources and reduce

234
00:11:25,540 --> 00:11:32,140
versus on reserve resources and they are

235
00:11:28,060 --> 00:11:34,449
executed concurrently and we have this

236
00:11:32,140 --> 00:11:39,760
interesting data shuffle going from

237
00:11:34,450 --> 00:11:41,230
transient to reserved resources and this

238
00:11:39,760 --> 00:11:43,090
you can see that with even with

239
00:11:41,230 --> 00:11:46,240
evictions this moves data out of

240
00:11:43,090 --> 00:11:48,610
returned resources quickly thus reducing

241
00:11:46,240 --> 00:11:51,790
the recomputation overhead with using

242
00:11:48,610 --> 00:11:53,800
trends and resources okay so we thought

243
00:11:51,790 --> 00:11:56,920
if two passes and they can be composed

244
00:11:53,800 --> 00:11:59,740
so given the single ayah deck we apply

245
00:11:56,920 --> 00:12:01,870
the large shuffle pass on top of that we

246
00:11:59,740 --> 00:12:04,870
can apply the transient resource path to

247
00:12:01,870 --> 00:12:08,710
get this nice ir that with the to

248
00:12:04,870 --> 00:12:12,780
optimizations combined and name-o checks

249
00:12:08,710 --> 00:12:15,370
that this ir deck is indeed correct and

250
00:12:12,780 --> 00:12:20,470
there was no conflict between the two

251
00:12:15,370 --> 00:12:23,860
passes okay I'll move on to the

252
00:12:20,470 --> 00:12:26,770
implementation and evaluation so

253
00:12:23,860 --> 00:12:29,080
approach demo is open source it has 32 K

254
00:12:26,770 --> 00:12:32,199
lines of Java code including its own

255
00:12:29,080 --> 00:12:34,120
runtime Nemo has good integration with

256
00:12:32,200 --> 00:12:36,220
other approach Big Data projects you can

257
00:12:34,120 --> 00:12:39,400
run your beam and spark applications on

258
00:12:36,220 --> 00:12:41,500
demo and demo itself runs on resource

259
00:12:39,400 --> 00:12:45,760
managers such as yarn and metals with

260
00:12:41,500 --> 00:12:47,500
the integration with a patch reef so

261
00:12:45,760 --> 00:12:50,410
we've evaluated various deployment

262
00:12:47,500 --> 00:12:52,210
scenarios and in this talk I'll just

263
00:12:50,410 --> 00:12:54,040
talk about large data shuffle trends and

264
00:12:52,210 --> 00:12:55,420
resources and large shuffle on trendy

265
00:12:54,040 --> 00:12:59,140
resources since they are the ones that

266
00:12:55,420 --> 00:13:01,390
I've been talking about and we've

267
00:12:59,140 --> 00:13:03,250
evaluated different systems here I'll

268
00:13:01,390 --> 00:13:06,430
just talk about sorry I'll just talk

269
00:13:03,250 --> 00:13:08,590
about Nemo and spark and paddle which is

270
00:13:06,430 --> 00:13:11,079
specialized for engine resources and

271
00:13:08,590 --> 00:13:15,010
spark is a state-of-the-art they are

272
00:13:11,080 --> 00:13:17,680
processing runtime okay so this is the

273
00:13:15,010 --> 00:13:20,800
result of large data shuffle so for this

274
00:13:17,680 --> 00:13:23,410
one we run a MapReduce on 20 easy two

275
00:13:20,800 --> 00:13:26,109
instances y-axis is a job completion

276
00:13:23,410 --> 00:13:28,300
time the lower is better x-axis is the

277
00:13:26,110 --> 00:13:31,870
input data size so as the input data

278
00:13:28,300 --> 00:13:33,189
size grows SPARC degrades or due to the

279
00:13:31,870 --> 00:13:36,160
disk seek overhead

280
00:13:33,190 --> 00:13:37,900
whereas Nemo outperformed spark with the

281
00:13:36,160 --> 00:13:42,430
large shuffle pass optimization

282
00:13:37,900 --> 00:13:45,040
we saw earlier this is the result of

283
00:13:42,430 --> 00:13:47,380
transient resources so here we run a

284
00:13:45,040 --> 00:13:49,920
machine learning algorithm on tenth

285
00:13:47,380 --> 00:13:53,110
engine plus two reserved resources

286
00:13:49,920 --> 00:13:56,229
y-axis is again job completion times the

287
00:13:53,110 --> 00:13:59,110
lower is better x-axis is eviction rate

288
00:13:56,230 --> 00:14:01,590
so as the eviction rate goes up SPARC

289
00:13:59,110 --> 00:14:05,110
suffers from the heavy recomputation of

290
00:14:01,590 --> 00:14:10,210
the evicted data whereas Nemo and paddle

291
00:14:05,110 --> 00:14:12,880
they handle the evictions gracefully and

292
00:14:10,210 --> 00:14:14,560
we observed that Nemo is actually on par

293
00:14:12,880 --> 00:14:17,320
with paddle which is specialized for

294
00:14:14,560 --> 00:14:19,209
Ranger resources and Nemo is optimized

295
00:14:17,320 --> 00:14:21,690
with the trending resource path that we

296
00:14:19,210 --> 00:14:21,690
saw earlier

297
00:14:21,750 --> 00:14:27,340
now this one is large shuffle on

298
00:14:24,430 --> 00:14:30,040
transient resources so we run a one

299
00:14:27,340 --> 00:14:31,890
terabyte MapReduce on ten transient and

300
00:14:30,040 --> 00:14:34,920
ten reserve resources

301
00:14:31,890 --> 00:14:38,830
y-axis is again job completion time

302
00:14:34,920 --> 00:14:41,410
x-axis now it's the path used on Nemo to

303
00:14:38,830 --> 00:14:43,990
run this workload and the default path

304
00:14:41,410 --> 00:14:46,270
works similar to how SPARC executed the

305
00:14:43,990 --> 00:14:48,520
job so without the transient resource

306
00:14:46,270 --> 00:14:51,760
pass default path and large of a path

307
00:14:48,520 --> 00:14:53,949
they both suffer from the recomputation

308
00:14:51,760 --> 00:14:56,110
x' whereas transient resource passed

309
00:14:53,950 --> 00:14:58,480
itself runs in total memory while

310
00:14:56,110 --> 00:15:02,260
pushing a lot of data to reserve

311
00:14:58,480 --> 00:15:04,660
resources whereas two passes combined we

312
00:15:02,260 --> 00:15:07,060
have what we are able to further improve

313
00:15:04,660 --> 00:15:10,390
performance over using just a single

314
00:15:07,060 --> 00:15:15,910
pass for handling this or combine the

315
00:15:10,390 --> 00:15:19,330
scenario okay so all this is a summary

316
00:15:15,910 --> 00:15:22,180
of a patch demo the problem we try to

317
00:15:19,330 --> 00:15:24,550
solve is we're trying to make it easy to

318
00:15:22,180 --> 00:15:27,670
optimize distributed data flows our

319
00:15:24,550 --> 00:15:29,589
solution is optimization passes that

320
00:15:27,670 --> 00:15:32,620
transform an intermediate representation

321
00:15:29,590 --> 00:15:34,990
deck the result shows that Nemo up

322
00:15:32,620 --> 00:15:36,790
performs a state-of-the-art Apache spark

323
00:15:34,990 --> 00:15:39,970
with clean and simple optimization

324
00:15:36,790 --> 00:15:42,400
passes and is on par with specialized

325
00:15:39,970 --> 00:15:45,460
runtimes and further improves

326
00:15:42,400 --> 00:15:46,840
performance for scenarios a with

327
00:15:45,460 --> 00:15:50,830
combined resources and data

328
00:15:46,840 --> 00:15:51,610
characteristics okay so I'd like to end

329
00:15:50,830 --> 00:15:54,220
the top by

330
00:15:51,610 --> 00:15:57,339
saying that we hope you find them more

331
00:15:54,220 --> 00:15:59,410
useful and we hope you use Nemo to build

332
00:15:57,339 --> 00:16:09,250
your own passes for your data flow

333
00:15:59,410 --> 00:16:12,149
research thank you very much thank you

334
00:16:09,250 --> 00:16:12,149
now we can take some questions

335
00:16:19,360 --> 00:16:24,189
well I have a question I mean I guess in

336
00:16:22,540 --> 00:16:26,469
the wild sort of what percentage of

337
00:16:24,189 --> 00:16:29,079
spark jobs do you think are amenable to

338
00:16:26,470 --> 00:16:32,470
this approach and if it's a lot you know

339
00:16:29,079 --> 00:16:34,420
should you just patch spark mm-hmm so I

340
00:16:32,470 --> 00:16:35,920
don't have the percentage number because

341
00:16:34,420 --> 00:16:40,179
I don't you know work for a company or

342
00:16:35,920 --> 00:16:43,868
anything but patching up spark is a

343
00:16:40,179 --> 00:16:45,639
possible approach but again to ensure

344
00:16:43,869 --> 00:16:46,749
those properties that I talked about the

345
00:16:45,639 --> 00:16:51,189
correctness reusability and

346
00:16:46,749 --> 00:16:53,259
composability I my feeling is that you

347
00:16:51,189 --> 00:16:55,059
need something like demo to make those

348
00:16:53,259 --> 00:16:57,459
work so you need some kind of a policy

349
00:16:55,059 --> 00:16:59,379
layer on top of spark even if you want

350
00:16:57,459 --> 00:17:06,638
to patch the spark to do that to just

351
00:16:59,379 --> 00:17:09,299
keep on using spark all right great any

352
00:17:06,638 --> 00:17:10,958
other questions

353
00:17:09,299 --> 00:17:12,270
all right well let's thank our speaker

354
00:17:10,959 --> 00:17:17,779
again

355
00:17:12,270 --> 00:17:17,779
[Applause]

