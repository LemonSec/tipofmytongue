1
00:00:10,670 --> 00:00:16,740
I'm chosen one from Tsinghua University

2
00:00:12,350 --> 00:00:18,900
and I'm happy to introduce you died

3
00:00:16,740 --> 00:00:21,750
culturing fast and a low interference

4
00:00:18,900 --> 00:00:23,729
data Korean very large story systems and

5
00:00:21,750 --> 00:00:26,579
if you see the collaboration work front

6
00:00:23,730 --> 00:00:31,259
my neighbor's mercy the Ohio State

7
00:00:26,579 --> 00:00:34,019
University and the Ali Baba when node

8
00:00:31,259 --> 00:00:36,720
fails repeat laboratory system we

9
00:00:34,019 --> 00:00:39,690
replicate lost trunks for other replicas

10
00:00:36,720 --> 00:00:41,820
to achieve to achieve this at a

11
00:00:39,690 --> 00:00:44,339
territory Persico should determine a

12
00:00:41,820 --> 00:00:47,100
transmission source a destination a

13
00:00:44,339 --> 00:00:51,780
bandwidth for each lost chunk we call

14
00:00:47,100 --> 00:00:53,820
that a Caritas gallery I do scheduling

15
00:00:51,780 --> 00:00:56,519
algorithm should achieve at least two

16
00:00:53,820 --> 00:00:58,800
girls first it should be able to

17
00:00:56,519 --> 00:01:01,010
generate high-quality recovery plan

18
00:00:58,800 --> 00:01:03,839
which allow the system to work very fast

19
00:01:01,010 --> 00:01:06,899
with small impact on the foreground

20
00:01:03,839 --> 00:01:09,030
traffic and a second the scheduling

21
00:01:06,899 --> 00:01:10,920
algorithm itself should be fast enough

22
00:01:09,030 --> 00:01:15,420
so that it does not become a bottleneck

23
00:01:10,920 --> 00:01:18,600
of the recovery to understand how well

24
00:01:15,420 --> 00:01:21,210
this thing protocols can achieve these

25
00:01:18,600 --> 00:01:23,759
two girls in a large system we analyzed

26
00:01:21,210 --> 00:01:26,210
the trace class from Ali class online

27
00:01:23,759 --> 00:01:30,090
and the line story system Pango Pango

28
00:01:26,210 --> 00:01:32,908
has a similar design as GFS and HDFS and

29
00:01:30,090 --> 00:01:36,180
so on and our observed system is

30
00:01:32,909 --> 00:01:40,680
deployed on a cluster about 3.5 thousand

31
00:01:36,180 --> 00:01:43,290
nodes we summarized our observations the

32
00:01:40,680 --> 00:01:46,079
first observation is a huge scale the

33
00:01:43,290 --> 00:01:49,770
cluster has about 3.5 thousand nodes and

34
00:01:46,079 --> 00:01:53,669
each no stores average about two hundred

35
00:01:49,770 --> 00:01:56,039
and fifteen thousand chunks this means

36
00:01:53,670 --> 00:01:59,509
scheduling is having terms of

37
00:01:56,039 --> 00:02:02,130
computation when node fails there are

38
00:01:59,509 --> 00:02:05,100
250,000 chunks of data need to be

39
00:02:02,130 --> 00:02:09,750
scheduled and each each chunk has about

40
00:02:05,100 --> 00:02:12,299
3,000 nodes as can't a destinations the

41
00:02:09,750 --> 00:02:14,760
second observations are the resources

42
00:02:12,299 --> 00:02:17,250
available for recovery are reached as a

43
00:02:14,760 --> 00:02:20,010
footprint only use only about half of

44
00:02:17,250 --> 00:02:24,420
the bandwidth if the recovery can use

45
00:02:20,010 --> 00:02:26,429
all idle bandwidth so ideal recovery

46
00:02:24,420 --> 00:02:30,720
some of the single news videos short

47
00:02:26,430 --> 00:02:33,690
average rate only 51 seconds and this is

48
00:02:30,720 --> 00:02:37,920
just that scheduler completed quickly so

49
00:02:33,690 --> 00:02:40,680
that now become the bottleneck the third

50
00:02:37,920 --> 00:02:43,290
observation is the imbalance on mutant

51
00:02:40,680 --> 00:02:46,130
on the one hand in the short tons of

52
00:02:43,290 --> 00:02:49,560
folk won the bandwidth utilization is

53
00:02:46,130 --> 00:02:52,920
distributed unevenly across note okay

54
00:02:49,560 --> 00:02:55,140
there are more than 90 cases where CoV

55
00:02:52,920 --> 00:02:58,320
of the folk one utilization is greater

56
00:02:55,140 --> 00:03:01,708
than the 40% indicating they have

57
00:02:58,320 --> 00:03:04,470
significant imbalance on the other hand

58
00:03:01,709 --> 00:03:07,830
replicas of zhongzong even know that I

59
00:03:04,470 --> 00:03:10,080
distributed unevenly across nodes so now

60
00:03:07,830 --> 00:03:14,360
they have a larger number of recovered

61
00:03:10,080 --> 00:03:16,800
available data chunks these two

62
00:03:14,360 --> 00:03:21,930
imbalance distribution pose a challenge

63
00:03:16,800 --> 00:03:24,660
to scheduling 44 the frequent traffic

64
00:03:21,930 --> 00:03:27,840
changes dramatically in some cases as of

65
00:03:24,660 --> 00:03:31,680
cases outside two red lines in below

66
00:03:27,840 --> 00:03:34,860
figure okay this requires a schedule to

67
00:03:31,680 --> 00:03:37,470
adjust scheduling plan quickly went

68
00:03:34,860 --> 00:03:43,920
observe 16 significant changes for

69
00:03:37,470 --> 00:03:46,320
ground traffic the above observations

70
00:03:43,920 --> 00:03:49,200
issues that scheduling algorithms need

71
00:03:46,320 --> 00:03:51,989
to compute a large and complex problems

72
00:03:49,200 --> 00:03:56,220
within second but none of existing

73
00:03:51,989 --> 00:03:58,500
approaches meet these girls simple

74
00:03:56,220 --> 00:04:00,750
algorithms like randomized the solutions

75
00:03:58,500 --> 00:04:03,680
finish scheduling quickly but generate

76
00:04:00,750 --> 00:04:07,290
low quality results and conversely

77
00:04:03,680 --> 00:04:09,420
complicated algorithms take long time to

78
00:04:07,290 --> 00:04:15,540
produce a high-quality route solution

79
00:04:09,420 --> 00:04:17,488
and we like to find an approach here to

80
00:04:15,540 --> 00:04:18,959
this end we design a fast and a low

81
00:04:17,488 --> 00:04:19,858
interference data recovery called

82
00:04:18,959 --> 00:04:22,530
quartile

83
00:04:19,858 --> 00:04:25,620
it's a name from a famous flag controls

84
00:04:22,530 --> 00:04:28,229
but in Chinese legend and we wish this

85
00:04:25,620 --> 00:04:31,830
protocol could also control the fog of

86
00:04:28,229 --> 00:04:35,310
recovery well Tyrel solve this problem

87
00:04:31,830 --> 00:04:37,370
but by designing completed algorithms

88
00:04:35,310 --> 00:04:39,740
with good scalability

89
00:04:37,370 --> 00:04:42,080
that uses a centralised scheduler which

90
00:04:39,740 --> 00:04:44,870
is schedule a task using a timeslot

91
00:04:42,080 --> 00:04:47,539
based protocol and we prefer the

92
00:04:44,870 --> 00:04:50,389
proposed four key techniques to achieve

93
00:04:47,540 --> 00:04:51,100
high speed and high quality you one time

94
00:04:50,389 --> 00:04:53,960
slot

95
00:04:51,100 --> 00:04:56,120
as mentioned before time is a time slot

96
00:04:53,960 --> 00:04:59,539
base protocol it advised the entire

97
00:04:56,120 --> 00:05:01,850
recovery times into slices a centralized

98
00:04:59,540 --> 00:05:03,830
scheduler class latest state of the

99
00:05:01,850 --> 00:05:06,410
cluster at the beginning of one time

100
00:05:03,830 --> 00:05:09,560
slot then schedule the tasks which I

101
00:05:06,410 --> 00:05:11,990
expected to complete in one time slot to

102
00:05:09,560 --> 00:05:14,620
fully utilize a bandwidth die overlaps

103
00:05:11,990 --> 00:05:18,169
and multiple time slots

104
00:05:14,620 --> 00:05:20,330
ok time swap a scheduling provide two

105
00:05:18,169 --> 00:05:22,820
benefits first time only need to

106
00:05:20,330 --> 00:05:24,740
schedule a subset of tasks in one time

107
00:05:22,820 --> 00:05:27,409
slot which reduces the computation

108
00:05:24,740 --> 00:05:29,539
overhead and a second where for one

109
00:05:27,410 --> 00:05:31,490
throw ground load changes dramatically

110
00:05:29,539 --> 00:05:36,440
that you can adjust as planning that

111
00:05:31,490 --> 00:05:39,500
time slot next we present the scheduling

112
00:05:36,440 --> 00:05:41,419
algorithms in one time slot because that

113
00:05:39,500 --> 00:05:43,460
the scheduling algorithms should

114
00:05:41,419 --> 00:05:46,729
determine a transmission source a

115
00:05:43,460 --> 00:05:49,489
destination and the bandwidth for each

116
00:05:46,729 --> 00:05:51,860
chunk each task to make these decisions

117
00:05:49,490 --> 00:05:54,580
and actually achieve high speed high

118
00:05:51,860 --> 00:05:57,680
quality scheduling tag propose full key

119
00:05:54,580 --> 00:06:02,389
techniques and let's look at them one by

120
00:05:57,680 --> 00:06:05,300
one now uses these first key techniques

121
00:06:02,389 --> 00:06:07,940
to selecting working nodes for each

122
00:06:05,300 --> 00:06:10,099
recovery task after some imaging

123
00:06:07,940 --> 00:06:12,940
experiment we decide to use a greedy

124
00:06:10,099 --> 00:06:16,940
like algorithm to choose working nodes

125
00:06:12,940 --> 00:06:19,969
that is for each task scheduler chooses

126
00:06:16,940 --> 00:06:23,240
a pair of salt and destined destination

127
00:06:19,970 --> 00:06:26,360
node with minimum expected completion

128
00:06:23,240 --> 00:06:30,789
time that is fun those were small ways

129
00:06:26,360 --> 00:06:30,789
to be devised the process

130
00:06:32,800 --> 00:06:40,160
moment okay when selecting a data source

131
00:06:37,190 --> 00:06:42,380
the triple replica Chang's usually have

132
00:06:40,160 --> 00:06:45,440
two replicas surviving the scheduler can

133
00:06:42,380 --> 00:06:48,020
choose a source node as this more with a

134
00:06:45,440 --> 00:06:51,070
small expected completion time from two

135
00:06:48,020 --> 00:06:51,070
corresponding nodes

136
00:06:51,550 --> 00:06:56,960
however when selecting a destination the

137
00:06:54,500 --> 00:07:00,440
number of candidates knows is large in a

138
00:06:56,960 --> 00:07:03,140
scanning all nodes is too slow thus that

139
00:07:00,440 --> 00:07:06,320
uses a dynamic comebacks how a grows and

140
00:07:03,140 --> 00:07:13,070
who used to use a chance to buy in

141
00:07:06,320 --> 00:07:15,800
binary searching the optional note the

142
00:07:13,070 --> 00:07:18,530
basic idea of domenica how come as how

143
00:07:15,800 --> 00:07:21,020
optimization is my or candidate no to

144
00:07:18,530 --> 00:07:24,679
the point in a Cartesian coordinate

145
00:07:21,020 --> 00:07:28,669
system using the available bandwidth B

146
00:07:24,680 --> 00:07:34,220
as a value of x axis and the accumulated

147
00:07:28,669 --> 00:07:36,409
tasks I see as a Y value task T is will

148
00:07:34,220 --> 00:07:40,040
also be mad because it is Cartesian

149
00:07:36,410 --> 00:07:43,940
coordinate system using zero as X value

150
00:07:40,040 --> 00:07:49,520
and the miners size of task T as Y value

151
00:07:43,940 --> 00:07:52,280
so funding the node was small as people

152
00:07:49,520 --> 00:07:55,099
divides the process is equal to funding

153
00:07:52,280 --> 00:08:01,159
the land connecting that's porn two new

154
00:07:55,100 --> 00:08:03,710
points with the lowest slope to quickly

155
00:08:01,160 --> 00:08:06,320
fund this we computer cameras how often

156
00:08:03,710 --> 00:08:08,750
all node point and only the lower part

157
00:08:06,320 --> 00:08:11,330
of these commerce how is used which is

158
00:08:08,750 --> 00:08:15,650
called lower commas show as a bran lands

159
00:08:11,330 --> 00:08:18,620
in figure the agar isms can find the

160
00:08:15,650 --> 00:08:23,539
optimal node through binary searching

161
00:08:18,620 --> 00:08:25,940
this lower commercial and after all the

162
00:08:23,540 --> 00:08:28,970
node is assigned within new tasks its

163
00:08:25,940 --> 00:08:31,430
accumulated tasks the sizes increases

164
00:08:28,970 --> 00:08:36,080
and the scheduler should maintain a

165
00:08:31,430 --> 00:08:40,400
lower cameras shell then count the next

166
00:08:36,080 --> 00:08:42,800
task to reduce maintenance maintenance

167
00:08:40,400 --> 00:08:44,930
overhead we further use packet

168
00:08:42,799 --> 00:08:47,359
optimization to reduce the size

169
00:08:44,930 --> 00:08:50,689
of candidate points of lower cameras

170
00:08:47,360 --> 00:08:53,270
show the playing of Cartesian coordinate

171
00:08:50,690 --> 00:08:56,360
system is divided into pockets as a

172
00:08:53,270 --> 00:08:58,970
dashed box in the figure only one point

173
00:08:56,360 --> 00:09:01,160
in each pocket can be the candidate note

174
00:08:58,970 --> 00:09:02,649
of the lower cameras share as the hollow

175
00:09:01,160 --> 00:09:06,199
point in the figure

176
00:09:02,649 --> 00:09:09,399
thus the set of candidates only includes

177
00:09:06,200 --> 00:09:11,810
all hollow points instead of all points

178
00:09:09,399 --> 00:09:14,420
simulation result shows that when the

179
00:09:11,810 --> 00:09:17,359
package says the size is set as one

180
00:09:14,420 --> 00:09:20,500
megabytes per second the candidates a

181
00:09:17,360 --> 00:09:25,310
size in only about twenty third of the

182
00:09:20,500 --> 00:09:27,649
123rd of the original one however only

183
00:09:25,310 --> 00:09:31,339
using hit anyone we found that the

184
00:09:27,649 --> 00:09:33,260
algorithm should carefully consider some

185
00:09:31,339 --> 00:09:36,260
nodes which have high available

186
00:09:33,260 --> 00:09:39,439
bandwidth but few available chunks these

187
00:09:36,260 --> 00:09:41,950
nodes are called underemployed nodes now

188
00:09:39,440 --> 00:09:45,230
first identify these nodes and

189
00:09:41,950 --> 00:09:50,209
prioritize the tasks that can use these

190
00:09:45,230 --> 00:09:52,339
and the employed nodes as a source after

191
00:09:50,209 --> 00:09:55,579
the source and the destination node of

192
00:09:52,339 --> 00:09:58,520
each task is determined that I should

193
00:09:55,580 --> 00:10:01,459
allocated bandwidth for it type proposal

194
00:09:58,520 --> 00:10:04,069
iterative WSS algorithm to allocate

195
00:10:01,459 --> 00:10:06,319
bandwidth for tasks and each task who

196
00:10:04,070 --> 00:10:09,589
uses the allocated bandwidth to be

197
00:10:06,320 --> 00:10:12,589
replicated the data the goal of these

198
00:10:09,589 --> 00:10:15,850
algorithm is that attacks complete as

199
00:10:12,589 --> 00:10:18,740
soon as possible in one time slot and

200
00:10:15,850 --> 00:10:22,220
introducing small interference to the

201
00:10:18,740 --> 00:10:27,350
foreground the iterative WSS algorithms

202
00:10:22,220 --> 00:10:31,100
works as follows in each in each

203
00:10:27,350 --> 00:10:34,820
iteration iterative WSS contact a

204
00:10:31,100 --> 00:10:37,310
similar procedure like the WSS algorithm

205
00:10:34,820 --> 00:10:40,040
there were knows have different

206
00:10:37,310 --> 00:10:43,640
different available bandwidth on both

207
00:10:40,040 --> 00:10:46,219
incoming and outgoing sites and if the

208
00:10:43,640 --> 00:10:50,660
air attacks task is assigned on these

209
00:10:46,220 --> 00:10:52,790
nodes the algorithm fairly allocates

210
00:10:50,660 --> 00:10:55,640
available bandwidth for all remaining

211
00:10:52,790 --> 00:10:56,870
tasks wizards there the task size as a

212
00:10:55,640 --> 00:11:00,760
weight

213
00:10:56,870 --> 00:11:04,220
to at least one link is fully allocated

214
00:11:00,760 --> 00:11:06,319
if the bandwidth is offer link is fully

215
00:11:04,220 --> 00:11:08,690
allocated which means that the task has

216
00:11:06,320 --> 00:11:11,420
just made on it cannot obtain more

217
00:11:08,690 --> 00:11:15,710
bandwidth then these tasks are removed

218
00:11:11,420 --> 00:11:18,680
as a read tasks here comes a second

219
00:11:15,710 --> 00:11:21,320
iteration iterative WSS also conduct

220
00:11:18,680 --> 00:11:23,540
bandwidth allocation until one link is

221
00:11:21,320 --> 00:11:29,110
fully saturated then move the

222
00:11:23,540 --> 00:11:32,329
corresponding tasks or third iteration

223
00:11:29,110 --> 00:11:36,800
finally no tasks can have more bandwidth

224
00:11:32,330 --> 00:11:39,350
than finish the allocation after

225
00:11:36,800 --> 00:11:41,750
combining above three key three key

226
00:11:39,350 --> 00:11:43,160
techniques we find some straggler tasks

227
00:11:41,750 --> 00:11:45,830
which influence the quality of

228
00:11:43,160 --> 00:11:48,439
scheduling due to the fact that in

229
00:11:45,830 --> 00:11:51,110
accurate workload estimation and so on

230
00:11:48,440 --> 00:11:53,020
some tasks can not compete in one time

231
00:11:51,110 --> 00:11:57,140
slot and if these tasks are called

232
00:11:53,020 --> 00:11:59,150
stragglers if we do not risk a Jewess of

233
00:11:57,140 --> 00:12:01,970
these tasks we are far too qaulity of

234
00:11:59,150 --> 00:12:04,400
scheduling in current time slot but if

235
00:12:01,970 --> 00:12:06,410
we reschedule them like a new task of

236
00:12:04,400 --> 00:12:10,130
stragglers switching destination will

237
00:12:06,410 --> 00:12:12,949
lose its all pro progress and to this

238
00:12:10,130 --> 00:12:15,380
end ty first estimate whether this

239
00:12:12,950 --> 00:12:17,450
schedulers should change its destination

240
00:12:15,380 --> 00:12:19,580
and 1/4 the struggles between the

241
00:12:17,450 --> 00:12:21,770
destinations they have to be resent and

242
00:12:19,580 --> 00:12:24,140
for the rest of us to address they can

243
00:12:21,770 --> 00:12:28,400
be resumed with the source node change

244
00:12:24,140 --> 00:12:31,040
or the bandwidth changed these four key

245
00:12:28,400 --> 00:12:33,829
tang is works as follows first the key

246
00:12:31,040 --> 00:12:36,709
tangy 4 is used to classify different

247
00:12:33,830 --> 00:12:38,839
type of stragglers second the key

248
00:12:36,709 --> 00:12:41,719
technique is used to determine the

249
00:12:38,839 --> 00:12:43,640
transformation source of some tasks then

250
00:12:41,720 --> 00:12:46,070
through the key technique when the

251
00:12:43,640 --> 00:12:48,589
source and destination of all this patch

252
00:12:46,070 --> 00:12:51,500
in tasks are determined and finally just

253
00:12:48,589 --> 00:12:55,850
transmit the transmission rate of all

254
00:12:51,500 --> 00:12:57,370
the special tasks decided by touch step

255
00:12:55,850 --> 00:12:59,810
3

256
00:12:57,370 --> 00:13:04,010
then all dispatching times are

257
00:12:59,810 --> 00:13:07,099
transmitted by the data servers we

258
00:13:04,010 --> 00:13:10,140
implement a time on Pangu the gray boxes

259
00:13:07,100 --> 00:13:12,240
are our modifications and we injured

260
00:13:10,140 --> 00:13:17,130
and we introduced this centralized

261
00:13:12,240 --> 00:13:20,040
scheduler observer we deployed I on a

262
00:13:17,130 --> 00:13:23,790
1,000 node cluster and in triggered 15

263
00:13:20,040 --> 00:13:26,819
terabytes theta to recover the baseline

264
00:13:23,790 --> 00:13:29,579
of this test a current panghu recovery

265
00:13:26,820 --> 00:13:32,160
strategy which randomly picked nodes to

266
00:13:29,580 --> 00:13:34,530
place data and allocates a constant know

267
00:13:32,160 --> 00:13:39,060
and constant recovery bandwidth on each

268
00:13:34,530 --> 00:13:42,060
node the bandwidth is allocated as 30 90

269
00:13:39,060 --> 00:13:44,459
and 150 megabytes per second called

270
00:13:42,060 --> 00:13:47,099
Pangu slow mean and fast respectively

271
00:13:44,460 --> 00:13:51,560
among them in panko slow that the for

272
00:13:47,100 --> 00:13:54,330
setting on Pangos production system the

273
00:13:51,560 --> 00:13:56,670
evaluation below the x-axis is a

274
00:13:54,330 --> 00:13:59,970
recovery time and if the y at the y-axis

275
00:13:56,670 --> 00:14:03,900
is the 90 percentile latency of the

276
00:13:59,970 --> 00:14:07,230
frequent traffic the results show that

277
00:14:03,900 --> 00:14:11,280
compared to panco original strategy the

278
00:14:07,230 --> 00:14:14,190
highest measurement reduced compared to

279
00:14:11,280 --> 00:14:16,589
Pangu slow tag has same level of low

280
00:14:14,190 --> 00:14:19,550
interference and it's nearly three times

281
00:14:16,590 --> 00:14:22,620
faster in terminal for recovery and

282
00:14:19,550 --> 00:14:25,500
compared to the Panamanian fast today we

283
00:14:22,620 --> 00:14:28,110
had same level of recovery in speed but

284
00:14:25,500 --> 00:14:30,870
Pangu min and father had far higher

285
00:14:28,110 --> 00:14:34,050
interference to foreground we also

286
00:14:30,870 --> 00:14:36,300
conduct some comparisons of tally with

287
00:14:34,050 --> 00:14:38,880
different algorithms and that the result

288
00:14:36,300 --> 00:14:44,040
is diode performance as well and you can

289
00:14:38,880 --> 00:14:46,320
find the result in paper next to title

290
00:14:44,040 --> 00:14:49,199
scallop its scalability of die we

291
00:14:46,320 --> 00:14:51,570
simulate data recovery with infinity

292
00:14:49,200 --> 00:14:54,420
tasks to an entire the throughput of

293
00:14:51,570 --> 00:14:56,880
different algorithms in 20 times worth

294
00:14:54,420 --> 00:14:58,800
the pay in the based on algorithms can

295
00:14:56,880 --> 00:15:02,970
be found in both research papers and

296
00:14:58,800 --> 00:15:06,150
industrial deployment the result can be

297
00:15:02,970 --> 00:15:08,970
found in this figure the x-axis is the

298
00:15:06,150 --> 00:15:11,459
cluster size while the y-axis is the

299
00:15:08,970 --> 00:15:17,370
throughput we found that time can scale

300
00:15:11,460 --> 00:15:19,650
to 225,000 no cluster and the algorithms

301
00:15:17,370 --> 00:15:22,720
can have same level of scalability but

302
00:15:19,650 --> 00:15:25,880
they are scheduling courses although

303
00:15:22,720 --> 00:15:28,370
to conclude through observations of

304
00:15:25,880 --> 00:15:30,560
production caster we find existing

305
00:15:28,370 --> 00:15:34,730
recovery scheduling failed to achieve

306
00:15:30,560 --> 00:15:37,069
both high speed and high quality and we

307
00:15:34,730 --> 00:15:39,400
propose time is to use a time slot based

308
00:15:37,070 --> 00:15:43,100
protocol and a centralized scheduler

309
00:15:39,400 --> 00:15:45,949
incorporates four key techniques in each

310
00:15:43,100 --> 00:15:48,920
time slot to achieve fast high speed and

311
00:15:45,950 --> 00:15:51,470
high quality scheduling the evaluation

312
00:15:48,920 --> 00:15:54,729
shows that time outperforms existing

313
00:15:51,470 --> 00:15:58,150
solutions and has a good scalability

314
00:15:54,730 --> 00:15:58,150
thank you for listening

315
00:15:58,590 --> 00:16:09,560
[Applause]

316
00:16:03,370 --> 00:16:11,480
ok questions hi god girl from Technion

317
00:16:09,560 --> 00:16:13,579
this is very nice work have you

318
00:16:11,480 --> 00:16:26,720
considered applying it to erasure coded

319
00:16:13,580 --> 00:16:29,150
data centers you you don't take into

320
00:16:26,720 --> 00:16:30,560
account that latency in trying to see

321
00:16:29,150 --> 00:16:32,360
the latency impact on the recovery

322
00:16:30,560 --> 00:16:33,430
because you might be recovering from

323
00:16:32,360 --> 00:16:35,390
somewhere which is a little far off

324
00:16:33,430 --> 00:16:36,819
because you only dimension you're

325
00:16:35,390 --> 00:16:42,560
considering is the bandwidth and the

326
00:16:36,820 --> 00:16:45,860
size I don't quite catch you but you

327
00:16:42,560 --> 00:16:49,969
mean that because the recovery time can

328
00:16:45,860 --> 00:16:52,070
be impacted by their latency of the node

329
00:16:49,970 --> 00:16:54,080
where you're recovering from so are like

330
00:16:52,070 --> 00:16:57,200
in your in your data center all all

331
00:16:54,080 --> 00:16:59,330
nodes are the similar the Layton sees or

332
00:16:57,200 --> 00:17:05,150
other latencies vary or do you recover

333
00:16:59,330 --> 00:17:08,209
from like some other data center also so

334
00:17:05,150 --> 00:17:10,910
you means latency is unnecessary in our

335
00:17:08,209 --> 00:17:13,400
evaluation yeah because you only

336
00:17:10,910 --> 00:17:16,100
consider the binary dimension the way

337
00:17:13,400 --> 00:17:18,410
you up okay it's a latency of open

338
00:17:16,099 --> 00:17:21,260
traffic we really have to show that's

339
00:17:18,410 --> 00:17:26,449
the foreground traffic and all be

340
00:17:21,260 --> 00:17:31,280
interference by the background okay okay

341
00:17:26,449 --> 00:17:33,740
thank you okay I'll ask my very standard

342
00:17:31,280 --> 00:17:34,340
question which I noticed you collected

343
00:17:33,740 --> 00:17:35,620
traces

344
00:17:34,340 --> 00:17:38,260
yes so can

345
00:17:35,620 --> 00:17:43,020
get them so we haven't heard meeting to

346
00:17:38,260 --> 00:17:43,020
talk about that okay I will be in touch

