1
00:00:10,429 --> 00:00:15,559
all right my name is Christopher Michael

2
00:00:12,679 --> 00:00:18,610
John I'm going to talk about scaling the

3
00:00:15,559 --> 00:00:22,189
distributed actor runtime with partisan

4
00:00:18,610 --> 00:00:23,390
so distributed actors distributed actors

5
00:00:22,189 --> 00:00:24,800
have been used on a lot of highly

6
00:00:23,390 --> 00:00:27,949
scalable highly concurrent applications

7
00:00:24,800 --> 00:00:29,779
they have tremendous industry success as

8
00:00:27,949 --> 00:00:31,519
I discovered yesterday during the poster

9
00:00:29,779 --> 00:00:33,920
session not many people know that these

10
00:00:31,519 --> 00:00:35,540
programming languages even exist

11
00:00:33,920 --> 00:00:47,269
so hopefully this talk will raise some

12
00:00:35,540 --> 00:00:53,830
awareness about that I hope that in the

13
00:00:47,269 --> 00:00:57,500
video just because okay all right

14
00:00:53,830 --> 00:00:59,449
and so you distributed actors really

15
00:00:57,500 --> 00:01:00,920
successful and you probably know some of

16
00:00:59,449 --> 00:01:03,320
the applications that they've been used

17
00:01:00,920 --> 00:01:06,320
on for tonight is pretty popular

18
00:01:03,320 --> 00:01:09,290
application Gears of War for Halo these

19
00:01:06,320 --> 00:01:11,449
are popular games League of Legends you

20
00:01:09,290 --> 00:01:13,040
may have heard of and whatsapp I'm sure

21
00:01:11,450 --> 00:01:15,110
a lot of you are probably using at this

22
00:01:13,040 --> 00:01:18,920
very moment especially when my mic fell

23
00:01:15,110 --> 00:01:21,250
off my lapel and so each of these actor

24
00:01:18,920 --> 00:01:23,510
systems uses one of the three major

25
00:01:21,250 --> 00:01:25,310
industrial-strength each of these

26
00:01:23,510 --> 00:01:26,840
applications uses one of the three major

27
00:01:25,310 --> 00:01:28,880
industrial-strength out there actor

28
00:01:26,840 --> 00:01:30,140
systems so for tonight for instance uses

29
00:01:28,880 --> 00:01:32,570
aqua cluster for the Scala programming

30
00:01:30,140 --> 00:01:35,409
language Gears of War for use as

31
00:01:32,570 --> 00:01:38,210
Microsoft or leans as does Halo and

32
00:01:35,409 --> 00:01:41,870
League of Legends and whatsapp use the

33
00:01:38,210 --> 00:01:43,880
Erlang programming language now part of

34
00:01:41,870 --> 00:01:45,710
the success part of the reason that

35
00:01:43,880 --> 00:01:47,330
distributed actor systems are so widely

36
00:01:45,710 --> 00:01:49,908
adopted is because of this programming

37
00:01:47,330 --> 00:01:50,870
model it's very simple so first I'm

38
00:01:49,909 --> 00:01:52,460
going to explain this function

39
00:01:50,870 --> 00:01:54,680
definition here so this is defining a

40
00:01:52,460 --> 00:01:56,899
function called call it takes three

41
00:01:54,680 --> 00:02:00,200
arguments a destination process ID a

42
00:01:56,900 --> 00:02:02,390
message and a timeout period we use this

43
00:02:00,200 --> 00:02:03,590
banks syntax here destination bank

44
00:02:02,390 --> 00:02:05,299
message to send a message to a

45
00:02:03,590 --> 00:02:07,100
destination process and we use this

46
00:02:05,299 --> 00:02:08,810
receive primitive to wait for a response

47
00:02:07,100 --> 00:02:11,239
and this will perform pattern matching

48
00:02:08,810 --> 00:02:12,950
and finally with this after clause in

49
00:02:11,239 --> 00:02:14,690
this timeout I'll wait a particular

50
00:02:12,950 --> 00:02:16,310
amount of time for message then I'll

51
00:02:14,690 --> 00:02:18,950
timeout and return an error to the user

52
00:02:16,310 --> 00:02:20,989
so once I define functions then I use

53
00:02:18,950 --> 00:02:23,209
this spawn primitive to instantiate

54
00:02:20,989 --> 00:02:24,230
actors in the system so here I say I'd

55
00:02:23,209 --> 00:02:25,720
like to create an actor

56
00:02:24,230 --> 00:02:27,920
here's the function I'd like to call and

57
00:02:25,720 --> 00:02:31,909
the actor will run that function to

58
00:02:27,920 --> 00:02:33,440
completion and then terminate so this is

59
00:02:31,909 --> 00:02:34,790
a nice programming model and it's really

60
00:02:33,440 --> 00:02:36,650
really nice for building distributed

61
00:02:34,790 --> 00:02:38,150
systems because you don't see networks

62
00:02:36,650 --> 00:02:40,159
you don't see sockets you don't see

63
00:02:38,150 --> 00:02:41,780
serialization you don't see desolation

64
00:02:40,159 --> 00:02:43,609
you don't see any of the stuff that we

65
00:02:41,780 --> 00:02:46,370
usually don't like writing when we're

66
00:02:43,610 --> 00:02:48,019
writing distributed code and all of

67
00:02:46,370 --> 00:02:50,629
these three actor systems whether it's

68
00:02:48,019 --> 00:02:52,549
akka or liens or Erlang all of them have

69
00:02:50,629 --> 00:02:54,109
the same programming model effectively

70
00:02:52,549 --> 00:02:57,140
but slightly different because they have

71
00:02:54,110 --> 00:02:58,879
different host languages so in this talk

72
00:02:57,140 --> 00:03:00,500
we're going to look at how we can

73
00:02:58,879 --> 00:03:02,750
improve distributed actor systems

74
00:03:00,500 --> 00:03:04,959
considering their two limitations the

75
00:03:02,750 --> 00:03:08,540
two limitations are scalability and

76
00:03:04,959 --> 00:03:10,280
latency now in terms of scalability

77
00:03:08,540 --> 00:03:12,650
we're going to increase scalability by

78
00:03:10,280 --> 00:03:15,109
growing clusters to larger clusters of

79
00:03:12,650 --> 00:03:17,180
nodes and in terms of latency what we're

80
00:03:15,109 --> 00:03:19,640
going to attempt to do is use available

81
00:03:17,180 --> 00:03:22,310
bandwidth to perform scheduling in

82
00:03:19,640 --> 00:03:24,140
parallel to reduce latency and increase

83
00:03:22,310 --> 00:03:25,370
overall system throughput now we're

84
00:03:24,140 --> 00:03:26,980
going to achieve this with minimal

85
00:03:25,370 --> 00:03:29,989
modifications to the programming model

86
00:03:26,980 --> 00:03:32,959
we're gonna do this at the library level

87
00:03:29,989 --> 00:03:34,280
which is really nice it's extensible we

88
00:03:32,959 --> 00:03:35,630
don't have to ship a custom runtime we

89
00:03:34,280 --> 00:03:37,040
don't have to ship a patch set for a

90
00:03:35,630 --> 00:03:40,040
custom runtime we don't have to make our

91
00:03:37,040 --> 00:03:41,870
own runtime so let's dive into the

92
00:03:40,040 --> 00:03:44,750
limitations so the first limitation is

93
00:03:41,870 --> 00:03:47,209
around scalability here I have a cluster

94
00:03:44,750 --> 00:03:49,669
of three nodes each is running two

95
00:03:47,209 --> 00:03:52,310
actors and these nodes are connected in

96
00:03:49,669 --> 00:03:53,930
a full mesh topology using TCP and what

97
00:03:52,310 --> 00:03:56,180
this means is when I add a fourth node

98
00:03:53,930 --> 00:03:58,970
and I spawn two actors and stancy eight

99
00:03:56,180 --> 00:04:00,769
two actors on this node I also have to

100
00:03:58,970 --> 00:04:02,049
connect this to all the other all the

101
00:04:00,769 --> 00:04:05,209
other machines in the cluster

102
00:04:02,049 --> 00:04:06,169
now these assumptions around having to

103
00:04:05,209 --> 00:04:08,030
connect all of the nodes together

104
00:04:06,169 --> 00:04:09,650
because these systems have to transmit

105
00:04:08,030 --> 00:04:11,359
metadata information they have to send

106
00:04:09,650 --> 00:04:13,879
heartbeat messages to keep the system

107
00:04:11,359 --> 00:04:15,880
operating because of this scalability is

108
00:04:13,879 --> 00:04:17,810
limited we end up exhausting

109
00:04:15,880 --> 00:04:19,789
communication and spending a lot of time

110
00:04:17,810 --> 00:04:22,490
in serialization for messages that are

111
00:04:19,789 --> 00:04:23,630
just for keeping the system running not

112
00:04:22,490 --> 00:04:25,970
even considering the requests or

113
00:04:23,630 --> 00:04:27,229
responses and this is evidenced by kind

114
00:04:25,970 --> 00:04:30,020
of these two data points that we have

115
00:04:27,229 --> 00:04:31,550
here art work focuses on Erlang so my

116
00:04:30,020 --> 00:04:33,349
two data points here on Erlang but one

117
00:04:31,550 --> 00:04:34,969
is that the only people who have been

118
00:04:33,349 --> 00:04:36,710
able to run distributed Erlang at 200

119
00:04:34,969 --> 00:04:38,210
notes is Ericsson the people who made

120
00:04:36,710 --> 00:04:40,130
the language

121
00:04:38,210 --> 00:04:41,810
and similarly the database that I used

122
00:04:40,130 --> 00:04:44,600
to work on before I quit my job to do my

123
00:04:41,810 --> 00:04:47,210
PhD that react is a dynamo inspired

124
00:04:44,600 --> 00:04:49,729
Cassandra Lake database this database

125
00:04:47,210 --> 00:04:51,169
only used to scale the 60 nodes so that

126
00:04:49,729 --> 00:04:54,050
sound good for a distributed data

127
00:04:51,169 --> 00:04:58,400
management platform surely now the

128
00:04:54,050 --> 00:05:01,160
second limitation is around latency if I

129
00:04:58,400 --> 00:05:03,500
consider a two cluster node to a two

130
00:05:01,160 --> 00:05:05,150
node cluster and I connect these two

131
00:05:03,500 --> 00:05:07,010
nodes and then I spawn like thousands of

132
00:05:05,150 --> 00:05:09,198
actors on node 1 and thousands of actors

133
00:05:07,010 --> 00:05:11,240
on node 2 what I need to do is use that

134
00:05:09,199 --> 00:05:13,970
single TCP connection to multiplex

135
00:05:11,240 --> 00:05:16,190
online communication for any actor to

136
00:05:13,970 --> 00:05:18,590
any other actor on either side of the

137
00:05:16,190 --> 00:05:19,850
cluster on either node and this results

138
00:05:18,590 --> 00:05:21,320
you know in queuing delay this

139
00:05:19,850 --> 00:05:22,520
head-of-line blocking that happens when

140
00:05:21,320 --> 00:05:24,680
you have messages sending at different

141
00:05:22,520 --> 00:05:26,448
rates and different sizes network

142
00:05:24,680 --> 00:05:28,310
congestion issues we're running this in

143
00:05:26,449 --> 00:05:30,050
geo distributed scenarios or you're

144
00:05:28,310 --> 00:05:31,520
running it at large objects and finally

145
00:05:30,050 --> 00:05:33,440
everybody's contending for access to

146
00:05:31,520 --> 00:05:34,789
this socket and that doesn't work when

147
00:05:33,440 --> 00:05:38,479
I'm mapping like a hundred thousand

148
00:05:34,789 --> 00:05:40,070
actors into one TCP connection so how do

149
00:05:38,479 --> 00:05:41,240
we solve this so the work that we're

150
00:05:40,070 --> 00:05:43,250
going to talk about today is called

151
00:05:41,240 --> 00:05:45,770
partisan it's a library that I've been

152
00:05:43,250 --> 00:05:47,479
working on for at least two maybe more

153
00:05:45,770 --> 00:05:49,400
years now it's a system that's designed

154
00:05:47,479 --> 00:05:50,840
to remove assumptions around current

155
00:05:49,400 --> 00:05:52,700
implementations that are made by

156
00:05:50,840 --> 00:05:55,700
runtimes these full mesh assumptions

157
00:05:52,700 --> 00:05:58,130
these single TCP assumptions as provided

158
00:05:55,700 --> 00:05:59,630
in user space as a library so that it

159
00:05:58,130 --> 00:06:01,130
can be extensible it can you know you

160
00:05:59,630 --> 00:06:03,260
can use a debugger all this nice stuff

161
00:06:01,130 --> 00:06:05,419
and can be leveraged immediately you can

162
00:06:03,260 --> 00:06:07,900
use it in applications today and so the

163
00:06:05,419 --> 00:06:10,849
key contributions of partisan are first

164
00:06:07,900 --> 00:06:12,859
allowing the application developer to

165
00:06:10,849 --> 00:06:14,659
specify the communication strategy the

166
00:06:12,860 --> 00:06:16,430
communication overlay that's used at

167
00:06:14,660 --> 00:06:19,550
runtime without changing application

168
00:06:16,430 --> 00:06:22,220
code and the second is enabling parallel

169
00:06:19,550 --> 00:06:24,500
transmission on the network so let's

170
00:06:22,220 --> 00:06:26,539
look at the first contribution so the

171
00:06:24,500 --> 00:06:29,120
first thing is around selecting the

172
00:06:26,539 --> 00:06:30,320
overlay so like I said before we connect

173
00:06:29,120 --> 00:06:31,789
all these things in this full mesh

174
00:06:30,320 --> 00:06:35,000
everybody communicates with everybody

175
00:06:31,789 --> 00:06:36,349
and the insight here is you know if we

176
00:06:35,000 --> 00:06:38,180
want to change the communication

177
00:06:36,349 --> 00:06:39,469
strategy we shouldn't let that be

178
00:06:38,180 --> 00:06:41,180
evident in the programming model we

179
00:06:39,470 --> 00:06:42,979
don't want that to come up and expose

180
00:06:41,180 --> 00:06:44,630
itself in the programming model we want

181
00:06:42,979 --> 00:06:46,609
to keep the programming model the same

182
00:06:44,630 --> 00:06:48,950
we want to preserve these distinct

183
00:06:46,610 --> 00:06:51,440
semantics and so here you know just to

184
00:06:48,950 --> 00:06:52,610
reiterate the point we really want to

185
00:06:51,440 --> 00:06:54,200
look at this does not changing anything

186
00:06:52,610 --> 00:06:55,430
because we have a model it's really

187
00:06:54,200 --> 00:06:58,219
successful that people are building

188
00:06:55,430 --> 00:07:01,550
these great applications in so in

189
00:06:58,220 --> 00:07:03,260
partisan today we we use we have this

190
00:07:01,550 --> 00:07:05,630
full mesh topology this is the default

191
00:07:03,260 --> 00:07:07,520
topology it's a simplest reason about it

192
00:07:05,630 --> 00:07:09,740
operates really well when you have

193
00:07:07,520 --> 00:07:11,570
smaller clusters and what happens is I

194
00:07:09,740 --> 00:07:13,550
connect all my nodes completely and then

195
00:07:11,570 --> 00:07:15,230
I use direct messaging to do

196
00:07:13,550 --> 00:07:18,590
point-to-point messaging so my API is

197
00:07:15,230 --> 00:07:20,510
point-to-point messaging we also provide

198
00:07:18,590 --> 00:07:22,460
a second topology called client-server

199
00:07:20,510 --> 00:07:23,900
this is a familiar hub-and-spoke kind of

200
00:07:22,460 --> 00:07:25,820
model right servers talk to servers

201
00:07:23,900 --> 00:07:27,229
clients talk to servers and what this

202
00:07:25,820 --> 00:07:28,909
means is that clients do not directly

203
00:07:27,230 --> 00:07:30,860
communicate with other clients and so

204
00:07:28,910 --> 00:07:32,510
the programming model to remain

205
00:07:30,860 --> 00:07:34,520
point-to-point we have to have servers

206
00:07:32,510 --> 00:07:35,719
around messages on clients behaves so

207
00:07:34,520 --> 00:07:38,539
that clients can still message one

208
00:07:35,720 --> 00:07:40,820
another similarly the the the

209
00:07:38,540 --> 00:07:43,070
peer-to-peer topology scales to massive

210
00:07:40,820 --> 00:07:46,219
clusters ten thousand nodes twenty

211
00:07:43,070 --> 00:07:48,170
thousand nodes and because of this every

212
00:07:46,220 --> 00:07:49,940
node needs to only see kind of only

213
00:07:48,170 --> 00:07:52,640
connect to a portion of the network

214
00:07:49,940 --> 00:07:54,800
right and this means that you might not

215
00:07:52,640 --> 00:07:56,300
even have a server to route messages on

216
00:07:54,800 --> 00:07:58,340
behalf so we have to do is transitive

217
00:07:56,300 --> 00:08:00,470
routing we have to have messages handed

218
00:07:58,340 --> 00:08:02,320
off between peers to get to the final

219
00:08:00,470 --> 00:08:05,180
destination

220
00:08:02,320 --> 00:08:08,210
now the second set of optimizations will

221
00:08:05,180 --> 00:08:10,880
look at is around application enabling

222
00:08:08,210 --> 00:08:12,289
parallelism on the network we're gonna

223
00:08:10,880 --> 00:08:13,940
break this down into two techniques so

224
00:08:12,290 --> 00:08:16,310
the first technique is called named

225
00:08:13,940 --> 00:08:18,530
channels and the way named channels work

226
00:08:16,310 --> 00:08:20,150
is under the assumption that we have you

227
00:08:18,530 --> 00:08:23,150
knows custom nodes with different actors

228
00:08:20,150 --> 00:08:25,580
sending different types of messages so

229
00:08:23,150 --> 00:08:27,500
some are request responses and some are

230
00:08:25,580 --> 00:08:29,930
maintenance traffic for the cluster

231
00:08:27,500 --> 00:08:31,460
maintenance itself right and so in the

232
00:08:29,930 --> 00:08:33,140
react distributed database we have to

233
00:08:31,460 --> 00:08:35,030
gossip or ring around we have to gossip

234
00:08:33,140 --> 00:08:36,740
metadata we have to send failure

235
00:08:35,030 --> 00:08:38,598
detection information and what we want

236
00:08:36,740 --> 00:08:40,190
to do is we want to say get all that

237
00:08:38,599 --> 00:08:42,349
stuff out of the request path unless

238
00:08:40,190 --> 00:08:44,360
it's absolutely necessary put this on to

239
00:08:42,349 --> 00:08:47,200
a different channel and let's pipeline

240
00:08:44,360 --> 00:08:50,810
these requests on this single path now

241
00:08:47,200 --> 00:08:52,460
we have to in Erlang we have to annotate

242
00:08:50,810 --> 00:08:54,619
all the call sites with message types

243
00:08:52,460 --> 00:08:58,160
this is unfortunate but this is because

244
00:08:54,620 --> 00:08:59,839
Erlang really has no types you you don't

245
00:08:58,160 --> 00:09:02,360
know what anything is everything is

246
00:08:59,839 --> 00:09:05,180
basically just a term or a tupple or a

247
00:09:02,360 --> 00:09:06,770
couple of terms and so we don't we can't

248
00:09:05,180 --> 00:09:09,140
this at runtime automatically but in a

249
00:09:06,770 --> 00:09:10,970
system like Scala we have a really rich

250
00:09:09,140 --> 00:09:12,920
type system and a system you know in a

251
00:09:10,970 --> 00:09:14,480
programming language like C sharp we can

252
00:09:12,920 --> 00:09:15,680
do runtime reflection and by doing

253
00:09:14,480 --> 00:09:19,100
runtime reflection we can do this

254
00:09:15,680 --> 00:09:21,079
automatically and so key here take the

255
00:09:19,100 --> 00:09:23,540
types and partition traffic on multiple

256
00:09:21,080 --> 00:09:26,000
connections based on types now a special

257
00:09:23,540 --> 00:09:28,569
case of that technique a special case of

258
00:09:26,000 --> 00:09:31,130
named channels we can try to keep actors

259
00:09:28,570 --> 00:09:33,170
connect are working on one connection

260
00:09:31,130 --> 00:09:35,689
and we can do this by a finit izing the

261
00:09:33,170 --> 00:09:37,099
traffic from multiple actors on two

262
00:09:35,690 --> 00:09:39,200
connections based on their sender

263
00:09:37,100 --> 00:09:41,450
identifier and based on their recipient

264
00:09:39,200 --> 00:09:43,190
identifier or we can use a logical

265
00:09:41,450 --> 00:09:44,480
identity if actors happen to take on

266
00:09:43,190 --> 00:09:47,360
different roles over time which is

267
00:09:44,480 --> 00:09:49,520
common in actor systems and so what this

268
00:09:47,360 --> 00:09:51,350
does is it lets us kind of take

269
00:09:49,520 --> 00:09:54,199
advantage of kind of pipelining

270
00:09:51,350 --> 00:09:55,970
operations where we have these request

271
00:09:54,200 --> 00:10:00,080
response patterns to a group of actors

272
00:09:55,970 --> 00:10:01,940
such as in a distributed database so

273
00:10:00,080 --> 00:10:03,620
let's see how all this stuff runs let's

274
00:10:01,940 --> 00:10:05,300
run some experiments I'm going to talk

275
00:10:03,620 --> 00:10:07,130
about three sets of experiments today

276
00:10:05,300 --> 00:10:10,660
the first experiment I want to talk

277
00:10:07,130 --> 00:10:13,250
about is a scenario that came from a

278
00:10:10,660 --> 00:10:15,380
industrial partnership we had with Rovio

279
00:10:13,250 --> 00:10:17,120
entertainment who makes Angry Birds this

280
00:10:15,380 --> 00:10:19,550
is a advertisement counter I'll explain

281
00:10:17,120 --> 00:10:20,570
it in a moment the second set of

282
00:10:19,550 --> 00:10:23,359
experiments will look at is

283
00:10:20,570 --> 00:10:25,160
point-to-point experiments for for

284
00:10:23,360 --> 00:10:26,600
looking at roundtrip messaging kind of

285
00:10:25,160 --> 00:10:28,189
round-trip performance and messaging so

286
00:10:26,600 --> 00:10:31,010
these will be a set of micro benchmarks

287
00:10:28,190 --> 00:10:33,170
to examine the impact of our techniques

288
00:10:31,010 --> 00:10:36,319
on latency and how we can reduce latency

289
00:10:33,170 --> 00:10:40,189
and then finally the last set of

290
00:10:36,320 --> 00:10:42,920
benchmarks are based on the distributed

291
00:10:40,190 --> 00:10:44,480
programming framework react core which

292
00:10:42,920 --> 00:10:46,219
is an implementation of the Amazon

293
00:10:44,480 --> 00:10:48,050
dynamo model in Erlang this is the

294
00:10:46,220 --> 00:10:49,610
actual framework that's used in the

295
00:10:48,050 --> 00:10:52,430
production react database that's

296
00:10:49,610 --> 00:10:55,340
deployed at the NHS and all these other

297
00:10:52,430 --> 00:10:57,170
places and we build two applications on

298
00:10:55,340 --> 00:10:58,970
top of this so we build a simple echo

299
00:10:57,170 --> 00:11:02,030
service so we're bound only by this to

300
00:10:58,970 --> 00:11:04,130
be to the network and then we build a

301
00:11:02,030 --> 00:11:06,380
little mini key value store distributed

302
00:11:04,130 --> 00:11:08,240
database rights to three nodes waits for

303
00:11:06,380 --> 00:11:11,360
a majority kind of like Cassandra

304
00:11:08,240 --> 00:11:14,150
operates so let's talk about the Rovio

305
00:11:11,360 --> 00:11:16,240
example so the romeo example is an

306
00:11:14,150 --> 00:11:18,290
advertisement counter so if you consider

307
00:11:16,240 --> 00:11:19,639
if you're playing Angry Birds

308
00:11:18,290 --> 00:11:21,649
some of you might be playing Angry Birds

309
00:11:19,639 --> 00:11:23,089
right now for all I know if you play

310
00:11:21,649 --> 00:11:26,839
Angry Birds sometimes you'll see a net

311
00:11:23,089 --> 00:11:29,690
and what we want to do is we want to

312
00:11:26,839 --> 00:11:31,370
aggregate the ad counts we want to

313
00:11:29,690 --> 00:11:33,759
aggregate the number of times ads have

314
00:11:31,370 --> 00:11:36,949
been displayed to all of the users and

315
00:11:33,759 --> 00:11:39,079
we want to turn the ad off when we've

316
00:11:36,949 --> 00:11:42,560
shown a minimum level a lower bound so

317
00:11:39,079 --> 00:11:43,699
at least 5,000 impressions now we're

318
00:11:42,560 --> 00:11:45,349
going to do is we're going to replicate

319
00:11:43,699 --> 00:11:47,449
this counter on everybody's device and

320
00:11:45,350 --> 00:11:48,769
we're going to periodically synchronize

321
00:11:47,449 --> 00:11:50,569
this counter and then we have this

322
00:11:48,769 --> 00:11:52,490
threshold trigger when the ad is shown X

323
00:11:50,569 --> 00:11:54,920
times so here's our three node cluster

324
00:11:52,490 --> 00:11:57,139
we have two active we have an actor on

325
00:11:54,920 --> 00:11:59,329
each node we increment the local counter

326
00:11:57,139 --> 00:12:01,279
and then we propagate that counter to

327
00:11:59,329 --> 00:12:03,050
the other nodes who merge it in and so

328
00:12:01,279 --> 00:12:05,630
this keeps this counter moving forward

329
00:12:03,050 --> 00:12:07,609
as its incremented locally and sent to

330
00:12:05,630 --> 00:12:09,019
all the other replicas in the system now

331
00:12:07,610 --> 00:12:10,759
we've run these experiments on ec2

332
00:12:09,019 --> 00:12:12,529
they're not simulated we didn't use

333
00:12:10,759 --> 00:12:14,360
Pearson and we're going to look at two

334
00:12:12,529 --> 00:12:16,519
of our topologies client-server and

335
00:12:14,360 --> 00:12:18,100
peer-to-peer we're going to use a fixed

336
00:12:16,519 --> 00:12:20,509
number of increment operation x' and

337
00:12:18,100 --> 00:12:22,370
this means that the amount of state that

338
00:12:20,509 --> 00:12:23,930
we generate for every experiment is the

339
00:12:22,370 --> 00:12:26,480
same but we're going to see the effect

340
00:12:23,930 --> 00:12:27,979
on redundancy in the overlays and can be

341
00:12:26,480 --> 00:12:31,250
different communication paths on the

342
00:12:27,980 --> 00:12:32,779
amount of data we transfer so here we

343
00:12:31,250 --> 00:12:34,430
have a graph on the y-axis we're

344
00:12:32,779 --> 00:12:36,350
plotting data transmission to complete

345
00:12:34,430 --> 00:12:39,469
the experiment in log scale on the

346
00:12:36,350 --> 00:12:43,040
x-axis we have the cluster size from 32

347
00:12:39,470 --> 00:12:44,540
up to 1024 the the the black bar

348
00:12:43,040 --> 00:12:46,010
represents the client-server topology

349
00:12:44,540 --> 00:12:48,620
and the gray bar represents the

350
00:12:46,010 --> 00:12:51,439
peer-to-peer topology now what we see

351
00:12:48,620 --> 00:12:54,649
here first is the data transmission

352
00:12:51,440 --> 00:12:56,089
serves as a proxy for redundancy so in

353
00:12:54,649 --> 00:12:57,800
the client-server one all the messages

354
00:12:56,089 --> 00:12:59,269
are sent to each destination once

355
00:12:57,800 --> 00:13:00,680
they're routed through the server so

356
00:12:59,269 --> 00:13:02,480
that's kind of our lower bound the

357
00:13:00,680 --> 00:13:04,430
minimum kind of data we have to transfer

358
00:13:02,480 --> 00:13:06,050
but with a peer-to-peer topology we see

359
00:13:04,430 --> 00:13:07,849
because there's redundant links people

360
00:13:06,050 --> 00:13:11,060
might get the same message down multiple

361
00:13:07,850 --> 00:13:12,319
links multiple times and so what we

362
00:13:11,060 --> 00:13:14,839
observe here is that at these lower

363
00:13:12,319 --> 00:13:16,250
cluster sizes these these less we're

364
00:13:14,839 --> 00:13:18,439
done in overlays that are better for

365
00:13:16,250 --> 00:13:20,449
smaller clusters they're more efficient

366
00:13:18,439 --> 00:13:22,339
on the wire they send less data but as

367
00:13:20,449 --> 00:13:23,750
we observe here the trend with

368
00:13:22,339 --> 00:13:25,670
peer-to-peer is that the peer-to-peer

369
00:13:23,750 --> 00:13:27,110
keeps scaling and we we had to stop our

370
00:13:25,670 --> 00:13:28,310
experiments here because I had I had

371
00:13:27,110 --> 00:13:29,600
spent quite a bit of the European

372
00:13:28,310 --> 00:13:31,430
Union's money where I was doing this

373
00:13:29,600 --> 00:13:33,440
work so we had to stop at 1024

374
00:13:31,430 --> 00:13:35,899
but we could have kept going and so at

375
00:13:33,440 --> 00:13:37,640
this 256 when we get to 512 we see the

376
00:13:35,899 --> 00:13:39,080
server instance runs out of memory to

377
00:13:37,640 --> 00:13:41,390
start addressing the clients actually

378
00:13:39,080 --> 00:13:42,830
message queues in Erlang are unbounded

379
00:13:41,390 --> 00:13:44,330
so when you send somebody a lot of

380
00:13:42,830 --> 00:13:46,970
messages they've run out of memory and

381
00:13:44,330 --> 00:13:47,899
then the UM killer kills the instance so

382
00:13:46,970 --> 00:13:49,880
kind of the takeaway here is

383
00:13:47,899 --> 00:13:51,080
peer-to-peer kind of got nice scaling

384
00:13:49,880 --> 00:13:52,760
properties but it's a little bit more

385
00:13:51,080 --> 00:13:54,800
expensive when we don't need it and then

386
00:13:52,760 --> 00:13:58,220
the client server is really efficient on

387
00:13:54,800 --> 00:14:00,740
the lower the lower end so latency

388
00:13:58,220 --> 00:14:01,970
benchmarks we'll get right into them so

389
00:14:00,740 --> 00:14:04,459
with the latency benchmarks what we're

390
00:14:01,970 --> 00:14:05,990
gonna do is look at round-trip time for

391
00:14:04,459 --> 00:14:08,270
sending individual messages on the wire

392
00:14:05,990 --> 00:14:10,180
we're gonna simulate 20 milliseconds of

393
00:14:08,270 --> 00:14:13,520
round-trip time latency to simulate

394
00:14:10,180 --> 00:14:15,620
intra DC in the same region for Amazon

395
00:14:13,520 --> 00:14:17,360
we have other experiments but I I found

396
00:14:15,620 --> 00:14:19,430
this one interesting to show so this is

397
00:14:17,360 --> 00:14:21,770
the one I picked we're gonna use a 512

398
00:14:19,430 --> 00:14:25,339
kilobytes a load size and we're gonna

399
00:14:21,770 --> 00:14:27,560
graph in red distributed Erlang in in

400
00:14:25,339 --> 00:14:29,779
green partisan with only a single TCP

401
00:14:27,560 --> 00:14:32,029
connection this will serve to show how

402
00:14:29,779 --> 00:14:34,430
much penalty we pay by being in user

403
00:14:32,029 --> 00:14:36,200
space and then in teal we're going to

404
00:14:34,430 --> 00:14:38,540
see partisan without with some of our

405
00:14:36,200 --> 00:14:41,089
optimizations and 16 connections and

406
00:14:38,540 --> 00:14:43,130
then in purple we're going to see the

407
00:14:41,089 --> 00:14:44,420
total optimal config so again just to

408
00:14:43,130 --> 00:14:46,160
reiterate the things you want to be

409
00:14:44,420 --> 00:14:47,890
paying attention to your two red

410
00:14:46,160 --> 00:14:51,230
distributed Erlang that's the baseline

411
00:14:47,890 --> 00:14:53,120
partisan that's the purple alright it's

412
00:14:51,230 --> 00:14:54,920
the first thing we see when we see this

413
00:14:53,120 --> 00:14:56,600
red to green is that the partisan

414
00:14:54,920 --> 00:14:59,510
performance is competitive even with the

415
00:14:56,600 --> 00:15:02,420
user space implementation so regardless

416
00:14:59,510 --> 00:15:04,330
of you know not being in the kernel not

417
00:15:02,420 --> 00:15:07,459
being written in C we remain competitive

418
00:15:04,330 --> 00:15:09,110
we see that with the green bar we start

419
00:15:07,459 --> 00:15:10,969
paying in term when we have a single

420
00:15:09,110 --> 00:15:14,420
connection we're paying penalties for

421
00:15:10,970 --> 00:15:16,070
context switching and user space but as

422
00:15:14,420 --> 00:15:17,750
soon as we have finit i's connections

423
00:15:16,070 --> 00:15:20,060
and take advantage of our optimizations

424
00:15:17,750 --> 00:15:24,980
we can get a 13 point 5 X improvement

425
00:15:20,060 --> 00:15:27,469
for 128 actors we have details in the

426
00:15:24,980 --> 00:15:29,149
paper why we chose 16 connections now in

427
00:15:27,470 --> 00:15:32,510
throughput the throughput experiments

428
00:15:29,149 --> 00:15:36,380
are going to use a key value store and

429
00:15:32,510 --> 00:15:39,110
an echo service that where we will issue

430
00:15:36,380 --> 00:15:43,550
requests to to a normal distribution

431
00:15:39,110 --> 00:15:45,020
over 10,000 nodes we'll look at how many

432
00:15:43,550 --> 00:15:45,349
operations were able to perform per

433
00:15:45,020 --> 00:15:47,780
second

434
00:15:45,350 --> 00:15:49,640
and then in our key-value example what

435
00:15:47,780 --> 00:15:52,970
we'll do as a fan out fan in Cassandra

436
00:15:49,640 --> 00:15:54,890
like pattern and so here on the x-axis

437
00:15:52,970 --> 00:15:58,640
we're varying the number of actors we

438
00:15:54,890 --> 00:15:59,870
got throughput per second on the Y in

439
00:15:58,640 --> 00:16:02,569
the red we're gonna have one kilobyte

440
00:15:59,870 --> 00:16:06,980
payloads green is 512 and the bottom is

441
00:16:02,570 --> 00:16:08,570
8 Meg if we focus in on 128 actors we

442
00:16:06,980 --> 00:16:12,790
see that we're roughly the same when it

443
00:16:08,570 --> 00:16:15,920
comes to does that count the mic part

444
00:16:12,790 --> 00:16:17,980
like we see that we're roughly the same

445
00:16:15,920 --> 00:16:20,360
performance when there's red and green

446
00:16:17,980 --> 00:16:23,350
when we have 1 kilobyte and 512

447
00:16:20,360 --> 00:16:27,080
kilobytes and then finally we get to

448
00:16:23,350 --> 00:16:28,850
here with 8 megabytes we get a 2.8 for X

449
00:16:27,080 --> 00:16:29,990
improvement alright so I'm basically out

450
00:16:28,850 --> 00:16:31,130
of time but I want to show this last

451
00:16:29,990 --> 00:16:33,560
graph because this is kind of the most

452
00:16:31,130 --> 00:16:35,630
important graph here and so this is the

453
00:16:33,560 --> 00:16:37,790
key value store this is the fan and fan

454
00:16:35,630 --> 00:16:40,520
out problem fan and fan out pattern so

455
00:16:37,790 --> 00:16:43,069
it's like Cassandra now what we observe

456
00:16:40,520 --> 00:16:45,410
here if we focus in 128 is that we have

457
00:16:43,070 --> 00:16:48,380
roughly the same performance when we're

458
00:16:45,410 --> 00:16:50,060
dealing with one kilobyte objects now

459
00:16:48,380 --> 00:16:52,810
when the object size starts increasing

460
00:16:50,060 --> 00:16:56,030
here two we get a 1.5 X when we move to

461
00:16:52,810 --> 00:16:58,250
512 K and then when we move to 8 Meg we

462
00:16:56,030 --> 00:17:00,110
have 104 operations per second with the

463
00:16:58,250 --> 00:17:01,820
partisan performance but distributed

464
00:17:00,110 --> 00:17:03,500
Erlang stupid completely collapses and

465
00:17:01,820 --> 00:17:05,810
we only complete a single experiment for

466
00:17:03,500 --> 00:17:07,280
the duration of the of the execution now

467
00:17:05,810 --> 00:17:10,399
this is an interesting result because

468
00:17:07,280 --> 00:17:11,810
react operators anecdotally we're told

469
00:17:10,400 --> 00:17:13,760
in the documentation it's still online

470
00:17:11,810 --> 00:17:15,050
you can go look at it too don't store

471
00:17:13,760 --> 00:17:16,520
objects in this database that are

472
00:17:15,050 --> 00:17:18,050
greater than 1 Meg because you'll kill

473
00:17:16,520 --> 00:17:19,490
the throughput of the system you'll

474
00:17:18,050 --> 00:17:22,460
actually crash the performance because

475
00:17:19,490 --> 00:17:25,099
like network carrier will collapse all

476
00:17:22,460 --> 00:17:26,960
right so to conclude distributed actor

477
00:17:25,099 --> 00:17:29,300
systems here have typically been limited

478
00:17:26,960 --> 00:17:30,590
by implementation assumptions they have

479
00:17:29,300 --> 00:17:32,480
not been limited by the programming

480
00:17:30,590 --> 00:17:34,490
model as we saw it's just sending

481
00:17:32,480 --> 00:17:36,530
messages most of these design decisions

482
00:17:34,490 --> 00:17:39,110
were made in the early 90s when we were

483
00:17:36,530 --> 00:17:41,389
deploying to single data centers and we

484
00:17:39,110 --> 00:17:43,219
believe that our work designs and design

485
00:17:41,390 --> 00:17:46,160
fills a need for improved large-scale

486
00:17:43,220 --> 00:17:47,810
actor runtimes now we believe this to be

487
00:17:46,160 --> 00:17:49,490
true because previously react

488
00:17:47,810 --> 00:17:51,220
implemented their own transport for

489
00:17:49,490 --> 00:17:53,180
large objects and geo distribution

490
00:17:51,220 --> 00:17:55,910
they're considering partisan as a

491
00:17:53,180 --> 00:17:57,230
replacement in react CS this was

492
00:17:55,910 --> 00:17:59,210
software that was developed to store

493
00:17:57,230 --> 00:18:01,010
large objects under the s3 API

494
00:17:59,210 --> 00:18:02,690
did one megabyte chunking so an engineer

495
00:18:01,010 --> 00:18:04,399
spent a long time building one megabyte

496
00:18:02,690 --> 00:18:07,340
chunking because of a problem in the run

497
00:18:04,399 --> 00:18:08,689
time and then finally we there's two new

498
00:18:07,340 --> 00:18:10,970
applications I'd like to mention that

499
00:18:08,690 --> 00:18:13,039
have been built on partisan barrel DB

500
00:18:10,970 --> 00:18:14,870
uses our parallelism optimizations and

501
00:18:13,039 --> 00:18:17,090
our overlay for providing a large-scale

502
00:18:14,870 --> 00:18:18,918
peer-to-peer replicated database this is

503
00:18:17,090 --> 00:18:21,830
built by developer former developers of

504
00:18:18,919 --> 00:18:23,570
couchdb and then Bondi is a RPC

505
00:18:21,830 --> 00:18:25,549
transport layer for hundreds of micro

506
00:18:23,570 --> 00:18:27,379
services that is been running in

507
00:18:25,549 --> 00:18:30,408
production for 18 months using partisan

508
00:18:27,380 --> 00:18:32,360
so to conclude we believe that our work

509
00:18:30,409 --> 00:18:35,899
enables new types of applications built

510
00:18:32,360 --> 00:18:37,370
using distributed actors and you know I

511
00:18:35,899 --> 00:18:39,469
think we've shown evidence that you can

512
00:18:37,370 --> 00:18:41,270
do large objects and you can do geo just

513
00:18:39,470 --> 00:18:42,770
distributed applications and we also

514
00:18:41,270 --> 00:18:44,120
believe that we paved the way to start

515
00:18:42,770 --> 00:18:45,559
using actors where they haven't been

516
00:18:44,120 --> 00:18:47,360
seen before maybe client-server

517
00:18:45,559 --> 00:18:50,480
applications maybe mobile devices who

518
00:18:47,360 --> 00:18:52,039
knows and so thank you for coming to my

519
00:18:50,480 --> 00:18:54,470
talk if it was your first time thanks

520
00:18:52,039 --> 00:19:07,970
for it and if it was your second special

521
00:18:54,470 --> 00:19:13,460
thanks for it hi do we get to ask

522
00:19:07,970 --> 00:19:15,230
questions so so i'm eric ID from the

523
00:19:13,460 --> 00:19:17,799
university of utah this is I think

524
00:19:15,230 --> 00:19:22,580
really great work very interesting work

525
00:19:17,799 --> 00:19:27,649
so so it seems that partisan is like a

526
00:19:22,580 --> 00:19:30,710
win in every dimension so it should just

527
00:19:27,649 --> 00:19:33,439
go into airline tomorrow so so why won't

528
00:19:30,710 --> 00:19:35,270
it go into airline so that's a great

529
00:19:33,440 --> 00:19:36,770
that's a really great question so there

530
00:19:35,270 --> 00:19:40,100
are there are a couple things going on

531
00:19:36,770 --> 00:19:43,190
there so first first since we didn't

532
00:19:40,100 --> 00:19:47,000
have runtime support we we don't support

533
00:19:43,190 --> 00:19:49,039
sending closures now this is an

534
00:19:47,000 --> 00:19:50,419
interesting thing because I don't

535
00:19:49,039 --> 00:19:51,770
believe there's anything stopping us

536
00:19:50,419 --> 00:19:53,899
from doing it but we're also a little

537
00:19:51,770 --> 00:19:56,539
dogmatic about it because we think it's

538
00:19:53,899 --> 00:19:58,340
really bad to send the reference to the

539
00:19:56,539 --> 00:20:00,320
number of a closure in some source file

540
00:19:58,340 --> 00:20:02,209
that the remote mode might not even have

541
00:20:00,320 --> 00:20:04,460
loaded or have a different version

542
00:20:02,210 --> 00:20:09,990
loaded so that's a functions or a

543
00:20:04,460 --> 00:20:13,200
problem another one is is around

544
00:20:09,990 --> 00:20:14,580
there's references we actually no

545
00:20:13,200 --> 00:20:17,639
references are fine there was one more

546
00:20:14,580 --> 00:20:19,649
around some of the failure detector

547
00:20:17,639 --> 00:20:21,510
behavior so the failure detector

548
00:20:19,649 --> 00:20:23,100
basically counts

549
00:20:21,510 --> 00:20:25,169
it sends heartbeat messages and it waits

550
00:20:23,100 --> 00:20:27,178
for like a heartbeat interval to elapse

551
00:20:25,169 --> 00:20:29,130
like oh I missed so many heartbeats I'll

552
00:20:27,179 --> 00:20:33,210
consider all of the remote actors dead

553
00:20:29,130 --> 00:20:34,769
and so this is you this heart beat this

554
00:20:33,210 --> 00:20:37,889
failure detector is used to build links

555
00:20:34,769 --> 00:20:40,350
and monitors and so people like doing

556
00:20:37,889 --> 00:20:42,149
this cross node and so it's really

557
00:20:40,350 --> 00:20:44,340
difficult to do this efficiently with

558
00:20:42,149 --> 00:20:46,080
the peer-to-peer Oh overlay because it

559
00:20:44,340 --> 00:20:47,639
kind of assumes that I I have if I need

560
00:20:46,080 --> 00:20:50,070
to know that some actor on that remote

561
00:20:47,639 --> 00:20:51,990
node is alive then I need to maintain a

562
00:20:50,070 --> 00:20:54,510
connection to it so I can I can tell

563
00:20:51,990 --> 00:20:56,370
that right and so the this existing

564
00:20:54,510 --> 00:20:58,139
semantics of Erlang would not be able to

565
00:20:56,370 --> 00:21:00,029
be mapped into this immediately until we

566
00:20:58,139 --> 00:21:02,639
had a good solution one solution is to

567
00:21:00,029 --> 00:21:04,139
transitively find out if somebody is

568
00:21:02,639 --> 00:21:06,479
alive but then that makes the failure

569
00:21:04,139 --> 00:21:07,769
detection interval really long so maybe

570
00:21:06,480 --> 00:21:10,769
the failure detector is less useful

571
00:21:07,769 --> 00:21:12,570
there so these have been kind of these

572
00:21:10,769 --> 00:21:14,730
have been like the big things these kind

573
00:21:12,570 --> 00:21:17,360
of two features that we don't we don't

574
00:21:14,730 --> 00:21:20,010
really know how to handle just yet so

575
00:21:17,360 --> 00:21:22,799
yeah so that's kind of kind of the

576
00:21:20,010 --> 00:21:26,760
blocking stuff with with with OTP inner

577
00:21:22,799 --> 00:21:28,710
thank you yep or the beam rather one

578
00:21:26,760 --> 00:21:30,720
quick question I just had a quick

579
00:21:28,710 --> 00:21:32,789
question about actor migration it seems

580
00:21:30,720 --> 00:21:34,710
like actor migration is made more

581
00:21:32,789 --> 00:21:36,210
complicated with partisan because all of

582
00:21:34,710 --> 00:21:38,279
a sudden you don't have this full mesh

583
00:21:36,210 --> 00:21:40,289
topology so which which actor migration

584
00:21:38,279 --> 00:21:42,960
if I wanted to my game I agreed an actor

585
00:21:40,289 --> 00:21:45,779
from one host to another yeah so I mean

586
00:21:42,960 --> 00:21:50,220
in Orleans so the Orleans solution there

587
00:21:45,779 --> 00:21:52,139
is you know to to kind of coordinate via

588
00:21:50,220 --> 00:21:54,929
cloud storage right so I say like I'm

589
00:21:52,139 --> 00:21:56,760
gonna terminate my actor on no day and

590
00:21:54,929 --> 00:21:58,139
I'll store the state and durable cloud

591
00:21:56,760 --> 00:22:00,419
storage that's addressable by anybody

592
00:21:58,139 --> 00:22:01,799
and then I can kind of rehydrate that

593
00:22:00,419 --> 00:22:02,940
actor on another node based on that

594
00:22:01,799 --> 00:22:04,379
cloud storage so I think that's the

595
00:22:02,940 --> 00:22:05,820
right model and I don't think that

596
00:22:04,380 --> 00:22:07,500
anything about our model would prohibit

597
00:22:05,820 --> 00:22:09,450
that model from working and I think

598
00:22:07,500 --> 00:22:10,860
that's a proven model that's been used

599
00:22:09,450 --> 00:22:12,539
on Halo and all this stuff we're

600
00:22:10,860 --> 00:22:14,010
actually doing this stuff at scale so I

601
00:22:12,539 --> 00:22:16,620
think that's the right model for

602
00:22:14,010 --> 00:22:18,990
migration Thank You Christopher

603
00:22:16,620 --> 00:22:21,050
Thanks

604
00:22:18,990 --> 00:22:21,050
you

