1
00:00:10,620 --> 00:00:18,369
so I'm Bradley Kuzma I did this work

2
00:00:14,799 --> 00:00:21,250
with Matteo frigo and Justin

3
00:00:18,369 --> 00:00:24,340
Missoula paluska and Sasha Sandler who

4
00:00:21,250 --> 00:00:26,948
who's here and there were a whole bunch

5
00:00:24,340 --> 00:00:29,259
of other people involved with this so

6
00:00:26,949 --> 00:00:30,369
these are just the four people who sort

7
00:00:29,260 --> 00:00:32,680
of were the first people on this

8
00:00:30,369 --> 00:00:34,840
particular project and what's a big a

9
00:00:32,680 --> 00:00:37,120
big project at Oracle is the the Oracle

10
00:00:34,840 --> 00:00:42,610
cloud infrastructure I'm going to talk

11
00:00:37,120 --> 00:00:44,919
about file service and so what is file

12
00:00:42,610 --> 00:00:46,989
storage service basically the game is is

13
00:00:44,920 --> 00:00:47,920
that Oracle's operating a cloud and so

14
00:00:46,989 --> 00:00:50,860
you know you could think of something

15
00:00:47,920 --> 00:00:52,930
like Amazon Web Services is they that's

16
00:00:50,860 --> 00:00:55,720
that's Amazon's Cloud Oracle also

17
00:00:52,930 --> 00:01:00,309
operates a cloud we're smaller but we

18
00:00:55,720 --> 00:01:02,680
try so the game is that you said we set

19
00:01:00,309 --> 00:01:04,720
up a file system for you and that file

20
00:01:02,680 --> 00:01:08,920
system shows up as an IP address in your

21
00:01:04,720 --> 00:01:11,500
virtual cloud network and behind that IP

22
00:01:08,920 --> 00:01:13,630
address is a network file server and we

23
00:01:11,500 --> 00:01:15,310
run the network file server and we Matt

24
00:01:13,630 --> 00:01:16,770
you know as you write data into it we

25
00:01:15,310 --> 00:01:19,290
make sure that there's enough storage

26
00:01:16,770 --> 00:01:21,550
and you don't have to manage the server

27
00:01:19,290 --> 00:01:22,960
you also be you know the game the

28
00:01:21,550 --> 00:01:24,759
business plan is also maybe you're

29
00:01:22,960 --> 00:01:25,899
renting NFS clients from us and maybe

30
00:01:24,760 --> 00:01:28,870
you're running a bunch of other software

31
00:01:25,900 --> 00:01:30,190
that we can make money on and you know

32
00:01:28,870 --> 00:01:34,150
cuz Oracle is all about making money

33
00:01:30,190 --> 00:01:35,770
right you pay for what you use so

34
00:01:34,150 --> 00:01:38,770
there's some price per gigabyte month

35
00:01:35,770 --> 00:01:40,539
and you start at zero and and and grow

36
00:01:38,770 --> 00:01:42,850
to be as big as you want we have a whole

37
00:01:40,540 --> 00:01:45,670
lot of file systems that are less than a

38
00:01:42,850 --> 00:01:47,350
megabyte and we have a bunch of them

39
00:01:45,670 --> 00:01:49,740
that are you know more than a petabytes

40
00:01:47,350 --> 00:01:53,530
so there's a big dynamic range in in

41
00:01:49,740 --> 00:01:56,830
filesystem size so we designed so here's

42
00:01:53,530 --> 00:01:58,600
the architecture and basically the

43
00:01:56,830 --> 00:02:00,220
picture here is the green things the NFS

44
00:01:58,600 --> 00:02:02,610
clients those are those would be your

45
00:02:00,220 --> 00:02:06,760
server that you were renting by the hour

46
00:02:02,610 --> 00:02:10,060
they talk to a presentation host and the

47
00:02:06,760 --> 00:02:11,440
presentation host speaks NFS this is

48
00:02:10,060 --> 00:02:13,390
architected so that maybe in the future

49
00:02:11,440 --> 00:02:16,170
we could do other other protocols

50
00:02:13,390 --> 00:02:18,640
besides NFS like the Windows protocol

51
00:02:16,170 --> 00:02:21,309
the presentation host is running a whole

52
00:02:18,640 --> 00:02:23,440
bunch of NFS processes that are actually

53
00:02:21,310 --> 00:02:23,980
doing the communication and they talk to

54
00:02:23,440 --> 00:02:25,959
your

55
00:02:23,980 --> 00:02:27,700
various clients and those clients are

56
00:02:25,959 --> 00:02:29,560
belonging to different customers in

57
00:02:27,700 --> 00:02:32,589
general so those IP addresses actually

58
00:02:29,560 --> 00:02:34,360
have are in you know only makes sense in

59
00:02:32,590 --> 00:02:37,030
the context of a network namespace on

60
00:02:34,360 --> 00:02:39,220
the backend sort of to the to the right

61
00:02:37,030 --> 00:02:40,569
are a bunch of storage hosts and these

62
00:02:39,220 --> 00:02:45,099
storage hosts have a bunch of disk

63
00:02:40,569 --> 00:02:47,410
drives in them well hard drives no nvme

64
00:02:45,099 --> 00:02:50,649
that's what they are so how much a whole

65
00:02:47,410 --> 00:02:53,170
bunch of storage and they run to two

66
00:02:50,650 --> 00:02:55,750
basic two services one is Daz d which is

67
00:02:53,170 --> 00:02:58,048
sort of IBM lingo for what a disk drive

68
00:02:55,750 --> 00:03:00,519
is direct access storage device and

69
00:02:58,049 --> 00:03:02,829
that's you know I'll talk a little bit

70
00:03:00,519 --> 00:03:05,019
about that dendron is the actually

71
00:03:02,829 --> 00:03:06,910
implements the file service so Daz D is

72
00:03:05,019 --> 00:03:09,160
sort of a distributed block device and

73
00:03:06,910 --> 00:03:11,950
dendron is the file service and mostly

74
00:03:09,160 --> 00:03:14,560
I'm gonna spend time sort of buried down

75
00:03:11,950 --> 00:03:16,450
in the DES D part I'm not going to talk

76
00:03:14,560 --> 00:03:19,840
very much about the NFS procedure

77
00:03:16,450 --> 00:03:24,940
process or really very much about

78
00:03:19,840 --> 00:03:27,849
dendron now if you were building a

79
00:03:24,940 --> 00:03:29,919
system to solve this problem the file

80
00:03:27,849 --> 00:03:32,048
service you could have you could imagine

81
00:03:29,919 --> 00:03:34,540
a simpler ideas like let's just go get a

82
00:03:32,049 --> 00:03:37,389
bunch of file servers and and we you

83
00:03:34,540 --> 00:03:40,929
know we can put nf-- we can put file sir

84
00:03:37,389 --> 00:03:43,660
files file systems on them and put NFS

85
00:03:40,930 --> 00:03:45,250
servers on them and pack a bunch of file

86
00:03:43,660 --> 00:03:47,560
systems our little so the server's kind

87
00:03:45,250 --> 00:03:51,130
of the blue box the file systems are the

88
00:03:47,560 --> 00:03:53,169
reddish circles and you can have a

89
00:03:51,130 --> 00:03:55,180
little file system like slash a and a

90
00:03:53,169 --> 00:03:56,530
medium-sized file system like slash D

91
00:03:55,180 --> 00:03:58,030
and you pack them in there and it's the

92
00:03:56,530 --> 00:04:00,160
file systems grow you have to figure out

93
00:03:58,030 --> 00:04:02,470
how you're gonna migrate file systems

94
00:04:00,160 --> 00:04:04,269
around and eventually get some big file

95
00:04:02,470 --> 00:04:05,769
system like the petabyte file systems

96
00:04:04,269 --> 00:04:08,470
that I mentioned that don't fit on a

97
00:04:05,769 --> 00:04:11,379
single server and somehow you have to to

98
00:04:08,470 --> 00:04:15,970
get those distributed across several

99
00:04:11,379 --> 00:04:17,680
storage servers so what's what's wrong

100
00:04:15,970 --> 00:04:19,478
with this sort of simpler idea because

101
00:04:17,680 --> 00:04:21,489
this is a simpler architecture than what

102
00:04:19,478 --> 00:04:23,889
we actually did so one of the problems

103
00:04:21,488 --> 00:04:25,299
is failover and replication you need to

104
00:04:23,889 --> 00:04:26,229
we you know this is supposed to be

105
00:04:25,300 --> 00:04:29,289
enterprise-grade

106
00:04:26,229 --> 00:04:32,680
file service so if a machine crashes we

107
00:04:29,289 --> 00:04:33,820
have to keep serving data you have to

108
00:04:32,680 --> 00:04:35,590
figure out how you're going to do the

109
00:04:33,820 --> 00:04:37,270
migration of these little file systems

110
00:04:35,590 --> 00:04:37,510
around and load-balanced it and how do

111
00:04:37,270 --> 00:04:39,400
you

112
00:04:37,510 --> 00:04:41,890
handle the big file systems and how do

113
00:04:39,400 --> 00:04:43,570
you know and and so we couldn't figure

114
00:04:41,890 --> 00:04:44,800
out how to use this simple architecture

115
00:04:43,570 --> 00:04:45,940
so we ended up doing the more

116
00:04:44,800 --> 00:04:51,490
complicated thing and the more

117
00:04:45,940 --> 00:04:53,050
complicated thing boils down to figuring

118
00:04:51,490 --> 00:04:58,000
out how to build a distributed data

119
00:04:53,050 --> 00:04:59,890
structure that crosses servers so here's

120
00:04:58,000 --> 00:05:01,900
you know I just made up this this isn't

121
00:04:59,890 --> 00:05:03,580
a particular data structure I've got the

122
00:05:01,900 --> 00:05:05,679
the servers are still blue and the data

123
00:05:03,580 --> 00:05:08,080
structure nodes are reddish and these

124
00:05:05,680 --> 00:05:10,480
these dark you know these purple nodes

125
00:05:08,080 --> 00:05:11,740
these purple edges are pointers within

126
00:05:10,480 --> 00:05:13,480
the data structure so maybe you have a

127
00:05:11,740 --> 00:05:16,330
little linked doubly linked list over

128
00:05:13,480 --> 00:05:17,890
here and a child of some node and so

129
00:05:16,330 --> 00:05:19,330
forth and I want to maintain some

130
00:05:17,890 --> 00:05:22,419
invariants on that kind of a data

131
00:05:19,330 --> 00:05:24,070
structure so the game is we're going to

132
00:05:22,420 --> 00:05:27,090
figure out how to solve this problem and

133
00:05:24,070 --> 00:05:31,120
then build a file system on top of it

134
00:05:27,090 --> 00:05:34,539
well let me do a digression about

135
00:05:31,120 --> 00:05:36,730
exactly what data structure we want what

136
00:05:34,540 --> 00:05:38,200
we want in principle is inodes because

137
00:05:36,730 --> 00:05:41,200
that's how you implement POSIX file

138
00:05:38,200 --> 00:05:43,090
systems so and I know it has it just

139
00:05:41,200 --> 00:05:44,289
this is review possibly for a lot of you

140
00:05:43,090 --> 00:05:46,810
but let me just sort of go through it

141
00:05:44,290 --> 00:05:49,600
anyway each file or directory or their

142
00:05:46,810 --> 00:05:51,190
file system object is represented by a

143
00:05:49,600 --> 00:05:51,760
numbered node so here I've got four I

144
00:05:51,190 --> 00:05:54,400
nodes

145
00:05:51,760 --> 00:05:58,480
I know zero I know 90 and I know number

146
00:05:54,400 --> 00:05:59,859
42 and and they have permission bits in

147
00:05:58,480 --> 00:06:01,810
them so the first one is the directory

148
00:05:59,860 --> 00:06:03,730
you can tell because it's drw X I don't

149
00:06:01,810 --> 00:06:05,110
know if you can see that the second

150
00:06:03,730 --> 00:06:07,030
one's also a directory and the third one

151
00:06:05,110 --> 00:06:08,560
is a file it doesn't have a D and this

152
00:06:07,030 --> 00:06:11,289
is the little piece of the filesystem

153
00:06:08,560 --> 00:06:16,020
that's representing a file named / u

154
00:06:11,290 --> 00:06:18,250
slash Fuu dot txt so the directory here

155
00:06:16,020 --> 00:06:21,640
this this is the root directory its

156
00:06:18,250 --> 00:06:23,610
inode number 0 by convention and it has

157
00:06:21,640 --> 00:06:27,640
a little directory here that Maps you to

158
00:06:23,610 --> 00:06:29,020
an inode and then this is you know that

159
00:06:27,640 --> 00:06:30,880
directory and it has a directory that

160
00:06:29,020 --> 00:06:33,549
Maps food to this inode and then this

161
00:06:30,880 --> 00:06:36,219
inode which is a regular file has a

162
00:06:33,550 --> 00:06:40,240
block map in it that that Maps offsets

163
00:06:36,220 --> 00:06:42,490
to block identifiers the data stored in

164
00:06:40,240 --> 00:06:44,710
the blocks so that's what I nodes are

165
00:06:42,490 --> 00:06:47,620
and that's in principle what we want to

166
00:06:44,710 --> 00:06:50,620
implement and you could imagine going

167
00:06:47,620 --> 00:06:52,330
ahead and directly implementing this

168
00:06:50,620 --> 00:06:55,060
data structure as the distributed data

169
00:06:52,330 --> 00:06:56,889
structure and some some vendors I think

170
00:06:55,060 --> 00:06:59,560
that's actually what they do but we did

171
00:06:56,889 --> 00:07:02,650
not we said well we want to abstract

172
00:06:59,560 --> 00:07:04,780
this a little bit and make it easier or

173
00:07:02,650 --> 00:07:06,638
harder or something so instead of

174
00:07:04,780 --> 00:07:08,590
implementing the inodes directly we

175
00:07:06,639 --> 00:07:11,800
think of these AI nodes as tabular data

176
00:07:08,590 --> 00:07:14,320
and we code up the I nodes as data so

177
00:07:11,800 --> 00:07:15,699
this is the same the same sub same

178
00:07:14,320 --> 00:07:17,260
little directory structure and it's

179
00:07:15,699 --> 00:07:19,720
represented by three tables there's an

180
00:07:17,260 --> 00:07:21,159
inode table which and all these tables

181
00:07:19,720 --> 00:07:23,949
are like key value tables who there's

182
00:07:21,160 --> 00:07:26,770
the left column which is a key the right

183
00:07:23,949 --> 00:07:28,720
column is the data so the inode table

184
00:07:26,770 --> 00:07:31,260
has inode number zero and some

185
00:07:28,720 --> 00:07:31,260
information

186
00:07:31,690 --> 00:07:35,590
inode number 42 and I don't number 90 so

187
00:07:34,210 --> 00:07:37,120
that's those are the I nodes and then

188
00:07:35,590 --> 00:07:39,789
below that I've shown the directory

189
00:07:37,120 --> 00:07:43,000
table which basically said the keys are

190
00:07:39,789 --> 00:07:48,460
pairs which are inode numbers and file

191
00:07:43,000 --> 00:07:51,160
names so if at I know number 0 U is that

192
00:07:48,460 --> 00:07:54,190
maps to inode number 90 that inode

193
00:07:51,160 --> 00:07:56,740
number 90 food tex mex to 42 and there's

194
00:07:54,190 --> 00:07:59,139
a block table that tells us for each

195
00:07:56,740 --> 00:08:02,979
inode and which for each offset what the

196
00:07:59,139 --> 00:08:08,500
block is so that's how we represent i

197
00:08:02,979 --> 00:08:10,060
nodes as tabular data now we well it's

198
00:08:08,500 --> 00:08:12,460
key value data so we stick them into a

199
00:08:10,060 --> 00:08:14,470
search tree and so the thing that we

200
00:08:12,460 --> 00:08:15,909
spend our a lot of time on this is the

201
00:08:14,470 --> 00:08:18,010
distributed data structure that we spent

202
00:08:15,910 --> 00:08:20,020
effort on making correct is to make a

203
00:08:18,010 --> 00:08:22,810
distributed me tree and a bee tree is

204
00:08:20,020 --> 00:08:25,930
just a search tree it's got a wide fan

205
00:08:22,810 --> 00:08:29,169
out so that you can exploit the fact

206
00:08:25,930 --> 00:08:31,030
that you know iOS are expensive and this

207
00:08:29,169 --> 00:08:33,039
is in this B tree all the data is stored

208
00:08:31,030 --> 00:08:34,838
at the leaves so technically it's a B+

209
00:08:33,039 --> 00:08:35,890
tree but I I think it's kind of

210
00:08:34,839 --> 00:08:38,620
pointless to talk about all the

211
00:08:35,890 --> 00:08:39,838
distinctions between B+ and B star and

212
00:08:38,620 --> 00:08:43,029
all those trees they all have the same

213
00:08:39,839 --> 00:08:44,650
asymptotic performance so we just use

214
00:08:43,029 --> 00:08:47,380
the one that everyone uses which is B

215
00:08:44,650 --> 00:08:49,959
plus trees this one also has a doubly

216
00:08:47,380 --> 00:08:51,820
linked list of among all the leaves so

217
00:08:49,959 --> 00:08:53,319
you could you can traverse the leaves

218
00:08:51,820 --> 00:08:55,500
from left to right if you want to as

219
00:08:53,320 --> 00:08:55,500
well

220
00:08:56,700 --> 00:09:02,800
so that is the sort of a quick picture

221
00:09:01,000 --> 00:09:06,310
of the bee tree that we implemented and

222
00:09:02,800 --> 00:09:10,680
these purple pointers could generally

223
00:09:06,310 --> 00:09:10,680
cross from one machine to another

224
00:09:11,730 --> 00:09:16,300
there's only one bee tree all the file

225
00:09:14,650 --> 00:09:18,850
systems are stored in that bee tree so

226
00:09:16,300 --> 00:09:20,740
some some file systems are little and

227
00:09:18,850 --> 00:09:22,360
they just use fewer key value ter pairs

228
00:09:20,740 --> 00:09:25,840
and some file systems are big and use a

229
00:09:22,360 --> 00:09:28,630
lot of key value pairs even the small

230
00:09:25,840 --> 00:09:31,170
systems end up spread across multiple

231
00:09:28,630 --> 00:09:31,170
servers

232
00:09:31,530 --> 00:09:36,069
well updating a bee tree requires atomic

233
00:09:34,450 --> 00:09:38,080
operations across servers so here's a

234
00:09:36,070 --> 00:09:41,040
little example of a kind of a typical

235
00:09:38,080 --> 00:09:44,560
bee tree operation I want to split this

236
00:09:41,040 --> 00:09:46,420
I've got this bee tree it's got it's got

237
00:09:44,560 --> 00:09:48,250
this node here which is a little bit too

238
00:09:46,420 --> 00:09:50,260
full and I want to split it to even it

239
00:09:48,250 --> 00:09:52,120
out so what I want to do is I want to

240
00:09:50,260 --> 00:09:54,250
allocate a new node which is sitting

241
00:09:52,120 --> 00:09:55,840
here in the free list and I want to put

242
00:09:54,250 --> 00:09:58,060
some of the data from here into here and

243
00:09:55,840 --> 00:09:59,800
I got to update all the all the pointers

244
00:09:58,060 --> 00:10:02,020
so here's the new free list it skips

245
00:09:59,800 --> 00:10:04,300
that the doubly linked list connecting

246
00:10:02,020 --> 00:10:06,850
everything together is there I've had to

247
00:10:04,300 --> 00:10:09,490
update the parent and the way I want to

248
00:10:06,850 --> 00:10:12,670
get this implemented is I want all those

249
00:10:09,490 --> 00:10:14,050
changes to be done atomically I don't

250
00:10:12,670 --> 00:10:16,050
want to be in a situation where if

251
00:10:14,050 --> 00:10:18,400
something fails in the middle that I

252
00:10:16,050 --> 00:10:20,050
I've got I've taken something out of the

253
00:10:18,400 --> 00:10:21,610
free list and dropped it on the floor or

254
00:10:20,050 --> 00:10:23,050
I've got it in the free list and it's in

255
00:10:21,610 --> 00:10:25,030
the bee tree or you know any of those

256
00:10:23,050 --> 00:10:28,870
kinds of failures don't want to have

257
00:10:25,030 --> 00:10:30,310
that happen so the rest of this talk is

258
00:10:28,870 --> 00:10:32,080
basically about how we went about

259
00:10:30,310 --> 00:10:39,250
solving the problem of implementing this

260
00:10:32,080 --> 00:10:42,670
kind of atomic operation well the

261
00:10:39,250 --> 00:10:46,150
classic solution is to use two-phase

262
00:10:42,670 --> 00:10:47,620
commit and basically the game with

263
00:10:46,150 --> 00:10:49,360
two-phase commit is you have a bunch of

264
00:10:47,620 --> 00:10:51,580
participants who want who are the

265
00:10:49,360 --> 00:10:52,980
different servers and they want to do

266
00:10:51,580 --> 00:10:55,990
some transaction

267
00:10:52,980 --> 00:10:57,310
each participant records enough

268
00:10:55,990 --> 00:10:59,110
information that they can roll the

269
00:10:57,310 --> 00:11:00,760
transaction forward or backward and they

270
00:10:59,110 --> 00:11:04,270
get ready to go and then there's a

271
00:11:00,760 --> 00:11:06,310
designated coordinator that decides to

272
00:11:04,270 --> 00:11:07,990
commit the transaction the coordinator

273
00:11:06,310 --> 00:11:09,439
notifies everybody whether to go forward

274
00:11:07,990 --> 00:11:11,480
or backwards and

275
00:11:09,440 --> 00:11:13,040
what happens and if if one of the

276
00:11:11,480 --> 00:11:16,250
participants misses that notification

277
00:11:13,040 --> 00:11:17,540
they have to ask later what happened so

278
00:11:16,250 --> 00:11:18,490
that they know whether to roll forward

279
00:11:17,540 --> 00:11:22,819
or backward

280
00:11:18,490 --> 00:11:24,200
so that's two-phase commit and it's kind

281
00:11:22,820 --> 00:11:25,580
of the way you make a distributed data

282
00:11:24,200 --> 00:11:26,000
structure the problem with two-phase

283
00:11:25,580 --> 00:11:28,220
commit

284
00:11:26,000 --> 00:11:30,980
happens this is what happens if the

285
00:11:28,220 --> 00:11:32,570
coordinator is running you get

286
00:11:30,980 --> 00:11:36,530
everything ready to go and your about to

287
00:11:32,570 --> 00:11:37,640
commit and the coordinator crashes may

288
00:11:36,530 --> 00:11:39,920
be the coordinator doesn't come back

289
00:11:37,640 --> 00:11:43,850
because it's it's it's had a hard drive

290
00:11:39,920 --> 00:11:44,479
failure or something or maybe the crash

291
00:11:43,850 --> 00:11:45,890
happened

292
00:11:44,480 --> 00:11:47,540
maybe the crash happened before the

293
00:11:45,890 --> 00:11:49,670
commit or maybe the crash happened after

294
00:11:47,540 --> 00:11:51,439
the commit at any time the coordinator

295
00:11:49,670 --> 00:11:53,630
could come back so you can't kind of

296
00:11:51,440 --> 00:11:55,070
decide without asking the coordinator

297
00:11:53,630 --> 00:11:56,689
what happened so the clients don't know

298
00:11:55,070 --> 00:11:58,940
what's going on and they get stuck for

299
00:11:56,690 --> 00:12:06,640
as long as it takes for the coordinator

300
00:11:58,940 --> 00:12:09,500
to come back which could be forever well

301
00:12:06,640 --> 00:12:12,560
the solution to this problem is Paxos

302
00:12:09,500 --> 00:12:14,750
paxos doesn't get stuck I'm not going to

303
00:12:12,560 --> 00:12:17,329
explain it in a lot of detail but Paxos

304
00:12:14,750 --> 00:12:19,040
lets you come to a consensus on a single

305
00:12:17,330 --> 00:12:21,770
value multipacks let's let's you make a

306
00:12:19,040 --> 00:12:24,170
log once you've got a log you can make a

307
00:12:21,770 --> 00:12:25,970
state machine because you basically have

308
00:12:24,170 --> 00:12:28,010
some state memory and you just apply log

309
00:12:25,970 --> 00:12:29,600
entries to it think of the log as

310
00:12:28,010 --> 00:12:34,310
commands that happen on the state like

311
00:12:29,600 --> 00:12:36,080
insert something into a tree maybe Paxos

312
00:12:34,310 --> 00:12:38,719
handles the cases where messages get

313
00:12:36,080 --> 00:12:39,920
lost or duplicated or machines crash and

314
00:12:38,720 --> 00:12:43,100
come back and as long as you have a

315
00:12:39,920 --> 00:12:44,420
majority of the machines eventually

316
00:12:43,100 --> 00:12:51,830
coming back the system keeps making

317
00:12:44,420 --> 00:12:55,400
progress so file service uses Paxos to

318
00:12:51,830 --> 00:12:57,200
implement two-phase commit and so each

319
00:12:55,400 --> 00:13:01,160
participant in the two-phase commit is a

320
00:12:57,200 --> 00:13:02,839
replicated state machine and it solves

321
00:13:01,160 --> 00:13:04,640
the problem that two-phase commit has is

322
00:13:02,839 --> 00:13:07,010
if the coordinator dies and doesn't come

323
00:13:04,640 --> 00:13:08,960
back you get stuck well the coordinator

324
00:13:07,010 --> 00:13:12,410
doesn't die because it's a replicated

325
00:13:08,960 --> 00:13:15,230
non stop state machine each of these

326
00:13:12,410 --> 00:13:17,680
replicated participants we call an

327
00:13:15,230 --> 00:13:17,680
extent

328
00:13:19,050 --> 00:13:25,390
so how big is an extent well an extent

329
00:13:23,470 --> 00:13:27,370
has to fit into a single server so it

330
00:13:25,390 --> 00:13:30,189
can't be you can't like make one extent

331
00:13:27,370 --> 00:13:31,870
that holds everything because this this

332
00:13:30,190 --> 00:13:34,870
pack so state machine has to fit in one

333
00:13:31,870 --> 00:13:36,160
server there's a lot of overhead for the

334
00:13:34,870 --> 00:13:38,950
state machine because this is

335
00:13:36,160 --> 00:13:40,839
implementing two-phase commit so we

336
00:13:38,950 --> 00:13:42,460
don't want the extent to be too small we

337
00:13:40,840 --> 00:13:44,230
don't want to have a whole extent for

338
00:13:42,460 --> 00:13:47,200
every node in the B tree that would be

339
00:13:44,230 --> 00:13:48,730
too much overhead so we sized the extent

340
00:13:47,200 --> 00:13:50,770
so that several hundreds of them fit on

341
00:13:48,730 --> 00:13:53,260
a server so maybe maybe it's a gigabyte

342
00:13:50,770 --> 00:13:55,600
or maybe a hundred gigabytes of space or

343
00:13:53,260 --> 00:13:58,270
something like that the extent state

344
00:13:55,600 --> 00:13:59,800
machine is a few megabytes so there's

345
00:13:58,270 --> 00:14:01,120
this interesting distinction in our in

346
00:13:59,800 --> 00:14:02,859
the way we've implemented this is

347
00:14:01,120 --> 00:14:05,350
there's the state machine and there's

348
00:14:02,860 --> 00:14:07,960
the gigabytes of pages that the state

349
00:14:05,350 --> 00:14:09,760
machine manages these extents are small

350
00:14:07,960 --> 00:14:11,650
enough that we can move them around for

351
00:14:09,760 --> 00:14:13,569
load balancing or to exploit parallelism

352
00:14:11,650 --> 00:14:16,000
machine crashes and we have to make a

353
00:14:13,570 --> 00:14:18,580
new replica we don't have to we can

354
00:14:16,000 --> 00:14:21,070
spread out the work of rear up locating

355
00:14:18,580 --> 00:14:24,490
the data to make failure recovery faster

356
00:14:21,070 --> 00:14:32,590
and we use five Way five Way replication

357
00:14:24,490 --> 00:14:34,000
for these extents so we programmed so so

358
00:14:32,590 --> 00:14:35,860
now I'm going to sort of switch to so

359
00:14:34,000 --> 00:14:37,810
how to sort of the programming model of

360
00:14:35,860 --> 00:14:40,060
how we implement this once we've got

361
00:14:37,810 --> 00:14:42,189
this two phase commit implemented what's

362
00:14:40,060 --> 00:14:45,099
the abstraction that I get to use as the

363
00:14:42,190 --> 00:14:47,500
B tree implementer or as the user on top

364
00:14:45,100 --> 00:14:49,570
of the B tree to program it and it's a

365
00:14:47,500 --> 00:14:51,580
kind of an optimistic concurrency style

366
00:14:49,570 --> 00:14:53,320
way of programming we we have an

367
00:14:51,580 --> 00:14:56,350
operation that we call multi-page store

368
00:14:53,320 --> 00:14:59,160
conditional it's very similar to some of

369
00:14:56,350 --> 00:15:01,600
the the processor primitives like

370
00:14:59,160 --> 00:15:03,400
load-linked store conditional except it

371
00:15:01,600 --> 00:15:04,780
operates on several pages at a time so

372
00:15:03,400 --> 00:15:06,640
you can the game is you get to read up

373
00:15:04,780 --> 00:15:08,770
to 15 pages you want to read fewer

374
00:15:06,640 --> 00:15:11,170
because fewer smaller transactions are

375
00:15:08,770 --> 00:15:14,410
less likely to to conflict or have other

376
00:15:11,170 --> 00:15:15,969
problems but you could read up to 15

377
00:15:14,410 --> 00:15:17,530
pages and for each page that you read

378
00:15:15,970 --> 00:15:19,450
you get a version tag which tells you

379
00:15:17,530 --> 00:15:22,270
how many times the page has been

380
00:15:19,450 --> 00:15:23,620
modified you compute new values for the

381
00:15:22,270 --> 00:15:25,449
pages and then you present the new

382
00:15:23,620 --> 00:15:29,020
values along with those version tags to

383
00:15:25,450 --> 00:15:31,270
the MPSC operation and either it writes

384
00:15:29,020 --> 00:15:32,710
them all atomically and only and that

385
00:15:31,270 --> 00:15:32,980
can only happen if the pages haven't

386
00:15:32,710 --> 00:15:35,019
been

387
00:15:32,980 --> 00:15:39,010
if I or if anything goes wrong it

388
00:15:35,019 --> 00:15:40,870
doesn't write anything so this is and so

389
00:15:39,010 --> 00:15:42,399
you say well let me try to change the

390
00:15:40,870 --> 00:15:44,290
bee tree in this way and you try any

391
00:15:42,399 --> 00:15:47,110
that the transaction succeeds or it

392
00:15:44,290 --> 00:15:49,000
fails and maybe you try again these

393
00:15:47,110 --> 00:15:50,680
operations are linearizable which means

394
00:15:49,000 --> 00:15:53,260
that they they can be viewed as having

395
00:15:50,680 --> 00:15:55,329
occurred in a total order and that total

396
00:15:53,260 --> 00:15:58,750
order is consistent with the real time

397
00:15:55,329 --> 00:16:00,519
that the transaction happened in it's a

398
00:15:58,750 --> 00:16:02,740
limited transaction so it's not too big

399
00:16:00,519 --> 00:16:05,110
because there's only fifteen pages which

400
00:16:02,740 --> 00:16:06,190
means we can statically allocated and

401
00:16:05,110 --> 00:16:07,930
everything we don't have to deal with

402
00:16:06,190 --> 00:16:09,220
the problems that databases have to deal

403
00:16:07,930 --> 00:16:11,709
with where you maybe have a transaction

404
00:16:09,220 --> 00:16:13,630
on many gigabytes of data we don't get

405
00:16:11,709 --> 00:16:16,329
to do that but it's not too small

406
00:16:13,630 --> 00:16:18,010
it would be hard to make a b-tree if I

407
00:16:16,329 --> 00:16:19,779
could only modify one or two pages at a

408
00:16:18,010 --> 00:16:22,329
time I need need to be able to modify

409
00:16:19,779 --> 00:16:23,709
several pages at a time at least if I

410
00:16:22,329 --> 00:16:26,439
want to have it to be easy to program

411
00:16:23,709 --> 00:16:28,599
and there's no locks at this level and

412
00:16:26,440 --> 00:16:30,490
above if you acquire a lock and you

413
00:16:28,600 --> 00:16:32,589
crash the system would get stuck because

414
00:16:30,490 --> 00:16:33,910
you've got this lock so the way we

415
00:16:32,589 --> 00:16:36,190
program here is you don't acquire the

416
00:16:33,910 --> 00:16:38,920
lock you you you read some data you try

417
00:16:36,190 --> 00:16:41,079
to write the new data out and if you

418
00:16:38,920 --> 00:16:43,389
crash anywhere along the way well your

419
00:16:41,079 --> 00:16:51,250
transaction abort sort succeeds

420
00:16:43,389 --> 00:16:52,690
either way it's okay so the so I'll talk

421
00:16:51,250 --> 00:16:54,670
briefly about performance there's a

422
00:16:52,690 --> 00:16:56,410
simple throughput model which is if each

423
00:16:54,670 --> 00:16:58,660
server is bringing a network interface

424
00:16:56,410 --> 00:17:01,240
it's got so many gigabits per second of

425
00:16:58,660 --> 00:17:02,769
network bandwidth when we write data we

426
00:17:01,240 --> 00:17:05,500
have to write it five times into five

427
00:17:02,769 --> 00:17:08,230
places so the simple model is that you

428
00:17:05,500 --> 00:17:10,540
take the the performance of all the

429
00:17:08,230 --> 00:17:12,130
network interfaces in your fleet and

430
00:17:10,540 --> 00:17:13,770
divide by five and that you cannot

431
00:17:12,130 --> 00:17:16,240
exceed that speed for write performance

432
00:17:13,770 --> 00:17:18,879
that's that's the Dow shalt not exceed

433
00:17:16,240 --> 00:17:20,380
the speed queuing theory says you really

434
00:17:18,880 --> 00:17:21,910
can't run at a hundred percent so

435
00:17:20,380 --> 00:17:24,069
queuing theory might suggest you could

436
00:17:21,910 --> 00:17:26,439
run at 70 percent without having the

437
00:17:24,069 --> 00:17:28,178
latency go up we don't do that well we

438
00:17:26,439 --> 00:17:31,480
managed to run it about one third of

439
00:17:28,179 --> 00:17:33,790
peak and you know and have the system do

440
00:17:31,480 --> 00:17:35,740
well so the simple model is that you

441
00:17:33,790 --> 00:17:37,030
take the bandwidth divided by fifteen

442
00:17:35,740 --> 00:17:38,380
because there's a factor of five for the

443
00:17:37,030 --> 00:17:41,260
right bandwidth and a factor of three

444
00:17:38,380 --> 00:17:44,290
for sort of queuing theory overhead and

445
00:17:41,260 --> 00:17:46,780
that's the total bandwidth that the

446
00:17:44,290 --> 00:17:48,399
fleet can offer to customers and

447
00:17:46,780 --> 00:17:50,170
surprisingly there's very simple

448
00:17:48,400 --> 00:17:52,000
programming models just seems to work

449
00:17:50,170 --> 00:17:54,100
for almost all workloads that are

450
00:17:52,000 --> 00:17:57,460
throughput oriented and I'm not gonna

451
00:17:54,100 --> 00:17:58,600
have time here to talk about latency but

452
00:17:57,460 --> 00:18:00,520
there is a sort of interesting curve

453
00:17:58,600 --> 00:18:03,129
that I came up with which is I plotted I

454
00:18:00,520 --> 00:18:05,200
have a bunch of NFS clients on some

455
00:18:03,130 --> 00:18:07,690
particular fleet the papers got details

456
00:18:05,200 --> 00:18:09,130
about it and so the x-axis is the number

457
00:18:07,690 --> 00:18:12,640
of clients pushing as hard as they can

458
00:18:09,130 --> 00:18:16,660
writing data in the y-axis is is is the

459
00:18:12,640 --> 00:18:18,370
bandwidth that we're getting and there's

460
00:18:16,660 --> 00:18:20,350
two curves one is for data where you're

461
00:18:18,370 --> 00:18:21,639
overwriting blocks and the other is

462
00:18:20,350 --> 00:18:22,959
whether you're having to allocate the

463
00:18:21,640 --> 00:18:24,880
blocks while you write it so the blue

464
00:18:22,960 --> 00:18:26,530
one is is the one we have to allocate

465
00:18:24,880 --> 00:18:27,880
and there's and this looks like a

466
00:18:26,530 --> 00:18:30,100
speed-up curve for a multiprocessor

467
00:18:27,880 --> 00:18:31,330
system right these feed up curves always

468
00:18:30,100 --> 00:18:33,550
have this property where things kind of

469
00:18:31,330 --> 00:18:34,960
speed up until you you run out of run

470
00:18:33,550 --> 00:18:36,909
out of parallelism or something and then

471
00:18:34,960 --> 00:18:39,120
they flatten out and so I did a curve

472
00:18:36,910 --> 00:18:43,210
fit and the speed-up curve says that

473
00:18:39,120 --> 00:18:46,479
this this fleet can write 3.3 gigabytes

474
00:18:43,210 --> 00:18:49,900
per second and that black dotted line is

475
00:18:46,480 --> 00:18:53,200
the curve and and the curve is actually

476
00:18:49,900 --> 00:18:54,670
sort of the the harmonic mean of the the

477
00:18:53,200 --> 00:18:56,620
part where you get linear speed-up until

478
00:18:54,670 --> 00:18:58,510
you run out of parallelism and then then

479
00:18:56,620 --> 00:19:00,760
you limited by the fleet performance and

480
00:18:58,510 --> 00:19:03,010
so I I kind of like it whenever

481
00:19:00,760 --> 00:19:04,990
something turns out to sort of this is

482
00:19:03,010 --> 00:19:06,730
like you know reminds me of the days of

483
00:19:04,990 --> 00:19:08,260
yore when I worked in supercomputing and

484
00:19:06,730 --> 00:19:09,550
you always got this curve right you

485
00:19:08,260 --> 00:19:12,430
always get this curve when you do

486
00:19:09,550 --> 00:19:15,700
parallel computing and the data points

487
00:19:12,430 --> 00:19:20,560
just are amazingly tightly fit to that

488
00:19:15,700 --> 00:19:24,280
that curve so that is the Oracle Files

489
00:19:20,560 --> 00:19:28,659
service we are in fact hiring both

490
00:19:24,280 --> 00:19:30,280
students and and engineers so if you're

491
00:19:28,660 --> 00:19:32,050
interested in working on this kind of

492
00:19:30,280 --> 00:19:33,399
problem you can come talk to me there's

493
00:19:32,050 --> 00:19:35,590
a lot of interesting problems in the

494
00:19:33,400 --> 00:19:36,910
cloud this is the scale the scales are

495
00:19:35,590 --> 00:19:38,649
it's one of the few places where you get

496
00:19:36,910 --> 00:19:40,000
to sort of do the things that we used to

497
00:19:38,650 --> 00:19:42,820
worry about for high-performance

498
00:19:40,000 --> 00:19:45,280
computing where we worried about hyper

499
00:19:42,820 --> 00:19:46,750
scalability it's one of the it's a

500
00:19:45,280 --> 00:19:48,280
commercially important place where that

501
00:19:46,750 --> 00:19:50,350
kind of hyper scalability actually

502
00:19:48,280 --> 00:19:51,790
matters and there's interesting problems

503
00:19:50,350 --> 00:19:53,800
there so it's kind of surprising that at

504
00:19:51,790 --> 00:19:55,980
a place like Oracle you get to do this

505
00:19:53,800 --> 00:20:00,870
kind of research

506
00:19:55,980 --> 00:20:00,870
thank you any questions

507
00:20:07,160 --> 00:20:12,070
here he's gonna make the trip to the

508
00:20:09,590 --> 00:20:12,070
microphone

509
00:20:13,120 --> 00:20:22,219
Jeff canning Harvey go to college I seem

510
00:20:16,850 --> 00:20:25,040
to recall that the number 15 was

511
00:20:22,220 --> 00:20:27,050
motivated by you had a transaction

512
00:20:25,040 --> 00:20:29,240
situation that required that number it's

513
00:20:27,050 --> 00:20:30,980
not just an arbitrary number yeah so the

514
00:20:29,240 --> 00:20:34,340
biggest transaction I needed for one

515
00:20:30,980 --> 00:20:37,400
case in the B tree was 15 and I hardly

516
00:20:34,340 --> 00:20:40,520
ever runs but if you Mateo wanted it to

517
00:20:37,400 --> 00:20:44,030
be 8 or 7 or 5 or something but or 3

518
00:20:40,520 --> 00:20:45,710
yeah but we only have to pay the cost of

519
00:20:44,030 --> 00:20:47,540
in terms of transaction conflicts when

520
00:20:45,710 --> 00:20:49,370
we actually use the large transactions

521
00:20:47,540 --> 00:20:52,790
so as long as most of them are small

522
00:20:49,370 --> 00:20:54,530
we're happy how painful would it be if

523
00:20:52,790 --> 00:20:56,840
you ever discovered a situation where

524
00:20:54,530 --> 00:21:01,960
you needed 17 well we'd have to

525
00:20:56,840 --> 00:21:01,959
recompile code okay so it's easy

526
00:21:02,410 --> 00:21:05,990
business crashing what you do is one

527
00:21:04,580 --> 00:21:09,409
victory at the beginning you showed

528
00:21:05,990 --> 00:21:11,660
three tables one for blocks assigned to

529
00:21:09,410 --> 00:21:13,280
two files and other I notes and other

530
00:21:11,660 --> 00:21:13,930
directories so how do you do the

531
00:21:13,280 --> 00:21:16,160
higher-level

532
00:21:13,930 --> 00:21:19,910
transaction to keep the file system

533
00:21:16,160 --> 00:21:21,980
consistent so we can do transactions on

534
00:21:19,910 --> 00:21:24,680
pages and it turns out that you feel

535
00:21:21,980 --> 00:21:26,210
free to unplug that you can we so we do

536
00:21:24,680 --> 00:21:27,620
fight you know the the the system I

537
00:21:26,210 --> 00:21:29,480
described talked about transactions on

538
00:21:27,620 --> 00:21:32,179
pages the B tree gives us transactions

539
00:21:29,480 --> 00:21:35,030
on key value pairs each key value pair

540
00:21:32,180 --> 00:21:37,250
you modify or read touches one page in

541
00:21:35,030 --> 00:21:39,020
the B tree so you're updating three B

542
00:21:37,250 --> 00:21:40,370
trees potentially correct well as

543
00:21:39,020 --> 00:21:42,830
there's one be treated as those three

544
00:21:40,370 --> 00:21:45,439
tables are put into I didn't I didn't

545
00:21:42,830 --> 00:21:47,090
tell you the detailed schema but you can

546
00:21:45,440 --> 00:21:48,740
sort of imagine a prefix on the table

547
00:21:47,090 --> 00:21:51,230
that says which table number it is and

548
00:21:48,740 --> 00:21:52,460
then put it into one tree or you could

549
00:21:51,230 --> 00:21:54,080
even mix them a little bit differently

550
00:21:52,460 --> 00:21:55,700
where you have another prefix to that

551
00:21:54,080 --> 00:21:57,290
which is which customer it is so that

552
00:21:55,700 --> 00:21:59,810
you have a different table for each

553
00:21:57,290 --> 00:22:03,610
customer so there's lots of tables lots

554
00:21:59,810 --> 00:22:07,820
of tables but there's only one B tree

555
00:22:03,610 --> 00:22:09,879
okay let's thank our speaker again

556
00:22:07,820 --> 00:22:09,879
you

