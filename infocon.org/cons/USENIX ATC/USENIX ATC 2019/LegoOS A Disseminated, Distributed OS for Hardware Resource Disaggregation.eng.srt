1
00:00:10,490 --> 00:00:14,809
hello everyone I mean John and today

2
00:00:13,040 --> 00:00:17,990
I'll be talking about a system that may

3
00:00:14,809 --> 00:00:22,040
raise some trademark issue for me called

4
00:00:17,990 --> 00:00:23,869
Lego s so a few years ago I started to

5
00:00:22,040 --> 00:00:26,390
look into an idea called hardware

6
00:00:23,869 --> 00:00:29,210
resource aggregation and yet the idea is

7
00:00:26,390 --> 00:00:31,160
quite simple so in a datacenter instead

8
00:00:29,210 --> 00:00:34,550
of having servers and having a metapod

9
00:00:31,160 --> 00:00:36,739
that hosts a bunch of devices how about

10
00:00:34,550 --> 00:00:40,610
we just separate these devices into

11
00:00:36,739 --> 00:00:42,379
independent network attached devices so

12
00:00:40,610 --> 00:00:45,079
this is called hardware resources of

13
00:00:42,380 --> 00:00:48,129
Education now for the natural question

14
00:00:45,079 --> 00:00:50,899
is why should we do something like this

15
00:00:48,129 --> 00:00:52,940
so if you look at applications that we

16
00:00:50,899 --> 00:00:54,800
are running in data centers they're

17
00:00:52,940 --> 00:00:57,678
essentially already distributed and

18
00:00:54,800 --> 00:01:00,078
functionally disaggregated so what

19
00:00:57,679 --> 00:01:01,909
clothes like data analytics machine

20
00:01:00,079 --> 00:01:04,269
learning they essentially are running in

21
00:01:01,909 --> 00:01:06,550
a distributed way but more than that

22
00:01:04,269 --> 00:01:08,900
functions are in English the

23
00:01:06,550 --> 00:01:11,539
applications are becoming more and more

24
00:01:08,900 --> 00:01:14,450
fine-grained with trancelike so less

25
00:01:11,540 --> 00:01:16,759
computing and micro services so the

26
00:01:14,450 --> 00:01:19,159
current practice is to run a distributed

27
00:01:16,759 --> 00:01:21,890
system on top of a monolithic linux

28
00:01:19,159 --> 00:01:23,990
server and then to group these different

29
00:01:21,890 --> 00:01:27,049
server server functions into different

30
00:01:23,990 --> 00:01:29,000
function pools but the problem is

31
00:01:27,049 --> 00:01:32,000
there's an overhead of having a

32
00:01:29,000 --> 00:01:34,189
distributed system interaction layer and

33
00:01:32,000 --> 00:01:36,350
also there's only so much you can do to

34
00:01:34,189 --> 00:01:39,979
customize a monolithic server and

35
00:01:36,350 --> 00:01:42,469
monolithic Linux so what about the

36
00:01:39,979 --> 00:01:45,170
layers below distributed systems so

37
00:01:42,469 --> 00:01:45,890
these are oh s and hardware so these

38
00:01:45,170 --> 00:01:48,079
layers

39
00:01:45,890 --> 00:01:50,659
unfortunately for decades they have been

40
00:01:48,079 --> 00:01:53,929
built with the assumption that every

41
00:01:50,659 --> 00:01:55,549
application is essentially local but if

42
00:01:53,930 --> 00:01:57,950
you look at applications in data centers

43
00:01:55,549 --> 00:02:00,200
now they are distributed so are we

44
00:01:57,950 --> 00:02:03,170
actually have your wrong assumption for

45
00:02:00,200 --> 00:02:05,270
these lower level systems so what we

46
00:02:03,170 --> 00:02:07,630
believe we should do is to have a clean

47
00:02:05,270 --> 00:02:10,728
slate design for these low level systems

48
00:02:07,630 --> 00:02:13,220
what I mean by that is to have built-in

49
00:02:10,729 --> 00:02:15,260
support for this tributed resource

50
00:02:13,220 --> 00:02:17,510
management for fine-grained failure

51
00:02:15,260 --> 00:02:19,370
handling for a fast Network for

52
00:02:17,510 --> 00:02:21,679
functioning separation customization and

53
00:02:19,370 --> 00:02:23,280
with this I believe we can reach another

54
00:02:21,680 --> 00:02:25,920
level of performance management

55
00:02:23,280 --> 00:02:26,910
and customization so that's on the

56
00:02:25,920 --> 00:02:28,829
application side

57
00:02:26,910 --> 00:02:30,690
what about hardware so if you look at

58
00:02:28,830 --> 00:02:32,490
data centers these days they're actually

59
00:02:30,690 --> 00:02:34,680
becoming more and more heterogeneous and

60
00:02:32,490 --> 00:02:38,400
domain-specific specific where things

61
00:02:34,680 --> 00:02:40,950
like TPU TPU FEG and and the N so now

62
00:02:38,400 --> 00:02:42,450
this is good good news for data centers

63
00:02:40,950 --> 00:02:44,250
they all want to use all these fancy

64
00:02:42,450 --> 00:02:47,459
hardware but the first thing they need

65
00:02:44,250 --> 00:02:49,560
to do now is to find server slots to put

66
00:02:47,459 --> 00:02:51,390
these devices in and if they don't have

67
00:02:49,560 --> 00:02:55,070
the need to buy new servers and retire

68
00:02:51,390 --> 00:02:57,929
own servers this is a costly process and

69
00:02:55,070 --> 00:03:01,769
because of that is how to incorporate

70
00:02:57,930 --> 00:03:03,959
many of the new hardware ideas but

71
00:03:01,769 --> 00:03:06,269
imagine refuges can directly connect

72
00:03:03,959 --> 00:03:08,519
devices to network and to deploy a new

73
00:03:06,269 --> 00:03:10,920
hardware you just add a new device to

74
00:03:08,519 --> 00:03:13,560
your network and to retire out one just

75
00:03:10,920 --> 00:03:16,350
take them off the network so this will

76
00:03:13,560 --> 00:03:19,130
gradually improve the heterogeneity and

77
00:03:16,350 --> 00:03:21,870
elasticity of hardware in data centers

78
00:03:19,130 --> 00:03:24,120
so now we just looked at application and

79
00:03:21,870 --> 00:03:26,640
hardware so what about some of the real

80
00:03:24,120 --> 00:03:30,630
problems data centers are facing one of

81
00:03:26,640 --> 00:03:31,828
it is a resource packing so essentially

82
00:03:30,630 --> 00:03:34,950
there are centers when they want to

83
00:03:31,829 --> 00:03:37,590
allocate resource for T dimensional

84
00:03:34,950 --> 00:03:39,030
being a packing problem let's look at

85
00:03:37,590 --> 00:03:40,620
the very thing for example let's say we

86
00:03:39,030 --> 00:03:42,480
have two machines and this is the

87
00:03:40,620 --> 00:03:46,079
occupied resource on machine 1 and

88
00:03:42,480 --> 00:03:50,190
machine 2 and we have this waiting job

89
00:03:46,079 --> 00:03:52,470
which needs three yellow to red and two

90
00:03:50,190 --> 00:03:54,090
blue and one red and together machine

91
00:03:52,470 --> 00:03:56,010
when a machine to have enough resource

92
00:03:54,090 --> 00:03:58,260
but because this job has to run on a

93
00:03:56,010 --> 00:04:02,548
single machine we cannot run this job

94
00:03:58,260 --> 00:04:05,100
and the related problem is that usually

95
00:04:02,549 --> 00:04:07,470
because you cannot easily move a job

96
00:04:05,100 --> 00:04:10,049
around after it starts to run you have

97
00:04:07,470 --> 00:04:12,720
to allocate pre reserved more resource

98
00:04:10,049 --> 00:04:15,120
than what is actually used and because

99
00:04:12,720 --> 00:04:18,180
of this we are seeing in major data

100
00:04:15,120 --> 00:04:20,519
centers like Google and Alabama the CPU

101
00:04:18,180 --> 00:04:25,080
and memory utilization is only 20% to

102
00:04:20,519 --> 00:04:27,600
60% so there's some current solution to

103
00:04:25,080 --> 00:04:29,820
this which is like you can split

104
00:04:27,600 --> 00:04:31,680
application into fine-grained smaller

105
00:04:29,820 --> 00:04:33,599
pieces with things like micro service

106
00:04:31,680 --> 00:04:35,159
and then run them separately on

107
00:04:33,599 --> 00:04:36,870
different machines and communicate

108
00:04:35,159 --> 00:04:40,139
through things like our DMA

109
00:04:36,870 --> 00:04:41,910
swap and distribution memory but they're

110
00:04:40,139 --> 00:04:43,889
still performance overhead to this and

111
00:04:41,910 --> 00:04:47,460
also there's no core support for for

112
00:04:43,889 --> 00:04:50,010
fine-grained failure but imagine if

113
00:04:47,460 --> 00:04:52,530
every device is just separate and

114
00:04:50,010 --> 00:04:55,909
desecrated on its own and when we want

115
00:04:52,530 --> 00:04:58,979
to allocate resource for this device and

116
00:04:55,910 --> 00:05:00,840
when you want more when you're seeing in

117
00:04:58,979 --> 00:05:02,849
the hide amount you can just allocate

118
00:05:00,840 --> 00:05:04,948
more and when you see in the demand

119
00:05:02,850 --> 00:05:07,350
starts reduce you just turn off some of

120
00:05:04,949 --> 00:05:11,070
the device and if the demand keeps

121
00:05:07,350 --> 00:05:13,460
increasing you can add more devices so

122
00:05:11,070 --> 00:05:14,639
with this we can easily reach

123
00:05:13,460 --> 00:05:18,180
auto-scaling

124
00:05:14,639 --> 00:05:21,120
right sizing and tight resource packing

125
00:05:18,180 --> 00:05:24,139
and together this would improve the

126
00:05:21,120 --> 00:05:27,990
monetary and energy cost of data centers

127
00:05:24,139 --> 00:05:31,050
so with all these trends and limitations

128
00:05:27,990 --> 00:05:32,940
what I think we should do is to move

129
00:05:31,050 --> 00:05:35,160
data centers to a new paradigm what I

130
00:05:32,940 --> 00:05:36,810
call this Agra data centers so

131
00:05:35,160 --> 00:05:39,630
essentially we should look at the

132
00:05:36,810 --> 00:05:42,150
problem from the perspective that we

133
00:05:39,630 --> 00:05:43,830
should admit that it operations they are

134
00:05:42,150 --> 00:05:46,919
distributed and functions are

135
00:05:43,830 --> 00:05:49,710
essentially separated so what we are

136
00:05:46,919 --> 00:05:51,810
proposing is to do this disaggregated

137
00:05:49,710 --> 00:05:54,479
data center from the hardware all the

138
00:05:51,810 --> 00:05:55,860
way to the application so from hardware

139
00:05:54,479 --> 00:05:58,530
we should just distributed and

140
00:05:55,860 --> 00:06:00,419
disaggregate hardware devices and then

141
00:05:58,530 --> 00:06:03,388
the core always part we also distribute

142
00:06:00,419 --> 00:06:05,580
and functionally this algorithm and then

143
00:06:03,389 --> 00:06:08,400
after this aggregating we run each of

144
00:06:05,580 --> 00:06:10,830
these separate OS smaller pieces on the

145
00:06:08,400 --> 00:06:13,020
hardware and for application already

146
00:06:10,830 --> 00:06:15,150
speed energy so edit now they can take

147
00:06:13,020 --> 00:06:20,450
through anomalies disaggregate Hardware

148
00:06:15,150 --> 00:06:23,190
OS easily so when this we have started a

149
00:06:20,450 --> 00:06:25,229
multi-year effort into building what we

150
00:06:23,190 --> 00:06:28,050
call a core do you see another trademark

151
00:06:25,229 --> 00:06:30,659
issue I guess so this is an end-to-end

152
00:06:28,050 --> 00:06:32,970
solution for the segue data centers so

153
00:06:30,660 --> 00:06:35,190
we're dealing with the problem from all

154
00:06:32,970 --> 00:06:38,400
the way from hardware to network to OS

155
00:06:35,190 --> 00:06:40,080
to distributed system and a little bit

156
00:06:38,400 --> 00:06:42,840
into application programming language

157
00:06:40,080 --> 00:06:45,270
but today let's just look at the OS

158
00:06:42,840 --> 00:06:49,710
layer which is called lego OS and it was

159
00:06:45,270 --> 00:06:50,770
originally presented in Ostia so SDI so

160
00:06:49,710 --> 00:06:53,349
the first question

161
00:06:50,770 --> 00:06:53,889
when we had is one sweet this a create

162
00:06:53,349 --> 00:06:56,650
hardware

163
00:06:53,889 --> 00:06:59,500
what type of hours should we build can

164
00:06:56,650 --> 00:07:01,870
existing OS work unfortunately existing

165
00:06:59,500 --> 00:07:04,060
OSS they were not designed for this

166
00:07:01,870 --> 00:07:06,759
upgraded resources and they cannot

167
00:07:04,060 --> 00:07:10,300
handle a lot of issues well for example

168
00:07:06,759 --> 00:07:13,090
now a lot of the resources they are now

169
00:07:10,300 --> 00:07:15,669
moving the cross network and traditional

170
00:07:13,090 --> 00:07:18,250
OSS they do not handle this remote

171
00:07:15,669 --> 00:07:20,289
result as well and not only are they

172
00:07:18,250 --> 00:07:23,440
remote but they are also distributed and

173
00:07:20,289 --> 00:07:26,490
there's no support for this low-level

174
00:07:23,440 --> 00:07:29,409
distributed resource and also existing

175
00:07:26,490 --> 00:07:33,340
OSS they do not handle fine-grained

176
00:07:29,409 --> 00:07:35,560
failure well so what type of us should

177
00:07:33,340 --> 00:07:37,599
we build our idea is quite simple so

178
00:07:35,560 --> 00:07:40,389
when hardware it is a graded the oil

179
00:07:37,599 --> 00:07:42,190
should also be so this is traditional OS

180
00:07:40,389 --> 00:07:43,419
which has process management virtual

181
00:07:42,190 --> 00:07:47,280
memory system and file system and

182
00:07:43,419 --> 00:07:47,280
network stack so what we

183
00:07:53,070 --> 00:07:55,130
you

184
00:07:56,479 --> 00:08:02,599
and hopesfire and star system to storage

185
00:07:59,150 --> 00:08:05,419
and by moving functioning close and loco

186
00:08:02,599 --> 00:08:07,998
to the device we believe we can achieve

187
00:08:05,419 --> 00:08:09,979
faster and better management and we can

188
00:08:07,999 --> 00:08:13,430
also customize these different pieces

189
00:08:09,979 --> 00:08:16,219
better where this we propose the

190
00:08:13,430 --> 00:08:17,270
architecture cost split colonel so let's

191
00:08:16,219 --> 00:08:19,009
build colonel

192
00:08:17,270 --> 00:08:21,498
we split always functions into what I

193
00:08:19,009 --> 00:08:23,839
call monitors and for example we have

194
00:08:21,499 --> 00:08:26,029
process monitor running on CPU GPU

195
00:08:23,839 --> 00:08:28,819
monitor renowned GPU memory monitor in

196
00:08:26,029 --> 00:08:30,620
our memory and when of you may invent a

197
00:08:28,819 --> 00:08:33,169
new hardware you can just build your own

198
00:08:30,620 --> 00:08:35,899
customized monitor and then plug that

199
00:08:33,169 --> 00:08:37,789
into the network and here we assuming a

200
00:08:35,899 --> 00:08:40,779
general purpose network that only does

201
00:08:37,789 --> 00:08:43,159
messaging what that means is we leave

202
00:08:40,779 --> 00:08:45,680
into a component coherence to

203
00:08:43,159 --> 00:08:48,680
application which solve a lot of our

204
00:08:45,680 --> 00:08:50,810
performance issues and also the split

205
00:08:48,680 --> 00:08:53,689
kernel would handle a failure and

206
00:08:50,810 --> 00:08:56,268
resource management so what's this

207
00:08:53,690 --> 00:08:57,620
Bitcoin idea we build Lego OS it's a new

208
00:08:56,269 --> 00:09:01,880
distributed or a sport is a great

209
00:08:57,620 --> 00:09:03,940
hardware so the first question we ask is

210
00:09:01,880 --> 00:09:07,550
how should level always appear to users

211
00:09:03,940 --> 00:09:09,829
so we have to to very extreme design

212
00:09:07,550 --> 00:09:11,689
choices on one end the whole thing can

213
00:09:09,829 --> 00:09:13,459
appear as a giant machine and we can

214
00:09:11,690 --> 00:09:15,620
hide out it are the details of the

215
00:09:13,459 --> 00:09:18,290
circuit in nature and on the other hand

216
00:09:15,620 --> 00:09:21,350
we can expose the desalinator to cure

217
00:09:18,290 --> 00:09:23,599
users and let it appear as a set of

218
00:09:21,350 --> 00:09:26,149
hardware devices we choose something in

219
00:09:23,600 --> 00:09:29,180
the middle which we call v nodes so this

220
00:09:26,149 --> 00:09:30,829
is closer to a container but not exactly

221
00:09:29,180 --> 00:09:32,569
a container so this is closer to what

222
00:09:30,829 --> 00:09:36,370
application developers are already

223
00:09:32,569 --> 00:09:41,540
familiar with and also we support more

224
00:09:36,370 --> 00:09:44,149
common Linux api's so this is what house

225
00:09:41,540 --> 00:09:47,029
v note works so we note is a protection

226
00:09:44,149 --> 00:09:49,370
domain and but when we know that can run

227
00:09:47,029 --> 00:09:52,339
on multiple devices and one device can

228
00:09:49,370 --> 00:09:54,199
remote e4v nodes and also we allocate

229
00:09:52,339 --> 00:09:59,329
with me node we allocate the resource on

230
00:09:54,199 --> 00:10:02,329
the amount so internally Lego s has many

231
00:09:59,329 --> 00:10:04,459
detailed design and I won't be able to

232
00:10:02,329 --> 00:10:07,760
cover all of them so today I will just

233
00:10:04,459 --> 00:10:10,069
be focusing on the first which is how we

234
00:10:07,760 --> 00:10:13,280
separate OS and hardware from

235
00:10:10,070 --> 00:10:17,390
charities and briefly talk about our we

236
00:10:13,280 --> 00:10:19,189
managed use us for the the most

237
00:10:17,390 --> 00:10:21,410
difficult part we faced when we were

238
00:10:19,190 --> 00:10:23,900
building Lego OS as two separate

239
00:10:21,410 --> 00:10:26,270
processor and memory so these two have

240
00:10:23,900 --> 00:10:29,180
been fundamentally built together for

241
00:10:26,270 --> 00:10:31,370
decades so how do we separate these so

242
00:10:29,180 --> 00:10:34,489
the first step is just to separate and

243
00:10:31,370 --> 00:10:36,590
move the earrin across network but

244
00:10:34,490 --> 00:10:38,390
that's not enough we also move all the

245
00:10:36,590 --> 00:10:42,560
hardware units that used to manage

246
00:10:38,390 --> 00:10:44,780
memory also cross network after that we

247
00:10:42,560 --> 00:10:46,520
move these software system that used to

248
00:10:44,780 --> 00:10:49,400
manage memory which is virtual memory

249
00:10:46,520 --> 00:10:52,000
system also to the memory and run it in

250
00:10:49,400 --> 00:10:55,430
a in a controller at the memory device

251
00:10:52,000 --> 00:10:57,950
so after this what we are seeing is we

252
00:10:55,430 --> 00:10:59,750
are separate we can separate the whole

253
00:10:57,950 --> 00:11:03,230
virtual memory system into the memory

254
00:10:59,750 --> 00:11:05,330
side and that leaves us what we call

255
00:11:03,230 --> 00:11:08,480
would I call P components for process

256
00:11:05,330 --> 00:11:11,210
and M component for memory and for the P

257
00:11:08,480 --> 00:11:14,000
component now we are we only deal with

258
00:11:11,210 --> 00:11:16,340
virtual address because all the virtual

259
00:11:14,000 --> 00:11:18,020
memory space physical memory space and

260
00:11:16,340 --> 00:11:20,570
the translation are handled at M

261
00:11:18,020 --> 00:11:23,449
components so what that means is we

262
00:11:20,570 --> 00:11:24,950
change our levels of CPU caches into

263
00:11:23,450 --> 00:11:28,070
virtual caches which are virtually

264
00:11:24,950 --> 00:11:29,810
attacked and virtually indexed so this

265
00:11:28,070 --> 00:11:31,430
functionally this whole thing now we

266
00:11:29,810 --> 00:11:33,319
have things are pressing our

267
00:11:31,430 --> 00:11:36,410
functionality but what about performance

268
00:11:33,320 --> 00:11:39,380
so if you look at this diagram you will

269
00:11:36,410 --> 00:11:42,219
see that every last level cache miss

270
00:11:39,380 --> 00:11:45,380
would involve a one network round-trip

271
00:11:42,220 --> 00:11:47,120
so what about network delay so let's

272
00:11:45,380 --> 00:11:49,820
look at how network speed has improved

273
00:11:47,120 --> 00:11:52,430
over the past couple of decades so this

274
00:11:49,820 --> 00:11:55,370
figure y-axis is bandwidth so higher is

275
00:11:52,430 --> 00:11:57,709
better so this blue line is a single

276
00:11:55,370 --> 00:12:00,500
single line Ethernet and this is called

277
00:11:57,710 --> 00:12:03,140
length of four times speed and this one

278
00:12:00,500 --> 00:12:06,950
is a single Bank DDR memory speed and

279
00:12:03,140 --> 00:12:08,960
this is DDR bus so if you we are just

280
00:12:06,950 --> 00:12:11,810
looking at comparing single lane

281
00:12:08,960 --> 00:12:13,910
ethernet to a single bank memory DDR

282
00:12:11,810 --> 00:12:16,300
memory you can see that throughput is

283
00:12:13,910 --> 00:12:20,000
actually close and some projection is

284
00:12:16,300 --> 00:12:21,880
network would even be faster but at the

285
00:12:20,000 --> 00:12:23,840
same time if you look a latency

286
00:12:21,880 --> 00:12:26,720
network is still 10 times

287
00:12:23,840 --> 00:12:28,460
around ten times worse and the

288
00:12:26,720 --> 00:12:31,700
interesting another interesting part is

289
00:12:28,460 --> 00:12:33,860
met many of the local drm they are

290
00:12:31,700 --> 00:12:36,200
actually facing both capacity and

291
00:12:33,860 --> 00:12:37,910
bandwidth war so what I think we should

292
00:12:36,200 --> 00:12:41,839
do is to resync the whole memory

293
00:12:37,910 --> 00:12:43,839
hierarchy and memory memory system so

294
00:12:41,839 --> 00:12:47,839
what we propose is to separate

295
00:12:43,839 --> 00:12:49,790
performance and capacity of memory so

296
00:12:47,839 --> 00:12:52,940
for performance we handle all that at

297
00:12:49,790 --> 00:12:55,160
key components and what we do is we add

298
00:12:52,940 --> 00:12:57,260
another level of what we call extended

299
00:12:55,160 --> 00:12:59,930
cache years cache below last level cache

300
00:12:57,260 --> 00:13:02,630
and we use a small few GBS of high

301
00:12:59,930 --> 00:13:05,029
bandwidth memory for that and this X

302
00:13:02,630 --> 00:13:08,630
cache is managed by the hardware on hit

303
00:13:05,029 --> 00:13:10,460
paths and OS manages the miss path so

304
00:13:08,630 --> 00:13:12,560
this with this we can actually improve

305
00:13:10,460 --> 00:13:15,620
the performance on the P component side

306
00:13:12,560 --> 00:13:19,430
and now we move or the capacity side

307
00:13:15,620 --> 00:13:21,830
across network what we do is we can

308
00:13:19,430 --> 00:13:23,689
increase the size of each M components

309
00:13:21,830 --> 00:13:26,510
theorem or even use number at our memory

310
00:13:23,690 --> 00:13:28,370
and we can have multiple of them so with

311
00:13:26,510 --> 00:13:32,569
this architecture we improve both

312
00:13:28,370 --> 00:13:35,120
performance and capacity and we can

313
00:13:32,570 --> 00:13:37,420
separate and mention independently so

314
00:13:35,120 --> 00:13:40,220
now it is very briefly talk about our

315
00:13:37,420 --> 00:13:43,459
distributed resource management so our

316
00:13:40,220 --> 00:13:45,950
idea is to use a two level management so

317
00:13:43,460 --> 00:13:48,470
at a lower level we do fine-grained

318
00:13:45,950 --> 00:13:50,750
management where each components they

319
00:13:48,470 --> 00:13:53,060
just communicate on their own with for

320
00:13:50,750 --> 00:13:56,810
fine-grained resource allocation and

321
00:13:53,060 --> 00:13:59,270
fine-grained access and then we have we

322
00:13:56,810 --> 00:14:01,489
maintain one a multiple global resource

323
00:13:59,270 --> 00:14:03,680
manager that has that this process

324
00:14:01,490 --> 00:14:05,270
global process management global memory

325
00:14:03,680 --> 00:14:07,040
management and global storage management

326
00:14:05,270 --> 00:14:09,949
and every time when you have a

327
00:14:07,040 --> 00:14:11,569
coarse-grained resource request like

328
00:14:09,950 --> 00:14:14,810
when you want to allocate a new process

329
00:14:11,570 --> 00:14:16,970
you go to the global process management

330
00:14:14,810 --> 00:14:20,000
but when you create a new thread it will

331
00:14:16,970 --> 00:14:21,920
be local so I don't have time for

332
00:14:20,000 --> 00:14:24,320
channel have time to go into a lot of

333
00:14:21,920 --> 00:14:25,640
the design details of our leggo us if

334
00:14:24,320 --> 00:14:28,339
interested you should check out paper

335
00:14:25,640 --> 00:14:30,980
out so now let's move to instrumentation

336
00:14:28,339 --> 00:14:33,200
evaluation so we implemented Lego as

337
00:14:30,980 --> 00:14:35,150
from scratch I think it's more than two

338
00:14:33,200 --> 00:14:37,650
hundred thousand lines of code now and

339
00:14:35,150 --> 00:14:40,560
we parted a lot of drivers from Linux

340
00:14:37,650 --> 00:14:43,079
and so at the time we were just using

341
00:14:40,560 --> 00:14:44,670
normal servers to emulate the security

342
00:14:43,080 --> 00:14:48,000
devices and currently we are building

343
00:14:44,670 --> 00:14:50,939
our own hardware solution so here we

344
00:14:48,000 --> 00:14:53,339
show results with a modified tensorflow

345
00:14:50,940 --> 00:14:55,980
that are running imagenet and cipher ten

346
00:14:53,339 --> 00:14:58,680
and we compare Lego s with several

347
00:14:55,980 --> 00:15:01,589
systems so the first and the baseline a

348
00:14:58,680 --> 00:15:04,109
single machine Linux which essentially

349
00:15:01,589 --> 00:15:06,270
unlimited memory so no swap and all

350
00:15:04,110 --> 00:15:08,040
memory is enough or the local memory is

351
00:15:06,270 --> 00:15:10,620
enough so this would give us optimum

352
00:15:08,040 --> 00:15:13,439
performance we also compare Linux swap

353
00:15:10,620 --> 00:15:15,990
to local ram disk so in memory disk and

354
00:15:13,440 --> 00:15:17,880
also a system called infinite swap that

355
00:15:15,990 --> 00:15:21,000
swaps to remote memory through

356
00:15:17,880 --> 00:15:23,880
InfiniBand so this figure shows the

357
00:15:21,000 --> 00:15:27,300
unsafe return result and our image net

358
00:15:23,880 --> 00:15:29,400
is similar so y-axis here we are showing

359
00:15:27,300 --> 00:15:33,180
performance per dollars our per dollar

360
00:15:29,400 --> 00:15:35,699
is calculated by Hardware energy cost

361
00:15:33,180 --> 00:15:40,279
and it's roughly with Lego as we can

362
00:15:35,700 --> 00:15:44,279
roughly save half of the cost so here an

363
00:15:40,279 --> 00:15:47,820
x-axis is the memory size local memory

364
00:15:44,279 --> 00:15:50,880
size our X cache size so if you look at

365
00:15:47,820 --> 00:15:53,010
just pure Lego OS how it compares to

366
00:15:50,880 --> 00:15:55,170
single machine Linux we can see that

367
00:15:53,010 --> 00:15:59,640
Lego has came proof performance per

368
00:15:55,170 --> 00:16:01,650
dollar by up to 1.5 1.4 times and then

369
00:15:59,640 --> 00:16:05,160
this is in Finnish WAP swap into remote

370
00:16:01,650 --> 00:16:06,900
memory and swap into local Ram disk so

371
00:16:05,160 --> 00:16:09,510
if we are only comparing pure

372
00:16:06,900 --> 00:16:12,300
performance level OS improves

373
00:16:09,510 --> 00:16:16,709
performance of these swap systems by 1.3

374
00:16:12,300 --> 00:16:19,949
x tube 2.0 2.1 x so this actually is the

375
00:16:16,709 --> 00:16:22,619
power of building something from ground

376
00:16:19,950 --> 00:16:26,910
up and solving things from OS and

377
00:16:22,620 --> 00:16:29,370
hardware level so to summer summarize

378
00:16:26,910 --> 00:16:32,400
levels firstly it's open source and I

379
00:16:29,370 --> 00:16:35,040
think just looking back I think the key

380
00:16:32,400 --> 00:16:37,529
contribution is in demonstrating the

381
00:16:35,040 --> 00:16:39,420
feed ability of separating something

382
00:16:37,529 --> 00:16:42,450
that is very fundamental and court who

383
00:16:39,420 --> 00:16:44,729
OS that is things like how do we

384
00:16:42,450 --> 00:16:46,320
separate process from memory and after

385
00:16:44,730 --> 00:16:48,300
separating there are a lot of new

386
00:16:46,320 --> 00:16:50,690
opportunities we can do we can customize

387
00:16:48,300 --> 00:16:52,519
application hardware

388
00:16:50,690 --> 00:16:55,100
I think this could encourage a lot of

389
00:16:52,519 --> 00:16:57,589
the future and Hardware OS research and

390
00:16:55,100 --> 00:16:59,060
like Ramsey said conclusion are always

391
00:16:57,589 --> 00:17:01,610
different from summary so to conclude

392
00:16:59,060 --> 00:17:03,709
conclude this this is most probably the

393
00:17:01,610 --> 00:17:06,020
most controversial sentence of the whole

394
00:17:03,709 --> 00:17:08,569
slide that that what at least what I

395
00:17:06,020 --> 00:17:11,030
think is the identity success allegation

396
00:17:08,569 --> 00:17:13,730
is not an if question but it's a Hawkeye

397
00:17:11,030 --> 00:17:17,389
stream so what we believe the approach

398
00:17:13,730 --> 00:17:20,299
to antenna salvation is an to end

399
00:17:17,390 --> 00:17:22,819
solution that do things from ground up

400
00:17:20,299 --> 00:17:25,189
we are pushing function disaggregation

401
00:17:22,819 --> 00:17:27,740
the distribution into our layers of the

402
00:17:25,189 --> 00:17:30,950
systems that and another interesting

403
00:17:27,740 --> 00:17:33,440
thing that we found is that especially

404
00:17:30,950 --> 00:17:36,440
to students here that building Kura is

405
00:17:33,440 --> 00:17:38,870
fun although you write a lot of code but

406
00:17:36,440 --> 00:17:41,750
it's new fun and nowadays we are seeing

407
00:17:38,870 --> 00:17:44,090
new ways to build OS so maybe OS can

408
00:17:41,750 --> 00:17:45,710
part of the OSS the user space it's this

409
00:17:44,090 --> 00:17:48,559
equity distributed or maybe you

410
00:17:45,710 --> 00:17:50,539
computerizing hardware and with that I

411
00:17:48,559 --> 00:17:54,139
want you to think about my students who

412
00:17:50,539 --> 00:18:05,750
work on Lego DC and happy to take

413
00:17:54,140 --> 00:18:08,450
questions hi

414
00:18:05,750 --> 00:18:10,130
we we spent a lot of time trying to put

415
00:18:08,450 --> 00:18:12,830
components close together in order to

416
00:18:10,130 --> 00:18:14,299
decrease latency I was just wondering

417
00:18:12,830 --> 00:18:16,250
this seems to fly in the face of that

418
00:18:14,299 --> 00:18:18,379
and then it introduces the latency which

419
00:18:16,250 --> 00:18:20,450
doesn't seem to be compressible beyond a

420
00:18:18,380 --> 00:18:22,130
certain point due to physics so I was

421
00:18:20,450 --> 00:18:24,260
just wondering what the effects of a

422
00:18:22,130 --> 00:18:26,780
latency might do to systems that are

423
00:18:24,260 --> 00:18:29,658
running a data center like this so this

424
00:18:26,780 --> 00:18:32,928
is a very good question so there are few

425
00:18:29,659 --> 00:18:37,100
angles are probably answer this so the

426
00:18:32,929 --> 00:18:40,280
first is lego OS and this separation

427
00:18:37,100 --> 00:18:42,709
does not solve problems of our problems

428
00:18:40,280 --> 00:18:45,860
so I would say this is better for a

429
00:18:42,710 --> 00:18:49,070
throughput oriented or orient oriented

430
00:18:45,860 --> 00:18:52,549
applications but also if you see the

431
00:18:49,070 --> 00:18:53,059
memories the X cache that we added so we

432
00:18:52,549 --> 00:18:54,770
think

433
00:18:53,059 --> 00:18:56,899
latency should be handled separately

434
00:18:54,770 --> 00:18:59,450
from throughput and forth Ruppert

435
00:18:56,900 --> 00:19:01,490
network is in enough at least for the

436
00:18:59,450 --> 00:19:03,380
things that we see and for that we can

437
00:19:01,490 --> 00:19:04,310
actually push a lot of the support

438
00:19:03,380 --> 00:19:06,380
oriented

439
00:19:04,310 --> 00:19:08,600
a lot of the data across network a for

440
00:19:06,380 --> 00:19:11,420
latency-sensitive we should just focus

441
00:19:08,600 --> 00:19:15,550
on optimizing the processor site with

442
00:19:11,420 --> 00:19:19,250
the cache yeah so that's my take on that

443
00:19:15,550 --> 00:19:23,360
hi I'm curious since you have more

444
00:19:19,250 --> 00:19:25,700
different distinct components now don't

445
00:19:23,360 --> 00:19:29,870
you increase the probability of failure

446
00:19:25,700 --> 00:19:33,290
like if one of those components fail and

447
00:19:29,870 --> 00:19:34,310
as well as security exposures so that's

448
00:19:33,290 --> 00:19:38,120
a very good question

449
00:19:34,310 --> 00:19:41,629
so depends on how you define failure so

450
00:19:38,120 --> 00:19:43,760
the do I think it's true that we may add

451
00:19:41,630 --> 00:19:45,410
more components but just to remember

452
00:19:43,760 --> 00:19:47,780
because our resource utilization is

453
00:19:45,410 --> 00:19:51,170
better so the total resource that you

454
00:19:47,780 --> 00:19:52,610
will need essentially decrease but each

455
00:19:51,170 --> 00:19:54,230
resource you are now adding more

456
00:19:52,610 --> 00:19:57,740
components so I would say this is

457
00:19:54,230 --> 00:19:59,570
roughly similar but in terms of what do

458
00:19:57,740 --> 00:20:02,320
you when you when something fail crash

459
00:19:59,570 --> 00:20:04,610
what it fails now it's more fine-grained

460
00:20:02,320 --> 00:20:06,980
currently when the processor failed the

461
00:20:04,610 --> 00:20:08,510
whole machine fails and our model when

462
00:20:06,980 --> 00:20:09,920
the process affair it only fails that

463
00:20:08,510 --> 00:20:12,410
processor the whole application still

464
00:20:09,920 --> 00:20:15,350
exists so it depends on it's a different

465
00:20:12,410 --> 00:20:18,560
way how you handle failure but don't you

466
00:20:15,350 --> 00:20:20,530
have more network connections and more

467
00:20:18,560 --> 00:20:23,649
like independent power supplies

468
00:20:20,530 --> 00:20:26,379
potentially so it seems like you have

469
00:20:23,650 --> 00:20:29,450
more of a chance for very small

470
00:20:26,380 --> 00:20:31,610
uncorrelated failure that would make

471
00:20:29,450 --> 00:20:34,070
your applications harder to write

472
00:20:31,610 --> 00:20:35,979
because now they have to deal with

473
00:20:34,070 --> 00:20:38,810
partial failures they don't get to like

474
00:20:35,980 --> 00:20:41,240
crash or like go away when the whole

475
00:20:38,810 --> 00:20:44,870
machine crashes now you have more

476
00:20:41,240 --> 00:20:48,530
chances of these more probable partial

477
00:20:44,870 --> 00:20:50,870
failures happening so well like first

478
00:20:48,530 --> 00:20:53,270
like I said the whole resource that you

479
00:20:50,870 --> 00:20:57,350
need is less because utilization is

480
00:20:53,270 --> 00:20:59,180
higher so the independent component the

481
00:20:57,350 --> 00:21:02,209
amount of increment component may not

482
00:20:59,180 --> 00:21:03,980
increase and the second is it depends on

483
00:21:02,210 --> 00:21:06,140
how you build applications and who would

484
00:21:03,980 --> 00:21:08,570
handle this failure so our approach is

485
00:21:06,140 --> 00:21:11,090
our level we will handle all these

486
00:21:08,570 --> 00:21:13,700
fine-grained failure with Lego s and

487
00:21:11,090 --> 00:21:15,379
hide that those from application some 2d

488
00:21:13,700 --> 00:21:16,850
application point of view they are just

489
00:21:15,380 --> 00:21:18,920
running a set of Linux

490
00:21:16,850 --> 00:21:26,149
containers let's see if you do like

491
00:21:18,920 --> 00:21:28,580
replication does your system expose like

492
00:21:26,150 --> 00:21:31,670
Network locality of resources to the

493
00:21:28,580 --> 00:21:33,230
user like is it there any notion of you

494
00:21:31,670 --> 00:21:35,840
know I want to make sure that I have ran

495
00:21:33,230 --> 00:21:37,220
that's in my rack versus the rack next

496
00:21:35,840 --> 00:21:40,250
to me versus like a totally different

497
00:21:37,220 --> 00:21:43,730
data center currently no and currently

498
00:21:40,250 --> 00:21:45,620
our scale is like a one or two racks but

499
00:21:43,730 --> 00:21:47,570
I would say we are working on we are

500
00:21:45,620 --> 00:21:49,399
working in larger scale and thinking

501
00:21:47,570 --> 00:21:57,280
about some of the locality hierarchy

502
00:21:49,400 --> 00:22:01,310
problems thank you for the great

503
00:21:57,280 --> 00:22:04,399
presentation it's very impressive so

504
00:22:01,310 --> 00:22:06,520
first question that I feel the overall

505
00:22:04,400 --> 00:22:09,140
system availability all reliabilities

506
00:22:06,520 --> 00:22:12,440
highly depend on the availability of the

507
00:22:09,140 --> 00:22:13,790
global monitoring system if there is any

508
00:22:12,440 --> 00:22:17,360
issue about the global monetary system

509
00:22:13,790 --> 00:22:19,850
that will impact a lot yeah so like I

510
00:22:17,360 --> 00:22:22,820
said the global monitor system first is

511
00:22:19,850 --> 00:22:24,919
we can also replicate the global monitor

512
00:22:22,820 --> 00:22:27,889
Carl Bo resource manager it's not a

513
00:22:24,920 --> 00:22:32,030
global monitor and the other thing is we

514
00:22:27,890 --> 00:22:33,980
actually saw the global management guess

515
00:22:32,030 --> 00:22:36,980
all can reconstruct all its information

516
00:22:33,980 --> 00:22:39,350
from contacting the individual resources

517
00:22:36,980 --> 00:22:42,800
individual devices so they keep

518
00:22:39,350 --> 00:22:45,139
fine-grained knowledge of resource

519
00:22:42,800 --> 00:22:47,240
utilization and other things so the

520
00:22:45,140 --> 00:22:49,580
global thing can be reconstructed and

521
00:22:47,240 --> 00:22:51,500
that when it fails you can just go to

522
00:22:49,580 --> 00:22:53,949
the find way which is a little bit

523
00:22:51,500 --> 00:22:56,170
slower I'm also thinking about another

524
00:22:53,950 --> 00:22:58,960
question may be very interesting so

525
00:22:56,170 --> 00:23:02,210
think about I'm a developer I want to

526
00:22:58,960 --> 00:23:04,460
improve this kind of system and I find

527
00:23:02,210 --> 00:23:07,610
out that this bargain in my global

528
00:23:04,460 --> 00:23:13,550
resource management and the impact of

529
00:23:07,610 --> 00:23:16,159
this part could be see when one memory

530
00:23:13,550 --> 00:23:18,860
slot or all name is slot I think it's a

531
00:23:16,160 --> 00:23:22,460
potential impact of a small part you

532
00:23:18,860 --> 00:23:25,219
know any component will be could be very

533
00:23:22,460 --> 00:23:27,320
huge how do you think about that Wow and

534
00:23:25,220 --> 00:23:29,600
so this first one I would also answer

535
00:23:27,320 --> 00:23:30,290
the other security was so the what we do

536
00:23:29,600 --> 00:23:33,709
is we

537
00:23:30,290 --> 00:23:36,220
prate lien you can think of a Linux OS

538
00:23:33,710 --> 00:23:39,290
into smaller pieces and each piece it's

539
00:23:36,220 --> 00:23:41,210
mostly independent you can protect it on

540
00:23:39,290 --> 00:23:43,840
its own you can develop and debug it

541
00:23:41,210 --> 00:23:48,200
only a song so from this point of view

542
00:23:43,840 --> 00:23:51,260
it's easier to to to protect you to make

543
00:23:48,200 --> 00:23:53,690
it more more reliable and also the

544
00:23:51,260 --> 00:23:55,850
global saying that I think any any

545
00:23:53,690 --> 00:23:58,160
system that uses a global management

546
00:23:55,850 --> 00:24:02,560
what happies would have similar issue

547
00:23:58,160 --> 00:24:06,670
and we we actually reduce the amount of

548
00:24:02,560 --> 00:24:11,030
dependency on this global management

549
00:24:06,670 --> 00:24:12,950
just take one more question and so my

550
00:24:11,030 --> 00:24:16,580
question is more about performance

551
00:24:12,950 --> 00:24:18,320
prediction how is the dividing this

552
00:24:16,580 --> 00:24:19,850
operating system into a lot of pieces

553
00:24:18,320 --> 00:24:23,300
talking to each other through network

554
00:24:19,850 --> 00:24:25,580
making the system is it more as it

555
00:24:23,300 --> 00:24:28,610
becomes more unpredictable because now

556
00:24:25,580 --> 00:24:30,020
the components speak with other

557
00:24:28,610 --> 00:24:33,770
components through network which it

558
00:24:30,020 --> 00:24:36,160
could be subject to noise that's a good

559
00:24:33,770 --> 00:24:39,290
question so first is I want to say that

560
00:24:36,160 --> 00:24:41,960
this is a big move and we are also

561
00:24:39,290 --> 00:24:44,120
building our own network solution which

562
00:24:41,960 --> 00:24:47,770
and there are others network solution to

563
00:24:44,120 --> 00:24:50,919
research this equation but in terms of

564
00:24:47,770 --> 00:24:53,389
all right what's your original classroom

565
00:24:50,920 --> 00:24:56,780
predictability of the application given

566
00:24:53,390 --> 00:24:59,780
that the network is noisy they predicted

567
00:24:56,780 --> 00:25:01,250
I will say that like I said in the

568
00:24:59,780 --> 00:25:03,350
beginning of the talk a lot of the

569
00:25:01,250 --> 00:25:06,350
applications they already distributed

570
00:25:03,350 --> 00:25:09,050
and this aggregated so I would say that

571
00:25:06,350 --> 00:25:11,000
if you can manage this disagreed in

572
00:25:09,050 --> 00:25:13,639
nature you know in the lower system like

573
00:25:11,000 --> 00:25:17,630
OS you can manage this and predictably

574
00:25:13,640 --> 00:25:20,390
and predictability better than if in the

575
00:25:17,630 --> 00:25:23,330
current way that everything is just hold

576
00:25:20,390 --> 00:25:25,750
is a created from the application point

577
00:25:23,330 --> 00:25:25,750
of view

578
00:25:26,230 --> 00:25:34,800
okay now that's sexist speaker

579
00:25:30,090 --> 00:25:34,800
[Applause]

