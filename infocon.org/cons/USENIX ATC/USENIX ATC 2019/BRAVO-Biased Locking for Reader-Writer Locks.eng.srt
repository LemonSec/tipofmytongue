1
00:00:10,139 --> 00:00:14,760
thank you for the introduction so I'm

2
00:00:12,599 --> 00:00:17,250
going to talk about the common problem

3
00:00:14,760 --> 00:00:19,169
reader/writer walks which is the

4
00:00:17,250 --> 00:00:23,599
scalability of those logs in the

5
00:00:19,169 --> 00:00:26,219
presence of multiple readers so

6
00:00:23,599 --> 00:00:27,540
reader/writer walk is the

7
00:00:26,219 --> 00:00:30,119
synchronization primitive for

8
00:00:27,540 --> 00:00:31,169
controlling access by multiple cells to

9
00:00:30,119 --> 00:00:33,690
shared resource

10
00:00:31,169 --> 00:00:35,640
this locks allow shared access for

11
00:00:33,690 --> 00:00:37,769
read-only use of resource while write

12
00:00:35,640 --> 00:00:40,680
operations access the resource

13
00:00:37,770 --> 00:00:44,220
exclusively those locks are common in

14
00:00:40,680 --> 00:00:46,829
modern systems ranging from databases in

15
00:00:44,220 --> 00:00:50,790
key value stores to file systems and

16
00:00:46,829 --> 00:00:52,770
operating system kernels reader writer

17
00:00:50,790 --> 00:00:54,660
logs have to keep track of the presence

18
00:00:52,770 --> 00:00:58,350
of active readers before law can be

19
00:00:54,660 --> 00:01:00,089
granted to a writer in the common case a

20
00:00:58,350 --> 00:01:02,399
shared counter is used which is

21
00:01:00,090 --> 00:01:04,280
incremented and decremented with every

22
00:01:02,399 --> 00:01:08,130
acquisition or release of the counter

23
00:01:04,280 --> 00:01:11,640
sorry of the log in the read mode now

24
00:01:08,130 --> 00:01:13,380
when the writer shows up it reads the

25
00:01:11,640 --> 00:01:16,890
value of the counter and it waits until

26
00:01:13,380 --> 00:01:19,560
it drops to zero this approach results

27
00:01:16,890 --> 00:01:21,479
in a very simple and compact lock and in

28
00:01:19,560 --> 00:01:23,970
fact is found in common reader writer

29
00:01:21,479 --> 00:01:26,580
walk implementations such as those used

30
00:01:23,970 --> 00:01:31,080
in the Linux kernel POSIX pieces library

31
00:01:26,580 --> 00:01:33,000
and many other places however this

32
00:01:31,080 --> 00:01:35,190
approach suffers under high intensity

33
00:01:33,000 --> 00:01:37,920
read AMA nated workloads when the reader

34
00:01:35,190 --> 00:01:39,658
indicator state is updated frequently by

35
00:01:37,920 --> 00:01:41,310
the first set of threads acquiring to

36
00:01:39,659 --> 00:01:45,659
walk for read causing cache invalidation

37
00:01:41,310 --> 00:01:47,820
and coherence traffic alternative

38
00:01:45,659 --> 00:01:50,520
designs for either idle walks employ

39
00:01:47,820 --> 00:01:53,369
distributed reader indicators one per

40
00:01:50,520 --> 00:01:56,520
newman old one tokoro for example one

41
00:01:53,369 --> 00:01:58,380
per thread now this improves reader read

42
00:01:56,520 --> 00:02:01,789
of scalability but also considerably

43
00:01:58,380 --> 00:02:04,020
increases the size of each lock instance

44
00:02:01,790 --> 00:02:06,270
furthermore the lock performance is

45
00:02:04,020 --> 00:02:09,119
hampered when writes are frequent

46
00:02:06,270 --> 00:02:12,030
because now multiple indicators have to

47
00:02:09,119 --> 00:02:15,620
be checked and or modified when a rider

48
00:02:12,030 --> 00:02:18,810
shows up plus a minor issue such locks

49
00:02:15,620 --> 00:02:21,140
can be instantiated statically since the

50
00:02:18,810 --> 00:02:23,120
number of new Menards or

51
00:02:21,140 --> 00:02:26,029
course or threats is typically not known

52
00:02:23,120 --> 00:02:29,420
until the runtime and that might be an

53
00:02:26,030 --> 00:02:31,730
issue for certain applications so the

54
00:02:29,420 --> 00:02:35,208
result designers of modern video Idol

55
00:02:31,730 --> 00:02:37,069
walks have to face a difficult rate of

56
00:02:35,209 --> 00:02:39,500
related to the scalability and footprint

57
00:02:37,069 --> 00:02:42,260
of maintaining the indication of readers

58
00:02:39,500 --> 00:02:46,450
presence forcing them to choose one

59
00:02:42,260 --> 00:02:48,829
feature over the other in this work we

60
00:02:46,450 --> 00:02:50,420
introduce Bravo which essentially

61
00:02:48,830 --> 00:02:52,520
eliminates the reader indicator dilemma

62
00:02:50,420 --> 00:02:54,440
and allows the reader idle walk to

63
00:02:52,520 --> 00:02:56,800
remain compact and scalable in the

64
00:02:54,440 --> 00:03:00,200
presence of multiple concurrent readers

65
00:02:56,800 --> 00:03:01,489
so Bravo augments any existing read

66
00:03:00,200 --> 00:03:03,649
erotic writer walk

67
00:03:01,489 --> 00:03:06,019
adding just two integer fields to the

68
00:03:03,650 --> 00:03:08,959
walk instance in addition and add a

69
00:03:06,019 --> 00:03:10,940
visible readers table of fixed size that

70
00:03:08,959 --> 00:03:14,450
can be shared by all threads and locks

71
00:03:10,940 --> 00:03:16,459
in the same outer space now those two

72
00:03:14,450 --> 00:03:19,190
new fields are called our bias and

73
00:03:16,459 --> 00:03:20,870
inhibit until and their meaning will

74
00:03:19,190 --> 00:03:23,300
become clear over the next few slides

75
00:03:20,870 --> 00:03:25,040
for now I only mentioned that our bias

76
00:03:23,300 --> 00:03:28,040
is just a flag that can be easily

77
00:03:25,040 --> 00:03:31,190
co-located with this new inhibit nto

78
00:03:28,040 --> 00:03:34,730
field but for clarity reasons we didn't

79
00:03:31,190 --> 00:03:36,950
do that in in our work so with Bravo

80
00:03:34,730 --> 00:03:39,679
readers make their presence known to

81
00:03:36,950 --> 00:03:40,940
writers by hashing the threads identity

82
00:03:39,680 --> 00:03:43,700
with the lock address

83
00:03:40,940 --> 00:03:46,190
forming an index entry visible readers

84
00:03:43,700 --> 00:03:47,899
table specifically they read the value

85
00:03:46,190 --> 00:03:50,150
of the otherwise flag and for now let's

86
00:03:47,900 --> 00:03:53,570
assume that the flag is said later I

87
00:03:50,150 --> 00:03:58,100
will explain how we determine the value

88
00:03:53,570 --> 00:03:59,930
of this flag so if the flag is said the

89
00:03:58,100 --> 00:04:01,640
reader will attempt to install the lock

90
00:03:59,930 --> 00:04:03,950
address into the slot in the table

91
00:04:01,640 --> 00:04:06,170
identified by the by the result of the

92
00:04:03,950 --> 00:04:08,780
hash function this attempt is scaled by

93
00:04:06,170 --> 00:04:11,359
an atomic comparing swap operation and

94
00:04:08,780 --> 00:04:12,860
if successful the reader can proceed

95
00:04:11,360 --> 00:04:14,900
with its critical section without

96
00:04:12,860 --> 00:04:18,019
modifying any shared state of the

97
00:04:14,900 --> 00:04:21,140
underlying log now when another reader

98
00:04:18,019 --> 00:04:24,200
shows up it will essentially follow the

99
00:04:21,140 --> 00:04:25,729
same procedure but now using its third

100
00:04:24,200 --> 00:04:28,760
identity will typically choose a

101
00:04:25,729 --> 00:04:32,110
different sort in the readers table and

102
00:04:28,760 --> 00:04:34,550
so make its presence known in their slot

103
00:04:32,110 --> 00:04:37,550
one may wonder what happens in the

104
00:04:34,550 --> 00:04:40,610
of the conflict so for instance if third

105
00:04:37,550 --> 00:04:42,800
radio shows up and picks a spot that is

106
00:04:40,610 --> 00:04:44,990
already occupied by another another

107
00:04:42,800 --> 00:04:46,610
threat another walk so in this case the

108
00:04:44,990 --> 00:04:48,890
compare-and-swap operation will fail and

109
00:04:46,610 --> 00:04:51,440
that reader will simply resort to the

110
00:04:48,890 --> 00:04:53,990
acquisition path of the antilog which in

111
00:04:51,440 --> 00:04:56,750
this case will simply increment the

112
00:04:53,990 --> 00:04:58,370
shared counter not however that

113
00:04:56,750 --> 00:05:00,920
collisions are benign and impact

114
00:04:58,370 --> 00:05:03,320
performance but not correctness and the

115
00:05:00,920 --> 00:05:06,040
odds of collisions equivalent to those

116
00:05:03,320 --> 00:05:08,450
given by the birthday paradox and

117
00:05:06,040 --> 00:05:10,550
dictated among other things by the size

118
00:05:08,450 --> 00:05:14,900
of the table and the number of a threat

119
00:05:10,550 --> 00:05:16,820
so as I already said before the table

120
00:05:14,900 --> 00:05:20,179
was shared by all threads and locks in

121
00:05:16,820 --> 00:05:22,940
the other space crucially though threads

122
00:05:20,180 --> 00:05:25,160
acquiring the same lock in the read mode

123
00:05:22,940 --> 00:05:27,710
tend to write to different locations in

124
00:05:25,160 --> 00:05:30,620
the table reducing coherence traffic and

125
00:05:27,710 --> 00:05:33,049
resulting in an Ummah friendly design in

126
00:05:30,620 --> 00:05:35,420
a natural this is the key for Bravo to

127
00:05:33,050 --> 00:05:39,260
be able to accelerate read dominated

128
00:05:35,420 --> 00:05:43,280
workloads now let's talk about writers

129
00:05:39,260 --> 00:05:44,870
so when a writer shows up it always uses

130
00:05:43,280 --> 00:05:47,090
the acquisition path of the underlined

131
00:05:44,870 --> 00:05:50,390
role so first it acquires the lock for

132
00:05:47,090 --> 00:05:53,119
write and then it resets the abayas

133
00:05:50,390 --> 00:05:55,099
flag and by doing that it prevents any

134
00:05:53,120 --> 00:05:59,180
new reader from using the table for the

135
00:05:55,100 --> 00:06:00,920
fast read acquisition now after

136
00:05:59,180 --> 00:06:02,900
resetting the a bias flag scans the

137
00:06:00,920 --> 00:06:04,850
table waiting for any existing reader

138
00:06:02,900 --> 00:06:08,239
that acquired that particular lock so

139
00:06:04,850 --> 00:06:10,640
the fast path obviously doing that

140
00:06:08,240 --> 00:06:12,170
revocation scan for each and every write

141
00:06:10,640 --> 00:06:14,659
acquisition would be prohibitively

142
00:06:12,170 --> 00:06:17,540
expensive therefore a simple mechanism

143
00:06:14,660 --> 00:06:19,370
is put in place to limit the overhead of

144
00:06:17,540 --> 00:06:22,220
scanning the table for workloads in

145
00:06:19,370 --> 00:06:24,500
which rights are frequent specifically

146
00:06:22,220 --> 00:06:27,200
the writer measures the latency of the

147
00:06:24,500 --> 00:06:29,540
revocation scan and then inhibits the

148
00:06:27,200 --> 00:06:31,550
subsequent setting of the bias for the

149
00:06:29,540 --> 00:06:34,040
duration of that time multiplied by some

150
00:06:31,550 --> 00:06:36,770
constant factor so the fact that was

151
00:06:34,040 --> 00:06:38,720
chosen that the worst case expected fall

152
00:06:36,770 --> 00:06:41,450
down from Bravo would be below certain

153
00:06:38,720 --> 00:06:42,920
threshold so in our case it's which

154
00:06:41,450 --> 00:06:46,760
shows the factor of 10%

155
00:06:42,920 --> 00:06:48,060
so to give you a concrete example for

156
00:06:46,760 --> 00:06:51,450
instance if the revocation

157
00:06:48,060 --> 00:06:54,060
Ian takes 10 milliseconds we inhibit

158
00:06:51,450 --> 00:06:56,789
sailing Dobbins flag for the next 100

159
00:06:54,060 --> 00:06:58,980
milliseconds by writing a tape a time

160
00:06:56,790 --> 00:07:01,650
and value into the inhibit until field

161
00:06:58,980 --> 00:07:03,600
and thus effectively disabling Bravo for

162
00:07:01,650 --> 00:07:05,909
the next 100 milliseconds in this case

163
00:07:03,600 --> 00:07:08,340
in using the acquisition functions of

164
00:07:05,910 --> 00:07:10,650
the underlying lock instead now this

165
00:07:08,340 --> 00:07:12,780
scheme is over simplistic and might be

166
00:07:10,650 --> 00:07:14,640
too conservative but we found that it's

167
00:07:12,780 --> 00:07:18,799
actually working is working really well

168
00:07:14,640 --> 00:07:21,300
in practice and very simple to implement

169
00:07:18,800 --> 00:07:23,910
with that I can finally explain how we

170
00:07:21,300 --> 00:07:26,100
said that our bias a flag and that's a

171
00:07:23,910 --> 00:07:28,950
pretty straightforward so when a reader

172
00:07:26,100 --> 00:07:30,930
acquires the walk in the read node it

173
00:07:28,950 --> 00:07:32,820
checks whether the our bias flag is not

174
00:07:30,930 --> 00:07:35,520
set and whether the current time is

175
00:07:32,820 --> 00:07:39,659
larger than the value currently written

176
00:07:35,520 --> 00:07:41,669
in the inhibit and teal field if that's

177
00:07:39,660 --> 00:07:43,920
the case it says the our bias flag

178
00:07:41,670 --> 00:07:46,350
essentially enabling subsequent read

179
00:07:43,920 --> 00:07:53,100
acquisitions to follow the fast paths

180
00:07:46,350 --> 00:07:56,160
and and use the table again so this

181
00:07:53,100 --> 00:07:58,080
essentially concludes the technical

182
00:07:56,160 --> 00:07:59,370
presentation of how power works and now

183
00:07:58,080 --> 00:08:01,520
I would like to talk about our

184
00:07:59,370 --> 00:08:03,960
evaluation so the goals of our

185
00:08:01,520 --> 00:08:05,909
evaluation were to show that Brava is

186
00:08:03,960 --> 00:08:09,090
easy to integrate with existing locks

187
00:08:05,910 --> 00:08:11,280
it's compact it accelerates reads and it

188
00:08:09,090 --> 00:08:13,409
handles writes gracefully so doesn't

189
00:08:11,280 --> 00:08:16,169
fall us all down writes and we achieved

190
00:08:13,410 --> 00:08:20,940
those goals both in the user space as

191
00:08:16,170 --> 00:08:23,220
well and Aquino so for the first part to

192
00:08:20,940 --> 00:08:25,560
demonstrate how Brava can be integrated

193
00:08:23,220 --> 00:08:28,080
easily with existing walks we did the

194
00:08:25,560 --> 00:08:30,240
integration with the compact and

195
00:08:28,080 --> 00:08:32,760
efficient reading book Anderson or be a

196
00:08:30,240 --> 00:08:36,480
reader writer walk as well as would be

197
00:08:32,760 --> 00:08:38,700
POSIX pieces reader/writer lock so from

198
00:08:36,480 --> 00:08:40,050
the perspective of Bravo POSIX pieces

199
00:08:38,700 --> 00:08:41,940
lock is really in a pack lock

200
00:08:40,049 --> 00:08:44,880
implementation we build brow as a

201
00:08:41,940 --> 00:08:47,270
wrapper that can be used with any reader

202
00:08:44,880 --> 00:08:49,350
writer walk in the user space

203
00:08:47,270 --> 00:08:51,510
furthermore we integrate the browser

204
00:08:49,350 --> 00:08:53,490
with the Linux kernel how W semaphore

205
00:08:51,510 --> 00:08:56,160
and I'll talk about this integration

206
00:08:53,490 --> 00:08:57,630
later but I'll just mention for now that

207
00:08:56,160 --> 00:08:58,050
in each and every case including the

208
00:08:57,630 --> 00:09:00,420
Keano

209
00:08:58,050 --> 00:09:03,020
the integration of our cloud just a few

210
00:09:00,420 --> 00:09:05,219
thousand lines of code

211
00:09:03,020 --> 00:09:07,110
now this slide shows the memory

212
00:09:05,220 --> 00:09:09,480
requirements for Bravo taking the be a

213
00:09:07,110 --> 00:09:11,220
lock is an example the be a lock

214
00:09:09,480 --> 00:09:13,470
requires just 40 bytes for it's for

215
00:09:11,220 --> 00:09:16,200
pointers into integer fields

216
00:09:13,470 --> 00:09:18,210
Bravo adds two fields which a consulted

217
00:09:16,200 --> 00:09:20,220
a required most 12 bytes even those I

218
00:09:18,210 --> 00:09:21,960
mentioned before those two two new

219
00:09:20,220 --> 00:09:24,960
fields can be co-located and use even

220
00:09:21,960 --> 00:09:27,570
less memory now that if the lock is

221
00:09:24,960 --> 00:09:29,670
padded and aligned to the size of the

222
00:09:27,570 --> 00:09:32,310
cache line or cache sector which are

223
00:09:29,670 --> 00:09:35,160
typically 64 128 bytes and that's

224
00:09:32,310 --> 00:09:37,439
actually petting and aligning walks is a

225
00:09:35,160 --> 00:09:40,650
common practice in real deployments

226
00:09:37,440 --> 00:09:43,200
so both Bravo and Bravo integrate sorry

227
00:09:40,650 --> 00:09:45,540
both VA and the be a lock integrated

228
00:09:43,200 --> 00:09:48,930
with Bravo required just one cache line

229
00:09:45,540 --> 00:09:50,969
or one cache sector of course in brown

230
00:09:48,930 --> 00:09:53,839
we also have the cost of the visible

231
00:09:50,970 --> 00:09:56,430
readers table now for our experiments we

232
00:09:53,840 --> 00:09:59,910
selected a table size of 4,000 entries

233
00:09:56,430 --> 00:10:01,650
or 4,000 pointers and that selection was

234
00:09:59,910 --> 00:10:03,150
made in periodically but in general we

235
00:10:01,650 --> 00:10:05,069
believed that the size should be a

236
00:10:03,150 --> 00:10:07,740
function of the number of logical cpus

237
00:10:05,070 --> 00:10:11,130
in the system much like the few weeks

238
00:10:07,740 --> 00:10:13,320
tables are sized in the linux kernel but

239
00:10:11,130 --> 00:10:15,600
there the memory size of the table comes

240
00:10:13,320 --> 00:10:18,180
down to 32 kilobytes but this cost

241
00:10:15,600 --> 00:10:19,770
becomes amortized and ingredie ball when

242
00:10:18,180 --> 00:10:23,219
thousands of reader/writer walks are

243
00:10:19,770 --> 00:10:24,480
used in an application now in comparison

244
00:10:23,220 --> 00:10:26,880
we also include two locks with

245
00:10:24,480 --> 00:10:29,370
distributed reader indicators one is

246
00:10:26,880 --> 00:10:31,950
called per CPUs and its name suggests it

247
00:10:29,370 --> 00:10:36,180
uses a per CPU reader indicator which

248
00:10:31,950 --> 00:10:39,720
are now system with 72 CPUs comes down

249
00:10:36,180 --> 00:10:43,530
to over 9000 bytes now another example

250
00:10:39,720 --> 00:10:46,470
is called our W walk which it uses a

251
00:10:43,530 --> 00:10:50,490
reader indicator per Numa node and anau

252
00:10:46,470 --> 00:10:52,410
do also keep system these logs come the

253
00:10:50,490 --> 00:10:53,610
footprint of this wall comes down to

254
00:10:52,410 --> 00:10:56,640
almost 900 bytes

255
00:10:53,610 --> 00:10:58,589
note that this is because for each and

256
00:10:56,640 --> 00:11:02,939
every such log it's not amortized when

257
00:10:58,589 --> 00:11:05,339
mul oxide used now in this chart we'll

258
00:11:02,940 --> 00:11:07,740
compare the performance of B a and P

259
00:11:05,339 --> 00:11:08,940
thread reader idle walks with the very

260
00:11:07,740 --> 00:11:12,810
ended

261
00:11:08,940 --> 00:11:14,760
variants that use Bravo as as baseline

262
00:11:12,810 --> 00:11:17,310
we also include the two locks with the

263
00:11:14,760 --> 00:11:19,740
CVT 3d indicators from the previous

264
00:11:17,310 --> 00:11:23,250
slide the Accord of w lock and the per

265
00:11:19,740 --> 00:11:25,200
CPU the world code here is generated by

266
00:11:23,250 --> 00:11:27,150
synthetic benchmark where threads

267
00:11:25,200 --> 00:11:29,180
perform law operations inside and

268
00:11:27,150 --> 00:11:31,890
outside of the critical section

269
00:11:29,180 --> 00:11:33,540
protected by reader/writer lock where in

270
00:11:31,890 --> 00:11:36,150
this case the lock is required for write

271
00:11:33,540 --> 00:11:39,510
on in 1 out of every 10,000 operations

272
00:11:36,150 --> 00:11:42,180
on average so the workout is really read

273
00:11:39,510 --> 00:11:44,939
AMA nated so here we show the throughput

274
00:11:42,180 --> 00:11:47,819
and the highest better and we can see at

275
00:11:44,940 --> 00:11:51,120
the bottom of this chart that both B a

276
00:11:47,820 --> 00:11:52,650
and B that reader idle walks do not

277
00:11:51,120 --> 00:11:55,920
scale at all as we increase the number

278
00:11:52,650 --> 00:11:58,709
of threads and that's because they use

279
00:11:55,920 --> 00:12:03,150
the contended reader indicators which

280
00:11:58,710 --> 00:12:06,000
yields a flat performance now call Wu's

281
00:12:03,150 --> 00:12:08,760
modest improvement to the performance

282
00:12:06,000 --> 00:12:12,030
but the interesting point here is that

283
00:12:08,760 --> 00:12:16,590
Bravo ba and Bravo pthread scale really

284
00:12:12,030 --> 00:12:18,870
well and perform a similar to the per

285
00:12:16,590 --> 00:12:22,320
CPU walk while using just a fraction of

286
00:12:18,870 --> 00:12:24,330
its memory now let's see what happens

287
00:12:22,320 --> 00:12:28,560
when the workout includes more write

288
00:12:24,330 --> 00:12:31,320
operations so in this case 9 out of 10

289
00:12:28,560 --> 00:12:34,739
operations are writes on average the

290
00:12:31,320 --> 00:12:37,410
this workload is a very red heavy and we

291
00:12:34,740 --> 00:12:39,300
see poor scholar scalability over all

292
00:12:37,410 --> 00:12:42,360
the logs just by the virtue of the

293
00:12:39,300 --> 00:12:45,329
highly civilized nature of the workload

294
00:12:42,360 --> 00:12:49,470
the per CPU lock at the bottom of the

295
00:12:45,330 --> 00:12:52,020
chart fares a particularly poorly as as

296
00:12:49,470 --> 00:12:55,850
write operations which are common need

297
00:12:52,020 --> 00:12:59,310
to scan the entire array of per CPU

298
00:12:55,850 --> 00:13:01,740
reader indicators now the interesting

299
00:12:59,310 --> 00:13:04,439
point here is that the Bravo BA in Bravo

300
00:13:01,740 --> 00:13:07,110
pthread locks track closely to their

301
00:13:04,440 --> 00:13:10,320
counterparts without Bravo providing

302
00:13:07,110 --> 00:13:13,950
native benefit nor harm as as we would

303
00:13:10,320 --> 00:13:17,010
like to see so there are many

304
00:13:13,950 --> 00:13:20,820
interesting points between 90% biases in

305
00:13:17,010 --> 00:13:22,170
this chart and 0.01% writes isn't the

306
00:13:20,820 --> 00:13:24,660
previous child

307
00:13:22,170 --> 00:13:26,849
and the our paper includes transform any

308
00:13:24,660 --> 00:13:29,250
of those points in the paper were also

309
00:13:26,850 --> 00:13:30,959
present results for other benchmarks

310
00:13:29,250 --> 00:13:34,350
including the popular key value store

311
00:13:30,959 --> 00:13:36,300
rocks DB for which Bravo also provides a

312
00:13:34,350 --> 00:13:39,139
dramatic improvement to the scalability

313
00:13:36,300 --> 00:13:42,180
of the underlying reader/writer locks

314
00:13:39,139 --> 00:13:44,130
however I would like to show that Bravo

315
00:13:42,180 --> 00:13:45,689
can be beneficial not just to user level

316
00:13:44,130 --> 00:13:48,029
locks but also to synchronization

317
00:13:45,690 --> 00:13:50,639
contacts found in the operating system

318
00:13:48,029 --> 00:13:52,199
piano as an example we demonstrated by

319
00:13:50,639 --> 00:13:56,190
integrated borrow into the audible

320
00:13:52,199 --> 00:13:57,510
semaphore in the Linux kernel so the LW

321
00:13:56,190 --> 00:14:00,000
semaphore is implemented with the

322
00:13:57,510 --> 00:14:02,910
counter in the waiting queue protected

323
00:14:00,000 --> 00:14:04,589
by a spin lock the counter keeps track

324
00:14:02,910 --> 00:14:07,050
of the number of readers and also

325
00:14:04,589 --> 00:14:08,430
records the presence of the writer now

326
00:14:07,050 --> 00:14:11,699
when a writer is not present the

327
00:14:08,430 --> 00:14:13,920
acquisition of the LW semaphore for e it

328
00:14:11,699 --> 00:14:17,849
boils down to just one atop atomic

329
00:14:13,920 --> 00:14:19,560
counter increment note however that this

330
00:14:17,850 --> 00:14:21,449
is this read acquisition creates

331
00:14:19,560 --> 00:14:24,000
contention of the cache when hosting the

332
00:14:21,449 --> 00:14:27,689
counter which is where Bravo can be

333
00:14:24,000 --> 00:14:30,480
useful now the reason that we chose to

334
00:14:27,690 --> 00:14:33,449
focus on LW semaphore is because one of

335
00:14:30,480 --> 00:14:35,250
its instances called M epsom is the

336
00:14:33,449 --> 00:14:38,219
serious well-known synchronization

337
00:14:35,250 --> 00:14:40,440
bottleneck in the key on o MF semaphore

338
00:14:38,220 --> 00:14:45,120
protects access to the future a memory

339
00:14:40,440 --> 00:14:48,600
area VMA of the process so so every VMI

340
00:14:45,120 --> 00:14:52,110
operation such as mmm unmet or page fall

341
00:14:48,600 --> 00:14:54,480
the interrupts acquired the ma semaphore

342
00:14:52,110 --> 00:14:59,040
creating contention for data intensive

343
00:14:54,480 --> 00:15:00,750
applications now to evaluate the impact

344
00:14:59,040 --> 00:15:02,969
of Bravo on the performance of MF

345
00:15:00,750 --> 00:15:04,760
semaphore we used we would scale which

346
00:15:02,970 --> 00:15:06,990
is an open source collection of

347
00:15:04,760 --> 00:15:09,420
benchmarks for stress testing various

348
00:15:06,990 --> 00:15:11,130
kernel subsystems in our case the

349
00:15:09,420 --> 00:15:15,920
relevant benchmarks were page fault and

350
00:15:11,130 --> 00:15:18,329
M have a page fault create mostly read

351
00:15:15,920 --> 00:15:20,579
dominated workload since page fault

352
00:15:18,329 --> 00:15:23,550
interrupt acquire MF semaphore for read

353
00:15:20,579 --> 00:15:26,069
and MF create write heavy workload since

354
00:15:23,550 --> 00:15:30,359
those separations they acquired a.m. at

355
00:15:26,069 --> 00:15:32,729
SFO for right so in those charts we can

356
00:15:30,360 --> 00:15:34,589
see that in the page hold example again

357
00:15:32,730 --> 00:15:35,550
we show of troop was so high as better

358
00:15:34,589 --> 00:15:37,440
the

359
00:15:35,550 --> 00:15:39,660
Bravo version skills across also at

360
00:15:37,440 --> 00:15:42,120
gowns while the stock version stopped

361
00:15:39,660 --> 00:15:44,339
scaling after about 16 threats when the

362
00:15:42,120 --> 00:15:47,430
contention on the counter in the iOW

363
00:15:44,339 --> 00:15:49,740
semaphore becomes significant at the

364
00:15:47,430 --> 00:15:51,839
same time a map exhibits no significant

365
00:15:49,740 --> 00:15:54,029
difference in the performance of brow

366
00:15:51,839 --> 00:15:56,910
versus talk confirming empirically that

367
00:15:54,029 --> 00:15:58,860
much like in the user space bravo

368
00:15:56,910 --> 00:16:00,860
doesn't reduce overhead in scenarios

369
00:15:58,860 --> 00:16:04,079
where it's not profitable

370
00:16:00,860 --> 00:16:05,430
so in summary bravo is a rapper that can

371
00:16:04,079 --> 00:16:07,829
be easily integrated with any

372
00:16:05,430 --> 00:16:10,680
reader/writer lock bravo accelerates

373
00:16:07,829 --> 00:16:12,630
reads by reducing a coherence cost that

374
00:16:10,680 --> 00:16:15,719
would normally be incurred by logs

375
00:16:12,630 --> 00:16:17,939
heavenly central reader indicator write

376
00:16:15,720 --> 00:16:20,820
performance is left and change relative

377
00:16:17,940 --> 00:16:23,060
to the underlying log bankers very small

378
00:16:20,820 --> 00:16:25,950
footprint increase per lock instance and

379
00:16:23,060 --> 00:16:28,439
overall it takes the reader indicator

380
00:16:25,950 --> 00:16:30,180
dealer my way so with that I would like

381
00:16:28,440 --> 00:16:32,400
to thank you for attention and I'll be

382
00:16:30,180 --> 00:16:38,549
happy to take your questions

383
00:16:32,400 --> 00:16:38,549
[Applause]

384
00:16:43,120 --> 00:16:51,040
I've been of the girl Dell so if in the

385
00:16:48,040 --> 00:16:52,300
current leader I'd lock the reader

386
00:16:51,040 --> 00:16:54,010
writers are only affecting each other

387
00:16:52,300 --> 00:16:54,969
but they're not they're not affecting

388
00:16:54,010 --> 00:16:56,950
each other they're only affecting the

389
00:16:54,970 --> 00:16:59,470
own lock but in this case because you

390
00:16:56,950 --> 00:17:01,930
have a common table any writer is

391
00:16:59,470 --> 00:17:05,500
affecting everyone else so isn't that a

392
00:17:01,930 --> 00:17:06,730
problem is it won't any writer cause the

393
00:17:05,500 --> 00:17:12,010
all the readers and the writers to

394
00:17:06,730 --> 00:17:16,240
actually gets get stalled so the

395
00:17:12,010 --> 00:17:18,910
conflicts indeed can have impact on the

396
00:17:16,240 --> 00:17:21,099
performance right now paper will include

397
00:17:18,910 --> 00:17:23,400
evaluation of an experiment where we

398
00:17:21,099 --> 00:17:29,320
measure the impact of those conflicts

399
00:17:23,400 --> 00:17:30,760
right and we show that compared to to an

400
00:17:29,320 --> 00:17:33,429
optimal case where there are no

401
00:17:30,760 --> 00:17:35,770
conflicts at all where each you know

402
00:17:33,430 --> 00:17:38,350
thread will use a separate table set or

403
00:17:35,770 --> 00:17:41,200
cough table the impact of those

404
00:17:38,350 --> 00:17:45,669
conflicts is is very small something

405
00:17:41,200 --> 00:17:47,170
like less than 6% and how do you handle

406
00:17:45,670 --> 00:17:49,720
the situation where the table is not big

407
00:17:47,170 --> 00:17:51,760
enough like because you need to know pre

408
00:17:49,720 --> 00:17:53,200
you need to know how many locks are that

409
00:17:51,760 --> 00:17:56,320
can fit in the table so if the dog

410
00:17:53,200 --> 00:17:58,930
exceeds what do you do right so in our

411
00:17:56,320 --> 00:18:01,139
work we we have and actually in the

412
00:17:58,930 --> 00:18:03,820
paper we stated you know list of

413
00:18:01,140 --> 00:18:05,680
directions future directions that we

414
00:18:03,820 --> 00:18:08,260
would like to explore and you know the

415
00:18:05,680 --> 00:18:12,880
first one on the list is dynamic table

416
00:18:08,260 --> 00:18:15,730
sizing right so we can you know try to

417
00:18:12,880 --> 00:18:18,370
increase the size of the table just by

418
00:18:15,730 --> 00:18:21,100
measuring the rate of collisions and do

419
00:18:18,370 --> 00:18:22,750
that dynamically and that's you know we

420
00:18:21,100 --> 00:18:26,370
can size the table according to that

421
00:18:22,750 --> 00:18:26,370
okay thank you sure

422
00:18:27,990 --> 00:18:36,259
that's wondering if you compared this to

423
00:18:31,009 --> 00:18:39,570
MCS locks so mcs locks are not

424
00:18:36,259 --> 00:18:42,119
reader/writer logs right there are mcs

425
00:18:39,570 --> 00:18:47,369
reader/writer locks oh yeah there is a

426
00:18:42,119 --> 00:18:53,100
variant of mcs reader/writer lock no we

427
00:18:47,369 --> 00:18:55,049
haven't compared to those so there

428
00:18:53,100 --> 00:18:57,330
shouldn't this have you encountered

429
00:18:55,049 --> 00:18:59,789
cases either in the linux kernel or

430
00:18:57,330 --> 00:19:03,090
applications where the revocation time

431
00:18:59,789 --> 00:19:05,009
was high or where you have to

432
00:19:03,090 --> 00:19:10,799
exponentially back off because of the

433
00:19:05,009 --> 00:19:12,539
revocation sorry so have we encounter

434
00:19:10,799 --> 00:19:16,499
encountered applications where the

435
00:19:12,539 --> 00:19:17,850
revocation time was high because let's

436
00:19:16,499 --> 00:19:20,850
say if there was a writer that's waiting

437
00:19:17,850 --> 00:19:22,740
for all the readers to complete and you

438
00:19:20,850 --> 00:19:25,649
have to keep waiting for the readers for

439
00:19:22,740 --> 00:19:29,129
that for the writer to write so the

440
00:19:25,649 --> 00:19:31,379
revocation scan can be expensive right

441
00:19:29,129 --> 00:19:33,840
but that's why we have this mechanism in

442
00:19:31,379 --> 00:19:37,590
place so that you know we ensure that it

443
00:19:33,840 --> 00:19:39,840
will happen once in a in a relatively

444
00:19:37,590 --> 00:19:42,899
long while now the other point that I

445
00:19:39,840 --> 00:19:45,740
want to highlight that probably once in

446
00:19:42,899 --> 00:19:47,998
our lifetime we finally have the

447
00:19:45,740 --> 00:19:50,850
hardware prefetcher working in our

448
00:19:47,999 --> 00:19:52,309
advantage right so when we scan and you

449
00:19:50,850 --> 00:19:55,709
know there are no that many readers

450
00:19:52,309 --> 00:19:59,460
around the prefetcher will make the disk

451
00:19:55,710 --> 00:20:02,249
and much more efficient now another

452
00:19:59,460 --> 00:20:04,350
point is that while we wait for you know

453
00:20:02,249 --> 00:20:07,139
one reader that we find in the table

454
00:20:04,350 --> 00:20:11,340
those are other readers that can be you

455
00:20:07,139 --> 00:20:13,590
know write down the table and the slot

456
00:20:11,340 --> 00:20:15,990
order may finish their critical sections

457
00:20:13,590 --> 00:20:18,360
and exit so we don't necessarily wait

458
00:20:15,990 --> 00:20:20,460
you know sequentially for one reader and

459
00:20:18,360 --> 00:20:23,279
then they out and then the third one so

460
00:20:20,460 --> 00:20:25,049
like it's a kind of you know we wait in

461
00:20:23,279 --> 00:20:26,999
parallel for all those readers even

462
00:20:25,049 --> 00:20:29,690
though that will probe just one location

463
00:20:26,999 --> 00:20:29,690
in the table

464
00:20:33,690 --> 00:20:38,190
all right if there's no more questions

465
00:20:35,530 --> 00:20:42,999
let's thank our speaker again

466
00:20:38,190 --> 00:20:42,999
[Applause]

