1
00:00:10,299 --> 00:00:14,949
good morning everyone it is my great

2
00:00:13,269 --> 00:00:17,410
pleasure to be here to present our

3
00:00:14,949 --> 00:00:19,840
recent research dynamic upon

4
00:00:17,410 --> 00:00:21,698
auscultation the first authors home

5
00:00:19,840 --> 00:00:23,349
cannot be here due to obvious idea so I

6
00:00:21,699 --> 00:00:26,020
will have him to present the paper

7
00:00:23,349 --> 00:00:28,660
ok let's table dynamic banner

8
00:00:26,020 --> 00:00:31,570
translation or DBT for short is a key

9
00:00:28,660 --> 00:00:34,300
enabling technology in general DBT

10
00:00:31,570 --> 00:00:36,489
systems translated binary code from a

11
00:00:34,300 --> 00:00:38,919
guest in dragon set to a host

12
00:00:36,489 --> 00:00:42,160
interacting set and executes the

13
00:00:38,920 --> 00:00:44,829
translated host a binary code previous

14
00:00:42,160 --> 00:00:48,398
studies have shown that in most cases

15
00:00:44,829 --> 00:00:51,190
the execution time of our DVD system is

16
00:00:48,399 --> 00:00:53,710
mainly consumed by executing the

17
00:00:51,190 --> 00:00:56,500
translated who's the binary code so

18
00:00:53,710 --> 00:00:59,829
generally high quality host binary code

19
00:00:56,500 --> 00:01:04,360
it were important to the efficiency of a

20
00:00:59,829 --> 00:01:07,210
DVD system to implement deeply systems a

21
00:01:04,360 --> 00:01:10,210
common way is to use intermediate

22
00:01:07,210 --> 00:01:13,119
representations or aiya we can falsely

23
00:01:10,210 --> 00:01:16,329
translate as a binary code to aya and

24
00:01:13,119 --> 00:01:20,439
perform optimizations higher to generate

25
00:01:16,329 --> 00:01:23,229
efficient hosts binary code however this

26
00:01:20,439 --> 00:01:26,859
approach has at least two limitations

27
00:01:23,229 --> 00:01:28,929
first the runtime optimizations can

28
00:01:26,859 --> 00:01:29,439
introduce very heavy translation

29
00:01:28,929 --> 00:01:32,799
overhead

30
00:01:29,439 --> 00:01:34,809
this is undesirable for DD system

31
00:01:32,799 --> 00:01:37,600
especially for shorter run in Kassel

32
00:01:34,810 --> 00:01:39,729
application because extremum of this

33
00:01:37,600 --> 00:01:42,428
application is many consumable in the

34
00:01:39,729 --> 00:01:46,299
translation process another limitation

35
00:01:42,429 --> 00:01:48,609
of this approach is that it requires a

36
00:01:46,299 --> 00:01:50,469
significant engineering effort to

37
00:01:48,609 --> 00:01:54,038
support different host architectures

38
00:01:50,469 --> 00:01:56,770
because the host specific optimizations

39
00:01:54,039 --> 00:01:59,740
need to be redeveloped to support

40
00:01:56,770 --> 00:02:02,939
different hosts to address these

41
00:01:59,740 --> 00:02:06,219
limitations our previous research work

42
00:02:02,939 --> 00:02:09,220
proposed a new approach to automatically

43
00:02:06,219 --> 00:02:11,590
learn panel translation rules this is

44
00:02:09,220 --> 00:02:14,650
inspired by the observation that the

45
00:02:11,590 --> 00:02:18,069
binary code compiled from the same

46
00:02:14,650 --> 00:02:20,590
source code using the same compiler for

47
00:02:18,069 --> 00:02:22,920
different architectures as semantically

48
00:02:20,590 --> 00:02:24,599
equivalent from

49
00:02:22,920 --> 00:02:26,700
this observation we can directly

50
00:02:24,599 --> 00:02:30,750
interact the translation rule from the

51
00:02:26,700 --> 00:02:34,079
compiled binaries this translation rule

52
00:02:30,750 --> 00:02:37,500
can map guest interaction directly to

53
00:02:34,080 --> 00:02:39,020
host interactions better it if the

54
00:02:37,500 --> 00:02:42,180
original compilation process

55
00:02:39,020 --> 00:02:44,790
incorporates optimizations the

56
00:02:42,180 --> 00:02:47,790
attractive translation rule will also

57
00:02:44,790 --> 00:02:52,230
embody these optimizations now let's see

58
00:02:47,790 --> 00:02:55,290
how this approach works first during the

59
00:02:52,230 --> 00:02:57,390
compilation process the guest

60
00:02:55,290 --> 00:02:59,489
interactions and the host in practice

61
00:02:57,390 --> 00:03:02,399
that correspond to the same learning

62
00:02:59,489 --> 00:03:05,940
scope I extracted here the learners

63
00:03:02,400 --> 00:03:08,730
group is one line of source code each

64
00:03:05,940 --> 00:03:12,930
pair of the extracted guest and host

65
00:03:08,730 --> 00:03:16,079
interaction from a translation room next

66
00:03:12,930 --> 00:03:18,120
to currently the correctness of the

67
00:03:16,080 --> 00:03:21,750
learner translation rule we need to

68
00:03:18,120 --> 00:03:24,060
verify them to achieve this we verify

69
00:03:21,750 --> 00:03:25,799
the semantic equivalence between the

70
00:03:24,060 --> 00:03:27,690
Kasserine dragon and the hostile

71
00:03:25,799 --> 00:03:30,989
interaction in a learner translation

72
00:03:27,690 --> 00:03:35,070
rules not equivalent translation rule

73
00:03:30,989 --> 00:03:36,750
assembly discarded finally during the

74
00:03:35,070 --> 00:03:38,660
translation process the learner

75
00:03:36,750 --> 00:03:41,340
translation rule can be applied to

76
00:03:38,660 --> 00:03:45,359
translate guest interaction into host

77
00:03:41,340 --> 00:03:48,239
interaction directly with this learning

78
00:03:45,359 --> 00:03:51,060
based approach we already achieved 25

79
00:03:48,239 --> 00:03:55,260
performance performance improvement

80
00:03:51,060 --> 00:03:59,640
compared to existing ir best translation

81
00:03:55,260 --> 00:04:01,980
approach the question here is can we

82
00:03:59,640 --> 00:04:06,660
further improve the performance using

83
00:04:01,980 --> 00:04:09,090
this approach this figure shows the

84
00:04:06,660 --> 00:04:11,160
translation coverage achieved by using

85
00:04:09,090 --> 00:04:14,549
the translation rules learned using this

86
00:04:11,160 --> 00:04:16,709
approach here the courage' means the

87
00:04:14,549 --> 00:04:19,350
percentage of the guest interactions

88
00:04:16,709 --> 00:04:22,169
that can be translated using the learner

89
00:04:19,350 --> 00:04:23,940
translation rules for those caster

90
00:04:22,169 --> 00:04:25,620
interactions that cannot be covered by

91
00:04:23,940 --> 00:04:28,830
the learner translation rule which you

92
00:04:25,620 --> 00:04:32,099
need to go through the original ir best

93
00:04:28,830 --> 00:04:34,530
approach to translate them all so in

94
00:04:32,099 --> 00:04:36,360
this figure with any to 55 percent

95
00:04:34,530 --> 00:04:38,250
coverage let me

96
00:04:36,360 --> 00:04:41,849
almost half of the cursor interactions

97
00:04:38,250 --> 00:04:45,599
we cannot use the learner translation

98
00:04:41,849 --> 00:04:48,000
rule to translate them so if we can have

99
00:04:45,599 --> 00:04:50,039
it the more translation rules during the

100
00:04:48,000 --> 00:04:52,379
learning process we can potentially

101
00:04:50,039 --> 00:04:55,770
improve the translation coverage and

102
00:04:52,379 --> 00:04:58,800
generate more optimized binary code this

103
00:04:55,770 --> 00:05:01,530
is a motivation of this work to achieve

104
00:04:58,800 --> 00:05:05,969
this we must address some limitations in

105
00:05:01,530 --> 00:05:08,580
the original learning best approach the

106
00:05:05,969 --> 00:05:12,120
first elimination is about as limited

107
00:05:08,580 --> 00:05:13,919
learning scope in the original learning

108
00:05:12,120 --> 00:05:18,139
approach the learning scope is limited

109
00:05:13,919 --> 00:05:22,139
to one line of source code although this

110
00:05:18,139 --> 00:05:25,379
can simplify the design of the learning

111
00:05:22,139 --> 00:05:27,750
approach it may also miss many potential

112
00:05:25,379 --> 00:05:30,389
translation rule let's see this example

113
00:05:27,750 --> 00:05:33,139
in this example we have two lines of

114
00:05:30,389 --> 00:05:37,469
source code we can use a compiler

115
00:05:33,139 --> 00:05:40,229
targeting for am for example irvm am to

116
00:05:37,469 --> 00:05:42,539
compare them to M interactions here we

117
00:05:40,229 --> 00:05:45,650
use the same color to indicate the

118
00:05:42,539 --> 00:05:48,090
source experiment and as a corresponding

119
00:05:45,650 --> 00:05:50,190
interaction generated from this source

120
00:05:48,090 --> 00:05:53,729
segment or shown in the figure we have

121
00:05:50,190 --> 00:05:56,819
two interactions similarly we can use

122
00:05:53,729 --> 00:05:59,940
the compiler error VM classics to

123
00:05:56,819 --> 00:06:03,180
compare these elements into a classics

124
00:05:59,940 --> 00:06:05,279
interaction due to the optimization

125
00:06:03,180 --> 00:06:07,969
across the source lines only one a

126
00:06:05,279 --> 00:06:10,949
classics interaction is generated so

127
00:06:07,969 --> 00:06:14,250
obviously in this example if we use one

128
00:06:10,949 --> 00:06:17,430
a single line or the learning scope we

129
00:06:14,250 --> 00:06:19,560
cannot learn any translation rule for

130
00:06:17,430 --> 00:06:21,930
the first source line there is no a

131
00:06:19,560 --> 00:06:25,229
classics interaction for the second

132
00:06:21,930 --> 00:06:27,690
assault line the stable interaction and

133
00:06:25,229 --> 00:06:31,409
the Agra six area interaction are not

134
00:06:27,690 --> 00:06:35,039
semantically equivalent but this

135
00:06:31,409 --> 00:06:36,479
provides us an opportunity to exploit

136
00:06:35,039 --> 00:06:41,068
the translation rules there are some

137
00:06:36,479 --> 00:06:43,490
multiple lines of source code another

138
00:06:41,069 --> 00:06:47,039
limitation in cost by the strict

139
00:06:43,490 --> 00:06:50,160
equivalence to verification the purpose

140
00:06:47,039 --> 00:06:52,890
of the some verification into word

141
00:06:50,160 --> 00:06:55,020
five this register and memory

142
00:06:52,890 --> 00:06:57,120
equivalence between the guest and host

143
00:06:55,020 --> 00:07:00,539
interaction in the learner translation

144
00:06:57,120 --> 00:07:01,080
rules however this equivalence word

145
00:07:00,540 --> 00:07:03,690
fication

146
00:07:01,080 --> 00:07:07,169
may also describe many potential

147
00:07:03,690 --> 00:07:10,590
translation rules as this example in

148
00:07:07,170 --> 00:07:14,100
this example the source line X plus plus

149
00:07:10,590 --> 00:07:18,530
is compared to three interactions and

150
00:07:14,100 --> 00:07:21,210
one a classics interaction respectively

151
00:07:18,530 --> 00:07:23,729
to verify the semantic equivalence

152
00:07:21,210 --> 00:07:26,330
between the interaction and the a

153
00:07:23,730 --> 00:07:29,610
classics interaction the original

154
00:07:26,330 --> 00:07:32,969
learning approach try to establish

155
00:07:29,610 --> 00:07:35,610
mappings between the operands and the

156
00:07:32,970 --> 00:07:38,940
classics operand for example the M

157
00:07:35,610 --> 00:07:43,020
register r1 can be mapped to a classic

158
00:07:38,940 --> 00:07:45,870
register eggs however we cannot find a

159
00:07:43,020 --> 00:07:49,169
classics register that can be can use

160
00:07:45,870 --> 00:07:52,500
can be used to map the arm register as

161
00:07:49,170 --> 00:07:55,560
there so this translation rule will be

162
00:07:52,500 --> 00:07:59,580
considered as equivalent and we had to

163
00:07:55,560 --> 00:08:01,710
be discarded but this provides us an

164
00:07:59,580 --> 00:08:04,370
opportunity to have is the more

165
00:08:01,710 --> 00:08:06,690
translation rule by relaxing the

166
00:08:04,370 --> 00:08:11,820
stricter semantic equivalence

167
00:08:06,690 --> 00:08:15,660
verification to take advantage of these

168
00:08:11,820 --> 00:08:19,830
opportunities we propose the following

169
00:08:15,660 --> 00:08:23,250
solutions in this work first during the

170
00:08:19,830 --> 00:08:26,190
learning process we use a sliding window

171
00:08:23,250 --> 00:08:28,320
to determine the learner's group this

172
00:08:26,190 --> 00:08:32,030
allows us to slide through the source

173
00:08:28,320 --> 00:08:35,240
code and examine multiple lines of

174
00:08:32,030 --> 00:08:39,030
source code to identify translation rule

175
00:08:35,240 --> 00:08:41,909
second during the equivalence the world

176
00:08:39,030 --> 00:08:45,140
fication process we introduced the

177
00:08:41,909 --> 00:08:48,719
notion of control semantic equivalence

178
00:08:45,140 --> 00:08:51,780
where translation rule is augmented with

179
00:08:48,720 --> 00:08:55,650
containing conditions there I mean the

180
00:08:51,780 --> 00:08:57,449
the translation rule is only applied

181
00:08:55,650 --> 00:09:01,910
when the containing conditions are

182
00:08:57,450 --> 00:09:07,009
satisfied now let's see more details

183
00:09:01,910 --> 00:09:10,819
first the sliding window is defined at a

184
00:09:07,009 --> 00:09:13,910
source code level also sediment covered

185
00:09:10,819 --> 00:09:16,300
by the window I use it to attract guests

186
00:09:13,910 --> 00:09:20,990
and hosts the interaction for

187
00:09:16,300 --> 00:09:23,180
translation rule learning each time the

188
00:09:20,990 --> 00:09:25,130
window slides forward one line of source

189
00:09:23,180 --> 00:09:27,979
code and the slides are the last line of

190
00:09:25,130 --> 00:09:31,930
the source code covered by the window by

191
00:09:27,980 --> 00:09:35,720
adjusting the size of the window we can

192
00:09:31,930 --> 00:09:38,719
explore wearable learning schools let's

193
00:09:35,720 --> 00:09:42,980
revisit this example in this example if

194
00:09:38,720 --> 00:09:44,959
we use a window signs with two of two we

195
00:09:42,980 --> 00:09:48,889
can learn a translation like this or

196
00:09:44,959 --> 00:09:51,920
sure in this figure actually our

197
00:09:48,889 --> 00:09:54,889
experimental results show that by just

198
00:09:51,920 --> 00:09:58,339
increasing the sliding window size to 2

199
00:09:54,889 --> 00:10:05,300
we can harvest 13% more translation

200
00:09:58,339 --> 00:10:07,670
rules next to relax the street

201
00:10:05,300 --> 00:10:10,969
equivalence word focaccia we introduced

202
00:10:07,670 --> 00:10:13,310
constrained semantic equivalence most

203
00:10:10,970 --> 00:10:15,800
basically the cursor interactions and

204
00:10:13,310 --> 00:10:18,258
the host interaction in each learner

205
00:10:15,800 --> 00:10:22,040
translational are considered a semantic

206
00:10:18,259 --> 00:10:25,180
equivalent only if the specified

207
00:10:22,040 --> 00:10:28,790
containing conditions are satisfied for

208
00:10:25,180 --> 00:10:30,019
each learner translation rules we record

209
00:10:28,790 --> 00:10:32,990
all unmapped

210
00:10:30,019 --> 00:10:36,920
guest and host registers as a containing

211
00:10:32,990 --> 00:10:38,660
condition as a translation stage the

212
00:10:36,920 --> 00:10:41,060
contrary conditions are checked to

213
00:10:38,660 --> 00:10:43,730
ensure they are satisfied before the

214
00:10:41,060 --> 00:10:46,008
translation rule can be applied now

215
00:10:43,730 --> 00:10:50,029
let's see the previous example in this

216
00:10:46,009 --> 00:10:52,730
examples also I mentioned before the

217
00:10:50,029 --> 00:10:55,579
easiest examples am register r0 is a

218
00:10:52,730 --> 00:10:58,069
mapped so it is included into the

219
00:10:55,579 --> 00:11:01,130
containing condition of this translation

220
00:10:58,069 --> 00:11:04,969
room that means this translation rule

221
00:11:01,130 --> 00:11:09,050
can be applied if the unregister r0 is

222
00:11:04,970 --> 00:11:12,079
not used in the following binary code in

223
00:11:09,050 --> 00:11:14,810
this way we can harvest the 23% more

224
00:11:12,079 --> 00:11:17,910
translation rules

225
00:11:14,810 --> 00:11:20,670
we have implemented these enhancements

226
00:11:17,910 --> 00:11:24,839
in the original learning framework

227
00:11:20,670 --> 00:11:27,719
personal area we also it can cure me

228
00:11:24,840 --> 00:11:29,670
which is a ir best translation system to

229
00:11:27,720 --> 00:11:31,620
accept as a learner translation rule to

230
00:11:29,670 --> 00:11:35,370
generate hosted binary code

231
00:11:31,620 --> 00:11:38,160
our evaluation covers all 12 allocations

232
00:11:35,370 --> 00:11:40,650
from the specs in 2006 for each

233
00:11:38,160 --> 00:11:40,949
application we only apply translation

234
00:11:40,650 --> 00:11:43,199
rules

235
00:11:40,950 --> 00:11:47,460
learn from other related applications

236
00:11:43,200 --> 00:11:50,250
except excluding the evaluator of the

237
00:11:47,460 --> 00:11:53,850
application itself now let's see some

238
00:11:50,250 --> 00:11:56,330
experimental results the first question

239
00:11:53,850 --> 00:11:59,030
we want to answer is whether this

240
00:11:56,330 --> 00:12:02,460
enhancer learning based approach can

241
00:11:59,030 --> 00:12:04,319
improve the translation coverage this

242
00:12:02,460 --> 00:12:06,570
figure shows the translation coverage

243
00:12:04,320 --> 00:12:08,340
achieved by the original learning

244
00:12:06,570 --> 00:12:11,190
approach and as the enhancer learning

245
00:12:08,340 --> 00:12:15,180
approach also in this figure we can

246
00:12:11,190 --> 00:12:18,570
achieve around 30% translation coverage

247
00:12:15,180 --> 00:12:21,510
improvement on average this demonstrates

248
00:12:18,570 --> 00:12:24,990
the effective effectiveness of the

249
00:12:21,510 --> 00:12:30,060
proposed enhancement to improve the

250
00:12:24,990 --> 00:12:32,670
translation coverage next we want to

251
00:12:30,060 --> 00:12:35,729
know the performance impact of the

252
00:12:32,670 --> 00:12:37,860
proposal enhanced learning based

253
00:12:35,730 --> 00:12:40,260
approach this figure shows the

254
00:12:37,860 --> 00:12:42,680
performance speed-up achieved by using

255
00:12:40,260 --> 00:12:44,970
the translation rules learned by the

256
00:12:42,680 --> 00:12:48,150
original learning approach and the

257
00:12:44,970 --> 00:12:51,210
enhanced learning approach and the

258
00:12:48,150 --> 00:12:53,760
performance baseline is existing IR best

259
00:12:51,210 --> 00:12:56,610
translation in qmu without using any

260
00:12:53,760 --> 00:13:00,120
learner translation rule issue in this

261
00:12:56,610 --> 00:13:02,900
figure we can achieve around 1.7

262
00:13:00,120 --> 00:13:06,540
performance times the performance Madhab

263
00:13:02,900 --> 00:13:08,610
average compared to qmu and for some

264
00:13:06,540 --> 00:13:11,339
applications such as Adobe MK and

265
00:13:08,610 --> 00:13:16,400
visible to the performance madaba can be

266
00:13:11,340 --> 00:13:19,380
as high at 2.5 compared to the original

267
00:13:16,400 --> 00:13:22,680
learning based approach we can achieve

268
00:13:19,380 --> 00:13:26,040
around one point ninety times perform

269
00:13:22,680 --> 00:13:27,459
performance adapt this demonstrates the

270
00:13:26,040 --> 00:13:29,589
capability of the

271
00:13:27,459 --> 00:13:32,498
enhanced learning better approach to

272
00:13:29,589 --> 00:13:38,019
generate more optimized host binary code

273
00:13:32,499 --> 00:13:40,629
to conclude in this work we propose

274
00:13:38,019 --> 00:13:43,179
enhanced learning best approach for

275
00:13:40,629 --> 00:13:46,959
dynamic binary translation with the

276
00:13:43,179 --> 00:13:50,230
proposed enhancement 1.19 time the

277
00:13:46,959 --> 00:13:52,899
performance speed up and the 13%

278
00:13:50,230 --> 00:13:57,100
translation coverage improvement

279
00:13:52,899 --> 00:13:59,949
observed while more work can be done to

280
00:13:57,100 --> 00:14:02,379
further improve the performance of a DVD

281
00:13:59,949 --> 00:14:03,309
system implemented using this learning

282
00:14:02,379 --> 00:14:05,999
best approach

283
00:14:03,309 --> 00:14:10,089
we believe the learning best translation

284
00:14:05,999 --> 00:14:13,649
provides us a viable and a promising

285
00:14:10,089 --> 00:14:15,910
direction for implementing TBD systems

286
00:14:13,649 --> 00:14:17,379
this is my talk thanks for your

287
00:14:15,910 --> 00:14:27,850
attention and I would be more than happy

288
00:14:17,379 --> 00:14:33,369
to take questions any questions please

289
00:14:27,850 --> 00:14:36,089
approach the mic hi I would like to know

290
00:14:33,369 --> 00:14:38,649
what's the difference if you change the

291
00:14:36,089 --> 00:14:43,869
sliding window of the size of the window

292
00:14:38,649 --> 00:14:45,069
you mentioned used to right yep so if I

293
00:14:43,869 --> 00:14:48,360
use a lava window

294
00:14:45,069 --> 00:14:51,040
does that mean I can learn faster or

295
00:14:48,360 --> 00:14:52,600
it's not about the efficiency of the

296
00:14:51,040 --> 00:14:54,549
learn it's about the more translation

297
00:14:52,600 --> 00:14:56,259
role that can be learned because in the

298
00:14:54,549 --> 00:14:59,290
original learning approach we only use

299
00:14:56,259 --> 00:15:02,699
one line of source code to attract the

300
00:14:59,290 --> 00:15:05,199
guest and host interactions so if we use

301
00:15:02,699 --> 00:15:07,359
like a two line of source code that we

302
00:15:05,199 --> 00:15:09,998
can learn more translation rules so does

303
00:15:07,360 --> 00:15:12,129
it mean longer because there's more

304
00:15:09,999 --> 00:15:14,769
information in there

305
00:15:12,129 --> 00:15:16,689
well me more information you have two

306
00:15:14,769 --> 00:15:20,220
lines compared to one right yeah we just

307
00:15:16,689 --> 00:15:23,618
extracted like this example

308
00:15:20,220 --> 00:15:25,540
yeah we just use two line of the source

309
00:15:23,619 --> 00:15:27,699
code of the linnaeus ago and is then we

310
00:15:25,540 --> 00:15:30,160
attracted the in our mean packaging the

311
00:15:27,699 --> 00:15:32,170
tool machine and also one a grass 16

312
00:15:30,160 --> 00:15:34,509
tracks in correspondent these two

313
00:15:32,170 --> 00:15:36,399
sources trailmen and again we can verify

314
00:15:34,509 --> 00:15:39,579
the equivalent semantic equivalence

315
00:15:36,399 --> 00:15:41,070
between the I mean dragazine and a class

316
00:15:39,579 --> 00:15:44,170
6 interaction

317
00:15:41,070 --> 00:15:46,990
this provides the flexibility of

318
00:15:44,170 --> 00:15:48,639
learning scope so we need to move on to

319
00:15:46,990 --> 00:15:49,690
other questions I'm sorry so hope you

320
00:15:48,639 --> 00:15:54,339
take it off okay we can talk more

321
00:15:49,690 --> 00:15:55,060
details yeah high genic Rizal University

322
00:15:54,339 --> 00:15:57,220
of Rochester

323
00:15:55,060 --> 00:16:00,670
nice work one question that I have is

324
00:15:57,220 --> 00:16:02,769
that it seems like the the efficacy of

325
00:16:00,670 --> 00:16:04,839
your approach the effectiveness depends

326
00:16:02,769 --> 00:16:06,579
upon what programs are actually used to

327
00:16:04,839 --> 00:16:09,430
learn the rule so have you done

328
00:16:06,579 --> 00:16:11,170
experiments where you've changed the the

329
00:16:09,430 --> 00:16:12,969
programs that you use for learning the

330
00:16:11,170 --> 00:16:14,410
rules and determine whether there's a

331
00:16:12,970 --> 00:16:16,060
correlation between what you use and the

332
00:16:14,410 --> 00:16:19,589
results that you get yeah this is a very

333
00:16:16,060 --> 00:16:22,959
good question actually we are trying to

334
00:16:19,589 --> 00:16:26,290
use a more program like a Java program

335
00:16:22,959 --> 00:16:29,109
or program in different domains to learn

336
00:16:26,290 --> 00:16:32,769
the translation but currently we haven't

337
00:16:29,110 --> 00:16:38,790
done this work in this area but it's a

338
00:16:32,769 --> 00:16:38,790
it's our calendar yes okay thanks thanks

339
00:16:38,949 --> 00:16:43,359
how much engineering effort is required

340
00:16:40,810 --> 00:16:45,099
to develop the verification equivalence

341
00:16:43,360 --> 00:16:48,040
checker so do you have to develop that

342
00:16:45,100 --> 00:16:50,500
for each pair of instruction sets you

343
00:16:48,040 --> 00:16:54,010
want to translate between other it means

344
00:16:50,500 --> 00:16:57,480
how how did we implemented equivalence

345
00:16:54,010 --> 00:17:01,630
were fication - yeah it is the best

346
00:16:57,480 --> 00:17:04,390
existing personally execution - name the

347
00:17:01,630 --> 00:17:08,140
name of the truth football and who is

348
00:17:04,390 --> 00:17:10,500
logically executed the guest and host in

349
00:17:08,140 --> 00:17:12,939
cracking sequences and we were we

350
00:17:10,500 --> 00:17:15,760
extracted the result excuse some

351
00:17:12,939 --> 00:17:18,040
symbolic execution results and fitted

352
00:17:15,760 --> 00:17:23,980
them to SMT solver to verify the

353
00:17:18,040 --> 00:17:25,869
equivalence Stefan Bucher from Google a

354
00:17:23,980 --> 00:17:28,960
very interesting work I wanted to ask

355
00:17:25,869 --> 00:17:31,840
like what is your fallback strategy in

356
00:17:28,960 --> 00:17:33,910
case you encounter during DBT like code

357
00:17:31,840 --> 00:17:36,610
that you cannot translate based on the

358
00:17:33,910 --> 00:17:38,980
rules that you learn do you use fall

359
00:17:36,610 --> 00:17:41,590
back on IR or something else are you me

360
00:17:38,980 --> 00:17:44,890
if we cannot a cursory interaction how

361
00:17:41,590 --> 00:17:47,740
can we translate right yeah so yeah we

362
00:17:44,890 --> 00:17:50,710
use the existing IR best translation in

363
00:17:47,740 --> 00:17:52,960
qemu - translator okay so and then how

364
00:17:50,710 --> 00:17:53,520
do you do you how to identify whether

365
00:17:52,960 --> 00:17:56,580
some

366
00:17:53,520 --> 00:17:58,860
needs to go with IR or vs. with the

367
00:17:56,580 --> 00:18:01,590
rules that you is if basically we

368
00:17:58,860 --> 00:18:03,270
firstly try to match the casa

369
00:18:01,590 --> 00:18:05,340
interaction with a literal translation

370
00:18:03,270 --> 00:18:07,410
rule you know we cannot find a match the

371
00:18:05,340 --> 00:18:12,959
translation rule we just go through the

372
00:18:07,410 --> 00:18:15,720
the IR pass the translation thank you hi

373
00:18:12,960 --> 00:18:18,020
I'm from goober thanks for the talk so

374
00:18:15,720 --> 00:18:21,090
my question is aware the new approach

375
00:18:18,020 --> 00:18:23,250
make it a rule space to be larger and

376
00:18:21,090 --> 00:18:24,810
the text a longer time to finish the

377
00:18:23,250 --> 00:18:25,980
translation even the eventual

378
00:18:24,810 --> 00:18:29,970
application performance would be

379
00:18:25,980 --> 00:18:32,640
improved you mean whether this approach

380
00:18:29,970 --> 00:18:36,750
we will increases our translation or

381
00:18:32,640 --> 00:18:39,750
ahead yeah no actually the the

382
00:18:36,750 --> 00:18:41,430
translation process using the rule using

383
00:18:39,750 --> 00:18:42,990
the translation we were fast because

384
00:18:41,430 --> 00:18:45,300
it's just a match mode match the

385
00:18:42,990 --> 00:18:47,070
translation rule in origin note IR

386
00:18:45,300 --> 00:18:49,740
better translation we firstly need two

387
00:18:47,070 --> 00:18:51,780
translators guess the interaction into

388
00:18:49,740 --> 00:18:54,630
iron and a perform optimization and

389
00:18:51,780 --> 00:18:58,080
design generator hosted in Russian using

390
00:18:54,630 --> 00:18:59,670
this translation learn the translation

391
00:18:58,080 --> 00:19:01,710
rules we can tell at least athletic a so

392
00:18:59,670 --> 00:19:03,900
in practice into the hosting regime so

393
00:19:01,710 --> 00:19:04,440
we can bypass all these steps used to

394
00:19:03,900 --> 00:19:09,150
water fast

395
00:19:04,440 --> 00:19:12,960
okay sex so just one last question for

396
00:19:09,150 --> 00:19:15,150
me if if you look at the rules that you

397
00:19:12,960 --> 00:19:17,550
couldn't generate or the all those gaps

398
00:19:15,150 --> 00:19:19,440
that you had in coverage what was the

399
00:19:17,550 --> 00:19:22,560
actual reason do you have any kind of

400
00:19:19,440 --> 00:19:27,840
clue in the intuition how to why you

401
00:19:22,560 --> 00:19:29,340
couldn't match these rules the learn

402
00:19:27,840 --> 00:19:32,610
these rules it was a measure of his

403
00:19:29,340 --> 00:19:34,740
evasion is that as I mentioned the minor

404
00:19:32,610 --> 00:19:38,300
is compared from the same source code as

405
00:19:34,740 --> 00:19:40,770
many Greek equivalent that's the worry

406
00:19:38,300 --> 00:19:44,610
intuitive observation of the compilation

407
00:19:40,770 --> 00:19:47,490
process and I think that's the most

408
00:19:44,610 --> 00:19:49,409
important thing we rely on to develop

409
00:19:47,490 --> 00:19:52,980
this learning best approach and also the

410
00:19:49,410 --> 00:19:54,690
learning better translation okay thank

411
00:19:52,980 --> 00:19:56,190
you thanks let's thank the speaker one

412
00:19:54,690 --> 00:19:58,250
last time

413
00:19:56,190 --> 00:19:58,250
you

