1
00:00:10,679 --> 00:00:15,690
good afternoon everybody today I'm gonna

2
00:00:13,049 --> 00:00:18,210
introduce an exotic kernel called chess

3
00:00:15,690 --> 00:00:20,189
kernel bridging monolithic kernel -

4
00:00:18,210 --> 00:00:22,439
peripheral course this is a joint work

5
00:00:20,189 --> 00:00:26,340
between strong guy for each how and my

6
00:00:22,439 --> 00:00:28,410
adviser Felix link from Purdue ECE once

7
00:00:26,340 --> 00:00:31,349
in the summary what is transcranial it

8
00:00:28,410 --> 00:00:33,780
is a novel OS model that runs unmodified

9
00:00:31,349 --> 00:00:36,089
monolithic kernel binary on a micro

10
00:00:33,780 --> 00:00:39,420
controller like a core of a

11
00:00:36,089 --> 00:00:41,070
heterogeneous SOC it features a novel

12
00:00:39,420 --> 00:00:43,710
combination of two key techniques

13
00:00:41,070 --> 00:00:46,830
dynamic binary solution and kernel

14
00:00:43,710 --> 00:00:49,019
service emulation to motivate this work

15
00:00:46,830 --> 00:00:51,750
a little we first introduced ephemeral

16
00:00:49,019 --> 00:00:54,059
tasks in smart things and here we refer

17
00:00:51,750 --> 00:00:56,909
those markings to be smartwatches smart

18
00:00:54,059 --> 00:00:59,070
speakers and other IOT devices if

19
00:00:56,909 --> 00:01:01,650
thermal tasks they are prevalent among

20
00:00:59,070 --> 00:01:03,540
these smart things they could push

21
00:01:01,650 --> 00:01:06,720
notifications periodically sensor data

22
00:01:03,540 --> 00:01:08,490
logging etc to execute such an ephemeral

23
00:01:06,720 --> 00:01:10,229
tasks the kernel has to go through a

24
00:01:08,490 --> 00:01:12,960
phase called device has been resumed

25
00:01:10,229 --> 00:01:14,850
where the kernel wakes up all your i/o

26
00:01:12,960 --> 00:01:17,399
devices for you some graphics controller

27
00:01:14,850 --> 00:01:19,589
your MMC controller and then it can ask

28
00:01:17,400 --> 00:01:21,420
you the task after that it will put all

29
00:01:19,590 --> 00:01:24,270
the i/o device devices back to sleep

30
00:01:21,420 --> 00:01:26,010
that is suspect however these different

31
00:01:24,270 --> 00:01:27,899
tasks are energy-hungry shown by price

32
00:01:26,010 --> 00:01:30,240
study they consume 30 percent or even

33
00:01:27,900 --> 00:01:32,850
more higher energy in these smart things

34
00:01:30,240 --> 00:01:34,009
we find that devices memory zoom is the

35
00:01:32,850 --> 00:01:36,830
key button neck

36
00:01:34,010 --> 00:01:39,240
why is devices memory room so efficient

37
00:01:36,830 --> 00:01:40,440
in efficient the first reason is that

38
00:01:39,240 --> 00:01:42,929
the i/o devices

39
00:01:40,440 --> 00:01:45,899
takes time to do power state transition

40
00:01:42,930 --> 00:01:47,820
and as a result the CPU is kept waiting

41
00:01:45,900 --> 00:01:50,220
and the second reason is that the

42
00:01:47,820 --> 00:01:52,889
complex device dependencies it prevents

43
00:01:50,220 --> 00:01:55,798
the process for further organization as

44
00:01:52,890 --> 00:01:58,320
such a procedure mismatches CPU and our

45
00:01:55,799 --> 00:02:00,299
proposal is to round Sussman resume on a

46
00:01:58,320 --> 00:02:02,190
peripheral core what is a peripheral

47
00:02:00,299 --> 00:02:04,170
core you may wonder just look at the dye

48
00:02:02,190 --> 00:02:05,940
photo you may easily notice that large

49
00:02:04,170 --> 00:02:07,979
areas are occupied by CPU and GPU

50
00:02:05,940 --> 00:02:10,769
however there is oh this little guy

51
00:02:07,979 --> 00:02:11,340
shown here is our perfect what we're

52
00:02:10,769 --> 00:02:13,349
talking about

53
00:02:11,340 --> 00:02:17,430
it is a microcontroller core and it's

54
00:02:13,349 --> 00:02:20,670
much wimpier however it delivers lower

55
00:02:17,430 --> 00:02:24,120
idle power and with higher PC execution

56
00:02:20,670 --> 00:02:24,519
energy on this heater geniuses SOC

57
00:02:24,120 --> 00:02:26,350
are

58
00:02:24,520 --> 00:02:28,720
CPU and our peripheral core there are

59
00:02:26,350 --> 00:02:31,570
asymmetric processors this year Hitler

60
00:02:28,720 --> 00:02:34,030
genius however similar Isis the ISIS

61
00:02:31,570 --> 00:02:36,850
from the same family however with

62
00:02:34,030 --> 00:02:38,350
different profiles also the CPU and

63
00:02:36,850 --> 00:02:39,970
peripheral core they are loosely coupled

64
00:02:38,350 --> 00:02:42,370
they can be turned on and off

65
00:02:39,970 --> 00:02:46,230
independently they shared the platform

66
00:02:42,370 --> 00:02:49,150
resources including I accuse and direct

67
00:02:46,230 --> 00:02:52,119
we find that many of C's feed our

68
00:02:49,150 --> 00:02:54,730
hardware model back in 2010 we had OMAP

69
00:02:52,120 --> 00:02:57,880
4460 which is equipped with peripheral

70
00:02:54,730 --> 00:02:59,649
core m3 + the CPU a nine and at prison

71
00:02:57,880 --> 00:03:01,690
time will have address fear which is

72
00:02:59,650 --> 00:03:04,120
Microsoft's IOT reference platform

73
00:03:01,690 --> 00:03:09,160
equipped with the peripheral core m4 and

74
00:03:04,120 --> 00:03:11,890
the CPU 87 so here's a problem now we

75
00:03:09,160 --> 00:03:13,990
have a hitter genius SOC which has the

76
00:03:11,890 --> 00:03:16,540
CPU and the peripheral core we're

77
00:03:13,990 --> 00:03:19,540
running a commodity monolithic kernel

78
00:03:16,540 --> 00:03:22,179
Linux for our own sin and we want to

79
00:03:19,540 --> 00:03:23,769
offload the devices been resumed to the

80
00:03:22,180 --> 00:03:26,040
peripheral core because we want to keep

81
00:03:23,770 --> 00:03:28,540
the CPU asleep as much as possible

82
00:03:26,040 --> 00:03:30,670
resulting in the following workflow

83
00:03:28,540 --> 00:03:32,590
where the device super-sperm resume is

84
00:03:30,670 --> 00:03:34,660
purely running on the diff peripheral

85
00:03:32,590 --> 00:03:37,470
core and the user task is still executed

86
00:03:34,660 --> 00:03:40,030
by the CPU so what are the approaches

87
00:03:37,470 --> 00:03:42,940
one we want to use a multi kernel right

88
00:03:40,030 --> 00:03:45,490
you can write both kernels from scratch

89
00:03:42,940 --> 00:03:47,470
man colonel and the perfect kernel where

90
00:03:45,490 --> 00:03:49,390
the preffer kernel only runs devices

91
00:03:47,470 --> 00:03:51,160
permission code these two kernels

92
00:03:49,390 --> 00:03:53,260
communicate through a message passing

93
00:03:51,160 --> 00:03:56,260
fashion without sharing any states

94
00:03:53,260 --> 00:03:58,450
however you lose compatibility with the

95
00:03:56,260 --> 00:04:00,970
Linux look how sad the penguin is and

96
00:03:58,450 --> 00:04:02,739
also you may it's not easy for you to

97
00:04:00,970 --> 00:04:05,980
reuse the Linux kernel driver which is

98
00:04:02,740 --> 00:04:08,590
diverse and mature the other approach is

99
00:04:05,980 --> 00:04:10,480
you code transplant the existing devices

100
00:04:08,590 --> 00:04:13,480
burn resume code the Fonda Linux kernel

101
00:04:10,480 --> 00:04:16,839
and static compile it to run on the

102
00:04:13,480 --> 00:04:19,390
perform these two kernels share the same

103
00:04:16,839 --> 00:04:21,789
single instance of current state however

104
00:04:19,390 --> 00:04:23,680
this also has a problem because the

105
00:04:21,790 --> 00:04:26,020
suspend resume code is not self

106
00:04:23,680 --> 00:04:27,850
contained at all instead they are

107
00:04:26,020 --> 00:04:29,950
dependent on a complex

108
00:04:27,850 --> 00:04:32,320
stack of kernel software including

109
00:04:29,950 --> 00:04:34,150
driver Carol traffic library code and a

110
00:04:32,320 --> 00:04:36,460
current library code and this code are

111
00:04:34,150 --> 00:04:38,219
stacked on the interfaces which is known

112
00:04:36,460 --> 00:04:41,469
to be unstable

113
00:04:38,219 --> 00:04:44,229
the third approach is a little bit crazy

114
00:04:41,469 --> 00:04:47,349
which is you run a full virtuix acute

115
00:04:44,229 --> 00:04:49,449
another peripheral core the simple you

116
00:04:47,349 --> 00:04:51,340
can implement a light weight virtue as

117
00:04:49,449 --> 00:04:55,719
secured on the peripheral core for

118
00:04:51,340 --> 00:04:57,758
example a DBT because the the provoker

119
00:04:55,719 --> 00:05:01,240
lags hardware support for virtualization

120
00:04:57,759 --> 00:05:03,999
you are facing a 25 X overhead if you

121
00:05:01,240 --> 00:05:06,550
just port that qumu for example the DBT

122
00:05:03,999 --> 00:05:07,960
to the perfect core and run it and why I

123
00:05:06,550 --> 00:05:09,639
should also consider that the peripheral

124
00:05:07,960 --> 00:05:13,330
core is much more wimpier than the CPU

125
00:05:09,639 --> 00:05:16,289
and runs on a slower clock speed so that

126
00:05:13,330 --> 00:05:19,750
this result no energy benefit at all

127
00:05:16,289 --> 00:05:22,000
instead our approach called trans kernel

128
00:05:19,750 --> 00:05:24,699
the goal is to ink offload that in

129
00:05:22,000 --> 00:05:26,650
efficient devices memory encode of Linux

130
00:05:24,699 --> 00:05:29,110
kernel run it on the peripheral core

131
00:05:26,650 --> 00:05:31,688
however with an affordable overhead and

132
00:05:29,110 --> 00:05:33,759
thus achieving energy efficiency the

133
00:05:31,689 --> 00:05:36,129
approach is that the peripheral core

134
00:05:33,759 --> 00:05:38,889
dynamically translates the kernel binary

135
00:05:36,129 --> 00:05:41,499
and executes it however underneath it's

136
00:05:38,889 --> 00:05:43,419
supported by a small set of a militia

137
00:05:41,499 --> 00:05:46,180
Colonel services by email here the

138
00:05:43,419 --> 00:05:49,210
kernel services women a small set of

139
00:05:46,180 --> 00:05:51,639
functional equivalent services that's

140
00:05:49,210 --> 00:05:53,948
required on the code suspend resume

141
00:05:51,639 --> 00:05:55,319
called path we will explain these

142
00:05:53,949 --> 00:05:58,060
services later

143
00:05:55,319 --> 00:06:01,060
let's pull transfer toe in the OS design

144
00:05:58,060 --> 00:06:03,819
space compared to multi kernels

145
00:06:01,060 --> 00:06:05,349
behravesh m3 where you write kernels

146
00:06:03,819 --> 00:06:07,689
from scratch you share lose

147
00:06:05,349 --> 00:06:08,979
compatibility with nascaro however we

148
00:06:07,689 --> 00:06:11,560
have compatibility with the main

149
00:06:08,979 --> 00:06:13,539
external compared with k2 popcorn which

150
00:06:11,560 --> 00:06:15,460
span a monolithic kernel to

151
00:06:13,539 --> 00:06:16,839
heterogeneous course we actually don't

152
00:06:15,460 --> 00:06:19,508
have to reason about the interface

153
00:06:16,839 --> 00:06:21,729
problem and compared with the DBT for

154
00:06:19,509 --> 00:06:26,199
example qumu we have a much more lower

155
00:06:21,729 --> 00:06:28,779
overhead Transco follows the following

156
00:06:26,199 --> 00:06:31,479
four principles first translate state

157
00:06:28,779 --> 00:06:33,849
for code emulate the stateless code by

158
00:06:31,479 --> 00:06:36,430
stateful code women the offloaded code

159
00:06:33,849 --> 00:06:38,949
that must share states with the kernel

160
00:06:36,430 --> 00:06:41,050
and a stateless code does not and for

161
00:06:38,949 --> 00:06:43,180
example we translates the que malloc

162
00:06:41,050 --> 00:06:45,969
function because we want to maintain a

163
00:06:43,180 --> 00:06:48,310
single instance between the CPU and the

164
00:06:45,969 --> 00:06:50,769
prep record however we choose to email

165
00:06:48,310 --> 00:06:51,920
it as scheduling services thus the

166
00:06:50,769 --> 00:06:54,170
peripheral core has this

167
00:06:51,920 --> 00:06:56,210
copy of a scheduler which does not share

168
00:06:54,170 --> 00:06:56,780
a state with a current with a min

169
00:06:56,210 --> 00:06:59,570
colonel

170
00:06:56,780 --> 00:07:02,479
the second principle is to identify a

171
00:06:59,570 --> 00:07:05,000
narrow translation emulation interfaces

172
00:07:02,480 --> 00:07:07,490
this is the interface whether translated

173
00:07:05,000 --> 00:07:09,680
colonel translated code makes down call

174
00:07:07,490 --> 00:07:12,080
to the emulated code requesting colonel

175
00:07:09,680 --> 00:07:13,070
services for example scheduler services

176
00:07:12,080 --> 00:07:15,800
and the spring-locks

177
00:07:13,070 --> 00:07:18,440
by doing this will make the maintenance

178
00:07:15,800 --> 00:07:20,330
of those emulator services much easier

179
00:07:18,440 --> 00:07:23,060
because you don't have to change your

180
00:07:20,330 --> 00:07:27,080
emulator services every time when

181
00:07:23,060 --> 00:07:28,880
colonel changes the third principle is

182
00:07:27,080 --> 00:07:31,010
to specialized for hot paths

183
00:07:28,880 --> 00:07:32,750
we are observed that for 99 percent of

184
00:07:31,010 --> 00:07:34,969
the execution device has been resumed

185
00:07:32,750 --> 00:07:37,160
follows a comma beaten path which is

186
00:07:34,970 --> 00:07:39,980
this no error and it will get all the

187
00:07:37,160 --> 00:07:41,480
resources it requested these are the hot

188
00:07:39,980 --> 00:07:43,850
paths that we talked about when we

189
00:07:41,480 --> 00:07:45,920
specialized for them in case we go off

190
00:07:43,850 --> 00:07:48,800
the hall pass we can migrate back to the

191
00:07:45,920 --> 00:07:51,020
CPU to continue execution and this

192
00:07:48,800 --> 00:07:53,000
simplifies our DB teaming Foundation and

193
00:07:51,020 --> 00:07:56,030
also make the engineering efforts

194
00:07:53,000 --> 00:07:58,190
tractable the fourth principle is to

195
00:07:56,030 --> 00:08:00,710
exploit the ISIS similarity between the

196
00:07:58,190 --> 00:08:03,010
CPU and the peripheral core and here the

197
00:08:00,710 --> 00:08:05,719
ISO second origin means the same set of

198
00:08:03,010 --> 00:08:08,150
general purpose registers the identical

199
00:08:05,720 --> 00:08:10,580
usage of control-flow register as well

200
00:08:08,150 --> 00:08:12,620
as the conditional flag semantics this

201
00:08:10,580 --> 00:08:14,690
reduces in the immediate instructions

202
00:08:12,620 --> 00:08:18,050
for DBT and it is key to the low

203
00:08:14,690 --> 00:08:20,210
overhead we introduce arc and ARM based

204
00:08:18,050 --> 00:08:24,650
in trans journal implementation and

205
00:08:20,210 --> 00:08:27,919
Platt for an OMAP 4460 equipped with the

206
00:08:24,650 --> 00:08:30,380
peripheral core n3 plus the CPU ni here

207
00:08:27,920 --> 00:08:32,630
is the software stack you can see

208
00:08:30,380 --> 00:08:34,330
running on the prep work or where the

209
00:08:32,630 --> 00:08:37,159
Linux kernel is taking aim and

210
00:08:34,330 --> 00:08:39,860
translated by our course I saw from VC

211
00:08:37,159 --> 00:08:42,880
m8 to ves mmm DBT

212
00:08:39,860 --> 00:08:45,230
end up with in the box are the full

213
00:08:42,880 --> 00:08:46,460
colonel services that will be translated

214
00:08:45,230 --> 00:08:48,380
they are stateful

215
00:08:46,460 --> 00:08:50,270
because we want to maintain the single

216
00:08:48,380 --> 00:08:52,280
instance with the kernel the included

217
00:08:50,270 --> 00:08:53,030
driver specific code driver library

218
00:08:52,280 --> 00:08:55,189
kernal library

219
00:08:53,030 --> 00:08:57,910
irq handler and deferred work which is

220
00:08:55,190 --> 00:09:00,290
the bottom half of the irq Hendra

221
00:08:57,910 --> 00:09:02,750
underneath are the analytic kernel

222
00:09:00,290 --> 00:09:04,130
services we provide they communicate the

223
00:09:02,750 --> 00:09:05,450
way the translated code is - there is a

224
00:09:04,130 --> 00:09:09,080
stable interface

225
00:09:05,450 --> 00:09:13,330
this emulate services only have small

226
00:09:09,080 --> 00:09:16,430
number 12 functions plus one variables

227
00:09:13,330 --> 00:09:18,320
arc reports the commute to the

228
00:09:16,430 --> 00:09:20,839
peripheral core to implement the cross I

229
00:09:18,320 --> 00:09:22,670
so DBT and we are able to derive the

230
00:09:20,840 --> 00:09:26,480
translation rule from the formal

231
00:09:22,670 --> 00:09:32,180
specification we found that out of 558

232
00:09:26,480 --> 00:09:34,190
on v7a instructions there exist 447 that

233
00:09:32,180 --> 00:09:36,410
can be directly translated to a single

234
00:09:34,190 --> 00:09:38,720
v7m instruction which is shown in the

235
00:09:36,410 --> 00:09:40,760
screen part for others in the orange and

236
00:09:38,720 --> 00:09:42,980
red part they are we have to emit

237
00:09:40,760 --> 00:09:46,040
additional one to four instructions to

238
00:09:42,980 --> 00:09:48,380
emulate and our DBT engine is able to

239
00:09:46,040 --> 00:09:50,209
correctly execute over 200 million

240
00:09:48,380 --> 00:09:52,760
instructions through our benchmark we

241
00:09:50,210 --> 00:09:55,220
verified us that by dominic dynamically

242
00:09:52,760 --> 00:09:56,870
comparing the execution results with the

243
00:09:55,220 --> 00:10:00,800
native kernel and also statically

244
00:09:56,870 --> 00:10:03,560
examining its kernels translated code so

245
00:10:00,800 --> 00:10:07,250
in evaluation we want to answer the SARC

246
00:10:03,560 --> 00:10:09,439
incur low overhead does arc incur

247
00:10:07,250 --> 00:10:12,350
tractable engineer efforts and desert

248
00:10:09,440 --> 00:10:14,360
does arc actually yelled at in the

249
00:10:12,350 --> 00:10:16,700
energy benefit and it will run the

250
00:10:14,360 --> 00:10:19,190
benchmark as follows we use a user space

251
00:10:16,700 --> 00:10:21,800
test script to run the hosts perm resume

252
00:10:19,190 --> 00:10:24,410
pass which will invoke nine diverse

253
00:10:21,800 --> 00:10:26,479
drivers and will record their execution

254
00:10:24,410 --> 00:10:28,270
time cycle counts of the crucible and in

255
00:10:26,480 --> 00:10:32,110
peripheral core as well as the energy

256
00:10:28,270 --> 00:10:34,939
let's first look at the DBT overhead

257
00:10:32,110 --> 00:10:37,250
from the figure which we separate the

258
00:10:34,940 --> 00:10:40,040
suspend and resume DBT overhead the

259
00:10:37,250 --> 00:10:41,900
x-axis stands for the diverse benchmark

260
00:10:40,040 --> 00:10:44,060
drivers the we we used in the benchmark

261
00:10:41,900 --> 00:10:46,040
and that the y-axis stands for the

262
00:10:44,060 --> 00:10:48,020
overhead where the overhead is a ratio

263
00:10:46,040 --> 00:10:51,140
cycle comércio between the peripheral

264
00:10:48,020 --> 00:10:53,810
core Intel CPU as we can see without any

265
00:10:51,140 --> 00:10:56,900
optimization where is the baseline Q it

266
00:10:53,810 --> 00:10:59,540
exhibits up to 25 X overhead however

267
00:10:56,900 --> 00:11:03,319
with arcs low overhead DVD were able to

268
00:10:59,540 --> 00:11:08,270
bridge that gap to a 2.7 X all across

269
00:11:03,320 --> 00:11:12,160
the benchmarks we show that our kriyas

270
00:11:08,270 --> 00:11:14,689
as Linux with low efforts with 10k

271
00:11:12,160 --> 00:11:17,719
implementation which is one-time efforts

272
00:11:14,690 --> 00:11:19,370
we're able to transparently reuse 40k

273
00:11:17,720 --> 00:11:21,860
lines of kernel driver code

274
00:11:19,370 --> 00:11:25,190
in our evaluation only and conceptually

275
00:11:21,860 --> 00:11:26,960
more drivers can also be reused we show

276
00:11:25,190 --> 00:11:28,790
that our maintains good compatibility

277
00:11:26,960 --> 00:11:31,340
with multiple versions and

278
00:11:28,790 --> 00:11:34,250
configurations of Linux we support from

279
00:11:31,340 --> 00:11:38,720
version 3.6 Singh and obtuse kernel

280
00:11:34,250 --> 00:11:42,020
version 3 4.20 so the Linux penguin is

281
00:11:38,720 --> 00:11:44,510
happy now let's look at the end of

282
00:11:42,020 --> 00:11:47,600
end-to-end execution time and the end

283
00:11:44,510 --> 00:11:50,060
actual energy benefits let's look at the

284
00:11:47,600 --> 00:11:52,040
execution time first from the top to

285
00:11:50,060 --> 00:11:54,229
bottom we run the native execution which

286
00:11:52,040 --> 00:11:56,930
is suspend resume on the CPU only and

287
00:11:54,230 --> 00:12:00,110
the arc and then baseline queue as you

288
00:11:56,930 --> 00:12:01,760
can see indeed I could prolong prolonged

289
00:12:00,110 --> 00:12:03,650
the execution time this is because the

290
00:12:01,760 --> 00:12:05,990
way around the DBT has its own overhead

291
00:12:03,650 --> 00:12:08,390
and that the peripheral core runs much

292
00:12:05,990 --> 00:12:11,800
slower than the CPU let's look at the

293
00:12:08,390 --> 00:12:15,130
energy in fact arc indeed saves energy

294
00:12:11,800 --> 00:12:17,630
resulting in a 34% of energy saving

295
00:12:15,130 --> 00:12:22,160
where does this energy come from you may

296
00:12:17,630 --> 00:12:23,810
wonder this is because arc runs on the

297
00:12:22,160 --> 00:12:27,020
peripheral core which which has some

298
00:12:23,810 --> 00:12:29,810
much lower PC execution energy as well

299
00:12:27,020 --> 00:12:31,490
as a negligible idle power as you can

300
00:12:29,810 --> 00:12:33,560
see in the orange part and a green part

301
00:12:31,490 --> 00:12:36,380
which is completely shortened or removed

302
00:12:33,560 --> 00:12:38,239
in the arcs energy consumption however

303
00:12:36,380 --> 00:12:41,240
there is one thing interesting in our

304
00:12:38,240 --> 00:12:44,240
experimentation is that arc incurs

305
00:12:41,240 --> 00:12:47,000
higher different energy and we conclude

306
00:12:44,240 --> 00:12:49,040
that is because the prep work or only

307
00:12:47,000 --> 00:12:52,370
has a small size of a class level cache

308
00:12:49,040 --> 00:12:54,770
which is 32 kilobyte and the thrashing

309
00:12:52,370 --> 00:12:56,990
of the small level smallest last level

310
00:12:54,770 --> 00:12:59,090
cache causes the Heidi rain traffic

311
00:12:56,990 --> 00:13:02,870
which ultimately results in the high

312
00:12:59,090 --> 00:13:05,420
energy we conduct a what-if analysis

313
00:13:02,870 --> 00:13:08,030
because the energy saving is majorly

314
00:13:05,420 --> 00:13:11,300
impacted by two factors the db2 overhead

315
00:13:08,030 --> 00:13:13,069
which is the x-axis you see and the

316
00:13:11,300 --> 00:13:14,719
kernel execution behavior which is the

317
00:13:13,070 --> 00:13:17,030
percent of time spent in the native

318
00:13:14,720 --> 00:13:20,000
execution in the busy execution which is

319
00:13:17,030 --> 00:13:21,800
the y-axis and the red zone is is the

320
00:13:20,000 --> 00:13:23,840
part that we actually wasted energy and

321
00:13:21,800 --> 00:13:26,359
the green zone is a part we can save the

322
00:13:23,840 --> 00:13:28,760
energy without any help the optimization

323
00:13:26,360 --> 00:13:31,700
out simple baseline straightforward port

324
00:13:28,760 --> 00:13:32,899
of the DB T can actually waste the 3x

325
00:13:31,700 --> 00:13:35,600
more energy than the

326
00:13:32,899 --> 00:13:37,699
of execution however with our DBT

327
00:13:35,600 --> 00:13:39,920
optimization and arc were able to push

328
00:13:37,699 --> 00:13:42,109
all the way to the green zone ultimately

329
00:13:39,920 --> 00:13:44,719
resulting in a 34 percent of energy

330
00:13:42,110 --> 00:13:49,220
saving this is made only made possible

331
00:13:44,720 --> 00:13:53,389
by our low overhead DBT so to conclude

332
00:13:49,220 --> 00:13:55,519
sound takeaway messages arc and trans

333
00:13:53,389 --> 00:13:57,559
kernel is a novel OS moto it features

334
00:13:55,519 --> 00:13:59,540
two key techniques dynamic minor

335
00:13:57,559 --> 00:14:02,480
sensation and identifying appropriate

336
00:13:59,540 --> 00:14:04,790
translation versus emulation boundary in

337
00:14:02,480 --> 00:14:07,220
a monolithic kernel chill operating

338
00:14:04,790 --> 00:14:09,559
system we contribute a new model to span

339
00:14:07,220 --> 00:14:12,920
a monolithic kernel across heterogeneous

340
00:14:09,559 --> 00:14:15,019
course to DBT we'll show that while the

341
00:14:12,920 --> 00:14:17,569
cross-ice at DBT is under the assumption

342
00:14:15,019 --> 00:14:20,420
of efficiency loss it can enable

343
00:14:17,569 --> 00:14:22,910
efficient thinking even on the on the

344
00:14:20,420 --> 00:14:25,459
off-the-shelf hardware and also we show

345
00:14:22,910 --> 00:14:27,949
that DBT can be applied to translate a

346
00:14:25,459 --> 00:14:32,229
specific path of a very complex software

347
00:14:27,949 --> 00:14:34,609
stack to architects we advocate of

348
00:14:32,230 --> 00:14:37,279
heterogeneous SOC design that is

349
00:14:34,610 --> 00:14:38,779
friendly to change kernel we advocate

350
00:14:37,279 --> 00:14:41,569
the equal rights for the peripheral core

351
00:14:38,779 --> 00:14:44,240
which shares irq DRM with the CPU and

352
00:14:41,569 --> 00:14:46,579
has the right size of less of cache and

353
00:14:44,240 --> 00:14:48,760
that concludes my talk I would like to

354
00:14:46,579 --> 00:14:55,409
take any questions

355
00:14:48,760 --> 00:14:55,409
[Applause]

356
00:15:00,190 --> 00:15:05,980
nice work I have a couple of questions

357
00:15:02,410 --> 00:15:06,819
so you exploit the is a similarity as I

358
00:15:05,980 --> 00:15:07,840
mentioned on the slides

359
00:15:06,820 --> 00:15:10,090
how does it work on a truly

360
00:15:07,840 --> 00:15:13,510
heterogeneous core say for example armed

361
00:15:10,090 --> 00:15:14,020
plus say a risk five that is very good

362
00:15:13,510 --> 00:15:16,600
question

363
00:15:14,020 --> 00:15:18,730
so the Isis similarity we we we exploit

364
00:15:16,600 --> 00:15:20,290
it here is based on the assumption that

365
00:15:18,730 --> 00:15:22,270
they are actually from the same

366
00:15:20,290 --> 00:15:25,000
eisah family however with different

367
00:15:22,270 --> 00:15:27,760
profile that is assumption that we think

368
00:15:25,000 --> 00:15:29,920
made by the architect so they choose to

369
00:15:27,760 --> 00:15:32,950
implement the same the different profile

370
00:15:29,920 --> 00:15:34,839
that has simpler semantics so that they

371
00:15:32,950 --> 00:15:37,840
can have energy saving in terms of

372
00:15:34,840 --> 00:15:40,810
cross-ice are really like a crossed

373
00:15:37,840 --> 00:15:44,320
family like from xxd says to arm that

374
00:15:40,810 --> 00:15:47,130
will have a consumer presumably higher

375
00:15:44,320 --> 00:15:52,540
overhead and we have a discussion in

376
00:15:47,130 --> 00:15:54,310
translating arm v78 to reason we we 8287

377
00:15:52,540 --> 00:15:57,900
in the paper so you can check it out to

378
00:15:54,310 --> 00:16:01,150
see how our can apply in this scenario

379
00:15:57,900 --> 00:16:03,280
thank you one more question so so you

380
00:16:01,150 --> 00:16:06,240
said like if there's a failure case you

381
00:16:03,280 --> 00:16:08,860
hand it off back to the CPU all right so

382
00:16:06,240 --> 00:16:11,080
I'm not sure if I've missed it so do you

383
00:16:08,860 --> 00:16:13,870
turn off the main core yes we're handing

384
00:16:11,080 --> 00:16:16,150
off yes so if there is a hand off back

385
00:16:13,870 --> 00:16:18,940
again so you wake up the CPU core right

386
00:16:16,150 --> 00:16:21,069
yeah so do you measure in this corner

387
00:16:18,940 --> 00:16:23,140
case like how much energy do you consume

388
00:16:21,070 --> 00:16:26,050
more energy in this case or less energy

389
00:16:23,140 --> 00:16:28,480
in total that is a great question so the

390
00:16:26,050 --> 00:16:30,370
work flow of work works like this first

391
00:16:28,480 --> 00:16:32,320
the CPU of the CPU the kernel main

392
00:16:30,370 --> 00:16:34,480
colonel wishes all but one CPU then he

393
00:16:32,320 --> 00:16:36,700
handles control over to our perfect core

394
00:16:34,480 --> 00:16:38,110
then he shuts down the last viewed and

395
00:16:36,700 --> 00:16:40,810
our key will finish all the system

396
00:16:38,110 --> 00:16:42,580
resume work and in case of emergency we

397
00:16:40,810 --> 00:16:45,459
will fall back to the main CPU by

398
00:16:42,580 --> 00:16:47,560
sending an IP I and then also we will

399
00:16:45,460 --> 00:16:50,230
chanced will also migrate the stack

400
00:16:47,560 --> 00:16:52,989
running on the preferable or back to the

401
00:16:50,230 --> 00:16:55,990
kernel stack and on the main kernel to

402
00:16:52,990 --> 00:16:58,840
continue execution so the implementation

403
00:16:55,990 --> 00:17:01,870
detail is also in the paper and the way

404
00:16:58,840 --> 00:17:03,850
do not measure the energy but all but we

405
00:17:01,870 --> 00:17:05,829
measure indeed measure the time to wake

406
00:17:03,850 --> 00:17:08,020
up the CPU it takes around 20

407
00:17:05,829 --> 00:17:11,809
microseconds so it's pretty fast all

408
00:17:08,020 --> 00:17:12,040
right thank you speaker again

409
00:17:11,809 --> 00:17:16,879
you

410
00:17:12,040 --> 00:17:16,879
[Applause]

