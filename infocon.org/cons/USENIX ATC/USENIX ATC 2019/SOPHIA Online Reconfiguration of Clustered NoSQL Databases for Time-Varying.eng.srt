1
00:00:10,610 --> 00:00:15,800
hello everyone this is Asha from a group

2
00:00:13,220 --> 00:00:17,780
I will be presenting Sofia online

3
00:00:15,800 --> 00:00:20,090
reconfiguration of clustered new sequel

4
00:00:17,780 --> 00:00:21,770
databases for time varying workloads

5
00:00:20,090 --> 00:00:23,240
this work is a collaboration between

6
00:00:21,770 --> 00:00:25,340
Purdue University's Johns Hopkins

7
00:00:23,240 --> 00:00:26,720
University Adobe Research and Argonne

8
00:00:25,340 --> 00:00:30,110
National Laboratory and the work is

9
00:00:26,720 --> 00:00:32,479
supported by NIH so the first thing we

10
00:00:30,110 --> 00:00:35,390
are going to do is to introduce what are

11
00:00:32,479 --> 00:00:37,220
the challenges in online tuning for no

12
00:00:35,390 --> 00:00:39,560
sequel databases and the first challenge

13
00:00:37,220 --> 00:00:41,180
is that these databases have numerous

14
00:00:39,560 --> 00:00:44,000
configuration parameters that control

15
00:00:41,180 --> 00:00:45,949
and impact the performance and in many

16
00:00:44,000 --> 00:00:47,989
real-world scenarios the workload

17
00:00:45,949 --> 00:00:50,149
characteristics is always changing over

18
00:00:47,989 --> 00:00:52,669
time and therefore reconfiguration is

19
00:00:50,149 --> 00:00:56,449
needed because the optimal parameters

20
00:00:52,670 --> 00:00:59,480
also change furthermore reconfiguration

21
00:00:56,449 --> 00:01:00,920
has a cost for example if to apply the

22
00:00:59,480 --> 00:01:03,050
new configuration we need the server

23
00:01:00,920 --> 00:01:06,100
restart then during the restore there

24
00:01:03,050 --> 00:01:10,039
will be data and availability as well as

25
00:01:06,100 --> 00:01:12,259
degradation and throughput and if the

26
00:01:10,040 --> 00:01:13,730
workload change is transient then the

27
00:01:12,260 --> 00:01:17,480
cost of free configuration might not be

28
00:01:13,730 --> 00:01:19,130
recouped over time and in this slide I'm

29
00:01:17,480 --> 00:01:21,560
showing a very simple example to

30
00:01:19,130 --> 00:01:23,899
illustrate illustrate the idea of the

31
00:01:21,560 --> 00:01:26,480
paper so and in this figure we see a

32
00:01:23,900 --> 00:01:28,610
cluster of Cassandra nodes running with

33
00:01:26,480 --> 00:01:30,110
conf 1 which is optimized for the

34
00:01:28,610 --> 00:01:34,039
current workload characteristics and

35
00:01:30,110 --> 00:01:36,080
achieves 70k ops per second but over

36
00:01:34,040 --> 00:01:39,290
time the workload changes to a different

37
00:01:36,080 --> 00:01:41,509
workload and now our configuration that

38
00:01:39,290 --> 00:01:43,240
is denoted as calm phone is becoming

39
00:01:41,510 --> 00:01:47,740
suboptimal and this is only achieving

40
00:01:43,240 --> 00:01:51,410
40k of super second and then if we

41
00:01:47,740 --> 00:01:54,350
reconfigured our cluster to confer -

42
00:01:51,410 --> 00:01:57,350
then our throughput is back up to 60k

43
00:01:54,350 --> 00:01:59,210
ops per second because we picked a

44
00:01:57,350 --> 00:02:01,640
confusion that is optimized for this

45
00:01:59,210 --> 00:02:03,259
workload but then over time the workload

46
00:02:01,640 --> 00:02:05,420
gets back to the old characteristics

47
00:02:03,260 --> 00:02:07,550
workload one and then confer - becomes

48
00:02:05,420 --> 00:02:10,788
suboptimal and achieves only 30 curbs

49
00:02:07,550 --> 00:02:12,170
per second the problem here is it is not

50
00:02:10,788 --> 00:02:14,440
always desirable to switch between

51
00:02:12,170 --> 00:02:17,208
configurations because changing the

52
00:02:14,440 --> 00:02:18,770
configurations at Suncoast and if the

53
00:02:17,209 --> 00:02:21,290
changes and the workload is not long

54
00:02:18,770 --> 00:02:23,540
enough to recoup that cost then the

55
00:02:21,290 --> 00:02:24,079
overall reconfiguration process will be

56
00:02:23,540 --> 00:02:27,109
harmful

57
00:02:24,080 --> 00:02:29,450
the performance over time and to

58
00:02:27,110 --> 00:02:31,220
understand better what this means we

59
00:02:29,450 --> 00:02:32,989
show this very simple example where we

60
00:02:31,220 --> 00:02:36,410
configure to Cassandra servers in

61
00:02:32,990 --> 00:02:38,690
runtime the x-axis shows time in seconds

62
00:02:36,410 --> 00:02:40,670
the primary y-axis shows the throughput

63
00:02:38,690 --> 00:02:43,070
in terms of us per second and the

64
00:02:40,670 --> 00:02:44,690
secondary axis shows the gain and gain

65
00:02:43,070 --> 00:02:46,880
is defined as the external number of

66
00:02:44,690 --> 00:02:50,090
races that we were able to perform

67
00:02:46,880 --> 00:02:51,799
because of the reconfiguration and we

68
00:02:50,090 --> 00:02:54,230
can see that at this point of time we

69
00:02:51,800 --> 00:02:55,610
were achieving only 40k ops per second

70
00:02:54,230 --> 00:02:57,859
but we have this other configuration

71
00:02:55,610 --> 00:02:59,900
that can achieve 50k of super second so

72
00:02:57,860 --> 00:03:02,209
we go ahead and reconfigure the servers

73
00:02:59,900 --> 00:03:04,370
the first thing that we notice is there

74
00:03:02,209 --> 00:03:06,440
is a transient degradation in

75
00:03:04,370 --> 00:03:09,530
performance which causes again the

76
00:03:06,440 --> 00:03:12,260
deadline to go below zero so it's a

77
00:03:09,530 --> 00:03:14,209
negative gain for now and then after

78
00:03:12,260 --> 00:03:16,579
some time the system reaches the

79
00:03:14,209 --> 00:03:18,440
steady-state achieving 50k of super

80
00:03:16,580 --> 00:03:20,560
second that we were hoping for but

81
00:03:18,440 --> 00:03:25,280
unless the workload less for this

82
00:03:20,560 --> 00:03:29,030
ex-market point at the gain will be a

83
00:03:25,280 --> 00:03:31,070
negative gain which means we need the

84
00:03:29,030 --> 00:03:33,380
new workload to last beyond this exploit

85
00:03:31,070 --> 00:03:37,850
before we start seeing a positive gain

86
00:03:33,380 --> 00:03:41,420
of the reconfiguration so this is the

87
00:03:37,850 --> 00:03:43,730
limitation of all prior works which

88
00:03:41,420 --> 00:03:47,059
which implement the configuration tuners

89
00:03:43,730 --> 00:03:48,768
the first thing they do is the to

90
00:03:47,060 --> 00:03:50,720
monitor the application and run time and

91
00:03:48,769 --> 00:03:52,250
whenever the workload changes from the

92
00:03:50,720 --> 00:03:54,769
application perspective new

93
00:03:52,250 --> 00:03:58,100
configurations is pushed to the database

94
00:03:54,769 --> 00:03:59,750
management system cluster and this does

95
00:03:58,100 --> 00:04:02,450
not work for dynamic workloads that

96
00:03:59,750 --> 00:04:04,340
changes back frequently because the lack

97
00:04:02,450 --> 00:04:07,280
of cost benefit analysis as well as

98
00:04:04,340 --> 00:04:09,170
causing performance degradation compared

99
00:04:07,280 --> 00:04:11,630
to static or default configurations and

100
00:04:09,170 --> 00:04:15,410
also making data transiently unavailable

101
00:04:11,630 --> 00:04:18,649
to users and this is where our solution

102
00:04:15,410 --> 00:04:22,190
comes to play we introduced Sofia that

103
00:04:18,649 --> 00:04:23,960
adds a workload predictor a cost-benefit

104
00:04:22,190 --> 00:04:27,229
analysis as well as a controller that

105
00:04:23,960 --> 00:04:28,820
finds a reconfiguration plan and this is

106
00:04:27,229 --> 00:04:32,180
how we represent a reconfiguration plan

107
00:04:28,820 --> 00:04:34,640
it simply says that to which points of

108
00:04:32,180 --> 00:04:37,400
time we apply which configuration so at

109
00:04:34,640 --> 00:04:41,509
time t1 we apply a variable value

110
00:04:37,400 --> 00:04:44,239
v 1 1 V 1 2 etc up till time T n where

111
00:04:41,509 --> 00:04:47,270
that was the end of the workload look

112
00:04:44,240 --> 00:04:50,300
ahead period we apply V N 1 V n 2 etc

113
00:04:47,270 --> 00:04:52,250
and we use our distributed protocol to

114
00:04:50,300 --> 00:04:54,050
gracefully switch between the older

115
00:04:52,250 --> 00:04:56,570
configurations and the new ones without

116
00:04:54,050 --> 00:05:00,740
degrading data consistency and

117
00:04:56,570 --> 00:05:04,550
availability requirements so the first

118
00:05:00,740 --> 00:05:07,460
thing we do is to use Rafiki which is a

119
00:05:04,550 --> 00:05:09,530
static tuner that identifies the most

120
00:05:07,460 --> 00:05:11,930
impactful parameters and for a given

121
00:05:09,530 --> 00:05:14,559
phase of the workload it achieves it

122
00:05:11,930 --> 00:05:16,940
finds the optimal configurations and

123
00:05:14,560 --> 00:05:19,130
based on the impactful parameters that

124
00:05:16,940 --> 00:05:21,289
was n divided by Rafiki we found that

125
00:05:19,130 --> 00:05:24,530
most of them require a silvery start for

126
00:05:21,289 --> 00:05:26,270
the new values to take effect and for

127
00:05:24,530 --> 00:05:28,880
predicting the workload we implemented a

128
00:05:26,270 --> 00:05:31,010
very simple in order Markov chain model

129
00:05:28,880 --> 00:05:34,099
that represents the different states of

130
00:05:31,010 --> 00:05:38,060
the workload and predicts what would be

131
00:05:34,099 --> 00:05:41,110
the future patterns of the workload so

132
00:05:38,060 --> 00:05:44,180
this is how Sofia estimates the cost of

133
00:05:41,110 --> 00:05:46,639
reconfiguration and this cost is because

134
00:05:44,180 --> 00:05:49,520
when we apply a configuration there is a

135
00:05:46,639 --> 00:05:50,870
downtime for for each server and if we

136
00:05:49,520 --> 00:05:53,260
didn't apply the configuration there

137
00:05:50,870 --> 00:05:57,080
would have been some operations that we

138
00:05:53,260 --> 00:05:59,539
we would perform so basically this loss

139
00:05:57,080 --> 00:06:01,219
function estimates what would have been

140
00:05:59,539 --> 00:06:03,530
the number of present that we had had

141
00:06:01,220 --> 00:06:05,840
achieved if we didn't perform the

142
00:06:03,530 --> 00:06:07,969
reconfiguration and it takes into

143
00:06:05,840 --> 00:06:10,698
account what is the work code looks like

144
00:06:07,970 --> 00:06:12,740
at time TK what is the set of

145
00:06:10,699 --> 00:06:14,510
coefficients that we use and at this

146
00:06:12,740 --> 00:06:16,699
time and how long does it take for a

147
00:06:14,510 --> 00:06:20,630
single server to restart and resync with

148
00:06:16,699 --> 00:06:23,060
the rest of the cluster and when we

149
00:06:20,630 --> 00:06:24,979
estimate the benefit it is simply the

150
00:06:23,060 --> 00:06:26,900
difference between the clusters

151
00:06:24,979 --> 00:06:29,800
performance with the new configurations

152
00:06:26,900 --> 00:06:32,870
versus with the old configurations and

153
00:06:29,800 --> 00:06:35,539
with the loss and the benefit functions

154
00:06:32,870 --> 00:06:40,010
we apply genetic algorithms that search

155
00:06:35,539 --> 00:06:41,510
the best configuration space and finds

156
00:06:40,010 --> 00:06:46,400
the best a plan that optimizes the

157
00:06:41,510 --> 00:06:49,539
performance over time then we apply our

158
00:06:46,400 --> 00:06:51,320
distributed online protocol that

159
00:06:49,539 --> 00:06:53,150
gracefully switches

160
00:06:51,320 --> 00:06:55,070
between the older confusion and the new

161
00:06:53,150 --> 00:06:56,630
conversation without degrading data

162
00:06:55,070 --> 00:06:59,450
availability and the first thing we do

163
00:06:56,630 --> 00:07:01,430
is to identify what is what we call the

164
00:06:59,450 --> 00:07:03,349
minimum availability subset which is

165
00:07:01,430 --> 00:07:06,440
defined as the subset of servers that

166
00:07:03,350 --> 00:07:09,350
cover all data records exactly CL times

167
00:07:06,440 --> 00:07:11,210
and we show a very simple example of

168
00:07:09,350 --> 00:07:13,630
four Cassandra servers with a

169
00:07:11,210 --> 00:07:18,469
replication factor of two so each data

170
00:07:13,630 --> 00:07:20,810
token is replicated twice and according

171
00:07:18,470 --> 00:07:22,190
to this particular data placement the

172
00:07:20,810 --> 00:07:24,710
minimum availability subsets could be

173
00:07:22,190 --> 00:07:27,080
servers one and three or servers to hunt

174
00:07:24,710 --> 00:07:29,900
for what she means we can reconfigure

175
00:07:27,080 --> 00:07:32,890
servers one and three and concurrently

176
00:07:29,900 --> 00:07:35,000
while servers two and four are up and

177
00:07:32,890 --> 00:07:39,380
vice versa without losing data

178
00:07:35,000 --> 00:07:42,620
availability requirements afterwards

179
00:07:39,380 --> 00:07:44,750
we apply these five steps we first drain

180
00:07:42,620 --> 00:07:46,670
which means we flush all uncommitted

181
00:07:44,750 --> 00:07:49,280
data records to the disk which is needed

182
00:07:46,670 --> 00:07:52,160
to avoid long and expensive data repair

183
00:07:49,280 --> 00:07:54,289
processes we shut down the ER and

184
00:07:52,160 --> 00:07:56,480
Cassandra process swap the configuration

185
00:07:54,290 --> 00:07:58,850
file and restart the new Cassandra

186
00:07:56,480 --> 00:08:00,740
process wait for some time for the new

187
00:07:58,850 --> 00:08:05,480
class of new server to sync with the

188
00:08:00,740 --> 00:08:07,340
rest of the cluster and here we show the

189
00:08:05,480 --> 00:08:10,190
three use cases that we used for our

190
00:08:07,340 --> 00:08:13,030
evaluation the first use case which

191
00:08:10,190 --> 00:08:15,710
which is called mg rest MGS is a real

192
00:08:13,030 --> 00:08:18,349
workload trace from the largest meter

193
00:08:15,710 --> 00:08:20,840
genomics analysis portal the workload

194
00:08:18,350 --> 00:08:23,300
industries has no daily or weekly

195
00:08:20,840 --> 00:08:26,539
pattern as the requests and the jobs are

196
00:08:23,300 --> 00:08:29,480
being submitted from all across the

197
00:08:26,540 --> 00:08:31,670
globe we noticed that the workload

198
00:08:29,480 --> 00:08:34,219
changes very drastically over a few

199
00:08:31,670 --> 00:08:37,630
minutes and it is only accurately

200
00:08:34,219 --> 00:08:40,130
predictable for look ahead of 5 minutes

201
00:08:37,630 --> 00:08:40,729
the second use case represents a bus

202
00:08:40,130 --> 00:08:43,610
tracking

203
00:08:40,729 --> 00:08:45,890
mobile application which issues a strong

204
00:08:43,610 --> 00:08:47,900
and daily the song daily and weekly

205
00:08:45,890 --> 00:08:49,640
pattern and the workload is more

206
00:08:47,900 --> 00:08:51,770
predictable for longer look ahead

207
00:08:49,640 --> 00:08:55,400
periods such as for like one hour or two

208
00:08:51,770 --> 00:08:58,100
hours the third use cases are simulated

209
00:08:55,400 --> 00:09:01,430
workload trees from batch data analytics

210
00:08:58,100 --> 00:09:03,560
jobs that are some that is submitted to

211
00:09:01,430 --> 00:09:04,880
a shared high performance computing

212
00:09:03,560 --> 00:09:07,369
queue

213
00:09:04,880 --> 00:09:09,770
using userland as your profiling

214
00:09:07,370 --> 00:09:11,600
techniques job execution times can be

215
00:09:09,770 --> 00:09:14,960
predicted with high accuracy and for

216
00:09:11,600 --> 00:09:16,910
longer look ahead periods and this

217
00:09:14,960 --> 00:09:19,550
figure shows the performance of using

218
00:09:16,910 --> 00:09:22,939
Sofia on top of Cassandra compared to

219
00:09:19,550 --> 00:09:25,339
three other three baselines the first

220
00:09:22,940 --> 00:09:26,990
baseline is simply the default which is

221
00:09:25,340 --> 00:09:29,660
the ascenders out of the box

222
00:09:26,990 --> 00:09:31,660
configurations the second one is the

223
00:09:29,660 --> 00:09:35,000
single aesthetic configuration that is

224
00:09:31,660 --> 00:09:38,000
optimized for for the workload given

225
00:09:35,000 --> 00:09:39,830
that we have perfect knowledge about how

226
00:09:38,000 --> 00:09:41,840
the workload will would be from end to

227
00:09:39,830 --> 00:09:44,000
end which is not a realistic baseline

228
00:09:41,840 --> 00:09:47,870
but the service as the upper bound for

229
00:09:44,000 --> 00:09:49,970
any static configuration technique the

230
00:09:47,870 --> 00:09:51,920
third technique is we called a naive

231
00:09:49,970 --> 00:09:53,390
approach which always applies the

232
00:09:51,920 --> 00:09:54,860
optimal configuration for the current

233
00:09:53,390 --> 00:09:56,660
phase of the workload so every time the

234
00:09:54,860 --> 00:10:00,010
workload changes it will configure the

235
00:09:56,660 --> 00:10:05,719
cluster to the optimal configuration and

236
00:10:00,010 --> 00:10:09,140
that the applications are ordered in the

237
00:10:05,720 --> 00:10:10,970
more the more predictable so the

238
00:10:09,140 --> 00:10:12,830
rightmost application is the most

239
00:10:10,970 --> 00:10:14,690
predictable application the leftmost

240
00:10:12,830 --> 00:10:18,350
which is MGS is the least predictable

241
00:10:14,690 --> 00:10:19,640
application and we noticed that with

242
00:10:18,350 --> 00:10:21,710
longer and more accurate workload

243
00:10:19,640 --> 00:10:23,620
predictions Sofia can find better

244
00:10:21,710 --> 00:10:27,800
configuration plans that achieves

245
00:10:23,620 --> 00:10:29,450
globally optimized performance and we

246
00:10:27,800 --> 00:10:32,449
also notice that compared to the static

247
00:10:29,450 --> 00:10:35,600
Oracle baseline which is a direct

248
00:10:32,450 --> 00:10:37,880
application of all aesthetic tuners in

249
00:10:35,600 --> 00:10:38,990
Prior work and also assuming that we

250
00:10:37,880 --> 00:10:40,640
have perfect knowledge about the

251
00:10:38,990 --> 00:10:42,050
workload Sofia achieves better

252
00:10:40,640 --> 00:10:46,220
performance for the best tracking and

253
00:10:42,050 --> 00:10:47,599
HPC while it it suffers from a little

254
00:10:46,220 --> 00:10:50,570
bit degradation of performance for the

255
00:10:47,600 --> 00:10:51,680
ng rest due to the very short look-ahead

256
00:10:50,570 --> 00:10:55,490
period that we have for this

257
00:10:51,680 --> 00:10:57,770
particularly use case and compared to

258
00:10:55,490 --> 00:10:59,600
the naive approach we see that Sofia

259
00:10:57,770 --> 00:11:02,840
achieves better performance in the range

260
00:10:59,600 --> 00:11:09,530
of 25 to 30 percent across all three use

261
00:11:02,840 --> 00:11:11,450
cases so we also apply Sofia to radius

262
00:11:09,530 --> 00:11:14,800
which is a very popular in memory

263
00:11:11,450 --> 00:11:18,290
datastore radius used to offer a feature

264
00:11:14,800 --> 00:11:20,599
and the versions before a version

265
00:11:18,290 --> 00:11:24,589
two point four that is called virtual

266
00:11:20,600 --> 00:11:26,899
memory and this feature allows to work

267
00:11:24,589 --> 00:11:31,100
with deficits that can spray spillover

268
00:11:26,899 --> 00:11:33,529
from from the available memory but since

269
00:11:31,100 --> 00:11:36,049
version 2.4 this feature was removed it

270
00:11:33,529 --> 00:11:38,059
was duplicated as it it caused serious

271
00:11:36,049 --> 00:11:40,989
performance degradation and many

272
00:11:38,059 --> 00:11:46,459
real-world deployments of Frida's

273
00:11:40,989 --> 00:11:48,559
however we used Sofia on top of radius

274
00:11:46,459 --> 00:11:51,589
in version 2.4 to automatically tune

275
00:11:48,559 --> 00:11:53,809
when and and when not to enable the

276
00:11:51,589 --> 00:11:55,579
virtual memory and also what is the

277
00:11:53,809 --> 00:12:00,889
maximum size of the Russian memory to

278
00:11:55,579 --> 00:12:02,929
use in runtime and that takeaway is with

279
00:12:00,889 --> 00:12:06,679
with Sofia it was able to achieve the

280
00:12:02,929 --> 00:12:09,499
best of the two worlds weather when we

281
00:12:06,679 --> 00:12:12,169
enable the VM we have the ability to

282
00:12:09,499 --> 00:12:14,779
serve jobs that that is larger than the

283
00:12:12,169 --> 00:12:17,509
available memory but then if the job

284
00:12:14,779 --> 00:12:21,799
does not meet if the job access pattern

285
00:12:17,509 --> 00:12:23,929
does not meet our VM size that the the

286
00:12:21,799 --> 00:12:26,419
the throughput of the database becomes

287
00:12:23,929 --> 00:12:29,899
very slow because most of the requests

288
00:12:26,419 --> 00:12:31,039
are being fulfilled from the disk so by

289
00:12:29,899 --> 00:12:33,639
automatically isolating the right

290
00:12:31,039 --> 00:12:36,309
parameters Sofia was able to achieve

291
00:12:33,639 --> 00:12:39,529
close to optimum performance in every

292
00:12:36,309 --> 00:12:41,569
case that we are showing with different

293
00:12:39,529 --> 00:12:46,309
job sizes different access patterns and

294
00:12:41,569 --> 00:12:48,649
different request distributions and the

295
00:12:46,309 --> 00:12:50,269
major insights from our work is online

296
00:12:48,649 --> 00:12:52,819
tuning of new sequel databases for

297
00:12:50,269 --> 00:12:54,789
dynamic workloads is challenging and all

298
00:12:52,819 --> 00:12:57,469
prior works suffer for dynamic workloads

299
00:12:54,789 --> 00:12:59,480
as a straightforward application of

300
00:12:57,470 --> 00:13:02,209
these will actually degrade the

301
00:12:59,480 --> 00:13:03,949
performance and data availability we

302
00:13:02,209 --> 00:13:07,399
introduce to fail to address all these

303
00:13:03,949 --> 00:13:08,929
shortcomings and combine workload

304
00:13:07,399 --> 00:13:12,589
prediction cost benefit analysis and

305
00:13:08,929 --> 00:13:15,009
genetic algorithm we evaluated Sofia

306
00:13:12,589 --> 00:13:17,389
with real workload traces and two

307
00:13:15,009 --> 00:13:20,179
popular no sequel data stores Cassandra

308
00:13:17,389 --> 00:13:21,679
and Redis and we showed that Sofia

309
00:13:20,179 --> 00:13:25,159
achieves globally optimized performance

310
00:13:21,679 --> 00:13:29,350
and respects users data consistency and

311
00:13:25,159 --> 00:13:40,230
availability requirements thank

312
00:13:29,350 --> 00:13:42,670
you all right let's take some questions

313
00:13:40,230 --> 00:13:45,610
thank you for the presentation and I'm

314
00:13:42,670 --> 00:13:46,300
Marlon I vote for realtor.com I have a

315
00:13:45,610 --> 00:13:49,510
quick question

316
00:13:46,300 --> 00:13:51,579
so no sequel databases like cassandra

317
00:13:49,510 --> 00:13:53,710
has like hundreds of two novels right

318
00:13:51,580 --> 00:13:56,700
varying from cache sizes different

319
00:13:53,710 --> 00:13:59,200
caches and consistency policies and

320
00:13:56,700 --> 00:14:01,060
topology and there is so many how does

321
00:13:59,200 --> 00:14:03,400
Sofia figure out which of these

322
00:14:01,060 --> 00:14:04,479
parameters matters the most and and how

323
00:14:03,400 --> 00:14:08,050
does it like you know things works

324
00:14:04,480 --> 00:14:09,250
afterwards so actually this is what you

325
00:14:08,050 --> 00:14:13,390
say there's a very challenging problem

326
00:14:09,250 --> 00:14:15,430
and we build on our previous system

327
00:14:13,390 --> 00:14:18,880
called Rafiki that appeared in

328
00:14:15,430 --> 00:14:22,030
middleware 2017 so Rafiki which we use

329
00:14:18,880 --> 00:14:25,750
here as a static tuner but Rafiki main

330
00:14:22,030 --> 00:14:27,819
main main claims in that paper is to

331
00:14:25,750 --> 00:14:30,220
identify which parameters are the most

332
00:14:27,820 --> 00:14:32,530
impactful to the workload so perform

333
00:14:30,220 --> 00:14:35,140
like feature space reduction and then in

334
00:14:32,530 --> 00:14:37,329
runtime when queried with a particular

335
00:14:35,140 --> 00:14:38,680
piece of the workload it can find very

336
00:14:37,330 --> 00:14:40,240
quickly what is the optimal

337
00:14:38,680 --> 00:14:43,510
configurations for the parameters that

338
00:14:40,240 --> 00:14:48,490
was identified so what you say it is a

339
00:14:43,510 --> 00:14:52,240
very challenging problem however this

340
00:14:48,490 --> 00:14:54,460
problem it was solved in and Rafiki as

341
00:14:52,240 --> 00:14:56,920
well as other systems with what we call

342
00:14:54,460 --> 00:15:04,530
the static tuners so Sofia kind of

343
00:14:56,920 --> 00:15:04,530
builds on on that any more questions

344
00:15:06,410 --> 00:15:12,110
well I'll ask one which is sort of

345
00:15:08,490 --> 00:15:16,080
what's the next step for this work well

346
00:15:12,110 --> 00:15:17,340
our ongoing project was looking at at

347
00:15:16,080 --> 00:15:19,980
the problem of tuning cloud

348
00:15:17,340 --> 00:15:23,430
configurations as well so what we found

349
00:15:19,980 --> 00:15:25,380
is now you have an Cassandra cluster

350
00:15:23,430 --> 00:15:28,680
that you want to host in the cloud and

351
00:15:25,380 --> 00:15:31,830
this adds more complexity to your

352
00:15:28,680 --> 00:15:33,359
problem so you you already had 50-plus

353
00:15:31,830 --> 00:15:35,820
configuration parameters for Cassandra

354
00:15:33,360 --> 00:15:38,640
and now you have to pick what is the VM

355
00:15:35,820 --> 00:15:41,490
size and VM type for the cluster and

356
00:15:38,640 --> 00:15:43,980
this brings also new metrics to the

357
00:15:41,490 --> 00:15:46,170
problem so you don't you don't look at

358
00:15:43,980 --> 00:15:49,500
the throughput only you also looking at

359
00:15:46,170 --> 00:15:50,910
the cost of your cloud configurations so

360
00:15:49,500 --> 00:15:56,010
this is one direction that we are

361
00:15:50,910 --> 00:16:03,150
looking at for our next paper all right

362
00:15:56,010 --> 00:16:05,760
last call for questions sorry yes sir so

363
00:16:03,150 --> 00:16:08,370
can you expand more about the workload

364
00:16:05,760 --> 00:16:10,819
prediction and the how does the local o

365
00:16:08,370 --> 00:16:16,200
prediction accuracy impact a whole

366
00:16:10,820 --> 00:16:17,940
parameter terrine yes so frankly

367
00:16:16,200 --> 00:16:19,980
workload prediction is not a new claim

368
00:16:17,940 --> 00:16:21,990
in this paper so there has been lots of

369
00:16:19,980 --> 00:16:23,400
work done an orchid prediction in

370
00:16:21,990 --> 00:16:26,250
different deployments

371
00:16:23,400 --> 00:16:29,189
not only database and and in our paper

372
00:16:26,250 --> 00:16:31,080
we kind of implemented a very simple

373
00:16:29,190 --> 00:16:33,270
Markov chain model like first order and

374
00:16:31,080 --> 00:16:37,050
second order model for every use case

375
00:16:33,270 --> 00:16:39,510
that we had although that more complex

376
00:16:37,050 --> 00:16:40,849
predictors can be used instead of the

377
00:16:39,510 --> 00:16:44,069
Markov chain

378
00:16:40,850 --> 00:16:45,900
so yeah workload prediction is a very

379
00:16:44,070 --> 00:16:50,070
challenging problem it's a parallel

380
00:16:45,900 --> 00:16:51,750
problem from from our perspective what

381
00:16:50,070 --> 00:16:53,760
we have found is the more the

382
00:16:51,750 --> 00:16:55,230
predictable the workload is then the

383
00:16:53,760 --> 00:16:56,939
longer look ahead you can you can

384
00:16:55,230 --> 00:16:59,310
forecast in the future and the better

385
00:16:56,940 --> 00:17:01,860
plans you can come up with so that you

386
00:16:59,310 --> 00:17:03,599
are sure you are certain that your

387
00:17:01,860 --> 00:17:05,339
configuration decisions are not like

388
00:17:03,600 --> 00:17:06,870
greedy decisions it will not improve

389
00:17:05,339 --> 00:17:08,069
your performance for a short period of

390
00:17:06,869 --> 00:17:10,469
time and then your performance will

391
00:17:08,069 --> 00:17:12,599
degrade you have some sort of confidence

392
00:17:10,470 --> 00:17:14,430
that the configuration plan that you

393
00:17:12,599 --> 00:17:17,719
have right now would be like globally

394
00:17:14,430 --> 00:17:17,720
optimized plan

395
00:17:17,829 --> 00:17:24,760
sorry do you have any like testing

396
00:17:21,339 --> 00:17:27,599
result about how does the workload

397
00:17:24,760 --> 00:17:32,140
prediction accuracy affect the general

398
00:17:27,599 --> 00:17:33,909
primary arena in your paper yes we are

399
00:17:32,140 --> 00:17:36,550
there in the paper and we also put it in

400
00:17:33,910 --> 00:17:39,010
the poster I omitted it from the

401
00:17:36,550 --> 00:17:42,070
president for the sake of time but yeah

402
00:17:39,010 --> 00:17:45,160
please come to the poster and we can we

403
00:17:42,070 --> 00:17:46,540
can discuss all the other results

404
00:17:45,160 --> 00:17:48,070
related to the workload prediction and

405
00:17:46,540 --> 00:17:50,850
how it's impacting the performance of

406
00:17:48,070 --> 00:17:50,850
solution thank you

407
00:17:54,030 --> 00:18:00,160
let's call for questions all right well

408
00:17:58,450 --> 00:18:01,780
this concludes our session on big data

409
00:18:00,160 --> 00:18:03,720
programming models and frameworks let's

410
00:18:01,780 --> 00:18:08,369
thank all of our speakers

411
00:18:03,720 --> 00:18:08,369
[Applause]

