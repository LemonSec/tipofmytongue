1
00:00:10,120 --> 00:00:15,190
thanks for the introduction today I'm

2
00:00:13,390 --> 00:00:18,369
going to talk about our system called

3
00:00:15,190 --> 00:00:20,410
III which is to support micro service

4
00:00:18,369 --> 00:00:23,650
execution transparently on smartly

5
00:00:20,410 --> 00:00:26,948
accelerated servers to gain biter MJ and

6
00:00:23,650 --> 00:00:28,779
cost efficiency so this is a joint work

7
00:00:26,949 --> 00:00:32,710
among University Washington University

8
00:00:28,780 --> 00:00:34,570
exsisting and UC Berkeley our work is

9
00:00:32,710 --> 00:00:36,970
motivated by three recent trends

10
00:00:34,570 --> 00:00:38,860
happening in the data center first

11
00:00:36,970 --> 00:00:40,750
Angie efficiency has become a major

12
00:00:38,860 --> 00:00:43,059
factor in when designing today's data

13
00:00:40,750 --> 00:00:44,890
center it is reported that US data

14
00:00:43,059 --> 00:00:48,430
centers consume 70 billion kilowatt

15
00:00:44,890 --> 00:00:51,100
hours of energy per year and server CPUs

16
00:00:48,430 --> 00:00:55,780
consumed the most occupy 57 percentage

17
00:00:51,100 --> 00:00:57,550
of it the second trend is associated 6r

18
00:00:55,780 --> 00:01:00,460
emerged in the data center

19
00:00:57,550 --> 00:01:02,319
this morning's our new kind of hodgins

20
00:01:00,460 --> 00:01:05,229
computing platform in the data center

21
00:01:02,320 --> 00:01:07,720
they present only packet data path and

22
00:01:05,229 --> 00:01:10,390
can precise networking requests in short

23
00:01:07,720 --> 00:01:12,690
latency more importantly they consume

24
00:01:10,390 --> 00:01:15,880
much lower power than a service if you

25
00:01:12,690 --> 00:01:19,209
in this work we focusing on the liquidus

26
00:01:15,880 --> 00:01:20,979
marnix which includes an actor to have

27
00:01:19,209 --> 00:01:23,130
core mix processor running at one point

28
00:01:20,979 --> 00:01:25,660
two kickers a cup of Thomas vez

29
00:01:23,130 --> 00:01:28,330
accelerators like crypto engines Patton

30
00:01:25,660 --> 00:01:31,780
use pattern matching units or fetch and

31
00:01:28,330 --> 00:01:34,119
add atomic units this marnik has a wimpy

32
00:01:31,780 --> 00:01:37,060
memory hierarchy with 32 kilobytes and

33
00:01:34,119 --> 00:01:40,000
one cache for megabytes l2 cache and 4

34
00:01:37,060 --> 00:01:42,190
gig pass the rams as a result it can

35
00:01:40,000 --> 00:01:44,440
only hold applications with small

36
00:01:42,190 --> 00:01:48,640
application working set the semantics

37
00:01:44,440 --> 00:01:51,700
have 210 G ports the third strand is

38
00:01:48,640 --> 00:01:53,560
cloud applications increasingly built

39
00:01:51,700 --> 00:01:55,959
with these loosely coupled micro

40
00:01:53,560 --> 00:01:58,750
services such as ezra circle database

41
00:01:55,959 --> 00:01:59,470
the out here perhaps or video

42
00:01:58,750 --> 00:02:01,149
Processing's

43
00:01:59,470 --> 00:02:03,880
google ads or even complex scenarios

44
00:02:01,149 --> 00:02:06,160
like Netflix or Twitter these macro

45
00:02:03,880 --> 00:02:07,839
services are fine-grained with small

46
00:02:06,160 --> 00:02:09,728
memory footprint and they are

47
00:02:07,840 --> 00:02:12,640
communication intensives which is

48
00:02:09,729 --> 00:02:14,290
invoked with our pcs ural a programmers

49
00:02:12,640 --> 00:02:16,988
build macro service based applications

50
00:02:14,290 --> 00:02:19,689
with different kinds of models and in

51
00:02:16,989 --> 00:02:21,730
our work we applied it flow program

52
00:02:19,689 --> 00:02:23,170
model where programmers build

53
00:02:21,730 --> 00:02:25,540
applications by assembling

54
00:02:23,170 --> 00:02:27,519
that graphs as a result the

55
00:02:25,540 --> 00:02:29,679
communication patterns are explicitly

56
00:02:27,520 --> 00:02:31,120
assigned by the programmers so

57
00:02:29,680 --> 00:02:32,709
microservices are usually run by a

58
00:02:31,120 --> 00:02:34,870
cluster scheduler that is our service

59
00:02:32,709 --> 00:02:38,530
fabric our Google application engines as

60
00:02:34,870 --> 00:02:40,120
a result it is easy to explore cluster

61
00:02:38,530 --> 00:02:44,890
level architecture hitch heterogeneity

62
00:02:40,120 --> 00:02:47,440
by running micro service applications in

63
00:02:44,890 --> 00:02:49,179
this work we evaluate 8 micro service

64
00:02:47,440 --> 00:02:50,920
based applications from three common

65
00:02:49,180 --> 00:02:52,690
workload domain there are network

66
00:02:50,920 --> 00:02:56,230
function visualizations route Hampton

67
00:02:52,690 --> 00:02:58,959
and the nikes on or out here hubs each

68
00:02:56,230 --> 00:03:02,649
applications are comprised 60 to 108

69
00:02:58,959 --> 00:03:04,380
micro services here is an example shows

70
00:03:02,650 --> 00:03:06,940
Alethea thermostat analytic applications

71
00:03:04,380 --> 00:03:09,640
which is built with macro services and

72
00:03:06,940 --> 00:03:12,040
arranged in three stages the blue box

73
00:03:09,640 --> 00:03:15,700
here is macro service and the arrow here

74
00:03:12,040 --> 00:03:18,790
is RPC request flows request come from

75
00:03:15,700 --> 00:03:21,160
externally go to the API gateways and in

76
00:03:18,790 --> 00:03:23,049
the first stage the thermostat updates

77
00:03:21,160 --> 00:03:25,660
will be authenticated by the Gateway and

78
00:03:23,050 --> 00:03:28,060
in the second stage we will login the

79
00:03:25,660 --> 00:03:30,549
updates into a Charlotte so called store

80
00:03:28,060 --> 00:03:33,100
and finally we will trigger different

81
00:03:30,549 --> 00:03:35,350
kind of data and the next task expected

82
00:03:33,100 --> 00:03:39,310
actions expand removing average of some

83
00:03:35,350 --> 00:03:41,769
of recommendation tasks so based on

84
00:03:39,310 --> 00:03:45,160
these three chance we build III systems

85
00:03:41,769 --> 00:03:48,280
our idea here is to run micro services

86
00:03:45,160 --> 00:03:53,380
and smart links to gain vital energy

87
00:03:48,280 --> 00:03:55,690
efficiency with minimal latency cost so

88
00:03:53,380 --> 00:03:58,420
in our work we build two tabs of smyrna

89
00:03:55,690 --> 00:04:00,730
consumers why singles marnik server and

90
00:03:58,420 --> 00:04:03,700
otherwise a Maurice marnik server the

91
00:04:00,730 --> 00:04:06,429
first tab is a wire server box which has

92
00:04:03,700 --> 00:04:09,190
inhale Havel machine with 64 gig D rams

93
00:04:06,430 --> 00:04:12,940
with one liquid automatics they connect

94
00:04:09,190 --> 00:04:14,590
to the toss switch with 10g in links the

95
00:04:12,940 --> 00:04:17,500
second half is a two-year server box

96
00:04:14,590 --> 00:04:20,978
which has to inhale Broadway machines

97
00:04:17,500 --> 00:04:23,680
processors which 108 gig D rams and

98
00:04:20,978 --> 00:04:26,050
force monix the server blocks connected

99
00:04:23,680 --> 00:04:28,730
at all switch with a full HD ethernet

100
00:04:26,050 --> 00:04:30,950
break all cables

101
00:04:28,730 --> 00:04:33,980
the key questions which had to answer

102
00:04:30,950 --> 00:04:35,710
with III is like in terms of running

103
00:04:33,980 --> 00:04:38,690
macro service based applications

104
00:04:35,710 --> 00:04:40,060
that's marnik and based servers

105
00:04:38,690 --> 00:04:42,440
providing better energy efficiency

106
00:04:40,060 --> 00:04:45,440
compared with other homogeneous or

107
00:04:42,440 --> 00:04:47,570
hydrogen's cluster setups and in this

108
00:04:45,440 --> 00:04:50,240
work we consider three cans of cluster

109
00:04:47,570 --> 00:04:52,580
the first cluster is a homogenous BP

110
00:04:50,240 --> 00:04:55,370
cluster where each server is a super

111
00:04:52,580 --> 00:04:57,650
michael why you box has one in health 12

112
00:04:55,370 --> 00:05:00,920
core FF 2 6 and 0 with 3 processors

113
00:04:57,650 --> 00:05:04,299
running at 2 and 1/2 years it has 64

114
00:05:00,920 --> 00:05:06,770
kilograms with a inhale Nick's the

115
00:05:04,300 --> 00:05:08,930
second cluster is a homogenous wimpy

116
00:05:06,770 --> 00:05:11,539
cluster where each box is a standard

117
00:05:08,930 --> 00:05:16,190
slack settings and in our case we use

118
00:05:11,540 --> 00:05:19,390
why you caveum CN 6 8 8 0 SOC which has

119
00:05:16,190 --> 00:05:22,340
an account 32 core mips processors and

120
00:05:19,390 --> 00:05:25,310
it has 4 hit theorems and to tension

121
00:05:22,340 --> 00:05:28,250
ports and the third cluster is a

122
00:05:25,310 --> 00:05:32,510
hydrogenous cluster with containing two

123
00:05:28,250 --> 00:05:35,210
above-mentioned servers and in this work

124
00:05:32,510 --> 00:05:38,030
we use on board a PMA utility or

125
00:05:35,210 --> 00:05:40,340
external what's HAP repeater to measure

126
00:05:38,030 --> 00:05:43,299
the server power and we report class

127
00:05:40,340 --> 00:05:45,919
power by aggregating across all servers

128
00:05:43,300 --> 00:05:47,510
so here's the outline of the talk I will

129
00:05:45,920 --> 00:05:49,760
firstly discuss the challenge of

130
00:05:47,510 --> 00:05:52,849
immigrating smartness into macro service

131
00:05:49,760 --> 00:05:56,030
exclusion platforms and then we'll talk

132
00:05:52,850 --> 00:05:58,850
about how each atom in a three and then

133
00:05:56,030 --> 00:06:00,530
are we talking about the evaluations in

134
00:05:58,850 --> 00:06:02,720
terms of energy efficiency cost

135
00:06:00,530 --> 00:06:05,539
efficiency and latency and then I will

136
00:06:02,720 --> 00:06:07,730
conclude the talk so as we mentioned

137
00:06:05,540 --> 00:06:09,200
smartness is a new kind of hydrogens

138
00:06:07,730 --> 00:06:11,840
platform on the beta path

139
00:06:09,200 --> 00:06:14,000
it presents three challenge to integrate

140
00:06:11,840 --> 00:06:15,530
into macro service excursion the first

141
00:06:14,000 --> 00:06:18,290
challenge is addressing and load

142
00:06:15,530 --> 00:06:20,090
balancing because smart --ax share the

143
00:06:18,290 --> 00:06:22,010
same MAC address with the host server

144
00:06:20,090 --> 00:06:24,260
therefore traditional outer layer

145
00:06:22,010 --> 00:06:26,210
switching is not enough we need another

146
00:06:24,260 --> 00:06:29,810
address and a load balance mechanism to

147
00:06:26,210 --> 00:06:31,250
deliver traffic to the host server the

148
00:06:29,810 --> 00:06:34,070
second challenge is smarting over

149
00:06:31,250 --> 00:06:36,140
loading because micro services share the

150
00:06:34,070 --> 00:06:38,900
knee curry sauce with the NIC boomer

151
00:06:36,140 --> 00:06:41,510
when it is overloaded this Manik will

152
00:06:38,900 --> 00:06:42,438
not be able to deliver enough traffic to

153
00:06:41,510 --> 00:06:45,529
the host server

154
00:06:42,439 --> 00:06:48,110
and the third challenge is not uniform

155
00:06:45,529 --> 00:06:50,419
Canadian cost in our conversations we

156
00:06:48,110 --> 00:06:52,939
found like smart need to host performs

157
00:06:50,419 --> 00:06:55,519
faster then smart too smart and a smart

158
00:06:52,939 --> 00:06:56,419
you are not a remote host so these are

159
00:06:55,519 --> 00:06:59,929
three challenge

160
00:06:56,419 --> 00:07:02,839
we found an easy three we address them

161
00:06:59,929 --> 00:07:05,239
with three tactics so from a Halawa bio

162
00:07:02,839 --> 00:07:07,429
III is a micro service excursion

163
00:07:05,239 --> 00:07:09,289
platform it follows the design

164
00:07:07,429 --> 00:07:11,508
philosophy of a sure service fabric and

165
00:07:09,289 --> 00:07:13,998
as three techniques to support smart

166
00:07:11,509 --> 00:07:16,279
eeks they are ecmp based the load

167
00:07:13,999 --> 00:07:17,989
balancing a load aware cluster manager

168
00:07:16,279 --> 00:07:21,019
and the communication of wire micro

169
00:07:17,989 --> 00:07:22,669
service placement algorithms the first

170
00:07:21,019 --> 00:07:25,189
techniques is ecmp based the load

171
00:07:22,669 --> 00:07:28,399
balancing which is an interest server

172
00:07:25,189 --> 00:07:30,589
addressing mechanisms it works in three

173
00:07:28,399 --> 00:07:32,989
steps first we assign different

174
00:07:30,589 --> 00:07:35,539
semantics and host server with different

175
00:07:32,989 --> 00:07:38,539
IPS and this is for addressing the host

176
00:07:35,539 --> 00:07:40,219
server and in the second step we will

177
00:07:38,539 --> 00:07:42,558
apply a nickimja to bound all the

178
00:07:40,219 --> 00:07:43,998
available smart ports and exposing what

179
00:07:42,559 --> 00:07:46,639
knowledge we interface to the host

180
00:07:43,999 --> 00:07:50,149
server as a result the host server can

181
00:07:46,639 --> 00:07:52,189
use all this Meramec downwards and in

182
00:07:50,149 --> 00:07:55,849
the last step will enable a CMP across

183
00:07:52,189 --> 00:07:57,919
which so consider the ingress traffic

184
00:07:55,849 --> 00:08:00,529
the load balancing we realize on the

185
00:07:57,919 --> 00:08:03,849
ICMP at a switch and on the egress side

186
00:08:00,529 --> 00:08:06,529
we will rely on the NIC teaming policies

187
00:08:03,849 --> 00:08:09,019
so compared with the case with other of

188
00:08:06,529 --> 00:08:10,419
approach where all traffic comes comes

189
00:08:09,019 --> 00:08:13,219
through wise marnix

190
00:08:10,419 --> 00:08:15,438
our mechanism achieved two and half acts

191
00:08:13,219 --> 00:08:17,569
better her throughput which translates

192
00:08:15,439 --> 00:08:22,249
to to a 2.2 backs better engine

193
00:08:17,569 --> 00:08:23,749
efficiency the second technique we

194
00:08:22,249 --> 00:08:26,300
propose is a load of wire cluster

195
00:08:23,749 --> 00:08:28,669
manager and is try to avoid host

196
00:08:26,300 --> 00:08:30,469
starvation the problem happens because

197
00:08:28,669 --> 00:08:32,870
micro service interference with the NIC

198
00:08:30,469 --> 00:08:34,458
premier as a result they were containing

199
00:08:32,870 --> 00:08:38,328
for the semantic memory and cache

200
00:08:34,458 --> 00:08:40,250
resources to address this problem we

201
00:08:38,328 --> 00:08:42,529
rely on the class manager the class

202
00:08:40,250 --> 00:08:44,779
manager will keep monitoring the ingress

203
00:08:42,529 --> 00:08:47,180
packet killed out of this Manik and the

204
00:08:44,779 --> 00:08:48,620
macro service CPU intensive and then

205
00:08:47,180 --> 00:08:50,750
when it is finally it is above the

206
00:08:48,620 --> 00:08:52,639
threshold the class manager will migrate

207
00:08:50,750 --> 00:08:55,069
the CPU entitled micro services to

208
00:08:52,639 --> 00:08:56,240
another commutation node and our

209
00:08:55,069 --> 00:08:58,128
approach

210
00:08:56,240 --> 00:08:59,540
we only had a two month views to the

211
00:08:58,129 --> 00:09:01,999
original service fabric heartbeat

212
00:08:59,540 --> 00:09:06,019
message why is the NICU tab another one

213
00:09:01,999 --> 00:09:08,899
CPU intensity so when enabling our

214
00:09:06,019 --> 00:09:10,999
approach it can achieve high point now

215
00:09:08,899 --> 00:09:15,199
expand her energy efficiency and reduce

216
00:09:10,999 --> 00:09:17,480
latency by 27 percentage the third

217
00:09:15,199 --> 00:09:18,800
technique we propose is a communication

218
00:09:17,480 --> 00:09:21,499
a wire micro service policeman

219
00:09:18,800 --> 00:09:23,569
algorithms which is try to consider the

220
00:09:21,499 --> 00:09:26,660
nine uniform combination cost presenting

221
00:09:23,569 --> 00:09:28,849
in the smarting servers in the service

222
00:09:26,660 --> 00:09:31,129
fabric it applies a stimulus a living

223
00:09:28,850 --> 00:09:32,839
method and consider a cup of constraint

224
00:09:31,129 --> 00:09:34,610
such as the slack and all the

225
00:09:32,839 --> 00:09:36,740
information like how many CPU cores in

226
00:09:34,610 --> 00:09:38,300
the one community node and what's the

227
00:09:36,740 --> 00:09:40,730
memory capacity of each combination node

228
00:09:38,300 --> 00:09:43,758
and also and some other runtime statics

229
00:09:40,730 --> 00:09:45,170
like CPU Network utilizations they

230
00:09:43,759 --> 00:09:48,860
didn't consider the communication

231
00:09:45,170 --> 00:09:50,569
distance between two micro services Andy

232
00:09:48,860 --> 00:09:52,579
our approach we proposed a hero

233
00:09:50,569 --> 00:09:55,729
communication a wire micro service

234
00:09:52,579 --> 00:09:57,920
placement algorithm specifically it

235
00:09:55,730 --> 00:09:59,689
organized the commutation nose into

236
00:09:57,920 --> 00:10:01,699
different levels of combination distance

237
00:09:59,689 --> 00:10:03,799
and we placed communication

238
00:10:01,699 --> 00:10:06,229
communicating micro services close to

239
00:10:03,799 --> 00:10:09,949
each other and we provide a high rocky

240
00:10:06,230 --> 00:10:12,049
way to prune the search space so our ik

241
00:10:09,949 --> 00:10:14,809
algorithm takes three inputs which a

242
00:10:12,049 --> 00:10:17,119
subset of service fabric it is micro

243
00:10:14,809 --> 00:10:19,309
service that graphs the soft macro node

244
00:10:17,119 --> 00:10:22,399
of the graph and the server cluster

245
00:10:19,309 --> 00:10:24,529
topology the Ariat work algorithm will

246
00:10:22,399 --> 00:10:26,629
performs a breadth-first traversal of

247
00:10:24,529 --> 00:10:29,059
the graph and map each micro service

248
00:10:26,629 --> 00:10:30,009
node to a computation node in the

249
00:10:29,059 --> 00:10:32,299
cluster

250
00:10:30,009 --> 00:10:35,179
so consider the following single rack

251
00:10:32,299 --> 00:10:36,619
examples we will put out if we put the

252
00:10:35,179 --> 00:10:39,230
first macro series on the smart neck

253
00:10:36,619 --> 00:10:42,529
node then L 1 will be the same condition

254
00:10:39,230 --> 00:10:44,089
node as the originals marnik the layer 2

255
00:10:42,529 --> 00:10:46,309
will be another combination node on the

256
00:10:44,089 --> 00:10:48,019
same server and layer 3 will be a

257
00:10:46,309 --> 00:10:50,179
neither smart condition node and

258
00:10:48,019 --> 00:10:53,389
therefore will be a host accumulation

259
00:10:50,179 --> 00:10:54,709
node on other servers compared with the

260
00:10:53,389 --> 00:10:57,199
service fabric approach

261
00:10:54,709 --> 00:10:59,149
HCM improves energy efficiency by 16

262
00:10:57,199 --> 00:11:02,929
percentage and reduce latency by 13

263
00:10:59,149 --> 00:11:05,720
percentage so we build III on commodity

264
00:11:02,929 --> 00:11:08,110
hardware and compare with different

265
00:11:05,720 --> 00:11:10,070
cluster topology as we mentioned before

266
00:11:08,110 --> 00:11:12,710
so first they have a talk

267
00:11:10,070 --> 00:11:15,110
the energy efficiency caliphates we take

268
00:11:12,710 --> 00:11:17,090
three smart ik singles money servers and

269
00:11:15,110 --> 00:11:18,830
the three in help if he service and the

270
00:11:17,090 --> 00:11:21,770
wit deploy as mine as application

271
00:11:18,830 --> 00:11:23,780
instances as possible where III and then

272
00:11:21,770 --> 00:11:25,550
we increasing the current site workload

273
00:11:23,780 --> 00:11:27,199
to maximize through coos but without

274
00:11:25,550 --> 00:11:28,430
overloading it and this is the paid

275
00:11:27,200 --> 00:11:31,940
based on the latency and throughput

276
00:11:28,430 --> 00:11:35,689
curve and then we measure the clusters

277
00:11:31,940 --> 00:11:37,280
throughput and the cluster power so the

278
00:11:35,690 --> 00:11:39,620
following figure shows the energy

279
00:11:37,280 --> 00:11:41,630
efficiency in terms of thousands

280
00:11:39,620 --> 00:11:45,260
requests per true for eight different

281
00:11:41,630 --> 00:11:46,850
applications and for the LT thermostat

282
00:11:45,260 --> 00:11:48,830
applications that we show before and the

283
00:11:46,850 --> 00:11:50,600
data and the next applications so on

284
00:11:48,830 --> 00:11:52,370
average for this queue application it

285
00:11:50,600 --> 00:11:55,880
achieve 1.3 x better energy efficiency

286
00:11:52,370 --> 00:11:58,100
and for the three rule template and the

287
00:11:55,880 --> 00:12:00,920
next applications like the twitter the

288
00:11:58,100 --> 00:12:02,780
unalaq's Analects application spam

289
00:12:00,920 --> 00:12:05,089
filter or server health monitoring

290
00:12:02,780 --> 00:12:08,270
application on average it also achieved

291
00:12:05,090 --> 00:12:09,350
1.3 x better energy efficiency and for 3

292
00:12:08,270 --> 00:12:11,800
network function virtualization

293
00:12:09,350 --> 00:12:14,420
applications they have flow deductions

294
00:12:11,800 --> 00:12:16,969
ip68 ways and instrument detection on

295
00:12:14,420 --> 00:12:19,310
average it achieved to an half x better

296
00:12:16,970 --> 00:12:21,680
energy efficiency and the full list one

297
00:12:19,310 --> 00:12:24,680
is is because we can offload in more

298
00:12:21,680 --> 00:12:26,420
macro service to this marnik to take one

299
00:12:24,680 --> 00:12:29,260
page of this morning accelerators and

300
00:12:26,420 --> 00:12:32,110
the ship completion apparel isms there

301
00:12:29,260 --> 00:12:35,540
we use the same experiment setup to

302
00:12:32,110 --> 00:12:37,130
evaluate latency so the following figure

303
00:12:35,540 --> 00:12:38,599
shows the average returns the in terms

304
00:12:37,130 --> 00:12:42,560
of milliseconds for eight applications

305
00:12:38,600 --> 00:12:45,380
and we compare two sightings we observe

306
00:12:42,560 --> 00:12:47,150
at most four percent agency cost for one

307
00:12:45,380 --> 00:12:50,720
of the real-time edited and tax

308
00:12:47,150 --> 00:12:53,780
applications and this is because in III

309
00:12:50,720 --> 00:12:55,760
it only put the comp microservices on

310
00:12:53,780 --> 00:12:57,650
ass morning and put all the other macro

311
00:12:55,760 --> 00:12:58,970
services on the whole society as a

312
00:12:57,650 --> 00:13:01,220
result there will be some unnecessary

313
00:12:58,970 --> 00:13:05,060
communication happens between semantic

314
00:13:01,220 --> 00:13:08,510
and host servers next I will talk about

315
00:13:05,060 --> 00:13:11,959
our cost efficiency of running micros

316
00:13:08,510 --> 00:13:13,819
Martic service we used the request per

317
00:13:11,960 --> 00:13:16,100
dollar as a metric and applies the

318
00:13:13,820 --> 00:13:18,140
following a formula the formula will

319
00:13:16,100 --> 00:13:20,930
consider the peak Michael service

320
00:13:18,140 --> 00:13:22,939
throughput in time and divided by the

321
00:13:20,930 --> 00:13:25,010
total cost of ownership in time

322
00:13:22,940 --> 00:13:27,280
and this cost including the capital cost

323
00:13:25,010 --> 00:13:31,189
which is constant and also the peak

324
00:13:27,280 --> 00:13:33,589
class or energy cost in high so the

325
00:13:31,190 --> 00:13:37,190
folding figure compares four different

326
00:13:33,590 --> 00:13:39,560
cluster setups for web applications so X

327
00:13:37,190 --> 00:13:41,810
is a time of ownership the application

328
00:13:39,560 --> 00:13:44,119
here is some health ammonia applications

329
00:13:41,810 --> 00:13:48,380
this application has both Iowa and

330
00:13:44,120 --> 00:13:51,500
compute impassive micro-services so in

331
00:13:48,380 --> 00:13:53,230
our case it ship up to 1.9 passed more

332
00:13:51,500 --> 00:13:56,060
cost efficiency after five years

333
00:13:53,230 --> 00:13:59,030
compared with the second pass case which

334
00:13:56,060 --> 00:14:02,150
is the beefy concert and this is best

335
00:13:59,030 --> 00:14:04,850
case for up eight applications and for

336
00:14:02,150 --> 00:14:06,260
the worst case we can see their network

337
00:14:04,850 --> 00:14:07,790
function virtualization application

338
00:14:06,260 --> 00:14:10,130
which is flow monitoring and this is

339
00:14:07,790 --> 00:14:11,599
pure our intensive and we found like

340
00:14:10,130 --> 00:14:14,840
when we cluster is the most cost

341
00:14:11,600 --> 00:14:16,760
efficient one and our per approach the

342
00:14:14,840 --> 00:14:19,850
modest marnik cluster runs the second

343
00:14:16,760 --> 00:14:23,990
which is 14 percentage layers after five

344
00:14:19,850 --> 00:14:26,480
years then the best one in the paper we

345
00:14:23,990 --> 00:14:29,240
have more evaluations such as the power

346
00:14:26,480 --> 00:14:32,260
personality and how our mechanisms

347
00:14:29,240 --> 00:14:36,110
performs at scale

348
00:14:32,260 --> 00:14:39,500
so to conclude marks our Hajis computing

349
00:14:36,110 --> 00:14:42,350
units on the beta path and in this work

350
00:14:39,500 --> 00:14:44,510
we build the III systems to offloading

351
00:14:42,350 --> 00:14:46,940
macro service and managed service to

352
00:14:44,510 --> 00:14:48,410
gain better energy efficiency in

353
00:14:46,940 --> 00:14:50,810
particularly would propose three

354
00:14:48,410 --> 00:14:52,880
techniques I is the MP based load

355
00:14:50,810 --> 00:14:55,550
balancer mechanism unload aware cluster

356
00:14:52,880 --> 00:14:58,130
manager and a communication a wire micro

357
00:14:55,550 --> 00:15:00,170
service placement algorithms we build

358
00:14:58,130 --> 00:15:01,850
the system on Molly hardware's and Luke

359
00:15:00,170 --> 00:15:03,560
allows marnix and compared with

360
00:15:01,850 --> 00:15:06,190
different cans of homogeneous or

361
00:15:03,560 --> 00:15:08,839
heterogeneous clusters and we found like

362
00:15:06,190 --> 00:15:11,210
smiling servers could ship up to 3x

363
00:15:08,839 --> 00:15:13,670
better energy efficiency with at most

364
00:15:11,210 --> 00:15:16,910
four percent identity cost and when

365
00:15:13,670 --> 00:15:19,250
applications can contain both IO and

366
00:15:16,910 --> 00:15:21,230
compute intensive microservices it

367
00:15:19,250 --> 00:15:23,620
achieve up to one point not better cause

368
00:15:21,230 --> 00:15:26,060
efficiency after five years of ownership

369
00:15:23,620 --> 00:15:29,420
that's what I have for today

370
00:15:26,060 --> 00:15:35,760
thanks I'd like to take questions

371
00:15:29,420 --> 00:15:35,760
[Applause]

372
00:15:37,570 --> 00:15:42,410
Idina EPFL great talk I just have a

373
00:15:40,970 --> 00:15:45,110
technical question so if you combine

374
00:15:42,410 --> 00:15:47,779
these cmp with nic teaming on a regular

375
00:15:45,110 --> 00:15:49,430
server without smart NICs you end up

376
00:15:47,779 --> 00:15:51,260
having this this key effect which is

377
00:15:49,430 --> 00:15:53,029
that the flows the two directions of the

378
00:15:51,260 --> 00:15:54,620
flows are not going on down the same

379
00:15:53,029 --> 00:15:57,350
wires right and that's perfectly fine

380
00:15:54,620 --> 00:15:58,730
and perfectly not a problem in your case

381
00:15:57,350 --> 00:16:01,010
it seems that you need to make sure that

382
00:15:58,730 --> 00:16:02,420
the two directions of the same flow are

383
00:16:01,010 --> 00:16:04,730
handled by the same path I'm just

384
00:16:02,420 --> 00:16:07,670
wondering how you do that like the

385
00:16:04,730 --> 00:16:10,370
question is in our case on the ingress

386
00:16:07,670 --> 00:16:12,709
side we rely on the TSM ecmp

387
00:16:10,370 --> 00:16:14,420
and on the egress that we rely on the

388
00:16:12,710 --> 00:16:16,040
NIC teaming and how to make sure the

389
00:16:14,420 --> 00:16:17,329
flow goes to the same wire is that

390
00:16:16,040 --> 00:16:19,189
questions yeah that's the question

391
00:16:17,330 --> 00:16:20,570
because it's not guaranteed if you just

392
00:16:19,190 --> 00:16:24,410
use NIC teaming and ecmp

393
00:16:20,570 --> 00:16:26,060
vanilla yes yes so in our case we didn't

394
00:16:24,410 --> 00:16:28,850
make sure they are the ingress and

395
00:16:26,060 --> 00:16:30,439
egress code flow go to the different go

396
00:16:28,850 --> 00:16:32,150
to the same wire because they are two

397
00:16:30,440 --> 00:16:34,730
different flows with different laptop

398
00:16:32,150 --> 00:16:36,350
host therefore in our case we on the

399
00:16:34,730 --> 00:16:37,790
inquire set an equal side based on

400
00:16:36,350 --> 00:16:42,920
different hashing policies they will go

401
00:16:37,790 --> 00:16:47,120
to different things I Thomas from Tuvan

402
00:16:42,920 --> 00:16:50,689
you showed that the relative energy

403
00:16:47,120 --> 00:16:52,970
efficiency per request is is better did

404
00:16:50,690 --> 00:16:55,459
you also analyze the overall absolute

405
00:16:52,970 --> 00:16:59,240
impact on the on the energy consumption

406
00:16:55,459 --> 00:17:02,329
of the data center you mean overall in

407
00:16:59,240 --> 00:17:05,359
terms of write how much energy would be

408
00:17:02,330 --> 00:17:10,970
with the data center consume less with

409
00:17:05,359 --> 00:17:14,479
your approach so we don't we don't have

410
00:17:10,970 --> 00:17:16,790
data center scale evaluations so in the

411
00:17:14,480 --> 00:17:19,280
paper we present the data for a cluster

412
00:17:16,790 --> 00:17:21,109
scale and we show how much lens a we can

413
00:17:19,280 --> 00:17:23,928
energy we can save compared with

414
00:17:21,109 --> 00:17:25,520
different other clusters at how's about

415
00:17:23,929 --> 00:17:27,890
we have the detailed data in the paper

416
00:17:25,520 --> 00:17:29,690
but it's not in the data center scale is

417
00:17:27,890 --> 00:17:36,440
in the classic scale that we are

418
00:17:29,690 --> 00:17:38,450
evaluating hi Mario here see bfl great

419
00:17:36,440 --> 00:17:40,070
work have a question about your load

420
00:17:38,450 --> 00:17:42,440
aware classroom management

421
00:17:40,070 --> 00:17:42,879
how fast can it react to load changes so

422
00:17:42,440 --> 00:17:44,320
what

423
00:17:42,880 --> 00:17:46,780
kind of floating balances are you going

424
00:17:44,320 --> 00:17:50,379
after yes so that's a quick questions

425
00:17:46,780 --> 00:17:52,090
the question is how react how fast we

426
00:17:50,380 --> 00:17:54,100
can detecting the load change and then

427
00:17:52,090 --> 00:17:56,909
make the migration decisions so in this

428
00:17:54,100 --> 00:18:00,310
case the trade-off is depending the

429
00:17:56,910 --> 00:18:04,170
heartbeat message frequency therefore

430
00:18:00,310 --> 00:18:06,879
our reaction to light will be bounded by

431
00:18:04,170 --> 00:18:09,340
the periodical heartbeat message

432
00:18:06,880 --> 00:18:12,190
frequency and it will be two round-trips

433
00:18:09,340 --> 00:18:13,750
to the cluster wines to the cluster two

434
00:18:12,190 --> 00:18:16,060
tag to know the information and then

435
00:18:13,750 --> 00:18:18,580
make the migration decision to the

436
00:18:16,060 --> 00:18:21,129
semantic then migration and that is a

437
00:18:18,580 --> 00:18:25,530
parameter that can be twins in our

438
00:18:21,130 --> 00:18:29,619
systems let's somehow uh speak again

439
00:18:25,530 --> 00:18:29,619
[Applause]

