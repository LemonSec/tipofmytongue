1
00:00:10,259 --> 00:00:15,570
hello everyone I'm ninja man from Peking

2
00:00:13,049 --> 00:00:18,240
University in China today I will talk

3
00:00:15,570 --> 00:00:20,400
about our work new graph parallel deep

4
00:00:18,240 --> 00:00:23,430
neural network computation and large

5
00:00:20,400 --> 00:00:27,630
graphs they seojun's work with Microsoft

6
00:00:23,430 --> 00:00:30,320
Research Asia deep neural networks have

7
00:00:27,630 --> 00:00:33,180
achieved the processes in many areas

8
00:00:30,320 --> 00:00:36,120
recently the area emerging training of

9
00:00:33,180 --> 00:00:38,339
random neural diplomas and graphs known

10
00:00:36,120 --> 00:00:40,769
as graph neural networks and they have

11
00:00:38,339 --> 00:00:43,350
achieved a commencing model accuracy in

12
00:00:40,769 --> 00:00:46,500
many real-world application applications

13
00:00:43,350 --> 00:00:48,859
free demo it can learn features from the

14
00:00:46,500 --> 00:00:52,890
user item graph for higher quality

15
00:00:48,859 --> 00:00:54,539
recommendation genes aggregates

16
00:00:52,890 --> 00:00:57,989
information following in the graph

17
00:00:54,539 --> 00:01:01,079
structure specifically each voters are h

18
00:00:57,989 --> 00:01:04,319
in the graph can be associated with a

19
00:01:01,079 --> 00:01:08,580
set of data as its features so children

20
00:01:04,319 --> 00:01:11,250
can consider multiple layers with the

21
00:01:08,580 --> 00:01:14,490
authority of publication conducted a

22
00:01:11,250 --> 00:01:17,069
layer by layer over the sink graph as I

23
00:01:14,490 --> 00:01:19,800
said each layer the buttress our age

24
00:01:17,069 --> 00:01:23,190
features are transformed and propagated

25
00:01:19,800 --> 00:01:26,459
along edges and then aggregated as the

26
00:01:23,190 --> 00:01:30,179
target vertices to produce new features

27
00:01:26,459 --> 00:01:33,300
for the next layer traditional genes

28
00:01:30,179 --> 00:01:35,940
have small and regular grade greatest

29
00:01:33,300 --> 00:01:36,360
structures which is friendly to chip

30
00:01:35,940 --> 00:01:40,739
jewels

31
00:01:36,360 --> 00:01:43,860
however engines graphs are large sparse

32
00:01:40,739 --> 00:01:45,920
and irregular we are to instability and

33
00:01:43,860 --> 00:01:48,959
efficiency problem

34
00:01:45,920 --> 00:01:51,619
there are many if not in systems like

35
00:01:48,959 --> 00:01:54,780
conserve low for neural network

36
00:01:51,619 --> 00:01:57,810
processing here is a simple example to

37
00:01:54,780 --> 00:02:01,110
describe how if learning systems wrong

38
00:01:57,810 --> 00:02:04,770
first with near several placeholders for

39
00:02:01,110 --> 00:02:09,090
input data then with layers forward

40
00:02:04,770 --> 00:02:11,640
computation logics ways operators deep

41
00:02:09,090 --> 00:02:13,950
learning systems can automatically

42
00:02:11,640 --> 00:02:16,319
generates the parallel computation

43
00:02:13,950 --> 00:02:19,920
without word differentiation to compute

44
00:02:16,319 --> 00:02:23,219
the gradients with this code we

45
00:02:19,920 --> 00:02:24,030
construct a graph called the flow graph

46
00:02:23,219 --> 00:02:26,850
as

47
00:02:24,030 --> 00:02:31,280
intermediate representation in deep

48
00:02:26,850 --> 00:02:34,799
learning training the data flow graph

49
00:02:31,280 --> 00:02:36,810
abstraction easily price neural networks

50
00:02:34,800 --> 00:02:40,010
and the affection for neural network

51
00:02:36,810 --> 00:02:43,230
occlusion however is hard to impress

52
00:02:40,010 --> 00:02:45,899
graph operations and handle large graphs

53
00:02:43,230 --> 00:02:49,769
because it takes the whole graph at

54
00:02:45,900 --> 00:02:53,040
attention without graph awareness most

55
00:02:49,770 --> 00:02:55,350
recently tgl was deep learning systems

56
00:02:53,040 --> 00:02:58,019
as graphic interfaces for teen

57
00:02:55,350 --> 00:03:00,030
programming however it has a single

58
00:02:58,020 --> 00:03:02,430
scalability and associated problems

59
00:03:00,030 --> 00:03:05,600
because the patient works as euro

60
00:03:02,430 --> 00:03:08,489
without her prefer wellness

61
00:03:05,600 --> 00:03:11,459
there are also many craft engines for

62
00:03:08,489 --> 00:03:15,239
last girl who are computing the problem

63
00:03:11,459 --> 00:03:19,020
as an example describe how car engines

64
00:03:15,239 --> 00:03:21,150
run first we define the keidel function

65
00:03:19,020 --> 00:03:24,090
to describe how a vertex gets

66
00:03:21,150 --> 00:03:27,150
information from its in neighbors then

67
00:03:24,090 --> 00:03:31,049
the apply function used to update itself

68
00:03:27,150 --> 00:03:34,980
ways gather the information fanime the

69
00:03:31,049 --> 00:03:37,140
battle send messages to the output to

70
00:03:34,980 --> 00:03:39,780
the out neighbors with the scatter

71
00:03:37,140 --> 00:03:42,720
function the whole procedure is defined

72
00:03:39,780 --> 00:03:47,190
in your bottles bill called butters

73
00:03:42,720 --> 00:03:51,750
programming thus graph engines candle

74
00:03:47,190 --> 00:03:54,000
each motors minor it is easy to use

75
00:03:51,750 --> 00:03:56,730
graph models to program graph

76
00:03:54,000 --> 00:03:58,709
applications like page rank and apply a

77
00:03:56,730 --> 00:04:00,328
grant for organizations and skill to

78
00:03:58,709 --> 00:04:03,420
very large graphs

79
00:04:00,329 --> 00:04:05,519
however these systems are hard to

80
00:04:03,420 --> 00:04:07,859
impress neural networks and an

81
00:04:05,519 --> 00:04:09,900
instruction for neural network occlusion

82
00:04:07,860 --> 00:04:13,799
due to the lake hub data flow

83
00:04:09,900 --> 00:04:16,228
obstruction we propose new graph which

84
00:04:13,799 --> 00:04:19,620
bridges graph and the data flow models

85
00:04:16,228 --> 00:04:22,260
to learn wisdom and benefit from both -

86
00:04:19,620 --> 00:04:25,410
supported fashion skill Bojan processing

87
00:04:22,260 --> 00:04:28,680
it contains a second model for

88
00:04:25,410 --> 00:04:31,020
programming applications trump a static

89
00:04:28,680 --> 00:04:32,849
flow graph translation and streaming

90
00:04:31,020 --> 00:04:35,849
processing auto imperial court to

91
00:04:32,849 --> 00:04:37,680
support large graphs we also designed

92
00:04:35,849 --> 00:04:40,440
highly optimized

93
00:04:37,680 --> 00:04:43,070
operators of aqua publication and the

94
00:04:40,440 --> 00:04:46,020
chin based parallel stream means

95
00:04:43,070 --> 00:04:48,990
strategy for fashion the material

96
00:04:46,020 --> 00:04:50,630
culture with these standings new graph

97
00:04:48,990 --> 00:04:53,760
outperform state-of-the-art

98
00:04:50,630 --> 00:04:56,550
implementations and smoke was 13 to TPO

99
00:04:53,760 --> 00:05:00,210
memory and skills to large graphs with

100
00:04:56,550 --> 00:05:01,620
trip use first let's talk about the

101
00:05:00,210 --> 00:05:04,919
certain objection

102
00:05:01,620 --> 00:05:07,290
there are four stages in stock first the

103
00:05:04,919 --> 00:05:09,930
scheduler propagates information from

104
00:05:07,290 --> 00:05:13,169
works to the age to prepare data for the

105
00:05:09,930 --> 00:05:15,840
age transformation then the ages

106
00:05:13,169 --> 00:05:19,198
recommends new network computation on

107
00:05:15,840 --> 00:05:21,570
age to transform the H theta then the

108
00:05:19,199 --> 00:05:25,110
transform the each data are gathered to

109
00:05:21,570 --> 00:05:27,479
the destination vertex finally the apply

110
00:05:25,110 --> 00:05:30,090
button represents the neural network

111
00:05:27,479 --> 00:05:34,169
computation and robotics to transform

112
00:05:30,090 --> 00:05:37,320
the approach from the can the from the

113
00:05:34,169 --> 00:05:40,669
Kaiser stage those four stages the final

114
00:05:37,320 --> 00:05:47,840
layout and users can define multiple

115
00:05:40,669 --> 00:05:51,270
layers in second schedule and gather

116
00:05:47,840 --> 00:05:55,440
work operations which are transparent to

117
00:05:51,270 --> 00:05:59,460
users where her age and apply buttons

118
00:05:55,440 --> 00:06:02,099
neural network operations where users

119
00:05:59,460 --> 00:06:05,700
define neural network computation with

120
00:06:02,099 --> 00:06:08,520
data flow hurried here is an example

121
00:06:05,700 --> 00:06:13,590
describe how to my graph convolutional

122
00:06:08,520 --> 00:06:16,139
network to occur in t-cell information

123
00:06:13,590 --> 00:06:19,440
from neighbors much pride with the

124
00:06:16,139 --> 00:06:23,870
scanner value underage so we implement

125
00:06:19,440 --> 00:06:27,180
multiple operator in the apply age as

126
00:06:23,870 --> 00:06:31,080
accumulator item to sum up neighbors

127
00:06:27,180 --> 00:06:33,060
information then this in highly

128
00:06:31,080 --> 00:06:36,419
connected the neural network on the

129
00:06:33,060 --> 00:06:40,020
Balkans so we implement it in the apply

130
00:06:36,419 --> 00:06:42,510
bottles the skoda represent a layer of

131
00:06:40,020 --> 00:06:45,270
the cell and we can implement multiple

132
00:06:42,510 --> 00:06:49,650
layers artisan by staking it layer by

133
00:06:45,270 --> 00:06:51,209
layer in each layout ian the buttress

134
00:06:49,650 --> 00:06:55,138
features and

135
00:06:51,209 --> 00:06:58,949
from the previous layer used to compute

136
00:06:55,139 --> 00:07:01,740
the new voters features however most

137
00:06:58,949 --> 00:07:05,789
real-world graphs lunch and kind of it

138
00:07:01,740 --> 00:07:09,349
cannot fit into GPU memory thanks to the

139
00:07:05,789 --> 00:07:12,449
model in second we can leverage

140
00:07:09,349 --> 00:07:15,089
competition to scale to large graphs new

141
00:07:12,449 --> 00:07:16,919
graph carefully combines competition

142
00:07:15,089 --> 00:07:21,089
wasted Pro to solve the scalability

143
00:07:16,919 --> 00:07:23,698
problem India specifically will average

144
00:07:21,089 --> 00:07:26,789
the truth equal partition the vertices

145
00:07:23,699 --> 00:07:29,909
and edges are partitioned into trunks

146
00:07:26,789 --> 00:07:32,789
for example to compute the new budget

147
00:07:29,909 --> 00:07:36,539
Ronco federal cloud which contains

148
00:07:32,789 --> 00:07:39,209
butters the arrow industry they need to

149
00:07:36,539 --> 00:07:44,699
gather information from neighbor waters

150
00:07:39,209 --> 00:07:47,699
1 & 3 in trunk in general and y1 0 then

151
00:07:44,699 --> 00:07:50,219
we can precise the world trunk by trunk

152
00:07:47,699 --> 00:07:53,879
in the limited Egyptian memory there is

153
00:07:50,219 --> 00:07:56,939
a scheduling problem we can consume the

154
00:07:53,879 --> 00:08:00,509
trunk row by row or column by column or

155
00:07:56,939 --> 00:08:03,629
any other orders however we observe that

156
00:08:00,509 --> 00:08:06,749
the intermediate data can be accumulated

157
00:08:03,629 --> 00:08:10,409
in GPU memory to reduce host device

158
00:08:06,749 --> 00:08:14,099
communication thus we take the column by

159
00:08:10,409 --> 00:08:14,639
column scheduling policy with grand

160
00:08:14,099 --> 00:08:17,308
partition

161
00:08:14,639 --> 00:08:20,399
new cough translates the second program

162
00:08:17,309 --> 00:08:23,429
to trunk base that inflow graph existing

163
00:08:20,399 --> 00:08:26,279
as either example to compute the trunk

164
00:08:23,429 --> 00:08:33,019
by the rocket we need to control a trunk

165
00:08:26,279 --> 00:08:36,299
with video either 0 and trunk V 1 Y 1 0

166
00:08:33,019 --> 00:08:39,568
with a column by column scheduling

167
00:08:36,299 --> 00:08:43,740
policy we first calculate either 0 with

168
00:08:39,568 --> 00:08:46,370
scatter of her age gather an object a

169
00:08:43,740 --> 00:08:50,000
human of this trunk

170
00:08:46,370 --> 00:08:53,790
specifically idea GT only has a

171
00:08:50,000 --> 00:08:56,850
multiplier operation for sauce bottles

172
00:08:53,790 --> 00:09:00,930
an age which cannot match prior operator

173
00:08:56,850 --> 00:09:03,149
between scattering gather thus the sauce

174
00:09:00,930 --> 00:09:04,290
bottle stator invaders are much more

175
00:09:03,149 --> 00:09:08,790
with age

176
00:09:04,290 --> 00:09:10,199
in a barrel and gathered to the water to

177
00:09:08,790 --> 00:09:13,769
upload an app you

178
00:09:10,199 --> 00:09:14,310
an interesting manner for trunk you and

179
00:09:13,769 --> 00:09:17,279
arrow

180
00:09:14,310 --> 00:09:20,310
after that the neighbors information had

181
00:09:17,279 --> 00:09:23,339
been corrected as a destination but he

182
00:09:20,310 --> 00:09:27,109
says then the robotics the function used

183
00:09:23,339 --> 00:09:31,339
to transform the data and outputs the

184
00:09:27,110 --> 00:09:35,399
way the robot and me one code can be

185
00:09:31,339 --> 00:09:37,769
computed in a similar manner thus we get

186
00:09:35,399 --> 00:09:40,079
a trump base that is a program for the

187
00:09:37,769 --> 00:09:42,209
forward computation logics and the

188
00:09:40,079 --> 00:09:45,589
backward computation can be generated by

189
00:09:42,209 --> 00:09:49,560
Auto differentiation

190
00:09:45,589 --> 00:09:51,569
okay next as graphs are your lunch we

191
00:09:49,560 --> 00:09:54,359
would like to sketch into much more

192
00:09:51,569 --> 00:09:57,509
cheap use for faster processing a naive

193
00:09:54,360 --> 00:10:01,440
solution to that chip geotech a column

194
00:09:57,509 --> 00:10:05,430
of a trunks and outputs the Rigveda

195
00:10:01,440 --> 00:10:08,100
buttress trunk however the precise lines

196
00:10:05,430 --> 00:10:11,160
are limited in modern servers so the

197
00:10:08,100 --> 00:10:13,829
precise which is introduced to support

198
00:10:11,160 --> 00:10:16,500
more tip shields in one server because

199
00:10:13,829 --> 00:10:20,040
Egyptian will take other important

200
00:10:16,500 --> 00:10:22,680
improve also trunks the redundant data

201
00:10:20,040 --> 00:10:27,300
transfer through shared upper links

202
00:10:22,680 --> 00:10:29,519
results in bandwidth bottleneck we have

203
00:10:27,300 --> 00:10:32,250
served sites the links to the new

204
00:10:29,519 --> 00:10:35,310
particles within the same pieces which

205
00:10:32,250 --> 00:10:39,060
are empty and each GPO will load the

206
00:10:35,310 --> 00:10:42,510
same data so we can let you directly

207
00:10:39,060 --> 00:10:46,018
load data from its neighbor GPO well GPO

208
00:10:42,510 --> 00:10:49,699
p2g communication which reduces the data

209
00:10:46,019 --> 00:10:52,800
transfer on the shelter darlink

210
00:10:49,699 --> 00:10:55,979
therefore we formulated to use within

211
00:10:52,800 --> 00:10:56,939
the simplest ie switch either chain to

212
00:10:55,980 --> 00:11:00,589
elaborate

213
00:10:56,939 --> 00:11:05,430
Elgin processing here is an example

214
00:11:00,589 --> 00:11:08,790
first the left the left of most GPO 0 &

215
00:11:05,430 --> 00:11:11,969
2 in each piece I switch load trunk we

216
00:11:08,790 --> 00:11:14,430
want from the host memory then GPO one

217
00:11:11,970 --> 00:11:18,150
load transfer one from GPO Sderot and

218
00:11:14,430 --> 00:11:21,510
cheapest way load transfer one from

219
00:11:18,150 --> 00:11:25,560
- meanwhile GPRO and one low trunk way

220
00:11:21,510 --> 00:11:28,890
to from the Xhosa memory then tip you

221
00:11:25,560 --> 00:11:31,589
wanna delete the consumed tranquil

222
00:11:28,890 --> 00:11:34,230
weather and Lauren big one from CPU

223
00:11:31,590 --> 00:11:37,910
Darrow and to mean well cheerio dear on

224
00:11:34,230 --> 00:11:41,220
to low trunk mystery from host memory

225
00:11:37,910 --> 00:11:44,610
then the interviews to the same manner

226
00:11:41,220 --> 00:11:48,450
for next runs this procedure describes

227
00:11:44,610 --> 00:11:52,410
the team based parallel streaming much

228
00:11:48,450 --> 00:11:54,320
modules finally let's talk about the

229
00:11:52,410 --> 00:11:57,500
corner organization in new world

230
00:11:54,320 --> 00:11:58,770
traditional graph algorithms like

231
00:11:57,500 --> 00:12:01,560
Barranca

232
00:11:58,770 --> 00:12:04,680
you only have scanners are vertices our

233
00:12:01,560 --> 00:12:07,530
edges so conventions make point them

234
00:12:04,680 --> 00:12:09,599
over vertices are edges we are in

235
00:12:07,530 --> 00:12:11,939
different interactions and different

236
00:12:09,600 --> 00:12:17,160
strides which you know in fashion for

237
00:12:11,940 --> 00:12:19,500
GPU well turns your lay have regular

238
00:12:17,160 --> 00:12:23,850
high dimension features are vertices are

239
00:12:19,500 --> 00:12:26,760
edges so we appoint prism feature

240
00:12:23,850 --> 00:12:31,130
dimension to achieve sing instructions

241
00:12:26,760 --> 00:12:35,880
over strides which he fashioned to TPO

242
00:12:31,130 --> 00:12:38,610
okay the evaluation we implemented a new

243
00:12:35,880 --> 00:12:41,790
graph on top of principle and compare it

244
00:12:38,610 --> 00:12:45,870
with tangible and DGL we also

245
00:12:41,790 --> 00:12:50,430
implemented TF shaka a baseline without

246
00:12:45,870 --> 00:12:52,920
any of transitions introduced before to

247
00:12:50,430 --> 00:12:56,400
choose the sous-sous priority of our of

248
00:12:52,920 --> 00:12:59,670
transitions we do impairment our server

249
00:12:56,400 --> 00:13:03,569
equipment awaits a trip use which use

250
00:12:59,670 --> 00:13:07,680
three typical gene applications on three

251
00:13:03,570 --> 00:13:10,890
small and three large thin sites for

252
00:13:07,680 --> 00:13:14,670
small parts fit into GPU memory because

253
00:13:10,890 --> 00:13:15,480
of our kernel organizations new graph

254
00:13:14,670 --> 00:13:18,360
achieves

255
00:13:15,480 --> 00:13:22,230
up to phantoms speed-up over tensorflow

256
00:13:18,360 --> 00:13:26,070
and up to nineteen pencils be up over t

257
00:13:22,230 --> 00:13:29,840
GL also new graph gets higher speed up

258
00:13:26,070 --> 00:13:29,840
for graphs with high intensity

259
00:13:30,600 --> 00:13:36,850
for large graphs that cannot fit into

260
00:13:33,910 --> 00:13:38,319
GPO tensorflow and the TGA out ran out

261
00:13:36,850 --> 00:13:41,019
of memory on GPO

262
00:13:38,319 --> 00:13:45,639
so we come here new graph with tons of

263
00:13:41,019 --> 00:13:49,569
procedural version and TF zonka issues

264
00:13:45,639 --> 00:13:54,220
that new graph achieved up to 47 times

265
00:13:49,569 --> 00:13:55,660
speed up over Kiev simcha version and up

266
00:13:54,220 --> 00:13:58,779
to 5 times over

267
00:13:55,660 --> 00:14:01,629
chef Santa baseline we can also see that

268
00:13:58,779 --> 00:14:04,899
the TF Sanka simcha version is faster

269
00:14:01,629 --> 00:14:08,350
than Jeff Scipio because trunks in

270
00:14:04,899 --> 00:14:11,439
Jeff's and Scipio contra concurrently on

271
00:14:08,350 --> 00:14:16,360
Scipio and achieve a higher CPU

272
00:14:11,439 --> 00:14:20,879
utilization finally we should the

273
00:14:16,360 --> 00:14:24,879
scalability over multiple GPUs with an 8

274
00:14:20,879 --> 00:14:28,240
without with we funded without stream

275
00:14:24,879 --> 00:14:31,180
new graph gets no speed up for two GPUs

276
00:14:28,240 --> 00:14:35,500
because of the Penguins bottleneck

277
00:14:31,180 --> 00:14:38,709
increases which thanks to the chimp a

278
00:14:35,500 --> 00:14:44,050
streaming strategy new graph can't get a

279
00:14:38,709 --> 00:14:47,680
nearly linear scalability through new

280
00:14:44,050 --> 00:14:50,019
graph were advocates unifying deep

281
00:14:47,680 --> 00:14:52,500
learning and the computing for efficient

282
00:14:50,019 --> 00:14:55,180
and scalable team processing new graph

283
00:14:52,500 --> 00:14:57,970
represents critical step in the

284
00:14:55,180 --> 00:15:00,660
structure by showing not only the face

285
00:14:57,970 --> 00:15:04,269
ability but also the potential of such

286
00:15:00,660 --> 00:15:06,670
unification this is accomplished by

287
00:15:04,269 --> 00:15:11,079
defining the second model to apprise

288
00:15:06,670 --> 00:15:13,569
genes and fusing graph out of

289
00:15:11,079 --> 00:15:16,388
transitions such as repetition

290
00:15:13,569 --> 00:15:18,899
scheduling and tourism into deep

291
00:15:16,389 --> 00:15:21,370
learning frameworks and achieving

292
00:15:18,899 --> 00:15:27,059
efficiency and scalability

293
00:15:21,370 --> 00:15:27,059
engine training that's all thank you

294
00:15:27,690 --> 00:15:35,790
questions comments I don't know if you

295
00:15:34,170 --> 00:15:38,640
guys notice but we had a GPU paper a

296
00:15:35,790 --> 00:15:41,130
disk paper a GPU paper and the last

297
00:15:38,640 --> 00:15:43,130
papers in this paper so for what I just

298
00:15:41,130 --> 00:15:45,330
sing great talk

299
00:15:43,130 --> 00:15:46,590
so it's interesting to see that you

300
00:15:45,330 --> 00:15:49,620
build this on tensorflow

301
00:15:46,590 --> 00:15:52,230
right right do you know any of the

302
00:15:49,620 --> 00:15:56,010
optimizations from graph processing GPU

303
00:15:52,230 --> 00:15:57,600
world I know what possible because of

304
00:15:56,010 --> 00:16:04,770
its processing model or its data

305
00:15:57,600 --> 00:16:06,510
management or any of those some of the

306
00:16:04,770 --> 00:16:09,180
optimizations which are already there in

307
00:16:06,510 --> 00:16:12,090
existing GPU based growl okay I know I

308
00:16:09,180 --> 00:16:13,709
know this right so well where the

309
00:16:12,090 --> 00:16:15,630
difficulty is in porting them some of

310
00:16:13,710 --> 00:16:18,210
them you couldn't put because tensorflow

311
00:16:15,630 --> 00:16:20,070
was adding some limitation to it maybe

312
00:16:18,210 --> 00:16:21,630
so I'm coming from graph processing

313
00:16:20,070 --> 00:16:23,910
perspective that's why I'm trying to

314
00:16:21,630 --> 00:16:27,080
understand this okay okay you said you

315
00:16:23,910 --> 00:16:31,079
want to know the difference between the

316
00:16:27,080 --> 00:16:33,120
other gpo based graph processing system

317
00:16:31,080 --> 00:16:37,350
that appear and they saw these are

318
00:16:33,120 --> 00:16:41,330
transitions sure yeah okay sure

319
00:16:37,350 --> 00:16:43,020
so there are a lot higher GPO based

320
00:16:41,330 --> 00:16:47,550
processing systems

321
00:16:43,020 --> 00:16:50,340
Ranko Cuccia but if the most focus on

322
00:16:47,550 --> 00:16:54,420
the traditional applications like

323
00:16:50,340 --> 00:16:58,200
PageRank as a peer and when we have Xu

324
00:16:54,420 --> 00:17:02,280
is before we have we have shown in the

325
00:16:58,200 --> 00:17:08,040
previous slide that in those

326
00:17:02,280 --> 00:17:10,589
applications the the data on the

327
00:17:08,040 --> 00:17:14,579
vertices are edges are always scanner

328
00:17:10,589 --> 00:17:19,909
values so they make poem over body

329
00:17:14,579 --> 00:17:22,948
states are edges then they were achieve

330
00:17:19,910 --> 00:17:28,920
some more some problems some problems

331
00:17:22,949 --> 00:17:32,520
like try conflict but in Qi and the data

332
00:17:28,920 --> 00:17:36,060
on the but voters are edges the high

333
00:17:32,520 --> 00:17:38,080
dimension vector so we can make a poem

334
00:17:36,060 --> 00:17:41,059
over the

335
00:17:38,080 --> 00:17:44,928
dimension the future dimension to

336
00:17:41,059 --> 00:17:54,559
achieve to achieve a piker performance

337
00:17:44,929 --> 00:17:57,380
fight thank you other questions so

338
00:17:54,559 --> 00:18:00,379
there's one aspect of cables question

339
00:17:57,380 --> 00:18:04,790
that you didn't address which was you

340
00:18:00,380 --> 00:18:08,270
built on top of tensorflow right what

341
00:18:04,790 --> 00:18:12,830
would you change in tensorflow to make

342
00:18:08,270 --> 00:18:13,490
your job easier and were you limited by

343
00:18:12,830 --> 00:18:17,240
tensorflow

344
00:18:13,490 --> 00:18:22,370
in any way all right first first of our

345
00:18:17,240 --> 00:18:25,809
way to not change the change the code

346
00:18:22,370 --> 00:18:29,330
the absence of row we implement some

347
00:18:25,809 --> 00:18:34,570
operators as a cone organization graph

348
00:18:29,330 --> 00:18:37,510
corners to these operators to tensorflow

349
00:18:34,570 --> 00:18:41,510
but the earlier in the earlier

350
00:18:37,510 --> 00:18:45,110
limitation in principle because when

351
00:18:41,510 --> 00:18:49,570
it's precise tensors are operators a

352
00:18:45,110 --> 00:18:54,049
need to load the whole tensor to GPU

353
00:18:49,570 --> 00:18:59,230
ices a quantity very sparse domain load

354
00:18:54,049 --> 00:19:05,650
a lot of useless data because the other

355
00:18:59,230 --> 00:19:09,530
only some works are useful in it so to

356
00:19:05,650 --> 00:19:13,250
to resolve this the problem we also did

357
00:19:09,530 --> 00:19:15,760
a selective scheduling organization in

358
00:19:13,250 --> 00:19:15,760
our paper

359
00:19:19,270 --> 00:19:21,330
you

