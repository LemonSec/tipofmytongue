1
00:00:10,830 --> 00:00:15,929
good morning everyone my name is EPA I'm

2
00:00:13,619 --> 00:00:18,240
I'm a PhD student from hajdu University

3
00:00:15,929 --> 00:00:20,189
of Science and Technology and today I'm

4
00:00:18,240 --> 00:00:23,070
very glad to be here to present our

5
00:00:20,189 --> 00:00:24,930
paper which is titled postman rapidly

6
00:00:23,070 --> 00:00:28,290
mitigating bursty traffic by offloading

7
00:00:24,930 --> 00:00:30,450
packet processing as known to us all

8
00:00:28,290 --> 00:00:32,969
that sudden events such as news in a

9
00:00:30,450 --> 00:00:35,280
spotlight on a social network or hot

10
00:00:32,969 --> 00:00:39,149
items in a shopping season is becoming a

11
00:00:35,280 --> 00:00:41,520
big waiters as such and such sudden

12
00:00:39,149 --> 00:00:44,370
humans always brings and expected bursty

13
00:00:41,520 --> 00:00:48,210
traffic and based on a statistic of

14
00:00:44,370 --> 00:00:51,360
Akamai and Alibaba a conversation rate

15
00:00:48,210 --> 00:00:54,450
on Cyber Monday increases 35 percent in

16
00:00:51,360 --> 00:00:57,840
24 hours and orders at the peak on

17
00:00:54,450 --> 00:01:00,870
double 11 shopping festival exceeds 32

18
00:00:57,840 --> 00:01:03,079
million per second and such bursty

19
00:01:00,870 --> 00:01:05,729
traffic can cause severe load imbalance

20
00:01:03,079 --> 00:01:07,740
impacting the services and some of these

21
00:01:05,729 --> 00:01:11,119
services such as memory cache are

22
00:01:07,740 --> 00:01:14,699
processing small requests for example

23
00:01:11,119 --> 00:01:18,179
this book reported that in its caching

24
00:01:14,700 --> 00:01:22,380
layer most icky sizes under 30 bytes and

25
00:01:18,179 --> 00:01:24,990
median value size is 135 bytes and

26
00:01:22,380 --> 00:01:28,708
processing such small packets would

27
00:01:24,990 --> 00:01:31,529
incur of our high overhead so the

28
00:01:28,709 --> 00:01:33,979
standard approach to mitigate load

29
00:01:31,529 --> 00:01:36,569
imbalance caused by such study events

30
00:01:33,979 --> 00:01:38,579
caused by such bursty traffic is

31
00:01:36,569 --> 00:01:41,490
migrating hard data to less be these

32
00:01:38,579 --> 00:01:43,979
servers however immigrating hard data is

33
00:01:41,490 --> 00:01:46,560
time consuming furthermore it will

34
00:01:43,979 --> 00:01:50,340
inevitably slow down the server that is

35
00:01:46,560 --> 00:01:54,509
already under heavy load and the high

36
00:01:50,340 --> 00:01:57,689
packet processing overheads do exist so

37
00:01:54,509 --> 00:02:00,389
Amazon Dena more ants data migration at

38
00:01:57,689 --> 00:02:03,598
the lowest priority and finds that

39
00:02:00,389 --> 00:02:05,818
during a busy shopping season data

40
00:02:03,599 --> 00:02:09,810
migration can take almost a day to

41
00:02:05,819 --> 00:02:12,660
complete so we propose postman an

42
00:02:09,810 --> 00:02:15,030
alternative approach to rapidly mitigate

43
00:02:12,660 --> 00:02:17,760
load imbalance for services processing

44
00:02:15,030 --> 00:02:21,090
small requests and postman deploys a

45
00:02:17,760 --> 00:02:23,579
number of middle boxes code helpers to

46
00:02:21,090 --> 00:02:24,810
adaptively batch small packets into

47
00:02:23,580 --> 00:02:28,680
large ones and

48
00:02:24,810 --> 00:02:30,810
to the heavily loaded server as a result

49
00:02:28,680 --> 00:02:40,880
the packet processing overhead is

50
00:02:30,810 --> 00:02:42,750
offloaded to the helpers on demand so

51
00:02:40,880 --> 00:02:45,450
benefiting from the above features

52
00:02:42,750 --> 00:02:49,650
postman is able to avoid data migration

53
00:02:45,450 --> 00:02:52,170
and achieve rapid mitigation so to batch

54
00:02:49,650 --> 00:02:53,819
smoke package we need to first discuss

55
00:02:52,170 --> 00:02:56,760
how are these small packets are

56
00:02:53,819 --> 00:03:00,238
assembled in a helper note when a packet

57
00:02:56,760 --> 00:03:02,190
is received the tcp/ip and mark headers

58
00:03:00,239 --> 00:03:05,040
will be replaced by a postman header

59
00:03:02,190 --> 00:03:07,980
such a postman header at a 3-tuple

60
00:03:05,040 --> 00:03:10,620
structure first tuple is a one byte and

61
00:03:07,980 --> 00:03:13,829
the vacation code that identifies the

62
00:03:10,620 --> 00:03:15,690
type of the package and the packet can

63
00:03:13,830 --> 00:03:20,430
have one of the following three types a

64
00:03:15,690 --> 00:03:23,730
request reply and connect the second

65
00:03:20,430 --> 00:03:27,660
tuple is a 2-byte lengths right field to

66
00:03:23,730 --> 00:03:30,060
record the lens of the payload in a

67
00:03:27,660 --> 00:03:31,890
third tuple is a four byte long a four

68
00:03:30,060 --> 00:03:34,590
byte long which contains the source IP

69
00:03:31,890 --> 00:03:37,410
and port over the payload to locate the

70
00:03:34,590 --> 00:03:40,350
server located the sender and help her

71
00:03:37,410 --> 00:03:43,560
extracts the lower 16 bits from a source

72
00:03:40,350 --> 00:03:45,959
IP and then hatch them into a 2-byte and

73
00:03:43,560 --> 00:03:49,799
two identifiers which can cover less

74
00:03:45,959 --> 00:03:55,019
than 64,000 machine for modest modest of

75
00:03:49,799 --> 00:03:57,540
skill cluster so after to define the

76
00:03:55,019 --> 00:04:01,350
postman header with them present how

77
00:03:57,540 --> 00:04:03,269
these packets are budgeted in helpers so

78
00:04:01,350 --> 00:04:07,079
to efficiently process these small

79
00:04:03,269 --> 00:04:11,340
packets we implement postman with DP DK

80
00:04:07,079 --> 00:04:13,920
and upon T PDK we use M TCP to handle

81
00:04:11,340 --> 00:04:18,269
TCP protocol and connections

82
00:04:13,920 --> 00:04:21,358
hence the packets can be processed

83
00:04:18,269 --> 00:04:25,710
efficiently with these fast IO technique

84
00:04:21,358 --> 00:04:27,810
and your survival Network stack and as

85
00:04:25,710 --> 00:04:31,770
such original packet headers are

86
00:04:27,810 --> 00:04:34,830
replaced by postman headers and helpers

87
00:04:31,770 --> 00:04:38,400
will patch the small packets that have

88
00:04:34,830 --> 00:04:40,680
the same destination IP and port in

89
00:04:38,400 --> 00:04:43,739
a large one and send it to the heavy

90
00:04:40,680 --> 00:04:48,060
loaded server as a result duplicated

91
00:04:43,740 --> 00:04:54,030
headers are replaced to alleviate packet

92
00:04:48,060 --> 00:04:56,910
processing overhead so postman leverages

93
00:04:54,030 --> 00:04:59,609
procore threat and independent procore

94
00:04:56,910 --> 00:05:04,110
contacts to avoid synchronization among

95
00:04:59,610 --> 00:05:06,660
different or Cymbeline threads so by now

96
00:05:04,110 --> 00:05:09,570
everything seems fine except the helper

97
00:05:06,660 --> 00:05:12,600
node fails so if a helper node fails it

98
00:05:09,570 --> 00:05:14,909
cannot provide enough information for

99
00:05:12,600 --> 00:05:17,250
packet of retransmission under such a

100
00:05:14,910 --> 00:05:20,850
scenario we're supposed to make great

101
00:05:17,250 --> 00:05:22,979
connection from the failed helper to

102
00:05:20,850 --> 00:05:28,199
another one and rescind

103
00:05:22,979 --> 00:05:30,870
the package in postman we choose to

104
00:05:28,199 --> 00:05:33,900
redirect requests to another helper note

105
00:05:30,870 --> 00:05:36,990
and the redirection approach brings

106
00:05:33,900 --> 00:05:39,570
lower overhead but it requires the 14

107
00:05:36,990 --> 00:05:42,270
node to be stateless namely it does not

108
00:05:39,570 --> 00:05:45,630
have any important states that will

109
00:05:42,270 --> 00:05:49,049
affect the execution so here is our

110
00:05:45,630 --> 00:05:53,580
solution supposing that one memory cache

111
00:05:49,050 --> 00:05:56,190
is under heavy load and the first four

112
00:05:53,580 --> 00:05:58,650
packets are sent and the server receives

113
00:05:56,190 --> 00:06:02,099
the first three packets and we're a

114
00:05:58,650 --> 00:06:06,030
helper node fills the client we will

115
00:06:02,099 --> 00:06:08,639
connect to another helper node and then

116
00:06:06,030 --> 00:06:11,698
sends a reconnect message to the servers

117
00:06:08,639 --> 00:06:13,919
through the new helper node which

118
00:06:11,699 --> 00:06:17,400
contains a number of sins and received

119
00:06:13,919 --> 00:06:19,650
package at the client side and when the

120
00:06:17,400 --> 00:06:21,960
server receives such a command it will

121
00:06:19,650 --> 00:06:26,729
stop receiving packets on all the

122
00:06:21,960 --> 00:06:30,120
connection and it will respond with a

123
00:06:26,729 --> 00:06:33,210
packet which contains the number of sins

124
00:06:30,120 --> 00:06:36,320
received packets at the server side so

125
00:06:33,210 --> 00:06:39,409
by exchanging the time as the number of

126
00:06:36,320 --> 00:06:41,880
sinned and the received package and

127
00:06:39,409 --> 00:06:44,880
compare that comparing them to the

128
00:06:41,880 --> 00:06:47,190
offset of the buffered packets and both

129
00:06:44,880 --> 00:06:50,330
sides can't determine which package

130
00:06:47,190 --> 00:06:50,330
should be very transferred

131
00:06:50,340 --> 00:06:58,929
so as a result postman can make great

132
00:06:55,990 --> 00:07:01,660
connection freely across help her helper

133
00:06:58,930 --> 00:07:06,880
notes and these helper notes are highly

134
00:07:01,660 --> 00:07:09,780
scalable because of de três nature's and

135
00:07:06,880 --> 00:07:12,610
to support the above functionalities of

136
00:07:09,780 --> 00:07:16,929
establishing connection assemble and

137
00:07:12,610 --> 00:07:20,470
disassemble in package a few additional

138
00:07:16,930 --> 00:07:26,199
a few postman average provides a few

139
00:07:20,470 --> 00:07:30,820
additional api's and like connect the

140
00:07:26,199 --> 00:07:33,910
compose and compose and cat info so a

141
00:07:30,820 --> 00:07:35,500
helper developer should use these

142
00:07:33,910 --> 00:07:38,440
additional api's together with

143
00:07:35,500 --> 00:07:42,159
traditional api's to build the

144
00:07:38,440 --> 00:07:45,310
applications so after presenting the

145
00:07:42,159 --> 00:07:48,340
above implementation details we then

146
00:07:45,310 --> 00:07:50,800
make summary of how postman works in

147
00:07:48,340 --> 00:07:54,280
practice first of all we need to answer

148
00:07:50,800 --> 00:07:57,220
a question for postman went to connect

149
00:07:54,280 --> 00:08:02,109
to helpers supposing that the server is

150
00:07:57,220 --> 00:08:05,050
under high load and then the client is

151
00:08:02,110 --> 00:08:09,419
the latency in the client is detected to

152
00:08:05,050 --> 00:08:12,039
be higher than SLA and in postman the

153
00:08:09,419 --> 00:08:14,530
clients will decide to disconnect from

154
00:08:12,039 --> 00:08:17,919
the server and connect to the helper

155
00:08:14,530 --> 00:08:22,239
which brings the minimal overhead to the

156
00:08:17,919 --> 00:08:26,370
server client to the server side then

157
00:08:22,240 --> 00:08:29,229
the clients are required to select one

158
00:08:26,370 --> 00:08:31,659
helper node to connect and a strategy of

159
00:08:29,229 --> 00:08:35,078
selecting helper nodes and post may is

160
00:08:31,659 --> 00:08:39,789
as follows and each helper will monitors

161
00:08:35,078 --> 00:08:41,859
its CPU and network utilization and when

162
00:08:39,789 --> 00:08:44,529
it connect I'm going to connect a window

163
00:08:41,860 --> 00:08:48,510
client establish a new connection it

164
00:08:44,529 --> 00:08:51,579
will select a number of helper nodes and

165
00:08:48,510 --> 00:08:55,420
these helper nodes will reply with a

166
00:08:51,579 --> 00:08:59,079
with their utilization resources so that

167
00:08:55,420 --> 00:09:01,959
the client can choose the helper with

168
00:08:59,079 --> 00:09:03,670
the lowest utilization and in this case

169
00:09:01,959 --> 00:09:06,579
the upper one is chosen

170
00:09:03,670 --> 00:09:09,400
and the connection can be moved can be

171
00:09:06,580 --> 00:09:12,460
established and when I help her funds

172
00:09:09,400 --> 00:09:15,760
its resource digitization is too high it

173
00:09:12,460 --> 00:09:18,610
disconnects existing connections so that

174
00:09:15,760 --> 00:09:22,210
Crest bonding clients can connect to

175
00:09:18,610 --> 00:09:25,150
other helpers so the other one is under

176
00:09:22,210 --> 00:09:29,800
is overloaded and one connection

177
00:09:25,150 --> 00:09:31,980
exaggerated to the other one finally we

178
00:09:29,800 --> 00:09:35,740
should decide when to disconnect from

179
00:09:31,980 --> 00:09:38,410
helpers and one Hennessey's client

180
00:09:35,740 --> 00:09:40,450
cannot gain the overall load of the

181
00:09:38,410 --> 00:09:42,969
server so it might not be able to make

182
00:09:40,450 --> 00:09:45,640
the best decision on the other hand a

183
00:09:42,970 --> 00:09:49,260
server certainly has more information to

184
00:09:45,640 --> 00:09:51,880
make a better decision but to execute

185
00:09:49,260 --> 00:09:54,850
the decision the server must pay the

186
00:09:51,880 --> 00:09:57,160
over overhead of notifying the

187
00:09:54,850 --> 00:10:01,120
corresponding helpers and clients

188
00:09:57,160 --> 00:10:03,400
which could be problematic if if the

189
00:10:01,120 --> 00:10:06,490
server is already under heavy load as a

190
00:10:03,400 --> 00:10:10,720
result in postman when the throughput of

191
00:10:06,490 --> 00:10:13,390
the server is become normal and the

192
00:10:10,720 --> 00:10:17,380
server will decide to disable helpers

193
00:10:13,390 --> 00:10:21,040
and notifies clients to establish direct

194
00:10:17,380 --> 00:10:24,220
connection to itself and the overhead is

195
00:10:21,040 --> 00:10:28,420
fine in this case since the server is

196
00:10:24,220 --> 00:10:31,930
not too busy now we clarify the

197
00:10:28,420 --> 00:10:35,740
positioning of postman so postman is

198
00:10:31,930 --> 00:10:37,989
designed for abrupt load imbalance so

199
00:10:35,740 --> 00:10:40,600
migrating data in this case may take

200
00:10:37,990 --> 00:10:43,150
much longer time than postman and may

201
00:10:40,600 --> 00:10:48,910
waste the resources if the load

202
00:10:43,150 --> 00:10:51,880
imbalance disappears soon so if the load

203
00:10:48,910 --> 00:10:57,579
imbalance becomes stable and predictable

204
00:10:51,880 --> 00:11:01,330
and the migrating data can finally solve

205
00:10:57,580 --> 00:11:04,270
the load imbalance problem and the

206
00:11:01,330 --> 00:11:08,160
postman can be disabled so post may

207
00:11:04,270 --> 00:11:08,160
enter the migration are complimentary

208
00:11:15,070 --> 00:11:20,170
and here listed the evaluation or

209
00:11:17,949 --> 00:11:23,529
evaluation setup our evaluation is

210
00:11:20,170 --> 00:11:26,889
conducted on cloud lab with 15 machines

211
00:11:23,529 --> 00:11:29,829
and every machine has ten physical cores

212
00:11:26,889 --> 00:11:31,660
with hyper-threading and the

213
00:11:29,829 --> 00:11:33,880
specification is the best vacation of

214
00:11:31,660 --> 00:11:36,880
software in the clients and helpers and

215
00:11:33,880 --> 00:11:42,730
servers elastic here finally we set the

216
00:11:36,880 --> 00:11:47,680
fsla as 500 microseconds and it is a 99

217
00:11:42,730 --> 00:11:50,470
percentile latency so compared with data

218
00:11:47,680 --> 00:11:52,930
migration and postman can mitigate

219
00:11:50,470 --> 00:11:56,670
bursty traffic within five hundred and

220
00:11:52,930 --> 00:12:03,250
fifty milliseconds on memory cache and

221
00:11:56,670 --> 00:12:06,610
750 made a second and pixels and postman

222
00:12:03,250 --> 00:12:09,069
can improve throughput by three three

223
00:12:06,610 --> 00:12:12,149
point three times a memory cache and two

224
00:12:09,069 --> 00:12:17,019
point eight times on Paxos respectively

225
00:12:12,149 --> 00:12:19,569
and to qualitatively understand how post

226
00:12:17,019 --> 00:12:21,639
man's capacity is affected by the pectus

227
00:12:19,569 --> 00:12:23,439
eyes and we use ping pong micro

228
00:12:21,639 --> 00:12:26,889
benchmark to mirror the throughput our

229
00:12:23,440 --> 00:12:32,589
postman and on linux are the turning

230
00:12:26,889 --> 00:12:36,339
points are 400 bytes and 1460 bytes

231
00:12:32,589 --> 00:12:36,850
respectively and onyx return importance

232
00:12:36,339 --> 00:12:41,769
are smaller

233
00:12:36,850 --> 00:12:47,110
to 206 60 bytes and 920 bytes

234
00:12:41,769 --> 00:12:49,959
respectively and to examine the fader

235
00:12:47,110 --> 00:12:52,329
recovery of helper nodes we first let

236
00:12:49,959 --> 00:12:55,209
all clients connect to one helper and

237
00:12:52,329 --> 00:12:57,939
record the throughput of the clients and

238
00:12:55,209 --> 00:13:01,510
manually killed the connected helper as

239
00:12:57,939 --> 00:13:05,410
shown in this figure the reconnection

240
00:13:01,510 --> 00:13:09,790
takes about 0.4 milliseconds to recover

241
00:13:05,410 --> 00:13:13,180
Oh 1,000 connections and finally we

242
00:13:09,790 --> 00:13:15,910
conclude our talk we post postman an

243
00:13:13,180 --> 00:13:18,370
alternative approach to rapidly mitigate

244
00:13:15,910 --> 00:13:21,100
load imbalance for services processing

245
00:13:18,370 --> 00:13:24,069
small requests and post manage rapid

246
00:13:21,100 --> 00:13:25,120
which is faster than the data migration

247
00:13:24,069 --> 00:13:28,120
and

248
00:13:25,120 --> 00:13:31,389
is efficient when possessing small

249
00:13:28,120 --> 00:13:34,329
requests and it is fault-tolerant for

250
00:13:31,389 --> 00:13:36,879
its dateless nature and the postman help

251
00:13:34,329 --> 00:13:39,579
her notes are highly scalable because it

252
00:13:36,879 --> 00:13:42,430
has no scalability bottleneck at all and

253
00:13:39,579 --> 00:13:45,969
here listed the reference in this talk

254
00:13:42,430 --> 00:13:46,699
and that's all thank you I'm happy to

255
00:13:45,970 --> 00:13:52,989
take any questions

256
00:13:46,700 --> 00:13:52,989
[Applause]

257
00:13:55,769 --> 00:14:01,870
hi I'm Hoshi Gupta from Georgia Tech I

258
00:13:58,540 --> 00:14:05,879
have a question about mem cast since I

259
00:14:01,870 --> 00:14:08,889
think that the request would be a lot

260
00:14:05,879 --> 00:14:11,350
biased towards reads the workload would

261
00:14:08,889 --> 00:14:13,749
be read heavy so in that case a content

262
00:14:11,350 --> 00:14:16,779
of alternate approach just migrated the

263
00:14:13,749 --> 00:14:18,220
request to another memcache server which

264
00:14:16,779 --> 00:14:20,110
can then fetch the data from the back

265
00:14:18,220 --> 00:14:23,110
end and then start serving requests to

266
00:14:20,110 --> 00:14:25,089
the clients instead so it would be like

267
00:14:23,110 --> 00:14:27,339
layer 7 load balancing instead of

268
00:14:25,089 --> 00:14:31,029
deploying this you just base packet

269
00:14:27,339 --> 00:14:33,100
processing application you asking the

270
00:14:31,029 --> 00:14:36,429
how the data is migration

271
00:14:33,100 --> 00:14:37,600
again nigga is migrated from the memory

272
00:14:36,429 --> 00:14:39,370
cache to another one

273
00:14:37,600 --> 00:14:41,079
no I'm saying maybe in memcache you

274
00:14:39,370 --> 00:14:43,660
don't need to migrate data you you can

275
00:14:41,079 --> 00:14:46,179
just replicate the cache the cache data

276
00:14:43,660 --> 00:14:48,129
on the other memcache server from the

277
00:14:46,179 --> 00:14:50,800
backend and then load balance the

278
00:14:48,129 --> 00:14:54,279
requests because it's read-only it's a

279
00:14:50,800 --> 00:15:00,998
read heavy workload I mean that you mean

280
00:14:54,279 --> 00:15:03,300
a data yes so the so so the migration is

281
00:15:00,999 --> 00:15:05,949
to make a rate to the hard data from one

282
00:15:03,300 --> 00:15:09,639
overloaded server to other less idle

283
00:15:05,949 --> 00:15:14,769
servers so other servers they don't have

284
00:15:09,639 --> 00:15:16,420
the hot the hot data so it must be mega

285
00:15:14,769 --> 00:15:20,050
region from the overloaded server to

286
00:15:16,420 --> 00:15:21,998
other last beta servers I guess the

287
00:15:20,050 --> 00:15:24,540
assumption is that there can be only one

288
00:15:21,999 --> 00:15:29,829
copy of data across all the servers

289
00:15:24,540 --> 00:15:33,459
right right but but we we can out made

290
00:15:29,829 --> 00:15:36,549
one tier a copy in advance so if the if

291
00:15:33,459 --> 00:15:39,170
the if the data becomes hot so we have

292
00:15:36,549 --> 00:15:42,709
two mega rate may

293
00:15:39,170 --> 00:15:45,650
when traffic burrows increases thank you

294
00:15:42,710 --> 00:15:49,340
thank you

295
00:15:45,650 --> 00:15:52,819
Idina EPFL interesting talk so I buy the

296
00:15:49,340 --> 00:15:54,320
fact that you can increase the good put

297
00:15:52,820 --> 00:15:56,390
one because you live in a debtor as you

298
00:15:54,320 --> 00:15:58,640
limited redundancy and you coalesce

299
00:15:56,390 --> 00:16:00,980
packets the question is how much does it

300
00:15:58,640 --> 00:16:05,360
cost and if I if I understand your

301
00:16:00,980 --> 00:16:09,170
valuation one postman can cover six

302
00:16:05,360 --> 00:16:14,630
servers right that correct one postman

303
00:16:09,170 --> 00:16:14,870
cover about six servers no no not like

304
00:16:14,630 --> 00:16:17,750
that

305
00:16:14,870 --> 00:16:19,360
no yeah oh maybe I didn't understand

306
00:16:17,750 --> 00:16:22,190
what you value how many how many

307
00:16:19,360 --> 00:16:25,610
memcache servers can you put behind one

308
00:16:22,190 --> 00:16:29,180
instance of postman okay we actually

309
00:16:25,610 --> 00:16:33,440
didn't matter how many back-end servers

310
00:16:29,180 --> 00:16:36,949
that the that helper could handle so it

311
00:16:33,440 --> 00:16:38,840
just matters how much data volumes back

312
00:16:36,950 --> 00:16:41,300
to the report that a postman can't

313
00:16:38,840 --> 00:16:43,580
handle but that's your cost metric right

314
00:16:41,300 --> 00:16:47,180
your cosmetic is rather than having

315
00:16:43,580 --> 00:16:48,830
let's say ten memcache servers right you

316
00:16:47,180 --> 00:16:50,989
can increase the throughput of these Ted

317
00:16:48,830 --> 00:16:53,300
memcache servers I buy that that's good

318
00:16:50,990 --> 00:16:55,130
but that has a cost and the cost is for

319
00:16:53,300 --> 00:16:58,699
these ten or 100 and memcache servers

320
00:16:55,130 --> 00:17:03,699
you need X additional servers and that

321
00:16:58,700 --> 00:17:08,000
number feels high sorry sir or you mean

322
00:17:03,699 --> 00:17:10,129
the X the the helper is one act when

323
00:17:08,000 --> 00:17:15,069
additional server right absolutely yes

324
00:17:10,130 --> 00:17:18,560
yeah because you mean maybe it is not a

325
00:17:15,069 --> 00:17:20,569
waste of resource you mean adding a new

326
00:17:18,560 --> 00:17:22,129
helper server right there right well

327
00:17:20,569 --> 00:17:23,720
it's tricky it's a cost yeah yeah I mean

328
00:17:22,130 --> 00:17:25,880
so I know my question is what is your

329
00:17:23,720 --> 00:17:30,530
cost and how did you measure it the cost

330
00:17:25,880 --> 00:17:33,170
okay sure actually the when the bursty

331
00:17:30,530 --> 00:17:36,050
traffic arrives and the data migration

332
00:17:33,170 --> 00:17:38,000
will do so to mitigate it is how to

333
00:17:36,050 --> 00:17:40,310
bursty traffic and make it migration

334
00:17:38,000 --> 00:17:42,500
data migration will be time-consuming so

335
00:17:40,310 --> 00:17:45,310
you don't have enough time to handle

336
00:17:42,500 --> 00:17:48,980
such a bursty traffic so you have to use

337
00:17:45,310 --> 00:17:51,350
helper node to mitigating such bursty

338
00:17:48,980 --> 00:17:53,600
traffic so

339
00:17:51,350 --> 00:17:56,570
first although the the resource is

340
00:17:53,600 --> 00:17:58,370
inevitable so no no no no no no you you

341
00:17:56,570 --> 00:18:00,500
increase the throughput that's the

342
00:17:58,370 --> 00:18:03,830
benefit you need to have additional

343
00:18:00,500 --> 00:18:05,660
resources that's the cost yeah okay

344
00:18:03,830 --> 00:18:07,909
thank you I want to make sure we have

345
00:18:05,660 --> 00:18:09,410
time for our last question and could our

346
00:18:07,910 --> 00:18:10,250
next speaker get set up all we're

347
00:18:09,410 --> 00:18:13,100
answering this question

348
00:18:10,250 --> 00:18:15,380
okay I'm saying from etiquette talks how

349
00:18:13,100 --> 00:18:17,330
I'm just wondering what you are basting

350
00:18:15,380 --> 00:18:19,250
trying to do is try to merge on multiple

351
00:18:17,330 --> 00:18:21,230
Network packets into a single big packet

352
00:18:19,250 --> 00:18:23,480
and send to the server so have you also

353
00:18:21,230 --> 00:18:25,700
considered like to merge a multiple

354
00:18:23,480 --> 00:18:28,130
application request for example hey your

355
00:18:25,700 --> 00:18:30,230
acts getting on multiple get requests

356
00:18:28,130 --> 00:18:32,060
from multiple clients so actually you

357
00:18:30,230 --> 00:18:34,340
could merge them if they are actually

358
00:18:32,060 --> 00:18:36,169
hitting a same hotkey or you are getting

359
00:18:34,340 --> 00:18:37,730
multiple like food requests they are

360
00:18:36,170 --> 00:18:39,680
also hitting to the same key actually

361
00:18:37,730 --> 00:18:41,690
you can merge them into a single request

362
00:18:39,680 --> 00:18:43,640
and send the last food request to the

363
00:18:41,690 --> 00:18:46,760
server so a view of the consider this

364
00:18:43,640 --> 00:18:51,500
can unmerged I'm assuming you could

365
00:18:46,760 --> 00:18:53,920
further happy returns be lower oh okay

366
00:18:51,500 --> 00:18:57,230
so happy also consider try to merge on

367
00:18:53,920 --> 00:18:59,030
the application request so what you are

368
00:18:57,230 --> 00:19:02,390
trying to do is to merge the network

369
00:18:59,030 --> 00:19:04,700
packet breath okay many cases like any

370
00:19:02,390 --> 00:19:06,380
kitchen requests could also be merged so

371
00:19:04,700 --> 00:19:09,380
you could basically reduce a number of

372
00:19:06,380 --> 00:19:11,690
final requests us into the server okay I

373
00:19:09,380 --> 00:19:14,390
mean why not just merge this requesting

374
00:19:11,690 --> 00:19:17,750
client side right no no in your own

375
00:19:14,390 --> 00:19:20,050
middle on postman oh right

376
00:19:17,750 --> 00:19:22,760
you mean just implication there that

377
00:19:20,050 --> 00:19:25,190
yeah for example for friend norm caste

378
00:19:22,760 --> 00:19:26,780
there are lots of like hotkeys so

379
00:19:25,190 --> 00:19:29,750
basically you are hitting the same key

380
00:19:26,780 --> 00:19:31,430
and this gives you a space to merge

381
00:19:29,750 --> 00:19:34,310
those requests into a single request

382
00:19:31,430 --> 00:19:36,530
right right I think that is interesting

383
00:19:34,310 --> 00:19:41,510
but I think postman is focus on the

384
00:19:36,530 --> 00:19:46,370
improve the throughput of a link so

385
00:19:41,510 --> 00:19:49,160
maybe we can we can add this make it

386
00:19:46,370 --> 00:19:51,250
quick maybe it's another good idea to

387
00:19:49,160 --> 00:19:54,350
solve this problem

388
00:19:51,250 --> 00:19:54,660
listen let's thank our speaker again

389
00:19:54,350 --> 00:19:59,208
you

390
00:19:54,660 --> 00:19:59,209
[Applause]

