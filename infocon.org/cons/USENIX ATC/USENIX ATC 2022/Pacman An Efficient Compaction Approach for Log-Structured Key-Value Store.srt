1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:13,620 --> 00:00:16,619
University

3
00:00:17,699 --> 00:00:20,880
today I will introduce our work Pac-Man

4
00:00:20,880 --> 00:00:24,359
an efficient compaction approach for log

5
00:00:24,359 --> 00:00:26,519
structure Key by the store on persistent

6
00:00:26,519 --> 00:00:27,660
memory

7
00:00:27,660 --> 00:00:30,060
this is a joint walk between qinghua

8
00:00:30,060 --> 00:00:33,660
University and Huawei Technologies

9
00:00:33,660 --> 00:00:36,780
the new memory technology persistent

10
00:00:36,780 --> 00:00:39,480
memory brings both opportunities and

11
00:00:39,480 --> 00:00:42,600
challenges to storage systems

12
00:00:42,600 --> 00:00:45,719
PM provides many attractive benefits

13
00:00:45,719 --> 00:00:48,180
such as data persistence and Light

14
00:00:48,180 --> 00:00:50,219
adjustability

15
00:00:50,219 --> 00:00:53,579
however PM also has some idiosyncrasies

16
00:00:53,579 --> 00:00:56,940
that programmers should be aware of

17
00:00:56,940 --> 00:01:00,960
for example compared with dram pm has

18
00:01:00,960 --> 00:01:03,899
high access latency about 300

19
00:01:03,899 --> 00:01:05,700
nanoseconds

20
00:01:05,700 --> 00:01:09,180
PM also has much slower right benefits

21
00:01:09,180 --> 00:01:12,180
the right bandwidth protein is about 2.2

22
00:01:12,180 --> 00:01:14,220
gigabytes per second

23
00:01:14,220 --> 00:01:18,240
which is about 1 6 of that of the ram

24
00:01:18,240 --> 00:01:21,479
the excess granularity of PM also called

25
00:01:21,479 --> 00:01:26,040
xb9 is 256 parts

26
00:01:26,040 --> 00:01:29,220
which is 4 times the size of cache 9.

27
00:01:29,220 --> 00:01:31,439
the mismatch of granularities can

28
00:01:31,439 --> 00:01:34,439
generate light amplification

29
00:01:34,439 --> 00:01:37,380
recent PM based key value stores adopt

30
00:01:37,380 --> 00:01:39,900
the log structure approach Europe PM's

31
00:01:39,900 --> 00:01:41,400
full potential

32
00:01:41,400 --> 00:01:43,380
the flicker shows the typical overview

33
00:01:43,380 --> 00:01:45,960
of locked such a KV store

34
00:01:45,960 --> 00:01:48,780
there are 10 KV objects sequentially in

35
00:01:48,780 --> 00:01:50,399
a storage door

36
00:01:50,399 --> 00:01:53,340
or in-memory storage each service thread

37
00:01:53,340 --> 00:01:55,680
usually maintains a password log for

38
00:01:55,680 --> 00:01:58,439
better threat scalability

39
00:01:58,439 --> 00:02:00,659
sweat can only write to their local log

40
00:02:00,659 --> 00:02:03,540
but can read all other logs

41
00:02:03,540 --> 00:02:05,520
object's location within the log

42
00:02:05,520 --> 00:02:08,580
attracted by an index data structure

43
00:02:08,580 --> 00:02:12,300
such as a hash table or B plus 3.

44
00:02:12,300 --> 00:02:15,060
in this talk the location information in

45
00:02:15,060 --> 00:02:18,540
the index is also called reference

46
00:02:18,540 --> 00:02:21,060
block structured approach as advantages

47
00:02:21,060 --> 00:02:24,180
like Fast allocation and high capacity

48
00:02:24,180 --> 00:02:25,739
utilization

49
00:02:25,739 --> 00:02:28,080
besides the sequential right and the

50
00:02:28,080 --> 00:02:30,660
out-of-place update pattern can also

51
00:02:30,660 --> 00:02:33,420
achieve small red amplification and the

52
00:02:33,420 --> 00:02:36,840
easy failure recovery on pm

53
00:02:36,840 --> 00:02:39,660
in the past few years researchers have

54
00:02:39,660 --> 00:02:42,239
designed many in-memory of structure KV

55
00:02:42,239 --> 00:02:43,739
stores

56
00:02:43,739 --> 00:02:47,220
however garbage collection or compaction

57
00:02:47,220 --> 00:02:49,980
is the main overhead of log structure

58
00:02:49,980 --> 00:02:50,940
approaches

59
00:02:50,940 --> 00:02:54,840
especially at high capacity utilizations

60
00:02:54,840 --> 00:02:57,720
for example from the evaluation results

61
00:02:57,720 --> 00:03:00,660
in Dreamhouse and enables paper

62
00:03:00,660 --> 00:03:03,120
at high memory utilizations

63
00:03:03,120 --> 00:03:05,819
from clouds throughput drops by 20 to 50

64
00:03:05,819 --> 00:03:06,959
percent

65
00:03:06,959 --> 00:03:10,200
and enabled throughput drops by up to 75

66
00:03:10,200 --> 00:03:12,500
percent

67
00:03:13,700 --> 00:03:17,760
GC overhead it is not cost efficient

68
00:03:17,760 --> 00:03:20,640
some companies have expressed that they

69
00:03:20,640 --> 00:03:22,620
have attached importance to capacity

70
00:03:22,620 --> 00:03:23,819
utilization

71
00:03:23,819 --> 00:03:25,260
for example

72
00:03:25,260 --> 00:03:27,540
Google wants to keep disks full to

73
00:03:27,540 --> 00:03:29,700
minimize storage TCO

74
00:03:29,700 --> 00:03:32,879
Facebook shows that space utilization is

75
00:03:32,879 --> 00:03:34,379
far more important than write

76
00:03:34,379 --> 00:03:35,940
amplification

77
00:03:35,940 --> 00:03:38,340
and their optimization Target shifts

78
00:03:38,340 --> 00:03:40,440
from optimizing performance to

79
00:03:40,440 --> 00:03:42,739
optimizing efficiency

80
00:03:42,739 --> 00:03:46,019
so how do PM based log structure KB

81
00:03:46,019 --> 00:03:47,760
stores behave at high capacity

82
00:03:47,760 --> 00:03:49,560
utilizations

83
00:03:49,560 --> 00:03:52,159
we found that PM's idiosyncrasies

84
00:03:52,159 --> 00:03:54,180
exacerbates the bottom neck of

85
00:03:54,180 --> 00:03:55,680
compaction

86
00:03:55,680 --> 00:03:57,720
we conduct experiments on

87
00:03:57,720 --> 00:04:00,299
state-of-the-art PM based lock structure

88
00:04:00,299 --> 00:04:01,440
KV stores

89
00:04:01,440 --> 00:04:04,519
their store and wiper under a typical

90
00:04:04,519 --> 00:04:07,440
ycsba like the workload

91
00:04:07,440 --> 00:04:09,840
the figures showed us to put a different

92
00:04:09,840 --> 00:04:12,060
capacity utilizations

93
00:04:12,060 --> 00:04:14,459
we found that at a high capacity

94
00:04:14,459 --> 00:04:17,100
utilizations the performance of both

95
00:04:17,100 --> 00:04:20,519
glass door and the Viper jobs obviously

96
00:04:20,519 --> 00:04:22,800
even if we double the clean industry at

97
00:04:22,800 --> 00:04:27,240
from 4 to 8. the help is very limited

98
00:04:27,240 --> 00:04:29,639
we found that existing compaction

99
00:04:29,639 --> 00:04:32,340
purchase are unaware of PM's

100
00:04:32,340 --> 00:04:34,380
characteristics

101
00:04:34,380 --> 00:04:36,840
therefore can we improve the compaction

102
00:04:36,840 --> 00:04:39,120
efficiency according to PM's

103
00:04:39,120 --> 00:04:42,120
characteristics and thus improve log

104
00:04:42,120 --> 00:04:44,340
structure cavity stores performance at

105
00:04:44,340 --> 00:04:47,040
high capacity utilizations

106
00:04:47,040 --> 00:04:49,560
next I will introduce our approach

107
00:04:49,560 --> 00:04:53,040
Pacman and PM aware convection approach

108
00:04:53,040 --> 00:04:55,919
for log structure cable stores

109
00:04:55,919 --> 00:04:58,560
before diving into the design details

110
00:04:58,560 --> 00:05:01,139
let's analyze the exact overhead of

111
00:05:01,139 --> 00:05:03,000
connection first

112
00:05:03,000 --> 00:05:05,880
during compaction a cleaner will scan

113
00:05:05,880 --> 00:05:08,580
all objects in the old segment

114
00:05:08,580 --> 00:05:11,100
first the cleaner will check whether an

115
00:05:11,100 --> 00:05:13,860
object is still valid which means it has

116
00:05:13,860 --> 00:05:16,740
not been updated or deleted

117
00:05:16,740 --> 00:05:19,740
then if the object is still valid the

118
00:05:19,740 --> 00:05:21,960
cleaner will copy the object to a first

119
00:05:21,960 --> 00:05:25,199
segment and position it

120
00:05:25,199 --> 00:05:27,960
after that a cleaner will update these

121
00:05:27,960 --> 00:05:29,520
object's reference

122
00:05:29,520 --> 00:05:32,400
therefore others can find the object in

123
00:05:32,400 --> 00:05:34,380
its new place

124
00:05:34,380 --> 00:05:37,139
when updating object's reference or when

125
00:05:37,139 --> 00:05:39,300
checking the object planers should

126
00:05:39,300 --> 00:05:42,419
travel stay index to find the reference

127
00:05:42,419 --> 00:05:45,479
however the traversal has several random

128
00:05:45,479 --> 00:05:47,699
access and is slow

129
00:05:47,699 --> 00:05:50,520
the high excess latency of PM make it

130
00:05:50,520 --> 00:05:51,479
worse

131
00:05:51,479 --> 00:05:54,360
according to our evaluation the index

132
00:05:54,360 --> 00:05:56,520
traversal contributes the most overhead

133
00:05:56,520 --> 00:05:58,919
in compaction

134
00:05:58,919 --> 00:06:01,440
the second problem is extra persistence

135
00:06:01,440 --> 00:06:02,580
work

136
00:06:02,580 --> 00:06:05,100
to guarantee the copied object is

137
00:06:05,100 --> 00:06:07,020
persisted in pm

138
00:06:07,020 --> 00:06:09,360
when flash instruction and one tense

139
00:06:09,360 --> 00:06:11,820
instruction are needed between Step 2

140
00:06:11,820 --> 00:06:15,479
and step 3 for each valid object

141
00:06:15,479 --> 00:06:18,900
besides if the index is also on pm

142
00:06:18,900 --> 00:06:21,660
one theory of large is also executed on

143
00:06:21,660 --> 00:06:23,400
the reference before handling index

144
00:06:23,400 --> 00:06:25,440
object

145
00:06:25,440 --> 00:06:27,840
however since the Flash and defense

146
00:06:27,840 --> 00:06:30,000
instructions are expensive

147
00:06:30,000 --> 00:06:33,120
this extra persistent work slow standard

148
00:06:33,120 --> 00:06:36,720
compaction in PM based systems

149
00:06:36,720 --> 00:06:39,240
the third problem is a large amount of

150
00:06:39,240 --> 00:06:42,180
data copying on pm

151
00:06:42,180 --> 00:06:45,060
then capacity utilization is high they

152
00:06:45,060 --> 00:06:47,100
are less garbage in a segment

153
00:06:47,100 --> 00:06:49,560
for cleaners need to copy more data to

154
00:06:49,560 --> 00:06:51,840
reclaim space

155
00:06:51,840 --> 00:06:54,539
however this data copying in convection

156
00:06:54,539 --> 00:06:57,419
will consume PM's limited right benefits

157
00:06:57,419 --> 00:06:59,759
and content with foreground service

158
00:06:59,759 --> 00:07:01,680
threads

159
00:07:01,680 --> 00:07:03,900
the fourth problem is excessive small

160
00:07:03,900 --> 00:07:06,479
random access on pm

161
00:07:06,479 --> 00:07:09,419
besides in background compaction in the

162
00:07:09,419 --> 00:07:12,300
foreground service threats also generate

163
00:07:12,300 --> 00:07:15,000
any small random access on PM for

164
00:07:15,000 --> 00:07:16,680
garbage collection

165
00:07:16,680 --> 00:07:19,860
for example after painting a new KB

166
00:07:19,860 --> 00:07:20,880
object

167
00:07:20,880 --> 00:07:22,860
the service thread will update the

168
00:07:22,860 --> 00:07:25,380
object's reference

169
00:07:25,380 --> 00:07:27,780
if the object has old version

170
00:07:27,780 --> 00:07:30,300
to facilitate the garbage collection

171
00:07:30,300 --> 00:07:32,220
the service thread will Mark the old

172
00:07:32,220 --> 00:07:35,280
objects click the effect in pm and read

173
00:07:35,280 --> 00:07:37,380
its size from pm to increase all the

174
00:07:37,380 --> 00:07:39,419
segments garbage bytes

175
00:07:39,419 --> 00:07:42,000
which is used to select segment

176
00:07:42,000 --> 00:07:44,940
candidate in convection

177
00:07:44,940 --> 00:07:47,940
however these small random reads have

178
00:07:47,940 --> 00:07:50,520
high access latency and this small

179
00:07:50,520 --> 00:07:52,020
random rights result in right

180
00:07:52,020 --> 00:07:54,840
amplification and the waste PM's limited

181
00:07:54,840 --> 00:07:57,240
dependent width

182
00:07:57,240 --> 00:07:59,759
to solve these problems Pacman

183
00:07:59,759 --> 00:08:01,919
introduced several techniques

184
00:08:01,919 --> 00:08:04,560
the first design is to use shortcut to

185
00:08:04,560 --> 00:08:08,160
Traverse the index in compaction

186
00:08:08,160 --> 00:08:10,800
Shortcuts Point at the reference in the

187
00:08:10,800 --> 00:08:12,660
index directly

188
00:08:12,660 --> 00:08:15,419
here we take a tree based index as

189
00:08:15,419 --> 00:08:16,979
example

190
00:08:16,979 --> 00:08:19,620
a shortcut contains two parts

191
00:08:19,620 --> 00:08:22,319
the node 80dr points at the leaf node

192
00:08:22,319 --> 00:08:25,500
and the KV post indicate the exact index

193
00:08:25,500 --> 00:08:28,440
entry in the entry array

194
00:08:28,440 --> 00:08:31,199
for example if a cleaner want to find

195
00:08:31,199 --> 00:08:32,940
the kb2

196
00:08:32,940 --> 00:08:35,399
a traditional approach to search from

197
00:08:35,399 --> 00:08:38,039
the root node and Traverse the long path

198
00:08:38,039 --> 00:08:40,919
layer by layer to the div node

199
00:08:40,919 --> 00:08:44,339
now with shortcut a cleaner can skip the

200
00:08:44,339 --> 00:08:47,040
high latency good to leave pass and get

201
00:08:47,040 --> 00:08:50,180
to the destination directly

202
00:08:50,180 --> 00:08:52,440
shortcuts are recorded by foreground

203
00:08:52,440 --> 00:08:54,420
servers in passing when writing the

204
00:08:54,420 --> 00:08:57,000
heavy objects and stored with the

205
00:08:57,000 --> 00:09:00,240
corresponding objects in PM log

206
00:09:00,240 --> 00:09:03,600
however as the index keeps inserting and

207
00:09:03,600 --> 00:09:05,339
deleting kbps

208
00:09:05,339 --> 00:09:07,080
its structure may change and the

209
00:09:07,080 --> 00:09:09,839
shortcuts may become invalid

210
00:09:09,839 --> 00:09:12,060
there are three situations of shortcut

211
00:09:12,060 --> 00:09:13,680
invalidation

212
00:09:13,680 --> 00:09:17,940
first the KV post is invalid which is

213
00:09:17,940 --> 00:09:20,339
caused by shift operations

214
00:09:20,339 --> 00:09:23,160
for example the can be post now is

215
00:09:23,160 --> 00:09:26,459
pointing at the second place kv1 but the

216
00:09:26,459 --> 00:09:30,300
real reference of this shortcut is kv2

217
00:09:30,300 --> 00:09:33,180
in this situation A Cleaner will first

218
00:09:33,180 --> 00:09:35,339
check the header of the leaf node to

219
00:09:35,339 --> 00:09:37,380
make sure this reference is still in

220
00:09:37,380 --> 00:09:40,680
this Leaf node then it research the if

221
00:09:40,680 --> 00:09:44,160
node to find the real reference

222
00:09:44,160 --> 00:09:46,680
the second situation is that the

223
00:09:46,680 --> 00:09:49,680
reference has been moved to another node

224
00:09:49,680 --> 00:09:52,380
enter the node 80dr points at a round

225
00:09:52,380 --> 00:09:53,660
node

226
00:09:53,660 --> 00:09:57,240
in this case a cleaner will first try to

227
00:09:57,240 --> 00:09:59,339
search The Sibling node

228
00:09:59,339 --> 00:10:02,459
if it fails a cleaner falls back to the

229
00:10:02,459 --> 00:10:04,260
normal search operation

230
00:10:04,260 --> 00:10:06,300
research the reference from the root

231
00:10:06,300 --> 00:10:08,700
node

232
00:10:08,700 --> 00:10:11,399
the third situation is that the original

233
00:10:11,399 --> 00:10:14,459
node pointed by the node 80dr has been

234
00:10:14,459 --> 00:10:15,720
deleted

235
00:10:15,720 --> 00:10:18,720
in this case the improper access is

236
00:10:18,720 --> 00:10:20,519
dangerous

237
00:10:20,519 --> 00:10:23,580
to prevent this situation Pacman will

238
00:10:23,580 --> 00:10:26,100
not delete the index node physically but

239
00:10:26,100 --> 00:10:28,320
logically such as marking the node as

240
00:10:28,320 --> 00:10:30,959
deleted in this header

241
00:10:30,959 --> 00:10:33,779
then the space of the deleted node is

242
00:10:33,779 --> 00:10:36,839
reserved for future allocation

243
00:10:36,839 --> 00:10:38,640
the cleaner will fall back to the normal

244
00:10:38,640 --> 00:10:41,880
search operation to find the reference

245
00:10:41,880 --> 00:10:44,339
since delete operations are not very

246
00:10:44,339 --> 00:10:46,140
frequent in real world production

247
00:10:46,140 --> 00:10:48,959
workloads Pac-Man will not Reserve too

248
00:10:48,959 --> 00:10:50,940
many nodes

249
00:10:50,940 --> 00:10:53,579
the second design of Pac-Man is

250
00:10:53,579 --> 00:10:56,279
redesigning the compaction pipeline

251
00:10:56,279 --> 00:10:59,279
as in existing compaction approach

252
00:10:59,279 --> 00:11:01,800
the compaction is conducted in a per

253
00:11:01,800 --> 00:11:03,480
object manner

254
00:11:03,480 --> 00:11:06,540
each object is handled entirely one by

255
00:11:06,540 --> 00:11:07,440
one

256
00:11:07,440 --> 00:11:10,380
in this manner one Flash and one fence

257
00:11:10,380 --> 00:11:13,560
are needed for every valid object and

258
00:11:13,560 --> 00:11:15,779
Flash on the reference are conducted

259
00:11:15,779 --> 00:11:17,820
severally

260
00:11:17,820 --> 00:11:20,880
to reduce the extra persistence work

261
00:11:20,880 --> 00:11:23,279
we redesign the convection pipeline to

262
00:11:23,279 --> 00:11:25,500
batch manner

263
00:11:25,500 --> 00:11:27,839
in the batch manner a cleaner first

264
00:11:27,839 --> 00:11:30,180
copies all value objects in the old

265
00:11:30,180 --> 00:11:33,420
segment to your volatile buffer

266
00:11:33,420 --> 00:11:36,600
then it used non-temporal stores to copy

267
00:11:36,600 --> 00:11:39,300
these objects to the first segment

268
00:11:39,300 --> 00:11:42,360
on temporal stores move data directly to

269
00:11:42,360 --> 00:11:45,779
pm and bypass the CPU cache

270
00:11:45,779 --> 00:11:47,940
now temporal store has higher bandwidth

271
00:11:47,940 --> 00:11:50,399
than normal store operation for bulk of

272
00:11:50,399 --> 00:11:51,600
data

273
00:11:51,600 --> 00:11:54,420
third the cleaner updates these objects

274
00:11:54,420 --> 00:11:57,240
reference with shortcuts and persists

275
00:11:57,240 --> 00:11:58,800
them in batch

276
00:11:58,800 --> 00:12:01,740
in this manner only one fence is needed

277
00:12:01,740 --> 00:12:03,779
between the second step and the third

278
00:12:03,779 --> 00:12:06,959
step for the whole segment

279
00:12:06,959 --> 00:12:10,740
as some flush instructions like co.b can

280
00:12:10,740 --> 00:12:12,660
be executed concurrently

281
00:12:12,660 --> 00:12:15,779
when persisting reference a cleaner can

282
00:12:15,779 --> 00:12:18,000
launch concurrent flash instructions on

283
00:12:18,000 --> 00:12:20,399
a batched update reference

284
00:12:20,399 --> 00:12:23,279
furthermore a cleaner prefetch reference

285
00:12:23,279 --> 00:12:25,740
via shortcuts to cover the excess

286
00:12:25,740 --> 00:12:28,100
latency

287
00:12:28,320 --> 00:12:31,500
to reduce the amount of data copying the

288
00:12:31,500 --> 00:12:33,779
search design is separating code and

289
00:12:33,779 --> 00:12:35,459
code data

290
00:12:35,459 --> 00:12:37,740
it's well known that separating hot and

291
00:12:37,740 --> 00:12:40,079
cold data can reduce the overhead of

292
00:12:40,079 --> 00:12:42,360
garbage collection product structured

293
00:12:42,360 --> 00:12:44,300
storage systems

294
00:12:44,300 --> 00:12:47,820
however for an in-memory system the

295
00:12:47,820 --> 00:12:50,220
approach to identify hotline code data

296
00:12:50,220 --> 00:12:53,279
should be lightweight enough

297
00:12:53,279 --> 00:12:56,820
used an interim immutable to offset we

298
00:12:56,820 --> 00:12:59,100
identify hot and cold data

299
00:12:59,100 --> 00:13:01,740
the immutable hot set contains hotkeys

300
00:13:01,740 --> 00:13:03,480
RC values

301
00:13:03,480 --> 00:13:05,579
we use an immutable data structure

302
00:13:05,579 --> 00:13:08,519
because a dynamic data structure has

303
00:13:08,519 --> 00:13:11,579
high overhead of contention

304
00:13:11,579 --> 00:13:14,820
now each service that maintains to the

305
00:13:14,820 --> 00:13:17,639
local segments one for hot objects and

306
00:13:17,639 --> 00:13:19,980
the other for code objects

307
00:13:19,980 --> 00:13:22,740
in this way since hot objects are

308
00:13:22,740 --> 00:13:24,660
updated more frequently

309
00:13:24,660 --> 00:13:27,480
hot segments will gather more garbage

310
00:13:27,480 --> 00:13:30,420
thus conduction will prefer hot segments

311
00:13:30,420 --> 00:13:32,519
to reclaim space which has less

312
00:13:32,519 --> 00:13:34,200
overheads

313
00:13:34,200 --> 00:13:36,899
in real world workloads the hot spots

314
00:13:36,899 --> 00:13:38,940
may change and the impute protocol set

315
00:13:38,940 --> 00:13:41,160
will become inaccurate

316
00:13:41,160 --> 00:13:44,040
to handle this situation each thread

317
00:13:44,040 --> 00:13:46,139
will count the cut object's proportion

318
00:13:46,139 --> 00:13:48,959
and record kit hash of reading objects

319
00:13:48,959 --> 00:13:52,079
by sampling in their local buffer

320
00:13:52,079 --> 00:13:55,079
if the reported hot proportion is low

321
00:13:55,079 --> 00:13:57,600
which means the current hot set is not

322
00:13:57,600 --> 00:13:59,279
accurate anymore

323
00:13:59,279 --> 00:14:01,680
a background thread will connect records

324
00:14:01,680 --> 00:14:04,860
from each stress record buffer then it

325
00:14:04,860 --> 00:14:07,200
generates a new hot set according to

326
00:14:07,200 --> 00:14:09,839
this records and replace the current hot

327
00:14:09,839 --> 00:14:13,200
set using epoch-based technique

328
00:14:13,200 --> 00:14:14,940
if the background thread finds the

329
00:14:14,940 --> 00:14:18,360
records are distributed uniformly and it

330
00:14:18,360 --> 00:14:22,100
will set the Hoster to empty

331
00:14:22,139 --> 00:14:24,660
the fourth design of tech bank is to

332
00:14:24,660 --> 00:14:27,300
reduce excessive PM access

333
00:14:27,300 --> 00:14:30,060
record that in the foreground for each

334
00:14:30,060 --> 00:14:32,940
updated object or delete the object the

335
00:14:32,940 --> 00:14:34,800
surface thread will read its size from

336
00:14:34,800 --> 00:14:37,260
pm to increase all segments garbage

337
00:14:37,260 --> 00:14:39,899
bytes and write all objects deleted

338
00:14:39,899 --> 00:14:41,639
effect in pm

339
00:14:41,639 --> 00:14:44,579
this small random access on PM have high

340
00:14:44,579 --> 00:14:46,980
overheads

341
00:14:46,980 --> 00:14:49,920
to reduce the PM read of size Pac-Man

342
00:14:49,920 --> 00:14:52,139
embeds the size information in the upper

343
00:14:52,139 --> 00:14:54,779
16 bits of reference value

344
00:14:54,779 --> 00:14:57,240
therefore the sides can be acrossed from

345
00:14:57,240 --> 00:14:59,880
the index when updating reference

346
00:14:59,880 --> 00:15:03,180
to reduce the PM right of deleted flag

347
00:15:03,180 --> 00:15:05,699
Pac-Man adopter deleted the flag bitmap

348
00:15:05,699 --> 00:15:08,820
on dram for each segment

349
00:15:08,820 --> 00:15:11,339
Pac-Man locates the corresponding bit of

350
00:15:11,339 --> 00:15:13,920
a variable size object with its offset

351
00:15:13,920 --> 00:15:15,540
directly

352
00:15:15,540 --> 00:15:18,180
we denote the minimum size of an object

353
00:15:18,180 --> 00:15:21,600
as mean sides the bitmap reserves one

354
00:15:21,600 --> 00:15:23,459
bit protein inside

355
00:15:23,459 --> 00:15:26,160
the position of the deleted effect is

356
00:15:26,160 --> 00:15:28,139
calculated by dividing the object's

357
00:15:28,139 --> 00:15:30,420
offset by mean size

358
00:15:30,420 --> 00:15:32,760
in the most extreme case

359
00:15:32,760 --> 00:15:36,180
the mean size is 24 bytes which includes

360
00:15:36,180 --> 00:15:39,779
8 bytes of key 8 bites of value and

361
00:15:39,779 --> 00:15:42,120
eight packs of metadata header

362
00:15:42,120 --> 00:15:45,000
in this case the bitmap only consumes

363
00:15:45,000 --> 00:15:49,380
0.5 percent of space of PM log

364
00:15:49,380 --> 00:15:51,899
there are also some other design details

365
00:15:51,899 --> 00:15:54,899
such as how to optimize space overhead

366
00:15:54,899 --> 00:15:58,680
of shortcut and the recovery of Pac-Man

367
00:15:58,680 --> 00:16:01,380
if you are interested please check out

368
00:16:01,380 --> 00:16:03,240
our paper

369
00:16:03,240 --> 00:16:06,180
next I will report some experimental

370
00:16:06,180 --> 00:16:07,500
results

371
00:16:07,500 --> 00:16:10,019
our experiments are conducted on a

372
00:16:10,019 --> 00:16:12,600
server using one Uma socket to avoid

373
00:16:12,600 --> 00:16:14,220
human effect

374
00:16:14,220 --> 00:16:16,800
each CPU socket is equipped with three

375
00:16:16,800 --> 00:16:21,180
opt-in teams and the 96 gigabytes dram

376
00:16:21,180 --> 00:16:24,000
we apply Pac-Man on two stage of the art

377
00:16:24,000 --> 00:16:26,699
PM based log structure KB stores

378
00:16:26,699 --> 00:16:29,100
the store and wiper

379
00:16:29,100 --> 00:16:31,800
we apply four versions of desktop to

380
00:16:31,800 --> 00:16:34,260
evaluate different index types

381
00:16:34,260 --> 00:16:36,899
including harsh table based and a tree

382
00:16:36,899 --> 00:16:41,279
based volatile and a persistent index

383
00:16:41,279 --> 00:16:44,399
Benchmark workloads include ycsb with

384
00:16:44,399 --> 00:16:46,500
different settings and their production

385
00:16:46,500 --> 00:16:50,399
workload Facebook Etc pool

386
00:16:50,399 --> 00:16:52,199
these clickers show the overall

387
00:16:52,199 --> 00:16:54,959
performance in the typical pcsba

388
00:16:54,959 --> 00:16:57,660
workloads which is the same evaluation

389
00:16:57,660 --> 00:17:00,180
we showed in the motivation

390
00:17:00,180 --> 00:17:02,579
we evaluate these systems with small

391
00:17:02,579 --> 00:17:04,859
value size which are common in

392
00:17:04,859 --> 00:17:06,959
production KV workloads

393
00:17:06,959 --> 00:17:10,439
in these figures x-axis is the capacity

394
00:17:10,439 --> 00:17:12,839
utilization and the y-axis is the

395
00:17:12,839 --> 00:17:14,880
throughput

396
00:17:14,880 --> 00:17:16,919
from the figures you can see that

397
00:17:16,919 --> 00:17:19,199
Pac-Man obviously contains the

398
00:17:19,199 --> 00:17:21,119
performance decline at high capacity

399
00:17:21,119 --> 00:17:22,319
utilizations

400
00:17:22,319 --> 00:17:27,419
and achieves 1.5 to 3.5 times beat up

401
00:17:27,419 --> 00:17:29,580
Eggman also enhance the performance at

402
00:17:29,580 --> 00:17:31,679
low capacity utilizations

403
00:17:31,679 --> 00:17:34,440
where compactions are not very urgent

404
00:17:34,440 --> 00:17:36,900
this is because Pac-Man reduced the sum

405
00:17:36,900 --> 00:17:40,080
more random access and save PM's limited

406
00:17:40,080 --> 00:17:42,020
bandwidth

407
00:17:42,020 --> 00:17:45,080
then may vary the workload settings

408
00:17:45,080 --> 00:17:48,360
including uniform distribution different

409
00:17:48,360 --> 00:17:51,240
thread counts different value size

410
00:17:51,240 --> 00:17:53,940
different write ratios and different

411
00:17:53,940 --> 00:17:57,179
numbers of objects

412
00:17:57,179 --> 00:17:59,760
these results show that admin is

413
00:17:59,760 --> 00:18:02,280
effective in red intensive workloads

414
00:18:02,280 --> 00:18:05,840
with various settings

415
00:18:06,179 --> 00:18:09,600
Facebook Etc Blue Book load has mixture

416
00:18:09,600 --> 00:18:11,940
of small and large kvps

417
00:18:11,940 --> 00:18:14,280
which represents real world production

418
00:18:14,280 --> 00:18:15,960
workloads

419
00:18:15,960 --> 00:18:19,320
there are 40 of KV items with size

420
00:18:19,320 --> 00:18:23,460
smaller than 13 bytes and 55 of KV items

421
00:18:23,460 --> 00:18:26,580
with size smaller than 300 bytes

422
00:18:26,580 --> 00:18:30,539
the get-to-proot ratio is 50 to 50.

423
00:18:30,539 --> 00:18:32,460
the compare flat store with Pac-Man

424
00:18:32,460 --> 00:18:35,340
against other Space Systems premium

425
00:18:35,340 --> 00:18:38,520
drugs DB a payment version of rock CB

426
00:18:38,520 --> 00:18:42,720
and pmkv from Intel p-man DK group

427
00:18:42,720 --> 00:18:45,000
and the chameleon DB Another Log

428
00:18:45,000 --> 00:18:46,860
structure can be stored with a

429
00:18:46,860 --> 00:18:49,860
well-designed hybrid index

430
00:18:49,860 --> 00:18:52,559
we set all systems using the same amount

431
00:18:52,559 --> 00:18:54,419
of CPU resource

432
00:18:54,419 --> 00:18:56,580
since pmkv doesn't need background

433
00:18:56,580 --> 00:19:01,260
stress it used 28 threads and others use

434
00:19:01,260 --> 00:19:04,080
34 foreground services and four

435
00:19:04,080 --> 00:19:07,260
background threads for compaction

436
00:19:07,260 --> 00:19:09,900
a capacity utilization of chameleon DB

437
00:19:09,900 --> 00:19:13,919
and a flash store is set to 80 percent

438
00:19:13,919 --> 00:19:16,620
figure a shows the two point and the

439
00:19:16,620 --> 00:19:18,419
other four figures show the median and

440
00:19:18,419 --> 00:19:20,640
the tail latency

441
00:19:20,640 --> 00:19:22,919
from these figures we can see log

442
00:19:22,919 --> 00:19:25,140
structure KB stores have higher

443
00:19:25,140 --> 00:19:27,900
throughput in the lower latencies which

444
00:19:27,900 --> 00:19:30,720
proves log structure approach suits PM

445
00:19:30,720 --> 00:19:32,160
rail

446
00:19:32,160 --> 00:19:34,260
our Pacman further enhanced log

447
00:19:34,260 --> 00:19:37,220
structure KV stores

448
00:19:37,440 --> 00:19:39,600
finally I will present a brief

449
00:19:39,600 --> 00:19:41,100
conclusion

450
00:19:41,100 --> 00:19:43,320
we found that current conduction

451
00:19:43,320 --> 00:19:45,660
approach are unaware and the notable

452
00:19:45,660 --> 00:19:49,140
design according to PM's characteristics

453
00:19:49,140 --> 00:19:52,799
however PM's characteristics exacerbate

454
00:19:52,799 --> 00:19:55,080
the bottleneck of compaction in log

455
00:19:55,080 --> 00:19:57,360
structure KV stores

456
00:19:57,360 --> 00:20:00,360
we propose Pac-Man and efficient pmlware

457
00:20:00,360 --> 00:20:02,820
compaction approach or look structured

458
00:20:02,820 --> 00:20:05,460
KV stores on pm

459
00:20:05,460 --> 00:20:09,320
we applied and enhance tube

