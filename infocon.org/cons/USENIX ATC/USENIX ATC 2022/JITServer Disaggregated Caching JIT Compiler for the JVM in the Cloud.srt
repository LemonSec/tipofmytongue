1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:16,160 --> 00:00:18,720
between the researchers at the

3
00:00:18,720 --> 00:00:22,260
University of Toronto Alexander and eyel

4
00:00:22,260 --> 00:00:25,140
de Lara and IBM Canada represented by

5
00:00:25,140 --> 00:00:27,660
Vijay sundarasan and myself since

6
00:00:27,660 --> 00:00:29,580
neither Alex say no real could attend

7
00:00:29,580 --> 00:00:31,500
the conference due to some last minute

8
00:00:31,500 --> 00:00:34,020
events the order to present the paper

9
00:00:34,020 --> 00:00:36,540
was bestowed to me

10
00:00:36,540 --> 00:00:39,059
um let's jump straight into it so as we

11
00:00:39,059 --> 00:00:41,160
all know Java virtual machines rely

12
00:00:41,160 --> 00:00:44,760
heavily on jit compilers to improve the

13
00:00:44,760 --> 00:00:47,040
performance of java applications but

14
00:00:47,040 --> 00:00:49,140
this comes with a cost in order to

15
00:00:49,140 --> 00:00:51,780
function the G compiler consumes CPU

16
00:00:51,780 --> 00:00:54,539
cycles and allocates memory for its

17
00:00:54,539 --> 00:00:56,340
internal data structures activities

18
00:00:56,340 --> 00:00:58,379
which can interfere with Java

19
00:00:58,379 --> 00:01:00,719
applications because compilations as we

20
00:01:00,719 --> 00:01:03,600
know are performed at runtime

21
00:01:03,600 --> 00:01:06,299
this interference is mostly felt during

22
00:01:06,299 --> 00:01:08,460
the startup and ramp up phase of the

23
00:01:08,460 --> 00:01:10,799
application because that's when most of

24
00:01:10,799 --> 00:01:12,960
the compilations take place so let's

25
00:01:12,960 --> 00:01:15,240
look at the graph top right so this

26
00:01:15,240 --> 00:01:18,420
depicts the CP utilization of a JDM

27
00:01:18,420 --> 00:01:21,299
running a web application called day

28
00:01:21,299 --> 00:01:24,540
trader 7. as you can see while at steady

29
00:01:24,540 --> 00:01:27,060
state this application consumes about

30
00:01:27,060 --> 00:01:30,420
half of a CPU sometimes there are big

31
00:01:30,420 --> 00:01:34,080
spikes in CP utilization as high as 350

32
00:01:34,080 --> 00:01:36,720
percent which are caused by digit

33
00:01:36,720 --> 00:01:39,840
compilation activity so this CPU spikes

34
00:01:39,840 --> 00:01:42,060
can create hiccups in the behavior of

35
00:01:42,060 --> 00:01:44,640
the Java application and lower your

36
00:01:44,640 --> 00:01:46,860
quality of service especially in

37
00:01:46,860 --> 00:01:48,900
environments that are scarce in

38
00:01:48,900 --> 00:01:50,880
Computing resources so you can think of

39
00:01:50,880 --> 00:01:52,920
micro containers

40
00:01:52,920 --> 00:01:55,799
a similar situation happens for memory

41
00:01:55,799 --> 00:01:57,960
consumption the G compiler can create

42
00:01:57,960 --> 00:02:00,600
footprint spikes that are conducive to

43
00:02:00,600 --> 00:02:03,119
out of memory scenarios which can bring

44
00:02:03,119 --> 00:02:05,759
down the jvm so let's look at the graph

45
00:02:05,759 --> 00:02:08,340
bottom right and this shows the memory

46
00:02:08,340 --> 00:02:10,679
utilization of the same day trader 7

47
00:02:10,679 --> 00:02:13,140
application but steady state this

48
00:02:13,140 --> 00:02:16,500
application uses about 370 megabytes of

49
00:02:16,500 --> 00:02:19,020
ram but from time to time there are big

50
00:02:19,020 --> 00:02:21,599
spikes in memory usage caused Again by

51
00:02:21,599 --> 00:02:23,040
jit calculations

52
00:02:23,040 --> 00:02:25,200
if you want to avoid the out of memory

53
00:02:25,200 --> 00:02:27,959
scenarios you have to over provision the

54
00:02:27,959 --> 00:02:30,840
JDM to cover those spikes but

55
00:02:30,840 --> 00:02:33,540
unfortunately this in turn increases

56
00:02:33,540 --> 00:02:34,860
your costs

57
00:02:34,860 --> 00:02:37,739
moreover you don't know how big this

58
00:02:37,739 --> 00:02:40,140
price can be and they vary in amplitude

59
00:02:40,140 --> 00:02:42,360
from round to run because Java as we

60
00:02:42,360 --> 00:02:45,120
know it it's not very deterministic so

61
00:02:45,120 --> 00:02:46,980
you'd have to run many experiments to

62
00:02:46,980 --> 00:02:49,080
determine the maximum size of these

63
00:02:49,080 --> 00:02:51,480
spikes which makes the provisioning task

64
00:02:51,480 --> 00:02:54,840
harder now all the disadvantages can be

65
00:02:54,840 --> 00:02:57,840
eliminated by using jit disaggregation

66
00:02:57,840 --> 00:03:00,000
so what is that anyway

67
00:03:00,000 --> 00:03:03,660
uh the idea of G disaggregation is to

68
00:03:03,660 --> 00:03:06,300
decouple the jit compiler from the jvm

69
00:03:06,300 --> 00:03:08,400
let it run in its own process

70
00:03:08,400 --> 00:03:11,099
containerize it and make it available as

71
00:03:11,099 --> 00:03:13,379
a service in the cloud of course more

72
00:03:13,379 --> 00:03:15,000
than one client can connect to a single

73
00:03:15,000 --> 00:03:16,800
G server instance because there is no

74
00:03:16,800 --> 00:03:18,599
one-to-one relationship

75
00:03:18,599 --> 00:03:21,720
later on in in the results section uh

76
00:03:21,720 --> 00:03:23,819
I'll look at how many clients a server

77
00:03:23,819 --> 00:03:27,360
can handle on the picture here the

78
00:03:27,360 --> 00:03:29,580
compiler from the client JDM is crossed

79
00:03:29,580 --> 00:03:31,920
out but I'd like to mention that the

80
00:03:31,920 --> 00:03:33,720
clients actually retain the capability

81
00:03:33,720 --> 00:03:36,480
of compiling locally just in case the G

82
00:03:36,480 --> 00:03:38,879
server is not available so this is a

83
00:03:38,879 --> 00:03:41,099
reliability feature

84
00:03:41,099 --> 00:03:43,200
uh so what are the advantages of such a

85
00:03:43,200 --> 00:03:46,319
solution well those memory spikes that

86
00:03:46,319 --> 00:03:48,599
you saw on the previous slide are now

87
00:03:48,599 --> 00:03:51,299
completely gone this means that we can

88
00:03:51,299 --> 00:03:53,340
use smaller memory limits for our

89
00:03:53,340 --> 00:03:55,440
containers which in turn means cost

90
00:03:55,440 --> 00:03:57,720
savings and these settings are realized

91
00:03:57,720 --> 00:03:59,760
even after we account for the memory

92
00:03:59,760 --> 00:04:02,700
consumed by the server itself this is

93
00:04:02,700 --> 00:04:04,760
possible because memory consumption

94
00:04:04,760 --> 00:04:06,860
Peaks from different applications

95
00:04:06,860 --> 00:04:10,019
typically don't align the server

96
00:04:10,019 --> 00:04:14,040
on the CPU front the git compiler no

97
00:04:14,040 --> 00:04:16,199
longer steals Cycles from the Java

98
00:04:16,199 --> 00:04:19,260
application threads so startup time ramp

99
00:04:19,260 --> 00:04:21,298
up time and quality of service all

100
00:04:21,298 --> 00:04:23,580
improve especially in constrained

101
00:04:23,580 --> 00:04:26,160
environments moreover G server

102
00:04:26,160 --> 00:04:28,560
compilation resources can now be scaled

103
00:04:28,560 --> 00:04:30,900
independently of the Java application

104
00:04:30,900 --> 00:04:33,300
resources so think of this like a micro

105
00:04:33,300 --> 00:04:35,940
Services solution but applied to the JDM

106
00:04:35,940 --> 00:04:36,780
level

107
00:04:36,780 --> 00:04:39,060
when the clients need to perform lots of

108
00:04:39,060 --> 00:04:41,580
compilations we can bring up more server

109
00:04:41,580 --> 00:04:44,100
instances and when the need for

110
00:04:44,100 --> 00:04:46,020
compilation subsides we can reduce the

111
00:04:46,020 --> 00:04:48,060
number of G server instances maybe even

112
00:04:48,060 --> 00:04:49,680
down to zero

113
00:04:49,680 --> 00:04:51,900
finally provisioning becomes simpler

114
00:04:51,900 --> 00:04:55,080
because the user only has to consider

115
00:04:55,080 --> 00:04:57,540
the memory and CPU needs of his own

116
00:04:57,540 --> 00:05:00,060
application and ignore the needs of the

117
00:05:00,060 --> 00:05:02,759
jit which as I mentioned before are very

118
00:05:02,759 --> 00:05:04,020
hard to gauge

119
00:05:04,020 --> 00:05:05,759
as a sidebar I would like to mention

120
00:05:05,759 --> 00:05:08,460
that we have implemented gd's

121
00:05:08,460 --> 00:05:11,759
aggregation in uh Eclipse open j9 which

122
00:05:11,759 --> 00:05:13,919
is a free open source production grade

123
00:05:13,919 --> 00:05:16,380
jvm the code name of the feature is

124
00:05:16,380 --> 00:05:18,680
actually Jeep server technology

125
00:05:18,680 --> 00:05:22,080
however it's not all roses and I can

126
00:05:22,080 --> 00:05:24,600
anticipate some questions related to the

127
00:05:24,600 --> 00:05:27,620
networking overhead

128
00:05:27,900 --> 00:05:30,600
so let me go to next slide so with a

129
00:05:30,600 --> 00:05:34,080
remote jet the city overhead required to

130
00:05:34,080 --> 00:05:36,900
perform a compilation does not go away

131
00:05:36,900 --> 00:05:39,000
instead it is moved from the client to

132
00:05:39,000 --> 00:05:42,000
the server this has some advantages for

133
00:05:42,000 --> 00:05:44,580
the client as we already mentioned but

134
00:05:44,580 --> 00:05:46,860
from the point of view of faster wide

135
00:05:46,860 --> 00:05:48,960
CPU consumption there is no improvement

136
00:05:48,960 --> 00:05:51,360
for the contrary we now spend more CPU

137
00:05:51,360 --> 00:05:52,919
because we also pay for the network

138
00:05:52,919 --> 00:05:54,780
communication which is not cheap by the

139
00:05:54,780 --> 00:05:58,440
way uh another disadvantage is that

140
00:05:58,440 --> 00:06:01,020
compilation latency can be hired with

141
00:06:01,020 --> 00:06:04,199
remote due to network latency uh it's

142
00:06:04,199 --> 00:06:05,759
interesting that when you talk to people

143
00:06:05,759 --> 00:06:08,220
about G server most of them assume that

144
00:06:08,220 --> 00:06:10,680
there is a single network round trip the

145
00:06:10,680 --> 00:06:12,479
client sends a computation request the

146
00:06:12,479 --> 00:06:14,280
server performs the compilation and

147
00:06:14,280 --> 00:06:15,840
responds back with the compiled body

148
00:06:15,840 --> 00:06:18,240
however in practice there are many

149
00:06:18,240 --> 00:06:20,520
messages exchanged between client and

150
00:06:20,520 --> 00:06:23,100
server during a compilation because the

151
00:06:23,100 --> 00:06:25,199
server needs to gather all sorts of

152
00:06:25,199 --> 00:06:27,960
pieces of information about other

153
00:06:27,960 --> 00:06:30,539
classes other methods profiling

154
00:06:30,539 --> 00:06:33,060
information and so on it's quite

155
00:06:33,060 --> 00:06:35,639
unfeasible for the client to anticipate

156
00:06:35,639 --> 00:06:38,160
everything the server needs and embed

157
00:06:38,160 --> 00:06:40,020
all that information in the compilation

158
00:06:40,020 --> 00:06:43,979
request yes G server tries to Cache as

159
00:06:43,979 --> 00:06:47,520
much as it can but with a dynamic

160
00:06:47,520 --> 00:06:49,440
environment like Java where classes are

161
00:06:49,440 --> 00:06:52,440
loaded unloaded modified runtime caching

162
00:06:52,440 --> 00:06:55,199
has its limits so most of the time

163
00:06:55,199 --> 00:06:57,060
you'll see a scenario like in this

164
00:06:57,060 --> 00:07:00,479
figure bottom right where the client

165
00:07:00,479 --> 00:07:02,880
issues a compilation request then the

166
00:07:02,880 --> 00:07:06,539
server will compile for a bit then you

167
00:07:06,539 --> 00:07:07,919
may need some piece of information from

168
00:07:07,919 --> 00:07:10,080
the client it will issue a query to the

169
00:07:10,080 --> 00:07:11,880
client the client responds with the

170
00:07:11,880 --> 00:07:14,100
desired information again the server

171
00:07:14,100 --> 00:07:16,199
does a bit of compilation maybe it hits

172
00:07:16,199 --> 00:07:17,699
another point where it needs some other

173
00:07:17,699 --> 00:07:19,440
piece of information another request is

174
00:07:19,440 --> 00:07:20,880
sent to the client and so on and so

175
00:07:20,880 --> 00:07:24,240
forth until the server manages to send

176
00:07:24,240 --> 00:07:27,660
the compiled body back to the client

177
00:07:27,660 --> 00:07:30,660
so all these network round trips add the

178
00:07:30,660 --> 00:07:33,660
latency possibly affecting uh startup

179
00:07:33,660 --> 00:07:37,020
time and ramp up time in all fairness

180
00:07:37,020 --> 00:07:40,199
the local population can suffer even

181
00:07:40,199 --> 00:07:42,720
larger delays when running in CPU

182
00:07:42,720 --> 00:07:44,580
constraint environments on the figure

183
00:07:44,580 --> 00:07:47,099
here I drew

184
00:07:47,099 --> 00:07:49,500
um this local compilation as a straight

185
00:07:49,500 --> 00:07:54,479
line but in a in a in an environment

186
00:07:54,479 --> 00:07:56,400
where you don't have enough CPU then the

187
00:07:56,400 --> 00:07:59,039
operating system can schedule out those

188
00:07:59,039 --> 00:08:00,840
compilation threads to make room for the

189
00:08:00,840 --> 00:08:04,319
application threads so in some cases the

190
00:08:04,319 --> 00:08:06,419
local population can take even longer

191
00:08:06,419 --> 00:08:09,960
than in a remote GCI

192
00:08:09,960 --> 00:08:12,599
uh so the question is can we do better

193
00:08:12,599 --> 00:08:14,940
despite these drawbacks can we do better

194
00:08:14,940 --> 00:08:18,419
with uh the remote digit

195
00:08:18,419 --> 00:08:21,840
so the idea behind improving remote in

196
00:08:21,840 --> 00:08:23,220
the cloud stems from the observation

197
00:08:23,220 --> 00:08:25,919
that in the cloud we see many instances

198
00:08:25,919 --> 00:08:28,080
of the same application due to

199
00:08:28,080 --> 00:08:31,080
horizontal pod Auto scale so why not

200
00:08:31,080 --> 00:08:33,419
cache the completion artifacts produced

201
00:08:33,419 --> 00:08:35,458
by the remote digit for a jvm and then

202
00:08:35,458 --> 00:08:37,500
I'll use them for other jvms that are

203
00:08:37,500 --> 00:08:39,240
running the same code so this would

204
00:08:39,240 --> 00:08:41,399
amortize the completion costs over many

205
00:08:41,399 --> 00:08:43,979
jvms and at the same time improve

206
00:08:43,979 --> 00:08:46,200
compilation latency because we skip the

207
00:08:46,200 --> 00:08:48,120
communication and all those back and

208
00:08:48,120 --> 00:08:51,420
forth message exchanges but conceptually

209
00:08:51,420 --> 00:08:53,700
this is a very simple idea but the

210
00:08:53,700 --> 00:08:56,459
implementation is far from simple

211
00:08:56,459 --> 00:08:58,560
so let's see some of the challenges

212
00:08:58,560 --> 00:09:01,860
first the compiled body uh typically

213
00:09:01,860 --> 00:09:04,680
refers to other classes methods or other

214
00:09:04,680 --> 00:09:06,360
internal data structures through

215
00:09:06,360 --> 00:09:09,839
pointers and these data structures can

216
00:09:09,839 --> 00:09:11,880
be loaded at different addresses in new

217
00:09:11,880 --> 00:09:14,820
jdms as shown in the figure below so we

218
00:09:14,820 --> 00:09:16,860
need to fix up those addresses before

219
00:09:16,860 --> 00:09:19,740
being able to use the cache compile body

220
00:09:19,740 --> 00:09:22,620
hence we need to have some relocation

221
00:09:22,620 --> 00:09:25,620
records to take care of those fix ups

222
00:09:25,620 --> 00:09:28,200
but it gets more complicated the jit

223
00:09:28,200 --> 00:09:30,360
uses speculative optimization based on

224
00:09:30,360 --> 00:09:32,580
the perceived class hierarchy so let me

225
00:09:32,580 --> 00:09:34,200
let me give you an example here so let's

226
00:09:34,200 --> 00:09:36,000
say that we have an interface call and

227
00:09:36,000 --> 00:09:38,040
that the GD term is that there is a

228
00:09:38,040 --> 00:09:40,080
single implementer for that call the jit

229
00:09:40,080 --> 00:09:41,820
can align the body of that implementer

230
00:09:41,820 --> 00:09:45,120
and at runtime if a new implementer gets

231
00:09:45,120 --> 00:09:46,740
loaded we may need to take some

232
00:09:46,740 --> 00:09:49,800
corrective action in our case we need to

233
00:09:49,800 --> 00:09:52,019
have some validation records to make

234
00:09:52,019 --> 00:09:54,000
sure that assumptions that are made

235
00:09:54,000 --> 00:09:56,279
during the completion of this cached

236
00:09:56,279 --> 00:09:59,160
method body still hold true in the new

237
00:09:59,160 --> 00:10:02,220
JDM and get even more complicated so how

238
00:10:02,220 --> 00:10:05,339
can we make sure that two classes in two

239
00:10:05,339 --> 00:10:07,620
different jdms are equivalent because

240
00:10:07,620 --> 00:10:10,440
class name class name alone is not going

241
00:10:10,440 --> 00:10:12,540
to cut it

242
00:10:12,540 --> 00:10:15,980
so our solution to these problems is to

243
00:10:15,980 --> 00:10:19,200
store compiled methods in the so-called

244
00:10:19,200 --> 00:10:21,959
serialized format which adds some

245
00:10:21,959 --> 00:10:24,660
serialization records that specify how

246
00:10:24,660 --> 00:10:27,060
to fix up the code in another JDM we

247
00:10:27,060 --> 00:10:29,519
have a location records for updating the

248
00:10:29,519 --> 00:10:31,620
pointers we have validation records for

249
00:10:31,620 --> 00:10:33,899
verifying compiler assumptions and we

250
00:10:33,899 --> 00:10:36,060
also have a mechanism for validating

251
00:10:36,060 --> 00:10:38,700
that two Java classes in two different

252
00:10:38,700 --> 00:10:41,339
jdms are equivalent in the end all

253
00:10:41,339 --> 00:10:43,740
validation records and most of the

254
00:10:43,740 --> 00:10:46,260
relocation records are expressed in

255
00:10:46,260 --> 00:10:49,320
terms of java classes

256
00:10:49,320 --> 00:10:52,200
uh so the question becomes how can we

257
00:10:52,200 --> 00:10:55,980
identify classes that are equivalent uh

258
00:10:55,980 --> 00:10:57,899
the idea here is to store enough

259
00:10:57,899 --> 00:11:00,959
information to look up and verify the

260
00:11:00,959 --> 00:11:03,959
runtime class in in any JDM specifically

261
00:11:03,959 --> 00:11:07,079
for each class we store the fully

262
00:11:07,079 --> 00:11:10,620
qualified class name uh and a secure

263
00:11:10,620 --> 00:11:14,820
hash of the entire ROM class but also

264
00:11:14,820 --> 00:11:18,660
any other uh class on The Inheritance

265
00:11:18,660 --> 00:11:21,899
chain including any interfaces that this

266
00:11:21,899 --> 00:11:24,959
class implements as a sidebar here a ROM

267
00:11:24,959 --> 00:11:27,899
Plus in openg9 parlance it is the

268
00:11:27,899 --> 00:11:30,240
read-only part of a class and you can

269
00:11:30,240 --> 00:11:33,320
think of it as a pre-processed

270
00:11:33,320 --> 00:11:36,240
java.class file and from it the runtime

271
00:11:36,240 --> 00:11:38,339
openj9 generates the so-called Ram

272
00:11:38,339 --> 00:11:40,140
classes which are internal

273
00:11:40,140 --> 00:11:44,040
representations of the Java classes

274
00:11:44,040 --> 00:11:46,800
um moreover we also store class loaders

275
00:11:46,800 --> 00:11:49,980
uh which are identified by the name of

276
00:11:49,980 --> 00:11:52,380
the first loaded class so this is a

277
00:11:52,380 --> 00:11:54,899
heuristic but we found that it works

278
00:11:54,899 --> 00:11:57,240
very well in practice and uh even if it

279
00:11:57,240 --> 00:11:59,220
fails it can only affect performance but

280
00:11:59,220 --> 00:12:01,019
not correct

281
00:12:01,019 --> 00:12:04,380
so let's look at an example so say we

282
00:12:04,380 --> 00:12:08,100
have a class B that extends Class A we

283
00:12:08,100 --> 00:12:11,820
compile method M2 from plus C which

284
00:12:11,820 --> 00:12:14,579
calls M1 which has an implementation in

285
00:12:14,579 --> 00:12:16,620
B but there could be other implementers

286
00:12:16,620 --> 00:12:19,019
as well and they are not shown here so

287
00:12:19,019 --> 00:12:20,459
let's say that the profiler has

288
00:12:20,459 --> 00:12:23,100
determined that most of the time the

289
00:12:23,100 --> 00:12:25,800
incoming object is of type B then the

290
00:12:25,800 --> 00:12:30,480
compiler will inline B dot M1 with a

291
00:12:30,480 --> 00:12:33,420
de-virtualization guard expressed by the

292
00:12:33,420 --> 00:12:37,200
two assembly instructions here

293
00:12:37,200 --> 00:12:39,660
so first we compile We compare the type

294
00:12:39,660 --> 00:12:43,019
of the incoming object if this is B then

295
00:12:43,019 --> 00:12:45,959
we continue to execute the inline body

296
00:12:45,959 --> 00:12:49,740
of B dot M1 if the incoming object is

297
00:12:49,740 --> 00:12:51,959
not of type D then we jump to the slow

298
00:12:51,959 --> 00:12:54,540
path and there we execute the virtual

299
00:12:54,540 --> 00:12:55,260
call

300
00:12:55,260 --> 00:12:57,899
when the client receives the compiled

301
00:12:57,899 --> 00:13:01,740
version of C dot M2 it needs to patch in

302
00:13:01,740 --> 00:13:05,399
its own value for Ram Class B so first

303
00:13:05,399 --> 00:13:08,459
he needs to to find its version of ram

304
00:13:08,459 --> 00:13:11,519
Class B and then initially ensure that

305
00:13:11,519 --> 00:13:14,279
its version is equivalent to Ram Class B

306
00:13:14,279 --> 00:13:17,100
used when the compilation was performed

307
00:13:17,100 --> 00:13:19,440
for that the server compares the entire

308
00:13:19,440 --> 00:13:22,500
inheritance chain starting from B down

309
00:13:22,500 --> 00:13:24,899
to Java Lang object so let's assume that

310
00:13:24,899 --> 00:13:28,019
all classes were loaded by the bootstrap

311
00:13:28,019 --> 00:13:30,540
class loader that loaded Java Lang

312
00:13:30,540 --> 00:13:32,639
object as its first class

313
00:13:32,639 --> 00:13:37,079
the client uses Java Lang object name to

314
00:13:37,079 --> 00:13:39,779
find the class loader that loaded its

315
00:13:39,779 --> 00:13:42,000
first class with that name and with a

316
00:13:42,000 --> 00:13:44,579
class loader in hand and name the in

317
00:13:44,579 --> 00:13:46,500
hand it finds the ram class

318
00:13:46,500 --> 00:13:49,079
corresponding to D and from there the

319
00:13:49,079 --> 00:13:52,079
wrong class D it then compares the

320
00:13:52,079 --> 00:13:55,740
sha-256 of its wrong class b to the shop

321
00:13:55,740 --> 00:13:58,440
256 received from the server and it does

322
00:13:58,440 --> 00:14:01,740
the same for classes a and Java link

323
00:14:01,740 --> 00:14:04,079
object because they are on its

324
00:14:04,079 --> 00:14:06,899
inheritance chain if everything matches

325
00:14:06,899 --> 00:14:10,079
the client patches its own ramply around

326
00:14:10,079 --> 00:14:14,839
class D over the guard here

327
00:14:15,420 --> 00:14:18,540
uh I should mention here that not all

328
00:14:18,540 --> 00:14:20,880
compilations are subject to caching for

329
00:14:20,880 --> 00:14:23,880
a few reasons the locatable code is

330
00:14:23,880 --> 00:14:26,579
typically 10 percent slower than code

331
00:14:26,579 --> 00:14:29,040
which is Taylor fit for a particular JDM

332
00:14:29,040 --> 00:14:31,740
therefore we use it to accelerate the

333
00:14:31,740 --> 00:14:34,019
ramp up of applications but then a

334
00:14:34,019 --> 00:14:36,240
relatively small set of methods that are

335
00:14:36,240 --> 00:14:38,639
hotter than the rest are recompiled at

336
00:14:38,639 --> 00:14:40,620
higher optimization levels from our

337
00:14:40,620 --> 00:14:42,899
experience caching compilations at

338
00:14:42,899 --> 00:14:45,420
higher optimization levels increases the

339
00:14:45,420 --> 00:14:47,760
likelihood of failing validation records

340
00:14:47,760 --> 00:14:50,220
and therefore is not worth it in

341
00:14:50,220 --> 00:14:54,120
practice we observe a cash rate a cash a

342
00:14:54,120 --> 00:14:57,360
hit rate of about 70 to 95 percent

343
00:14:57,360 --> 00:14:59,399
depending on the application

344
00:14:59,399 --> 00:15:01,860
now let's look at some performance

345
00:15:01,860 --> 00:15:04,800
numbers so in our evaluation we use the

346
00:15:04,800 --> 00:15:08,459
three different web applications uh acne

347
00:15:08,459 --> 00:15:10,800
F day trader and spring pet clinic but

348
00:15:10,800 --> 00:15:12,600
in this presentation I'm going to show

349
00:15:12,600 --> 00:15:15,300
only acneer because the results are

350
00:15:15,300 --> 00:15:19,820
relatively similar for the others we use

351
00:15:19,820 --> 00:15:23,100
several machines with 16 CPUs and all

352
00:15:23,100 --> 00:15:25,320
these machines are connected with 10

353
00:15:25,320 --> 00:15:27,899
gigabyte ethernet which I consider to be

354
00:15:27,899 --> 00:15:30,480
standard for today's data centers

355
00:15:30,480 --> 00:15:33,360
uh all applications are run in a Docker

356
00:15:33,360 --> 00:15:37,860
containers and the default size for our

357
00:15:37,860 --> 00:15:41,040
containers uh is uh one CPU and one

358
00:15:41,040 --> 00:15:43,139
gigabyte of memory but uh for for some

359
00:15:43,139 --> 00:15:46,380
experiments we vary these sizes the

360
00:15:46,380 --> 00:15:50,399
server runs on a separate machine

361
00:15:50,399 --> 00:15:52,980
so now let's look at the startup time so

362
00:15:52,980 --> 00:15:56,160
on this graph here I'm showing the

363
00:15:56,160 --> 00:15:58,380
startup time measured in seconds on the

364
00:15:58,380 --> 00:16:01,380
y-axis and on x-axis we have different

365
00:16:01,380 --> 00:16:03,300
configurations so different container

366
00:16:03,300 --> 00:16:06,839
sizes extra small uses containers with

367
00:16:06,839 --> 00:16:09,300
half a CPU and half a gigabyte of memory

368
00:16:09,300 --> 00:16:11,699
small with one CPU one gigabyte of

369
00:16:11,699 --> 00:16:13,740
memory and so on and so forth for medium

370
00:16:13,740 --> 00:16:16,139
and large doubling the the sizes as we

371
00:16:16,139 --> 00:16:17,240
go

372
00:16:17,240 --> 00:16:22,440
uh let me uh say that by startup time we

373
00:16:22,440 --> 00:16:25,800
need the time needed by the JDM to be

374
00:16:25,800 --> 00:16:29,160
able to serve requests for each

375
00:16:29,160 --> 00:16:32,220
configuration we have three bars so the

376
00:16:32,220 --> 00:16:34,800
one in blue is the local jet no remote

377
00:16:34,800 --> 00:16:37,920
populations here uh the one in Orange is

378
00:16:37,920 --> 00:16:39,720
the remote jet but it doesn't use a

379
00:16:39,720 --> 00:16:42,240
cache and in green we add the cache to

380
00:16:42,240 --> 00:16:44,880
the remote to Jeep we can observe from

381
00:16:44,880 --> 00:16:47,519
the graph that even the remote jit alone

382
00:16:47,519 --> 00:16:50,279
is able to provide decent improvements

383
00:16:50,279 --> 00:16:53,339
in startup time but if we add the cache

384
00:16:53,339 --> 00:16:56,699
those improvements become bigger so with

385
00:16:56,699 --> 00:16:59,300
caching we can achieve as much as 15

386
00:16:59,300 --> 00:17:02,220
reduction in startup time

387
00:17:02,220 --> 00:17:04,559
uh and also another observation is that

388
00:17:04,559 --> 00:17:07,559
as you go from uh small containers to

389
00:17:07,559 --> 00:17:09,480
larger and larger containers those

390
00:17:09,480 --> 00:17:12,599
benefits uh decrease because now the

391
00:17:12,599 --> 00:17:15,599
local JDM has all the capacity needs to

392
00:17:15,599 --> 00:17:17,280
perform those compilations locally

393
00:17:17,280 --> 00:17:19,439
without affecting other application

394
00:17:19,439 --> 00:17:20,699
threads

395
00:17:20,699 --> 00:17:23,579
uh now let's look at warm-up time so

396
00:17:23,579 --> 00:17:25,799
this is measured in second we Define

397
00:17:25,799 --> 00:17:28,079
warm-up time as the time needed for an

398
00:17:28,079 --> 00:17:30,480
application to reach 90 percent of its

399
00:17:30,480 --> 00:17:32,940
peak throughput can we apply load just

400
00:17:32,940 --> 00:17:36,360
enough to saturate those instances

401
00:17:36,360 --> 00:17:41,100
uh remote jit by itself is very useful

402
00:17:41,100 --> 00:17:43,919
in improving the ramp up time and by

403
00:17:43,919 --> 00:17:46,860
adding the cache we extract a little bit

404
00:17:46,860 --> 00:17:49,620
of extra gain in terms of warm-up time

405
00:17:49,620 --> 00:17:53,340
uh why is that this is because during

406
00:17:53,340 --> 00:17:56,760
warm-up uh we have a mix of uh

407
00:17:56,760 --> 00:17:59,520
compilations coming from the cache but

408
00:17:59,520 --> 00:18:02,880
also recompilations remember that 10 Gap

409
00:18:02,880 --> 00:18:05,760
from relocatable code we try to recover

410
00:18:05,760 --> 00:18:09,000
that Gap by recompanying the code and

411
00:18:09,000 --> 00:18:10,500
those are the compilations do not take

412
00:18:10,500 --> 00:18:12,960
advantage of the cache they are they are

413
00:18:12,960 --> 00:18:15,539
consuming Cycles at the server

414
00:18:15,539 --> 00:18:16,559
um anyway

415
00:18:16,559 --> 00:18:19,200
um the jit server with cache is able to

416
00:18:19,200 --> 00:18:20,299
reduce

417
00:18:20,299 --> 00:18:25,140
ramp up time by up to 87 percent

418
00:18:25,140 --> 00:18:28,080
uh how about the system efficiency with

419
00:18:28,080 --> 00:18:29,940
respect to CPU cost because in the

420
00:18:29,940 --> 00:18:32,340
introduction I told you that this is a

421
00:18:32,340 --> 00:18:35,900
problem for the remote widget in itself

422
00:18:35,900 --> 00:18:39,480
in here the experiments are conducting

423
00:18:39,480 --> 00:18:43,080
such that we run 64 jvm instances that

424
00:18:43,080 --> 00:18:45,299
are start at the same time

425
00:18:45,299 --> 00:18:46,980
um actually no parents at the same time

426
00:18:46,980 --> 00:18:49,860
they have a small Gap in between uh and

427
00:18:49,860 --> 00:18:51,720
and they are short-lived so some of them

428
00:18:51,720 --> 00:18:53,340
last for two minutes in other

429
00:18:53,340 --> 00:18:55,200
experiments they run for five minutes

430
00:18:55,200 --> 00:18:57,120
and yet another in another experiment

431
00:18:57,120 --> 00:18:59,220
they run for 10 minutes so they are

432
00:18:59,220 --> 00:19:01,919
start started and stopped all the time

433
00:19:01,919 --> 00:19:05,340
uh we uh look at CPU cost which is

434
00:19:05,340 --> 00:19:08,039
defined as the total CPU time so the

435
00:19:08,039 --> 00:19:10,559
jdm's plus the CPU that is consumed by

436
00:19:10,559 --> 00:19:13,320
g-server and we divide that metric by

437
00:19:13,320 --> 00:19:16,620
the number of requests served as you can

438
00:19:16,620 --> 00:19:19,020
see uh here in the first grouping of

439
00:19:19,020 --> 00:19:23,280
bars remote digit can increase CPU time

440
00:19:23,280 --> 00:19:25,559
for reasons that I explained in the

441
00:19:25,559 --> 00:19:28,500
introduction uh however the moment you

442
00:19:28,500 --> 00:19:30,720
add the cache we don't have to perform

443
00:19:30,720 --> 00:19:32,880
all the compilations again and again we

444
00:19:32,880 --> 00:19:34,740
can serve directly from cache and we can

445
00:19:34,740 --> 00:19:36,600
save a lot of CPU so there is a

446
00:19:36,600 --> 00:19:39,440
significant Improvement in

447
00:19:39,440 --> 00:19:42,900
in CPU consumed with the addition of the

448
00:19:42,900 --> 00:19:46,020
cache uh that number comes up to be up

449
00:19:46,020 --> 00:19:50,280
to 77 percent uh smaller CPU cost with

450
00:19:50,280 --> 00:19:52,140
caching

451
00:19:52,140 --> 00:19:55,020
how about the memory usage so here we

452
00:19:55,020 --> 00:19:57,539
see good improvements uh from the remote

453
00:19:57,539 --> 00:20:01,380
digit alone and the addition of the

454
00:20:01,380 --> 00:20:04,679
cache doesn't provide much so uh from

455
00:20:04,679 --> 00:20:06,419
the memory point of view just the remote

456
00:20:06,419 --> 00:20:09,480
it is good enough and this uh why is

457
00:20:09,480 --> 00:20:11,820
this important for the end user well as

458
00:20:11,820 --> 00:20:13,700
I said the

459
00:20:13,700 --> 00:20:17,400
earlier with smaller containers you can

460
00:20:17,400 --> 00:20:19,020
increase the application density and

461
00:20:19,020 --> 00:20:21,419
therefore improve your costs in the

462
00:20:21,419 --> 00:20:22,799
cloud

463
00:20:22,799 --> 00:20:25,860
now how about the scalability uh on here

464
00:20:25,860 --> 00:20:27,720
on this graph I'm showing the full

465
00:20:27,720 --> 00:20:30,720
warm-up time and this is normalized to

466
00:20:30,720 --> 00:20:32,340
the situation where we don't use the

467
00:20:32,340 --> 00:20:34,500
remote digit therefore the local jit is

468
00:20:34,500 --> 00:20:37,380
a straight line uh if we look at the

469
00:20:37,380 --> 00:20:41,100
line in Orange the remote jit is able to

470
00:20:41,100 --> 00:20:43,440
handle about 50 instances before

471
00:20:43,440 --> 00:20:46,620
Crossing out the local jit whereas if we

472
00:20:46,620 --> 00:20:48,600
add the cache this is the line in a

473
00:20:48,600 --> 00:20:51,840
green then we can tolerate even more

474
00:20:51,840 --> 00:20:55,620
instances without additional CPU

475
00:20:55,620 --> 00:20:56,760
consumption

476
00:20:56,760 --> 00:21:00,000
so uh the the gist of this is that

477
00:21:00,000 --> 00:21:02,820
caching allows you to serve more clients

478
00:21:02,820 --> 00:21:05,400
using the same amount of resources

479
00:21:05,400 --> 00:21:07,340
because the compilation cost is uh

480
00:21:07,340 --> 00:21:10,919
amortized over multiple clients and

481
00:21:10,919 --> 00:21:12,860
finally let's look at the network

482
00:21:12,860 --> 00:21:16,280
latency how does this affect the

483
00:21:16,280 --> 00:21:20,720
performance of G server we run various

484
00:21:20,720 --> 00:21:23,100
experiments with increasing Network

485
00:21:23,100 --> 00:21:28,620
latency uh up to eight milliseconds

486
00:21:28,620 --> 00:21:32,360
and we see that remote jet can tolerate

487
00:21:32,360 --> 00:21:35,159
latencies about three milliseconds

488
00:21:35,159 --> 00:21:38,880
before uh

489
00:21:38,880 --> 00:21:43,200
before making a warm-up time larger than

490
00:21:43,200 --> 00:21:45,840
when we don't use the local jit whereas

491
00:21:45,840 --> 00:21:48,900
if we add the cache we can tolerate

492
00:21:48,900 --> 00:21:51,299
latencies natural latencies that are

493
00:21:51,299 --> 00:21:55,020
double in size so about six milliseconds

494
00:21:55,020 --> 00:21:57,900
and I would say that in the typical data

495
00:21:57,900 --> 00:22:01,620
center uh Network latencies should be in

496
00:22:01,620 --> 00:22:04,559
that range maybe even I've seen it on

497
00:22:04,559 --> 00:22:07,740
Amazon latencies that are well under one

498
00:22:07,740 --> 00:22:10,940
millisecond so this is not

499
00:22:10,940 --> 00:22:15,960
something that uh it's uh faking in our

500
00:22:15,960 --> 00:22:17,580
evaluation

501
00:22:17,580 --> 00:22:18,900
okay

502
00:22:18,900 --> 00:22:22,200
um so that is the last uh experiment

503
00:22:22,200 --> 00:22:25,500
that we've done in conclusion uh in this

504
00:22:25,500 --> 00:22:28,620
presentation we showed um that the G

505
00:22:28,620 --> 00:22:30,840
compilation of our head can pose some

506
00:22:30,840 --> 00:22:32,280
Performance challenges to Java

507
00:22:32,280 --> 00:22:34,620
applications running in the cloud uh

508
00:22:34,620 --> 00:22:36,980
where frequent restarts may be happening

509
00:22:36,980 --> 00:22:40,320
these problems can be alleviated to a

510
00:22:40,320 --> 00:22:42,240
large extent with a disaggregated remote

511
00:22:42,240 --> 00:22:44,640
jet however this solution tends to

512
00:22:44,640 --> 00:22:47,940
increase CPU consumption cluster wide

513
00:22:47,940 --> 00:22:51,000
due to networking overheads to address

514
00:22:51,000 --> 00:22:53,640
this issue we propose to reuse

515
00:22:53,640 --> 00:22:56,640
previously compiled code by adding a

516
00:22:56,640 --> 00:22:59,220
cache and the g server and we described

517
00:22:59,220 --> 00:23:01,679
a novel mechanism for serializing

518
00:23:01,679 --> 00:23:03,900
dynamically dynamically compiled code

519
00:23:03,900 --> 00:23:06,299
the caching mechanism of the server

520
00:23:06,299 --> 00:23:09,000
further improves the performance of the

521
00:23:09,000 --> 00:23:12,840
remote jit allowing our solution to reap

522
00:23:12,840 --> 00:23:15,179
significant benefits in terms of startup

523
00:23:15,179 --> 00:23:18,539
time ramp up time CPU usage memory usage

524
00:23:18,539 --> 00:23:21,720
and application density this solution is

525
00:23:21,720 --> 00:23:25,740
fully implemented in Eclipse open j9 jvm

526
00:23:25,740 --> 00:23:28,440
and it can be tried today

527
00:23:28,440 --> 00:23:30,539
so thank you that concludes my

528
00:23:30,539 --> 00:23:32,400
presentation and I'm ready to take

529
00:23:32,400 --> 00:23:34,820
questions

