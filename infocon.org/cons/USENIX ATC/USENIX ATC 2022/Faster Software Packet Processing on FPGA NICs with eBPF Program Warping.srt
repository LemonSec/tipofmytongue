1
00:00:13,200 --> 00:00:15,599
hello everybody i'm here to present the

2
00:00:15,599 --> 00:00:17,520
work faster software packet processing

3
00:00:17,520 --> 00:00:20,640
on fpgenix with a bpf program warping so

4
00:00:20,640 --> 00:00:22,160
first of all i would like to thank all

5
00:00:22,160 --> 00:00:24,160
the co-authors of this work this is a

6
00:00:24,160 --> 00:00:27,279
joint work by experience knit nec and

7
00:00:27,279 --> 00:00:29,439
university of roma

8
00:00:29,439 --> 00:00:31,039
so let me give you a little bit of

9
00:00:31,039 --> 00:00:32,479
context

10
00:00:32,479 --> 00:00:33,600
so it's

11
00:00:33,600 --> 00:00:35,840
widely acknowledged that due to

12
00:00:35,840 --> 00:00:38,160
different emerging paradigms like

13
00:00:38,160 --> 00:00:39,680
software-defined networking network

14
00:00:39,680 --> 00:00:42,160
function virtualization cloud-native

15
00:00:42,160 --> 00:00:44,640
networking it is nowadays pretty common

16
00:00:44,640 --> 00:00:47,360
to implement a wide range of network

17
00:00:47,360 --> 00:00:49,680
functions and software and run them on

18
00:00:49,680 --> 00:00:52,480
top of general purpose cpus notable

19
00:00:52,480 --> 00:00:55,600
examples include the layer 2 switching

20
00:00:55,600 --> 00:00:57,920
layer 3 forwarding firewall network

21
00:00:57,920 --> 00:00:59,920
chosen detection and so on

22
00:00:59,920 --> 00:01:02,239
now unfortunately running

23
00:01:02,239 --> 00:01:04,239
software network functions on general

24
00:01:04,239 --> 00:01:06,400
purpose service and general purpose cpus

25
00:01:06,400 --> 00:01:08,000
required

26
00:01:08,000 --> 00:01:10,560
a significant amount of cpu resources

27
00:01:10,560 --> 00:01:13,280
which significantly contributes to the

28
00:01:13,280 --> 00:01:15,280
role infrastructure costs and energy

29
00:01:15,280 --> 00:01:18,799
consumption now fortunately on one side

30
00:01:18,799 --> 00:01:20,720
the network traffic is still increasing

31
00:01:20,720 --> 00:01:22,640
every year by the for the introduction

32
00:01:22,640 --> 00:01:24,720
of new services and new technologies but

33
00:01:24,720 --> 00:01:26,000
unfortunately we have entered the

34
00:01:26,000 --> 00:01:28,080
postmore era so it means that processors

35
00:01:28,080 --> 00:01:30,640
are not getting any faster and this is

36
00:01:30,640 --> 00:01:32,159
the main reason why

37
00:01:32,159 --> 00:01:34,159
existing and emerging vendors are

38
00:01:34,159 --> 00:01:37,040
already commercializing a set of new

39
00:01:37,040 --> 00:01:39,040
network hardware accelerators named

40
00:01:39,040 --> 00:01:42,320
sometimes martiniques or dpus or ipu's

41
00:01:42,320 --> 00:01:45,520
whatever in the end these devices are

42
00:01:45,520 --> 00:01:47,360
network interface cards with some

43
00:01:47,360 --> 00:01:49,439
additional hardware components that are

44
00:01:49,439 --> 00:01:51,920
specialized in execution of network

45
00:01:51,920 --> 00:01:53,600
workloads

46
00:01:53,600 --> 00:01:56,159
so how do we scale up the execution of

47
00:01:56,159 --> 00:01:58,479
generic software network function in the

48
00:01:58,479 --> 00:02:01,680
endos so we may think that simple we

49
00:02:01,680 --> 00:02:03,680
just push the software network function

50
00:02:03,680 --> 00:02:06,399
into the nic but this is a little bit

51
00:02:06,399 --> 00:02:08,399
it's more complicated than we may think

52
00:02:08,399 --> 00:02:11,200
and let's take a look at how

53
00:02:11,200 --> 00:02:13,760
these devices are are designed now of

54
00:02:13,760 --> 00:02:16,080
course the architectural details may

55
00:02:16,080 --> 00:02:18,640
vary but from vendor to vendor of course

56
00:02:18,640 --> 00:02:20,959
but from a very level point of view we

57
00:02:20,959 --> 00:02:22,640
have the following components we have

58
00:02:22,640 --> 00:02:25,440
two interfaces generally one one or more

59
00:02:25,440 --> 00:02:27,680
network ports and one host interface for

60
00:02:27,680 --> 00:02:29,520
communicating with your system like for

61
00:02:29,520 --> 00:02:31,599
example pci express interface one

62
00:02:31,599 --> 00:02:34,480
lecture data plane which is usually a

63
00:02:34,480 --> 00:02:38,640
programmable asic processing unit and or

64
00:02:38,640 --> 00:02:41,440
an fpga module then we have a processing

65
00:02:41,440 --> 00:02:43,120
clusters which

66
00:02:43,120 --> 00:02:44,560
consists of

67
00:02:44,560 --> 00:02:47,200
generally general purpose cpus like arm

68
00:02:47,200 --> 00:02:49,360
cores risk five cores and then we have a

69
00:02:49,360 --> 00:02:52,080
bank of delegated accelerators that are

70
00:02:52,080 --> 00:02:53,680
responsible for the execution of

71
00:02:53,680 --> 00:02:56,319
functions like crypto qos debug

72
00:02:56,319 --> 00:02:58,879
inspection and so on so do we really

73
00:02:58,879 --> 00:03:00,959
have a solution how do we execute

74
00:03:00,959 --> 00:03:02,480
software network function on this kind

75
00:03:02,480 --> 00:03:06,080
of architecture so the most obvious

76
00:03:06,080 --> 00:03:07,920
approach would be to leverage the

77
00:03:07,920 --> 00:03:10,640
typical sdn separation between the slow

78
00:03:10,640 --> 00:03:12,480
pattern the fastpass the control pane

79
00:03:12,480 --> 00:03:14,640
and the data plane and run the control

80
00:03:14,640 --> 00:03:16,879
logic of the program on the general

81
00:03:16,879 --> 00:03:18,879
purpose processing cluster and the

82
00:03:18,879 --> 00:03:21,120
packet processing program on the network

83
00:03:21,120 --> 00:03:23,200
that are playing with some help from the

84
00:03:23,200 --> 00:03:25,519
dedicated accelerators but this is not

85
00:03:25,519 --> 00:03:28,720
as easy again as it may seem and

86
00:03:28,720 --> 00:03:31,599
actually everything depends on which

87
00:03:31,599 --> 00:03:34,480
programming interface we have used

88
00:03:34,480 --> 00:03:37,120
to write our own programs now what is

89
00:03:37,120 --> 00:03:40,000
the best approach for simplifying the

90
00:03:40,000 --> 00:03:41,920
overall natural function development in

91
00:03:41,920 --> 00:03:43,519
the nick while at the same time

92
00:03:43,519 --> 00:03:45,120
leveraging the

93
00:03:45,120 --> 00:03:47,120
specialized hardware architecture of

94
00:03:47,120 --> 00:03:49,440
these devices probably design this

95
00:03:49,440 --> 00:03:52,000
question is not yet answered but in the

96
00:03:52,000 --> 00:03:54,239
meantime a new network programming

97
00:03:54,239 --> 00:03:56,239
interface has emerged from the linux

98
00:03:56,239 --> 00:03:59,040
world it is called ebpf and it's getting

99
00:03:59,040 --> 00:04:00,560
a lot of attention from both the

100
00:04:00,560 --> 00:04:03,439
industry and the research community and

101
00:04:03,439 --> 00:04:05,840
you can say that people are really

102
00:04:05,840 --> 00:04:08,480
looking to ebpf by simply observing the

103
00:04:08,480 --> 00:04:11,040
names of the early adopters and the huge

104
00:04:11,040 --> 00:04:13,439
number of research works related to this

105
00:04:13,439 --> 00:04:16,320
topic so it seems like ebpf is a good

106
00:04:16,320 --> 00:04:18,478
solution for programming our nik so but

107
00:04:18,478 --> 00:04:22,079
how can we run an ebf a new bpf program

108
00:04:22,079 --> 00:04:23,680
on the nic

109
00:04:23,680 --> 00:04:25,040
so this is not

110
00:04:25,040 --> 00:04:28,000
easy at all so one approach could be to

111
00:04:28,000 --> 00:04:30,720
use the general purpose processing class

112
00:04:30,720 --> 00:04:32,720
okay from one hand

113
00:04:32,720 --> 00:04:35,120
this approach would permit to run

114
00:04:35,120 --> 00:04:38,320
unmodified ebpf programs inside the nic

115
00:04:38,320 --> 00:04:40,800
but this approach would present a set of

116
00:04:40,800 --> 00:04:42,560
inefficiencies that are related to the

117
00:04:42,560 --> 00:04:44,400
fact that we are using general purpose

118
00:04:44,400 --> 00:04:47,680
cpus and also related to the overhead

119
00:04:47,680 --> 00:04:51,520
required to port to fully port the bpf

120
00:04:51,520 --> 00:04:53,840
software framework into the nic

121
00:04:53,840 --> 00:04:55,520
a better approach in terms of

122
00:04:55,520 --> 00:04:57,759
performance would be to re-implement the

123
00:04:57,759 --> 00:04:59,759
ebpf program and run it on top of the

124
00:04:59,759 --> 00:05:02,320
programmable airplane and the excel and

125
00:05:02,320 --> 00:05:04,639
the dedicated accelerators now

126
00:05:04,639 --> 00:05:06,080
this would be great in term of

127
00:05:06,080 --> 00:05:08,000
performance of course but it would

128
00:05:08,000 --> 00:05:10,479
require additional engineering effort

129
00:05:10,479 --> 00:05:12,080
because of course you have to re-adapt

130
00:05:12,080 --> 00:05:13,919
the program into the actual target

131
00:05:13,919 --> 00:05:15,199
architecture

132
00:05:15,199 --> 00:05:17,199
but actually things are even worse

133
00:05:17,199 --> 00:05:19,680
because this is not always possible

134
00:05:19,680 --> 00:05:21,520
because for example bpf is much more

135
00:05:21,520 --> 00:05:23,360
flexible than other programming

136
00:05:23,360 --> 00:05:25,759
abstractions okay for example p4 now p4

137
00:05:25,759 --> 00:05:28,080
is great again but you can do more with

138
00:05:28,080 --> 00:05:30,960
ebpf with respect to p4 and it's not

139
00:05:30,960 --> 00:05:33,600
always granted that you are able to

140
00:05:33,600 --> 00:05:35,919
execute on any bpf program into the nic

141
00:05:35,919 --> 00:05:38,479
and lastly each nic is a different

142
00:05:38,479 --> 00:05:40,479
hardware platform so we would need to

143
00:05:40,479 --> 00:05:42,400
implement every time for every different

144
00:05:42,400 --> 00:05:45,520
target architecture our program and we

145
00:05:45,520 --> 00:05:46,800
would break

146
00:05:46,800 --> 00:05:48,720
this way one of the best features of a

147
00:05:48,720 --> 00:05:51,199
bpf which is of course portability so we

148
00:05:51,199 --> 00:05:53,199
really believe that if we want to run in

149
00:05:53,199 --> 00:05:55,919
bpf programs and modify the bpf programs

150
00:05:55,919 --> 00:05:56,880
on the nic

151
00:05:56,880 --> 00:05:59,039
we don't need to rethink

152
00:05:59,039 --> 00:06:01,039
about the internal architecture of the

153
00:06:01,039 --> 00:06:02,960
smart nic and this is what we have been

154
00:06:02,960 --> 00:06:04,639
doing for the last years and

155
00:06:04,639 --> 00:06:07,440
particularly in 2020 we published this

156
00:06:07,440 --> 00:06:10,639
work at usnx osdi the naming was hxdp

157
00:06:10,639 --> 00:06:12,479
efficient software packet processing on

158
00:06:12,479 --> 00:06:15,919
fpga mix in this work we proposed a full

159
00:06:15,919 --> 00:06:18,560
nik design with a dedicated hardware

160
00:06:18,560 --> 00:06:20,560
block including a very long extraction

161
00:06:20,560 --> 00:06:22,479
word processor that is

162
00:06:22,479 --> 00:06:25,280
specifically designed for the execution

163
00:06:25,280 --> 00:06:28,960
of a modified ebp of xdp programs now we

164
00:06:28,960 --> 00:06:31,280
proved that even if we have

165
00:06:31,280 --> 00:06:33,759
clock frequencies that are much lower on

166
00:06:33,759 --> 00:06:35,440
the net fpga we had if i remember

167
00:06:35,440 --> 00:06:39,039
correctly 150 megahertz we managed to

168
00:06:39,039 --> 00:06:41,520
have performance that for some use cases

169
00:06:41,520 --> 00:06:44,720
was comparable with the performance that

170
00:06:44,720 --> 00:06:47,280
we obtained on a x86 software

171
00:06:47,280 --> 00:06:49,520
implementation now we kept working on

172
00:06:49,520 --> 00:06:52,160
hxdp after conference and we improved

173
00:06:52,160 --> 00:06:54,800
the design of course we also supported

174
00:06:54,800 --> 00:06:57,759
the design from the net fpgas roommate

175
00:06:57,759 --> 00:06:59,919
to the exciting

176
00:06:59,919 --> 00:07:02,720
ultrascale philosophy ganx

177
00:07:02,720 --> 00:07:06,080
allowing higher clock frequency up to

178
00:07:06,080 --> 00:07:09,520
250 measures and in particular also

179
00:07:09,520 --> 00:07:11,440
enabling new features like for example

180
00:07:11,440 --> 00:07:14,039
multi-processing

181
00:07:14,039 --> 00:07:16,880
multi-multi-core processing still for

182
00:07:16,880 --> 00:07:19,360
some use cases we were not able to reach

183
00:07:19,360 --> 00:07:21,520
the performance that we wanted to to

184
00:07:21,520 --> 00:07:24,240
reach with a dedicated hardware and this

185
00:07:24,240 --> 00:07:26,479
is what brings us here so basically the

186
00:07:26,479 --> 00:07:28,000
question is can we

187
00:07:28,000 --> 00:07:30,479
do something smarter in order to

188
00:07:30,479 --> 00:07:32,800
get faster on the fpga

189
00:07:32,800 --> 00:07:34,800
and the answer is yes and basically in

190
00:07:34,800 --> 00:07:38,000
this work we prove that with limited

191
00:07:38,000 --> 00:07:40,479
additional hardware resources and the

192
00:07:40,479 --> 00:07:43,280
help of a very smart compiler we are

193
00:07:43,280 --> 00:07:45,039
able to boost the performance of

194
00:07:45,039 --> 00:07:48,400
unmodified ebp of xdp programs up to a

195
00:07:48,400 --> 00:07:51,120
factor of 18x for example for the use

196
00:07:51,120 --> 00:07:52,880
case regat

197
00:07:52,880 --> 00:07:55,360
so but how is it possible so let me give

198
00:07:55,360 --> 00:07:59,039
you a brief overview of how the program

199
00:07:59,039 --> 00:08:01,840
working works so on the left we have a

200
00:08:01,840 --> 00:08:04,080
high level description of all the entry

201
00:08:04,080 --> 00:08:06,160
points in which we can push an ebpf

202
00:08:06,160 --> 00:08:08,319
program into the kernel namely the ebpf

203
00:08:08,319 --> 00:08:09,280
hooks

204
00:08:09,280 --> 00:08:11,280
now needless to say that we are

205
00:08:11,280 --> 00:08:13,919
targeting the xdp hook for our work

206
00:08:13,919 --> 00:08:16,400
because it's the hook that has least

207
00:08:16,400 --> 00:08:19,280
dependencies on other kernel components

208
00:08:19,280 --> 00:08:21,120
and of course offers a good opportunity

209
00:08:21,120 --> 00:08:23,039
for outdoor offloading on the right we

210
00:08:23,039 --> 00:08:25,680
have a very very simple toy example that

211
00:08:25,680 --> 00:08:28,240
i'm going to use to show you how the bpf

212
00:08:28,240 --> 00:08:29,440
program work

213
00:08:29,440 --> 00:08:31,599
works so basically we're checking a few

214
00:08:31,599 --> 00:08:34,159
fields the header length the ip protocol

215
00:08:34,159 --> 00:08:36,958
then we are constructing a key that used

216
00:08:36,958 --> 00:08:39,519
to retrieve a status from an ebpf map

217
00:08:39,519 --> 00:08:41,360
then we take a forwarding decision

218
00:08:41,360 --> 00:08:43,519
according to the state that we retrieve

219
00:08:43,519 --> 00:08:46,240
from the map and then we update

220
00:08:46,240 --> 00:08:48,560
a counter now

221
00:08:48,560 --> 00:08:50,959
the original hxdp approach is the

222
00:08:50,959 --> 00:08:53,279
following one so basically we took we

223
00:08:53,279 --> 00:08:55,680
take the original program we compile it

224
00:08:55,680 --> 00:08:57,600
with standard compilers then we take the

225
00:08:57,600 --> 00:09:00,800
byte code and we adapt the mdpf bytecode

226
00:09:00,800 --> 00:09:03,760
into our hxdp instruction set and then

227
00:09:03,760 --> 00:09:05,680
we run the program so for every packet

228
00:09:05,680 --> 00:09:07,839
we run the full program all the

229
00:09:07,839 --> 00:09:10,240
instructions as soon as we finish

230
00:09:10,240 --> 00:09:11,760
with one packet we

231
00:09:11,760 --> 00:09:13,600
we process the next packet and this was

232
00:09:13,600 --> 00:09:15,120
the most reasonable approach for us

233
00:09:15,120 --> 00:09:17,440
because we didn't want to add any

234
00:09:17,440 --> 00:09:19,440
constraints on top of the constraints

235
00:09:19,440 --> 00:09:23,040
that a bbf program already as

236
00:09:23,040 --> 00:09:26,399
from the um in kernel verify but if we

237
00:09:26,399 --> 00:09:28,720
think a little bit about

238
00:09:28,720 --> 00:09:31,279
network programs we may agree that even

239
00:09:31,279 --> 00:09:33,680
though you can write your bpf program as

240
00:09:33,680 --> 00:09:34,720
you like

241
00:09:34,720 --> 00:09:36,720
so in the end

242
00:09:36,720 --> 00:09:38,560
most programs

243
00:09:38,560 --> 00:09:41,920
do a set of recurring operations and in

244
00:09:41,920 --> 00:09:44,399
particular at the beginning of a program

245
00:09:44,399 --> 00:09:46,880
so as highlighted here for example

246
00:09:46,880 --> 00:09:49,600
usually all natural programs start with

247
00:09:49,600 --> 00:09:51,680
a portion of more portion in which you

248
00:09:51,680 --> 00:09:52,959
parse in the bucket so basically you

249
00:09:52,959 --> 00:09:55,120
extract some fields from the packet you

250
00:09:55,120 --> 00:09:57,600
verify a set of matching conditions and

251
00:09:57,600 --> 00:09:59,760
you probably take some early verdict on

252
00:09:59,760 --> 00:10:01,600
the packet for example i don't care

253
00:10:01,600 --> 00:10:03,839
about ipv6 packet let's just drop it

254
00:10:03,839 --> 00:10:06,320
before doing anything else okay then

255
00:10:06,320 --> 00:10:09,360
after the parsing block let's say we

256
00:10:09,360 --> 00:10:12,560
always have a lookup key construction

257
00:10:12,560 --> 00:10:15,200
portion in which basically you construct

258
00:10:15,200 --> 00:10:16,640
your key

259
00:10:16,640 --> 00:10:18,240
that you're going to use to retrieve

260
00:10:18,240 --> 00:10:19,680
some data from

261
00:10:19,680 --> 00:10:22,000
from the bpf maps now this is the

262
00:10:22,000 --> 00:10:25,120
intuition of this work if this initial

263
00:10:25,120 --> 00:10:28,480
part of the program happens before any

264
00:10:28,480 --> 00:10:31,200
other ebpf calls that produce an

265
00:10:31,200 --> 00:10:32,720
unpredictable

266
00:10:32,720 --> 00:10:33,920
output

267
00:10:33,920 --> 00:10:36,640
this portion of the program depends only

268
00:10:36,640 --> 00:10:38,480
on the packet header or on the packets

269
00:10:38,480 --> 00:10:41,920
in general okay so assuming that we are

270
00:10:41,920 --> 00:10:44,320
able to build a software component able

271
00:10:44,320 --> 00:10:46,880
to understand all these matching rules

272
00:10:46,880 --> 00:10:48,640
at the beginning of the program to

273
00:10:48,640 --> 00:10:51,600
understand how to parse the packet and

274
00:10:51,600 --> 00:10:54,720
it understands how to reconstruct the

275
00:10:54,720 --> 00:10:57,519
program context in the point in which

276
00:10:57,519 --> 00:10:59,760
the map lookup is performed and with the

277
00:10:59,760 --> 00:11:02,160
program context i mean the content of

278
00:11:02,160 --> 00:11:03,839
the stack and the content of the

279
00:11:03,839 --> 00:11:06,880
register and assuming that we have a

280
00:11:06,880 --> 00:11:09,519
hardware block specialized in execution

281
00:11:09,519 --> 00:11:12,079
of this operation and an hardware block

282
00:11:12,079 --> 00:11:14,160
who is able to push the program context

283
00:11:14,160 --> 00:11:16,720
into an http executor

284
00:11:16,720 --> 00:11:19,920
now we can completely skip the first

285
00:11:19,920 --> 00:11:22,000
part of the program delegate the

286
00:11:22,000 --> 00:11:23,600
execution of this first part of the

287
00:11:23,600 --> 00:11:25,120
program to this specialized hardware

288
00:11:25,120 --> 00:11:27,839
block and start exactly from the point

289
00:11:27,839 --> 00:11:31,120
in which we perform the map lookup

290
00:11:31,120 --> 00:11:34,399
of course if the number of clock cycles

291
00:11:34,399 --> 00:11:36,480
required to execute the first portion of

292
00:11:36,480 --> 00:11:38,079
the program in hardware in the

293
00:11:38,079 --> 00:11:40,079
specialized start dirt are significantly

294
00:11:40,079 --> 00:11:43,600
less than the number of cycles required

295
00:11:43,600 --> 00:11:45,360
by the the software implementation let's

296
00:11:45,360 --> 00:11:47,040
say of the first part of the program you

297
00:11:47,040 --> 00:11:49,440
get a performance improvement a

298
00:11:49,440 --> 00:11:52,399
throughput improvement now we

299
00:11:52,399 --> 00:11:54,240
know and we proved that actually this

300
00:11:54,240 --> 00:11:56,399
first part of the program can be easily

301
00:11:56,399 --> 00:11:58,399
and efficiently implemented in artboard

302
00:11:58,399 --> 00:12:00,240
because in the end it's something like

303
00:12:00,240 --> 00:12:02,240
that that makes section table in the

304
00:12:02,240 --> 00:12:04,800
slide basically you do some matches you

305
00:12:04,800 --> 00:12:07,120
verify some fields and then you decide

306
00:12:07,120 --> 00:12:08,560
what to do you can drop the packet

307
00:12:08,560 --> 00:12:10,399
transmit the packet or

308
00:12:10,399 --> 00:12:12,720
in case of an execution branch which you

309
00:12:12,720 --> 00:12:14,560
want to look up into a map you can

310
00:12:14,560 --> 00:12:16,399
simply restore the context of the

311
00:12:16,399 --> 00:12:19,040
program and jump directly to the point

312
00:12:19,040 --> 00:12:20,880
in which you do the map lookup and what

313
00:12:20,880 --> 00:12:24,480
i've just said is the general um

314
00:12:24,480 --> 00:12:26,560
i mean it's it's how the program working

315
00:12:26,560 --> 00:12:28,560
works so let's recap a little bit so we

316
00:12:28,560 --> 00:12:31,440
start from unmodified bpf programs

317
00:12:31,440 --> 00:12:33,760
we compile the program with standard

318
00:12:33,760 --> 00:12:37,519
abpf compilers like llvm we get the

319
00:12:37,519 --> 00:12:40,480
standard ebp of bytecode now we run our

320
00:12:40,480 --> 00:12:43,120
work optimizer the word protimizers

321
00:12:43,120 --> 00:12:45,200
understand what are the word

322
00:12:45,200 --> 00:12:47,040
instructions so the instructions that

323
00:12:47,040 --> 00:12:48,160
can be

324
00:12:48,160 --> 00:12:49,920
executed by the warping giant

325
00:12:49,920 --> 00:12:52,320
automatically generates the

326
00:12:52,320 --> 00:12:54,880
configuration for the work engine block

327
00:12:54,880 --> 00:12:56,800
and then extract the unmodified

328
00:12:56,800 --> 00:12:58,240
instructions so the reminder of the

329
00:12:58,240 --> 00:12:59,920
program then push the remainder of the

330
00:12:59,920 --> 00:13:02,320
program into the xdp execution

331
00:13:02,320 --> 00:13:04,800
environment which in this case is of

332
00:13:04,800 --> 00:13:06,880
course hxdp because this work can be

333
00:13:06,880 --> 00:13:10,320
seen as an extension to hsdp of course

334
00:13:10,320 --> 00:13:12,079
now

335
00:13:12,079 --> 00:13:14,399
all the packets that we are going to

336
00:13:14,399 --> 00:13:16,399
process in our architecture will first

337
00:13:16,399 --> 00:13:18,639
traverse the warp engine

338
00:13:18,639 --> 00:13:20,560
it will be matched against the match

339
00:13:20,560 --> 00:13:22,000
action table i'll show you before and

340
00:13:22,000 --> 00:13:24,800
then of course they will enter the xdp

341
00:13:24,800 --> 00:13:27,360
execution environment starting from the

342
00:13:27,360 --> 00:13:30,560
context that is reconstructed and pushed

343
00:13:30,560 --> 00:13:33,040
by the warping giant

344
00:13:33,040 --> 00:13:34,639
so let me give you a few details about

345
00:13:34,639 --> 00:13:36,079
the two main components of this

346
00:13:36,079 --> 00:13:38,240
architecture so the warping optimizer is

347
00:13:38,240 --> 00:13:40,560
basically the compiler okay so it's this

348
00:13:40,560 --> 00:13:42,160
software component that is able to do

349
00:13:42,160 --> 00:13:43,920
what i just said

350
00:13:43,920 --> 00:13:46,399
uh on the left we have another example

351
00:13:46,399 --> 00:13:49,040
this is even easier so but trust me this

352
00:13:49,040 --> 00:13:51,040
algorithm works also which much more

353
00:13:51,040 --> 00:13:52,639
complicated use cases but it would be

354
00:13:52,639 --> 00:13:54,800
impossible to show you how it works when

355
00:13:54,800 --> 00:13:56,079
i'm more complicated use cases so

356
00:13:56,079 --> 00:13:58,560
basically it does very few things

357
00:13:58,560 --> 00:14:00,800
just check the content of the ethernet

358
00:14:00,800 --> 00:14:03,360
protocol in case of a pv6 that drops the

359
00:14:03,360 --> 00:14:05,920
packet in case of ipv before it performs

360
00:14:05,920 --> 00:14:09,040
a lookup into the map and in and else

361
00:14:09,040 --> 00:14:11,040
and all the other cases that just pass

362
00:14:11,040 --> 00:14:14,639
the packet okay so this algorithm starts

363
00:14:14,639 --> 00:14:16,800
by generating a control flow graph

364
00:14:16,800 --> 00:14:18,800
related to the program okay so in this

365
00:14:18,800 --> 00:14:20,800
control flow graph we can have different

366
00:14:20,800 --> 00:14:22,480
nodes but first of all we have the

367
00:14:22,480 --> 00:14:24,639
starting node in this case it's b1 the

368
00:14:24,639 --> 00:14:26,639
starting block then of course we have

369
00:14:26,639 --> 00:14:27,519
inter

370
00:14:27,519 --> 00:14:29,519
terminal nodes a terminal nodes is a

371
00:14:29,519 --> 00:14:33,040
node in which we have either an exit or

372
00:14:33,040 --> 00:14:35,040
an mbpf call

373
00:14:35,040 --> 00:14:37,279
or

374
00:14:38,079 --> 00:14:40,639
a map lookup okay so basically when we

375
00:14:40,639 --> 00:14:43,519
reach this block we need to emit

376
00:14:43,519 --> 00:14:46,720
a rule when we reach a terminal node

377
00:14:46,720 --> 00:14:48,480
before reaching a terminal node of

378
00:14:48,480 --> 00:14:51,279
course we can traverse multiple middle

379
00:14:51,279 --> 00:14:54,720
nodes middle nodes can be matching nodes

380
00:14:54,720 --> 00:14:57,199
or a metric node is a block portion

381
00:14:57,199 --> 00:15:00,639
which we have a conditional

382
00:15:00,639 --> 00:15:01,600
jump

383
00:15:01,600 --> 00:15:04,639
uh with some packet value okay if i p

384
00:15:04,639 --> 00:15:07,120
protocol is ipv4 jump to this branch

385
00:15:07,120 --> 00:15:09,600
this is a a matching node a non-matching

386
00:15:09,600 --> 00:15:11,680
node is a block

387
00:15:11,680 --> 00:15:13,360
yes it's a block in which you don't have

388
00:15:13,360 --> 00:15:14,720
a conditional jump you have an

389
00:15:14,720 --> 00:15:16,959
unconditional jump let's say

390
00:15:16,959 --> 00:15:19,199
okay now the algorithm starts like this

391
00:15:19,199 --> 00:15:21,120
it initializes a set of internal

392
00:15:21,120 --> 00:15:22,959
variables to zero like for example the

393
00:15:22,959 --> 00:15:24,800
current priority of the route that i'm

394
00:15:24,800 --> 00:15:27,360
going to meet but it also said to zero

395
00:15:27,360 --> 00:15:29,120
the list of

396
00:15:29,120 --> 00:15:31,519
fields that i'm going to read the list

397
00:15:31,519 --> 00:15:33,440
of matching rules the content of the

398
00:15:33,440 --> 00:15:34,880
registers and the content of the stack

399
00:15:34,880 --> 00:15:36,560
everything is set to there and then it

400
00:15:36,560 --> 00:15:38,320
starts of course it starts from the

401
00:15:38,320 --> 00:15:40,720
starting node it performs at

402
00:15:40,720 --> 00:15:43,199
that first search and found the first

403
00:15:43,199 --> 00:15:44,880
execution path so in this case the first

404
00:15:44,880 --> 00:15:48,160
execution path is b1 b2 and b6 and in

405
00:15:48,160 --> 00:15:51,120
this case for each node that understand

406
00:15:51,120 --> 00:15:53,040
if we are writing something in the stack

407
00:15:53,040 --> 00:15:54,639
if we are reading something from the

408
00:15:54,639 --> 00:15:56,560
bucket you understand the matching rules

409
00:15:56,560 --> 00:15:58,320
and in this case it understands that

410
00:15:58,320 --> 00:16:00,720
there is one match field which is

411
00:16:00,720 --> 00:16:03,759
basically from byte 12 to byte 13 which

412
00:16:03,759 --> 00:16:05,839
is the other net protocol and understand

413
00:16:05,839 --> 00:16:08,399
that this branch is triggered when we

414
00:16:08,399 --> 00:16:11,040
receive a packet with ethernet protocol

415
00:16:11,040 --> 00:16:13,680
equal to ipv6 now when it reaches the

416
00:16:13,680 --> 00:16:16,160
terminal node in this case b6

417
00:16:16,160 --> 00:16:18,160
it emits the rule and in this case we

418
00:16:18,160 --> 00:16:19,920
have with priority zero that if we have

419
00:16:19,920 --> 00:16:22,639
a packet with ethernet protocol

420
00:16:22,639 --> 00:16:25,600
ipv6 we just drop the packet now this is

421
00:16:25,600 --> 00:16:27,680
a recursive algorithm so we go back to

422
00:16:27,680 --> 00:16:29,199
the first parent node then we take

423
00:16:29,199 --> 00:16:31,120
another execution branch in this case

424
00:16:31,120 --> 00:16:34,000
the execution branch is b1 b2 b3 before

425
00:16:34,000 --> 00:16:36,480
in this case we end up in a terminal

426
00:16:36,480 --> 00:16:38,800
node in which we reform a map lookup so

427
00:16:38,800 --> 00:16:42,399
in this case the compiler understands

428
00:16:42,399 --> 00:16:45,920
how the program context is formed at the

429
00:16:45,920 --> 00:16:47,759
point in which we perform the lookup and

430
00:16:47,759 --> 00:16:49,440
in particular it understands that the

431
00:16:49,440 --> 00:16:52,320
program counter is equal 34 register one

432
00:16:52,320 --> 00:16:55,360
contains zero immediate value error two

433
00:16:55,360 --> 00:16:58,000
contains minus eight it's a pointer to

434
00:16:58,000 --> 00:16:59,120
the stack

435
00:16:59,120 --> 00:17:01,120
register three contains a byte in the

436
00:17:01,120 --> 00:17:03,519
packet and in the stack we have from

437
00:17:03,519 --> 00:17:05,520
bytes six of the packet to buy the lemon

438
00:17:05,520 --> 00:17:07,199
of the packet

439
00:17:07,199 --> 00:17:09,439
of course it's soon it's reaches the

440
00:17:09,439 --> 00:17:11,199
point in which we invoke the call it

441
00:17:11,199 --> 00:17:13,199
emits a rule a new rule which is if you

442
00:17:13,199 --> 00:17:16,480
get a packet with ethernet protocol ipv4

443
00:17:16,480 --> 00:17:18,880
restore the context and jump at the

444
00:17:18,880 --> 00:17:21,199
point in which a program counter is 34.

445
00:17:21,199 --> 00:17:23,359
now again recursive algorithm we'll go

446
00:17:23,359 --> 00:17:24,959
back to the first parent we take the

447
00:17:24,959 --> 00:17:26,720
last possible branch this is an easy

448
00:17:26,720 --> 00:17:28,640
branch because basically this is the

449
00:17:28,640 --> 00:17:30,240
else bridge

450
00:17:30,240 --> 00:17:32,320
branch and in fact we emit a rule with a

451
00:17:32,320 --> 00:17:34,640
wild card value on that match field

452
00:17:34,640 --> 00:17:37,200
which is simply pass

453
00:17:37,200 --> 00:17:39,760
so this is the beginning of our program

454
00:17:39,760 --> 00:17:41,440
can be

455
00:17:41,440 --> 00:17:43,760
represented as a match action table with

456
00:17:43,760 --> 00:17:47,200
this specific new restore context action

457
00:17:47,200 --> 00:17:48,799
now let me give you a few details about

458
00:17:48,799 --> 00:17:50,240
the warp engine

459
00:17:50,240 --> 00:17:52,240
so the actual hardware block that is

460
00:17:52,240 --> 00:17:54,720
going to implement what i just said now

461
00:17:54,720 --> 00:17:57,840
this is a pipeline implementation of a

462
00:17:57,840 --> 00:17:58,960
fuse

463
00:17:58,960 --> 00:18:01,440
parsing unit and match action unit which

464
00:18:01,440 --> 00:18:03,440
is similar to other asic switching

465
00:18:03,440 --> 00:18:05,039
technologies but it's much easier in the

466
00:18:05,039 --> 00:18:06,880
end because of some optimization and

467
00:18:06,880 --> 00:18:08,320
simplification

468
00:18:08,320 --> 00:18:10,640
due to the co-design with the warp

469
00:18:10,640 --> 00:18:14,000
optimizer so basically we can see three

470
00:18:14,000 --> 00:18:16,559
main stages in this design we have a

471
00:18:16,559 --> 00:18:19,600
field structure this is a

472
00:18:19,600 --> 00:18:22,160
a stage consisting of 12 sub stages in

473
00:18:22,160 --> 00:18:24,640
which we are able to extract up to 16

474
00:18:24,640 --> 00:18:27,520
bytes from the packet and for maki this

475
00:18:27,520 --> 00:18:29,039
key is used as

476
00:18:29,039 --> 00:18:31,360
lookup key for the next stage of the

477
00:18:31,360 --> 00:18:32,960
warp engine which is the mesh action

478
00:18:32,960 --> 00:18:34,799
unit is exactly the match action table i

479
00:18:34,799 --> 00:18:37,360
showed you before so we extract the key

480
00:18:37,360 --> 00:18:39,440
we look up into the sticker

481
00:18:39,440 --> 00:18:42,559
and then of course if we have the

482
00:18:42,559 --> 00:18:44,960
xdp verdict transactions like drop and

483
00:18:44,960 --> 00:18:47,280
transmit we don't need anything else but

484
00:18:47,280 --> 00:18:50,080
if the if the action associated to the

485
00:18:50,080 --> 00:18:53,520
tkm key is restore context and jump

486
00:18:53,520 --> 00:18:56,160
there of course we're gonna put in the

487
00:18:56,160 --> 00:18:58,880
register memory in the stack memory

488
00:18:58,880 --> 00:19:02,080
an indication of how to reconstruct the

489
00:19:02,080 --> 00:19:05,280
stack and the register at that point now

490
00:19:05,280 --> 00:19:07,200
for all the packets that need to reach

491
00:19:07,200 --> 00:19:10,559
the final xdp executor of course we need

492
00:19:10,559 --> 00:19:11,280
to

493
00:19:11,280 --> 00:19:13,440
traverse the context registration unit

494
00:19:13,440 --> 00:19:16,080
which is basically the piece of hardware

495
00:19:16,080 --> 00:19:20,160
that pushes inside the xdp executor the

496
00:19:20,160 --> 00:19:21,280
context

497
00:19:21,280 --> 00:19:23,440
for that particular packet at that

498
00:19:23,440 --> 00:19:26,640
particular position in the code

499
00:19:26,640 --> 00:19:29,120
now on the right we have the last pass

500
00:19:29,120 --> 00:19:31,039
the last piece of the architecture which

501
00:19:31,039 --> 00:19:32,559
is not a contribution of this paper

502
00:19:32,559 --> 00:19:35,039
because this is basically hxdp and in

503
00:19:35,039 --> 00:19:38,000
particular this is the last version hxdp

504
00:19:38,000 --> 00:19:40,960
which was specifically extended in order

505
00:19:40,960 --> 00:19:43,360
to hook the warp engine into the

506
00:19:43,360 --> 00:19:46,000
executor now without entering into other

507
00:19:46,000 --> 00:19:48,160
further architectural details i'm

508
00:19:48,160 --> 00:19:50,640
probably not even the best

509
00:19:50,640 --> 00:19:52,720
person in the team to talk about the

510
00:19:52,720 --> 00:19:54,720
fpga design let me

511
00:19:54,720 --> 00:19:57,039
summarize the main features of this warp

512
00:19:57,039 --> 00:19:58,559
engine so basically this is runtime

513
00:19:58,559 --> 00:20:00,720
programmable it means that this pipeline

514
00:20:00,720 --> 00:20:03,039
can be reprogrammed at runtime according

515
00:20:03,039 --> 00:20:05,520
to the configuration produced by the

516
00:20:05,520 --> 00:20:08,320
work optimizer

517
00:20:08,320 --> 00:20:10,559
as i said before this is a pipeline it

518
00:20:10,559 --> 00:20:12,880
means that it never stalls so it means

519
00:20:12,880 --> 00:20:13,679
that

520
00:20:13,679 --> 00:20:16,960
it is not it is never a bottleneck for

521
00:20:16,960 --> 00:20:19,039
the overall execution of the program we

522
00:20:19,039 --> 00:20:21,280
go here the bottleneck is actually the

523
00:20:21,280 --> 00:20:23,520
xdp executor so the throughput is

524
00:20:23,520 --> 00:20:26,240
limited by the time required by the xdp

525
00:20:26,240 --> 00:20:29,520
executor to complete the program

526
00:20:29,520 --> 00:20:30,400
third

527
00:20:30,400 --> 00:20:32,880
for packets that need to be let's say

528
00:20:32,880 --> 00:20:36,080
either transmitted or dropped b24 the

529
00:20:36,080 --> 00:20:37,679
actual lookup

530
00:20:37,679 --> 00:20:40,480
this warp engine completely replaces the

531
00:20:40,480 --> 00:20:42,159
software implementation

532
00:20:42,159 --> 00:20:44,240
instead for all the reminder for the

533
00:20:44,240 --> 00:20:46,320
remaining packets this piece of hardware

534
00:20:46,320 --> 00:20:47,840
is

535
00:20:47,840 --> 00:20:50,159
restore the context push the packet and

536
00:20:50,159 --> 00:20:52,960
terminate the xdp program execution

537
00:20:52,960 --> 00:20:55,600
inside hxdp

538
00:20:55,600 --> 00:20:57,520
now implementation

539
00:20:57,520 --> 00:20:59,440
this is the overall picture so basically

540
00:20:59,440 --> 00:21:01,120
we have two main components now the

541
00:21:01,120 --> 00:21:03,919
compiler the optimizer and the nic okay

542
00:21:03,919 --> 00:21:06,640
the work optimizer has been prototyped

543
00:21:06,640 --> 00:21:08,960
as a python arc application that

544
00:21:08,960 --> 00:21:12,000
integrates also the hxdp compiler the

545
00:21:12,000 --> 00:21:15,039
input of this software component is the

546
00:21:15,039 --> 00:21:17,520
standard ebpf bytecode

547
00:21:17,520 --> 00:21:19,840
and the output is twofold we have on the

548
00:21:19,840 --> 00:21:21,600
one hand we have the warp engine

549
00:21:21,600 --> 00:21:23,120
configuration and on the other end we

550
00:21:23,120 --> 00:21:24,720
have the remaining of the program let's

551
00:21:24,720 --> 00:21:27,039
say the unmodified instructions that

552
00:21:27,039 --> 00:21:30,559
need to be executed by the xdp executor

553
00:21:30,559 --> 00:21:31,520
the

554
00:21:31,520 --> 00:21:33,440
warp engine has been implemented on top

555
00:21:33,440 --> 00:21:38,480
of an exilinx lv50 clocked at 250 megs

556
00:21:38,480 --> 00:21:41,360
and of course here our fpga x

557
00:21:41,360 --> 00:21:44,400
includes both the work optimizer and the

558
00:21:44,400 --> 00:21:47,760
hxdp executor

559
00:21:48,320 --> 00:21:51,440
evaluation evaluation took a lot of time

560
00:21:51,440 --> 00:21:54,000
actually for this work and basically we

561
00:21:54,000 --> 00:21:55,120
need to

562
00:21:55,120 --> 00:21:56,960
answer the following question first of

563
00:21:56,960 --> 00:21:58,720
all and this is probably the most

564
00:21:58,720 --> 00:22:01,600
complicated one is is the optimize

565
00:22:01,600 --> 00:22:03,679
program functionally equivalent to the

566
00:22:03,679 --> 00:22:06,080
original one you don't have to think

567
00:22:06,080 --> 00:22:08,000
of the simple example that i'll show you

568
00:22:08,000 --> 00:22:09,919
before you need to think about a complex

569
00:22:09,919 --> 00:22:12,240
program we have a lot of education so

570
00:22:12,240 --> 00:22:13,760
the first thing that we wanted to be

571
00:22:13,760 --> 00:22:16,240
sure about was is the output of the

572
00:22:16,240 --> 00:22:18,960
optimizer functionally equivalent to the

573
00:22:18,960 --> 00:22:21,360
original program for all the use cases

574
00:22:21,360 --> 00:22:23,520
in our use case

575
00:22:23,520 --> 00:22:25,760
reference set second how many

576
00:22:25,760 --> 00:22:27,840
instruction can we skip

577
00:22:27,840 --> 00:22:30,240
third what is the triplet improvement

578
00:22:30,240 --> 00:22:33,039
and last how much do we pay in terms of

579
00:22:33,039 --> 00:22:35,440
new resources

580
00:22:35,440 --> 00:22:36,159
now

581
00:22:36,159 --> 00:22:38,400
for different evaluations of the works

582
00:22:38,400 --> 00:22:40,480
we used an emulator a software emulator

583
00:22:40,480 --> 00:22:42,880
of our warp engine

584
00:22:42,880 --> 00:22:45,120
because basically we had to compare the

585
00:22:45,120 --> 00:22:47,200
warp engine with an xdp implementation

586
00:22:47,200 --> 00:22:48,799
without the warp engine so either we

587
00:22:48,799 --> 00:22:50,640
extend the kernel we have to do it in

588
00:22:50,640 --> 00:22:52,559
another way and basically we we build

589
00:22:52,559 --> 00:22:54,640
the software emulator starting from the

590
00:22:54,640 --> 00:22:56,640
micro bpf implementation the user space

591
00:22:56,640 --> 00:22:59,039
implementation of bpf we extended those

592
00:22:59,039 --> 00:23:00,720
that implementation in order to fully

593
00:23:00,720 --> 00:23:03,360
support xdp and then in order to support

594
00:23:03,360 --> 00:23:06,719
the warp optimizer

595
00:23:07,360 --> 00:23:10,080
this emulator take an input a pickup

596
00:23:10,080 --> 00:23:12,080
which is the input trace the input

597
00:23:12,080 --> 00:23:14,320
traffic and generates four different

598
00:23:14,320 --> 00:23:16,799
pickup traces uh related to the four

599
00:23:16,799 --> 00:23:19,360
different ebpf vertex the transmit the

600
00:23:19,360 --> 00:23:21,200
pass support and drop

601
00:23:21,200 --> 00:23:23,360
so basically we can verify what we have

602
00:23:23,360 --> 00:23:26,159
been output for the work engine and for

603
00:23:26,159 --> 00:23:28,240
the xdp executor without the warp engine

604
00:23:28,240 --> 00:23:30,000
on the right we have the set of

605
00:23:30,000 --> 00:23:32,559
reference use cases that we used in this

606
00:23:32,559 --> 00:23:34,640
work we have the layer 2 scl the running

607
00:23:34,640 --> 00:23:36,960
a sample stupid one a dynamic nut that

608
00:23:36,960 --> 00:23:40,080
we wrote two example in the kernel three

609
00:23:40,080 --> 00:23:42,080
the router and the txt tunnel and then

610
00:23:42,080 --> 00:23:44,159
surikata and then katran kadran is the

611
00:23:44,159 --> 00:23:46,240
facebook load balancer written with a

612
00:23:46,240 --> 00:23:48,480
bpf now functional equivalence to prove

613
00:23:48,480 --> 00:23:50,960
the function equivalence we enumerated

614
00:23:50,960 --> 00:23:53,600
all the programs control path in all the

615
00:23:53,600 --> 00:23:56,320
use case then we synthetically generated

616
00:23:56,320 --> 00:23:59,200
a set of input traces that trigger all

617
00:23:59,200 --> 00:24:02,320
the different execution paths

618
00:24:02,320 --> 00:24:03,919
and then of course we verified that the

619
00:24:03,919 --> 00:24:06,400
output was the same was the same in case

620
00:24:06,400 --> 00:24:09,600
of the work optimization and in case of

621
00:24:09,600 --> 00:24:11,919
no warp interpretation and of course you

622
00:24:11,919 --> 00:24:14,240
can read the details in the paper the

623
00:24:14,240 --> 00:24:16,880
functional equivalence is satisfied by

624
00:24:16,880 --> 00:24:18,720
our warp engine

625
00:24:18,720 --> 00:24:20,799
now how many instruction can we skip of

626
00:24:20,799 --> 00:24:22,799
course this depends on the particular

627
00:24:22,799 --> 00:24:24,480
use case

628
00:24:24,480 --> 00:24:26,640
so what we did basically to see the

629
00:24:26,640 --> 00:24:28,960
impact of this is we

630
00:24:28,960 --> 00:24:31,279
counted the number of extraction without

631
00:24:31,279 --> 00:24:32,720
the optimization

632
00:24:32,720 --> 00:24:34,799
and the number of reduced instruction

633
00:24:34,799 --> 00:24:37,039
when we actually have the implementation

634
00:24:37,039 --> 00:24:39,120
then we divided the standard and we saw

635
00:24:39,120 --> 00:24:41,520
the impact for many use cases we have an

636
00:24:41,520 --> 00:24:43,520
improvement factor greater than 50

637
00:24:43,520 --> 00:24:45,840
percent but at least we have sixteen

638
00:24:45,840 --> 00:24:47,440
point three percent of improvement

639
00:24:47,440 --> 00:24:49,440
suriga is one of the use cases which

640
00:24:49,440 --> 00:24:51,360
work

641
00:24:51,360 --> 00:24:54,400
ah okay sorry it works really well okay

642
00:24:54,400 --> 00:24:57,679
uh that's coming you just if you

643
00:24:57,679 --> 00:24:59,440
just about the additional hardware

644
00:24:59,440 --> 00:25:01,679
resources that we need so basically the

645
00:25:01,679 --> 00:25:04,000
the the combination of the xdp and the

646
00:25:04,000 --> 00:25:06,720
warp engine takes less than 70 of all

647
00:25:06,720 --> 00:25:09,919
fpgas resources so we kept our original

648
00:25:09,919 --> 00:25:12,720
requirement was to be below 20

649
00:25:12,720 --> 00:25:14,400
and in terms of throughput

650
00:25:14,400 --> 00:25:16,480
we have let's regatta we have an average

651
00:25:16,480 --> 00:25:19,600
trouble of 308 percent and for the other

652
00:25:19,600 --> 00:25:21,440
use cases this is the average throughput

653
00:25:21,440 --> 00:25:23,840
improvement 30 percent for the ruler 28

654
00:25:23,840 --> 00:25:25,840
for a ton of the not 23 and cut around

655
00:25:25,840 --> 00:25:27,600
131

656
00:25:27,600 --> 00:25:30,720
so sorry it took me more than

657
00:25:30,720 --> 00:25:33,720
expected

