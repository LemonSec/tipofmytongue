1
00:00:07,940 --> 00:00:10,940
thank you

2
00:00:13,040 --> 00:00:16,920
hello everyone I am Chinese a PhD

3
00:00:16,920 --> 00:00:18,199
student from Hong Kong University

4
00:00:18,199 --> 00:00:21,600
supervised by Dr Ramin sui today I'm

5
00:00:21,600 --> 00:00:24,300
going to present Salter a secure and

6
00:00:24,300 --> 00:00:26,279
high performance influence system for

7
00:00:26,279 --> 00:00:28,800
General neural networks this work is

8
00:00:28,800 --> 00:00:30,720
collaborated with Huawei Hong Kong

9
00:00:30,720 --> 00:00:32,820
Polytechnic University and Southern

10
00:00:32,820 --> 00:00:36,860
University of Science and Technology

11
00:00:37,880 --> 00:00:40,440
nowadays giant companies like Google

12
00:00:40,440 --> 00:00:42,360
provide well-trained deep learning

13
00:00:42,360 --> 00:00:45,000
models to clients deep learning models

14
00:00:45,000 --> 00:00:47,399
especially deep neural network serve

15
00:00:47,399 --> 00:00:48,840
numerous Mission critical AI

16
00:00:48,840 --> 00:00:51,480
applications in our daily life such as

17
00:00:51,480 --> 00:00:53,879
autonomous driving home monitoring

18
00:00:53,879 --> 00:00:55,739
virtual assistance and speech

19
00:00:55,739 --> 00:00:57,059
recognition

20
00:00:57,059 --> 00:00:59,399
to obtain accurate models giant

21
00:00:59,399 --> 00:01:01,440
companies must pay substantial training

22
00:01:01,440 --> 00:01:03,600
efforts to collect private training data

23
00:01:03,600 --> 00:01:06,420
sets to hyper parameters and afford huge

24
00:01:06,420 --> 00:01:08,580
amount of expensive training resource

25
00:01:08,580 --> 00:01:11,159
hence World trending models are

26
00:01:11,159 --> 00:01:13,140
intellectual properties which are

27
00:01:13,140 --> 00:01:14,400
private

28
00:01:14,400 --> 00:01:17,100
to provide high quality services these

29
00:01:17,100 --> 00:01:19,140
private deal models are usually deployed

30
00:01:19,140 --> 00:01:21,479
on edge site user devices

31
00:01:21,479 --> 00:01:24,360
clients run exciting inference to get

32
00:01:24,360 --> 00:01:27,119
real-time results the basic workflow is

33
00:01:27,119 --> 00:01:29,820
shown Below in this workflow the model

34
00:01:29,820 --> 00:01:32,340
provider offloads its private model to

35
00:01:32,340 --> 00:01:34,860
the edge the client constantly sends

36
00:01:34,860 --> 00:01:37,140
query input such as an environmental

37
00:01:37,140 --> 00:01:39,540
snapshot to the edge device that runs

38
00:01:39,540 --> 00:01:41,100
the offloading model

39
00:01:41,100 --> 00:01:43,619
by running model inference locally The

40
00:01:43,619 --> 00:01:45,119
Edge device returns to the final

41
00:01:45,119 --> 00:01:47,340
inference result such as a turn right

42
00:01:47,340 --> 00:01:49,860
instruction back to the client

43
00:01:49,860 --> 00:01:52,619
however in this workflow the private

44
00:01:52,619 --> 00:01:55,200
model's sensitive parameters are exposed

45
00:01:55,200 --> 00:01:57,899
and since the edge device is untrusted

46
00:01:57,899 --> 00:02:00,960
the inference tasks can be interfered at

47
00:02:00,960 --> 00:02:02,820
the untrusted edge

48
00:02:02,820 --> 00:02:06,000
in some an exciting inference requires

49
00:02:06,000 --> 00:02:08,520
low latency high accuracy with motor

50
00:02:08,520 --> 00:02:10,860
confidentiality and influence Integrity

51
00:02:10,860 --> 00:02:13,400
protection

52
00:02:13,500 --> 00:02:16,200
to protect the offloading Model A

53
00:02:16,200 --> 00:02:18,599
pragmatical approach is to use trusted

54
00:02:18,599 --> 00:02:21,540
execution environment or te to protect

55
00:02:21,540 --> 00:02:23,700
model confidentiality

56
00:02:23,700 --> 00:02:26,879
teas such as Intel sjx and arm trust

57
00:02:26,879 --> 00:02:29,099
Zone use Hardware encryption techniques

58
00:02:29,099 --> 00:02:31,379
to form a secure memory space called

59
00:02:31,379 --> 00:02:33,900
Enclave which provides both data

60
00:02:33,900 --> 00:02:36,000
confident actuality and a code Integrity

61
00:02:36,000 --> 00:02:37,800
guarantees

62
00:02:37,800 --> 00:02:40,680
these are widely used to protect Edge

63
00:02:40,680 --> 00:02:43,739
services for instance Samsung uses trust

64
00:02:43,739 --> 00:02:45,300
loan to store sensitive payment

65
00:02:45,300 --> 00:02:48,900
information trust Sonic uses te to build

66
00:02:48,900 --> 00:02:51,360
iot applications with so-called trusted

67
00:02:51,360 --> 00:02:52,440
UI

68
00:02:52,440 --> 00:02:54,239
or into the prevalence and strong

69
00:02:54,239 --> 00:02:56,640
security guarantees te best security

70
00:02:56,640 --> 00:02:59,099
inference systems are emerging and we

71
00:02:59,099 --> 00:03:00,959
will give more details of these systems

72
00:03:00,959 --> 00:03:02,940
in next pages

73
00:03:02,940 --> 00:03:06,120
although excites can be trusted however

74
00:03:06,120 --> 00:03:09,000
age size third-party gpus are untrusted

75
00:03:09,000 --> 00:03:11,420
by model providers this is because

76
00:03:11,420 --> 00:03:15,300
cputes does not support GPU acceleration

77
00:03:15,300 --> 00:03:17,400
in addition although there are some

78
00:03:17,400 --> 00:03:20,220
promising T integrated trusted GPU

79
00:03:20,220 --> 00:03:22,680
research systems these systems are not

80
00:03:22,680 --> 00:03:24,840
publicly available are they either

81
00:03:24,840 --> 00:03:26,879
require extensive Hardware modifications

82
00:03:26,879 --> 00:03:30,120
or support only Hardware simulators

83
00:03:30,120 --> 00:03:33,599
however GPU is essential for high

84
00:03:33,599 --> 00:03:36,300
performance numerous Edge devices equips

85
00:03:36,300 --> 00:03:39,480
GPU to accelerate Edge intelligence for

86
00:03:39,480 --> 00:03:42,360
example Apple's a15 chip equips four

87
00:03:42,360 --> 00:03:45,120
core GPU Samsung's new mobile processor

88
00:03:45,120 --> 00:03:48,060
includes AMD GPU

89
00:03:48,060 --> 00:03:50,159
we consider an edge side influence

90
00:03:50,159 --> 00:03:52,799
scenario as shown below we'll consider

91
00:03:52,799 --> 00:03:55,260
the model provider to be honest which

92
00:03:55,260 --> 00:03:57,540
means that the model provider provides

93
00:03:57,540 --> 00:03:59,879
the correct model requested by the

94
00:03:59,879 --> 00:04:00,599
client

95
00:04:00,599 --> 00:04:04,920
The Hite is trusted as well however any

96
00:04:04,920 --> 00:04:08,040
components outside the te are untrusted

97
00:04:08,040 --> 00:04:10,379
we also consider an edge side attacker

98
00:04:10,379 --> 00:04:12,360
that tries to steal the sensitive model

99
00:04:12,360 --> 00:04:14,879
parameters and perturb any components

100
00:04:14,879 --> 00:04:17,699
outside the te to modify the inference

101
00:04:17,699 --> 00:04:19,260
results

102
00:04:19,260 --> 00:04:21,180
an ID or Edge side influence system

103
00:04:21,180 --> 00:04:23,340
should meet the performance and security

104
00:04:23,340 --> 00:04:25,979
requirements at the same time

105
00:04:25,979 --> 00:04:28,740
specifically the DNA inference running

106
00:04:28,740 --> 00:04:30,840
on the edge device should be accelerated

107
00:04:30,840 --> 00:04:33,780
with GPU for low latency and the

108
00:04:33,780 --> 00:04:35,880
inference results should retain the same

109
00:04:35,880 --> 00:04:38,340
high accuracy of the originally Trend

110
00:04:38,340 --> 00:04:40,740
model without Precision loss

111
00:04:40,740 --> 00:04:43,500
for security the model parameters plain

112
00:04:43,500 --> 00:04:46,740
text should be hidden last the inference

113
00:04:46,740 --> 00:04:48,600
Integrity requirement captures the

114
00:04:48,600 --> 00:04:50,699
demand that any attacks such as

115
00:04:50,699 --> 00:04:53,040
malicious modifications on inference

116
00:04:53,040 --> 00:04:56,040
results should be detected

117
00:04:56,040 --> 00:04:58,440
existing T based influence systems

118
00:04:58,440 --> 00:05:00,600
include T shielding approach and

119
00:05:00,600 --> 00:05:02,520
partition based approach the first

120
00:05:02,520 --> 00:05:04,560
category will work is the te shielding

121
00:05:04,560 --> 00:05:07,320
approach basically it has four steps

122
00:05:07,320 --> 00:05:10,139
first the model provider attached to the

123
00:05:10,139 --> 00:05:12,479
T equipped Edge device to confirm the T

124
00:05:12,479 --> 00:05:14,280
device is running the correct code

125
00:05:14,280 --> 00:05:16,620
second the server offloads the

126
00:05:16,620 --> 00:05:18,900
encrypting model to Hite and then

127
00:05:18,900 --> 00:05:21,479
decrypt the model third The Edge device

128
00:05:21,479 --> 00:05:24,000
constantly takes client input to Raw

129
00:05:24,000 --> 00:05:26,340
inference purely inside the te and

130
00:05:26,340 --> 00:05:27,900
finally returns the inference result

131
00:05:27,900 --> 00:05:29,699
back to the client

132
00:05:29,699 --> 00:05:32,100
such a simple t-shirting approach has

133
00:05:32,100 --> 00:05:34,380
great advantages including the well

134
00:05:34,380 --> 00:05:36,419
protected motor confidentiality and

135
00:05:36,419 --> 00:05:38,699
inference Integrity because all the

136
00:05:38,699 --> 00:05:41,400
model parameters are hidden in a te even

137
00:05:41,400 --> 00:05:44,160
a privileged Os or hypervisor cannot see

138
00:05:44,160 --> 00:05:45,960
the parameters and perturb the inference

139
00:05:45,960 --> 00:05:48,960
process also it retains High influence

140
00:05:48,960 --> 00:05:51,479
accuracy because no modification has to

141
00:05:51,479 --> 00:05:53,820
be made on the offloading model

142
00:05:53,820 --> 00:05:55,979
however this approach does not

143
00:05:55,979 --> 00:05:58,560
incorporate with GPU acceleration and

144
00:05:58,560 --> 00:06:00,979
runs influence purely within a cput

145
00:06:00,979 --> 00:06:02,940
including extremely high interest

146
00:06:02,940 --> 00:06:05,160
latency this makes this approach

147
00:06:05,160 --> 00:06:07,440
unsuitable for Mission critical AI

148
00:06:07,440 --> 00:06:09,600
applications which requires low latency

149
00:06:09,600 --> 00:06:11,940
interactions

150
00:06:11,940 --> 00:06:13,740
the second category is the

151
00:06:13,740 --> 00:06:15,840
partition-based approach in this

152
00:06:15,840 --> 00:06:18,419
approach a partition strategy from an AI

153
00:06:18,419 --> 00:06:20,460
expert is taking out the system input

154
00:06:20,460 --> 00:06:22,560
the partition strategy divides the

155
00:06:22,560 --> 00:06:25,259
original model into segments it places

156
00:06:25,259 --> 00:06:27,720
sensitive segments into trusted but slow

157
00:06:27,720 --> 00:06:31,080
CPT for confidentiality protection and

158
00:06:31,080 --> 00:06:33,240
puts insensitive segments with other

159
00:06:33,240 --> 00:06:35,039
plain text parameters or retrain

160
00:06:35,039 --> 00:06:36,840
parameters into your own trusted but

161
00:06:36,840 --> 00:06:39,419
fast GPU to accelerate partial inference

162
00:06:39,419 --> 00:06:40,620
computation

163
00:06:40,620 --> 00:06:42,900
apparently by partitioning partial

164
00:06:42,900 --> 00:06:44,880
inference computation to GPU this

165
00:06:44,880 --> 00:06:46,800
approach achieves much lower inference

166
00:06:46,800 --> 00:06:49,080
latency than te shielding approach

167
00:06:49,080 --> 00:06:51,600
however such an approach incurred either

168
00:06:51,600 --> 00:06:53,819
confidentiality loss or accuracy loss

169
00:06:53,819 --> 00:06:56,639
this is because if model parameters with

170
00:06:56,639 --> 00:06:58,380
plant texts are partitioned to an

171
00:06:58,380 --> 00:07:00,660
untrusted GPU they accuracy remains

172
00:07:00,660 --> 00:07:02,819
unchanged but partial confidentiality or

173
00:07:02,819 --> 00:07:05,639
partition model is sacrificed on the

174
00:07:05,639 --> 00:07:07,680
other hand if model parameters are

175
00:07:07,680 --> 00:07:09,479
retrained and then partitioned to the

176
00:07:09,479 --> 00:07:12,060
GPU the confidentiality is protected

177
00:07:12,060 --> 00:07:14,759
because no original parameters will be

178
00:07:14,759 --> 00:07:17,280
revealed but the accuracy drops due to

179
00:07:17,280 --> 00:07:19,919
the training this is a confidentiality

180
00:07:19,919 --> 00:07:22,319
accuracy dilemma besides the

181
00:07:22,319 --> 00:07:24,479
partition-based approach potentially has

182
00:07:24,479 --> 00:07:26,460
integrated risk because some

183
00:07:26,460 --> 00:07:28,139
computations are running outside the te

184
00:07:28,139 --> 00:07:31,280
without protection

185
00:07:31,380 --> 00:07:33,720
we present Slaughter the partition-based

186
00:07:33,720 --> 00:07:35,520
influence system that achieves all

187
00:07:35,520 --> 00:07:37,380
desired properties for each side dealing

188
00:07:37,380 --> 00:07:39,720
influence solder accelerates partial

189
00:07:39,720 --> 00:07:42,180
heavyweight computation with GPU and

190
00:07:42,180 --> 00:07:43,979
retains high accuracy same as the

191
00:07:43,979 --> 00:07:46,199
original model sorter protects a motor

192
00:07:46,199 --> 00:07:48,479
confidentiality by hiding all parameters

193
00:07:48,479 --> 00:07:51,120
plain text meanwhile software detects

194
00:07:51,120 --> 00:07:52,860
any integrative Bridges such as

195
00:07:52,860 --> 00:07:54,900
malicious modifications on inference

196
00:07:54,900 --> 00:07:56,220
results

197
00:07:56,220 --> 00:07:58,380
comparing to existing Edge side deal

198
00:07:58,380 --> 00:08:00,599
Neutron systems software retrieves all

199
00:08:00,599 --> 00:08:03,419
these desired properties simultaneously

200
00:08:03,419 --> 00:08:06,060
to achieve this course Soldier asks two

201
00:08:06,060 --> 00:08:07,139
questions

202
00:08:07,139 --> 00:08:09,660
first how can we utilize untrusted GPU

203
00:08:09,660 --> 00:08:11,520
for acceleration without sacrificing

204
00:08:11,520 --> 00:08:13,979
confidentiality or accuracy

205
00:08:13,979 --> 00:08:16,620
second how can we efficiently detect

206
00:08:16,620 --> 00:08:20,660
integral breaches outside the te

207
00:08:20,699 --> 00:08:22,800
before answering these questions let's

208
00:08:22,800 --> 00:08:24,240
have a recap of dealing mode

209
00:08:24,240 --> 00:08:26,759
architecture a deal model can be

210
00:08:26,759 --> 00:08:28,800
represented as a sequence of connected

211
00:08:28,800 --> 00:08:31,139
layers with each layer assigned a set of

212
00:08:31,139 --> 00:08:32,940
operators assuming the image

213
00:08:32,940 --> 00:08:35,339
classification example below the

214
00:08:35,339 --> 00:08:37,679
operator is either a linear operator or

215
00:08:37,679 --> 00:08:39,719
non-linear operator where a linear

216
00:08:39,719 --> 00:08:41,458
operator is weighted by parameter

217
00:08:41,458 --> 00:08:43,919
matrices during an inference the model

218
00:08:43,919 --> 00:08:45,839
passes an input through layers of

219
00:08:45,839 --> 00:08:47,700
operators to finally output the class

220
00:08:47,700 --> 00:08:49,019
label

221
00:08:49,019 --> 00:08:51,180
dealing operators widely have an

222
00:08:51,180 --> 00:08:54,120
associativity property first all linear

223
00:08:54,120 --> 00:08:56,519
operators such as convolution and fully

224
00:08:56,519 --> 00:08:58,440
connected satisfy this associativity

225
00:08:58,440 --> 00:09:00,480
property as they conduct linear

226
00:09:00,480 --> 00:09:03,480
transformation on the input data also

227
00:09:03,480 --> 00:09:05,640
these linear operators represent a major

228
00:09:05,640 --> 00:09:08,459
fraction of computation in inference

229
00:09:08,459 --> 00:09:11,100
second some non-linear operators such as

230
00:09:11,100 --> 00:09:13,740
relu are scale invariant and thus

231
00:09:13,740 --> 00:09:15,720
satisfy this property under specific

232
00:09:15,720 --> 00:09:16,800
constraints

233
00:09:16,800 --> 00:09:19,440
for example where mu is larger than zero

234
00:09:19,440 --> 00:09:23,660
the following equation always holds

235
00:09:23,760 --> 00:09:25,760
now to answer the first question

236
00:09:25,760 --> 00:09:27,779
recalling that in existing

237
00:09:27,779 --> 00:09:29,880
partition-based systems if we partition

238
00:09:29,880 --> 00:09:31,800
partial model to GPU with plain text

239
00:09:31,800 --> 00:09:34,140
parameters the confidentiality is

240
00:09:34,140 --> 00:09:36,720
sacrificed if we partition partial model

241
00:09:36,720 --> 00:09:39,180
to GPU with retrained parameters the

242
00:09:39,180 --> 00:09:41,940
accuracy of the original model will drop

243
00:09:41,940 --> 00:09:44,399
to bridge this confidentiality accuracy

244
00:09:44,399 --> 00:09:46,560
Gap sorter's key weapon is the general

245
00:09:46,560 --> 00:09:48,420
associativity property of common

246
00:09:48,420 --> 00:09:51,000
inference operators are shown below the

247
00:09:51,000 --> 00:09:53,279
left part of this equation which is the

248
00:09:53,279 --> 00:09:55,200
original model parameters are sensitive

249
00:09:55,200 --> 00:09:57,420
which should be kept secret and are

250
00:09:57,420 --> 00:09:59,519
observable by untrusted Edge side

251
00:09:59,519 --> 00:10:02,160
attackers the meal itself is sensitive

252
00:10:02,160 --> 00:10:04,380
as well because knowing the exact value

253
00:10:04,380 --> 00:10:06,839
of mu will reveal the parameters of the

254
00:10:06,839 --> 00:10:08,040
left part

255
00:10:08,040 --> 00:10:10,440
however the skilled parameters are

256
00:10:10,440 --> 00:10:13,140
insensitive as long as Mu is hidden and

257
00:10:13,140 --> 00:10:14,820
it can be outsourced to GPU for

258
00:10:14,820 --> 00:10:16,320
acceleration

259
00:10:16,320 --> 00:10:18,899
based on this property solder utilizes

260
00:10:18,899 --> 00:10:21,060
GPU to accelerate partial heavyweight

261
00:10:21,060 --> 00:10:23,040
computation while always keeping GPU

262
00:10:23,040 --> 00:10:25,260
operators parameters secret the major

263
00:10:25,260 --> 00:10:28,740
workflow contains four steps first Soto

264
00:10:28,740 --> 00:10:30,660
automatically provides an encrypted

265
00:10:30,660 --> 00:10:33,899
model in Te then solder moves a portion

266
00:10:33,899 --> 00:10:36,180
of associative operators parameters with

267
00:10:36,180 --> 00:10:38,279
scalars hidden in Te

268
00:10:38,279 --> 00:10:40,620
next solder partitions these moves The

269
00:10:40,620 --> 00:10:43,980
Operators to run our GPU last software

270
00:10:43,980 --> 00:10:46,380
executes operators in order transmits

271
00:10:46,380 --> 00:10:48,720
intermediate results between kernels and

272
00:10:48,720 --> 00:10:50,700
finally restores execution results with

273
00:10:50,700 --> 00:10:53,279
hidden scholars in Te

274
00:10:53,279 --> 00:10:55,860
as shown in the right example two linear

275
00:10:55,860 --> 00:10:58,320
operators which are in red are morphed

276
00:10:58,320 --> 00:11:00,660
and partitioned into GPU while the green

277
00:11:00,660 --> 00:11:03,260
radio operator is kept within CPU GE

278
00:11:03,260 --> 00:11:05,940
these three operators take user input

279
00:11:05,940 --> 00:11:08,579
execute metrics computations with most

280
00:11:08,579 --> 00:11:10,680
parameters in order and restore

281
00:11:10,680 --> 00:11:12,779
intermediate results with hidden scalars

282
00:11:12,779 --> 00:11:15,600
in Te this process will iterate until

283
00:11:15,600 --> 00:11:19,140
the final operator is computed

284
00:11:19,140 --> 00:11:21,839
as a partition based system inevitably

285
00:11:21,839 --> 00:11:23,880
open access to integral risks or

286
00:11:23,880 --> 00:11:26,519
partition operators outside the te it is

287
00:11:26,519 --> 00:11:29,279
urgent to detect integrative Bridges to

288
00:11:29,279 --> 00:11:31,320
detect integrative Bridges the stronger

289
00:11:31,320 --> 00:11:33,240
approach could be a recomputing approach

290
00:11:33,240 --> 00:11:35,820
using trusted fingerprints The Trusted

291
00:11:35,820 --> 00:11:37,920
fingerprints is produced inside te

292
00:11:37,920 --> 00:11:40,320
before the influence computation by

293
00:11:40,320 --> 00:11:42,000
generating a random input and

294
00:11:42,000 --> 00:11:43,620
pre-computing the output of a partition

295
00:11:43,620 --> 00:11:46,800
operator inside te the input and output

296
00:11:46,800 --> 00:11:49,320
pair works as a validation code which we

297
00:11:49,320 --> 00:11:51,899
call trusted fingerprints during the

298
00:11:51,899 --> 00:11:54,060
influence by sending a fingerprint input

299
00:11:54,060 --> 00:11:56,519
to the GPU for proof we can compare the

300
00:11:56,519 --> 00:11:58,380
proof inside the te with the

301
00:11:58,380 --> 00:12:01,200
pre-computed fingerprint output enemies

302
00:12:01,200 --> 00:12:03,899
match indicates an Integrity Bridge

303
00:12:03,899 --> 00:12:06,540
however trivially using such an approach

304
00:12:06,540 --> 00:12:09,000
is not feasible because there exists an

305
00:12:09,000 --> 00:12:11,459
obliviousness timelessness Dilemma on

306
00:12:11,459 --> 00:12:13,140
the one hand if we use fixed

307
00:12:13,140 --> 00:12:15,180
fingerprints the adversary can easily

308
00:12:15,180 --> 00:12:17,820
observe them and bypass the detection

309
00:12:17,820 --> 00:12:20,040
on the other hand we if we constantly

310
00:12:20,040 --> 00:12:21,899
generate new fingerprints as regular

311
00:12:21,899 --> 00:12:24,899
user input in cpute fingerprints become

312
00:12:24,899 --> 00:12:27,600
oblivious to observe but the generation

313
00:12:27,600 --> 00:12:30,240
process in cpte becomes a performance

314
00:12:30,240 --> 00:12:32,820
bottleneck leading to slow detection of

315
00:12:32,820 --> 00:12:34,920
Integrative Bridges

316
00:12:34,920 --> 00:12:37,320
solder solves the challenge using the

317
00:12:37,320 --> 00:12:39,420
same associativity observation from

318
00:12:39,420 --> 00:12:41,399
confidentiality protection

319
00:12:41,399 --> 00:12:43,500
we observe the following variant of

320
00:12:43,500 --> 00:12:45,899
linear combination which can be used to

321
00:12:45,899 --> 00:12:47,760
efficiently generate new fingerprints at

322
00:12:47,760 --> 00:12:50,820
runtime specifically there are two steps

323
00:12:50,820 --> 00:12:52,980
in the first step solder prepares

324
00:12:52,980 --> 00:12:55,019
several Cornerstone fingerprints in a

325
00:12:55,019 --> 00:12:57,300
pre-processing phase before inference

326
00:12:57,300 --> 00:12:59,579
during the inference runtime sort of

327
00:12:59,579 --> 00:13:01,920
generates random new Scholars and uses

328
00:13:01,920 --> 00:13:04,200
the debuff associativity variants to

329
00:13:04,200 --> 00:13:06,240
constantly produce new fingerprints in

330
00:13:06,240 --> 00:13:09,380
oblivious manner

331
00:13:09,620 --> 00:13:12,540
by using the same associativity weapon

332
00:13:12,540 --> 00:13:15,000
three key modules running two execution

333
00:13:15,000 --> 00:13:17,339
phases to collectively provide low

334
00:13:17,339 --> 00:13:19,320
latency high accuracy model

335
00:13:19,320 --> 00:13:22,740
confidentiality and integrity protection

336
00:13:22,740 --> 00:13:24,600
the profiler and inference manager

337
00:13:24,600 --> 00:13:26,880
module speeds out model inference with

338
00:13:26,880 --> 00:13:29,040
untrusted GPU while protecting

339
00:13:29,040 --> 00:13:32,339
parameters print text specifically these

340
00:13:32,339 --> 00:13:34,620
two modules automatically profile and

341
00:13:34,620 --> 00:13:36,839
formulate partition plans and high

342
00:13:36,839 --> 00:13:39,060
partition operators parameters with

343
00:13:39,060 --> 00:13:40,800
hidden blending coils

344
00:13:40,800 --> 00:13:43,260
the Integrity monitor module checks

345
00:13:43,260 --> 00:13:45,060
partitional GPU operators execution

346
00:13:45,060 --> 00:13:47,519
results to detect any possible Integrity

347
00:13:47,519 --> 00:13:50,339
breaches these three modules constitute

348
00:13:50,339 --> 00:13:53,459
the whole architecture of sorter

349
00:13:53,459 --> 00:13:55,800
we implemented solder on Python and

350
00:13:55,800 --> 00:13:58,680
graphing sgx but solder is accessible to

351
00:13:58,680 --> 00:14:00,600
any imperative deep learning Frameworks

352
00:14:00,600 --> 00:14:03,480
and te code base we adopted a two-phase

353
00:14:03,480 --> 00:14:05,160
design for offline pre-processing and

354
00:14:05,160 --> 00:14:07,380
online inference we designed a monthly

355
00:14:07,380 --> 00:14:09,120
restore protocol focal operative

356
00:14:09,120 --> 00:14:12,000
executions between kernels we design a

357
00:14:12,000 --> 00:14:13,980
theoretical updating mechanism to

358
00:14:13,980 --> 00:14:16,560
prevent choosing plantex attacks we also

359
00:14:16,560 --> 00:14:18,120
designed an on-demand operator

360
00:14:18,120 --> 00:14:20,459
preferching mechanism to reduce te

361
00:14:20,459 --> 00:14:22,139
memory footprints

362
00:14:22,139 --> 00:14:24,779
for the baselines we evaluated capsular

363
00:14:24,779 --> 00:14:28,019
LG sting and Enclave ml capsule is a

364
00:14:28,019 --> 00:14:30,480
t-shirting approach LG sting and Enclave

365
00:14:30,480 --> 00:14:32,220
are state-of-the-art partition-based

366
00:14:32,220 --> 00:14:34,620
approaches know that the above blue

367
00:14:34,620 --> 00:14:37,260
optimization is also Incorporated in a

368
00:14:37,260 --> 00:14:39,839
three-based lines for the evaluation we

369
00:14:39,839 --> 00:14:42,660
run all experiments in our classroom we

370
00:14:42,660 --> 00:14:44,339
use a server with real sdx Hardware

371
00:14:44,339 --> 00:14:47,459
sport we used a GPU form with Nvidia

372
00:14:47,459 --> 00:14:50,279
gpus each GPU had 11 gigabyte physical

373
00:14:50,279 --> 00:14:53,579
memory we evaluated six prevalent deals

374
00:14:53,579 --> 00:14:55,560
covering both computer vision and

375
00:14:55,560 --> 00:14:59,180
natural language processing tasks

376
00:14:59,339 --> 00:15:01,800
we asked the following questions first

377
00:15:01,800 --> 00:15:03,779
how is solder's end-to-end performance

378
00:15:03,779 --> 00:15:06,600
compared to best lines second how is

379
00:15:06,600 --> 00:15:08,160
solder's confidentiality protection

380
00:15:08,160 --> 00:15:11,100
compared to best lines third assaulters

381
00:15:11,100 --> 00:15:12,839
trusted fingerprint oblivious to the

382
00:15:12,839 --> 00:15:15,420
adversary outside the te last how

383
00:15:15,420 --> 00:15:17,339
sensitive is Soldier's performance to

384
00:15:17,339 --> 00:15:19,740
different partition ratio we will report

385
00:15:19,740 --> 00:15:23,220
the top three questions in next slides

386
00:15:23,220 --> 00:15:25,560
for the end-to-end performance Figure 1

387
00:15:25,560 --> 00:15:27,660
shows the inference latency which is

388
00:15:27,660 --> 00:15:29,820
normalized to insecurity field inference

389
00:15:29,820 --> 00:15:31,860
compared to three baselines running 6

390
00:15:31,860 --> 00:15:34,740
prevent DM models solder achieved one

391
00:15:34,740 --> 00:15:36,420
times to four times lower Universe

392
00:15:36,420 --> 00:15:38,760
latency than T shirting Baseline ml

393
00:15:38,760 --> 00:15:41,699
capsule a solder securely utilizes GPU

394
00:15:41,699 --> 00:15:43,500
to accelerate partial heavy weight

395
00:15:43,500 --> 00:15:45,540
influence computations including the

396
00:15:45,540 --> 00:15:47,220
convolution and fully connected

397
00:15:47,220 --> 00:15:48,480
operators

398
00:15:48,480 --> 00:15:50,760
and even sorter pays additional effort

399
00:15:50,760 --> 00:15:53,399
to enforce Integrity protection solder

400
00:15:53,399 --> 00:15:55,260
incurred only moderate overhead than

401
00:15:55,260 --> 00:15:59,420
partition based Baseline hsdm

402
00:15:59,880 --> 00:16:01,980
even if sort of completely hides

403
00:16:01,980 --> 00:16:04,019
partition operators plantex and

404
00:16:04,019 --> 00:16:06,000
adversary may still conduct model steam

405
00:16:06,000 --> 00:16:07,800
attacks to train a substitute model

406
00:16:07,800 --> 00:16:10,560
hence we run model steaming attacks on

407
00:16:10,560 --> 00:16:12,959
all baselines and use the accuracy and

408
00:16:12,959 --> 00:16:15,540
Blu score as a metric to evaluate the

409
00:16:15,540 --> 00:16:16,920
confidentiality

410
00:16:16,920 --> 00:16:19,380
figure 2 shows the accuracy and Bru

411
00:16:19,380 --> 00:16:21,420
score over the trend substitute model

412
00:16:21,420 --> 00:16:24,420
note that the higher accuracy of BYU

413
00:16:24,420 --> 00:16:26,760
score of a substitute model means more

414
00:16:26,760 --> 00:16:28,620
confidentiality loss

415
00:16:28,620 --> 00:16:31,199
solder achieved stronger confidentiality

416
00:16:31,199 --> 00:16:34,079
protection than Aegis Dune which implies

417
00:16:34,079 --> 00:16:36,300
that moving operators by scaling its

418
00:16:36,300 --> 00:16:37,980
parameters has significant model

419
00:16:37,980 --> 00:16:40,920
information compared to hsdn which

420
00:16:40,920 --> 00:16:42,480
directly partitions model parameters

421
00:16:42,480 --> 00:16:45,300
plain text to untrusted GPU

422
00:16:45,300 --> 00:16:47,639
meanwhile Sota achieved the same strong

423
00:16:47,639 --> 00:16:49,920
confidentiality protection as Enclave

424
00:16:49,920 --> 00:16:52,320
will Enclave sacrifices influence

425
00:16:52,320 --> 00:16:54,720
accuracy because Enclave transparation

426
00:16:54,720 --> 00:16:56,519
model parameters to hide the original

427
00:16:56,519 --> 00:16:58,740
operators parameters on the untrusted

428
00:16:58,740 --> 00:16:59,820
GPU

429
00:16:59,820 --> 00:17:02,579
to validate the Integrity protection We

430
00:17:02,579 --> 00:17:04,380
compare sorters of Olivia's fingerprint

431
00:17:04,380 --> 00:17:07,020
with a strong fixed fingerprint approach

432
00:17:07,020 --> 00:17:08,939
figure 3 shoots that solder's

433
00:17:08,939 --> 00:17:10,619
fingerprints are oblivious to the

434
00:17:10,619 --> 00:17:12,839
adversary because the L2 distance

435
00:17:12,839 --> 00:17:15,359
distribution of fingerprints shares the

436
00:17:15,359 --> 00:17:17,400
same form of normal distribution as

437
00:17:17,400 --> 00:17:20,160
client's normal query input while the L2

438
00:17:20,160 --> 00:17:22,260
distance distribution of fixed

439
00:17:22,260 --> 00:17:24,359
fingerprints does not share the form of

440
00:17:24,359 --> 00:17:26,699
normal distribution

441
00:17:26,699 --> 00:17:29,460
to conclude in this paper we present

442
00:17:29,460 --> 00:17:31,919
solder the first work that achieves

443
00:17:31,919 --> 00:17:34,679
modal confidentiality low latency and

444
00:17:34,679 --> 00:17:36,900
high accuracy with Integrity protection

445
00:17:36,900 --> 00:17:39,660
for General new network inference solder

446
00:17:39,660 --> 00:17:40,740
achieves comparable strong

447
00:17:40,740 --> 00:17:43,260
confidentiality as T schroding approach

448
00:17:43,260 --> 00:17:45,600
comparable low latency as partition

449
00:17:45,600 --> 00:17:48,299
based approach high accuracy same as

450
00:17:48,299 --> 00:17:50,940
insecure GPU inference and overwhelming

451
00:17:50,940 --> 00:17:52,980
high probability of obliviously

452
00:17:52,980 --> 00:17:55,740
detecting interrogative breaches these

453
00:17:55,740 --> 00:17:57,900
features encourage giant companies to

454
00:17:57,900 --> 00:18:00,000
develop powerful models and deploy them

455
00:18:00,000 --> 00:18:02,580
on third-party Edge devices meanwhile

456
00:18:02,580 --> 00:18:04,799
solder can also help with protecting

457
00:18:04,799 --> 00:18:07,500
models on untrusted cloud servers

458
00:18:07,500 --> 00:18:10,080
solder's future work is brought software

459
00:18:10,080 --> 00:18:11,940
can integrate with emerging black boss

460
00:18:11,940 --> 00:18:14,160
defenses to further strengthen its

461
00:18:14,160 --> 00:18:16,980
privacy guarantees also software can be

462
00:18:16,980 --> 00:18:19,559
extended to multiple gpus and tees for

463
00:18:19,559 --> 00:18:21,660
Distributing model influence

464
00:18:21,660 --> 00:18:24,120
solder's artifact is available on our

465
00:18:24,120 --> 00:18:26,940
group's website thank you that's all for

466
00:18:26,940 --> 00:18:28,980
my presentation and I'm happy to take

467
00:18:28,980 --> 00:18:31,640
questions now

