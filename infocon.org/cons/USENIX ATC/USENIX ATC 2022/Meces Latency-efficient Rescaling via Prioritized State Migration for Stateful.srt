1
00:00:14,240 --> 00:00:16,880
hello everyone i'm rongo for london

2
00:00:16,880 --> 00:00:19,359
university it's quite a great honor to

3
00:00:19,359 --> 00:00:22,160
be here to present our work it is titled

4
00:00:22,160 --> 00:00:24,720
max's latency efficiently scaling web

5
00:00:24,720 --> 00:00:26,720
for organized integration for

6
00:00:26,720 --> 00:00:28,320
state-of-the-art distributed stream

7
00:00:28,320 --> 00:00:31,039
processing systems this work is joined

8
00:00:31,039 --> 00:00:34,320
to down by rongo hanging with chan zhong

9
00:00:34,320 --> 00:00:36,480
cheong fong yuan and iwang from london

10
00:00:36,480 --> 00:00:38,079
university

11
00:00:38,079 --> 00:00:40,160
in recent 30 years stanford stream

12
00:00:40,160 --> 00:00:43,840
processing engines or shows as xpe's

13
00:00:43,840 --> 00:00:45,600
been widely adopted because of the

14
00:00:45,600 --> 00:00:47,600
increasing demands for complicated

15
00:00:47,600 --> 00:00:50,160
analytics over real-time data

16
00:00:50,160 --> 00:00:53,039
for example the threat detection logo

17
00:00:53,039 --> 00:00:54,079
monitoring

18
00:00:54,079 --> 00:00:56,160
sentimental analysis and iot

19
00:00:56,160 --> 00:00:58,719
applications

20
00:00:58,719 --> 00:01:02,640
spes are expected to be long running and

21
00:01:02,640 --> 00:01:05,119
always and always have no latency its

22
00:01:05,119 --> 00:01:06,320
performance

23
00:01:06,320 --> 00:01:09,280
therefore it commonly requires speeds to

24
00:01:09,280 --> 00:01:11,920
perform dynamic discovery in the face

25
00:01:11,920 --> 00:01:14,640
because of unpredictable circumstances

26
00:01:14,640 --> 00:01:15,840
for example

27
00:01:15,840 --> 00:01:18,000
the data rate of fluctuation

28
00:01:18,000 --> 00:01:19,520
machine failures

29
00:01:19,520 --> 00:01:21,759
processing stragglers

30
00:01:21,759 --> 00:01:23,040
and so on

31
00:01:23,040 --> 00:01:25,360
however as a processing

32
00:01:25,360 --> 00:01:28,000
in spe are usually therefore in a

33
00:01:28,000 --> 00:01:30,240
partition across network

34
00:01:30,240 --> 00:01:32,960
workers rescaling them calls for system

35
00:01:32,960 --> 00:01:35,040
migration which means

36
00:01:35,040 --> 00:01:36,880
moving state between data between

37
00:01:36,880 --> 00:01:40,720
workers even across networks

38
00:01:40,720 --> 00:01:43,680
prior major advancement in this area in

39
00:01:43,680 --> 00:01:45,600
after decades can manage it be

40
00:01:45,600 --> 00:01:47,840
classified into four decades or sorry

41
00:01:47,840 --> 00:01:49,520
four categories

42
00:01:49,520 --> 00:01:51,920
the first one is the

43
00:01:51,920 --> 00:01:54,479
full restart approach it pauses and a

44
00:01:54,479 --> 00:01:57,360
regret resumes the whole task when it is

45
00:01:57,360 --> 00:01:58,960
union states

46
00:01:58,960 --> 00:02:01,119
the second one is the partial post

47
00:02:01,119 --> 00:02:03,840
approach it restarts a subgraph instead

48
00:02:03,840 --> 00:02:05,759
of the whole job technology to reduce

49
00:02:05,759 --> 00:02:07,840
the extreme blocking

50
00:02:07,840 --> 00:02:09,199
oil however

51
00:02:09,199 --> 00:02:10,720
both approaches

52
00:02:10,720 --> 00:02:13,440
that block the processing of spe they

53
00:02:13,440 --> 00:02:15,599
usually cause latent spikes during the

54
00:02:15,599 --> 00:02:17,760
scaling periods

55
00:02:17,760 --> 00:02:20,319
the third kind of

56
00:02:20,319 --> 00:02:22,080
approach is called a replicated dead

57
00:02:22,080 --> 00:02:23,280
flow approach

58
00:02:23,280 --> 00:02:26,080
it excuse a new dead flow imperial with

59
00:02:26,080 --> 00:02:27,680
the older one until finishing the state

60
00:02:27,680 --> 00:02:29,120
of migration

61
00:02:29,120 --> 00:02:31,360
therefore it usually results in high

62
00:02:31,360 --> 00:02:34,319
resource usages during scaling

63
00:02:34,319 --> 00:02:36,400
the last category is called a proactive

64
00:02:36,400 --> 00:02:39,440
approach it adds extra behavior to land

65
00:02:39,440 --> 00:02:41,519
scaling stream processing periods to

66
00:02:41,519 --> 00:02:43,519
relieve the pressure during state

67
00:02:43,519 --> 00:02:44,959
migration

68
00:02:44,959 --> 00:02:47,120
it can smooth the latency curve during

69
00:02:47,120 --> 00:02:49,840
scaling but due to this is design it can

70
00:02:49,840 --> 00:02:50,959
lead to

71
00:02:50,959 --> 00:02:54,000
in increased extra overhead to a long

72
00:02:54,000 --> 00:02:57,200
non-skilling dead flow

73
00:02:57,519 --> 00:03:00,160
in conclusion existing state migration

74
00:03:00,160 --> 00:03:03,040
approaches suffer latency spikes or high

75
00:03:03,040 --> 00:03:07,679
resource usages or major disruptions

76
00:03:07,760 --> 00:03:10,480
as discussed in this paper existing

77
00:03:10,480 --> 00:03:12,720
approaches common limitations lie in

78
00:03:12,720 --> 00:03:15,040
other unaware state migration

79
00:03:15,040 --> 00:03:17,440
that's it to say they do not take into

80
00:03:17,440 --> 00:03:19,280
account the order in which

81
00:03:19,280 --> 00:03:22,480
operator state migrates

82
00:03:22,640 --> 00:03:25,440
here we use an example to illustrate how

83
00:03:25,440 --> 00:03:27,840
the migration orders affects spe latency

84
00:03:27,840 --> 00:03:30,159
performance during scaling

85
00:03:30,159 --> 00:03:32,400
we take a representative stateful stream

86
00:03:32,400 --> 00:03:35,519
processing drop kick as an example

87
00:03:35,519 --> 00:03:37,599
where the record with random keys come

88
00:03:37,599 --> 00:03:41,120
from upstream and are processed by spe

89
00:03:41,120 --> 00:03:44,000
in a fifo manner unless the first come

90
00:03:44,000 --> 00:03:47,200
in first out manner in this case stream

91
00:03:47,200 --> 00:03:49,360
operators store and the count

92
00:03:49,360 --> 00:03:51,280
value of each key as the corresponding

93
00:03:51,280 --> 00:03:52,159
states

94
00:03:52,159 --> 00:03:55,120
now during the scaling c1 these two

95
00:03:55,120 --> 00:03:59,280
migrates keys 1 2 3 to c3

96
00:03:59,280 --> 00:04:02,000
so practice of processing and affect the

97
00:04:02,000 --> 00:04:04,239
operator needs to receive the migrated

98
00:04:04,239 --> 00:04:06,319
states which are the global counter

99
00:04:06,319 --> 00:04:08,959
value of the keys before it can process

100
00:04:08,959 --> 00:04:13,120
the corresponding income records

101
00:04:13,519 --> 00:04:16,000
if the states are migrated in an

102
00:04:16,000 --> 00:04:18,798
aware manner the first coming record may

103
00:04:18,798 --> 00:04:21,120
not be processed in time

104
00:04:21,120 --> 00:04:23,280
because it needs to wait for the arrival

105
00:04:23,280 --> 00:04:25,840
of its corresponding state

106
00:04:25,840 --> 00:04:28,240
this also blocks subsequent records in

107
00:04:28,240 --> 00:04:30,800
the queue due to the fifa processing

108
00:04:30,800 --> 00:04:33,199
eventually it will accumulate the

109
00:04:33,199 --> 00:04:35,840
processing latency for all records over

110
00:04:35,840 --> 00:04:38,639
a period of time

111
00:04:38,639 --> 00:04:41,199
in the worst case as shown in subsequent

112
00:04:41,199 --> 00:04:42,800
b here

113
00:04:42,800 --> 00:04:45,040
the state of the first record is not so

114
00:04:45,040 --> 00:04:47,120
long to migrate it

115
00:04:47,120 --> 00:04:49,520
blocking all record processing before

116
00:04:49,520 --> 00:04:52,320
the scan declaration is finished

117
00:04:52,320 --> 00:04:55,759
ideally as we show in sub figure c here

118
00:04:55,759 --> 00:04:57,919
states are migrated in exactly the same

119
00:04:57,919 --> 00:05:00,880
order as the records arrived therefore

120
00:05:00,880 --> 00:05:03,040
minimum time is spent in waiting queue

121
00:05:03,040 --> 00:05:04,720
in the waiting queue and the latency can

122
00:05:04,720 --> 00:05:07,840
be gradually reduced

123
00:05:09,600 --> 00:05:12,160
from this observation we can find that

124
00:05:12,160 --> 00:05:14,000
when online

125
00:05:14,000 --> 00:05:16,240
migrating states in spe

126
00:05:16,240 --> 00:05:19,039
there are actual hotkeys which refers to

127
00:05:19,039 --> 00:05:22,320
the keys that a lot are being processed

128
00:05:22,320 --> 00:05:25,120
or about to be processed by downstream

129
00:05:25,120 --> 00:05:26,800
operators tasks

130
00:05:26,800 --> 00:05:29,840
we find that the state of hotkeys

131
00:05:29,840 --> 00:05:32,560
need to be proactivelized so that the

132
00:05:32,560 --> 00:05:34,240
stream processing proceeds without

133
00:05:34,240 --> 00:05:36,720
blocking

134
00:05:37,360 --> 00:05:39,440
and based on that in this paper you

135
00:05:39,440 --> 00:05:42,400
propose nexus an on the fly with steel

136
00:05:42,400 --> 00:05:44,639
mechanism which enables prior autonomous

137
00:05:44,639 --> 00:05:47,120
state migration for spees

138
00:05:47,120 --> 00:05:48,560
to achieve that

139
00:05:48,560 --> 00:05:51,919
one change is to dynamically adjusted

140
00:05:51,919 --> 00:05:53,520
the state of migration order according

141
00:05:53,520 --> 00:05:55,840
to the incoming records during spec

142
00:05:55,840 --> 00:05:57,840
scaling

143
00:05:57,840 --> 00:06:00,160
to address this address this issue

144
00:06:00,160 --> 00:06:02,240
nexus leverages a fashion demand

145
00:06:02,240 --> 00:06:05,280
statement essays model

146
00:06:05,280 --> 00:06:07,360
during this gallery the state can be

147
00:06:07,360 --> 00:06:09,520
actively featured by sp operator

148
00:06:09,520 --> 00:06:11,919
instance when receiving a data recorder

149
00:06:11,919 --> 00:06:14,400
who steady local

150
00:06:14,400 --> 00:06:16,479
another challenge is to maintain the

151
00:06:16,479 --> 00:06:19,039
state consistency during the

152
00:06:19,039 --> 00:06:21,919
prioritized migration process

153
00:06:21,919 --> 00:06:24,560
therefore inspired by privileges works

154
00:06:24,560 --> 00:06:28,080
in maxis we use a coordination protocol

155
00:06:28,080 --> 00:06:31,840
based on controller messages

156
00:06:32,080 --> 00:06:35,440
next we use an example of a scale out

157
00:06:35,440 --> 00:06:37,919
operation of a string key counter drop

158
00:06:37,919 --> 00:06:40,000
to illustrate the above design for the

159
00:06:40,000 --> 00:06:42,880
scaling periods in maxis

160
00:06:42,880 --> 00:06:44,479
in this example

161
00:06:44,479 --> 00:06:47,280
the degree of parallelism of the kick

162
00:06:47,280 --> 00:06:50,080
of the count operator increases from 2

163
00:06:50,080 --> 00:06:52,080
to 3.

164
00:06:52,080 --> 00:06:54,560
for simplicity we assume the keys are

165
00:06:54,560 --> 00:06:57,440
between 1 and 12.

166
00:06:57,440 --> 00:06:59,520
therefore based on the uniform

167
00:06:59,520 --> 00:07:01,759
distribution the distribution of the key

168
00:07:01,759 --> 00:07:04,160
space before and after the scaling is

169
00:07:04,160 --> 00:07:07,199
shown in the right subfigure

170
00:07:07,199 --> 00:07:08,800
we call the time period from the

171
00:07:08,800 --> 00:07:11,120
beginning to the end of the stated

172
00:07:11,120 --> 00:07:16,280
distribution as a migration stage

173
00:07:16,639 --> 00:07:20,000
the global controller of spe starts at

174
00:07:20,000 --> 00:07:22,800
the different stage by injection and by

175
00:07:22,800 --> 00:07:24,960
injecting a special data record called

176
00:07:24,960 --> 00:07:27,440
the controller message into the source

177
00:07:27,440 --> 00:07:29,680
operates

178
00:07:29,680 --> 00:07:31,919
the message then travels through the

179
00:07:31,919 --> 00:07:33,919
whole power line in the same way as the

180
00:07:33,919 --> 00:07:35,840
regulated record

181
00:07:35,840 --> 00:07:38,560
when s1 or sq receives the control

182
00:07:38,560 --> 00:07:39,759
messages

183
00:07:39,759 --> 00:07:42,000
it updates the routine strategies and

184
00:07:42,000 --> 00:07:44,800
outputs the subsequent data records in

185
00:07:44,800 --> 00:07:47,440
accordance with the new terminology

186
00:07:47,440 --> 00:07:50,160
as this downstream of price degree

187
00:07:50,160 --> 00:07:52,560
apparently increased by 1 its news

188
00:07:52,560 --> 00:07:54,080
strategy

189
00:07:54,080 --> 00:07:56,080
divides the key space into three parts

190
00:07:56,080 --> 00:07:57,120
equally

191
00:07:57,120 --> 00:08:01,199
we can see the the demonstration here

192
00:08:06,960 --> 00:08:08,080
okay

193
00:08:08,080 --> 00:08:09,919
other shoe here the direction of the map

194
00:08:09,919 --> 00:08:12,560
to lie will probably the center to b but

195
00:08:12,560 --> 00:08:13,520
it will be

196
00:08:13,520 --> 00:08:17,360
bishop to the new inside c for not all

197
00:08:17,360 --> 00:08:20,879
meanwhile the record with key six

198
00:08:20,879 --> 00:08:23,759
which were consumed by a should then be

199
00:08:23,759 --> 00:08:28,000
in charge of b be within the charge of b

200
00:08:29,599 --> 00:08:32,399
other for the c can't operate in general

201
00:08:32,399 --> 00:08:34,640
the states are sent from the previously

202
00:08:34,640 --> 00:08:36,719
responsible instance but the newly

203
00:08:36,719 --> 00:08:38,320
responsible instance

204
00:08:38,320 --> 00:08:40,640
also active phase states in response to

205
00:08:40,640 --> 00:08:42,799
the incoming data records

206
00:08:42,799 --> 00:08:45,920
taking b as an example when b first

207
00:08:45,920 --> 00:08:48,480
receives a control message such as from

208
00:08:48,480 --> 00:08:51,519
s2 it can foresee the arrival of the

209
00:08:51,519 --> 00:08:54,640
keys that did not belong to it before

210
00:08:54,640 --> 00:08:55,760
after that

211
00:08:55,760 --> 00:08:58,160
when b encounter around the fourth key

212
00:08:58,160 --> 00:09:01,440
is not a local such as key six

213
00:09:01,440 --> 00:09:03,519
we borrow the corresponding state of

214
00:09:03,519 --> 00:09:05,519
this key from other current operating

215
00:09:05,519 --> 00:09:08,399
instance to complete the processing we

216
00:09:08,399 --> 00:09:11,440
can see the demo here

217
00:09:14,720 --> 00:09:16,240
okay

218
00:09:16,240 --> 00:09:18,800
note that

219
00:09:18,800 --> 00:09:20,880
in this phase

220
00:09:20,880 --> 00:09:24,160
the message from s1 has not reached b

221
00:09:24,160 --> 00:09:26,160
which means a may still have to deal

222
00:09:26,160 --> 00:09:28,800
with record with key six

223
00:09:28,800 --> 00:09:31,120
because of that we should also be

224
00:09:31,120 --> 00:09:32,800
prepared that

225
00:09:32,800 --> 00:09:35,440
a state of six can still be pulled back

226
00:09:35,440 --> 00:09:37,839
by others

227
00:09:39,680 --> 00:09:42,720
the migration for b is aligned once it

228
00:09:42,720 --> 00:09:44,959
receives control message from all of its

229
00:09:44,959 --> 00:09:47,760
input channels

230
00:09:47,920 --> 00:09:51,800
we can see the demo here

231
00:09:52,959 --> 00:09:55,040
okay in this situation

232
00:09:55,040 --> 00:09:56,800
it is the guarantee that

233
00:09:56,800 --> 00:10:00,000
all future records with key 5 and the

234
00:10:00,000 --> 00:10:03,440
key 6 are shipped only to b and b will

235
00:10:03,440 --> 00:10:05,839
no longer receive records with keys from

236
00:10:05,839 --> 00:10:08,240
9 to 12.

237
00:10:08,240 --> 00:10:10,000
therefore biggest start is state

238
00:10:10,000 --> 00:10:11,600
immigration

239
00:10:11,600 --> 00:10:14,000
in the sense the state between 9 and 12

240
00:10:14,000 --> 00:10:16,079
to other instances and the such form

241
00:10:16,079 --> 00:10:19,479
states in

242
00:10:20,640 --> 00:10:23,680
a synchronized

243
00:10:23,839 --> 00:10:26,560
when finishing sending and fetching b

244
00:10:26,560 --> 00:10:28,480
stands for the complete completion

245
00:10:28,480 --> 00:10:33,040
signal of this migration stage

246
00:10:33,040 --> 00:10:35,760
in the above process we can maintain

247
00:10:35,760 --> 00:10:38,160
exact one schematics during regression

248
00:10:38,160 --> 00:10:39,279
stage

249
00:10:39,279 --> 00:10:42,000
and the stream processing operators keep

250
00:10:42,000 --> 00:10:43,839
functioning without explicitly blocking

251
00:10:43,839 --> 00:10:47,200
the input channels

252
00:10:47,200 --> 00:10:50,000
in addition as a fetch on demand mode of

253
00:10:50,000 --> 00:10:52,959
code for lighter weight status section

254
00:10:52,959 --> 00:10:55,519
we also designed for fine grained state

255
00:10:55,519 --> 00:10:57,279
transmission

256
00:10:57,279 --> 00:10:58,640
in access

257
00:10:58,640 --> 00:11:01,760
during scaling we further divide each

258
00:11:01,760 --> 00:11:04,399
key group into multiple subgroups

259
00:11:04,399 --> 00:11:06,640
when encountering a ref record that

260
00:11:06,640 --> 00:11:08,560
requires a remote state

261
00:11:08,560 --> 00:11:10,480
and instance it tries to fetch the

262
00:11:10,480 --> 00:11:13,279
corresponding subgroup of the record key

263
00:11:13,279 --> 00:11:16,480
instead of the entire key group

264
00:11:16,480 --> 00:11:19,600
this reduces the overhead used to

265
00:11:19,600 --> 00:11:22,000
obtain the data that is not needed

266
00:11:22,000 --> 00:11:24,560
immediately

267
00:11:25,120 --> 00:11:27,440
we also achieve fine grading to the

268
00:11:27,440 --> 00:11:29,360
migration we have gradual migration

269
00:11:29,360 --> 00:11:32,320
strategy which splits the update into

270
00:11:32,320 --> 00:11:36,880
several micro batches of state migration

271
00:11:37,200 --> 00:11:39,680
so the signal migration stage is split

272
00:11:39,680 --> 00:11:42,560
into several virtual phase stages

273
00:11:42,560 --> 00:11:45,600
in this way we affect only a tiny

274
00:11:45,600 --> 00:11:48,079
proportion of the entire

275
00:11:48,079 --> 00:11:49,680
states at the e

276
00:11:49,680 --> 00:11:52,399
at each gradual phase stage state

277
00:11:52,399 --> 00:11:53,920
where most of the records can be

278
00:11:53,920 --> 00:11:57,399
processed normally

279
00:11:58,160 --> 00:12:00,480
we implement the max test on top of the

280
00:12:00,480 --> 00:12:03,600
mainstream of mainstream open source spe

281
00:12:03,600 --> 00:12:07,279
which is called apache flint

282
00:12:07,279 --> 00:12:09,600
max is implemented without affecting

283
00:12:09,600 --> 00:12:11,279
non-skilled periods

284
00:12:11,279 --> 00:12:13,040
the online state management and

285
00:12:13,040 --> 00:12:15,839
migration in sp runtime are completely

286
00:12:15,839 --> 00:12:18,000
transparent to user codes

287
00:12:18,000 --> 00:12:20,480
therefore it takes minimal effort to

288
00:12:20,480 --> 00:12:21,839
switch between

289
00:12:21,839 --> 00:12:23,440
links and max's statement

290
00:12:23,440 --> 00:12:26,240
implementations

291
00:12:26,240 --> 00:12:27,040
we

292
00:12:27,040 --> 00:12:29,519
evaluated the latency performance of spe

293
00:12:29,519 --> 00:12:31,040
student scaling

294
00:12:31,040 --> 00:12:34,480
we compare maxes with a native flink

295
00:12:34,480 --> 00:12:36,480
which stops the whole job when we

296
00:12:36,480 --> 00:12:37,680
scaling

297
00:12:37,680 --> 00:12:40,560
an old unaware which is online

298
00:12:40,560 --> 00:12:42,959
block-based data migration without other

299
00:12:42,959 --> 00:12:45,600
prior authorization

300
00:12:45,600 --> 00:12:48,880
on the keycard job both native flink and

301
00:12:48,880 --> 00:12:51,519
other artwork show a latency peak

302
00:12:51,519 --> 00:12:54,240
when a which is three orders magnitude

303
00:12:54,240 --> 00:12:56,720
higher than you

304
00:12:56,720 --> 00:12:59,440
the legend decreases gradually after the

305
00:12:59,440 --> 00:13:02,160
restarting of migration companies

306
00:13:02,160 --> 00:13:05,440
and from access it keeps an agency under

307
00:13:05,440 --> 00:13:07,839
600 milliseconds during the

308
00:13:07,839 --> 00:13:10,720
migration stage

309
00:13:11,680 --> 00:13:13,920
we further evaluated

310
00:13:13,920 --> 00:13:16,320
on the real-world net mark benchmark

311
00:13:16,320 --> 00:13:17,920
field

312
00:13:17,920 --> 00:13:19,760
similar conclusion can be drawn from the

313
00:13:19,760 --> 00:13:20,720
result

314
00:13:20,720 --> 00:13:22,800
next let's lower the latency peak by

315
00:13:22,800 --> 00:13:25,839
orders of magnitude

316
00:13:25,920 --> 00:13:28,320
we also report the latency breakdown of

317
00:13:28,320 --> 00:13:29,200
access

318
00:13:29,200 --> 00:13:31,279
compared with the old unaware the

319
00:13:31,279 --> 00:13:34,160
latency peak in maxis is gradually

320
00:13:34,160 --> 00:13:38,320
reduced to less than 400 milliseconds

321
00:13:38,320 --> 00:13:40,560
this is because when max's nuclear

322
00:13:40,560 --> 00:13:44,399
states are shown in fixed c here

323
00:13:44,399 --> 00:13:46,480
the serial long duration exclusion

324
00:13:46,480 --> 00:13:48,480
blocks caused by

325
00:13:48,480 --> 00:13:50,959
negligent costs are converted into

326
00:13:50,959 --> 00:13:52,240
thousands of

327
00:13:52,240 --> 00:13:54,959
short-duration phase operations

328
00:13:54,959 --> 00:13:56,079
therefore

329
00:13:56,079 --> 00:13:58,639
in nexus although the sum

330
00:13:58,639 --> 00:14:00,720
of the migration costs

331
00:14:00,720 --> 00:14:02,880
does not differ much

332
00:14:02,880 --> 00:14:06,240
for two for for two strategies

333
00:14:06,240 --> 00:14:09,440
each record indeed does not have to wait

334
00:14:09,440 --> 00:14:11,920
for long for itself to be negated

335
00:14:11,920 --> 00:14:13,120
eventually

336
00:14:13,120 --> 00:14:15,760
we can reduce the queuing cost and

337
00:14:15,760 --> 00:14:19,920
flatten the overall latency curve

338
00:14:20,399 --> 00:14:22,639
further we compare max's with some sort

339
00:14:22,639 --> 00:14:24,000
of works

340
00:14:24,000 --> 00:14:26,240
first we implement the maxphone's state

341
00:14:26,240 --> 00:14:28,800
migration mechanism on flink along with

342
00:14:28,800 --> 00:14:29,440
a

343
00:14:29,440 --> 00:14:31,279
simplified version of microphone spread

344
00:14:31,279 --> 00:14:34,320
across of spe

345
00:14:34,320 --> 00:14:36,959
this extra freeze calls for

346
00:14:36,959 --> 00:14:38,160
extra

347
00:14:38,160 --> 00:14:40,800
uh synchronization and communication

348
00:14:40,800 --> 00:14:41,839
therefore

349
00:14:41,839 --> 00:14:44,720
when not only scaling max link shows an

350
00:14:44,720 --> 00:14:46,480
order of magnitude high latency name

351
00:14:46,480 --> 00:14:47,519
axis

352
00:14:47,519 --> 00:14:49,920
during steering both systems show a

353
00:14:49,920 --> 00:14:52,560
limited amount of latency increase

354
00:14:52,560 --> 00:14:55,120
however the latency of microphones stay

355
00:14:55,120 --> 00:14:58,320
at the level around

356
00:14:58,320 --> 00:15:00,800
8 000 milliseconds

357
00:15:00,800 --> 00:15:03,040
while max has never reached the bar of

358
00:15:03,040 --> 00:15:06,079
1000 milliseconds

359
00:15:06,079 --> 00:15:09,199
next for a fair comparison with rhino

360
00:15:09,199 --> 00:15:10,959
we implemented the mechanism of rhino

361
00:15:10,959 --> 00:15:13,199
based on flink

362
00:15:13,199 --> 00:15:16,240
on a key kind of job run on fling shows

363
00:15:16,240 --> 00:15:20,000
a similar latency peak to

364
00:15:20,000 --> 00:15:23,279
older owner whose peak is nearly 10 000

365
00:15:23,279 --> 00:15:24,720
milliseconds

366
00:15:24,720 --> 00:15:27,920
as a comparison the prerequisite latency

367
00:15:27,920 --> 00:15:29,920
of nexus never reaches

368
00:15:29,920 --> 00:15:31,199
1000

369
00:15:31,199 --> 00:15:33,440
milliseconds during the whole process

370
00:15:33,440 --> 00:15:34,320
also

371
00:15:34,320 --> 00:15:37,680
rhino calls for extra network overhead

372
00:15:37,680 --> 00:15:41,680
when the job is not scaling while

373
00:15:41,680 --> 00:15:44,639
maxis includes low network overhead to

374
00:15:44,639 --> 00:15:48,079
land scaling stream processing

375
00:15:48,079 --> 00:15:49,519
in conclusion

376
00:15:49,519 --> 00:15:51,920
max has pro utilized the migration of

377
00:15:51,920 --> 00:15:54,399
hotkeys to achieve low latency and

378
00:15:54,399 --> 00:15:58,480
resource efficient security in spes

379
00:15:58,480 --> 00:16:01,199
in addition we use a control message for

380
00:16:01,199 --> 00:16:04,399
status mix consistency and they use low

381
00:16:04,399 --> 00:16:06,800
granted statement management for

382
00:16:06,800 --> 00:16:09,279
efficient data transmission

383
00:16:09,279 --> 00:16:11,920
max is implanted on top of the widely

384
00:16:11,920 --> 00:16:14,160
used xpe apache link

385
00:16:14,160 --> 00:16:16,480
requiring minimal user

386
00:16:16,480 --> 00:16:19,920
code modification and load interruption

387
00:16:19,920 --> 00:16:22,560
to long-scaling periods that's all for

388
00:16:22,560 --> 00:16:24,720
this representation presentation and i'm

389
00:16:24,720 --> 00:16:28,440
happy to take some questions

