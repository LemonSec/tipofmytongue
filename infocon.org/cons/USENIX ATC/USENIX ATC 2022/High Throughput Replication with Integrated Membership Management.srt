1
00:00:15,599 --> 00:00:18,320
okay so hello uh i'm going to present

2
00:00:18,320 --> 00:00:20,640
the work we've been doing in nova with

3
00:00:20,640 --> 00:00:23,680
my advisors professors nun pregis and

4
00:00:23,680 --> 00:00:26,400
john layton which is entitled i

5
00:00:26,400 --> 00:00:28,960
throughput replication with integrated

6
00:00:28,960 --> 00:00:30,960
membership management

7
00:00:30,960 --> 00:00:33,040
okay so starting with a bit of

8
00:00:33,040 --> 00:00:35,360
motivation and context

9
00:00:35,360 --> 00:00:37,760
our work is in the area of consensus and

10
00:00:37,760 --> 00:00:39,920
state machine replication

11
00:00:39,920 --> 00:00:42,000
which i don't believe i have to explain

12
00:00:42,000 --> 00:00:42,800
that

13
00:00:42,800 --> 00:00:45,520
it's the building block of many

14
00:00:45,520 --> 00:00:48,960
uh practical replication systems and its

15
00:00:48,960 --> 00:00:51,039
performance is very critical to the

16
00:00:51,039 --> 00:00:53,360
operation of these systems and that's

17
00:00:53,360 --> 00:00:55,680
why many alternatives have been designed

18
00:00:55,680 --> 00:00:58,559
and proposed over the years

19
00:00:58,559 --> 00:01:00,559
there are two very relevant ones that i

20
00:01:00,559 --> 00:01:02,879
want to quickly summarize in this

21
00:01:02,879 --> 00:01:04,799
presentation which are multiplexes and

22
00:01:04,799 --> 00:01:06,320
chain replication

23
00:01:06,320 --> 00:01:07,840
okay

24
00:01:07,840 --> 00:01:10,000
so starting with multiplexers in

25
00:01:10,000 --> 00:01:12,720
multiplex we have a leader and in the

26
00:01:12,720 --> 00:01:14,640
classic multipacks

27
00:01:14,640 --> 00:01:16,640
skipping the first phase

28
00:01:16,640 --> 00:01:18,799
the leader when he wants to propose

29
00:01:18,799 --> 00:01:21,520
something sends to every other replica

30
00:01:21,520 --> 00:01:24,000
in this case that yellow operation and

31
00:01:24,000 --> 00:01:27,200
then every replica broadcasts it to each

32
00:01:27,200 --> 00:01:29,680
other and then when we have a quorum of

33
00:01:29,680 --> 00:01:32,320
accepted messages we can execute the

34
00:01:32,320 --> 00:01:34,560
operation

35
00:01:34,560 --> 00:01:38,079
uh so this is a small problem that is

36
00:01:38,079 --> 00:01:40,960
the message complexity

37
00:01:40,960 --> 00:01:41,330
it

38
00:01:41,330 --> 00:01:42,640
[Music]

39
00:01:42,640 --> 00:01:45,280
depends on the number of replicas

40
00:01:45,280 --> 00:01:47,520
and then we have some alternatives for

41
00:01:47,520 --> 00:01:50,399
instance the distinguished learner where

42
00:01:50,399 --> 00:01:53,040
the leader or better the followers and

43
00:01:53,040 --> 00:01:54,880
we need to deal with a single message

44
00:01:54,880 --> 00:01:57,920
but then the leader still needs to

45
00:01:57,920 --> 00:01:59,759
deal with the number of message that is

46
00:01:59,759 --> 00:02:02,240
proportional to the number of replicas

47
00:02:02,240 --> 00:02:05,439
okay however paxus has something very

48
00:02:05,439 --> 00:02:07,759
good which is its entire purpose is that

49
00:02:07,759 --> 00:02:10,080
it guarantees consensus safety of

50
00:02:10,080 --> 00:02:12,720
consensus in an asynchronous network

51
00:02:12,720 --> 00:02:14,560
model

52
00:02:14,560 --> 00:02:17,120
okay then reaction replication

53
00:02:17,120 --> 00:02:19,520
question replication is quite simple we

54
00:02:19,520 --> 00:02:21,760
have an ads we have a tile when when to

55
00:02:21,760 --> 00:02:24,080
create an appetite we just propagate it

56
00:02:24,080 --> 00:02:26,239
through the shine until it reaches the

57
00:02:26,239 --> 00:02:27,360
tile

58
00:02:27,360 --> 00:02:29,120
it has this

59
00:02:29,120 --> 00:02:31,920
very useful detail that each replica

60
00:02:31,920 --> 00:02:34,080
only deals with a single message

61
00:02:34,080 --> 00:02:36,879
however it has its own limitations and

62
00:02:36,879 --> 00:02:39,360
we'll get there soon

63
00:02:39,360 --> 00:02:41,440
okay

64
00:02:41,440 --> 00:02:43,680
so entering a bit more in the context of

65
00:02:43,680 --> 00:02:46,080
our work uh while there are many

66
00:02:46,080 --> 00:02:48,080
consensus alternatives there are two

67
00:02:48,080 --> 00:02:50,800
aspects which are very often overlooked

68
00:02:50,800 --> 00:02:52,879
which are the performance of read

69
00:02:52,879 --> 00:02:54,560
operations

70
00:02:54,560 --> 00:02:56,879
and the membership management

71
00:02:56,879 --> 00:02:59,519
okay starting with performance of read

72
00:02:59,519 --> 00:03:01,120
operations

73
00:03:01,120 --> 00:03:03,200
or better yet line arrizable read

74
00:03:03,200 --> 00:03:05,760
operations because just reading without

75
00:03:05,760 --> 00:03:08,959
any consistency is easy

76
00:03:08,959 --> 00:03:10,640
we have solutions that assume

77
00:03:10,640 --> 00:03:12,400
synchronous models for instance chain

78
00:03:12,400 --> 00:03:14,800
replication that i just mentioned

79
00:03:14,800 --> 00:03:17,280
okay and when i say they assume

80
00:03:17,280 --> 00:03:19,360
synchronous models is because if you

81
00:03:19,360 --> 00:03:22,000
have a network partition

82
00:03:22,000 --> 00:03:24,640
they stop working so in this example if

83
00:03:24,640 --> 00:03:27,760
the old style gets partitioned then the

84
00:03:27,760 --> 00:03:30,159
rest of the system continues operating

85
00:03:30,159 --> 00:03:33,040
and the old style will continue serving

86
00:03:33,040 --> 00:03:34,799
read operations

87
00:03:34,799 --> 00:03:39,319
which will break linearizability

88
00:03:40,959 --> 00:03:42,080
so to

89
00:03:42,080 --> 00:03:45,599
to handle the asynchrony problems

90
00:03:45,599 --> 00:03:48,720
there are many solutions uh

91
00:03:48,720 --> 00:03:50,159
the most

92
00:03:50,159 --> 00:03:53,680
common ones are relaxing consistency

93
00:03:53,680 --> 00:03:56,000
which means basically not providing

94
00:03:56,000 --> 00:03:59,040
linearizable rates for instance sukipa

95
00:03:59,040 --> 00:04:01,640
or the alternative is adding extra

96
00:04:01,640 --> 00:04:03,519
synchronizations and costly

97
00:04:03,519 --> 00:04:07,120
communication steps when executing each

98
00:04:07,120 --> 00:04:09,519
read operation

99
00:04:09,519 --> 00:04:11,280
so the other aspect that i wanted to

100
00:04:11,280 --> 00:04:14,959
mention is membership management

101
00:04:14,959 --> 00:04:16,639
that is something that is often

102
00:04:16,639 --> 00:04:18,798
overlooked in these

103
00:04:18,798 --> 00:04:20,000
systems

104
00:04:20,000 --> 00:04:22,960
uh being that most of them often say

105
00:04:22,960 --> 00:04:24,320
something like

106
00:04:24,320 --> 00:04:26,960
we'll just plug zookeeper there and

107
00:04:26,960 --> 00:04:29,040
zookeeper will handle everything and

108
00:04:29,040 --> 00:04:32,800
it's trivial and everything works

109
00:04:32,800 --> 00:04:34,240
we have

110
00:04:34,240 --> 00:04:36,479
a series of counter-arguments against

111
00:04:36,479 --> 00:04:38,560
this

112
00:04:38,560 --> 00:04:40,720
in a way that we do not think this is a

113
00:04:40,720 --> 00:04:43,520
good solution the first one is that

114
00:04:43,520 --> 00:04:45,759
fault tolerance becomes complex so

115
00:04:45,759 --> 00:04:47,280
assuming you have your consensus

116
00:04:47,280 --> 00:04:48,479
solution

117
00:04:48,479 --> 00:04:50,000
you're going to add

118
00:04:50,000 --> 00:04:53,040
some external coordinator on the sides

119
00:04:53,040 --> 00:04:56,400
but now you have a tr replicas but your

120
00:04:56,400 --> 00:04:58,720
false tolerance is only one

121
00:04:58,720 --> 00:05:01,199
and then you can say but i'll

122
00:05:01,199 --> 00:05:03,919
just add more replicas to my coordinator

123
00:05:03,919 --> 00:05:06,639
service but then you now have 10

124
00:05:06,639 --> 00:05:08,800
replicas but your fault tolerance is

125
00:05:08,800 --> 00:05:11,840
still only two

126
00:05:12,400 --> 00:05:14,080
okay so

127
00:05:14,080 --> 00:05:16,160
other problems is that you actually have

128
00:05:16,160 --> 00:05:17,360
to

129
00:05:17,360 --> 00:05:19,759
require complex integrations with your

130
00:05:19,759 --> 00:05:23,360
consensus solution itself

131
00:05:23,360 --> 00:05:25,520
and i'll give you an example if one of

132
00:05:25,520 --> 00:05:27,759
your replicas files

133
00:05:27,759 --> 00:05:30,880
uh usually what happens is that your

134
00:05:30,880 --> 00:05:32,960
coordinator servers will execute the

135
00:05:32,960 --> 00:05:36,320
consensus around to decide the removal

136
00:05:36,320 --> 00:05:39,600
however you have an asynchronous network

137
00:05:39,600 --> 00:05:42,479
and so the decision of the removal

138
00:05:42,479 --> 00:05:44,800
is delivered in an asynchronous manner

139
00:05:44,800 --> 00:05:46,960
and your replicas cannot simply change

140
00:05:46,960 --> 00:05:48,479
their views at will

141
00:05:48,479 --> 00:05:50,800
so what will happen is that you'll

142
00:05:50,800 --> 00:05:53,520
execute yet another redundant consensus

143
00:05:53,520 --> 00:05:56,479
round in your own solution which kind of

144
00:05:56,479 --> 00:05:59,520
defeats the purpose

145
00:05:59,520 --> 00:06:01,919
and finally there's been a

146
00:06:01,919 --> 00:06:04,080
quite recent study

147
00:06:04,080 --> 00:06:06,880
that shows that

148
00:06:06,880 --> 00:06:09,360
this kind of setups using

149
00:06:09,360 --> 00:06:11,680
external coordinator services actually

150
00:06:11,680 --> 00:06:13,120
turn your

151
00:06:13,120 --> 00:06:15,600
system more vulnerable to partition

152
00:06:15,600 --> 00:06:17,759
partial network partitions

153
00:06:17,759 --> 00:06:19,680
okay and i'll give you an example what

154
00:06:19,680 --> 00:06:22,400
happens if you have a partial partition

155
00:06:22,400 --> 00:06:25,039
between some of your nodes and your

156
00:06:25,039 --> 00:06:28,160
coordinating coordinator service

157
00:06:28,160 --> 00:06:30,240
well your correct replicas will be

158
00:06:30,240 --> 00:06:31,759
removed

159
00:06:31,759 --> 00:06:34,400
or in another example what if you have a

160
00:06:34,400 --> 00:06:36,560
partition between your consensus

161
00:06:36,560 --> 00:06:38,960
replicas but they can still communicate

162
00:06:38,960 --> 00:06:40,880
with the coordinator

163
00:06:40,880 --> 00:06:44,240
and you are unlucky and one of those

164
00:06:44,240 --> 00:06:46,400
that are in the smallest partition is

165
00:06:46,400 --> 00:06:48,560
the leader or primary or some sort of

166
00:06:48,560 --> 00:06:50,960
special role well then your system will

167
00:06:50,960 --> 00:06:53,360
out because the coordinator service will

168
00:06:53,360 --> 00:06:56,240
not remove them

169
00:06:57,199 --> 00:07:00,000
okay so all of this to get to our

170
00:07:00,000 --> 00:07:02,960
proposal which is

171
00:07:02,960 --> 00:07:05,680
a new consensus algorithm which we call

172
00:07:05,680 --> 00:07:08,160
chain boxes and as you can guess it

173
00:07:08,160 --> 00:07:10,960
combines properties of both multi-parts

174
00:07:10,960 --> 00:07:13,840
and chain replication

175
00:07:13,840 --> 00:07:14,840
namely

176
00:07:14,840 --> 00:07:18,880
it uses the correctness in a synchronous

177
00:07:18,880 --> 00:07:21,840
network that is provided by multiplexes

178
00:07:21,840 --> 00:07:24,720
but it has constant message complexity

179
00:07:24,720 --> 00:07:27,919
now this is not necessarily new but then

180
00:07:27,919 --> 00:07:33,199
we go ahead and our proposal

181
00:07:33,199 --> 00:07:35,840
proposes the following

182
00:07:35,840 --> 00:07:38,080
things which are minimizing throughput

183
00:07:38,080 --> 00:07:40,639
of both reads and write operations

184
00:07:40,639 --> 00:07:42,960
providing local linearizable reads in

185
00:07:42,960 --> 00:07:45,520
any replica without any extra

186
00:07:45,520 --> 00:07:47,440
communication and integrating

187
00:07:47,440 --> 00:07:49,759
reconfiguration and false tolerance in

188
00:07:49,759 --> 00:07:52,319
the algorithm itself

189
00:07:52,319 --> 00:07:55,919
okay so showing our solution

190
00:07:55,919 --> 00:07:58,639
and starting by how do we actually write

191
00:07:58,639 --> 00:08:01,199
and commit operations

192
00:08:01,199 --> 00:08:03,280
where we have a simple setup with five

193
00:08:03,280 --> 00:08:06,160
replicas with a leader which is

194
00:08:06,160 --> 00:08:08,400
elected using the regular multiplexes

195
00:08:08,400 --> 00:08:10,000
leader election

196
00:08:10,000 --> 00:08:11,840
we want to write an operation that

197
00:08:11,840 --> 00:08:13,759
operation is propagated to the leader

198
00:08:13,759 --> 00:08:15,360
and then the leader will simply

199
00:08:15,360 --> 00:08:17,840
propagate it through the chain however

200
00:08:17,840 --> 00:08:20,800
when propagating to the shine

201
00:08:20,800 --> 00:08:23,199
uh these messages that are propagated

202
00:08:23,199 --> 00:08:25,919
can be seen as encapsulating multiple

203
00:08:25,919 --> 00:08:28,319
multiplexes messages in this case we

204
00:08:28,319 --> 00:08:30,400
encapsulate the accept and the asset

205
00:08:30,400 --> 00:08:32,479
docker

206
00:08:32,479 --> 00:08:34,399
we do the same thing through the shine

207
00:08:34,399 --> 00:08:36,240
but when propagating to the third

208
00:08:36,240 --> 00:08:38,719
replica we already have two acceptor

209
00:08:38,719 --> 00:08:41,039
guys and so the third replica can

210
00:08:41,039 --> 00:08:44,560
execute the operation and so on

211
00:08:44,560 --> 00:08:46,399
reaching the end of the

212
00:08:46,399 --> 00:08:47,920
the chain

213
00:08:47,920 --> 00:08:49,680
we still need to execute the operation

214
00:08:49,680 --> 00:08:51,920
in the first two replicas and garbage

215
00:08:51,920 --> 00:08:55,360
collect information about the operations

216
00:08:55,360 --> 00:08:58,240
so what we do is we send an acknowledge

217
00:08:58,240 --> 00:09:00,800
message back to the leader which will

218
00:09:00,800 --> 00:09:02,880
trigger the execution of the operation

219
00:09:02,880 --> 00:09:06,320
and garbage collection

220
00:09:07,360 --> 00:09:10,480
so now again this isn't exactly new uh

221
00:09:10,480 --> 00:09:13,680
what is new is what we do next and

222
00:09:13,680 --> 00:09:16,240
starting by providing local linearizable

223
00:09:16,240 --> 00:09:17,200
reads

224
00:09:17,200 --> 00:09:18,320
uh

225
00:09:18,320 --> 00:09:20,800
a very brief summary of the requirements

226
00:09:20,800 --> 00:09:22,480
basically to provide

227
00:09:22,480 --> 00:09:24,480
line reasonable reads we need to make

228
00:09:24,480 --> 00:09:27,360
sure that read reflects

229
00:09:27,360 --> 00:09:29,440
the results of every write and read

230
00:09:29,440 --> 00:09:31,839
operation that completed before that

231
00:09:31,839 --> 00:09:33,920
read started

232
00:09:33,920 --> 00:09:36,160
and the challenge here is reading from

233
00:09:36,160 --> 00:09:39,120
any replica without any extra

234
00:09:39,120 --> 00:09:41,360
communication steps

235
00:09:41,360 --> 00:09:42,320
okay

236
00:09:42,320 --> 00:09:45,360
and for this the chain topology uh can

237
00:09:45,360 --> 00:09:47,760
be very useful okay we have again

238
00:09:47,760 --> 00:09:50,399
another example in this case we have

239
00:09:50,399 --> 00:09:52,959
that green operation which has already

240
00:09:52,959 --> 00:09:55,040
been executed in the third and fourth

241
00:09:55,040 --> 00:09:57,360
nodes and we have that yellow operation

242
00:09:57,360 --> 00:10:00,399
which has not yet been executed anyway

243
00:10:00,399 --> 00:10:02,240
and now we have a read

244
00:10:02,240 --> 00:10:06,160
reaching the last replica

245
00:10:06,160 --> 00:10:08,959
okay so summarizing the requirements

246
00:10:08,959 --> 00:10:11,360
we're going to ignore completed reads by

247
00:10:11,360 --> 00:10:13,360
now and basically what we need is to

248
00:10:13,360 --> 00:10:15,519
make sure that that read operation

249
00:10:15,519 --> 00:10:18,399
contains the green oppression since it

250
00:10:18,399 --> 00:10:20,480
has already been executed before the

251
00:10:20,480 --> 00:10:22,880
reit started

252
00:10:22,880 --> 00:10:25,279
so obviously we cannot

253
00:10:25,279 --> 00:10:28,160
return the current state to the client

254
00:10:28,160 --> 00:10:30,160
immediately

255
00:10:30,160 --> 00:10:32,959
so what our always does is

256
00:10:32,959 --> 00:10:36,640
it stores the read operation

257
00:10:36,640 --> 00:10:38,560
it stays pending and then it will be

258
00:10:38,560 --> 00:10:40,959
attached to the next operation that is

259
00:10:40,959 --> 00:10:42,800
received by the node so in this case the

260
00:10:42,800 --> 00:10:45,040
next operation will be the green one

261
00:10:45,040 --> 00:10:47,120
so the replica will attach the read

262
00:10:47,120 --> 00:10:50,079
operation to the green one

263
00:10:50,079 --> 00:10:53,040
and then basically we wait until until

264
00:10:53,040 --> 00:10:55,279
the acknowledge of the green operation

265
00:10:55,279 --> 00:10:57,680
goes back goes around the chain and

266
00:10:57,680 --> 00:11:01,440
reaches that last replica

267
00:11:01,440 --> 00:11:03,279
and what this will do is basically make

268
00:11:03,279 --> 00:11:05,680
sure that each write operation that is

269
00:11:05,680 --> 00:11:07,839
pending or has already been completed in

270
00:11:07,839 --> 00:11:10,720
the shine will be executed

271
00:11:10,720 --> 00:11:13,040
before the read returns

272
00:11:13,040 --> 00:11:15,519
okay so in this case we

273
00:11:15,519 --> 00:11:18,160
waited for the acknowledgement and upon

274
00:11:18,160 --> 00:11:20,079
reaching the replica we had already

275
00:11:20,079 --> 00:11:23,040
executed the green oppression and we had

276
00:11:23,040 --> 00:11:25,519
actually already executed the yellow one

277
00:11:25,519 --> 00:11:27,519
which is a bit stronger than strictly

278
00:11:27,519 --> 00:11:28,800
necessary

279
00:11:28,800 --> 00:11:30,160
but

280
00:11:30,160 --> 00:11:34,160
it also provides linearizability

281
00:11:34,160 --> 00:11:37,760
okay so assuming we have a second read

282
00:11:37,760 --> 00:11:40,160
and now we need to make sure that

283
00:11:40,160 --> 00:11:42,880
this reads contains the results of any

284
00:11:42,880 --> 00:11:46,000
previous reads we still

285
00:11:46,000 --> 00:11:48,560
the reasoning is the same we execute the

286
00:11:48,560 --> 00:11:51,040
same algorithm and by waiting for the

287
00:11:51,040 --> 00:11:53,120
acknowledged message in this case after

288
00:11:53,120 --> 00:11:56,240
read message of the red operation we

289
00:11:56,240 --> 00:11:58,880
make sure that every pinning operation

290
00:11:58,880 --> 00:12:01,040
in this case the yellow one is pushed

291
00:12:01,040 --> 00:12:04,160
through the shine and reaches us before

292
00:12:04,160 --> 00:12:07,360
that acknowledgement so that we can

293
00:12:07,360 --> 00:12:11,320
respond to the client

294
00:12:13,760 --> 00:12:16,000
so

295
00:12:16,480 --> 00:12:17,920
the final

296
00:12:17,920 --> 00:12:19,920
contribution of our algorithm is the

297
00:12:19,920 --> 00:12:22,959
reconfiguration okay so it supports

298
00:12:22,959 --> 00:12:25,440
dynamic membership management adding

299
00:12:25,440 --> 00:12:28,560
replicas is not very exciting so

300
00:12:28,560 --> 00:12:30,480
i will show an example of removing

301
00:12:30,480 --> 00:12:31,760
replicas

302
00:12:31,760 --> 00:12:34,160
okay which is

303
00:12:34,160 --> 00:12:36,160
important since

304
00:12:36,160 --> 00:12:38,399
the failure of a single replica can stop

305
00:12:38,399 --> 00:12:40,320
the entire shine

306
00:12:40,320 --> 00:12:42,320
so what we do in our algorithm is that

307
00:12:42,320 --> 00:12:44,720
replicas monitor the next replica in the

308
00:12:44,720 --> 00:12:46,000
shine

309
00:12:46,000 --> 00:12:48,480
and upon

310
00:12:48,480 --> 00:12:52,000
suspecting that the next replica files

311
00:12:52,000 --> 00:12:54,959
they will basically request the leader

312
00:12:54,959 --> 00:12:57,600
to remove that replica and that

313
00:12:57,600 --> 00:12:59,680
removal is executed like a normal

314
00:12:59,680 --> 00:13:02,800
operation okay except that when it

315
00:13:02,800 --> 00:13:04,480
reaches the

316
00:13:04,480 --> 00:13:07,920
replica that suspected the next one that

317
00:13:07,920 --> 00:13:10,800
replica will skip the suspected replica

318
00:13:10,800 --> 00:13:15,200
a send message directly to the next one

319
00:13:15,200 --> 00:13:16,720
so we still need to make sure that

320
00:13:16,720 --> 00:13:18,880
operations are delivered in order so

321
00:13:18,880 --> 00:13:21,519
first the second replica needs to

322
00:13:21,519 --> 00:13:23,360
propagate the green operation since it

323
00:13:23,360 --> 00:13:25,440
doesn't know if the failed replica

324
00:13:25,440 --> 00:13:28,320
propagated it before filing or not and

325
00:13:28,320 --> 00:13:30,880
then it propagates the removal replica

326
00:13:30,880 --> 00:13:33,440
upon reaching the fourth replica we have

327
00:13:33,440 --> 00:13:35,839
a majority core so

328
00:13:35,839 --> 00:13:36,800
the

329
00:13:36,800 --> 00:13:40,320
failed or suspected replica is removed

330
00:13:40,320 --> 00:13:41,680
okay

331
00:13:41,680 --> 00:13:43,600
if for some reason the fourth replica

332
00:13:43,600 --> 00:13:45,279
add also filed

333
00:13:45,279 --> 00:13:47,440
then there is no problem we just repeat

334
00:13:47,440 --> 00:13:50,000
the same procedure we request the leader

335
00:13:50,000 --> 00:13:52,639
to remove the fort we skipped both

336
00:13:52,639 --> 00:13:55,120
suspected replicas since we have pinning

337
00:13:55,120 --> 00:13:57,600
message for removing both of them and we

338
00:13:57,600 --> 00:14:00,839
go straight to the legs next

339
00:14:00,839 --> 00:14:03,600
one okay

340
00:14:03,600 --> 00:14:06,320
so a little summary of what we do

341
00:14:06,320 --> 00:14:08,959
basically our solution aggregates

342
00:14:08,959 --> 00:14:12,000
multiplexes messages which in which

343
00:14:12,000 --> 00:14:13,920
ensures correctness

344
00:14:13,920 --> 00:14:16,480
and we minimize the cost of both writes

345
00:14:16,480 --> 00:14:19,360
and read operations

346
00:14:19,360 --> 00:14:21,440
and are able to provide locally

347
00:14:21,440 --> 00:14:23,680
linearizable reads in any replica

348
00:14:23,680 --> 00:14:25,519
without requiring any extra

349
00:14:25,519 --> 00:14:27,839
communications to complete those read

350
00:14:27,839 --> 00:14:29,199
operations

351
00:14:29,199 --> 00:14:30,839
and we also integrate

352
00:14:30,839 --> 00:14:33,040
reconfiguration in the system which

353
00:14:33,040 --> 00:14:35,440
avoids using external coordination

354
00:14:35,440 --> 00:14:37,920
service

355
00:14:38,320 --> 00:14:40,399
okay so we

356
00:14:40,399 --> 00:14:42,079
have

357
00:14:42,079 --> 00:14:44,560
we executed an evaluation of our system

358
00:14:44,560 --> 00:14:46,399
where we basically try to answer these

359
00:14:46,399 --> 00:14:48,639
questions how does shinbox perform

360
00:14:48,639 --> 00:14:50,959
against state of the art what is the

361
00:14:50,959 --> 00:14:53,360
latency of red of the shine which is a

362
00:14:53,360 --> 00:14:54,639
common

363
00:14:54,639 --> 00:14:57,760
critique of showing topologies

364
00:14:57,760 --> 00:14:59,839
what is the performance increase on

365
00:14:59,839 --> 00:15:02,079
local reads and can we use these in a

366
00:15:02,079 --> 00:15:03,839
practical setting

367
00:15:03,839 --> 00:15:04,959
okay

368
00:15:04,959 --> 00:15:07,360
so we have two different setups we

369
00:15:07,360 --> 00:15:09,120
implemented the simple duplicated key

370
00:15:09,120 --> 00:15:11,760
value store which used to compare shank

371
00:15:11,760 --> 00:15:14,880
bugs against other state-of-the-art

372
00:15:14,880 --> 00:15:16,320
protocols

373
00:15:16,320 --> 00:15:18,480
and we also tried to evaluate in a more

374
00:15:18,480 --> 00:15:21,279
realistic scenario where what we did is

375
00:15:21,279 --> 00:15:24,560
replaced zap which is basically

376
00:15:24,560 --> 00:15:27,120
zookeepers consensus protocol which

377
00:15:27,120 --> 00:15:30,000
chain packs and then we compared that

378
00:15:30,000 --> 00:15:33,839
implementation against the original

379
00:15:33,839 --> 00:15:35,360
zookeeper

380
00:15:35,360 --> 00:15:37,839
okay we use the grid 5000 test pad we

381
00:15:37,839 --> 00:15:40,240
emulated clients with ycsv and we

382
00:15:40,240 --> 00:15:42,639
measure the throughput and latency as

383
00:15:42,639 --> 00:15:44,560
observed by clients while varying the

384
00:15:44,560 --> 00:15:45,920
number of

385
00:15:45,920 --> 00:15:48,639
replicas the loads and the percentage of

386
00:15:48,639 --> 00:15:49,920
rates

387
00:15:49,920 --> 00:15:54,000
okay and starting with the first setup

388
00:15:54,000 --> 00:15:55,839
how does it perform against state of the

389
00:15:55,839 --> 00:15:58,399
art well our conclusions were that it

390
00:15:58,399 --> 00:16:00,240
performs pretty well

391
00:16:00,240 --> 00:16:02,959
uh and basically the conclusion is quite

392
00:16:02,959 --> 00:16:05,839
simple if we minimize the number of

393
00:16:05,839 --> 00:16:08,000
messages that are propagated and handled

394
00:16:08,000 --> 00:16:10,160
by each node

395
00:16:10,160 --> 00:16:14,480
the throughput is optimal

396
00:16:15,360 --> 00:16:19,199
so regarding the latency of the chain

397
00:16:19,199 --> 00:16:21,440
we executed tests using different number

398
00:16:21,440 --> 00:16:22,959
of replicas

399
00:16:22,959 --> 00:16:24,880
three five and seven

400
00:16:24,880 --> 00:16:26,880
and our conclusions were actually quite

401
00:16:26,880 --> 00:16:29,360
surprising since with a low number of

402
00:16:29,360 --> 00:16:32,800
replicas we can actually have a lower

403
00:16:32,800 --> 00:16:35,440
latency than other solutions

404
00:16:35,440 --> 00:16:37,920
and then as expected when we start

405
00:16:37,920 --> 00:16:40,959
getting a higher number of cyplicus

406
00:16:40,959 --> 00:16:43,600
the latency starts increasing however it

407
00:16:43,600 --> 00:16:46,240
requires at least seven or more replicas

408
00:16:46,240 --> 00:16:50,199
until it becomes a problem

409
00:16:50,480 --> 00:16:53,519
regarding local local reads performance

410
00:16:53,519 --> 00:16:54,800
uh we

411
00:16:54,800 --> 00:16:56,800
have a small test where we basically

412
00:16:56,800 --> 00:16:58,720
tested what's the performance of

413
00:16:58,720 --> 00:17:01,120
executing reads through the chain

414
00:17:01,120 --> 00:17:03,360
and then the performance of executing

415
00:17:03,360 --> 00:17:07,039
reads using our local serializable reads

416
00:17:07,039 --> 00:17:10,480
protocol in this case with 50 rates and

417
00:17:10,480 --> 00:17:13,439
then with 95 percent rates and the

418
00:17:13,439 --> 00:17:16,640
results are pretty satisfactory

419
00:17:16,640 --> 00:17:18,400
um

420
00:17:18,400 --> 00:17:20,480
and it's also interesting to note that

421
00:17:20,480 --> 00:17:24,480
the latency of red is actually uh

422
00:17:24,480 --> 00:17:26,000
quite small

423
00:17:26,000 --> 00:17:28,799
okay another interesting aspect is that

424
00:17:28,799 --> 00:17:31,360
since the reads do not require any extra

425
00:17:31,360 --> 00:17:33,440
communication by increasing the number

426
00:17:33,440 --> 00:17:35,520
of replicas we actually increase the

427
00:17:35,520 --> 00:17:38,559
number of reads that we can execute

428
00:17:38,559 --> 00:17:40,640
so in this case we three replicas around

429
00:17:40,640 --> 00:17:43,840
1300 with seven replicas we get to

430
00:17:43,840 --> 00:17:47,559
almost 1600

431
00:17:49,280 --> 00:17:52,480
the final evaluation was comparing with

432
00:17:52,480 --> 00:17:53,679
zap

433
00:17:53,679 --> 00:17:57,120
okay so what we did was we test we

434
00:17:57,120 --> 00:17:59,440
tested the performance of both our

435
00:17:59,440 --> 00:18:02,320
implementation in zookeeper and zap

436
00:18:02,320 --> 00:18:04,720
using different numbers of replicas and

437
00:18:04,720 --> 00:18:07,840
the conclusions were basically that

438
00:18:07,840 --> 00:18:09,360
our algorithm

439
00:18:09,360 --> 00:18:11,360
shows our throughput

440
00:18:11,360 --> 00:18:14,000
and another interesting aspect is that

441
00:18:14,000 --> 00:18:16,400
while the originals up

442
00:18:16,400 --> 00:18:18,400
the throughput decreases with the number

443
00:18:18,400 --> 00:18:20,240
of replicas

444
00:18:20,240 --> 00:18:21,200
in our

445
00:18:21,200 --> 00:18:22,880
in our protocol

446
00:18:22,880 --> 00:18:25,600
the number of replicas has a very small

447
00:18:25,600 --> 00:18:29,840
effect on the overall throughput

448
00:18:30,799 --> 00:18:32,480
we also did

449
00:18:32,480 --> 00:18:36,000
some tests with read operations

450
00:18:36,000 --> 00:18:39,520
where we compared our linearizable reads

451
00:18:39,520 --> 00:18:41,039
with

452
00:18:41,039 --> 00:18:44,559
strong reads in zukip

453
00:18:44,559 --> 00:18:48,080
where our reads were about twice as much

454
00:18:48,080 --> 00:18:49,520
performance

455
00:18:49,520 --> 00:18:52,080
and actually when comparing our

456
00:18:52,080 --> 00:18:55,440
linearizable reads against weak the weak

457
00:18:55,440 --> 00:18:57,600
reads of zookeeper

458
00:18:57,600 --> 00:18:58,960
we

459
00:18:58,960 --> 00:19:02,960
we can almost match its performance

460
00:19:02,960 --> 00:19:05,600
okay and again with

461
00:19:05,600 --> 00:19:11,039
not very significant latency over it

462
00:19:11,039 --> 00:19:13,760
okay so just a quick recap basically we

463
00:19:13,760 --> 00:19:16,240
proposed a consensus already which

464
00:19:16,240 --> 00:19:18,240
combines some aspects of multiplex

465
00:19:18,240 --> 00:19:20,960
transgender replication and what we were

466
00:19:20,960 --> 00:19:23,679
able to do was maximizing the throughput

467
00:19:23,679 --> 00:19:26,160
of what read and write operations while

468
00:19:26,160 --> 00:19:28,880
providing locally linearizable reads

469
00:19:28,880 --> 00:19:31,440
without any kind of extra communication

470
00:19:31,440 --> 00:19:33,520
and integrating reconfiguration and

471
00:19:33,520 --> 00:19:35,120
fault tolerance

472
00:19:35,120 --> 00:19:38,320
in the algorithm itself

473
00:19:38,320 --> 00:19:40,559
okay and

474
00:19:40,559 --> 00:19:42,720
the paper is available for you check it

475
00:19:42,720 --> 00:19:45,120
out of course and i'm open to questions

476
00:19:45,120 --> 00:19:48,360
thank you

