1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:13,700 --> 00:00:15,560
my name is

3
00:00:15,560 --> 00:00:17,940
and today I'm going to talk about cash

4
00:00:17,940 --> 00:00:20,880
SEC lies automation optimization for

5
00:00:20,880 --> 00:00:24,919
Google data center fresh caches

6
00:00:25,380 --> 00:00:27,779
okay so first of all let's talk about

7
00:00:27,779 --> 00:00:30,480
colors of Fresh Catch light is the

8
00:00:30,480 --> 00:00:32,460
general purpose flash cache service for

9
00:00:32,460 --> 00:00:34,079
collectors

10
00:00:34,079 --> 00:00:37,140
and it works as an index server so that

11
00:00:37,140 --> 00:00:40,200
means if I'm a user and I want to access

12
00:00:40,200 --> 00:00:42,960
my data then first of all I will send

13
00:00:42,960 --> 00:00:45,239
the request to the cache index server to

14
00:00:45,239 --> 00:00:48,420
see the data is cached or not and if the

15
00:00:48,420 --> 00:00:50,820
data is cached then the index server

16
00:00:50,820 --> 00:00:53,700
will reply the cash location in courses

17
00:00:53,700 --> 00:00:56,940
and if it is a cash Miss then I have to

18
00:00:56,940 --> 00:01:00,480
write a real data from http

19
00:01:00,480 --> 00:01:03,440
and this service is fully decentralized

20
00:01:03,440 --> 00:01:07,140
each index server is a fraction of the

21
00:01:07,140 --> 00:01:10,740
key Space by hash so any single failure

22
00:01:10,740 --> 00:01:14,400
will not affect the other cash servers

23
00:01:14,400 --> 00:01:17,000
and the main goal of the

24
00:01:17,000 --> 00:01:20,100
closer Fast Cash is to reduce the

25
00:01:20,100 --> 00:01:22,560
overall decrease risk or spindles

26
00:01:22,560 --> 00:01:25,979
the latency is often improved but it's

27
00:01:25,979 --> 00:01:28,439
not guaranteed

28
00:01:28,439 --> 00:01:31,740
and our lead service serves many widely

29
00:01:31,740 --> 00:01:34,140
used Google service like bigtable

30
00:01:34,140 --> 00:01:40,220
spanner bigquery and F1 and much more

31
00:01:41,460 --> 00:01:44,579
okay then let's talk about cash stack

32
00:01:44,579 --> 00:01:47,340
law is the admission algorithm for

33
00:01:47,340 --> 00:01:49,500
closer flash cache

34
00:01:49,500 --> 00:01:52,380
and compared to a ring cache we need to

35
00:01:52,380 --> 00:01:54,000
additionally consider the following

36
00:01:54,000 --> 00:01:56,040
issue reality to flash

37
00:01:56,040 --> 00:01:59,159
the first one is right amplification

38
00:01:59,159 --> 00:02:01,259
and the second one is the right

39
00:02:01,259 --> 00:02:02,640
endurance

40
00:02:02,640 --> 00:02:04,979
and we also need to consider how can we

41
00:02:04,979 --> 00:02:09,239
cache the data only address a few times

42
00:02:09,239 --> 00:02:13,020
and the last one is closer specific law

43
00:02:13,020 --> 00:02:15,599
is the existence of closed buffer cache

44
00:02:15,599 --> 00:02:17,760
but in general if you have a

45
00:02:17,760 --> 00:02:19,500
hierarchical occasion system you will

46
00:02:19,500 --> 00:02:21,900
have the similar issue

47
00:02:21,900 --> 00:02:25,020
okay so let's talk about all this one by

48
00:02:25,020 --> 00:02:26,760
one

49
00:02:26,760 --> 00:02:29,760
okay so first of all right amplification

50
00:02:29,760 --> 00:02:32,520
what is ratification that means when you

51
00:02:32,520 --> 00:02:34,680
want to write the data to a flash block

52
00:02:34,680 --> 00:02:37,140
then first of all you need to move the

53
00:02:37,140 --> 00:02:40,620
Life part of the block to somewhere else

54
00:02:40,620 --> 00:02:43,560
and the extra y will reduce the flash

55
00:02:43,560 --> 00:02:45,420
performance and reduce the flash

56
00:02:45,420 --> 00:02:46,920
lifetime

57
00:02:46,920 --> 00:02:49,800
and while this is related to related to

58
00:02:49,800 --> 00:02:53,040
a fresh cache because typically you will

59
00:02:53,040 --> 00:02:55,739
have the non-sequential evictions for

60
00:02:55,739 --> 00:02:58,319
example the classical one lru

61
00:02:58,319 --> 00:03:00,840
and the non-sequential eviction will

62
00:03:00,840 --> 00:03:04,200
give you a very fragmented case space

63
00:03:04,200 --> 00:03:07,319
that means you have a very serious right

64
00:03:07,319 --> 00:03:09,900
amplification issue

65
00:03:09,900 --> 00:03:13,260
and to mitigate this problem uh actually

66
00:03:13,260 --> 00:03:16,200
we use the approximate error eviction

67
00:03:16,200 --> 00:03:17,640
strategy

68
00:03:17,640 --> 00:03:22,200
so the cash is a 50q of men many one

69
00:03:22,200 --> 00:03:25,379
gigabyte containers of the cash box

70
00:03:25,379 --> 00:03:28,080
and when we evict the container at the

71
00:03:28,080 --> 00:03:31,260
tail of Q we will recycle the hot block

72
00:03:31,260 --> 00:03:34,680
and reinser them to the head open

73
00:03:34,680 --> 00:03:37,980
and with this extensive study and we

74
00:03:37,980 --> 00:03:40,140
found that the aggregated behavior of

75
00:03:40,140 --> 00:03:42,540
this approximate UI strategy is very

76
00:03:42,540 --> 00:03:45,659
similar to the true Liu eviction

77
00:03:45,659 --> 00:03:48,120
and the idea here is that we want to

78
00:03:48,120 --> 00:03:50,220
keep the eviction simple because we have

79
00:03:50,220 --> 00:03:52,379
the issue of replication

80
00:03:52,379 --> 00:03:54,239
and we focus on the admission

81
00:03:54,239 --> 00:03:58,400
optimization which is the cash attack

82
00:03:59,959 --> 00:04:02,640
okay then let's talk about right

83
00:04:02,640 --> 00:04:05,580
endurance because Flash has limited

84
00:04:05,580 --> 00:04:07,680
right endurance so that means you can

85
00:04:07,680 --> 00:04:09,900
adjust simply write everything to the

86
00:04:09,900 --> 00:04:11,939
flash cache

87
00:04:11,939 --> 00:04:14,640
and the observation is the following we

88
00:04:14,640 --> 00:04:17,459
found that the majority of our data are

89
00:04:17,459 --> 00:04:20,040
only access ones so they are not

90
00:04:20,040 --> 00:04:21,899
catchable at all

91
00:04:21,899 --> 00:04:25,139
and if laser case we can use the

92
00:04:25,139 --> 00:04:28,139
algorithm called log let's lazy adaptive

93
00:04:28,139 --> 00:04:30,840
replacement cache it is a very simple

94
00:04:30,840 --> 00:04:34,320
but very powerful idea it says that okay

95
00:04:34,320 --> 00:04:37,500
if this is the case then we just admit

96
00:04:37,500 --> 00:04:39,660
any data at the second time

97
00:04:39,660 --> 00:04:44,040
so on every one ss data will be excluded

98
00:04:44,040 --> 00:04:46,440
and actually lock was the previous

99
00:04:46,440 --> 00:04:49,139
admission control we used to reduce The

100
00:04:49,139 --> 00:04:51,720
Return by to flash and also avoid the

101
00:04:51,720 --> 00:04:54,380
cash pollution

102
00:04:56,520 --> 00:05:00,300
okay but log has its own issue the most

103
00:05:00,300 --> 00:05:02,040
obvious issue is that if you always

104
00:05:02,040 --> 00:05:04,199
admit the data at the second time that

105
00:05:04,199 --> 00:05:07,199
means you always miss the First Cash hit

106
00:05:07,199 --> 00:05:10,500
and this become a big problem if the

107
00:05:10,500 --> 00:05:13,560
data is accessed only a few times

108
00:05:13,560 --> 00:05:15,419
because you always miss the First Cash

109
00:05:15,419 --> 00:05:16,919
hit

110
00:05:16,919 --> 00:05:20,280
and we have this problem in some of our

111
00:05:20,280 --> 00:05:22,860
biggest applications

112
00:05:22,860 --> 00:05:25,979
and in the past our workaround is we

113
00:05:25,979 --> 00:05:29,580
will manually monitor our workloads and

114
00:05:29,580 --> 00:05:32,100
whenever we found this issue we will

115
00:05:32,100 --> 00:05:33,900
manually turn off the lock for live

116
00:05:33,900 --> 00:05:38,940
workload this is a true manual process

117
00:05:38,940 --> 00:05:41,580
and obviously now we have more and more

118
00:05:41,580 --> 00:05:44,340
users then this menu monitoring and

119
00:05:44,340 --> 00:05:47,599
maintenance is not feasible

120
00:05:50,400 --> 00:05:53,639
okay then let's talk about causes buffer

121
00:05:53,639 --> 00:05:54,539
cache

122
00:05:54,539 --> 00:05:57,720
La is the rent buffer cache in the HD

123
00:05:57,720 --> 00:05:59,820
servers

124
00:05:59,820 --> 00:06:04,320
okay so that means if I have SS and the

125
00:06:04,320 --> 00:06:06,960
SS is a cache mean in The Flash cache

126
00:06:06,960 --> 00:06:09,900
but it is a cash hit in the buffer cache

127
00:06:09,900 --> 00:06:13,199
then I don't cause any extra tax rate

128
00:06:13,199 --> 00:06:15,300
I'm still safe

129
00:06:15,300 --> 00:06:19,080
and because a list is this long before

130
00:06:19,080 --> 00:06:21,660
the existence of course a buffer cache

131
00:06:21,660 --> 00:06:24,720
many workers already heavily utilize

132
00:06:24,720 --> 00:06:26,699
this buffer cache

133
00:06:26,699 --> 00:06:30,120
and while this is related to our flash

134
00:06:30,120 --> 00:06:33,840
cache because it's possible that if you

135
00:06:33,840 --> 00:06:35,880
don't design your fresh cash algorithm

136
00:06:35,880 --> 00:06:38,220
carefully then you can find the issue

137
00:06:38,220 --> 00:06:40,740
that you have of cash algorithm that

138
00:06:40,740 --> 00:06:42,780
gives you a very high cash key rate

139
00:06:42,780 --> 00:06:45,840
but you also have a very high uh

140
00:06:45,840 --> 00:06:47,400
disagree rate

141
00:06:47,400 --> 00:06:50,699
so the heightix uh High cache hero won't

142
00:06:50,699 --> 00:06:53,300
help you at all

143
00:06:54,600 --> 00:06:57,479
okay then let's talk about the cash Tech

144
00:06:57,479 --> 00:07:00,720
model La is the automation optimization

145
00:07:00,720 --> 00:07:04,199
to minimize the overall cost of discrete

146
00:07:04,199 --> 00:07:06,600
and the flashlight

147
00:07:06,600 --> 00:07:08,639
and what we want to do is the following

148
00:07:08,639 --> 00:07:11,880
we want to position our traffic into

149
00:07:11,880 --> 00:07:13,919
several categories

150
00:07:13,919 --> 00:07:16,500
and what do you mean by a category for

151
00:07:16,500 --> 00:07:19,319
example in big table or spanner a

152
00:07:19,319 --> 00:07:22,800
category is a locate group or uh called

153
00:07:22,800 --> 00:07:26,160
current family of a table

154
00:07:26,160 --> 00:07:28,440
and we also have different admission

155
00:07:28,440 --> 00:07:31,080
policies by their aggressiveness

156
00:07:31,080 --> 00:07:33,660
for example we have a domain of means

157
00:07:33,660 --> 00:07:36,360
not just a simple eru

158
00:07:36,360 --> 00:07:39,000
and we also have admin and second means

159
00:07:39,000 --> 00:07:40,800
let's lock

160
00:07:40,800 --> 00:07:43,380
or we can do it in a very aggressive way

161
00:07:43,380 --> 00:07:46,259
last of the mean Android that means when

162
00:07:46,259 --> 00:07:48,840
you write the data to HDD you at the

163
00:07:48,840 --> 00:07:51,180
same time will put the same copy in the

164
00:07:51,180 --> 00:07:53,160
flash cache

165
00:07:53,160 --> 00:07:56,220
and of course we can do we can just say

166
00:07:56,220 --> 00:07:57,660
okay I don't want to write anything to

167
00:07:57,660 --> 00:08:00,300
the cache that's never I think

168
00:08:00,300 --> 00:08:03,660
now you have many categories and you

169
00:08:03,660 --> 00:08:06,060
have some

170
00:08:06,060 --> 00:08:07,860
of the mission policies

171
00:08:07,860 --> 00:08:10,440
then the reasonable way is I want to

172
00:08:10,440 --> 00:08:13,500
apply a more aggressive policy to a more

173
00:08:13,500 --> 00:08:15,060
casual category

174
00:08:15,060 --> 00:08:16,680
that sounds reasonable

175
00:08:16,680 --> 00:08:18,900
but how can we do that in a quantitative

176
00:08:18,900 --> 00:08:19,919
way

177
00:08:19,919 --> 00:08:22,379
then we have to formulate a knapsack

178
00:08:22,379 --> 00:08:23,280
carbon

179
00:08:23,280 --> 00:08:26,160
so given the case size I want to choose

180
00:08:26,160 --> 00:08:28,800
the admission policy per category to

181
00:08:28,800 --> 00:08:32,419
minimize My overall cost

182
00:08:33,719 --> 00:08:36,120
okay so before we go to the optimization

183
00:08:36,120 --> 00:08:38,059
we need to have a model

184
00:08:38,059 --> 00:08:42,240
so let's use Simple Lau or admin or Miss

185
00:08:42,240 --> 00:08:43,740
as an example

186
00:08:43,740 --> 00:08:47,580
now say you have a block then you can

187
00:08:47,580 --> 00:08:50,700
have all these SS times T1 T2 T3 and so

188
00:08:50,700 --> 00:08:51,540
on

189
00:08:51,540 --> 00:08:54,000
and once you have the access times you

190
00:08:54,000 --> 00:08:56,339
can compute all the interval times not

191
00:08:56,339 --> 00:08:59,220
just t i minus TI minus one

192
00:08:59,220 --> 00:09:02,420
now let's assume that we know the cash

193
00:09:02,420 --> 00:09:06,180
retention time that's capital D log is

194
00:09:06,180 --> 00:09:09,060
the duration of a bug that can stay in

195
00:09:09,060 --> 00:09:12,660
an lru cache without any sses

196
00:09:12,660 --> 00:09:15,899
then once you define this quantity you

197
00:09:15,899 --> 00:09:17,640
can classify all your inter arrival

198
00:09:17,640 --> 00:09:18,480
times

199
00:09:18,480 --> 00:09:21,779
first if your Intel real time less than

200
00:09:21,779 --> 00:09:23,040
the retention time

201
00:09:23,040 --> 00:09:26,220
that means the SS arrived before the

202
00:09:26,220 --> 00:09:28,920
data leave the cache so like the cache

203
00:09:28,920 --> 00:09:29,640
Heat

204
00:09:29,640 --> 00:09:32,519
and because this UI cache you will move

205
00:09:32,519 --> 00:09:35,580
the block to the head of queue

206
00:09:35,580 --> 00:09:38,220
on the other hand if the inter arrival

207
00:09:38,220 --> 00:09:40,200
time is greater than the cash retention

208
00:09:40,200 --> 00:09:41,220
time

209
00:09:41,220 --> 00:09:45,360
then your SS arrives after the leave the

210
00:09:45,360 --> 00:09:47,940
cache as a cache mix

211
00:09:47,940 --> 00:09:51,180
and if this is a simple AIU that means

212
00:09:51,180 --> 00:09:52,980
whenever you have a cash means you

213
00:09:52,980 --> 00:09:55,080
should write the data to the fetch that

214
00:09:55,080 --> 00:09:57,120
calls the flash right

215
00:09:57,120 --> 00:10:00,240
and remember we have the Colossal buffer

216
00:10:00,240 --> 00:10:02,700
cache so whenever we have a cache Miss

217
00:10:02,700 --> 00:10:05,940
in Flash cache we also run the buffet

218
00:10:05,940 --> 00:10:08,820
simulator to see whether it is also a

219
00:10:08,820 --> 00:10:12,140
cache Miss in buffer cache

220
00:10:13,500 --> 00:10:15,480
okay then let's talk about the

221
00:10:15,480 --> 00:10:16,920
optimization

222
00:10:16,920 --> 00:10:19,440
so by doing this model we can compute

223
00:10:19,440 --> 00:10:21,899
all the quantities we want the spindle

224
00:10:21,899 --> 00:10:23,220
the D series

225
00:10:23,220 --> 00:10:27,660
the fresh right and also the cash usage

226
00:10:27,660 --> 00:10:29,820
and then We additionally allow

227
00:10:29,820 --> 00:10:32,339
fractional policies that means in the

228
00:10:32,339 --> 00:10:35,100
same category I for example I can apply

229
00:10:35,100 --> 00:10:37,260
log to 30 percent of the Block in this

230
00:10:37,260 --> 00:10:39,959
category and then apply never a debate

231
00:10:39,959 --> 00:10:41,700
to another 10 percent of the broad in

232
00:10:41,700 --> 00:10:44,640
the same category so on so forth

233
00:10:44,640 --> 00:10:46,980
then I can formulate a fractional

234
00:10:46,980 --> 00:10:48,540
website problem

235
00:10:48,540 --> 00:10:50,760
so what I want to do is to find the

236
00:10:50,760 --> 00:10:53,420
optimal fraction per policy per category

237
00:10:53,420 --> 00:10:56,160
to minimize the overall cost

238
00:10:56,160 --> 00:10:58,980
in this case that's the D3 plus the

239
00:10:58,980 --> 00:11:01,620
written bytes waste the cash capacity

240
00:11:01,620 --> 00:11:03,540
constraint

241
00:11:03,540 --> 00:11:06,000
and the good thing here is the

242
00:11:06,000 --> 00:11:08,040
fractional website can be solved very

243
00:11:08,040 --> 00:11:11,279
efficiently by using a greedy algorithm

244
00:11:11,279 --> 00:11:13,380
light is in contrast to the

245
00:11:13,380 --> 00:11:17,420
combinatorial website by SMP heart

246
00:11:19,440 --> 00:11:22,920
okay so this sounds very nice but the

247
00:11:22,920 --> 00:11:25,019
problem is that the

248
00:11:25,019 --> 00:11:28,320
fresh known episode problem only for the

249
00:11:28,320 --> 00:11:30,480
given cash retention type

250
00:11:30,480 --> 00:11:33,720
but in reality how come you can know the

251
00:11:33,720 --> 00:11:36,300
cash retention time in advance

252
00:11:36,300 --> 00:11:38,160
so

253
00:11:38,160 --> 00:11:40,500
to find the global optimal you need to

254
00:11:40,500 --> 00:11:42,660
solve the same website problem for all

255
00:11:42,660 --> 00:11:45,300
the possible cash retention times

256
00:11:45,300 --> 00:11:48,720
and in production we have 127 cash

257
00:11:48,720 --> 00:11:51,839
retention times from 15 minutes to 16

258
00:11:51,839 --> 00:11:55,200
days with six percent increments

259
00:11:55,200 --> 00:11:58,160
and in the past we also try

260
00:11:58,160 --> 00:12:00,899
255 cash retention times these three

261
00:12:00,899 --> 00:12:02,880
percent equipment so you have a better

262
00:12:02,880 --> 00:12:04,140
granularity

263
00:12:04,140 --> 00:12:07,560
and we found them to have very similar

264
00:12:07,560 --> 00:12:09,600
results so we go with the last values

265
00:12:09,600 --> 00:12:13,700
because you just use half a red

266
00:12:14,640 --> 00:12:15,720
okay

267
00:12:15,720 --> 00:12:19,079
so uh we have a full list in production

268
00:12:19,079 --> 00:12:22,560
so care SEC is also fully decentralized

269
00:12:22,560 --> 00:12:24,500
it requires only the information

270
00:12:24,500 --> 00:12:28,380
received by a single index server and

271
00:12:28,380 --> 00:12:30,180
the failure of a single server won't

272
00:12:30,180 --> 00:12:32,040
impact others

273
00:12:32,040 --> 00:12:34,500
and because we can solve the next

274
00:12:34,500 --> 00:12:36,959
problem very efficiently it can run in

275
00:12:36,959 --> 00:12:39,600
real time and just use a fraction of the

276
00:12:39,600 --> 00:12:42,120
resource of an index server

277
00:12:42,120 --> 00:12:45,540
and to get the Intel arrival times we

278
00:12:45,540 --> 00:12:48,420
have a ghost cache like the lookup table

279
00:12:48,420 --> 00:12:50,940
for the older let's asset sign of every

280
00:12:50,940 --> 00:12:52,560
data entry

281
00:12:52,560 --> 00:12:55,860
okay and we run the entire optimization

282
00:12:55,860 --> 00:12:58,380
every five five minutes

283
00:12:58,380 --> 00:13:00,720
and use the latest result to make the

284
00:13:00,720 --> 00:13:03,620
admission decisions

285
00:13:04,260 --> 00:13:07,380
okay lesson learned we found a few

286
00:13:07,380 --> 00:13:11,459
things first of all we found out if uh

287
00:13:11,459 --> 00:13:14,579
we say we tell the user that list will

288
00:13:14,579 --> 00:13:16,200
be all the configuration will be done

289
00:13:16,200 --> 00:13:18,839
automatically then we found that user

290
00:13:18,839 --> 00:13:21,660
are more willing to use our service

291
00:13:21,660 --> 00:13:22,860
uh

292
00:13:22,860 --> 00:13:25,620
and second uh this experiment

293
00:13:25,620 --> 00:13:28,200
infrastructure greatly help the future

294
00:13:28,200 --> 00:13:30,959
development because the entire system is

295
00:13:30,959 --> 00:13:33,720
fully decentralized so that means I can

296
00:13:33,720 --> 00:13:35,940
always use a small set of cache index

297
00:13:35,940 --> 00:13:37,680
server to run my experience in

298
00:13:37,680 --> 00:13:40,200
production and no matter what I did I

299
00:13:40,200 --> 00:13:42,540
won't scoop up the entire system

300
00:13:42,540 --> 00:13:45,420
and actually before the full deployment

301
00:13:45,420 --> 00:13:49,139
We Run The cadstack as an experiment for

302
00:13:49,139 --> 00:13:51,540
a few months and most of issues were

303
00:13:51,540 --> 00:13:54,120
identified during that stage

304
00:13:54,120 --> 00:13:57,000
and finally our list model is highly

305
00:13:57,000 --> 00:14:00,899
introspectable solar means the DVS and

306
00:14:00,899 --> 00:14:03,480
Sie can fully understand the model

307
00:14:03,480 --> 00:14:06,600
so after the initial deployment and we

308
00:14:06,600 --> 00:14:09,240
just give everything to them and the new

309
00:14:09,240 --> 00:14:11,459
new feature and the maintenance are

310
00:14:11,459 --> 00:14:13,860
totally done by then without any

311
00:14:13,860 --> 00:14:16,820
assistance from us

312
00:14:18,420 --> 00:14:21,600
okay then let's see uh the comparison in

313
00:14:21,600 --> 00:14:22,560
production

314
00:14:22,560 --> 00:14:25,620
as I say this is a fully decentralized

315
00:14:25,620 --> 00:14:26,459
system

316
00:14:26,459 --> 00:14:28,800
so each index server represents a

317
00:14:28,800 --> 00:14:31,920
fraction of the key Space by hash

318
00:14:31,920 --> 00:14:35,040
then we can compare all the algorithms

319
00:14:35,040 --> 00:14:38,160
simultaneously by running them in

320
00:14:38,160 --> 00:14:41,279
different cache index servers

321
00:14:41,279 --> 00:14:43,860
okay and we run all the experiments for

322
00:14:43,860 --> 00:14:46,199
week we compare three different

323
00:14:46,199 --> 00:14:49,380
algorithms the care stack the simple Liu

324
00:14:49,380 --> 00:14:51,060
and the log

325
00:14:51,060 --> 00:14:54,240
and as you can see uh ksec will give you

326
00:14:54,240 --> 00:14:57,180
the lowest discrete and also the lowest

327
00:14:57,180 --> 00:15:00,360
return by to flash so it has the lowest

328
00:15:00,360 --> 00:15:02,100
overall cost

329
00:15:02,100 --> 00:15:05,220
and one interesting thing here is that

330
00:15:05,220 --> 00:15:08,279
if you look at uh let me armies last

331
00:15:08,279 --> 00:15:09,839
simple lru

332
00:15:09,839 --> 00:15:13,980
it gives the highest hit cache ratio

333
00:15:13,980 --> 00:15:17,040
in Flash cash but it also gives you the

334
00:15:17,040 --> 00:15:18,480
worst outcome

335
00:15:18,480 --> 00:15:21,060
this is because of the Colossal buff

336
00:15:21,060 --> 00:15:24,060
cache so many of its cashews are

337
00:15:24,060 --> 00:15:27,260
actually not useful at all

338
00:15:28,740 --> 00:15:31,459
okay so in conclusion

339
00:15:31,459 --> 00:15:34,199
improved the overall cost of colossal

340
00:15:34,199 --> 00:15:38,279
buffer cost of fresh cash by 6.5 this is

341
00:15:38,279 --> 00:15:41,040
one week average compared to log

342
00:15:41,040 --> 00:15:43,339
and the automation are done

343
00:15:43,339 --> 00:15:46,620
automatically and dynamically so we just

344
00:15:46,620 --> 00:15:48,899
replicate all the menu monitoring and

345
00:15:48,899 --> 00:15:50,880
maintenance and we also have some

346
00:15:50,880 --> 00:15:53,579
heuristic based hand tuning rule in the

347
00:15:53,579 --> 00:15:55,320
code base and after the full deployment

348
00:15:55,320 --> 00:15:57,480
we also depreciate it

349
00:15:57,480 --> 00:16:00,120
and it becomes the foundation of many

350
00:16:00,120 --> 00:16:02,639
ongoing optimization for example the

351
00:16:02,639 --> 00:16:05,760
spatial prevention for closest Fresh

352
00:16:05,760 --> 00:16:06,779
cash

353
00:16:06,779 --> 00:16:09,420
and this is my talk today and I'm happy

354
00:16:09,420 --> 00:16:12,680
to answer any questions

