1
00:00:13,599 --> 00:00:16,480
hi i'm miyu from xiaozu university i am

2
00:00:16,480 --> 00:00:18,960
very glad to present our work zero chain

3
00:00:18,960 --> 00:00:21,199
object transmission for distributed big

4
00:00:21,199 --> 00:00:23,199
data analytics

5
00:00:23,199 --> 00:00:25,359
this work is done by me sure wong

6
00:00:25,359 --> 00:00:28,000
hypochon and binza

7
00:00:28,000 --> 00:00:30,160
the distributed big data analytics are

8
00:00:30,160 --> 00:00:32,800
widely used in many areas

9
00:00:32,800 --> 00:00:34,239
they can hide messy details on

10
00:00:34,239 --> 00:00:36,559
distributed data processing such as test

11
00:00:36,559 --> 00:00:38,320
scheduling resource management for

12
00:00:38,320 --> 00:00:40,559
tolerance and so on

13
00:00:40,559 --> 00:00:42,640
popular big data analytics framework

14
00:00:42,640 --> 00:00:46,000
include apache spark flink and hadoop

15
00:00:46,000 --> 00:00:48,000
those frameworks can make programming

16
00:00:48,000 --> 00:00:51,120
much easier so programmers can focus on

17
00:00:51,120 --> 00:00:55,360
business logic and data processing

18
00:00:55,360 --> 00:00:57,120
most frameworks are written in languages

19
00:00:57,120 --> 00:00:58,879
like java and scala

20
00:00:58,879 --> 00:01:01,280
to leverage their rich functionality and

21
00:01:01,280 --> 00:01:03,120
reliability

22
00:01:03,120 --> 00:01:04,799
they also rely on the runtime

23
00:01:04,799 --> 00:01:06,720
environment provided by language virtual

24
00:01:06,720 --> 00:01:07,680
machines

25
00:01:07,680 --> 00:01:11,960
the java attribution or jvms

26
00:01:12,400 --> 00:01:14,400
the workflow of big data processing is

27
00:01:14,400 --> 00:01:16,400
like that first

28
00:01:16,400 --> 00:01:18,720
we will launch managers and workers on

29
00:01:18,720 --> 00:01:20,320
various machines

30
00:01:20,320 --> 00:01:22,320
taking spark as an example

31
00:01:22,320 --> 00:01:24,960
suppose we want to launch one manager

32
00:01:24,960 --> 00:01:27,280
and three workers we will launch them on

33
00:01:27,280 --> 00:01:29,200
four different machines

34
00:01:29,200 --> 00:01:31,360
so the first step would be users

35
00:01:31,360 --> 00:01:33,680
uploading their applications to the

36
00:01:33,680 --> 00:01:36,079
spark manager the application is

37
00:01:36,079 --> 00:01:38,880
uploaded in a java format which contains

38
00:01:38,880 --> 00:01:41,119
the java class files which will be

39
00:01:41,119 --> 00:01:43,360
needed to execute our workers and

40
00:01:43,360 --> 00:01:45,759
managers

41
00:01:45,840 --> 00:01:48,399
once the manager finishes processing the

42
00:01:48,399 --> 00:01:51,520
java file it will send tasks into two

43
00:01:51,520 --> 00:01:53,680
different workers so that they can be

44
00:01:53,680 --> 00:01:56,640
parallel executed

45
00:01:57,040 --> 00:01:58,880
during the execution the workers may

46
00:01:58,880 --> 00:02:01,520
need to access data generated by other

47
00:02:01,520 --> 00:02:04,079
workers so spark will initiate the

48
00:02:04,079 --> 00:02:06,560
sharpening base which means that each

49
00:02:06,560 --> 00:02:08,560
worker will fetch data from other

50
00:02:08,560 --> 00:02:10,160
workers

51
00:02:10,160 --> 00:02:12,480
after finishing all the processing the

52
00:02:12,480 --> 00:02:15,360
workers will resend results back to the

53
00:02:15,360 --> 00:02:16,640
manager

54
00:02:16,640 --> 00:02:19,440
as we can see in a data processing phase

55
00:02:19,440 --> 00:02:20,800
all nodes actually frequently

56
00:02:20,800 --> 00:02:22,879
communicate with each other a worker

57
00:02:22,879 --> 00:02:24,800
communicates with other workers in the

58
00:02:24,800 --> 00:02:26,879
shuffling phase while at the beginning

59
00:02:26,879 --> 00:02:29,440
and the end a manager should communicate

60
00:02:29,440 --> 00:02:32,319
with all workers

61
00:02:32,319 --> 00:02:34,400
the communication can be costly and it

62
00:02:34,400 --> 00:02:37,840
becomes even worse for the jvm scenario

63
00:02:37,840 --> 00:02:40,000
this is because each jvm has its own way

64
00:02:40,000 --> 00:02:41,920
to represent java objects which can be

65
00:02:41,920 --> 00:02:43,680
divided into two parts

66
00:02:43,680 --> 00:02:45,360
the first part is header part which

67
00:02:45,360 --> 00:02:47,680
stores metadata for each object and the

68
00:02:47,680 --> 00:02:49,599
most important thing is to store and

69
00:02:49,599 --> 00:02:50,400
adjust

70
00:02:50,400 --> 00:02:52,720
to the object's type information it is

71
00:02:52,720 --> 00:02:55,519
called a chaos in opengdk

72
00:02:55,519 --> 00:02:58,080
the second part is data which can store

73
00:02:58,080 --> 00:03:00,160
references to other objects the

74
00:03:00,160 --> 00:03:02,400
reference is encoded as absolute virtual

75
00:03:02,400 --> 00:03:04,560
address of other objects

76
00:03:04,560 --> 00:03:06,239
both header and data different in

77
00:03:06,239 --> 00:03:07,840
different jvms

78
00:03:07,840 --> 00:03:11,680
so if we move an object to jvm1 to gmail

79
00:03:11,680 --> 00:03:13,280
to the object cannot be directly

80
00:03:13,280 --> 00:03:14,319
accessed

81
00:03:14,319 --> 00:03:16,640
because the galax are different and the

82
00:03:16,640 --> 00:03:18,879
objects are different and the gvm do not

83
00:03:18,879 --> 00:03:20,959
know how to interpret those fields and

84
00:03:20,959 --> 00:03:22,879
methods

85
00:03:22,879 --> 00:03:24,640
to solve this problem

86
00:03:24,640 --> 00:03:26,640
java has introduced an extra phase

87
00:03:26,640 --> 00:03:29,680
called serialization and deceleration or

88
00:03:29,680 --> 00:03:30,959
smd

89
00:03:30,959 --> 00:03:33,599
the civilization phase converts objects

90
00:03:33,599 --> 00:03:35,840
into by string which contains objects

91
00:03:35,840 --> 00:03:38,799
data and class information

92
00:03:38,799 --> 00:03:40,720
the by stream is in a general format

93
00:03:40,720 --> 00:03:43,519
agreed by all gbms

94
00:03:43,519 --> 00:03:45,840
as for deceleration the by stream will

95
00:03:45,840 --> 00:03:48,400
be converted back to objects so that the

96
00:03:48,400 --> 00:03:52,000
receiver can reuse those objects again

97
00:03:52,000 --> 00:03:55,519
the sd phase is quite costly

98
00:03:55,519 --> 00:03:58,080
for the simulation phase it traverses

99
00:03:58,080 --> 00:04:00,560
all reachable objects and pack them

100
00:04:00,560 --> 00:04:02,480
including their type information into

101
00:04:02,480 --> 00:04:04,159
byte arrays

102
00:04:04,159 --> 00:04:06,799
for deceleration you need to decode

103
00:04:06,799 --> 00:04:09,920
bytes and allocate new object store the

104
00:04:09,920 --> 00:04:12,159
decoded contents

105
00:04:12,159 --> 00:04:14,000
both separation and distribution are

106
00:04:14,000 --> 00:04:16,079
compute intensive and they cannot be

107
00:04:16,079 --> 00:04:18,000
improved by better network

108
00:04:18,000 --> 00:04:20,478
what's worse when the network bandwidth

109
00:04:20,478 --> 00:04:21,519
improves

110
00:04:21,519 --> 00:04:23,199
the network transmit transmission time

111
00:04:23,199 --> 00:04:25,360
can be reduced but the civilization and

112
00:04:25,360 --> 00:04:27,280
deceleration will become a severe

113
00:04:27,280 --> 00:04:28,560
bottleneck

114
00:04:28,560 --> 00:04:30,639
in our evaluation the sd phase can

115
00:04:30,639 --> 00:04:32,960
account for more than a half of the

116
00:04:32,960 --> 00:04:35,759
execution time for spark applications

117
00:04:35,759 --> 00:04:37,680
we also have some existing sd

118
00:04:37,680 --> 00:04:39,759
optimizations to improve the performance

119
00:04:39,759 --> 00:04:41,680
of sd

120
00:04:41,680 --> 00:04:44,080
crowd is an open source

121
00:04:44,080 --> 00:04:46,639
sd tool which improves our original java

122
00:04:46,639 --> 00:04:48,479
building tool

123
00:04:48,479 --> 00:04:50,800
it has optimized the layout of bible

124
00:04:50,800 --> 00:04:53,280
streams to make it more compact

125
00:04:53,280 --> 00:04:55,280
as can reduce the number of bytes

126
00:04:55,280 --> 00:04:56,400
transmitted

127
00:04:56,400 --> 00:04:58,720
however the transformation phases still

128
00:04:58,720 --> 00:05:01,120
exist which means that the java object

129
00:05:01,120 --> 00:05:03,600
is still needed to transmit

130
00:05:03,600 --> 00:05:06,400
in byte string and transform back to

131
00:05:06,400 --> 00:05:08,479
objects later

132
00:05:08,479 --> 00:05:11,440
scale away is an optimization on sd

133
00:05:11,440 --> 00:05:13,840
instead of sending binary formats

134
00:05:13,840 --> 00:05:16,320
it directly sends object graphs

135
00:05:16,320 --> 00:05:17,600
to achieve this

136
00:05:17,600 --> 00:05:19,759
it encodes and decodes type information

137
00:05:19,759 --> 00:05:23,280
and references during the sd phase

138
00:05:23,280 --> 00:05:25,120
this can simplify the transformation

139
00:05:25,120 --> 00:05:27,680
part by still requires transformation on

140
00:05:27,680 --> 00:05:31,280
references and type information

141
00:05:31,759 --> 00:05:34,400
now this is another optimization

142
00:05:34,400 --> 00:05:36,639
it's more rdma friendly which means that

143
00:05:36,639 --> 00:05:38,960
you can use the audience right to

144
00:05:38,960 --> 00:05:41,759
directly write object into the receiver

145
00:05:41,759 --> 00:05:44,400
machine however you still need

146
00:05:44,400 --> 00:05:46,880
references and type information

147
00:05:46,880 --> 00:05:50,160
fixed before using by the receiver

148
00:05:50,160 --> 00:05:51,919
although existing optimizations can

149
00:05:51,919 --> 00:05:54,320
improve the performance of sd

150
00:05:54,320 --> 00:05:56,080
it still requires the transformation

151
00:05:56,080 --> 00:05:58,720
between the sender and receiver

152
00:05:58,720 --> 00:06:00,960
so our question is that can we totally

153
00:06:00,960 --> 00:06:03,440
remove all the sd-related transformation

154
00:06:03,440 --> 00:06:05,280
to further improve the performance of

155
00:06:05,280 --> 00:06:08,800
acceleration and visualization

156
00:06:08,800 --> 00:06:12,080
so our solution is called vcot

157
00:06:12,080 --> 00:06:15,199
it is zero change object transmission

158
00:06:15,199 --> 00:06:17,440
which means that when a receiver

159
00:06:17,440 --> 00:06:19,840
receives objects they can be directly

160
00:06:19,840 --> 00:06:22,720
used without any change

161
00:06:22,720 --> 00:06:25,520
with our zclt mechanism the object can

162
00:06:25,520 --> 00:06:28,560
be directly read and written

163
00:06:28,560 --> 00:06:30,080
as the figure shows

164
00:06:30,080 --> 00:06:32,479
when a sender wants to send an object it

165
00:06:32,479 --> 00:06:35,039
can directly write an object into a

166
00:06:35,039 --> 00:06:36,720
given address

167
00:06:36,720 --> 00:06:38,800
afterwards the receiver can directly

168
00:06:38,800 --> 00:06:41,680
read object on the same address

169
00:06:41,680 --> 00:06:44,319
without any change

170
00:06:44,319 --> 00:06:48,479
so how to achieve the 0t mechanism

171
00:06:48,479 --> 00:06:50,960
first we require that each of them has a

172
00:06:50,960 --> 00:06:52,080
shared space

173
00:06:52,080 --> 00:06:54,560
we call it exchange space it is only

174
00:06:54,560 --> 00:06:59,360
used for communications among gbms

175
00:06:59,360 --> 00:07:01,919
since the exchange space is shared by

176
00:07:01,919 --> 00:07:04,400
different jvms and all jvms share the

177
00:07:04,400 --> 00:07:06,639
same view on exchange space the objects

178
00:07:06,639 --> 00:07:08,880
can be directly accessed without pointer

179
00:07:08,880 --> 00:07:10,639
fixing when they are stored in exchange

180
00:07:10,639 --> 00:07:12,160
space

181
00:07:12,160 --> 00:07:14,560
of course we also use a purchase and

182
00:07:14,560 --> 00:07:16,400
private space so they can be used for

183
00:07:16,400 --> 00:07:18,319
normal allocation while applications

184
00:07:18,319 --> 00:07:20,240
does not need communication with other

185
00:07:20,240 --> 00:07:22,000
jbms

186
00:07:22,000 --> 00:07:23,599
now the exchange space can solve the

187
00:07:23,599 --> 00:07:25,840
reference fixing problem but what about

188
00:07:25,840 --> 00:07:28,880
class pointers in a header

189
00:07:28,880 --> 00:07:30,800
to solve this problem the exchange space

190
00:07:30,800 --> 00:07:33,120
should contain a class subspace

191
00:07:33,120 --> 00:07:35,039
which source type information used by

192
00:07:35,039 --> 00:07:38,080
all objects in use chain space

193
00:07:38,080 --> 00:07:40,560
so when an object is stored into the

194
00:07:40,560 --> 00:07:42,720
exchange space or the object subspace in

195
00:07:42,720 --> 00:07:43,759
the figure

196
00:07:43,759 --> 00:07:46,160
no class pointer is required to fix

197
00:07:46,160 --> 00:07:48,400
because all chaos are stored in a class

198
00:07:48,400 --> 00:07:50,880
subspace

199
00:07:50,880 --> 00:07:53,440
the basic idea of ccot might be

200
00:07:53,440 --> 00:07:55,919
straightforward but it is not very easy

201
00:07:55,919 --> 00:07:58,879
to realize clt have at least some

202
00:07:58,879 --> 00:08:00,000
challenges

203
00:08:00,000 --> 00:08:02,000
the first one is how to construct a

204
00:08:02,000 --> 00:08:04,400
shared space for all javas

205
00:08:04,400 --> 00:08:06,879
second is how to remain compatible with

206
00:08:06,879 --> 00:08:09,360
existing applications like spark

207
00:08:09,360 --> 00:08:11,840
third is how to manage memory resources

208
00:08:11,840 --> 00:08:13,360
among gpms

209
00:08:13,360 --> 00:08:17,199
especially in a distributed environment

210
00:08:17,360 --> 00:08:19,599
to construct a space shared by multiple

211
00:08:19,599 --> 00:08:23,440
jvms we use a mechanism called dcds or

212
00:08:23,440 --> 00:08:25,840
distributed class they are sharing

213
00:08:25,840 --> 00:08:27,919
it actually extends the built-in

214
00:08:27,919 --> 00:08:30,000
application class data sharing mechanism

215
00:08:30,000 --> 00:08:32,880
in opengk to support distributed sharing

216
00:08:32,880 --> 00:08:36,159
in both class and objects

217
00:08:36,159 --> 00:08:38,799
first we generate a class archive from

218
00:08:38,799 --> 00:08:41,360
user java through the abb cds tools

219
00:08:41,360 --> 00:08:44,159
provided by opengdp community

220
00:08:44,159 --> 00:08:46,560
secondly we distribute the class archive

221
00:08:46,560 --> 00:08:48,399
into different jbms

222
00:08:48,399 --> 00:08:50,399
the class archive actually contains all

223
00:08:50,399 --> 00:08:52,240
classes which will be used in

224
00:08:52,240 --> 00:08:54,560
communication later

225
00:08:54,560 --> 00:08:57,120
thirdly when the jvms are launched they

226
00:08:57,120 --> 00:08:59,360
will map the outcast archive into the

227
00:08:59,360 --> 00:09:01,519
same address and construct class

228
00:09:01,519 --> 00:09:04,560
subspace and object subspace

229
00:09:04,560 --> 00:09:07,200
so from now on we will generate a share

230
00:09:07,200 --> 00:09:10,000
exchange space for all jvms on the same

231
00:09:10,000 --> 00:09:12,320
recharges

232
00:09:12,320 --> 00:09:13,760
so the second challenge is the

233
00:09:13,760 --> 00:09:17,040
compatibility with existing applications

234
00:09:17,040 --> 00:09:19,120
we have known that vcot sends and

235
00:09:19,120 --> 00:09:21,360
received our data in your object format

236
00:09:21,360 --> 00:09:23,760
however existing applications like spark

237
00:09:23,760 --> 00:09:27,920
and link still use smd interfaces

238
00:09:27,920 --> 00:09:29,360
simulation

239
00:09:29,360 --> 00:09:30,160
use

240
00:09:30,160 --> 00:09:32,640
interfaces like right objects which

241
00:09:32,640 --> 00:09:35,839
writes objects into a byte output stream

242
00:09:35,839 --> 00:09:38,720
this variation uses read object which

243
00:09:38,720 --> 00:09:40,959
reads from a byte input string and

244
00:09:40,959 --> 00:09:44,800
conversion to a object

245
00:09:44,800 --> 00:09:47,120
so this problem is that how to remain

246
00:09:47,120 --> 00:09:49,760
compatible with this ot's object-based

247
00:09:49,760 --> 00:09:52,080
mechanism

248
00:09:52,080 --> 00:09:54,399
to resolve the compatibility problem the

249
00:09:54,399 --> 00:09:56,560
clt solution is two level data

250
00:09:56,560 --> 00:09:57,839
transmission

251
00:09:57,839 --> 00:09:59,920
which means that the clt's transmission

252
00:09:59,920 --> 00:10:03,279
is divided into front and back

253
00:10:03,279 --> 00:10:05,600
in the front end until this ot tries to

254
00:10:05,600 --> 00:10:07,760
remain compatible with original sd

255
00:10:07,760 --> 00:10:09,200
interfaces

256
00:10:09,200 --> 00:10:11,839
suppose we want to copy an object whose

257
00:10:11,839 --> 00:10:15,120
starter address is 0x 3000

258
00:10:15,120 --> 00:10:17,360
we still use the output string and input

259
00:10:17,360 --> 00:10:19,920
string to transmit by buffers

260
00:10:19,920 --> 00:10:22,320
but the data is actually some simple

261
00:10:22,320 --> 00:10:24,160
metadata

262
00:10:24,160 --> 00:10:26,240
in this example we store the start

263
00:10:26,240 --> 00:10:29,040
address and the whole length of the

264
00:10:29,040 --> 00:10:31,200
object into the output stream it will be

265
00:10:31,200 --> 00:10:33,600
sent to the receiver while the input

266
00:10:33,600 --> 00:10:35,920
string

267
00:10:35,920 --> 00:10:38,399
meanwhile the backhand actually sends

268
00:10:38,399 --> 00:10:41,440
and receive real objects

269
00:10:41,440 --> 00:10:43,680
dcot will allocate send buffer and

270
00:10:43,680 --> 00:10:45,360
receive buffer for the sender and

271
00:10:45,360 --> 00:10:46,560
receiver

272
00:10:46,560 --> 00:10:49,120
and it will be used to send data through

273
00:10:49,120 --> 00:10:51,519
different jvms whose length is equal to

274
00:10:51,519 --> 00:10:55,120
the metadata in the frontend sending

275
00:10:55,120 --> 00:10:57,760
now the search engine is match memory in

276
00:10:57,760 --> 00:11:00,320
a distributed environment

277
00:11:00,320 --> 00:11:02,959
dclt uses a metadata server to manage

278
00:11:02,959 --> 00:11:04,800
the exchange space

279
00:11:04,800 --> 00:11:07,839
the basic unit for management is chalk

280
00:11:07,839 --> 00:11:10,079
since this ot is mainly designed for big

281
00:11:10,079 --> 00:11:13,399
data analytics 34 size quite large it's

282
00:11:13,399 --> 00:11:16,240
256 megabytes

283
00:11:16,240 --> 00:11:17,839
this ot further

284
00:11:17,839 --> 00:11:20,640
uses a location map which mark if a

285
00:11:20,640 --> 00:11:22,399
chunk has been allocated

286
00:11:22,399 --> 00:11:24,160
for each beat

287
00:11:24,160 --> 00:11:26,640
this lt also uses a chunk mapping table

288
00:11:26,640 --> 00:11:31,120
to mark which vms has a copy of a chunk

289
00:11:31,120 --> 00:11:33,600
in the example it shows that the chunk y

290
00:11:33,600 --> 00:11:36,640
is copied by the jvm1 and chunk 4 is

291
00:11:36,640 --> 00:11:39,360
copied by jvm0

292
00:11:39,360 --> 00:11:42,000
slt also needs to maintain some member

293
00:11:42,000 --> 00:11:44,320
table which contains information or for

294
00:11:44,320 --> 00:11:46,160
all java virtual machines

295
00:11:46,160 --> 00:11:48,240
in the member table we can find the ip

296
00:11:48,240 --> 00:11:50,720
and the port of different jvms they can

297
00:11:50,720 --> 00:11:52,240
be used to maintain compatible

298
00:11:52,240 --> 00:11:54,880
communications and connections between

299
00:11:54,880 --> 00:11:56,720
different jvms

300
00:11:56,720 --> 00:11:59,120
upon the data structure the media server

301
00:11:59,120 --> 00:12:02,320
provides four rpc interfaces for gvms

302
00:12:02,320 --> 00:12:04,560
the first one is register which is used

303
00:12:04,560 --> 00:12:07,600
to register jvm into the memory table it

304
00:12:07,600 --> 00:12:11,040
is usually used when jvm is launched

305
00:12:11,040 --> 00:12:13,360
the second one is acquired which acquire

306
00:12:13,360 --> 00:12:17,040
a new chunk from the method server

307
00:12:17,040 --> 00:12:19,760
the third one is kit remote which gets a

308
00:12:19,760 --> 00:12:22,240
remote chunk from other jvms

309
00:12:22,240 --> 00:12:24,720
although other jvms actually contain

310
00:12:24,720 --> 00:12:27,040
copies for different chunks

311
00:12:27,040 --> 00:12:29,519
it still needs coordination from the

312
00:12:29,519 --> 00:12:31,360
maintenance server so we provide this

313
00:12:31,360 --> 00:12:33,200
rpc

314
00:12:33,200 --> 00:12:35,600
the fourth one is release which releases

315
00:12:35,600 --> 00:12:37,279
a chunk to the millennium server when

316
00:12:37,279 --> 00:12:40,320
these loans are used

317
00:12:40,320 --> 00:12:42,639
since rpc interfaces manage the memory

318
00:12:42,639 --> 00:12:44,720
and distributing environment it needs to

319
00:12:44,720 --> 00:12:46,800
be integrated with many amendments of

320
00:12:46,800 --> 00:12:49,440
individual gpms for example

321
00:12:49,440 --> 00:12:51,760
the garbage collection of a jvm should

322
00:12:51,760 --> 00:12:53,920
invoke the release rpc when you find

323
00:12:53,920 --> 00:12:57,040
that all objects in a chunk is no longer

324
00:12:57,040 --> 00:12:59,200
reachable

325
00:12:59,200 --> 00:13:01,040
now we have introduced the challenges of

326
00:13:01,040 --> 00:13:03,839
vcot and how to resolve them we will use

327
00:13:03,839 --> 00:13:06,880
an example to show how this co2 works

328
00:13:06,880 --> 00:13:08,959
with the sender and the receiver

329
00:13:08,959 --> 00:13:10,320
we can see that

330
00:13:10,320 --> 00:13:12,079
both the sender and receiver has a

331
00:13:12,079 --> 00:13:14,320
private space for normal allocation and

332
00:13:14,320 --> 00:13:16,160
the share of the same view on the

333
00:13:16,160 --> 00:13:17,920
exchange space

334
00:13:17,920 --> 00:13:20,160
meanwhile there are also a media server

335
00:13:20,160 --> 00:13:22,959
to serve the distributed allocation for

336
00:13:22,959 --> 00:13:25,920
sender and receiver

337
00:13:26,079 --> 00:13:27,760
suppose the sender wants to send an

338
00:13:27,760 --> 00:13:28,720
object

339
00:13:28,720 --> 00:13:30,959
it will first acquire chunks

340
00:13:30,959 --> 00:13:32,959
from the media server through the

341
00:13:32,959 --> 00:13:34,800
acquire api

342
00:13:34,800 --> 00:13:36,639
when the main hana server receives

343
00:13:36,639 --> 00:13:38,880
acquire api you will first allocate a

344
00:13:38,880 --> 00:13:42,160
chunk suppose the change address is

345
00:13:42,160 --> 00:13:44,320
0x 10 000

346
00:13:44,320 --> 00:13:46,320
afterwards it will maintain a trunk

347
00:13:46,320 --> 00:13:49,279
mapping table to mark that jvm1 owns a

348
00:13:49,279 --> 00:13:54,240
chunk 1 whose address is 0x 10000

349
00:13:54,240 --> 00:13:56,480
when receiving the charge sender will

350
00:13:56,480 --> 00:13:59,040
copy an object from the private space to

351
00:13:59,040 --> 00:14:01,360
exchange space whose address is given by

352
00:14:01,360 --> 00:14:03,120
response

353
00:14:03,120 --> 00:14:05,920
after copying they also would maintain

354
00:14:05,920 --> 00:14:07,920
some metadata

355
00:14:07,920 --> 00:14:10,000
including the start address and the

356
00:14:10,000 --> 00:14:12,480
length of objects

357
00:14:12,480 --> 00:14:15,519
afterwards the sender will send

358
00:14:15,519 --> 00:14:16,880
through the output stream and input

359
00:14:16,880 --> 00:14:19,839
string without the front-end sending

360
00:14:19,839 --> 00:14:22,160
now the receiver will receive the melody

361
00:14:22,160 --> 00:14:24,079
and use it later

362
00:14:24,079 --> 00:14:26,480
since the metadata in the front-end

363
00:14:26,480 --> 00:14:28,800
sending has contained the star address

364
00:14:28,800 --> 00:14:31,519
of an object receiver now can access the

365
00:14:31,519 --> 00:14:33,600
objects at the given address

366
00:14:33,600 --> 00:14:35,519
however since the real data is not

367
00:14:35,519 --> 00:14:38,079
transmitted yet that test will cause a

368
00:14:38,079 --> 00:14:40,639
page fault on the receiver side

369
00:14:40,639 --> 00:14:42,480
when a page fault is triggered the

370
00:14:42,480 --> 00:14:44,880
receiver will go into a pre-registered

371
00:14:44,880 --> 00:14:47,680
patchbot handler which sends a remote

372
00:14:47,680 --> 00:14:50,959
rpc to to the metadata server

373
00:14:50,959 --> 00:14:53,279
the media0 will find that the given

374
00:14:53,279 --> 00:14:56,000
address is chunk1 and the jvm1 has a

375
00:14:56,000 --> 00:14:59,360
copy of chunk1 so it forwards the rpc to

376
00:14:59,360 --> 00:15:03,440
the sender actually the jvm1

377
00:15:03,440 --> 00:15:04,560
finally

378
00:15:04,560 --> 00:15:07,360
chain 1 ascender will send the chunk 1

379
00:15:07,360 --> 00:15:08,720
to the receiver

380
00:15:08,720 --> 00:15:10,639
at the given address

381
00:15:10,639 --> 00:15:12,560
now the receiver can directly access

382
00:15:12,560 --> 00:15:16,638
those objects and without any change

383
00:15:17,760 --> 00:15:19,839
now i have introduced the basic workflow

384
00:15:19,839 --> 00:15:22,480
of the cot but we actually could discuss

385
00:15:22,480 --> 00:15:24,399
many details in our paper

386
00:15:24,399 --> 00:15:26,880
for example we discuss how data should

387
00:15:26,880 --> 00:15:29,839
be persisted if the application required

388
00:15:29,839 --> 00:15:32,480
we also discuss good-based prefetching

389
00:15:32,480 --> 00:15:34,720
so that we can reduce the number of page

390
00:15:34,720 --> 00:15:37,120
faults and reduce the overhead

391
00:15:37,120 --> 00:15:39,360
i also discuss how to integrate vcot

392
00:15:39,360 --> 00:15:40,399
with gc

393
00:15:40,399 --> 00:15:44,240
so that the gc overhead will be large

394
00:15:44,240 --> 00:15:46,560
we also find that the data transmitted

395
00:15:46,560 --> 00:15:49,360
in different runs maybe duplicate and

396
00:15:49,360 --> 00:15:51,519
implement a data duplication

397
00:15:51,519 --> 00:15:52,959
optimization

398
00:15:52,959 --> 00:15:54,720
for all those details please check our

399
00:15:54,720 --> 00:15:56,959
paper

400
00:15:56,959 --> 00:15:59,199
as for evaluation we use a cluster with

401
00:15:59,199 --> 00:16:01,360
four nodes for evaluation

402
00:16:01,360 --> 00:16:04,560
it contains 100 gigabits network cards

403
00:16:04,560 --> 00:16:07,440
and each node contains two cpus and 128

404
00:16:07,440 --> 00:16:09,440
gigabytes drag

405
00:16:09,440 --> 00:16:11,360
and fold evaluation with three different

406
00:16:11,360 --> 00:16:13,279
evaluations the first one is micro

407
00:16:13,279 --> 00:16:16,160
benchmark and the the two and the other

408
00:16:16,160 --> 00:16:18,160
choose a spark and flink

409
00:16:18,160 --> 00:16:20,079
the micro benchmark use the mic perp

410
00:16:20,079 --> 00:16:22,720
tester from now for evaluation

411
00:16:22,720 --> 00:16:24,880
the microperv civilized and designates

412
00:16:24,880 --> 00:16:27,120
different kinds of data structure and

413
00:16:27,120 --> 00:16:29,440
sentence through network and evaluate

414
00:16:29,440 --> 00:16:31,199
performance

415
00:16:31,199 --> 00:16:33,279
since it only contains some simple data

416
00:16:33,279 --> 00:16:36,320
structure we use a data structure called

417
00:16:36,320 --> 00:16:39,600
media files from the skyway to test this

418
00:16:39,600 --> 00:16:41,040
performance

419
00:16:41,040 --> 00:16:42,399
we evaluate

420
00:16:42,399 --> 00:16:44,480
uh zclt against four information

421
00:16:44,480 --> 00:16:46,880
baselines the java built-in serializer

422
00:16:46,880 --> 00:16:48,160
or jso

423
00:16:48,160 --> 00:16:51,839
crown skyway announced

424
00:16:51,839 --> 00:16:53,519
the performance show that

425
00:16:53,519 --> 00:16:55,920
this crt can improve transmission phases

426
00:16:55,920 --> 00:16:58,480
against all baselines

427
00:16:58,480 --> 00:17:00,160
the average improvement compared with

428
00:17:00,160 --> 00:17:03,839
snails is 2.28 times

429
00:17:03,839 --> 00:17:06,480
for spark we first find that it is easy

430
00:17:06,480 --> 00:17:07,919
to integrate

431
00:17:07,919 --> 00:17:11,760
the zclt into spark code base

432
00:17:11,760 --> 00:17:14,799
since eclt is compatible with spark's sd

433
00:17:14,799 --> 00:17:17,599
interface we only need to implement a

434
00:17:17,599 --> 00:17:20,160
decision visor in place of the original

435
00:17:20,160 --> 00:17:22,720
cryo theorizer and the java stabilizer

436
00:17:22,720 --> 00:17:24,559
and config the spark to use this

437
00:17:24,559 --> 00:17:27,359
systemizer instead of others

438
00:17:27,359 --> 00:17:29,440
the number of codes of this systemizer

439
00:17:29,440 --> 00:17:32,240
is only 70.

440
00:17:32,240 --> 00:17:35,280
and for evaluation results we find that

441
00:17:35,280 --> 00:17:37,039
application execution time can be

442
00:17:37,039 --> 00:17:40,080
improved by 13.9

443
00:17:40,080 --> 00:17:42,880
average on five applications against

444
00:17:42,880 --> 00:17:45,360
cryo which is the default civilizer in

445
00:17:45,360 --> 00:17:47,039
spark

446
00:17:47,039 --> 00:17:49,039
we have broken down the

447
00:17:49,039 --> 00:17:51,600
application time and we find that in the

448
00:17:51,600 --> 00:17:52,880
right part which contains the

449
00:17:52,880 --> 00:17:54,799
civilization phase

450
00:17:54,799 --> 00:17:56,880
this ot can reach

451
00:17:56,880 --> 00:17:58,400
four point nineteen times speed up

452
00:17:58,400 --> 00:18:01,120
compare required and for the real part

453
00:18:01,120 --> 00:18:05,679
the speed speed up is 2.95 times

454
00:18:05,679 --> 00:18:08,000
and for fling's performance we evaluate

455
00:18:08,000 --> 00:18:10,320
it with four different chords in tpc

456
00:18:10,320 --> 00:18:11,200
edge

457
00:18:11,200 --> 00:18:12,559
you can find that

458
00:18:12,559 --> 00:18:15,200
zlt can receive twenty two point two

459
00:18:15,200 --> 00:18:16,960
percent improvement at the best in a

460
00:18:16,960 --> 00:18:19,039
quarter ten

461
00:18:19,039 --> 00:18:21,440
actually the improvement is less

462
00:18:21,440 --> 00:18:23,600
compared with spark this is because the

463
00:18:23,600 --> 00:18:26,559
flink sd interfaces and the libraries is

464
00:18:26,559 --> 00:18:28,480
manually optimized

465
00:18:28,480 --> 00:18:30,960
however even those are mentally

466
00:18:30,960 --> 00:18:33,520
optimized this od can still receive some

467
00:18:33,520 --> 00:18:35,520
improvement

468
00:18:35,520 --> 00:18:37,919
okay to conclude the data transmission

469
00:18:37,919 --> 00:18:40,320
phase is actually very costly in big

470
00:18:40,320 --> 00:18:42,880
data analytics especially in distributed

471
00:18:42,880 --> 00:18:44,559
environments

472
00:18:44,559 --> 00:18:47,120
the scenario becomes more severe in java

473
00:18:47,120 --> 00:18:49,679
because of the extra civilization and

474
00:18:49,679 --> 00:18:52,720
the deceleration phase of sd

475
00:18:52,720 --> 00:18:55,200
in this world we propose dcot

476
00:18:55,200 --> 00:18:57,600
zero change object transmission

477
00:18:57,600 --> 00:18:59,840
which sends and receive objects through

478
00:18:59,840 --> 00:19:01,840
a shared exchange space

479
00:19:01,840 --> 00:19:02,640
when

480
00:19:02,640 --> 00:19:04,559
a receiver receive objects they can

481
00:19:04,559 --> 00:19:06,160
directly use them without any

482
00:19:06,160 --> 00:19:08,640
transformation and changing

483
00:19:08,640 --> 00:19:10,720
besides this lte also remains compatible

484
00:19:10,720 --> 00:19:13,520
with existing sd interfaces

485
00:19:13,520 --> 00:19:15,760
the evaluation shows that dcld can

486
00:19:15,760 --> 00:19:18,480
receive significant speed up against

487
00:19:18,480 --> 00:19:22,000
sd libraries and existing optimizations

488
00:19:22,000 --> 00:19:23,919
thank you for listening and i'm ready to

489
00:19:23,919 --> 00:19:27,080
take questions

