1
00:00:09,760 --> 00:00:12,639
hi

2
00:00:10,160 --> 00:00:14,480
i'm mim wu from shanghai university i'm

3
00:00:12,639 --> 00:00:16,160
happy to share our work platinum

4
00:00:14,480 --> 00:00:17,680
a cpu efficient concurrent garbage

5
00:00:16,160 --> 00:00:19,359
collector or tail reduction of

6
00:00:17,680 --> 00:00:20,960
interactive services

7
00:00:19,359 --> 00:00:24,000
this is a joint work from shanghai

8
00:00:20,960 --> 00:00:26,640
university and alibaba group

9
00:00:24,000 --> 00:00:28,320
for ease of maintenance and deployment

10
00:00:26,640 --> 00:00:29,199
applications in cloud have been split

11
00:00:28,320 --> 00:00:31,840
into small

12
00:00:29,199 --> 00:00:33,760
single purpose and interactive services

13
00:00:31,840 --> 00:00:36,000
so a single user request may rely on the

14
00:00:33,760 --> 00:00:38,320
corporation of multiple services

15
00:00:36,000 --> 00:00:40,239
for example one user wants to check out

16
00:00:38,320 --> 00:00:40,800
he or she will go to the checkout page

17
00:00:40,239 --> 00:00:42,718
on its

18
00:00:40,800 --> 00:00:44,959
cell phone which is actually rendered by

19
00:00:42,719 --> 00:00:46,960
many services such as the coupon service

20
00:00:44,960 --> 00:00:49,360
to calculate the most cost effective

21
00:00:46,960 --> 00:00:50,160
coupons the cost service to list all

22
00:00:49,360 --> 00:00:51,839
items

23
00:00:50,160 --> 00:00:55,199
and the recommendation service to

24
00:00:51,840 --> 00:00:57,840
recommend items user might be interested

25
00:00:55,199 --> 00:00:58,879
besides the services may interact with a

26
00:00:57,840 --> 00:01:02,719
cache services

27
00:00:58,879 --> 00:01:03,680
to retrieve data since java has many

28
00:01:02,719 --> 00:01:06,720
advantages like

29
00:01:03,680 --> 00:01:09,119
portability and reliability in alibaba

30
00:01:06,720 --> 00:01:10,240
most online services are written in java

31
00:01:09,119 --> 00:01:12,080
which means that

32
00:01:10,240 --> 00:01:14,240
those services are all managed by the

33
00:01:12,080 --> 00:01:16,158
java runtime the jvm

34
00:01:14,240 --> 00:01:18,560
so the performance of services will be

35
00:01:16,159 --> 00:01:20,799
affected by modules in gmail

36
00:01:18,560 --> 00:01:22,880
if a service is paused by jvm other

37
00:01:20,799 --> 00:01:24,560
services will also be affected

38
00:01:22,880 --> 00:01:27,199
and the user may find that the page

39
00:01:24,560 --> 00:01:28,960
fails to be loaded

40
00:01:27,200 --> 00:01:31,360
garbage collection is one of the cases

41
00:01:28,960 --> 00:01:33,600
where the applications should be paused

42
00:01:31,360 --> 00:01:36,560
it is automatic memory management module

43
00:01:33,600 --> 00:01:38,960
in language runtimes such as jvm

44
00:01:36,560 --> 00:01:40,240
in java private government collectors

45
00:01:38,960 --> 00:01:42,240
you stop the word

46
00:01:40,240 --> 00:01:43,520
as the extrusion flow shows

47
00:01:42,240 --> 00:01:46,240
multiplication threats

48
00:01:43,520 --> 00:01:47,039
or mutators around me genetic cells are

49
00:01:46,240 --> 00:01:49,199
idle

50
00:01:47,040 --> 00:01:51,200
when jesus is triggered all muslims will

51
00:01:49,200 --> 00:01:52,880
be paused so that jesus threats can

52
00:01:51,200 --> 00:01:54,799
reclaim the memory

53
00:01:52,880 --> 00:01:57,679
the advantage of the stop the world she

54
00:01:54,799 --> 00:02:00,079
says that since all mutators are paused

55
00:01:57,680 --> 00:02:01,920
genesis can monopoly the cpu resources

56
00:02:00,079 --> 00:02:05,039
and achieve high gst throughput

57
00:02:01,920 --> 00:02:06,960
and satisfy cpu efficiency however

58
00:02:05,040 --> 00:02:08,800
since applications are paused during the

59
00:02:06,960 --> 00:02:10,318
whole gc the latency

60
00:02:08,800 --> 00:02:13,920
especially the tail latency for

61
00:02:10,318 --> 00:02:13,920
applications will be affected

62
00:02:14,319 --> 00:02:18,238
we have evaluated coupon service in

63
00:02:16,239 --> 00:02:19,200
alibaba to study the relationship

64
00:02:18,239 --> 00:02:21,760
between gc

65
00:02:19,200 --> 00:02:23,200
and application latency we run the

66
00:02:21,760 --> 00:02:25,920
service for 30 seconds

67
00:02:23,200 --> 00:02:27,119
and collect the latency for each request

68
00:02:25,920 --> 00:02:29,519
in the left figure

69
00:02:27,120 --> 00:02:30,640
each black dot stands for request and

70
00:02:29,520 --> 00:02:33,280
the vertical red line

71
00:02:30,640 --> 00:02:34,559
stands for garbage collection when she

72
00:02:33,280 --> 00:02:36,959
says pause happens

73
00:02:34,560 --> 00:02:38,000
the latency of request fluctuates

74
00:02:36,959 --> 00:02:40,000
dramatically

75
00:02:38,000 --> 00:02:41,680
and as the right figure shows those

76
00:02:40,000 --> 00:02:43,200
requests cause a long tail of the

77
00:02:41,680 --> 00:02:44,720
execution

78
00:02:43,200 --> 00:02:46,480
note that the coupon service is running

79
00:02:44,720 --> 00:02:49,280
with other services so

80
00:02:46,480 --> 00:02:49,518
it also interacts with others to network

81
00:02:49,280 --> 00:02:52,319
and

82
00:02:49,519 --> 00:02:53,120
you also use this i o to access files

83
00:02:52,319 --> 00:02:55,119
however

84
00:02:53,120 --> 00:02:58,720
our invention shows that gce is the

85
00:02:55,120 --> 00:02:58,720
killer factor for television

86
00:02:58,879 --> 00:03:01,920
since gc process affect the television

87
00:03:00,959 --> 00:03:04,080
of services

88
00:03:01,920 --> 00:03:06,559
a solution is to allow mutators to

89
00:03:04,080 --> 00:03:09,680
execute during garbage detection

90
00:03:06,560 --> 00:03:11,680
this kind of gc is called concurrent gc

91
00:03:09,680 --> 00:03:13,680
concurrent gc can be classified into two

92
00:03:11,680 --> 00:03:16,800
categories partial concurrent

93
00:03:13,680 --> 00:03:17,440
and mostly concurrent partial concurrent

94
00:03:16,800 --> 00:03:19,200
gc

95
00:03:17,440 --> 00:03:20,560
allow materials to execute in some

96
00:03:19,200 --> 00:03:23,440
phases in gc

97
00:03:20,560 --> 00:03:24,319
a typical example is g1 as the execution

98
00:03:23,440 --> 00:03:26,720
flow shows

99
00:03:24,319 --> 00:03:28,480
in the first part of gc mutators can run

100
00:03:26,720 --> 00:03:30,400
concurrently with gt threats

101
00:03:28,480 --> 00:03:32,399
but for the second part the material

102
00:03:30,400 --> 00:03:34,239
will have to pause

103
00:03:32,400 --> 00:03:36,239
to reduce the duration of the stop the

104
00:03:34,239 --> 00:03:37,200
word process partially concurrent

105
00:03:36,239 --> 00:03:39,200
collectors provide

106
00:03:37,200 --> 00:03:42,480
arguments for user to till the maximum

107
00:03:39,200 --> 00:03:42,480
limit on gc process

108
00:03:43,120 --> 00:03:46,400
the second category is mostly concurrent

109
00:03:45,360 --> 00:03:48,400
collectors

110
00:03:46,400 --> 00:03:50,080
and the typical example is shenandoah

111
00:03:48,400 --> 00:03:53,120
agency which is a new gc

112
00:03:50,080 --> 00:03:55,519
open jk in most concurrent

113
00:03:53,120 --> 00:03:57,280
collectors materials can execute nearly

114
00:03:55,519 --> 00:03:59,920
all g-surfaces

115
00:03:57,280 --> 00:04:00,480
as the extrusion flow shows mutators can

116
00:03:59,920 --> 00:04:02,559
need

117
00:04:00,480 --> 00:04:04,079
only need two ports for very short time

118
00:04:02,560 --> 00:04:07,040
when genitals try to achieve some

119
00:04:04,080 --> 00:04:07,040
simulation points

120
00:04:07,920 --> 00:04:11,439
since concurrent gc can reduce the

121
00:04:09,920 --> 00:04:13,439
duration of process

122
00:04:11,439 --> 00:04:15,680
is it always careful to reduce the tail

123
00:04:13,439 --> 00:04:16,639
latency we have evaluated those two

124
00:04:15,680 --> 00:04:18,079
kinds of gc

125
00:04:16,639 --> 00:04:19,680
with a straightforward load in the

126
00:04:18,079 --> 00:04:22,720
coupon service

127
00:04:19,680 --> 00:04:23,919
for g1 we tune its argument maximum gc

128
00:04:22,720 --> 00:04:27,759
plus millisecond

129
00:04:23,919 --> 00:04:29,680
to restrict the maximum gz pulse time

130
00:04:27,759 --> 00:04:30,479
will reduce argument from 60

131
00:04:29,680 --> 00:04:33,280
milliseconds

132
00:04:30,479 --> 00:04:36,639
to 30 milliseconds the minimum and the

133
00:04:33,280 --> 00:04:39,440
average is a part decrease

134
00:04:36,639 --> 00:04:40,400
however the number of gc is enlarged by

135
00:04:39,440 --> 00:04:42,240
five times

136
00:04:40,400 --> 00:04:43,440
and the accumulated gdp actually

137
00:04:42,240 --> 00:04:45,680
increases

138
00:04:43,440 --> 00:04:47,120
this means that gz threats are consuming

139
00:04:45,680 --> 00:04:49,360
more cpu resources

140
00:04:47,120 --> 00:04:51,919
so the average cpu utilization also

141
00:04:49,360 --> 00:04:51,919
increases

142
00:04:52,160 --> 00:04:56,560
as a result although the argument is

143
00:04:54,160 --> 00:04:58,560
helpful to reduce purchasing plus time

144
00:04:56,560 --> 00:05:01,600
the tail relationship the tail latency

145
00:04:58,560 --> 00:05:01,600
actually becomes worse

146
00:05:02,720 --> 00:05:06,800
for the mostly concurrent gc the

147
00:05:04,320 --> 00:05:09,360
situation actually becomes worse

148
00:05:06,800 --> 00:05:11,360
we have evaluated shenandoah with the

149
00:05:09,360 --> 00:05:14,160
same workload as g1

150
00:05:11,360 --> 00:05:14,720
compared with g1 the 30 millisecond

151
00:05:14,160 --> 00:05:16,560
setting

152
00:05:14,720 --> 00:05:18,320
the gz process in shenandoah are much

153
00:05:16,560 --> 00:05:22,080
shorter both the

154
00:05:18,320 --> 00:05:25,199
minimum gc pulse and average is impulse

155
00:05:22,080 --> 00:05:27,440
however its gc duration is quite long

156
00:05:25,199 --> 00:05:28,240
the duration of the evaluation is 60

157
00:05:27,440 --> 00:05:30,080
seconds

158
00:05:28,240 --> 00:05:32,880
while the gz thread are active in more

159
00:05:30,080 --> 00:05:34,960
than 53 seconds for shenandoah

160
00:05:32,880 --> 00:05:38,000
so the average cpu realization is in

161
00:05:34,960 --> 00:05:39,758
shenandoah is quite high

162
00:05:38,000 --> 00:05:41,280
and as a result the television for

163
00:05:39,759 --> 00:05:43,600
shenandoah is even worse

164
00:05:41,280 --> 00:05:47,039
than the world stating the 30 minutes

165
00:05:43,600 --> 00:05:47,039
millisecond setting of g1

166
00:05:47,520 --> 00:05:51,758
we have listed three important reasons

167
00:05:49,680 --> 00:05:52,479
on why concurrent collectors are less

168
00:05:51,759 --> 00:05:54,560
efficient

169
00:05:52,479 --> 00:05:55,680
than stop the stop the world capital

170
00:05:54,560 --> 00:05:58,400
collectors

171
00:05:55,680 --> 00:06:00,639
first in stop the world gc g threats can

172
00:05:58,400 --> 00:06:03,120
monopoly or cpu resources

173
00:06:00,639 --> 00:06:04,960
but for the concurrent gc gs3 have to

174
00:06:03,120 --> 00:06:06,960
share cpus with materials

175
00:06:04,960 --> 00:06:08,638
so g threads get less resources for

176
00:06:06,960 --> 00:06:10,960
collection

177
00:06:08,639 --> 00:06:12,479
second since gta 3 and mutators are

178
00:06:10,960 --> 00:06:14,080
running simultaneously

179
00:06:12,479 --> 00:06:16,479
it is possible that they are accessing

180
00:06:14,080 --> 00:06:18,639
the same object at the same time

181
00:06:16,479 --> 00:06:21,039
so gs3 have to synchronize with

182
00:06:18,639 --> 00:06:24,479
materials to ensure correct correctness

183
00:06:21,039 --> 00:06:27,039
which leads to more on time overhead

184
00:06:24,479 --> 00:06:28,240
third formulators before they read or

185
00:06:27,039 --> 00:06:30,400
write an object

186
00:06:28,240 --> 00:06:32,840
they have to make sure that the object

187
00:06:30,400 --> 00:06:34,960
is not copied or modified by beginner

188
00:06:32,840 --> 00:06:37,280
threads so measures have to

189
00:06:34,960 --> 00:06:38,960
instrument the code before ever read and

190
00:06:37,280 --> 00:06:41,919
or ever write operations

191
00:06:38,960 --> 00:06:42,719
which is called barrier code as the

192
00:06:41,919 --> 00:06:45,758
example shows

193
00:06:42,720 --> 00:06:48,720
before modifying object y a museum has

194
00:06:45,759 --> 00:06:51,199
to check if y is being collected if so

195
00:06:48,720 --> 00:06:52,240
it needs to call into a slow path this

196
00:06:51,199 --> 00:06:55,199
part is

197
00:06:52,240 --> 00:06:55,840
called is called barrical the barricade

198
00:06:55,199 --> 00:06:58,560
needs to

199
00:06:55,840 --> 00:07:02,400
be added into every or write operations

200
00:06:58,560 --> 00:07:04,560
so it will introduce runtime overhead

201
00:07:02,400 --> 00:07:06,560
given the three problems or questions

202
00:07:04,560 --> 00:07:10,560
can we design a collector with both

203
00:07:06,560 --> 00:07:12,080
low latency and high cpu efficiency

204
00:07:10,560 --> 00:07:14,400
we have found some opportunities to

205
00:07:12,080 --> 00:07:17,919
design such a new garbage collector

206
00:07:14,400 --> 00:07:20,159
the first one is i don't cause during gc

207
00:07:17,919 --> 00:07:22,159
even for the stopwatch you see since the

208
00:07:20,160 --> 00:07:24,720
gc algorithm is like a graph

209
00:07:22,160 --> 00:07:27,120
traversal on objects so the workload for

210
00:07:24,720 --> 00:07:30,240
each thread is unknown before processing

211
00:07:27,120 --> 00:07:33,360
and it is hard to achieve load balance

212
00:07:30,240 --> 00:07:35,360
we have evaluated spec wbb 2015 a

213
00:07:33,360 --> 00:07:37,280
simulated online supermarket service

214
00:07:35,360 --> 00:07:39,599
with ethiological cores

215
00:07:37,280 --> 00:07:41,599
we find that even for paris damage a

216
00:07:39,599 --> 00:07:43,599
stoppable gc open jdk

217
00:07:41,599 --> 00:07:46,400
is gt performance remains stable when

218
00:07:43,599 --> 00:07:48,800
reaching 30 cores

219
00:07:46,400 --> 00:07:49,520
open jdk is aware of the scalability

220
00:07:48,800 --> 00:07:52,080
problem

221
00:07:49,520 --> 00:07:54,080
so its default setting uses less cheesy

222
00:07:52,080 --> 00:07:56,560
threads than the number of cores

223
00:07:54,080 --> 00:07:58,240
for example the default g7 number with

224
00:07:56,560 --> 00:08:01,360
80 cores is 53

225
00:07:58,240 --> 00:08:04,639
which means that the other 27 cores

226
00:08:01,360 --> 00:08:04,639
during gc are idle

227
00:08:05,599 --> 00:08:08,960
the second opportunity is skilled right

228
00:08:07,440 --> 00:08:10,800
behavior

229
00:08:08,960 --> 00:08:13,680
at the figure shoes the interactive

230
00:08:10,800 --> 00:08:15,840
services process requests in decisions

231
00:08:13,680 --> 00:08:17,919
when a request is received a session

232
00:08:15,840 --> 00:08:20,400
begins when response is sent

233
00:08:17,919 --> 00:08:22,159
the session ends when the session is

234
00:08:20,400 --> 00:08:24,960
active the service will allocate

235
00:08:22,160 --> 00:08:26,879
object and manipulator of course the

236
00:08:24,960 --> 00:08:27,680
service also modifies shared data

237
00:08:26,879 --> 00:08:30,400
structures

238
00:08:27,680 --> 00:08:31,919
but it is unlikely to manipulate objects

239
00:08:30,400 --> 00:08:33,838
in other stations

240
00:08:31,919 --> 00:08:35,679
so we assume interactive service may

241
00:08:33,839 --> 00:08:37,919
have skewed right behaviors

242
00:08:35,679 --> 00:08:40,079
when a session is active most right will

243
00:08:37,919 --> 00:08:41,919
fall into the new objects created by the

244
00:08:40,080 --> 00:08:45,760
station

245
00:08:41,919 --> 00:08:45,760
we call the memory span a working set

246
00:08:45,839 --> 00:08:48,959
we have evaluated different services a

247
00:08:48,320 --> 00:08:51,760
cassandra

248
00:08:48,959 --> 00:08:53,599
keyboard store coupon shop center are

249
00:08:51,760 --> 00:08:55,680
online services in alibaba

250
00:08:53,600 --> 00:08:56,800
and a spectrum bb a simulated

251
00:08:55,680 --> 00:08:58,399
supermarket

252
00:08:56,800 --> 00:09:00,079
those services share similar right

253
00:08:58,399 --> 00:09:02,080
behaviors which means that

254
00:09:00,080 --> 00:09:04,320
very few rights for out of the working

255
00:09:02,080 --> 00:09:04,880
set but for other applications like

256
00:09:04,320 --> 00:09:06,959
spark

257
00:09:04,880 --> 00:09:09,279
a big data processing framework the

258
00:09:06,959 --> 00:09:11,518
memory behavior is quite different

259
00:09:09,279 --> 00:09:14,560
the station spark will incur many rights

260
00:09:11,519 --> 00:09:14,560
outside the working set

261
00:09:14,800 --> 00:09:18,000
the last opportunity the development of

262
00:09:16,560 --> 00:09:20,959
hardware features

263
00:09:18,000 --> 00:09:22,000
mpk or memory protection keys allow

264
00:09:20,959 --> 00:09:24,000
users to configure

265
00:09:22,000 --> 00:09:25,200
differentiated page permissions within

266
00:09:24,000 --> 00:09:27,360
your process

267
00:09:25,200 --> 00:09:29,360
for example we can divide virtual pages

268
00:09:27,360 --> 00:09:31,200
in our process into three domains

269
00:09:29,360 --> 00:09:33,120
and configure the threads with different

270
00:09:31,200 --> 00:09:35,360
permissions on those domains

271
00:09:33,120 --> 00:09:37,040
for example 31 has read write

272
00:09:35,360 --> 00:09:39,920
permissions to the domain 0

273
00:09:37,040 --> 00:09:40,319
and the 32 has only read only permission

274
00:09:39,920 --> 00:09:44,000
for

275
00:09:40,320 --> 00:09:46,720
to the domain domain 0. previously

276
00:09:44,000 --> 00:09:48,640
mpk is mainly used to achieve isolation

277
00:09:46,720 --> 00:09:50,560
and security between threads

278
00:09:48,640 --> 00:09:54,560
but our question is is it possible to

279
00:09:50,560 --> 00:09:54,560
use mpk also for performance

280
00:09:55,200 --> 00:09:58,640
we propose platinum a mostly concurrent

281
00:09:57,920 --> 00:10:01,760
collector

282
00:09:58,640 --> 00:10:04,079
with moderate cpu consumption

283
00:10:01,760 --> 00:10:06,079
as the extrusion flow shows platinum is

284
00:10:04,079 --> 00:10:08,399
a three-phase collection algorithm

285
00:10:06,079 --> 00:10:09,599
the first phase is an initial pause when

286
00:10:08,399 --> 00:10:11,920
platinum needs to

287
00:10:09,600 --> 00:10:13,440
initialize the connection it's quite

288
00:10:11,920 --> 00:10:15,360
short and it takes less than one

289
00:10:13,440 --> 00:10:17,519
millisecond

290
00:10:15,360 --> 00:10:18,880
the last phase is also opposed to update

291
00:10:17,519 --> 00:10:21,360
some steel references

292
00:10:18,880 --> 00:10:23,279
which takes about 10 milliseconds the

293
00:10:21,360 --> 00:10:25,440
middle part is the concurrent phase

294
00:10:23,279 --> 00:10:26,880
where mutators can run simultaneously

295
00:10:25,440 --> 00:10:28,320
with gc threats

296
00:10:26,880 --> 00:10:30,000
though they are muted mutated in the

297
00:10:28,320 --> 00:10:32,240
concurrent phase as killed with

298
00:10:30,000 --> 00:10:36,399
restrictions which is a major difference

299
00:10:32,240 --> 00:10:36,399
between our platinum and private gc

300
00:10:36,959 --> 00:10:40,479
platinum mini contains three design

301
00:10:39,040 --> 00:10:42,800
highlights first

302
00:10:40,480 --> 00:10:43,680
it collects idle costs and not used by

303
00:10:42,800 --> 00:10:46,880
cheese threads

304
00:10:43,680 --> 00:10:49,199
and give them two new theaters second

305
00:10:46,880 --> 00:10:51,680
we partition the heat isolate isolates

306
00:10:49,200 --> 00:10:53,440
memory between gc threads and mutators

307
00:10:51,680 --> 00:10:55,279
and minimize the interest rate

308
00:10:53,440 --> 00:10:58,079
synchronizations

309
00:10:55,279 --> 00:10:59,120
third it uses mpk to remove the need for

310
00:10:58,079 --> 00:11:00,640
various

311
00:10:59,120 --> 00:11:03,360
we will introduce those three parts

312
00:11:00,640 --> 00:11:03,360
respectively

313
00:11:04,160 --> 00:11:09,839
as for cpu platinum first uses the linux

314
00:11:07,360 --> 00:11:12,160
schedule set affinity api to bind

315
00:11:09,839 --> 00:11:13,839
choosing threads to separated cores

316
00:11:12,160 --> 00:11:16,719
in this way each genetic threat can

317
00:11:13,839 --> 00:11:18,720
monopoly its core during gc

318
00:11:16,720 --> 00:11:20,000
since the number of genetics is smaller

319
00:11:18,720 --> 00:11:21,519
than the number of cores

320
00:11:20,000 --> 00:11:24,079
other courses not used by genetic

321
00:11:21,519 --> 00:11:25,360
threats are identified as idol caused by

322
00:11:24,079 --> 00:11:27,519
platinum

323
00:11:25,360 --> 00:11:29,200
when gc is triggered platinum also

324
00:11:27,519 --> 00:11:31,600
changes affinity on mutators

325
00:11:29,200 --> 00:11:32,720
so that they can only execute on idle

326
00:11:31,600 --> 00:11:35,200
cores

327
00:11:32,720 --> 00:11:37,200
this mechanism isolates the cores used

328
00:11:35,200 --> 00:11:41,040
by mutators and adjacent threads

329
00:11:37,200 --> 00:11:41,040
and similar contention is avoided

330
00:11:41,120 --> 00:11:45,519
for the key memory according to the

331
00:11:43,279 --> 00:11:47,760
aforementioned skew-write behavior

332
00:11:45,519 --> 00:11:48,560
platinum partitions are keep into three

333
00:11:47,760 --> 00:11:50,480
areas

334
00:11:48,560 --> 00:11:53,199
the first collection error are contained

335
00:11:50,480 --> 00:11:55,519
objects which require to be collected

336
00:11:53,200 --> 00:11:57,200
the pin area contains objects allocated

337
00:11:55,519 --> 00:11:59,040
by the active sessions

338
00:11:57,200 --> 00:12:01,839
so they are frequently manipulated by

339
00:11:59,040 --> 00:12:03,760
mutators and should not be collected

340
00:12:01,839 --> 00:12:06,000
the location area is reserved for

341
00:12:03,760 --> 00:12:10,319
mutators so that we can allocate new

342
00:12:06,000 --> 00:12:12,959
objects during gc

343
00:12:10,320 --> 00:12:14,800
after partition platinum has enforced

344
00:12:12,959 --> 00:12:18,000
isolation for gc threads

345
00:12:14,800 --> 00:12:20,479
and mutators for gz threat they can only

346
00:12:18,000 --> 00:12:22,959
collect objects in a collection area

347
00:12:20,480 --> 00:12:24,320
if we find that an object in other two

348
00:12:22,959 --> 00:12:26,560
areas the pin error

349
00:12:24,320 --> 00:12:28,320
or the allocation area it will treat it

350
00:12:26,560 --> 00:12:31,518
as a newly created object

351
00:12:28,320 --> 00:12:33,040
and avoid touching it for mutators

352
00:12:31,519 --> 00:12:35,440
since they follow the skill right

353
00:12:33,040 --> 00:12:38,880
behavior they will mostly access the pin

354
00:12:35,440 --> 00:12:40,560
area and allocation area this design

355
00:12:38,880 --> 00:12:42,800
makes mutators and gta threads

356
00:12:40,560 --> 00:12:44,719
focus on their own memory part and

357
00:12:42,800 --> 00:12:46,880
minimizes the synchronizations between

358
00:12:44,720 --> 00:12:46,880
them

359
00:12:47,120 --> 00:12:51,279
however the heat partition can only

360
00:12:48,880 --> 00:12:52,160
guarantee that mutators mostly modify

361
00:12:51,279 --> 00:12:54,800
the pink

362
00:12:52,160 --> 00:12:56,719
and the allocation area it is still

363
00:12:54,800 --> 00:12:59,040
possible for mutators to access and

364
00:12:56,720 --> 00:13:00,800
modify the collection area and the cost

365
00:12:59,040 --> 00:13:03,680
data races

366
00:13:00,800 --> 00:13:05,519
a traditional solution is right barriers

367
00:13:03,680 --> 00:13:08,079
we mentioned before

368
00:13:05,519 --> 00:13:09,920
for example we can check if an object is

369
00:13:08,079 --> 00:13:10,560
in the collection error before modifying

370
00:13:09,920 --> 00:13:12,959
it

371
00:13:10,560 --> 00:13:13,599
if so we can use a slow pass to make

372
00:13:12,959 --> 00:13:15,439
sure that

373
00:13:13,600 --> 00:13:18,720
the right operation can correctly

374
00:13:15,440 --> 00:13:20,480
synchronize with cheated threads

375
00:13:18,720 --> 00:13:22,480
however this solution requires

376
00:13:20,480 --> 00:13:27,120
instrumenting every write operations

377
00:13:22,480 --> 00:13:27,120
which is quite costly and unnecessary

378
00:13:28,880 --> 00:13:33,600
platinum instead uses an mpk based

379
00:13:31,440 --> 00:13:35,839
hardware protection academy

380
00:13:33,600 --> 00:13:37,040
it further divides the key into two mpk

381
00:13:35,839 --> 00:13:39,360
domains

382
00:13:37,040 --> 00:13:40,160
the collection error is in the first mpk

383
00:13:39,360 --> 00:13:42,480
domain

384
00:13:40,160 --> 00:13:44,959
while the pin and allocation area are in

385
00:13:42,480 --> 00:13:46,800
the second mpk domain

386
00:13:44,959 --> 00:13:48,239
then platinum also configure the

387
00:13:46,800 --> 00:13:50,160
permission of mutators

388
00:13:48,240 --> 00:13:51,440
so they only have read-only permission

389
00:13:50,160 --> 00:13:54,079
for the domain one

390
00:13:51,440 --> 00:13:56,639
while gcsev have rewrite permission to

391
00:13:54,079 --> 00:13:59,040
both two domains

392
00:13:56,639 --> 00:13:59,760
in this way if a musician tries to

393
00:13:59,040 --> 00:14:02,000
modify an

394
00:13:59,760 --> 00:14:03,360
object in a collection area it will

395
00:14:02,000 --> 00:14:05,600
trigger a page fault

396
00:14:03,360 --> 00:14:08,480
and the pre-register handler in pattern

397
00:14:05,600 --> 00:14:10,639
will handle is right correctly

398
00:14:08,480 --> 00:14:14,079
for detail of the page fault handling

399
00:14:10,639 --> 00:14:14,079
please refer to our paper

400
00:14:15,360 --> 00:14:18,800
we evaluate platinum with the 80 core

401
00:14:17,600 --> 00:14:21,600
machine

402
00:14:18,800 --> 00:14:23,760
with three other collectors as baseline

403
00:14:21,600 --> 00:14:25,440
concurrent max suite or cms

404
00:14:23,760 --> 00:14:27,279
is a classic partially concurrent

405
00:14:25,440 --> 00:14:29,279
collector and its pulse time is

406
00:14:27,279 --> 00:14:32,000
relatively large

407
00:14:29,279 --> 00:14:33,760
gravity first or g1 is a highly tunable

408
00:14:32,000 --> 00:14:37,600
partially concurrent collector

409
00:14:33,760 --> 00:14:40,079
which becomes the default gc urban jk9

410
00:14:37,600 --> 00:14:42,399
in the evaluation we have tuned g1 to

411
00:14:40,079 --> 00:14:45,599
reach its best latency

412
00:14:42,399 --> 00:14:47,279
for each application shenandoah is a

413
00:14:45,600 --> 00:14:50,399
mostly concurrent collector

414
00:14:47,279 --> 00:14:52,800
which is a new collector in opengdk

415
00:14:50,399 --> 00:14:53,920
and as for applications we use different

416
00:14:52,800 --> 00:14:57,279
applications for

417
00:14:53,920 --> 00:15:00,160
our evaluation spec gme 2015

418
00:14:57,279 --> 00:15:01,439
is a simulated online supermarket which

419
00:15:00,160 --> 00:15:04,399
can be seen as a

420
00:15:01,440 --> 00:15:05,839
web service cassandra is a keyword store

421
00:15:04,399 --> 00:15:06,800
which can be treated as a storage

422
00:15:05,839 --> 00:15:08,880
service

423
00:15:06,800 --> 00:15:12,959
and the coupon is a real online service

424
00:15:08,880 --> 00:15:16,399
in alibaba

425
00:15:12,959 --> 00:15:18,160
as for spatulab 2015 we have tested

426
00:15:16,399 --> 00:15:20,240
with different throughput settings

427
00:15:18,160 --> 00:15:23,120
ranging from a thousand to

428
00:15:20,240 --> 00:15:24,880
forty thousand the results show that

429
00:15:23,120 --> 00:15:27,600
platinum has better 99

430
00:15:24,880 --> 00:15:28,639
latency than cms in all settings and it

431
00:15:27,600 --> 00:15:31,680
can reduce its

432
00:15:28,639 --> 00:15:32,959
length night latency by up to 79.3

433
00:15:31,680 --> 00:15:36,000
percent

434
00:15:32,959 --> 00:15:39,518
platinum also has comparable 99 latency

435
00:15:36,000 --> 00:15:41,680
with r2 and g1 as for throughputs

436
00:15:39,519 --> 00:15:44,240
platinum has the best maximum throughput

437
00:15:41,680 --> 00:15:46,479
among all collectors

438
00:15:44,240 --> 00:15:48,560
which suggests that a platinum has a

439
00:15:46,480 --> 00:15:52,480
great cpu efficiency and can stand

440
00:15:48,560 --> 00:15:52,479
very high throughput

441
00:15:52,959 --> 00:15:57,518
for cassandra we evaluate it with two

442
00:15:55,519 --> 00:16:00,800
y6b workload city

443
00:15:57,519 --> 00:16:01,519
a read intensive which contains 76 000

444
00:16:00,800 --> 00:16:04,639
reads

445
00:16:01,519 --> 00:16:05,600
and the 4000 updates per second and the

446
00:16:04,639 --> 00:16:08,000
right intensive

447
00:16:05,600 --> 00:16:10,560
which contains 40 000 reads and 47

448
00:16:08,000 --> 00:16:12,720
updates per second

449
00:16:10,560 --> 00:16:14,160
for the read intensive workload platinum

450
00:16:12,720 --> 00:16:16,160
has comparable

451
00:16:14,160 --> 00:16:18,240
tail latency with shenandoah and the

452
00:16:16,160 --> 00:16:20,240
beast g1 and cms

453
00:16:18,240 --> 00:16:22,399
but for the writings in the workload

454
00:16:20,240 --> 00:16:24,160
platinum performs worse because right

455
00:16:22,399 --> 00:16:26,480
operations require

456
00:16:24,160 --> 00:16:27,839
introducing more modifications on the

457
00:16:26,480 --> 00:16:29,600
global data structure

458
00:16:27,839 --> 00:16:31,120
which is outside of working set so the

459
00:16:29,600 --> 00:16:34,560
pattern for the number of 24

460
00:16:31,120 --> 00:16:36,480
will increase however in the wide

461
00:16:34,560 --> 00:16:39,920
intensive workload platinum still

462
00:16:36,480 --> 00:16:39,920
performs better than cms

463
00:16:41,199 --> 00:16:44,880
and for the coupon service in alibaba we

464
00:16:44,000 --> 00:16:48,399
evaluate with

465
00:16:44,880 --> 00:16:50,720
production choices the result shows that

466
00:16:48,399 --> 00:16:52,240
platinum has better tail latency for g1

467
00:16:50,720 --> 00:16:54,079
and cms

468
00:16:52,240 --> 00:16:55,839
as we mentioned before since the

469
00:16:54,079 --> 00:16:57,359
application latency in shenandoah is

470
00:16:55,839 --> 00:16:59,120
much worse than others

471
00:16:57,360 --> 00:17:01,440
so we do not show its latency in this

472
00:16:59,120 --> 00:17:03,680
figure

473
00:17:01,440 --> 00:17:05,760
finally we'll also show the average cpu

474
00:17:03,680 --> 00:17:07,359
utilization under stressful workload for

475
00:17:05,760 --> 00:17:09,599
different services

476
00:17:07,359 --> 00:17:12,000
the result shows that cms actually

477
00:17:09,599 --> 00:17:14,559
introduces moderate cpu consumption

478
00:17:12,000 --> 00:17:15,679
this is because it introduces relatively

479
00:17:14,559 --> 00:17:18,559
long process

480
00:17:15,679 --> 00:17:19,199
and reaches satisfying gc efficiency

481
00:17:18,559 --> 00:17:21,199
however

482
00:17:19,199 --> 00:17:22,240
as we showed before its tail latency is

483
00:17:21,199 --> 00:17:25,280
quite high

484
00:17:22,240 --> 00:17:27,599
and worse compared with other collectors

485
00:17:25,280 --> 00:17:29,440
compared with g1 and shenandoah platinum

486
00:17:27,599 --> 00:17:32,080
has better cpu utilization

487
00:17:29,440 --> 00:17:32,880
which confirmed that cpu platinum can

488
00:17:32,080 --> 00:17:34,960
achieve both

489
00:17:32,880 --> 00:17:37,520
low latency and moderate signal

490
00:17:34,960 --> 00:17:37,520
consumption

491
00:17:38,720 --> 00:17:42,400
okay to conclude private collectors make

492
00:17:41,440 --> 00:17:46,000
a trade-off

493
00:17:42,400 --> 00:17:47,120
between latency and cpu efficiency we

494
00:17:46,000 --> 00:17:50,160
therefore propose

495
00:17:47,120 --> 00:17:52,239
platinum to break this trigger

496
00:17:50,160 --> 00:17:54,400
and it provides three design points to

497
00:17:52,240 --> 00:17:54,799
preserve low gc process while reducing

498
00:17:54,400 --> 00:17:57,600
the

499
00:17:54,799 --> 00:17:58,400
overhead in private collectors they are

500
00:17:57,600 --> 00:18:00,480
idle correct

501
00:17:58,400 --> 00:18:02,640
idle core connection to mitigate the

502
00:18:00,480 --> 00:18:04,559
civil contentions between gta threat

503
00:18:02,640 --> 00:18:06,000
and hit partition to minimize the

504
00:18:04,559 --> 00:18:09,200
synchronization between

505
00:18:06,000 --> 00:18:11,440
cheese threads and mutators an npk-based

506
00:18:09,200 --> 00:18:13,919
barrier immigration which uses the

507
00:18:11,440 --> 00:18:17,440
recently released mpk hardware feature

508
00:18:13,919 --> 00:18:19,440
to reduce the runtime overhead

509
00:18:17,440 --> 00:18:20,640
an evaluation on different interactive

510
00:18:19,440 --> 00:18:22,960
services show that

511
00:18:20,640 --> 00:18:24,640
platinum can achieve both low latency

512
00:18:22,960 --> 00:18:27,039
and moderate cpu consumption

513
00:18:24,640 --> 00:18:27,679
compared with private garbage collectors

514
00:18:27,039 --> 00:18:41,760
that's all

515
00:18:27,679 --> 00:18:41,760
thank you for listening

