1
00:00:09,760 --> 00:00:13,440
hello everyone my name is sorut and i'll

2
00:00:11,599 --> 00:00:16,960
be presenting our paper

3
00:00:13,440 --> 00:00:18,880
today so let's start with a little bit

4
00:00:16,960 --> 00:00:21,520
of background

5
00:00:18,880 --> 00:00:24,320
our inspiration began by the application

6
00:00:21,520 --> 00:00:26,960
of neural networks using computer vision

7
00:00:24,320 --> 00:00:28,320
in autonomous embedded systems so let's

8
00:00:26,960 --> 00:00:30,240
briefly discuss each of these

9
00:00:28,320 --> 00:00:31,920
technologies individually

10
00:00:30,240 --> 00:00:34,000
neural networks which you can see an

11
00:00:31,920 --> 00:00:36,800
abstract silhouette on the left

12
00:00:34,000 --> 00:00:37,760
for them are approximate functions which

13
00:00:36,800 --> 00:00:40,000
are constructed

14
00:00:37,760 --> 00:00:41,360
by training multiple layers of neurons

15
00:00:40,000 --> 00:00:43,280
on supercomputers

16
00:00:41,360 --> 00:00:45,360
the motivation of getting better and

17
00:00:43,280 --> 00:00:48,160
better accuracy compared to the ground

18
00:00:45,360 --> 00:00:51,199
truth has driven dnn developers to adopt

19
00:00:48,160 --> 00:00:52,319
ever more complex architectures accurate

20
00:00:51,199 --> 00:00:54,719
dnns are thus

21
00:00:52,320 --> 00:00:55,680
inherently computation heavy on the

22
00:00:54,719 --> 00:00:58,160
other hand

23
00:00:55,680 --> 00:00:59,359
autonomous embedded systems are all

24
00:00:58,160 --> 00:01:01,599
based on

25
00:00:59,359 --> 00:01:03,520
embedded systems even the latest

26
00:01:01,600 --> 00:01:05,360
embedded systems such as nvidia's taker

27
00:01:03,520 --> 00:01:07,439
based lineup of products which you can

28
00:01:05,360 --> 00:01:09,920
see the agex xavier here

29
00:01:07,439 --> 00:01:11,839
have incredible performance but are

30
00:01:09,920 --> 00:01:13,600
still limited in terms of relative

31
00:01:11,840 --> 00:01:15,439
computing prowess

32
00:01:13,600 --> 00:01:17,520
power consumption thermal dissipation

33
00:01:15,439 --> 00:01:18,639
and space compared to the desktop and

34
00:01:17,520 --> 00:01:22,000
powerful servers that

35
00:01:18,640 --> 00:01:24,240
are used to develop the units

36
00:01:22,000 --> 00:01:25,600
as you can see these two are largely

37
00:01:24,240 --> 00:01:28,720
different areas of research with

38
00:01:25,600 --> 00:01:31,439
different requirements and goals

39
00:01:28,720 --> 00:01:33,360
however we came across the marriage of

40
00:01:31,439 --> 00:01:35,119
these technologies while working with

41
00:01:33,360 --> 00:01:36,720
the open source autonomous driving

42
00:01:35,119 --> 00:01:38,640
software ottawa

43
00:01:36,720 --> 00:01:40,720
which uses neural networks for object

44
00:01:38,640 --> 00:01:42,240
detection image recognition and even

45
00:01:40,720 --> 00:01:44,720
localization

46
00:01:42,240 --> 00:01:46,000
and all these dnns share the same

47
00:01:44,720 --> 00:01:47,759
architecture

48
00:01:46,000 --> 00:01:49,680
this in itself has resulted in other

49
00:01:47,759 --> 00:01:50,720
projects and publications which we won't

50
00:01:49,680 --> 00:01:53,439
discuss here

51
00:01:50,720 --> 00:01:56,000
however we were interested in how this

52
00:01:53,439 --> 00:01:58,960
marriage is addressed in the literature

53
00:01:56,000 --> 00:02:01,360
so as is accustomed in uh system

54
00:01:58,960 --> 00:02:02,880
research we looked at the entire stack

55
00:02:01,360 --> 00:02:05,119
from hardware all the way to the

56
00:02:02,880 --> 00:02:07,520
application itself

57
00:02:05,119 --> 00:02:09,038
so interestingly there is ample research

58
00:02:07,520 --> 00:02:12,239
at the application level

59
00:02:09,038 --> 00:02:14,879
by implementing ever more sophisticated

60
00:02:12,239 --> 00:02:17,280
ways of reducing down requirements

61
00:02:14,879 --> 00:02:18,959
examples include quantization low rank

62
00:02:17,280 --> 00:02:22,080
approximation

63
00:02:18,959 --> 00:02:23,280
model optimization etc often at the

64
00:02:22,080 --> 00:02:25,680
expense of

65
00:02:23,280 --> 00:02:28,640
accuracy at the other end there's tons

66
00:02:25,680 --> 00:02:31,680
of research on hardware optimizations

67
00:02:28,640 --> 00:02:34,000
for dnns for example new types of

68
00:02:31,680 --> 00:02:34,959
processors and coprocessors are popping

69
00:02:34,000 --> 00:02:36,959
up

70
00:02:34,959 --> 00:02:38,000
like the tesla's ai chip which is

71
00:02:36,959 --> 00:02:41,680
upcoming um

72
00:02:38,000 --> 00:02:44,000
and the nvidia's mv dla process

73
00:02:41,680 --> 00:02:45,200
however as the researchers in the field

74
00:02:44,000 --> 00:02:47,280
of real-time systems

75
00:02:45,200 --> 00:02:49,679
we realize that some goals cannot be

76
00:02:47,280 --> 00:02:51,200
achieved by purely application level or

77
00:02:49,680 --> 00:02:53,280
hardware level solutions

78
00:02:51,200 --> 00:02:55,920
and i'll show you with detailed

79
00:02:53,280 --> 00:02:59,760
experiments in a second

80
00:02:55,920 --> 00:03:03,119
but first let's set our goals clear

81
00:02:59,760 --> 00:03:04,640
so the dnn first of all might take too

82
00:03:03,120 --> 00:03:07,120
long to execute right

83
00:03:04,640 --> 00:03:09,040
causing mission critical system to fail

84
00:03:07,120 --> 00:03:11,599
therefore our first goal is to ensure

85
00:03:09,040 --> 00:03:13,440
dnn execution is timing predictable

86
00:03:11,599 --> 00:03:15,359
second that the enemy might consume

87
00:03:13,440 --> 00:03:18,239
unacceptable amounts of energy

88
00:03:15,360 --> 00:03:20,959
causing overheating decreased range or

89
00:03:18,239 --> 00:03:23,040
even system failure in extreme cases

90
00:03:20,959 --> 00:03:24,480
therefore our second goal is that dns

91
00:03:23,040 --> 00:03:27,120
should be power efficient

92
00:03:24,480 --> 00:03:28,640
and third the previous two issues might

93
00:03:27,120 --> 00:03:30,840
motivate developers to adopt

94
00:03:28,640 --> 00:03:32,000
less accurate dna models as i discussed

95
00:03:30,840 --> 00:03:34,480
before

96
00:03:32,000 --> 00:03:36,560
to meet the tiny requirements and be

97
00:03:34,480 --> 00:03:38,798
energy efficient however this would lead

98
00:03:36,560 --> 00:03:40,239
to loss of accuracy which is also very

99
00:03:38,799 --> 00:03:42,319
important in these systems

100
00:03:40,239 --> 00:03:43,840
therefore our third goal is to be as

101
00:03:42,319 --> 00:03:47,760
accurate as possible

102
00:03:43,840 --> 00:03:49,920
so now let me show you our motivation

103
00:03:47,760 --> 00:03:51,200
so here i want to show you that it is

104
00:03:49,920 --> 00:03:53,280
impossible to achieve

105
00:03:51,200 --> 00:03:55,040
all these three goals at the same time

106
00:03:53,280 --> 00:03:58,080
if you don't get the framework

107
00:03:55,040 --> 00:04:00,798
and the operating system involved

108
00:03:58,080 --> 00:04:02,319
first let's talk a look at our first two

109
00:04:00,799 --> 00:04:04,159
goals

110
00:04:02,319 --> 00:04:06,399
so achieving timing predictability

111
00:04:04,159 --> 00:04:07,280
involving however efficient is possible

112
00:04:06,400 --> 00:04:10,080
at hardware

113
00:04:07,280 --> 00:04:12,879
or system level by adjusting the dynamic

114
00:04:10,080 --> 00:04:14,879
voltage frequency scale or dvfs

115
00:04:12,879 --> 00:04:16,959
configuration of the system there is a

116
00:04:14,879 --> 00:04:17,440
lot of research in this area which

117
00:04:16,959 --> 00:04:20,560
either

118
00:04:17,440 --> 00:04:23,440
involves reactive ufdbfs adjustment at

119
00:04:20,560 --> 00:04:25,600
hardware levels such as nvidia's max-q

120
00:04:23,440 --> 00:04:27,280
or based on applications characteristics

121
00:04:25,600 --> 00:04:29,120
such as port

122
00:04:27,280 --> 00:04:31,119
however achieving these two goals

123
00:04:29,120 --> 00:04:34,320
simultaneously for dnns

124
00:04:31,120 --> 00:04:35,680
is not simple reactive dvfs adjustment

125
00:04:34,320 --> 00:04:38,159
generally acts blind

126
00:04:35,680 --> 00:04:39,280
and as we will show in our evaluation

127
00:04:38,160 --> 00:04:42,080
doesn't perform

128
00:04:39,280 --> 00:04:43,599
well application specific tools on the

129
00:04:42,080 --> 00:04:46,639
other hand look promising

130
00:04:43,600 --> 00:04:49,680
however very early on we discovered that

131
00:04:46,639 --> 00:04:51,600
each dna layer is its own application

132
00:04:49,680 --> 00:04:53,199
meaning it has its own power profile and

133
00:04:51,600 --> 00:04:54,240
reacts differently to the defense

134
00:04:53,199 --> 00:04:56,000
adjustments

135
00:04:54,240 --> 00:04:57,759
here we have scoured all the possible

136
00:04:56,000 --> 00:05:01,199
dvfs configurations

137
00:04:57,759 --> 00:05:03,440
on the nvidia's json tx2 for each layer

138
00:05:01,199 --> 00:05:06,240
of alexnet you can see the layer numbers

139
00:05:03,440 --> 00:05:08,240
on the y-axis and recorded the dvfs

140
00:05:06,240 --> 00:05:11,199
configuration you can see them

141
00:05:08,240 --> 00:05:12,960
number on the x that consumes the least

142
00:05:11,199 --> 00:05:16,080
amount of power

143
00:05:12,960 --> 00:05:18,000
so the power here power consumption here

144
00:05:16,080 --> 00:05:21,198
means the total millijoules consumed

145
00:05:18,000 --> 00:05:22,720
over the execution time of that layer

146
00:05:21,199 --> 00:05:25,440
as you can see each layer has a

147
00:05:22,720 --> 00:05:28,080
different optimal dbfs configuration

148
00:05:25,440 --> 00:05:30,160
so what about achieving timing

149
00:05:28,080 --> 00:05:32,639
predictability and good accuracy

150
00:05:30,160 --> 00:05:33,360
this can only be done at application

151
00:05:32,639 --> 00:05:34,800
level

152
00:05:33,360 --> 00:05:37,039
by changing the application

153
00:05:34,800 --> 00:05:38,639
configuration however different layers

154
00:05:37,039 --> 00:05:40,080
have different sensitivities to

155
00:05:38,639 --> 00:05:43,120
approximation

156
00:05:40,080 --> 00:05:45,198
here i don't go over the details but

157
00:05:43,120 --> 00:05:47,360
speaking theoretically to achieve a 12

158
00:05:45,199 --> 00:05:50,320
millisecond deadline in alexnet

159
00:05:47,360 --> 00:05:52,240
here's the optimal approximation value

160
00:05:50,320 --> 00:05:54,240
that needs to be achieved for each layer

161
00:05:52,240 --> 00:05:56,080
on the jetson tx2

162
00:05:54,240 --> 00:05:57,520
for more information on this you can

163
00:05:56,080 --> 00:06:00,639
read our ap net paper

164
00:05:57,520 --> 00:06:00,639
published in rtss

165
00:06:00,720 --> 00:06:04,240
so already we see that existing

166
00:06:02,479 --> 00:06:06,318
application level and system hardware

167
00:06:04,240 --> 00:06:08,639
level solutions need to change for dnfs

168
00:06:06,319 --> 00:06:10,160
however our goal was to achieve all

169
00:06:08,639 --> 00:06:12,240
three at the same time

170
00:06:10,160 --> 00:06:13,840
timing predictability power efficiency

171
00:06:12,240 --> 00:06:16,240
and accuracy

172
00:06:13,840 --> 00:06:17,119
so let's make layer level solutions for

173
00:06:16,240 --> 00:06:19,520
both

174
00:06:17,120 --> 00:06:22,319
application level and system level and

175
00:06:19,520 --> 00:06:25,198
run them simultaneously

176
00:06:22,319 --> 00:06:25,199
this is what we get

177
00:06:25,840 --> 00:06:30,880
so in this experiment the deadline is

178
00:06:28,800 --> 00:06:33,039
set to 20 millisecond

179
00:06:30,880 --> 00:06:35,280
and we measure the projected deficit the

180
00:06:33,039 --> 00:06:37,919
system is going to have at each layer

181
00:06:35,280 --> 00:06:39,599
we'll talk about how this can be done

182
00:06:37,919 --> 00:06:41,198
the deficit can be calculated in a

183
00:06:39,600 --> 00:06:44,080
design

184
00:06:41,199 --> 00:06:45,680
but in an abstract way the deficit shows

185
00:06:44,080 --> 00:06:48,880
if the system is ahead or

186
00:06:45,680 --> 00:06:52,720
behind an ideal schedule so alexnet can

187
00:06:48,880 --> 00:06:55,840
easily reach the 20 millisecond deadline

188
00:06:52,720 --> 00:06:57,759
here we said here by some dvfs

189
00:06:55,840 --> 00:06:58,719
adjustments it doesn't need any accuracy

190
00:06:57,759 --> 00:07:00,479
adjustments

191
00:06:58,720 --> 00:07:02,160
however as you can see in our experiment

192
00:07:00,479 --> 00:07:04,240
both the energy and accuracy keep

193
00:07:02,160 --> 00:07:06,800
decreasing at the same rate

194
00:07:04,240 --> 00:07:07,440
initially this the deficit is almost

195
00:07:06,800 --> 00:07:10,240
zero

196
00:07:07,440 --> 00:07:12,000
but still negative in an attempt to

197
00:07:10,240 --> 00:07:13,759
reduce this deficit

198
00:07:12,000 --> 00:07:15,440
the negative deficit means the system is

199
00:07:13,759 --> 00:07:16,000
behind the ideal schedule and is likely

200
00:07:15,440 --> 00:07:18,479
going to

201
00:07:16,000 --> 00:07:19,759
miss the 20 millisecond deadline both

202
00:07:18,479 --> 00:07:21,680
the system level solution and the

203
00:07:19,759 --> 00:07:23,360
application level solution switch to a

204
00:07:21,680 --> 00:07:27,120
lower configuration

205
00:07:23,360 --> 00:07:29,440
you can see around four layer four that

206
00:07:27,120 --> 00:07:31,440
happens

207
00:07:29,440 --> 00:07:35,440
and then continues and their search

208
00:07:31,440 --> 00:07:39,120
continues all the way around layer 10.

209
00:07:35,440 --> 00:07:41,120
um so at layer 10 until the

210
00:07:39,120 --> 00:07:42,479
the deficit becomes positive however you

211
00:07:41,120 --> 00:07:43,919
can see that both of them

212
00:07:42,479 --> 00:07:46,000
because both of them are trying at the

213
00:07:43,919 --> 00:07:47,919
same time and both of them are

214
00:07:46,000 --> 00:07:49,360
using discrete configurations both of

215
00:07:47,919 --> 00:07:52,000
them overshoot

216
00:07:49,360 --> 00:07:53,039
wisely and you can see that the deficit

217
00:07:52,000 --> 00:07:56,319
is now

218
00:07:53,039 --> 00:07:59,599
positive so the

219
00:07:56,319 --> 00:08:02,720
system level solution sees this as a way

220
00:07:59,599 --> 00:08:03,759
uh actually to be able to save energy

221
00:08:02,720 --> 00:08:06,240
right

222
00:08:03,759 --> 00:08:08,080
um so it will switch actually to a

223
00:08:06,240 --> 00:08:10,560
slower dvfs configuration

224
00:08:08,080 --> 00:08:12,000
but here the system level solution again

225
00:08:10,560 --> 00:08:13,840
overshoots again

226
00:08:12,000 --> 00:08:15,840
causing the deficit to become negative

227
00:08:13,840 --> 00:08:16,960
you can see that around the year 19 it's

228
00:08:15,840 --> 00:08:18,719
negative again

229
00:08:16,960 --> 00:08:20,000
which results in the application level

230
00:08:18,720 --> 00:08:22,639
solution decreasing the

231
00:08:20,000 --> 00:08:23,360
accuracy even further and you can see in

232
00:08:22,639 --> 00:08:26,560
the end

233
00:08:23,360 --> 00:08:27,680
everything works out but the deficit is

234
00:08:26,560 --> 00:08:29,680
way too positive

235
00:08:27,680 --> 00:08:32,720
the accuracy is lower significantly and

236
00:08:29,680 --> 00:08:32,720
the whole thing is a mess

237
00:08:33,200 --> 00:08:39,120
and here's what happens uh basically

238
00:08:36,399 --> 00:08:41,839
we have a negative feedback loop right

239
00:08:39,120 --> 00:08:43,599
which is even if you're running it

240
00:08:41,839 --> 00:08:45,519
running your system level application

241
00:08:43,599 --> 00:08:45,839
solution and application level solution

242
00:08:45,519 --> 00:08:48,080
at

243
00:08:45,839 --> 00:08:49,839
different frequencies you still

244
00:08:48,080 --> 00:08:51,800
potentially get this negative feedback

245
00:08:49,839 --> 00:08:54,640
loop which both of them try to

246
00:08:51,800 --> 00:08:56,560
save the system from missing a deadline

247
00:08:54,640 --> 00:08:58,240
both of them overshoot and then try to

248
00:08:56,560 --> 00:08:59,839
correct their mistake

249
00:08:58,240 --> 00:09:01,839
and then you get this negative feedback

250
00:08:59,839 --> 00:09:04,720
loop forever so for

251
00:09:01,839 --> 00:09:06,399
these motivations again as we discussed

252
00:09:04,720 --> 00:09:09,040
we need per layer adjustments

253
00:09:06,399 --> 00:09:09,600
and we need coordination uh one more

254
00:09:09,040 --> 00:09:11,199
thing

255
00:09:09,600 --> 00:09:13,920
we need to discuss before getting to the

256
00:09:11,200 --> 00:09:15,519
design uh we didn't realize this until

257
00:09:13,920 --> 00:09:17,760
we actually tried to use this

258
00:09:15,519 --> 00:09:19,600
in outerwear but most autonomous

259
00:09:17,760 --> 00:09:20,640
embedded systems have multiple instances

260
00:09:19,600 --> 00:09:22,800
of dna

261
00:09:20,640 --> 00:09:24,160
the issue here is that adjusting dvfs

262
00:09:22,800 --> 00:09:26,160
configurations for

263
00:09:24,160 --> 00:09:28,000
one layer of one dna instance will

264
00:09:26,160 --> 00:09:31,839
affect all the other

265
00:09:28,000 --> 00:09:34,160
uh dnn instances often negatively

266
00:09:31,839 --> 00:09:35,360
here we run our layer level system

267
00:09:34,160 --> 00:09:37,279
solution

268
00:09:35,360 --> 00:09:39,600
on eight instances of resonant and

269
00:09:37,279 --> 00:09:40,560
recorded both the normalized latency and

270
00:09:39,600 --> 00:09:44,320
the normalized

271
00:09:40,560 --> 00:09:45,359
energy as you can see the first dnn is

272
00:09:44,320 --> 00:09:48,560
lucky

273
00:09:45,360 --> 00:09:50,160
well it's greedy and

274
00:09:48,560 --> 00:09:52,800
therefore it is fast and energy

275
00:09:50,160 --> 00:09:55,279
efficient but but this grid has resulted

276
00:09:52,800 --> 00:09:57,760
in other dnns performing much worse

277
00:09:55,279 --> 00:10:00,240
and having an uneven distribution amount

278
00:09:57,760 --> 00:10:00,240
among them

279
00:10:00,560 --> 00:10:08,479
so the takeaway uh from this motivation

280
00:10:05,440 --> 00:10:10,480
are that we need a new system right so

281
00:10:08,480 --> 00:10:10,959
before we begin or to design our system

282
00:10:10,480 --> 00:10:14,720
let's

283
00:10:10,959 --> 00:10:15,199
set our core goals so the most important

284
00:10:14,720 --> 00:10:18,399
is

285
00:10:15,200 --> 00:10:20,399
of course these four that we motivated

286
00:10:18,399 --> 00:10:22,560
the ultimate goal is to design a timely

287
00:10:20,399 --> 00:10:23,360
practical framework for multi-dns

288
00:10:22,560 --> 00:10:25,599
systems

289
00:10:23,360 --> 00:10:26,880
that can conserve energy and maximize

290
00:10:25,600 --> 00:10:29,519
accuracy

291
00:10:26,880 --> 00:10:30,480
however we should also page flexibility

292
00:10:29,519 --> 00:10:32,079
into our design

293
00:10:30,480 --> 00:10:33,760
we would like this framework to be used

294
00:10:32,079 --> 00:10:35,439
in anywhere from small drones to

295
00:10:33,760 --> 00:10:37,200
production systems so highly safety

296
00:10:35,440 --> 00:10:39,680
critical autonomous vehicles

297
00:10:37,200 --> 00:10:41,360
therefore before we begin we set three

298
00:10:39,680 --> 00:10:42,800
optimization targets for the

299
00:10:41,360 --> 00:10:44,640
three typical scenarios we have

300
00:10:42,800 --> 00:10:47,760
identified so we

301
00:10:44,640 --> 00:10:50,319
so we have minimum energy we show as mp

302
00:10:47,760 --> 00:10:52,640
which is used when new os is using

303
00:10:50,320 --> 00:10:53,360
systems with critically small energy

304
00:10:52,640 --> 00:10:55,199
envelopes

305
00:10:53,360 --> 00:10:58,640
such as remote sensing devices smart

306
00:10:55,200 --> 00:11:01,600
watches small drones etc

307
00:10:58,640 --> 00:11:02,640
max accuracy or mp can be used when new

308
00:11:01,600 --> 00:11:05,200
os is deployed in

309
00:11:02,640 --> 00:11:07,199
extremely mission critical applications

310
00:11:05,200 --> 00:11:08,240
alternatively in applications such as

311
00:11:07,200 --> 00:11:10,399
autonomous driving

312
00:11:08,240 --> 00:11:13,680
an external policy controller can choose

313
00:11:10,399 --> 00:11:16,320
this configuration in certain scenarios

314
00:11:13,680 --> 00:11:17,040
finally we have balanced energy and

315
00:11:16,320 --> 00:11:19,760
accuracy

316
00:11:17,040 --> 00:11:22,079
which is the catch-all method where

317
00:11:19,760 --> 00:11:22,560
newest can try to optimize everything on

318
00:11:22,079 --> 00:11:24,959
its own

319
00:11:22,560 --> 00:11:26,880
in a balanced way we do however give

320
00:11:24,959 --> 00:11:28,800
some control to the system designer or

321
00:11:26,880 --> 00:11:32,800
the external policy controller to adjust

322
00:11:28,800 --> 00:11:32,800
the sensitivity of this balancing act

323
00:11:33,760 --> 00:11:39,120
so for our design we give four major

324
00:11:36,800 --> 00:11:39,120
points

325
00:11:40,240 --> 00:11:44,240
first how do we ensure timing

326
00:11:42,640 --> 00:11:46,000
predictability

327
00:11:44,240 --> 00:11:48,640
uh well the answer is we use lag

328
00:11:46,000 --> 00:11:51,040
analysis well where we keep track of the

329
00:11:48,640 --> 00:11:53,839
progress each dna instance is making

330
00:11:51,040 --> 00:11:55,040
and compare it against an ideal schedule

331
00:11:53,839 --> 00:11:57,040
so you can see

332
00:11:55,040 --> 00:11:59,760
we actually record per layer execution

333
00:11:57,040 --> 00:12:03,439
time as el

334
00:11:59,760 --> 00:12:06,000
um and we calculate the idea schedule

335
00:12:03,440 --> 00:12:07,440
based on the proportional deadline taken

336
00:12:06,000 --> 00:12:09,200
so you can see the per layers of

337
00:12:07,440 --> 00:12:12,000
deadline on the left d

338
00:12:09,200 --> 00:12:14,480
l and how it is calculated you can see

339
00:12:12,000 --> 00:12:16,880
it on the right

340
00:12:14,480 --> 00:12:19,200
so based on any recorded execution trace

341
00:12:16,880 --> 00:12:23,200
of a dnn we can calculate some deadlines

342
00:12:19,200 --> 00:12:23,200
for each layer using proportional design

343
00:12:23,360 --> 00:12:27,040
that top deadline can then act as the

344
00:12:25,440 --> 00:12:29,440
ideal execution time for

345
00:12:27,040 --> 00:12:30,560
that day if you go over this ideal

346
00:12:29,440 --> 00:12:32,480
execution time

347
00:12:30,560 --> 00:12:34,319
the lag becomes negative meaning the

348
00:12:32,480 --> 00:12:38,800
system is behind the ideal schedule

349
00:12:34,320 --> 00:12:40,800
and needs to run faster um to catch up

350
00:12:38,800 --> 00:12:42,000
and if we go over the ideal schedule the

351
00:12:40,800 --> 00:12:44,160
lag becomes positive

352
00:12:42,000 --> 00:12:45,760
meaning the system is ahead of schedule

353
00:12:44,160 --> 00:12:48,560
and then the system can

354
00:12:45,760 --> 00:12:50,639
uh run slower to save energy or be more

355
00:12:48,560 --> 00:12:53,839
accurate

356
00:12:50,639 --> 00:12:56,000
so the second is how do we coordinate

357
00:12:53,839 --> 00:12:58,079
well the answer is twofold first you can

358
00:12:56,000 --> 00:12:58,959
see on the left we keep track of a

359
00:12:58,079 --> 00:13:02,079
cohort

360
00:12:58,959 --> 00:13:04,239
the cohort is a pair of lag and x

361
00:13:02,079 --> 00:13:05,680
for each dnn instance shared between all

362
00:13:04,240 --> 00:13:07,680
dnn instances

363
00:13:05,680 --> 00:13:10,319
the value of x is the approximation

364
00:13:07,680 --> 00:13:12,719
configuration that dnn has chosen

365
00:13:10,320 --> 00:13:14,079
second we design our core algorithms you

366
00:13:12,720 --> 00:13:16,800
can see on the right

367
00:13:14,079 --> 00:13:18,160
to take into account this cohort when

368
00:13:16,800 --> 00:13:21,359
making decisions

369
00:13:18,160 --> 00:13:22,959
so let's discuss these algorithms so

370
00:13:21,360 --> 00:13:24,880
these two algorithms work in

371
00:13:22,959 --> 00:13:27,279
hand in hand to choose the best dbfs

372
00:13:24,880 --> 00:13:30,720
configuration for the entire cohort and

373
00:13:27,279 --> 00:13:32,800
minimize accuracy loss and i'll show you

374
00:13:30,720 --> 00:13:34,480
a more intuitive way of how these two

375
00:13:32,800 --> 00:13:37,120
work together in the next slide

376
00:13:34,480 --> 00:13:38,959
but here you can see the abstract of

377
00:13:37,120 --> 00:13:40,639
both of these algorithms

378
00:13:38,959 --> 00:13:42,079
the first algorithm is our delta

379
00:13:40,639 --> 00:13:44,399
calculator

380
00:13:42,079 --> 00:13:45,839
which based on each last reported value

381
00:13:44,399 --> 00:13:48,240
of lag in the cohort

382
00:13:45,839 --> 00:13:50,240
finds individually the best dvfs

383
00:13:48,240 --> 00:13:51,920
configuration for each dna instance

384
00:13:50,240 --> 00:13:54,639
and this is happening in a distributed

385
00:13:51,920 --> 00:13:59,040
way so each dnn basically

386
00:13:54,639 --> 00:14:01,360
runs this algorithm the key here is the

387
00:13:59,040 --> 00:14:02,319
oops sorry the key here is the lookup

388
00:14:01,360 --> 00:14:05,519
procedure

389
00:14:02,320 --> 00:14:07,519
which needs to be fast for this we rely

390
00:14:05,519 --> 00:14:09,680
on a speed-up power of table

391
00:14:07,519 --> 00:14:10,639
that is stored in a hash format for more

392
00:14:09,680 --> 00:14:14,719
information on

393
00:14:10,639 --> 00:14:16,720
this please see the paper

394
00:14:14,720 --> 00:14:18,079
so this algorithm then first calculates

395
00:14:16,720 --> 00:14:22,000
the required speed up

396
00:14:18,079 --> 00:14:24,560
uh on the given sub deadline for a layer

397
00:14:22,000 --> 00:14:25,199
uh calculated and also it takes into

398
00:14:24,560 --> 00:14:28,399
account the

399
00:14:25,199 --> 00:14:30,319
lag and uses the calculated speed up

400
00:14:28,399 --> 00:14:32,000
which again i have to mention can be a

401
00:14:30,320 --> 00:14:32,959
slow down if you want to sell save

402
00:14:32,000 --> 00:14:34,800
energy

403
00:14:32,959 --> 00:14:36,399
as a search key for the speed up

404
00:14:34,800 --> 00:14:38,319
power-up table

405
00:14:36,399 --> 00:14:40,000
so the second algorithm takes this

406
00:14:38,320 --> 00:14:43,120
calculation which will be

407
00:14:40,000 --> 00:14:45,199
a set of possible dbfs configuration

408
00:14:43,120 --> 00:14:47,360
and calculates a second speed up for

409
00:14:45,199 --> 00:14:49,439
each dbfs configuration

410
00:14:47,360 --> 00:14:51,440
this time purely by using application

411
00:14:49,440 --> 00:14:53,920
level approximation configuration

412
00:14:51,440 --> 00:14:55,120
this speed up or again slow down is

413
00:14:53,920 --> 00:14:57,199
called sa

414
00:14:55,120 --> 00:14:59,360
and is based on the projected effect of

415
00:14:57,199 --> 00:15:01,359
the given dvfs configuration on other

416
00:14:59,360 --> 00:15:03,760
dns

417
00:15:01,360 --> 00:15:05,600
this can also be easily calculated based

418
00:15:03,760 --> 00:15:07,199
on the hashed speed of power up table

419
00:15:05,600 --> 00:15:10,079
for each dnn type

420
00:15:07,199 --> 00:15:12,719
finally the required approximate

421
00:15:10,079 --> 00:15:15,120
configuration is found based on

422
00:15:12,720 --> 00:15:16,880
this second speed up the key here is

423
00:15:15,120 --> 00:15:19,360
again the lookup procedure

424
00:15:16,880 --> 00:15:21,600
in our implementation we only use low

425
00:15:19,360 --> 00:15:24,079
rank as the approximation configuration

426
00:15:21,600 --> 00:15:25,920
therefore this step is fast however for

427
00:15:24,079 --> 00:15:27,760
even more choices of approximation

428
00:15:25,920 --> 00:15:29,759
configurations we provided a speedup

429
00:15:27,760 --> 00:15:30,560
accuracy table which is also hashed and

430
00:15:29,759 --> 00:15:32,000
stored

431
00:15:30,560 --> 00:15:34,638
given that the number of possible

432
00:15:32,000 --> 00:15:36,480
configure dbfs configurations

433
00:15:34,639 --> 00:15:38,000
range in the tens of thousands as we'll

434
00:15:36,480 --> 00:15:39,920
see in the evaluation

435
00:15:38,000 --> 00:15:43,680
the approximation configuration lookup

436
00:15:39,920 --> 00:15:43,680
has minimal overhead in comparison

437
00:15:44,880 --> 00:15:51,040
so here on the left uh

438
00:15:47,920 --> 00:15:54,079
basically you can see the overall way

439
00:15:51,040 --> 00:15:55,839
that that our algorithms operate so you

440
00:15:54,079 --> 00:15:58,000
can see that you have the cohort here we

441
00:15:55,839 --> 00:16:01,040
have ndn instances

442
00:15:58,000 --> 00:16:03,360
so for each value in the cohort the

443
00:16:01,040 --> 00:16:05,439
delta calculator calculates

444
00:16:03,360 --> 00:16:07,279
an optimal dvfs configuration which you

445
00:16:05,440 --> 00:16:11,199
can see in the second row

446
00:16:07,279 --> 00:16:14,000
from delta 1 all the way to delta n

447
00:16:11,199 --> 00:16:16,079
so based on each of these ideal dvfs

448
00:16:14,000 --> 00:16:19,519
configurations

449
00:16:16,079 --> 00:16:23,680
the xi calculator will calculate

450
00:16:19,519 --> 00:16:27,279
a required approximation if you will

451
00:16:23,680 --> 00:16:29,758
so the effect is that choosing any

452
00:16:27,279 --> 00:16:31,279
um of the dvfs configurations will have

453
00:16:29,759 --> 00:16:33,440
implications for

454
00:16:31,279 --> 00:16:34,839
accuracy loss for all the dnns in the

455
00:16:33,440 --> 00:16:38,079
core

456
00:16:34,839 --> 00:16:40,480
right so

457
00:16:38,079 --> 00:16:41,758
in essence the previous two algorithms

458
00:16:40,480 --> 00:16:44,399
would not solve our

459
00:16:41,759 --> 00:16:46,560
optimization problem what they'll do is

460
00:16:44,399 --> 00:16:48,160
they create a projected decision tree

461
00:16:46,560 --> 00:16:50,239
for each dna instance

462
00:16:48,160 --> 00:16:52,319
based on this tree we can choose a pair

463
00:16:50,240 --> 00:16:52,800
of configurations a dvfs configuration

464
00:16:52,320 --> 00:16:55,040
and an

465
00:16:52,800 --> 00:16:58,319
approximation configuration for the

466
00:16:55,040 --> 00:17:00,800
local dna instance at the layer boundary

467
00:16:58,320 --> 00:17:02,639
how this decision is made purely depends

468
00:17:00,800 --> 00:17:04,240
on the system requirement for example

469
00:17:02,639 --> 00:17:06,160
for max accuracy we only

470
00:17:04,240 --> 00:17:08,160
consider paths that involve no

471
00:17:06,160 --> 00:17:08,799
approximation but please see the paper

472
00:17:08,160 --> 00:17:12,000
if you want to

473
00:17:08,799 --> 00:17:14,400
learn more about our design so

474
00:17:12,000 --> 00:17:16,319
now comes the interesting stuff so our

475
00:17:14,400 --> 00:17:20,079
implementation and evaluation

476
00:17:16,319 --> 00:17:22,079
our implementation is based on cafe

477
00:17:20,079 --> 00:17:23,599
and we made it available as an open

478
00:17:22,079 --> 00:17:26,480
source project

479
00:17:23,599 --> 00:17:28,319
to use new os you don't need to use any

480
00:17:26,480 --> 00:17:30,480
apis or change your model

481
00:17:28,319 --> 00:17:32,720
you do need to however generate hash

482
00:17:30,480 --> 00:17:34,559
tables for dbfs configurations for each

483
00:17:32,720 --> 00:17:36,799
platform and each dnf

484
00:17:34,559 --> 00:17:39,039
you also need to generate the lowering

485
00:17:36,799 --> 00:17:40,799
approximation version of your dnn model

486
00:17:39,039 --> 00:17:44,320
the scripts for this we

487
00:17:40,799 --> 00:17:46,559
already provide so this initial cost of

488
00:17:44,320 --> 00:17:48,960
preparing these tables and the low rank

489
00:17:46,559 --> 00:17:48,960
model

490
00:17:49,679 --> 00:17:54,880
has to only be incurred once and will

491
00:17:53,440 --> 00:17:56,960
substantially reduce the runtime

492
00:17:54,880 --> 00:18:01,840
complexity of our approach making it

493
00:17:56,960 --> 00:18:01,840
efficient as a real world solution

494
00:18:01,919 --> 00:18:08,720
so we also extensively evaluate

495
00:18:04,960 --> 00:18:11,760
new os we evaluated on the nvidia's

496
00:18:08,720 --> 00:18:13,520
low power jetson tx2 which is an

497
00:18:11,760 --> 00:18:15,760
embedded device and the

498
00:18:13,520 --> 00:18:17,120
next generation and much faster jetson

499
00:18:15,760 --> 00:18:18,799
ags xavier

500
00:18:17,120 --> 00:18:21,360
which is actively being pushed for

501
00:18:18,799 --> 00:18:24,080
autonomous emblem systems by nvidia

502
00:18:21,360 --> 00:18:24,719
uh we use image recognition dnns alexnet

503
00:18:24,080 --> 00:18:27,199
google net

504
00:18:24,720 --> 00:18:28,880
resnet and vgnet as a representative of

505
00:18:27,200 --> 00:18:31,280
our target platform

506
00:18:28,880 --> 00:18:33,280
we set our target latencies based on dnn

507
00:18:31,280 --> 00:18:35,039
complexity and platform

508
00:18:33,280 --> 00:18:38,480
just the deadlines are based on the

509
00:18:35,039 --> 00:18:38,480
characteristics of the dnns

510
00:18:39,679 --> 00:18:46,080
we also test our platform

511
00:18:43,039 --> 00:18:48,240
using various sizes of cohort using a

512
00:18:46,080 --> 00:18:49,760
small chord with one dna instance

513
00:18:48,240 --> 00:18:51,679
to directly compare against all the

514
00:18:49,760 --> 00:18:56,080
approaches that are multidn and

515
00:18:51,679 --> 00:18:58,720
agnostic and we also have medium

516
00:18:56,080 --> 00:19:01,120
a medium cohort and a large cohort to

517
00:18:58,720 --> 00:19:03,919
test our multi-dnn capability

518
00:19:01,120 --> 00:19:04,719
we also include a mix scenario which we

519
00:19:03,919 --> 00:19:06,640
uh

520
00:19:04,720 --> 00:19:09,039
include the dna instance from each of

521
00:19:06,640 --> 00:19:10,559
these to show the versatility of our

522
00:19:09,039 --> 00:19:13,919
approach

523
00:19:10,559 --> 00:19:16,399
okay so let's first evaluate the energy

524
00:19:13,919 --> 00:19:16,400
profile

525
00:19:17,840 --> 00:19:24,000
so this

526
00:19:21,039 --> 00:19:24,879
first we evaluate energy profile latency

527
00:19:24,000 --> 00:19:27,600
and accuracy for

528
00:19:24,880 --> 00:19:29,039
a balanced approach which we believe is

529
00:19:27,600 --> 00:19:32,480
going to be the most

530
00:19:29,039 --> 00:19:35,120
widely applicable approach to general

531
00:19:32,480 --> 00:19:35,120
applications

532
00:19:36,840 --> 00:19:42,240
so for the small cohort we compare

533
00:19:40,240 --> 00:19:43,840
against system level solutions spread to

534
00:19:42,240 --> 00:19:46,160
poet and race to idle

535
00:19:43,840 --> 00:19:49,039
and hardware level solutions max n and

536
00:19:46,160 --> 00:19:51,280
max q provided by nvidia

537
00:19:49,039 --> 00:19:52,640
and you can see the breakdown for energy

538
00:19:51,280 --> 00:19:55,039
for the small cohort

539
00:19:52,640 --> 00:19:55,840
we compare against all the solutions for

540
00:19:55,039 --> 00:19:57,679
medium

541
00:19:55,840 --> 00:19:58,959
and large cohorts we compare only

542
00:19:57,679 --> 00:20:01,840
against spread

543
00:19:58,960 --> 00:20:02,320
to save space and also because in our

544
00:20:01,840 --> 00:20:04,840
test

545
00:20:02,320 --> 00:20:06,799
it vastly outperforms other solutions

546
00:20:04,840 --> 00:20:08,799
anyway

547
00:20:06,799 --> 00:20:10,879
so as you can see across the board nuos

548
00:20:08,799 --> 00:20:13,520
outperforms other solutions

549
00:20:10,880 --> 00:20:15,120
because of its layer word design its

550
00:20:13,520 --> 00:20:16,799
capability to coordinate between

551
00:20:15,120 --> 00:20:18,799
application and system

552
00:20:16,799 --> 00:20:20,559
and its ability to communicate between

553
00:20:18,799 --> 00:20:23,760
multiple dna instances

554
00:20:20,559 --> 00:20:26,960
you can see here that we have uh

555
00:20:23,760 --> 00:20:29,919
about 68 average improvement on tx2

556
00:20:26,960 --> 00:20:32,400
and 46 percent average improvement on

557
00:20:29,919 --> 00:20:34,880
the agx xavier for the small cohort

558
00:20:32,400 --> 00:20:37,760
and 70 average improvement on tx2 for

559
00:20:34,880 --> 00:20:39,520
the medium and large core

560
00:20:37,760 --> 00:20:41,520
however there are some anomalies here as

561
00:20:39,520 --> 00:20:44,799
you can see for vggnet

562
00:20:41,520 --> 00:20:46,320
and for the medium cohort and for some

563
00:20:44,799 --> 00:20:49,840
dna instances for the

564
00:20:46,320 --> 00:20:49,840
large cohort on the agx

565
00:20:50,080 --> 00:20:54,158
new os performs slightly worse than

566
00:20:52,080 --> 00:20:56,240
prejud and we shall explain why in the

567
00:20:54,159 --> 00:20:59,280
next slide

568
00:20:56,240 --> 00:21:02,080
so here's the latency breakdown

569
00:20:59,280 --> 00:21:03,600
as you can see here newest outperforms

570
00:21:02,080 --> 00:21:04,720
other solutions and i'll give you the

571
00:21:03,600 --> 00:21:06,959
numbers in a second

572
00:21:04,720 --> 00:21:08,880
but the anomalies we talked about here

573
00:21:06,960 --> 00:21:10,799
you can see that the credible would miss

574
00:21:08,880 --> 00:21:14,240
the deadlines we've set for it

575
00:21:10,799 --> 00:21:17,280
um however newers would not so the

576
00:21:14,240 --> 00:21:20,559
sacrificing energy was to

577
00:21:17,280 --> 00:21:22,399
meet the deadline and here's our average

578
00:21:20,559 --> 00:21:24,158
improvements

579
00:21:22,400 --> 00:21:26,480
again across the board we see

580
00:21:24,159 --> 00:21:28,960
improvements

581
00:21:26,480 --> 00:21:30,159
tx2 has more headroom for improvements

582
00:21:28,960 --> 00:21:32,400
but you can see

583
00:21:30,159 --> 00:21:34,799
also substantial improvements on the

584
00:21:32,400 --> 00:21:37,760
agex xavier

585
00:21:34,799 --> 00:21:40,080
we also do tail latency analysis where

586
00:21:37,760 --> 00:21:42,720
we first

587
00:21:40,080 --> 00:21:44,240
measure the deadline miss ratio and you

588
00:21:42,720 --> 00:21:46,080
we find that it's

589
00:21:44,240 --> 00:21:48,000
about three percent across the board for

590
00:21:46,080 --> 00:21:50,639
small medium and large cohorts

591
00:21:48,000 --> 00:21:52,159
we also record tail latency here it's

592
00:21:50,640 --> 00:21:55,280
the 99.9

593
00:21:52,159 --> 00:21:58,240
percentile and you can see

594
00:21:55,280 --> 00:21:59,120
that it is within an acceptable range

595
00:21:58,240 --> 00:22:02,000
given that it

596
00:21:59,120 --> 00:22:02,959
only happens less than three percent of

597
00:22:02,000 --> 00:22:04,799
the time

598
00:22:02,960 --> 00:22:06,240
finally we also measure the relative

599
00:22:04,799 --> 00:22:08,960
accuracy so

600
00:22:06,240 --> 00:22:09,760
this accuracy how it is calculated is a

601
00:22:08,960 --> 00:22:12,799
little bit

602
00:22:09,760 --> 00:22:15,840
um complicated

603
00:22:12,799 --> 00:22:16,960
in the paper we detail how this accuracy

604
00:22:15,840 --> 00:22:18,720
is calculated

605
00:22:16,960 --> 00:22:20,000
so please consult the paper if you have

606
00:22:18,720 --> 00:22:22,720
questions

607
00:22:20,000 --> 00:22:24,840
um here we only compare against ap net

608
00:22:22,720 --> 00:22:28,559
because that's the only runtime

609
00:22:24,840 --> 00:22:31,280
um dynamic accuracy adjustment

610
00:22:28,559 --> 00:22:33,039
application we know for dnns

611
00:22:31,280 --> 00:22:34,320
which is tailored for autonomous

612
00:22:33,039 --> 00:22:37,360
embedded systems

613
00:22:34,320 --> 00:22:39,678
and because just purely because nuos has

614
00:22:37,360 --> 00:22:42,240
the ability to adjust dbfs configuration

615
00:22:39,679 --> 00:22:46,320
let's allow the optimization algorithm

616
00:22:42,240 --> 00:22:48,720
it can outperform ap net we also

617
00:22:46,320 --> 00:22:49,600
do evaluation on our flexibility which

618
00:22:48,720 --> 00:22:52,240
we compare

619
00:22:49,600 --> 00:22:52,719
our max accuracy mean energy and balance

620
00:22:52,240 --> 00:22:55,520
approach

621
00:22:52,720 --> 00:22:56,720
shown as t is here again spread to and

622
00:22:55,520 --> 00:23:00,000
overall

623
00:22:56,720 --> 00:23:02,640
um for

624
00:23:00,000 --> 00:23:04,720
the jetson tx2 the balanced approach it

625
00:23:02,640 --> 00:23:08,000
performs very well so holds up very well

626
00:23:04,720 --> 00:23:10,400
but you can actually get

627
00:23:08,000 --> 00:23:11,679
especially for medium and large cohorts

628
00:23:10,400 --> 00:23:15,360
lower

629
00:23:11,679 --> 00:23:17,200
accuracy loss if you use ma

630
00:23:15,360 --> 00:23:18,719
actually zero accuracy loss if you use

631
00:23:17,200 --> 00:23:21,679
ma and

632
00:23:18,720 --> 00:23:23,280
um minimum energy consumption if you use

633
00:23:21,679 --> 00:23:24,640
mp

634
00:23:23,280 --> 00:23:27,440
and on the right you can see the

635
00:23:24,640 --> 00:23:28,880
configuration space for the dvfs and

636
00:23:27,440 --> 00:23:33,039
accuracy adjustment

637
00:23:28,880 --> 00:23:36,159
uh on the jetson tx2

638
00:23:33,039 --> 00:23:39,760
this is in a ternary plot and again how

639
00:23:36,159 --> 00:23:41,840
we did this is please consult the paper

640
00:23:39,760 --> 00:23:43,360
but you can see that the desirable

641
00:23:41,840 --> 00:23:45,039
configurations even though we're trying

642
00:23:43,360 --> 00:23:46,399
to optimize this problem the desirable

643
00:23:45,039 --> 00:23:49,520
configurations are down

644
00:23:46,400 --> 00:23:51,520
on the corner on the left but still

645
00:23:49,520 --> 00:23:53,679
they have huge implications which one

646
00:23:51,520 --> 00:23:56,720
you choose

647
00:23:53,679 --> 00:23:58,799
and just to give you uh

648
00:23:56,720 --> 00:23:59,840
a point of view on how complex this

649
00:23:58,799 --> 00:24:02,080
problem is is

650
00:23:59,840 --> 00:24:04,639
you have almost 12 000 dbfs

651
00:24:02,080 --> 00:24:07,039
configurations on the jetson tx2 and 52

652
00:24:04,640 --> 00:24:09,840
000 dbfs configurations unique dvfs

653
00:24:07,039 --> 00:24:12,480
configurations on the agx xav

654
00:24:09,840 --> 00:24:14,959
and we also measure our overhead both in

655
00:24:12,480 --> 00:24:16,880
terms of computation and memory overhead

656
00:24:14,960 --> 00:24:18,240
so the computation overhead is as you

657
00:24:16,880 --> 00:24:22,240
can see relatively

658
00:24:18,240 --> 00:24:25,520
negligible it's in microseconds um

659
00:24:22,240 --> 00:24:29,039
relative to the execution time of the

660
00:24:25,520 --> 00:24:30,879
dnn instances this is for alexnet

661
00:24:29,039 --> 00:24:32,720
and on the right you can see the memory

662
00:24:30,880 --> 00:24:35,840
overhead for all the

663
00:24:32,720 --> 00:24:39,039
dnns that we use

664
00:24:35,840 --> 00:24:42,879
so what is unavoidable is the low rank

665
00:24:39,039 --> 00:24:44,840
um but you can see on the right we have

666
00:24:42,880 --> 00:24:46,000
we have also included the ratio to total

667
00:24:44,840 --> 00:24:48,559
memory

668
00:24:46,000 --> 00:24:50,240
which shows that comfortably you can

669
00:24:48,559 --> 00:24:52,158
have

670
00:24:50,240 --> 00:24:54,000
up to eight instances of even the

671
00:24:52,159 --> 00:24:58,880
largest one vgnet

672
00:24:54,000 --> 00:25:01,200
on the ajax xavier and the txt

673
00:24:58,880 --> 00:25:03,279
so i would like to conclude by saying

674
00:25:01,200 --> 00:25:04,720
that this problem is uniquely positioned

675
00:25:03,279 --> 00:25:06,640
for the system community

676
00:25:04,720 --> 00:25:07,919
so the ai researchers and hardware

677
00:25:06,640 --> 00:25:10,159
researchers

678
00:25:07,919 --> 00:25:11,440
don't have the tools that we have to

679
00:25:10,159 --> 00:25:14,159
solve this problem

680
00:25:11,440 --> 00:25:15,919
and uh i'll be glad to answer any of

681
00:25:14,159 --> 00:25:17,600
your questions here's my email and

682
00:25:15,919 --> 00:25:19,760
here's the source code of new os

683
00:25:17,600 --> 00:25:21,039
if you have issues please raise an issue

684
00:25:19,760 --> 00:25:29,840
on github and i'll

685
00:25:21,039 --> 00:25:29,840
get to it right away thank you

686
00:25:32,559 --> 00:25:34,639
you

