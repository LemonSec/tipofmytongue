1
00:00:08,480 --> 00:00:14,320
hello everyone my name is jay park

2
00:00:10,880 --> 00:00:16,640
and i'm a phd candidate in unison korea

3
00:00:14,320 --> 00:00:19,039
in this talk i represent head pipe

4
00:00:16,640 --> 00:00:21,520
enabling large dnn training on vimpy

5
00:00:19,039 --> 00:00:23,760
heterogeneous gpu clusters

6
00:00:21,520 --> 00:00:27,439
through integration of pipelined border

7
00:00:23,760 --> 00:00:27,439
perigeum and theta parallelism

8
00:00:28,000 --> 00:00:34,239
this is the top outline i'll start with

9
00:00:30,800 --> 00:00:34,239
motivation and background

10
00:00:35,040 --> 00:00:38,960
dna models continue to grow for higher

11
00:00:37,440 --> 00:00:40,640
accuracy

12
00:00:38,960 --> 00:00:42,559
this graph shows the number of

13
00:00:40,640 --> 00:00:45,600
parameters for each model

14
00:00:42,559 --> 00:00:46,480
and imagine a type 1 accuracy in the

15
00:00:45,600 --> 00:00:48,640
centres

16
00:00:46,480 --> 00:00:50,800
larger models are used to increase

17
00:00:48,640 --> 00:00:53,280
accuracy

18
00:00:50,800 --> 00:00:56,399
this condition requires more powerful

19
00:00:53,280 --> 00:00:58,399
fuse for training

20
00:00:56,399 --> 00:01:01,600
as the tna model grows better

21
00:00:58,399 --> 00:01:03,840
performance gpus are released every year

22
00:01:01,600 --> 00:01:05,199
training a large dnm requires more

23
00:01:03,840 --> 00:01:07,200
powerful gpus

24
00:01:05,199 --> 00:01:09,600
but it is practically difficult to

25
00:01:07,200 --> 00:01:11,040
purchase the highest performance gpus

26
00:01:09,600 --> 00:01:14,320
every time

27
00:01:11,040 --> 00:01:16,320
even if we purchase new gpus we need to

28
00:01:14,320 --> 00:01:17,119
take advantage of old and low

29
00:01:16,320 --> 00:01:20,479
performance

30
00:01:17,119 --> 00:01:21,119
windpitch fuels the usual heterogeneous

31
00:01:20,479 --> 00:01:23,920
gpu

32
00:01:21,119 --> 00:01:25,119
is inevitable due to the short release

33
00:01:23,920 --> 00:01:28,560
cycle of utp

34
00:01:25,119 --> 00:01:30,400
architectures so what can you do with

35
00:01:28,560 --> 00:01:33,600
vintage pews

36
00:01:30,400 --> 00:01:37,600
this paper answers these questions

37
00:01:33,600 --> 00:01:40,960
but first i will explain the background

38
00:01:37,600 --> 00:01:43,600
let's take a brief look at dnn training

39
00:01:40,960 --> 00:01:47,199
the dna model has a weight parameter w

40
00:01:43,600 --> 00:01:49,600
to train and find the optimal value

41
00:01:47,200 --> 00:01:51,360
training data randomly sampled into mini

42
00:01:49,600 --> 00:01:54,798
batches

43
00:01:51,360 --> 00:01:57,759
mini batches are fed into models first

44
00:01:54,799 --> 00:01:59,920
the forward pass generates predictions

45
00:01:57,759 --> 00:02:02,799
and calculates the loss between the

46
00:01:59,920 --> 00:02:05,360
prediction and real labor

47
00:02:02,799 --> 00:02:06,719
then backward pass backward package

48
00:02:05,360 --> 00:02:10,160
errors to obtain you

49
00:02:06,719 --> 00:02:10,160
to update bold average

50
00:02:10,639 --> 00:02:15,040
parallelizing dnn training is used to

51
00:02:13,120 --> 00:02:17,760
speed up the training

52
00:02:15,040 --> 00:02:21,120
there are two parallelization approaches

53
00:02:17,760 --> 00:02:23,599
data parallelism and body parallation

54
00:02:21,120 --> 00:02:25,280
for data perishing each worker holds

55
00:02:23,599 --> 00:02:27,599
your replicated border

56
00:02:25,280 --> 00:02:29,280
and processes different set of training

57
00:02:27,599 --> 00:02:31,760
data

58
00:02:29,280 --> 00:02:33,200
replicated models are synchronized

59
00:02:31,760 --> 00:02:36,640
through parameter server

60
00:02:33,200 --> 00:02:39,040
or earliest communication however

61
00:02:36,640 --> 00:02:40,799
tp cannot train models larger than the

62
00:02:39,040 --> 00:02:44,720
gph memory

63
00:02:40,800 --> 00:02:47,280
to solve this model parallelism is used

64
00:02:44,720 --> 00:02:48,640
mp partitions model among multi-project

65
00:02:47,280 --> 00:02:51,440
fuse

66
00:02:48,640 --> 00:02:54,160
each piece is responsible for training

67
00:02:51,440 --> 00:02:56,480
of assigned model layers

68
00:02:54,160 --> 00:02:57,359
however this leads to low speed

69
00:02:56,480 --> 00:03:00,159
utilization

70
00:02:57,360 --> 00:03:03,120
[Music]

71
00:03:00,159 --> 00:03:04,000
to improve the utilization of moderation

72
00:03:03,120 --> 00:03:07,840
mini minivaches

73
00:03:04,000 --> 00:03:10,640
can be processed in a pipelined manner

74
00:03:07,840 --> 00:03:12,400
this pmp stretch has been investigated

75
00:03:10,640 --> 00:03:14,720
in previous studies

76
00:03:12,400 --> 00:03:17,760
pipedream exploits pmp to avoid

77
00:03:14,720 --> 00:03:20,400
parameter communication available tp

78
00:03:17,760 --> 00:03:22,959
and g5 is your scheme to support large

79
00:03:20,400 --> 00:03:25,200
dna models

80
00:03:22,959 --> 00:03:26,159
these studies are designed for to be

81
00:03:25,200 --> 00:03:29,760
used in

82
00:03:26,159 --> 00:03:33,840
homogeneous cpus it also launched as

83
00:03:29,760 --> 00:03:37,599
a single pnp occur

84
00:03:33,840 --> 00:03:38,640
then we propose headphy this is have 5.0

85
00:03:37,599 --> 00:03:41,280
share

86
00:03:38,640 --> 00:03:42,879
first we call this 1 pmp worker as a

87
00:03:41,280 --> 00:03:45,519
virtual account

88
00:03:42,879 --> 00:03:48,280
in hack 5 we define a group of multiple

89
00:03:45,519 --> 00:03:51,519
trips as a virtual worker

90
00:03:48,280 --> 00:03:54,720
multi-perpetual cars can configure it

91
00:03:51,519 --> 00:03:57,040
virtual cars gpus can be heterogeneous

92
00:03:54,720 --> 00:03:59,599
as shown in the figure virtual car can

93
00:03:57,040 --> 00:04:02,000
have different performance

94
00:03:59,599 --> 00:04:04,079
to synchronize each virtual course page

95
00:04:02,000 --> 00:04:07,040
data paragraph is performed with a

96
00:04:04,080 --> 00:04:07,040
parameter server

97
00:04:07,360 --> 00:04:12,720
here we synchronize with our double

98
00:04:09,599 --> 00:04:14,879
parameter synchronization model wsp

99
00:04:12,720 --> 00:04:17,439
which stands for wave synchronous

100
00:04:14,879 --> 00:04:17,438
parallel

101
00:04:17,918 --> 00:04:21,440
integrating pnp with tp may sound

102
00:04:20,560 --> 00:04:24,639
trivial

103
00:04:21,440 --> 00:04:26,160
but in fact it is quite challenging also

104
00:04:24,639 --> 00:04:26,800
considering the heterogeneous

105
00:04:26,160 --> 00:04:29,840
environment

106
00:04:26,800 --> 00:04:31,759
cause many problems first

107
00:04:29,840 --> 00:04:34,000
what weight version should be used by

108
00:04:31,759 --> 00:04:36,160
each virtual worker to synchronize with

109
00:04:34,000 --> 00:04:38,800
other virtual occurs

110
00:04:36,160 --> 00:04:42,720
second how do we reduce virtual record

111
00:04:38,800 --> 00:04:45,919
straight blurs when we consider tp

112
00:04:42,720 --> 00:04:46,320
many more challenges are in the paper we

113
00:04:45,919 --> 00:04:49,520
solve

114
00:04:46,320 --> 00:04:49,520
some of the problems

115
00:04:50,240 --> 00:04:54,400
our contributions are as follows high

116
00:04:53,440 --> 00:04:56,560
pipe enables

117
00:04:54,400 --> 00:04:58,799
large dna training on a heterogeneous

118
00:04:56,560 --> 00:05:01,039
gpu cluster environment

119
00:04:58,800 --> 00:05:02,639
through this heterogeneous resource can

120
00:05:01,039 --> 00:05:05,280
be utilized well

121
00:05:02,639 --> 00:05:07,520
and regular problems can be solved to

122
00:05:05,280 --> 00:05:09,758
speed up the training

123
00:05:07,520 --> 00:05:11,520
integrate pipelined body perishing and

124
00:05:09,759 --> 00:05:13,919
data parallelism

125
00:05:11,520 --> 00:05:16,479
we propose a parameter synchronization

126
00:05:13,919 --> 00:05:19,359
model wsp

127
00:05:16,479 --> 00:05:21,440
we proved that the dna model converges

128
00:05:19,360 --> 00:05:25,919
with wsp

129
00:05:21,440 --> 00:05:29,360
now let me explain how the pipe works

130
00:05:25,919 --> 00:05:31,520
this is hepa workflow resource locator

131
00:05:29,360 --> 00:05:32,160
receives cluster configuration and

132
00:05:31,520 --> 00:05:36,080
decides

133
00:05:32,160 --> 00:05:38,639
which gpus to use for each virtual occur

134
00:05:36,080 --> 00:05:40,960
diffuse assigns to each virtual core can

135
00:05:38,639 --> 00:05:43,520
be heterogeneous

136
00:05:40,960 --> 00:05:45,198
next after receiving the dna model and

137
00:05:43,520 --> 00:05:47,599
gpu configuration

138
00:05:45,199 --> 00:05:49,280
the model partitional partitions model

139
00:05:47,600 --> 00:05:51,039
into k

140
00:05:49,280 --> 00:05:52,960
the model partition has different

141
00:05:51,039 --> 00:05:56,960
partition research considering the

142
00:05:52,960 --> 00:05:59,440
heterogeneous gpus of each culture occur

143
00:05:56,960 --> 00:06:02,719
partitions borders are assigned to each

144
00:05:59,440 --> 00:06:02,719
virtual course gpu

145
00:06:04,800 --> 00:06:10,319
now each virtual worker performs pnp

146
00:06:08,000 --> 00:06:12,319
virtual occurs a multiple mini batch

147
00:06:10,319 --> 00:06:15,039
concurrently and each virtual occurred

148
00:06:12,319 --> 00:06:18,639
can have a different speed

149
00:06:15,039 --> 00:06:22,240
here the stylus problem is inevitable

150
00:06:18,639 --> 00:06:24,800
each part of a car can have local teles

151
00:06:22,240 --> 00:06:26,479
a pipe also has global stylists while

152
00:06:24,800 --> 00:06:28,240
synchronizing the weights of each

153
00:06:26,479 --> 00:06:30,800
virtual occurrence

154
00:06:28,240 --> 00:06:33,919
i will describe both local stylists and

155
00:06:30,800 --> 00:06:34,400
global stylists in world detail later

156
00:06:33,919 --> 00:06:37,120
first

157
00:06:34,400 --> 00:06:40,960
i will explain the detail how wsp

158
00:06:37,120 --> 00:06:40,960
synchronize each virtual curve

159
00:06:41,360 --> 00:06:45,520
let's start with the single virtual

160
00:06:43,120 --> 00:06:45,520
occur

161
00:06:45,840 --> 00:06:49,919
this is the behavior between a single

162
00:06:47,919 --> 00:06:52,400
virtual occur

163
00:06:49,919 --> 00:06:55,039
virtual workers can non-any mini batches

164
00:06:52,400 --> 00:06:58,799
concurrently in a pipelined manner

165
00:06:55,039 --> 00:07:01,120
for example we will show an image 4.

166
00:06:58,800 --> 00:07:04,479
each number represents a sequence of

167
00:07:01,120 --> 00:07:07,360
mini batch in a different data set

168
00:07:04,479 --> 00:07:09,440
and each virtual car has a consistent

169
00:07:07,360 --> 00:07:11,840
version of local weight

170
00:07:09,440 --> 00:07:16,080
this local rate is used to manage the

171
00:07:11,840 --> 00:07:19,520
weight within the virtual worker

172
00:07:16,080 --> 00:07:21,280
i will explain how to update which

173
00:07:19,520 --> 00:07:23,520
when the initial weight version is

174
00:07:21,280 --> 00:07:25,599
double zero the local weight

175
00:07:23,520 --> 00:07:27,840
and the weight of mean vectors one to

176
00:07:25,599 --> 00:07:30,319
four are the same

177
00:07:27,840 --> 00:07:32,318
when mini battery one is finished the

178
00:07:30,319 --> 00:07:35,759
result of u1 is update

179
00:07:32,319 --> 00:07:38,479
to the local rate the local rate is

180
00:07:35,759 --> 00:07:41,360
updated with u1

181
00:07:38,479 --> 00:07:44,560
then minibase 5 launched with the latest

182
00:07:41,360 --> 00:07:48,240
local weight

183
00:07:44,560 --> 00:07:50,720
i will explain the local style list

184
00:07:48,240 --> 00:07:52,560
the rates of wind batch 5 does not have

185
00:07:50,720 --> 00:07:55,759
updates from universe 2

186
00:07:52,560 --> 00:07:59,919
3 and 4 because at this point

187
00:07:55,759 --> 00:08:02,319
minifigures 2 3 and 4 are running

188
00:07:59,919 --> 00:08:03,440
we defined each missing object as local

189
00:08:02,319 --> 00:08:07,360
stylist

190
00:08:03,440 --> 00:08:09,280
here it is 3. local stylist is necessary

191
00:08:07,360 --> 00:08:11,360
because multiple mini patches are

192
00:08:09,280 --> 00:08:13,840
running concurrently in a pipelined

193
00:08:11,360 --> 00:08:13,840
banners

194
00:08:14,080 --> 00:08:18,159
the update of mini batch 2 is done in

195
00:08:16,400 --> 00:08:20,318
the same way

196
00:08:18,160 --> 00:08:22,080
here local weight is the version that

197
00:08:20,319 --> 00:08:26,160
reflects an update over

198
00:08:22,080 --> 00:08:29,840
previous minivah1 minibase6 likewise

199
00:08:26,160 --> 00:08:33,759
has a local stylist the pipeline

200
00:08:29,840 --> 00:08:33,759
launched while rotating the same way

201
00:08:34,719 --> 00:08:40,959
next i will explain the behavior of

202
00:08:37,039 --> 00:08:44,159
multiple virtual occurs

203
00:08:40,958 --> 00:08:46,560
a 5 can have n virtual occurs

204
00:08:44,159 --> 00:08:48,480
green arrows indicate the progress of

205
00:08:46,560 --> 00:08:50,719
each mini batch number

206
00:08:48,480 --> 00:08:54,240
as in the example of a single virtual

207
00:08:50,720 --> 00:08:56,720
card a name is 4 in this figure

208
00:08:54,240 --> 00:08:57,839
have 5 defines wave as a sequence of

209
00:08:56,720 --> 00:09:00,000
mini-batches

210
00:08:57,839 --> 00:09:02,959
that are proceed concurrently without

211
00:09:00,000 --> 00:09:05,120
dependency in a virtual worker

212
00:09:02,959 --> 00:09:08,399
and the clock unit is defined as

213
00:09:05,120 --> 00:09:10,320
progress of completing one way

214
00:09:08,399 --> 00:09:12,240
high five wave synchronous parallel

215
00:09:10,320 --> 00:09:14,399
model synchronizes

216
00:09:12,240 --> 00:09:15,680
ways through push shampoo in a clock

217
00:09:14,399 --> 00:09:17,399
unit

218
00:09:15,680 --> 00:09:18,880
it has a parameter server for

219
00:09:17,399 --> 00:09:21,279
synchronization

220
00:09:18,880 --> 00:09:22,720
and global weight is in the parameter

221
00:09:21,279 --> 00:09:25,040
server

222
00:09:22,720 --> 00:09:27,839
next i will explain the procedure of

223
00:09:25,040 --> 00:09:27,839
push and pull

224
00:09:28,320 --> 00:09:32,320
let's explain it in the case of virtual

225
00:09:30,720 --> 00:09:34,880
occur one

226
00:09:32,320 --> 00:09:37,440
the first push occurs at clock 1 when

227
00:09:34,880 --> 00:09:40,240
wave 0 completes

228
00:09:37,440 --> 00:09:41,680
after minibase 4 is finished the

229
00:09:40,240 --> 00:09:45,440
is performed

230
00:09:41,680 --> 00:09:48,479
at this point minibatch 8 is blocked

231
00:09:45,440 --> 00:09:50,480
on the other hand mini batches 5 to 7

232
00:09:48,480 --> 00:09:53,200
can proceed

233
00:09:50,480 --> 00:09:54,240
push sends the aggregated object to wave

234
00:09:53,200 --> 00:09:56,240
0.

235
00:09:54,240 --> 00:09:58,720
this is the aggregated update of

236
00:09:56,240 --> 00:10:01,440
minibase 1 to 4.

237
00:09:58,720 --> 00:10:04,079
finally the global weight of parameter

238
00:10:01,440 --> 00:10:09,360
server is updated with the aggregated

239
00:10:04,079 --> 00:10:09,359
u push operation occurs every clock

240
00:10:10,640 --> 00:10:16,399
however pull occurs intermittently

241
00:10:14,000 --> 00:10:18,560
it is determined by the clock distance

242
00:10:16,399 --> 00:10:21,279
threshold t

243
00:10:18,560 --> 00:10:22,800
if t value is zero pull occurs every

244
00:10:21,279 --> 00:10:25,360
clock

245
00:10:22,800 --> 00:10:27,359
for virtual occur want to pull it has to

246
00:10:25,360 --> 00:10:29,760
wait until all other virtual occurs

247
00:10:27,360 --> 00:10:32,160
finishing the push

248
00:10:29,760 --> 00:10:33,519
here i will explain with the example of

249
00:10:32,160 --> 00:10:37,360
virtual rocker 2

250
00:10:33,519 --> 00:10:39,680
or relatively slower low current

251
00:10:37,360 --> 00:10:42,480
virtual worker launch mini batteries 5

252
00:10:39,680 --> 00:10:45,599
to 7 can proceed

253
00:10:42,480 --> 00:10:49,360
after wave 0 or virtual car 2 is over

254
00:10:45,600 --> 00:10:51,920
and virtual occur 2 push as clock 1.

255
00:10:49,360 --> 00:10:56,160
the push process of virtual occur 2 is

256
00:10:51,920 --> 00:10:56,160
the same as that of virtual rocker 1.

257
00:10:56,720 --> 00:11:00,000
herbert travel car have finished it

258
00:10:58,720 --> 00:11:03,360
pushing and then

259
00:11:00,000 --> 00:11:05,600
pull occurs the full operation brings

260
00:11:03,360 --> 00:11:08,560
the global wage to the local range of

261
00:11:05,600 --> 00:11:11,279
each virtual occur

262
00:11:08,560 --> 00:11:13,518
when done synchronizing mini-batch 8 is

263
00:11:11,279 --> 00:11:16,640
ready to proceed

264
00:11:13,519 --> 00:11:18,079
the hlb h8 reflects updates of

265
00:11:16,640 --> 00:11:22,160
mini-batch one to four

266
00:11:18,079 --> 00:11:24,079
of each virtual car local stylists and

267
00:11:22,160 --> 00:11:24,880
global sellers will be explained

268
00:11:24,079 --> 00:11:28,479
together with

269
00:11:24,880 --> 00:11:28,880
examples when the pipeline continues to

270
00:11:28,480 --> 00:11:31,360
launch

271
00:11:28,880 --> 00:11:33,839
i will explain the weighted status of

272
00:11:31,360 --> 00:11:36,079
mini batch 11.

273
00:11:33,839 --> 00:11:37,040
the weight value of minivah11 is

274
00:11:36,079 --> 00:11:41,040
composed as

275
00:11:37,040 --> 00:11:42,800
follows this started at the initial rate

276
00:11:41,040 --> 00:11:45,120
zero

277
00:11:42,800 --> 00:11:46,560
and the t update of being batch one to

278
00:11:45,120 --> 00:11:48,880
four or virtual cars

279
00:11:46,560 --> 00:11:50,959
one and two were reflected through the

280
00:11:48,880 --> 00:11:53,760
global rate

281
00:11:50,959 --> 00:11:56,319
next update to mini batches five to

282
00:11:53,760 --> 00:11:59,439
seven of virtual car one were reflected

283
00:11:56,320 --> 00:12:01,519
through local weight management

284
00:11:59,440 --> 00:12:04,800
however the updates showed from being

285
00:12:01,519 --> 00:12:07,040
batch 8 to 10 were now reflected

286
00:12:04,800 --> 00:12:11,040
these updates will be invested were not

287
00:12:07,040 --> 00:12:14,000
completed when mini batteries 11 started

288
00:12:11,040 --> 00:12:15,920
we previously described this as local

289
00:12:14,000 --> 00:12:18,639
stylist

290
00:12:15,920 --> 00:12:19,199
and there are missing updates of minivah

291
00:12:18,639 --> 00:12:22,399
5

292
00:12:19,200 --> 00:12:22,720
to 7 or virtual core 2 that have not yet

293
00:12:22,399 --> 00:12:26,480
been

294
00:12:22,720 --> 00:12:29,120
replaced in global wage these are global

295
00:12:26,480 --> 00:12:29,120
stylists

296
00:12:30,560 --> 00:12:35,680
minibase 12 has to wait at the

297
00:12:32,800 --> 00:12:37,839
synchronization point clock 2.

298
00:12:35,680 --> 00:12:38,719
it can be run after the virtual occurs

299
00:12:37,839 --> 00:12:41,760
me batch a

300
00:12:38,720 --> 00:12:44,720
is done and the synchronization process

301
00:12:41,760 --> 00:12:44,720
is completed

302
00:12:44,959 --> 00:12:50,000
i will explain a simple example of clock

303
00:12:47,600 --> 00:12:53,120
distance threshold d

304
00:12:50,000 --> 00:12:55,519
we call that value of d affects the

305
00:12:53,120 --> 00:12:58,639
frequency of poor operation

306
00:12:55,519 --> 00:13:01,360
if t is one this can have a one clock

307
00:12:58,639 --> 00:13:04,800
distance between the fastest and slowest

308
00:13:01,360 --> 00:13:07,279
virtual occurs so

309
00:13:04,800 --> 00:13:09,599
the mini batch a can continue without a

310
00:13:07,279 --> 00:13:09,600
pull

311
00:13:10,160 --> 00:13:15,600
going on virtual core one has two ways

312
00:13:12,399 --> 00:13:18,480
to pull performing batch 12 starch

313
00:13:15,600 --> 00:13:19,040
because d1 the clock distance does not

314
00:13:18,480 --> 00:13:23,200
exist

315
00:13:19,040 --> 00:13:24,719
one the weights of memphis 11 are as far

316
00:13:23,200 --> 00:13:27,040
lows

317
00:13:24,720 --> 00:13:29,200
as the pull has not been performed yet

318
00:13:27,040 --> 00:13:32,079
only updates one to seven or virtual

319
00:13:29,200 --> 00:13:35,920
corner reflected

320
00:13:32,079 --> 00:13:38,479
as with the 0 updates from 8 to 10 are

321
00:13:35,920 --> 00:13:40,800
local stylists

322
00:13:38,480 --> 00:13:41,920
global stylist in between updates of

323
00:13:40,800 --> 00:13:45,359
minivaches

324
00:13:41,920 --> 00:13:49,839
8 to 10 of virtual gowan and updates of

325
00:13:45,360 --> 00:13:49,839
batteries 1-7 of virtual core 2.

326
00:13:50,959 --> 00:13:57,760
now i will explain the evaluation

327
00:13:54,959 --> 00:13:58,638
to evaluate hep we use a heterogeneous

328
00:13:57,760 --> 00:14:01,600
cluster with

329
00:13:58,639 --> 00:14:02,480
four types of disputes each node is

330
00:14:01,600 --> 00:14:06,480
equipped with

331
00:14:02,480 --> 00:14:08,079
four homogeneous gpus implement connects

332
00:14:06,480 --> 00:14:10,720
four nodes

333
00:14:08,079 --> 00:14:12,959
the four fields used in the evaluation

334
00:14:10,720 --> 00:14:16,720
have different computation power and

335
00:14:12,959 --> 00:14:20,239
memory size we will show the result of

336
00:14:16,720 --> 00:14:22,639
the experiments using two dna models

337
00:14:20,240 --> 00:14:24,800
we use solid to mini-batch size from the

338
00:14:22,639 --> 00:14:26,639
imagenet data cell

339
00:14:24,800 --> 00:14:28,399
the original model has a relatively

340
00:14:26,639 --> 00:14:30,880
large activation output

341
00:14:28,399 --> 00:14:33,199
and the pcg model has a large parameter

342
00:14:30,880 --> 00:14:33,199
size

343
00:14:33,920 --> 00:14:38,160
i will explain three ways to configure a

344
00:14:36,320 --> 00:14:40,399
virtual curve

345
00:14:38,160 --> 00:14:42,079
first those partitional signs are node

346
00:14:40,399 --> 00:14:44,639
perpetual occur

347
00:14:42,079 --> 00:14:47,040
thus each virtual car is composed of

348
00:14:44,639 --> 00:14:49,120
homogeneous gpus

349
00:14:47,040 --> 00:14:52,560
mp results in minimal communication

350
00:14:49,120 --> 00:14:55,040
overhead within each virtual car

351
00:14:52,560 --> 00:14:56,880
on the other hand as each virtual car's

352
00:14:55,040 --> 00:14:59,279
performance differences

353
00:14:56,880 --> 00:15:01,680
a straggler may degrade performance with

354
00:14:59,279 --> 00:15:01,680
tp

355
00:15:01,760 --> 00:15:05,360
second equal distribution is evenly

356
00:15:04,399 --> 00:15:07,920
distributed

357
00:15:05,360 --> 00:15:09,120
gpus from each node to every virtual

358
00:15:07,920 --> 00:15:12,560
worker

359
00:15:09,120 --> 00:15:14,880
every virtual car has the same resources

360
00:15:12,560 --> 00:15:16,319
therefore virtual cars have the same

361
00:15:14,880 --> 00:15:20,000
performance

362
00:15:16,320 --> 00:15:22,079
this mitigates the struggler program

363
00:15:20,000 --> 00:15:24,079
however easy research in high

364
00:15:22,079 --> 00:15:26,479
communication overhead within each

365
00:15:24,079 --> 00:15:29,359
virtual occur

366
00:15:26,480 --> 00:15:30,800
finally this policy is a hybrid of mp

367
00:15:29,360 --> 00:15:33,120
and et

368
00:15:30,800 --> 00:15:34,560
aperture occur consists of two different

369
00:15:33,120 --> 00:15:37,199
gpus

370
00:15:34,560 --> 00:15:39,680
two gpus used for each virtual car are

371
00:15:37,199 --> 00:15:41,758
located to balance the computation power

372
00:15:39,680 --> 00:15:44,479
or memory size

373
00:15:41,759 --> 00:15:47,199
with hd configuration we can mitigate

374
00:15:44,480 --> 00:15:49,040
the straggler problem to some degree

375
00:15:47,199 --> 00:15:51,439
while we can reduce communication

376
00:15:49,040 --> 00:15:53,599
overhead between each virtual curve

377
00:15:51,440 --> 00:15:56,560
by using a smaller number node for

378
00:15:53,600 --> 00:15:56,560
aperture occur

379
00:15:57,120 --> 00:16:01,759
in our experiment we can have two

380
00:15:59,120 --> 00:16:04,560
policies for parameter placement

381
00:16:01,759 --> 00:16:06,480
first policy is round robin i've

382
00:16:04,560 --> 00:16:08,800
explained around drawing policy by

383
00:16:06,480 --> 00:16:10,800
example idi or location

384
00:16:08,800 --> 00:16:12,160
the model is partitions as in this

385
00:16:10,800 --> 00:16:14,399
figure

386
00:16:12,160 --> 00:16:16,880
global parameters are corresponding the

387
00:16:14,399 --> 00:16:18,959
color of each layer

388
00:16:16,880 --> 00:16:20,320
if parameters are placed in lounge

389
00:16:18,959 --> 00:16:23,839
logging on each node

390
00:16:20,320 --> 00:16:23,839
it can be as in this figure

391
00:16:24,720 --> 00:16:31,199
the second policy is local placement

392
00:16:28,000 --> 00:16:34,560
only ideal location is applicable

393
00:16:31,199 --> 00:16:38,479
we call this ed rocker

394
00:16:34,560 --> 00:16:38,479
let me explain about ed rocker

395
00:16:38,560 --> 00:16:45,040
we place the layers of partition on the

396
00:16:41,279 --> 00:16:48,160
parameter server running on a same node

397
00:16:45,040 --> 00:16:48,880
let's compare it with ed the red line

398
00:16:48,160 --> 00:16:50,639
indicates

399
00:16:48,880 --> 00:16:53,439
communication between the global

400
00:16:50,639 --> 00:16:55,920
parameter and virtual one

401
00:16:53,440 --> 00:16:58,639
finally the local placement policy can

402
00:16:55,920 --> 00:17:01,199
use considerable amount of communication

403
00:16:58,639 --> 00:17:01,199
overhead

404
00:17:01,759 --> 00:17:05,199
now compared to horribles for each

405
00:17:03,600 --> 00:17:07,520
allocation frequency

406
00:17:05,199 --> 00:17:09,199
forbot is the state-of-the-art data

407
00:17:07,520 --> 00:17:10,720
paragram that using orleans

408
00:17:09,199 --> 00:17:13,439
communication

409
00:17:10,720 --> 00:17:15,760
this bar chart shows the performance the

410
00:17:13,439 --> 00:17:16,720
x-axis represents the total number of

411
00:17:15,760 --> 00:17:19,520
gpus

412
00:17:16,720 --> 00:17:21,439
and the y-axis is throughput for

413
00:17:19,520 --> 00:17:21,918
legendary model using solid to patch

414
00:17:21,439 --> 00:17:23,760
size

415
00:17:21,919 --> 00:17:26,720
the whole model is too large to be

416
00:17:23,760 --> 00:17:30,320
loaded into a single g-type gpu

417
00:17:26,720 --> 00:17:33,360
so horribles use 12 gpus

418
00:17:30,320 --> 00:17:35,360
ed case reduces the traveler problem and

419
00:17:33,360 --> 00:17:36,240
easy local case the communication

420
00:17:35,360 --> 00:17:40,559
overhead was

421
00:17:36,240 --> 00:17:44,000
reduced and up to 1.4 and 1.8 times

422
00:17:40,559 --> 00:17:46,639
faster on each model

423
00:17:44,000 --> 00:17:48,880
next we investigate how the throughput

424
00:17:46,640 --> 00:17:51,600
is improved when unimpeded cpus are

425
00:17:48,880 --> 00:17:53,919
additionally used for training

426
00:17:51,600 --> 00:17:55,840
there is a single free gpu and four

427
00:17:53,919 --> 00:17:59,280
wimpy gpus are added

428
00:17:55,840 --> 00:18:00,879
in order of r q and g from four which

429
00:17:59,280 --> 00:18:03,200
diffuse

430
00:18:00,880 --> 00:18:04,640
both robot and high pipe tends to

431
00:18:03,200 --> 00:18:09,039
improve

432
00:18:04,640 --> 00:18:11,679
a 5 achieves up to 2.3 times speedo

433
00:18:09,039 --> 00:18:14,640
and additional vintage push allows for

434
00:18:11,679 --> 00:18:16,160
faster training

435
00:18:14,640 --> 00:18:19,200
i will show you the result of

436
00:18:16,160 --> 00:18:22,720
convergence the x-axis is time

437
00:18:19,200 --> 00:18:25,360
and the y-axis is total accuracy

438
00:18:22,720 --> 00:18:26,799
for legendary 74 percentage target

439
00:18:25,360 --> 00:18:30,399
accuracy

440
00:18:26,799 --> 00:18:35,039
a pipe evaluated with 12 gpus like robot

441
00:18:30,400 --> 00:18:37,679
and 16 gpus using all of the vmp gpus

442
00:18:35,039 --> 00:18:39,600
a pipe solved those travel problem in a

443
00:18:37,679 --> 00:18:42,400
heterogeneous environment

444
00:18:39,600 --> 00:18:45,199
and trained up to 39 percent faster

445
00:18:42,400 --> 00:18:48,799
using 16 gpus

446
00:18:45,200 --> 00:18:52,080
the use of the vmp fuse resulted in a 7

447
00:18:48,799 --> 00:18:52,080
performance increase

448
00:18:52,320 --> 00:18:58,720
for pct we evaluate with robot and

449
00:18:55,600 --> 00:19:01,918
different t values when d

450
00:18:58,720 --> 00:19:03,840
is zero it is 29 percent faster than

451
00:19:01,919 --> 00:19:08,799
robot

452
00:19:03,840 --> 00:19:11,120
and a pipe trend up to 49 percent faster

453
00:19:08,799 --> 00:19:12,960
convergence results according to t

454
00:19:11,120 --> 00:19:15,520
values

455
00:19:12,960 --> 00:19:16,080
when d becomes very large such as solid

456
00:19:15,520 --> 00:19:18,559
2

457
00:19:16,080 --> 00:19:21,120
the convergence performance degrades by

458
00:19:18,559 --> 00:19:24,160
4.7 percent

459
00:19:21,120 --> 00:19:28,239
this is because higher global sales can

460
00:19:24,160 --> 00:19:28,240
degrade the convergence performance

461
00:19:28,720 --> 00:19:32,160
finally these are the parts that were

462
00:19:31,360 --> 00:19:35,280
not present

463
00:19:32,160 --> 00:19:38,480
in this talk we omitted some features

464
00:19:35,280 --> 00:19:42,240
including proof of wsp

465
00:19:38,480 --> 00:19:45,280
it is discussed in the paper

466
00:19:42,240 --> 00:19:47,679
this is the conclusion hap5 makes it

467
00:19:45,280 --> 00:19:50,399
possible to train large dna models with

468
00:19:47,679 --> 00:19:53,600
heterogeneous gpus

469
00:19:50,400 --> 00:19:56,880
integrate pmp with dp and propose the

470
00:19:53,600 --> 00:19:59,760
synchronization model wsp

471
00:19:56,880 --> 00:20:00,720
dna models converge up to 49 percent

472
00:19:59,760 --> 00:20:05,440
faster with

473
00:20:00,720 --> 00:20:09,360
headpipe thank you for your attention

474
00:20:05,440 --> 00:20:09,360
i will now take questions if you have

475
00:20:17,480 --> 00:20:20,480
any

