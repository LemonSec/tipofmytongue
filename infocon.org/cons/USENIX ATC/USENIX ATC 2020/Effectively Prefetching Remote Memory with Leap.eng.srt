1
00:00:08,240 --> 00:00:11,200
hello everyone i'm hassan from the

2
00:00:09,840 --> 00:00:12,960
university of michigan

3
00:00:11,200 --> 00:00:15,360
and today i'm going to present our work

4
00:00:12,960 --> 00:00:16,960
only lip is a lightweight and efficient

5
00:00:15,360 --> 00:00:19,038
data path for remote memory

6
00:00:16,960 --> 00:00:20,080
at its core it uses an online

7
00:00:19,039 --> 00:00:22,000
prefetching technique

8
00:00:20,080 --> 00:00:23,359
to reduce the latency bottleneck during

9
00:00:22,000 --> 00:00:24,880
remote memory access

10
00:00:23,359 --> 00:00:27,439
and this eventually improves the

11
00:00:24,880 --> 00:00:29,599
end-to-end application level performance

12
00:00:27,439 --> 00:00:30,800
this work is done by me and my advisor

13
00:00:29,599 --> 00:00:32,800
mosher of chowdhury

14
00:00:30,800 --> 00:00:34,000
so before we start to talk about lip

15
00:00:32,800 --> 00:00:36,399
let's first discuss

16
00:00:34,000 --> 00:00:38,239
why we care about remote memory what are

17
00:00:36,399 --> 00:00:39,040
the issues with existing remote memory

18
00:00:38,239 --> 00:00:41,040
frameworks

19
00:00:39,040 --> 00:00:42,879
and how we come up with the design idea

20
00:00:41,040 --> 00:00:44,800
of limb

21
00:00:42,879 --> 00:00:46,239
memory intensive applications are widely

22
00:00:44,800 --> 00:00:48,239
being used in many cases

23
00:00:46,239 --> 00:00:49,519
like low latency services and data

24
00:00:48,239 --> 00:00:51,519
intensive analytics

25
00:00:49,520 --> 00:00:53,199
this kind of application can provide you

26
00:00:51,520 --> 00:00:55,280
significant performance benefit

27
00:00:53,199 --> 00:00:57,440
when the whole working set can fully fit

28
00:00:55,280 --> 00:00:59,840
into the host machine's physical memory

29
00:00:57,440 --> 00:01:01,680
however if the host machine cannot

30
00:00:59,840 --> 00:01:03,600
provide them with enough memory

31
00:01:01,680 --> 00:01:05,438
they need to go through expensive disk

32
00:01:03,600 --> 00:01:07,520
operation and at that point

33
00:01:05,438 --> 00:01:08,639
they face severe performance drop to

34
00:01:07,520 --> 00:01:11,200
illustrate this

35
00:01:08,640 --> 00:01:13,600
we run tpcs workload on top of an

36
00:01:11,200 --> 00:01:15,680
in-memory database system named voldevi

37
00:01:13,600 --> 00:01:17,039
and measured its performance in terms of

38
00:01:15,680 --> 00:01:18,880
two foot per second

39
00:01:17,040 --> 00:01:20,560
here higher throughput means better

40
00:01:18,880 --> 00:01:23,280
performance

41
00:01:20,560 --> 00:01:24,640
as you can see if we take away 25

42
00:01:23,280 --> 00:01:25,600
percent of the memory from the host

43
00:01:24,640 --> 00:01:27,600
machine

44
00:01:25,600 --> 00:01:28,640
volte will start to swap to the disk and

45
00:01:27,600 --> 00:01:30,479
at that point

46
00:01:28,640 --> 00:01:32,880
it loses almost 80 percent of its

47
00:01:30,479 --> 00:01:35,119
performance if we take away 25

48
00:01:32,880 --> 00:01:36,240
more memory that means in 50

49
00:01:35,119 --> 00:01:38,320
configuration

50
00:01:36,240 --> 00:01:41,039
voltaville loses almost 95 of its

51
00:01:38,320 --> 00:01:43,360
performance and it can hardly run

52
00:01:41,040 --> 00:01:45,040
same thing happens for latency sensitive

53
00:01:43,360 --> 00:01:47,600
applications like paragraph

54
00:01:45,040 --> 00:01:48,960
here we run page rank algorithm on top

55
00:01:47,600 --> 00:01:51,039
of twitter data set

56
00:01:48,960 --> 00:01:53,360
of our paragraph and we measure the end

57
00:01:51,040 --> 00:01:56,320
to end completion times in terms of

58
00:01:53,360 --> 00:01:58,320
performance matrix as you can see

59
00:01:56,320 --> 00:01:59,919
similar to voldemi when you take a half

60
00:01:58,320 --> 00:02:01,520
of the memory from paragraph

61
00:01:59,920 --> 00:02:03,360
it starts to show up to the disk and

62
00:02:01,520 --> 00:02:05,200
loses almost 75 percent of its

63
00:02:03,360 --> 00:02:07,600
performance

64
00:02:05,200 --> 00:02:09,759
this is obvious you take your memory

65
00:02:07,600 --> 00:02:11,680
your application will lose performance

66
00:02:09,758 --> 00:02:13,599
but this performance drop is highly

67
00:02:11,680 --> 00:02:16,080
disproportional to the memory loss

68
00:02:13,599 --> 00:02:18,079
for example for vol db and paragraph

69
00:02:16,080 --> 00:02:20,319
taking a half of the memory causes them

70
00:02:18,080 --> 00:02:22,160
to lose 38 times and four times of their

71
00:02:20,319 --> 00:02:24,238
performance respectively

72
00:02:22,160 --> 00:02:26,000
and to handle this while deploying this

73
00:02:24,239 --> 00:02:27,840
kind of application in the cloud

74
00:02:26,000 --> 00:02:30,080
users usually allocate more memory than

75
00:02:27,840 --> 00:02:32,319
needed and this put us

76
00:02:30,080 --> 00:02:34,720
in a situation between a rock and a hard

77
00:02:32,319 --> 00:02:35,599
place in one case if we allocate less

78
00:02:34,720 --> 00:02:37,840
memory

79
00:02:35,599 --> 00:02:39,440
we will face severe performance loss and

80
00:02:37,840 --> 00:02:40,640
on the other hand if we allocate more

81
00:02:39,440 --> 00:02:42,560
memory than needed

82
00:02:40,640 --> 00:02:44,799
then we will face significant resource

83
00:02:42,560 --> 00:02:46,959
under utilization in the cluster

84
00:02:44,800 --> 00:02:48,480
for example in big clusters like google

85
00:02:46,959 --> 00:02:50,640
facebook and alibaba

86
00:02:48,480 --> 00:02:52,160
almost 30 to 40 percent of the cluster

87
00:02:50,640 --> 00:02:53,760
weight memory remains under utilized

88
00:02:52,160 --> 00:02:56,079
most of the time

89
00:02:53,760 --> 00:02:58,239
more importantly this under utilization

90
00:02:56,080 --> 00:03:00,239
is not uniform throughout the cluster

91
00:02:58,239 --> 00:03:02,400
some machine can have significant amount

92
00:03:00,239 --> 00:03:06,080
of free memory while the others are in

93
00:03:02,400 --> 00:03:08,000
under civil memory pressure the idea of

94
00:03:06,080 --> 00:03:08,800
memory desegregation can solve this

95
00:03:08,000 --> 00:03:11,120
problem

96
00:03:08,800 --> 00:03:12,720
by exposing a cluster with global memory

97
00:03:11,120 --> 00:03:14,560
pool in this setup

98
00:03:12,720 --> 00:03:17,040
when a machine is under severe memory

99
00:03:14,560 --> 00:03:19,360
pressure like machine one in this figure

100
00:03:17,040 --> 00:03:20,799
it can use the free memory available in

101
00:03:19,360 --> 00:03:23,120
other machine in the cluster

102
00:03:20,800 --> 00:03:25,599
and therefore it can run more tasks and

103
00:03:23,120 --> 00:03:27,680
more applications

104
00:03:25,599 --> 00:03:29,280
the idea of memory desegregation is

105
00:03:27,680 --> 00:03:31,040
getting much popular these days

106
00:03:29,280 --> 00:03:32,640
with the availability of ultrafast

107
00:03:31,040 --> 00:03:34,560
network like rdma

108
00:03:32,640 --> 00:03:36,079
over the last few years people designed

109
00:03:34,560 --> 00:03:38,720
memory designation framework

110
00:03:36,080 --> 00:03:39,680
to use the remote memory during paging

111
00:03:38,720 --> 00:03:41,120
file access

112
00:03:39,680 --> 00:03:43,680
and even running the whole operating

113
00:03:41,120 --> 00:03:46,319
system in a disaggregated manner

114
00:03:43,680 --> 00:03:47,360
in this kind of frameworks memory uh the

115
00:03:46,319 --> 00:03:50,238
network is in

116
00:03:47,360 --> 00:03:52,239
involved and and for this reason the

117
00:03:50,239 --> 00:03:54,959
performance loss is inevitable

118
00:03:52,239 --> 00:03:56,159
for example to access a four kilobyte

119
00:03:54,959 --> 00:03:59,200
page from the

120
00:03:56,159 --> 00:04:00,560
local disk local uh memory it can takes

121
00:03:59,200 --> 00:04:02,958
hundreds of nanoseconds

122
00:04:00,560 --> 00:04:03,920
however to access it from the remote

123
00:04:02,959 --> 00:04:06,080
memory

124
00:04:03,920 --> 00:04:07,040
through the rdma it takes around four

125
00:04:06,080 --> 00:04:08,480
microseconds

126
00:04:07,040 --> 00:04:10,079
and this is without any kind of

127
00:04:08,480 --> 00:04:11,200
background load at the presence of

128
00:04:10,080 --> 00:04:13,599
background load

129
00:04:11,200 --> 00:04:15,760
it can cause up to tens of microseconds

130
00:04:13,599 --> 00:04:18,238
which is orders of magnitude higher than

131
00:04:15,760 --> 00:04:20,478
the local memory access latency

132
00:04:18,238 --> 00:04:21,518
recent study shows that to maintain the

133
00:04:20,478 --> 00:04:24,000
performance loss

134
00:04:21,519 --> 00:04:24,960
of such frameworks under an unnoticeable

135
00:04:24,000 --> 00:04:27,040
bound

136
00:04:24,960 --> 00:04:29,039
the end-to-end memory access latency

137
00:04:27,040 --> 00:04:30,639
should not go beyond three microseconds

138
00:04:29,040 --> 00:04:32,560
and existing memory desegregation

139
00:04:30,639 --> 00:04:34,400
frameworks can hardly achieve that

140
00:04:32,560 --> 00:04:35,919
our analysis says that there are two

141
00:04:34,400 --> 00:04:38,080
prime reasons behind this

142
00:04:35,919 --> 00:04:39,919
the first one is the traditional data

143
00:04:38,080 --> 00:04:40,639
overhead while accessing the remote

144
00:04:39,919 --> 00:04:42,240
memory

145
00:04:40,639 --> 00:04:43,680
and the second one is the latency

146
00:04:42,240 --> 00:04:46,000
variation in the network

147
00:04:43,680 --> 00:04:47,280
to understand the root cause behind this

148
00:04:46,000 --> 00:04:49,199
latency overhead

149
00:04:47,280 --> 00:04:52,080
let's see what happens inside the linux

150
00:04:49,199 --> 00:04:55,040
panel during a page fault event

151
00:04:52,080 --> 00:04:56,000
in linux when a page fault happens by

152
00:04:55,040 --> 00:04:58,160
process

153
00:04:56,000 --> 00:04:59,199
the kernel stretch to serve it from the

154
00:04:58,160 --> 00:05:01,600
storage device

155
00:04:59,199 --> 00:05:02,880
and in traditional setup this is the

156
00:05:01,600 --> 00:05:05,440
storage device

157
00:05:02,880 --> 00:05:07,120
here to provide a faster data service

158
00:05:05,440 --> 00:05:07,759
the operating system maintains page

159
00:05:07,120 --> 00:05:10,000
cache

160
00:05:07,759 --> 00:05:11,840
if the page is found in the cache it can

161
00:05:10,000 --> 00:05:14,160
be served instantly

162
00:05:11,840 --> 00:05:15,758
however if the page is not there then a

163
00:05:14,160 --> 00:05:17,919
disk access is a must

164
00:05:15,759 --> 00:05:19,680
in that case the device mapping layer

165
00:05:17,919 --> 00:05:21,280
initially figures out the position of

166
00:05:19,680 --> 00:05:23,199
the page within the disk

167
00:05:21,280 --> 00:05:24,880
and therefore it creates a biorequest to

168
00:05:23,199 --> 00:05:27,039
the generic block layer

169
00:05:24,880 --> 00:05:28,080
now the generic block layer is optimized

170
00:05:27,039 --> 00:05:30,960
to hide the disk

171
00:05:28,080 --> 00:05:31,758
signal it always tries to maximize the

172
00:05:30,960 --> 00:05:34,719
sequential

173
00:05:31,759 --> 00:05:36,639
excess as much as possible that's why it

174
00:05:34,720 --> 00:05:38,320
intentionally adds delay by putting the

175
00:05:36,639 --> 00:05:40,639
biorecast into a

176
00:05:38,320 --> 00:05:42,240
request queue so that it can match

177
00:05:40,639 --> 00:05:45,440
multiple continuous buy requests

178
00:05:42,240 --> 00:05:47,120
to a single large request and eventually

179
00:05:45,440 --> 00:05:48,240
the bio request is served from the

180
00:05:47,120 --> 00:05:50,080
storage device

181
00:05:48,240 --> 00:05:52,080
and in existing memory segregation

182
00:05:50,080 --> 00:05:53,840
framework all the remote memory access

183
00:05:52,080 --> 00:05:54,719
requests go through all of these buyer

184
00:05:53,840 --> 00:05:56,719
operations

185
00:05:54,720 --> 00:05:58,639
even though they have no value in remote

186
00:05:56,720 --> 00:06:02,000
storage

187
00:05:58,639 --> 00:06:04,400
if we look into the latency breakdown of

188
00:06:02,000 --> 00:06:06,319
database operations we can see that if a

189
00:06:04,400 --> 00:06:07,919
page can be served from the cache

190
00:06:06,319 --> 00:06:09,440
this can be served within hundreds of

191
00:06:07,919 --> 00:06:11,520
nanoseconds and this

192
00:06:09,440 --> 00:06:13,039
is the first path of memory access

193
00:06:11,520 --> 00:06:15,120
however you can if

194
00:06:13,039 --> 00:06:17,440
it cannot be served from the cache due

195
00:06:15,120 --> 00:06:19,440
to the expensive buy operations

196
00:06:17,440 --> 00:06:21,039
it goes through a delay of 30

197
00:06:19,440 --> 00:06:22,960
microseconds on average

198
00:06:21,039 --> 00:06:24,560
and in the worst case it can go up to

199
00:06:22,960 --> 00:06:25,840
milliseconds and even hundreds of

200
00:06:24,560 --> 00:06:27,759
microseconds

201
00:06:25,840 --> 00:06:29,440
and this is the slow path of memory

202
00:06:27,759 --> 00:06:31,680
access as you can see

203
00:06:29,440 --> 00:06:33,280
the latest in the slow path is way

204
00:06:31,680 --> 00:06:35,440
higher than the three microsecond

205
00:06:33,280 --> 00:06:37,919
requirement we mentioned earlier

206
00:06:35,440 --> 00:06:39,600
so here the takeaway is if we want to

207
00:06:37,919 --> 00:06:41,359
provide a better performance during

208
00:06:39,600 --> 00:06:43,360
memory desegregation framework

209
00:06:41,360 --> 00:06:44,400
we want to increase the number of first

210
00:06:43,360 --> 00:06:46,240
part access

211
00:06:44,400 --> 00:06:47,599
and to do so we need to increase the

212
00:06:46,240 --> 00:06:49,520
cache

213
00:06:47,600 --> 00:06:51,520
here an effective prefecture can improve

214
00:06:49,520 --> 00:06:54,080
the cash rate by bringing more accurate

215
00:06:51,520 --> 00:06:56,159
pages into the cash beforehand

216
00:06:54,080 --> 00:06:59,599
and the second obvious thing is we want

217
00:06:56,160 --> 00:07:02,720
to make our slow path more faster

218
00:06:59,599 --> 00:07:04,880
as bio as bio operations are completely

219
00:07:02,720 --> 00:07:08,000
unnecessary during remote memory we need

220
00:07:04,880 --> 00:07:10,400
to get rid of them from our slows path

221
00:07:08,000 --> 00:07:12,240
considering these two observation we

222
00:07:10,400 --> 00:07:13,840
designed our framework leave which is

223
00:07:12,240 --> 00:07:14,960
basically an online remote memory

224
00:07:13,840 --> 00:07:17,440
prefetcher

225
00:07:14,960 --> 00:07:19,599
this is a software solution to identify

226
00:07:17,440 --> 00:07:22,400
memory access pattern of each process

227
00:07:19,599 --> 00:07:22,880
and therefore to prefetch pages in a

228
00:07:22,400 --> 00:07:24,799
fast

229
00:07:22,880 --> 00:07:26,560
cache efficient and resilient manner

230
00:07:24,800 --> 00:07:28,560
without modifying the application or

231
00:07:26,560 --> 00:07:31,199
hardware

232
00:07:28,560 --> 00:07:32,960
in lib we cut all the unnecessary block

233
00:07:31,199 --> 00:07:35,759
layer operations from the slow path

234
00:07:32,960 --> 00:07:37,680
and make it much much faster and leaner

235
00:07:35,759 --> 00:07:41,039
we track each process page access

236
00:07:37,680 --> 00:07:41,840
history into an fixed size circular

237
00:07:41,039 --> 00:07:43,759
buffer

238
00:07:41,840 --> 00:07:45,440
and we employ and majority-based pattern

239
00:07:43,759 --> 00:07:48,240
detection technique on top of them

240
00:07:45,440 --> 00:07:50,080
to find the availability of any pattern

241
00:07:48,240 --> 00:07:52,240
within the page access stream

242
00:07:50,080 --> 00:07:53,199
we therefore bring more accurate pages

243
00:07:52,240 --> 00:07:55,919
into the cache and

244
00:07:53,199 --> 00:07:57,199
improve the cachet to reduce the cache

245
00:07:55,919 --> 00:07:59,039
allocation wait time

246
00:07:57,199 --> 00:08:01,680
we employ an eager cash prevention

247
00:07:59,039 --> 00:08:03,919
policy here in this presentation i am

248
00:08:01,680 --> 00:08:06,240
going to talk mostly about the linux

249
00:08:03,919 --> 00:08:07,680
mostly about the leaves prefecture in

250
00:08:06,240 --> 00:08:09,199
our paper we have detailed

251
00:08:07,680 --> 00:08:11,120
description about the rest of the

252
00:08:09,199 --> 00:08:12,800
components

253
00:08:11,120 --> 00:08:14,879
so before we talk about the lips

254
00:08:12,800 --> 00:08:16,400
preparation let's see how the existing

255
00:08:14,879 --> 00:08:18,160
prefetching techniques work

256
00:08:16,400 --> 00:08:19,520
and how leaves prefecture is different

257
00:08:18,160 --> 00:08:21,840
from them

258
00:08:19,520 --> 00:08:23,599
in today's linux they use a read ahead

259
00:08:21,840 --> 00:08:26,159
graffiti technique which is ideally

260
00:08:23,599 --> 00:08:26,560
optimized to hide distinct time that's

261
00:08:26,160 --> 00:08:29,280
why

262
00:08:26,560 --> 00:08:29,919
when accessing a disk it always suggests

263
00:08:29,280 --> 00:08:31,758
to bring

264
00:08:29,919 --> 00:08:33,279
few more extra pages around the page

265
00:08:31,759 --> 00:08:34,880
address

266
00:08:33,279 --> 00:08:36,799
and while making this prefetching

267
00:08:34,880 --> 00:08:37,679
decision it does not consider the page

268
00:08:36,799 --> 00:08:40,159
access history

269
00:08:37,679 --> 00:08:42,159
it only considered the last access if

270
00:08:40,159 --> 00:08:44,319
the last two accesses are sequential

271
00:08:42,159 --> 00:08:45,279
then it aggressively prefetch more pages

272
00:08:44,320 --> 00:08:47,680
into the cache

273
00:08:45,279 --> 00:08:49,040
and this might sometimes cause cache

274
00:08:47,680 --> 00:08:51,359
pollution

275
00:08:49,040 --> 00:08:52,880
on the other hand if the two excesses

276
00:08:51,360 --> 00:08:55,120
are not sequential

277
00:08:52,880 --> 00:08:57,040
then it becomes much more conservative

278
00:08:55,120 --> 00:09:00,640
and it shut down the prefetching

279
00:08:57,040 --> 00:09:02,480
these are the two exchange situations

280
00:09:00,640 --> 00:09:04,640
moreover linux prefetcher cannot

281
00:09:02,480 --> 00:09:06,800
distinguish the processes which call the

282
00:09:04,640 --> 00:09:09,360
prefetch request

283
00:09:06,800 --> 00:09:11,359
this has some drawbacks for example in

284
00:09:09,360 --> 00:09:12,160
linux processors share the same soft

285
00:09:11,360 --> 00:09:14,880
space

286
00:09:12,160 --> 00:09:16,719
so if two different process calls page

287
00:09:14,880 --> 00:09:18,320
fault on two different pages

288
00:09:16,720 --> 00:09:20,720
which are basically in continuous

289
00:09:18,320 --> 00:09:21,760
subspace linux will consider them a

290
00:09:20,720 --> 00:09:24,080
sequential access

291
00:09:21,760 --> 00:09:25,760
and therefore it will bring more pages

292
00:09:24,080 --> 00:09:28,080
into the cache and eventually

293
00:09:25,760 --> 00:09:28,880
waste the cache space and the most

294
00:09:28,080 --> 00:09:31,440
important thing

295
00:09:28,880 --> 00:09:33,360
is that is that linux cannot identify

296
00:09:31,440 --> 00:09:37,920
any short term irregularity in

297
00:09:33,360 --> 00:09:41,200
the page access history now to become an

298
00:09:37,920 --> 00:09:42,399
real-time prefecture and prefetching

299
00:09:41,200 --> 00:09:44,880
algorithm should have

300
00:09:42,399 --> 00:09:45,440
certain following certain properties for

301
00:09:44,880 --> 00:09:47,920
example

302
00:09:45,440 --> 00:09:49,680
it should have low latency in

303
00:09:47,920 --> 00:09:52,719
computation and it has

304
00:09:49,680 --> 00:09:53,839
low resource overhead to be generic it

305
00:09:52,720 --> 00:09:55,920
should be transparent to

306
00:09:53,839 --> 00:09:57,519
applications and it should not depend on

307
00:09:55,920 --> 00:09:58,880
any specific hardware or software

308
00:09:57,519 --> 00:10:00,720
requirements

309
00:09:58,880 --> 00:10:02,320
it should be aware of temporal and

310
00:10:00,720 --> 00:10:04,560
special logic in speech

311
00:10:02,320 --> 00:10:05,600
in page access events and most

312
00:10:04,560 --> 00:10:08,479
importantly

313
00:10:05,600 --> 00:10:10,320
it should keep the cache position as low

314
00:10:08,480 --> 00:10:13,200
as possible

315
00:10:10,320 --> 00:10:14,560
next online and stride are too easy to

316
00:10:13,200 --> 00:10:15,279
implement and generate prefetching

317
00:10:14,560 --> 00:10:18,800
algorithm

318
00:10:15,279 --> 00:10:21,360
but they causes high cache pollution

319
00:10:18,800 --> 00:10:22,319
most of the time instruction-based

320
00:10:21,360 --> 00:10:24,240
pre-phasing technique

321
00:10:22,320 --> 00:10:25,440
usually depends on a specific hardware

322
00:10:24,240 --> 00:10:28,560
device or

323
00:10:25,440 --> 00:10:29,519
it depends on the in um compiling

324
00:10:28,560 --> 00:10:31,599
injected code

325
00:10:29,519 --> 00:10:33,360
and that's why they often cause high

326
00:10:31,600 --> 00:10:36,079
resource overhead

327
00:10:33,360 --> 00:10:37,839
moreover they cause a high cash

328
00:10:36,079 --> 00:10:40,319
pollution most of the time

329
00:10:37,839 --> 00:10:40,880
linux video head has most of the

330
00:10:40,320 --> 00:10:43,040
following

331
00:10:40,880 --> 00:10:44,959
most of the mentioned characteristics

332
00:10:43,040 --> 00:10:46,560
but as i mentioned earlier during the

333
00:10:44,959 --> 00:10:49,040
presence of irregularity

334
00:10:46,560 --> 00:10:51,518
they also cause high cash pollution

335
00:10:49,040 --> 00:10:53,040
while most of the prefetching techniques

336
00:10:51,519 --> 00:10:55,519
fall short of either either of the

337
00:10:53,040 --> 00:10:56,160
characteristics our prefecture lip can

338
00:10:55,519 --> 00:10:59,120
fulfill

339
00:10:56,160 --> 00:11:00,880
all of them and now we will see how it

340
00:10:59,120 --> 00:11:03,680
works

341
00:11:00,880 --> 00:11:05,680
on a high level leap has two components

342
00:11:03,680 --> 00:11:07,680
the trend detection algorithm

343
00:11:05,680 --> 00:11:09,519
detects the availability of trend in the

344
00:11:07,680 --> 00:11:11,199
page access stream

345
00:11:09,519 --> 00:11:12,720
and based on the availability

346
00:11:11,200 --> 00:11:15,040
availability of the trend

347
00:11:12,720 --> 00:11:16,320
and preface utilization the prefetch

348
00:11:15,040 --> 00:11:18,959
window size detection

349
00:11:16,320 --> 00:11:19,839
algorithm defines how many pages we need

350
00:11:18,959 --> 00:11:22,239
to bring

351
00:11:19,839 --> 00:11:23,600
with during a prefetch request and both

352
00:11:22,240 --> 00:11:25,360
of this component works

353
00:11:23,600 --> 00:11:27,440
in linear linear time and constant

354
00:11:25,360 --> 00:11:30,079
memory space

355
00:11:27,440 --> 00:11:31,200
so after we determine the prefetch

356
00:11:30,079 --> 00:11:33,359
window size

357
00:11:31,200 --> 00:11:34,320
if there is a trend in the page access

358
00:11:33,360 --> 00:11:36,240
history

359
00:11:34,320 --> 00:11:38,480
leaves prefetcher will follow the trend

360
00:11:36,240 --> 00:11:39,839
to bring more pages into the cache

361
00:11:38,480 --> 00:11:42,160
otherwise it will stick to the

362
00:11:39,839 --> 00:11:44,480
previously found trend

363
00:11:42,160 --> 00:11:46,160
and if the prefetch window size is zero

364
00:11:44,480 --> 00:11:48,320
we do not prefetch anything we just

365
00:11:46,160 --> 00:11:50,399
bring the requested page

366
00:11:48,320 --> 00:11:52,320
and during train detection leaves

367
00:11:50,399 --> 00:11:53,200
prefetcher do not look for any strict

368
00:11:52,320 --> 00:11:54,880
pattern

369
00:11:53,200 --> 00:11:57,279
rather it looks for the majority

370
00:11:54,880 --> 00:12:00,720
elements in the page access stream

371
00:11:57,279 --> 00:12:02,320
and this makes us flexible to any sort

372
00:12:00,720 --> 00:12:03,519
of irregularities in the page access

373
00:12:02,320 --> 00:12:06,800
pattern

374
00:12:03,519 --> 00:12:09,519
so when a process follow a

375
00:12:06,800 --> 00:12:10,000
train for a certain period of time this

376
00:12:09,519 --> 00:12:12,320
can be

377
00:12:10,000 --> 00:12:14,320
easily detected from the last few

378
00:12:12,320 --> 00:12:18,000
excesses of pages

379
00:12:14,320 --> 00:12:20,320
and that's why lib initially

380
00:12:18,000 --> 00:12:21,040
do not look for the do not look over the

381
00:12:20,320 --> 00:12:23,440
whole

382
00:12:21,040 --> 00:12:24,160
page access history rather it takes a

383
00:12:23,440 --> 00:12:25,760
smaller

384
00:12:24,160 --> 00:12:27,360
window size which is basically a

385
00:12:25,760 --> 00:12:28,720
fraction of the latest element of the

386
00:12:27,360 --> 00:12:31,760
page access history

387
00:12:28,720 --> 00:12:33,839
and therefore it employs a linear time

388
00:12:31,760 --> 00:12:35,279
one more majority voting algorithm to

389
00:12:33,839 --> 00:12:36,240
find the majority return within the

390
00:12:35,279 --> 00:12:39,120
window

391
00:12:36,240 --> 00:12:40,720
if the window does not have any trend it

392
00:12:39,120 --> 00:12:42,880
increases the window size

393
00:12:40,720 --> 00:12:43,760
and repeats the same process again and

394
00:12:42,880 --> 00:12:47,920
again until

395
00:12:43,760 --> 00:12:49,680
it reaches to the maximum size capacity

396
00:12:47,920 --> 00:12:51,760
the whole process will be simplified

397
00:12:49,680 --> 00:12:54,880
after we go through some examples

398
00:12:51,760 --> 00:12:56,079
let's say at nsm t3 our history buffer

399
00:12:54,880 --> 00:12:59,200
has a size of 8

400
00:12:56,079 --> 00:13:02,560
and it has the following four components

401
00:12:59,200 --> 00:13:05,360
now the numbers on top of the boxes

402
00:13:02,560 --> 00:13:06,560
shows the page addresses the number at

403
00:13:05,360 --> 00:13:09,680
the bottom of the

404
00:13:06,560 --> 00:13:10,479
boxes like t0 t1 these are the timestamp

405
00:13:09,680 --> 00:13:14,079
when the page

406
00:13:10,480 --> 00:13:15,600
accesses were requested and the number

407
00:13:14,079 --> 00:13:18,079
inside the boxes are the difference

408
00:13:15,600 --> 00:13:20,240
between the last two page addresses

409
00:13:18,079 --> 00:13:22,638
here the colored box indicates the head

410
00:13:20,240 --> 00:13:25,440
of the buffer at current time

411
00:13:22,639 --> 00:13:27,200
now at time t3 the page addresses follow

412
00:13:25,440 --> 00:13:29,279
a trend of -3

413
00:13:27,200 --> 00:13:33,440
and this can be detected by the majority

414
00:13:29,279 --> 00:13:36,480
element within the window of t0 to t3

415
00:13:33,440 --> 00:13:38,399
let's say at time t4 the after the time

416
00:13:36,480 --> 00:13:39,199
t4 the trend of minus 3 is going to

417
00:13:38,399 --> 00:13:41,279
disappear

418
00:13:39,199 --> 00:13:42,319
and a new trend of plus 2 is going to

419
00:13:41,279 --> 00:13:44,639
appear

420
00:13:42,320 --> 00:13:46,399
now when a trend starts it is hard to

421
00:13:44,639 --> 00:13:49,120
determine whether this is a

422
00:13:46,399 --> 00:13:49,680
real trend or something irregular is

423
00:13:49,120 --> 00:13:51,680
happening

424
00:13:49,680 --> 00:13:54,239
in between while prevailing the previous

425
00:13:51,680 --> 00:13:56,959
trend so at time t7

426
00:13:54,240 --> 00:13:57,680
lip does not mandate for any nutrient

427
00:13:56,959 --> 00:14:00,719
however

428
00:13:57,680 --> 00:14:02,319
after the arrival of the th element now

429
00:14:00,720 --> 00:14:04,399
we can surely say that

430
00:14:02,320 --> 00:14:06,320
a new trend has started and we will

431
00:14:04,399 --> 00:14:08,160
forget the chain of minus 3

432
00:14:06,320 --> 00:14:10,399
and we'll follow the trend of plus 2

433
00:14:08,160 --> 00:14:13,120
during prefetching

434
00:14:10,399 --> 00:14:14,639
in the next example we will see how lip

435
00:14:13,120 --> 00:14:16,079
can detect the

436
00:14:14,639 --> 00:14:17,680
trend even at the presence of

437
00:14:16,079 --> 00:14:19,839
irregularity

438
00:14:17,680 --> 00:14:21,680
let's say at time t 11 instead of

439
00:14:19,839 --> 00:14:23,920
following the trend of plus two

440
00:14:21,680 --> 00:14:25,519
the page addresses following follow a

441
00:14:23,920 --> 00:14:27,680
trend of plus four

442
00:14:25,519 --> 00:14:28,560
at time t12 something random stuff is

443
00:14:27,680 --> 00:14:31,760
happening

444
00:14:28,560 --> 00:14:32,719
and from time t14 the trend of plus 2

445
00:14:31,760 --> 00:14:35,600
continues

446
00:14:32,720 --> 00:14:37,279
and we can detect the trend within the

447
00:14:35,600 --> 00:14:39,199
window within the

448
00:14:37,279 --> 00:14:40,959
history buffer using the majority

449
00:14:39,199 --> 00:14:44,399
elements of the winter

450
00:14:40,959 --> 00:14:46,800
here in the smaller window of t12 or t5

451
00:14:44,399 --> 00:14:48,160
t2 to t15 even though the trend is not

452
00:14:46,800 --> 00:14:50,479
available

453
00:14:48,160 --> 00:14:51,600
if we look into the larger window of t8

454
00:14:50,480 --> 00:14:53,760
to t15

455
00:14:51,600 --> 00:14:55,839
here the majority elements are plus two

456
00:14:53,760 --> 00:14:57,600
and hence we can detect the majority

457
00:14:55,839 --> 00:14:59,440
detect the trend of plus 2 among the

458
00:14:57,600 --> 00:15:01,920
irregularities considering the majority

459
00:14:59,440 --> 00:15:04,399
elements

460
00:15:01,920 --> 00:15:06,560
while detecting the prefetch window size

461
00:15:04,399 --> 00:15:09,040
we consider two information

462
00:15:06,560 --> 00:15:10,160
the number of cash and the availability

463
00:15:09,040 --> 00:15:12,079
of trend

464
00:15:10,160 --> 00:15:13,279
here the cash sheet indicates a preface

465
00:15:12,079 --> 00:15:15,439
utilization

466
00:15:13,279 --> 00:15:16,959
leaves tracks the number of cashiers

467
00:15:15,440 --> 00:15:17,760
between two consecutive prefetch

468
00:15:16,959 --> 00:15:19,760
requires

469
00:15:17,760 --> 00:15:22,160
and therefore it adjusts the prefetch

470
00:15:19,760 --> 00:15:24,079
window size accordingly

471
00:15:22,160 --> 00:15:25,920
it increases the prefetch window size

472
00:15:24,079 --> 00:15:28,638
with the increase in the cache

473
00:15:25,920 --> 00:15:30,639
however if there is no cachet that means

474
00:15:28,639 --> 00:15:32,639
either random access is happening

475
00:15:30,639 --> 00:15:34,399
or our prefetching algorithm is doing

476
00:15:32,639 --> 00:15:37,440
bad in both cases

477
00:15:34,399 --> 00:15:40,240
we need to slow down however instead

478
00:15:37,440 --> 00:15:40,720
we do not while slowing down we do not

479
00:15:40,240 --> 00:15:43,519
do

480
00:15:40,720 --> 00:15:45,920
drastic shutdown because this may cause

481
00:15:43,519 --> 00:15:48,720
steel situation in prefetching

482
00:15:45,920 --> 00:15:50,000
whether here we look for any

483
00:15:48,720 --> 00:15:52,320
availability of trend

484
00:15:50,000 --> 00:15:53,600
and if we find any trend in the page

485
00:15:52,320 --> 00:15:56,079
access history

486
00:15:53,600 --> 00:15:58,480
we cautiously say to bring another extra

487
00:15:56,079 --> 00:16:01,120
page along the requested one

488
00:15:58,480 --> 00:16:01,759
however if no trend is found then we

489
00:16:01,120 --> 00:16:03,759
don't bring

490
00:16:01,759 --> 00:16:07,199
any extra page along the requested one

491
00:16:03,759 --> 00:16:07,199
which has been the requested page

492
00:16:07,519 --> 00:16:11,519
here during the slow down we always do

493
00:16:10,399 --> 00:16:14,320
it gradually

494
00:16:11,519 --> 00:16:15,440
so that we our briefing prefetching

495
00:16:14,320 --> 00:16:17,440
algorithm

496
00:16:15,440 --> 00:16:18,959
remains flexible to any certain changes

497
00:16:17,440 --> 00:16:22,959
in the page access

498
00:16:18,959 --> 00:16:25,439
page accessories we implement lib

499
00:16:22,959 --> 00:16:26,638
inside linux kernel version 4.4 and

500
00:16:25,440 --> 00:16:30,320
deploy it on a

501
00:16:26,639 --> 00:16:32,320
rdm enabled cluster we integrate it

502
00:16:30,320 --> 00:16:34,399
on top of two state-of-the-art memory

503
00:16:32,320 --> 00:16:36,959
desegregation frameworks infinity swap

504
00:16:34,399 --> 00:16:39,120
and limit regions we therefore evaluate

505
00:16:36,959 --> 00:16:40,800
it using both micro benchmark and real

506
00:16:39,120 --> 00:16:42,320
world applications

507
00:16:40,800 --> 00:16:44,880
integration of link improves the

508
00:16:42,320 --> 00:16:48,079
performance of both of these frameworks

509
00:16:44,880 --> 00:16:49,759
however due to the time constraint here

510
00:16:48,079 --> 00:16:52,638
i am going to present the benefit of

511
00:16:49,759 --> 00:16:55,600
leave over infinite swap

512
00:16:52,639 --> 00:16:56,639
due to its lightweight data path lib

513
00:16:55,600 --> 00:16:58,399
improved the

514
00:16:56,639 --> 00:16:59,759
remote page excess latency during

515
00:16:58,399 --> 00:17:02,079
sequential patterns

516
00:16:59,759 --> 00:17:02,959
the integration of leave improved the

517
00:17:02,079 --> 00:17:05,039
infinites of

518
00:17:02,959 --> 00:17:06,480
median four kilobyte page access latency

519
00:17:05,039 --> 00:17:09,520
by four times

520
00:17:06,480 --> 00:17:11,120
in linux when the stride size is

521
00:17:09,520 --> 00:17:12,720
greater than the maximum frequency

522
00:17:11,119 --> 00:17:16,639
window size every

523
00:17:12,720 --> 00:17:19,280
prefixed page will be and waste however

524
00:17:16,640 --> 00:17:21,120
in lead both the stride and sequential

525
00:17:19,280 --> 00:17:24,160
exercises are identical

526
00:17:21,119 --> 00:17:27,359
that's why lift provides the same

527
00:17:24,160 --> 00:17:28,559
low remote excess latency during any

528
00:17:27,359 --> 00:17:33,840
sized pattern of

529
00:17:28,559 --> 00:17:33,840
any size any size straight pattern

530
00:17:34,559 --> 00:17:38,080
leaves majority-based pattern detection

531
00:17:36,480 --> 00:17:40,400
has benefit over the

532
00:17:38,080 --> 00:17:41,918
strict pattern detection technique for

533
00:17:40,400 --> 00:17:44,080
example for paragraph

534
00:17:41,919 --> 00:17:45,280
lip can detect 30 more sequential

535
00:17:44,080 --> 00:17:47,918
excesses

536
00:17:45,280 --> 00:17:49,840
in linux they only consider the last two

537
00:17:47,919 --> 00:17:52,799
accesses and that's why

538
00:17:49,840 --> 00:17:54,320
any non-sequential access is basically a

539
00:17:52,799 --> 00:17:56,000
straight access to it

540
00:17:54,320 --> 00:17:58,320
on the other hand as we consider a

541
00:17:56,000 --> 00:18:00,880
certain amount of page access stream

542
00:17:58,320 --> 00:18:04,000
we can efficiently distinguish between

543
00:18:00,880 --> 00:18:07,120
irregular and straight excess pattern

544
00:18:04,000 --> 00:18:08,240
for example for paragraph lip can detect

545
00:18:07,120 --> 00:18:10,320
the 4

546
00:18:08,240 --> 00:18:11,280
almost 14 percent of the non-sequential

547
00:18:10,320 --> 00:18:13,520
excesses as

548
00:18:11,280 --> 00:18:14,480
irregular axis pattern and during

549
00:18:13,520 --> 00:18:17,120
irregularity

550
00:18:14,480 --> 00:18:17,840
it does not prefetch and for

551
00:18:17,120 --> 00:18:19,918
applications

552
00:18:17,840 --> 00:18:20,879
with high irregular access pattern like

553
00:18:19,919 --> 00:18:23,600
memcached

554
00:18:20,880 --> 00:18:25,120
this no prefetching helps most by not

555
00:18:23,600 --> 00:18:28,799
wasting the cash

556
00:18:25,120 --> 00:18:32,000
space not wasting the cpu cycle and the

557
00:18:28,799 --> 00:18:33,679
network bandwidth now we will see the

558
00:18:32,000 --> 00:18:36,480
performance benefit of lip

559
00:18:33,679 --> 00:18:37,760
over real world applications as you

560
00:18:36,480 --> 00:18:39,200
mentioned earlier

561
00:18:37,760 --> 00:18:41,039
throughput sensitive applications live

562
00:18:39,200 --> 00:18:42,080
boldly when half of the memory is taken

563
00:18:41,039 --> 00:18:44,799
away from them

564
00:18:42,080 --> 00:18:45,199
they faces almost 38 times performance

565
00:18:44,799 --> 00:18:47,600
drop

566
00:18:45,200 --> 00:18:49,520
due to swapping to the disk swapping to

567
00:18:47,600 --> 00:18:50,719
remote memory using infinite swap can

568
00:18:49,520 --> 00:18:53,360
improve the situation

569
00:18:50,720 --> 00:18:54,799
but here we still faces students

570
00:18:53,360 --> 00:18:57,039
performance drop

571
00:18:54,799 --> 00:18:59,120
however due to the lightweight data path

572
00:18:57,039 --> 00:19:01,919
and efficient prefetching

573
00:18:59,120 --> 00:19:03,199
in lib volume faces almost the local

574
00:19:01,919 --> 00:19:05,039
memory performance

575
00:19:03,200 --> 00:19:07,760
benefit when it is integrated with

576
00:19:05,039 --> 00:19:07,760
infinite straw

577
00:19:07,919 --> 00:19:11,360
leaves performance benefit prevails even

578
00:19:10,000 --> 00:19:15,200
at the presence of

579
00:19:11,360 --> 00:19:17,039
extreme memory constraint for example

580
00:19:15,200 --> 00:19:18,960
when the host machine can provide only

581
00:19:17,039 --> 00:19:21,600
25 percent of the memory

582
00:19:18,960 --> 00:19:22,960
voltav cannot run with disk with

583
00:19:21,600 --> 00:19:26,000
infinity swap

584
00:19:22,960 --> 00:19:27,919
it can run hardly almost losing 95

585
00:19:26,000 --> 00:19:30,000
percent of its performance

586
00:19:27,919 --> 00:19:31,679
on the other hand lip provides almost

587
00:19:30,000 --> 00:19:32,799
some linear performance drop in such

588
00:19:31,679 --> 00:19:34,799
situation

589
00:19:32,799 --> 00:19:36,559
here even though almost three-fourth of

590
00:19:34,799 --> 00:19:38,400
the memory is taken away

591
00:19:36,559 --> 00:19:40,080
integration of flip provides the vault

592
00:19:38,400 --> 00:19:43,840
db only

593
00:19:40,080 --> 00:19:43,840
2.4 times performance loss

594
00:19:44,080 --> 00:19:48,559
finally we'll see the benefit of each of

595
00:19:46,480 --> 00:19:50,320
the leaps component

596
00:19:48,559 --> 00:19:52,080
removing the unnecessary block layer

597
00:19:50,320 --> 00:19:54,240
operations from leaves data path

598
00:19:52,080 --> 00:19:56,080
gives a single microsecond latency up to

599
00:19:54,240 --> 00:19:58,400
the 95 percentage

600
00:19:56,080 --> 00:20:00,799
inclusion of the prefetcher gives a sub

601
00:19:58,400 --> 00:20:03,360
microsecond latency up to the 85

602
00:20:00,799 --> 00:20:04,879
percenter and the tail latency improves

603
00:20:03,360 --> 00:20:07,918
by 12 percent

604
00:20:04,880 --> 00:20:09,760
on top of this lightweight data the

605
00:20:07,919 --> 00:20:11,919
eager cash eviction policy

606
00:20:09,760 --> 00:20:13,600
reduces the page allocation wait time

607
00:20:11,919 --> 00:20:17,520
and therefore it improves the tail

608
00:20:13,600 --> 00:20:17,520
latency by another 22 percent

609
00:20:18,159 --> 00:20:21,840
our expense only

610
00:20:22,400 --> 00:20:26,640
from our experience only we realize the

611
00:20:24,320 --> 00:20:29,678
scope of falling research direction

612
00:20:26,640 --> 00:20:31,600
to further enhance its performance in

613
00:20:29,679 --> 00:20:34,400
today's linux memory address space

614
00:20:31,600 --> 00:20:35,678
is managed at the process level thread

615
00:20:34,400 --> 00:20:38,000
specific prefetching

616
00:20:35,679 --> 00:20:40,320
and page tracking can help us to

617
00:20:38,000 --> 00:20:40,960
efficiently identify multiple concurrent

618
00:20:40,320 --> 00:20:43,439
streams

619
00:20:40,960 --> 00:20:44,559
originated from different chairs however

620
00:20:43,440 --> 00:20:46,480
to do so

621
00:20:44,559 --> 00:20:48,480
we need to significantly modify the

622
00:20:46,480 --> 00:20:50,480
whole virtual memory subsystem

623
00:20:48,480 --> 00:20:52,640
in a future work we want to realize the

624
00:20:50,480 --> 00:20:54,960
scope of low overhead threat specific

625
00:20:52,640 --> 00:20:57,440
prefetching and page tracking

626
00:20:54,960 --> 00:20:59,120
in our current work we mostly focus on

627
00:20:57,440 --> 00:21:00,080
augmenting existing remote memory

628
00:20:59,120 --> 00:21:02,239
frameworks

629
00:21:00,080 --> 00:21:03,360
that's why it doesn't live in such a way

630
00:21:02,240 --> 00:21:05,919
that it remains

631
00:21:03,360 --> 00:21:07,039
transparent to the remote io interface

632
00:21:05,919 --> 00:21:09,440
in our future work

633
00:21:07,039 --> 00:21:10,640
we want to integrate an optimized i o

634
00:21:09,440 --> 00:21:13,200
interface

635
00:21:10,640 --> 00:21:14,240
considering the effect of load balancing

636
00:21:13,200 --> 00:21:16,240
fault tolerance

637
00:21:14,240 --> 00:21:18,400
data locality and applications

638
00:21:16,240 --> 00:21:19,840
application specific isolation in remote

639
00:21:18,400 --> 00:21:22,240
memory

640
00:21:19,840 --> 00:21:24,240
to summarize lib is a lightweight and

641
00:21:22,240 --> 00:21:25,760
efficient data path for remote memory

642
00:21:24,240 --> 00:21:27,280
which can operate without any

643
00:21:25,760 --> 00:21:28,720
modification in the application and

644
00:21:27,280 --> 00:21:30,799
hardware

645
00:21:28,720 --> 00:21:32,000
at its core it employs an online

646
00:21:30,799 --> 00:21:34,000
preferencing technique

647
00:21:32,000 --> 00:21:36,080
which is complemented by and linear data

648
00:21:34,000 --> 00:21:38,400
path and eager cash eviction policy

649
00:21:36,080 --> 00:21:39,199
with a goal to improve the remote eye

650
00:21:38,400 --> 00:21:41,440
latency

651
00:21:39,200 --> 00:21:43,120
and application level performance and

652
00:21:41,440 --> 00:21:45,440
that's all from me today

653
00:21:43,120 --> 00:21:57,678
thank you for being here and listening

654
00:21:45,440 --> 00:21:57,679
to my presentation

