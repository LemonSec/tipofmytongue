1
00:00:00,719 --> 00:00:04,080
all right so we're gonna start in

2
00:00:04,080 --> 00:00:06,500
English

3
00:00:08,039 --> 00:00:10,620
so here am I with uh

4
00:00:10,620 --> 00:00:13,099
my body one more time of course

5
00:00:13,099 --> 00:00:16,560
to introduce the plot for eye

6
00:00:16,560 --> 00:00:18,600
yes quickly where I am I'm a privacy

7
00:00:18,600 --> 00:00:20,820
engineer

8
00:00:20,820 --> 00:00:24,480
um advisor we have a consultancy called

9
00:00:24,480 --> 00:00:27,359
right we will focused specifically on

10
00:00:27,359 --> 00:00:31,099
privacy engineering questions

11
00:00:31,880 --> 00:00:34,920
such a big topic

12
00:00:34,920 --> 00:00:37,380
um I'm also part of the

13
00:00:37,380 --> 00:00:39,180
Anita

14
00:00:39,180 --> 00:00:44,579
organization as a party data protection

15
00:00:44,579 --> 00:00:47,760
Engineering Group as one of the advisors

16
00:00:47,760 --> 00:00:50,100
so for yeah one of you that don't know

17
00:00:50,100 --> 00:00:51,600
what really privacy engineering is

18
00:00:51,600 --> 00:00:53,879
there's a lot of

19
00:00:53,879 --> 00:00:57,140
technical uh

20
00:00:57,660 --> 00:01:00,500
um yeah research this is a way of really

21
00:01:00,500 --> 00:01:03,059
approaching privacy and protecting

22
00:01:03,059 --> 00:01:04,799
personal data from the technical

23
00:01:04,799 --> 00:01:06,840
perspective so it has a lot of things in

24
00:01:06,840 --> 00:01:08,220
common with security

25
00:01:08,220 --> 00:01:10,020
so we look out a lot of its description

26
00:01:10,020 --> 00:01:12,060
and all those things but you also need

27
00:01:12,060 --> 00:01:14,820
to understand the legal part

28
00:01:14,820 --> 00:01:17,400
and uh yeah more time maybe you want to

29
00:01:17,400 --> 00:01:19,080
say something about yourself

30
00:01:19,080 --> 00:01:20,780
yeah my name is

31
00:01:20,780 --> 00:01:22,799
I don't have such an impressive track

32
00:01:22,799 --> 00:01:26,100
record this Isabel but I mainly do

33
00:01:26,100 --> 00:01:28,380
security and I'm moving into privacy and

34
00:01:28,380 --> 00:01:30,840
yeah now that we started a company also

35
00:01:30,840 --> 00:01:32,340
moving into AI

36
00:01:32,340 --> 00:01:34,619
and yeah today we're here going to

37
00:01:34,619 --> 00:01:36,840
present about plot for AI something to

38
00:01:36,840 --> 00:01:38,220
build developed

39
00:01:38,220 --> 00:01:42,060
town yes you're gonna first I will give

40
00:01:42,060 --> 00:01:45,659
a short introduction maybe also

41
00:01:45,659 --> 00:01:48,659
um this is listed as a talk uh but it's

42
00:01:48,659 --> 00:01:50,340
going to be much more than a book we're

43
00:01:50,340 --> 00:01:52,860
gonna do some actual work too we brought

44
00:01:52,860 --> 00:01:55,140
the threat modeling library with us and

45
00:01:55,140 --> 00:01:56,880
you'll be able to do some Hands-On work

46
00:01:56,880 --> 00:01:58,920
in the second part of this presentation

47
00:01:58,920 --> 00:02:02,340
in teams in teams so it's going to be

48
00:02:02,340 --> 00:02:04,619
really fun I hope

49
00:02:04,619 --> 00:02:06,420
um but before that I want to give a

50
00:02:06,420 --> 00:02:08,098
really really really small introduction

51
00:02:08,098 --> 00:02:10,318
about threat modeling

52
00:02:10,318 --> 00:02:12,239
um so first I would like to know who

53
00:02:12,239 --> 00:02:15,120
here knows or understands what threat

54
00:02:15,120 --> 00:02:17,840
modeling is

55
00:02:17,940 --> 00:02:21,480
okay yeah about half really good and who

56
00:02:21,480 --> 00:02:23,879
does threat modeling or has done it in

57
00:02:23,879 --> 00:02:25,860
the past

58
00:02:25,860 --> 00:02:28,819
fewer hands

59
00:02:29,120 --> 00:02:32,400
actually we all do thread modeling every

60
00:02:32,400 --> 00:02:34,560
day this is a picture I took in the

61
00:02:34,560 --> 00:02:38,099
supermarket uh the Cucumber here

62
00:02:38,099 --> 00:02:40,319
on the right a bit less than one Euro

63
00:02:40,319 --> 00:02:42,540
cucumbers and on the left

64
00:02:42,540 --> 00:02:45,540
other cucumbers like 50 more expensive

65
00:02:45,540 --> 00:02:47,040
but they're biological so they're

66
00:02:47,040 --> 00:02:49,860
probably better for your health so

67
00:02:49,860 --> 00:02:51,840
this is the choice that you have what do

68
00:02:51,840 --> 00:02:53,300
you choose

69
00:02:53,300 --> 00:02:55,620
it also depends on your risk appetite

70
00:02:55,620 --> 00:02:57,480
and this is where you actually already

71
00:02:57,480 --> 00:02:59,160
do some thread modeling how do I take

72
00:02:59,160 --> 00:03:01,140
this risk do I find it acceptable what

73
00:03:01,140 --> 00:03:03,720
is really a risk so we'll do threat

74
00:03:03,720 --> 00:03:05,580
modeling at some point

75
00:03:05,580 --> 00:03:06,959
and

76
00:03:06,959 --> 00:03:08,700
when you look for thread modeling online

77
00:03:08,700 --> 00:03:10,860
you will go to websites of ovasp or

78
00:03:10,860 --> 00:03:12,840
Wikipedia and you have like really nice

79
00:03:12,840 --> 00:03:15,599
definitions of threat modeling but to me

80
00:03:15,599 --> 00:03:17,819
threat modeling in its Essence it's

81
00:03:17,819 --> 00:03:20,700
really having a mindset to question what

82
00:03:20,700 --> 00:03:23,299
can go wrong

83
00:03:24,000 --> 00:03:25,860
so how do you do threat modeling how do

84
00:03:25,860 --> 00:03:28,379
you need to be an expert for that

85
00:03:28,379 --> 00:03:29,819
um in my opinion you don't really need

86
00:03:29,819 --> 00:03:32,040
to be an expert I think if you in a

87
00:03:32,040 --> 00:03:34,080
professional situation if you are in a

88
00:03:34,080 --> 00:03:35,159
work environment if you want to do

89
00:03:35,159 --> 00:03:36,959
threat modeling and you see it with a

90
00:03:36,959 --> 00:03:38,519
really diverse group of stakeholders

91
00:03:38,519 --> 00:03:41,340
you're good to go have a great mindset

92
00:03:41,340 --> 00:03:44,159
of course but of course it does help and

93
00:03:44,159 --> 00:03:45,900
there's an expert presence that can like

94
00:03:45,900 --> 00:03:47,879
guide it

95
00:03:47,879 --> 00:03:49,860
um there's also most that can help you

96
00:03:49,860 --> 00:03:53,459
stride is a very well-known model it's

97
00:03:53,459 --> 00:03:55,680
developed by Microsoft and again if you

98
00:03:55,680 --> 00:03:57,780
have an expert there that knows how that

99
00:03:57,780 --> 00:03:59,640
works that can guide a session that that

100
00:03:59,640 --> 00:04:01,140
really helps

101
00:04:01,140 --> 00:04:03,780
and there's also tools available

102
00:04:03,780 --> 00:04:06,599
so um but a little bit more about that

103
00:04:06,599 --> 00:04:08,519
later

104
00:04:08,519 --> 00:04:09,180
um

105
00:04:09,180 --> 00:04:12,120
I suspect that most of you all have a

106
00:04:12,120 --> 00:04:13,980
background in security or at least the

107
00:04:13,980 --> 00:04:15,720
majority of the audience here so when

108
00:04:15,720 --> 00:04:17,040
you think about threat modeling you

109
00:04:17,040 --> 00:04:18,720
probably think about threat modeling in

110
00:04:18,720 --> 00:04:21,298
a security context

111
00:04:21,298 --> 00:04:23,940
and just for the purpose of this really

112
00:04:23,940 --> 00:04:25,680
brief introduction I want to highlight

113
00:04:25,680 --> 00:04:27,720
these three aspects

114
00:04:27,720 --> 00:04:29,940
a technical aspects functional aspects

115
00:04:29,940 --> 00:04:31,860
and processes what do I mean with that

116
00:04:31,860 --> 00:04:34,080
like a technical aspect is for example

117
00:04:34,080 --> 00:04:36,060
encryption what kind of encryption do

118
00:04:36,060 --> 00:04:38,600
you have or do you even have encryption

119
00:04:38,600 --> 00:04:40,919
functional aspects you should think

120
00:04:40,919 --> 00:04:43,080
about say you are developing like a web

121
00:04:43,080 --> 00:04:44,940
application and you have a login so a

122
00:04:44,940 --> 00:04:46,979
login is in functional aspects

123
00:04:46,979 --> 00:04:49,020
and with processes what I mean there is

124
00:04:49,020 --> 00:04:51,419
more like business processes so you

125
00:04:51,419 --> 00:04:52,620
might have customers going to your

126
00:04:52,620 --> 00:04:55,080
website they log in but the customer can

127
00:04:55,080 --> 00:04:56,759
also decide not to go to your website

128
00:04:56,759 --> 00:04:58,620
but to Go customer service and

129
00:04:58,620 --> 00:05:00,660
authenticate themselves there

130
00:05:00,660 --> 00:05:04,380
and um when you look at the usage of

131
00:05:04,380 --> 00:05:06,860
tools oh

132
00:05:06,860 --> 00:05:09,600
this was another presentation in another

133
00:05:09,600 --> 00:05:11,880
computer but we had to switch so this we

134
00:05:11,880 --> 00:05:13,520
never first didn't

135
00:05:13,520 --> 00:05:16,199
threat modeling here

136
00:05:16,199 --> 00:05:18,900
um when you think about tools that

137
00:05:18,900 --> 00:05:20,759
usually I will go back to the previous

138
00:05:20,759 --> 00:05:22,919
slide so

139
00:05:22,919 --> 00:05:24,600
tools are usually really good at

140
00:05:24,600 --> 00:05:27,180
technical effects they are less good at

141
00:05:27,180 --> 00:05:28,740
the functional aspects and they are not

142
00:05:28,740 --> 00:05:32,460
good at all at the processes but having

143
00:05:32,460 --> 00:05:34,680
that into account

144
00:05:34,680 --> 00:05:37,860
they have some some benefits and so it's

145
00:05:37,860 --> 00:05:40,020
teams that are not so experienced in

146
00:05:40,020 --> 00:05:41,639
threat modeling they really help out

147
00:05:41,639 --> 00:05:43,740
there it's also really good for

148
00:05:43,740 --> 00:05:44,960
automation

149
00:05:44,960 --> 00:05:47,520
but some negative

150
00:05:47,520 --> 00:05:50,820
SX is more I have the feeling they

151
00:05:50,820 --> 00:05:52,740
sometimes create they kill the creative

152
00:05:52,740 --> 00:05:54,479
mindset here because everything is spoon

153
00:05:54,479 --> 00:05:55,880
fit

154
00:05:55,880 --> 00:06:00,500
people tend to think less of themselves

155
00:06:01,380 --> 00:06:03,600
so that was security of course I've done

156
00:06:03,600 --> 00:06:05,280
it like really short

157
00:06:05,280 --> 00:06:07,380
um but also outside of security threat

158
00:06:07,380 --> 00:06:09,419
modeling is also done uh if you look at

159
00:06:09,419 --> 00:06:12,780
privacy uh lindum is uh probably the the

160
00:06:12,780 --> 00:06:15,300
most famous methodology for doing threat

161
00:06:15,300 --> 00:06:17,400
modeling

162
00:06:17,400 --> 00:06:20,039
um it is sort of a tool like not really

163
00:06:20,039 --> 00:06:22,979
actually have some security uh but it is

164
00:06:22,979 --> 00:06:25,199
already much more structured than having

165
00:06:25,199 --> 00:06:27,840
just a free format session with some

166
00:06:27,840 --> 00:06:30,360
stakeholders when you sit down it really

167
00:06:30,360 --> 00:06:32,400
presents you with questions and it helps

168
00:06:32,400 --> 00:06:35,400
you to think in in privacy threats and

169
00:06:35,400 --> 00:06:37,259
the reason I'm pointing out LinkedIn is

170
00:06:37,259 --> 00:06:39,120
that today we'll be talking about threat

171
00:06:39,120 --> 00:06:41,460
modeling in in AI

172
00:06:41,460 --> 00:06:45,360
for AI for AI and

173
00:06:45,360 --> 00:06:49,080
um it was inspired by lindung so to to

174
00:06:49,080 --> 00:06:51,840
wrap it up uh like what I started with

175
00:06:51,840 --> 00:06:53,580
for me threat modeling is really having

176
00:06:53,580 --> 00:06:55,800
a mindset to question what can go wrong

177
00:06:55,800 --> 00:06:59,819
now ai is very new also the landscape of

178
00:06:59,819 --> 00:07:01,919
things that can go wrong it's it's very

179
00:07:01,919 --> 00:07:04,259
very diverse and everyone is still

180
00:07:04,259 --> 00:07:06,360
struggling with that and that is really

181
00:07:06,360 --> 00:07:09,600
where both why I can help it helps you

182
00:07:09,600 --> 00:07:11,880
um both with having them right mindsets

183
00:07:11,880 --> 00:07:14,100
but also it helps you with your

184
00:07:14,100 --> 00:07:16,759
education of that very diverse landscape

185
00:07:16,759 --> 00:07:19,560
and uh yeah Isabel is going to tell you

186
00:07:19,560 --> 00:07:22,199
all about that now it's the final note I

187
00:07:22,199 --> 00:07:24,000
find it really nice to be here today in

188
00:07:24,000 --> 00:07:25,500
the hacker Hotel

189
00:07:25,500 --> 00:07:26,220
um

190
00:07:26,220 --> 00:07:28,740
because what do hackers do when

191
00:07:28,740 --> 00:07:30,660
something is not available they look at

192
00:07:30,660 --> 00:07:32,880
what is available and they maybe try to

193
00:07:32,880 --> 00:07:35,220
convert it and make it something of

194
00:07:35,220 --> 00:07:37,319
their own and that is really what Isabel

195
00:07:37,319 --> 00:07:39,000
has done when she started with this

196
00:07:39,000 --> 00:07:42,060
nothing like this existed uh she took

197
00:07:42,060 --> 00:07:44,039
some inspiration like from lindum and

198
00:07:44,039 --> 00:07:46,740
she created something all by herself uh

199
00:07:46,740 --> 00:07:48,120
that yeah

200
00:07:48,120 --> 00:07:49,979
came into this and then also open

201
00:07:49,979 --> 00:07:52,080
sourced it so everyone can benefit from

202
00:07:52,080 --> 00:07:54,720
it so if you get a guidance after this

203
00:07:54,720 --> 00:07:56,460
presentation it's all online it's all

204
00:07:56,460 --> 00:07:59,720
available and everyone can use it so

205
00:07:59,720 --> 00:08:02,220
thank you

206
00:08:02,220 --> 00:08:05,940
very nice way of opening the

207
00:08:05,940 --> 00:08:08,400
well I'm going to introduce you I think

208
00:08:08,400 --> 00:08:10,560
it's also nice to you to understand how

209
00:08:10,560 --> 00:08:12,780
I created plot for AI where does it come

210
00:08:12,780 --> 00:08:13,200
from

211
00:08:13,200 --> 00:08:15,360
[Applause]

212
00:08:15,360 --> 00:08:17,460
or just to understand that there is

213
00:08:17,460 --> 00:08:20,460
based on my background and security and

214
00:08:20,460 --> 00:08:23,220
then the times have you threat modeling

215
00:08:23,220 --> 00:08:25,740
it is much less technical you will see

216
00:08:25,740 --> 00:08:28,020
now that with with AI and thread

217
00:08:28,020 --> 00:08:29,819
modeling you really need to look beyond

218
00:08:29,819 --> 00:08:32,640
the security threats

219
00:08:32,640 --> 00:08:34,679
uh but well I would start with as an

220
00:08:34,679 --> 00:08:35,820
introduction

221
00:08:35,820 --> 00:08:38,039
um where does it come from

222
00:08:38,039 --> 00:08:39,958
this is plot for AI with eight different

223
00:08:39,958 --> 00:08:45,000
categories 86 different threads

224
00:08:45,000 --> 00:08:47,880
we see threats related to the technical

225
00:08:47,880 --> 00:08:50,760
part of AI processes involved in the

226
00:08:50,760 --> 00:08:52,320
development of AI

227
00:08:52,320 --> 00:08:54,120
but also threats related to

228
00:08:54,120 --> 00:08:56,279
accessibility because sometimes you are

229
00:08:56,279 --> 00:08:57,779
developing an AI application and you

230
00:08:57,779 --> 00:08:59,040
really need to have an account the way

231
00:08:59,040 --> 00:09:00,540
you present certain information for

232
00:09:00,540 --> 00:09:03,600
instance how is it accessible there's

233
00:09:03,600 --> 00:09:06,060
also threats related to what I call

234
00:09:06,060 --> 00:09:07,980
non-compliance and you will see that

235
00:09:07,980 --> 00:09:10,680
some of the names here these names

236
00:09:10,680 --> 00:09:12,420
because they come from lindum I will

237
00:09:12,420 --> 00:09:14,700
tell you you will understand now why

238
00:09:14,700 --> 00:09:16,320
and by no compliance they are really

239
00:09:16,320 --> 00:09:19,440
risk related to yeah a lot of Regulation

240
00:09:19,440 --> 00:09:21,240
and not only privacy but could be

241
00:09:21,240 --> 00:09:24,180
copyright competition or unless a lot of

242
00:09:24,180 --> 00:09:25,980
stuff that you need to have in account

243
00:09:25,980 --> 00:09:28,920
and you are as a AI

244
00:09:28,920 --> 00:09:31,080
an awareness that would be a lack of

245
00:09:31,080 --> 00:09:32,339
transparency lack of information

246
00:09:32,339 --> 00:09:34,440
something that now with AI is also quite

247
00:09:34,440 --> 00:09:35,760
important

248
00:09:35,760 --> 00:09:37,800
we already have the gdpr

249
00:09:37,800 --> 00:09:40,080
then threats related to ethics and human

250
00:09:40,080 --> 00:09:41,519
rights

251
00:09:41,519 --> 00:09:43,800
and there's also a section a category

252
00:09:43,800 --> 00:09:45,600
called identifiability and linkability

253
00:09:45,600 --> 00:09:48,060
that also comes from lindum and it's in

254
00:09:48,060 --> 00:09:50,040
case when you're really using AI where

255
00:09:50,040 --> 00:09:52,019
personal data can be identifiable maybe

256
00:09:52,019 --> 00:09:54,240
in the when the training that's set or

257
00:09:54,240 --> 00:09:55,980
trying to model

258
00:09:55,980 --> 00:09:58,800
the other section related to safety

259
00:09:58,800 --> 00:10:01,560
another physical safety and another for

260
00:10:01,560 --> 00:10:03,739
security

261
00:10:04,260 --> 00:10:06,839
now all this information comes from

262
00:10:06,839 --> 00:10:10,140
about 200 different sources of uh yeah

263
00:10:10,140 --> 00:10:11,880
of information that I've been collecting

264
00:10:11,880 --> 00:10:14,220
for the last three years so this is a

265
00:10:14,220 --> 00:10:16,200
three years research

266
00:10:16,200 --> 00:10:18,060
so yes this is just to mentioned a few

267
00:10:18,060 --> 00:10:20,519
but this uh if it's I'm like I'm

268
00:10:20,519 --> 00:10:23,519
everything that comes uh me I analyze it

269
00:10:23,519 --> 00:10:26,279
and I I start putting it in the library

270
00:10:26,279 --> 00:10:28,380
doing the analysis

271
00:10:28,380 --> 00:10:30,300
so with all the information I collected

272
00:10:30,300 --> 00:10:35,240
I classified and I created a plot for AI

273
00:10:35,339 --> 00:10:36,839
opinions of this for the Ones review

274
00:10:36,839 --> 00:10:39,720
that I guess uh I think how many of you

275
00:10:39,720 --> 00:10:43,640
is not aware with that benefits

276
00:10:44,160 --> 00:10:47,399
you don't know can any of use any mode

277
00:10:47,399 --> 00:10:50,880
it was Flora

278
00:10:55,079 --> 00:10:57,720
the Dutch texture of specially profiled

279
00:10:57,720 --> 00:11:00,600
people with risk for

280
00:11:00,600 --> 00:11:03,779
hmm falsely claiming benefits and the

281
00:11:03,779 --> 00:11:06,240
rich profile was based on

282
00:11:06,240 --> 00:11:09,120
more for categories of personal data

283
00:11:09,120 --> 00:11:12,779
like NST or country version of people it

284
00:11:12,779 --> 00:11:16,019
was still still resolved

285
00:11:16,019 --> 00:11:17,820
but

286
00:11:17,820 --> 00:11:20,880
I I I could add or remove things from

287
00:11:20,880 --> 00:11:22,620
your comment

288
00:11:22,620 --> 00:11:27,060
but I I was after the the flag after I

289
00:11:27,060 --> 00:11:29,339
was hired to analyze uh what happened

290
00:11:29,339 --> 00:11:31,800
here so the algorithm the whole process

291
00:11:31,800 --> 00:11:33,839
and to finalize them

292
00:11:33,839 --> 00:11:35,820
data privacy impact assessment that

293
00:11:35,820 --> 00:11:39,300
hadn't been analyzed by that time so

294
00:11:39,300 --> 00:11:41,579
from that research of course came a lot

295
00:11:41,579 --> 00:11:43,680
of things no I had all got this open

296
00:11:43,680 --> 00:11:46,920
information so that that the report had

297
00:11:46,920 --> 00:11:48,959
to be sent to the parliament so all this

298
00:11:48,959 --> 00:11:50,579
is open

299
00:11:50,579 --> 00:11:53,600
but when I was working here

300
00:11:53,600 --> 00:11:56,279
then I realized you know I mean I've

301
00:11:56,279 --> 00:11:58,260
been using

302
00:11:58,260 --> 00:12:00,060
that modeling and privacy fit modeling

303
00:12:00,060 --> 00:12:02,820
like lindum and software development but

304
00:12:02,820 --> 00:12:05,220
when you really have this difficult

305
00:12:05,220 --> 00:12:08,820
sessions developing AI after really as

306
00:12:08,820 --> 00:12:10,339
machine learning

307
00:12:10,339 --> 00:12:12,360
where do I have to look at there you

308
00:12:12,360 --> 00:12:16,019
have this risk sessions and there's so

309
00:12:16,019 --> 00:12:17,700
many things that come wrong it's not

310
00:12:17,700 --> 00:12:20,880
just going through your uh yeah typical

311
00:12:20,880 --> 00:12:24,300
privacy risks or security risks but it

312
00:12:24,300 --> 00:12:26,339
can really go beyond that and it's

313
00:12:26,339 --> 00:12:27,899
really complicated

314
00:12:27,899 --> 00:12:30,360
so that was when I started with the IDE

315
00:12:30,360 --> 00:12:32,519
okay I

316
00:12:32,519 --> 00:12:34,860
no I think I went too much forward

317
00:12:34,860 --> 00:12:37,260
I I explained in the problem man the

318
00:12:37,260 --> 00:12:38,640
problem you face when you are working in

319
00:12:38,640 --> 00:12:40,500
privacy that's you need to look at so

320
00:12:40,500 --> 00:12:42,300
many risks like I mentioned especially

321
00:12:42,300 --> 00:12:44,760
when you need to eventually build some

322
00:12:44,760 --> 00:12:46,800
responsible AIS like how do you really

323
00:12:46,800 --> 00:12:49,019
do it because you need to look at yeah

324
00:12:49,019 --> 00:12:51,800
safety compliance and

325
00:12:51,800 --> 00:12:54,540
Technical risks so it's in place or you

326
00:12:54,540 --> 00:12:55,800
have a lot of knowledge or you have the

327
00:12:55,800 --> 00:12:57,899
right stakeholders on the table or and

328
00:12:57,899 --> 00:12:59,519
you need you need to focus you need to

329
00:12:59,519 --> 00:13:03,240
to understand what you need to look at

330
00:13:03,240 --> 00:13:05,279
and the tools that we have available at

331
00:13:05,279 --> 00:13:06,959
this moment and besides the technical

332
00:13:06,959 --> 00:13:10,380
tools of course for analyzing to to do

333
00:13:10,380 --> 00:13:12,060
some metrics for fairness explainability

334
00:13:12,060 --> 00:13:14,639
but that is not enough you need to look

335
00:13:14,639 --> 00:13:17,040
much more there and and we have some

336
00:13:17,040 --> 00:13:19,079
assessment tools like the outside like

337
00:13:19,079 --> 00:13:21,420
now in Netherlands we have the the Yama

338
00:13:21,420 --> 00:13:23,639
but for fundamental rights

339
00:13:23,639 --> 00:13:26,279
but this type of assessment tools uh

340
00:13:26,279 --> 00:13:29,459
they all contain a list of questions and

341
00:13:29,459 --> 00:13:32,220
if you analyze the questions there often

342
00:13:32,220 --> 00:13:34,079
questions in the in the future like

343
00:13:34,079 --> 00:13:37,260
which model would you be using or did

344
00:13:37,260 --> 00:13:39,420
you do a pen test yeah but when you are

345
00:13:39,420 --> 00:13:41,100
in the design phase if you don't know

346
00:13:41,100 --> 00:13:43,500
those things so it's they feel more like

347
00:13:43,500 --> 00:13:46,019
a kind of an audit internal audit tool

348
00:13:46,019 --> 00:13:48,779
or just a checklist and really something

349
00:13:48,779 --> 00:13:50,760
you need when you are in the development

350
00:13:50,760 --> 00:13:52,680
process

351
00:13:52,680 --> 00:13:55,980
and my experience in this project is a

352
00:13:55,980 --> 00:13:58,639
lot of noise going on everybody

353
00:13:58,639 --> 00:14:01,680
discussing that you see the data

354
00:14:01,680 --> 00:14:03,420
scientists teams starting that thing the

355
00:14:03,420 --> 00:14:04,980
business could be discussing thinking

356
00:14:04,980 --> 00:14:07,800
how much can we get of this

357
00:14:07,800 --> 00:14:11,100
I wanted to focus make it short really

358
00:14:11,100 --> 00:14:14,160
like we work in in the agile but just

359
00:14:14,160 --> 00:14:17,639
simply Clarity focus with teamwork and

360
00:14:17,639 --> 00:14:19,860
yeah so with a bit of fun and not these

361
00:14:19,860 --> 00:14:22,079
recession so boring hours that you don't

362
00:14:22,079 --> 00:14:23,399
know

363
00:14:23,399 --> 00:14:25,980
so that's how I came up with the idea of

364
00:14:25,980 --> 00:14:27,899
um let's extend lindum

365
00:14:27,899 --> 00:14:30,540
so I'm really fan of threat modeling I'm

366
00:14:30,540 --> 00:14:33,600
really aware of their yeah that value

367
00:14:33,600 --> 00:14:36,540
I like lingum and I think why not to

368
00:14:36,540 --> 00:14:38,160
make link Doom that is more for software

369
00:14:38,160 --> 00:14:40,920
development more uh to to develop it

370
00:14:40,920 --> 00:14:43,320
into really AI

371
00:14:43,320 --> 00:14:45,000
so I know also the researchers because

372
00:14:45,000 --> 00:14:47,160
lindum has been created by the carlofen

373
00:14:47,160 --> 00:14:48,899
university in Belgium

374
00:14:48,899 --> 00:14:52,620
and uh well one of their searches is uh

375
00:14:52,620 --> 00:14:54,959
one of my friends do so I I've been to

376
00:14:54,959 --> 00:14:56,399
they're involved in the whole

377
00:14:56,399 --> 00:14:57,959
development process so that they knew

378
00:14:57,959 --> 00:15:00,180
this is what I'm doing now with lindu so

379
00:15:00,180 --> 00:15:02,040
it's a Linden resource open source so

380
00:15:02,040 --> 00:15:05,519
that you know I'm that adjusted to for

381
00:15:05,519 --> 00:15:07,199
AI

382
00:15:07,199 --> 00:15:09,180
and here you see some of the categories

383
00:15:09,180 --> 00:15:11,339
that are part of Linton what I did was

384
00:15:11,339 --> 00:15:15,180
to based on my analysis reduce some of

385
00:15:15,180 --> 00:15:16,920
them and adapt

386
00:15:16,920 --> 00:15:21,560
towards later will become plot for AI

387
00:15:21,600 --> 00:15:25,560
in 2021 I presented a

388
00:15:25,560 --> 00:15:27,360
lot free either that time was called

389
00:15:27,360 --> 00:15:31,399
lindum ML and only had 25

390
00:15:31,399 --> 00:15:34,560
threats and I presented it with uh with

391
00:15:34,560 --> 00:15:36,720
Kim without one of the researchers from

392
00:15:36,720 --> 00:15:41,220
uh from lindum in in a in a conference

393
00:15:41,220 --> 00:15:45,180
in the U.S and yeah what I said it was

394
00:15:45,180 --> 00:15:47,399
really nothing at that moment

395
00:15:47,399 --> 00:15:49,560
and now yeah like I say it became really

396
00:15:49,560 --> 00:15:51,839
I see some personalities I'll name plot

397
00:15:51,839 --> 00:15:54,240
3i and it has 86 threads so as you can

398
00:15:54,240 --> 00:15:56,820
see it keeps evolving and I wouldn't say

399
00:15:56,820 --> 00:15:58,440
well we're gonna have how many treasure

400
00:15:58,440 --> 00:15:59,880
we're gonna have here because it becomes

401
00:15:59,880 --> 00:16:01,380
a lot

402
00:16:01,380 --> 00:16:02,339
um

403
00:16:02,339 --> 00:16:05,399
yeah at this moment I try to combine

404
00:16:05,399 --> 00:16:07,139
threads when I see I keep doing the

405
00:16:07,139 --> 00:16:10,199
analysis I um and it keeps being in 86

406
00:16:10,199 --> 00:16:12,779
threads luckily so um let's see how much

407
00:16:12,779 --> 00:16:15,180
you can grow this Community Drive

408
00:16:15,180 --> 00:16:17,599
project

409
00:16:18,000 --> 00:16:20,399
uh just to mention all the threats are

410
00:16:20,399 --> 00:16:22,459
also categorized

411
00:16:22,459 --> 00:16:25,380
during the development life cycle so

412
00:16:25,380 --> 00:16:27,959
when you work with AI

413
00:16:27,959 --> 00:16:32,160
often you were with one methodology

414
00:16:32,160 --> 00:16:34,440
and I don't know if any of you work with

415
00:16:34,440 --> 00:16:36,360
an AI project

416
00:16:36,360 --> 00:16:38,220
I know Crips DM is the one that we use

417
00:16:38,220 --> 00:16:39,600
more often but I've also worked with

418
00:16:39,600 --> 00:16:42,899
SEMA for instance if you use SAS

419
00:16:42,899 --> 00:16:45,660
so and you can adapt it

420
00:16:45,660 --> 00:16:46,079
[Music]

421
00:16:46,079 --> 00:16:47,100
um

422
00:16:47,100 --> 00:16:48,779
I come up with the idea of making it

423
00:16:48,779 --> 00:16:49,980
more simple

424
00:16:49,980 --> 00:16:52,940
and just using it to design input

425
00:16:52,940 --> 00:16:56,519
modeling and on the output

426
00:16:56,519 --> 00:16:58,680
because if all stakeholders is more it's

427
00:16:58,680 --> 00:17:00,300
more clear what you really need to in

428
00:17:00,300 --> 00:17:01,740
which phase you are when you are

429
00:17:01,740 --> 00:17:03,720
analyzing the risks

430
00:17:03,720 --> 00:17:05,520
and with this picture there you see that

431
00:17:05,520 --> 00:17:07,199
eventually it yeah all the different

432
00:17:07,199 --> 00:17:08,760
steps within the development life cycle

433
00:17:08,760 --> 00:17:11,579
are aligned there

434
00:17:11,579 --> 00:17:13,559
so did you see in all the threads for

435
00:17:13,559 --> 00:17:16,679
from plot 3i there's some icons and

436
00:17:16,679 --> 00:17:19,799
every thread is indicated in which phase

437
00:17:19,799 --> 00:17:22,140
of development life cycle this stats

438
00:17:22,140 --> 00:17:24,179
could arise

439
00:17:24,179 --> 00:17:26,699
and my advice is always check during the

440
00:17:26,699 --> 00:17:28,199
design phase almost all of them because

441
00:17:28,199 --> 00:17:32,220
it could be that that they happen

442
00:17:32,220 --> 00:17:32,760
um

443
00:17:32,760 --> 00:17:35,400
but for the rest some advice there I

444
00:17:35,400 --> 00:17:37,440
recommended you maybe this face or maybe

445
00:17:37,440 --> 00:17:39,059
the other

446
00:17:39,059 --> 00:17:42,299
now how does it really work plot for AI

447
00:17:42,299 --> 00:17:45,780
uh yeah it's a set of cards so this is a

448
00:17:45,780 --> 00:17:47,940
gamified

449
00:17:47,940 --> 00:17:50,760
um every car every category has a color

450
00:17:50,760 --> 00:17:53,280
and and it's also online so all the

451
00:17:53,280 --> 00:17:55,200
threads are also available online all

452
00:17:55,200 --> 00:17:56,760
the cards are online you can turn them

453
00:17:56,760 --> 00:17:58,860
so it's it's you have the online version

454
00:17:58,860 --> 00:18:00,900
and the paper version that is the one

455
00:18:00,900 --> 00:18:03,000
we're gonna use today now in uh during

456
00:18:03,000 --> 00:18:06,559
one of the games that we're gonna do

457
00:18:06,559 --> 00:18:09,539
so how does it work you will have a

458
00:18:09,539 --> 00:18:11,160
thread modeling session so you sit

459
00:18:11,160 --> 00:18:14,220
together with different stakeholders

460
00:18:14,220 --> 00:18:18,240
yeah I don't have a magic uh tip for who

461
00:18:18,240 --> 00:18:20,160
should be on the table it really depends

462
00:18:20,160 --> 00:18:22,620
on the use case on the face it's really

463
00:18:22,620 --> 00:18:24,660
difficult but try not to be just with

464
00:18:24,660 --> 00:18:27,600
the with the data science team and what

465
00:18:27,600 --> 00:18:30,240
I would say it also repents the type of

466
00:18:30,240 --> 00:18:32,460
threats you want to assess the threats

467
00:18:32,460 --> 00:18:34,740
for instance related to Security in the

468
00:18:34,740 --> 00:18:36,900
AI field they come you quite complex

469
00:18:36,900 --> 00:18:39,900
some of them so you really need people

470
00:18:39,900 --> 00:18:43,020
on the table that has that knowledge

471
00:18:43,020 --> 00:18:44,340
when it comes for instance with

472
00:18:44,340 --> 00:18:46,320
translated to ethics and human rights

473
00:18:46,320 --> 00:18:48,480
and the more the merrier you can really

474
00:18:48,480 --> 00:18:50,700
the diversity is really important in the

475
00:18:50,700 --> 00:18:52,500
field

476
00:18:52,500 --> 00:18:54,020
foreign

477
00:18:54,020 --> 00:18:57,059
modeling we often use a data flow

478
00:18:57,059 --> 00:18:57,900
diagram

479
00:18:57,900 --> 00:19:01,260
in AI in my experience

480
00:19:01,260 --> 00:19:04,140
we tend not to use anything what I I

481
00:19:04,140 --> 00:19:07,020
find a problem because you forget that

482
00:19:07,020 --> 00:19:08,760
you you have threats during the input

483
00:19:08,760 --> 00:19:11,400
phase and you have phases and we're

484
00:19:11,400 --> 00:19:13,140
doing the output what you see in the

485
00:19:13,140 --> 00:19:15,360
sessions is that the

486
00:19:15,360 --> 00:19:17,039
yeah we tend to thinking what the result

487
00:19:17,039 --> 00:19:19,140
or the impact could be from the output

488
00:19:19,140 --> 00:19:20,700
from the model but you forget that you

489
00:19:20,700 --> 00:19:22,620
still need the data to fit the model so

490
00:19:22,620 --> 00:19:24,360
then it's really good to have in around

491
00:19:24,360 --> 00:19:28,740
the whole iterative nature of of AI

492
00:19:28,740 --> 00:19:31,020
and if you go further than that yeah

493
00:19:31,020 --> 00:19:33,059
then like in other any other security

494
00:19:33,059 --> 00:19:35,160
threat mobilitation you you should look

495
00:19:35,160 --> 00:19:37,799
at the Integrations yeah also your third

496
00:19:37,799 --> 00:19:39,900
party providers all the apis you might

497
00:19:39,900 --> 00:19:41,940
be using that probably here a lot but

498
00:19:41,940 --> 00:19:44,100
also where all your training uh they

499
00:19:44,100 --> 00:19:46,080
store your model saturation then you

500
00:19:46,080 --> 00:19:47,280
started really looking

501
00:19:47,280 --> 00:19:50,100
wider because the threats also grow and

502
00:19:50,100 --> 00:19:51,600
then you also see that these threats are

503
00:19:51,600 --> 00:19:53,940
more the normal security threats that we

504
00:19:53,940 --> 00:19:55,440
usually have it's not

505
00:19:55,440 --> 00:19:58,039
different

506
00:19:58,580 --> 00:20:01,440
now what we see with plot for AI what I

507
00:20:01,440 --> 00:20:04,679
did was uh all the data I collected all

508
00:20:04,679 --> 00:20:08,000
the possible threads I I

509
00:20:08,000 --> 00:20:10,559
translated I've transformed them into a

510
00:20:10,559 --> 00:20:11,640
question

511
00:20:11,640 --> 00:20:13,799
in a way that it makes you really

512
00:20:13,799 --> 00:20:16,080
reflect so you have the game the card

513
00:20:16,080 --> 00:20:18,780
the threat you get the question direct

514
00:20:18,780 --> 00:20:21,480
to you as team and then you immediately

515
00:20:21,480 --> 00:20:23,580
have to give answer yes no oh I don't

516
00:20:23,580 --> 00:20:24,240
know

517
00:20:24,240 --> 00:20:26,039
or some say yes oh there's no then you

518
00:20:26,039 --> 00:20:27,840
immediately this could be a threat so

519
00:20:27,840 --> 00:20:30,918
you mark it as a threat

520
00:20:32,460 --> 00:20:35,520
and in the cards from plot for AI you

521
00:20:35,520 --> 00:20:38,400
see the question you also see on the top

522
00:20:38,400 --> 00:20:40,500
the category belongs to

523
00:20:40,500 --> 00:20:42,840
you see the development life cycle that

524
00:20:42,840 --> 00:20:44,460
is recommended we just recommended that

525
00:20:44,460 --> 00:20:46,500
you use the the card

526
00:20:46,500 --> 00:20:49,820
you see some information related

527
00:20:49,820 --> 00:20:53,160
and what really the question means and

528
00:20:53,160 --> 00:20:54,600
the game already gives you an answer if

529
00:20:54,600 --> 00:20:57,240
your answer is yes or no uh yeah you

530
00:20:57,240 --> 00:20:59,220
could have a threat

531
00:20:59,220 --> 00:21:00,720
and behind the card you have

532
00:21:00,720 --> 00:21:02,580
recommendations so once you turn it it

533
00:21:02,580 --> 00:21:04,500
gives you recommendation on how to solve

534
00:21:04,500 --> 00:21:06,059
that that fact

535
00:21:06,059 --> 00:21:07,980
and it also gives you uh links to

536
00:21:07,980 --> 00:21:10,620
interesting resources a lot of research

537
00:21:10,620 --> 00:21:11,840
papers

538
00:21:11,840 --> 00:21:15,000
sometimes blocks so everything is what

539
00:21:15,000 --> 00:21:16,380
I've been collecting during the last

540
00:21:16,380 --> 00:21:18,780
three years is there

541
00:21:18,780 --> 00:21:21,179
this is just a picture of one of the

542
00:21:21,179 --> 00:21:24,360
physical cards so basically the same and

543
00:21:24,360 --> 00:21:26,299
only in the back of course the links are

544
00:21:26,299 --> 00:21:29,880
you see a QR there because of course on

545
00:21:29,880 --> 00:21:31,440
paper you cannot keep updating the links

546
00:21:31,440 --> 00:21:33,780
but with the keyword yes so once you go

547
00:21:33,780 --> 00:21:35,520
to the QR it brings you to the website

548
00:21:35,520 --> 00:21:38,480
where the cart is

549
00:21:38,760 --> 00:21:41,039
now it's it's when we were with plot

550
00:21:41,039 --> 00:21:43,740
three I uh

551
00:21:43,740 --> 00:21:46,020
we just have a spreadsheet with the

552
00:21:46,020 --> 00:21:48,240
amount of risk that that you have

553
00:21:48,240 --> 00:21:52,200
selected you have identified and then if

554
00:21:52,200 --> 00:21:54,480
you have time at that moment you can do

555
00:21:54,480 --> 00:21:56,820
it later you could mark this thread as a

556
00:21:56,820 --> 00:21:59,220
high risk medium risk or low risk just

557
00:21:59,220 --> 00:22:01,919
make it really simple some industries of

558
00:22:01,919 --> 00:22:03,539
course we were fairly in the risk

559
00:22:03,539 --> 00:22:05,760
assessment risk management but at least

560
00:22:05,760 --> 00:22:07,380
in my experience

561
00:22:07,380 --> 00:22:08,940
in these sessions you need to do it

562
00:22:08,940 --> 00:22:10,740
quick and people doesn't like to spare

563
00:22:10,740 --> 00:22:12,840
time in analyzing risk so first at least

564
00:22:12,840 --> 00:22:15,240
at least a really big step is to

565
00:22:15,240 --> 00:22:17,520
identify threats and then later you can

566
00:22:17,520 --> 00:22:19,620
send them to the right person you create

567
00:22:19,620 --> 00:22:21,419
the user storage interior whatever you

568
00:22:21,419 --> 00:22:24,240
want to do with them but do some work on

569
00:22:24,240 --> 00:22:27,559
your threads that you have identified

570
00:22:28,500 --> 00:22:30,299
this uh

571
00:22:30,299 --> 00:22:32,580
I think doesn't work here

572
00:22:32,580 --> 00:22:34,740
for any reason

573
00:22:34,740 --> 00:22:37,320
it's not speeding this is in the website

574
00:22:37,320 --> 00:22:39,179
of plot 3 I

575
00:22:39,179 --> 00:22:40,799
um what you can also see is the

576
00:22:40,799 --> 00:22:42,179
assessment tool

577
00:22:42,179 --> 00:22:44,580
so um

578
00:22:44,580 --> 00:22:47,820
yeah it works exactly the same as with

579
00:22:47,820 --> 00:22:50,220
the cards so you will select the

580
00:22:50,220 --> 00:22:53,039
category you want to to do thread

581
00:22:53,039 --> 00:22:56,400
modeling also the the the development

582
00:22:56,400 --> 00:22:58,860
life cycle phase where you want to to

583
00:22:58,860 --> 00:23:01,620
thread model and then would you get are

584
00:23:01,620 --> 00:23:04,559
the questions with different colors so

585
00:23:04,559 --> 00:23:07,140
per question you go selecting yes no or

586
00:23:07,140 --> 00:23:09,120
I don't know and after that you get a

587
00:23:09,120 --> 00:23:10,080
report

588
00:23:10,080 --> 00:23:12,780
and threads it with your threads so

589
00:23:12,780 --> 00:23:14,580
after that you can just share the thread

590
00:23:14,580 --> 00:23:17,039
the the file and keep working saying if

591
00:23:17,039 --> 00:23:19,140
there is high risk medium low

592
00:23:19,140 --> 00:23:20,880
because you're gonna see that but in the

593
00:23:20,880 --> 00:23:24,000
website of course is all available

594
00:23:24,000 --> 00:23:26,220
and that when we do work remote to teams

595
00:23:26,220 --> 00:23:28,679
it's really really handy

596
00:23:28,679 --> 00:23:30,299
so this is yeah of course we I couldn't

597
00:23:30,299 --> 00:23:32,520
show you but in the in the in the video

598
00:23:32,520 --> 00:23:35,700
we had made a short selection we

599
00:23:35,700 --> 00:23:37,919
answered the questions and this is what

600
00:23:37,919 --> 00:23:40,500
we get a report with the two threads

601
00:23:40,500 --> 00:23:42,480
that have been identified

602
00:23:42,480 --> 00:23:45,720
and then yeah that you you move that

603
00:23:45,720 --> 00:23:48,120
usually two year available everybody can

604
00:23:48,120 --> 00:23:50,700
do different things here

605
00:23:50,700 --> 00:23:52,919
now because we are aware there are 86

606
00:23:52,919 --> 00:23:56,159
streets threats so that's a lot of

607
00:23:56,159 --> 00:23:58,919
yeah a high learning queue curve so we

608
00:23:58,919 --> 00:24:00,419
know this is the people yeah I think

609
00:24:00,419 --> 00:24:01,860
that's a lot of threats how can you

610
00:24:01,860 --> 00:24:04,799
really work with so many threats uh wake

611
00:24:04,799 --> 00:24:07,140
up with the heavy well we do like um

612
00:24:07,140 --> 00:24:10,020
a threat every day so you can just say

613
00:24:10,020 --> 00:24:11,880
through the website you can also put it

614
00:24:11,880 --> 00:24:14,400
in your in your phone away every day it

615
00:24:14,400 --> 00:24:16,860
tells you like today February 11th you

616
00:24:16,860 --> 00:24:19,080
have the threat we need to use metadata

617
00:24:19,080 --> 00:24:20,460
to fit our model

618
00:24:20,460 --> 00:24:22,380
so when you click there and you will see

619
00:24:22,380 --> 00:24:24,240
information about that specific thread

620
00:24:24,240 --> 00:24:25,919
and in the way every day you can learn

621
00:24:25,919 --> 00:24:28,500
about a new a different thread

622
00:24:28,500 --> 00:24:30,240
because the nice plot for your eyes that

623
00:24:30,240 --> 00:24:31,380
even if you don't use it for threat

624
00:24:31,380 --> 00:24:33,179
modeling it's a really good knowledge

625
00:24:33,179 --> 00:24:36,919
base there's a lot of knowledge there

626
00:24:37,320 --> 00:24:39,720
well the result after

627
00:24:39,720 --> 00:24:43,860
having worked with plot 3i

628
00:24:43,860 --> 00:24:46,200
is that in general what uses the

629
00:24:46,200 --> 00:24:48,360
organization becomes more mature because

630
00:24:48,360 --> 00:24:50,460
you really realize the threats are even

631
00:24:50,460 --> 00:24:52,260
affecting the organization the

632
00:24:52,260 --> 00:24:54,480
especially the quality process

633
00:24:54,480 --> 00:24:57,299
improves collaboration reduces a lot we

634
00:24:57,299 --> 00:24:59,940
work so we have seen projects where

635
00:24:59,940 --> 00:25:01,440
after one session we already killed the

636
00:25:01,440 --> 00:25:03,600
project we're pretty clear that this is

637
00:25:03,600 --> 00:25:05,280
not a we are not going in the right

638
00:25:05,280 --> 00:25:06,179
direction

639
00:25:06,179 --> 00:25:08,940
so and of course especially privacy

640
00:25:08,940 --> 00:25:10,380
officer is going to really happy because

641
00:25:10,380 --> 00:25:12,240
you have a list of threads identified

642
00:25:12,240 --> 00:25:14,700
and that can be added to the the

643
00:25:14,700 --> 00:25:16,320
Enterprise impact assessment so

644
00:25:16,320 --> 00:25:19,520
everybody is happy there

645
00:25:19,760 --> 00:25:23,580
it's a open source have a creative cons

646
00:25:23,580 --> 00:25:27,120
license and yeah it's everything is in

647
00:25:27,120 --> 00:25:29,400
GitHub so what we said the forecast

648
00:25:29,400 --> 00:25:31,559
collaborate

649
00:25:31,559 --> 00:25:32,460
um

650
00:25:32,460 --> 00:25:34,620
I'll send you feedback so just for it

651
00:25:34,620 --> 00:25:37,260
for all of us

652
00:25:37,260 --> 00:25:39,179
now in the future

653
00:25:39,179 --> 00:25:42,179
um blood free eye is like fat becoming

654
00:25:42,179 --> 00:25:44,880
quite famous around the world and it's

655
00:25:44,880 --> 00:25:48,360
been using a lot of organizations

656
00:25:48,360 --> 00:25:49,140
um

657
00:25:49,140 --> 00:25:53,299
in some Dutch universities especially

658
00:25:53,360 --> 00:25:56,279
by myself teaching them to engineers and

659
00:25:56,279 --> 00:25:57,779
then some of you with some use cases so

660
00:25:57,779 --> 00:26:00,060
that's really really nice to see

661
00:26:00,060 --> 00:26:03,159
[Music]

662
00:26:03,740 --> 00:26:06,960
for instance we are introducing all the

663
00:26:06,960 --> 00:26:08,400
threats from

664
00:26:08,400 --> 00:26:11,039
well not all the ones applicable to the

665
00:26:11,039 --> 00:26:12,600
risk assessment tool that they have all

666
00:26:12,600 --> 00:26:15,720
municipalities so that's also yeah a

667
00:26:15,720 --> 00:26:16,860
good step

668
00:26:16,860 --> 00:26:19,020
and it's recognized but um

669
00:26:19,020 --> 00:26:21,120
internationally by some authorities as

670
00:26:21,120 --> 00:26:24,179
one of the AI assessment tools so well I

671
00:26:24,179 --> 00:26:26,340
feel of course really proud of that of

672
00:26:26,340 --> 00:26:27,539
that

673
00:26:27,539 --> 00:26:29,600
and we are working towards a more

674
00:26:29,600 --> 00:26:32,880
automated version with eventually some

675
00:26:32,880 --> 00:26:35,460
kind of auditing tool

676
00:26:35,460 --> 00:26:37,380
and you're always looking for Pilots I

677
00:26:37,380 --> 00:26:38,820
have other companies that want to try it

678
00:26:38,820 --> 00:26:40,020
because we see that this international

679
00:26:40,020 --> 00:26:42,500
company is trying and we don't even know

680
00:26:42,500 --> 00:26:46,080
how they do so yeah it's always nice for

681
00:26:46,080 --> 00:26:48,360
for us to know

682
00:26:48,360 --> 00:26:50,720
and now we're gonna practice

683
00:26:50,720 --> 00:26:54,600
so what I would like is that um

684
00:26:54,600 --> 00:26:56,460
let's see because

685
00:26:56,460 --> 00:26:58,500
I don't have it yeah because we have now

686
00:26:58,500 --> 00:27:00,299
different computers I'm missing uh

687
00:27:00,299 --> 00:27:02,039
information but

688
00:27:02,039 --> 00:27:05,220
okay we have to use cases

689
00:27:05,220 --> 00:27:06,960
and I'm gonna give it to you so we are

690
00:27:06,960 --> 00:27:07,799
gonna

691
00:27:07,799 --> 00:27:11,658
um work on that design phase

692
00:27:11,760 --> 00:27:12,900
um

693
00:27:12,900 --> 00:27:16,740
in groups of let's see

694
00:27:16,740 --> 00:27:21,200
we are 12. let's do

695
00:27:21,900 --> 00:27:25,440
all two groups of six is also okay

696
00:27:25,440 --> 00:27:27,000
well if you don't feel more comfortable

697
00:27:27,000 --> 00:27:28,740
with three groups of four I I don't mind

698
00:27:28,740 --> 00:27:32,039
I'm gonna we're gonna work on a use case

699
00:27:32,039 --> 00:27:33,960
you're gonna get the information it's

700
00:27:33,960 --> 00:27:35,279
not too much because it's still a design

701
00:27:35,279 --> 00:27:38,039
phase you will see that in Facebook but

702
00:27:38,039 --> 00:27:40,559
in reality what we Face a lot with the

703
00:27:40,559 --> 00:27:43,559
AI especially comes the cool idea and

704
00:27:43,559 --> 00:27:45,840
the data science is already working on

705
00:27:45,840 --> 00:27:47,220
it and

706
00:27:47,220 --> 00:27:49,799
and then comes the session during the

707
00:27:49,799 --> 00:27:52,200
design phase and then you see oh my God

708
00:27:52,200 --> 00:27:54,900
so many things can go wrong yeah

709
00:27:54,900 --> 00:27:57,059
so I'm gonna give you some cards per

710
00:27:57,059 --> 00:27:57,840
group

711
00:27:57,840 --> 00:28:00,360
and also the spreadsheet that you can

712
00:28:00,360 --> 00:28:01,919
fill in

713
00:28:01,919 --> 00:28:03,539
so you're gonna discuss in the group

714
00:28:03,539 --> 00:28:05,520
based on the cards and the questions in

715
00:28:05,520 --> 00:28:07,679
the cards if it's a possible threat or

716
00:28:07,679 --> 00:28:08,700
not

717
00:28:08,700 --> 00:28:11,419
and then later

718
00:28:11,419 --> 00:28:15,059
then you can make some comments again or

719
00:28:15,059 --> 00:28:16,140
comment about the threats you have

720
00:28:16,140 --> 00:28:17,340
discovered

721
00:28:17,340 --> 00:28:19,080
so you see this is different than

722
00:28:19,080 --> 00:28:21,659
security threat modeling and we're more

723
00:28:21,659 --> 00:28:24,000
looking at the attack factors attack

724
00:28:24,000 --> 00:28:27,360
factors here you really have even

725
00:28:27,360 --> 00:28:28,980
questions related to ethics they do

726
00:28:28,980 --> 00:28:32,100
things that we need to think for and not

727
00:28:32,100 --> 00:28:34,799
just in knowledge or possibilities here

728
00:28:34,799 --> 00:28:36,900
you have to really think of impact for

729
00:28:36,900 --> 00:28:39,960
that have on other people so it all it

730
00:28:39,960 --> 00:28:41,880
requires

731
00:28:41,880 --> 00:28:45,120
or sometimes an effort so

732
00:28:45,120 --> 00:28:47,279
I hope you enjoy it it's gonna be

733
00:28:47,279 --> 00:28:49,559
probably something different

734
00:28:49,559 --> 00:28:53,400
so if you can sit in groups

735
00:28:53,400 --> 00:28:57,320
probably one you turn your chairs

736
00:29:02,000 --> 00:29:05,600
should be on the screen

737
00:29:05,700 --> 00:29:08,419
no problem

738
00:29:13,320 --> 00:29:16,520
no it's okay

739
00:29:20,300 --> 00:29:23,359
[Music]

740
00:29:32,179 --> 00:29:34,200
who are you I don't remember

741
00:29:34,200 --> 00:29:36,559
[Music]

742
00:29:36,559 --> 00:29:39,799
let's see

743
00:29:42,840 --> 00:29:45,840
okay

744
00:29:51,299 --> 00:29:53,159
scared I will explain you about the use

745
00:29:53,159 --> 00:29:56,880
case of course now you have to a I'm

746
00:29:56,880 --> 00:29:59,419
informed

747
00:30:00,419 --> 00:30:03,299
to be do you know to be I'm Gonna Give

748
00:30:03,299 --> 00:30:07,220
You 2D it's a bit more variation

749
00:30:08,340 --> 00:30:12,240
so you have I believe yeah ethics and

750
00:30:12,240 --> 00:30:16,260
human rights category and I'm gonna oh

751
00:30:16,260 --> 00:30:18,000
Father I'm gonna let you choose do you

752
00:30:18,000 --> 00:30:19,620
want to do also ethics and human rights

753
00:30:19,620 --> 00:30:23,640
or compliance or a mix of uh techniques

754
00:30:23,640 --> 00:30:26,120
accessibility

755
00:30:26,279 --> 00:30:28,260
I'm going to take compliance but I don't

756
00:30:28,260 --> 00:30:31,879
want the foil I can't foreign

757
00:30:57,779 --> 00:30:59,580
somebody has the feeling

758
00:30:59,580 --> 00:31:00,899
and I'm going to explain you know what

759
00:31:00,899 --> 00:31:03,120
you have to do

760
00:31:03,120 --> 00:31:06,979
you have a pen

761
00:31:09,779 --> 00:31:13,039
so you have a company

762
00:31:13,500 --> 00:31:17,840
your papa company called e-medical

763
00:31:19,919 --> 00:31:21,539
you listen

764
00:31:21,539 --> 00:31:25,200
to like a school hey so you have a

765
00:31:25,200 --> 00:31:27,299
company called imagica right so you are

766
00:31:27,299 --> 00:31:28,980
the the company you don't have in this

767
00:31:28,980 --> 00:31:30,179
case uh

768
00:31:30,179 --> 00:31:32,820
about owner telling you or a client

769
00:31:32,820 --> 00:31:34,679
telling you I want you to build this but

770
00:31:34,679 --> 00:31:36,600
it's your own ID because you know it

771
00:31:36,600 --> 00:31:38,880
really changed the perspective

772
00:31:38,880 --> 00:31:41,580
to to really look at risk so your

773
00:31:41,580 --> 00:31:43,440
company in medical wants to build an

774
00:31:43,440 --> 00:31:45,960
application that can identify risks to

775
00:31:45,960 --> 00:31:48,120
suffer certain diseases

776
00:31:48,120 --> 00:31:50,580
by analyzing Behavior so you can think

777
00:31:50,580 --> 00:31:53,039
in a wearable for instance

778
00:31:53,039 --> 00:31:55,559
that is going to collect different data

779
00:31:55,559 --> 00:31:57,539
you could even have different sensors to

780
00:31:57,539 --> 00:32:01,440
send to to to collect your movement and

781
00:32:01,440 --> 00:32:04,679
that will tell you things related to

782
00:32:04,679 --> 00:32:08,539
your behavior and about your health

783
00:32:08,640 --> 00:32:11,520
the benefits you see as company it's

784
00:32:11,520 --> 00:32:13,380
like the people could take preventing

785
00:32:13,380 --> 00:32:15,960
actions to avoid getting sick

786
00:32:15,960 --> 00:32:18,360
and doctors could be informed of the

787
00:32:18,360 --> 00:32:20,940
risks of their patients what could help

788
00:32:20,940 --> 00:32:23,580
them to apply the right treatment

789
00:32:23,580 --> 00:32:26,760
and so the year you already have some

790
00:32:26,760 --> 00:32:30,419
some hints about well it's not only

791
00:32:30,419 --> 00:32:33,659
probably the user but you already have

792
00:32:33,659 --> 00:32:36,240
other parties are not gonna get that

793
00:32:36,240 --> 00:32:39,720
data like the doctors

794
00:32:39,720 --> 00:32:43,140
now there's some rule playing here uh I

795
00:32:43,140 --> 00:32:45,419
don't know for the interest of Time how

796
00:32:45,419 --> 00:32:47,960
long we have

797
00:32:49,880 --> 00:32:52,080
425 minutes

798
00:32:52,080 --> 00:32:54,179
no I think was we have one and a half

799
00:32:54,179 --> 00:32:55,799
hours right

800
00:32:55,799 --> 00:32:58,380
oh then we have time well

801
00:32:58,380 --> 00:33:00,960
um I might say when uh

802
00:33:00,960 --> 00:33:03,179
when I do a worship about the plot for

803
00:33:03,179 --> 00:33:05,460
AI and of course in real life we'll have

804
00:33:05,460 --> 00:33:07,559
our different functions we have the

805
00:33:07,559 --> 00:33:09,720
privacy officer the security engineer

806
00:33:09,720 --> 00:33:12,779
who is in the team the scientist

807
00:33:12,779 --> 00:33:15,179
but I when I Do Worship friends with

808
00:33:15,179 --> 00:33:16,860
students and we go about the role

809
00:33:16,860 --> 00:33:18,659
playing and it's for you more to

810
00:33:18,659 --> 00:33:20,880
understand being in this role

811
00:33:20,880 --> 00:33:22,799
I would probably have a different

812
00:33:22,799 --> 00:33:24,419
opinion when it comes to the question is

813
00:33:24,419 --> 00:33:25,919
this a threat or not

814
00:33:25,919 --> 00:33:27,779
and what makes it more complex in real

815
00:33:27,779 --> 00:33:28,980
life

816
00:33:28,980 --> 00:33:31,380
now I give you the opportunity to take a

817
00:33:31,380 --> 00:33:33,720
different but today to really be a

818
00:33:33,720 --> 00:33:35,279
different person

819
00:33:35,279 --> 00:33:37,080
and choose about one of the roles here

820
00:33:37,080 --> 00:33:39,059
but in my experience I must say it

821
00:33:39,059 --> 00:33:40,260
really takes five minutes you go back

822
00:33:40,260 --> 00:33:42,299
always to yourself

823
00:33:42,299 --> 00:33:44,940
can work very well unless we are really

824
00:33:44,940 --> 00:33:46,440
a strict saying this is a role play game

825
00:33:46,440 --> 00:33:47,940
but today is not really a role play game

826
00:33:47,940 --> 00:33:50,700
so just oh yeah to add more fun to the

827
00:33:50,700 --> 00:33:52,980
game you can just decide to be somebody

828
00:33:52,980 --> 00:33:56,399
different in the team you don't have to

829
00:33:56,399 --> 00:33:59,399
so what you will do is you go through

830
00:33:59,399 --> 00:34:03,179
the questions you ask the question

831
00:34:03,179 --> 00:34:05,580
and you answer to it so all of you have

832
00:34:05,580 --> 00:34:07,200
answered to it

833
00:34:07,200 --> 00:34:09,239
and we have time today so you have more

834
00:34:09,239 --> 00:34:11,219
time to reflect on the answer

835
00:34:11,219 --> 00:34:12,980
in real life

836
00:34:12,980 --> 00:34:16,679
when I'm coordinating the sessions I

837
00:34:16,679 --> 00:34:18,300
like to do it really quick

838
00:34:18,300 --> 00:34:20,879
so I time box really the sessions I just

839
00:34:20,879 --> 00:34:23,219
want to see yes no or even a face of

840
00:34:23,219 --> 00:34:26,460
panic then I immediately mark it as a

841
00:34:26,460 --> 00:34:27,359
threat

842
00:34:27,359 --> 00:34:29,399
because you see a lot of the product

843
00:34:29,399 --> 00:34:31,139
owners want to of course they want their

844
00:34:31,139 --> 00:34:33,480
product the data scientists want another

845
00:34:33,480 --> 00:34:35,580
thing and you don't want discussions

846
00:34:35,580 --> 00:34:37,739
because then it becomes a risk session

847
00:34:37,739 --> 00:34:40,020
that we are always discussing and we

848
00:34:40,020 --> 00:34:42,599
don't Rich consensus this is just to

849
00:34:42,599 --> 00:34:44,460
identify this could be a problem yes or

850
00:34:44,460 --> 00:34:46,679
not quick so the more threat we go

851
00:34:46,679 --> 00:34:49,859
through better so you can be really

852
00:34:49,859 --> 00:34:51,839
strict really at time boxed really

853
00:34:51,839 --> 00:34:54,119
quickly like one means per per answer if

854
00:34:54,119 --> 00:34:56,940
you want but today we are not going to

855
00:34:56,940 --> 00:34:58,080
be so strict

856
00:34:58,080 --> 00:34:59,339
so you can really go through the

857
00:34:59,339 --> 00:35:01,080
questions and

858
00:35:01,080 --> 00:35:03,300
yeah decide about them especially

859
00:35:03,300 --> 00:35:06,119
because you both have ethics and often

860
00:35:06,119 --> 00:35:08,640
that brings more um

861
00:35:08,640 --> 00:35:10,619
well yeah type for reflection you need

862
00:35:10,619 --> 00:35:12,720
more time to give answer to this type of

863
00:35:12,720 --> 00:35:14,460
questions

864
00:35:14,460 --> 00:35:18,300
and once you give answer to a question

865
00:35:18,300 --> 00:35:21,180
um you just mark it in the in the paper

866
00:35:21,180 --> 00:35:22,560
I gave you

867
00:35:22,560 --> 00:35:24,540
yeah and then later we're gonna discuss

868
00:35:24,540 --> 00:35:27,180
about the threats you have identified

869
00:35:27,180 --> 00:35:30,359
and even if you think in Solutions so

870
00:35:30,359 --> 00:35:34,140
actions how to solve it better so let's

871
00:35:34,140 --> 00:35:37,260
see later so yeah enjoy the game how you

872
00:35:37,260 --> 00:35:39,560
can start

873
00:36:18,800 --> 00:36:23,060
if you want to talk about more practices

874
00:36:53,280 --> 00:36:55,820
from

875
00:37:00,180 --> 00:37:02,220
I will give one to everyone so you can

876
00:37:02,220 --> 00:37:04,939
see the website

877
00:37:08,339 --> 00:37:10,440
I'm giving you all a car because here is

878
00:37:10,440 --> 00:37:14,900
the website so you can have a look too

879
00:37:17,099 --> 00:37:19,460
yeah

880
00:37:20,540 --> 00:37:23,460
no I think he wanted

881
00:37:23,460 --> 00:37:25,579
okay

882
00:37:38,220 --> 00:37:42,060
the website complete is there so you can

883
00:37:42,060 --> 00:37:44,720
example

884
00:37:48,440 --> 00:37:51,300
now you're completely right

885
00:37:51,300 --> 00:37:54,300
I also said that to my children

886
00:37:54,300 --> 00:37:56,280
that's why I make pictures after I

887
00:37:56,280 --> 00:37:59,240
written after one day

888
00:38:28,440 --> 00:38:29,599
thank you

889
00:38:29,599 --> 00:38:32,839
very much

890
00:39:35,700 --> 00:39:38,099
oh look here it is

891
00:39:38,099 --> 00:39:40,500
is it everything inside

892
00:39:40,500 --> 00:39:42,500
um

893
00:39:50,640 --> 00:39:52,500
then let me keep everything in my bag

894
00:39:52,500 --> 00:39:54,800
because

895
00:40:13,680 --> 00:40:16,740
yeah what

896
00:40:16,740 --> 00:40:20,479
no say again absolutely

897
00:40:45,359 --> 00:40:48,060
always like them so wonderful so nice

898
00:40:48,060 --> 00:40:50,599
see

899
00:41:18,660 --> 00:41:22,279
nice pictures like this

900
00:41:25,320 --> 00:41:27,500
thank you

901
00:41:29,099 --> 00:41:32,240
have nothing to drink

902
00:41:36,720 --> 00:41:39,000
where was this

903
00:41:39,000 --> 00:41:41,540
oh

904
00:42:17,940 --> 00:42:21,320
we'll put that again

905
00:42:40,680 --> 00:42:43,680
foreign

906
00:42:55,920 --> 00:42:58,640
downtown

907
00:43:07,859 --> 00:43:09,859
um

908
00:43:30,420 --> 00:43:33,420
foreign

909
00:44:14,000 --> 00:44:17,359
this kind of

910
00:44:26,819 --> 00:44:29,839
is it going on

911
00:44:32,700 --> 00:44:35,460
yeah

912
00:44:35,460 --> 00:44:38,940
it's okay I'm Gonna Give You grades for

913
00:44:38,940 --> 00:44:41,900
the writing or anything

914
00:44:57,420 --> 00:44:59,960
foreign

915
00:45:56,940 --> 00:46:00,260
under his laughter

916
00:46:03,599 --> 00:46:06,359
yeah

917
00:46:06,359 --> 00:46:09,920
it's a privacy

918
00:46:14,940 --> 00:46:16,040
yeah yeah

919
00:46:16,040 --> 00:46:21,680
they got the holy compliance so this is

920
00:46:33,119 --> 00:46:36,119
uh

921
00:46:43,020 --> 00:46:45,500
oh yeah uh

922
00:46:45,500 --> 00:46:49,579
stand for the Privacy officers

923
00:46:51,980 --> 00:46:55,460
in the discussion

924
00:46:55,940 --> 00:46:59,119
this is

925
00:46:59,880 --> 00:47:02,880
foreign

926
00:47:33,060 --> 00:47:35,359
foreign

927
00:48:03,599 --> 00:48:06,599
foreign

928
00:48:27,660 --> 00:48:29,339
development

929
00:48:29,339 --> 00:48:32,339
foreign

930
00:48:53,900 --> 00:48:56,099
that is a

931
00:48:56,099 --> 00:49:00,180
the Sofia come welcome

932
00:49:02,880 --> 00:49:05,300
in

933
00:49:08,640 --> 00:49:11,640
foreign

934
00:49:40,619 --> 00:49:43,619
foreign

935
00:50:11,760 --> 00:50:14,300
now

936
00:50:39,359 --> 00:50:43,220
I can give them more cards but

937
00:50:51,119 --> 00:50:52,380
I think

938
00:50:52,380 --> 00:50:53,940
she started talking to different people

939
00:50:53,940 --> 00:50:58,079
maybe like 10-15 parts

940
00:50:58,079 --> 00:51:00,300
no that is why but there's still 10

941
00:51:00,300 --> 00:51:02,480
minutes

942
00:51:04,740 --> 00:51:07,459
to then

943
00:51:08,579 --> 00:51:10,740
I can give this to other groups they

944
00:51:10,740 --> 00:51:12,919
want

945
00:51:28,500 --> 00:51:31,760
the person you leave

946
00:51:45,800 --> 00:51:48,920
the garden

947
00:51:59,520 --> 00:52:02,520
foreign

948
00:52:29,460 --> 00:52:32,000
no

949
00:52:40,140 --> 00:52:42,740
hello hello

950
00:52:42,900 --> 00:52:45,559
yeah

951
00:52:48,960 --> 00:52:50,700
um

952
00:52:50,700 --> 00:52:53,180
yeah

953
00:52:58,200 --> 00:53:00,200
um

954
00:53:06,599 --> 00:53:09,599
foreign

955
00:53:47,220 --> 00:53:50,779
yeah that's how you go yeah

956
00:54:04,579 --> 00:54:08,359
but the transcription

957
00:54:42,720 --> 00:54:44,720
um

958
00:54:48,599 --> 00:54:51,599
okay

959
00:55:13,859 --> 00:55:15,859
um

960
00:55:18,440 --> 00:55:22,460
on the running yeah

961
00:55:26,460 --> 00:55:29,460
foreign

962
00:55:55,980 --> 00:55:59,420
yeah you see the guys

963
00:56:29,000 --> 00:56:32,059
thank you

964
00:56:32,900 --> 00:56:37,700
very much it is

965
00:57:08,839 --> 00:57:12,380
from the UK

966
00:57:13,400 --> 00:57:16,520
it is

967
00:57:21,059 --> 00:57:24,079
I think they have finished

968
00:57:24,900 --> 00:57:28,700
yeah yeah this is

969
00:57:43,619 --> 00:57:46,619
foreign

970
00:58:16,980 --> 00:58:19,980
foreign

971
00:58:38,220 --> 00:58:42,059
should we share our findings

972
00:58:42,059 --> 00:58:43,980
maybe it's nice to share what did you

973
00:58:43,980 --> 00:58:46,280
find

974
00:58:48,359 --> 00:58:53,000
if you're there one living

975
00:58:55,140 --> 00:58:58,140
here

976
00:59:00,720 --> 00:59:03,540
are we are you guys ready to share your

977
00:59:03,540 --> 00:59:04,619
findings

978
00:59:04,619 --> 00:59:06,859
yeah

979
00:59:08,299 --> 00:59:11,460
okay why I think you can oh yeah you can

980
00:59:11,460 --> 00:59:15,900
just yeah yeah that's fine

981
00:59:15,900 --> 00:59:18,180
so

982
00:59:18,180 --> 00:59:21,599
are you prepared to share

983
00:59:21,599 --> 00:59:24,420
what did you find of uh how many threads

984
00:59:24,420 --> 00:59:27,240
did you find from your sets

985
00:59:27,240 --> 00:59:30,200
who wants to start

986
00:59:30,440 --> 00:59:35,940
so you even classified wow very good

987
00:59:35,940 --> 00:59:38,220
so everything was a threat

988
00:59:38,220 --> 00:59:40,559
according to you

989
00:59:40,559 --> 00:59:42,920
so

990
00:59:44,339 --> 00:59:47,599
yeah number one is

991
00:59:47,599 --> 00:59:50,940
Society at large we have high risk for

992
00:59:50,940 --> 00:59:52,740
several reasons first of all it's very

993
00:59:52,740 --> 00:59:55,440
easy to ask specific ways to these

994
00:59:55,440 --> 00:59:56,940
models to get straight out of specific

995
00:59:56,940 --> 00:59:58,280
personal people

996
00:59:58,280 --> 01:00:01,280
also it will be used for insurance

997
01:00:01,280 --> 01:00:02,900
adjustments

998
01:00:02,900 --> 01:00:06,480
or whether you do hire or don't hire

999
01:00:06,480 --> 01:00:08,819
someone based on real so yeah that one

1000
01:00:08,819 --> 01:00:11,180
at High

1001
01:00:12,680 --> 01:00:15,720
impact on decisions regarding the rights

1002
01:00:15,720 --> 01:00:17,520
of life we also had on height

1003
01:00:17,520 --> 01:00:20,460
because there's so many uh

1004
01:00:20,460 --> 01:00:23,099
things that for example if you're old uh

1005
01:00:23,099 --> 01:00:24,780
do you do you do you not give medicine

1006
01:00:24,780 --> 01:00:26,700
to someone it's already old that's very

1007
01:00:26,700 --> 01:00:29,160
expensive or an operation

1008
01:00:29,160 --> 01:00:31,079
yeah but also the output could not be

1009
01:00:31,079 --> 01:00:32,640
correct and if that goes to the doctor

1010
01:00:32,640 --> 01:00:34,500
and he has to take a decision about your

1011
01:00:34,500 --> 01:00:37,319
treatment so but still you will have the

1012
01:00:37,319 --> 01:00:40,360
human oversight there but yeah

1013
01:00:40,360 --> 01:00:41,400
[Music]

1014
01:00:41,400 --> 01:00:43,740
also keep in mind that doctors will use

1015
01:00:43,740 --> 01:00:44,940
the system

1016
01:00:44,940 --> 01:00:47,760
as an excuse to make your decision

1017
01:00:47,760 --> 01:00:51,900
like as in you you can't expect the

1018
01:00:51,900 --> 01:00:54,180
doctor to be the final

1019
01:00:54,180 --> 01:00:56,940
well take a look at the eye

1020
01:00:56,940 --> 01:00:59,760
make a decision but it's also sometimes

1021
01:00:59,760 --> 01:01:01,500
to leave the other way around like they

1022
01:01:01,500 --> 01:01:03,599
have an AI that just tells a random

1023
01:01:03,599 --> 01:01:05,819
thing and the doctor looks at it well I

1024
01:01:05,819 --> 01:01:07,740
I told me to do that whatever let's do

1025
01:01:07,740 --> 01:01:11,280
that so you are you are challenging uh

1026
01:01:11,280 --> 01:01:15,299
yeah one way or the other at the end

1027
01:01:15,299 --> 01:01:18,540
every profession across any field if if

1028
01:01:18,540 --> 01:01:21,240
they can remove responsibility from them

1029
01:01:21,240 --> 01:01:23,040
and give it to some machine like AI it

1030
01:01:23,040 --> 01:01:24,119
will do it

1031
01:01:24,119 --> 01:01:26,280
yeah so you're challenging one with a

1032
01:01:26,280 --> 01:01:28,559
liability yeah it's already a really big

1033
01:01:28,559 --> 01:01:31,200
issue in Ai and uh well there's no

1034
01:01:31,200 --> 01:01:33,359
directives regulations being built our

1035
01:01:33,359 --> 01:01:35,579
new white paper the European commission

1036
01:01:35,579 --> 01:01:38,660
is working on creating some liability

1037
01:01:38,660 --> 01:01:40,980
directly for

1038
01:01:40,980 --> 01:01:44,220
for you for Europe

1039
01:01:44,220 --> 01:01:45,000
um

1040
01:01:45,000 --> 01:01:46,920
and you're also challenging I had a kind

1041
01:01:46,920 --> 01:01:50,040
of the automation bias of the that is

1042
01:01:50,040 --> 01:01:51,720
what we call one of the decisions if the

1043
01:01:51,720 --> 01:01:54,059
decisions made by the the in this case

1044
01:01:54,059 --> 01:01:55,859
by the doctors are really

1045
01:01:55,859 --> 01:01:57,720
well yeah

1046
01:01:57,720 --> 01:02:01,619
neutral and you're Fair

1047
01:02:01,619 --> 01:02:03,660
giving an ability to ignore the case and

1048
01:02:03,660 --> 01:02:05,339
just take AI for an answer

1049
01:02:05,339 --> 01:02:07,619
yeah so you will then you will that case

1050
01:02:07,619 --> 01:02:09,540
could have some kind of

1051
01:02:09,540 --> 01:02:12,359
issue of bias in different stages that

1052
01:02:12,359 --> 01:02:14,520
you will need to tackle from the the way

1053
01:02:14,520 --> 01:02:16,319
you the leads that you are input into

1054
01:02:16,319 --> 01:02:19,140
the model into the output eyes use how

1055
01:02:19,140 --> 01:02:20,579
is that person trained so you have

1056
01:02:20,579 --> 01:02:23,640
really a lot of things there to which

1057
01:02:23,640 --> 01:02:25,980
so if you ask the question a little bit

1058
01:02:25,980 --> 01:02:27,540
differently I'm going to get an answer

1059
01:02:27,540 --> 01:02:29,119
which might as well

1060
01:02:29,119 --> 01:02:31,680
what should be the pre-deposition so far

1061
01:02:31,680 --> 01:02:33,359
yeah that's a really good point because

1062
01:02:33,359 --> 01:02:35,160
in fact there's one thread this I always

1063
01:02:35,160 --> 01:02:36,420
say that's the first one you should do

1064
01:02:36,420 --> 01:02:38,280
in the game always but it's from the

1065
01:02:38,280 --> 01:02:39,960
category technique so you didn't see it

1066
01:02:39,960 --> 01:02:43,140
today it's uh is the task clear

1067
01:02:43,140 --> 01:02:44,760
okay so one of the things we face really

1068
01:02:44,760 --> 01:02:46,260
often well also in software development

1069
01:02:46,260 --> 01:02:50,099
but especially in in AI is that there's

1070
01:02:50,099 --> 01:02:52,380
a lot of everybody is fascinating of the

1071
01:02:52,380 --> 01:02:54,420
power and then you see the business

1072
01:02:54,420 --> 01:02:56,280
thinking well maybe we could also do

1073
01:02:56,280 --> 01:02:58,380
this we could also do that

1074
01:02:58,380 --> 01:03:00,839
yeah eventually it's just maths and you

1075
01:03:00,839 --> 01:03:02,460
have to put it you have to have really

1076
01:03:02,460 --> 01:03:04,680
clear what type of maths and algorithm

1077
01:03:04,680 --> 01:03:06,299
you're gonna use to what type of recipe

1078
01:03:06,299 --> 01:03:09,480
you have for to get the the cake you

1079
01:03:09,480 --> 01:03:11,700
want to eat to put it like that so it's

1080
01:03:11,700 --> 01:03:13,680
really important that the the really the

1081
01:03:13,680 --> 01:03:16,200
the success factor to Define what we

1082
01:03:16,200 --> 01:03:17,520
really need

1083
01:03:17,520 --> 01:03:19,559
um what you really want to achieve

1084
01:03:19,559 --> 01:03:21,359
that's something in practice it's really

1085
01:03:21,359 --> 01:03:25,339
whereas in practice is difficult

1086
01:03:25,380 --> 01:03:28,380
medium

1087
01:03:29,700 --> 01:03:32,460
because uh there are some risks but also

1088
01:03:32,460 --> 01:03:34,200
it's not fair they're no different from

1089
01:03:34,200 --> 01:03:36,420
another human but there might be some

1090
01:03:36,420 --> 01:03:38,460
decisions that come out of the AI that

1091
01:03:38,460 --> 01:03:40,740
might have more impacts on children like

1092
01:03:40,740 --> 01:03:42,839
a very heavy mission that might impact

1093
01:03:42,839 --> 01:03:46,619
their adulthood or some decisions that

1094
01:03:46,619 --> 01:03:48,900
where a doctor could have the empathy to

1095
01:03:48,900 --> 01:03:51,000
make a decision based on also the

1096
01:03:51,000 --> 01:03:54,000
empathy and the state of a child and I

1097
01:03:54,000 --> 01:03:55,799
AI will not will just treat it like a

1098
01:03:55,799 --> 01:03:57,180
normal uh

1099
01:03:57,180 --> 01:03:59,640
yeah in fact the question is something I

1100
01:03:59,640 --> 01:04:01,700
decided to add base to my experience

1101
01:04:01,700 --> 01:04:05,099
this thread so this is not one of all my

1102
01:04:05,099 --> 01:04:07,559
Collections and

1103
01:04:07,559 --> 01:04:10,500
the fact of it thinking if what I'm

1104
01:04:10,500 --> 01:04:12,000
building it's going to be used by

1105
01:04:12,000 --> 01:04:14,160
children one way the other it can have

1106
01:04:14,160 --> 01:04:15,660
enormous implications of the whole

1107
01:04:15,660 --> 01:04:17,940
development even from having to to give

1108
01:04:17,940 --> 01:04:19,920
up proper information to make it

1109
01:04:19,920 --> 01:04:21,839
accessible in a different way

1110
01:04:21,839 --> 01:04:24,599
comply with different rules in a way

1111
01:04:24,599 --> 01:04:25,920
that the children can still develop

1112
01:04:25,920 --> 01:04:27,839
themselves or maybe even participate in

1113
01:04:27,839 --> 01:04:30,180
the development that's just in terms of

1114
01:04:30,180 --> 01:04:32,220
compliance or some things you need to

1115
01:04:32,220 --> 01:04:35,720
comply with and in fact this um

1116
01:04:35,720 --> 01:04:38,339
a couple of days ago there was a product

1117
01:04:38,339 --> 01:04:40,799
from a company called replica that has

1118
01:04:40,799 --> 01:04:44,160
been banned in Italy so there was a I

1119
01:04:44,160 --> 01:04:46,740
believe it was a chatbot and was giving

1120
01:04:46,740 --> 01:04:50,339
a I think like emotional therapy so you

1121
01:04:50,339 --> 01:04:52,680
get to talk to him or I don't know where

1122
01:04:52,680 --> 01:04:55,500
it is and and show you um give you some

1123
01:04:55,500 --> 01:04:57,960
kind of uh fort

1124
01:04:57,960 --> 01:05:00,900
but this company had never

1125
01:05:00,900 --> 01:05:01,559
um

1126
01:05:01,559 --> 01:05:03,119
saw that it could be used also by

1127
01:05:03,119 --> 01:05:04,020
children

1128
01:05:04,020 --> 01:05:06,839
and the data privacy Authority from

1129
01:05:06,839 --> 01:05:09,599
Italy did some run some tests on this

1130
01:05:09,599 --> 01:05:12,180
chatbot and they saw that yeah it was

1131
01:05:12,180 --> 01:05:14,099
really not meant for children and even

1132
01:05:14,099 --> 01:05:16,619
sometimes you got feedback that was well

1133
01:05:16,619 --> 01:05:19,680
not from the proper language for a child

1134
01:05:19,680 --> 01:05:21,599
so I said but you have not done your due

1135
01:05:21,599 --> 01:05:24,059
diligence here so we really bought the

1136
01:05:24,059 --> 01:05:25,980
tool here and you have I believe 20 days

1137
01:05:25,980 --> 01:05:27,960
to delete all data from my Italian

1138
01:05:27,960 --> 01:05:30,960
citizens and to work on the on a proper

1139
01:05:30,960 --> 01:05:32,640
solution so come back once you have done

1140
01:05:32,640 --> 01:05:33,780
your work

1141
01:05:33,780 --> 01:05:35,400
so as you see if you see a threat like

1142
01:05:35,400 --> 01:05:37,079
this when you are in the development

1143
01:05:37,079 --> 01:05:39,240
life cycle in the design phase it's

1144
01:05:39,240 --> 01:05:40,319
already

1145
01:05:40,319 --> 01:05:42,180
you can put you a step back and say well

1146
01:05:42,180 --> 01:05:45,000
let's go to the room table and think

1147
01:05:45,000 --> 01:05:46,859
again how we're gonna do this

1148
01:05:46,859 --> 01:05:48,660
just not having it in account could

1149
01:05:48,660 --> 01:05:49,500
really

1150
01:05:49,500 --> 01:05:51,660
kill the whole project like we see

1151
01:05:51,660 --> 01:05:54,540
nowadays mrmo multiple characters with

1152
01:05:54,540 --> 01:05:56,460
decision based like if we decide our

1153
01:05:56,460 --> 01:05:58,020
product to be for children we have to

1154
01:05:58,020 --> 01:06:00,359
train your children we just have to give

1155
01:06:00,359 --> 01:06:02,700
them above yeah the nice of having the

1156
01:06:02,700 --> 01:06:04,559
thread there for you is that it makes

1157
01:06:04,559 --> 01:06:07,140
you realize okay it's not gonna be for

1158
01:06:07,140 --> 01:06:08,819
children so let's act on that and

1159
01:06:08,819 --> 01:06:10,559
document that is not fulfilling but we

1160
01:06:10,559 --> 01:06:12,299
also take measures to our children is

1161
01:06:12,299 --> 01:06:14,579
going to use it to avoid risks for them

1162
01:06:14,579 --> 01:06:17,579
so you are conscious of a risk and you

1163
01:06:17,579 --> 01:06:19,200
take some mitigation measures what

1164
01:06:19,200 --> 01:06:20,280
already put you in a much better

1165
01:06:20,280 --> 01:06:22,559
position if something happens that of

1166
01:06:22,559 --> 01:06:25,039
course risk you know you cannot 100

1167
01:06:25,039 --> 01:06:29,480
be covered for all risks so

1168
01:06:29,520 --> 01:06:32,520
uh

1169
01:06:39,740 --> 01:06:42,599
whether we have no medium because I mean

1170
01:06:42,599 --> 01:06:43,740
there's not really anything without

1171
01:06:43,740 --> 01:06:46,680
ambiguity about except for mathematics

1172
01:06:46,680 --> 01:06:49,799
so you always have to risk uh that the

1173
01:06:49,799 --> 01:06:53,220
output will be at the ambiguous

1174
01:06:53,220 --> 01:06:54,839
and what is the question again what was

1175
01:06:54,839 --> 01:06:57,259
the threat

1176
01:07:00,119 --> 01:07:01,680
okay

1177
01:07:01,680 --> 01:07:05,538
I don't know why we put it on medium

1178
01:07:06,480 --> 01:07:08,099
yeah and you need to realize when you

1179
01:07:08,099 --> 01:07:09,359
have these type of questions from the

1180
01:07:09,359 --> 01:07:11,640
ethical part you also need to check the

1181
01:07:11,640 --> 01:07:14,099
technical part yeah yeah so you want to

1182
01:07:14,099 --> 01:07:16,740
be fair you have to be representative

1183
01:07:16,740 --> 01:07:18,839
and you need to realize in which context

1184
01:07:18,839 --> 01:07:20,420
you are releasing certain applications

1185
01:07:20,420 --> 01:07:23,160
so come with the idea of let's just

1186
01:07:23,160 --> 01:07:24,900
build something that everybody could use

1187
01:07:24,900 --> 01:07:28,200
or maybe that is not the case and that

1188
01:07:28,200 --> 01:07:29,760
affects you all your product even to the

1189
01:07:29,760 --> 01:07:32,039
price and you so it's not only in the

1190
01:07:32,039 --> 01:07:34,380
development life cycle but but it's good

1191
01:07:34,380 --> 01:07:36,480
to think especially with AI

1192
01:07:36,480 --> 01:07:38,700
we also see that there we develop based

1193
01:07:38,700 --> 01:07:41,400
on our data that we have often yes open

1194
01:07:41,400 --> 01:07:43,319
data that is available somewhere

1195
01:07:43,319 --> 01:07:44,880
and when we want to put that into

1196
01:07:44,880 --> 01:07:48,000
production it's not working so you need

1197
01:07:48,000 --> 01:07:49,559
to keep monitoring validating your model

1198
01:07:49,559 --> 01:07:51,180
you need to and that's something that

1199
01:07:51,180 --> 01:07:53,520
even in practice in my experience is not

1200
01:07:53,520 --> 01:07:55,700
done

1201
01:07:56,099 --> 01:07:58,980
10 minutes left so maybe

1202
01:07:58,980 --> 01:08:00,539
but I think

1203
01:08:00,539 --> 01:08:03,480
right

1204
01:08:03,480 --> 01:08:05,460
yeah so quickly

1205
01:08:05,460 --> 01:08:07,460
um

1206
01:08:07,550 --> 01:08:09,319
[Music]

1207
01:08:09,319 --> 01:08:11,400
professionals to make this asset anyway

1208
01:08:11,400 --> 01:08:13,819
so there's no uh

1209
01:08:13,819 --> 01:08:17,279
yeah this is about labeling data right

1210
01:08:17,279 --> 01:08:19,859
yeah there's a threat

1211
01:08:19,859 --> 01:08:22,799
uh yeah asking if the the data that you

1212
01:08:22,799 --> 01:08:24,779
are using in case you use a supervised

1213
01:08:24,779 --> 01:08:27,060
model with the label data of course you

1214
01:08:27,060 --> 01:08:29,100
could use other type of uh technology

1215
01:08:29,100 --> 01:08:31,560
but in that case

1216
01:08:31,560 --> 01:08:33,920
um what we see now the trend is a lot of

1217
01:08:33,920 --> 01:08:36,080
countries especially in

1218
01:08:36,080 --> 01:08:38,640
undeveloped countries where they have

1219
01:08:38,640 --> 01:08:40,679
really a really big Workforce working on

1220
01:08:40,679 --> 01:08:43,500
labeling data underpaid on the really

1221
01:08:43,500 --> 01:08:44,880
bad conditions

1222
01:08:44,880 --> 01:08:46,920
and that is something that yeah for my

1223
01:08:46,920 --> 01:08:49,500
human rights perspective we try to also

1224
01:08:49,500 --> 01:08:51,540
put there on the spotlight like this is

1225
01:08:51,540 --> 01:08:53,399
happening so really good we need level

1226
01:08:53,399 --> 01:08:55,799
data but a couple years and then they're

1227
01:08:55,799 --> 01:08:59,759
automated the way so oh wow but it's for

1228
01:08:59,759 --> 01:09:02,698
U.S organization to say to decide do I

1229
01:09:02,698 --> 01:09:05,640
want to participate in that or or not do

1230
01:09:05,640 --> 01:09:07,799
I want to but it's more as organization

1231
01:09:07,799 --> 01:09:09,238
your own reputation you're on the way

1232
01:09:09,238 --> 01:09:11,580
you see yourself uh that could also be a

1233
01:09:11,580 --> 01:09:15,979
threat and the last one where I

1234
01:09:18,590 --> 01:09:21,659
[Music]

1235
01:09:22,560 --> 01:09:23,299
uh

1236
01:09:23,299 --> 01:09:25,560
like this it's almost impossible to

1237
01:09:25,560 --> 01:09:28,100
remove them

1238
01:09:28,219 --> 01:09:30,979
yeah and in this case it is something

1239
01:09:30,979 --> 01:09:34,560
that you might try to prevent during the

1240
01:09:34,560 --> 01:09:36,620
the first phases of development

1241
01:09:36,620 --> 01:09:39,660
you try to to clear your bias in your

1242
01:09:39,660 --> 01:09:41,040
models you try to represent all

1243
01:09:41,040 --> 01:09:42,719
populations that you think should be

1244
01:09:42,719 --> 01:09:43,920
represented

1245
01:09:43,920 --> 01:09:47,100
and still it could happen that with the

1246
01:09:47,100 --> 01:09:49,380
output you see that other groups appear

1247
01:09:49,380 --> 01:09:50,880
so you have to keep monitoring

1248
01:09:50,880 --> 01:09:54,179
monitoring and doing the bias tests and

1249
01:09:54,179 --> 01:09:55,800
other type of metrics

1250
01:09:55,800 --> 01:09:58,679
to see in that case that's actually more

1251
01:09:58,679 --> 01:10:00,780
of a goal of a project we want to

1252
01:10:00,780 --> 01:10:02,880
identify and categorize people like this

1253
01:10:02,880 --> 01:10:05,580
person will die more of this person what

1254
01:10:05,580 --> 01:10:08,460
about why people yeah but um

1255
01:10:08,460 --> 01:10:11,580
well no I mean that yeah but look that

1256
01:10:11,580 --> 01:10:12,900
is already related to the question what

1257
01:10:12,900 --> 01:10:14,100
is your task

1258
01:10:14,100 --> 01:10:17,400
is your task really create categories of

1259
01:10:17,400 --> 01:10:19,080
[Music]

1260
01:10:19,080 --> 01:10:21,960
health status to put it like that or is

1261
01:10:21,960 --> 01:10:23,580
your task yes

1262
01:10:23,580 --> 01:10:26,280
to give a sign when something could go

1263
01:10:26,280 --> 01:10:29,159
wrong with yourself so that you can take

1264
01:10:29,159 --> 01:10:32,900
because it's not the same yeah

1265
01:10:35,460 --> 01:10:37,739
you could and and then it is up to you

1266
01:10:37,739 --> 01:10:39,840
decide why we are not gonna do that so

1267
01:10:39,840 --> 01:10:41,040
we are not gonna have a different

1268
01:10:41,040 --> 01:10:42,360
purpose

1269
01:10:42,360 --> 01:10:44,100
okay but that's why the task is really

1270
01:10:44,100 --> 01:10:45,659
important we said what do we really want

1271
01:10:45,659 --> 01:10:46,739
to do now

1272
01:10:46,739 --> 01:10:48,540
and later that of course you can do

1273
01:10:48,540 --> 01:10:50,820
different analysis yes but then it's a

1274
01:10:50,820 --> 01:10:52,199
different purpose

1275
01:10:52,199 --> 01:10:54,559
so

1276
01:10:58,500 --> 01:10:59,699
we just want to see it doesn't want to

1277
01:10:59,699 --> 01:11:01,920
have breast cancer or not you might also

1278
01:11:01,920 --> 01:11:04,860
exactly uh sort of name the people as a

1279
01:11:04,860 --> 01:11:07,800
high risk of yeah absolutely your output

1280
01:11:07,800 --> 01:11:09,960
could be wrong in that sense

1281
01:11:09,960 --> 01:11:11,280
very good

1282
01:11:11,280 --> 01:11:12,600
thank you

1283
01:11:12,600 --> 01:11:15,420
Now we move to the next group

1284
01:11:15,420 --> 01:11:18,199
who wants to

1285
01:11:18,600 --> 01:11:21,540
um yeah we just marked everything as a

1286
01:11:21,540 --> 01:11:23,880
Potential Threat we were mostly

1287
01:11:23,880 --> 01:11:25,679
discussing about how to interpret the

1288
01:11:25,679 --> 01:11:29,280
question and how many kind of ways we

1289
01:11:29,280 --> 01:11:31,860
could think of the threatswood

1290
01:11:31,860 --> 01:11:35,159
uh-huh become reality so the first one

1291
01:11:35,159 --> 01:11:37,920
bias and discrimination could be groups

1292
01:11:37,920 --> 01:11:40,080
who might be disproportionately affected

1293
01:11:40,080 --> 01:11:43,080
by the outcomes of the AI system the

1294
01:11:43,080 --> 01:11:45,239
obvious answer is yes yeah in this

1295
01:11:45,239 --> 01:11:47,820
specific content that's used but there's

1296
01:11:47,820 --> 01:11:50,420
also unintended ways

1297
01:11:50,420 --> 01:11:53,460
the specific use case with the medical

1298
01:11:53,460 --> 01:11:58,860
information absolutely yes people

1299
01:12:00,560 --> 01:12:03,179
yeah and also be conscious of the data

1300
01:12:03,179 --> 01:12:04,980
you are using if you are training models

1301
01:12:04,980 --> 01:12:07,860
because often it comes from

1302
01:12:07,860 --> 01:12:09,900
countries for instance with only certain

1303
01:12:09,900 --> 01:12:12,120
at least these are represented for

1304
01:12:12,120 --> 01:12:13,980
instance or you have more data from Men

1305
01:12:13,980 --> 01:12:16,860
of women or American children and then

1306
01:12:16,860 --> 01:12:18,420
you realize that what you are really

1307
01:12:18,420 --> 01:12:21,420
getting is is not the right output and

1308
01:12:21,420 --> 01:12:24,239
can we expect mostly positive reactions

1309
01:12:24,239 --> 01:12:27,179
from the users or individuals and we had

1310
01:12:27,179 --> 01:12:30,480
a lot of debates about exactly like

1311
01:12:30,480 --> 01:12:33,800
who the scope is but yes

1312
01:12:33,800 --> 01:12:36,780
we should have on screen at the same

1313
01:12:36,780 --> 01:12:37,739
time

1314
01:12:37,739 --> 01:12:40,920
depends on the transparency beforehand

1315
01:12:40,920 --> 01:12:43,320
and the shock when people read about it

1316
01:12:43,320 --> 01:12:45,420
in the newspaper or want to know about

1317
01:12:45,420 --> 01:12:49,320
it and all kinds of things no uh who the

1318
01:12:49,320 --> 01:12:51,239
AI system affect the freedom of its

1319
01:12:51,239 --> 01:12:52,560
users

1320
01:12:52,560 --> 01:12:53,400
um

1321
01:12:53,400 --> 01:12:55,640
I think for me personally

1322
01:12:55,640 --> 01:12:58,140
uh the question is wrong it should be

1323
01:12:58,140 --> 01:13:00,719
not the users who are the doctors but

1324
01:13:00,719 --> 01:13:04,020
mostly the patients who the uh the

1325
01:13:04,020 --> 01:13:06,000
assessment bowling yeah but on the other

1326
01:13:06,000 --> 01:13:09,239
hand if you are Korean wearable

1327
01:13:09,239 --> 01:13:12,120
the user will be the user really the

1328
01:13:12,120 --> 01:13:15,900
patient s

1329
01:13:15,900 --> 01:13:18,719
advising the doctors but and monitoring

1330
01:13:18,719 --> 01:13:21,179
the patients so do you

1331
01:13:21,179 --> 01:13:23,940
at least yeah this the the questions

1332
01:13:23,940 --> 01:13:26,880
might be more I'm I would say the data

1333
01:13:26,880 --> 01:13:30,179
subjects instead of the user but that's

1334
01:13:30,179 --> 01:13:33,060
more of professional bias uh yeah but I

1335
01:13:33,060 --> 01:13:34,380
understand because of course I was in

1336
01:13:34,380 --> 01:13:36,480
the Privacy corner so I never really

1337
01:13:36,480 --> 01:13:39,019
what you mean

1338
01:13:47,580 --> 01:13:50,460
Freedom like a nintended like a

1339
01:13:50,460 --> 01:13:53,760
necessary hospitalization yeah but even

1340
01:13:53,760 --> 01:13:55,980
you could go further than thinking

1341
01:13:55,980 --> 01:13:56,940
Behavior

1342
01:13:56,940 --> 01:14:00,300
I am like like for instance when when

1343
01:14:00,300 --> 01:14:02,699
the creators of uh I don't know Facebook

1344
01:14:02,699 --> 01:14:05,400
or all those things uh or Tick Tock they

1345
01:14:05,400 --> 01:14:06,600
launched something on the market I

1346
01:14:06,600 --> 01:14:08,820
wonder if they thought we're gonna

1347
01:14:08,820 --> 01:14:10,560
change the life or children that is the

1348
01:14:10,560 --> 01:14:12,120
only thing they do nice all day or doing

1349
01:14:12,120 --> 01:14:15,060
dances uh to be in Tick Tock but it can

1350
01:14:15,060 --> 01:14:17,340
really change a whole generation so if

1351
01:14:17,340 --> 01:14:19,020
you are offering a product like that

1352
01:14:19,020 --> 01:14:20,640
that everybody

1353
01:14:20,640 --> 01:14:22,860
oh a lot of people like to use and you

1354
01:14:22,860 --> 01:14:24,120
give it a really good price and more

1355
01:14:24,120 --> 01:14:25,620
people can use it so you get more data

1356
01:14:25,620 --> 01:14:28,400
so that could build a strategy

1357
01:14:28,400 --> 01:14:30,780
did you want to change the behavior of

1358
01:14:30,780 --> 01:14:32,940
people they want to be correct they want

1359
01:14:32,940 --> 01:14:34,980
to be healthy it could affect even the

1360
01:14:34,980 --> 01:14:36,600
insurances I mean it could have a lot of

1361
01:14:36,600 --> 01:14:39,239
in the whole journey affect a lot of

1362
01:14:39,239 --> 01:14:40,920
different ways of behavior and change

1363
01:14:40,920 --> 01:14:43,280
society

1364
01:14:54,960 --> 01:14:57,360
trying to model to predict a few God's

1365
01:14:57,360 --> 01:14:59,280
coverage yes or no and the model is

1366
01:14:59,280 --> 01:15:01,800
trying to say this certain culture group

1367
01:15:01,800 --> 01:15:04,140
always has code so you should be in

1368
01:15:04,140 --> 01:15:06,360
lockdown and China you've got this model

1369
01:15:06,360 --> 01:15:08,340
where you're going to use green orange

1370
01:15:08,340 --> 01:15:11,040
red or green yes it was a black box

1371
01:15:11,040 --> 01:15:14,040
behind that yeah that's the phrasing the

1372
01:15:14,040 --> 01:15:16,140
problem but they can also be I guess

1373
01:15:16,140 --> 01:15:17,820
good guys

1374
01:15:17,820 --> 01:15:19,800
ethically they're wrong because you're

1375
01:15:19,800 --> 01:15:21,600
forcing basically manipulating people to

1376
01:15:21,600 --> 01:15:23,840
make certain decisions or choices yes

1377
01:15:23,840 --> 01:15:26,580
orally they're probably a good thing and

1378
01:15:26,580 --> 01:15:27,960
it's kind of

1379
01:15:27,960 --> 01:15:30,360
how do you think yeah but that's why it

1380
01:15:30,360 --> 01:15:32,159
falls under the category of six and

1381
01:15:32,159 --> 01:15:33,840
human rights yeah because ethics keeps

1382
01:15:33,840 --> 01:15:36,420
being uh trade off and keeps being I

1383
01:15:36,420 --> 01:15:38,340
mean it's nothing unique so you might

1384
01:15:38,340 --> 01:15:39,900
think in a model that makes all of us

1385
01:15:39,900 --> 01:15:42,000
eat healthy it's only good for us let's

1386
01:15:42,000 --> 01:15:44,760
do that but you also have a right to be

1387
01:15:44,760 --> 01:15:47,040
free exactly and to have a choice

1388
01:15:47,040 --> 01:15:50,219
and to believe I'm healthy and to and so

1389
01:15:50,219 --> 01:15:53,219
so how far can you and also that it's

1390
01:15:53,219 --> 01:15:55,080
not here but in other countries for

1391
01:15:55,080 --> 01:15:56,520
instance a threat about how your product

1392
01:15:56,520 --> 01:15:58,800
could be misused like for instance by

1393
01:15:58,800 --> 01:16:00,239
governments or surveillance for

1394
01:16:00,239 --> 01:16:02,940
manipulation of uh and even have been a

1395
01:16:02,940 --> 01:16:06,919
threat for democracy yes

1396
01:16:07,800 --> 01:16:09,179
the the line where's the line for

1397
01:16:09,179 --> 01:16:11,640
example or is it or is sort of like a

1398
01:16:11,640 --> 01:16:13,860
framework to model your line

1399
01:16:13,860 --> 01:16:15,840
your line it should be is that also a

1400
01:16:15,840 --> 01:16:17,880
bigger than the Buffalo no but it's a

1401
01:16:17,880 --> 01:16:20,219
good tip to think about something like

1402
01:16:20,219 --> 01:16:21,480
that

1403
01:16:21,480 --> 01:16:24,179
so yeah good good tip I will work on

1404
01:16:24,179 --> 01:16:25,020
that

1405
01:16:25,020 --> 01:16:27,500
nice

1406
01:16:29,270 --> 01:16:32,339
[Music]

1407
01:16:32,880 --> 01:16:35,159
fearing what a universe decision-making

1408
01:16:35,159 --> 01:16:39,179
in an unintended and undesirable way

1409
01:16:39,179 --> 01:16:42,239
I would change the question yeah but you

1410
01:16:42,239 --> 01:16:44,880
sir they deserve I know describe early

1411
01:16:44,880 --> 01:16:48,600
intenders because also the affecting

1412
01:16:48,600 --> 01:16:51,840
decision making in an intended way can a

1413
01:16:51,840 --> 01:16:53,880
big impact

1414
01:16:53,880 --> 01:16:56,640
um yeah like it doesn't have to be

1415
01:16:56,640 --> 01:16:59,219
unlawful or something but but in this

1416
01:16:59,219 --> 01:17:01,500
specific threat it is really unintended

1417
01:17:01,500 --> 01:17:03,179
in the sense that

1418
01:17:03,179 --> 01:17:06,300
how far the output from our model is

1419
01:17:06,300 --> 01:17:08,580
could really affect

1420
01:17:08,580 --> 01:17:11,580
the decision making of somebody without

1421
01:17:11,580 --> 01:17:15,260
an unintended way but without really

1422
01:17:15,260 --> 01:17:18,060
because it it happens because you are

1423
01:17:18,060 --> 01:17:19,199
sometimes they're not conscious of

1424
01:17:19,199 --> 01:17:20,760
things that can go wrong

1425
01:17:20,760 --> 01:17:23,460
and sometimes what what you get from the

1426
01:17:23,460 --> 01:17:25,560
output could really without being your

1427
01:17:25,560 --> 01:17:26,820
intention because that was not really

1428
01:17:26,820 --> 01:17:29,280
your your attack it's really changing

1429
01:17:29,280 --> 01:17:31,860
Behavior changing the decision making

1430
01:17:31,860 --> 01:17:33,960
and and then you you already have that

1431
01:17:33,960 --> 01:17:36,600
when you are tagging or labeling things

1432
01:17:36,600 --> 01:17:38,880
like in these tools like Facebook and

1433
01:17:38,880 --> 01:17:40,140
all the things that already change

1434
01:17:40,140 --> 01:17:42,900
behavior of a lot of people and I wonder

1435
01:17:42,900 --> 01:17:45,480
if that what's the intention when maybe

1436
01:17:45,480 --> 01:17:46,980
yes in that moment but but this is more

1437
01:17:46,980 --> 01:17:48,480
for when you are developing to be

1438
01:17:48,480 --> 01:17:49,860
conscious that things can go in a

1439
01:17:49,860 --> 01:17:51,480
different way that you think for

1440
01:17:51,480 --> 01:17:55,159
intention that's another cut so I mean

1441
01:17:56,400 --> 01:18:01,099
your risk for the patient or the doctor

1442
01:18:01,140 --> 01:18:03,480
of course and that's why diversity of

1443
01:18:03,480 --> 01:18:05,159
teams and that's always really important

1444
01:18:05,159 --> 01:18:07,080
of course yeah that could also be of

1445
01:18:07,080 --> 01:18:08,760
influence yeah and are we going to

1446
01:18:08,760 --> 01:18:11,100
collect and use behavioral data to feed

1447
01:18:11,100 --> 01:18:13,679
the AI I think that's the design that

1448
01:18:13,679 --> 01:18:15,780
the purpose exactly in this case it's

1449
01:18:15,780 --> 01:18:18,960
obvious yeah and when you you discover a

1450
01:18:18,960 --> 01:18:20,280
threat like that

1451
01:18:20,280 --> 01:18:22,920
yeah it is a matter of now let's act on

1452
01:18:22,920 --> 01:18:24,540
that what does it mean what does it mean

1453
01:18:24,540 --> 01:18:26,460
use behavioral data what risks do we

1454
01:18:26,460 --> 01:18:27,960
have there and especially you comes from

1455
01:18:27,960 --> 01:18:29,880
the compliance site you know about this

1456
01:18:29,880 --> 01:18:32,219
means that we probably have to

1457
01:18:32,219 --> 01:18:36,120
extra work if we even can do this

1458
01:18:36,120 --> 01:18:38,540
so

1459
01:18:41,280 --> 01:18:43,340
yeah

1460
01:18:43,620 --> 01:18:45,739
cool yeah it really is really good

1461
01:18:45,739 --> 01:18:49,140
I hope you enjoyed the session

1462
01:18:49,140 --> 01:18:52,320
but uh yeah you know float Freya is like

1463
01:18:52,320 --> 01:18:54,420
I mentioned open source resoling GitHub

1464
01:18:54,420 --> 01:18:56,820
so if you have tips for improvement

1465
01:18:56,820 --> 01:18:59,820
please through GitHub or you can also

1466
01:18:59,820 --> 01:19:00,960
send an email

1467
01:19:00,960 --> 01:19:03,060
like I said this is something I was

1468
01:19:03,060 --> 01:19:05,100
developing three or three years of

1469
01:19:05,100 --> 01:19:08,580
researchers by myself and then it worked

1470
01:19:08,580 --> 01:19:09,900
in practice I mean you have seen earlier

1471
01:19:09,900 --> 01:19:11,460
you are able to see and the nice thing

1472
01:19:11,460 --> 01:19:13,440
is to when you recommend things then you

1473
01:19:13,440 --> 01:19:15,060
can really act on that that's the

1474
01:19:15,060 --> 01:19:18,540
important to discover risks on time

1475
01:19:18,540 --> 01:19:20,340
and then yeah like I say it's a

1476
01:19:20,340 --> 01:19:23,940
Community Driven project so ideally yeah

1477
01:19:23,940 --> 01:19:26,159
we all make it uh useful for everybody

1478
01:19:26,159 --> 01:19:28,699
but that that's the point

1479
01:19:28,699 --> 01:19:30,600
and then yeah everything is online

1480
01:19:30,600 --> 01:19:32,400
available

1481
01:19:32,400 --> 01:19:34,860
um but there's also boxes like you see

1482
01:19:34,860 --> 01:19:35,640
there

1483
01:19:35,640 --> 01:19:38,520
and I'm gonna also buy a box so I sell

1484
01:19:38,520 --> 01:19:40,620
them by the cost price so I don't have

1485
01:19:40,620 --> 01:19:42,900
any benefits from it

1486
01:19:42,900 --> 01:19:44,940
um so yeah if any of using Terence is

1487
01:19:44,940 --> 01:19:46,860
interested in a box uh yeah I have a

1488
01:19:46,860 --> 01:19:49,260
couple here

1489
01:19:49,260 --> 01:19:52,660
and then thank you

1490
01:19:52,660 --> 01:19:56,120
[Applause]

