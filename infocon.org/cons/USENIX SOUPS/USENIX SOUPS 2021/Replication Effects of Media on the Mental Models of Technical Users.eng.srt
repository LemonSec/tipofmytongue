1
00:00:16,800 --> 00:00:19,039
hi everybody my name is khadija and

2
00:00:19,039 --> 00:00:20,880
today i'll be representing the paper

3
00:00:20,880 --> 00:00:23,199
replication effective media on the

4
00:00:23,199 --> 00:00:26,880
mental models of technical users

5
00:00:27,359 --> 00:00:29,279
users with technical background have a

6
00:00:29,279 --> 00:00:30,960
much larger role to play in online

7
00:00:30,960 --> 00:00:32,000
security than those who are

8
00:00:32,000 --> 00:00:33,600
non-technical

9
00:00:33,600 --> 00:00:35,360
all technical users have an influence

10
00:00:35,360 --> 00:00:37,520
within their job on security and also

11
00:00:37,520 --> 00:00:39,280
serve as informal advisors for

12
00:00:39,280 --> 00:00:40,800
non-technical people amongst their

13
00:00:40,800 --> 00:00:43,840
family friends and

14
00:00:43,840 --> 00:00:45,520
for this reason it is important that

15
00:00:45,520 --> 00:00:47,039
technical users have accurate mental

16
00:00:47,039 --> 00:00:48,719
models of security

17
00:00:48,719 --> 00:00:50,960
how computer systems work methods of

18
00:00:50,960 --> 00:00:54,640
protection and risky behaviors

19
00:00:54,879 --> 00:00:56,239
one of the ways these mental models

20
00:00:56,239 --> 00:00:58,559
might be influenced is through media

21
00:00:58,559 --> 00:01:01,039
cybersecurity depictions in media are

22
00:01:01,039 --> 00:01:03,199
often fast-paced and dramatic with the

23
00:01:03,199 --> 00:01:04,879
use of several tropes

24
00:01:04,879 --> 00:01:06,400
and previous studies suggest that it

25
00:01:06,400 --> 00:01:08,400
might influence fuser viewers mental

26
00:01:08,400 --> 00:01:10,080
models

27
00:01:10,080 --> 00:01:12,080
one such study is that of fulton that

28
00:01:12,080 --> 00:01:13,280
else

29
00:01:13,280 --> 00:01:15,520
titled the effect of entertainment media

30
00:01:15,520 --> 00:01:19,439
on mental models of computer security

31
00:01:20,240 --> 00:01:22,400
fulton study confirms that non-technical

32
00:01:22,400 --> 00:01:24,560
end users often turn to fictional media

33
00:01:24,560 --> 00:01:26,159
and its tropes to fill gaps in their

34
00:01:26,159 --> 00:01:28,000
technical knowledge

35
00:01:28,000 --> 00:01:29,680
given that the study did not control for

36
00:01:29,680 --> 00:01:31,840
technical expertise we replicate it with

37
00:01:31,840 --> 00:01:35,439
users who have a technical background

38
00:01:36,320 --> 00:01:39,119
we had 23 participants in our study

39
00:01:39,119 --> 00:01:41,040
during each study session participants

40
00:01:41,040 --> 00:01:42,720
completed an interview followed by a

41
00:01:42,720 --> 00:01:44,240
questionnaire that asked about general

42
00:01:44,240 --> 00:01:46,720
demographics media consumption and

43
00:01:46,720 --> 00:01:48,560
technical background

44
00:01:48,560 --> 00:01:51,280
data was then was then analyzed by

45
00:01:51,280 --> 00:01:53,360
inductive thematic analysis

46
00:01:53,360 --> 00:01:55,280
and each transcript was analyzed by at

47
00:01:55,280 --> 00:01:58,479
least two researchers

48
00:01:59,360 --> 00:02:01,119
in the second half of the interview

49
00:02:01,119 --> 00:02:03,439
participants viewed six video clips and

50
00:02:03,439 --> 00:02:05,119
discussed what they found realistic and

51
00:02:05,119 --> 00:02:06,880
unrealistic about each

52
00:02:06,880 --> 00:02:09,598
the video clips chosen by fulton cover

53
00:02:09,598 --> 00:02:11,680
common cyber security concepts like

54
00:02:11,680 --> 00:02:15,280
hacking and password usage

55
00:02:15,680 --> 00:02:17,360
we will focus on the portion of the

56
00:02:17,360 --> 00:02:19,599
interview related to the video clips

57
00:02:19,599 --> 00:02:21,200
we will go over some details of what

58
00:02:21,200 --> 00:02:23,520
made us seem realistic or unrealistic

59
00:02:23,520 --> 00:02:25,599
and focus on the aspects that overlap

60
00:02:25,599 --> 00:02:28,239
with the original studies results

61
00:02:28,239 --> 00:02:30,000
our new dif our new findings or

62
00:02:30,000 --> 00:02:31,360
differences will be highlighted in

63
00:02:31,360 --> 00:02:33,200
orange so results that match the

64
00:02:33,200 --> 00:02:37,238
original study will be black

65
00:02:37,680 --> 00:02:39,519
when faced with unplugging a computer to

66
00:02:39,519 --> 00:02:41,599
stop a hack some of our participants

67
00:02:41,599 --> 00:02:43,599
like those of the original study agreed

68
00:02:43,599 --> 00:02:44,959
that this would be an efficient way to

69
00:02:44,959 --> 00:02:46,239
do so

70
00:02:46,239 --> 00:02:48,560
others however noted that this would be

71
00:02:48,560 --> 00:02:50,160
ineffective when the network was

72
00:02:50,160 --> 00:02:52,799
compromised

73
00:02:54,160 --> 00:02:55,680
participants were also faced with a

74
00:02:55,680 --> 00:02:57,519
scene in which users were alerted of the

75
00:02:57,519 --> 00:02:59,760
hack due to a multitude of pop-ups on

76
00:02:59,760 --> 00:03:00,879
the screen

77
00:03:00,879 --> 00:03:02,319
while the original studies participants

78
00:03:02,319 --> 00:03:04,319
found this accurate our technical

79
00:03:04,319 --> 00:03:06,080
participants distinguished pop-ups to be

80
00:03:06,080 --> 00:03:08,080
a feature of malware feeling that a

81
00:03:08,080 --> 00:03:10,080
hacker would remember to prefer to

82
00:03:10,080 --> 00:03:13,170
remain undetected instead

83
00:03:13,170 --> 00:03:14,640
[Music]

84
00:03:14,640 --> 00:03:16,400
most of our technical participants felt

85
00:03:16,400 --> 00:03:18,159
encryption to be secure and hard to

86
00:03:18,159 --> 00:03:19,040
break

87
00:03:19,040 --> 00:03:20,800
this is in stark contrast to the

88
00:03:20,800 --> 00:03:22,879
original study where the participants

89
00:03:22,879 --> 00:03:26,480
felt encryption to be easily broken

90
00:03:27,920 --> 00:03:29,599
when discussing intended targets of a

91
00:03:29,599 --> 00:03:31,519
breach there is overlap between the

92
00:03:31,519 --> 00:03:33,120
original studies participants and our

93
00:03:33,120 --> 00:03:35,280
technical participants both believed

94
00:03:35,280 --> 00:03:37,200
that specific important targets were

95
00:03:37,200 --> 00:03:38,799
likely to be attacked

96
00:03:38,799 --> 00:03:40,640
some of our participants did however

97
00:03:40,640 --> 00:03:42,480
acknowledge that not everybody is an

98
00:03:42,480 --> 00:03:45,120
intended target

99
00:03:45,120 --> 00:03:47,280
both sets of participants agreed that

100
00:03:47,280 --> 00:03:48,799
suspicious links should be treated with

101
00:03:48,799 --> 00:03:50,799
caution however our technical

102
00:03:50,799 --> 00:03:52,560
participants were particularly

103
00:03:52,560 --> 00:03:54,799
unforgiving of victims of importance who

104
00:03:54,799 --> 00:03:58,239
they believed should know better

105
00:03:58,319 --> 00:04:00,480
similarly both sets also agreed that a

106
00:04:00,480 --> 00:04:02,239
breach probably takes longer than just a

107
00:04:02,239 --> 00:04:03,840
few seconds

108
00:04:03,840 --> 00:04:05,840
our participants further elaborated that

109
00:04:05,840 --> 00:04:08,000
this would only be possible with the

110
00:04:08,000 --> 00:04:10,080
help of an insider or due to lack

111
00:04:10,080 --> 00:04:11,599
security measures

112
00:04:11,599 --> 00:04:14,000
most participants did however expect the

113
00:04:14,000 --> 00:04:17,599
systems to be heavily defended

114
00:04:18,560 --> 00:04:20,560
methods of assessing realism were mostly

115
00:04:20,560 --> 00:04:22,000
consistent between the technical and

116
00:04:22,000 --> 00:04:24,080
non-technical participants both using

117
00:04:24,080 --> 00:04:25,680
their technical knowledge personal

118
00:04:25,680 --> 00:04:28,320
experience context and cinematic cues to

119
00:04:28,320 --> 00:04:30,719
do so

120
00:04:30,800 --> 00:04:32,080
while our participants had a more

121
00:04:32,080 --> 00:04:34,000
nuanced understanding of cyber security

122
00:04:34,000 --> 00:04:36,400
concepts there were gaps in their mental

123
00:04:36,400 --> 00:04:38,160
models even amongst those who

124
00:04:38,160 --> 00:04:40,240
demonstrated reasonable knowledge

125
00:04:40,240 --> 00:04:43,199
the paper provides numerous examples

126
00:04:43,199 --> 00:04:45,440
our study results provide educators with

127
00:04:45,440 --> 00:04:47,199
insight on the nuances and depth of

128
00:04:47,199 --> 00:04:49,680
misconceptions held by technical users

129
00:04:49,680 --> 00:04:51,120
in addition to the recommendations

130
00:04:51,120 --> 00:04:53,280
offered by fulton at al we suggest the

131
00:04:53,280 --> 00:04:55,280
development of a more holistic thorough

132
00:04:55,280 --> 00:04:57,120
cyber security curriculum

133
00:04:57,120 --> 00:04:59,120
we also suggest these misconceptions be

134
00:04:59,120 --> 00:05:01,360
included in fact-checking websites and

135
00:05:01,360 --> 00:05:03,440
emphasize using media as a tool to

136
00:05:03,440 --> 00:05:05,280
increase awareness of cybersecurity

137
00:05:05,280 --> 00:05:07,759
concepts

138
00:05:07,759 --> 00:05:09,600
thank you so much for listening five

139
00:05:09,600 --> 00:05:11,360
minutes is just a sample so please do

140
00:05:11,360 --> 00:05:13,280
read the paper and feel free to send me

141
00:05:13,280 --> 00:05:17,479
an email for follow-up questions

