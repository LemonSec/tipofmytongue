1
00:00:16,160 --> 00:00:18,160
i'm rick wash and together with norbert

2
00:00:18,160 --> 00:00:20,000
antala and emily rader we've been

3
00:00:20,000 --> 00:00:22,000
looking at how humans detect phishing

4
00:00:22,000 --> 00:00:23,359
messages

5
00:00:23,359 --> 00:00:25,519
we've been taking a somewhat unorthodox

6
00:00:25,519 --> 00:00:27,760
approach most research on phishing looks

7
00:00:27,760 --> 00:00:30,000
to find people's weaknesses and then to

8
00:00:30,000 --> 00:00:32,320
create training to fix or patch those

9
00:00:32,320 --> 00:00:33,600
weaknesses

10
00:00:33,600 --> 00:00:35,680
instead what we're doing is we're

11
00:00:35,680 --> 00:00:37,440
looking at what things people are good

12
00:00:37,440 --> 00:00:39,760
at at least in some circumstances and

13
00:00:39,760 --> 00:00:41,520
then trying to make those things work

14
00:00:41,520 --> 00:00:42,559
better

15
00:00:42,559 --> 00:00:44,000
that is rather than trying to get people

16
00:00:44,000 --> 00:00:46,000
to do something they are not good at

17
00:00:46,000 --> 00:00:47,360
we want to understand what people are

18
00:00:47,360 --> 00:00:48,879
already doing well and then help them

19
00:00:48,879 --> 00:00:50,399
become better at that

20
00:00:50,399 --> 00:00:51,920
we've done multiple studies on this

21
00:00:51,920 --> 00:00:53,199
topic

22
00:00:53,199 --> 00:00:55,840
this particular study is a survey of 300

23
00:00:55,840 --> 00:00:58,559
or so non-expert email users one of the

24
00:00:58,559 --> 00:01:00,079
great things about surveys is that you

25
00:01:00,079 --> 00:01:02,160
can get a large number of responses and

26
00:01:02,160 --> 00:01:04,239
you can demographically match those

27
00:01:04,239 --> 00:01:06,560
responses to a population like the u.s

28
00:01:06,560 --> 00:01:08,799
population which is what we did

29
00:01:08,799 --> 00:01:11,040
the downside is that surveys

30
00:01:11,040 --> 00:01:12,320
you can only ask questions you know

31
00:01:12,320 --> 00:01:14,479
about ahead of time

32
00:01:14,479 --> 00:01:16,560
we asked respondents to identify a

33
00:01:16,560 --> 00:01:18,640
specific instance of phishing a specific

34
00:01:18,640 --> 00:01:20,320
email that they experienced

35
00:01:20,320 --> 00:01:22,000
which means one that they successfully

36
00:01:22,000 --> 00:01:24,320
detected and we asked them to answer

37
00:01:24,320 --> 00:01:26,000
questions about what they did and how

38
00:01:26,000 --> 00:01:27,600
they detected it

39
00:01:27,600 --> 00:01:29,600
we based our questions on a paper that i

40
00:01:29,600 --> 00:01:32,320
published last year that studied how it

41
00:01:32,320 --> 00:01:35,360
experts identify phishing

42
00:01:35,360 --> 00:01:37,600
in that i identified six steps that

43
00:01:37,600 --> 00:01:40,479
experts use to identify phishing emails

44
00:01:40,479 --> 00:01:42,640
we then took and wrote custom survey

45
00:01:42,640 --> 00:01:44,079
questions to measure how many of our

46
00:01:44,079 --> 00:01:46,560
non-expert respondents did things in

47
00:01:46,560 --> 00:01:48,479
each of those six categories

48
00:01:48,479 --> 00:01:50,240
our paper has a full report on what we

49
00:01:50,240 --> 00:01:51,119
found

50
00:01:51,119 --> 00:01:52,640
today i'm just going to highlight a

51
00:01:52,640 --> 00:01:54,799
couple of the most interesting findings

52
00:01:54,799 --> 00:01:56,799
about the knowledge and capabilities

53
00:01:56,799 --> 00:01:58,719
that humans have that they bring to

54
00:01:58,719 --> 00:02:00,159
phishing detection

55
00:02:00,159 --> 00:02:01,680
that work differently than the way

56
00:02:01,680 --> 00:02:04,479
computers typically detect phishing

57
00:02:04,479 --> 00:02:06,159
and we'll start with knowledge and the

58
00:02:06,159 --> 00:02:08,000
knowledge that humans use when detecting

59
00:02:08,000 --> 00:02:10,239
phishing messages that technical filters

60
00:02:10,239 --> 00:02:12,000
just don't have

61
00:02:12,000 --> 00:02:14,000
72 percent of our respondents felt like

62
00:02:14,000 --> 00:02:16,640
they had similar emails in the past

63
00:02:16,640 --> 00:02:19,120
that is they had the phishing email that

64
00:02:19,120 --> 00:02:22,000
they detected felt familiar to them

65
00:02:22,000 --> 00:02:24,800
however 95 of the respondents also

66
00:02:24,800 --> 00:02:27,120
reported that the email was unexpected

67
00:02:27,120 --> 00:02:28,480
that many emails they received are

68
00:02:28,480 --> 00:02:31,519
expected but this particular one was not

69
00:02:31,519 --> 00:02:32,480
together

70
00:02:32,480 --> 00:02:35,519
this familiarity with similar emails and

71
00:02:35,519 --> 00:02:37,440
the unexpected nature of the email

72
00:02:37,440 --> 00:02:39,519
allowed people to

73
00:02:39,519 --> 00:02:41,280
kind of have an idea of what is

74
00:02:41,280 --> 00:02:43,599
typically present what these emails

75
00:02:43,599 --> 00:02:45,120
typically look like

76
00:02:45,120 --> 00:02:47,599
and then 86 percent of our respondents

77
00:02:47,599 --> 00:02:49,920
noticed that the phishing email wasn't

78
00:02:49,920 --> 00:02:51,920
normal it didn't have what is typically

79
00:02:51,920 --> 00:02:54,480
present in the emails

80
00:02:54,480 --> 00:02:56,080
this knowledge of what previous similar

81
00:02:56,080 --> 00:02:57,440
emails look like and what they typically

82
00:02:57,440 --> 00:02:59,519
contain isn't something that technical

83
00:02:59,519 --> 00:03:01,040
filters can do but it is something

84
00:03:01,040 --> 00:03:02,840
humans do

85
00:03:02,840 --> 00:03:04,400
automatically

86
00:03:04,400 --> 00:03:05,519
humans also have a number of

87
00:03:05,519 --> 00:03:07,280
capabilities that they use when

88
00:03:07,280 --> 00:03:08,959
detecting phishing emails that technical

89
00:03:08,959 --> 00:03:10,959
filters don't have

90
00:03:10,959 --> 00:03:13,760
94 of our respondents were able to

91
00:03:13,760 --> 00:03:15,519
remember the action that the email asked

92
00:03:15,519 --> 00:03:16,560
them to take

93
00:03:16,560 --> 00:03:18,800
and that action stood out as unusual to

94
00:03:18,800 --> 00:03:21,120
76 of the respondents

95
00:03:21,120 --> 00:03:23,519
email user emails often ask people to

96
00:03:23,519 --> 00:03:25,680
take actions but it's only the users

97
00:03:25,680 --> 00:03:26,959
themselves that can tell you if the

98
00:03:26,959 --> 00:03:29,280
action is normal or reasonable for them

99
00:03:29,280 --> 00:03:30,640
this is something that our respondents

100
00:03:30,640 --> 00:03:33,040
seem to do automatically

101
00:03:33,040 --> 00:03:34,239
additionally

102
00:03:34,239 --> 00:03:36,400
73 of our respondents intentionally

103
00:03:36,400 --> 00:03:38,480
delayed responding to an email in order

104
00:03:38,480 --> 00:03:40,640
to further investigate the email

105
00:03:40,640 --> 00:03:42,640
sometimes the delays were small such as

106
00:03:42,640 --> 00:03:44,720
hovering over an email address

107
00:03:44,720 --> 00:03:46,159
but in a number of instances people

108
00:03:46,159 --> 00:03:48,640
would wait and ask other people for help

109
00:03:48,640 --> 00:03:50,879
end users have this capability to delay

110
00:03:50,879 --> 00:03:52,239
dealing with the email until they have

111
00:03:52,239 --> 00:03:53,920
more information which is something that

112
00:03:53,920 --> 00:03:56,319
technical filters generally can't do

113
00:03:56,319 --> 00:03:58,319
they also have the capability to ask

114
00:03:58,319 --> 00:03:59,760
senders or other people for more

115
00:03:59,760 --> 00:04:01,120
information about the email that can

116
00:04:01,120 --> 00:04:01,840
help them

117
00:04:01,840 --> 00:04:03,519
[Music]

118
00:04:03,519 --> 00:04:05,280
fishing detection is very similar to

119
00:04:05,280 --> 00:04:07,040
james reason's swiss cheese model of

120
00:04:07,040 --> 00:04:08,799
accident prevention

121
00:04:08,799 --> 00:04:10,799
each slice of cheese is a filter that

122
00:04:10,799 --> 00:04:12,319
prevents many fishing messages from

123
00:04:12,319 --> 00:04:14,319
getting through though each slice has

124
00:04:14,319 --> 00:04:16,639
holes that allow some messages through

125
00:04:16,639 --> 00:04:18,639
if phishing detectors all use the same

126
00:04:18,639 --> 00:04:20,720
information and capabilities then the

127
00:04:20,720 --> 00:04:22,479
holes in the cheese line up and there's

128
00:04:22,479 --> 00:04:24,080
a path for malicious messages to get

129
00:04:24,080 --> 00:04:25,360
through

130
00:04:25,360 --> 00:04:27,040
if we try to make people work like

131
00:04:27,040 --> 00:04:30,160
computers for example parsing urls

132
00:04:30,160 --> 00:04:32,720
then we line up the holes in the chiefs

133
00:04:32,720 --> 00:04:33,759
however

134
00:04:33,759 --> 00:04:35,840
we found that people naturally use very

135
00:04:35,840 --> 00:04:37,440
different knowledge and capabilities

136
00:04:37,440 --> 00:04:39,040
when they detect phishing than computers

137
00:04:39,040 --> 00:04:39,759
do

138
00:04:39,759 --> 00:04:41,360
which means their holes are in different

139
00:04:41,360 --> 00:04:42,880
places than the holes in the technical

140
00:04:42,880 --> 00:04:44,479
filters

141
00:04:44,479 --> 00:04:45,919
much of the advice about phishing

142
00:04:45,919 --> 00:04:48,320
prevention focuses on stopping messages

143
00:04:48,320 --> 00:04:49,840
from ever getting to end users in the

144
00:04:49,840 --> 00:04:51,360
first place

145
00:04:51,360 --> 00:04:53,520
instead our findings highlight how end

146
00:04:53,520 --> 00:04:55,199
users operate using this different

147
00:04:55,199 --> 00:04:58,000
knowledge and capabilities and therefore

148
00:04:58,000 --> 00:04:59,440
including both

149
00:04:59,440 --> 00:05:02,720
technical filters and end user detection

150
00:05:02,720 --> 00:05:04,880
in the whole system enables a wider

151
00:05:04,880 --> 00:05:06,479
range of phishing detection than

152
00:05:06,479 --> 00:05:08,240
technical filters alone

153
00:05:08,240 --> 00:05:10,160
our findings also suggest that end user

154
00:05:10,160 --> 00:05:11,919
detection can be improved by training

155
00:05:11,919 --> 00:05:14,880
users to better utilize their own unique

156
00:05:14,880 --> 00:05:16,479
knowledge and capabilities to detect

157
00:05:16,479 --> 00:05:18,639
phishing messages

158
00:05:18,639 --> 00:05:21,880
thank you

159
00:05:26,639 --> 00:05:28,720
you

