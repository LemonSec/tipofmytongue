1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:11,480 --> 00:00:13,799
Simone I will present our paper on

3
00:00:13,799 --> 00:00:15,599
exploring and evaluating suitable

4
00:00:15,599 --> 00:00:17,100
metaphors for explaining differential

5
00:00:17,100 --> 00:00:19,440
privacy to users This research is a

6
00:00:19,440 --> 00:00:21,180
result of two projects funded by The

7
00:00:21,180 --> 00:00:23,160
Horizon 2020 framework of the European

8
00:00:23,160 --> 00:00:25,260
commission and by the Swedish knowledge

9
00:00:25,260 --> 00:00:27,539
Foundation

10
00:00:27,539 --> 00:00:29,640
our objective in this work is to

11
00:00:29,640 --> 00:00:31,500
investigate how to effectively explain

12
00:00:31,500 --> 00:00:33,180
the underlying differentially private

13
00:00:33,180 --> 00:00:35,579
data analysis to data subjects to

14
00:00:35,579 --> 00:00:37,260
facilitate their decisions by using

15
00:00:37,260 --> 00:00:39,840
suitable metaphors the data subjects are

16
00:00:39,840 --> 00:00:41,660
mainly lay users who need to make

17
00:00:41,660 --> 00:00:44,040
privacy decisions about sharing their

18
00:00:44,040 --> 00:00:46,079
data when confronted with DP enabled

19
00:00:46,079 --> 00:00:48,780
systems however researchers have shown

20
00:00:48,780 --> 00:00:51,420
that how DP is described in practice is

21
00:00:51,420 --> 00:00:53,460
insufficient to help users make informed

22
00:00:53,460 --> 00:00:55,760
decisions

23
00:00:55,980 --> 00:00:58,620
let's play a game imagine that I asked

24
00:00:58,620 --> 00:01:00,180
all of my audience whether they prefer

25
00:01:00,180 --> 00:01:02,760
hard work or cheating to succeed I give

26
00:01:02,760 --> 00:01:05,099
each of you a spinner between areas amb

27
00:01:05,099 --> 00:01:07,500
and some instructions to follow you spin

28
00:01:07,500 --> 00:01:08,820
it one time

29
00:01:08,820 --> 00:01:10,619
if it stands on B you should tell me

30
00:01:10,619 --> 00:01:13,140
your truthful answer if it stands on a

31
00:01:13,140 --> 00:01:15,479
you should experience again

32
00:01:15,479 --> 00:01:18,000
this time if it descends on a it should

33
00:01:18,000 --> 00:01:19,260
tell me that you prefer cheating

34
00:01:19,260 --> 00:01:21,299
otherwise you should tell me that you

35
00:01:21,299 --> 00:01:23,700
preferred hard work regardless of your

36
00:01:23,700 --> 00:01:26,460
truthful answer to the question

37
00:01:26,460 --> 00:01:29,100
not knowing about how each of your

38
00:01:29,100 --> 00:01:31,439
Spinners land would I be able to

39
00:01:31,439 --> 00:01:33,299
distinguish whether your answer to the

40
00:01:33,299 --> 00:01:35,400
question is your truthful answer

41
00:01:35,400 --> 00:01:36,659
of course not

42
00:01:36,659 --> 00:01:38,880
you can deny that the answer is a true

43
00:01:38,880 --> 00:01:39,840
answer

44
00:01:39,840 --> 00:01:42,240
I would benefit from what I achieved if

45
00:01:42,240 --> 00:01:44,520
I received a large number of answers

46
00:01:44,520 --> 00:01:46,380
and I would get insights on how many

47
00:01:46,380 --> 00:01:48,659
approximately prefer hard work for

48
00:01:48,659 --> 00:01:49,560
example

49
00:01:49,560 --> 00:01:51,420
this technique is randomized response

50
00:01:51,420 --> 00:01:54,600
technique and ants and this randomized

51
00:01:54,600 --> 00:01:55,520
process

52
00:01:55,520 --> 00:01:57,360
satisfies differential privacy

53
00:01:57,360 --> 00:01:59,820
abbreviated at DP because the

54
00:01:59,820 --> 00:02:01,680
distribution of the output is

55
00:02:01,680 --> 00:02:03,720
insensitive to changes in one

56
00:02:03,720 --> 00:02:06,600
individual's user's input in our work we

57
00:02:06,600 --> 00:02:08,340
use the spinner as a metaphor for local

58
00:02:08,340 --> 00:02:11,038
differential privacy

59
00:02:11,038 --> 00:02:12,959
differentially private mechanisms can be

60
00:02:12,959 --> 00:02:14,819
implemented as local and Central models

61
00:02:14,819 --> 00:02:17,040
in central models we have a trusted data

62
00:02:17,040 --> 00:02:18,060
aggregator

63
00:02:18,060 --> 00:02:20,340
in local models however users do not

64
00:02:20,340 --> 00:02:22,500
need to trust the entity responsible for

65
00:02:22,500 --> 00:02:24,900
analysis because the data get perturbed

66
00:02:24,900 --> 00:02:26,819
before being shared

67
00:02:26,819 --> 00:02:28,620
although the information disclose your

68
00:02:28,620 --> 00:02:30,660
risks substantially differ between these

69
00:02:30,660 --> 00:02:32,940
two models in communicating with users

70
00:02:32,940 --> 00:02:35,280
industry and media Alpha DP descriptions

71
00:02:35,280 --> 00:02:37,500
do not clearly distinguish between the

72
00:02:37,500 --> 00:02:40,379
models as reported in literature however

73
00:02:40,379 --> 00:02:42,900
in our work we distinguished between the

74
00:02:42,900 --> 00:02:45,060
local and Central models and and we

75
00:02:45,060 --> 00:02:47,640
defined uh three different data analysis

76
00:02:47,640 --> 00:02:50,099
scenarios in the context of e-health one

77
00:02:50,099 --> 00:02:52,620
for local model in scenario one and two

78
00:02:52,620 --> 00:02:54,540
aggregate level scenarios scenario two

79
00:02:54,540 --> 00:02:56,879
and three including DP for Federated

80
00:02:56,879 --> 00:02:59,299
learning

81
00:02:59,580 --> 00:03:01,800
for scenario 1 we chose the metaphor of

82
00:03:01,800 --> 00:03:03,959
an easy picture showing different levels

83
00:03:03,959 --> 00:03:06,540
of added noise with different degrees of

84
00:03:06,540 --> 00:03:10,319
fixation and we also as I said use the

85
00:03:10,319 --> 00:03:12,239
spinner metaphor with different levels

86
00:03:12,239 --> 00:03:14,840
of perturbation

87
00:03:15,060 --> 00:03:17,700
for scenario 2 a noisy combined picture

88
00:03:17,700 --> 00:03:19,680
metaphor was used to convey that noise

89
00:03:19,680 --> 00:03:21,959
is added to aggregated data and not

90
00:03:21,959 --> 00:03:24,300
directly to individual recourse for

91
00:03:24,300 --> 00:03:27,180
example here user selfies

92
00:03:27,180 --> 00:03:29,459
for scenario 3 we use the distorted

93
00:03:29,459 --> 00:03:31,739
brain for which some of the neural

94
00:03:31,739 --> 00:03:34,440
connections uh are grayed out as a

95
00:03:34,440 --> 00:03:36,000
metaphor of a differentially private

96
00:03:36,000 --> 00:03:38,540
trained model

97
00:03:39,060 --> 00:03:41,280
our approach to reach our objective in

98
00:03:41,280 --> 00:03:42,780
this work is based on a three-phase

99
00:03:42,780 --> 00:03:45,120
framework in the first two phases we

100
00:03:45,120 --> 00:03:46,860
generated an analytically evaluated

101
00:03:46,860 --> 00:03:48,959
Armature force in the third phase we

102
00:03:48,959 --> 00:03:50,819
empirically evaluated our metaphors in

103
00:03:50,819 --> 00:03:53,580
online interviews with lay users for the

104
00:03:53,580 --> 00:03:55,500
details of the first two phases please

105
00:03:55,500 --> 00:03:58,319
refer to the paper I will focus on our

106
00:03:58,319 --> 00:03:59,640
interviews in the rest of this

107
00:03:59,640 --> 00:04:02,179
presentation

108
00:04:02,879 --> 00:04:05,040
we had to research question to address

109
00:04:05,040 --> 00:04:07,200
in our interviews the first one what

110
00:04:07,200 --> 00:04:09,239
information is required by users to

111
00:04:09,239 --> 00:04:12,120
decide about using DP enabled systems

112
00:04:12,120 --> 00:04:14,400
question two what are users perception

113
00:04:14,400 --> 00:04:16,620
of privacy provided by the proposed

114
00:04:16,620 --> 00:04:17,880
metaphors

115
00:04:17,880 --> 00:04:20,459
and question three what's the extent of

116
00:04:20,459 --> 00:04:22,500
suitability of our metaphors to convey

117
00:04:22,500 --> 00:04:25,620
DP to users

118
00:04:25,620 --> 00:04:28,080
we conducted 30 online interviews 10 for

119
00:04:28,080 --> 00:04:30,360
each scenario via Zoom we let users be

120
00:04:30,360 --> 00:04:32,580
recreated by a prolific platform the

121
00:04:32,580 --> 00:04:34,320
main session of our interviews had to

122
00:04:34,320 --> 00:04:36,780
parse in the first part we introduced

123
00:04:36,780 --> 00:04:38,160
the scenario and conveyed to the

124
00:04:38,160 --> 00:04:39,720
interviewees that the Privacy technique

125
00:04:39,720 --> 00:04:42,000
based on GP would protect their privates

126
00:04:42,000 --> 00:04:44,940
over their privacy under data but we

127
00:04:44,940 --> 00:04:47,040
didn't reveal in detail on GP and then

128
00:04:47,040 --> 00:04:48,780
we investigated the expectation and

129
00:04:48,780 --> 00:04:49,919
opinions

130
00:04:49,919 --> 00:04:51,960
in the second part we exposed them to

131
00:04:51,960 --> 00:04:53,460
the related metaphor for the scenario

132
00:04:53,460 --> 00:04:56,340
and explore the perceptions and opinions

133
00:04:56,340 --> 00:04:57,900
of the metaphor

134
00:04:57,900 --> 00:05:01,320
13 identify themselves as female 16 as

135
00:05:01,320 --> 00:05:03,000
male and one didn't answer the

136
00:05:03,000 --> 00:05:05,699
demographic questions our interview is

137
00:05:05,699 --> 00:05:07,860
very relatively young and had diverse

138
00:05:07,860 --> 00:05:10,259
academic backgrounds our participants

139
00:05:10,259 --> 00:05:12,060
were not generally knowledgeable about

140
00:05:12,060 --> 00:05:14,340
privacy enhancing Technologies and

141
00:05:14,340 --> 00:05:16,139
hadn't heard about GP before the

142
00:05:16,139 --> 00:05:18,720
interviews meaning they were non-experts

143
00:05:18,720 --> 00:05:21,000
in privacy for the details of the study

144
00:05:21,000 --> 00:05:22,800
design sampling and recruitment please

145
00:05:22,800 --> 00:05:25,340
refer to the paper

146
00:05:25,340 --> 00:05:28,080
arithmetic analysis resulted in 12 main

147
00:05:28,080 --> 00:05:30,720
teams the first four themes are pretty

148
00:05:30,720 --> 00:05:33,539
explanation before exposure to the

149
00:05:33,539 --> 00:05:36,180
metaphor and the rest are

150
00:05:36,180 --> 00:05:38,400
post-explanation themes I will highlight

151
00:05:38,400 --> 00:05:40,020
some of the important results based on

152
00:05:40,020 --> 00:05:42,060
our research questions please refer to

153
00:05:42,060 --> 00:05:43,680
the paper for the details of the themes

154
00:05:43,680 --> 00:05:46,320
and complete results

155
00:05:46,320 --> 00:05:48,060
the team's addressing research question

156
00:05:48,060 --> 00:05:50,280
1 highlights information needed for

157
00:05:50,280 --> 00:05:52,320
trusting DP neighbor systems and sharing

158
00:05:52,320 --> 00:05:54,840
data research systems by data subjects

159
00:05:54,840 --> 00:05:57,120
the results show that the mere presence

160
00:05:57,120 --> 00:05:59,160
of the Privacy technology is seemingly

161
00:05:59,160 --> 00:06:00,960
enough to persuade users to share their

162
00:06:00,960 --> 00:06:04,320
data however lack of transparency about

163
00:06:04,320 --> 00:06:06,479
differential privacy leads to varied

164
00:06:06,479 --> 00:06:08,820
expectation and interpretations of who

165
00:06:08,820 --> 00:06:11,699
gets access to actual raw data and also

166
00:06:11,699 --> 00:06:13,620
to different correct or incorrect

167
00:06:13,620 --> 00:06:17,039
assumptions about DP and leads to

168
00:06:17,039 --> 00:06:19,080
negative impacts on willingness to share

169
00:06:19,080 --> 00:06:21,120
date of it and Trust in DP enabled

170
00:06:21,120 --> 00:06:21,960
systems

171
00:06:21,960 --> 00:06:24,060
most participants required usable

172
00:06:24,060 --> 00:06:26,460
transparency of DP for example to know

173
00:06:26,460 --> 00:06:29,280
how DP Works how it protects and uses

174
00:06:29,280 --> 00:06:31,319
personal data and to know about the

175
00:06:31,319 --> 00:06:34,400
risks of identifications

176
00:06:34,560 --> 00:06:36,539
the team's addressing registration two

177
00:06:36,539 --> 00:06:38,520
and three reveal uses perception about

178
00:06:38,520 --> 00:06:40,919
the claim data protection of DP and

179
00:06:40,919 --> 00:06:42,380
their understanding of its different

180
00:06:42,380 --> 00:06:45,240
privacy features employed or conveyed by

181
00:06:45,240 --> 00:06:47,880
our metaphors in some participants

182
00:06:47,880 --> 00:06:49,620
correctly perceived that perturbation

183
00:06:49,620 --> 00:06:51,900
leads to privacy protection they also

184
00:06:51,900 --> 00:06:53,400
understood to varying degrees in all

185
00:06:53,400 --> 00:06:55,080
scenarios the perturbation protects

186
00:06:55,080 --> 00:06:57,660
against identifiability and provides

187
00:06:57,660 --> 00:07:01,080
plausible deniability however in all

188
00:07:01,080 --> 00:07:02,759
scenarios most of the participants

189
00:07:02,759 --> 00:07:04,199
understood the trade-off between

190
00:07:04,199 --> 00:07:06,600
accuracy and privacy protection

191
00:07:06,600 --> 00:07:09,180
an analysis of users a perception of

192
00:07:09,180 --> 00:07:11,580
privacy features of JP revealed several

193
00:07:11,580 --> 00:07:14,160
misconceptions as well people also had

194
00:07:14,160 --> 00:07:16,199
varied perceptions about protection

195
00:07:16,199 --> 00:07:17,940
against adversaries with auxiliary

196
00:07:17,940 --> 00:07:18,860
information

197
00:07:18,860 --> 00:07:21,180
preferences for the level of distortion

198
00:07:21,180 --> 00:07:23,699
and acceptance of and perceptions about

199
00:07:23,699 --> 00:07:28,099
remaining risk across all scenarios

200
00:07:28,560 --> 00:07:31,500
so let's see what misconceptions were

201
00:07:31,500 --> 00:07:33,479
the only common misconception among all

202
00:07:33,479 --> 00:07:34,979
scenarios was the perception of noise

203
00:07:34,979 --> 00:07:36,479
addition or perturbation being

204
00:07:36,479 --> 00:07:39,180
reversible however in scenario 1 the

205
00:07:39,180 --> 00:07:41,220
reversibility of DP was triggered by the

206
00:07:41,220 --> 00:07:44,520
by the uh no easy picture metaphor and

207
00:07:44,520 --> 00:07:46,259
not by the spinner metaphor

208
00:07:46,259 --> 00:07:48,120
other misconceptions include the

209
00:07:48,120 --> 00:07:50,039
perception of DP enabling selective

210
00:07:50,039 --> 00:07:51,840
disclosure and the perception of

211
00:07:51,840 --> 00:07:55,259
perturbation on an individual records uh

212
00:07:55,259 --> 00:07:57,000
instead of on aggregate level in

213
00:07:57,000 --> 00:07:59,580
scenario two and three further there was

214
00:07:59,580 --> 00:08:02,280
a perception that aggregation uh

215
00:08:02,280 --> 00:08:04,500
provides enough privacy

216
00:08:04,500 --> 00:08:06,660
in scenario one based on the noisy

217
00:08:06,660 --> 00:08:08,580
picture metaphor the description was

218
00:08:08,580 --> 00:08:10,259
taken literally and led to the

219
00:08:10,259 --> 00:08:12,800
perception of distortion as pixelation

220
00:08:12,800 --> 00:08:16,860
pixelation of data or the Mosaic classic

221
00:08:16,860 --> 00:08:19,740
music censorship further it led to the

222
00:08:19,740 --> 00:08:22,500
perception of DP as encryption in

223
00:08:22,500 --> 00:08:24,840
scenario 2 it was assumed that how DP

224
00:08:24,840 --> 00:08:27,360
works for the secret which led to the

225
00:08:27,360 --> 00:08:29,039
misconception that knowledge of DP by

226
00:08:29,039 --> 00:08:31,979
someone could reveal information about

227
00:08:31,979 --> 00:08:34,020
individuals if that person acts as

228
00:08:34,020 --> 00:08:35,640
differentially private results of an

229
00:08:35,640 --> 00:08:37,500
analysis

230
00:08:37,500 --> 00:08:39,779
our results revealed in general that

231
00:08:39,779 --> 00:08:42,000
misconceptions impact trust perception

232
00:08:42,000 --> 00:08:43,919
of access to data and willingness to

233
00:08:43,919 --> 00:08:48,020
share data with DP enabled systems

234
00:08:49,320 --> 00:08:51,120
our interview results showed the

235
00:08:51,120 --> 00:08:52,740
plausible suitability of our metaphors

236
00:08:52,740 --> 00:08:55,260
each to a varying degree to convey the

237
00:08:55,260 --> 00:08:57,660
Privacy features of dp2lay users I

238
00:08:57,660 --> 00:08:59,459
recommend that interested audience to

239
00:08:59,459 --> 00:09:02,760
like to take a look at table 2 in the

240
00:09:02,760 --> 00:09:04,920
paper which summarizes the extent of the

241
00:09:04,920 --> 00:09:07,680
suitability of our metaphors at the same

242
00:09:07,680 --> 00:09:09,720
time our study rebuilds and confirms

243
00:09:09,720 --> 00:09:11,580
several challenges that require further

244
00:09:11,580 --> 00:09:13,860
attention if we intend to use metaphors

245
00:09:13,860 --> 00:09:16,500
I highlight some of the challenges and

246
00:09:16,500 --> 00:09:18,540
recommendations here however please

247
00:09:18,540 --> 00:09:20,459
refer to the paper for a complete

248
00:09:20,459 --> 00:09:21,720
discussion on challenges and

249
00:09:21,720 --> 00:09:22,980
recommendations

250
00:09:22,980 --> 00:09:25,140
based on our results we recommend future

251
00:09:25,140 --> 00:09:26,700
research on the effects of DP

252
00:09:26,700 --> 00:09:28,740
explanations that emphasize the

253
00:09:28,740 --> 00:09:30,839
reduction of identification risks rather

254
00:09:30,839 --> 00:09:32,940
than the feature of accuracy loss when

255
00:09:32,940 --> 00:09:34,620
explaining GP to different groups of

256
00:09:34,620 --> 00:09:38,279
users in addition users should be guided

257
00:09:38,279 --> 00:09:41,160
regarding adequate identification risks

258
00:09:41,160 --> 00:09:44,459
per context and the implications

259
00:09:44,459 --> 00:09:46,680
misconceptions about DP are likely

260
00:09:46,680 --> 00:09:48,660
triggered by the participant's knowledge

261
00:09:48,660 --> 00:09:51,060
of security Technologies for instance

262
00:09:51,060 --> 00:09:52,920
two of the participants who were

263
00:09:52,920 --> 00:09:55,200
familiar with vpns and their feature of

264
00:09:55,200 --> 00:09:57,540
hiding IP addresses perceived DP as

265
00:09:57,540 --> 00:09:59,399
selectively hiding data

266
00:09:59,399 --> 00:10:01,680
hence besides considering real world

267
00:10:01,680 --> 00:10:04,019
analogies DP metaphors should address

268
00:10:04,019 --> 00:10:05,760
the challenge of catering for digital

269
00:10:05,760 --> 00:10:09,060
world analogies that users may make

270
00:10:09,060 --> 00:10:12,000
metaphorical explanations inherently

271
00:10:12,000 --> 00:10:14,220
suffer from several shortcomings that we

272
00:10:14,220 --> 00:10:17,339
need to consider and counteract when we

273
00:10:17,339 --> 00:10:20,279
use metaphors to explain uh privacy

274
00:10:20,279 --> 00:10:22,380
Technologies to users for example half

275
00:10:22,380 --> 00:10:24,180
of our participants in scenario one

276
00:10:24,180 --> 00:10:26,100
prefer to be exposed to the spinner

277
00:10:26,100 --> 00:10:28,019
metaphor because they assumed it

278
00:10:28,019 --> 00:10:29,880
provided a better privacy accuracy

279
00:10:29,880 --> 00:10:31,920
trade-off compared to the noisy picture

280
00:10:31,920 --> 00:10:34,760
metaphor the diverse levels of

281
00:10:34,760 --> 00:10:36,839
abstractions as a result of using

282
00:10:36,839 --> 00:10:39,240
different metaphors May impose the risk

283
00:10:39,240 --> 00:10:41,279
of different or perhaps inaccurate

284
00:10:41,279 --> 00:10:43,440
perceptions of privacy protection

285
00:10:43,440 --> 00:10:45,420
completing metaphors with suitable

286
00:10:45,420 --> 00:10:47,640
additional information can be one way to

287
00:10:47,640 --> 00:10:50,839
counteract these shortcomings

288
00:10:54,300 --> 00:10:56,640
thanks a lot for listening to me if you

289
00:10:56,640 --> 00:10:58,440
have any questions I'd be happy to

290
00:10:58,440 --> 00:11:02,899
answer you can also contact me via email

