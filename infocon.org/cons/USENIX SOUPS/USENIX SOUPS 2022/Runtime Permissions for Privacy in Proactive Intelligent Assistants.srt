1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:10,040 --> 00:00:12,780
I'll be talking to you about the privacy

3
00:00:12,780 --> 00:00:15,260
of a product that does not exist yet

4
00:00:15,260 --> 00:00:18,300
proactive intelligent assistance

5
00:00:18,300 --> 00:00:19,859
well I guess it sort of doesn't exist

6
00:00:19,859 --> 00:00:22,380
what I actually have in mind are voice

7
00:00:22,380 --> 00:00:25,320
assistants like Alexa or Siri if you're

8
00:00:25,320 --> 00:00:26,760
like half of Americans you have one of

9
00:00:26,760 --> 00:00:28,560
these at home and even if you don't you

10
00:00:28,560 --> 00:00:29,939
probably have a pretty good mental model

11
00:00:29,939 --> 00:00:31,980
for how they work you start with a wake

12
00:00:31,980 --> 00:00:33,840
word and then follow that up with a

13
00:00:33,840 --> 00:00:36,120
command or a question

14
00:00:36,120 --> 00:00:38,880
but this trigger-based nature of these

15
00:00:38,880 --> 00:00:41,040
assistants is starting to change just a

16
00:00:41,040 --> 00:00:42,480
couple of months ago Google announced

17
00:00:42,480 --> 00:00:44,640
that the Wake words will actually be

18
00:00:44,640 --> 00:00:47,040
optional in certain circumstances

19
00:00:47,040 --> 00:00:49,320
Alexa isn't far behind and they're also

20
00:00:49,320 --> 00:00:50,760
working on making their assistant more

21
00:00:50,760 --> 00:00:52,260
proactive

22
00:00:52,260 --> 00:00:54,480
what does proactive actually mean well

23
00:00:54,480 --> 00:00:57,960
we envisioned that in the future we that

24
00:00:57,960 --> 00:01:00,120
assistance might get as far as what

25
00:01:00,120 --> 00:01:02,579
we've called passive listening ambiently

26
00:01:02,579 --> 00:01:04,440
analyzing all audio and all

27
00:01:04,440 --> 00:01:06,600
conversations in order to be able to

28
00:01:06,600 --> 00:01:08,700
answer queries on demand or even provide

29
00:01:08,700 --> 00:01:09,960
suggestions

30
00:01:09,960 --> 00:01:12,119
practically

31
00:01:12,119 --> 00:01:14,580
this naturally requires continuous

32
00:01:14,580 --> 00:01:16,080
listening and that of course raises

33
00:01:16,080 --> 00:01:17,820
privacy concerns and so the research

34
00:01:17,820 --> 00:01:19,860
question motivating our work was to try

35
00:01:19,860 --> 00:01:21,900
to understand how can we provide the

36
00:01:21,900 --> 00:01:23,939
maximal Privacy protection for users who

37
00:01:23,939 --> 00:01:26,820
do adopt these proactive devices

38
00:01:26,820 --> 00:01:28,619
one type of privacy controls that we're

39
00:01:28,619 --> 00:01:30,119
all pretty familiar with is mute buttons

40
00:01:30,119 --> 00:01:32,100
but research has shown that people tend

41
00:01:32,100 --> 00:01:34,140
to be reluctant to use those and more

42
00:01:34,140 --> 00:01:35,939
generally these sorts of controls tend

43
00:01:35,939 --> 00:01:38,100
to be All or Nothing whereas when we're

44
00:01:38,100 --> 00:01:40,200
talking about these proactive features

45
00:01:40,200 --> 00:01:41,520
it would be nice to have something

46
00:01:41,520 --> 00:01:43,380
that's a bit more granular

47
00:01:43,380 --> 00:01:45,360
however permissions are a pretty good

48
00:01:45,360 --> 00:01:48,119
start and in fact existing assistants do

49
00:01:48,119 --> 00:01:50,040
already make use of these permissions

50
00:01:50,040 --> 00:01:52,500
for example if you have an Alexa

51
00:01:52,500 --> 00:01:54,899
if you go to install a skill that's

52
00:01:54,899 --> 00:01:57,299
considered sensitive it will ask you to

53
00:01:57,299 --> 00:01:59,220
approve it through one of these screens

54
00:01:59,220 --> 00:02:00,780
if this interface is looking a little

55
00:02:00,780 --> 00:02:01,979
bit familiar

56
00:02:01,979 --> 00:02:03,600
because you've

57
00:02:03,600 --> 00:02:05,219
done this different content in this

58
00:02:05,219 --> 00:02:06,600
different context for example when

59
00:02:06,600 --> 00:02:09,598
installing apps for your Android phone a

60
00:02:09,598 --> 00:02:10,739
few years ago

61
00:02:10,739 --> 00:02:13,200
and that is actually a bit of an issue

62
00:02:13,200 --> 00:02:14,879
because a lot of research coming out of

63
00:02:14,879 --> 00:02:15,959
this community has shown that install

64
00:02:15,959 --> 00:02:18,000
time permissions aren't very effective

65
00:02:18,000 --> 00:02:20,099
people struggle to understand them and

66
00:02:20,099 --> 00:02:21,959
often just don't pay attention to them

67
00:02:21,959 --> 00:02:24,060
that's why in smartphones they have been

68
00:02:24,060 --> 00:02:26,040
largely supplanted by runtime

69
00:02:26,040 --> 00:02:27,840
permissions and it's possible that these

70
00:02:27,840 --> 00:02:29,340
would work better for voice assistants

71
00:02:29,340 --> 00:02:30,959
as well but it's a little bit harder to

72
00:02:30,959 --> 00:02:32,700
imagine how that would work

73
00:02:32,700 --> 00:02:35,040
especially if this isn't Super Active

74
00:02:35,040 --> 00:02:36,780
and so answering that question was the

75
00:02:36,780 --> 00:02:39,120
focus of our study

76
00:02:39,120 --> 00:02:40,680
one of the challenges of our research

77
00:02:40,680 --> 00:02:42,959
was that proactive assistants today look

78
00:02:42,959 --> 00:02:45,840
less like this and more like this

79
00:02:45,840 --> 00:02:47,700
and so to address this problem what we

80
00:02:47,700 --> 00:02:51,000
did was we implemented our own proactive

81
00:02:51,000 --> 00:02:53,280
always listening assistant

82
00:02:53,280 --> 00:02:55,140
we were inspired by smart displays and

83
00:02:55,140 --> 00:02:56,519
how it worked but what it actually

84
00:02:56,519 --> 00:02:57,720
looked like for our participants was

85
00:02:57,720 --> 00:02:59,220
more like this because we constructed

86
00:02:59,220 --> 00:03:01,019
this study remotely and so what they saw

87
00:03:01,019 --> 00:03:02,519
was a window that was being shared with

88
00:03:02,519 --> 00:03:03,660
them over Zoom

89
00:03:03,660 --> 00:03:05,519
the way this worked was that we asked

90
00:03:05,519 --> 00:03:06,900
people to have a conversation and we

91
00:03:06,900 --> 00:03:08,340
invited participants into pairs so they

92
00:03:08,340 --> 00:03:10,200
would have someone to talk to and as

93
00:03:10,200 --> 00:03:11,700
they talked if the assistant was able to

94
00:03:11,700 --> 00:03:13,620
offer proactive suggestions they showed

95
00:03:13,620 --> 00:03:17,060
up on the screen visually

96
00:03:17,060 --> 00:03:19,980
but before any of these suggestions

97
00:03:19,980 --> 00:03:22,080
could show up the assistant had to ask

98
00:03:22,080 --> 00:03:23,220
for permission

99
00:03:23,220 --> 00:03:25,140
the way this worked was a dialogue such

100
00:03:25,140 --> 00:03:27,060
as this would pop up and it would

101
00:03:27,060 --> 00:03:28,560
identify the particular feature that

102
00:03:28,560 --> 00:03:31,560
wanted access as well as specific text

103
00:03:31,560 --> 00:03:33,360
transcribed from audio about what was

104
00:03:33,360 --> 00:03:35,340
being accessed and then the user had to

105
00:03:35,340 --> 00:03:38,220
say allow or deny to address this

106
00:03:38,220 --> 00:03:40,739
request assuming the user allowed this

107
00:03:40,739 --> 00:03:42,659
only then with the specific suggestions

108
00:03:42,659 --> 00:03:43,860
show up

109
00:03:43,860 --> 00:03:45,599
if you're wondering by the way what cool

110
00:03:45,599 --> 00:03:47,819
AI process we use to generate these

111
00:03:47,819 --> 00:03:49,620
suggestions I got to inform you that

112
00:03:49,620 --> 00:03:50,760
this was a much more old-fashioned

113
00:03:50,760 --> 00:03:52,500
technique called Wizard of Oz and it was

114
00:03:52,500 --> 00:03:54,120
me on the other side of the connection

115
00:03:54,120 --> 00:03:55,860
trying really fast to come up with

116
00:03:55,860 --> 00:03:58,019
suggestions for our participants

117
00:03:58,019 --> 00:03:59,940
clearly that resulted in some sort of

118
00:03:59,940 --> 00:04:02,040
lag before they come up and this was

119
00:04:02,040 --> 00:04:03,239
probably not good enough for real

120
00:04:03,239 --> 00:04:04,560
product but it worked surprisingly well

121
00:04:04,560 --> 00:04:06,599
for a study that aimed to elicit

122
00:04:06,599 --> 00:04:09,180
attitudes

123
00:04:09,180 --> 00:04:11,340
in the system I sketched out for you so

124
00:04:11,340 --> 00:04:13,500
far these permission requests would come

125
00:04:13,500 --> 00:04:16,380
at every point of data access

126
00:04:16,380 --> 00:04:18,779
and over the course of conversation that

127
00:04:18,779 --> 00:04:21,060
adds up and as you can imagine that's

128
00:04:21,060 --> 00:04:22,979
going to be pretty annoying

129
00:04:22,979 --> 00:04:24,720
we anticipated that and so what we

130
00:04:24,720 --> 00:04:26,759
really wanted to study was some other

131
00:04:26,759 --> 00:04:28,080
modes that we thought it would be less

132
00:04:28,080 --> 00:04:29,160
interrupting

133
00:04:29,160 --> 00:04:31,680
the first one is one we called learning

134
00:04:31,680 --> 00:04:33,180
where the permission request looks

135
00:04:33,180 --> 00:04:35,100
exactly the same but what was different

136
00:04:35,100 --> 00:04:36,540
is that you'd only see a couple of them

137
00:04:36,540 --> 00:04:39,720
and they then you'd see none or fewer

138
00:04:39,720 --> 00:04:41,820
and that's because what we're trying to

139
00:04:41,820 --> 00:04:44,580
simulate is the work of privacy

140
00:04:44,580 --> 00:04:47,100
assistance which is a topic that folks

141
00:04:47,100 --> 00:04:49,500
here have studied where they look at

142
00:04:49,500 --> 00:04:51,419
your decisions and then learn from them

143
00:04:51,419 --> 00:04:53,940
and then in the future they can emulate

144
00:04:53,940 --> 00:04:57,440
your privacy decisions for you

145
00:04:57,479 --> 00:04:59,759
the other approach that we tested was

146
00:04:59,759 --> 00:05:02,520
when we called rules and this was meant

147
00:05:02,520 --> 00:05:04,320
to emulate a bit more closely that ascon

148
00:05:04,320 --> 00:05:06,540
first use model that smartphones use

149
00:05:06,540 --> 00:05:08,580
where you can always allow or always

150
00:05:08,580 --> 00:05:10,500
deny access

151
00:05:10,500 --> 00:05:12,960
in both cases the access was scoped to a

152
00:05:12,960 --> 00:05:14,520
particular feature type so you have

153
00:05:14,520 --> 00:05:15,600
different types of permissions for

154
00:05:15,600 --> 00:05:17,880
recipes for example and for accessing

155
00:05:17,880 --> 00:05:19,860
the weather and other types

156
00:05:19,860 --> 00:05:21,960
also all of our participants saw all

157
00:05:21,960 --> 00:05:24,780
three types of all three of these modes

158
00:05:24,780 --> 00:05:26,880
so that we could ask them to compare

159
00:05:26,880 --> 00:05:28,199
their experiences and see which one they

160
00:05:28,199 --> 00:05:30,479
preferred

161
00:05:30,479 --> 00:05:32,039
or in this particular study we recruited

162
00:05:32,039 --> 00:05:33,840
23 pairs of participants from Craigslist

163
00:05:33,840 --> 00:05:36,479
we try to balance our sample some

164
00:05:36,479 --> 00:05:39,000
demographics as well as making sure we

165
00:05:39,000 --> 00:05:41,160
had both current users and non-users of

166
00:05:41,160 --> 00:05:42,960
voice assistants

167
00:05:42,960 --> 00:05:45,479
we found that reactions to these

168
00:05:45,479 --> 00:05:47,759
proactive systems were pretty positive

169
00:05:47,759 --> 00:05:49,620
and that stands in contrast to some of

170
00:05:49,620 --> 00:05:50,880
our earlier work on the same subject

171
00:05:50,880 --> 00:05:52,740
where people expressed an understandable

172
00:05:52,740 --> 00:05:54,419
hesitance about having an always

173
00:05:54,419 --> 00:05:55,620
listening device

174
00:05:55,620 --> 00:05:58,680
we think this is partially artifact of

175
00:05:58,680 --> 00:06:00,780
the sample because we recruited people

176
00:06:00,780 --> 00:06:02,940
who were willing to be interviewed and

177
00:06:02,940 --> 00:06:04,800
recorded talking about Voice assistance

178
00:06:04,800 --> 00:06:07,199
but we also think it reflects a gradual

179
00:06:07,199 --> 00:06:09,419
shift in acceptance of always on

180
00:06:09,419 --> 00:06:11,280
microphones

181
00:06:11,280 --> 00:06:14,220
in terms of the way people use

182
00:06:14,220 --> 00:06:15,419
permissions and the concerns they

183
00:06:15,419 --> 00:06:18,660
expressed these focused primarily they

184
00:06:18,660 --> 00:06:20,520
focused Less on the always listening

185
00:06:20,520 --> 00:06:22,199
nature of the devices and more on the

186
00:06:22,199 --> 00:06:23,940
proactive behaviors and their

187
00:06:23,940 --> 00:06:25,620
consequences

188
00:06:25,620 --> 00:06:27,539
well we know that privacy is contextual

189
00:06:27,539 --> 00:06:29,460
in terms of the concerns people

190
00:06:29,460 --> 00:06:31,800
articulated most of them focused on what

191
00:06:31,800 --> 00:06:33,539
I would call Standard sensitive data

192
00:06:33,539 --> 00:06:35,940
types things like financial information

193
00:06:35,940 --> 00:06:38,160
but again with a

194
00:06:38,160 --> 00:06:40,979
emphasis on consequences so less a

195
00:06:40,979 --> 00:06:42,600
concern that the assistant might hear

196
00:06:42,600 --> 00:06:45,000
your credit card number and more worry

197
00:06:45,000 --> 00:06:47,220
that it would make a purchase on your

198
00:06:47,220 --> 00:06:49,620
behalf that you didn't actually approve

199
00:06:49,620 --> 00:06:51,120
another area of concern was

200
00:06:51,120 --> 00:06:53,639
interpersonal data things like gossip or

201
00:06:53,639 --> 00:06:55,500
relationship secrets

202
00:06:55,500 --> 00:06:57,539
and because of this when we asked

203
00:06:57,539 --> 00:06:59,100
participants about the controls they

204
00:06:59,100 --> 00:07:00,960
wanted to see in these devices one thing

205
00:07:00,960 --> 00:07:02,100
that came up frequently and

206
00:07:02,100 --> 00:07:03,720
independently was the use of voice

207
00:07:03,720 --> 00:07:05,940
recognition to distinguished speakers

208
00:07:05,940 --> 00:07:07,740
and make sure that the assistant was

209
00:07:07,740 --> 00:07:09,780
only delivering information to the owner

210
00:07:09,780 --> 00:07:12,360
of that data rather than to someone else

211
00:07:12,360 --> 00:07:14,160
along similar lines we had a number of

212
00:07:14,160 --> 00:07:15,479
parents in our sample and they

213
00:07:15,479 --> 00:07:16,680
highlighted the need for parental

214
00:07:16,680 --> 00:07:19,259
controls which would range from either

215
00:07:19,259 --> 00:07:21,300
complete denial of access to prevent

216
00:07:21,300 --> 00:07:23,280
toddlers for example from spamming

217
00:07:23,280 --> 00:07:25,319
everyone with notifications all the way

218
00:07:25,319 --> 00:07:28,979
to gentler controls uh to make sure that

219
00:07:28,979 --> 00:07:31,319
kids got age-appropriate content

220
00:07:31,319 --> 00:07:33,060
and I also want to mention that a lot of

221
00:07:33,060 --> 00:07:34,319
these findings are pretty consistent

222
00:07:34,319 --> 00:07:36,960
with work that a lot of people in our

223
00:07:36,960 --> 00:07:39,419
community have found on

224
00:07:39,419 --> 00:07:42,060
interpersonal privacy in Smart Homes and

225
00:07:42,060 --> 00:07:44,360
Beyond

226
00:07:45,360 --> 00:07:47,280
themselves we found that they were

227
00:07:47,280 --> 00:07:49,860
pretty effective at stopping misbehavior

228
00:07:49,860 --> 00:07:52,500
specifically when the assistant tried to

229
00:07:52,500 --> 00:07:55,080
request access to information that was

230
00:07:55,080 --> 00:07:56,580
not relevant to a particular feature

231
00:07:56,580 --> 00:07:58,919
which we insured happened at least a

232
00:07:58,919 --> 00:08:00,900
couple times for each participant people

233
00:08:00,900 --> 00:08:02,940
tended to deny those requests whereas in

234
00:08:02,940 --> 00:08:04,860
contrast they allowed most other

235
00:08:04,860 --> 00:08:07,259
requests in our study

236
00:08:07,259 --> 00:08:09,240
more subjectively when we integrated

237
00:08:09,240 --> 00:08:12,300
participants about the permissions that

238
00:08:12,300 --> 00:08:15,479
they tried we found that they said that

239
00:08:15,479 --> 00:08:17,580
they provided a sense of control and

240
00:08:17,580 --> 00:08:19,259
that they felt they had ownership of the

241
00:08:19,259 --> 00:08:20,580
system because of that and that's

242
00:08:20,580 --> 00:08:22,319
something they appreciated

243
00:08:22,319 --> 00:08:24,720
on the other hand most people also found

244
00:08:24,720 --> 00:08:26,280
that these protections were not

245
00:08:26,280 --> 00:08:28,560
sufficient on their own when we pose the

246
00:08:28,560 --> 00:08:30,900
scenario where you were talking about

247
00:08:30,900 --> 00:08:32,640
something you really didn't want this

248
00:08:32,640 --> 00:08:34,500
system to hear

249
00:08:34,500 --> 00:08:36,360
most people said that the protection

250
00:08:36,360 --> 00:08:38,159
provided by permissions wasn't

251
00:08:38,159 --> 00:08:40,200
sufficient to ensure their confidence

252
00:08:40,200 --> 00:08:42,539
and instead they would approach other

253
00:08:42,539 --> 00:08:45,240
other lower Tech approaches like leaving

254
00:08:45,240 --> 00:08:48,660
the room or unplugging the device

255
00:08:48,660 --> 00:08:50,760
as we expected our less interrupting

256
00:08:50,760 --> 00:08:52,860
conditions were received much more

257
00:08:52,860 --> 00:08:55,680
positively than the ones that asked for

258
00:08:55,680 --> 00:08:57,360
permission every single time it needed

259
00:08:57,360 --> 00:08:59,399
access to data but beyond that there was

260
00:08:59,399 --> 00:09:01,260
not a lot of consensus about what would

261
00:09:01,260 --> 00:09:02,279
be better

262
00:09:02,279 --> 00:09:04,140
people who tended to trust automation

263
00:09:04,140 --> 00:09:06,779
more preferred the learning mode but

264
00:09:06,779 --> 00:09:08,220
those who were a bit more privacy

265
00:09:08,220 --> 00:09:11,339
conscious liked the rules designed a bit

266
00:09:11,339 --> 00:09:13,019
more because they didn't want to give up

267
00:09:13,019 --> 00:09:14,760
that level of control

268
00:09:14,760 --> 00:09:17,399
on the other hand rules also elicited a

269
00:09:17,399 --> 00:09:19,800
lot of confusion and people didn't like

270
00:09:19,800 --> 00:09:21,420
the fact that once you set a rule by

271
00:09:21,420 --> 00:09:24,060
default it was remembered forever even

272
00:09:24,060 --> 00:09:25,920
though that's sort of how smartphone

273
00:09:25,920 --> 00:09:28,080
permissions work today

274
00:09:28,080 --> 00:09:29,760
another approach that some though not

275
00:09:29,760 --> 00:09:31,980
all liked was what we called auditing

276
00:09:31,980 --> 00:09:33,660
where we proposed getting rid of

277
00:09:33,660 --> 00:09:36,240
permissions altogether and then proving

278
00:09:36,240 --> 00:09:38,339
any request by default though providing

279
00:09:38,339 --> 00:09:39,839
an audit mechanism that you could review

280
00:09:39,839 --> 00:09:41,640
on your own time

281
00:09:41,640 --> 00:09:43,200
even though people like that both are

282
00:09:43,200 --> 00:09:44,880
study and prior research suggests that

283
00:09:44,880 --> 00:09:46,920
people tend to not engage in mechanisms

284
00:09:46,920 --> 00:09:48,540
like this so whether this would actually

285
00:09:48,540 --> 00:09:50,160
be better for privacy is an open

286
00:09:50,160 --> 00:09:52,459
question

287
00:09:52,560 --> 00:09:54,720
in summary we found that permissions

288
00:09:54,720 --> 00:09:57,839
offered people the control they wanted

289
00:09:57,839 --> 00:10:01,080
but the resulting user experience left a

290
00:10:01,080 --> 00:10:03,480
lot to be desired and even the Privacy

291
00:10:03,480 --> 00:10:05,339
protections were probably not sufficient

292
00:10:05,339 --> 00:10:06,420
on their own

293
00:10:06,420 --> 00:10:08,580
instead for the time being probably the

294
00:10:08,580 --> 00:10:10,320
best approach is to layer different

295
00:10:10,320 --> 00:10:13,800
protections for example permissions and

296
00:10:13,800 --> 00:10:15,959
a mute button and voice recognition and

297
00:10:15,959 --> 00:10:18,420
Delight lists and continue working on

298
00:10:18,420 --> 00:10:19,860
new approaches that might be better

299
00:10:19,860 --> 00:10:22,019
because if these proactive assistants do

300
00:10:22,019 --> 00:10:23,399
become real we'll need something more

301
00:10:23,399 --> 00:10:25,260
than just a mute button to protect our

302
00:10:25,260 --> 00:10:26,519
users privacy

303
00:10:26,519 --> 00:10:27,899
there's a lot more in the paper I

304
00:10:27,899 --> 00:10:29,279
encourage you to check it out but I'll

305
00:10:29,279 --> 00:10:30,420
stop there and I'm happy to take any

306
00:10:30,420 --> 00:10:32,599
questions

