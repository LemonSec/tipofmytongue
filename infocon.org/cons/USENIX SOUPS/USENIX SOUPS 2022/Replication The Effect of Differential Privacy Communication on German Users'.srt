1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:11,120 --> 00:00:13,380
you've heard the title of the

3
00:00:13,380 --> 00:00:15,120
presentation already it's a study I've

4
00:00:15,120 --> 00:00:17,580
conducted together with Victoria Park

5
00:00:17,580 --> 00:00:19,859
and Delphine Reinhardt we're all from

6
00:00:19,859 --> 00:00:22,080
the University of cuttingen

7
00:00:22,080 --> 00:00:25,560
so first

8
00:00:25,560 --> 00:00:26,820
um

9
00:00:26,820 --> 00:00:28,680
there we go first thing about

10
00:00:28,680 --> 00:00:30,779
differential privacy I will not go into

11
00:00:30,779 --> 00:00:34,020
detail just a little overview

12
00:00:34,020 --> 00:00:36,540
we focus on the two models of

13
00:00:36,540 --> 00:00:38,100
differential privacy the global model

14
00:00:38,100 --> 00:00:39,899
which you can see on the top and the

15
00:00:39,899 --> 00:00:42,300
local model on the bottom what does

16
00:00:42,300 --> 00:00:45,120
differential privacy do it basically the

17
00:00:45,120 --> 00:00:47,219
idea behind differential privacy is to

18
00:00:47,219 --> 00:00:49,980
perturb data in such a way to protect an

19
00:00:49,980 --> 00:00:52,140
individual's privacy while keeping the

20
00:00:52,140 --> 00:00:54,539
underlying data distribution intact by

21
00:00:54,539 --> 00:00:57,360
adding noise to the data we can see here

22
00:00:57,360 --> 00:01:00,239
on the top in the global model that the

23
00:01:00,239 --> 00:01:03,180
data is perturbed so the noise is added

24
00:01:03,180 --> 00:01:06,299
globally so to speak like on a like you

25
00:01:06,299 --> 00:01:08,880
can imagine a company server whereas in

26
00:01:08,880 --> 00:01:10,500
the local model which you can see here

27
00:01:10,500 --> 00:01:13,560
on the bottom the data gets perturbed

28
00:01:13,560 --> 00:01:16,740
locally on for example the users device

29
00:01:16,740 --> 00:01:19,619
and only project data leaves the device

30
00:01:19,619 --> 00:01:20,939
so

31
00:01:20,939 --> 00:01:23,640
to to take away basically is that raw

32
00:01:23,640 --> 00:01:25,560
data never leaves the device in the in

33
00:01:25,560 --> 00:01:27,600
the local model which means it is more

34
00:01:27,600 --> 00:01:29,880
privacy preserving

35
00:01:29,880 --> 00:01:33,420
so what did we do uh we kind of like saw

36
00:01:33,420 --> 00:01:34,979
the idea behind our study and the

37
00:01:34,979 --> 00:01:36,540
original study which we replicated is

38
00:01:36,540 --> 00:01:39,540
can differential privacy increase the

39
00:01:39,540 --> 00:01:41,880
user's willingness to share data why do

40
00:01:41,880 --> 00:01:44,100
we need the data for example for machine

41
00:01:44,100 --> 00:01:46,380
learning applications

42
00:01:46,380 --> 00:01:48,299
so as I've said the original study was

43
00:01:48,299 --> 00:01:50,939
conducted by iping Shong and colleagues

44
00:01:50,939 --> 00:01:52,259
in 2020

45
00:01:52,259 --> 00:01:54,479
and we know

46
00:01:54,479 --> 00:01:57,720
um that uh country's culture and privacy

47
00:01:57,720 --> 00:02:00,000
regulations among comp among continents

48
00:02:00,000 --> 00:02:03,299
impact privacy attitudes so therefore we

49
00:02:03,299 --> 00:02:05,159
thought it was worthwhile to replicate

50
00:02:05,159 --> 00:02:08,580
the study in another cultural context we

51
00:02:08,580 --> 00:02:10,860
can see here the

52
00:02:10,860 --> 00:02:13,860
small overview of about the differences

53
00:02:13,860 --> 00:02:16,980
of our sample in the originals

54
00:02:16,980 --> 00:02:20,040
our sample was Germans

55
00:02:20,040 --> 00:02:21,599
representative of the German population

56
00:02:21,599 --> 00:02:24,120
in terms of gender age and education

57
00:02:24,120 --> 00:02:25,500
whereas you can see in the original

58
00:02:25,500 --> 00:02:28,620
study which was conducted on mturk it

59
00:02:28,620 --> 00:02:30,860
was heavily skilled skewed towards

60
00:02:30,860 --> 00:02:34,500
younger higher educated people primarily

61
00:02:34,500 --> 00:02:36,780
from the US and India

62
00:02:36,780 --> 00:02:39,060
so we conducted two experiments the

63
00:02:39,060 --> 00:02:41,840
first one it was an online questionnaire

64
00:02:41,840 --> 00:02:44,580
where we put our participants into a

65
00:02:44,580 --> 00:02:46,319
scenario where we told them you just

66
00:02:46,319 --> 00:02:48,599
downloaded a health app called orange

67
00:02:48,599 --> 00:02:49,500
health

68
00:02:49,500 --> 00:02:52,019
and this app requires certain sensitive

69
00:02:52,019 --> 00:02:53,819
information of you

70
00:02:53,819 --> 00:02:54,599
um

71
00:02:54,599 --> 00:02:56,700
and the app needs that information in

72
00:02:56,700 --> 00:02:58,379
order to improve the app locally for you

73
00:02:58,379 --> 00:03:00,900
to recommend certain things for you and

74
00:03:00,900 --> 00:03:04,400
we also want to improve the app globally

75
00:03:04,400 --> 00:03:07,019
for all users for for example for

76
00:03:07,019 --> 00:03:09,360
machine learning applications so we had

77
00:03:09,360 --> 00:03:11,640
three groups three conditions one was

78
00:03:11,640 --> 00:03:13,560
exposed to differential privacy one to

79
00:03:13,560 --> 00:03:15,360
local differential privacy and a control

80
00:03:15,360 --> 00:03:19,140
group and this all is in line with the

81
00:03:19,140 --> 00:03:22,080
original study and we also copied the

82
00:03:22,080 --> 00:03:24,300
questionnaire basically verbatim from

83
00:03:24,300 --> 00:03:26,040
the original study

84
00:03:26,040 --> 00:03:28,500
so this is basically what our

85
00:03:28,500 --> 00:03:31,200
participants saw they had this mock-up

86
00:03:31,200 --> 00:03:33,480
basically of an IOS app

87
00:03:33,480 --> 00:03:37,319
um where they were post 14 questions for

88
00:03:37,319 --> 00:03:39,480
example date of birth weight height but

89
00:03:39,480 --> 00:03:40,680
also more sensitive questions like

90
00:03:40,680 --> 00:03:42,959
income level medication

91
00:03:42,959 --> 00:03:44,239
um

92
00:03:44,239 --> 00:03:48,060
like medical history and so they did not

93
00:03:48,060 --> 00:03:49,260
actually have to answer these questions

94
00:03:49,260 --> 00:03:50,879
but rather

95
00:03:50,879 --> 00:03:53,280
um indicate how they would their

96
00:03:53,280 --> 00:03:55,260
potential answers to be processed so

97
00:03:55,260 --> 00:03:57,659
they could choose to have it used only

98
00:03:57,659 --> 00:03:59,060
by the app locally

99
00:03:59,060 --> 00:04:01,860
which would be in line with people who

100
00:04:01,860 --> 00:04:03,480
are a bit a bit more privacy preserving

101
00:04:03,480 --> 00:04:05,459
it could be used by the app locally and

102
00:04:05,459 --> 00:04:07,620
the server so basically give the data

103
00:04:07,620 --> 00:04:08,599
away

104
00:04:08,599 --> 00:04:11,159
uh and also of course for those who

105
00:04:11,159 --> 00:04:13,799
don't did not want to give out the data

106
00:04:13,799 --> 00:04:15,659
the potential data

107
00:04:15,659 --> 00:04:17,579
um to not share with neither the Apple

108
00:04:17,579 --> 00:04:19,798
model server or they could also choose

109
00:04:19,798 --> 00:04:21,779
not to answer

110
00:04:21,779 --> 00:04:24,960
so what could we confirm from the

111
00:04:24,960 --> 00:04:27,600
original study that our participants

112
00:04:27,600 --> 00:04:29,520
just as in the original study did not

113
00:04:29,520 --> 00:04:31,440
differentiate between differential

114
00:04:31,440 --> 00:04:33,240
privacy like the global and the local

115
00:04:33,240 --> 00:04:35,820
model of differential privacy answers in

116
00:04:35,820 --> 00:04:37,320
both conditions were very consistent

117
00:04:37,320 --> 00:04:39,960
very uh similar so there was no

118
00:04:39,960 --> 00:04:43,380
difference between among these groups

119
00:04:43,380 --> 00:04:45,360
um we have however some new findings

120
00:04:45,360 --> 00:04:48,600
some differences that are in our sample

121
00:04:48,600 --> 00:04:49,979
the communication of differential

122
00:04:49,979 --> 00:04:52,199
privacy in both groups local and Global

123
00:04:52,199 --> 00:04:55,800
had in fact an uh an effect on their

124
00:04:55,800 --> 00:04:57,900
willingness to share data especially

125
00:04:57,900 --> 00:05:00,540
when it comes to high sensitive data and

126
00:05:00,540 --> 00:05:01,860
also we've asked an additional question

127
00:05:01,860 --> 00:05:03,240
which was not asked in the original

128
00:05:03,240 --> 00:05:07,020
study whether they use a health app in

129
00:05:07,020 --> 00:05:10,080
their private life and participants who

130
00:05:10,080 --> 00:05:12,240
actually use the health app showed more

131
00:05:12,240 --> 00:05:14,880
willingness to share data

132
00:05:14,880 --> 00:05:17,880
now for a second experiment uh it was

133
00:05:17,880 --> 00:05:19,259
the same scenario you download the

134
00:05:19,259 --> 00:05:20,460
health app that requires certain

135
00:05:20,460 --> 00:05:25,020
sensitive information and so but in this

136
00:05:25,020 --> 00:05:27,060
case we had in line with the original

137
00:05:27,060 --> 00:05:29,400
study 11 different descriptions of

138
00:05:29,400 --> 00:05:31,800
global and local differential privacy to

139
00:05:31,800 --> 00:05:33,860
find out which of these descriptions

140
00:05:33,860 --> 00:05:37,380
showed the greatest effect in the

141
00:05:37,380 --> 00:05:39,180
willingness to share data but also in

142
00:05:39,180 --> 00:05:41,580
the understanding and the comprehension

143
00:05:41,580 --> 00:05:44,639
of differential privacy so

144
00:05:44,639 --> 00:05:47,160
we were first asked do you want to share

145
00:05:47,160 --> 00:05:51,360
data and and why or why not and secondly

146
00:05:51,360 --> 00:05:53,580
and more importantly in this experiment

147
00:05:53,580 --> 00:05:56,460
the focus light on comprehension

148
00:05:56,460 --> 00:05:58,259
um so it they could self-report their

149
00:05:58,259 --> 00:05:59,660
understanding of differential privacy

150
00:05:59,660 --> 00:06:04,380
but also later kodam had to answer five

151
00:06:04,380 --> 00:06:06,960
comprehension questions an example you

152
00:06:06,960 --> 00:06:08,699
can see here can an attacker see real

153
00:06:08,699 --> 00:06:11,300
data if they get access to the database

154
00:06:11,300 --> 00:06:14,880
and for other questions in this in this

155
00:06:14,880 --> 00:06:16,020
line

156
00:06:16,020 --> 00:06:17,220
so

157
00:06:17,220 --> 00:06:19,979
uh I will just show one interesting

158
00:06:19,979 --> 00:06:21,600
finding from from the second experiment

159
00:06:21,600 --> 00:06:24,300
uh if we focus on the y-axis one moment

160
00:06:24,300 --> 00:06:26,520
we can see here we post five

161
00:06:26,520 --> 00:06:28,440
comprehension questions they get one

162
00:06:28,440 --> 00:06:30,060
point if they answered a comprehension

163
00:06:30,060 --> 00:06:32,220
question correctly so five points is the

164
00:06:32,220 --> 00:06:33,900
maximum and you can see that the scores

165
00:06:33,900 --> 00:06:36,960
these red dots here are very very low

166
00:06:36,960 --> 00:06:38,580
and

167
00:06:38,580 --> 00:06:41,280
if we look at the x-axis here these are

168
00:06:41,280 --> 00:06:43,020
this is the time spent in seconds

169
00:06:43,020 --> 00:06:44,819
looking at the description of

170
00:06:44,819 --> 00:06:46,620
differential privacy so basically people

171
00:06:46,620 --> 00:06:49,139
who just spent uh less than 20 seconds

172
00:06:49,139 --> 00:06:51,680
on the description scored

173
00:06:51,680 --> 00:06:53,819
significantly lower than people who

174
00:06:53,819 --> 00:06:55,800
spend around three minutes there is no

175
00:06:55,800 --> 00:06:59,639
increase afterwards which suggests that

176
00:06:59,639 --> 00:07:01,500
um participants who actually spend more

177
00:07:01,500 --> 00:07:03,479
time reading and understanding or trying

178
00:07:03,479 --> 00:07:05,400
to understand the description also

179
00:07:05,400 --> 00:07:07,740
understood uh differential privacy

180
00:07:07,740 --> 00:07:09,479
better

181
00:07:09,479 --> 00:07:11,940
so what could we confirm we had a very

182
00:07:11,940 --> 00:07:13,979
similar overall sharing rate con

183
00:07:13,979 --> 00:07:16,199
compared to the original study around

184
00:07:16,199 --> 00:07:18,180
also roughly 50 of our participants

185
00:07:18,180 --> 00:07:19,680
wanted to share data on the differential

186
00:07:19,680 --> 00:07:22,220
privacy and we had an overall

187
00:07:22,220 --> 00:07:24,360
difficulty to comprehend rate which was

188
00:07:24,360 --> 00:07:26,400
also very similar to the original study

189
00:07:26,400 --> 00:07:30,720
meaning 13 around uh indicated that they

190
00:07:30,720 --> 00:07:32,639
found it hard to understand differential

191
00:07:32,639 --> 00:07:36,599
privacy which if you remember this slide

192
00:07:36,599 --> 00:07:40,080
you know they were wrong uh so we have

193
00:07:40,080 --> 00:07:42,180
some differences and additional findings

194
00:07:42,180 --> 00:07:45,419
so among our 11 groups there were there

195
00:07:45,419 --> 00:07:47,460
weren't many differences

196
00:07:47,460 --> 00:07:49,380
um so so the differences were there but

197
00:07:49,380 --> 00:07:50,819
not as Extreme as they were in the

198
00:07:50,819 --> 00:07:52,020
original study

199
00:07:52,020 --> 00:07:56,099
so we had very like homogeneous results

200
00:07:56,099 --> 00:07:58,620
basically we could correlate the I.T

201
00:07:58,620 --> 00:08:00,419
background like a self-reported I.T

202
00:08:00,419 --> 00:08:02,819
background of our participants with the

203
00:08:02,819 --> 00:08:04,259
difficulty to comprehend differential

204
00:08:04,259 --> 00:08:05,580
privacy and also the actual

205
00:08:05,580 --> 00:08:08,699
understanding which both show uh higher

206
00:08:08,699 --> 00:08:10,560
results when participants had an I.T

207
00:08:10,560 --> 00:08:12,539
background and also again the usage of

208
00:08:12,539 --> 00:08:13,699
Health apps

209
00:08:13,699 --> 00:08:15,479
significantly increased the willingness

210
00:08:15,479 --> 00:08:17,699
to share

211
00:08:17,699 --> 00:08:21,240
so for discussion and future work it is

212
00:08:21,240 --> 00:08:23,160
clear from the original study and

213
00:08:23,160 --> 00:08:24,840
through our now I would say like

214
00:08:24,840 --> 00:08:27,360
validation that differential privacy is

215
00:08:27,360 --> 00:08:30,660
not well understood in its currently you

216
00:08:30,660 --> 00:08:33,000
know performance currently uh

217
00:08:33,000 --> 00:08:35,399
transported form

218
00:08:35,399 --> 00:08:37,260
um our participants had an like All or

219
00:08:37,260 --> 00:08:39,120
Nothing mindset meaning they either

220
00:08:39,120 --> 00:08:40,620
didn't want to share anything or they

221
00:08:40,620 --> 00:08:43,140
wanted to share with uh globally and

222
00:08:43,140 --> 00:08:45,500
locally so with a server and and the app

223
00:08:45,500 --> 00:08:47,700
meaning that the difference between

224
00:08:47,700 --> 00:08:49,200
Global and local differential privacy

225
00:08:49,200 --> 00:08:52,080
was also not present in our study

226
00:08:52,080 --> 00:08:55,320
and we know that text is not the ideal

227
00:08:55,320 --> 00:08:57,959
way to communicate any privacy related

228
00:08:57,959 --> 00:08:59,540
things like privacy notices and anything

229
00:08:59,540 --> 00:09:03,060
so also for differential privacy we need

230
00:09:03,060 --> 00:09:04,200
better

231
00:09:04,200 --> 00:09:06,240
metaphors which we will uh hear about

232
00:09:06,240 --> 00:09:08,399
later I guess but also like graphical

233
00:09:08,399 --> 00:09:11,580
descriptions of differential privacy

234
00:09:11,580 --> 00:09:13,680
so this concludes my talk and thank you

235
00:09:13,680 --> 00:09:14,760
very much for your attention and I'm

236
00:09:14,760 --> 00:09:17,300
open to questions

