1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:08,660 --> 00:00:11,160
weisel from the Internet safety labs and

3
00:00:11,160 --> 00:00:12,840
I'm here to talk about informed consent

4
00:00:12,840 --> 00:00:15,360
and participant data privacy we'd like

5
00:00:15,360 --> 00:00:16,980
to be sure that the data about our

6
00:00:16,980 --> 00:00:19,140
research participants stay between us

7
00:00:19,140 --> 00:00:21,240
and the test participant but are our

8
00:00:21,240 --> 00:00:22,980
participants fully aware of the data

9
00:00:22,980 --> 00:00:24,539
sharing agreements underlying the

10
00:00:24,539 --> 00:00:26,519
participants use of these testing tools

11
00:00:26,519 --> 00:00:28,980
the confidentiality agreement that they

12
00:00:28,980 --> 00:00:30,539
have with us is only part of the picture

13
00:00:30,539 --> 00:00:32,700
in this short talk I'll discuss how to

14
00:00:32,700 --> 00:00:34,680
ensure your participants know their data

15
00:00:34,680 --> 00:00:36,960
is collected and how it might be used or

16
00:00:36,960 --> 00:00:38,579
shared beyond the scope of the covered

17
00:00:38,579 --> 00:00:40,860
research project I'll focus on a mini

18
00:00:40,860 --> 00:00:43,079
audit of several user testing software

19
00:00:43,079 --> 00:00:45,000
packages that we performed based on the

20
00:00:45,000 --> 00:00:47,340
10 attributes for a respectful me to be

21
00:00:47,340 --> 00:00:49,559
commitments that underlie our safe

22
00:00:49,559 --> 00:00:51,960
technology specification researchers

23
00:00:51,960 --> 00:00:53,760
collect and store data with a number of

24
00:00:53,760 --> 00:00:55,739
different research tools that in turn

25
00:00:55,739 --> 00:00:58,140
use underlying technology that may also

26
00:00:58,140 --> 00:01:00,899
access this data we call that a need to

27
00:01:00,899 --> 00:01:03,120
T relationship knowing who might be

28
00:01:03,120 --> 00:01:04,559
eavesdropping through the testing

29
00:01:04,559 --> 00:01:06,299
platform's relationship with these

30
00:01:06,299 --> 00:01:08,640
underlying tools helps you to evaluate

31
00:01:08,640 --> 00:01:10,500
whether you are exposing your team or

32
00:01:10,500 --> 00:01:12,240
your participants to risks that come

33
00:01:12,240 --> 00:01:15,119
with access by these Technologies a lack

34
00:01:15,119 --> 00:01:17,220
of notice and consent to share data is a

35
00:01:17,220 --> 00:01:19,260
significant risk while the risk of the

36
00:01:19,260 --> 00:01:20,939
researcher are similar to those of the

37
00:01:20,939 --> 00:01:23,340
user testing platform the platform Bears

38
00:01:23,340 --> 00:01:25,200
responsibility for ensuring that anyone

39
00:01:25,200 --> 00:01:27,180
participating in a test on their

40
00:01:27,180 --> 00:01:28,920
platform has an appropriate level of

41
00:01:28,920 --> 00:01:31,140
notification of the data being collected

42
00:01:31,140 --> 00:01:33,000
and shared as well as allowing the

43
00:01:33,000 --> 00:01:34,740
participant control over whether to

44
00:01:34,740 --> 00:01:36,540
continue now let's look at our audit

45
00:01:36,540 --> 00:01:38,400
researchers collect and store data with

46
00:01:38,400 --> 00:01:40,500
a number of different research tools and

47
00:01:40,500 --> 00:01:42,600
that creates that me to T technology

48
00:01:42,600 --> 00:01:45,420
relationship that we spoke of before our

49
00:01:45,420 --> 00:01:47,340
mini audit it's not randomized and only

50
00:01:47,340 --> 00:01:49,560
reflects the software packages that we

51
00:01:49,560 --> 00:01:50,939
either have been using in our own

52
00:01:50,939 --> 00:01:52,799
research or those that we've documented

53
00:01:52,799 --> 00:01:54,600
in forums that we participate in but

54
00:01:54,600 --> 00:01:56,280
you'll notice right here that most of

55
00:01:56,280 --> 00:01:58,020
the software we looked at share data

56
00:01:58,020 --> 00:01:59,820
with Google and other external vendors

57
00:01:59,820 --> 00:02:02,280
at least one shared with Facebook and

58
00:02:02,280 --> 00:02:05,040
two shared with Amazon and Microsoft you

59
00:02:05,040 --> 00:02:06,240
can see that just for these eight

60
00:02:06,240 --> 00:02:07,799
companies there are a few dozen

61
00:02:07,799 --> 00:02:10,318
companies or company assets that are

62
00:02:10,318 --> 00:02:12,599
also receiving data the ones in bold are

63
00:02:12,599 --> 00:02:14,700
advertising or tracking software and

64
00:02:14,700 --> 00:02:16,379
many of these tools aren't necessarily

65
00:02:16,379 --> 00:02:18,480
exploiting user data but they are doing

66
00:02:18,480 --> 00:02:20,340
ways to entities that now have some

67
00:02:20,340 --> 00:02:22,800
access to your participants data for our

68
00:02:22,800 --> 00:02:24,780
study we used a tool called track or not

69
00:02:24,780 --> 00:02:27,480
that exposes tags allowing data sharing

70
00:02:27,480 --> 00:02:29,640
between entities and what you're seeing

71
00:02:29,640 --> 00:02:32,160
here is a map of the underlying

72
00:02:32,160 --> 00:02:33,780
connections between the testing software

73
00:02:33,780 --> 00:02:36,300
and various first and third-party

74
00:02:36,300 --> 00:02:37,980
Technologies we were particularly

75
00:02:37,980 --> 00:02:39,959
interested in advertising networks

76
00:02:39,959 --> 00:02:42,720
analytics and trackers that are

77
00:02:42,720 --> 00:02:45,480
represented in blue red angle we started

78
00:02:45,480 --> 00:02:47,819
with Google and Microsoft forms because

79
00:02:47,819 --> 00:02:49,980
they are popular free tools that a lot

80
00:02:49,980 --> 00:02:51,720
of people use and don't require a lot of

81
00:02:51,720 --> 00:02:53,760
expertise to set up we expected to see

82
00:02:53,760 --> 00:02:55,440
sharing with their own advertising

83
00:02:55,440 --> 00:02:57,840
networks but it turns out we only found

84
00:02:57,840 --> 00:03:00,959
on Microsoft sharing with Bing ads a

85
00:03:00,959 --> 00:03:02,879
Savvy user may see that Google has its

86
00:03:02,879 --> 00:03:04,739
own privacy policy here at the bottom of

87
00:03:04,739 --> 00:03:06,660
this form and they may also May note

88
00:03:06,660 --> 00:03:09,000
that it would be in a addition to any

89
00:03:09,000 --> 00:03:11,400
data policy for the study that you

90
00:03:11,400 --> 00:03:13,440
present to them and also notice that the

91
00:03:13,440 --> 00:03:16,200
this form here has a line saying that

92
00:03:16,200 --> 00:03:18,000
the survey contains a completion code

93
00:03:18,000 --> 00:03:20,580
for survey swap which is a panel

94
00:03:20,580 --> 00:03:22,440
recruiting company and this indicates

95
00:03:22,440 --> 00:03:25,379
that the participants might have some

96
00:03:25,379 --> 00:03:28,019
additional third-party technologies that

97
00:03:28,019 --> 00:03:30,000
are in play here but I don't see any

98
00:03:30,000 --> 00:03:31,620
reference to privacy and consent

99
00:03:31,620 --> 00:03:33,540
practices of these underlying

100
00:03:33,540 --> 00:03:36,239
Technologies so maybe Google doesn't

101
00:03:36,239 --> 00:03:38,459
share much but survey swap data

102
00:03:38,459 --> 00:03:40,440
indicates that participants in the study

103
00:03:40,440 --> 00:03:42,540
are potentially being exposed to data

104
00:03:42,540 --> 00:03:44,280
sharing from the panel company pretty

105
00:03:44,280 --> 00:03:47,159
extensively we ran a few other tests

106
00:03:47,159 --> 00:03:49,620
here are the tracker maps at a couple of

107
00:03:49,620 --> 00:03:51,840
usability testing platforms That We

108
00:03:51,840 --> 00:03:53,879
examined and you can see that at least

109
00:03:53,879 --> 00:03:56,280
one is sharing with doubleclick and

110
00:03:56,280 --> 00:03:58,739
Google survey vendors tended to have a

111
00:03:58,739 --> 00:04:00,239
relatively small number of tracking

112
00:04:00,239 --> 00:04:01,980
vendors and the third group that we

113
00:04:01,980 --> 00:04:04,080
looked at was those panel recruiters

114
00:04:04,080 --> 00:04:06,000
where we actually did see a lot of

115
00:04:06,000 --> 00:04:07,680
activity sharing with entities like

116
00:04:07,680 --> 00:04:09,720
Facebook ads double click on Microsoft

117
00:04:09,720 --> 00:04:11,640
marketing and Adobe metrics at least in

118
00:04:11,640 --> 00:04:12,959
this one I mean when you look at these

119
00:04:12,959 --> 00:04:14,640
you should be asking yourself whether

120
00:04:14,640 --> 00:04:16,320
your participants are aware that these

121
00:04:16,320 --> 00:04:18,180
entities may have access to their data

122
00:04:18,180 --> 00:04:19,918
we feel it's a good idea to remind

123
00:04:19,918 --> 00:04:22,560
participants about any meat to T consent

124
00:04:22,560 --> 00:04:24,120
relationships that they may have when

125
00:04:24,120 --> 00:04:26,100
they participate in your study so what

126
00:04:26,100 --> 00:04:28,380
can you do product development is flawed

127
00:04:28,380 --> 00:04:30,600
often there is no consent when testing

128
00:04:30,600 --> 00:04:32,880
with potential users so researchers

129
00:04:32,880 --> 00:04:34,680
should advocate for informed consent

130
00:04:34,680 --> 00:04:36,360
through a form that highlights all

131
00:04:36,360 --> 00:04:39,240
potential recipients of participant data

132
00:04:39,240 --> 00:04:41,580
including any additional data policies

133
00:04:41,580 --> 00:04:43,440
underlying the usability platform

134
00:04:43,440 --> 00:04:45,720
software or panel recruitment agencies

135
00:04:45,720 --> 00:04:48,600
software platforms should take a close

136
00:04:48,600 --> 00:04:49,740
look at their data protection

137
00:04:49,740 --> 00:04:51,600
responsibilities and make a greater

138
00:04:51,600 --> 00:04:53,460
effort to inform participants and test

139
00:04:53,460 --> 00:04:55,800
creators of their data sharing policies

140
00:04:55,800 --> 00:04:57,900
and this should be not just once but

141
00:04:57,900 --> 00:04:59,880
every time you create a new study and

142
00:04:59,880 --> 00:05:02,280
every time your participants participate

143
00:05:02,280 --> 00:05:04,199
through those Technologies I'm looking

144
00:05:04,199 --> 00:05:05,759
forward to hearing any questions that

145
00:05:05,759 --> 00:05:07,919
anyone may have enjoy the rest of the

146
00:05:07,919 --> 00:05:10,400
conference

