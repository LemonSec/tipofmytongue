1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:08,880 --> 00:00:11,280
good afternoon everyone my name is

3
00:00:11,280 --> 00:00:13,080
Hannah and I'm presenting our framework

4
00:00:13,080 --> 00:00:15,299
on how to evaluate the usability of

5
00:00:15,299 --> 00:00:17,760
privacy Choice mechanisms

6
00:00:17,760 --> 00:00:20,100
so For Better or Worse consumer privacy

7
00:00:20,100 --> 00:00:21,840
protection has long been rooted in

8
00:00:21,840 --> 00:00:23,880
noticed in choice and this has led to

9
00:00:23,880 --> 00:00:25,560
the proliferation of different types of

10
00:00:25,560 --> 00:00:27,840
privacy choices such as device

11
00:00:27,840 --> 00:00:29,699
permission prompts cookie consent

12
00:00:29,699 --> 00:00:31,980
notices social media audience settings

13
00:00:31,980 --> 00:00:34,620
and various types of opt-outs

14
00:00:34,620 --> 00:00:37,320
and best work by our soups Community has

15
00:00:37,320 --> 00:00:39,239
shown that in general these privacy

16
00:00:39,239 --> 00:00:42,000
choices have poor usability

17
00:00:42,000 --> 00:00:43,739
um our this password has shown that

18
00:00:43,739 --> 00:00:45,899
they're hard to find that they're often

19
00:00:45,899 --> 00:00:47,879
confusing and that there may even be

20
00:00:47,879 --> 00:00:49,739
dark patterns that nudge people to

21
00:00:49,739 --> 00:00:51,899
privacy choices that they likely don't

22
00:00:51,899 --> 00:00:53,579
want

23
00:00:53,579 --> 00:00:55,440
so the seemingly simple solution to

24
00:00:55,440 --> 00:00:57,239
improve the usability of privacy Choice

25
00:00:57,239 --> 00:01:01,079
interfaces is to test them but testing

26
00:01:01,079 --> 00:01:03,120
privacy choices effectively is actually

27
00:01:03,120 --> 00:01:05,580
quite hard there's some complexity

28
00:01:05,580 --> 00:01:08,220
involved in studying privacy threats in

29
00:01:08,220 --> 00:01:10,920
an ecologically valid and ethical way

30
00:01:10,920 --> 00:01:13,020
there's also the consideration that

31
00:01:13,020 --> 00:01:14,760
privacy and security are typically

32
00:01:14,760 --> 00:01:18,000
secondary to how users are using the

33
00:01:18,000 --> 00:01:20,700
system they may be using a website for

34
00:01:20,700 --> 00:01:25,320
example to to shop or or to chat with

35
00:01:25,320 --> 00:01:26,520
their friends

36
00:01:26,520 --> 00:01:28,439
so these challenges raise the questions

37
00:01:28,439 --> 00:01:31,860
of what actually needs to be tested and

38
00:01:31,860 --> 00:01:33,659
what makes a privacy Choice interface

39
00:01:33,659 --> 00:01:37,619
usable for a particular choice context

40
00:01:37,619 --> 00:01:39,840
so the existing usability assessment

41
00:01:39,840 --> 00:01:41,520
Frameworks get at part of the problem

42
00:01:41,520 --> 00:01:44,340
and we incorporate this into a framework

43
00:01:44,340 --> 00:01:46,799
that more directly adapts it for the

44
00:01:46,799 --> 00:01:49,259
Privacy Choice context

45
00:01:49,259 --> 00:01:52,079
so our framework proposes criteria to

46
00:01:52,079 --> 00:01:53,759
consider an evaluations of privacy

47
00:01:53,759 --> 00:01:56,220
Choice interfaces it provides guidance

48
00:01:56,220 --> 00:01:57,960
on how to evaluate privacy Choice

49
00:01:57,960 --> 00:02:00,000
interfaces and organizations can use

50
00:02:00,000 --> 00:02:01,140
these guidance throughout the

51
00:02:01,140 --> 00:02:03,119
development of a privacy Choice

52
00:02:03,119 --> 00:02:06,180
interface and they can also be used to

53
00:02:06,180 --> 00:02:08,340
show the Privacy Choice interface is not

54
00:02:08,340 --> 00:02:10,080
the right it's not appropriate for a

55
00:02:10,080 --> 00:02:11,640
particular choice context and that there

56
00:02:11,640 --> 00:02:13,680
needs to be another approach to privacy

57
00:02:13,680 --> 00:02:15,599
protection

58
00:02:15,599 --> 00:02:18,599
Regulators could also use this framework

59
00:02:18,599 --> 00:02:19,700
as

60
00:02:19,700 --> 00:02:22,440
for for keeping organizations

61
00:02:22,440 --> 00:02:26,160
accountable to usable design and to also

62
00:02:26,160 --> 00:02:28,739
assess if regulations are successful in

63
00:02:28,739 --> 00:02:30,360
transpiring usable privacy Choice

64
00:02:30,360 --> 00:02:32,580
interfaces

65
00:02:32,580 --> 00:02:34,739
so here's a table that summarizes our

66
00:02:34,739 --> 00:02:36,900
framework it's in our framework I don't

67
00:02:36,900 --> 00:02:38,700
expect you to it's in our paper I don't

68
00:02:38,700 --> 00:02:39,959
expect you to read it now but I

69
00:02:39,959 --> 00:02:42,840
encourage you to give it a look I just

70
00:02:42,840 --> 00:02:45,060
wanted to go over some of the important

71
00:02:45,060 --> 00:02:46,200
parts of the framework in this

72
00:02:46,200 --> 00:02:47,879
presentation

73
00:02:47,879 --> 00:02:50,040
so the organizing structure of the

74
00:02:50,040 --> 00:02:52,800
framework our usability aspects which we

75
00:02:52,800 --> 00:02:54,540
adopt from our prior work published at

76
00:02:54,540 --> 00:02:55,440
Kai

77
00:02:55,440 --> 00:02:58,920
and this incorporates seven aspects of

78
00:02:58,920 --> 00:03:00,319
usability

79
00:03:00,319 --> 00:03:03,060
that are relevant to the Privacy Choice

80
00:03:03,060 --> 00:03:05,940
context that were identified after a

81
00:03:05,940 --> 00:03:10,080
review of literature and privacy and HCI

82
00:03:10,080 --> 00:03:12,360
uh the framework also outlines different

83
00:03:12,360 --> 00:03:14,640
approaches to usability evaluation and

84
00:03:14,640 --> 00:03:16,200
how they've been adapted to the Privacy

85
00:03:16,200 --> 00:03:18,360
Choice context and it includes both

86
00:03:18,360 --> 00:03:22,440
expert evaluation and user study methods

87
00:03:22,440 --> 00:03:24,840
the framework also describes the timing

88
00:03:24,840 --> 00:03:27,659
component of the privacy of privacy

89
00:03:27,659 --> 00:03:30,180
Choice interface design as described in

90
00:03:30,180 --> 00:03:33,420
the taxonomy by thing at all so we group

91
00:03:33,420 --> 00:03:36,060
we describe privacy Choice interfaces as

92
00:03:36,060 --> 00:03:39,120
on demand which are privacy

93
00:03:39,120 --> 00:03:43,019
settings pages that users seek out or as

94
00:03:43,019 --> 00:03:45,060
interruptive which are interfaces that

95
00:03:45,060 --> 00:03:48,500
appear during the use of a system

96
00:03:48,599 --> 00:03:50,340
and our framework proposes these

97
00:03:50,340 --> 00:03:52,140
criteria that can be incorporated into

98
00:03:52,140 --> 00:03:54,840
usability evaluations and these are

99
00:03:54,840 --> 00:03:57,360
mapped to usability aspects evaluation

100
00:03:57,360 --> 00:04:00,540
approaches and interface timings as

101
00:04:00,540 --> 00:04:03,959
informed by prior work and standard HCI

102
00:04:03,959 --> 00:04:06,120
practices and framework

103
00:04:06,120 --> 00:04:08,220
so rather than going into more detail

104
00:04:08,220 --> 00:04:10,260
about the actual framework I wanted to

105
00:04:10,260 --> 00:04:13,200
go over a few examples as to how this

106
00:04:13,200 --> 00:04:15,780
framework could be applied in practice

107
00:04:15,780 --> 00:04:17,699
so imagine that you're working for a

108
00:04:17,699 --> 00:04:19,320
company that's developing a new skin

109
00:04:19,320 --> 00:04:21,540
care app and this app might allow users

110
00:04:21,540 --> 00:04:23,280
to take photographs of their skin get

111
00:04:23,280 --> 00:04:25,560
recommendations for skin care products

112
00:04:25,560 --> 00:04:27,900
get referrals to dermatologists and

113
00:04:27,900 --> 00:04:29,639
discuss their skincare issues with other

114
00:04:29,639 --> 00:04:31,320
users

115
00:04:31,320 --> 00:04:33,300
so as you begin developing the app it

116
00:04:33,300 --> 00:04:35,460
would be a good idea to focus on users

117
00:04:35,460 --> 00:04:37,800
privacy needs and this could be done

118
00:04:37,800 --> 00:04:39,720
with self-report methods like interviews

119
00:04:39,720 --> 00:04:43,500
focus groups or surveys and such a study

120
00:04:43,500 --> 00:04:45,540
could be conducted for either on-demand

121
00:04:45,540 --> 00:04:47,639
privacy settings or interrupted privacy

122
00:04:47,639 --> 00:04:48,840
choices

123
00:04:48,840 --> 00:04:50,460
and this could provide insight into

124
00:04:50,460 --> 00:04:53,040
users privacy objectives including the

125
00:04:53,040 --> 00:04:54,900
types of privacy choices that users

126
00:04:54,900 --> 00:04:56,400
would like to have and whether there's

127
00:04:56,400 --> 00:04:58,560
any special requirements for this

128
00:04:58,560 --> 00:05:00,780
population of users which might include

129
00:05:00,780 --> 00:05:03,000
acne prone teenagers or people who

130
00:05:03,000 --> 00:05:05,759
suffer from chronic skin disorders

131
00:05:05,759 --> 00:05:09,419
it would also be useful so such a user

132
00:05:09,419 --> 00:05:12,199
study might help identify whether

133
00:05:12,199 --> 00:05:15,060
fine-grained controls or more course

134
00:05:15,060 --> 00:05:19,259
controls over data sharing would be most

135
00:05:19,259 --> 00:05:21,660
helpful to users as well as different

136
00:05:21,660 --> 00:05:24,180
types of users who may have different

137
00:05:24,180 --> 00:05:27,120
needs for example there may be groups of

138
00:05:27,120 --> 00:05:30,000
users who are have little sensitivity

139
00:05:30,000 --> 00:05:32,639
sensitivity discussing Their Skin Care

140
00:05:32,639 --> 00:05:34,440
concerns and are mostly interested in

141
00:05:34,440 --> 00:05:36,900
getting recommendations and ads and

142
00:05:36,900 --> 00:05:39,600
discounts on relevant products but there

143
00:05:39,600 --> 00:05:41,280
may be users on the other side of the

144
00:05:41,280 --> 00:05:43,620
spectrum who are interested in getting

145
00:05:43,620 --> 00:05:46,259
advice from experts and other users with

146
00:05:46,259 --> 00:05:48,600
their condition but maybe confirmed

147
00:05:48,600 --> 00:05:50,340
about concerned about being identified

148
00:05:50,340 --> 00:05:51,900
as someone with a particular skin

149
00:05:51,900 --> 00:05:54,198
condition

150
00:05:54,900 --> 00:05:57,419
so if an app includes on-demand privacy

151
00:05:57,419 --> 00:05:59,340
choices like privacy settings and

152
00:05:59,340 --> 00:06:01,500
evaluation might include assigning

153
00:06:01,500 --> 00:06:04,800
participants to a privacy task such as

154
00:06:04,800 --> 00:06:07,620
to find a privacy Choice interface and

155
00:06:07,620 --> 00:06:09,539
make the Privacy choices that they'd

156
00:06:09,539 --> 00:06:11,280
like to have

157
00:06:11,280 --> 00:06:13,259
and this could be helpful to evaluate a

158
00:06:13,259 --> 00:06:15,900
number of usability aspects this could

159
00:06:15,900 --> 00:06:18,180
include criteria related to users

160
00:06:18,180 --> 00:06:21,900
ability and efforts to make to make and

161
00:06:21,900 --> 00:06:24,300
find the Privacy Choice participants

162
00:06:24,300 --> 00:06:26,220
might also be asked questions related to

163
00:06:26,220 --> 00:06:28,620
comprehension to assess their objective

164
00:06:28,620 --> 00:06:30,840
knowledge of what privacy choices are

165
00:06:30,840 --> 00:06:32,759
available and what they do when their

166
00:06:32,759 --> 00:06:34,259
attention is actually focused on the

167
00:06:34,259 --> 00:06:35,600
interface

168
00:06:35,600 --> 00:06:37,800
researchers might also want to ask

169
00:06:37,800 --> 00:06:39,600
participants about their privacy

170
00:06:39,600 --> 00:06:41,699
intentions to confirm that the Privacy

171
00:06:41,699 --> 00:06:43,020
choices that are offered in the

172
00:06:43,020 --> 00:06:45,360
interface meet participants meet users

173
00:06:45,360 --> 00:06:48,060
needs and to see whether the choices

174
00:06:48,060 --> 00:06:50,039
that participants made in the study

175
00:06:50,039 --> 00:06:54,080
actually aligned with their objectives

176
00:06:54,419 --> 00:06:57,419
so to evaluate interruptive privacy

177
00:06:57,419 --> 00:07:00,479
choices like a prompt for a user to make

178
00:07:00,479 --> 00:07:02,280
a sharing decision about an uploaded

179
00:07:02,280 --> 00:07:03,319
photograph

180
00:07:03,319 --> 00:07:06,240
users might be assigned a distraction

181
00:07:06,240 --> 00:07:09,840
task or to perform a task that that

182
00:07:09,840 --> 00:07:12,180
triggers that interruption

183
00:07:12,180 --> 00:07:14,160
so here participants might be asked

184
00:07:14,160 --> 00:07:16,560
questions about awareness that the

185
00:07:16,560 --> 00:07:18,960
choice actually existed they might be

186
00:07:18,960 --> 00:07:21,240
asked comprehension questions to assess

187
00:07:21,240 --> 00:07:23,639
their objective knowledge when their

188
00:07:23,639 --> 00:07:25,560
attention is focused elsewhere which is

189
00:07:25,560 --> 00:07:28,340
somewhat more realistic assessment of

190
00:07:28,340 --> 00:07:30,539
their actual interactions with the

191
00:07:30,539 --> 00:07:31,520
system

192
00:07:31,520 --> 00:07:34,080
there's such an evaluation might include

193
00:07:34,080 --> 00:07:36,360
an assessment of user sentiment such as

194
00:07:36,360 --> 00:07:37,860
their investment in decision making

195
00:07:37,860 --> 00:07:40,319
which allows an assessment as to whether

196
00:07:40,319 --> 00:07:42,780
people are trying to make a meaningful

197
00:07:42,780 --> 00:07:44,759
decision at the time the prompt came up

198
00:07:44,759 --> 00:07:46,139
or whether they're just trying to swap

199
00:07:46,139 --> 00:07:47,759
The Prompt away

200
00:07:47,759 --> 00:07:50,759
uh the the data collected from this user

201
00:07:50,759 --> 00:07:52,199
study might also be helpful for

202
00:07:52,199 --> 00:07:54,500
evaluating for potential dark patterns

203
00:07:54,500 --> 00:07:57,360
particularly uh whether the interface

204
00:07:57,360 --> 00:08:00,419
designs or whether interface design can

205
00:08:00,419 --> 00:08:04,139
uh impedes individual autonomy in a way

206
00:08:04,139 --> 00:08:07,440
that people are nudged to choices that

207
00:08:07,440 --> 00:08:10,819
aren't aligned with their preferences

208
00:08:11,099 --> 00:08:14,699
so in addition a an evaluation of a

209
00:08:14,699 --> 00:08:16,860
privacy Choice interface might also be

210
00:08:16,860 --> 00:08:19,379
performed by an expert one or more

211
00:08:19,379 --> 00:08:21,479
experts which may be conducted before

212
00:08:21,479 --> 00:08:23,819
and after a user study

213
00:08:23,819 --> 00:08:26,580
so a design expert might examine for

214
00:08:26,580 --> 00:08:28,259
interface completeness and interface

215
00:08:28,259 --> 00:08:30,539
accuracy related to the needs uncovered

216
00:08:30,539 --> 00:08:33,360
in in the prior evaluations and to

217
00:08:33,360 --> 00:08:35,159
evaluate the usefulness of the developed

218
00:08:35,159 --> 00:08:36,240
interface

219
00:08:36,240 --> 00:08:38,580
they might also estimate the effort

220
00:08:38,580 --> 00:08:40,679
required to find make and comprehend

221
00:08:40,679 --> 00:08:42,360
privacy choices

222
00:08:42,360 --> 00:08:45,120
and a privacy legal expert for example

223
00:08:45,120 --> 00:08:47,100
might evaluate for alignment with

224
00:08:47,100 --> 00:08:49,740
regulatory objectives particularly those

225
00:08:49,740 --> 00:08:53,279
related to dark patterns and as well as

226
00:08:53,279 --> 00:08:55,380
relevant laws that it might be

227
00:08:55,380 --> 00:08:57,300
concerning sensitive health information

228
00:08:57,300 --> 00:09:00,420
or children's privacy in the in this

229
00:09:00,420 --> 00:09:02,580
app's context

230
00:09:02,580 --> 00:09:05,160
so we also describe a few considerations

231
00:09:05,160 --> 00:09:08,160
when planning evaluation studies I

232
00:09:08,160 --> 00:09:09,899
describe these in more detail in the

233
00:09:09,899 --> 00:09:12,420
paper but I wanted to quickly go over a

234
00:09:12,420 --> 00:09:15,120
few first there's a tension between

235
00:09:15,120 --> 00:09:17,279
informed privacy decision making and

236
00:09:17,279 --> 00:09:19,560
usability of the overall system so

237
00:09:19,560 --> 00:09:21,240
designs that are the most privacy

238
00:09:21,240 --> 00:09:23,040
protective may not be the most usable

239
00:09:23,040 --> 00:09:24,839
and vice versa

240
00:09:24,839 --> 00:09:27,540
there are also populations with needs

241
00:09:27,540 --> 00:09:30,600
that may differ from those that might be

242
00:09:30,600 --> 00:09:33,120
considered the typical user

243
00:09:33,120 --> 00:09:34,800
and there are also considerations

244
00:09:34,800 --> 00:09:36,660
related to the organization that's

245
00:09:36,660 --> 00:09:38,519
deploying the Privacy Choice interface

246
00:09:38,519 --> 00:09:40,740
such as the resources available for

247
00:09:40,740 --> 00:09:43,260
evaluations

248
00:09:43,260 --> 00:09:45,420
and lastly there's limitations related

249
00:09:45,420 --> 00:09:48,240
to privacy choice usability and privacy

250
00:09:48,240 --> 00:09:50,820
self-management overall even the most

251
00:09:50,820 --> 00:09:52,980
usable privacy Choice interfaces place

252
00:09:52,980 --> 00:09:55,019
the burden of privacy Management on

253
00:09:55,019 --> 00:09:57,360
users

254
00:09:57,360 --> 00:10:01,860
so I wanted to summarize my talk first I

255
00:10:01,860 --> 00:10:03,779
presented the framework that provides

256
00:10:03,779 --> 00:10:05,820
guidance on how to conduct usability

257
00:10:05,820 --> 00:10:07,980
evaluations of privacy Choice interfaces

258
00:10:07,980 --> 00:10:10,200
and then I went over a few examples

259
00:10:10,200 --> 00:10:13,080
using a case study of a skin care app of

260
00:10:13,080 --> 00:10:15,660
how this framework could be applied

261
00:10:15,660 --> 00:10:18,240
uh thank you everyone for your for

262
00:10:18,240 --> 00:10:20,100
attending the time for attending the

263
00:10:20,100 --> 00:10:22,080
talk today and I welcome any questions

264
00:10:22,080 --> 00:10:25,140
and feel free to reach out or uh pull me

265
00:10:25,140 --> 00:10:28,279
over in the hallway thanks

