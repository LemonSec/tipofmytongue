1
00:00:08,559 --> 00:00:11,120
hi

2
00:00:08,960 --> 00:00:12,000
i'm robert ramirez from cetcom in japan

3
00:00:11,120 --> 00:00:14,079
we're trying to make

4
00:00:12,000 --> 00:00:16,000
a systematic and low effort way for

5
00:00:14,080 --> 00:00:17,520
security researchers to evaluate the

6
00:00:16,000 --> 00:00:19,198
ethics of their research

7
00:00:17,520 --> 00:00:21,600
down to the specific circumstances

8
00:00:19,199 --> 00:00:23,359
behind any given action they take

9
00:00:21,600 --> 00:00:25,119
there already are a number of well-known

10
00:00:23,359 --> 00:00:26,880
abstract frameworks for ict

11
00:00:25,119 --> 00:00:28,880
like the recently updated acm code of

12
00:00:26,880 --> 00:00:30,240
ethics as well as the menlo report which

13
00:00:28,880 --> 00:00:32,238
music uses

14
00:00:30,240 --> 00:00:33,760
but these all exist only as lengthy

15
00:00:32,238 --> 00:00:36,239
documents and they don't give

16
00:00:33,760 --> 00:00:37,519
recommendations at a very granular level

17
00:00:36,239 --> 00:00:38,959
especially for most of the dilemmas

18
00:00:37,520 --> 00:00:40,399
faced by security researchers

19
00:00:38,960 --> 00:00:42,000
specifically

20
00:00:40,399 --> 00:00:43,680
we're proposing an easily searchable

21
00:00:42,000 --> 00:00:45,039
decision tree style web-based support

22
00:00:43,680 --> 00:00:46,480
tool to fill this need

23
00:00:45,039 --> 00:00:47,840
we compiled the knowledge base for the

24
00:00:46,480 --> 00:00:49,919
tool by analyzing the ethics of

25
00:00:47,840 --> 00:00:51,520
practices we know researchers care about

26
00:00:49,920 --> 00:00:53,199
by sampling over a hundred conference

27
00:00:51,520 --> 00:00:55,120
papers from across different research

28
00:00:53,199 --> 00:00:56,480
areas of cyber security

29
00:00:55,120 --> 00:00:58,160
at our current stage we're really

30
00:00:56,480 --> 00:00:59,440
looking for their feedback on the tool

31
00:00:58,160 --> 00:01:01,760
which you can learn more about via the

32
00:00:59,440 --> 00:01:03,039
link in the top right or to collaborate

33
00:01:01,760 --> 00:01:04,959
if you're interested in helping maintain

34
00:01:03,039 --> 00:01:06,240
or improve it or in testing with your

35
00:01:04,959 --> 00:01:13,839
organization or conference

36
00:01:06,240 --> 00:01:13,839
hope to hear from you soon

37
00:01:16,960 --> 00:01:19,039
you

