1
00:00:09,180 --> 00:00:13,119
[Applause]

2
00:00:17,119 --> 00:00:21,439
thank you soups2020

3
00:00:19,119 --> 00:00:22,480
thank you to the session chair lori

4
00:00:21,439 --> 00:00:25,039
kranner

5
00:00:22,480 --> 00:00:26,400
thank you to sonia thank you to heather

6
00:00:25,039 --> 00:00:30,080
uh the general chair

7
00:00:26,400 --> 00:00:31,598
and the vice chair

8
00:00:30,080 --> 00:00:34,239
it's an honor and a pleasure to be here

9
00:00:31,599 --> 00:00:36,800
today i'm going to be speaking on

10
00:00:34,239 --> 00:00:38,320
maybe we have been doing this wrong

11
00:00:36,800 --> 00:00:40,239
protester as person

12
00:00:38,320 --> 00:00:41,520
i'm so lucky to be able to work with

13
00:00:40,239 --> 00:00:44,640
ford foundation

14
00:00:41,520 --> 00:00:45,120
in their fight against inequality we

15
00:00:44,640 --> 00:00:47,120
support

16
00:00:45,120 --> 00:00:49,199
organizations and individuals who are

17
00:00:47,120 --> 00:00:51,519
making a huge impact on a global level

18
00:00:49,200 --> 00:00:54,559
i'm going to go into this idea of

19
00:00:51,520 --> 00:00:56,399
protester as persona and you know

20
00:00:54,559 --> 00:00:57,280
obviously these are my words not those

21
00:00:56,399 --> 00:00:59,840
of my

22
00:00:57,280 --> 00:01:01,280
employer but i feel like we're aligned

23
00:00:59,840 --> 00:01:03,280
in this idea that

24
00:01:01,280 --> 00:01:04,479
to fight inequality and to support

25
00:01:03,280 --> 00:01:07,280
people we need

26
00:01:04,479 --> 00:01:08,400
privacy we need great user research we

27
00:01:07,280 --> 00:01:10,720
need security

28
00:01:08,400 --> 00:01:13,840
but also we need to understand the

29
00:01:10,720 --> 00:01:17,039
unique needs of the people who

30
00:01:13,840 --> 00:01:18,240
surveillance and attacks against privacy

31
00:01:17,040 --> 00:01:20,320
and security

32
00:01:18,240 --> 00:01:22,880
happen to the most things i want to

33
00:01:20,320 --> 00:01:26,399
cover are um

34
00:01:22,880 --> 00:01:27,600
usable and practical security and

35
00:01:26,400 --> 00:01:30,320
privacy

36
00:01:27,600 --> 00:01:31,199
for and how that affects people on the

37
00:01:30,320 --> 00:01:33,600
margins

38
00:01:31,200 --> 00:01:35,200
people who've been pushed to the margins

39
00:01:33,600 --> 00:01:37,039
up not because they have a choice

40
00:01:35,200 --> 00:01:39,040
and i think it's important for us to

41
00:01:37,040 --> 00:01:40,079
address the forces that push them there

42
00:01:39,040 --> 00:01:42,720
and how it affects

43
00:01:40,079 --> 00:01:45,199
privacy and security i'm going to speak

44
00:01:42,720 --> 00:01:46,560
about my personal experiences my

45
00:01:45,200 --> 00:01:48,320
lived experience my professional

46
00:01:46,560 --> 00:01:50,560
experience working with

47
00:01:48,320 --> 00:01:52,639
marginalized communities not just here

48
00:01:50,560 --> 00:01:54,720
in the united states or on base but

49
00:01:52,640 --> 00:01:57,840
also throughout the world you know

50
00:01:54,720 --> 00:02:01,039
marginalized communities have a unique

51
00:01:57,840 --> 00:02:02,640
security and privacy needs and there are

52
00:02:01,040 --> 00:02:04,719
different issues that affect those

53
00:02:02,640 --> 00:02:06,799
things and we want to go into that

54
00:02:04,719 --> 00:02:08,878
what if the way that we've been

55
00:02:06,799 --> 00:02:09,920
addressing privacy and security could

56
00:02:08,878 --> 00:02:13,040
use

57
00:02:09,919 --> 00:02:15,519
um let's just say an infusion of

58
00:02:13,040 --> 00:02:17,519
different thinking and i think most of

59
00:02:15,520 --> 00:02:20,720
that should be based on the idea that

60
00:02:17,520 --> 00:02:21,599
for there to to be privacy right a

61
00:02:20,720 --> 00:02:23,920
person needs to have

62
00:02:21,599 --> 00:02:24,959
agency and i think that's an important

63
00:02:23,920 --> 00:02:28,000
thing to start

64
00:02:24,959 --> 00:02:29,920
and talk about looking at current events

65
00:02:28,000 --> 00:02:32,000
and current affairs what's going on

66
00:02:29,920 --> 00:02:34,720
globally locally

67
00:02:32,000 --> 00:02:36,319
domestically wherever you're sitting and

68
00:02:34,720 --> 00:02:38,160
thinking how much of this

69
00:02:36,319 --> 00:02:39,440
affects the work that i do how much of

70
00:02:38,160 --> 00:02:42,640
this affects my work

71
00:02:39,440 --> 00:02:45,440
my research uh on privacy uh

72
00:02:42,640 --> 00:02:46,000
on security and if it doesn't have a

73
00:02:45,440 --> 00:02:48,079
large

74
00:02:46,000 --> 00:02:50,000
impact to the work we're doing maybe

75
00:02:48,080 --> 00:02:52,879
we're doing this wrong

76
00:02:50,000 --> 00:02:54,239
where i am in the united states you know

77
00:02:52,879 --> 00:02:56,959
we're looking at

78
00:02:54,239 --> 00:02:58,800
nationwide uprisings and protests uh

79
00:02:56,959 --> 00:03:00,800
against police brutality

80
00:02:58,800 --> 00:03:02,000
there's a large movement the movement

81
00:03:00,800 --> 00:03:04,400
for black lives

82
00:03:02,000 --> 00:03:06,239
and we're also dealing on a global level

83
00:03:04,400 --> 00:03:08,879
with a pandemic

84
00:03:06,239 --> 00:03:09,920
um that the likes of which we've never

85
00:03:08,879 --> 00:03:13,599
seen

86
00:03:09,920 --> 00:03:14,640
and have impacted so many different

87
00:03:13,599 --> 00:03:17,040
people

88
00:03:14,640 --> 00:03:18,879
not just uh on a personal level in a

89
00:03:17,040 --> 00:03:20,799
personal level but governments

90
00:03:18,879 --> 00:03:22,480
and uh affecting people's autonomy and

91
00:03:20,800 --> 00:03:23,840
people's agency

92
00:03:22,480 --> 00:03:25,920
so if the work that we're doing on

93
00:03:23,840 --> 00:03:28,400
privacy and security is

94
00:03:25,920 --> 00:03:29,920
is the same work we'd be doing if this

95
00:03:28,400 --> 00:03:33,200
was a year ago

96
00:03:29,920 --> 00:03:33,920
then something's wrong right and if not

97
00:03:33,200 --> 00:03:35,839
now

98
00:03:33,920 --> 00:03:37,518
what better time to pause and think

99
00:03:35,840 --> 00:03:39,920
about the work that we're doing

100
00:03:37,519 --> 00:03:42,480
and how maybe by approaching it

101
00:03:39,920 --> 00:03:44,159
differently we can have a larger impact

102
00:03:42,480 --> 00:03:46,000
and probably protect those who need it

103
00:03:44,159 --> 00:03:50,000
more most

104
00:03:46,000 --> 00:03:52,400
surveillance right and and other tools

105
00:03:50,000 --> 00:03:54,480
against privacy pushing against an

106
00:03:52,400 --> 00:03:57,439
individual's privacy pushing against

107
00:03:54,480 --> 00:03:58,319
a system's privacy those are tools of

108
00:03:57,439 --> 00:04:00,959
oppression

109
00:03:58,319 --> 00:04:01,920
right it's always been a tool and tools

110
00:04:00,959 --> 00:04:04,000
of oppression

111
00:04:01,920 --> 00:04:07,040
but it's also important to remember that

112
00:04:04,000 --> 00:04:09,040
these things are not metered out evenly

113
00:04:07,040 --> 00:04:10,400
these tools of oppression surveillance

114
00:04:09,040 --> 00:04:14,159
and other things that harm

115
00:04:10,400 --> 00:04:15,360
uh try to take away uh privacy whether

116
00:04:14,159 --> 00:04:18,560
on an individual level or on a

117
00:04:15,360 --> 00:04:21,040
systematic level or electronic level

118
00:04:18,560 --> 00:04:22,880
these things affect certain communities

119
00:04:21,040 --> 00:04:24,160
certain individuals certain identities

120
00:04:22,880 --> 00:04:27,520
more than others

121
00:04:24,160 --> 00:04:30,160
and if we're not addressing that then

122
00:04:27,520 --> 00:04:31,680
we need to start over or at least bring

123
00:04:30,160 --> 00:04:34,720
in some additional thinking

124
00:04:31,680 --> 00:04:39,120
to the work that we do we know that

125
00:04:34,720 --> 00:04:41,280
if you identify as a woman

126
00:04:39,120 --> 00:04:43,440
and you're on the internet you're one of

127
00:04:41,280 --> 00:04:44,638
the most targeted groups on the internet

128
00:04:43,440 --> 00:04:46,639
you're going to have a completely

129
00:04:44,639 --> 00:04:47,520
different experience on the internet

130
00:04:46,639 --> 00:04:49,919
and there have been countless

131
00:04:47,520 --> 00:04:51,758
experiments of people

132
00:04:49,919 --> 00:04:53,919
changing their profiles changing their

133
00:04:51,759 --> 00:04:54,560
names and noticing the behavior that

134
00:04:53,919 --> 00:04:56,479
they

135
00:04:54,560 --> 00:04:58,160
um with the exact same content that they

136
00:04:56,479 --> 00:04:59,280
would um you know that they would have

137
00:04:58,160 --> 00:04:59,840
the exact same background they would

138
00:04:59,280 --> 00:05:01,679
have the

139
00:04:59,840 --> 00:05:03,679
exact same accreditations that they

140
00:05:01,680 --> 00:05:04,960
would have um but the internet's a

141
00:05:03,680 --> 00:05:05,360
different place it's a more harmful

142
00:05:04,960 --> 00:05:07,280
place

143
00:05:05,360 --> 00:05:09,520
it's a more abusive place and it's a

144
00:05:07,280 --> 00:05:11,520
place where security

145
00:05:09,520 --> 00:05:12,799
is something that you really need right

146
00:05:11,520 --> 00:05:14,080
and it's a place where privacy is

147
00:05:12,800 --> 00:05:16,160
something that you're really craving

148
00:05:14,080 --> 00:05:18,000
as a way to protect yourself i'm going

149
00:05:16,160 --> 00:05:19,440
to talk about some of the work i do

150
00:05:18,000 --> 00:05:21,759
and some of the work i do with

151
00:05:19,440 --> 00:05:22,800
marginalized communities as well as go

152
00:05:21,759 --> 00:05:25,280
into

153
00:05:22,800 --> 00:05:26,800
uh how you know the audience that's

154
00:05:25,280 --> 00:05:29,679
attending this talk and the

155
00:05:26,800 --> 00:05:31,600
participants to this talk can use uh

156
00:05:29,680 --> 00:05:34,960
certain tools certain research

157
00:05:31,600 --> 00:05:37,600
uh certain content to assist them in

158
00:05:34,960 --> 00:05:38,880
making their tools making their research

159
00:05:37,600 --> 00:05:41,280
making the work that they do

160
00:05:38,880 --> 00:05:42,400
uh even more safe and secure right and

161
00:05:41,280 --> 00:05:44,320
assisting people

162
00:05:42,400 --> 00:05:46,560
um even better and what that looked like

163
00:05:44,320 --> 00:05:49,840
you know i've been um

164
00:05:46,560 --> 00:05:52,000
working for many years now on a project

165
00:05:49,840 --> 00:05:55,039
that i founded called crypto harlem

166
00:05:52,000 --> 00:05:58,960
and i remember it was

167
00:05:55,039 --> 00:06:01,919
during the trayvon martin

168
00:05:58,960 --> 00:06:03,520
george zimmerman court proceedings that

169
00:06:01,919 --> 00:06:05,359
i started thinking you know what can i

170
00:06:03,520 --> 00:06:08,318
do

171
00:06:05,360 --> 00:06:10,080
what can i do to make an impact what can

172
00:06:08,319 --> 00:06:11,199
i do to support my community around

173
00:06:10,080 --> 00:06:14,800
myself here

174
00:06:11,199 --> 00:06:16,000
uh in harlem and um i thought you know

175
00:06:14,800 --> 00:06:18,880
what

176
00:06:16,000 --> 00:06:21,520
i'm a computer hacker uh you know i'm an

177
00:06:18,880 --> 00:06:22,159
operational security person i'm someone

178
00:06:21,520 --> 00:06:24,960
who

179
00:06:22,160 --> 00:06:26,800
trains people maybe i can reach out to

180
00:06:24,960 --> 00:06:28,880
the community around me so step one i

181
00:06:26,800 --> 00:06:30,960
think was just like

182
00:06:28,880 --> 00:06:32,880
this is my skill this is my approach but

183
00:06:30,960 --> 00:06:36,159
let me see how i can

184
00:06:32,880 --> 00:06:39,039
take the work that i do and

185
00:06:36,160 --> 00:06:40,560
and apply it to the issues facing a

186
00:06:39,039 --> 00:06:42,240
marginalized community

187
00:06:40,560 --> 00:06:44,080
now in this case there's a black

188
00:06:42,240 --> 00:06:45,280
community in america and the black

189
00:06:44,080 --> 00:06:47,039
community in harlem

190
00:06:45,280 --> 00:06:48,400
of course i'm black so i thought okay

191
00:06:47,039 --> 00:06:50,639
that makes the most sense

192
00:06:48,400 --> 00:06:52,159
let me find a community center let me

193
00:06:50,639 --> 00:06:55,360
find a low barrier entry

194
00:06:52,160 --> 00:06:57,039
for that community to engage with them

195
00:06:55,360 --> 00:06:58,240
let me listen to folks let me hear what

196
00:06:57,039 --> 00:07:01,360
their concerns are

197
00:06:58,240 --> 00:07:03,120
and then once i speak with them i can

198
00:07:01,360 --> 00:07:06,400
have a better understanding on how to

199
00:07:03,120 --> 00:07:08,319
uh apply these thinking and support them

200
00:07:06,400 --> 00:07:10,080
in learning about surveillance learning

201
00:07:08,319 --> 00:07:12,160
about all the different

202
00:07:10,080 --> 00:07:13,758
uh things that affect their safety

203
00:07:12,160 --> 00:07:16,319
security and privacy

204
00:07:13,759 --> 00:07:17,919
and um it was great i think like for a

205
00:07:16,319 --> 00:07:19,520
lot of people they had questions about

206
00:07:17,919 --> 00:07:21,758
when i wake up in the morning and i see

207
00:07:19,520 --> 00:07:24,479
these devices around me in my community

208
00:07:21,759 --> 00:07:26,000
they're hanging on light poles or uh

209
00:07:24,479 --> 00:07:27,919
aimed at me

210
00:07:26,000 --> 00:07:29,120
in my where i live or my neighborhood

211
00:07:27,919 --> 00:07:29,520
but i don't see them in other places

212
00:07:29,120 --> 00:07:32,080
like

213
00:07:29,520 --> 00:07:33,599
what are these devices uh what's the

214
00:07:32,080 --> 00:07:35,599
hardware involved what's the software

215
00:07:33,599 --> 00:07:36,319
involved how did it get there what can i

216
00:07:35,599 --> 00:07:38,719
do

217
00:07:36,319 --> 00:07:40,960
uh to have more control have more agency

218
00:07:38,720 --> 00:07:41,520
on my privacy on my security and things

219
00:07:40,960 --> 00:07:43,120
like that

220
00:07:41,520 --> 00:07:45,440
and that's what we talked about at these

221
00:07:43,120 --> 00:07:47,520
events that i held called crypto harlem

222
00:07:45,440 --> 00:07:48,800
and crypto harlem is still going in the

223
00:07:47,520 --> 00:07:51,440
age of covert 19

224
00:07:48,800 --> 00:07:53,520
of course now we're a live stream crypto

225
00:07:51,440 --> 00:07:56,719
harlem is focused on

226
00:07:53,520 --> 00:07:59,840
teaching security privacy

227
00:07:56,720 --> 00:08:01,680
and circumvention to the community

228
00:07:59,840 --> 00:08:03,280
of african americans living in upper

229
00:08:01,680 --> 00:08:05,840
manhattan in harlem

230
00:08:03,280 --> 00:08:07,758
crypto harlem also works in other black

231
00:08:05,840 --> 00:08:11,198
communities whenever we can

232
00:08:07,759 --> 00:08:13,599
as well as online to make sure that

233
00:08:11,199 --> 00:08:16,479
people have a strong understanding of

234
00:08:13,599 --> 00:08:17,440
their unique privacy and security needs

235
00:08:16,479 --> 00:08:19,280
and also

236
00:08:17,440 --> 00:08:20,560
things that they can do to safeguard

237
00:08:19,280 --> 00:08:22,960
them and

238
00:08:20,560 --> 00:08:24,319
it you know through that work and the

239
00:08:22,960 --> 00:08:26,878
work i've done

240
00:08:24,319 --> 00:08:28,560
traveling working with folks keeping

241
00:08:26,879 --> 00:08:31,360
them digitally safe

242
00:08:28,560 --> 00:08:33,200
digitally secure dissidents and human

243
00:08:31,360 --> 00:08:34,399
rights defenders

244
00:08:33,200 --> 00:08:36,959
it's really helped me a lot in

245
00:08:34,399 --> 00:08:39,599
understanding

246
00:08:36,958 --> 00:08:40,079
the unique needs that these folks have

247
00:08:39,599 --> 00:08:42,959
and

248
00:08:40,080 --> 00:08:43,919
how much we fail them but not not in

249
00:08:42,958 --> 00:08:46,399
intentionally

250
00:08:43,919 --> 00:08:46,959
right but with good intentions sometimes

251
00:08:46,399 --> 00:08:50,240
without

252
00:08:46,959 --> 00:08:51,199
a lack of of uh analysis we can easily

253
00:08:50,240 --> 00:08:53,360
fail folks

254
00:08:51,200 --> 00:08:55,120
what i would say another thing that i

255
00:08:53,360 --> 00:08:58,480
found was a lot of people

256
00:08:55,120 --> 00:08:59,680
didn't have a background a strong

257
00:08:58,480 --> 00:09:03,279
understanding

258
00:08:59,680 --> 00:09:05,439
on the this identity of black folks

259
00:09:03,279 --> 00:09:06,560
and what the privacy and security

260
00:09:05,440 --> 00:09:08,480
concerns are

261
00:09:06,560 --> 00:09:10,239
but the good thing is there's quite a

262
00:09:08,480 --> 00:09:11,680
lot of literature on it

263
00:09:10,240 --> 00:09:14,320
and so i think like one of the first

264
00:09:11,680 --> 00:09:17,279
things is you know understanding that

265
00:09:14,320 --> 00:09:19,040
privacy and security and those things

266
00:09:17,279 --> 00:09:19,839
are needed by some groups more than

267
00:09:19,040 --> 00:09:22,959
others

268
00:09:19,839 --> 00:09:26,080
right um but also like the way that

269
00:09:22,959 --> 00:09:26,880
it is thought about right the culture

270
00:09:26,080 --> 00:09:28,320
behind it

271
00:09:26,880 --> 00:09:30,000
might be unique and different so it's

272
00:09:28,320 --> 00:09:32,640
worth understanding

273
00:09:30,000 --> 00:09:33,920
one way is through research and i would

274
00:09:32,640 --> 00:09:34,640
say you know for folks who are

275
00:09:33,920 --> 00:09:37,279
interested in

276
00:09:34,640 --> 00:09:38,720
working in with my community simone

277
00:09:37,279 --> 00:09:41,439
brown

278
00:09:38,720 --> 00:09:41,839
has a book called dark matters it talks

279
00:09:41,440 --> 00:09:43,839
about

280
00:09:41,839 --> 00:09:45,519
the history of surveillance of black

281
00:09:43,839 --> 00:09:48,000
folks and

282
00:09:45,519 --> 00:09:49,839
you know i find that a lot of people

283
00:09:48,000 --> 00:09:50,640
just don't have that full academic

284
00:09:49,839 --> 00:09:53,760
knowledge

285
00:09:50,640 --> 00:09:55,600
of surveillance and it is an important

286
00:09:53,760 --> 00:09:57,920
powerful tool is understanding the

287
00:09:55,600 --> 00:09:59,760
history against privacy

288
00:09:57,920 --> 00:10:01,040
uh the history of these things when

289
00:09:59,760 --> 00:10:02,560
we're trying to um

290
00:10:01,040 --> 00:10:03,760
trying to solve it right trying to

291
00:10:02,560 --> 00:10:05,199
trying to make things better i think

292
00:10:03,760 --> 00:10:09,120
it's so important to understand

293
00:10:05,200 --> 00:10:12,079
the history of surveillance the history

294
00:10:09,120 --> 00:10:13,360
of things that go against our uses of

295
00:10:12,079 --> 00:10:17,040
technology in a free

296
00:10:13,360 --> 00:10:17,040
private and secure way

297
00:10:17,360 --> 00:10:24,160
uh another great piece of literature

298
00:10:20,399 --> 00:10:26,079
it was uh sophia emojia noble's

299
00:10:24,160 --> 00:10:27,839
algorithms of oppression i would

300
00:10:26,079 --> 00:10:31,199
definitely recommend that to folks

301
00:10:27,839 --> 00:10:33,680
if you want to read that book

302
00:10:31,200 --> 00:10:34,800
it talks about um surveillance

303
00:10:33,680 --> 00:10:36,479
capitalism

304
00:10:34,800 --> 00:10:37,920
spends a lot of time talking about uh

305
00:10:36,480 --> 00:10:40,959
search engines

306
00:10:37,920 --> 00:10:41,760
and the effects on communities and also

307
00:10:40,959 --> 00:10:45,518
this idea

308
00:10:41,760 --> 00:10:48,560
that these are um you know

309
00:10:45,519 --> 00:10:51,600
public works and even in fair

310
00:10:48,560 --> 00:10:52,239
when uh that's not exactly how these

311
00:10:51,600 --> 00:10:53,600
tools work

312
00:10:52,240 --> 00:10:55,600
i think there's a misunderstanding among

313
00:10:53,600 --> 00:10:57,519
the public and

314
00:10:55,600 --> 00:10:58,720
these kinds of books allow people to

315
00:10:57,519 --> 00:10:59,440
really raise their thinking and

316
00:10:58,720 --> 00:11:01,040
understanding

317
00:10:59,440 --> 00:11:03,920
and as researchers the people who work

318
00:11:01,040 --> 00:11:06,800
with user experience right user research

319
00:11:03,920 --> 00:11:09,120
uh developers and security experts it

320
00:11:06,800 --> 00:11:11,680
behooves us to understand these things

321
00:11:09,120 --> 00:11:12,480
and to have at least some body of

322
00:11:11,680 --> 00:11:15,040
knowledge

323
00:11:12,480 --> 00:11:16,880
on marginalized groups on the privacy

324
00:11:15,040 --> 00:11:18,480
and security of marginalized groups

325
00:11:16,880 --> 00:11:20,480
i had a friend who reached out to me and

326
00:11:18,480 --> 00:11:21,839
said hey matt i know you work with a lot

327
00:11:20,480 --> 00:11:24,959
of different groups and you

328
00:11:21,839 --> 00:11:28,000
you know direct people to a secure

329
00:11:24,959 --> 00:11:30,239
application for voice and and messaging

330
00:11:28,000 --> 00:11:31,600
called signal and i was like yeah i love

331
00:11:30,240 --> 00:11:31,920
signal it works really great i talk to

332
00:11:31,600 --> 00:11:34,000
people

333
00:11:31,920 --> 00:11:35,279
all the time my friend said well listen

334
00:11:34,000 --> 00:11:37,760
i'm working with

335
00:11:35,279 --> 00:11:39,120
survivors of abuse and domestic abuse

336
00:11:37,760 --> 00:11:42,640
shelter

337
00:11:39,120 --> 00:11:45,120
and i can't figure out how to block

338
00:11:42,640 --> 00:11:47,439
calls and text messages from people

339
00:11:45,120 --> 00:11:49,279
right you know people in your contacts

340
00:11:47,440 --> 00:11:50,639
what's happened is these people have

341
00:11:49,279 --> 00:11:53,839
blocked

342
00:11:50,639 --> 00:11:55,920
the contacts of the individuals

343
00:11:53,839 --> 00:11:58,480
who are harassing and abusing them but

344
00:11:55,920 --> 00:12:01,360
by installing the signal app

345
00:11:58,480 --> 00:12:02,639
they were somehow allowing them back in

346
00:12:01,360 --> 00:12:05,920
and there wasn't a way on

347
00:12:02,639 --> 00:12:07,920
android to block these um which is what

348
00:12:05,920 --> 00:12:09,920
uh the device on many of these these

349
00:12:07,920 --> 00:12:11,920
people had there wasn't a way to block

350
00:12:09,920 --> 00:12:14,160
contacts from contacting you

351
00:12:11,920 --> 00:12:16,079
and i was like wow i can't believe this

352
00:12:14,160 --> 00:12:18,639
happened and you know this isn't a

353
00:12:16,079 --> 00:12:20,160
a bug that was of ill intent of the

354
00:12:18,639 --> 00:12:22,399
developers of signal

355
00:12:20,160 --> 00:12:23,680
but they didn't keep in mind that there

356
00:12:22,399 --> 00:12:24,800
are some people who need certain

357
00:12:23,680 --> 00:12:28,319
resources or in

358
00:12:24,800 --> 00:12:31,439
app features for their very survival

359
00:12:28,320 --> 00:12:31,920
right and these are small things that we

360
00:12:31,440 --> 00:12:34,320
can do

361
00:12:31,920 --> 00:12:35,360
to enhance privacy and security that

362
00:12:34,320 --> 00:12:38,480
when we leave out

363
00:12:35,360 --> 00:12:39,200
have a very very large impact a negative

364
00:12:38,480 --> 00:12:42,240
impact

365
00:12:39,200 --> 00:12:44,320
to a marginalized community um so

366
00:12:42,240 --> 00:12:46,000
now if you know obviously through many

367
00:12:44,320 --> 00:12:46,880
updates and changes this is now a

368
00:12:46,000 --> 00:12:48,720
feature

369
00:12:46,880 --> 00:12:50,160
that exists in the application but at

370
00:12:48,720 --> 00:12:53,279
the time it did not

371
00:12:50,160 --> 00:12:55,439
and to go out the door

372
00:12:53,279 --> 00:12:56,560
without thinking about that was a

373
00:12:55,440 --> 00:12:58,399
mistake

374
00:12:56,560 --> 00:13:00,000
and i think that it's just things like

375
00:12:58,399 --> 00:13:01,680
this that we have to be able to

376
00:13:00,000 --> 00:13:03,200
think about and realize look if we have

377
00:13:01,680 --> 00:13:05,839
a way for people to communicate

378
00:13:03,200 --> 00:13:07,040
in any kind of tool or allow users to

379
00:13:05,839 --> 00:13:07,760
speak to each other in any kind of

380
00:13:07,040 --> 00:13:08,959
system

381
00:13:07,760 --> 00:13:11,600
we also have to have a way where that

382
00:13:08,959 --> 00:13:14,319
user is empowered to block and protect

383
00:13:11,600 --> 00:13:16,240
give them a door give them curtains give

384
00:13:14,320 --> 00:13:19,040
them privacy and safety

385
00:13:16,240 --> 00:13:20,000
looking at the protest inside the united

386
00:13:19,040 --> 00:13:23,360
states

387
00:13:20,000 --> 00:13:26,079
there are needs of protesters

388
00:13:23,360 --> 00:13:26,560
demonstrators who are you know following

389
00:13:26,079 --> 00:13:30,319
the

390
00:13:26,560 --> 00:13:31,920
uh tradition of civil disobedience

391
00:13:30,320 --> 00:13:33,440
following the tradition tradition of

392
00:13:31,920 --> 00:13:36,000
marching for

393
00:13:33,440 --> 00:13:37,600
what they believe is right in the united

394
00:13:36,000 --> 00:13:40,639
states we have protests

395
00:13:37,600 --> 00:13:42,480
and the protesters and demonstrators

396
00:13:40,639 --> 00:13:44,560
are following tradition in the united

397
00:13:42,480 --> 00:13:46,880
states uh you know just

398
00:13:44,560 --> 00:13:48,638
trying to let their voices be heard

399
00:13:46,880 --> 00:13:52,000
which is such a powerful

400
00:13:48,639 --> 00:13:55,040
and important part of any democracy tech

401
00:13:52,000 --> 00:13:57,440
companies though are

402
00:13:55,040 --> 00:13:58,800
being asked for information and will you

403
00:13:57,440 --> 00:14:01,680
work for

404
00:13:58,800 --> 00:14:02,479
right the unique needs of protesters

405
00:14:01,680 --> 00:14:05,760
foursquare

406
00:14:02,480 --> 00:14:06,480
a geolocation app said you know we'll do

407
00:14:05,760 --> 00:14:09,600
our best

408
00:14:06,480 --> 00:14:12,639
to protect the geolocation information

409
00:14:09,600 --> 00:14:14,399
and privacy of protesters right and that

410
00:14:12,639 --> 00:14:16,720
also means that we'll have to resist

411
00:14:14,399 --> 00:14:18,720
requests from law enforcement that we

412
00:14:16,720 --> 00:14:21,040
feel

413
00:14:18,720 --> 00:14:22,240
do not have bearing or our legal team

414
00:14:21,040 --> 00:14:24,800
has found like don't meet

415
00:14:22,240 --> 00:14:25,760
the criteria right for us to get

416
00:14:24,800 --> 00:14:29,199
involved

417
00:14:25,760 --> 00:14:31,519
and that's an important thing for any

418
00:14:29,199 --> 00:14:34,079
software development organization for

419
00:14:31,519 --> 00:14:37,120
any programmers developers or companies

420
00:14:34,079 --> 00:14:40,160
is to say what are we doing

421
00:14:37,120 --> 00:14:41,839
to protect folks who are using our

422
00:14:40,160 --> 00:14:45,439
technologies

423
00:14:41,839 --> 00:14:48,720
for social justice to fight inequality

424
00:14:45,440 --> 00:14:50,320
i was a contributor to a project that

425
00:14:48,720 --> 00:14:52,000
i really enjoyed and i feel like it's a

426
00:14:50,320 --> 00:14:54,959
step in the right direction

427
00:14:52,000 --> 00:14:56,320
it was a diverse team a majority of whom

428
00:14:54,959 --> 00:14:59,359
were people of color

429
00:14:56,320 --> 00:15:00,399
and of that group a majority of were

430
00:14:59,360 --> 00:15:03,839
women

431
00:15:00,399 --> 00:15:07,199
and it was a user experience checklist

432
00:15:03,839 --> 00:15:09,839
and it came there's all these uh

433
00:15:07,199 --> 00:15:12,560
thinkings and questions and ideas that

434
00:15:09,839 --> 00:15:16,000
are so important to add to user research

435
00:15:12,560 --> 00:15:17,359
but it's also not naturally part of how

436
00:15:16,000 --> 00:15:19,199
someone might approach that work

437
00:15:17,360 --> 00:15:22,079
so it's easy to skip a step and that's

438
00:15:19,199 --> 00:15:23,439
uh that's something that i heard from

439
00:15:22,079 --> 00:15:25,359
this team i was meeting with at

440
00:15:23,440 --> 00:15:28,399
accessnow's um

441
00:15:25,360 --> 00:15:31,680
write con in brussels

442
00:15:28,399 --> 00:15:33,199
many years ago and

443
00:15:31,680 --> 00:15:35,519
what we've done is we were like okay

444
00:15:33,199 --> 00:15:38,959
let's uh think about this

445
00:15:35,519 --> 00:15:41,920
what what are ways to address this so uh

446
00:15:38,959 --> 00:15:43,758
i chimed in and said you know what in

447
00:15:41,920 --> 00:15:44,399
the security world we use checklist a

448
00:15:43,759 --> 00:15:45,759
lot for

449
00:15:44,399 --> 00:15:46,880
things that are important to make sure

450
00:15:45,759 --> 00:15:48,160
that we don't skip things and they're

451
00:15:46,880 --> 00:15:50,959
manageable right

452
00:15:48,160 --> 00:15:52,000
uh and so they took their research and

453
00:15:50,959 --> 00:15:55,040
their thinking

454
00:15:52,000 --> 00:15:57,040
and this idea of checklist and over the

455
00:15:55,040 --> 00:15:58,079
years developed a checklist for user

456
00:15:57,040 --> 00:16:00,880
experience

457
00:15:58,079 --> 00:16:02,959
and user research and to make sure that

458
00:16:00,880 --> 00:16:05,600
the privacy of the user

459
00:16:02,959 --> 00:16:06,399
is first and foremost right and that a

460
00:16:05,600 --> 00:16:08,399
user

461
00:16:06,399 --> 00:16:09,920
researcher and someone working for the

462
00:16:08,399 --> 00:16:12,560
user experience

463
00:16:09,920 --> 00:16:13,680
of a tool of an app of a programmer

464
00:16:12,560 --> 00:16:14,800
system

465
00:16:13,680 --> 00:16:16,959
are asking themselves the right

466
00:16:14,800 --> 00:16:18,719
questions to make sure that they're

467
00:16:16,959 --> 00:16:19,680
thinking about the practical security

468
00:16:18,720 --> 00:16:22,880
and privacy

469
00:16:19,680 --> 00:16:25,040
of the it's really an honor for me to

470
00:16:22,880 --> 00:16:27,360
use my professional skills to assist

471
00:16:25,040 --> 00:16:30,079
folks i had the honor of

472
00:16:27,360 --> 00:16:30,959
working with a lot of human rights

473
00:16:30,079 --> 00:16:34,638
defenders

474
00:16:30,959 --> 00:16:36,719
journalists lawyers in their fight to

475
00:16:34,639 --> 00:16:38,160
uh you know for social justice and

476
00:16:36,720 --> 00:16:40,160
protecting the rights

477
00:16:38,160 --> 00:16:41,759
of people on the margin people who've

478
00:16:40,160 --> 00:16:44,000
been pushed there for

479
00:16:41,759 --> 00:16:45,440
various reasons uh marginalized

480
00:16:44,000 --> 00:16:47,040
communities whether you're black or

481
00:16:45,440 --> 00:16:49,519
brown or queer folks

482
00:16:47,040 --> 00:16:52,160
uh gender non-conforming folks who just

483
00:16:49,519 --> 00:16:55,279
have different security needs

484
00:16:52,160 --> 00:16:57,519
when developing personas

485
00:16:55,279 --> 00:16:59,040
there's this idea in the title of this

486
00:16:57,519 --> 00:17:02,000
talk

487
00:16:59,040 --> 00:17:03,120
protester as a persona but it's

488
00:17:02,000 --> 00:17:06,559
important to remember that

489
00:17:03,120 --> 00:17:08,000
we don't need in this work a separate

490
00:17:06,559 --> 00:17:12,480
persona

491
00:17:08,000 --> 00:17:13,760
for um dissidents and protesters human

492
00:17:12,480 --> 00:17:16,559
rights defenders and

493
00:17:13,760 --> 00:17:18,480
people fighting for social justice civil

494
00:17:16,559 --> 00:17:20,319
society organizations social justice

495
00:17:18,480 --> 00:17:22,319
leaders

496
00:17:20,319 --> 00:17:24,559
it's important to remember that that

497
00:17:22,319 --> 00:17:27,359
group exists inside

498
00:17:24,559 --> 00:17:28,000
the personas that we come up with

499
00:17:27,359 --> 00:17:31,199
whether

500
00:17:28,000 --> 00:17:34,000
they're users or or people or

501
00:17:31,200 --> 00:17:34,960
clients whatever it is some of those

502
00:17:34,000 --> 00:17:38,400
individuals

503
00:17:34,960 --> 00:17:39,840
are dealing with issues that impact them

504
00:17:38,400 --> 00:17:41,360
differently and it's so important that

505
00:17:39,840 --> 00:17:44,159
the tools that we develop

506
00:17:41,360 --> 00:17:45,280
and that we work on address those issues

507
00:17:44,160 --> 00:17:48,080
and empower

508
00:17:45,280 --> 00:17:48,639
individuals users and it's so important

509
00:17:48,080 --> 00:17:51,918
that

510
00:17:48,640 --> 00:17:55,039
we empower users

511
00:17:51,919 --> 00:17:56,960
to protect themselves from the

512
00:17:55,039 --> 00:17:58,240
unique and different risk and threats

513
00:17:56,960 --> 00:18:00,640
that they face

514
00:17:58,240 --> 00:18:02,480
what this might look like is when

515
00:18:00,640 --> 00:18:05,520
developing scenarios

516
00:18:02,480 --> 00:18:07,440
saying what about this type of user or

517
00:18:05,520 --> 00:18:10,639
what about this type of use case

518
00:18:07,440 --> 00:18:12,559
but adding the identity of a queer

519
00:18:10,640 --> 00:18:15,280
person a black and brown person

520
00:18:12,559 --> 00:18:16,480
a demonstrator someone who's

521
00:18:15,280 --> 00:18:19,840
marginalized

522
00:18:16,480 --> 00:18:22,400
woman um because

523
00:18:19,840 --> 00:18:23,039
the other personas and the other ideas

524
00:18:22,400 --> 00:18:25,280
of

525
00:18:23,039 --> 00:18:26,320
who our users are and who's coming to

526
00:18:25,280 --> 00:18:28,639
these works

527
00:18:26,320 --> 00:18:30,320
cannot lack the intersection of what

528
00:18:28,640 --> 00:18:32,799
these identities cross upon

529
00:18:30,320 --> 00:18:34,080
right whenever i'm thinking about

530
00:18:32,799 --> 00:18:36,160
measuring risk

531
00:18:34,080 --> 00:18:37,439
and threats one of the first things i

532
00:18:36,160 --> 00:18:40,840
have to think about

533
00:18:37,440 --> 00:18:42,000
is the identity of this individual or

534
00:18:40,840 --> 00:18:45,840
organization

535
00:18:42,000 --> 00:18:47,919
and how that identity compounds

536
00:18:45,840 --> 00:18:48,879
right or safeguards them from certain

537
00:18:47,919 --> 00:18:52,400
risks and threats

538
00:18:48,880 --> 00:18:55,679
to people who are considered elderly

539
00:18:52,400 --> 00:18:56,799
suspicious they're pushed out to the

540
00:18:55,679 --> 00:18:59,679
margins

541
00:18:56,799 --> 00:19:01,120
instead of asking and investigating and

542
00:18:59,679 --> 00:19:04,400
measuring oftentimes

543
00:19:01,120 --> 00:19:07,439
we are uh eroding the privacy

544
00:19:04,400 --> 00:19:09,200
surveilling and targeting what

545
00:19:07,440 --> 00:19:10,880
and as we build technologies

546
00:19:09,200 --> 00:19:13,440
technologies can be made

547
00:19:10,880 --> 00:19:14,320
in ways that protect marginalized

548
00:19:13,440 --> 00:19:16,480
communities

549
00:19:14,320 --> 00:19:17,360
and oppressed people where technologies

550
00:19:16,480 --> 00:19:19,679
can be in

551
00:19:17,360 --> 00:19:21,520
made in a way that they are weaponized

552
00:19:19,679 --> 00:19:24,160
against these very communities

553
00:19:21,520 --> 00:19:24,879
and often times it's not with either

554
00:19:24,160 --> 00:19:26,720
intention

555
00:19:24,880 --> 00:19:28,799
and that's the problem if we don't

556
00:19:26,720 --> 00:19:31,760
intentionally balance technologies

557
00:19:28,799 --> 00:19:32,480
leaning towards the idea of how can we

558
00:19:31,760 --> 00:19:34,400
think about

559
00:19:32,480 --> 00:19:36,320
the intersections and identities of our

560
00:19:34,400 --> 00:19:39,039
users and are these use cases and

561
00:19:36,320 --> 00:19:42,159
personas that we're working on

562
00:19:39,039 --> 00:19:44,559
then we introduce the possible risk

563
00:19:42,160 --> 00:19:45,760
of having a huge negative impact instead

564
00:19:44,559 --> 00:19:48,559
of a positive one

565
00:19:45,760 --> 00:19:49,840
it's going to be a wonderful day today

566
00:19:48,559 --> 00:19:53,520
i've been checking out

567
00:19:49,840 --> 00:19:55,760
the early speakers as well as the agenda

568
00:19:53,520 --> 00:19:58,480
for the rest of soups 2020

569
00:19:55,760 --> 00:19:59,840
and i just want to wish you all a great

570
00:19:58,480 --> 00:20:02,880
super 2020

571
00:19:59,840 --> 00:20:05,360
stay safe make this world better and

572
00:20:02,880 --> 00:20:07,760
thank you for your time

573
00:20:05,360 --> 00:20:09,600
i just want to take time out to thank

574
00:20:07,760 --> 00:20:10,720
all of you who are recipients of the

575
00:20:09,600 --> 00:20:12,799
different grants

576
00:20:10,720 --> 00:20:14,159
whether it was a diversity grant a

577
00:20:12,799 --> 00:20:17,039
student grant

578
00:20:14,159 --> 00:20:18,480
diversity makes conferences better it

579
00:20:17,039 --> 00:20:20,158
makes usements better

580
00:20:18,480 --> 00:20:21,919
it makes security better and of course

581
00:20:20,159 --> 00:20:24,240
makes supes better and

582
00:20:21,919 --> 00:20:35,840
congratulations thank you for being here

583
00:20:24,240 --> 00:20:35,840
and have a wonderful day today

584
00:20:39,919 --> 00:20:42,000
you

