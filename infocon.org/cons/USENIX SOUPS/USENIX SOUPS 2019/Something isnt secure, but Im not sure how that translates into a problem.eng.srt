1
00:00:10,790 --> 00:00:15,110
okay well I'm gonna share with you some

2
00:00:12,530 --> 00:00:17,210
work that was spearheaded by my graduate

3
00:00:15,110 --> 00:00:18,560
student Justin woo he at first he

4
00:00:17,210 --> 00:00:22,599
couldn't be here today he's about to

5
00:00:18,560 --> 00:00:25,310
graduate and move on to a job at Sandia

6
00:00:22,599 --> 00:00:27,109
and he supervised a number of students

7
00:00:25,310 --> 00:00:29,630
that worked on this project as a

8
00:00:27,109 --> 00:00:31,669
collaborative effort now what we're

9
00:00:29,630 --> 00:00:35,000
really interested in looking at is how

10
00:00:31,669 --> 00:00:36,800
do we help users choose behaviors that

11
00:00:35,000 --> 00:00:38,960
enhance their security and privacy and

12
00:00:36,800 --> 00:00:41,739
the emphasis there is on the word shoes

13
00:00:38,960 --> 00:00:44,090
we're not looking at areas where

14
00:00:41,739 --> 00:00:46,160
compliances is in place in a workplace

15
00:00:44,090 --> 00:00:48,110
where people are kind of forced or

16
00:00:46,160 --> 00:00:50,179
required to do something secure a

17
00:00:48,110 --> 00:00:52,340
private but really where they're gonna

18
00:00:50,180 --> 00:00:53,480
actually choose on their own to adopt

19
00:00:52,340 --> 00:00:55,910
some behavior we're looking at the

20
00:00:53,480 --> 00:00:58,370
general public here in the example that

21
00:00:55,910 --> 00:01:00,140
we used for our study was to look at the

22
00:00:58,370 --> 00:01:02,809
authentication ceremony and secure

23
00:01:00,140 --> 00:01:04,759
messaging apps specifically signal and

24
00:01:02,809 --> 00:01:07,399
applications that are based on the

25
00:01:04,759 --> 00:01:09,429
signal protocol like whatsapp and so I'm

26
00:01:07,399 --> 00:01:11,990
going to give you a quick tour through

27
00:01:09,429 --> 00:01:14,869
what we mean by the authentication

28
00:01:11,990 --> 00:01:17,479
ceremony and how this works in signal so

29
00:01:14,869 --> 00:01:20,179
here is an example of two users I'm

30
00:01:17,479 --> 00:01:22,940
using Aisha and Booker they both

31
00:01:20,179 --> 00:01:24,950
installed the signal app on their phones

32
00:01:22,940 --> 00:01:26,840
and you see that they were both assigned

33
00:01:24,950 --> 00:01:29,690
a public and private key pair I'm

34
00:01:26,840 --> 00:01:32,270
denoting ayisha's insert this gold

35
00:01:29,690 --> 00:01:35,390
colored and Booker's in the blue colored

36
00:01:32,270 --> 00:01:37,069
key when they register their app with

37
00:01:35,390 --> 00:01:39,229
signal when they reach their phone with

38
00:01:37,069 --> 00:01:41,690
the signal server they're going to share

39
00:01:39,229 --> 00:01:43,340
their public key with the signal server

40
00:01:41,690 --> 00:01:45,709
and so here's a shoe doing it

41
00:01:43,340 --> 00:01:47,300
here's Booker doing it then at some

42
00:01:45,709 --> 00:01:48,259
later point in time when they want to

43
00:01:47,300 --> 00:01:51,229
talk to each other

44
00:01:48,259 --> 00:01:53,539
Aisha needs to download Booker's public

45
00:01:51,229 --> 00:01:55,959
key from the signal server and Booker

46
00:01:53,539 --> 00:01:58,789
needs to do the same thing for Aisha

47
00:01:55,959 --> 00:02:00,979
then at some point in time when they

48
00:01:58,789 --> 00:02:02,390
begin their conversation they're going

49
00:02:00,979 --> 00:02:04,190
to drive a secret key for the

50
00:02:02,390 --> 00:02:05,929
conversation they're gonna combine the

51
00:02:04,190 --> 00:02:08,119
yellow and the blue keys to derive here

52
00:02:05,929 --> 00:02:09,800
I'm showing a black key to derive a

53
00:02:08,119 --> 00:02:12,620
secret key Booker will do the same thing

54
00:02:09,800 --> 00:02:14,840
as Aisha and then they will use this key

55
00:02:12,620 --> 00:02:17,540
to begin communicating with each other

56
00:02:14,840 --> 00:02:19,519
using encrypted messages and there's

57
00:02:17,540 --> 00:02:21,108
some details here in terms of how signal

58
00:02:19,519 --> 00:02:23,270
ratchet's those keys it continually

59
00:02:21,109 --> 00:02:24,770
changes those keys over time

60
00:02:23,270 --> 00:02:26,570
but the basic idea here is that we need

61
00:02:24,770 --> 00:02:28,880
to start with public keys that are

62
00:02:26,570 --> 00:02:30,470
correct for those two users and from

63
00:02:28,880 --> 00:02:33,799
there we can derive secret keys to

64
00:02:30,470 --> 00:02:36,740
encrypt messages in the conversation but

65
00:02:33,800 --> 00:02:38,660
we have to beware we might have an

66
00:02:36,740 --> 00:02:41,090
attacker who tries to break into the

67
00:02:38,660 --> 00:02:43,460
system so here I'm showing our elite

68
00:02:41,090 --> 00:02:45,500
hacker who has broken into the signal

69
00:02:43,460 --> 00:02:47,540
server and what this hacker is gonna do

70
00:02:45,500 --> 00:02:50,090
she's going to give a red key to Ayesha

71
00:02:47,540 --> 00:02:52,160
claiming that that is Booker's key and a

72
00:02:50,090 --> 00:02:55,100
red key to book her claiming it's

73
00:02:52,160 --> 00:02:57,980
Ayesha's public key and then she's going

74
00:02:55,100 --> 00:03:00,140
to have them derive their secret keys

75
00:02:57,980 --> 00:03:02,619
we have Ayesha driving sort of a dark

76
00:03:00,140 --> 00:03:06,140
grey and Booker driving a light grey key

77
00:03:02,620 --> 00:03:08,660
and now she's gonna sit in the middle of

78
00:03:06,140 --> 00:03:11,179
that conversation she's going to be

79
00:03:08,660 --> 00:03:12,770
using the dark key to talk with Aisha

80
00:03:11,180 --> 00:03:16,250
and the light grey key to talk with

81
00:03:12,770 --> 00:03:18,470
Booker and be able to intercept those

82
00:03:16,250 --> 00:03:19,910
those messages so she can listen in on

83
00:03:18,470 --> 00:03:22,060
all the messages she contentiously even

84
00:03:19,910 --> 00:03:25,310
changed messages in this conversation so

85
00:03:22,060 --> 00:03:28,220
how are we going to help Asian Booker to

86
00:03:25,310 --> 00:03:29,540
foil the attacker inside of signal

87
00:03:28,220 --> 00:03:32,630
there's something called the

88
00:03:29,540 --> 00:03:34,900
authentication ceremony they should be

89
00:03:32,630 --> 00:03:37,250
able to take their two public keys and

90
00:03:34,900 --> 00:03:38,990
combine them there's an algorithm signal

91
00:03:37,250 --> 00:03:41,570
users to take parts of their public keys

92
00:03:38,990 --> 00:03:43,810
and derive what signal calls safety

93
00:03:41,570 --> 00:03:45,739
numbers which are key fingerprints and

94
00:03:43,810 --> 00:03:47,780
Booker is going to be able to do the

95
00:03:45,740 --> 00:03:49,550
same thing independently of Asia and so

96
00:03:47,780 --> 00:03:52,070
they need to somehow get together and

97
00:03:49,550 --> 00:03:53,690
compare these key fingerprints the

98
00:03:52,070 --> 00:03:56,600
safety numbers and make sure that they

99
00:03:53,690 --> 00:03:58,160
match they have to do that by scanning a

100
00:03:56,600 --> 00:04:00,680
QR code if they have to be in the same

101
00:03:58,160 --> 00:04:02,690
place or maybe making a phone call and

102
00:04:00,680 --> 00:04:04,610
reading these long numbers over a phone

103
00:04:02,690 --> 00:04:06,350
call to make sure that they match we

104
00:04:04,610 --> 00:04:08,300
refer to this as the authentication

105
00:04:06,350 --> 00:04:11,840
ceremony they were authenticating each

106
00:04:08,300 --> 00:04:13,850
other and if they've received keys from

107
00:04:11,840 --> 00:04:15,620
this hacker who's broken in a signal

108
00:04:13,850 --> 00:04:17,120
server then they will be computing

109
00:04:15,620 --> 00:04:20,269
different safety numbers and they won't

110
00:04:17,120 --> 00:04:22,820
match so it turns out there's been

111
00:04:20,269 --> 00:04:24,859
research done on this quite a few papers

112
00:04:22,820 --> 00:04:27,140
that can cite their and not too

113
00:04:24,860 --> 00:04:29,120
surprising the users don't perform that

114
00:04:27,140 --> 00:04:31,610
authentication ceremony organically and

115
00:04:29,120 --> 00:04:33,169
even if we prompt them to do it they

116
00:04:31,610 --> 00:04:34,760
don't complete it properly and they

117
00:04:33,169 --> 00:04:36,659
don't really understand the importance

118
00:04:34,760 --> 00:04:40,680
of it or what this is doing to

119
00:04:36,660 --> 00:04:43,380
protect their privacy our prior approach

120
00:04:40,680 --> 00:04:45,390
that we published last year at Supes was

121
00:04:43,380 --> 00:04:48,120
to try to get everyone to always

122
00:04:45,390 --> 00:04:50,190
complete the authentication ceremony and

123
00:04:48,120 --> 00:04:52,110
we used opinionated design to try to

124
00:04:50,190 --> 00:04:53,880
encourage users and really push them

125
00:04:52,110 --> 00:04:57,890
towards hey you should do this ceremony

126
00:04:53,880 --> 00:05:00,090
and we focused on adherence rates and

127
00:04:57,890 --> 00:05:02,550
timing to try to get that to be as fast

128
00:05:00,090 --> 00:05:05,070
as possible so there's some advantages

129
00:05:02,550 --> 00:05:06,270
to that approach we did manage to show

130
00:05:05,070 --> 00:05:07,590
that you could increase security this

131
00:05:06,270 --> 00:05:09,870
way we get more people doing the

132
00:05:07,590 --> 00:05:11,549
ceremony so it's really easy to measure

133
00:05:09,870 --> 00:05:13,320
adherence to see how many people are

134
00:05:11,550 --> 00:05:15,090
doing it you can measure time to

135
00:05:13,320 --> 00:05:15,390
completion and see how fast it takes to

136
00:05:15,090 --> 00:05:17,760
do it

137
00:05:15,390 --> 00:05:20,669
but there's a real drawback here in that

138
00:05:17,760 --> 00:05:22,680
we're ignoring perception of risk from

139
00:05:20,670 --> 00:05:24,360
the users we're requiring them to do

140
00:05:22,680 --> 00:05:25,740
this ceremony even if they think oh this

141
00:05:24,360 --> 00:05:28,140
particular conversation is not

142
00:05:25,740 --> 00:05:30,390
particularly important and we're

143
00:05:28,140 --> 00:05:32,340
ignoring response costs so we're trying

144
00:05:30,390 --> 00:05:35,520
to push them to do something that does

145
00:05:32,340 --> 00:05:37,979
take some meaningful time and effort

146
00:05:35,520 --> 00:05:39,930
when they may consider that effort be

147
00:05:37,980 --> 00:05:43,050
wasted if they don't perceive a genuine

148
00:05:39,930 --> 00:05:45,570
risk here it turns out that almost

149
00:05:43,050 --> 00:05:47,550
always your security number should

150
00:05:45,570 --> 00:05:50,040
change because one of you reinstalled

151
00:05:47,550 --> 00:05:52,620
signal not because there was a hacker in

152
00:05:50,040 --> 00:05:55,650
present there I'm not aware of any

153
00:05:52,620 --> 00:05:57,720
particular case where signal or some

154
00:05:55,650 --> 00:05:59,489
secure messaging service like whatsapp

155
00:05:57,720 --> 00:06:01,680
has been hacked in the way of we're

156
00:05:59,490 --> 00:06:03,600
gonna actually make these safety numbers

157
00:06:01,680 --> 00:06:06,510
change so what this means is that

158
00:06:03,600 --> 00:06:08,100
response cost is high and risk is low

159
00:06:06,510 --> 00:06:09,930
and that's a bad situation in which

160
00:06:08,100 --> 00:06:13,320
you're going to force everyone to follow

161
00:06:09,930 --> 00:06:15,780
through on this there's a great quote

162
00:06:13,320 --> 00:06:17,250
from Angela sass in this paper for a

163
00:06:15,780 --> 00:06:19,440
number of years ago that says security

164
00:06:17,250 --> 00:06:21,390
that routinely diverts the attention and

165
00:06:19,440 --> 00:06:23,730
disrupts the activities of users and

166
00:06:21,390 --> 00:06:25,680
pursuit of their primary goals is thus

167
00:06:23,730 --> 00:06:26,090
the antithesis of a user centred

168
00:06:25,680 --> 00:06:28,590
approach

169
00:06:26,090 --> 00:06:31,140
okay and she called this bullying users

170
00:06:28,590 --> 00:06:34,169
into into having strong security or

171
00:06:31,140 --> 00:06:36,000
privacy practices so our approach is

172
00:06:34,169 --> 00:06:37,530
grounded in a theory called risk

173
00:06:36,000 --> 00:06:39,660
communication this has been used

174
00:06:37,530 --> 00:06:42,419
extensively in areas of Public Health

175
00:06:39,660 --> 00:06:44,789
and the idea is to help users understand

176
00:06:42,419 --> 00:06:47,849
the likelihood of a risk as well as the

177
00:06:44,789 --> 00:06:50,190
severity of the risk and then also help

178
00:06:47,850 --> 00:06:51,510
them understand response efficacy what

179
00:06:50,190 --> 00:06:55,110
action could they take that would

180
00:06:51,510 --> 00:06:57,659
mitigate that risk and how how well does

181
00:06:55,110 --> 00:07:00,510
that response actually address their

182
00:06:57,660 --> 00:07:02,250
concern and also understand response

183
00:07:00,510 --> 00:07:04,770
cost so how much is this going to cost

184
00:07:02,250 --> 00:07:08,580
them and success comes in risk

185
00:07:04,770 --> 00:07:11,159
communication not if everyone adheres to

186
00:07:08,580 --> 00:07:13,680
best practices but instead if users are

187
00:07:11,160 --> 00:07:16,830
making informed choices that align with

188
00:07:13,680 --> 00:07:18,750
their own values and perceptions so if

189
00:07:16,830 --> 00:07:20,820
someone perceives for example in our

190
00:07:18,750 --> 00:07:23,010
situation that this is a conversation

191
00:07:20,820 --> 00:07:25,140
that's not particularly important and so

192
00:07:23,010 --> 00:07:26,310
they're not concerned about doing the

193
00:07:25,140 --> 00:07:28,650
authentication so maybe that's in

194
00:07:26,310 --> 00:07:30,330
alignment and we're okay with that but

195
00:07:28,650 --> 00:07:33,239
if they do perceive that the risk is

196
00:07:30,330 --> 00:07:34,979
likely and severe then we're hoping that

197
00:07:33,240 --> 00:07:37,350
they should also perceive there's this

198
00:07:34,980 --> 00:07:38,610
response that they can use and we should

199
00:07:37,350 --> 00:07:40,820
see them follow through and do the

200
00:07:38,610 --> 00:07:44,820
authentication certainly in that case

201
00:07:40,820 --> 00:07:47,670
okay so our work consists of three parts

202
00:07:44,820 --> 00:07:50,370
the first part was to evaluate warnings

203
00:07:47,670 --> 00:07:52,860
in signal to see how good they are at

204
00:07:50,370 --> 00:07:55,230
risk communication we did both a

205
00:07:52,860 --> 00:07:57,810
cognitive walkthrough and a fairly

206
00:07:55,230 --> 00:07:59,960
extensive lab user study to study how

207
00:07:57,810 --> 00:08:02,670
well their their existing warnings were

208
00:07:59,960 --> 00:08:04,500
we then took what we learned and

209
00:08:02,670 --> 00:08:06,360
developed improvements that involved

210
00:08:04,500 --> 00:08:08,370
some Mechanical Turk studies to design

211
00:08:06,360 --> 00:08:10,440
those improvements as well as a

212
00:08:08,370 --> 00:08:12,120
simulated signal experience so that we

213
00:08:10,440 --> 00:08:13,590
could sample with a large number of

214
00:08:12,120 --> 00:08:14,850
Mechanical Turk users walking them

215
00:08:13,590 --> 00:08:17,909
through this to see how well they

216
00:08:14,850 --> 00:08:22,020
understood it and then we evaluated our

217
00:08:17,910 --> 00:08:23,760
new design that resulted by also using

218
00:08:22,020 --> 00:08:25,950
some of that data from the simulated

219
00:08:23,760 --> 00:08:27,659
signal experience and then repeating our

220
00:08:25,950 --> 00:08:29,760
lab user study with a new set of users

221
00:08:27,660 --> 00:08:31,669
to see if their behavior changed if

222
00:08:29,760 --> 00:08:34,169
their understanding changed

223
00:08:31,669 --> 00:08:35,760
unfortunately there's way too much in

224
00:08:34,169 --> 00:08:38,218
the paper for me to go through and cover

225
00:08:35,760 --> 00:08:41,250
all that for you so instead I'm going to

226
00:08:38,219 --> 00:08:42,930
cover the highlights in three areas what

227
00:08:41,250 --> 00:08:45,420
things did we find were wrong with

228
00:08:42,929 --> 00:08:47,959
signal what did we do to fix them and

229
00:08:45,420 --> 00:08:50,610
how well did our improvements fix things

230
00:08:47,960 --> 00:08:51,390
hey to guide you through that it's

231
00:08:50,610 --> 00:08:53,790
getting a little late in the afternoon

232
00:08:51,390 --> 00:08:56,010
so we're going to use Doctor Who to help

233
00:08:53,790 --> 00:08:58,560
signal that we're getting to a new part

234
00:08:56,010 --> 00:09:00,480
of the talk so here is the very best

235
00:08:58,560 --> 00:09:03,310
Doctor Who portrayal by Jodie Whittaker

236
00:09:00,480 --> 00:09:04,990
and that she's looking vaguely

237
00:09:03,310 --> 00:09:06,579
worried that there might be some areas

238
00:09:04,990 --> 00:09:08,050
for improvement in signal and so I'm

239
00:09:06,580 --> 00:09:12,550
going to walk you through some of those

240
00:09:08,050 --> 00:09:15,279
areas of concern we diagrammed in our

241
00:09:12,550 --> 00:09:17,199
cognitive walkthrough every single

242
00:09:15,279 --> 00:09:20,529
interaction between every single screen

243
00:09:17,200 --> 00:09:22,930
in signal and this is a subset of that

244
00:09:20,529 --> 00:09:24,850
very large picture showing just the

245
00:09:22,930 --> 00:09:27,930
interactions for how you would get to

246
00:09:24,850 --> 00:09:31,210
the authentications ceremony in signal

247
00:09:27,930 --> 00:09:33,250
if you walk through this there's

248
00:09:31,210 --> 00:09:35,589
actually three different ways three

249
00:09:33,250 --> 00:09:38,650
different scenarios in which you can get

250
00:09:35,589 --> 00:09:42,370
to the authentication ceremony there is

251
00:09:38,650 --> 00:09:44,439
this top path which happens in certain

252
00:09:42,370 --> 00:09:47,470
situations and then you end up having

253
00:09:44,440 --> 00:09:49,660
your message not be delivered it's like

254
00:09:47,470 --> 00:09:51,400
your cell phone connection was broken

255
00:09:49,660 --> 00:09:52,630
and so the message isn't delivered

256
00:09:51,400 --> 00:09:54,069
there's a little warning there and if

257
00:09:52,630 --> 00:09:56,410
you click on that warning it says well

258
00:09:54,070 --> 00:09:59,950
your safety numbers with Alice have

259
00:09:56,410 --> 00:10:01,300
changed this could mean that someone is

260
00:09:59,950 --> 00:10:03,760
trying to intercept the communications

261
00:10:01,300 --> 00:10:06,219
or it could be that Alice simply

262
00:10:03,760 --> 00:10:07,750
reinstalled signal gives a link to the

263
00:10:06,220 --> 00:10:11,260
authentication ceremony and then these

264
00:10:07,750 --> 00:10:14,470
accept and cancel buttons so that's one

265
00:10:11,260 --> 00:10:17,740
flow through here the bottom flow is

266
00:10:14,470 --> 00:10:19,360
when the numbers change in the middle of

267
00:10:17,740 --> 00:10:21,190
a conversation with someone's signal

268
00:10:19,360 --> 00:10:26,110
considers this to be more alarming and

269
00:10:21,190 --> 00:10:29,050
so it instead excuse me this is the

270
00:10:26,110 --> 00:10:32,920
bottom flow and so in this case it just

271
00:10:29,050 --> 00:10:34,329
simply puts a warning message in there

272
00:10:32,920 --> 00:10:36,130
so there's a very little warning message

273
00:10:34,330 --> 00:10:38,440
at the bottom saying your safety number

274
00:10:36,130 --> 00:10:41,410
with Alice has changed otherwise you can

275
00:10:38,440 --> 00:10:44,530
continue communicating and then we have

276
00:10:41,410 --> 00:10:45,969
this flow here which does actually block

277
00:10:44,530 --> 00:10:47,589
the message you're in the middle of

278
00:10:45,970 --> 00:10:49,720
sending your message when you press the

279
00:10:47,589 --> 00:10:50,950
send button then it says whoa wait a

280
00:10:49,720 --> 00:10:52,959
minute your safety numbers have changed

281
00:10:50,950 --> 00:10:54,970
do you really want to send this message

282
00:10:52,959 --> 00:10:56,560
it does not give you a link to the

283
00:10:54,970 --> 00:10:58,360
authentication ceremony and then you can

284
00:10:56,560 --> 00:11:02,170
click send or cancel here if you want to

285
00:10:58,360 --> 00:11:04,120
go ahead and send your message or not so

286
00:11:02,170 --> 00:11:05,890
we took all of this and put this into a

287
00:11:04,120 --> 00:11:07,540
user study we walked users through

288
00:11:05,890 --> 00:11:09,730
different scenarios and then

289
00:11:07,540 --> 00:11:11,949
investigated what their perceptions of

290
00:11:09,730 --> 00:11:13,480
risk were and response efficacy and

291
00:11:11,950 --> 00:11:15,820
whether they understood what was being

292
00:11:13,480 --> 00:11:16,819
shown here and what we found was some

293
00:11:15,820 --> 00:11:19,220
really unclear

294
00:11:16,819 --> 00:11:22,399
risk communication so if you take a look

295
00:11:19,220 --> 00:11:24,729
at this warning here it's saying that

296
00:11:22,399 --> 00:11:28,100
some issues need your attention and

297
00:11:24,729 --> 00:11:30,199
Alice has a new safety number and we

298
00:11:28,100 --> 00:11:31,759
have regularly found as we've done it

299
00:11:30,199 --> 00:11:34,248
user studies with signal that users

300
00:11:31,759 --> 00:11:35,869
don't know what a safety number is they

301
00:11:34,249 --> 00:11:37,489
don't know what it means that the safety

302
00:11:35,869 --> 00:11:40,399
number has changed and so there's no way

303
00:11:37,489 --> 00:11:43,339
for them to perceive what is the risk

304
00:11:40,399 --> 00:11:45,529
going on here why am I at risk here what

305
00:11:43,339 --> 00:11:48,499
exactly is that risk how likely is it

306
00:11:45,529 --> 00:11:50,809
how severe is it there's just not a lot

307
00:11:48,499 --> 00:11:53,720
for them to go on to judge how severe

308
00:11:50,809 --> 00:11:55,189
this this warning is when they go

309
00:11:53,720 --> 00:11:57,559
through and start clicking through some

310
00:11:55,189 --> 00:12:00,199
of these dialogs these dialogs don't

311
00:11:57,559 --> 00:12:01,939
communicate response costs so we're not

312
00:12:00,199 --> 00:12:03,919
really telling users this is what it's

313
00:12:01,939 --> 00:12:05,959
going to take to verify their safety

314
00:12:03,919 --> 00:12:07,309
numbers how long we'll take you need to

315
00:12:05,959 --> 00:12:09,319
be in the same room or you need to make

316
00:12:07,309 --> 00:12:12,228
a phone call these things are not

317
00:12:09,319 --> 00:12:14,179
communicated the consequences of actions

318
00:12:12,229 --> 00:12:15,919
are not clear it turns out that if

319
00:12:14,179 --> 00:12:17,899
you're sending messages that just don't

320
00:12:15,919 --> 00:12:19,609
go through and then you pop up this

321
00:12:17,899 --> 00:12:20,239
dialog that says hey your safety number

322
00:12:19,609 --> 00:12:22,039
has changed

323
00:12:20,239 --> 00:12:24,829
if you click accept here it actually

324
00:12:22,039 --> 00:12:26,959
sends all of your backlog messages which

325
00:12:24,829 --> 00:12:29,839
is maybe not a good thing to do if the

326
00:12:26,959 --> 00:12:31,128
conversation is being intercepted and

327
00:12:29,839 --> 00:12:34,999
that's it's just not clear that that's

328
00:12:31,129 --> 00:12:38,029
going to happen if you do happen to get

329
00:12:34,999 --> 00:12:40,369
the authentication ceremony the

330
00:12:38,029 --> 00:12:42,679
implications of success or failure are

331
00:12:40,369 --> 00:12:45,529
not clear so if these numbers don't

332
00:12:42,679 --> 00:12:47,238
match if you scan them with a QR code

333
00:12:45,529 --> 00:12:50,029
you get a big red X but then it doesn't

334
00:12:47,239 --> 00:12:52,579
tell you anything after that and if they

335
00:12:50,029 --> 00:12:54,229
do match it doesn't say oh this is what

336
00:12:52,579 --> 00:12:56,029
that means that they match that means

337
00:12:54,229 --> 00:12:59,629
you're talking to the right person for

338
00:12:56,029 --> 00:13:01,579
example there's this little toggle

339
00:12:59,629 --> 00:13:03,889
button that you're supposed to switch

340
00:13:01,579 --> 00:13:07,488
only if you make sure that the safety

341
00:13:03,889 --> 00:13:09,379
numbers match and people just turn that

342
00:13:07,489 --> 00:13:11,779
toggle on and say oh that must have

343
00:13:09,379 --> 00:13:13,999
verified my contact magic my

344
00:13:11,779 --> 00:13:15,889
conversation looks secure now and so

345
00:13:13,999 --> 00:13:18,489
they don't really understand know they

346
00:13:15,889 --> 00:13:21,199
were supposed to check before toggling

347
00:13:18,489 --> 00:13:22,999
okay so here's Jodie Whittaker again now

348
00:13:21,199 --> 00:13:25,189
she's looking pleased because she has

349
00:13:22,999 --> 00:13:26,239
seen our improvements to signal and so

350
00:13:25,189 --> 00:13:30,370
you're gonna we're gonna walk through

351
00:13:26,239 --> 00:13:32,860
what we did to change signal

352
00:13:30,370 --> 00:13:35,920
we simplified that complicated diagram

353
00:13:32,860 --> 00:13:38,260
down to a single flow so we have one

354
00:13:35,920 --> 00:13:40,390
possible flow if the safety numbers ever

355
00:13:38,260 --> 00:13:42,310
change for any reason we will block the

356
00:13:40,390 --> 00:13:44,140
very next message of ussen and not allow

357
00:13:42,310 --> 00:13:45,729
it to go through we have some data to

358
00:13:44,140 --> 00:13:48,970
back up that choice as to why that was a

359
00:13:45,730 --> 00:13:51,220
good choice we then use positive framing

360
00:13:48,970 --> 00:13:53,980
for the authentication ceremony we use

361
00:13:51,220 --> 00:13:55,750
the terms privacy check we are going to

362
00:13:53,980 --> 00:13:58,030
encourage you to check your privacy in

363
00:13:55,750 --> 00:14:00,310
this case and everything around this

364
00:13:58,030 --> 00:14:02,800
ceremony is framed around positive words

365
00:14:00,310 --> 00:14:04,479
so if that succeeds then the privacy

366
00:14:02,800 --> 00:14:08,620
check means that your privacy is

367
00:14:04,480 --> 00:14:11,170
guaranteed we also communicate response

368
00:14:08,620 --> 00:14:13,270
costs we tell them right up front that

369
00:14:11,170 --> 00:14:14,770
this is going to take a few minutes for

370
00:14:13,270 --> 00:14:16,780
them to do and that they need to either

371
00:14:14,770 --> 00:14:18,189
be in the same room or make a phone call

372
00:14:16,780 --> 00:14:20,949
with the person that they're talking to

373
00:14:18,190 --> 00:14:23,890
we clearly label their choices they can

374
00:14:20,950 --> 00:14:25,510
say oh not now or yes I do want to get

375
00:14:23,890 --> 00:14:26,800
started with that right now so it's very

376
00:14:25,510 --> 00:14:30,310
clear what they're choosing to do

377
00:14:26,800 --> 00:14:32,709
instead of just okay or cancel then if

378
00:14:30,310 --> 00:14:34,780
they click not now we give them the

379
00:14:32,710 --> 00:14:36,190
option to be reminded later that they

380
00:14:34,780 --> 00:14:38,860
might want to do it at some later point

381
00:14:36,190 --> 00:14:41,850
in time if they click get started we go

382
00:14:38,860 --> 00:14:44,860
to a new authentication ceremony screen

383
00:14:41,850 --> 00:14:46,750
we change the safety number terminology

384
00:14:44,860 --> 00:14:46,960
to instead talk about device identifier

385
00:14:46,750 --> 00:14:49,720
x'

386
00:14:46,960 --> 00:14:51,760
that's based on some work we did last

387
00:14:49,720 --> 00:14:53,290
year on mental modeling and when people

388
00:14:51,760 --> 00:14:56,439
think of encryption they think of it as

389
00:14:53,290 --> 00:14:58,060
a permission where a blocking access and

390
00:14:56,440 --> 00:14:59,320
so we're trying to cast the

391
00:14:58,060 --> 00:15:01,530
authentication somewhere instead in

392
00:14:59,320 --> 00:15:04,810
terms of granting access to your device

393
00:15:01,530 --> 00:15:07,480
so we split that safety number up and we

394
00:15:04,810 --> 00:15:09,760
also divided it in into two parts

395
00:15:07,480 --> 00:15:11,800
your identifier the other person's in a

396
00:15:09,760 --> 00:15:13,120
fire and then we group the numbers into

397
00:15:11,800 --> 00:15:15,130
groups of three to reduce cognitive

398
00:15:13,120 --> 00:15:17,350
loads so now instead of saying that I

399
00:15:15,130 --> 00:15:20,020
have to read for seven nine zero zero

400
00:15:17,350 --> 00:15:23,170
six I can read for seventy nine six and

401
00:15:20,020 --> 00:15:24,730
and so forth one of the biggest

402
00:15:23,170 --> 00:15:26,500
complaints we've had in the number of

403
00:15:24,730 --> 00:15:28,750
studies we've done is the length of the

404
00:15:26,500 --> 00:15:31,270
safety numbers and so this way it's it's

405
00:15:28,750 --> 00:15:32,830
really only one two three four five

406
00:15:31,270 --> 00:15:34,900
there's ten numbers they have to read

407
00:15:32,830 --> 00:15:36,340
and then have their partner reading ten

408
00:15:34,900 --> 00:15:40,240
numbers which is much shorter than

409
00:15:36,340 --> 00:15:42,029
having to read the longer number we

410
00:15:40,240 --> 00:15:44,160
communicated a

411
00:15:42,029 --> 00:15:46,470
success and failure and what they should

412
00:15:44,160 --> 00:15:47,939
do in those cases if failure occurs we

413
00:15:46,470 --> 00:15:50,220
give them a warning and say you probably

414
00:15:47,939 --> 00:15:52,049
shouldn't talk to this person if you're

415
00:15:50,220 --> 00:15:54,509
using sensitive information in the

416
00:15:52,049 --> 00:15:57,629
conversation and if it works we give

417
00:15:54,509 --> 00:16:00,509
them a privacy verified logo we

418
00:15:57,629 --> 00:16:02,549
redesigned icons and so we have a new

419
00:16:00,509 --> 00:16:04,769
icon that appears in the header with

420
00:16:02,549 --> 00:16:07,230
three different states the default state

421
00:16:04,769 --> 00:16:08,790
the verified state and the unsafe state

422
00:16:07,230 --> 00:16:10,980
indicating whether this particular

423
00:16:08,790 --> 00:16:13,319
conversation is safe or not you can

424
00:16:10,980 --> 00:16:15,689
actually click on that icon and it will

425
00:16:13,319 --> 00:16:17,549
lead to a dialog to say hey you can do

426
00:16:15,689 --> 00:16:21,089
the privacy check if you want to verify

427
00:16:17,549 --> 00:16:23,549
your conversation if you are verified it

428
00:16:21,089 --> 00:16:24,989
will click and tell you yes you are

429
00:16:23,549 --> 00:16:28,230
verified if you want to go back and

430
00:16:24,989 --> 00:16:30,299
double check you can do that and if it

431
00:16:28,230 --> 00:16:31,980
failed you can click and say there's

432
00:16:30,299 --> 00:16:33,720
this big warning here don't communicate

433
00:16:31,980 --> 00:16:38,249
any sensitive information with this

434
00:16:33,720 --> 00:16:39,839
contact all right now Jodie is telling

435
00:16:38,249 --> 00:16:41,519
us it's time to do some experiments and

436
00:16:39,839 --> 00:16:44,419
see how well these improvements actually

437
00:16:41,519 --> 00:16:46,769
worked we did a user study where we

438
00:16:44,419 --> 00:16:49,410
modified the signal source code to

439
00:16:46,769 --> 00:16:51,359
simulate a man the middle at our desire

440
00:16:49,410 --> 00:16:52,769
so we were sitting by a study

441
00:16:51,359 --> 00:16:56,160
coordinators with a button we could push

442
00:16:52,769 --> 00:16:58,379
to say man the middle right now we had

443
00:16:56,160 --> 00:17:01,319
four groups of people that came in in

444
00:16:58,379 --> 00:17:03,029
pairs they each group walked through one

445
00:17:01,319 --> 00:17:05,789
of these four flows the three original

446
00:17:03,029 --> 00:17:08,579
flows and our newly designed flow so we

447
00:17:05,789 --> 00:17:11,929
had 60 pairs 120 participants all

448
00:17:08,579 --> 00:17:16,589
together with 15 pairs doing each flow

449
00:17:11,929 --> 00:17:19,110
we asked them did you perceive any risk

450
00:17:16,589 --> 00:17:21,569
while you were using this app this was

451
00:17:19,109 --> 00:17:23,519
all during a non risky scenario so they

452
00:17:21,569 --> 00:17:25,199
were just talking about a vacation that

453
00:17:23,519 --> 00:17:27,569
they had and then we turned on the man

454
00:17:25,199 --> 00:17:29,909
in the middle and we were able to show

455
00:17:27,569 --> 00:17:32,970
that two-thirds of the users in the new

456
00:17:29,909 --> 00:17:34,500
design perceived a risk in the middle

457
00:17:32,970 --> 00:17:35,730
flow the flow where the message just

458
00:17:34,500 --> 00:17:38,340
goes through and there's a little

459
00:17:35,730 --> 00:17:41,250
notification of this of the shield

460
00:17:38,340 --> 00:17:43,918
notification very few people noticed

461
00:17:41,250 --> 00:17:45,360
that at all and we had noticed the

462
00:17:43,919 --> 00:17:46,679
message block flow worked pretty well

463
00:17:45,360 --> 00:17:50,969
and that was why we were working with

464
00:17:46,679 --> 00:17:52,860
the blocking flow in our case - we asked

465
00:17:50,970 --> 00:17:54,240
people then oh you perceived a risk what

466
00:17:52,860 --> 00:17:55,520
did you do to cope with the risk and

467
00:17:54,240 --> 00:17:57,140
we're really hoping our risk

468
00:17:55,520 --> 00:17:59,320
communication worked and they say oh I

469
00:17:57,140 --> 00:18:02,420
should do the privacy check if my

470
00:17:59,320 --> 00:18:05,149
privacy is at risk and no actually that

471
00:18:02,420 --> 00:18:07,040
was not what they chose they said oh I'm

472
00:18:05,150 --> 00:18:10,250
just gonna not I'm gonna avoid talking

473
00:18:07,040 --> 00:18:12,980
about anything sensitive they said I'm

474
00:18:10,250 --> 00:18:15,200
gonna just use a phone call

475
00:18:12,980 --> 00:18:16,340
they said I should verify my contact

476
00:18:15,200 --> 00:18:17,870
like I'll call them on the phone and

477
00:18:16,340 --> 00:18:21,139
make sure that's them on the other line

478
00:18:17,870 --> 00:18:22,760
I'll check my app permissions some of

479
00:18:21,140 --> 00:18:26,090
them even said I'll switch to Facebook

480
00:18:22,760 --> 00:18:28,580
messenger which is not a good idea only

481
00:18:26,090 --> 00:18:31,070
two of them said oh I should use the

482
00:18:28,580 --> 00:18:32,629
privacy check so there's still a lot of

483
00:18:31,070 --> 00:18:35,830
work to be done here to actually get

484
00:18:32,630 --> 00:18:39,050
people to understand response efficacy

485
00:18:35,830 --> 00:18:41,330
we walk them through what this

486
00:18:39,050 --> 00:18:43,159
particular dialogue meant to them nearly

487
00:18:41,330 --> 00:18:45,620
everybody did associate it with a

488
00:18:43,160 --> 00:18:47,450
potential threat those who acted on it

489
00:18:45,620 --> 00:18:50,060
said oh I'm checking because I am

490
00:18:47,450 --> 00:18:51,770
checking for a threat or because they

491
00:18:50,060 --> 00:18:54,230
it's better better to be safe than sorry

492
00:18:51,770 --> 00:18:56,030
and those who didn't act said well the

493
00:18:54,230 --> 00:18:57,740
risk was minimal or the privacy check

494
00:18:56,030 --> 00:18:59,180
was to inconvenience so that actually

495
00:18:57,740 --> 00:19:00,410
had a strong alignment with what we're

496
00:18:59,180 --> 00:19:03,710
trying to do here in terms of risk

497
00:19:00,410 --> 00:19:06,140
communication we also asked them what

498
00:19:03,710 --> 00:19:08,120
did they think as verifying the safety

499
00:19:06,140 --> 00:19:10,370
number or performing the privacy check

500
00:19:08,120 --> 00:19:12,439
actually accomplishes and we checked

501
00:19:10,370 --> 00:19:14,719
their answers for accuracy and we graded

502
00:19:12,440 --> 00:19:17,000
them either correct or partially correct

503
00:19:14,720 --> 00:19:18,200
or incorrect on the left is the original

504
00:19:17,000 --> 00:19:20,030
design and on the right is the new

505
00:19:18,200 --> 00:19:22,430
design so you can see that we increased

506
00:19:20,030 --> 00:19:24,440
correct answers and we decrease the

507
00:19:22,430 --> 00:19:26,570
number of people who's had an incorrect

508
00:19:24,440 --> 00:19:27,020
answer or didn't know so that was a good

509
00:19:26,570 --> 00:19:29,210
result

510
00:19:27,020 --> 00:19:32,000
we also asked them what does it mean

511
00:19:29,210 --> 00:19:33,770
when safety numbers match had more mixed

512
00:19:32,000 --> 00:19:35,810
result here we had more correct answers

513
00:19:33,770 --> 00:19:37,310
and fewer partially correct answers but

514
00:19:35,810 --> 00:19:39,200
we also increased number of people who

515
00:19:37,310 --> 00:19:41,330
didn't know so we have some work to be

516
00:19:39,200 --> 00:19:43,220
done there we asked them what does it

517
00:19:41,330 --> 00:19:44,689
mean if they don't match and we had some

518
00:19:43,220 --> 00:19:46,820
pretty good results there in terms of

519
00:19:44,690 --> 00:19:48,350
increasing correct answers but still a

520
00:19:46,820 --> 00:19:50,149
lot of room to go we had about 50%

521
00:19:48,350 --> 00:19:52,280
giving correct answers in all three

522
00:19:50,150 --> 00:19:56,660
cases and we'd like to get more than

523
00:19:52,280 --> 00:19:58,310
that all right so now Jody is very

524
00:19:56,660 --> 00:20:00,440
surprised Wow what did we learn about

525
00:19:58,310 --> 00:20:02,360
risk communication then there must be

526
00:20:00,440 --> 00:20:04,850
some great stuff here we learned we can

527
00:20:02,360 --> 00:20:06,379
design for understanding we learned that

528
00:20:04,850 --> 00:20:08,070
there can be good alignment between

529
00:20:06,380 --> 00:20:09,990
perception of risk and action

530
00:20:08,070 --> 00:20:11,790
acting on risk but we also learned

531
00:20:09,990 --> 00:20:13,650
there's a lot of work needed on response

532
00:20:11,790 --> 00:20:16,710
efficacy helping people know how to cope

533
00:20:13,650 --> 00:20:18,810
with the risk in this particular case we

534
00:20:16,710 --> 00:20:20,940
had one user say something isn't secure

535
00:20:18,810 --> 00:20:22,740
but I'm not sure how that translates

536
00:20:20,940 --> 00:20:24,780
into a problem so this indicates

537
00:20:22,740 --> 00:20:26,760
perception of risk severity actually is

538
00:20:24,780 --> 00:20:29,700
an important component of choosing

539
00:20:26,760 --> 00:20:31,620
privacy protecting behaviors we had

540
00:20:29,700 --> 00:20:33,450
someone say even if though it's only

541
00:20:31,620 --> 00:20:36,060
about fish that's really not cool with

542
00:20:33,450 --> 00:20:37,800
me they were talking about the fish that

543
00:20:36,060 --> 00:20:40,649
they had photographed on their vacation

544
00:20:37,800 --> 00:20:42,360
in Hawaii and so this showed that users

545
00:20:40,650 --> 00:20:44,220
do have different risk profiles some

546
00:20:42,360 --> 00:20:45,689
people it is not cool if there's

547
00:20:44,220 --> 00:20:48,780
interception going on even if they're

548
00:20:45,690 --> 00:20:50,310
only just talking about fish and we had

549
00:20:48,780 --> 00:20:52,170
someone say if it was easy enough I

550
00:20:50,310 --> 00:20:54,000
would be happy to secure my conversation

551
00:20:52,170 --> 00:20:56,570
but at the same time how necessary is it

552
00:20:54,000 --> 00:21:00,000
so this is indicating a mix there of

553
00:20:56,570 --> 00:21:03,419
risks severity being low and also being

554
00:21:00,000 --> 00:21:05,550
worried about response cost now suppose

555
00:21:03,420 --> 00:21:07,440
we automate the authentication ceremony

556
00:21:05,550 --> 00:21:10,379
what if we could somehow make this all

557
00:21:07,440 --> 00:21:11,940
not visible to the user that could

558
00:21:10,380 --> 00:21:15,030
potentially help differentiate between

559
00:21:11,940 --> 00:21:18,150
when someone reinstalled versus an

560
00:21:15,030 --> 00:21:20,190
actual definite threat but we're still

561
00:21:18,150 --> 00:21:22,380
going to need warnings when a threat is

562
00:21:20,190 --> 00:21:24,060
detected we're still going to have users

563
00:21:22,380 --> 00:21:24,990
with different risk profiles deciding

564
00:21:24,060 --> 00:21:27,090
how they're going to react to that

565
00:21:24,990 --> 00:21:29,010
threat and these are still need guidance

566
00:21:27,090 --> 00:21:32,550
with coping strategies to know what to

567
00:21:29,010 --> 00:21:34,440
do if that threat occurs and it turns

568
00:21:32,550 --> 00:21:36,090
out that user strategies for coping with

569
00:21:34,440 --> 00:21:38,130
online threats extend beyond the

570
00:21:36,090 --> 00:21:39,810
ecosystem of your app so when we're

571
00:21:38,130 --> 00:21:41,130
giving people advice we need to focus

572
00:21:39,810 --> 00:21:43,050
not just on what should they do with

573
00:21:41,130 --> 00:21:44,910
this app to be safer but what could they

574
00:21:43,050 --> 00:21:48,389
do in the broader sense if they're not

575
00:21:44,910 --> 00:21:50,910
using my app so our future work is to

576
00:21:48,390 --> 00:21:52,650
look at better design for understanding

577
00:21:50,910 --> 00:21:54,900
especially looking at better response

578
00:21:52,650 --> 00:21:56,220
efficacy and we're also interested in

579
00:21:54,900 --> 00:21:58,350
studying different risk scenarios

580
00:21:56,220 --> 00:21:59,310
olivarez were students at a university

581
00:21:58,350 --> 00:22:01,139
and so we're really interested in

582
00:21:59,310 --> 00:22:03,300
studying different populations that

583
00:22:01,140 --> 00:22:04,910
might be at risk and giving them a

584
00:22:03,300 --> 00:22:08,310
scenario where they actually are at risk

585
00:22:04,910 --> 00:22:10,580
simulated and seeing whether this design

586
00:22:08,310 --> 00:22:13,230
helps them better and protect themselves

587
00:22:10,580 --> 00:22:14,939
so now you're all really fascinated by

588
00:22:13,230 --> 00:22:16,560
risk communication designing for

589
00:22:14,940 --> 00:22:19,560
understanding so we'll all celebrate

590
00:22:16,560 --> 00:22:21,030
with Jodie Whittaker and if you'd like

591
00:22:19,560 --> 00:22:22,590
to learn more replicate our work we have

592
00:22:21,030 --> 00:22:24,510
all of our data and our studies

593
00:22:22,590 --> 00:22:26,260
available for you to to replicate if

594
00:22:24,510 --> 00:22:34,539
you'd like thank you very much

595
00:22:26,260 --> 00:22:34,539
[Applause]

596
00:22:43,299 --> 00:22:48,440
thanks that was a really fantastic talk

597
00:22:45,799 --> 00:22:51,230
a couple questions if anyone else has

598
00:22:48,440 --> 00:22:54,559
one please interrupt did you look at all

599
00:22:51,230 --> 00:22:56,779
the impact of understanding in terms of

600
00:22:54,559 --> 00:22:58,639
group chats where safety numbers may

601
00:22:56,779 --> 00:23:00,260
change much more frequently since

602
00:22:58,640 --> 00:23:02,450
there's more members who might lose a

603
00:23:00,260 --> 00:23:05,029
phone or uninstall the app that is one

604
00:23:02,450 --> 00:23:09,850
area we did not look at so that's a

605
00:23:05,029 --> 00:23:12,770
great place to go next and then I

606
00:23:09,850 --> 00:23:14,570
noticed the particular wording in your

607
00:23:12,770 --> 00:23:17,480
privacy check said that there's a small

608
00:23:14,570 --> 00:23:20,000
chance that mm-hmm presented some clear

609
00:23:17,480 --> 00:23:21,380
information did you consider the

610
00:23:20,000 --> 00:23:22,460
scenarios that the risk might change

611
00:23:21,380 --> 00:23:25,610
over time

612
00:23:22,460 --> 00:23:28,159
specifically GCHQ has been talking about

613
00:23:25,610 --> 00:23:31,370
inserting ghost users into end-to-end

614
00:23:28,159 --> 00:23:34,130
group chats as one way to try to get

615
00:23:31,370 --> 00:23:35,389
around the end-to-end so as things like

616
00:23:34,130 --> 00:23:37,850
that may or may not happen the risk

617
00:23:35,390 --> 00:23:40,399
could change over time yeah that's a

618
00:23:37,850 --> 00:23:43,428
really good point we were basing our

619
00:23:40,399 --> 00:23:45,350
messaging on the risk based on our our

620
00:23:43,429 --> 00:23:47,809
understanding of risk now that this

621
00:23:45,350 --> 00:23:50,600
actually is a very low risk especially

622
00:23:47,809 --> 00:23:52,549
in signal right now but yes moving

623
00:23:50,600 --> 00:23:54,469
forward if that risk profile changed

624
00:23:52,549 --> 00:23:56,320
then we would need to change the

625
00:23:54,470 --> 00:23:58,700
messaging there and potentially make it

626
00:23:56,320 --> 00:24:00,700
more in the vein of types of warning

627
00:23:58,700 --> 00:24:03,409
design that you've seen for like

628
00:24:00,700 --> 00:24:04,880
certificate errors on on the web

629
00:24:03,409 --> 00:24:06,260
something that would catch people's

630
00:24:04,880 --> 00:24:08,870
attention more because that would be

631
00:24:06,260 --> 00:24:11,510
more threatening and and more likely

632
00:24:08,870 --> 00:24:13,789
that it would be severe just one last

633
00:24:11,510 --> 00:24:15,379
question you mentioned everything's

634
00:24:13,789 --> 00:24:18,230
available to replicate thanks so much

635
00:24:15,380 --> 00:24:19,820
for that I know that key base has a

636
00:24:18,230 --> 00:24:21,559
different security model where they can

637
00:24:19,820 --> 00:24:23,510
cryptographically verify the public

638
00:24:21,559 --> 00:24:26,330
attestations that someone has put

639
00:24:23,510 --> 00:24:28,399
forward how do you think this research

640
00:24:26,330 --> 00:24:31,850
might change for an app like that that

641
00:24:28,399 --> 00:24:33,199
has a different security model oh that's

642
00:24:31,850 --> 00:24:35,149
a good one I'll talk to you offline

643
00:24:33,200 --> 00:24:36,799
about that because yeah that's gonna

644
00:24:35,149 --> 00:24:38,299
change quite a bit once you move into

645
00:24:36,799 --> 00:24:40,730
different area we've looked at risk

646
00:24:38,299 --> 00:24:42,649
communication for secure email is sort

647
00:24:40,730 --> 00:24:44,240
of the next step we're going but key

648
00:24:42,649 --> 00:24:46,189
base would be another really interesting

649
00:24:44,240 --> 00:24:50,500
place to look at there and yeah it

650
00:24:46,190 --> 00:24:50,500
changes there thanks a lot great talk

651
00:24:51,440 --> 00:24:56,720
thank you for your presentation I was

652
00:24:54,470 --> 00:25:00,050
just wondering if you were able to

653
00:24:56,720 --> 00:25:01,730
measure if users some of them just

654
00:25:00,050 --> 00:25:04,460
ignored the text I think they found it

655
00:25:01,730 --> 00:25:07,280
too wordy and how to mitigate against

656
00:25:04,460 --> 00:25:10,580
that in the future oh great question

657
00:25:07,280 --> 00:25:12,560
we worked really hard to shorten our

658
00:25:10,580 --> 00:25:14,750
text when we were originally developing

659
00:25:12,560 --> 00:25:16,520
the text it was really long and we

660
00:25:14,750 --> 00:25:19,010
worked really hard to say no we get one

661
00:25:16,520 --> 00:25:23,090
sentence for the risk and one sentence

662
00:25:19,010 --> 00:25:25,730
for response cost but we didn't have a

663
00:25:23,090 --> 00:25:27,740
way of measuring whether people actually

664
00:25:25,730 --> 00:25:29,420
read the text and we didn't want to ask

665
00:25:27,740 --> 00:25:32,390
them because they would probably just

666
00:25:29,420 --> 00:25:33,770
tell us yes they did and so that might

667
00:25:32,390 --> 00:25:36,950
be a case where you might use an eye

668
00:25:33,770 --> 00:25:39,410
tracker or maybe screen recording to try

669
00:25:36,950 --> 00:25:41,600
to understand were people actually

670
00:25:39,410 --> 00:25:43,190
paying attention to the text that

671
00:25:41,600 --> 00:25:44,600
particular text there and we just didn't

672
00:25:43,190 --> 00:25:45,740
have enough room in our stated to

673
00:25:44,600 --> 00:25:49,969
measure that it's a good thing to look

674
00:25:45,740 --> 00:25:53,360
at hi Tamra Jenna University of Utah

675
00:25:49,970 --> 00:25:55,790
neighborhood um so you showed three

676
00:25:53,360 --> 00:25:57,830
icons right one was for default assumes

677
00:25:55,790 --> 00:26:02,300
secure one was for verified and one was

678
00:25:57,830 --> 00:26:03,949
for alarmed incidents yeah yeah I was

679
00:26:02,300 --> 00:26:05,210
curious and I haven't read your papers I

680
00:26:03,950 --> 00:26:07,760
don't know if you discussed it all the

681
00:26:05,210 --> 00:26:10,280
possibility of doing a question mark for

682
00:26:07,760 --> 00:26:14,240
the unknown but assumed unverified state

683
00:26:10,280 --> 00:26:16,160
we did I don't remember if that was one

684
00:26:14,240 --> 00:26:18,740
of the ones we tested so we actually did

685
00:26:16,160 --> 00:26:21,320
some tests on Turk looking at people's

686
00:26:18,740 --> 00:26:24,290
responses to icons and we tested I want

687
00:26:21,320 --> 00:26:25,909
to say a dozen different icons i I

688
00:26:24,290 --> 00:26:27,409
remember a question mark being in the

689
00:26:25,910 --> 00:26:29,360
mix there I don't remember if we ended

690
00:26:27,410 --> 00:26:31,340
up including that one but if we go to

691
00:26:29,360 --> 00:26:33,110
the paper we can see some data on the

692
00:26:31,340 --> 00:26:35,659
question mark there we definitely

693
00:26:33,110 --> 00:26:38,810
thought about that and we looked at how

694
00:26:35,660 --> 00:26:40,790
much worry it gave people and how much

695
00:26:38,810 --> 00:26:43,580
concern again people we're trying to get

696
00:26:40,790 --> 00:26:45,950
a neutral icon for default state without

697
00:26:43,580 --> 00:26:47,990
a ton of worry because it is supposed to

698
00:26:45,950 --> 00:26:50,720
be safe assuming they weren't act right

699
00:26:47,990 --> 00:26:52,220
from the very beginning so in the paper

700
00:26:50,720 --> 00:26:53,690
yeah so there should be I think a

701
00:26:52,220 --> 00:26:57,590
question marks of data on the question

702
00:26:53,690 --> 00:26:59,840
mark icon debate yeah hi Tom mark from

703
00:26:57,590 --> 00:27:02,659
Oracle um this is wonderful have you

704
00:26:59,840 --> 00:27:04,080
talked to whisper systems about you know

705
00:27:02,660 --> 00:27:07,410
this informing the next

706
00:27:04,080 --> 00:27:08,879
signal and their UI design not yet that

707
00:27:07,410 --> 00:27:12,030
is on our list of things we would like

708
00:27:08,880 --> 00:27:14,910
to do a great also a bit of warning I

709
00:27:12,030 --> 00:27:17,780
would be extremely cautious about trying

710
00:27:14,910 --> 00:27:20,040
to automate the authentication ceremony

711
00:27:17,780 --> 00:27:21,450
yeah that's the sort of thing that leaks

712
00:27:20,040 --> 00:27:23,070
side channels everywhere and if your

713
00:27:21,450 --> 00:27:24,210
threat model is I don't want anyone to

714
00:27:23,070 --> 00:27:29,720
know I have any contact with this person

715
00:27:24,210 --> 00:27:29,720
not long not even just the payload good

716
00:27:30,800 --> 00:27:33,860
thank you

