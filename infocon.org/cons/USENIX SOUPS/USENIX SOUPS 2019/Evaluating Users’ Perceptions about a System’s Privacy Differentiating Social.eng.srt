1
00:00:10,160 --> 00:00:15,110
and so I'm going to be that a study that

2
00:00:12,860 --> 00:00:18,590
have been done by me and by my advisor

3
00:00:15,110 --> 00:00:21,320
dr. Londo and in this study we evaluate

4
00:00:18,590 --> 00:00:23,740
we study how we can evaluate users by

5
00:00:21,320 --> 00:00:26,419
with a perception about a given system

6
00:00:23,740 --> 00:00:29,540
so the background for the study is

7
00:00:26,419 --> 00:00:31,160
published by design in which the ideal

8
00:00:29,540 --> 00:00:33,680
five is by design is to implement

9
00:00:31,160 --> 00:00:35,720
privacy solution from the very beginning

10
00:00:33,680 --> 00:00:38,000
and not after the system is already

11
00:00:35,720 --> 00:00:40,010
built and it's a very important approach

12
00:00:38,000 --> 00:00:42,230
it's part of the regulation part of the

13
00:00:40,010 --> 00:00:44,989
Federal Trade Commission the FTC and

14
00:00:42,230 --> 00:00:48,290
part of the EU general data protection

15
00:00:44,990 --> 00:00:51,740
regulation the GTR but like every other

16
00:00:48,290 --> 00:00:55,010
thing there are also criticism and one

17
00:00:51,740 --> 00:00:57,230
of the criticism was done by Wong and

18
00:00:55,010 --> 00:00:59,059
Mulligan when they said that the design

19
00:00:57,230 --> 00:01:02,000
part of privacy by design it's currently

20
00:00:59,060 --> 00:01:05,360
conducted from and narrow layer like

21
00:01:02,000 --> 00:01:07,880
legal perspective and they suggest to do

22
00:01:05,360 --> 00:01:10,400
it to conduct for design while taking

23
00:01:07,880 --> 00:01:12,679
human-computer interaction approach and

24
00:01:10,400 --> 00:01:15,140
for example taking into account those

25
00:01:12,680 --> 00:01:18,740
who develop the system and also those

26
00:01:15,140 --> 00:01:20,689
who are using the system so in our study

27
00:01:18,740 --> 00:01:22,969
we are looking at the users perspective

28
00:01:20,689 --> 00:01:25,609
and in the context of privacy by design

29
00:01:22,969 --> 00:01:27,408
and privacy by design also look at the

30
00:01:25,609 --> 00:01:29,749
user they call to protect individuals

31
00:01:27,409 --> 00:01:33,380
and what you see here is a screenshot

32
00:01:29,749 --> 00:01:36,048
taking from equal to K of Information

33
00:01:33,380 --> 00:01:38,060
Commissioner office and how do we do

34
00:01:36,049 --> 00:01:40,639
this in practice refers to privacy by

35
00:01:38,060 --> 00:01:42,920
design in the context of the GD P R so

36
00:01:40,639 --> 00:01:44,990
we see that they refer to do individuals

37
00:01:42,920 --> 00:01:47,869
however they were certain individuals

38
00:01:44,990 --> 00:01:50,958
from organizational perspective we don't

39
00:01:47,869 --> 00:01:53,569
call to involve these in the in the

40
00:01:50,959 --> 00:01:55,639
development process which is exactly

41
00:01:53,569 --> 00:01:57,560
what you the Center design is about to

42
00:01:55,639 --> 00:02:00,079
involve the users during the development

43
00:01:57,560 --> 00:02:01,999
and here in this diagram we see that the

44
00:02:00,079 --> 00:02:04,009
users are involved at the beginning of

45
00:02:01,999 --> 00:02:06,889
the process where the designers involved

46
00:02:04,009 --> 00:02:09,259
M they watch the use of the act in

47
00:02:06,889 --> 00:02:11,180
question and also the users are involved

48
00:02:09,258 --> 00:02:13,160
in later phase of the study where

49
00:02:11,180 --> 00:02:15,410
they're asked to test the prototype at a

50
00:02:13,160 --> 00:02:17,750
prototype so these are two different

51
00:02:15,410 --> 00:02:19,549
approach looking at the individuals from

52
00:02:17,750 --> 00:02:23,510
organizational perspective and actually

53
00:02:19,550 --> 00:02:25,160
involving them so why to involve users

54
00:02:23,510 --> 00:02:28,220
so what you see here is the screenshot

55
00:02:25,160 --> 00:02:31,040
taking from facebook Messenger as it

56
00:02:28,220 --> 00:02:33,319
used to be in 2015 so back then the

57
00:02:31,040 --> 00:02:35,480
messages were automatically sent for

58
00:02:33,319 --> 00:02:37,280
delegation with their location so if I

59
00:02:35,480 --> 00:02:40,910
got the message I could press on it and

60
00:02:37,280 --> 00:02:42,050
to see the standard vacation after you

61
00:02:40,910 --> 00:02:44,269
did have been complaining about it

62
00:02:42,050 --> 00:02:46,580
Facebook changes but we want to know how

63
00:02:44,269 --> 00:02:48,590
we can avoid similar cases from the

64
00:02:46,580 --> 00:02:50,870
first place how we can implement privacy

65
00:02:48,590 --> 00:02:54,019
by design while taking the users into

66
00:02:50,870 --> 00:02:56,510
consideration so I already mentioned our

67
00:02:54,019 --> 00:02:58,819
approach so we're taking a user centered

68
00:02:56,510 --> 00:03:00,679
design approach similar to and having

69
00:02:58,819 --> 00:03:02,988
usability test we claim that we need to

70
00:03:00,680 --> 00:03:05,780
have privacy tests to involve the user

71
00:03:02,989 --> 00:03:08,780
and specifically we're going to look at

72
00:03:05,780 --> 00:03:11,510
a be testing one of user centered design

73
00:03:08,780 --> 00:03:14,870
approach methodology in which we compare

74
00:03:11,510 --> 00:03:16,340
different design and we have small

75
00:03:14,870 --> 00:03:17,660
difference between the design and we

76
00:03:16,340 --> 00:03:20,060
want to see the effect of these

77
00:03:17,660 --> 00:03:22,810
differences on our exploit outcome

78
00:03:20,060 --> 00:03:25,130
usability buying the product or whatever

79
00:03:22,810 --> 00:03:29,359
so we're going to take a same approach

80
00:03:25,130 --> 00:03:31,700
but with privacy we want to see how

81
00:03:29,359 --> 00:03:34,250
different privacy design affect a

82
00:03:31,700 --> 00:03:36,108
specific score for the neck the first

83
00:03:34,250 --> 00:03:38,269
thing that we need to ask is what will

84
00:03:36,109 --> 00:03:41,540
be the score which privacy scale should

85
00:03:38,269 --> 00:03:44,720
we use so reading privacy scales

86
00:03:41,540 --> 00:03:47,720
literature we found that there are two

87
00:03:44,720 --> 00:03:50,150
main types of privacy scales and the

88
00:03:47,720 --> 00:03:51,950
first one refer to individuals privacy

89
00:03:50,150 --> 00:03:54,980
concerns and but this is not what we're

90
00:03:51,950 --> 00:03:58,000
looking for we want to to measure system

91
00:03:54,980 --> 00:04:00,500
privacy and there are studies that

92
00:03:58,000 --> 00:04:02,959
suggested privacy scale that measured

93
00:04:00,500 --> 00:04:05,420
system privacy however most of them

94
00:04:02,959 --> 00:04:07,940
refer to information flow between users

95
00:04:05,420 --> 00:04:11,510
and the 15 not many of them referred to

96
00:04:07,940 --> 00:04:13,970
information flow that refer to the users

97
00:04:11,510 --> 00:04:16,219
in the system so since we did not have

98
00:04:13,970 --> 00:04:17,720
we did not find a scale that really fit

99
00:04:16,220 --> 00:04:19,820
what we look for so we develop the

100
00:04:17,720 --> 00:04:22,280
scales ourselves

101
00:04:19,820 --> 00:04:24,680
so I mentioned information flow between

102
00:04:22,280 --> 00:04:27,739
user and the system and information flow

103
00:04:24,680 --> 00:04:29,750
between users in the system in social

104
00:04:27,740 --> 00:04:32,599
network study they found that users

105
00:04:29,750 --> 00:04:35,849
perception uses privacy concerns can be

106
00:04:32,599 --> 00:04:37,679
divided to two types the first one in

107
00:04:35,849 --> 00:04:40,619
additional privately confirmed in which

108
00:04:37,679 --> 00:04:43,830
the users are concerned about possible

109
00:04:40,619 --> 00:04:45,779
uses the company or government are doing

110
00:04:43,830 --> 00:04:47,339
with the personal information so this is

111
00:04:45,779 --> 00:04:50,249
the institutional privacy concern

112
00:04:47,339 --> 00:04:52,349
another type is social privacy concern

113
00:04:50,249 --> 00:04:54,929
in which users are concerned about

114
00:04:52,349 --> 00:04:57,300
information access a bit done by people

115
00:04:54,929 --> 00:04:59,998
their friends family colleagues in a set

116
00:04:57,300 --> 00:05:02,999
way so when we come to do develop our

117
00:04:59,999 --> 00:05:06,089
our scale we looked at two types of them

118
00:05:02,999 --> 00:05:08,819
of privacy literature we were looking at

119
00:05:06,089 --> 00:05:09,539
privacy skills and purple or privacy

120
00:05:08,819 --> 00:05:12,809
construct

121
00:05:09,539 --> 00:05:15,240
for example privacy control privacy risk

122
00:05:12,809 --> 00:05:17,189
and we are also taking into account the

123
00:05:15,240 --> 00:05:20,339
difference between institutional and

124
00:05:17,189 --> 00:05:23,459
privacy concern so yet to be formal

125
00:05:20,339 --> 00:05:25,409
about our research objective we want to

126
00:05:23,459 --> 00:05:27,029
find a framework to evaluate users

127
00:05:25,409 --> 00:05:28,740
privacy perceptions of a given system

128
00:05:27,029 --> 00:05:31,229
and you will see that this framework

129
00:05:28,740 --> 00:05:33,990
consists of dedicated scale and

130
00:05:31,229 --> 00:05:36,119
conducting a be testing next we want to

131
00:05:33,990 --> 00:05:38,069
evaluate our suggested framework and

132
00:05:36,119 --> 00:05:40,199
last as we know that there is a

133
00:05:38,069 --> 00:05:42,389
difference between institutional and

134
00:05:40,199 --> 00:05:44,909
social social privacy we want to know

135
00:05:42,389 --> 00:05:50,099
whether our framework is applicable for

136
00:05:44,909 --> 00:05:52,860
both cases ok so what did we do so we

137
00:05:50,099 --> 00:05:54,930
had a study that has two main phases in

138
00:05:52,860 --> 00:05:57,360
the first phase were developing the

139
00:05:54,930 --> 00:06:00,629
scale and we conducted the survey study

140
00:05:57,360 --> 00:06:02,789
to develop the scale and then we use the

141
00:06:00,629 --> 00:06:04,610
results of the first page the scale to

142
00:06:02,789 --> 00:06:07,259
see if we can differentiate between

143
00:06:04,610 --> 00:06:10,679
privacy design and to do this we

144
00:06:07,259 --> 00:06:12,449
conducted a be testing study the

145
00:06:10,679 --> 00:06:16,169
participants for all the study were

146
00:06:12,449 --> 00:06:18,329
recruited by another Mechanical Turk ok

147
00:06:16,169 --> 00:06:20,279
so I will give a very short review of

148
00:06:18,329 --> 00:06:23,610
the first phase in which we develop a

149
00:06:20,279 --> 00:06:26,249
scale we had two sub studies in which we

150
00:06:23,610 --> 00:06:28,589
started with 47 questions and based on

151
00:06:26,249 --> 00:06:31,289
the study results we reduced the amount

152
00:06:28,589 --> 00:06:34,529
of of of this question wields all kind

153
00:06:31,289 --> 00:06:36,599
of statistical analysis including

154
00:06:34,529 --> 00:06:39,149
principal components analysis and

155
00:06:36,599 --> 00:06:42,209
exploratory factor analysis to get the

156
00:06:39,149 --> 00:06:44,490
final result so there is also a scale

157
00:06:42,209 --> 00:06:47,399
that we named users perceived system

158
00:06:44,490 --> 00:06:50,800
privacy scale the u p SP

159
00:06:47,399 --> 00:06:52,960
and our scale consists of 27 questions

160
00:06:50,800 --> 00:06:55,869
that you've distributed between three

161
00:06:52,960 --> 00:06:57,969
distinct as a construct institutional

162
00:06:55,869 --> 00:07:00,580
risk and social and I will give example

163
00:06:57,969 --> 00:07:02,770
for each one of them okay so on the

164
00:07:00,580 --> 00:07:05,169
right you see the loading and they will

165
00:07:02,770 --> 00:07:08,109
get from our exploratory factor analysis

166
00:07:05,169 --> 00:07:10,839
so first example for the institutional

167
00:07:08,110 --> 00:07:13,569
construct I believe they have control of

168
00:07:10,839 --> 00:07:16,180
how my personal information is used by x

169
00:07:13,569 --> 00:07:20,159
axes the study that is the system that

170
00:07:16,180 --> 00:07:22,149
we are exploring then a risk construct

171
00:07:20,159 --> 00:07:24,159
considering the information I provide to

172
00:07:22,149 --> 00:07:26,199
X and the people who might see it I

173
00:07:24,159 --> 00:07:28,419
think it will be risky to give my

174
00:07:26,199 --> 00:07:31,209
personal information to X and the last

175
00:07:28,419 --> 00:07:33,490
one the last social construct it looks

176
00:07:31,209 --> 00:07:36,430
easy to restrict intended people from

177
00:07:33,490 --> 00:07:38,289
viewing my personal information on X so

178
00:07:36,430 --> 00:07:42,189
this is the first phase we have this

179
00:07:38,289 --> 00:07:44,378
part of the question of this scale okay

180
00:07:42,189 --> 00:07:47,349
so the next step was we want to

181
00:07:44,379 --> 00:07:50,499
differentiate between privacy design so

182
00:07:47,349 --> 00:07:52,719
to do that I'm going to a be testing so

183
00:07:50,499 --> 00:07:55,059
we developed five different scenarios

184
00:07:52,719 --> 00:07:58,439
each scenario represents an application

185
00:07:55,059 --> 00:08:01,719
and since we want to explore whether our

186
00:07:58,439 --> 00:08:04,930
framework is applicable for both social

187
00:08:01,719 --> 00:08:08,110
and institutional we had three scenarios

188
00:08:04,930 --> 00:08:09,999
that covered social effect in which the

189
00:08:08,110 --> 00:08:11,849
privacy issue was the information flow

190
00:08:09,999 --> 00:08:14,889
between between users and to

191
00:08:11,849 --> 00:08:18,248
institutional privacy aspects so each

192
00:08:14,889 --> 00:08:20,199
scenario we had to privacy design one

193
00:08:18,249 --> 00:08:22,599
with more privacy respectful than the

194
00:08:20,199 --> 00:08:25,360
other altogether we had ten conditions

195
00:08:22,599 --> 00:08:28,029
and each participants was presented with

196
00:08:25,360 --> 00:08:30,309
one condition only so I will show you

197
00:08:28,029 --> 00:08:33,458
how it looks from the participant

198
00:08:30,309 --> 00:08:35,529
perspective so this is one example he

199
00:08:33,458 --> 00:08:37,149
says I find best scenario so the

200
00:08:35,529 --> 00:08:40,179
participants were presented with the

201
00:08:37,149 --> 00:08:41,679
application name I find worse then a

202
00:08:40,179 --> 00:08:43,779
very short explanation of what the

203
00:08:41,679 --> 00:08:46,989
application does in this case each an

204
00:08:43,779 --> 00:08:48,790
application they help the user to find

205
00:08:46,990 --> 00:08:52,720
the restaurant based on their location

206
00:08:48,790 --> 00:08:55,449
and how you can also reserve a table in

207
00:08:52,720 --> 00:08:57,990
the restaurant and a screenshot of the

208
00:08:55,449 --> 00:09:00,329
application then as

209
00:08:57,990 --> 00:09:02,160
cific scenario was presented and this

210
00:09:00,330 --> 00:09:05,100
case was different between the two

211
00:09:02,160 --> 00:09:08,969
conditions since it exemplified how the

212
00:09:05,100 --> 00:09:11,640
each design work in each condition okay

213
00:09:08,970 --> 00:09:13,560
so I told you that we had three social

214
00:09:11,640 --> 00:09:16,560
aspects and tools and two social

215
00:09:13,560 --> 00:09:18,930
scenario I took to be social and to

216
00:09:16,560 --> 00:09:22,349
institutional so this case this example

217
00:09:18,930 --> 00:09:26,040
of social privacy aspect in this case

218
00:09:22,350 --> 00:09:28,170
the participants were told that if the

219
00:09:26,040 --> 00:09:29,790
restaurant is mark in you can see it if

220
00:09:28,170 --> 00:09:32,099
it's marked in green it means that

221
00:09:29,790 --> 00:09:34,170
someone from their contact list also

222
00:09:32,100 --> 00:09:37,290
made reservation for this restaurant in

223
00:09:34,170 --> 00:09:40,469
the same hour so on the left you see the

224
00:09:37,290 --> 00:09:43,740
intrusive design in which the but it's

225
00:09:40,470 --> 00:09:46,050
the user can tell exactly can tell by

226
00:09:43,740 --> 00:09:48,089
default who will be these people were

227
00:09:46,050 --> 00:09:50,880
they going to be in the restaurant well

228
00:09:48,089 --> 00:09:52,980
in the right side you see that he can

229
00:09:50,880 --> 00:09:54,450
tell that someone's going to be someone

230
00:09:52,980 --> 00:09:56,370
he knows it's going to be in the

231
00:09:54,450 --> 00:09:59,399
restaurant but it can tell who so we

232
00:09:56,370 --> 00:10:01,910
have these two designs I would also like

233
00:09:59,399 --> 00:10:05,339
to give an example of institutional case

234
00:10:01,910 --> 00:10:10,020
so in this case you see it's a chat app

235
00:10:05,339 --> 00:10:12,750
and we have ads in both of the cases but

236
00:10:10,020 --> 00:10:15,240
so the chat is about trying to Spain and

237
00:10:12,750 --> 00:10:17,339
on the left you see the intrusive design

238
00:10:15,240 --> 00:10:19,649
in which it can understand it can be

239
00:10:17,339 --> 00:10:21,510
understood that the application reads

240
00:10:19,649 --> 00:10:24,180
the check because the chatted about

241
00:10:21,510 --> 00:10:26,640
flying to Spain and so you defecate

242
00:10:24,180 --> 00:10:29,399
though the the ad is about trying to

243
00:10:26,640 --> 00:10:31,110
Spain and on the right you see they were

244
00:10:29,399 --> 00:10:33,810
stuck for design in which you can see an

245
00:10:31,110 --> 00:10:37,890
ad but it has nothing to do with flying

246
00:10:33,810 --> 00:10:40,319
the same okay and here we had as I said

247
00:10:37,890 --> 00:10:42,209
we had three social and you have two

248
00:10:40,320 --> 00:10:46,440
more social here and one more

249
00:10:42,209 --> 00:10:49,380
institutional example on the right so

250
00:10:46,440 --> 00:10:51,660
what did we get so just to explain what

251
00:10:49,380 --> 00:10:54,500
how I'm presenting there is also on the

252
00:10:51,660 --> 00:10:57,360
bottom you see two scenario that has

253
00:10:54,500 --> 00:11:00,450
institutional aspects and on the up you

254
00:10:57,360 --> 00:11:03,149
see the older social scenario so to

255
00:11:00,450 --> 00:11:06,510
analyze the result we conducted t-test

256
00:11:03,149 --> 00:11:08,790
between the design per each sub scale

257
00:11:06,510 --> 00:11:11,370
we thought that the first thing they

258
00:11:08,790 --> 00:11:13,050
proceeded we only find significant

259
00:11:11,370 --> 00:11:15,930
difference between the design in the

260
00:11:13,050 --> 00:11:18,180
case where there was social aspect when

261
00:11:15,930 --> 00:11:20,420
looking inside a subscale we find mixed

262
00:11:18,180 --> 00:11:23,160
result in which in some case we had

263
00:11:20,420 --> 00:11:25,620
different significant difference between

264
00:11:23,160 --> 00:11:27,389
the design only in the whisk and in

265
00:11:25,620 --> 00:11:30,170
other case we had significant design

266
00:11:27,389 --> 00:11:32,699
only in social or institutional aspects

267
00:11:30,170 --> 00:11:35,910
and we also had an example in which we

268
00:11:32,699 --> 00:11:38,880
found significant difference between the

269
00:11:35,910 --> 00:11:41,730
design in the whisk but in this case the

270
00:11:38,880 --> 00:11:43,920
participant found what we considered as

271
00:11:41,730 --> 00:11:47,100
a respectful design so the participant

272
00:11:43,920 --> 00:11:49,079
found it is riskier design as for

273
00:11:47,100 --> 00:11:51,180
institutional aspects we do not find

274
00:11:49,079 --> 00:11:54,540
significant difference for any of the k

275
00:11:51,180 --> 00:11:57,540
for any of the sub scale okay so to

276
00:11:54,540 --> 00:11:59,810
summarize our results so we found that

277
00:11:57,540 --> 00:12:02,610
users perceived information system

278
00:11:59,810 --> 00:12:05,969
through three distinct aspects

279
00:12:02,610 --> 00:12:07,980
institutional social and risk and when

280
00:12:05,970 --> 00:12:09,990
comparing design will find that they

281
00:12:07,980 --> 00:12:13,290
mostly able to differentiate between

282
00:12:09,990 --> 00:12:17,100
privacy design if it's about social

283
00:12:13,290 --> 00:12:19,439
aspect so what could be possible

284
00:12:17,100 --> 00:12:23,339
explanation for our results why did we

285
00:12:19,440 --> 00:12:26,279
only found in institutional significant

286
00:12:23,339 --> 00:12:28,649
different in with social aspect one

287
00:12:26,279 --> 00:12:30,449
possible explanation is that our scale

288
00:12:28,649 --> 00:12:34,350
is not sensitive it's not sensitive

289
00:12:30,449 --> 00:12:36,389
enough we when we developed it we aimed

290
00:12:34,350 --> 00:12:38,880
it to be a generic scale that can fit

291
00:12:36,389 --> 00:12:41,220
every system and every case social or

292
00:12:38,880 --> 00:12:43,050
institutional and it might be might be

293
00:12:41,220 --> 00:12:46,319
the case if it's only sensitive for

294
00:12:43,050 --> 00:12:48,839
social another possible explanation is

295
00:12:46,319 --> 00:12:52,290
that we only explored two institutional

296
00:12:48,839 --> 00:12:55,680
aspect and maybe if we tried more so we

297
00:12:52,290 --> 00:12:58,110
will get another outcome and another

298
00:12:55,680 --> 00:13:00,479
explanation that we thought about is in

299
00:12:58,110 --> 00:13:03,630
user experience field we have something

300
00:13:00,480 --> 00:13:06,240
named as perceived affordances in which

301
00:13:03,630 --> 00:13:08,939
users perceive something about what he

302
00:13:06,240 --> 00:13:11,250
do so in this case of the tubes it's

303
00:13:08,940 --> 00:13:13,110
really the affordances is not very good

304
00:13:11,250 --> 00:13:14,399
it's not understood what we were

305
00:13:13,110 --> 00:13:17,010
supposed to be to do with the tube

306
00:13:14,399 --> 00:13:19,490
unlike in the case of button in which

307
00:13:17,010 --> 00:13:21,829
you push and switch the flip and I

308
00:13:19,490 --> 00:13:25,300
so which privacy which also might be a

309
00:13:21,829 --> 00:13:28,219
possible explanation that system have

310
00:13:25,300 --> 00:13:31,189
weaker or stronger privacy affordances

311
00:13:28,220 --> 00:13:34,249
and with social aspects it might be that

312
00:13:31,189 --> 00:13:36,889
I have a stronger privacy affordances

313
00:13:34,249 --> 00:13:39,259
because users and users use social

314
00:13:36,889 --> 00:13:41,870
aspect in social assistance so they can

315
00:13:39,259 --> 00:13:43,819
understand a lot easier what's going on

316
00:13:41,870 --> 00:13:47,389
so they understand that if they see

317
00:13:43,819 --> 00:13:50,540
someone information so that other people

318
00:13:47,389 --> 00:13:52,939
can see their information as well and

319
00:13:50,540 --> 00:13:54,980
with social with institutional aspect it

320
00:13:52,939 --> 00:13:57,769
might be different so it's much harder

321
00:13:54,980 --> 00:13:59,540
to understand what is the data flow what

322
00:13:57,769 --> 00:14:01,420
is happening with the data so the

323
00:13:59,540 --> 00:14:03,800
privacy affordances in the case of

324
00:14:01,420 --> 00:14:06,229
institutional systems or institutional

325
00:14:03,800 --> 00:14:08,359
design is much weaker so it's not

326
00:14:06,230 --> 00:14:10,670
necessarily that people don't care about

327
00:14:08,360 --> 00:14:13,509
institutional aspect but yet they don't

328
00:14:10,670 --> 00:14:13,509
understand it

329
00:14:13,579 --> 00:14:19,189
based on our study results we developed

330
00:14:16,639 --> 00:14:22,189
88p testing which may techne allow

331
00:14:19,189 --> 00:14:25,670
developers researchers organization to

332
00:14:22,189 --> 00:14:28,550
do the same thing that we did and allow

333
00:14:25,670 --> 00:14:32,029
the allow allow them to upload screen

334
00:14:28,550 --> 00:14:34,279
shot of the of their explode system and

335
00:14:32,029 --> 00:14:38,199
to conduct the same study that we did we

336
00:14:34,279 --> 00:14:42,439
also have the question in this system

337
00:14:38,199 --> 00:14:44,329
so to summarize so really wanted to

338
00:14:42,439 --> 00:14:46,639
bring user centered design to privacy by

339
00:14:44,329 --> 00:14:49,430
design so we can involve user doing

340
00:14:46,639 --> 00:14:51,889
privacy by design positives we found

341
00:14:49,430 --> 00:14:54,258
that users perceive system privacy based

342
00:14:51,889 --> 00:14:58,819
on three aspect institutional social and

343
00:14:54,259 --> 00:15:00,620
risk and we call organization that if

344
00:14:58,819 --> 00:15:02,479
they want to develop a system that are

345
00:15:00,620 --> 00:15:04,850
more privacy respectful we call them to

346
00:15:02,480 --> 00:15:07,429
involve involve doodle you can use a

347
00:15:04,850 --> 00:15:08,899
protecting and rely or in an essential

348
00:15:07,429 --> 00:15:11,709
design and on four different disciplines

349
00:15:08,899 --> 00:15:15,100
consider the three aspect that we found

350
00:15:11,709 --> 00:15:15,099
thank you very much

351
00:15:18,650 --> 00:15:26,689
okay so we have some time left for

352
00:15:23,690 --> 00:15:26,690
questions

353
00:15:29,270 --> 00:15:38,430
so I'm going to ask some questions here

354
00:15:34,200 --> 00:15:40,200
so did that surprise you a little bit

355
00:15:38,430 --> 00:15:45,589
when you were looking at these cases

356
00:15:40,200 --> 00:15:48,120
where you didn't find like you know

357
00:15:45,590 --> 00:15:50,250
statistical difference between some of

358
00:15:48,120 --> 00:15:52,440
the cases because in the in the case you

359
00:15:50,250 --> 00:15:55,530
just put in there in terms of the

360
00:15:52,440 --> 00:15:58,530
holidays it's pretty clear that one is

361
00:15:55,530 --> 00:16:01,500
actually processing what they are

362
00:15:58,530 --> 00:16:04,680
talking about and the other one it

363
00:16:01,500 --> 00:16:08,010
doesn't so it it seems like pretty

364
00:16:04,680 --> 00:16:11,160
purpose invasive and the difference and

365
00:16:08,010 --> 00:16:14,970
they seem tests to regard both has

366
00:16:11,160 --> 00:16:18,439
equally privacy invasive I guess what

367
00:16:14,970 --> 00:16:18,440
was your interpretation of that

368
00:16:20,390 --> 00:16:24,689
institutional for instance I'm asking

369
00:16:22,260 --> 00:16:26,850
about if you were surprised and what

370
00:16:24,690 --> 00:16:28,770
kind of interpretation you make of this

371
00:16:26,850 --> 00:16:33,420
lack of differences where for instance

372
00:16:28,770 --> 00:16:35,340
in this case one could think like well

373
00:16:33,420 --> 00:16:37,349
in one you're just putting there an ad

374
00:16:35,340 --> 00:16:39,690
that doesn't require any kind of

375
00:16:37,350 --> 00:16:41,880
information processing for the other one

376
00:16:39,690 --> 00:16:43,860
you have to actually process what they

377
00:16:41,880 --> 00:16:45,630
are talking about to be able to make a

378
00:16:43,860 --> 00:16:49,020
recommendation so it's clearly more

379
00:16:45,630 --> 00:16:53,370
privacy invasive but it seems like users

380
00:16:49,020 --> 00:16:56,250
didn't perceive it as so again that we

381
00:16:53,370 --> 00:17:00,780
our skill is not sensitive enough or I

382
00:16:56,250 --> 00:17:03,300
know possible that we may not reviewing

383
00:17:00,780 --> 00:17:06,000
that clearly enough that what exactly is

384
00:17:03,300 --> 00:17:07,470
going on I mean for you probably most

385
00:17:06,000 --> 00:17:09,240
people in the room they understand that

386
00:17:07,470 --> 00:17:12,390
they're reading and this is privacy

387
00:17:09,240 --> 00:17:14,420
invasive maybe for you know a more

388
00:17:12,390 --> 00:17:17,660
general population they need something

389
00:17:14,420 --> 00:17:19,890
stronger to make in clear and

390
00:17:17,660 --> 00:17:22,440
understatement of what's going on of how

391
00:17:19,890 --> 00:17:24,690
the information flows so it will be more

392
00:17:22,440 --> 00:17:27,390
obvious that hey someone is reading your

393
00:17:24,690 --> 00:17:29,940
messages but that may it might be

394
00:17:27,390 --> 00:17:33,600
did you get any kind of qualitative data

395
00:17:29,940 --> 00:17:35,700
that might be a very good idea for there

396
00:17:33,600 --> 00:17:38,070
is maybe they might just say like I mean

397
00:17:35,700 --> 00:17:40,320
okay now if I if I get so mad I prefer

398
00:17:38,070 --> 00:17:43,020
it to be something relevant to me or I

399
00:17:40,320 --> 00:17:46,370
don't know yeah okay so we have fun

400
00:17:43,020 --> 00:17:46,370
question yeah okay

401
00:17:48,470 --> 00:17:55,799
so with the interface that you have the

402
00:17:52,320 --> 00:17:59,580
AP testing have people been using that

403
00:17:55,799 --> 00:18:01,110
and do you have a sense of whether it's

404
00:17:59,580 --> 00:18:02,250
more people who are just like hey we've

405
00:18:01,110 --> 00:18:04,409
got some designs we'll throw them in

406
00:18:02,250 --> 00:18:06,960
here or whether they were really setting

407
00:18:04,410 --> 00:18:08,340
out to like there or whether it's

408
00:18:06,960 --> 00:18:10,049
designers who actually care about

409
00:18:08,340 --> 00:18:11,790
designing for privacy and are you know

410
00:18:10,049 --> 00:18:14,010
setting out say you know are our

411
00:18:11,790 --> 00:18:15,809
instincts correct about what people are

412
00:18:14,010 --> 00:18:17,549
going to you know we have these two

413
00:18:15,809 --> 00:18:18,540
designs we've won a coupon I really want

414
00:18:17,549 --> 00:18:22,830
to figure this out

415
00:18:18,540 --> 00:18:25,159
or is it more just I'm sorry can I don't

416
00:18:22,830 --> 00:18:28,409
and I'm finding the question I mean so

417
00:18:25,160 --> 00:18:31,080
who's using your AP testing and what are

418
00:18:28,410 --> 00:18:31,919
they all right our people using it and

419
00:18:31,080 --> 00:18:35,639
what are they using it for

420
00:18:31,919 --> 00:18:38,010
what's that your AP testing yes who's

421
00:18:35,640 --> 00:18:40,860
using it and what are they do you have a

422
00:18:38,010 --> 00:18:42,000
sense of how they are using that

423
00:18:40,860 --> 00:18:46,290
information that they're getting out of

424
00:18:42,000 --> 00:18:48,870
it yeah you're throwing today to the the

425
00:18:46,290 --> 00:18:50,220
study that we conducted who usually at

426
00:18:48,870 --> 00:18:53,909
the end we've created a thing

427
00:18:50,220 --> 00:18:56,400
or am ia misunderstanding that they ate

428
00:18:53,910 --> 00:18:58,679
a bigger thing or pizza thing I'm really

429
00:18:56,400 --> 00:19:00,840
ate the AP testing that what they what

430
00:18:58,679 --> 00:19:02,460
we develop yeah okay so yeah we

431
00:19:00,840 --> 00:19:04,709
developed it okay so we developed it

432
00:19:02,460 --> 00:19:07,020
based on that if they did not use it I

433
00:19:04,710 --> 00:19:10,140
mean this is something that we based it

434
00:19:07,020 --> 00:19:13,230
is based on our study and now other

435
00:19:10,140 --> 00:19:16,440
people researchers or organizations can

436
00:19:13,230 --> 00:19:19,919
use that so they can reach people easily

437
00:19:16,440 --> 00:19:22,140
and do a large-scale study of people

438
00:19:19,919 --> 00:19:24,600
privacy preferences so this was the idea

439
00:19:22,140 --> 00:19:26,669
of other people to use it similar to you

440
00:19:24,600 --> 00:19:29,490
the ability testing basically yeah so

441
00:19:26,669 --> 00:19:34,770
but has it been used oh no no and no one

442
00:19:29,490 --> 00:19:36,570
would ever know I'd ask me yet okay hi

443
00:19:34,770 --> 00:19:38,370
my name is hey John come on up from

444
00:19:36,570 --> 00:19:40,310
Texas A&M University I wanted to

445
00:19:38,370 --> 00:19:42,770
actually start to by saying I really

446
00:19:40,310 --> 00:19:44,929
your presentation I myself think privacy

447
00:19:42,770 --> 00:19:48,280
by design is actually key to most of the

448
00:19:44,930 --> 00:19:50,750
problems and privacy to improve so your

449
00:19:48,280 --> 00:19:53,030
general way of setting up in a very

450
00:19:50,750 --> 00:19:55,280
rigorous way ways to measure things

451
00:19:53,030 --> 00:19:57,710
setting up a platform so that it's easy

452
00:19:55,280 --> 00:19:59,510
I totally agree with the fact that you

453
00:19:57,710 --> 00:20:00,290
know this is really about having good

454
00:19:59,510 --> 00:20:02,060
HCI

455
00:20:00,290 --> 00:20:04,070
kind of interface and user experience

456
00:20:02,060 --> 00:20:05,990
I'm not one of them I actually work with

457
00:20:04,070 --> 00:20:09,740
a great person who does that but my

458
00:20:05,990 --> 00:20:12,650
question was privacy and my experience

459
00:20:09,740 --> 00:20:14,570
is a very personal thing so in that

460
00:20:12,650 --> 00:20:16,790
especially in this user interface space

461
00:20:14,570 --> 00:20:20,300
I don't I don't personally think there

462
00:20:16,790 --> 00:20:23,780
is one right privacy design and it's

463
00:20:20,300 --> 00:20:25,940
more about there are segments of people

464
00:20:23,780 --> 00:20:29,360
who like certain kinds of things I mean

465
00:20:25,940 --> 00:20:30,530
in a way I have seen that it could be a

466
00:20:29,360 --> 00:20:32,479
hundred and eighty percent like

467
00:20:30,530 --> 00:20:34,970
difference in opinion in terms of this

468
00:20:32,480 --> 00:20:36,500
is more privately respectful than the

469
00:20:34,970 --> 00:20:38,590
other one so it's really difficult to

470
00:20:36,500 --> 00:20:43,010
maneuver that space and was wondering

471
00:20:38,590 --> 00:20:46,540
what's your experience in in using

472
00:20:43,010 --> 00:20:49,640
privacy by design to maneuver the

473
00:20:46,540 --> 00:20:55,760
personal opinion of privacy in this

474
00:20:49,640 --> 00:20:59,120
space okay so so I think that's similar

475
00:20:55,760 --> 00:21:03,050
to when you conduct usability testing so

476
00:20:59,120 --> 00:21:05,449
you have in mind who are you users and

477
00:21:03,050 --> 00:21:08,330
you want to the product to fit them so

478
00:21:05,450 --> 00:21:13,460
it might also be similar in this case

479
00:21:08,330 --> 00:21:16,850
that if you know your users are more or

480
00:21:13,460 --> 00:21:18,530
less privacy savvy or not so you might

481
00:21:16,850 --> 00:21:21,830
want to take this into consideration

482
00:21:18,530 --> 00:21:23,810
there are personal privacy perception

483
00:21:21,830 --> 00:21:29,629
obviously there's no one right answer

484
00:21:23,810 --> 00:21:34,310
but if but if you do want to have a

485
00:21:29,630 --> 00:21:37,040
general of more people expecting you so

486
00:21:34,310 --> 00:21:39,200
you might be expecting your your

487
00:21:37,040 --> 00:21:41,330
decision so you might be want to use

488
00:21:39,200 --> 00:21:44,780
such thing because the word privacy

489
00:21:41,330 --> 00:21:48,280
cases in which many people disagree with

490
00:21:44,780 --> 00:21:51,410
the company so in this case you want

491
00:21:48,280 --> 00:21:52,649
doing such experiment in advance might

492
00:21:51,410 --> 00:21:55,950
help you know

493
00:21:52,650 --> 00:21:59,510
to launch something that a lot of people

494
00:21:55,950 --> 00:21:59,510
would disagree with your design

495
00:21:59,930 --> 00:22:03,510
okay so let's thank officer again thank

496
00:22:03,000 --> 00:22:08,789
you very much

497
00:22:03,510 --> 00:22:08,789
[Applause]

