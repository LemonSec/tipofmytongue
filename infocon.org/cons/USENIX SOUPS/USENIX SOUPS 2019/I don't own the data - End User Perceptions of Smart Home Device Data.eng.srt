1
00:00:10,770 --> 00:00:16,230
hello everyone I'm Molly ha I'm a PhD

2
00:00:14,580 --> 00:00:18,960
student at University of North Carolina

3
00:00:16,230 --> 00:00:20,640
and Charlotte and today I'm going to

4
00:00:18,960 --> 00:00:22,439
present or a study on end-user

5
00:00:20,640 --> 00:00:24,900
perceptions of a smart home device

6
00:00:22,439 --> 00:00:28,710
manufacturer data practices and relevant

7
00:00:24,900 --> 00:00:31,380
wrists so a smart home market is growing

8
00:00:28,710 --> 00:00:33,329
very fast people are getting more

9
00:00:31,380 --> 00:00:36,660
interested in having internet connected

10
00:00:33,329 --> 00:00:39,270
devices in their home for increased

11
00:00:36,660 --> 00:00:44,489
conveniences or increased security and

12
00:00:39,270 --> 00:00:47,609
safety and in just last one year the

13
00:00:44,489 --> 00:00:49,530
smart home market grown 12% only in US

14
00:00:47,609 --> 00:00:53,160
and expected to be a forty billion

15
00:00:49,530 --> 00:00:56,760
dollar business by 2020 and a lot of

16
00:00:53,160 --> 00:01:00,569
people in u.s. has two or more smart

17
00:00:56,760 --> 00:01:02,608
home devices in their house so with the

18
00:01:00,570 --> 00:01:04,980
prevalence of these devices also counts

19
00:01:02,609 --> 00:01:07,470
many security and privacy risks because

20
00:01:04,980 --> 00:01:09,510
these devices are actually automatically

21
00:01:07,470 --> 00:01:13,350
collecting a lot of potentially private

22
00:01:09,510 --> 00:01:16,500
information about its users and because

23
00:01:13,350 --> 00:01:18,990
data is important both tech companies

24
00:01:16,500 --> 00:01:22,170
and malicious parties are getting

25
00:01:18,990 --> 00:01:25,470
interested in these smart home devices

26
00:01:22,170 --> 00:01:29,240
and we are seeing more and more attack

27
00:01:25,470 --> 00:01:34,350
on a smart home and IOT devices

28
00:01:29,240 --> 00:01:36,689
regularly nowadays so there are some

29
00:01:34,350 --> 00:01:38,729
papers who looked at security and

30
00:01:36,689 --> 00:01:42,619
privacy in his smartphone from end users

31
00:01:38,729 --> 00:01:45,390
perspective for instance Jeff Janet L

32
00:01:42,619 --> 00:01:48,240
conducted an interview study and found

33
00:01:45,390 --> 00:01:50,490
that even expert users have incomplete

34
00:01:48,240 --> 00:01:53,219
trade model of security and privacy

35
00:01:50,490 --> 00:01:55,350
recently smart home and instead of

36
00:01:53,219 --> 00:01:58,229
sharing a common set of concerns

37
00:01:55,350 --> 00:02:01,199
it is often limited and varied among the

38
00:01:58,229 --> 00:02:05,479
participants there are another study who

39
00:02:01,200 --> 00:02:09,210
investigated 11 mostly technical users

40
00:02:05,479 --> 00:02:10,978
focusing on their perception of specific

41
00:02:09,210 --> 00:02:14,880
data collection entities and found that

42
00:02:10,979 --> 00:02:17,160
users comfort on sharing their data

43
00:02:14,880 --> 00:02:19,670
depend on the benefit they get from the

44
00:02:17,160 --> 00:02:23,010
device and their trust on those entities

45
00:02:19,670 --> 00:02:26,129
however none of the previous work looked

46
00:02:23,010 --> 00:02:29,099
that what the current users of these

47
00:02:26,129 --> 00:02:31,859
smart devices think about what happening

48
00:02:29,099 --> 00:02:36,510
with their data and what is their

49
00:02:31,860 --> 00:02:40,200
concerns and comfort in with these data

50
00:02:36,510 --> 00:02:42,510
collection and users and how that is

51
00:02:40,200 --> 00:02:44,910
affecting their behavior security and

52
00:02:42,510 --> 00:02:47,660
privacy protection behavior also the

53
00:02:44,910 --> 00:02:50,940
earlier state is mostly concentrated on

54
00:02:47,660 --> 00:02:53,879
expert users who installed an automated

55
00:02:50,940 --> 00:02:57,629
a smart home devices in their house but

56
00:02:53,879 --> 00:02:59,459
not on the incidental users who were not

57
00:02:57,629 --> 00:03:01,709
involved in the installation and

58
00:02:59,459 --> 00:03:06,329
automation but use these devices in a

59
00:03:01,709 --> 00:03:08,700
regular basis so in this study we

60
00:03:06,329 --> 00:03:11,730
decided to get a more detail and

61
00:03:08,700 --> 00:03:16,170
holistic understanding of both expert

62
00:03:11,730 --> 00:03:18,090
and non-expert users perception of very

63
00:03:16,170 --> 00:03:20,790
smart device manufacturer data practices

64
00:03:18,090 --> 00:03:22,650
more specifically what data do they

65
00:03:20,790 --> 00:03:25,620
think this is martim devices collect

66
00:03:22,650 --> 00:03:28,579
where the data is stored who can accept

67
00:03:25,620 --> 00:03:32,900
that that data how that data is used and

68
00:03:28,579 --> 00:03:35,459
how that perception is shaping their

69
00:03:32,900 --> 00:03:37,919
security and privacy concerns in smart

70
00:03:35,459 --> 00:03:41,880
home and how that is affecting their

71
00:03:37,919 --> 00:03:45,329
security and privacy actions to protect

72
00:03:41,880 --> 00:03:48,090
their data so to answer these questions

73
00:03:45,329 --> 00:03:49,680
we conducted a semi-structured interview

74
00:03:48,090 --> 00:03:52,650
with 23 participants

75
00:03:49,680 --> 00:03:55,169
it was a phone interview which lasted of

76
00:03:52,650 --> 00:03:57,510
on average one hour we recruited

77
00:03:55,169 --> 00:04:00,870
participants from I have two related

78
00:03:57,510 --> 00:04:03,030
online forums from Reddit and we

79
00:04:00,870 --> 00:04:04,919
recruited participants who has at least

80
00:04:03,030 --> 00:04:07,379
three types of smart home devices

81
00:04:04,919 --> 00:04:11,370
because we wanted people who have

82
00:04:07,379 --> 00:04:17,250
experience interacting with different

83
00:04:11,370 --> 00:04:19,380
types of devices so which I to recruit a

84
00:04:17,250 --> 00:04:22,199
balanced sample of participants in terms

85
00:04:19,380 --> 00:04:25,349
of both age gender different technical

86
00:04:22,199 --> 00:04:28,380
background and also people who are its

87
00:04:25,349 --> 00:04:31,320
purchasers in involved in installation

88
00:04:28,380 --> 00:04:36,240
and automation and also people who just

89
00:04:31,320 --> 00:04:39,940
use the devices as incidental users

90
00:04:36,240 --> 00:04:42,220
so our participants had a lot of

91
00:04:39,940 --> 00:04:45,160
different devices and they use the

92
00:04:42,220 --> 00:04:47,350
smartphone devices mainly for automating

93
00:04:45,160 --> 00:04:49,600
their household remotely sensing and

94
00:04:47,350 --> 00:04:51,940
controlling the devices and increasing

95
00:04:49,600 --> 00:04:54,160
security and safety of their house in

96
00:04:51,940 --> 00:04:56,160
some way some of the participants also

97
00:04:54,160 --> 00:04:58,870
mentioned we use these devices for

98
00:04:56,160 --> 00:05:01,540
saving energy and help with household

99
00:04:58,870 --> 00:05:04,240
chores most of the participants had some

100
00:05:01,540 --> 00:05:06,760
central controls controller set of four

101
00:05:04,240 --> 00:05:09,010
extends either yzma things or a smart

102
00:05:06,760 --> 00:05:12,219
voice assistant and for many of our

103
00:05:09,010 --> 00:05:16,719
participants voice was the main method

104
00:05:12,220 --> 00:05:19,000
of interaction so as one of the goal of

105
00:05:16,720 --> 00:05:20,980
our study was to understand what people

106
00:05:19,000 --> 00:05:22,600
think about the data we conducted a

107
00:05:20,980 --> 00:05:25,360
drawing exercise where we asked

108
00:05:22,600 --> 00:05:28,000
participant how the thing the data is

109
00:05:25,360 --> 00:05:30,970
flowing in the air a smart home so we

110
00:05:28,000 --> 00:05:32,980
found that users mental model depended

111
00:05:30,970 --> 00:05:35,340
on their technical background and their

112
00:05:32,980 --> 00:05:37,690
interaction with different devices so

113
00:05:35,340 --> 00:05:39,849
participant who had advanced mental

114
00:05:37,690 --> 00:05:42,550
model he had a more detailed

115
00:05:39,850 --> 00:05:44,200
understanding of their smart home all of

116
00:05:42,550 --> 00:05:46,900
those participants who had advanced

117
00:05:44,200 --> 00:05:48,969
mental model know about the cloud and

118
00:05:46,900 --> 00:05:50,739
the role of cloud in device interaction

119
00:05:48,970 --> 00:05:53,080
they know that data goes back and forth

120
00:05:50,740 --> 00:05:55,720
between the devices and the cloud when

121
00:05:53,080 --> 00:05:58,380
the interaction happens in contrast

122
00:05:55,720 --> 00:06:01,300
people who have service-oriented model

123
00:05:58,380 --> 00:06:04,930
was mainly consists of how they control

124
00:06:01,300 --> 00:06:08,170
the device that they control these

125
00:06:04,930 --> 00:06:10,480
devices with its devices so that that's

126
00:06:08,170 --> 00:06:12,580
how the data flows some of them

127
00:06:10,480 --> 00:06:15,610
mentioned cloud but none of them has a

128
00:06:12,580 --> 00:06:20,770
good idea of the role of cloud in device

129
00:06:15,610 --> 00:06:22,300
interaction so after that we in our in

130
00:06:20,770 --> 00:06:25,870
the rest of our study we asked

131
00:06:22,300 --> 00:06:29,530
participants not a manufacturer data

132
00:06:25,870 --> 00:06:32,050
practices so we found that the depth of

133
00:06:29,530 --> 00:06:35,140
people understanding of their smart home

134
00:06:32,050 --> 00:06:37,210
didn't actually affect their perception

135
00:06:35,140 --> 00:06:39,820
or understanding of his smart home

136
00:06:37,210 --> 00:06:43,299
device manufacturer data practices for

137
00:06:39,820 --> 00:06:46,780
instance users perception of data

138
00:06:43,300 --> 00:06:48,460
collection depended on the type of the

139
00:06:46,780 --> 00:06:51,099
device and their interaction with

140
00:06:48,460 --> 00:06:53,500
the device or 30 letter app for instance

141
00:06:51,100 --> 00:06:55,449
the people who has video doorbell all of

142
00:06:53,500 --> 00:06:57,970
them knew that the video doorbell is

143
00:06:55,449 --> 00:07:00,729
collecting video but none of them

144
00:06:57,970 --> 00:07:02,470
mention that the app may be collecting

145
00:07:00,729 --> 00:07:06,250
the location when they are accessing the

146
00:07:02,470 --> 00:07:09,190
video all of their participants knew

147
00:07:06,250 --> 00:07:11,139
that their interaction and users may be

148
00:07:09,190 --> 00:07:13,479
collected by the device manufacturers

149
00:07:11,139 --> 00:07:16,930
but again they were not really concerned

150
00:07:13,479 --> 00:07:19,139
so we look more specifically at audio

151
00:07:16,930 --> 00:07:22,539
and video data because they normally

152
00:07:19,139 --> 00:07:24,880
seemed as more sensitive and the video

153
00:07:22,539 --> 00:07:27,250
was still considered very sensitive by

154
00:07:24,880 --> 00:07:30,550
our participants but our participants

155
00:07:27,250 --> 00:07:33,070
found practices to be become comfortable

156
00:07:30,550 --> 00:07:34,900
around those devices for instance one of

157
00:07:33,070 --> 00:07:38,469
our participants said he just turn on

158
00:07:34,900 --> 00:07:41,620
the recording when he's not home or some

159
00:07:38,470 --> 00:07:44,020
said that they only used a video in

160
00:07:41,620 --> 00:07:47,830
video camera in live streaming mode so

161
00:07:44,020 --> 00:07:49,150
none of the video gets recorded our

162
00:07:47,830 --> 00:07:51,219
participants also mentioned that

163
00:07:49,150 --> 00:07:54,280
sensitive information can be inferred

164
00:07:51,220 --> 00:07:57,370
from from the data these devices are

165
00:07:54,280 --> 00:08:00,820
collecting and that information can be

166
00:07:57,370 --> 00:08:03,969
used for building advertising model for

167
00:08:00,820 --> 00:08:07,090
them and target for targeted advertising

168
00:08:03,969 --> 00:08:09,219
but they are not very concerned

169
00:08:07,090 --> 00:08:11,679
they say that targeted advertising

170
00:08:09,219 --> 00:08:14,620
becomes so common our kind of integral

171
00:08:11,680 --> 00:08:17,880
part of their life that they think that

172
00:08:14,620 --> 00:08:20,740
is kind of a cost of using the Internet

173
00:08:17,880 --> 00:08:23,050
our participants also mentioned that the

174
00:08:20,740 --> 00:08:25,750
companies collect these data to improve

175
00:08:23,050 --> 00:08:28,240
the product for example if there is a

176
00:08:25,750 --> 00:08:31,870
hero if something is not working the

177
00:08:28,240 --> 00:08:34,630
company collected data and use that data

178
00:08:31,870 --> 00:08:37,899
to resolve the problem and also they say

179
00:08:34,630 --> 00:08:40,779
that they use the data to identify users

180
00:08:37,899 --> 00:08:42,399
need to develop new product our

181
00:08:40,779 --> 00:08:44,740
participants know that device

182
00:08:42,399 --> 00:08:47,740
manufacturer shared their devices with

183
00:08:44,740 --> 00:08:49,720
third-party advertisers but they are not

184
00:08:47,740 --> 00:08:51,970
really sure the extent of data that

185
00:08:49,720 --> 00:08:54,339
being shared so some things that only

186
00:08:51,970 --> 00:08:57,070
the demographic data is being shared

187
00:08:54,339 --> 00:08:59,230
some things that only small companies

188
00:08:57,070 --> 00:09:00,820
share the data big companies don't share

189
00:08:59,230 --> 00:09:03,360
the data they collect the data from

190
00:09:00,820 --> 00:09:06,730
small companies

191
00:09:03,360 --> 00:09:09,910
our participant mentioned that their

192
00:09:06,730 --> 00:09:12,310
data is going to be device manufacturer

193
00:09:09,910 --> 00:09:13,689
server of the cloud and some of them

194
00:09:12,310 --> 00:09:15,670
also mentioned that the device

195
00:09:13,690 --> 00:09:19,030
manufacturers may not have enough

196
00:09:15,670 --> 00:09:22,180
protection in place in the cloud and

197
00:09:19,030 --> 00:09:25,990
they were also not sure about how long

198
00:09:22,180 --> 00:09:27,910
the data will be stored most of them

199
00:09:25,990 --> 00:09:29,800
think that the data will be installed

200
00:09:27,910 --> 00:09:32,770
indefinitely and many of our

201
00:09:29,800 --> 00:09:34,719
participants also were not aware of the

202
00:09:32,770 --> 00:09:38,380
security and privacy controls that are

203
00:09:34,720 --> 00:09:41,080
available in many of the smart home

204
00:09:38,380 --> 00:09:44,530
devices and that makes our participants

205
00:09:41,080 --> 00:09:48,040
uncomfortable for instance one of our

206
00:09:44,530 --> 00:09:50,829
participants didn't want elect Eco in

207
00:09:48,040 --> 00:09:53,079
her house because she thought that there

208
00:09:50,830 --> 00:09:55,840
is no option to check the audio

209
00:09:53,080 --> 00:09:59,920
recordings and remove that data and that

210
00:09:55,840 --> 00:10:01,930
make had uncomfortable that he want to

211
00:09:59,920 --> 00:10:08,079
remove she wanted to remove the device

212
00:10:01,930 --> 00:10:10,719
from her house after learning about

213
00:10:08,080 --> 00:10:13,630
their perception of device manufacturer

214
00:10:10,720 --> 00:10:16,210
data practices we asked them what what

215
00:10:13,630 --> 00:10:20,350
can happen to them based on what is

216
00:10:16,210 --> 00:10:24,670
happening to their data so the

217
00:10:20,350 --> 00:10:26,380
participant mostly said that yes there

218
00:10:24,670 --> 00:10:29,589
can be a data breach in the cloud and

219
00:10:26,380 --> 00:10:31,840
their data can be hacked some also said

220
00:10:29,590 --> 00:10:34,810
that the device can be hacked and

221
00:10:31,840 --> 00:10:38,380
remotely controlled by the adversary

222
00:10:34,810 --> 00:10:40,930
some more also said that there can be

223
00:10:38,380 --> 00:10:44,130
improper sharing between between

224
00:10:40,930 --> 00:10:47,319
different companies and as a consequence

225
00:10:44,130 --> 00:10:50,140
their physical security can be hampered

226
00:10:47,320 --> 00:10:52,030
there can be more risk of identity theft

227
00:10:50,140 --> 00:10:54,970
some advanced participants also

228
00:10:52,030 --> 00:10:57,640
mentioned that with these data the

229
00:10:54,970 --> 00:11:00,430
companies can some way manipulate their

230
00:10:57,640 --> 00:11:04,300
decision or perception of things and

231
00:11:00,430 --> 00:11:07,089
some also mention discomfort around the

232
00:11:04,300 --> 00:11:09,240
civilians especially around the devices

233
00:11:07,090 --> 00:11:11,080
that collect audio and video data our

234
00:11:09,240 --> 00:11:14,540
advanced

235
00:11:11,080 --> 00:11:19,970
identified more treads but again only a

236
00:11:14,540 --> 00:11:22,160
few were really concerned so instead of

237
00:11:19,970 --> 00:11:26,330
they're not really concerned they

238
00:11:22,160 --> 00:11:29,630
actually to conduct some protective

239
00:11:26,330 --> 00:11:32,209
measures so for many of our participants

240
00:11:29,630 --> 00:11:34,040
say it like they sell self-censored

241
00:11:32,209 --> 00:11:37,430
themselves in some way around the

242
00:11:34,040 --> 00:11:39,050
devices so for instance turn the turn of

243
00:11:37,430 --> 00:11:41,750
the device when they don't use the

244
00:11:39,050 --> 00:11:45,229
device or do not use certain device

245
00:11:41,750 --> 00:11:47,990
functionality or just would fake data in

246
00:11:45,230 --> 00:11:50,120
their account and some also say they

247
00:11:47,990 --> 00:11:53,690
change their behavior around these

248
00:11:50,120 --> 00:11:55,940
devices many of our participants use

249
00:11:53,690 --> 00:11:57,709
technical based practices that they know

250
00:11:55,940 --> 00:11:59,779
from other computing context for example

251
00:11:57,709 --> 00:12:03,739
they say that they use a strong password

252
00:11:59,779 --> 00:12:05,750
and two-factor authentication some of

253
00:12:03,740 --> 00:12:08,060
our expert participants said that they

254
00:12:05,750 --> 00:12:10,130
install some kind of tool to protect

255
00:12:08,060 --> 00:12:12,469
their data for instance two of our

256
00:12:10,130 --> 00:12:14,839
expert participants mentioned that they

257
00:12:12,470 --> 00:12:17,600
installed a local server and customized

258
00:12:14,839 --> 00:12:20,089
the devices to work with the server so

259
00:12:17,600 --> 00:12:22,640
their data do not go outside in the

260
00:12:20,089 --> 00:12:25,520
internet but most majority of our

261
00:12:22,640 --> 00:12:28,069
participants said they either use some

262
00:12:25,520 --> 00:12:31,339
technical mitigations or changing their

263
00:12:28,070 --> 00:12:36,110
behavior in some way around that devices

264
00:12:31,339 --> 00:12:37,550
- as a protective measure and also

265
00:12:36,110 --> 00:12:40,810
mentioned that they are not really

266
00:12:37,550 --> 00:12:43,430
concerned about the threats and

267
00:12:40,810 --> 00:12:45,829
mentioned the number of reasons why they

268
00:12:43,430 --> 00:12:48,739
are not concerned so one of the reason

269
00:12:45,829 --> 00:12:50,689
is they say that there is no way other

270
00:12:48,740 --> 00:12:53,329
than accepting these trade-offs if they

271
00:12:50,690 --> 00:12:56,540
want to use that device they have to

272
00:12:53,329 --> 00:12:58,310
accept the risks some also say that they

273
00:12:56,540 --> 00:13:01,040
trust that the manufacturer will not

274
00:12:58,310 --> 00:13:03,739
misuse their data because because it

275
00:13:01,040 --> 00:13:06,709
will be financially it will it will

276
00:13:03,740 --> 00:13:11,360
damage their reputation and not be

277
00:13:06,709 --> 00:13:13,310
financially very profitable some was

278
00:13:11,360 --> 00:13:15,829
very optimistic that they will never be

279
00:13:13,310 --> 00:13:19,880
a target because they are not solvent

280
00:13:15,829 --> 00:13:22,520
enough and some judges theories by how

281
00:13:19,880 --> 00:13:23,820
expose they already are so they say that

282
00:13:22,520 --> 00:13:25,590
there is already enough in

283
00:13:23,820 --> 00:13:28,170
formation about me in the internet so

284
00:13:25,590 --> 00:13:32,000
adding in new smart home devices will

285
00:13:28,170 --> 00:13:35,069
not increase my risk of identity theft

286
00:13:32,000 --> 00:13:38,730
some trusted that there is strict

287
00:13:35,070 --> 00:13:41,190
regulatory body who will look over their

288
00:13:38,730 --> 00:13:43,470
data and make sure that the companies

289
00:13:41,190 --> 00:13:45,500
are not misusing their data and some

290
00:13:43,470 --> 00:13:47,850
expert participant mentioned the

291
00:13:45,500 --> 00:13:51,500
difficulty of implementing protective

292
00:13:47,850 --> 00:13:55,830
actions like as like implementing a

293
00:13:51,500 --> 00:13:58,850
local server and sometimes and that cost

294
00:13:55,830 --> 00:14:02,460
of creative action is so high it's often

295
00:13:58,850 --> 00:14:07,760
overrun the limited concern of the

296
00:14:02,460 --> 00:14:11,940
participant so from our study we learn

297
00:14:07,760 --> 00:14:15,480
that users perceptions of device

298
00:14:11,940 --> 00:14:17,910
manufacturer data practices is is not

299
00:14:15,480 --> 00:14:20,430
much different from their perception of

300
00:14:17,910 --> 00:14:22,530
Internet and these knowledge also don't

301
00:14:20,430 --> 00:14:25,290
affect their security and privacy we

302
00:14:22,530 --> 00:14:27,120
have aired any smart home for instance

303
00:14:25,290 --> 00:14:29,250
our expert participants did know about

304
00:14:27,120 --> 00:14:31,800
more threats and more protective

305
00:14:29,250 --> 00:14:36,420
measures but still they didn't actually

306
00:14:31,800 --> 00:14:38,969
implement it instead if they are

307
00:14:36,420 --> 00:14:41,880
protected via via depend on their own

308
00:14:38,970 --> 00:14:45,870
biases and they're concerned with

309
00:14:41,880 --> 00:14:48,000
general internet users our participants

310
00:14:45,870 --> 00:14:50,730
conscious concerns were thought was also

311
00:14:48,000 --> 00:14:52,980
paradoxical for instance they knew that

312
00:14:50,730 --> 00:14:57,050
these devices are collecting data

313
00:14:52,980 --> 00:14:59,730
sensitivity data can be inferred the

314
00:14:57,050 --> 00:15:02,640
companies may not have enough protection

315
00:14:59,730 --> 00:15:05,100
in the cloud or there may not be in

316
00:15:02,640 --> 00:15:08,069
Africa Latorre bodies but again when we

317
00:15:05,100 --> 00:15:10,680
ask them why they are not concerned they

318
00:15:08,070 --> 00:15:13,200
are kind of backing it up with the fact

319
00:15:10,680 --> 00:15:14,459
that the trusted company will not misses

320
00:15:13,200 --> 00:15:17,070
their data there

321
00:15:14,460 --> 00:15:20,310
there are come regulatory bodies who

322
00:15:17,070 --> 00:15:21,630
will look over their data and this can

323
00:15:20,310 --> 00:15:24,839
be explained by learned helplessness

324
00:15:21,630 --> 00:15:27,090
where people ignore negative outcome

325
00:15:24,840 --> 00:15:29,040
because they don't have control and many

326
00:15:27,090 --> 00:15:31,680
of our participant explicitly say they

327
00:15:29,040 --> 00:15:34,140
don't have any controls once the data

328
00:15:31,680 --> 00:15:36,630
get into the device it's out of out of

329
00:15:34,140 --> 00:15:37,350
their hand so they use different coping

330
00:15:36,630 --> 00:15:39,600
mechanism

331
00:15:37,350 --> 00:15:41,300
so data don't get into the device in the

332
00:15:39,600 --> 00:15:43,860
first place

333
00:15:41,300 --> 00:15:46,469
for many of our participants the

334
00:15:43,860 --> 00:15:50,160
estimated risk from these devices was

335
00:15:46,470 --> 00:15:52,620
also very low because for instance they

336
00:15:50,160 --> 00:15:54,569
know that there can be their physical

337
00:15:52,620 --> 00:15:57,570
security can be hampered but they

338
00:15:54,570 --> 00:16:02,520
thought that there will never be a good

339
00:15:57,570 --> 00:16:05,310
target they know that there can be

340
00:16:02,520 --> 00:16:06,960
identity theft but they thought that

341
00:16:05,310 --> 00:16:08,579
there is already enough information in

342
00:16:06,960 --> 00:16:11,130
the internet so if someone wants to

343
00:16:08,580 --> 00:16:13,890
target me the information is already out

344
00:16:11,130 --> 00:16:16,260
there even the people who had a victim

345
00:16:13,890 --> 00:16:17,550
of identity theft told that they have

346
00:16:16,260 --> 00:16:22,020
enough protection in their financial

347
00:16:17,550 --> 00:16:25,709
account so they're good so they don't

348
00:16:22,020 --> 00:16:28,010
understand the breadth of the risks that

349
00:16:25,710 --> 00:16:32,250
can come from it smartphone devices and

350
00:16:28,010 --> 00:16:35,250
lastly the lack of awareness of divert

351
00:16:32,250 --> 00:16:37,820
level controls actually impede users and

352
00:16:35,250 --> 00:16:40,830
make the participants more uncomfortable

353
00:16:37,820 --> 00:16:43,910
and from our interview it was appeared

354
00:16:40,830 --> 00:16:47,730
that if they knew about these controls

355
00:16:43,910 --> 00:16:51,420
their protective Vav arm agent in some

356
00:16:47,730 --> 00:16:55,980
way so these underscored the importance

357
00:16:51,420 --> 00:16:58,890
of more studies to examine the nudges

358
00:16:55,980 --> 00:17:01,290
that drive users especially the norm

359
00:16:58,890 --> 00:17:03,449
Staller of these devices towards the

360
00:17:01,290 --> 00:17:06,180
security and privacy controls that is

361
00:17:03,450 --> 00:17:10,850
already available with the devices

362
00:17:06,180 --> 00:17:17,430
so with that I'll finish my talk and

363
00:17:10,849 --> 00:17:21,329
happy to answer your question some time

364
00:17:17,430 --> 00:17:23,520
for questions hi so I'm a yonathan

365
00:17:21,329 --> 00:17:25,649
Zanger I am at Houma but I actually used

366
00:17:23,520 --> 00:17:27,240
to had infra and privacy for the Google

367
00:17:25,650 --> 00:17:30,480
assistants so thank you very much for

368
00:17:27,240 --> 00:17:32,970
this talk I had a question about the

369
00:17:30,480 --> 00:17:36,540
interpretation of this data you are

370
00:17:32,970 --> 00:17:38,400
saying how people are making fairly low

371
00:17:36,540 --> 00:17:40,230
estimates of the risk and that they're

372
00:17:38,400 --> 00:17:43,260
ignoring certain types of hazard and so

373
00:17:40,230 --> 00:17:45,180
on how do we tell whether when we're

374
00:17:43,260 --> 00:17:47,890
looking at this we're seeing at user fat

375
00:17:45,180 --> 00:17:50,500
security fatigue or privacy fatigue

376
00:17:47,890 --> 00:17:52,570
versus people actually making fairly

377
00:17:50,500 --> 00:17:55,090
sophisticated risk/reward trade-offs

378
00:17:52,570 --> 00:17:56,290
because in the same interviews you are

379
00:17:55,090 --> 00:17:58,120
talking about looking at this data it

380
00:17:56,290 --> 00:18:00,100
also looked like people had pretty

381
00:17:58,120 --> 00:18:01,959
complex understandings of where their

382
00:18:00,100 --> 00:18:03,730
data was how it could potentially be

383
00:18:01,960 --> 00:18:06,190
used and had actually been making

384
00:18:03,730 --> 00:18:10,750
decisions deliberately how do we know

385
00:18:06,190 --> 00:18:12,520
what's the right way to read this so so

386
00:18:10,750 --> 00:18:15,700
that was one of the interesting findings

387
00:18:12,520 --> 00:18:17,740
we had from our data that yes we thought

388
00:18:15,700 --> 00:18:19,150
that people don't know anything so maybe

389
00:18:17,740 --> 00:18:22,390
that's why they are not doing anything

390
00:18:19,150 --> 00:18:24,910
but actually people know that okay they

391
00:18:22,390 --> 00:18:26,169
have complex model that yes that is

392
00:18:24,910 --> 00:18:27,730
happening to my data

393
00:18:26,169 --> 00:18:29,980
yes sensitive information can be

394
00:18:27,730 --> 00:18:32,980
inferred from my data you still they

395
00:18:29,980 --> 00:18:35,169
don't think that that can directly

396
00:18:32,980 --> 00:18:39,340
affect them because they don't think

397
00:18:35,169 --> 00:18:43,570
them as a potential victim or potential

398
00:18:39,340 --> 00:18:46,030
target for of whatever data that are

399
00:18:43,570 --> 00:18:47,470
available and but it sounded like they

400
00:18:46,030 --> 00:18:50,350
were in numerating various ways it could

401
00:18:47,470 --> 00:18:52,780
affect them what it sounded like they

402
00:18:50,350 --> 00:18:56,139
were enumerated risk of identity theft

403
00:18:52,780 --> 00:18:59,559
physical security yes

404
00:18:56,140 --> 00:19:01,660
yeah they worried about like as I said

405
00:18:59,559 --> 00:19:04,090
they all read about identity theft but

406
00:19:01,660 --> 00:19:05,559
again they have multiple of our

407
00:19:04,090 --> 00:19:08,649
participants said they already have

408
00:19:05,559 --> 00:19:11,678
protection of their final data financial

409
00:19:08,650 --> 00:19:14,350
data so they thought that okay that will

410
00:19:11,679 --> 00:19:17,250
be enough like if someone want to break

411
00:19:14,350 --> 00:19:22,090
into my back account then I I would know

412
00:19:17,250 --> 00:19:25,390
but they know about the risks but they

413
00:19:22,090 --> 00:19:28,530
also have reasons that why I'm not I I

414
00:19:25,390 --> 00:19:28,530
will not be concerned

415
00:19:28,950 --> 00:19:36,549
okay thank you so you mentioned that

416
00:19:33,929 --> 00:19:38,770
many of your participants were not aware

417
00:19:36,549 --> 00:19:40,750
of privacy controls that some of these

418
00:19:38,770 --> 00:19:42,610
devices had and you also said that some

419
00:19:40,750 --> 00:19:44,950
of them had wrong mental models of

420
00:19:42,610 --> 00:19:46,959
either the protections or the

421
00:19:44,950 --> 00:19:48,610
regulations that were in place and you

422
00:19:46,960 --> 00:19:49,780
mentioned notches at the end so I was

423
00:19:48,610 --> 00:19:52,389
just wondering if you thought more about

424
00:19:49,780 --> 00:19:53,860
how you could people help have more

425
00:19:52,390 --> 00:19:56,290
accurate mental models so make them

426
00:19:53,860 --> 00:19:58,770
aware of privacy controls that might be

427
00:19:56,290 --> 00:19:58,770
useful to them

428
00:20:00,240 --> 00:20:08,800
so if people know about the privacy

429
00:20:05,380 --> 00:20:11,230
controls from my experience with the my

430
00:20:08,800 --> 00:20:14,680
participants I think it it will be

431
00:20:11,230 --> 00:20:16,810
helpful for them because many of our

432
00:20:14,680 --> 00:20:19,630
participants when I told them that this

433
00:20:16,810 --> 00:20:23,080
is actually available like with these

434
00:20:19,630 --> 00:20:25,000
device and then they told me that if I

435
00:20:23,080 --> 00:20:27,699
would know that I would I would remove

436
00:20:25,000 --> 00:20:31,210
my video I would I would look at the

437
00:20:27,700 --> 00:20:33,250
audio recordings and delete it and may

438
00:20:31,210 --> 00:20:35,680
not be this much uncomfortable like one

439
00:20:33,250 --> 00:20:39,340
of our participants actually remove

440
00:20:35,680 --> 00:20:41,290
tannest camera for her house at some

441
00:20:39,340 --> 00:20:44,889
point because she got really

442
00:20:41,290 --> 00:20:47,620
uncomfortable with that device so I

443
00:20:44,890 --> 00:20:52,030
think if if people know about these

444
00:20:47,620 --> 00:20:53,979
controls they that would help them get

445
00:20:52,030 --> 00:20:57,310
more comfortable around these devices

446
00:20:53,980 --> 00:21:00,610
and use more private privacy protective

447
00:20:57,310 --> 00:21:02,350
behaviors and do you have any ideas how

448
00:21:00,610 --> 00:21:04,719
we could make that happen beyond you

449
00:21:02,350 --> 00:21:07,719
going and visiting every user of a

450
00:21:04,720 --> 00:21:10,570
device so that's that's another problem

451
00:21:07,720 --> 00:21:12,340
because the ecosystem is very complex so

452
00:21:10,570 --> 00:21:14,110
each people have different types of

453
00:21:12,340 --> 00:21:16,120
devices and different devices has

454
00:21:14,110 --> 00:21:18,610
different types of policies provide

455
00:21:16,120 --> 00:21:21,129
different types of controls so at the

456
00:21:18,610 --> 00:21:23,919
future stay for our study right now we

457
00:21:21,130 --> 00:21:27,090
are investigating what are the controls

458
00:21:23,920 --> 00:21:30,130
that are available in different set of

459
00:21:27,090 --> 00:21:32,050
set of devices and what people's

460
00:21:30,130 --> 00:21:34,870
perception of those controls how people

461
00:21:32,050 --> 00:21:37,960
use those controls and what their needs

462
00:21:34,870 --> 00:21:40,199
so it's kind of a futuristic okay sounds

463
00:21:37,960 --> 00:21:44,099
great thank you let's thank our speaker

464
00:21:40,200 --> 00:21:44,099
[Applause]

