1
00:00:00,400 --> 00:00:13,070
during gotta sleep so yeah well that's a
good discussion point how many of you

2
00:00:13,070 --> 00:00:16,519
had some international conflict last
night did you guys enjoy the diplomacy

3
00:00:16,519 --> 00:00:25,630
party that's higher and higher that's
about as many as I expected but cheer

4
00:00:25,630 --> 00:00:30,019
team captain that are awake yeah you
wanted it faster

5
00:00:30,019 --> 00:00:35,910
10 minutes was too slow wow ok so I've
heard whispers that there might be an

6
00:00:35,910 --> 00:00:41,640
impromptu diplomacy game and the this
ETF no lunch so if you do not get enough

7
00:00:41,640 --> 00:00:46,000
diplomacy and backstabbing and betrayal
last night we'll see what we can do

8
00:00:46,000 --> 00:00:52,860
later on as far as today we have a full
lineup of talks and presentations in

9
00:00:52,860 --> 00:00:57,370
this room all the villages are still
open so hardware hacking lockpicking and

10
00:00:57,370 --> 00:01:03,209
see ETFs are all running in this ETF
village we have the opposition and the

11
00:01:03,210 --> 00:01:07,470
official capture the flag contest
there's also a hidden challenge if you

12
00:01:07,470 --> 00:01:13,230
didn't hear me talk about this yesterday
that has something to do with FM radio I

13
00:01:13,230 --> 00:01:17,409
actually felt my hand test yesterday so
I'm not sure how that works but I'm told

14
00:01:17,409 --> 00:01:22,540
something about FM radio and hidden
challenges and they told me that none of

15
00:01:22,540 --> 00:01:27,800
you guys can solve it so I was hoping
you would prove them wrong other than

16
00:01:27,800 --> 00:01:33,940
that if you're in the temper evidence
the room contest you have three minutes

17
00:01:33,940 --> 00:01:39,350
to turn in your package otherwise your
your source will die in this tale of

18
00:01:39,350 --> 00:01:46,169
spying mystery and intrigue later on
today at 1400 we have the book on robot

19
00:01:46,170 --> 00:01:51,140
battle that will be out in the pool area
there's also entered a lockpicking

20
00:01:51,140 --> 00:01:58,020
lockpicking village later today and the
CTF saw land at about four o'clock so if

21
00:01:58,020 --> 00:02:01,020
you're working on problems get all your
answers submitted before then

22
00:02:01,520 --> 00:02:05,890
outside all our vendors and sponsors so
be sure to say hi to them there's lots

23
00:02:05,890 --> 00:02:10,929
of swag actually if I was a conference
organizer I would have gotten back your

24
00:02:10,929 --> 00:02:12,130
swag throw you can

25
00:02:12,130 --> 00:02:15,450
me but I drank a lot last night what can
I say

26
00:02:15,450 --> 00:02:21,040
coming up next we have cheaper now
talking about the ethical spine so we'll

27
00:02:21,040 --> 00:02:24,040
get that started in just a few minutes
thank you

28
00:02:51,069 --> 00:02:54,518
ok so I'm she

29
00:02:54,519 --> 00:03:04,709
data scientist I frac I understand that
everybody's hungover luckily I think

30
00:03:04,709 --> 00:03:07,599
this might be a short talks I'm headed
in my head that these are half hour

31
00:03:07,599 --> 00:03:14,078
talks today so I'm gonna be talking to
you today about data privacy everybody's

32
00:03:14,079 --> 00:03:20,700
hearts and how to strike a good balance
between making data driven service is

33
00:03:20,700 --> 00:03:25,649
useful and protecting the interests of
the user and in a climate where

34
00:03:25,650 --> 00:03:30,370
accidentally disclose data can have very
very far-reaching consequences I think I

35
00:03:30,370 --> 00:03:34,040
don't need to go deeply into it you guys
because this whole entire weekend has

36
00:03:34,040 --> 00:03:38,569
been extended reiterations of why it's
important that your data not going to

37
00:03:38,569 --> 00:03:46,060
loose talk to you about how to ensure
that as rebuilding outdid urban services

38
00:03:46,060 --> 00:03:53,280
we don't compromise the user's personal
interests in the in the in the critic

39
00:03:53,280 --> 00:03:58,909
for the goals of delivering a good
product and services there are a lot of

40
00:03:58,909 --> 00:04:04,269
them out there and more things are data
driven every day because that's in the

41
00:04:04,269 --> 00:04:07,120
in a climate where there's a huge amount
of information to filter through

42
00:04:07,120 --> 00:04:10,620
offloading as much of that as you can
into services are really good idea

43
00:04:11,579 --> 00:04:17,130
recommendation and discovery under the
first one that everybody thinks of in

44
00:04:17,130 --> 00:04:20,579
order to combat information overload you
need to know a little bit about what you

45
00:04:20,579 --> 00:04:23,710
need to filter off the stream and that's
a very different set of filters for

46
00:04:23,710 --> 00:04:30,638
everybody so recommendation engines
discovery engines tender sponsors used

47
00:04:30,639 --> 00:04:38,909
to work there does a lot of that and we
need to know a lot about you in order to

48
00:04:38,909 --> 00:04:42,020
deliver reasonable recommendations we
need to know what you're after we need

49
00:04:42,020 --> 00:04:47,080
to know who have slowed sleep yes and no
one before so that we can deliver things

50
00:04:47,080 --> 00:04:49,219
that might be relevant to you

51
00:04:49,219 --> 00:04:55,210
crowdsourcing maps and traffic everybody
uses ways most people use with everybody

52
00:04:55,210 --> 00:04:55,568
you

53
00:04:55,569 --> 00:05:00,249
ways is giving up their location trail
to a public to a service that doesn't

54
00:05:00,249 --> 00:05:03,529
really disclose what they're going to do
with that after you do you give it to

55
00:05:03,529 --> 00:05:06,639
them there's probably a privacy policy

56
00:05:06,639 --> 00:05:09,860
I've never seen it raise your hand if
you've seen with our Privacy Policy

57
00:05:09,860 --> 00:05:20,719
anybody so that's a lot of information
if somebody knows where you are and who

58
00:05:20,719 --> 00:05:24,589
you are they know how to get at you and
that's that's kind of one of the primary

59
00:05:24,589 --> 00:05:26,419
concerns here

60
00:05:26,419 --> 00:05:30,289
the trouble is that if somebody knows
your identity and your location they can

61
00:05:30,289 --> 00:05:36,449
get away with a lot of German services
are amazingly useful the solution isn't

62
00:05:36,449 --> 00:05:40,759
to get rid of them we want to continue
sharing our information to make things

63
00:05:40,759 --> 00:05:41,349
better

64
00:05:41,349 --> 00:05:50,149
most of us yeah everybody's to hunger
remove science

65
00:05:52,220 --> 00:05:59,110
but data privacy policies have a lot of
issues that exist where they exist

66
00:05:59,110 --> 00:06:03,370
they're often hard to find their written
in legalese they are written in language

67
00:06:03,370 --> 00:06:07,820
in a language that really is meant not
to protect you as a user they're written

68
00:06:07,820 --> 00:06:11,469
in a way that instead is really pretty
much there to cover the service

69
00:06:11,470 --> 00:06:19,250
providers but the purpose of a data
privacy policy is to in on the scale

70
00:06:19,250 --> 00:06:23,430
confiscated language inform you the user
what they're going to do with your data

71
00:06:23,430 --> 00:06:28,340
so that when you say hey what the hell
because they told you so and that's not

72
00:06:28,340 --> 00:06:32,159
ideal that's not that's not oriented
towards of towards a climate of trust

73
00:06:32,160 --> 00:06:38,750
that's not something that allows a user
to really make an informed decision it's

74
00:06:38,750 --> 00:06:42,880
not always easy to find these things not
always easy to review these things and

75
00:06:42,880 --> 00:06:46,370
they are rarely flexible if you're
signing up for a service the

76
00:06:46,370 --> 00:06:50,530
understanding is that you it's on you to
go and review what it is that you're

77
00:06:50,530 --> 00:06:56,330
giving away what the consequences might
be that assess your own risks kind of in

78
00:06:56,330 --> 00:06:59,530
a vacuum without really understanding
what's being kept how it's being kept

79
00:06:59,530 --> 00:07:03,510
her who will have access to it and if
you want to do that well okay just opt

80
00:07:03,510 --> 00:07:09,150
out don't use the service that works
sometimes that can be an alright model

81
00:07:09,150 --> 00:07:13,229
for something like waves it's kind of a
no-brainer that if you're using that

82
00:07:13,229 --> 00:07:18,039
service they know who you are where you
are they know some things about the

83
00:07:18,040 --> 00:07:21,180
clusters of locations that you visit so
they know maybe where you work where you

84
00:07:21,180 --> 00:07:22,440
live

85
00:07:22,440 --> 00:07:26,790
that's pretty identifiable and the fact
that they don't really disclosed to you

86
00:07:26,790 --> 00:07:30,910
in a way that's easy to find and easy to
understand what they're going to do with

87
00:07:30,910 --> 00:07:34,550
that just make you assume that ok well
if you're going to use the service you

88
00:07:34,550 --> 00:07:40,260
just kind of getting a lot of autonomy
that's not good that's not what I think

89
00:07:40,260 --> 00:07:42,159
any of us really wants

90
00:07:42,160 --> 00:07:45,370
there's got to be a better way

91
00:07:45,370 --> 00:07:50,140
consider sexy people are drawn that
around a lot lately it's also really

92
00:07:50,140 --> 00:07:53,409
really complicated how do you consent

93
00:07:53,410 --> 00:08:00,100
how do you as a service provider assess
what it is you need to ask permission

94
00:08:00,100 --> 00:08:06,210
for how do you deliver that to a user in
a way that makes sense that's

95
00:08:06,210 --> 00:08:11,270
comprehensible and that is that can that
can really allow a user to genuinely say

96
00:08:11,270 --> 00:08:14,760
yes ok I understand what I'm taking in
what time when I'm giving you understand

97
00:08:14,760 --> 00:08:22,390
what the restrictions are on that and
I'm cool and interesting model that I've

98
00:08:22,390 --> 00:08:26,909
decided to base on base the rest of this
on is medical informed consent informed

99
00:08:26,910 --> 00:08:32,620
consent has a very narrow definition
it's it has the advantage of having been

100
00:08:32,620 --> 00:08:38,450
tried in a lot of courts it's pretty
well defined at this point the reason

101
00:08:38,450 --> 00:08:42,960
why they've had to define it so well is
because medical decision-making involves

102
00:08:42,960 --> 00:08:49,570
bodily autonomy it involves risk your
life your health your abilities you know

103
00:08:49,570 --> 00:08:55,530
it it requires a robust model of consent
where when you are accepting a procedure

104
00:08:55,530 --> 00:08:58,850
that's going to be done to you when
you're accepting something that's going

105
00:08:58,850 --> 00:09:05,270
to put you at risk you must be well
informed as to what you're accepting and

106
00:09:05,270 --> 00:09:10,410
you have to have a robust means to say
yes I'm accepting this I'm taking on

107
00:09:10,410 --> 00:09:19,459
these risks data can also get you can't
there are stories out for just about

108
00:09:19,460 --> 00:09:22,520
every dating site that exists if you
know the person who accidentally went on

109
00:09:22,520 --> 00:09:25,569
a date with a serial killer sometimes it
ends well sometimes it doesn't

110
00:09:25,570 --> 00:09:31,940
there are lots of people who don't want
to be found by lots of other people for

111
00:09:31,940 --> 00:09:36,620
a variety of reasons and if you are
exposing your location

112
00:09:37,750 --> 00:09:43,800
your facebook I D anything that comes
with your facebook identity to a service

113
00:09:43,800 --> 00:09:47,349
which they then sell your service and in
aggregate but

114
00:09:47,350 --> 00:09:53,310
you know as a as a collection points
that may be an unbiased it can be

115
00:09:53,310 --> 00:09:57,949
discovered what your habits are they can
be discovered where you're going in case

116
00:09:57,950 --> 00:10:01,820
in case of a location service it can be
discovered where you live in those cases

117
00:10:01,820 --> 00:10:11,690
right now I'm working at home automation
we know a lot about people's home habits

118
00:10:11,690 --> 00:10:16,240
if an attacker discovered this it's
trivial even without access to the

119
00:10:16,240 --> 00:10:20,180
command interface you know and which in
turn on somebody's life for their door

120
00:10:21,160 --> 00:10:24,510
you know when they go to bed you know
when they get up you know when they're

121
00:10:24,510 --> 00:10:29,380
usually out if you have there if you
have their their location clusters their

122
00:10:29,380 --> 00:10:33,760
habits at home you know a whole lot
about them and you know enough to mount

123
00:10:33,760 --> 00:10:38,540
an actual legitimate physical attack
that could pose a serious risk to life

124
00:10:38,540 --> 00:10:43,410
safety data can really get you killed
and so I believe that on medical

125
00:10:43,410 --> 00:10:47,180
informed consent model is actually a
really really good way to base

126
00:10:47,180 --> 00:10:49,250
discussions about this going forward

127
00:10:49,250 --> 00:10:55,570
know what is that luckily like I said
the lawyers have been all over this

128
00:10:55,570 --> 00:11:00,910
there's there have been identified three
major components to consent that is

129
00:11:00,910 --> 00:11:06,969
informed it's necessary that there be
disclosure the person consenting needs

130
00:11:06,970 --> 00:11:13,140
to understand what's being done if I say
hey can I can I do this procedure on you

131
00:11:13,140 --> 00:11:18,380
so sure and you have no idea what
actually know what actually that entails

132
00:11:18,380 --> 00:11:20,520
will there be anesthesia or not you know

133
00:11:20,520 --> 00:11:24,579
will there be surgery no you haven't you
haven't necessarily consent unless you

134
00:11:24,580 --> 00:11:29,050
understand what it is you're consenting
to the same as fairly basic but it

135
00:11:29,050 --> 00:11:32,380
actually you know has been tried and
retried and signed into law how do you

136
00:11:32,380 --> 00:11:38,900
disclose these things what is important
to disclose and how you how you make

137
00:11:38,900 --> 00:11:43,530
sure that someone has understood this
next it is necessary that you have the

138
00:11:43,530 --> 00:11:49,110
capacity to consent if you are very
young you can't consent of things

139
00:11:49,110 --> 00:11:58,100
medically the ages 13 I've been told
United States edition you know relatedly

140
00:11:58,100 --> 00:12:01,130
probably there's a law called cockroach
the Children's Online Privacy Protection

141
00:12:01,130 --> 00:12:07,189
Act which is behind the existence of all
those forms and websites you say I am at

142
00:12:07,190 --> 00:12:15,350
least 13 13 seems to be the generally
accepted age for people at Which Wich

143
00:12:15,350 --> 00:12:19,990
somebody can asset can accurately
accessory assess risk enough to make

144
00:12:19,990 --> 00:12:23,460
medical decisions for themselves in our
Privacy decisions for themselves so

145
00:12:23,460 --> 00:12:28,100
that's the working definition that I but
doctor also necessary but you have UN

146
00:12:28,100 --> 00:12:32,410
General be able to exercise autonomy
responsibly if you've been declared

147
00:12:32,410 --> 00:12:39,350
incapacitated you may not be able to
consent finally and this is an 81 on

148
00:12:39,350 --> 00:12:42,160
this is a tricky one and I'm gonna go
into this more deeply later it's

149
00:12:42,160 --> 00:12:46,100
necessary that consent befallen Terry
and what that means is that you cannot

150
00:12:46,100 --> 00:12:52,410
be coerced know what's coercion
obviously if somebody's got a firearm

151
00:12:52,410 --> 00:12:57,430
and they pointing it at your head and
they're saying it's not consent that's

152
00:12:57,430 --> 00:13:02,030
that's clearcut coercion but what if
someone saying all you know you have

153
00:13:02,030 --> 00:13:08,380
every right to decline you don't have to
do this but she really should do this

154
00:13:08,380 --> 00:13:14,439
and their social pressure in place such
that you don't feel like safely you can

155
00:13:14,440 --> 00:13:19,250
say no and being a defensible position
or you don't feel like you can say no

156
00:13:19,250 --> 00:13:23,990
and avoid consequences that you don't
want that are not related directly to

157
00:13:23,990 --> 00:13:27,939
the lack of consent to this service is
that concern

158
00:13:27,939 --> 00:13:34,559
legally it's still the debt is not if
you do not pursue if you do not have

159
00:13:34,559 --> 00:13:40,719
received the ability to say no you can
also yes so these are the three

160
00:13:40,720 --> 00:13:47,179
components that I'd like to use as a
working definition of what consent

161
00:13:47,179 --> 00:13:52,409
entails and how it can be assessed that
someone has consented to have their

162
00:13:52,409 --> 00:14:01,459
information used by a service beginning
to look a lot like standards purpose of

163
00:14:01,459 --> 00:14:05,689
this talk and there is no running around
appeared ten o'clock in the morning

164
00:14:05,689 --> 00:14:12,549
before everybody's over their hangovers
is I would like to move towards a common

165
00:14:12,549 --> 00:14:19,228
definition of what it means to collect
data in a consenting fashion from users

166
00:14:19,229 --> 00:14:25,139
who are informed so what if what if we
had a standard set of disclosures in a

167
00:14:25,139 --> 00:14:30,599
format for those disclosures that a user
had to receive before they can send and

168
00:14:30,599 --> 00:14:36,220
share their data what if those disclosed
this to this closures covered the entire

169
00:14:36,220 --> 00:14:42,299
lifecycle of that data what is being
collected what the plant uses are how

170
00:14:42,299 --> 00:14:50,089
it'll be retained how long it's retained
how it secured how it's destroyed and

171
00:14:50,089 --> 00:14:53,299
what their responsibilities of the
collecting party are in the event that

172
00:14:53,299 --> 00:15:00,019
it's exposed what if those disclosures
were given in a language of the user was

173
00:15:00,019 --> 00:15:03,479
guaranteed to understand both because it
is the native language of the user

174
00:15:03,479 --> 00:15:04,910
interface their operating in

175
00:15:04,910 --> 00:15:10,589
in and use template language that had
very clear understood publicly defined

176
00:15:10,590 --> 00:15:16,350
meanings and what if there were a
structure so that service providers

177
00:15:16,350 --> 00:15:20,660
could be held accountable for violations
of this what if although this is

178
00:15:20,660 --> 00:15:24,199
voluntary standard what if someone
advertising that they meet this standard

179
00:15:24,200 --> 00:15:29,600
was discovered not be meeting the
standard were somehow made accountable

180
00:15:29,600 --> 00:15:33,010
for the promises they made in that
disclosure how breach was going to be

181
00:15:33,010 --> 00:15:42,930
handle it sounds good so this is a
democracy I have begun working on my own

182
00:15:42,930 --> 00:15:49,219
and IGF draft covering what how one
might collect data with consent it's a

183
00:15:49,220 --> 00:15:54,530
framework for these disclosures it will
contain some some baseline templated

184
00:15:54,530 --> 00:16:00,510
language and English that's my language
for accountability and for how you

185
00:16:00,510 --> 00:16:06,120
evaluate consent the purpose of the
document is to protect the user

186
00:16:07,080 --> 00:16:13,550
well allowing service providers to
remain flexible service providers as

187
00:16:13,550 --> 00:16:18,319
they develop a service often cannot
provide these value-added services until

188
00:16:18,320 --> 00:16:24,020
they have a nice data coming in so how
do we covered the case where you know

189
00:16:24,020 --> 00:16:28,920
you have a plan future feature you need
to create collection baseline data but

190
00:16:28,920 --> 00:16:32,650
the user by ship by failing to share
this is only making the service

191
00:16:32,650 --> 00:16:36,760
development situation actually impacted
themselves there's no advantage

192
00:16:36,760 --> 00:16:41,700
immediately for the user to share this
information is just a voluntary thing to

193
00:16:41,700 --> 00:16:46,050
help make a service better how do we
disclose that how do we say we'd like to

194
00:16:46,050 --> 00:16:51,870
collect this from you when I know what
we're going to use it for you how to

195
00:16:51,870 --> 00:16:54,560
disclose that in a way that allows
somebody to say well yes that's a risk

196
00:16:54,560 --> 00:16:58,719
I'm still willing to take the things
need the draft covers changes in the

197
00:16:58,720 --> 00:17:03,260
user status what happens if someone
becomes incapacitated what happens if

198
00:17:03,260 --> 00:17:06,260
somebody dies what happens to their
content what happens to their metadata

199
00:17:07,970 --> 00:17:11,720
and it's designed to provide a
groundwork for trust between service

200
00:17:11,720 --> 00:17:18,209
providers and users because right now I
don't I don't feel that that exists I

201
00:17:18,209 --> 00:17:22,069
don't feel that there's really a real
baseline for saying okay well his these

202
00:17:22,069 --> 00:17:25,599
the disclosures the privacy policy of
policies that existing means something

203
00:17:25,599 --> 00:17:29,520
when I see our privacy policy policy
listed even if they're even if it's

204
00:17:29,520 --> 00:17:34,000
accessible my first thought is an
upgrade their protector like your spot

205
00:17:34,000 --> 00:17:38,240
is let me read this very carefully
because I know the discoverer somebody

206
00:17:38,240 --> 00:17:41,240
else's butt and I know that this is not
designed for protection

207
00:17:42,590 --> 00:17:47,039
it would be great if we had a standard
that people can voluntarily abide by

208
00:17:47,039 --> 00:17:56,559
that proposal that allowed for a better
model so I prepared a much shorter talk

209
00:17:56,559 --> 00:18:00,168
when I realize I should be preparing but
that's kinda good because I really want

210
00:18:00,169 --> 00:18:05,210
to open up the floor for you guys to
contribute one of the things I'm hoping

211
00:18:05,210 --> 00:18:09,169
comes out of this is that any of you who
are interested in this idea and think

212
00:18:09,169 --> 00:18:10,679
it's cool

213
00:18:10,679 --> 00:18:14,890
feel empowered and ready to come talk to
me and to that end to start some

214
00:18:14,890 --> 00:18:21,350
discussions I've got some open questions
one of the things I'm interested in

215
00:18:21,350 --> 00:18:27,299
evaluating this how you define capacity
is 13 really a reason to believe judge

216
00:18:27,299 --> 00:18:31,530
should there be an age limit on consent
for privacy

217
00:18:32,490 --> 00:18:41,919
how do we handle someone who is legally
declared incapacitated delegation that's

218
00:18:41,919 --> 00:18:45,570
always tricky in a voluntary standard
and I would say that maybe this is the

219
00:18:45,570 --> 00:18:50,780
biggest open question right know how do
we decide that someone is compliant with

220
00:18:50,780 --> 00:18:54,470
the standard say we've got this publish
we've got an RFC somebody says okay

221
00:18:54,470 --> 00:19:02,460
we're RFC mumble mumble compliant ok
they said so if we're really fostering

222
00:19:02,460 --> 00:19:06,220
trust here we actually have some sort of
certifying board says okay well he might

223
00:19:06,220 --> 00:19:07,230
be audited

224
00:19:07,230 --> 00:19:11,980
look and say you know actually
implementing the standard thing people

225
00:19:11,980 --> 00:19:20,470
around content versus metrics I'm going
to go through in a minute I'm actually

226
00:19:20,470 --> 00:19:27,900
going through unfortunately the the
conversion so there's there's a tool

227
00:19:27,900 --> 00:19:32,790
that allows you to develop IETF draft an
XML and convert them to standard RFC

228
00:19:32,790 --> 00:19:40,520
format nose like a great shining show
the converted version online version of

229
00:19:40,520 --> 00:19:47,440
the XML converter tool is down and get
it to install on that great but

230
00:19:47,440 --> 00:19:54,540
everybody here to read actually all
hackers soldier that up in a moment the

231
00:19:54,540 --> 00:20:00,780
language of the draft makes a
distinction between content and metrics

232
00:20:00,780 --> 00:20:03,950
content being something that's intended
for consumption by someone other than

233
00:20:03,950 --> 00:20:09,070
the service itself metrics being Shane
readable information that's provided to

234
00:20:09,070 --> 00:20:12,540
the service for use by the service so
you know on Facebook

235
00:20:13,580 --> 00:20:24,799
your browsing history symmetric your age
demographics that symmetric the content

236
00:20:24,799 --> 00:20:31,070
your posting is obviously content
sensitive data vs non sensitive data

237
00:20:31,070 --> 00:20:36,659
versus p.m. there's a lot of information
that one could reasonably collect some

238
00:20:36,660 --> 00:20:43,350
of it doesn't matter you know there's
some information that we might be able

239
00:20:43,350 --> 00:20:51,260
to say is harmless but you can always
stay because it's so innocuous the user

240
00:20:51,260 --> 00:20:53,370
name someone just choose for themselves
as bad

241
00:20:53,370 --> 00:20:59,168
sensitive is an uncensored PII is
personally identifiable information

242
00:20:59,169 --> 00:21:02,750
that's got a very narrow legal
definition is so we're pretty covered

243
00:21:02,750 --> 00:21:07,620
but there's a large large universe of
data out there that is not covered by

244
00:21:07,620 --> 00:21:10,620
standard definition how much of it needs
to be protected

245
00:21:14,370 --> 00:21:19,780
another big one how do we communicate
risk it's one thing to tell user in OJ

246
00:21:19,780 --> 00:21:26,360
random user New Zealand oh you're
sharing your agreeing to share your

247
00:21:26,360 --> 00:21:31,429
location trail if someone is not
accustomed to thinking about this they

248
00:21:31,430 --> 00:21:33,780
might say okay well you can see where I
was

249
00:21:33,780 --> 00:21:39,889
you can retain that indefinitely how do
we communicate in a way that's clear

250
00:21:39,890 --> 00:21:45,970
that this is this is not something you
maybe want out there this is something

251
00:21:45,970 --> 00:21:50,740
you need to be protecting people kind of
don't think about this

252
00:21:50,740 --> 00:21:55,100
outside of outside of rooms like this
people are willing to share all kinds of

253
00:21:55,100 --> 00:21:59,178
things and that's handy for me is you
know did a scientist it's great that I

254
00:21:59,179 --> 00:22:04,320
have a big data set but I'd like to know
that I haven't collected on ethically so

255
00:22:04,320 --> 00:22:11,010
how does how is it that we communicated
users what they're putting it stick what

256
00:22:11,010 --> 00:22:14,679
things are what things are considered to
be posed pose a risk to you know your

257
00:22:14,679 --> 00:22:21,820
property for your personal safety your
future personal safety what about health

258
00:22:21,820 --> 00:22:26,399
information you know there's a lot of
laws governing what may be shared but

259
00:22:26,400 --> 00:22:30,480
they are all out the window of your
voluntarily sharing something with the

260
00:22:30,480 --> 00:22:39,120
service how do we communicate to a user
that might not be a good idea what I'd

261
00:22:39,120 --> 00:22:45,449
like to do now is through the draft up
here and I apologize for the formatting

262
00:22:45,450 --> 00:22:48,450
because it was supposed to be a lot
shinier

263
00:22:52,060 --> 00:23:05,139
from matter we've largely gone over this
interesting definition of disclosure

264
00:23:05,140 --> 00:23:10,850
this is a dress standards so there's
lots of there's lots of things to to go

265
00:23:10,850 --> 00:23:17,360
through this before this this is the
required content before allowing a user

266
00:23:17,360 --> 00:23:24,360
to consent what we what must the service
provider share this is where I'm using a

267
00:23:24,360 --> 00:23:29,209
lot of metrics content is kind of a big
open questions for me how do you protect

268
00:23:29,210 --> 00:23:34,750
that how do you it's it's much what
might be in there anything in there so

269
00:23:34,750 --> 00:23:43,180
it is it always sensitive is it always
considered sensitive data is interesting

270
00:23:43,180 --> 00:23:49,720
and here sharing data with other
services what happens when you as a

271
00:23:49,720 --> 00:23:53,700
service I mean everybody is sharing data
with everybody this is in this part of

272
00:23:53,700 --> 00:23:57,640
the product that people have these
agreements this point you know ok we're

273
00:23:57,640 --> 00:24:00,950
gonna get the data from this service
over here we're used to make the service

274
00:24:00,950 --> 00:24:07,320
better and you know right now there's a
one click link the accounts great they

275
00:24:07,320 --> 00:24:10,870
already had it who cares about them
that's not a good idea

276
00:24:11,460 --> 00:24:16,070
privacy policies may vary greatly in
between those two services how he

277
00:24:16,070 --> 00:24:22,310
disclosed that to use this address is
this sharing must be disclosed under

278
00:24:22,310 --> 00:24:27,700
this model under this model and
disclosure of services of service

279
00:24:27,700 --> 00:24:32,200
sharing needs to include all of the same
information that the original disclosure

280
00:24:32,200 --> 00:24:36,800
included including the retention period
security model the destruction

281
00:24:36,800 --> 00:24:38,520
richresponse

282
00:24:38,520 --> 00:24:44,360
and destination at the at the sharing
service at the shared to service rather

283
00:24:44,360 --> 00:24:48,850
where user can go to get a full listing
the privacy policy

284
00:24:49,900 --> 00:24:54,120
how do we handle Sherrington
non-compliant services if the standard

285
00:24:54,120 --> 00:24:58,379
is completed and adopted we can assume
that at least at the beginning probably

286
00:24:58,380 --> 00:25:01,170
forever

287
00:25:01,170 --> 00:25:07,080
there'll be a lot of services that don't
choose to comply we should not restrict

288
00:25:07,080 --> 00:25:11,870
a service provider from sharing data
with on compliance services we should

289
00:25:11,870 --> 00:25:14,389
restrict how they can do that and how
they must disclose it if they're going

290
00:25:14,390 --> 00:25:21,550
to remain compliant pasady determination
the loss of capacity this one is

291
00:25:21,550 --> 00:25:27,740
interesting I'm proposing that if he
hears or loses the capacity to consent

292
00:25:27,740 --> 00:25:33,780
you know they passed away when they
become legally incapacitated they should

293
00:25:33,780 --> 00:25:38,820
be able to before that designated proxy
with service to this person is empowered

294
00:25:38,820 --> 00:25:46,159
to those persons and Howard consent for
me to take charge of my information if

295
00:25:46,160 --> 00:25:52,390
that proxy doesn't isn't is not defined
or can be contacted you need to proceed

296
00:25:52,390 --> 00:25:56,820
as if consent has been withdrawn this
means you remove data that has been

297
00:25:56,820 --> 00:26:02,080
retained you just you just assume that
the consent was not about to begin with

298
00:26:02,600 --> 00:26:06,330
that's also what happens if you discover
that someone was not actually capable of

299
00:26:06,330 --> 00:26:10,679
consenting if you have a bizarre that
says only like 25 when you find out

300
00:26:10,680 --> 00:26:17,200
there like six what do you do what you
do is you must consider that consent to

301
00:26:17,200 --> 00:26:19,080
have been actively immediately

302
00:26:19,080 --> 00:26:24,668
got dumped everything you must not
continue to collect anything and unless

303
00:26:24,669 --> 00:26:30,559
there's a reasonable expectation the
user would be exposed harm their proxy

304
00:26:30,559 --> 00:26:34,460
should be notified that data was
collected without authorization and so

305
00:26:34,460 --> 00:26:40,029
that you can proceed in honor of the men
are defined by the disclosure agreement

306
00:26:42,640 --> 00:26:52,029
here's another interesting section that
I haven't gone over at all I think this

307
00:26:52,029 --> 00:26:57,360
is really neat because there are there's
a very there's a very clear distinction

308
00:26:57,360 --> 00:27:01,090
for me although the borderline is has a
lot of fuzziness in it and things kind

309
00:27:01,090 --> 00:27:07,158
of can jump over this border some
services I can just have to i dont have

310
00:27:07,159 --> 00:27:15,510
to be on tender have to use lift so I
don't like the third collecting this

311
00:27:15,510 --> 00:27:19,658
information about me I don't have to use
wink and I can say I don't want the

312
00:27:19,659 --> 00:27:27,940
internet to know that much about me I'm
not going to use it and so do things

313
00:27:27,940 --> 00:27:32,519
that I cannot use this service without
it's very easy for me to say okay well

314
00:27:32,519 --> 00:27:37,360
you know I'm going in and if I don't
want to use the service that's an easy

315
00:27:37,360 --> 00:27:42,799
opt out for me there are situations and
they're kind of company for which this

316
00:27:42,799 --> 00:27:48,620
is not true and we need to handle these
effectively I'm drawing a distinction

317
00:27:48,620 --> 00:27:52,489
here in this document between a company
that should be considered a utility in a

318
00:27:52,490 --> 00:28:00,240
company that is not utility company is a
utility if someone cannot just withdraw

319
00:28:00,240 --> 00:28:04,159
their use of the Service and your use of
the Service without being exposed to

320
00:28:04,159 --> 00:28:10,110
very negative repercussions the electric
company it's not trivial for me to say

321
00:28:10,110 --> 00:28:16,549
really use dwp anywhere you know I don't
like that they're collecting light meter

322
00:28:16,549 --> 00:28:17,049
data

323
00:28:17,049 --> 00:28:20,418
like that they know how many people are
in my house because of how much how many

324
00:28:20,419 --> 00:28:28,179
utilities and using that's not possible
to do and so what I'm proposing is that

325
00:28:28,179 --> 00:28:36,210
if some of it if the company is reaches
the pervasiveness and the life necessity

326
00:28:36,210 --> 00:28:43,279
of being considered a utility there is a
much smaller set of set of permissions

327
00:28:43,279 --> 00:28:48,309
that they can make mandatory by much
smaller I mean that pretty much the only

328
00:28:48,309 --> 00:28:53,668
thing i think is really necessary is
billing address for services that are

329
00:28:53,669 --> 00:28:59,889
available if you are if you are
complicated enough and indented enough

330
00:28:59,889 --> 00:29:04,320
and culture that there are major
negative repercussions for you not using

331
00:29:04,320 --> 00:29:10,239
this service you can't really consider
and any collected information to have

332
00:29:10,239 --> 00:29:13,690
been given on coercive lead so at that
point you need to have an opt-out for

333
00:29:13,690 --> 00:29:20,220
everything so what I'm proposing is that
the one the one next to one possible

334
00:29:20,220 --> 00:29:25,639
exception that someone may may propose
for this is something necessary for

335
00:29:25,639 --> 00:29:34,149
building and that should never be
mandatorily electronic it should never

336
00:29:34,149 --> 00:29:37,729
be should never be mandatory that you
place your financial do that with any

337
00:29:37,730 --> 00:29:43,769
service unless you can reasonably just
not use the service so I'm talking about

338
00:29:43,769 --> 00:29:50,609
mandatory vs vs optional got a very
clean definition of this really quickly

339
00:29:51,570 --> 00:29:55,049
metric esteemed mandatory for use of
service provider cannot deliver on its

340
00:29:55,049 --> 00:29:58,929
core functionality or can't collect
agreed upon payment for services without

341
00:29:58,929 --> 00:30:03,809
collecting the metric according to the
disclosure terrors example would be

342
00:30:03,809 --> 00:30:08,668
collection of location please buy
something like ways not really gonna

343
00:30:08,669 --> 00:30:11,549
work for you if they're not at least
collecting that information and

344
00:30:11,549 --> 00:30:18,940
retaining it for long enough to give you
to give you reasonable routing and to

345
00:30:18,940 --> 00:30:20,210
build a traffic map that makes

346
00:30:20,210 --> 00:30:25,740
sense so that's mandatory for you so
that you said that service for lift they

347
00:30:25,740 --> 00:30:28,480
need to know where you are because I
need to know you got in the car they

348
00:30:28,480 --> 00:30:32,440
need to know where the sense in the car
to get to know you got out they need to

349
00:30:32,440 --> 00:30:39,080
know how to bill you what about the case
where lift becomes a utility imagine a

350
00:30:39,080 --> 00:30:44,659
future where imagine a future where
where there are buses where there are

351
00:30:44,660 --> 00:30:48,510
private taxis where everything is
through service like lift and you can't

352
00:30:48,510 --> 00:30:55,710
reasonably transport yourself without
lift what happens then at that point

353
00:30:55,710 --> 00:30:59,250
they need to be able to provide an
opt-out that says well I don't don't

354
00:30:59,250 --> 00:31:04,400
collect my location you may not retain
this this may be used locally on my

355
00:31:04,400 --> 00:31:08,600
drivers device may not collect my own
personal information you need to have

356
00:31:08,600 --> 00:31:19,870
this amendatory metric given that lived
is not a utility yet does not have to

357
00:31:19,870 --> 00:31:25,479
provide enough dough user or user has
given consent if they're using the

358
00:31:25,480 --> 00:31:30,280
service they're still subject to
disclosure capacity but they aren't

359
00:31:30,280 --> 00:31:33,280
considered to be coercive

360
00:31:34,030 --> 00:31:39,980
metrics can't be considered mandatory in
case of utility except for the billing

361
00:31:39,980 --> 00:31:45,860
address rebuild services which can be
superseded by electronic you know if

362
00:31:45,860 --> 00:31:49,199
I've already given my credit card
information they don't need to have my

363
00:31:49,200 --> 00:31:52,920
address because they don't need them for
building but if they have no other way

364
00:31:52,920 --> 00:31:55,870
of killing me they can't make it a
billing address mandatory and that's the

365
00:31:55,870 --> 00:32:02,310
one thing i think is hard to get around
a metric is optional if a provider can

366
00:32:02,310 --> 00:32:05,740
deliver core functionality to the user
without collecting it even if it's

367
00:32:05,740 --> 00:32:09,400
necessary for the delivery of some value
added services now this gives service

368
00:32:09,400 --> 00:32:15,360
provider fair bit of wiggle room what
score that's really if that's really a

369
00:32:15,360 --> 00:32:17,459
determination to be made by the service
provider

370
00:32:17,460 --> 00:32:25,429
is what's what's a good one is is tender
still tender if it's not giving you a

371
00:32:25,429 --> 00:32:30,440
location-aware information is tender
still tender if it's not as if it's not

372
00:32:30,440 --> 00:32:39,850
filtering on your demographics sure
probably so it will be a lot of this

373
00:32:39,850 --> 00:32:43,668
leaves a lot up to the service provider
to determine what's mandatory which is

374
00:32:43,669 --> 00:32:50,700
why I place this restriction on utility
companies because in that case they

375
00:32:50,700 --> 00:32:55,049
could just to find lots of things is
mandatory and the new religiously just

376
00:32:55,049 --> 00:33:02,220
like we already are an example of
value-added service that provides

377
00:33:02,220 --> 00:33:06,409
additional utility but isn't more
functionality as long-term retention of

378
00:33:06,409 --> 00:33:12,789
passages long-term retention of location
to determine where as a user you like to

379
00:33:12,789 --> 00:33:17,730
go where's home where's your office it's
possible to his way it should be

380
00:33:17,730 --> 00:33:24,580
possible to use ways without exposing
tonight information at that point you

381
00:33:24,580 --> 00:33:30,389
need to allow a user to stop collecting
it but in order for this to be

382
00:33:30,390 --> 00:33:33,980
consenting you need to disclose it will
in part of the disclosure in this case

383
00:33:33,980 --> 00:33:41,010
is what happens if I opted out which
services will degrade part of the

384
00:33:41,010 --> 00:33:44,700
boilerplate language is that I'm
proposing covers how are you telling

385
00:33:44,700 --> 00:33:49,740
user what's going to suck if they say no
to something what they're going to lose

386
00:33:49,740 --> 00:33:55,010
because you can access assess risk
without seeing without knowing both

387
00:33:55,010 --> 00:34:00,200
what's in it for you and what you stand
to lose you can't make decisions without

388
00:34:00,200 --> 00:34:03,260
those two pieces of information and so
in the case of opt-outs you have to

389
00:34:03,260 --> 00:34:06,260
disclose what what is it that's not
going to work

390
00:34:07,140 --> 00:34:11,389
which brings us neatly to some of the
special considerations what about

391
00:34:11,389 --> 00:34:17,760
innovation I touched on this briefly
before service providers often are

392
00:34:17,760 --> 00:34:21,839
working on things in the back room that
require information that is not

393
00:34:21,839 --> 00:34:22,860
necessary

394
00:34:22,860 --> 00:34:27,930
any current service now part of a
disclosure as I mentioned says this is

395
00:34:27,929 --> 00:34:32,819
what we're using the data for future
under development

396
00:34:32,820 --> 00:34:36,470
you may not wish to disclose that to a
user yet because he may not wish to

397
00:34:36,469 --> 00:34:44,109
disclose that to your competitors this
covers what you do in those cases any

398
00:34:44,110 --> 00:34:47,060
such metrics that you want to collect
because you're developing a future

399
00:34:47,060 --> 00:34:53,389
service need to be treated as optional
and provide an opt-out in that

400
00:34:53,389 --> 00:34:58,279
description of the opt-out it must
confirm that you will not degrade and

401
00:34:58,280 --> 00:35:03,450
any currently available services that
what you stand to lose right now but not

402
00:35:03,450 --> 00:35:09,169
opting into this collection is nothing
you must clarify that because otherwise

403
00:35:09,170 --> 00:35:14,630
you make you may be coercive coercing
someone by providing incorrect

404
00:35:14,630 --> 00:35:20,470
information but you may inform the user
the quality of future services may be

405
00:35:20,470 --> 00:35:24,379
impacted otherwise would do it

406
00:35:25,190 --> 00:35:33,410
alarmed this is something that happens
it's it's you see this chairman aviation

407
00:35:33,410 --> 00:35:37,670
you need to just words carefully so
there are constant red lights blinking

408
00:35:37,670 --> 00:35:42,400
because then the important read later
when can you don't notice users that are

409
00:35:42,400 --> 00:35:46,550
confronted with a license agreement that
huge as this sounds like it might be

410
00:35:46,550 --> 00:35:52,430
might kill pressure to just say oh hell
and not going to read all this just just

411
00:35:52,430 --> 00:35:57,819
say yes that's not consent that's not
important to you bypass the disclosure

412
00:35:57,820 --> 00:36:04,010
battling with bullshit this is not to be
loud and part of the standard needs to

413
00:36:04,010 --> 00:36:07,830
define not only what must be disclosed
but how much of it should be disclosed

414
00:36:07,830 --> 00:36:11,430
you know how how much issued bombard the
user with this information

415
00:36:12,930 --> 00:36:16,799
also frequent updates to the collection
disclosures in case we're actively

416
00:36:16,800 --> 00:36:20,860
developing services and every week
you're getting a little pink that says

417
00:36:20,860 --> 00:36:24,380
do you want to disclose this information
read a bunch more disclosures people are

418
00:36:24,380 --> 00:36:28,950
gonna stop reading that other they're
gonna leave the service which is good

419
00:36:28,950 --> 00:36:34,379
for them but probably not good for you
or they're gonna stop reading it and

420
00:36:34,380 --> 00:36:38,370
stop actually getting real concern
that's meaningful one of the ways and

421
00:36:38,370 --> 00:36:47,009
proposed to combat this is too is that a
service may choose to treat opt-outs up

422
00:36:47,010 --> 00:36:53,000
and instead a service may choose to just
give a minimal set of permissions from

423
00:36:53,000 --> 00:36:57,900
animal core functionality at the outset
and inception there any user but if they

424
00:36:57,900 --> 00:37:03,850
do this they must consider the user to
have opted out from the beginning of all

425
00:37:03,850 --> 00:37:10,920
optional services metric elections but
that user must receive just look at this

426
00:37:10,920 --> 00:37:14,970
closure still of what they're losing
because if you have everything turned

427
00:37:14,970 --> 00:37:18,919
off by default users don't know what
you've got and they can make an informed

428
00:37:18,920 --> 00:37:21,920
decision

429
00:37:22,620 --> 00:37:31,160
opting out should be considered to be
retroactive to space you know and you

430
00:37:31,160 --> 00:37:34,120
said yes to everything and he went
through the privacy policy later

431
00:37:34,120 --> 00:37:40,150
wait what what you should be able to say
you know the assumption when you

432
00:37:40,150 --> 00:37:45,680
withdraw consent for a particular
medical collection is that you need to

433
00:37:45,680 --> 00:37:49,359
you need to drop all that going
backwards at the user the user has not

434
00:37:49,360 --> 00:37:55,590
consented for any use of this metric
anymore it is optional for a service

435
00:37:55,590 --> 00:38:00,340
provider to allow someone to waive that
requirement it is not optional to

436
00:38:00,340 --> 00:38:04,840
provide the retroactive doubt but it is
optional to allow the user to retain

437
00:38:04,840 --> 00:38:06,380
what's already been collected

438
00:38:06,380 --> 00:38:11,300
you may allow a user to do this in case
they do that the retention period from

439
00:38:11,300 --> 00:38:18,750
there is no disclosure continues to
apply I think I'm ready for questions

440
00:38:18,750 --> 00:38:22,260
we've been over a bunch of this got
something you

441
00:38:38,740 --> 00:39:19,649
I would love to I should be taking notes
and collaborators for people to join its

442
00:39:19,650 --> 00:39:25,630
not going to get to their with a lot
more experience in fact is that a real

443
00:39:25,630 --> 00:39:28,630
question

444
00:39:48,330 --> 00:40:06,630
company that operates enough to get me
started

445
00:40:06,630 --> 00:40:09,880
smart enough to adhere to those
restrictions liens

446
00:40:09,880 --> 00:40:13,940
specifically there already are a lot of
laws in place that tell you how you must

447
00:40:13,940 --> 00:40:16,240
encrypt things that's part of the
security model that needs to be

448
00:40:16,240 --> 00:40:20,479
disclosed but what you're bringing what
the thing that he brought up that i

449
00:40:20,480 --> 00:40:24,720
think is exceptionally interesting is
what happens if something status changes

450
00:40:24,720 --> 00:40:30,730
what if the jurisdictional definitions
change and something becomes Pio that

451
00:40:30,730 --> 00:40:33,730
was not before

452
00:40:37,740 --> 00:40:40,740
yeah

453
00:40:41,420 --> 00:40:48,410
around that is to consider everything
sensitive and treated as sensitive and

454
00:40:48,410 --> 00:40:53,069
let your let your sensitive definitions
for the Disclosure and protection of

455
00:40:53,069 --> 00:40:58,240
sensitive data a very conservative and
essentially treat everything is that's

456
00:40:58,240 --> 00:41:05,029
the safe approach alternatively you may
collect data that sensitive but not Pio

457
00:41:05,030 --> 00:41:09,240
Pio and not protected according to the
PIAA rules but at the point at which

458
00:41:09,240 --> 00:41:15,149
becomes it becomes you would need to
handle it essentially as a breach you

459
00:41:15,150 --> 00:41:18,150
would need to offer any assistance or
compensation to the user that you had

460
00:41:18,150 --> 00:41:24,470
agreed to offer you would need to put a
hold on that data possibly destroyed

461
00:41:24,470 --> 00:41:29,709
immediately and that's a situation that
nobody really wants to be and so the

462
00:41:29,710 --> 00:41:33,380
safe approach providers to say well
everything is we should we should

463
00:41:33,380 --> 00:41:38,910
protect everything is piiiii because
once we have enough of it will be I

464
00:41:38,910 --> 00:41:41,649
think this standard does handle the case
where somebody just kind of doesn't

465
00:41:41,650 --> 00:41:44,829
think about it and then realizes oh
shoot we've got we've got a whole bunch

466
00:41:44,829 --> 00:41:48,700
of Pir ends at that point you've reached
your disclosure agreement and the

467
00:41:48,700 --> 00:41:54,569
scandals what you doing that case that's
up to the user I mean this is consent

468
00:41:54,569 --> 00:41:58,450
based on the part of both the user and
the provider important thing to realize

469
00:41:58,450 --> 00:42:02,629
is that it's up to the provider to say
well okay this is the compensations

470
00:42:02,630 --> 00:42:06,079
we're offering in the event that are due
to the door entry that our agreement

471
00:42:06,079 --> 00:42:11,170
gets breached that's part of your risk
assessment do you want to do this or not

472
00:42:11,170 --> 00:42:17,859
so I think it's reasonable to say that
if if a service provider handles data

473
00:42:17,859 --> 00:42:23,348
poorly and winds up with Pio that they
did not protect PII they need to just

474
00:42:23,349 --> 00:42:26,349
handle it as a breach of the agreement

475
00:43:31,760 --> 00:43:44,710
that exists and is retained can be
assumed to be vulnerable to government

476
00:43:44,710 --> 00:43:50,980
superior and that needs to be part of
the language on disclosures I would like

477
00:43:50,980 --> 00:43:54,450
to see that included in the templates in
the template language that's used to

478
00:43:54,450 --> 00:43:59,430
disclose this because basically the only
thing that makes you safe from the

479
00:43:59,430 --> 00:44:03,730
government saying hey so about that you
know something's the only thing that

480
00:44:03,730 --> 00:44:10,680
really protects you from that is not
retaining or one-way encryption and then

481
00:44:10,680 --> 00:44:13,500
you know you still probably have to hand
over your hashes it just might not do

482
00:44:13,500 --> 00:44:20,430
anybody any good so that that definitely
doesn't need to be legitimately

483
00:44:20,430 --> 00:44:23,620
addressed because that's certainly part
of risk assessment that something that

484
00:44:23,620 --> 00:44:27,980
the that's something that any user needs
to be told it reminded of any time this

485
00:44:27,980 --> 00:44:32,130
is this is a choice they're making if
you're allowing us to retain something

486
00:44:32,130 --> 00:44:35,420
it definitely that means that any time
the government wants to know about that

487
00:44:35,420 --> 00:44:41,730
thing about you they can get whatever
we've got security models mitigate that

488
00:44:41,730 --> 00:44:50,590
if I'm one-way hashing on my content
with a reasonable reasonable algorithm

489
00:44:50,590 --> 00:44:55,320
than retrieval would be difficult and I
might decide that's unacceptable risk

490
00:44:55,320 --> 00:44:58,320
but I needed to say that's an acceptable
risk

491
00:45:23,099 --> 00:45:32,809
this is this could be this could apply
to anyone I suppose at this stage of

492
00:45:32,809 --> 00:45:35,769
things I'm not trying to enshrine this
into law anything that doesn't seem very

493
00:45:35,769 --> 00:45:44,029
voluntary to me at all I can definitely
see other applications for this in terms

494
00:45:44,029 --> 00:45:50,229
of disclosures of retain data certainly
a company could adopt the standard when

495
00:45:50,229 --> 00:45:56,149
dealing with employee information
internally companies could adopt it when

496
00:45:56,150 --> 00:45:59,930
dealing with go with information they
received from other companies and in

497
00:45:59,930 --> 00:46:03,390
that case the user is presumed to be the
company the entity acting as the company

498
00:46:03,390 --> 00:46:08,328
who consents in that case how do you
assess capacity to think an open

499
00:46:08,329 --> 00:46:11,329
question

500
00:47:36,859 --> 00:47:48,558
that's really interesting attention to
be disclosed an interesting story and

501
00:47:48,559 --> 00:47:52,839
what's mandatory for utilities there are
some things we r attention will be

502
00:47:52,839 --> 00:47:55,369
mandated break that down real quick and
then go ahead

503
00:47:55,369 --> 00:48:06,279
corporate world where you're involved in
litigation you have to turn over certain

504
00:48:06,279 --> 00:48:13,789
things to get a party and you may want
to get that you don't do that you get

505
00:48:13,789 --> 00:48:20,549
sanctions ourselves so we get out of
that if you have a written policy really

506
00:48:20,549 --> 00:48:28,989
hold are you working here but you have
to have a policy that there are

507
00:48:28,989 --> 00:48:32,670
situations where where police OC

508
00:48:33,380 --> 00:48:41,030
welfare organization and how many of us
have to go back then realized that got

509
00:48:41,030 --> 00:48:47,790
stuff from exactly how to individuals
notify individuals that they're into

510
00:48:47,790 --> 00:48:50,980
their going to retain communication
nobody really thinks about that you

511
00:48:50,980 --> 00:48:58,110
could adopt the standard personally the
comment previous I don't want to have

512
00:48:58,110 --> 00:49:04,390
people know how many people were later
one there's an easier way he walked

513
00:49:04,390 --> 00:49:07,890
around with a button camera I've got all
your bases I know how many people here

514
00:49:07,890 --> 00:49:15,150
have to do any plans to you know that
you're worrying about because there's

515
00:49:15,150 --> 00:49:22,320
other other avenues to get that
information packets you know you have to

516
00:49:22,320 --> 00:49:32,430
look at the whole picture made suits are
very secure the last

517
00:49:48,440 --> 00:49:56,200
I think that's a good idea standard
everyone understands the definition of

518
00:49:56,200 --> 00:49:59,310
this is available somewhere else and
everyone can be going be informed about

519
00:49:59,310 --> 00:50:03,349
this i think thats possible you must of
course include a link with everything

520
00:50:03,349 --> 00:50:06,790
that you disclose in this way to
somewhere where you can discover their

521
00:50:06,790 --> 00:50:11,910
definitions of these things easily and
they need to be people you double but

522
00:50:11,910 --> 00:50:19,190
yes I think that's shorthand essentially
well I seem to feel that my time this is

523
00:50:19,190 --> 00:50:41,920
a super fun thank you goes on video
selling them and although she is that

524
00:50:41,920 --> 00:50:42,569
correct

525
00:50:42,569 --> 00:50:47,140
$5 each you see that discounts like
crazy

526
00:50:47,140 --> 00:50:54,160
$5 per taco or $40 for the whole weekend
so if you're interested in any talks you

527
00:50:54,160 --> 00:50:59,710
miss you just want a copy of a good talk
like they all armchair now this one

528
00:50:59,710 --> 00:51:06,000
though he says they will be available on
the whole way later this afternoon if

529
00:51:06,000 --> 00:51:11,099
you are doing the application is ctfu
have about four hours left five hours

530
00:51:11,099 --> 00:51:15,030
left before they close up so finish up
your problems getting submitted get

531
00:51:15,030 --> 00:51:19,660
those points it to the top of the
scoreboard the mystery challenge is

532
00:51:19,660 --> 00:51:24,390
still running again I'm told that has
something to do with FM radio you guys

533
00:51:24,390 --> 00:51:31,618
are probably know more about them than I
so please win that contest for me other

534
00:51:31,619 --> 00:51:36,250
than that later tonight after we wrap up
the last talked at 5 p.m. we're all

535
00:51:36,250 --> 00:51:36,560
gonna

536
00:51:36,560 --> 00:51:42,240
head over to the 23 be shot down in
Fullerton its local local and clothes

537
00:51:42,240 --> 00:51:51,140
like ass Los Angeles space we're gonna
have a big BBQ the next speaker is

538
00:51:51,140 --> 00:51:55,410
actually from 23 be so he can he can
give you the address and all these

539
00:51:55,410 --> 00:51:59,549
things you guys have the internet I
usually say it's like a contest you can

540
00:51:59,550 --> 00:52:03,370
figure out how to get there then you're
welcome to join us at the afterparty if

541
00:52:03,370 --> 00:52:07,049
you're from out of town are you looking
for some rights shares I think around 5

542
00:52:07,050 --> 00:52:10,160
p.m. trying to figure that out so if
you're willing to give a ride are you

543
00:52:10,160 --> 00:52:11,490
looking for a ride

544
00:52:11,490 --> 00:52:16,959
meeting the lobby area at the pool area
and shot of people otherwise our next

545
00:52:16,960 --> 00:52:25,650
talk is gonna get started in a few
minutes and have a wonderful day

