1
00:00:01,410 --> 00:00:06,030
[Music]

2
00:00:08,160 --> 00:00:09,599
all right let's get started here uh

3
00:00:09,599 --> 00:00:11,200
before i get started i'd like to thank

4
00:00:11,200 --> 00:00:12,240
uh

5
00:00:12,240 --> 00:00:13,280
um

6
00:00:13,280 --> 00:00:16,239
a wasp um and i'm very proud to be a

7
00:00:16,239 --> 00:00:17,840
long-standing member of owasp it's a

8
00:00:17,840 --> 00:00:19,840
great organization uh thank you to the

9
00:00:19,840 --> 00:00:22,640
wasp programming team uh mark miller

10
00:00:22,640 --> 00:00:25,359
uh and the the rest of the folks that uh

11
00:00:25,359 --> 00:00:26,960
are facilitating this today thank you

12
00:00:26,960 --> 00:00:28,800
very much for inviting me

13
00:00:28,800 --> 00:00:30,480
uh my session is going to be on security

14
00:00:30,480 --> 00:00:33,760
chaos engineering uh and and how it can

15
00:00:33,760 --> 00:00:35,680
help turn the tide in a war on

16
00:00:35,680 --> 00:00:38,079
uncertainty and how we build

17
00:00:38,079 --> 00:00:40,079
uh modern software

18
00:00:40,079 --> 00:00:42,239
so uh and especially how we secure that

19
00:00:42,239 --> 00:00:44,239
modern software so uh right at the

20
00:00:44,239 --> 00:00:45,440
bottom you'll see

21
00:00:45,440 --> 00:00:46,960
my twitter information at aaron

22
00:00:46,960 --> 00:00:48,559
reinhardt please feel free to dm me

23
00:00:48,559 --> 00:00:49,760
anytime

24
00:00:49,760 --> 00:00:52,640
my names are open

25
00:00:53,120 --> 00:00:54,640
all right so i'm going to talk a little

26
00:00:54,640 --> 00:00:56,879
bit about what is chaos engineering i'm

27
00:00:56,879 --> 00:00:58,960
going to explain what its applications

28
00:00:58,960 --> 00:01:01,359
of to cyber security are and how to do

29
00:01:01,359 --> 00:01:02,160
that

30
00:01:02,160 --> 00:01:04,319
i'm going to talk a bit about

31
00:01:04,319 --> 00:01:06,320
also complexity modern software i'm

32
00:01:06,320 --> 00:01:08,320
going to talk about the use cases you

33
00:01:08,320 --> 00:01:10,400
can use chaos engineering for for

34
00:01:10,400 --> 00:01:11,680
security

35
00:01:11,680 --> 00:01:13,600
we're going to talk about a light

36
00:01:13,600 --> 00:01:16,159
experiment framework uh and i'll give an

37
00:01:16,159 --> 00:01:17,840
example a security kiosk engineering

38
00:01:17,840 --> 00:01:19,200
experiment

39
00:01:19,200 --> 00:01:20,000
um

40
00:01:20,000 --> 00:01:22,400
let's get started here

41
00:01:22,400 --> 00:01:26,720
okay oh yeah here's my background so um

42
00:01:26,720 --> 00:01:27,840
i'm the former chief of security

43
00:01:27,840 --> 00:01:29,920
architect united health group i'm uh but

44
00:01:29,920 --> 00:01:32,560
currently i'm the cto at barricadeal i

45
00:01:32,560 --> 00:01:34,000
started varica

46
00:01:34,000 --> 00:01:35,680
with casey rosenthal the creator of

47
00:01:35,680 --> 00:01:37,840
chaos engineering at netflix he is my

48
00:01:37,840 --> 00:01:39,040
co-founder

49
00:01:39,040 --> 00:01:41,360
i'm a frequent speaker and author on in

50
00:01:41,360 --> 00:01:43,759
in uh on the domains of chaos

51
00:01:43,759 --> 00:01:45,840
engineering uh in security

52
00:01:45,840 --> 00:01:48,479
um i'm the o'reilly uh i wrote i

53
00:01:48,479 --> 00:01:50,399
recently wrote the o'reilly book on

54
00:01:50,399 --> 00:01:52,159
security chaos engineering with kelly

55
00:01:52,159 --> 00:01:53,520
shortridge and we're actually writing

56
00:01:53,520 --> 00:01:56,000
the larger book now but i also helped

57
00:01:56,000 --> 00:01:58,159
write the main body of knowledge or

58
00:01:58,159 --> 00:02:01,040
chaos engineering with casey

59
00:02:01,040 --> 00:02:04,240
and let's get started

60
00:02:04,240 --> 00:02:05,759
the issue that we're trying to combat

61
00:02:05,759 --> 00:02:07,920
with chaos engineering uh especially for

62
00:02:07,920 --> 00:02:09,440
security um

63
00:02:09,440 --> 00:02:11,760
is uh is we're not we don't seem to be

64
00:02:11,760 --> 00:02:13,120
out of the outages breaches and

65
00:02:13,120 --> 00:02:14,640
incidents seem to be happening more

66
00:02:14,640 --> 00:02:17,120
often they seem to be getting larger

67
00:02:17,120 --> 00:02:21,040
uh and uh either way from a from a

68
00:02:21,040 --> 00:02:23,920
grade grade or a score uh we don't score

69
00:02:23,920 --> 00:02:25,520
card we don't seem to be getting much

70
00:02:25,520 --> 00:02:27,760
better at what we're doing

71
00:02:27,760 --> 00:02:30,000
um why is this i'll give some of my

72
00:02:30,000 --> 00:02:32,560
thesis and what i believe why this is

73
00:02:32,560 --> 00:02:34,640
happening um and what i think we might

74
00:02:34,640 --> 00:02:36,879
be doing wrong

75
00:02:36,879 --> 00:02:39,519
um the problem is is one of complexity

76
00:02:39,519 --> 00:02:41,599
is that our systems have evolved beyond

77
00:02:41,599 --> 00:02:43,360
our human ability to mentally model

78
00:02:43,360 --> 00:02:45,120
their behavior

79
00:02:45,120 --> 00:02:47,040
because of the size scale speed and

80
00:02:47,040 --> 00:02:48,959
complexity of modern software things

81
00:02:48,959 --> 00:02:50,879
like the public cloud once you start

82
00:02:50,879 --> 00:02:53,040
adopting like the public cloud devops

83
00:02:53,040 --> 00:02:56,000
cicd practices um

84
00:02:56,000 --> 00:02:59,360
you know uh and um you know adopting the

85
00:02:59,360 --> 00:03:02,080
microservice architecture models it's

86
00:03:02,080 --> 00:03:04,800
and our systems just are moving at such

87
00:03:04,800 --> 00:03:07,519
a pace uh and that they're in this the

88
00:03:07,519 --> 00:03:09,360
scale they operate is like nothing we've

89
00:03:09,360 --> 00:03:11,920
ever seen before it's very difficult for

90
00:03:11,920 --> 00:03:14,400
us as humans to mentally model what's

91
00:03:14,400 --> 00:03:16,800
going on in that post-deployment world

92
00:03:16,800 --> 00:03:18,879
so chaos engineering and security and

93
00:03:18,879 --> 00:03:21,280
its applications to security um are

94
00:03:21,280 --> 00:03:22,800
really what we're we're not really

95
00:03:22,800 --> 00:03:24,959
targeting the sort of the build process

96
00:03:24,959 --> 00:03:26,239
with our experiments it's the

97
00:03:26,239 --> 00:03:28,480
post-deployment world that is becoming

98
00:03:28,480 --> 00:03:30,080
overly complex

99
00:03:30,080 --> 00:03:32,000
and i'll explain more about that here in

100
00:03:32,000 --> 00:03:34,239
a minute but i just want to draw your

101
00:03:34,239 --> 00:03:36,720
attention to this little diagram on the

102
00:03:36,720 --> 00:03:38,720
left hand side of the slide you'll see a

103
00:03:38,720 --> 00:03:41,599
bunch of dots and that are connected um

104
00:03:41,599 --> 00:03:44,159
each dot represents a micro service okay

105
00:03:44,159 --> 00:03:46,159
what's happening is is that like when

106
00:03:46,159 --> 00:03:48,480
you have like a system with 10 micro

107
00:03:48,480 --> 00:03:50,000
services you don't actually have 10 of

108
00:03:50,000 --> 00:03:52,159
them you may have first and foremost you

109
00:03:52,159 --> 00:03:53,599
may have a different group of humans

110
00:03:53,599 --> 00:03:56,159
working on each microservice i

111
00:03:56,159 --> 00:03:57,840
you probably have at least three or four

112
00:03:57,840 --> 00:04:00,720
micro services uh

113
00:04:00,720 --> 00:04:02,319
three of each micro three or four of

114
00:04:02,319 --> 00:04:04,239
each microservice running for throughput

115
00:04:04,239 --> 00:04:06,000
reasons on top of that you might have

116
00:04:06,000 --> 00:04:08,239
older versions running uh to support

117
00:04:08,239 --> 00:04:09,920
other functionality and other services

118
00:04:09,920 --> 00:04:11,680
because microservices believe it or not

119
00:04:11,680 --> 00:04:14,000
are not independent they're dependent um

120
00:04:14,000 --> 00:04:15,599
so what happens is you may have at the

121
00:04:15,599 --> 00:04:17,600
gate you may have i don't know five to

122
00:04:17,600 --> 00:04:19,759
ten to fifteen of each service because

123
00:04:19,759 --> 00:04:21,519
you also may be uh doing blue green

124
00:04:21,519 --> 00:04:22,960
deployments and testing out new

125
00:04:22,960 --> 00:04:25,600
functionality and some services so it

126
00:04:25,600 --> 00:04:27,680
gets really complex really quickly the

127
00:04:27,680 --> 00:04:29,440
problem is is no group of humans

128
00:04:29,440 --> 00:04:31,360
anywhere in that model has a really good

129
00:04:31,360 --> 00:04:32,800
understanding of what the system looks

130
00:04:32,800 --> 00:04:34,800
like post-deployment and it's hard for

131
00:04:34,800 --> 00:04:37,600
us humans to to model that in our brains

132
00:04:37,600 --> 00:04:39,520
because we need to abstract and simplify

133
00:04:39,520 --> 00:04:40,479
so but

134
00:04:40,479 --> 00:04:42,080
this is the crux of the problem is the

135
00:04:42,080 --> 00:04:44,800
complexity is magnifying because of

136
00:04:44,800 --> 00:04:47,280
speed and scale

137
00:04:47,280 --> 00:04:48,880
so where does that complexity come from

138
00:04:48,880 --> 00:04:50,479
well um you know there are a couple

139
00:04:50,479 --> 00:04:52,160
different schools without here but there

140
00:04:52,160 --> 00:04:53,919
there's uh there's essential complexity

141
00:04:53,919 --> 00:04:56,000
uh comes from things like conway's law

142
00:04:56,000 --> 00:04:58,479
so the way that organizations design uh

143
00:04:58,479 --> 00:05:01,120
the way that like uh you know basically

144
00:05:01,120 --> 00:05:02,960
economist law states that organizations

145
00:05:02,960 --> 00:05:04,320
who are destined to design computer

146
00:05:04,320 --> 00:05:06,000
systems reflect the way they communicate

147
00:05:06,000 --> 00:05:07,280
as a business

148
00:05:07,280 --> 00:05:09,280
um that you can't really change that

149
00:05:09,280 --> 00:05:11,440
complexity comes from that from that

150
00:05:11,440 --> 00:05:13,520
venue from that uh that

151
00:05:13,520 --> 00:05:15,759
that avenue without uh changing the

152
00:05:15,759 --> 00:05:17,680
business itself the other is accidental

153
00:05:17,680 --> 00:05:19,600
complexity the way in methodologies and

154
00:05:19,600 --> 00:05:21,759
the way we build software

155
00:05:21,759 --> 00:05:24,240
but the problem with software is that it

156
00:05:24,240 --> 00:05:26,479
only increases the complexity

157
00:05:26,479 --> 00:05:27,919
so but all these other techniques you're

158
00:05:27,919 --> 00:05:29,680
seeing on here like you see devops

159
00:05:29,680 --> 00:05:31,039
continuous integration see cloud

160
00:05:31,039 --> 00:05:33,039
computing service meshes micro services

161
00:05:33,039 --> 00:05:35,120
auto scaling circuit breaker patterns

162
00:05:35,120 --> 00:05:36,560
these but you're like aaron these are

163
00:05:36,560 --> 00:05:37,919
all things that help us deliver value to

164
00:05:37,919 --> 00:05:39,759
market much faster yes but they also

165
00:05:39,759 --> 00:05:40,880
increase

166
00:05:40,880 --> 00:05:43,120
they also increases the uh our ability

167
00:05:43,120 --> 00:05:45,759
to to the scale and to change things

168
00:05:45,759 --> 00:05:47,840
quickly which also is inherently related

169
00:05:47,840 --> 00:05:49,440
to complexity

170
00:05:49,440 --> 00:05:50,840
and we'll talk more about this as we go

171
00:05:50,840 --> 00:05:54,880
on so uh news flash i love this slide

172
00:05:54,880 --> 00:05:56,560
the new osi model is software software

173
00:05:56,560 --> 00:05:58,639
self-sub software pretty much layer two

174
00:05:58,639 --> 00:06:00,240
and above is pretty much all software

175
00:06:00,240 --> 00:06:03,199
now uh and it officially has taken over

176
00:06:03,199 --> 00:06:04,960
the problem with that is it only ever

177
00:06:04,960 --> 00:06:06,479
increases the complexity

178
00:06:06,479 --> 00:06:08,240
you know so it let's say you have a

179
00:06:08,240 --> 00:06:10,720
complex software system right and say

180
00:06:10,720 --> 00:06:13,440
you wanted to make it simple well

181
00:06:13,440 --> 00:06:15,360
there's a relationship between

182
00:06:15,360 --> 00:06:19,199
changing something and um you know and

183
00:06:19,199 --> 00:06:21,039
it making it more complex the more you

184
00:06:21,039 --> 00:06:23,120
change the more you more more complexity

185
00:06:23,120 --> 00:06:26,080
you add uh and um you know if you wanted

186
00:06:26,080 --> 00:06:28,160
to make a complex system simple you have

187
00:06:28,160 --> 00:06:30,560
to change it to do that right so you're

188
00:06:30,560 --> 00:06:32,080
just really you're not actually

189
00:06:32,080 --> 00:06:33,199
simplifying you're just moving

190
00:06:33,199 --> 00:06:34,400
complexity around

191
00:06:34,400 --> 00:06:36,080
so chaos engineer what we're going to

192
00:06:36,080 --> 00:06:37,919
talk about is it's about navigating the

193
00:06:37,919 --> 00:06:39,280
complexity it's not about trying to

194
00:06:39,280 --> 00:06:41,680
simplify it

195
00:06:41,680 --> 00:06:43,440
so um and that's really what we're

196
00:06:43,440 --> 00:06:45,919
trying to do here uh is is and that's

197
00:06:45,919 --> 00:06:48,800
what so chaos engineering allows us to

198
00:06:48,800 --> 00:06:51,039
ensure that the system is actually

199
00:06:51,039 --> 00:06:54,319
reflecting what uh it actually exhibits

200
00:06:54,319 --> 00:06:56,319
the characteristics that we believe it's

201
00:06:56,319 --> 00:06:59,039
that we designed it to initially

202
00:06:59,039 --> 00:07:01,599
operate under

203
00:07:01,599 --> 00:07:04,560
so a good example would be um

204
00:07:04,560 --> 00:07:06,800
is every every company has a legacy

205
00:07:06,800 --> 00:07:08,720
system right some of the characteristics

206
00:07:08,720 --> 00:07:11,120
for legacy systems could be um

207
00:07:11,120 --> 00:07:12,560
you know that they're they're mostly

208
00:07:12,560 --> 00:07:14,080
known for being stable

209
00:07:14,080 --> 00:07:15,680
engineers are somewhat confident and

210
00:07:15,680 --> 00:07:17,840
competent on how to operate the system

211
00:07:17,840 --> 00:07:20,160
it rarely has outages or incidents or

212
00:07:20,160 --> 00:07:22,479
issues you know but it's legacy because

213
00:07:22,479 --> 00:07:24,160
it's business critical right i mean if

214
00:07:24,160 --> 00:07:25,440
we wanted

215
00:07:25,440 --> 00:07:27,280
we would get rid of it if it wasn't

216
00:07:27,280 --> 00:07:30,400
right well um the question i found

217
00:07:30,400 --> 00:07:32,080
i formed in my mind a few years ago is

218
00:07:32,080 --> 00:07:34,479
like was was was the legacy system

219
00:07:34,479 --> 00:07:37,199
always so stable well um

220
00:07:37,199 --> 00:07:39,440
they weren't right is is the answer is

221
00:07:39,440 --> 00:07:41,280
that we slowly learned about how the

222
00:07:41,280 --> 00:07:43,199
system actually worked versus how we

223
00:07:43,199 --> 00:07:44,720
thought it worked through a series of

224
00:07:44,720 --> 00:07:47,120
unforeseen events surprises uh there

225
00:07:47,120 --> 00:07:48,479
were surprises because we would have

226
00:07:48,479 --> 00:07:50,400
known surprises means incidents and

227
00:07:50,400 --> 00:07:52,560
outages if we weren't surprises we would

228
00:07:52,560 --> 00:07:54,160
have just fixed them right

229
00:07:54,160 --> 00:07:55,680
well um

230
00:07:55,680 --> 00:07:56,879
well

231
00:07:56,879 --> 00:07:58,879
learning so like learning learning about

232
00:07:58,879 --> 00:08:01,360
how the system actually works uh versus

233
00:08:01,360 --> 00:08:03,280
how we thought it works uh through

234
00:08:03,280 --> 00:08:04,960
incidents and outages is a very

235
00:08:04,960 --> 00:08:07,199
expensive and counterproductive exercise

236
00:08:07,199 --> 00:08:09,599
yes slowly we learned uh that the system

237
00:08:09,599 --> 00:08:11,039
worked a different way than we thought

238
00:08:11,039 --> 00:08:12,720
we were able to fix it recalibrate it

239
00:08:12,720 --> 00:08:14,479
and we over time we developed a better

240
00:08:14,479 --> 00:08:16,240
understanding but that process

241
00:08:16,240 --> 00:08:18,080
encountered a lot of pain a lot of pain

242
00:08:18,080 --> 00:08:19,360
for customers a lot of pain for the

243
00:08:19,360 --> 00:08:21,280
engineers so what you can think about is

244
00:08:21,280 --> 00:08:23,520
chaos engineering chaos engineering is a

245
00:08:23,520 --> 00:08:26,400
proactive exercise of of introducing

246
00:08:26,400 --> 00:08:27,520
uh

247
00:08:27,520 --> 00:08:30,960
you know i'd say um

248
00:08:30,960 --> 00:08:32,479
so it's a proactive exercise of

249
00:08:32,479 --> 00:08:34,000
introducing turbulent conditions into a

250
00:08:34,000 --> 00:08:35,360
system or service

251
00:08:35,360 --> 00:08:36,799
try to understand the conditions by

252
00:08:36,799 --> 00:08:39,039
which it will fail before it actually

253
00:08:39,039 --> 00:08:42,159
fails um and so what's great about chaos

254
00:08:42,159 --> 00:08:43,360
engineering is we're not actually

255
00:08:43,360 --> 00:08:45,360
causing chaos what we're trying to do is

256
00:08:45,360 --> 00:08:48,080
proactively ensure that the system act

257
00:08:48,080 --> 00:08:49,360
can actually

258
00:08:49,360 --> 00:08:51,360
um do what it's supposed to do under the

259
00:08:51,360 --> 00:08:53,279
conditions we design it for if you think

260
00:08:53,279 --> 00:08:55,760
about things like failover logic or

261
00:08:55,760 --> 00:08:57,920
circuit breakers or um

262
00:08:57,920 --> 00:08:59,120
you know

263
00:08:59,120 --> 00:09:00,240
uh

264
00:09:00,240 --> 00:09:01,600
you know yeah

265
00:09:01,600 --> 00:09:02,800
fillers or circuit breakers even

266
00:09:02,800 --> 00:09:05,120
security controls though those code

267
00:09:05,120 --> 00:09:07,839
paths rarely ever get exercised until

268
00:09:07,839 --> 00:09:09,839
they're actually needed

269
00:09:09,839 --> 00:09:11,920
and when they're needed it's usually

270
00:09:11,920 --> 00:09:13,760
some sort of catastrophic event the

271
00:09:13,760 --> 00:09:16,080
problem is is that our systems the rest

272
00:09:16,080 --> 00:09:17,680
of the system has changed a lot since we

273
00:09:17,680 --> 00:09:19,440
originally designed those code pass and

274
00:09:19,440 --> 00:09:21,600
those code paths might not

275
00:09:21,600 --> 00:09:22,959
work uh the way we think they're

276
00:09:22,959 --> 00:09:25,200
supposed to work when we need them

277
00:09:25,200 --> 00:09:26,959
same thing with security we often build

278
00:09:26,959 --> 00:09:29,360
uh detection and prevention types of

279
00:09:29,360 --> 00:09:31,279
controls and capabilities under a

280
00:09:31,279 --> 00:09:33,680
certain context understanding

281
00:09:33,680 --> 00:09:35,519
but the system often changes a lot

282
00:09:35,519 --> 00:09:37,839
before those controls actually come into

283
00:09:37,839 --> 00:09:39,519
use so what we're trying to do is

284
00:09:39,519 --> 00:09:42,320
proactively ensure the system still does

285
00:09:42,320 --> 00:09:44,240
the things it's supposed to instead of

286
00:09:44,240 --> 00:09:46,320
learning about learning that we didn't

287
00:09:46,320 --> 00:09:47,839
understand the system through an outage

288
00:09:47,839 --> 00:09:50,560
or a security incident

289
00:09:50,560 --> 00:09:52,320
um part of this problem is that system

290
00:09:52,320 --> 00:09:54,240
engineering is a messy exercise

291
00:09:54,240 --> 00:09:55,680
okay in the beginning in the beginning

292
00:09:55,680 --> 00:09:56,959
we love to

293
00:09:56,959 --> 00:09:59,120
um yeah we love to think the system is

294
00:09:59,120 --> 00:10:00,560
very simple right we've got a plan we've

295
00:10:00,560 --> 00:10:02,560
got our time we got the resources we've

296
00:10:02,560 --> 00:10:03,279
got

297
00:10:03,279 --> 00:10:05,120
the uh the engineering team put together

298
00:10:05,120 --> 00:10:07,839
we've got our doctor images our secrets

299
00:10:07,839 --> 00:10:09,360
taken care of again so we've got

300
00:10:09,360 --> 00:10:10,959
different environments and of course we

301
00:10:10,959 --> 00:10:14,640
have a beautiful 3d aws diagram well in

302
00:10:14,640 --> 00:10:16,880
reality our system never looks like this

303
00:10:16,880 --> 00:10:19,760
okay uh it's um because after a few

304
00:10:19,760 --> 00:10:21,680
weeks every month we start learning

305
00:10:21,680 --> 00:10:23,120
about what we didn't actually know about

306
00:10:23,120 --> 00:10:25,760
the system right uh after uh you know

307
00:10:25,760 --> 00:10:28,320
after the first week uh we had an outage

308
00:10:28,320 --> 00:10:29,920
on the payments api so we have the hard

309
00:10:29,920 --> 00:10:32,000
coded token a marketing team comes down

310
00:10:32,000 --> 00:10:33,519
and says we have to refactor the pricing

311
00:10:33,519 --> 00:10:36,079
modules we refactor right we go from

312
00:10:36,079 --> 00:10:38,240
incident to incident to incident

313
00:10:38,240 --> 00:10:40,000
but these are what these incidents are

314
00:10:40,000 --> 00:10:42,320
informing us is that that difference

315
00:10:42,320 --> 00:10:43,279
between

316
00:10:43,279 --> 00:10:44,959
what we how we thought the system worked

317
00:10:44,959 --> 00:10:46,800
and how it actually worked

318
00:10:46,800 --> 00:10:49,120
and then over time uh it just continues

319
00:10:49,120 --> 00:10:51,040
to magnify in our system what they call

320
00:10:51,040 --> 00:10:52,720
what city decker calls this he's one of

321
00:10:52,720 --> 00:10:54,880
the world's experts in in complex

322
00:10:54,880 --> 00:10:56,480
systems uh in terms of safety

323
00:10:56,480 --> 00:10:58,240
engineering he likes to call this the

324
00:10:58,240 --> 00:11:00,079
drift into failure to drift into the

325
00:11:00,079 --> 00:11:03,279
unknown in a complex system

326
00:11:03,279 --> 00:11:05,360
so in the end the summary is is that our

327
00:11:05,360 --> 00:11:06,880
systems have become more complex and

328
00:11:06,880 --> 00:11:08,320
messy than we originally remember them

329
00:11:08,320 --> 00:11:10,160
being

330
00:11:10,160 --> 00:11:11,120
all right so what does all this have to

331
00:11:11,120 --> 00:11:12,560
do with security i'm getting there i'm

332
00:11:12,560 --> 00:11:14,480
getting there

333
00:11:14,480 --> 00:11:16,880
okay so security is a context dependent

334
00:11:16,880 --> 00:11:18,640
discipline so what i mean by that is is

335
00:11:18,640 --> 00:11:20,480
that so i've been a builder most of my

336
00:11:20,480 --> 00:11:22,000
career software engineer predominantly

337
00:11:22,000 --> 00:11:23,200
most of my career before i got into

338
00:11:23,200 --> 00:11:25,519
security uh and so as an engineer i need

339
00:11:25,519 --> 00:11:26,720
the flexibility and convenience to

340
00:11:26,720 --> 00:11:28,320
change something that's my job i'm

341
00:11:28,320 --> 00:11:30,160
trying to so i'm constantly trying to

342
00:11:30,160 --> 00:11:31,200
change something because i'm trying to

343
00:11:31,200 --> 00:11:33,760
deliver value to market via product you

344
00:11:33,760 --> 00:11:35,440
know delivery to customer right so

345
00:11:35,440 --> 00:11:37,279
constantly trying to deliver on that

346
00:11:37,279 --> 00:11:39,519
promise you know so i'm constantly

347
00:11:39,519 --> 00:11:41,440
building and delivering uh you know

348
00:11:41,440 --> 00:11:44,880
those uh that that value uh but security

349
00:11:44,880 --> 00:11:46,720
is a context dependent this one you need

350
00:11:46,720 --> 00:11:48,640
to know what you're trying to secure in

351
00:11:48,640 --> 00:11:50,480
order to know in order to you know what

352
00:11:50,480 --> 00:11:52,240
needs to be secured about it so we're

353
00:11:52,240 --> 00:11:53,680
kind of forced into a stateful

354
00:11:53,680 --> 00:11:55,279
understanding of a thing in order to

355
00:11:55,279 --> 00:11:57,279
actually manifest the security what

356
00:11:57,279 --> 00:11:59,440
happens is is that uh what's happening

357
00:11:59,440 --> 00:12:01,120
is we're starting to see a

358
00:12:01,120 --> 00:12:03,200
drift issue between the rate of change

359
00:12:03,200 --> 00:12:05,440
of the actual system and the security

360
00:12:05,440 --> 00:12:08,880
being able to maintain alignment with um

361
00:12:08,880 --> 00:12:11,120
with uh its original context and

362
00:12:11,120 --> 00:12:13,200
understanding with chaos engineering

363
00:12:13,200 --> 00:12:14,639
especially security we're introducing

364
00:12:14,639 --> 00:12:16,240
the conditions that our controls were

365
00:12:16,240 --> 00:12:17,839
originally designed for

366
00:12:17,839 --> 00:12:20,959
to make sure that we can catch uh uh

367
00:12:20,959 --> 00:12:23,600
uh to make sure we can catch the drift

368
00:12:23,600 --> 00:12:25,360
uh out of effectiveness of the control

369
00:12:25,360 --> 00:12:28,160
before it actually uh ford adversary can

370
00:12:28,160 --> 00:12:29,360
take advantage of the fact that we

371
00:12:29,360 --> 00:12:31,760
didn't uh we didn't realize that

372
00:12:31,760 --> 00:12:34,560
security control needed recalibration uh

373
00:12:34,560 --> 00:12:36,000
and um

374
00:12:36,000 --> 00:12:38,560
so that's that's kind of the crux here

375
00:12:38,560 --> 00:12:41,440
um chaos engineering uh so in terms of

376
00:12:41,440 --> 00:12:44,079
like instrumentation for software uh

377
00:12:44,079 --> 00:12:46,320
casey and i like to sort of um

378
00:12:46,320 --> 00:12:48,560
uh refer to uh break break the down and

379
00:12:48,560 --> 00:12:50,560
sort of two domains there's testing and

380
00:12:50,560 --> 00:12:52,800
there's experimentation experimentation

381
00:12:52,800 --> 00:12:54,079
so testing is a verification of

382
00:12:54,079 --> 00:12:55,279
validation of something you already know

383
00:12:55,279 --> 00:12:57,360
to be true or false you know what you're

384
00:12:57,360 --> 00:12:59,200
looking for before you go looking for

385
00:12:59,200 --> 00:13:00,880
our world that's like a cve that's an

386
00:13:00,880 --> 00:13:02,720
attack pattern that's a signature things

387
00:13:02,720 --> 00:13:05,440
like that where experimentation we're

388
00:13:05,440 --> 00:13:07,360
trying to derive new information that we

389
00:13:07,360 --> 00:13:09,600
previously did not know and this is

390
00:13:09,600 --> 00:13:11,120
where chaos engineering fits in we're

391
00:13:11,120 --> 00:13:14,160
not trying to uh do a simple uh test

392
00:13:14,160 --> 00:13:16,560
what we're trying to do is uh experiment

393
00:13:16,560 --> 00:13:18,880
and i'm trying to generate new context

394
00:13:18,880 --> 00:13:20,880
understanding about how the system is

395
00:13:20,880 --> 00:13:23,680
operating post deployment

396
00:13:23,680 --> 00:13:25,279
so how do we till we discover when our

397
00:13:25,279 --> 00:13:26,399
security measures fail well let's

398
00:13:26,399 --> 00:13:27,920
typically do some sort of footstep in

399
00:13:27,920 --> 00:13:30,880
the sand some observable event um some

400
00:13:30,880 --> 00:13:32,800
context the computer tells us meaning it

401
00:13:32,800 --> 00:13:34,720
could be a long event it could be an

402
00:13:34,720 --> 00:13:38,000
alert uh it could be um and usually the

403
00:13:38,000 --> 00:13:40,079
problem is is that we often only

404
00:13:40,079 --> 00:13:42,320
discover that our security measures were

405
00:13:42,320 --> 00:13:43,600
not effective and when there's a

406
00:13:43,600 --> 00:13:44,880
security incident

407
00:13:44,880 --> 00:13:46,639
but unfortunately security incidents are

408
00:13:46,639 --> 00:13:48,000
not an effective measure detection

409
00:13:48,000 --> 00:13:50,560
because it's often too late

410
00:13:50,560 --> 00:13:51,839
so what happens during a security

411
00:13:51,839 --> 00:13:54,160
incident okay well shorthand people

412
00:13:54,160 --> 00:13:56,880
freak out you know um and this is not a

413
00:13:56,880 --> 00:13:58,800
good learning environment for especially

414
00:13:58,800 --> 00:14:00,720
for the engineers right

415
00:14:00,720 --> 00:14:02,720
is that so we don't do chaos engineering

416
00:14:02,720 --> 00:14:03,839
here right where there's an active

417
00:14:03,839 --> 00:14:06,160
incident or an issue um

418
00:14:06,160 --> 00:14:08,560
we do chaos engineering when there is no

419
00:14:08,560 --> 00:14:11,120
problem to proactively understand so we

420
00:14:11,120 --> 00:14:12,560
don't in so we don't end up in this

421
00:14:12,560 --> 00:14:14,480
situation we do it here right we

422
00:14:14,480 --> 00:14:15,760
proactively try to build an

423
00:14:15,760 --> 00:14:17,680
understanding um

424
00:14:17,680 --> 00:14:19,519
about whether or not the security still

425
00:14:19,519 --> 00:14:21,680
does what it's supposed to do before uh

426
00:14:21,680 --> 00:14:23,440
before we run into situations where

427
00:14:23,440 --> 00:14:25,040
we're freaking out

428
00:14:25,040 --> 00:14:26,240
it'll make more sense when i go through

429
00:14:26,240 --> 00:14:28,079
a couple examples

430
00:14:28,079 --> 00:14:30,000
so chaos engineering so the netflix

431
00:14:30,000 --> 00:14:31,600
definition of chaos engineering was the

432
00:14:31,600 --> 00:14:33,279
discipline of experimentation on

433
00:14:33,279 --> 00:14:34,959
distributed systems or to build

434
00:14:34,959 --> 00:14:36,320
confidence in the system's ability to

435
00:14:36,320 --> 00:14:38,160
withstand turbulent conditions or like i

436
00:14:38,160 --> 00:14:39,600
said before it's the practice of

437
00:14:39,600 --> 00:14:42,079
proactively introducing uh failure

438
00:14:42,079 --> 00:14:44,000
conditions or faults into a system or

439
00:14:44,000 --> 00:14:45,680
service to try to understand the

440
00:14:45,680 --> 00:14:46,959
conditions by which the system or

441
00:14:46,959 --> 00:14:49,279
service will fail before it actually

442
00:14:49,279 --> 00:14:51,519
fails instead of chasing outages we're

443
00:14:51,519 --> 00:14:53,279
proactively just ensuring the system

444
00:14:53,279 --> 00:14:55,199
does what it was originally designed to

445
00:14:55,199 --> 00:14:57,359
do

446
00:14:57,440 --> 00:15:00,000
um so chaos engineering very important

447
00:15:00,000 --> 00:15:01,360
it's not about breaking things in

448
00:15:01,360 --> 00:15:02,880
production it's not about breaking

449
00:15:02,880 --> 00:15:06,079
things don't don't don't don't uh

450
00:15:06,079 --> 00:15:08,000
go home go back to your job at work and

451
00:15:08,000 --> 00:15:09,199
say you wanna do chaos engineering to

452
00:15:09,199 --> 00:15:10,480
break stuff i'm pretty sure you get

453
00:15:10,480 --> 00:15:14,000
fired so it's about proactively um

454
00:15:14,000 --> 00:15:14,880
uh

455
00:15:14,880 --> 00:15:16,560
fixing things we're trying to fix things

456
00:15:16,560 --> 00:15:18,639
right we're an established order not

457
00:15:18,639 --> 00:15:20,800
create chaos

458
00:15:20,800 --> 00:15:22,240
so there's several books on chaos

459
00:15:22,240 --> 00:15:24,079
engineering i mentioned a couple of them

460
00:15:24,079 --> 00:15:25,760
earlier actually there'll be links to

461
00:15:25,760 --> 00:15:27,839
download them i highly recommend you

462
00:15:27,839 --> 00:15:28,959
download them both now if you're

463
00:15:28,959 --> 00:15:31,199
watching this because i'm not sure i

464
00:15:31,199 --> 00:15:32,959
think one of uh both of these i think

465
00:15:32,959 --> 00:15:34,880
will expire soon on the free download

466
00:15:34,880 --> 00:15:36,800
you'll only sponsor the book forever you

467
00:15:36,800 --> 00:15:38,800
can't sponsor it forever so

468
00:15:38,800 --> 00:15:40,399
highly recommend you go get that book

469
00:15:40,399 --> 00:15:42,880
the links will be at the end

470
00:15:42,880 --> 00:15:44,800
so um security chaos engineering well

471
00:15:44,800 --> 00:15:46,160
news flash it's not a whole lot

472
00:15:46,160 --> 00:15:48,480
different than chaos engineering

473
00:15:48,480 --> 00:15:51,199
um and so as so one before i sort of

474
00:15:51,199 --> 00:15:53,040
explain security kiosk engineering i

475
00:15:53,040 --> 00:15:55,440
want to remind um

476
00:15:55,440 --> 00:15:57,360
everyone of how i see software

477
00:15:57,360 --> 00:15:58,959
engineering is that engineers don't

478
00:15:58,959 --> 00:16:00,240
believe

479
00:16:00,240 --> 00:16:01,600
well we don't believe in two things we

480
00:16:01,600 --> 00:16:03,279
don't believe in hope and luck

481
00:16:03,279 --> 00:16:05,040
and we believe in good instrumentation

482
00:16:05,040 --> 00:16:07,040
data and feedback loops that's that's

483
00:16:07,040 --> 00:16:08,720
our that's what we believe in i mean

484
00:16:08,720 --> 00:16:10,560
hope and luck worked in star wars it

485
00:16:10,560 --> 00:16:12,880
doesn't really work in engineering

486
00:16:12,880 --> 00:16:14,720
okay what we're trying to establish the

487
00:16:14,720 --> 00:16:17,120
security kiosk engineer is understand

488
00:16:17,120 --> 00:16:19,360
excuse me

489
00:16:19,360 --> 00:16:21,680
where are security gaps and needs for

490
00:16:21,680 --> 00:16:24,320
recalibration are before an adversary

491
00:16:24,320 --> 00:16:26,800
can take advantage of them

492
00:16:26,800 --> 00:16:29,360
so um a use case uh

493
00:16:29,360 --> 00:16:30,880
that i'd like to talk about uh for

494
00:16:30,880 --> 00:16:32,240
security chaos engineer will be instant

495
00:16:32,240 --> 00:16:34,399
response i'm gonna cover a few other use

496
00:16:34,399 --> 00:16:37,600
cases as well but the main problem with

497
00:16:37,600 --> 00:16:39,839
instant response itself is that it's a

498
00:16:39,839 --> 00:16:41,120
response

499
00:16:41,120 --> 00:16:43,199
so um before i do that i'm just gonna

500
00:16:43,199 --> 00:16:44,399
explain a couple of use cases you can

501
00:16:44,399 --> 00:16:45,440
use it for

502
00:16:45,440 --> 00:16:47,120
uh you can use

503
00:16:47,120 --> 00:16:48,800
oh by the way all these use cases are

504
00:16:48,800 --> 00:16:50,560
well documented in this book and they're

505
00:16:50,560 --> 00:16:52,560
gonna be expanded on the larger book uh

506
00:16:52,560 --> 00:16:54,880
so um you can you can dive into the

507
00:16:54,880 --> 00:16:56,639
detail later if you would like

508
00:16:56,639 --> 00:16:57,600
um

509
00:16:57,600 --> 00:16:58,800
uh where i started with chaos

510
00:16:58,800 --> 00:17:00,480
engineering for security would be uh

511
00:17:00,480 --> 00:17:02,720
security control validation i was trying

512
00:17:02,720 --> 00:17:04,160
as the chief security architect i wanted

513
00:17:04,160 --> 00:17:06,880
to ensure that post deployment uh the

514
00:17:06,880 --> 00:17:09,199
security mechanisms and controls and

515
00:17:09,199 --> 00:17:10,480
things like that were actually being

516
00:17:10,480 --> 00:17:12,240
implemented correctly because

517
00:17:12,240 --> 00:17:13,520
configuration matters how it's

518
00:17:13,520 --> 00:17:15,520
configured how it's placed how many of

519
00:17:15,520 --> 00:17:18,079
them where they are you know and uh

520
00:17:18,079 --> 00:17:20,079
there's too much subjective process and

521
00:17:20,079 --> 00:17:22,240
assessment between me and the computer i

522
00:17:22,240 --> 00:17:23,919
need to ask the computer a question and

523
00:17:23,919 --> 00:17:25,359
instrumentation is a great way to do

524
00:17:25,359 --> 00:17:28,079
that so i created a new methodology uh

525
00:17:28,079 --> 00:17:29,520
with uh

526
00:17:29,520 --> 00:17:32,160
and a new open source tool that actually

527
00:17:32,160 --> 00:17:33,520
allowed me to do that i'll explain that

528
00:17:33,520 --> 00:17:36,320
in a minute um another great uh use case

529
00:17:36,320 --> 00:17:38,640
is security observability uh

530
00:17:38,640 --> 00:17:39,760
it's one of the biggest problems in

531
00:17:39,760 --> 00:17:42,480
software security in my opinion um

532
00:17:42,480 --> 00:17:44,400
is that it helps you because you're

533
00:17:44,400 --> 00:17:48,240
proactively introducing uh conditions uh

534
00:17:48,240 --> 00:17:50,160
that should security control should fire

535
00:17:50,160 --> 00:17:52,240
on you actually um you can get a better

536
00:17:52,240 --> 00:17:53,679
understanding of how

537
00:17:53,679 --> 00:17:56,080
uh of what the log data makes sense that

538
00:17:56,080 --> 00:17:58,080
you got from the control did like if

539
00:17:58,080 --> 00:17:59,520
this were a real incident do we have

540
00:17:59,520 --> 00:18:01,280
enough log information to correlate

541
00:18:01,280 --> 00:18:03,760
alerts didn't correlate an alert did we

542
00:18:03,760 --> 00:18:06,000
understand what the alerts uh or did the

543
00:18:06,000 --> 00:18:08,160
uh stock analyst uh understand the

544
00:18:08,160 --> 00:18:10,240
alerts and what to do with it uh another

545
00:18:10,240 --> 00:18:11,600
great

546
00:18:11,600 --> 00:18:13,919
use case for is compliance

547
00:18:13,919 --> 00:18:15,520
is compliance every chaos experiment

548
00:18:15,520 --> 00:18:17,440
whether it's availability or stability

549
00:18:17,440 --> 00:18:19,520
based or security based has compliance

550
00:18:19,520 --> 00:18:21,120
values so don't make sure you just keep

551
00:18:21,120 --> 00:18:23,280
the output in high integrity way

552
00:18:23,280 --> 00:18:24,720
and the label with right control

553
00:18:24,720 --> 00:18:26,799
framework

554
00:18:26,799 --> 00:18:28,960
so back to its response so

555
00:18:28,960 --> 00:18:30,559
the problem with the into response is

556
00:18:30,559 --> 00:18:32,480
the response and the security incidents

557
00:18:32,480 --> 00:18:35,520
are somewhat subjective no matter

558
00:18:35,520 --> 00:18:37,919
how much money you spend how many people

559
00:18:37,919 --> 00:18:39,600
you have in security

560
00:18:39,600 --> 00:18:41,520
you know um but

561
00:18:41,520 --> 00:18:43,039
you still don't know a lot of things you

562
00:18:43,039 --> 00:18:44,400
don't know where it's going to happen

563
00:18:44,400 --> 00:18:46,080
why it's happening who's trying to uh

564
00:18:46,080 --> 00:18:47,919
who's trying to get in uh how they're

565
00:18:47,919 --> 00:18:49,039
gonna get it and what they're trying to

566
00:18:49,039 --> 00:18:51,440
achieve right um but what's it what's

567
00:18:51,440 --> 00:18:52,880
great about chaos engineering is we're

568
00:18:52,880 --> 00:18:54,160
proactively

569
00:18:54,160 --> 00:18:56,160
introducing the conditions ourselves

570
00:18:56,160 --> 00:18:58,720
it's managed right we're introducing um

571
00:18:58,720 --> 00:19:00,480
a misconfiguration of some kind and we

572
00:19:00,480 --> 00:19:01,840
can watch it because now we're not

573
00:19:01,840 --> 00:19:03,200
waiting for something to happen and try

574
00:19:03,200 --> 00:19:06,240
to figure out do we uh you know uh if

575
00:19:06,240 --> 00:19:07,919
we're prepared or not because you know

576
00:19:07,919 --> 00:19:09,120
like that's

577
00:19:09,120 --> 00:19:11,360
um that's a very subjective way of doing

578
00:19:11,360 --> 00:19:12,960
it what we're doing is introducing a

579
00:19:12,960 --> 00:19:14,880
objective signal in the system and

580
00:19:14,880 --> 00:19:17,120
watching it so you know we can when we

581
00:19:17,120 --> 00:19:18,320
start doing introducing these

582
00:19:18,320 --> 00:19:20,400
experiments we can now because we know

583
00:19:20,400 --> 00:19:22,559
the point started right so we can look

584
00:19:22,559 --> 00:19:24,240
to see whether technology was effective

585
00:19:24,240 --> 00:19:26,400
doing we're supposed to do we can uh we

586
00:19:26,400 --> 00:19:28,960
can uh manage and measure things like uh

587
00:19:28,960 --> 00:19:29,760
did

588
00:19:29,760 --> 00:19:31,200
the runbooks correct do we have enough

589
00:19:31,200 --> 00:19:33,760
people on call did they know what to do

590
00:19:33,760 --> 00:19:36,160
did we follow the process correctly um

591
00:19:36,160 --> 00:19:37,760
and uh um

592
00:19:37,760 --> 00:19:39,039
that could be a great and highly

593
00:19:39,039 --> 00:19:41,280
valuable feedback for uh sharpening the

594
00:19:41,280 --> 00:19:43,840
instant response process

595
00:19:43,840 --> 00:19:45,679
so a chaos linger chaosing was the first

596
00:19:45,679 --> 00:19:48,000
ever application of netflix's chaos

597
00:19:48,000 --> 00:19:49,440
engineering to cyber security it is now

598
00:19:49,440 --> 00:19:51,600
a deprecated tool out there on github

599
00:19:51,600 --> 00:19:54,240
but um there uh it represents a

600
00:19:54,240 --> 00:19:55,360
framework on actually how to write

601
00:19:55,360 --> 00:19:56,960
security chaos experiments through a

602
00:19:56,960 --> 00:19:59,760
series of python based lambdas uh and

603
00:19:59,760 --> 00:20:01,760
it's fairly easy to understand the

604
00:20:01,760 --> 00:20:03,679
framework if you check it out it's also

605
00:20:03,679 --> 00:20:07,360
documented in the o'reilly report

606
00:20:07,360 --> 00:20:08,960
so uh the main example when we open

607
00:20:08,960 --> 00:20:12,080
source chaos slinger uh was a uh we

608
00:20:12,080 --> 00:20:13,440
wrote several experiments for

609
00:20:13,440 --> 00:20:15,600
chaoslinger but the uh one of the main

610
00:20:15,600 --> 00:20:17,039
example we needed an example that a lot

611
00:20:17,039 --> 00:20:18,559
of whether you're a software engineer a

612
00:20:18,559 --> 00:20:21,520
network engineer a system engineer uh an

613
00:20:21,520 --> 00:20:23,280
executive that you could understand what

614
00:20:23,280 --> 00:20:25,440
we're trying to do uh and the value

615
00:20:25,440 --> 00:20:27,120
we're trying to achieve and for some odd

616
00:20:27,120 --> 00:20:28,960
reason misconfigured or on our

617
00:20:28,960 --> 00:20:31,200
unauthorized sport changes steep skills

618
00:20:31,200 --> 00:20:33,520
still happen a lot of uh

619
00:20:33,520 --> 00:20:35,760
a lot of the time even in the cloud so

620
00:20:35,760 --> 00:20:38,000
um what we did was united health group

621
00:20:38,000 --> 00:20:39,840
when i was there we were we were very

622
00:20:39,840 --> 00:20:42,880
new to the aws and and what we um what

623
00:20:42,880 --> 00:20:44,880
we started doing this is

624
00:20:44,880 --> 00:20:46,640
so our

625
00:20:46,640 --> 00:20:48,720
assumption is is that when we introduced

626
00:20:48,720 --> 00:20:50,320
a misconfigured unauthorized sport

627
00:20:50,320 --> 00:20:52,159
change into our aws instances we

628
00:20:52,159 --> 00:20:54,080
expected the firewall to immediately

629
00:20:54,080 --> 00:20:55,679
kind of detect and block that kind of

630
00:20:55,679 --> 00:20:57,679
activity and be a non-issue so what we

631
00:20:57,679 --> 00:20:59,679
did was is that we would

632
00:20:59,679 --> 00:21:01,760
sort of randomly select a

633
00:21:01,760 --> 00:21:03,679
through a series of aw aws tags you can

634
00:21:03,679 --> 00:21:05,200
see how this works on the repo for

635
00:21:05,200 --> 00:21:08,000
chaoslinger on github but it will select

636
00:21:08,000 --> 00:21:10,640
a series of tags to be opt-in or opt-out

637
00:21:10,640 --> 00:21:12,799
uh if it's opted in that means it's you

638
00:21:12,799 --> 00:21:14,080
that we were able to actually do the

639
00:21:14,080 --> 00:21:16,480
experiment on that instance but we would

640
00:21:16,480 --> 00:21:18,000
open or close a port that wasn't already

641
00:21:18,000 --> 00:21:20,720
over closed what we're trying to do uh

642
00:21:20,720 --> 00:21:23,440
is uh you know is sort of trigger to

643
00:21:23,440 --> 00:21:24,880
make make sure that the firewall

644
00:21:24,880 --> 00:21:27,200
actually was detecting uh um and

645
00:21:27,200 --> 00:21:28,320
preventing what we thought it was

646
00:21:28,320 --> 00:21:30,240
supposed to prevent and detect what

647
00:21:30,240 --> 00:21:32,159
actually happened was it only worked

648
00:21:32,159 --> 00:21:34,640
about 60 of the time uh is that what we

649
00:21:34,640 --> 00:21:35,679
learned was actually there was a

650
00:21:35,679 --> 00:21:37,440
configuration drift issue between how

651
00:21:37,440 --> 00:21:38,880
our non-commercial and our commercial

652
00:21:38,880 --> 00:21:41,520
software aws environments easy remember

653
00:21:41,520 --> 00:21:43,360
there was no incident there was no war

654
00:21:43,360 --> 00:21:45,679
room there was no uh nobody's freaking

655
00:21:45,679 --> 00:21:47,840
out uh we proactively realized we had a

656
00:21:47,840 --> 00:21:50,159
drift issue we were able to fix it right

657
00:21:50,159 --> 00:21:51,679
so the second thing we learned was the

658
00:21:51,679 --> 00:21:53,360
cognitive configuration management tool

659
00:21:53,360 --> 00:21:55,039
caught caught the change and bought it

660
00:21:55,039 --> 00:21:56,640
every time so something we're barely

661
00:21:56,640 --> 00:21:58,559
paying for didn't even we didn't expect

662
00:21:58,559 --> 00:22:00,320
this to happen i caught it and bought it

663
00:22:00,320 --> 00:22:01,760
every time so that was very interesting

664
00:22:01,760 --> 00:22:03,440
to learn that so the third thing we

665
00:22:03,440 --> 00:22:04,960
learned is we didn't really have a sim

666
00:22:04,960 --> 00:22:06,640
we wrote our own sort of security big

667
00:22:06,640 --> 00:22:10,159
data lake solution uh and um i did not

668
00:22:10,159 --> 00:22:11,440
have a whole lot of confidence that

669
00:22:11,440 --> 00:22:13,840
actually their alert would get generated

670
00:22:13,840 --> 00:22:16,880
from uh that from the logs that came uh

671
00:22:16,880 --> 00:22:18,880
from the controls it actually did

672
00:22:18,880 --> 00:22:20,080
according to the alert the work went to

673
00:22:20,080 --> 00:22:22,400
the sock the problem is is that when the

674
00:22:22,400 --> 00:22:23,840
stock got the alert they couldn't tell

675
00:22:23,840 --> 00:22:27,280
which aws environment came from uh and

676
00:22:27,280 --> 00:22:28,720
as an engineer you're saying oh aaron i

677
00:22:28,720 --> 00:22:30,240
can map back the ip address and forgot

678
00:22:30,240 --> 00:22:31,840
where it came from yeah you can but that

679
00:22:31,840 --> 00:22:34,880
could take 15 to 20 minutes maybe uh and

680
00:22:34,880 --> 00:22:37,280
or it could take an hour to p if s nat

681
00:22:37,280 --> 00:22:38,720
is in play because s not intentionally

682
00:22:38,720 --> 00:22:40,880
hides the real ip address so you could

683
00:22:40,880 --> 00:22:43,440
uh you know that's a long time to be uh

684
00:22:43,440 --> 00:22:46,080
if especially that's an outage okay uh

685
00:22:46,080 --> 00:22:47,840
but here's a great thing there was no

686
00:22:47,840 --> 00:22:49,200
outage remember nobody freaked out

687
00:22:49,200 --> 00:22:50,640
because we were being proactive and we

688
00:22:50,640 --> 00:22:53,039
did discover this that um

689
00:22:53,039 --> 00:22:56,880
we uh um you know uh all we had to do is

690
00:22:56,880 --> 00:22:58,799
add metadata to the alert and solve the

691
00:22:58,799 --> 00:23:00,559
problem solved so that's kind of value

692
00:23:00,559 --> 00:23:01,840
in doing some of this you can find more

693
00:23:01,840 --> 00:23:03,280
about this like i said in the o'reilly

694
00:23:03,280 --> 00:23:06,159
report um and i'm

695
00:23:06,159 --> 00:23:07,679
you can actually download that report at

696
00:23:07,679 --> 00:23:10,960
this link and download both books uh um

697
00:23:10,960 --> 00:23:12,640
here are the links to both

698
00:23:12,640 --> 00:23:15,039
um i hope you enjoyed my presentation uh

699
00:23:15,039 --> 00:23:16,559
it's somewhat a brief brief presentation

700
00:23:16,559 --> 00:23:18,159
on security chaos engineering like i

701
00:23:18,159 --> 00:23:19,600
said you can find more both of these

702
00:23:19,600 --> 00:23:21,280
resources about it

703
00:23:21,280 --> 00:23:23,840
thank you

