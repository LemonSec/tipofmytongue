1
00:00:00,060 --> 00:00:04,619
good afternoon everyone I hope you enjoy

2
00:00:02,490 --> 00:00:07,470
the conference so far

3
00:00:04,620 --> 00:00:09,809
my name is here and together with me on

4
00:00:07,470 --> 00:00:11,849
stage we have a girl and actually our

5
00:00:09,809 --> 00:00:14,149
roots in the industry come from the

6
00:00:11,849 --> 00:00:17,039
field of web application security

7
00:00:14,150 --> 00:00:19,619
ranging from the exciting days of watch

8
00:00:17,039 --> 00:00:23,310
fire and after we got acquired also in

9
00:00:19,619 --> 00:00:25,800
IBM but in the past seven years our

10
00:00:23,310 --> 00:00:28,859
focus has shifted to mobility mobile

11
00:00:25,800 --> 00:00:31,380
security I co-founded Sky Hill and eager

12
00:00:28,859 --> 00:00:33,540
was one of our first employees and we

13
00:00:31,380 --> 00:00:36,379
focused on many areas of mobile security

14
00:00:33,540 --> 00:00:39,809
os security in network security and

15
00:00:36,380 --> 00:00:41,899
application security and today what we

16
00:00:39,809 --> 00:00:44,309
want to do is actually discuss

17
00:00:41,899 --> 00:00:47,460
differently pitting coding pitfalls

18
00:00:44,309 --> 00:00:50,370
we've identified over deals how they

19
00:00:47,460 --> 00:00:52,079
happen how they can may be mitigated etc

20
00:00:50,370 --> 00:00:55,199
and we will start with a very quick

21
00:00:52,079 --> 00:00:57,300
overview of OS level issues ID issues

22
00:00:55,199 --> 00:00:59,390
and then the core of the presentation

23
00:00:57,300 --> 00:01:01,858
will be around application security

24
00:00:59,390 --> 00:01:03,690
afterwards then we will conclude take a

25
00:01:01,859 --> 00:01:06,600
few examples that we cover today and

26
00:01:03,690 --> 00:01:10,369
perform a live demonstration of how

27
00:01:06,600 --> 00:01:13,740
those coding pitfalls might be exploited

28
00:01:10,369 --> 00:01:17,100
so let's start with OS so obviously I

29
00:01:13,740 --> 00:01:19,589
think that when software is developed

30
00:01:17,100 --> 00:01:21,750
new coding pitfalls arise and the same

31
00:01:19,590 --> 00:01:24,119
applies to any operating system I've

32
00:01:21,750 --> 00:01:27,210
ever seen I can show you that over the

33
00:01:24,119 --> 00:01:30,270
years we've seen hundreds of distinct

34
00:01:27,210 --> 00:01:32,789
security issues publicly disclosed both

35
00:01:30,270 --> 00:01:34,890
for iOS and Android and because of the

36
00:01:32,790 --> 00:01:37,350
great value of security issues in those

37
00:01:34,890 --> 00:01:39,630
operating systems the belief is that the

38
00:01:37,350 --> 00:01:41,669
actual number of new vulnerabilities

39
00:01:39,630 --> 00:01:44,310
that are being identified and exploited

40
00:01:41,670 --> 00:01:47,490
is much higher than what is publicly

41
00:01:44,310 --> 00:01:50,909
discussed so I think that when it comes

42
00:01:47,490 --> 00:01:53,369
to OS it can range from esoteric very

43
00:01:50,909 --> 00:01:55,590
weird glitches such as the glitter in

44
00:01:53,369 --> 00:01:59,340
FaceTime that was identified earlier

45
00:01:55,590 --> 00:02:01,200
this year by a 14 years old boy and it

46
00:01:59,340 --> 00:02:04,170
practically allowed to set up a group

47
00:02:01,200 --> 00:02:06,180
call in FaceTime and be able to snow

48
00:02:04,170 --> 00:02:09,060
into the microphone and others other

49
00:02:06,180 --> 00:02:11,430
conditions also to the video even before

50
00:02:09,060 --> 00:02:13,440
the victim had a chance to either pick

51
00:02:11,430 --> 00:02:15,510
up or hang up

52
00:02:13,440 --> 00:02:18,030
I think a more interesting example of

53
00:02:15,510 --> 00:02:19,920
our notable security issue in operating

54
00:02:18,030 --> 00:02:21,720
systems is goto fail

55
00:02:19,920 --> 00:02:24,510
so how many of you are familiar with

56
00:02:21,720 --> 00:02:26,520
goto fail okay okay

57
00:02:24,510 --> 00:02:28,380
so this is a security issue that was

58
00:02:26,520 --> 00:02:32,040
identified a few years ago it actually

59
00:02:28,380 --> 00:02:34,950
existed in iOS for about 17 months until

60
00:02:32,040 --> 00:02:37,350
it was patched and I think for those of

61
00:02:34,950 --> 00:02:39,869
you that would develop it might be very

62
00:02:37,350 --> 00:02:42,329
familiar to you from your own story so

63
00:02:39,870 --> 00:02:45,630
what we seen here is is it is a piece of

64
00:02:42,330 --> 00:02:47,910
the the phases of TLS handshake right

65
00:02:45,630 --> 00:02:50,370
the diesels responsible for forward

66
00:02:47,910 --> 00:02:55,710
secrecy and this piece of code just have

67
00:02:50,370 --> 00:02:58,290
to verify part of the change of the keys

68
00:02:55,710 --> 00:03:01,380
so this is a function it needs to return

69
00:02:58,290 --> 00:03:03,900
zero if everything okay if not obviously

70
00:03:01,380 --> 00:03:05,670
something else and I think the most most

71
00:03:03,900 --> 00:03:08,520
important part of the code is obviously

72
00:03:05,670 --> 00:03:10,260
that function but if you come to look at

73
00:03:08,520 --> 00:03:13,200
this implementation that actually

74
00:03:10,260 --> 00:03:15,600
existed in iOS and also Mac OS the big

75
00:03:13,200 --> 00:03:18,750
problem lies here looks like you go in

76
00:03:15,600 --> 00:03:20,760
like copy double pasted right so because

77
00:03:18,750 --> 00:03:23,550
there is it there isn't any usage of

78
00:03:20,760 --> 00:03:25,620
heavy buckets etc what practically

79
00:03:23,550 --> 00:03:27,630
happens is that the first go-to fail

80
00:03:25,620 --> 00:03:30,900
happens if something wrong happens to

81
00:03:27,630 --> 00:03:34,890
the update function but regardless the

82
00:03:30,900 --> 00:03:36,180
second one will be executed if not that

83
00:03:34,890 --> 00:03:38,670
means that the critical code in here

84
00:03:36,180 --> 00:03:41,160
doesn't even get executed under any

85
00:03:38,670 --> 00:03:43,260
circumstances and a problem with that is

86
00:03:41,160 --> 00:03:45,660
that practically if the first kind of

87
00:03:43,260 --> 00:03:48,149
the first list of functions are just

88
00:03:45,660 --> 00:03:50,190
okay and not fail we get into the

89
00:03:48,150 --> 00:03:53,580
situation where the function returns

90
00:03:50,190 --> 00:03:55,560
zero presumably verified that phase but

91
00:03:53,580 --> 00:03:58,020
it didn't really and that kind of

92
00:03:55,560 --> 00:04:00,600
mistake actually led to the ability of

93
00:03:58,020 --> 00:04:02,730
Amanda middle attacker - not only snow

94
00:04:00,600 --> 00:04:04,739
upon the plain text communication right

95
00:04:02,730 --> 00:04:10,760
but also into the encrypted

96
00:04:04,739 --> 00:04:13,739
communication okay so bit on the IDs so

97
00:04:10,760 --> 00:04:16,980
again another interesting attack from a

98
00:04:13,739 --> 00:04:21,570
few years ago was Xcode ghost in this

99
00:04:16,980 --> 00:04:24,030
case developers mainly from China we're

100
00:04:21,570 --> 00:04:24,760
using a mirror site to download upgrades

101
00:04:24,030 --> 00:04:28,979
for

102
00:04:24,760 --> 00:04:32,620
Xcode mainly because of limited of

103
00:04:28,980 --> 00:04:35,950
bandwidth problems with the official

104
00:04:32,620 --> 00:04:40,030
Apple sites so what happened was that

105
00:04:35,950 --> 00:04:43,960
they downloaded an IDE that would inject

106
00:04:40,030 --> 00:04:46,150
malicious code after the app was already

107
00:04:43,960 --> 00:04:49,299
built into the binary before it was

108
00:04:46,150 --> 00:04:53,169
signed and sent to the App Store for

109
00:04:49,300 --> 00:04:57,030
review now because at the time much of

110
00:04:53,170 --> 00:05:00,670
the review process of Apple dependent on

111
00:04:57,030 --> 00:05:04,989
reputation and those apps had hundreds

112
00:05:00,670 --> 00:05:07,780
of millions of end-users using them they

113
00:05:04,990 --> 00:05:09,520
were approved by Apple and went on the

114
00:05:07,780 --> 00:05:12,190
store and all of those users were

115
00:05:09,520 --> 00:05:14,799
infected and it took quite some time

116
00:05:12,190 --> 00:05:17,890
until Apple realized it and took them

117
00:05:14,800 --> 00:05:20,050
down from the store yes just an anecdote

118
00:05:17,890 --> 00:05:22,090
we've been following those incarnations

119
00:05:20,050 --> 00:05:24,580
for many years and even though the

120
00:05:22,090 --> 00:05:27,330
initial publication happened end of 2015

121
00:05:24,580 --> 00:05:30,010
to these very days we still see

122
00:05:27,330 --> 00:05:32,380
instances of compromised versions of

123
00:05:30,010 --> 00:05:34,390
those apps used by people because they

124
00:05:32,380 --> 00:05:38,080
didn't updates their application

125
00:05:34,390 --> 00:05:39,940
versions so let's jump on jump over and

126
00:05:38,080 --> 00:05:42,250
discuss a few with pitting coding

127
00:05:39,940 --> 00:05:44,560
pitfalls we have seen constantly coming

128
00:05:42,250 --> 00:05:46,960
back and back and back the first one we

129
00:05:44,560 --> 00:05:49,480
call it hospital gown and I want to give

130
00:05:46,960 --> 00:05:51,070
you a quick illustration of why that

131
00:05:49,480 --> 00:05:53,740
happens and later on what are the

132
00:05:51,070 --> 00:05:56,710
ramifications so let's look at this

133
00:05:53,740 --> 00:05:59,170
diagram let's imagine that we have a

134
00:05:56,710 --> 00:06:01,450
development team that develops photo app

135
00:05:59,170 --> 00:06:04,420
right and now the product manager wants

136
00:06:01,450 --> 00:06:07,060
to add an ability to upload new photos

137
00:06:04,420 --> 00:06:09,280
from the mobile app to the servers right

138
00:06:07,060 --> 00:06:10,570
so they go to the developer the

139
00:06:09,280 --> 00:06:12,820
developer says sure no problem

140
00:06:10,570 --> 00:06:16,000
immediately things no problem let's just

141
00:06:12,820 --> 00:06:17,770
take those files upload them to s3 it

142
00:06:16,000 --> 00:06:20,860
then goes to the DevOps engineer and

143
00:06:17,770 --> 00:06:24,370
tells them I need a way to upload files

144
00:06:20,860 --> 00:06:26,890
to s3 Davis regional provides the user

145
00:06:24,370 --> 00:06:29,320
access key and quickly after we have a

146
00:06:26,890 --> 00:06:31,630
new shiny functionality the developer

147
00:06:29,320 --> 00:06:34,930
incorporated that access key into the

148
00:06:31,630 --> 00:06:36,440
mobile app what's the problem comedy of

149
00:06:34,930 --> 00:06:39,590
errors right

150
00:06:36,440 --> 00:06:41,960
what actually happens is that now we

151
00:06:39,590 --> 00:06:44,239
have a mobile app that any hacker can

152
00:06:41,960 --> 00:06:46,729
take reverse-engineer and extract the

153
00:06:44,240 --> 00:06:49,850
keys form and in this case what happens

154
00:06:46,730 --> 00:06:52,040
is this is a very promiscuous version of

155
00:06:49,850 --> 00:06:56,180
an access key that can allow to actually

156
00:06:52,040 --> 00:06:58,820
access all buckets in s3 okay so usually

157
00:06:56,180 --> 00:07:01,010
when we talk about this use case to our

158
00:06:58,820 --> 00:07:03,320
colleagues in the industry to say well

159
00:07:01,010 --> 00:07:05,060
that's terrible that might happen not

160
00:07:03,320 --> 00:07:07,640
likely to happen to me or not likely to

161
00:07:05,060 --> 00:07:09,650
happen at all and therefore what we

162
00:07:07,640 --> 00:07:12,530
decided to do is to actually analyze

163
00:07:09,650 --> 00:07:15,679
millions of apps millions of mobile apps

164
00:07:12,530 --> 00:07:17,869
using static and dynamic analysis and we

165
00:07:15,680 --> 00:07:20,270
looked into applications that try to

166
00:07:17,870 --> 00:07:23,330
upload stuff to the cloud cloud storage

167
00:07:20,270 --> 00:07:27,469
Microsoft Amazon schoolgirls and others

168
00:07:23,330 --> 00:07:30,260
and we're actually amazed to see a huge

169
00:07:27,470 --> 00:07:33,500
amount of applications that did exactly

170
00:07:30,260 --> 00:07:36,380
those kind of mistakes okay as an

171
00:07:33,500 --> 00:07:39,020
anecdote we looked into applications

172
00:07:36,380 --> 00:07:40,610
that upload stuff to s3 and have you

173
00:07:39,020 --> 00:07:44,659
know the utilization of an access token

174
00:07:40,610 --> 00:07:47,720
there and 46 percent of those and these

175
00:07:44,660 --> 00:07:49,850
tokens that allow access to all buckets

176
00:07:47,720 --> 00:07:53,450
not only the bucket you plan to upload

177
00:07:49,850 --> 00:07:55,490
files to ok and just to clarify the

178
00:07:53,450 --> 00:07:57,969
ramifications of those findings are

179
00:07:55,490 --> 00:08:01,340
actually hundreds of millions of users

180
00:07:57,970 --> 00:08:04,160
sensitive records the results are

181
00:08:01,340 --> 00:08:06,049
actually confidential sensitive

182
00:08:04,160 --> 00:08:08,450
corporate files that were stored in

183
00:08:06,050 --> 00:08:10,280
different buckets in the account but

184
00:08:08,450 --> 00:08:12,140
well suddenly exposed because of those

185
00:08:10,280 --> 00:08:14,690
mistakes who actually came across

186
00:08:12,140 --> 00:08:20,060
backups of internal systems again that

187
00:08:14,690 --> 00:08:22,150
will back up to those buckets so let's

188
00:08:20,060 --> 00:08:25,580
try to understand why this happens often

189
00:08:22,150 --> 00:08:28,460
first thing is let's look at the default

190
00:08:25,580 --> 00:08:31,070
policies of AWS if you go to AWS and you

191
00:08:28,460 --> 00:08:33,710
look for s3 this is what you get and the

192
00:08:31,070 --> 00:08:36,650
default policies the main ones are

193
00:08:33,710 --> 00:08:39,680
read-only or full access and what you

194
00:08:36,650 --> 00:08:43,459
might notice is that both of them always

195
00:08:39,679 --> 00:08:47,030
rely to all of the buckets all of the

196
00:08:43,460 --> 00:08:49,880
directories everything and by using

197
00:08:47,030 --> 00:08:53,750
those default policies this is the usual

198
00:08:49,880 --> 00:08:54,290
fail point where the developers make the

199
00:08:53,750 --> 00:08:57,530
mistake

200
00:08:54,290 --> 00:09:00,290
now how you could try and resolve this

201
00:08:57,530 --> 00:09:03,050
first option is to use pre signed URLs

202
00:09:00,290 --> 00:09:06,290
pre-signed URLs is a feature supported

203
00:09:03,050 --> 00:09:09,829
by AWS where you generate a unique URL

204
00:09:06,290 --> 00:09:12,620
to to a specific file it has a signature

205
00:09:09,830 --> 00:09:15,620
it has an expiration date and it's

206
00:09:12,620 --> 00:09:17,360
extremely secure you can go and upload a

207
00:09:15,620 --> 00:09:20,690
single file to the application and it

208
00:09:17,360 --> 00:09:22,640
even goes away after a time the overhead

209
00:09:20,690 --> 00:09:24,560
here is that I'm trying to build

210
00:09:22,640 --> 00:09:26,480
something that's scalable I'm trying to

211
00:09:24,560 --> 00:09:29,359
use the cloud and I still need to talk

212
00:09:26,480 --> 00:09:31,340
from the client to the server for each

213
00:09:29,360 --> 00:09:34,850
file I want to upload so that I will get

214
00:09:31,340 --> 00:09:37,730
this unique URL and permission to upload

215
00:09:34,850 --> 00:09:41,150
this file so let's look at another

216
00:09:37,730 --> 00:09:44,750
alternative another alternative would be

217
00:09:41,150 --> 00:09:47,480
to build a custom policy this time we'll

218
00:09:44,750 --> 00:09:49,910
only give the specific permission in

219
00:09:47,480 --> 00:09:53,330
this case only upload a single file at a

220
00:09:49,910 --> 00:09:56,000
time and we will limit it to our

221
00:09:53,330 --> 00:09:58,580
specific buckets of course we'll build

222
00:09:56,000 --> 00:10:00,260
such a policy per bucket and each thing

223
00:09:58,580 --> 00:10:04,130
should be used only for the specific

224
00:10:00,260 --> 00:10:07,280
purpose now once we do that we still

225
00:10:04,130 --> 00:10:11,420
have one minor issue that you could

226
00:10:07,280 --> 00:10:13,850
override files using that same key you

227
00:10:11,420 --> 00:10:16,910
could easily solve this by generating a

228
00:10:13,850 --> 00:10:18,760
secret or a random token and adding it

229
00:10:16,910 --> 00:10:23,630
to the file name so that others can't

230
00:10:18,760 --> 00:10:27,410
either maliciously or by accident guess

231
00:10:23,630 --> 00:10:29,330
your file name and override it another

232
00:10:27,410 --> 00:10:32,329
layer of security that you might want to

233
00:10:29,330 --> 00:10:35,450
adhere to prevent others from making the

234
00:10:32,330 --> 00:10:37,220
same mistake that you have avoided is to

235
00:10:35,450 --> 00:10:39,920
add the bucket encryption bucket

236
00:10:37,220 --> 00:10:43,220
encryption allows you to attach a KMS

237
00:10:39,920 --> 00:10:44,839
key per bucket which means that not only

238
00:10:43,220 --> 00:10:47,660
do you have to have the specific

239
00:10:44,840 --> 00:10:50,330
permission to access files on that

240
00:10:47,660 --> 00:10:53,589
bucket and write to that bucket but you

241
00:10:50,330 --> 00:10:56,210
also have to have access to this key

242
00:10:53,590 --> 00:10:58,280
meaning that if someone else uses the

243
00:10:56,210 --> 00:11:00,320
default policy he won't have the key

244
00:10:58,280 --> 00:11:02,480
thus he won't be able to list the file

245
00:11:00,320 --> 00:11:06,800
and take them from your bucket that

246
00:11:02,480 --> 00:11:09,110
you're trying to secure okay so this was

247
00:11:06,800 --> 00:11:12,410
one one issue wanted to share with you

248
00:11:09,110 --> 00:11:13,970
another one relies really relates to man

249
00:11:12,410 --> 00:11:16,160
in the middle attacks so obviously over

250
00:11:13,970 --> 00:11:19,550
this men the middle has become a very

251
00:11:16,160 --> 00:11:22,610
prominent discussion in the industry and

252
00:11:19,550 --> 00:11:24,949
I think had a very important impact on

253
00:11:22,610 --> 00:11:27,830
an industry on the positive side we've

254
00:11:24,950 --> 00:11:29,480
seen a significant growth in the

255
00:11:27,830 --> 00:11:32,480
utilization of encryption right in

256
00:11:29,480 --> 00:11:35,180
different services and and and service

257
00:11:32,480 --> 00:11:37,300
and service and it actually is the best

258
00:11:35,180 --> 00:11:40,520
key against men demeanor attacks right

259
00:11:37,300 --> 00:11:42,260
now when you come to think about what

260
00:11:40,520 --> 00:11:44,780
you need to do in order to implement

261
00:11:42,260 --> 00:11:46,520
encryption and protect yourself against

262
00:11:44,780 --> 00:11:49,250
minidom in their attacks when you think

263
00:11:46,520 --> 00:11:51,560
about browsers as an example you have a

264
00:11:49,250 --> 00:11:54,200
situation where the developer of the

265
00:11:51,560 --> 00:11:56,300
browser does not know how the users will

266
00:11:54,200 --> 00:11:57,950
use it right where will they browse to

267
00:11:56,300 --> 00:11:59,599
which kind of service they will connect

268
00:11:57,950 --> 00:12:01,700
to and therefore the challenge is first

269
00:11:59,600 --> 00:12:03,920
of all before you encrypt to make sure

270
00:12:01,700 --> 00:12:05,720
that the server the client tries to

271
00:12:03,920 --> 00:12:07,670
connect to is indeed the server itself

272
00:12:05,720 --> 00:12:09,400
and then obviously encrypts the

273
00:12:07,670 --> 00:12:12,500
communication between the two sites and

274
00:12:09,400 --> 00:12:14,959
the challenge just mentioned led to the

275
00:12:12,500 --> 00:12:18,470
utilization of the concept of chain of

276
00:12:14,960 --> 00:12:21,860
trust right identifying a bunch of third

277
00:12:18,470 --> 00:12:24,650
parties trusted sources we call it we

278
00:12:21,860 --> 00:12:26,570
call them what CAS having them their

279
00:12:24,650 --> 00:12:29,689
certificates already pre-installed or

280
00:12:26,570 --> 00:12:33,410
installed by the browser or by the host

281
00:12:29,690 --> 00:12:35,540
itself and then by giving them the

282
00:12:33,410 --> 00:12:37,640
responsibility to verify the identity of

283
00:12:35,540 --> 00:12:39,709
servers and then mathematically sign-on

284
00:12:37,640 --> 00:12:42,140
their certificates with a nice model

285
00:12:39,710 --> 00:12:44,750
where the agents the clients the browser

286
00:12:42,140 --> 00:12:47,120
can try to connect to a server get a

287
00:12:44,750 --> 00:12:49,250
certificate compare the domain to the

288
00:12:47,120 --> 00:12:51,320
subject in the certificate and then just

289
00:12:49,250 --> 00:12:53,510
validate that the certificate itself is

290
00:12:51,320 --> 00:12:56,120
mathematically signed directly or

291
00:12:53,510 --> 00:12:58,310
indirectly by a would say that's awesome

292
00:12:56,120 --> 00:13:00,790
that works very very well the big

293
00:12:58,310 --> 00:13:03,680
problem is that as encryption went up

294
00:13:00,790 --> 00:13:05,810
attackers started to focus on the weak

295
00:13:03,680 --> 00:13:10,219
point in that model which is obviously

296
00:13:05,810 --> 00:13:12,040
that list of trusted CAS right so what

297
00:13:10,220 --> 00:13:14,470
that occurs started to do more

298
00:13:12,040 --> 00:13:16,860
more either by exploiting security

299
00:13:14,470 --> 00:13:20,170
issues or just by social engineering

300
00:13:16,860 --> 00:13:22,720
they just focused on getting a bad would

301
00:13:20,170 --> 00:13:25,029
CA into the trusted list and then from

302
00:13:22,720 --> 00:13:26,860
that that moment the whole model fails

303
00:13:25,029 --> 00:13:28,990
because that allows a man-in-the-middle

304
00:13:26,860 --> 00:13:31,480
attack you to provide an invalid

305
00:13:28,990 --> 00:13:33,730
certificate that would be signed by the

306
00:13:31,480 --> 00:13:34,899
malicious would CA and from the

307
00:13:33,730 --> 00:13:37,360
perspective of the client-side

308
00:13:34,899 --> 00:13:39,970
everything looks legit because all the

309
00:13:37,360 --> 00:13:40,690
steps that just mentioned are working

310
00:13:39,970 --> 00:13:43,089
okay

311
00:13:40,690 --> 00:13:46,029
now let's think about for a moment about

312
00:13:43,089 --> 00:13:48,610
mobile applications in those situations

313
00:13:46,029 --> 00:13:51,160
that the Vella pel of the client is

314
00:13:48,610 --> 00:13:53,440
usually also the owner of the critical

315
00:13:51,160 --> 00:13:55,810
servers with which the mobile app is

316
00:13:53,440 --> 00:14:01,149
communicated with right that opens the

317
00:13:55,810 --> 00:14:03,638
door for certificate pinning so again as

318
00:14:01,149 --> 00:14:06,639
developers we are used to look at the

319
00:14:03,639 --> 00:14:09,279
let's say the high level and when we

320
00:14:06,639 --> 00:14:11,529
make requests we look at the responses

321
00:14:09,279 --> 00:14:16,180
this is the data part we kind of ignore

322
00:14:11,529 --> 00:14:18,970
this critical part of the handshake that

323
00:14:16,180 --> 00:14:22,239
happens at the beginning and in order to

324
00:14:18,970 --> 00:14:25,260
implement this pinning correctly we will

325
00:14:22,240 --> 00:14:28,540
have to get into this process as well so

326
00:14:25,260 --> 00:14:30,939
let's split it into a few steps we'll

327
00:14:28,540 --> 00:14:33,279
have to hook the handshake phase be able

328
00:14:30,940 --> 00:14:35,260
to look at the specific certificate we

329
00:14:33,279 --> 00:14:37,170
still want to do all the validations

330
00:14:35,260 --> 00:14:40,269
that the operating system does for us

331
00:14:37,170 --> 00:14:41,860
making sure that this certificate is

332
00:14:40,269 --> 00:14:45,670
actually valid it signs the correct

333
00:14:41,860 --> 00:14:48,519
domain expiration dates etc and the last

334
00:14:45,670 --> 00:14:52,300
part will be adding our own validation

335
00:14:48,519 --> 00:14:54,100
layer where we would compare the

336
00:14:52,300 --> 00:14:57,880
specific certificate that we received

337
00:14:54,100 --> 00:15:01,319
with a trusted list that our application

338
00:14:57,880 --> 00:15:05,980
will maintain preventing others from

339
00:15:01,319 --> 00:15:11,800
going around this mechanism so a bit

340
00:15:05,980 --> 00:15:14,980
about code let's say we're using iOS and

341
00:15:11,800 --> 00:15:17,920
we use URL session in order to make our

342
00:15:14,980 --> 00:15:22,060
requests we can register a delegate and

343
00:15:17,920 --> 00:15:24,439
this callback is basically our first

344
00:15:22,060 --> 00:15:27,018
step that we mentioned this is the hook

345
00:15:24,440 --> 00:15:28,759
and here we are in the middle of the

346
00:15:27,019 --> 00:15:31,850
handshake part we received a certificate

347
00:15:28,759 --> 00:15:35,540
and we have the ability to either accept

348
00:15:31,850 --> 00:15:39,410
or reject the specific certificate and

349
00:15:35,540 --> 00:15:41,089
add our own validations second part is

350
00:15:39,410 --> 00:15:42,649
the default behavior of the operating

351
00:15:41,089 --> 00:15:46,009
system we just create a default policy

352
00:15:42,649 --> 00:15:48,589
do the SSL validations just as the

353
00:15:46,009 --> 00:15:50,779
operating system would and here the

354
00:15:48,589 --> 00:15:55,519
third part is the part where we add our

355
00:15:50,779 --> 00:15:57,920
own mechanism to try and add the

356
00:15:55,519 --> 00:16:00,019
additional validation so let's look at a

357
00:15:57,920 --> 00:16:05,870
couple of interesting implementations

358
00:16:00,019 --> 00:16:09,199
for this first one is taking the whole

359
00:16:05,870 --> 00:16:12,470
chain in this case we chose to sign and

360
00:16:09,199 --> 00:16:14,240
validate the leaf certificates so zero

361
00:16:12,470 --> 00:16:16,639
here that you see is basically the first

362
00:16:14,240 --> 00:16:18,470
part first certificate in the chain this

363
00:16:16,639 --> 00:16:21,649
is the leaf we will generate a

364
00:16:18,470 --> 00:16:23,360
fingerprint and compare this fingerprint

365
00:16:21,649 --> 00:16:25,160
with a trust at least that our

366
00:16:23,360 --> 00:16:29,649
application maintains and needs to be

367
00:16:25,160 --> 00:16:32,990
up-to-date all the time now a common

368
00:16:29,649 --> 00:16:36,050
problem with that is that it's again

369
00:16:32,990 --> 00:16:38,720
high maintenance we will usually replace

370
00:16:36,050 --> 00:16:40,910
our certificates once a year that means

371
00:16:38,720 --> 00:16:42,620
that each time before we upload the new

372
00:16:40,910 --> 00:16:46,180
certificate to the site we need to

373
00:16:42,620 --> 00:16:50,449
release a new application in advance and

374
00:16:46,180 --> 00:16:52,069
for those users that do not often update

375
00:16:50,449 --> 00:16:54,139
their application we need to dynamically

376
00:16:52,069 --> 00:16:56,930
pass on the information of the new

377
00:16:54,139 --> 00:16:58,790
fingerprint so that the old application

378
00:16:56,930 --> 00:17:01,930
is still aware of the new fingerprint

379
00:16:58,790 --> 00:17:05,599
exists so one other option that we can

380
00:17:01,930 --> 00:17:08,119
implement is not looking at the complete

381
00:17:05,599 --> 00:17:11,149
certificate but rather looking at the

382
00:17:08,119 --> 00:17:13,879
public key assuming that it has not been

383
00:17:11,150 --> 00:17:16,189
compromised we could earn some time and

384
00:17:13,880 --> 00:17:20,169
reduce the frequency of replacements of

385
00:17:16,189 --> 00:17:23,870
certificates off of the application by

386
00:17:20,169 --> 00:17:26,740
generating for two or three years this

387
00:17:23,869 --> 00:17:30,289
new certificates each year from the same

388
00:17:26,740 --> 00:17:34,730
public and private keys allowing us to

389
00:17:30,289 --> 00:17:35,960
still do the fingerprinting but not

390
00:17:34,730 --> 00:17:38,679
having to

391
00:17:35,960 --> 00:17:43,490
the app each time we replace the

392
00:17:38,679 --> 00:17:47,299
certificate so we've done that and

393
00:17:43,490 --> 00:17:49,549
probably some of you are kind of feeling

394
00:17:47,299 --> 00:17:51,379
that they're afraid because okay make

395
00:17:49,549 --> 00:17:53,539
some mistake we don't update it in time

396
00:17:51,379 --> 00:17:55,519
I'm getting locked out of my server

397
00:17:53,539 --> 00:17:59,299
now I have a useless app it can't

398
00:17:55,519 --> 00:18:04,159
communicate with my server so a bit

399
00:17:59,299 --> 00:18:07,340
about alternatives to overcome this one

400
00:18:04,159 --> 00:18:10,159
of the one of the suggestions is to use

401
00:18:07,340 --> 00:18:13,189
an alternative secure channel that will

402
00:18:10,159 --> 00:18:16,369
allow adding temporary a temporary

403
00:18:13,190 --> 00:18:18,679
fingerprint in addition to the existing

404
00:18:16,369 --> 00:18:20,689
list just to open a single sync with the

405
00:18:18,679 --> 00:18:23,480
server allowing us to fetch the full

406
00:18:20,690 --> 00:18:26,360
configuration again so in this case even

407
00:18:23,480 --> 00:18:28,730
if the application didn't get the

408
00:18:26,360 --> 00:18:30,019
updating time and the binary was not

409
00:18:28,730 --> 00:18:31,999
updated with a new one

410
00:18:30,019 --> 00:18:34,299
containing the new fingerprint we can

411
00:18:31,999 --> 00:18:37,730
use a push notification either from

412
00:18:34,299 --> 00:18:41,240
Apple's APNs or Google's FCM - just push

413
00:18:37,730 --> 00:18:44,389
the new token temporarily unlocking the

414
00:18:41,240 --> 00:18:49,879
app to allow you to communicate with a

415
00:18:44,389 --> 00:18:52,100
server thanks Cal and I think the third

416
00:18:49,879 --> 00:18:58,399
example is actually my personal

417
00:18:52,100 --> 00:19:00,590
favorites and and actually over this one

418
00:18:58,399 --> 00:19:02,989
things I like to do when interviewing

419
00:19:00,590 --> 00:19:06,678
candidates is to ask them a very simple

420
00:19:02,990 --> 00:19:09,259
coding question I tell them that they

421
00:19:06,679 --> 00:19:11,600
have a zip file that they need to just

422
00:19:09,259 --> 00:19:13,789
unpack into the file system so they have

423
00:19:11,600 --> 00:19:15,590
a target directory to which to unpack

424
00:19:13,789 --> 00:19:17,299
and they have some kind of object that

425
00:19:15,590 --> 00:19:20,178
allows them to iterate over the zip

426
00:19:17,299 --> 00:19:22,309
files and usually I get very similar

427
00:19:20,179 --> 00:19:24,860
answers in this case you can look at the

428
00:19:22,309 --> 00:19:26,779
code from Java to do this that is very

429
00:19:24,860 --> 00:19:29,719
successfully by the way too much

430
00:19:26,779 --> 00:19:32,119
successfully and then naturally what you

431
00:19:29,720 --> 00:19:34,399
can see here is an iteration of the zip

432
00:19:32,119 --> 00:19:37,939
entries we've got the destination deal

433
00:19:34,399 --> 00:19:40,879
which is developer controlled this case

434
00:19:37,940 --> 00:19:43,009
my op slash target deal but the problem

435
00:19:40,879 --> 00:19:45,350
is that the zip file itself is user

436
00:19:43,009 --> 00:19:47,509
controlled meaning attackers controlled

437
00:19:45,350 --> 00:19:48,879
in one of the most trivial things an

438
00:19:47,509 --> 00:19:51,490
attacker might do

439
00:19:48,880 --> 00:19:54,550
we're a specially crafted zip file that

440
00:19:51,490 --> 00:19:57,280
will contain dot slash dot slash etc and

441
00:19:54,550 --> 00:19:59,860
practically director which reveals the

442
00:19:57,280 --> 00:20:02,590
whole situation so when you can cut the

443
00:19:59,860 --> 00:20:05,050
two strengths obviously we are gaining

444
00:20:02,590 --> 00:20:07,270
into situation where we actually escaped

445
00:20:05,050 --> 00:20:10,870
from the target directory and gained

446
00:20:07,270 --> 00:20:13,900
arbitrary file right in this case we

447
00:20:10,870 --> 00:20:16,080
likely just took over the host right

448
00:20:13,900 --> 00:20:18,700
I think the interesting part about

449
00:20:16,080 --> 00:20:20,470
Baskerville cell is that it has been

450
00:20:18,700 --> 00:20:25,060
around for decades

451
00:20:20,470 --> 00:20:28,110
ok so in here you can see flag 35 as you

452
00:20:25,060 --> 00:20:30,730
can see it's from 91 and it talks about

453
00:20:28,110 --> 00:20:31,149
WWI V for those of you that are old

454
00:20:30,730 --> 00:20:33,640
enough

455
00:20:31,150 --> 00:20:35,320
this is was a very well known VBS

456
00:20:33,640 --> 00:20:38,170
framework it's actually still being

457
00:20:35,320 --> 00:20:40,450
maintained and what they've shown is

458
00:20:38,170 --> 00:20:43,900
practically part of else'll to take over

459
00:20:40,450 --> 00:20:46,450
that framework okay so this is very old

460
00:20:43,900 --> 00:20:49,180
the interesting part that is even more

461
00:20:46,450 --> 00:20:51,910
interesting is that it's still very very

462
00:20:49,180 --> 00:20:54,730
relevant in the past year we've seen

463
00:20:51,910 --> 00:20:57,580
research by snake and other very

464
00:20:54,730 --> 00:21:00,190
notables Israeli startup that actually

465
00:20:57,580 --> 00:21:03,149
uncovered the huge amount of current

466
00:21:00,190 --> 00:21:05,230
open source frameworks that well

467
00:21:03,150 --> 00:21:07,390
vulnerable to this problem and

468
00:21:05,230 --> 00:21:09,640
practically compromised the ones that

469
00:21:07,390 --> 00:21:12,700
use them another notable research was

470
00:21:09,640 --> 00:21:15,610
zippered down by Pangu that showed a

471
00:21:12,700 --> 00:21:17,980
huge amount of ios and android apps that

472
00:21:15,610 --> 00:21:20,800
well and some of them are still are

473
00:21:17,980 --> 00:21:26,020
susceptible to part of elsa we will

474
00:21:20,800 --> 00:21:29,500
discuss this shortly so how can we fix

475
00:21:26,020 --> 00:21:31,510
it so usually the the approach in

476
00:21:29,500 --> 00:21:33,220
general in application security is just

477
00:21:31,510 --> 00:21:35,290
say you know this does not look

478
00:21:33,220 --> 00:21:37,960
legitimate right dot dot slash is not

479
00:21:35,290 --> 00:21:41,409
legitimate let's just wipe it away but

480
00:21:37,960 --> 00:21:43,930
one of the big problems in general when

481
00:21:41,410 --> 00:21:45,880
you sanitize input as I think all of us

482
00:21:43,930 --> 00:21:49,290
know is that it's very hard to implement

483
00:21:45,880 --> 00:21:51,880
and very easy to bypass in many cases so

484
00:21:49,290 --> 00:21:54,430
please raise your hand if you understand

485
00:21:51,880 --> 00:21:58,540
why that sanitation is actually a

486
00:21:54,430 --> 00:22:00,470
terrible sanitation okay so give you a

487
00:21:58,540 --> 00:22:03,629
very simple example the attacker

488
00:22:00,470 --> 00:22:06,060
just create an invalid path in the zip

489
00:22:03,630 --> 00:22:08,640
file by itself it will not work but

490
00:22:06,060 --> 00:22:10,950
thanks to the sanitization it will be

491
00:22:08,640 --> 00:22:12,750
transformed into a valid path of FL

492
00:22:10,950 --> 00:22:17,060
attack okay so this is a simple example

493
00:22:12,750 --> 00:22:17,060
that shows why that's so terrible so

494
00:22:17,570 --> 00:22:23,129
let's see how we could solve this

495
00:22:20,820 --> 00:22:25,590
problem so again we want to use the

496
00:22:23,130 --> 00:22:29,070
correct libraries given to us by the

497
00:22:25,590 --> 00:22:31,470
operating system in this case we would

498
00:22:29,070 --> 00:22:35,639
like to actually evaluate the final path

499
00:22:31,470 --> 00:22:39,600
by looking at the canonical path and as

500
00:22:35,640 --> 00:22:42,800
long as this final path still remains

501
00:22:39,600 --> 00:22:44,310
within our desired destination directory

502
00:22:42,800 --> 00:22:46,500
we're good

503
00:22:44,310 --> 00:22:51,990
otherwise we would just fail the attempt

504
00:22:46,500 --> 00:22:55,410
to unzip this file okay

505
00:22:51,990 --> 00:22:59,640
so let's try to combine several of those

506
00:22:55,410 --> 00:23:03,360
pitfalls into a modern use case that

507
00:22:59,640 --> 00:23:07,730
happens today so what I want to look at

508
00:23:03,360 --> 00:23:11,459
is a hybrid hybrid application it has

509
00:23:07,730 --> 00:23:14,750
some HTML and JavaScript that is

510
00:23:11,460 --> 00:23:18,420
actually used as a website that I use

511
00:23:14,750 --> 00:23:21,630
without my mobile application and it has

512
00:23:18,420 --> 00:23:25,350
native code that leverages additional

513
00:23:21,630 --> 00:23:29,430
api's from the device to extend my logic

514
00:23:25,350 --> 00:23:32,100
when I want to look at this site so

515
00:23:29,430 --> 00:23:35,690
we'll try to look at the live demo in

516
00:23:32,100 --> 00:23:35,689
just a second let me set it up

517
00:23:40,160 --> 00:23:45,860
so we have a tradition it worked it

518
00:23:42,590 --> 00:24:02,389
worked one time outside of 100 attempts

519
00:23:45,860 --> 00:24:05,060
so let's hope it works ok so we have a

520
00:24:02,390 --> 00:24:06,710
phone I'm not going to attack it yet I

521
00:24:05,060 --> 00:24:08,929
just want to go through the logic of the

522
00:24:06,710 --> 00:24:14,000
application I have an application that

523
00:24:08,930 --> 00:24:16,780
is a photo album manager and I wrapped

524
00:24:14,000 --> 00:24:21,170
it with some native code allowing

525
00:24:16,780 --> 00:24:25,220
basically two main interfaces extensions

526
00:24:21,170 --> 00:24:27,500
one as I don't want to enter my

527
00:24:25,220 --> 00:24:29,450
credentials again and again because it

528
00:24:27,500 --> 00:24:31,520
expires in the website I just want the

529
00:24:29,450 --> 00:24:34,760
native part to store it and inject it

530
00:24:31,520 --> 00:24:38,450
into the web part any time it needs to

531
00:24:34,760 --> 00:24:41,150
and the second part is of course in the

532
00:24:38,450 --> 00:24:43,310
web UI I can add an upload button but

533
00:24:41,150 --> 00:24:46,220
it's very cumbersome and I just want to

534
00:24:43,310 --> 00:24:48,110
leverage the native UI to already look

535
00:24:46,220 --> 00:24:50,710
at the file system see that there are

536
00:24:48,110 --> 00:24:53,780
new a plethora so that have not yet been

537
00:24:50,710 --> 00:24:57,430
uploaded such as the example there of

538
00:24:53,780 --> 00:24:59,960
the crowd here and suggest them in a

539
00:24:57,430 --> 00:25:03,980
very comfortable way to upload them

540
00:24:59,960 --> 00:25:06,260
quickly so the phone is already

541
00:25:03,980 --> 00:25:08,390
connected to a network that has an

542
00:25:06,260 --> 00:25:13,790
attacker on it I have not started attack

543
00:25:08,390 --> 00:25:24,620
yet we will start it now and what I'm

544
00:25:13,790 --> 00:25:29,389
doing here is a model that is going to

545
00:25:24,620 --> 00:25:32,719
look for a cache some cache zip that is

546
00:25:29,390 --> 00:25:34,100
loaded from an unsecured source the

547
00:25:32,720 --> 00:25:35,660
developer didn't think there is any

548
00:25:34,100 --> 00:25:37,010
problem with that he's doing the

549
00:25:35,660 --> 00:25:39,770
authentication correctly everything

550
00:25:37,010 --> 00:25:42,890
works correctly the cache is just some

551
00:25:39,770 --> 00:25:44,999
zip with some images to have a quicker

552
00:25:42,890 --> 00:25:50,489
start up

553
00:25:44,999 --> 00:25:54,509
so let's kill the app and reload it now

554
00:25:50,489 --> 00:25:57,629
the app is going to load the cache again

555
00:25:54,509 --> 00:26:00,149
and what what we can see here is that

556
00:25:57,629 --> 00:26:03,719
there was an injection reported by our

557
00:26:00,149 --> 00:26:07,158
attack tool basically what it did was to

558
00:26:03,720 --> 00:26:10,889
catch this zip that was passed and

559
00:26:07,159 --> 00:26:14,970
inject malicious malicious JavaScript

560
00:26:10,889 --> 00:26:16,678
code with a filename that leverages path

561
00:26:14,970 --> 00:26:18,090
traversal as we've looked at the

562
00:26:16,679 --> 00:26:22,609
application we know that it is

563
00:26:18,090 --> 00:26:26,869
susceptible to path reversal attacks

564
00:26:22,609 --> 00:26:32,158
okay so now look now let's look at the

565
00:26:26,869 --> 00:26:33,779
command and control console okay so the

566
00:26:32,159 --> 00:26:36,840
first thing that we can see here is that

567
00:26:33,779 --> 00:26:39,059
I've already caught the D credentials

568
00:26:36,840 --> 00:26:41,549
but the interesting part here was that I

569
00:26:39,059 --> 00:26:44,279
didn't leverage any network attack

570
00:26:41,549 --> 00:26:46,109
during the authentication again the

571
00:26:44,279 --> 00:26:49,139
authentication was secure I was not able

572
00:26:46,109 --> 00:26:51,840
to catch the credentials at that face

573
00:26:49,139 --> 00:26:55,799
but what our malicious code that was

574
00:26:51,840 --> 00:26:58,709
extracted did was actually to take hold

575
00:26:55,799 --> 00:27:01,460
of the bridge between the web view and

576
00:26:58,710 --> 00:27:04,710
the native part of the application

577
00:27:01,460 --> 00:27:08,309
listening in on any events being passed

578
00:27:04,710 --> 00:27:10,799
through either side so the first thing

579
00:27:08,309 --> 00:27:12,749
that we did was to take a hold of the

580
00:27:10,799 --> 00:27:14,879
credentials but now we have access only

581
00:27:12,749 --> 00:27:17,789
to the web part we want to do something

582
00:27:14,879 --> 00:27:19,859
more interesting want to actually go and

583
00:27:17,789 --> 00:27:22,619
run something on the native part of the

584
00:27:19,859 --> 00:27:27,239
application and taking hold photos that

585
00:27:22,619 --> 00:27:34,379
never left the device so if we send our

586
00:27:27,239 --> 00:27:38,789
command to the device okay we start

587
00:27:34,379 --> 00:27:43,559
getting up loads of photos that have

588
00:27:38,789 --> 00:27:45,179
never left the device so let's go back

589
00:27:43,559 --> 00:27:46,918
to the presentation and have a quick

590
00:27:45,179 --> 00:27:48,809
summary of this demo and understand what

591
00:27:46,919 --> 00:27:50,340
happened here again we have a man in the

592
00:27:48,809 --> 00:27:53,489
middle he sits on the network he sees

593
00:27:50,340 --> 00:27:55,738
the request for a sip that is not secure

594
00:27:53,489 --> 00:27:56,850
he catches this zip this he just

595
00:27:55,739 --> 00:28:00,630
contains at least five

596
00:27:56,850 --> 00:28:01,050
and we inject some malicious code using

597
00:28:00,630 --> 00:28:03,480
again

598
00:28:01,050 --> 00:28:06,899
path traversal again the interesting

599
00:28:03,480 --> 00:28:10,140
part here was that using this malicious

600
00:28:06,900 --> 00:28:14,510
code we were actually able through the

601
00:28:10,140 --> 00:28:18,780
webview to trigger and run native code

602
00:28:14,510 --> 00:28:22,290
that we should never have gained access

603
00:28:18,780 --> 00:28:23,639
to from the web yeah and I think there

604
00:28:22,290 --> 00:28:26,190
was a lot of discussion over there's

605
00:28:23,640 --> 00:28:28,530
about the value of bridges of hybrid

606
00:28:26,190 --> 00:28:30,810
apps but I think it's a good incarnation

607
00:28:28,530 --> 00:28:34,530
good demonstration for the additional

608
00:28:30,810 --> 00:28:36,330
risk of having that model of bridges etc

609
00:28:34,530 --> 00:28:39,510
and the importance of having proper

610
00:28:36,330 --> 00:28:42,840
skill coding within them

611
00:28:39,510 --> 00:28:45,960
so to summarize I think we discussed a

612
00:28:42,840 --> 00:28:47,699
few examples and many of them are

613
00:28:45,960 --> 00:28:49,650
actually repeating problems of their

614
00:28:47,700 --> 00:28:52,140
many years so many people like to talk

615
00:28:49,650 --> 00:28:54,870
about this area as a never-ending

616
00:28:52,140 --> 00:28:57,390
problem but I think there are specific

617
00:28:54,870 --> 00:28:59,429
things we can do as an industry so we

618
00:28:57,390 --> 00:29:01,740
didn't use the damage of those kind of

619
00:28:59,430 --> 00:29:05,610
problems so first one is obviously

620
00:29:01,740 --> 00:29:08,280
education I think from experience those

621
00:29:05,610 --> 00:29:11,129
problems happen a lot but once people

622
00:29:08,280 --> 00:29:13,800
see them and and learn very quickly

623
00:29:11,130 --> 00:29:16,020
about them it becomes trivial not to

624
00:29:13,800 --> 00:29:17,730
fall for that I think our responsibility

625
00:29:16,020 --> 00:29:21,350
is to make sure that in our

626
00:29:17,730 --> 00:29:24,000
organisations we fitted ly provide

627
00:29:21,350 --> 00:29:26,669
presentations such as this one where we

628
00:29:24,000 --> 00:29:28,110
covered the common coding pitfalls and

629
00:29:26,670 --> 00:29:30,870
make sure that any developer and

630
00:29:28,110 --> 00:29:33,240
organization has this in mind we've seen

631
00:29:30,870 --> 00:29:35,550
this as a very power month process to

632
00:29:33,240 --> 00:29:38,550
adduce those kind of problems in our

633
00:29:35,550 --> 00:29:41,460
organization another thing is that I

634
00:29:38,550 --> 00:29:43,409
didn't touch this earlier but when you

635
00:29:41,460 --> 00:29:45,570
would go and look at many of the

636
00:29:43,410 --> 00:29:48,210
processes like even unpacking a zip file

637
00:29:45,570 --> 00:29:50,250
you will go to stack overflow second

638
00:29:48,210 --> 00:29:52,200
flow provides a great solutions simple

639
00:29:50,250 --> 00:29:54,570
solutions the problem is that even to

640
00:29:52,200 --> 00:29:57,210
these very days you will find a lot of

641
00:29:54,570 --> 00:29:59,700
implementations that are just vulnerable

642
00:29:57,210 --> 00:30:02,250
so just copying text from there is

643
00:29:59,700 --> 00:30:03,840
really risky to conclude there is

644
00:30:02,250 --> 00:30:05,520
something we believe that the vendors

645
00:30:03,840 --> 00:30:07,889
themselves can do and that is the

646
00:30:05,520 --> 00:30:08,580
importance of secured by design secure

647
00:30:07,890 --> 00:30:10,359
by default

648
00:30:08,580 --> 00:30:12,549
egle mentioned earlier

649
00:30:10,359 --> 00:30:15,158
the configuration in cloud services that

650
00:30:12,549 --> 00:30:18,399
by default might leads us to make

651
00:30:15,159 --> 00:30:22,029
mistakes the same applies for path to

652
00:30:18,399 --> 00:30:24,219
vessel if you now go to Java you still

653
00:30:22,029 --> 00:30:26,470
have just a way to implement what we

654
00:30:24,220 --> 00:30:28,960
just shown even though the need to

655
00:30:26,470 --> 00:30:31,600
unpack zip files is extremely common and

656
00:30:28,960 --> 00:30:33,970
our expectation is for vendors to

657
00:30:31,600 --> 00:30:36,059
provide a different way to just as an

658
00:30:33,970 --> 00:30:36,059
example

