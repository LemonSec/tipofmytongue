1
00:00:01,420 --> 00:00:05,279
[Music]

2
00:00:05,279 --> 00:00:07,120
thank you so much for that welcome and

3
00:00:07,120 --> 00:00:08,880
we're both very happy to be here to

4
00:00:08,880 --> 00:00:12,320
present this topic today at owas absec

5
00:00:12,320 --> 00:00:14,400
like um previously introduced my name is

6
00:00:14,400 --> 00:00:16,480
megan and i'm here with uma and we're

7
00:00:16,480 --> 00:00:18,000
going to be presenting practical threat

8
00:00:18,000 --> 00:00:20,080
modeling for real world and cloud

9
00:00:20,080 --> 00:00:21,760
situations in our hybrid and work from

10
00:00:21,760 --> 00:00:23,680
home world

11
00:00:23,680 --> 00:00:25,119
so to take you through we have a little

12
00:00:25,119 --> 00:00:27,039
bit of an agenda we'll be doing

13
00:00:27,039 --> 00:00:29,519
introductions and then we'll go over how

14
00:00:29,519 --> 00:00:31,679
to threat model with examples

15
00:00:31,679 --> 00:00:34,079
and then we will be doing some actual

16
00:00:34,079 --> 00:00:35,840
practicing with threat bottling so um

17
00:00:35,840 --> 00:00:37,520
will be taking us through that and then

18
00:00:37,520 --> 00:00:38,960
we'll go through some questions and

19
00:00:38,960 --> 00:00:41,200
answers so whatever questions you might

20
00:00:41,200 --> 00:00:43,040
have please feel free to submit those

21
00:00:43,040 --> 00:00:44,640
through the hula app and we'll be going

22
00:00:44,640 --> 00:00:45,760
through those

23
00:00:45,760 --> 00:00:47,600
so who am i

24
00:00:47,600 --> 00:00:49,600
well i have had a variety of different

25
00:00:49,600 --> 00:00:52,879
experiences in technology um i have

26
00:00:52,879 --> 00:00:58,320
about 10 years of it experience

27
00:00:58,399 --> 00:01:00,079
a little bit more than that and i have a

28
00:01:00,079 --> 00:01:02,480
bachelor's in cyber security with a

29
00:01:02,480 --> 00:01:05,360
focus on network system administration

30
00:01:05,360 --> 00:01:07,600
and a master's in leadership

31
00:01:07,600 --> 00:01:09,360
and i've done

32
00:01:09,360 --> 00:01:10,720
just you know

33
00:01:10,720 --> 00:01:13,760
a variety of different things be it

34
00:01:13,760 --> 00:01:16,240
exploring

35
00:01:16,240 --> 00:01:19,680
building with electronics

36
00:01:19,680 --> 00:01:22,240
threat intelligence risk assessment so

37
00:01:22,240 --> 00:01:24,400
right now i'm doing threat intelligence

38
00:01:24,400 --> 00:01:26,479
and tremendously enjoying that

39
00:01:26,479 --> 00:01:27,920
i think it's so important that we

40
00:01:27,920 --> 00:01:29,200
recognize

41
00:01:29,200 --> 00:01:31,759
that we are not an island and we didn't

42
00:01:31,759 --> 00:01:32,960
get here

43
00:01:32,960 --> 00:01:35,200
just by doing one thing or meeting one

44
00:01:35,200 --> 00:01:36,960
person or

45
00:01:36,960 --> 00:01:39,119
connecting with one group and so i'm

46
00:01:39,119 --> 00:01:41,200
fairly involved with the information

47
00:01:41,200 --> 00:01:44,079
security community and a number of

48
00:01:44,079 --> 00:01:46,720
organizations both as a mentor and as

49
00:01:46,720 --> 00:01:48,159
someone who believes in constantly

50
00:01:48,159 --> 00:01:50,640
learning as a mentee as well

51
00:01:50,640 --> 00:01:52,320
in fact uma and i actually met through

52
00:01:52,320 --> 00:01:54,159
cloud security alliance the washington

53
00:01:54,159 --> 00:01:56,159
dc chapter and um she runs the

54
00:01:56,159 --> 00:01:58,079
operations and i have i help provide

55
00:01:58,079 --> 00:01:59,680
some support with that

56
00:01:59,680 --> 00:02:01,840
i also love to investigate research so

57
00:02:01,840 --> 00:02:03,680
i'm a research advisory board member for

58
00:02:03,680 --> 00:02:05,920
breaking barriers in cyber security

59
00:02:05,920 --> 00:02:08,878
and then i love to travel so i've been

60
00:02:08,878 --> 00:02:10,878
to all the states in the united states

61
00:02:10,878 --> 00:02:12,879
several the territories and i'd like to

62
00:02:12,879 --> 00:02:14,239
go to all the continents one day i'm

63
00:02:14,239 --> 00:02:16,080
about halfway there

64
00:02:16,080 --> 00:02:19,200
and i also do some podcasting about ai

65
00:02:19,200 --> 00:02:21,360
ethics research and

66
00:02:21,360 --> 00:02:22,720
artificial intelligence and emerging

67
00:02:22,720 --> 00:02:25,520
technology and data loss prevention

68
00:02:25,520 --> 00:02:27,520
then i will turn it over to uma to share

69
00:02:27,520 --> 00:02:30,000
about herself

70
00:02:33,280 --> 00:02:35,280
all right hopefully you are able to see

71
00:02:35,280 --> 00:02:37,519
my screen um

72
00:02:37,519 --> 00:02:38,319
good

73
00:02:38,319 --> 00:02:41,840
thank you megan and thank you moderator

74
00:02:41,840 --> 00:02:44,080
hello everyone and thanks for attending

75
00:02:44,080 --> 00:02:45,680
our webinar today

76
00:02:45,680 --> 00:02:48,959
my name is umaraj gopal i have 20 plus

77
00:02:48,959 --> 00:02:51,280
years of id experience i came to this

78
00:02:51,280 --> 00:02:54,959
country for about uh 1998 in r2k

79
00:02:54,959 --> 00:02:58,400
projects in the past decade i've been

80
00:02:58,400 --> 00:03:00,159
mostly focused on

81
00:03:00,159 --> 00:03:03,040
information security compliance and

82
00:03:03,040 --> 00:03:05,840
third party assessments

83
00:03:05,840 --> 00:03:07,680
i have completed masters in cyber

84
00:03:07,680 --> 00:03:10,319
security and information assurance here

85
00:03:10,319 --> 00:03:11,360
are some

86
00:03:11,360 --> 00:03:14,159
industrial certifications i have taken

87
00:03:14,159 --> 00:03:16,319
over the year

88
00:03:16,319 --> 00:03:18,879
facts about me uh these are my tour of

89
00:03:18,879 --> 00:03:21,200
various cyber security platforms so it's

90
00:03:21,200 --> 00:03:23,360
very critical to give back and very

91
00:03:23,360 --> 00:03:26,319
critical to make sure um the people who

92
00:03:26,319 --> 00:03:28,239
wants to get in to break into cyber

93
00:03:28,239 --> 00:03:31,360
security get the guidance they need so

94
00:03:31,360 --> 00:03:34,239
please free to uh hit me up on linkedin

95
00:03:34,239 --> 00:03:38,080
uh but we'll see where we can get there

96
00:03:38,080 --> 00:03:42,640
if you catch me reading any books or uh

97
00:03:42,640 --> 00:03:45,519
looking at youtube videos or podcasts

98
00:03:45,519 --> 00:03:47,920
mostly it is going to be on cyber in the

99
00:03:47,920 --> 00:03:50,560
recent years um i've been a board member

100
00:03:50,560 --> 00:03:52,799
for cloud security alliance washington

101
00:03:52,799 --> 00:03:56,400
dc chapter we run monthly webinars uh

102
00:03:56,400 --> 00:03:59,599
please check us out and i also

103
00:03:59,599 --> 00:04:02,000
co-authored the zero trust architecture

104
00:04:02,000 --> 00:04:02,799
for

105
00:04:02,799 --> 00:04:07,040
uh the the dc chapter uh research team

106
00:04:07,040 --> 00:04:09,280
also check it out it is up and on our

107
00:04:09,280 --> 00:04:10,720
website

108
00:04:10,720 --> 00:04:13,680
one fun fact about me um is i climbed

109
00:04:13,680 --> 00:04:16,320
the mount himalayas prior to pandemic

110
00:04:16,320 --> 00:04:19,519
and it was a quite an experience

111
00:04:19,519 --> 00:04:21,680
all right let's get into the meat of

112
00:04:21,680 --> 00:04:24,160
this presentation

113
00:04:24,160 --> 00:04:27,120
what is threat modeling

114
00:04:27,120 --> 00:04:30,240
there is one card that comes to my mind

115
00:04:30,240 --> 00:04:32,880
when we talk about threat modeling this

116
00:04:32,880 --> 00:04:35,360
is none of this is said by none other

117
00:04:35,360 --> 00:04:39,199
than our key no speaker today adam

118
00:04:39,199 --> 00:04:42,080
he says shrek modeling is a fancy name

119
00:04:42,080 --> 00:04:45,360
for something we do instinctively

120
00:04:45,360 --> 00:04:49,120
i love this card here is why

121
00:04:49,120 --> 00:04:52,560
imagine you want to go for a walk

122
00:04:52,560 --> 00:04:55,120
what would you do you would do a quick

123
00:04:55,120 --> 00:04:57,280
health check to make sure

124
00:04:57,280 --> 00:04:58,960
um you are good to go you are

125
00:04:58,960 --> 00:05:01,199
comfortable going for a walk

126
00:05:01,199 --> 00:05:03,840
and you don't have any pains

127
00:05:03,840 --> 00:05:05,840
you will also check weather

128
00:05:05,840 --> 00:05:08,320
to make sure it's not raining or it's

129
00:05:08,320 --> 00:05:10,800
not super cold or hard

130
00:05:10,800 --> 00:05:13,440
accordingly you will take things that

131
00:05:13,440 --> 00:05:15,120
will help you

132
00:05:15,120 --> 00:05:19,600
you also will grab phones or headset

133
00:05:19,600 --> 00:05:22,160
possibly take water and little snacks if

134
00:05:22,160 --> 00:05:24,560
it is longer walk

135
00:05:24,560 --> 00:05:26,639
you are going to let the people know

136
00:05:26,639 --> 00:05:28,479
who's living with you so that they don't

137
00:05:28,479 --> 00:05:30,479
have to worry about when you're stepping

138
00:05:30,479 --> 00:05:31,759
away

139
00:05:31,759 --> 00:05:35,039
and you also use the known part

140
00:05:35,039 --> 00:05:36,800
what did you just do

141
00:05:36,800 --> 00:05:39,560
you just did the threat modeling

142
00:05:39,560 --> 00:05:41,120
subconsciously

143
00:05:41,120 --> 00:05:43,680
you looked at what you want to do and

144
00:05:43,680 --> 00:05:45,840
what could go wrong

145
00:05:45,840 --> 00:05:49,199
and what you can do to mitigate them or

146
00:05:49,199 --> 00:05:50,560
if there is something that you can

147
00:05:50,560 --> 00:05:52,080
accept the rest you would accept the

148
00:05:52,080 --> 00:05:54,400
risk and move on

149
00:05:54,400 --> 00:05:57,360
for example you take the phone into even

150
00:05:57,360 --> 00:05:58,960
something happens it's kind of a

151
00:05:58,960 --> 00:06:00,720
learning mechanism

152
00:06:00,720 --> 00:06:03,280
where you're able to reach someone for

153
00:06:03,280 --> 00:06:05,120
help

154
00:06:05,120 --> 00:06:07,520
likewise water your performance you

155
00:06:07,520 --> 00:06:08,800
don't want to get

156
00:06:08,800 --> 00:06:10,720
your performance affected so you would

157
00:06:10,720 --> 00:06:13,120
take water or snack to make sure you can

158
00:06:13,120 --> 00:06:15,680
go your availability of doing this is

159
00:06:15,680 --> 00:06:17,360
not affected

160
00:06:17,360 --> 00:06:19,280
so this is why

161
00:06:19,280 --> 00:06:21,759
things that we instinctively think about

162
00:06:21,759 --> 00:06:23,360
what the threat is

163
00:06:23,360 --> 00:06:26,720
does it apply to me if it does

164
00:06:26,720 --> 00:06:29,440
what can we do to control

165
00:06:29,440 --> 00:06:30,720
so i'm gonna

166
00:06:30,720 --> 00:06:33,680
get back to megan who's gonna take us us

167
00:06:33,680 --> 00:06:35,759
through what the threat modelings and

168
00:06:35,759 --> 00:06:38,080
why and how we do it

169
00:06:38,080 --> 00:06:40,080
and i will circle back with the

170
00:06:40,080 --> 00:06:41,440
practical

171
00:06:41,440 --> 00:06:44,400
example that we all can do together

172
00:06:44,400 --> 00:06:46,000
back to you megan

173
00:06:46,000 --> 00:06:49,160
thank you

174
00:06:52,000 --> 00:06:54,720
okay so um just took us through

175
00:06:54,720 --> 00:06:57,759
a very real world example that is

176
00:06:57,759 --> 00:06:59,840
something that you know

177
00:06:59,840 --> 00:07:02,319
hopefully we're we're going outside at

178
00:07:02,319 --> 00:07:04,160
least where we are on the east coast

179
00:07:04,160 --> 00:07:07,039
here it's been a lovely weather week um

180
00:07:07,039 --> 00:07:09,440
the leaves are falling

181
00:07:09,440 --> 00:07:10,479
and

182
00:07:10,479 --> 00:07:11,680
you know you can kind of think about

183
00:07:11,680 --> 00:07:12,720
planning

184
00:07:12,720 --> 00:07:15,759
and how that is going to relate to

185
00:07:15,759 --> 00:07:17,199
threat modeling and something you might

186
00:07:17,199 --> 00:07:19,280
do instinctively right so everyone can

187
00:07:19,280 --> 00:07:21,520
kind of place themselves literally into

188
00:07:21,520 --> 00:07:23,280
those shoes

189
00:07:23,280 --> 00:07:25,919
so another thing that we might think

190
00:07:25,919 --> 00:07:29,520
about is how many things changed

191
00:07:29,520 --> 00:07:30,560
during

192
00:07:30,560 --> 00:07:32,319
this past

193
00:07:32,319 --> 00:07:33,199
year

194
00:07:33,199 --> 00:07:35,919
and into 2021 as well

195
00:07:35,919 --> 00:07:37,120
so

196
00:07:37,120 --> 00:07:38,000
work

197
00:07:38,000 --> 00:07:39,520
in 2019

198
00:07:39,520 --> 00:07:43,280
and then march in 2020 um huge changes

199
00:07:43,280 --> 00:07:44,800
for a lot of people

200
00:07:44,800 --> 00:07:46,160
and some of you might not have had any

201
00:07:46,160 --> 00:07:48,639
changes depending on what you do it

202
00:07:48,639 --> 00:07:52,240
might be that your work always was work

203
00:07:52,240 --> 00:07:53,440
from home

204
00:07:53,440 --> 00:07:56,240
and it continued that way

205
00:07:56,240 --> 00:07:58,560
but others of you it might be

206
00:07:58,560 --> 00:07:59,520
that

207
00:07:59,520 --> 00:08:01,520
you now

208
00:08:01,520 --> 00:08:03,599
do work from home and you don't have a

209
00:08:03,599 --> 00:08:05,919
return date i have a number of friends

210
00:08:05,919 --> 00:08:09,039
who work in government positions and

211
00:08:09,039 --> 00:08:10,720
they don't have a specific return to

212
00:08:10,720 --> 00:08:13,280
office date and so you have to make a

213
00:08:13,280 --> 00:08:16,879
number of adjustments and think through

214
00:08:16,879 --> 00:08:19,120
what are different things

215
00:08:19,120 --> 00:08:20,960
that changed

216
00:08:20,960 --> 00:08:21,919
when

217
00:08:21,919 --> 00:08:24,160
those changed happen

218
00:08:24,160 --> 00:08:25,759
and as you think through those changes

219
00:08:25,759 --> 00:08:28,560
you might think about well first

220
00:08:28,560 --> 00:08:30,879
you know

221
00:08:31,759 --> 00:08:35,360
i just started working at home and i

222
00:08:35,360 --> 00:08:38,080
had maybe some bandwidth issues and i

223
00:08:38,080 --> 00:08:39,519
had to change that

224
00:08:39,519 --> 00:08:42,320
and maybe i had

225
00:08:42,320 --> 00:08:43,279
you know

226
00:08:43,279 --> 00:08:46,160
work documents that i had out or i had

227
00:08:46,160 --> 00:08:48,560
my screen open and maybe it was on a

228
00:08:48,560 --> 00:08:50,240
call and a family member was home and

229
00:08:50,240 --> 00:08:51,440
maybe some of that information was

230
00:08:51,440 --> 00:08:53,760
sensitive and shouldn't have been heard

231
00:08:53,760 --> 00:08:54,959
and so you have to start thinking about

232
00:08:54,959 --> 00:08:57,680
like maybe my workplaces actually

233
00:08:57,680 --> 00:08:58,959
changed

234
00:08:58,959 --> 00:09:01,279
and where you worked changed from home

235
00:09:01,279 --> 00:09:03,600
as the progression of work from home

236
00:09:03,600 --> 00:09:07,600
changed and so those are ways that work

237
00:09:07,600 --> 00:09:09,760
from home threat modeling might have

238
00:09:09,760 --> 00:09:10,720
happened

239
00:09:10,720 --> 00:09:12,000
where you might have actually

240
00:09:12,000 --> 00:09:14,640
instinctively changed things

241
00:09:14,640 --> 00:09:17,279
as you were iteratively trying

242
00:09:17,279 --> 00:09:19,279
what works and what doesn't work for my

243
00:09:19,279 --> 00:09:21,600
specific situation

244
00:09:21,600 --> 00:09:23,360
and so as you can kind of think through

245
00:09:23,360 --> 00:09:25,440
like did you change things what has

246
00:09:25,440 --> 00:09:28,000
changed how those changes happen

247
00:09:28,000 --> 00:09:29,920
um those would be some of the ways that

248
00:09:29,920 --> 00:09:32,560
you might have gone through

249
00:09:32,560 --> 00:09:34,720
other things that might have happened

250
00:09:34,720 --> 00:09:36,880
you know when you were

251
00:09:36,880 --> 00:09:39,600
in an office you might have had a whole

252
00:09:39,600 --> 00:09:42,240
team that was devoted to pushing updates

253
00:09:42,240 --> 00:09:44,399
and making sure that everything

254
00:09:44,399 --> 00:09:46,240
that you were doing

255
00:09:46,240 --> 00:09:48,480
um was fully patched and that they were

256
00:09:48,480 --> 00:09:49,519
checking all those different things

257
00:09:49,519 --> 00:09:51,680
ahead of time um

258
00:09:51,680 --> 00:09:53,839
and you know maybe you saw a couple

259
00:09:53,839 --> 00:09:55,600
weeks ago with the

260
00:09:55,600 --> 00:09:57,040
um

261
00:09:57,040 --> 00:10:01,120
with npm that you know oh hey i do some

262
00:10:01,120 --> 00:10:02,720
work with that

263
00:10:02,720 --> 00:10:04,959
and i need to actually now do a self

264
00:10:04,959 --> 00:10:07,440
check at home

265
00:10:07,440 --> 00:10:10,320
what version do i have

266
00:10:10,320 --> 00:10:13,519
of this and so you might be doing at

267
00:10:13,519 --> 00:10:14,640
home

268
00:10:14,640 --> 00:10:17,360
more self checks of your technology

269
00:10:17,360 --> 00:10:18,720
than you did

270
00:10:18,720 --> 00:10:21,120
because you might be mixing different

271
00:10:21,120 --> 00:10:22,560
things in a way that you weren't with

272
00:10:22,560 --> 00:10:25,120
your at-home network maybe you are

273
00:10:25,120 --> 00:10:27,040
isolating things in a different way as

274
00:10:27,040 --> 00:10:28,079
well too

275
00:10:28,079 --> 00:10:30,560
so all of these are things that you

276
00:10:30,560 --> 00:10:32,560
might be thinking through

277
00:10:32,560 --> 00:10:33,360
um

278
00:10:33,360 --> 00:10:35,279
and changes that

279
00:10:35,279 --> 00:10:38,320
you might just be making

280
00:10:38,320 --> 00:10:40,480
very very instinctively

281
00:10:40,480 --> 00:10:42,079
so we've gone through

282
00:10:42,079 --> 00:10:43,920
um an example of just being able to go

283
00:10:43,920 --> 00:10:45,360
for a walk

284
00:10:45,360 --> 00:10:47,200
of thinking through changes that might

285
00:10:47,200 --> 00:10:49,600
have made that you might have made

286
00:10:49,600 --> 00:10:50,720
um

287
00:10:50,720 --> 00:10:53,519
because of circumstances that happen um

288
00:10:53,519 --> 00:10:55,600
globally

289
00:10:55,600 --> 00:10:56,720
and

290
00:10:56,720 --> 00:10:58,880
hopefully you know you're at this talk

291
00:10:58,880 --> 00:11:02,880
the the talk title caught your eye

292
00:11:02,880 --> 00:11:04,959
hopefully you

293
00:11:04,959 --> 00:11:06,240
think maybe

294
00:11:06,240 --> 00:11:08,399
threat modeling should exist and it

295
00:11:08,399 --> 00:11:10,079
should be something that one does and

296
00:11:10,079 --> 00:11:12,399
maybe it's part of the work that you do

297
00:11:12,399 --> 00:11:14,959
so we're gonna just quickly go through

298
00:11:14,959 --> 00:11:17,600
why we should threat model and this

299
00:11:17,600 --> 00:11:18,880
could also be something that you take

300
00:11:18,880 --> 00:11:20,640
back to your team if it's not something

301
00:11:20,640 --> 00:11:22,959
that you are currently doing and

302
00:11:22,959 --> 00:11:26,079
something that you want to have added

303
00:11:26,079 --> 00:11:26,959
to

304
00:11:26,959 --> 00:11:29,040
your systems and designs

305
00:11:29,040 --> 00:11:30,880
so one of the reasons

306
00:11:30,880 --> 00:11:33,920
is that it does promote a

307
00:11:33,920 --> 00:11:35,760
security culture

308
00:11:35,760 --> 00:11:38,720
in your practices

309
00:11:38,720 --> 00:11:40,640
and design practices

310
00:11:40,640 --> 00:11:42,160
and really trying to make sure that

311
00:11:42,160 --> 00:11:44,480
within that security culture that you're

312
00:11:44,480 --> 00:11:46,959
shifting security left

313
00:11:46,959 --> 00:11:48,800
that you are making sure

314
00:11:48,800 --> 00:11:51,040
that you're trying to

315
00:11:51,040 --> 00:11:53,040
design things and think about things in

316
00:11:53,040 --> 00:11:55,680
a very proactive manner

317
00:11:55,680 --> 00:11:57,519
and thinking about things from the

318
00:11:57,519 --> 00:11:59,360
design life cycle

319
00:11:59,360 --> 00:12:00,399
and

320
00:12:00,399 --> 00:12:02,800
if you're able to

321
00:12:02,800 --> 00:12:06,880
come up with oh this could be an issue

322
00:12:06,880 --> 00:12:10,160
and fix that configuration

323
00:12:10,160 --> 00:12:12,560
prior to it being an issue that is going

324
00:12:12,560 --> 00:12:13,920
to cost

325
00:12:13,920 --> 00:12:17,120
much less money in the long run

326
00:12:17,120 --> 00:12:18,880
now it could be

327
00:12:18,880 --> 00:12:19,760
that

328
00:12:19,760 --> 00:12:20,800
you

329
00:12:20,800 --> 00:12:22,480
as a team are not

330
00:12:22,480 --> 00:12:24,320
currently threat modeling you already

331
00:12:24,320 --> 00:12:26,399
have some things in production

332
00:12:26,399 --> 00:12:28,720
so that's perfectly fine

333
00:12:28,720 --> 00:12:32,160
it is okay to add in threat modeling if

334
00:12:32,160 --> 00:12:34,240
you don't already have it

335
00:12:34,240 --> 00:12:36,399
and so some of the reasons you might

336
00:12:36,399 --> 00:12:39,680
want to do that are because

337
00:12:39,680 --> 00:12:40,560
when

338
00:12:40,560 --> 00:12:43,360
in production but not already shipped

339
00:12:43,360 --> 00:12:45,680
it can allow you to think through

340
00:12:45,680 --> 00:12:47,519
hey these might be some problems that

341
00:12:47,519 --> 00:12:50,160
might occur

342
00:12:50,480 --> 00:12:53,040
that an attacker might find

343
00:12:53,040 --> 00:12:54,720
and so same thing

344
00:12:54,720 --> 00:12:56,560
you would be able to save

345
00:12:56,560 --> 00:13:00,000
from a cost perspective

346
00:13:00,000 --> 00:13:02,560
and then because you're working across

347
00:13:02,560 --> 00:13:04,800
different teams and we'll i'll talk

348
00:13:04,800 --> 00:13:06,639
through this a little bit later

349
00:13:06,639 --> 00:13:08,880
and i know we'll also discuss this when

350
00:13:08,880 --> 00:13:10,079
she goes through

351
00:13:10,079 --> 00:13:11,440
her example

352
00:13:11,440 --> 00:13:13,360
you can really see how it can build

353
00:13:13,360 --> 00:13:15,279
teamwork because you're all working

354
00:13:15,279 --> 00:13:16,480
together

355
00:13:16,480 --> 00:13:18,079
to make

356
00:13:18,079 --> 00:13:19,680
the systems

357
00:13:19,680 --> 00:13:21,680
the things that you design

358
00:13:21,680 --> 00:13:24,880
more secure and so it's it's with a very

359
00:13:24,880 --> 00:13:26,760
um

360
00:13:26,760 --> 00:13:28,399
defenders-based

361
00:13:28,399 --> 00:13:30,720
approach um

362
00:13:30,720 --> 00:13:33,120
really thinking through you know okay

363
00:13:33,120 --> 00:13:34,399
these are maybe some things that could

364
00:13:34,399 --> 00:13:37,360
go wrong but how do we fix it how do we

365
00:13:37,360 --> 00:13:39,839
get to that before it would happen

366
00:13:39,839 --> 00:13:42,720
um to go back to uma's example earlier

367
00:13:42,720 --> 00:13:44,880
you know you think about when you're

368
00:13:44,880 --> 00:13:46,639
gonna go for a walk

369
00:13:46,639 --> 00:13:49,120
and you check the weather if you see

370
00:13:49,120 --> 00:13:51,360
it's a high likelihood of rain you bring

371
00:13:51,360 --> 00:13:53,279
that umbrella

372
00:13:53,279 --> 00:13:54,720
sometimes you don't even need the

373
00:13:54,720 --> 00:13:56,639
umbrella but the fact that you have it

374
00:13:56,639 --> 00:13:58,079
right you've done that preparation and

375
00:13:58,079 --> 00:13:59,600
you've been proactive

376
00:13:59,600 --> 00:14:01,040
and so that's what a lot of this is

377
00:14:01,040 --> 00:14:03,600
about and then you think about how then

378
00:14:03,600 --> 00:14:04,880
as a team

379
00:14:04,880 --> 00:14:07,040
you're all helping each other and then

380
00:14:07,040 --> 00:14:08,720
that builds that team culture and

381
00:14:08,720 --> 00:14:10,800
collaboration

382
00:14:10,800 --> 00:14:11,680
so

383
00:14:11,680 --> 00:14:13,519
we've gone through some examples we've

384
00:14:13,519 --> 00:14:15,360
gone through why we do it

385
00:14:15,360 --> 00:14:17,040
now let's actually get into some of the

386
00:14:17,040 --> 00:14:20,000
how and engaging with it so i'm first

387
00:14:20,000 --> 00:14:23,440
going to be very very broad with this

388
00:14:23,440 --> 00:14:25,120
and then i'm going to go into some

389
00:14:25,120 --> 00:14:28,000
specific examples

390
00:14:28,000 --> 00:14:30,720
so broaden the narrow

391
00:14:30,720 --> 00:14:33,360
so it's not that there's any one single

392
00:14:33,360 --> 00:14:36,320
right way or one approach to do this

393
00:14:36,320 --> 00:14:38,639
but what we're going to do today is go

394
00:14:38,639 --> 00:14:41,360
through a generalized framework

395
00:14:41,360 --> 00:14:42,480
and then

396
00:14:42,480 --> 00:14:46,399
go through stages that can be placed

397
00:14:46,399 --> 00:14:48,720
within this flight framework

398
00:14:48,720 --> 00:14:52,320
and then also give some examples

399
00:14:52,320 --> 00:14:53,279
so

400
00:14:53,279 --> 00:14:55,600
one place to start is what exactly are

401
00:14:55,600 --> 00:14:57,120
you working on

402
00:14:57,120 --> 00:14:59,279
you know what projects

403
00:14:59,279 --> 00:15:01,199
are these what systems are you building

404
00:15:01,199 --> 00:15:02,320
what what different things you're

405
00:15:02,320 --> 00:15:04,560
working on

406
00:15:04,560 --> 00:15:06,720
what can go wrong which that question in

407
00:15:06,720 --> 00:15:09,040
itself can be kind of an overwhelming

408
00:15:09,040 --> 00:15:10,160
question

409
00:15:10,160 --> 00:15:13,600
and so asking it can be a brave thing to

410
00:15:13,600 --> 00:15:14,720
do

411
00:15:14,720 --> 00:15:16,480
but it's a very important and it's a

412
00:15:16,480 --> 00:15:19,920
very important thing to do as well

413
00:15:21,600 --> 00:15:23,360
okay you've thought through

414
00:15:23,360 --> 00:15:25,519
these are the things that can go wrong

415
00:15:25,519 --> 00:15:26,639
and

416
00:15:26,639 --> 00:15:29,279
now maybe you're

417
00:15:29,279 --> 00:15:31,199
a little bit

418
00:15:31,199 --> 00:15:33,279
you know

419
00:15:33,279 --> 00:15:36,320
nervous about those things um

420
00:15:36,320 --> 00:15:37,680
this is where

421
00:15:37,680 --> 00:15:39,839
this

422
00:15:39,839 --> 00:15:41,759
proactive piece comes in that i really

423
00:15:41,759 --> 00:15:43,600
enjoy because you're really trying to

424
00:15:43,600 --> 00:15:45,440
make it actionable what are you going to

425
00:15:45,440 --> 00:15:46,800
do about it

426
00:15:46,800 --> 00:15:48,959
what are the steps that you're going to

427
00:15:48,959 --> 00:15:51,199
take what are they going to be

428
00:15:51,199 --> 00:15:52,320
okay

429
00:15:52,320 --> 00:15:55,440
you found that

430
00:15:55,440 --> 00:15:57,279
there is

431
00:15:57,279 --> 00:15:58,560
potential

432
00:15:58,560 --> 00:16:00,800
for

433
00:16:02,720 --> 00:16:04,480
cross-site scripting to occur what are

434
00:16:04,480 --> 00:16:06,160
you going to do about it how are you

435
00:16:06,160 --> 00:16:07,440
going to harden the systems how are you

436
00:16:07,440 --> 00:16:09,680
going to mitigate that um hopefully

437
00:16:09,680 --> 00:16:11,199
you're not just going to say yes we

438
00:16:11,199 --> 00:16:12,800
accept that risk

439
00:16:12,800 --> 00:16:13,680
so

440
00:16:13,680 --> 00:16:14,880
what are you going to do about it and

441
00:16:14,880 --> 00:16:16,959
that's the thing that i love because you

442
00:16:16,959 --> 00:16:18,639
know you can work with the different

443
00:16:18,639 --> 00:16:20,839
teams and actually

444
00:16:20,839 --> 00:16:22,399
make

445
00:16:22,399 --> 00:16:24,880
those systems better and fix them

446
00:16:24,880 --> 00:16:25,920
and then

447
00:16:25,920 --> 00:16:27,920
you know with any changes you make you

448
00:16:27,920 --> 00:16:30,320
need to figure out

449
00:16:30,320 --> 00:16:33,440
was that actually effective did it work

450
00:16:33,440 --> 00:16:35,120
you know we we came up with this plan to

451
00:16:35,120 --> 00:16:36,560
do this thing

452
00:16:36,560 --> 00:16:37,440
we

453
00:16:37,440 --> 00:16:39,360
had a project manager on it we tracked

454
00:16:39,360 --> 00:16:40,240
it we

455
00:16:40,240 --> 00:16:41,839
thought it happened

456
00:16:41,839 --> 00:16:44,399
did it work did it do the thing and so

457
00:16:44,399 --> 00:16:46,240
it becomes iterative

458
00:16:46,240 --> 00:16:47,920
right um

459
00:16:47,920 --> 00:16:49,360
and so

460
00:16:49,360 --> 00:16:51,120
we'll go through a couple different

461
00:16:51,120 --> 00:16:52,880
models so these are all like i said

462
00:16:52,880 --> 00:16:53,759
before

463
00:16:53,759 --> 00:16:56,480
there's not one right one

464
00:16:56,480 --> 00:16:57,279
um

465
00:16:57,279 --> 00:16:58,399
but you can kind of see with these

466
00:16:58,399 --> 00:17:00,079
different models

467
00:17:00,079 --> 00:17:03,199
and then we'll go back out to another

468
00:17:03,199 --> 00:17:05,039
big picture example

469
00:17:05,039 --> 00:17:06,640
but you can see with these different

470
00:17:06,640 --> 00:17:09,439
models that

471
00:17:09,439 --> 00:17:12,000
you can

472
00:17:12,160 --> 00:17:14,319
take threat modeling

473
00:17:14,319 --> 00:17:16,079
and really apply it in different ways

474
00:17:16,079 --> 00:17:17,599
depending on which projects you're

475
00:17:17,599 --> 00:17:18,799
working on

476
00:17:18,799 --> 00:17:22,480
so being that we're at the owasp

477
00:17:22,480 --> 00:17:23,919
conference we thought it would be

478
00:17:23,919 --> 00:17:26,319
interesting to go through

479
00:17:26,319 --> 00:17:28,559
some different threat models and connect

480
00:17:28,559 --> 00:17:31,919
them with some of the owasp top 10

481
00:17:31,919 --> 00:17:33,679
from 2021

482
00:17:33,679 --> 00:17:34,559
so

483
00:17:34,559 --> 00:17:35,919
one of the models and we'll come back to

484
00:17:35,919 --> 00:17:37,120
this one later

485
00:17:37,120 --> 00:17:38,559
is stride

486
00:17:38,559 --> 00:17:40,799
and so this is

487
00:17:40,799 --> 00:17:42,880
a caustic acronym

488
00:17:42,880 --> 00:17:45,440
and so you can see it defined out so we

489
00:17:45,440 --> 00:17:48,000
have spoofing tampering repudiation

490
00:17:48,000 --> 00:17:50,799
information disclosure denial of service

491
00:17:50,799 --> 00:17:52,559
and elevation of privilege

492
00:17:52,559 --> 00:17:54,000
and so what do all those things sound

493
00:17:54,000 --> 00:17:56,400
like right these are all threats that

494
00:17:56,400 --> 00:17:57,840
could occur

495
00:17:57,840 --> 00:17:59,520
and so broad

496
00:17:59,520 --> 00:18:02,320
categories of threats

497
00:18:02,320 --> 00:18:03,679
and

498
00:18:03,679 --> 00:18:06,480
you're trying to analyze

499
00:18:06,480 --> 00:18:09,360
you know what could go wrong

500
00:18:09,360 --> 00:18:11,120
and then come up with your strategy

501
00:18:11,120 --> 00:18:12,400
after that

502
00:18:12,400 --> 00:18:15,200
and so within

503
00:18:15,200 --> 00:18:17,200
a couple of these

504
00:18:17,200 --> 00:18:19,840
thought through you know well tampering

505
00:18:19,840 --> 00:18:20,880
um

506
00:18:20,880 --> 00:18:23,280
tempering can often occur

507
00:18:23,280 --> 00:18:24,880
when

508
00:18:24,880 --> 00:18:26,880
injection occurs like let's say you have

509
00:18:26,880 --> 00:18:30,480
php or sql injection

510
00:18:30,480 --> 00:18:33,120
that can have data tampering

511
00:18:33,120 --> 00:18:34,480
right

512
00:18:34,480 --> 00:18:35,600
or

513
00:18:35,600 --> 00:18:39,280
let's say you have

514
00:18:39,360 --> 00:18:43,360
a security misconfiguration where you

515
00:18:43,360 --> 00:18:45,600
thought that a certain patch was taking

516
00:18:45,600 --> 00:18:47,919
care of something but then it did not

517
00:18:47,919 --> 00:18:49,919
and then this led to

518
00:18:49,919 --> 00:18:52,240
certain reports being open

519
00:18:52,240 --> 00:18:55,039
and so then that misconfiguration

520
00:18:55,039 --> 00:18:56,960
led to

521
00:18:56,960 --> 00:18:59,520
an attacker being able to come in

522
00:18:59,520 --> 00:19:00,320
um

523
00:19:00,320 --> 00:19:02,160
a much higher

524
00:19:02,160 --> 00:19:04,240
threat level um

525
00:19:04,240 --> 00:19:05,039
and

526
00:19:05,039 --> 00:19:06,960
they were that attacker was unable to

527
00:19:06,960 --> 00:19:08,880
elevate their privileges

528
00:19:08,880 --> 00:19:12,559
so you can kind of go through different

529
00:19:12,559 --> 00:19:14,799
ways things can go wrong

530
00:19:14,799 --> 00:19:17,360
and categorize those threats so that's

531
00:19:17,360 --> 00:19:20,320
one example of mod of modeling

532
00:19:20,320 --> 00:19:22,480
um with a lot of these you'd also be of

533
00:19:22,480 --> 00:19:24,640
course then be doing

534
00:19:24,640 --> 00:19:27,280
vulnerability scans

535
00:19:27,280 --> 00:19:28,880
and you'd want to have

536
00:19:28,880 --> 00:19:30,720
asset management with knowing what

537
00:19:30,720 --> 00:19:31,760
different things you have in your

538
00:19:31,760 --> 00:19:34,480
systems too

539
00:19:35,520 --> 00:19:38,720
a very different model and the three

540
00:19:38,720 --> 00:19:40,400
models i'll be going to through are all

541
00:19:40,400 --> 00:19:41,760
very different from each other a very

542
00:19:41,760 --> 00:19:44,000
different model is called the pasta

543
00:19:44,000 --> 00:19:46,640
threat model

544
00:19:47,039 --> 00:19:48,080
so

545
00:19:48,080 --> 00:19:49,679
stride

546
00:19:49,679 --> 00:19:51,600
does categorization

547
00:19:51,600 --> 00:19:54,320
of threats

548
00:19:55,600 --> 00:19:59,679
pasta takes an integrated approach where

549
00:19:59,679 --> 00:20:02,000
you're going through

550
00:20:02,000 --> 00:20:05,440
what type of simulations could occur

551
00:20:05,440 --> 00:20:08,480
and it's essentially like you're you're

552
00:20:08,480 --> 00:20:10,159
thinking through almost like a war room

553
00:20:10,159 --> 00:20:11,360
strategy

554
00:20:11,360 --> 00:20:13,440
okay

555
00:20:13,440 --> 00:20:15,360
what is our scope what's our business

556
00:20:15,360 --> 00:20:17,600
strategy um

557
00:20:17,600 --> 00:20:19,440
how are we gonna detect different

558
00:20:19,440 --> 00:20:21,200
vulnerabilities

559
00:20:21,200 --> 00:20:22,559
what threat

560
00:20:22,559 --> 00:20:25,280
intelligence exists out there

561
00:20:25,280 --> 00:20:26,960
and so then

562
00:20:26,960 --> 00:20:29,760
within these seven stages

563
00:20:29,760 --> 00:20:31,120
you know

564
00:20:31,120 --> 00:20:33,280
the sixth and the seventh

565
00:20:33,280 --> 00:20:36,000
are really where you're getting into

566
00:20:36,000 --> 00:20:40,880
the proactive pieces a lot of it is

567
00:20:40,880 --> 00:20:43,039
observational

568
00:20:43,039 --> 00:20:43,620
up to

569
00:20:43,620 --> 00:20:45,039
[Music]

570
00:20:45,039 --> 00:20:48,159
stage five

571
00:20:48,159 --> 00:20:49,200
and so

572
00:20:49,200 --> 00:20:50,799
as you model out the attacks you're

573
00:20:50,799 --> 00:20:53,520
really thinking from an attacker mindset

574
00:20:53,520 --> 00:20:54,559
what are all the things that can go

575
00:20:54,559 --> 00:20:56,000
wrong

576
00:20:56,000 --> 00:20:58,000
how are all the ways our systems could

577
00:20:58,000 --> 00:20:59,679
be penetrated

578
00:20:59,679 --> 00:21:01,440
and then

579
00:21:01,440 --> 00:21:03,039
what will we do

580
00:21:03,039 --> 00:21:04,559
because of that so what are our

581
00:21:04,559 --> 00:21:06,640
proactive measures going to be how will

582
00:21:06,640 --> 00:21:09,679
we fix these things what risks will we

583
00:21:09,679 --> 00:21:13,039
mitigate eliminate except

584
00:21:13,039 --> 00:21:16,159
and so

585
00:21:16,159 --> 00:21:19,280
this ends up becoming

586
00:21:20,799 --> 00:21:24,720
a much more elaborate style

587
00:21:24,799 --> 00:21:28,639
with stages four and five

588
00:21:29,280 --> 00:21:31,120
so here four and five the threat

589
00:21:31,120 --> 00:21:32,880
analysis

590
00:21:32,880 --> 00:21:35,039
they really build on each other

591
00:21:35,039 --> 00:21:37,600
so let's imagine

592
00:21:37,600 --> 00:21:40,159
that you gather threat and tell

593
00:21:40,159 --> 00:21:42,080
on organization

594
00:21:42,080 --> 00:21:43,039
and

595
00:21:43,039 --> 00:21:46,400
this gets an enterprise organization

596
00:21:46,400 --> 00:21:48,159
they've had a variety of credential

597
00:21:48,159 --> 00:21:49,120
leaks

598
00:21:49,120 --> 00:21:50,480
um

599
00:21:50,480 --> 00:21:52,640
you know it's a

600
00:21:52,640 --> 00:21:55,760
standard credential leak um

601
00:21:55,760 --> 00:21:57,600
it's both

602
00:21:57,600 --> 00:21:59,520
a regular exposure but then also there's

603
00:21:59,520 --> 00:22:02,799
some dark one chatter okay

604
00:22:02,799 --> 00:22:05,039
so

605
00:22:06,799 --> 00:22:10,960
not only is it the accounts but also it

606
00:22:10,960 --> 00:22:13,520
is um

607
00:22:13,520 --> 00:22:16,159
that their passwords are

608
00:22:16,159 --> 00:22:17,520
some of them are hash but some of them

609
00:22:17,520 --> 00:22:19,360
are actually in plain text so it's it's

610
00:22:19,360 --> 00:22:21,440
quite the database for for this

611
00:22:21,440 --> 00:22:24,159
enterprise organization

612
00:22:24,159 --> 00:22:26,320
so how could this be used right so if

613
00:22:26,320 --> 00:22:27,600
we're doing threat analysis based on

614
00:22:27,600 --> 00:22:29,520
threat intelligence we're going to be

615
00:22:29,520 --> 00:22:31,120
looking at

616
00:22:31,120 --> 00:22:33,120
where is this being mentioned are these

617
00:22:33,120 --> 00:22:35,440
first time mentions

618
00:22:35,440 --> 00:22:37,360
how might they be used

619
00:22:37,360 --> 00:22:39,520
um

620
00:22:39,520 --> 00:22:41,919
are these active and current employees

621
00:22:41,919 --> 00:22:44,799
of this organization

622
00:22:44,799 --> 00:22:46,320
and

623
00:22:46,320 --> 00:22:48,559
are

624
00:22:49,360 --> 00:22:51,039
any of these

625
00:22:51,039 --> 00:22:52,799
credential leaks

626
00:22:52,799 --> 00:22:55,760
upper level management c-suite level so

627
00:22:55,760 --> 00:22:58,320
all of these things

628
00:22:58,320 --> 00:23:00,000
are pieces of threat intelligence that

629
00:23:00,000 --> 00:23:02,320
would be taken into account

630
00:23:02,320 --> 00:23:04,080
as one is building

631
00:23:04,080 --> 00:23:06,840
up the

632
00:23:06,840 --> 00:23:08,640
analysis

633
00:23:08,640 --> 00:23:11,520
those credential leaks could be used

634
00:23:11,520 --> 00:23:13,440
with one of the os top 10 the

635
00:23:13,440 --> 00:23:15,039
identification and authentication

636
00:23:15,039 --> 00:23:17,120
failures because they could be used for

637
00:23:17,120 --> 00:23:20,559
various attacks it could be used for

638
00:23:20,559 --> 00:23:22,400
brute forcing um

639
00:23:22,400 --> 00:23:24,000
they could be used just for regular

640
00:23:24,000 --> 00:23:25,280
logging in

641
00:23:25,280 --> 00:23:27,360
for the accounts um

642
00:23:27,360 --> 00:23:28,240
so

643
00:23:28,240 --> 00:23:30,000
that could be one way that the

644
00:23:30,000 --> 00:23:31,520
credential leaks are used they could be

645
00:23:31,520 --> 00:23:34,559
used once one is in the system

646
00:23:34,559 --> 00:23:36,960
for privilege escalation as well

647
00:23:36,960 --> 00:23:37,919
so

648
00:23:37,919 --> 00:23:39,760
the

649
00:23:39,760 --> 00:23:43,679
colonial pipeline was through a vpn um

650
00:23:43,679 --> 00:23:47,760
access account um through vpn log and

651
00:23:47,760 --> 00:23:50,320
from a credential leak

652
00:23:50,320 --> 00:23:53,200
in stage five

653
00:23:53,200 --> 00:23:54,000
we

654
00:23:54,000 --> 00:23:56,080
also

655
00:23:56,080 --> 00:23:57,840
then

656
00:23:57,840 --> 00:24:01,600
might do a vulnerability scan

657
00:24:01,600 --> 00:24:04,640
and we might see

658
00:24:04,640 --> 00:24:08,320
um that our system scan shows us that we

659
00:24:08,320 --> 00:24:09,600
have

660
00:24:09,600 --> 00:24:11,039
um

661
00:24:11,039 --> 00:24:12,960
certain ports that are open that we

662
00:24:12,960 --> 00:24:14,480
might not want open

663
00:24:14,480 --> 00:24:18,799
uh maybe we have remote desktop open

664
00:24:18,799 --> 00:24:20,880
just across the board for a variety of

665
00:24:20,880 --> 00:24:22,799
employees regardless if they need this

666
00:24:22,799 --> 00:24:25,039
or not

667
00:24:25,039 --> 00:24:26,960
and so we're kind of thinking through

668
00:24:26,960 --> 00:24:28,320
okay well

669
00:24:28,320 --> 00:24:30,480
we might want to

670
00:24:30,480 --> 00:24:31,600
close

671
00:24:31,600 --> 00:24:32,880
some of these

672
00:24:32,880 --> 00:24:34,960
remote desktop access port

673
00:24:34,960 --> 00:24:37,360
places

674
00:24:37,360 --> 00:24:40,479
so we can think through

675
00:24:40,880 --> 00:24:43,039
is we gain information right so we gain

676
00:24:43,039 --> 00:24:44,640
information about these credential leaks

677
00:24:44,640 --> 00:24:47,600
we gain information that there is a

678
00:24:47,600 --> 00:24:50,240
vulnerable component

679
00:24:50,240 --> 00:24:52,960
maybe there's a patch that happens

680
00:24:52,960 --> 00:24:54,720
and then that leads to a further

681
00:24:54,720 --> 00:24:58,200
security misconfiguration

682
00:25:01,279 --> 00:25:02,720
all of this

683
00:25:02,720 --> 00:25:04,960
is going to be used to paint a very

684
00:25:04,960 --> 00:25:06,880
elaborate picture

685
00:25:06,880 --> 00:25:08,880
about

686
00:25:08,880 --> 00:25:10,799
this organization

687
00:25:10,799 --> 00:25:13,600
which will then be used to develop the

688
00:25:13,600 --> 00:25:16,320
countermeasures

689
00:25:18,000 --> 00:25:20,000
and then the third model that i'll

690
00:25:20,000 --> 00:25:22,159
discuss today

691
00:25:22,159 --> 00:25:24,480
is the diamond threat model

692
00:25:24,480 --> 00:25:27,360
and so you can think actually about a

693
00:25:27,360 --> 00:25:29,679
series of diamonds that can be attached

694
00:25:29,679 --> 00:25:31,600
to each other

695
00:25:31,600 --> 00:25:32,720
and

696
00:25:32,720 --> 00:25:35,440
with this model you can choose to have

697
00:25:35,440 --> 00:25:37,440
different centered approaches

698
00:25:37,440 --> 00:25:40,080
a lot of people take the victim-centered

699
00:25:40,080 --> 00:25:42,080
approach where they think about like

700
00:25:42,080 --> 00:25:43,120
okay

701
00:25:43,120 --> 00:25:45,120
these were different places that

702
00:25:45,120 --> 00:25:46,480
recently

703
00:25:46,480 --> 00:25:48,159
had attacks

704
00:25:48,159 --> 00:25:49,279
and

705
00:25:49,279 --> 00:25:51,520
this could be a focus it will take but

706
00:25:51,520 --> 00:25:54,640
you could take any of these approaches

707
00:25:54,640 --> 00:25:57,360
so if we were to take the victim

708
00:25:57,360 --> 00:26:00,159
approach and we looked at the scottish

709
00:26:00,159 --> 00:26:01,120
epa

710
00:26:01,120 --> 00:26:02,640
and then maybe a couple different

711
00:26:02,640 --> 00:26:05,279
international luxury jewelers

712
00:26:05,279 --> 00:26:07,520
and we saw you know what what do these

713
00:26:07,520 --> 00:26:09,039
places have in common

714
00:26:09,039 --> 00:26:11,360
oh they were both

715
00:26:11,360 --> 00:26:13,360
recently

716
00:26:13,360 --> 00:26:15,360
within the last year

717
00:26:15,360 --> 00:26:18,320
um victims of the same adversary a

718
00:26:18,320 --> 00:26:21,520
ransomware as a service game

719
00:26:21,520 --> 00:26:26,240
and we can see okay this adversary

720
00:26:26,240 --> 00:26:27,919
has

721
00:26:27,919 --> 00:26:30,559
oh sorry let me go back one slide

722
00:26:30,559 --> 00:26:32,320
this adversary

723
00:26:32,320 --> 00:26:33,279
has

724
00:26:33,279 --> 00:26:35,679
a certain infrastructure

725
00:26:35,679 --> 00:26:36,880
it has

726
00:26:36,880 --> 00:26:38,960
command and control servers

727
00:26:38,960 --> 00:26:41,600
it has affiliate hackers

728
00:26:41,600 --> 00:26:43,279
it has

729
00:26:43,279 --> 00:26:45,679
its own ransomware that it's built

730
00:26:45,679 --> 00:26:47,279
um botnets

731
00:26:47,279 --> 00:26:50,000
and one of the systems that it's using

732
00:26:50,000 --> 00:26:51,360
for

733
00:26:51,360 --> 00:26:54,960
a lot of access is it's using

734
00:26:54,960 --> 00:26:57,440
remote desktop boards um which we can

735
00:26:57,440 --> 00:26:58,799
kind of think about how that might have

736
00:26:58,799 --> 00:27:00,320
gone up

737
00:27:00,320 --> 00:27:03,520
also during work from home

738
00:27:03,520 --> 00:27:04,400
um

739
00:27:04,400 --> 00:27:07,400
and

740
00:27:08,159 --> 00:27:10,240
one of these victims in particular

741
00:27:10,240 --> 00:27:12,799
i do recommend

742
00:27:12,799 --> 00:27:14,480
taking a look at the way they approach

743
00:27:14,480 --> 00:27:17,039
this so

744
00:27:17,039 --> 00:27:18,480
another thing

745
00:27:18,480 --> 00:27:20,320
with the centered approach you can see

746
00:27:20,320 --> 00:27:23,679
for looking at trend analysis is

747
00:27:23,679 --> 00:27:24,559
you know

748
00:27:24,559 --> 00:27:28,000
other factors of commonality so

749
00:27:28,000 --> 00:27:29,120
cepa

750
00:27:29,120 --> 00:27:31,039
the scottish epa

751
00:27:31,039 --> 00:27:34,480
was attacked at a holiday

752
00:27:34,480 --> 00:27:36,720
and

753
00:27:37,919 --> 00:27:40,000
their

754
00:27:40,000 --> 00:27:41,760
entry access point

755
00:27:41,760 --> 00:27:43,600
um

756
00:27:43,600 --> 00:27:45,840
was through

757
00:27:45,840 --> 00:27:48,159
a remote desktop

758
00:27:48,159 --> 00:27:51,520
and then privilege escalation

759
00:27:51,919 --> 00:27:54,399
and then they have had four studies

760
00:27:54,399 --> 00:27:56,320
commissioned

761
00:27:56,320 --> 00:27:57,120
on

762
00:27:57,120 --> 00:27:59,279
that attack and then they publicly

763
00:27:59,279 --> 00:28:01,279
shared

764
00:28:01,279 --> 00:28:02,880
that data

765
00:28:02,880 --> 00:28:05,279
so they've

766
00:28:05,279 --> 00:28:06,399
said you know

767
00:28:06,399 --> 00:28:08,240
we learned a lot from this attack we

768
00:28:08,240 --> 00:28:09,679
want to make sure that the security

769
00:28:09,679 --> 00:28:11,600
community also learns a lot from this

770
00:28:11,600 --> 00:28:13,120
attack

771
00:28:13,120 --> 00:28:15,440
and so it's a little bit redacted but

772
00:28:15,440 --> 00:28:17,840
quite a bit

773
00:28:18,399 --> 00:28:20,719
is

774
00:28:21,919 --> 00:28:24,799
not redacted from it um

775
00:28:24,799 --> 00:28:26,880
so

776
00:28:26,880 --> 00:28:28,640
that is a really interesting one to kind

777
00:28:28,640 --> 00:28:30,320
of pay attention to so those are three

778
00:28:30,320 --> 00:28:32,559
models

779
00:28:32,559 --> 00:28:36,559
and then as we're thinking through

780
00:28:36,960 --> 00:28:39,600
big picture

781
00:28:40,159 --> 00:28:41,520
we want to make sure we've created a

782
00:28:41,520 --> 00:28:42,720
model

783
00:28:42,720 --> 00:28:45,200
we've identified threats

784
00:28:45,200 --> 00:28:48,399
we've addressed different threats

785
00:28:48,399 --> 00:28:50,399
we want to communicate everything that

786
00:28:50,399 --> 00:28:53,279
we've done with all of these things

787
00:28:53,279 --> 00:28:55,200
and then we want to make sure that all

788
00:28:55,200 --> 00:28:56,799
of the things that we've done

789
00:28:56,799 --> 00:28:58,640
are validated

790
00:28:58,640 --> 00:29:00,480
so i'll go through those

791
00:29:00,480 --> 00:29:03,200
fairly quickly

792
00:29:03,200 --> 00:29:04,799
so our first three

793
00:29:04,799 --> 00:29:06,399
as we create the model

794
00:29:06,399 --> 00:29:08,320
we are thinking about scope we're

795
00:29:08,320 --> 00:29:10,880
thinking about what could go wrong we're

796
00:29:10,880 --> 00:29:13,840
thinking about

797
00:29:14,559 --> 00:29:15,760
what are the different systems that

798
00:29:15,760 --> 00:29:16,880
we're going to be looking at what

799
00:29:16,880 --> 00:29:18,559
problems are we going to be

800
00:29:18,559 --> 00:29:19,919
trying to

801
00:29:19,919 --> 00:29:21,840
threat model

802
00:29:21,840 --> 00:29:23,919
as we identify we're going to be

803
00:29:23,919 --> 00:29:25,600
figuring out

804
00:29:25,600 --> 00:29:28,240
what tools are we using as well

805
00:29:28,240 --> 00:29:29,039
what

806
00:29:29,039 --> 00:29:31,200
intelligence are we gathering

807
00:29:31,200 --> 00:29:33,520
and then we will figure out addressing

808
00:29:33,520 --> 00:29:35,360
our threats

809
00:29:35,360 --> 00:29:37,679
and we'll share out our findings

810
00:29:37,679 --> 00:29:39,279
just like i was referencing earlier with

811
00:29:39,279 --> 00:29:40,640
the scottish epa sharing out those

812
00:29:40,640 --> 00:29:42,559
findings and that might be internal of

813
00:29:42,559 --> 00:29:44,880
course um so there might be a purely

814
00:29:44,880 --> 00:29:46,640
internal or there could be an external

815
00:29:46,640 --> 00:29:48,080
component to it or a combination of the

816
00:29:48,080 --> 00:29:49,760
two

817
00:29:49,760 --> 00:29:52,559
and then we'll need to look through did

818
00:29:52,559 --> 00:29:53,600
what

819
00:29:53,600 --> 00:29:55,760
we thought was going to happen happen or

820
00:29:55,760 --> 00:29:58,320
should we be doing something differently

821
00:29:58,320 --> 00:30:00,960
so when we create the model

822
00:30:00,960 --> 00:30:04,399
it is really important to think through

823
00:30:04,399 --> 00:30:06,320
what

824
00:30:06,320 --> 00:30:08,399
and who are on the team how much time is

825
00:30:08,399 --> 00:30:09,279
there

826
00:30:09,279 --> 00:30:11,600
to do this who's on the team

827
00:30:11,600 --> 00:30:13,360
and that's going to determine a lot of

828
00:30:13,360 --> 00:30:16,240
different things for how the whole

829
00:30:16,240 --> 00:30:19,679
threat modeling process is planned out

830
00:30:19,679 --> 00:30:21,200
so these are a couple different examples

831
00:30:21,200 --> 00:30:23,200
for this

832
00:30:23,200 --> 00:30:24,399
we could think about is it something

833
00:30:24,399 --> 00:30:27,360
that's new or is it a sub component or

834
00:30:27,360 --> 00:30:29,120
is it existing

835
00:30:29,120 --> 00:30:31,600
process

836
00:30:31,919 --> 00:30:34,320
and just like how i started broad and

837
00:30:34,320 --> 00:30:36,320
then we're becoming more and more narrow

838
00:30:36,320 --> 00:30:38,000
it's the same thing with us you can

839
00:30:38,000 --> 00:30:41,600
start broad and then focus

840
00:30:42,720 --> 00:30:43,760
then

841
00:30:43,760 --> 00:30:47,520
we would want to identify the threats

842
00:30:47,760 --> 00:30:50,159
so what can go wrong goes back to those

843
00:30:50,159 --> 00:30:53,279
earlier four questions we're asking

844
00:30:53,279 --> 00:30:55,520
so having a variety of people on your

845
00:30:55,520 --> 00:30:56,880
team

846
00:30:56,880 --> 00:30:59,279
is very important

847
00:30:59,279 --> 00:31:01,919
and it requires a good mix of security

848
00:31:01,919 --> 00:31:04,559
knowledge deep understanding of the

849
00:31:04,559 --> 00:31:07,600
information being threatened

850
00:31:09,360 --> 00:31:10,880
now there are many different tools and

851
00:31:10,880 --> 00:31:13,519
methodologies for finding threats

852
00:31:13,519 --> 00:31:15,519
and so that's one of the parts that

853
00:31:15,519 --> 00:31:19,519
you'll work on with scope as well

854
00:31:19,519 --> 00:31:21,360
and then this can be you know fairly

855
00:31:21,360 --> 00:31:23,279
enjoyable part of the whole process as

856
00:31:23,279 --> 00:31:25,279
well because it's like

857
00:31:25,279 --> 00:31:26,960
kind of like poking at the whole system

858
00:31:26,960 --> 00:31:27,919
like oh

859
00:31:27,919 --> 00:31:30,000
what are the ways that this could go

860
00:31:30,000 --> 00:31:32,320
this could go wrong

861
00:31:32,320 --> 00:31:35,120
but for a proactive

862
00:31:35,120 --> 00:31:37,518
manner

863
00:31:37,840 --> 00:31:38,640
so

864
00:31:38,640 --> 00:31:41,519
as you've then figured out hey

865
00:31:41,519 --> 00:31:43,360
these are the threats

866
00:31:43,360 --> 00:31:45,679
this is what we've learned

867
00:31:45,679 --> 00:31:46,880
you then

868
00:31:46,880 --> 00:31:48,320
need to

869
00:31:48,320 --> 00:31:49,840
address them

870
00:31:49,840 --> 00:31:51,600
you learn these are these are all the

871
00:31:51,600 --> 00:31:54,320
things and hopefully hopefully you did

872
00:31:54,320 --> 00:31:57,039
figure out these are all the things

873
00:31:57,039 --> 00:31:58,960
and so you need to decide if you'll

874
00:31:58,960 --> 00:32:00,799
eliminate mitigate

875
00:32:00,799 --> 00:32:03,120
transfer or accept those

876
00:32:03,120 --> 00:32:06,159
um and so

877
00:32:06,159 --> 00:32:07,279
if

878
00:32:07,279 --> 00:32:08,799
you do not threat model something i

879
00:32:08,799 --> 00:32:10,000
think this is probably one of the most

880
00:32:10,000 --> 00:32:12,000
important things within this if you do

881
00:32:12,000 --> 00:32:15,039
not threat model something

882
00:32:15,039 --> 00:32:18,480
you by default accept that threat

883
00:32:18,480 --> 00:32:19,760
so that's going to be really important

884
00:32:19,760 --> 00:32:21,039
to think through so even if it's

885
00:32:21,039 --> 00:32:24,559
something that you didn't think of

886
00:32:25,200 --> 00:32:29,200
it is then a threat that you've accepted

887
00:32:29,200 --> 00:32:32,080
as you go are going through

888
00:32:32,080 --> 00:32:33,760
how you gathered your threats what you

889
00:32:33,760 --> 00:32:36,640
did with them what processes you took

890
00:32:36,640 --> 00:32:37,919
that's where

891
00:32:37,919 --> 00:32:40,159
you want to have documentation and the

892
00:32:40,159 --> 00:32:42,960
documentation is going to very much so

893
00:32:42,960 --> 00:32:44,000
tie in

894
00:32:44,000 --> 00:32:46,320
with your communication right

895
00:32:46,320 --> 00:32:48,080
because you're going to see what actions

896
00:32:48,080 --> 00:32:49,039
you took

897
00:32:49,039 --> 00:32:50,799
or non-actions

898
00:32:50,799 --> 00:32:52,880
how you prioritize things and then this

899
00:32:52,880 --> 00:32:54,480
is also going to help with that teamwork

900
00:32:54,480 --> 00:32:56,880
that i spoke about earlier

901
00:32:56,880 --> 00:32:58,399
and so you'll want to have a system that

902
00:32:58,399 --> 00:33:00,799
you're using for tracking that

903
00:33:00,799 --> 00:33:03,360
so as you've documented things

904
00:33:03,360 --> 00:33:06,640
you'll then want to communicate aha

905
00:33:06,640 --> 00:33:08,399
this is what we did we found these

906
00:33:08,399 --> 00:33:11,519
things we did these things

907
00:33:11,519 --> 00:33:14,640
who needs to know about

908
00:33:15,279 --> 00:33:16,960
everything you did right so who are your

909
00:33:16,960 --> 00:33:18,720
key stakeholders who

910
00:33:18,720 --> 00:33:19,919
are the people you need to share your

911
00:33:19,919 --> 00:33:21,360
findings

912
00:33:21,360 --> 00:33:23,440
what is the best way to share that

913
00:33:23,440 --> 00:33:25,360
and of course then go ahead and do that

914
00:33:25,360 --> 00:33:26,640
and then should you be sharing it out

915
00:33:26,640 --> 00:33:28,320
with the whole community is it something

916
00:33:28,320 --> 00:33:29,679
that the security community would

917
00:33:29,679 --> 00:33:32,720
benefit from learning about

918
00:33:32,720 --> 00:33:34,240
so all these things are very important

919
00:33:34,240 --> 00:33:36,240
to think through

920
00:33:36,240 --> 00:33:38,320
now our last stage is validating the

921
00:33:38,320 --> 00:33:39,519
model

922
00:33:39,519 --> 00:33:40,320
and

923
00:33:40,320 --> 00:33:42,559
this is so important because you have to

924
00:33:42,559 --> 00:33:43,519
measure

925
00:33:43,519 --> 00:33:45,519
did you actually do the things you

926
00:33:45,519 --> 00:33:48,320
thought you were going to do

927
00:33:48,320 --> 00:33:50,080
did you stay within scope or did it have

928
00:33:50,080 --> 00:33:51,519
scope creep

929
00:33:51,519 --> 00:33:54,640
if it had scope creep why

930
00:33:54,640 --> 00:33:57,760
what about criticality

931
00:33:57,760 --> 00:33:59,679
were the right people involved

932
00:33:59,679 --> 00:34:03,200
and did you need to support other teams

933
00:34:03,360 --> 00:34:07,039
did you find enough threats

934
00:34:07,039 --> 00:34:09,199
was there a range of threats for

935
00:34:09,199 --> 00:34:12,079
severity and type

936
00:34:12,079 --> 00:34:13,679
did you kind of see different things

937
00:34:13,679 --> 00:34:15,760
with third parties or

938
00:34:15,760 --> 00:34:18,079
see if threats that were visible and

939
00:34:18,079 --> 00:34:19,359
actionable

940
00:34:19,359 --> 00:34:20,639
and allowed for team members to be

941
00:34:20,639 --> 00:34:22,719
accountable

942
00:34:22,719 --> 00:34:24,639
and did you check in with subject matter

943
00:34:24,639 --> 00:34:27,119
experts

944
00:34:28,000 --> 00:34:30,239
so as you're working through this

945
00:34:30,239 --> 00:34:31,918
did you then act on those threats you

946
00:34:31,918 --> 00:34:33,040
found

947
00:34:33,040 --> 00:34:34,480
i've already walked through those four

948
00:34:34,480 --> 00:34:36,480
different things you can do

949
00:34:36,480 --> 00:34:39,040
and as you're documenting

950
00:34:39,040 --> 00:34:40,719
did you prioritize and act on those in a

951
00:34:40,719 --> 00:34:42,399
timely manner and figure out did those

952
00:34:42,399 --> 00:34:43,839
mitigations work

953
00:34:43,839 --> 00:34:47,199
and are you validating the mitigations

954
00:34:47,199 --> 00:34:49,119
and this is my last question i really

955
00:34:49,119 --> 00:34:50,960
like this one did any mitigations

956
00:34:50,960 --> 00:34:52,480
introduce new threats because you need

957
00:34:52,480 --> 00:34:54,639
to be very cognizant that certain things

958
00:34:54,639 --> 00:34:56,560
you do can also then introduce new

959
00:34:56,560 --> 00:35:00,000
threats so very iterative right

960
00:35:00,000 --> 00:35:02,400
so as you're validating that model

961
00:35:02,400 --> 00:35:03,280
then

962
00:35:03,280 --> 00:35:04,160
you'll

963
00:35:04,160 --> 00:35:06,480
learn certain things that will end up

964
00:35:06,480 --> 00:35:07,760
being circled back to from a

965
00:35:07,760 --> 00:35:11,119
communication standpoint as well

966
00:35:11,200 --> 00:35:14,000
so finally

967
00:35:14,000 --> 00:35:15,359
do you kind of have these acceptance

968
00:35:15,359 --> 00:35:17,040
criteria

969
00:35:17,040 --> 00:35:18,079
do you

970
00:35:18,079 --> 00:35:19,920
have as an organization ways that you

971
00:35:19,920 --> 00:35:22,640
plan out and do you work on things with

972
00:35:22,640 --> 00:35:23,760
your team

973
00:35:23,760 --> 00:35:24,640
um

974
00:35:24,640 --> 00:35:26,000
where you have different maturity levels

975
00:35:26,000 --> 00:35:27,599
so all of these things are so important

976
00:35:27,599 --> 00:35:29,440
to think through from a validation

977
00:35:29,440 --> 00:35:30,560
standpoint

978
00:35:30,560 --> 00:35:32,640
and now we've gone through

979
00:35:32,640 --> 00:35:34,800
different threat models we've gone

980
00:35:34,800 --> 00:35:36,320
through different ways to do threat

981
00:35:36,320 --> 00:35:37,359
modeling

982
00:35:37,359 --> 00:35:40,240
and we've gone through very broad to

983
00:35:40,240 --> 00:35:41,520
very specific right we did three

984
00:35:41,520 --> 00:35:43,119
different threat models and we just did

985
00:35:43,119 --> 00:35:45,040
like how to process that we're going to

986
00:35:45,040 --> 00:35:47,119
actually do some practice and i will

987
00:35:47,119 --> 00:35:48,880
stop screen sharing because we'll take

988
00:35:48,880 --> 00:35:52,400
it over and lead us through a practice

989
00:35:52,400 --> 00:35:55,599
all right oh thank you megan appreciate

990
00:35:55,599 --> 00:35:57,040
it

991
00:35:57,040 --> 00:35:58,480
let's see

992
00:35:58,480 --> 00:36:01,520
can you guys see my screen now

993
00:36:01,520 --> 00:36:03,680
all right thank you

994
00:36:03,680 --> 00:36:06,160
um now that you have learned five stages

995
00:36:06,160 --> 00:36:08,720
of uh threat modeling that megan walked

996
00:36:08,720 --> 00:36:11,520
uh you through uh let's put that into

997
00:36:11,520 --> 00:36:14,880
practice let's take an example

998
00:36:14,880 --> 00:36:18,320
all right let's take a billing system

999
00:36:18,320 --> 00:36:21,040
for our company that we want to thread

1000
00:36:21,040 --> 00:36:23,440
moral

1001
00:36:23,599 --> 00:36:26,160
so this application building system

1002
00:36:26,160 --> 00:36:30,720
accepts clients transactions and process

1003
00:36:30,720 --> 00:36:33,760
them through by applying some rules and

1004
00:36:33,760 --> 00:36:35,440
send it back to the database for

1005
00:36:35,440 --> 00:36:37,200
internal use

1006
00:36:37,200 --> 00:36:40,720
there is a batch process as well which

1007
00:36:40,720 --> 00:36:43,599
actually takes a file uh from clients uh

1008
00:36:43,599 --> 00:36:46,640
that contains all the transactions

1009
00:36:46,640 --> 00:36:47,520
and

1010
00:36:47,520 --> 00:36:48,320
um

1011
00:36:48,320 --> 00:36:49,599
take them through

1012
00:36:49,599 --> 00:36:51,440
to the database

1013
00:36:51,440 --> 00:36:55,280
and i also want to target the ui portion

1014
00:36:55,280 --> 00:36:58,640
of this application uh in school

1015
00:36:58,640 --> 00:37:02,480
this ui basically what it browses um the

1016
00:37:02,480 --> 00:37:05,440
customer or client or external user or

1017
00:37:05,440 --> 00:37:07,359
even internal users

1018
00:37:07,359 --> 00:37:09,520
are able to log in

1019
00:37:09,520 --> 00:37:11,040
and see

1020
00:37:11,040 --> 00:37:12,640
their transaction

1021
00:37:12,640 --> 00:37:14,640
they can search for their transactions

1022
00:37:14,640 --> 00:37:18,480
they can export to csv or pdf

1023
00:37:18,480 --> 00:37:21,200
and they have also have a facility to

1024
00:37:21,200 --> 00:37:22,880
reset their password

1025
00:37:22,880 --> 00:37:25,200
i also want to focus on

1026
00:37:25,200 --> 00:37:29,680
admin users here who can create users um

1027
00:37:29,680 --> 00:37:33,040
the client or the internal users as well

1028
00:37:33,040 --> 00:37:36,079
so this building system has a lot more

1029
00:37:36,079 --> 00:37:37,280
to do

1030
00:37:37,280 --> 00:37:39,839
but we are going to for the purpose of

1031
00:37:39,839 --> 00:37:41,280
this presentation we are just going to

1032
00:37:41,280 --> 00:37:43,920
focus on these three which is what we

1033
00:37:43,920 --> 00:37:47,280
did on a step one to find our scope

1034
00:37:47,280 --> 00:37:48,240
all right

1035
00:37:48,240 --> 00:37:49,359
i'm going to go through this

1036
00:37:49,359 --> 00:37:51,440
architecture

1037
00:37:51,440 --> 00:37:53,040
typically

1038
00:37:53,040 --> 00:37:56,720
a person who is closer to this

1039
00:37:56,720 --> 00:37:59,599
application a team lead or developer

1040
00:37:59,599 --> 00:38:01,200
will walk you through

1041
00:38:01,200 --> 00:38:03,760
to everybody who's in that session so

1042
00:38:03,760 --> 00:38:05,040
they all

1043
00:38:05,040 --> 00:38:06,960
have a common understanding of what it

1044
00:38:06,960 --> 00:38:09,520
is so they can all identify the right

1045
00:38:09,520 --> 00:38:10,880
threats

1046
00:38:10,880 --> 00:38:13,200
so i'm going to wear my uh developer hat

1047
00:38:13,200 --> 00:38:14,400
on and i'm going to walk you through

1048
00:38:14,400 --> 00:38:17,440
this now so feel free to find any

1049
00:38:17,440 --> 00:38:19,839
touch you can come up with and put it on

1050
00:38:19,839 --> 00:38:22,640
your on our chat window

1051
00:38:22,640 --> 00:38:25,760
all right this application is as you can

1052
00:38:25,760 --> 00:38:30,000
see it is in aws hosted in aws and it is

1053
00:38:30,000 --> 00:38:33,200
in a single vpc account

1054
00:38:33,200 --> 00:38:37,359
you can see a couple of subnets

1055
00:38:37,440 --> 00:38:40,880
the top subnet that you see is um

1056
00:38:40,880 --> 00:38:43,839
where external users are logging into ui

1057
00:38:43,839 --> 00:38:46,320
through https and i and you can see

1058
00:38:46,320 --> 00:38:47,680
there is a

1059
00:38:47,680 --> 00:38:49,920
bas is available

1060
00:38:49,920 --> 00:38:51,839
in the mirror section where the sub that

1061
00:38:51,839 --> 00:38:54,640
the middle subnet is you have ui

1062
00:38:54,640 --> 00:38:56,800
component uh application component and

1063
00:38:56,800 --> 00:38:58,800
also a couple of apis

1064
00:38:58,800 --> 00:39:01,040
that does uh some processing whatever

1065
00:39:01,040 --> 00:39:03,280
rules you have set it up uh to to

1066
00:39:03,280 --> 00:39:06,880
process those transaction or any action

1067
00:39:06,880 --> 00:39:09,760
the users took on the screen you would

1068
00:39:09,760 --> 00:39:12,320
have to process those so it all

1069
00:39:12,320 --> 00:39:14,640
happening in the middle subnet

1070
00:39:14,640 --> 00:39:17,440
and once it's done it sends off the data

1071
00:39:17,440 --> 00:39:19,520
to audios or retrieves the data back

1072
00:39:19,520 --> 00:39:22,640
from rds to the web dui

1073
00:39:22,640 --> 00:39:26,560
the ods database itself is in separate

1074
00:39:26,560 --> 00:39:27,599
subnet

1075
00:39:27,599 --> 00:39:30,560
then up at the bottom you see there is a

1076
00:39:30,560 --> 00:39:33,200
um another subnet where the external

1077
00:39:33,200 --> 00:39:36,400
files um that the client sends are

1078
00:39:36,400 --> 00:39:38,800
putting in a three bucket and there is a

1079
00:39:38,800 --> 00:39:41,440
lambda function which takes the data and

1080
00:39:41,440 --> 00:39:44,240
process it through and send it back to

1081
00:39:44,240 --> 00:39:47,359
rds for any internal processing or any

1082
00:39:47,359 --> 00:39:49,280
other internal system to consume that

1083
00:39:49,280 --> 00:39:50,800
data

1084
00:39:50,800 --> 00:39:52,640
so i'm going to check out my developer

1085
00:39:52,640 --> 00:39:54,839
head i hope everybody has a common

1086
00:39:54,839 --> 00:39:56,880
understanding and now i'm going to go

1087
00:39:56,880 --> 00:40:00,560
back to look at what can go wrong here

1088
00:40:00,560 --> 00:40:02,240
so we are going to apply what megan just

1089
00:40:02,240 --> 00:40:04,079
walks us through

1090
00:40:04,079 --> 00:40:08,480
before we go there i want to um like i

1091
00:40:08,480 --> 00:40:11,040
recommend gamifying this what i mean by

1092
00:40:11,040 --> 00:40:12,319
that is

1093
00:40:12,319 --> 00:40:14,960
um split into a couple of teams

1094
00:40:14,960 --> 00:40:17,119
and see if you can score if somebody

1095
00:40:17,119 --> 00:40:19,599
some team finds out the good threat and

1096
00:40:19,599 --> 00:40:21,119
someone comes up with

1097
00:40:21,119 --> 00:40:22,880
some controls or medication or a

1098
00:40:22,880 --> 00:40:25,599
mediation uh control in place you know

1099
00:40:25,599 --> 00:40:29,119
score them uh try to have a a a game but

1100
00:40:29,119 --> 00:40:31,359
then within the team itself and see who

1101
00:40:31,359 --> 00:40:33,839
gets what and you know who can

1102
00:40:33,839 --> 00:40:35,839
get a high score

1103
00:40:35,839 --> 00:40:39,839
not only um does this develop the team

1104
00:40:39,839 --> 00:40:40,800
uh

1105
00:40:40,800 --> 00:40:43,440
that team development here um

1106
00:40:43,440 --> 00:40:46,319
but also at the end of the day you are

1107
00:40:46,319 --> 00:40:48,800
finding the cuts and also it makes

1108
00:40:48,800 --> 00:40:51,520
everybody with in the session are able

1109
00:40:51,520 --> 00:40:53,440
to participate and attend and comes up

1110
00:40:53,440 --> 00:40:55,280
with uh comes up with the threat that

1111
00:40:55,280 --> 00:40:57,040
they can't come up with and break that

1112
00:40:57,040 --> 00:41:00,560
barrier um of uh you know openly talking

1113
00:41:00,560 --> 00:41:03,119
about what could go wrong here so

1114
00:41:03,119 --> 00:41:04,839
highly highly gamify

1115
00:41:04,839 --> 00:41:08,160
this and we are going to be using the

1116
00:41:08,160 --> 00:41:11,280
framework um straight that past our

1117
00:41:11,280 --> 00:41:13,760
diamond that megan walked us through but

1118
00:41:13,760 --> 00:41:16,000
we are going to use arthrit just to

1119
00:41:16,000 --> 00:41:18,319
recap what stride is uh stride is

1120
00:41:18,319 --> 00:41:21,200
basically uh spoofing tampering

1121
00:41:21,200 --> 00:41:24,480
um repudiation information disclosure

1122
00:41:24,480 --> 00:41:27,119
denial of service and elevation of

1123
00:41:27,119 --> 00:41:29,200
privilege is what we are going to use

1124
00:41:29,200 --> 00:41:31,680
that as a format and identify those uh

1125
00:41:31,680 --> 00:41:34,480
thoughts here

1126
00:41:34,480 --> 00:41:36,480
one thing i want to note it down here is

1127
00:41:36,480 --> 00:41:39,119
i want to acknowledge the fact that um

1128
00:41:39,119 --> 00:41:41,119
this application has a solid

1129
00:41:41,119 --> 00:41:44,319
segmentation um which has multiple

1130
00:41:44,319 --> 00:41:47,200
subnets that reduces the landscape

1131
00:41:47,200 --> 00:41:49,599
threat landscape here or attack surface

1132
00:41:49,599 --> 00:41:52,079
you can call it um so it's a really good

1133
00:41:52,079 --> 00:41:53,599
segmentation and

1134
00:41:53,599 --> 00:41:57,040
um and not only the segmentation it also

1135
00:41:57,040 --> 00:41:58,319
has

1136
00:41:58,319 --> 00:42:00,480
its own security each component has its

1137
00:42:00,480 --> 00:42:03,599
own security group which is great

1138
00:42:03,599 --> 00:42:06,880
so let's go into identifying some

1139
00:42:06,880 --> 00:42:08,880
threats here hopefully you would catch

1140
00:42:08,880 --> 00:42:10,960
what i'm going through by no means it's

1141
00:42:10,960 --> 00:42:13,440
all complete um i'm sure we can find a

1142
00:42:13,440 --> 00:42:15,680
larger but for the purpose of this

1143
00:42:15,680 --> 00:42:17,680
presentation i'm going to stick with a

1144
00:42:17,680 --> 00:42:19,280
couple of them

1145
00:42:19,280 --> 00:42:22,400
malaysia's 5 cent um this is the case of

1146
00:42:22,400 --> 00:42:25,119
tampering where you would somebody would

1147
00:42:25,119 --> 00:42:28,560
tamper uh the you know get access to to

1148
00:42:28,560 --> 00:42:31,280
to the uh the location and change the

1149
00:42:31,280 --> 00:42:33,680
file uh probably the data within the

1150
00:42:33,680 --> 00:42:35,040
file or

1151
00:42:35,040 --> 00:42:37,520
change the entire file itself if you are

1152
00:42:37,520 --> 00:42:40,160
looking at or expecting csv file it

1153
00:42:40,160 --> 00:42:42,960
could just send you jpeg with the bad

1154
00:42:42,960 --> 00:42:45,440
code in it that could be devastating if

1155
00:42:45,440 --> 00:42:47,359
that uh well

1156
00:42:47,359 --> 00:42:49,359
if that threat um exploits the

1157
00:42:49,359 --> 00:42:52,480
vulnerability that we have

1158
00:42:52,480 --> 00:42:55,280
other one i can think of is again this

1159
00:42:55,280 --> 00:42:57,520
is uh the element of spoofing will come

1160
00:42:57,520 --> 00:42:59,040
into picture where

1161
00:42:59,040 --> 00:43:01,440
uh an attacker can

1162
00:43:01,440 --> 00:43:05,119
act as a spoof as a valid user can get

1163
00:43:05,119 --> 00:43:06,640
onto the ui

1164
00:43:06,640 --> 00:43:09,200
and navigate through and get the data

1165
00:43:09,200 --> 00:43:11,359
exploit the data or do some damage to

1166
00:43:11,359 --> 00:43:12,960
the system

1167
00:43:12,960 --> 00:43:15,280
data security that goes with information

1168
00:43:15,280 --> 00:43:18,319
disclosure is a big thing uh since this

1169
00:43:18,319 --> 00:43:21,119
is in a billing application um obviously

1170
00:43:21,119 --> 00:43:24,240
you would have some npa data

1171
00:43:24,240 --> 00:43:28,000
you have to make sure they are protected

1172
00:43:28,000 --> 00:43:31,920
developer rotation this is often time um

1173
00:43:31,920 --> 00:43:34,079
not looked at so that's why i wanted to

1174
00:43:34,079 --> 00:43:36,000
bring it here elevation approval age

1175
00:43:36,000 --> 00:43:38,000
element is in picture here

1176
00:43:38,000 --> 00:43:39,520
um

1177
00:43:39,520 --> 00:43:42,720
the smaller organization uh sometimes

1178
00:43:42,720 --> 00:43:44,880
most of the time they have shared the

1179
00:43:44,880 --> 00:43:47,520
developer resources where they would

1180
00:43:47,520 --> 00:43:49,359
work on this project and then they move

1181
00:43:49,359 --> 00:43:50,800
on to the next project

1182
00:43:50,800 --> 00:43:53,599
when they do it is very critical it is

1183
00:43:53,599 --> 00:43:55,520
important to make sure the access

1184
00:43:55,520 --> 00:43:58,319
control is cut off if not necessary um

1185
00:43:58,319 --> 00:44:00,480
very critical here the same goes with

1186
00:44:00,480 --> 00:44:02,960
access control and that's part of

1187
00:44:02,960 --> 00:44:06,800
elevation of privilege where

1188
00:44:07,040 --> 00:44:09,920
an admin user i should not have access

1189
00:44:09,920 --> 00:44:10,640
to

1190
00:44:10,640 --> 00:44:14,079
update a transaction or upload a file so

1191
00:44:14,079 --> 00:44:16,400
that need to know at least a privilege

1192
00:44:16,400 --> 00:44:19,680
uh the fundamental of best practices

1193
00:44:19,680 --> 00:44:22,079
should have should be followed here so

1194
00:44:22,079 --> 00:44:24,720
that could be one of the threads

1195
00:44:24,720 --> 00:44:27,920
abstract finding and this would um tick

1196
00:44:27,920 --> 00:44:30,800
off all the elements of stride um

1197
00:44:30,800 --> 00:44:32,720
depends on the vulnerability that you

1198
00:44:32,720 --> 00:44:35,920
can find on the database or you can find

1199
00:44:35,920 --> 00:44:38,640
on the web ui or even

1200
00:44:38,640 --> 00:44:42,960
um on the api itself so you do have to

1201
00:44:42,960 --> 00:44:46,000
see what vulnerabilities how your patch

1202
00:44:46,000 --> 00:44:48,560
management will look like um it's very

1203
00:44:48,560 --> 00:44:51,040
critical here

1204
00:44:51,040 --> 00:44:53,760
there's one uh example i wanted to

1205
00:44:53,760 --> 00:44:56,079
provide for denial of service

1206
00:44:56,079 --> 00:44:58,079
what if if an attacker sends you

1207
00:44:58,079 --> 00:45:00,240
thousands of file wherein your lambda

1208
00:45:00,240 --> 00:45:02,560
function is designed or expecting to do

1209
00:45:02,560 --> 00:45:04,800
only one file at a time

1210
00:45:04,800 --> 00:45:06,880
this will bring down your entire system

1211
00:45:06,880 --> 00:45:09,760
you are not able to uh process the

1212
00:45:09,760 --> 00:45:12,240
actual real file

1213
00:45:12,240 --> 00:45:14,400
which which means your availability of

1214
00:45:14,400 --> 00:45:16,400
the system will be gone so you have to

1215
00:45:16,400 --> 00:45:17,760
think through

1216
00:45:17,760 --> 00:45:19,839
all of those elements and see what can

1217
00:45:19,839 --> 00:45:22,319
go wrong

1218
00:45:22,400 --> 00:45:24,240
again that this is not complete list

1219
00:45:24,240 --> 00:45:26,319
there are a lot more we can come up with

1220
00:45:26,319 --> 00:45:28,480
but i'm just limiting for this uh for

1221
00:45:28,480 --> 00:45:30,079
this webinar here

1222
00:45:30,079 --> 00:45:32,560
um once you find those threads you have

1223
00:45:32,560 --> 00:45:35,440
to document them kind of register i

1224
00:45:35,440 --> 00:45:38,720
would call um and uh see whatever tool

1225
00:45:38,720 --> 00:45:41,040
of your choice um according to your

1226
00:45:41,040 --> 00:45:42,319
organization

1227
00:45:42,319 --> 00:45:44,079
you would um

1228
00:45:44,079 --> 00:45:46,160
you would you would register them you

1229
00:45:46,160 --> 00:45:48,960
would document them um here the risk you

1230
00:45:48,960 --> 00:45:50,160
see here

1231
00:45:50,160 --> 00:45:52,880
is i have mentioned this high this is

1232
00:45:52,880 --> 00:45:54,240
before you

1233
00:45:54,240 --> 00:45:55,839
before you uh

1234
00:45:55,839 --> 00:45:58,640
add any context or before you know what

1235
00:45:58,640 --> 00:46:00,720
kind of medication control you have in

1236
00:46:00,720 --> 00:46:03,760
place um so it's now came up with a high

1237
00:46:03,760 --> 00:46:05,920
you would document to whatever we have

1238
00:46:05,920 --> 00:46:07,119
found now

1239
00:46:07,119 --> 00:46:09,520
then i want to go back into

1240
00:46:09,520 --> 00:46:11,760
the next step would be you have to go

1241
00:46:11,760 --> 00:46:14,400
deep dive into each one of them and see

1242
00:46:14,400 --> 00:46:17,280
how you want to address this right

1243
00:46:17,280 --> 00:46:19,520
so let's take one

1244
00:46:19,520 --> 00:46:21,839
example here um which is you know

1245
00:46:21,839 --> 00:46:23,839
malaysia's file upload

1246
00:46:23,839 --> 00:46:25,359
uh would cause an insecure

1247
00:46:25,359 --> 00:46:27,680
decentralization attack if it's not if

1248
00:46:27,680 --> 00:46:30,079
you don't have the right control in

1249
00:46:30,079 --> 00:46:32,160
you will have to find out okay what

1250
00:46:32,160 --> 00:46:34,640
control we have now um medicating

1251
00:46:34,640 --> 00:46:36,720
control or compensated control what do

1252
00:46:36,720 --> 00:46:39,440
we do here in order to

1253
00:46:39,440 --> 00:46:42,079
in order to uh com in order to bring the

1254
00:46:42,079 --> 00:46:44,480
risk level to uh low

1255
00:46:44,480 --> 00:46:46,880
so once if you have

1256
00:46:46,880 --> 00:46:50,319
say for example sso mfa only thruster

1257
00:46:50,319 --> 00:46:53,760
resource can be deserialized um but then

1258
00:46:53,760 --> 00:46:57,119
your risk level could go back to medium

1259
00:46:57,119 --> 00:46:58,880
in that case

1260
00:46:58,880 --> 00:47:01,760
um you can open up a backlog story and

1261
00:47:01,760 --> 00:47:04,560
um and then you know get it prioritized

1262
00:47:04,560 --> 00:47:06,480
but if your threat level is still high

1263
00:47:06,480 --> 00:47:08,720
or critical and the step four of

1264
00:47:08,720 --> 00:47:10,960
communicating is very critical here you

1265
00:47:10,960 --> 00:47:12,880
have to let your leadership know that

1266
00:47:12,880 --> 00:47:14,560
you have this vulnerability high and

1267
00:47:14,560 --> 00:47:16,160
critical and they can help you

1268
00:47:16,160 --> 00:47:18,960
prioritize them so the recommendations

1269
00:47:18,960 --> 00:47:21,599
here by the scan obviously file size

1270
00:47:21,599 --> 00:47:24,960
check um if you have if you're expecting

1271
00:47:24,960 --> 00:47:28,000
10 gig and uh the file size is 100k you

1272
00:47:28,000 --> 00:47:30,720
have to make sure um you are uh you have

1273
00:47:30,720 --> 00:47:33,520
some controls to test that and privilege

1274
00:47:33,520 --> 00:47:35,920
user access should be monitored like i

1275
00:47:35,920 --> 00:47:37,920
mean admin users should not be able to

1276
00:47:37,920 --> 00:47:40,400
go back and and update the data

1277
00:47:40,400 --> 00:47:42,880
one more example i want to give you here

1278
00:47:42,880 --> 00:47:46,079
um i would like to see the uh time i

1279
00:47:46,079 --> 00:47:47,599
want to make sure we are cognizant of

1280
00:47:47,599 --> 00:47:50,960
time here all right so one example here

1281
00:47:50,960 --> 00:47:52,559
i want to take it this is the example

1282
00:47:52,559 --> 00:47:55,280
where you would accept the risk

1283
00:47:55,280 --> 00:47:58,160
um in that array i

1284
00:47:58,160 --> 00:47:59,680
i wanted to show you this example where

1285
00:47:59,680 --> 00:48:02,240
you can accept it

1286
00:48:02,240 --> 00:48:04,880
i'm going to pass for a second here why

1287
00:48:04,880 --> 00:48:07,599
this is a threat let me know what do you

1288
00:48:07,599 --> 00:48:09,760
think this could be a threat for the

1289
00:48:09,760 --> 00:48:12,400
organization

1290
00:48:14,640 --> 00:48:15,760
okay

1291
00:48:15,760 --> 00:48:17,760
um i'm going to come up with this this

1292
00:48:17,760 --> 00:48:19,839
is what i came up with

1293
00:48:19,839 --> 00:48:23,520
by allowing the report locations means

1294
00:48:23,520 --> 00:48:26,079
that any sensitive data can be visible

1295
00:48:26,079 --> 00:48:28,559
to your friends and families of employee

1296
00:48:28,559 --> 00:48:30,160
this directly goes to the element of

1297
00:48:30,160 --> 00:48:33,040
stride so you will have you will have to

1298
00:48:33,040 --> 00:48:34,640
find out what medication control you

1299
00:48:34,640 --> 00:48:36,400
have or compensating control you already

1300
00:48:36,400 --> 00:48:38,640
have and which will reduce your risk

1301
00:48:38,640 --> 00:48:41,520
relating to uh the law um if you have

1302
00:48:41,520 --> 00:48:43,760
those controls in place so for example

1303
00:48:43,760 --> 00:48:45,680
you don't have to show

1304
00:48:45,680 --> 00:48:47,440
all sensitive information in every

1305
00:48:47,440 --> 00:48:50,000
screen you can mask them you show them

1306
00:48:50,000 --> 00:48:53,119
only when it is absolutely needed that's

1307
00:48:53,119 --> 00:48:54,800
one of the control you can implement if

1308
00:48:54,800 --> 00:48:56,160
you don't have it

1309
00:48:56,160 --> 00:48:58,720
uh on a composite control obviously you

1310
00:48:58,720 --> 00:49:01,359
can recommend the privacy screen you can

1311
00:49:01,359 --> 00:49:04,880
give them a mandatory cbt where uh the

1312
00:49:04,880 --> 00:49:07,200
employees goes through and see how they

1313
00:49:07,200 --> 00:49:09,680
can work from home safe and secure um

1314
00:49:09,680 --> 00:49:11,359
obviously you can do a background check

1315
00:49:11,359 --> 00:49:12,960
on employees

1316
00:49:12,960 --> 00:49:14,800
so the recommendation i come up with

1317
00:49:14,800 --> 00:49:16,480
this you know document the thread for

1318
00:49:16,480 --> 00:49:18,640
visibility of course and then can you

1319
00:49:18,640 --> 00:49:23,200
continue to monitor for any anti-parents

1320
00:49:23,200 --> 00:49:25,359
so going back to the documentation now

1321
00:49:25,359 --> 00:49:27,520
the risk is reduced to a medium for the

1322
00:49:27,520 --> 00:49:29,599
first example that we walked us through

1323
00:49:29,599 --> 00:49:32,240
you will go into uh each one of them and

1324
00:49:32,240 --> 00:49:34,559
do the same exercise on what you will do

1325
00:49:34,559 --> 00:49:36,240
what kind of story it is going to create

1326
00:49:36,240 --> 00:49:37,599
for you how you can

1327
00:49:37,599 --> 00:49:40,160
prioritize them

1328
00:49:40,160 --> 00:49:43,280
so we have done a step one to four um

1329
00:49:43,280 --> 00:49:45,520
and now this part validation part is

1330
00:49:45,520 --> 00:49:48,160
really really critical uh the reason is

1331
00:49:48,160 --> 00:49:49,200
you know did you cover the right

1332
00:49:49,200 --> 00:49:51,280
component you have to make sure you're

1333
00:49:51,280 --> 00:49:53,200
not covering you are covering the right

1334
00:49:53,200 --> 00:49:56,079
component so that um you know it makes

1335
00:49:56,079 --> 00:49:58,720
sense and sense for that session

1336
00:49:58,720 --> 00:50:01,359
and did you have

1337
00:50:01,359 --> 00:50:04,400
all a level of uh skill set in that

1338
00:50:04,400 --> 00:50:07,040
session do you have extended team come

1339
00:50:07,040 --> 00:50:09,760
on board and attend the session to go

1340
00:50:09,760 --> 00:50:13,119
with go through this exercise with you

1341
00:50:13,119 --> 00:50:15,280
did you find enough stress most

1342
00:50:15,280 --> 00:50:17,760
importantly did you find the right

1343
00:50:17,760 --> 00:50:20,319
threads it's very critical and also i

1344
00:50:20,319 --> 00:50:21,680
have to make sure

1345
00:50:21,680 --> 00:50:23,680
the thoughts that are identified are

1346
00:50:23,680 --> 00:50:27,200
visible and actionable are you acting on

1347
00:50:27,200 --> 00:50:29,680
the threat that you have found um i like

1348
00:50:29,680 --> 00:50:32,000
the example what megan said you know

1349
00:50:32,000 --> 00:50:35,040
that she's trusted on if you have acted

1350
00:50:35,040 --> 00:50:37,680
on a threat did it introduce any new

1351
00:50:37,680 --> 00:50:40,640
threat um that has to be uh you know

1352
00:50:40,640 --> 00:50:43,440
looked at and then had to be documented

1353
00:50:43,440 --> 00:50:44,720
as well

1354
00:50:44,720 --> 00:50:46,640
and uh is the approach to threat

1355
00:50:46,640 --> 00:50:49,680
modeling working uh what i mean by that

1356
00:50:49,680 --> 00:50:53,920
is um you know there are ways to uh

1357
00:50:53,920 --> 00:50:55,760
validate if this approach is working or

1358
00:50:55,760 --> 00:50:59,200
not for example pen testing um if you

1359
00:50:59,200 --> 00:51:01,440
have a lesson number of uh findings

1360
00:51:01,440 --> 00:51:04,160
that's uh that's one way to see if this

1361
00:51:04,160 --> 00:51:05,920
approach is working for you

1362
00:51:05,920 --> 00:51:09,599
secondly you do um

1363
00:51:09,599 --> 00:51:12,800
and also you have to make sure that uh

1364
00:51:12,800 --> 00:51:14,960
this approach you know the ping testing

1365
00:51:14,960 --> 00:51:17,359
is less and also have to make sure that

1366
00:51:17,359 --> 00:51:21,920
uh um the uh your devsex

1367
00:51:21,920 --> 00:51:23,040
cycle

1368
00:51:23,040 --> 00:51:25,760
is lesser now so all of the all of those

1369
00:51:25,760 --> 00:51:28,240
metrics will tell you if this approach

1370
00:51:28,240 --> 00:51:31,599
is working or not for you

1371
00:51:31,599 --> 00:51:35,359
all right right um so here are the recap

1372
00:51:35,359 --> 00:51:36,880
are the five steps of threat modeling

1373
00:51:36,880 --> 00:51:39,440
create the model identify the threats

1374
00:51:39,440 --> 00:51:40,960
address the threats communicate the

1375
00:51:40,960 --> 00:51:44,640
results and validate it

1376
00:51:44,640 --> 00:51:48,480
now that um go back to the example we uh

1377
00:51:48,480 --> 00:51:50,240
we started up with you know going for a

1378
00:51:50,240 --> 00:51:52,880
walk and things you would do right uh

1379
00:51:52,880 --> 00:51:54,880
now that you know all these five steps

1380
00:51:54,880 --> 00:51:58,480
of threat modeling um apply them apply

1381
00:51:58,480 --> 00:52:01,680
them into uh every day uh you know

1382
00:52:01,680 --> 00:52:04,079
development life cycle to make sure that

1383
00:52:04,079 --> 00:52:06,960
if that is the future or if it's a

1384
00:52:06,960 --> 00:52:09,440
component or a new initiative um you

1385
00:52:09,440 --> 00:52:12,240
would have to apply them go back to uh

1386
00:52:12,240 --> 00:52:15,839
that example i provided before and

1387
00:52:15,839 --> 00:52:19,040
go simple don't over think it go broad

1388
00:52:19,040 --> 00:52:21,760
as you can there's no one way or one

1389
00:52:21,760 --> 00:52:25,040
right way to do this um and introduce

1390
00:52:25,040 --> 00:52:26,559
that one there's one thing if you have

1391
00:52:26,559 --> 00:52:29,200
to take it away from this presentation

1392
00:52:29,200 --> 00:52:31,760
i this would be it

1393
00:52:31,760 --> 00:52:33,920
introduce the third modeling to

1394
00:52:33,920 --> 00:52:35,599
your development team and read the

1395
00:52:35,599 --> 00:52:38,800
benefit of threat modeling

1396
00:52:38,800 --> 00:52:42,480
with that i conclude our presentation

1397
00:52:42,480 --> 00:52:45,040
and here are the references so that you

1398
00:52:45,040 --> 00:52:46,800
can use

1399
00:52:46,800 --> 00:52:49,760
and um here's our contact information uh

1400
00:52:49,760 --> 00:52:50,960
we can

1401
00:52:50,960 --> 00:52:53,200
we can be available on linkedin and

1402
00:52:53,200 --> 00:52:55,280
megan can be contacted on twitter as

1403
00:52:55,280 --> 00:52:56,480
well

1404
00:52:56,480 --> 00:53:00,319
now we are ready for q a

