1
00:00:01,420 --> 00:00:05,200
[Music]

2
00:00:05,200 --> 00:00:07,919
welcoming you to global appsec i'm

3
00:00:07,919 --> 00:00:11,360
really excited to be here

4
00:00:11,360 --> 00:00:13,040
and

5
00:00:13,040 --> 00:00:14,799
this talk

6
00:00:14,799 --> 00:00:18,400
this talk is actually 26 years in the

7
00:00:18,400 --> 00:00:20,560
making i'll talk about the off by one

8
00:00:20,560 --> 00:00:23,039
error in just a minute

9
00:00:23,039 --> 00:00:27,599
but 25 26 years ago i was

10
00:00:27,599 --> 00:00:32,320
working for a bank and it was my first

11
00:00:32,320 --> 00:00:34,800
appsec role and so i

12
00:00:34,800 --> 00:00:38,879
recently was rebuilding my website

13
00:00:38,879 --> 00:00:41,200
i found this file which i had put on the

14
00:00:41,200 --> 00:00:44,239
web and i was like wow this thing is 25

15
00:00:44,239 --> 00:00:45,920
years old it's a

16
00:00:45,920 --> 00:00:49,039
it's a few months older than olive ones

17
00:00:49,039 --> 00:00:51,680
um smashing the stack which had its

18
00:00:51,680 --> 00:00:54,719
anniversary just a couple of days ago

19
00:00:54,719 --> 00:00:57,120
and so i started thinking about

20
00:00:57,120 --> 00:01:00,800
what is how is the world changed in this

21
00:01:00,800 --> 00:01:02,000
time

22
00:01:02,000 --> 00:01:04,479
and that led me towards how will where

23
00:01:04,479 --> 00:01:08,240
are we now and how will the world change

24
00:01:08,240 --> 00:01:11,200
and so with that let's get going

25
00:01:11,200 --> 00:01:12,400
um

26
00:01:12,400 --> 00:01:14,640
martin gave me a very kind introduction

27
00:01:14,640 --> 00:01:17,119
i don't need to do that

28
00:01:17,119 --> 00:01:19,920
and my agenda today is pretty simple it

29
00:01:19,920 --> 00:01:22,799
is the past the present and the future

30
00:01:22,799 --> 00:01:26,159
of apsec with some remembrances along

31
00:01:26,159 --> 00:01:27,759
the way

32
00:01:27,759 --> 00:01:30,960
so let me start out in the past

33
00:01:30,960 --> 00:01:35,119
so in 1995 i was contracting at fidelity

34
00:01:35,119 --> 00:01:36,720
investments

35
00:01:36,720 --> 00:01:37,600
and

36
00:01:37,600 --> 00:01:39,360
reviewing code that went into their

37
00:01:39,360 --> 00:01:41,439
firewall systems

38
00:01:41,439 --> 00:01:43,520
and there was a lot of competition at

39
00:01:43,520 --> 00:01:47,439
the time to provide financial services

40
00:01:47,439 --> 00:01:51,119
via this new world wide web thing

41
00:01:51,119 --> 00:01:53,680
and that competition

42
00:01:53,680 --> 00:01:56,560
led to

43
00:01:56,560 --> 00:01:59,920
led to tension between

44
00:01:59,920 --> 00:02:02,960
the business and security weird i mean

45
00:02:02,960 --> 00:02:06,079
we've solved that one right um

46
00:02:06,079 --> 00:02:06,960
but

47
00:02:06,960 --> 00:02:11,120
we haven't really solved that one and

48
00:02:11,120 --> 00:02:15,520
this is this is an example of

49
00:02:16,160 --> 00:02:17,760
the way in which the world stays the

50
00:02:17,760 --> 00:02:20,160
same which i'll talk about um but i

51
00:02:20,160 --> 00:02:24,080
wrote a set of guidelines to er to help

52
00:02:24,080 --> 00:02:27,200
manage that conflict better

53
00:02:27,200 --> 00:02:30,239
um and i got the okay to share these in

54
00:02:30,239 --> 00:02:32,800
august of 1996 and i want to thank the

55
00:02:32,800 --> 00:02:34,720
folks at fidelity i'm not speaking for

56
00:02:34,720 --> 00:02:36,560
them obviously i want to thank steve

57
00:02:36,560 --> 00:02:37,760
mcclellan

58
00:02:37,760 --> 00:02:39,680
and if i had better notes i would thank

59
00:02:39,680 --> 00:02:41,680
the whole darn team because it was a

60
00:02:41,680 --> 00:02:44,879
great team to have worked with

61
00:02:44,879 --> 00:02:46,640
um

62
00:02:46,640 --> 00:02:49,040
but let's let me explain the situation

63
00:02:49,040 --> 00:02:52,080
in a little more detail

64
00:02:52,080 --> 00:02:53,840
so

65
00:02:53,840 --> 00:02:56,239
situation looked roughly like this there

66
00:02:56,239 --> 00:02:58,640
were web browsers like uh netscape

67
00:02:58,640 --> 00:03:00,239
navigator

68
00:03:00,239 --> 00:03:03,280
and people would use that to connect to

69
00:03:03,280 --> 00:03:04,640
a proxy

70
00:03:04,640 --> 00:03:07,760
and the proxy would terminate tcp

71
00:03:07,760 --> 00:03:09,840
would

72
00:03:09,840 --> 00:03:13,440
send a request based on its code to some

73
00:03:13,440 --> 00:03:15,599
internal system

74
00:03:15,599 --> 00:03:18,159
and that was custom code that was being

75
00:03:18,159 --> 00:03:19,440
written by

76
00:03:19,440 --> 00:03:21,760
teams around the company

77
00:03:21,760 --> 00:03:24,720
and we were aware even then that that

78
00:03:24,720 --> 00:03:30,000
code was in danger in various ways

79
00:03:30,000 --> 00:03:30,840
and

80
00:03:30,840 --> 00:03:35,040
so what we did was we created these code

81
00:03:35,040 --> 00:03:37,360
review guidelines and and you can see

82
00:03:37,360 --> 00:03:38,799
here

83
00:03:38,799 --> 00:03:41,760
and you can see here that this document

84
00:03:41,760 --> 00:03:44,080
has two purposes

85
00:03:44,080 --> 00:03:46,080
it was a guideline and checklist for the

86
00:03:46,080 --> 00:03:48,080
security team

87
00:03:48,080 --> 00:03:50,480
and it was an attempt to give the

88
00:03:50,480 --> 00:03:52,959
development teams

89
00:03:52,959 --> 00:03:54,560
information about what we were going to

90
00:03:54,560 --> 00:03:57,840
look for in a sense this is what we now

91
00:03:57,840 --> 00:04:00,720
talk about when we talk about peeved

92
00:04:00,720 --> 00:04:03,760
roads and it was a much more primitive

93
00:04:03,760 --> 00:04:06,000
approach than today's paved roads but

94
00:04:06,000 --> 00:04:10,159
it's a it is in a sense a precursor

95
00:04:10,159 --> 00:04:12,560
and at the end of this talk i'm going to

96
00:04:12,560 --> 00:04:16,160
give you a link to my blog it will have

97
00:04:16,160 --> 00:04:18,000
the slides the final version of the

98
00:04:18,000 --> 00:04:19,680
slides a few minutes after the talk

99
00:04:19,680 --> 00:04:21,120
concludes

100
00:04:21,120 --> 00:04:23,199
and it will have all of the links which

101
00:04:23,199 --> 00:04:25,199
are in this talk which i think are

102
00:04:25,199 --> 00:04:27,199
interesting for you to follow

103
00:04:27,199 --> 00:04:28,880
so you're welcome of course to take

104
00:04:28,880 --> 00:04:31,360
screenshots but all of it will be

105
00:04:31,360 --> 00:04:34,639
available in a few minutes

106
00:04:35,680 --> 00:04:37,680
so what's in the guidelines what's in

107
00:04:37,680 --> 00:04:39,759
the guidelines is

108
00:04:39,759 --> 00:04:41,840
some discussion of architecture

109
00:04:41,840 --> 00:04:45,120
including what data flows do you have

110
00:04:45,120 --> 00:04:47,280
there is some

111
00:04:47,280 --> 00:04:49,440
discussion of logging there's specifics

112
00:04:49,440 --> 00:04:51,840
like charaot trigrud is an early

113
00:04:51,840 --> 00:04:54,160
sandboxing technology and we knew there

114
00:04:54,160 --> 00:04:58,560
were issues with it for example if you

115
00:04:58,560 --> 00:05:00,080
had a

116
00:05:00,080 --> 00:05:02,320
had a link out of the truthered area the

117
00:05:02,320 --> 00:05:04,000
attacker could follow that link and

118
00:05:04,000 --> 00:05:06,160
break the sandbox

119
00:05:06,160 --> 00:05:09,360
so there was input validation we knew

120
00:05:09,360 --> 00:05:12,240
about dangerous functions like gets and

121
00:05:12,240 --> 00:05:15,039
system and even stir copy

122
00:05:15,039 --> 00:05:18,160
uh and these guidelines were focused on

123
00:05:18,160 --> 00:05:21,199
c c plus plus and perl because that's

124
00:05:21,199 --> 00:05:25,039
what was current at the time

125
00:05:25,039 --> 00:05:27,759
there were looking back there were a lot

126
00:05:27,759 --> 00:05:30,400
of things we didn't have

127
00:05:30,400 --> 00:05:33,360
we didn't have any tooling literally no

128
00:05:33,360 --> 00:05:35,360
tooling we didn't have static analysis

129
00:05:35,360 --> 00:05:37,759
we didn't have fuzzers

130
00:05:37,759 --> 00:05:40,320
we didn't have books that were focused

131
00:05:40,320 --> 00:05:42,080
on software security

132
00:05:42,080 --> 00:05:44,479
gary mcgraw's building secure software

133
00:05:44,479 --> 00:05:46,560
mike howard and dave leblanc through

134
00:05:46,560 --> 00:05:49,039
writing secure code

135
00:05:49,039 --> 00:05:51,520
lincoln stein's web security these were

136
00:05:51,520 --> 00:05:53,759
all in the future

137
00:05:53,759 --> 00:05:55,280
we didn't have consultants who were

138
00:05:55,280 --> 00:05:56,960
focused on apsec

139
00:05:56,960 --> 00:05:59,039
we didn't have penetration testers who

140
00:05:59,039 --> 00:06:01,280
called themselves that

141
00:06:01,280 --> 00:06:02,880
we didn't have structured threat

142
00:06:02,880 --> 00:06:03,919
modeling

143
00:06:03,919 --> 00:06:05,680
i was not aware at the time of ed

144
00:06:05,680 --> 00:06:09,039
amoroso's work on attack trees the book

145
00:06:09,039 --> 00:06:10,880
had published a year or two earlier and

146
00:06:10,880 --> 00:06:12,160
i

147
00:06:12,160 --> 00:06:15,039
didn't wasn't aware of it

148
00:06:15,039 --> 00:06:16,880
um but we did have

149
00:06:16,880 --> 00:06:18,960
business conflict and we had a need for

150
00:06:18,960 --> 00:06:21,039
support we had a need to help people

151
00:06:21,039 --> 00:06:22,880
move quickly

152
00:06:22,880 --> 00:06:24,720
some other perspective i mentioned

153
00:06:24,720 --> 00:06:27,759
smashing the stack 25 years old

154
00:06:27,759 --> 00:06:30,560
now happy birthday to that paper

155
00:06:30,560 --> 00:06:31,680
we had some

156
00:06:31,680 --> 00:06:34,240
mailing lists and usedna nat as are

157
00:06:34,240 --> 00:06:38,000
forms of community they're on bug track

158
00:06:38,000 --> 00:06:40,319
on the original firewalls mailing list

159
00:06:40,319 --> 00:06:41,919
on cypherpunks

160
00:06:41,919 --> 00:06:43,919
there was discussion of secure coding

161
00:06:43,919 --> 00:06:47,120
but there was no place where we

162
00:06:47,120 --> 00:06:50,080
in appsec could get together and talk in

163
00:06:50,080 --> 00:06:51,280
depth

164
00:06:51,280 --> 00:06:53,919
about what it was we were trying to

165
00:06:53,919 --> 00:06:55,680
achieve

166
00:06:55,680 --> 00:06:58,560
we did have some great books uh cheswick

167
00:06:58,560 --> 00:07:00,319
and bellevin's firewalls and internet

168
00:07:00,319 --> 00:07:01,759
security

169
00:07:01,759 --> 00:07:04,800
talks about the difficulty of patching

170
00:07:04,800 --> 00:07:07,199
all of that code of finding all of those

171
00:07:07,199 --> 00:07:08,400
phones

172
00:07:08,400 --> 00:07:11,440
and therefore the need to use firewalls

173
00:07:11,440 --> 00:07:13,440
to protect what's inside until we can

174
00:07:13,440 --> 00:07:15,440
make those updates

175
00:07:15,440 --> 00:07:17,919
spafford and garfinkel's practical unix

176
00:07:17,919 --> 00:07:20,400
and internet security does talk

177
00:07:20,400 --> 00:07:23,599
about writing secure code

178
00:07:23,599 --> 00:07:26,240
there's a few pages in the network

179
00:07:26,240 --> 00:07:28,479
proxies on your section on writing your

180
00:07:28,479 --> 00:07:29,360
own

181
00:07:29,360 --> 00:07:32,240
and in the chapter on safe network and

182
00:07:32,240 --> 00:07:35,280
set uid programming there's a good three

183
00:07:35,280 --> 00:07:36,800
pages

184
00:07:36,800 --> 00:07:40,080
and and that was what we had to go with

185
00:07:40,080 --> 00:07:43,360
a lot a lot of the framing

186
00:07:43,360 --> 00:07:47,360
of how we were thinking about security

187
00:07:47,360 --> 00:07:49,919
was papers like this one by dan farmer

188
00:07:49,919 --> 00:07:52,319
and whitsey venema

189
00:07:52,319 --> 00:07:54,160
improving the security of your site by

190
00:07:54,160 --> 00:07:56,160
breaking into it

191
00:07:56,160 --> 00:07:58,120
this was a very

192
00:07:58,120 --> 00:08:00,319
attacker-centered viewpoint we're going

193
00:08:00,319 --> 00:08:03,120
to run some network scans to find

194
00:08:03,120 --> 00:08:05,759
vulnerabilities and exposures

195
00:08:05,759 --> 00:08:08,080
and in doing so we're going to find the

196
00:08:08,080 --> 00:08:10,960
things that you need to reconfigure

197
00:08:10,960 --> 00:08:13,440
hardened turn off so you can protect

198
00:08:13,440 --> 00:08:15,840
your systems

199
00:08:15,840 --> 00:08:16,720
now

200
00:08:16,720 --> 00:08:20,319
moving forward going across 25 years of

201
00:08:20,319 --> 00:08:22,720
appsec incredibly quickly

202
00:08:22,720 --> 00:08:25,199
martin mentioned that a wasp just had

203
00:08:25,199 --> 00:08:28,720
its 20th anniversary happy birthday

204
00:08:28,720 --> 00:08:29,919
um

205
00:08:29,919 --> 00:08:31,599
microsoft's

206
00:08:31,599 --> 00:08:34,080
trustworthy computing memo and secure

207
00:08:34,080 --> 00:08:36,659
development life cycle happened and

208
00:08:36,659 --> 00:08:38,000
[Music]

209
00:08:38,000 --> 00:08:40,479
i joined microsoft a few years after

210
00:08:40,479 --> 00:08:42,240
this when it came out i was really

211
00:08:42,240 --> 00:08:43,440
skeptical

212
00:08:43,440 --> 00:08:45,120
um

213
00:08:45,120 --> 00:08:46,160
but

214
00:08:46,160 --> 00:08:47,600
what we saw

215
00:08:47,600 --> 00:08:50,000
was that a big company

216
00:08:50,000 --> 00:08:52,959
that ships a lot of software could take

217
00:08:52,959 --> 00:08:56,480
on the idea that everyone was going to

218
00:08:56,480 --> 00:08:58,000
engage with

219
00:08:58,000 --> 00:09:01,600
security and be responsible for it

220
00:09:01,600 --> 00:09:03,839
and in the early days they even stood

221
00:09:03,839 --> 00:09:06,959
down and delayed ship on products

222
00:09:06,959 --> 00:09:11,040
and in 2001 2002 not only was that a

223
00:09:11,040 --> 00:09:13,440
shopping choice

224
00:09:13,440 --> 00:09:15,680
it was doubly shocking that it was

225
00:09:15,680 --> 00:09:18,560
microsoft that would do it because we

226
00:09:18,560 --> 00:09:20,560
talk about move fast and break things

227
00:09:20,560 --> 00:09:24,480
today or ship it and fix it in v2

228
00:09:24,480 --> 00:09:28,080
microsoft was big on that at the time

229
00:09:28,080 --> 00:09:31,200
there's been a profusion of commercial

230
00:09:31,200 --> 00:09:32,240
tooling

231
00:09:32,240 --> 00:09:33,760
um

232
00:09:33,760 --> 00:09:36,880
static analysis fuzzing

233
00:09:36,880 --> 00:09:40,000
runtime app security orchestration

234
00:09:40,000 --> 00:09:42,800
threat modeling tooling there's a

235
00:09:42,800 --> 00:09:44,000
there's just

236
00:09:44,000 --> 00:09:46,839
this wonderful

237
00:09:46,839 --> 00:09:50,399
availability of both open source

238
00:09:50,399 --> 00:09:53,040
and commercial tooling to help you get

239
00:09:53,040 --> 00:09:55,519
your job done

240
00:09:55,519 --> 00:09:56,320
um

241
00:09:56,320 --> 00:09:59,200
i've seen a rise in bug bounties jobs in

242
00:09:59,200 --> 00:10:02,399
bug hunting and penetration testing

243
00:10:02,399 --> 00:10:04,720
we've seen the rise and fall of entire

244
00:10:04,720 --> 00:10:08,800
bug classes like sql injection or php

245
00:10:08,800 --> 00:10:10,800
and uh

246
00:10:10,800 --> 00:10:12,760
sql injection

247
00:10:12,760 --> 00:10:16,720
1999 or so and over the last few years

248
00:10:16,720 --> 00:10:18,160
i've seen people bringing up the

249
00:10:18,160 --> 00:10:20,800
question of does sql injection really

250
00:10:20,800 --> 00:10:23,360
happen in new code anymore is it really

251
00:10:23,360 --> 00:10:25,440
a problem and of course

252
00:10:25,440 --> 00:10:28,240
php is not a bug class it's a lovely

253
00:10:28,240 --> 00:10:30,000
programming language

254
00:10:30,000 --> 00:10:32,720
which makes it easy to write code and

255
00:10:32,720 --> 00:10:35,040
easy to write code which surprises the

256
00:10:35,040 --> 00:10:38,560
developer and delights the bug hunter

257
00:10:38,560 --> 00:10:39,600
um

258
00:10:39,600 --> 00:10:43,360
we've also seen a massive shift in

259
00:10:43,360 --> 00:10:47,040
breach reporting the idea that you can

260
00:10:47,040 --> 00:10:48,320
cover up an issue and i'm going to

261
00:10:48,320 --> 00:10:51,200
return to this later on

262
00:10:51,200 --> 00:10:53,600
um but the idea that you have to talk

263
00:10:53,600 --> 00:10:55,680
about certain classes of security

264
00:10:55,680 --> 00:10:58,560
problems i believe to be new and really

265
00:10:58,560 --> 00:11:01,839
important for our field

266
00:11:02,560 --> 00:11:04,399
i also want to mention a little bit more

267
00:11:04,399 --> 00:11:07,440
broadly development um

268
00:11:07,440 --> 00:11:12,320
i remember going to data centers and

269
00:11:12,320 --> 00:11:14,640
talking about the physical layout of

270
00:11:14,640 --> 00:11:16,959
hosts in the data center

271
00:11:16,959 --> 00:11:20,079
uh back in 1996

272
00:11:20,079 --> 00:11:21,920
and since then we've had the agile

273
00:11:21,920 --> 00:11:24,560
manifesto we've had the rise of devops

274
00:11:24,560 --> 00:11:26,640
and sre

275
00:11:26,640 --> 00:11:29,519
we've had the rise of clouds software as

276
00:11:29,519 --> 00:11:33,720
a service wasn't a thing in 1996

277
00:11:33,720 --> 00:11:38,079
virtualization wasn't a thing in 1996.

278
00:11:38,079 --> 00:11:40,959
we've had mobile platforms iphone and

279
00:11:40,959 --> 00:11:43,200
android and i'll talk about the security

280
00:11:43,200 --> 00:11:46,480
importance of those things but in 1996

281
00:11:46,480 --> 00:11:49,360
i was carrying in a pager displayed two

282
00:11:49,360 --> 00:11:52,000
whole lines of text at a time and i

283
00:11:52,000 --> 00:11:54,079
could go backwards and forwards between

284
00:11:54,079 --> 00:11:57,200
those lines it was pretty cool

285
00:11:57,200 --> 00:11:58,320
and so

286
00:11:58,320 --> 00:12:00,320
there's been there's been really

287
00:12:00,320 --> 00:12:03,200
tremendous change and it's important to

288
00:12:03,200 --> 00:12:06,399
understand that as we get

289
00:12:06,399 --> 00:12:09,120
to the present

290
00:12:09,120 --> 00:12:12,000
because there have been more really

291
00:12:12,000 --> 00:12:14,320
important changes

292
00:12:14,320 --> 00:12:16,079
so

293
00:12:16,079 --> 00:12:20,000
one change which i think is we have not

294
00:12:20,000 --> 00:12:24,160
even seen the full value of yes

295
00:12:24,160 --> 00:12:26,560
is

296
00:12:26,560 --> 00:12:29,839
security properties and features

297
00:12:29,839 --> 00:12:31,200
are moving

298
00:12:31,200 --> 00:12:34,079
through much more of the stack that we

299
00:12:34,079 --> 00:12:36,959
use to deliver software today

300
00:12:36,959 --> 00:12:39,360
it's not something that we just bolt on

301
00:12:39,360 --> 00:12:43,279
or you harden the operating system

302
00:12:43,279 --> 00:12:45,839
excuse me

303
00:12:49,360 --> 00:12:51,200
um

304
00:12:51,200 --> 00:12:53,600
we see languages that have security

305
00:12:53,600 --> 00:12:56,720
goals like rust we have frameworks react

306
00:12:56,720 --> 00:12:59,920
angular that have security properties

307
00:12:59,920 --> 00:13:03,440
we have security chips apple's t2

308
00:13:03,440 --> 00:13:06,959
windows 11 needs a tpm

309
00:13:06,959 --> 00:13:08,399
um

310
00:13:08,399 --> 00:13:10,720
i was i would see over at black hat

311
00:13:10,720 --> 00:13:14,240
right now there's a talk on the

312
00:13:14,240 --> 00:13:17,120
google security chip

313
00:13:17,120 --> 00:13:19,200
and its properties

314
00:13:19,200 --> 00:13:22,000
and we even have and i think of all the

315
00:13:22,000 --> 00:13:23,600
things this is one of the most

316
00:13:23,600 --> 00:13:27,600
surprising to me is that formal methods

317
00:13:27,600 --> 00:13:30,880
have actually been taken from academic

318
00:13:30,880 --> 00:13:32,839
use

319
00:13:32,839 --> 00:13:34,399
to

320
00:13:34,399 --> 00:13:35,920
to real

321
00:13:35,920 --> 00:13:38,720
um systems amazon has talked about their

322
00:13:38,720 --> 00:13:40,800
use of the tla plus

323
00:13:40,800 --> 00:13:43,440
temporal logic analyzer

324
00:13:43,440 --> 00:13:44,260
to

325
00:13:44,260 --> 00:13:46,000
[Music]

326
00:13:46,000 --> 00:13:47,680
prove certain properties about the

327
00:13:47,680 --> 00:13:51,040
systems they're building in the cloud

328
00:13:51,040 --> 00:13:53,920
um we have langsac langsec helps us

329
00:13:53,920 --> 00:13:55,519
frame

330
00:13:55,519 --> 00:13:58,160
the security of new languages especially

331
00:13:58,160 --> 00:14:01,040
don't but not limited to domain specific

332
00:14:01,040 --> 00:14:03,839
languages so we can think about what is

333
00:14:03,839 --> 00:14:06,000
it that we're building and what are its

334
00:14:06,000 --> 00:14:09,680
security properties in ways that i think

335
00:14:09,680 --> 00:14:11,839
are enabling

336
00:14:11,839 --> 00:14:12,800
and

337
00:14:12,800 --> 00:14:16,399
ios android these mobile first apps that

338
00:14:16,399 --> 00:14:18,079
we're creating are built with

339
00:14:18,079 --> 00:14:19,680
compartments

340
00:14:19,680 --> 00:14:22,079
that are much stronger

341
00:14:22,079 --> 00:14:24,000
much more containing

342
00:14:24,000 --> 00:14:25,760
than anything we could have thought

343
00:14:25,760 --> 00:14:28,800
about back then

344
00:14:28,959 --> 00:14:30,720
there's also been a lot of progress at

345
00:14:30,720 --> 00:14:34,000
the governmental level in 1996 we had

346
00:14:34,000 --> 00:14:37,120
the orange book or the rainbow series

347
00:14:37,120 --> 00:14:39,120
and we had crypto export restrictions

348
00:14:39,120 --> 00:14:40,800
that made it hard to incorporate

349
00:14:40,800 --> 00:14:45,079
cryptography into our products

350
00:14:45,680 --> 00:14:48,399
2021 the president of the united states

351
00:14:48,399 --> 00:14:51,279
issued a long executive order on cyber

352
00:14:51,279 --> 00:14:53,199
security

353
00:14:53,199 --> 00:14:55,680
we have ever growing breach reporting

354
00:14:55,680 --> 00:14:57,680
requirements

355
00:14:57,680 --> 00:15:00,000
we have things like the security bill of

356
00:15:00,000 --> 00:15:01,440
materials

357
00:15:01,440 --> 00:15:03,440
you must and there's some interesting

358
00:15:03,440 --> 00:15:06,000
looking s-bomb talks here at global

359
00:15:06,000 --> 00:15:07,519
appsec

360
00:15:07,519 --> 00:15:10,240
the idea that you actually have to know

361
00:15:10,240 --> 00:15:12,720
and talk about everything in your

362
00:15:12,720 --> 00:15:15,199
software is new

363
00:15:15,199 --> 00:15:16,320
and this

364
00:15:16,320 --> 00:15:18,160
presents some challenges if you're doing

365
00:15:18,160 --> 00:15:20,560
something like npm it's not that you

366
00:15:20,560 --> 00:15:23,040
can't but you actually have to

367
00:15:23,040 --> 00:15:25,279
think about bringing in new modules

368
00:15:25,279 --> 00:15:29,519
because they'll become customer visible

369
00:15:29,519 --> 00:15:31,519
the food and drug administration is

370
00:15:31,519 --> 00:15:34,160
recommending threat modeling to medical

371
00:15:34,160 --> 00:15:36,639
device manufacturers

372
00:15:36,639 --> 00:15:40,240
nist has released a set of secure has

373
00:15:40,240 --> 00:15:41,920
really secure software development

374
00:15:41,920 --> 00:15:45,279
framework they're at version 1.3 or so

375
00:15:45,279 --> 00:15:47,279
they release software verification

376
00:15:47,279 --> 00:15:50,560
guidelines as a result of the

377
00:15:50,560 --> 00:15:53,040
executive order and they put threat

378
00:15:53,040 --> 00:15:55,600
modeling front and center

379
00:15:55,600 --> 00:15:57,440
and hey

380
00:15:57,440 --> 00:15:59,279
in 2021

381
00:15:59,279 --> 00:16:03,360
insecure design has made the top 10.

382
00:16:03,360 --> 00:16:08,759
and i'm excited by that and also

383
00:16:10,079 --> 00:16:12,079
to be to be completely blunt a little

384
00:16:12,079 --> 00:16:15,519
disappointed that it's taken us so long

385
00:16:15,519 --> 00:16:17,279
but i'm only a little disappointed

386
00:16:17,279 --> 00:16:19,600
because when i think about it

387
00:16:19,600 --> 00:16:22,399
there are good reasons for that which

388
00:16:22,399 --> 00:16:23,839
are worth thinking about and

389
00:16:23,839 --> 00:16:25,680
understanding

390
00:16:25,680 --> 00:16:27,120
and so

391
00:16:27,120 --> 00:16:29,360
i think the first reason it's been hard

392
00:16:29,360 --> 00:16:32,959
to get insecure design is because

393
00:16:32,959 --> 00:16:35,120
actually fixing issues like injection

394
00:16:35,120 --> 00:16:36,639
has been hard

395
00:16:36,639 --> 00:16:39,360
so a lot of there's a lot of it

396
00:16:39,360 --> 00:16:42,480
it's visible right nobody looks at a sql

397
00:16:42,480 --> 00:16:45,440
injection issue and says oh

398
00:16:45,440 --> 00:16:48,000
that's a feature not a bug there's never

399
00:16:48,000 --> 00:16:52,000
any debate over whether or not

400
00:16:52,000 --> 00:16:54,800
a bug like sql injection or a remote

401
00:16:54,800 --> 00:16:57,920
code execution is a problem and so it's

402
00:16:57,920 --> 00:16:59,759
easier to fix and i think one of the

403
00:16:59,759 --> 00:17:01,199
challenges

404
00:17:01,199 --> 00:17:04,079
that we as a community will face over

405
00:17:04,079 --> 00:17:06,559
the next several years

406
00:17:06,559 --> 00:17:07,439
is

407
00:17:07,439 --> 00:17:09,359
design choices

408
00:17:09,359 --> 00:17:12,319
design trade-offs

409
00:17:12,319 --> 00:17:14,400
are different than many of the things

410
00:17:14,400 --> 00:17:16,000
that have been in the top ten and i'll

411
00:17:16,000 --> 00:17:19,839
talk about how that's going to play out

412
00:17:19,839 --> 00:17:21,280
how it might play out and some of the

413
00:17:21,280 --> 00:17:23,679
challenges we face

414
00:17:23,679 --> 00:17:26,079
another issue is that design is a dirty

415
00:17:26,079 --> 00:17:27,679
word

416
00:17:27,679 --> 00:17:29,360
people don't like talking about design

417
00:17:29,360 --> 00:17:30,559
they don't like talking about

418
00:17:30,559 --> 00:17:33,360
architecture oh we're agile

419
00:17:33,360 --> 00:17:36,320
we we don't do architecture anymore and

420
00:17:36,320 --> 00:17:38,000
that's a

421
00:17:38,000 --> 00:17:40,799
response to some very heavyweight and

422
00:17:40,799 --> 00:17:43,200
perhaps not particularly useful

423
00:17:43,200 --> 00:17:45,760
practices in the past but you do do

424
00:17:45,760 --> 00:17:48,080
architecture every everything has an

425
00:17:48,080 --> 00:17:50,080
architecture it's just a question of

426
00:17:50,080 --> 00:17:52,880
whether or not you understand it

427
00:17:52,880 --> 00:17:54,720
and we used to talk about threat

428
00:17:54,720 --> 00:17:56,559
modeling as think like an attacker and

429
00:17:56,559 --> 00:17:58,880
that's really hard

430
00:17:58,880 --> 00:18:01,280
so what are we doing about this

431
00:18:01,280 --> 00:18:04,799
um stride by lauren confeder and prairie

432
00:18:04,799 --> 00:18:09,679
garg is 22 this year um

433
00:18:09,679 --> 00:18:12,080
and by the way lauren has a new book

434
00:18:12,080 --> 00:18:14,400
designing secure software

435
00:18:14,400 --> 00:18:16,720
which i really like and there'll be a

436
00:18:16,720 --> 00:18:19,200
link to that in the links

437
00:18:19,200 --> 00:18:20,559
we've

438
00:18:20,559 --> 00:18:23,520
we've largely settled on the four

439
00:18:23,520 --> 00:18:25,280
question framework of what are we

440
00:18:25,280 --> 00:18:27,520
working on what can go wrong what are we

441
00:18:27,520 --> 00:18:29,200
going to do about it and did we do a

442
00:18:29,200 --> 00:18:30,880
good job

443
00:18:30,880 --> 00:18:33,760
as a way to modularize

444
00:18:33,760 --> 00:18:36,480
modularize

445
00:18:36,480 --> 00:18:38,760
threat modeling and enable

446
00:18:38,760 --> 00:18:42,000
experimentation we can swap kill chains

447
00:18:42,000 --> 00:18:44,799
for stride as ways to answer what can go

448
00:18:44,799 --> 00:18:45,840
wrong

449
00:18:45,840 --> 00:18:48,960
we can swap data flow diagrams for state

450
00:18:48,960 --> 00:18:51,039
machines as we think about what are we

451
00:18:51,039 --> 00:18:53,160
working on and so it enables

452
00:18:53,160 --> 00:18:55,679
experimentation it makes it easier to

453
00:18:55,679 --> 00:18:58,400
teach and learn throughout modeling

454
00:18:58,400 --> 00:19:00,480
we have games like elevation of

455
00:19:00,480 --> 00:19:03,919
privilege and a wasp cornucopia we have

456
00:19:03,919 --> 00:19:05,200
books

457
00:19:05,200 --> 00:19:08,080
that make threat modeling accessible we

458
00:19:08,080 --> 00:19:10,080
have a manifesto for threat modeling

459
00:19:10,080 --> 00:19:12,160
talking about patterns and anti-patterns

460
00:19:12,160 --> 00:19:14,559
and all of these things

461
00:19:14,559 --> 00:19:17,039
enable us to

462
00:19:17,039 --> 00:19:21,200
bring insecure design into the top ten

463
00:19:21,200 --> 00:19:25,360
to talk about it in our organizations in

464
00:19:25,360 --> 00:19:27,200
ways that are going to enable that

465
00:19:27,200 --> 00:19:29,679
conversation to happen

466
00:19:29,679 --> 00:19:31,760
and i think it's going to be key to the

467
00:19:31,760 --> 00:19:33,440
future

468
00:19:33,440 --> 00:19:34,480
and

469
00:19:34,480 --> 00:19:37,520
so talking about the future let me start

470
00:19:37,520 --> 00:19:40,480
out by quoting a wise person who said

471
00:19:40,480 --> 00:19:42,240
predictions are hard especially about

472
00:19:42,240 --> 00:19:45,120
the future and when i think about this

473
00:19:45,120 --> 00:19:46,320
talk

474
00:19:46,320 --> 00:19:47,840
um

475
00:19:47,840 --> 00:19:51,039
looking back 25 years and wanting to

476
00:19:51,039 --> 00:19:53,840
look forward 25 years

477
00:19:53,840 --> 00:19:56,400
thinking about all of the

478
00:19:56,400 --> 00:19:59,600
changes in development over the last 25

479
00:19:59,600 --> 00:20:02,799
years i can confidently say

480
00:20:02,799 --> 00:20:06,880
that i can't look out that far with

481
00:20:06,880 --> 00:20:09,360
any degree of reasonable confidence

482
00:20:09,360 --> 00:20:12,080
except about one thing

483
00:20:12,080 --> 00:20:14,720
and so i believe that that state and

484
00:20:14,720 --> 00:20:17,520
trends are going to continue and in 25

485
00:20:17,520 --> 00:20:19,760
years our kernels will still be written

486
00:20:19,760 --> 00:20:21,200
in c

487
00:20:21,200 --> 00:20:25,039
the reason i say that is because

488
00:20:25,039 --> 00:20:28,400
all of the kernels we use today mock

489
00:20:28,400 --> 00:20:30,480
um

490
00:20:30,480 --> 00:20:31,440
mock

491
00:20:31,440 --> 00:20:32,559
linux

492
00:20:32,559 --> 00:20:34,880
and he is a little younger

493
00:20:34,880 --> 00:20:37,120
but if we want to replace the operating

494
00:20:37,120 --> 00:20:38,880
system kernels that we'll be using in

495
00:20:38,880 --> 00:20:40,960
2046

496
00:20:40,960 --> 00:20:42,960
time is running out

497
00:20:42,960 --> 00:20:45,919
um and so i believe we'll continue to

498
00:20:45,919 --> 00:20:47,679
see kernels in c

499
00:20:47,679 --> 00:20:49,760
25 years from now

500
00:20:49,760 --> 00:20:52,000
i also believe that the trend towards

501
00:20:52,000 --> 00:20:54,559
better security properties is going to

502
00:20:54,559 --> 00:20:56,240
continue

503
00:20:56,240 --> 00:20:59,360
and that means that attacks at the seams

504
00:20:59,360 --> 00:21:00,799
are going to grow

505
00:21:00,799 --> 00:21:03,520
give you an example of this

506
00:21:03,520 --> 00:21:06,720
so there was a great bug

507
00:21:06,720 --> 00:21:09,840
in how apple managed p lists and it

508
00:21:09,840 --> 00:21:12,640
turns out they had two different parsers

509
00:21:12,640 --> 00:21:16,240
that managed um managed comment closure

510
00:21:16,240 --> 00:21:17,520
differently

511
00:21:17,520 --> 00:21:20,320
somebody discovered this and so one

512
00:21:20,320 --> 00:21:22,080
person checked the validity of the p

513
00:21:22,080 --> 00:21:24,240
list the other one executed it and they

514
00:21:24,240 --> 00:21:26,720
did different things with the comments

515
00:21:26,720 --> 00:21:28,480
oops

516
00:21:28,480 --> 00:21:31,360
that's a seam between the two things and

517
00:21:31,360 --> 00:21:35,919
those sorts of issues are going to grow

518
00:21:35,919 --> 00:21:38,240
the other thing we're going to see is

519
00:21:38,240 --> 00:21:40,880
better and better isolation and we talk

520
00:21:40,880 --> 00:21:43,280
about this in terms of

521
00:21:43,280 --> 00:21:45,520
blast radius we talk about this in terms

522
00:21:45,520 --> 00:21:48,240
of virtualization we talk about this in

523
00:21:48,240 --> 00:21:52,640
terms of more vpcs

524
00:21:52,640 --> 00:21:58,000
we're going to see that continue and so

525
00:21:58,000 --> 00:21:59,600
horizontal

526
00:21:59,600 --> 00:22:02,480
um privilege expansion is going to

527
00:22:02,480 --> 00:22:04,480
become a thing

528
00:22:04,480 --> 00:22:08,640
that goes alongside privilege escalation

529
00:22:08,640 --> 00:22:10,400
being able to get from compartment to

530
00:22:10,400 --> 00:22:12,320
compartment

531
00:22:12,320 --> 00:22:15,200
even in a lesser privileged sense

532
00:22:15,200 --> 00:22:16,880
will be important

533
00:22:16,880 --> 00:22:18,880
i believe ransomware is going to get

534
00:22:18,880 --> 00:22:20,320
really evil

535
00:22:20,320 --> 00:22:22,000
and you might think ransomware is evil

536
00:22:22,000 --> 00:22:24,640
today and it is

537
00:22:24,640 --> 00:22:26,799
um

538
00:22:26,799 --> 00:22:29,440
just a few ideas

539
00:22:29,440 --> 00:22:31,760
we'll see you again oh before i say my

540
00:22:31,760 --> 00:22:33,280
few ideas

541
00:22:33,280 --> 00:22:35,360
today's ransomware

542
00:22:35,360 --> 00:22:36,640
businesses

543
00:22:36,640 --> 00:22:38,159
and they are businesses much as we

544
00:22:38,159 --> 00:22:40,640
dislike them

545
00:22:40,640 --> 00:22:41,520
will

546
00:22:41,520 --> 00:22:43,919
go in they will dig out their victims

547
00:22:43,919 --> 00:22:46,640
insurance policy and so when you argue

548
00:22:46,640 --> 00:22:48,799
that you can't afford the ransom they'll

549
00:22:48,799 --> 00:22:50,320
pull out they'll show you your own

550
00:22:50,320 --> 00:22:53,200
insurance policy and say yes you can

551
00:22:53,200 --> 00:22:54,960
and the price will go up

552
00:22:54,960 --> 00:22:56,320
ransomware

553
00:22:56,320 --> 00:23:00,080
attackers are investing in understanding

554
00:23:00,080 --> 00:23:02,720
their victims

555
00:23:02,720 --> 00:23:05,520
those investments will continue and so

556
00:23:05,520 --> 00:23:07,200
for example

557
00:23:07,200 --> 00:23:08,799
they will change the manufacturing

558
00:23:08,799 --> 00:23:11,360
tolerances on your cnc machines they

559
00:23:11,360 --> 00:23:13,120
will change the tolerances on your

560
00:23:13,120 --> 00:23:15,679
quality assurance processes

561
00:23:15,679 --> 00:23:18,799
they will change email addresses in your

562
00:23:18,799 --> 00:23:20,799
crm database

563
00:23:20,799 --> 00:23:22,720
they will

564
00:23:22,720 --> 00:23:26,080
move data outside of your pci boundary

565
00:23:26,080 --> 00:23:29,120
so you don't pass pci anymore

566
00:23:29,120 --> 00:23:31,919
if you think about

567
00:23:31,919 --> 00:23:36,400
the ways in which they can be evil

568
00:23:36,400 --> 00:23:38,240
there's uh there's unfortunately a lot

569
00:23:38,240 --> 00:23:40,720
of room for growth and i believe we'll

570
00:23:40,720 --> 00:23:43,600
see much of that happening

571
00:23:43,600 --> 00:23:46,320
appsec is going to change

572
00:23:46,320 --> 00:23:49,840
um we'll see a change from attacks on

573
00:23:49,840 --> 00:23:50,960
systems

574
00:23:50,960 --> 00:23:52,240
to attacks

575
00:23:52,240 --> 00:23:55,120
through systems and so when i look at

576
00:23:55,120 --> 00:23:57,200
the top ten

577
00:23:57,200 --> 00:24:00,480
these are attacks on systems there are

578
00:24:00,480 --> 00:24:02,840
tax on the integrity

579
00:24:02,840 --> 00:24:06,320
confidentiality availability

580
00:24:06,320 --> 00:24:08,559
of the systems we're using

581
00:24:08,559 --> 00:24:10,640
we're going to see and we're already

582
00:24:10,640 --> 00:24:12,320
seeing

583
00:24:12,320 --> 00:24:16,559
abuse conflict harm that runs through

584
00:24:16,559 --> 00:24:19,520
these systems using the systems as

585
00:24:19,520 --> 00:24:22,880
designed and intended

586
00:24:22,880 --> 00:24:26,240
in ways that surprise their creators and

587
00:24:26,240 --> 00:24:29,120
hurt people but the system still works

588
00:24:29,120 --> 00:24:31,760
and we see this in we see companies

589
00:24:31,760 --> 00:24:33,440
responding to this

590
00:24:33,440 --> 00:24:36,080
with trust and safety style teams that

591
00:24:36,080 --> 00:24:37,120
augment

592
00:24:37,120 --> 00:24:39,120
the security work they're parallel to

593
00:24:39,120 --> 00:24:41,120
what we do in appsec

594
00:24:41,120 --> 00:24:43,039
and i think we're going to see that the

595
00:24:43,039 --> 00:24:45,360
two disciplines grow

596
00:24:45,360 --> 00:24:48,080
more together

597
00:24:48,080 --> 00:24:50,400
we'll see a shift towards demonstrating

598
00:24:50,400 --> 00:24:53,279
trustworthiness instead and less and

599
00:24:53,279 --> 00:24:55,200
less

600
00:24:55,200 --> 00:24:57,360
trying to bolt it on

601
00:24:57,360 --> 00:24:59,039
we're going to see the growth of

602
00:24:59,039 --> 00:25:01,039
artificial intelligence we're going to

603
00:25:01,039 --> 00:25:03,600
get more data driven

604
00:25:03,600 --> 00:25:06,559
lastly the frame in which we talk about

605
00:25:06,559 --> 00:25:08,880
these problems is going to matter

606
00:25:08,880 --> 00:25:10,960
increasingly

607
00:25:10,960 --> 00:25:13,039
so let me

608
00:25:13,039 --> 00:25:15,919
let me go to ai let me start with ai and

609
00:25:15,919 --> 00:25:18,000
the first thing i want to say is ai as a

610
00:25:18,000 --> 00:25:19,919
problem solver

611
00:25:19,919 --> 00:25:22,799
so in 25 years application security will

612
00:25:22,799 --> 00:25:24,400
be more mature

613
00:25:24,400 --> 00:25:26,400
we'll have a lot more tools and a lot

614
00:25:26,400 --> 00:25:29,200
more people who know how to use them

615
00:25:29,200 --> 00:25:31,279
and let me talk about ai as a problem

616
00:25:31,279 --> 00:25:33,520
solver because this slide was actually

617
00:25:33,520 --> 00:25:37,039
written for me by openai's gpt3

618
00:25:37,039 --> 00:25:39,039
um it was solving the problem that i

619
00:25:39,039 --> 00:25:42,799
needed some ai driven content

620
00:25:42,799 --> 00:25:44,720
and it started out pretty well and this

621
00:25:44,720 --> 00:25:47,360
was actually attempt number four

622
00:25:47,360 --> 00:25:49,760
um for it but

623
00:25:49,760 --> 00:25:51,919
other than the duplicated sentences this

624
00:25:51,919 --> 00:25:55,039
sounds almost like something i would say

625
00:25:55,039 --> 00:25:59,919
and so ais is really starting to do

626
00:25:59,919 --> 00:26:02,080
impressive work

627
00:26:02,080 --> 00:26:02,960
in

628
00:26:02,960 --> 00:26:05,520
very narrow ways

629
00:26:05,520 --> 00:26:07,600
and i think some of the ways

630
00:26:07,600 --> 00:26:10,720
um and this is not written by opengp by

631
00:26:10,720 --> 00:26:13,440
gpt3 by the way this is actually my text

632
00:26:13,440 --> 00:26:14,640
again

633
00:26:14,640 --> 00:26:17,039
um

634
00:26:17,360 --> 00:26:19,279
some of the ways it's going to improve

635
00:26:19,279 --> 00:26:21,600
are code review we're going to see

636
00:26:21,600 --> 00:26:24,720
smarter and smarter systems

637
00:26:24,720 --> 00:26:27,039
and we're seeing the beginning of this

638
00:26:27,039 --> 00:26:28,960
with um

639
00:26:28,960 --> 00:26:31,360
automated copying and pasting from stack

640
00:26:31,360 --> 00:26:34,719
exchange um

641
00:26:35,039 --> 00:26:37,360
where we're going to see

642
00:26:37,360 --> 00:26:40,000
that code get substantially smarter and

643
00:26:40,000 --> 00:26:42,799
be way less likely to write vulnerable

644
00:26:42,799 --> 00:26:44,080
code

645
00:26:44,080 --> 00:26:48,559
bug detection and remediation analysis

646
00:26:48,559 --> 00:26:50,240
will get better

647
00:26:50,240 --> 00:26:52,320
we'll see composition analysis those

648
00:26:52,320 --> 00:26:54,159
seems i talked about

649
00:26:54,159 --> 00:26:57,440
ai will start to think about some subset

650
00:26:57,440 --> 00:27:01,760
of the way in which those scenes happen

651
00:27:01,760 --> 00:27:04,400
but ai is also going to be a problem

652
00:27:04,400 --> 00:27:05,600
area

653
00:27:05,600 --> 00:27:08,400
we have to worry about the security of

654
00:27:08,400 --> 00:27:11,120
ai and machine learning systems uh the

655
00:27:11,120 --> 00:27:13,440
berryville institute of machine learning

656
00:27:13,440 --> 00:27:16,640
and microsoft all have

657
00:27:16,640 --> 00:27:20,480
interesting work in this area

658
00:27:20,480 --> 00:27:22,320
um

659
00:27:22,320 --> 00:27:24,240
i'll have some links for those in the

660
00:27:24,240 --> 00:27:26,320
follow-up

661
00:27:26,320 --> 00:27:28,399
but ai and machine learning problems are

662
00:27:28,399 --> 00:27:30,320
not just security there's questions of

663
00:27:30,320 --> 00:27:32,159
why did it do that

664
00:27:32,159 --> 00:27:34,240
explainability there's questions of

665
00:27:34,240 --> 00:27:36,080
transparency

666
00:27:36,080 --> 00:27:38,640
do you tell your customers that you use

667
00:27:38,640 --> 00:27:40,720
ai do you tell them where you get your

668
00:27:40,720 --> 00:27:42,720
training data does that create a

669
00:27:42,720 --> 00:27:45,279
security issue for you

670
00:27:45,279 --> 00:27:49,760
there's privacy issues with ai where

671
00:27:49,760 --> 00:27:51,840
it's hard to train a model without that

672
00:27:51,840 --> 00:27:54,320
model containing information about its

673
00:27:54,320 --> 00:27:56,159
training data set

674
00:27:56,159 --> 00:27:58,240
there's environmental costs i've read

675
00:27:58,240 --> 00:28:01,520
papers talking about the carbon

676
00:28:01,520 --> 00:28:02,880
emissions

677
00:28:02,880 --> 00:28:06,320
needed to create a new ai model

678
00:28:06,320 --> 00:28:09,200
and there are issues of bias and

679
00:28:09,200 --> 00:28:11,840
fairness which are tremendously

680
00:28:11,840 --> 00:28:14,480
important and i want to share a little

681
00:28:14,480 --> 00:28:16,559
bit about a paper

682
00:28:16,559 --> 00:28:19,760
that i read recently the impossibility

683
00:28:19,760 --> 00:28:21,520
of fairness

684
00:28:21,520 --> 00:28:24,399
and what they point out is that

685
00:28:24,399 --> 00:28:26,320
definitions of fairness spring from

686
00:28:26,320 --> 00:28:27,840
world views

687
00:28:27,840 --> 00:28:29,679
for example we have a definition which

688
00:28:29,679 --> 00:28:32,720
is individual fairness individuals

689
00:28:32,720 --> 00:28:34,320
who are similar should be treated

690
00:28:34,320 --> 00:28:36,000
similarly

691
00:28:36,000 --> 00:28:38,399
and we have a definition which is that

692
00:28:38,399 --> 00:28:41,360
demographic groups should be treated

693
00:28:41,360 --> 00:28:43,279
approximately the same across

694
00:28:43,279 --> 00:28:45,200
demographic groups

695
00:28:45,200 --> 00:28:47,039
and they demonstrate

696
00:28:47,039 --> 00:28:47,840
for

697
00:28:47,840 --> 00:28:50,240
in a mathematical way

698
00:28:50,240 --> 00:28:54,559
that you can have one or the other

699
00:28:54,559 --> 00:28:58,480
and so in a sense

700
00:28:58,480 --> 00:29:01,440
according to this work

701
00:29:01,440 --> 00:29:05,440
all ai systems contain biases

702
00:29:05,440 --> 00:29:07,520
and so it's trivial to say this ai

703
00:29:07,520 --> 00:29:12,080
system is biased it's unfair to x

704
00:29:12,080 --> 00:29:13,840
and we'll have to come to grips with

705
00:29:13,840 --> 00:29:16,720
that and we as computer scientists are

706
00:29:16,720 --> 00:29:19,120
not particularly good at that

707
00:29:19,120 --> 00:29:21,279
so we're going to need to

708
00:29:21,279 --> 00:29:23,679
develop skills at

709
00:29:23,679 --> 00:29:27,520
engaging with other disciplines engaging

710
00:29:27,520 --> 00:29:29,679
with people whose world views whose

711
00:29:29,679 --> 00:29:32,720
backgrounds are different than ours

712
00:29:32,720 --> 00:29:34,640
and

713
00:29:34,640 --> 00:29:38,000
figure out how to deal with this problem

714
00:29:38,000 --> 00:29:39,760
in

715
00:29:39,760 --> 00:29:42,799
better ways than we do today

716
00:29:42,799 --> 00:29:45,440
i also believe that ai is going to be a

717
00:29:45,440 --> 00:29:48,480
problem creator for us so there's a

718
00:29:48,480 --> 00:29:50,080
great quip

719
00:29:50,080 --> 00:29:52,159
ransomware is just a pen test whose

720
00:29:52,159 --> 00:29:54,480
terms you negotiate after the report's

721
00:29:54,480 --> 00:29:56,080
been delivered

722
00:29:56,080 --> 00:29:57,840
or it's bug bounty

723
00:29:57,840 --> 00:30:01,679
whose terms you negotiate after the

724
00:30:01,679 --> 00:30:04,159
reports delivered and so if ai is going

725
00:30:04,159 --> 00:30:07,039
to hunt bugs

726
00:30:07,520 --> 00:30:09,279
excuse me different people will have

727
00:30:09,279 --> 00:30:11,120
different bug hunting systems and some

728
00:30:11,120 --> 00:30:14,240
of them will be used um at odds with our

729
00:30:14,240 --> 00:30:16,880
hopes and intents

730
00:30:16,880 --> 00:30:19,919
darpa did their cyber crime challenge in

731
00:30:19,919 --> 00:30:22,480
2016. it's five years old

732
00:30:22,480 --> 00:30:25,520
and in that grand challenge

733
00:30:25,520 --> 00:30:28,320
they had ai systems

734
00:30:28,320 --> 00:30:30,720
automatically finding bugs automatically

735
00:30:30,720 --> 00:30:33,200
writing patches for them

736
00:30:33,200 --> 00:30:34,559
in a

737
00:30:34,559 --> 00:30:37,840
capture the flag sort of scenario

738
00:30:37,840 --> 00:30:40,399
and they were doing it with

739
00:30:40,399 --> 00:30:41,520
a different

740
00:30:41,520 --> 00:30:43,919
machine language than we tend to see in

741
00:30:43,919 --> 00:30:45,760
the real world but

742
00:30:45,760 --> 00:30:49,200
that's five-year-old technology now

743
00:30:49,200 --> 00:30:53,200
um we're also going to see ai exploiting

744
00:30:53,200 --> 00:30:55,679
human beings this is the attacks through

745
00:30:55,679 --> 00:30:57,120
the systems

746
00:30:57,120 --> 00:30:59,600
we're going to see things like deep

747
00:30:59,600 --> 00:31:02,399
fakes and voice clones and text fakes

748
00:31:02,399 --> 00:31:04,799
being used in fishing we're already

749
00:31:04,799 --> 00:31:07,039
starting to see that

750
00:31:07,039 --> 00:31:09,919
um and those are going to scale in ways

751
00:31:09,919 --> 00:31:11,200
that we are

752
00:31:11,200 --> 00:31:14,240
ill-equipped to manage

753
00:31:14,240 --> 00:31:17,519
and as examples of this include things

754
00:31:17,519 --> 00:31:20,399
like stalker wear the abuse of

755
00:31:20,399 --> 00:31:23,360
intimate imagery some of which is faked

756
00:31:23,360 --> 00:31:25,360
but has a psychological effect on the

757
00:31:25,360 --> 00:31:28,000
person whose image is faked

758
00:31:28,000 --> 00:31:30,240
um

759
00:31:30,240 --> 00:31:34,880
we see iot being abused by people by

760
00:31:34,880 --> 00:31:36,960
abusive domestic partners who are forced

761
00:31:36,960 --> 00:31:39,039
to leave but still have access to the to

762
00:31:39,039 --> 00:31:42,159
the thermostat for example

763
00:31:42,159 --> 00:31:44,880
we've got trolling and swatting and the

764
00:31:44,880 --> 00:31:47,360
internet hate canon i'll talk about

765
00:31:47,360 --> 00:31:50,080
jamal khashoggi in just a minute

766
00:31:50,080 --> 00:31:53,120
all of these are going to be

767
00:31:53,120 --> 00:31:55,919
negatively enhanced by ai

768
00:31:55,919 --> 00:31:58,640
we've got election manipulation it's

769
00:31:58,640 --> 00:31:59,600
cheap

770
00:31:59,600 --> 00:32:02,480
and ai is going to play a huge part in

771
00:32:02,480 --> 00:32:05,679
both the attacks and the defenses

772
00:32:05,679 --> 00:32:08,559
so before the saudi government murdered

773
00:32:08,559 --> 00:32:12,080
him jamal khashoggi was the victim

774
00:32:12,080 --> 00:32:15,440
of an internet harassment campaign

775
00:32:15,440 --> 00:32:17,919
that harassment campaign is going to get

776
00:32:17,919 --> 00:32:21,039
worse and the abuse the

777
00:32:21,039 --> 00:32:24,559
protective tools those safety and trust

778
00:32:24,559 --> 00:32:27,760
tools the report of problem tools

779
00:32:27,760 --> 00:32:29,840
are going to be

780
00:32:29,840 --> 00:32:32,399
driven by ai

781
00:32:32,399 --> 00:32:34,640
they're going to be attacked by false

782
00:32:34,640 --> 00:32:37,440
reports by bots and humans

783
00:32:37,440 --> 00:32:39,360
we've seen an example

784
00:32:39,360 --> 00:32:42,960
of police officers playing copyrighted

785
00:32:42,960 --> 00:32:44,000
music

786
00:32:44,000 --> 00:32:45,919
when misbehaving

787
00:32:45,919 --> 00:32:48,559
and telling the people around them that

788
00:32:48,559 --> 00:32:50,399
they were doing it so that they couldn't

789
00:32:50,399 --> 00:32:52,159
so that the people who were recording

790
00:32:52,159 --> 00:32:53,039
them

791
00:32:53,039 --> 00:32:55,919
couldn't post the video to youtube

792
00:32:55,919 --> 00:32:58,240
because youtube has automated takedown

793
00:32:58,240 --> 00:33:00,640
bots

794
00:33:01,600 --> 00:33:05,279
how do we put that in the top ten

795
00:33:05,679 --> 00:33:07,919
going back to khashoggi

796
00:33:07,919 --> 00:33:12,880
um who was the victim of this organized

797
00:33:12,880 --> 00:33:16,240
campaign that i believe was human driven

798
00:33:16,240 --> 00:33:19,279
khashoggi was a thorn in the side he was

799
00:33:19,279 --> 00:33:21,279
a reporter who upset the saudi

800
00:33:21,279 --> 00:33:22,640
government

801
00:33:22,640 --> 00:33:25,039
um enough that they

802
00:33:25,039 --> 00:33:27,360
that they murdered him

803
00:33:27,360 --> 00:33:29,678
um

804
00:33:29,760 --> 00:33:33,200
these these campaigns will scale out to

805
00:33:33,200 --> 00:33:36,480
way more people way faster

806
00:33:36,480 --> 00:33:40,399
and i don't believe we're ready for this

807
00:33:40,399 --> 00:33:42,880
and so i want to mention people like

808
00:33:42,880 --> 00:33:46,240
diana freed and karen levy julia slepska

809
00:33:46,240 --> 00:33:48,960
leonie tanzaker

810
00:33:48,960 --> 00:33:51,279
who have been doing phenomenal work on

811
00:33:51,279 --> 00:33:54,159
threat modeling around abuse they really

812
00:33:54,159 --> 00:33:56,720
have informed my thinking

813
00:33:56,720 --> 00:33:59,120
there are some papers here those links

814
00:33:59,120 --> 00:34:02,480
will be in the blog post and i've been

815
00:34:02,480 --> 00:34:05,120
doing some thinking about

816
00:34:05,120 --> 00:34:08,079
how we use the threat modeling framework

817
00:34:08,079 --> 00:34:10,320
of what are we working on what can go

818
00:34:10,320 --> 00:34:11,679
wrong what are we going to do about it

819
00:34:11,679 --> 00:34:13,839
did we do a good job

820
00:34:13,839 --> 00:34:16,000
in helping us think about conflict

821
00:34:16,000 --> 00:34:18,159
because i believe it's going to be a

822
00:34:18,159 --> 00:34:20,879
tremendously important area

823
00:34:20,879 --> 00:34:25,040
and i'm not alone in this in his uh 2017

824
00:34:25,040 --> 00:34:27,760
black hat keynote alex stamos showed

825
00:34:27,760 --> 00:34:29,440
this chart

826
00:34:29,440 --> 00:34:32,079
and he challenged the black hat audience

827
00:34:32,079 --> 00:34:34,000
and he said you know black hat is all

828
00:34:34,000 --> 00:34:36,560
about zero day you're up here at the

829
00:34:36,560 --> 00:34:38,800
very tip of the pyramid

830
00:34:38,800 --> 00:34:40,639
but the things that really hurt people

831
00:34:40,639 --> 00:34:43,280
are these password reuse attacks they're

832
00:34:43,280 --> 00:34:45,599
these abuse attacks

833
00:34:45,599 --> 00:34:47,040
and he asked what are we going to do

834
00:34:47,040 --> 00:34:48,960
about that and so i just want to echo

835
00:34:48,960 --> 00:34:50,960
his question

836
00:34:50,960 --> 00:34:54,320
and ask is a wasp here

837
00:34:54,320 --> 00:34:56,879
is this the right place for us to be for

838
00:34:56,879 --> 00:34:59,920
the next 5 10 20 years

839
00:34:59,920 --> 00:35:02,079
and if not

840
00:35:02,079 --> 00:35:05,440
how do we expand and and i'm not saying

841
00:35:05,440 --> 00:35:07,760
we're not doing this by the way i i want

842
00:35:07,760 --> 00:35:09,839
to respect the people who are thinking

843
00:35:09,839 --> 00:35:12,160
about this

844
00:35:12,160 --> 00:35:14,880
rather than trying to claim sole credit

845
00:35:14,880 --> 00:35:17,359
but i believe it's important for all of

846
00:35:17,359 --> 00:35:20,800
us to be thinking about how do we expand

847
00:35:20,800 --> 00:35:23,520
what our community cares about

848
00:35:23,520 --> 00:35:25,440
and ensure that we're

849
00:35:25,440 --> 00:35:28,480
balancing our efforts in in the most

850
00:35:28,480 --> 00:35:31,599
effective ways

851
00:35:31,599 --> 00:35:34,560
another interesting paper i read

852
00:35:34,560 --> 00:35:36,720
recently about demonstrating

853
00:35:36,720 --> 00:35:39,440
trustworthiness is informing my thinking

854
00:35:39,440 --> 00:35:41,119
as i think about

855
00:35:41,119 --> 00:35:42,960
where we're going

856
00:35:42,960 --> 00:35:45,200
and

857
00:35:45,200 --> 00:35:47,440
they put forth a taxonomy

858
00:35:47,440 --> 00:35:48,880
where

859
00:35:48,880 --> 00:35:51,920
we go from testing or monitoring to

860
00:35:51,920 --> 00:35:55,280
formal verification or synthesizing code

861
00:35:55,280 --> 00:35:57,359
from specifications

862
00:35:57,359 --> 00:35:59,200
so that we can have higher assurance

863
00:35:59,200 --> 00:36:01,200
that it's trustworthy

864
00:36:01,200 --> 00:36:03,680
and a lot of what we do

865
00:36:03,680 --> 00:36:07,119
is oriented around testing

866
00:36:07,119 --> 00:36:09,119
my friend eric douglas

867
00:36:09,119 --> 00:36:12,800
has described threat modeling as clever

868
00:36:12,800 --> 00:36:16,160
test case planning or clever test

869
00:36:16,160 --> 00:36:18,720
planning

870
00:36:18,800 --> 00:36:22,079
not sure i agree fully with him

871
00:36:22,079 --> 00:36:23,599
but

872
00:36:23,599 --> 00:36:25,680
threat modeling is often closer to

873
00:36:25,680 --> 00:36:27,760
testing and driving monitoring than it

874
00:36:27,760 --> 00:36:29,920
is to formal verification and i think

875
00:36:29,920 --> 00:36:31,680
we're going to need to develop these

876
00:36:31,680 --> 00:36:35,200
techniques over the next 25 years

877
00:36:35,200 --> 00:36:37,359
and when i think about synthesis i also

878
00:36:37,359 --> 00:36:39,440
think about composition

879
00:36:39,440 --> 00:36:41,280
and if i think about synthesis being

880
00:36:41,280 --> 00:36:43,839
from specification we also have

881
00:36:43,839 --> 00:36:46,720
composition from the components

882
00:36:46,720 --> 00:36:49,599
and as more secure components emerge

883
00:36:49,599 --> 00:36:52,000
well composition is if you will

884
00:36:52,000 --> 00:36:54,640
a shell shockingly hard problem

885
00:36:54,640 --> 00:36:57,359
and if you remember shell shock it was

886
00:36:57,359 --> 00:37:00,160
everything eventually relies on bash and

887
00:37:00,160 --> 00:37:02,800
passes its input to bash

888
00:37:02,800 --> 00:37:04,400
oops

889
00:37:04,400 --> 00:37:05,680
um

890
00:37:05,680 --> 00:37:06,640
so

891
00:37:06,640 --> 00:37:09,119
specification is a really really hard

892
00:37:09,119 --> 00:37:12,160
problem requirements are a hard problem

893
00:37:12,160 --> 00:37:15,040
and i think ai will help

894
00:37:15,040 --> 00:37:18,000
but i don't believe it will help as much

895
00:37:18,000 --> 00:37:21,119
as we may hope without better specs

896
00:37:21,119 --> 00:37:23,520
better compositional techniques

897
00:37:23,520 --> 00:37:26,079
so i think that's an area that requires

898
00:37:26,079 --> 00:37:29,280
attention from us all

899
00:37:29,440 --> 00:37:31,359
and when i think about these problems

900
00:37:31,359 --> 00:37:33,680
one of the questions that i ask myself

901
00:37:33,680 --> 00:37:36,800
is how are we measuring these how are we

902
00:37:36,800 --> 00:37:39,359
prioritizing what we work on how do we

903
00:37:39,359 --> 00:37:41,520
figure out what's going on and how do we

904
00:37:41,520 --> 00:37:43,040
assess project

905
00:37:43,040 --> 00:37:44,240
progress

906
00:37:44,240 --> 00:37:46,240
excuse me

907
00:37:46,240 --> 00:37:48,720
and there's a project whose report is

908
00:37:48,720 --> 00:37:50,560
close to dropping and i've been working

909
00:37:50,560 --> 00:37:53,200
with uh rob kanaki who's a non-resident

910
00:37:53,200 --> 00:37:55,520
fellow at the belfor center

911
00:37:55,520 --> 00:37:58,640
at harvard's kennedy school and we are

912
00:37:58,640 --> 00:38:00,720
close to finalizing the report from this

913
00:38:00,720 --> 00:38:02,839
workshop on learning from cyber

914
00:38:02,839 --> 00:38:05,680
incidents what we did was we took a set

915
00:38:05,680 --> 00:38:10,240
of models from aviation a cyber ntsb or

916
00:38:10,240 --> 00:38:12,880
a cyber near miss capability

917
00:38:12,880 --> 00:38:15,280
brought together 70 people and we've got

918
00:38:15,280 --> 00:38:16,560
a report

919
00:38:16,560 --> 00:38:19,119
that i'm really excited about because i

920
00:38:19,119 --> 00:38:20,800
believe

921
00:38:20,800 --> 00:38:23,040
that more and better learning from

922
00:38:23,040 --> 00:38:24,400
incidents

923
00:38:24,400 --> 00:38:26,960
is crucial to what we're going to do

924
00:38:26,960 --> 00:38:30,640
over the next 25 years

925
00:38:30,640 --> 00:38:32,640
and there's tension over this nobody

926
00:38:32,640 --> 00:38:36,000
likes to admit to mistakes

927
00:38:36,000 --> 00:38:37,599
um but

928
00:38:37,599 --> 00:38:41,200
we have a trend towards faster timelines

929
00:38:41,200 --> 00:38:43,359
so for example this is a news report

930
00:38:43,359 --> 00:38:45,280
from last week

931
00:38:45,280 --> 00:38:48,560
senators moved to include a 72-hour

932
00:38:48,560 --> 00:38:51,040
reporting timeline for cyber incidents

933
00:38:51,040 --> 00:38:53,520
in this must-pass bill

934
00:38:53,520 --> 00:38:55,440
and not in the headline but in the body

935
00:38:55,440 --> 00:38:56,880
of the article

936
00:38:56,880 --> 00:38:58,960
24 hours if you make a ransomware

937
00:38:58,960 --> 00:39:01,760
payment and we've we've treated this as

938
00:39:01,760 --> 00:39:05,200
a very one-dimensional problem of report

939
00:39:05,200 --> 00:39:07,280
faster and faster is coming to us from

940
00:39:07,280 --> 00:39:09,599
policymakers

941
00:39:09,599 --> 00:39:11,760
i believe

942
00:39:11,760 --> 00:39:13,119
that we have a trade-off that's

943
00:39:13,119 --> 00:39:14,960
available to us if we think about

944
00:39:14,960 --> 00:39:17,280
reporting not only in terms of timeline

945
00:39:17,280 --> 00:39:19,520
but in terms of content

946
00:39:19,520 --> 00:39:21,760
maybe we can get more by hearing about

947
00:39:21,760 --> 00:39:23,599
root causes

948
00:39:23,599 --> 00:39:25,119
and that's a less quick reporting

949
00:39:25,119 --> 00:39:27,440
timeline but we'll learn more

950
00:39:27,440 --> 00:39:29,520
and it will inform

951
00:39:29,520 --> 00:39:32,880
how we prioritize what we're doing in

952
00:39:32,880 --> 00:39:35,680
the field and so i think that this is an

953
00:39:35,680 --> 00:39:40,000
important thing that is going to move

954
00:39:40,079 --> 00:39:42,079
in ways that we're going to look back in

955
00:39:42,079 --> 00:39:44,640
10 years and 15 years even and say wow

956
00:39:44,640 --> 00:39:48,400
how did we work without that data

957
00:39:48,400 --> 00:39:50,400
so what do we do

958
00:39:50,400 --> 00:39:52,560
i think the best someone else said the

959
00:39:52,560 --> 00:39:54,640
best way to predict the future is to

960
00:39:54,640 --> 00:39:58,880
invent it and opportunities abound

961
00:39:58,880 --> 00:40:00,160
um

962
00:40:00,160 --> 00:40:02,240
we have synthesis and composition there

963
00:40:02,240 --> 00:40:05,040
are challenges in ai we have threat

964
00:40:05,040 --> 00:40:08,800
modeling and appsec for conflict

965
00:40:08,800 --> 00:40:10,800
we have and i didn't really talk about

966
00:40:10,800 --> 00:40:12,880
this but a number of folks have done

967
00:40:12,880 --> 00:40:14,480
really good work

968
00:40:14,480 --> 00:40:16,400
and pointed out that the threat modeling

969
00:40:16,400 --> 00:40:20,000
work which i do which we talk about

970
00:40:20,000 --> 00:40:22,560
tends to be focused on creators of

971
00:40:22,560 --> 00:40:25,040
technology rather than the end users of

972
00:40:25,040 --> 00:40:27,119
technology

973
00:40:27,119 --> 00:40:29,839
how should we help normal people

974
00:40:29,839 --> 00:40:32,079
whose choices are more centered around

975
00:40:32,079 --> 00:40:35,280
buying and configuring the technology

976
00:40:35,280 --> 00:40:38,880
in ways allowed by its creators

977
00:40:38,880 --> 00:40:40,880
how should we help them think about

978
00:40:40,880 --> 00:40:42,720
their security

979
00:40:42,720 --> 00:40:44,319
so i think there are plenty of

980
00:40:44,319 --> 00:40:45,920
opportunities

981
00:40:45,920 --> 00:40:47,440
and

982
00:40:47,440 --> 00:40:50,000
i want to close out by talking about the

983
00:40:50,000 --> 00:40:52,880
frame just a little bit there's a lot of

984
00:40:52,880 --> 00:40:56,720
ways in which we speak of cyber security

985
00:40:56,720 --> 00:40:58,400
today

986
00:40:58,400 --> 00:41:00,800
and i'm aware that i'm using the term

987
00:41:00,800 --> 00:41:02,720
cyber security which still causes some

988
00:41:02,720 --> 00:41:04,800
people to eye roll because they're an

989
00:41:04,800 --> 00:41:08,000
information security or something else

990
00:41:08,000 --> 00:41:09,839
but there's cyber war and cyber

991
00:41:09,839 --> 00:41:12,640
espionage these are exciting frames for

992
00:41:12,640 --> 00:41:15,040
us to think about and hear about

993
00:41:15,040 --> 00:41:17,440
there's criminals and hacktivists who

994
00:41:17,440 --> 00:41:19,839
cause a lot the criminals cause a lot of

995
00:41:19,839 --> 00:41:21,040
damage

996
00:41:21,040 --> 00:41:22,960
the hacktivists cause a lot of

997
00:41:22,960 --> 00:41:24,640
embarrassment

998
00:41:24,640 --> 00:41:27,200
there's a frame that's very popular now

999
00:41:27,200 --> 00:41:29,760
of threat hunting and bug hunting

1000
00:41:29,760 --> 00:41:32,000
there's a frame of compliance there's a

1001
00:41:32,000 --> 00:41:34,880
lot of energy being spent in compliance

1002
00:41:34,880 --> 00:41:37,520
management these days energy being put

1003
00:41:37,520 --> 00:41:39,680
into things like cmmc

1004
00:41:39,680 --> 00:41:41,200
v next

1005
00:41:41,200 --> 00:41:43,359
and then there's apsec which sometimes

1006
00:41:43,359 --> 00:41:45,200
seems like

1007
00:41:45,200 --> 00:41:46,880
the

1008
00:41:46,880 --> 00:41:48,400
the poor cousin

1009
00:41:48,400 --> 00:41:50,160
if you will

1010
00:41:50,160 --> 00:41:52,800
and you know at the beginning

1011
00:41:52,800 --> 00:41:55,040
i wish you all a happy armistice day

1012
00:41:55,040 --> 00:41:57,280
happy remembrance day a happy veterans

1013
00:41:57,280 --> 00:42:00,000
day because today is november 11th it is

1014
00:42:00,000 --> 00:42:01,520
the end

1015
00:42:01,520 --> 00:42:04,000
uh it's the date on which world war one

1016
00:42:04,000 --> 00:42:06,960
ended and world war one

1017
00:42:06,960 --> 00:42:10,880
was for most of its for most of the war

1018
00:42:10,880 --> 00:42:12,960
dominated by defense

1019
00:42:12,960 --> 00:42:15,760
the defenses were so the technological

1020
00:42:15,760 --> 00:42:18,800
defenses were so powerful

1021
00:42:18,800 --> 00:42:21,680
that attackers

1022
00:42:21,680 --> 00:42:24,560
died by the thousands trying to overcome

1023
00:42:24,560 --> 00:42:27,119
them with little success

1024
00:42:27,119 --> 00:42:28,839
and i think that that's a

1025
00:42:28,839 --> 00:42:32,160
powerful thing to think about

1026
00:42:32,160 --> 00:42:35,200
because today our world is dominated by

1027
00:42:35,200 --> 00:42:36,720
offense

1028
00:42:36,720 --> 00:42:39,520
and i look forward to a time when

1029
00:42:39,520 --> 00:42:41,680
despite the fact that this conflict is

1030
00:42:41,680 --> 00:42:43,280
real it's not going to go away people

1031
00:42:43,280 --> 00:42:46,319
are not going to become less motivated

1032
00:42:46,319 --> 00:42:49,200
to attack us

1033
00:42:49,520 --> 00:42:51,920
we can we can

1034
00:42:51,920 --> 00:42:55,359
build castles we can build defensible

1035
00:42:55,359 --> 00:42:56,640
systems

1036
00:42:56,640 --> 00:42:59,359
that will last against determined

1037
00:42:59,359 --> 00:43:01,920
attackers and right now the pendulum is

1038
00:43:01,920 --> 00:43:03,920
on the side of the attackers but that

1039
00:43:03,920 --> 00:43:06,400
doesn't mean it always will be

1040
00:43:06,400 --> 00:43:09,359
i believe that the goal of apsec should

1041
00:43:09,359 --> 00:43:10,240
be

1042
00:43:10,240 --> 00:43:13,119
to build these effective defenses

1043
00:43:13,119 --> 00:43:14,800
and

1044
00:43:14,800 --> 00:43:15,760
so

1045
00:43:15,760 --> 00:43:18,400
that is my hope that is my request to

1046
00:43:18,400 --> 00:43:21,440
you is to build these defenses

1047
00:43:21,440 --> 00:43:24,400
because going forward i want to

1048
00:43:24,400 --> 00:43:26,400
quote one last person and say we're not

1049
00:43:26,400 --> 00:43:28,640
at the end the beginning of the end

1050
00:43:28,640 --> 00:43:30,640
we're at the end of the beginning

1051
00:43:30,640 --> 00:43:32,880
this field is

1052
00:43:32,880 --> 00:43:34,960
still new

1053
00:43:34,960 --> 00:43:38,720
there's still tremendous opportunities

1054
00:43:38,720 --> 00:43:41,760
and i am looking forward to the next 25

1055
00:43:41,760 --> 00:43:43,200
years

1056
00:43:43,200 --> 00:43:44,560
so with that

1057
00:43:44,560 --> 00:43:47,119
i want to say thank you very much for

1058
00:43:47,119 --> 00:43:51,040
listening i hope you've enjoyed this

1059
00:43:51,040 --> 00:43:52,560
talk

1060
00:43:52,560 --> 00:43:56,560
i am happy to take questions the slides

1061
00:43:56,560 --> 00:43:59,680
will be at showstack.org

1062
00:43:59,680 --> 00:44:01,040
blog

1063
00:44:01,040 --> 00:44:05,040
um a few minutes after we close today

1064
00:44:05,040 --> 00:44:06,400
and

1065
00:44:06,400 --> 00:44:07,680
yeah thank you very much for your time

1066
00:44:07,680 --> 00:44:10,759
and attention

