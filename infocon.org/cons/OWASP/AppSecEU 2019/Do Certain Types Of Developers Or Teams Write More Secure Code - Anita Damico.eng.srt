1
00:00:04,220 --> 00:00:08,910
well good morning and welcome to the

2
00:00:07,049 --> 00:00:11,550
presentation do certain types of

3
00:00:08,910 --> 00:00:14,640
developers or teams write more secure

4
00:00:11,550 --> 00:00:17,429
code the subtitle of this presentation

5
00:00:14,640 --> 00:00:19,289
is human factors and application

6
00:00:17,429 --> 00:00:21,240
security and the reason for that

7
00:00:19,289 --> 00:00:25,589
subtitle will become obvious in a few

8
00:00:21,240 --> 00:00:28,320
minutes first let me introduce myself my

9
00:00:25,589 --> 00:00:31,859
name is Anita D'Amico and I am the CEO

10
00:00:28,320 --> 00:00:34,440
of code DX I'm also the director of

11
00:00:31,859 --> 00:00:37,770
secure decisions secure decisions is a

12
00:00:34,440 --> 00:00:39,930
cybersecurity research organization that

13
00:00:37,770 --> 00:00:42,090
does work primarily for the US

14
00:00:39,930 --> 00:00:44,310
government we we do cybersecurity

15
00:00:42,090 --> 00:00:46,740
research and develop new technologies

16
00:00:44,310 --> 00:00:48,780
and then those technologies and

17
00:00:46,740 --> 00:00:52,230
applications security which are the most

18
00:00:48,780 --> 00:00:53,940
promising we bring over to code DX which

19
00:00:52,230 --> 00:00:56,190
is a separate company that was spun out

20
00:00:53,940 --> 00:00:58,500
of secure decisions and we mature those

21
00:00:56,190 --> 00:01:01,470
OPSEC technologies and commercialize

22
00:00:58,500 --> 00:01:03,330
them I'm here today with Chris Horne

23
00:01:01,470 --> 00:01:05,218
from secure decisions he's a senior

24
00:01:03,330 --> 00:01:08,249
researcher there and some of you may

25
00:01:05,218 --> 00:01:11,009
have seen him present yesterday on the

26
00:01:08,249 --> 00:01:13,530
topic of doing research in benchmarking

27
00:01:11,009 --> 00:01:17,640
static code analyzers so he'll be doing

28
00:01:13,530 --> 00:01:20,189
part of this talk today so there are

29
00:01:17,640 --> 00:01:23,310
four parts to this talk part one is

30
00:01:20,189 --> 00:01:25,678
going to talk about why it is that we do

31
00:01:23,310 --> 00:01:29,280
research in human factors that affect

32
00:01:25,679 --> 00:01:32,039
code quality and security part two we'll

33
00:01:29,280 --> 00:01:34,979
discuss how we do that research part

34
00:01:32,039 --> 00:01:38,159
three is the crux of this presentation

35
00:01:34,979 --> 00:01:41,130
and it shows you some of the results of

36
00:01:38,159 --> 00:01:45,030
what we have found to date and then part

37
00:01:41,130 --> 00:01:47,639
four is where can we borrow some lessons

38
00:01:45,030 --> 00:01:50,340
learned from other non software domains

39
00:01:47,639 --> 00:01:54,990
about human factors that affect

40
00:01:50,340 --> 00:01:57,689
performance so ready to go so let's talk

41
00:01:54,990 --> 00:01:59,908
about why why should we be investigating

42
00:01:57,689 --> 00:02:01,309
human factors that affect code quality

43
00:01:59,909 --> 00:02:04,259
and code security

44
00:02:01,310 --> 00:02:08,369
well software vulnerabilities are the

45
00:02:04,259 --> 00:02:11,250
gateway to most major breaches in fact

46
00:02:08,369 --> 00:02:14,370
the Verizon data breach report showed

47
00:02:11,250 --> 00:02:16,700
that more than 90 percent

48
00:02:14,370 --> 00:02:20,010
of breaches in the information industry

49
00:02:16,700 --> 00:02:23,549
started with using web applications as

50
00:02:20,010 --> 00:02:25,440
the attack vector so we know that we

51
00:02:23,550 --> 00:02:27,840
have to find these software

52
00:02:25,440 --> 00:02:30,510
vulnerabilities yet it still takes a

53
00:02:27,840 --> 00:02:33,560
really long time despite the the state

54
00:02:30,510 --> 00:02:36,929
of the art the heartbleed vulnerability

55
00:02:33,560 --> 00:02:39,000
took about two years to discover the

56
00:02:36,930 --> 00:02:41,430
Apache struts vulnerability took about

57
00:02:39,000 --> 00:02:43,980
that was used in the Equifax breach took

58
00:02:41,430 --> 00:02:45,660
about four years to discover and akkad

59
00:02:43,980 --> 00:02:48,390
emissions have studied open source

60
00:02:45,660 --> 00:02:50,190
repositories and found that despite the

61
00:02:48,390 --> 00:02:53,670
fact that there are many eyes on the

62
00:02:50,190 --> 00:02:57,870
code most vulnerabilities on average

63
00:02:53,670 --> 00:03:00,629
take two years to to discover now

64
00:02:57,870 --> 00:03:03,569
actually it's two years to be reported

65
00:03:00,629 --> 00:03:05,849
right they very well may be discovered

66
00:03:03,569 --> 00:03:08,578
long before that but they aren't

67
00:03:05,849 --> 00:03:10,768
publicized for two years until after

68
00:03:08,579 --> 00:03:12,870
they were originally introduced so

69
00:03:10,769 --> 00:03:16,200
that's a long time for a vulnerability

70
00:03:12,870 --> 00:03:19,160
to sit there and remain unknown to most

71
00:03:16,200 --> 00:03:22,500
of the users of the open source software

72
00:03:19,160 --> 00:03:25,430
now there are ways of course of finding

73
00:03:22,500 --> 00:03:28,350
security weaknesses and vulnerabilities

74
00:03:25,430 --> 00:03:29,940
most people here are familiar with

75
00:03:28,350 --> 00:03:33,060
static application security testing

76
00:03:29,940 --> 00:03:36,560
tools sass tools that can find security

77
00:03:33,060 --> 00:03:39,750
weaknesses which may be indicative of

78
00:03:36,560 --> 00:03:42,870
vulnerabilities but there have been

79
00:03:39,750 --> 00:03:45,239
benchmarking tests of sass tools done by

80
00:03:42,870 --> 00:03:46,799
the US government done by the National

81
00:03:45,239 --> 00:03:50,549
Institute for Standards and Technology

82
00:03:46,799 --> 00:03:52,410
and NSA and they took test Suites of

83
00:03:50,549 --> 00:03:54,959
software with known vulnerabilities and

84
00:03:52,410 --> 00:03:57,090
ran commercial and open source static

85
00:03:54,959 --> 00:03:59,010
analyzers against them and found that on

86
00:03:57,090 --> 00:04:01,650
average they found 14 percent of the

87
00:03:59,010 --> 00:04:03,599
known vulnerabilities and each tool will

88
00:04:01,650 --> 00:04:05,010
found almost a unique different 14

89
00:04:03,599 --> 00:04:07,048
percent so you need to combine the

90
00:04:05,010 --> 00:04:09,000
results to get the good vulnerability

91
00:04:07,049 --> 00:04:11,010
coverage this is why a lot of people

92
00:04:09,000 --> 00:04:13,079
still rely on manual code reviews and

93
00:04:11,010 --> 00:04:14,849
the problem with manual code reviews is

94
00:04:13,079 --> 00:04:17,370
that there's a lot of software to go

95
00:04:14,849 --> 00:04:18,918
through where do you orient yourself as

96
00:04:17,370 --> 00:04:21,939
to where to look

97
00:04:18,918 --> 00:04:24,938
so that's where human factors comes in

98
00:04:21,939 --> 00:04:27,110
what if you were looking for

99
00:04:24,939 --> 00:04:30,229
vulnerabilities and code suppose you

100
00:04:27,110 --> 00:04:33,259
were hunting for them perhaps you could

101
00:04:30,229 --> 00:04:35,300
search on who the developer was or the

102
00:04:33,259 --> 00:04:36,680
developer characteristics or maybe you

103
00:04:35,300 --> 00:04:38,090
know something about the team and you

104
00:04:36,680 --> 00:04:40,430
know that there's something about the

105
00:04:38,090 --> 00:04:42,770
team characteristics that is more likely

106
00:04:40,430 --> 00:04:45,409
to introduce security weaknesses or

107
00:04:42,770 --> 00:04:48,469
maybe when when the code was written Tom

108
00:04:45,409 --> 00:04:50,748
if day even time of year or where the

109
00:04:48,469 --> 00:04:53,479
code was written if you could use that

110
00:04:50,749 --> 00:04:55,789
to hunt for vulnerabilities then he

111
00:04:53,479 --> 00:04:58,909
would have an advantage and where to

112
00:04:55,789 --> 00:05:02,150
start looking so these factors that I

113
00:04:58,909 --> 00:05:04,759
described are called human factors human

114
00:05:02,150 --> 00:05:07,580
factors are properties of people and

115
00:05:04,759 --> 00:05:09,590
their environment that affect human

116
00:05:07,580 --> 00:05:13,370
performance so there are a number of

117
00:05:09,590 --> 00:05:16,159
types there is psychological so for

118
00:05:13,370 --> 00:05:19,389
example an individual's ability to focus

119
00:05:16,159 --> 00:05:21,498
their attention is a human factor or

120
00:05:19,389 --> 00:05:23,539
their memory or the way they make

121
00:05:21,499 --> 00:05:25,310
decisions on a group level there are

122
00:05:23,539 --> 00:05:27,259
human factors such as the way people

123
00:05:25,310 --> 00:05:29,750
collaborate with each other or the way

124
00:05:27,259 --> 00:05:32,629
they communicate with each other there's

125
00:05:29,750 --> 00:05:35,529
also cultural norms that will affect the

126
00:05:32,629 --> 00:05:38,240
way people perform their job as a group

127
00:05:35,529 --> 00:05:41,389
there's also physiological factors for

128
00:05:38,240 --> 00:05:42,800
example is the individual fatigue

129
00:05:41,389 --> 00:05:46,279
this will this could affect their

130
00:05:42,800 --> 00:05:48,860
performance or circadian rhythm a little

131
00:05:46,279 --> 00:05:53,180
bit about circadian rhythm circadian

132
00:05:48,860 --> 00:05:55,099
rhythm is the changes the diurnal cycles

133
00:05:53,180 --> 00:05:56,960
that your body goes through during the

134
00:05:55,099 --> 00:05:59,449
course of a day so there are certain

135
00:05:56,960 --> 00:06:01,549
chemicals that are associated with your

136
00:05:59,449 --> 00:06:03,529
alertness and arousal level and those

137
00:06:01,550 --> 00:06:06,289
chemicals shift during the course of the

138
00:06:03,529 --> 00:06:09,889
day and it's known that circadian rhythm

139
00:06:06,289 --> 00:06:11,659
affects as things like the watch

140
00:06:09,889 --> 00:06:13,250
standing attempt the attention of watch

141
00:06:11,659 --> 00:06:18,050
standing officers on the bridge of a

142
00:06:13,250 --> 00:06:20,389
ship so maybe that's relevant to to

143
00:06:18,050 --> 00:06:23,330
software developers and then finally

144
00:06:20,389 --> 00:06:26,240
environment so if the if the environment

145
00:06:23,330 --> 00:06:28,219
is noisy if it's distracting if their

146
00:06:26,240 --> 00:06:28,670
temperature changes or lighting these

147
00:06:28,219 --> 00:06:32,390
are

148
00:06:28,670 --> 00:06:35,000
factors now these human factors are

149
00:06:32,390 --> 00:06:37,640
considered in almost all safety critical

150
00:06:35,000 --> 00:06:40,400
systems in their design and also in the

151
00:06:37,640 --> 00:06:46,010
analysis of failures so why not look at

152
00:06:40,400 --> 00:06:48,710
them in software engineering so that's

153
00:06:46,010 --> 00:06:51,110
what we're doing we're looking at human

154
00:06:48,710 --> 00:06:53,479
factors in software engineering to see

155
00:06:51,110 --> 00:06:56,780
if we can find correlations between

156
00:06:53,480 --> 00:06:59,600
certain human factors and the resulting

157
00:06:56,780 --> 00:07:01,099
quality of the code the quality and the

158
00:06:59,600 --> 00:07:03,290
security of the code that software

159
00:07:01,100 --> 00:07:04,670
developers are producing and I'll

160
00:07:03,290 --> 00:07:08,330
describe a little bit about how this

161
00:07:04,670 --> 00:07:11,210
research is done so the way most of this

162
00:07:08,330 --> 00:07:14,630
research is done to date is first of all

163
00:07:11,210 --> 00:07:16,190
it's done by mostly academia so one

164
00:07:14,630 --> 00:07:17,840
example is Rochester Institute of

165
00:07:16,190 --> 00:07:20,390
Technology that's their logo up there

166
00:07:17,840 --> 00:07:22,940
and what they typically do is they work

167
00:07:20,390 --> 00:07:25,370
with only open source projects fairly

168
00:07:22,940 --> 00:07:28,390
medium to large-sized repos like linux

169
00:07:25,370 --> 00:07:33,710
kernel or chromium apache Postgres

170
00:07:28,390 --> 00:07:37,969
tomcat and they mine those repositories

171
00:07:33,710 --> 00:07:40,099
for what they are consider indicators of

172
00:07:37,970 --> 00:07:42,890
human factors now they can't actually

173
00:07:40,100 --> 00:07:44,990
measure somebody's fatigue level but

174
00:07:42,890 --> 00:07:47,090
they might look at what the local time

175
00:07:44,990 --> 00:07:48,560
zone was that when the code was

176
00:07:47,090 --> 00:07:51,530
committed if it's 11 o'clock at night

177
00:07:48,560 --> 00:07:56,810
they might infer that the person may be

178
00:07:51,530 --> 00:08:00,080
tired similarly they can't look at the

179
00:07:56,810 --> 00:08:02,360
actual size of a team you know in terms

180
00:08:00,080 --> 00:08:05,599
of the team dynamics but they might look

181
00:08:02,360 --> 00:08:08,240
at the number of develop developers who

182
00:08:05,600 --> 00:08:10,520
contribute to a file or look at the

183
00:08:08,240 --> 00:08:12,830
comments on the commits to see how

184
00:08:10,520 --> 00:08:15,320
people are communicating with each other

185
00:08:12,830 --> 00:08:17,719
so they're looking at indirect

186
00:08:15,320 --> 00:08:20,630
indicators of human factors and then

187
00:08:17,720 --> 00:08:22,640
they look at the publicly disclosed

188
00:08:20,630 --> 00:08:25,490
vulnerabilities in the open source and

189
00:08:22,640 --> 00:08:27,860
they basically make two piles of results

190
00:08:25,490 --> 00:08:30,560
they take let's say Apache server

191
00:08:27,860 --> 00:08:32,840
they'll say here are all the files that

192
00:08:30,560 --> 00:08:34,909
have vulnerabilities in them to have at

193
00:08:32,840 --> 00:08:36,590
least one vulnerability and over here

194
00:08:34,909 --> 00:08:38,598
are all the files that have no

195
00:08:36,590 --> 00:08:40,310
vulnerabilities so they have two piles

196
00:08:38,599 --> 00:08:42,180
and then what they do is they try to

197
00:08:40,309 --> 00:08:44,699
maximally discriminate between

198
00:08:42,179 --> 00:08:46,529
- what are the unique characteristics of

199
00:08:44,700 --> 00:08:48,779
this pile that have ulnar abilities

200
00:08:46,529 --> 00:08:50,520
versus this pile over here that doesn't

201
00:08:48,779 --> 00:08:54,240
and they start making imprints it's

202
00:08:50,520 --> 00:08:56,670
based on that now the other type of

203
00:08:54,240 --> 00:08:59,010
study and they're very few of these are

204
00:08:56,670 --> 00:09:01,020
done in proprietary environments and it

205
00:08:59,010 --> 00:09:02,520
may be that the way you develop in a

206
00:09:01,020 --> 00:09:05,189
proprietary environment is different

207
00:09:02,520 --> 00:09:07,439
than contributing to open source so

208
00:09:05,190 --> 00:09:11,100
there's studies by Microsoft and ATT and

209
00:09:07,440 --> 00:09:13,050
Nortel Microsoft has a human factors

210
00:09:11,100 --> 00:09:15,750
group that studies these types of things

211
00:09:13,050 --> 00:09:17,670
and I'll be referencing one of their one

212
00:09:15,750 --> 00:09:22,260
of their present one of their published

213
00:09:17,670 --> 00:09:24,360
papers what we are doing is we are now

214
00:09:22,260 --> 00:09:27,689
under contract to the Defense Advanced

215
00:09:24,360 --> 00:09:30,720
Research Projects Agency DARPA it's a US

216
00:09:27,690 --> 00:09:32,610
government R&D organization they have a

217
00:09:30,720 --> 00:09:34,500
three billion dollar a year budget and

218
00:09:32,610 --> 00:09:37,620
they did invent the Internet

219
00:09:34,500 --> 00:09:39,630
it's called ARPANET after DARPA it was

220
00:09:37,620 --> 00:09:41,970
called opera at the time and so what

221
00:09:39,630 --> 00:09:43,589
they've asked us to do is expand on this

222
00:09:41,970 --> 00:09:46,890
body of research to start looking at

223
00:09:43,589 --> 00:09:50,730
proprietary environments and also to

224
00:09:46,890 --> 00:09:53,160
study human factors more directly so let

225
00:09:50,730 --> 00:09:54,990
me tell you a little bit about how that

226
00:09:53,160 --> 00:09:57,390
work is going to be done and is being

227
00:09:54,990 --> 00:09:59,279
done so there are three different types

228
00:09:57,390 --> 00:10:00,810
of approaches that we're taking what I'm

229
00:09:59,279 --> 00:10:02,850
going to be talking about today is

230
00:10:00,810 --> 00:10:05,430
mostly this first approach was a

231
00:10:02,850 --> 00:10:08,240
retrospective analysis that basically

232
00:10:05,430 --> 00:10:11,339
means a historical analysis of existing

233
00:10:08,240 --> 00:10:15,270
software repositories issued trackers

234
00:10:11,339 --> 00:10:17,730
basically resources and we're looking at

235
00:10:15,270 --> 00:10:21,390
both open-source as well as proprietary

236
00:10:17,730 --> 00:10:24,150
code repositories and when we do that we

237
00:10:21,390 --> 00:10:26,339
look for these human factors indicators

238
00:10:24,150 --> 00:10:29,939
in the repositories and then we

239
00:10:26,339 --> 00:10:33,450
correlate those two measures of security

240
00:10:29,940 --> 00:10:34,650
now if it's an open source repository we

241
00:10:33,450 --> 00:10:37,230
can use publicly disclosed

242
00:10:34,650 --> 00:10:41,130
vulnerabilities but for both open source

243
00:10:37,230 --> 00:10:43,500
and for proprietary code bases we're

244
00:10:41,130 --> 00:10:46,050
also using the results of static code

245
00:10:43,500 --> 00:10:48,420
analyzers so basically fast findings

246
00:10:46,050 --> 00:10:51,089
those are indicators of both code

247
00:10:48,420 --> 00:10:53,250
quality as well as code security the

248
00:10:51,089 --> 00:10:54,410
advantage of using them is that you can

249
00:10:53,250 --> 00:10:56,209
apply it though

250
00:10:54,410 --> 00:10:59,870
to open source and proprietary code

251
00:10:56,209 --> 00:11:02,508
bases even compare also since we know

252
00:10:59,870 --> 00:11:04,940
that vulnerabilities remain unreported

253
00:11:02,509 --> 00:11:08,089
in open source for updated for on

254
00:11:04,940 --> 00:11:10,100
average two years these weaknesses that

255
00:11:08,089 --> 00:11:12,319
are found in the SAS tools may be

256
00:11:10,100 --> 00:11:16,250
indicators of problems even if at

257
00:11:12,319 --> 00:11:17,990
vulnerability has not been disclosed now

258
00:11:16,250 --> 00:11:20,899
the other thing that we do with these

259
00:11:17,990 --> 00:11:22,699
proprietary code bases is that we're not

260
00:11:20,899 --> 00:11:24,980
just looking at the code repositories

261
00:11:22,699 --> 00:11:27,589
but we'll work with an organization and

262
00:11:24,980 --> 00:11:29,720
see what other kind of data they have do

263
00:11:27,589 --> 00:11:31,699
they have information about the level of

264
00:11:29,720 --> 00:11:34,279
experience of the developers or their

265
00:11:31,699 --> 00:11:36,800
education and what in one case we have

266
00:11:34,279 --> 00:11:40,490
timecard information and that tells us

267
00:11:36,800 --> 00:11:43,430
how many hours the developer worked that

268
00:11:40,490 --> 00:11:46,670
week and we can correlate excessive work

269
00:11:43,430 --> 00:11:49,250
hours to code quality or security it

270
00:11:46,670 --> 00:11:51,680
also tells us on the time cards how many

271
00:11:49,250 --> 00:11:53,870
different tasks they build so are they

272
00:11:51,680 --> 00:11:55,579
focused on one thing all day long or are

273
00:11:53,870 --> 00:11:58,790
they constantly context switching

274
00:11:55,579 --> 00:12:00,800
between different tasks now the second

275
00:11:58,790 --> 00:12:03,469
type of analysis that we're doing is

276
00:12:00,800 --> 00:12:07,008
concurrent analysis and that is where we

277
00:12:03,470 --> 00:12:08,540
study developers as they code and we

278
00:12:07,009 --> 00:12:09,949
start at this part of the research

279
00:12:08,540 --> 00:12:12,699
program already although I don't have

280
00:12:09,949 --> 00:12:15,620
results to report I hope to report it

281
00:12:12,699 --> 00:12:17,810
next year so what the concurrent

282
00:12:15,620 --> 00:12:20,899
analysis does is we instrument the

283
00:12:17,810 --> 00:12:23,359
developers environment and we measure of

284
00:12:20,899 --> 00:12:25,699
various human factors directly so they

285
00:12:23,360 --> 00:12:27,439
sign on in the morning and we say good

286
00:12:25,699 --> 00:12:29,899
morning how many hours of sleep did you

287
00:12:27,439 --> 00:12:31,519
get last night and during the course of

288
00:12:29,899 --> 00:12:34,069
the day two other times we asked them

289
00:12:31,519 --> 00:12:36,050
about their subjective fatigue level we

290
00:12:34,069 --> 00:12:38,300
also asked about interruptions what

291
00:12:36,050 --> 00:12:41,389
they're listening to on their earphones

292
00:12:38,300 --> 00:12:47,359
and how much communication they've had

293
00:12:41,389 --> 00:12:49,730
with other members of the team so you

294
00:12:47,360 --> 00:12:52,850
advance debate okay or I did okay so the

295
00:12:49,730 --> 00:12:56,300
third type of approach is vulnerability

296
00:12:52,850 --> 00:12:59,990
history analysis there this is also

297
00:12:56,300 --> 00:13:01,790
fairly new we're taking vulnerabilities

298
00:12:59,990 --> 00:13:04,639
that have been disclosed in open source

299
00:13:01,790 --> 00:13:06,529
and we know that it was discovered over

300
00:13:04,639 --> 00:13:09,139
here in time

301
00:13:06,529 --> 00:13:12,889
over here in time and we go back in time

302
00:13:09,139 --> 00:13:15,589
to see when was it originated what was

303
00:13:12,889 --> 00:13:17,509
the originating commit that caused that

304
00:13:15,589 --> 00:13:19,369
vulnerability and what we're doing is

305
00:13:17,509 --> 00:13:21,709
we're looking at what were the factors

306
00:13:19,369 --> 00:13:23,149
in play in that repository at the time

307
00:13:21,709 --> 00:13:25,939
where there a whole bunch of people

308
00:13:23,149 --> 00:13:27,739
introducing new features where there are

309
00:13:25,939 --> 00:13:29,299
a lot of people everything a lot more

310
00:13:27,739 --> 00:13:31,009
people where there's only one person in

311
00:13:29,299 --> 00:13:34,669
the repo we're trying to figure out what

312
00:13:31,009 --> 00:13:36,859
are the indicators of what might be wet

313
00:13:34,669 --> 00:13:39,949
what are indicators of a vulnerability

314
00:13:36,859 --> 00:13:41,929
being introduced we also go to the time

315
00:13:39,949 --> 00:13:44,269
of the discovery to see if we can

316
00:13:41,929 --> 00:13:47,509
determine what are the factors in play

317
00:13:44,269 --> 00:13:50,419
that help facilitate the discovery of a

318
00:13:47,509 --> 00:13:54,099
vulnerability so we'll hopefully have

319
00:13:50,419 --> 00:13:56,659
results of that next year as well so

320
00:13:54,099 --> 00:13:59,479
what we're trying to do is answer the

321
00:13:56,659 --> 00:14:01,909
question can human factors predict code

322
00:13:59,479 --> 00:14:03,079
quality and security and today we're

323
00:14:01,909 --> 00:14:05,779
going to be telling you some of the

324
00:14:03,079 --> 00:14:08,388
results of not only our research but

325
00:14:05,779 --> 00:14:11,689
other research that's been done by

326
00:14:08,389 --> 00:14:14,059
academia as well as by large companies

327
00:14:11,689 --> 00:14:16,789
so the predictors here's a list of the

328
00:14:14,059 --> 00:14:19,299
predictors these are various human

329
00:14:16,789 --> 00:14:21,739
factors that we'll talk about today and

330
00:14:19,299 --> 00:14:23,509
they are trying to we're trying to

331
00:14:21,739 --> 00:14:26,329
correlate those with outcome measures

332
00:14:23,509 --> 00:14:28,429
those outcome measures could be known

333
00:14:26,329 --> 00:14:30,769
vulnerabilities that could be security

334
00:14:28,429 --> 00:14:33,169
quality and security weaknesses in the

335
00:14:30,769 --> 00:14:34,909
code could be bug frequency failure rate

336
00:14:33,169 --> 00:14:38,839
so this is what we're trying to do

337
00:14:34,909 --> 00:14:39,439
predictors and outcomes so what did we

338
00:14:38,839 --> 00:14:50,449
find

339
00:14:39,439 --> 00:14:54,228
a dramatic pause so let's start with a

340
00:14:50,449 --> 00:14:57,049
question does is does quote this code

341
00:14:54,229 --> 00:14:58,809
quality vary with teen location in other

342
00:14:57,049 --> 00:15:02,478
words is there a difference between

343
00:14:58,809 --> 00:15:05,809
teams that are co-located and teams that

344
00:15:02,479 --> 00:15:09,649
are remotely distributed so Microsoft

345
00:15:05,809 --> 00:15:11,929
studied this specifically and they

346
00:15:09,649 --> 00:15:13,849
looked at the post release failures a

347
00:15:11,929 --> 00:15:15,230
failure rates in Windows Vista and

348
00:15:13,849 --> 00:15:18,220
office

349
00:15:15,230 --> 00:15:21,550
and what do you think do you think that

350
00:15:18,220 --> 00:15:25,010
collocation versus just distributed

351
00:15:21,550 --> 00:15:30,770
teams makes a difference or no

352
00:15:25,010 --> 00:15:34,220
difference the answer is no counter

353
00:15:30,770 --> 00:15:37,250
intuitively the answer is no they looked

354
00:15:34,220 --> 00:15:39,710
at all different types of distributed

355
00:15:37,250 --> 00:15:41,690
teams they looked at teams that were in

356
00:15:39,710 --> 00:15:44,000
the same building teams that were in

357
00:15:41,690 --> 00:15:46,940
different buildings but shared the same

358
00:15:44,000 --> 00:15:49,010
cafeteria teams in the same campus in

359
00:15:46,940 --> 00:15:51,910
the same region they looked at teams

360
00:15:49,010 --> 00:15:55,460
that were across continents there was no

361
00:15:51,910 --> 00:15:57,949
difference there was a difference though

362
00:15:55,460 --> 00:16:01,100
that explain the different failure rates

363
00:15:57,950 --> 00:16:04,610
and it wasn't location and I'll tell you

364
00:16:01,100 --> 00:16:14,290
about that in a few minutes so you can't

365
00:16:04,610 --> 00:16:16,610
leave how about time today all right

366
00:16:14,290 --> 00:16:18,140
this is something a particular interest

367
00:16:16,610 --> 00:16:20,720
to me because actually my doctoral

368
00:16:18,140 --> 00:16:24,620
dissertation was on circadian rhythm and

369
00:16:20,720 --> 00:16:27,590
time of day and sleep deprivation and so

370
00:16:24,620 --> 00:16:29,750
I was very interested in this and our

371
00:16:27,590 --> 00:16:33,020
own research results are not yet final

372
00:16:29,750 --> 00:16:34,760
but I could tell you that it does though

373
00:16:33,020 --> 00:16:37,640
there is other research that indicates

374
00:16:34,760 --> 00:16:41,960
that late-night commits have more bugs

375
00:16:37,640 --> 00:16:44,600
than morning commits now why is that

376
00:16:41,960 --> 00:16:46,910
well I have one theory and it's just a

377
00:16:44,600 --> 00:16:49,820
theory and it has to do with circadian

378
00:16:46,910 --> 00:16:52,370
rhythm take a look at that chart you may

379
00:16:49,820 --> 00:16:54,770
all relate to that there is a human

380
00:16:52,370 --> 00:16:57,050
condition circadian rhythm it's fairly

381
00:16:54,770 --> 00:16:59,300
universal that says that there are

382
00:16:57,050 --> 00:17:02,209
certain certain chemicals in your body

383
00:16:59,300 --> 00:17:04,639
that increase starting at about 7:00 in

384
00:17:02,210 --> 00:17:07,280
the morning they increase fairly

385
00:17:04,640 --> 00:17:11,060
significantly until about noon about

386
00:17:07,280 --> 00:17:13,339
2:00 p.m. they drop that is your siesta

387
00:17:11,060 --> 00:17:15,770
time right a lot of you get tired around

388
00:17:13,339 --> 00:17:18,319
2 o'clock that's why because their

389
00:17:15,770 --> 00:17:21,079
changes in your body chemistry they then

390
00:17:18,319 --> 00:17:23,540
go back up at about 3:00 and they they

391
00:17:21,079 --> 00:17:26,599
stay up and so you stay alert until

392
00:17:23,540 --> 00:17:27,589
about 9 o'clock 10 o'clock at night at

393
00:17:26,599 --> 00:17:28,760
which point they start dropping

394
00:17:27,589 --> 00:17:34,399
precipitously

395
00:17:28,760 --> 00:17:36,710
and you can go into aviation accidents

396
00:17:34,400 --> 00:17:38,390
and accidents at sea and you could you

397
00:17:36,710 --> 00:17:40,670
could look at all kinds of accidents and

398
00:17:38,390 --> 00:17:42,910
you will see far more of them at those

399
00:17:40,670 --> 00:17:47,360
times when you have a circadian trough

400
00:17:42,910 --> 00:17:49,340
and so that may explain this I'll take

401
00:17:47,360 --> 00:17:56,540
one question if yeah I don't I want to

402
00:17:49,340 --> 00:17:59,540
make sure we have enough time but if we

403
00:17:56,540 --> 00:18:04,909
do with very very similar that's very

404
00:17:59,540 --> 00:18:07,180
similar that's different that's when

405
00:18:04,910 --> 00:18:10,160
you're in a cave when you're in a cave

406
00:18:07,180 --> 00:18:12,410
when you're in a cave you have no

407
00:18:10,160 --> 00:18:14,030
sunlight and so you don't have your body

408
00:18:12,410 --> 00:18:16,640
doesn't have the feedback mechanism and

409
00:18:14,030 --> 00:18:20,240
the actual normal cycle of a human body

410
00:18:16,640 --> 00:18:22,430
is twenty five hours not twenty-four so

411
00:18:20,240 --> 00:18:23,660
if you're put into a cave and you think

412
00:18:22,430 --> 00:18:26,810
that you've counted the days by the time

413
00:18:23,660 --> 00:18:29,720
you get to the twenty-fifth day you you

414
00:18:26,810 --> 00:18:35,830
actually you have an extra day in there

415
00:18:29,720 --> 00:18:35,830
right all right do people synchronize

416
00:18:35,920 --> 00:18:42,260
yes yes they are mm-hmm by and large

417
00:18:39,830 --> 00:18:44,840
which is why it's so difficult for night

418
00:18:42,260 --> 00:18:46,760
workers to adjust there are some people

419
00:18:44,840 --> 00:18:50,230
who can actually change their circadian

420
00:18:46,760 --> 00:18:50,230
rhythms but they are in the minority

421
00:18:52,180 --> 00:18:57,830
that's that's more personality driven

422
00:18:55,300 --> 00:18:59,810
but you're still going to if you measure

423
00:18:57,830 --> 00:19:03,470
the urine catecholamines you're gonna

424
00:18:59,810 --> 00:19:06,260
see that these cycles are fairly

425
00:19:03,470 --> 00:19:07,460
universal I just want to hold those

426
00:19:06,260 --> 00:19:12,320
questions cuz I want to make sure the

427
00:19:07,460 --> 00:19:14,630
Chris it gets time so okay remember

428
00:19:12,320 --> 00:19:16,100
talked about indicators of human factors

429
00:19:14,630 --> 00:19:17,630
so when you're looking at a software

430
00:19:16,100 --> 00:19:20,570
repository you can't actually measure

431
00:19:17,630 --> 00:19:22,820
somebody's attention but what we can do

432
00:19:20,570 --> 00:19:24,530
is infer it and so there's something

433
00:19:22,820 --> 00:19:29,179
that we use in this line of research

434
00:19:24,530 --> 00:19:31,180
called unfocused contribution and it is

435
00:19:29,180 --> 00:19:33,620
an indicator of how much attention

436
00:19:31,180 --> 00:19:38,210
developers are focusing on specific

437
00:19:33,620 --> 00:19:41,239
files so unconscious contribution goes

438
00:19:38,210 --> 00:19:42,390
up when developers who are working on a

439
00:19:41,240 --> 00:19:45,390
file are all

440
00:19:42,390 --> 00:19:46,680
so busy modifying other files working

441
00:19:45,390 --> 00:19:50,700
here the work in here the work in here

442
00:19:46,680 --> 00:19:53,940
or a file has a lot of high unfocused

443
00:19:50,700 --> 00:19:57,180
contribution when many developers are

444
00:19:53,940 --> 00:19:59,610
modifying it so basically a file has

445
00:19:57,180 --> 00:20:01,860
unfocused a high unfocused contribution

446
00:19:59,610 --> 00:20:05,879
when it's not getting the direct

447
00:20:01,860 --> 00:20:09,649
attention of just a few developers so

448
00:20:05,880 --> 00:20:13,380
you think it makes a difference it does

449
00:20:09,650 --> 00:20:17,970
yep there's more the more unfocused

450
00:20:13,380 --> 00:20:21,720
contribution the more insecure the code

451
00:20:17,970 --> 00:20:24,000
so we looked at chromium and Apache web

452
00:20:21,720 --> 00:20:26,100
server files and remember those piles

453
00:20:24,000 --> 00:20:27,690
the pile with the vulnerabilities and

454
00:20:26,100 --> 00:20:29,820
the pile without the vulnerabilities

455
00:20:27,690 --> 00:20:32,390
while the pile with the vulnerabilities

456
00:20:29,820 --> 00:20:35,879
had a lot more unfocused contribution

457
00:20:32,390 --> 00:20:37,470
now we also looked at static analysis

458
00:20:35,880 --> 00:20:41,130
findings and we did this across four

459
00:20:37,470 --> 00:20:44,730
repos to open source and to proprietary

460
00:20:41,130 --> 00:20:47,540
and we found that there is a correlation

461
00:20:44,730 --> 00:20:50,730
a significant correlation such that as

462
00:20:47,540 --> 00:20:53,190
unfocused contribution goes up so to do

463
00:20:50,730 --> 00:21:00,750
the number of static analysis findings

464
00:20:53,190 --> 00:21:03,780
in both code quality and security number

465
00:21:00,750 --> 00:21:08,970
of developers a lot of people say many

466
00:21:03,780 --> 00:21:11,250
eyes make good security so we we measure

467
00:21:08,970 --> 00:21:12,810
number of developers by the number of

468
00:21:11,250 --> 00:21:15,750
developers that contributed to a file

469
00:21:12,810 --> 00:21:20,370
based on the commit data I think it

470
00:21:15,750 --> 00:21:22,140
makes a difference yep it sure does

471
00:21:20,370 --> 00:21:24,179
remember that Microsoft studies that I

472
00:21:22,140 --> 00:21:27,360
said there was one factor that was

473
00:21:24,180 --> 00:21:29,250
directly related to the failure rates it

474
00:21:27,360 --> 00:21:31,050
was number of developers it didn't

475
00:21:29,250 --> 00:21:32,580
matter whether you were in two entirely

476
00:21:31,050 --> 00:21:35,250
different contents that the team was

477
00:21:32,580 --> 00:21:37,290
smaller they had fewer failure rates if

478
00:21:35,250 --> 00:21:42,740
the team was bigger they had more

479
00:21:37,290 --> 00:21:42,740
failure rates now we're finding this

480
00:21:48,130 --> 00:21:54,410
um you know that's a very good question

481
00:21:50,840 --> 00:21:56,720
I don't know what they did in in

482
00:21:54,410 --> 00:21:58,610
Microsoft I could tell you that because

483
00:21:56,720 --> 00:22:00,920
of that question we we asked theirs

484
00:21:58,610 --> 00:22:04,250
ourselves in our own research the same

485
00:22:00,920 --> 00:22:06,440
question what we are now doing is not

486
00:22:04,250 --> 00:22:08,120
just measuring the total number of

487
00:22:06,440 --> 00:22:10,760
static analysis findings we're actually

488
00:22:08,120 --> 00:22:13,639
looking at defect density so that we are

489
00:22:10,760 --> 00:22:16,430
normalizing for both lines of code and

490
00:22:13,640 --> 00:22:17,930
churn so when we report our results next

491
00:22:16,430 --> 00:22:27,680
year you're going to see density

492
00:22:17,930 --> 00:22:30,410
measures so the age of the file I'm not

493
00:22:27,680 --> 00:22:33,380
sure what Microsoft did but we actually

494
00:22:30,410 --> 00:22:35,540
when we did our analyses last year we

495
00:22:33,380 --> 00:22:37,520
did two years worth of data we did six

496
00:22:35,540 --> 00:22:39,260
months worth of data pretty much that's

497
00:22:37,520 --> 00:22:40,760
a lot of findings hold up even when

498
00:22:39,260 --> 00:22:44,600
you're only looking at six months worth

499
00:22:40,760 --> 00:22:45,950
of data so age of a file might have a

500
00:22:44,600 --> 00:22:47,899
difference but it's probably lines of

501
00:22:45,950 --> 00:22:50,780
code and if we normalized four lines of

502
00:22:47,900 --> 00:22:53,300
code and in turn we should control four

503
00:22:50,780 --> 00:22:55,820
we should be able to capture age so

504
00:22:53,300 --> 00:22:59,090
let's take a look at what we found or

505
00:22:55,820 --> 00:23:03,139
what others found Linux remember those

506
00:22:59,090 --> 00:23:06,020
two piles those pile those those files

507
00:23:03,140 --> 00:23:09,560
that had nine or more developers on them

508
00:23:06,020 --> 00:23:15,350
were 16 times more likely to have a

509
00:23:09,560 --> 00:23:22,059
vulnerability what about chromium 9 or

510
00:23:15,350 --> 00:23:29,498
more developers 68 times web

511
00:23:22,059 --> 00:23:33,009
Apache web server 117 topics okay

512
00:23:29,499 --> 00:23:35,919
now we also looked at static analysis

513
00:23:33,009 --> 00:23:38,019
findings and we looked at the for

514
00:23:35,919 --> 00:23:39,849
repositories and we found that there is

515
00:23:38,019 --> 00:23:44,049
a significant correlation the more

516
00:23:39,849 --> 00:23:47,799
developers that are on a project the

517
00:23:44,049 --> 00:23:51,940
more static analysis findings so what

518
00:23:47,799 --> 00:23:54,339
might we what might be to play here we

519
00:23:51,940 --> 00:23:56,440
don't know but one idea is something

520
00:23:54,339 --> 00:23:59,200
called the bystander effect

521
00:23:56,440 --> 00:24:01,179
you have only three people in a

522
00:23:59,200 --> 00:24:03,639
situation if something happens you see

523
00:24:01,179 --> 00:24:06,129
something you say something right well

524
00:24:03,639 --> 00:24:07,748
you have a lot more people that's like

525
00:24:06,129 --> 00:24:10,139
everybody else thinks that somebody else

526
00:24:07,749 --> 00:24:12,580
is taking care of it right so that maybe

527
00:24:10,139 --> 00:24:14,889
it's a psychological thing that happens

528
00:24:12,580 --> 00:24:16,570
is social social psychologists study

529
00:24:14,889 --> 00:24:20,859
this and it's called the bystander

530
00:24:16,570 --> 00:24:23,849
effect so it looks pretty clear-cut but

531
00:24:20,859 --> 00:24:27,580
this has some alternative evidence

532
00:24:23,849 --> 00:24:31,479
that's right thanks Anita so not all the

533
00:24:27,580 --> 00:24:33,549
research agrees so there's other

534
00:24:31,479 --> 00:24:37,029
research that's been done that has not

535
00:24:33,549 --> 00:24:38,799
found that correlation and so this first

536
00:24:37,029 --> 00:24:40,359
one here is a study of four different

537
00:24:38,799 --> 00:24:42,849
open source projects I forgot which I

538
00:24:40,359 --> 00:24:44,978
think Postgres is in there and then

539
00:24:42,849 --> 00:24:47,139
these two proprietary studies of

540
00:24:44,979 --> 00:24:50,139
telephone software so AT&T is a big

541
00:24:47,139 --> 00:24:53,158
telephone monopoly in the States and in

542
00:24:50,139 --> 00:24:55,899
both of those cases they found that

543
00:24:53,159 --> 00:24:57,039
quality which is basically false right

544
00:24:55,899 --> 00:25:01,658
so that's a little different than

545
00:24:57,039 --> 00:25:05,259
security and in the end bugs which is

546
00:25:01,659 --> 00:25:06,849
this this middle one here did not have a

547
00:25:05,259 --> 00:25:09,190
correlation of this good number of

548
00:25:06,849 --> 00:25:10,749
developers and so one of the things that

549
00:25:09,190 --> 00:25:12,669
we think could explain this is that

550
00:25:10,749 --> 00:25:14,379
quality and security are likely

551
00:25:12,669 --> 00:25:16,629
different right and so there's actually

552
00:25:14,379 --> 00:25:20,228
a some research that's been done to look

553
00:25:16,629 --> 00:25:23,949
to see whether quality measures and and

554
00:25:20,229 --> 00:25:26,379
faults right mistakes crashes things of

555
00:25:23,950 --> 00:25:28,149
that nature are the same as security and

556
00:25:26,379 --> 00:25:32,469
the they're similar but different they

557
00:25:28,149 --> 00:25:34,629
don't always overlap another one is

558
00:25:32,470 --> 00:25:36,650
developer experience so who here thinks

559
00:25:34,629 --> 00:25:41,929
that developer

560
00:25:36,650 --> 00:25:44,440
relates to quality popular opinion yep

561
00:25:41,930 --> 00:25:47,000
so and just one of the things here so

562
00:25:44,440 --> 00:25:48,440
people weren't able to survey developers

563
00:25:47,000 --> 00:25:50,420
in this research so one of the things

564
00:25:48,440 --> 00:25:52,190
they do to measure the developer

565
00:25:50,420 --> 00:25:54,950
experiences look at how long they've

566
00:25:52,190 --> 00:25:56,870
been active in the codebase or in the

567
00:25:54,950 --> 00:25:59,990
number of commits they have made to a

568
00:25:56,870 --> 00:26:02,209
codebase right and and the research as

569
00:25:59,990 --> 00:26:05,390
the developer as developers gain

570
00:26:02,210 --> 00:26:07,460
experience they actually are looking as

571
00:26:05,390 --> 00:26:09,620
they go so it's not like you lump all of

572
00:26:07,460 --> 00:26:11,360
the developers commits over their entire

573
00:26:09,620 --> 00:26:12,739
history right so when they have six

574
00:26:11,360 --> 00:26:13,879
months of experience you're looking at

575
00:26:12,740 --> 00:26:19,070
six months and when it's a year it's

576
00:26:13,880 --> 00:26:22,550
here and in fact they did so Microsoft

577
00:26:19,070 --> 00:26:25,669
found that the components that have

578
00:26:22,550 --> 00:26:29,409
these more contributors have more minor

579
00:26:25,670 --> 00:26:31,910
contributors have more more problems and

580
00:26:29,410 --> 00:26:34,820
the minor contributors are basically

581
00:26:31,910 --> 00:26:37,220
people who are making relatively small

582
00:26:34,820 --> 00:26:39,200
amounts of commits relative to the total

583
00:26:37,220 --> 00:26:40,910
commits to a file right so if you've got

584
00:26:39,200 --> 00:26:46,580
100 developers contributing to a file

585
00:26:40,910 --> 00:26:48,560
and most of those commits are from like

586
00:26:46,580 --> 00:26:49,730
two or three three people right all

587
00:26:48,560 --> 00:26:53,690
everybody else is gonna be a minor

588
00:26:49,730 --> 00:26:57,170
contributor same thing in the study here

589
00:26:53,690 --> 00:27:03,010
of Linux and Postgres I think we've got

590
00:26:57,170 --> 00:27:03,010
one more here so what's that

591
00:27:04,030 --> 00:27:13,879
yep Oh day job yes so that's where I'm

592
00:27:12,710 --> 00:27:16,100
trying to remember the details of the

593
00:27:13,880 --> 00:27:18,740
study now they looked at the commit

594
00:27:16,100 --> 00:27:22,580
patterns I think they were using time of

595
00:27:18,740 --> 00:27:25,190
day here so you can tell the difference

596
00:27:22,580 --> 00:27:28,070
in especially the like Linux and

597
00:27:25,190 --> 00:27:29,480
Postgres you can see time and tell you

598
00:27:28,070 --> 00:27:31,370
differences in two different people's

599
00:27:29,480 --> 00:27:33,470
contributions right so some people

600
00:27:31,370 --> 00:27:35,659
contribute primarily at night and some

601
00:27:33,470 --> 00:27:37,520
people contribute during the day and so

602
00:27:35,660 --> 00:27:40,310
the people who are during the day are

603
00:27:37,520 --> 00:27:42,530
more like you know IBM errs or Google

604
00:27:40,310 --> 00:27:45,379
whose full-time job it is to contribute

605
00:27:42,530 --> 00:27:46,970
to the kernel and that's different than

606
00:27:45,380 --> 00:27:48,710
what you know people think of as the

607
00:27:46,970 --> 00:27:49,669
prototypical open source developer who's

608
00:27:48,710 --> 00:27:52,129
working on their spare

609
00:27:49,669 --> 00:27:54,139
time right and so they actually found

610
00:27:52,129 --> 00:27:56,859
that these people whose job it is

611
00:27:54,139 --> 00:27:59,899
they're actually making more mistakes

612
00:27:56,859 --> 00:28:02,269
and that's just that's interesting to us

613
00:27:59,899 --> 00:28:04,129
because that's one of the reasons we

614
00:28:02,269 --> 00:28:06,019
want to study both open source and

615
00:28:04,129 --> 00:28:08,478
proprietary software right because we

616
00:28:06,019 --> 00:28:10,639
think there might be differences in the

617
00:28:08,479 --> 00:28:12,679
sort of fault patterns and human factors

618
00:28:10,639 --> 00:28:15,439
that are at play right so people who are

619
00:28:12,679 --> 00:28:16,849
working on their own time and of their

620
00:28:15,440 --> 00:28:18,349
own volition is very different than

621
00:28:16,849 --> 00:28:20,178
somebody who's doing it for their job

622
00:28:18,349 --> 00:28:24,739
and there's different social incentive

623
00:28:20,179 --> 00:28:26,959
structures and companies as well so

624
00:28:24,739 --> 00:28:28,820
another thing here is it is the way that

625
00:28:26,959 --> 00:28:29,659
developers interact and so you know

626
00:28:28,820 --> 00:28:31,428
there are a lot of interpersonal

627
00:28:29,659 --> 00:28:33,349
interactions that are not captured by

628
00:28:31,429 --> 00:28:35,029
most development systems right so your

629
00:28:33,349 --> 00:28:36,649
version control systems not keeping

630
00:28:35,029 --> 00:28:38,509
track of if you had a meeting that day

631
00:28:36,649 --> 00:28:41,059
or who you talk to or who you're

632
00:28:38,509 --> 00:28:43,820
slacking with or anything like that but

633
00:28:41,059 --> 00:28:45,529
we can do is we can see the editing

634
00:28:43,820 --> 00:28:49,279
behavior in the files right so if we

635
00:28:45,529 --> 00:28:51,379
have the same code in the file that's

636
00:28:49,279 --> 00:28:53,149
getting modified by one person then a

637
00:28:51,379 --> 00:28:55,339
different person than a different person

638
00:28:53,149 --> 00:28:58,070
that's something that we call this

639
00:28:55,339 --> 00:29:01,759
interactive churn so churn in general is

640
00:28:58,070 --> 00:29:03,289
the idea of in a commit it's the changes

641
00:29:01,759 --> 00:29:04,969
right it's basically the change set so

642
00:29:03,289 --> 00:29:09,309
it's the lines of code that have been

643
00:29:04,969 --> 00:29:12,169
modified added remove deleted right and

644
00:29:09,309 --> 00:29:14,269
so the interactive churn is in that

645
00:29:12,169 --> 00:29:16,969
commit those lines of codes that you

646
00:29:14,269 --> 00:29:18,409
added modified or deleted that were last

647
00:29:16,969 --> 00:29:19,940
touched by somebody else so if you're

648
00:29:18,409 --> 00:29:21,619
familiar with the git blame command

649
00:29:19,940 --> 00:29:25,419
that's one of the ways you can figure

650
00:29:21,619 --> 00:29:28,249
this out and so do you think that

651
00:29:25,419 --> 00:29:29,839
basically when developers are editing

652
00:29:28,249 --> 00:29:32,079
other people's code do you think that's

653
00:29:29,839 --> 00:29:39,049
associated with more problems or not

654
00:29:32,079 --> 00:29:42,529
yeah that's right so and so what we've

655
00:29:39,049 --> 00:29:44,690
seen in we saw it in this chromium and

656
00:29:42,529 --> 00:29:46,700
chromium browser and the Apache web

657
00:29:44,690 --> 00:29:48,259
server this is the two stacks of files

658
00:29:46,700 --> 00:29:50,389
the ones with vulnerabilities in their

659
00:29:48,259 --> 00:29:52,429
history and the ones without and so we

660
00:29:50,389 --> 00:29:58,069
see that there are more in there is more

661
00:29:52,429 --> 00:30:00,999
interactive churn and files that have a

662
00:29:58,069 --> 00:30:00,999
vulnerability right

663
00:30:01,340 --> 00:30:05,709
okay and then this we just thought was

664
00:30:03,080 --> 00:30:07,879
interesting it's not I don't have any

665
00:30:05,710 --> 00:30:09,830
correlation with outcome measures here

666
00:30:07,880 --> 00:30:13,040
but one of the common interaction

667
00:30:09,830 --> 00:30:14,480
patterns so this this paper that's cited

668
00:30:13,040 --> 00:30:16,310
here and just for the reference all

669
00:30:14,480 --> 00:30:17,720
these references are in the bottom of

670
00:30:16,310 --> 00:30:19,879
our presentation so if you'd like to go

671
00:30:17,720 --> 00:30:21,290
read the original research ask us we'll

672
00:30:19,880 --> 00:30:24,470
give you a copy we've got links

673
00:30:21,290 --> 00:30:26,480
citations to all our work but this this

674
00:30:24,470 --> 00:30:31,460
researcher actually studied the patterns

675
00:30:26,480 --> 00:30:32,960
by which vulnerabilities get is it

676
00:30:31,460 --> 00:30:36,620
vulnerabilities or bugs I can't remember

677
00:30:32,960 --> 00:30:38,270
all these papers are different bugs get

678
00:30:36,620 --> 00:30:39,709
introduced and then how they get fixed

679
00:30:38,270 --> 00:30:41,810
and the most common pattern here is

680
00:30:39,710 --> 00:30:43,640
we're basically personai fixes it and

681
00:30:41,810 --> 00:30:45,560
somebody else comes or introduces a

682
00:30:43,640 --> 00:30:47,420
problem and another person comes in and

683
00:30:45,560 --> 00:30:49,460
fixes it and that's one of the most

684
00:30:47,420 --> 00:30:52,430
common patterns versus you know two

685
00:30:49,460 --> 00:30:54,140
people introducing the same thing or the

686
00:30:52,430 --> 00:30:55,670
same person fixing your own problem

687
00:30:54,140 --> 00:30:59,750
later basically takes the second set of

688
00:30:55,670 --> 00:31:02,480
eyes to fix things usually and so this

689
00:30:59,750 --> 00:31:04,100
final section of the presentation is

690
00:31:02,480 --> 00:31:06,680
where we can draw lessons from non

691
00:31:04,100 --> 00:31:08,179
software domains so that's all the

692
00:31:06,680 --> 00:31:09,470
things that neither I just covered are

693
00:31:08,180 --> 00:31:11,660
things that have been studied more in

694
00:31:09,470 --> 00:31:14,300
the context of software engineering here

695
00:31:11,660 --> 00:31:19,670
we've got some slides about human

696
00:31:14,300 --> 00:31:21,919
factors and how they have been accounted

697
00:31:19,670 --> 00:31:23,720
for in other fields right and so we're

698
00:31:21,920 --> 00:31:25,790
gonna look at mostly transportation

699
00:31:23,720 --> 00:31:28,190
medicine and occupational safe and

700
00:31:25,790 --> 00:31:31,340
health and safety so that's like on the

701
00:31:28,190 --> 00:31:34,130
workplace and things like that and the

702
00:31:31,340 --> 00:31:36,699
first one here is fatigue and so this is

703
00:31:34,130 --> 00:31:41,810
one of the most well known well studied

704
00:31:36,700 --> 00:31:43,760
causes of human error right it's just

705
00:31:41,810 --> 00:31:45,800
well known to degrade human performance

706
00:31:43,760 --> 00:31:47,379
after about 17 hours of being awake

707
00:31:45,800 --> 00:31:50,180
which is emitted Li a pretty long time

708
00:31:47,380 --> 00:31:51,860
your performance on a number of tasks

709
00:31:50,180 --> 00:31:54,320
and there's a battery of tests that

710
00:31:51,860 --> 00:31:56,479
people run but your performance drops to

711
00:31:54,320 --> 00:31:58,820
about the point where you're close to

712
00:31:56,480 --> 00:32:00,470
being the legal limit for intoxicated

713
00:31:58,820 --> 00:32:05,810
for alcohol in the United States right

714
00:32:00,470 --> 00:32:07,340
you're basically drunk and basically

715
00:32:05,810 --> 00:32:09,320
these two fields these there's a lot of

716
00:32:07,340 --> 00:32:11,600
words here but in medicine and

717
00:32:09,320 --> 00:32:13,879
transportation the take-home message

718
00:32:11,600 --> 00:32:15,350
here is that both of those fields have

719
00:32:13,880 --> 00:32:17,450
limited the amount of

720
00:32:15,350 --> 00:32:19,969
hours you can work in a day to about 11

721
00:32:17,450 --> 00:32:22,130
hours right they don't let you work more

722
00:32:19,970 --> 00:32:23,990
than that you it is against the law to

723
00:32:22,130 --> 00:32:26,600
drive a truck for more than 11 hours of

724
00:32:23,990 --> 00:32:29,000
your commercial trucker if you're a grad

725
00:32:26,600 --> 00:32:30,678
student in med school you're not allowed

726
00:32:29,000 --> 00:32:32,299
to work more than 80 hours in a week

727
00:32:30,679 --> 00:32:35,179
which works out to about 11 hours a day

728
00:32:32,299 --> 00:32:37,039
right because after that point your

729
00:32:35,179 --> 00:32:39,020
performance just plummets and it's

730
00:32:37,039 --> 00:32:40,850
correlated with really bad outcomes in

731
00:32:39,020 --> 00:32:46,400
medical contexts which looks like people

732
00:32:40,850 --> 00:32:48,260
dying also experience oh and so what I

733
00:32:46,400 --> 00:32:50,690
wanted to do was say here was that you

734
00:32:48,260 --> 00:32:53,809
know in software engineering you know we

735
00:32:50,690 --> 00:32:56,150
don't necessarily have caps on how how

736
00:32:53,809 --> 00:32:57,559
much developers can work right but maybe

737
00:32:56,150 --> 00:33:01,490
we should be thinking about that maybe

738
00:32:57,559 --> 00:33:04,399
we should not be you know hero wising be

739
00:33:01,490 --> 00:33:06,140
you know the long you know all-night

740
00:33:04,400 --> 00:33:09,130
marathons right maybe that's not such a

741
00:33:06,140 --> 00:33:11,539
good idea from a security standpoint and

742
00:33:09,130 --> 00:33:12,890
experience in qualification so maybe we

743
00:33:11,539 --> 00:33:14,090
need from a software engineering

744
00:33:12,890 --> 00:33:15,500
standpoint we need to get a lot more

745
00:33:14,090 --> 00:33:17,240
serious about looking at the

746
00:33:15,500 --> 00:33:20,510
qualifications and certifications of

747
00:33:17,240 --> 00:33:22,549
engineers right so professional

748
00:33:20,510 --> 00:33:24,799
engineers is a is a proper title in the

749
00:33:22,549 --> 00:33:26,900
states and you know in order to be

750
00:33:24,799 --> 00:33:28,668
granted that title you have to go to a

751
00:33:26,900 --> 00:33:30,559
bunch of school you have to apprentice

752
00:33:28,669 --> 00:33:32,990
under somebody who's done something you

753
00:33:30,559 --> 00:33:34,760
then have to take companies six teams

754
00:33:32,990 --> 00:33:36,409
and you have to maintain continuing

755
00:33:34,760 --> 00:33:39,408
education and it works very much the

756
00:33:36,409 --> 00:33:41,090
same in a lot of sort of regulated and

757
00:33:39,409 --> 00:33:43,039
violence right like medicines do the

758
00:33:41,090 --> 00:33:45,049
same way it could have just as well been

759
00:33:43,039 --> 00:33:47,330
like you know what it takes to become a

760
00:33:45,049 --> 00:33:49,668
doctor and even no lawyer to some degree

761
00:33:47,330 --> 00:33:51,049
and in the federal government there are

762
00:33:49,669 --> 00:33:52,730
a lot of job qualifications and

763
00:33:51,049 --> 00:33:54,530
requirements just to hold the job you

764
00:33:52,730 --> 00:33:56,120
need to have a lot of certifications and

765
00:33:54,530 --> 00:33:58,100
accreditation in order to be allowed to

766
00:33:56,120 --> 00:34:01,449
perform the job so maybe we need to be

767
00:33:58,100 --> 00:34:04,039
thinking about what is minimum education

768
00:34:01,450 --> 00:34:07,309
for software engineering and security

769
00:34:04,039 --> 00:34:08,780
and then this last one culture and so if

770
00:34:07,309 --> 00:34:10,820
you were on the last session I think she

771
00:34:08,780 --> 00:34:13,580
didn't Allison did from screen did a

772
00:34:10,820 --> 00:34:15,830
really great job talking about this but

773
00:34:13,580 --> 00:34:17,899
culture actually matters a lot and so

774
00:34:15,830 --> 00:34:21,109
creating a safety or a security culture

775
00:34:17,899 --> 00:34:22,699
is is often when you talk I talked to a

776
00:34:21,109 --> 00:34:24,739
bunch of CEOs in my line of work I've

777
00:34:22,699 --> 00:34:27,168
did a study where I talked to a large

778
00:34:24,739 --> 00:34:29,359
number of security practitioners and you

779
00:34:27,168 --> 00:34:31,969
find them basically working within their

780
00:34:29,360 --> 00:34:33,200
to create with basically our security

781
00:34:31,969 --> 00:34:35,029
cultures and they don't always talk

782
00:34:33,199 --> 00:34:36,710
about it in those ways right but raising

783
00:34:35,030 --> 00:34:38,600
awareness and creating shared values and

784
00:34:36,710 --> 00:34:43,670
having everybody on the same page is a

785
00:34:38,600 --> 00:34:45,290
culture and in medical contexts these

786
00:34:43,670 --> 00:34:47,870
types of safety cultures have been

787
00:34:45,290 --> 00:34:50,420
linked with the outcomes in the medical

788
00:34:47,870 --> 00:34:52,190
field so the first is an intensive care

789
00:34:50,420 --> 00:34:55,400
unit here and the second is at a

790
00:34:52,190 --> 00:34:56,840
hospital and ten hospitals so in the

791
00:34:55,400 --> 00:34:58,970
first one they looked across these

792
00:34:56,840 --> 00:35:01,940
intensive care units and they have this

793
00:34:58,970 --> 00:35:03,859
survey that's been you know deemed

794
00:35:01,940 --> 00:35:07,190
reliable to measure the safety culture

795
00:35:03,860 --> 00:35:08,390
of that ICU and when you look across all

796
00:35:07,190 --> 00:35:10,730
the different eyes to use you can

797
00:35:08,390 --> 00:35:13,819
correlate those safety culture scores

798
00:35:10,730 --> 00:35:18,680
with patient outcomes

799
00:35:13,820 --> 00:35:21,710
so complications and deaths and in the

800
00:35:18,680 --> 00:35:24,500
hospitals basically they did this

801
00:35:21,710 --> 00:35:26,840
intervention took two years but they

802
00:35:24,500 --> 00:35:28,640
were able to shift the culture and that

803
00:35:26,840 --> 00:35:31,730
was associated with improved outcomes

804
00:35:28,640 --> 00:35:34,040
where the culture is shifted so cultural

805
00:35:31,730 --> 00:35:35,660
change is slow right it's not something

806
00:35:34,040 --> 00:35:38,300
that happens it's changing people's

807
00:35:35,660 --> 00:35:40,670
opinions and beliefs takes basically at

808
00:35:38,300 --> 00:35:42,470
least a year right but this is something

809
00:35:40,670 --> 00:35:44,480
that we should probably be paying

810
00:35:42,470 --> 00:35:52,580
attention to so with that I'm going to

811
00:35:44,480 --> 00:35:55,160
turn it back to Anita thanks Chris so

812
00:35:52,580 --> 00:35:57,770
let's wrap up we really believe that

813
00:35:55,160 --> 00:36:00,020
there is a need for research into the

814
00:35:57,770 --> 00:36:02,650
human factors that affect code quality

815
00:36:00,020 --> 00:36:05,509
and security and we are looking for

816
00:36:02,650 --> 00:36:06,950
teams especially proprietary teams that

817
00:36:05,510 --> 00:36:10,210
would like to participate in this

818
00:36:06,950 --> 00:36:12,259
research we're looking for code bases

819
00:36:10,210 --> 00:36:13,850
proprietary code bases that we could

820
00:36:12,260 --> 00:36:16,280
study ideally if you have information

821
00:36:13,850 --> 00:36:18,560
about the developers or teams or the

822
00:36:16,280 --> 00:36:20,930
environment that would be very helpful

823
00:36:18,560 --> 00:36:23,990
or if you're interested in working with

824
00:36:20,930 --> 00:36:25,580
us we can work with you to figure out

825
00:36:23,990 --> 00:36:27,950
what are the human factors that your

826
00:36:25,580 --> 00:36:29,770
organization is interested in and then

827
00:36:27,950 --> 00:36:31,549
we could figure out a way of

828
00:36:29,770 --> 00:36:33,980
instrumenting or collecting that data

829
00:36:31,550 --> 00:36:36,800
and come up with with some actual

830
00:36:33,980 --> 00:36:38,180
empirical evidence to determine whether

831
00:36:36,800 --> 00:36:40,460
or not those human factors make a

832
00:36:38,180 --> 00:36:42,910
difference and then if we do find

833
00:36:40,460 --> 00:36:44,859
differences what do you do with it

834
00:36:42,910 --> 00:36:47,769
so what we're really trying to do is

835
00:36:44,859 --> 00:36:51,430
study things that are actionable that is

836
00:36:47,769 --> 00:36:54,098
that if if we find something like number

837
00:36:51,430 --> 00:36:56,470
of developers or number of hours worked

838
00:36:54,099 --> 00:36:58,720
that you can actually do something and

839
00:36:56,470 --> 00:37:01,480
change the work environment to

840
00:36:58,720 --> 00:37:04,689
facilitate a more secure code

841
00:37:01,480 --> 00:37:06,880
environment culture but you also can use

842
00:37:04,690 --> 00:37:09,880
this information to look for

843
00:37:06,880 --> 00:37:11,319
vulnerabilities in code so what have we

844
00:37:09,880 --> 00:37:13,359
learned today where would you start

845
00:37:11,319 --> 00:37:16,509
hunting for vulnerabilities based on

846
00:37:13,359 --> 00:37:19,150
what I present it code committed after

847
00:37:16,509 --> 00:37:22,140
midnight probably it very well may be

848
00:37:19,150 --> 00:37:26,309
buggy if not have security weaknesses

849
00:37:22,140 --> 00:37:28,808
files with unfocused contribution

850
00:37:26,309 --> 00:37:32,680
attention these are where multiple

851
00:37:28,809 --> 00:37:34,900
developers have contributed to many

852
00:37:32,680 --> 00:37:38,399
other files right that's basically what

853
00:37:34,900 --> 00:37:40,930
it is files with nine or more developers

854
00:37:38,400 --> 00:37:43,420
files where contributors had little

855
00:37:40,930 --> 00:37:49,598
experience in the codebase we sometimes

856
00:37:43,420 --> 00:37:52,180
call these drive-by committers and also

857
00:37:49,599 --> 00:37:55,690
files with high levels of interactive

858
00:37:52,180 --> 00:37:59,640
churn so that's our presentation would

859
00:37:55,690 --> 00:37:59,640
be happy to field questions

860
00:37:59,780 --> 00:38:11,780
[Applause]

861
00:38:05,720 --> 00:38:16,160
Richard I know you have a question well

862
00:38:11,780 --> 00:38:19,369
done both of you um one of the the areas

863
00:38:16,160 --> 00:38:21,440
that I believe strongly in that should

864
00:38:19,369 --> 00:38:23,990
be studied and that can make a huge

865
00:38:21,440 --> 00:38:26,900
impact or an you touched on it but the

866
00:38:23,990 --> 00:38:30,680
culture you know what about what about

867
00:38:26,900 --> 00:38:33,589
areas for example where mistakes are

868
00:38:30,680 --> 00:38:35,649
frowned upon where creativity is stifled

869
00:38:33,589 --> 00:38:37,730
what about cultures where the

870
00:38:35,650 --> 00:38:39,289
application team and the security team

871
00:38:37,730 --> 00:38:39,890
are interacting and working well

872
00:38:39,289 --> 00:38:41,839
together

873
00:38:39,890 --> 00:38:44,299
what about cultures where a company is

874
00:38:41,839 --> 00:38:46,339
pushing get it out get it out I don't

875
00:38:44,299 --> 00:38:48,619
care right these things are probably

876
00:38:46,339 --> 00:38:51,319
more impactful than any of those but

877
00:38:48,619 --> 00:38:53,630
they're harder to change because that's

878
00:38:51,319 --> 00:38:56,240
from the top down and so I'd be curious

879
00:38:53,630 --> 00:38:58,099
actually I'd love to see a study that we

880
00:38:56,240 --> 00:39:00,439
can then take to the c-suite and say we

881
00:38:58,099 --> 00:39:04,160
have a problem here but what can we do

882
00:39:00,440 --> 00:39:05,599
to improve the culture mm-hmm I just I'd

883
00:39:04,160 --> 00:39:08,270
want to get on my hobby horse so if

884
00:39:05,599 --> 00:39:10,279
anybody would like to partner with us to

885
00:39:08,270 --> 00:39:11,809
have you have us in your organization

886
00:39:10,279 --> 00:39:13,490
and work with you to measure culture so

887
00:39:11,809 --> 00:39:15,230
culture is a difficult thing to measure

888
00:39:13,490 --> 00:39:18,348
because it's really know one thing it's

889
00:39:15,230 --> 00:39:19,640
about a thousand of them but you know

890
00:39:18,349 --> 00:39:21,740
there are survey instruments they've

891
00:39:19,640 --> 00:39:23,150
been validated to measure security

892
00:39:21,740 --> 00:39:25,759
safety culture we might be able to adapt

893
00:39:23,150 --> 00:39:27,680
them for security and we're very

894
00:39:25,760 --> 00:39:29,270
interested and we have the funding right

895
00:39:27,680 --> 00:39:31,069
now to do that kind of work with

896
00:39:29,270 --> 00:39:32,990
organizations and but yeah I think it's

897
00:39:31,069 --> 00:39:36,170
got a lot of promise and it's difficult

898
00:39:32,990 --> 00:39:37,939
to measure but I think it's be very good

899
00:39:36,170 --> 00:39:40,640
to demonstrate you know scientifically

900
00:39:37,940 --> 00:39:45,910
that it's correlated or causal one of

901
00:39:40,640 --> 00:39:49,490
the things that we can do is look at

902
00:39:45,910 --> 00:39:51,710
feature density like you could almost

903
00:39:49,490 --> 00:39:54,558
see in a repository as you roll up to a

904
00:39:51,710 --> 00:39:56,359
release as are there more features is

905
00:39:54,559 --> 00:39:59,930
the rate at which features are being

906
00:39:56,359 --> 00:40:00,589
added does that affect the quality and

907
00:39:59,930 --> 00:40:03,589
post-security

908
00:40:00,589 --> 00:40:10,970
so that that would be something that we

909
00:40:03,589 --> 00:40:14,480
could look at in a repository but I'm

910
00:40:10,970 --> 00:40:16,669
gonna live in myself to to to what

911
00:40:14,480 --> 00:40:19,040
extent do you make this the distinction

912
00:40:16,670 --> 00:40:26,930
between you know security bugs or

913
00:40:19,040 --> 00:40:29,150
these versus real exploitable bugs yeah

914
00:40:26,930 --> 00:40:30,759
so the everybody had heard the question

915
00:40:29,150 --> 00:40:33,860
can you Mike

916
00:40:30,760 --> 00:40:35,090
so I believe I mean the best of my

917
00:40:33,860 --> 00:40:38,450
knowledge of vulnerability is

918
00:40:35,090 --> 00:40:40,400
exploitable so CVE has been demonstrated

919
00:40:38,450 --> 00:40:41,930
as an exploitable problem and that's how

920
00:40:40,400 --> 00:40:47,990
that's part of the process of becoming

921
00:40:41,930 --> 00:40:50,089
labeled as a CD mmm I would say that not

922
00:40:47,990 --> 00:40:53,450
necessarily the case I mean you might

923
00:40:50,090 --> 00:40:55,970
have a dependency for example that has a

924
00:40:53,450 --> 00:40:58,460
CV attached to it but oh you're talking

925
00:40:55,970 --> 00:41:00,200
about in your organization so if you're

926
00:40:58,460 --> 00:41:03,320
using a library let's say that has a

927
00:41:00,200 --> 00:41:06,620
published phoner ability or a security

928
00:41:03,320 --> 00:41:08,390
bug that's not exploitable by saves so

929
00:41:06,620 --> 00:41:11,029
for example if you have a security bug

930
00:41:08,390 --> 00:41:13,370
in your website but that functionality

931
00:41:11,030 --> 00:41:19,250
is not necessarily you know exploding I

932
00:41:13,370 --> 00:41:22,040
know yeah so that that's a note that

933
00:41:19,250 --> 00:41:25,100
that's true and I would say from a

934
00:41:22,040 --> 00:41:27,560
research standpoint there's not the

935
00:41:25,100 --> 00:41:29,799
manpower and time to go through and

936
00:41:27,560 --> 00:41:31,850
manually verify every single

937
00:41:29,800 --> 00:41:34,750
vulnerability and so what we're using

938
00:41:31,850 --> 00:41:37,190
are some degree proxy measures right so

939
00:41:34,750 --> 00:41:39,140
the number of static analysis findings

940
00:41:37,190 --> 00:41:41,510
is not a perfect measure of security of

941
00:41:39,140 --> 00:41:42,830
code right but it is a measure and it's

942
00:41:41,510 --> 00:41:44,120
a repeatable measure and so it's

943
00:41:42,830 --> 00:41:45,440
probably it's better than nothing is

944
00:41:44,120 --> 00:41:47,930
what argument I understand the

945
00:41:45,440 --> 00:41:52,730
challenges but yeah so and the second

946
00:41:47,930 --> 00:41:56,149
question is so most of the samples like

947
00:41:52,730 --> 00:42:01,940
code samples you use that is Postgres

948
00:41:56,150 --> 00:42:05,060
chromium windows they are developed in

949
00:42:01,940 --> 00:42:06,470
low-level memory unsafe languages I was

950
00:42:05,060 --> 00:42:09,170
curious to what extent to take into

951
00:42:06,470 --> 00:42:10,790
account also like kind of programming

952
00:42:09,170 --> 00:42:12,320
language types of programming languages

953
00:42:10,790 --> 00:42:14,779
we yeah there there has been research

954
00:42:12,320 --> 00:42:16,550
done in to look at the effective

955
00:42:14,780 --> 00:42:19,880
programming language on the security of

956
00:42:16,550 --> 00:42:21,200
the code and they found some

957
00:42:19,880 --> 00:42:23,330
correlations I would say they're not

958
00:42:21,200 --> 00:42:26,000
super strong so they found generally

959
00:42:23,330 --> 00:42:28,610
that the conclusion the paper reached

960
00:42:26,000 --> 00:42:30,920
was that typed languages were stronger

961
00:42:28,610 --> 00:42:34,100
but it wasn't always true fandom if I

962
00:42:30,920 --> 00:42:36,080
went on my reading of the data so it's

963
00:42:34,100 --> 00:42:38,240
it's a it's a bit of a mixed bag I don't

964
00:42:36,080 --> 00:42:41,680
think it's a strong predictor thank you

965
00:42:38,240 --> 00:42:50,569
very much very useful and great here

966
00:42:41,680 --> 00:42:52,730
last question so I wanted to point out

967
00:42:50,570 --> 00:42:56,960
that we have references if you wanted to

968
00:42:52,730 --> 00:42:58,640
you want a copy of the presentation you

969
00:42:56,960 --> 00:42:59,420
could do that and this is our contact

970
00:42:58,640 --> 00:43:01,850
information

971
00:42:59,420 --> 00:43:04,010
so if you want to copy the presentation

972
00:43:01,850 --> 00:43:07,250
with the references or you want to

973
00:43:04,010 --> 00:43:09,770
discuss possibly participating either by

974
00:43:07,250 --> 00:43:12,680
offering a proprietary code repository

975
00:43:09,770 --> 00:43:17,030
or by offering a development team please

976
00:43:12,680 --> 00:43:19,009
contact either Kris horn or or me and we

977
00:43:17,030 --> 00:43:21,960
would be happy to continue the

978
00:43:19,010 --> 00:43:27,050
conversation I hope you found it useful

979
00:43:21,960 --> 00:43:27,050
[Applause]

