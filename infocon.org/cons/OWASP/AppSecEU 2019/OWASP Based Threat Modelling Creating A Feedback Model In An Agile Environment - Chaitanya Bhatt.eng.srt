1
00:00:00,530 --> 00:00:06,150
you

2
00:00:02,460 --> 00:00:09,570
in a sentence right so as I introduce

3
00:00:06,150 --> 00:00:11,789
myself I'm Chaitanya I've been doing

4
00:00:09,570 --> 00:00:15,389
threat modeling for a while

5
00:00:11,789 --> 00:00:20,460
coffee enthusiast so you all know I can

6
00:00:15,389 --> 00:00:24,539
easily be bribe for a good coffee we

7
00:00:20,460 --> 00:00:26,160
have lot of things to cover so the

8
00:00:24,539 --> 00:00:28,410
agenda is straightforward we will talk

9
00:00:26,160 --> 00:00:30,720
about what is threat modeling some

10
00:00:28,410 --> 00:00:34,260
frameworks available in the industry

11
00:00:30,720 --> 00:00:36,390
widely used frameworks and how are they

12
00:00:34,260 --> 00:00:38,610
relevant and then we'll slowly move on

13
00:00:36,390 --> 00:00:43,140
to introducing a new way of doing a

14
00:00:38,610 --> 00:00:45,269
threat modeling so what is threat

15
00:00:43,140 --> 00:00:47,100
modeling why do we need threat modeling

16
00:00:45,270 --> 00:00:49,970
now we have a lot of experts in the room

17
00:00:47,100 --> 00:00:53,370
so I won't spend much time with this one

18
00:00:49,970 --> 00:00:56,640
so threat modeling is an art there's an

19
00:00:53,370 --> 00:00:59,459
art of foreseeing threats in a lot early

20
00:00:56,640 --> 00:01:01,170
stages of course conditions apply you

21
00:00:59,460 --> 00:01:04,110
need to have the right security mindset

22
00:01:01,170 --> 00:01:07,520
to foresee those threats but if you are

23
00:01:04,110 --> 00:01:11,280
able to do that you save a lot of money

24
00:01:07,520 --> 00:01:14,039
resources for your organization so why

25
00:01:11,280 --> 00:01:18,150
do we need it for this we have to go

26
00:01:14,040 --> 00:01:21,140
back in time and discuss with you when

27
00:01:18,150 --> 00:01:23,640
the sdlc came into picture we all knew

28
00:01:21,140 --> 00:01:25,940
software development lifecycle some what

29
00:01:23,640 --> 00:01:28,500
looked like this at a very high level

30
00:01:25,940 --> 00:01:30,539
was divided into five different stages

31
00:01:28,500 --> 00:01:33,030
security used to come in the end and

32
00:01:30,540 --> 00:01:35,220
then we thought why don't we embed into

33
00:01:33,030 --> 00:01:39,000
the software development lifecycle in an

34
00:01:35,220 --> 00:01:42,270
early stage and there came the secure

35
00:01:39,000 --> 00:01:44,490
STL C we decided to sit with the

36
00:01:42,270 --> 00:01:47,850
developers and the architectures right

37
00:01:44,490 --> 00:01:50,039
in the early stage we used to provide

38
00:01:47,850 --> 00:01:52,408
security guidelines and requirements in

39
00:01:50,040 --> 00:01:53,940
the requirement phase when designing we

40
00:01:52,409 --> 00:01:56,430
started doing threat modeling with them

41
00:01:53,940 --> 00:01:58,710
in coding phase we started doing static

42
00:01:56,430 --> 00:02:01,500
code analysis and open source analysis

43
00:01:58,710 --> 00:02:04,259
with them in testing we started doing

44
00:02:01,500 --> 00:02:06,720
dynamic code analysis and pin testing

45
00:02:04,260 --> 00:02:09,330
and finally once the code is deployed a

46
00:02:06,720 --> 00:02:12,090
job is not done there we still do what a

47
00:02:09,330 --> 00:02:15,069
vulnerability scanning and pen testing

48
00:02:12,090 --> 00:02:19,269
program onto our applications

49
00:02:15,069 --> 00:02:22,750
then came the new era of agile what is

50
00:02:19,269 --> 00:02:25,209
agile and iterative circular approach

51
00:02:22,750 --> 00:02:28,000
that the software development team

52
00:02:25,209 --> 00:02:31,629
started applying security said we want

53
00:02:28,000 --> 00:02:34,319
to embed into that so what we did we

54
00:02:31,629 --> 00:02:37,358
took the first in last chance of RSS DLC

55
00:02:34,319 --> 00:02:40,230
merge them together and we created

56
00:02:37,359 --> 00:02:44,319
something like this and we call it agile

57
00:02:40,230 --> 00:02:45,819
technically it's not a giant right there

58
00:02:44,319 --> 00:02:47,470
are a lot of problems with this approach

59
00:02:45,819 --> 00:02:52,629
and we'll talk about it in our

60
00:02:47,470 --> 00:02:54,519
subsequent slides but coming back to our

61
00:02:52,629 --> 00:02:56,888
presentation which is about threat

62
00:02:54,519 --> 00:03:02,379
modeling so I'll come back to threat

63
00:02:56,889 --> 00:03:07,180
modeling there are lot of industry-wide

64
00:03:02,379 --> 00:03:08,709
used frameworks if I'm not wrong my my

65
00:03:07,180 --> 00:03:11,799
knowledge says there are around 11

66
00:03:08,709 --> 00:03:13,389
frameworks in the industry each and

67
00:03:11,799 --> 00:03:15,669
every organization uses different

68
00:03:13,389 --> 00:03:17,980
frameworks we'll talk about some of the

69
00:03:15,669 --> 00:03:20,109
very commonly used frameworks and to

70
00:03:17,980 --> 00:03:21,369
start with our own very favorite one of

71
00:03:20,109 --> 00:03:25,419
the oldest threat modeling framework

72
00:03:21,370 --> 00:03:28,239
stripe the name came as an acronym for

73
00:03:25,419 --> 00:03:30,579
the six threat categories that were

74
00:03:28,239 --> 00:03:32,440
created right as the name suggests as

75
00:03:30,579 --> 00:03:34,769
you can see it spoofing tampering

76
00:03:32,440 --> 00:03:37,030
repudiation information disclosure

77
00:03:34,769 --> 00:03:39,340
denial of service and elevation of

78
00:03:37,030 --> 00:03:41,889
privileges combined together becomes try

79
00:03:39,340 --> 00:03:44,709
a lot of teams a lot of organizations

80
00:03:41,889 --> 00:03:49,299
have been using them then came the era

81
00:03:44,709 --> 00:03:52,479
of dread again a cool acronym based out

82
00:03:49,299 --> 00:03:54,729
of the five the the five categories of

83
00:03:52,479 --> 00:03:58,090
risk but again the dread was more

84
00:03:54,729 --> 00:04:01,329
focused on the risk analysis and less on

85
00:03:58,090 --> 00:04:03,370
the threat actors a lot of organizations

86
00:04:01,329 --> 00:04:05,680
still today use a combination of stride

87
00:04:03,370 --> 00:04:08,319
and trick where stride is used to

88
00:04:05,680 --> 00:04:10,989
identify the threats and dread is used

89
00:04:08,319 --> 00:04:13,659
to evaluate the risk associated with

90
00:04:10,989 --> 00:04:17,440
those threats so the combination goes

91
00:04:13,659 --> 00:04:19,839
well and then came pasta really cool

92
00:04:17,440 --> 00:04:22,659
acronym stands for process for attack

93
00:04:19,839 --> 00:04:24,669
simulation and threat analysis pasta is

94
00:04:22,659 --> 00:04:27,940
a seven step approach for risk

95
00:04:24,669 --> 00:04:30,400
evaluation and tech modeling for this

96
00:04:27,940 --> 00:04:32,590
some people say it is attack attacker

97
00:04:30,400 --> 00:04:35,679
centric some people believe it's risk

98
00:04:32,590 --> 00:04:38,080
centric there is a debate which will

99
00:04:35,680 --> 00:04:38,830
keep on going but we are not here for

100
00:04:38,080 --> 00:04:41,800
that

101
00:04:38,830 --> 00:04:44,859
so these frameworks which are always

102
00:04:41,800 --> 00:04:47,350
available in the market you guys must be

103
00:04:44,860 --> 00:04:51,070
wondering what is good for me what

104
00:04:47,350 --> 00:04:54,610
should I use here comes a million dollar

105
00:04:51,070 --> 00:04:57,670
question how relevant are they are they

106
00:04:54,610 --> 00:04:59,230
relevant in today's world we have threat

107
00:04:57,670 --> 00:05:02,200
landscapes changing every day

108
00:04:59,230 --> 00:05:04,810
we have attack scenarios changing every

109
00:05:02,200 --> 00:05:08,170
day we are in the world where BOTS

110
00:05:04,810 --> 00:05:11,410
attacks are slowly rising we are in the

111
00:05:08,170 --> 00:05:13,900
world where we slowly started seeing how

112
00:05:11,410 --> 00:05:16,350
powerful JavaScript is becoming and that

113
00:05:13,900 --> 00:05:19,239
is leading to attacks like mage card

114
00:05:16,350 --> 00:05:21,910
companies like British Airways had to

115
00:05:19,240 --> 00:05:24,640
pay million dollars because of the mage

116
00:05:21,910 --> 00:05:27,400
cut attack you guys are not aware of

117
00:05:24,640 --> 00:05:30,880
mage card isn't is a newly introduced

118
00:05:27,400 --> 00:05:33,070
way where a JavaScript and externally

119
00:05:30,880 --> 00:05:34,810
loaded JavaScript on your page can start

120
00:05:33,070 --> 00:05:38,020
skimming your payment card information

121
00:05:34,810 --> 00:05:40,420
from the page these kind of attacks when

122
00:05:38,020 --> 00:05:43,150
they start coming into the market my

123
00:05:40,420 --> 00:05:45,340
question to you is does your existing

124
00:05:43,150 --> 00:05:49,150
threat modeling framework let it be

125
00:05:45,340 --> 00:05:52,150
stride pasta wasp any threat modeling

126
00:05:49,150 --> 00:05:55,299
framework can it actually address these

127
00:05:52,150 --> 00:05:58,929
new concerns new security threats that

128
00:05:55,300 --> 00:06:01,390
are coming in can it skill you have

129
00:05:58,930 --> 00:06:04,630
thousand plus requests coming for threat

130
00:06:01,390 --> 00:06:07,000
modeling for our organization does your

131
00:06:04,630 --> 00:06:10,240
current threat modeling framework able

132
00:06:07,000 --> 00:06:12,880
to scale those thousand requests can it

133
00:06:10,240 --> 00:06:15,550
blend in well with your agile

134
00:06:12,880 --> 00:06:18,510
environment when we read in the theories

135
00:06:15,550 --> 00:06:21,190
these are excellent these are marvelous

136
00:06:18,510 --> 00:06:24,520
but when I try to implement them in real

137
00:06:21,190 --> 00:06:28,060
life the story is different it is not

138
00:06:24,520 --> 00:06:30,669
purely agile it's not helping me keep a

139
00:06:28,060 --> 00:06:32,680
track of thousand plus threat modeling

140
00:06:30,669 --> 00:06:36,039
requests that I get in an organization

141
00:06:32,680 --> 00:06:38,979
such as eBay so how do we deal with the

142
00:06:36,039 --> 00:06:41,680
situation how do we tackle this problem

143
00:06:38,979 --> 00:06:45,370
and there comes

144
00:06:41,680 --> 00:06:49,090
a new threat modeling approach which is

145
00:06:45,370 --> 00:06:52,479
based on OS I didn't give him any cool

146
00:06:49,090 --> 00:06:54,280
acronyms because this is not another

147
00:06:52,479 --> 00:06:56,050
framework that I want to add to the

148
00:06:54,280 --> 00:06:58,750
industry I don't want to come up with a

149
00:06:56,050 --> 00:07:00,310
12th framework and tomorrow some other

150
00:06:58,750 --> 00:07:02,919
Chaitanya bird standing here will be

151
00:07:00,310 --> 00:07:06,520
introducing 13th framework we don't want

152
00:07:02,919 --> 00:07:10,299
to do that what we want is a mindset

153
00:07:06,520 --> 00:07:13,060
what we want is an approach if there are

154
00:07:10,300 --> 00:07:14,410
60 people sitting in the room they all

155
00:07:13,060 --> 00:07:17,530
should be going back to their

156
00:07:14,410 --> 00:07:19,720
organization and creating a threat

157
00:07:17,530 --> 00:07:22,448
modeling framework for yourself for your

158
00:07:19,720 --> 00:07:24,490
own organization so what we are trying

159
00:07:22,449 --> 00:07:28,210
to discuss here what we are aiming here

160
00:07:24,490 --> 00:07:29,949
is to talk about the approach what

161
00:07:28,210 --> 00:07:35,229
approach suits well for your

162
00:07:29,949 --> 00:07:37,870
organization so let's start the basic

163
00:07:35,229 --> 00:07:41,500
building block for this approach is a

164
00:07:37,870 --> 00:07:43,690
three step approach you have your

165
00:07:41,500 --> 00:07:46,360
InfoSec policy each and every

166
00:07:43,690 --> 00:07:49,630
organization has your own InfoSec policy

167
00:07:46,360 --> 00:07:52,330
these InfoSec policies differ from

168
00:07:49,630 --> 00:07:55,210
company to company and InfoSec policy

169
00:07:52,330 --> 00:07:56,919
for an ecommerce company will be

170
00:07:55,210 --> 00:07:59,739
different from an eco 4 from a

171
00:07:56,919 --> 00:08:02,310
manufacturing company right so the

172
00:07:59,740 --> 00:08:06,789
foundation of this approach is based on

173
00:08:02,310 --> 00:08:09,789
solely your InfoSec policy once you have

174
00:08:06,789 --> 00:08:11,680
your InfoSec policy this is where the

175
00:08:09,789 --> 00:08:14,560
threat modelers the security engineers

176
00:08:11,680 --> 00:08:17,830
come into the player and start creating

177
00:08:14,560 --> 00:08:21,130
the security standards these security

178
00:08:17,830 --> 00:08:23,380
standards are nothing but what should be

179
00:08:21,130 --> 00:08:26,380
required to achieve those inclusive

180
00:08:23,380 --> 00:08:30,280
policies these are all based on over

181
00:08:26,380 --> 00:08:32,260
top-10 mitigations not attacks rather

182
00:08:30,280 --> 00:08:34,569
than focusing on attacks the security

183
00:08:32,260 --> 00:08:36,580
standards that security team has to

184
00:08:34,570 --> 00:08:38,979
create must be focused on the

185
00:08:36,580 --> 00:08:41,680
mitigations that is how you connect to

186
00:08:38,979 --> 00:08:45,040
the developers so once you have your

187
00:08:41,679 --> 00:08:48,040
policy you create your standards what's

188
00:08:45,040 --> 00:08:49,180
the last step your controls your

189
00:08:48,040 --> 00:08:51,480
controls are nothing but the

190
00:08:49,180 --> 00:08:54,709
recommendations these recommendations

191
00:08:51,480 --> 00:08:59,060
will help you achieve those standards

192
00:08:54,710 --> 00:09:01,370
and these controls can be strict can be

193
00:08:59,060 --> 00:09:05,510
lenient based on how critical the flow

194
00:09:01,370 --> 00:09:08,300
is so we are not pushing you into a box

195
00:09:05,510 --> 00:09:11,630
of lists of controls that this is what

196
00:09:08,300 --> 00:09:14,780
you have to do no this is your security

197
00:09:11,630 --> 00:09:16,430
mindset that lets you believe that lets

198
00:09:14,780 --> 00:09:18,790
you take a decision on what kind of

199
00:09:16,430 --> 00:09:21,109
security controls you're going to take

200
00:09:18,790 --> 00:09:22,780
to make this more simple let's take an

201
00:09:21,110 --> 00:09:25,460
example

202
00:09:22,780 --> 00:09:27,500
your organization this is a very common

203
00:09:25,460 --> 00:09:29,870
policy that each organization has which

204
00:09:27,500 --> 00:09:31,850
is access control policy so if you have

205
00:09:29,870 --> 00:09:34,820
access control policy in order to

206
00:09:31,850 --> 00:09:35,990
achieve that let's say a team of

207
00:09:34,820 --> 00:09:38,470
security engineers come up with a

208
00:09:35,990 --> 00:09:41,420
standard called authorization

209
00:09:38,470 --> 00:09:43,310
straightforward simple now when an

210
00:09:41,420 --> 00:09:44,719
application comes forward review my

211
00:09:43,310 --> 00:09:48,680
control for that

212
00:09:44,720 --> 00:09:52,700
can be some strict scopes least

213
00:09:48,680 --> 00:09:55,489
privileged access revoking the access

214
00:09:52,700 --> 00:09:58,010
after usage now these can go even more

215
00:09:55,490 --> 00:10:00,560
strict if it's a sign-in flow I'm going

216
00:09:58,010 --> 00:10:02,660
to keep it more strict if it's a regular

217
00:10:00,560 --> 00:10:05,479
back in service flow I might keep it a

218
00:10:02,660 --> 00:10:07,160
little bit liberal right so based on how

219
00:10:05,480 --> 00:10:11,210
critical or how high the risk an

220
00:10:07,160 --> 00:10:15,550
application possess I can keep changing

221
00:10:11,210 --> 00:10:18,470
my controls in order to accommodate time

222
00:10:15,550 --> 00:10:20,000
so in order to proceed with this

223
00:10:18,470 --> 00:10:23,060
presentation I took the liberty of

224
00:10:20,000 --> 00:10:25,610
coming up with 13 security standards

225
00:10:23,060 --> 00:10:29,089
which are very generic you all can

226
00:10:25,610 --> 00:10:31,940
utilize it you might add some new based

227
00:10:29,090 --> 00:10:33,560
on your organization you might remove

228
00:10:31,940 --> 00:10:35,810
you if they're not relevant in your

229
00:10:33,560 --> 00:10:38,359
organization but these are a very

230
00:10:35,810 --> 00:10:41,510
generic security standards that I came

231
00:10:38,360 --> 00:10:45,380
up with now as you can see these

232
00:10:41,510 --> 00:10:48,230
security standards will cover all the

233
00:10:45,380 --> 00:10:53,060
top 10 vulnerabilities but you won't see

234
00:10:48,230 --> 00:10:53,990
any exercise or CSRF on it so if there

235
00:10:53,060 --> 00:10:57,170
is an exercise

236
00:10:53,990 --> 00:11:00,110
bug you would go and recommend your

237
00:10:57,170 --> 00:11:03,650
developers to implement input validation

238
00:11:00,110 --> 00:11:05,720
and manipulation right which covers all

239
00:11:03,650 --> 00:11:08,449
the input sanitization related controls

240
00:11:05,720 --> 00:11:10,970
if you want to create a defense in

241
00:11:08,450 --> 00:11:13,880
depth you would go in and recommend your

242
00:11:10,970 --> 00:11:14,690
users to implement CSV policies how do

243
00:11:13,880 --> 00:11:16,520
you do that

244
00:11:14,690 --> 00:11:19,400
browse the security and we'll take care

245
00:11:16,520 --> 00:11:22,780
of it browser security contains all the

246
00:11:19,400 --> 00:11:25,430
controls that that includes the security

247
00:11:22,780 --> 00:11:27,530
provided by browsers all you have to do

248
00:11:25,430 --> 00:11:29,770
is just go in there and enable those

249
00:11:27,530 --> 00:11:33,530
functionalities CSP is one such example

250
00:11:29,770 --> 00:11:35,120
sub resource integrity check if you

251
00:11:33,530 --> 00:11:38,630
remember I talked about an attack called

252
00:11:35,120 --> 00:11:40,340
match card now mage card is a serious

253
00:11:38,630 --> 00:11:42,350
problem a lot of companies are actually

254
00:11:40,340 --> 00:11:44,660
trying to tackle that problem well the

255
00:11:42,350 --> 00:11:47,810
solution one way to fix the problem is

256
00:11:44,660 --> 00:11:49,969
sub resource integrity check you start

257
00:11:47,810 --> 00:11:53,300
adding integrity hashes to a Java Script

258
00:11:49,970 --> 00:11:55,610
if you want to recommend that that would

259
00:11:53,300 --> 00:11:57,290
fall into browser security because most

260
00:11:55,610 --> 00:11:59,900
of the modern browsers except I think

261
00:11:57,290 --> 00:12:02,630
suffering do support sub resource

262
00:11:59,900 --> 00:12:05,180
integrity check all you have to do is

263
00:12:02,630 --> 00:12:07,250
just enable that so these are the kind

264
00:12:05,180 --> 00:12:09,800
of recommendations you can use in these

265
00:12:07,250 --> 00:12:11,330
high level high level categories high

266
00:12:09,800 --> 00:12:14,150
level standards will help you achieve

267
00:12:11,330 --> 00:12:17,150
that anti automation the first one

268
00:12:14,150 --> 00:12:20,329
there's nothing but a protection against

269
00:12:17,150 --> 00:12:22,490
bots it will keep you it will keep a

270
00:12:20,330 --> 00:12:25,190
check it will kind of put a rate limiter

271
00:12:22,490 --> 00:12:28,700
on your pages when someone is trying to

272
00:12:25,190 --> 00:12:30,490
do a lot of bot related attacks keeps on

273
00:12:28,700 --> 00:12:33,830
hitting your page again and again

274
00:12:30,490 --> 00:12:36,400
alright there's another category that I

275
00:12:33,830 --> 00:12:39,460
have added called business logic abuse

276
00:12:36,400 --> 00:12:42,590
business logic abuse is kind of a very

277
00:12:39,460 --> 00:12:45,260
tricky one because here is where you

278
00:12:42,590 --> 00:12:47,960
have to wear your most being most

279
00:12:45,260 --> 00:12:50,300
pessimist a security hat and come up

280
00:12:47,960 --> 00:12:54,200
with a lot of what-if scenarios what if

281
00:12:50,300 --> 00:12:56,270
I try to do this what if I try to bypass

282
00:12:54,200 --> 00:12:59,120
this and you come up with some business

283
00:12:56,270 --> 00:13:02,569
logic abuse cases because a lot of the

284
00:12:59,120 --> 00:13:05,480
attacks are not always because of some

285
00:13:02,570 --> 00:13:07,940
actual trick present many a times it is

286
00:13:05,480 --> 00:13:11,090
because an attacker is able to exploit

287
00:13:07,940 --> 00:13:14,330
your functionality or by create some

288
00:13:11,090 --> 00:13:16,310
business logic abuse case I'll move on

289
00:13:14,330 --> 00:13:19,100
to the next ones I'll just give quick a

290
00:13:16,310 --> 00:13:22,229
quick brief one-liners about each of

291
00:13:19,100 --> 00:13:24,810
them there is compliance right within

292
00:13:22,230 --> 00:13:27,450
action of GDP our California Privacy Act

293
00:13:24,810 --> 00:13:29,280
a lot of things have been coming in and

294
00:13:27,450 --> 00:13:31,440
that's where I think security has to

295
00:13:29,280 --> 00:13:33,329
step up our game come up with the

296
00:13:31,440 --> 00:13:36,240
compliance requirements to whenever they

297
00:13:33,330 --> 00:13:38,010
are needed and also if you have your

298
00:13:36,240 --> 00:13:40,770
internal compliance requirements in your

299
00:13:38,010 --> 00:13:42,990
organization such as and a service has

300
00:13:40,770 --> 00:13:44,130
to pass some of the tests you can of

301
00:13:42,990 --> 00:13:46,020
course recommend everything under

302
00:13:44,130 --> 00:13:49,320
compliance configuration management

303
00:13:46,020 --> 00:13:50,569
refers to over stopped in Security miss

304
00:13:49,320 --> 00:13:53,010
configuration this could be

305
00:13:50,570 --> 00:13:55,460
misconfigured server misconfigured

306
00:13:53,010 --> 00:13:58,250
certificates all that falls into that

307
00:13:55,460 --> 00:14:01,380
cryptographic control the name suggests

308
00:13:58,250 --> 00:14:04,920
all crypto related stuff has to fall

309
00:14:01,380 --> 00:14:07,230
into this data management anything where

310
00:14:04,920 --> 00:14:09,569
your database is unable to handle your

311
00:14:07,230 --> 00:14:12,060
requests properly your parameterised

312
00:14:09,570 --> 00:14:15,060
queries these kind of recommendations is

313
00:14:12,060 --> 00:14:19,500
what falls into data management already

314
00:14:15,060 --> 00:14:21,780
talked about input validation logging we

315
00:14:19,500 --> 00:14:24,120
all do log I think we had an excellent

316
00:14:21,780 --> 00:14:26,670
session here before where someone was

317
00:14:24,120 --> 00:14:28,500
talking about logging stuff right but

318
00:14:26,670 --> 00:14:30,839
when you log stuff you have to make sure

319
00:14:28,500 --> 00:14:32,190
you don't start logging sensitive

320
00:14:30,840 --> 00:14:34,680
information you don't start logging

321
00:14:32,190 --> 00:14:37,020
passwords in your logs right so this is

322
00:14:34,680 --> 00:14:38,339
a new Avenue that you keep on adding to

323
00:14:37,020 --> 00:14:40,680
your threat modeling scopes

324
00:14:38,340 --> 00:14:42,240
these were not available these are not

325
00:14:40,680 --> 00:14:45,239
available in our existing frameworks

326
00:14:42,240 --> 00:14:48,890
known vulnerabilities again a new era

327
00:14:45,240 --> 00:14:51,510
where biggest breach happened because

328
00:14:48,890 --> 00:14:53,490
someone was using unknown vulnerable

329
00:14:51,510 --> 00:14:57,660
version of Apache struts to that lead

330
00:14:53,490 --> 00:15:01,110
that led to what s essence SSN from

331
00:14:57,660 --> 00:15:03,089
Equifax was breached right so these kind

332
00:15:01,110 --> 00:15:05,280
of attacks must be addressed in your

333
00:15:03,090 --> 00:15:08,280
threat modeling framework what's the use

334
00:15:05,280 --> 00:15:10,380
of the art of foreseeing threats if you

335
00:15:08,280 --> 00:15:13,290
cannot actually determine them in an

336
00:15:10,380 --> 00:15:16,320
early stage so using these standards

337
00:15:13,290 --> 00:15:18,780
will actually proceed you must be one

338
00:15:16,320 --> 00:15:21,300
wondering like okay you this guys coming

339
00:15:18,780 --> 00:15:22,800
up with a new approach is he gonna

340
00:15:21,300 --> 00:15:25,109
change the process how we do threat

341
00:15:22,800 --> 00:15:28,050
modeling no I'm not changing the process

342
00:15:25,110 --> 00:15:30,120
we still rely on the requirement

343
00:15:28,050 --> 00:15:32,640
gathering an onboarding stage we have

344
00:15:30,120 --> 00:15:34,440
identifying and discovering the phase we

345
00:15:32,640 --> 00:15:35,910
decompose the application which is

346
00:15:34,440 --> 00:15:40,440
nothing but the simple dividing

347
00:15:35,910 --> 00:15:43,560
conquer we apply pse pse again nothing

348
00:15:40,440 --> 00:15:46,410
but our model that I mentioned policy

349
00:15:43,560 --> 00:15:49,380
standards control acronym for that is

350
00:15:46,410 --> 00:15:51,329
PSE but that's not the name again

351
00:15:49,380 --> 00:15:54,090
and finally we give out recommendation

352
00:15:51,330 --> 00:15:57,030
and balance out the risk so with this

353
00:15:54,090 --> 00:15:59,850
approach I think we're getting a lot of

354
00:15:57,030 --> 00:16:02,310
information lot of talking right so what

355
00:15:59,850 --> 00:16:06,120
we want to do next is we'll try to take

356
00:16:02,310 --> 00:16:09,150
an example one sample use case and try

357
00:16:06,120 --> 00:16:11,730
applying this PSC model onto this and

358
00:16:09,150 --> 00:16:15,030
for the sake of simplicity I took a

359
00:16:11,730 --> 00:16:18,480
library management system as an example

360
00:16:15,030 --> 00:16:20,370
and we'll follow those five steps so to

361
00:16:18,480 --> 00:16:23,880
start with the first step which was

362
00:16:20,370 --> 00:16:26,520
requirement gathering and onboarding we

363
00:16:23,880 --> 00:16:28,380
start gathering the requirement that the

364
00:16:26,520 --> 00:16:30,780
library management system it aims to

365
00:16:28,380 --> 00:16:33,150
manage resource giving access to the

366
00:16:30,780 --> 00:16:35,189
users there are three types of actors

367
00:16:33,150 --> 00:16:39,510
who are going to access this there is a

368
00:16:35,190 --> 00:16:41,610
regular user members and admin the kind

369
00:16:39,510 --> 00:16:43,680
of data that this portal is going to

370
00:16:41,610 --> 00:16:48,660
handle is PCI data because it accepts

371
00:16:43,680 --> 00:16:50,910
credit card for your membership fees the

372
00:16:48,660 --> 00:16:52,620
portal is internet facing not intranet

373
00:16:50,910 --> 00:16:54,870
facing so that's a very important

374
00:16:52,620 --> 00:16:57,870
information and you'll get to know the

375
00:16:54,870 --> 00:17:01,320
importance of this the portal is built

376
00:16:57,870 --> 00:17:03,870
on node.js Express framework html5 css3

377
00:17:01,320 --> 00:17:06,960
pretty straightforward and MongoDB is

378
00:17:03,870 --> 00:17:10,530
what the default database that the team

379
00:17:06,960 --> 00:17:14,670
is planning to use step to identify and

380
00:17:10,530 --> 00:17:18,030
decompose from our flow so we started

381
00:17:14,670 --> 00:17:20,100
identifying what are the flows we came

382
00:17:18,030 --> 00:17:22,200
up with these three users where a user

383
00:17:20,099 --> 00:17:25,079
who's a non-member might come and

384
00:17:22,200 --> 00:17:28,890
register pay membership fee and become a

385
00:17:25,079 --> 00:17:31,320
regular user once he's a regular user he

386
00:17:28,890 --> 00:17:34,230
can log-in issue book return book and

387
00:17:31,320 --> 00:17:37,379
renew membership similarly on the admin

388
00:17:34,230 --> 00:17:40,890
side you can manage resources update

389
00:17:37,380 --> 00:17:43,470
payments for late find and send

390
00:17:40,890 --> 00:17:45,930
reminders so with that we have

391
00:17:43,470 --> 00:17:48,360
identified the flows what are you might

392
00:17:45,930 --> 00:17:49,740
already have started identifying some

393
00:17:48,360 --> 00:17:52,439
critical flows and these

394
00:17:49,740 --> 00:17:54,659
right so we start understanding we start

395
00:17:52,440 --> 00:17:58,039
analyzing that what's the next step

396
00:17:54,659 --> 00:18:02,190
decompose for the sake of simplicity

397
00:17:58,039 --> 00:18:07,279
we'll just take the first row for our

398
00:18:02,190 --> 00:18:09,690
for our POC and this is our favorite

399
00:18:07,279 --> 00:18:13,350
every threat modeling team loves that

400
00:18:09,690 --> 00:18:17,340
data flow diagrams right we go crazy for

401
00:18:13,350 --> 00:18:20,370
data flow diagrams so we have a clutter

402
00:18:17,340 --> 00:18:22,500
here all I see is clutter I don't know

403
00:18:20,370 --> 00:18:24,029
what's going on with this although I

404
00:18:22,500 --> 00:18:27,899
made it but I don't know what's going on

405
00:18:24,029 --> 00:18:31,380
so following the third step of my

406
00:18:27,899 --> 00:18:34,020
process which was decompose I decompose

407
00:18:31,380 --> 00:18:38,130
this and we'll try to focus on just the

408
00:18:34,020 --> 00:18:40,529
login but since I have to explain this

409
00:18:38,130 --> 00:18:43,980
rather than doing a check modeling on

410
00:18:40,529 --> 00:18:46,110
this clutter I just did a simplistic job

411
00:18:43,980 --> 00:18:48,419
but just creating an architecture

412
00:18:46,110 --> 00:18:49,820
diagram and will try to apply PSC model

413
00:18:48,419 --> 00:18:54,059
on this one

414
00:18:49,820 --> 00:18:57,270
so the flow still remains the same you

415
00:18:54,059 --> 00:19:00,059
have admin member signs n there's a log

416
00:18:57,270 --> 00:19:03,809
in service that request all the all the

417
00:19:00,059 --> 00:19:05,220
parameters it logs everything checks for

418
00:19:03,809 --> 00:19:08,100
the member status there are three

419
00:19:05,220 --> 00:19:10,080
databases in here the payment DB is in

420
00:19:08,100 --> 00:19:12,840
PCI Zone so that's why you might see a

421
00:19:10,080 --> 00:19:15,720
red dot there there is College database

422
00:19:12,840 --> 00:19:17,639
which is an another zone which actually

423
00:19:15,720 --> 00:19:20,130
is responsible for checking if a user is

424
00:19:17,640 --> 00:19:23,220
a part of this college or not and of

425
00:19:20,130 --> 00:19:26,909
course the front one that you see is an

426
00:19:23,220 --> 00:19:29,250
internet boundary so with this let's

427
00:19:26,909 --> 00:19:31,890
start applying the PSC model and see how

428
00:19:29,250 --> 00:19:35,909
fun it is I'll start with the sign-in

429
00:19:31,890 --> 00:19:37,799
page and I automation is the first thing

430
00:19:35,909 --> 00:19:40,409
that I would like to recommend my

431
00:19:37,799 --> 00:19:43,260
InfoSec policy is for anti automation

432
00:19:40,409 --> 00:19:45,390
the standard that I applied was a a that

433
00:19:43,260 --> 00:19:48,270
is anti automation and the controls that

434
00:19:45,390 --> 00:19:50,580
I want to put on this one is limit sign

435
00:19:48,270 --> 00:19:54,179
in attempts I want to challenge users

436
00:19:50,580 --> 00:19:56,699
with CAPTCHA if you remember I talked

437
00:19:54,179 --> 00:20:01,169
about some recent threats such as bot

438
00:19:56,700 --> 00:20:01,950
attacks this one will help you protect

439
00:20:01,169 --> 00:20:03,840
again

440
00:20:01,950 --> 00:20:06,510
BOTS trying to do cuttings and stuffing

441
00:20:03,840 --> 00:20:08,449
on your page you want to make sure these

442
00:20:06,510 --> 00:20:11,160
attacks do not happen on your page so

443
00:20:08,450 --> 00:20:13,700
our entire automation is one such

444
00:20:11,160 --> 00:20:17,040
control that are going to prevent that

445
00:20:13,700 --> 00:20:18,750
input validation of course it's going to

446
00:20:17,040 --> 00:20:22,200
accept user parameters username and

447
00:20:18,750 --> 00:20:26,400
password I want to make sure it is

448
00:20:22,200 --> 00:20:30,090
sanitized no funky characters accepted

449
00:20:26,400 --> 00:20:34,590
so an output security out code output

450
00:20:30,090 --> 00:20:38,040
encoding is applied so a next browser

451
00:20:34,590 --> 00:20:40,939
policy but I want to make sure CSP

452
00:20:38,040 --> 00:20:43,290
policies are implemented for non scripts

453
00:20:40,940 --> 00:20:45,660
sub resource integrity checks are

454
00:20:43,290 --> 00:20:48,210
applied if there are any externally

455
00:20:45,660 --> 00:20:50,580
hosted Java scripts on the page and you

456
00:20:48,210 --> 00:20:53,820
keep on adding those this can go more

457
00:20:50,580 --> 00:20:57,199
strict this can go more lenient on how

458
00:20:53,820 --> 00:21:00,629
you feel what your security mindset is

459
00:20:57,200 --> 00:21:03,300
next is log of course you don't want to

460
00:21:00,630 --> 00:21:05,040
you don't want to log any sensitive

461
00:21:03,300 --> 00:21:07,950
information but if you do you have to

462
00:21:05,040 --> 00:21:09,899
make sure you mask it right you want to

463
00:21:07,950 --> 00:21:12,120
log all the sign-in attempts that have

464
00:21:09,900 --> 00:21:15,590
been made just for your auditing purpose

465
00:21:12,120 --> 00:21:18,719
and so on and so forth I'll just quickly

466
00:21:15,590 --> 00:21:20,520
add rest of the components all the rest

467
00:21:18,720 --> 00:21:23,010
of the standards and it would look

468
00:21:20,520 --> 00:21:26,610
something like this right where you will

469
00:21:23,010 --> 00:21:29,700
see login service I've added known

470
00:21:26,610 --> 00:21:32,189
vulnerability kV here because I realize

471
00:21:29,700 --> 00:21:35,370
it's being built on node.js Express

472
00:21:32,190 --> 00:21:38,550
framework and I want to make sure I let

473
00:21:35,370 --> 00:21:41,520
the team know to start using 10.15 and

474
00:21:38,550 --> 00:21:43,800
not anything before that because there

475
00:21:41,520 --> 00:21:46,379
are known vulnerabilities for all the

476
00:21:43,800 --> 00:21:49,139
previous versions of node.js I want to

477
00:21:46,380 --> 00:21:51,480
get those things right now to the team

478
00:21:49,140 --> 00:21:54,690
so that they don't have to really factor

479
00:21:51,480 --> 00:21:57,180
the whole code by including new new

480
00:21:54,690 --> 00:21:59,280
frameworks or have to upgrade it to the

481
00:21:57,180 --> 00:22:01,050
new framework right

482
00:21:59,280 --> 00:22:02,670
there's configuration management that I

483
00:22:01,050 --> 00:22:04,800
have added in just to make sure the

484
00:22:02,670 --> 00:22:07,740
HTTPS certificates are rightly

485
00:22:04,800 --> 00:22:09,419
configured so all those things are

486
00:22:07,740 --> 00:22:13,350
actually this is how they are being

487
00:22:09,420 --> 00:22:15,350
applied in here so we have

488
00:22:13,350 --> 00:22:22,649
applied our PSC model that was step four

489
00:22:15,350 --> 00:22:24,600
Step five risk the most important part

490
00:22:22,650 --> 00:22:29,190
when you want to communicate this to the

491
00:22:24,600 --> 00:22:32,370
developers how critical it is now for an

492
00:22:29,190 --> 00:22:33,750
organization which is newly introducing

493
00:22:32,370 --> 00:22:36,870
threat modeling into their framework

494
00:22:33,750 --> 00:22:38,760
into their SDLC pipeline can actually

495
00:22:36,870 --> 00:22:42,780
start with something like this which is

496
00:22:38,760 --> 00:22:44,580
an OS based risk rating framework it's a

497
00:22:42,780 --> 00:22:46,918
simple combination of likelihood and

498
00:22:44,580 --> 00:22:48,658
impact but if you if your threat

499
00:22:46,919 --> 00:22:51,590
modeling processes mature enough you

500
00:22:48,659 --> 00:22:55,559
might also be using something like dread

501
00:22:51,590 --> 00:22:59,789
but the most important question here is

502
00:22:55,559 --> 00:23:03,210
is this okay is this sufficient with the

503
00:22:59,789 --> 00:23:05,658
PSC model let me give you let me ask

504
00:23:03,210 --> 00:23:10,700
this question again with an example

505
00:23:05,659 --> 00:23:13,320
let's take this use case sprint one

506
00:23:10,700 --> 00:23:15,179
first phase a back-end system came in

507
00:23:13,320 --> 00:23:18,178
for our design review which was talking

508
00:23:15,179 --> 00:23:20,970
to database and we realized there is an

509
00:23:18,179 --> 00:23:22,980
authorization issue because something in

510
00:23:20,970 --> 00:23:26,490
the backend is directly referencing to

511
00:23:22,980 --> 00:23:28,909
the database I felt this should be noted

512
00:23:26,490 --> 00:23:32,520
and I added data management and

513
00:23:28,909 --> 00:23:33,090
authorization into it based on my risk

514
00:23:32,520 --> 00:23:35,760
rating

515
00:23:33,090 --> 00:23:40,080
I felt the risk is high but that was

516
00:23:35,760 --> 00:23:44,100
phase one second sprint phase two of

517
00:23:40,080 --> 00:23:46,500
agile now there is a front-end system

518
00:23:44,100 --> 00:23:50,010
which is going to which is going to

519
00:23:46,500 --> 00:23:51,900
consume this back-end service now if you

520
00:23:50,010 --> 00:23:55,530
think about it there was already a

521
00:23:51,900 --> 00:23:59,340
residual risk of authorization which was

522
00:23:55,530 --> 00:24:06,330
categorized as risk hi this had

523
00:23:59,340 --> 00:24:09,199
authorization and now we have unsecure

524
00:24:06,330 --> 00:24:12,928
direct object reference in the front-end

525
00:24:09,200 --> 00:24:17,309
you still feel the risk is high it is

526
00:24:12,929 --> 00:24:21,750
critical it is critical and the reason

527
00:24:17,309 --> 00:24:24,928
why we could get this is because just by

528
00:24:21,750 --> 00:24:26,490
applying that standard box wouldn't have

529
00:24:24,929 --> 00:24:28,980
wouldn't have helped

530
00:24:26,490 --> 00:24:30,740
identify or classify this as critical

531
00:24:28,980 --> 00:24:35,400
this would have still been a high risk

532
00:24:30,740 --> 00:24:37,530
because in our security agile world we

533
00:24:35,400 --> 00:24:39,900
don't take the information what we have

534
00:24:37,530 --> 00:24:44,010
learned in our previous phase to the

535
00:24:39,900 --> 00:24:46,620
next phase and that is why when we

536
00:24:44,010 --> 00:24:50,129
balance the risk we need an additional

537
00:24:46,620 --> 00:24:52,050
column of existing risk it looks a

538
00:24:50,130 --> 00:24:56,460
little bit confusing but let me explain

539
00:24:52,050 --> 00:24:59,930
how this can be rated so a vulnerability

540
00:24:56,460 --> 00:25:03,120
with impact high with a likelihood

541
00:24:59,930 --> 00:25:06,270
medium but we realize there's an

542
00:25:03,120 --> 00:25:08,399
existing risk which was high becomes a

543
00:25:06,270 --> 00:25:11,160
critical bug is no longer a high or a

544
00:25:08,400 --> 00:25:13,740
medium issue so when you start

545
00:25:11,160 --> 00:25:16,560
propagating what you learned in your any

546
00:25:13,740 --> 00:25:18,450
previous phase into your next phase you

547
00:25:16,560 --> 00:25:21,480
start bumping up those categories and

548
00:25:18,450 --> 00:25:23,370
you learn and that's how you keep

549
00:25:21,480 --> 00:25:25,950
changing your balancing the risk phase

550
00:25:23,370 --> 00:25:31,169
of that's the last phase of your threat

551
00:25:25,950 --> 00:25:34,050
modeling right so with this we complete

552
00:25:31,170 --> 00:25:36,030
all the five steps of threat modeling we

553
00:25:34,050 --> 00:25:38,580
have learned how to apply P how to

554
00:25:36,030 --> 00:25:40,230
create BSC for your organization we have

555
00:25:38,580 --> 00:25:41,970
learned how you can apply those BSC

556
00:25:40,230 --> 00:25:46,970
model we have learned how you can

557
00:25:41,970 --> 00:25:49,410
balance the risk but let me ask you this

558
00:25:46,970 --> 00:25:52,980
how do you measure your success of your

559
00:25:49,410 --> 00:25:55,710
program is it going well are there

560
00:25:52,980 --> 00:25:57,990
things to be changed as a threat

561
00:25:55,710 --> 00:25:59,790
modeling team if I have to ask you what

562
00:25:57,990 --> 00:26:02,490
are the 10 biggest threats your

563
00:25:59,790 --> 00:26:04,409
organization have will you be able to

564
00:26:02,490 --> 00:26:08,010
answer that what are the top five

565
00:26:04,410 --> 00:26:10,470
products with maximum risk will you be

566
00:26:08,010 --> 00:26:12,180
able to answer that how do you

567
00:26:10,470 --> 00:26:14,910
prioritize the threat modeling requests

568
00:26:12,180 --> 00:26:17,790
if your requests are 100 plus or

569
00:26:14,910 --> 00:26:21,090
thousand plus how do you handle the

570
00:26:17,790 --> 00:26:25,110
incremental changes some very valid

571
00:26:21,090 --> 00:26:28,010
questions my manager asked me and I

572
00:26:25,110 --> 00:26:31,260
didn't have answers and that's when I

573
00:26:28,010 --> 00:26:36,870
came with the last missing piece of the

574
00:26:31,260 --> 00:26:39,710
threat modeling a threat surfing tool is

575
00:26:36,870 --> 00:26:41,330
a tool that was created in eBay at

576
00:26:39,710 --> 00:26:45,409
we have been working on for a while and

577
00:26:41,330 --> 00:26:49,220
this is what helps me complete the full

578
00:26:45,409 --> 00:26:51,140
puzzle of threat modeling this is the

579
00:26:49,220 --> 00:26:55,010
answer to all the questions that were

580
00:26:51,140 --> 00:26:58,340
asked in the previous slide so where

581
00:26:55,010 --> 00:27:00,440
does this fit in the threat surfing fits

582
00:26:58,340 --> 00:27:02,840
in your first stage and you'll see

583
00:27:00,440 --> 00:27:04,520
another sixth step added to a threat

584
00:27:02,840 --> 00:27:07,789
modeling process which is stored and

585
00:27:04,520 --> 00:27:10,039
analyzed on your requirement onboarding

586
00:27:07,789 --> 00:27:12,740
and gathering phase threat surfing would

587
00:27:10,039 --> 00:27:14,510
ask you some basic questions just to

588
00:27:12,740 --> 00:27:16,820
understand how critical the project is

589
00:27:14,510 --> 00:27:20,330
just to understand what is the priority

590
00:27:16,820 --> 00:27:22,460
of this project and once it determines

591
00:27:20,330 --> 00:27:24,830
the risk associated how critical the

592
00:27:22,460 --> 00:27:27,380
project is it actually passes on it

593
00:27:24,830 --> 00:27:29,960
prioritizes these applications and at

594
00:27:27,380 --> 00:27:32,679
the end of threat modeling you basically

595
00:27:29,960 --> 00:27:35,510
store and create a risk analytics

596
00:27:32,679 --> 00:27:40,549
dashboard which can be used by multiple

597
00:27:35,510 --> 00:27:42,169
people so what we did here if you

598
00:27:40,549 --> 00:27:45,500
remember my previous slide I talked

599
00:27:42,169 --> 00:27:48,230
about the agile problem we actually

600
00:27:45,500 --> 00:27:50,720
didn't solve the agile problem when we

601
00:27:48,230 --> 00:27:55,490
just created a circular process within

602
00:27:50,720 --> 00:27:57,500
security a true agile can only be

603
00:27:55,490 --> 00:28:00,289
achieved when you start creating a

604
00:27:57,500 --> 00:28:03,169
feedback model a feedback that comes

605
00:28:00,289 --> 00:28:05,658
back from SAS a feedback that come from

606
00:28:03,169 --> 00:28:08,330
your test feedback that comes back from

607
00:28:05,659 --> 00:28:10,340
pen testing into a thread surfing or

608
00:28:08,330 --> 00:28:12,799
threat modeling phase the thread

609
00:28:10,340 --> 00:28:16,870
modelling should be the brain of your

610
00:28:12,799 --> 00:28:19,610
process that can help you identify and

611
00:28:16,870 --> 00:28:23,570
foresee these kind of threats and risk

612
00:28:19,610 --> 00:28:25,039
associated with your application so how

613
00:28:23,570 --> 00:28:27,710
does the thread surfing architecture

614
00:28:25,039 --> 00:28:30,590
looks like there's an onboarding portal

615
00:28:27,710 --> 00:28:32,630
the teams will be coming in they'll be

616
00:28:30,590 --> 00:28:36,439
answering questions like what kind of

617
00:28:32,630 --> 00:28:38,000
data are you using can you give out some

618
00:28:36,440 --> 00:28:39,799
data elements what you are using

619
00:28:38,000 --> 00:28:43,010
what's the development language you are

620
00:28:39,799 --> 00:28:45,110
planning to build this on what are the

621
00:28:43,010 --> 00:28:46,960
upstream services that you're going to

622
00:28:45,110 --> 00:28:50,539
consume what are the downstream services

623
00:28:46,960 --> 00:28:52,580
associated with this application after

624
00:28:50,539 --> 00:28:53,660
answering these questions this is all

625
00:28:52,580 --> 00:28:55,909
fed into our

626
00:28:53,660 --> 00:28:58,070
database and this database is also

627
00:28:55,910 --> 00:29:00,169
plugged to our ticketing system at this

628
00:28:58,070 --> 00:29:01,370
ticketing system is nothing but the

629
00:29:00,169 --> 00:29:03,350
feedback that I showed in the previous

630
00:29:01,370 --> 00:29:06,199
slide it actually pulls data from your

631
00:29:03,350 --> 00:29:09,770
sassed pulls data from your dashed pulls

632
00:29:06,200 --> 00:29:13,010
data from pentesting and everything it

633
00:29:09,770 --> 00:29:15,590
can it can have all the data associated

634
00:29:13,010 --> 00:29:18,289
with an application which are open which

635
00:29:15,590 --> 00:29:20,770
we have previously reported that's how

636
00:29:18,289 --> 00:29:24,590
you know what are the residual risks

637
00:29:20,770 --> 00:29:26,710
combining that with the pse model is fed

638
00:29:24,590 --> 00:29:29,530
into the threat modeling engine and that

639
00:29:26,710 --> 00:29:33,429
gives out your threat modeling portal

640
00:29:29,530 --> 00:29:36,740
your engineers can log in they can see

641
00:29:33,429 --> 00:29:38,840
what are the what is the queue that I

642
00:29:36,740 --> 00:29:42,500
have what are the previous risks that

643
00:29:38,840 --> 00:29:44,330
are available with this request they

644
00:29:42,500 --> 00:29:46,970
already have a prefilled information

645
00:29:44,330 --> 00:29:49,039
that helps them analyze and get some

646
00:29:46,970 --> 00:29:52,400
easy understanding right into the early

647
00:29:49,039 --> 00:29:54,950
stage to know this could be a big big

648
00:29:52,400 --> 00:29:58,100
big project that could possess some big

649
00:29:54,950 --> 00:30:00,530
risks right your security auditors can

650
00:29:58,100 --> 00:30:02,809
log into this portal and see top five

651
00:30:00,530 --> 00:30:05,149
threats in an organ in your organization

652
00:30:02,809 --> 00:30:07,129
which is the biggest risk your

653
00:30:05,150 --> 00:30:10,669
application which is the biggest risk

654
00:30:07,130 --> 00:30:12,590
that your each application has which is

655
00:30:10,669 --> 00:30:15,620
the most risky application we are trying

656
00:30:12,590 --> 00:30:18,080
to handle at this moment and last but

657
00:30:15,620 --> 00:30:20,000
not the least your executors your

658
00:30:18,080 --> 00:30:21,789
leaders your seaso can log in to see

659
00:30:20,000 --> 00:30:24,470
what is a threat landscape

660
00:30:21,789 --> 00:30:29,360
how does my organization threat

661
00:30:24,470 --> 00:30:32,510
landscape looks like so sadly I was

662
00:30:29,360 --> 00:30:35,030
unable to bring out this tool here

663
00:30:32,510 --> 00:30:37,429
because we are still evaluating the

664
00:30:35,030 --> 00:30:40,129
legal and privacy aspects of it but keep

665
00:30:37,429 --> 00:30:42,679
an eye on the github eBay page you

666
00:30:40,130 --> 00:30:45,169
should be able to get this tool we are

667
00:30:42,679 --> 00:30:48,260
soon open sourcing it but if you guys

668
00:30:45,169 --> 00:30:52,640
want to build your own the the basic

669
00:30:48,260 --> 00:30:55,340
idea still remains the same so how the

670
00:30:52,640 --> 00:30:58,520
tool looks I was still able to get some

671
00:30:55,340 --> 00:31:02,120
screenshots hey guys so we have a chat

672
00:30:58,520 --> 00:31:03,830
bot which is nothing but an onboarding

673
00:31:02,120 --> 00:31:06,979
which is what is required for onboarding

674
00:31:03,830 --> 00:31:08,510
so you basically product teams comes in

675
00:31:06,980 --> 00:31:10,909
answer some basic question the chat

676
00:31:08,510 --> 00:31:12,559
board will ask you some questions series

677
00:31:10,909 --> 00:31:14,720
of questions just to identify what all

678
00:31:12,559 --> 00:31:16,190
data elements you're using what are

679
00:31:14,720 --> 00:31:18,919
upstream services downstream services

680
00:31:16,190 --> 00:31:20,210
PCI data are restricted data what are

681
00:31:18,919 --> 00:31:24,889
the data classifications that you're

682
00:31:20,210 --> 00:31:30,110
using and this along with PSC model

683
00:31:24,889 --> 00:31:32,809
finally gives me a threat landscape this

684
00:31:30,110 --> 00:31:38,299
is what every executive every leadership

685
00:31:32,809 --> 00:31:40,460
wants to know wants to see this is what

686
00:31:38,299 --> 00:31:42,230
came out from threat surfing that gives

687
00:31:40,460 --> 00:31:44,090
me that helps me creating the baseline

688
00:31:42,230 --> 00:31:47,630
so the red line that you see is a

689
00:31:44,090 --> 00:31:51,019
baseline from previous year and the blue

690
00:31:47,630 --> 00:31:54,230
bar chart that you see is nothing but

691
00:31:51,019 --> 00:31:56,570
the risk for this year how do you read

692
00:31:54,230 --> 00:32:01,010
this chart you can see here the browser

693
00:31:56,570 --> 00:32:06,408
security which was 5% last year the

694
00:32:01,010 --> 00:32:08,179
baseline has increased to 18% and again

695
00:32:06,409 --> 00:32:13,159
this is based on test data this is not

696
00:32:08,179 --> 00:32:15,169
eBay's threat landscape so I just wanted

697
00:32:13,159 --> 00:32:18,409
to clarify that

698
00:32:15,169 --> 00:32:20,149
so the browser security slowly we

699
00:32:18,409 --> 00:32:22,460
realize that there is an increasing

700
00:32:20,149 --> 00:32:25,309
scope there's an increasing threats

701
00:32:22,460 --> 00:32:28,970
associated with browser security what

702
00:32:25,309 --> 00:32:31,039
can I do with this data 2020 I can plant

703
00:32:28,970 --> 00:32:32,600
projects for this that I have to focus

704
00:32:31,039 --> 00:32:37,158
more on browser security

705
00:32:32,600 --> 00:32:39,309
I know 2020 when I train developers I

706
00:32:37,159 --> 00:32:41,960
have to train them on browser security

707
00:32:39,309 --> 00:32:44,059
components start adding them into your

708
00:32:41,960 --> 00:32:47,179
training modules start adding them into

709
00:32:44,059 --> 00:32:48,678
your requirement documentation so this

710
00:32:47,179 --> 00:32:51,740
is what actually helps you create a

711
00:32:48,679 --> 00:32:53,929
feedback loop you'll slowly start seeing

712
00:32:51,740 --> 00:32:57,320
an improvement like how you saw in

713
00:32:53,929 --> 00:33:00,230
crypto the nine percent from last year

714
00:32:57,320 --> 00:33:02,418
has gone down to seven percent because

715
00:33:00,230 --> 00:33:05,210
you actually added some right controls

716
00:33:02,419 --> 00:33:06,950
some right training modules some right

717
00:33:05,210 --> 00:33:09,769
requirement documentation to the

718
00:33:06,950 --> 00:33:11,090
developers and that is how you know that

719
00:33:09,769 --> 00:33:18,039
you are actually doing something right

720
00:33:11,090 --> 00:33:20,370
in your organization right so PSC model

721
00:33:18,039 --> 00:33:23,400
and you

722
00:33:20,370 --> 00:33:25,889
trait surfing combined will actually

723
00:33:23,400 --> 00:33:30,630
give you a lot of benefits it is agile

724
00:33:25,890 --> 00:33:32,549
in true sense it can easily update you

725
00:33:30,630 --> 00:33:35,820
can easily update your threat modeling

726
00:33:32,549 --> 00:33:38,129
cycle usually people try to upgrade

727
00:33:35,820 --> 00:33:40,168
their process and once in five years

728
00:33:38,130 --> 00:33:42,270
but this would actually help you up

729
00:33:40,169 --> 00:33:44,309
changing a threat modeling process every

730
00:33:42,270 --> 00:33:46,320
year you might add new standards

731
00:33:44,309 --> 00:33:48,450
you might remove new standards as soon

732
00:33:46,320 --> 00:33:50,189
as the InfoSec policy changes you might

733
00:33:48,450 --> 00:33:52,380
change the news you might add the new

734
00:33:50,190 --> 00:33:55,470
standards according to your policy right

735
00:33:52,380 --> 00:33:56,940
it is mitigation centric that is how you

736
00:33:55,470 --> 00:34:00,870
connect to the developers rather than

737
00:33:56,940 --> 00:34:02,580
throwing stuff like CSRF SSR if the

738
00:34:00,870 --> 00:34:05,510
developer is going to get scared out of

739
00:34:02,580 --> 00:34:08,699
it rather I tell him what to fix and

740
00:34:05,510 --> 00:34:09,780
that is how we connect to the product

741
00:34:08,699 --> 00:34:12,178
teams more easily

742
00:34:09,780 --> 00:34:14,399
it actually can handle incremental

743
00:34:12,179 --> 00:34:16,320
changes it is developer friendly as I

744
00:34:14,399 --> 00:34:18,989
mentioned it aligns well with your

745
00:34:16,320 --> 00:34:21,210
organization goals and it gives you a

746
00:34:18,989 --> 00:34:22,580
better visibility across the

747
00:34:21,210 --> 00:34:26,129
organization

748
00:34:22,580 --> 00:34:28,080
so with that thing I know there was a

749
00:34:26,129 --> 00:34:31,219
lot of information but I'll quickly

750
00:34:28,080 --> 00:34:34,980
summarize it with four key takeaways

751
00:34:31,219 --> 00:34:39,868
first what we learned from this session

752
00:34:34,980 --> 00:34:42,869
a circular process doesn't make stuff

753
00:34:39,869 --> 00:34:45,659
agile you have to always make sure the

754
00:34:42,869 --> 00:34:47,820
smaller iterations are created within

755
00:34:45,659 --> 00:34:50,940
your process in order to truly

756
00:34:47,820 --> 00:34:56,099
accommodate in order to truly blend into

757
00:34:50,940 --> 00:35:00,839
your assess DLC process focus on top-10

758
00:34:56,099 --> 00:35:02,790
mitigations OS top 10 is good for us it

759
00:35:00,839 --> 00:35:05,520
might not be relevant for developers

760
00:35:02,790 --> 00:35:08,730
might not be relevant for the product

761
00:35:05,520 --> 00:35:10,890
teams build your own top 10 mitigations

762
00:35:08,730 --> 00:35:12,750
tell them what to fix rather than

763
00:35:10,890 --> 00:35:16,848
telling them that you have CSRF in your

764
00:35:12,750 --> 00:35:16,849
application tell them what should I do

765
00:35:17,270 --> 00:35:23,670
threat modeling can be the brains of SS

766
00:35:20,910 --> 00:35:26,190
DLC process and that visibility can be

767
00:35:23,670 --> 00:35:29,339
achieved by a tool something like thread

768
00:35:26,190 --> 00:35:31,920
surfing right it helps you maintaining

769
00:35:29,339 --> 00:35:34,190
the record of your residual risk if you

770
00:35:31,920 --> 00:35:36,619
remember during the balancing risk

771
00:35:34,190 --> 00:35:39,200
we talked about how you can identify the

772
00:35:36,619 --> 00:35:40,670
existing risk that existing risk I know

773
00:35:39,200 --> 00:35:44,089
the traditional way of threat modeling

774
00:35:40,670 --> 00:35:46,309
is we write I think 40 50 60 page worth

775
00:35:44,089 --> 00:35:48,500
document and just hand it over to the

776
00:35:46,309 --> 00:35:51,260
developer teams how do we keep track of

777
00:35:48,500 --> 00:35:53,869
it so we need some tools like thread

778
00:35:51,260 --> 00:35:56,390
surfing that helps us in creating and

779
00:35:53,869 --> 00:35:59,299
maintaining those records and that is

780
00:35:56,390 --> 00:36:01,069
how we'll be able to fit in well with

781
00:35:59,299 --> 00:36:03,559
the agile world we'll be able to

782
00:36:01,069 --> 00:36:08,290
identify the residual risk from each and

783
00:36:03,559 --> 00:36:10,970
every step and last the most important

784
00:36:08,290 --> 00:36:13,849
adapt threat modeling framework which is

785
00:36:10,970 --> 00:36:16,689
best suited to your organization which

786
00:36:13,849 --> 00:36:20,839
is good for your customers rather than

787
00:36:16,690 --> 00:36:22,790
following a standard white paper that

788
00:36:20,839 --> 00:36:26,599
tells you what kind of threats your

789
00:36:22,790 --> 00:36:28,970
organization has rather than that you

790
00:36:26,599 --> 00:36:30,290
come up with your own threats what are

791
00:36:28,970 --> 00:36:33,950
the biggest challenges that you are

792
00:36:30,290 --> 00:36:37,849
facing and the pse model the pse

793
00:36:33,950 --> 00:36:39,740
approach is flexible it's not a new way

794
00:36:37,849 --> 00:36:42,440
of threat modeling it just gives you an

795
00:36:39,740 --> 00:36:44,089
approach that you all can go back and

796
00:36:42,440 --> 00:36:46,660
create your own click modeling framework

797
00:36:44,089 --> 00:36:49,400
in your organization and that is how you

798
00:36:46,660 --> 00:36:51,740
excel in your program and that is how

799
00:36:49,400 --> 00:36:55,069
you can bring out the maximum benefit

800
00:36:51,740 --> 00:36:57,589
from it with that I'd like to conclude

801
00:36:55,069 --> 00:36:59,359
my presentation thank you very much if

802
00:36:57,589 --> 00:37:02,000
you have any questions feel free to

803
00:36:59,359 --> 00:37:04,009
shoot me an email reach out to me I

804
00:37:02,000 --> 00:37:05,990
think we still have a couple of minutes

805
00:37:04,010 --> 00:37:09,220
so I can take some of the questions if

806
00:37:05,990 --> 00:37:09,220
you have yes

807
00:37:22,210 --> 00:38:03,770
yes I know so okay how do you mean ten

808
00:38:00,980 --> 00:38:05,270
the consistency right exactly that's a

809
00:38:03,770 --> 00:38:07,850
very valid question and that is one of

810
00:38:05,270 --> 00:38:10,400
the biggest challenges that we have with

811
00:38:07,850 --> 00:38:12,860
threat modeling frameworks we have to

812
00:38:10,400 --> 00:38:15,980
have a consistency throughout your

813
00:38:12,860 --> 00:38:18,800
threat modeling process now the way we

814
00:38:15,980 --> 00:38:21,830
define these standards we're all aligned

815
00:38:18,800 --> 00:38:23,600
to your inclusive policies right now if

816
00:38:21,830 --> 00:38:25,790
your InfoSec policy has to have a

817
00:38:23,600 --> 00:38:27,980
JavaScript protection with sub resource

818
00:38:25,790 --> 00:38:30,170
integrity check of course I agree with

819
00:38:27,980 --> 00:38:31,880
your point that some of you might feel

820
00:38:30,170 --> 00:38:34,040
that since you're adding an integrity

821
00:38:31,880 --> 00:38:35,480
hash your JavaScript should this be a

822
00:38:34,040 --> 00:38:38,810
cryptographic control rather than a

823
00:38:35,480 --> 00:38:41,480
browser security right but then you

824
00:38:38,810 --> 00:38:43,070
define your policy then when you're

825
00:38:41,480 --> 00:38:44,870
actually creating your standards on top

826
00:38:43,070 --> 00:38:47,060
of your policy this is where you

827
00:38:44,870 --> 00:38:49,490
actually define the threats that are

828
00:38:47,060 --> 00:38:52,549
actually covered under this right so

829
00:38:49,490 --> 00:38:54,979
browser security should be covering mage

830
00:38:52,550 --> 00:38:57,290
card attack your browser security should

831
00:38:54,980 --> 00:39:00,170
be covering CSV related recommendations

832
00:38:57,290 --> 00:39:02,000
right and that is how how stringent you

833
00:39:00,170 --> 00:39:04,880
actually create your standards and your

834
00:39:02,000 --> 00:39:07,100
policies and your controls that is what

835
00:39:04,880 --> 00:39:09,920
is going to define how consistent your

836
00:39:07,100 --> 00:39:11,569
threat modeling is across like you've

837
00:39:09,920 --> 00:39:13,550
been doing it for five years you want to

838
00:39:11,570 --> 00:39:15,500
make sure the consistency is maintained

839
00:39:13,550 --> 00:39:17,000
and this is how you actually do it right

840
00:39:15,500 --> 00:39:19,970
in the early phase when you're actually

841
00:39:17,000 --> 00:39:22,670
defining the standards right and above

842
00:39:19,970 --> 00:39:24,350
all this is something that is the sub

843
00:39:22,670 --> 00:39:26,240
resource integrity check is more like a

844
00:39:24,350 --> 00:39:28,220
browser feature that the browser is

845
00:39:26,240 --> 00:39:29,930
giving out to you this is not that the

846
00:39:28,220 --> 00:39:31,910
browser is going to hash in JavaScript

847
00:39:29,930 --> 00:39:34,038
for you but no it's something that

848
00:39:31,910 --> 00:39:35,779
has that you add so that the browser can

849
00:39:34,039 --> 00:39:39,559
validate when the JavaScript is loading

850
00:39:35,780 --> 00:39:41,839
on the page hash matches and boom it

851
00:39:39,559 --> 00:39:44,240
actually loads the page loads the

852
00:39:41,839 --> 00:39:45,828
JavaScript on your page so that is the

853
00:39:44,240 --> 00:39:58,729
whole concept behind the browser

854
00:39:45,829 --> 00:40:01,369
security stuff okay so these standards

855
00:39:58,730 --> 00:40:03,349
are very generic standards they can be

856
00:40:01,369 --> 00:40:06,500
utilized right away but my

857
00:40:03,349 --> 00:40:09,260
recommendation to everyone is to check

858
00:40:06,500 --> 00:40:11,059
with your own InfoSec policy most of

859
00:40:09,260 --> 00:40:12,740
them will align with your InfoSec policy

860
00:40:11,059 --> 00:40:14,750
but there might be as I mentioned in the

861
00:40:12,740 --> 00:40:16,609
beginning and InfoSec policy for a

862
00:40:14,750 --> 00:40:18,740
manufacturing company would be different

863
00:40:16,609 --> 00:40:20,990
from an InfoSec policy for an e-commerce

864
00:40:18,740 --> 00:40:22,819
company right an e-commerce company

865
00:40:20,990 --> 00:40:26,118
wants to look more into browsers stuff

866
00:40:22,819 --> 00:40:27,589
more into the site related software as a

867
00:40:26,119 --> 00:40:29,900
manufacturing company might have some

868
00:40:27,589 --> 00:40:31,849
other intercept policy so the standards

869
00:40:29,900 --> 00:40:33,650
that you saw can actually very well

870
00:40:31,849 --> 00:40:35,510
apply to most of the organizations in

871
00:40:33,650 --> 00:40:37,220
Prosek policy but if there are any more

872
00:40:35,510 --> 00:40:39,740
that these standards haven't been

873
00:40:37,220 --> 00:40:44,740
covering I would recommend you to add or

874
00:40:39,740 --> 00:40:46,669
subtract as per your own enforcer policy

875
00:40:44,740 --> 00:40:50,890
yeah exactly

876
00:40:46,670 --> 00:40:50,890
thank you yeah

877
00:40:59,960 --> 00:41:05,760
no so-so so how you do threat modeling

878
00:41:03,420 --> 00:41:07,470
is still the manual process in my

879
00:41:05,760 --> 00:41:09,510
opinion in my personal opinion I don't

880
00:41:07,470 --> 00:41:12,598
believe that the the threat modeling

881
00:41:09,510 --> 00:41:14,040
should be automated because one of the

882
00:41:12,599 --> 00:41:15,900
categories that I talked about is the

883
00:41:14,040 --> 00:41:18,740
business logic of use case threat

884
00:41:15,900 --> 00:41:21,510
modeling team is the one that requires

885
00:41:18,740 --> 00:41:23,669
very maximum amount of security mindset

886
00:41:21,510 --> 00:41:26,490
because you are the ones who are

887
00:41:23,670 --> 00:41:28,920
actually foreseeing the threats I'm not

888
00:41:26,490 --> 00:41:31,529
sure this we have a sophisticated

889
00:41:28,920 --> 00:41:33,299
automation at this place in the industry

890
00:41:31,530 --> 00:41:35,490
where actually that can automatically

891
00:41:33,299 --> 00:41:38,130
foresee based on some information so

892
00:41:35,490 --> 00:41:39,808
this is just an information the tool

893
00:41:38,130 --> 00:41:43,829
will just give you some prerequisites

894
00:41:39,809 --> 00:41:45,599
some initial prioritization of an

895
00:41:43,829 --> 00:41:48,329
application that will like just give you

896
00:41:45,599 --> 00:41:50,309
how critical this is how high-risk it is

897
00:41:48,329 --> 00:41:52,950
hey you are doing this threat modeling

898
00:41:50,309 --> 00:41:55,109
which already has five pin bugs from the

899
00:41:52,950 --> 00:41:56,640
previous cycle these information is what

900
00:41:55,109 --> 00:41:58,770
you're going to have and that is going

901
00:41:56,640 --> 00:42:00,058
to help you when you perform threat

902
00:41:58,770 --> 00:42:07,319
modeling but of course threat modeling

903
00:42:00,059 --> 00:42:09,780
still is a manual process yeah

904
00:42:07,319 --> 00:42:11,640
so those things yeah these things will

905
00:42:09,780 --> 00:42:14,880
be available in tool so the tool is

906
00:42:11,640 --> 00:42:16,710
currently as you can see in this one

907
00:42:14,880 --> 00:42:19,920
where the PSE model is actually embedded

908
00:42:16,710 --> 00:42:21,750
into the engine so your PSE model which

909
00:42:19,920 --> 00:42:24,089
you create will be embedded into the

910
00:42:21,750 --> 00:42:26,549
into the engine and and the portal will

911
00:42:24,089 --> 00:42:28,200
give out will help you determine where

912
00:42:26,549 --> 00:42:29,790
you want to apply browser security where

913
00:42:28,200 --> 00:42:31,990
you want to apply configuration

914
00:42:29,790 --> 00:42:35,230
management

915
00:42:31,990 --> 00:42:35,229
[Music]

916
00:42:48,740 --> 00:42:55,439
so I think some of the previous threat

917
00:42:51,720 --> 00:42:58,560
modeling projects by OS is something

918
00:42:55,440 --> 00:43:01,109
like red dragon and stuff which you

919
00:42:58,560 --> 00:43:03,570
which is more like focused on you

920
00:43:01,109 --> 00:43:05,430
performing threat modeling right but it

921
00:43:03,570 --> 00:43:09,240
actually doesn't give you whole

922
00:43:05,430 --> 00:43:13,230
end-to-end process for this just the

923
00:43:09,240 --> 00:43:15,149
engine exactly so so the reason why I

924
00:43:13,230 --> 00:43:18,089
called it a wasp a strict modeling is

925
00:43:15,150 --> 00:43:20,790
because there's a heavy dependency on

926
00:43:18,089 --> 00:43:22,320
wasps top ten the mitigations that are

927
00:43:20,790 --> 00:43:24,029
provided by wasps there is a heavy

928
00:43:22,320 --> 00:43:26,250
dependency on the way the risk is

929
00:43:24,030 --> 00:43:30,210
actually evaluated which is also based

930
00:43:26,250 --> 00:43:31,710
on wasps framework so that is why we

931
00:43:30,210 --> 00:43:33,960
came up with wasps threat modeling

932
00:43:31,710 --> 00:43:35,910
approach but again this is more like an

933
00:43:33,960 --> 00:44:03,900
approach which can be embedded with I

934
00:43:35,910 --> 00:44:05,970
think if you integrate this with no so I

935
00:44:03,900 --> 00:44:08,099
think to answer your question the best

936
00:44:05,970 --> 00:44:10,830
approach would be a combination of

937
00:44:08,099 --> 00:44:12,660
threat dragon along with this that could

938
00:44:10,830 --> 00:44:15,569
give you the full end-to-end picture

939
00:44:12,660 --> 00:44:18,118
because what this tool doesn't cover is

940
00:44:15,570 --> 00:44:21,540
something that red thread dragon does so

941
00:44:18,119 --> 00:44:22,060
they both complement each other okay

942
00:44:21,540 --> 00:44:26,520
thank you

943
00:44:22,060 --> 00:44:26,520
[Applause]

