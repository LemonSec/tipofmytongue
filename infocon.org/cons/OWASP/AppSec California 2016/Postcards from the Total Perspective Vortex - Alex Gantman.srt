1
00:00:18,460 --> 00:00:32,029
so that's my twitter handle and I'll be
talking about what I've seen a little

2
00:00:32,029 --> 00:00:37,140
perspective vortex before we get started
want to get a sense for the kind of the

3
00:00:37,140 --> 00:00:40,879
tenure distribution in the room so how
many of you have been in the industry

4
00:00:40,879 --> 00:00:46,680
for more than five years 10 years 15
years

5
00:00:46,680 --> 00:00:50,489
alright so that there's this is more
gonna be less words of wisdom or group

6
00:00:50,489 --> 00:00:51,260
therapy

7
00:00:51,260 --> 00:01:00,079
yes that's right first off a little
about my job so I work at Qualcomm

8
00:01:00,079 --> 00:01:05,349
Qualcomm makes designs and sells
semiconductors primarily for the mobile

9
00:01:05,349 --> 00:01:12,199
industry so so primarily so pretty much
all of your smartphones will have you

10
00:01:12,200 --> 00:01:17,060
there Snapdragon processor or modem from
Qualcomm inside of it to fairly large

11
00:01:17,060 --> 00:01:21,440
company about 30,000 people maybe twelve
thousand software engineers 8,000

12
00:01:21,440 --> 00:01:28,289
hardware engineers are so I work in the
product security team that's our logo it

13
00:01:28,290 --> 00:01:32,240
has sharks with laser beings which don't
need explanation and has a crooked

14
00:01:32,240 --> 00:01:38,548
profitable which has a long story that I
don't have time to go into but suffice

15
00:01:38,549 --> 00:01:43,969
it to say the crocodiles were bred to
control the out of control

16
00:01:43,969 --> 00:01:49,860
shark population and the sharp Falcons
were introduced to control the world

17
00:01:49,860 --> 00:01:54,719
pigeons and that's as much as I'm gonna
say about it so I i've been in there

18
00:01:54,719 --> 00:02:02,259
product security team for 15 years I
started working on security before

19
00:02:02,259 --> 00:02:07,479
before there was a product security team
joined as a sort of entry level engineer

20
00:02:07,479 --> 00:02:12,239
worked on risk assessments threat
modeling static analysis of protocol

21
00:02:12,239 --> 00:02:18,000
design all sorts of stuff today lead the
team of just over 50 people and we're

22
00:02:18,000 --> 00:02:22,579
responsible for the security of our
focus products so a little bit more

23
00:02:22,579 --> 00:02:24,319
about the product

24
00:02:24,319 --> 00:02:28,099
the core of the business as I mentioned
this mobile computing the processors in

25
00:02:28,099 --> 00:02:32,540
the software they go on to it but
there's also networking so wifi routers

26
00:02:32,540 --> 00:02:39,569
the wifi cards in your laptops smart
homes wearables automotive telematics

27
00:02:39,569 --> 00:02:46,458
and infotainment units moving into ECU's
with train cars etcetera smart cities

28
00:02:46,459 --> 00:02:50,260
internet of everything which is I guess
everything that's not already captured

29
00:02:50,260 --> 00:02:52,060
by those other categories

30
00:02:52,060 --> 00:02:59,129
light bulbs pacemakers and then there's
some service offerings on top of that an

31
00:02:59,129 --> 00:03:06,138
education and health care so very broad
range of technologies a broad range of

32
00:03:06,139 --> 00:03:16,489
use cases very broad range of threat
models so when I was invited to speak

33
00:03:16,489 --> 00:03:21,629
and given free rein on what to talk
about I started thinking about what

34
00:03:21,629 --> 00:03:28,000
would be interesting to share after 15
years on the job of the things that i

35
00:03:28,000 --> 00:03:32,870
really wanna share can I share publicly
and you know we should the things I can

36
00:03:32,870 --> 00:03:38,479
talk about it without crying into the
fetal position and sort of as I was

37
00:03:38,479 --> 00:03:44,180
thinking about it and talking to friends
at work one theme kept coming over

38
00:03:44,180 --> 00:03:49,019
kept coming up over and over again and
that was complexity this is supposed to

39
00:03:49,019 --> 00:03:58,229
be a picture of the universe there is a
real complex problems that we come

40
00:03:58,229 --> 00:04:04,849
across in this job in multiple domains
not just technology and a lot of it is

41
00:04:04,849 --> 00:04:10,000
really fascinating so that's what I
decided to talk about and that's why

42
00:04:10,000 --> 00:04:14,840
title the talk perspective postcards
from the total perspective for tix for

43
00:04:14,840 --> 00:04:18,988
those of you not familiar with
Hitchhiker's Guide to the Galaxy the

44
00:04:18,988 --> 00:04:25,219
total perspective for tax was the door
is the invention that allows the subject

45
00:04:25,219 --> 00:04:30,680
to see the full complexity and enormity
of the universe and to perceive their

46
00:04:30,680 --> 00:04:34,800
insignificance in perspective

47
00:04:34,800 --> 00:04:43,069
if there's one point I want to make in
this presentation and that's to succeed

48
00:04:43,069 --> 00:04:47,449
in our line of business line of work
when you to be able to understand and

49
00:04:47,449 --> 00:04:51,080
navigate complexity across technology
business ecosystem and corporate culture

50
00:04:51,080 --> 00:05:02,229
I you know there are no purely technical
jobs in our line of work at least that's

51
00:05:02,229 --> 00:05:06,270
what I do I used to think that they're
purely technical roles but I don't

52
00:05:06,270 --> 00:05:15,919
anymore he's a CTO I'll go into a little
bit of that later but if you are in a

53
00:05:15,919 --> 00:05:22,280
position where you can focus exclusively
on technical parts it is because

54
00:05:22,280 --> 00:05:26,239
somebody else's taking care of the other
aspects for you and I hope you are

55
00:05:26,240 --> 00:05:29,289
sufficiently appreciate as to them for
that

56
00:05:29,289 --> 00:05:37,068
alright so complex in technology let me
start with the SOC that's in the phone

57
00:05:37,069 --> 00:05:43,139
so I wanted to bring a sample but I
didn't imagine that you know that chip

58
00:05:43,139 --> 00:05:49,849
is about the size of a microSD card
right so this is kind of a picture of

59
00:05:49,849 --> 00:05:54,729
one of the recent ones blown up and the
different components superimposed on it

60
00:05:54,729 --> 00:06:04,628
and what I want to explain today's that
chip is not really a processor a modern

61
00:06:04,629 --> 00:06:10,360
SoC is really a network of systems on a
chip writes each of those boxes as a

62
00:06:10,360 --> 00:06:13,750
separate process of the separate running
on it

63
00:06:13,750 --> 00:06:20,259
many cases like a full blown OS you know
many of them running multi million line

64
00:06:20,259 --> 00:06:26,210
many millions lines of code on them so
the CPU one up on top that's the you

65
00:06:26,210 --> 00:06:30,830
know that's the multi-core CPU the
grants high-level operating systems like

66
00:06:30,830 --> 00:06:34,340
Android whatever in the apps but then
they're all these other systems right

67
00:06:34,340 --> 00:06:38,690
the modem and the connectivity and
engine in the GPU and so on and all of

68
00:06:38,690 --> 00:06:44,270
them talk to each other in the use
shared resources on this network

69
00:06:44,270 --> 00:06:48,109
and we have to worry about you know what
happens if you get go to cash in on one

70
00:06:48,110 --> 00:06:52,990
of them can you jump laterally and
resources from one of the other boxes

71
00:06:52,990 --> 00:07:01,940
picture how do you properly set up
access control and so on I was recently

72
00:07:01,940 --> 00:07:08,780
sitting in a code review for you know
for one of the modules and I realized

73
00:07:08,780 --> 00:07:12,419
that I needed to get a better
understanding for how the memory

74
00:07:12,420 --> 00:07:19,130
subsystem was working so I decided to
spend more time and you know talk to our

75
00:07:19,130 --> 00:07:24,250
experts and figure out how does a load
instruction actually work load value

76
00:07:24,250 --> 00:07:27,910
address speed to register are you don't
have the high-level understanding that

77
00:07:27,910 --> 00:07:31,820
we all have from computer architecture
class III mmm you and catches and so on

78
00:07:31,820 --> 00:07:39,430
but many weeks later I realized that I
understand very very little about how

79
00:07:39,430 --> 00:07:45,310
computers work it is the amount of
complexity involved amount of functional

80
00:07:45,310 --> 00:07:49,000
units that are involved in figuring out
which actual physical location to look

81
00:07:49,000 --> 00:07:54,660
up and you know figuring out whether the
current execution context has the access

82
00:07:54,660 --> 00:07:59,410
rights to that location is insane I
could probably spend this entire

83
00:07:59,410 --> 00:08:03,740
presentation just a load instruction and
only provided very cursory overview of

84
00:08:03,740 --> 00:08:12,430
it and and that's that's example of
complexity serve just the chip level

85
00:08:12,430 --> 00:08:18,940
right you can go you can go lower down
into the gates on the circuit level down

86
00:08:18,940 --> 00:08:25,090
into silicon security issues at that
level you can go up to board level when

87
00:08:25,090 --> 00:08:29,580
you introduce you know different
interfaces have to deal with the

88
00:08:29,580 --> 00:08:34,549
security of the cellular network and
then you get to the android framework in

89
00:08:34,549 --> 00:08:35,549
the Alps

90
00:08:35,549 --> 00:08:41,079
most of this conference is about the
apps and even within this slice there's

91
00:08:41,080 --> 00:08:45,830
incredible complexity now imagine
scaling up across all of those layers of

92
00:08:45,830 --> 00:08:50,340
the users and some users are more high
risk than other users

93
00:08:50,340 --> 00:09:01,480
and and pretty soon and this is just
have to figure how is it different for

94
00:09:01,480 --> 00:09:06,900
pacemakers or how is it different for
light bulbs how's it different for cars

95
00:09:06,900 --> 00:09:25,470
so what do we do when faced with complex
in technology abstractions

96
00:09:25,470 --> 00:09:32,510
abstractions so abstraction allows us to
deal with complexity essentially hiding

97
00:09:32,510 --> 00:09:38,340
it and that's for both its promise and
the curse and has certainly brought a

98
00:09:38,340 --> 00:09:41,570
cyst layers of attractions layers of
abstraction become boundaries of

99
00:09:41,570 --> 00:09:44,590
confidence right i mean that's what
they're meant to do they're meant to

100
00:09:44,590 --> 00:09:49,840
keep the complexity of hidden from you
so once you have the extraction you no

101
00:09:49,840 --> 00:09:55,790
longer understand how this thing really
works so you know kind of to have a very

102
00:09:55,790 --> 00:10:00,630
simplified graphical things here you
have a very nice indeed abstraction you

103
00:10:00,630 --> 00:10:04,790
have reality that's not quite so nice in
need has more complex rounded corners

104
00:10:04,790 --> 00:10:07,949
and there's a little bit of Delta
between them there's there's a very

105
00:10:07,950 --> 00:10:17,050
technical term for it and security for
the Delta between abstraction or so and

106
00:10:17,050 --> 00:10:20,120
if what you see is sort of from the
defenders point of view from the system

107
00:10:20,120 --> 00:10:23,450
builders point of view you have this
nice solid brick wall made out of solid

108
00:10:23,450 --> 00:10:28,320
abstractions and from the attack respond
if you have a wall full of holes I think

109
00:10:28,320 --> 00:10:33,600
pretty much every vulnerability type or
exploit type of can think of

110
00:10:33,600 --> 00:10:38,150
falls into this category there's
something the attacker understands about

111
00:10:38,150 --> 00:10:45,520
how the system really works at the
defender forgot whether the defense so

112
00:10:45,520 --> 00:10:55,090
very very simple technical question so
assuming no binary this is going to be a

113
00:10:55,090 --> 00:10:59,690
binary question I made a simple as
possible in me to just wanted it now

114
00:10:59,690 --> 00:11:10,410
what is the range of values that can be
represented by one bit and anybody

115
00:11:10,410 --> 00:11:29,569
021 021 nobody gets negative 0 alright
so here's a hint so what is the range of

116
00:11:29,569 --> 00:11:41,170
values minus 120 so if you have a one
hit and struck the whatever it can never

117
00:11:41,170 --> 00:11:47,729
be one if you compare that value to 1 it
will fail because it can be minus 10 and

118
00:11:47,730 --> 00:12:00,360
when you compare it to one this was from
actually this was a little bit more time

119
00:12:00,360 --> 00:12:03,980
on this was years ago when we're still
running as opposed to more modern static

120
00:12:03,980 --> 00:12:07,660
analysis tools and Lynn complained and
said look you know the value that you're

121
00:12:07,660 --> 00:12:11,719
testing you know comparing to one can
never be 11 is outside the range for

122
00:12:11,720 --> 00:12:17,949
this view how can one be outside the
range for anything right thing it took

123
00:12:17,949 --> 00:12:30,029
us awhile but with the right so I guess
how do we deal with it I think the main

124
00:12:30,029 --> 00:12:34,730
tool is getting really good people so we
try to hire people who are strong broad

125
00:12:34,730 --> 00:12:39,899
generalist insecurity but then have our
expert class world-class experts and

126
00:12:39,899 --> 00:12:46,250
some very narrow niche complement each
other and they can rely on each other's

127
00:12:46,250 --> 00:12:47,360
expertise

128
00:12:47,360 --> 00:12:53,790
people that are able to pierce through
multiple layers of abstraction know when

129
00:12:53,790 --> 00:13:00,269
there may be relying on over simplified
assumptions and no one to the other one

130
00:13:00,269 --> 00:13:06,829
and many people is reverse engineering
think as the complexity of our systems

131
00:13:06,829 --> 00:13:13,500
increases we are more than ever reliant
on reverse engineering to tell us what

132
00:13:13,500 --> 00:13:18,079
these systems are really capable there
are some properties that are going to be

133
00:13:18,079 --> 00:13:22,029
emerging there are not going to be clear
from the designer from the source code

134
00:13:22,029 --> 00:13:23,220
from anything else

135
00:13:23,220 --> 00:13:32,569
and reverse engineering is how we know
what our systems move onto complexity in

136
00:13:32,569 --> 00:13:39,120
the business business ecosystem alright
so this is where I explain why you can't

137
00:13:39,120 --> 00:13:44,100
focus on the technology so you all know
that you know you can't both security on

138
00:13:44,100 --> 00:13:48,300
you have to build it if you're gonna
build it in you haven't been building in

139
00:13:48,300 --> 00:13:54,319
before you have to change how your
products are being built and how they're

140
00:13:54,319 --> 00:13:58,670
being configured and how they're being
sold and deployed etcetera and in order

141
00:13:58,670 --> 00:14:03,259
to change all of that you have to
understand how all of their works are

142
00:14:03,259 --> 00:14:09,290
you have to understand who buy your
products customers are partners and

143
00:14:09,290 --> 00:14:11,699
suppliers you have what are their
interest in that they are lined with

144
00:14:11,699 --> 00:14:22,399
your source jump to this one sorry so
most of you or may mean many of you

145
00:14:22,399 --> 00:14:26,079
probably know some version of this
cartoon right it's a project management

146
00:14:26,079 --> 00:14:33,250
cartoon you know how the customer
explained it was understood how was

147
00:14:33,250 --> 00:14:38,000
implemented was sold and really wanted
so I was looking at it

148
00:14:38,000 --> 00:14:45,540
well you know not a lot of these cells
map onto the software development

149
00:14:45,540 --> 00:14:49,459
lifecycle stages you know and we talked
about secure development life cycle in

150
00:14:49,459 --> 00:14:54,910
touch points at the different product
looks so different in each of those

151
00:14:54,910 --> 00:15:00,769
which were so here's the security
version of it right so there are some

152
00:15:00,769 --> 00:15:03,839
people that was requested and you kind
of do a high-level threat model in your

153
00:15:03,839 --> 00:15:07,120
head you know that doesn't sound too bad
but we should probably a sign somebody

154
00:15:07,120 --> 00:15:11,509
to look at it when you request
documentation you get nothing you know

155
00:15:11,509 --> 00:15:15,410
you finally get to analyze the design
and you propose the medications because

156
00:15:15,410 --> 00:15:22,410
you know the one piece of wood is not
strong enough to make him put three men

157
00:15:22,410 --> 00:15:26,639
eventually you know the code is complete
and they want you to review it and you

158
00:15:26,639 --> 00:15:29,730
know the team that could use the code to
ever talk to the people that review the

159
00:15:29,730 --> 00:15:35,440
design do they know what teacher was
requested in the first place

160
00:15:35,440 --> 00:15:41,180
the code and maybe even the bugs are
fixed on apprentice the final product

161
00:15:41,180 --> 00:15:44,010
and the configuration that you were
given to paint us has all the features

162
00:15:44,010 --> 00:15:52,300
that you care about turned up so clean
you know you have the deployment and

163
00:15:52,300 --> 00:15:58,010
then Sammy comes to block her talks
about your product and then after that

164
00:15:58,010 --> 00:16:01,680
you really take security seriously and
all the meanwhile your competitor is

165
00:16:01,680 --> 00:16:12,459
selling something so crazily insecure
you don't even nobody cares so how well

166
00:16:12,460 --> 00:16:17,620
do you know your software supply and
distribution chain right this is kind of

167
00:16:17,620 --> 00:16:20,600
the cradle-to-grave for developers
keyboard to the landfill

168
00:16:20,600 --> 00:16:26,930
love your software do you know what
ideas are being used

169
00:16:26,930 --> 00:16:31,180
revision control system is being used to
know how to use it are you sure they're

170
00:16:31,180 --> 00:16:32,579
not launching stuff

171
00:16:32,580 --> 00:16:39,570
shipping stuff from developer sandbox
ranches or old revisions you know what

172
00:16:39,570 --> 00:16:43,580
the release management process like test
infrastructure

173
00:16:43,580 --> 00:16:46,420
landfill and you know for some of us it
doesn't under the landfill for those

174
00:16:46,420 --> 00:16:51,449
companies that have to worry about kind
of grey market recycling and landfill in

175
00:16:51,450 --> 00:16:55,710
here at three developers keyboard
because I have to worry about product

176
00:16:55,710 --> 00:17:03,940
requirements and so on so let me talk
about if you kind of motivating examples

177
00:17:03,940 --> 00:17:05,439
so few years ago

178
00:17:05,439 --> 00:17:12,030
mattel had a problem with black paint on
their toys so European that's the case

179
00:17:12,030 --> 00:17:17,339
down to the bottom one of their European
retailers that some independent testing

180
00:17:17,339 --> 00:17:23,429
and notified them that they detect it
led on paint or let intent on their toys

181
00:17:23,430 --> 00:17:26,970
within a week Mattel identified the

182
00:17:26,970 --> 00:17:32,640
supplier in China that was using
contaminated pain within one more week

183
00:17:32,640 --> 00:17:37,070
they identified a track down and pulled
from store shelves and from warehouses

184
00:17:37,070 --> 00:17:46,280
all tainted products that was in my mind
remarkably efficient now too by the way

185
00:17:46,280 --> 00:17:50,250
they deserve a lot of credit because
they went out of their way to prevent

186
00:17:50,250 --> 00:17:54,720
something like this from happening they
were actually providing let free pain to

187
00:17:54,720 --> 00:17:59,590
the supplier who was then you know to
use on their toys he was reselling it

188
00:17:59,590 --> 00:18:11,158
and buying cheaper pain can you do that
i mean if your property is a kind of web

189
00:18:11,159 --> 00:18:17,919
properties if you actually shipping
product brands on systems that you don't

190
00:18:17,919 --> 00:18:22,159
own can you do that you know given you
know when you when the bug report comes

191
00:18:22,159 --> 00:18:27,580
in and you know this device has this
book can you trace it back to you know

192
00:18:27,580 --> 00:18:32,490
what we call patient zero the very first
time that bug was that bug appears in

193
00:18:32,490 --> 00:18:36,799
your revision control system and from
there can you trace of forward to all

194
00:18:36,799 --> 00:18:40,240
the all the product lines all the
branches all the products in the field

195
00:18:40,240 --> 00:18:45,130
right now have this book your property
to fix them and who are you relying on

196
00:18:45,130 --> 00:18:49,850
that right if the bug was provided by a
supplier of yours how much visibility do

197
00:18:49,850 --> 00:18:53,389
you have into their supply chain and you
know how much accountability do they

198
00:18:53,390 --> 00:18:57,070
have to you you know will they have to
fix it when you pointed out on the

199
00:18:57,070 --> 00:19:02,330
distributor site same thing you know if
you're relying on somebody else we don't

200
00:19:02,330 --> 00:19:04,590
sell the final product to the consumer

201
00:19:04,590 --> 00:19:11,030
we have to give the pics to device
manufacturer will be propagated forward

202
00:19:11,030 --> 00:19:21,940
the other the other inspirational taste
here was on how researchers started

203
00:19:21,940 --> 00:19:30,279
measuring research in cities so you know
before you know they would do

204
00:19:30,279 --> 00:19:35,190
would ask people they would do random
samples then eventually have somebody

205
00:19:35,190 --> 00:19:40,200
had the bright idea you can just go to
the sewage treatment plants and test

206
00:19:40,200 --> 00:19:44,869
their you know everybody actually use
the bathroom and it all goes out there

207
00:19:44,869 --> 00:19:51,039
and see if you could get very accurate
citywide information on what's actually

208
00:19:51,039 --> 00:19:59,330
happening so we tried to take the
following approach I mean we tried to

209
00:19:59,330 --> 00:20:04,109
imitate this approach in many cases it's
great to intersect our development

210
00:20:04,109 --> 00:20:08,918
pipeline at different stages but don't
forget to actually look at what comes

211
00:20:08,919 --> 00:20:15,499
out right actually go out and buy
commercial version of the device and see

212
00:20:15,499 --> 00:20:18,159
how it ended up being configured

213
00:20:18,159 --> 00:20:29,679
features are turned on what the builders
on it

214
00:20:29,679 --> 00:20:37,639
corporate culture

215
00:20:37,639 --> 00:20:45,428
the the first point I want to me as I
want to encourage you to stay away from

216
00:20:45,429 --> 00:20:48,829
the US versus them attitude where is the
security people in them or the

217
00:20:48,829 --> 00:20:53,649
developers are business people or
anybody else write it generally doesn't

218
00:20:53,649 --> 00:21:00,799
work well almost always you have the
same shirt gold you all want the company

219
00:21:00,799 --> 00:21:06,369
to succeed you may disagree on what that
means you know what that requires in

220
00:21:06,369 --> 00:21:14,099
this particular instance but you do have
a shared overarching goal and don't

221
00:21:14,099 --> 00:21:18,450
forget to treat everyone you interact
with both inside the company an outside

222
00:21:18,450 --> 00:21:19,509
with respect

223
00:21:19,509 --> 00:21:24,070
right there real people they have
families their concerns probably most of

224
00:21:24,070 --> 00:21:27,769
the stuff they worry about outside of
work is way more important than whatever

225
00:21:27,769 --> 00:21:36,239
issue you're discussing and the other
point here is the change takes time many

226
00:21:36,239 --> 00:21:47,129
years and it's easy to be misled by the
tipping point you see in other companies

227
00:21:47,129 --> 00:21:51,359
because it looks like the change came
suddenly to them yesterday they didn't

228
00:21:51,359 --> 00:21:55,349
care about security in you know today
launched a major security initiative but

229
00:21:55,349 --> 00:21:59,950
talk to people that worked there for 10
years leading up to that and ask them

230
00:21:59,950 --> 00:22:09,769
about all the sort of bodies that made
it possible so be patient

231
00:22:09,769 --> 00:22:16,450
know how to earn and spend political
capital know how to run and went to

232
00:22:16,450 --> 00:22:21,119
spend political capital you have to be
credible you have to know what you're

233
00:22:21,119 --> 00:22:25,689
actually talking about right you know
don't bluff don't hide behind your own

234
00:22:25,690 --> 00:22:36,320
credible you have to listen and convince
the people that you work with developers

235
00:22:36,320 --> 00:22:42,399
the development leads you understand
their position that you understand the

236
00:22:42,399 --> 00:22:46,489
constraints of their operating in
understand their position in the truth

237
00:22:46,490 --> 00:22:52,679
they have to believe the tribune
reasonable and then chances are not

238
00:22:52,679 --> 00:22:57,190
working security in your company you
care about security more than anybody

239
00:22:57,190 --> 00:23:00,040
else in the company or at least your
team fears about security more than any

240
00:23:00,040 --> 00:23:03,730
other team and that means when you're
talking about doing something for

241
00:23:03,730 --> 00:23:09,280
security you have to be always willing
to do more than your fair share if you

242
00:23:09,280 --> 00:23:12,649
are not willing to put in more than your
fair share then why you asking other

243
00:23:12,650 --> 00:23:13,570
people too

244
00:23:13,570 --> 00:23:24,230
now the the other side of political
capital is that you have to make sure

245
00:23:24,230 --> 00:23:29,630
not to forget why you're right there
will be times when you want to spend it

246
00:23:29,630 --> 00:23:33,640
right when you're fighting for an
important issue when you want somebody

247
00:23:33,640 --> 00:23:38,840
to take on significant risk and you want
them to trust you that this is the right

248
00:23:38,840 --> 00:23:45,659
thing when you make a big mistaken sort
of don't want it to be career-ending you

249
00:23:45,660 --> 00:23:56,429
know those are the reasons why you stock
up on political capital ahead of time

250
00:23:56,429 --> 00:24:09,179
how many people have you know go to look
at a bug and felt superior

251
00:24:09,179 --> 00:24:13,269
like I would never write code like that
how could somebody right to delete this

252
00:24:13,269 --> 00:24:18,289
how did we ever higher personal you know
they need a license to use a keyboard

253
00:24:18,289 --> 00:24:27,100
that ok so people didn't raise their
hands if you're much much better person

254
00:24:27,100 --> 00:24:34,320
than I am or you've never seen about so
once again so I want you to keep it up

255
00:24:34,320 --> 00:24:42,408
until you go and read this book rights
so the effect is a book about the

256
00:24:42,409 --> 00:24:48,369
Stanford Prison Experiment by the
scientists that conducted the experiment

257
00:24:48,369 --> 00:24:55,209
Stanford Prison Experiment if you're not
familiar with that was conducted in this

258
00:24:55,210 --> 00:25:04,789
seventies in Stanford was psychology
experiment they basically recruited

259
00:25:04,789 --> 00:25:08,970
random people mostly Stanford grad
students randomly assigned them into two

260
00:25:08,970 --> 00:25:13,779
groups prisoners and guards and the aim
was to run the experiment for two weeks

261
00:25:13,779 --> 00:25:17,490
to observe you know how people how
normal people behave in the prison said

262
00:25:17,490 --> 00:25:25,899
it had to be called off after five days
because the levels of abuse reached Abu

263
00:25:25,899 --> 00:25:35,408
Ghraib levels within that time and this
is like Stanford grad students they were

264
00:25:35,409 --> 00:25:41,019
more creative than other people would be
about and what was fascinating was so

265
00:25:41,019 --> 00:25:45,419
there there multiple listings here one
was that people play the role there are

266
00:25:45,419 --> 00:25:50,549
signs so it's not just that the guards
behaved as guards prisoners fell into

267
00:25:50,549 --> 00:25:54,789
the personal they had marked parole
hearings people broke down and cried and

268
00:25:54,789 --> 00:26:00,389
sort of asked for parole nobody ever
said I don't wanna play the game anymore

269
00:26:00,389 --> 00:26:06,918
like I'm out of the experiment so people
stayed in character

270
00:26:06,919 --> 00:26:11,889
ur and then the other because you know
civic this experiment and others like it

271
00:26:11,889 --> 00:26:18,998
where we were sort of repeated multiple
times everybody thinks that they would

272
00:26:18,999 --> 00:26:22,609
do something different situation in both
cases right people think they would

273
00:26:22,609 --> 00:26:26,070
never be as abusive as a guard and they
would think of their prisoner they would

274
00:26:26,070 --> 00:26:31,350
stand up to authority everybody behave
the same way in those roles rights if

275
00:26:31,350 --> 00:26:35,709
you think you would be a different kind
of developer you're deluding yourself in

276
00:26:35,710 --> 00:26:39,330
the same situation with the same release
pressures you would be doing the same

277
00:26:39,330 --> 00:26:45,289
thing i would be doing the same thing I
know that so if I find myself as a

278
00:26:45,289 --> 00:26:50,470
development Li tomorrow in this sort of
in the environment that I am in my code

279
00:26:50,470 --> 00:26:53,960
would be on-time more often than it
would be secure and it's not because I

280
00:26:53,960 --> 00:26:56,350
don't know it's not because i dont care
its

281
00:26:56,350 --> 00:27:03,178
that's what incentive system is
structured like the other lesson here is

282
00:27:03,179 --> 00:27:08,970
don't hide behind your badge right so
having a uniform having the sunglasses

283
00:27:08,970 --> 00:27:16,679
having the badge humanizes you an
anonymizer right and if you ever catch

284
00:27:16,679 --> 00:27:22,289
yourself or somebody in your teen
telling a developer you have to do this

285
00:27:22,289 --> 00:27:26,629
because that's the policy and they can't
actually explain why you know why this

286
00:27:26,629 --> 00:27:30,219
is the policy that's a huge red flag
right that's people just hiding behind

287
00:27:30,220 --> 00:27:34,149
the back they're not taking personal
responsibility for you know what they're

288
00:27:34,149 --> 00:27:44,369
asking people to do like you know I
don't pretend to understand roentgens

289
00:27:44,369 --> 00:27:55,988
hold it in this but this is the only
book I push on people

290
00:27:55,989 --> 00:28:06,970
psychology study done in princeton as
the Good Samaritan study of the summary

291
00:28:06,970 --> 00:28:11,409
of the abstract but basically I think
the subjects here are mostly seminary

292
00:28:11,409 --> 00:28:17,450
students they ask them to prepare a talk
and then rush across campus to deliver

293
00:28:17,450 --> 00:28:20,260
the talk on their way was a person

294
00:28:20,260 --> 00:28:24,760
addressed clutching his chest and they
measured how many people stopped to

295
00:28:24,760 --> 00:28:29,890
offer health most people didn't stop
some people had to step over the guy to

296
00:28:29,890 --> 00:28:34,670
get to where there is a prime some of
the subjects but asking them to prepare

297
00:28:34,670 --> 00:28:41,230
a talk on the parable of the Good
Samaritan had no effect the only the

298
00:28:41,230 --> 00:28:44,610
only variable that had any impact on
whether people in the likelihood of

299
00:28:44,610 --> 00:28:49,129
people offering help was how much time
they had to get to the building the more

300
00:28:49,130 --> 00:28:54,910
they were in a hurry the less likely
they were to help so think about that

301
00:28:54,910 --> 00:28:58,100
when you think about your developers
right it's not that they're not being

302
00:28:58,100 --> 00:29:03,750
preached to know if they're being asked
to you know most likely they're under a

303
00:29:03,750 --> 00:29:09,390
lot of pressure to ship coal on time so
you know preaching to them isn't gonna

304
00:29:09,390 --> 00:29:13,780
help figure out how to structure the
systemic forces how you need to make

305
00:29:13,780 --> 00:29:18,250
sure that incentives are properly
aligned in the doing the right thing is

306
00:29:18,250 --> 00:29:26,670
the is the easy thing and aligned with
their expected to do anyway and this is

307
00:29:26,670 --> 00:29:38,810
the last point I want to make friends
come and go but enemies accumulate so

308
00:29:38,810 --> 00:29:53,510
that's very being in the company for
almost 20 years so I think you know a

309
00:29:53,510 --> 00:29:58,310
lot of people have the storm in the
industry security evangelist that I

310
00:29:58,310 --> 00:30:02,360
never really quite like they think what
we do has a lot more to do with

311
00:30:02,360 --> 00:30:07,600
corporate anthropology in evangelism
right that's trying to understand the

312
00:30:07,600 --> 00:30:08,879
corporate culture

313
00:30:08,880 --> 00:30:13,200
you know how does it work what secret
what's not you know what are the

314
00:30:13,200 --> 00:30:19,860
important things to change in how to
change and preaching didn't at least for

315
00:30:19,860 --> 00:30:27,110
the environment that I am never really
worked out well so you know you have to

316
00:30:27,110 --> 00:30:30,610
know kind of crazy guy with the beard is
the high priest in which one is just

317
00:30:30,610 --> 00:30:32,159
crazy guy with a beard

318
00:30:32,160 --> 00:30:38,410
attention to what happened to last
person

319
00:30:38,410 --> 00:30:43,590
change right is there a VPS office
somewhere with heads mounted on the wall

320
00:30:43,590 --> 00:30:51,370
and and develop a broad network

321
00:30:51,370 --> 00:30:58,159
this might sound cynical but you need a
lot of human intelligence right you need

322
00:30:58,160 --> 00:31:01,730
to know what's going on in the company
what people are talking about what

323
00:31:01,730 --> 00:31:07,590
people are doing what pressures the
developers in the trenches are feeling

324
00:31:07,590 --> 00:31:13,179
you know what you get from PowerPoint
some reason so many layers of

325
00:31:13,180 --> 00:31:27,710
abstraction of reality I think back to
the universe so hopefully then depress

326
00:31:27,710 --> 00:31:29,650
you too much don't panic

327
00:31:29,650 --> 00:31:36,700
notion that there's no shortage of
challenger in challenging problems or

328
00:31:36,700 --> 00:31:44,660
opportunities to pursue them and I think
we prepare to fail repeatedly but hold

329
00:31:44,660 --> 00:31:47,540
on to the delusion that someday you will
succeed

330
00:31:47,540 --> 00:32:09,409
that's how I stay sane questions

331
00:32:09,410 --> 00:32:14,340
so because I spent all my time
essentially in the industry the same

332
00:32:14,340 --> 00:32:17,500
company people in you know they have
spent a lot of time in other companies

333
00:32:17,500 --> 00:32:21,560
this resonate as your experience totally
different same

