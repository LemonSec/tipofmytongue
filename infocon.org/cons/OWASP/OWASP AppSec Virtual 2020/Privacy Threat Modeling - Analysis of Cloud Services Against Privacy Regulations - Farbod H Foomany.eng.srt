1
00:00:01,120 --> 00:00:03,360
hello everyone good morning good evening

2
00:00:03,360 --> 00:00:05,759
good afternoon uh depending on where

3
00:00:05,759 --> 00:00:07,759
where and when you're watching this and

4
00:00:07,759 --> 00:00:11,200
thanks for um choosing this presentation

5
00:00:11,200 --> 00:00:13,120
i'm far both for money and i have many

6
00:00:13,120 --> 00:00:14,480
years of

7
00:00:14,480 --> 00:00:16,720
research experience at security compass

8
00:00:16,720 --> 00:00:18,240
and at

9
00:00:18,240 --> 00:00:21,359
in academia and also in industry

10
00:00:21,359 --> 00:00:24,000
and i'm taking a perk pro

11
00:00:24,000 --> 00:00:26,160
product manager of security research at

12
00:00:26,160 --> 00:00:27,840
security campus and previously i was

13
00:00:27,840 --> 00:00:30,000
researcher and senior researcher and

14
00:00:30,000 --> 00:00:31,760
lead researcher and my research

15
00:00:31,760 --> 00:00:34,719
interests include privacy engineering

16
00:00:34,719 --> 00:00:37,440
and includes security engineering and

17
00:00:37,440 --> 00:00:39,680
considering my background the use of ai

18
00:00:39,680 --> 00:00:42,000
and machine learning methods to automate

19
00:00:42,000 --> 00:00:43,600
them

20
00:00:43,600 --> 00:00:46,480
so i have divided this presentation into

21
00:00:46,480 --> 00:00:49,360
four different sections

22
00:00:49,360 --> 00:00:51,120
and in the first section i'm going to

23
00:00:51,120 --> 00:00:53,440
talk about the opportunity and challenge

24
00:00:53,440 --> 00:00:55,840
here here and why we're talking about

25
00:00:55,840 --> 00:00:58,000
this so we're going to talk about

26
00:00:58,000 --> 00:01:00,480
privacy modeling for cloud services

27
00:01:00,480 --> 00:01:02,160
based on the compliance regulations so

28
00:01:02,160 --> 00:01:04,000
there are three important components

29
00:01:04,000 --> 00:01:06,080
here cloud services

30
00:01:06,080 --> 00:01:08,159
privacy modeling

31
00:01:08,159 --> 00:01:09,280
and

32
00:01:09,280 --> 00:01:13,119
finally compliance regulations

33
00:01:13,119 --> 00:01:15,600
so this is a very typical situation i'm

34
00:01:15,600 --> 00:01:16,960
sure you have been

35
00:01:16,960 --> 00:01:18,640
in this situation that you've had a

36
00:01:18,640 --> 00:01:20,560
number of standards compliance

37
00:01:20,560 --> 00:01:23,200
regulations laws that you have to abide

38
00:01:23,200 --> 00:01:25,920
by and you have to comply with and you

39
00:01:25,920 --> 00:01:29,119
were creating a process or a

40
00:01:29,119 --> 00:01:31,920
product or a solution and you didn't

41
00:01:31,920 --> 00:01:33,680
know how you can relate how you can

42
00:01:33,680 --> 00:01:36,320
bridge between the

43
00:01:36,320 --> 00:01:39,360
compliance mandates and between them the

44
00:01:39,360 --> 00:01:41,439
actual tasks that you had to create for

45
00:01:41,439 --> 00:01:43,040
the technology and

46
00:01:43,040 --> 00:01:44,960
and the features that you had to create

47
00:01:44,960 --> 00:01:46,720
with the technology this is the problem

48
00:01:46,720 --> 00:01:49,520
that uh has fascinated me for a while

49
00:01:49,520 --> 00:01:51,520
and i've focused on this problem and

50
00:01:51,520 --> 00:01:53,280
threat modeling is

51
00:01:53,280 --> 00:01:56,240
one of the very important and useful

52
00:01:56,240 --> 00:01:59,119
tools for privacy engineering that tries

53
00:01:59,119 --> 00:02:02,240
to solve this problem

54
00:02:02,560 --> 00:02:05,200
so what is threat modeling so i

55
00:02:05,200 --> 00:02:06,960
i looked at different definitions of

56
00:02:06,960 --> 00:02:09,758
threats and one of the most

57
00:02:09,758 --> 00:02:13,040
reliable ones and most coated ones are

58
00:02:13,040 --> 00:02:14,560
from mistaken

59
00:02:14,560 --> 00:02:18,480
160 that says that threat

60
00:02:18,480 --> 00:02:20,160
is an event or condition that has the

61
00:02:20,160 --> 00:02:22,560
potential for causing asset loss and

62
00:02:22,560 --> 00:02:25,840
under desirable consequences

63
00:02:25,840 --> 00:02:30,000
so what does it mean for privacy

64
00:02:30,239 --> 00:02:31,920
so i'm going to talk about the challenge

65
00:02:31,920 --> 00:02:34,160
that we have in privacy so

66
00:02:34,160 --> 00:02:36,800
this code from benjamin franklin i think

67
00:02:36,800 --> 00:02:39,519
actually summarizes our situation with

68
00:02:39,519 --> 00:02:41,599
privacy it says it takes many good deeds

69
00:02:41,599 --> 00:02:42,560
to build

70
00:02:42,560 --> 00:02:45,440
good reputation and only one bad one to

71
00:02:45,440 --> 00:02:48,720
lose it so in my opinion it's very much

72
00:02:48,720 --> 00:02:49,680
um

73
00:02:49,680 --> 00:02:52,720
very much related to privacy and in

74
00:02:52,720 --> 00:02:56,720
privacy that the consequences include

75
00:02:56,720 --> 00:02:59,840
uh find and replace reputational damages

76
00:02:59,840 --> 00:03:01,840
and many things and many other

77
00:03:01,840 --> 00:03:05,040
consequences that you can you may care

78
00:03:05,040 --> 00:03:06,720
as a result

79
00:03:06,720 --> 00:03:09,040
so the challenge is that privacy threat

80
00:03:09,040 --> 00:03:12,640
modeling as a tool is not well known

81
00:03:12,640 --> 00:03:15,040
not a lot of people know about the

82
00:03:15,040 --> 00:03:16,159
privacy

83
00:03:16,159 --> 00:03:18,640
threat modeling techniques that exist

84
00:03:18,640 --> 00:03:20,560
in the literature and that's actually an

85
00:03:20,560 --> 00:03:22,560
opportunity so by learning about these

86
00:03:22,560 --> 00:03:25,440
ideas that i'm explaining today and i

87
00:03:25,440 --> 00:03:28,080
will pro i provide a lot of references

88
00:03:28,080 --> 00:03:29,440
and links

89
00:03:29,440 --> 00:03:31,760
you will be ahead of the curve and

90
00:03:31,760 --> 00:03:34,319
you'll you will be able to have impact

91
00:03:34,319 --> 00:03:36,799
in your organization and you can go back

92
00:03:36,799 --> 00:03:38,239
and apply those

93
00:03:38,239 --> 00:03:40,480
ideas to your

94
00:03:40,480 --> 00:03:41,519
problem

95
00:03:41,519 --> 00:03:44,560
and then have it have a positive impact

96
00:03:44,560 --> 00:03:46,560
and influence and contribution in your

97
00:03:46,560 --> 00:03:48,319
organization and for the problem that

98
00:03:48,319 --> 00:03:49,680
you are solving

99
00:03:49,680 --> 00:03:51,519
the other

100
00:03:51,519 --> 00:03:53,439
the other important challenge that we

101
00:03:53,439 --> 00:03:56,239
have here is cloud cloud has a shared

102
00:03:56,239 --> 00:03:58,239
responsibility model between the

103
00:03:58,239 --> 00:03:59,599
provider

104
00:03:59,599 --> 00:04:02,560
and the consumer and you have indirect

105
00:04:02,560 --> 00:04:04,879
control over data and over the processes

106
00:04:04,879 --> 00:04:07,280
so that also complicates

107
00:04:07,280 --> 00:04:08,799
the privacy

108
00:04:08,799 --> 00:04:11,439
engineering of cloud services and cloud

109
00:04:11,439 --> 00:04:14,000
solutions

110
00:04:14,000 --> 00:04:16,160
but what's the opportunity here so this

111
00:04:16,160 --> 00:04:18,560
is my goal opportunity statements what

112
00:04:18,560 --> 00:04:20,720
i'm saying is that with

113
00:04:20,720 --> 00:04:23,280
having regulation-based privacy threat

114
00:04:23,280 --> 00:04:26,160
modeling for cloud services we can avoid

115
00:04:26,160 --> 00:04:28,560
all the privacy risks and we can we can

116
00:04:28,560 --> 00:04:31,360
achieve compliance and privacy by design

117
00:04:31,360 --> 00:04:33,280
with minimal overheads

118
00:04:33,280 --> 00:04:35,680
so again throughout the presentation pay

119
00:04:35,680 --> 00:04:37,840
attention to three different concepts

120
00:04:37,840 --> 00:04:40,320
and components cloud privacy thread

121
00:04:40,320 --> 00:04:42,320
modeling and compliance compliance

122
00:04:42,320 --> 00:04:44,639
driven or compliance of their

123
00:04:44,639 --> 00:04:47,840
privacy threat modeling

124
00:04:48,080 --> 00:04:50,160
so in the talk i'll talk about different

125
00:04:50,160 --> 00:04:52,240
privacy threat modeling methods and i

126
00:04:52,240 --> 00:04:54,320
will compre compare and contrast them i

127
00:04:54,320 --> 00:04:56,400
will share my own experience

128
00:04:56,400 --> 00:04:58,400
with you and also the experience of

129
00:04:58,400 --> 00:05:00,639
other people that have used them and i

130
00:05:00,639 --> 00:05:02,320
hope that i will give you some tools

131
00:05:02,320 --> 00:05:04,560
that you can use for your own

132
00:05:04,560 --> 00:05:06,960
uh problem

133
00:05:06,960 --> 00:05:08,720
so the next section will be about

134
00:05:08,720 --> 00:05:11,199
privacy threat modeling so i have chosen

135
00:05:11,199 --> 00:05:12,720
these four

136
00:05:12,720 --> 00:05:14,639
um four different

137
00:05:14,639 --> 00:05:16,880
uh threat modeling techniques privacy

138
00:05:16,880 --> 00:05:19,840
threat modeling techniques uh from a

139
00:05:19,840 --> 00:05:21,759
bells of different

140
00:05:21,759 --> 00:05:24,800
methods from many from a myriad of

141
00:05:24,800 --> 00:05:26,240
different methods that exist in the

142
00:05:26,240 --> 00:05:28,560
literature so these slides don't render

143
00:05:28,560 --> 00:05:30,960
correctly because of the

144
00:05:30,960 --> 00:05:33,919
difference between the systems um

145
00:05:33,919 --> 00:05:37,680
so the i have chosen linden qttm cptm

146
00:05:37,680 --> 00:05:40,000
and privacy tagging and we have chosen

147
00:05:40,000 --> 00:05:43,199
them selectively for a reason so linden

148
00:05:43,199 --> 00:05:45,600
gets its threat from a threat a number

149
00:05:45,600 --> 00:05:48,479
of predefined threat categories

150
00:05:48,479 --> 00:05:52,400
cptm is first of all is mostly it's it's

151
00:05:52,400 --> 00:05:54,000
mainly and chiefly

152
00:05:54,000 --> 00:05:56,160
designed for cloud and it gets its

153
00:05:56,160 --> 00:05:58,000
requirement from some privacy

154
00:05:58,000 --> 00:06:01,280
requirements and from compliance qut tm

155
00:06:01,280 --> 00:06:04,080
works on some privacy goals and i also

156
00:06:04,080 --> 00:06:06,000
introduced the work that we had done

157
00:06:06,000 --> 00:06:09,520
previously on privacy tagging

158
00:06:10,160 --> 00:06:11,919
during this research i have looked at

159
00:06:11,919 --> 00:06:15,919
all of the other methods and

160
00:06:15,919 --> 00:06:18,880
only i only chose these four methods

161
00:06:18,880 --> 00:06:20,800
to be able to tell a story but there are

162
00:06:20,800 --> 00:06:22,720
also other methods that you can go and

163
00:06:22,720 --> 00:06:23,520
check

164
00:06:23,520 --> 00:06:24,319
um

165
00:06:24,319 --> 00:06:27,120
including propane square press and all

166
00:06:27,120 --> 00:06:29,759
of these links uh

167
00:06:29,759 --> 00:06:32,560
take you to the research and initiatives

168
00:06:32,560 --> 00:06:34,000
that have worked on different methods

169
00:06:34,000 --> 00:06:36,319
but for the sake of this presentation

170
00:06:36,319 --> 00:06:38,800
and for the for the sake of

171
00:06:38,800 --> 00:06:41,199
conciseness and brevity i have chosen

172
00:06:41,199 --> 00:06:44,080
only these methods but all those other

173
00:06:44,080 --> 00:06:46,800
methods also have similar elements and

174
00:06:46,800 --> 00:06:48,639
common elements with this one i start

175
00:06:48,639 --> 00:06:50,720
from clinton

176
00:06:50,720 --> 00:06:52,400
linden was

177
00:06:52,400 --> 00:06:55,840
is the result of research at k.u leon

178
00:06:55,840 --> 00:06:58,960
university and uh you can you can read

179
00:06:58,960 --> 00:07:01,919
more about this in

180
00:07:03,759 --> 00:07:09,520
thesis uh phd thesis at in 2010 and 2015

181
00:07:09,520 --> 00:07:12,800
uh linden was inspired by strike so

182
00:07:12,800 --> 00:07:14,639
you're probably familiar with the strike

183
00:07:14,639 --> 00:07:15,599
that is

184
00:07:15,599 --> 00:07:18,720
used for security threat modeling

185
00:07:18,720 --> 00:07:21,360
so lyndon these are the steps in london

186
00:07:21,360 --> 00:07:24,479
so you draw a data flow diagram

187
00:07:24,479 --> 00:07:25,599
and then

188
00:07:25,599 --> 00:07:28,560
you map linden categories to the end

189
00:07:28,560 --> 00:07:30,800
elements of data flow diagram

190
00:07:30,800 --> 00:07:33,440
and you find the threads and then you

191
00:07:33,440 --> 00:07:36,000
prioritize analyze them and

192
00:07:36,000 --> 00:07:40,319
design require mitigation methods

193
00:07:40,319 --> 00:07:42,400
so if you look at this

194
00:07:42,400 --> 00:07:44,960
the third the first three steps are

195
00:07:44,960 --> 00:07:47,199
probably in the problem space you you

196
00:07:47,199 --> 00:07:49,440
try to find the problem

197
00:07:49,440 --> 00:07:51,039
and uh this

198
00:07:51,039 --> 00:07:53,520
this is where we are focused today so

199
00:07:53,520 --> 00:07:55,120
we're just paying attention to the

200
00:07:55,120 --> 00:07:58,879
problem space finding the threats

201
00:07:58,879 --> 00:07:59,680
so

202
00:07:59,680 --> 00:08:00,879
i talked about

203
00:08:00,879 --> 00:08:03,120
data flow diagram and linkedin so what

204
00:08:03,120 --> 00:08:05,599
is linden you ask and what is data flow

205
00:08:05,599 --> 00:08:08,159
diagram

206
00:08:08,560 --> 00:08:10,240
so the

207
00:08:10,240 --> 00:08:13,440
linden team define a number of

208
00:08:13,440 --> 00:08:15,199
root threats

209
00:08:15,199 --> 00:08:18,400
or a number of category of threats

210
00:08:18,400 --> 00:08:20,400
and uh there

211
00:08:20,400 --> 00:08:22,560
and this lindens actually and the

212
00:08:22,560 --> 00:08:25,280
mnemonic is acronym for these

213
00:08:25,280 --> 00:08:27,280
different type of threats

214
00:08:27,280 --> 00:08:28,080
so

215
00:08:28,080 --> 00:08:30,160
the first one is linkability so the

216
00:08:30,160 --> 00:08:31,840
ability to

217
00:08:31,840 --> 00:08:34,080
link two items of interest for example

218
00:08:34,080 --> 00:08:36,159
you can say that you may not be be able

219
00:08:36,159 --> 00:08:39,279
to identify the sender and receiver of

220
00:08:39,279 --> 00:08:42,159
message but you say that

221
00:08:42,159 --> 00:08:45,440
this person has has sent a message to

222
00:08:45,440 --> 00:08:47,519
this person so these two people are

223
00:08:47,519 --> 00:08:49,040
linked

224
00:08:49,040 --> 00:08:50,080
the other

225
00:08:50,080 --> 00:08:52,000
concepts that is

226
00:08:52,000 --> 00:08:54,480
coded there is identifiability which is

227
00:08:54,480 --> 00:08:56,800
clear that you can identify the subject

228
00:08:56,800 --> 00:08:58,480
from some evidence

229
00:08:58,480 --> 00:09:00,880
uh we have non-repudiation there which

230
00:09:00,880 --> 00:09:03,040
is exactly the opposite of what we have

231
00:09:03,040 --> 00:09:04,080
in

232
00:09:04,080 --> 00:09:05,279
security

233
00:09:05,279 --> 00:09:06,399
uh which

234
00:09:06,399 --> 00:09:09,279
he though here it is a threat but in the

235
00:09:09,279 --> 00:09:12,399
in security is it's a goal

236
00:09:12,399 --> 00:09:14,800
uh we have detectability which means

237
00:09:14,800 --> 00:09:15,600
that

238
00:09:15,600 --> 00:09:18,399
whether something exists or not

239
00:09:18,399 --> 00:09:20,080
an example of that

240
00:09:20,080 --> 00:09:21,440
that linden

241
00:09:21,440 --> 00:09:23,680
team gives is for example whether a

242
00:09:23,680 --> 00:09:25,600
celebrity has a

243
00:09:25,600 --> 00:09:27,200
court case or a

244
00:09:27,200 --> 00:09:29,120
record in the hospital or something like

245
00:09:29,120 --> 00:09:30,959
that

246
00:09:30,959 --> 00:09:32,080
you've whether

247
00:09:32,080 --> 00:09:34,160
you want to know if there is a record

248
00:09:34,160 --> 00:09:35,760
but you may not be able to link it to

249
00:09:35,760 --> 00:09:37,519
something or you may not

250
00:09:37,519 --> 00:09:39,760
be able to identify it so it's not

251
00:09:39,760 --> 00:09:42,080
disclosure of information but just the

252
00:09:42,080 --> 00:09:44,000
fact that you know whether it exists or

253
00:09:44,000 --> 00:09:46,640
not is detectability and then you have

254
00:09:46,640 --> 00:09:48,560
obviously disclosure information that

255
00:09:48,560 --> 00:09:52,000
has some overlap with cia insecurity

256
00:09:52,000 --> 00:09:54,800
and an awareness which is being unaware

257
00:09:54,800 --> 00:09:57,920
of the consequences of doing something

258
00:09:57,920 --> 00:10:00,000
in the past now

259
00:10:00,000 --> 00:10:01,519
or in the future

260
00:10:01,519 --> 00:10:04,160
and finally non-compliance and you can

261
00:10:04,160 --> 00:10:07,360
see how they have coded the entire

262
00:10:07,360 --> 00:10:11,519
legislatory domain and compliance in one

263
00:10:11,519 --> 00:10:13,200
threat

264
00:10:13,200 --> 00:10:15,519
so these are different threats in linden

265
00:10:15,519 --> 00:10:17,279
methods

266
00:10:17,279 --> 00:10:19,920
so what's data flow diagram

267
00:10:19,920 --> 00:10:22,640
so data flow diagram actually shows the

268
00:10:22,640 --> 00:10:24,800
flow of data through a process or a

269
00:10:24,800 --> 00:10:27,760
system so there are four main

270
00:10:27,760 --> 00:10:31,360
elements in a data flow diagram

271
00:10:31,360 --> 00:10:33,440
one of the elements is data store where

272
00:10:33,440 --> 00:10:36,000
you store the data you have an external

273
00:10:36,000 --> 00:10:38,399
entity that is normally a user or

274
00:10:38,399 --> 00:10:41,200
administrator or other systems you have

275
00:10:41,200 --> 00:10:45,040
the flow of data and you have a process

276
00:10:45,040 --> 00:10:47,440
and also you have a trust boundary

277
00:10:47,440 --> 00:10:49,600
and cross-boundary of system shows where

278
00:10:49,600 --> 00:10:53,760
the sub elements of the subsystem

279
00:10:53,760 --> 00:10:57,120
trust one another

280
00:10:57,440 --> 00:11:00,320
so i've shown a diagram here and it

281
00:11:00,320 --> 00:11:03,040
shows on on the top it shows the

282
00:11:03,040 --> 00:11:05,839
architecture diagram for a typical

283
00:11:05,839 --> 00:11:07,760
application and you see that there's a

284
00:11:07,760 --> 00:11:08,800
mobile

285
00:11:08,800 --> 00:11:10,720
device that connects to a web

286
00:11:10,720 --> 00:11:13,440
application that is hosted in

287
00:11:13,440 --> 00:11:15,680
an app engine and then it the app engine

288
00:11:15,680 --> 00:11:18,000
collects connects to a database and

289
00:11:18,000 --> 00:11:19,600
cloud sql

290
00:11:19,600 --> 00:11:22,160
and uh you see on the bottom

291
00:11:22,160 --> 00:11:24,959
on the bottom half of the page that it

292
00:11:24,959 --> 00:11:28,160
shows the that in dft which it shows

293
00:11:28,160 --> 00:11:30,640
only one of the processors in dft so

294
00:11:30,640 --> 00:11:33,920
it's the user registers themselves and

295
00:11:33,920 --> 00:11:35,760
then it's the data is stored in the

296
00:11:35,760 --> 00:11:38,399
database so this you can see that you

297
00:11:38,399 --> 00:11:40,720
can have for for an architecture you may

298
00:11:40,720 --> 00:11:44,800
have many dfds which each of which

299
00:11:44,800 --> 00:11:48,560
focuses on one process

300
00:11:49,040 --> 00:11:51,120
so how do you do london

301
00:11:51,120 --> 00:11:53,680
back so you look at different elements

302
00:11:53,680 --> 00:11:57,600
of dfd for each element you try to apply

303
00:11:57,600 --> 00:12:00,600
l-i-n-d-d-u-n

304
00:12:01,440 --> 00:12:03,519
so you you look at user database and you

305
00:12:03,519 --> 00:12:04,320
see

306
00:12:04,320 --> 00:12:06,959
how linkability identifiability and

307
00:12:06,959 --> 00:12:11,839
reputation and all are applicable there

308
00:12:12,399 --> 00:12:14,399
so this these two diagrams i've taken

309
00:12:14,399 --> 00:12:15,760
from

310
00:12:15,760 --> 00:12:18,000
some from kim voice

311
00:12:18,000 --> 00:12:20,880
2014 and 2019

312
00:12:20,880 --> 00:12:23,200
papers and documents

313
00:12:23,200 --> 00:12:25,680
the first one on the left shows

314
00:12:25,680 --> 00:12:27,279
the

315
00:12:27,279 --> 00:12:29,600
one of the threads and the sub dress the

316
00:12:29,600 --> 00:12:31,920
subcategory of thirds which

317
00:12:31,920 --> 00:12:35,200
they call concrete threads and the top

318
00:12:35,200 --> 00:12:37,600
is like root thread so you break down

319
00:12:37,600 --> 00:12:39,760
the root thread into some concrete

320
00:12:39,760 --> 00:12:42,399
thread and do the study uh it's very

321
00:12:42,399 --> 00:12:43,680
much like

322
00:12:43,680 --> 00:12:46,560
if you are familiar with tank trees this

323
00:12:46,560 --> 00:12:49,040
is directory with threads which is very

324
00:12:49,040 --> 00:12:51,120
similar to attack tree and on the bottom

325
00:12:51,120 --> 00:12:52,800
you see that you have to repeat this

326
00:12:52,800 --> 00:12:56,800
process of applying linden concepts to

327
00:12:56,800 --> 00:13:00,399
various elements of

328
00:13:00,399 --> 00:13:02,320
dft

329
00:13:02,320 --> 00:13:04,320
so for example if you have

330
00:13:04,320 --> 00:13:07,120
five data flows you have to look at all

331
00:13:07,120 --> 00:13:09,040
those five data flows and and think

332
00:13:09,040 --> 00:13:10,480
about linden

333
00:13:10,480 --> 00:13:12,880
uh and then see how they apply to this

334
00:13:12,880 --> 00:13:15,440
situation and what what kind of concrete

335
00:13:15,440 --> 00:13:18,079
threats they create so you have to to

336
00:13:18,079 --> 00:13:19,920
start from the internet from the one of

337
00:13:19,920 --> 00:13:22,240
the elements and then go back and create

338
00:13:22,240 --> 00:13:23,120
the

339
00:13:23,120 --> 00:13:25,839
thread tree

340
00:13:26,320 --> 00:13:28,639
uh there's a more there's a lot more to

341
00:13:28,639 --> 00:13:31,519
be said about linden and there's um and

342
00:13:31,519 --> 00:13:33,519
in the references there are a lot of

343
00:13:33,519 --> 00:13:35,120
links that you can use to learn more

344
00:13:35,120 --> 00:13:37,680
about linden i have summarized my own

345
00:13:37,680 --> 00:13:39,680
experience and

346
00:13:39,680 --> 00:13:42,320
also other people's opinion about linden

347
00:13:42,320 --> 00:13:43,120
here

348
00:13:43,120 --> 00:13:44,480
linden in my opinion is the most

349
00:13:44,480 --> 00:13:46,480
developed and advanced method for

350
00:13:46,480 --> 00:13:48,639
privacy threat modeling there's a pulse

351
00:13:48,639 --> 00:13:51,120
of information about

352
00:13:51,120 --> 00:13:52,880
linden

353
00:13:52,880 --> 00:13:55,920
some of the threat categories are not my

354
00:13:55,920 --> 00:13:56,880
favorite

355
00:13:56,880 --> 00:13:58,240
and also i've seen that other people

356
00:13:58,240 --> 00:13:59,839
have reported this

357
00:13:59,839 --> 00:14:01,519
um some of these

358
00:14:01,519 --> 00:14:02,399
categories

359
00:14:02,399 --> 00:14:04,560
may not be applicable or may not even be

360
00:14:04,560 --> 00:14:06,720
a goal to avoid like for example

361
00:14:06,720 --> 00:14:09,279
detectability in a particular situation

362
00:14:09,279 --> 00:14:11,279
especially when you look at some of the

363
00:14:11,279 --> 00:14:14,320
dft elements

364
00:14:14,639 --> 00:14:16,880
also these uh this work that they have

365
00:14:16,880 --> 00:14:19,440
done on different levels of threats and

366
00:14:19,440 --> 00:14:20,639
attack three

367
00:14:20,639 --> 00:14:21,920
threats trees

368
00:14:21,920 --> 00:14:24,800
are not reusable and not may not be

369
00:14:24,800 --> 00:14:26,880
generic for all of the problems so you

370
00:14:26,880 --> 00:14:28,160
have to

371
00:14:28,160 --> 00:14:29,680
do this again

372
00:14:29,680 --> 00:14:31,839
and uh the last and maybe the most

373
00:14:31,839 --> 00:14:32,720
important

374
00:14:32,720 --> 00:14:36,800
part is that uh is it's introduced as

375
00:14:36,800 --> 00:14:40,160
by elements by element threat modeling

376
00:14:40,160 --> 00:14:43,440
and uh for each of the dft elements you

377
00:14:43,440 --> 00:14:44,399
have to

378
00:14:44,399 --> 00:14:46,160
analyze landon so if you look at their

379
00:14:46,160 --> 00:14:49,199
table there are 21 threat categories for

380
00:14:49,199 --> 00:14:52,079
a simple dft of only four elements for

381
00:14:52,079 --> 00:14:53,440
each element

382
00:14:53,440 --> 00:14:54,800
each

383
00:14:54,800 --> 00:14:57,120
example for each for for elements so for

384
00:14:57,120 --> 00:14:59,839
example this uh simple example that i

385
00:14:59,839 --> 00:15:01,519
showed with only four elements you have

386
00:15:01,519 --> 00:15:03,920
to analyze 21 threads and i don't know

387
00:15:03,920 --> 00:15:07,360
how scalable it is

388
00:15:07,360 --> 00:15:10,000
so we talked about linden and now we

389
00:15:10,000 --> 00:15:12,240
want to transition to cloud privacy

390
00:15:12,240 --> 00:15:13,839
threat modeling and the reason that i

391
00:15:13,839 --> 00:15:16,160
chose to talk about cptm

392
00:15:16,160 --> 00:15:19,279
is that it's it gets its category

393
00:15:19,279 --> 00:15:21,279
categories from somewhere else

394
00:15:21,279 --> 00:15:22,800
and that is the

395
00:15:22,800 --> 00:15:25,040
privacy requirement

396
00:15:25,040 --> 00:15:27,440
so cpkm is based on privacy requirement

397
00:15:27,440 --> 00:15:29,759
what does this mean

398
00:15:29,759 --> 00:15:30,720
so

399
00:15:30,720 --> 00:15:34,320
cptm is the result of uh aldi hola me

400
00:15:34,320 --> 00:15:36,399
research and uh they have published

401
00:15:36,399 --> 00:15:40,079
their work in 2014 2016 there is another

402
00:15:40,079 --> 00:15:43,680
advanced cptm uh with minor changes to

403
00:15:43,680 --> 00:15:45,920
the original cptm and

404
00:15:45,920 --> 00:15:46,639
the

405
00:15:46,639 --> 00:15:49,199
uh i have summarized the algorithm for

406
00:15:49,199 --> 00:15:52,079
ctp cptm here is that you you go and

407
00:15:52,079 --> 00:15:54,560
analyze the cloud environment

408
00:15:54,560 --> 00:15:57,759
you identify architecture actors assets

409
00:15:57,759 --> 00:15:58,880
then

410
00:15:58,880 --> 00:16:01,519
you look at you you get a source of

411
00:16:01,519 --> 00:16:03,360
privacy requirements and that is the

412
00:16:03,360 --> 00:16:05,759
interesting part and that's why i chose

413
00:16:05,759 --> 00:16:08,399
cptn so you for example you say that i

414
00:16:08,399 --> 00:16:11,199
wanted so because the work was all there

415
00:16:11,199 --> 00:16:13,360
they didn't use gdpr for example they

416
00:16:13,360 --> 00:16:17,519
used data privacy directive directive 95

417
00:16:17,519 --> 00:16:20,320
and they got their requirements from

418
00:16:20,320 --> 00:16:22,639
there so they the requirements were

419
00:16:22,639 --> 00:16:25,519
lawfulness informed consent purpose

420
00:16:25,519 --> 00:16:27,120
finding data

421
00:16:27,120 --> 00:16:29,360
minimization and all

422
00:16:29,360 --> 00:16:32,160
so you get those requirements and then

423
00:16:32,160 --> 00:16:35,519
you correlate cloud actors and actors

424
00:16:35,519 --> 00:16:38,480
that are specified in law for example if

425
00:16:38,480 --> 00:16:42,000
you have cloud provider it translates to

426
00:16:42,000 --> 00:16:43,440
a data

427
00:16:43,440 --> 00:16:45,440
controller

428
00:16:45,440 --> 00:16:47,360
and then

429
00:16:47,360 --> 00:16:48,240
um

430
00:16:48,240 --> 00:16:50,480
it's very cloud

431
00:16:50,480 --> 00:16:52,240
different situation it might

432
00:16:52,240 --> 00:16:54,560
translate to processor or it might

433
00:16:54,560 --> 00:16:56,480
translate to controllers so you

434
00:16:56,480 --> 00:16:59,680
correlate those uh requirements and then

435
00:16:59,680 --> 00:17:02,079
you for each of the pr privacy

436
00:17:02,079 --> 00:17:04,720
requirements you extract a number of

437
00:17:04,720 --> 00:17:06,720
threads

438
00:17:06,720 --> 00:17:08,640
so they the way that they have quoted is

439
00:17:08,640 --> 00:17:11,439
that they say that threat inj

440
00:17:11,439 --> 00:17:14,559
comes from the privacy requirement i and

441
00:17:14,559 --> 00:17:16,559
the threat number j the actual threat

442
00:17:16,559 --> 00:17:19,359
chain so i give an example from the

443
00:17:19,359 --> 00:17:22,799
biobank research so we know that privacy

444
00:17:22,799 --> 00:17:25,679
requirement two is informed consent

445
00:17:25,679 --> 00:17:26,559
then

446
00:17:26,559 --> 00:17:29,120
what they do is that they think about

447
00:17:29,120 --> 00:17:31,360
cloud and then they come up with

448
00:17:31,360 --> 00:17:32,559
excessive

449
00:17:32,559 --> 00:17:35,280
terp of service as the actual threats

450
00:17:35,280 --> 00:17:37,280
under this informed consent so this is

451
00:17:37,280 --> 00:17:39,440
the first one in the category of

452
00:17:39,440 --> 00:17:42,000
informed consent and that will be t21

453
00:17:42,000 --> 00:17:46,320
and then they go and prioritize this

454
00:17:46,320 --> 00:17:48,160
um i'll try to

455
00:17:48,160 --> 00:17:51,200
give the pros and cons of cptm

456
00:17:51,200 --> 00:17:52,799
so it's driven by compliance

457
00:17:52,799 --> 00:17:55,360
requirements this is positive

458
00:17:55,360 --> 00:17:57,520
so you can use any set of requirements

459
00:17:57,520 --> 00:17:59,600
it could be any law any

460
00:17:59,600 --> 00:18:02,160
any standards

461
00:18:02,160 --> 00:18:03,440
the

462
00:18:03,440 --> 00:18:05,600
difficulty or the challenge that i found

463
00:18:05,600 --> 00:18:07,840
with cptm is that was that

464
00:18:07,840 --> 00:18:10,559
it doesn't specify how you get from

465
00:18:10,559 --> 00:18:13,120
architecture actors and assets

466
00:18:13,120 --> 00:18:16,559
to those actual threats see it tells you

467
00:18:16,559 --> 00:18:20,240
that you go and um draw a architecture

468
00:18:20,240 --> 00:18:23,440
diagram identify actors identify assets

469
00:18:23,440 --> 00:18:26,640
it also says i look at the pi here i but

470
00:18:26,640 --> 00:18:30,400
there's not an established process from

471
00:18:30,400 --> 00:18:34,080
these two elements to the threads

472
00:18:36,960 --> 00:18:39,200
okay so we learned about linden and the

473
00:18:39,200 --> 00:18:42,240
x-ray categories we learned about cptn

474
00:18:42,240 --> 00:18:44,320
and the fact that you can get privacy

475
00:18:44,320 --> 00:18:45,840
requirements from different sources and

476
00:18:45,840 --> 00:18:48,320
the fact that they have introduced

477
00:18:48,320 --> 00:18:50,240
that for cloud

478
00:18:50,240 --> 00:18:51,360
the third

479
00:18:51,360 --> 00:18:53,919
system that i'm going to introduce is

480
00:18:53,919 --> 00:18:56,919
qttm

481
00:18:57,360 --> 00:19:01,440
so qt mm sorry ptm is similar to linden

482
00:19:01,440 --> 00:19:03,919
in problem space

483
00:19:03,919 --> 00:19:06,720
but it gets instead of those

484
00:19:06,720 --> 00:19:10,080
uh acronyms and those categories those

485
00:19:10,080 --> 00:19:12,559
predefined categories it uses a

486
00:19:12,559 --> 00:19:14,400
different set of privacy and security

487
00:19:14,400 --> 00:19:16,240
goals that solves one of the problems

488
00:19:16,240 --> 00:19:17,919
that we mentioned

489
00:19:17,919 --> 00:19:21,679
so there's steps of qut tm in the

490
00:19:21,679 --> 00:19:23,840
problem of space is exactly like linden

491
00:19:23,840 --> 00:19:25,760
so you draw a data flow diagram but

492
00:19:25,760 --> 00:19:29,039
instead now you get some privacy goals

493
00:19:29,039 --> 00:19:30,799
that i will explain later in the next

494
00:19:30,799 --> 00:19:32,640
slide and then

495
00:19:32,640 --> 00:19:35,520
you apply them to the elements of dft

496
00:19:35,520 --> 00:19:38,080
and then you come up with threads the

497
00:19:38,080 --> 00:19:40,960
rest of the method is outside our scope

498
00:19:40,960 --> 00:19:43,120
because it's like about the

499
00:19:43,120 --> 00:19:45,360
quantification of the attack trees and

500
00:19:45,360 --> 00:19:47,520
quantification of the risk which is

501
00:19:47,520 --> 00:19:49,360
outside the scope but in the problem

502
00:19:49,360 --> 00:19:51,440
space is exactly the same influence

503
00:19:51,440 --> 00:19:52,960
linda

504
00:19:52,960 --> 00:19:55,280
so where are the privacy goals that

505
00:19:55,280 --> 00:19:56,640
they use

506
00:19:56,640 --> 00:20:00,480
so in the security space the privacy

507
00:20:00,480 --> 00:20:03,919
goals that they use was cia

508
00:20:03,919 --> 00:20:07,520
and in the privacy space space they used

509
00:20:07,520 --> 00:20:10,799
they um borrowed the privacy goes from

510
00:20:10,799 --> 00:20:13,200
another paper privacy protection goals

511
00:20:13,200 --> 00:20:15,200
uh of 2011

512
00:20:15,200 --> 00:20:17,280
and a nitrogen paper and they have

513
00:20:17,280 --> 00:20:18,880
published their work in

514
00:20:18,880 --> 00:20:21,840
and

515
00:20:22,080 --> 00:20:23,360
and uh

516
00:20:23,360 --> 00:20:24,720
this is i

517
00:20:24,720 --> 00:20:26,400
i've taken this from

518
00:20:26,400 --> 00:20:28,559
the paper the this is the

519
00:20:28,559 --> 00:20:31,360
data flow diagram again the same same

520
00:20:31,360 --> 00:20:32,559
same

521
00:20:32,559 --> 00:20:34,480
flow as linton

522
00:20:34,480 --> 00:20:36,799
you get each of the elements of data

523
00:20:36,799 --> 00:20:38,960
flow diagram and then create attack

524
00:20:38,960 --> 00:20:41,440
series they call it ataxies as twit as

525
00:20:41,440 --> 00:20:44,240
opposed to threat trees and the circles

526
00:20:44,240 --> 00:20:46,720
shows the tags and the rectangles sorry

527
00:20:46,720 --> 00:20:49,840
the circles uh show threads

528
00:20:49,840 --> 00:20:54,559
and um the rectangles shows attacks

529
00:20:54,880 --> 00:20:55,760
so

530
00:20:55,760 --> 00:20:58,559
what is new and qttm and what are the

531
00:20:58,559 --> 00:21:01,120
pros and cons so

532
00:21:01,120 --> 00:21:03,600
obviously the method is very similar to

533
00:21:03,600 --> 00:21:06,080
linden in the problem space only church

534
00:21:06,080 --> 00:21:08,559
categories are different

535
00:21:08,559 --> 00:21:12,240
but i wanted to give you a quote from

536
00:21:12,240 --> 00:21:14,559
their study and it's very interesting

537
00:21:14,559 --> 00:21:15,919
and it was very interesting for me

538
00:21:15,919 --> 00:21:16,960
because it

539
00:21:16,960 --> 00:21:19,440
actually validated what my own

540
00:21:19,440 --> 00:21:22,880
experience and i it it resonated with me

541
00:21:22,880 --> 00:21:24,880
so they said that performing a

542
00:21:24,880 --> 00:21:26,880
comprehensive security and privacy

543
00:21:26,880 --> 00:21:29,600
analysis with bismuth methodology

544
00:21:29,600 --> 00:21:31,600
required a big set of parameters they

545
00:21:31,600 --> 00:21:33,120
were talking about linda

546
00:21:33,120 --> 00:21:35,200
so they said that if we wanted to use

547
00:21:35,200 --> 00:21:37,679
lyndon instead of our privacy goals

548
00:21:37,679 --> 00:21:40,320
we had to do we had to take six first

549
00:21:40,320 --> 00:21:42,880
security and by six they m they meant

550
00:21:42,880 --> 00:21:44,400
dementia strikes

551
00:21:44,400 --> 00:21:47,039
and seven for privacy lyndon

552
00:21:47,039 --> 00:21:47,840
and

553
00:21:47,840 --> 00:21:50,280
they had this ambiguity around like

554
00:21:50,280 --> 00:21:53,360
non-repudiation and unlinkability

555
00:21:53,360 --> 00:21:55,280
and also they mentioned that there was a

556
00:21:55,280 --> 00:21:56,960
missing concept which was

557
00:21:56,960 --> 00:21:59,600
intervenability

558
00:21:59,600 --> 00:22:02,159
um so i really liked their the concept

559
00:22:02,159 --> 00:22:04,720
of intervenability so let's go back back

560
00:22:04,720 --> 00:22:07,120
to this slide

561
00:22:07,120 --> 00:22:10,320
so the security cia is clear but in

562
00:22:10,320 --> 00:22:12,559
privacy domain they mentioned

563
00:22:12,559 --> 00:22:14,640
unlinkability which has a similar

564
00:22:14,640 --> 00:22:17,360
concept in london they mentioned

565
00:22:17,360 --> 00:22:18,960
transparency

566
00:22:18,960 --> 00:22:21,280
which is somehow new if you don't relate

567
00:22:21,280 --> 00:22:23,520
it to the compliance non-compliance in

568
00:22:23,520 --> 00:22:26,240
london and also intervenability which i

569
00:22:26,240 --> 00:22:28,799
think i've in my own experience i found

570
00:22:28,799 --> 00:22:32,559
it useful and necessary to consider when

571
00:22:32,559 --> 00:22:34,960
you're doing threat modeling because a

572
00:22:34,960 --> 00:22:37,919
lot of regulation especially ask for

573
00:22:37,919 --> 00:22:41,280
intervenability as for a allowing user

574
00:22:41,280 --> 00:22:43,919
ask for user control control of user

575
00:22:43,919 --> 00:22:45,679
over their own data

576
00:22:45,679 --> 00:22:48,400
so what they say is that first of all

577
00:22:48,400 --> 00:22:50,880
linden was too complicated not all of

578
00:22:50,880 --> 00:22:53,120
the concepts would apply in their own

579
00:22:53,120 --> 00:22:54,559
experience and

580
00:22:54,559 --> 00:22:57,919
also they they wanted the concepts of in

581
00:22:57,919 --> 00:23:00,640
concept of intervenability

582
00:23:00,640 --> 00:23:03,280
i found the 2012 paper

583
00:23:03,280 --> 00:23:06,320
and then i also found it useful to quote

584
00:23:06,320 --> 00:23:09,039
from adam jostak book

585
00:23:09,039 --> 00:23:11,600
he also says that adam schuster is the

586
00:23:11,600 --> 00:23:13,760
author of uh designing for security at

587
00:23:13,760 --> 00:23:15,919
set mother and design for security book

588
00:23:15,919 --> 00:23:18,640
and he also says that linden leaves your

589
00:23:18,640 --> 00:23:20,799
author deeply conflicted

590
00:23:20,799 --> 00:23:22,720
the privacy terminology it relies on

591
00:23:22,720 --> 00:23:24,480
will be challenging for many readers

592
00:23:24,480 --> 00:23:27,200
however however however it is one of the

593
00:23:27,200 --> 00:23:28,960
most serious and thought-provoking

594
00:23:28,960 --> 00:23:31,600
approaches to privacy threat modeling

595
00:23:31,600 --> 00:23:36,039
which i agree with

596
00:23:39,360 --> 00:23:41,120
uh the other

597
00:23:41,120 --> 00:23:43,440
challenge that i wanted to mention and

598
00:23:43,440 --> 00:23:45,279
actually related to the last code was

599
00:23:45,279 --> 00:23:48,559
that again for if you want to do linden

600
00:23:48,559 --> 00:23:50,559
for a very simple diagram with four

601
00:23:50,559 --> 00:23:55,918
elements you have you'll have 21 threads

602
00:23:58,159 --> 00:23:59,200
which

603
00:23:59,200 --> 00:24:01,520
when you're doing thread modeling by

604
00:24:01,520 --> 00:24:03,760
elements most of or some of these

605
00:24:03,760 --> 00:24:07,039
threats are not meaningful

606
00:24:07,039 --> 00:24:09,200
so there's another another idea of

607
00:24:09,200 --> 00:24:11,679
threat modeling per interaction

608
00:24:11,679 --> 00:24:14,320
uh that you focus on interactions

609
00:24:14,320 --> 00:24:15,360
instead of

610
00:24:15,360 --> 00:24:18,640
each elements of dft you focus on on the

611
00:24:18,640 --> 00:24:20,880
entire interaction and i quote from a

612
00:24:20,880 --> 00:24:24,000
2017 paper that is protection strategies

613
00:24:24,000 --> 00:24:26,159
are normally enough to protect systems

614
00:24:26,159 --> 00:24:28,720
so um i i don't have enough time to

615
00:24:28,720 --> 00:24:31,279
explain the whole idea of privacy threat

616
00:24:31,279 --> 00:24:33,679
modeling parent traction but i want to

617
00:24:33,679 --> 00:24:35,520
draw your attention to the fact that

618
00:24:35,520 --> 00:24:37,600
there is a pair interaction way of

619
00:24:37,600 --> 00:24:39,760
threat modeling that i'll try to use in

620
00:24:39,760 --> 00:24:41,120
my

621
00:24:41,120 --> 00:24:44,159
own method that i'm going to propose so

622
00:24:44,159 --> 00:24:46,960
the last idea that i'm going to

623
00:24:46,960 --> 00:24:49,760
share with you is based on our own

624
00:24:49,760 --> 00:24:52,159
research we presented this with

625
00:24:52,159 --> 00:24:54,559
mina miri and

626
00:24:54,559 --> 00:24:57,120
constantin k at different

627
00:24:57,120 --> 00:24:58,400
venues

628
00:24:58,400 --> 00:24:59,200
in

629
00:24:59,200 --> 00:25:02,480
iu pregnancies in symposium and also a

630
00:25:02,480 --> 00:25:04,320
nice soccer journal and an absolute

631
00:25:04,320 --> 00:25:07,200
conference the idea behind tagging

632
00:25:07,200 --> 00:25:10,720
and you can go and read about that it's

633
00:25:10,720 --> 00:25:12,799
there's a huge room to develop this for

634
00:25:12,799 --> 00:25:15,120
privacy engineering but

635
00:25:15,120 --> 00:25:16,880
the challenge that we had and want to

636
00:25:16,880 --> 00:25:18,799
address and the problem that we wanted

637
00:25:18,799 --> 00:25:21,760
to solve was that

638
00:25:21,760 --> 00:25:24,240
how could we identify the features the

639
00:25:24,240 --> 00:25:26,000
software features that are needed to

640
00:25:26,000 --> 00:25:29,600
comply with gdpr and how how could we

641
00:25:29,600 --> 00:25:33,840
ensure that gdpr requirements were met

642
00:25:34,080 --> 00:25:36,799
so we came with we came up with the idea

643
00:25:36,799 --> 00:25:39,600
of a tagging system which was a

644
00:25:39,600 --> 00:25:41,279
was an abstract layer between

645
00:25:41,279 --> 00:25:42,559
regulations

646
00:25:42,559 --> 00:25:46,240
and the tasks and user stories

647
00:25:46,240 --> 00:25:47,520
uh so i

648
00:25:47,520 --> 00:25:49,600
i really i want to be

649
00:25:49,600 --> 00:25:52,159
brief about this so you look at one i

650
00:25:52,159 --> 00:25:54,240
will only give a number of examples so

651
00:25:54,240 --> 00:25:57,919
you look at article four seven of gdpr

652
00:25:57,919 --> 00:25:59,919
and then you read about write to

653
00:25:59,919 --> 00:26:02,320
withdraw and then you code it

654
00:26:02,320 --> 00:26:04,960
in a tag and this is the idea comes from

655
00:26:04,960 --> 00:26:07,679
and it's inspired by uh grounded theory

656
00:26:07,679 --> 00:26:09,840
and different type of open coding excel

657
00:26:09,840 --> 00:26:12,159
coding and selective coding that

658
00:26:12,159 --> 00:26:13,840
you do there and then you come up with a

659
00:26:13,840 --> 00:26:17,120
number of codes and tags

660
00:26:17,120 --> 00:26:20,719
i will go to the examples

661
00:26:23,279 --> 00:26:26,159
this is one example just let's focus on

662
00:26:26,159 --> 00:26:28,320
one example again the slide is not

663
00:26:28,320 --> 00:26:29,760
rendered correctly

664
00:26:29,760 --> 00:26:32,400
uh so the example starts from article 12

665
00:26:32,400 --> 00:26:35,760
recited 58 or article 12

666
00:26:35,760 --> 00:26:39,039
article 12 recite recycle and recycle 59

667
00:26:39,039 --> 00:26:42,159
of gdpr and we looked at that and we

668
00:26:42,159 --> 00:26:44,480
tagged it into transparency a whole

669
00:26:44,480 --> 00:26:47,200
program and then we wrote a user story

670
00:26:47,200 --> 00:26:49,919
which specifies the goal

671
00:26:49,919 --> 00:26:52,720
from a user's perspective so it says

672
00:26:52,720 --> 00:26:55,919
that as a user i want to be able

673
00:26:55,919 --> 00:26:57,600
able to freely

674
00:26:57,600 --> 00:26:59,919
access information about processing

675
00:26:59,919 --> 00:27:02,480
activities that involves my personal

676
00:27:02,480 --> 00:27:05,600
data so that i can exercise my right to

677
00:27:05,600 --> 00:27:09,279
view my process data

678
00:27:09,279 --> 00:27:11,679
so this is a user story then the slide

679
00:27:11,679 --> 00:27:14,000
shows how we got from the

680
00:27:14,000 --> 00:27:15,440
mandate

681
00:27:15,440 --> 00:27:18,960
to the tag and to that from that to user

682
00:27:18,960 --> 00:27:23,200
story there's another example here

683
00:27:23,200 --> 00:27:25,679
again tag user story mandate

684
00:27:25,679 --> 00:27:26,559
and

685
00:27:26,559 --> 00:27:27,919
you look at the

686
00:27:27,919 --> 00:27:30,640
compliance regulations mondays

687
00:27:30,640 --> 00:27:31,360
you

688
00:27:31,360 --> 00:27:33,200
find a tag and then you turn it into

689
00:27:33,200 --> 00:27:34,159
users

690
00:27:34,159 --> 00:27:37,520
so you we had tens of user search based

691
00:27:37,520 --> 00:27:40,720
based on gdpr and i want you to in this

692
00:27:40,720 --> 00:27:42,480
slide i want you to focus on the user

693
00:27:42,480 --> 00:27:45,440
story so we had this user studies i only

694
00:27:45,440 --> 00:27:47,840
read the first one like as a user i want

695
00:27:47,840 --> 00:27:50,000
to be able to edit update my information

696
00:27:50,000 --> 00:27:52,240
in the system so that i can ensure

697
00:27:52,240 --> 00:27:55,120
accuracy of

698
00:27:55,279 --> 00:27:56,720
any

699
00:27:56,720 --> 00:27:58,159
and have control

700
00:27:58,159 --> 00:27:59,679
i can ensure the accuracy of and have

701
00:27:59,679 --> 00:28:02,880
control over my data

702
00:28:02,880 --> 00:28:06,080
so the third part is where is the center

703
00:28:06,080 --> 00:28:07,200
says

704
00:28:07,200 --> 00:28:09,120
this which i'll try to put everything

705
00:28:09,120 --> 00:28:11,120
together and give you some tools

706
00:28:11,120 --> 00:28:13,200
and tips about this

707
00:28:13,200 --> 00:28:16,399
so this is probably my favorite slide of

708
00:28:16,399 --> 00:28:19,279
all time about combining and merging

709
00:28:19,279 --> 00:28:21,600
different standards

710
00:28:21,600 --> 00:28:24,399
i give you 2-3 seconds to take a look at

711
00:28:24,399 --> 00:28:28,520
this if you haven't seen it

712
00:28:30,640 --> 00:28:32,799
so whenever you try to

713
00:28:32,799 --> 00:28:34,640
merge everything and create a new thing

714
00:28:34,640 --> 00:28:36,399
that unifies everything else it's

715
00:28:36,399 --> 00:28:39,919
probably uh it's an illusion it's it's

716
00:28:39,919 --> 00:28:41,760
hard to do that because different

717
00:28:41,760 --> 00:28:43,279
standards try to solve different

718
00:28:43,279 --> 00:28:46,240
problems but yet i tried to do this and

719
00:28:46,240 --> 00:28:48,080
i tried to put everything together and

720
00:28:48,080 --> 00:28:50,080
create a taxonomy and relationship

721
00:28:50,080 --> 00:28:51,200
between

722
00:28:51,200 --> 00:28:53,919
all the elements of cloud privacy threat

723
00:28:53,919 --> 00:28:56,640
modeling so and this is actually a

724
00:28:56,640 --> 00:28:59,120
summary of everything that i said so far

725
00:28:59,120 --> 00:29:00,799
and summary of

726
00:29:00,799 --> 00:29:03,279
my study and research on various

727
00:29:03,279 --> 00:29:04,240
different

728
00:29:04,240 --> 00:29:07,039
types of privacy threat modeling so i

729
00:29:07,039 --> 00:29:09,120
see this pattern that you can get your

730
00:29:09,120 --> 00:29:11,440
threads from goals

731
00:29:11,440 --> 00:29:14,240
and the example of goals was obviously

732
00:29:14,240 --> 00:29:17,520
qttm method that they use some privacy

733
00:29:17,520 --> 00:29:19,200
protection goals or you can get from

734
00:29:19,200 --> 00:29:20,640
threat category

735
00:29:20,640 --> 00:29:23,039
uh what's the example of that

736
00:29:23,039 --> 00:29:24,559
correct linda

737
00:29:24,559 --> 00:29:26,240
and you can get that from compliance

738
00:29:26,240 --> 00:29:29,279
requirements for example in case of cptm

739
00:29:29,279 --> 00:29:31,120
they got they got that from the

740
00:29:31,120 --> 00:29:34,960
directive 95 if bu directive 95

741
00:29:34,960 --> 00:29:38,159
and then you arrive at the threat

742
00:29:38,159 --> 00:29:39,600
so now

743
00:29:39,600 --> 00:29:41,679
what are the threats are

744
00:29:41,679 --> 00:29:44,240
you apply those threats to the cloud

745
00:29:44,240 --> 00:29:45,360
service

746
00:29:45,360 --> 00:29:47,919
and then i try to code that with the

747
00:29:47,919 --> 00:29:51,200
diam on in the diameter of circles i

748
00:29:51,200 --> 00:29:52,640
would like to

749
00:29:52,640 --> 00:29:54,880
suggest that you should put this much

750
00:29:54,880 --> 00:29:56,880
much emphasis on different

751
00:29:56,880 --> 00:30:00,559
uh elements of dft so entity usually

752
00:30:00,559 --> 00:30:03,440
less but data store data flow more and i

753
00:30:03,440 --> 00:30:05,840
would like to ask you to focus more on

754
00:30:05,840 --> 00:30:08,559
interaction and processes and then by

755
00:30:08,559 --> 00:30:10,720
applying those you write requirements

756
00:30:10,720 --> 00:30:13,520
and features that are needed the other

757
00:30:13,520 --> 00:30:15,760
idea that's shared here is that

758
00:30:15,760 --> 00:30:18,000
the compliance report requirements can

759
00:30:18,000 --> 00:30:19,360
be can

760
00:30:19,360 --> 00:30:21,760
give parameters to the threads i'll give

761
00:30:21,760 --> 00:30:23,039
you examples

762
00:30:23,039 --> 00:30:24,720
and then the compliance requirements

763
00:30:24,720 --> 00:30:26,720
also can define

764
00:30:26,720 --> 00:30:30,000
the requirements and with that you know

765
00:30:30,000 --> 00:30:31,200
with within

766
00:30:31,200 --> 00:30:33,679
in a quantitative way and with some kind

767
00:30:33,679 --> 00:30:35,200
of parameters

768
00:30:35,200 --> 00:30:37,200
i will explain more

769
00:30:37,200 --> 00:30:39,919
so this is the whole um scheme and

770
00:30:39,919 --> 00:30:41,760
framework that i'm suggesting

771
00:30:41,760 --> 00:30:43,679
so i'm suggesting that you can use any

772
00:30:43,679 --> 00:30:45,200
set of goals and threats that you're

773
00:30:45,200 --> 00:30:47,679
comfortable with it could be lyndon

774
00:30:47,679 --> 00:30:49,600
it could be

775
00:30:49,600 --> 00:30:51,919
i'm actually suggesting some other ways

776
00:30:51,919 --> 00:30:53,679
that you can do that privacy protection

777
00:30:53,679 --> 00:30:58,480
goals that the cptm that the qttm

778
00:30:58,480 --> 00:30:59,919
team has used

779
00:30:59,919 --> 00:31:02,000
you can use gaap

780
00:31:02,000 --> 00:31:05,279
or you can use gps the the the global

781
00:31:05,279 --> 00:31:07,120
privacy standard that

782
00:31:07,120 --> 00:31:09,679
uh and kovacian has

783
00:31:09,679 --> 00:31:12,640
has created and also you can for example

784
00:31:12,640 --> 00:31:15,039
get the iep for information practice

785
00:31:15,039 --> 00:31:18,039
principles

786
00:31:18,320 --> 00:31:21,840
i did that based on our own um user

787
00:31:21,840 --> 00:31:23,679
stories and i went through all of our

788
00:31:23,679 --> 00:31:25,840
user stories and tried trying to find

789
00:31:25,840 --> 00:31:28,799
out what the threat was that this user

790
00:31:28,799 --> 00:31:30,159
sort of became

791
00:31:30,159 --> 00:31:31,840
necessary based on the compliance

792
00:31:31,840 --> 00:31:33,279
regulation so that is actually

793
00:31:33,279 --> 00:31:36,159
indirectly coding the companionship

794
00:31:36,159 --> 00:31:38,320
regulation and translating it into

795
00:31:38,320 --> 00:31:41,200
threats category and also i mapped it to

796
00:31:41,200 --> 00:31:43,039
linden and goes

797
00:31:43,039 --> 00:31:45,440
so based on my own study so this is the

798
00:31:45,440 --> 00:31:46,640
result of my

799
00:31:46,640 --> 00:31:48,399
own work i'm not saying that this is the

800
00:31:48,399 --> 00:31:50,240
only way that you can come up with those

801
00:31:50,240 --> 00:31:51,919
threats but this is one of the ways that

802
00:31:51,919 --> 00:31:53,360
you can do this

803
00:31:53,360 --> 00:31:55,919
and i came up with four categories lack

804
00:31:55,919 --> 00:31:58,480
of control lack of protection

805
00:31:58,480 --> 00:32:00,240
lack of minimality and lack of

806
00:32:00,240 --> 00:32:02,080
transparency

807
00:32:02,080 --> 00:32:04,240
and under which under under each of them

808
00:32:04,240 --> 00:32:05,919
there are a number of subcategories of

809
00:32:05,919 --> 00:32:07,120
threats

810
00:32:07,120 --> 00:32:08,159
or

811
00:32:08,159 --> 00:32:10,159
concrete threats and with the definition

812
00:32:10,159 --> 00:32:11,760
of them

813
00:32:11,760 --> 00:32:13,440
so again this is not the only way that

814
00:32:13,440 --> 00:32:14,640
you can do

815
00:32:14,640 --> 00:32:17,279
and if you ask if i had doubts about

816
00:32:17,279 --> 00:32:19,360
where i should put these threats and

817
00:32:19,360 --> 00:32:22,080
concrete threats yes obviously i did

818
00:32:22,080 --> 00:32:23,519
have doubts

819
00:32:23,519 --> 00:32:27,200
and uh there are many ways to do this

820
00:32:27,200 --> 00:32:29,120
many ways to create a hierarchy and tax

821
00:32:29,120 --> 00:32:30,320
science

822
00:32:30,320 --> 00:32:32,960
uh so the next step is that focus under

823
00:32:32,960 --> 00:32:35,519
on the interaction

824
00:32:35,519 --> 00:32:37,600
so this is an example that has all the

825
00:32:37,600 --> 00:32:40,399
elements of cloud

826
00:32:40,399 --> 00:32:42,960
and i chose an example and then and i i

827
00:32:42,960 --> 00:32:44,720
did the thread modeling on this but the

828
00:32:44,720 --> 00:32:46,480
reason that i chose this example was

829
00:32:46,480 --> 00:32:48,559
that it had all the other typical

830
00:32:48,559 --> 00:32:49,760
elements that

831
00:32:49,760 --> 00:32:51,600
we needed so it's a mood diary that

832
00:32:51,600 --> 00:32:54,000
people take selfies of themselves they

833
00:32:54,000 --> 00:32:55,519
uploaded to the application the

834
00:32:55,519 --> 00:32:57,760
application saves service saves the

835
00:32:57,760 --> 00:32:59,919
store saves

836
00:32:59,919 --> 00:33:02,480
saves the pictures and closes the search

837
00:33:02,480 --> 00:33:03,840
and some and it

838
00:33:03,840 --> 00:33:05,919
connects to the cloud region a vision

839
00:33:05,919 --> 00:33:08,240
api understand how happy or sad the

840
00:33:08,240 --> 00:33:10,399
person is and then stores data

841
00:33:10,399 --> 00:33:12,640
on a regular basis on cloud skill and

842
00:33:12,640 --> 00:33:13,840
also logs

843
00:33:13,840 --> 00:33:17,120
use the cloud login

844
00:33:17,120 --> 00:33:18,640
so we don't have time to go to the

845
00:33:18,640 --> 00:33:21,360
details of this application but i

846
00:33:21,360 --> 00:33:23,360
i can show you that you can you can go

847
00:33:23,360 --> 00:33:25,440
through all these concepts

848
00:33:25,440 --> 00:33:26,880
different kind of threats and threat

849
00:33:26,880 --> 00:33:28,880
categories and then

850
00:33:28,880 --> 00:33:29,600
see

851
00:33:29,600 --> 00:33:31,600
whether they apply to this particular or

852
00:33:31,600 --> 00:33:33,440
typical service

853
00:33:33,440 --> 00:33:34,640
and then

854
00:33:34,640 --> 00:33:36,559
if yes then you can

855
00:33:36,559 --> 00:33:38,399
go one step further

856
00:33:38,399 --> 00:33:40,240
so you look you look at the thread

857
00:33:40,240 --> 00:33:43,039
categories and you look at a typical

858
00:33:43,039 --> 00:33:45,279
service and then you look at various

859
00:33:45,279 --> 00:33:47,919
interactions that it has and you will be

860
00:33:47,919 --> 00:33:50,640
able to be even beforehand we will be

861
00:33:50,640 --> 00:33:52,399
able to collectively

862
00:33:52,399 --> 00:33:55,120
have typical services and have typical

863
00:33:55,120 --> 00:33:57,519
processes and interactions under each of

864
00:33:57,519 --> 00:33:59,440
the services

865
00:33:59,440 --> 00:34:01,519
and then we can code them

866
00:34:01,519 --> 00:34:04,320
and so we'll have a pre-populated list

867
00:34:04,320 --> 00:34:08,560
of threads for generic services

868
00:34:08,560 --> 00:34:11,280
then we'll identify some kind of

869
00:34:11,280 --> 00:34:13,679
relevance or applicability criteria i've

870
00:34:13,679 --> 00:34:16,480
shown two of these examples

871
00:34:16,480 --> 00:34:18,879
just for the sake of simplicity so the

872
00:34:18,879 --> 00:34:21,280
first one we know that we have lack of

873
00:34:21,280 --> 00:34:24,159
control is a threat and lack of control

874
00:34:24,159 --> 00:34:25,839
over agreement is addressed so the

875
00:34:25,839 --> 00:34:27,760
question is that are user agreement

876
00:34:27,760 --> 00:34:29,040
requirements

877
00:34:29,040 --> 00:34:31,440
at rest under this component or it's

878
00:34:31,440 --> 00:34:32,960
addressed somewhere else

879
00:34:32,960 --> 00:34:35,520
because you need to address this

880
00:34:35,520 --> 00:34:37,599
probably once for the whole system you

881
00:34:37,599 --> 00:34:39,679
don't have to address this or mention it

882
00:34:39,679 --> 00:34:42,480
as a threat for each of the components

883
00:34:42,480 --> 00:34:45,040
the other real applicability criteria

884
00:34:45,040 --> 00:34:47,280
that i've given this example is that

885
00:34:47,280 --> 00:34:49,199
what another threat is lack of data

886
00:34:49,199 --> 00:34:51,359
protection

887
00:34:51,359 --> 00:34:53,359
for the data transfer to the third party

888
00:34:53,359 --> 00:34:54,800
or third country

889
00:34:54,800 --> 00:34:56,639
so the question is is the data

890
00:34:56,639 --> 00:34:59,280
transferred to a third country or region

891
00:34:59,280 --> 00:35:01,119
or is locally

892
00:35:01,119 --> 00:35:02,720
store

893
00:35:02,720 --> 00:35:05,040
so based on the answer to this problem

894
00:35:05,040 --> 00:35:07,680
this particular threats becomes active

895
00:35:07,680 --> 00:35:08,880
or not

896
00:35:08,880 --> 00:35:10,480
so you will

897
00:35:10,480 --> 00:35:12,320
using your tool you will have a subset

898
00:35:12,320 --> 00:35:13,680
of threads so you start with

899
00:35:13,680 --> 00:35:15,200
pre-populated

900
00:35:15,200 --> 00:35:17,359
of threats for generic services there

901
00:35:17,359 --> 00:35:18,720
are a number of questions that you

902
00:35:18,720 --> 00:35:20,240
answer and there will be a subset of

903
00:35:20,240 --> 00:35:22,400
threats that you will get

904
00:35:22,400 --> 00:35:24,079
and the last point that i want to share

905
00:35:24,079 --> 00:35:26,240
with you the last step of this framework

906
00:35:26,240 --> 00:35:28,839
and this process is parameterizing

907
00:35:28,839 --> 00:35:31,599
threats or parameterizing the

908
00:35:31,599 --> 00:35:35,280
requirements based on a regulation

909
00:35:35,280 --> 00:35:37,680
and i only give some examples

910
00:35:37,680 --> 00:35:40,000
so we know that different different

911
00:35:40,000 --> 00:35:41,839
regulations have different requirements

912
00:35:41,839 --> 00:35:45,359
right how do we code them how do we make

913
00:35:45,359 --> 00:35:47,520
how do we make different threats based

914
00:35:47,520 --> 00:35:49,200
on the requirements of

915
00:35:49,200 --> 00:35:50,880
their regulations

916
00:35:50,880 --> 00:35:53,359
so you can do that in two ways one way

917
00:35:53,359 --> 00:35:55,920
is that you can parametrize the threats

918
00:35:55,920 --> 00:35:57,839
so the trust that i mentioned i will

919
00:35:57,839 --> 00:36:00,480
give only a few examples like let's

920
00:36:00,480 --> 00:36:02,480
let's consider lgpd

921
00:36:02,480 --> 00:36:06,800
which is um enforcing brazil and gdpr

922
00:36:06,800 --> 00:36:10,960
which is the eu eu of data privacy

923
00:36:10,960 --> 00:36:12,960
so we know that for example we have lack

924
00:36:12,960 --> 00:36:16,720
of control on data access right so gdpr

925
00:36:16,720 --> 00:36:19,359
allows 30 day to answer access requires

926
00:36:19,359 --> 00:36:23,680
an lg pd 15 15 days so you have two ways

927
00:36:23,680 --> 00:36:25,359
you you can either

928
00:36:25,359 --> 00:36:27,119
code these as part of the threat

929
00:36:27,119 --> 00:36:28,880
analysis or you can

930
00:36:28,880 --> 00:36:31,520
code them as part of the requirement

931
00:36:31,520 --> 00:36:33,760
generation the other example is lack of

932
00:36:33,760 --> 00:36:36,160
transparency or breach notification for

933
00:36:36,160 --> 00:36:38,079
example gdpr

934
00:36:38,079 --> 00:36:41,760
asks for 70 maximum of 72 hours after a

935
00:36:41,760 --> 00:36:45,680
breach to notify the users and lgpd says

936
00:36:45,680 --> 00:36:47,119
reasonable time

937
00:36:47,119 --> 00:36:50,240
or lack of transparency over the legal

938
00:36:50,240 --> 00:36:52,160
ground

939
00:36:52,160 --> 00:36:54,880
gdpr applies to obviously all the all eu

940
00:36:54,880 --> 00:36:59,200
citizens but uh lg if lg lgpd doesn't

941
00:36:59,200 --> 00:37:00,560
apply if the

942
00:37:00,560 --> 00:37:03,119
processing is not done in the country

943
00:37:03,119 --> 00:37:05,119
but gdpr applies even if the processing

944
00:37:05,119 --> 00:37:08,079
is outside the country on the data from

945
00:37:08,079 --> 00:37:08,880
the

946
00:37:08,880 --> 00:37:10,720
from the from eu

947
00:37:10,720 --> 00:37:12,240
residents

948
00:37:12,240 --> 00:37:13,599
or for example

949
00:37:13,599 --> 00:37:15,920
lgpd provides additional grounds for

950
00:37:15,920 --> 00:37:18,880
process processing of data on the basis

951
00:37:18,880 --> 00:37:22,720
of for research purposes for

952
00:37:22,720 --> 00:37:26,079
for legal in legal circumstances and for

953
00:37:26,079 --> 00:37:30,000
health and credit data protection

954
00:37:30,000 --> 00:37:33,680
so again you can parametrize the data

955
00:37:33,680 --> 00:37:35,599
parameterized based on the requirements

956
00:37:35,599 --> 00:37:37,520
of the regulation

957
00:37:37,520 --> 00:37:40,400
in for the threats or for the for the

958
00:37:40,400 --> 00:37:43,839
requirements that are are associated

959
00:37:43,839 --> 00:37:45,839
with the threats

960
00:37:45,839 --> 00:37:48,320
so my last slides are conclusion

961
00:37:48,320 --> 00:37:50,560
and some suggestion for the future but i

962
00:37:50,560 --> 00:37:52,800
have summarized everything again and

963
00:37:52,800 --> 00:37:55,680
reiterated the same thing again here so

964
00:37:55,680 --> 00:37:58,880
start with any set of priority threats

965
00:37:58,880 --> 00:38:01,520
it you can you can compile that

966
00:38:01,520 --> 00:38:04,720
list based on the compliance you can

967
00:38:04,720 --> 00:38:07,599
compile that list based on requirements

968
00:38:07,599 --> 00:38:09,040
uh and uh

969
00:38:09,040 --> 00:38:10,400
it could be compliance where you could

970
00:38:10,400 --> 00:38:12,320
it could be requirement based it could

971
00:38:12,320 --> 00:38:15,440
be a goal driven it could be category

972
00:38:15,440 --> 00:38:18,800
driven i gave four examples of with

973
00:38:18,800 --> 00:38:20,880
examples of each that you can you can

974
00:38:20,880 --> 00:38:23,520
use any of the sources to compile a list

975
00:38:23,520 --> 00:38:25,680
of threads then you need to apply the

976
00:38:25,680 --> 00:38:28,560
threat analysis to the interaction of

977
00:38:28,560 --> 00:38:30,640
the cloud services again i want to

978
00:38:30,640 --> 00:38:32,560
emphasize that

979
00:38:32,560 --> 00:38:35,119
focus on processes and focus on the

980
00:38:35,119 --> 00:38:36,720
interactions

981
00:38:36,720 --> 00:38:39,200
and you can all you need to also define

982
00:38:39,200 --> 00:38:40,880
those relevance or

983
00:38:40,880 --> 00:38:43,440
applicability rules for the threats

984
00:38:43,440 --> 00:38:46,079
and this makes it repeatable and

985
00:38:46,079 --> 00:38:48,079
scalable because you can do that on the

986
00:38:48,079 --> 00:38:50,400
generic services for example for logging

987
00:38:50,400 --> 00:38:52,720
and identity management for storage and

988
00:38:52,720 --> 00:38:54,079
then there will be a question number of

989
00:38:54,079 --> 00:38:56,320
questions that you answer and a subset

990
00:38:56,320 --> 00:38:58,800
of threads will be given to you instead

991
00:38:58,800 --> 00:39:02,079
of analyzing the dft for each of the

992
00:39:02,079 --> 00:39:04,320
components again and the last part is

993
00:39:04,320 --> 00:39:06,880
that you can parametrize the threats or

994
00:39:06,880 --> 00:39:08,560
associated

995
00:39:08,560 --> 00:39:12,320
requirements based on the regulations

996
00:39:13,040 --> 00:39:15,839
um i gave examples all of this um my

997
00:39:15,839 --> 00:39:18,560
last points are that um privacy

998
00:39:18,560 --> 00:39:20,240
treadmill and is chiefly compliance

999
00:39:20,240 --> 00:39:22,640
driven so i really suggest that we

1000
00:39:22,640 --> 00:39:24,560
should start from compliance try to code

1001
00:39:24,560 --> 00:39:26,640
the compliance it doesn't mean that we

1002
00:39:26,640 --> 00:39:29,200
cannot go to threat categories like

1003
00:39:29,200 --> 00:39:30,079
linked

1004
00:39:30,079 --> 00:39:32,800
the categories that linden has uh

1005
00:39:32,800 --> 00:39:36,400
has introduced or the or other privacy

1006
00:39:36,400 --> 00:39:39,119
protection goals but uh mainly starting

1007
00:39:39,119 --> 00:39:43,240
from compliance is very helpful

1008
00:39:43,520 --> 00:39:46,320
this was my

1009
00:39:46,960 --> 00:39:48,960
opportunity goal statement again i want

1010
00:39:48,960 --> 00:39:52,160
to each reiterate this that by

1011
00:39:52,160 --> 00:39:54,560
regulation-based privacy threat modeling

1012
00:39:54,560 --> 00:39:56,880
we can actually both compliance and

1013
00:39:56,880 --> 00:39:58,960
privacy by by design with minimal

1014
00:39:58,960 --> 00:40:01,119
overhead this will be the process will

1015
00:40:01,119 --> 00:40:03,520
be repeatable and we have to do it once

1016
00:40:03,520 --> 00:40:05,359
for a number of

1017
00:40:05,359 --> 00:40:08,560
services cloud services typical services

1018
00:40:08,560 --> 00:40:11,599
i think future research and work should

1019
00:40:11,599 --> 00:40:13,760
should focus on modeling typical

1020
00:40:13,760 --> 00:40:16,560
interaction processor for cloud services

1021
00:40:16,560 --> 00:40:19,359
i showed some examples of that

1022
00:40:19,359 --> 00:40:22,000
modeling relevance and applicability

1023
00:40:22,000 --> 00:40:23,520
criteria for

1024
00:40:23,520 --> 00:40:25,599
threats and processes

1025
00:40:25,599 --> 00:40:27,680
which again i showed that for lgbt and

1026
00:40:27,680 --> 00:40:28,800
gdpr

1027
00:40:28,800 --> 00:40:31,520
and also coding compliance specifics as

1028
00:40:31,520 --> 00:40:34,160
parameters and then

1029
00:40:34,160 --> 00:40:35,920
last one and maybe the most important

1030
00:40:35,920 --> 00:40:38,720
one is creating a data exchange format

1031
00:40:38,720 --> 00:40:41,440
between customers and providers that if

1032
00:40:41,440 --> 00:40:43,359
when we create this kind of

1033
00:40:43,359 --> 00:40:45,839
privacy information and privacy

1034
00:40:45,839 --> 00:40:48,079
pre-populated lists we can communicate

1035
00:40:48,079 --> 00:40:50,720
and we can reuse the data

1036
00:40:50,720 --> 00:40:53,040
that was all i had to say and i really

1037
00:40:53,040 --> 00:40:55,359
hope that what i said and what i shared

1038
00:40:55,359 --> 00:40:57,599
with you has been useful for you and you

1039
00:40:57,599 --> 00:40:59,200
have tools to

1040
00:40:59,200 --> 00:41:01,440
take it back to your organization and to

1041
00:41:01,440 --> 00:41:03,839
your own problem and try to solve

1042
00:41:03,839 --> 00:41:05,040
problem

1043
00:41:05,040 --> 00:41:06,720
with this

1044
00:41:06,720 --> 00:41:11,759
tools and techniques thank you very much

