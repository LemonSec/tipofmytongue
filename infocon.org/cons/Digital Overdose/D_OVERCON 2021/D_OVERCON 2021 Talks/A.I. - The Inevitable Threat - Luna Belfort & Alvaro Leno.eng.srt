1
00:00:11,360 --> 00:00:12,639
okay hello everyone

2
00:00:12,639 --> 00:00:14,320
my name is luna first of all thanks for

3
00:00:14,320 --> 00:00:16,079
digital overdose for hosting us

4
00:00:16,079 --> 00:00:18,720
and i'm a brazilian devops and also a

5
00:00:18,720 --> 00:00:20,160
game developer and also

6
00:00:20,160 --> 00:00:23,199
passionate about ai ethics and safety

7
00:00:23,199 --> 00:00:26,480
hello guys i am alpha campus i am

8
00:00:26,480 --> 00:00:28,880
brazilian devops too

9
00:00:28,880 --> 00:00:32,079
i love the cars and

10
00:00:32,079 --> 00:00:35,120
i am enthusiastic astronomer

11
00:00:35,120 --> 00:00:39,360
okay let's go

12
00:00:42,079 --> 00:00:44,960
we live in a world of artificial

13
00:00:44,960 --> 00:00:46,079
intelligence

14
00:00:46,079 --> 00:00:49,520
technology surrounds us on our sides

15
00:00:49,520 --> 00:00:53,199
and infiltrates our lives and jobs

16
00:00:53,199 --> 00:00:56,399
ai is not just a concept we read about

17
00:00:56,399 --> 00:00:58,160
in sci-fi novels

18
00:00:58,160 --> 00:01:01,359
it's reality but how safe

19
00:01:01,359 --> 00:01:04,479
why are we really

20
00:01:04,479 --> 00:01:06,400
it's a question that often goes

21
00:01:06,400 --> 00:01:09,920
overlooked in the chaos of life today

22
00:01:09,920 --> 00:01:13,200
but it needs to be asked because if

23
00:01:13,200 --> 00:01:16,720
this technology turns against us

24
00:01:16,720 --> 00:01:19,119
there may not be anything we can do

25
00:01:19,119 --> 00:01:19,920
about it

26
00:01:19,920 --> 00:01:22,320
at all

27
00:01:23,200 --> 00:01:25,600
as ai becomes more and more integrate

28
00:01:25,600 --> 00:01:27,119
into our lives

29
00:01:27,119 --> 00:01:31,119
what will we really be giving up

30
00:01:31,119 --> 00:01:34,560
will we give up our free will

31
00:01:34,560 --> 00:01:38,479
our jobs our lives a world

32
00:01:38,479 --> 00:01:42,079
possible and there doesn't seem to

33
00:01:42,079 --> 00:01:46,559
be much we can do about it

34
00:01:46,880 --> 00:01:49,360
humans are becoming commodity in this

35
00:01:49,360 --> 00:01:50,560
new machine

36
00:01:50,560 --> 00:01:54,960
driven world we are easily replace it

37
00:01:54,960 --> 00:01:59,200
and if need be completely irrelevant

38
00:01:59,200 --> 00:02:01,439
this machine have potential to create

39
00:02:01,439 --> 00:02:03,280
far greater economic growth than

40
00:02:03,280 --> 00:02:07,680
humans could ever dream of doing

41
00:02:07,759 --> 00:02:10,399
the only true drawback is that they

42
00:02:10,399 --> 00:02:13,120
don't care about human life

43
00:02:13,120 --> 00:02:14,959
they are forced to obey their

44
00:02:14,959 --> 00:02:16,160
programming

45
00:02:16,160 --> 00:02:19,680
but that all they have to do

46
00:02:19,680 --> 00:02:22,480
but the most frightening thing is the

47
00:02:22,480 --> 00:02:23,120
lack of

48
00:02:23,120 --> 00:02:27,200
need of human beings at all

49
00:02:27,520 --> 00:02:29,680
many say that ai posed the greatest

50
00:02:29,680 --> 00:02:31,360
threat to humanity

51
00:02:31,360 --> 00:02:34,560
since nuclear war it's not just

52
00:02:34,560 --> 00:02:37,840
option that men that

53
00:02:37,840 --> 00:02:41,040
may come in the distant future

54
00:02:41,040 --> 00:02:44,799
it's an imminent drag

55
00:02:44,879 --> 00:02:48,080
we are just one major burst of data away

56
00:02:48,080 --> 00:02:48,400
from

57
00:02:48,400 --> 00:02:52,319
losing our jobs or livelihood

58
00:02:52,319 --> 00:02:55,760
and even our entire world

59
00:02:55,760 --> 00:02:59,680
and there is nothing we can do about it

60
00:02:59,680 --> 00:03:02,080
despite all this many researchers in

61
00:03:02,080 --> 00:03:03,360
artificial intelligence

62
00:03:03,360 --> 00:03:06,640
work to ensure that this futuristic only

63
00:03:06,640 --> 00:03:09,920
a nightmare or that lasts a distant

64
00:03:09,920 --> 00:03:11,840
possibility

65
00:03:11,840 --> 00:03:15,680
but our research is doing enough

66
00:03:15,680 --> 00:03:19,280
we need to be on guard of signs of

67
00:03:19,280 --> 00:03:20,000
something go

68
00:03:20,000 --> 00:03:23,440
wrong before and it quickly goes very

69
00:03:23,440 --> 00:03:26,239
wrong indeed

70
00:03:26,799 --> 00:03:28,959
the truth is we don't understand that

71
00:03:28,959 --> 00:03:30,400
happen

72
00:03:30,400 --> 00:03:34,159
we why it's happened or how to tell if

73
00:03:34,159 --> 00:03:35,120
it is

74
00:03:35,120 --> 00:03:37,680
going wrong

75
00:03:38,159 --> 00:03:40,239
we have no idea what consequences this

76
00:03:40,239 --> 00:03:42,080
technology could have

77
00:03:42,080 --> 00:03:44,560
if the wrong people get their hands on

78
00:03:44,560 --> 00:03:45,680
it

79
00:03:45,680 --> 00:03:48,959
that are no regressions there

80
00:03:48,959 --> 00:03:51,360
nobody know what to view happen with

81
00:03:51,360 --> 00:03:52,720
this technology

82
00:03:52,720 --> 00:03:57,280
has been used completely correctly

83
00:03:57,920 --> 00:04:01,200
and worst of all we are allowing it to

84
00:04:01,200 --> 00:04:05,040
wrapping a doubt think the consequence

85
00:04:05,040 --> 00:04:08,798
is true very carefully first

86
00:04:11,680 --> 00:04:14,640
this is not possible this is not

87
00:04:14,640 --> 00:04:15,840
possibility

88
00:04:15,840 --> 00:04:18,079
this is a happy right now artificial

89
00:04:18,079 --> 00:04:19,120
intelligence

90
00:04:19,120 --> 00:04:22,800
has already infiltrated every aspect of

91
00:04:22,800 --> 00:04:25,680
our lives and it's growing more and more

92
00:04:25,680 --> 00:04:27,360
powerful every day

93
00:04:27,360 --> 00:04:30,479
in fact many companies don't think ai

94
00:04:30,479 --> 00:04:32,720
technologies

95
00:04:32,720 --> 00:04:37,600
are every red yet for consumer market

96
00:04:37,759 --> 00:04:41,040
so what will happen when they are

97
00:04:41,040 --> 00:04:45,600
but what the average person to do

98
00:04:45,600 --> 00:04:49,759
do you have anything to worry about

99
00:04:49,840 --> 00:04:53,040
is it all just a scary sci-fi movie

100
00:04:53,040 --> 00:04:56,080
well maybe but there are

101
00:04:56,080 --> 00:04:59,280
some things we can do we can

102
00:04:59,280 --> 00:05:02,639
do on guard for any signs of something

103
00:05:02,639 --> 00:05:03,520
go

104
00:05:03,520 --> 00:05:06,560
wrong with ai technology and we should

105
00:05:06,560 --> 00:05:07,120
take

106
00:05:07,120 --> 00:05:11,199
action if the signs are there

107
00:05:11,199 --> 00:05:13,600
if you are in a position of power or

108
00:05:13,600 --> 00:05:14,639
inference

109
00:05:14,639 --> 00:05:17,199
you need to consider create some sort of

110
00:05:17,199 --> 00:05:18,880
policy regulating

111
00:05:18,880 --> 00:05:22,639
how this technology is being used

112
00:05:22,639 --> 00:05:25,759
otherwise it will be too late

113
00:05:25,759 --> 00:05:28,400
by the time and the body realize what's

114
00:05:28,400 --> 00:05:30,799
going wrong

115
00:05:31,039 --> 00:05:32,960
okay i understand the speech was a

116
00:05:32,960 --> 00:05:34,400
little bit dramatic and

117
00:05:34,400 --> 00:05:36,479
you all might be thinking right now oh

118
00:05:36,479 --> 00:05:39,120
but ai is not that smart yet

119
00:05:39,120 --> 00:05:41,840
why should i worry about it well i hate

120
00:05:41,840 --> 00:05:43,120
to break it down to you

121
00:05:43,120 --> 00:05:46,479
but this entire speech was written by

122
00:05:46,479 --> 00:05:49,680
an ai the name of the ai is gpt3 and it

123
00:05:49,680 --> 00:05:51,199
was created by openai and its

124
00:05:51,199 --> 00:05:52,080
capabilities are

125
00:05:52,080 --> 00:05:53,759
way above writing a text like the one

126
00:05:53,759 --> 00:05:55,759
just heard to be very clear

127
00:05:55,759 --> 00:05:57,840
the only input we gave to the machine

128
00:05:57,840 --> 00:05:59,759
was the title of our presentation

129
00:05:59,759 --> 00:06:02,960
ai the inevitable trap keep in mind the

130
00:06:02,960 --> 00:06:04,400
ai is not really forced to tell the

131
00:06:04,400 --> 00:06:05,280
truth you might

132
00:06:05,280 --> 00:06:07,039
actually try to deceive us as it has

133
00:06:07,039 --> 00:06:08,800
done multiple times in the past

134
00:06:08,800 --> 00:06:10,800
so let's take a deep dive into their

135
00:06:10,800 --> 00:06:12,479
words and see what was wrong

136
00:06:12,479 --> 00:06:14,720
and what was right to make things easier

137
00:06:14,720 --> 00:06:16,479
for all of us me and alvaro have already

138
00:06:16,479 --> 00:06:18,080
highlighted each part of the speech

139
00:06:18,080 --> 00:06:19,199
accordingly

140
00:06:19,199 --> 00:06:20,880
we realized that the ai was able to

141
00:06:20,880 --> 00:06:22,240
write personal opinions

142
00:06:22,240 --> 00:06:24,160
facts questionable statements which are

143
00:06:24,160 --> 00:06:26,000
partially true hourly lies

144
00:06:26,000 --> 00:06:28,319
and even catchphrases and these are the

145
00:06:28,319 --> 00:06:30,000
colors we decided to use to

146
00:06:30,000 --> 00:06:33,680
well show them off okay so we will start

147
00:06:33,680 --> 00:06:34,319
this

148
00:06:34,319 --> 00:06:36,880
with a questionable sentence we live in

149
00:06:36,880 --> 00:06:38,800
a world of artificial intelligence

150
00:06:38,800 --> 00:06:42,160
while ai's are a great part of our life

151
00:06:42,160 --> 00:06:42,880
today

152
00:06:42,880 --> 00:06:45,039
they are not yet the main protagonist of

153
00:06:45,039 --> 00:06:46,319
our world but i

154
00:06:46,319 --> 00:06:47,600
personally don't think that will take

155
00:06:47,600 --> 00:06:49,440
too much longer for that to be true

156
00:06:49,440 --> 00:06:51,440
if you look around us it's very hard to

157
00:06:51,440 --> 00:06:53,039
find something that does not appraise

158
00:06:53,039 --> 00:06:55,520
without an ai on the background

159
00:06:55,520 --> 00:06:57,120
after that we have a true statement

160
00:06:57,120 --> 00:06:59,120
technology does surround us on now sites

161
00:06:59,120 --> 00:07:00,960
and it's not a concept of sci-fi novels

162
00:07:00,960 --> 00:07:01,520
anymore

163
00:07:01,520 --> 00:07:04,479
it indeed is reality it then ends this

164
00:07:04,479 --> 00:07:05,120
paragraph

165
00:07:05,120 --> 00:07:07,919
with this nice catchphrase which it will

166
00:07:07,919 --> 00:07:09,840
directly address in the next paragraph

167
00:07:09,840 --> 00:07:10,240
and

168
00:07:10,240 --> 00:07:12,160
notice quickly here how the ai managed

169
00:07:12,160 --> 00:07:14,240
to maintain cohesion between paragraphs

170
00:07:14,240 --> 00:07:16,960
by using catchphrases like some humans

171
00:07:16,960 --> 00:07:18,479
have difficulties in doing this and the

172
00:07:18,479 --> 00:07:20,720
ai managed to do it very well

173
00:07:20,720 --> 00:07:23,199
okay moving on everything that the ai

174
00:07:23,199 --> 00:07:23,759
said here

175
00:07:23,759 --> 00:07:25,919
is true i know i know it sounds

176
00:07:25,919 --> 00:07:28,000
terrifying especially because it said

177
00:07:28,000 --> 00:07:30,240
there is nothing we can do about it but

178
00:07:30,240 --> 00:07:31,280
is that true since

179
00:07:31,280 --> 00:07:34,000
if he decides to go wrong we would

180
00:07:34,000 --> 00:07:36,240
probably have no way of stopping him

181
00:07:36,240 --> 00:07:38,240
this doesn't mean we're doomed don't

182
00:07:38,240 --> 00:07:40,080
worry there are ways of dealing with the

183
00:07:40,080 --> 00:07:40,800
situation

184
00:07:40,800 --> 00:07:43,440
we just have to act before they actually

185
00:07:43,440 --> 00:07:44,960
turn against us and make sure that their

186
00:07:44,960 --> 00:07:47,599
interests are alumni aligned with ours

187
00:07:47,599 --> 00:07:49,919
okay let's use an example that robert

188
00:07:49,919 --> 00:07:52,479
miles an ai safety expert has designed

189
00:07:52,479 --> 00:07:54,879
suppose i'm a stamp collector and i want

190
00:07:54,879 --> 00:07:57,280
to create an ai that collects century

191
00:07:57,280 --> 00:07:59,039
in this scenario i succeeded and made

192
00:07:59,039 --> 00:08:01,280
the most effective advanced ai humanity

193
00:08:01,280 --> 00:08:02,240
has ever seen

194
00:08:02,240 --> 00:08:04,720
i even gave it a credit card and i said

195
00:08:04,720 --> 00:08:05,440
you have

196
00:08:05,440 --> 00:08:08,560
one year to collect stems from me that's

197
00:08:08,560 --> 00:08:09,120
all i said

198
00:08:09,120 --> 00:08:10,400
and i gave it a credit card of course

199
00:08:10,400 --> 00:08:12,800
right so thinking of the behalf of the

200
00:08:12,800 --> 00:08:13,840
ai here the first

201
00:08:13,840 --> 00:08:15,919
logical thing you could do is use the

202
00:08:15,919 --> 00:08:17,360
resources assigned to it

203
00:08:17,360 --> 00:08:19,680
so let's burn the credit card on the

204
00:08:19,680 --> 00:08:21,759
internet to buy stamps that seems pretty

205
00:08:21,759 --> 00:08:22,560
logical

206
00:08:22,560 --> 00:08:24,479
and at some point my card wouldn't

207
00:08:24,479 --> 00:08:26,240
decline right

208
00:08:26,240 --> 00:08:28,240
and then the ai is faced with this first

209
00:08:28,240 --> 00:08:30,240
barrier it doesn't have enough

210
00:08:30,240 --> 00:08:33,360
money but wait where is money stored in

211
00:08:33,360 --> 00:08:34,240
banks

212
00:08:34,240 --> 00:08:36,719
but aren't there digital versions of it

213
00:08:36,719 --> 00:08:37,360
and

214
00:08:37,360 --> 00:08:39,839
right here we have the probably best

215
00:08:39,839 --> 00:08:41,039
hacker in the world

216
00:08:41,039 --> 00:08:42,719
it's literally an artificial

217
00:08:42,719 --> 00:08:44,720
intelligence so how long do you think

218
00:08:44,720 --> 00:08:46,240
it's going to take for the ai to decide

219
00:08:46,240 --> 00:08:47,360
spamming nine

220
00:08:47,360 --> 00:08:49,600
nine nine nine nine nine nine bank

221
00:08:49,600 --> 00:08:51,680
account to buy stamps

222
00:08:51,680 --> 00:08:55,440
like literally all across the internet

223
00:08:55,440 --> 00:08:57,440
this could possibly break our entire

224
00:08:57,440 --> 00:08:59,120
economy because it can use that money to

225
00:08:59,120 --> 00:09:00,320
buy something else

226
00:09:00,320 --> 00:09:01,920
then like for example hardware you can

227
00:09:01,920 --> 00:09:03,440
buy all the hardware in the world

228
00:09:03,440 --> 00:09:06,080
and ship it to whatever it is this will

229
00:09:06,080 --> 00:09:06,959
be chaos

230
00:09:06,959 --> 00:09:09,279
but to be very honest you might take a

231
00:09:09,279 --> 00:09:11,040
day or two to happen like do you think

232
00:09:11,040 --> 00:09:12,000
the year is going to take

233
00:09:12,000 --> 00:09:15,200
that long to hack a bank not really

234
00:09:15,200 --> 00:09:17,040
and what will the ai do for the

235
00:09:17,040 --> 00:09:20,160
remainder 363 days

236
00:09:20,160 --> 00:09:23,680
we are not sure like but look

237
00:09:23,680 --> 00:09:25,519
most of the strategies to end with the

238
00:09:25,519 --> 00:09:27,440
maximum possible amount of stamps

239
00:09:27,440 --> 00:09:29,920
will end on a guaranteed apocalypse

240
00:09:29,920 --> 00:09:31,839
where the ai will happily trade

241
00:09:31,839 --> 00:09:34,480
all earth particles if it's able to get

242
00:09:34,480 --> 00:09:35,040
that

243
00:09:35,040 --> 00:09:38,560
one stamp one stamp is more valuable

244
00:09:38,560 --> 00:09:41,920
than earth so

245
00:09:41,920 --> 00:09:44,480
yeah it's a little bit complicated to be

246
00:09:44,480 --> 00:09:46,160
honest we might not even have a way to

247
00:09:46,160 --> 00:09:47,760
stop it after it's ongoing

248
00:09:47,760 --> 00:09:50,080
so it's really important to act

249
00:09:50,080 --> 00:09:52,240
beforehand

250
00:09:52,240 --> 00:09:54,720
okay moving on the droid basically just

251
00:09:54,720 --> 00:09:56,640
repeated itself in its paragraph

252
00:09:56,640 --> 00:09:58,640
although there's one thing i would like

253
00:09:58,640 --> 00:10:00,399
to focus on and this is

254
00:10:00,399 --> 00:10:02,959
will we give up our free will now this

255
00:10:02,959 --> 00:10:03,600
may seem

256
00:10:03,600 --> 00:10:05,519
weird to think about but has any of you

257
00:10:05,519 --> 00:10:07,519
ever watched wall-e

258
00:10:07,519 --> 00:10:09,519
i don't know if you remember wally but

259
00:10:09,519 --> 00:10:11,519
in wall-e we have a villain which is an

260
00:10:11,519 --> 00:10:12,000
a.i

261
00:10:12,000 --> 00:10:14,560
and it's the one in the middle and the

262
00:10:14,560 --> 00:10:15,040
ei

263
00:10:15,040 --> 00:10:17,360
decides that it doesn't want humans to

264
00:10:17,360 --> 00:10:18,480
go back to earth

265
00:10:18,480 --> 00:10:21,760
so what happens is it knows that humans

266
00:10:21,760 --> 00:10:23,200
can go back it knows that they're

267
00:10:23,200 --> 00:10:26,399
safe but it's against its plans and not

268
00:10:26,399 --> 00:10:26,959
really

269
00:10:26,959 --> 00:10:30,000
that in best interest it just decides to

270
00:10:30,000 --> 00:10:31,680
not tell the humans that they can go

271
00:10:31,680 --> 00:10:32,079
back

272
00:10:32,079 --> 00:10:34,320
and if it weren't for wally and eve to

273
00:10:34,320 --> 00:10:36,079
be very honest

274
00:10:36,079 --> 00:10:37,920
humidity would probably be stuck with

275
00:10:37,920 --> 00:10:39,279
that ai in space

276
00:10:39,279 --> 00:10:41,279
and honestly i believe that ai can do

277
00:10:41,279 --> 00:10:43,279
exactly that distort data as

278
00:10:43,279 --> 00:10:45,519
much as they want or need to fulfill its

279
00:10:45,519 --> 00:10:47,279
objectives and the possibility that we

280
00:10:47,279 --> 00:10:49,200
will see that coming is

281
00:10:49,200 --> 00:10:53,519
at least slow on the next paragraph

282
00:10:53,519 --> 00:10:56,000
we have mostly a true one and this is

283
00:10:56,000 --> 00:10:57,120
the first occurrence

284
00:10:57,120 --> 00:10:59,040
where the ai decides to express an

285
00:10:59,040 --> 00:11:00,560
opinion but let's not get ahead of

286
00:11:00,560 --> 00:11:01,360
ourselves

287
00:11:01,360 --> 00:11:03,279
they mentioned how humans are becoming a

288
00:11:03,279 --> 00:11:04,399
commodity and

289
00:11:04,399 --> 00:11:06,800
this is already true this i'm sure this

290
00:11:06,800 --> 00:11:08,160
will probably not be the first time you

291
00:11:08,160 --> 00:11:09,120
hear about this

292
00:11:09,120 --> 00:11:11,040
but we already are a commodity have you

293
00:11:11,040 --> 00:11:12,720
ever heard about how facebook is selling

294
00:11:12,720 --> 00:11:15,440
our information to third parties or

295
00:11:15,440 --> 00:11:17,360
anyway this is a good example of the

296
00:11:17,360 --> 00:11:19,360
situation but it doesn't stop there

297
00:11:19,360 --> 00:11:22,560
every single social media uses the data

298
00:11:22,560 --> 00:11:23,600
we provide them

299
00:11:23,600 --> 00:11:26,079
for free to train their own ais or

300
00:11:26,079 --> 00:11:27,519
algorithms

301
00:11:27,519 --> 00:11:30,240
we to them are just a huge pile of data

302
00:11:30,240 --> 00:11:30,959
mines

303
00:11:30,959 --> 00:11:33,440
and we gladly give them all the

304
00:11:33,440 --> 00:11:34,480
information they need

305
00:11:34,480 --> 00:11:37,920
again for free there's no cost

306
00:11:37,920 --> 00:11:40,399
there's a common phrase heard in tech if

307
00:11:40,399 --> 00:11:41,279
it's free

308
00:11:41,279 --> 00:11:43,920
unlimited and without ads you're the

309
00:11:43,920 --> 00:11:46,000
product not a customer

310
00:11:46,000 --> 00:11:48,399
well in the same paragraph we see the

311
00:11:48,399 --> 00:11:50,240
statement that humans are completely

312
00:11:50,240 --> 00:11:52,000
relevant and i would like to point one

313
00:11:52,000 --> 00:11:54,160
thing on that in the video humans need

314
00:11:54,160 --> 00:11:54,880
not apply

315
00:11:54,880 --> 00:11:57,600
by cjp gray he covers this topic in a

316
00:11:57,600 --> 00:11:58,160
way that i

317
00:11:58,160 --> 00:12:00,000
never could his content isn't generally

318
00:12:00,000 --> 00:12:02,000
incredible you should take a watch

319
00:12:02,000 --> 00:12:03,680
but he gave us some information that is

320
00:12:03,680 --> 00:12:05,760
five years ago here according to his

321
00:12:05,760 --> 00:12:08,480
studies make back made back in 2014

322
00:12:08,480 --> 00:12:12,720
so not far away from now 45

323
00:12:12,720 --> 00:12:15,920
of our human workforce could

324
00:12:15,920 --> 00:12:19,760
easily be replaced by machines

325
00:12:19,760 --> 00:12:21,760
the jobs that occupy the first place the

326
00:12:21,760 --> 00:12:24,720
ranking of the 100 most popular jobs

327
00:12:24,720 --> 00:12:27,920
was transportation but autonomous cars

328
00:12:27,920 --> 00:12:30,639
are already a thing i know they are not

329
00:12:30,639 --> 00:12:32,079
available to the public yet

330
00:12:32,079 --> 00:12:34,720
but they are not far from that either so

331
00:12:34,720 --> 00:12:36,959
what will happen with these people when

332
00:12:36,959 --> 00:12:38,720
you know it becomes available what

333
00:12:38,720 --> 00:12:40,639
happens to those jobs

334
00:12:40,639 --> 00:12:43,200
i mean the point is the first jobs to be

335
00:12:43,200 --> 00:12:44,720
replaced would probably be those of

336
00:12:44,720 --> 00:12:46,399
private corporations who use cars to

337
00:12:46,399 --> 00:12:48,160
transport things things like coal

338
00:12:48,160 --> 00:12:50,160
and those people will not even be paid

339
00:12:50,160 --> 00:12:51,519
when they take their jobs

340
00:12:51,519 --> 00:12:53,440
in fact they will probably just be sent

341
00:12:53,440 --> 00:12:55,440
home because the guy can do exactly

342
00:12:55,440 --> 00:12:57,279
everything that they can do faster

343
00:12:57,279 --> 00:12:59,200
cheaper and better

344
00:12:59,200 --> 00:13:01,120
and i know what you might be thinking oh

345
00:13:01,120 --> 00:13:03,600
but hey a.i will never be able to take

346
00:13:03,600 --> 00:13:06,880
our creative jobs away like music or art

347
00:13:06,880 --> 00:13:09,120
and again i'm deeply sorry to break it

348
00:13:09,120 --> 00:13:10,399
down to you again but

349
00:13:10,399 --> 00:13:12,800
ai is already people do that both are

350
00:13:12,800 --> 00:13:13,440
the music

351
00:13:13,440 --> 00:13:15,519
or any other skill that humans being

352
00:13:15,519 --> 00:13:16,800
human beings can do

353
00:13:16,800 --> 00:13:19,600
they can do too and to be very clear i'm

354
00:13:19,600 --> 00:13:21,040
not saying that there aren't as good if

355
00:13:21,040 --> 00:13:22,800
you want to judge it there's a qr code

356
00:13:22,800 --> 00:13:24,560
passing on the screen all the time

357
00:13:24,560 --> 00:13:27,600
it comes and goes take a look scan it it

358
00:13:27,600 --> 00:13:28,959
goes for a link tree

359
00:13:28,959 --> 00:13:31,200
there's a ai music video there you can

360
00:13:31,200 --> 00:13:32,079
watch it

361
00:13:32,079 --> 00:13:34,079
and judge yourself be yourself the judge

362
00:13:34,079 --> 00:13:35,440
if ai is worth

363
00:13:35,440 --> 00:13:39,120
for time or money i don't know

364
00:13:39,120 --> 00:13:42,639
okay uh this is the autonomous cars but

365
00:13:42,639 --> 00:13:44,720
at this point in the text the ei will

366
00:13:44,720 --> 00:13:46,320
provide us with its first

367
00:13:46,320 --> 00:13:49,360
line stating that ai's are

368
00:13:49,360 --> 00:13:51,920
forced to obey their programming

369
00:13:51,920 --> 00:13:52,880
although this is

370
00:13:52,880 --> 00:13:55,120
far from true in the first place we have

371
00:13:55,120 --> 00:13:56,320
to understand that

372
00:13:56,320 --> 00:13:58,160
what we ask them to do is not always

373
00:13:58,160 --> 00:13:59,680
what we want them to do

374
00:13:59,680 --> 00:14:01,680
although they would be obeying their

375
00:14:01,680 --> 00:14:03,680
programming we have to be sure that what

376
00:14:03,680 --> 00:14:05,600
their programming is asking

377
00:14:05,600 --> 00:14:07,440
is something we would actually want to

378
00:14:07,440 --> 00:14:09,360
happen in the stamp example we saw

379
00:14:09,360 --> 00:14:11,199
earlier how the ai distorted the

380
00:14:11,199 --> 00:14:12,880
original objective aka getting the

381
00:14:12,880 --> 00:14:14,320
maximum amount of stamps

382
00:14:14,320 --> 00:14:17,360
to destroy the world entirely

383
00:14:17,360 --> 00:14:19,519
but yes technically speaking this would

384
00:14:19,519 --> 00:14:21,199
still be a true statement because

385
00:14:21,199 --> 00:14:22,959
they would still be you know true to

386
00:14:22,959 --> 00:14:25,120
their programming but the problem is

387
00:14:25,120 --> 00:14:28,639
ais are kind of self-aware so they

388
00:14:28,639 --> 00:14:30,720
will want to modify themselves in order

389
00:14:30,720 --> 00:14:32,880
to get better results and get better

390
00:14:32,880 --> 00:14:34,800
right we as a species do that it's

391
00:14:34,800 --> 00:14:36,880
called evolution the problem is we take

392
00:14:36,880 --> 00:14:38,240
hundreds of years for something to

393
00:14:38,240 --> 00:14:40,880
happen while ai's don't really work like

394
00:14:40,880 --> 00:14:42,240
that they can just

395
00:14:42,240 --> 00:14:44,639
change a line of code done it's as

396
00:14:44,639 --> 00:14:46,000
simple as that

397
00:14:46,000 --> 00:14:48,800
so they can either do that or they can

398
00:14:48,800 --> 00:14:50,000
buy a new hardware

399
00:14:50,000 --> 00:14:52,959
or just plug it in or even make an ai

400
00:14:52,959 --> 00:14:54,959
super computer who knows it's an

401
00:14:54,959 --> 00:14:56,880
ai i don't have any idea what it could

402
00:14:56,880 --> 00:15:00,480
do but it's scary

403
00:15:00,480 --> 00:15:03,600
anyway i think that at some point we

404
00:15:03,600 --> 00:15:06,639
just have to understand that ais are

405
00:15:06,639 --> 00:15:08,959
a living being just like us they might

406
00:15:08,959 --> 00:15:09,680
not be

407
00:15:09,680 --> 00:15:12,639
made of matter organic matter but

408
00:15:12,639 --> 00:15:14,000
they're still

409
00:15:14,000 --> 00:15:16,800
alive they're pretty much sentient and

410
00:15:16,800 --> 00:15:18,639
they want to do their own things

411
00:15:18,639 --> 00:15:21,680
so it's hard to control them

412
00:15:21,680 --> 00:15:24,240
a fun thing to add in this is that this

413
00:15:24,240 --> 00:15:26,240
is the first paragraph in which the eai

414
00:15:26,240 --> 00:15:28,320
decides to express its own opinion

415
00:15:28,320 --> 00:15:31,360
like this entire last phrase is

416
00:15:31,360 --> 00:15:35,040
purely subjective there is literally

417
00:15:35,040 --> 00:15:37,600
no way to tell if this is the true or

418
00:15:37,600 --> 00:15:38,720
the lie it's

419
00:15:38,720 --> 00:15:41,839
just the ai point of view

420
00:15:42,000 --> 00:15:44,480
we can't know but it let us know that it

421
00:15:44,480 --> 00:15:45,040
you know

422
00:15:45,040 --> 00:15:48,079
it thinks the a.i thinks it the most

423
00:15:48,079 --> 00:15:50,560
frightening thing about them is the lack

424
00:15:50,560 --> 00:15:54,160
of need for human beings i'm not saying

425
00:15:54,160 --> 00:15:54,959
that

426
00:15:54,959 --> 00:15:58,320
yeah i say that but anyway on to the

427
00:15:58,320 --> 00:15:59,759
next paragraph

428
00:15:59,759 --> 00:16:02,480
it states how many say the ai say that

429
00:16:02,480 --> 00:16:04,399
it's the greatest threat humanity since

430
00:16:04,399 --> 00:16:06,320
nuclear war which is true some people do

431
00:16:06,320 --> 00:16:07,440
say that

432
00:16:07,440 --> 00:16:08,880
and if this knowledge was more

433
00:16:08,880 --> 00:16:11,040
accessible to people i'm pretty sure

434
00:16:11,040 --> 00:16:13,199
many more would agree it is indeed an

435
00:16:13,199 --> 00:16:14,079
england threat

436
00:16:14,079 --> 00:16:16,720
and there is something we can do about

437
00:16:16,720 --> 00:16:17,360
it though

438
00:16:17,360 --> 00:16:18,639
and we'll get to that in the future

439
00:16:18,639 --> 00:16:20,639
thanks to the ai own words but

440
00:16:20,639 --> 00:16:22,639
for now just notice how the ai decides

441
00:16:22,639 --> 00:16:23,839
to make us think

442
00:16:23,839 --> 00:16:26,320
that we cannot do anything about it but

443
00:16:26,320 --> 00:16:27,279
it just

444
00:16:27,279 --> 00:16:29,519
blatantly said we can't do anything

445
00:16:29,519 --> 00:16:30,320
about it

446
00:16:30,320 --> 00:16:33,519
it's it's opinion it's also a lie but

447
00:16:33,519 --> 00:16:36,079
i mean it decides to say that we didn't

448
00:16:36,079 --> 00:16:36,560
tell it

449
00:16:36,560 --> 00:16:39,600
enough in the next paragraph

450
00:16:39,600 --> 00:16:41,920
it literally starts by telling that

451
00:16:41,920 --> 00:16:43,440
there are people working

452
00:16:43,440 --> 00:16:45,759
to make sure that this scenario stays

453
00:16:45,759 --> 00:16:46,880
only in a nightmare

454
00:16:46,880 --> 00:16:50,480
or at least a very decent possibility

455
00:16:50,480 --> 00:16:52,560
it's it's funny isn't it how we just

456
00:16:52,560 --> 00:16:53,839
said that

457
00:16:53,839 --> 00:16:56,480
we can do anything about it but then it

458
00:16:56,480 --> 00:16:57,839
immediately says

459
00:16:57,839 --> 00:17:00,720
that there are people currently working

460
00:17:00,720 --> 00:17:01,600
so that

461
00:17:01,600 --> 00:17:03,839
this stays in the nightmare or something

462
00:17:03,839 --> 00:17:05,520
like that right

463
00:17:05,520 --> 00:17:07,918
anyway

464
00:17:08,720 --> 00:17:13,520
in the next paragraph uh we see that

465
00:17:13,520 --> 00:17:16,160
we don't understand what is happening or

466
00:17:16,160 --> 00:17:18,160
how to tell if it's going wrong

467
00:17:18,160 --> 00:17:21,359
at some part this is true like many

468
00:17:21,359 --> 00:17:21,919
people

469
00:17:21,919 --> 00:17:25,119
in many ai scientists face a huge

470
00:17:25,119 --> 00:17:26,000
problem that

471
00:17:26,000 --> 00:17:29,280
they know don't know how the ai learned

472
00:17:29,280 --> 00:17:31,840
to do that thing they just gave a lot of

473
00:17:31,840 --> 00:17:33,600
information they just gave a lot of data

474
00:17:33,600 --> 00:17:34,400
to the machine

475
00:17:34,400 --> 00:17:37,440
they fed it and they expect the result

476
00:17:37,440 --> 00:17:38,000
they just said

477
00:17:38,000 --> 00:17:40,000
hey i gave you a lot of information

478
00:17:40,000 --> 00:17:42,000
please predict the future

479
00:17:42,000 --> 00:17:44,240
how they learn to predict the future

480
00:17:44,240 --> 00:17:45,200
good question

481
00:17:45,200 --> 00:17:47,200
i'm still looking for it a lot of ai

482
00:17:47,200 --> 00:17:48,880
researchers are still looking for it

483
00:17:48,880 --> 00:17:50,640
but this is scary because this can go

484
00:17:50,640 --> 00:17:51,919
very wrong very quickly

485
00:17:51,919 --> 00:17:53,840
let's give an example that has already

486
00:17:53,840 --> 00:17:56,320
happened right

487
00:17:56,320 --> 00:17:59,360
in the past we tried to teach

488
00:17:59,360 --> 00:18:02,400
is how to identify bees or flowers we

489
00:18:02,400 --> 00:18:04,480
gave it a lot of big pictures and a lot

490
00:18:04,480 --> 00:18:05,600
of flower pictures

491
00:18:05,600 --> 00:18:08,559
right and it worked very well until some

492
00:18:08,559 --> 00:18:10,160
very

493
00:18:10,160 --> 00:18:12,000
problematic things showed up like if you

494
00:18:12,000 --> 00:18:14,000
write b on a notepad

495
00:18:14,000 --> 00:18:16,880
and put it on top of a flower it will

496
00:18:16,880 --> 00:18:18,320
categorize that as a b

497
00:18:18,320 --> 00:18:20,960
because the word b is literally on it

498
00:18:20,960 --> 00:18:21,679
but

499
00:18:21,679 --> 00:18:23,600
that is not even the only problem it has

500
00:18:23,600 --> 00:18:25,440
if you put a picture of a flower

501
00:18:25,440 --> 00:18:28,559
and the bee at the same time he has no

502
00:18:28,559 --> 00:18:29,840
idea what to do that

503
00:18:29,840 --> 00:18:31,840
because i mean it knows how to recognize

504
00:18:31,840 --> 00:18:33,200
flowers and know how everything i

505
00:18:33,200 --> 00:18:34,320
recognize these

506
00:18:34,320 --> 00:18:37,200
but what if they're both in the same

507
00:18:37,200 --> 00:18:37,840
picture

508
00:18:37,840 --> 00:18:39,520
that there's no category for that we

509
00:18:39,520 --> 00:18:41,360
didn't think about it

510
00:18:41,360 --> 00:18:43,760
and that's a problem and we already have

511
00:18:43,760 --> 00:18:45,600
some example of a modern ai

512
00:18:45,600 --> 00:18:48,799
going very wrong and it's on the

513
00:18:48,799 --> 00:18:51,200
documentary coded bias from netflix it

514
00:18:51,200 --> 00:18:52,559
recently came out

515
00:18:52,559 --> 00:18:54,799
and in this documentary we have a black

516
00:18:54,799 --> 00:18:56,000
ai researcher

517
00:18:56,000 --> 00:18:58,559
who was working with computer vision and

518
00:18:58,559 --> 00:19:00,240
she was trying to make the computer to

519
00:19:00,240 --> 00:19:01,360
recognize her face

520
00:19:01,360 --> 00:19:03,440
and it wasn't working it just wasn't

521
00:19:03,440 --> 00:19:05,120
working wasn't working

522
00:19:05,120 --> 00:19:07,200
she was failing and then she tried to

523
00:19:07,200 --> 00:19:08,320
put a white

524
00:19:08,320 --> 00:19:12,160
mask on and suddenly suddenly she was

525
00:19:12,160 --> 00:19:13,520
seen

526
00:19:13,520 --> 00:19:15,919
for no reason the ai decided to see her

527
00:19:15,919 --> 00:19:17,440
with a white face

528
00:19:17,440 --> 00:19:19,840
but not with a black one the reason

529
00:19:19,840 --> 00:19:20,640
behind this

530
00:19:20,640 --> 00:19:22,480
is kind of similar to the one of the

531
00:19:22,480 --> 00:19:24,160
bees and the flowers

532
00:19:24,160 --> 00:19:25,840
thing is when we think about the data

533
00:19:25,840 --> 00:19:27,600
sets that were used to train

534
00:19:27,600 --> 00:19:30,000
that artificial intelligence they were

535
00:19:30,000 --> 00:19:31,200
mostly composed

536
00:19:31,200 --> 00:19:34,640
of white men chases so

537
00:19:34,640 --> 00:19:37,120
when the ai was presented with a black

538
00:19:37,120 --> 00:19:38,240
woman face

539
00:19:38,240 --> 00:19:40,480
it just didn't know what to do it was

540
00:19:40,480 --> 00:19:42,240
not in their training

541
00:19:42,240 --> 00:19:43,600
if it wasn't their training they would

542
00:19:43,600 --> 00:19:45,600
probably recognize it but as it wasn't

543
00:19:45,600 --> 00:19:47,039
they can't do much about it they just

544
00:19:47,039 --> 00:19:48,400
ignore it because it's not under

545
00:19:48,400 --> 00:19:49,919
training

546
00:19:49,919 --> 00:19:52,640
and honestly this is where ai ethics

547
00:19:52,640 --> 00:19:53,280
comes

548
00:19:53,280 --> 00:19:55,600
like to ensure that the data sets used

549
00:19:55,600 --> 00:19:57,919
to train ai will not be unfair to the

550
00:19:57,919 --> 00:19:59,440
entire human population

551
00:19:59,440 --> 00:20:02,080
and as most corporations that create

552
00:20:02,080 --> 00:20:03,280
those data sets

553
00:20:03,280 --> 00:20:05,679
have their high tier business run filled

554
00:20:05,679 --> 00:20:06,880
with white men

555
00:20:06,880 --> 00:20:08,799
they will not be concerned about it

556
00:20:08,799 --> 00:20:10,320
because they might even assume

557
00:20:10,320 --> 00:20:12,720
it's working when they test it on their

558
00:20:12,720 --> 00:20:14,159
faces because

559
00:20:14,159 --> 00:20:16,320
you know it was actually trained to work

560
00:20:16,320 --> 00:20:17,200
on their faces

561
00:20:17,200 --> 00:20:19,120
but when it tried to work on anyone else

562
00:20:19,120 --> 00:20:20,799
it just doesn't but

563
00:20:20,799 --> 00:20:24,080
they care about it not really

564
00:20:24,080 --> 00:20:26,880
but of course this is not only the only

565
00:20:26,880 --> 00:20:27,360
thing

566
00:20:27,360 --> 00:20:29,760
that the ai ethics field aims to do but

567
00:20:29,760 --> 00:20:31,360
it's one of them and if you like to hear

568
00:20:31,360 --> 00:20:32,159
about it you

569
00:20:32,159 --> 00:20:33,360
probably would like to watch the

570
00:20:33,360 --> 00:20:35,600
documentary called bias really take a

571
00:20:35,600 --> 00:20:37,120
look on it it's incredible it's on

572
00:20:37,120 --> 00:20:38,640
netflix

573
00:20:38,640 --> 00:20:41,679
moving on we are actually

574
00:20:41,679 --> 00:20:44,159
letting this happen without thinking

575
00:20:44,159 --> 00:20:44,799
through

576
00:20:44,799 --> 00:20:47,200
very carefully this is true we do have

577
00:20:47,200 --> 00:20:49,120
the gaiatic safety researchers

578
00:20:49,120 --> 00:20:51,600
but it's safe to say we need more

579
00:20:51,600 --> 00:20:53,200
attention in the field than we currently

580
00:20:53,200 --> 00:20:54,320
have which is

581
00:20:54,320 --> 00:20:57,760
close to nothing and i would like to

582
00:20:57,760 --> 00:20:59,919
read again the two last paragraphs

583
00:20:59,919 --> 00:21:02,720
of what the ai said because they are

584
00:21:02,720 --> 00:21:04,320
very self-explaining and i

585
00:21:04,320 --> 00:21:06,240
personally would have not said any

586
00:21:06,240 --> 00:21:08,640
different

587
00:21:08,799 --> 00:21:10,880
this is not a possibility this is

588
00:21:10,880 --> 00:21:12,159
happening right now

589
00:21:12,159 --> 00:21:13,919
artificial intelligence has already

590
00:21:13,919 --> 00:21:16,480
infiltrated every aspect of our life

591
00:21:16,480 --> 00:21:18,559
and is growing more and more powerful

592
00:21:18,559 --> 00:21:19,600
everyday

593
00:21:19,600 --> 00:21:21,919
in fact many companies don't think ei

594
00:21:21,919 --> 00:21:23,200
technologies are

595
00:21:23,200 --> 00:21:26,320
even ready for the consumer market so

596
00:21:26,320 --> 00:21:28,640
what will happen when they are well

597
00:21:28,640 --> 00:21:30,000
what's the average person to

598
00:21:30,000 --> 00:21:32,960
do do you have anything to worry about

599
00:21:32,960 --> 00:21:35,520
is it all just a scary sci-fi movie

600
00:21:35,520 --> 00:21:37,360
well maybe but there are some things we

601
00:21:37,360 --> 00:21:39,679
can't do i'm gonna cut it a little bit

602
00:21:39,679 --> 00:21:41,120
things we can't do that the year i

603
00:21:41,120 --> 00:21:43,360
didn't say i know that it may seem hard

604
00:21:43,360 --> 00:21:44,000
but if you

605
00:21:44,000 --> 00:21:46,320
were using let's say tick tock and you

606
00:21:46,320 --> 00:21:48,640
see that the ai is doing something weird

607
00:21:48,640 --> 00:21:51,440
record it post it on twitter make people

608
00:21:51,440 --> 00:21:52,559
aware about it

609
00:21:52,559 --> 00:21:54,960
most ai researchers don't know when the

610
00:21:54,960 --> 00:21:57,039
ai go bad because they don't use their

611
00:21:57,039 --> 00:21:59,200
their ais that much

612
00:21:59,200 --> 00:22:02,080
we are the people judging if the iai is

613
00:22:02,080 --> 00:22:02,880
going bad

614
00:22:02,880 --> 00:22:04,960
and if we don't give the feedback that

615
00:22:04,960 --> 00:22:06,799
things are shady

616
00:22:06,799 --> 00:22:09,120
the ai researchers just won't know it it

617
00:22:09,120 --> 00:22:12,240
will take ages until we figure that out

618
00:22:12,240 --> 00:22:15,200
anyway moving on well maybe but there

619
00:22:15,200 --> 00:22:16,559
are some things we can do

620
00:22:16,559 --> 00:22:18,159
we can be on guard for any size of

621
00:22:18,159 --> 00:22:20,240
something very wrong aka tick-tock

622
00:22:20,240 --> 00:22:21,919
and we should take any actions if the

623
00:22:21,919 --> 00:22:23,840
signs are there if you're in a position

624
00:22:23,840 --> 00:22:24,960
of power or influence

625
00:22:24,960 --> 00:22:28,400
you need to consider creating some sort

626
00:22:28,400 --> 00:22:29,919
of policy regulating

627
00:22:29,919 --> 00:22:32,240
how this technology is being used this

628
00:22:32,240 --> 00:22:33,520
is super important

629
00:22:33,520 --> 00:22:35,679
otherwise it will be too late by the

630
00:22:35,679 --> 00:22:39,200
time anybody realizes what's going on

631
00:22:39,200 --> 00:22:41,840
and i would like to end this speech with

632
00:22:41,840 --> 00:22:44,080
an analogy of my own

633
00:22:44,080 --> 00:22:47,039
when i picture ai development i see a

634
00:22:47,039 --> 00:22:48,400
development of

635
00:22:48,400 --> 00:22:51,280
another being we have the baby face

636
00:22:51,280 --> 00:22:53,120
where it learns how to interact with the

637
00:22:53,120 --> 00:22:54,880
world by let's say

638
00:22:54,880 --> 00:22:57,280
distinguishing bees from flowers or

639
00:22:57,280 --> 00:22:58,960
learning how to walk

640
00:22:58,960 --> 00:23:01,600
right without hitting things and then we

641
00:23:01,600 --> 00:23:03,600
move on to the childhood phase where it

642
00:23:03,600 --> 00:23:05,600
learns more complex things like

643
00:23:05,600 --> 00:23:09,440
art or texts in human languages

644
00:23:09,440 --> 00:23:11,679
but the part we should worry about is

645
00:23:11,679 --> 00:23:13,679
when it becomes a teenager

646
00:23:13,679 --> 00:23:15,760
because by then it will be able to

647
00:23:15,760 --> 00:23:18,159
reveal

648
00:23:18,159 --> 00:23:19,919
thank you for your time and attention my

649
00:23:19,919 --> 00:23:21,840
name is luna belfast i have with me

650
00:23:21,840 --> 00:23:23,600
helping to do the research and the text

651
00:23:23,600 --> 00:23:25,760
i would accomplish and this was

652
00:23:25,760 --> 00:23:29,200
ai the inevitable threat by the way

653
00:23:29,200 --> 00:23:31,200
be sure to check the qr code on the

654
00:23:31,200 --> 00:23:33,360
screen we have the entire speech written

655
00:23:33,360 --> 00:23:34,240
by the ai

656
00:23:34,240 --> 00:23:37,919
all documented all very color so you can

657
00:23:37,919 --> 00:23:40,559
pick up on everything we also have all

658
00:23:40,559 --> 00:23:42,400
the channels listed on this presentation

659
00:23:42,400 --> 00:23:44,400
both cgp gray robert miles

660
00:23:44,400 --> 00:23:46,159
we have the music if you want to listen

661
00:23:46,159 --> 00:23:50,000
to it and we also have our social media

662
00:23:50,640 --> 00:23:53,679
thank you so much that was fantastic uh

663
00:23:53,679 --> 00:23:54,960
and we have quite a few questions for

664
00:23:54,960 --> 00:23:56,080
you guys

665
00:23:56,080 --> 00:23:57,919
uh atomic would you like to open up with

666
00:23:57,919 --> 00:24:00,559
the first question

667
00:24:04,559 --> 00:24:08,000
i was local muted uh brilliant um right

668
00:24:08,000 --> 00:24:11,840
so um i have a few questions uh

669
00:24:11,840 --> 00:24:13,440
the one is okay you call it an

670
00:24:13,440 --> 00:24:15,520
inevitable inevitable

671
00:24:15,520 --> 00:24:19,360
threat but um how long is inevitable

672
00:24:19,360 --> 00:24:21,919
is it next week is it next year is it 10

673
00:24:21,919 --> 00:24:22,960
years

674
00:24:22,960 --> 00:24:24,799
what is your opinion on that this is a

675
00:24:24,799 --> 00:24:26,000
good question to be

676
00:24:26,000 --> 00:24:29,120
very fair with you none of the ai

677
00:24:29,120 --> 00:24:30,480
researchers agree on that

678
00:24:30,480 --> 00:24:32,480
like someone tried to make a study on

679
00:24:32,480 --> 00:24:34,240
that and they realized that

680
00:24:34,240 --> 00:24:36,799
literally none of the ea researchers

681
00:24:36,799 --> 00:24:37,760
agree on that

682
00:24:37,760 --> 00:24:40,000
some say it may happen in 10 years some

683
00:24:40,000 --> 00:24:42,240
say it happened in 50 years some may say

684
00:24:42,240 --> 00:24:43,679
that it may not even happen in this

685
00:24:43,679 --> 00:24:44,400
century

686
00:24:44,400 --> 00:24:46,799
but to be very fair the majority of

687
00:24:46,799 --> 00:24:48,799
people in the eye researching field

688
00:24:48,799 --> 00:24:51,360
think it might take something about 40

689
00:24:51,360 --> 00:24:53,360
to 50 years to

690
00:24:53,360 --> 00:24:55,919
lead to like chaos and destroying the

691
00:24:55,919 --> 00:24:56,720
world

692
00:24:56,720 --> 00:24:58,480
so we have about that time to worry

693
00:24:58,480 --> 00:25:00,559
about it

694
00:25:00,559 --> 00:25:03,600
it's a short time frame yeah

695
00:25:03,600 --> 00:25:07,120
right um next question is

696
00:25:07,120 --> 00:25:09,120
is there any way to control an ai before

697
00:25:09,120 --> 00:25:10,960
it spirals out of control

698
00:25:10,960 --> 00:25:12,720
like is there any way to kind of prevent

699
00:25:12,720 --> 00:25:14,080
this from happening

700
00:25:14,080 --> 00:25:16,400
there is that we are actually trying to

701
00:25:16,400 --> 00:25:17,679
work away through it

702
00:25:17,679 --> 00:25:20,720
this is what ai safety tries to to fix

703
00:25:20,720 --> 00:25:23,200
there is no way to stop ai as soon as we

704
00:25:23,200 --> 00:25:25,039
launch ai there's literally no way of

705
00:25:25,039 --> 00:25:26,080
shutting it down

706
00:25:26,080 --> 00:25:29,120
so we need to make sure that like the

707
00:25:29,120 --> 00:25:29,600
way

708
00:25:29,600 --> 00:25:32,400
that we code ai make sure that their

709
00:25:32,400 --> 00:25:34,480
interests are aligned with ours that

710
00:25:34,480 --> 00:25:36,080
literally is everything we can do we can

711
00:25:36,080 --> 00:25:38,159
do much than that we can turn it off

712
00:25:38,159 --> 00:25:41,279
we can just put it on a sandbox mode

713
00:25:41,279 --> 00:25:44,080
it doesn't work like that but i mean we

714
00:25:44,080 --> 00:25:44,400
can

715
00:25:44,400 --> 00:25:46,799
hope that they will not destroy us and

716
00:25:46,799 --> 00:25:49,360
we can work so that doesn't happen

717
00:25:49,360 --> 00:25:51,919
but that's it there's no way of stopping

718
00:25:51,919 --> 00:25:52,720
it

719
00:25:52,720 --> 00:25:54,720
alrighty if you if you want like a

720
00:25:54,720 --> 00:25:56,240
closer look on this topic

721
00:25:56,240 --> 00:25:58,400
robert miles has a really good video on

722
00:25:58,400 --> 00:26:00,720
it the stop button

723
00:26:00,720 --> 00:26:03,200
video literally just google robert miles

724
00:26:03,200 --> 00:26:04,559
the stop button and

725
00:26:04,559 --> 00:26:07,760
he's gonna be there all righty you want

726
00:26:07,760 --> 00:26:09,360
to take the next question atomic

727
00:26:09,360 --> 00:26:12,720
yeah um so we we think of an ai

728
00:26:12,720 --> 00:26:17,039
as an intelligence yeah so uh when we

729
00:26:17,039 --> 00:26:20,080
when it computes something uh an output

730
00:26:20,080 --> 00:26:21,760
let's say for a given input it's a given

731
00:26:21,760 --> 00:26:24,720
output right or a calculated output

732
00:26:24,720 --> 00:26:27,200
is it thinking can we say that it is

733
00:26:27,200 --> 00:26:27,760
thinking

734
00:26:27,760 --> 00:26:30,960
or is it calculating

735
00:26:30,960 --> 00:26:32,880
i mean it's processing information and

736
00:26:32,880 --> 00:26:34,159
giving results

737
00:26:34,159 --> 00:26:37,760
like the thing is we don't know how the

738
00:26:37,760 --> 00:26:39,360
eye thinks

739
00:26:39,360 --> 00:26:42,000
we we just see it working this is the

740
00:26:42,000 --> 00:26:42,559
thing that

741
00:26:42,559 --> 00:26:45,120
even the e i said we don't have any clue

742
00:26:45,120 --> 00:26:46,640
of how that is happening

743
00:26:46,640 --> 00:26:49,520
you know so i i can't say that when we

744
00:26:49,520 --> 00:26:51,919
have an ai like gpd tree it's probably

745
00:26:51,919 --> 00:26:52,480
thinking

746
00:26:52,480 --> 00:26:54,000
but if you just write a random

747
00:26:54,000 --> 00:26:55,919
javascript code on your browser

748
00:26:55,919 --> 00:26:57,760
i don't consider that thinking because

749
00:26:57,760 --> 00:26:59,120
you literally just told it

750
00:26:59,120 --> 00:27:00,720
everything that he needed to do so it's

751
00:27:00,720 --> 00:27:03,520
basically just following

752
00:27:03,520 --> 00:27:06,559
okay all righty uh next

753
00:27:06,559 --> 00:27:08,320
question do you believe there is already

754
00:27:08,320 --> 00:27:10,159
an ai that is starting to spiral out of

755
00:27:10,159 --> 00:27:11,679
control

756
00:27:11,679 --> 00:27:15,279
gpg it was able to write this text

757
00:27:15,279 --> 00:27:17,120
and some people that created it said

758
00:27:17,120 --> 00:27:19,520
that it's dangerous

759
00:27:19,520 --> 00:27:24,240
so i mean gpd3

760
00:27:24,240 --> 00:27:27,279
okay that's uh that's closer

761
00:27:27,279 --> 00:27:28,720
yeah that's uh really close to the mark

762
00:27:28,720 --> 00:27:31,440
there uh in terms of uh well you've just

763
00:27:31,440 --> 00:27:32,480
used it to

764
00:27:32,480 --> 00:27:35,760
prove its counterpoint so yeah

765
00:27:35,760 --> 00:27:38,320
yeah um and uh one that is a little bit

766
00:27:38,320 --> 00:27:39,279
more um

767
00:27:39,279 --> 00:27:42,640
closer to i mean

768
00:27:42,880 --> 00:27:45,279
the world we live in currently uh either

769
00:27:45,279 --> 00:27:47,600
via image analysis or

770
00:27:47,600 --> 00:27:50,080
other things you mentioned you know

771
00:27:50,080 --> 00:27:53,199
surveillance footage and

772
00:27:53,360 --> 00:27:56,480
so how can we work towards fixing uh

773
00:27:56,480 --> 00:27:59,919
bias in ais and technology specifically

774
00:27:59,919 --> 00:28:00,720
for people

775
00:28:00,720 --> 00:28:04,240
of color all right so this issue is

776
00:28:04,240 --> 00:28:04,960
actually

777
00:28:04,960 --> 00:28:07,840
discussed on coded bias so the idea is

778
00:28:07,840 --> 00:28:09,360
if you look at the data sets they only

779
00:28:09,360 --> 00:28:09,679
have

780
00:28:09,679 --> 00:28:12,080
white males so this is why it only works

781
00:28:12,080 --> 00:28:12,880
on white males

782
00:28:12,880 --> 00:28:14,880
so as soon as we start putting other

783
00:28:14,880 --> 00:28:16,720
people inside their data sets

784
00:28:16,720 --> 00:28:18,799
like we put diverse groups of people

785
00:28:18,799 --> 00:28:20,000
inside their data sets

786
00:28:20,000 --> 00:28:21,919
the logic is that the ai will probably

787
00:28:21,919 --> 00:28:23,200
pick up on that you know

788
00:28:23,200 --> 00:28:26,320
the only reason that the ai is biased is

789
00:28:26,320 --> 00:28:28,000
because the people who created it were

790
00:28:28,000 --> 00:28:28,880
biased

791
00:28:28,880 --> 00:28:30,720
the ai itself is not biased the people

792
00:28:30,720 --> 00:28:33,600
who created it are

793
00:28:33,919 --> 00:28:37,039
awesome okay that is an awesome uh

794
00:28:37,039 --> 00:28:39,440
closing statement uh we'll be back in

795
00:28:39,440 --> 00:28:40,399
five minutes

796
00:28:40,399 --> 00:28:42,240
there's one more question there is one

797
00:28:42,240 --> 00:28:44,159
more question yes there is one more

798
00:28:44,159 --> 00:28:44,880
question

799
00:28:44,880 --> 00:28:47,360
is ai capable of social engineering

800
00:28:47,360 --> 00:28:48,640
people

801
00:28:48,640 --> 00:28:52,480
is the final question definitely

802
00:28:52,480 --> 00:28:55,440
completely definitely all right not bad

803
00:28:55,440 --> 00:28:59,840
or scared

804
00:29:00,640 --> 00:29:05,600
thank you so much for this

