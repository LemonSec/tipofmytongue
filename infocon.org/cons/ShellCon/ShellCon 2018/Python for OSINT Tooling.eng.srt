1
00:00:00,030 --> 00:00:05,970
so this is Python 400 cent tooling with

2
00:00:03,179 --> 00:00:07,798
my chance Emily a chance is a consultant

3
00:00:05,970 --> 00:00:09,330
in the Los Angeles area she provides OSN

4
00:00:07,799 --> 00:00:11,070
services to small and medium businesses

5
00:00:09,330 --> 00:00:12,599
and private clients for the purposes for

6
00:00:11,070 --> 00:00:14,370
the purpose of doing risk and security

7
00:00:12,599 --> 00:00:15,809
assessments in her spare time she hangs

8
00:00:14,370 --> 00:00:17,250
out with the two dogs Kirby and Qbert

9
00:00:15,809 --> 00:00:18,270
and reads a lot of books about

10
00:00:17,250 --> 00:00:21,980
everything she can

11
00:00:18,270 --> 00:00:21,980
please welcome Emily to shell con 2018

12
00:00:23,480 --> 00:00:28,140
hello

13
00:00:25,350 --> 00:00:30,449
so first off a brief announcement I am

14
00:00:28,140 --> 00:00:32,308
just recovering from a small cold so

15
00:00:30,449 --> 00:00:35,210
forgive me if I have to step away from

16
00:00:32,308 --> 00:00:37,589
the mic a bit to cough I don't want to

17
00:00:35,210 --> 00:00:41,340
blow anyone's eardrums out with loud

18
00:00:37,590 --> 00:00:45,239
coughing so this is my talk Python for

19
00:00:41,340 --> 00:00:47,430
Osen it is about automating your open

20
00:00:45,239 --> 00:00:49,199
source intelligence gathering using a

21
00:00:47,430 --> 00:00:54,149
few Python libraries that I have found

22
00:00:49,200 --> 00:00:56,820
useful about me like wedgy said I am a

23
00:00:54,149 --> 00:00:59,579
consultant in the Los Angeles area a lot

24
00:00:56,820 --> 00:01:02,910
of what I do in the ocean space is

25
00:00:59,579 --> 00:01:04,890
gathering open source intelligence for

26
00:01:02,910 --> 00:01:07,649
either small or medium businesses or

27
00:01:04,890 --> 00:01:09,960
private clients which usually just means

28
00:01:07,650 --> 00:01:13,619
wealthy individuals for the purpose of

29
00:01:09,960 --> 00:01:16,559
doing risk assessments or other types of

30
00:01:13,619 --> 00:01:20,009
security assessments I am a self-taught

31
00:01:16,560 --> 00:01:22,320
Python developer I don't write a lot of

32
00:01:20,009 --> 00:01:26,220
Python on a day to day basis most of

33
00:01:22,320 --> 00:01:28,710
what I do is write a tool leave it until

34
00:01:26,220 --> 00:01:31,950
it needs to be fixed and then work on it

35
00:01:28,710 --> 00:01:34,669
some more if I spend you know four hours

36
00:01:31,950 --> 00:01:37,320
a week writing Python it's a good week

37
00:01:34,670 --> 00:01:39,799
so some of this code is going to be a

38
00:01:37,320 --> 00:01:42,779
little claw G and not super professional

39
00:01:39,799 --> 00:01:46,350
but it doesn't have to be for what I

40
00:01:42,780 --> 00:01:49,049
need it to do I am a DEFCON 562 member

41
00:01:46,350 --> 00:01:52,048
where the local DEFCON group out of Long

42
00:01:49,049 --> 00:01:54,329
Beach and they are also running the CTF

43
00:01:52,049 --> 00:01:57,450
this year so check them out if you're

44
00:01:54,329 --> 00:01:59,158
looking for a space to you know try to

45
00:01:57,450 --> 00:02:03,060
connect with your local InfoSec

46
00:01:59,159 --> 00:02:05,490
community I can be found online at G

47
00:02:03,060 --> 00:02:07,409
underscore Solaria on Twitter so if you

48
00:02:05,490 --> 00:02:08,758
want to get in touch with me that's a

49
00:02:07,409 --> 00:02:11,760
good way to do it

50
00:02:08,758 --> 00:02:13,299
I am also as wedgy said a dog bomb to

51
00:02:11,760 --> 00:02:17,470
Kirby

52
00:02:13,300 --> 00:02:19,590
and Qbert my babies they are probably my

53
00:02:17,470 --> 00:02:21,940
favorite things in the world outside of

54
00:02:19,590 --> 00:02:24,730
well just my favorite things in the

55
00:02:21,940 --> 00:02:27,370
world so I do have a co-author for this

56
00:02:24,730 --> 00:02:29,230
talk her name is a litt glazier she is

57
00:02:27,370 --> 00:02:32,650
based in France so she was not able to

58
00:02:29,230 --> 00:02:34,989
be here today but she is a freelance

59
00:02:32,650 --> 00:02:38,440
Python developer and she does a lot of

60
00:02:34,990 --> 00:02:41,140
database DBA stuff as well she has about

61
00:02:38,440 --> 00:02:43,780
10 years of focus on making scientific

62
00:02:41,140 --> 00:02:46,140
research tools and currently focuses on

63
00:02:43,780 --> 00:02:48,820
making tools for small teams and

64
00:02:46,140 --> 00:02:52,809
researchers as well at one point in time

65
00:02:48,820 --> 00:02:57,070
I gave her the tool that I'm open

66
00:02:52,810 --> 00:02:58,840
sourcing with this talk it was a sort of

67
00:02:57,070 --> 00:03:01,900
clutch together group of Python scripts

68
00:02:58,840 --> 00:03:04,420
and she sat down and instead of giving

69
00:03:01,900 --> 00:03:06,640
me some advice on it took a lot of my

70
00:03:04,420 --> 00:03:10,000
code and rewrote it to be far more

71
00:03:06,640 --> 00:03:12,279
elegant so she is the co-author on this

72
00:03:10,000 --> 00:03:13,870
talk because she has a lot of

73
00:03:12,280 --> 00:03:16,780
contributions to the code that you're

74
00:03:13,870 --> 00:03:20,020
going to see especially at the end she

75
00:03:16,780 --> 00:03:24,070
is a cat mom to two lovely cats named

76
00:03:20,020 --> 00:03:27,430
squeaker and potato they are absolutely

77
00:03:24,070 --> 00:03:29,940
wonderful kitties I wish I had photos of

78
00:03:27,430 --> 00:03:32,560
them but she didn't have any good photos

79
00:03:29,940 --> 00:03:36,070
the purpose of this talk is to cover

80
00:03:32,560 --> 00:03:37,810
several open source in telepath on

81
00:03:36,070 --> 00:03:40,180
libraries that can be used to automate

82
00:03:37,810 --> 00:03:42,209
open source intelligence gathering this

83
00:03:40,180 --> 00:03:45,070
talk assumes that you have some

84
00:03:42,209 --> 00:03:46,720
familiarity with both the process of

85
00:03:45,070 --> 00:03:49,540
open source intelligence gathering and

86
00:03:46,720 --> 00:03:51,600
also with writing Python however if you

87
00:03:49,540 --> 00:03:55,260
don't have experience with those things

88
00:03:51,600 --> 00:03:57,549
definitely feel free to stick around I

89
00:03:55,260 --> 00:03:59,920
recommend getting experience with both

90
00:03:57,550 --> 00:04:01,900
those things if you are you know working

91
00:03:59,920 --> 00:04:04,390
in the InfoSec space they're both very

92
00:04:01,900 --> 00:04:06,010
useful and as you start to learn more

93
00:04:04,390 --> 00:04:07,809
about those things even if you don't

94
00:04:06,010 --> 00:04:09,310
know much about it now there will be

95
00:04:07,810 --> 00:04:11,440
things from this talk that will pop up

96
00:04:09,310 --> 00:04:13,420
in your head as you start learning those

97
00:04:11,440 --> 00:04:16,899
things and you'll say hey I remember

98
00:04:13,420 --> 00:04:19,120
this we're gonna walk through some

99
00:04:16,899 --> 00:04:22,120
libraries and show examples of programs

100
00:04:19,120 --> 00:04:24,970
that can use them unfortunately it seems

101
00:04:22,120 --> 00:04:26,570
like the actual code examples that are

102
00:04:24,970 --> 00:04:28,550
going to be up on the screen

103
00:04:26,570 --> 00:04:33,290
aren't going to show up very well based

104
00:04:28,550 --> 00:04:36,020
on the the first slide so if you want to

105
00:04:33,290 --> 00:04:38,840
look at them while we're going through

106
00:04:36,020 --> 00:04:39,229
them they can be found at this github

107
00:04:38,840 --> 00:04:43,190
link

108
00:04:39,230 --> 00:04:52,010
it's just github calm /g - Solaria slash

109
00:04:43,190 --> 00:04:54,650
shell con 2018 mimosa's have arrived two

110
00:04:52,010 --> 00:04:58,310
of them Oh Lord that's gonna be a

111
00:04:54,650 --> 00:05:01,070
problem thank you very much

112
00:04:58,310 --> 00:05:04,880
so all of these programs are written in

113
00:05:01,070 --> 00:05:07,190
Python 3 as the good Lord intended some

114
00:05:04,880 --> 00:05:09,350
of the code examples here may not give

115
00:05:07,190 --> 00:05:12,560
incredibly useful results so if you're

116
00:05:09,350 --> 00:05:15,110
running them along with me you may think

117
00:05:12,560 --> 00:05:17,540
this isn't super useful that's because

118
00:05:15,110 --> 00:05:20,210
they're sort of pared down to

119
00:05:17,540 --> 00:05:23,630
demonstrate one specific context or one

120
00:05:20,210 --> 00:05:26,390
specific use at the end we're gonna be

121
00:05:23,630 --> 00:05:28,430
looking at the the rewritten program

122
00:05:26,390 --> 00:05:30,919
that eylandt made called sonnet ER and

123
00:05:28,430 --> 00:05:32,600
that is going to glue all of these

124
00:05:30,920 --> 00:05:34,070
together in a way that is much more

125
00:05:32,600 --> 00:05:35,900
useful so if you're looking at some of

126
00:05:34,070 --> 00:05:37,990
this and saying this is only doing one

127
00:05:35,900 --> 00:05:40,609
little thing what's the use of this

128
00:05:37,990 --> 00:05:42,350
probably nothing but it'll become

129
00:05:40,610 --> 00:05:44,870
apparent when you add it together with

130
00:05:42,350 --> 00:05:47,000
all of the other things the libraries

131
00:05:44,870 --> 00:05:49,660
that we're going to be covering are the

132
00:05:47,000 --> 00:05:53,360
Google Custom Search API library

133
00:05:49,660 --> 00:05:56,780
beautifulsoup the Google cloud language

134
00:05:53,360 --> 00:06:00,170
API library a library called fuzzy-wuzzy

135
00:05:56,780 --> 00:06:02,330
and selenium so let's go ahead and dive

136
00:06:00,170 --> 00:06:04,360
in the first thing we're going to talk

137
00:06:02,330 --> 00:06:08,120
about is the Google Custom Search API

138
00:06:04,360 --> 00:06:10,580
Google provides the ability to create a

139
00:06:08,120 --> 00:06:12,470
custom search engine usually they're

140
00:06:10,580 --> 00:06:13,940
their thinking behind this is that

141
00:06:12,470 --> 00:06:16,040
you're going to take that custom search

142
00:06:13,940 --> 00:06:20,120
engine and stick it on your website and

143
00:06:16,040 --> 00:06:23,540
use it to search your website or one or

144
00:06:20,120 --> 00:06:25,250
two websites that are associated it's

145
00:06:23,540 --> 00:06:27,470
restrictive because we can only look at

146
00:06:25,250 --> 00:06:30,800
the domains that we've specified when we

147
00:06:27,470 --> 00:06:32,630
are creating the CSE however there's a

148
00:06:30,800 --> 00:06:34,550
workaround so that you can go back in

149
00:06:32,630 --> 00:06:36,320
and delete the domains that you've added

150
00:06:34,550 --> 00:06:39,720
at that point you're basically just

151
00:06:36,320 --> 00:06:42,449
searching all of Google with this API

152
00:06:39,720 --> 00:06:45,389
to create this you just go to the CSU

153
00:06:42,449 --> 00:06:48,300
website you click Add fill out the

154
00:06:45,389 --> 00:06:51,750
information click create and then go to

155
00:06:48,300 --> 00:06:53,340
the control panel and delete your the

156
00:06:51,750 --> 00:06:55,740
domains that you specified at the

157
00:06:53,340 --> 00:06:59,789
beginning now you have like I said an

158
00:06:55,740 --> 00:07:01,650
API for searching all of Google there is

159
00:06:59,789 --> 00:07:04,380
a cost to this it is a hundred searches

160
00:07:01,650 --> 00:07:06,448
per day for free after that it's five

161
00:07:04,380 --> 00:07:08,490
dollars per thousand searches up to ten

162
00:07:06,449 --> 00:07:10,050
thousand a day if you're getting up to

163
00:07:08,490 --> 00:07:12,389
the point of doing ten thousand searches

164
00:07:10,050 --> 00:07:13,860
a day chances are you're probably doing

165
00:07:12,389 --> 00:07:15,960
something for work and they should be

166
00:07:13,860 --> 00:07:18,180
giving you the ability to you know use

167
00:07:15,960 --> 00:07:21,750
their billing account if you're not

168
00:07:18,180 --> 00:07:23,340
however the Google cloud billing account

169
00:07:21,750 --> 00:07:25,199
will give you three hundred dollars in

170
00:07:23,340 --> 00:07:27,119
free credit every time you create a new

171
00:07:25,199 --> 00:07:28,729
account so if you find yourself running

172
00:07:27,120 --> 00:07:32,099
into the limits where you're actually

173
00:07:28,729 --> 00:07:34,229
costing yourself money just create new

174
00:07:32,099 --> 00:07:36,780
accounts and switch out the API key and

175
00:07:34,229 --> 00:07:39,599
the CSE ID and you've got three hundred

176
00:07:36,780 --> 00:07:42,948
dollars you can install the library

177
00:07:39,599 --> 00:07:45,930
using pip the command is right there

178
00:07:42,949 --> 00:07:49,259
that is the best way in my opinion to

179
00:07:45,930 --> 00:07:52,770
install that so this is the code that

180
00:07:49,259 --> 00:07:55,259
like I said is not super visible here

181
00:07:52,770 --> 00:07:59,698
and I'm sorry about that what we're

182
00:07:55,259 --> 00:08:04,409
interested in is the the function on

183
00:07:59,699 --> 00:08:06,030
line 25 and the for loop on line 35 the

184
00:08:04,409 --> 00:08:07,469
rest of this is just things that have

185
00:08:06,030 --> 00:08:10,559
been added in to actually make this

186
00:08:07,469 --> 00:08:14,940
functional but what we're doing here is

187
00:08:10,560 --> 00:08:16,560
we are actually taking the well we're

188
00:08:14,940 --> 00:08:19,259
importing the library the Google API

189
00:08:16,560 --> 00:08:21,780
client discovery you're importing build

190
00:08:19,259 --> 00:08:26,430
from that and then you're going to go

191
00:08:21,780 --> 00:08:30,179
ahead and on line 26 here you tell it to

192
00:08:26,430 --> 00:08:33,419
go ahead and build the service using a

193
00:08:30,180 --> 00:08:36,120
custom search which specifies what API

194
00:08:33,419 --> 00:08:40,199
you're going to hit the version 1 and

195
00:08:36,120 --> 00:08:44,039
then you give it the API key for your

196
00:08:40,200 --> 00:08:46,950
account on line 27 you go ahead and

197
00:08:44,039 --> 00:08:50,250
actually tell it to execute that by

198
00:08:46,950 --> 00:08:52,500
doing service CSE list you give it a

199
00:08:50,250 --> 00:08:53,040
search term you give it this custom

200
00:08:52,500 --> 00:08:55,170
search

201
00:08:53,040 --> 00:08:57,750
engine ID which is the other thing that

202
00:08:55,170 --> 00:08:59,729
you get from them when you create this

203
00:08:57,750 --> 00:09:04,170
and then it does take some keyword

204
00:08:59,730 --> 00:09:06,180
arguments and tell it to execute once

205
00:09:04,170 --> 00:09:09,810
you have that built you can take that

206
00:09:06,180 --> 00:09:11,969
function and create a query list which

207
00:09:09,810 --> 00:09:14,760
in my case what I'm doing is I'm taking

208
00:09:11,970 --> 00:09:18,260
a list of websites and a list of

209
00:09:14,760 --> 00:09:21,000
keywords that I want to use I am

210
00:09:18,260 --> 00:09:22,949
creating a you know reading the both of

211
00:09:21,000 --> 00:09:26,070
those into memory creating a list for

212
00:09:22,949 --> 00:09:28,740
both of those combining those as queries

213
00:09:26,070 --> 00:09:31,949
and then just running them through that

214
00:09:28,740 --> 00:09:35,790
Custom Search API to get results back

215
00:09:31,949 --> 00:09:37,889
from this this will give you back this

216
00:09:35,790 --> 00:09:40,920
specific thing will give you back the

217
00:09:37,889 --> 00:09:44,730
ten top results for each domain that you

218
00:09:40,920 --> 00:09:48,420
feed it and at this point you've got a

219
00:09:44,730 --> 00:09:51,420
list of however many results from Google

220
00:09:48,420 --> 00:09:56,310
that you want for the primary keyword in

221
00:09:51,420 --> 00:09:57,899
your list once we move on we'll see that

222
00:09:56,310 --> 00:10:00,479
we can actually start taking that

223
00:09:57,899 --> 00:10:03,149
information and feeding it into other

224
00:10:00,480 --> 00:10:04,949
libraries or other functions to do

225
00:10:03,149 --> 00:10:09,120
interesting things with it but this just

226
00:10:04,949 --> 00:10:11,189
gets us our initial results list the

227
00:10:09,120 --> 00:10:14,100
next thing that we're gonna take a look

228
00:10:11,190 --> 00:10:17,160
at here is beautiful soup beautiful soup

229
00:10:14,100 --> 00:10:19,440
is a really useful HTML parsing library

230
00:10:17,160 --> 00:10:23,430
so you've got this list of results from

231
00:10:19,440 --> 00:10:25,800
the Google API but you can't really do a

232
00:10:23,430 --> 00:10:29,849
whole lot with that unless you start

233
00:10:25,800 --> 00:10:32,099
parsing it parsing HTML using Python is

234
00:10:29,850 --> 00:10:34,230
somewhat difficult if you try to do it

235
00:10:32,100 --> 00:10:36,089
using like regular expressions or

236
00:10:34,230 --> 00:10:38,550
anything like that you will find very

237
00:10:36,089 --> 00:10:40,260
quickly that it doesn't really give you

238
00:10:38,550 --> 00:10:42,120
the results that you want and you're

239
00:10:40,260 --> 00:10:45,260
going to be fighting with a lot of you

240
00:10:42,120 --> 00:10:48,930
know the the structure of the HTML

241
00:10:45,260 --> 00:10:51,600
itself so beautiful soup will create a

242
00:10:48,930 --> 00:10:54,388
beautiful soup object and it maintains

243
00:10:51,600 --> 00:10:57,149
the structure of the page can be worked

244
00:10:54,389 --> 00:10:59,459
with in multiple ways it allows you to

245
00:10:57,149 --> 00:11:01,319
select portions of text from the page

246
00:10:59,459 --> 00:11:04,859
based on things like the tags the

247
00:11:01,319 --> 00:11:06,569
classes you can even actually use the

248
00:11:04,860 --> 00:11:10,380
find all and

249
00:11:06,570 --> 00:11:12,950
and attributes to locate specific words

250
00:11:10,380 --> 00:11:15,570
or specific phrases so if you want to

251
00:11:12,950 --> 00:11:18,630
and this is where regular expressions

252
00:11:15,570 --> 00:11:21,420
will come in handy you can actually give

253
00:11:18,630 --> 00:11:23,460
it a regular expression and tell it find

254
00:11:21,420 --> 00:11:26,969
these within the page and it will handle

255
00:11:23,460 --> 00:11:29,670
all of the you know I want to find it in

256
00:11:26,970 --> 00:11:32,790
the body I want to find this in you know

257
00:11:29,670 --> 00:11:35,130
any h1 tags I want to find this in these

258
00:11:32,790 --> 00:11:38,939
particular areas as opposed to just

259
00:11:35,130 --> 00:11:42,390
trying to use regex itself which it gets

260
00:11:38,940 --> 00:11:46,680
fairly complicated once again easy to

261
00:11:42,390 --> 00:11:49,710
install using pip so this is the

262
00:11:46,680 --> 00:11:51,750
specific code using a beautiful soup

263
00:11:49,710 --> 00:11:56,400
what you're gonna do is you're just

264
00:11:51,750 --> 00:11:59,340
going to say you know create the

265
00:11:56,400 --> 00:12:06,980
beautiful soup object which is we're

266
00:11:59,340 --> 00:12:10,940
looking at that on line where is this

267
00:12:06,980 --> 00:12:13,590
this may be the wrong file unfortunately

268
00:12:10,940 --> 00:12:17,640
but what we're gonna do is we're gonna

269
00:12:13,590 --> 00:12:21,060
say okay we have a result here usually

270
00:12:17,640 --> 00:12:24,180
you can use either the URL Lib library

271
00:12:21,060 --> 00:12:27,180
or I used results which is a separate

272
00:12:24,180 --> 00:12:29,819
library you would just say you know for

273
00:12:27,180 --> 00:12:32,880
this result go ahead and request that

274
00:12:29,820 --> 00:12:35,340
get that page download it and then take

275
00:12:32,880 --> 00:12:37,590
that and turn it into a beautiful soup

276
00:12:35,340 --> 00:12:40,140
object at which point once you've turned

277
00:12:37,590 --> 00:12:42,960
it into a beautiful soup object you can

278
00:12:40,140 --> 00:12:46,680
then do things like going through and

279
00:12:42,960 --> 00:12:49,080
finding all of the specific words for

280
00:12:46,680 --> 00:12:51,239
the key words that we mentioned earlier

281
00:12:49,080 --> 00:12:54,630
in the key word list so that you would

282
00:12:51,240 --> 00:12:56,100
just say okay our search word that we

283
00:12:54,630 --> 00:12:58,830
want to look for the key word that we

284
00:12:56,100 --> 00:13:00,630
want to look for is the first word in

285
00:12:58,830 --> 00:13:05,030
our keyword list we're gonna go ahead

286
00:13:00,630 --> 00:13:08,850
and say that the list of keywords is

287
00:13:05,030 --> 00:13:10,740
HTML soup body find all and then you

288
00:13:08,850 --> 00:13:15,330
just feed it the arguments that you want

289
00:13:10,740 --> 00:13:18,390
it to have in this case we're saying you

290
00:13:15,330 --> 00:13:20,100
know we're using a regex to format the

291
00:13:18,390 --> 00:13:23,399
search word finding that within

292
00:13:20,100 --> 00:13:27,600
thing that we've grabbed and returning

293
00:13:23,399 --> 00:13:29,490
that to us once we have that we can go

294
00:13:27,600 --> 00:13:31,440
ahead and start saying okay how many

295
00:13:29,490 --> 00:13:33,389
times does this word occur on the page

296
00:13:31,440 --> 00:13:35,759
that can be useful sometimes for

297
00:13:33,389 --> 00:13:38,339
prioritization so say you have a list of

298
00:13:35,759 --> 00:13:41,430
results from your custom search API and

299
00:13:38,339 --> 00:13:43,889
you want to figure out which of these

300
00:13:41,430 --> 00:13:47,219
are most relevant to me one of the

301
00:13:43,889 --> 00:13:50,699
things that I often do as opposed to you

302
00:13:47,220 --> 00:13:53,790
know Osen for things like you know pen

303
00:13:50,699 --> 00:13:56,969
tests or that kind of thing is working

304
00:13:53,790 --> 00:13:58,680
with clients who want to see what type

305
00:13:56,970 --> 00:14:00,600
of information about them is out there

306
00:13:58,680 --> 00:14:02,670
and then figure out how to remediate

307
00:14:00,600 --> 00:14:04,740
some of that if they're worried about

308
00:14:02,670 --> 00:14:07,079
you know this specific thing is out

309
00:14:04,740 --> 00:14:09,870
there so using this as a prioritization

310
00:14:07,079 --> 00:14:13,430
scheme allows you to go ahead and say

311
00:14:09,870 --> 00:14:16,319
okay we're gonna focus on which of these

312
00:14:13,430 --> 00:14:18,930
results has the highest concentration of

313
00:14:16,319 --> 00:14:20,969
the primary keyword and then the other

314
00:14:18,930 --> 00:14:24,180
keywords that we've put in our keyword

315
00:14:20,970 --> 00:14:26,639
file and that'll allow us to say okay we

316
00:14:24,180 --> 00:14:31,560
need to focus on this first as a

317
00:14:26,639 --> 00:14:33,569
priority in our remediations the next

318
00:14:31,560 --> 00:14:37,079
place to go with this is the google

319
00:14:33,569 --> 00:14:39,000
cloud language api it can be created on

320
00:14:37,079 --> 00:14:41,609
the same Google cloud billing account as

321
00:14:39,000 --> 00:14:44,630
the custom search engine so once again

322
00:14:41,610 --> 00:14:48,240
you get that $300 to you know

323
00:14:44,630 --> 00:14:52,370
offset the cost of actually hitting the

324
00:14:48,240 --> 00:14:56,160
API there also it's installed via pip

325
00:14:52,370 --> 00:14:59,069
the library itself is just Google -

326
00:14:56,160 --> 00:15:01,050
cloud - language this is slightly

327
00:14:59,069 --> 00:15:03,920
different in terms of how you actually

328
00:15:01,050 --> 00:15:07,258
do the credentials it will give you a

329
00:15:03,920 --> 00:15:09,360
JSON file containing that credentials

330
00:15:07,259 --> 00:15:12,209
you have to export that to your

331
00:15:09,360 --> 00:15:13,620
environment variables there are other

332
00:15:12,209 --> 00:15:15,300
ways to do it but I've found that this

333
00:15:13,620 --> 00:15:17,069
is the easiest one especially if you're

334
00:15:15,300 --> 00:15:20,508
running it on something that isn't gonna

335
00:15:17,069 --> 00:15:24,420
be rebooting frequently this allows for

336
00:15:20,509 --> 00:15:26,550
analysis of entities it allows for

337
00:15:24,420 --> 00:15:28,620
analysis of the sentiment of the overall

338
00:15:26,550 --> 00:15:31,349
document and it also allows you to

339
00:15:28,620 --> 00:15:33,400
analyze the sentiment towards specific

340
00:15:31,350 --> 00:15:36,090
entities that you find

341
00:15:33,400 --> 00:15:39,010
so one of the things that you can do is

342
00:15:36,090 --> 00:15:41,740
go ahead and take the beautiful soup

343
00:15:39,010 --> 00:15:46,930
objects that we created in the last the

344
00:15:41,740 --> 00:15:48,670
last slide there you pull out whatever

345
00:15:46,930 --> 00:15:50,170
text you want from that whether that's

346
00:15:48,670 --> 00:15:52,300
the body whether that's the headers

347
00:15:50,170 --> 00:15:54,699
whether it's all of the text and then

348
00:15:52,300 --> 00:15:56,620
you go ahead and you feed it into the

349
00:15:54,700 --> 00:15:58,920
cloud language API now the cloud

350
00:15:56,620 --> 00:16:01,750
language API has a few different ways of

351
00:15:58,920 --> 00:16:05,800
getting the information that you want it

352
00:16:01,750 --> 00:16:08,800
you can feed it raw text plain text you

353
00:16:05,800 --> 00:16:12,130
can also if you are working within the

354
00:16:08,800 --> 00:16:14,949
actual Google Cloud it will allow you to

355
00:16:12,130 --> 00:16:18,130
access content that is stored on their

356
00:16:14,950 --> 00:16:20,470
cloud just using the URL so instead of

357
00:16:18,130 --> 00:16:23,140
having to pull the beautifulsoup object

358
00:16:20,470 --> 00:16:24,850
pull out the text and feed it in you can

359
00:16:23,140 --> 00:16:26,710
just say okay access this resource

360
00:16:24,850 --> 00:16:29,890
that's stored on the Google cloud

361
00:16:26,710 --> 00:16:31,840
platform I am NOT using the Google cloud

362
00:16:29,890 --> 00:16:35,110
platform so I'm not doing that here that

363
00:16:31,840 --> 00:16:38,650
is another way of getting the resources

364
00:16:35,110 --> 00:16:40,900
that you want into the the cloud API so

365
00:16:38,650 --> 00:16:44,650
what we've done here is we've gone ahead

366
00:16:40,900 --> 00:16:47,260
and we've created our client which is

367
00:16:44,650 --> 00:16:49,540
the language language language service

368
00:16:47,260 --> 00:16:51,250
client we've given it the document which

369
00:16:49,540 --> 00:16:55,300
is the document that you're going to be

370
00:16:51,250 --> 00:16:57,250
feeding it and then we have declared

371
00:16:55,300 --> 00:17:00,160
what our response is going to be as well

372
00:16:57,250 --> 00:17:04,109
we want to analyze the sentiment of this

373
00:17:00,160 --> 00:17:07,119
document at that point you go ahead and

374
00:17:04,109 --> 00:17:09,310
take your list of results once again

375
00:17:07,119 --> 00:17:11,379
you're going to pull down the results

376
00:17:09,310 --> 00:17:14,169
create a beautiful soup object with it

377
00:17:11,380 --> 00:17:16,420
pull out the body text and then go ahead

378
00:17:14,170 --> 00:17:18,610
and feed it back into this function that

379
00:17:16,420 --> 00:17:22,000
we've created that will get the actual

380
00:17:18,609 --> 00:17:24,639
object get the actual sentiments for you

381
00:17:22,000 --> 00:17:26,709
print out the sentiment scores so this

382
00:17:24,640 --> 00:17:28,449
is going to be useful in situations for

383
00:17:26,709 --> 00:17:31,780
me once again where we're not

384
00:17:28,449 --> 00:17:33,610
necessarily dealing with I'm doing you

385
00:17:31,780 --> 00:17:35,920
know intelligence gathering for a pen

386
00:17:33,610 --> 00:17:39,070
test but say you have a client who is

387
00:17:35,920 --> 00:17:41,290
concerned about information that is out

388
00:17:39,070 --> 00:17:43,720
there and wants to monitor how people

389
00:17:41,290 --> 00:17:45,370
are feeling about them personally how

390
00:17:43,720 --> 00:17:47,080
people are feeling about their company

391
00:17:45,370 --> 00:17:48,629
how people are feeling about

392
00:17:47,080 --> 00:17:51,760
product that they are about to release

393
00:17:48,630 --> 00:17:53,710
this will allow you to go ahead and take

394
00:17:51,760 --> 00:17:57,190
a bunch of results feed it through and

395
00:17:53,710 --> 00:17:59,409
get back an analysis of you know what

396
00:17:57,190 --> 00:18:01,899
are people talking about what are they

397
00:17:59,409 --> 00:18:04,480
feeling about it if they're talking

398
00:18:01,899 --> 00:18:06,219
about other companies alongside of your

399
00:18:04,480 --> 00:18:07,990
company so you know you're a company and

400
00:18:06,220 --> 00:18:10,360
you want to figure out what other

401
00:18:07,990 --> 00:18:13,120
companies are being talked about in

402
00:18:10,360 --> 00:18:15,639
comparison to you this is one way that

403
00:18:13,120 --> 00:18:19,209
you can go ahead and automate that kind

404
00:18:15,640 --> 00:18:20,559
of thing so now we're gonna move on to

405
00:18:19,210 --> 00:18:25,690
fuzzy wuzzy

406
00:18:20,559 --> 00:18:28,990
fuzzy wuzzy is a library that allows you

407
00:18:25,690 --> 00:18:31,960
to do edit distance comparisons

408
00:18:28,990 --> 00:18:36,100
comparisons specifically it's using the

409
00:18:31,960 --> 00:18:38,380
levenshtein distance formula this is

410
00:18:36,100 --> 00:18:40,178
useful if you've got a situation where

411
00:18:38,380 --> 00:18:42,899
you have a page that certain key words

412
00:18:40,179 --> 00:18:45,669
are misspelled or abbreviated or

413
00:18:42,899 --> 00:18:47,559
anything like that you can tell it okay

414
00:18:45,669 --> 00:18:51,370
I also want to find keywords in this

415
00:18:47,559 --> 00:18:53,590
page that are you know similar to my

416
00:18:51,370 --> 00:18:55,209
keyword but not exactly my keyword maybe

417
00:18:53,590 --> 00:18:56,740
somebody abbreviated it maybe somebody

418
00:18:55,210 --> 00:18:57,970
misspelled it but we don't want to miss

419
00:18:56,740 --> 00:19:00,070
those because those are still going to

420
00:18:57,970 --> 00:19:02,740
be useful to us they still want to be

421
00:19:00,070 --> 00:19:07,269
added into things like a priority score

422
00:19:02,740 --> 00:19:09,820
etc fuzzy-wuzzy can be installed once

423
00:19:07,269 --> 00:19:12,190
again using pip I recommend using the

424
00:19:09,820 --> 00:19:16,240
speed up option which also will install

425
00:19:12,190 --> 00:19:18,850
the Python levenshtein package and that

426
00:19:16,240 --> 00:19:20,710
speeds it up significantly in terms of

427
00:19:18,850 --> 00:19:24,610
how quickly it does those edit distance

428
00:19:20,710 --> 00:19:26,610
comparisons so here we've got and I feel

429
00:19:24,610 --> 00:19:29,320
bad that this code is so small because

430
00:19:26,610 --> 00:19:31,000
once again you can't see it perfectly

431
00:19:29,320 --> 00:19:32,830
well but it is available online if you

432
00:19:31,000 --> 00:19:34,840
want to go look at it later

433
00:19:32,830 --> 00:19:38,019
here we've basically just got something

434
00:19:34,840 --> 00:19:40,360
that's again using the cloud language

435
00:19:38,019 --> 00:19:42,730
API to pull out all of the entities and

436
00:19:40,360 --> 00:19:45,668
then running it through fuzzy-wuzzy to

437
00:19:42,730 --> 00:19:48,760
say how many entities are on this page

438
00:19:45,669 --> 00:19:51,940
that also match our keywords that we

439
00:19:48,760 --> 00:19:55,270
feeded it that we fed it with a 90%

440
00:19:51,940 --> 00:19:59,139
ratio so an edit distance ratio of 90

441
00:19:55,270 --> 00:20:00,580
percent or if 90 excuse me and that will

442
00:19:59,139 --> 00:20:02,979
give you pages

443
00:20:00,580 --> 00:20:05,230
that are you know or results that are

444
00:20:02,980 --> 00:20:08,110
similar and relevant and still allow you

445
00:20:05,230 --> 00:20:10,870
to say okay you know we've got this this

446
00:20:08,110 --> 00:20:12,908
page it might not have our keyword

447
00:20:10,870 --> 00:20:15,908
spelled correctly across it on the whole

448
00:20:12,909 --> 00:20:17,769
thing but we can also take those

449
00:20:15,909 --> 00:20:20,890
misspelled keywords those abbreviated

450
00:20:17,769 --> 00:20:23,289
keywords anything that you know we still

451
00:20:20,890 --> 00:20:26,679
would want to have show up in our

452
00:20:23,289 --> 00:20:30,879
results and go ahead and you know take

453
00:20:26,679 --> 00:20:34,389
those as well we're again starting to

454
00:20:30,880 --> 00:20:36,490
build on each library using the google

455
00:20:34,389 --> 00:20:38,649
cloud language api and using

456
00:20:36,490 --> 00:20:40,389
beautifulsoup here to actually get the

457
00:20:38,649 --> 00:20:42,279
text that we're feeding it there are

458
00:20:40,389 --> 00:20:43,840
different ways of implementing this as

459
00:20:42,279 --> 00:20:46,750
well obviously like I said you could use

460
00:20:43,840 --> 00:20:48,789
these you could you could store some of

461
00:20:46,750 --> 00:20:51,309
the things that you're looking at in the

462
00:20:48,789 --> 00:20:55,809
Google cloud platform but here we're

463
00:20:51,309 --> 00:20:58,000
using the request get to actually pull

464
00:20:55,809 --> 00:21:00,779
the page down which slows it down a

465
00:20:58,000 --> 00:21:04,179
little bit but not significantly enough

466
00:21:00,779 --> 00:21:06,220
that it's a problem

467
00:21:04,179 --> 00:21:09,279
the last library that we're going to

468
00:21:06,220 --> 00:21:13,840
talk about here is selenium selenium

469
00:21:09,279 --> 00:21:15,820
emulates a web browser and if you have

470
00:21:13,840 --> 00:21:18,309
situations where you want to monitor

471
00:21:15,820 --> 00:21:20,678
things on websites where you would need

472
00:21:18,309 --> 00:21:21,908
to log in selenium is really really

473
00:21:20,679 --> 00:21:25,149
useful

474
00:21:21,909 --> 00:21:27,730
it allows you to pass credentials and

475
00:21:25,149 --> 00:21:30,760
store cookies things of that nature so

476
00:21:27,730 --> 00:21:33,279
say you're working on a project where

477
00:21:30,760 --> 00:21:35,529
you want to monitor the sentiment or the

478
00:21:33,279 --> 00:21:39,010
you know the feeling that people are

479
00:21:35,529 --> 00:21:42,340
having of a specific product that's

480
00:21:39,010 --> 00:21:45,190
being released you want to look at tech

481
00:21:42,340 --> 00:21:47,230
websites that are talking about this so

482
00:21:45,190 --> 00:21:50,710
you know certain reddit subreddits

483
00:21:47,230 --> 00:21:53,080
hacker news you know tech news sites

484
00:21:50,710 --> 00:21:57,039
like wired or you know motherboard

485
00:21:53,080 --> 00:21:59,710
device you could sometimes run into

486
00:21:57,039 --> 00:22:00,190
situations where you're going to have a

487
00:21:59,710 --> 00:22:03,100
paywall

488
00:22:00,190 --> 00:22:05,559
or you're going to need to log in to get

489
00:22:03,100 --> 00:22:07,389
to certain places you know if you've got

490
00:22:05,559 --> 00:22:09,520
subreddits that are private that you

491
00:22:07,389 --> 00:22:11,559
want to monitor say you want to monitor

492
00:22:09,520 --> 00:22:13,539
major news websites like New York Times

493
00:22:11,559 --> 00:22:14,279
well they're only gonna give you five

494
00:22:13,539 --> 00:22:16,169
articles

495
00:22:14,279 --> 00:22:18,299
month and selenium is still gonna run

496
00:22:16,169 --> 00:22:19,799
into that if you don't feed it

497
00:22:18,299 --> 00:22:21,389
credentials but you have the option to

498
00:22:19,799 --> 00:22:23,549
feed it credentials and that makes it

499
00:22:21,389 --> 00:22:25,379
significantly more useful for being able

500
00:22:23,549 --> 00:22:27,539
to gather information from places where

501
00:22:25,379 --> 00:22:31,649
there are paywalls you know required

502
00:22:27,539 --> 00:22:34,019
logins that kind of thing and you can

503
00:22:31,649 --> 00:22:35,639
also use it using headless chrome which

504
00:22:34,019 --> 00:22:37,289
is super useful because then you don't

505
00:22:35,639 --> 00:22:39,539
have to actually have the browser in

506
00:22:37,289 --> 00:22:42,239
front of you you can feed it different

507
00:22:39,539 --> 00:22:43,590
user agents using a couple different

508
00:22:42,239 --> 00:22:45,539
libraries that are available for that

509
00:22:43,590 --> 00:22:48,269
that are a little outside the scope of

510
00:22:45,539 --> 00:22:51,359
this but there are several ways to work

511
00:22:48,269 --> 00:22:54,899
with this that can automate the things

512
00:22:51,359 --> 00:22:57,658
that you would need a browser to do so

513
00:22:54,899 --> 00:23:00,209
here we've got some code that's using

514
00:22:57,659 --> 00:23:03,589
selenium you're just going to go ahead

515
00:23:00,210 --> 00:23:06,179
and tell it what driver you want to use

516
00:23:03,589 --> 00:23:08,219
I'm using the chrome driver because I'm

517
00:23:06,179 --> 00:23:10,799
using headless chrome here so you give

518
00:23:08,219 --> 00:23:12,659
it the binary location you tell it you

519
00:23:10,799 --> 00:23:15,029
know these are the options I want to use

520
00:23:12,659 --> 00:23:17,190
you specify in this case that it's

521
00:23:15,029 --> 00:23:18,690
headless and then you go ahead and you

522
00:23:17,190 --> 00:23:20,009
actually create the driver which is

523
00:23:18,690 --> 00:23:23,969
going to be the thing that you use to

524
00:23:20,009 --> 00:23:25,919
grab the results you say you know use

525
00:23:23,969 --> 00:23:29,700
that driver to get in this case we're

526
00:23:25,919 --> 00:23:32,219
using Facebook Facebook has a really

527
00:23:29,700 --> 00:23:35,279
interesting list and I talked about this

528
00:23:32,219 --> 00:23:37,320
last year in my talk about OSINT for red

529
00:23:35,279 --> 00:23:39,089
teaming my son has a or excuse me

530
00:23:37,320 --> 00:23:42,509
Facebook has a really interesting list

531
00:23:39,089 --> 00:23:46,529
of ways to search content on people's

532
00:23:42,509 --> 00:23:48,419
pages you can get things like all of the

533
00:23:46,529 --> 00:23:51,330
events that they have attended all of

534
00:23:48,419 --> 00:23:54,059
their you know all of the places they've

535
00:23:51,330 --> 00:23:56,279
checked in all of the posts that they've

536
00:23:54,059 --> 00:23:59,009
been tagged in just by accessing a

537
00:23:56,279 --> 00:24:02,009
specific URL using their profile profile

538
00:23:59,009 --> 00:24:03,269
ID so this is this still has a few bugs

539
00:24:02,009 --> 00:24:05,639
in it that need to be worked out

540
00:24:03,269 --> 00:24:08,070
basically what this does is it takes the

541
00:24:05,639 --> 00:24:10,978
profile ID for a specific Facebook

542
00:24:08,070 --> 00:24:13,710
account goes through logs into Facebook

543
00:24:10,979 --> 00:24:15,869
grabs all of those pages opens them all

544
00:24:13,710 --> 00:24:17,999
up takes a screenshot and saves it which

545
00:24:15,869 --> 00:24:19,978
is super useful if you're doing Osen on

546
00:24:17,999 --> 00:24:22,589
a specific individual and you want to

547
00:24:19,979 --> 00:24:25,620
get all of this information without

548
00:24:22,589 --> 00:24:30,700
having to go through each of those pages

549
00:24:25,620 --> 00:24:33,610
so this brings us to the sort of putting

550
00:24:30,700 --> 00:24:38,410
together of all of these it's a program

551
00:24:33,610 --> 00:24:40,540
called sonnet ER this is also I forgot

552
00:24:38,410 --> 00:24:42,850
to put the repo URL in there I apologize

553
00:24:40,540 --> 00:24:45,430
but it's on my github so if you just

554
00:24:42,850 --> 00:24:47,080
look at the repos on the same github

555
00:24:45,430 --> 00:24:49,630
that the slides and the other code is on

556
00:24:47,080 --> 00:24:52,750
you'll see it it's a separate repo Zana

557
00:24:49,630 --> 00:24:55,300
der is the program that Eilat wrote when

558
00:24:52,750 --> 00:24:57,070
I went and gave her a bunch of scripts

559
00:24:55,300 --> 00:24:58,899
and asked her hey can you help me work

560
00:24:57,070 --> 00:25:00,490
out some bugs in this instead of working

561
00:24:58,900 --> 00:25:02,800
out some bugs in it she basically got

562
00:25:00,490 --> 00:25:05,820
bored and rewrote it in a weekend which

563
00:25:02,800 --> 00:25:08,169
is something that she tends to do and I

564
00:25:05,820 --> 00:25:12,790
didn't mind because what she wrote was a

565
00:25:08,170 --> 00:25:15,100
lot more interesting and useful once

566
00:25:12,790 --> 00:25:17,280
again it allows you to take a list of

567
00:25:15,100 --> 00:25:21,610
websites and a list of keywords and

568
00:25:17,280 --> 00:25:23,440
specify what keyword you want to you

569
00:25:21,610 --> 00:25:25,149
know what keyword you want to search as

570
00:25:23,440 --> 00:25:26,620
your primary keyword and then the

571
00:25:25,150 --> 00:25:30,610
websites that you want to search that

572
00:25:26,620 --> 00:25:33,520
across it uses the custom search engine

573
00:25:30,610 --> 00:25:36,520
to find the results and then it goes it

574
00:25:33,520 --> 00:25:39,879
goes and takes the cloud language API to

575
00:25:36,520 --> 00:25:41,680
find entity sentiments and it uses

576
00:25:39,880 --> 00:25:44,920
keyword weighting so instead of the

577
00:25:41,680 --> 00:25:47,110
somewhat you know hacky solutions I had

578
00:25:44,920 --> 00:25:49,360
earlier of just finding the number of

579
00:25:47,110 --> 00:25:51,850
times that the keyword apply is or

580
00:25:49,360 --> 00:25:54,189
appears in a page and then dividing that

581
00:25:51,850 --> 00:25:56,800
based on how much I want that keyword to

582
00:25:54,190 --> 00:25:59,620
wait this actually has a specific

583
00:25:56,800 --> 00:26:01,990
keyword waiting option she's used a

584
00:25:59,620 --> 00:26:05,110
library called config parser which is

585
00:26:01,990 --> 00:26:08,170
also outside the scope of this talk but

586
00:26:05,110 --> 00:26:10,870
it allows you to create a options file

587
00:26:08,170 --> 00:26:12,490
and a target file that will say you know

588
00:26:10,870 --> 00:26:14,889
okay I want this keyword waited at this

589
00:26:12,490 --> 00:26:16,990
this is how I want to wait the keywords

590
00:26:14,890 --> 00:26:20,560
you know based on their priorities

591
00:26:16,990 --> 00:26:24,240
things like that and it will allow you

592
00:26:20,560 --> 00:26:26,110
to monitor results and assign them

593
00:26:24,240 --> 00:26:28,030
priorities based on the keyword

594
00:26:26,110 --> 00:26:30,610
concentration and the entities that

595
00:26:28,030 --> 00:26:33,520
exist and then it will also get the

596
00:26:30,610 --> 00:26:36,189
entity sentiments and the overall

597
00:26:33,520 --> 00:26:38,269
sentiment analysis for the document that

598
00:26:36,190 --> 00:26:40,559
you feed it

599
00:26:38,269 --> 00:26:43,889
one of the things that I have been using

600
00:26:40,559 --> 00:26:47,220
this for since she went ahead in and

601
00:26:43,889 --> 00:26:49,949
gave this to me was using it as a cron

602
00:26:47,220 --> 00:26:52,080
job to monitor results consistently so

603
00:26:49,950 --> 00:26:54,840
if I have a client who says I'm

604
00:26:52,080 --> 00:26:56,009
releasing XYZ product I want to know how

605
00:26:54,840 --> 00:26:57,928
people feel about it

606
00:26:56,009 --> 00:27:00,029
and I want to know how people are how

607
00:26:57,929 --> 00:27:02,009
people are feeling about it over time I

608
00:27:00,029 --> 00:27:04,259
want to know if people's feelings about

609
00:27:02,009 --> 00:27:06,950
it change as they start using it more

610
00:27:04,259 --> 00:27:08,879
regularly say we have a client

611
00:27:06,950 --> 00:27:12,509
specifically for instance I have a

612
00:27:08,879 --> 00:27:16,230
client who has been subject to pretty

613
00:27:12,509 --> 00:27:18,330
pernicious individuals trying to hurt

614
00:27:16,230 --> 00:27:21,899
her reputation by constantly releasing a

615
00:27:18,330 --> 00:27:24,600
revenge porn video of her so using this

616
00:27:21,899 --> 00:27:26,729
script we're able to you know find that

617
00:27:24,600 --> 00:27:28,439
video when it pops up because they use

618
00:27:26,730 --> 00:27:30,299
the same keywords and then we're also

619
00:27:28,440 --> 00:27:32,519
able to monitor certain places where

620
00:27:30,299 --> 00:27:34,799
this is talked about to look at how

621
00:27:32,519 --> 00:27:37,049
people are responding to this being

622
00:27:34,799 --> 00:27:38,960
released our people you know sympathetic

623
00:27:37,049 --> 00:27:41,549
with her are people saying you know

624
00:27:38,960 --> 00:27:43,590
things about her that are sort of

625
00:27:41,549 --> 00:27:45,899
indicative of her reputation being

626
00:27:43,590 --> 00:27:47,850
harmed negatively because we want to

627
00:27:45,899 --> 00:27:49,739
store all of this so that if and when

628
00:27:47,850 --> 00:27:52,678
the individual who's responsible for

629
00:27:49,740 --> 00:27:54,509
this you know is able to be taken to

630
00:27:52,679 --> 00:27:55,679
court unfortunately at this point we

631
00:27:54,509 --> 00:27:58,860
don't have enough evidence to

632
00:27:55,679 --> 00:28:01,080
specifically do that but if and when we

633
00:27:58,860 --> 00:28:03,000
can take him to court we can use this

634
00:28:01,080 --> 00:28:05,970
and say look this is how this is

635
00:28:03,000 --> 00:28:09,389
actually concretely her reputation over

636
00:28:05,970 --> 00:28:11,789
time we can say over time we can see

637
00:28:09,389 --> 00:28:14,039
that this specific forum was discussing

638
00:28:11,789 --> 00:28:17,220
her and the sentiment analysis was

639
00:28:14,039 --> 00:28:18,840
positive and as these videos continue to

640
00:28:17,220 --> 00:28:20,970
be released and posted on different

641
00:28:18,840 --> 00:28:22,949
forums the sentiment analysis in this

642
00:28:20,970 --> 00:28:28,519
specific place shows that her reputation

643
00:28:22,950 --> 00:28:33,870
was actually harmed so I went ahead and

644
00:28:28,519 --> 00:28:37,169
did just a very broad you know use of

645
00:28:33,870 --> 00:28:39,959
this let's say we're looking at how

646
00:28:37,169 --> 00:28:43,230
people in Seattle feel about the idea of

647
00:28:39,960 --> 00:28:45,029
Amazon and specifically how they feel

648
00:28:43,230 --> 00:28:48,179
about the idea of Amazon Yunnan

649
00:28:45,029 --> 00:28:51,630
unionizing we're gonna look across once

650
00:28:48,179 --> 00:28:54,130
again just some very broad websites

651
00:28:51,630 --> 00:28:56,340
obviously some large news websites but

652
00:28:54,130 --> 00:28:59,399
then also some website specific to

653
00:28:56,340 --> 00:29:04,509
publishing news for the Seattle area

654
00:28:59,399 --> 00:29:06,969
what we get in the end is a CSV that

655
00:29:04,509 --> 00:29:10,179
gives us all of these results and then

656
00:29:06,970 --> 00:29:12,519
their priority score so we can see you

657
00:29:10,179 --> 00:29:14,470
know we've got the the Seattle PI com

658
00:29:12,519 --> 00:29:16,570
that's going to be the highest priority

659
00:29:14,470 --> 00:29:18,580
because it contains the most of our

660
00:29:16,570 --> 00:29:20,529
keywords and so we look at that and we

661
00:29:18,580 --> 00:29:22,360
say okay this is an article we should

662
00:29:20,529 --> 00:29:24,659
definitely look at in terms of seeing

663
00:29:22,360 --> 00:29:28,330
how people are feeling about the idea of

664
00:29:24,659 --> 00:29:31,240
Amazon and Amazon employees unionizing

665
00:29:28,330 --> 00:29:35,529
within the Seattle area and then it goes

666
00:29:31,240 --> 00:29:39,009
on this when the CSV are initially is

667
00:29:35,529 --> 00:29:41,470
exported or it was saved this is not

668
00:29:39,009 --> 00:29:43,870
sorted but it's really easy to just say

669
00:29:41,470 --> 00:29:46,269
sort based on the value in the priority

670
00:29:43,870 --> 00:29:48,459
column and then you can look at that and

671
00:29:46,269 --> 00:29:50,799
say these are the ones that we need to

672
00:29:48,460 --> 00:29:52,779
work with these are very broad results

673
00:29:50,799 --> 00:29:55,090
because once again we're using a very

674
00:29:52,779 --> 00:29:56,740
broad subject here and Jeff Bezos and

675
00:29:55,090 --> 00:29:59,649
Amazon is something that's talked about

676
00:29:56,740 --> 00:30:01,779
very broadly but if you're using this

677
00:29:59,649 --> 00:30:04,479
for a smaller situation a smaller

678
00:30:01,779 --> 00:30:06,009
company things like that there are other

679
00:30:04,480 --> 00:30:08,500
ways that you could use this you could

680
00:30:06,009 --> 00:30:11,679
use this to look for things like

681
00:30:08,500 --> 00:30:14,379
sensitive keywords for company projects

682
00:30:11,679 --> 00:30:17,259
being posted on various websites that

683
00:30:14,379 --> 00:30:19,928
you think might you know might have that

684
00:30:17,259 --> 00:30:22,330
information if you were wanting to say

685
00:30:19,929 --> 00:30:24,370
look for credential leaks for your

686
00:30:22,330 --> 00:30:26,139
company you could use this to go and

687
00:30:24,370 --> 00:30:27,699
look at the various pastebin websites

688
00:30:26,139 --> 00:30:30,820
where oftentimes people would paste

689
00:30:27,700 --> 00:30:33,460
credential leaks and then monitor for

690
00:30:30,820 --> 00:30:36,668
specific keywords whether that be your

691
00:30:33,460 --> 00:30:38,559
company name the actual user names of

692
00:30:36,669 --> 00:30:41,169
certain individuals within your

693
00:30:38,559 --> 00:30:43,480
organization things like that and then

694
00:30:41,169 --> 00:30:46,149
obviously get a priority based on you

695
00:30:43,480 --> 00:30:48,340
know okay this has a lot of our keywords

696
00:30:46,149 --> 00:30:50,110
this looks like it could be an

697
00:30:48,340 --> 00:30:53,230
information leak or a credential leak or

698
00:30:50,110 --> 00:30:55,840
something of that that basis once again

699
00:30:53,230 --> 00:30:58,539
in my situation if I've got clients who

700
00:30:55,840 --> 00:31:00,519
are wanting to know you know how are

701
00:30:58,539 --> 00:31:02,980
people where are people talking about me

702
00:31:00,519 --> 00:31:04,659
related to these specific subjects this

703
00:31:02,980 --> 00:31:06,220
would give me the opportunity to say

704
00:31:04,659 --> 00:31:07,960
okay let's put you know the client name

705
00:31:06,220 --> 00:31:10,090
is the main keyword and then those

706
00:31:07,960 --> 00:31:11,799
subjects that they're looking for here

707
00:31:10,090 --> 00:31:13,749
are the the the places where that's

708
00:31:11,799 --> 00:31:16,779
being talked about here the highest

709
00:31:13,749 --> 00:31:18,190
priority places with where that's being

710
00:31:16,779 --> 00:31:20,200
talked about these are the places that

711
00:31:18,190 --> 00:31:22,599
we need to worry about triaging for one

712
00:31:20,200 --> 00:31:24,940
reason or another and then it also is

713
00:31:22,599 --> 00:31:28,239
going to give you the sentiment analysis

714
00:31:24,940 --> 00:31:34,269
for the keyword that you that it finds

715
00:31:28,239 --> 00:31:36,849
most frequently in that so once again

716
00:31:34,269 --> 00:31:40,690
we've got you know Amazon is a fairly

717
00:31:36,849 --> 00:31:44,289
frequent keyword you can again sort this

718
00:31:40,690 --> 00:31:47,409
document based on the sentiment where

719
00:31:44,289 --> 00:31:52,720
the magnitude score which will allow you

720
00:31:47,409 --> 00:31:54,970
to see you know how how positive or how

721
00:31:52,720 --> 00:31:57,489
negative is this sentiment is this

722
00:31:54,970 --> 00:31:59,019
sentiment overwhelmingly good maybe we

723
00:31:57,489 --> 00:32:00,580
don't care about the overwhelmingly good

724
00:31:59,019 --> 00:32:02,409
ones maybe we want to look at the ones

725
00:32:00,580 --> 00:32:04,389
at the bottom where the sentiment is

726
00:32:02,409 --> 00:32:06,549
overwhelmingly negative and so the

727
00:32:04,389 --> 00:32:08,320
sentiment score is gonna tell you this

728
00:32:06,549 --> 00:32:10,918
is positive this is negative the

729
00:32:08,320 --> 00:32:14,559
magnitude score is gonna tell you it's

730
00:32:10,919 --> 00:32:16,299
overwhelmingly one or the other or maybe

731
00:32:14,559 --> 00:32:18,849
it's just in the middle maybe it's not

732
00:32:16,299 --> 00:32:20,799
very overwhelmingly positive or negative

733
00:32:18,849 --> 00:32:22,809
at all maybe it's just sort of slightly

734
00:32:20,799 --> 00:32:24,729
off neutral one way or the other and

735
00:32:22,809 --> 00:32:26,229
that's gonna be able to tell you where

736
00:32:24,729 --> 00:32:28,269
you need to look if you're looking for

737
00:32:26,229 --> 00:32:29,799
things like you know negative

738
00:32:28,269 --> 00:32:32,799
discussions of company negative

739
00:32:29,799 --> 00:32:35,559
discussions of an individual you know

740
00:32:32,799 --> 00:32:38,950
and and if you're trying to triage those

741
00:32:35,559 --> 00:32:40,690
you know say you're in PR or something

742
00:32:38,950 --> 00:32:43,059
of that nature you've released a product

743
00:32:40,690 --> 00:32:44,889
you see there are some places out there

744
00:32:43,059 --> 00:32:46,690
where there are negative discussions

745
00:32:44,889 --> 00:32:49,799
about your product this will allow you

746
00:32:46,690 --> 00:32:52,479
to automate pulling all of that up and

747
00:32:49,799 --> 00:32:57,299
looking at the results that need to be

748
00:32:52,479 --> 00:32:59,409
specifically taken care of to begin with

749
00:32:57,299 --> 00:33:03,190
so obviously once again there's

750
00:32:59,409 --> 00:33:06,009
potential uses monitor the online

751
00:33:03,190 --> 00:33:09,429
sentiment of a person a product or an

752
00:33:06,009 --> 00:33:12,039
event you can once again look at

753
00:33:09,429 --> 00:33:14,739
monitoring for potential data leaks and

754
00:33:12,039 --> 00:33:16,749
then just automate portions of ongoing

755
00:33:14,739 --> 00:33:18,100
Osen and honestly I'm sure that there

756
00:33:16,749 --> 00:33:20,289
are uses out there that I

757
00:33:18,100 --> 00:33:22,030
haven't even considered or thought of if

758
00:33:20,289 --> 00:33:23,650
anybody has any that they are

759
00:33:22,030 --> 00:33:25,690
immediately thinking hey this could be

760
00:33:23,650 --> 00:33:26,980
useful for this I'd love to hear about

761
00:33:25,690 --> 00:33:28,890
it because I'm sure that there are other

762
00:33:26,980 --> 00:33:32,919
places where this could be useful

763
00:33:28,890 --> 00:33:35,140
there's a few to do's for sonnet ER and

764
00:33:32,919 --> 00:33:37,000
we would love to get community

765
00:33:35,140 --> 00:33:40,030
contributions on this we are open

766
00:33:37,000 --> 00:33:42,370
sourcing it so we want people to go

767
00:33:40,030 --> 00:33:44,260
ahead and give us feedback use it find

768
00:33:42,370 --> 00:33:46,659
bugs file issues file

769
00:33:44,260 --> 00:33:48,940
you know submit pull requests we will

770
00:33:46,660 --> 00:33:50,320
definitely take those seriously one of

771
00:33:48,940 --> 00:33:52,480
the things that we need to do right off

772
00:33:50,320 --> 00:33:54,520
the bat is we need to implement selenium

773
00:33:52,480 --> 00:33:56,409
support so that it can do those things

774
00:33:54,520 --> 00:33:59,049
like logging into websites handling

775
00:33:56,409 --> 00:34:01,690
credentials handling cookies that's a

776
00:33:59,049 --> 00:34:04,990
fairly difficult not fairly difficult

777
00:34:01,690 --> 00:34:06,730
but fairly time intensive process so

778
00:34:04,990 --> 00:34:08,980
that is one of the things that is left

779
00:34:06,730 --> 00:34:11,199
to do and then also we're working on

780
00:34:08,980 --> 00:34:14,800
setting it up to track results across

781
00:34:11,199 --> 00:34:17,830
time and actually be able to graph out

782
00:34:14,800 --> 00:34:19,869
things like changes in sentiment so that

783
00:34:17,830 --> 00:34:23,350
if you need to look at that kind of

784
00:34:19,869 --> 00:34:25,929
thing it's easily available and easily

785
00:34:23,350 --> 00:34:28,270
visualized for you as opposed to having

786
00:34:25,929 --> 00:34:31,090
to go and say let's look at each

787
00:34:28,270 --> 00:34:34,719
individual output document and see how

788
00:34:31,090 --> 00:34:36,070
the sentiment has changed manually so

789
00:34:34,719 --> 00:34:37,989
those are some of the things that we're

790
00:34:36,070 --> 00:34:41,379
still working on doing if anybody you

791
00:34:37,989 --> 00:34:42,699
know has the itch to go ahead and you

792
00:34:41,379 --> 00:34:46,389
know work on that with us we definitely

793
00:34:42,699 --> 00:34:49,388
welcome those community contributions so

794
00:34:46,389 --> 00:34:50,830
I am kind of sped through this so I'm

795
00:34:49,389 --> 00:34:53,040
done a little early but are there any

796
00:34:50,830 --> 00:34:53,040
questions

797
00:34:56,639 --> 00:34:59,640
okay

798
00:35:05,620 --> 00:35:12,580
your selenium connection is it connected

799
00:35:09,200 --> 00:35:12,580
with selenium on a server

800
00:35:12,680 --> 00:35:20,788
no it is making the connection directly

801
00:35:15,569 --> 00:35:26,490
from your computer to the the result

802
00:35:20,789 --> 00:35:29,240
that you're wanting to access the

803
00:35:26,490 --> 00:35:32,430
question was is the the selenium

804
00:35:29,240 --> 00:35:51,029
implementation is it using a server or

805
00:35:32,430 --> 00:35:54,269
where or not your own account the key

806
00:35:51,029 --> 00:35:56,250
the question was where you get the API

807
00:35:54,269 --> 00:35:58,709
keys if those are something that are out

808
00:35:56,250 --> 00:36:00,150
there you know for everyone to use or if

809
00:35:58,710 --> 00:36:02,130
you have to have your own account the

810
00:36:00,150 --> 00:36:06,390
keys are associated with a Google cloud

811
00:36:02,130 --> 00:36:09,299
billing account which is where you you

812
00:36:06,390 --> 00:36:12,808
get the keys both for the cloud language

813
00:36:09,299 --> 00:36:15,150
API and the Custom Search API both of

814
00:36:12,809 --> 00:36:17,460
those once again like I said will give

815
00:36:15,150 --> 00:36:19,319
you $300 in credit to begin with so

816
00:36:17,460 --> 00:36:21,839
that's why it's it's useful to have your

817
00:36:19,319 --> 00:36:24,240
own account because you can you know

818
00:36:21,839 --> 00:36:28,740
easily just recreate those accounts and

819
00:36:24,240 --> 00:36:36,930
get yourself more credit on that any

820
00:36:28,740 --> 00:36:39,509
other questions is there when you doing

821
00:36:36,930 --> 00:36:41,430
these searches

822
00:36:39,510 --> 00:36:45,270
Google also tracking what you're

823
00:36:41,430 --> 00:36:46,919
searching to make a correlation there so

824
00:36:45,270 --> 00:36:48,570
because you're running the searches

825
00:36:46,920 --> 00:36:52,860
through Google it is going to be

826
00:36:48,570 --> 00:36:54,810
tracking that there are instances where

827
00:36:52,860 --> 00:36:57,900
I don't want that to be the case and so

828
00:36:54,810 --> 00:37:00,990
I've written some other web scrapers

829
00:36:57,900 --> 00:37:04,710
that don't use Google specifically that

830
00:37:00,990 --> 00:37:07,020
will look at specific pages and then

831
00:37:04,710 --> 00:37:09,420
crawl out and find the links off those

832
00:37:07,020 --> 00:37:11,310
pages and actually create its own you

833
00:37:09,420 --> 00:37:14,160
know sort of index of domains that it's

834
00:37:11,310 --> 00:37:16,170
looking at but those I'm not I'm not

835
00:37:14,160 --> 00:37:19,470
ready or willing to open source because

836
00:37:16,170 --> 00:37:25,290
they're just too proprietary it's in my

837
00:37:19,470 --> 00:37:26,399
specific process yeah you could

838
00:37:25,290 --> 00:37:28,650
definitely do that and we would

839
00:37:26,400 --> 00:37:30,300
definitely welcome that you know there

840
00:37:28,650 --> 00:37:33,450
are several other search engines that

841
00:37:30,300 --> 00:37:36,330
have api's that you can hit that would

842
00:37:33,450 --> 00:37:39,509
you know do similar things and allow you

843
00:37:36,330 --> 00:37:41,250
to get even more data in terms of you

844
00:37:39,510 --> 00:37:43,880
know how things are ranked and things

845
00:37:41,250 --> 00:37:43,880
like that so

846
00:37:54,670 --> 00:38:00,289
not worked with law enforcement

847
00:37:57,490 --> 00:38:03,618
specifically with this program I have

848
00:38:00,289 --> 00:38:07,700
done some work with law enforcement on a

849
00:38:03,619 --> 00:38:10,730
few different things but this has come

850
00:38:07,700 --> 00:38:13,730
about sort of sense that that work was

851
00:38:10,730 --> 00:38:17,150
done so no but I could actually see how

852
00:38:13,730 --> 00:38:18,499
that could be useful that you know there

853
00:38:17,150 --> 00:38:30,079
would be places where that would be

854
00:38:18,499 --> 00:38:32,868
applicable I have built it specifically

855
00:38:30,079 --> 00:38:35,539
for monitoring specific domain names but

856
00:38:32,869 --> 00:38:37,640
you could definitely take it and rip

857
00:38:35,539 --> 00:38:40,400
that portion out and just have it be

858
00:38:37,640 --> 00:38:43,999
doing searches you know through Google

859
00:38:40,400 --> 00:38:46,940
calm right now the the way it builds the

860
00:38:43,999 --> 00:38:52,249
query is you know using site colon

861
00:38:46,940 --> 00:38:54,589
domain name space keyword but you don't

862
00:38:52,249 --> 00:38:57,140
have to do it that way I did it that way

863
00:38:54,589 --> 00:38:59,359
because a lot of times the things that I

864
00:38:57,140 --> 00:39:01,879
am looking at I want to be looking at

865
00:38:59,359 --> 00:39:04,759
specific websites because we know that

866
00:39:01,880 --> 00:39:06,499
those are the places that certain things

867
00:39:04,759 --> 00:39:09,349
need to be monitored consistently

868
00:39:06,499 --> 00:39:11,359
usually this is based on the results of

869
00:39:09,349 --> 00:39:13,549
having done some manual open source

870
00:39:11,359 --> 00:39:15,619
intelligence gathering and then finding

871
00:39:13,549 --> 00:39:19,249
things that we need to consistently

872
00:39:15,619 --> 00:39:21,140
monitor and keep you know a close eye on

873
00:39:19,249 --> 00:39:23,538
but you don't have to do it that way you

874
00:39:21,140 --> 00:39:25,549
could easily rip that portion out if you

875
00:39:23,539 --> 00:39:28,700
wanted to fork it and you know make your

876
00:39:25,549 --> 00:39:31,999
own version that doesn't use the you

877
00:39:28,700 --> 00:39:46,220
know the domain argument no you don't

878
00:39:31,999 --> 00:39:50,359
have to do that at all go ahead about

879
00:39:46,220 --> 00:39:54,439
doing that way I don't really play the

880
00:39:50,359 --> 00:39:57,348
stock market um I have my little IRA

881
00:39:54,440 --> 00:39:57,980
that I contribute to and that's about

882
00:39:57,349 --> 00:39:59,779
all I do

883
00:39:57,980 --> 00:40:03,589
but yeah you probably could use it for

884
00:39:59,779 --> 00:40:05,660
that you know feed it a list of the

885
00:40:03,589 --> 00:40:07,380
common websites that you would look at

886
00:40:05,660 --> 00:40:09,660
for that kind of thing and then you

887
00:40:07,380 --> 00:40:12,810
get back that sentiment analysis and

888
00:40:09,660 --> 00:40:16,470
whatnot I have recommended the cloud

889
00:40:12,810 --> 00:40:18,750
language API to a friend who does do

890
00:40:16,470 --> 00:40:21,959
investing and you know wants to sort of

891
00:40:18,750 --> 00:40:25,530
build something to do specifically

892
00:40:21,960 --> 00:40:27,240
looking at that kind of thing so that is

893
00:40:25,530 --> 00:40:29,220
a place where you know that library

894
00:40:27,240 --> 00:40:32,359
specifically and and you know maybe this

895
00:40:29,220 --> 00:40:32,359
in general would be useful

896
00:40:35,300 --> 00:40:43,890
any other questions all right well I'll

897
00:40:41,190 --> 00:40:45,600
go ahead and finish up early then that

898
00:40:43,890 --> 00:40:47,339
gives you guys time to run and get

899
00:40:45,600 --> 00:40:50,009
unlimited mimosas still I believe

900
00:40:47,340 --> 00:40:51,970
because they're available till 11:00

901
00:40:50,010 --> 00:40:56,340
so thank you all for coming

902
00:40:51,970 --> 00:40:56,339
[Applause]

