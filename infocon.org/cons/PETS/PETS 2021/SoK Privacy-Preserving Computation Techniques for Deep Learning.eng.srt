1
00:00:00,240 --> 00:00:01,760
my name is jose and in collaboration

2
00:00:01,760 --> 00:00:03,439
with sergio pastrana we have made this

3
00:00:03,439 --> 00:00:05,279
sop on privacy-preserving computation

4
00:00:05,279 --> 00:00:07,040
techniques for deep learning

5
00:00:07,040 --> 00:00:08,880
in this work we have analyzed over 30

6
00:00:08,880 --> 00:00:10,559
state-of-the-art contributions

7
00:00:10,559 --> 00:00:12,080
our goal was to understand how

8
00:00:12,080 --> 00:00:13,679
cryptographic techniques to compute

9
00:00:13,679 --> 00:00:15,440
privately can be applied to deep

10
00:00:15,440 --> 00:00:16,560
learning

11
00:00:16,560 --> 00:00:18,640
for that we have analyzed the different

12
00:00:18,640 --> 00:00:20,160
tools and techniques that authors have

13
00:00:20,160 --> 00:00:21,520
proposed

14
00:00:21,520 --> 00:00:23,519
we aim to evaluate the efficiency and

15
00:00:23,519 --> 00:00:25,439
usability of the different proposals and

16
00:00:25,439 --> 00:00:27,119
to understand future lines of research

17
00:00:27,119 --> 00:00:28,480
in this area

18
00:00:28,480 --> 00:00:30,640
this is an overall view of the paper

19
00:00:30,640 --> 00:00:32,558
first to protect deep learning we need

20
00:00:32,558 --> 00:00:33,840
to understand which are the privacy

21
00:00:33,840 --> 00:00:35,840
benefits we want to obtain from it

22
00:00:35,840 --> 00:00:37,760
once we know the goals we can detail the

23
00:00:37,760 --> 00:00:39,520
different cryptographic mechanisms that

24
00:00:39,520 --> 00:00:41,840
ensure partially or totally these goals

25
00:00:41,840 --> 00:00:43,600
some authors purposely introduce

26
00:00:43,600 --> 00:00:44,960
modifications to the use of the

27
00:00:44,960 --> 00:00:46,559
mechanisms in what we name

28
00:00:46,559 --> 00:00:48,160
protocols to ensure more privacy

29
00:00:48,160 --> 00:00:50,000
guarantees

30
00:00:50,000 --> 00:00:51,680
to start i would like to give you a

31
00:00:51,680 --> 00:00:53,199
glimpse of what deep learning is and how

32
00:00:53,199 --> 00:00:55,039
we use deep learning nowadays

33
00:00:55,039 --> 00:00:56,879
deep learning is a set of statistical

34
00:00:56,879 --> 00:00:58,879
models which are able to learn from data

35
00:00:58,879 --> 00:00:59,440
sets

36
00:00:59,440 --> 00:01:01,440
in this work we focus on supervised

37
00:01:01,440 --> 00:01:03,440
learning that is when we learn from data

38
00:01:03,440 --> 00:01:05,040
sets where we know the expected input

39
00:01:05,040 --> 00:01:06,640
and output of the data set

40
00:01:06,640 --> 00:01:08,880
deep learning is carried out into phases

41
00:01:08,880 --> 00:01:10,560
first we make a training phase

42
00:01:10,560 --> 00:01:12,159
where we extract correlations from the

43
00:01:12,159 --> 00:01:14,479
labeled dataset into a mod

44
00:01:14,479 --> 00:01:16,159
then we can use the extracted

45
00:01:16,159 --> 00:01:18,400
correlations in order to predict unseen

46
00:01:18,400 --> 00:01:19,840
data

47
00:01:19,840 --> 00:01:21,200
the main building blocks of deep

48
00:01:21,200 --> 00:01:23,040
learning models are called layers which

49
00:01:23,040 --> 00:01:24,960
are usually executed sequentially

50
00:01:24,960 --> 00:01:26,960
authors have proposed different types of

51
00:01:26,960 --> 00:01:28,000
layers over time

52
00:01:28,000 --> 00:01:29,840
which adapt to different characteristics

53
00:01:29,840 --> 00:01:32,000
of the data however for this work

54
00:01:32,000 --> 00:01:33,119
and the techniques we are going to

55
00:01:33,119 --> 00:01:34,560
describe we will work with two main

56
00:01:34,560 --> 00:01:36,400
kinds of layers which are linear layers

57
00:01:36,400 --> 00:01:36,640
and

58
00:01:36,640 --> 00:01:38,320
non-linear layers and their main

59
00:01:38,320 --> 00:01:39,439
difference is whether they can be

60
00:01:39,439 --> 00:01:40,159
simplified

61
00:01:40,159 --> 00:01:43,040
into a polynomial or not in short both

62
00:01:43,040 --> 00:01:44,880
linear layers dense and convolutional

63
00:01:44,880 --> 00:01:46,240
can be simplified into matrix

64
00:01:46,240 --> 00:01:47,280
multiplications

65
00:01:47,280 --> 00:01:49,600
and thus multiplications and additions

66
00:01:49,600 --> 00:01:51,600
however the problem comes with nonlinear

67
00:01:51,600 --> 00:01:53,200
layers which are the magic of deep

68
00:01:53,200 --> 00:01:55,040
learning they introduced changes that

69
00:01:55,040 --> 00:01:56,880
are needed to learn complex patterns

70
00:01:56,880 --> 00:01:58,640
here we propose the max pooling and the

71
00:01:58,640 --> 00:02:00,320
activation functions which are used for

72
00:02:00,320 --> 00:02:01,680
forward propagation

73
00:02:01,680 --> 00:02:03,759
however for training the problem comes

74
00:02:03,759 --> 00:02:05,520
with loss functions and the derivatives

75
00:02:05,520 --> 00:02:07,360
of the activation and max pooling layers

76
00:02:07,360 --> 00:02:09,038
which are also non-linear

77
00:02:09,038 --> 00:02:10,959
now i would like to comment why these

78
00:02:10,959 --> 00:02:12,560
works are crucial

79
00:02:12,560 --> 00:02:13,840
the ability of deep learning to

80
00:02:13,840 --> 00:02:16,080
correlate apparently on related data

81
00:02:16,080 --> 00:02:17,599
allows solving problems in many

82
00:02:17,599 --> 00:02:19,280
disciplines such as finance social

83
00:02:19,280 --> 00:02:21,280
sciences or healthcare

84
00:02:21,280 --> 00:02:23,760
now we need to understand that these

85
00:02:23,760 --> 00:02:24,640
works

86
00:02:24,640 --> 00:02:26,720
are dealing with private data and we

87
00:02:26,720 --> 00:02:28,400
need ways to protect it

88
00:02:28,400 --> 00:02:30,080
first we need to protect the inference

89
00:02:30,080 --> 00:02:31,440
and training data

90
00:02:31,440 --> 00:02:33,519
also the deep learning models are

91
00:02:33,519 --> 00:02:34,959
private information that should be

92
00:02:34,959 --> 00:02:36,239
protected

93
00:02:36,239 --> 00:02:38,239
finally we need to understand how to

94
00:02:38,239 --> 00:02:40,720
keep legal and other intellectual

95
00:02:40,720 --> 00:02:42,480
property issues

96
00:02:42,480 --> 00:02:44,160
we have identified three main privacy

97
00:02:44,160 --> 00:02:45,840
guarantees that classical deep learning

98
00:02:45,840 --> 00:02:47,599
models do not always achieve

99
00:02:47,599 --> 00:02:49,120
input privacy relates to the input

100
00:02:49,120 --> 00:02:50,879
elements of a deep learning model

101
00:02:50,879 --> 00:02:52,640
that is the training data set and the

102
00:02:52,640 --> 00:02:54,000
inference samples

103
00:02:54,000 --> 00:02:55,440
we have to protect that from

104
00:02:55,440 --> 00:02:58,000
unauthorized third-party access

105
00:02:58,000 --> 00:03:00,159
output privacy relates to the security

106
00:03:00,159 --> 00:03:02,319
of the output elements of deep learning

107
00:03:02,319 --> 00:03:04,080
that is the trained model and the output

108
00:03:04,080 --> 00:03:05,440
classification

109
00:03:05,440 --> 00:03:06,800
when deep learning models find the

110
00:03:06,800 --> 00:03:08,959
statistical distribution outliers they

111
00:03:08,959 --> 00:03:10,080
often overfit

112
00:03:10,080 --> 00:03:12,159
and somehow memorize the classifications

113
00:03:12,159 --> 00:03:13,440
of these samples

114
00:03:13,440 --> 00:03:15,200
various attacks permit receiving this

115
00:03:15,200 --> 00:03:17,440
information by using certain privacy

116
00:03:17,440 --> 00:03:18,560
preserving techniques

117
00:03:18,560 --> 00:03:20,080
we can protect the data from these

118
00:03:20,080 --> 00:03:22,080
attacks there is a final consideration

119
00:03:22,080 --> 00:03:23,360
that we have identified through

120
00:03:23,360 --> 00:03:25,200
analyzing the different works which is

121
00:03:25,200 --> 00:03:26,400
model secrecy

122
00:03:26,400 --> 00:03:28,319
people invest money and time into

123
00:03:28,319 --> 00:03:29,760
creating deep learning models

124
00:03:29,760 --> 00:03:31,360
and releasing it to a third party could

125
00:03:31,360 --> 00:03:33,599
be losing the intellectual property

126
00:03:33,599 --> 00:03:35,440
furthermore if certain output privacy

127
00:03:35,440 --> 00:03:37,040
guarantees cannot be ensured

128
00:03:37,040 --> 00:03:38,959
it is better to have access control over

129
00:03:38,959 --> 00:03:40,080
the model

130
00:03:40,080 --> 00:03:41,599
in this case we divide it into

131
00:03:41,599 --> 00:03:43,840
architectural secrecy and weight secrecy

132
00:03:43,840 --> 00:03:46,159
architectural secrecy refers to not

133
00:03:46,159 --> 00:03:48,080
releasing the specific organization of

134
00:03:48,080 --> 00:03:48,879
the layers

135
00:03:48,879 --> 00:03:51,040
and white secrecy refers to not

136
00:03:51,040 --> 00:03:53,120
releasing the specific weights

137
00:03:53,120 --> 00:03:54,959
learned during training having

138
00:03:54,959 --> 00:03:56,640
understood the different privacy goals

139
00:03:56,640 --> 00:03:57,519
of deep learning

140
00:03:57,519 --> 00:03:59,280
we can make a classification of privacy

141
00:03:59,280 --> 00:04:00,959
preserving techniques

142
00:04:00,959 --> 00:04:03,120
i would like to start with data privacy

143
00:04:03,120 --> 00:04:05,120
which is techniques that focus on

144
00:04:05,120 --> 00:04:07,360
reducing the amount of information that

145
00:04:07,360 --> 00:04:10,319
data sets carry out in that way models

146
00:04:10,319 --> 00:04:10,879
trained

147
00:04:10,879 --> 00:04:13,200
with that data ensure that they will not

148
00:04:13,200 --> 00:04:15,280
include private information

149
00:04:15,280 --> 00:04:17,040
differential privacy is one example of

150
00:04:17,040 --> 00:04:18,478
these techniques

151
00:04:18,478 --> 00:04:20,160
let me jump over privacy-preserving

152
00:04:20,160 --> 00:04:22,160
computation techniques and start with

153
00:04:22,160 --> 00:04:24,080
trusted execution environments

154
00:04:24,080 --> 00:04:26,160
trusted execution environments are

155
00:04:26,160 --> 00:04:28,240
really common in modern processors

156
00:04:28,240 --> 00:04:30,320
they work by privatizing the memory

157
00:04:30,320 --> 00:04:31,919
space of a process

158
00:04:31,919 --> 00:04:33,600
when the information of that process has

159
00:04:33,600 --> 00:04:35,040
to be possessed

160
00:04:35,040 --> 00:04:37,360
then the information is decrypted in the

161
00:04:37,360 --> 00:04:38,240
processor

162
00:04:38,240 --> 00:04:40,400
processed and re-encrypted again

163
00:04:40,400 --> 00:04:41,520
strictly speaking

164
00:04:41,520 --> 00:04:43,600
this is not the focus of our work since

165
00:04:43,600 --> 00:04:45,120
the computation is

166
00:04:45,120 --> 00:04:47,600
fully done in clear text federated

167
00:04:47,600 --> 00:04:49,680
learning is a protocol first proposed by

168
00:04:49,680 --> 00:04:51,280
google over which there have been

169
00:04:51,280 --> 00:04:52,880
multiple enhancements

170
00:04:52,880 --> 00:04:55,120
these protocols ensure that information

171
00:04:55,120 --> 00:04:57,120
is paid private on each of the silos or

172
00:04:57,120 --> 00:04:59,440
parties participating in the learning

173
00:04:59,440 --> 00:05:01,120
the only information exchange are the

174
00:05:01,120 --> 00:05:02,479
gradients of training

175
00:05:02,479 --> 00:05:04,479
and the central server aggregates them

176
00:05:04,479 --> 00:05:05,520
privately

177
00:05:05,520 --> 00:05:07,280
this is a completely different field in

178
00:05:07,280 --> 00:05:08,960
which some of the ppct's that we will

179
00:05:08,960 --> 00:05:09,600
describe

180
00:05:09,600 --> 00:05:11,520
take part but in general we will

181
00:05:11,520 --> 00:05:13,600
consider a small subset of information

182
00:05:13,600 --> 00:05:15,280
being processed privately

183
00:05:15,280 --> 00:05:17,120
and then we go over privacy preserving

184
00:05:17,120 --> 00:05:18,479
computation techniques

185
00:05:18,479 --> 00:05:20,880
where the data is fully fuscated and an

186
00:05:20,880 --> 00:05:22,320
adversary processing it

187
00:05:22,320 --> 00:05:25,039
has no knowledge about it apart from

188
00:05:25,039 --> 00:05:25,919
that it has

189
00:05:25,919 --> 00:05:27,520
cryptographic guarantees behind the

190
00:05:27,520 --> 00:05:30,240
protection here we overview three types

191
00:05:30,240 --> 00:05:30,880
of them

192
00:05:30,880 --> 00:05:32,800
first we have several morphic encryption

193
00:05:32,800 --> 00:05:34,720
which is a property of encryption

194
00:05:34,720 --> 00:05:35,280
schemes

195
00:05:35,280 --> 00:05:37,520
that permits operating over ciphertext

196
00:05:37,520 --> 00:05:39,120
and having these changes applied over

197
00:05:39,120 --> 00:05:41,199
the plaintext

198
00:05:41,199 --> 00:05:42,560
as we see in the figure below the

199
00:05:42,560 --> 00:05:44,000
envelope is encrypted on the local

200
00:05:44,000 --> 00:05:45,680
premises and sent to the cloud

201
00:05:45,680 --> 00:05:47,280
the cloud in our case would contain the

202
00:05:47,280 --> 00:05:48,880
deep learning model which can privately

203
00:05:48,880 --> 00:05:50,560
compute any function over it

204
00:05:50,560 --> 00:05:52,240
once the cloud has a result it can be

205
00:05:52,240 --> 00:05:54,639
sent back to the client who decrypts it

206
00:05:54,639 --> 00:05:56,240
the cloud would have learned nothing

207
00:05:56,240 --> 00:05:57,840
about this process

208
00:05:57,840 --> 00:05:59,759
in the top figure we showed there are

209
00:05:59,759 --> 00:06:01,440
various flavors of achieving

210
00:06:01,440 --> 00:06:03,360
out of this level demographic encryption

211
00:06:03,360 --> 00:06:05,360
has been demos using the proposals

212
00:06:05,360 --> 00:06:07,120
that is because it provides a simple but

213
00:06:07,120 --> 00:06:08,960
efficient way of computing information

214
00:06:08,960 --> 00:06:10,880
though the three quits are of a limited

215
00:06:10,880 --> 00:06:11,919
depth

216
00:06:11,919 --> 00:06:13,919
recently we are seeing third generation

217
00:06:13,919 --> 00:06:15,600
schemes with good performance in

218
00:06:15,600 --> 00:06:16,800
bootstrapping

219
00:06:16,800 --> 00:06:18,880
so we believe they will become an option

220
00:06:18,880 --> 00:06:20,240
in the future

221
00:06:20,240 --> 00:06:22,080
another privacy preserving computation

222
00:06:22,080 --> 00:06:23,919
technique is secure multi-party

223
00:06:23,919 --> 00:06:24,720
computation

224
00:06:24,720 --> 00:06:26,240
which permits a number of different

225
00:06:26,240 --> 00:06:27,680
parties to interact and generally

226
00:06:27,680 --> 00:06:29,120
compute functions without revealing

227
00:06:29,120 --> 00:06:30,400
their private inputs

228
00:06:30,400 --> 00:06:32,319
the figure we can see how the different

229
00:06:32,319 --> 00:06:34,000
parties can sort of divide

230
00:06:34,000 --> 00:06:35,759
their inputs in reality this

231
00:06:35,759 --> 00:06:37,600
preprocessing generates a complementary

232
00:06:37,600 --> 00:06:40,400
representation of information or sharing

233
00:06:40,400 --> 00:06:42,240
these sharings can be sent to the cloud

234
00:06:42,240 --> 00:06:44,080
servers who operate on them

235
00:06:44,080 --> 00:06:45,840
the individual shares do not reveal any

236
00:06:45,840 --> 00:06:47,840
information and ones combined back

237
00:06:47,840 --> 00:06:49,759
reveal the result of operating on the

238
00:06:49,759 --> 00:06:51,120
shares of data

239
00:06:51,120 --> 00:06:53,680
the top diagram shows different smpc

240
00:06:53,680 --> 00:06:55,680
protocols that have been used for deep

241
00:06:55,680 --> 00:06:56,319
learning

242
00:06:56,319 --> 00:06:58,000
in the advanced constructions we would

243
00:06:58,000 --> 00:06:59,919
find more efficient and secure protocols

244
00:06:59,919 --> 00:07:01,840
and these secure variations such as spd

245
00:07:01,840 --> 00:07:02,639
set

246
00:07:02,639 --> 00:07:04,319
hybrid techniques are a specific

247
00:07:04,319 --> 00:07:06,720
classification we include in this sok

248
00:07:06,720 --> 00:07:08,080
they are mostly one of the two

249
00:07:08,080 --> 00:07:10,479
categories either snpc or he

250
00:07:10,479 --> 00:07:12,240
but they often implement cryptographic

251
00:07:12,240 --> 00:07:13,840
conversion protocols which permit

252
00:07:13,840 --> 00:07:15,520
switching to other protocols in the

253
00:07:15,520 --> 00:07:17,280
different categories

254
00:07:17,280 --> 00:07:18,960
deep learning is often carried out in

255
00:07:18,960 --> 00:07:20,319
floating point arithmetic

256
00:07:20,319 --> 00:07:22,240
however many of the activation functions

257
00:07:22,240 --> 00:07:23,840
can only be computed through boolean

258
00:07:23,840 --> 00:07:25,039
arithmetics

259
00:07:25,039 --> 00:07:26,400
through the cryptographic conversion

260
00:07:26,400 --> 00:07:28,240
protocols in hybrid techniques we can

261
00:07:28,240 --> 00:07:30,400
also switch the arithmetic this makes

262
00:07:30,400 --> 00:07:32,000
these techniques really powerful for

263
00:07:32,000 --> 00:07:33,280
computing deep learning

264
00:07:33,280 --> 00:07:35,120
as we will see they shift the paradigm

265
00:07:35,120 --> 00:07:36,319
in inference

266
00:07:36,319 --> 00:07:38,080
see all of these techniques provide

267
00:07:38,080 --> 00:07:39,759
input privacy that is

268
00:07:39,759 --> 00:07:41,919
anything that is input to these

269
00:07:41,919 --> 00:07:43,840
processes is kept private and not

270
00:07:43,840 --> 00:07:44,879
revealed

271
00:07:44,879 --> 00:07:46,720
now that we have explored the taxonomy

272
00:07:46,720 --> 00:07:48,800
and goals we can start understanding how

273
00:07:48,800 --> 00:07:50,639
the basic protocols that were proposed

274
00:07:50,639 --> 00:07:51,680
work

275
00:07:51,680 --> 00:07:53,840
the first modern paper to propose deep

276
00:07:53,840 --> 00:07:55,280
learning and privacy

277
00:07:55,280 --> 00:07:57,440
was kryptonites i say modern because

278
00:07:57,440 --> 00:07:59,280
there's another paper tasty which was

279
00:07:59,280 --> 00:08:01,039
proposed in 2009

280
00:08:01,039 --> 00:08:03,280
however at that point neither hg nor

281
00:08:03,280 --> 00:08:04,800
deep learning were mature enough for

282
00:08:04,800 --> 00:08:05,759
these

283
00:08:05,759 --> 00:08:07,840
kryptonites approximated floating point

284
00:08:07,840 --> 00:08:09,280
numbers with integers

285
00:08:09,280 --> 00:08:11,360
and was used with power of two

286
00:08:11,360 --> 00:08:12,800
activation functions

287
00:08:12,800 --> 00:08:15,680
this was not very good and in 2017

288
00:08:15,680 --> 00:08:17,599
crypto dlp process improvements to the

289
00:08:17,599 --> 00:08:18,879
activation factions

290
00:08:18,879 --> 00:08:20,800
by giving it more accurate linear

291
00:08:20,800 --> 00:08:22,160
approximations

292
00:08:22,160 --> 00:08:24,080
other works such as faster kryptonets

293
00:08:24,080 --> 00:08:25,680
are young at all proposed more

294
00:08:25,680 --> 00:08:27,280
optimizations but more on the deep

295
00:08:27,280 --> 00:08:28,479
learning side to accelerate the

296
00:08:28,479 --> 00:08:29,599
computations

297
00:08:29,599 --> 00:08:31,440
on a sideline we have other approaches

298
00:08:31,440 --> 00:08:33,200
focused on other arithmetics such as

299
00:08:33,200 --> 00:08:35,360
tapas or fhe dinn who use

300
00:08:35,360 --> 00:08:37,279
boolean and discretize neural networks

301
00:08:37,279 --> 00:08:38,799
respectively

302
00:08:38,799 --> 00:08:41,360
on the other side we have snpc all the

303
00:08:41,360 --> 00:08:42,799
approaches of snpc

304
00:08:42,799 --> 00:08:44,560
use boolean circuits for the neural

305
00:08:44,560 --> 00:08:47,040
networks in general they are faster to

306
00:08:47,040 --> 00:08:47,760
the ah

307
00:08:47,760 --> 00:08:50,080
counterparts however having to use the

308
00:08:50,080 --> 00:08:51,200
binary weights

309
00:08:51,200 --> 00:08:52,800
makes changes to the neural networks

310
00:08:52,800 --> 00:08:54,480
which are not very convenient

311
00:08:54,480 --> 00:08:56,560
however there's a complete shift in the

312
00:08:56,560 --> 00:08:59,760
paradigm when gasel and chameleon appear

313
00:08:59,760 --> 00:09:01,519
instead of modifying the deep learning

314
00:09:01,519 --> 00:09:03,680
structures they propose changes in the

315
00:09:03,680 --> 00:09:04,880
cryptographic techniques

316
00:09:04,880 --> 00:09:06,959
that permit executing deep learning the

317
00:09:06,959 --> 00:09:08,959
same way could be doing classically

318
00:09:08,959 --> 00:09:10,720
with the rise of privacy preserving deep

319
00:09:10,720 --> 00:09:12,959
learning many of the works focused on

320
00:09:12,959 --> 00:09:14,880
bringing useability for data scientists

321
00:09:14,880 --> 00:09:16,080
to use these tools

322
00:09:16,080 --> 00:09:17,760
there are three main research lines in

323
00:09:17,760 --> 00:09:20,240
this timeline first we have piscift and

324
00:09:20,240 --> 00:09:21,279
tf encrypted

325
00:09:21,279 --> 00:09:23,279
who are big open source initiative that

326
00:09:23,279 --> 00:09:24,640
revolve around creating common

327
00:09:24,640 --> 00:09:26,399
interfaces for deep learning and privacy

328
00:09:26,399 --> 00:09:27,680
preserving techniques

329
00:09:27,680 --> 00:09:30,080
but until recently they are mostly used

330
00:09:30,080 --> 00:09:32,800
and focused on usability

331
00:09:32,800 --> 00:09:35,120
other works focus more on the security

332
00:09:35,120 --> 00:09:37,440
side together with the usability

333
00:09:37,440 --> 00:09:40,000
such as engraf hg and their successors

334
00:09:40,000 --> 00:09:40,959
in graphic g2

335
00:09:40,959 --> 00:09:44,320
blade ml or mp2ml apart from that we

336
00:09:44,320 --> 00:09:46,160
have cryptflow who focuses on a secure

337
00:09:46,160 --> 00:09:47,760
multiparty computation site

338
00:09:47,760 --> 00:09:50,160
and tiny garble while all of the

339
00:09:50,160 --> 00:09:51,360
previous works

340
00:09:51,360 --> 00:09:54,000
require manual parameter selection chet

341
00:09:54,000 --> 00:09:56,160
and eva provide simple interfaces

342
00:09:56,160 --> 00:09:58,560
that automate the parameter selection

343
00:09:58,560 --> 00:10:00,399
all the previous papers focused on

344
00:10:00,399 --> 00:10:01,120
inference

345
00:10:01,120 --> 00:10:03,279
that is assuming a neural network was

346
00:10:03,279 --> 00:10:04,959
already pre-trained

347
00:10:04,959 --> 00:10:06,880
in this timeline we explore a bit more

348
00:10:06,880 --> 00:10:08,399
the side of training

349
00:10:08,399 --> 00:10:09,839
there's a first difference in all the

350
00:10:09,839 --> 00:10:11,920
cases neural networks need to be much

351
00:10:11,920 --> 00:10:12,959
simpler

352
00:10:12,959 --> 00:10:14,640
training is already a very cost

353
00:10:14,640 --> 00:10:16,000
ineffective process

354
00:10:16,000 --> 00:10:18,480
considering we had a complex layer on

355
00:10:18,480 --> 00:10:19,279
top of it

356
00:10:19,279 --> 00:10:21,040
which is a cryptographic primitive it

357
00:10:21,040 --> 00:10:22,800
makes it very difficult for this process

358
00:10:22,800 --> 00:10:23,920
to be carried out

359
00:10:23,920 --> 00:10:25,600
first it works on achieve prepare an

360
00:10:25,600 --> 00:10:27,600
encrypted dataset and then the training

361
00:10:27,600 --> 00:10:29,120
neural network out of it

362
00:10:29,120 --> 00:10:31,120
that is the case when a server receives

363
00:10:31,120 --> 00:10:33,120
an encrypted data set and trains a model

364
00:10:33,120 --> 00:10:34,320
out of it

365
00:10:34,320 --> 00:10:36,000
even though they managed to do that the

366
00:10:36,000 --> 00:10:37,680
comparison in resource consumption is

367
00:10:37,680 --> 00:10:38,560
very poor

368
00:10:38,560 --> 00:10:40,320
in the case of snpc and hybrid

369
00:10:40,320 --> 00:10:42,079
techniques the scenario is very similar

370
00:10:42,079 --> 00:10:43,680
to cloud federated learning

371
00:10:43,680 --> 00:10:45,600
but when all operations even the forward

372
00:10:45,600 --> 00:10:48,000
propagation are performed encrypted

373
00:10:48,000 --> 00:10:50,640
in that case it permits outsourcing the

374
00:10:50,640 --> 00:10:52,399
training to an external server

375
00:10:52,399 --> 00:10:55,120
and also keeping the data secret all

376
00:10:55,120 --> 00:10:56,560
these papers make something different

377
00:10:56,560 --> 00:10:58,160
than the rest so i encourage you to look

378
00:10:58,160 --> 00:11:00,000
at the paper if you're interested in it

379
00:11:00,000 --> 00:11:01,519
now that we have covered all the papers

380
00:11:01,519 --> 00:11:02,560
i would like to have light some

381
00:11:02,560 --> 00:11:04,160
takeaways of the different

382
00:11:04,160 --> 00:11:06,399
contributions first we will cover

383
00:11:06,399 --> 00:11:08,160
security and then efficiency and

384
00:11:08,160 --> 00:11:09,600
usability

385
00:11:09,600 --> 00:11:11,120
there are two kinds of adversaries when

386
00:11:11,120 --> 00:11:12,880
designing a protocol

387
00:11:12,880 --> 00:11:14,720
the honest bacterius adversary is a

388
00:11:14,720 --> 00:11:16,480
passive adversary that complex with a

389
00:11:16,480 --> 00:11:18,480
protocol but tries to learn as much as

390
00:11:18,480 --> 00:11:20,320
possible from the interactions the

391
00:11:20,320 --> 00:11:21,920
malicious adversary on the other hand

392
00:11:21,920 --> 00:11:23,760
has a stronger capabilities as it can

393
00:11:23,760 --> 00:11:25,200
tamper with the protocol

394
00:11:25,200 --> 00:11:27,120
dynamic changing the inputs or

395
00:11:27,120 --> 00:11:29,040
interrupting that participation at any

396
00:11:29,040 --> 00:11:29,920
point

397
00:11:29,920 --> 00:11:31,279
although there are ways to enhance the

398
00:11:31,279 --> 00:11:32,800
honest but curious adversaries to

399
00:11:32,800 --> 00:11:33,440
malicious

400
00:11:33,440 --> 00:11:35,600
it is often computationally costly and

401
00:11:35,600 --> 00:11:37,040
most of the articles we have seen

402
00:11:37,040 --> 00:11:39,279
propose a honest but curious adversary

403
00:11:39,279 --> 00:11:41,200
in the highlighted column of the table

404
00:11:41,200 --> 00:11:43,279
you can see how most of the papers

405
00:11:43,279 --> 00:11:45,839
use a honest but curious adversary we

406
00:11:45,839 --> 00:11:48,079
believe it is interesting for the future

407
00:11:48,079 --> 00:11:49,440
though i start understanding the

408
00:11:49,440 --> 00:11:51,440
adaptions of the wholeness but curious

409
00:11:51,440 --> 00:11:53,040
into the malicious adversary in an

410
00:11:53,040 --> 00:11:54,399
efficient way

411
00:11:54,399 --> 00:11:56,079
while we claim that most protocols

412
00:11:56,079 --> 00:11:58,079
preserve architectural and with secrecy

413
00:11:58,079 --> 00:12:00,079
it is because the papers model owners

414
00:12:00,079 --> 00:12:01,680
are considered a trusted third party

415
00:12:01,680 --> 00:12:03,600
that will not steal the model

416
00:12:03,600 --> 00:12:05,279
we believe the consideration of model

417
00:12:05,279 --> 00:12:07,120
secrecy could be enhanced through the

418
00:12:07,120 --> 00:12:09,519
use of ppcts in combination with trusted

419
00:12:09,519 --> 00:12:10,079
execution

420
00:12:10,079 --> 00:12:12,320
environments as we see on the table

421
00:12:12,320 --> 00:12:14,000
except in training proposals

422
00:12:14,000 --> 00:12:16,079
most of the papers cover architectural

423
00:12:16,079 --> 00:12:17,760
and weight secrecy

424
00:12:17,760 --> 00:12:19,680
we believe it is necessary to introduce

425
00:12:19,680 --> 00:12:21,839
output privacy in these protocols

426
00:12:21,839 --> 00:12:23,839
in the table the blue hyphen means that

427
00:12:23,839 --> 00:12:25,680
the guarantee depends on your specific

428
00:12:25,680 --> 00:12:26,800
implementation

429
00:12:26,800 --> 00:12:29,279
so it is led aside from the protocol

430
00:12:29,279 --> 00:12:31,200
most protocols ensure input privacy

431
00:12:31,200 --> 00:12:32,720
battle with privacy depends on the

432
00:12:32,720 --> 00:12:34,480
relationships between the actors and the

433
00:12:34,480 --> 00:12:36,240
way models have been trained

434
00:12:36,240 --> 00:12:37,920
end-to-end pipelines including all these

435
00:12:37,920 --> 00:12:39,600
techniques are the future of privacy

436
00:12:39,600 --> 00:12:40,800
preserving deep learning

437
00:12:40,800 --> 00:12:43,120
as a final security takeaway we believe

438
00:12:43,120 --> 00:12:44,560
there are attacks such as model

439
00:12:44,560 --> 00:12:46,480
extraction or model inversion attacks

440
00:12:46,480 --> 00:12:48,399
that can be undercovered by the use of

441
00:12:48,399 --> 00:12:50,079
ppcts

442
00:12:50,079 --> 00:12:52,000
although it may be far we need to

443
00:12:52,000 --> 00:12:54,000
envision future international detection

444
00:12:54,000 --> 00:12:54,560
systems

445
00:12:54,560 --> 00:12:56,240
that detect authors trying to exploit

446
00:12:56,240 --> 00:12:58,000
these attacks against models

447
00:12:58,000 --> 00:12:59,680
privacy-preserving processing will

448
00:12:59,680 --> 00:13:01,519
require envisioning a new generation of

449
00:13:01,519 --> 00:13:03,519
countermeasures to attacks

450
00:13:03,519 --> 00:13:05,279
it is difficult to compare efficiency in

451
00:13:05,279 --> 00:13:07,680
the different works each work trains on

452
00:13:07,680 --> 00:13:09,519
a different neural network architecture

453
00:13:09,519 --> 00:13:11,360
and obtains different weights

454
00:13:11,360 --> 00:13:13,440
different depleting trainings may result

455
00:13:13,440 --> 00:13:14,800
in different base accuracies

456
00:13:14,800 --> 00:13:16,320
and its translation to the privacy

457
00:13:16,320 --> 00:13:18,079
reserving protocol may be affected

458
00:13:18,079 --> 00:13:19,680
differently

459
00:13:19,680 --> 00:13:21,519
we believe it is needed to standardize

460
00:13:21,519 --> 00:13:22,800
the benchmarking

461
00:13:22,800 --> 00:13:24,399
while the difference in computational

462
00:13:24,399 --> 00:13:25,839
architectures may not be easy to

463
00:13:25,839 --> 00:13:26,560
quantify

464
00:13:26,560 --> 00:13:28,320
we believe it is feasible to elaborate

465
00:13:28,320 --> 00:13:30,240
common models for the community to be

466
00:13:30,240 --> 00:13:34,160
able to objectively compare efficiencies

467
00:13:34,160 --> 00:13:36,240
to analyze usability and reproducibility

468
00:13:36,240 --> 00:13:37,920
of the many works we covered

469
00:13:37,920 --> 00:13:39,760
we tried to understand the maturity

470
00:13:39,760 --> 00:13:41,040
level of the contribution

471
00:13:41,040 --> 00:13:44,079
until reaching data scientists for that

472
00:13:44,079 --> 00:13:45,680
we searched for the opening of source

473
00:13:45,680 --> 00:13:47,680
implementation of the protocols

474
00:13:47,680 --> 00:13:49,760
if it was available we have compared the

475
00:13:49,760 --> 00:13:51,760
implementation with what was proposed on

476
00:13:51,760 --> 00:13:52,880
the paper

477
00:13:52,880 --> 00:13:54,480
furthermore we checked if the

478
00:13:54,480 --> 00:13:56,079
repositories are maintained

479
00:13:56,079 --> 00:13:58,160
and if they implement a breach to common

480
00:13:58,160 --> 00:14:00,160
deep learning frameworks

481
00:14:00,160 --> 00:14:02,240
in inference many works are released

482
00:14:02,240 --> 00:14:03,839
open source all of the open

483
00:14:03,839 --> 00:14:05,600
implementation match the article

484
00:14:05,600 --> 00:14:07,240
proposal and they immediately favor

485
00:14:07,240 --> 00:14:08,800
reproducibility

486
00:14:08,800 --> 00:14:10,720
in training proposals there's much less

487
00:14:10,720 --> 00:14:12,959
code sharing we believe it is due to the

488
00:14:12,959 --> 00:14:14,959
performance limitations

489
00:14:14,959 --> 00:14:17,440
finally in usability focused proposal

490
00:14:17,440 --> 00:14:19,279
the code sharing is really good

491
00:14:19,279 --> 00:14:21,360
and most proposals are well maintained

492
00:14:21,360 --> 00:14:23,040
and there are relevant updates for the

493
00:14:23,040 --> 00:14:24,079
code

494
00:14:24,079 --> 00:14:26,160
we see some common flaws and we believe

495
00:14:26,160 --> 00:14:28,000
integration within standard frameworks

496
00:14:28,000 --> 00:14:29,440
would also help the goal of having

497
00:14:29,440 --> 00:14:31,600
common benchmarking

498
00:14:31,600 --> 00:14:34,079
furthermore we believe common points and

499
00:14:34,079 --> 00:14:35,680
integration with common deep learning

500
00:14:35,680 --> 00:14:37,040
frameworks are step

501
00:14:37,040 --> 00:14:39,519
forward towards compatibility with data

502
00:14:39,519 --> 00:14:41,120
science communities

503
00:14:41,120 --> 00:14:43,040
if you want more information of the code

504
00:14:43,040 --> 00:14:46,639
repositories the list is in the article

505
00:14:46,639 --> 00:14:48,320
finally i would like to give some

506
00:14:48,320 --> 00:14:50,000
concluding remarks

507
00:14:50,000 --> 00:14:52,240
we believe ppct is on its way to reach

508
00:14:52,240 --> 00:14:53,920
data scientists and more and more

509
00:14:53,920 --> 00:14:55,360
more usable solutions will be

510
00:14:55,360 --> 00:14:57,920
approaching the security and privacy

511
00:14:57,920 --> 00:14:58,720
innovations

512
00:14:58,720 --> 00:15:00,399
make using privacy a really good

513
00:15:00,399 --> 00:15:02,079
alternative for deep learning

514
00:15:02,079 --> 00:15:04,160
and ppcts are a good provision of

515
00:15:04,160 --> 00:15:06,079
security and efficiency especially for

516
00:15:06,079 --> 00:15:07,360
inference

517
00:15:07,360 --> 00:15:08,880
we believe there are many evolving

518
00:15:08,880 --> 00:15:10,880
technologies and this favors

519
00:15:10,880 --> 00:15:13,040
the creation of many new proposals one

520
00:15:13,040 --> 00:15:14,320
of them falcon

521
00:15:14,320 --> 00:15:17,120
is presented next in this conference

522
00:15:17,120 --> 00:15:19,040
thank you very much for listening to me

523
00:15:19,040 --> 00:15:20,959
i'll leave here my interest and current

524
00:15:20,959 --> 00:15:23,519
research lines if any one of you wants

525
00:15:23,519 --> 00:15:26,720
to drop a mail i'm happy to answer there

526
00:15:26,720 --> 00:15:28,160
you have all the references for the

527
00:15:28,160 --> 00:15:29,360
different works

528
00:15:29,360 --> 00:15:31,279
and said that i remain of your disposal

529
00:15:31,279 --> 00:15:32,800
for an email further questions you may

530
00:15:32,800 --> 00:15:33,519
have

531
00:15:33,519 --> 00:15:35,120
if you were not able to submit any

532
00:15:35,120 --> 00:15:36,560
question during the conference i'm happy

533
00:15:36,560 --> 00:15:39,920
to answer it by mail too

