1
00:00:00,799 --> 00:00:03,040
hello this is our azura ajapi today i'm

2
00:00:03,040 --> 00:00:04,799
going to present or work on the

3
00:00:04,799 --> 00:00:05,759
practically

4
00:00:05,759 --> 00:00:07,440
or impractically of adversarial

5
00:00:07,440 --> 00:00:09,599
perturbation for image privacy

6
00:00:09,599 --> 00:00:11,679
this work has been done when i was a pc

7
00:00:11,679 --> 00:00:13,679
student at oregon state university

8
00:00:13,679 --> 00:00:15,679
and to do this project i collaborated

9
00:00:15,679 --> 00:00:16,800
with the portland

10
00:00:16,800 --> 00:00:19,840
state university

11
00:00:19,840 --> 00:00:22,160
in this paper we focus on image privacy

12
00:00:22,160 --> 00:00:24,880
threats and the reason is that

13
00:00:24,880 --> 00:00:27,279
recently we faced different image

14
00:00:27,279 --> 00:00:28,800
privacy violations

15
00:00:28,800 --> 00:00:30,720
and one of these violations that we can

16
00:00:30,720 --> 00:00:32,960
mention is reverse image search

17
00:00:32,960 --> 00:00:35,840
uh as an example an adversary can use

18
00:00:35,840 --> 00:00:37,920
clearview api

19
00:00:37,920 --> 00:00:40,480
to find all of your social accounts or

20
00:00:40,480 --> 00:00:42,320
your personal website by using your one

21
00:00:42,320 --> 00:00:44,320
of your photos

22
00:00:44,320 --> 00:00:47,680
the other privacy image privacy to it we

23
00:00:47,680 --> 00:00:48,879
can mention the

24
00:00:48,879 --> 00:00:51,680
to analyze image classification uh

25
00:00:51,680 --> 00:00:53,760
recently a framework has been

26
00:00:53,760 --> 00:00:57,039
proposed which called kp this framework

27
00:00:57,039 --> 00:00:58,079
use face recognition

28
00:00:58,079 --> 00:01:00,160
and face detection models to track your

29
00:01:00,160 --> 00:01:01,359
relationship

30
00:01:01,359 --> 00:01:05,680
using your social networks images

31
00:01:05,920 --> 00:01:08,000
in this paper we especially focus on

32
00:01:08,000 --> 00:01:10,080
unauthorized automated face recognition

33
00:01:10,080 --> 00:01:12,080
models and the reason is that there are

34
00:01:12,080 --> 00:01:14,720
billions of uh available image and at

35
00:01:14,720 --> 00:01:16,799
first you can use gpus azure or

36
00:01:16,799 --> 00:01:20,159
aws to learn very large uh

37
00:01:20,159 --> 00:01:22,400
and high accurate uh face recognition

38
00:01:22,400 --> 00:01:23,200
models

39
00:01:23,200 --> 00:01:25,360
and we focus on imaging platforms

40
00:01:25,360 --> 00:01:26,799
especially because they

41
00:01:26,799 --> 00:01:30,159
uh they only already have access to

42
00:01:30,159 --> 00:01:33,360
uh or images and they have the resources

43
00:01:33,360 --> 00:01:35,280
to land face recognition models

44
00:01:35,280 --> 00:01:37,280
so they can easily track or

45
00:01:37,280 --> 00:01:38,479
relationships or

46
00:01:38,479 --> 00:01:41,600
uh or activities

47
00:01:41,600 --> 00:01:43,200
as we said we focus on the face

48
00:01:43,200 --> 00:01:45,360
recognition models in this paper

49
00:01:45,360 --> 00:01:47,119
and the reason is that in the past for

50
00:01:47,119 --> 00:01:48,960
example in 1991

51
00:01:48,960 --> 00:01:52,479
uh the best facial cognition models

52
00:01:52,479 --> 00:01:55,360
achieved at most 60 percent accuracy on

53
00:01:55,360 --> 00:01:55,920
large

54
00:01:55,920 --> 00:01:59,759
data but now recently with the advent of

55
00:01:59,759 --> 00:02:00,640
our way

56
00:02:00,640 --> 00:02:03,200
um complicated and advanced machine

57
00:02:03,200 --> 00:02:04,240
learning

58
00:02:04,240 --> 00:02:06,880
algorithms for example deep learning one

59
00:02:06,880 --> 00:02:08,080
can learn a kind of

60
00:02:08,080 --> 00:02:10,959
deep neural networks on the large

61
00:02:10,959 --> 00:02:12,160
dataset and achieve

62
00:02:12,160 --> 00:02:15,520
high high accuracy as an example and

63
00:02:15,520 --> 00:02:16,640
recently a

64
00:02:16,640 --> 00:02:19,599
deep phrase achieved more than 97

65
00:02:19,599 --> 00:02:20,720
accuracy on

66
00:02:20,720 --> 00:02:24,080
lfw dataset and lfw dataset

67
00:02:24,080 --> 00:02:27,200
actually contains more than 1000 of the

68
00:02:27,200 --> 00:02:28,000
images

69
00:02:28,000 --> 00:02:31,599
uh of uh celebrities and

70
00:02:31,599 --> 00:02:34,800
what the these um deep neural networks

71
00:02:34,800 --> 00:02:36,560
are actually deep neural networks for

72
00:02:36,560 --> 00:02:37,680
the images are

73
00:02:37,680 --> 00:02:39,680
commercial neural networks uh the

74
00:02:39,680 --> 00:02:41,120
conversion neural networks are

75
00:02:41,120 --> 00:02:42,080
constructed

76
00:02:42,080 --> 00:02:44,640
with the different layers and these

77
00:02:44,640 --> 00:02:46,560
layers are convolutional layers max

78
00:02:46,560 --> 00:02:47,040
pooling

79
00:02:47,040 --> 00:02:51,840
and some fully collected layers

80
00:02:53,120 --> 00:02:55,120
despite the high accuracy of commercial

81
00:02:55,120 --> 00:02:56,800
neural networks or cns they are

82
00:02:56,800 --> 00:02:58,879
vulnerable to adversarial examples and

83
00:02:58,879 --> 00:02:59,519
adverse

84
00:02:59,519 --> 00:03:03,440
examples are been on example or images

85
00:03:03,440 --> 00:03:06,000
with adversarial noise adjustable noise

86
00:03:06,000 --> 00:03:07,840
is trained on

87
00:03:07,840 --> 00:03:11,040
a target cnn and as you can see in this

88
00:03:11,040 --> 00:03:14,159
image we can full a target cnn just by

89
00:03:14,159 --> 00:03:14,879
adding

90
00:03:14,879 --> 00:03:16,879
less than one percent of the adversarial

91
00:03:16,879 --> 00:03:19,280
noise the image in the middle

92
00:03:19,280 --> 00:03:22,319
that trained on the target cnn that

93
00:03:22,319 --> 00:03:23,680
visual examples

94
00:03:23,680 --> 00:03:26,640
have two nice properties the first one

95
00:03:26,640 --> 00:03:27,519
is that

96
00:03:27,519 --> 00:03:30,239
these images are recognizable for humans

97
00:03:30,239 --> 00:03:30,720
but not

98
00:03:30,720 --> 00:03:33,840
cns and so they can be trained for

99
00:03:33,840 --> 00:03:36,959
transferability that means that uh it

100
00:03:36,959 --> 00:03:39,440
attribute examples can be trained on the

101
00:03:39,440 --> 00:03:40,799
cnn a

102
00:03:40,799 --> 00:03:44,000
as such that they are able to fool

103
00:03:44,000 --> 00:03:47,840
other cnn for example cnn b

104
00:03:48,640 --> 00:03:51,159
because of a nice properties of adverse

105
00:03:51,159 --> 00:03:52,640
elevation they

106
00:03:52,640 --> 00:03:55,040
has been they have been considered as a

107
00:03:55,040 --> 00:03:56,480
potential defense

108
00:03:56,480 --> 00:04:00,480
for image privacy and recently a

109
00:04:00,480 --> 00:04:02,080
method has been proposed based on the

110
00:04:02,080 --> 00:04:03,519
adversarial examples

111
00:04:03,519 --> 00:04:07,120
that suggest a user to pertap her

112
00:04:07,120 --> 00:04:09,680
images before posting or sharing but the

113
00:04:09,680 --> 00:04:11,040
problem with this

114
00:04:11,040 --> 00:04:13,360
approach is that this approach assumes

115
00:04:13,360 --> 00:04:14,799
uh

116
00:04:14,799 --> 00:04:16,959
a user has access to the target sentence

117
00:04:16,959 --> 00:04:19,120
and also the users

118
00:04:19,120 --> 00:04:22,320
need to learn one perturbation for every

119
00:04:22,320 --> 00:04:22,800
image

120
00:04:22,800 --> 00:04:24,720
which is not practical for the real

121
00:04:24,720 --> 00:04:26,320
application or

122
00:04:26,320 --> 00:04:29,840
also we have seen two nice uh

123
00:04:29,840 --> 00:04:32,720
other adversarial-based schemes for um

124
00:04:32,720 --> 00:04:34,479
image privacy in this session

125
00:04:34,479 --> 00:04:36,639
but they're trying to solve uh other

126
00:04:36,639 --> 00:04:38,560
problems and they are not suitable for

127
00:04:38,560 --> 00:04:40,080
imaging platforms

128
00:04:40,080 --> 00:04:43,040
so before introducing our approaches we

129
00:04:43,040 --> 00:04:43,919
uh

130
00:04:43,919 --> 00:04:47,120
we identify some practical requirements

131
00:04:47,120 --> 00:04:50,000
for adversarial uh based approaches that

132
00:04:50,000 --> 00:04:50,639
design

133
00:04:50,639 --> 00:04:54,639
especially for image sharing platforms

134
00:04:55,360 --> 00:04:57,360
the first requirement is black box

135
00:04:57,360 --> 00:04:58,560
setting it means that

136
00:04:58,560 --> 00:05:01,280
user doesn't have a user doesn't have

137
00:05:01,280 --> 00:05:02,479
any knowledge about

138
00:05:02,479 --> 00:05:05,759
the target cnns and

139
00:05:05,759 --> 00:05:09,680
users don't have a very large data set

140
00:05:09,680 --> 00:05:11,919
or they don't want to share their images

141
00:05:11,919 --> 00:05:13,520
with the third party for learning

142
00:05:13,520 --> 00:05:17,360
a cnn or a perturbation

143
00:05:17,360 --> 00:05:19,919
also they want to to recover their

144
00:05:19,919 --> 00:05:21,680
images

145
00:05:21,680 --> 00:05:24,000
and they don't want to have a kind of

146
00:05:24,000 --> 00:05:25,120
one perturbation

147
00:05:25,120 --> 00:05:28,400
per image for recoverability

148
00:05:28,400 --> 00:05:30,720
also they want to have a recognizable

149
00:05:30,720 --> 00:05:31,440
image

150
00:05:31,440 --> 00:05:35,360
so they can browse their image or

151
00:05:35,360 --> 00:05:37,840
they can search over their images and

152
00:05:37,840 --> 00:05:39,360
also these approaches should

153
00:05:39,360 --> 00:05:42,960
be should not be able to work with the

154
00:05:42,960 --> 00:05:46,240
current or existing platforms

155
00:05:46,240 --> 00:05:48,000
the first approach that we propose

156
00:05:48,000 --> 00:05:50,400
called universal ensemble perturbation

157
00:05:50,400 --> 00:05:53,759
or uap

158
00:05:53,759 --> 00:05:56,560
universal in ensembles participation

159
00:05:56,560 --> 00:05:59,759
lends a perturbation over a small cnn so

160
00:05:59,759 --> 00:06:03,280
it's compositionally inexpensive

161
00:06:03,280 --> 00:06:05,840
also this approach lends participation

162
00:06:05,840 --> 00:06:08,720
over multiple scenes and several images

163
00:06:08,720 --> 00:06:11,039
to provide transferability and this

164
00:06:11,039 --> 00:06:12,160
approach can

165
00:06:12,160 --> 00:06:15,440
full unknown cns it's a

166
00:06:15,440 --> 00:06:17,280
disapproval adds a perturbation to

167
00:06:17,280 --> 00:06:18,639
architectural hyperbolic

168
00:06:18,639 --> 00:06:21,280
space of the image so we can recover the

169
00:06:21,280 --> 00:06:23,520
image with the minimum loss

170
00:06:23,520 --> 00:06:26,960
and this approach one uh just

171
00:06:26,960 --> 00:06:28,720
learn one particulation for several

172
00:06:28,720 --> 00:06:30,080
images

173
00:06:30,080 --> 00:06:31,919
it means that we don't need to save

174
00:06:31,919 --> 00:06:34,080
several uh one perturbation per

175
00:06:34,080 --> 00:06:36,479
image so this approach actually meets

176
00:06:36,479 --> 00:06:39,840
the practical requirements

177
00:06:40,639 --> 00:06:42,800
to the universal ensemble perturbation

178
00:06:42,800 --> 00:06:44,160
we use three cns

179
00:06:44,160 --> 00:06:46,960
and we learned this particulation over

180
00:06:46,960 --> 00:06:49,280
200 images

181
00:06:49,280 --> 00:06:51,599
the extended colony attack to support in

182
00:06:51,599 --> 00:06:53,599
symbol and universal learning

183
00:06:53,599 --> 00:06:55,280
and then we'll learn a minimum

184
00:06:55,280 --> 00:06:56,880
perturbation that can fool

185
00:06:56,880 --> 00:06:59,440
all these three cnns then we add this

186
00:06:59,440 --> 00:07:01,280
perturbation to the

187
00:07:01,280 --> 00:07:03,440
and hyperbolic space of the image with

188
00:07:03,440 --> 00:07:04,800
the different levels

189
00:07:04,800 --> 00:07:06,800
and this level is defined with the

190
00:07:06,800 --> 00:07:08,319
better values

191
00:07:08,319 --> 00:07:10,560
for example when beta is equal to 3 it

192
00:07:10,560 --> 00:07:11,840
means we add 3 times

193
00:07:11,840 --> 00:07:14,960
more perturbation compared to when the

194
00:07:14,960 --> 00:07:18,400
beta is equal to 1 increasing these

195
00:07:18,400 --> 00:07:21,759
parameter beta values needs

196
00:07:21,759 --> 00:07:25,840
the the transversality increases

197
00:07:25,840 --> 00:07:28,560
to evaluate our uap approach we use

198
00:07:28,560 --> 00:07:29,759
three different

199
00:07:29,759 --> 00:07:32,720
models so the first one is google vision

200
00:07:32,720 --> 00:07:33,360
api

201
00:07:33,360 --> 00:07:35,840
phase detection model which is an online

202
00:07:35,840 --> 00:07:36,960
uh model

203
00:07:36,960 --> 00:07:38,479
and the second one is clarify face

204
00:07:38,479 --> 00:07:40,720
detection and face recognition model and

205
00:07:40,720 --> 00:07:43,440
this is uh these models are online as

206
00:07:43,440 --> 00:07:44,080
well

207
00:07:44,080 --> 00:07:47,280
and we used an offline model um

208
00:07:47,280 --> 00:07:49,520
that's called deep face and it has

209
00:07:49,520 --> 00:07:51,440
facilitation and face recognition

210
00:07:51,440 --> 00:07:54,639
models as well as you can see

211
00:07:54,639 --> 00:07:58,240
we evaluated or uepa for different beta

212
00:07:58,240 --> 00:07:58,800
values

213
00:07:58,800 --> 00:08:02,080
and for beta equal to three we can

214
00:08:02,080 --> 00:08:05,120
see that um the transformability is high

215
00:08:05,120 --> 00:08:06,479
and we can full

216
00:08:06,479 --> 00:08:09,120
face recognition models very well and we

217
00:08:09,120 --> 00:08:09,680
found that

218
00:08:09,680 --> 00:08:12,639
for um that following the face detection

219
00:08:12,639 --> 00:08:14,000
models is really hard

220
00:08:14,000 --> 00:08:16,639
but as long as we can full face

221
00:08:16,639 --> 00:08:18,639
recognition models we can

222
00:08:18,639 --> 00:08:22,479
provide some level of privacy

223
00:08:23,199 --> 00:08:25,680
we also considered the different

224
00:08:25,680 --> 00:08:27,039
potential attacks

225
00:08:27,039 --> 00:08:29,680
against uep and we found that the

226
00:08:29,680 --> 00:08:31,680
perturbation estimation and removal is

227
00:08:31,680 --> 00:08:33,039
the most effective one

228
00:08:33,039 --> 00:08:35,519
in this attack an attacker assumes that

229
00:08:35,519 --> 00:08:36,479
the perturbation

230
00:08:36,479 --> 00:08:39,760
is added directly to pixel's value and

231
00:08:39,760 --> 00:08:41,839
attacker can use the medium function to

232
00:08:41,839 --> 00:08:43,919
estimate uep

233
00:08:43,919 --> 00:08:46,800
for example if the up has again if the

234
00:08:46,800 --> 00:08:48,640
adversary has access to the

235
00:08:48,640 --> 00:08:51,760
multiple protect images uh so

236
00:08:51,760 --> 00:08:55,279
she can estimate the perturbation uep

237
00:08:55,279 --> 00:08:56,880
just by use

238
00:08:56,880 --> 00:08:59,200
by using the media function you can see

239
00:08:59,200 --> 00:09:00,560
the estimated uep

240
00:09:00,560 --> 00:09:04,399
in in the second image from the left

241
00:09:04,399 --> 00:09:07,040
by inverting this estimated uep and add

242
00:09:07,040 --> 00:09:07,600
it to the

243
00:09:07,600 --> 00:09:11,040
petted image an adversary can recover

244
00:09:11,040 --> 00:09:14,640
some image that is classifiable for the

245
00:09:14,640 --> 00:09:18,480
classifiers this image is not

246
00:09:18,480 --> 00:09:21,519
exactly this original one but

247
00:09:21,519 --> 00:09:24,560
good enough for classification the

248
00:09:24,560 --> 00:09:27,440
problem with the uep is that we use the

249
00:09:27,440 --> 00:09:30,160
a single perturbation for several images

250
00:09:30,160 --> 00:09:32,560
so it's not secure

251
00:09:32,560 --> 00:09:35,200
and the solution is that we have to use

252
00:09:35,200 --> 00:09:36,959
a unique perturbation per

253
00:09:36,959 --> 00:09:41,439
image and it's not practical

254
00:09:41,519 --> 00:09:44,560
to address this problem we came up

255
00:09:44,560 --> 00:09:47,680
with another idea and the new approach

256
00:09:47,680 --> 00:09:49,200
is called

257
00:09:49,200 --> 00:09:51,680
k randomized transparent image overlay

258
00:09:51,680 --> 00:09:53,760
or krtio

259
00:09:53,760 --> 00:09:56,720
so transparent overlay images uh for the

260
00:09:56,720 --> 00:09:58,880
first time has been proposed to full

261
00:09:58,880 --> 00:10:01,920
online video classifiers and in which

262
00:10:01,920 --> 00:10:04,959
uh there is a kind of uh source image

263
00:10:04,959 --> 00:10:05,600
and a

264
00:10:05,600 --> 00:10:08,640
overlay image and the overlay image uh

265
00:10:08,640 --> 00:10:11,200
will be added to the source image with

266
00:10:11,200 --> 00:10:12,079
the weight of

267
00:10:12,079 --> 00:10:15,360
alpha so uh for example if if the weight

268
00:10:15,360 --> 00:10:15,920
of

269
00:10:15,920 --> 00:10:18,560
if the alpha is equal to 0.7 it means

270
00:10:18,560 --> 00:10:20,240
the 70 percent of the

271
00:10:20,240 --> 00:10:23,040
image comes from the source image and 30

272
00:10:23,040 --> 00:10:25,120
percent of the competitive image

273
00:10:25,120 --> 00:10:28,000
comes from the overlay image and here

274
00:10:28,000 --> 00:10:29,760
for example

275
00:10:29,760 --> 00:10:32,399
the picture of the car is a an overlay

276
00:10:32,399 --> 00:10:33,680
image and

277
00:10:33,680 --> 00:10:36,959
the picture of the face is

278
00:10:36,959 --> 00:10:40,240
a source image

279
00:10:40,240 --> 00:10:42,720
this approach unfortunately is

280
00:10:42,720 --> 00:10:44,800
vulnerable to blind signal separation

281
00:10:44,800 --> 00:10:46,000
when we use one

282
00:10:46,000 --> 00:10:49,839
overlay image for several images

283
00:10:49,839 --> 00:10:52,959
if we want to save one overlay per image

284
00:10:52,959 --> 00:10:53,519
this

285
00:10:53,519 --> 00:10:56,240
approach can be used for image privacy

286
00:10:56,240 --> 00:10:57,360
but

287
00:10:57,360 --> 00:11:00,560
it's not practical since we need to save

288
00:11:00,560 --> 00:11:04,239
one perturbation per image

289
00:11:05,519 --> 00:11:08,320
to address this problem uh we came up

290
00:11:08,320 --> 00:11:09,360
with a

291
00:11:09,360 --> 00:11:12,000
new idea that's called the kera normal

292
00:11:12,000 --> 00:11:15,360
transparent image overlays or krtio

293
00:11:15,360 --> 00:11:17,920
this approach generates a unique overlay

294
00:11:17,920 --> 00:11:18,480
image

295
00:11:18,480 --> 00:11:21,440
just by using a few overlay images and a

296
00:11:21,440 --> 00:11:23,440
secret key

297
00:11:23,440 --> 00:11:26,160
let's assume that we have a set of

298
00:11:26,160 --> 00:11:28,079
overlay images uh

299
00:11:28,079 --> 00:11:31,360
and we want to generate a a unique

300
00:11:31,360 --> 00:11:32,000
overlay

301
00:11:32,000 --> 00:11:35,279
image for a source image uh this

302
00:11:35,279 --> 00:11:38,959
approach uses the idea of a source image

303
00:11:38,959 --> 00:11:41,360
and secret key to select k

304
00:11:41,360 --> 00:11:44,800
all overlai images let's assume k is

305
00:11:44,800 --> 00:11:46,079
equal to 2.

306
00:11:46,079 --> 00:11:49,600
after selecting two overlay image

307
00:11:49,600 --> 00:11:53,360
this approach divides

308
00:11:53,360 --> 00:11:56,320
the images to the samplex and the

309
00:11:56,320 --> 00:11:57,200
permutes

310
00:11:57,200 --> 00:12:00,800
the black uh the blacks just by using

311
00:12:00,800 --> 00:12:03,120
the idea of the overlay image and the

312
00:12:03,120 --> 00:12:04,639
secret key

313
00:12:04,639 --> 00:12:08,160
after permuting the blacks

314
00:12:08,160 --> 00:12:11,200
this approach computes the average of

315
00:12:11,200 --> 00:12:12,720
the overlay image and

316
00:12:12,720 --> 00:12:14,880
added this average of the overlay image

317
00:12:14,880 --> 00:12:16,160
with the weight of alpha

318
00:12:16,160 --> 00:12:19,680
to the source image

319
00:12:21,519 --> 00:12:24,320
here we present different protected

320
00:12:24,320 --> 00:12:25,839
image with krtl

321
00:12:25,839 --> 00:12:28,959
approach uh on the right you can see the

322
00:12:28,959 --> 00:12:32,320
image that protected with the different

323
00:12:32,320 --> 00:12:35,200
k values and the like sizes for the

324
00:12:35,200 --> 00:12:37,800
fixed alpha which is a quad to

325
00:12:37,800 --> 00:12:40,560
2.5 as you can see

326
00:12:40,560 --> 00:12:43,680
increasing the k values uh leads leads

327
00:12:43,680 --> 00:12:44,160
that

328
00:12:44,160 --> 00:12:46,800
the final image to look like a noisy

329
00:12:46,800 --> 00:12:47,519
image

330
00:12:47,519 --> 00:12:50,320
and now the noisy image the random noise

331
00:12:50,320 --> 00:12:51,920
doesn't work on

332
00:12:51,920 --> 00:12:55,600
cns on the left you can see

333
00:12:55,600 --> 00:12:58,079
that the images that protect with the

334
00:12:58,079 --> 00:13:00,320
different alpha values and black size

335
00:13:00,320 --> 00:13:03,279
and for the k equal to 3 as you can see

336
00:13:03,279 --> 00:13:04,959
increasing the alpha values

337
00:13:04,959 --> 00:13:07,360
and improve the recognizability of the

338
00:13:07,360 --> 00:13:09,440
images

339
00:13:09,440 --> 00:13:13,839
to evaluate krtl approach we evaluated

340
00:13:13,839 --> 00:13:15,920
this approach against google vision api

341
00:13:15,920 --> 00:13:18,160
phase record and phase detection model

342
00:13:18,160 --> 00:13:20,639
as you can see for a k equal to 8 we

343
00:13:20,639 --> 00:13:23,200
couldn't fool this

344
00:13:23,200 --> 00:13:26,079
model very well but for the k equal tree

345
00:13:26,079 --> 00:13:26,720
and the

346
00:13:26,720 --> 00:13:29,760
small values for black size and

347
00:13:29,760 --> 00:13:35,360
alpha we can fold this model very well

348
00:13:35,360 --> 00:13:38,800
also we evaluated krtl against clarify

349
00:13:38,800 --> 00:13:40,639
phase detection and phase recognition

350
00:13:40,639 --> 00:13:42,880
models as you can see for a small value

351
00:13:42,880 --> 00:13:43,519
of the

352
00:13:43,519 --> 00:13:46,560
black size and the alpha and when the k

353
00:13:46,560 --> 00:13:48,639
equal to 3 we can fool the face

354
00:13:48,639 --> 00:13:50,560
recognition models very well

355
00:13:50,560 --> 00:13:52,560
but we cannot we couldn't defool the

356
00:13:52,560 --> 00:13:55,680
face detection model

357
00:13:55,760 --> 00:13:58,720
we also evaluated krtio against the face

358
00:13:58,720 --> 00:14:00,480
face recognition and face detection

359
00:14:00,480 --> 00:14:01,279
models

360
00:14:01,279 --> 00:14:04,079
as you can see again for the small value

361
00:14:04,079 --> 00:14:05,440
of the block size

362
00:14:05,440 --> 00:14:08,160
and the alpha values we could fool this

363
00:14:08,160 --> 00:14:09,519
model very well

364
00:14:09,519 --> 00:14:11,760
in both phase detection and face

365
00:14:11,760 --> 00:14:14,800
recognition models

366
00:14:15,519 --> 00:14:18,240
here they consider different potential

367
00:14:18,240 --> 00:14:20,320
attacks against krtio

368
00:14:20,320 --> 00:14:22,000
the first potential attack could be

369
00:14:22,000 --> 00:14:24,160
improving image

370
00:14:24,160 --> 00:14:26,079
quality using filtering techniques and

371
00:14:26,079 --> 00:14:27,199
the second one

372
00:14:27,199 --> 00:14:30,160
is training a robust cnns on both

373
00:14:30,160 --> 00:14:31,920
spinning and characterio

374
00:14:31,920 --> 00:14:34,560
protected images the first approach

375
00:14:34,560 --> 00:14:35,279
which is the

376
00:14:35,279 --> 00:14:38,560
using filtering techniques is a

377
00:14:38,560 --> 00:14:40,399
computational inexpensive because the

378
00:14:40,399 --> 00:14:41,920
advisory doesn't need

379
00:14:41,920 --> 00:14:46,959
to retain hair models and we found that

380
00:14:46,959 --> 00:14:48,959
different we tried different um

381
00:14:48,959 --> 00:14:50,959
filtering techniques and we found that

382
00:14:50,959 --> 00:14:53,199
these techniques couldn't improve the

383
00:14:53,199 --> 00:14:54,800
face recognitions uh

384
00:14:54,800 --> 00:14:57,600
mod facial cognition models performance

385
00:14:57,600 --> 00:14:59,839
but for some hyper parameters these

386
00:14:59,839 --> 00:15:02,480
techniques could improve the phase

387
00:15:02,480 --> 00:15:03,519
detection

388
00:15:03,519 --> 00:15:06,720
model's performance

389
00:15:06,720 --> 00:15:08,480
the second approach which is that

390
00:15:08,480 --> 00:15:10,639
training a robust cnn

391
00:15:10,639 --> 00:15:13,600
and adversity needs to return a new

392
00:15:13,600 --> 00:15:14,320
model

393
00:15:14,320 --> 00:15:17,760
on both uh character and um

394
00:15:17,760 --> 00:15:20,959
benign images so when an adversary

395
00:15:20,959 --> 00:15:21,600
returns

396
00:15:21,600 --> 00:15:25,360
a robust cnns she can improve

397
00:15:25,360 --> 00:15:28,560
uh her seniors uh accuracy

398
00:15:28,560 --> 00:15:32,480
by uh 15 to 20 percent but this approach

399
00:15:32,480 --> 00:15:35,519
is conditionally expensive and also it

400
00:15:35,519 --> 00:15:36,720
doesn't guarantee

401
00:15:36,720 --> 00:15:39,199
uh robustness for other type of

402
00:15:39,199 --> 00:15:42,160
adversarial examples

403
00:15:42,160 --> 00:15:45,040
in this paper uh we first identified the

404
00:15:45,040 --> 00:15:46,320
practical requirement for

405
00:15:46,320 --> 00:15:48,240
adversarial-based image privacy

406
00:15:48,240 --> 00:15:49,279
approaches that

407
00:15:49,279 --> 00:15:54,000
designed for imaging platforms and we

408
00:15:54,000 --> 00:15:56,240
propose a learning based image adverse

409
00:15:56,240 --> 00:15:57,600
perturbation called uep

410
00:15:57,600 --> 00:16:00,160
and other one is a semantic based

411
00:16:00,160 --> 00:16:03,040
adversarial participation called krtio

412
00:16:03,040 --> 00:16:06,639
for image privacy and we observed that

413
00:16:06,639 --> 00:16:08,800
the semantical the semantic-based

414
00:16:08,800 --> 00:16:11,120
adversarial perturbation krtio

415
00:16:11,120 --> 00:16:13,839
is composition inexpensive and can full

416
00:16:13,839 --> 00:16:15,600
unknown cns and also this

417
00:16:15,600 --> 00:16:17,920
approach is more robust against

418
00:16:17,920 --> 00:16:21,439
different type of attacks

419
00:16:21,519 --> 00:16:23,199
thank you so much for listening to my

420
00:16:23,199 --> 00:16:25,519
presentation if you have any question

421
00:16:25,519 --> 00:16:27,920
uh i would be happy to take them also

422
00:16:27,920 --> 00:16:30,399
you can send your question to my email

423
00:16:30,399 --> 00:16:35,600
or to dr rakesh pupa

