1
00:00:01,120 --> 00:00:03,520
hi today i'm going to talk about privgan

2
00:00:03,520 --> 00:00:06,000
a novel privacy president protecting gan

3
00:00:06,000 --> 00:00:08,640
architecture

4
00:00:10,800 --> 00:00:13,360
dataset sharing is hard essential

5
00:00:13,360 --> 00:00:15,040
sharing data publicly or between

6
00:00:15,040 --> 00:00:16,320
institutions leads to

7
00:00:16,320 --> 00:00:18,000
innovations such as development of new

8
00:00:18,000 --> 00:00:19,680
machine learning models

9
00:00:19,680 --> 00:00:22,480
drug development etc however such data

10
00:00:22,480 --> 00:00:23,439
can often

11
00:00:23,439 --> 00:00:25,359
contain private information about

12
00:00:25,359 --> 00:00:27,199
individuals which can be misused by

13
00:00:27,199 --> 00:00:28,720
malicious actors

14
00:00:28,720 --> 00:00:30,080
therefore there is a huge need to

15
00:00:30,080 --> 00:00:32,159
develop the privacy preserving

16
00:00:32,159 --> 00:00:33,760
techniques to share data between

17
00:00:33,760 --> 00:00:37,280
institutions or publicly

18
00:00:37,680 --> 00:00:39,680
one potential solution is the use of

19
00:00:39,680 --> 00:00:41,280
synthetic data

20
00:00:41,280 --> 00:00:43,360
recent progress in generative machine

21
00:00:43,360 --> 00:00:45,440
learning has led to models that can

22
00:00:45,440 --> 00:00:47,680
generate realistic synthetic data

23
00:00:47,680 --> 00:00:50,800
after training on a real data set

24
00:00:50,800 --> 00:00:54,000
an example is shown here the leftmost

25
00:00:54,000 --> 00:00:54,480
image

26
00:00:54,480 --> 00:00:57,440
is a real image and the two left images

27
00:00:57,440 --> 00:00:59,120
are generated by cans

28
00:00:59,120 --> 00:01:01,840
as you can see the fake images are quite

29
00:01:01,840 --> 00:01:03,680
like the real images

30
00:01:03,680 --> 00:01:06,640
the idea with synthetic data is that the

31
00:01:06,640 --> 00:01:08,720
synthetic datasets can be used to train

32
00:01:08,720 --> 00:01:10,320
models for downstream machine learning

33
00:01:10,320 --> 00:01:12,159
tasks such as regression classification

34
00:01:12,159 --> 00:01:15,520
etc and the naive assumption

35
00:01:15,520 --> 00:01:18,159
that people had when this practice

36
00:01:18,159 --> 00:01:19,680
became common was

37
00:01:19,680 --> 00:01:22,080
that since samples are synthetic each

38
00:01:22,080 --> 00:01:23,840
sample does not leak information about

39
00:01:23,840 --> 00:01:25,600
real people

40
00:01:25,600 --> 00:01:28,240
however this is an incorrect assumption

41
00:01:28,240 --> 00:01:30,159
and i'll explain how

42
00:01:30,159 --> 00:01:32,159
to do that i'll first need to describe

43
00:01:32,159 --> 00:01:34,400
what a membership inference attack is

44
00:01:34,400 --> 00:01:36,960
a membership inference attack is a

45
00:01:36,960 --> 00:01:39,280
privacy attack

46
00:01:39,280 --> 00:01:42,880
where an adversary with access to

47
00:01:42,880 --> 00:01:46,000
many samples wants to just

48
00:01:46,000 --> 00:01:48,880
simply know whether a sample was used to

49
00:01:48,880 --> 00:01:51,280
train a machine learning model or not

50
00:01:51,280 --> 00:01:54,399
the adversary has some access to the

51
00:01:54,399 --> 00:01:58,640
trained model query access

52
00:01:58,640 --> 00:02:02,640
and uses this query the query output for

53
00:02:02,640 --> 00:02:03,680
each sample

54
00:02:03,680 --> 00:02:07,040
to predict whether or not the sample was

55
00:02:07,040 --> 00:02:07,520
used

56
00:02:07,520 --> 00:02:10,080
to train the machine learning model so

57
00:02:10,080 --> 00:02:12,560
why would such an attack work

58
00:02:12,560 --> 00:02:14,560
for tasks like this to work the query

59
00:02:14,560 --> 00:02:16,000
values for

60
00:02:16,000 --> 00:02:17,920
samples used to train the model should

61
00:02:17,920 --> 00:02:19,680
be very different from samples that were

62
00:02:19,680 --> 00:02:22,160
not used to train the model

63
00:02:22,160 --> 00:02:25,440
and as most of you who have

64
00:02:25,440 --> 00:02:27,440
worked with with machine learning would

65
00:02:27,440 --> 00:02:30,000
know that this happens

66
00:02:30,000 --> 00:02:33,200
a lot overfitting a model happens a lot

67
00:02:33,200 --> 00:02:35,120
in machine learning particularly as

68
00:02:35,120 --> 00:02:38,480
model complexity increases and hence

69
00:02:38,480 --> 00:02:41,120
the trainings that sample the query

70
00:02:41,120 --> 00:02:42,560
output for single training set samples

71
00:02:42,560 --> 00:02:43,040
are

72
00:02:43,040 --> 00:02:45,519
quite often quite different from the

73
00:02:45,519 --> 00:02:47,040
samples that were not used in training

74
00:02:47,040 --> 00:02:51,280
making such attacks very powerful

75
00:02:51,280 --> 00:02:54,640
okay um so let's take a quick diversion

76
00:02:54,640 --> 00:02:55,920
diversion to

77
00:02:55,920 --> 00:02:58,959
first uh to define what again is

78
00:02:58,959 --> 00:03:01,200
gan stands for generative adversarial

79
00:03:01,200 --> 00:03:02,480
networks

80
00:03:02,480 --> 00:03:04,319
generally adversarial networks are broad

81
00:03:04,319 --> 00:03:05,760
family of

82
00:03:05,760 --> 00:03:08,400
generative machine learning models and

83
00:03:08,400 --> 00:03:10,239
they usually comprise of

84
00:03:10,239 --> 00:03:12,560
two machine learning modules a generator

85
00:03:12,560 --> 00:03:14,000
and a discriminator

86
00:03:14,000 --> 00:03:16,560
the goal of the generator is attempt to

87
00:03:16,560 --> 00:03:18,480
generate realistic data

88
00:03:18,480 --> 00:03:20,959
while the discriminator attempts to

89
00:03:20,959 --> 00:03:21,680
identify

90
00:03:21,680 --> 00:03:24,879
fake samples from real samples so the

91
00:03:24,879 --> 00:03:25,599
process of

92
00:03:25,599 --> 00:03:27,840
training these two modules reduces to a

93
00:03:27,840 --> 00:03:28,959
two-player game between the

94
00:03:28,959 --> 00:03:30,799
discriminator and the generator

95
00:03:30,799 --> 00:03:32,959
and eventually the generator succeeds in

96
00:03:32,959 --> 00:03:34,319
generating samples that are

97
00:03:34,319 --> 00:03:36,319
indistinguishable from the real

98
00:03:36,319 --> 00:03:39,360
or in other words it learns the

99
00:03:39,360 --> 00:03:41,680
data set that the sample the real

100
00:03:41,680 --> 00:03:43,599
samples are drawn from

101
00:03:43,599 --> 00:03:45,519
so how can such a model overfit to the

102
00:03:45,519 --> 00:03:48,080
training set

103
00:03:48,159 --> 00:03:50,239
to demonstrate that let's look at this

104
00:03:50,239 --> 00:03:52,720
experiment

105
00:03:52,720 --> 00:03:55,680
here we plot a histogram of the

106
00:03:55,680 --> 00:03:57,599
discriminator scores

107
00:03:57,599 --> 00:04:00,000
a quick reminder this screener is just a

108
00:04:00,000 --> 00:04:01,760
binary classifier

109
00:04:01,760 --> 00:04:04,959
for real versus fake so its output is a

110
00:04:04,959 --> 00:04:06,480
number between 0 and 1.

111
00:04:06,480 --> 00:04:09,200
so we plot the histogram of the

112
00:04:09,200 --> 00:04:11,360
discriminator scores for samples that

113
00:04:11,360 --> 00:04:11,840
were

114
00:04:11,840 --> 00:04:14,560
used to train the model shown in red and

115
00:04:14,560 --> 00:04:16,320
samples that were not used to train the

116
00:04:16,320 --> 00:04:16,798
model

117
00:04:16,798 --> 00:04:19,759
shown in blue and as you can see there

118
00:04:19,759 --> 00:04:22,079
is quite a large discrepancy between the

119
00:04:22,079 --> 00:04:23,600
distributions

120
00:04:23,600 --> 00:04:26,080
to the red and the blue distributions

121
00:04:26,080 --> 00:04:27,440
and this is even larger in

122
00:04:27,440 --> 00:04:29,120
passionateness than

123
00:04:29,120 --> 00:04:31,280
compared to mnist uh since fashion

124
00:04:31,280 --> 00:04:34,639
numbness is a more complicated data set

125
00:04:34,639 --> 00:04:37,680
um and as one might imagine since there

126
00:04:37,680 --> 00:04:38,400
are such

127
00:04:38,400 --> 00:04:41,040
there's such a large discrepancy between

128
00:04:41,040 --> 00:04:42,560
these two distributions an

129
00:04:42,560 --> 00:04:45,600
adversary that relies on this difference

130
00:04:45,600 --> 00:04:49,360
would quite would be quite powerful

131
00:04:49,919 --> 00:04:51,759
so what are the existing solutions to

132
00:04:51,759 --> 00:04:54,080
this problem the most common class of

133
00:04:54,080 --> 00:04:55,040
existing solution

134
00:04:55,040 --> 00:04:58,639
is are differentially private gans

135
00:04:58,639 --> 00:05:00,400
as most of you might know differential

136
00:05:00,400 --> 00:05:02,800
privacy is a way to bound the privacy of

137
00:05:02,800 --> 00:05:03,680
algorithms

138
00:05:03,680 --> 00:05:06,560
not models and leads to strong formal

139
00:05:06,560 --> 00:05:08,960
guarantees

140
00:05:08,960 --> 00:05:11,919
it involves the addition of noise to

141
00:05:11,919 --> 00:05:14,400
gradients during discriminator training

142
00:05:14,400 --> 00:05:17,520
as in dbgan

143
00:05:17,520 --> 00:05:20,800
or adding noise to labels

144
00:05:20,800 --> 00:05:23,840
for discriminatory training as in patty

145
00:05:23,840 --> 00:05:25,680
the problem however is that this leads

146
00:05:25,680 --> 00:05:28,240
to very poor synthetic image quality

147
00:05:28,240 --> 00:05:31,199
um as demonstrated in this example here

148
00:05:31,199 --> 00:05:32,880
so the leftmost uh

149
00:05:32,880 --> 00:05:36,840
set of images are real images uh whereas

150
00:05:36,840 --> 00:05:39,840
the everything right of it

151
00:05:39,840 --> 00:05:42,080
are synthetic images and as you can see

152
00:05:42,080 --> 00:05:43,360
as you

153
00:05:43,360 --> 00:05:45,600
decrease the amount of privacy epsilon

154
00:05:45,600 --> 00:05:46,720
here

155
00:05:46,720 --> 00:05:48,960
you eventually get to a point where the

156
00:05:48,960 --> 00:05:49,919
samples are

157
00:05:49,919 --> 00:05:52,560
quite realistic however only for the

158
00:05:52,560 --> 00:05:53,759
rightmost

159
00:05:53,759 --> 00:05:56,319
column where images are horribly

160
00:05:56,319 --> 00:05:57,360
corrupted

161
00:05:57,360 --> 00:06:00,560
is the privacy parameter epsilon

162
00:06:00,560 --> 00:06:04,840
even in a realistic range to provide a

163
00:06:04,840 --> 00:06:08,720
private usable privacy bound everything

164
00:06:08,720 --> 00:06:12,560
left of it is the provides a privacy

165
00:06:12,560 --> 00:06:13,120
bound that

166
00:06:13,120 --> 00:06:16,000
is so loose that it's almost as good as

167
00:06:16,000 --> 00:06:20,240
not providing a bound at all

168
00:06:20,240 --> 00:06:23,840
um this brings us to our solution

169
00:06:23,840 --> 00:06:27,919
protgan private is much like a regular

170
00:06:27,919 --> 00:06:28,400
again

171
00:06:28,400 --> 00:06:30,479
it contains uh of generated and

172
00:06:30,479 --> 00:06:32,080
discriminatory modules but

173
00:06:32,080 --> 00:06:34,240
instead of one generator and one

174
00:06:34,240 --> 00:06:35,120
discriminator

175
00:06:35,120 --> 00:06:37,199
it can module it contains multiple

176
00:06:37,199 --> 00:06:39,199
generators and discriminators

177
00:06:39,199 --> 00:06:41,440
the way it works is the data set is

178
00:06:41,440 --> 00:06:43,759
initially randomly split into two or

179
00:06:43,759 --> 00:06:44,160
more

180
00:06:44,160 --> 00:06:46,800
non-overlapping parts each part of the

181
00:06:46,800 --> 00:06:48,400
data set gets a generator and a

182
00:06:48,400 --> 00:06:50,479
discriminator

183
00:06:50,479 --> 00:06:53,280
the goal of this the generator is now to

184
00:06:53,280 --> 00:06:53,840
fool

185
00:06:53,840 --> 00:06:56,400
not just its corresponding discriminator

186
00:06:56,400 --> 00:06:57,039
but an

187
00:06:57,039 --> 00:06:58,560
additional module called the privacy

188
00:06:58,560 --> 00:07:00,080
discriminator

189
00:07:00,080 --> 00:07:03,039
the privacy discriminator looks at

190
00:07:03,039 --> 00:07:04,800
synthetic data generated from different

191
00:07:04,800 --> 00:07:07,360
generators and tries to tell them apart

192
00:07:07,360 --> 00:07:10,560
and the generator's goal is to therefore

193
00:07:10,560 --> 00:07:12,080
generate synthetic data

194
00:07:12,080 --> 00:07:15,199
that is that somehow has the

195
00:07:15,199 --> 00:07:17,440
characteristics of the overall data set

196
00:07:17,440 --> 00:07:18,800
and not just the portion it's being

197
00:07:18,800 --> 00:07:20,960
exposed to

198
00:07:20,960 --> 00:07:23,039
so this takes the form of a multiplayer

199
00:07:23,039 --> 00:07:24,080
game

200
00:07:24,080 --> 00:07:26,160
and it can be shown that the effect of

201
00:07:26,160 --> 00:07:28,080
adding the privacy discriminator

202
00:07:28,080 --> 00:07:31,199
is um mathematically equivalent

203
00:07:31,199 --> 00:07:34,400
to providing a regularization

204
00:07:34,400 --> 00:07:37,759
of sorts and it bounds the

205
00:07:37,759 --> 00:07:41,120
um the distribution learn

206
00:07:41,120 --> 00:07:43,039
the synthetic distributions learned by

207
00:07:43,039 --> 00:07:45,840
each generator

208
00:07:46,879 --> 00:07:50,240
so the overall

209
00:07:50,240 --> 00:07:53,199
outcome of this process is that proofgan

210
00:07:53,199 --> 00:07:54,960
prevents generators and discriminators

211
00:07:54,960 --> 00:07:59,120
from overfitting to any data split

212
00:07:59,120 --> 00:08:01,759
so how private is bribcan so coming back

213
00:08:01,759 --> 00:08:03,680
to our previous example

214
00:08:03,680 --> 00:08:07,680
of now on

215
00:08:07,680 --> 00:08:10,720
the same data sets that we showed that

216
00:08:10,720 --> 00:08:14,319
the non-private can horribly overfits

217
00:08:14,319 --> 00:08:18,240
um to the training set uh we can show

218
00:08:18,240 --> 00:08:19,520
that trivian

219
00:08:19,520 --> 00:08:22,319
uh again has multiple discriminators so

220
00:08:22,319 --> 00:08:22,720
we

221
00:08:22,720 --> 00:08:24,720
choose one of the one one of the

222
00:08:24,720 --> 00:08:26,080
discriminations on random

223
00:08:26,080 --> 00:08:27,919
and we perform the same experiment and

224
00:08:27,919 --> 00:08:29,680
we show that um

225
00:08:29,680 --> 00:08:31,599
the distribution the difference between

226
00:08:31,599 --> 00:08:33,839
the distributions of same

227
00:08:33,839 --> 00:08:36,399
distributions blue and red is much

228
00:08:36,399 --> 00:08:37,200
smaller

229
00:08:37,200 --> 00:08:40,479
so um discriminatory scores for

230
00:08:40,479 --> 00:08:41,919
samples that were in the training set

231
00:08:41,919 --> 00:08:43,279
versus samples that were not in the

232
00:08:43,279 --> 00:08:44,080
training set

233
00:08:44,080 --> 00:08:46,720
are very small in case of proof gain so

234
00:08:46,720 --> 00:08:48,160
an attack that relies

235
00:08:48,160 --> 00:08:52,560
on the use of such scores would be very

236
00:08:52,839 --> 00:08:54,160
ineffective

237
00:08:54,160 --> 00:08:56,959
so can we show this quantity uh to

238
00:08:56,959 --> 00:08:58,800
demonstrate this quantitatively

239
00:08:58,800 --> 00:09:00,880
we performed experiments against several

240
00:09:00,880 --> 00:09:03,120
state-of-the-art attacks in our paper

241
00:09:03,120 --> 00:09:05,680
uh the one that i'm going to show here

242
00:09:05,680 --> 00:09:06,839
is

243
00:09:06,839 --> 00:09:09,440
um quite similar to the qualitative

244
00:09:09,440 --> 00:09:11,760
experiment shown previously

245
00:09:11,760 --> 00:09:14,480
so the way it works is uh you have data

246
00:09:14,480 --> 00:09:14,959
set

247
00:09:14,959 --> 00:09:17,440
you pass the data set the address has a

248
00:09:17,440 --> 00:09:18,080
data set

249
00:09:18,080 --> 00:09:19,839
passes each of the samples in the data

250
00:09:19,839 --> 00:09:21,279
set through the discriminator

251
00:09:21,279 --> 00:09:24,720
obtains a score for each sample and then

252
00:09:24,720 --> 00:09:28,000
sorts the samples in descending order

253
00:09:28,000 --> 00:09:30,320
the attack also assumes that the

254
00:09:30,320 --> 00:09:32,399
adversary knows how many samples were

255
00:09:32,399 --> 00:09:33,440
used in

256
00:09:33,440 --> 00:09:36,720
the training of the model say n

257
00:09:36,720 --> 00:09:40,720
and takes the top end predictions

258
00:09:40,720 --> 00:09:45,760
um so how successful is this attack

259
00:09:45,760 --> 00:09:48,320
so in the case of a regular gan shown in

260
00:09:48,320 --> 00:09:50,399
red you can see that as you increase the

261
00:09:50,399 --> 00:09:51,600
number of epochs

262
00:09:51,600 --> 00:09:55,120
uh the white box attack accuracy can go

263
00:09:55,120 --> 00:09:58,800
up quite a bit um however prick can

264
00:09:58,800 --> 00:10:00,160
consistently

265
00:10:00,160 --> 00:10:04,399
uh provide um you know

266
00:10:04,399 --> 00:10:06,880
privacy membership privacy protection at

267
00:10:06,880 --> 00:10:08,640
least against this stack

268
00:10:08,640 --> 00:10:11,680
here and we show that

269
00:10:11,680 --> 00:10:15,040
uh we in in the paper we show

270
00:10:15,040 --> 00:10:17,360
that this is true for other

271
00:10:17,360 --> 00:10:18,399
state-of-the-art

272
00:10:18,399 --> 00:10:21,360
heart attacks as well

273
00:10:21,760 --> 00:10:25,120
so how does the hyper parameter choices

274
00:10:25,120 --> 00:10:27,600
improve can affect membership privacy

275
00:10:27,600 --> 00:10:30,320
um tricant has two hyper parameters and

276
00:10:30,320 --> 00:10:31,440
the number of generator and

277
00:10:31,440 --> 00:10:33,360
discriminator pairs

278
00:10:33,360 --> 00:10:36,480
and lambda which is how much we weigh

279
00:10:36,480 --> 00:10:38,959
the differential the privacy

280
00:10:38,959 --> 00:10:40,560
discriminator module

281
00:10:40,560 --> 00:10:44,480
in the in the loss function

282
00:10:44,480 --> 00:10:47,279
so we show here that as you increase

283
00:10:47,279 --> 00:10:48,720
lambda

284
00:10:48,720 --> 00:10:51,200
the white box accuracy decreases on all

285
00:10:51,200 --> 00:10:52,079
data sets

286
00:10:52,079 --> 00:10:54,000
and similarly as you increase the number

287
00:10:54,000 --> 00:10:55,279
of generators you

288
00:10:55,279 --> 00:10:58,560
see the same effect however it is

289
00:10:58,560 --> 00:11:00,800
important to point out that unlike

290
00:11:00,800 --> 00:11:02,320
epsilon and delta and differential

291
00:11:02,320 --> 00:11:03,839
private differentially private

292
00:11:03,839 --> 00:11:06,079
approaches

293
00:11:06,079 --> 00:11:08,240
n and lambda and privigan are data set

294
00:11:08,240 --> 00:11:10,240
dependent quantities and they don't have

295
00:11:10,240 --> 00:11:10,480
an

296
00:11:10,480 --> 00:11:14,160
intrinsic meaning in terms of privacy

297
00:11:14,160 --> 00:11:17,200
so what n and lambda will work best for

298
00:11:17,200 --> 00:11:19,839
your data set is dependent on your data

299
00:11:19,839 --> 00:11:20,320
set

300
00:11:20,320 --> 00:11:25,360
and has to be experimentally determined

301
00:11:25,440 --> 00:11:29,200
so um as mentioned before

302
00:11:29,200 --> 00:11:31,600
uh one of the motivations behind privgan

303
00:11:31,600 --> 00:11:33,600
was uh

304
00:11:33,600 --> 00:11:35,839
providing a decent level of performance

305
00:11:35,839 --> 00:11:37,440
downstream utility

306
00:11:37,440 --> 00:11:40,079
um while providing membership privacy

307
00:11:40,079 --> 00:11:41,200
benefits

308
00:11:41,200 --> 00:11:44,399
so to see whether we're able to do that

309
00:11:44,399 --> 00:11:46,399
we perform this experiment where you

310
00:11:46,399 --> 00:11:47,120
take

311
00:11:47,120 --> 00:11:52,480
um various gans for again

312
00:11:52,480 --> 00:11:55,200
the non-private can and dp can generate

313
00:11:55,200 --> 00:11:56,399
synthetic images

314
00:11:56,399 --> 00:12:00,079
same number as the training set um

315
00:12:00,079 --> 00:12:03,440
in these various data sets train a

316
00:12:03,440 --> 00:12:05,360
cnn based classifier model on the

317
00:12:05,360 --> 00:12:06,480
synthetic data

318
00:12:06,480 --> 00:12:10,000
and then test on the real test set so

319
00:12:10,000 --> 00:12:12,880
uh you can see in the very er on the red

320
00:12:12,880 --> 00:12:13,440
bar

321
00:12:13,440 --> 00:12:16,000
is if you train them the cnn model on

322
00:12:16,000 --> 00:12:17,120
real data

323
00:12:17,120 --> 00:12:19,519
um and test on real data this is

324
00:12:19,519 --> 00:12:21,360
obviously the best case scenario

325
00:12:21,360 --> 00:12:24,560
uh the gray bar is if you use a

326
00:12:24,560 --> 00:12:26,639
non-private can

327
00:12:26,639 --> 00:12:29,200
and then the three blue bars are private

328
00:12:29,200 --> 00:12:31,440
for increasing levels of privacy

329
00:12:31,440 --> 00:12:34,959
uh we test point one one and um

330
00:12:34,959 --> 00:12:38,639
ten uh values for lambda

331
00:12:38,639 --> 00:12:40,800
the green bar is dp again at an epsilon

332
00:12:40,800 --> 00:12:42,480
of 100 which is a ridiculously high

333
00:12:42,480 --> 00:12:44,560
epsilon but anything below that

334
00:12:44,560 --> 00:12:47,600
leads to unusable images pretty much

335
00:12:47,600 --> 00:12:50,480
and you can see consistently that

336
00:12:50,480 --> 00:12:52,240
provgan leads to very

337
00:12:52,240 --> 00:12:57,040
little drop in utility um compared to

338
00:12:57,040 --> 00:13:01,200
um compared to the non-private gan and

339
00:13:01,200 --> 00:13:03,600
the utility is much higher than db can

340
00:13:03,600 --> 00:13:04,399
even for

341
00:13:04,399 --> 00:13:08,639
a very high value of epsilon and d began

342
00:13:08,959 --> 00:13:11,839
um so so far we've shown privacy and

343
00:13:11,839 --> 00:13:13,680
utility separately

344
00:13:13,680 --> 00:13:16,720
and shown that privigen

345
00:13:16,720 --> 00:13:18,240
provides both privacy and utility

346
00:13:18,240 --> 00:13:22,560
benefits but what if we compare

347
00:13:22,560 --> 00:13:25,760
them simultaneously so we

348
00:13:25,760 --> 00:13:28,240
do that here where we take various

349
00:13:28,240 --> 00:13:28,800
values of

350
00:13:28,800 --> 00:13:30,880
epsilon in the case of dpn and various

351
00:13:30,880 --> 00:13:31,839
values of

352
00:13:31,839 --> 00:13:36,160
the lambda in case of privgan and

353
00:13:36,160 --> 00:13:39,920
generate synthetic data and perform um

354
00:13:39,920 --> 00:13:42,480
you know the utility experiment record

355
00:13:42,480 --> 00:13:44,000
the classification accuracy and the

356
00:13:44,000 --> 00:13:45,920
privacy experiment and report the

357
00:13:45,920 --> 00:13:49,600
white box accuracy and you can see that

358
00:13:49,600 --> 00:13:52,959
in across two data sets we can see that

359
00:13:52,959 --> 00:13:53,440
for

360
00:13:53,440 --> 00:13:57,440
most values of membership privacy

361
00:13:57,440 --> 00:13:59,600
quantified by the white box accuracy

362
00:13:59,600 --> 00:14:02,480
privigan provides

363
00:14:02,480 --> 00:14:05,519
much higher utility

364
00:14:05,519 --> 00:14:07,519
measured by classification accuracy in

365
00:14:07,519 --> 00:14:10,160
the previous experiment

366
00:14:10,160 --> 00:14:14,000
and so we can

367
00:14:14,000 --> 00:14:16,560
show that in most regimes uh privcan is

368
00:14:16,560 --> 00:14:18,160
a better alternative to dpgan

369
00:14:18,160 --> 00:14:20,720
and we performed a similar experiment on

370
00:14:20,720 --> 00:14:21,600
patty again

371
00:14:21,600 --> 00:14:23,120
there are several practical deployment

372
00:14:23,120 --> 00:14:25,519
considerations while using privian

373
00:14:25,519 --> 00:14:28,720
the first is scan architecture selection

374
00:14:28,720 --> 00:14:30,480
we recommend performing architecture

375
00:14:30,480 --> 00:14:32,800
selection on the non-private can of your

376
00:14:32,800 --> 00:14:33,519
choice

377
00:14:33,519 --> 00:14:35,360
and then use the same discriminator and

378
00:14:35,360 --> 00:14:36,880
generator architectures

379
00:14:36,880 --> 00:14:41,440
for critcan um the privacy discriminator

380
00:14:41,440 --> 00:14:43,120
which is the additional modules found in

381
00:14:43,120 --> 00:14:45,680
privacan but not in other gans

382
00:14:45,680 --> 00:14:49,040
is simply a minor modification to the

383
00:14:49,040 --> 00:14:51,680
regular discriminator modules and

384
00:14:51,680 --> 00:14:53,199
requires a modification in the final

385
00:14:53,199 --> 00:14:56,319
layer as described in

386
00:14:56,839 --> 00:14:58,320
paper

387
00:14:58,320 --> 00:15:00,000
another consideration might be

388
00:15:00,000 --> 00:15:02,160
membership privacy certification

389
00:15:02,160 --> 00:15:03,839
for both the model and the synthetic

390
00:15:03,839 --> 00:15:06,800
data sets um

391
00:15:06,800 --> 00:15:08,560
we recommend using either

392
00:15:08,560 --> 00:15:11,040
state-of-the-art protects

393
00:15:11,040 --> 00:15:13,920
as query specific empirical certificates

394
00:15:13,920 --> 00:15:14,639
or using

395
00:15:14,639 --> 00:15:16,959
formal query specific private membership

396
00:15:16,959 --> 00:15:19,680
types privacy certification mechanisms

397
00:15:19,680 --> 00:15:23,760
as described in our follow-up work below

398
00:15:25,279 --> 00:15:27,839
um finally private has two additional

399
00:15:27,839 --> 00:15:29,680
hyper parameters

400
00:15:29,680 --> 00:15:31,680
which affect both privacy as well as

401
00:15:31,680 --> 00:15:33,040
utility

402
00:15:33,040 --> 00:15:34,959
we recommend users to identify their

403
00:15:34,959 --> 00:15:37,279
desired utility and query specific

404
00:15:37,279 --> 00:15:38,560
privacy levels

405
00:15:38,560 --> 00:15:40,959
and perform a grid search to identify

406
00:15:40,959 --> 00:15:42,160
appropriate values

407
00:15:42,160 --> 00:15:46,000
of n the number of generators and lambda

408
00:15:46,000 --> 00:15:49,360
that provide the desired utility and

409
00:15:49,360 --> 00:15:53,440
privacy levels and this too can use the

410
00:15:53,440 --> 00:15:56,880
framework cited below in summary

411
00:15:56,880 --> 00:15:58,639
provegan is a novel membership privacy

412
00:15:58,639 --> 00:15:59,759
protecting

413
00:15:59,759 --> 00:16:01,839
can architecture provegan can

414
00:16:01,839 --> 00:16:03,360
effectively protect gans against

415
00:16:03,360 --> 00:16:04,959
state-of-the-art membership inference

416
00:16:04,959 --> 00:16:05,759
attacks

417
00:16:05,759 --> 00:16:07,519
shown in our paper while maintaining

418
00:16:07,519 --> 00:16:09,920
high quality of generated samples

419
00:16:09,920 --> 00:16:12,399
propaganda compares favorably in terms

420
00:16:12,399 --> 00:16:14,399
of privacy versus utility against

421
00:16:14,399 --> 00:16:16,800
other privacy preserving canard

422
00:16:16,800 --> 00:16:18,240
approaches such as the began and

423
00:16:18,240 --> 00:16:19,920
pakistan

424
00:16:19,920 --> 00:16:23,120
and here is the link to our repo

425
00:16:23,120 --> 00:16:28,160
thank you

