1
00:00:01,599 --> 00:00:03,840
hi i'm sameer i'm excited to present

2
00:00:03,840 --> 00:00:05,759
falcon which is a framework for privacy

3
00:00:05,759 --> 00:00:07,520
presenting machine learning

4
00:00:07,520 --> 00:00:09,440
this is joint work with shruti fabrice

5
00:00:09,440 --> 00:00:12,320
er pratik antar

6
00:00:12,320 --> 00:00:14,320
the focus of our mpc framework is on

7
00:00:14,320 --> 00:00:16,400
machine learning applications

8
00:00:16,400 --> 00:00:17,760
similar to prior works when we take a

9
00:00:17,760 --> 00:00:19,920
machine learning model such as this and

10
00:00:19,920 --> 00:00:21,439
want to do either private training or

11
00:00:21,439 --> 00:00:22,480
inference on it

12
00:00:22,480 --> 00:00:23,840
we break it down into a bunch of

13
00:00:23,840 --> 00:00:25,359
functionalities and come up with secure

14
00:00:25,359 --> 00:00:28,960
computation protocols for each of this

15
00:00:29,439 --> 00:00:32,159
so the three uh biggest takeaways uh of

16
00:00:32,159 --> 00:00:32,800
falcon

17
00:00:32,800 --> 00:00:35,840
at first we we extend this uh we

18
00:00:35,840 --> 00:00:38,399
we operate with uh security against both

19
00:00:38,399 --> 00:00:40,000
semi honest as well as malicious

20
00:00:40,000 --> 00:00:40,960
adversaries

21
00:00:40,960 --> 00:00:42,800
so in the honest majority corruption

22
00:00:42,800 --> 00:00:44,640
model and so one party can be corrupt

23
00:00:44,640 --> 00:00:47,520
both semi honest or maliciously

24
00:00:47,520 --> 00:00:51,199
the second key takeaway of falcon is

25
00:00:51,199 --> 00:00:53,280
that protocols are extremely simple so

26
00:00:53,280 --> 00:00:54,960
that makes them very easy to implement

27
00:00:54,960 --> 00:00:56,480
as well as highly performance so they

28
00:00:56,480 --> 00:01:00,160
don't rely on any heavy cryptography

29
00:01:00,160 --> 00:01:01,920
and then the final takeaway is we

30
00:01:01,920 --> 00:01:03,600
evaluate our very large networks and

31
00:01:03,600 --> 00:01:04,479
data sets such as

32
00:01:04,479 --> 00:01:07,280
alex netvg16 which contain hundreds of

33
00:01:07,280 --> 00:01:08,720
millions of parameters

34
00:01:08,720 --> 00:01:11,920
also on larger data sets and we do a

35
00:01:11,920 --> 00:01:13,439
number of other experiments to

36
00:01:13,439 --> 00:01:15,680
really give some new insights on on this

37
00:01:15,680 --> 00:01:17,200
domain of privacy-preserving machine

38
00:01:17,200 --> 00:01:18,640
learning

39
00:01:18,640 --> 00:01:20,560
so i'm going to present each of these uh

40
00:01:20,560 --> 00:01:22,080
three takeaways like what we do

41
00:01:22,080 --> 00:01:24,080
uh in the reverse fashion so i'll start

42
00:01:24,080 --> 00:01:25,759
with um

43
00:01:25,759 --> 00:01:29,840
adversaries so our starting point is

44
00:01:29,840 --> 00:01:31,520
sort of the secure end protocol which

45
00:01:31,520 --> 00:01:33,360
proposed a three-party computation model

46
00:01:33,360 --> 00:01:34,479
with

47
00:01:34,479 --> 00:01:36,479
three parties but then it underneath it

48
00:01:36,479 --> 00:01:38,240
it used a two out of two secret sharing

49
00:01:38,240 --> 00:01:39,439
so

50
00:01:39,439 --> 00:01:40,880
there were two primary parties which

51
00:01:40,880 --> 00:01:42,880
would actually perform the computation

52
00:01:42,880 --> 00:01:44,240
and the third helper party which would

53
00:01:44,240 --> 00:01:47,200
help them all a consequence of a two out

54
00:01:47,200 --> 00:01:48,720
of two secret sharing is that whenever

55
00:01:48,720 --> 00:01:50,320
you reconstruct the value for instance

56
00:01:50,320 --> 00:01:51,520
the secret a

57
00:01:51,520 --> 00:01:54,880
which is as shares a0 and a1 each party

58
00:01:54,880 --> 00:01:56,159
just sends their share to the other

59
00:01:56,159 --> 00:01:58,560
party and both of them now have the

60
00:01:58,560 --> 00:02:01,680
value of the secret a but this

61
00:02:01,680 --> 00:02:03,520
has no security against a malicious

62
00:02:03,520 --> 00:02:05,200
adversary so if one of the parties is

63
00:02:05,200 --> 00:02:07,040
corrupt then they can arbitrarily lie

64
00:02:07,040 --> 00:02:08,639
about their value and so you don't get

65
00:02:08,639 --> 00:02:10,560
any correctness of computation

66
00:02:10,560 --> 00:02:13,840
guarantees when dealing in such a model

67
00:02:13,840 --> 00:02:16,239
the way we address this issue is using

68
00:02:16,239 --> 00:02:17,599
something known as a two out of three

69
00:02:17,599 --> 00:02:19,360
secret sharing this uh

70
00:02:19,360 --> 00:02:21,360
this allows you to have uh it's also

71
00:02:21,360 --> 00:02:23,360
known as replicated secret share

72
00:02:23,360 --> 00:02:25,520
so each party so the secret a is

73
00:02:25,520 --> 00:02:26,720
actually split into

74
00:02:26,720 --> 00:02:29,840
three different shares a0 a1 a2 and each

75
00:02:29,840 --> 00:02:30,480
of these

76
00:02:30,480 --> 00:02:32,239
shares uh two out of these shares are

77
00:02:32,239 --> 00:02:34,000
given to each party so each party is

78
00:02:34,000 --> 00:02:35,440
missing one component

79
00:02:35,440 --> 00:02:38,800
out of these shares one consequence of

80
00:02:38,800 --> 00:02:39,200
this

81
00:02:39,200 --> 00:02:41,760
in the semi honest model you could just

82
00:02:41,760 --> 00:02:43,599
give each party their missing component

83
00:02:43,599 --> 00:02:44,480
and so

84
00:02:44,480 --> 00:02:46,400
for instance the leftmost party can

85
00:02:46,400 --> 00:02:48,239
actually receive the value a0 from one

86
00:02:48,239 --> 00:02:50,319
of the other two parties and and

87
00:02:50,319 --> 00:02:52,239
actually reconstruct the value a

88
00:02:52,239 --> 00:02:54,720
but also in a miniature setting like the

89
00:02:54,720 --> 00:02:56,400
intuition is that you could actually do

90
00:02:56,400 --> 00:02:57,920
the reconstruction two ways so you have

91
00:02:57,920 --> 00:02:58,720
robustness

92
00:02:58,720 --> 00:03:01,760
in the sense that the value a0 is held

93
00:03:01,760 --> 00:03:03,519
by two other parties and so if both of

94
00:03:03,519 --> 00:03:04,720
them send the value

95
00:03:04,720 --> 00:03:07,360
and if the value received are the same

96
00:03:07,360 --> 00:03:08,319
that gives you

97
00:03:08,319 --> 00:03:10,959
a guarantee that there was no malicious

98
00:03:10,959 --> 00:03:12,480
behavior because in particular when you

99
00:03:12,480 --> 00:03:13,840
have a three-party

100
00:03:13,840 --> 00:03:16,080
model with a single corruption we know

101
00:03:16,080 --> 00:03:17,840
at least one of the other two parties is

102
00:03:17,840 --> 00:03:18,480
honest

103
00:03:18,480 --> 00:03:20,720
since there are two honest parties and

104
00:03:20,720 --> 00:03:22,560
this allows you to do

105
00:03:22,560 --> 00:03:25,360
a malicious maliciously secure protocol

106
00:03:25,360 --> 00:03:28,239
with with this one corruption model

107
00:03:28,239 --> 00:03:29,840
so that's sort of the first takeaway

108
00:03:29,840 --> 00:03:31,680
that you can achieve malicious security

109
00:03:31,680 --> 00:03:32,080
uh

110
00:03:32,080 --> 00:03:34,159
using this replicated secret sharing as

111
00:03:34,159 --> 00:03:35,680
as the foundation of

112
00:03:35,680 --> 00:03:39,200
of the entire protocols the

113
00:03:39,200 --> 00:03:41,040
the second key insight is this is the

114
00:03:41,040 --> 00:03:42,799
functional dependence of secure nn but

115
00:03:42,799 --> 00:03:44,640
that's largely the case for

116
00:03:44,640 --> 00:03:47,680
most prior work so each of these works

117
00:03:47,680 --> 00:03:52,000
usually would would

118
00:03:52,959 --> 00:03:54,560
use like roughly a similar functional

119
00:03:54,560 --> 00:03:56,959
dependence so in particular we have

120
00:03:56,959 --> 00:03:58,720
these set of functionalities such as max

121
00:03:58,720 --> 00:04:01,120
pool relu division matrix multiplication

122
00:04:01,120 --> 00:04:03,840
all of these are common to pretty much

123
00:04:03,840 --> 00:04:05,519
all these prior words because

124
00:04:05,519 --> 00:04:07,120
the end goal is to actually train neural

125
00:04:07,120 --> 00:04:09,200
networks um

126
00:04:09,200 --> 00:04:12,480
secure nnn had this set of protocols

127
00:04:12,480 --> 00:04:13,840
which they proposed which was a private

128
00:04:13,840 --> 00:04:15,519
comparison protocol compute msb and

129
00:04:15,519 --> 00:04:16,560
share convert

130
00:04:16,560 --> 00:04:19,358
and the share convert and compute msb

131
00:04:19,358 --> 00:04:21,680
these were really

132
00:04:21,680 --> 00:04:23,680
the core contributions which actually

133
00:04:23,680 --> 00:04:25,040
allow you to do a

134
00:04:25,040 --> 00:04:27,680
derivative of relu or a comparison and

135
00:04:27,680 --> 00:04:29,600
each of them use the subroutine private

136
00:04:29,600 --> 00:04:30,880
compare

137
00:04:30,880 --> 00:04:32,479
roughly once and private compare is

138
00:04:32,479 --> 00:04:34,080
really the bottleneck of these protocols

139
00:04:34,080 --> 00:04:35,360
and so

140
00:04:35,360 --> 00:04:36,960
the overhead of this is roughly two

141
00:04:36,960 --> 00:04:38,400
times the overhead of a private

142
00:04:38,400 --> 00:04:40,880
comparison protocol

143
00:04:40,880 --> 00:04:43,360
so the first biggest change uh falcon

144
00:04:43,360 --> 00:04:45,520
makes is uh in actually replacing these

145
00:04:45,520 --> 00:04:46,880
two functionalities with a single

146
00:04:46,880 --> 00:04:48,479
functionality called wrap

147
00:04:48,479 --> 00:04:50,479
um the intuition for which i'm going to

148
00:04:50,479 --> 00:04:52,000
present a little later

149
00:04:52,000 --> 00:04:53,520
uh we replace it by that so that

150
00:04:53,520 --> 00:04:55,360
immediately improves the performance by

151
00:04:55,360 --> 00:04:58,720
by by twice and

152
00:04:58,720 --> 00:05:01,280
um so as a consequence the first thing

153
00:05:01,280 --> 00:05:02,240
is we actually

154
00:05:02,240 --> 00:05:05,039
enable such a a protocol for this in the

155
00:05:05,039 --> 00:05:06,320
replicated secret sharing

156
00:05:06,320 --> 00:05:08,479
model whereas securin was a highly

157
00:05:08,479 --> 00:05:10,000
two-party computation model so it was

158
00:05:10,000 --> 00:05:13,680
really using the third party to uh

159
00:05:13,680 --> 00:05:16,800
to actually do very uh to do simple

160
00:05:16,800 --> 00:05:17,759
things which which

161
00:05:17,759 --> 00:05:19,120
which cannot be proven secure in the

162
00:05:19,120 --> 00:05:22,160
maliciously secure model uh whereas

163
00:05:22,160 --> 00:05:24,000
the the first contribution here is to

164
00:05:24,000 --> 00:05:26,560
actually enable a protocol for rap

165
00:05:26,560 --> 00:05:28,320
which is secure even in this uh

166
00:05:28,320 --> 00:05:30,880
replicated secret sharing

167
00:05:30,880 --> 00:05:32,720
the other one is uh the highly efficient

168
00:05:32,720 --> 00:05:34,400
part is the protocol for this actually

169
00:05:34,400 --> 00:05:36,000
does not use any heavy crypto is just

170
00:05:36,000 --> 00:05:37,680
addition subtraction

171
00:05:37,680 --> 00:05:40,000
bit operations and not even secret bit

172
00:05:40,000 --> 00:05:41,680
operations over local values

173
00:05:41,680 --> 00:05:44,639
and so that makes it highly performant

174
00:05:44,639 --> 00:05:46,479
and then the final change is we actually

175
00:05:46,479 --> 00:05:47,680
implemented

176
00:05:47,680 --> 00:05:49,600
a leaky version of a batch noun protocol

177
00:05:49,600 --> 00:05:50,720
so where it reveals

178
00:05:50,720 --> 00:05:54,000
a quantified amount of information but

179
00:05:54,000 --> 00:05:56,400
we have a very efficient in with

180
00:05:56,400 --> 00:05:57,759
concrete efficiency we have a very

181
00:05:57,759 --> 00:05:59,759
efficient protocol for batch now

182
00:05:59,759 --> 00:06:01,919
which is really required for training

183
00:06:01,919 --> 00:06:04,479
large networks such as alexnet and pgg

184
00:06:04,479 --> 00:06:06,319
and these are really high multi-million

185
00:06:06,319 --> 00:06:09,039
parameter networks so such as this

186
00:06:09,039 --> 00:06:12,960
so that's what can largely be said is uh

187
00:06:12,960 --> 00:06:14,800
how we change the uh functionality

188
00:06:14,800 --> 00:06:16,880
dependence

189
00:06:16,880 --> 00:06:19,120
so before i proceed let me give a quick

190
00:06:19,120 --> 00:06:20,880
intuition before i set up the intuition

191
00:06:20,880 --> 00:06:22,960
behind the comparison protocol

192
00:06:22,960 --> 00:06:25,440
i'll also talk briefly about the fixed

193
00:06:25,440 --> 00:06:28,000
point arithmetic part of this so

194
00:06:28,000 --> 00:06:31,120
when we want to train our

195
00:06:31,120 --> 00:06:32,800
neural networks we we actually want to

196
00:06:32,800 --> 00:06:34,960
use floating point values

197
00:06:34,960 --> 00:06:37,919
and on the other end when we use we want

198
00:06:37,919 --> 00:06:39,520
to do cryptographic operations we we

199
00:06:39,520 --> 00:06:42,000
prefer using fixed point values and so

200
00:06:42,000 --> 00:06:43,680
if this is the range of values so this

201
00:06:43,680 --> 00:06:45,759
is 64-bit values

202
00:06:45,759 --> 00:06:49,039
and this is the unsigned 64-bit integers

203
00:06:49,039 --> 00:06:49,440
and

204
00:06:49,440 --> 00:06:50,880
data type you're most familiar with so

205
00:06:50,880 --> 00:06:52,720
zeros represents all

206
00:06:52,720 --> 00:06:54,960
all zeros representable number zero and

207
00:06:54,960 --> 00:06:56,160
all one represents

208
00:06:56,160 --> 00:06:59,199
the number two to the power 64 minus one

209
00:06:59,199 --> 00:07:01,440
uh fixed point arithmetic implies that

210
00:07:01,440 --> 00:07:02,560
we actually consider

211
00:07:02,560 --> 00:07:04,319
we interpret these values differently so

212
00:07:04,319 --> 00:07:06,000
we actually consider there is a binary

213
00:07:06,000 --> 00:07:06,639
point

214
00:07:06,639 --> 00:07:09,199
somewhere so here it's shown uh at the

215
00:07:09,199 --> 00:07:09,919
end from

216
00:07:09,919 --> 00:07:12,479
five decimal digits and so the fixed

217
00:07:12,479 --> 00:07:13,599
point precision of this

218
00:07:13,599 --> 00:07:17,120
is five binary bits and so

219
00:07:17,120 --> 00:07:20,800
a number such as a unsigned 64-bit

220
00:07:20,800 --> 00:07:23,360
number which is 7 which is shown in here

221
00:07:23,360 --> 00:07:25,039
is actually represented by the floating

222
00:07:25,039 --> 00:07:27,599
point number which is 7 over 32 and 32

223
00:07:27,599 --> 00:07:29,840
is the fifth power of

224
00:07:29,840 --> 00:07:32,319
and so this is sort of the mapping which

225
00:07:32,319 --> 00:07:34,319
uh which the protocols have to kind of

226
00:07:34,319 --> 00:07:36,080
implicitly take into account that there

227
00:07:36,080 --> 00:07:38,080
is a fixed point encoding in there

228
00:07:38,080 --> 00:07:41,360
and then um consider them

229
00:07:41,360 --> 00:07:43,360
so when we talk about this this sort of

230
00:07:43,360 --> 00:07:44,800
encoding

231
00:07:44,800 --> 00:07:47,440
the the first thing is positive and

232
00:07:47,440 --> 00:07:49,039
negative numbers are encoded in these

233
00:07:49,039 --> 00:07:50,319
two half ranges

234
00:07:50,319 --> 00:07:52,160
and so the relu or the comparison

235
00:07:52,160 --> 00:07:53,440
function is

236
00:07:53,440 --> 00:07:56,319
is really just figuring out if a number

237
00:07:56,319 --> 00:07:57,759
is positive or negative and so we want

238
00:07:57,759 --> 00:07:59,360
to find if a number is in the first half

239
00:07:59,360 --> 00:08:02,080
or the second half

240
00:08:02,319 --> 00:08:03,759
so that's that's the foundations

241
00:08:03,759 --> 00:08:05,199
technique let's take a look at what the

242
00:08:05,199 --> 00:08:06,879
secure comparison uh problem is so

243
00:08:06,879 --> 00:08:08,319
secure comparison on the left

244
00:08:08,319 --> 00:08:10,160
is we have the input a which is secret

245
00:08:10,160 --> 00:08:12,400
shared as a0 a1 a2

246
00:08:12,400 --> 00:08:13,919
and as i mentioned before it's it's

247
00:08:13,919 --> 00:08:15,759
replicated secret sharing and so

248
00:08:15,759 --> 00:08:18,720
each component is shared uh is is held

249
00:08:18,720 --> 00:08:20,240
by two parties

250
00:08:20,240 --> 00:08:21,840
and on the right we have the output

251
00:08:21,840 --> 00:08:23,840
which is let's say the most significant

252
00:08:23,840 --> 00:08:24,800
bit of a

253
00:08:24,800 --> 00:08:27,039
because most significant bit as we saw

254
00:08:27,039 --> 00:08:28,639
is indicates whether you're in the left

255
00:08:28,639 --> 00:08:29,840
half or the right half

256
00:08:29,840 --> 00:08:31,520
and so if you want to compute this so

257
00:08:31,520 --> 00:08:33,519
let's say that most significant bit x is

258
00:08:33,519 --> 00:08:35,679
x which is 0 or 1

259
00:08:35,679 --> 00:08:37,279
we have shares of x let's say in the

260
00:08:37,279 --> 00:08:39,760
arithmetic sharing here

261
00:08:39,760 --> 00:08:42,000
so the way we approach this is we break

262
00:08:42,000 --> 00:08:43,360
down this into

263
00:08:43,360 --> 00:08:45,760
a few different components so the first

264
00:08:45,760 --> 00:08:47,040
insight is that

265
00:08:47,040 --> 00:08:49,040
once you have arithmetic secret sharing

266
00:08:49,040 --> 00:08:51,279
a uh you can only have one of three

267
00:08:51,279 --> 00:08:53,120
possibilities that the summation

268
00:08:53,120 --> 00:08:56,399
a0 a1 a2 that is actually in

269
00:08:56,399 --> 00:08:58,320
in a modular arithmetic sense is always

270
00:08:58,320 --> 00:08:59,440
equal to a

271
00:08:59,440 --> 00:09:01,519
but it can take one of three values it

272
00:09:01,519 --> 00:09:02,880
can be between 0

273
00:09:02,880 --> 00:09:04,560
and 2 to the power k which is the

274
00:09:04,560 --> 00:09:06,959
modulus here so that's the first

275
00:09:06,959 --> 00:09:09,200
possibility the second one is actually

276
00:09:09,200 --> 00:09:11,120
it's actually between 2 to the power k

277
00:09:11,120 --> 00:09:11,440
and

278
00:09:11,440 --> 00:09:13,519
twice that value and the third one is

279
00:09:13,519 --> 00:09:15,120
between two i centralize the value so

280
00:09:15,120 --> 00:09:16,560
those are the only three possibilities

281
00:09:16,560 --> 00:09:16,959
because

282
00:09:16,959 --> 00:09:19,360
each individual share is a number

283
00:09:19,360 --> 00:09:20,959
between 0 and 2 to the power k

284
00:09:20,959 --> 00:09:22,880
and so when you add 3 of them the sum

285
00:09:22,880 --> 00:09:24,640
can at most be 3 times

286
00:09:24,640 --> 00:09:27,440
2 to the power k and so once we have

287
00:09:27,440 --> 00:09:29,839
these three possibilities

288
00:09:29,839 --> 00:09:31,839
we we define something called as the

289
00:09:31,839 --> 00:09:33,600
wrap function which basically says that

290
00:09:33,600 --> 00:09:35,440
whether you are in possibility 1 two or

291
00:09:35,440 --> 00:09:36,480
three

292
00:09:36,480 --> 00:09:39,279
and the biggest insight here is is that

293
00:09:39,279 --> 00:09:39,760
this

294
00:09:39,760 --> 00:09:41,920
function is sufficient or like just

295
00:09:41,920 --> 00:09:42,800
knowing this

296
00:09:42,800 --> 00:09:45,200
um a0 like whether we are in case one

297
00:09:45,200 --> 00:09:46,320
two or three

298
00:09:46,320 --> 00:09:48,000
that functionality is sufficient to

299
00:09:48,000 --> 00:09:50,000
actually compute this msp

300
00:09:50,000 --> 00:09:51,760
and that insight is given by this

301
00:09:51,760 --> 00:09:53,200
equation

302
00:09:53,200 --> 00:09:55,120
what it says is the most significant bit

303
00:09:55,120 --> 00:09:57,680
of a number is actually a local com

304
00:09:57,680 --> 00:10:00,800
operation so once you compute this wrap

305
00:10:00,800 --> 00:10:02,560
function on three different values and

306
00:10:02,560 --> 00:10:04,160
these different values are just twice

307
00:10:04,160 --> 00:10:05,360
the value of

308
00:10:05,360 --> 00:10:09,519
the shares you can actually compute the

309
00:10:09,519 --> 00:10:13,200
msb using uh local operations so

310
00:10:13,200 --> 00:10:14,800
you compute this wrap function and then

311
00:10:14,800 --> 00:10:17,600
you xor it with msb's of a1 a2 a3

312
00:10:17,600 --> 00:10:19,360
which are actually already locally

313
00:10:19,360 --> 00:10:21,600
available to each of the parties

314
00:10:21,600 --> 00:10:24,640
and so that's the inside let's take a

315
00:10:24,640 --> 00:10:26,160
quick look into why

316
00:10:26,160 --> 00:10:29,360
um some intuition behind this insight

317
00:10:29,360 --> 00:10:30,480
and so

318
00:10:30,480 --> 00:10:32,959
this the best way to look at this is uh

319
00:10:32,959 --> 00:10:33,519
as

320
00:10:33,519 --> 00:10:35,760
as going uh the old school way of like

321
00:10:35,760 --> 00:10:37,120
writing this addition so let's say

322
00:10:37,120 --> 00:10:39,040
a0 a1 a2 are these three numbers and

323
00:10:39,040 --> 00:10:40,240
then they add up to this

324
00:10:40,240 --> 00:10:42,160
in a modular sense add up to a and so

325
00:10:42,160 --> 00:10:43,360
this is the sum

326
00:10:43,360 --> 00:10:45,360
now when we say we are interested in

327
00:10:45,360 --> 00:10:47,279
computing the most significant bit

328
00:10:47,279 --> 00:10:49,519
uh we are interested in this uh this bit

329
00:10:49,519 --> 00:10:51,519
zero here

330
00:10:51,519 --> 00:10:54,160
the way this bit is done as um in terms

331
00:10:54,160 --> 00:10:55,680
of the addition is simply going to be

332
00:10:55,680 --> 00:10:56,240
the sum

333
00:10:56,240 --> 00:10:58,720
of this bit this bit this bit like the

334
00:10:58,720 --> 00:11:01,120
msbs of a0 a1 a2

335
00:11:01,120 --> 00:11:03,519
and it's also going to contain one more

336
00:11:03,519 --> 00:11:05,920
factor which is what is the carry over

337
00:11:05,920 --> 00:11:08,160
and that's really the inside that noting

338
00:11:08,160 --> 00:11:10,160
that the carry over of this

339
00:11:10,160 --> 00:11:12,560
remaining half is simply the wrap

340
00:11:12,560 --> 00:11:13,440
function

341
00:11:13,440 --> 00:11:17,040
computed on uh twice the values and the

342
00:11:17,040 --> 00:11:18,399
reason why it's twice the values is

343
00:11:18,399 --> 00:11:19,120
because

344
00:11:19,120 --> 00:11:21,120
once you compute two times a zero it

345
00:11:21,120 --> 00:11:23,200
just bit shifts this entire box

346
00:11:23,200 --> 00:11:25,680
by one one bit to the left and so that

347
00:11:25,680 --> 00:11:26,480
gives you the

348
00:11:26,480 --> 00:11:29,839
the carry bit of this operation and then

349
00:11:29,839 --> 00:11:32,640
uh if effectively if you xor that along

350
00:11:32,640 --> 00:11:34,800
with the msbs of a0 a1 a2

351
00:11:34,800 --> 00:11:38,000
you get the msb of a um one

352
00:11:38,000 --> 00:11:39,600
one detail which i missed here is even

353
00:11:39,600 --> 00:11:40,880
though rap3 has three different

354
00:11:40,880 --> 00:11:42,000
possibilities so it can take

355
00:11:42,000 --> 00:11:45,120
value 0 1 2. we only consider the mod 2

356
00:11:45,120 --> 00:11:46,720
reduction of that and so all you care

357
00:11:46,720 --> 00:11:48,560
about is is the carry over 0

358
00:11:48,560 --> 00:11:51,120
or 1 and so that's effectively what we

359
00:11:51,120 --> 00:11:53,839
do in the paper

360
00:11:54,320 --> 00:11:56,800
so with that i'm going to jump into the

361
00:11:56,800 --> 00:11:58,560
experimental evaluation components of

362
00:11:58,560 --> 00:11:59,600
this work so

363
00:11:59,600 --> 00:12:02,320
falcon is open sourced um and it's

364
00:12:02,320 --> 00:12:03,920
available at this repository

365
00:12:03,920 --> 00:12:05,920
uh it has passed the artifact submission

366
00:12:05,920 --> 00:12:07,360
and we are

367
00:12:07,360 --> 00:12:11,120
happy to have people use this code base

368
00:12:11,120 --> 00:12:13,120
the falcon the pseudocode is really

369
00:12:13,120 --> 00:12:14,480
simple once you write some of the basic

370
00:12:14,480 --> 00:12:15,279
functionalities

371
00:12:15,279 --> 00:12:16,720
addition subtractions you can actually

372
00:12:16,720 --> 00:12:18,399
write it in a few lines of code

373
00:12:18,399 --> 00:12:21,760
and so that's one of the benefits of

374
00:12:21,760 --> 00:12:24,959
a simple protocol the the second one is

375
00:12:24,959 --> 00:12:27,440
we actually evaluated over a series of

376
00:12:27,440 --> 00:12:28,320
different uh

377
00:12:28,320 --> 00:12:30,639
neural network architectures so we go

378
00:12:30,639 --> 00:12:32,160
from all the way from simple multi-layer

379
00:12:32,160 --> 00:12:33,360
perceptron such as

380
00:12:33,360 --> 00:12:35,839
secure ml which the the values in these

381
00:12:35,839 --> 00:12:37,519
boxes are the number of parameters these

382
00:12:37,519 --> 00:12:38,720
networks use

383
00:12:38,720 --> 00:12:42,000
to some cnn such as mini and leonard

384
00:12:42,000 --> 00:12:43,760
and then all the way to large networks

385
00:12:43,760 --> 00:12:46,560
such as alex netg16 so these contain

386
00:12:46,560 --> 00:12:48,240
more than tens or hundreds of millions

387
00:12:48,240 --> 00:12:50,880
of parameters

388
00:12:50,959 --> 00:12:53,519
so the first work is comparison with

389
00:12:53,519 --> 00:12:54,720
prior work and so

390
00:12:54,720 --> 00:12:56,720
here this is numbers presented so we

391
00:12:56,720 --> 00:12:58,320
perform extensive comparison with prime

392
00:12:58,320 --> 00:12:58,959
work

393
00:12:58,959 --> 00:13:01,279
uh on the same set of networks we also

394
00:13:01,279 --> 00:13:02,079
test our

395
00:13:02,079 --> 00:13:05,519
networks over lan as well as well and so

396
00:13:05,519 --> 00:13:06,959
as you can see here like falcon

397
00:13:06,959 --> 00:13:08,880
generally outperforms prior work

398
00:13:08,880 --> 00:13:11,120
uh by by a significant margin the

399
00:13:11,120 --> 00:13:12,480
communication is also

400
00:13:12,480 --> 00:13:15,680
significantly lower we also perform

401
00:13:15,680 --> 00:13:17,600
experiments for private training so

402
00:13:17,600 --> 00:13:19,200
here are some of the frameworks which do

403
00:13:19,200 --> 00:13:21,440
private training and then again we might

404
00:13:21,440 --> 00:13:24,399
benchmark these over both lan and van

405
00:13:24,399 --> 00:13:27,120
network settings

406
00:13:27,120 --> 00:13:28,639
the other set of experiments is we

407
00:13:28,639 --> 00:13:30,560
actually run experience on larger

408
00:13:30,560 --> 00:13:31,360
networks so

409
00:13:31,360 --> 00:13:34,240
here we run it on lxnet vg16 on c4 as

410
00:13:34,240 --> 00:13:36,639
well as like tiny machine data sets

411
00:13:36,639 --> 00:13:39,440
and uh these are the the benchmarks of

412
00:13:39,440 --> 00:13:40,560
of the protocol

413
00:13:40,560 --> 00:13:42,320
some of these results are slightly grim

414
00:13:42,320 --> 00:13:44,320
in the sense the time taken to

415
00:13:44,320 --> 00:13:45,920
actually train these networks can run

416
00:13:45,920 --> 00:13:47,440
all the way up to years

417
00:13:47,440 --> 00:13:49,519
but once again like the the protocol the

418
00:13:49,519 --> 00:13:51,199
code base is not highly optimized in

419
00:13:51,199 --> 00:13:52,959
that sense and so

420
00:13:52,959 --> 00:13:55,040
there is definitely room for improvement

421
00:13:55,040 --> 00:13:56,079
here and

422
00:13:56,079 --> 00:13:58,480
getting these training times down to

423
00:13:58,480 --> 00:14:01,440
more practical values

424
00:14:01,440 --> 00:14:03,920
the the one other really interesting

425
00:14:03,920 --> 00:14:05,760
insight when running um

426
00:14:05,760 --> 00:14:08,160
this uh the benchmarking over larger

427
00:14:08,160 --> 00:14:10,720
networks is presented in this graph

428
00:14:10,720 --> 00:14:13,120
so this is something which um which came

429
00:14:13,120 --> 00:14:14,720
as a slight surprise uh

430
00:14:14,720 --> 00:14:16,639
partly also it has to do a lot with like

431
00:14:16,639 --> 00:14:18,720
how this uh the program is implemented

432
00:14:18,720 --> 00:14:20,320
and over what frameworks and

433
00:14:20,320 --> 00:14:23,519
but the uh each different uh

434
00:14:23,519 --> 00:14:25,120
mpc protocol like so if you take a

435
00:14:25,120 --> 00:14:26,720
functionality such as convolution matrix

436
00:14:26,720 --> 00:14:27,600
multiplication

437
00:14:27,600 --> 00:14:29,600
comparison and so on all of them have

438
00:14:29,600 --> 00:14:31,600
different scalings

439
00:14:31,600 --> 00:14:34,480
with sizes and so if we take different

440
00:14:34,480 --> 00:14:34,880
uh

441
00:14:34,880 --> 00:14:37,199
network architectures they scale very

442
00:14:37,199 --> 00:14:38,880
differently in mpc

443
00:14:38,880 --> 00:14:41,199
as the skies grows and what happens is

444
00:14:41,199 --> 00:14:42,959
once we go to very large networks

445
00:14:42,959 --> 00:14:44,800
the matrix multiplication cost just

446
00:14:44,800 --> 00:14:46,160
starts dominating

447
00:14:46,160 --> 00:14:47,839
uh which in hindsight starts making

448
00:14:47,839 --> 00:14:50,160
sense because matrix multiplication is

449
00:14:50,160 --> 00:14:52,480
uh a super quadratic operation and so no

450
00:14:52,480 --> 00:14:54,000
matter what happens the computation is

451
00:14:54,000 --> 00:14:56,000
going to go more than quadratic

452
00:14:56,000 --> 00:14:59,760
whereas um the the rest of the protocols

453
00:14:59,760 --> 00:15:01,279
comparison which is the most dominant

454
00:15:01,279 --> 00:15:03,360
cause from the mpc point of view

455
00:15:03,360 --> 00:15:06,720
still runs over vectors or

456
00:15:06,720 --> 00:15:09,120
like vectors over which are at most

457
00:15:09,120 --> 00:15:11,040
quadratic in the size of the matrices

458
00:15:11,040 --> 00:15:12,639
and so that tussle eventually starts

459
00:15:12,639 --> 00:15:13,920
blowing up when you go to larger

460
00:15:13,920 --> 00:15:15,040
networks and so

461
00:15:15,040 --> 00:15:16,480
these start becoming more and more

462
00:15:16,480 --> 00:15:18,399
compute dominated so here is a graph

463
00:15:18,399 --> 00:15:19,279
which presents

464
00:15:19,279 --> 00:15:22,160
the relative uh overhead of a network

465
00:15:22,160 --> 00:15:23,040
time spent in

466
00:15:23,040 --> 00:15:26,959
communication versus in computation

467
00:15:26,959 --> 00:15:29,519
um so this this is also a very

468
00:15:29,519 --> 00:15:30,560
interesting insight that

469
00:15:30,560 --> 00:15:32,399
it challenges our understanding that mpc

470
00:15:32,399 --> 00:15:34,079
is just always communication bound it

471
00:15:34,079 --> 00:15:35,600
really depends on the setup and it can

472
00:15:35,600 --> 00:15:37,360
become compute bound when you go to

473
00:15:37,360 --> 00:15:40,639
very very large networks

474
00:15:40,639 --> 00:15:43,040
we also provide some comparison with

475
00:15:43,040 --> 00:15:44,639
plain text computation so these are

476
00:15:44,639 --> 00:15:46,639
not apples to apples comparison because

477
00:15:46,639 --> 00:15:48,800
the plain text versions are run both on

478
00:15:48,800 --> 00:15:50,320
cpu as well as gpu

479
00:15:50,320 --> 00:15:52,720
whereas the mpc versions are only run on

480
00:15:52,720 --> 00:15:53,519
cpu

481
00:15:53,519 --> 00:15:56,160
the other difference of comparison is

482
00:15:56,160 --> 00:15:58,079
that they are run over by torch which is

483
00:15:58,079 --> 00:15:59,759
really the popular uh benchmarking

484
00:15:59,759 --> 00:16:01,199
framework and

485
00:16:01,199 --> 00:16:03,440
it generally shows that like over lan

486
00:16:03,440 --> 00:16:05,360
mpc protocols are about

487
00:16:05,360 --> 00:16:07,680
two to three orders of magnitude slower

488
00:16:07,680 --> 00:16:09,279
and the van setting could be another

489
00:16:09,279 --> 00:16:10,959
order of magnitude slower than that and

490
00:16:10,959 --> 00:16:12,560
this is benchmark only for the larger

491
00:16:12,560 --> 00:16:15,040
networks

492
00:16:15,120 --> 00:16:18,240
finally we also find out that

493
00:16:18,240 --> 00:16:20,240
if you are only focusing on private

494
00:16:20,240 --> 00:16:22,320
inference 32-bit values

495
00:16:22,320 --> 00:16:24,160
do give us like sufficiently high

496
00:16:24,160 --> 00:16:25,920
precision and so this is uh

497
00:16:25,920 --> 00:16:27,839
verified in this experiment here so on

498
00:16:27,839 --> 00:16:29,279
the left we have a

499
00:16:29,279 --> 00:16:32,320
clear text output on the same network

500
00:16:32,320 --> 00:16:34,320
uh so done with no privacy in it and

501
00:16:34,320 --> 00:16:36,320
it's over 64-bit float so it has

502
00:16:36,320 --> 00:16:38,320
arbitrary high precision

503
00:16:38,320 --> 00:16:40,480
and on the right we have the mpc output

504
00:16:40,480 --> 00:16:42,639
of private inference performed using

505
00:16:42,639 --> 00:16:43,360
falcon

506
00:16:43,360 --> 00:16:45,920
or only 32-bit integer data types and as

507
00:16:45,920 --> 00:16:47,920
you can see the values usually agree up

508
00:16:47,920 --> 00:16:50,000
to two or three decimal digits

509
00:16:50,000 --> 00:16:52,399
and this is already huge because neural

510
00:16:52,399 --> 00:16:54,480
networks already are fairly robust

511
00:16:54,480 --> 00:16:56,399
and when we actually perform this

512
00:16:56,399 --> 00:16:58,000
accuracy test much more highly

513
00:16:58,000 --> 00:17:00,160
here we have exponents which show the

514
00:17:00,160 --> 00:17:01,680
training and inference accuracy of the

515
00:17:01,680 --> 00:17:02,880
plaintext network

516
00:17:02,880 --> 00:17:04,959
but then also we can see the inference

517
00:17:04,959 --> 00:17:06,480
accuracy of falcon when we do it

518
00:17:06,480 --> 00:17:07,280
privately

519
00:17:07,280 --> 00:17:09,679
and for most networks uh the accuracy

520
00:17:09,679 --> 00:17:10,319
does not

521
00:17:10,319 --> 00:17:11,760
change at all because it's just so

522
00:17:11,760 --> 00:17:13,520
robust so even though each individual

523
00:17:13,520 --> 00:17:14,240
value

524
00:17:14,240 --> 00:17:16,640
is slightly different between them the

525
00:17:16,640 --> 00:17:18,720
overall prediction result doesn't change

526
00:17:18,720 --> 00:17:20,319
and that is quantified by this other

527
00:17:20,319 --> 00:17:21,919
term which is the relative error so

528
00:17:21,919 --> 00:17:23,199
once we pass it through the entire

529
00:17:23,199 --> 00:17:25,599
network the final values are

530
00:17:25,599 --> 00:17:27,439
have a very low relative error compared

531
00:17:27,439 --> 00:17:29,280
to the plain text values

532
00:17:29,280 --> 00:17:31,840
so this sort of quantifies like how uh

533
00:17:31,840 --> 00:17:33,360
error propagates through the entire

534
00:17:33,360 --> 00:17:34,720
network and how

535
00:17:34,720 --> 00:17:36,400
how different the values are because of

536
00:17:36,400 --> 00:17:39,520
the approximation in mpc

537
00:17:39,520 --> 00:17:41,520
so with that i would like to thank you

538
00:17:41,520 --> 00:17:43,120
for your attention

539
00:17:43,120 --> 00:17:45,280
and happy to take questions uh here is

540
00:17:45,280 --> 00:17:46,160
the falcon

541
00:17:46,160 --> 00:17:48,080
repository once again and the link to

542
00:17:48,080 --> 00:17:49,600
the paper on archive

543
00:17:49,600 --> 00:17:54,719
thank you

