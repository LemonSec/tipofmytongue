1
00:00:00,960 --> 00:00:03,600
hi my name is nathan reininger i'm a phd

2
00:00:03,600 --> 00:00:05,440
student at the university of maryland

3
00:00:05,440 --> 00:00:07,120
today i'm thrilled to be able to present

4
00:00:07,120 --> 00:00:09,040
to you some work i did with my advisor

5
00:00:09,040 --> 00:00:11,360
michelle on improving the state of art

6
00:00:11,360 --> 00:00:12,160
and blocking

7
00:00:12,160 --> 00:00:14,000
a particular type of tracking known as

8
00:00:14,000 --> 00:00:16,320
canvas fingerprinting with our tool

9
00:00:16,320 --> 00:00:19,279
mlcb

10
00:00:19,359 --> 00:00:21,039
of the many types of tracking that occur

11
00:00:21,039 --> 00:00:23,680
online one of them comes from html5's

12
00:00:23,680 --> 00:00:25,279
canvas element

13
00:00:25,279 --> 00:00:27,680
to catch this concept in realistic terms

14
00:00:27,680 --> 00:00:29,480
imagine that you visited the website

15
00:00:29,480 --> 00:00:32,159
lenscrafters.com this is what that

16
00:00:32,159 --> 00:00:33,120
website looked like

17
00:00:33,120 --> 00:00:36,480
in june of 2021 what you don't see here

18
00:00:36,480 --> 00:00:39,520
are canvas images many of the images you

19
00:00:39,520 --> 00:00:39,920
see

20
00:00:39,920 --> 00:00:42,320
are files that are served to you rather

21
00:00:42,320 --> 00:00:44,239
than images drawn to the canvas

22
00:00:44,239 --> 00:00:45,840
that's not to say this page has no

23
00:00:45,840 --> 00:00:48,000
canvas drawings to find the canvas

24
00:00:48,000 --> 00:00:49,760
images that are being drawn by this page

25
00:00:49,760 --> 00:00:51,199
you'd have to dig into the website's

26
00:00:51,199 --> 00:00:53,360
source code this is because canvas

27
00:00:53,360 --> 00:00:55,120
fingerprinting is a mechanism

28
00:00:55,120 --> 00:00:56,640
that can be done without any user

29
00:00:56,640 --> 00:00:58,879
awareness or user consent

30
00:00:58,879 --> 00:01:01,600
it's surreptitious in this way if you

31
00:01:01,600 --> 00:01:03,199
did dig into the website source code

32
00:01:03,199 --> 00:01:06,159
you'd find this piece of javascript code

33
00:01:06,159 --> 00:01:08,080
this code's purpose is actually to draw

34
00:01:08,080 --> 00:01:10,640
the following image

35
00:01:10,640 --> 00:01:13,439
this image is a canvas fingerprint so

36
00:01:13,439 --> 00:01:15,280
the website telemeter device to draw the

37
00:01:15,280 --> 00:01:15,920
image

38
00:01:15,920 --> 00:01:18,159
the image turns out to be one that is

39
00:01:18,159 --> 00:01:20,320
bespoke to my device's particular

40
00:01:20,320 --> 00:01:20,880
hardware

41
00:01:20,880 --> 00:01:22,960
and software characteristics and the

42
00:01:22,960 --> 00:01:24,479
site can therefore track me

43
00:01:24,479 --> 00:01:26,799
by using this program and especially

44
00:01:26,799 --> 00:01:27,600
that final

45
00:01:27,600 --> 00:01:30,720
call there to data url noted on the last

46
00:01:30,720 --> 00:01:32,240
line

47
00:01:32,240 --> 00:01:34,159
canvas fingerprinting originates from a

48
00:01:34,159 --> 00:01:36,400
2012 academic paper

49
00:01:36,400 --> 00:01:37,600
explaining how you could draw a

50
00:01:37,600 --> 00:01:39,920
particular style of image to the canvas

51
00:01:39,920 --> 00:01:41,520
and it will provide you with a pretty

52
00:01:41,520 --> 00:01:43,280
good fingerprint

53
00:01:43,280 --> 00:01:45,680
the fingerprint would be consistent it

54
00:01:45,680 --> 00:01:47,360
really pulls out the uniqueness between

55
00:01:47,360 --> 00:01:48,560
devices

56
00:01:48,560 --> 00:01:51,360
it fits well with existing fingerprints

57
00:01:51,360 --> 00:01:53,520
it's transparent to the user

58
00:01:53,520 --> 00:01:56,719
and it's readily available looking at

59
00:01:56,719 --> 00:01:58,320
the code used on the lens crafters

60
00:01:58,320 --> 00:02:00,079
website allows us to get a pretty good

61
00:02:00,079 --> 00:02:01,840
sense for how canvas fingerprinting

62
00:02:01,840 --> 00:02:03,040
works

63
00:02:03,040 --> 00:02:04,640
what a canvas fingerprinting program

64
00:02:04,640 --> 00:02:06,479
aims to do is draw something to the

65
00:02:06,479 --> 00:02:08,399
canvas that uses letters

66
00:02:08,399 --> 00:02:11,120
colors and shapes and tries to create a

67
00:02:11,120 --> 00:02:12,480
lot of variation

68
00:02:12,480 --> 00:02:14,400
this program on the left draws the image

69
00:02:14,400 --> 00:02:16,319
on the right the two versions are from

70
00:02:16,319 --> 00:02:18,800
two different computers

71
00:02:18,800 --> 00:02:20,319
to give you a sense of the variations

72
00:02:20,319 --> 00:02:22,480
here we can look at variable c

73
00:02:22,480 --> 00:02:24,000
this is actually something known as a

74
00:02:24,000 --> 00:02:26,400
pan gram it uses every letter in the

75
00:02:26,400 --> 00:02:28,959
english language

76
00:02:28,959 --> 00:02:30,879
another notable feature is the call to

77
00:02:30,879 --> 00:02:33,680
two data url that i mentioned before

78
00:02:33,680 --> 00:02:36,000
this function returns a base64 encoded

79
00:02:36,000 --> 00:02:37,200
version of the drawing

80
00:02:37,200 --> 00:02:40,160
which can then be compared to other ver

81
00:02:40,160 --> 00:02:41,120
other strings

82
00:02:41,120 --> 00:02:44,239
to identify similarity or dissimilarity

83
00:02:44,239 --> 00:02:45,840
so the two images on the right look very

84
00:02:45,840 --> 00:02:47,360
similar and i told you that they were

85
00:02:47,360 --> 00:02:49,519
drawn by two different computers

86
00:02:49,519 --> 00:02:52,239
using that same program if i showed you

87
00:02:52,239 --> 00:02:53,599
them back to back with the naked eye

88
00:02:53,599 --> 00:02:54,879
you'd have a hard time distinguishing

89
00:02:54,879 --> 00:02:55,599
them

90
00:02:55,599 --> 00:02:57,680
but if i showed you the base64 encoded

91
00:02:57,680 --> 00:02:59,920
string as a result of that two-day url

92
00:02:59,920 --> 00:03:03,040
url call it's very easy to see

93
00:03:03,040 --> 00:03:04,800
that they start to be distinguishable on

94
00:03:04,800 --> 00:03:07,840
line 3 and moving forward

95
00:03:07,840 --> 00:03:09,280
the tor project said that canvas

96
00:03:09,280 --> 00:03:11,280
fingerprinting following plugins and

97
00:03:11,280 --> 00:03:12,800
plugin provided information

98
00:03:12,800 --> 00:03:14,319
was the number one threat that browsers

99
00:03:14,319 --> 00:03:17,200
face in terms of a privacy loss

100
00:03:17,200 --> 00:03:18,800
part of the reason the canvas is so

101
00:03:18,800 --> 00:03:21,200
tricky in terms of it being a tracking

102
00:03:21,200 --> 00:03:21,840
vector

103
00:03:21,840 --> 00:03:24,159
is that it's a dual use technology the

104
00:03:24,159 --> 00:03:25,840
same mechanism that makes tracking

105
00:03:25,840 --> 00:03:26,640
possible

106
00:03:26,640 --> 00:03:29,360
also makes useful functionality possible

107
00:03:29,360 --> 00:03:30,560
so similar to how

108
00:03:30,560 --> 00:03:33,440
if your text if you computer is served

109
00:03:33,440 --> 00:03:33,920
text

110
00:03:33,920 --> 00:03:35,519
that's dynamically rendered on your

111
00:03:35,519 --> 00:03:37,840
screen versus being a certain image of

112
00:03:37,840 --> 00:03:39,280
that same text

113
00:03:39,280 --> 00:03:41,440
dynamically rendering the text is going

114
00:03:41,440 --> 00:03:43,599
to look better than the image

115
00:03:43,599 --> 00:03:46,000
and this is what the canvas allows it

116
00:03:46,000 --> 00:03:48,239
allows you to have images that look good

117
00:03:48,239 --> 00:03:49,599
because they use your computer's

118
00:03:49,599 --> 00:03:52,560
hardware and software characteristics

119
00:03:52,560 --> 00:03:54,159
in that light this paper's main aim is

120
00:03:54,159 --> 00:03:56,239
to try and block only those canvas

121
00:03:56,239 --> 00:03:56,879
actions

122
00:03:56,879 --> 00:03:59,920
that are geared toward tracking this

123
00:03:59,920 --> 00:04:01,840
talk has three parts

124
00:04:01,840 --> 00:04:04,400
in part one the background i'll discuss

125
00:04:04,400 --> 00:04:06,239
how canvas fingerprinting is currently

126
00:04:06,239 --> 00:04:08,159
blocked

127
00:04:08,159 --> 00:04:11,120
part two will be our approach to

128
00:04:11,120 --> 00:04:12,080
blocking

129
00:04:12,080 --> 00:04:15,439
tracking focused canvas actions

130
00:04:15,439 --> 00:04:18,478
part three i'll discuss our results and

131
00:04:18,478 --> 00:04:20,320
how our approach compares to the state

132
00:04:20,320 --> 00:04:21,759
of the art

133
00:04:21,759 --> 00:04:23,600
so let's get started with part one the

134
00:04:23,600 --> 00:04:26,160
background

135
00:04:26,560 --> 00:04:28,240
identifying and blocking canvas

136
00:04:28,240 --> 00:04:30,639
fingerprinting is not a new problem

137
00:04:30,639 --> 00:04:32,639
several other works have made attempts

138
00:04:32,639 --> 00:04:35,199
at blocking this tracking vector

139
00:04:35,199 --> 00:04:36,800
one of the initial ways to block this

140
00:04:36,800 --> 00:04:38,720
type of tracking works by modifying

141
00:04:38,720 --> 00:04:40,479
all of the images that are drawn to the

142
00:04:40,479 --> 00:04:42,880
canvas so here we're injecting noise

143
00:04:42,880 --> 00:04:44,720
into these canvas images

144
00:04:44,720 --> 00:04:47,680
and that creates broken consistency so

145
00:04:47,680 --> 00:04:49,440
the same user visits the same website

146
00:04:49,440 --> 00:04:50,400
multiple times

147
00:04:50,400 --> 00:04:52,400
but draws a different canvas image and

148
00:04:52,400 --> 00:04:53,680
that thwarts the

149
00:04:53,680 --> 00:04:56,240
classification of that user this is

150
00:04:56,240 --> 00:04:58,400
actually a fairly safe method

151
00:04:58,400 --> 00:05:00,320
but has limits to functionality because

152
00:05:00,320 --> 00:05:02,080
we're affecting the canvas images that

153
00:05:02,080 --> 00:05:04,080
we're drawing

154
00:05:04,080 --> 00:05:06,560
a second option is to disable canvas

155
00:05:06,560 --> 00:05:07,759
images by default

156
00:05:07,759 --> 00:05:09,520
and ask the user for permission to

157
00:05:09,520 --> 00:05:10,800
render

158
00:05:10,800 --> 00:05:12,720
again this is quite safe it makes the

159
00:05:12,720 --> 00:05:13,840
default setting

160
00:05:13,840 --> 00:05:16,479
a fairly high standard of protection the

161
00:05:16,479 --> 00:05:17,440
downside here

162
00:05:17,440 --> 00:05:19,280
is that it requires the user's knowledge

163
00:05:19,280 --> 00:05:21,440
and attention on whether to allow a

164
00:05:21,440 --> 00:05:24,639
certain canvas action

165
00:05:24,639 --> 00:05:26,479
a third way to approach this problem is

166
00:05:26,479 --> 00:05:28,960
to use a black a block list

167
00:05:28,960 --> 00:05:31,360
so here we in the naive sense we can use

168
00:05:31,360 --> 00:05:32,240
something like

169
00:05:32,240 --> 00:05:35,520
a hard-coded string match

170
00:05:35,520 --> 00:05:38,479
so think the disconnect list where we're

171
00:05:38,479 --> 00:05:39,840
using a rejects match

172
00:05:39,840 --> 00:05:42,080
on a particular url and if it's a match

173
00:05:42,080 --> 00:05:44,720
we're going to block that resource

174
00:05:44,720 --> 00:05:46,479
in a more nuanced sense you can look for

175
00:05:46,479 --> 00:05:48,000
a certain mixture of attributes that are

176
00:05:48,000 --> 00:05:49,280
associated with what you're trying to

177
00:05:49,280 --> 00:05:50,080
block

178
00:05:50,080 --> 00:05:51,680
there's a very influential paper out of

179
00:05:51,680 --> 00:05:53,199
2016

180
00:05:53,199 --> 00:05:55,759
that discussed how certain height color

181
00:05:55,759 --> 00:05:58,000
and specific api calls were associated

182
00:05:58,000 --> 00:05:59,440
with canvas fingerprinting

183
00:05:59,440 --> 00:06:01,280
so if we identify these attributes we

184
00:06:01,280 --> 00:06:03,039
can then block

185
00:06:03,039 --> 00:06:05,759
the resulting actions these approaches

186
00:06:05,759 --> 00:06:06,720
are fairly nimble

187
00:06:06,720 --> 00:06:08,400
because they don't block things on a

188
00:06:08,400 --> 00:06:09,919
very large scope

189
00:06:09,919 --> 00:06:11,759
but they're not as flexible as we might

190
00:06:11,759 --> 00:06:14,479
hope because they're taken

191
00:06:14,479 --> 00:06:17,039
when we have a snapshot of what the

192
00:06:17,039 --> 00:06:18,000
canvas

193
00:06:18,000 --> 00:06:20,319
images used for fingerprinting look like

194
00:06:20,319 --> 00:06:22,240
and those may change over time

195
00:06:22,240 --> 00:06:23,840
and so you have to update the the

196
00:06:23,840 --> 00:06:27,199
heuristic or the hard coded lists

197
00:06:27,199 --> 00:06:29,600
to add some flexibility another line of

198
00:06:29,600 --> 00:06:31,440
work uses machine learning models to

199
00:06:31,440 --> 00:06:34,639
make that block and a block decision

200
00:06:34,639 --> 00:06:37,199
the linchpin for this line of work

201
00:06:37,199 --> 00:06:39,039
really concerns the ground truth

202
00:06:39,039 --> 00:06:40,639
because we're using supervised learning

203
00:06:40,639 --> 00:06:42,720
in our machine learning

204
00:06:42,720 --> 00:06:45,759
and the work thus far in the 2017 paper

205
00:06:45,759 --> 00:06:47,919
has used ground truth of manually

206
00:06:47,919 --> 00:06:50,160
inspecting the programs that are used

207
00:06:50,160 --> 00:06:50,720
for the

208
00:06:50,720 --> 00:06:52,800
for fingerprinting which can be quite

209
00:06:52,800 --> 00:06:54,960
laborious in the end

210
00:06:54,960 --> 00:06:58,960
the workout of 2021 uses the heuristic

211
00:06:58,960 --> 00:07:00,960
as ground truth and then builds upon it

212
00:07:00,960 --> 00:07:02,880
in an iterative fashion

213
00:07:02,880 --> 00:07:06,400
but we're still using that heuristic so

214
00:07:06,400 --> 00:07:08,800
what our paper does is tries to improve

215
00:07:08,800 --> 00:07:10,319
the ground truth of the process of

216
00:07:10,319 --> 00:07:11,440
gaining your own truth

217
00:07:11,440 --> 00:07:13,120
and we do this by using a fairly

218
00:07:13,120 --> 00:07:14,560
intuitive method

219
00:07:14,560 --> 00:07:16,160
if i showed you these two images on the

220
00:07:16,160 --> 00:07:17,919
right it'd be fairly easy to tell which

221
00:07:17,919 --> 00:07:19,360
one makes sense for a website

222
00:07:19,360 --> 00:07:21,840
the one on the top and which one doesn't

223
00:07:21,840 --> 00:07:23,520
the one on the bottom

224
00:07:23,520 --> 00:07:25,680
and we can use that easy human judgment

225
00:07:25,680 --> 00:07:28,160
to create our ground truth

226
00:07:28,160 --> 00:07:29,680
what we're actually going to do is take

227
00:07:29,680 --> 00:07:31,440
this one step further

228
00:07:31,440 --> 00:07:33,440
so we have this easy labeling process

229
00:07:33,440 --> 00:07:35,199
but we'd like a data source that is

230
00:07:35,199 --> 00:07:37,759
one not easy for an attacker to change

231
00:07:37,759 --> 00:07:39,199
and two

232
00:07:39,199 --> 00:07:42,000
more stable over time images can be

233
00:07:42,000 --> 00:07:43,280
changed fairly easily

234
00:07:43,280 --> 00:07:44,879
but the programs used to draw those

235
00:07:44,879 --> 00:07:47,919
images that have certain api calls and

236
00:07:47,919 --> 00:07:49,199
certain structures

237
00:07:49,199 --> 00:07:51,039
associated with them are difficult to

238
00:07:51,039 --> 00:07:52,240
change

239
00:07:52,240 --> 00:07:55,440
using images for labeling and text as a

240
00:07:55,440 --> 00:07:56,319
data source

241
00:07:56,319 --> 00:07:59,039
additionally allows us to label hundreds

242
00:07:59,039 --> 00:08:01,280
of programs with a single image

243
00:08:01,280 --> 00:08:03,199
and this turned out to be true because

244
00:08:03,199 --> 00:08:05,120
what we found was that a lot of these

245
00:08:05,120 --> 00:08:06,160
programs that are used for

246
00:08:06,160 --> 00:08:06,879
fingerprinting

247
00:08:06,879 --> 00:08:09,919
are cloned across the web

248
00:08:09,919 --> 00:08:12,319
moreover when we use text we're allowed

249
00:08:12,319 --> 00:08:14,560
to use tools like js nice

250
00:08:14,560 --> 00:08:17,280
js de-obfuscates javascript text by

251
00:08:17,280 --> 00:08:18,319
using machine learning

252
00:08:18,319 --> 00:08:20,400
to predict names and ident names of

253
00:08:20,400 --> 00:08:22,960
identifiers and annotations of variables

254
00:08:22,960 --> 00:08:24,479
so essentially we're able to pull

255
00:08:24,479 --> 00:08:25,919
natural language meaning out of

256
00:08:25,919 --> 00:08:28,000
otherwise minified or obfuscated

257
00:08:28,000 --> 00:08:30,960
javascript text

258
00:08:31,039 --> 00:08:32,479
let's turn to the approach that we use

259
00:08:32,479 --> 00:08:35,680
to build our classifiers

260
00:08:36,479 --> 00:08:38,320
the end goal here is to have enough data

261
00:08:38,320 --> 00:08:40,000
to be able to train a machine learning

262
00:08:40,000 --> 00:08:42,479
classifier so we need to gather a lot of

263
00:08:42,479 --> 00:08:44,560
canvas images from the web

264
00:08:44,560 --> 00:08:46,720
to get these images we built a custom

265
00:08:46,720 --> 00:08:48,000
google chrome extension

266
00:08:48,000 --> 00:08:50,240
that grabbed data about the canvas as it

267
00:08:50,240 --> 00:08:51,920
was used by websites

268
00:08:51,920 --> 00:08:53,440
we targeted roughly half a million

269
00:08:53,440 --> 00:08:55,519
websites listed on alexa top sites

270
00:08:55,519 --> 00:08:57,680
for the initial scrape and this initial

271
00:08:57,680 --> 00:09:01,360
scrape occurred in 2018

272
00:09:01,360 --> 00:09:03,360
of those roughly half a million websites

273
00:09:03,360 --> 00:09:05,440
we successfully grabbed canvas drawing

274
00:09:05,440 --> 00:09:06,399
data

275
00:09:06,399 --> 00:09:09,920
from about 200 000 of them

276
00:09:09,920 --> 00:09:11,680
we looked at all the images returned by

277
00:09:11,680 --> 00:09:13,600
this scrape and were able to create our

278
00:09:13,600 --> 00:09:16,080
set of ground truth

279
00:09:16,080 --> 00:09:17,920
our machine learning models were then

280
00:09:17,920 --> 00:09:19,839
able to train on this data

281
00:09:19,839 --> 00:09:22,640
from the initial scrape we had about 84

282
00:09:22,640 --> 00:09:25,200
000 programs and 3 500 images

283
00:09:25,200 --> 00:09:27,519
and these are the distinct counts in

284
00:09:27,519 --> 00:09:31,040
each of those respective categories

285
00:09:31,040 --> 00:09:32,399
to assess how well our models will

286
00:09:32,399 --> 00:09:34,560
behave in the real world we re-scrape

287
00:09:34,560 --> 00:09:36,320
the web in 2020

288
00:09:36,320 --> 00:09:39,600
we pulled down 408 programs and 181

289
00:09:39,600 --> 00:09:41,920
canvas images and then used this new

290
00:09:41,920 --> 00:09:44,480
data to assess our model's performance

291
00:09:44,480 --> 00:09:46,080
before diving into the results of that

292
00:09:46,080 --> 00:09:48,240
performance because we scraped nearly

293
00:09:48,240 --> 00:09:49,760
half a million websites

294
00:09:49,760 --> 00:09:51,440
we're able to assess the state of the

295
00:09:51,440 --> 00:09:52,959
canvas on the web

296
00:09:52,959 --> 00:09:54,399
i'll next discuss a few of our

297
00:09:54,399 --> 00:09:57,440
measurement insights

298
00:09:58,480 --> 00:10:01,040
firstly the canvas is not a tool used

299
00:10:01,040 --> 00:10:01,920
exclusively

300
00:10:01,920 --> 00:10:05,120
by fingerprinters in fact

301
00:10:05,120 --> 00:10:07,839
the top five most common images listed

302
00:10:07,839 --> 00:10:09,200
in occurrence from most

303
00:10:09,200 --> 00:10:12,240
to least left to right

304
00:10:12,240 --> 00:10:16,480
are all emojis this non-majority use

305
00:10:16,480 --> 00:10:16,959
case

306
00:10:16,959 --> 00:10:19,760
fact becomes more obvious when you look

307
00:10:19,760 --> 00:10:21,440
at this information in terms of the

308
00:10:21,440 --> 00:10:23,120
alexa rank

309
00:10:23,120 --> 00:10:25,200
so here we have intervals of alexa rank

310
00:10:25,200 --> 00:10:27,040
the one to 100 category

311
00:10:27,040 --> 00:10:30,720
100 to 1 000 and 1 000 to 10 000

312
00:10:30,720 --> 00:10:34,320
listed along the bottom on the left we

313
00:10:34,320 --> 00:10:36,079
can see the percentage of websites that

314
00:10:36,079 --> 00:10:37,360
fall into the interval

315
00:10:37,360 --> 00:10:38,959
that are associated with either using

316
00:10:38,959 --> 00:10:41,040
two data url

317
00:10:41,040 --> 00:10:44,320
in gray or using two data url for a

318
00:10:44,320 --> 00:10:45,760
fingerprinting purpose

319
00:10:45,760 --> 00:10:49,040
in blue what this chart

320
00:10:49,040 --> 00:10:51,360
also allows us to see is that when we

321
00:10:51,360 --> 00:10:53,360
compare this result with prior work

322
00:10:53,360 --> 00:10:55,440
we find that there's a trend that's

323
00:10:55,440 --> 00:10:57,760
rising so in 2014

324
00:10:57,760 --> 00:11:00,079
previous work found that five percent of

325
00:11:00,079 --> 00:11:01,920
websites that were in this interval the

326
00:11:01,920 --> 00:11:04,000
1k to 10k range

327
00:11:04,000 --> 00:11:06,079
used two data url for a fingerprinting

328
00:11:06,079 --> 00:11:07,200
purpose

329
00:11:07,200 --> 00:11:10,560
in 2016 this number was updated to 7

330
00:11:10,560 --> 00:11:13,839
and our original scrape in 2018 showed

331
00:11:13,839 --> 00:11:14,800
that 11

332
00:11:14,800 --> 00:11:17,519
of these websites were using two-day url

333
00:11:17,519 --> 00:11:19,200
for fingerprinting

334
00:11:19,200 --> 00:11:21,040
so even though canvas fingerprinting is

335
00:11:21,040 --> 00:11:22,800
a minority use case here

336
00:11:22,800 --> 00:11:26,320
its use is rising secondly when looking

337
00:11:26,320 --> 00:11:27,760
at the programs that drew canvas

338
00:11:27,760 --> 00:11:28,640
fingerprints

339
00:11:28,640 --> 00:11:30,079
we find that there's quite a lot of

340
00:11:30,079 --> 00:11:32,160
overlap between programs another way of

341
00:11:32,160 --> 00:11:32,720
saying this

342
00:11:32,720 --> 00:11:35,519
is that code cloning is the norm here in

343
00:11:35,519 --> 00:11:36,959
fact if you did a comparison of all

344
00:11:36,959 --> 00:11:38,160
fingerprinting programs

345
00:11:38,160 --> 00:11:40,720
so pairwise you'd find that the mean

346
00:11:40,720 --> 00:11:42,240
jaccard similarity score

347
00:11:42,240 --> 00:11:43,760
in other words a way of measuring the

348
00:11:43,760 --> 00:11:47,040
overlap here is 40 percent

349
00:11:47,040 --> 00:11:49,200
finally like other research we found

350
00:11:49,200 --> 00:11:50,880
that websites that were monetized by

351
00:11:50,880 --> 00:11:51,920
advertising

352
00:11:51,920 --> 00:11:53,839
were most likely to engage in use of the

353
00:11:53,839 --> 00:11:56,240
canvas for fingerprinting

354
00:11:56,240 --> 00:11:58,160
news consistently comes up as the number

355
00:11:58,160 --> 00:11:59,279
one category here

356
00:11:59,279 --> 00:12:00,880
of websites that engage in canvas

357
00:12:00,880 --> 00:12:02,639
fingerprinting for tracking

358
00:12:02,639 --> 00:12:04,560
but we also found that cooking recipe

359
00:12:04,560 --> 00:12:06,639
websites and websites related to arts

360
00:12:06,639 --> 00:12:07,600
entertainment

361
00:12:07,600 --> 00:12:11,839
commonly employ this tracking technique

362
00:12:11,920 --> 00:12:13,519
now let's turn to the performance of

363
00:12:13,519 --> 00:12:16,399
mlcb how our models do when compared to

364
00:12:16,399 --> 00:12:19,200
the state-of-the-art

365
00:12:19,279 --> 00:12:21,120
as background we dug deep into the

366
00:12:21,120 --> 00:12:23,360
performance of assessing our models on

367
00:12:23,360 --> 00:12:24,880
many different fronts

368
00:12:24,880 --> 00:12:26,399
the first of those is our original

369
00:12:26,399 --> 00:12:29,279
scrape data so here we have 2018 data

370
00:12:29,279 --> 00:12:32,720
which is images and text the second is

371
00:12:32,720 --> 00:12:34,079
our test suite data

372
00:12:34,079 --> 00:12:36,160
we also have images in text but this is

373
00:12:36,160 --> 00:12:38,000
from 2020.

374
00:12:38,000 --> 00:12:39,839
finally in order to assess how our

375
00:12:39,839 --> 00:12:41,680
models would fare against an adversary

376
00:12:41,680 --> 00:12:43,600
officegate's website source code in an

377
00:12:43,600 --> 00:12:46,399
attempt to try and trick our classifiers

378
00:12:46,399 --> 00:12:49,120
we took text text from the test suite

379
00:12:49,120 --> 00:12:50,720
and we ran it through the javascript

380
00:12:50,720 --> 00:12:52,160
obfuscator tool

381
00:12:52,160 --> 00:12:54,240
so we're trying to create obfuscated

382
00:12:54,240 --> 00:12:56,399
javascript as an adversary might

383
00:12:56,399 --> 00:12:59,279
and see how our models do with this type

384
00:12:59,279 --> 00:13:01,600
of data

385
00:13:01,600 --> 00:13:03,680
here's some of our performance metrics a

386
00:13:03,680 --> 00:13:05,600
few basic points to cover here

387
00:13:05,600 --> 00:13:07,839
the f1 score is a harmonic mean between

388
00:13:07,839 --> 00:13:08,639
the precision

389
00:13:08,639 --> 00:13:11,360
and the recall the three models listed

390
00:13:11,360 --> 00:13:12,560
they're all text-based

391
00:13:12,560 --> 00:13:14,800
and the text that they're using as data

392
00:13:14,800 --> 00:13:17,760
has been transformed with jsnice

393
00:13:17,760 --> 00:13:19,440
additionally these results are generated

394
00:13:19,440 --> 00:13:22,480
using stratified k-fold cross-validation

395
00:13:22,480 --> 00:13:24,320
you can learn more about this and other

396
00:13:24,320 --> 00:13:25,519
details in our paper

397
00:13:25,519 --> 00:13:27,360
but at a high level the three different

398
00:13:27,360 --> 00:13:28,880
data sets that we're looking at here and

399
00:13:28,880 --> 00:13:30,000
the scores that we have

400
00:13:30,000 --> 00:13:32,079
essentially it says how well do these

401
00:13:32,079 --> 00:13:33,600
models do with fresh

402
00:13:33,600 --> 00:13:36,320
contemporaneous data how well do they do

403
00:13:36,320 --> 00:13:37,040
over time

404
00:13:37,040 --> 00:13:40,480
with the drift between 2018 and 2020

405
00:13:40,480 --> 00:13:42,079
and how would they do in the adversarial

406
00:13:42,079 --> 00:13:44,000
setting

407
00:13:44,000 --> 00:13:45,760
i'll now drill down on a few high-level

408
00:13:45,760 --> 00:13:48,240
points about these results

409
00:13:48,240 --> 00:13:50,240
for one our models all work well with

410
00:13:50,240 --> 00:13:51,600
contemporaneous data

411
00:13:51,600 --> 00:13:53,120
the data that comes from the original

412
00:13:53,120 --> 00:13:55,120
scrape additionally

413
00:13:55,120 --> 00:13:56,959
the best model here performs well

414
00:13:56,959 --> 00:14:00,000
overall with f1 scores at or above 80

415
00:14:00,000 --> 00:14:03,040
across all three data sets

416
00:14:03,040 --> 00:14:05,120
secondly our classifiers work fairly

417
00:14:05,120 --> 00:14:07,279
well even with the two-year drift that

418
00:14:07,279 --> 00:14:08,079
occurred

419
00:14:08,079 --> 00:14:10,160
between our original scrape and the test

420
00:14:10,160 --> 00:14:12,720
suites crate

421
00:14:12,720 --> 00:14:14,839
we can also see here how the cnn would

422
00:14:14,839 --> 00:14:16,000
do

423
00:14:16,000 --> 00:14:17,760
although it competed with test-based

424
00:14:17,760 --> 00:14:19,680
models initially as we can see in the

425
00:14:19,680 --> 00:14:21,600
original scrape data the red dot showing

426
00:14:21,600 --> 00:14:24,000
the cnn is above 85 percent

427
00:14:24,000 --> 00:14:25,839
it seems fairly sensitive to the new

428
00:14:25,839 --> 00:14:27,839
data that was found in the test suite

429
00:14:27,839 --> 00:14:30,480
it looks like it drops below 75 percent

430
00:14:30,480 --> 00:14:32,880
in the test suite

431
00:14:32,880 --> 00:14:34,720
we can also compare our model directly

432
00:14:34,720 --> 00:14:36,079
with the heuristic

433
00:14:36,079 --> 00:14:38,160
a caveat here is that these results are

434
00:14:38,160 --> 00:14:39,839
on the subset of the test suite

435
00:14:39,839 --> 00:14:41,440
because we wanted to directly compare

436
00:14:41,440 --> 00:14:43,680
the heuristic to mlcb

437
00:14:43,680 --> 00:14:46,320
and to do that we took a subset of the

438
00:14:46,320 --> 00:14:48,000
test suite where we had this one-to-one

439
00:14:48,000 --> 00:14:49,600
comparison

440
00:14:49,600 --> 00:14:52,000
so we also see a drop here in how the

441
00:14:52,000 --> 00:14:52,880
heuristic does

442
00:14:52,880 --> 00:14:56,160
in comparison with mlcb our hunch

443
00:14:56,160 --> 00:14:58,480
was that we're having these drops with

444
00:14:58,480 --> 00:14:59,440
the cnn

445
00:14:59,440 --> 00:15:02,079
and the heuristic because they're not as

446
00:15:02,079 --> 00:15:03,920
robust over time

447
00:15:03,920 --> 00:15:05,519
and actually if we dig into this result

448
00:15:05,519 --> 00:15:07,279
a little more we're able to figure out

449
00:15:07,279 --> 00:15:10,079
why there's this type of drop

450
00:15:10,079 --> 00:15:12,000
so the culprit is really this image

451
00:15:12,000 --> 00:15:13,199
shown on the bottom

452
00:15:13,199 --> 00:15:15,279
this comes from a paper illustrating how

453
00:15:15,279 --> 00:15:17,040
you could improve upon the canvas

454
00:15:17,040 --> 00:15:18,720
fingerprinting technique

455
00:15:18,720 --> 00:15:21,040
if you drew this particular type of

456
00:15:21,040 --> 00:15:22,240
image

457
00:15:22,240 --> 00:15:24,000
although this type of image is very rare

458
00:15:24,000 --> 00:15:26,399
in our original scrape data

459
00:15:26,399 --> 00:15:28,320
it could be commonly found among our

460
00:15:28,320 --> 00:15:30,079
test suite data

461
00:15:30,079 --> 00:15:31,839
these fingerprints do not generally fit

462
00:15:31,839 --> 00:15:33,680
the rules of heuristic

463
00:15:33,680 --> 00:15:35,519
and they're odd looking enough for our

464
00:15:35,519 --> 00:15:36,720
image classifier

465
00:15:36,720 --> 00:15:39,279
to think that they're not fingerprinting

466
00:15:39,279 --> 00:15:40,959
so we find that the heuristic

467
00:15:40,959 --> 00:15:43,199
and the cnn the convolutional neural

468
00:15:43,199 --> 00:15:45,040
network trained on images

469
00:15:45,040 --> 00:15:47,440
are performing more poorly when they

470
00:15:47,440 --> 00:15:49,920
consider these type of images

471
00:15:49,920 --> 00:15:51,279
lastly we should note that the

472
00:15:51,279 --> 00:15:52,959
obfuscation used

473
00:15:52,959 --> 00:15:55,440
in the adversarial perspective is quite

474
00:15:55,440 --> 00:15:56,079
heavy

475
00:15:56,079 --> 00:15:58,639
so it makes good sense why the models

476
00:15:58,639 --> 00:16:00,240
drop in performance when we

477
00:16:00,240 --> 00:16:03,759
when we look at this here's an example

478
00:16:03,759 --> 00:16:05,920
this is one from the paper so this

479
00:16:05,920 --> 00:16:07,600
program draws the image at the top of

480
00:16:07,600 --> 00:16:08,160
the screen

481
00:16:08,160 --> 00:16:10,160
and this program looks very similar to

482
00:16:10,160 --> 00:16:12,320
the program the lens crafters was using

483
00:16:12,320 --> 00:16:15,120
that i showed in the beginning

484
00:16:15,120 --> 00:16:17,040
when we run this through the javascript

485
00:16:17,040 --> 00:16:19,440
obscure tool the output looks like this

486
00:16:19,440 --> 00:16:21,279
and in fact this is then run through the

487
00:16:21,279 --> 00:16:22,800
js nice tool which

488
00:16:22,800 --> 00:16:24,320
was supposed to give us some more

489
00:16:24,320 --> 00:16:26,480
natural language understanding to it

490
00:16:26,480 --> 00:16:29,440
and even with that done it still is very

491
00:16:29,440 --> 00:16:33,199
difficult to parse what's going on here

492
00:16:33,199 --> 00:16:35,360
that said what we found when we looked

493
00:16:35,360 --> 00:16:36,399
into this result

494
00:16:36,399 --> 00:16:38,079
was that we're actually showing very

495
00:16:38,079 --> 00:16:40,480
high recall and low precision

496
00:16:40,480 --> 00:16:42,399
so when our classifiers see this type of

497
00:16:42,399 --> 00:16:44,320
data they're more likely to call it a

498
00:16:44,320 --> 00:16:45,920
fingerprinting program

499
00:16:45,920 --> 00:16:47,519
now the implication of this is that our

500
00:16:47,519 --> 00:16:49,639
classifiers in some ways are

501
00:16:49,639 --> 00:16:50,800
disincentivizing

502
00:16:50,800 --> 00:16:53,040
the use of obfuscation because when you

503
00:16:53,040 --> 00:16:54,000
use obfuscation

504
00:16:54,000 --> 00:16:56,000
our classifiers are more likely to block

505
00:16:56,000 --> 00:16:57,120
your program

506
00:16:57,120 --> 00:16:58,560
and that may be a good thing from a

507
00:16:58,560 --> 00:17:00,959
policy perspective

508
00:17:00,959 --> 00:17:02,880
so in summary canvas fingerprinting is a

509
00:17:02,880 --> 00:17:04,000
technique that's

510
00:17:04,000 --> 00:17:07,039
on the rise that said what we've learned

511
00:17:07,039 --> 00:17:09,280
is that wholesale canvas

512
00:17:09,280 --> 00:17:12,000
blocking would disproportionately block

513
00:17:12,000 --> 00:17:15,280
a number of benevolent canvas actions

514
00:17:15,280 --> 00:17:17,679
mlcb improves the state of the art by

515
00:17:17,679 --> 00:17:20,000
using images to easily label hundreds of

516
00:17:20,000 --> 00:17:20,880
programs

517
00:17:20,880 --> 00:17:23,199
it also provides more robust classifiers

518
00:17:23,199 --> 00:17:26,079
given its reliance on text-based data

519
00:17:26,079 --> 00:17:27,760
and it works well despite drift and

520
00:17:27,760 --> 00:17:30,400
despite some amount of obfuscation

521
00:17:30,400 --> 00:17:32,080
finally we'd like to note that our

522
00:17:32,080 --> 00:17:33,919
entire data set of canvas images and

523
00:17:33,919 --> 00:17:34,799
program text

524
00:17:34,799 --> 00:17:37,360
is available at the links above along

525
00:17:37,360 --> 00:17:39,039
with the source code we used to build

526
00:17:39,039 --> 00:17:40,799
all of our machine learning models

527
00:17:40,799 --> 00:17:47,440
thanks again for having us at pets 2021

