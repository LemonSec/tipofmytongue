1
00:00:00,080 --> 00:00:01,680
hello i'm edwin dauber and today i'm

2
00:00:01,680 --> 00:00:03,520
talking about supervised authorship

3
00:00:03,520 --> 00:00:04,960
segmentation of open source code

4
00:00:04,960 --> 00:00:06,000
projects

5
00:00:06,000 --> 00:00:07,680
this is joint work with my co-authors

6
00:00:07,680 --> 00:00:09,360
robert irvonker gregory shearer michael

7
00:00:09,360 --> 00:00:11,120
weisman and rodrigo nelson

8
00:00:11,120 --> 00:00:12,639
from the united states army research lab

9
00:00:12,639 --> 00:00:15,440
and rachel greenstone from

10
00:00:15,440 --> 00:00:16,640
i'd nyu to give a shout out to michael

11
00:00:16,640 --> 00:00:18,960
weissman for for work on the graphics in

12
00:00:18,960 --> 00:00:21,600
these slides

13
00:00:22,400 --> 00:00:24,320
so this work is looking at code

14
00:00:24,320 --> 00:00:26,160
attribution identifying authors of

15
00:00:26,160 --> 00:00:27,760
pieces of code

16
00:00:27,760 --> 00:00:29,599
it's often easier to think about this in

17
00:00:29,599 --> 00:00:31,279
terms of natural language text so for

18
00:00:31,279 --> 00:00:32,558
this slide let's consider

19
00:00:32,558 --> 00:00:35,599
the text here on the left

20
00:00:36,160 --> 00:00:38,239
our goals when doing this work would

21
00:00:38,239 --> 00:00:40,320
typically be to identify bad actors such

22
00:00:40,320 --> 00:00:41,360
as malware authors

23
00:00:41,360 --> 00:00:43,680
cyber terrorists and people involved in

24
00:00:43,680 --> 00:00:46,480
cyber warfare

25
00:00:46,879 --> 00:00:50,399
may also include selling legal disputes

26
00:00:50,399 --> 00:00:53,199
just copyright issues or non-compete

27
00:00:53,199 --> 00:00:55,440
so if we look at this text maybe there

28
00:00:55,440 --> 00:00:58,879
is some part that was plagiarized or

29
00:00:58,879 --> 00:01:01,680
maybe some part of it is malicious or is

30
00:01:01,680 --> 00:01:03,840
it somehow

31
00:01:03,840 --> 00:01:06,159
involved in terrorist activity we want

32
00:01:06,159 --> 00:01:07,760
to identify which those pieces are

33
00:01:07,760 --> 00:01:10,840
and then who wrote those pieces of the

34
00:01:10,840 --> 00:01:13,840
text

35
00:01:13,920 --> 00:01:15,759
so in this work we're translating those

36
00:01:15,759 --> 00:01:18,880
ideas into code

37
00:01:19,759 --> 00:01:22,400
but if we can do that there's some

38
00:01:22,400 --> 00:01:24,320
privacy issues that come about

39
00:01:24,320 --> 00:01:26,960
that we need to think about if we can

40
00:01:26,960 --> 00:01:28,799
identify

41
00:01:28,799 --> 00:01:31,040
cyber terrorists or people involved in

42
00:01:31,040 --> 00:01:32,320
cyber warfare

43
00:01:32,320 --> 00:01:34,880
or malware authors we can identify open

44
00:01:34,880 --> 00:01:36,000
source contributors

45
00:01:36,000 --> 00:01:39,520
or activists hacktivists and just

46
00:01:39,520 --> 00:01:43,039
ordinary everyday programmers

47
00:01:43,439 --> 00:01:46,079
so we want to be able to understand what

48
00:01:46,079 --> 00:01:47,920
these fitness can do

49
00:01:47,920 --> 00:01:50,479
in order to understand how much of a

50
00:01:50,479 --> 00:01:51,840
threat

51
00:01:51,840 --> 00:01:55,840
these kind of people face

52
00:01:56,719 --> 00:01:59,439
so there's a large body of work that's

53
00:01:59,439 --> 00:02:01,920
very successful at attributing projects

54
00:02:01,920 --> 00:02:03,920
that are written by a single person but

55
00:02:03,920 --> 00:02:05,520
in the wild

56
00:02:05,520 --> 00:02:09,758
code projects they have many programmers

57
00:02:09,758 --> 00:02:11,200
now if these parties are under version

58
00:02:11,200 --> 00:02:12,560
control and we have access to the

59
00:02:12,560 --> 00:02:13,920
repository

60
00:02:13,920 --> 00:02:15,200
we have a commit history that can give

61
00:02:15,200 --> 00:02:17,360
us segments and then we can use

62
00:02:17,360 --> 00:02:19,680
techniques developed in work i presented

63
00:02:19,680 --> 00:02:21,120
pets a few years ago

64
00:02:21,120 --> 00:02:23,520
looked at blame who in order to

65
00:02:23,520 --> 00:02:25,840
attribute those segments

66
00:02:25,840 --> 00:02:29,680
but if we don't have the repository

67
00:02:29,680 --> 00:02:32,319
then we need to segment it ourselves now

68
00:02:32,319 --> 00:02:33,519
at this point some of you may be

69
00:02:33,519 --> 00:02:35,599
thinking back to last year

70
00:02:35,599 --> 00:02:38,000
to paper call multi-chi it was published

71
00:02:38,000 --> 00:02:38,879
last year

72
00:02:38,879 --> 00:02:42,400
and did sliding windows segmentation of

73
00:02:42,400 --> 00:02:43,519
files from nine

74
00:02:43,519 --> 00:02:45,760
major github projects and achieved high

75
00:02:45,760 --> 00:02:47,280
accuracy

76
00:02:47,280 --> 00:02:50,879
on a fairly large suspect set

77
00:02:50,879 --> 00:02:53,599
which might lead you to thinking this is

78
00:02:53,599 --> 00:02:56,640
already a solved problem

79
00:02:57,760 --> 00:03:00,879
but consider that sometimes

80
00:03:00,879 --> 00:03:03,040
the change is made to a text that can

81
00:03:03,040 --> 00:03:04,800
drastically change its function can be

82
00:03:04,800 --> 00:03:05,840
small

83
00:03:05,840 --> 00:03:07,519
and can be distributed throughout the

84
00:03:07,519 --> 00:03:09,120
code

85
00:03:09,120 --> 00:03:11,280
if that's true it may be difficult to

86
00:03:11,280 --> 00:03:13,040
detect with the sliding window

87
00:03:13,040 --> 00:03:14,959
and even if we detect it we may be

88
00:03:14,959 --> 00:03:16,560
losing information from other parts of

89
00:03:16,560 --> 00:03:19,840
the code

90
00:03:20,000 --> 00:03:23,280
but it might be possible to detect these

91
00:03:23,280 --> 00:03:24,400
things from the ast

92
00:03:24,400 --> 00:03:28,799
the abstract syntax tree in which case

93
00:03:28,799 --> 00:03:30,720
we want to try to segment the abstract

94
00:03:30,720 --> 00:03:32,480
syntax trait

95
00:03:32,480 --> 00:03:33,920
anyone who needs a refresher the affect

96
00:03:33,920 --> 00:03:37,280
syntax tree is how we parse code

97
00:03:37,280 --> 00:03:39,120
program execution is a depth first

98
00:03:39,120 --> 00:03:47,840
reading of the abstract syntax tree

99
00:03:47,920 --> 00:03:49,360
all right individual nodes in the tree

100
00:03:49,360 --> 00:03:52,239
may be individual tokens from the code

101
00:03:52,239 --> 00:03:55,360
they may be compound

102
00:03:55,360 --> 00:03:59,280
elements of code the details are

103
00:03:59,280 --> 00:04:00,799
more complex than time we're allowed to

104
00:04:00,799 --> 00:04:03,200
discuss

105
00:04:04,720 --> 00:04:07,599
so if we look at this tree on the left

106
00:04:07,599 --> 00:04:08,159
let's

107
00:04:08,159 --> 00:04:10,640
imagine that the green boxes are the

108
00:04:10,640 --> 00:04:12,480
level of granularity a sliding window

109
00:04:12,480 --> 00:04:14,640
approach gives us

110
00:04:14,640 --> 00:04:17,918
so we can we can attribute

111
00:04:17,918 --> 00:04:19,918
the first box the second box the third

112
00:04:19,918 --> 00:04:22,479
box in the fourth box

113
00:04:22,479 --> 00:04:24,639
now if there's a slight overlap in this

114
00:04:24,639 --> 00:04:28,479
case between the second and third box

115
00:04:28,479 --> 00:04:31,758
one of the higher level notes

116
00:04:33,040 --> 00:04:34,960
but let's say what we're interested in

117
00:04:34,960 --> 00:04:37,360
really are the purple boxes

118
00:04:37,360 --> 00:04:39,360
these are the parts that some malicious

119
00:04:39,360 --> 00:04:42,000
person changed to create an exploit in

120
00:04:42,000 --> 00:04:44,560
this code

121
00:04:46,720 --> 00:04:48,880
maybe we identify that author as the

122
00:04:48,880 --> 00:04:50,560
author of the first box or maybe we miss

123
00:04:50,560 --> 00:04:51,680
it all together

124
00:04:51,680 --> 00:04:54,560
either way we lose information but it

125
00:04:54,560 --> 00:04:56,000
can get worse

126
00:04:56,000 --> 00:04:59,280
what if the changes are these

127
00:04:59,280 --> 00:05:02,639
blocks again

128
00:05:02,639 --> 00:05:06,479
maybe we identify one of these sections

129
00:05:06,479 --> 00:05:07,919
no matter what happens we're losing a

130
00:05:07,919 --> 00:05:09,440
lot of information about the authorship

131
00:05:09,440 --> 00:05:11,840
of this program

132
00:05:15,360 --> 00:05:16,800
if we just use the sliding window

133
00:05:16,800 --> 00:05:19,199
approach

134
00:05:19,840 --> 00:05:24,160
right so what are the exact differences

135
00:05:24,160 --> 00:05:27,039
between this work and multi-chi

136
00:05:27,039 --> 00:05:29,199
so some of the differences are in terms

137
00:05:29,199 --> 00:05:31,440
of the actual method itself

138
00:05:31,440 --> 00:05:33,600
multi-chi segments at the level of lines

139
00:05:33,600 --> 00:05:36,240
of code using features from word to vect

140
00:05:36,240 --> 00:05:37,280
which gives a deep learning

141
00:05:37,280 --> 00:05:39,680
representation of the text

142
00:05:39,680 --> 00:05:43,199
of the code in this work we segment

143
00:05:43,199 --> 00:05:45,280
the level of hatred syntax tree nodes

144
00:05:45,280 --> 00:05:46,479
and subtrees

145
00:05:46,479 --> 00:05:48,080
using features derived from the abject

146
00:05:48,080 --> 00:05:50,800
syntax tray

147
00:05:51,600 --> 00:05:53,680
other features are in terms of

148
00:05:53,680 --> 00:05:55,759
evaluation procedure

149
00:05:55,759 --> 00:05:57,680
multi-tie was evaluated in the closed

150
00:05:57,680 --> 00:05:59,919
world this work is evaluated in the open

151
00:05:59,919 --> 00:06:00,880
world

152
00:06:00,880 --> 00:06:03,039
that means in multi-kind they assume

153
00:06:03,039 --> 00:06:04,720
they knew all the people who could

154
00:06:04,720 --> 00:06:06,639
possibly be the author of

155
00:06:06,639 --> 00:06:09,440
a segment in our work we assume we know

156
00:06:09,440 --> 00:06:10,960
some of the possible authors

157
00:06:10,960 --> 00:06:12,479
but there's also other people in the

158
00:06:12,479 --> 00:06:15,280
world it could be

159
00:06:16,960 --> 00:06:19,759
all right multi-chi had a single set of

160
00:06:19,759 --> 00:06:21,840
562 suspects

161
00:06:21,840 --> 00:06:24,000
in our work for each project we look at

162
00:06:24,000 --> 00:06:25,680
the authors the known authors of that

163
00:06:25,680 --> 00:06:26,639
project

164
00:06:26,639 --> 00:06:29,039
plus an additional class to represent

165
00:06:29,039 --> 00:06:31,680
anyone else

166
00:06:33,600 --> 00:06:35,120
finally you look at what we were

167
00:06:35,120 --> 00:06:36,880
actually segmenting and how we were

168
00:06:36,880 --> 00:06:38,639
building our training set

169
00:06:38,639 --> 00:06:40,720
in multi-chi they were segmenting

170
00:06:40,720 --> 00:06:42,240
individual files

171
00:06:42,240 --> 00:06:43,919
and their trained test split was a

172
00:06:43,919 --> 00:06:46,319
random selection of files

173
00:06:46,319 --> 00:06:48,080
this is a normal procedure we did this

174
00:06:48,080 --> 00:06:50,160
in get blame who and it makes up for the

175
00:06:50,160 --> 00:06:52,560
fact that it's very difficult

176
00:06:52,560 --> 00:06:54,560
to build training sets for authors in

177
00:06:54,560 --> 00:06:57,039
the wild

178
00:06:57,120 --> 00:06:59,280
however this does allow for the

179
00:06:59,280 --> 00:07:01,599
possibility that related files

180
00:07:01,599 --> 00:07:03,199
could be split between the training and

181
00:07:03,199 --> 00:07:05,759
test set

182
00:07:05,840 --> 00:07:09,039
so in this work we took on

183
00:07:09,039 --> 00:07:11,599
the burden of more difficult to build

184
00:07:11,599 --> 00:07:12,400
training sets

185
00:07:12,400 --> 00:07:14,160
and more authors we could not build

186
00:07:14,160 --> 00:07:16,080
training sets for

187
00:07:16,080 --> 00:07:18,240
in order to give us the situation in

188
00:07:18,240 --> 00:07:19,360
which we are

189
00:07:19,360 --> 00:07:21,759
certain that all related files within a

190
00:07:21,759 --> 00:07:22,560
project

191
00:07:22,560 --> 00:07:26,880
are in either the test or the training

192
00:07:26,880 --> 00:07:28,720
because at any given time we test on one

193
00:07:28,720 --> 00:07:30,000
project and try on all

194
00:07:30,000 --> 00:07:33,360
the other projects so the fact that we

195
00:07:33,360 --> 00:07:34,479
were able to come up with a table with

196
00:07:34,479 --> 00:07:35,840
this many differences

197
00:07:35,840 --> 00:07:37,120
should be able to tell us this is not

198
00:07:37,120 --> 00:07:38,639
quite a solved problem although

199
00:07:38,639 --> 00:07:39,280
multi-tie

200
00:07:39,280 --> 00:07:41,759
was a great start there's just some

201
00:07:41,759 --> 00:07:45,840
unanswered questions left

202
00:07:48,479 --> 00:07:50,800
so to prepare our data we start by

203
00:07:50,800 --> 00:07:53,360
extracting the object syntax string

204
00:07:53,360 --> 00:07:55,599
we assign ground truth to nodes although

205
00:07:55,599 --> 00:07:56,720
i'll note

206
00:07:56,720 --> 00:07:58,400
there are issues with that all right our

207
00:07:58,400 --> 00:08:00,080
ground truth is really at the level of

208
00:08:00,080 --> 00:08:00,960
lines

209
00:08:00,960 --> 00:08:04,239
not at ast nodes

210
00:08:05,440 --> 00:08:06,800
and in order to do this is this

211
00:08:06,800 --> 00:08:08,720
assignment we had to be able to

212
00:08:08,720 --> 00:08:11,840
reverse engineer the parsing to link

213
00:08:11,840 --> 00:08:12,160
back

214
00:08:12,160 --> 00:08:13,680
nodes to the lines from which they

215
00:08:13,680 --> 00:08:15,680
originated and this is just

216
00:08:15,680 --> 00:08:17,759
a simple fact of the tools that are

217
00:08:17,759 --> 00:08:18,720
available

218
00:08:18,720 --> 00:08:22,000
for parsing and for

219
00:08:22,000 --> 00:08:24,840
and for identifying authors of these

220
00:08:24,840 --> 00:08:26,720
projects

221
00:08:26,720 --> 00:08:30,720
we then proceed to extract the features

222
00:08:34,399 --> 00:08:37,919
so you see in this table

223
00:08:37,919 --> 00:08:41,039
on average each

224
00:08:41,039 --> 00:08:45,120
data sample which is each subtree

225
00:08:45,120 --> 00:08:47,839
had an average of 11 non-zero features

226
00:08:47,839 --> 00:08:50,640
and 210

227
00:08:50,640 --> 00:08:53,279
zero value features this would range

228
00:08:53,279 --> 00:08:54,399
wildly from

229
00:08:54,399 --> 00:08:56,640
leaf nodes which would have very few

230
00:08:56,640 --> 00:08:58,320
non-zero features

231
00:08:58,320 --> 00:09:01,760
to root nodes which would have many

232
00:09:04,959 --> 00:09:06,640
i'll note that there are no word

233
00:09:06,640 --> 00:09:08,560
features no textual features

234
00:09:08,560 --> 00:09:10,800
can be used except for keywords which

235
00:09:10,800 --> 00:09:12,959
are preserved during parsing

236
00:09:12,959 --> 00:09:16,320
these keywords are the language reserved

237
00:09:16,320 --> 00:09:16,880
words

238
00:09:16,880 --> 00:09:18,800
the code was all c plus plus code so

239
00:09:18,800 --> 00:09:21,760
that's c plus reserved keywords

240
00:09:21,760 --> 00:09:25,920
things like for while

241
00:09:25,920 --> 00:09:30,000
things like and any words that are

242
00:09:30,000 --> 00:09:34,160
have a special meaning in c plus plus

243
00:09:35,120 --> 00:09:37,279
all of our other features are ast based

244
00:09:37,279 --> 00:09:38,880
including things like

245
00:09:38,880 --> 00:09:42,000
types of like count the types of nodes

246
00:09:42,000 --> 00:09:43,760
average depths of types of nodes in the

247
00:09:43,760 --> 00:09:45,600
tree

248
00:09:45,600 --> 00:09:48,640
counts of node bi-grams the pairs parent

249
00:09:48,640 --> 00:09:49,680
child

250
00:09:49,680 --> 00:09:52,959
nodes maximum and average breadth and

251
00:09:52,959 --> 00:09:54,000
depth of the

252
00:09:54,000 --> 00:09:57,760
subtract sibling

253
00:09:57,760 --> 00:09:59,360
bi-grams and trigrams are the same type

254
00:09:59,360 --> 00:10:01,200
so that's if we have

255
00:10:01,200 --> 00:10:04,160
a node that is compound expression and

256
00:10:04,160 --> 00:10:05,839
its immediate sibling is a compound

257
00:10:05,839 --> 00:10:06,880
expression

258
00:10:06,880 --> 00:10:09,920
that's a sibling diagram

259
00:10:10,320 --> 00:10:11,920
we then remove unique features and

260
00:10:11,920 --> 00:10:14,800
constant features

261
00:10:16,720 --> 00:10:19,680
so we use a random forest with 100 trees

262
00:10:19,680 --> 00:10:21,680
and a maximum depth of 50.

263
00:10:21,680 --> 00:10:24,240
this is ours as our baseline we then use

264
00:10:24,240 --> 00:10:25,760
techniques we call adjustment and

265
00:10:25,760 --> 00:10:27,120
blocking

266
00:10:27,120 --> 00:10:30,079
and blocking adjustment that i'll

267
00:10:30,079 --> 00:10:31,279
describe briefly now

268
00:10:31,279 --> 00:10:34,720
more details can be found in the paper

269
00:10:34,720 --> 00:10:36,480
so for adjustment we start by applying

270
00:10:36,480 --> 00:10:38,079
our base learner

271
00:10:38,079 --> 00:10:39,760
and then for each sub-tree we observe

272
00:10:39,760 --> 00:10:41,360
the results from the parent unless it's

273
00:10:41,360 --> 00:10:42,160
the root

274
00:10:42,160 --> 00:10:45,120
and all the children unless this belief

275
00:10:45,120 --> 00:10:46,399
and then we adjust

276
00:10:46,399 --> 00:10:48,560
the results for our subtree with

277
00:10:48,560 --> 00:10:49,839
weighted contributions

278
00:10:49,839 --> 00:10:52,959
of the parent and children

279
00:10:53,120 --> 00:10:54,959
the intuition is that related subtrees

280
00:10:54,959 --> 00:10:57,040
are usually but not always by the same

281
00:10:57,040 --> 00:10:58,480
author

282
00:10:58,480 --> 00:11:00,160
and the individual subtrees have low

283
00:11:00,160 --> 00:11:02,560
information so we're using the structure

284
00:11:02,560 --> 00:11:04,800
of the code of the tree

285
00:11:04,800 --> 00:11:08,959
to give us more accurate attributions

286
00:11:11,680 --> 00:11:13,839
blocking is a little bit different first

287
00:11:13,839 --> 00:11:15,760
we set a threshold to determine if an

288
00:11:15,760 --> 00:11:16,160
author

289
00:11:16,160 --> 00:11:18,560
is the same or different between parent

290
00:11:18,560 --> 00:11:21,120
and child nodes

291
00:11:21,120 --> 00:11:22,959
if we think they're the same we combine

292
00:11:22,959 --> 00:11:25,839
them into a block

293
00:11:26,839 --> 00:11:28,800
then

294
00:11:28,800 --> 00:11:31,360
once we've completed our blocking we

295
00:11:31,360 --> 00:11:33,040
average the confidence distributions

296
00:11:33,040 --> 00:11:33,680
across

297
00:11:33,680 --> 00:11:37,680
each member of a block we expect

298
00:11:37,680 --> 00:11:40,880
higher level blocks higher level

299
00:11:40,880 --> 00:11:43,200
nodes in the block to be more accurate

300
00:11:43,200 --> 00:11:46,160
and more confident

301
00:11:46,640 --> 00:11:48,320
and that this will then allow us to get

302
00:11:48,320 --> 00:11:52,160
a better attribution for the whole block

303
00:11:52,320 --> 00:11:55,839
we can apply a penalty having the same

304
00:11:55,839 --> 00:11:57,839
class between adjacent blocks

305
00:11:57,839 --> 00:11:59,519
because we believe that this is where a

306
00:11:59,519 --> 00:12:02,320
change occurs

307
00:12:02,399 --> 00:12:03,760
so we can parameterize this with the

308
00:12:03,760 --> 00:12:06,560
threshold and the penalty

309
00:12:06,560 --> 00:12:08,000
in many ways this is more strict than

310
00:12:08,000 --> 00:12:09,760
adjustment adjustment

311
00:12:09,760 --> 00:12:11,200
allows neighboring nodes to have

312
00:12:11,200 --> 00:12:12,959
different authors

313
00:12:12,959 --> 00:12:15,279
but allows them to influence each other

314
00:12:15,279 --> 00:12:16,959
blocking assumes we know exactly where

315
00:12:16,959 --> 00:12:18,399
the changes happen

316
00:12:18,399 --> 00:12:19,839
so the whole block is attributed

317
00:12:19,839 --> 00:12:22,240
together

318
00:12:22,240 --> 00:12:24,000
so finally there's blocking adjustment

319
00:12:24,000 --> 00:12:25,600
we start by blocking

320
00:12:25,600 --> 00:12:26,880
but then we do adjustment with some

321
00:12:26,880 --> 00:12:28,720
modifications specifically

322
00:12:28,720 --> 00:12:30,320
we use the original distributions to

323
00:12:30,320 --> 00:12:31,760
compute parent and child

324
00:12:31,760 --> 00:12:34,160
contributions and a contribution from

325
00:12:34,160 --> 00:12:36,000
this node itself

326
00:12:36,000 --> 00:12:37,839
this allows us to do to get the benefits

327
00:12:37,839 --> 00:12:39,360
of blocking but then

328
00:12:39,360 --> 00:12:41,279
still have some room for maybe we

329
00:12:41,279 --> 00:12:42,720
weren't quite right about where this

330
00:12:42,720 --> 00:12:45,440
changes occur

331
00:12:45,839 --> 00:12:49,120
so we had 155 products from github

332
00:12:49,120 --> 00:12:53,120
so each project is an experiment

333
00:12:53,120 --> 00:12:54,720
it has an open world class and classes

334
00:12:54,720 --> 00:12:56,399
for all the programmers of that project

335
00:12:56,399 --> 00:12:59,360
that had trained data

336
00:12:59,600 --> 00:13:01,760
we also we had a validation set and a

337
00:13:01,760 --> 00:13:02,639
test set

338
00:13:02,639 --> 00:13:04,079
we also created a subset of our

339
00:13:04,079 --> 00:13:06,160
validation set that would allow us

340
00:13:06,160 --> 00:13:07,680
better control over the amount of

341
00:13:07,680 --> 00:13:08,560
trading data

342
00:13:08,560 --> 00:13:10,160
because it ranged wildly between

343
00:13:10,160 --> 00:13:12,800
officers some had very little

344
00:13:12,800 --> 00:13:15,040
some had a large amount so we created

345
00:13:15,040 --> 00:13:16,480
this subset where we could

346
00:13:16,480 --> 00:13:18,959
could really control how much train data

347
00:13:18,959 --> 00:13:21,839
we had

348
00:13:22,880 --> 00:13:24,560
so blocking and therefore blocking

349
00:13:24,560 --> 00:13:26,000
adjustment depend on being able to

350
00:13:26,000 --> 00:13:26,560
detect

351
00:13:26,560 --> 00:13:30,320
changes in authorship so most subtrees

352
00:13:30,320 --> 00:13:33,279
have the same author as their parent and

353
00:13:33,279 --> 00:13:34,639
these graphs which are mirrors of each

354
00:13:34,639 --> 00:13:35,200
other

355
00:13:35,200 --> 00:13:37,279
show us that we can achieve

356
00:13:37,279 --> 00:13:38,639
approximately 85

357
00:13:38,639 --> 00:13:43,279
accuracy detecting changes in authorship

358
00:13:44,240 --> 00:13:46,320
with thresholding note we could

359
00:13:46,320 --> 00:13:48,639
trivially get very high accuracy

360
00:13:48,639 --> 00:13:50,480
by saying it's always the same but that

361
00:13:50,480 --> 00:13:54,320
doesn't actually tell us anything useful

362
00:13:58,959 --> 00:14:01,199
so our results show us that blocking is

363
00:14:01,199 --> 00:14:02,160
very strong

364
00:14:02,160 --> 00:14:03,760
and that adding adjustment allows some

365
00:14:03,760 --> 00:14:06,399
fine tuning

366
00:14:09,680 --> 00:14:11,519
so that's why for overall accuracy we do

367
00:14:11,519 --> 00:14:13,440
our best with blocking adjustment

368
00:14:13,440 --> 00:14:14,720
although for product average and

369
00:14:14,720 --> 00:14:16,560
balanced accuracy which are both always

370
00:14:16,560 --> 00:14:18,399
much higher

371
00:14:18,399 --> 00:14:21,760
we do better with just blocking

372
00:14:22,800 --> 00:14:26,079
we also can observe that some projects

373
00:14:26,079 --> 00:14:27,839
are complete failures we get zero

374
00:14:27,839 --> 00:14:29,360
percent accuracy

375
00:14:29,360 --> 00:14:32,320
or very close to it

376
00:14:32,639 --> 00:14:34,800
well for others our trivial statement we

377
00:14:34,800 --> 00:14:35,680
can get 100

378
00:14:35,680 --> 00:14:39,199
accuracy or very close to it

379
00:14:40,079 --> 00:14:41,920
if we were able to get further research

380
00:14:41,920 --> 00:14:43,199
into this it may enhance our

381
00:14:43,199 --> 00:14:44,720
understanding of this problem

382
00:14:44,720 --> 00:14:49,040
and these techniques and

383
00:14:49,040 --> 00:14:50,880
also demonstrate quickly to test that

384
00:14:50,880 --> 00:14:52,240
results

385
00:14:52,240 --> 00:14:54,480
in line with what we saw from the

386
00:14:54,480 --> 00:14:58,240
validation set

387
00:14:58,240 --> 00:15:00,320
one thing we noticed was that unlike in

388
00:15:00,320 --> 00:15:02,079
the get lame who work we did a few years

389
00:15:02,079 --> 00:15:03,120
ago

390
00:15:03,120 --> 00:15:04,720
classification confidence is not

391
00:15:04,720 --> 00:15:06,720
particularly useful

392
00:15:06,720 --> 00:15:08,320
in identifying whether an attribution

393
00:15:08,320 --> 00:15:10,560
was correct except that

394
00:15:10,560 --> 00:15:13,760
if we are extremely confident we were

395
00:15:13,760 --> 00:15:15,440
more likely to actually be wrong

396
00:15:15,440 --> 00:15:18,079
in this case

397
00:15:20,399 --> 00:15:22,399
we also looked at a combined method

398
00:15:22,399 --> 00:15:23,920
where we used blocking adjustment for

399
00:15:23,920 --> 00:15:24,720
subtrees

400
00:15:24,720 --> 00:15:26,720
that are very small with a very slight

401
00:15:26,720 --> 00:15:29,600
change in parameters

402
00:15:30,240 --> 00:15:34,160
and then adjustment for larger subtrees

403
00:15:34,160 --> 00:15:37,120
which gave us higher accuracy in both

404
00:15:37,120 --> 00:15:39,680
our validation and test sets

405
00:15:39,680 --> 00:15:41,440
i'll note that research suggests there's

406
00:15:41,440 --> 00:15:43,360
an average of seven nodes per line of

407
00:15:43,360 --> 00:15:44,079
code

408
00:15:44,079 --> 00:15:47,279
so between 1 and 35 ast nodes is up to 5

409
00:15:47,279 --> 00:15:49,920
lines of code

410
00:15:51,199 --> 00:15:53,279
and we see that accuracy is correlated

411
00:15:53,279 --> 00:15:55,199
with subtree size

412
00:15:55,199 --> 00:15:57,120
and i'll note while there's other issues

413
00:15:57,120 --> 00:15:58,720
involved such as

414
00:15:58,720 --> 00:16:02,079
you know suspect set size

415
00:16:02,079 --> 00:16:05,360
the the training on files or projects

416
00:16:05,360 --> 00:16:07,920
our validation set accuracy is

417
00:16:07,920 --> 00:16:09,680
comparable to multi-chi

418
00:16:09,680 --> 00:16:13,040
at similar size and they saw

419
00:16:13,040 --> 00:16:16,079
around 95 accuracy once they got to five

420
00:16:16,079 --> 00:16:17,759
to seven

421
00:16:17,759 --> 00:16:21,199
nodes and we were right in that range

422
00:16:21,199 --> 00:16:24,639
i have seven lines of code which is 35

423
00:16:24,639 --> 00:16:27,600
to 49 nodes

424
00:16:27,600 --> 00:16:29,839
but in this work we can also then look

425
00:16:29,839 --> 00:16:30,720
at

426
00:16:30,720 --> 00:16:33,839
smaller and it's less accurate but we

427
00:16:33,839 --> 00:16:34,399
can still

428
00:16:34,399 --> 00:16:38,800
gain some insights from that

429
00:16:39,759 --> 00:16:42,800
so we can do over 80

430
00:16:42,800 --> 00:16:44,240
accuracy identifying change in

431
00:16:44,240 --> 00:16:46,720
authorship but the data strongly favors

432
00:16:46,720 --> 00:16:51,519
same authorship

433
00:16:51,519 --> 00:16:53,360
we also obtain accuracy over 80 for

434
00:16:53,360 --> 00:16:54,639
subtrees of at least 25

435
00:16:54,639 --> 00:16:57,120
nodes around three and a half lines of

436
00:16:57,120 --> 00:16:57,839
code

437
00:16:57,839 --> 00:16:59,680
and over ninety percent for at least 33

438
00:16:59,680 --> 00:17:01,199
nodes about five

439
00:17:01,199 --> 00:17:04,720
lines of code and 70 for

440
00:17:04,720 --> 00:17:07,039
around five lines of code in the test

441
00:17:07,039 --> 00:17:07,919
set

442
00:17:07,919 --> 00:17:09,520
tests that had lower accuracy for

443
00:17:09,520 --> 00:17:11,520
validation than validation for large

444
00:17:11,520 --> 00:17:14,240
subtrees but higher for small

445
00:17:14,240 --> 00:17:15,520
we also thought we can combine our

446
00:17:15,520 --> 00:17:17,199
techniques to get a best of all worlds

447
00:17:17,199 --> 00:17:19,839
approach

448
00:17:19,919 --> 00:17:22,480
finally we see that data is a challenge

449
00:17:22,480 --> 00:17:24,160
we're limited to line level ground truth

450
00:17:24,160 --> 00:17:25,599
for a method that's capable of greater

451
00:17:25,599 --> 00:17:26,640
granularity

452
00:17:26,640 --> 00:17:28,400
and so maybe we want to parse it with

453
00:17:28,400 --> 00:17:30,240
authorship tagging

454
00:17:30,240 --> 00:17:32,400
also password is split by file instead

455
00:17:32,400 --> 00:17:33,440
of by project

456
00:17:33,440 --> 00:17:34,799
because the lack of data makes this

457
00:17:34,799 --> 00:17:36,480
almost necessary

458
00:17:36,480 --> 00:17:37,840
um but it opens the possibility we're

459
00:17:37,840 --> 00:17:39,679
overestimating our results

460
00:17:39,679 --> 00:17:41,760
we wanted to to get towards with this

461
00:17:41,760 --> 00:17:43,520
work

462
00:17:43,520 --> 00:17:44,960
but also we still need to enhance

463
00:17:44,960 --> 00:17:46,880
accuracy for the small sub-trees

464
00:17:46,880 --> 00:17:48,640
currently for leaf nodes we can get up

465
00:17:48,640 --> 00:17:50,080
to about 40 to 50

466
00:17:50,080 --> 00:17:52,400
accuracy so i'd like to thank the

467
00:17:52,400 --> 00:17:54,480
research lab

468
00:17:54,480 --> 00:17:56,640
darpa and dr richard harang for

469
00:17:56,640 --> 00:17:57,600
inspiration

470
00:17:57,600 --> 00:17:59,919
several years back that led eventually

471
00:17:59,919 --> 00:18:01,440
to this work

472
00:18:01,440 --> 00:18:05,520
so with that thank you

