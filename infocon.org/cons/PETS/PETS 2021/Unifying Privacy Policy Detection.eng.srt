1
00:00:03,439 --> 00:00:05,600
if you have conducted research

2
00:00:05,600 --> 00:00:08,800
on a small corpus of privacy policies

3
00:00:08,800 --> 00:00:10,960
you might have been able to extract the

4
00:00:10,960 --> 00:00:14,320
texts of the privacy policies by hand

5
00:00:14,320 --> 00:00:17,359
also you might have been able to perform

6
00:00:17,359 --> 00:00:19,760
language determination manually

7
00:00:19,760 --> 00:00:21,920
as well as filtering out non-privacy

8
00:00:21,920 --> 00:00:25,039
policies from the corpus by hand

9
00:00:25,039 --> 00:00:26,880
but what if you would like to conduct a

10
00:00:26,880 --> 00:00:28,720
large-scale study

11
00:00:28,720 --> 00:00:32,159
or you already have a corpus of raw html

12
00:00:32,159 --> 00:00:33,040
files

13
00:00:33,040 --> 00:00:36,079
where you know that it is a mix of

14
00:00:36,079 --> 00:00:37,520
privacy policies

15
00:00:37,520 --> 00:00:40,800
and non-privacy policies it might be

16
00:00:40,800 --> 00:00:41,840
handy here

17
00:00:41,840 --> 00:00:45,200
to have a toolchain which is specialized

18
00:00:45,200 --> 00:00:46,160
on detecting

19
00:00:46,160 --> 00:00:49,680
privacy policies hello

20
00:00:49,680 --> 00:00:51,600
and welcome to the presentation of our

21
00:00:51,600 --> 00:00:55,360
paper unifying privacy policy detection

22
00:00:55,360 --> 00:00:58,320
i'm henry and this is joint work with my

23
00:00:58,320 --> 00:01:00,640
supervisor thomas operi

24
00:01:00,640 --> 00:01:03,280
as well as martin diggling and christine

25
00:01:03,280 --> 00:01:05,680
woods

26
00:01:06,960 --> 00:01:09,600
so in order to build such a tool chain

27
00:01:09,600 --> 00:01:10,240
which

28
00:01:10,240 --> 00:01:13,600
naturally consists of several modules

29
00:01:13,600 --> 00:01:16,799
several steps are necessary

30
00:01:16,799 --> 00:01:19,439
we would have a link detection module

31
00:01:19,439 --> 00:01:19,920
which

32
00:01:19,920 --> 00:01:22,240
describes potential privacy policies

33
00:01:22,240 --> 00:01:23,920
from websites

34
00:01:23,920 --> 00:01:27,360
a text extraction module which extracts

35
00:01:27,360 --> 00:01:28,000
the text

36
00:01:28,000 --> 00:01:30,640
of the privacy policies as completely as

37
00:01:30,640 --> 00:01:34,560
possible without any boiler plates

38
00:01:34,560 --> 00:01:36,640
we might need a language determination

39
00:01:36,640 --> 00:01:38,840
module based on the scope of your

40
00:01:38,840 --> 00:01:40,720
research

41
00:01:40,720 --> 00:01:43,680
if you plan to train classifiers to

42
00:01:43,680 --> 00:01:45,600
detect privacy policies

43
00:01:45,600 --> 00:01:48,560
you might have the need to perform

44
00:01:48,560 --> 00:01:51,119
manual labeling

45
00:01:51,119 --> 00:01:54,399
feature engineering because naturally

46
00:01:54,399 --> 00:01:58,000
classifiers need features the classifier

47
00:01:58,000 --> 00:01:59,119
training itself

48
00:01:59,119 --> 00:02:01,360
as well as the validation of the

49
00:02:01,360 --> 00:02:04,079
classifier

50
00:02:05,920 --> 00:02:08,160
so in order to build this tool chain we

51
00:02:08,160 --> 00:02:10,000
naturally need data

52
00:02:10,000 --> 00:02:13,200
and luckily for the english language

53
00:02:13,200 --> 00:02:16,080
there exists already several corpora of

54
00:02:16,080 --> 00:02:18,000
privacy policies

55
00:02:18,000 --> 00:02:22,000
as well as a corpus which consists of

56
00:02:22,000 --> 00:02:25,599
privacy news incidents

57
00:02:25,840 --> 00:02:28,800
unfortunately this is not the case for

58
00:02:28,800 --> 00:02:30,720
the german language

59
00:02:30,720 --> 00:02:34,800
therefore we created a privacy related

60
00:02:34,800 --> 00:02:36,560
news articles corpus

61
00:02:36,560 --> 00:02:40,080
consisting of 112 privacy

62
00:02:40,080 --> 00:02:43,280
related news articles the reason for

63
00:02:43,280 --> 00:02:45,040
creating this corpus

64
00:02:45,040 --> 00:02:48,080
and also including the privacy news

65
00:02:48,080 --> 00:02:50,239
incidents database in english

66
00:02:50,239 --> 00:02:53,440
is to train the classifiers so that they

67
00:02:53,440 --> 00:02:54,160
are able

68
00:02:54,160 --> 00:02:56,959
to distinguish between privacy policies

69
00:02:56,959 --> 00:02:59,680
and privacy related news articles

70
00:02:59,680 --> 00:03:02,000
and since a similar purpose to the

71
00:03:02,000 --> 00:03:04,480
sanitized english corporate privacy

72
00:03:04,480 --> 00:03:06,560
policies does not exist

73
00:03:06,560 --> 00:03:11,680
we need to manually label the gdpr 2019

74
00:03:11,680 --> 00:03:16,319
corpus which is a multilingual corpus

75
00:03:16,319 --> 00:03:20,319
in order to also obtain labeled data for

76
00:03:20,319 --> 00:03:21,519
the german language

77
00:03:21,519 --> 00:03:24,640
as well as to expand the

78
00:03:24,640 --> 00:03:27,760
english training set and

79
00:03:27,760 --> 00:03:30,239
for how we accelerated the manual

80
00:03:30,239 --> 00:03:31,360
labeling process

81
00:03:31,360 --> 00:03:33,519
as well as detailed statistics on our

82
00:03:33,519 --> 00:03:34,640
training set

83
00:03:34,640 --> 00:03:38,319
i refer you to our paper

84
00:03:40,239 --> 00:03:43,360
so we evaluated for text extraction

85
00:03:43,360 --> 00:03:46,000
the performance of seven text from html

86
00:03:46,000 --> 00:03:48,159
extraction libraries

87
00:03:48,159 --> 00:03:51,200
for this purpose we created a

88
00:03:51,200 --> 00:03:55,840
small corpus of 111 html files

89
00:03:55,840 --> 00:03:59,439
which were actually privacy policies

90
00:03:59,439 --> 00:04:02,400
and we manually extracted the policy

91
00:04:02,400 --> 00:04:03,280
texts

92
00:04:03,280 --> 00:04:06,400
from these html files

93
00:04:06,400 --> 00:04:08,799
and as performance metric we utilize the

94
00:04:08,799 --> 00:04:11,920
registering matching

95
00:04:12,840 --> 00:04:14,000
score

96
00:04:14,000 --> 00:04:17,040
so i only show you the

97
00:04:17,040 --> 00:04:19,199
best performing libraries with their

98
00:04:19,199 --> 00:04:21,199
respecting settings

99
00:04:21,199 --> 00:04:23,919
it turns out that the boilerpipe text

100
00:04:23,919 --> 00:04:26,720
from html extraction library with the

101
00:04:26,720 --> 00:04:29,759
non-words rule setting performs best for

102
00:04:29,759 --> 00:04:31,759
english and german

103
00:04:31,759 --> 00:04:34,720
the irritability.js library performs

104
00:04:34,720 --> 00:04:35,759
slightly better

105
00:04:35,759 --> 00:04:39,120
for other languages and

106
00:04:39,120 --> 00:04:42,160
the boilerpipe tool with the canola

107
00:04:42,160 --> 00:04:43,120
extractor

108
00:04:43,120 --> 00:04:47,280
also shows very good results

109
00:04:47,280 --> 00:04:51,120
as a result we recommend to set

110
00:04:51,120 --> 00:04:53,360
boilerpipe with the numbered rule

111
00:04:53,360 --> 00:04:54,160
setting

112
00:04:54,160 --> 00:04:57,680
as default and also keep

113
00:04:57,680 --> 00:05:00,639
these two um text from html extraction

114
00:05:00,639 --> 00:05:01,360
libraries

115
00:05:01,360 --> 00:05:04,880
as backup solutions

116
00:05:06,400 --> 00:05:09,919
regarding language detection we decided

117
00:05:09,919 --> 00:05:10,639
not to use

118
00:05:10,639 --> 00:05:13,680
only a single language detection library

119
00:05:13,680 --> 00:05:16,320
but rather a majority voting scheme

120
00:05:16,320 --> 00:05:17,840
which consists of eight language

121
00:05:17,840 --> 00:05:19,360
detection libraries

122
00:05:19,360 --> 00:05:21,120
and two of these eight language

123
00:05:21,120 --> 00:05:22,800
detection libraries

124
00:05:22,800 --> 00:05:26,479
are able to detect multilingual texts

125
00:05:26,479 --> 00:05:30,240
the reason for building such a scheme

126
00:05:30,240 --> 00:05:32,880
is aiming for higher precision regarding

127
00:05:32,880 --> 00:05:35,840
language detection

128
00:05:37,520 --> 00:05:40,000
in order to compare this approach with

129
00:05:40,000 --> 00:05:42,400
an approach where only a single language

130
00:05:42,400 --> 00:05:44,160
detection library was used

131
00:05:44,160 --> 00:05:47,360
we apply our language detection scheme

132
00:05:47,360 --> 00:05:50,160
on the princeton leven longitudinal

133
00:05:50,160 --> 00:05:52,720
corpus of privacy policies

134
00:05:52,720 --> 00:05:57,280
and for this corpus the cld2 library was

135
00:05:57,280 --> 00:05:58,160
used

136
00:05:58,160 --> 00:05:59,919
which is already a very good language

137
00:05:59,919 --> 00:06:01,280
detection library

138
00:06:01,280 --> 00:06:03,280
and since we will make use of this

139
00:06:03,280 --> 00:06:05,440
corpus as a means

140
00:06:05,440 --> 00:06:07,759
to compare our approach with other

141
00:06:07,759 --> 00:06:08,880
approaches

142
00:06:08,880 --> 00:06:11,440
we refer to this corpus as the princeton

143
00:06:11,440 --> 00:06:14,960
2020 from now on

144
00:06:16,319 --> 00:06:18,960
so here you see the results of applying

145
00:06:18,960 --> 00:06:20,000
the

146
00:06:20,000 --> 00:06:22,000
language detection scheme on the

147
00:06:22,000 --> 00:06:24,479
princeton 2020 corpus

148
00:06:24,479 --> 00:06:27,039
this corpus consists of both privacy

149
00:06:27,039 --> 00:06:30,479
policies and non-privacy policies

150
00:06:30,479 --> 00:06:32,840
and is supposed to only contain english

151
00:06:32,840 --> 00:06:34,639
texts

152
00:06:34,639 --> 00:06:37,440
as you can see the cld2 library already

153
00:06:37,440 --> 00:06:37,840
has

154
00:06:37,840 --> 00:06:40,960
performed a very good job however

155
00:06:40,960 --> 00:06:43,520
our language detection scheme is able to

156
00:06:43,520 --> 00:06:44,000
catch

157
00:06:44,000 --> 00:06:47,440
also multilingual texts as well as

158
00:06:47,440 --> 00:06:50,960
some texts that were in other languages

159
00:06:50,960 --> 00:06:51,280
than

160
00:06:51,280 --> 00:06:54,639
english so as you can see our scheme

161
00:06:54,639 --> 00:06:55,520
increases the

162
00:06:55,520 --> 00:06:59,120
language detection precision

163
00:07:00,880 --> 00:07:03,680
so let's talk about feature engineering

164
00:07:03,680 --> 00:07:04,720
and

165
00:07:04,720 --> 00:07:07,520
typical text classification and leverage

166
00:07:07,520 --> 00:07:08,240
engrams

167
00:07:08,240 --> 00:07:11,599
in order to train classifiers

168
00:07:11,599 --> 00:07:14,400
however due to the diversity of privacy

169
00:07:14,400 --> 00:07:15,360
policies

170
00:07:15,360 --> 00:07:18,479
we decided to apply unsupervised

171
00:07:18,479 --> 00:07:20,479
keyphrase extraction instead

172
00:07:20,479 --> 00:07:24,000
and use the key phrases as features in

173
00:07:24,000 --> 00:07:26,400
order to train classifiers

174
00:07:26,400 --> 00:07:29,599
the reason behind this is a resulting

175
00:07:29,599 --> 00:07:31,599
lower dimensionality in the feature

176
00:07:31,599 --> 00:07:32,720
vectors

177
00:07:32,720 --> 00:07:35,440
and also having a therefore more

178
00:07:35,440 --> 00:07:38,800
resource saving approach

179
00:07:39,199 --> 00:07:41,919
let me show you how this looks um so in

180
00:07:41,919 --> 00:07:43,599
case that we would have

181
00:07:43,599 --> 00:07:46,879
utilized for example trigrams

182
00:07:46,879 --> 00:07:48,960
as features you would have something

183
00:07:48,960 --> 00:07:51,120
like once you agree

184
00:07:51,120 --> 00:07:54,319
you agree to and agree to allow

185
00:07:54,319 --> 00:07:57,520
so far and so on however key keyphrase

186
00:07:57,520 --> 00:07:58,240
extraction

187
00:07:58,240 --> 00:08:02,160
allows to only extract the

188
00:08:02,160 --> 00:08:04,560
most important key phrases that exist in

189
00:08:04,560 --> 00:08:05,680
the text

190
00:08:05,680 --> 00:08:09,039
and discard every other engrams and

191
00:08:09,039 --> 00:08:10,000
phrases

192
00:08:10,000 --> 00:08:12,639
that are not considered as the most

193
00:08:12,639 --> 00:08:14,960
important key phrases in the text

194
00:08:14,960 --> 00:08:17,919
this is usually performed by either

195
00:08:17,919 --> 00:08:19,520
applying

196
00:08:19,520 --> 00:08:27,680
statistical measures or by graph theory

197
00:08:27,680 --> 00:08:29,360
regarding the properties of these

198
00:08:29,360 --> 00:08:30,720
selected

199
00:08:30,720 --> 00:08:32,640
key phase extraction algorithms

200
00:08:32,640 --> 00:08:35,279
originally we had 16 candidates however

201
00:08:35,279 --> 00:08:35,919
we kept

202
00:08:35,919 --> 00:08:37,839
only eight key phrase extraction

203
00:08:37,839 --> 00:08:40,399
algorithms in our tool chain

204
00:08:40,399 --> 00:08:42,958
which were applicable on individual

205
00:08:42,958 --> 00:08:44,720
texts

206
00:08:44,720 --> 00:08:46,800
were unsupervised so that they do not

207
00:08:46,800 --> 00:08:49,120
require any sort of training

208
00:08:49,120 --> 00:08:52,880
domain independent fast and also support

209
00:08:52,880 --> 00:08:55,760
multi-processing in order to accelerate

210
00:08:55,760 --> 00:08:56,320
the

211
00:08:56,320 --> 00:08:59,440
extraction of the keyphrases from the

212
00:08:59,440 --> 00:09:01,120
texts

213
00:09:01,120 --> 00:09:04,480
and these resulting key phrases for each

214
00:09:04,480 --> 00:09:05,200
document

215
00:09:05,200 --> 00:09:09,839
form a binary feature vector

216
00:09:11,519 --> 00:09:15,440
so let's talk about the classifier

217
00:09:15,440 --> 00:09:18,720
and we decided to use an

218
00:09:18,720 --> 00:09:21,760
ensemble soft voting classifier which

219
00:09:21,760 --> 00:09:24,720
basically consists of three underlying

220
00:09:24,720 --> 00:09:26,399
classifiers

221
00:09:26,399 --> 00:09:29,519
each of these classifiers outputs the

222
00:09:29,519 --> 00:09:31,279
prediction probability

223
00:09:31,279 --> 00:09:34,480
for each of the texts

224
00:09:34,480 --> 00:09:39,360
and the resulting label is determined by

225
00:09:39,360 --> 00:09:42,240
choosing the higher mean prediction

226
00:09:42,240 --> 00:09:43,600
probability

227
00:09:43,600 --> 00:09:47,120
for the text each of these classifiers

228
00:09:47,120 --> 00:09:50,560
was calibrated so that they output

229
00:09:50,560 --> 00:09:53,920
precise prediction probability

230
00:09:53,920 --> 00:09:58,720
and we validated our approach

231
00:09:58,720 --> 00:10:02,320
on the resulting training set and as you

232
00:10:02,320 --> 00:10:03,519
can see

233
00:10:03,519 --> 00:10:06,800
we have pretty good results uh now over

234
00:10:06,800 --> 00:10:08,079
99

235
00:10:08,079 --> 00:10:11,839
f1 score as well as a 99

236
00:10:11,839 --> 00:10:14,959
balance accuracy

237
00:10:16,000 --> 00:10:18,959
so in order to have a further means of

238
00:10:18,959 --> 00:10:20,000
comparison

239
00:10:20,000 --> 00:10:22,560
we applied our classifiers on the

240
00:10:22,560 --> 00:10:25,279
princeton 2020 corpus

241
00:10:25,279 --> 00:10:28,000
and it turns out that for english texts

242
00:10:28,000 --> 00:10:29,320
we have a

243
00:10:29,320 --> 00:10:31,920
96.7 agreement on the levels of the

244
00:10:31,920 --> 00:10:34,720
privacy policies

245
00:10:34,720 --> 00:10:38,959
however we only have a 41.7 percent

246
00:10:38,959 --> 00:10:40,480
agreement on the labels of the

247
00:10:40,480 --> 00:10:43,360
non-privacy policies

248
00:10:43,360 --> 00:10:46,240
we manually inspected the assigned

249
00:10:46,240 --> 00:10:47,120
labels

250
00:10:47,120 --> 00:10:49,760
in order to find out the reason for this

251
00:10:49,760 --> 00:10:51,680
observation

252
00:10:51,680 --> 00:10:54,880
and it turns out that our classifier

253
00:10:54,880 --> 00:10:58,560
identified privacy policies that

254
00:10:58,560 --> 00:11:00,560
had originally been labeled as

255
00:11:00,560 --> 00:11:02,399
non-privacy policies

256
00:11:02,399 --> 00:11:05,279
we could observe similar results on the

257
00:11:05,279 --> 00:11:05,760
small

258
00:11:05,760 --> 00:11:08,800
portion of as german identified texts of

259
00:11:08,800 --> 00:11:10,079
this corpus

260
00:11:10,079 --> 00:11:12,959
a detailed analysis on this is also

261
00:11:12,959 --> 00:11:15,839
included in the paper

262
00:11:17,519 --> 00:11:19,519
so let's talk about finding potential

263
00:11:19,519 --> 00:11:21,839
privacy policies on websites

264
00:11:21,839 --> 00:11:24,880
for this purpose we implemented

265
00:11:24,880 --> 00:11:27,120
four methods that had been utilized in

266
00:11:27,120 --> 00:11:29,360
previous work

267
00:11:29,360 --> 00:11:32,800
first a so-called simple english method

268
00:11:32,800 --> 00:11:36,160
which basically searches in the linked

269
00:11:36,160 --> 00:11:37,279
texts for

270
00:11:37,279 --> 00:11:40,000
either privacy or the combination of

271
00:11:40,000 --> 00:11:40,560
data

272
00:11:40,560 --> 00:11:43,680
and protection two-step english

273
00:11:43,680 --> 00:11:47,040
which first searches for a smaller list

274
00:11:47,040 --> 00:11:50,639
of matches in the link texts

275
00:11:50,639 --> 00:11:54,000
and if no match is found then it is

276
00:11:54,000 --> 00:11:55,519
expanded to a

277
00:11:55,519 --> 00:11:59,120
broader list of terms a multilingual

278
00:11:59,120 --> 00:12:00,160
word list

279
00:12:00,160 --> 00:12:04,000
has also been implemented as a method

280
00:12:04,000 --> 00:12:07,519
in order to search for

281
00:12:07,519 --> 00:12:10,800
other privacy policies than

282
00:12:10,800 --> 00:12:14,639
english ones and we also have

283
00:12:14,639 --> 00:12:17,040
the context-based approach which

284
00:12:17,040 --> 00:12:18,800
considers both

285
00:12:18,800 --> 00:12:22,839
the link text and the previous html

286
00:12:22,839 --> 00:12:25,600
elements

287
00:12:25,600 --> 00:12:28,720
so we tested these link detection

288
00:12:28,720 --> 00:12:29,440
methods

289
00:12:29,440 --> 00:12:32,240
on the top 10 000 websites of the

290
00:12:32,240 --> 00:12:33,120
tranquilist

291
00:12:33,120 --> 00:12:36,959
at the end of january 2021

292
00:12:36,959 --> 00:12:41,120
and out of 8624 reachable websites

293
00:12:41,120 --> 00:12:44,240
uh 7353

294
00:12:44,240 --> 00:12:47,279
matched at least one of the um

295
00:12:47,279 --> 00:12:51,440
four link detection methods

296
00:12:51,440 --> 00:12:54,480
it turns out that the more extensive the

297
00:12:54,480 --> 00:12:57,519
search list actually is the higher

298
00:12:57,519 --> 00:13:01,839
um is the number of false positives

299
00:13:01,839 --> 00:13:05,920
for details um statistics on

300
00:13:05,920 --> 00:13:08,480
each of these link detection methods i

301
00:13:08,480 --> 00:13:10,480
refer you to the paper

302
00:13:10,480 --> 00:13:13,120
but what i can demonstrate you here is

303
00:13:13,120 --> 00:13:13,519
that

304
00:13:13,519 --> 00:13:16,720
if we combine all of these link

305
00:13:16,720 --> 00:13:18,160
detection methods

306
00:13:18,160 --> 00:13:20,560
the results uh according to our

307
00:13:20,560 --> 00:13:21,360
classifier

308
00:13:21,360 --> 00:13:25,440
turns out to only have a 57 percent

309
00:13:25,440 --> 00:13:28,959
actual privacy policies for english and

310
00:13:28,959 --> 00:13:33,040
60 uh for the german language

311
00:13:33,040 --> 00:13:37,040
which indicates that applying only

312
00:13:37,040 --> 00:13:40,639
a link detection is not enough to have a

313
00:13:40,639 --> 00:13:48,079
sanitized corpus of privacy policies

314
00:13:48,079 --> 00:13:51,040
all right so we demonstrated that the

315
00:13:51,040 --> 00:13:53,440
pre-processing phrase for privacy

316
00:13:53,440 --> 00:13:54,399
policies

317
00:13:54,399 --> 00:13:57,920
is crucial to conduct proper research

318
00:13:57,920 --> 00:14:01,680
and we evaluated candidate tools

319
00:14:01,680 --> 00:14:03,839
and carefully selected them to include

320
00:14:03,839 --> 00:14:06,320
them in our tool chain

321
00:14:06,320 --> 00:14:09,199
we evaluated several text extraction

322
00:14:09,199 --> 00:14:10,160
libraries

323
00:14:10,160 --> 00:14:12,560
and included the best one in our tool

324
00:14:12,560 --> 00:14:13,920
chain

325
00:14:13,920 --> 00:14:17,360
we demonstrated that majority voting

326
00:14:17,360 --> 00:14:19,199
increases the precision of

327
00:14:19,199 --> 00:14:22,240
language detection

328
00:14:22,240 --> 00:14:25,040
and we demonstrated that our classifiers

329
00:14:25,040 --> 00:14:26,959
help in order to build

330
00:14:26,959 --> 00:14:31,440
cleaner corpora of privacy policies

331
00:14:31,440 --> 00:14:34,560
currently we only support english and

332
00:14:34,560 --> 00:14:35,519
german

333
00:14:35,519 --> 00:14:37,920
but we would be happy to expand our tool

334
00:14:37,920 --> 00:14:40,320
chain also to other languages the source

335
00:14:40,320 --> 00:14:42,639
code is available on github

336
00:14:42,639 --> 00:14:45,000
we are looking forward to your

337
00:14:45,000 --> 00:14:46,880
contributions

338
00:14:46,880 --> 00:14:59,600
thank you very much

