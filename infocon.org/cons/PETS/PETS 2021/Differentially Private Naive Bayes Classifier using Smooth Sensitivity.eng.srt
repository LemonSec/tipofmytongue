1
00:00:02,240 --> 00:00:03,120
hello everyone

2
00:00:03,120 --> 00:00:04,880
i'm fair zaza ferrani from purdue

3
00:00:04,880 --> 00:00:06,319
university

4
00:00:06,319 --> 00:00:07,919
and today i'm going to talk about

5
00:00:07,919 --> 00:00:09,679
differentially private naive bayes

6
00:00:09,679 --> 00:00:12,719
classifier using smooth sensitivity

7
00:00:12,719 --> 00:00:14,960
um this is a joint work with chris

8
00:00:14,960 --> 00:00:18,400
clifton from purdue university

9
00:00:19,199 --> 00:00:21,920
so this is the outline of my talk at

10
00:00:21,920 --> 00:00:23,760
first i'm giving you some motivation

11
00:00:23,760 --> 00:00:24,960
about the problem

12
00:00:24,960 --> 00:00:26,880
then i go over a little bit background

13
00:00:26,880 --> 00:00:28,480
on the naive bayes classifier

14
00:00:28,480 --> 00:00:30,320
differential privacy

15
00:00:30,320 --> 00:00:33,760
and finally smooth sensitivity then we

16
00:00:33,760 --> 00:00:34,320
discuss

17
00:00:34,320 --> 00:00:36,399
a differentially private naive bayes

18
00:00:36,399 --> 00:00:39,280
classifier using smooth sensitivity

19
00:00:39,280 --> 00:00:42,480
and finally i present some

20
00:00:42,480 --> 00:00:45,839
experimental results

21
00:00:47,360 --> 00:00:50,079
so um a model generated by a machine

22
00:00:50,079 --> 00:00:51,199
learning algorithm

23
00:00:51,199 --> 00:00:53,280
when trained on a data set can reveal

24
00:00:53,280 --> 00:00:55,760
sensitive information

25
00:00:55,760 --> 00:00:58,399
so consider the scenario that we have a

26
00:00:58,399 --> 00:01:00,239
training data set

27
00:01:00,239 --> 00:01:02,320
of course we cannot reveal that as a

28
00:01:02,320 --> 00:01:04,720
part of the privacy protection

29
00:01:04,720 --> 00:01:06,560
and the hope is to train a machine

30
00:01:06,560 --> 00:01:08,479
learning model that goes through a lot

31
00:01:08,479 --> 00:01:08,720
of

32
00:01:08,720 --> 00:01:11,200
training and we could potentially

33
00:01:11,200 --> 00:01:12,000
publish

34
00:01:12,000 --> 00:01:15,119
and not reveal the sensitive data whose

35
00:01:15,119 --> 00:01:17,040
privacy must be preserved

36
00:01:17,040 --> 00:01:19,759
so the hope is that the model can be

37
00:01:19,759 --> 00:01:22,880
shared and get published

38
00:01:23,439 --> 00:01:25,759
well the problem is that the machine

39
00:01:25,759 --> 00:01:27,720
learning model captures

40
00:01:27,720 --> 00:01:30,640
a lot of information from the input

41
00:01:30,640 --> 00:01:34,640
and by doing doing that the model

42
00:01:34,960 --> 00:01:36,880
contains a lot of information about the

43
00:01:36,880 --> 00:01:38,400
input so

44
00:01:38,400 --> 00:01:40,240
intuitively what's happening here is

45
00:01:40,240 --> 00:01:42,560
that the model reflects very interesting

46
00:01:42,560 --> 00:01:45,360
details about the input

47
00:01:45,360 --> 00:01:47,200
and that is the reason why membership

48
00:01:47,200 --> 00:01:49,360
attacks and model inversion attacks are

49
00:01:49,360 --> 00:01:51,439
actually quite powerful in this case

50
00:01:51,439 --> 00:01:54,240
because the information is actually

51
00:01:54,240 --> 00:01:57,280
captured in the model

52
00:01:59,439 --> 00:02:02,240
um so there are a series of recent work

53
00:02:02,240 --> 00:02:03,600
works that use

54
00:02:03,600 --> 00:02:05,680
differential privacy to protect users

55
00:02:05,680 --> 00:02:08,959
data within a machine learning model

56
00:02:08,959 --> 00:02:12,000
some examples are differentially private

57
00:02:12,000 --> 00:02:16,080
decision trees svm deep neural networks

58
00:02:16,080 --> 00:02:18,000
logistic regression naive bayes

59
00:02:18,000 --> 00:02:19,520
classifier

60
00:02:19,520 --> 00:02:21,599
and a naive bayes classifier is a

61
00:02:21,599 --> 00:02:23,520
popular machine learning algorithm

62
00:02:23,520 --> 00:02:27,840
used as a baseline for many tasks

63
00:02:29,040 --> 00:02:32,879
so let's just go over the

64
00:02:32,879 --> 00:02:35,920
definition of the naive bayes classifier

65
00:02:35,920 --> 00:02:37,840
so given a training set

66
00:02:37,840 --> 00:02:39,920
training set of examples with the

67
00:02:39,920 --> 00:02:41,920
corresponding labels

68
00:02:41,920 --> 00:02:44,800
the task is to assign a new class c map

69
00:02:44,800 --> 00:02:45,680
to an

70
00:02:45,680 --> 00:02:49,120
to an unseen instance x

71
00:02:49,120 --> 00:02:51,760
uh so the learning task would be that

72
00:02:51,760 --> 00:02:52,160
for

73
00:02:52,160 --> 00:02:55,760
each instance x consists of m features

74
00:02:55,760 --> 00:02:58,959
assign a conditional probability of

75
00:02:58,959 --> 00:03:02,400
p of cj given x for each k

76
00:03:02,400 --> 00:03:05,840
possible classes

77
00:03:06,239 --> 00:03:08,879
and the c map is assigned to be the

78
00:03:08,879 --> 00:03:11,360
maximum conditional probability c

79
00:03:11,360 --> 00:03:19,280
j given x for all js

80
00:03:19,280 --> 00:03:22,640
uh then we use the base theorem uh to

81
00:03:22,640 --> 00:03:25,200
rewrite the above formula and finally

82
00:03:25,200 --> 00:03:27,440
uh the naive bayes makes this uh

83
00:03:27,440 --> 00:03:29,440
simplifying assumption

84
00:03:29,440 --> 00:03:31,360
that the attribute values are

85
00:03:31,360 --> 00:03:33,120
conditionally independent given the

86
00:03:33,120 --> 00:03:34,400
target value

87
00:03:34,400 --> 00:03:38,080
therefore we get c of nb to be

88
00:03:38,080 --> 00:03:41,920
r max of probability of cj

89
00:03:41,920 --> 00:03:45,200
times the product of all conditional

90
00:03:45,200 --> 00:03:46,560
probability

91
00:03:46,560 --> 00:03:49,840
of x i given cj

92
00:03:49,840 --> 00:03:52,879
for all i's

93
00:03:56,879 --> 00:04:00,080
okay next we go to the definition

94
00:04:00,080 --> 00:04:02,720
of differential privacy so differential

95
00:04:02,720 --> 00:04:04,080
privacy was

96
00:04:04,080 --> 00:04:07,439
uh first introduced in 2006 by

97
00:04:07,439 --> 00:04:11,519
uh divorce mcshary nasim and smith

98
00:04:11,519 --> 00:04:13,920
we give the definition from a follow-on

99
00:04:13,920 --> 00:04:16,560
paper by the work

100
00:04:16,560 --> 00:04:19,918
so epsilon differential privacy privacy

101
00:04:19,918 --> 00:04:20,720
which is a

102
00:04:20,720 --> 00:04:23,759
mapping between the database space

103
00:04:23,759 --> 00:04:27,520
and the outcome space says that for

104
00:04:27,520 --> 00:04:30,639
any two neighboring data sets meaning uh

105
00:04:30,639 --> 00:04:31,120
within

106
00:04:31,120 --> 00:04:33,040
l1 distance in their histogram

107
00:04:33,040 --> 00:04:34,400
representation

108
00:04:34,400 --> 00:04:36,800
and any subset of mechanism that we

109
00:04:36,800 --> 00:04:39,840
might be interested

110
00:04:41,120 --> 00:04:44,160
the probability that our algorithm maps

111
00:04:44,160 --> 00:04:47,199
the uh first database into the outcome

112
00:04:47,199 --> 00:04:47,919
space

113
00:04:47,919 --> 00:04:50,960
is multiplicatively very close

114
00:04:50,960 --> 00:04:53,600
to the probability that our algorithm

115
00:04:53,600 --> 00:04:55,680
maps the second database into the

116
00:04:55,680 --> 00:04:56,320
outcomes

117
00:04:56,320 --> 00:04:59,680
into that outcome space

118
00:05:00,080 --> 00:05:03,440
so another concept to discuss

119
00:05:03,440 --> 00:05:05,759
is the notion of sensitivity the

120
00:05:05,759 --> 00:05:07,280
sensitivity of a function

121
00:05:07,280 --> 00:05:10,720
f is defined as how much the output of

122
00:05:10,720 --> 00:05:13,840
f may change between neighboring

123
00:05:13,840 --> 00:05:14,560
database

124
00:05:14,560 --> 00:05:17,039
x and y

125
00:05:19,520 --> 00:05:22,240
so there are two types of sensitivity

126
00:05:22,240 --> 00:05:22,720
one

127
00:05:22,720 --> 00:05:25,600
is a global sensitivity which for a

128
00:05:25,600 --> 00:05:26,160
function

129
00:05:26,160 --> 00:05:29,360
f with respect to l1 metric

130
00:05:29,360 --> 00:05:32,000
is the maximum absolute difference

131
00:05:32,000 --> 00:05:33,199
between the outcome of

132
00:05:33,199 --> 00:05:39,520
f for all pairs of neighboring databases

133
00:05:39,520 --> 00:05:43,199
the other one is called

134
00:05:43,199 --> 00:05:47,039
local sensitivity which is defined for a

135
00:05:47,039 --> 00:05:48,080
given database

136
00:05:48,080 --> 00:05:51,520
x and we only look at the neighbors of x

137
00:05:51,520 --> 00:05:54,240
and report the maximum absolute

138
00:05:54,240 --> 00:05:55,840
difference between

139
00:05:55,840 --> 00:05:59,600
f of x and f of y for all neighbors of x

140
00:05:59,600 --> 00:06:06,160
denoted by y

141
00:06:06,160 --> 00:06:09,199
so um the thing to note here is that

142
00:06:09,199 --> 00:06:11,199
adding noise proportional to local

143
00:06:11,199 --> 00:06:12,160
sensitivity

144
00:06:12,160 --> 00:06:14,479
tells you something about the data set

145
00:06:14,479 --> 00:06:16,639
so it doesn't really end up giving you

146
00:06:16,639 --> 00:06:19,680
differential privacy um

147
00:06:19,680 --> 00:06:23,280
so nasim at all defined a smooth bound

148
00:06:23,280 --> 00:06:25,520
that addressed this by not looking at

149
00:06:25,520 --> 00:06:27,360
the neighbors of the current data set

150
00:06:27,360 --> 00:06:30,720
but also their neighbors so they defined

151
00:06:30,720 --> 00:06:33,199
the smooth bound which is for a beta

152
00:06:33,199 --> 00:06:34,639
greater than zero

153
00:06:34,639 --> 00:06:37,360
a function s is a beta smooth upper

154
00:06:37,360 --> 00:06:39,840
bound on the local sensitivity of f

155
00:06:39,840 --> 00:06:41,759
if it satisfies the following two

156
00:06:41,759 --> 00:06:43,360
requirements

157
00:06:43,360 --> 00:06:46,639
first it is greater than or equal to the

158
00:06:46,639 --> 00:06:48,240
local sensitivity

159
00:06:48,240 --> 00:06:51,440
and the second it is a smooth function

160
00:06:51,440 --> 00:06:53,440
and we have demonstrated that in the

161
00:06:53,440 --> 00:06:56,479
right hand side figure

162
00:07:00,080 --> 00:07:03,440
so next um is the definition of smooth

163
00:07:03,440 --> 00:07:05,039
sensitivity by nasim at

164
00:07:05,039 --> 00:07:08,560
all for a beta greater than zero

165
00:07:08,560 --> 00:07:11,039
the beta smooth sensitivity of f is

166
00:07:11,039 --> 00:07:14,000
defined as the following

167
00:07:14,840 --> 00:07:17,840
equation

168
00:07:17,919 --> 00:07:21,039
and um they in their paper they have

169
00:07:21,039 --> 00:07:22,800
discussed how to compute the

170
00:07:22,800 --> 00:07:25,840
smooth sensitivity of a function f uh

171
00:07:25,840 --> 00:07:28,720
so the smooth sensitivity of a function

172
00:07:28,720 --> 00:07:28,960
f

173
00:07:28,960 --> 00:07:32,720
at distance k is as follows

174
00:07:32,720 --> 00:07:35,039
and we can express the smooth

175
00:07:35,039 --> 00:07:36,479
sensitivity of f

176
00:07:36,479 --> 00:07:45,440
in terms of a of k

177
00:07:45,440 --> 00:07:49,360
okay um so next we discuss

178
00:07:49,360 --> 00:07:51,520
the differentially private naive bayes

179
00:07:51,520 --> 00:07:52,400
classifier

180
00:07:52,400 --> 00:07:55,919
using smooth sensitivity

181
00:07:56,080 --> 00:07:59,599
um so a standard approach for

182
00:07:59,599 --> 00:08:01,199
fitting a machine learning model to a

183
00:08:01,199 --> 00:08:03,280
numerical attribute is to assume that

184
00:08:03,280 --> 00:08:06,080
the underlying distribution is cautioned

185
00:08:06,080 --> 00:08:09,039
um we assume that the numerical features

186
00:08:09,039 --> 00:08:11,120
values are bounded and compute the

187
00:08:11,120 --> 00:08:12,240
smooth sensitivity

188
00:08:12,240 --> 00:08:14,560
for estimating the parameters of the

189
00:08:14,560 --> 00:08:17,440
truncated normal distribution

190
00:08:17,440 --> 00:08:20,960
uh we also only train using a subset of

191
00:08:20,960 --> 00:08:22,080
the data

192
00:08:22,080 --> 00:08:24,080
the way this subset is defined and then

193
00:08:24,080 --> 00:08:27,840
he builds us a smooth bound

194
00:08:30,800 --> 00:08:34,080
so we give the definition for the trim

195
00:08:34,080 --> 00:08:37,120
sample it's just let's

196
00:08:37,120 --> 00:08:39,440
let x you know the sample in a sorted

197
00:08:39,440 --> 00:08:42,159
order and let m be a trimming parameter

198
00:08:42,159 --> 00:08:45,040
the trim sequence of the of sample x is

199
00:08:45,040 --> 00:08:46,080
defined to be

200
00:08:46,080 --> 00:08:49,200
x m plus 1 till x n minus 1

201
00:08:49,200 --> 00:08:52,320
till x n minus m so in other words we

202
00:08:52,320 --> 00:08:54,160
are drawing a window of size

203
00:08:54,160 --> 00:08:57,920
n minus 2m on the data

204
00:09:00,399 --> 00:09:03,519
okay so in the following theorem we say

205
00:09:03,519 --> 00:09:04,080
how

206
00:09:04,080 --> 00:09:07,360
we can compute the smooth sensitivity of

207
00:09:07,360 --> 00:09:09,040
the mean

208
00:09:09,040 --> 00:09:12,880
given a list of n bounded real numbers v

209
00:09:12,880 --> 00:09:15,600
from x1 to xn in the range of the

210
00:09:15,600 --> 00:09:16,240
interval

211
00:09:16,240 --> 00:09:19,040
l to u the smooth sensitivity of the

212
00:09:19,040 --> 00:09:20,080
mean

213
00:09:20,080 --> 00:09:22,720
can be computed and the high level proof

214
00:09:22,720 --> 00:09:23,680
idea is that

215
00:09:23,680 --> 00:09:26,720
we either move the k leftmost elements

216
00:09:26,720 --> 00:09:27,040
to

217
00:09:27,040 --> 00:09:30,720
u or move the k rightmost elements

218
00:09:30,720 --> 00:09:33,440
to l

219
00:09:35,360 --> 00:09:38,640
okay um next we discuss how we

220
00:09:38,640 --> 00:09:40,800
can compute the smooth sensitivity of

221
00:09:40,800 --> 00:09:42,000
the variance

222
00:09:42,000 --> 00:09:45,440
uh we first define the k maximal

223
00:09:45,440 --> 00:09:49,839
variance subset um so given a set of

224
00:09:49,839 --> 00:09:52,240
given a set of v of n real numbers in

225
00:09:52,240 --> 00:09:54,320
the ascending order and an integer

226
00:09:54,320 --> 00:09:57,839
k a subset q is called a k

227
00:09:57,839 --> 00:10:01,040
maximal variance subset of v if the size

228
00:10:01,040 --> 00:10:01,600
of q

229
00:10:01,600 --> 00:10:04,800
is k and the variance of q

230
00:10:04,800 --> 00:10:07,440
would be larger than any other subset of

231
00:10:07,440 --> 00:10:08,399
the same

232
00:10:08,399 --> 00:10:11,839
size k of e

233
00:10:12,399 --> 00:10:15,680
and um we have this theorem that given a

234
00:10:15,680 --> 00:10:16,240
list of

235
00:10:16,240 --> 00:10:19,440
n bounded real numbers v in the range of

236
00:10:19,440 --> 00:10:20,160
interval

237
00:10:20,160 --> 00:10:23,600
l to u and an integer k the k

238
00:10:23,600 --> 00:10:25,920
maximal variance subset can be computed

239
00:10:25,920 --> 00:10:32,959
in o of n squared

240
00:10:32,959 --> 00:10:36,160
okay and we provide the following

241
00:10:36,160 --> 00:10:37,760
corollary

242
00:10:37,760 --> 00:10:40,079
it says that given a list of n bounded

243
00:10:40,079 --> 00:10:41,360
real numbers

244
00:10:41,360 --> 00:10:44,399
in the range l to u and an integer k

245
00:10:44,399 --> 00:10:46,560
became maximal variance subset can be

246
00:10:46,560 --> 00:10:48,480
achieved by removing

247
00:10:48,480 --> 00:10:53,360
n minus k consecutive elements in v

248
00:10:56,800 --> 00:11:00,560
okay next we define how the smooth

249
00:11:00,560 --> 00:11:02,320
sensitivity of the variance can be

250
00:11:02,320 --> 00:11:03,920
computed

251
00:11:03,920 --> 00:11:06,240
the following theorem says that given a

252
00:11:06,240 --> 00:11:07,279
list of

253
00:11:07,279 --> 00:11:10,079
n bounded real numbers v in the range of

254
00:11:10,079 --> 00:11:10,880
interval

255
00:11:10,880 --> 00:11:14,160
l to u this smooth sensitivity

256
00:11:14,160 --> 00:11:17,120
of the variance v can be computed in o

257
00:11:17,120 --> 00:11:17,519
of n

258
00:11:17,519 --> 00:11:20,640
squared so the high level proof idea

259
00:11:20,640 --> 00:11:23,600
is that we iterate to k consecutive

260
00:11:23,600 --> 00:11:25,360
elements in a data set

261
00:11:25,360 --> 00:11:28,000
we move the first t elements to l and

262
00:11:28,000 --> 00:11:28,560
write k

263
00:11:28,560 --> 00:11:31,760
minus t elements to u and we move

264
00:11:31,760 --> 00:11:34,880
one last elements to its extreme case

265
00:11:34,880 --> 00:11:38,160
l u or mu of the window

266
00:11:38,160 --> 00:11:40,880
or we move k tail elements in the data

267
00:11:40,880 --> 00:11:41,760
dataset

268
00:11:41,760 --> 00:11:44,959
we move t leftmost elements and k minus

269
00:11:44,959 --> 00:11:47,120
t rightmost elements to the mean of the

270
00:11:47,120 --> 00:11:48,800
remaining window

271
00:11:48,800 --> 00:11:51,040
and we move one last elements to its

272
00:11:51,040 --> 00:11:52,000
extreme case

273
00:11:52,000 --> 00:11:57,839
l u or mu of the window

274
00:11:59,200 --> 00:12:02,000
okay um so we have included our

275
00:12:02,000 --> 00:12:04,880
algorithm pseudo code on the right side

276
00:12:04,880 --> 00:12:08,079
um so the way we distribute the

277
00:12:08,079 --> 00:12:10,480
privacy budget or epsilon between

278
00:12:10,480 --> 00:12:12,480
numerical attributes and

279
00:12:12,480 --> 00:12:15,360
categorical attributes is with a ratio

280
00:12:15,360 --> 00:12:15,920
of

281
00:12:15,920 --> 00:12:20,079
two to one the um

282
00:12:20,720 --> 00:12:23,760
for numerical mean and variance we have

283
00:12:23,760 --> 00:12:24,480
added

284
00:12:24,480 --> 00:12:26,639
a cauchy noise scale to the smooth

285
00:12:26,639 --> 00:12:27,920
sensitivity

286
00:12:27,920 --> 00:12:31,200
to achieve epsilon differential privacy

287
00:12:31,200 --> 00:12:34,480
and also since the

288
00:12:34,480 --> 00:12:36,800
categorical count essentially will

289
00:12:36,800 --> 00:12:38,320
change by at most one

290
00:12:38,320 --> 00:12:40,240
regardless of the category changes or

291
00:12:40,240 --> 00:12:41,600
not

292
00:12:41,600 --> 00:12:43,360
the smooth sensitivity doesn't really

293
00:12:43,360 --> 00:12:44,639
benefit here

294
00:12:44,639 --> 00:12:48,959
and the laplace noise is optimal in this

295
00:12:50,839 --> 00:12:53,839
case

296
00:12:55,040 --> 00:12:58,079
okay we finally do some experiments on

297
00:12:58,079 --> 00:12:59,519
the uci data sets

298
00:12:59,519 --> 00:13:03,279
including adult data set mushrooms skin

299
00:13:03,279 --> 00:13:06,800
seed and glass we also

300
00:13:06,800 --> 00:13:09,360
we have also tested our algorithm on 90

301
00:13:09,360 --> 00:13:10,560
40 census

302
00:13:10,560 --> 00:13:12,800
data set which is a sample drawn

303
00:13:12,800 --> 00:13:14,959
uniformly at random from the u.s

304
00:13:14,959 --> 00:13:16,079
population

305
00:13:16,079 --> 00:13:19,120
from the 90 40 census uh

306
00:13:19,120 --> 00:13:21,839
we have built the classifier for four

307
00:13:21,839 --> 00:13:23,360
different states

308
00:13:23,360 --> 00:13:26,000
including the state of washington oregon

309
00:13:26,000 --> 00:13:29,279
wyoming and nevada

310
00:13:31,680 --> 00:13:34,959
and as a baseline comparison we have

311
00:13:34,959 --> 00:13:36,959
compared our algorithm with the most

312
00:13:36,959 --> 00:13:38,320
frequent class

313
00:13:38,320 --> 00:13:40,480
uh the non-private naive bayes

314
00:13:40,480 --> 00:13:41,680
classifier

315
00:13:41,680 --> 00:13:44,240
the differentially private naive bayes

316
00:13:44,240 --> 00:13:46,800
classifier using global sensitivity by

317
00:13:46,800 --> 00:13:49,760
vadiya at all and as noted by the

318
00:13:49,760 --> 00:13:50,959
reviewers

319
00:13:50,959 --> 00:13:53,680
with bunnenstein keys mean estimation

320
00:13:53,680 --> 00:13:56,239
algorithm

321
00:13:59,760 --> 00:14:03,519
okay so here you can see our results uh

322
00:14:03,519 --> 00:14:05,839
on the left hand side you see the

323
00:14:05,839 --> 00:14:08,240
results for the adult data set

324
00:14:08,240 --> 00:14:11,839
which on the x-axis we have

325
00:14:11,839 --> 00:14:14,839
uh reported the different values for

326
00:14:14,839 --> 00:14:18,399
epsilon and on the y-axis

327
00:14:18,399 --> 00:14:20,959
we have reported the accuracy percentage

328
00:14:20,959 --> 00:14:22,639
of the model

329
00:14:22,639 --> 00:14:25,360
in our pr in our paper we have provided

330
00:14:25,360 --> 00:14:27,199
approximate dp2

331
00:14:27,199 --> 00:14:29,839
which you can see our results in the

332
00:14:29,839 --> 00:14:31,600
figure

333
00:14:31,600 --> 00:14:35,279
so the solid lines uh are our results

334
00:14:35,279 --> 00:14:36,800
and the dashed lines are the other

335
00:14:36,800 --> 00:14:39,040
methods

336
00:14:39,040 --> 00:14:40,720
so on the left you can see the result

337
00:14:40,720 --> 00:14:42,399
for the adult data set on the right you

338
00:14:42,399 --> 00:14:45,839
can see the seed data set

339
00:14:46,560 --> 00:14:48,399
and here on the left side you see the

340
00:14:48,399 --> 00:14:50,480
result for the glass data set

341
00:14:50,480 --> 00:14:52,079
and on the right side you see the

342
00:14:52,079 --> 00:14:55,680
results for the skin data set

343
00:14:57,199 --> 00:15:00,320
so this is the 90 40s census

344
00:15:00,320 --> 00:15:03,360
which is a kind of larger data set

345
00:15:03,360 --> 00:15:07,199
as you can see our results are

346
00:15:07,199 --> 00:15:09,040
on most of the data sets follow the same

347
00:15:09,040 --> 00:15:10,880
pattern

348
00:15:10,880 --> 00:15:12,959
so on the left we have this result for

349
00:15:12,959 --> 00:15:14,079
the

350
00:15:14,079 --> 00:15:16,000
state of washington and on the right you

351
00:15:16,000 --> 00:15:19,839
see the result for the state of wyoming

352
00:15:20,399 --> 00:15:23,440
um again on the left side we have

353
00:15:23,440 --> 00:15:25,360
reported the accuracy percentage for the

354
00:15:25,360 --> 00:15:26,800
state of nevada

355
00:15:26,800 --> 00:15:28,800
and on the right we have shown our

356
00:15:28,800 --> 00:15:32,479
results for the state of oregon

357
00:15:34,079 --> 00:15:35,800
all right thank you so much for your

358
00:15:35,800 --> 00:15:38,800
time

