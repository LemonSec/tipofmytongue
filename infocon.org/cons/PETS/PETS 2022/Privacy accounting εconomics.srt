1
00:00:01,199 --> 00:00:03,599
my name is valentin hartman i'm a phd

2
00:00:03,600 --> 00:00:06,080
student at ubfl and today i will present

3
00:00:06,080 --> 00:00:07,359
our work on how to improve the

4
00:00:07,359 --> 00:00:08,960
composition of differentially private

5
00:00:08,960 --> 00:00:11,840
mechanisms by a posterior rebounds

6
00:00:11,840 --> 00:00:13,759
this is joint work with warsaw from the

7
00:00:13,759 --> 00:00:15,920
university of florida alexander from the

8
00:00:15,920 --> 00:00:17,359
institute of software the chinese

9
00:00:17,359 --> 00:00:22,080
academy of sciences and bob from epfl

10
00:00:22,320 --> 00:00:24,480
in classic differential privacy analysis

11
00:00:24,480 --> 00:00:26,320
the leakage of private information via

12
00:00:26,320 --> 00:00:28,320
the outputs of a mechanism is analyzed

13
00:00:28,320 --> 00:00:30,240
upfront before the mechanism has

14
00:00:30,240 --> 00:00:32,000
produced an output

15
00:00:32,000 --> 00:00:33,920
this results in a worst case guarantee

16
00:00:33,920 --> 00:00:35,280
over the possible outputs of the

17
00:00:35,280 --> 00:00:37,840
mechanism

18
00:00:37,920 --> 00:00:39,760
we have made the observation

19
00:00:39,760 --> 00:00:41,760
that for mechanisms from various domains

20
00:00:41,760 --> 00:00:43,600
some outputs need less information about

21
00:00:43,600 --> 00:00:45,920
the input database than others

22
00:00:45,920 --> 00:00:48,320
we propose output differential privacy

23
00:00:48,320 --> 00:00:49,840
the tool for joining the analyzing

24
00:00:49,840 --> 00:00:52,399
mechanism and its output are posteriori

25
00:00:52,399 --> 00:00:54,559
that is after the mechanism has been

26
00:00:54,559 --> 00:00:56,559
invoked

27
00:00:56,559 --> 00:00:58,960
this results in tighter privacy bonds

28
00:00:58,960 --> 00:01:00,879
and therefore better privacy utility

29
00:01:00,879 --> 00:01:03,440
tradeoffs

30
00:01:04,159 --> 00:01:05,600
most likely all of you know the

31
00:01:05,600 --> 00:01:07,760
definition of differential privacy but i

32
00:01:07,760 --> 00:01:09,760
will repeat it here

33
00:01:09,760 --> 00:01:11,840
a randomized mechanism m is epsilon

34
00:01:11,840 --> 00:01:14,320
delta differentially private if for all

35
00:01:14,320 --> 00:01:16,320
pairs of neighboring data with x and x

36
00:01:16,320 --> 00:01:18,880
prime and for all subsets s of the range

37
00:01:18,880 --> 00:01:20,960
of the mechanism the probability of

38
00:01:20,960 --> 00:01:23,759
producing the set s when invoking m on x

39
00:01:23,759 --> 00:01:25,759
is bounded by e to the epsilon times the

40
00:01:25,759 --> 00:01:28,400
probability of using s on a database x

41
00:01:28,400 --> 00:01:31,680
prime plus delta

42
00:01:31,680 --> 00:01:33,280
the part of this definition that we will

43
00:01:33,280 --> 00:01:35,920
focus on today the universal quantifier

44
00:01:35,920 --> 00:01:38,799
for the stats which the inequality holds

45
00:01:38,799 --> 00:01:40,720
by requiring the inequality to hold for

46
00:01:40,720 --> 00:01:42,960
all possible output sets one guarantees

47
00:01:42,960 --> 00:01:46,159
privacy even for the worst case outputs

48
00:01:46,159 --> 00:01:48,640
however when applying a dp mechanism in

49
00:01:48,640 --> 00:01:50,479
practice only a single output is

50
00:01:50,479 --> 00:01:52,320
produced and the leakage of private

51
00:01:52,320 --> 00:01:54,079
information via this output might be

52
00:01:54,079 --> 00:01:55,840
overestimated by the standard b

53
00:01:55,840 --> 00:01:57,439
guarantee

54
00:01:57,439 --> 00:02:00,880
let me give you a simple example

55
00:02:00,880 --> 00:02:03,280
consider the following mechanism

56
00:02:03,280 --> 00:02:05,520
first a coin is flipped

57
00:02:05,520 --> 00:02:07,680
if the coin comes up heads we return the

58
00:02:07,680 --> 00:02:09,840
value of a function f that is computed

59
00:02:09,840 --> 00:02:12,080
on the private database plus noise

60
00:02:12,080 --> 00:02:13,680
sampled from the laplace distribution

61
00:02:13,680 --> 00:02:16,239
with parameter one over epsilon

62
00:02:16,239 --> 00:02:18,720
we assume that f has sensitivity one

63
00:02:18,720 --> 00:02:20,720
thus returning the value of f plus the

64
00:02:20,720 --> 00:02:22,560
laplace noise ensures epsilon

65
00:02:22,560 --> 00:02:24,720
differential privacy

66
00:02:24,720 --> 00:02:26,959
if the coin comes up tails we return the

67
00:02:26,959 --> 00:02:29,120
fixed bottom symbol which is independent

68
00:02:29,120 --> 00:02:30,640
of the database

69
00:02:30,640 --> 00:02:32,720
thus in this case no private information

70
00:02:32,720 --> 00:02:34,800
is rebuilt

71
00:02:34,800 --> 00:02:36,959
the overall mechanism has a dp guarantee

72
00:02:36,959 --> 00:02:39,280
of epsilon but obviously this is an

73
00:02:39,280 --> 00:02:41,040
overestimation of the true leakage in

74
00:02:41,040 --> 00:02:44,560
the case where the coin comes up tables

75
00:02:44,560 --> 00:02:46,480
this is a toy example but let me give

76
00:02:46,480 --> 00:02:48,239
you a more interesting example that we

77
00:02:48,239 --> 00:02:51,200
analyze in our paper

78
00:02:51,200 --> 00:02:52,959
assume a data analyst that trains the

79
00:02:52,959 --> 00:02:54,800
logistic regression model p in a

80
00:02:54,800 --> 00:02:56,879
differentially private way

81
00:02:56,879 --> 00:02:58,319
after having trained the model they

82
00:02:58,319 --> 00:03:00,000
compute the error that this model makes

83
00:03:00,000 --> 00:03:02,000
on a held out test set

84
00:03:02,000 --> 00:03:04,000
if the error is sufficiently small the

85
00:03:04,000 --> 00:03:06,560
data analyst releases the model

86
00:03:06,560 --> 00:03:08,480
however if the error is too large for

87
00:03:08,480 --> 00:03:10,560
the intended application there is no use

88
00:03:10,560 --> 00:03:12,720
in reasonable model and the data analyst

89
00:03:12,720 --> 00:03:15,760
instead only releases the volume symbol

90
00:03:15,760 --> 00:03:18,319
intuitively and also analytically as we

91
00:03:18,319 --> 00:03:20,560
show on the paper much less information

92
00:03:20,560 --> 00:03:22,400
about the private database should be

93
00:03:22,400 --> 00:03:23,599
revealed

94
00:03:23,599 --> 00:03:25,280
when only the bottom symbol instead of

95
00:03:25,280 --> 00:03:28,640
the model parameters is released

96
00:03:29,440 --> 00:03:31,280
similar example is the proposed test

97
00:03:31,280 --> 00:03:33,920
release framework by dwark and lay

98
00:03:33,920 --> 00:03:37,040
the goal is to compute the statistic f

99
00:03:37,040 --> 00:03:39,200
in our paper we analyze the case where f

100
00:03:39,200 --> 00:03:41,280
is the interquartile range a measure of

101
00:03:41,280 --> 00:03:43,040
the spread of the data similar to the

102
00:03:43,040 --> 00:03:44,560
variance

103
00:03:44,560 --> 00:03:46,640
the post-test release makes use of the

104
00:03:46,640 --> 00:03:49,360
local sensitivity of f that is how much

105
00:03:49,360 --> 00:03:51,519
the value of f changes when one changes

106
00:03:51,519 --> 00:03:54,640
a single record in the current database

107
00:03:54,640 --> 00:03:56,239
the statistics considered in drawk's

108
00:03:56,239 --> 00:03:58,000
paper have the property that if the

109
00:03:58,000 --> 00:04:00,400
local sensitivity is high the statistics

110
00:04:00,400 --> 00:04:02,080
would not be robust enough and would

111
00:04:02,080 --> 00:04:06,159
that thus not be interesting to release

112
00:04:06,159 --> 00:04:07,840
the mechanism therefore proceeds by

113
00:04:07,840 --> 00:04:09,439
proposing an upper bound on the local

114
00:04:09,439 --> 00:04:11,200
sensitivity

115
00:04:11,200 --> 00:04:13,040
then checks in a differentially private

116
00:04:13,040 --> 00:04:15,920
way whether the actual local sensitivity

117
00:04:15,920 --> 00:04:18,160
lies below this bound

118
00:04:18,160 --> 00:04:20,639
this is the case noisy version of ffx is

119
00:04:20,639 --> 00:04:22,160
returned

120
00:04:22,160 --> 00:04:24,240
otherwise the bottom symbol is returned

121
00:04:24,240 --> 00:04:28,080
which reveals much less about the data

122
00:04:28,080 --> 00:04:30,080
now seen three examples of mechanisms

123
00:04:30,080 --> 00:04:31,520
where the actual leakage of private

124
00:04:31,520 --> 00:04:33,280
information depends on the mechanism's

125
00:04:33,280 --> 00:04:34,639
output

126
00:04:34,639 --> 00:04:36,479
but how do we make use of such an upper

127
00:04:36,479 --> 00:04:39,520
stereo analysis

128
00:04:40,479 --> 00:04:42,960
negative proposed to use this insight in

129
00:04:42,960 --> 00:04:44,960
applications where given utility

130
00:04:44,960 --> 00:04:46,960
necessarily needs to be achieved and the

131
00:04:46,960 --> 00:04:49,199
privacy guarantee is secondary

132
00:04:49,199 --> 00:04:51,120
in such a setting the parameters of the

133
00:04:51,120 --> 00:04:53,360
p mechanism can be chosen in such a way

134
00:04:53,360 --> 00:04:55,600
that the target utility is achieved

135
00:04:55,600 --> 00:04:57,280
and then the achieved privacy level is

136
00:04:57,280 --> 00:04:59,199
computed

137
00:04:59,199 --> 00:05:00,880
however this does not yield the strong

138
00:05:00,880 --> 00:05:03,360
rpo rebounds that we know from vp that

139
00:05:03,360 --> 00:05:05,039
are important in many privacy sensitive

140
00:05:05,039 --> 00:05:06,720
applications

141
00:05:06,720 --> 00:05:08,240
to achieve such strong privacy

142
00:05:08,240 --> 00:05:10,400
protection until now we have to consent

143
00:05:10,400 --> 00:05:12,000
ourselves with the conservative dp

144
00:05:12,000 --> 00:05:13,840
bounds that do not take into account the

145
00:05:13,840 --> 00:05:15,919
actually produced outputs and thus do

146
00:05:15,919 --> 00:05:17,520
not make use of potential privacy

147
00:05:17,520 --> 00:05:19,440
improvements

148
00:05:19,440 --> 00:05:21,360
we show on our paper that it's possible

149
00:05:21,360 --> 00:05:24,080
to achieve both the strong our priority

150
00:05:24,080 --> 00:05:26,479
privacy protection of bp and utility

151
00:05:26,479 --> 00:05:28,400
improvements from analyzing mechanism

152
00:05:28,400 --> 00:05:30,799
outputs

153
00:05:31,440 --> 00:05:33,360
for this we first need to formalize the

154
00:05:33,360 --> 00:05:35,039
examples that we have seen so far for

155
00:05:35,039 --> 00:05:36,800
mechanisms that exhibit different

156
00:05:36,800 --> 00:05:39,600
amounts of leakage for different outputs

157
00:05:39,600 --> 00:05:41,039
we define the concept of output

158
00:05:41,039 --> 00:05:43,199
differential pricing which applies to

159
00:05:43,199 --> 00:05:45,759
randomized mechanisms n

160
00:05:45,759 --> 00:05:47,360
we assume that there exists a partition

161
00:05:47,360 --> 00:05:49,680
p of the output set of a mechanism the

162
00:05:49,680 --> 00:05:51,840
value delta and the function e that

163
00:05:51,840 --> 00:05:53,919
decides an epsilon value to each set in

164
00:05:53,919 --> 00:05:56,080
the partition

165
00:05:56,080 --> 00:05:58,880
we then say that m fulfills p e delta

166
00:05:58,880 --> 00:06:01,199
output differential parallelism for all

167
00:06:01,199 --> 00:06:03,039
neighboring databases and for all output

168
00:06:03,039 --> 00:06:05,360
sets s an inequality similar to that of

169
00:06:05,360 --> 00:06:07,600
standard dp holes

170
00:06:07,600 --> 00:06:09,199
the difference is that instead of

171
00:06:09,199 --> 00:06:10,880
multiplying the probability on the right

172
00:06:10,880 --> 00:06:12,960
hand side of e to the epsilon for some

173
00:06:12,960 --> 00:06:15,440
global epsilon we split the probability

174
00:06:15,440 --> 00:06:17,680
up by intersecting s with the different

175
00:06:17,680 --> 00:06:19,919
sets in the partition p and multiply

176
00:06:19,919 --> 00:06:21,360
each probability but lead to the

177
00:06:21,360 --> 00:06:24,319
corresponding option

178
00:06:24,639 --> 00:06:26,319
to make this more concrete

179
00:06:26,319 --> 00:06:28,160
go back to our conflict example from the

180
00:06:28,160 --> 00:06:30,240
beginning the output could either be a

181
00:06:30,240 --> 00:06:32,080
real number generated by the laplace

182
00:06:32,080 --> 00:06:34,720
mechanism or the bottom symbol

183
00:06:34,720 --> 00:06:36,400
in the former case the leakage is

184
00:06:36,400 --> 00:06:38,319
epsilon whereas in the latter case there

185
00:06:38,319 --> 00:06:41,520
is no leakage of private information

186
00:06:41,520 --> 00:06:43,440
as the first set of the partition of the

187
00:06:43,440 --> 00:06:45,520
output space we can just choose the real

188
00:06:45,520 --> 00:06:48,000
numbers and as the second set the set

189
00:06:48,000 --> 00:06:51,280
containing the bottom symbol

190
00:06:51,360 --> 00:06:53,520
you can see quite easily that odp is a

191
00:06:53,520 --> 00:06:56,400
refinement of dp

192
00:06:56,400 --> 00:06:58,880
any mechanism that fulfills dp also

193
00:06:58,880 --> 00:07:01,599
fulfills odp where we simply take the

194
00:07:01,599 --> 00:07:03,759
entire output set of the mechanism as

195
00:07:03,759 --> 00:07:06,080
the only set in the partition

196
00:07:06,080 --> 00:07:08,400
furthermore any odp mechanism fulfills

197
00:07:08,400 --> 00:07:11,120
dp but epsilon is the supremum of all

198
00:07:11,120 --> 00:07:13,039
epsilon values for the different sets in

199
00:07:13,039 --> 00:07:14,479
the output partition

200
00:07:14,479 --> 00:07:17,680
at least the supremum is finite

201
00:07:17,680 --> 00:07:18,960
now that we have the definition of

202
00:07:18,960 --> 00:07:21,039
output differential privacy we can use

203
00:07:21,039 --> 00:07:22,800
it to improve the utility of dp

204
00:07:22,800 --> 00:07:25,440
mechanisms

205
00:07:26,240 --> 00:07:28,000
this is possible in a setting where we

206
00:07:28,000 --> 00:07:31,039
compose multiple mechanisms with a total

207
00:07:31,039 --> 00:07:33,520
privacy budget of epsilon t and delta t

208
00:07:33,520 --> 00:07:35,520
we want to spend this budget in multiple

209
00:07:35,520 --> 00:07:38,719
mechanism implications

210
00:07:41,440 --> 00:07:43,919
in each iteration we choose a new odp

211
00:07:43,919 --> 00:07:46,160
mechanism mi and yet to produce an

212
00:07:46,160 --> 00:07:48,240
output

213
00:07:48,240 --> 00:07:50,319
then check which set of the partition

214
00:07:50,319 --> 00:07:52,400
the produced output falls into and

215
00:07:52,400 --> 00:07:54,960
subtract the corresponding epsilon from

216
00:07:54,960 --> 00:07:57,360
the epsilon budget

217
00:07:57,360 --> 00:07:59,520
the coin flip example we thus subtract

218
00:07:59,520 --> 00:08:01,360
nothing from the epsilon budget if the

219
00:08:01,360 --> 00:08:03,599
output is the bottom symbol

220
00:08:03,599 --> 00:08:05,440
contrast to that in classic dp

221
00:08:05,440 --> 00:08:07,680
composition we would always subtract the

222
00:08:07,680 --> 00:08:09,360
epsilon corresponding to the worst case

223
00:08:09,360 --> 00:08:11,680
output which is the supremum over all

224
00:08:11,680 --> 00:08:13,919
output specific epsilons

225
00:08:13,919 --> 00:08:15,360
this means that

226
00:08:15,360 --> 00:08:17,280
depending on the outputs produced we can

227
00:08:17,280 --> 00:08:19,199
save epsilon budget

228
00:08:19,199 --> 00:08:21,199
this budget can either be used to invoke

229
00:08:21,199 --> 00:08:23,360
more mechanisms or to reduce the amount

230
00:08:23,360 --> 00:08:25,039
of noise required to edit and

231
00:08:25,039 --> 00:08:29,120
subsequently invoke mechanisms

232
00:08:29,759 --> 00:08:31,520
an example for the letter applications

233
00:08:31,520 --> 00:08:33,360
is vast vector technique

234
00:08:33,360 --> 00:08:35,360
this dp mechanism is applied to sparse

235
00:08:35,360 --> 00:08:38,399
vectors that have few large entries

236
00:08:38,399 --> 00:08:40,799
the mechanism works in two steps

237
00:08:40,799 --> 00:08:42,640
first it identifies the indices of the

238
00:08:42,640 --> 00:08:44,880
large entries in the vector

239
00:08:44,880 --> 00:08:46,880
and then it releases the values of

240
00:08:46,880 --> 00:08:49,519
either noise

241
00:08:49,519 --> 00:08:51,680
as we show on our paper the first step

242
00:08:51,680 --> 00:08:53,519
that searches for the large entries

243
00:08:53,519 --> 00:08:55,440
leaks less private information and the

244
00:08:55,440 --> 00:08:57,120
number of protected large entries is

245
00:08:57,120 --> 00:08:59,440
smaller than in the worst case

246
00:08:59,440 --> 00:09:01,519
this in such cases can save privacy

247
00:09:01,519 --> 00:09:03,279
budget and use it for reducing the

248
00:09:03,279 --> 00:09:05,040
amount of noise that is added to the

249
00:09:05,040 --> 00:09:08,240
entries in the second step

250
00:09:08,240 --> 00:09:10,320
the plot shows this for the example of a

251
00:09:10,320 --> 00:09:12,399
vector of length 100.

252
00:09:12,399 --> 00:09:14,000
you can see that for smaller numbers of

253
00:09:14,000 --> 00:09:16,000
large entries the expected noise that

254
00:09:16,000 --> 00:09:18,080
needs to be added was an odp analysis

255
00:09:18,080 --> 00:09:19,839
substantially smaller than with a

256
00:09:19,839 --> 00:09:23,480
standard dp analysis

257
00:09:23,680 --> 00:09:25,680
this concludes my talk

258
00:09:25,680 --> 00:09:27,440
i've introduced output differential

259
00:09:27,440 --> 00:09:29,600
privacy the tool for increasing the

260
00:09:29,600 --> 00:09:31,680
utility of privacy preserving mechanisms

261
00:09:31,680 --> 00:09:33,440
without weakening the differential

262
00:09:33,440 --> 00:09:35,519
privacy guarantee

263
00:09:35,519 --> 00:09:37,120
this talk i've given three examples of

264
00:09:37,120 --> 00:09:38,880
mechanisms to which our analysis tool

265
00:09:38,880 --> 00:09:40,240
can be applied

266
00:09:40,240 --> 00:09:42,160
now paper you'll find one more such

267
00:09:42,160 --> 00:09:43,839
example

268
00:09:43,839 --> 00:09:45,680
we've formally verified the correctness

269
00:09:45,680 --> 00:09:47,519
of our composition theorem in the proof

270
00:09:47,519 --> 00:09:48,880
assistant lien

271
00:09:48,880 --> 00:09:50,640
you can find this formalization and the

272
00:09:50,640 --> 00:09:52,160
code for generating the plots in the

273
00:09:52,160 --> 00:09:54,640
paper at the url at the bottom of the

274
00:09:54,640 --> 00:09:56,160
slide

275
00:09:56,160 --> 00:09:57,839
if you want to get in touch you can send

276
00:09:57,839 --> 00:10:00,240
me an email at valentine.hardman

277
00:10:00,240 --> 00:10:03,399
at ebfl.ch

278
00:10:04,160 --> 00:10:05,279
finally

279
00:10:05,279 --> 00:10:06,880
this has been my first submission to

280
00:10:06,880 --> 00:10:07,839
pets

281
00:10:07,839 --> 00:10:09,440
i would like to give a huge thanks to

282
00:10:09,440 --> 00:10:11,600
the anonymous reviewers and to the meter

283
00:10:11,600 --> 00:10:13,519
reviewer we have very detailed and very

284
00:10:13,519 --> 00:10:15,839
useful feedback that has helped improve

285
00:10:15,839 --> 00:10:19,399
our paper significantly

