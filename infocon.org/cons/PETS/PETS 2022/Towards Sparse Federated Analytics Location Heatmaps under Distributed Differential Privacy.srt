1
00:00:00,240 --> 00:00:02,639
hi my name is eugene bagdasarian and

2
00:00:02,639 --> 00:00:05,200
together with my hosts at google peter

3
00:00:05,200 --> 00:00:08,240
stefan adria kelly and marco and my

4
00:00:08,240 --> 00:00:10,480
advisor deborah we're going to talk

5
00:00:10,480 --> 00:00:12,559
about iterated analytics

6
00:00:12,559 --> 00:00:15,040
our system for location heat maps under

7
00:00:15,040 --> 00:00:16,560
distributed differential privacy and

8
00:00:16,560 --> 00:00:18,800
secure aggregation

9
00:00:18,800 --> 00:00:21,520
aggregated location data benefits

10
00:00:21,520 --> 00:00:24,160
variety of different services

11
00:00:24,160 --> 00:00:25,920
ranging from public health applications

12
00:00:25,920 --> 00:00:28,320
such as monitoring the disease spread to

13
00:00:28,320 --> 00:00:30,800
traffic jams and so on

14
00:00:30,800 --> 00:00:33,040
however releasing this data requires

15
00:00:33,040 --> 00:00:35,200
certain privacy protections supplied

16
00:00:35,200 --> 00:00:36,800
such that

17
00:00:36,800 --> 00:00:38,800
public won't be able to figure out

18
00:00:38,800 --> 00:00:41,360
individual user locations

19
00:00:41,360 --> 00:00:42,399
and

20
00:00:42,399 --> 00:00:45,120
reverse engineering map the data should

21
00:00:45,120 --> 00:00:47,920
be anonymized and

22
00:00:47,920 --> 00:00:50,079
the allocations mix with others and also

23
00:00:50,079 --> 00:00:51,520
certain differential

24
00:00:51,520 --> 00:00:52,719
privacy

25
00:00:52,719 --> 00:00:55,440
guarantees applied to the resulting set

26
00:00:55,440 --> 00:00:57,199
however

27
00:00:57,199 --> 00:00:59,440
applying and modifying

28
00:00:59,440 --> 00:01:00,960
the map and applying this privacy

29
00:01:00,960 --> 00:01:02,800
techniques would require a trusted

30
00:01:02,800 --> 00:01:03,920
server

31
00:01:03,920 --> 00:01:06,240
where the server knows the locations of

32
00:01:06,240 --> 00:01:09,040
the user but performs this privacy

33
00:01:09,040 --> 00:01:10,640
modifications to read it before

34
00:01:10,640 --> 00:01:12,960
releasing it to public

35
00:01:12,960 --> 00:01:14,400
another way

36
00:01:14,400 --> 00:01:17,040
to not

37
00:01:17,040 --> 00:01:18,960
share the sensitive information with the

38
00:01:18,960 --> 00:01:20,720
server is to use local differential

39
00:01:20,720 --> 00:01:22,880
privacy for example if the user wants to

40
00:01:22,880 --> 00:01:25,200
report where they are located in one of

41
00:01:25,200 --> 00:01:26,640
the four regions

42
00:01:26,640 --> 00:01:29,200
they might contribute their own data but

43
00:01:29,200 --> 00:01:31,119
then add significant amount of noise

44
00:01:31,119 --> 00:01:33,360
such that server will not be able to

45
00:01:33,360 --> 00:01:36,079
figure out where the user was

46
00:01:36,079 --> 00:01:38,400
and unsurprisingly this results in a

47
00:01:38,400 --> 00:01:39,360
highly

48
00:01:39,360 --> 00:01:42,000
noisy maps that might not be

49
00:01:42,000 --> 00:01:44,159
very accurate or useful for it for the

50
00:01:44,159 --> 00:01:46,479
services

51
00:01:46,479 --> 00:01:48,720
instead we propose to use distributed

52
00:01:48,720 --> 00:01:51,119
differential privacy where we rely on

53
00:01:51,119 --> 00:01:52,960
technique called secure aggregation that

54
00:01:52,960 --> 00:01:56,880
uses multi-party computation to securely

55
00:01:56,880 --> 00:01:59,040
compute a sum of

56
00:01:59,040 --> 00:02:01,119
user contributions

57
00:02:01,119 --> 00:02:04,240
and only present this sum to the server

58
00:02:04,240 --> 00:02:07,439
in this case users still add noise to

59
00:02:07,439 --> 00:02:09,598
their data but significantly smaller

60
00:02:09,598 --> 00:02:12,239
amount of noise however the sum of the

61
00:02:12,239 --> 00:02:14,800
noise will present central differential

62
00:02:14,800 --> 00:02:16,879
privacy guarantee available to the

63
00:02:16,879 --> 00:02:18,640
server and then later that can be

64
00:02:18,640 --> 00:02:21,200
released to the public

65
00:02:21,200 --> 00:02:23,120
if we look uh

66
00:02:23,120 --> 00:02:25,040
more in more details

67
00:02:25,040 --> 00:02:27,840
uh we can rely on hierarchical histogram

68
00:02:27,840 --> 00:02:29,040
algorithm

69
00:02:29,040 --> 00:02:31,519
that looks at the at the map and this is

70
00:02:31,519 --> 00:02:34,879
the map from new york times article

71
00:02:34,879 --> 00:02:37,519
of manhattan and location data so at the

72
00:02:37,519 --> 00:02:38,640
first time

73
00:02:38,640 --> 00:02:40,239
users uh

74
00:02:40,239 --> 00:02:41,519
select

75
00:02:41,519 --> 00:02:44,480
from four regions only so we built a

76
00:02:44,480 --> 00:02:48,000
quad tree with only four nodes and users

77
00:02:48,000 --> 00:02:50,720
need to encode their location in

78
00:02:50,720 --> 00:02:52,640
to to figure out where exactly they are

79
00:02:52,640 --> 00:02:54,319
located

80
00:02:54,319 --> 00:02:57,680
and report so user one reports there in

81
00:02:57,680 --> 00:03:01,680
one region add noise user two

82
00:03:01,680 --> 00:03:04,640
also reports and user serious report

83
00:03:04,640 --> 00:03:06,000
then once

84
00:03:06,000 --> 00:03:08,879
the map is summed up the

85
00:03:08,879 --> 00:03:10,800
noise is enough to provide central

86
00:03:10,800 --> 00:03:12,720
differential privacy

87
00:03:12,720 --> 00:03:15,680
and only this sound will be visible to

88
00:03:15,680 --> 00:03:17,440
the server

89
00:03:17,440 --> 00:03:20,400
so if we uh look at the

90
00:03:20,400 --> 00:03:23,760
the root node we can uh

91
00:03:23,760 --> 00:03:26,159
count the numbers of uh

92
00:03:26,159 --> 00:03:27,840
points in each region and then make the

93
00:03:27,840 --> 00:03:30,239
decision whether we want to split the

94
00:03:30,239 --> 00:03:32,959
node and continue further such that if

95
00:03:32,959 --> 00:03:33,599
we

96
00:03:33,599 --> 00:03:35,040
receive

97
00:03:35,040 --> 00:03:36,720
those contributions we for example

98
00:03:36,720 --> 00:03:38,879
decide to split all the nodes

99
00:03:38,879 --> 00:03:41,280
and

100
00:03:41,460 --> 00:03:43,360
[Music]

101
00:03:43,360 --> 00:03:45,280
split it again

102
00:03:45,280 --> 00:03:48,080
and then for the second query we again

103
00:03:48,080 --> 00:03:50,560
collect all the points uh maybe

104
00:03:50,560 --> 00:03:52,000
different from the different people but

105
00:03:52,000 --> 00:03:54,400
also applying a significant amount of

106
00:03:54,400 --> 00:03:55,280
noise

107
00:03:55,280 --> 00:03:58,560
and then we make the decision again

108
00:03:58,560 --> 00:03:59,680
and

109
00:03:59,680 --> 00:04:00,400
we

110
00:04:00,400 --> 00:04:02,400
uh collect

111
00:04:02,400 --> 00:04:04,879
the location data again

112
00:04:04,879 --> 00:04:07,519
and then we make the decision again and

113
00:04:07,519 --> 00:04:10,400
so on and so on until we

114
00:04:10,400 --> 00:04:11,680
end up with

115
00:04:11,680 --> 00:04:14,879
a relatively accurate representation of

116
00:04:14,879 --> 00:04:18,719
manhattan and with a

117
00:04:19,040 --> 00:04:22,240
high quality grid

118
00:04:22,240 --> 00:04:25,600
there are a few challenges that

119
00:04:25,600 --> 00:04:28,320
exist in this algorithm that we address

120
00:04:28,320 --> 00:04:31,120
in our work first one is how to select a

121
00:04:31,120 --> 00:04:34,479
threshold on deciding when should we

122
00:04:34,479 --> 00:04:35,759
expand

123
00:04:35,759 --> 00:04:37,759
or collapse the node

124
00:04:37,759 --> 00:04:40,240
in expanding uh we

125
00:04:40,240 --> 00:04:43,120
pick an adaptive threshold the main

126
00:04:43,120 --> 00:04:44,639
motivation why we can adapt the

127
00:04:44,639 --> 00:04:46,400
threshold is that

128
00:04:46,400 --> 00:04:49,360
the server selects uh and knows the

129
00:04:49,360 --> 00:04:51,600
amount of noise that will be added right

130
00:04:51,600 --> 00:04:53,600
because differential privacy

131
00:04:53,600 --> 00:04:54,960
budget

132
00:04:54,960 --> 00:04:58,400
specifies the exact epson we can compute

133
00:04:58,400 --> 00:05:00,720
uh standard noise deviation and can just

134
00:05:00,720 --> 00:05:03,600
set for the specific noise the threshold

135
00:05:03,600 --> 00:05:05,919
to be above two standard deviations of

136
00:05:05,919 --> 00:05:07,440
this noise

137
00:05:07,440 --> 00:05:10,160
in this case if we obtain a value above

138
00:05:10,160 --> 00:05:13,280
this noise above this threshold it would

139
00:05:13,280 --> 00:05:16,400
mean that we have

140
00:05:16,400 --> 00:05:18,960
for sure

141
00:05:18,960 --> 00:05:20,870
some people located in this region

142
00:05:20,870 --> 00:05:22,320
[Music]

143
00:05:22,320 --> 00:05:25,360
another challenge is once even we know

144
00:05:25,360 --> 00:05:27,280
the threshold we need to figure out how

145
00:05:27,280 --> 00:05:30,639
much privacy budget was spent across the

146
00:05:30,639 --> 00:05:32,479
sub queries

147
00:05:32,479 --> 00:05:34,639
we could spend equal amount

148
00:05:34,639 --> 00:05:35,440
of

149
00:05:35,440 --> 00:05:37,520
budget for example we have a budget of

150
00:05:37,520 --> 00:05:39,120
one we can

151
00:05:39,120 --> 00:05:42,720
spend 0.1 for 10 sub queries however we

152
00:05:42,720 --> 00:05:43,680
have

153
00:05:43,680 --> 00:05:45,520
you can observe that

154
00:05:45,520 --> 00:05:46,240
in

155
00:05:46,240 --> 00:05:47,360
first

156
00:05:47,360 --> 00:05:49,680
regions in first sub query there were

157
00:05:49,680 --> 00:05:51,280
only four regions

158
00:05:51,280 --> 00:05:53,840
in four regions we essentially have

159
00:05:53,840 --> 00:05:56,160
higher user per cell count

160
00:05:56,160 --> 00:05:57,919
and it would result even if we had a lot

161
00:05:57,919 --> 00:06:02,479
of noise it will still allow us to

162
00:06:02,479 --> 00:06:04,800
distinguish the signal from noise

163
00:06:04,800 --> 00:06:06,880
therefore we can raise the amount of

164
00:06:06,880 --> 00:06:09,360
noise and and therefore decrease the

165
00:06:09,360 --> 00:06:12,000
privacy budget and

166
00:06:12,000 --> 00:06:14,160
increase the threshold

167
00:06:14,160 --> 00:06:17,919
in on the other side once we

168
00:06:17,919 --> 00:06:20,560
obtain a more fine-grained grit

169
00:06:20,560 --> 00:06:21,840
and

170
00:06:21,840 --> 00:06:23,919
a lot of noise might not be

171
00:06:23,919 --> 00:06:25,520
very beneficial because we will

172
00:06:25,520 --> 00:06:26,800
essentially noise out all the

173
00:06:26,800 --> 00:06:28,880
contributions so we would want to

174
00:06:28,880 --> 00:06:31,280
decrease the noise so we increase the

175
00:06:31,280 --> 00:06:32,560
budget

176
00:06:32,560 --> 00:06:34,479
and decrease the threshold so then we

177
00:06:34,479 --> 00:06:36,319
can get the most accurate

178
00:06:36,319 --> 00:06:38,080
numbers

179
00:06:38,080 --> 00:06:39,759
and lastly

180
00:06:39,759 --> 00:06:42,880
since we run subcurious multiple times

181
00:06:42,880 --> 00:06:44,319
there might be different users

182
00:06:44,319 --> 00:06:45,919
participating it might be different

183
00:06:45,919 --> 00:06:48,880
times for time frames and

184
00:06:48,880 --> 00:06:52,639
we track all the regions across all the

185
00:06:52,639 --> 00:06:55,039
sub queries so we always query the whole

186
00:06:55,039 --> 00:06:57,520
map and because the user always can

187
00:06:57,520 --> 00:06:59,919
report where they are whether on the

188
00:06:59,919 --> 00:07:02,240
more fine-grained or coarse-grained

189
00:07:02,240 --> 00:07:04,639
regions and then we can adaptively

190
00:07:04,639 --> 00:07:06,880
decide whether we want to collapse

191
00:07:06,880 --> 00:07:08,240
certain nodes

192
00:07:08,240 --> 00:07:10,639
or expand those nodes so then we can

193
00:07:10,639 --> 00:07:12,720
have more up-to-date map

194
00:07:12,720 --> 00:07:14,479
every time

195
00:07:14,479 --> 00:07:16,319
all right so here's an example of how we

196
00:07:16,319 --> 00:07:19,520
uh use our algorithm assuming uh at a

197
00:07:19,520 --> 00:07:22,479
certain subquery k we spent epsilon

198
00:07:22,479 --> 00:07:25,680
budget of 0.1 and obtained this

199
00:07:25,680 --> 00:07:26,720
arm up

200
00:07:26,720 --> 00:07:29,280
we then analyze the amount of noise

201
00:07:29,280 --> 00:07:32,400
added and can decide on the collapsing

202
00:07:32,400 --> 00:07:34,400
and splitting threshold

203
00:07:34,400 --> 00:07:35,759
and we see

204
00:07:35,759 --> 00:07:39,039
that for example top left corner has

205
00:07:39,039 --> 00:07:41,440
values below 10 and we can collapse

206
00:07:41,440 --> 00:07:43,919
those regions and bottom right corner

207
00:07:43,919 --> 00:07:47,759
has 137 and we can expand the region

208
00:07:47,759 --> 00:07:50,800
then we run a new query with a privacy

209
00:07:50,800 --> 00:07:52,800
budget significantly higher than the

210
00:07:52,800 --> 00:07:55,520
previous one and we obtain new values

211
00:07:55,520 --> 00:07:57,039
and you see that these values might be

212
00:07:57,039 --> 00:07:59,440
different from the original values

213
00:07:59,440 --> 00:08:00,479
and

214
00:08:00,479 --> 00:08:02,080
mostly because

215
00:08:02,080 --> 00:08:04,639
there is less noise added or you know

216
00:08:04,639 --> 00:08:06,400
the distribution slightly changed

217
00:08:06,400 --> 00:08:08,000
between the queries

218
00:08:08,000 --> 00:08:10,240
but it uh

219
00:08:10,240 --> 00:08:11,440
presents more

220
00:08:11,440 --> 00:08:14,000
accurate picture because there is uh

221
00:08:14,000 --> 00:08:16,319
the privacy budget is higher

222
00:08:16,319 --> 00:08:18,479
all right uh to

223
00:08:18,479 --> 00:08:21,360
demonstrate you uh the full algorithm

224
00:08:21,360 --> 00:08:22,720
run so we

225
00:08:22,720 --> 00:08:25,199
use the same map with hundred thousand

226
00:08:25,199 --> 00:08:28,160
users and the total budget of one

227
00:08:28,160 --> 00:08:31,280
and here you see that we start with

228
00:08:31,280 --> 00:08:33,519
just only four regions and we spend a

229
00:08:33,519 --> 00:08:35,719
fraction of the privacy budget

230
00:08:35,719 --> 00:08:37,440
0.036

231
00:08:37,440 --> 00:08:40,958
and the split threshold was around 2500

232
00:08:40,958 --> 00:08:42,640
which is a pretty big

233
00:08:42,640 --> 00:08:44,720
we still are able to split all the

234
00:08:44,720 --> 00:08:47,200
regions in the

235
00:08:47,200 --> 00:08:49,440
in the map and then we continue slightly

236
00:08:49,440 --> 00:08:50,959
increasing the budget

237
00:08:50,959 --> 00:08:52,640
and decreasing the threshold and then we

238
00:08:52,640 --> 00:08:55,680
continue more and more and finally we

239
00:08:55,680 --> 00:08:58,880
spend 0.7 budget and get

240
00:08:58,880 --> 00:08:59,760
a

241
00:08:59,760 --> 00:09:01,760
very accurate map of

242
00:09:01,760 --> 00:09:04,319
manhattan

243
00:09:04,959 --> 00:09:07,519
all right and to

244
00:09:07,519 --> 00:09:10,480
compare our results with

245
00:09:10,480 --> 00:09:12,560
some baseline so we

246
00:09:12,560 --> 00:09:15,600
measure mean square error between

247
00:09:15,600 --> 00:09:17,360
original map and

248
00:09:17,360 --> 00:09:19,600
the mod that we obtained and we measured

249
00:09:19,600 --> 00:09:22,640
the total communication cost per user

250
00:09:22,640 --> 00:09:24,320
we first start with the non-private

251
00:09:24,320 --> 00:09:27,279
baseline in the non-private baseline you

252
00:09:27,279 --> 00:09:28,959
essentially can

253
00:09:28,959 --> 00:09:32,720
submit two coordinates x and y which is

254
00:09:32,720 --> 00:09:35,279
means that the communication cost is two

255
00:09:35,279 --> 00:09:38,800
and mean square error is around 6.5

256
00:09:38,800 --> 00:09:40,959
which is the result of the sampling

257
00:09:40,959 --> 00:09:42,640
error since we only have hundred

258
00:09:42,640 --> 00:09:45,839
thousand users and the map

259
00:09:45,839 --> 00:09:47,440
we adopt

260
00:09:47,440 --> 00:09:48,480
from the

261
00:09:48,480 --> 00:09:50,800
from the image uh

262
00:09:50,800 --> 00:09:53,519
as having around 50 million so we simply

263
00:09:53,519 --> 00:09:57,360
count uh luminosity as a as a as a user

264
00:09:57,360 --> 00:09:59,519
um on the map

265
00:09:59,519 --> 00:10:01,760
we also compare it to a couple of more

266
00:10:01,760 --> 00:10:04,480
baselines so we first start with the

267
00:10:04,480 --> 00:10:05,519
flat

268
00:10:05,519 --> 00:10:08,000
baseline in this case we split

269
00:10:08,000 --> 00:10:08,959
the map

270
00:10:08,959 --> 00:10:11,120
in very fine grained regions around 10

271
00:10:11,120 --> 00:10:13,440
24 to 10 24 which significantly

272
00:10:13,440 --> 00:10:15,600
increases the communication cost and

273
00:10:15,600 --> 00:10:18,240
since the map is very fine-grained lots

274
00:10:18,240 --> 00:10:20,880
of noise is applied so we get really

275
00:10:20,880 --> 00:10:22,800
not accurate result

276
00:10:22,800 --> 00:10:24,320
we can

277
00:10:24,320 --> 00:10:27,360
similarly use count mean sketches to

278
00:10:27,360 --> 00:10:29,360
reduce the amount of communication it

279
00:10:29,360 --> 00:10:31,200
slightly improves the

280
00:10:31,200 --> 00:10:32,880
performance

281
00:10:32,880 --> 00:10:35,040
we also compare it to some a couple of

282
00:10:35,040 --> 00:10:37,360
other works using adaptive grid

283
00:10:37,360 --> 00:10:38,959
decompositions

284
00:10:38,959 --> 00:10:41,440
special decomposition

285
00:10:41,440 --> 00:10:42,959
and

286
00:10:42,959 --> 00:10:46,560
both cases improve the results

287
00:10:46,560 --> 00:10:48,800
and hierarchical histogram is the naive

288
00:10:48,800 --> 00:10:51,600
implementation without adaptive

289
00:10:51,600 --> 00:10:53,519
threshold and scheduling

290
00:10:53,519 --> 00:10:55,760
in our case we're able to significantly

291
00:10:55,760 --> 00:10:58,320
reduce the amount of communication

292
00:10:58,320 --> 00:11:01,360
and achieve a very close to non-private

293
00:11:01,360 --> 00:11:03,230
baseline error

294
00:11:03,230 --> 00:11:04,959
[Music]

295
00:11:04,959 --> 00:11:07,279
we also experimented with our algorithm

296
00:11:07,279 --> 00:11:10,000
on other data sets we used humanitarian

297
00:11:10,000 --> 00:11:12,959
exchange data set and built this maps

298
00:11:12,959 --> 00:11:15,839
for mayota and lagos nigeria and you can

299
00:11:15,839 --> 00:11:18,399
see there also relatively accurately

300
00:11:18,399 --> 00:11:22,560
represent the underlying distributions

301
00:11:22,560 --> 00:11:23,920
finally

302
00:11:23,920 --> 00:11:24,640
we

303
00:11:24,640 --> 00:11:27,040
wanted to sum up our contributions so we

304
00:11:27,040 --> 00:11:29,279
designed a scalable and distributed

305
00:11:29,279 --> 00:11:30,800
differentially private

306
00:11:30,800 --> 00:11:34,240
approach that uses secure aggregation

307
00:11:34,240 --> 00:11:37,120
in our experiments we use this designed

308
00:11:37,120 --> 00:11:39,440
adaptive algorithm

309
00:11:39,440 --> 00:11:41,760
can adapt for unknown and dynamic

310
00:11:41,760 --> 00:11:45,760
distributions it also works with dropout

311
00:11:45,760 --> 00:11:47,360
both provide secure aggregation

312
00:11:47,360 --> 00:11:48,720
guarantees and differentiate privacy

313
00:11:48,720 --> 00:11:50,000
agreements

314
00:11:50,000 --> 00:11:52,240
and we designed this adaptive mechanism

315
00:11:52,240 --> 00:11:54,160
for privacy budget schedule and dynamic

316
00:11:54,160 --> 00:11:57,360
threshold and experimented for on public

317
00:11:57,360 --> 00:11:58,959
geospatial data

318
00:11:58,959 --> 00:12:02,239
thank you so much

