1
00:00:00,240 --> 00:00:02,879
hi i'm gabriel and i'll be presenting my

2
00:00:02,879 --> 00:00:05,120
team's work on the privacy assessment of

3
00:00:05,120 --> 00:00:06,879
very large data sets

4
00:00:06,879 --> 00:00:09,519
in-app is the federal government agency

5
00:00:09,519 --> 00:00:11,840
in brazil responsible for the country's

6
00:00:11,840 --> 00:00:14,400
educational censuses in brazil a

7
00:00:14,400 --> 00:00:17,840
transparency law from 2011 established a

8
00:00:17,840 --> 00:00:19,840
tradition of governmental data

9
00:00:19,840 --> 00:00:23,600
transparency but since 2018 the

10
00:00:23,600 --> 00:00:25,760
enactment of a new privacy law

11
00:00:25,760 --> 00:00:27,599
restricted the release of data on

12
00:00:27,599 --> 00:00:30,640
individuals as a data curator inapp has

13
00:00:30,640 --> 00:00:32,640
now to carefully balance those two

14
00:00:32,640 --> 00:00:33,920
principles

15
00:00:33,920 --> 00:00:36,320
and for doing so it is crucial to

16
00:00:36,320 --> 00:00:38,320
identify meaningful threats

17
00:00:38,320 --> 00:00:39,840
in order to do so

18
00:00:39,840 --> 00:00:41,680
we were tasked with providing a

19
00:00:41,680 --> 00:00:44,320
theoretically solid solution that could

20
00:00:44,320 --> 00:00:47,120
be at the same time flexible scalable

21
00:00:47,120 --> 00:00:48,719
and explainable

22
00:00:48,719 --> 00:00:51,199
our contributions include a

23
00:00:51,199 --> 00:00:54,320
factorization of privacy attack models a

24
00:00:54,320 --> 00:00:56,239
new way of applying the quantitative

25
00:00:56,239 --> 00:00:58,559
information flow framework in an

26
00:00:58,559 --> 00:01:00,879
illustration of both flexibility and

27
00:01:00,879 --> 00:01:03,280
scalability of the quick framework on

28
00:01:03,280 --> 00:01:06,080
the literature one can find several

29
00:01:06,080 --> 00:01:08,960
privacy attack models usually classified

30
00:01:08,960 --> 00:01:10,720
according to the type of information

31
00:01:10,720 --> 00:01:13,360
solved as membership inference

32
00:01:13,360 --> 00:01:16,479
identification or attribute inference

33
00:01:16,479 --> 00:01:18,640
identification in particular

34
00:01:18,640 --> 00:01:21,520
is usually also classified according to

35
00:01:21,520 --> 00:01:24,479
the advisor's prior knowledge and target

36
00:01:24,479 --> 00:01:27,759
as the attack models known as prosecutor

37
00:01:27,759 --> 00:01:30,400
journalist and marketeer

38
00:01:30,400 --> 00:01:33,280
instead we propose a new classification

39
00:01:33,280 --> 00:01:35,600
based on three orthogonal access

40
00:01:35,600 --> 00:01:38,079
one for the information sought by the

41
00:01:38,079 --> 00:01:39,280
anniversary

42
00:01:39,280 --> 00:01:41,759
another for the adversary's target and a

43
00:01:41,759 --> 00:01:44,399
third access for the adversary's access

44
00:01:44,399 --> 00:01:47,280
to datasets given our orthogonal

45
00:01:47,280 --> 00:01:50,079
classification we devised 12 distinct

46
00:01:50,079 --> 00:01:51,680
privacy attacks

47
00:01:51,680 --> 00:01:53,360
including those already found on the

48
00:01:53,360 --> 00:01:54,720
literature

49
00:01:54,720 --> 00:01:57,759
more interesting our factorization

50
00:01:57,759 --> 00:02:00,799
covers new scenarios such as attributes

51
00:02:00,799 --> 00:02:03,119
attribute inference attacks all

52
00:02:03,119 --> 00:02:05,520
institutional collections of data sets

53
00:02:05,520 --> 00:02:07,520
which generalize all the others i will

54
00:02:07,520 --> 00:02:09,440
now briefly introduce the quantitative

55
00:02:09,440 --> 00:02:12,000
information flow framework followed by

56
00:02:12,000 --> 00:02:13,520
an example

57
00:02:13,520 --> 00:02:15,520
one of the main advantages of the equip

58
00:02:15,520 --> 00:02:17,680
framework is that it separates into

59
00:02:17,680 --> 00:02:20,160
three distinct entities the adversary's

60
00:02:20,160 --> 00:02:22,160
knowledge which is modeled as

61
00:02:22,160 --> 00:02:25,120
probabilistic distribution on the secret

62
00:02:25,120 --> 00:02:27,920
values and usually called prior

63
00:02:27,920 --> 00:02:30,400
the description of the actual leakage of

64
00:02:30,400 --> 00:02:32,879
information being exploited which is

65
00:02:32,879 --> 00:02:35,760
modeled as by asian reasoning to produce

66
00:02:35,760 --> 00:02:37,680
a hyper distribution from the

67
00:02:37,680 --> 00:02:39,840
interaction between the channel that

68
00:02:39,840 --> 00:02:42,800
describes the system and the prior

69
00:02:42,800 --> 00:02:44,480
and the anniversary's intentions and

70
00:02:44,480 --> 00:02:46,959
capabilities which are modeled as a game

71
00:02:46,959 --> 00:02:49,840
function as an example assume our

72
00:02:49,840 --> 00:02:52,000
adversary is about to meet someone for

73
00:02:52,000 --> 00:02:54,160
the first time and is trying to guess

74
00:02:54,160 --> 00:02:56,959
the native language of the person

75
00:02:56,959 --> 00:02:59,040
the adversary assumes the person is

76
00:02:59,040 --> 00:03:02,959
equally likely to be any one of the four

77
00:03:02,959 --> 00:03:05,519
in the data set shown here which is

78
00:03:05,519 --> 00:03:07,599
accessible to anyone

79
00:03:07,599 --> 00:03:09,760
we can compute from the data set the

80
00:03:09,760 --> 00:03:12,319
prior own language which corresponds to

81
00:03:12,319 --> 00:03:14,000
the anniversary's knowledge before

82
00:03:14,000 --> 00:03:15,760
seeing the person

83
00:03:15,760 --> 00:03:18,239
clearly the adversary's best guess

84
00:03:18,239 --> 00:03:21,040
before seeing the person with german

85
00:03:21,040 --> 00:03:23,040
but if the anniversary seal the person

86
00:03:23,040 --> 00:03:25,920
before guessing then both gender and age

87
00:03:25,920 --> 00:03:27,360
are leaked

88
00:03:27,360 --> 00:03:29,519
the full procedure for converting the

89
00:03:29,519 --> 00:03:32,319
original data set into the hype

90
00:03:32,319 --> 00:03:35,760
distribution is presented in the paper

91
00:03:35,760 --> 00:03:38,400
but from the hyper shown here we have

92
00:03:38,400 --> 00:03:40,400
four possible observations with the

93
00:03:40,400 --> 00:03:42,879
corresponding probabilities given by the

94
00:03:42,879 --> 00:03:44,720
outer distribution

95
00:03:44,720 --> 00:03:47,120
for each observation the corresponding

96
00:03:47,120 --> 00:03:49,280
posterior probability gives what the

97
00:03:49,280 --> 00:03:51,040
anniversary has learned

98
00:03:51,040 --> 00:03:54,319
about the language from that observation

99
00:03:54,319 --> 00:03:56,720
for instance there is a 50 percent

100
00:03:56,720 --> 00:03:59,120
chance that investor will see

101
00:03:59,120 --> 00:04:00,400
a young man

102
00:04:00,400 --> 00:04:01,840
and from that observation the

103
00:04:01,840 --> 00:04:04,480
anniversary will learn that there is a

104
00:04:04,480 --> 00:04:08,400
50 chance of the language being partners

105
00:04:08,400 --> 00:04:09,680
or german

106
00:04:09,680 --> 00:04:11,760
but there is one missing piece here the

107
00:04:11,760 --> 00:04:13,280
game function

108
00:04:13,280 --> 00:04:15,439
suppose the adversary can be described

109
00:04:15,439 --> 00:04:17,839
with a gain function that yields four

110
00:04:17,839 --> 00:04:20,959
dollars for correct gas and zero for a

111
00:04:20,959 --> 00:04:22,160
wrong gas

112
00:04:22,160 --> 00:04:24,240
before the leakage the adversary's best

113
00:04:24,240 --> 00:04:26,960
gas from the prior would be german in

114
00:04:26,960 --> 00:04:29,520
this case the expected gain would be of

115
00:04:29,520 --> 00:04:30,880
two dollars

116
00:04:30,880 --> 00:04:33,040
after the leakage the expected gain is

117
00:04:33,040 --> 00:04:36,000
computed from the hyper in this case the

118
00:04:36,000 --> 00:04:38,639
expected gain would be of three dollars

119
00:04:38,639 --> 00:04:41,280
in order to instantiate quiff

120
00:04:41,280 --> 00:04:43,759
for the in-app scenario we assume the

121
00:04:43,759 --> 00:04:45,680
following there is a longitudinal

122
00:04:45,680 --> 00:04:48,000
collection of data sets and a persistent

123
00:04:48,000 --> 00:04:50,240
attribute of unique identification for

124
00:04:50,240 --> 00:04:51,840
each student

125
00:04:51,840 --> 00:04:54,240
the adversary's prior knowledge includes

126
00:04:54,240 --> 00:04:56,560
access to all the data sets considered

127
00:04:56,560 --> 00:04:58,479
and hence to their respective

128
00:04:58,479 --> 00:05:01,120
distributions of secret values

129
00:05:01,120 --> 00:05:03,360
for longitudinal attacks we select one

130
00:05:03,360 --> 00:05:06,320
of the data sets as the focal one in

131
00:05:06,320 --> 00:05:08,320
which the attack will be performed while

132
00:05:08,320 --> 00:05:10,560
the other data sets are considered to be

133
00:05:10,560 --> 00:05:12,639
auxiliary information

134
00:05:12,639 --> 00:05:13,840
furthermore

135
00:05:13,840 --> 00:05:15,919
the adversary assumes that each

136
00:05:15,919 --> 00:05:18,240
individual holds only one record on the

137
00:05:18,240 --> 00:05:21,600
focal data set and at most one in each

138
00:05:21,600 --> 00:05:23,280
other data set

139
00:05:23,280 --> 00:05:26,400
the channel is a pre-written version of

140
00:05:26,400 --> 00:05:28,639
either a unique data set or an

141
00:05:28,639 --> 00:05:32,240
aggregated data set divided from joining

142
00:05:32,240 --> 00:05:35,120
the focal and auxiliary data sets

143
00:05:35,120 --> 00:05:37,520
moreover we consider the anniversary

144
00:05:37,520 --> 00:05:40,560
also minus auxiliary information from

145
00:05:40,560 --> 00:05:43,680
other sources to proceed with the attack

146
00:05:43,680 --> 00:05:45,759
for instance from social media the

147
00:05:45,759 --> 00:05:47,600
attack is then performed

148
00:05:47,600 --> 00:05:49,520
when the adversary combines the prior

149
00:05:49,520 --> 00:05:52,400
knowledge with the channel and applies

150
00:05:52,400 --> 00:05:54,720
by asian inference to produce the hyper

151
00:05:54,720 --> 00:05:56,160
distribution

152
00:05:56,160 --> 00:05:58,479
for deterministic attack the threat is

153
00:05:58,479 --> 00:06:00,479
quantified as the proportion of

154
00:06:00,479 --> 00:06:02,880
individuals whose secret values can be

155
00:06:02,880 --> 00:06:05,440
inferred with absolute certainty for

156
00:06:05,440 --> 00:06:07,759
probably probabilistic attack

157
00:06:07,759 --> 00:06:09,680
the threat is quantified using the

158
00:06:09,680 --> 00:06:11,759
biggest vulnerability function which

159
00:06:11,759 --> 00:06:13,440
corresponds to the probability of

160
00:06:13,440 --> 00:06:16,800
inferring the secret in one try

161
00:06:16,800 --> 00:06:18,720
finally the leakage of information is

162
00:06:18,720 --> 00:06:21,199
quantified by either the ratio or the

163
00:06:21,199 --> 00:06:23,520
difference between the adversary's prior

164
00:06:23,520 --> 00:06:25,759
and posterior knowledge

165
00:06:25,759 --> 00:06:28,880
this figure schematize and generalize

166
00:06:28,880 --> 00:06:31,360
our attack models in cliff

167
00:06:31,360 --> 00:06:34,000
at first the adversary has access to the

168
00:06:34,000 --> 00:06:36,800
focal data set say the school census of

169
00:06:36,800 --> 00:06:38,560
2014

170
00:06:38,560 --> 00:06:40,639
from which the diversity derives a prior

171
00:06:40,639 --> 00:06:41,840
knowledge

172
00:06:41,840 --> 00:06:44,639
moreover the adversary has access to the

173
00:06:44,639 --> 00:06:47,840
data sets for the school census of 2015

174
00:06:47,840 --> 00:06:51,120
2016 and 2017

175
00:06:51,120 --> 00:06:53,039
and can also gather information from

176
00:06:53,039 --> 00:06:54,800
social media

177
00:06:54,800 --> 00:06:56,800
once the attacks perform

178
00:06:56,800 --> 00:06:58,960
the adversary may become capable of

179
00:06:58,960 --> 00:07:01,759
reading fine videos or inferring the

180
00:07:01,759 --> 00:07:04,080
values of force sensitive attributes

181
00:07:04,080 --> 00:07:06,160
from magical conditions to economic

182
00:07:06,160 --> 00:07:08,720
status so here we have some details

183
00:07:08,720 --> 00:07:10,479
about the in-app data sets we have

184
00:07:10,479 --> 00:07:11,759
analyzed

185
00:07:11,759 --> 00:07:14,000
for all of them the only disclosure

186
00:07:14,000 --> 00:07:16,479
avoidance methods applied by net to

187
00:07:16,479 --> 00:07:19,440
protect the privacy of individuals or

188
00:07:19,440 --> 00:07:22,160
the identification which consists in the

189
00:07:22,160 --> 00:07:24,080
removal of obvious

190
00:07:24,080 --> 00:07:27,360
personal identifiers such as name

191
00:07:27,360 --> 00:07:30,720
and cell dynamization which consists

192
00:07:30,720 --> 00:07:33,199
in the substitution of such obvious

193
00:07:33,199 --> 00:07:35,440
personal identifiers for artificially

194
00:07:35,440 --> 00:07:37,280
created ones

195
00:07:37,280 --> 00:07:39,840
in order to fulfill the assumption of

196
00:07:39,840 --> 00:07:42,160
only one report for each individual in

197
00:07:42,160 --> 00:07:44,560
each data set we have treated the micro

198
00:07:44,560 --> 00:07:47,199
data by randomly selecting only one

199
00:07:47,199 --> 00:07:49,360
record for each student with the same

200
00:07:49,360 --> 00:07:52,560
unique syllabization code in each data

201
00:07:52,560 --> 00:07:53,440
set

202
00:07:53,440 --> 00:07:55,039
for attacks on the school sensors of

203
00:07:55,039 --> 00:07:59,199
2018 we chose the 11 attributes listed

204
00:07:59,199 --> 00:08:01,440
on the left column and performed the

205
00:08:01,440 --> 00:08:05,039
analysis for all the 2047

206
00:08:05,039 --> 00:08:06,479
non-empty combinations of those

207
00:08:06,479 --> 00:08:07,680
attributes

208
00:08:07,680 --> 00:08:09,360
for attacks on the institutional

209
00:08:09,360 --> 00:08:10,639
collection

210
00:08:10,639 --> 00:08:14,319
from 2014 to 2017

211
00:08:14,319 --> 00:08:15,599
we chose

212
00:08:15,599 --> 00:08:18,000
the three attributes on the top of the

213
00:08:18,000 --> 00:08:19,360
right column

214
00:08:19,360 --> 00:08:21,759
which may change over the years in both

215
00:08:21,759 --> 00:08:23,840
cases we have selected the disability

216
00:08:23,840 --> 00:08:26,080
status in the use of publicly school

217
00:08:26,080 --> 00:08:28,080
transportation as the sensitive

218
00:08:28,080 --> 00:08:30,720
attributes for attribute inference

219
00:08:30,720 --> 00:08:33,599
attacks so here we have all the results

220
00:08:33,599 --> 00:08:35,839
for the 2047

221
00:08:35,839 --> 00:08:38,399
non-empty combinations of qyds high

222
00:08:38,399 --> 00:08:40,479
school sensors of 2018 for both

223
00:08:40,479 --> 00:08:42,159
deterministic and probabilistic

224
00:08:42,159 --> 00:08:44,640
measurements of privacy degradation on

225
00:08:44,640 --> 00:08:47,600
the horizontal axis we have the size of

226
00:08:47,600 --> 00:08:50,320
the set of qids used by the anniversary

227
00:08:50,320 --> 00:08:53,279
and on the vertical axis we have the

228
00:08:53,279 --> 00:08:55,120
adversary's success

229
00:08:55,120 --> 00:08:58,080
the horizontal line before the priority

230
00:08:58,080 --> 00:09:00,399
represents the diversity's knowledge

231
00:09:00,399 --> 00:09:01,920
before the attack

232
00:09:01,920 --> 00:09:03,920
there is the information obtained from

233
00:09:03,920 --> 00:09:06,720
just the data set itself and it's

234
00:09:06,720 --> 00:09:09,440
distribution of secret values

235
00:09:09,440 --> 00:09:11,600
for instance with only day and month of

236
00:09:11,600 --> 00:09:14,720
birth and school code almost 31 percent

237
00:09:14,720 --> 00:09:17,279
of the students could be re-identified

238
00:09:17,279 --> 00:09:19,760
while 95 percent could have their

239
00:09:19,760 --> 00:09:23,120
disability status inferred and 85

240
00:09:23,120 --> 00:09:25,040
percent could have the transportation

241
00:09:25,040 --> 00:09:27,839
method inferred in all cases with

242
00:09:27,839 --> 00:09:30,240
absolute certainty

243
00:09:30,240 --> 00:09:32,399
by adding only the year of birth to the

244
00:09:32,399 --> 00:09:34,720
set of key ids those numbers would

245
00:09:34,720 --> 00:09:38,399
increase to 81 percent 99

246
00:09:38,399 --> 00:09:41,680
and 97 respectively

247
00:09:41,680 --> 00:09:43,920
for the long institutional attacks the

248
00:09:43,920 --> 00:09:45,839
analysis were performed using only one

249
00:09:45,839 --> 00:09:49,279
set of qids namely syria of residency

250
00:09:49,279 --> 00:09:52,399
school code and educational stage

251
00:09:52,399 --> 00:09:54,320
here we present the results for

252
00:09:54,320 --> 00:09:56,720
deterministic measurement of privacy

253
00:09:56,720 --> 00:09:58,080
degradation

254
00:09:58,080 --> 00:10:00,320
we've only three seemingly innocuous

255
00:10:00,320 --> 00:10:04,160
qids and access to up to three auxiliary

256
00:10:04,160 --> 00:10:06,720
data sets we can verify the large

257
00:10:06,720 --> 00:10:09,040
proportions of students are available to

258
00:10:09,040 --> 00:10:12,079
attribute inference attacks which result

259
00:10:12,079 --> 00:10:15,920
in absolute certainty by the adversary

260
00:10:15,920 --> 00:10:17,760
the same goes for the probabilistic

261
00:10:17,760 --> 00:10:19,839
measurement of privacy reduction

262
00:10:19,839 --> 00:10:21,600
particularly when it comes to

263
00:10:21,600 --> 00:10:23,600
re-identification attacks

264
00:10:23,600 --> 00:10:25,839
here the percentages are the probability

265
00:10:25,839 --> 00:10:28,959
of successful inference in one try

266
00:10:28,959 --> 00:10:30,839
measured by the base vulnerability

267
00:10:30,839 --> 00:10:33,600
function the prior success for attribute

268
00:10:33,600 --> 00:10:37,040
inference attacks is highly influenced

269
00:10:37,040 --> 00:10:39,519
by the skewness of the distribution of

270
00:10:39,519 --> 00:10:42,240
secret values in this project we have

271
00:10:42,240 --> 00:10:45,600
learned the importance of intrepid

272
00:10:45,600 --> 00:10:48,560
interpreting and reproducing results

273
00:10:48,560 --> 00:10:50,959
from the literature in order to convince

274
00:10:50,959 --> 00:10:53,519
stakeholders of the existence of privacy

275
00:10:53,519 --> 00:10:54,959
vulnerabilities

276
00:10:54,959 --> 00:10:57,279
a literature review on its own is not

277
00:10:57,279 --> 00:10:59,680
convincing for politicians or republic

278
00:10:59,680 --> 00:11:01,760
in general for instance

279
00:11:01,760 --> 00:11:04,000
moreover the use of relational

280
00:11:04,000 --> 00:11:07,200
adversaries such as that model by the

281
00:11:07,200 --> 00:11:09,200
deterministic measurements of privacy

282
00:11:09,200 --> 00:11:12,480
degradation were essential on this task

283
00:11:12,480 --> 00:11:14,800
on the technical and scientific aspects

284
00:11:14,800 --> 00:11:16,959
we have learned new ways to use the

285
00:11:16,959 --> 00:11:19,839
framework a clear benefit for basic

286
00:11:19,839 --> 00:11:22,560
scientific research as a result of

287
00:11:22,560 --> 00:11:25,120
engaging with a real world problem

288
00:11:25,120 --> 00:11:28,320
for future work we envisage the use of

289
00:11:28,320 --> 00:11:31,200
qids instead of a persistent attribute

290
00:11:31,200 --> 00:11:33,920
of unique identification in the process

291
00:11:33,920 --> 00:11:37,519
of aggregating longitudinal data sets

292
00:11:37,519 --> 00:11:40,399
furthermore we envisage the use of the

293
00:11:40,399 --> 00:11:43,120
channel capacity which can estimate the

294
00:11:43,120 --> 00:11:46,640
maximum privacy risk over all reasonable

295
00:11:46,640 --> 00:11:48,880
adversarial models the software

296
00:11:48,880 --> 00:11:50,720
developed for this work is publicly

297
00:11:50,720 --> 00:11:53,040
available on github given the

298
00:11:53,040 --> 00:11:55,440
vulnerabilities reported in this project

299
00:11:55,440 --> 00:11:57,920
he never has recently removed the micro

300
00:11:57,920 --> 00:11:59,920
data from their website

301
00:11:59,920 --> 00:12:02,399
instead in apps now providing aggregated

302
00:12:02,399 --> 00:12:06,000
statistics as a temporary solution

303
00:12:06,000 --> 00:12:08,079
thank you all for your attention and

304
00:12:08,079 --> 00:12:12,519
special thanks to my co-authors

