1
00:00:01,120 --> 00:00:03,760
hello everyone this is arizura ajapi

2
00:00:03,760 --> 00:00:06,480
from university of washington today i'm

3
00:00:06,480 --> 00:00:08,960
going to present or paypal on free

4
00:00:08,960 --> 00:00:10,960
adversarial examples for super

5
00:00:10,960 --> 00:00:14,080
resolution convolutional neural networks

6
00:00:14,080 --> 00:00:17,920
thanks in advance for your time

7
00:00:18,320 --> 00:00:20,640
before introducing our approach i would

8
00:00:20,640 --> 00:00:22,880
like to talk a little bit about super

9
00:00:22,880 --> 00:00:25,439
resolution convolutional neural networks

10
00:00:25,439 --> 00:00:27,359
or srcnns

11
00:00:27,359 --> 00:00:30,160
srcns are a type of deep neural networks

12
00:00:30,160 --> 00:00:32,880
that take very low resolution images and

13
00:00:32,880 --> 00:00:35,680
generate high resolution images

14
00:00:35,680 --> 00:00:39,280
srcns poses areas privacy threat for

15
00:00:39,280 --> 00:00:41,840
example many application or online

16
00:00:41,840 --> 00:00:43,920
services don't share high resolution

17
00:00:43,920 --> 00:00:46,160
images but they share

18
00:00:46,160 --> 00:00:48,879
low resolution images since they think

19
00:00:48,879 --> 00:00:50,800
the low resolution images are not

20
00:00:50,800 --> 00:00:54,239
classifiable however as a shown in fear

21
00:00:54,239 --> 00:00:57,360
on the left side an adversary can use

22
00:00:57,360 --> 00:01:00,000
ns to generate high

23
00:01:00,000 --> 00:01:03,039
resolution and classifiable images for

24
00:01:03,039 --> 00:01:04,959
hair classifiers

25
00:01:04,959 --> 00:01:07,200
as an example we use as

26
00:01:07,200 --> 00:01:10,560
srcns to generate high resolution image

27
00:01:10,560 --> 00:01:13,840
from a very low resolution face image

28
00:01:13,840 --> 00:01:16,240
and then gave it to the face recognition

29
00:01:16,240 --> 00:01:20,159
model of clarified.com as shown in this

30
00:01:20,159 --> 00:01:23,040
figure on the right side the face

31
00:01:23,040 --> 00:01:26,000
recognition model recognizes the face

32
00:01:26,000 --> 00:01:28,560
correctly

33
00:01:30,079 --> 00:01:32,720
srcnns might affect the performance or

34
00:01:32,720 --> 00:01:35,280
practicality of two image privacy

35
00:01:35,280 --> 00:01:37,759
approaches the first approach is the

36
00:01:37,759 --> 00:01:40,799
perturbation based image privacy methods

37
00:01:40,799 --> 00:01:43,840
like uep and krtio that published in

38
00:01:43,840 --> 00:01:46,079
pets 2021

39
00:01:46,079 --> 00:01:48,640
since these approaches have never taken

40
00:01:48,640 --> 00:01:51,520
srcns into account

41
00:01:51,520 --> 00:01:53,600
the other approach is terminal

42
00:01:53,600 --> 00:01:56,000
preserving encryption methods we

43
00:01:56,000 --> 00:01:58,719
generate an encrypted image with an

44
00:01:58,719 --> 00:02:01,840
exact low resolution of its original

45
00:02:01,840 --> 00:02:04,320
image there are two main questions that

46
00:02:04,320 --> 00:02:07,360
need to be answered

47
00:02:07,360 --> 00:02:09,840
first adversarial perturbation-based

48
00:02:09,840 --> 00:02:14,239
privacy privacy methods practical second

49
00:02:14,239 --> 00:02:17,440
can we share all low-resolution images

50
00:02:17,440 --> 00:02:19,840
to make these approaches practical we

51
00:02:19,840 --> 00:02:22,160
need to learn adversarial noise for low

52
00:02:22,160 --> 00:02:24,319
resolution images such that the

53
00:02:24,319 --> 00:02:26,560
generated high resolution images from

54
00:02:26,560 --> 00:02:28,879
them can full

55
00:02:28,879 --> 00:02:31,760
classifiers

56
00:02:32,480 --> 00:02:35,200
in this paper we focus on adversarial or

57
00:02:35,200 --> 00:02:38,160
perturbation based privacy preserving

58
00:02:38,160 --> 00:02:39,200
methods

59
00:02:39,200 --> 00:02:41,599
these methods are becoming popular for

60
00:02:41,599 --> 00:02:43,599
two main properties of adversarial

61
00:02:43,599 --> 00:02:44,560
images

62
00:02:44,560 --> 00:02:47,440
adversarial images can fool unknown cnns

63
00:02:47,440 --> 00:02:50,000
means if they are trained on cnn a they

64
00:02:50,000 --> 00:02:52,480
are able to full cnn b

65
00:02:52,480 --> 00:02:54,400
therefore the knowledge of

66
00:02:54,400 --> 00:02:56,800
the adversary cnn classifiers is not

67
00:02:56,800 --> 00:02:58,640
required

68
00:02:58,640 --> 00:03:01,120
they are recognizable for human but not

69
00:03:01,120 --> 00:03:02,640
classifiers

70
00:03:02,640 --> 00:03:05,360
therefore users can browse and search

71
00:03:05,360 --> 00:03:08,319
over their images

72
00:03:09,840 --> 00:03:12,239
as a result we focus on how we can

73
00:03:12,239 --> 00:03:14,480
present these two adversarial images

74
00:03:14,480 --> 00:03:17,200
properties when they are processed by

75
00:03:17,200 --> 00:03:20,000
srcnns

76
00:03:20,080 --> 00:03:22,239
generating low resolution at result

77
00:03:22,239 --> 00:03:25,040
images with these two properties is

78
00:03:25,040 --> 00:03:26,799
shown to be visible by joint

79
00:03:26,799 --> 00:03:29,280
optimization in this scenario both

80
00:03:29,280 --> 00:03:33,120
targets srcn and classifier are known

81
00:03:33,120 --> 00:03:35,200
and their hyper parameters are available

82
00:03:35,200 --> 00:03:38,239
to users therefore the user can lend

83
00:03:38,239 --> 00:03:40,799
adversarial low resolution images with

84
00:03:40,799 --> 00:03:42,560
the property of fooling the target

85
00:03:42,560 --> 00:03:43,840
classifier

86
00:03:43,840 --> 00:03:46,400
however this survey is not realistic

87
00:03:46,400 --> 00:03:48,080
since the user

88
00:03:48,080 --> 00:03:49,920
don't have any knowledge about the

89
00:03:49,920 --> 00:03:54,238
adversary's srcns or classifiers

90
00:03:54,959 --> 00:03:57,840
therefore the question is that if users

91
00:03:57,840 --> 00:04:00,400
use their own srcns to land low

92
00:04:00,400 --> 00:04:03,120
resolution adversely images do they full

93
00:04:03,120 --> 00:04:05,840
unknown srcns or classifiers

94
00:04:05,840 --> 00:04:07,920
if yes how to update the adversarial

95
00:04:07,920 --> 00:04:10,400
perturbation based method for joint

96
00:04:10,400 --> 00:04:13,400
optimization

97
00:04:14,640 --> 00:04:16,880
before introducing our approach let's

98
00:04:16,880 --> 00:04:19,199
review our assumptions

99
00:04:19,199 --> 00:04:21,199
an adversary has only access to low

100
00:04:21,199 --> 00:04:22,800
resolution images

101
00:04:22,800 --> 00:04:25,680
user can train a local cnns to learn

102
00:04:25,680 --> 00:04:28,400
adversarial noise or perturbation users

103
00:04:28,400 --> 00:04:31,360
don't have any knowledge about the srcns

104
00:04:31,360 --> 00:04:34,080
that might be used by an adversary

105
00:04:34,080 --> 00:04:35,759
user goal is

106
00:04:35,759 --> 00:04:38,479
to add survivable perturbation to their

107
00:04:38,479 --> 00:04:40,320
low resolution images such that the

108
00:04:40,320 --> 00:04:42,720
generated high resolution images by

109
00:04:42,720 --> 00:04:46,880
srcns are not classifiable

110
00:04:49,120 --> 00:04:51,520
in this work we aim to answer the

111
00:04:51,520 --> 00:04:54,000
following questions

112
00:04:54,000 --> 00:04:56,800
does adversarial perturbation or noise

113
00:04:56,800 --> 00:04:58,560
train only on

114
00:04:58,560 --> 00:05:02,560
cnn's classifiers so why choose srcnn or

115
00:05:02,560 --> 00:05:05,520
do we really need to upgrade the

116
00:05:05,520 --> 00:05:07,600
adversarial noise learning methods to

117
00:05:07,600 --> 00:05:10,639
consider srcns

118
00:05:10,639 --> 00:05:13,280
if yes how can we land survivable

119
00:05:13,280 --> 00:05:15,120
adversarial perturbation for low

120
00:05:15,120 --> 00:05:18,160
resolution images

121
00:05:19,759 --> 00:05:22,080
before answering those questions let's

122
00:05:22,080 --> 00:05:24,479
define survivability for adversarial

123
00:05:24,479 --> 00:05:27,360
images an adversarial low resolution

124
00:05:27,360 --> 00:05:31,039
image survives through srcns if

125
00:05:31,039 --> 00:05:33,600
it's super resolved image can full

126
00:05:33,600 --> 00:05:36,080
unknown cnn

127
00:05:36,080 --> 00:05:38,800
we use the metric of transferability to

128
00:05:38,800 --> 00:05:41,360
access this property transferability

129
00:05:41,360 --> 00:05:44,160
measures the ratio of super-resolved low

130
00:05:44,160 --> 00:05:47,199
resolution images that can full unknown

131
00:05:47,199 --> 00:05:49,680
cnns

132
00:05:50,880 --> 00:05:53,280
the other property we considered for

133
00:05:53,280 --> 00:05:57,199
survivability is recognizability

134
00:05:57,199 --> 00:05:59,759
the adversarial images are not required

135
00:05:59,759 --> 00:06:02,240
recognizable for classifiers while they

136
00:06:02,240 --> 00:06:05,520
are perceptually recognizable for humans

137
00:06:05,520 --> 00:06:07,120
this is the main reason for the

138
00:06:07,120 --> 00:06:09,360
popularity of adversarial based image

139
00:06:09,360 --> 00:06:12,319
privacy approaches

140
00:06:12,319 --> 00:06:14,720
consequently we would like

141
00:06:14,720 --> 00:06:16,800
the super result images from low

142
00:06:16,800 --> 00:06:19,120
resolution images to be recognizable for

143
00:06:19,120 --> 00:06:22,400
human therefore they can browse their

144
00:06:22,400 --> 00:06:24,960
images we use similarity metrics to

145
00:06:24,960 --> 00:06:26,960
measure how well this property of

146
00:06:26,960 --> 00:06:29,120
adversarial images is

147
00:06:29,120 --> 00:06:33,880
preserved by going through srcns

148
00:06:34,479 --> 00:06:37,600
till now we talk about survivability of

149
00:06:37,600 --> 00:06:40,160
adversarial low resolution images and

150
00:06:40,160 --> 00:06:42,479
now we are going to talk about the

151
00:06:42,479 --> 00:06:44,720
approaches one can use to land low

152
00:06:44,720 --> 00:06:46,880
resolution at virtual images

153
00:06:46,880 --> 00:06:49,440
the first approach is to

154
00:06:49,440 --> 00:06:51,280
train at result images on high

155
00:06:51,280 --> 00:06:54,479
resolution images and then unscale them

156
00:06:54,479 --> 00:06:56,639
the previous adversarial or perturbation

157
00:06:56,639 --> 00:06:59,520
based methods learn adversarial noise on

158
00:06:59,520 --> 00:07:02,080
high resolution images and assume the

159
00:07:02,080 --> 00:07:05,680
user has access to a large cns

160
00:07:05,680 --> 00:07:07,520
the main question about

161
00:07:07,520 --> 00:07:10,160
this approach is that if done scholarly

162
00:07:10,160 --> 00:07:11,599
done scaling

163
00:07:11,599 --> 00:07:13,840
the adversarial images reduces their

164
00:07:13,840 --> 00:07:17,440
impacts or not

165
00:07:17,440 --> 00:07:19,680
the other approach to generate low

166
00:07:19,680 --> 00:07:22,000
resolution adversarial images is to

167
00:07:22,000 --> 00:07:23,840
change them

168
00:07:23,840 --> 00:07:27,360
directly on a small cns when we say a

169
00:07:27,360 --> 00:07:29,680
small cnn we mean

170
00:07:29,680 --> 00:07:31,680
they are trained on low resolution

171
00:07:31,680 --> 00:07:35,599
images with a limited number of classes

172
00:07:35,680 --> 00:07:37,759
here the main question is that if the

173
00:07:37,759 --> 00:07:40,160
low resolution at result images trained

174
00:07:40,160 --> 00:07:42,000
on a small cnn

175
00:07:42,000 --> 00:07:44,759
can make srcns to generate

176
00:07:44,759 --> 00:07:47,440
unclassifiable high resolution images or

177
00:07:47,440 --> 00:07:49,680
not

178
00:07:50,960 --> 00:07:52,800
now we plan to assess the server

179
00:07:52,800 --> 00:07:55,120
viability of low resolution images

180
00:07:55,120 --> 00:07:57,599
generated by the first approach which is

181
00:07:57,599 --> 00:08:00,639
done scaling high resolution adversarial

182
00:08:00,639 --> 00:08:01,840
images

183
00:08:01,840 --> 00:08:04,160
the first metric to assess the

184
00:08:04,160 --> 00:08:05,759
survivability

185
00:08:05,759 --> 00:08:08,240
of these images is transferability to

186
00:08:08,240 --> 00:08:10,879
measure transferability we considered

187
00:08:10,879 --> 00:08:14,240
both white box and black box

188
00:08:14,240 --> 00:08:16,319
access scenarios

189
00:08:16,319 --> 00:08:18,400
in white box scenario we train at

190
00:08:18,400 --> 00:08:20,319
virtual images on original high

191
00:08:20,319 --> 00:08:23,039
resolution images using a cnn let's call

192
00:08:23,039 --> 00:08:26,639
it cnn a then we've we don't scroll them

193
00:08:26,639 --> 00:08:29,680
after that we fit the cnna

194
00:08:29,680 --> 00:08:32,000
with the super resolved images generated

195
00:08:32,000 --> 00:08:34,080
by srcnns

196
00:08:34,080 --> 00:08:36,000
and we measure the test

197
00:08:36,000 --> 00:08:37,679
the transferability

198
00:08:37,679 --> 00:08:40,399
for blackbox scenario we gave the super

199
00:08:40,399 --> 00:08:43,760
resolved images generated by c srcns to

200
00:08:43,760 --> 00:08:45,200
another cnn

201
00:08:45,200 --> 00:08:46,399
let's call it

202
00:08:46,399 --> 00:08:48,480
cnnb and then we measure the

203
00:08:48,480 --> 00:08:51,440
transferability

204
00:08:52,240 --> 00:08:53,519
here we use

205
00:08:53,519 --> 00:08:56,800
two large cnns train on imagenet dataset

206
00:08:56,800 --> 00:09:01,839
call it resnet 150 and resnet 101

207
00:09:01,839 --> 00:09:04,959
also we used fast gradient sign method

208
00:09:04,959 --> 00:09:06,880
for learning adversely images with

209
00:09:06,880 --> 00:09:09,600
different values of epsilon

210
00:09:09,600 --> 00:09:12,000
as you can see transfer adversarial

211
00:09:12,000 --> 00:09:16,000
images for those scenarios is comparable

212
00:09:16,000 --> 00:09:18,240
the other question that we wanted to

213
00:09:18,240 --> 00:09:19,360
answer

214
00:09:19,360 --> 00:09:22,959
is if the user hypothetically has access

215
00:09:22,959 --> 00:09:26,320
to the output of srcns and adds

216
00:09:26,320 --> 00:09:27,440
the

217
00:09:27,440 --> 00:09:30,080
adversarial noise then on the original

218
00:09:30,080 --> 00:09:32,560
high resolution images to the output of

219
00:09:32,560 --> 00:09:34,880
srcns then the terence will ability

220
00:09:34,880 --> 00:09:36,720
improves or not

221
00:09:36,720 --> 00:09:38,320
or experiments

222
00:09:38,320 --> 00:09:40,080
show that

223
00:09:40,080 --> 00:09:43,279
the noise generated by srcns

224
00:09:43,279 --> 00:09:45,279
might

225
00:09:45,279 --> 00:09:48,080
reduce the impact of adversarial noise

226
00:09:48,080 --> 00:09:50,720
therefore having access to the output of

227
00:09:50,720 --> 00:09:52,959
src n doesn't help here

228
00:09:52,959 --> 00:09:56,160
for example it's a for card x4 an

229
00:09:56,160 --> 00:09:59,600
epsilon up five percent for black box

230
00:09:59,600 --> 00:10:01,600
scenarios

231
00:10:01,600 --> 00:10:04,399
the transport is around 75 percent while

232
00:10:04,399 --> 00:10:06,480
adding that adversarial noise directly

233
00:10:06,480 --> 00:10:08,959
to the output of srcns decreases the

234
00:10:08,959 --> 00:10:12,880
transferability to 31 percent

235
00:10:14,399 --> 00:10:16,560
the other property we consider for

236
00:10:16,560 --> 00:10:19,279
survivability is recognizable df super

237
00:10:19,279 --> 00:10:21,920
resolved images from low resolve low

238
00:10:21,920 --> 00:10:23,920
resolution adversarial images

239
00:10:23,920 --> 00:10:25,760
the adversarial images are not

240
00:10:25,760 --> 00:10:28,399
recognizable for classifiers while they

241
00:10:28,399 --> 00:10:31,600
are perceptually recognizable for human

242
00:10:31,600 --> 00:10:34,160
as is shown in the figure on the right

243
00:10:34,160 --> 00:10:37,200
side the super resolve low resolution at

244
00:10:37,200 --> 00:10:38,959
virtual images are similar to the

245
00:10:38,959 --> 00:10:41,200
original high resolution images

246
00:10:41,200 --> 00:10:42,720
or experiments

247
00:10:42,720 --> 00:10:44,320
show larger

248
00:10:44,320 --> 00:10:46,640
amount of adversarial noise leads the

249
00:10:46,640 --> 00:10:48,800
super resolved images to have lower

250
00:10:48,800 --> 00:10:50,800
quality but they are essentially

251
00:10:50,800 --> 00:10:53,040
recognizable we use the similarity

252
00:10:53,040 --> 00:10:55,360
matrix to measure how well this property

253
00:10:55,360 --> 00:10:58,079
of adversarial images is preserved by

254
00:10:58,079 --> 00:10:59,839
going through

255
00:10:59,839 --> 00:11:01,920
please read the paper for more

256
00:11:01,920 --> 00:11:04,560
information

257
00:11:04,800 --> 00:11:07,839
also we evaluate or second approach for

258
00:11:07,839 --> 00:11:09,839
generating low

259
00:11:09,839 --> 00:11:12,240
resolution adverse images which is

260
00:11:12,240 --> 00:11:14,800
directly learning low resolution images

261
00:11:14,800 --> 00:11:18,000
on a small cnn in this scenario a user

262
00:11:18,000 --> 00:11:22,320
needs to train a small cnn to learn

263
00:11:22,320 --> 00:11:24,959
adversarial low resolution images

264
00:11:24,959 --> 00:11:27,600
as is shown in this table for a small

265
00:11:27,600 --> 00:11:29,120
value of

266
00:11:29,120 --> 00:11:31,600
epsilon like 30 percent

267
00:11:31,600 --> 00:11:34,399
three percent the transport is high and

268
00:11:34,399 --> 00:11:37,519
more than 95 percent for a black box

269
00:11:37,519 --> 00:11:40,839
scenario also figure in the

270
00:11:40,839 --> 00:11:42,399
bottom

271
00:11:42,399 --> 00:11:44,720
shows that super result images are

272
00:11:44,720 --> 00:11:47,600
recognizable

273
00:11:51,279 --> 00:11:53,600
we received a great question from

274
00:11:53,600 --> 00:11:56,800
reviewers during the rebuttal phase they

275
00:11:56,800 --> 00:11:58,800
asked how might b trans the

276
00:11:58,800 --> 00:12:01,040
transferability of low resolution

277
00:12:01,040 --> 00:12:03,760
adversarial images be affected if the

278
00:12:03,760 --> 00:12:06,480
adversary uses a robust cnn

279
00:12:06,480 --> 00:12:10,000
a robust cnn is defined as if classifier

280
00:12:10,000 --> 00:12:13,120
returns label y for an input x it

281
00:12:13,120 --> 00:12:16,639
returns label y for any input

282
00:12:16,639 --> 00:12:21,279
x plus delta for all delta less than r

283
00:12:21,920 --> 00:12:24,720
we observed in this scenario if the user

284
00:12:24,720 --> 00:12:28,560
utilizes a non-robust cnn she cannot

285
00:12:28,560 --> 00:12:31,200
learn a transferable adversarial image

286
00:12:31,200 --> 00:12:34,240
therefore we use two pre-trained robust

287
00:12:34,240 --> 00:12:36,959
models on imagenet dataset as users and

288
00:12:36,959 --> 00:12:40,480
adversaries cnns and evaluated both

289
00:12:40,480 --> 00:12:43,440
black box and white box scenarios

290
00:12:43,440 --> 00:12:46,079
our experiments show that the super

291
00:12:46,079 --> 00:12:48,240
result images have comparable

292
00:12:48,240 --> 00:12:50,079
transferability to the original

293
00:12:50,079 --> 00:12:52,800
adversarial images

294
00:12:52,800 --> 00:12:55,600
for example for car x2 invite box

295
00:12:55,600 --> 00:12:58,639
scenario we got 33 percent trans quality

296
00:12:58,639 --> 00:13:01,519
for original adversarial images and 27

297
00:13:01,519 --> 00:13:03,519
percent transferability for super

298
00:13:03,519 --> 00:13:07,120
resolved images note that for

299
00:13:07,120 --> 00:13:11,040
whitebox setting both adversary and user

300
00:13:11,040 --> 00:13:14,480
use the same robust sentence which is

301
00:13:14,480 --> 00:13:17,680
a robustness with the l2 norm of

302
00:13:17,680 --> 00:13:19,519
epsilon equal to 3.

303
00:13:19,519 --> 00:13:22,320
we observed similar result

304
00:13:22,320 --> 00:13:24,720
results for black box settings in which

305
00:13:24,720 --> 00:13:27,839
the adversary use uses robust ends with

306
00:13:27,839 --> 00:13:31,600
the l infinity norm of 8 we can conclude

307
00:13:31,600 --> 00:13:36,160
if users utilize robust cnns then they

308
00:13:36,160 --> 00:13:38,880
can lend survivable adversarial images

309
00:13:38,880 --> 00:13:41,360
against an adversary with the robust

310
00:13:41,360 --> 00:13:44,360
cnns

311
00:13:48,240 --> 00:13:51,279
briefly in our paper we show that

312
00:13:51,279 --> 00:13:53,519
adversarial noise

313
00:13:53,519 --> 00:13:56,160
survives well in dynastical adversarial

314
00:13:56,160 --> 00:13:59,519
examples through srcns

315
00:13:59,519 --> 00:14:02,240
adversal noise trained directly on low

316
00:14:02,240 --> 00:14:04,720
resolution images can survive through

317
00:14:04,720 --> 00:14:07,199
srcns

318
00:14:07,199 --> 00:14:09,199
robustness

319
00:14:09,199 --> 00:14:11,839
can reduce the transferability

320
00:14:11,839 --> 00:14:13,600
but if users

321
00:14:13,600 --> 00:14:17,519
utilize it if users utilize a robot cnn

322
00:14:17,519 --> 00:14:22,399
then their transferability will be high

323
00:14:23,920 --> 00:14:26,240
thanks for your time and attention if

324
00:14:26,240 --> 00:14:28,560
you have any question i would

325
00:14:28,560 --> 00:14:31,839
be happy to take them

