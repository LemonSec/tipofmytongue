1
00:00:01,599 --> 00:00:04,240
hi i'm alexandra cupp and i present you

2
00:00:04,240 --> 00:00:06,560
my topic on collection usage and privacy

3
00:00:06,560 --> 00:00:08,320
of mobility data in the enterprise on

4
00:00:08,320 --> 00:00:10,000
public administrations

5
00:00:10,000 --> 00:00:12,160
i'm a phd student at the university of

6
00:00:12,160 --> 00:00:14,639
applied sciences in berlin and i'm part

7
00:00:14,639 --> 00:00:15,679
of the

8
00:00:15,679 --> 00:00:17,520
research project free move where we

9
00:00:17,520 --> 00:00:19,760
focus on researching the privacy of

10
00:00:19,760 --> 00:00:22,080
mobility data

11
00:00:22,080 --> 00:00:24,240
research on privacy of mobility data is

12
00:00:24,240 --> 00:00:26,400
commonly motivated with the need for

13
00:00:26,400 --> 00:00:28,560
data-driven solutions especially for

14
00:00:28,560 --> 00:00:32,000
mobility or planning processes

15
00:00:32,000 --> 00:00:33,600
this then raised the issue of the

16
00:00:33,600 --> 00:00:36,000
privacy of mobility data where privacy

17
00:00:36,000 --> 00:00:37,920
enhancing technologies are researched to

18
00:00:37,920 --> 00:00:40,879
provide such privacy especially focusing

19
00:00:40,879 --> 00:00:42,840
on balancing the utility privacy

20
00:00:42,840 --> 00:00:45,440
trade-off so far so good but

21
00:00:45,440 --> 00:00:47,600
how do i measure the utility and what

22
00:00:47,600 --> 00:00:49,920
does a utility loss for practitioners

23
00:00:49,920 --> 00:00:52,559
actually mean

24
00:00:52,640 --> 00:00:55,360
we first need a good understanding of

25
00:00:55,360 --> 00:00:57,920
those use cases in practice to answer

26
00:00:57,920 --> 00:01:00,960
those questions so how is which data

27
00:01:00,960 --> 00:01:03,840
exactly used for what kind of analysis

28
00:01:03,840 --> 00:01:06,159
on the search for ansys i found many

29
00:01:06,159 --> 00:01:08,640
assumptions maybe also vague statements

30
00:01:08,640 --> 00:01:11,600
about urban planning but not a lot of

31
00:01:11,600 --> 00:01:14,640
concrete information was actually done

32
00:01:14,640 --> 00:01:17,360
even less information was available on

33
00:01:17,360 --> 00:01:19,520
uh current usage of privacy enhancing

34
00:01:19,520 --> 00:01:21,280
technologies uh

35
00:01:21,280 --> 00:01:23,600
within practitioners work

36
00:01:23,600 --> 00:01:26,159
so are there already any pets used which

37
00:01:26,159 --> 00:01:28,320
are those

38
00:01:28,320 --> 00:01:29,920
those are questions that we're

39
00:01:29,920 --> 00:01:32,159
interested in to then

40
00:01:32,159 --> 00:01:34,720
be able to give profound recommendations

41
00:01:34,720 --> 00:01:37,840
on privacy enhanced technologies

42
00:01:37,840 --> 00:01:40,320
to use and practice for mobility data

43
00:01:40,320 --> 00:01:42,720
because this is the objective of our

44
00:01:42,720 --> 00:01:44,320
free move project

45
00:01:44,320 --> 00:01:46,799
and in order to do that we first need a

46
00:01:46,799 --> 00:01:49,200
comprehensive understanding of real life

47
00:01:49,200 --> 00:01:51,759
practices

48
00:01:51,840 --> 00:01:53,920
this is why we decided to conduct expert

49
00:01:53,920 --> 00:01:54,960
interviews

50
00:01:54,960 --> 00:01:57,600
so a video called were 13 experts from

51
00:01:57,600 --> 00:01:59,920
german organizations from the private

52
00:01:59,920 --> 00:02:02,000
and public sector working with mobility

53
00:02:02,000 --> 00:02:05,600
data all in somewhat leading positions

54
00:02:05,600 --> 00:02:07,759
so companies were from public

55
00:02:07,759 --> 00:02:09,520
administrations public transport

56
00:02:09,520 --> 00:02:11,038
companies

57
00:02:11,038 --> 00:02:14,239
mobility platforms automotive

58
00:02:14,239 --> 00:02:15,760
manufacturers

59
00:02:15,760 --> 00:02:17,440
center companies market research

60
00:02:17,440 --> 00:02:18,959
companies

61
00:02:18,959 --> 00:02:20,160
so after

62
00:02:20,160 --> 00:02:22,720
the interviews we then evaluated them

63
00:02:22,720 --> 00:02:25,040
with a qualitative analysis where the

64
00:02:25,040 --> 00:02:29,440
main categories were the following four

65
00:02:29,680 --> 00:02:32,400
which you can see here so data sources

66
00:02:32,400 --> 00:02:34,879
privacy enhancement data analysis and

67
00:02:34,879 --> 00:02:36,400
modeling and purposes

68
00:02:36,400 --> 00:02:39,440
which build the context where mobility

69
00:02:39,440 --> 00:02:41,360
data is used in

70
00:02:41,360 --> 00:02:42,239
so

71
00:02:42,239 --> 00:02:44,160
i first asked questions on which

72
00:02:44,160 --> 00:02:46,319
mobility data sources are collected

73
00:02:46,319 --> 00:02:49,200
acquired from third parties by

74
00:02:49,200 --> 00:02:51,120
practitioners

75
00:02:51,120 --> 00:02:53,120
what kind of personal information that

76
00:02:53,120 --> 00:02:55,920
data contained what granularity the data

77
00:02:55,920 --> 00:02:59,120
has how frequent the data is collected

78
00:02:59,120 --> 00:03:01,760
then i ask questions about

79
00:03:01,760 --> 00:03:03,360
privacy enhancement

80
00:03:03,360 --> 00:03:04,400
if they

81
00:03:04,400 --> 00:03:07,440
already have any measures in place if so

82
00:03:07,440 --> 00:03:09,760
which ones those are

83
00:03:09,760 --> 00:03:12,400
and i put the privacy enhancement in

84
00:03:12,400 --> 00:03:14,000
this graph between the data source and

85
00:03:14,000 --> 00:03:16,000
the data analysis even though this can

86
00:03:16,000 --> 00:03:18,720
of course also be

87
00:03:18,720 --> 00:03:20,800
positioned differently so for example

88
00:03:20,800 --> 00:03:22,720
after the data analysis but just for

89
00:03:22,720 --> 00:03:25,519
simplicity it is put there

90
00:03:25,519 --> 00:03:28,640
then i ask questions about what types of

91
00:03:28,640 --> 00:03:31,200
analyses or modellings were performed

92
00:03:31,200 --> 00:03:32,720
and

93
00:03:32,720 --> 00:03:33,680
then

94
00:03:33,680 --> 00:03:36,400
yeah one uh

95
00:03:36,400 --> 00:03:38,560
important uh question of what those

96
00:03:38,560 --> 00:03:40,560
analyses were performed for so what are

97
00:03:40,560 --> 00:03:42,720
the purposes because analysis are

98
00:03:42,720 --> 00:03:45,440
usually not a mean in its health but

99
00:03:45,440 --> 00:03:47,200
there's some kind of insight you want to

100
00:03:47,200 --> 00:03:48,959
gain and

101
00:03:48,959 --> 00:03:50,239
in the best case even some kind of

102
00:03:50,239 --> 00:03:51,920
action that would come out of that

103
00:03:51,920 --> 00:03:54,239
insight

104
00:03:54,239 --> 00:03:56,400
so let's jump into the results the data

105
00:03:56,400 --> 00:03:58,799
sources and responsibilities within the

106
00:03:58,799 --> 00:04:01,040
literature you do find information about

107
00:04:01,040 --> 00:04:02,720
data sources and they also mainly

108
00:04:02,720 --> 00:04:04,640
overlap with the ones that were stated

109
00:04:04,640 --> 00:04:06,560
in the interviews

110
00:04:06,560 --> 00:04:09,200
so surveys sensor data transaction data

111
00:04:09,200 --> 00:04:11,360
gps tracking mobile phone data

112
00:04:11,360 --> 00:04:13,680
interestingly rooting queries was a data

113
00:04:13,680 --> 00:04:15,280
source that i did not find in any

114
00:04:15,280 --> 00:04:17,040
literature so far

115
00:04:17,040 --> 00:04:19,918
but in addition to the sources

116
00:04:19,918 --> 00:04:21,839
i was interested to know who is using

117
00:04:21,839 --> 00:04:24,400
which kind of data and additionally who

118
00:04:24,400 --> 00:04:27,440
provides the data and who uses the data

119
00:04:27,440 --> 00:04:30,240
this distinction is important because

120
00:04:30,240 --> 00:04:32,080
the responsibility for privacy is

121
00:04:32,080 --> 00:04:35,199
usually seen within the providing entity

122
00:04:35,199 --> 00:04:37,120
and thus

123
00:04:37,120 --> 00:04:38,560
this distinction is important to

124
00:04:38,560 --> 00:04:40,479
determine who the target group for a

125
00:04:40,479 --> 00:04:42,720
certain privacy enhancing technologies

126
00:04:42,720 --> 00:04:44,800
so for example with mobile phone data

127
00:04:44,800 --> 00:04:46,880
commonly used in research uh the

128
00:04:46,880 --> 00:04:48,720
provider is usually the cellular network

129
00:04:48,720 --> 00:04:50,800
provider and

130
00:04:50,800 --> 00:04:53,440
they aggregate and anonymize the data in

131
00:04:53,440 --> 00:04:56,240
the form of od matrices often to provide

132
00:04:56,240 --> 00:04:57,680
them for example to public

133
00:04:57,680 --> 00:04:59,199
administration and public transport

134
00:04:59,199 --> 00:05:01,120
companies so the cellular network

135
00:05:01,120 --> 00:05:04,720
provider would be the one the um who is

136
00:05:04,720 --> 00:05:06,080
enforcing the

137
00:05:06,080 --> 00:05:08,400
uh the anonymization technique while the

138
00:05:08,400 --> 00:05:11,039
utility is actually finally determined

139
00:05:11,039 --> 00:05:13,600
by the user so the public administration

140
00:05:13,600 --> 00:05:16,240
for example

141
00:05:16,400 --> 00:05:18,240
next let's have a look at the data

142
00:05:18,240 --> 00:05:20,960
analysis and modeling tasks so first in

143
00:05:20,960 --> 00:05:22,960
table three we see all the statistical

144
00:05:22,960 --> 00:05:25,680
aggregations that expert named i don't

145
00:05:25,680 --> 00:05:27,520
want to go into all of those but just to

146
00:05:27,520 --> 00:05:30,800
give you an overview what kind of um

147
00:05:30,800 --> 00:05:33,440
analysis analysis are performed those

148
00:05:33,440 --> 00:05:36,320
range from very highly aggregated ones

149
00:05:36,320 --> 00:05:38,160
like how many trips do we have in our

150
00:05:38,160 --> 00:05:40,880
data set how many customers do we have

151
00:05:40,880 --> 00:05:44,160
to um how many customers per hour of day

152
00:05:44,160 --> 00:05:45,360
do we have

153
00:05:45,360 --> 00:05:47,759
um what is the demand by origin

154
00:05:47,759 --> 00:05:49,520
destination matrix or from where to

155
00:05:49,520 --> 00:05:51,840
where are people actually traveling

156
00:05:51,840 --> 00:05:53,440
what's the speed on different road

157
00:05:53,440 --> 00:05:54,720
segments

158
00:05:54,720 --> 00:05:57,360
what is the average trip length

159
00:05:57,360 --> 00:05:58,240
and

160
00:05:58,240 --> 00:06:00,319
yeah for those uh statistical

161
00:06:00,319 --> 00:06:02,319
aggregations it's a lot easier to

162
00:06:02,319 --> 00:06:04,800
provide proper anonymization techniques

163
00:06:04,800 --> 00:06:07,600
than for example for

164
00:06:07,600 --> 00:06:09,120
a raw data set

165
00:06:09,120 --> 00:06:11,039
and

166
00:06:11,039 --> 00:06:12,800
also easier than

167
00:06:12,800 --> 00:06:14,960
maybe for some mathematical models which

168
00:06:14,960 --> 00:06:17,919
were also named but not as many

169
00:06:17,919 --> 00:06:19,680
they are they also named a lot that are

170
00:06:19,680 --> 00:06:21,520
only in the planning so for example next

171
00:06:21,520 --> 00:06:22,880
location prediction as a machine

172
00:06:22,880 --> 00:06:25,360
learning task which is a hot topic in

173
00:06:25,360 --> 00:06:28,240
deep learning and mobility at the moment

174
00:06:28,240 --> 00:06:30,720
um was only named by one startup to be

175
00:06:30,720 --> 00:06:32,800
in the planning but not actually used so

176
00:06:32,800 --> 00:06:33,600
far

177
00:06:33,600 --> 00:06:36,400
also agent-based models

178
00:06:36,400 --> 00:06:38,800
were not already used yet but are in the

179
00:06:38,800 --> 00:06:41,199
planning by a few

180
00:06:41,199 --> 00:06:42,960
to replace

181
00:06:42,960 --> 00:06:45,120
four-step traffic models in the future

182
00:06:45,120 --> 00:06:48,160
and those agent-based models um are also

183
00:06:48,160 --> 00:06:50,560
in the need of more fine granular data

184
00:06:50,560 --> 00:06:52,400
than

185
00:06:52,400 --> 00:06:55,759
models that have been used so far

186
00:06:55,759 --> 00:06:57,599
now let's have a look on the results on

187
00:06:57,599 --> 00:07:00,000
privacy first a few common themes that i

188
00:07:00,000 --> 00:07:02,560
identified and then the

189
00:07:02,560 --> 00:07:04,400
privacy-enhancing technologies that are

190
00:07:04,400 --> 00:07:07,919
already being used by the experts

191
00:07:07,919 --> 00:07:10,479
so first thing i found was a different

192
00:07:10,479 --> 00:07:12,240
engagement of the interviews with

193
00:07:12,240 --> 00:07:14,639
privacy measures so we hypothesized that

194
00:07:14,639 --> 00:07:15,840
there's a difference between

195
00:07:15,840 --> 00:07:17,680
participants organizations that collect

196
00:07:17,680 --> 00:07:19,680
data themselves and those that obtain

197
00:07:19,680 --> 00:07:22,160
them from third parties so like i

198
00:07:22,160 --> 00:07:25,039
already said with the data sources um

199
00:07:25,039 --> 00:07:28,720
only the data providers are ones

200
00:07:28,720 --> 00:07:31,360
that are actually applying pets and

201
00:07:31,360 --> 00:07:33,440
anonymization techniques themselves

202
00:07:33,440 --> 00:07:36,160
while uh if parties obtain data from

203
00:07:36,160 --> 00:07:38,319
third parties then they would not apply

204
00:07:38,319 --> 00:07:40,800
any anonymization techniques

205
00:07:40,800 --> 00:07:44,400
uh themselves after they got the data

206
00:07:44,400 --> 00:07:46,240
all interviews applying anonymization

207
00:07:46,240 --> 00:07:47,919
methods to their data named one of the

208
00:07:47,919 --> 00:07:50,240
two reasons for purposes outside of the

209
00:07:50,240 --> 00:07:51,840
scope of the

210
00:07:51,840 --> 00:07:54,000
the user consented to and to make the

211
00:07:54,000 --> 00:07:56,319
data available to third parties so

212
00:07:56,319 --> 00:07:58,879
basically to comply with gdpr

213
00:07:58,879 --> 00:08:00,319
not to

214
00:08:00,319 --> 00:08:02,479
provide privacy to their users because

215
00:08:02,479 --> 00:08:05,440
they think that's an important good

216
00:08:05,440 --> 00:08:07,199
interviews with a business model based

217
00:08:07,199 --> 00:08:09,039
on providing data to third parties such

218
00:08:09,039 --> 00:08:10,639
as market research companies of the

219
00:08:10,639 --> 00:08:12,800
sensor provider have a high interest in

220
00:08:12,800 --> 00:08:15,039
applying privacy measures as compliance

221
00:08:15,039 --> 00:08:17,759
with gdpr is a major criterion to

222
00:08:17,759 --> 00:08:19,759
acquire clients

223
00:08:19,759 --> 00:08:20,479
so

224
00:08:20,479 --> 00:08:22,080
again

225
00:08:22,080 --> 00:08:24,560
the user would

226
00:08:24,560 --> 00:08:26,400
require that the provider

227
00:08:26,400 --> 00:08:28,639
is complying with gdpr

228
00:08:28,639 --> 00:08:30,080
but the provider is the one being

229
00:08:30,080 --> 00:08:32,399
responsible for that

230
00:08:32,399 --> 00:08:34,479
and finally different experts reported

231
00:08:34,479 --> 00:08:36,080
that they struggled to pursue all the

232
00:08:36,080 --> 00:08:40,760
use cases due to gdpr

233
00:08:41,200 --> 00:08:43,279
so the privacy enhancing methods that

234
00:08:43,279 --> 00:08:45,760
were stated by the experts were

235
00:08:45,760 --> 00:08:47,040
mostly

236
00:08:47,040 --> 00:08:49,200
if at all

237
00:08:49,200 --> 00:08:51,200
very simple ones like removing of

238
00:08:51,200 --> 00:08:54,320
personal attributes or pseudonymization

239
00:08:54,320 --> 00:08:56,160
aggregation was often seen as being

240
00:08:56,160 --> 00:08:57,040
enough

241
00:08:57,040 --> 00:09:00,160
of a data anonymization

242
00:09:00,160 --> 00:09:02,080
if you mentioned

243
00:09:02,080 --> 00:09:04,240
distinguishability so

244
00:09:04,240 --> 00:09:06,080
this was usually in the form of origin

245
00:09:06,080 --> 00:09:08,560
destination matrices where

246
00:09:08,560 --> 00:09:10,399
such cell accounts would only be shown

247
00:09:10,399 --> 00:09:12,160
if they would

248
00:09:12,160 --> 00:09:14,959
go beyond a certain threshold

249
00:09:14,959 --> 00:09:16,240
then

250
00:09:16,240 --> 00:09:17,279
we heard

251
00:09:17,279 --> 00:09:20,399
twice about coarsening so for example

252
00:09:20,399 --> 00:09:23,200
only showing a heat map or

253
00:09:23,200 --> 00:09:24,880
rounding the coordinates to three

254
00:09:24,880 --> 00:09:26,720
decimal places

255
00:09:26,720 --> 00:09:28,560
we also had twice about the cropping of

256
00:09:28,560 --> 00:09:30,240
trajectories so

257
00:09:30,240 --> 00:09:32,240
cropping off the beginning and the end

258
00:09:32,240 --> 00:09:34,160
of a trajectory

259
00:09:34,160 --> 00:09:36,560
to obscure the actual starter

260
00:09:36,560 --> 00:09:37,920
destination

261
00:09:37,920 --> 00:09:39,120
um

262
00:09:39,120 --> 00:09:40,959
and then we had one participant from a

263
00:09:40,959 --> 00:09:43,360
market research company was the only one

264
00:09:43,360 --> 00:09:44,959
who actually talked about adding noise

265
00:09:44,959 --> 00:09:46,959
about data synthesization techniques

266
00:09:46,959 --> 00:09:49,200
about differential privacy and about

267
00:09:49,200 --> 00:09:50,480
decentralized

268
00:09:50,480 --> 00:09:53,920
data processing though um all of those

269
00:09:53,920 --> 00:09:56,480
more advanced techniques were only named

270
00:09:56,480 --> 00:09:57,680
as

271
00:09:57,680 --> 00:09:59,680
they heard of it they

272
00:09:59,680 --> 00:10:01,760
considered it they might be trying it

273
00:10:01,760 --> 00:10:03,920
out but none of the measures were

274
00:10:03,920 --> 00:10:06,719
already in place

275
00:10:07,760 --> 00:10:11,279
uh yeah as a final conclusion of my

276
00:10:11,279 --> 00:10:13,440
talk i want to provide the practical

277
00:10:13,440 --> 00:10:16,240
implications that i derived from the

278
00:10:16,240 --> 00:10:19,519
results from the expert interviews so

279
00:10:19,519 --> 00:10:21,839
the first is that guidance and clarity

280
00:10:21,839 --> 00:10:24,079
and the use of state-of-the-art privacy

281
00:10:24,079 --> 00:10:26,480
enhancing methods is needed for example

282
00:10:26,480 --> 00:10:28,480
a framework which compiles practical

283
00:10:28,480 --> 00:10:30,399
real-world use cases and suggests

284
00:10:30,399 --> 00:10:33,360
adequate privacy methods

285
00:10:33,360 --> 00:10:36,800
as there's a lot of unclarity within

286
00:10:36,800 --> 00:10:39,360
the practitioners

287
00:10:39,360 --> 00:10:42,160
as to what set of the arm methods are

288
00:10:42,160 --> 00:10:44,560
how they could be applied and what

289
00:10:44,560 --> 00:10:46,399
actually um

290
00:10:46,399 --> 00:10:48,079
what what are actually the implications

291
00:10:48,079 --> 00:10:49,200
for them

292
00:10:49,200 --> 00:10:51,440
um

293
00:10:51,600 --> 00:10:54,079
then easy-to-use tools for pets will

294
00:10:54,079 --> 00:10:55,680
enable organizations without the

295
00:10:55,680 --> 00:10:57,680
expertise and resources to implement

296
00:10:57,680 --> 00:11:00,800
state-of-the-art methods for example a

297
00:11:00,800 --> 00:11:04,320
few experts also said we don't have the

298
00:11:04,320 --> 00:11:06,560
the resources and the knowledge to to

299
00:11:06,560 --> 00:11:08,480
apply any complicated algorithms or

300
00:11:08,480 --> 00:11:10,880
mechanisms to provide privacy

301
00:11:10,880 --> 00:11:11,760
um

302
00:11:11,760 --> 00:11:15,120
so if there's not any tool then this is

303
00:11:15,120 --> 00:11:18,720
not really feasible for them

304
00:11:18,720 --> 00:11:20,720
also standardized similarity measures

305
00:11:20,720 --> 00:11:22,720
and downstream downstream tasks would

306
00:11:22,720 --> 00:11:25,600
facilitate the comparison of the impact

307
00:11:25,600 --> 00:11:29,200
on utility of pets so what i mean with

308
00:11:29,200 --> 00:11:31,440
that if we go back to the context that i

309
00:11:31,440 --> 00:11:33,600
showed at the beginning

310
00:11:33,600 --> 00:11:36,000
we can evaluate the privacy enhancement

311
00:11:36,000 --> 00:11:39,279
with similarity measures by comparing

312
00:11:39,279 --> 00:11:41,600
the results with and without privacy

313
00:11:41,600 --> 00:11:44,640
enhancement and such similarity measures

314
00:11:44,640 --> 00:11:46,720
are not very standardized for mobility

315
00:11:46,720 --> 00:11:48,240
data but

316
00:11:48,240 --> 00:11:50,399
yeah every author every approach

317
00:11:50,399 --> 00:11:52,959
uses whatever suits for their purposes

318
00:11:52,959 --> 00:11:54,880
which makes it very hard to compare

319
00:11:54,880 --> 00:11:58,800
different approaches with one another

320
00:11:58,800 --> 00:12:00,880
and then finally gdpr certificates for

321
00:12:00,880 --> 00:12:02,639
pets could accelerate the processes

322
00:12:02,639 --> 00:12:04,079
within organizations and provide

323
00:12:04,079 --> 00:12:06,800
security for decision makers as approval

324
00:12:06,800 --> 00:12:08,880
processes due to gdpr

325
00:12:08,880 --> 00:12:10,720
can take quite some time within the

326
00:12:10,720 --> 00:12:13,200
organizations

327
00:12:13,200 --> 00:12:15,360
so thank you very much feel free to

328
00:12:15,360 --> 00:12:17,440
contact me and have a great rest of the

329
00:12:17,440 --> 00:12:20,480
pets conference

