1
00:00:01,599 --> 00:00:03,679
hi my name is mohammad tahi thank you

2
00:00:03,679 --> 00:00:05,680
very much for attending our talk today

3
00:00:05,680 --> 00:00:07,600
i'm going to talk to you about privacy

4
00:00:07,600 --> 00:00:09,840
related advice on a stack overflow i did

5
00:00:09,840 --> 00:00:11,679
this research with tianji lee from

6
00:00:11,679 --> 00:00:13,679
carnegie mellon university and kami

7
00:00:13,679 --> 00:00:17,359
vanier from the university of edinburgh

8
00:00:17,359 --> 00:00:19,840
the main idea behind this research is to

9
00:00:19,840 --> 00:00:22,160
find out how developers make use of

10
00:00:22,160 --> 00:00:24,560
privacy frameworks so for example when

11
00:00:24,560 --> 00:00:27,599
we talk about privacy design strategies

12
00:00:27,599 --> 00:00:29,920
we wanted to better understand how these

13
00:00:29,920 --> 00:00:31,920
strategies are applied and used by

14
00:00:31,920 --> 00:00:33,680
developers

15
00:00:33,680 --> 00:00:35,200
we've got all sorts of privacy

16
00:00:35,200 --> 00:00:37,520
regulations and laws coming into action

17
00:00:37,520 --> 00:00:39,760
in the past few years for example we've

18
00:00:39,760 --> 00:00:41,920
got gdpr in europe

19
00:00:41,920 --> 00:00:45,200
or ccpa and copa in the united states

20
00:00:45,200 --> 00:00:47,200
and we've got other privacy regulations

21
00:00:47,200 --> 00:00:48,800
in other countries that are being

22
00:00:48,800 --> 00:00:52,239
introduced to protect citizens privacy

23
00:00:52,239 --> 00:00:53,360
however

24
00:00:53,360 --> 00:00:55,440
these regulations and laws are very high

25
00:00:55,440 --> 00:00:57,360
level and difficult to understand for

26
00:00:57,360 --> 00:00:59,199
developers

27
00:00:59,199 --> 00:01:01,120
so these laws and regulations for

28
00:01:01,120 --> 00:01:03,039
example may talk about protecting

29
00:01:03,039 --> 00:01:05,199
privacy but not necessarily give

30
00:01:05,199 --> 00:01:07,680
detailed guides about how to achieve it

31
00:01:07,680 --> 00:01:10,720
in the technical level

32
00:01:10,720 --> 00:01:13,040
there have been efforts by the research

33
00:01:13,040 --> 00:01:15,439
community to make that transition easier

34
00:01:15,439 --> 00:01:17,520
for developers and translate those

35
00:01:17,520 --> 00:01:20,240
requirements or guidelines provided by

36
00:01:20,240 --> 00:01:21,920
those regulations to a more

37
00:01:21,920 --> 00:01:25,280
understanding technical requirement

38
00:01:25,280 --> 00:01:27,439
however it's not very clear

39
00:01:27,439 --> 00:01:29,600
how developers make use of these

40
00:01:29,600 --> 00:01:32,000
frameworks and how much they can help

41
00:01:32,000 --> 00:01:34,159
developers in building privacy friendly

42
00:01:34,159 --> 00:01:36,960
applications

43
00:01:37,840 --> 00:01:39,759
we wanted to better understand how

44
00:01:39,759 --> 00:01:42,320
developers make use of these frameworks

45
00:01:42,320 --> 00:01:44,479
we decided to focus on one specific

46
00:01:44,479 --> 00:01:47,119
framework which is called privacy design

47
00:01:47,119 --> 00:01:50,320
strategies suggested by open

48
00:01:50,320 --> 00:01:52,799
it's one level below privacy by design

49
00:01:52,799 --> 00:01:54,960
because it tries to really target

50
00:01:54,960 --> 00:01:57,360
developers and designers and provide a

51
00:01:57,360 --> 00:01:59,759
detailed guide for considering privacy

52
00:01:59,759 --> 00:02:03,040
in the design stages

53
00:02:03,040 --> 00:02:04,880
we also decided to focus on stack

54
00:02:04,880 --> 00:02:06,960
overflow as a source of advice for

55
00:02:06,960 --> 00:02:09,598
developers because it's the largest q a

56
00:02:09,598 --> 00:02:12,640
platform for developers

57
00:02:12,640 --> 00:02:15,040
so in the first research question we

58
00:02:15,040 --> 00:02:17,360
wanted to understand how does privacy

59
00:02:17,360 --> 00:02:19,840
advice developers give one another on a

60
00:02:19,840 --> 00:02:22,640
stack overflow relate to the privacy

61
00:02:22,640 --> 00:02:24,080
design

62
00:02:24,080 --> 00:02:27,840
strategies suggested by hopman

63
00:02:27,840 --> 00:02:29,680
in the second research question we

64
00:02:29,680 --> 00:02:31,200
wanted to understand

65
00:02:31,200 --> 00:02:33,040
what advice and information do

66
00:02:33,040 --> 00:02:35,120
developers give one another on a stack

67
00:02:35,120 --> 00:02:39,200
overflow to address privacy issues

68
00:02:39,840 --> 00:02:42,239
we decided to focus on a stack overflow

69
00:02:42,239 --> 00:02:44,480
because it's the largest qna platform

70
00:02:44,480 --> 00:02:46,720
for developers they ask different types

71
00:02:46,720 --> 00:02:48,800
of questions here including programming

72
00:02:48,800 --> 00:02:51,360
questions of course and also topics

73
00:02:51,360 --> 00:02:54,959
around privacy security and databases

74
00:02:54,959 --> 00:02:57,760
in akai paper in 2020 we focused on the

75
00:02:57,760 --> 00:02:59,840
questions that developers ask as a

76
00:02:59,840 --> 00:03:02,159
source of confusions and challenges they

77
00:03:02,159 --> 00:03:06,480
face while working with privacy topics

78
00:03:06,480 --> 00:03:08,319
we found that privacy policies are very

79
00:03:08,319 --> 00:03:10,239
difficult for them to manage permissions

80
00:03:10,239 --> 00:03:12,640
and in general protecting user privacy

81
00:03:12,640 --> 00:03:15,200
are confusing topics for developers

82
00:03:15,200 --> 00:03:17,680
however at the time we then focus on the

83
00:03:17,680 --> 00:03:18,879
answers

84
00:03:18,879 --> 00:03:20,480
and since then there haven't been

85
00:03:20,480 --> 00:03:22,640
research focusing on the answers that

86
00:03:22,640 --> 00:03:24,959
developers give one another on privacy

87
00:03:24,959 --> 00:03:27,120
topics

88
00:03:27,120 --> 00:03:29,200
so in this research we focus on the

89
00:03:29,200 --> 00:03:33,560
answers as a source of advice

90
00:03:34,560 --> 00:03:37,120
before i jump in to the methods section

91
00:03:37,120 --> 00:03:38,879
i wanted to briefly introduce the

92
00:03:38,879 --> 00:03:41,040
privacy design strategies that we used

93
00:03:41,040 --> 00:03:42,720
in this paper

94
00:03:42,720 --> 00:03:44,879
so it has eight different strategies

95
00:03:44,879 --> 00:03:47,040
very briefly

96
00:03:47,040 --> 00:03:48,959
minimize talks about limiting the

97
00:03:48,959 --> 00:03:51,680
processing of personal information

98
00:03:51,680 --> 00:03:53,519
separate talks about separating the

99
00:03:53,519 --> 00:03:56,159
processing of data as much as possible

100
00:03:56,159 --> 00:03:58,080
so instead of processing everything on

101
00:03:58,080 --> 00:04:00,159
one central you need process the data on

102
00:04:00,159 --> 00:04:02,959
multiple units

103
00:04:02,959 --> 00:04:04,799
abstract talks about limiting the

104
00:04:04,799 --> 00:04:07,840
details of personal data so for example

105
00:04:07,840 --> 00:04:10,239
instead of using find location

106
00:04:10,239 --> 00:04:12,720
use course location

107
00:04:12,720 --> 00:04:14,959
height talks about making sure that the

108
00:04:14,959 --> 00:04:17,600
data doesn't become public or known

109
00:04:17,600 --> 00:04:19,519
for example by using some encryption

110
00:04:19,519 --> 00:04:21,918
methods

111
00:04:21,918 --> 00:04:24,080
inform talks about informing subjects

112
00:04:24,080 --> 00:04:25,840
about the processing of their personal

113
00:04:25,840 --> 00:04:27,440
data

114
00:04:27,440 --> 00:04:29,280
control talks about giving adequate

115
00:04:29,280 --> 00:04:31,120
control to the subjects

116
00:04:31,120 --> 00:04:32,880
over the processing of their personal

117
00:04:32,880 --> 00:04:34,560
data

118
00:04:34,560 --> 00:04:36,320
enforce talks about committing the

119
00:04:36,320 --> 00:04:37,600
organization

120
00:04:37,600 --> 00:04:40,479
to a privacy friendly data processing

121
00:04:40,479 --> 00:04:42,560
and demonstrate ensures that the

122
00:04:42,560 --> 00:04:45,120
privacy-friendly data processing is also

123
00:04:45,120 --> 00:04:48,000
demonstrated

124
00:04:49,840 --> 00:04:51,840
to answer our research questions we

125
00:04:51,840 --> 00:04:54,160
collected 170

126
00:04:54,160 --> 00:04:56,479
privacy-related posts from stack

127
00:04:56,479 --> 00:04:58,720
overflow these were created between

128
00:04:58,720 --> 00:05:02,479
april 20 16 to april 2021 all these

129
00:05:02,479 --> 00:05:05,199
posts contained the privacy tag

130
00:05:05,199 --> 00:05:09,039
and they all had an accepted answer

131
00:05:09,039 --> 00:05:10,720
we chose to focus on the accepted

132
00:05:10,720 --> 00:05:13,199
answers because we wanted to make sure

133
00:05:13,199 --> 00:05:15,520
that those answers did actually fix the

134
00:05:15,520 --> 00:05:18,479
asker's problem so those answers are

135
00:05:18,479 --> 00:05:20,800
marked as accepted by the asker of the

136
00:05:20,800 --> 00:05:22,560
question

137
00:05:22,560 --> 00:05:24,479
with the classic bottom-up qualitative

138
00:05:24,479 --> 00:05:26,960
analysis with two coders which you can

139
00:05:26,960 --> 00:05:30,160
find more details about it in the paper

140
00:05:30,160 --> 00:05:32,160
we found that there are two types of

141
00:05:32,160 --> 00:05:36,000
posts in 48 of the posts users disguised

142
00:05:36,000 --> 00:05:38,000
protecting their own user probably their

143
00:05:38,000 --> 00:05:40,400
own privacy for example how can i

144
00:05:40,400 --> 00:05:43,039
protect my own privacy on github by

145
00:05:43,039 --> 00:05:45,600
removing my email address or my username

146
00:05:45,600 --> 00:05:47,039
from gitlogs

147
00:05:47,039 --> 00:05:50,160
and in 119 posts they discussed user

148
00:05:50,160 --> 00:05:51,440
privacy

149
00:05:51,440 --> 00:05:53,440
which is the focus of this study we

150
00:05:53,440 --> 00:05:55,600
extracted 148

151
00:05:55,600 --> 00:05:59,680
pieces of advice from these posts

152
00:05:59,919 --> 00:06:01,199
i'm going to briefly talk about the

153
00:06:01,199 --> 00:06:03,600
findings

154
00:06:03,600 --> 00:06:06,000
so first of all we mapped all those

155
00:06:06,000 --> 00:06:08,319
pieces of advice to privacy design

156
00:06:08,319 --> 00:06:09,520
strategies

157
00:06:09,520 --> 00:06:12,400
we found that in form and hide

158
00:06:12,400 --> 00:06:14,800
are the most commonly used strategies by

159
00:06:14,800 --> 00:06:17,440
developers for example trying to inform

160
00:06:17,440 --> 00:06:19,520
users about what kinds of data they're

161
00:06:19,520 --> 00:06:21,199
collecting and what they're doing with

162
00:06:21,199 --> 00:06:22,639
their data

163
00:06:22,639 --> 00:06:24,000
height means

164
00:06:24,000 --> 00:06:25,840
like for example using some encryption

165
00:06:25,840 --> 00:06:28,319
methods control means in addition to

166
00:06:28,319 --> 00:06:31,120
informing users they wanted to make sure

167
00:06:31,120 --> 00:06:33,759
that users are also given a choice and

168
00:06:33,759 --> 00:06:37,440
control over processing of their data

169
00:06:37,440 --> 00:06:39,199
minimize for example talks about

170
00:06:39,199 --> 00:06:41,120
minimizing data collection and

171
00:06:41,120 --> 00:06:43,759
interestingly we then observe abstract

172
00:06:43,759 --> 00:06:46,319
and separate coming up as much enforce

173
00:06:46,319 --> 00:06:48,479
and demonstrate the same they came up

174
00:06:48,479 --> 00:06:50,479
very rarely

175
00:06:50,479 --> 00:06:52,080
i'm going to talk about the implications

176
00:06:52,080 --> 00:06:55,359
of these in the next slides

177
00:06:55,759 --> 00:06:58,560
we also analyze the posts for generally

178
00:06:58,560 --> 00:07:00,319
the advice that developers give one

179
00:07:00,319 --> 00:07:03,039
another around privacy

180
00:07:03,039 --> 00:07:06,080
we found that mostly the advice

181
00:07:06,080 --> 00:07:08,160
is about making sure that they are

182
00:07:08,160 --> 00:07:10,080
compliant with the regulations and their

183
00:07:10,080 --> 00:07:13,280
consequences for example one user said

184
00:07:13,280 --> 00:07:15,840
before requesting permission you could

185
00:07:15,840 --> 00:07:18,560
display an alert that explains why are

186
00:07:18,560 --> 00:07:21,599
you going to request permission

187
00:07:21,599 --> 00:07:23,599
you can use whatever text you like in

188
00:07:23,599 --> 00:07:26,240
this alert

189
00:07:27,919 --> 00:07:30,800
and in the second group of advice they

190
00:07:30,800 --> 00:07:32,960
talked about ensuring confidentiality

191
00:07:32,960 --> 00:07:34,800
for example by using some sort of

192
00:07:34,800 --> 00:07:36,400
encryption

193
00:07:36,400 --> 00:07:39,199
for example one user said

194
00:07:39,199 --> 00:07:41,520
make sure you have set all applicable

195
00:07:41,520 --> 00:07:42,960
http

196
00:07:42,960 --> 00:07:44,639
security headers

197
00:07:44,639 --> 00:07:46,479
and if you are not already you should be

198
00:07:46,479 --> 00:07:51,120
using https even for a static site

199
00:07:53,039 --> 00:07:55,120
the third group of advice talked about

200
00:07:55,120 --> 00:07:57,840
avoiding data collection for example one

201
00:07:57,840 --> 00:07:59,120
user said

202
00:07:59,120 --> 00:08:01,599
there is one very simple way of avoiding

203
00:08:01,599 --> 00:08:03,520
all the negative consequences of

204
00:08:03,520 --> 00:08:06,560
third-party cookies don't have any

205
00:08:06,560 --> 00:08:09,199
it's possible to do a great many things

206
00:08:09,199 --> 00:08:10,479
without them

207
00:08:10,479 --> 00:08:12,639
it means that you may not need to

208
00:08:12,639 --> 00:08:14,960
display cookie notifications or seek

209
00:08:14,960 --> 00:08:16,879
consent

210
00:08:16,879 --> 00:08:19,280
so as you can see interestingly there

211
00:08:19,280 --> 00:08:21,520
are some really privacy conscience users

212
00:08:21,520 --> 00:08:23,120
on stack overflow

213
00:08:23,120 --> 00:08:25,599
who are suggesting others not to even

214
00:08:25,599 --> 00:08:27,759
collect data from the get-go because

215
00:08:27,759 --> 00:08:29,599
it's gonna make their life easier in the

216
00:08:29,599 --> 00:08:32,159
future because they don't need to

217
00:08:32,159 --> 00:08:34,559
take care of removing or storing the

218
00:08:34,559 --> 00:08:38,478
data in a privacy preserving manner

219
00:08:39,360 --> 00:08:42,240
and in the last group of advice

220
00:08:42,240 --> 00:08:43,839
they talked about understanding and

221
00:08:43,839 --> 00:08:46,800
reading more about third party services

222
00:08:46,800 --> 00:08:48,959
for example in this example

223
00:08:48,959 --> 00:08:52,000
the answerer posted a code snippet that

224
00:08:52,000 --> 00:08:55,200
helps the asker to find any code

225
00:08:55,200 --> 00:08:57,040
that uses location data in their

226
00:08:57,040 --> 00:08:58,720
application

227
00:08:58,720 --> 00:09:00,959
because the asker couldn't figure out

228
00:09:00,959 --> 00:09:03,440
why their app is using location data

229
00:09:03,440 --> 00:09:05,600
when they didn't when they didn't intend

230
00:09:05,600 --> 00:09:08,000
it to apparently somehow there was some

231
00:09:08,000 --> 00:09:09,680
location data being collected without

232
00:09:09,680 --> 00:09:11,760
the developer's knowledge

233
00:09:11,760 --> 00:09:13,680
so the answer is saying

234
00:09:13,680 --> 00:09:17,760
once you find the offending library lib

235
00:09:17,760 --> 00:09:19,680
you can try to figure out what purpose

236
00:09:19,680 --> 00:09:21,760
location data has been and then decide

237
00:09:21,760 --> 00:09:25,519
whether you can get rid of it

238
00:09:25,519 --> 00:09:27,600
as you can see third-party libraries and

239
00:09:27,600 --> 00:09:30,480
their privacy consequences can be very

240
00:09:30,480 --> 00:09:32,399
hard and tricky for developers to

241
00:09:32,399 --> 00:09:34,640
understand

242
00:09:34,640 --> 00:09:37,200
so as a takeaway we find that

243
00:09:37,200 --> 00:09:39,600
the most commonly applied privacy design

244
00:09:39,600 --> 00:09:42,240
strategies in our sample are in form and

245
00:09:42,240 --> 00:09:44,560
control

246
00:09:44,560 --> 00:09:46,560
we think that these are most commonly

247
00:09:46,560 --> 00:09:49,200
used because app stores and mobile

248
00:09:49,200 --> 00:09:50,560
operating systems

249
00:09:50,560 --> 00:09:53,360
specifically ios and android are mostly

250
00:09:53,360 --> 00:09:55,120
focused on consent

251
00:09:55,120 --> 00:09:57,279
which shows that the impact of app

252
00:09:57,279 --> 00:09:59,040
stores and operating systems on the

253
00:09:59,040 --> 00:10:00,480
developers community and their

254
00:10:00,480 --> 00:10:02,839
understanding around

255
00:10:02,839 --> 00:10:05,680
privacy did observe that some people

256
00:10:05,680 --> 00:10:08,160
talk about hide and minimize strategies

257
00:10:08,160 --> 00:10:10,160
we think that perhaps because height is

258
00:10:10,160 --> 00:10:12,000
slightly combined with security and

259
00:10:12,000 --> 00:10:13,920
encryption therefore it's used more

260
00:10:13,920 --> 00:10:15,839
often

261
00:10:15,839 --> 00:10:17,600
we did observe that the minimizer

262
00:10:17,600 --> 00:10:20,079
strategy used pretty often which is very

263
00:10:20,079 --> 00:10:22,399
interesting for us because it shows that

264
00:10:22,399 --> 00:10:24,720
people are actually actively advising

265
00:10:24,720 --> 00:10:26,560
each other about minimizing data

266
00:10:26,560 --> 00:10:29,839
collection from the get-go

267
00:10:30,480 --> 00:10:33,040
very few people talked about enforce and

268
00:10:33,040 --> 00:10:35,519
demonstrate we think that it might be

269
00:10:35,519 --> 00:10:37,920
because developers aren't asking a lot

270
00:10:37,920 --> 00:10:39,839
of organizational level questions on a

271
00:10:39,839 --> 00:10:41,279
stack overflow

272
00:10:41,279 --> 00:10:43,440
and perhaps these two strategies are

273
00:10:43,440 --> 00:10:45,760
more organizational level so we didn't

274
00:10:45,760 --> 00:10:48,000
observe those coming up in our sample as

275
00:10:48,000 --> 00:10:50,320
much

276
00:10:51,040 --> 00:10:52,800
discussions around how to do data

277
00:10:52,800 --> 00:10:55,519
abstraction and separate data processing

278
00:10:55,519 --> 00:10:58,480
were very rare

279
00:10:58,720 --> 00:11:01,040
which opens up a nice research direction

280
00:11:01,040 --> 00:11:02,800
for future to study

281
00:11:02,800 --> 00:11:04,720
why developers are not talking about

282
00:11:04,720 --> 00:11:06,079
these methods

283
00:11:06,079 --> 00:11:08,240
could it be because they aren't covered

284
00:11:08,240 --> 00:11:10,079
by the typical libraries and apis that

285
00:11:10,079 --> 00:11:12,560
developers use or perhaps they are not

286
00:11:12,560 --> 00:11:14,399
covered in the app stores and operating

287
00:11:14,399 --> 00:11:17,120
systems or maybe developers are not just

288
00:11:17,120 --> 00:11:18,800
aware of them as much as the other

289
00:11:18,800 --> 00:11:21,519
strategies so overall we think that

290
00:11:21,519 --> 00:11:22,959
future research

291
00:11:22,959 --> 00:11:24,959
is needed to find out how we can better

292
00:11:24,959 --> 00:11:26,959
support developers in applying and

293
00:11:26,959 --> 00:11:29,200
making use of all the available privacy

294
00:11:29,200 --> 00:11:30,320
enhancing

295
00:11:30,320 --> 00:11:32,560
methods

296
00:11:32,560 --> 00:11:35,440
through the research community

297
00:11:35,440 --> 00:11:39,240
thank you very much for listening

