1
00:00:00,320 --> 00:00:02,399
hello everyone i'm shujan from the

2
00:00:02,399 --> 00:00:05,200
technical university of munich today i'm

3
00:00:05,200 --> 00:00:06,600
going to present our work on

4
00:00:06,600 --> 00:00:08,639
privacy-preserving high-dimensional data

5
00:00:08,639 --> 00:00:10,480
collection with federated generative

6
00:00:10,480 --> 00:00:11,840
auto encoder

7
00:00:11,840 --> 00:00:13,759
this is joint work with steven joel from

8
00:00:13,759 --> 00:00:15,759
huawei munich research center and yes

9
00:00:15,759 --> 00:00:17,279
growth class from the technical

10
00:00:17,279 --> 00:00:19,600
university of munich

11
00:00:19,600 --> 00:00:22,080
in the era of big data large and diverse

12
00:00:22,080 --> 00:00:24,160
quantities of user data such as

13
00:00:24,160 --> 00:00:26,000
electronic health records and web

14
00:00:26,000 --> 00:00:27,840
browsing history are frequently

15
00:00:27,840 --> 00:00:30,720
generated on local devices this local

16
00:00:30,720 --> 00:00:32,880
data usually contain many attributes

17
00:00:32,880 --> 00:00:34,880
describing user profiles from different

18
00:00:34,880 --> 00:00:36,079
aspects

19
00:00:36,079 --> 00:00:37,920
collecting and analyzing the hidden

20
00:00:37,920 --> 00:00:39,920
correlations of this multi-dimensional

21
00:00:39,920 --> 00:00:42,320
data can help companies to obtain a

22
00:00:42,320 --> 00:00:44,719
deeper understanding of user groups and

23
00:00:44,719 --> 00:00:47,120
provide better services

24
00:00:47,120 --> 00:00:49,520
however the direct collection of raw

25
00:00:49,520 --> 00:00:51,680
user data may not only evaluate the

26
00:00:51,680 --> 00:00:54,160
increasingly strict privacy regulations

27
00:00:54,160 --> 00:00:56,079
but also lead to serious privacy

28
00:00:56,079 --> 00:00:57,680
accidents

29
00:00:57,680 --> 00:00:59,680
local differential privacy has been

30
00:00:59,680 --> 00:01:01,680
considered a state-of-the-art technique

31
00:01:01,680 --> 00:01:03,359
for data collection

32
00:01:03,359 --> 00:01:05,760
the definition of ldp states that a

33
00:01:05,760 --> 00:01:08,720
randomized mechanism m satisfies epsilon

34
00:01:08,720 --> 00:01:12,000
ldp if for energy inputs d and d prime

35
00:01:12,000 --> 00:01:14,320
the probability of outputting any value

36
00:01:14,320 --> 00:01:16,320
y is bounded by e to the power of

37
00:01:16,320 --> 00:01:17,360
epsilon

38
00:01:17,360 --> 00:01:19,439
here epsilon refers to the privacy

39
00:01:19,439 --> 00:01:21,920
budget the smaller epsilon the harder

40
00:01:21,920 --> 00:01:23,840
one can distinguish the input pair from

41
00:01:23,840 --> 00:01:26,720
the output and the stronger privacy

42
00:01:26,720 --> 00:01:29,119
in the data collection scenario applying

43
00:01:29,119 --> 00:01:31,200
ldp perturbation on the local side

44
00:01:31,200 --> 00:01:33,600
ensures that the server cannot infer the

45
00:01:33,600 --> 00:01:35,520
real user data from the perturbed

46
00:01:35,520 --> 00:01:38,240
results hence achieving strict privacy

47
00:01:38,240 --> 00:01:40,159
guarantees

48
00:01:40,159 --> 00:01:42,320
although ldp provides strong privacy

49
00:01:42,320 --> 00:01:44,640
protection for local data existing

50
00:01:44,640 --> 00:01:46,479
algorithms are not applicable to

51
00:01:46,479 --> 00:01:48,640
collecting high dimensional data the

52
00:01:48,640 --> 00:01:50,560
increase of attributes will not only

53
00:01:50,560 --> 00:01:52,240
result in a higher computational

54
00:01:52,240 --> 00:01:55,119
complexity but also significant decrease

55
00:01:55,119 --> 00:01:56,799
in data utility

56
00:01:56,799 --> 00:01:59,200
on the other hand in recent years many

57
00:01:59,200 --> 00:02:01,439
companies adopted deep generative models

58
00:02:01,439 --> 00:02:03,439
to learn the statistical properties of

59
00:02:03,439 --> 00:02:05,920
complex statuses and generates high

60
00:02:05,920 --> 00:02:08,160
utility synthetic data for building ai

61
00:02:08,160 --> 00:02:11,280
services however these applications only

62
00:02:11,280 --> 00:02:13,440
focus on the scenarios where the real

63
00:02:13,440 --> 00:02:15,920
data are already stored on the server

64
00:02:15,920 --> 00:02:18,239
yet do not consider the privacy issues

65
00:02:18,239 --> 00:02:19,840
in data collection

66
00:02:19,840 --> 00:02:22,000
therefore solutions for collecting high

67
00:02:22,000 --> 00:02:24,000
dimensional data with a good privacy

68
00:02:24,000 --> 00:02:28,239
utility balance are still greatly needed

69
00:02:28,239 --> 00:02:31,760
with this motivation we propose dpfedwa

70
00:02:31,760 --> 00:02:33,680
a privacy preserving framework for

71
00:02:33,680 --> 00:02:35,440
collecting high dimensional categorical

72
00:02:35,440 --> 00:02:36,400
data

73
00:02:36,400 --> 00:02:38,560
the main idea is to train a generative

74
00:02:38,560 --> 00:02:40,560
model in a private manner to learn the

75
00:02:40,560 --> 00:02:43,040
distributions of real local data and

76
00:02:43,040 --> 00:02:45,040
then generate high utility synthetic

77
00:02:45,040 --> 00:02:47,200
data on the server side

78
00:02:47,200 --> 00:02:49,760
the framework includes three key modules

79
00:02:49,760 --> 00:02:52,239
first we use the generative bus standard

80
00:02:52,239 --> 00:02:54,400
encoder for data synthesis

81
00:02:54,400 --> 00:02:56,480
moreover we train the model using the

82
00:02:56,480 --> 00:02:58,959
feather's learning mechanism which only

83
00:02:58,959 --> 00:03:01,200
exchanges model parameters and always

84
00:03:01,200 --> 00:03:03,760
keeps the real data on the local side

85
00:03:03,760 --> 00:03:06,239
finally we propose a novel randomization

86
00:03:06,239 --> 00:03:08,959
algorithm sandy s which provides strict

87
00:03:08,959 --> 00:03:11,360
ldp guarantees to the framework

88
00:03:11,360 --> 00:03:13,519
next we will introduce each module in

89
00:03:13,519 --> 00:03:15,120
detail

90
00:03:15,120 --> 00:03:17,040
in our framework we use the lesser

91
00:03:17,040 --> 00:03:19,120
sustained auto encoder as the generative

92
00:03:19,120 --> 00:03:20,000
model

93
00:03:20,000 --> 00:03:23,040
the wa model contains an encoder q which

94
00:03:23,040 --> 00:03:25,200
compresses the original high dimensional

95
00:03:25,200 --> 00:03:27,120
input x to a low dimensional latent

96
00:03:27,120 --> 00:03:30,480
feature set and a decoder g which maps

97
00:03:30,480 --> 00:03:33,519
that to the reconstructed output x prime

98
00:03:33,519 --> 00:03:36,319
x prime shares the same shape as x

99
00:03:36,319 --> 00:03:38,319
the loss function is comprised of two

100
00:03:38,319 --> 00:03:40,720
parts the reconstruction loss which

101
00:03:40,720 --> 00:03:42,640
measures the distance between the input

102
00:03:42,640 --> 00:03:45,200
x and output x prime and a latent

103
00:03:45,200 --> 00:03:47,440
penalty which quantifies the difference

104
00:03:47,440 --> 00:03:49,599
between the latent space distribution q

105
00:03:49,599 --> 00:03:51,760
set and a certain prior distribution

106
00:03:51,760 --> 00:03:52,959
pset

107
00:03:52,959 --> 00:03:55,439
here we set psets to follow the standard

108
00:03:55,439 --> 00:03:57,120
gaussian distribution

109
00:03:57,120 --> 00:03:59,120
the goal of training is to find an

110
00:03:59,120 --> 00:04:01,840
optimal set of parameters that minimizes

111
00:04:01,840 --> 00:04:03,519
the reconstruction loss while

112
00:04:03,519 --> 00:04:05,680
restricting a latent space to follow the

113
00:04:05,680 --> 00:04:08,239
prior distribution

114
00:04:08,239 --> 00:04:10,239
in order to prevent the server from

115
00:04:10,239 --> 00:04:12,640
accessing the real local data we propose

116
00:04:12,640 --> 00:04:14,400
to train the auto encoder using

117
00:04:14,400 --> 00:04:16,880
federated learning the training process

118
00:04:16,880 --> 00:04:18,399
goes as follows

119
00:04:18,399 --> 00:04:20,238
in each global round the server

120
00:04:20,238 --> 00:04:22,240
distributes the current global model to

121
00:04:22,240 --> 00:04:24,800
a group of local clients each client

122
00:04:24,800 --> 00:04:27,040
trades the model using his local data

123
00:04:27,040 --> 00:04:29,440
and computes the local update which will

124
00:04:29,440 --> 00:04:31,280
be returned to the server for updating

125
00:04:31,280 --> 00:04:32,880
the global model

126
00:04:32,880 --> 00:04:34,880
although federated learning successfully

127
00:04:34,880 --> 00:04:37,120
avoids the collection of real data

128
00:04:37,120 --> 00:04:39,440
recent studies point out that returning

129
00:04:39,440 --> 00:04:41,280
the local actives may still cause

130
00:04:41,280 --> 00:04:44,160
serious privacy leakage

131
00:04:44,160 --> 00:04:45,919
therefore we propose a novel

132
00:04:45,919 --> 00:04:48,160
randomization algorithm scientist to

133
00:04:48,160 --> 00:04:50,240
enhance privacy protection

134
00:04:50,240 --> 00:04:52,479
the main idea is that instead of sending

135
00:04:52,479 --> 00:04:54,800
the complete local update each client

136
00:04:54,800 --> 00:04:56,960
only returns the dimension index and

137
00:04:56,960 --> 00:04:59,759
update value of one important parameter

138
00:04:59,759 --> 00:05:01,919
the server can then use this information

139
00:05:01,919 --> 00:05:04,080
to construct the sparse local updates

140
00:05:04,080 --> 00:05:06,639
and to update the global model

141
00:05:06,639 --> 00:05:08,720
since the parameter information is still

142
00:05:08,720 --> 00:05:11,440
related to the local data our algorithm

143
00:05:11,440 --> 00:05:14,240
provides two-fold privacy protection

144
00:05:14,240 --> 00:05:16,560
first we replace the real update value

145
00:05:16,560 --> 00:05:19,199
with the sine value s which is randomly

146
00:05:19,199 --> 00:05:22,160
sampled by each client the sine value is

147
00:05:22,160 --> 00:05:24,639
further used to determine a top key set

148
00:05:24,639 --> 00:05:26,720
that contains the dimension indices of

149
00:05:26,720 --> 00:05:29,280
the k in most updated parameters

150
00:05:29,280 --> 00:05:31,600
if the sign equals 1 we select the

151
00:05:31,600 --> 00:05:34,160
indices of the k largest values

152
00:05:34,160 --> 00:05:36,560
otherwise we select the indexes of the k

153
00:05:36,560 --> 00:05:38,400
smallest values

154
00:05:38,400 --> 00:05:40,720
next we apply a private dimension

155
00:05:40,720 --> 00:05:42,960
selection algorithm where the dimension

156
00:05:42,960 --> 00:05:45,280
index j can either be selected from the

157
00:05:45,280 --> 00:05:48,000
top key set with a probability of p or

158
00:05:48,000 --> 00:05:50,000
be selected from the non-topic set with

159
00:05:50,000 --> 00:05:52,479
a probability of one minus p

160
00:05:52,479 --> 00:05:54,639
we prove that the algorithm satisfies

161
00:05:54,639 --> 00:05:56,800
epsilon ldp guarantees

162
00:05:56,800 --> 00:05:58,960
finally the random sign value and the

163
00:05:58,960 --> 00:06:01,440
private dimension index will be returned

164
00:06:01,440 --> 00:06:02,720
to the server

165
00:06:02,720 --> 00:06:04,720
we refer the audience to check section

166
00:06:04,720 --> 00:06:07,120
3.2 for more details

167
00:06:07,120 --> 00:06:08,880
by summarizing the above design

168
00:06:08,880 --> 00:06:11,120
considerations we present the overall

169
00:06:11,120 --> 00:06:14,160
workflow of our framework first the we

170
00:06:14,160 --> 00:06:16,000
model is trained between the server and

171
00:06:16,000 --> 00:06:17,840
clients and the feathers learning to

172
00:06:17,840 --> 00:06:19,919
learn the statistical distributions of

173
00:06:19,919 --> 00:06:23,199
real local data additionally the sign ds

174
00:06:23,199 --> 00:06:25,600
algorithm is applied to prevent privacy

175
00:06:25,600 --> 00:06:28,080
leakage from the real local updates

176
00:06:28,080 --> 00:06:30,560
on the server side the dimension indices

177
00:06:30,560 --> 00:06:32,800
and sine values are used to update the

178
00:06:32,800 --> 00:06:35,360
global model the training process is

179
00:06:35,360 --> 00:06:37,680
repeated for several global rounds until

180
00:06:37,680 --> 00:06:40,240
the wee model achieves the satisfactory

181
00:06:40,240 --> 00:06:41,600
performance

182
00:06:41,600 --> 00:06:43,680
after the model is trained we use the

183
00:06:43,680 --> 00:06:45,360
decoder part for generating the

184
00:06:45,360 --> 00:06:46,880
synthetic data

185
00:06:46,880 --> 00:06:49,039
since the latent space distribution is

186
00:06:49,039 --> 00:06:50,720
restricted to follow the prior

187
00:06:50,720 --> 00:06:53,280
distribution we can simply sample random

188
00:06:53,280 --> 00:06:55,120
latent features from the prior

189
00:06:55,120 --> 00:06:57,120
distribution and feed them into the

190
00:06:57,120 --> 00:07:00,000
decoder to produce the synthetic data

191
00:07:00,000 --> 00:07:02,160
the generated data can then be used for

192
00:07:02,160 --> 00:07:04,080
downstream data mining and model

193
00:07:04,080 --> 00:07:05,520
training tasks

194
00:07:05,520 --> 00:07:07,599
we evaluate our framework from both

195
00:07:07,599 --> 00:07:10,319
utility and privacy aspects using four

196
00:07:10,319 --> 00:07:12,080
open source datasets

197
00:07:12,080 --> 00:07:14,160
for the utility evaluation we

198
00:07:14,160 --> 00:07:16,240
investigate whether the synthetic data

199
00:07:16,240 --> 00:07:18,639
preserves similar statistical properties

200
00:07:18,639 --> 00:07:21,039
as real data and can support ai training

201
00:07:21,039 --> 00:07:22,000
tasks

202
00:07:22,000 --> 00:07:24,240
for the privacy evaluation we use the

203
00:07:24,240 --> 00:07:26,479
membership inference attack to analyze

204
00:07:26,479 --> 00:07:28,400
whether the synthetic data can reveal

205
00:07:28,400 --> 00:07:30,400
privacy of real data

206
00:07:30,400 --> 00:07:32,240
we compare the framework's performance

207
00:07:32,240 --> 00:07:34,400
with two baseline algorithms both

208
00:07:34,400 --> 00:07:36,400
algorithms directly apply ldp

209
00:07:36,400 --> 00:07:38,560
perturbation on the real local data

210
00:07:38,560 --> 00:07:40,319
where the privacy budget is evenly

211
00:07:40,319 --> 00:07:42,960
allocated to all the attributes

212
00:07:42,960 --> 00:07:45,199
we first used the average variation

213
00:07:45,199 --> 00:07:47,280
distance to compare the multivariate

214
00:07:47,280 --> 00:07:50,000
distributions of real and synthetic data

215
00:07:50,000 --> 00:07:52,080
the figures show the results of four-way

216
00:07:52,080 --> 00:07:54,800
avd under different privacy levels

217
00:07:54,800 --> 00:07:57,360
it can be seen that the evd decreases

218
00:07:57,360 --> 00:07:59,120
with the increase of privacy budget

219
00:07:59,120 --> 00:08:01,440
epsilon and our framework generally

220
00:08:01,440 --> 00:08:03,680
achieves a smaller led compared to

221
00:08:03,680 --> 00:08:04,960
baselines

222
00:08:04,960 --> 00:08:07,280
this indicates that the synthetic data

223
00:08:07,280 --> 00:08:09,599
generated by our framework can preserve

224
00:08:09,599 --> 00:08:11,759
better multivariate distributions in

225
00:08:11,759 --> 00:08:13,120
real data

226
00:08:13,120 --> 00:08:15,919
moreover we find that for our framework

227
00:08:15,919 --> 00:08:17,840
choosing different top key ratio alpha

228
00:08:17,840 --> 00:08:20,879
may slightly impact the data utility

229
00:08:20,879 --> 00:08:22,560
according to the dimension selection

230
00:08:22,560 --> 00:08:25,280
probability the alpha is inversely

231
00:08:25,280 --> 00:08:26,960
proportional to e to the power of

232
00:08:26,960 --> 00:08:29,759
epsilon therefore the optimal choice of

233
00:08:29,759 --> 00:08:31,840
the top key ratio alpha is in general

234
00:08:31,840 --> 00:08:34,159
negatively correlated with the privacy

235
00:08:34,159 --> 00:08:36,159
budget

236
00:08:36,159 --> 00:08:38,240
next we investigate whether the

237
00:08:38,240 --> 00:08:39,760
synthetic data have similar

238
00:08:39,760 --> 00:08:41,760
cross-attribute correlations to real

239
00:08:41,760 --> 00:08:44,640
data to this end we randomly pick 10

240
00:08:44,640 --> 00:08:46,560
attributes for each data set and

241
00:08:46,560 --> 00:08:48,480
visualize the correlation heat maps of

242
00:08:48,480 --> 00:08:50,880
both real and synthetic data

243
00:08:50,880 --> 00:08:53,200
from the results it can be seen that the

244
00:08:53,200 --> 00:08:55,200
correlation heat maps are very similar

245
00:08:55,200 --> 00:08:57,440
to each other which again demonstrates

246
00:08:57,440 --> 00:08:59,760
that the synthetic data can preserve the

247
00:08:59,760 --> 00:09:01,920
statistical properties of real data

248
00:09:01,920 --> 00:09:03,360
quite well

249
00:09:03,360 --> 00:09:06,240
finally we evaluate the data utility in

250
00:09:06,240 --> 00:09:08,959
ai training tasks to this end we train

251
00:09:08,959 --> 00:09:11,200
two classification models respectively

252
00:09:11,200 --> 00:09:13,519
with real and synthetic data and test

253
00:09:13,519 --> 00:09:15,519
the models with a set of held out real

254
00:09:15,519 --> 00:09:18,240
data the figures show the test accuracy

255
00:09:18,240 --> 00:09:20,320
and the different privacy levels

256
00:09:20,320 --> 00:09:22,240
it can be seen that our framework

257
00:09:22,240 --> 00:09:24,560
consistently show a better test accuracy

258
00:09:24,560 --> 00:09:26,320
compared to the baselines

259
00:09:26,320 --> 00:09:28,800
particularly when epstein equals eight

260
00:09:28,800 --> 00:09:30,959
the models trained with synthetic data

261
00:09:30,959 --> 00:09:32,720
only yield one to three percent of

262
00:09:32,720 --> 00:09:34,320
accuracy loss

263
00:09:34,320 --> 00:09:36,560
the results show that the synthetic data

264
00:09:36,560 --> 00:09:38,480
can effectively capture the hidden

265
00:09:38,480 --> 00:09:40,800
patterns of real data and can be used

266
00:09:40,800 --> 00:09:42,959
for ai training tasks

267
00:09:42,959 --> 00:09:45,519
in section 5.2 we also show that

268
00:09:45,519 --> 00:09:48,080
pre-training the wa model can further

269
00:09:48,080 --> 00:09:51,279
improve the classification accuracy

270
00:09:51,279 --> 00:09:53,920
besides utility evaluation we further

271
00:09:53,920 --> 00:09:55,680
performed the membership influence

272
00:09:55,680 --> 00:09:57,680
attack to verify the privacy of our

273
00:09:57,680 --> 00:09:59,839
framework we followed the attack

274
00:09:59,839 --> 00:10:02,480
proposed by state letter where a privacy

275
00:10:02,480 --> 00:10:04,640
adversary aims to use a published

276
00:10:04,640 --> 00:10:07,040
synthetic data set to infer whether a

277
00:10:07,040 --> 00:10:09,040
target record was used to train the

278
00:10:09,040 --> 00:10:11,920
generative model to perform the attack

279
00:10:11,920 --> 00:10:14,320
it is assumed that the adversary has a

280
00:10:14,320 --> 00:10:16,720
reference data set which shares the same

281
00:10:16,720 --> 00:10:19,600
distribution as real data the adversary

282
00:10:19,600 --> 00:10:21,920
respectively trains a pair of generative

283
00:10:21,920 --> 00:10:24,240
models g-in and g-out using the

284
00:10:24,240 --> 00:10:26,320
reference data set with and without a

285
00:10:26,320 --> 00:10:27,839
target record

286
00:10:27,839 --> 00:10:30,399
then the synthetic datasets generated by

287
00:10:30,399 --> 00:10:33,360
both models will be labeled and used to

288
00:10:33,360 --> 00:10:35,519
train an attack model which can be

289
00:10:35,519 --> 00:10:38,560
regarded as a binary classification task

290
00:10:38,560 --> 00:10:40,959
finally given the published synthetic

291
00:10:40,959 --> 00:10:43,360
data set the adversary can use the

292
00:10:43,360 --> 00:10:45,920
attack model to infer the membership of

293
00:10:45,920 --> 00:10:47,680
the target record

294
00:10:47,680 --> 00:10:50,160
here we report the attack accuracy of

295
00:10:50,160 --> 00:10:52,000
the four data sets and the different

296
00:10:52,000 --> 00:10:53,519
privacy levels

297
00:10:53,519 --> 00:10:55,600
it can be seen that simply training the

298
00:10:55,600 --> 00:10:57,920
generative model without any protection

299
00:10:57,920 --> 00:11:00,399
may still cause privacy leakage where

300
00:11:00,399 --> 00:11:02,720
the attack accuracy of all the data sets

301
00:11:02,720 --> 00:11:04,320
is more than 60

302
00:11:04,320 --> 00:11:06,079
and even more than 70

303
00:11:06,079 --> 00:11:08,079
for the census data set

304
00:11:08,079 --> 00:11:10,079
on the other hand applying differential

305
00:11:10,079 --> 00:11:12,079
privacy can effectively reduce the

306
00:11:12,079 --> 00:11:13,680
attack accuracy

307
00:11:13,680 --> 00:11:15,760
when epsilon equals 8 the attack

308
00:11:15,760 --> 00:11:19,040
accuracy is reduced by 8 to 15 percent

309
00:11:19,040 --> 00:11:21,760
when epsilon equals 0.5 the attack

310
00:11:21,760 --> 00:11:25,440
accuracy is even close to random gases

311
00:11:25,440 --> 00:11:28,000
in conclusion in this paper we proposed

312
00:11:28,000 --> 00:11:30,800
dpfed wae an efficient and privacy

313
00:11:30,800 --> 00:11:32,800
preserving framework for collecting high

314
00:11:32,800 --> 00:11:34,880
dimensional categorical data

315
00:11:34,880 --> 00:11:37,120
we further proposed 9ds a novel

316
00:11:37,120 --> 00:11:39,200
randomization algorithm to provide

317
00:11:39,200 --> 00:11:40,800
strict local differential privacy

318
00:11:40,800 --> 00:11:42,800
guarantees to the framework

319
00:11:42,800 --> 00:11:44,800
finally we conduct the extensive

320
00:11:44,800 --> 00:11:47,279
evaluation experiments and show that our

321
00:11:47,279 --> 00:11:49,200
framework can enjoy a satisfactory

322
00:11:49,200 --> 00:11:51,360
privacy utility balance and the

323
00:11:51,360 --> 00:11:53,600
generated synthetic data can replace

324
00:11:53,600 --> 00:11:55,680
real data for downstream data mining and

325
00:11:55,680 --> 00:11:57,839
ai training tasks thank you for

326
00:11:57,839 --> 00:12:00,560
listening

