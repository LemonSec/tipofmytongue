1
00:00:00,120 --> 00:00:01,920
thank you everyone for attending this

2
00:00:01,920 --> 00:00:03,899
talk today I will be telling you about

3
00:00:03,899 --> 00:00:06,180
private aggregation of trajectories and

4
00:00:06,180 --> 00:00:07,799
this job working but you can see new

5
00:00:07,799 --> 00:00:10,559
camera Ravi Kuma and Anika Chang

6
00:00:10,559 --> 00:00:13,200
in the trajectory aggregation problem

7
00:00:13,200 --> 00:00:15,719
we are given multiple trajectories as

8
00:00:15,719 --> 00:00:17,100
input

9
00:00:17,100 --> 00:00:18,720
and our algorithm would like to

10
00:00:18,720 --> 00:00:21,000
aggregate them into a single trajectory

11
00:00:21,000 --> 00:00:25,260
that will represent the input

12
00:00:25,260 --> 00:00:27,779
as trajectories are some of the most

13
00:00:27,779 --> 00:00:30,840
basic special or temporary data

14
00:00:30,840 --> 00:00:34,260
this problem has multiple applications

15
00:00:34,260 --> 00:00:36,899
for example each trajectory may

16
00:00:36,899 --> 00:00:37,920
represent

17
00:00:37,920 --> 00:00:40,260
users travel path

18
00:00:40,260 --> 00:00:43,519
collected via GPS

19
00:00:43,800 --> 00:00:46,140
aggregating these paths can help us

20
00:00:46,140 --> 00:00:49,379
discover public transit routes

21
00:00:49,379 --> 00:00:54,239
or common travel paths

22
00:00:54,239 --> 00:00:56,940
however in such applications

23
00:00:56,940 --> 00:00:59,820
trajectories can be sensitive as it

24
00:00:59,820 --> 00:01:02,640
contains user location data

25
00:01:02,640 --> 00:01:04,799
and we want to make sure that our

26
00:01:04,799 --> 00:01:08,760
algorithm respect the user's privacy

27
00:01:08,760 --> 00:01:11,159
the notion we use for privacy here is

28
00:01:11,159 --> 00:01:13,140
differential privacy

29
00:01:13,140 --> 00:01:16,799
roughly speaking it says that adding or

30
00:01:16,799 --> 00:01:19,860
removing a single user shouldn't affect

31
00:01:19,860 --> 00:01:22,340
the algorithm output too much

32
00:01:22,340 --> 00:01:25,380
specifically the output distribution of

33
00:01:25,380 --> 00:01:28,380
the algorithm shouldn't change too much

34
00:01:28,380 --> 00:01:31,380
this is parameterized by two parameter

35
00:01:31,380 --> 00:01:33,780
Epsilon and Delta

36
00:01:33,780 --> 00:01:35,159
and for those who haven't seen

37
00:01:35,159 --> 00:01:37,560
differential privacy before you should

38
00:01:37,560 --> 00:01:39,659
think of Epsilon as being a small

39
00:01:39,659 --> 00:01:43,740
constant and Delta being negligible in

40
00:01:43,740 --> 00:01:46,820
the number of trajectories

41
00:01:48,060 --> 00:01:52,020
throughout our work we make several

42
00:01:52,020 --> 00:01:55,140
assumptions for example we assume that

43
00:01:55,140 --> 00:01:59,159
each trajectory is a polyline resulting

44
00:01:59,159 --> 00:02:02,100
from joining of the same number of

45
00:02:02,100 --> 00:02:03,659
points M

46
00:02:03,659 --> 00:02:06,180
and furthermore we assume that these

47
00:02:06,180 --> 00:02:09,119
trajectories are in sync understand that

48
00:02:09,119 --> 00:02:12,000
the Jade point of each trajectory

49
00:02:12,000 --> 00:02:15,540
corresponds to the same section of the

50
00:02:15,540 --> 00:02:18,720
underlying trajectory

51
00:02:18,720 --> 00:02:21,360
I would not go into more details on

52
00:02:21,360 --> 00:02:25,080
formal ideas assumptions more but in our

53
00:02:25,080 --> 00:02:27,900
full paper we have a formalization of

54
00:02:27,900 --> 00:02:30,360
this under which we can prove some

55
00:02:30,360 --> 00:02:35,300
performance guarantee of our algorithms

56
00:02:35,459 --> 00:02:38,340
a principal way to achieve differential

57
00:02:38,340 --> 00:02:42,300
privacy is to add noise to the output

58
00:02:42,300 --> 00:02:44,700
and our algorithm we will also employ

59
00:02:44,700 --> 00:02:47,700
this strategy as well specifically we

60
00:02:47,700 --> 00:02:50,400
will use as subroutine the so-called

61
00:02:50,400 --> 00:02:52,260
gaussian mechanism

62
00:02:52,260 --> 00:02:54,840
these are very generic mechanism that

63
00:02:54,840 --> 00:02:58,140
applies to any function whose range is

64
00:02:58,140 --> 00:03:00,659
in R to the D

65
00:03:00,659 --> 00:03:03,239
and it is very simple instead of

66
00:03:03,239 --> 00:03:06,420
outputting the function FX value

67
00:03:06,420 --> 00:03:11,040
directly we output FX plus some noise C

68
00:03:11,040 --> 00:03:13,140
which is drawn from the spherical

69
00:03:13,140 --> 00:03:15,180
gaussian distribution

70
00:03:15,180 --> 00:03:19,140
scaled by a factor of Sigma

71
00:03:19,140 --> 00:03:21,540
now there is a question of how to set

72
00:03:21,540 --> 00:03:24,060
Sigma such that we achieve Epsilon Delta

73
00:03:24,060 --> 00:03:25,980
differential privacy

74
00:03:25,980 --> 00:03:28,379
obviously Sigma will have to depend on

75
00:03:28,379 --> 00:03:31,080
Epsilon and Delta but it also depends on

76
00:03:31,080 --> 00:03:33,659
another important parameter which is the

77
00:03:33,659 --> 00:03:36,360
sensitivity of f

78
00:03:36,360 --> 00:03:39,239
the sensitivity of f is defined as the

79
00:03:39,239 --> 00:03:40,319
maximum

80
00:03:40,319 --> 00:03:41,760
of the

81
00:03:41,760 --> 00:03:45,000
L2 Norm of the difference between f x

82
00:03:45,000 --> 00:03:48,480
and f x Prime where X and X Prime are

83
00:03:48,480 --> 00:03:49,920
ranging over

84
00:03:49,920 --> 00:03:53,519
all the input data sets that differ on a

85
00:03:53,519 --> 00:03:56,400
single user or in our work as a single

86
00:03:56,400 --> 00:03:58,939
trajectory

87
00:03:59,400 --> 00:04:02,760
it is known that we have to add noise

88
00:04:02,760 --> 00:04:04,620
that scale proportionally to the

89
00:04:04,620 --> 00:04:07,799
sensitivity to achieve Epsilon Delta DP

90
00:04:07,799 --> 00:04:10,920
now let us get back from this generic

91
00:04:10,920 --> 00:04:13,140
gaussian mechanism to our trajectory

92
00:04:13,140 --> 00:04:15,420
aggregation problem

93
00:04:15,420 --> 00:04:17,699
suppose we want to apply the gaussian

94
00:04:17,699 --> 00:04:19,440
mechanism to our problem

95
00:04:19,440 --> 00:04:21,720
what should we do

96
00:04:21,720 --> 00:04:25,320
first we have to select our function f

97
00:04:25,320 --> 00:04:28,380
now there are multiple ways to define

98
00:04:28,380 --> 00:04:30,780
the function f for aggregating

99
00:04:30,780 --> 00:04:33,660
trajectory in our paper we use perhaps

100
00:04:33,660 --> 00:04:35,220
the most basic

101
00:04:35,220 --> 00:04:38,040
function which is to average all the

102
00:04:38,040 --> 00:04:42,500
input trajectories Point by point

103
00:04:42,960 --> 00:04:45,120
next we have to answer what is the

104
00:04:45,120 --> 00:04:47,340
sensitivity of f so that we know how

105
00:04:47,340 --> 00:04:49,919
much noise to add

106
00:04:49,919 --> 00:04:52,800
and in general it is not obvious because

107
00:04:52,800 --> 00:04:54,960
different data set will result in

108
00:04:54,960 --> 00:04:56,940
different trajectory

109
00:04:56,940 --> 00:04:59,520
but often the sensitivity can be

110
00:04:59,520 --> 00:05:02,720
inferred from the input domain

111
00:05:02,720 --> 00:05:05,340
specifically if we know that the inputs

112
00:05:05,340 --> 00:05:07,979
are location data then we know that each

113
00:05:07,979 --> 00:05:10,560
point in the trajectory is within a ball

114
00:05:10,560 --> 00:05:14,160
of radius R where R is the radius of the

115
00:05:14,160 --> 00:05:16,020
Earth

116
00:05:16,020 --> 00:05:19,979
this is Illustrated below here

117
00:05:19,979 --> 00:05:24,180
we call such a radius such a bounding

118
00:05:24,180 --> 00:05:27,900
Circle A trivial bounding Circle

119
00:05:27,900 --> 00:05:29,759
which is the one that we can infer

120
00:05:29,759 --> 00:05:33,539
directly from the data format

121
00:05:33,539 --> 00:05:36,180
now if we know that each point is within

122
00:05:36,180 --> 00:05:39,419
radius R of the origin

123
00:05:39,419 --> 00:05:42,600
then since there are employed in each

124
00:05:42,600 --> 00:05:45,060
trajectory we can compute the

125
00:05:45,060 --> 00:05:48,300
sensitivity of the averaging function to

126
00:05:48,300 --> 00:05:48,960
be

127
00:05:48,960 --> 00:05:52,020
R Times Square Root M over n

128
00:05:52,020 --> 00:05:54,419
and if we add noise according to this

129
00:05:54,419 --> 00:05:56,819
sensitivity and the formula from the

130
00:05:56,819 --> 00:05:59,940
previous slide then we would get our

131
00:05:59,940 --> 00:06:02,100
differentially private trajectory

132
00:06:02,100 --> 00:06:04,759
aggregation

133
00:06:04,800 --> 00:06:07,259
and this is indeed our first bed line

134
00:06:07,259 --> 00:06:09,360
which we call the trivial bounding

135
00:06:09,360 --> 00:06:12,139
Circle algorithm

136
00:06:12,360 --> 00:06:14,940
now while this is okay

137
00:06:14,940 --> 00:06:18,120
it's still not the best we can do

138
00:06:18,120 --> 00:06:20,819
specifically the trivial bounding Circle

139
00:06:20,819 --> 00:06:24,780
can be much larger than the area in

140
00:06:24,780 --> 00:06:27,720
which the trajectories actually reside

141
00:06:27,720 --> 00:06:31,440
for example in this case if we were told

142
00:06:31,440 --> 00:06:34,380
this red circle which contains all the

143
00:06:34,380 --> 00:06:36,479
input trajectory

144
00:06:36,479 --> 00:06:38,580
then we would be able to add noise

145
00:06:38,580 --> 00:06:40,860
proportional to the radius of this

146
00:06:40,860 --> 00:06:42,600
circle

147
00:06:42,600 --> 00:06:44,819
which can be much smaller than the

148
00:06:44,819 --> 00:06:48,960
trivial Circle that we used earlier

149
00:06:48,960 --> 00:06:52,319
such a red circle will be called the

150
00:06:52,319 --> 00:06:54,300
global bonding Circle

151
00:06:54,300 --> 00:06:56,880
unfortunately the global warning Circle

152
00:06:56,880 --> 00:07:00,780
may not be possible to infer from the

153
00:07:00,780 --> 00:07:03,060
data format alone

154
00:07:03,060 --> 00:07:04,860
and therefore we have to look at the

155
00:07:04,860 --> 00:07:06,120
data

156
00:07:06,120 --> 00:07:09,060
themselves in order to find the global

157
00:07:09,060 --> 00:07:10,979
mounting Circle

158
00:07:10,979 --> 00:07:13,620
but since our data is sensitive we have

159
00:07:13,620 --> 00:07:16,199
to do this privately

160
00:07:16,199 --> 00:07:19,259
and the way we do it is as follows

161
00:07:19,259 --> 00:07:22,199
first we use the so-called sparse Vector

162
00:07:22,199 --> 00:07:26,639
technique to compute the radius and we

163
00:07:26,639 --> 00:07:28,380
will not go into the details here but

164
00:07:28,380 --> 00:07:31,199
sparse Vector technique is again a noisy

165
00:07:31,199 --> 00:07:33,060
mechanism that is smart in the sense

166
00:07:33,060 --> 00:07:34,680
that it adds a little bit less noise

167
00:07:34,680 --> 00:07:35,639
than

168
00:07:35,639 --> 00:07:38,580
what we would have done trivially

169
00:07:38,580 --> 00:07:42,419
once we have the radius we then divide

170
00:07:42,419 --> 00:07:46,259
the region into grid cells and compute

171
00:07:46,259 --> 00:07:48,900
the noisy histogram on the number of

172
00:07:48,900 --> 00:07:52,860
trajectories in each grid cells

173
00:07:52,860 --> 00:07:55,199
then we pick the grid cell with largest

174
00:07:55,199 --> 00:07:58,800
noise count and then we let our Global

175
00:07:58,800 --> 00:08:01,440
bonding Circle be the smallest bonding

176
00:08:01,440 --> 00:08:04,080
Circle containing the cell

177
00:08:04,080 --> 00:08:06,060
so this gives us the global bonding

178
00:08:06,060 --> 00:08:09,360
Circle which we can then use to add less

179
00:08:09,360 --> 00:08:12,419
noise than the to rear bounding Circle

180
00:08:12,419 --> 00:08:15,720
and this is our second base line

181
00:08:15,720 --> 00:08:17,879
again this is an improvement over the

182
00:08:17,879 --> 00:08:20,340
previous bed line but it turns out that

183
00:08:20,340 --> 00:08:23,460
it's not the best we can do

184
00:08:23,460 --> 00:08:25,979
to see how we can improve it lets us

185
00:08:25,979 --> 00:08:30,060
zoom in into this Global bonding Circle

186
00:08:30,060 --> 00:08:32,880
recall that we averaged the trajectories

187
00:08:32,880 --> 00:08:35,880
point by point which means that we start

188
00:08:35,880 --> 00:08:38,399
by averaging only these three first

189
00:08:38,399 --> 00:08:39,599
points

190
00:08:39,599 --> 00:08:43,440
these points are in a bounding Circle

191
00:08:43,440 --> 00:08:45,600
which is much smaller than the global

192
00:08:45,600 --> 00:08:46,920
bounding Circle

193
00:08:46,920 --> 00:08:49,320
this new bunny Circle we call it a local

194
00:08:49,320 --> 00:08:52,080
bonding Circle again if we know this

195
00:08:52,080 --> 00:08:53,940
local bounding Circle we can add noise

196
00:08:53,940 --> 00:08:56,820
proportional to its radius instead of

197
00:08:56,820 --> 00:08:58,920
the radius of the global bonding Circle

198
00:08:58,920 --> 00:09:02,459
so we will end up with much less noise

199
00:09:02,459 --> 00:09:05,040
and this is the main underpinning idea

200
00:09:05,040 --> 00:09:07,560
of our final algorithm

201
00:09:07,560 --> 00:09:10,320
which keeps this local bounding Circle

202
00:09:10,320 --> 00:09:13,140
and advances along the track as we build

203
00:09:13,140 --> 00:09:15,180
the aggregated track

204
00:09:15,180 --> 00:09:18,480
more specifically it works as follow we

205
00:09:18,480 --> 00:09:21,720
start by finding the initial local

206
00:09:21,720 --> 00:09:23,459
bounding Circle

207
00:09:23,459 --> 00:09:25,860
by running the previous

208
00:09:25,860 --> 00:09:28,260
algorithm for finding a global bounding

209
00:09:28,260 --> 00:09:31,200
Circle but instead of for all points in

210
00:09:31,200 --> 00:09:33,360
the trajectory we only run it for the

211
00:09:33,360 --> 00:09:37,500
first two points in the trajectories

212
00:09:37,500 --> 00:09:40,620
and then we repeat the following we use

213
00:09:40,620 --> 00:09:43,140
the local bounding Circle to compute the

214
00:09:43,140 --> 00:09:45,660
noisy aggregate of the current points

215
00:09:45,660 --> 00:09:48,360
and then remove the local bounding

216
00:09:48,360 --> 00:09:52,140
Circle Center to this noisy average and

217
00:09:52,140 --> 00:09:54,779
then at once along as we construct our

218
00:09:54,779 --> 00:09:56,279
solution

219
00:09:56,279 --> 00:09:58,080
so let's see this algorithm in action

220
00:09:58,080 --> 00:10:01,320
suppose that we have take the noisy

221
00:10:01,320 --> 00:10:03,000
average of the first three points and

222
00:10:03,000 --> 00:10:05,459
this is our center for the local

223
00:10:05,459 --> 00:10:07,019
bounding box

224
00:10:07,019 --> 00:10:09,000
next we want to average these three

225
00:10:09,000 --> 00:10:11,399
points so we use this local bounding box

226
00:10:11,399 --> 00:10:13,100
and then we compute a noisy average

227
00:10:13,100 --> 00:10:15,540
suppose that this is the new noisy

228
00:10:15,540 --> 00:10:16,440
average

229
00:10:16,440 --> 00:10:19,260
we then move the local bounding box to

230
00:10:19,260 --> 00:10:20,820
this noisy average

231
00:10:20,820 --> 00:10:23,519
and then we compute the average of the

232
00:10:23,519 --> 00:10:25,320
next three points

233
00:10:25,320 --> 00:10:27,720
and then we move this along

234
00:10:27,720 --> 00:10:29,220
but now it is example something

235
00:10:29,220 --> 00:10:31,440
interesting happened the next three

236
00:10:31,440 --> 00:10:33,959
points that we want to aggregate are

237
00:10:33,959 --> 00:10:35,880
actually outside of the box

238
00:10:35,880 --> 00:10:37,980
and this is something I have caused over

239
00:10:37,980 --> 00:10:41,839
earlier but this issue can be

240
00:10:41,839 --> 00:10:45,060
overcome by projecting these points onto

241
00:10:45,060 --> 00:10:47,220
the bounding Circle and compute the

242
00:10:47,220 --> 00:10:48,420
noisy average

243
00:10:48,420 --> 00:10:51,720
this ensures that the sensitivity is

244
00:10:51,720 --> 00:10:53,700
bounded as V1

245
00:10:53,700 --> 00:10:55,980
and we continue doing this until we get

246
00:10:55,980 --> 00:10:58,740
all the noisy averages and then we link

247
00:10:58,740 --> 00:11:01,980
them up to form our output trajectory

248
00:11:01,980 --> 00:11:06,019
and that's it that's our algorithm

249
00:11:06,060 --> 00:11:08,399
we evaluate our algorithms on multiple

250
00:11:08,399 --> 00:11:10,800
data set including one containing

251
00:11:10,800 --> 00:11:13,560
migration route of pigeons another fun

252
00:11:13,560 --> 00:11:16,320
training Strokes of characters and

253
00:11:16,320 --> 00:11:19,860
another containing DBS bus route

254
00:11:19,860 --> 00:11:23,399
in all cases our takeaway is that the

255
00:11:23,399 --> 00:11:25,920
global bounding Circle indeed gives uh

256
00:11:25,920 --> 00:11:28,079
an improvement over the trivial burning

257
00:11:28,079 --> 00:11:30,420
Circle and the local bounding Circle

258
00:11:30,420 --> 00:11:33,360
also achieve a noticeable improvement

259
00:11:33,360 --> 00:11:36,540
over the global bonding Circle

260
00:11:36,540 --> 00:11:38,760
all right let me end by mentioning two

261
00:11:38,760 --> 00:11:41,399
open questions one is that since our

262
00:11:41,399 --> 00:11:43,920
algorithm is just averaging Point by

263
00:11:43,920 --> 00:11:46,320
point it's not very robust towards track

264
00:11:46,320 --> 00:11:49,260
that have different links or are not in

265
00:11:49,260 --> 00:11:51,660
sync it would be nice to have an

266
00:11:51,660 --> 00:11:53,820
algorithm that is more robust towards

267
00:11:53,820 --> 00:11:55,200
these issues

268
00:11:55,200 --> 00:11:57,959
another is that there are non-private

269
00:11:57,959 --> 00:12:01,019
algorithms with theoretical guarantees

270
00:12:01,019 --> 00:12:02,959
for certain

271
00:12:02,959 --> 00:12:06,600
objective functions it would be nice to

272
00:12:06,600 --> 00:12:08,579
make them work in their private setting

273
00:12:08,579 --> 00:12:09,959
as well

274
00:12:09,959 --> 00:12:11,880
and with that thank you all very much

275
00:12:11,880 --> 00:12:15,320
for your attention thank you

