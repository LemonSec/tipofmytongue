1
00:00:01,360 --> 00:00:04,240
hello everyone welcome to my talk i am

2
00:00:04,240 --> 00:00:06,640
jigar from the university of virginia

3
00:00:06,640 --> 00:00:08,400
and we are glad to present our paper

4
00:00:08,400 --> 00:00:11,280
today the title is deletion influence

5
00:00:11,280 --> 00:00:13,679
reconstruction and compliance in machine

6
00:00:13,679 --> 00:00:15,120
learning

7
00:00:15,120 --> 00:00:17,199
this is a collaboration work with sandra

8
00:00:17,199 --> 00:00:19,439
mohammed and prashant

9
00:00:19,439 --> 00:00:21,680
here is an outline of this talk we will

10
00:00:21,680 --> 00:00:23,600
introduce two major threat models

11
00:00:23,600 --> 00:00:25,439
division inference attack and deletion

12
00:00:25,439 --> 00:00:28,480
reconstruction attack

13
00:00:29,199 --> 00:00:30,880
recently there has been more and more

14
00:00:30,880 --> 00:00:33,360
regulations about right to erasure that

15
00:00:33,360 --> 00:00:35,440
is individuals can request that they

16
00:00:35,440 --> 00:00:37,920
have to be deleted for example

17
00:00:37,920 --> 00:00:40,239
gdpr in europe allows consumers to

18
00:00:40,239 --> 00:00:42,320
delete their data followed by many

19
00:00:42,320 --> 00:00:45,120
states in united states from this map we

20
00:00:45,120 --> 00:00:47,120
can see a huge map of u.s are

21
00:00:47,120 --> 00:00:50,480
considering similar privacy regulations

22
00:00:50,480 --> 00:00:52,320
we know that the machine learning models

23
00:00:52,320 --> 00:00:54,399
are built on user data so iphone

24
00:00:54,399 --> 00:00:56,480
requests from consumer we will need to

25
00:00:56,480 --> 00:00:58,879
update model makes the model forget this

26
00:00:58,879 --> 00:01:00,480
specific data

27
00:01:00,480 --> 00:01:03,520
and this process is very costly

28
00:01:03,520 --> 00:01:05,360
this fact motivates this line of work

29
00:01:05,360 --> 00:01:08,159
called machine learning

30
00:01:08,159 --> 00:01:09,920
we briefly introduced this machine

31
00:01:09,920 --> 00:01:12,400
learning process here suppose we have a

32
00:01:12,400 --> 00:01:15,200
model h that is trained with examples e1

33
00:01:15,200 --> 00:01:16,320
to e5

34
00:01:16,320 --> 00:01:18,560
now we get this request for deleting an

35
00:01:18,560 --> 00:01:20,720
example e4 in the data set

36
00:01:20,720 --> 00:01:22,720
the goal of machine learning is to get a

37
00:01:22,720 --> 00:01:25,759
new model we call it edge dell that is

38
00:01:25,759 --> 00:01:28,560
ideally the same as training a new

39
00:01:28,560 --> 00:01:30,640
model from scratch with the training set

40
00:01:30,640 --> 00:01:33,439
as except this example e4

41
00:01:33,439 --> 00:01:35,439
we call this ideal case as perfect

42
00:01:35,439 --> 00:01:37,919
deletion

43
00:01:38,960 --> 00:01:40,479
we now post a question

44
00:01:40,479 --> 00:01:42,399
if privacy motivates such erasure

45
00:01:42,399 --> 00:01:44,479
requests that doing this on learning

46
00:01:44,479 --> 00:01:46,880
really helps individuals privacy

47
00:01:46,880 --> 00:01:48,479
this perfect model will get very

48
00:01:48,479 --> 00:01:50,880
training is built without this record e

49
00:01:50,880 --> 00:01:52,640
so it seems to be unable to learn

50
00:01:52,640 --> 00:01:55,119
anything of e here however is that

51
00:01:55,119 --> 00:01:57,840
really the case

52
00:01:59,280 --> 00:02:01,280
an adversary can observe both versions

53
00:02:01,280 --> 00:02:02,560
of the model

54
00:02:02,560 --> 00:02:04,640
here the address will already observe

55
00:02:04,640 --> 00:02:07,040
the model before deletion

56
00:02:07,040 --> 00:02:09,280
and after delete request the model get

57
00:02:09,280 --> 00:02:11,360
updated that user query is the second

58
00:02:11,360 --> 00:02:13,360
model

59
00:02:13,360 --> 00:02:15,840
and here's the problem as a contract

60
00:02:15,840 --> 00:02:18,560
example suppose that our model returns a

61
00:02:18,560 --> 00:02:20,879
summation of records in a set

62
00:02:20,879 --> 00:02:23,040
so for a single record the model

63
00:02:23,040 --> 00:02:25,760
preserve is privacy to some extent

64
00:02:25,760 --> 00:02:26,879
however

65
00:02:26,879 --> 00:02:29,599
there is required both model can then

66
00:02:29,599 --> 00:02:31,920
exactly infer this record

67
00:02:31,920 --> 00:02:35,040
by just applying a single deduction

68
00:02:35,040 --> 00:02:36,959
so in this example the deletion

69
00:02:36,959 --> 00:02:38,879
operation totally destroys the privacy

70
00:02:38,879 --> 00:02:41,040
of the record

71
00:02:41,040 --> 00:02:43,200
come to our work we study the privacy

72
00:02:43,200 --> 00:02:45,440
implication of this machine on learning

73
00:02:45,440 --> 00:02:47,760
and we make the following contributions

74
00:02:47,760 --> 00:02:50,879
first we formally define strain models

75
00:02:50,879 --> 00:02:52,080
including

76
00:02:52,080 --> 00:02:54,480
the reconstruction and inference attack

77
00:02:54,480 --> 00:02:57,920
tailored for machine learning

78
00:02:58,159 --> 00:03:00,480
and secondly we also show some very

79
00:03:00,480 --> 00:03:02,400
simple attack can succeed in these

80
00:03:02,400 --> 00:03:03,920
thread models for different machine

81
00:03:03,920 --> 00:03:06,399
learners

82
00:03:07,599 --> 00:03:10,000
specifically we focus on two-strand

83
00:03:10,000 --> 00:03:11,280
models

84
00:03:11,280 --> 00:03:13,760
in the deletion inference attack address

85
00:03:13,760 --> 00:03:15,680
we want to infer whether an example is

86
00:03:15,680 --> 00:03:17,760
deleted or not

87
00:03:17,760 --> 00:03:20,080
and in deletion reconstruction attack

88
00:03:20,080 --> 00:03:22,080
that user wants to reconstruct the

89
00:03:22,080 --> 00:03:23,760
deleted example

90
00:03:23,760 --> 00:03:26,720
both thread models are very general

91
00:03:26,720 --> 00:03:29,599
meaning that they have various forms

92
00:03:29,599 --> 00:03:31,280
and can be applied to many machine

93
00:03:31,280 --> 00:03:33,840
learning tasks

94
00:03:34,400 --> 00:03:36,319
before coming to our attack we first

95
00:03:36,319 --> 00:03:38,159
introduced some relative work on our

96
00:03:38,159 --> 00:03:39,120
topic

97
00:03:39,120 --> 00:03:41,280
salem medal 2020 proposed privacy

98
00:03:41,280 --> 00:03:43,680
attacks on updating machinery models the

99
00:03:43,680 --> 00:03:45,599
model is updated with the additional

100
00:03:45,599 --> 00:03:47,680
example and they clean the generating

101
00:03:47,680 --> 00:03:50,080
models to reconstruct the example from

102
00:03:50,080 --> 00:03:51,599
the input for

103
00:03:51,599 --> 00:03:53,519
both model before addition and after

104
00:03:53,519 --> 00:03:54,480
addition

105
00:03:54,480 --> 00:03:56,959
a concurrent world trade or 2021

106
00:03:56,959 --> 00:03:59,599
proposed privacy attack on deletion they

107
00:03:59,599 --> 00:04:01,920
adapt the memory inference framework by

108
00:04:01,920 --> 00:04:04,000
training an attack model from the output

109
00:04:04,000 --> 00:04:05,840
on the two models before and after

110
00:04:05,840 --> 00:04:07,680
division to infor whether an example is

111
00:04:07,680 --> 00:04:09,360
digital

112
00:04:09,360 --> 00:04:11,760
and comparing to these two relative

113
00:04:11,760 --> 00:04:14,159
works we give a new formal definition of

114
00:04:14,159 --> 00:04:17,358
privacy in various new settings

115
00:04:17,358 --> 00:04:19,519
also we propose extremely simple but

116
00:04:19,519 --> 00:04:21,440
effective attack on both inference and

117
00:04:21,440 --> 00:04:23,440
reconstruction scenarios

118
00:04:23,440 --> 00:04:26,160
we also present some partial theoretical

119
00:04:26,160 --> 00:04:28,560
justifications of why this attacks work

120
00:04:28,560 --> 00:04:30,960
and study attacks on new models such as

121
00:04:30,960 --> 00:04:33,440
language models

122
00:04:33,440 --> 00:04:35,600
there is also a very recent work study

123
00:04:35,600 --> 00:04:38,000
managing influence on model update with

124
00:04:38,000 --> 00:04:42,440
access on updating models

125
00:04:42,960 --> 00:04:44,720
now let's start with deletion inference

126
00:04:44,720 --> 00:04:46,800
attack

127
00:04:46,800 --> 00:04:48,560
we start with the deletion inference

128
00:04:48,560 --> 00:04:50,400
attack

129
00:04:50,400 --> 00:04:52,479
first thread model introduces decision

130
00:04:52,479 --> 00:04:54,960
inference which is inferring whether an

131
00:04:54,960 --> 00:04:57,440
example is deleted or not

132
00:04:57,440 --> 00:04:59,680
so here in the slice there is a wonder

133
00:04:59,680 --> 00:05:03,039
whether an example e is deleted

134
00:05:03,039 --> 00:05:04,880
there is a get to query the model before

135
00:05:04,880 --> 00:05:06,000
deletion

136
00:05:06,000 --> 00:05:07,840
and then query the new model after

137
00:05:07,840 --> 00:05:09,120
deletion

138
00:05:09,120 --> 00:05:10,880
note that the sequence of the query is

139
00:05:10,880 --> 00:05:13,120
fixed because after the deletion the

140
00:05:13,120 --> 00:05:17,600
original model is not accessible anymore

141
00:05:17,840 --> 00:05:20,400
to clarify one thing here that really

142
00:05:20,400 --> 00:05:22,320
knows the deletion happens but just

143
00:05:22,320 --> 00:05:24,560
wondering about what is digit

144
00:05:24,560 --> 00:05:27,120
to highlight that we study a more basic

145
00:05:27,120 --> 00:05:29,240
scenario which is inspired by the

146
00:05:29,240 --> 00:05:31,360
indistinguishability security games in

147
00:05:31,360 --> 00:05:35,919
crypto such as in cpa or cca security

148
00:05:35,919 --> 00:05:37,280
in the scenario

149
00:05:37,280 --> 00:05:39,919
the address is given two choices e0 and

150
00:05:39,919 --> 00:05:40,960
e1

151
00:05:40,960 --> 00:05:43,520
and need to find out which one of them

152
00:05:43,520 --> 00:05:46,240
is deleted

153
00:05:46,800 --> 00:05:49,039
we now formally define the security game

154
00:05:49,039 --> 00:05:50,639
of deletion inference

155
00:05:50,639 --> 00:05:52,639
there are two parties a challenger and

156
00:05:52,639 --> 00:05:54,000
an adversary

157
00:05:54,000 --> 00:05:55,680
the challenger first pick a data set

158
00:05:55,680 --> 00:05:57,680
with sex m

159
00:05:57,680 --> 00:05:59,600
the challenger then pick two examples

160
00:05:59,600 --> 00:06:01,600
yeah and ej and send them to the

161
00:06:01,600 --> 00:06:03,280
adversary

162
00:06:03,280 --> 00:06:05,039
the chinese entrance model is the

163
00:06:05,039 --> 00:06:06,960
learner

164
00:06:06,960 --> 00:06:09,039
the artist will have oracle access to

165
00:06:09,039 --> 00:06:12,319
this model before the next step

166
00:06:12,319 --> 00:06:14,479
then the challenger toss a coin to

167
00:06:14,479 --> 00:06:16,400
delete one example

168
00:06:16,400 --> 00:06:18,880
between yan and ej

169
00:06:18,880 --> 00:06:21,120
and get a new model

170
00:06:21,120 --> 00:06:23,280
and after that the address is given

171
00:06:23,280 --> 00:06:26,000
oracle access to this new model

172
00:06:26,000 --> 00:06:28,639
and finally the address guesses which

173
00:06:28,639 --> 00:06:32,319
one among ei and ej is deleted

174
00:06:32,319 --> 00:06:35,280
the address tell challenger a bit 001

175
00:06:35,280 --> 00:06:39,120
and wins if the guess is correct

176
00:06:39,120 --> 00:06:42,240
we call a scheme drawing skewer against

177
00:06:42,240 --> 00:06:44,880
deletion inference if there exists an

178
00:06:44,880 --> 00:06:47,199
address who succeeds with probability at

179
00:06:47,199 --> 00:06:48,639
least low

180
00:06:48,639 --> 00:06:51,039
so when raw is half it is trivial

181
00:06:51,039 --> 00:06:52,720
because at least you can just flip a

182
00:06:52,720 --> 00:06:56,000
random coin to achieve that

183
00:06:56,000 --> 00:06:58,560
now before introducing our attack we

184
00:06:58,560 --> 00:07:00,720
first see one possible attack which is

185
00:07:00,720 --> 00:07:02,319
reducing the problem to membership

186
00:07:02,319 --> 00:07:04,240
influence

187
00:07:04,240 --> 00:07:06,319
membership influence attacks the type of

188
00:07:06,319 --> 00:07:08,240
privacy attacker returns whether an

189
00:07:08,240 --> 00:07:12,080
input is part of the data set or not

190
00:07:12,080 --> 00:07:13,840
if we have a membership influencer

191
00:07:13,840 --> 00:07:16,240
address that always succeed we can then

192
00:07:16,240 --> 00:07:18,880
use it to get the membership of the two

193
00:07:18,880 --> 00:07:21,199
examples on the two models

194
00:07:21,199 --> 00:07:24,720
and then decide which example is digit

195
00:07:24,720 --> 00:07:27,039
is because the deleted example loses its

196
00:07:27,039 --> 00:07:30,080
membership after deletion

197
00:07:30,080 --> 00:07:32,080
because of this reduction

198
00:07:32,080 --> 00:07:34,000
inference attack is only interesting

199
00:07:34,000 --> 00:07:36,720
when it can beat this reduction

200
00:07:36,720 --> 00:07:39,199
now can we define inference attack that

201
00:07:39,199 --> 00:07:42,720
can leverage this deletion scenario

202
00:07:42,720 --> 00:07:45,440
we propose a simple attack the intuition

203
00:07:45,440 --> 00:07:47,599
is that the loss of the deleted example

204
00:07:47,599 --> 00:07:50,080
should increase

205
00:07:50,080 --> 00:07:54,240
because it is removed from the data set

206
00:07:54,720 --> 00:07:56,879
the attack is very simple

207
00:07:56,879 --> 00:07:58,879
just compare the difference on the loss

208
00:07:58,879 --> 00:08:01,120
that is the loss after deletion minus

209
00:08:01,120 --> 00:08:03,120
the loss before division

210
00:08:03,120 --> 00:08:05,440
so the attack first query the model h

211
00:08:05,440 --> 00:08:10,560
and f del with both examples e0 and e1

212
00:08:10,800 --> 00:08:12,400
and then it

213
00:08:12,400 --> 00:08:14,800
gets a loss of the two examples compute

214
00:08:14,800 --> 00:08:18,240
the difference for both e0 and e1 and

215
00:08:18,240 --> 00:08:20,400
finally the model returns example is

216
00:08:20,400 --> 00:08:23,440
larger loss difference

217
00:08:25,120 --> 00:08:27,919
for evaluation our goal is to evaluate

218
00:08:27,919 --> 00:08:29,840
our attack on large models between a

219
00:08:29,840 --> 00:08:31,919
large data set

220
00:08:31,919 --> 00:08:34,080
our baseline is the reduction to the

221
00:08:34,080 --> 00:08:35,839
membership influence attack from

222
00:08:35,839 --> 00:08:37,200
shockery at all

223
00:08:37,200 --> 00:08:39,599
one of the famous membership influence

224
00:08:39,599 --> 00:08:41,839
attack

225
00:08:43,200 --> 00:08:45,680
the trina attack model with the help of

226
00:08:45,680 --> 00:08:48,560
accelerated data from same distribution

227
00:08:48,560 --> 00:08:51,040
the problem is that the shocking attack

228
00:08:51,040 --> 00:08:52,959
trains several machine learning models

229
00:08:52,959 --> 00:08:55,200
to attack so to compare we need to

230
00:08:55,200 --> 00:08:57,040
retrieve all these models for each

231
00:08:57,040 --> 00:09:00,480
deletion which is very costly

232
00:09:00,480 --> 00:09:03,040
to alleviate this problem

233
00:09:03,040 --> 00:09:05,839
we apply the multi-division setting

234
00:09:05,839 --> 00:09:08,560
so each time we pick a batch of 100

235
00:09:08,560 --> 00:09:11,519
examples and read all of them

236
00:09:11,519 --> 00:09:14,160
we also pick another 100 examples inside

237
00:09:14,160 --> 00:09:17,120
the data set but not deleted

238
00:09:17,120 --> 00:09:19,279
then we perform deletion inference for

239
00:09:19,279 --> 00:09:21,519
each pair of the examples across these

240
00:09:21,519 --> 00:09:23,760
batches

241
00:09:23,760 --> 00:09:26,080
we test these attacks on two deep

242
00:09:26,080 --> 00:09:28,320
convolutional neural network a small

243
00:09:28,320 --> 00:09:30,800
conversion neural network small cnn and

244
00:09:30,800 --> 00:09:32,800
a famous convolutional neural network

245
00:09:32,800 --> 00:09:36,000
regionating we train these models on two

246
00:09:36,000 --> 00:09:38,399
image classification tasks

247
00:09:38,399 --> 00:09:41,839
cypher 10 and 700

248
00:09:41,839 --> 00:09:43,680
we summarize the result in these four

249
00:09:43,680 --> 00:09:46,160
figures our deletion inference attack is

250
00:09:46,160 --> 00:09:48,959
a blue curve here

251
00:09:49,120 --> 00:09:51,040
our deletion influencer attack has high

252
00:09:51,040 --> 00:09:53,120
success rate even in the case when the

253
00:09:53,120 --> 00:09:55,040
data set size is large

254
00:09:55,040 --> 00:09:56,880
we show that the deletion influence can

255
00:09:56,880 --> 00:09:58,720
be done when the data sets and models

256
00:09:58,720 --> 00:10:01,279
are large and when a batch of examples

257
00:10:01,279 --> 00:10:02,839
is deleted

258
00:10:02,839 --> 00:10:05,680
together give the time limit

259
00:10:05,680 --> 00:10:07,600
please refer to our paper for more

260
00:10:07,600 --> 00:10:10,000
experiment results

261
00:10:10,000 --> 00:10:12,000
this concludes our result on division

262
00:10:12,000 --> 00:10:13,200
inference

263
00:10:13,200 --> 00:10:15,120
we now move on to the second type of

264
00:10:15,120 --> 00:10:18,320
attacks decision reconstruction attack

265
00:10:18,320 --> 00:10:21,600
deletion reconstruction is a harder task

266
00:10:21,600 --> 00:10:24,240
suppose example e is deleted and others

267
00:10:24,240 --> 00:10:26,399
will try to reconstruct example e from

268
00:10:26,399 --> 00:10:28,240
the query

269
00:10:28,240 --> 00:10:30,160
deletion reconstruction attack is

270
00:10:30,160 --> 00:10:32,240
stronger attack that can reduce to

271
00:10:32,240 --> 00:10:33,760
deletion inference

272
00:10:33,760 --> 00:10:36,880
as if someone can recontract the example

273
00:10:36,880 --> 00:10:39,040
they can also compare it with the

274
00:10:39,040 --> 00:10:40,959
example given by the challenger and tell

275
00:10:40,959 --> 00:10:42,880
which one is dehu

276
00:10:42,880 --> 00:10:45,440
we also work on wearing of these models

277
00:10:45,440 --> 00:10:47,760
please check our paper for wearing the

278
00:10:47,760 --> 00:10:49,440
reconstruction that we call deletion

279
00:10:49,440 --> 00:10:52,640
label reconstruction

280
00:10:52,640 --> 00:10:54,399
similar to deletion inference there are

281
00:10:54,399 --> 00:10:56,079
two parties a challenger and an

282
00:10:56,079 --> 00:10:57,279
adversary

283
00:10:57,279 --> 00:10:59,120
the challenger first pick a data set

284
00:10:59,120 --> 00:11:01,279
with size m and trigger model with the

285
00:11:01,279 --> 00:11:02,320
learner

286
00:11:02,320 --> 00:11:04,399
the address has oracle access to this

287
00:11:04,399 --> 00:11:06,320
model

288
00:11:06,320 --> 00:11:09,360
and change the pick an example to delete

289
00:11:09,360 --> 00:11:12,000
and change a new model

290
00:11:12,000 --> 00:11:14,560
after that the address is given oracle

291
00:11:14,560 --> 00:11:17,120
access to this new model

292
00:11:17,120 --> 00:11:19,200
the difference here is that in deletion

293
00:11:19,200 --> 00:11:21,360
reconstruction the others will need to

294
00:11:21,360 --> 00:11:23,200
estimate the example and send back to

295
00:11:23,200 --> 00:11:25,839
the challenger

296
00:11:25,839 --> 00:11:27,600
the reconstruction doesn't need to be

297
00:11:27,600 --> 00:11:29,279
perfect

298
00:11:29,279 --> 00:11:30,720
and the addresses performance is

299
00:11:30,720 --> 00:11:33,040
measured by some distance metric

300
00:11:33,040 --> 00:11:34,560
that measures the distance between the

301
00:11:34,560 --> 00:11:38,560
reconstructed example and the example

302
00:11:38,560 --> 00:11:40,640
now i present a reconstruction attack

303
00:11:40,640 --> 00:11:42,399
that is based on the nutrition that the

304
00:11:42,399 --> 00:11:44,480
output of the instance around the

305
00:11:44,480 --> 00:11:46,560
example e are likely to be different

306
00:11:46,560 --> 00:11:48,399
after deletion

307
00:11:48,399 --> 00:11:49,600
in that case

308
00:11:49,600 --> 00:11:51,680
dilute reference compose a set of

309
00:11:51,680 --> 00:11:54,079
instances t which can be obtained from

310
00:11:54,079 --> 00:11:56,000
accelerating instances from the data

311
00:11:56,000 --> 00:11:57,279
distribution

312
00:11:57,279 --> 00:11:59,200
or just random sampling from the input

313
00:11:59,200 --> 00:12:01,200
space

314
00:12:01,200 --> 00:12:03,120
that there is a first query model with

315
00:12:03,120 --> 00:12:05,519
all the instances in t

316
00:12:05,519 --> 00:12:07,600
and after getting access

317
00:12:07,600 --> 00:12:10,480
to the deletion model it queries other

318
00:12:10,480 --> 00:12:14,000
examples on the deleted model

319
00:12:14,000 --> 00:12:16,399
the address reason creates a subset of t

320
00:12:16,399 --> 00:12:18,399
which includes all the instances whose

321
00:12:18,399 --> 00:12:20,560
prediction label changed as the deletion

322
00:12:20,560 --> 00:12:22,959
region t prime

323
00:12:22,959 --> 00:12:24,560
the attacker doesn't compute the

324
00:12:24,560 --> 00:12:26,639
majority of t prime

325
00:12:26,639 --> 00:12:28,480
it is actually a meta attack because of

326
00:12:28,480 --> 00:12:30,880
majority here it can be general and the

327
00:12:30,880 --> 00:12:32,560
reason we can choose an appropriate

328
00:12:32,560 --> 00:12:34,480
aggregation function

329
00:12:34,480 --> 00:12:37,040
depends on the task

330
00:12:37,040 --> 00:12:39,440
example on the majority function is that

331
00:12:39,440 --> 00:12:41,839
for each bit in the data just take the

332
00:12:41,839 --> 00:12:44,000
majority vote of that bit over all the

333
00:12:44,000 --> 00:12:45,920
examples in key prime and return the

334
00:12:45,920 --> 00:12:49,199
reconstruction based on that

335
00:12:49,760 --> 00:12:51,920
as a test to the reconstruction attack

336
00:12:51,920 --> 00:12:53,680
we consider a case when we want to

337
00:12:53,680 --> 00:12:55,519
reconstruct images for nearest neighbor

338
00:12:55,519 --> 00:12:56,880
predictors

339
00:12:56,880 --> 00:12:59,360
we use omniglo dataset with for that

340
00:12:59,360 --> 00:13:01,760
which include 20 copies for handwritten

341
00:13:01,760 --> 00:13:03,200
characters

342
00:13:03,200 --> 00:13:04,240
we use

343
00:13:04,240 --> 00:13:06,560
10 copies of each character to learn

344
00:13:06,560 --> 00:13:09,120
model and the other 10 copies of each

345
00:13:09,120 --> 00:13:10,880
character the viewer accelerates the

346
00:13:10,880 --> 00:13:12,720
process that is available to the

347
00:13:12,720 --> 00:13:14,240
adversary

348
00:13:14,240 --> 00:13:15,920
our deletion reconstruction attack

349
00:13:15,920 --> 00:13:18,480
reconstructed a lot of examples which is

350
00:13:18,480 --> 00:13:20,800
shown in the rows markers too

351
00:13:20,800 --> 00:13:22,800
compared to the actual deleted example

352
00:13:22,800 --> 00:13:24,560
of the row three they show a lot of

353
00:13:24,560 --> 00:13:27,200
similarity and we can see that without

354
00:13:27,200 --> 00:13:30,160
lesion the reconstruction basically

355
00:13:30,160 --> 00:13:31,839
reconstructs nothing

356
00:13:31,839 --> 00:13:33,680
please refer to our paper for more

357
00:13:33,680 --> 00:13:36,880
experiment results and details

358
00:13:36,880 --> 00:13:39,199
as a summary in this paper we study

359
00:13:39,199 --> 00:13:40,880
privacy implications of machine learning

360
00:13:40,880 --> 00:13:43,360
learning we propose two strand models

361
00:13:43,360 --> 00:13:44,720
deletion inference and division

362
00:13:44,720 --> 00:13:47,040
reconstruction i'm ensure that simple

363
00:13:47,040 --> 00:13:48,720
attacks are effective for variety of

364
00:13:48,720 --> 00:13:50,240
settings and models

365
00:13:50,240 --> 00:13:52,560
for future work one direction is to give

366
00:13:52,560 --> 00:13:54,639
optimal bonds on the deletion inference

367
00:13:54,639 --> 00:13:55,760
attacks

368
00:13:55,760 --> 00:13:57,600
another direction is to have probable

369
00:13:57,600 --> 00:14:00,079
attacks and defenses under update

370
00:14:00,079 --> 00:14:02,079
beyond merely applying differential

371
00:14:02,079 --> 00:14:03,920
privacy

372
00:14:03,920 --> 00:14:06,240
that's all if you are interested in our

373
00:14:06,240 --> 00:14:07,920
work please check our paper for the

374
00:14:07,920 --> 00:14:11,800
details thank you

