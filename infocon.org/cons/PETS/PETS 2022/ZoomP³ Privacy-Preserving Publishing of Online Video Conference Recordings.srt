1
00:00:01,120 --> 00:00:03,280
hello everyone my name is yuya eastman i

2
00:00:03,280 --> 00:00:06,240
was pct student at penn state university

3
00:00:06,240 --> 00:00:08,240
today i would like to share our work

4
00:00:08,240 --> 00:00:11,120
zoom p3 privacy preserving publishing of

5
00:00:11,120 --> 00:00:12,559
online video

6
00:00:12,559 --> 00:00:14,719
conference recordings this is a joint

7
00:00:14,719 --> 00:00:16,320
work with professor cynthia andrew and

8
00:00:16,320 --> 00:00:18,800
professor uchen

9
00:00:18,800 --> 00:00:21,920
recently due to the impact of academic

10
00:00:21,920 --> 00:00:24,080
video conference application have become

11
00:00:24,080 --> 00:00:27,119
increasingly popular such as zoom google

12
00:00:27,119 --> 00:00:30,480
meet and the microsoft teams

13
00:00:30,480 --> 00:00:31,920
video conference applications are

14
00:00:31,920 --> 00:00:34,000
suitable for different scenarios such as

15
00:00:34,000 --> 00:00:36,079
entertainment video conference in this

16
00:00:36,079 --> 00:00:38,480
example video the participants in the

17
00:00:38,480 --> 00:00:40,559
meeting express their feelings let's

18
00:00:40,559 --> 00:00:42,800
take a quick look of this video just

19
00:00:42,800 --> 00:00:44,879
reset the camera

20
00:00:44,879 --> 00:00:46,079
okay

21
00:00:46,079 --> 00:00:47,840
like this

22
00:00:47,840 --> 00:00:50,239
did i activate zoom

23
00:00:50,239 --> 00:00:53,600
no you turned it off

24
00:00:53,600 --> 00:00:55,680
so following demo is more formal for

25
00:00:55,680 --> 00:00:57,680
business video conference where

26
00:00:57,680 --> 00:01:00,079
participants speak one by one

27
00:01:00,079 --> 00:01:01,840
let's take a quick look of this short

28
00:01:01,840 --> 00:01:03,920
video started and

29
00:01:03,920 --> 00:01:05,920
hopefully over the next few years get

30
00:01:05,920 --> 00:01:07,680
them coming back and then work on that

31
00:01:07,680 --> 00:01:09,600
showcase

32
00:01:09,600 --> 00:01:13,839
so what's the actual funding

33
00:01:14,400 --> 00:01:16,159
there is a lot of personally

34
00:01:16,159 --> 00:01:18,880
identifiable information that is exposed

35
00:01:18,880 --> 00:01:21,840
in the meeting including face

36
00:01:21,840 --> 00:01:25,200
name tags and the voice

37
00:01:25,200 --> 00:01:27,600
there will be significant privacy

38
00:01:27,600 --> 00:01:31,200
concern once the video contains this pii

39
00:01:31,200 --> 00:01:33,439
are released to the public website like

40
00:01:33,439 --> 00:01:35,920
of youtube

41
00:01:35,920 --> 00:01:38,479
the previous user study has shown that

42
00:01:38,479 --> 00:01:41,119
video conference recordings are ideal

43
00:01:41,119 --> 00:01:44,560
for an attacker to collect the user data

44
00:01:44,560 --> 00:01:47,119
attacker can draw a large number of vcrs

45
00:01:47,119 --> 00:01:49,680
to extract their visual information and

46
00:01:49,680 --> 00:01:51,600
corresponding participants name

47
00:01:51,600 --> 00:01:54,720
determines the participants age and the

48
00:01:54,720 --> 00:01:55,680
gender

49
00:01:55,680 --> 00:01:58,320
if such a database is sold by the

50
00:01:58,320 --> 00:02:00,560
attacker the purchaser may

51
00:02:00,560 --> 00:02:02,399
either target the victim with the

52
00:02:02,399 --> 00:02:04,719
advertisement or

53
00:02:04,719 --> 00:02:06,640
make use of the information to

54
00:02:06,640 --> 00:02:08,878
impersonate the victim

55
00:02:08,878 --> 00:02:11,440
in this research we aim to address the

56
00:02:11,440 --> 00:02:14,560
above privacy risk by proposing

57
00:02:14,560 --> 00:02:17,120
automated and efficient video

58
00:02:17,120 --> 00:02:19,200
privacy preserving season for protecting

59
00:02:19,200 --> 00:02:22,200
vcrs

60
00:02:22,480 --> 00:02:24,959
here are some preliminary to know all

61
00:02:24,959 --> 00:02:27,040
videos are made up of a number of

62
00:02:27,040 --> 00:02:28,800
continuous image

63
00:02:28,800 --> 00:02:30,480
each of an image is

64
00:02:30,480 --> 00:02:32,239
called a frame

65
00:02:32,239 --> 00:02:34,480
there are several different modes in the

66
00:02:34,480 --> 00:02:37,120
video conference including speaker view

67
00:02:37,120 --> 00:02:39,760
gridw and the share screen mode they

68
00:02:39,760 --> 00:02:42,319
have a different window layout

69
00:02:42,319 --> 00:02:45,280
in our system we have two types of users

70
00:02:45,280 --> 00:02:47,760
one is called public users which refer

71
00:02:47,760 --> 00:02:50,879
to those who allowed their pii to be

72
00:02:50,879 --> 00:02:53,519
disclosed with the video and the other

73
00:02:53,519 --> 00:02:55,360
one is called the private sector user

74
00:02:55,360 --> 00:02:58,000
which refers to those who do not allow

75
00:02:58,000 --> 00:03:01,519
the api to be disclosed literally

76
00:03:01,519 --> 00:03:04,000
in our system there are two protection

77
00:03:04,000 --> 00:03:06,480
modes whether it's the blacklist you

78
00:03:06,480 --> 00:03:09,040
know widely smooth for example if a

79
00:03:09,040 --> 00:03:11,599
professor teaches 15 minutes class now

80
00:03:11,599 --> 00:03:14,319
the professor is a public user

81
00:03:14,319 --> 00:03:16,000
all students participate in the new

82
00:03:16,000 --> 00:03:16,959
class

83
00:03:16,959 --> 00:03:19,920
privacy sensitive users and we expect

84
00:03:19,920 --> 00:03:22,800
all students pii to be protected

85
00:03:22,800 --> 00:03:25,120
blacklist mode for example for

86
00:03:25,120 --> 00:03:27,920
conference video the user address

87
00:03:27,920 --> 00:03:30,879
explicitly requires the conference host

88
00:03:30,879 --> 00:03:34,720
to remove her pii from the way

89
00:03:34,799 --> 00:03:37,840
here is our system workflow for example

90
00:03:37,840 --> 00:03:40,400
if there is a original video that

91
00:03:40,400 --> 00:03:42,480
needs a privacy protection then the

92
00:03:42,480 --> 00:03:44,560
first step is to select the targeted

93
00:03:44,560 --> 00:03:45,519
users

94
00:03:45,519 --> 00:03:46,400
regions

95
00:03:46,400 --> 00:03:49,840
and the voice interval then execute the

96
00:03:49,840 --> 00:03:53,439
privacy protection mode model and

97
00:03:53,439 --> 00:03:56,560
finally run the video patching system to

98
00:03:56,560 --> 00:03:59,360
fix any possible protection leakage and

99
00:03:59,360 --> 00:04:01,840
finally get the final reading

100
00:04:01,840 --> 00:04:04,319
in our season the privacy protection

101
00:04:04,319 --> 00:04:08,080
model is the cape model as shown in the

102
00:04:08,080 --> 00:04:11,360
figure on the right it will separate the

103
00:04:11,360 --> 00:04:15,120
video into video and audio respectively

104
00:04:15,120 --> 00:04:17,600
for privacy protection and

105
00:04:17,600 --> 00:04:20,160
reassemble the video and audio into the

106
00:04:20,160 --> 00:04:23,040
final video

107
00:04:24,240 --> 00:04:26,320
as i mentioned before face area is a

108
00:04:26,320 --> 00:04:30,080
part of pri we need to locate the phase

109
00:04:30,080 --> 00:04:33,840
area that is fixed detection here we re

110
00:04:33,840 --> 00:04:36,320
introduce some pistachio algorithm with

111
00:04:36,320 --> 00:04:39,040
their advantage and digital advantage

112
00:04:39,040 --> 00:04:41,040
for example sata phase which is

113
00:04:41,040 --> 00:04:42,479
lightweight and fast

114
00:04:42,479 --> 00:04:45,199
but has the disadvantage of not being

115
00:04:45,199 --> 00:04:47,680
able to detect small phase

116
00:04:47,680 --> 00:04:49,440
db phase is good

117
00:04:49,440 --> 00:04:52,240
at detecting small phase but has a lower

118
00:04:52,240 --> 00:04:54,560
performance

119
00:04:54,560 --> 00:04:56,560
phase recognization of face

120
00:04:56,560 --> 00:04:59,360
identification is to answer the question

121
00:04:59,360 --> 00:05:02,479
of who is the face since we are many

122
00:05:02,479 --> 00:05:05,120
targeting conference video and the vast

123
00:05:05,120 --> 00:05:07,840
majority users are close enough to the

124
00:05:07,840 --> 00:05:10,639
camera we use sata phase for both the

125
00:05:10,639 --> 00:05:12,800
face detection and first recognization

126
00:05:12,800 --> 00:05:16,160
by default to improve the performance

127
00:05:16,160 --> 00:05:18,639
the figure on the right

128
00:05:18,639 --> 00:05:21,120
sorry the finger on the right is the

129
00:05:21,120 --> 00:05:22,639
result of fixed

130
00:05:22,639 --> 00:05:25,440
protection you can see that all face are

131
00:05:25,440 --> 00:05:28,000
protected

132
00:05:30,800 --> 00:05:33,199
how to make the whole precise

133
00:05:33,199 --> 00:05:35,680
privacy protection scale the simplest

134
00:05:35,680 --> 00:05:38,560
way is the frame by frame protection

135
00:05:38,560 --> 00:05:41,199
face detection is provides to each frame

136
00:05:41,199 --> 00:05:42,960
of the video followed by the face

137
00:05:42,960 --> 00:05:45,759
identification if a sensitive phase

138
00:05:45,759 --> 00:05:47,280
identified in

139
00:05:47,280 --> 00:05:50,080
a frame it will be blurred

140
00:05:50,080 --> 00:05:53,440
then comes with with our proposed greedy

141
00:05:53,440 --> 00:05:55,919
backward precision because a large

142
00:05:55,919 --> 00:05:58,160
number of the frames are extremely

143
00:05:58,160 --> 00:06:00,880
similar we divide the radius into groups

144
00:06:00,880 --> 00:06:03,680
and the set select one keyframe to

145
00:06:03,680 --> 00:06:05,600
represent the group

146
00:06:05,600 --> 00:06:08,080
detection and phase identification are

147
00:06:08,080 --> 00:06:09,840
only conduct

148
00:06:09,840 --> 00:06:13,039
on the k-frame in each group for each

149
00:06:13,039 --> 00:06:15,840
non-keyframe it will be precise

150
00:06:15,840 --> 00:06:17,600
according to the fixed detection and

151
00:06:17,600 --> 00:06:20,639
fixed recognization result of the 2k

152
00:06:20,639 --> 00:06:23,039
frame before and after it

153
00:06:23,039 --> 00:06:25,360
here is an example

154
00:06:25,360 --> 00:06:28,160
this video has a total

155
00:06:28,160 --> 00:06:31,440
totally six frames alienating between

156
00:06:31,440 --> 00:06:34,560
the bob and alex bob is a public user

157
00:06:34,560 --> 00:06:36,960
and the addis is private sensitive users

158
00:06:36,960 --> 00:06:39,520
the group size is three so the third and

159
00:06:39,520 --> 00:06:43,039
the six frames are k frames and the

160
00:06:43,039 --> 00:06:45,440
first frame is the also listed at the k

161
00:06:45,440 --> 00:06:47,440
frame because it is the beginning of the

162
00:06:47,440 --> 00:06:48,880
video

163
00:06:48,880 --> 00:06:50,960
the first framework came in

164
00:06:50,960 --> 00:06:51,919
the first

165
00:06:51,919 --> 00:06:54,960
frame is keyframe so perform surface

166
00:06:54,960 --> 00:06:58,240
detection and fix recognization uh and

167
00:06:58,240 --> 00:07:00,800
puts the result into the cache

168
00:07:00,800 --> 00:07:03,280
the second frame is not keyframe

169
00:07:03,280 --> 00:07:07,120
and directly puts put it into the cache

170
00:07:07,120 --> 00:07:08,880
the third frame is a keyframe and the

171
00:07:08,880 --> 00:07:12,080
precise as the first frame and at this

172
00:07:12,080 --> 00:07:15,360
point the cache has reached three frames

173
00:07:15,360 --> 00:07:19,280
and the third frame is inferred inferred

174
00:07:19,280 --> 00:07:21,120
according to the k frame before an

175
00:07:21,120 --> 00:07:24,080
update since the address appears in the

176
00:07:24,080 --> 00:07:26,400
third frame it is the possible side and

177
00:07:26,400 --> 00:07:28,800
is also appear in the second frame so

178
00:07:28,800 --> 00:07:31,280
the area corresponding to the second

179
00:07:31,280 --> 00:07:33,280
frame is protected

180
00:07:33,280 --> 00:07:35,759
the fourth frame is not k frame and

181
00:07:35,759 --> 00:07:38,319
precise as the second fret

182
00:07:38,319 --> 00:07:41,680
the fifth frame is the same

183
00:07:41,680 --> 00:07:43,520
the sixth frame is keyframe and the

184
00:07:43,520 --> 00:07:46,960
precise according to the surface

185
00:07:46,960 --> 00:07:50,080
here is our final result

186
00:07:50,080 --> 00:07:52,479
the final video below shows that

187
00:07:52,479 --> 00:07:54,960
although there is a over protection in

188
00:07:54,960 --> 00:07:56,319
the second and the

189
00:07:56,319 --> 00:07:59,680
fifth frames it ensures that the frames

190
00:07:59,680 --> 00:08:03,919
associated with addis are protected

191
00:08:04,160 --> 00:08:06,960
obviously if the group size is increased

192
00:08:06,960 --> 00:08:08,560
the performance can be improved

193
00:08:08,560 --> 00:08:11,199
significantly if there is no speaker

194
00:08:11,199 --> 00:08:13,120
change in your group we can increase the

195
00:08:13,120 --> 00:08:14,639
size of the group to reduce the

196
00:08:14,639 --> 00:08:15,919
computation

197
00:08:15,919 --> 00:08:18,080
how to detect speaker change

198
00:08:18,080 --> 00:08:21,039
we use the perception hash to detect the

199
00:08:21,039 --> 00:08:23,599
speaker change in the speaker's view

200
00:08:23,599 --> 00:08:26,160
mode only when the speaker is changed

201
00:08:26,160 --> 00:08:28,000
there will be a dramatic

202
00:08:28,000 --> 00:08:30,080
change in two

203
00:08:30,080 --> 00:08:32,479
adjacent frames

204
00:08:32,479 --> 00:08:35,599
we use this approach to increase the

205
00:08:35,599 --> 00:08:37,440
group size and the big system more

206
00:08:37,440 --> 00:08:40,080
efficient

207
00:08:40,080 --> 00:08:42,320
in this presentation we have only

208
00:08:42,320 --> 00:08:45,440
covered the face privacy protection so

209
00:08:45,440 --> 00:08:47,200
audio protection

210
00:08:47,200 --> 00:08:50,399
is based on the speaker theorization

211
00:08:50,399 --> 00:08:52,320
then protect the

212
00:08:52,320 --> 00:08:54,640
voice to ensure that the voice it cannot

213
00:08:54,640 --> 00:08:57,760
be identified identified speaker

214
00:08:57,760 --> 00:09:01,040
generalization is precise to particip

215
00:09:01,040 --> 00:09:03,519
partition an audio stream with

216
00:09:03,519 --> 00:09:04,959
multiple people

217
00:09:04,959 --> 00:09:07,040
to homogeneous segments based on the

218
00:09:07,040 --> 00:09:08,480
speaker identity

219
00:09:08,480 --> 00:09:10,880
for example in the figure below we can

220
00:09:10,880 --> 00:09:13,600
output the similarity value of each

221
00:09:13,600 --> 00:09:15,760
speaker at the moment

222
00:09:15,760 --> 00:09:17,760
using the speaker's information we

223
00:09:17,760 --> 00:09:20,480
protect the voice and add

224
00:09:20,480 --> 00:09:22,959
randomness to ensure to a certain

225
00:09:22,959 --> 00:09:25,519
speaker's interval so that the attacker

226
00:09:25,519 --> 00:09:27,760
will not be able to restore the original

227
00:09:27,760 --> 00:09:29,120
voice

228
00:09:29,120 --> 00:09:31,120
the name type protection is based on the

229
00:09:31,120 --> 00:09:33,839
ocr to protect the system with tax

230
00:09:33,839 --> 00:09:34,959
information

231
00:09:34,959 --> 00:09:37,519
as shown in the figure below given a

232
00:09:37,519 --> 00:09:39,519
image output are

233
00:09:39,519 --> 00:09:42,640
the all embedded text as well as the

234
00:09:42,640 --> 00:09:43,839
chorus

235
00:09:43,839 --> 00:09:46,640
coordinates of the

236
00:09:46,640 --> 00:09:49,440
bounding box of each character during

237
00:09:49,440 --> 00:09:52,800
the white list and blacklist modes based

238
00:09:52,800 --> 00:09:55,760
on some information such as

239
00:09:55,760 --> 00:09:58,240
location and size we can find out all

240
00:09:58,240 --> 00:10:01,200
the text areas that need to be protected

241
00:10:01,200 --> 00:10:04,000
then we can protect all the tags needed

242
00:10:04,000 --> 00:10:07,040
to be protected

243
00:10:07,200 --> 00:10:09,600
due to the time constraints please see

244
00:10:09,600 --> 00:10:12,320
the paper for detail on the

245
00:10:12,320 --> 00:10:14,480
privacy protection of audio and name

246
00:10:14,480 --> 00:10:16,800
tags

247
00:10:17,519 --> 00:10:18,880
uh the

248
00:10:18,880 --> 00:10:21,360
precision time virus along with the

249
00:10:21,360 --> 00:10:22,800
length of video

250
00:10:22,800 --> 00:10:25,120
the number of people in the video and

251
00:10:25,120 --> 00:10:27,839
the frequency uh since

252
00:10:27,839 --> 00:10:30,399
switching different different amount of

253
00:10:30,399 --> 00:10:34,560
values we use the snl videos

254
00:10:34,560 --> 00:10:38,320
as an example to test here is the result

255
00:10:38,320 --> 00:10:40,880
let's take a quick look just reset the

256
00:10:40,880 --> 00:10:42,000
camera

257
00:10:42,000 --> 00:10:43,200
okay

258
00:10:43,200 --> 00:10:46,519
like this

259
00:10:46,560 --> 00:10:49,040
in this demo the mine is public users

260
00:10:49,040 --> 00:10:51,120
others are privacy sensitive users from

261
00:10:51,120 --> 00:10:52,880
the demo you can see that all privacy

262
00:10:52,880 --> 00:10:55,200
systems of users face name tag and voice

263
00:10:55,200 --> 00:10:57,839
are protected

264
00:10:59,279 --> 00:11:00,959
uh evaluation

265
00:11:00,959 --> 00:11:03,839
we choose the group size of five and the

266
00:11:03,839 --> 00:11:06,800
five four parallel computations we can

267
00:11:06,800 --> 00:11:09,360
reduce a video processing time from the

268
00:11:09,360 --> 00:11:11,839
800 seconds to

269
00:11:11,839 --> 00:11:15,279
62 seconds

270
00:11:15,279 --> 00:11:18,240
conclusion we introduced zoom p3 a

271
00:11:18,240 --> 00:11:20,720
practical privacy preserving published

272
00:11:20,720 --> 00:11:23,200
system for protecting both the video and

273
00:11:23,200 --> 00:11:25,760
audio of privacy sensitive participants

274
00:11:25,760 --> 00:11:27,600
in online meetings

275
00:11:27,600 --> 00:11:30,560
we will investigate how to segment the

276
00:11:30,560 --> 00:11:32,000
very zoom

277
00:11:32,000 --> 00:11:34,720
windows more precisely and we will

278
00:11:34,720 --> 00:11:37,360
investigate how to make the theorization

279
00:11:37,360 --> 00:11:41,720
more accurate thank you

280
00:11:44,480 --> 00:11:46,560
you

