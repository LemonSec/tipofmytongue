1
00:00:01,040 --> 00:00:03,919
hi my name is hassan and i'm presenting

2
00:00:03,919 --> 00:00:06,160
our paper titled making the most of

3
00:00:06,160 --> 00:00:07,759
parallel composition and differential

4
00:00:07,759 --> 00:00:10,639
privacy it's a joint work with john john

5
00:00:10,639 --> 00:00:12,240
paulo serene

6
00:00:12,240 --> 00:00:15,599
surgeon paulo and paul

7
00:00:15,599 --> 00:00:18,480
and the problem we are looking at is um

8
00:00:18,480 --> 00:00:21,359
the problem of um answering queries on a

9
00:00:21,359 --> 00:00:23,359
sensitive data set through a

10
00:00:23,359 --> 00:00:25,439
differentially private mechanism

11
00:00:25,439 --> 00:00:27,840
and the goal is to maximize the number

12
00:00:27,840 --> 00:00:30,960
of queries that can be answered

13
00:00:30,960 --> 00:00:34,399
under a fixed global privacy loss

14
00:00:34,399 --> 00:00:37,200
and the idea is to avoid wasting the

15
00:00:37,200 --> 00:00:39,440
privacy budget a simplest example of

16
00:00:39,440 --> 00:00:42,000
that would be to avoid

17
00:00:42,000 --> 00:00:43,360
answering

18
00:00:43,360 --> 00:00:48,160
the same query multiple times with a

19
00:00:48,239 --> 00:00:50,959
different voice

20
00:00:51,039 --> 00:00:52,000
so

21
00:00:52,000 --> 00:00:53,520
on the basic

22
00:00:53,520 --> 00:00:56,480
composition of differential privacy

23
00:00:56,480 --> 00:01:00,879
answering key queries consumes t epsilon

24
00:01:00,879 --> 00:01:03,520
budget this is not optimal and there

25
00:01:03,520 --> 00:01:05,680
have been various relaxations of

26
00:01:05,680 --> 00:01:07,360
differential privacy

27
00:01:07,360 --> 00:01:11,439
in order to find a tighter composition

28
00:01:11,439 --> 00:01:12,880
most of these works

29
00:01:12,880 --> 00:01:15,759
are on sequential composition and less

30
00:01:15,759 --> 00:01:18,400
focus has been given to

31
00:01:18,400 --> 00:01:20,080
another form of composition called

32
00:01:20,080 --> 00:01:22,560
parallel composition

33
00:01:22,560 --> 00:01:23,840
so

34
00:01:23,840 --> 00:01:25,680
informally this means that two

35
00:01:25,680 --> 00:01:27,840
mechanisms are

36
00:01:27,840 --> 00:01:31,119
composed in parallel if they work on

37
00:01:31,119 --> 00:01:34,240
disjoint subdomains

38
00:01:34,240 --> 00:01:36,960
in this case the privacy loss is only

39
00:01:36,960 --> 00:01:38,720
maximum of the two and the intuition

40
00:01:38,720 --> 00:01:41,360
behind that is that individual can only

41
00:01:41,360 --> 00:01:42,320
be

42
00:01:42,320 --> 00:01:43,119
in

43
00:01:43,119 --> 00:01:47,439
one of these two data subdomains

44
00:01:47,439 --> 00:01:49,360
so we have two queries

45
00:01:49,360 --> 00:01:53,439
which are the two different subdomains

46
00:01:53,439 --> 00:01:55,759
and each having a privacy budget of

47
00:01:55,759 --> 00:01:59,280
epsilon then under basic composition the

48
00:01:59,280 --> 00:02:01,920
privacy loss is bounded by two epsilon

49
00:02:01,920 --> 00:02:03,759
but parallel composition gives us a

50
00:02:03,759 --> 00:02:05,520
tighter

51
00:02:05,520 --> 00:02:08,720
bound which is only epsilon in this case

52
00:02:08,720 --> 00:02:10,160
so we can squeeze more out of the

53
00:02:10,160 --> 00:02:12,080
privacy budget if you use parallel

54
00:02:12,080 --> 00:02:14,640
composition

55
00:02:14,720 --> 00:02:16,640
so the question then is that if you're

56
00:02:16,640 --> 00:02:19,360
given some number of couriers t

57
00:02:19,360 --> 00:02:21,520
each with a different privacy budget and

58
00:02:21,520 --> 00:02:24,560
a fixed dp mechanism how do we

59
00:02:24,560 --> 00:02:26,959
find out if any subset

60
00:02:26,959 --> 00:02:29,280
composed in parallel

61
00:02:29,280 --> 00:02:30,879
in order to answer that question we

62
00:02:30,879 --> 00:02:32,879
defined the

63
00:02:32,879 --> 00:02:35,040
notion of maximum overlap which is

64
00:02:35,040 --> 00:02:38,800
defined in terms of query coverage

65
00:02:38,800 --> 00:02:41,280
so for a single query we

66
00:02:41,280 --> 00:02:43,200
define its coverage as all the domain

67
00:02:43,200 --> 00:02:45,920
points which if removed would change the

68
00:02:45,920 --> 00:02:47,680
answer to that query

69
00:02:47,680 --> 00:02:50,319
and likewise we can define the coverage

70
00:02:50,319 --> 00:02:52,879
of a set of queries as the intersection

71
00:02:52,879 --> 00:02:54,080
of the

72
00:02:54,080 --> 00:02:56,000
individual coverages

73
00:02:56,000 --> 00:02:58,319
the maximum overlap is then

74
00:02:58,319 --> 00:02:59,360
the

75
00:02:59,360 --> 00:03:02,239
maximum budget consumption by any subset

76
00:03:02,239 --> 00:03:03,840
of queries that

77
00:03:03,840 --> 00:03:06,080
overlap

78
00:03:06,080 --> 00:03:06,879
so

79
00:03:06,879 --> 00:03:08,800
optimal composition would then be

80
00:03:08,800 --> 00:03:10,159
related to

81
00:03:10,159 --> 00:03:12,000
the maximum overlap in the sense that

82
00:03:12,000 --> 00:03:14,800
the privacy loss would be exactly the

83
00:03:14,800 --> 00:03:16,560
maximum overlap and the rest of the

84
00:03:16,560 --> 00:03:20,800
queries we'll be composing in parallel

85
00:03:20,800 --> 00:03:22,640
so how do we compute that a naive

86
00:03:22,640 --> 00:03:25,040
solution would look at all the possible

87
00:03:25,040 --> 00:03:27,280
subset of queries to check if they

88
00:03:27,280 --> 00:03:28,799
overlap

89
00:03:28,799 --> 00:03:30,959
and there are two different parameters

90
00:03:30,959 --> 00:03:32,959
which affect the complexity one is the

91
00:03:32,959 --> 00:03:34,640
number of boost because we need to check

92
00:03:34,640 --> 00:03:36,799
all possible subsets the other one is

93
00:03:36,799 --> 00:03:39,360
the domain size which is exponential in

94
00:03:39,360 --> 00:03:41,440
the number of attributes and the reason

95
00:03:41,440 --> 00:03:43,440
for that is in order to check if queries

96
00:03:43,440 --> 00:03:45,200
overlap we need to go through all the

97
00:03:45,200 --> 00:03:46,640
domain points

98
00:03:46,640 --> 00:03:48,879
in the naive way

99
00:03:48,879 --> 00:03:49,680
and

100
00:03:49,680 --> 00:03:51,920
notice that the domain points is

101
00:03:51,920 --> 00:03:54,080
different from the actual data points

102
00:03:54,080 --> 00:03:57,760
the main points covers all possible

103
00:03:57,760 --> 00:04:01,519
data points that there could be

104
00:04:01,519 --> 00:04:04,080
so in order to tame this complexity we

105
00:04:04,080 --> 00:04:06,560
focus on

106
00:04:06,560 --> 00:04:08,159
a subset of queries called predicate

107
00:04:08,159 --> 00:04:09,599
degrees these are defined as

108
00:04:09,599 --> 00:04:11,200
conjunctions

109
00:04:11,200 --> 00:04:14,159
of predicates on individual attributes

110
00:04:14,159 --> 00:04:18,238
so q1 2 q3 are examples of predicted

111
00:04:18,238 --> 00:04:20,079
queries

112
00:04:20,079 --> 00:04:22,400
on the other hand the query says

113
00:04:22,400 --> 00:04:25,840
postcode a or native

114
00:04:25,840 --> 00:04:28,240
equals n is not a pretty good query

115
00:04:28,240 --> 00:04:32,560
because it's actually a disjunction

116
00:04:32,560 --> 00:04:34,240
and the reason to use pretty good

117
00:04:34,240 --> 00:04:38,000
queries is that we can um

118
00:04:38,000 --> 00:04:39,520
check if those

119
00:04:39,520 --> 00:04:41,360
if any two queries are disjoined by

120
00:04:41,360 --> 00:04:42,880
looking at the

121
00:04:42,880 --> 00:04:45,440
predicates individually if

122
00:04:45,440 --> 00:04:47,520
on any attribute the predicates are

123
00:04:47,520 --> 00:04:48,960
disjoint

124
00:04:48,960 --> 00:04:51,120
then the queries are destroyed

125
00:04:51,120 --> 00:04:54,840
as in this case

126
00:04:56,240 --> 00:04:58,960
unfortunately even if we can check

127
00:04:58,960 --> 00:05:01,600
pairwise where the queries overlap the

128
00:05:01,600 --> 00:05:04,080
problem remains that'd be hard because

129
00:05:04,080 --> 00:05:07,039
even if they pairwise overlapped the

130
00:05:07,039 --> 00:05:10,800
joint coverage might be empty

131
00:05:10,800 --> 00:05:12,960
and this is not surprising an instance

132
00:05:12,960 --> 00:05:15,120
of this problem is has been shown to be

133
00:05:15,120 --> 00:05:17,039
at the heart which is defined in terms

134
00:05:17,039 --> 00:05:19,440
of finding the l1 sensitivity of a

135
00:05:19,440 --> 00:05:21,680
subset of queries

136
00:05:21,680 --> 00:05:23,680
and in our paper we also show that the

137
00:05:23,680 --> 00:05:25,759
more general problem of maximum overlap

138
00:05:25,759 --> 00:05:27,759
is that we complete

139
00:05:27,759 --> 00:05:30,240
uh we calling it more general because it

140
00:05:30,240 --> 00:05:33,520
covers uh dp mechanisms which are not

141
00:05:33,520 --> 00:05:35,520
defined in terms of elbow sensitivity

142
00:05:35,520 --> 00:05:38,000
for example the calcium

143
00:05:38,000 --> 00:05:40,320
so if this is empty complete what can we

144
00:05:40,320 --> 00:05:42,479
do

145
00:05:42,639 --> 00:05:44,960
our idea is to formulate the problem in

146
00:05:44,960 --> 00:05:47,840
terms of graphs so one

147
00:05:47,840 --> 00:05:50,000
way would be to formulate

148
00:05:50,000 --> 00:05:51,520
in terms of a

149
00:05:51,520 --> 00:05:53,199
hypergraph so each node in the

150
00:05:53,199 --> 00:05:55,039
hypergraph is a query

151
00:05:55,039 --> 00:05:58,000
and a hyperedge is any subset of queries

152
00:05:58,000 --> 00:05:58,960
that

153
00:05:58,960 --> 00:06:02,479
has a coverage status on it

154
00:06:02,479 --> 00:06:05,199
then we get the maximum overlap readily

155
00:06:05,199 --> 00:06:07,840
as the

156
00:06:08,000 --> 00:06:09,280
cardinal

157
00:06:09,280 --> 00:06:11,120
as they hybrid with the largest

158
00:06:11,120 --> 00:06:14,240
cardinality problem is that this

159
00:06:14,240 --> 00:06:16,479
has exponential time to construct this

160
00:06:16,479 --> 00:06:18,639
hypergraph so instead we

161
00:06:18,639 --> 00:06:20,400
focus on the query graph

162
00:06:20,400 --> 00:06:23,199
each node again is a query

163
00:06:23,199 --> 00:06:24,960
and there is an edge between two nodes

164
00:06:24,960 --> 00:06:26,960
if they overlap

165
00:06:26,960 --> 00:06:29,199
this only takes t-square time to

166
00:06:29,199 --> 00:06:31,360
construct but we don't get maximum

167
00:06:31,360 --> 00:06:33,840
overlap readily instead we are going to

168
00:06:33,840 --> 00:06:35,840
link properties of this graph to maximum

169
00:06:35,840 --> 00:06:39,039
overlap so here's an example of the

170
00:06:39,039 --> 00:06:41,520
query graph formulation we are given six

171
00:06:41,520 --> 00:06:42,720
queries here

172
00:06:42,720 --> 00:06:45,520
on the top here we have the query graph

173
00:06:45,520 --> 00:06:48,400
and the bottom we have a hypergraph

174
00:06:48,400 --> 00:06:49,520
the three

175
00:06:49,520 --> 00:06:51,280
three queries here

176
00:06:51,280 --> 00:06:53,199
have a joint coverage that is not empty

177
00:06:53,199 --> 00:06:55,280
and this is indicated by this hybrid

178
00:06:55,280 --> 00:06:56,319
edge

179
00:06:56,319 --> 00:06:59,280
of shading integrate

180
00:06:59,280 --> 00:07:02,319
so which problems could then be related

181
00:07:02,319 --> 00:07:04,560
to maximum overlap one of them is

182
00:07:04,560 --> 00:07:06,560
maximum click which is defined as the

183
00:07:06,560 --> 00:07:09,440
size of the largest

184
00:07:09,440 --> 00:07:11,759
complete sub graph

185
00:07:11,759 --> 00:07:13,440
the problem is in this case we need to

186
00:07:13,440 --> 00:07:16,000
use an exact algorithm because any

187
00:07:16,000 --> 00:07:18,800
approximate algorithm may underestimate

188
00:07:18,800 --> 00:07:20,800
the click number which could in turn be

189
00:07:20,800 --> 00:07:22,560
less than the maximum overlap which is

190
00:07:22,560 --> 00:07:25,280
could be a privacy breach our proposal

191
00:07:25,280 --> 00:07:27,039
is instead to use

192
00:07:27,039 --> 00:07:28,840
the chromatic

193
00:07:28,840 --> 00:07:32,319
number and the advantage here is that we

194
00:07:32,319 --> 00:07:34,240
can use approximate algorithms for that

195
00:07:34,240 --> 00:07:37,199
because it's a minimization problem

196
00:07:37,199 --> 00:07:39,360
and hence any approximation would be

197
00:07:39,360 --> 00:07:41,199
higher than the maximum overlap and no

198
00:07:41,199 --> 00:07:44,800
privacy leakage would be a

199
00:07:44,800 --> 00:07:47,440
good result

200
00:07:47,680 --> 00:07:49,520
um even though these two problems are

201
00:07:49,520 --> 00:07:51,120
still going to be complete

202
00:07:51,120 --> 00:07:52,879
they have been studied

203
00:07:52,879 --> 00:07:56,000
very extensively and hence the algorithm

204
00:07:56,000 --> 00:07:58,400
might be efficient in practice

205
00:07:58,400 --> 00:08:00,319
so in order to check that we have our

206
00:08:00,319 --> 00:08:03,120
experimental setup we are checking the

207
00:08:03,120 --> 00:08:05,520
efficiency of the algorithm

208
00:08:05,520 --> 00:08:08,639
algorithms in terms of two parameters in

209
00:08:08,639 --> 00:08:10,639
general at the domain size and the

210
00:08:10,639 --> 00:08:12,639
number of queries and we also have a

211
00:08:12,639 --> 00:08:14,160
timeline because we are looking at

212
00:08:14,160 --> 00:08:16,720
online mechanism so any query that takes

213
00:08:16,720 --> 00:08:18,560
more than 60 seconds

214
00:08:18,560 --> 00:08:20,639
is considered to have

215
00:08:20,639 --> 00:08:22,240
failed

216
00:08:22,240 --> 00:08:23,840
in order to

217
00:08:23,840 --> 00:08:26,319
test utility we look at the percentage

218
00:08:26,319 --> 00:08:28,319
gain if only sequential composition was

219
00:08:28,319 --> 00:08:30,479
applied and we have both synthetic and

220
00:08:30,479 --> 00:08:32,240
real census queries

221
00:08:32,240 --> 00:08:34,399
and the algorithms are exact maximum

222
00:08:34,399 --> 00:08:35,360
click

223
00:08:35,360 --> 00:08:37,360
exact maximum overlap

224
00:08:37,360 --> 00:08:41,679
and the approximate chromatic number

225
00:08:41,679 --> 00:08:43,839
so

226
00:08:43,839 --> 00:08:46,000
the first of our results

227
00:08:46,000 --> 00:08:48,000
shows

228
00:08:48,000 --> 00:08:50,000
the feasibility of the algorithm in

229
00:08:50,000 --> 00:08:52,000
terms of the increasing domain size on

230
00:08:52,000 --> 00:08:53,760
the y-axis and the increasing number of

231
00:08:53,760 --> 00:08:56,480
queries the yellow regions show those

232
00:08:56,480 --> 00:08:58,880
queries that were answered

233
00:08:58,880 --> 00:09:00,959
within the timeout of 60 seconds and we

234
00:09:00,959 --> 00:09:02,800
can see that the approximate chromatic

235
00:09:02,800 --> 00:09:06,560
number can handle more queries

236
00:09:06,560 --> 00:09:08,959
than the maximum clip

237
00:09:08,959 --> 00:09:11,600
in terms of utility we worked on a data

238
00:09:11,600 --> 00:09:15,200
set of real sensors census queries

239
00:09:15,200 --> 00:09:16,880
obtained from australian bureau of

240
00:09:16,880 --> 00:09:19,680
statistics and we we can see from this

241
00:09:19,680 --> 00:09:22,640
table that in almost all cases

242
00:09:22,640 --> 00:09:25,040
we obtain good utility

243
00:09:25,040 --> 00:09:25,839
to

244
00:09:25,839 --> 00:09:28,640
the maximum overlap

245
00:09:28,640 --> 00:09:30,480
and this is over

246
00:09:30,480 --> 00:09:34,640
simple sequential composition

247
00:09:35,120 --> 00:09:37,279
uh there are other comp contributions in

248
00:09:37,279 --> 00:09:39,279
our paper

249
00:09:39,279 --> 00:09:40,320
um

250
00:09:40,320 --> 00:09:42,959
one of them is that instead of simply

251
00:09:42,959 --> 00:09:45,519
defining maximum overlap as a fixed

252
00:09:45,519 --> 00:09:47,040
mechanism and

253
00:09:47,040 --> 00:09:50,080
t different queries we can define it as

254
00:09:50,080 --> 00:09:52,800
the composition of two different dp

255
00:09:52,800 --> 00:09:54,399
mechanisms

256
00:09:54,399 --> 00:09:58,160
and see if they compose in parallel

257
00:09:58,160 --> 00:10:00,959
so in order to

258
00:10:01,360 --> 00:10:03,040
define this we

259
00:10:03,040 --> 00:10:04,880
defined that under the notion of f

260
00:10:04,880 --> 00:10:06,640
differential privacy which is a recent

261
00:10:06,640 --> 00:10:08,480
notion

262
00:10:08,480 --> 00:10:11,279
of differential privacy

263
00:10:11,279 --> 00:10:13,279
characterized in terms of

264
00:10:13,279 --> 00:10:16,079
hypothesis testing

265
00:10:16,079 --> 00:10:18,880
one of our contributions is to prove a

266
00:10:18,880 --> 00:10:22,560
parallel composition theorem for ftp

267
00:10:22,560 --> 00:10:25,440
and also then use that to have a

268
00:10:25,440 --> 00:10:28,000
arbitrary optimal composition for ftp

269
00:10:28,000 --> 00:10:31,120
mechanisms the reason to focus on fdp is

270
00:10:31,120 --> 00:10:32,959
that we can then relate all these

271
00:10:32,959 --> 00:10:35,680
results to other flavors of dp through

272
00:10:35,680 --> 00:10:39,519
the connection with fdp

273
00:10:39,519 --> 00:10:41,279
there are some limitations in our

274
00:10:41,279 --> 00:10:43,440
current work

275
00:10:43,440 --> 00:10:45,440
one of them is that we

276
00:10:45,440 --> 00:10:46,959
with each new query we need to

277
00:10:46,959 --> 00:10:49,519
regenerate the query graph

278
00:10:49,519 --> 00:10:50,320
um

279
00:10:50,320 --> 00:10:51,760
so instead of that

280
00:10:51,760 --> 00:10:54,160
a dynamic approach which only updates

281
00:10:54,160 --> 00:10:58,640
the current choreograph could be useful

282
00:10:58,839 --> 00:11:01,519
likewise um we could do some

283
00:11:01,519 --> 00:11:04,959
pre-processing before the query graph is

284
00:11:04,959 --> 00:11:07,680
constructed so this could be

285
00:11:07,680 --> 00:11:11,439
that queries which are obviously

286
00:11:11,519 --> 00:11:13,440
can be obviously grouped together could

287
00:11:13,440 --> 00:11:16,800
be grouped beforehand

288
00:11:16,800 --> 00:11:18,800
another thing is we have defined query

289
00:11:18,800 --> 00:11:21,360
overlap as a binary problem but we could

290
00:11:21,360 --> 00:11:23,600
look into the extent

291
00:11:23,600 --> 00:11:24,720
by which

292
00:11:24,720 --> 00:11:26,480
queries overlap

293
00:11:26,480 --> 00:11:28,480
and may be able to squeeze more out of

294
00:11:28,480 --> 00:11:31,600
the privacy budget using that approach

295
00:11:31,600 --> 00:11:34,640
and um some other pointers could be to

296
00:11:34,640 --> 00:11:37,360
use approximation algorithm for hyper

297
00:11:37,360 --> 00:11:38,959
graphs instead of just looking at the

298
00:11:38,959 --> 00:11:40,079
query graph

299
00:11:40,079 --> 00:11:41,600
or

300
00:11:41,600 --> 00:11:44,160
any other problem that could relate to

301
00:11:44,160 --> 00:11:46,399
maximum overlap for which we know some

302
00:11:46,399 --> 00:11:49,600
efficient algorithms in practice

303
00:11:49,600 --> 00:11:52,240
so that's the end of the presentation if

304
00:11:52,240 --> 00:11:55,760
you have any questions you can email

305
00:11:55,760 --> 00:11:59,240
may or so

