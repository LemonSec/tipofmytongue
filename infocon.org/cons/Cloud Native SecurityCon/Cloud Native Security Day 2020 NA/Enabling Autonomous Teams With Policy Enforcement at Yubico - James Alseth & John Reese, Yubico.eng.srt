1
00:00:00,000 --> 00:00:02,080
hi welcome to our talk on enabling

2
00:00:02,080 --> 00:00:03,439
autonomous teams through policy

3
00:00:03,439 --> 00:00:04,400
enforcement

4
00:00:04,400 --> 00:00:05,759
before we get started a quick

5
00:00:05,759 --> 00:00:07,759
introduction about ourselves

6
00:00:07,759 --> 00:00:09,200
my name is james alsoth and i'm a

7
00:00:09,200 --> 00:00:11,040
security engineer at ubico currently

8
00:00:11,040 --> 00:00:13,759
focused on cloud infrastructure security

9
00:00:13,759 --> 00:00:15,759
presenting with me is john reese who is

10
00:00:15,759 --> 00:00:17,600
a software engineer at yubico with a lot

11
00:00:17,600 --> 00:00:20,080
of experience in go and kubernetes

12
00:00:20,080 --> 00:00:21,760
before we get started let's go over what

13
00:00:21,760 --> 00:00:23,760
we're going to be discussing today

14
00:00:23,760 --> 00:00:25,039
first we're going to start with a brief

15
00:00:25,039 --> 00:00:26,960
history of kubernetes at yubico

16
00:00:26,960 --> 00:00:28,560
how we got started on our kubernetes

17
00:00:28,560 --> 00:00:30,560
journey and some of the previous gaps in

18
00:00:30,560 --> 00:00:33,200
our kubernetes tech stack

19
00:00:33,200 --> 00:00:35,120
we're then going to discuss how policy

20
00:00:35,120 --> 00:00:36,800
helps to address those gaps and enable

21
00:00:36,800 --> 00:00:38,800
more autonomous teams

22
00:00:38,800 --> 00:00:40,079
we're definitely going to talk about the

23
00:00:40,079 --> 00:00:41,760
awesome open source tooling that enables

24
00:00:41,760 --> 00:00:44,320
us to enforce these policies

25
00:00:44,320 --> 00:00:46,000
and we're going to wrap up with

26
00:00:46,000 --> 00:00:47,920
discussing our journey thus far

27
00:00:47,920 --> 00:00:49,440
sort of where we are now and where we

28
00:00:49,440 --> 00:00:51,280
see ourselves in the future

29
00:00:51,280 --> 00:00:52,640
and of course there will be some time

30
00:00:52,640 --> 00:00:55,520
with them for questions

31
00:00:55,520 --> 00:00:57,280
so let's chat about how ubico got

32
00:00:57,280 --> 00:00:58,800
started on its kubernetes adoption

33
00:00:58,800 --> 00:00:59,680
journey

34
00:00:59,680 --> 00:01:01,840
for us that started about two years ago

35
00:01:01,840 --> 00:01:03,120
with an initiative led by our

36
00:01:03,120 --> 00:01:04,799
infrastructure team to standardize the

37
00:01:04,799 --> 00:01:07,040
platform that our services run on

38
00:01:07,040 --> 00:01:09,280
uh previous to this we were mostly

39
00:01:09,280 --> 00:01:10,720
running on virtual machines

40
00:01:10,720 --> 00:01:12,080
and we didn't have too many

41
00:01:12,080 --> 00:01:14,960
containerized workloads yet

42
00:01:14,960 --> 00:01:16,960
like many organizations we used to

43
00:01:16,960 --> 00:01:18,479
manage kubernetes service to get up and

44
00:01:18,479 --> 00:01:20,000
running as fast as possible

45
00:01:20,000 --> 00:01:21,680
and to help avoid some of the pain

46
00:01:21,680 --> 00:01:24,840
points of cluster setup and cluster

47
00:01:24,840 --> 00:01:26,080
management

48
00:01:26,080 --> 00:01:27,280
for us though probably the first

49
00:01:27,280 --> 00:01:29,040
question that pops into our head is how

50
00:01:29,040 --> 00:01:30,400
can we ensure that the kubernetes

51
00:01:30,400 --> 00:01:32,640
workloads are configured securely

52
00:01:32,640 --> 00:01:34,720
and what that's really asking is how do

53
00:01:34,720 --> 00:01:36,320
we control changes that are made to the

54
00:01:36,320 --> 00:01:37,680
cluster

55
00:01:37,680 --> 00:01:39,439
well we started where i think most

56
00:01:39,439 --> 00:01:42,560
organizations do leaning on three things

57
00:01:42,560 --> 00:01:45,200
authentication authorization as well as

58
00:01:45,200 --> 00:01:48,320
consistent peer review

59
00:01:48,640 --> 00:01:51,200
diving into the first of those we were

60
00:01:51,200 --> 00:01:52,799
able to take advantage of the managed

61
00:01:52,799 --> 00:01:54,079
kubernetes offering

62
00:01:54,079 --> 00:01:55,840
than that it allowed us to tie into our

63
00:01:55,840 --> 00:01:58,000
existing identity provider very easily

64
00:01:58,000 --> 00:01:59,040
so we got up and running with

65
00:01:59,040 --> 00:02:01,200
authentication pretty quick

66
00:02:01,200 --> 00:02:02,880
additionally it probably comes to no

67
00:02:02,880 --> 00:02:04,479
surprise to those of you who are

68
00:02:04,479 --> 00:02:05,600
familiar with yubico

69
00:02:05,600 --> 00:02:07,680
but we also require strong multi-factor

70
00:02:07,680 --> 00:02:09,280
authentication with web on

71
00:02:09,280 --> 00:02:12,720
web authent and yubikeys additionally we

72
00:02:12,720 --> 00:02:14,480
regularly expire the sessions for those

73
00:02:14,480 --> 00:02:16,319
with access to infrastructure

74
00:02:16,319 --> 00:02:18,080
requiring re-authentication with

75
00:02:18,080 --> 00:02:21,920
multi-factor authentication frequently

76
00:02:21,920 --> 00:02:22,640
moving on to

77
00:02:22,640 --> 00:02:24,720
the role-based authorization thankfully

78
00:02:24,720 --> 00:02:26,640
kubernetes has role-based access control

79
00:02:26,640 --> 00:02:27,280
built in

80
00:02:27,280 --> 00:02:29,680
and it has for quite a few versions now

81
00:02:29,680 --> 00:02:30,879
this allows us to tie

82
00:02:30,879 --> 00:02:34,080
users groups and service accounts to any

83
00:02:34,080 --> 00:02:36,400
any role these roles can either be

84
00:02:36,400 --> 00:02:37,120
scoped to

85
00:02:37,120 --> 00:02:39,760
a namespace or they can be applied

86
00:02:39,760 --> 00:02:41,360
cluster-wide

87
00:02:41,360 --> 00:02:42,879
these roles allow for extremely

88
00:02:42,879 --> 00:02:44,400
fine-grained permissions

89
00:02:44,400 --> 00:02:46,400
allowing you to specify the exact verbs

90
00:02:46,400 --> 00:02:47,440
an actor can use

91
00:02:47,440 --> 00:02:50,080
such as create update or delete what

92
00:02:50,080 --> 00:02:52,000
types of resources they can act on

93
00:02:52,000 --> 00:02:54,400
such as a deployment resource and it can

94
00:02:54,400 --> 00:02:55,440
even go as far as

95
00:02:55,440 --> 00:02:57,200
allow restricting it only to

96
00:02:57,200 --> 00:03:00,720
specifically named resources

97
00:03:00,720 --> 00:03:02,480
again our managed kubernetes offering

98
00:03:02,480 --> 00:03:04,640
made this easier by tying groups into

99
00:03:04,640 --> 00:03:09,279
from our idp into this system

100
00:03:09,760 --> 00:03:11,599
and the final tool in our toolbelt was

101
00:03:11,599 --> 00:03:12,800
peer review

102
00:03:12,800 --> 00:03:14,560
for us we enforce this using github

103
00:03:14,560 --> 00:03:16,239
branch protection rules ensuring that

104
00:03:16,239 --> 00:03:17,680
all changes happened through pull

105
00:03:17,680 --> 00:03:18,800
requests

106
00:03:18,800 --> 00:03:20,319
and on each of these pull requests we

107
00:03:20,319 --> 00:03:22,319
required at least one other person to

108
00:03:22,319 --> 00:03:24,159
review

109
00:03:24,159 --> 00:03:26,720
for us most of this peer review work

110
00:03:26,720 --> 00:03:27,200
landed

111
00:03:27,200 --> 00:03:29,440
on our infrastructure team because they

112
00:03:29,440 --> 00:03:30,959
had the most experience of kubernetes

113
00:03:30,959 --> 00:03:32,879
and had spent the most time to

114
00:03:32,879 --> 00:03:34,640
learn about all of the best practices

115
00:03:34,640 --> 00:03:37,839
security or otherwise

116
00:03:38,000 --> 00:03:40,560
about peer review though it definitely

117
00:03:40,560 --> 00:03:42,239
has some drawbacks when it's the only

118
00:03:42,239 --> 00:03:43,840
way that you're restricting changes to

119
00:03:43,840 --> 00:03:44,879
your clusters

120
00:03:44,879 --> 00:03:47,040
for one it needs to be consistent in

121
00:03:47,040 --> 00:03:48,480
order to be effective

122
00:03:48,480 --> 00:03:50,239
and when you have consistent review

123
00:03:50,239 --> 00:03:52,000
that's a significant time investment for

124
00:03:52,000 --> 00:03:53,680
the reviewers

125
00:03:53,680 --> 00:03:55,599
because of this it often bottlenecks on

126
00:03:55,599 --> 00:03:57,680
the team or individual that has the most

127
00:03:57,680 --> 00:03:59,200
experience with the technology

128
00:03:59,200 --> 00:04:00,319
which of course in this case is

129
00:04:00,319 --> 00:04:03,200
kubernetes and all of this adds up to

130
00:04:03,200 --> 00:04:04,959
slowing down the release cycle

131
00:04:04,959 --> 00:04:06,799
and this is important because when he

132
00:04:06,799 --> 00:04:08,319
teams hit too much friction

133
00:04:08,319 --> 00:04:09,920
they often start to work around your

134
00:04:09,920 --> 00:04:12,640
processes whether you know it or not

135
00:04:12,640 --> 00:04:14,400
this is of course bad for security

136
00:04:14,400 --> 00:04:16,079
because you no longer have control over

137
00:04:16,079 --> 00:04:17,918
these configurations

138
00:04:17,918 --> 00:04:19,759
but they're also bad for just general

139
00:04:19,759 --> 00:04:24,079
cluster consistency and maintainability

140
00:04:24,320 --> 00:04:26,800
none of this was really a surprise to us

141
00:04:26,800 --> 00:04:27,520
we kind of

142
00:04:27,520 --> 00:04:29,199
saw this coming from a mile away but

143
00:04:29,199 --> 00:04:30,639
that didn't make the problem any less

144
00:04:30,639 --> 00:04:31,680
real when we had to deal

145
00:04:31,680 --> 00:04:34,880
with it so what we did is we spent some

146
00:04:34,880 --> 00:04:36,479
time researching what other

147
00:04:36,479 --> 00:04:38,000
organizations were doing and what the

148
00:04:38,000 --> 00:04:39,759
kubernetes community was doing

149
00:04:39,759 --> 00:04:41,600
and for us the answer became abundantly

150
00:04:41,600 --> 00:04:44,560
clear policy was the way forward

151
00:04:44,560 --> 00:04:46,240
when people think of policy it's usually

152
00:04:46,240 --> 00:04:47,840
a negative reaction as they

153
00:04:47,840 --> 00:04:49,440
imagine having more hoops to jump

154
00:04:49,440 --> 00:04:52,320
through in order to get their work done

155
00:04:52,320 --> 00:04:54,880
however in our case since all of these

156
00:04:54,880 --> 00:04:55,440
changes

157
00:04:55,440 --> 00:04:57,199
to kubernetes happen through the api

158
00:04:57,199 --> 00:04:59,759
server working with structured json data

159
00:04:59,759 --> 00:05:01,280
we can automate the enforcement of these

160
00:05:01,280 --> 00:05:04,000
policies entirely

161
00:05:04,000 --> 00:05:05,440
but what do we mean when we say that in

162
00:05:05,440 --> 00:05:07,120
this context well

163
00:05:07,120 --> 00:05:09,039
it allows us to enforce what we actually

164
00:05:09,039 --> 00:05:11,520
care about for example we don't really

165
00:05:11,520 --> 00:05:13,600
care that a services team is deploying a

166
00:05:13,600 --> 00:05:15,039
new version of their service

167
00:05:15,039 --> 00:05:17,280
that's a part of their core job function

168
00:05:17,280 --> 00:05:18,880
however we do care that when they do

169
00:05:18,880 --> 00:05:19,280
that

170
00:05:19,280 --> 00:05:22,400
the resources are configured securely

171
00:05:22,400 --> 00:05:24,800
for example we probably want to ensure

172
00:05:24,800 --> 00:05:26,160
that the workloads aren't running as

173
00:05:26,160 --> 00:05:26,800
root

174
00:05:26,800 --> 00:05:28,880
and that they don't have any extra linux

175
00:05:28,880 --> 00:05:31,600
capabilities attached to them

176
00:05:31,600 --> 00:05:33,360
these policies can also easily extend

177
00:05:33,360 --> 00:05:35,680
past security related settings though

178
00:05:35,680 --> 00:05:38,479
for example we can require each resource

179
00:05:38,479 --> 00:05:38,960
in a

180
00:05:38,960 --> 00:05:40,800
namespace to have a certain label set

181
00:05:40,800 --> 00:05:42,080
that identifies the owner of that

182
00:05:42,080 --> 00:05:43,360
resource

183
00:05:43,360 --> 00:05:45,199
that makes it easy so when you're

184
00:05:45,199 --> 00:05:46,880
working on troubleshooting an issue

185
00:05:46,880 --> 00:05:48,800
or you just need to know who's who owns

186
00:05:48,800 --> 00:05:50,400
that resource it's right there in the

187
00:05:50,400 --> 00:05:53,199
metadata of the resource

188
00:05:53,199 --> 00:05:54,560
with that i'd like to turn it over to

189
00:05:54,560 --> 00:05:56,560
john to discuss the tooling we've

190
00:05:56,560 --> 00:05:59,600
selected to enforce these policies

191
00:05:59,600 --> 00:06:02,000
thanks james so as james mentioned we

192
00:06:02,000 --> 00:06:03,919
knew we wanted to use policy to solve a

193
00:06:03,919 --> 00:06:05,680
lot of the problems we were having at

194
00:06:05,680 --> 00:06:06,639
yubico

195
00:06:06,639 --> 00:06:08,479
we looked at a lot of the tools out

196
00:06:08,479 --> 00:06:10,639
there that solved this problem

197
00:06:10,639 --> 00:06:13,280
but opa was the clear winner in this

198
00:06:13,280 --> 00:06:15,440
space we saw a lot of adoption with

199
00:06:15,440 --> 00:06:16,400
other tools

200
00:06:16,400 --> 00:06:18,400
that we knew we wanted to leverage and

201
00:06:18,400 --> 00:06:19,600
it came with its own

202
00:06:19,600 --> 00:06:22,400
policy language but before getting into

203
00:06:22,400 --> 00:06:23,360
opa itself

204
00:06:23,360 --> 00:06:25,199
it's really important to understand what

205
00:06:25,199 --> 00:06:26,400
a policy is

206
00:06:26,400 --> 00:06:29,600
what it looks like and rego itself so

207
00:06:29,600 --> 00:06:32,400
rego is the policy language that opa

208
00:06:32,400 --> 00:06:33,360
knows

209
00:06:33,360 --> 00:06:36,720
that understands and on my screen here

210
00:06:36,720 --> 00:06:38,720
you can see a policy

211
00:06:38,720 --> 00:06:41,600
for a kubernetes manifest that says that

212
00:06:41,600 --> 00:06:42,880
it must have

213
00:06:42,880 --> 00:06:45,520
a owner label on it specifically

214
00:06:45,520 --> 00:06:46,400
namespaces

215
00:06:46,400 --> 00:06:49,120
must have an owner label so when a when

216
00:06:49,120 --> 00:06:50,319
a request comes in

217
00:06:50,319 --> 00:06:53,039
in the cluster for a namespace creation

218
00:06:53,039 --> 00:06:55,199
this policy will first check to see

219
00:06:55,199 --> 00:06:57,199
this input that's coming in this input

220
00:06:57,199 --> 00:06:59,919
document is it of type namespace

221
00:06:59,919 --> 00:07:01,919
and if it doesn't have an owner's label

222
00:07:01,919 --> 00:07:03,919
on it return a message that says

223
00:07:03,919 --> 00:07:05,680
namespaces must have an owner so the

224
00:07:05,680 --> 00:07:08,319
user the uh the individual trying to

225
00:07:08,319 --> 00:07:10,319
deploy this namespace knows how to fix

226
00:07:10,319 --> 00:07:10,880
it

227
00:07:10,880 --> 00:07:14,000
and so the important takeaway here

228
00:07:14,000 --> 00:07:17,039
is the input keyword the input keyword

229
00:07:17,039 --> 00:07:20,080
denotes a input document for rego and

230
00:07:20,080 --> 00:07:22,080
the input document is just the

231
00:07:22,080 --> 00:07:24,720
structured data in our case it's a yaml

232
00:07:24,720 --> 00:07:25,280
file

233
00:07:25,280 --> 00:07:28,240
so anything beyond the input dot should

234
00:07:28,240 --> 00:07:30,000
look really familiar we see kind we

235
00:07:30,000 --> 00:07:33,440
see metadata but the the input dot

236
00:07:33,440 --> 00:07:35,280
and anything after that is just

237
00:07:35,280 --> 00:07:36,960
dependent upon the data

238
00:07:36,960 --> 00:07:39,360
that you give it it could be terraform

239
00:07:39,360 --> 00:07:40,800
it could be a docker file

240
00:07:40,800 --> 00:07:44,080
any sort of of structured data so

241
00:07:44,080 --> 00:07:47,120
again very generic language um

242
00:07:47,120 --> 00:07:50,000
immensely immensely powerful and so now

243
00:07:50,000 --> 00:07:51,120
that we have this

244
00:07:51,120 --> 00:07:54,000
this rego file we need a way to actually

245
00:07:54,000 --> 00:07:54,879
determine

246
00:07:54,879 --> 00:07:57,360
if the document that we give it would be

247
00:07:57,360 --> 00:07:59,199
would be in violation and there's a few

248
00:07:59,199 --> 00:08:00,800
ways to do this right we could

249
00:08:00,800 --> 00:08:03,199
we could be the input document the the

250
00:08:03,199 --> 00:08:04,080
rego

251
00:08:04,080 --> 00:08:06,639
to james and he can verify on a

252
00:08:06,639 --> 00:08:08,240
case-by-case basis whether or not the

253
00:08:08,240 --> 00:08:09,120
document

254
00:08:09,120 --> 00:08:11,599
is uh is violated or not but we're we're

255
00:08:11,599 --> 00:08:12,800
all about automation so

256
00:08:12,800 --> 00:08:15,120
as briefly talked about before we

257
00:08:15,120 --> 00:08:16,560
decided to go with uh with the open

258
00:08:16,560 --> 00:08:18,000
policy agent and just like

259
00:08:18,000 --> 00:08:19,840
just look at the logo of of course we

260
00:08:19,840 --> 00:08:21,360
did um there's

261
00:08:21,360 --> 00:08:23,039
there's just there's no reason not to

262
00:08:23,039 --> 00:08:25,280
choose opa it's a work

263
00:08:25,280 --> 00:08:28,720
of art but no really we um

264
00:08:28,720 --> 00:08:30,080
the community is great again there's

265
00:08:30,080 --> 00:08:32,080
there's so much adoption around

266
00:08:32,080 --> 00:08:34,559
opa it was um it was it's been it's been

267
00:08:34,559 --> 00:08:36,719
a real joy to leverage

268
00:08:36,719 --> 00:08:39,440
opa um working in their their slack

269
00:08:39,440 --> 00:08:40,320
channel

270
00:08:40,320 --> 00:08:42,719
everyone's super friendly there's always

271
00:08:42,719 --> 00:08:44,320
someone there to help you out

272
00:08:44,320 --> 00:08:45,839
it was it was a really good a really

273
00:08:45,839 --> 00:08:47,680
really good choice for us

274
00:08:47,680 --> 00:08:51,200
and so how this how this works how opa

275
00:08:51,200 --> 00:08:52,560
works as a service

276
00:08:52,560 --> 00:08:54,959
you uh you deploy it somewhere be it

277
00:08:54,959 --> 00:08:56,160
kubernetes

278
00:08:56,160 --> 00:08:58,080
be it a web server wherever you want to

279
00:08:58,080 --> 00:08:59,600
put it as long as you can get a web

280
00:08:59,600 --> 00:09:01,040
request to it

281
00:09:01,040 --> 00:09:03,680
um and then you also include your your

282
00:09:03,680 --> 00:09:05,360
regular files with that with that

283
00:09:05,360 --> 00:09:07,040
deployment so opa can know which

284
00:09:07,040 --> 00:09:08,080
policies

285
00:09:08,080 --> 00:09:10,880
you want it to enforce and so you you

286
00:09:10,880 --> 00:09:13,040
submit an input document again be it a

287
00:09:13,040 --> 00:09:14,240
kubernetes manifest

288
00:09:14,240 --> 00:09:16,880
be it a docker file anything you want

289
00:09:16,880 --> 00:09:18,480
give it to the opa service

290
00:09:18,480 --> 00:09:21,200
it will validate the the document run

291
00:09:21,200 --> 00:09:22,560
through run it through the policies and

292
00:09:22,560 --> 00:09:23,120
tell you

293
00:09:23,120 --> 00:09:25,600
does this document violate any of the

294
00:09:25,600 --> 00:09:26,560
policies you have

295
00:09:26,560 --> 00:09:29,279
loaded into it and there's also the the

296
00:09:29,279 --> 00:09:30,000
really

297
00:09:30,000 --> 00:09:32,080
nice piece of the fact that it can also

298
00:09:32,080 --> 00:09:33,040
take external

299
00:09:33,040 --> 00:09:35,120
data so you can see here in the the

300
00:09:35,120 --> 00:09:36,320
bottom right the

301
00:09:36,320 --> 00:09:39,360
the data document that's external data

302
00:09:39,360 --> 00:09:40,480
and that can come from

303
00:09:40,480 --> 00:09:42,399
any number of sources so if we build on

304
00:09:42,399 --> 00:09:44,399
the previous example of

305
00:09:44,399 --> 00:09:47,440
the policy where that teams must have a

306
00:09:47,440 --> 00:09:50,000
namespace label all name spaces must

307
00:09:50,000 --> 00:09:51,600
have a label of owner on it

308
00:09:51,600 --> 00:09:53,120
we could also add a policy that says

309
00:09:53,120 --> 00:09:54,880
that owners

310
00:09:54,880 --> 00:09:57,680
teams can only own a single namespace

311
00:09:57,680 --> 00:09:58,080
and so

312
00:09:58,080 --> 00:10:00,560
in order to do that we would need some

313
00:10:00,560 --> 00:10:03,120
form of external data in this case a

314
00:10:03,120 --> 00:10:05,279
count of how many namespaces that

315
00:10:05,279 --> 00:10:06,160
they've already

316
00:10:06,160 --> 00:10:09,440
created and so when we create namespaces

317
00:10:09,440 --> 00:10:12,079
when we delete namespaces we can keep

318
00:10:12,079 --> 00:10:14,000
track of that number give it to opa and

319
00:10:14,000 --> 00:10:15,760
then opa can use that when it's

320
00:10:15,760 --> 00:10:18,880
when it's evaluating all of its policies

321
00:10:18,880 --> 00:10:20,720
and so while that was an example of

322
00:10:20,720 --> 00:10:22,399
using op as a service

323
00:10:22,399 --> 00:10:24,720
you can actually use opa as a library

324
00:10:24,720 --> 00:10:26,320
which makes it

325
00:10:26,320 --> 00:10:29,200
so much easier to to enforce policy

326
00:10:29,200 --> 00:10:31,040
there's a lot of tools out there

327
00:10:31,040 --> 00:10:33,920
that will actually take the opa engine

328
00:10:33,920 --> 00:10:34,399
um

329
00:10:34,399 --> 00:10:37,040
import it as a dependency and then run

330
00:10:37,040 --> 00:10:38,399
the the same checks

331
00:10:38,399 --> 00:10:41,680
that uh that opa itself would

332
00:10:41,680 --> 00:10:44,640
and so we really wanted to leverage this

333
00:10:44,640 --> 00:10:46,320
um this type of functionality

334
00:10:46,320 --> 00:10:49,200
in order to shift our policy enforcement

335
00:10:49,200 --> 00:10:51,200
to the left because we quickly realized

336
00:10:51,200 --> 00:10:51,839
that

337
00:10:51,839 --> 00:10:55,360
when we deployed opa while we were able

338
00:10:55,360 --> 00:10:55,839
to

339
00:10:55,839 --> 00:10:57,600
have this policy enforcement this policy

340
00:10:57,600 --> 00:10:58,959
validation

341
00:10:58,959 --> 00:11:01,120
our engineers didn't really know whether

342
00:11:01,120 --> 00:11:02,240
or not the

343
00:11:02,240 --> 00:11:05,120
code they were writing the policies and

344
00:11:05,120 --> 00:11:07,040
uh manifest they were writing

345
00:11:07,040 --> 00:11:09,120
would be in violation until they

346
00:11:09,120 --> 00:11:10,640
actually deployed it

347
00:11:10,640 --> 00:11:12,560
so we really wanted a solution that we

348
00:11:12,560 --> 00:11:14,560
could give them

349
00:11:14,560 --> 00:11:16,240
put on their local machine and they

350
00:11:16,240 --> 00:11:18,320
could just run it without having to

351
00:11:18,320 --> 00:11:19,920
worry about any of that and that silly

352
00:11:19,920 --> 00:11:21,519
networking stuff

353
00:11:21,519 --> 00:11:23,920
and so we found a tool called called

354
00:11:23,920 --> 00:11:25,600
comptest

355
00:11:25,600 --> 00:11:29,360
and comtess more or less lets you

356
00:11:29,360 --> 00:11:32,320
run opa on on on your local machine like

357
00:11:32,320 --> 00:11:32,800
opa

358
00:11:32,800 --> 00:11:35,279
you can but contest just makes the

359
00:11:35,279 --> 00:11:36,160
experience

360
00:11:36,160 --> 00:11:38,720
so much better so like when i said

361
00:11:38,720 --> 00:11:39,920
before

362
00:11:39,920 --> 00:11:42,800
you can give any input document to opa

363
00:11:42,800 --> 00:11:43,839
it doesn't really care

364
00:11:43,839 --> 00:11:45,920
it's like it's half true it still

365
00:11:45,920 --> 00:11:46,880
doesn't care but

366
00:11:46,880 --> 00:11:49,920
as long as it's yaml or json so

367
00:11:49,920 --> 00:11:51,519
com tests can actually take a lot of

368
00:11:51,519 --> 00:11:53,440
different file formats you can see here

369
00:11:53,440 --> 00:11:56,560
ini tomal hcl and it can convert those

370
00:11:56,560 --> 00:11:57,600
file formats

371
00:11:57,600 --> 00:12:00,800
into into json and then shepard into opa

372
00:12:00,800 --> 00:12:02,639
so you can actually use

373
00:12:02,639 --> 00:12:05,839
any format with with opa there's also

374
00:12:05,839 --> 00:12:07,040
some nicety about

375
00:12:07,040 --> 00:12:09,360
being able to take in files from from

376
00:12:09,360 --> 00:12:10,160
different folders

377
00:12:10,160 --> 00:12:12,480
anywhere on your on your machine and

378
00:12:12,480 --> 00:12:15,040
then print the result again in a user

379
00:12:15,040 --> 00:12:18,240
friendly way so com test is for

380
00:12:18,240 --> 00:12:21,920
local policy validation it's for

381
00:12:21,920 --> 00:12:24,720
pipeline validation in all of your your

382
00:12:24,720 --> 00:12:25,760
manifest

383
00:12:25,760 --> 00:12:28,720
and then anything beyond that would be

384
00:12:28,720 --> 00:12:30,560
like opa deployed as a service for

385
00:12:30,560 --> 00:12:32,959
continue enforcement

386
00:12:32,959 --> 00:12:34,480
and so you can see here this is a

387
00:12:34,480 --> 00:12:37,040
another example of a policy file on the

388
00:12:37,040 --> 00:12:39,040
left this time we're looking at

389
00:12:39,040 --> 00:12:40,560
deployments to make sure they're not

390
00:12:40,560 --> 00:12:41,839
running as root and that

391
00:12:41,839 --> 00:12:45,040
the container has app label for pawn

392
00:12:45,040 --> 00:12:46,000
selectors

393
00:12:46,000 --> 00:12:47,760
and on the right we have our input

394
00:12:47,760 --> 00:12:50,639
document our deploy.yaml

395
00:12:50,639 --> 00:12:52,720
itself and so if we actually run this

396
00:12:52,720 --> 00:12:54,880
through com test using the test command

397
00:12:54,880 --> 00:12:56,480
all you have to do is pass in the

398
00:12:56,480 --> 00:12:59,920
policy.rego as well as the deploy.yaml

399
00:12:59,920 --> 00:13:02,560
and then it will take that deploy.yml

400
00:13:02,560 --> 00:13:03,440
and see

401
00:13:03,440 --> 00:13:06,160
does that input document violate any of

402
00:13:06,160 --> 00:13:08,079
the policies that we have set forth

403
00:13:08,079 --> 00:13:09,360
in this case there are there are two

404
00:13:09,360 --> 00:13:11,920
policies that were that were violated

405
00:13:11,920 --> 00:13:14,000
and we can take this policy and we can

406
00:13:14,000 --> 00:13:15,040
apply it to

407
00:13:15,040 --> 00:13:17,279
the op as a service and get the exact

408
00:13:17,279 --> 00:13:19,040
same behavior so we're checking

409
00:13:19,040 --> 00:13:21,680
both the the local environment as well

410
00:13:21,680 --> 00:13:22,320
as the

411
00:13:22,320 --> 00:13:24,720
um as well as the production environment

412
00:13:24,720 --> 00:13:26,399
and then again this it can be run

413
00:13:26,399 --> 00:13:28,639
local machines pipelines and you can get

414
00:13:28,639 --> 00:13:31,360
that immediate feedback

415
00:13:31,360 --> 00:13:33,120
there's also the benefit with comtess to

416
00:13:33,120 --> 00:13:34,639
be able to

417
00:13:34,639 --> 00:13:36,959
share policies across the organization

418
00:13:36,959 --> 00:13:37,920
because

419
00:13:37,920 --> 00:13:40,240
it's a fair use case a valid use case

420
00:13:40,240 --> 00:13:42,160
that your policies are managed and

421
00:13:42,160 --> 00:13:43,360
written by a completely

422
00:13:43,360 --> 00:13:45,600
separate team a security team much like

423
00:13:45,600 --> 00:13:47,279
they are done at yubico

424
00:13:47,279 --> 00:13:49,120
we'll have a lot of different

425
00:13:49,120 --> 00:13:51,839
repositories we want to make sure that

426
00:13:51,839 --> 00:13:55,040
the our policies are being enforced and

427
00:13:55,040 --> 00:13:56,320
there's really no way to get those

428
00:13:56,320 --> 00:13:58,480
policies without

429
00:13:58,480 --> 00:14:00,560
trying them out in the cluster but with

430
00:14:00,560 --> 00:14:02,079
comptest you can actually

431
00:14:02,079 --> 00:14:05,279
push policies policy bundles to a oci

432
00:14:05,279 --> 00:14:06,959
compliant registry

433
00:14:06,959 --> 00:14:09,199
and then pull them down for for later

434
00:14:09,199 --> 00:14:10,639
use so you can see here in the example

435
00:14:10,639 --> 00:14:11,120
where

436
00:14:11,120 --> 00:14:13,839
we're pulling down a bundle of cluster

437
00:14:13,839 --> 00:14:14,959
policies

438
00:14:14,959 --> 00:14:17,360
and then we're actually running the

439
00:14:17,360 --> 00:14:19,519
comptest test command locally

440
00:14:19,519 --> 00:14:21,839
on that bundle that we just pulled on

441
00:14:21,839 --> 00:14:23,680
that same deployed.yaml and then the

442
00:14:23,680 --> 00:14:24,959
result is the same

443
00:14:24,959 --> 00:14:27,440
so this is a way to be able to push

444
00:14:27,440 --> 00:14:29,279
policies out there and then pull them

445
00:14:29,279 --> 00:14:29,680
down

446
00:14:29,680 --> 00:14:32,160
for for cross-team usage this is really

447
00:14:32,160 --> 00:14:33,519
huge as well in um

448
00:14:33,519 --> 00:14:35,519
in pipelines or other kind of approaches

449
00:14:35,519 --> 00:14:36,800
where you need to

450
00:14:36,800 --> 00:14:38,560
bundle together a lot of different

451
00:14:38,560 --> 00:14:40,240
policies

452
00:14:40,240 --> 00:14:43,680
and so artifact hub is

453
00:14:43,680 --> 00:14:46,720
an attempt to be able to

454
00:14:46,720 --> 00:14:49,120
expose a lot of different policy bundles

455
00:14:49,120 --> 00:14:50,160
because

456
00:14:50,160 --> 00:14:52,000
more or less like the policies that we

457
00:14:52,000 --> 00:14:54,320
really care about things like

458
00:14:54,320 --> 00:14:57,279
containers having resource constraints

459
00:14:57,279 --> 00:14:58,000
containers not

460
00:14:58,000 --> 00:15:00,560
running as root those types of policies

461
00:15:00,560 --> 00:15:01,680
should more or less be

462
00:15:01,680 --> 00:15:03,680
the same but we're kind of in a state

463
00:15:03,680 --> 00:15:06,240
now where teams companies organizations

464
00:15:06,240 --> 00:15:07,920
are all writing the same policies we

465
00:15:07,920 --> 00:15:10,320
don't have a good distribution mechanism

466
00:15:10,320 --> 00:15:13,440
and artifact hub is again the the the

467
00:15:13,440 --> 00:15:14,160
solution

468
00:15:14,160 --> 00:15:15,680
for that um it's currently it's a

469
00:15:15,680 --> 00:15:18,079
sandbox project there are a whole lot of

470
00:15:18,079 --> 00:15:19,920
policy bundles out there i think there's

471
00:15:19,920 --> 00:15:21,120
like one or two

472
00:15:21,120 --> 00:15:23,199
but i would definitely keep an eye on

473
00:15:23,199 --> 00:15:25,519
this contribute where you can

474
00:15:25,519 --> 00:15:27,519
if you do have a public bundle that you

475
00:15:27,519 --> 00:15:29,199
want to to contribute i

476
00:15:29,199 --> 00:15:31,279
recommend pushing it up there and let's

477
00:15:31,279 --> 00:15:33,360
try to make this successful though so we

478
00:15:33,360 --> 00:15:35,199
can actually start sharing policies with

479
00:15:35,199 --> 00:15:37,040
one another not having to uh

480
00:15:37,040 --> 00:15:38,720
to rewrite them over and over and over

481
00:15:38,720 --> 00:15:40,320
again for every team who wants to be

482
00:15:40,320 --> 00:15:42,079
able to use policy

483
00:15:42,079 --> 00:15:44,320
and so a lot of the talks of we've a lot

484
00:15:44,320 --> 00:15:45,759
of the conversation we've had

485
00:15:45,759 --> 00:15:47,920
is all about policy enforcement on the

486
00:15:47,920 --> 00:15:49,199
local environments

487
00:15:49,199 --> 00:15:51,600
but we also need to make sure that the

488
00:15:51,600 --> 00:15:53,360
policies are enforced in

489
00:15:53,360 --> 00:15:56,560
in production and so once you get beyond

490
00:15:56,560 --> 00:15:59,040
the local environment we decided to go

491
00:15:59,040 --> 00:15:59,680
with a

492
00:15:59,680 --> 00:16:02,959
tool called called gatekeeper and

493
00:16:02,959 --> 00:16:05,519
gatekeeper lets us enforce these

494
00:16:05,519 --> 00:16:08,320
policies continuously inside inside of a

495
00:16:08,320 --> 00:16:09,279
kubernetes

496
00:16:09,279 --> 00:16:13,519
cluster it's a mission controller

497
00:16:13,519 --> 00:16:15,759
so when you deploy a resource to

498
00:16:15,759 --> 00:16:16,639
kubernetes

499
00:16:16,639 --> 00:16:17,600
it'll go through the admission

500
00:16:17,600 --> 00:16:19,839
controller look at all the policy that

501
00:16:19,839 --> 00:16:20,560
you have

502
00:16:20,560 --> 00:16:23,680
loaded and if any of the the resources

503
00:16:23,680 --> 00:16:24,160
that you

504
00:16:24,160 --> 00:16:26,240
are attempting to add to the cluster it

505
00:16:26,240 --> 00:16:27,600
will reject

506
00:16:27,600 --> 00:16:30,000
or or let the policy go through it also

507
00:16:30,000 --> 00:16:32,480
has an and some audit functionality

508
00:16:32,480 --> 00:16:34,800
saying it'll continually audit your

509
00:16:34,800 --> 00:16:35,680
cluster

510
00:16:35,680 --> 00:16:37,680
are there any resources that that are

511
00:16:37,680 --> 00:16:39,040
violating policy if

512
00:16:39,040 --> 00:16:41,360
in the case that you're just starting to

513
00:16:41,360 --> 00:16:43,040
adopt gatekeeper

514
00:16:43,040 --> 00:16:44,560
and you want to see if i were to

515
00:16:44,560 --> 00:16:46,560
actually enforce this policy how many

516
00:16:46,560 --> 00:16:47,759
resources

517
00:16:47,759 --> 00:16:49,680
are kind of out of band or just in the

518
00:16:49,680 --> 00:16:51,600
case that gatekeeper went down for a

519
00:16:51,600 --> 00:16:53,120
little bit you know want to

520
00:16:53,120 --> 00:16:55,600
make sure that there wasn't a a resource

521
00:16:55,600 --> 00:16:57,360
that got in like during that that small

522
00:16:57,360 --> 00:16:58,079
window

523
00:16:58,079 --> 00:16:59,680
and again the huge one here is it's

524
00:16:59,680 --> 00:17:01,759
using the same policies so

525
00:17:01,759 --> 00:17:03,600
we're if you're checking on your local

526
00:17:03,600 --> 00:17:05,439
versus in production

527
00:17:05,439 --> 00:17:07,359
we can always continuously use the same

528
00:17:07,359 --> 00:17:08,880
policy that doesn't change from

529
00:17:08,880 --> 00:17:10,240
environment to environment

530
00:17:10,240 --> 00:17:14,160
but with that said um it's

531
00:17:14,160 --> 00:17:17,839
almost the same policies so uh we go

532
00:17:17,839 --> 00:17:18,480
back to

533
00:17:18,480 --> 00:17:21,039
the input document um when you're

534
00:17:21,039 --> 00:17:22,640
working with yaml the input document is

535
00:17:22,640 --> 00:17:23,199
going to be

536
00:17:23,199 --> 00:17:25,760
a yaml file so we would expect

537
00:17:25,760 --> 00:17:27,240
input.kind

538
00:17:27,240 --> 00:17:29,760
input.metadata just like we saw before

539
00:17:29,760 --> 00:17:32,400
but when we're in the context of

540
00:17:32,400 --> 00:17:34,480
admission control it's going to be a

541
00:17:34,480 --> 00:17:36,600
little different i bolded here

542
00:17:36,600 --> 00:17:39,039
input.review.object because this is what

543
00:17:39,039 --> 00:17:39,360
a

544
00:17:39,360 --> 00:17:41,120
admission review is going to look like

545
00:17:41,120 --> 00:17:43,200
to to gatekeeper

546
00:17:43,200 --> 00:17:45,600
this is the the document that is going

547
00:17:45,600 --> 00:17:46,480
to be received

548
00:17:46,480 --> 00:17:49,520
from opa so again it's not

549
00:17:49,520 --> 00:17:51,679
quite the same you would actually have

550
00:17:51,679 --> 00:17:53,360
to write a policy

551
00:17:53,360 --> 00:17:56,080
that had input.review.object in it but

552
00:17:56,080 --> 00:17:57,760
that would only work for gatekeeper

553
00:17:57,760 --> 00:17:59,919
and if you did just input.kind that

554
00:17:59,919 --> 00:18:01,919
wouldn't work for gatekeeper

555
00:18:01,919 --> 00:18:04,559
so what we ended up doing was really

556
00:18:04,559 --> 00:18:06,480
adopting this idea of rego being the

557
00:18:06,480 --> 00:18:08,400
source of truth your policies because

558
00:18:08,400 --> 00:18:11,440
it really it really is rego is

559
00:18:11,440 --> 00:18:14,240
generic it's it doesn't matter the uh

560
00:18:14,240 --> 00:18:16,400
the context that you're in

561
00:18:16,400 --> 00:18:19,200
it's really all about does this input

562
00:18:19,200 --> 00:18:20,559
document that you're giving me

563
00:18:20,559 --> 00:18:23,280
violate this policy that you have

564
00:18:23,280 --> 00:18:24,960
defined and so in every

565
00:18:24,960 --> 00:18:27,280
everything that's that you do that's

566
00:18:27,280 --> 00:18:28,720
based off of your rego

567
00:18:28,720 --> 00:18:30,960
should should adjust the changes of your

568
00:18:30,960 --> 00:18:33,520
regula and not the other way around

569
00:18:33,520 --> 00:18:35,760
and so to solve this problem we actually

570
00:18:35,760 --> 00:18:37,919
wrote a tool called constraint

571
00:18:37,919 --> 00:18:40,160
and constraint brings to the table three

572
00:18:40,160 --> 00:18:41,360
really important

573
00:18:41,360 --> 00:18:43,919
factors first and foremost it it

574
00:18:43,919 --> 00:18:45,679
actually does provide a library

575
00:18:45,679 --> 00:18:47,280
where you can write policies that work

576
00:18:47,280 --> 00:18:49,520
with both comptest and gatekeeper

577
00:18:49,520 --> 00:18:52,160
it's really just a a wrapper that

578
00:18:52,160 --> 00:18:53,440
normalizes

579
00:18:53,440 --> 00:18:56,799
a a polyfill that that will say

580
00:18:56,799 --> 00:18:59,120
if you're in the context of gatekeeper

581
00:18:59,120 --> 00:18:59,919
then

582
00:18:59,919 --> 00:19:01,559
spit out your policies for

583
00:19:01,559 --> 00:19:03,039
input.review.object if you're in the

584
00:19:03,039 --> 00:19:04,720
context of conf test

585
00:19:04,720 --> 00:19:06,880
it's just input dot and that handles all

586
00:19:06,880 --> 00:19:07,919
of that for you

587
00:19:07,919 --> 00:19:10,799
so your policies can be completely

588
00:19:10,799 --> 00:19:11,679
unchanged

589
00:19:11,679 --> 00:19:13,200
no matter what environment that you're

590
00:19:13,200 --> 00:19:15,760
running in the other benefit is the

591
00:19:15,760 --> 00:19:17,919
template and constraint creation and

592
00:19:17,919 --> 00:19:18,880
management

593
00:19:18,880 --> 00:19:20,240
so when you saw on the previous

594
00:19:20,240 --> 00:19:22,320
constraint uh previous screen

595
00:19:22,320 --> 00:19:25,280
the the rego there was actually embedded

596
00:19:25,280 --> 00:19:27,840
into the constraint template the yaml

597
00:19:27,840 --> 00:19:29,840
and that's because that's how gatekeeper

598
00:19:29,840 --> 00:19:32,160
is able to um

599
00:19:32,160 --> 00:19:34,400
to uh to load in your policies it's just

600
00:19:34,400 --> 00:19:36,160
done through a yaml file

601
00:19:36,160 --> 00:19:38,799
and so you're gonna have a rego file on

602
00:19:38,799 --> 00:19:39,919
disk

603
00:19:39,919 --> 00:19:42,799
and if you were to change that rego file

604
00:19:42,799 --> 00:19:44,080
you would also have to

605
00:19:44,080 --> 00:19:45,919
copy and paste your changes into that

606
00:19:45,919 --> 00:19:47,679
yaml which

607
00:19:47,679 --> 00:19:50,240
isn't the most ideal situation and so

608
00:19:50,240 --> 00:19:52,400
what constraint will actually do is

609
00:19:52,400 --> 00:19:54,720
it will look at all of your radio files

610
00:19:54,720 --> 00:19:56,480
and then it will actually

611
00:19:56,480 --> 00:19:59,120
generate the template and constraint for

612
00:19:59,120 --> 00:20:00,000
you so

613
00:20:00,000 --> 00:20:02,400
you never have to touch yaml you're only

614
00:20:02,400 --> 00:20:03,760
focused purely on

615
00:20:03,760 --> 00:20:06,400
on your rego file and then lastly it

616
00:20:06,400 --> 00:20:08,240
actually will generate documentation

617
00:20:08,240 --> 00:20:09,840
for your policies we really wanted to

618
00:20:09,840 --> 00:20:12,080
give our engineers the ability to see

619
00:20:12,080 --> 00:20:14,720
what policies were being enforced as

620
00:20:14,720 --> 00:20:15,280
well as

621
00:20:15,280 --> 00:20:17,520
how they can how they can resolve them

622
00:20:17,520 --> 00:20:20,720
if they ever run into a policy violation

623
00:20:20,720 --> 00:20:22,880
and so when it comes to the policies

624
00:20:22,880 --> 00:20:23,919
themselves

625
00:20:23,919 --> 00:20:26,080
it'll look relatively familiar that the

626
00:20:26,080 --> 00:20:27,840
biggest difference here is definitely

627
00:20:27,840 --> 00:20:29,679
the the comment header

628
00:20:29,679 --> 00:20:32,400
we added some some metadata to to the

629
00:20:32,400 --> 00:20:34,000
policy in form of a

630
00:20:34,000 --> 00:20:37,280
header comment where we say title

631
00:20:37,280 --> 00:20:41,039
is the the title of of the the policy

632
00:20:41,039 --> 00:20:42,720
here we're saying images must not use

633
00:20:42,720 --> 00:20:44,080
the latest tag

634
00:20:44,080 --> 00:20:46,880
and then why this policy exists or

635
00:20:46,880 --> 00:20:48,000
really any other flavor

636
00:20:48,000 --> 00:20:50,400
that you want to give it to give this

637
00:20:50,400 --> 00:20:52,400
policy be the description or anything

638
00:20:52,400 --> 00:20:53,120
else

639
00:20:53,120 --> 00:20:55,200
the the enforcement type here is saying

640
00:20:55,200 --> 00:20:56,240
deny

641
00:20:56,240 --> 00:20:59,120
the alternative is dry run in case you

642
00:20:59,120 --> 00:20:59,679
want to

643
00:20:59,679 --> 00:21:01,520
test out this policy in your cluster and

644
00:21:01,520 --> 00:21:03,840
not actually do any sort of

645
00:21:03,840 --> 00:21:06,080
enforcement and then which kinds which

646
00:21:06,080 --> 00:21:08,960
kubernetes resources that this policy

647
00:21:08,960 --> 00:21:11,919
will be enforced on be it just ingresses

648
00:21:11,919 --> 00:21:14,559
be it just namespaces workloads etc

649
00:21:14,559 --> 00:21:16,720
so we define here a list of resources

650
00:21:16,720 --> 00:21:17,760
that this policy

651
00:21:17,760 --> 00:21:19,280
isn't forced on and then we use this

652
00:21:19,280 --> 00:21:21,760
metadata to generate all the other yamls

653
00:21:21,760 --> 00:21:22,720
that we were previously

654
00:21:22,720 --> 00:21:25,039
talking about and in the violation

655
00:21:25,039 --> 00:21:27,120
itself you see here we're importing two

656
00:21:27,120 --> 00:21:28,840
libraries which is the constraint

657
00:21:28,840 --> 00:21:30,159
library

658
00:21:30,159 --> 00:21:33,159
the the important note here is that

659
00:21:33,159 --> 00:21:34,640
pods.container

660
00:21:34,640 --> 00:21:37,120
our pods library will actually look at

661
00:21:37,120 --> 00:21:38,320
containers from

662
00:21:38,320 --> 00:21:41,200
any possible source because pods can

663
00:21:41,200 --> 00:21:42,880
come from cron jobs they can come from

664
00:21:42,880 --> 00:21:44,960
deployment staple sets daemon sets

665
00:21:44,960 --> 00:21:47,120
there's a large list of those and

666
00:21:47,120 --> 00:21:48,799
they're all embedded in kubernetes

667
00:21:48,799 --> 00:21:50,640
resources differently

668
00:21:50,640 --> 00:21:53,679
so pods handles that for you and then we

669
00:21:53,679 --> 00:21:54,559
can take

670
00:21:54,559 --> 00:21:56,240
the the resulting container that comes

671
00:21:56,240 --> 00:21:58,400
out of that does that container have an

672
00:21:58,400 --> 00:22:01,120
image of latest and if it does

673
00:22:01,120 --> 00:22:02,960
give a note to the the user saying that

674
00:22:02,960 --> 00:22:04,480
images must not use the

675
00:22:04,480 --> 00:22:07,039
the latest tag and again we have two

676
00:22:07,039 --> 00:22:08,880
commands for that one to generate the

677
00:22:08,880 --> 00:22:10,799
the templates and the constraints and

678
00:22:10,799 --> 00:22:12,880
then one for for the markdown

679
00:22:12,880 --> 00:22:17,360
describing describing our our policies

680
00:22:17,360 --> 00:22:19,919
and then this is an example of what the

681
00:22:19,919 --> 00:22:20,880
documentation

682
00:22:20,880 --> 00:22:24,840
looks like you can see here the the id

683
00:22:24,840 --> 00:22:28,080
p1001 we also embedded something into

684
00:22:28,080 --> 00:22:29,520
into the tool that you can actually

685
00:22:29,520 --> 00:22:31,120
assign an id

686
00:22:31,120 --> 00:22:33,440
to a policy so you can refer back to it

687
00:22:33,440 --> 00:22:35,360
instead of just using a title

688
00:22:35,360 --> 00:22:37,840
the the severity is coming from the the

689
00:22:37,840 --> 00:22:39,840
severity of the rule because in rego you

690
00:22:39,840 --> 00:22:40,640
can have

691
00:22:40,640 --> 00:22:42,159
warning you can have deny you can have

692
00:22:42,159 --> 00:22:45,200
violation and based on that rule

693
00:22:45,200 --> 00:22:46,799
different things will happen so we pull

694
00:22:46,799 --> 00:22:48,640
the severity out of the rego and put

695
00:22:48,640 --> 00:22:50,400
that in the document for you

696
00:22:50,400 --> 00:22:52,960
same with the resources that it impacts

697
00:22:52,960 --> 00:22:54,240
the

698
00:22:54,240 --> 00:22:56,799
the description that dictates what this

699
00:22:56,799 --> 00:22:59,280
policy does or why we have it

700
00:22:59,280 --> 00:23:01,679
and then this is the the rego itself if

701
00:23:01,679 --> 00:23:02,960
you want that information

702
00:23:02,960 --> 00:23:05,360
again completely completely configurable

703
00:23:05,360 --> 00:23:06,799
if you change your rego

704
00:23:06,799 --> 00:23:08,559
again all the documentation is

705
00:23:08,559 --> 00:23:09,840
regenerated

706
00:23:09,840 --> 00:23:12,080
none of this is hand typed and then you

707
00:23:12,080 --> 00:23:12,960
also

708
00:23:12,960 --> 00:23:14,880
are given a link to to the source and

709
00:23:14,880 --> 00:23:17,360
that source can either be a relative url

710
00:23:17,360 --> 00:23:19,600
if the policy lives in the same location

711
00:23:19,600 --> 00:23:21,600
of the source the same repository

712
00:23:21,600 --> 00:23:23,919
or if it's a remote repository the

713
00:23:23,919 --> 00:23:25,120
source can also be

714
00:23:25,120 --> 00:23:28,960
a uh be a url so we um

715
00:23:28,960 --> 00:23:32,159
we found a lot of usage out of this tool

716
00:23:32,159 --> 00:23:35,120
we use it for um like almost every day

717
00:23:35,120 --> 00:23:37,200
it's really ingrained into

718
00:23:37,200 --> 00:23:39,360
into our workflows when it comes to

719
00:23:39,360 --> 00:23:41,120
gatekeeper and policy so

720
00:23:41,120 --> 00:23:42,960
if you're interested if it sounds

721
00:23:42,960 --> 00:23:44,799
something like you'd want to use

722
00:23:44,799 --> 00:23:48,799
always open to uh to talk about it

723
00:23:48,799 --> 00:23:52,000
contributions always welcome and uh

724
00:23:52,000 --> 00:23:53,760
that's really all i have for for the

725
00:23:53,760 --> 00:23:55,039
tooling piece of it

726
00:23:55,039 --> 00:23:56,880
uh james is going to kind of go into

727
00:23:56,880 --> 00:23:58,320
into deeper detail

728
00:23:58,320 --> 00:24:01,120
of how we actually have leveraged these

729
00:24:01,120 --> 00:24:02,720
tools in our policies

730
00:24:02,720 --> 00:24:06,240
and in our pipelines and processes

731
00:24:07,440 --> 00:24:08,880
thanks john now that we have an

732
00:24:08,880 --> 00:24:10,159
understanding of how the tooling works

733
00:24:10,159 --> 00:24:10,720
together

734
00:24:10,720 --> 00:24:14,159
let's dive into ubiko's policy journey

735
00:24:14,159 --> 00:24:15,520
in the beginning since we didn't have

736
00:24:15,520 --> 00:24:17,600
too many workloads on kubernetes yet

737
00:24:17,600 --> 00:24:19,520
and we were sure that we had consistent

738
00:24:19,520 --> 00:24:20,960
peer review happening

739
00:24:20,960 --> 00:24:22,880
we started with a simple plan because we

740
00:24:22,880 --> 00:24:24,720
didn't anticipate too many resources

741
00:24:24,720 --> 00:24:27,360
would violate these policies

742
00:24:27,360 --> 00:24:28,960
we would start with writing the policies

743
00:24:28,960 --> 00:24:30,960
and their tests after which we would

744
00:24:30,960 --> 00:24:32,799
engage with our services teams to add

745
00:24:32,799 --> 00:24:34,720
these checks to their ci flows using

746
00:24:34,720 --> 00:24:36,000
conf test

747
00:24:36,000 --> 00:24:38,159
simultaneous to that we would be working

748
00:24:38,159 --> 00:24:39,919
on deploying gatekeeper to our clusters

749
00:24:39,919 --> 00:24:41,679
in audit only mode

750
00:24:41,679 --> 00:24:43,360
and then finally after we had worked

751
00:24:43,360 --> 00:24:45,120
with the teams to remediate all of the

752
00:24:45,120 --> 00:24:46,480
identified issues

753
00:24:46,480 --> 00:24:48,000
we would flip the switch and move

754
00:24:48,000 --> 00:24:51,440
gatekeeper into enforcement mode

755
00:24:51,440 --> 00:24:52,880
as you might have expected from how i

756
00:24:52,880 --> 00:24:55,120
framed the previous slide this plan ran

757
00:24:55,120 --> 00:24:56,400
into some issues

758
00:24:56,400 --> 00:24:58,080
we made it as far as writing and testing

759
00:24:58,080 --> 00:25:00,159
the policies but when we moved to engage

760
00:25:00,159 --> 00:25:00,799
with

761
00:25:00,799 --> 00:25:02,720
some select teams to add conf tests to

762
00:25:02,720 --> 00:25:04,000
their ci flows

763
00:25:04,000 --> 00:25:05,679
the issues became pretty readily

764
00:25:05,679 --> 00:25:08,080
apparent

765
00:25:08,559 --> 00:25:10,640
well for one there were more violations

766
00:25:10,640 --> 00:25:11,679
than anticipated

767
00:25:11,679 --> 00:25:13,760
which meant that there was a potentially

768
00:25:13,760 --> 00:25:15,679
a very long window between when we

769
00:25:15,679 --> 00:25:17,919
identified these resources and when we

770
00:25:17,919 --> 00:25:19,440
would actually be able to

771
00:25:19,440 --> 00:25:21,120
apply remediation across all of our

772
00:25:21,120 --> 00:25:23,360
clusters

773
00:25:23,360 --> 00:25:25,840
this was compounded by the fact that we

774
00:25:25,840 --> 00:25:26,400
were all

775
00:25:26,400 --> 00:25:29,200
not only migrating existing workloads to

776
00:25:29,200 --> 00:25:30,159
kubernetes

777
00:25:30,159 --> 00:25:32,400
but we were in a growth period hiring

778
00:25:32,400 --> 00:25:34,240
and starting up some new services on

779
00:25:34,240 --> 00:25:37,200
kubernetes as well

780
00:25:37,600 --> 00:25:39,440
additionally since the policies were

781
00:25:39,440 --> 00:25:41,120
always essentially production

782
00:25:41,120 --> 00:25:43,200
there was no way to safely test new

783
00:25:43,200 --> 00:25:46,320
policies or changes to existing policies

784
00:25:46,320 --> 00:25:48,799
this meant that in a ci flow with conf

785
00:25:48,799 --> 00:25:51,039
test the ci flow would fail immediately

786
00:25:51,039 --> 00:25:51,279
if

787
00:25:51,279 --> 00:25:54,960
a violation was found and similarly

788
00:25:54,960 --> 00:25:57,039
gatekeeper would just reject changes to

789
00:25:57,039 --> 00:26:00,960
the cluster if it didn't meet policy

790
00:26:01,440 --> 00:26:03,919
additionally adding conf test to rci

791
00:26:03,919 --> 00:26:05,440
flows wasn't as easy as it could have

792
00:26:05,440 --> 00:26:06,159
been

793
00:26:06,159 --> 00:26:08,080
for one it kind of required our services

794
00:26:08,080 --> 00:26:10,320
teams to know the comp test flags and

795
00:26:10,320 --> 00:26:11,760
sort of how it worked

796
00:26:11,760 --> 00:26:14,320
and additionally these it took multiple

797
00:26:14,320 --> 00:26:15,520
steps to actually get

798
00:26:15,520 --> 00:26:17,760
policies from a remote source into the

799
00:26:17,760 --> 00:26:20,880
repo and then run the test

800
00:26:20,880 --> 00:26:23,200
but most importantly the contest results

801
00:26:23,200 --> 00:26:24,880
weren't surface to the teams working on

802
00:26:24,880 --> 00:26:26,240
the resources

803
00:26:26,240 --> 00:26:28,320
this meant that unless there was an

804
00:26:28,320 --> 00:26:29,600
actual violation

805
00:26:29,600 --> 00:26:31,279
no one would even know what tests were

806
00:26:31,279 --> 00:26:33,200
run or anything like that

807
00:26:33,200 --> 00:26:34,559
this was especially important to us

808
00:26:34,559 --> 00:26:36,320
because we do have some policies that we

809
00:26:36,320 --> 00:26:38,240
have labeled as just warnings

810
00:26:38,240 --> 00:26:40,159
which aren't blockers for deployment but

811
00:26:40,159 --> 00:26:42,000
they are a way that we want to

812
00:26:42,000 --> 00:26:43,840
communicate to our teams

813
00:26:43,840 --> 00:26:44,799
that the way that they have the

814
00:26:44,799 --> 00:26:47,360
resources configured might not be best

815
00:26:47,360 --> 00:26:48,159
practices

816
00:26:48,159 --> 00:26:51,679
practice finally

817
00:26:51,679 --> 00:26:53,840
policy admins such as myself had no

818
00:26:53,840 --> 00:26:55,760
visibility into the test results

819
00:26:55,760 --> 00:26:58,159
so we didn't really have any way to

820
00:26:58,159 --> 00:26:58,880
track which

821
00:26:58,880 --> 00:27:00,640
repositories or which teams had started

822
00:27:00,640 --> 00:27:03,200
using the policies or any of the results

823
00:27:03,200 --> 00:27:05,279
uh for which policies were making

824
00:27:05,279 --> 00:27:07,679
the test runs fail or which ones were

825
00:27:07,679 --> 00:27:10,640
just emitting warnings

826
00:27:10,640 --> 00:27:12,559
with these pain points identified we

827
00:27:12,559 --> 00:27:14,000
determined that there was essentially

828
00:27:14,000 --> 00:27:16,400
two things that we needed to do

829
00:27:16,400 --> 00:27:18,240
we needed to build a policy pipeline and

830
00:27:18,240 --> 00:27:19,520
that pipeline would ensure that the

831
00:27:19,520 --> 00:27:21,279
policies are safe to enforce throughout

832
00:27:21,279 --> 00:27:22,480
our clusters

833
00:27:22,480 --> 00:27:24,320
and we had to make the policy adoption

834
00:27:24,320 --> 00:27:26,240
as easy as possible

835
00:27:26,240 --> 00:27:28,399
if either of these weren't true it was a

836
00:27:28,399 --> 00:27:29,840
pretty good chance that they

837
00:27:29,840 --> 00:27:31,840
our policies wouldn't be adopted or it

838
00:27:31,840 --> 00:27:33,679
would just be a long uphill battle

839
00:27:33,679 --> 00:27:36,960
trying to get our teams to adopt them

840
00:27:36,960 --> 00:27:38,960
so first let's focus on what we did to

841
00:27:38,960 --> 00:27:40,799
make that policy adoption as easy as

842
00:27:40,799 --> 00:27:42,000
possible

843
00:27:42,000 --> 00:27:44,159
and to do that we created two github

844
00:27:44,159 --> 00:27:45,279
actions

845
00:27:45,279 --> 00:27:47,279
the first is a wrapper around conf test

846
00:27:47,279 --> 00:27:49,200
itself and it addresses some of the pain

847
00:27:49,200 --> 00:27:49,840
points

848
00:27:49,840 --> 00:27:52,240
from the previous slides it

849
00:27:52,240 --> 00:27:53,840
automatically pulls the latest policies

850
00:27:53,840 --> 00:27:55,360
from a remote source

851
00:27:55,360 --> 00:27:57,200
it surfaces the policy violation

852
00:27:57,200 --> 00:27:58,640
warnings and

853
00:27:58,640 --> 00:28:00,159
violations and warnings into the pull

854
00:28:00,159 --> 00:28:01,600
request comments so that the teams

855
00:28:01,600 --> 00:28:02,960
working on the resources

856
00:28:02,960 --> 00:28:06,640
can see the test results

857
00:28:06,640 --> 00:28:08,559
and it submits the results to a remote

858
00:28:08,559 --> 00:28:10,399
server so policy admins can

859
00:28:10,399 --> 00:28:14,158
monitor the deployments

860
00:28:15,039 --> 00:28:17,919
the second addresses an issue that we

861
00:28:17,919 --> 00:28:19,120
learned about later

862
00:28:19,120 --> 00:28:21,120
was that some of our teams had started

863
00:28:21,120 --> 00:28:24,320
to adopt flux cd for continuous delivery

864
00:28:24,320 --> 00:28:26,640
and we're using its helm operator and

865
00:28:26,640 --> 00:28:29,120
this home operator has a custom resource

866
00:28:29,120 --> 00:28:31,840
that lets you specify the helm chart

867
00:28:31,840 --> 00:28:32,480
source

868
00:28:32,480 --> 00:28:34,320
and then what values you want to apply

869
00:28:34,320 --> 00:28:36,240
to that chart and then it will

870
00:28:36,240 --> 00:28:38,240
go and fetch everything needed and just

871
00:28:38,240 --> 00:28:39,679
make those changes in your cluster for

872
00:28:39,679 --> 00:28:41,840
you

873
00:28:41,840 --> 00:28:44,159
however since helm templates are just

874
00:28:44,159 --> 00:28:45,360
that they're templates they aren't

875
00:28:45,360 --> 00:28:47,039
kubernetes resources

876
00:28:47,039 --> 00:28:49,360
we couldn't use config on them directly

877
00:28:49,360 --> 00:28:50,960
and this is because the data structure

878
00:28:50,960 --> 00:28:52,960
in the yaml was different

879
00:28:52,960 --> 00:28:54,960
and even if it was the same with

880
00:28:54,960 --> 00:28:56,559
templates you wouldn't actually have

881
00:28:56,559 --> 00:28:58,000
everything you needed until after

882
00:28:58,000 --> 00:28:59,760
execution

883
00:28:59,760 --> 00:29:02,399
so what this action does is it parses

884
00:29:02,399 --> 00:29:03,039
the

885
00:29:03,039 --> 00:29:06,320
the helm release resource

886
00:29:06,320 --> 00:29:08,320
it pulls the chart info the version all

887
00:29:08,320 --> 00:29:10,080
of those things

888
00:29:10,080 --> 00:29:12,399
it automatically sets up a helm

889
00:29:12,399 --> 00:29:14,080
repository so that it can pull those

890
00:29:14,080 --> 00:29:16,240
templates from the remote repository

891
00:29:16,240 --> 00:29:18,960
and then executes the templates so with

892
00:29:18,960 --> 00:29:20,320
this we can easily

893
00:29:20,320 --> 00:29:22,320
template out these resources before we

894
00:29:22,320 --> 00:29:23,440
run conf test

895
00:29:23,440 --> 00:29:25,360
so that it's nice and easy and it's a

896
00:29:25,360 --> 00:29:27,840
solid flow

897
00:29:28,960 --> 00:29:30,399
this makes it easy for our developers

898
00:29:30,399 --> 00:29:31,760
because they don't have to remember all

899
00:29:31,760 --> 00:29:33,440
of the flags for the helm template

900
00:29:33,440 --> 00:29:35,279
command or with the argument order

901
00:29:35,279 --> 00:29:38,240
or anything like that one thing to note

902
00:29:38,240 --> 00:29:39,600
here is that this currently only

903
00:29:39,600 --> 00:29:41,679
supports public helm repositories

904
00:29:41,679 --> 00:29:43,120
but we're working on adding support for

905
00:29:43,120 --> 00:29:45,600
private repositories too

906
00:29:45,600 --> 00:29:48,080
so with the ease of adoption addressed

907
00:29:48,080 --> 00:29:49,600
let's move on to the policy pipeline

908
00:29:49,600 --> 00:29:51,600
itself

909
00:29:51,600 --> 00:29:53,200
early on in the design of the policy

910
00:29:53,200 --> 00:29:55,039
pipeline we have this one rule

911
00:29:55,039 --> 00:29:57,039
is that we must not ever break

912
00:29:57,039 --> 00:29:58,159
production

913
00:29:58,159 --> 00:29:59,840
and for us that also includes any of the

914
00:29:59,840 --> 00:30:02,240
pipelines leading up to production

915
00:30:02,240 --> 00:30:03,919
this meant that for our teams that have

916
00:30:03,919 --> 00:30:06,159
an automated deployment from development

917
00:30:06,159 --> 00:30:08,080
to staging to production

918
00:30:08,080 --> 00:30:10,720
using custom metrics that breaking their

919
00:30:10,720 --> 00:30:12,559
access to the development cluster is the

920
00:30:12,559 --> 00:30:13,919
same as breaking their production

921
00:30:13,919 --> 00:30:16,000
pipeline

922
00:30:16,000 --> 00:30:18,320
in order to accomplish this we used two

923
00:30:18,320 --> 00:30:19,760
main methodologies

924
00:30:19,760 --> 00:30:21,520
the first was data-driven policy

925
00:30:21,520 --> 00:30:23,919
promotion and the second was a git ops

926
00:30:23,919 --> 00:30:26,320
deployment flow

927
00:30:26,320 --> 00:30:28,399
so diving into our policy promotion

928
00:30:28,399 --> 00:30:29,440
strategy

929
00:30:29,440 --> 00:30:32,399
we wanted to tackle one policy at a time

930
00:30:32,399 --> 00:30:33,840
which again is just

931
00:30:33,840 --> 00:30:35,840
reducing the window that new resources

932
00:30:35,840 --> 00:30:36,880
are introduced

933
00:30:36,880 --> 00:30:38,399
that violate the policy while you're

934
00:30:38,399 --> 00:30:40,240
working about on remediating the ones

935
00:30:40,240 --> 00:30:43,200
that you already know about

936
00:30:43,200 --> 00:30:45,039
another key component is we use

937
00:30:45,039 --> 00:30:47,360
gatekeepers enforcement action property

938
00:30:47,360 --> 00:30:49,679
to enforce to introduce the policies in

939
00:30:49,679 --> 00:30:50,559
dry run mode

940
00:30:50,559 --> 00:30:53,279
where they are not enforced however when

941
00:30:53,279 --> 00:30:54,960
they are in this mode we can still use

942
00:30:54,960 --> 00:30:57,039
gatekeepers audit functionality

943
00:30:57,039 --> 00:30:59,200
to audit our resources in our clusters

944
00:30:59,200 --> 00:31:00,159
and see which of them

945
00:31:00,159 --> 00:31:04,000
violate the policies

946
00:31:04,000 --> 00:31:06,000
we've made the decision to only switch

947
00:31:06,000 --> 00:31:07,360
to enforcement mode

948
00:31:07,360 --> 00:31:09,440
after we've identified that all of the

949
00:31:09,440 --> 00:31:12,480
offending resources have been remediated

950
00:31:12,480 --> 00:31:14,720
and as a side effect of this we have

951
00:31:14,720 --> 00:31:16,720
avoided setting hard deadlines for our

952
00:31:16,720 --> 00:31:18,799
teams to

953
00:31:18,799 --> 00:31:20,000
update their resources and make sure

954
00:31:20,000 --> 00:31:22,480
that they're remediated

955
00:31:22,480 --> 00:31:24,000
so one thing that we've done to work

956
00:31:24,000 --> 00:31:26,480
around that is in the case where a team

957
00:31:26,480 --> 00:31:28,559
says they just really can't

958
00:31:28,559 --> 00:31:30,960
get this fixed in the next couple weeks

959
00:31:30,960 --> 00:31:32,000
we can add temporary

960
00:31:32,000 --> 00:31:33,919
exceptions to the policy for those

961
00:31:33,919 --> 00:31:35,919
specific resources in specific name

962
00:31:35,919 --> 00:31:37,120
spaces

963
00:31:37,120 --> 00:31:39,679
but only when necessary that way we

964
00:31:39,679 --> 00:31:41,840
still have good coverage of you know 99

965
00:31:41,840 --> 00:31:43,600
of the resources in our clusters that

966
00:31:43,600 --> 00:31:47,440
are here adhering to the policy

967
00:31:47,440 --> 00:31:50,720
and finally we only promote policies to

968
00:31:50,720 --> 00:31:53,279
production when they're linked to a

969
00:31:53,279 --> 00:31:54,799
change management ticket which allows

970
00:31:54,799 --> 00:31:56,240
them to be scheduled

971
00:31:56,240 --> 00:31:57,679
this of course ensures that all the

972
00:31:57,679 --> 00:31:59,440
potentially impacted parties are aware

973
00:31:59,440 --> 00:32:00,960
of this upcoming change

974
00:32:00,960 --> 00:32:03,039
and it lets us schedule around times

975
00:32:03,039 --> 00:32:04,960
that we may be adding a feature release

976
00:32:04,960 --> 00:32:07,840
a product launch or something like that

977
00:32:07,840 --> 00:32:09,760
moving on to our get ops deployment flow

978
00:32:09,760 --> 00:32:11,840
approach it's a pretty standard approach

979
00:32:11,840 --> 00:32:13,360
where we use pull requests to move

980
00:32:13,360 --> 00:32:15,600
policies throughout the pipeline

981
00:32:15,600 --> 00:32:17,519
we use branch protection rules to ensure

982
00:32:17,519 --> 00:32:19,360
that peer review occurs and that all of

983
00:32:19,360 --> 00:32:21,360
our unit tests pass

984
00:32:21,360 --> 00:32:22,559
a couple of things that we're doing

985
00:32:22,559 --> 00:32:24,880
there is we require each policy have

986
00:32:24,880 --> 00:32:27,360
a unique policy identifier and we

987
00:32:27,360 --> 00:32:29,120
require that each policy have at least

988
00:32:29,120 --> 00:32:30,960
two unit tests

989
00:32:30,960 --> 00:32:33,519
one is for the positive path where

990
00:32:33,519 --> 00:32:35,039
gatekeeper blocks something that we

991
00:32:35,039 --> 00:32:36,000
expect it to

992
00:32:36,000 --> 00:32:38,080
and the second is the negative path

993
00:32:38,080 --> 00:32:39,679
where we

994
00:32:39,679 --> 00:32:41,200
a gatekeeper allow something through

995
00:32:41,200 --> 00:32:44,960
that we expect it to not lock

996
00:32:45,519 --> 00:32:47,360
we also take advantage of the github

997
00:32:47,360 --> 00:32:48,799
code owner's features

998
00:32:48,799 --> 00:32:51,120
which ensures that the peer reviews come

999
00:32:51,120 --> 00:32:52,480
from policy admins

1000
00:32:52,480 --> 00:32:53,919
and that's because the policy admins are

1001
00:32:53,919 --> 00:32:55,200
the ones who are the most familiar with

1002
00:32:55,200 --> 00:32:56,399
the regular language

1003
00:32:56,399 --> 00:32:58,960
and also some of the more intricate

1004
00:32:58,960 --> 00:33:02,159
details of kubernetes

1005
00:33:02,640 --> 00:33:04,320
and what's probably the most important

1006
00:33:04,320 --> 00:33:06,159
point is that we use automation to

1007
00:33:06,159 --> 00:33:06,640
create

1008
00:33:06,640 --> 00:33:09,840
the gatekeeper and conf test resources

1009
00:33:09,840 --> 00:33:12,159
this means that reviewers can focus on

1010
00:33:12,159 --> 00:33:13,200
the policy

1011
00:33:13,200 --> 00:33:15,039
and not the gatekeeper resources you

1012
00:33:15,039 --> 00:33:17,200
know those giant emo files

1013
00:33:17,200 --> 00:33:18,960
and it also makes it really obvious if

1014
00:33:18,960 --> 00:33:20,399
someone is attempting to go around the

1015
00:33:20,399 --> 00:33:21,519
tooling in place

1016
00:33:21,519 --> 00:33:23,360
because no human should ever be trying

1017
00:33:23,360 --> 00:33:25,600
to modify the gatekeeper or conf test

1018
00:33:25,600 --> 00:33:28,080
resources directly

1019
00:33:28,080 --> 00:33:29,440
with that let's go through the life of a

1020
00:33:29,440 --> 00:33:32,000
policy in this policy pipeline

1021
00:33:32,000 --> 00:33:34,159
so here we have a higher level view of

1022
00:33:34,159 --> 00:33:36,000
how the policy flows

1023
00:33:36,000 --> 00:33:38,399
we start by introducing a policy into

1024
00:33:38,399 --> 00:33:39,360
the dev branch

1025
00:33:39,360 --> 00:33:41,279
through a pull request and we want to

1026
00:33:41,279 --> 00:33:43,039
make sure that the policy always has the

1027
00:33:43,039 --> 00:33:45,360
enforcement action set to dry run

1028
00:33:45,360 --> 00:33:47,120
after it's merged flux will

1029
00:33:47,120 --> 00:33:48,559
automatically pick it up and start

1030
00:33:48,559 --> 00:33:51,200
syncing it to the development clusters

1031
00:33:51,200 --> 00:33:53,279
next we then promote this to staging and

1032
00:33:53,279 --> 00:33:54,960
production branches

1033
00:33:54,960 --> 00:33:56,720
still in dry run mode and this is to

1034
00:33:56,720 --> 00:33:58,240
ensure that we have full visibility

1035
00:33:58,240 --> 00:34:00,080
across all of our clusters

1036
00:34:00,080 --> 00:34:01,600
because try as we might to keep all of

1037
00:34:01,600 --> 00:34:03,919
these clusters configured identically

1038
00:34:03,919 --> 00:34:04,559
through

1039
00:34:04,559 --> 00:34:06,720
development staging and prod there's

1040
00:34:06,720 --> 00:34:08,800
almost inevitably some variation in how

1041
00:34:08,800 --> 00:34:11,280
they're configured

1042
00:34:11,280 --> 00:34:13,520
so one thing to note is when we merge

1043
00:34:13,520 --> 00:34:15,119
into the production branch is when we

1044
00:34:15,119 --> 00:34:16,399
actually generate the conf test

1045
00:34:16,399 --> 00:34:17,679
resources

1046
00:34:17,679 --> 00:34:19,119
and one thing that we do there since

1047
00:34:19,119 --> 00:34:22,079
conf test doesn't have the concept of

1048
00:34:22,079 --> 00:34:25,359
an enforcement action is that we

1049
00:34:25,359 --> 00:34:26,960
parse that enforcement action from the

1050
00:34:26,960 --> 00:34:28,639
comment header and we

1051
00:34:28,639 --> 00:34:31,199
in line rewrite any violation or deny

1052
00:34:31,199 --> 00:34:32,719
rules to warnings

1053
00:34:32,719 --> 00:34:35,280
so that when they're used in the ci

1054
00:34:35,280 --> 00:34:36,079
flows

1055
00:34:36,079 --> 00:34:37,760
the warnings are still surfaced to the

1056
00:34:37,760 --> 00:34:39,760
teams working on those resources

1057
00:34:39,760 --> 00:34:44,079
but it doesn't fail the ci flows yet

1058
00:34:44,079 --> 00:34:46,239
so once we have all of these set up and

1059
00:34:46,239 --> 00:34:48,159
running we then use the gatekeeper audit

1060
00:34:48,159 --> 00:34:49,679
data as the source of truth

1061
00:34:49,679 --> 00:34:52,480
to identify our existing resources that

1062
00:34:52,480 --> 00:34:53,918
violate the policy

1063
00:34:53,918 --> 00:34:56,239
and then we open tickets to work with

1064
00:34:56,239 --> 00:34:58,079
our teams to remediate

1065
00:34:58,079 --> 00:35:00,320
the issues that we've identified or to

1066
00:35:00,320 --> 00:35:03,440
add exceptions where necessary

1067
00:35:03,440 --> 00:35:05,440
after we've ensured that those are all

1068
00:35:05,440 --> 00:35:07,760
remediated and the audit data shows this

1069
00:35:07,760 --> 00:35:10,160
we switch the development clusters and

1070
00:35:10,160 --> 00:35:11,359
the development branch to

1071
00:35:11,359 --> 00:35:14,240
actually enforcement this is done by

1072
00:35:14,240 --> 00:35:15,839
changing the enforcement action in the

1073
00:35:15,839 --> 00:35:16,800
header from

1074
00:35:16,800 --> 00:35:20,160
dry run to deny and once again

1075
00:35:20,160 --> 00:35:21,680
after we make this change and merge to

1076
00:35:21,680 --> 00:35:24,079
dev we are continuously monitoring the

1077
00:35:24,079 --> 00:35:26,079
gatekeeper audit data to make sure that

1078
00:35:26,079 --> 00:35:28,839
there isn't anything that we didn't

1079
00:35:28,839 --> 00:35:31,520
expect finally once we do that we

1080
00:35:31,520 --> 00:35:33,280
follow the same flow to promote to

1081
00:35:33,280 --> 00:35:36,079
staging and then production

1082
00:35:36,079 --> 00:35:38,320
it's worth noting again that when we

1083
00:35:38,320 --> 00:35:39,839
make this change to production

1084
00:35:39,839 --> 00:35:42,480
is when the conf test policies will

1085
00:35:42,480 --> 00:35:43,040
actually

1086
00:35:43,040 --> 00:35:46,720
be changed back to either a violation or

1087
00:35:46,720 --> 00:35:47,680
a deny

1088
00:35:47,680 --> 00:35:50,640
so at this point is when the ci flows

1089
00:35:50,640 --> 00:35:51,920
will start failing

1090
00:35:51,920 --> 00:35:53,440
if they have resources that violate the

1091
00:35:53,440 --> 00:35:55,920
policy

1092
00:35:56,880 --> 00:35:59,119
the comptest metrics here is useful for

1093
00:35:59,119 --> 00:36:00,240
us to

1094
00:36:00,240 --> 00:36:01,920
see what's going on across our

1095
00:36:01,920 --> 00:36:03,680
organization to have a more full picture

1096
00:36:03,680 --> 00:36:05,839
especially of newer repositories and

1097
00:36:05,839 --> 00:36:07,280
newer projects that

1098
00:36:07,280 --> 00:36:08,880
haven't actually made it into a cluster

1099
00:36:08,880 --> 00:36:10,720
yet but they are not the

1100
00:36:10,720 --> 00:36:12,480
source of truth for when we promote

1101
00:36:12,480 --> 00:36:14,960
policies

1102
00:36:14,960 --> 00:36:17,119
so where is ubico now on its policy

1103
00:36:17,119 --> 00:36:18,000
journey

1104
00:36:18,000 --> 00:36:19,920
well we have gatekeeper deployed to all

1105
00:36:19,920 --> 00:36:21,680
of our clusters and we're tracking the

1106
00:36:21,680 --> 00:36:24,079
resources that violate our policies

1107
00:36:24,079 --> 00:36:25,359
additionally we're making our way

1108
00:36:25,359 --> 00:36:27,359
through each policy and moving

1109
00:36:27,359 --> 00:36:29,920
each to enforcement as we go we've

1110
00:36:29,920 --> 00:36:30,720
noticed that in

1111
00:36:30,720 --> 00:36:33,280
a lot of scenarios these policy

1112
00:36:33,280 --> 00:36:34,800
violations are actually introduced

1113
00:36:34,800 --> 00:36:35,440
upstream

1114
00:36:35,440 --> 00:36:37,280
whether that be internal or external

1115
00:36:37,280 --> 00:36:39,520
project and whenever we run into that we

1116
00:36:39,520 --> 00:36:40,480
try and make our

1117
00:36:40,480 --> 00:36:43,359
upstream our changes as well looking

1118
00:36:43,359 --> 00:36:44,720
into the future though there's a few

1119
00:36:44,720 --> 00:36:46,560
ways that we can work on making this

1120
00:36:46,560 --> 00:36:47,920
better

1121
00:36:47,920 --> 00:36:49,520
the first is to enable our teams to

1122
00:36:49,520 --> 00:36:51,599
write their own policies for enforcing

1123
00:36:51,599 --> 00:36:53,760
their own specific best practices

1124
00:36:53,760 --> 00:36:56,320
this can be anything from a custom label

1125
00:36:56,320 --> 00:36:58,320
to requiring that every deployment have

1126
00:36:58,320 --> 00:36:58,720
a

1127
00:36:58,720 --> 00:37:01,920
horizontal pod auto scaler attached

1128
00:37:01,920 --> 00:37:03,440
additionally we're looking into syncing

1129
00:37:03,440 --> 00:37:05,200
data from outside the cluster into

1130
00:37:05,200 --> 00:37:06,480
gatekeeper to be used for

1131
00:37:06,480 --> 00:37:09,040
more informed policy decisions for

1132
00:37:09,040 --> 00:37:10,960
example we might want to sync our

1133
00:37:10,960 --> 00:37:12,800
on-call rotation schedule into

1134
00:37:12,800 --> 00:37:15,040
gatekeeper so that only the person who's

1135
00:37:15,040 --> 00:37:16,480
on call for a given team

1136
00:37:16,480 --> 00:37:18,240
can make changes to production in the

1137
00:37:18,240 --> 00:37:20,320
event that a production issue or outage

1138
00:37:20,320 --> 00:37:22,079
is occurring

1139
00:37:22,079 --> 00:37:24,400
looking even further we are considering

1140
00:37:24,400 --> 00:37:26,240
adding mutation controllers as well

1141
00:37:26,240 --> 00:37:27,520
and those are a different type of

1142
00:37:27,520 --> 00:37:29,359
controller that the api server can work

1143
00:37:29,359 --> 00:37:30,000
with

1144
00:37:30,000 --> 00:37:32,079
which rather than just rejecting a

1145
00:37:32,079 --> 00:37:34,000
resource if it doesn't meet policy

1146
00:37:34,000 --> 00:37:37,119
it can inline change the defaults as

1147
00:37:37,119 --> 00:37:38,400
needed

1148
00:37:38,400 --> 00:37:40,400
one thing to note there is gatekeeper

1149
00:37:40,400 --> 00:37:41,920
currently has an open

1150
00:37:41,920 --> 00:37:44,480
design for their implementation of that

1151
00:37:44,480 --> 00:37:45,200
they haven't

1152
00:37:45,200 --> 00:37:47,839
started on it yet so if you want to add

1153
00:37:47,839 --> 00:37:49,119
your thoughts about how that should be

1154
00:37:49,119 --> 00:37:50,960
shaped or anything like that

1155
00:37:50,960 --> 00:37:52,480
go ahead and just search on the opa

1156
00:37:52,480 --> 00:37:54,240
slack for

1157
00:37:54,240 --> 00:37:58,160
mutation design and it'll come right up

1158
00:37:58,800 --> 00:38:00,480
and that about wraps it up thank you

1159
00:38:00,480 --> 00:38:02,640
everyone for attending and we are going

1160
00:38:02,640 --> 00:38:05,839
to open it for questions

