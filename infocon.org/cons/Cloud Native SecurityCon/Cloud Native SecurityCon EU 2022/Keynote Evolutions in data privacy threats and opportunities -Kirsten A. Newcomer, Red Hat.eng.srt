1
00:00:00,080 --> 00:00:02,800
it's great to be here uh

2
00:00:02,800 --> 00:00:04,799
i guess i could take this off hope

3
00:00:04,799 --> 00:00:09,120
everybody's doing well keeping safe

4
00:00:09,120 --> 00:00:10,800
and i've noticed we all have different

5
00:00:10,800 --> 00:00:14,639
templates for our talks today so

6
00:00:14,639 --> 00:00:16,880
as was noted i'm going to focus a bit on

7
00:00:16,880 --> 00:00:19,680
data privacy threats and opportunities

8
00:00:19,680 --> 00:00:21,359
today

9
00:00:21,359 --> 00:00:23,680
this particular word cloud

10
00:00:23,680 --> 00:00:26,000
was built from

11
00:00:26,000 --> 00:00:29,039
a blog from the uk government

12
00:00:29,039 --> 00:00:31,840
it governance dot uk

13
00:00:31,840 --> 00:00:35,600
about data breaches in 2021

14
00:00:35,600 --> 00:00:36,640
and

15
00:00:36,640 --> 00:00:39,120
i realized i forgot my notes and frankly

16
00:00:39,120 --> 00:00:41,120
i was prepping late last night so i'm

17
00:00:41,120 --> 00:00:42,840
getting notes

18
00:00:42,840 --> 00:00:45,280
um so

19
00:00:45,280 --> 00:00:47,520
you can see that data breaches are

20
00:00:47,520 --> 00:00:49,520
ongoing i don't think that's news to any

21
00:00:49,520 --> 00:00:51,440
of us in this room any of us who are

22
00:00:51,440 --> 00:00:53,920
paying attention to security we know

23
00:00:53,920 --> 00:00:56,239
this is this is an ongoing reality of

24
00:00:56,239 --> 00:00:58,399
the world we're in

25
00:00:58,399 --> 00:01:00,559
it's a data driven world it's becoming

26
00:01:00,559 --> 00:01:02,640
more and more data driven

27
00:01:02,640 --> 00:01:05,280
and we all have data at risk

28
00:01:05,280 --> 00:01:07,439
this data this information comes from

29
00:01:07,439 --> 00:01:09,439
the same blog

30
00:01:09,439 --> 00:01:12,000
it's interesting to see that health care

31
00:01:12,000 --> 00:01:12,880
is

32
00:01:12,880 --> 00:01:15,439
one of the major sources of breaches

33
00:01:15,439 --> 00:01:17,600
public sector

34
00:01:17,600 --> 00:01:19,920
nice that financial services is a bit

35
00:01:19,920 --> 00:01:21,680
smaller i would have expected i guess

36
00:01:21,680 --> 00:01:23,360
they've they've been doing a good job of

37
00:01:23,360 --> 00:01:26,640
keeping up with protections um but you

38
00:01:26,640 --> 00:01:28,880
can also see that on the

39
00:01:28,880 --> 00:01:30,640
uh

40
00:01:30,640 --> 00:01:33,200
right-hand side of the slide

41
00:01:33,200 --> 00:01:35,520
right the areas that have the the

42
00:01:35,520 --> 00:01:37,840
organizations that have had the biggest

43
00:01:37,840 --> 00:01:39,920
number of breaches

44
00:01:39,920 --> 00:01:42,000
including linkedin which i imagine many

45
00:01:42,000 --> 00:01:45,200
of us here today are on

46
00:01:45,200 --> 00:01:48,720
so encrypting data continues to be key

47
00:01:48,720 --> 00:01:51,600
attestation of

48
00:01:51,600 --> 00:01:54,720
servers and environments also important

49
00:01:54,720 --> 00:01:56,960
more important than ever especially when

50
00:01:56,960 --> 00:01:59,759
data is at the edge which is more and

51
00:01:59,759 --> 00:02:01,680
more so right all the data on our cell

52
00:02:01,680 --> 00:02:03,920
phones mobile phones

53
00:02:03,920 --> 00:02:05,680
and there's progress happening that our

54
00:02:05,680 --> 00:02:08,399
community is helping to drive open sls

55
00:02:08,399 --> 00:02:12,720
ssl three is out fips 140-3 is in

56
00:02:12,720 --> 00:02:13,920
progress

57
00:02:13,920 --> 00:02:15,840
sig store one of the most you know

58
00:02:15,840 --> 00:02:18,239
quickly growing adopted projects that

59
00:02:18,239 --> 00:02:20,640
i've seen in the open source community

60
00:02:20,640 --> 00:02:23,040
to help with supply chain security and

61
00:02:23,040 --> 00:02:25,280
signing of assets as they move through

62
00:02:25,280 --> 00:02:27,120
the supply chain

63
00:02:27,120 --> 00:02:30,319
techtom chains working with tecton for

64
00:02:30,319 --> 00:02:32,239
again cloud native pipelines and

65
00:02:32,239 --> 00:02:34,480
attestation of that tool chain

66
00:02:34,480 --> 00:02:38,000
key lime remote attestation of servers

67
00:02:38,000 --> 00:02:40,640
and the cncf sandbox project on

68
00:02:40,640 --> 00:02:43,840
confidential containers bringing trusted

69
00:02:43,840 --> 00:02:46,480
execution environments to containers

70
00:02:46,480 --> 00:02:48,560
based on kata containers

71
00:02:48,560 --> 00:02:50,800
so great stuff happening

72
00:02:50,800 --> 00:02:52,160
in the community

73
00:02:52,160 --> 00:02:54,959
also ai and ml can help

74
00:02:54,959 --> 00:02:57,360
when it comes to addressing

75
00:02:57,360 --> 00:02:59,519
these kinds of threats threats against

76
00:02:59,519 --> 00:03:00,400
data

77
00:03:00,400 --> 00:03:01,440
ai and

78
00:03:01,440 --> 00:03:04,159
ml can do a better job than humans at

79
00:03:04,159 --> 00:03:08,239
identifying patterns malware patterns

80
00:03:08,239 --> 00:03:10,800
other kinds of challenges that show up

81
00:03:10,800 --> 00:03:13,280
out there they can predict potential

82
00:03:13,280 --> 00:03:15,120
attacks

83
00:03:15,120 --> 00:03:17,680
by identifying trends and at the same

84
00:03:17,680 --> 00:03:20,080
time doing all of this requires access

85
00:03:20,080 --> 00:03:22,239
to data

86
00:03:22,239 --> 00:03:24,080
a project that might be interesting kind

87
00:03:24,080 --> 00:03:25,840
of the learn more links are scattered

88
00:03:25,840 --> 00:03:27,840
throughout this deck as i when i upload

89
00:03:27,840 --> 00:03:30,040
things they'll be available to you

90
00:03:30,040 --> 00:03:33,920
opencep complex event processing

91
00:03:33,920 --> 00:03:36,000
is a project that is available for

92
00:03:36,000 --> 00:03:38,319
contribution evaluation anybody who's

93
00:03:38,319 --> 00:03:39,440
interested

94
00:03:39,440 --> 00:03:41,040
helps to

95
00:03:41,040 --> 00:03:42,400
do things that

96
00:03:42,400 --> 00:03:45,200
can be leveraged to look for financial

97
00:03:45,200 --> 00:03:46,560
fraud

98
00:03:46,560 --> 00:03:49,599
privacy threats things along those lines

99
00:03:49,599 --> 00:03:52,560
that said attackers are also learning to

100
00:03:52,560 --> 00:03:55,120
trick some of these algorithms so this

101
00:03:55,120 --> 00:03:57,840
is an area both to contribute to and to

102
00:03:57,840 --> 00:03:59,599
pay attention to

103
00:03:59,599 --> 00:04:02,000
one of the things we might do in this

104
00:04:02,000 --> 00:04:02,959
space

105
00:04:02,959 --> 00:04:04,480
actually is start thinking about

106
00:04:04,480 --> 00:04:07,200
homomorphic encryption

107
00:04:07,200 --> 00:04:09,519
this is a type of encryption

108
00:04:09,519 --> 00:04:12,159
that enables computations on data

109
00:04:12,159 --> 00:04:14,959
without decrypting the data

110
00:04:14,959 --> 00:04:17,199
and the computation results remain

111
00:04:17,199 --> 00:04:19,199
encrypted as well

112
00:04:19,199 --> 00:04:21,839
so this can enable privacy

113
00:04:21,839 --> 00:04:25,199
of the data while this ai and ml type of

114
00:04:25,199 --> 00:04:28,080
analysis is happening on the data can

115
00:04:28,080 --> 00:04:30,080
allow you to do things like maintain

116
00:04:30,080 --> 00:04:32,000
privacy with health care data again

117
00:04:32,000 --> 00:04:33,919
remember health care was one of the main

118
00:04:33,919 --> 00:04:36,160
areas of attack

119
00:04:36,160 --> 00:04:37,840
in 2021

120
00:04:37,840 --> 00:04:40,400
and this can allow for a more granular

121
00:04:40,400 --> 00:04:42,639
protection of that health care data as

122
00:04:42,639 --> 00:04:43,520
well

123
00:04:43,520 --> 00:04:46,000
so an area again that's worth investing

124
00:04:46,000 --> 00:04:48,400
investigating investing in

125
00:04:48,400 --> 00:04:50,400
lots for us as a community to see what

126
00:04:50,400 --> 00:04:52,240
we can be doing how can we leverage

127
00:04:52,240 --> 00:04:54,400
these technologies

128
00:04:54,400 --> 00:04:57,040
and at the same time

129
00:04:57,040 --> 00:04:59,600
uh quantum computing is coming for our

130
00:04:59,600 --> 00:05:02,960
crypto right so it's been demonstrated

131
00:05:02,960 --> 00:05:06,080
that quantum computing can break some of

132
00:05:06,080 --> 00:05:08,639
our existing crypto algorithms within 10

133
00:05:08,639 --> 00:05:10,160
seconds

134
00:05:10,160 --> 00:05:12,160
so there's a strong investment also

135
00:05:12,160 --> 00:05:15,840
happening for post-quantum cryptography

136
00:05:15,840 --> 00:05:16,800
and

137
00:05:16,800 --> 00:05:19,600
nist etsy iso are all investing in

138
00:05:19,600 --> 00:05:21,759
standards in this space

139
00:05:21,759 --> 00:05:23,680
that said this work has been going on

140
00:05:23,680 --> 00:05:26,320
for some time

141
00:05:26,320 --> 00:05:28,880
ideally we will see new standards in

142
00:05:28,880 --> 00:05:34,080
2023 to 2026 that's not that near term

143
00:05:34,080 --> 00:05:36,160
and we know you know the the threats are

144
00:05:36,160 --> 00:05:37,759
out there

145
00:05:37,759 --> 00:05:39,199
also we know it's going to take some

146
00:05:39,199 --> 00:05:42,320
time for our our companies our industry

147
00:05:42,320 --> 00:05:46,240
our ecosystem to adopt the new standards

148
00:05:46,240 --> 00:05:48,479
so given the short time we have today

149
00:05:48,479 --> 00:05:50,720
this is really just a teaser about all

150
00:05:50,720 --> 00:05:52,800
this kind of information but please

151
00:05:52,800 --> 00:05:54,479
especially if any of you are really

152
00:05:54,479 --> 00:05:57,120
interested in crypto get involved

153
00:05:57,120 --> 00:06:00,160
contribute look into ai and ml and how

154
00:06:00,160 --> 00:06:03,520
that can help us with security and also

155
00:06:03,520 --> 00:06:06,560
get involved in post-crypto post-quantum

156
00:06:06,560 --> 00:06:09,759
cryptography and homomorphic encryption

157
00:06:09,759 --> 00:06:12,800
as options for improving data protection

158
00:06:12,800 --> 00:06:14,080
today

159
00:06:14,080 --> 00:06:16,710
thanks so much for your time

160
00:06:16,710 --> 00:06:20,270
[Applause]

