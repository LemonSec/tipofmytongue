1
00:00:00,060 --> 00:00:02,610
good morning to all of you my name is

2
00:00:02,610 --> 00:00:05,339
Sabrina I'm the head of information

3
00:00:05,339 --> 00:00:07,500
security mile which is a New York City

4
00:00:07,500 --> 00:00:11,719
startup before joining for mio I spend

5
00:00:11,719 --> 00:00:15,000
six years in AT&T research doing the

6
00:00:15,000 --> 00:00:19,439
securities research on IOT cloud

7
00:00:19,439 --> 00:00:21,930
security and software-defined networks

8
00:00:21,930 --> 00:00:24,330
and before that I spent five Great years

9
00:00:24,330 --> 00:00:26,519
in Georgia Tech on my PhD in cloud

10
00:00:26,519 --> 00:00:29,070
security and as the head of security of

11
00:00:29,070 --> 00:00:31,230
mio I oversee the entire security

12
00:00:31,230 --> 00:00:34,260
program application security cloud

13
00:00:34,260 --> 00:00:36,450
security threat intelligence security

14
00:00:36,450 --> 00:00:39,090
operation is in Incident Response and of

15
00:00:39,090 --> 00:00:41,460
course compliance and today I will be

16
00:00:41,460 --> 00:00:44,070
talking about ml guard service that my

17
00:00:44,070 --> 00:00:46,710
team developed to detect malicious web

18
00:00:46,710 --> 00:00:50,239
requests in the cloud using server glass

19
00:00:50,239 --> 00:00:52,590
so just to give you a quick background

20
00:00:52,590 --> 00:00:56,390
on what frame dot IO is so we are the

21
00:00:56,390 --> 00:00:58,379
world's famous video review and

22
00:00:58,379 --> 00:01:01,320
collaboration platform the allow users

23
00:01:01,320 --> 00:01:04,199
to upload media content contents in our

24
00:01:04,199 --> 00:01:06,990
cloud and then invite team members and

25
00:01:06,990 --> 00:01:10,140
collaborators to actually our team

26
00:01:10,140 --> 00:01:11,580
members and clients to collaborate on

27
00:01:11,580 --> 00:01:14,460
those videos so you can think of us as a

28
00:01:14,460 --> 00:01:16,290
github for videos or Google Doc for

29
00:01:16,290 --> 00:01:20,820
videos one of the main feature that we

30
00:01:20,820 --> 00:01:23,700
provide is a frame accurate

31
00:01:23,700 --> 00:01:27,750
communication so for example if you can

32
00:01:27,750 --> 00:01:30,060
go on a specific frame and then type

33
00:01:30,060 --> 00:01:32,220
comments saying that hey change these

34
00:01:32,220 --> 00:01:35,909
colors or look at the fonts and so on

35
00:01:35,909 --> 00:01:38,610
and and those comments get actually

36
00:01:38,610 --> 00:01:41,100
embedded in the video itself and then

37
00:01:41,100 --> 00:01:42,840
you can also annotate the video if you

38
00:01:42,840 --> 00:01:45,240
want to be more pictorial in in your

39
00:01:45,240 --> 00:01:47,220
comments and these comments can be seen

40
00:01:47,220 --> 00:01:49,530
in real time to your team members and

41
00:01:49,530 --> 00:01:52,280
collaborators and they can perform

42
00:01:52,280 --> 00:01:55,320
actions and this saves a lot of time and

43
00:01:55,320 --> 00:01:58,140
awards long email threads that you have

44
00:01:58,140 --> 00:02:03,360
during your review process another thing

45
00:02:03,360 --> 00:02:06,390
that we allow people to to create a

46
00:02:06,390 --> 00:02:08,538
secure hub for their film productions

47
00:02:08,538 --> 00:02:11,310
it's a single place a single place where

48
00:02:11,310 --> 00:02:13,440
you can your teams can control

49
00:02:13,440 --> 00:02:16,500
who can see what and when and it also

50
00:02:16,500 --> 00:02:19,610
lets team to easily organize and manage

51
00:02:19,610 --> 00:02:22,560
divergence of each assets so which is

52
00:02:22,560 --> 00:02:24,690
again very important when you are

53
00:02:24,690 --> 00:02:26,490
working with thousands of episodic

54
00:02:26,490 --> 00:02:29,280
contents and you want it you want a

55
00:02:29,280 --> 00:02:30,930
place where you can easily manage the

56
00:02:30,930 --> 00:02:36,000
and those are videos and finally we

57
00:02:36,000 --> 00:02:38,610
allow users to securely share this

58
00:02:38,610 --> 00:02:40,560
content with external parties right

59
00:02:40,560 --> 00:02:44,430
because sometimes you have to go in and

60
00:02:44,430 --> 00:02:47,370
get approval to executives or all those

61
00:02:47,370 --> 00:02:48,930
people who are not part of the platform

62
00:02:48,930 --> 00:02:51,720
and through our platform you can do that

63
00:02:51,720 --> 00:02:54,840
and you can also customize that how and

64
00:02:54,840 --> 00:02:58,050
what they will see and again this is

65
00:02:58,050 --> 00:03:00,570
very important end up in the

66
00:03:00,570 --> 00:03:03,420
post-production phase so I mean these

67
00:03:03,420 --> 00:03:06,270
value propositions have have enabled us

68
00:03:06,270 --> 00:03:09,450
to work with some biggest customers in

69
00:03:09,450 --> 00:03:11,160
the media entertainment industry and

70
00:03:11,160 --> 00:03:12,960
also in the technological industries

71
00:03:12,960 --> 00:03:15,120
because these days everybody's pretty

72
00:03:15,120 --> 00:03:18,660
producing content and also this habit

73
00:03:18,660 --> 00:03:23,010
and this this feature have made of a

74
00:03:23,010 --> 00:03:27,450
platform a target for attacks so let's

75
00:03:27,450 --> 00:03:31,440
take a quick look that after getting a

76
00:03:31,440 --> 00:03:33,450
30,000 foot overview how actually gets

77
00:03:33,450 --> 00:03:35,400
translated into actual platform and this

78
00:03:35,400 --> 00:03:37,739
is a very simplified view of our

79
00:03:37,739 --> 00:03:42,470
platform but this is but this this is

80
00:03:42,470 --> 00:03:45,780
relevant for the today's talk when users

81
00:03:45,780 --> 00:03:48,269
come to a platform this and request and

82
00:03:48,269 --> 00:03:49,769
that request comes through the load

83
00:03:49,769 --> 00:03:53,340
balancer and load balancer decides where

84
00:03:53,340 --> 00:03:54,989
to send the request and we here and

85
00:03:54,989 --> 00:03:57,060
containerized workload and we are also

86
00:03:57,060 --> 00:03:59,940
moving to kubernetes as well and we are

87
00:03:59,940 --> 00:04:03,959
entirely hosted in in AWS so all the

88
00:04:03,959 --> 00:04:06,780
workloads running inside VPC and we have

89
00:04:06,780 --> 00:04:08,880
lot more readable services running

90
00:04:08,880 --> 00:04:11,700
behind the scene and security group and

91
00:04:11,700 --> 00:04:14,489
so on and the database actually is used

92
00:04:14,489 --> 00:04:16,620
to store the transaction data and there

93
00:04:16,620 --> 00:04:18,238
is a separate path here that I am not

94
00:04:18,238 --> 00:04:19,620
showing here which is not relevant for

95
00:04:19,620 --> 00:04:23,580
the today's talk is to how we talk to s3

96
00:04:23,580 --> 00:04:24,990
bucket for uploading and downloading

97
00:04:24,990 --> 00:04:26,860
videos

98
00:04:26,860 --> 00:04:30,669
now as I said that is the best platform

99
00:04:30,669 --> 00:04:33,699
so users are sending requests and

100
00:04:33,699 --> 00:04:35,800
attacked us also also sending bad

101
00:04:35,800 --> 00:04:37,840
requests with some some weeks we see

102
00:04:37,840 --> 00:04:40,960
millions of attacks to a platform some

103
00:04:40,960 --> 00:04:43,659
some are targeted some are scanners

104
00:04:43,659 --> 00:04:46,740
running in the system or on the net and

105
00:04:46,740 --> 00:04:51,159
when it happens though the the best way

106
00:04:51,159 --> 00:04:54,039
or one of the ways to secure or block

107
00:04:54,039 --> 00:04:56,650
those malicious requests is to use Web

108
00:04:56,650 --> 00:04:59,789
Application Firewall AWS has a rough

109
00:04:59,789 --> 00:05:02,590
service that we use a lot we have

110
00:05:02,590 --> 00:05:04,780
developed our own custom rules on top of

111
00:05:04,780 --> 00:05:08,259
graph but we also use some knowledge

112
00:05:08,259 --> 00:05:10,990
rule services from the marketplace and

113
00:05:10,990 --> 00:05:17,639
that help us block WASC top-ten attacks

114
00:05:17,639 --> 00:05:20,620
attacks coming from bots and and so on

115
00:05:20,620 --> 00:05:24,909
and that gives us say if gives us the

116
00:05:24,909 --> 00:05:27,909
first layer of defense and block

117
00:05:27,909 --> 00:05:31,659
malicious requests so when we started

118
00:05:31,659 --> 00:05:34,330
running these graphs and started

119
00:05:34,330 --> 00:05:36,279
collecting data from the replication law

120
00:05:36,279 --> 00:05:38,529
firewall logs and we started seeing what

121
00:05:38,529 --> 00:05:40,150
kind of requests are getting in what

122
00:05:40,150 --> 00:05:42,129
what is what kind of requests are

123
00:05:42,129 --> 00:05:45,129
getting blocked and he found that graphs

124
00:05:45,129 --> 00:05:48,610
are easy to evade and I mean this is not

125
00:05:48,610 --> 00:05:50,349
a news we all know that right signature

126
00:05:50,349 --> 00:05:54,789
based systems are susceptible to evasion

127
00:05:54,789 --> 00:05:58,870
techniques because they are static so

128
00:05:58,870 --> 00:06:01,690
the ones you craft the rules rules you

129
00:06:01,690 --> 00:06:04,360
don't change that often they are signal

130
00:06:04,360 --> 00:06:08,020
and they are signature based systems so

131
00:06:08,020 --> 00:06:11,199
so you have a sequel injection signature

132
00:06:11,199 --> 00:06:13,300
they try to mass equal injection but if

133
00:06:13,300 --> 00:06:16,500
you encode your

134
00:06:16,509 --> 00:06:18,910
input multiple times they won't be able

135
00:06:18,910 --> 00:06:21,550
to parse it and then that's why it's

136
00:06:21,550 --> 00:06:24,520
very hard for four vas to detect zero

137
00:06:24,520 --> 00:06:30,069
day attacks and once once we started

138
00:06:30,069 --> 00:06:32,379
seeing the requests we in our logs that

139
00:06:32,379 --> 00:06:34,030
we thought that it should be blocked by

140
00:06:34,030 --> 00:06:35,949
valve they were not getting blocked by

141
00:06:35,949 --> 00:06:38,520
valve so so we started looking into

142
00:06:38,520 --> 00:06:41,680
anomaly detection based systems again

143
00:06:41,680 --> 00:06:43,360
it's well known that anomaly based

144
00:06:43,360 --> 00:06:46,060
systems are dynamic because they they

145
00:06:46,060 --> 00:06:48,940
learn over time how the system is

146
00:06:48,940 --> 00:06:50,800
behaving what the clothes are good what

147
00:06:50,800 --> 00:06:52,960
APIs are supposed to be blog and then

148
00:06:52,960 --> 00:06:56,400
they can easily find anomalous requests

149
00:06:56,400 --> 00:06:59,380
they are more context aware so for

150
00:06:59,380 --> 00:07:01,000
example if you are running a ruby or

151
00:07:01,000 --> 00:07:04,020
elixir based applications and your

152
00:07:04,020 --> 00:07:06,880
scanner is sending you PHP requests

153
00:07:06,880 --> 00:07:09,669
normally since valves don't have any

154
00:07:09,669 --> 00:07:11,680
application context they will still that

155
00:07:11,680 --> 00:07:14,560
all PHP related requests go through your

156
00:07:14,560 --> 00:07:17,949
firewall but since anomaly detection

157
00:07:17,949 --> 00:07:20,199
system knows it's more context aware it

158
00:07:20,199 --> 00:07:22,120
can block those required can it can find

159
00:07:22,120 --> 00:07:24,039
them anomalous and it can it can alert

160
00:07:24,039 --> 00:07:26,710
you that some scanners are sending PHP

161
00:07:26,710 --> 00:07:30,520
requests and and due to this nature they

162
00:07:30,520 --> 00:07:34,270
can easily detect 0-2 exploits once you

163
00:07:34,270 --> 00:07:38,229
know that there is enough anomaly is

164
00:07:38,229 --> 00:07:40,300
seen in the in the request pattern you

165
00:07:40,300 --> 00:07:42,009
can block it whether it's known attack

166
00:07:42,009 --> 00:07:47,590
or unknown attacks and with this insight

167
00:07:47,590 --> 00:07:52,509
into our own own systems we we came up

168
00:07:52,509 --> 00:07:54,810
with this idea of developing ml guard

169
00:07:54,810 --> 00:07:57,729
it's a service based machine learning

170
00:07:57,729 --> 00:08:00,340
system that basically detects malicious

171
00:08:00,340 --> 00:08:04,360
web requests you we when we when we were

172
00:08:04,360 --> 00:08:06,400
designing ml guard we really didn't want

173
00:08:06,400 --> 00:08:09,699
to create our own infrastructure

174
00:08:09,699 --> 00:08:12,009
footprint right we didn't want to run a

175
00:08:12,009 --> 00:08:14,580
lot of V arms or heavy machine learning

176
00:08:14,580 --> 00:08:17,650
systems and then having the

177
00:08:17,650 --> 00:08:20,560
responsibility of managing it managing

178
00:08:20,560 --> 00:08:22,569
our own security infrastructure and

179
00:08:22,569 --> 00:08:25,330
that's why we we decided to use a lot of

180
00:08:25,330 --> 00:08:27,159
server as there's technologies as well

181
00:08:27,159 --> 00:08:29,320
and that I will show you

182
00:08:29,320 --> 00:08:38,409
this dog so emily guard has has five

183
00:08:38,409 --> 00:08:41,350
stages and as most of machine learnings

184
00:08:41,350 --> 00:08:44,560
model or our systems have in the first

185
00:08:44,560 --> 00:08:48,820
stage we collect logs logs will help us

186
00:08:48,820 --> 00:08:51,940
build models and once we have the model

187
00:08:51,940 --> 00:08:55,180
we deploy the model and then using those

188
00:08:55,180 --> 00:09:00,400
models for future it was we use we using

189
00:09:00,400 --> 00:09:02,740
the model for future requests we decide

190
00:09:02,740 --> 00:09:04,360
whether it's a good request or bad

191
00:09:04,360 --> 00:09:07,180
request and then they say no normally we

192
00:09:07,180 --> 00:09:11,020
notify to two security team that this IP

193
00:09:11,020 --> 00:09:13,720
is sending bad requests and it crosses

194
00:09:13,720 --> 00:09:17,250
the threshold and all these stages use

195
00:09:17,250 --> 00:09:23,770
service technologies in our pipeline so

196
00:09:23,770 --> 00:09:25,660
before we look into an ml guard let's

197
00:09:25,660 --> 00:09:27,640
take a quick overview of what what kind

198
00:09:27,640 --> 00:09:29,650
of service technologies we are using so

199
00:09:29,650 --> 00:09:31,750
we are using mainly functions as a

200
00:09:31,750 --> 00:09:33,910
service and in it since we are entirely

201
00:09:33,910 --> 00:09:36,100
hosted in AWS we are using a dove this

202
00:09:36,100 --> 00:09:39,300
lambda extensively in our platform so

203
00:09:39,300 --> 00:09:41,890
when the cloud when the when the in the

204
00:09:41,890 --> 00:09:43,420
in the beginning cloud providers were

205
00:09:43,420 --> 00:09:46,750
offering highest services they still

206
00:09:46,750 --> 00:09:49,210
offer but but in the beginning it was

207
00:09:49,210 --> 00:09:51,190
the only service that is being offered

208
00:09:51,190 --> 00:09:52,750
they are hardware and hypervisor or

209
00:09:52,750 --> 00:09:55,600
managed by cloud providers and virtual

210
00:09:55,600 --> 00:09:57,790
machine operating system and app was the

211
00:09:57,790 --> 00:10:01,390
customer's responsibility in the

212
00:10:01,390 --> 00:10:03,700
platform world it got changed little bit

213
00:10:03,700 --> 00:10:05,470
because now hardware hypervisor and

214
00:10:05,470 --> 00:10:06,940
virtual machines are being managed by

215
00:10:06,940 --> 00:10:09,220
cloud providers and containers and

216
00:10:09,220 --> 00:10:11,020
applications were the responsibility of

217
00:10:11,020 --> 00:10:12,700
customers they have to do patch

218
00:10:12,700 --> 00:10:14,380
management they have to make sure that

219
00:10:14,380 --> 00:10:18,780
vulnerabilities gets addressed and so on

220
00:10:18,780 --> 00:10:21,880
but if this got pushed to an extreme in

221
00:10:21,880 --> 00:10:23,560
the function as a service world we are

222
00:10:23,560 --> 00:10:25,210
now cloud providers are managing

223
00:10:25,210 --> 00:10:27,250
hardware hypervisor virtual machine

224
00:10:27,250 --> 00:10:29,860
operating system and even the runtime so

225
00:10:29,860 --> 00:10:32,110
you don't have to you just as a customer

226
00:10:32,110 --> 00:10:33,940
you have to just bring your code and

227
00:10:33,940 --> 00:10:35,500
start

228
00:10:35,500 --> 00:10:37,840
running it so if you want to develop

229
00:10:37,840 --> 00:10:39,760
Python based application or Java based

230
00:10:39,760 --> 00:10:41,650
application you don't have to worry

231
00:10:41,650 --> 00:10:43,540
about their setting of the runtime or

232
00:10:43,540 --> 00:10:45,100
setting them the environment you can

233
00:10:45,100 --> 00:10:47,500
just bring your code and start working I

234
00:10:47,500 --> 00:10:51,220
start executing it and and that way we

235
00:10:51,220 --> 00:10:52,900
don't have to worry about patching our

236
00:10:52,900 --> 00:10:54,930
own infrastructure you can you can

237
00:10:54,930 --> 00:10:57,100
transfer this responsibility to the

238
00:10:57,100 --> 00:10:59,110
cloud provider that those millions or

239
00:10:59,110 --> 00:11:02,310
machines are properly managed and secure

240
00:11:02,310 --> 00:11:05,260
and you just have to worry about the

241
00:11:05,260 --> 00:11:07,600
security of your own code to make sure

242
00:11:07,600 --> 00:11:11,220
that you don't have any bugs in there

243
00:11:11,430 --> 00:11:15,220
and there are couple and there are

244
00:11:15,220 --> 00:11:17,380
several benefits of using servlets

245
00:11:17,380 --> 00:11:19,000
right first so as I said that no servers

246
00:11:19,000 --> 00:11:20,680
to manage so you don't have to worry

247
00:11:20,680 --> 00:11:24,190
about Danny about patching or securing

248
00:11:24,190 --> 00:11:26,830
those machines you don't have to worry

249
00:11:26,830 --> 00:11:30,910
about the scaling of those service

250
00:11:30,910 --> 00:11:33,130
functions as well because if there is

251
00:11:33,130 --> 00:11:36,490
yan is the if at the peak demand if you

252
00:11:36,490 --> 00:11:38,230
want to run thousands of concurrent

253
00:11:38,230 --> 00:11:40,870
execution of your service cloud

254
00:11:40,870 --> 00:11:43,000
providers will do that you don't have to

255
00:11:43,000 --> 00:11:45,990
set up automatic scaling group and so on

256
00:11:45,990 --> 00:11:49,630
you had it's it can help you save cost

257
00:11:49,630 --> 00:11:52,450
because the it's provides fine-grained

258
00:11:52,450 --> 00:11:55,510
metering so you are going to be charged

259
00:11:55,510 --> 00:11:58,150
on each invocation of your functions so

260
00:11:58,150 --> 00:11:59,530
you don't have to worry about that

261
00:11:59,530 --> 00:12:03,100
functions are unlike VMs where you have

262
00:12:03,100 --> 00:12:04,720
to pay when the VMS are running whether

263
00:12:04,720 --> 00:12:06,339
they are processing the workload or not

264
00:12:06,339 --> 00:12:08,650
functions you only pay when they are

265
00:12:08,650 --> 00:12:11,589
involved and it's and it's a faster time

266
00:12:11,589 --> 00:12:14,440
to market because again you don't have

267
00:12:14,440 --> 00:12:16,780
to worry about the environment so we use

268
00:12:16,780 --> 00:12:19,360
server server less a lot in our entire

269
00:12:19,360 --> 00:12:21,160
infrastructure we have a transcoding

270
00:12:21,160 --> 00:12:23,589
pipeline where we transcode videos using

271
00:12:23,589 --> 00:12:25,450
servers and step functions and in

272
00:12:25,450 --> 00:12:28,930
security team is using a lot and based

273
00:12:28,930 --> 00:12:31,110
on our extensive usage we came up with

274
00:12:31,110 --> 00:12:34,360
six or six different design patterns for

275
00:12:34,360 --> 00:12:36,940
service we even wrote a research paper

276
00:12:36,940 --> 00:12:39,880
last year in hot floud that describes

277
00:12:39,880 --> 00:12:41,770
all the design patterns and how those

278
00:12:41,770 --> 00:12:44,770
patterns count came together in our

279
00:12:44,770 --> 00:12:46,750
third intelligent system but in this

280
00:12:46,750 --> 00:12:48,790
stuff or for this talk I would

281
00:12:48,790 --> 00:12:50,350
to cover two patterns that we are using

282
00:12:50,350 --> 00:12:54,400
a lot in ml God so one is even driven

283
00:12:54,400 --> 00:12:57,420
and one other is periodic invocation

284
00:12:57,420 --> 00:13:00,220
they are very easy to understand even

285
00:13:00,220 --> 00:13:02,620
Durin's functions are when these

286
00:13:02,620 --> 00:13:04,450
functions of the service or lambda

287
00:13:04,450 --> 00:13:06,760
functions get at get subscribed to

288
00:13:06,760 --> 00:13:10,570
events so for example lambda functions

289
00:13:10,570 --> 00:13:13,780
can can sit on top of s3 and listen for

290
00:13:13,780 --> 00:13:16,390
all the put objects operation and as

291
00:13:16,390 --> 00:13:18,280
soon as objects are stored in the

292
00:13:18,280 --> 00:13:20,350
industry bucket this lambda function

293
00:13:20,350 --> 00:13:24,460
gets invoked process the event and and

294
00:13:24,460 --> 00:13:27,910
and go back to sleep and and and this

295
00:13:27,910 --> 00:13:30,310
kind of functions are very useful

296
00:13:30,310 --> 00:13:33,370
because you only pay for their

297
00:13:33,370 --> 00:13:36,100
invocation so you don't have to so that

298
00:13:36,100 --> 00:13:39,190
saves cost and also you don't have to do

299
00:13:39,190 --> 00:13:41,680
polling it because they are only being

300
00:13:41,680 --> 00:13:43,480
involved when the event is at of

301
00:13:43,480 --> 00:13:50,530
interest is actually happening and s3 is

302
00:13:50,530 --> 00:13:53,200
one example you can also use lambda

303
00:13:53,200 --> 00:13:54,700
functions can also be attached to

304
00:13:54,700 --> 00:13:57,730
DynamoDB so a table so if they if you

305
00:13:57,730 --> 00:13:59,770
whenever you add new entry these lambda

306
00:13:59,770 --> 00:14:01,720
functions can be invoked to process

307
00:14:01,720 --> 00:14:09,010
those added roles periodic invocation

308
00:14:09,010 --> 00:14:11,800
service functions are nothing but think

309
00:14:11,800 --> 00:14:14,250
of this a glorified cron job sort of

310
00:14:14,250 --> 00:14:17,650
that we have all used in our in in the

311
00:14:17,650 --> 00:14:20,160
past so they are invoked periodically

312
00:14:20,160 --> 00:14:23,650
every minute we are daily they can be

313
00:14:23,650 --> 00:14:26,290
customized and then they get when it

314
00:14:26,290 --> 00:14:28,330
gets invoked it does is its performance

315
00:14:28,330 --> 00:14:30,640
is this job and then uses some

316
00:14:30,640 --> 00:14:32,770
asynchronous mechanism or sometimes

317
00:14:32,770 --> 00:14:36,760
email to is pass the result to the pass

318
00:14:36,760 --> 00:14:39,160
the results to to the function that is

319
00:14:39,160 --> 00:14:41,440
calling or to the service that is

320
00:14:41,440 --> 00:14:44,320
calling and that's very useful for

321
00:14:44,320 --> 00:14:48,190
example if you want to develop it it's

322
00:14:48,190 --> 00:14:51,160
service that that is using a larger base

323
00:14:51,160 --> 00:14:54,400
algorithm to transfer data from s3 to

324
00:14:54,400 --> 00:14:56,680
glacier these lambda functions can be

325
00:14:56,680 --> 00:14:59,290
invoked once in a day look at the LRU

326
00:14:59,290 --> 00:15:01,630
policy or for each uploaded object and

327
00:15:01,630 --> 00:15:02,080
this

328
00:15:02,080 --> 00:15:06,040
transfer to Glacial since V as you know

329
00:15:06,040 --> 00:15:08,740
as in our platform we allow users to

330
00:15:08,740 --> 00:15:10,870
upload media contents right so we have a

331
00:15:10,870 --> 00:15:13,330
petabytes of a storage right so for us

332
00:15:13,330 --> 00:15:15,430
to save cost we would like to we have

333
00:15:15,430 --> 00:15:17,590
this kind of lambdas running that can

334
00:15:17,590 --> 00:15:20,290
transfer data to glacier to - for the

335
00:15:20,290 --> 00:15:25,570
vault to save cost and this is also good

336
00:15:25,570 --> 00:15:28,060
for for compliance purposes because

337
00:15:28,060 --> 00:15:30,340
dailyvee you want to check whether our

338
00:15:30,340 --> 00:15:32,290
infrastructure or services or cloud

339
00:15:32,290 --> 00:15:35,260
configurations are compliant for sock -

340
00:15:35,260 --> 00:15:37,090
or for other compliance framework that

341
00:15:37,090 --> 00:15:41,560
we we are part of so with that

342
00:15:41,560 --> 00:15:43,930
information let's look ml guard again

343
00:15:43,930 --> 00:15:47,860
so again five stages and and collect

344
00:15:47,860 --> 00:15:51,700
build deploy prediction and notify the

345
00:15:51,700 --> 00:15:53,290
first step is that how do we collect

346
00:15:53,290 --> 00:15:56,650
logs right so ml guard as I shown you in

347
00:15:56,650 --> 00:16:01,810
the first slide that the all our

348
00:16:01,810 --> 00:16:03,370
incoming requests hits the load

349
00:16:03,370 --> 00:16:06,160
balancers so we ml guard works off the

350
00:16:06,160 --> 00:16:08,890
load balancer data it's a very similar

351
00:16:08,890 --> 00:16:11,530
to web logs it has all the fields that

352
00:16:11,530 --> 00:16:13,330
you normally find in the web logs and

353
00:16:13,330 --> 00:16:16,240
since it is it captures all the

354
00:16:16,240 --> 00:16:18,370
interactions with the customer we are

355
00:16:18,370 --> 00:16:21,330
using that log to train the model and

356
00:16:21,330 --> 00:16:25,600
all the logs are provided by AWS so

357
00:16:25,600 --> 00:16:27,880
these logs are actually stored in the in

358
00:16:27,880 --> 00:16:30,850
the s3 bucket and we call them raw logs

359
00:16:30,850 --> 00:16:33,310
because they are though they are that's

360
00:16:33,310 --> 00:16:36,970
the log that AWS provides but then we

361
00:16:36,970 --> 00:16:39,070
use even driven lambda functions on top

362
00:16:39,070 --> 00:16:41,890
of this s3 bucket - and this lambdas job

363
00:16:41,890 --> 00:16:44,470
is to enrich the data that we get from

364
00:16:44,470 --> 00:16:48,550
AWS so enrichment for example ELB logs

365
00:16:48,550 --> 00:16:51,040
have IP addresses then but we enrich the

366
00:16:51,040 --> 00:16:53,740
data by adding geo locations in there in

367
00:16:53,740 --> 00:16:58,720
it it has IP addresses of our instances

368
00:16:58,720 --> 00:17:01,330
or VMs but then we attach security

369
00:17:01,330 --> 00:17:03,580
groups or other important informations

370
00:17:03,580 --> 00:17:06,220
that we have you know you know in our

371
00:17:06,220 --> 00:17:09,880
environment to do that - that entry so

372
00:17:09,880 --> 00:17:11,980
that it becomes enraged it has lot more

373
00:17:11,980 --> 00:17:14,670
context and that's going to help us

374
00:17:14,670 --> 00:17:16,410
train the model

375
00:17:16,410 --> 00:17:19,770
and and and and and find problems when

376
00:17:19,770 --> 00:17:22,140
night when we look at the logs and then

377
00:17:22,140 --> 00:17:23,670
this lambda function is toward the

378
00:17:23,670 --> 00:17:26,069
enriched data into the into another

379
00:17:26,069 --> 00:17:30,810
bucket around the prefix and the s3 and

380
00:17:30,810 --> 00:17:33,180
we also pass this data to our to

381
00:17:33,180 --> 00:17:35,520
elasticsearch so we use elastic such as

382
00:17:35,520 --> 00:17:40,080
our sim so it can help us create graphs

383
00:17:40,080 --> 00:17:43,830
visualizations and and even then we want

384
00:17:43,830 --> 00:17:46,200
to when in some in case of attacks we

385
00:17:46,200 --> 00:17:48,120
can easily go to elastic search and see

386
00:17:48,120 --> 00:17:53,280
what kind of request was sent once we

387
00:17:53,280 --> 00:17:56,960
have the log then the next step is to

388
00:17:56,960 --> 00:17:59,370
what algorithm should be used to

389
00:17:59,370 --> 00:18:02,910
actually build a model so there are

390
00:18:02,910 --> 00:18:05,070
supervisor algorithms in machine

391
00:18:05,070 --> 00:18:06,570
learning there are unsupervised there's

392
00:18:06,570 --> 00:18:10,170
reinforcements right so supervised we

393
00:18:10,170 --> 00:18:11,910
need label data but it's very hard to

394
00:18:11,910 --> 00:18:13,410
get the label data in the in the

395
00:18:13,410 --> 00:18:15,120
security was right because you don't

396
00:18:15,120 --> 00:18:19,080
know what all the task patterns right so

397
00:18:19,080 --> 00:18:20,900
we resorted to unsupervised learning

398
00:18:20,900 --> 00:18:23,430
right because we don't need label data

399
00:18:23,430 --> 00:18:26,040
for that but it does require us to have

400
00:18:26,040 --> 00:18:28,500
a huge amount of data set right to train

401
00:18:28,500 --> 00:18:31,320
the model luckily for us we get millions

402
00:18:31,320 --> 00:18:33,870
of requests every day so millions of

403
00:18:33,870 --> 00:18:36,030
logs ELB logs that is good and

404
00:18:36,030 --> 00:18:37,710
sufficient enough for us to train the

405
00:18:37,710 --> 00:18:41,430
model so we use unsupervised learning to

406
00:18:41,430 --> 00:18:43,440
basically basically find the anomalous

407
00:18:43,440 --> 00:18:48,420
requests sent by attackers so it becomes

408
00:18:48,420 --> 00:18:51,030
an outlier detection problem right find

409
00:18:51,030 --> 00:18:54,660
the needle in the haystack so we we use

410
00:18:54,660 --> 00:18:57,420
isolation forest algorithm it says in

411
00:18:57,420 --> 00:18:59,910
outlier detection algorithm whose job is

412
00:18:59,910 --> 00:19:04,860
to find and on this point by another's

413
00:19:04,860 --> 00:19:06,870
point from a given distribution by

414
00:19:06,870 --> 00:19:10,200
creating in Samba of binary trees right

415
00:19:10,200 --> 00:19:13,860
so in a nutshell without going too much

416
00:19:13,860 --> 00:19:16,590
into the details and we can talk offline

417
00:19:16,590 --> 00:19:20,040
on that the way isolation forest works

418
00:19:20,040 --> 00:19:21,960
is like this it's very intuitive to

419
00:19:21,960 --> 00:19:24,630
understand that it basically finds

420
00:19:24,630 --> 00:19:26,730
outlier right it's fine it finds so that

421
00:19:26,730 --> 00:19:29,340
the point is

422
00:19:29,340 --> 00:19:33,160
is is anomalous so the way it does it

423
00:19:33,160 --> 00:19:38,050
basically creates cuts in the in the in

424
00:19:38,050 --> 00:19:41,740
the data set so if you are or splits so

425
00:19:41,740 --> 00:19:44,380
if you if in a few splits if you can

426
00:19:44,380 --> 00:19:46,990
isolate a point means point is an

427
00:19:46,990 --> 00:19:49,600
outlier right if it's to think about in

428
00:19:49,600 --> 00:19:51,850
this point if you kid take a one cut and

429
00:19:51,850 --> 00:19:53,920
the point is off then it means an

430
00:19:53,920 --> 00:19:58,150
outlier but if you are using 10 15 20

431
00:19:58,150 --> 00:20:01,000
cuts in order to split the data and and

432
00:20:01,000 --> 00:20:05,770
now and and isolate a point means that

433
00:20:05,770 --> 00:20:08,200
this point is normal right that's what's

434
00:20:08,200 --> 00:20:10,990
shown here that if the red point is in

435
00:20:10,990 --> 00:20:13,690
three cuts B we could isolate it it

436
00:20:13,690 --> 00:20:16,240
means that it's an outlier but the point

437
00:20:16,240 --> 00:20:19,630
on the in the center we have to go

438
00:20:19,630 --> 00:20:23,830
through almost 700 cuts it means that

439
00:20:23,830 --> 00:20:25,840
this point is not an outlier normal

440
00:20:25,840 --> 00:20:28,450
point and that's the basic idea behind

441
00:20:28,450 --> 00:20:33,520
isolation forests now we have data we

442
00:20:33,520 --> 00:20:35,620
have model so what features do we need

443
00:20:35,620 --> 00:20:37,810
to do we need to use to train the model

444
00:20:37,810 --> 00:20:41,320
and and the idea that we want to come up

445
00:20:41,320 --> 00:20:43,090
with that we don't want to know

446
00:20:43,090 --> 00:20:45,520
individual HTTP requests or individual

447
00:20:45,520 --> 00:20:47,530
requesters they are good or bad we want

448
00:20:47,530 --> 00:20:50,410
to know whether IP is good or bad right

449
00:20:50,410 --> 00:20:55,750
and and we can find it out based on what

450
00:20:55,750 --> 00:20:57,460
kind of request is being sent by the

451
00:20:57,460 --> 00:21:00,370
denied by that IP so on the Left if you

452
00:21:00,370 --> 00:21:02,650
see that if IP is sending a lot of good

453
00:21:02,650 --> 00:21:05,080
to a lot of 200 requests 300 requests

454
00:21:05,080 --> 00:21:09,550
which are supposedly good and very few

455
00:21:09,550 --> 00:21:13,330
400 500 requests which are signs of a

456
00:21:13,330 --> 00:21:15,370
bad it was forbidden or internal server

457
00:21:15,370 --> 00:21:18,790
error means this IPS is overall good IP

458
00:21:18,790 --> 00:21:19,450
right

459
00:21:19,450 --> 00:21:22,270
but on the on the right side if an IP is

460
00:21:22,270 --> 00:21:25,990
sending very few 200 300 requests but a

461
00:21:25,990 --> 00:21:29,050
lot more 400 and 500 Ric was it means

462
00:21:29,050 --> 00:21:31,210
that the type is either is scanning

463
00:21:31,210 --> 00:21:33,280
they're trying to find its way and

464
00:21:33,280 --> 00:21:35,920
that's where they are getting denied so

465
00:21:35,920 --> 00:21:38,020
many times knew the site is bad and

466
00:21:38,020 --> 00:21:40,570
that's when we want to look into what

467
00:21:40,570 --> 00:21:44,220
that IP is doing so that we can block it

468
00:21:45,660 --> 00:21:48,940
so the next step is to build train and

469
00:21:48,940 --> 00:21:52,150
deploy model and for this purpose we use

470
00:21:52,150 --> 00:21:53,920
AWS sage maker

471
00:21:53,920 --> 00:21:55,900
it's a machine learning as a service

472
00:21:55,900 --> 00:21:58,330
that AWS provides that makes your job

473
00:21:58,330 --> 00:22:00,820
lot easier in terms of build and train

474
00:22:00,820 --> 00:22:03,550
and deploy model once of our algorithm

475
00:22:03,550 --> 00:22:05,710
was ready we in few hours we could have

476
00:22:05,710 --> 00:22:07,540
our system up and running we're using

477
00:22:07,540 --> 00:22:11,260
AWS age maker and there we are using

478
00:22:11,260 --> 00:22:15,880
again lot of star wallis technologies so

479
00:22:15,880 --> 00:22:17,800
here we are using periodic lambda

480
00:22:17,800 --> 00:22:21,070
invocation so what what what we did once

481
00:22:21,070 --> 00:22:22,900
we have once we know we are using

482
00:22:22,900 --> 00:22:28,900
isolation forests and we are our model

483
00:22:28,900 --> 00:22:32,830
was coded we containerized it right so

484
00:22:32,830 --> 00:22:34,660
and published into the ECR

485
00:22:34,660 --> 00:22:37,840
and wrote a periodic lambda function

486
00:22:37,840 --> 00:22:41,970
whose job is to wakes up every 24 hours

487
00:22:41,970 --> 00:22:44,820
run the container automatically and

488
00:22:44,820 --> 00:22:48,460
container talks to the english lb bits

489
00:22:48,460 --> 00:22:51,700
that enrich data from s3 retains the

490
00:22:51,700 --> 00:22:54,130
model every 24 hours and deploys the

491
00:22:54,130 --> 00:22:56,260
final model in the stage maker there is

492
00:22:56,260 --> 00:22:59,170
no manual intervention at all a model

493
00:22:59,170 --> 00:23:02,500
every everyday more this lambda function

494
00:23:02,500 --> 00:23:05,370
is training the model automatically and

495
00:23:05,370 --> 00:23:07,990
once the model strain it is running in

496
00:23:07,990 --> 00:23:10,780
the stage maker and that's when we go to

497
00:23:10,780 --> 00:23:13,960
the prediction stage and what happens

498
00:23:13,960 --> 00:23:15,820
when you deploy a model in ch maker it

499
00:23:15,820 --> 00:23:18,610
gives you an HTTP endpoint that you can

500
00:23:18,610 --> 00:23:21,130
directly invoke and it can tell you what

501
00:23:21,130 --> 00:23:23,260
the request is good or bad so again we

502
00:23:23,260 --> 00:23:25,450
are using periodic lambda invocation

503
00:23:25,450 --> 00:23:27,880
that that invokes every few minutes and

504
00:23:27,880 --> 00:23:30,730
looks into the recent request that was

505
00:23:30,730 --> 00:23:34,630
sent by by IPS and it gets the model

506
00:23:34,630 --> 00:23:37,630
from the database and starts invoking

507
00:23:37,630 --> 00:23:40,960
invoking invoking the model with the

508
00:23:40,960 --> 00:23:43,030
HTTP request or with the with the

509
00:23:43,030 --> 00:23:45,520
collection of HTTP requests based on IPS

510
00:23:45,520 --> 00:23:48,220
and started worrying whether this is a

511
00:23:48,220 --> 00:23:51,160
good IP bad IP good IP bad IP and stage

512
00:23:51,160 --> 00:23:54,220
maker tells us that our model tells us

513
00:23:54,220 --> 00:23:55,140
that

514
00:23:55,140 --> 00:23:57,810
the results and if the mother if the

515
00:23:57,810 --> 00:23:59,880
predictor lambda finds out that this is

516
00:23:59,880 --> 00:24:02,250
a bad I P we get modified onslaught

517
00:24:02,250 --> 00:24:07,140
saying that this is the attack going on

518
00:24:07,140 --> 00:24:09,630
or this IP sending bad requests look

519
00:24:09,630 --> 00:24:12,300
into it and through slack we can again

520
00:24:12,300 --> 00:24:17,160
automatic response we can take so this

521
00:24:17,160 --> 00:24:19,820
is a notification to security analyst

522
00:24:19,820 --> 00:24:23,640
duties I took some details off from this

523
00:24:23,640 --> 00:24:26,160
this alert those who are interested I

524
00:24:26,160 --> 00:24:28,740
can show you offline so it says that

525
00:24:28,740 --> 00:24:32,390
anomalous IP this IP is anomalous and

526
00:24:32,390 --> 00:24:35,790
this post a link to our Cabana

527
00:24:35,790 --> 00:24:38,670
elasticsearch dashboard if you click on

528
00:24:38,670 --> 00:24:40,620
it you can directly go to the elastic

529
00:24:40,620 --> 00:24:42,480
search and see all the requests sent by

530
00:24:42,480 --> 00:24:44,520
that IP in the last few minutes so you

531
00:24:44,520 --> 00:24:46,080
can see that in real time what is

532
00:24:46,080 --> 00:24:49,470
happening then we show the IP but we

533
00:24:49,470 --> 00:24:52,050
also add IPS reputation along with it so

534
00:24:52,050 --> 00:24:54,300
if you click on that IP it can take you

535
00:24:54,300 --> 00:24:57,210
out to the reputation website to show

536
00:24:57,210 --> 00:25:00,420
you whether this IP is part of Dracula

537
00:25:00,420 --> 00:25:02,610
is part of email spoofing is from China

538
00:25:02,610 --> 00:25:04,320
is from Russia you can know all those

539
00:25:04,320 --> 00:25:06,780
things and they also have a geolocation

540
00:25:06,780 --> 00:25:09,240
but some geo locations are changing

541
00:25:09,240 --> 00:25:11,820
sometimes so you have to get it and keep

542
00:25:11,820 --> 00:25:15,120
updating your geo I play database and we

543
00:25:15,120 --> 00:25:17,430
have a block list and the triage this

544
00:25:17,430 --> 00:25:19,650
means that if you triage means that ok

545
00:25:19,650 --> 00:25:21,690
you looked into it you you ignored it

546
00:25:21,690 --> 00:25:23,970
but if you say block we can directly

547
00:25:23,970 --> 00:25:26,280
block if you click on this thing web

548
00:25:26,280 --> 00:25:28,770
book gets fired that invokes few other

549
00:25:28,770 --> 00:25:30,570
lambda functions and we directly add

550
00:25:30,570 --> 00:25:32,970
this IP to our Web Application Firewall

551
00:25:32,970 --> 00:25:36,690
list or block list and that's when this

552
00:25:36,690 --> 00:25:43,770
IP is blocked automatically so few

553
00:25:43,770 --> 00:25:46,620
metrics related to our system in the

554
00:25:46,620 --> 00:25:48,750
last month of October through our system

555
00:25:48,750 --> 00:25:53,070
we blocked 339 IPs alone that were

556
00:25:53,070 --> 00:25:55,380
basically flagged by our system and then

557
00:25:55,380 --> 00:25:57,510
we found out that these IPS were indeed

558
00:25:57,510 --> 00:26:00,270
sending bad requests we so we blocked

559
00:26:00,270 --> 00:26:04,740
them it's not an accurate and 527 unique

560
00:26:04,740 --> 00:26:07,740
IPS were reported by another guard so if

561
00:26:07,740 --> 00:26:08,880
you look into the person

562
00:26:08,880 --> 00:26:11,670
just like a 65% of IPS that were

563
00:26:11,670 --> 00:26:12,420
reported

564
00:26:12,420 --> 00:26:14,310
we actually block them but that's not an

565
00:26:14,310 --> 00:26:17,880
accuracy test because sometimes Amal

566
00:26:17,880 --> 00:26:20,760
guards still detects that this IP is a

567
00:26:20,760 --> 00:26:23,520
bad IP but for a business reason we

568
00:26:23,520 --> 00:26:27,500
decide to not to block it right because

569
00:26:27,500 --> 00:26:29,820
they are either hitting our rate

570
00:26:29,820 --> 00:26:31,680
limiting violation and we do want them

571
00:26:31,680 --> 00:26:34,200
to still test it but we looked into it

572
00:26:34,200 --> 00:26:37,250
but still want them to go through and

573
00:26:37,250 --> 00:26:42,030
sometimes Amal guard identifies problems

574
00:26:42,030 --> 00:26:44,640
in our web application right that that

575
00:26:44,640 --> 00:26:46,320
we then we go to developers and tell

576
00:26:46,320 --> 00:26:48,240
them why we are sending this error code

577
00:26:48,240 --> 00:26:49,680
when we were supposed to sending some

578
00:26:49,680 --> 00:26:51,840
different error codes so - they use - to

579
00:26:51,840 --> 00:26:54,900
end user and that's when it's very good

580
00:26:54,900 --> 00:26:56,970
for our developers to see that what's

581
00:26:56,970 --> 00:27:00,330
going to get a real insight on on how

582
00:27:00,330 --> 00:27:02,280
what are the problems are within the

583
00:27:02,280 --> 00:27:08,010
application so they can fix that so the

584
00:27:08,010 --> 00:27:12,480
key takeaway from this talk that it used

585
00:27:12,480 --> 00:27:14,820
to be very hard to develop machine

586
00:27:14,820 --> 00:27:16,710
learning based systems right you have to

587
00:27:16,710 --> 00:27:19,980
spend so much as days months to build

588
00:27:19,980 --> 00:27:23,460
train and deploy models but with the in

589
00:27:23,460 --> 00:27:25,950
the cloud with the server less and with

590
00:27:25,950 --> 00:27:27,450
the machine learning service this

591
00:27:27,450 --> 00:27:30,030
becomes very easy we are using lot more

592
00:27:30,030 --> 00:27:32,340
algorithms right now in our pipeline or

593
00:27:32,340 --> 00:27:35,580
in our in our layer defense that are AI

594
00:27:35,580 --> 00:27:38,370
and machine learning driven rather than

595
00:27:38,370 --> 00:27:41,280
just signature-based driven so do try it

596
00:27:41,280 --> 00:27:43,380
out I mean it's like developing

597
00:27:43,380 --> 00:27:45,270
integrating these kind of services in

598
00:27:45,270 --> 00:27:47,880
serve with server less and services are

599
00:27:47,880 --> 00:27:53,160
are the I mean are possible and is the

600
00:27:53,160 --> 00:27:57,060
way forward thank you

601
00:27:57,060 --> 00:28:03,059
[Applause]

