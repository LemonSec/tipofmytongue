1
00:00:00,000 --> 00:00:01,920
thank you very much uh it's so exciting

2
00:00:01,920 --> 00:00:04,500
to be here uh there's so much gratitude

3
00:00:04,500 --> 00:00:06,600
uh and and and and really debt that we

4
00:00:06,600 --> 00:00:08,639
owe to the cloud native Community uh at

5
00:00:08,639 --> 00:00:10,800
the open source security Foundation uh

6
00:00:10,800 --> 00:00:12,540
and uh just really happy to be talking

7
00:00:12,540 --> 00:00:14,219
with you about a little bit about what

8
00:00:14,219 --> 00:00:15,599
we're doing but but I actually wanted to

9
00:00:15,599 --> 00:00:17,520
start out a bit with um the kinds of

10
00:00:17,520 --> 00:00:18,660
things that we want to be thinking about

11
00:00:18,660 --> 00:00:21,960
next because so often we're uh fixing

12
00:00:21,960 --> 00:00:24,060
security rules today that that reflect

13
00:00:24,060 --> 00:00:26,880
uh attacks that uh have been kind of

14
00:00:26,880 --> 00:00:28,859
pervasive on the internet since since uh

15
00:00:28,859 --> 00:00:31,199
time immemorial uh but but I want to try

16
00:00:31,199 --> 00:00:33,180
to set a context for how do we prepare

17
00:00:33,180 --> 00:00:35,340
for things that are coming up right uh

18
00:00:35,340 --> 00:00:37,200
and so pardon me if this seems like a

19
00:00:37,200 --> 00:00:38,340
little bit of a late night brainstorm

20
00:00:38,340 --> 00:00:40,559
using chat GPT and Google image search

21
00:00:40,559 --> 00:00:43,200
but uh hopefully you'll forgive me so um

22
00:00:43,200 --> 00:00:45,360
you know in the early days and you can

23
00:00:45,360 --> 00:00:47,160
tell this is a slide about the past

24
00:00:47,160 --> 00:00:49,620
because there's a CRT on the on the uh

25
00:00:49,620 --> 00:00:52,559
the counter there uh you know we you

26
00:00:52,559 --> 00:00:54,300
know does anyone remember telnet I don't

27
00:00:54,300 --> 00:00:57,180
think anyone born after 1980 uh has ever

28
00:00:57,180 --> 00:00:58,800
typed the letters telnet unless you were

29
00:00:58,800 --> 00:01:00,480
like doing something really weird

30
00:01:00,480 --> 00:01:01,980
um but like I wrote a whole like chat

31
00:01:01,980 --> 00:01:03,660
system where telnet was the client it

32
00:01:03,660 --> 00:01:04,860
was awesome right

33
00:01:04,860 --> 00:01:06,299
um and you could you know go from one

34
00:01:06,299 --> 00:01:07,799
machine to another you could pretend to

35
00:01:07,799 --> 00:01:09,240
be a mail server you know that kind of

36
00:01:09,240 --> 00:01:10,260
thing but

37
00:01:10,260 --> 00:01:12,540
um we kind of just took for granted that

38
00:01:12,540 --> 00:01:14,400
the systems administrators and the

39
00:01:14,400 --> 00:01:15,900
network admins and others weren't going

40
00:01:15,900 --> 00:01:17,400
to be sniffing our packets because like

41
00:01:17,400 --> 00:01:18,720
why bother well there's nothing

42
00:01:18,720 --> 00:01:20,460
interesting going over uh this traffic

43
00:01:20,460 --> 00:01:24,900
anyways uh SMTP uh was not secure by

44
00:01:24,900 --> 00:01:27,000
default when it first came out right uh

45
00:01:27,000 --> 00:01:29,580
all these different protocols kind of uh

46
00:01:29,580 --> 00:01:31,680
we we kind of took for granted that we

47
00:01:31,680 --> 00:01:34,080
could trust a certain layer of the

48
00:01:34,080 --> 00:01:36,060
internet or the people that ran certain

49
00:01:36,060 --> 00:01:38,280
layers below us so that we could move

50
00:01:38,280 --> 00:01:39,720
more quickly so that we could like build

51
00:01:39,720 --> 00:01:41,100
the kinds of things we wanted to build

52
00:01:41,100 --> 00:01:44,820
but those kinds of decisions left uh uh

53
00:01:44,820 --> 00:01:47,159
to to Future Generations uh kind of

54
00:01:47,159 --> 00:01:48,659
patching up those assumptions and

55
00:01:48,659 --> 00:01:50,640
defaults and biases right it was great

56
00:01:50,640 --> 00:01:52,680
that we were able to move quickly but I

57
00:01:52,680 --> 00:01:54,780
I the internet was kind of like didn't

58
00:01:54,780 --> 00:01:57,299
have security by default uh for a long

59
00:01:57,299 --> 00:01:58,380
time and arguably it still doesn't

60
00:01:58,380 --> 00:02:00,479
either right but it took us us a while

61
00:02:00,479 --> 00:02:03,299
now to our to in our defense one of the

62
00:02:03,299 --> 00:02:05,399
things that kept us from pervasively

63
00:02:05,399 --> 00:02:07,920
adding uh public key cryptography to all

64
00:02:07,920 --> 00:02:09,239
of our network connections and the like

65
00:02:09,239 --> 00:02:10,739
was the fact that public key

66
00:02:10,739 --> 00:02:12,720
cryptography was considered a munition

67
00:02:12,720 --> 00:02:14,819
by the US government it was considered a

68
00:02:14,819 --> 00:02:17,760
weapon a dual use technology that was

69
00:02:17,760 --> 00:02:19,860
regulated and the only way that you

70
00:02:19,860 --> 00:02:22,800
could transport that you could send a a

71
00:02:22,800 --> 00:02:25,140
software package that talked uh public

72
00:02:25,140 --> 00:02:27,480
key cryptography protocols that used

73
00:02:27,480 --> 00:02:30,120
more than 40 bits of entropy uh was to

74
00:02:30,120 --> 00:02:31,560
do that was to limit it to 40 bits or

75
00:02:31,560 --> 00:02:33,300
128 if you got special probes or

76
00:02:33,300 --> 00:02:35,340
whatever that meant you couldn't ship

77
00:02:35,340 --> 00:02:37,800
source code you could not uh because

78
00:02:37,800 --> 00:02:39,120
source code meant you could use

79
00:02:39,120 --> 00:02:42,480
arbitrary length Keys now in 99 there

80
00:02:42,480 --> 00:02:44,220
was a court case that was decided called

81
00:02:44,220 --> 00:02:46,680
The Bernstein case that the Apache

82
00:02:46,680 --> 00:02:48,360
software Foundation submitted an amicus

83
00:02:48,360 --> 00:02:50,940
brief to that actually stipulated that

84
00:02:50,940 --> 00:02:53,220
software development is a uh as a

85
00:02:53,220 --> 00:02:55,019
function of speech rather than a

86
00:02:55,019 --> 00:02:56,819
function of Commerce and that

87
00:02:56,819 --> 00:02:58,800
researchers at the very least needed the

88
00:02:58,800 --> 00:03:00,540
ability to talk about Crypt photography

89
00:03:00,540 --> 00:03:02,280
publicly it also helped that people took

90
00:03:02,280 --> 00:03:04,560
RSA and reduced it to like four lines of

91
00:03:04,560 --> 00:03:05,760
Pearl and printed it on the back of

92
00:03:05,760 --> 00:03:07,260
t-shirts and wore them as they crossed

93
00:03:07,260 --> 00:03:09,660
borders that was kind of fun but we made

94
00:03:09,660 --> 00:03:12,180
this case and we won and we won the

95
00:03:12,180 --> 00:03:14,760
argument that uh uh that basically

96
00:03:14,760 --> 00:03:17,220
public key cryptography should be widely

97
00:03:17,220 --> 00:03:19,920
available to help uh help us bootstrap

98
00:03:19,920 --> 00:03:22,260
and and get moved Beyond this default

99
00:03:22,260 --> 00:03:24,720
bias uh that you know we we couldn't

100
00:03:24,720 --> 00:03:26,099
have cryptography on the the lower

101
00:03:26,099 --> 00:03:27,540
levels of the internet

102
00:03:27,540 --> 00:03:28,739
um uh and that was that was pretty

103
00:03:28,739 --> 00:03:30,060
useful that was a pretty nice thing to

104
00:03:30,060 --> 00:03:33,780
be able to assume uh but uh that only uh

105
00:03:33,780 --> 00:03:36,000
Stripped Away one layer of the onion and

106
00:03:36,000 --> 00:03:37,379
we realized there were a whole lot more

107
00:03:37,379 --> 00:03:39,480
places where we had some default

108
00:03:39,480 --> 00:03:41,040
assumptions that that would later come

109
00:03:41,040 --> 00:03:42,840
to bite Us in the ass now this is Dan

110
00:03:42,840 --> 00:03:45,540
Kaminsky uh uh who passed away sadly a

111
00:03:45,540 --> 00:03:48,360
few years ago Dan um is probably the

112
00:03:48,360 --> 00:03:50,280
only person that I would ever credit

113
00:03:50,280 --> 00:03:52,739
with having saved the internet just like

114
00:03:52,739 --> 00:03:55,200
unquestionably Dan discovered a bug in

115
00:03:55,200 --> 00:03:57,720
bind the now it was more of a protocol

116
00:03:57,720 --> 00:04:01,260
bug in the DNS protocols uh frankly that

117
00:04:01,260 --> 00:04:03,540
allowed for something called DNS cache

118
00:04:03,540 --> 00:04:06,060
poisoning which meant preemptively an

119
00:04:06,060 --> 00:04:08,400
attacker could tell a DNS server you

120
00:04:08,400 --> 00:04:10,260
know google.com doesn't actually go to

121
00:04:10,260 --> 00:04:12,900
one IP address it goes to another and

122
00:04:12,900 --> 00:04:15,120
that meant that you know even with all

123
00:04:15,120 --> 00:04:17,160
the other work that we did yeah uh if

124
00:04:17,160 --> 00:04:19,079
you could uh corruptively you know

125
00:04:19,079 --> 00:04:21,600
corrupt all these DNS caches out there

126
00:04:21,600 --> 00:04:23,460
you could direct traffic wherever you

127
00:04:23,460 --> 00:04:25,500
wanted uh and and use that to steal

128
00:04:25,500 --> 00:04:27,840
credentials use that to steal other

129
00:04:27,840 --> 00:04:30,060
kinds of traffic and the problem was it

130
00:04:30,060 --> 00:04:32,580
was such a trivial trivially easy bug to

131
00:04:32,580 --> 00:04:35,400
exploit that if now I'm a big believer

132
00:04:35,400 --> 00:04:37,620
in security through transparency in

133
00:04:37,620 --> 00:04:39,360
trying to be public about about flaws

134
00:04:39,360 --> 00:04:41,220
and that kind of thing so that as a

135
00:04:41,220 --> 00:04:43,139
means to get them fixed faster but he

136
00:04:43,139 --> 00:04:44,820
kind of realized as a bunch of people

137
00:04:44,820 --> 00:04:46,620
did when he started to talk with him

138
00:04:46,620 --> 00:04:48,600
that the more this was would be known

139
00:04:48,600 --> 00:04:51,300
before it was fixed the more likely that

140
00:04:51,300 --> 00:04:52,680
the entire internet would really come

141
00:04:52,680 --> 00:04:55,320
down I mean if you bring down DNS uh

142
00:04:55,320 --> 00:04:57,180
where do you else do you bootstrap from

143
00:04:57,180 --> 00:04:58,620
I mean we would have had to use Etsy

144
00:04:58,620 --> 00:05:02,460
host files uh with IP addresses shared

145
00:05:02,460 --> 00:05:03,900
over Billboards or something like that

146
00:05:03,900 --> 00:05:05,820
in order to bootstrap back up and get to

147
00:05:05,820 --> 00:05:08,520
a usable internet again and so uh he

148
00:05:08,520 --> 00:05:10,199
worked very stealthily but but very

149
00:05:10,199 --> 00:05:12,060
determinantly with a whole set of the

150
00:05:12,060 --> 00:05:15,120
main DNS admins the back uh the uh the

151
00:05:15,120 --> 00:05:17,100
the the Upstream kind of a root DNS

152
00:05:17,100 --> 00:05:19,259
server sorry uh and others to get

153
00:05:19,259 --> 00:05:21,419
patches to software to get protocol

154
00:05:21,419 --> 00:05:23,520
changes where necessary to basically get

155
00:05:23,520 --> 00:05:25,440
to the point where DNS responses were

156
00:05:25,440 --> 00:05:28,020
verifiable uh and eliminated that bug

157
00:05:28,020 --> 00:05:29,940
and it had to be quiet but it got out

158
00:05:29,940 --> 00:05:32,580
there and it got updated and so we you

159
00:05:32,580 --> 00:05:35,240
know the transport layer security

160
00:05:35,240 --> 00:05:38,100
DNS layer security there's all these

161
00:05:38,100 --> 00:05:40,320
places where there's this technical debt

162
00:05:40,320 --> 00:05:43,500
that we accumulate as uh as developers

163
00:05:43,500 --> 00:05:45,840
and as protocol designers and as people

164
00:05:45,840 --> 00:05:47,220
out there in the world

165
00:05:47,220 --> 00:05:49,560
um building upon it now let's let's give

166
00:05:49,560 --> 00:05:50,820
ourselves a little bit of credit here

167
00:05:50,820 --> 00:05:53,880
every project bootstraps by taking a few

168
00:05:53,880 --> 00:05:55,500
things for granted otherwise I mean you

169
00:05:55,500 --> 00:05:56,940
can't boil the ocean you can't solve The

170
00:05:56,940 --> 00:05:58,139
World's problems you have to start

171
00:05:58,139 --> 00:06:01,020
somewhere you have to to decide where

172
00:06:01,020 --> 00:06:03,060
who you're going to trust right you have

173
00:06:03,060 --> 00:06:05,940
to decide uh how you're going to to get

174
00:06:05,940 --> 00:06:07,620
to rough consensus and running code

175
00:06:07,620 --> 00:06:09,660
quickly enough before your boss cancels

176
00:06:09,660 --> 00:06:12,060
your project or your grant money runs

177
00:06:12,060 --> 00:06:13,440
out or other things before you're able

178
00:06:13,440 --> 00:06:15,660
to prove hey we've got something but

179
00:06:15,660 --> 00:06:17,820
um but those decisions those biases

180
00:06:17,820 --> 00:06:20,039
create technical debt and often those

181
00:06:20,039 --> 00:06:21,780
assumptions and biases are never well

182
00:06:21,780 --> 00:06:23,639
documented they're not issues in an

183
00:06:23,639 --> 00:06:25,860
issue tracker they're not left as as

184
00:06:25,860 --> 00:06:28,020
things to do they're left as things for

185
00:06:28,020 --> 00:06:30,060
people to take up and and try to fix

186
00:06:30,060 --> 00:06:32,280
after the fact an example of this is

187
00:06:32,280 --> 00:06:34,740
there's a company called trellix uh that

188
00:06:34,740 --> 00:06:37,979
I announced last week two weeks ago it

189
00:06:37,979 --> 00:06:40,500
was the January 23rd that they had

190
00:06:40,500 --> 00:06:42,900
automatically submitted pull requests

191
00:06:42,900 --> 00:06:45,840
against 61 000 vulnerable open source

192
00:06:45,840 --> 00:06:49,080
projects that had adopted a c python

193
00:06:49,080 --> 00:06:51,900
actually module called tar file that had

194
00:06:51,900 --> 00:06:55,319
a cve from 2007 in it that was not fixed

195
00:06:55,319 --> 00:06:57,180
because the tar file maintainer is

196
00:06:57,180 --> 00:06:58,380
actually the C python maintainers

197
00:06:58,380 --> 00:07:00,900
contend that to fix fix it in a way that

198
00:07:00,900 --> 00:07:02,520
solved this problem would break posix

199
00:07:02,520 --> 00:07:04,199
compliance okay so this debate from like

200
00:07:04,199 --> 00:07:06,660
2007 but because it was unresolved

201
00:07:06,660 --> 00:07:09,360
because the the the the issue on it you

202
00:07:09,360 --> 00:07:11,039
know the comments go back 10 years it's

203
00:07:11,039 --> 00:07:13,380
hilarious uh uh because these weren't 15

204
00:07:13,380 --> 00:07:14,819
years sorry because this wasn't fixed

205
00:07:14,819 --> 00:07:16,560
thousands of projects picked this up and

206
00:07:16,560 --> 00:07:18,660
have used it in an unsafe way without

207
00:07:18,660 --> 00:07:20,940
validating inputs uh to make sure that

208
00:07:20,940 --> 00:07:22,680
expanding a tar file didn't overwrite

209
00:07:22,680 --> 00:07:25,440
Etsy password uh and uh because of that

210
00:07:25,440 --> 00:07:27,479
uh it was easy to scan easy to find

211
00:07:27,479 --> 00:07:28,740
these projects that were using in an

212
00:07:28,740 --> 00:07:31,500
unsafe way easy even to come up with

213
00:07:31,500 --> 00:07:33,360
fixes for that and submit pull requests

214
00:07:33,360 --> 00:07:36,300
that fix it now trellis I think has done

215
00:07:36,300 --> 00:07:38,699
those 61 000 projects a favor but I

216
00:07:38,699 --> 00:07:40,979
think they're going to be lucky if 15 of

217
00:07:40,979 --> 00:07:43,440
those projects even respond based on the

218
00:07:43,440 --> 00:07:45,060
work that folks like Jonathan Leach who

219
00:07:45,060 --> 00:07:46,680
gave a talk about automated pull

220
00:07:46,680 --> 00:07:48,840
requests and and fixing bugs at scale at

221
00:07:48,840 --> 00:07:51,360
Defcon last year uh his experiences and

222
00:07:51,360 --> 00:07:52,440
doing the same kinds of things

223
00:07:52,440 --> 00:07:54,300
identifying patterns identifying old

224
00:07:54,300 --> 00:07:56,639
bugs that need to go go back and be

225
00:07:56,639 --> 00:07:58,860
fixed it is extraordinarily hard and

226
00:07:58,860 --> 00:08:00,780
frankly for good reason maintainers hate

227
00:08:00,780 --> 00:08:02,520
it when you show up and say my scanning

228
00:08:02,520 --> 00:08:05,099
tool found a bunch of like worry some

229
00:08:05,099 --> 00:08:07,440
things in your code right so we've got

230
00:08:07,440 --> 00:08:09,240
to figure out how to get better at doing

231
00:08:09,240 --> 00:08:11,400
this and and how to go back and fix some

232
00:08:11,400 --> 00:08:12,780
of these low-level assumptions that are

233
00:08:12,780 --> 00:08:15,419
being made now thank you uh Priyanka for

234
00:08:15,419 --> 00:08:17,220
mentioning Sig store thank you to all of

235
00:08:17,220 --> 00:08:19,440
you who are using Sig store who are

236
00:08:19,440 --> 00:08:21,360
helping develop it uh who are are

237
00:08:21,360 --> 00:08:23,400
pushing it forward and getting and

238
00:08:23,400 --> 00:08:25,440
helping establish it as a standard for

239
00:08:25,440 --> 00:08:27,240
signing artifacts in the software supply

240
00:08:27,240 --> 00:08:29,940
chain but frankly signatures on on

241
00:08:29,940 --> 00:08:31,440
objects as they flow through the chain

242
00:08:31,440 --> 00:08:33,179
and into our dependencies should have

243
00:08:33,179 --> 00:08:35,820
been a problem we solved in 2005 2007

244
00:08:35,820 --> 00:08:37,679
and and we solved it somewhat most

245
00:08:37,679 --> 00:08:39,958
people saw it at The Last Mile with you

246
00:08:39,958 --> 00:08:41,820
know signatures and you know apt-get and

247
00:08:41,820 --> 00:08:43,500
that kind of thing but further up the

248
00:08:43,500 --> 00:08:45,060
chain we kind of took for granted that

249
00:08:45,060 --> 00:08:47,820
if something was on an https website a

250
00:08:47,820 --> 00:08:50,040
module there claiming to be a build of

251
00:08:50,040 --> 00:08:51,959
source code over here at this repo then

252
00:08:51,959 --> 00:08:54,060
we could trust it right and those trust

253
00:08:54,060 --> 00:08:56,220
that again that default assumption that

254
00:08:56,220 --> 00:08:57,839
default trust is really dangerous to

255
00:08:57,839 --> 00:08:59,880
have now

256
00:08:59,880 --> 00:09:02,100
what are some of the bad patterns we're

257
00:09:02,100 --> 00:09:03,779
still persisting today I know some of

258
00:09:03,779 --> 00:09:05,519
you just want to see the world burn but

259
00:09:05,519 --> 00:09:07,800
when you tell your users you know curl

260
00:09:07,800 --> 00:09:11,120
you know URL pipe to pseudo sh

261
00:09:11,120 --> 00:09:13,320
you're kind of doing the same thing I

262
00:09:13,320 --> 00:09:15,120
mean your argument might be well apt-get

263
00:09:15,120 --> 00:09:16,920
is just the same thing you can run a

264
00:09:16,920 --> 00:09:18,839
post install script that that you know

265
00:09:18,839 --> 00:09:20,220
compromises systems and everything

266
00:09:20,220 --> 00:09:21,720
should be in containers anyways right

267
00:09:21,720 --> 00:09:24,600
but that's cynicism about uh you know

268
00:09:24,600 --> 00:09:26,399
being able to build better resilient

269
00:09:26,399 --> 00:09:28,140
more resilient systems is kind of out

270
00:09:28,140 --> 00:09:30,000
there I mean even a dark pattern like

271
00:09:30,000 --> 00:09:32,100
choosing which package to use based on

272
00:09:32,100 --> 00:09:34,980
the number of stars on GitHub uh is is

273
00:09:34,980 --> 00:09:37,320
worrisome right like like there should

274
00:09:37,320 --> 00:09:39,720
be other data you use to figure out uh

275
00:09:39,720 --> 00:09:41,399
which packages to use and which to build

276
00:09:41,399 --> 00:09:43,380
because there's this thing called time

277
00:09:43,380 --> 00:09:46,560
that works against us in so many ways um

278
00:09:46,560 --> 00:09:48,420
time and these are just some general

279
00:09:48,420 --> 00:09:49,800
principles again two in the morning

280
00:09:49,800 --> 00:09:51,959
brainstorm apologize for that but there

281
00:09:51,959 --> 00:09:53,399
is really no such thing as true zero

282
00:09:53,399 --> 00:09:55,620
trust architecture there's defaults

283
00:09:55,620 --> 00:09:57,600
assumptions biases and things we build

284
00:09:57,600 --> 00:09:59,580
on top of for better and For Worse that

285
00:09:59,580 --> 00:10:01,920
we have to take for granted right you

286
00:10:01,920 --> 00:10:03,660
can take for granted that you know if

287
00:10:03,660 --> 00:10:05,640
you took the subway here or or a taxi

288
00:10:05,640 --> 00:10:07,260
here that it's you know the the wheels

289
00:10:07,260 --> 00:10:09,300
don't come off at the wrong time you

290
00:10:09,300 --> 00:10:10,920
know and it might once in a billion

291
00:10:10,920 --> 00:10:12,839
times but but you're able to take for

292
00:10:12,839 --> 00:10:14,339
granted that that system works right so

293
00:10:14,339 --> 00:10:16,320
it's not a flaw that we take things for

294
00:10:16,320 --> 00:10:18,060
granted but we just have to continually

295
00:10:18,060 --> 00:10:21,300
interrogate the the attack surface on

296
00:10:21,300 --> 00:10:23,959
the trust decisions that we make right

297
00:10:23,959 --> 00:10:26,459
attacks we think are hard to exploit

298
00:10:26,459 --> 00:10:28,980
also get easier over time this is kind

299
00:10:28,980 --> 00:10:31,440
of the chat GPT thing as well right this

300
00:10:31,440 --> 00:10:33,600
is the hey it used to be hard to write a

301
00:10:33,600 --> 00:10:34,980
lot of meaningless texts that looked

302
00:10:34,980 --> 00:10:37,500
good uh kind of it's mansplaining as a

303
00:10:37,500 --> 00:10:39,660
service is the term I like to use but

304
00:10:39,660 --> 00:10:42,959
um it's it's it's it but now it's

305
00:10:42,959 --> 00:10:44,459
actually trivially easy to do that and

306
00:10:44,459 --> 00:10:46,560
even to script that into processes my

307
00:10:46,560 --> 00:10:47,940
other favorite example of this is side

308
00:10:47,940 --> 00:10:49,680
Channel attacks like the fact that you

309
00:10:49,680 --> 00:10:51,480
could try to Divine a private key based

310
00:10:51,480 --> 00:10:53,220
on the timing of a CPU that's generating

311
00:10:53,220 --> 00:10:55,200
that like what the that's magic

312
00:10:55,200 --> 00:10:57,600
um but uh but the second principle and

313
00:10:57,600 --> 00:10:59,160
the second way the time works against us

314
00:10:59,160 --> 00:11:01,800
is that things that we think are norms

315
00:11:01,800 --> 00:11:02,940
things that we think people would be

316
00:11:02,940 --> 00:11:04,920
embarrassed by like who would possibly

317
00:11:04,920 --> 00:11:07,079
tell that to Port 25 and send mail from

318
00:11:07,079 --> 00:11:08,880
president whitehouse.gov while I did

319
00:11:08,880 --> 00:11:10,920
that as a college freshman somebody will

320
00:11:10,920 --> 00:11:13,800
eventually do that and if your theory of

321
00:11:13,800 --> 00:11:17,339
stability rests upon social norms that's

322
00:11:17,339 --> 00:11:19,140
fragile that's super fragile when you

323
00:11:19,140 --> 00:11:21,480
get to the number of users Beyond you

324
00:11:21,480 --> 00:11:24,120
know dunbar's number and personalities

325
00:11:24,120 --> 00:11:26,660
stop being a useful check on on security

326
00:11:26,660 --> 00:11:29,579
and then finally software deserves to

327
00:11:29,579 --> 00:11:31,500
have should have an expiration date it

328
00:11:31,500 --> 00:11:33,720
really you know there should we should

329
00:11:33,720 --> 00:11:35,459
assume software falls apart that

330
00:11:35,459 --> 00:11:38,339
software is suffers from bit rod in

331
00:11:38,339 --> 00:11:39,899
unusual ways

332
00:11:39,899 --> 00:11:41,160
um that you know you know how

333
00:11:41,160 --> 00:11:42,720
depreciation works you get to write off

334
00:11:42,720 --> 00:11:44,279
a computer asset over three years or

335
00:11:44,279 --> 00:11:45,660
five years whatever well I think you

336
00:11:45,660 --> 00:11:48,000
should write off a software that's been

337
00:11:48,000 --> 00:11:49,800
written and past three or five years

338
00:11:49,800 --> 00:11:52,740
take it from like a positive asset to a

339
00:11:52,740 --> 00:11:54,540
liability right that you try to get off

340
00:11:54,540 --> 00:11:56,040
your books because we have no other

341
00:11:56,040 --> 00:11:57,959
great way to measure technical debt

342
00:11:57,959 --> 00:11:59,700
except hey this this stuff is really all

343
00:11:59,700 --> 00:12:01,740
and I don't care if it still works it's

344
00:12:01,740 --> 00:12:04,200
still it's still a risk so putting these

345
00:12:04,200 --> 00:12:06,600
things together and I swear chat GPT did

346
00:12:06,600 --> 00:12:09,300
not require me to put this a slide in

347
00:12:09,300 --> 00:12:11,760
here it's I I came up with this all on

348
00:12:11,760 --> 00:12:13,680
my own um but let's think about ways

349
00:12:13,680 --> 00:12:15,600
that new tools like Chad gbt and AI

350
00:12:15,600 --> 00:12:17,519
Tools in general might generate new

351
00:12:17,519 --> 00:12:19,140
kinds of attacks on these these things

352
00:12:19,140 --> 00:12:20,760
these these things that we take for

353
00:12:20,760 --> 00:12:22,560
granted I mean first off automating

354
00:12:22,560 --> 00:12:24,420
spear phishing attacks on open source

355
00:12:24,420 --> 00:12:26,820
projects themselves using AI generated

356
00:12:26,820 --> 00:12:29,519
you know uh uh pull requests or comments

357
00:12:29,519 --> 00:12:31,440
and threads or that kind of thing has

358
00:12:31,440 --> 00:12:33,720
gone a lot from being like that's sci-fi

359
00:12:33,720 --> 00:12:35,820
that's Corey doctoral territory two no

360
00:12:35,820 --> 00:12:37,800
no this is going to happen this year I'm

361
00:12:37,800 --> 00:12:39,200
sure absolutely

362
00:12:39,200 --> 00:12:42,720
along similar lines I I I'll come back

363
00:12:42,720 --> 00:12:44,339
to the corrupted AI models in a bit AI

364
00:12:44,339 --> 00:12:46,079
generated pull requests that are just

365
00:12:46,079 --> 00:12:48,899
right and just wrong enough to DDOS

366
00:12:48,899 --> 00:12:51,240
teams Upstream teams to slow or stop the

367
00:12:51,240 --> 00:12:52,740
reaction when a real zero day is

368
00:12:52,740 --> 00:12:55,260
reported would be a really big risk AI

369
00:12:55,260 --> 00:12:56,579
generated contributors who make

370
00:12:56,579 --> 00:12:58,320
automated like Dock cleanups and things

371
00:12:58,320 --> 00:12:59,639
like that and then build up a repute

372
00:12:59,639 --> 00:13:02,040
station in your project maybe you even

373
00:13:02,040 --> 00:13:04,139
give them admin proves right uh that's

374
00:13:04,139 --> 00:13:06,360
that's that that is a risk as well uh

375
00:13:06,360 --> 00:13:08,040
and then we know that AI models can be

376
00:13:08,040 --> 00:13:09,480
corrupted this is a picture of a stop

377
00:13:09,480 --> 00:13:11,160
sign that some researchers were able to

378
00:13:11,160 --> 00:13:13,800
convince an AI to recognize as a speed

379
00:13:13,800 --> 00:13:16,680
limit 30 sign uh which is a very

380
00:13:16,680 --> 00:13:18,540
different thing than intended and think

381
00:13:18,540 --> 00:13:20,160
about ways that you might corrupt things

382
00:13:20,160 --> 00:13:22,740
like copilot to make its recommendations

383
00:13:22,740 --> 00:13:24,779
lead to insecure software

384
00:13:24,779 --> 00:13:26,160
um a second attack service that I think

385
00:13:26,160 --> 00:13:27,660
is emergent is an identity and

386
00:13:27,660 --> 00:13:29,279
centrality we've not solved the internet

387
00:13:29,279 --> 00:13:31,139
identity problem this by the way is the

388
00:13:31,139 --> 00:13:32,820
other Brian bellendorf he's a maintainer

389
00:13:32,820 --> 00:13:35,220
on opencfs he gets our name and the

390
00:13:35,220 --> 00:13:36,779
Linux kernel change logs he's pretty

391
00:13:36,779 --> 00:13:39,240
cool uh he's uh we've met we've had

392
00:13:39,240 --> 00:13:41,760
pizza uh he's a much better programmer

393
00:13:41,760 --> 00:13:45,899
than I ever have been or will be but you

394
00:13:45,899 --> 00:13:47,639
know if you see my name Brian bellendorf

395
00:13:47,639 --> 00:13:48,779
I know because I get a lot of support

396
00:13:48,779 --> 00:13:50,700
queries for open ZFS that I forward on

397
00:13:50,700 --> 00:13:51,959
to the other Brian bellendorf and it

398
00:13:51,959 --> 00:13:53,339
kind of freaks people out

399
00:13:53,339 --> 00:13:56,220
um but uh uh this kind of thing is real

400
00:13:56,220 --> 00:13:58,019
uh you know the prospect of somebody

401
00:13:58,019 --> 00:13:59,399
showing up pretending to be somebody

402
00:13:59,399 --> 00:14:01,800
else else and being very convincing at

403
00:14:01,800 --> 00:14:03,779
it I think would be would be a real big

404
00:14:03,779 --> 00:14:05,579
factor there's a bunch of others but the

405
00:14:05,579 --> 00:14:07,139
the one I want to focus that's kind of

406
00:14:07,139 --> 00:14:09,360
you know related to this is there's

407
00:14:09,360 --> 00:14:11,220
often these these things that we take

408
00:14:11,220 --> 00:14:13,139
for granted like the accessibility of an

409
00:14:13,139 --> 00:14:16,680
npm package uh repository or apache.org

410
00:14:16,680 --> 00:14:19,260
and resolving dtds uh these kinds of

411
00:14:19,260 --> 00:14:20,760
things that we have to assume in this

412
00:14:20,760 --> 00:14:22,860
world one in a couple of you know orders

413
00:14:22,860 --> 00:14:25,200
of magnitude times uh those systems will

414
00:14:25,200 --> 00:14:26,700
be gone we won't be able to access it

415
00:14:26,700 --> 00:14:29,160
your DNS will fail uh and do you really

416
00:14:29,160 --> 00:14:30,540
want to limit your production push to

417
00:14:30,540 --> 00:14:32,700
production because some non-profits

418
00:14:32,700 --> 00:14:34,800
website is down I kind of don't think so

419
00:14:34,800 --> 00:14:38,160
the third one I'd worry about are free

420
00:14:38,160 --> 00:14:39,839
writers and Regulation and this is kind

421
00:14:39,839 --> 00:14:41,100
of more nuanced than I think I can get

422
00:14:41,100 --> 00:14:43,680
out in the 20 seconds I have left but

423
00:14:43,680 --> 00:14:45,660
um as maintainers we kind of take for

424
00:14:45,660 --> 00:14:47,399
granted that users are on their own and

425
00:14:47,399 --> 00:14:49,199
can be self-sufficient and often we try

426
00:14:49,199 --> 00:14:50,519
to think about them the better ones of

427
00:14:50,519 --> 00:14:52,079
us do you think about how to pull people

428
00:14:52,079 --> 00:14:54,480
in and cross that bridge but users also

429
00:14:54,480 --> 00:14:56,820
free ride on the assumption that as

430
00:14:56,820 --> 00:14:58,980
maintainers we take security issues for

431
00:14:58,980 --> 00:15:01,199
granted and and the number of reported

432
00:15:01,199 --> 00:15:02,639
security vulnerabilities that don't get

433
00:15:02,639 --> 00:15:04,199
responded to by maintainers in a

434
00:15:04,199 --> 00:15:05,459
reasonable amount of time I mean

435
00:15:05,459 --> 00:15:06,899
nobody's formally tracking this and

436
00:15:06,899 --> 00:15:08,459
frankly we probably should and I think

437
00:15:08,459 --> 00:15:10,440
in between the two lies some risk and

438
00:15:10,440 --> 00:15:12,180
that's risk that that can be exploited

439
00:15:12,180 --> 00:15:14,699
by grifters and scammers uh uh and and

440
00:15:14,699 --> 00:15:16,620
the like that I'm not quite sure exactly

441
00:15:16,620 --> 00:15:17,760
what those attacks are going to be but

442
00:15:17,760 --> 00:15:19,320
they're going to happen the second

443
00:15:19,320 --> 00:15:20,880
category of this that I really want to

444
00:15:20,880 --> 00:15:23,040
highlight is there are moves afoot at a

445
00:15:23,040 --> 00:15:25,500
regulatory level to respond to some of

446
00:15:25,500 --> 00:15:27,240
the free writer problems some of these

447
00:15:27,240 --> 00:15:29,760
issues by putting more liability upon

448
00:15:29,760 --> 00:15:31,980
all of you as developers the European

449
00:15:31,980 --> 00:15:35,220
Union's cyber resiliency act has a whole

450
00:15:35,220 --> 00:15:37,199
bunch of worrisome kind of requirements

451
00:15:37,199 --> 00:15:38,940
that might fall on you if your software

452
00:15:38,940 --> 00:15:40,500
happens to be unlucky enough to be used

453
00:15:40,500 --> 00:15:44,399
in a European nuclear plant or or by a

454
00:15:44,399 --> 00:15:46,500
transportation agency this is where a

455
00:15:46,500 --> 00:15:47,820
cement it could get us back to the bad

456
00:15:47,820 --> 00:15:49,680
old days of having to remember what

457
00:15:49,680 --> 00:15:51,120
country you're in to depend upon whether

458
00:15:51,120 --> 00:15:53,100
I can ship code to you or not um the

459
00:15:53,100 --> 00:15:54,480
second wrong answer is to make

460
00:15:54,480 --> 00:15:56,100
developers personally liable for the use

461
00:15:56,100 --> 00:15:57,720
of their software for illegal purposes

462
00:15:57,720 --> 00:16:00,300
uh read up more on the tornado developer

463
00:16:00,300 --> 00:16:01,920
and what's happening there these are not

464
00:16:01,920 --> 00:16:03,740
ways to solve the cyber security problem

465
00:16:03,740 --> 00:16:06,480
but some of the tools will make the

466
00:16:06,480 --> 00:16:08,399
problems inherent in this so much more

467
00:16:08,399 --> 00:16:11,760
severe so at openssf we've got a lot of

468
00:16:11,760 --> 00:16:13,019
activities going on we're kind of a

469
00:16:13,019 --> 00:16:15,000
circus it's really great lots of

470
00:16:15,000 --> 00:16:16,740
different ways to tackle this but we've

471
00:16:16,740 --> 00:16:18,899
organized ourselves around working

472
00:16:18,899 --> 00:16:22,079
groups in a thematic way that uh we

473
00:16:22,079 --> 00:16:23,399
think will prepare us to think

474
00:16:23,399 --> 00:16:24,779
holistically about many of these

475
00:16:24,779 --> 00:16:26,699
challenges to think about vulnerability

476
00:16:26,699 --> 00:16:29,459
disclosure in a long-term way like what

477
00:16:29,459 --> 00:16:31,199
not just how do we how do we write a

478
00:16:31,199 --> 00:16:33,180
tool to solve one problem or come up

479
00:16:33,180 --> 00:16:34,800
with a spec to solve another but think

480
00:16:34,800 --> 00:16:36,120
holistically about the whole supply

481
00:16:36,120 --> 00:16:37,800
chain challenges how do we think about a

482
00:16:37,800 --> 00:16:40,440
digital identity and uh supply chain

483
00:16:40,440 --> 00:16:43,160
Integrity how do we think about uh uh

484
00:16:43,160 --> 00:16:45,360
about all these different kinds of new

485
00:16:45,360 --> 00:16:46,500
forms of attack we don't have a working

486
00:16:46,500 --> 00:16:49,079
group on AI yet maybe chat gbt will

487
00:16:49,079 --> 00:16:51,779
start one for us but I I it's it's I

488
00:16:51,779 --> 00:16:53,040
think we're in a position to be well

489
00:16:53,040 --> 00:16:54,480
prepared to be thinking about this next

490
00:16:54,480 --> 00:16:56,759
wave of attacks and I just want to thank

491
00:16:56,759 --> 00:16:59,100
all of you again uh open ssf happened

492
00:16:59,100 --> 00:17:00,720
because because the cloud native

493
00:17:00,720 --> 00:17:02,100
Community said hey there's a bunch of

494
00:17:02,100 --> 00:17:04,859
tools we should be building and uh and

495
00:17:04,859 --> 00:17:07,079
brought those to the party and shipped

496
00:17:07,079 --> 00:17:09,000
code and shipping code is really all

497
00:17:09,000 --> 00:17:11,099
that matters uh and and for that we have

498
00:17:11,099 --> 00:17:12,599
a debt of gratitude to many of you in

499
00:17:12,599 --> 00:17:14,280
this room and frankly to all of you who

500
00:17:14,280 --> 00:17:15,780
are using these tools now to validate

501
00:17:15,780 --> 00:17:17,280
your work so thank you very much and

502
00:17:17,280 --> 00:17:20,000
have a great conference

