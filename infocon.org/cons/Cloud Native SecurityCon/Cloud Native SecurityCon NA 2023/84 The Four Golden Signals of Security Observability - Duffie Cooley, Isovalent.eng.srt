1
00:00:00,120 --> 00:00:02,100
I guess let's get started my name is

2
00:00:02,100 --> 00:00:03,899
Duffy Cooley I'm the field CTO at eye

3
00:00:03,899 --> 00:00:05,460
surveillance I'm here to talk to you a

4
00:00:05,460 --> 00:00:08,280
little bit today about psyllium grafana

5
00:00:08,280 --> 00:00:11,099
and golden signals I'm actually kind of

6
00:00:11,099 --> 00:00:12,780
curious about the term like if people

7
00:00:12,780 --> 00:00:13,860
understand what I mean by Goldman

8
00:00:13,860 --> 00:00:15,059
signals today like just in

9
00:00:15,059 --> 00:00:16,379
troubleshooting and understanding like

10
00:00:16,379 --> 00:00:17,760
how your applications are behaving and

11
00:00:17,760 --> 00:00:19,500
those sorts of things what do you

12
00:00:19,500 --> 00:00:22,880
consider to be a golden signal

13
00:00:24,000 --> 00:00:25,320
what's that

14
00:00:25,320 --> 00:00:27,060
errors right yeah

15
00:00:27,060 --> 00:00:28,439
there's like there you know there are a

16
00:00:28,439 --> 00:00:29,760
couple competing ones there's like rate

17
00:00:29,760 --> 00:00:31,199
and use and like there's a bunch of

18
00:00:31,199 --> 00:00:32,420
different ways to actually measure

19
00:00:32,420 --> 00:00:34,440
different types of applications or

20
00:00:34,440 --> 00:00:36,719
different types of capabilities that

21
00:00:36,719 --> 00:00:38,280
you're looking at the first thing I'm

22
00:00:38,280 --> 00:00:39,180
going to do is I'm going to do a little

23
00:00:39,180 --> 00:00:42,180
introduction into psyllium and ebpf and

24
00:00:42,180 --> 00:00:43,739
we're going to jump into that and then

25
00:00:43,739 --> 00:00:44,879
we'll talk a little bit about

26
00:00:44,879 --> 00:00:46,500
observability and then I'm going to talk

27
00:00:46,500 --> 00:00:48,899
I'm going to show you some of what we're

28
00:00:48,899 --> 00:00:50,879
doing

29
00:00:50,879 --> 00:00:54,620
with um psyllium

30
00:00:56,520 --> 00:00:57,840
set up here

31
00:00:57,840 --> 00:00:59,699
who who here is already familiar with

32
00:00:59,699 --> 00:01:00,899
psyllium

33
00:01:00,899 --> 00:01:03,180
the open source project I love it how

34
00:01:03,180 --> 00:01:04,559
many people are familiar with the term

35
00:01:04,559 --> 00:01:06,840
evpf

36
00:01:06,840 --> 00:01:08,400
I can't tell if that's actually more or

37
00:01:08,400 --> 00:01:10,020
less but I think I figure I figure it's

38
00:01:10,020 --> 00:01:11,280
about the same

39
00:01:11,280 --> 00:01:13,680
so psyllium is an open source project

40
00:01:13,680 --> 00:01:15,900
it's actually been donated to the cncf

41
00:01:15,900 --> 00:01:17,820
it is I think we're going to try and

42
00:01:17,820 --> 00:01:19,200
graduate this year we'll see how we'll

43
00:01:19,200 --> 00:01:21,119
see how it goes but we're seeing a lot

44
00:01:21,119 --> 00:01:23,820
of really great adoption if you are a

45
00:01:23,820 --> 00:01:25,380
company or represent a company that is

46
00:01:25,380 --> 00:01:26,820
using psyllium and you would like to

47
00:01:26,820 --> 00:01:28,500
participate in that if you go to the

48
00:01:28,500 --> 00:01:31,259
psyllium repo github.com psyllium

49
00:01:31,259 --> 00:01:33,240
psyllium you'll see in a doctor's page

50
00:01:33,240 --> 00:01:34,920
feel free to put in a pull request

51
00:01:34,920 --> 00:01:36,600
saying that you have adopted psyllium

52
00:01:36,600 --> 00:01:37,979
within your infrastructure that'd be

53
00:01:37,979 --> 00:01:39,060
tremendous that would be a tremendous

54
00:01:39,060 --> 00:01:41,540
help for us

55
00:01:42,060 --> 00:01:43,380
um I work for isoville at the company

56
00:01:43,380 --> 00:01:46,500
behind it and primarily we focus on ebpf

57
00:01:46,500 --> 00:01:49,439
and Technologies around it

58
00:01:49,439 --> 00:01:52,200
psyllium is implemented in evpf and to

59
00:01:52,200 --> 00:01:53,939
kind of give you just kind of a sort of

60
00:01:53,939 --> 00:01:56,939
10 000 foot view of what evpf is if you

61
00:01:56,939 --> 00:01:59,040
haven't already kind of thought about it

62
00:01:59,040 --> 00:02:01,680
in this way evpf basically makes the

63
00:02:01,680 --> 00:02:03,299
Linux kernel programmable

64
00:02:03,299 --> 00:02:05,880
and a good way to kind of conceptualize

65
00:02:05,880 --> 00:02:08,340
that in your head is that you can think

66
00:02:08,340 --> 00:02:10,080
of the Linux kernel as having a very

67
00:02:10,080 --> 00:02:12,959
large API surface right and those API

68
00:02:12,959 --> 00:02:15,120
calls can be system calls they can be

69
00:02:15,120 --> 00:02:17,520
socket you know opening a new socket to

70
00:02:17,520 --> 00:02:19,680
another external endpoint all of those

71
00:02:19,680 --> 00:02:21,300
things could be considered API calls

72
00:02:21,300 --> 00:02:23,640
with ebpf we can sit on the other side

73
00:02:23,640 --> 00:02:26,099
of that API call and intercept those

74
00:02:26,099 --> 00:02:29,220
and determine you know like what we can

75
00:02:29,220 --> 00:02:31,260
pull down uh information about like what

76
00:02:31,260 --> 00:02:32,940
that call is happening you said file

77
00:02:32,940 --> 00:02:34,920
open what was the file what file system

78
00:02:34,920 --> 00:02:37,140
was that file part of if you had said

79
00:02:37,140 --> 00:02:39,000
socket open what was the destination

80
00:02:39,000 --> 00:02:40,920
address like where is the traffic headed

81
00:02:40,920 --> 00:02:42,900
to we have a lot more context about

82
00:02:42,900 --> 00:02:44,099
what's actually happening because we're

83
00:02:44,099 --> 00:02:45,540
running right there in the Linux kernel

84
00:02:45,540 --> 00:02:47,220
right after that call has happened we

85
00:02:47,220 --> 00:02:49,019
get notified that an event has happened

86
00:02:49,019 --> 00:02:51,360
and then we can determine like what we

87
00:02:51,360 --> 00:02:53,280
want to do with that information

88
00:02:53,280 --> 00:02:55,800
for the most part people are using ebpf

89
00:02:55,800 --> 00:02:57,840
to do things like observability being

90
00:02:57,840 --> 00:03:01,379
able to you know instrumenting function

91
00:03:01,379 --> 00:03:03,060
calls or system calls in the Linux

92
00:03:03,060 --> 00:03:04,620
kernel and then persisting that

93
00:03:04,620 --> 00:03:06,540
information down into user space so that

94
00:03:06,540 --> 00:03:08,459
you can see like what's actually

95
00:03:08,459 --> 00:03:10,319
happening when your application is doing

96
00:03:10,319 --> 00:03:13,680
stuff against Linux kernel

97
00:03:13,680 --> 00:03:15,300
foreign

98
00:03:15,300 --> 00:03:18,000
but as in this diagram as this time

99
00:03:18,000 --> 00:03:20,099
describes there's actually a ton of

100
00:03:20,099 --> 00:03:22,379
different places and parts inside the

101
00:03:22,379 --> 00:03:24,180
kernel that we can hook into right we

102
00:03:24,180 --> 00:03:26,280
can hook into any system call that's

103
00:03:26,280 --> 00:03:28,260
making access that has access to the

104
00:03:28,260 --> 00:03:30,420
file system we can hook into network

105
00:03:30,420 --> 00:03:33,120
interface carts with xtp we can hook

106
00:03:33,120 --> 00:03:35,099
into basically just a regular socket

107
00:03:35,099 --> 00:03:37,140
call and all those sorts of things and

108
00:03:37,140 --> 00:03:38,519
when we hook into those things we have

109
00:03:38,519 --> 00:03:40,080
the choice of basically just reporting

110
00:03:40,080 --> 00:03:41,099
what we found

111
00:03:41,099 --> 00:03:43,080
or you know providing context about

112
00:03:43,080 --> 00:03:44,519
what's actually happening in the Linux

113
00:03:44,519 --> 00:03:46,140
kernel or we can actually also make

114
00:03:46,140 --> 00:03:48,299
changes which is one of the things that

115
00:03:48,299 --> 00:03:50,780
we do with psyllium

116
00:03:50,780 --> 00:03:53,220
so with psyllium

117
00:03:53,220 --> 00:03:55,739
where a cni primarily right so if you're

118
00:03:55,739 --> 00:03:58,200
using a kubernetes as your container

119
00:03:58,200 --> 00:04:00,000
orchestration system you can use

120
00:04:00,000 --> 00:04:03,239
psyllium as the cni piece of it now a

121
00:04:03,239 --> 00:04:04,500
cni is a container networking

122
00:04:04,500 --> 00:04:06,599
implementation and its goal is to

123
00:04:06,599 --> 00:04:08,700
basically provide networking for all of

124
00:04:08,700 --> 00:04:10,260
the pods and all the different workloads

125
00:04:10,260 --> 00:04:11,879
that you deploy into into your

126
00:04:11,879 --> 00:04:14,840
kubernetes environment

127
00:04:15,180 --> 00:04:16,738
psyllium does a lot more than that since

128
00:04:16,738 --> 00:04:18,238
we're actually again instrumenting

129
00:04:18,238 --> 00:04:20,459
inside of the Linux kernel using ebpf we

130
00:04:20,459 --> 00:04:23,460
can do things like replace Cube proxy

131
00:04:23,460 --> 00:04:24,960
and we could do that by basically

132
00:04:24,960 --> 00:04:26,880
writing an ebpf program for every

133
00:04:26,880 --> 00:04:29,720
workload that you have on every node and

134
00:04:29,720 --> 00:04:31,800
determining exactly like what the world

135
00:04:31,800 --> 00:04:33,060
should look like from the networking

136
00:04:33,060 --> 00:04:35,580
perspective and when we see a new

137
00:04:35,580 --> 00:04:37,320
network call come in we've seen that

138
00:04:37,320 --> 00:04:39,180
second that socket call come in right

139
00:04:39,180 --> 00:04:41,580
this application is trying to make a

140
00:04:41,580 --> 00:04:43,979
connection to a kubernetes service

141
00:04:43,979 --> 00:04:46,080
just like you would in iptables we can

142
00:04:46,080 --> 00:04:47,699
actually intercept that call we can say

143
00:04:47,699 --> 00:04:50,400
hey this is going to a service I

144
00:04:50,400 --> 00:04:51,960
understand the healthy endpoints behind

145
00:04:51,960 --> 00:04:54,780
that service I can actually do Nat right

146
00:04:54,780 --> 00:04:56,580
there in an ebpf program running

147
00:04:56,580 --> 00:04:59,400
natively in the Linux kernel and

148
00:04:59,400 --> 00:05:01,620
determine what healthy endpoint I want

149
00:05:01,620 --> 00:05:03,479
to route that traffic to manipulate the

150
00:05:03,479 --> 00:05:06,360
packet before it actually proceeds

151
00:05:06,360 --> 00:05:07,800
and then when that packet comes down

152
00:05:07,800 --> 00:05:09,660
into the routing layer on the underlying

153
00:05:09,660 --> 00:05:12,180
host the NAT has already happened

154
00:05:12,180 --> 00:05:13,800
right so we're not even we're not using

155
00:05:13,800 --> 00:05:16,020
IP tables for net we're not using ipvs

156
00:05:16,020 --> 00:05:17,820
for Nat we're able to do Nat directly in

157
00:05:17,820 --> 00:05:20,460
evpf

158
00:05:20,460 --> 00:05:23,000
pretty wild

159
00:05:23,340 --> 00:05:25,380
and of course this also gives us kind of

160
00:05:25,380 --> 00:05:27,300
unprecedented visibility

161
00:05:27,300 --> 00:05:29,580
right we're able to persist down into

162
00:05:29,580 --> 00:05:31,979
down into user space effectively that

163
00:05:31,979 --> 00:05:34,440
event stream that describes what

164
00:05:34,440 --> 00:05:36,120
applications are connecting to what

165
00:05:36,120 --> 00:05:38,220
other applications and how and whether

166
00:05:38,220 --> 00:05:39,960
that was allowed or denied and whether

167
00:05:39,960 --> 00:05:41,940
there was a network policy decision

168
00:05:41,940 --> 00:05:45,600
about it or whether there was not

169
00:05:45,600 --> 00:05:48,000
so there's tons there's tons of tons of

170
00:05:48,000 --> 00:05:49,259
stuff that we're doing with psyllium to

171
00:05:49,259 --> 00:05:52,580
kind of solve these problems

172
00:05:53,220 --> 00:05:56,160
we are um again kind of if anywhere you

173
00:05:56,160 --> 00:05:58,380
can run kubernetes you can run psyllium

174
00:05:58,380 --> 00:06:00,660
Azure cni we have great Integrations

175
00:06:00,660 --> 00:06:02,820
with different Cloud providers including

176
00:06:02,820 --> 00:06:05,820
Google Cloud their new data plane V2 is

177
00:06:05,820 --> 00:06:08,100
psyllium based we're working on we're

178
00:06:08,100 --> 00:06:09,419
working on a great partnership with

179
00:06:09,419 --> 00:06:11,780
Azure where they're actually

180
00:06:11,780 --> 00:06:14,520
allow allowing for new AKs clusters to

181
00:06:14,520 --> 00:06:16,020
be created today like if you were to

182
00:06:16,020 --> 00:06:17,820
create an AKs cluster right now you'd be

183
00:06:17,820 --> 00:06:19,259
how you would have the option of using

184
00:06:19,259 --> 00:06:22,020
psyllium as the data plane

185
00:06:22,020 --> 00:06:24,240
um we have a similar thing with AWS if

186
00:06:24,240 --> 00:06:27,060
you're using aws's eks anywhere we are

187
00:06:27,060 --> 00:06:31,020
the underlying cni choice for that

188
00:06:31,020 --> 00:06:33,720
so it's pretty widely adopted and these

189
00:06:33,720 --> 00:06:35,100
are kind of the areas that we've been

190
00:06:35,100 --> 00:06:37,080
focusing the product on

191
00:06:37,080 --> 00:06:39,060
um in general

192
00:06:39,060 --> 00:06:40,919
so we've been like you've heard me talk

193
00:06:40,919 --> 00:06:42,300
a lot about the networking piece there's

194
00:06:42,300 --> 00:06:43,620
a lot more to talk about in the

195
00:06:43,620 --> 00:06:45,120
networking piece I'm not here to talk a

196
00:06:45,120 --> 00:06:47,280
lot about that today but some of the

197
00:06:47,280 --> 00:06:48,479
pieces that I do want to share with you

198
00:06:48,479 --> 00:06:49,800
are what we're doing with like Hubble

199
00:06:49,800 --> 00:06:51,419
observability and specifically what

200
00:06:51,419 --> 00:06:54,180
we're doing with service mesh

201
00:06:54,180 --> 00:06:56,100
one of the things that we've been uh

202
00:06:56,100 --> 00:06:58,319
doing forever I mean if you've ever used

203
00:06:58,319 --> 00:07:00,120
psyllium and you've ever explored Hubble

204
00:07:00,120 --> 00:07:03,000
he realized that we've kind of provided

205
00:07:03,000 --> 00:07:04,319
you insight into what's actually

206
00:07:04,319 --> 00:07:05,819
happening at the network layer for quite

207
00:07:05,819 --> 00:07:07,979
a long time and we expose that Insight

208
00:07:07,979 --> 00:07:11,160
in the form of metrics or in the form of

209
00:07:11,160 --> 00:07:13,199
the um

210
00:07:13,199 --> 00:07:14,880
capability that lets you see what's

211
00:07:14,880 --> 00:07:16,979
actually happening

212
00:07:16,979 --> 00:07:19,759
at the application layer

213
00:07:19,759 --> 00:07:22,199
but what we haven't done is we haven't

214
00:07:22,199 --> 00:07:24,180
actually exposed all of those metrics

215
00:07:24,180 --> 00:07:26,880
and all of those things in a way that a

216
00:07:26,880 --> 00:07:29,460
service mesh does for the most part when

217
00:07:29,460 --> 00:07:31,440
people think of golden signals they

218
00:07:31,440 --> 00:07:33,539
think of I want to be able to instrument

219
00:07:33,539 --> 00:07:35,940
map instrument my application in such a

220
00:07:35,940 --> 00:07:37,919
way that I can understand for the last

221
00:07:37,919 --> 00:07:39,840
you know much traffic that went through

222
00:07:39,840 --> 00:07:42,360
from this app from this application how

223
00:07:42,360 --> 00:07:44,400
many of the HTTP requests from this

224
00:07:44,400 --> 00:07:46,020
application to some dependent service

225
00:07:46,020 --> 00:07:49,380
return to 200 how many returned 503 how

226
00:07:49,380 --> 00:07:50,940
many returned like particular HTTP

227
00:07:50,940 --> 00:07:52,139
status codes

228
00:07:52,139 --> 00:07:55,139
or if we move it to like the TCP State I

229
00:07:55,139 --> 00:07:57,780
want to know you know like how many um

230
00:07:57,780 --> 00:07:59,340
how many connections are going through

231
00:07:59,340 --> 00:08:01,080
what's the rate or the utilization of

232
00:08:01,080 --> 00:08:02,699
that link are there any errors

233
00:08:02,699 --> 00:08:05,220
associated with that link right these

234
00:08:05,220 --> 00:08:06,419
are the golden metrics that we've been

235
00:08:06,419 --> 00:08:07,979
talking about and we've been surfacing

236
00:08:07,979 --> 00:08:09,599
that information for quite a long time

237
00:08:09,599 --> 00:08:11,819
but we haven't actually presented it in

238
00:08:11,819 --> 00:08:13,800
the way that a service mesh does

239
00:08:13,800 --> 00:08:15,780
what we're doing now and what we have

240
00:08:15,780 --> 00:08:18,479
what we have shipped as part of 1.12 is

241
00:08:18,479 --> 00:08:20,340
the ability to actually see the same

242
00:08:20,340 --> 00:08:22,319
metrics in that in that way

243
00:08:22,319 --> 00:08:24,419
so it makes it really great for solving

244
00:08:24,419 --> 00:08:26,160
the observability use cases or the

245
00:08:26,160 --> 00:08:28,979
challenges that we see in

246
00:08:28,979 --> 00:08:32,039
just by leveraging psyllium cni and

247
00:08:32,039 --> 00:08:33,899
Hubble Enterprise or a Hubble I should

248
00:08:33,899 --> 00:08:35,640
say tetragram psyllium and tetragon

249
00:08:35,640 --> 00:08:37,080
together can actually give you all of

250
00:08:37,080 --> 00:08:39,560
that data

251
00:08:40,979 --> 00:08:43,559
so again kind of this is just sort of a

252
00:08:43,559 --> 00:08:45,779
way of describing like where some of the

253
00:08:45,779 --> 00:08:47,399
other existing mechanisms are sort of

254
00:08:47,399 --> 00:08:50,339
sort of falling short when

255
00:08:50,339 --> 00:08:52,200
faced or confronted with this Cloud

256
00:08:52,200 --> 00:08:53,459
native environment

257
00:08:53,459 --> 00:08:55,980
a lot of the kind of standard existing

258
00:08:55,980 --> 00:08:58,140
solutions kind of focus on like a five

259
00:08:58,140 --> 00:09:00,420
Tuple sort of use case where you have

260
00:09:00,420 --> 00:09:01,920
the source address the source Mac

261
00:09:01,920 --> 00:09:03,660
address the destination address the

262
00:09:03,660 --> 00:09:05,580
destination Mac address and like the

263
00:09:05,580 --> 00:09:06,959
direction of the traffic or like what

264
00:09:06,959 --> 00:09:09,000
the protocol of that traffic is

265
00:09:09,000 --> 00:09:10,920
a lot of those things are I mean those

266
00:09:10,920 --> 00:09:12,120
things are useful when you think about

267
00:09:12,120 --> 00:09:13,920
like troubleshooting a specific link

268
00:09:13,920 --> 00:09:16,080
between two points but when you're

269
00:09:16,080 --> 00:09:17,580
trying to actually understand this

270
00:09:17,580 --> 00:09:19,380
what's actually happening in this age of

271
00:09:19,380 --> 00:09:20,700
distributed systems you need a little

272
00:09:20,700 --> 00:09:22,380
more context than that right you need to

273
00:09:22,380 --> 00:09:24,360
understand it with this POD at this time

274
00:09:24,360 --> 00:09:26,640
or this workload talking to this

275
00:09:26,640 --> 00:09:29,420
external fqdn this was the actual

276
00:09:29,420 --> 00:09:31,800
connection that was being made and I

277
00:09:31,800 --> 00:09:33,480
don't have a lot more information about

278
00:09:33,480 --> 00:09:35,220
what's actually whether that was allowed

279
00:09:35,220 --> 00:09:37,440
or denied and a lot more context about

280
00:09:37,440 --> 00:09:40,339
what's actually happening

281
00:09:41,399 --> 00:09:43,080
and that's primarily what we've been

282
00:09:43,080 --> 00:09:44,880
focusing on being able to really kind of

283
00:09:44,880 --> 00:09:46,740
make everything identity based being

284
00:09:46,740 --> 00:09:48,480
able to give you a really good view into

285
00:09:48,480 --> 00:09:50,100
what's actually

286
00:09:50,100 --> 00:09:51,600
um

287
00:09:51,600 --> 00:09:53,760
being presented

288
00:09:53,760 --> 00:09:55,200
or what's actually happening at that

289
00:09:55,200 --> 00:09:57,180
Network layer in a way that you can

290
00:09:57,180 --> 00:09:59,760
easily understand and make use and

291
00:09:59,760 --> 00:10:02,640
and use to troubleshoot or understand or

292
00:10:02,640 --> 00:10:05,480
what's happening there

293
00:10:05,480 --> 00:10:07,920
so you've heard me mention Hubble Hubble

294
00:10:07,920 --> 00:10:11,279
is a suite of tools Hubble is a CLI that

295
00:10:11,279 --> 00:10:12,959
lets you actually investigate what's

296
00:10:12,959 --> 00:10:15,240
actually happening at the at the network

297
00:10:15,240 --> 00:10:18,360
layer and an analog Hubble it's

298
00:10:18,360 --> 00:10:20,880
basically the ability to understand

299
00:10:20,880 --> 00:10:21,959
um

300
00:10:21,959 --> 00:10:24,060
what's you know it's people think

301
00:10:24,060 --> 00:10:26,220
frequently when they see Hubble they

302
00:10:26,220 --> 00:10:28,440
think oh this is like TCB dump right

303
00:10:28,440 --> 00:10:31,440
because I'm able to see the source a

304
00:10:31,440 --> 00:10:33,240
workload and I'm able to see traffic

305
00:10:33,240 --> 00:10:35,100
going from that Source workload to a

306
00:10:35,100 --> 00:10:37,440
destination maybe to the DNS server or

307
00:10:37,440 --> 00:10:39,300
maybe to another workload

308
00:10:39,300 --> 00:10:41,580
this is kind of like TCP dump what's

309
00:10:41,580 --> 00:10:43,980
amazing though is that this is not a

310
00:10:43,980 --> 00:10:47,339
view that looks at two particular points

311
00:10:47,339 --> 00:10:49,800
this is a view showing you like the

312
00:10:49,800 --> 00:10:51,120
context of what's happening on the

313
00:10:51,120 --> 00:10:53,940
network across the entire cluster across

314
00:10:53,940 --> 00:10:55,680
all of their clothes and you're

315
00:10:55,680 --> 00:10:57,240
filtering all of that information down

316
00:10:57,240 --> 00:10:58,680
to only those things that you actually

317
00:10:58,680 --> 00:11:00,180
are interested in troubleshooting at

318
00:11:00,180 --> 00:11:01,079
this time

319
00:11:01,079 --> 00:11:03,959
but do you have effectively TCP dump

320
00:11:03,959 --> 00:11:06,540
across all workloads across all nodes

321
00:11:06,540 --> 00:11:08,700
across all traffic moving back and forth

322
00:11:08,700 --> 00:11:10,160
between

323
00:11:10,160 --> 00:11:12,480
any workloads within your kubernetes

324
00:11:12,480 --> 00:11:14,040
cluster and if you were to do something

325
00:11:14,040 --> 00:11:15,360
like cluster mesh where you can actually

326
00:11:15,360 --> 00:11:17,220
join multiple clusters together then

327
00:11:17,220 --> 00:11:19,019
you'd have that you could expand that

328
00:11:19,019 --> 00:11:21,480
domain to understand all connectivity

329
00:11:21,480 --> 00:11:24,839
between all of the Clusters it's kind of

330
00:11:24,839 --> 00:11:26,959
wild

331
00:11:27,060 --> 00:11:30,180
so it's TCB dump but you know Galaxy

332
00:11:30,180 --> 00:11:32,940
brain TCP dump

333
00:11:32,940 --> 00:11:35,279
which is pretty cool

334
00:11:35,279 --> 00:11:36,839
and what we're doing

335
00:11:36,839 --> 00:11:38,399
um and what we're working and this is

336
00:11:38,399 --> 00:11:40,560
the uiver component of it so instead of

337
00:11:40,560 --> 00:11:42,000
actually treating it like a effectively

338
00:11:42,000 --> 00:11:45,000
a searchable searchable event stream of

339
00:11:45,000 --> 00:11:46,140
what's actually happening on the network

340
00:11:46,140 --> 00:11:48,000
layer we can also give you visualization

341
00:11:48,000 --> 00:11:50,220
tools right describe what ports are

342
00:11:50,220 --> 00:11:52,740
being you know what our clothes are

343
00:11:52,740 --> 00:11:54,540
dependent on other workloads what

344
00:11:54,540 --> 00:11:55,920
traffic is moving back and forth between

345
00:11:55,920 --> 00:11:57,720
those things

346
00:11:57,720 --> 00:11:59,339
whether that traffic was allowed or

347
00:11:59,339 --> 00:12:00,779
denied what the identity of that traffic

348
00:12:00,779 --> 00:12:01,620
is

349
00:12:01,620 --> 00:12:03,420
all that information is available to you

350
00:12:03,420 --> 00:12:06,019
in the UI

351
00:12:11,040 --> 00:12:13,140
so moving on like this is again kind of

352
00:12:13,140 --> 00:12:14,700
like how we think of the world right

353
00:12:14,700 --> 00:12:17,339
this is how we fit into that puzzle so

354
00:12:17,339 --> 00:12:19,440
when a connect call an application or a

355
00:12:19,440 --> 00:12:20,640
workload within your kubernetes

356
00:12:20,640 --> 00:12:22,500
environment or even on an external VM

357
00:12:22,500 --> 00:12:24,839
makes a connect call we're able to

358
00:12:24,839 --> 00:12:27,060
actually start immediately and determine

359
00:12:27,060 --> 00:12:29,459
exactly a number of a number of really

360
00:12:29,459 --> 00:12:31,200
interesting pieces of information right

361
00:12:31,200 --> 00:12:33,240
we can say this connect call has

362
00:12:33,240 --> 00:12:35,279
happened do we want to allow or deny

363
00:12:35,279 --> 00:12:37,079
that traffic even before it becomes a

364
00:12:37,079 --> 00:12:39,360
packet right even if this isn't about

365
00:12:39,360 --> 00:12:41,640
packets per second this is like when we

366
00:12:41,640 --> 00:12:43,440
see that socket call happen

367
00:12:43,440 --> 00:12:45,420
do we want to allow that traffic to

368
00:12:45,420 --> 00:12:47,100
egress that workload

369
00:12:47,100 --> 00:12:49,320
before it even hits the wire

370
00:12:49,320 --> 00:12:51,000
we can make that decision that Network

371
00:12:51,000 --> 00:12:53,040
policy decision before it even before it

372
00:12:53,040 --> 00:12:54,300
proceeds from the socket call

373
00:12:54,300 --> 00:12:55,500
perspective

374
00:12:55,500 --> 00:12:57,000
we can also make a decision about

375
00:12:57,000 --> 00:12:58,740
whether you know this traffic is

376
00:12:58,740 --> 00:13:00,120
actually going to call from one

377
00:13:00,120 --> 00:13:02,100
application it's going over localhost to

378
00:13:02,100 --> 00:13:03,959
another application in another container

379
00:13:03,959 --> 00:13:06,060
in that within the same pod

380
00:13:06,060 --> 00:13:07,920
we could do socket layer load balancing

381
00:13:07,920 --> 00:13:10,139
and allow for very fast path connections

382
00:13:10,139 --> 00:13:12,720
between two applications within the same

383
00:13:12,720 --> 00:13:13,920
so you wouldn't have to actually

384
00:13:13,920 --> 00:13:16,560
Traverse the TCP stack across localhost

385
00:13:16,560 --> 00:13:18,420
to do it right we would allow the

386
00:13:18,420 --> 00:13:19,800
connection to become established and we

387
00:13:19,800 --> 00:13:20,880
could actually just shortcut that

388
00:13:20,880 --> 00:13:23,100
traffic between those two processes

389
00:13:23,100 --> 00:13:24,660
again because we're operating at the

390
00:13:24,660 --> 00:13:26,700
kernel layer pretty amazing stuff

391
00:13:26,700 --> 00:13:29,399
and then finally the observability piece

392
00:13:29,399 --> 00:13:33,440
can actually be extended Beyond what's

