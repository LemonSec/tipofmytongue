1
00:00:00,120 --> 00:00:02,280
awesome hey everyone I'm Jeremy I'm a

2
00:00:02,280 --> 00:00:03,959
technical product marketer at Optics and

3
00:00:03,959 --> 00:00:04,860
I'm really excited to talk to you all

4
00:00:04,860 --> 00:00:06,000
today so I'm going to be talking about

5
00:00:06,000 --> 00:00:08,580
securing the CI CD Pipeline and kind of

6
00:00:08,580 --> 00:00:10,080
really the special place that developer

7
00:00:10,080 --> 00:00:11,960
laptops have from a security perspective

8
00:00:11,960 --> 00:00:14,099
so I really only have two things to talk

9
00:00:14,099 --> 00:00:16,020
to you guys about first I want to take a

10
00:00:16,020 --> 00:00:18,600
look at a traditional CI CD Pipeline and

11
00:00:18,600 --> 00:00:20,160
really break down some of the data silos

12
00:00:20,160 --> 00:00:21,720
and security gaps that we create for

13
00:00:21,720 --> 00:00:23,340
ourselves there and then I want to dive

14
00:00:23,340 --> 00:00:25,019
a little deeper to security at the

15
00:00:25,019 --> 00:00:27,240
developer laptop so on the right I

16
00:00:27,240 --> 00:00:28,619
including a fun headline that grabbed me

17
00:00:28,619 --> 00:00:29,699
from about a month ago it's pretty

18
00:00:29,699 --> 00:00:31,920
prevalent for this talk so LastPass got

19
00:00:31,920 --> 00:00:34,020
hacked and hackers had access to the

20
00:00:34,020 --> 00:00:35,579
development environment for over four

21
00:00:35,579 --> 00:00:36,960
days so Andrew was touching on this

22
00:00:36,960 --> 00:00:38,880
earlier when he gave the opening remarks

23
00:00:38,880 --> 00:00:40,620
but kind of keep in mind that idea of

24
00:00:40,620 --> 00:00:42,059
software supply chain attacks and

25
00:00:42,059 --> 00:00:43,920
attackers embedding themselves into your

26
00:00:43,920 --> 00:00:46,680
development pipeline

27
00:00:46,680 --> 00:00:48,840
so yeah this is kind of the Innovation

28
00:00:48,840 --> 00:00:51,480
pipeline or traditional CI CD pipeline

29
00:00:51,480 --> 00:00:52,739
as we see it you know on the far left

30
00:00:52,739 --> 00:00:54,539
you have that development stage you have

31
00:00:54,539 --> 00:00:56,940
developers working off laptops crafting

32
00:00:56,940 --> 00:00:58,559
the crown jewels of your organization

33
00:00:58,559 --> 00:00:59,879
really building that intellectual

34
00:00:59,879 --> 00:01:02,219
property you move into the CI CD stage

35
00:01:02,219 --> 00:01:03,600
you maybe have a build server you're

36
00:01:03,600 --> 00:01:05,220
scanning images you're testing for

37
00:01:05,220 --> 00:01:07,560
compliance vulnerabilities registry

38
00:01:07,560 --> 00:01:09,180
scanning maybe secret scanning as well

39
00:01:09,180 --> 00:01:11,340
and then we hit runtime and in runtime

40
00:01:11,340 --> 00:01:13,320
we kind of split this up into two phases

41
00:01:13,320 --> 00:01:15,000
we have the control plane layer of that

42
00:01:15,000 --> 00:01:17,280
orchestration and runtime services and

43
00:01:17,280 --> 00:01:18,540
then you have the data layer of those

44
00:01:18,540 --> 00:01:21,060
actual running nodes and containers and

45
00:01:21,060 --> 00:01:22,200
I want to reiterate what I said on the

46
00:01:22,200 --> 00:01:23,640
last side where let's look at this and

47
00:01:23,640 --> 00:01:25,140
let's see some of the data silos and

48
00:01:25,140 --> 00:01:27,479
security gaps we create for ourselves so

49
00:01:27,479 --> 00:01:29,040
let's take runtime for example and

50
00:01:29,040 --> 00:01:30,420
runtime you have this control plane

51
00:01:30,420 --> 00:01:32,400
layer in this data plane layer and at

52
00:01:32,400 --> 00:01:33,960
the control plane layer you have you

53
00:01:33,960 --> 00:01:35,939
know runtime orchestration you're doing

54
00:01:35,939 --> 00:01:37,799
compliance you're doing maybe Network

55
00:01:37,799 --> 00:01:39,780
policy as well and at the data point

56
00:01:39,780 --> 00:01:41,400
layer you have this Rich socket event

57
00:01:41,400 --> 00:01:43,619
and process event data but teams right

58
00:01:43,619 --> 00:01:44,700
now are really struggling with

59
00:01:44,700 --> 00:01:46,439
correlating this data together or

60
00:01:46,439 --> 00:01:48,240
correlating this data from say the data

61
00:01:48,240 --> 00:01:50,159
plane back to your backend

62
00:01:50,159 --> 00:01:51,659
infrastructure and this is a problem

63
00:01:51,659 --> 00:01:53,340
let's imagine you know like a container

64
00:01:53,340 --> 00:01:55,439
Escape attack pretty high profile your

65
00:01:55,439 --> 00:01:57,299
node gets compromised they're trying to

66
00:01:57,299 --> 00:01:58,619
hop to another container they're trying

67
00:01:58,619 --> 00:02:00,180
to hop to another node maybe they're

68
00:02:00,180 --> 00:02:01,680
trying to hop to the control plane or to

69
00:02:01,680 --> 00:02:04,020
your AWS infrastructure are you able to

70
00:02:04,020 --> 00:02:06,180
correlate this data back together and I

71
00:02:06,180 --> 00:02:07,200
think that's the big question right now

72
00:02:07,200 --> 00:02:09,479
is that attackers don't think in silos

73
00:02:09,479 --> 00:02:11,459
and we need to be sure that we're

74
00:02:11,459 --> 00:02:13,800
securing across the CI CD pipeline so

75
00:02:13,800 --> 00:02:14,879
that way we're not creating these

76
00:02:14,879 --> 00:02:16,200
security gaps and we're able to

77
00:02:16,200 --> 00:02:18,480
correlate data together so kind of with

78
00:02:18,480 --> 00:02:19,860
that in mind I want to dive a little

79
00:02:19,860 --> 00:02:22,140
deeper into security at the developer

80
00:02:22,140 --> 00:02:23,400
laptop

81
00:02:23,400 --> 00:02:25,800
my security at the developer laptop well

82
00:02:25,800 --> 00:02:28,080
first off we've actually seen first hand

83
00:02:28,080 --> 00:02:31,140
a rise in a attacker's targeting

84
00:02:31,140 --> 00:02:33,300
developer laptops and I think that's for

85
00:02:33,300 --> 00:02:34,560
a few reasons but one of the main ones

86
00:02:34,560 --> 00:02:35,819
is this is just a really high value

87
00:02:35,819 --> 00:02:38,220
Asset you know I think too often we

88
00:02:38,220 --> 00:02:40,319
focus on the the shiny part of the hack

89
00:02:40,319 --> 00:02:42,840
where data gets exfiltrated or remote

90
00:02:42,840 --> 00:02:45,120
code gets executed and I think we need

91
00:02:45,120 --> 00:02:46,860
to look a little layer deeper you know

92
00:02:46,860 --> 00:02:48,900
imagine a developer laptop is like the

93
00:02:48,900 --> 00:02:51,180
perfect entry point for an attacker they

94
00:02:51,180 --> 00:02:53,099
can enumerate your environment they can

95
00:02:53,099 --> 00:02:54,660
see what tooling you have they can try

96
00:02:54,660 --> 00:02:56,700
and steal get SSH keys they can try and

97
00:02:56,700 --> 00:02:59,640
steal AWS credentials so this is just a

98
00:02:59,640 --> 00:03:00,959
really strong point that we need to

99
00:03:00,959 --> 00:03:02,879
secure when we think holistically about

100
00:03:02,879 --> 00:03:05,160
our pipeline so on the right here I

101
00:03:05,160 --> 00:03:06,720
including some of the the fun examples

102
00:03:06,720 --> 00:03:08,099
that customers have been coming to us to

103
00:03:08,099 --> 00:03:10,080
help solve this this problem of security

104
00:03:10,080 --> 00:03:12,120
at the developer laptop

105
00:03:12,120 --> 00:03:14,040
so I'll go through them now the first

106
00:03:14,040 --> 00:03:15,840
one this one's pretty fun auditing for

107
00:03:15,840 --> 00:03:17,159
vulnerable software packages or

108
00:03:17,159 --> 00:03:18,900
malicious Chrome extensions we have some

109
00:03:18,900 --> 00:03:20,280
really fun War stories around Chrome

110
00:03:20,280 --> 00:03:21,540
extensions and malicious Chrome

111
00:03:21,540 --> 00:03:24,060
extensions so folks will attackers will

112
00:03:24,060 --> 00:03:26,099
actually clone real Chrome extensions

113
00:03:26,099 --> 00:03:27,959
put them on the store and try to entice

114
00:03:27,959 --> 00:03:29,879
and like Spearfish specific developers

115
00:03:29,879 --> 00:03:31,200
to try and download these Chrome

116
00:03:31,200 --> 00:03:33,000
extensions onto their developer laptops

117
00:03:33,000 --> 00:03:34,800
so some really fun stuff happy to talk

118
00:03:34,800 --> 00:03:36,000
about it more after I can't share all

119
00:03:36,000 --> 00:03:38,220
right now but number two Dynamic trust

120
00:03:38,220 --> 00:03:40,739
scores for zero trust access so this is

121
00:03:40,739 --> 00:03:42,560
a really good one we know in real time

122
00:03:42,560 --> 00:03:46,019
dynamically quickly assigning uh zero

123
00:03:46,019 --> 00:03:47,879
trust scores so being able to assess the

124
00:03:47,879 --> 00:03:49,739
identity and health of a developer's

125
00:03:49,739 --> 00:03:52,319
laptop as it's trying to access critical

126
00:03:52,319 --> 00:03:54,599
resources or infrastructure and for me

127
00:03:54,599 --> 00:03:56,940
this is a really big one because it goes

128
00:03:56,940 --> 00:03:58,500
back to that idea of security should

129
00:03:58,500 --> 00:04:00,900
really enable our development teams you

130
00:04:00,900 --> 00:04:02,220
know too often we hear about security

131
00:04:02,220 --> 00:04:04,260
roadblocks and I think zero trust access

132
00:04:04,260 --> 00:04:05,760
is a really fun one where we can break

133
00:04:05,760 --> 00:04:07,500
down those roadblocks and really enable

134
00:04:07,500 --> 00:04:10,080
teams to work from these untrusted or

135
00:04:10,080 --> 00:04:11,580
lightly secured home networks around the

136
00:04:11,580 --> 00:04:13,200
world as everyone works remotely

137
00:04:13,200 --> 00:04:15,659
nowadays and then finally detecting and

138
00:04:15,659 --> 00:04:17,220
protecting against malicious behavior

139
00:04:17,220 --> 00:04:19,260
and this really synthesizes so much of

140
00:04:19,260 --> 00:04:20,699
the talk you know go back to that last

141
00:04:20,699 --> 00:04:23,160
past example of hackers having access to

142
00:04:23,160 --> 00:04:24,919
the environment for over four days or

143
00:04:24,919 --> 00:04:27,300
maybe two years ago the solar wind

144
00:04:27,300 --> 00:04:29,040
Sunburst attack

145
00:04:29,040 --> 00:04:30,479
those of you who are familiar with the

146
00:04:30,479 --> 00:04:31,860
the solar winds attack also will

147
00:04:31,860 --> 00:04:34,139
remember that was actually a software

148
00:04:34,139 --> 00:04:36,000
supply chain attack which goes back to

149
00:04:36,000 --> 00:04:38,160
Andrew's point and you know attackers

150
00:04:38,160 --> 00:04:40,680
embedded malicious code into the build

151
00:04:40,680 --> 00:04:43,440
the build got distributed out and then

152
00:04:43,440 --> 00:04:45,540
attackers actually executed the code so

153
00:04:45,540 --> 00:04:47,280
keeping all of that in mind I want to

154
00:04:47,280 --> 00:04:48,300
say thank you so much I want to

155
00:04:48,300 --> 00:04:52,199
reiterate two points first attackers

156
00:04:52,199 --> 00:04:54,479
don't think in silos and that's why we

157
00:04:54,479 --> 00:04:56,100
really need to normalize and correlate

158
00:04:56,100 --> 00:04:58,080
data regardless of whether it starts in

159
00:04:58,080 --> 00:05:00,180
that development section that runtime

160
00:05:00,180 --> 00:05:02,820
control plane layer or that data layer

161
00:05:02,820 --> 00:05:04,620
and then my second point is really

162
00:05:04,620 --> 00:05:06,840
bringing laptops into the fold and

163
00:05:06,840 --> 00:05:08,520
enabling our developers through good

164
00:05:08,520 --> 00:05:10,860
security so that's all I had had for you

165
00:05:10,860 --> 00:05:12,180
today if any of this resonated with you

166
00:05:12,180 --> 00:05:13,860
definitely come find me after even

167
00:05:13,860 --> 00:05:15,120
better actually if any of this didn't

168
00:05:15,120 --> 00:05:17,100
resonate with you uh come find me after

169
00:05:17,100 --> 00:05:18,360
you know that's why we're all here is to

170
00:05:18,360 --> 00:05:20,460
have these fun conversations so upticks

171
00:05:20,460 --> 00:05:23,280
will be at booth number G29 and we'll be

172
00:05:23,280 --> 00:05:24,720
around all week in the purple shirt so

173
00:05:24,720 --> 00:05:26,699
come say hi thank you so much for

174
00:05:26,699 --> 00:05:29,479
letting me talk with you all today

