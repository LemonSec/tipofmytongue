1
00:00:00,880 --> 00:00:02,399
hello everyone

2
00:00:02,399 --> 00:00:04,319
thank you so much for coming to my talk

3
00:00:04,319 --> 00:00:07,200
today my name is kennedy tokura and i am

4
00:00:07,200 --> 00:00:09,840
a senior class security researcher at

5
00:00:09,840 --> 00:00:11,599
fireball analytics

6
00:00:11,599 --> 00:00:13,360
so today i'm going to be talking about

7
00:00:13,360 --> 00:00:15,759
security cares engineering for fun and

8
00:00:15,759 --> 00:00:17,119
profit

9
00:00:17,119 --> 00:00:19,119
and you can see my twitter handle there

10
00:00:19,119 --> 00:00:21,119
and feel free to hit me up

11
00:00:21,119 --> 00:00:23,519
to ask questions about this talk at any

12
00:00:23,519 --> 00:00:26,080
point in time

13
00:00:26,560 --> 00:00:29,119
all right so um i'm going to cover a

14
00:00:29,119 --> 00:00:30,960
couple of topics today

15
00:00:30,960 --> 00:00:33,200
we will look at chaos engineering and

16
00:00:33,200 --> 00:00:35,680
also security cares engineering just to

17
00:00:35,680 --> 00:00:37,840
you know to try to have an understanding

18
00:00:37,840 --> 00:00:39,760
of these terms and how they are

19
00:00:39,760 --> 00:00:42,239
different different

20
00:00:42,239 --> 00:00:44,480
then we will look at um security cares

21
00:00:44,480 --> 00:00:46,239
engineering in cloud native security to

22
00:00:46,239 --> 00:00:48,239
understand you know why are we talking

23
00:00:48,239 --> 00:00:50,879
about security cares engineering for

24
00:00:50,879 --> 00:00:53,360
cloud native security right uh

25
00:00:53,360 --> 00:00:55,120
afterwards we will look at i'm gonna

26
00:00:55,120 --> 00:00:57,600
walk you through three um examples

27
00:00:57,600 --> 00:01:00,079
security cares engineering experiments

28
00:01:00,079 --> 00:01:01,840
and then lastly i will talk about

29
00:01:01,840 --> 00:01:03,760
risk-driven fault injection which is

30
00:01:03,760 --> 00:01:06,159
just my opinionated way of you know

31
00:01:06,159 --> 00:01:08,880
implementing security cares engineering

32
00:01:08,880 --> 00:01:10,840
so let's get

33
00:01:10,840 --> 00:01:13,760
started now chaos engineering i believe

34
00:01:13,760 --> 00:01:15,680
um some of us in the audience already

35
00:01:15,680 --> 00:01:17,840
have heard about it and probably some of

36
00:01:17,840 --> 00:01:19,840
us are already using it

37
00:01:19,840 --> 00:01:22,240
essentially um you know it is defined

38
00:01:22,240 --> 00:01:23,680
you know and looking actually at the

39
00:01:23,680 --> 00:01:26,000
definition from the principles of

40
00:01:26,000 --> 00:01:28,479
chaos.org you know case engineering is

41
00:01:28,479 --> 00:01:30,400
defined as the as the discipline of

42
00:01:30,400 --> 00:01:32,960
experimenting on the system in order to

43
00:01:32,960 --> 00:01:34,720
build confidence in the system's

44
00:01:34,720 --> 00:01:36,799
capability to withstand trouble and

45
00:01:36,799 --> 00:01:39,840
conditions in production so let's unpack

46
00:01:39,840 --> 00:01:42,079
this definition a little bit

47
00:01:42,079 --> 00:01:44,399
so at the core of of course engineering

48
00:01:44,399 --> 00:01:47,759
is is that proactiveness um to address

49
00:01:47,759 --> 00:01:50,640
availability problems um or problems

50
00:01:50,640 --> 00:01:52,799
that affect the performance of of of

51
00:01:52,799 --> 00:01:54,799
systems of distributed systems of

52
00:01:54,799 --> 00:01:57,119
virtually any kind of system and we all

53
00:01:57,119 --> 00:01:59,520
know that this um this concept was

54
00:01:59,520 --> 00:02:02,240
evolved was introduced by by netflix a

55
00:02:02,240 --> 00:02:04,719
couple of years ago and already there

56
00:02:04,719 --> 00:02:06,320
are a couple of products that are out

57
00:02:06,320 --> 00:02:08,720
there that are helping people to you to

58
00:02:08,720 --> 00:02:10,239
implement chaos engineering in their

59
00:02:10,239 --> 00:02:12,080
india in their companies for their

60
00:02:12,080 --> 00:02:14,879
products for their their services and of

61
00:02:14,879 --> 00:02:16,959
course there are a couple of um

62
00:02:16,959 --> 00:02:19,599
resiliency patterns that efficiently or

63
00:02:19,599 --> 00:02:22,480
effectively sort of implement chaos

64
00:02:22,480 --> 00:02:24,640
engineering so we have got things like

65
00:02:24,640 --> 00:02:27,280
time outs things like bug heads and

66
00:02:27,280 --> 00:02:29,840
circuit breaker right

67
00:02:29,840 --> 00:02:32,000
but let's look at chaos engineering i

68
00:02:32,000 --> 00:02:34,239
mean security care center right so

69
00:02:34,239 --> 00:02:36,720
security cares engineering is defined by

70
00:02:36,720 --> 00:02:39,040
aaron reinhardt who incidentally is the

71
00:02:39,040 --> 00:02:41,760
person who's who who actually started

72
00:02:41,760 --> 00:02:44,080
thinking about how the principles of

73
00:02:44,080 --> 00:02:47,040
case engineering could be could actually

74
00:02:47,040 --> 00:02:49,360
be applied to cyber security and he

75
00:02:49,360 --> 00:02:51,440
defined it as you know as the

76
00:02:51,440 --> 00:02:53,280
identification of security control

77
00:02:53,280 --> 00:02:55,519
failures through proactive

78
00:02:55,519 --> 00:02:57,760
experimentation to build confidence in

79
00:02:57,760 --> 00:03:00,319
the system's ability to defend against

80
00:03:00,319 --> 00:03:03,440
malicious conditions in production yeah

81
00:03:03,440 --> 00:03:05,200
it's it's a lot of words but you know

82
00:03:05,200 --> 00:03:07,840
the key things the key um key keywords

83
00:03:07,840 --> 00:03:09,760
in this definition is what

84
00:03:09,760 --> 00:03:12,159
security control failures proactive

85
00:03:12,159 --> 00:03:14,560
experimentation and you know defending

86
00:03:14,560 --> 00:03:17,040
against malicious um conditions in

87
00:03:17,040 --> 00:03:19,360
production right

88
00:03:19,360 --> 00:03:21,760
so let's let's let's understand this a

89
00:03:21,760 --> 00:03:24,080
little bit all right so unlike case

90
00:03:24,080 --> 00:03:26,400
engineering that just focuses on on

91
00:03:26,400 --> 00:03:28,720
availability and performance problems

92
00:03:28,720 --> 00:03:30,879
security cares engineering is trying to

93
00:03:30,879 --> 00:03:32,480
you know to be proactive

94
00:03:32,480 --> 00:03:35,120
um within the context of cyber security

95
00:03:35,120 --> 00:03:36,640
and when i talk about

96
00:03:36,640 --> 00:03:38,959
about security in this i'm talking about

97
00:03:38,959 --> 00:03:42,000
the three pillars of security meaning

98
00:03:42,000 --> 00:03:44,000
confidentiality integrity and

99
00:03:44,000 --> 00:03:46,480
availability and the idea is you want to

100
00:03:46,480 --> 00:03:48,720
understand you know if there are

101
00:03:48,720 --> 00:03:51,840
problems um that impact on these three

102
00:03:51,840 --> 00:03:54,080
pillars um in a way that we compromise

103
00:03:54,080 --> 00:03:55,760
your system in a way that might lead to

104
00:03:55,760 --> 00:03:58,159
your system be feeling and essentially

105
00:03:58,159 --> 00:03:59,920
in order to do this you're going to be

106
00:03:59,920 --> 00:04:02,400
you know injecting failures that we test

107
00:04:02,400 --> 00:04:04,239
you know the security controls and we

108
00:04:04,239 --> 00:04:06,560
will we will look more about we i will

109
00:04:06,560 --> 00:04:08,319
talk more about that in the next slide

110
00:04:08,319 --> 00:04:10,560
but you know the major problem the major

111
00:04:10,560 --> 00:04:13,599
goal here is to detect security blind

112
00:04:13,599 --> 00:04:14,560
spots

113
00:04:14,560 --> 00:04:17,358
and these are things that other security

114
00:04:17,358 --> 00:04:19,918
mechanisms security architectures are

115
00:04:19,918 --> 00:04:23,520
actually not looking at at all

116
00:04:23,520 --> 00:04:27,120
so um well how do we go about doing this

117
00:04:27,120 --> 00:04:30,240
um so we got our security faults which

118
00:04:30,240 --> 00:04:32,720
are basically you know security and

119
00:04:32,720 --> 00:04:34,160
cares engineering security cares

120
00:04:34,160 --> 00:04:36,240
engineering experiments that you are

121
00:04:36,240 --> 00:04:38,960
constructing and you are

122
00:04:38,960 --> 00:04:41,360
constructing these experiments you know

123
00:04:41,360 --> 00:04:44,080
or you can also call them as hypotheses

124
00:04:44,080 --> 00:04:45,520
um and

125
00:04:45,520 --> 00:04:48,080
inject them against you know the

126
00:04:48,080 --> 00:04:51,040
the the security controls now we know

127
00:04:51,040 --> 00:04:52,960
that um there are three major security

128
00:04:52,960 --> 00:04:55,840
controls um in in this domain of cyber

129
00:04:55,840 --> 00:04:58,320
security security we got the preventive

130
00:04:58,320 --> 00:05:00,720
controls for example identity access

131
00:05:00,720 --> 00:05:03,360
management systems and firewalls we also

132
00:05:03,360 --> 00:05:05,680
got the detective controls for example

133
00:05:05,680 --> 00:05:08,479
um id and nutrition detection systems

134
00:05:08,479 --> 00:05:11,120
and also the corrective controls right

135
00:05:11,120 --> 00:05:12,000
now

136
00:05:12,000 --> 00:05:13,919
the idea of security cares engineering

137
00:05:13,919 --> 00:05:16,560
is to test or to verify whether any of

138
00:05:16,560 --> 00:05:19,120
these controls are functioning in a way

139
00:05:19,120 --> 00:05:21,440
that they have promised or the vendors

140
00:05:21,440 --> 00:05:22,639
have promised they're gonna they're

141
00:05:22,639 --> 00:05:24,800
gonna perform you want to understand if

142
00:05:24,800 --> 00:05:26,880
they are feeling if they are if they are

143
00:05:26,880 --> 00:05:30,400
working as efficiently as they are and

144
00:05:30,400 --> 00:05:32,560
if they are not you want to understand

145
00:05:32,560 --> 00:05:35,280
how the impact upon um confidentiality

146
00:05:35,280 --> 00:05:38,479
integrity and availability

147
00:05:38,479 --> 00:05:39,360
so

148
00:05:39,360 --> 00:05:41,199
next we want to understand why are we

149
00:05:41,199 --> 00:05:43,600
even thinking about how we can begin to

150
00:05:43,600 --> 00:05:45,919
inject security faults against you know

151
00:05:45,919 --> 00:05:48,320
against cloud native infrastructure or

152
00:05:48,320 --> 00:05:49,600
how can we

153
00:05:49,600 --> 00:05:52,479
how why is it even important for cloud

154
00:05:52,479 --> 00:05:55,440
native security

155
00:05:55,520 --> 00:05:58,080
now we know that cognitive security is

156
00:05:58,080 --> 00:06:00,560
complex right in fact it is it is an

157
00:06:00,560 --> 00:06:03,600
abstraction of multiple abstractions um

158
00:06:03,600 --> 00:06:05,280
the death star we see the dead star

159
00:06:05,280 --> 00:06:07,759
graphs we see here have become very

160
00:06:07,759 --> 00:06:09,759
popular ways for

161
00:06:09,759 --> 00:06:11,039
kind of you know

162
00:06:11,039 --> 00:06:13,840
visually representing complex systems

163
00:06:13,840 --> 00:06:16,080
and effects efficiently effectively what

164
00:06:16,080 --> 00:06:18,639
we see here uh you know every node on

165
00:06:18,639 --> 00:06:21,759
this graph um kind of represents a an

166
00:06:21,759 --> 00:06:25,199
application or a a virtual machine or a

167
00:06:25,199 --> 00:06:27,520
server and we got all of these lines

168
00:06:27,520 --> 00:06:29,199
that are connecting and i kind of

169
00:06:29,199 --> 00:06:30,400
telling us

170
00:06:30,400 --> 00:06:31,600
you know how these nodes are

171
00:06:31,600 --> 00:06:33,520
communicating among themselves

172
00:06:33,520 --> 00:06:36,240
and you can see how how how this looks

173
00:06:36,240 --> 00:06:38,000
really complicated

174
00:06:38,000 --> 00:06:39,680
and just imagine how security

175
00:06:39,680 --> 00:06:42,639
professionals are able to identify when

176
00:06:42,639 --> 00:06:44,240
there are attacks in such an

177
00:06:44,240 --> 00:06:46,319
infrastructure how they are able to

178
00:06:46,319 --> 00:06:48,160
analyze attacks how they're able to

179
00:06:48,160 --> 00:06:51,680
detect defend against attackers

180
00:06:51,680 --> 00:06:54,080
now this is not far-fetched right um

181
00:06:54,080 --> 00:06:57,360
brishnaya who is one of the very popular

182
00:06:57,360 --> 00:07:00,560
figures or people in cyber security said

183
00:07:00,560 --> 00:07:02,080
almost a decade ago he said that the

184
00:07:02,080 --> 00:07:05,919
future of digital systems is complexity

185
00:07:05,919 --> 00:07:07,840
and complexity is the worst enemy of

186
00:07:07,840 --> 00:07:10,080
security and exactly this is what we are

187
00:07:10,080 --> 00:07:11,599
seeing today this is the kind these are

188
00:07:11,599 --> 00:07:13,759
the kind of problems that we are seeing

189
00:07:13,759 --> 00:07:16,560
within the domain of security

190
00:07:16,560 --> 00:07:18,800
complex systems like

191
00:07:18,800 --> 00:07:20,880
cloud native infrastructure

192
00:07:20,880 --> 00:07:22,560
make the the job of security

193
00:07:22,560 --> 00:07:25,759
professionals um very difficult um

194
00:07:25,759 --> 00:07:27,360
because on the first hand they got to

195
00:07:27,360 --> 00:07:29,840
understand how the systems work and then

196
00:07:29,840 --> 00:07:32,479
they have to defend against um defend to

197
00:07:32,479 --> 00:07:34,880
protect the system so harden them and

198
00:07:34,880 --> 00:07:37,199
that is exactly the problem we are

199
00:07:37,199 --> 00:07:40,639
facing today um in cyber security

200
00:07:40,639 --> 00:07:42,080
and actually there are a couple of

201
00:07:42,080 --> 00:07:45,120
reports that have come out you know to

202
00:07:45,120 --> 00:07:48,160
kind of solidify this statement um for

203
00:07:48,160 --> 00:07:50,879
example we have the cloud native trade

204
00:07:50,879 --> 00:07:53,199
report uh actually this was released

205
00:07:53,199 --> 00:07:55,520
last year by aqua security and you know

206
00:07:55,520 --> 00:07:57,520
the according to them after conducting a

207
00:07:57,520 --> 00:07:59,840
couple of experiments deploying cloud

208
00:07:59,840 --> 00:08:02,319
native infrastructure in a wild what i

209
00:08:02,319 --> 00:08:05,440
saw is you know as many as 106 attacks

210
00:08:05,440 --> 00:08:07,599
per day against its infrastructure and

211
00:08:07,599 --> 00:08:11,360
that was just in the first half of 2020.

212
00:08:11,360 --> 00:08:13,840
similarly um there was a report that was

213
00:08:13,840 --> 00:08:16,560
released um just a few months ago by the

214
00:08:16,560 --> 00:08:19,440
end by ibm and in this report they

215
00:08:19,440 --> 00:08:23,280
observed that there's a 150 increase of

216
00:08:23,280 --> 00:08:25,360
cloud vulnerabilities you know in the

217
00:08:25,360 --> 00:08:29,520
last five years 150 increase um

218
00:08:29,520 --> 00:08:30,400
and

219
00:08:30,400 --> 00:08:32,240
the point to note here is it's not just

220
00:08:32,240 --> 00:08:34,880
about it's not just that these attacks

221
00:08:34,880 --> 00:08:37,599
are increasing but also the complexity

222
00:08:37,599 --> 00:08:40,719
of the attacks are getting um

223
00:08:40,719 --> 00:08:42,479
i mean the attacks are actually getting

224
00:08:42,479 --> 00:08:44,880
more so sophisticated they are not

225
00:08:44,880 --> 00:08:47,360
conducted just by script kitties and you

226
00:08:47,360 --> 00:08:49,920
got um highly organized criminals that

227
00:08:49,920 --> 00:08:51,920
are actually involved in conducting

228
00:08:51,920 --> 00:08:53,600
these attacks

229
00:08:53,600 --> 00:08:55,839
and today so it means that you know

230
00:08:55,839 --> 00:08:57,200
defending against cloud native

231
00:08:57,200 --> 00:09:00,080
infrastructure becomes more and more

232
00:09:00,080 --> 00:09:02,080
difficult

233
00:09:02,080 --> 00:09:05,200
now i know it might be that um maybe

234
00:09:05,200 --> 00:09:06,800
some of us might be thinking that oh

235
00:09:06,800 --> 00:09:08,480
they are already cloud native security

236
00:09:08,480 --> 00:09:10,880
tools and of course you know

237
00:09:10,880 --> 00:09:13,600
if you have a look at the um the the

238
00:09:13,600 --> 00:09:15,680
security and compliance landscape of the

239
00:09:15,680 --> 00:09:18,320
cncf you got a lot of tools out there

240
00:09:18,320 --> 00:09:20,000
you know great tools

241
00:09:20,000 --> 00:09:22,800
um that are looking at um cloud native

242
00:09:22,800 --> 00:09:24,880
infrastructure trying to protect it they

243
00:09:24,880 --> 00:09:27,040
are implementing different dimensions of

244
00:09:27,040 --> 00:09:30,080
cloud native security which is cool

245
00:09:30,080 --> 00:09:31,200
but

246
00:09:31,200 --> 00:09:32,959
from what i've just said from from the

247
00:09:32,959 --> 00:09:35,279
researchers coming we observed that you

248
00:09:35,279 --> 00:09:37,440
know these attacks are still on the

249
00:09:37,440 --> 00:09:39,120
increase you know these attacks are

250
00:09:39,120 --> 00:09:41,120
becoming more complicated

251
00:09:41,120 --> 00:09:43,680
and from from a view um

252
00:09:43,680 --> 00:09:45,920
the the tool the methodology of the

253
00:09:45,920 --> 00:09:50,080
tools um have to actually um evolve um

254
00:09:50,080 --> 00:09:52,480
we need tools that are not just looking

255
00:09:52,480 --> 00:09:55,120
at the abstraction layers but tools are

256
00:09:55,120 --> 00:09:58,320
able to understand how attackers are

257
00:09:58,320 --> 00:10:00,320
moving from one abstraction layer to the

258
00:10:00,320 --> 00:10:02,480
other and i'm going to be

259
00:10:02,480 --> 00:10:03,680
um

260
00:10:03,680 --> 00:10:05,360
going deeper into this um in the next

261
00:10:05,360 --> 00:10:08,000
slide so for us to understand um exactly

262
00:10:08,000 --> 00:10:09,920
what i'm trying to talk about right now

263
00:10:09,920 --> 00:10:12,079
you know the forces of cloud native

264
00:10:12,079 --> 00:10:13,839
security is a great model that was

265
00:10:13,839 --> 00:10:16,720
proposed by the kubernetes security team

266
00:10:16,720 --> 00:10:20,399
um a few years ago and this model um

267
00:10:20,399 --> 00:10:22,959
what it does one of the one of the major

268
00:10:22,959 --> 00:10:25,680
pieces of information it passes us is

269
00:10:25,680 --> 00:10:27,600
about you know the abstraction layers

270
00:10:27,600 --> 00:10:29,200
that compose a cloud native

271
00:10:29,200 --> 00:10:31,120
infrastructure

272
00:10:31,120 --> 00:10:33,360
which which means code layer um

273
00:10:33,360 --> 00:10:36,000
container layer cluster and cloud layer

274
00:10:36,000 --> 00:10:38,959
and this the this model tells also helps

275
00:10:38,959 --> 00:10:40,480
us to understand as security

276
00:10:40,480 --> 00:10:43,279
professionals we get to deploy security

277
00:10:43,279 --> 00:10:47,040
mechanisms at every layer of abstraction

278
00:10:47,040 --> 00:10:49,519
um and this is essentially a defense in

279
00:10:49,519 --> 00:10:52,880
depth um approach and um security is got

280
00:10:52,880 --> 00:10:55,040
to be layered right

281
00:10:55,040 --> 00:10:56,320
however

282
00:10:56,320 --> 00:10:58,079
this is also a cl this is also a cloud

283
00:10:58,079 --> 00:11:00,079
native infrastructure and what we

284
00:11:00,079 --> 00:11:02,480
observe is cloud native infrastructure

285
00:11:02,480 --> 00:11:04,880
only actually has a quite large attack

286
00:11:04,880 --> 00:11:07,360
surface you know this multiple layers of

287
00:11:07,360 --> 00:11:10,800
abstraction um they introduce complexity

288
00:11:10,800 --> 00:11:13,279
and they and they effectively expose a

289
00:11:13,279 --> 00:11:15,360
wider attack surface meaning that

290
00:11:15,360 --> 00:11:18,320
attackers can take advantage of this

291
00:11:18,320 --> 00:11:21,360
this wide attack surface so for example

292
00:11:21,360 --> 00:11:24,000
we get on this diagram here we can see

293
00:11:24,000 --> 00:11:27,360
the cool layer also the darker layer uh

294
00:11:27,360 --> 00:11:29,360
or the container layer the the you know

295
00:11:29,360 --> 00:11:31,200
the cluster layer as well as the cloud

296
00:11:31,200 --> 00:11:33,360
layer uh but you know

297
00:11:33,360 --> 00:11:36,240
what attackers see is just one point you

298
00:11:36,240 --> 00:11:38,880
know attackers just you know they don't

299
00:11:38,880 --> 00:11:41,440
break this into layers attackers just

300
00:11:41,440 --> 00:11:43,279
see a target

301
00:11:43,279 --> 00:11:45,920
maybe a target of opportunity they go in

302
00:11:45,920 --> 00:11:48,720
there and they execute the attack um

303
00:11:48,720 --> 00:11:51,680
either patiently or with um or they try

304
00:11:51,680 --> 00:11:53,760
to understand the environment as they

305
00:11:53,760 --> 00:11:55,360
as they conduct the attack and

306
00:11:55,360 --> 00:11:57,440
eventually achieve their goals

307
00:11:57,440 --> 00:11:59,120
and i think that

308
00:11:59,120 --> 00:12:02,079
we as a defenders we also have to be

309
00:12:02,079 --> 00:12:05,360
able to defend our systems you know from

310
00:12:05,360 --> 00:12:07,839
this similar viewpoint that attackers

311
00:12:07,839 --> 00:12:08,639
are

312
00:12:08,639 --> 00:12:11,279
are using we got to be able to look at

313
00:12:11,279 --> 00:12:14,240
the infrastructure not just as you know

314
00:12:14,240 --> 00:12:14,959
um

315
00:12:14,959 --> 00:12:18,399
silos of of or layers of abstraction but

316
00:12:18,399 --> 00:12:20,880
we have to evolve tools that are able to

317
00:12:20,880 --> 00:12:21,839
look at

318
00:12:21,839 --> 00:12:24,480
the the connecting layers and are able

319
00:12:24,480 --> 00:12:26,560
to understand the relationships between

320
00:12:26,560 --> 00:12:28,639
each of these layers and i think that

321
00:12:28,639 --> 00:12:31,440
this is one of the value propositions of

322
00:12:31,440 --> 00:12:34,079
of of of security chaos engineering

323
00:12:34,079 --> 00:12:36,320
because um security case engineering is

324
00:12:36,320 --> 00:12:37,519
actually

325
00:12:37,519 --> 00:12:39,920
layer agnostic it is not dependent on

326
00:12:39,920 --> 00:12:42,800
any of these layers it can actually be

327
00:12:42,800 --> 00:12:44,959
injected or it can actually implement it

328
00:12:44,959 --> 00:12:46,880
across the entire stack of the cloud

329
00:12:46,880 --> 00:12:49,200
native infrastructure actually from one

330
00:12:49,200 --> 00:12:51,760
point and that gives the view of

331
00:12:51,760 --> 00:12:53,839
understanding which of these layers are

332
00:12:53,839 --> 00:12:54,959
weak

333
00:12:54,959 --> 00:12:56,959
makes us to understand okay

334
00:12:56,959 --> 00:12:59,600
what are the relationships

335
00:12:59,600 --> 00:13:02,240
across the the entire layers what are

336
00:13:02,240 --> 00:13:04,959
the weaknesses across the layers and how

337
00:13:04,959 --> 00:13:07,760
we can deploy systems that effectively

338
00:13:07,760 --> 00:13:09,040
defend against

339
00:13:09,040 --> 00:13:12,319
um these kinds of attacks

340
00:13:12,720 --> 00:13:15,040
all right so let us have a look at a few

341
00:13:15,040 --> 00:13:16,959
um experiments example experiments and

342
00:13:16,959 --> 00:13:18,880
the first one is the public bucket

343
00:13:18,880 --> 00:13:21,279
experiment which is um which is actually

344
00:13:21,279 --> 00:13:24,000
a very simple one um because you know s3

345
00:13:24,000 --> 00:13:26,480
buckets are being

346
00:13:26,480 --> 00:13:29,440
um are one of the most um attacked um

347
00:13:29,440 --> 00:13:32,160
resources in the cloud and so let's just

348
00:13:32,160 --> 00:13:34,160
walk through this this this example so

349
00:13:34,160 --> 00:13:36,160
firstly we see that the attacker here

350
00:13:36,160 --> 00:13:38,880
creates a user called bob um and bob is

351
00:13:38,880 --> 00:13:40,480
able to get access or is able to

352
00:13:40,480 --> 00:13:43,600
enumerate aws buckets gets one bucket

353
00:13:43,600 --> 00:13:45,600
creates a malicious policy and

354
00:13:45,600 --> 00:13:48,399
and eventually he takes over that bucket

355
00:13:48,399 --> 00:13:50,160
and you know after taking over the

356
00:13:50,160 --> 00:13:52,160
bucket he's he can do a lot of things he

357
00:13:52,160 --> 00:13:54,639
can you know just um read the data in

358
00:13:54,639 --> 00:13:56,480
that bucket maybe they are crucial

359
00:13:56,480 --> 00:13:59,600
information it can actually also um you

360
00:13:59,600 --> 00:14:01,680
know you know in excel trade data data

361
00:14:01,680 --> 00:14:04,399
away and for so if you inject if you

362
00:14:04,399 --> 00:14:06,639
conduct this kind of attack uh or this

363
00:14:06,639 --> 00:14:09,199
kind of um experiment you know a couple

364
00:14:09,199 --> 00:14:12,079
of things um that are important here is

365
00:14:12,079 --> 00:14:14,320
to understand whether the security

366
00:14:14,320 --> 00:14:15,920
controls that are supposed to either

367
00:14:15,920 --> 00:14:18,560
detect or prevent this attack are

368
00:14:18,560 --> 00:14:21,040
actually working as they should now if

369
00:14:21,040 --> 00:14:23,360
they fail you know that you got um you

370
00:14:23,360 --> 00:14:25,040
got a problem to fix

371
00:14:25,040 --> 00:14:27,680
and even if they are able to trigger

372
00:14:27,680 --> 00:14:30,320
some alerts um you have to understand

373
00:14:30,320 --> 00:14:31,440
you have to

374
00:14:31,440 --> 00:14:33,680
analyze these alerts and see whether

375
00:14:33,680 --> 00:14:35,920
that information that is being spilled

376
00:14:35,920 --> 00:14:36,639
out

377
00:14:36,639 --> 00:14:38,720
makes enough sense for you as a security

378
00:14:38,720 --> 00:14:41,120
professional

379
00:14:41,120 --> 00:14:43,040
let's look at um

380
00:14:43,040 --> 00:14:45,279
the next the next experiment is the

381
00:14:45,279 --> 00:14:47,440
bucket ransomware experiment and of

382
00:14:47,440 --> 00:14:50,800
course this also is an is one of the um

383
00:14:50,800 --> 00:14:52,720
attack methods that is really really on

384
00:14:52,720 --> 00:14:54,480
the rise and it's causing a lot of

385
00:14:54,480 --> 00:14:57,600
problem and it is this this experiment

386
00:14:57,600 --> 00:14:59,920
is a buildup of the previous one and um

387
00:14:59,920 --> 00:15:02,079
there is just one single point that is

388
00:15:02,079 --> 00:15:04,480
different which is the bucket encryption

389
00:15:04,480 --> 00:15:06,720
um which happens after the attacker

390
00:15:06,720 --> 00:15:09,839
selects one or more buckets now in this

391
00:15:09,839 --> 00:15:12,480
case um the important point here or one

392
00:15:12,480 --> 00:15:15,519
of possible hypotheses will be you know

393
00:15:15,519 --> 00:15:18,639
to to to verify whether all of the

394
00:15:18,639 --> 00:15:21,120
counter ransomware measures that might

395
00:15:21,120 --> 00:15:22,720
have been put in place are actually

396
00:15:22,720 --> 00:15:25,120
efficient and i've observed that you

397
00:15:25,120 --> 00:15:27,600
know since ransomware became a hot topic

398
00:15:27,600 --> 00:15:30,399
um cloud service providers or you know

399
00:15:30,399 --> 00:15:32,480
different tools different um security

400
00:15:32,480 --> 00:15:34,320
vendors are beginning to come up with

401
00:15:34,320 --> 00:15:36,959
different tools different uh mechanisms

402
00:15:36,959 --> 00:15:39,040
and you know that about how to defend

403
00:15:39,040 --> 00:15:40,399
against these attacks

404
00:15:40,399 --> 00:15:41,360
and so

405
00:15:41,360 --> 00:15:43,120
it's going to be it's going to be very

406
00:15:43,120 --> 00:15:46,560
useful and to understand here whether

407
00:15:46,560 --> 00:15:48,639
the backups that were made of the you

408
00:15:48,639 --> 00:15:50,399
know the backups the backups for the

409
00:15:50,399 --> 00:15:53,519
buckets um very useful at all

410
00:15:53,519 --> 00:15:56,320
were you able to resume um you know in

411
00:15:56,320 --> 00:15:58,880
your operations for your customers uh in

412
00:15:58,880 --> 00:16:00,560
the midst of these

413
00:16:00,560 --> 00:16:01,920
ransomware

414
00:16:01,920 --> 00:16:03,440
based on the backups

415
00:16:03,440 --> 00:16:05,519
were you able to conduct an incident

416
00:16:05,519 --> 00:16:08,320
response in in a way that was efficient

417
00:16:08,320 --> 00:16:10,720
you know these are kind of um the

418
00:16:10,720 --> 00:16:13,440
possible hypotheses that might be framed

419
00:16:13,440 --> 00:16:14,959
and within the context of this

420
00:16:14,959 --> 00:16:18,000
ransomware experiment

421
00:16:18,000 --> 00:16:19,440
now let's look at the last one and the

422
00:16:19,440 --> 00:16:22,800
last one here um is is a little bit more

423
00:16:22,800 --> 00:16:25,920
more complicated right it is actually

424
00:16:25,920 --> 00:16:28,480
different because here um bob um

425
00:16:28,480 --> 00:16:31,279
actually goes into the eks cluster and

426
00:16:31,279 --> 00:16:34,320
from there he compromises a pod and from

427
00:16:34,320 --> 00:16:36,639
there he he moves over to compromise the

428
00:16:36,639 --> 00:16:39,759
s3 bucket before encrypting it right

429
00:16:39,759 --> 00:16:41,199
and um

430
00:16:41,199 --> 00:16:42,560
oh sorry

431
00:16:42,560 --> 00:16:44,639
and essentially um

432
00:16:44,639 --> 00:16:47,120
the point here is that you know bob bob

433
00:16:47,120 --> 00:16:49,839
is able to you know he's able to move uh

434
00:16:49,839 --> 00:16:52,800
from the from the m cloud control plane

435
00:16:52,800 --> 00:16:55,920
into the into the kubernetes cluster

436
00:16:55,920 --> 00:16:57,680
that means this attack itself is

437
00:16:57,680 --> 00:16:59,680
actually more complicated

438
00:16:59,680 --> 00:17:00,480
and

439
00:17:00,480 --> 00:17:02,639
the attacker might actually confuse the

440
00:17:02,639 --> 00:17:05,280
defender um if the tools that are for

441
00:17:05,280 --> 00:17:07,439
example in this case if you got um a

442
00:17:07,439 --> 00:17:09,760
cloud work workload protection platform

443
00:17:09,760 --> 00:17:11,359
that is deployed for on the in case

444
00:17:11,359 --> 00:17:15,280
cluster and that plug that and cwpp

445
00:17:15,280 --> 00:17:18,319
is not kind of speaking in any way with

446
00:17:18,319 --> 00:17:20,720
any of the aws native tool or maybe the

447
00:17:20,720 --> 00:17:23,919
cspm um then this kind of attack is

448
00:17:23,919 --> 00:17:26,240
going to be much more difficult and to

449
00:17:26,240 --> 00:17:28,799
defend against

450
00:17:28,799 --> 00:17:30,480
all right so

451
00:17:30,480 --> 00:17:32,240
let us talk a little bit now about the

452
00:17:32,240 --> 00:17:34,799
risk-driven fault injection and this is

453
00:17:34,799 --> 00:17:38,000
just um actually um based off of my

454
00:17:38,000 --> 00:17:40,720
research and it is a way where like

455
00:17:40,720 --> 00:17:43,280
let's say a framework that enables us to

456
00:17:43,280 --> 00:17:45,360
apply security cares engineering you

457
00:17:45,360 --> 00:17:47,120
know in our environments

458
00:17:47,120 --> 00:17:49,200
and i thought about this because after

459
00:17:49,200 --> 00:17:51,600
speaking with several people about um

460
00:17:51,600 --> 00:17:54,160
security cares engineering i realized

461
00:17:54,160 --> 00:17:56,799
that you know it is a it's a topic that

462
00:17:56,799 --> 00:17:59,919
is a little bit difficult to get a bind

463
00:17:59,919 --> 00:18:01,840
of the of the management

464
00:18:01,840 --> 00:18:03,840
which is kind of typical of security

465
00:18:03,840 --> 00:18:05,760
because we are talking we talk in

466
00:18:05,760 --> 00:18:08,400
abstract terms but at the end of the day

467
00:18:08,400 --> 00:18:10,480
by you being able to

468
00:18:10,480 --> 00:18:13,280
map whatever finding you got to to to

469
00:18:13,280 --> 00:18:14,880
cyber risk

470
00:18:14,880 --> 00:18:17,120
it makes more sense to speak to the

471
00:18:17,120 --> 00:18:19,520
management about about security cares

472
00:18:19,520 --> 00:18:20,720
engineering

473
00:18:20,720 --> 00:18:22,400
and so this the risk grain fault

474
00:18:22,400 --> 00:18:25,520
injection has got five pillars execute

475
00:18:25,520 --> 00:18:28,160
monitor analyze plan and knowledge and

476
00:18:28,160 --> 00:18:30,240
we're gonna look at them one after the

477
00:18:30,240 --> 00:18:33,120
other so starting with execute so by

478
00:18:33,120 --> 00:18:35,520
execute and we gotta have an aim for

479
00:18:35,520 --> 00:18:38,240
your experiment so it's not just um to

480
00:18:38,240 --> 00:18:41,120
experiment for the sake of causing chaos

481
00:18:41,120 --> 00:18:42,720
you know but we want to take away the

482
00:18:42,720 --> 00:18:45,440
chaos so you gotta have it an aim for

483
00:18:45,440 --> 00:18:47,360
your experiment you gotta craft a

484
00:18:47,360 --> 00:18:49,360
hypothesis like

485
00:18:49,360 --> 00:18:51,280
like some of the examples we just we

486
00:18:51,280 --> 00:18:53,600
just we just we just had to look at

487
00:18:53,600 --> 00:18:55,679
and then next we have to like have a

488
00:18:55,679 --> 00:18:58,240
scoop which means that you have to kind

489
00:18:58,240 --> 00:19:00,240
of determine the skill the depth and

490
00:19:00,240 --> 00:19:02,799
intensity of the experiments

491
00:19:02,799 --> 00:19:04,799
and most importantly is about

492
00:19:04,799 --> 00:19:06,960
coordination you got to coordinate with

493
00:19:06,960 --> 00:19:08,720
the teams um that are going to be

494
00:19:08,720 --> 00:19:11,280
involved in these experiments maybe this

495
00:19:11,280 --> 00:19:14,240
could be the devops um this could be um

496
00:19:14,240 --> 00:19:16,080
this could actually be you know um

497
00:19:16,080 --> 00:19:18,480
different people that will be involved

498
00:19:18,480 --> 00:19:21,039
you know in in in this particular

499
00:19:21,039 --> 00:19:22,799
experiment and it could also be

500
00:19:22,799 --> 00:19:25,280
something like like um

501
00:19:25,280 --> 00:19:27,840
it could also be like it cares and

502
00:19:27,840 --> 00:19:29,840
exercise uh and you gotta do it with

503
00:19:29,840 --> 00:19:30,640
them

504
00:19:30,640 --> 00:19:33,679
and um one other part very important

505
00:19:33,679 --> 00:19:35,840
here is about the steady state right so

506
00:19:35,840 --> 00:19:38,160
the steady state is the state of the

507
00:19:38,160 --> 00:19:40,640
infrastructure before chaos is being

508
00:19:40,640 --> 00:19:44,080
injected and that has to be kind of um

509
00:19:44,080 --> 00:19:46,320
that has to be kept either either by

510
00:19:46,320 --> 00:19:48,559
using infrastructure as code or it is

511
00:19:48,559 --> 00:19:51,679
storing um the the the storing the

512
00:19:51,679 --> 00:19:53,840
framework of the environment in a

513
00:19:53,840 --> 00:19:55,440
database

514
00:19:55,440 --> 00:19:57,200
the next point is about monitoring

515
00:19:57,200 --> 00:19:59,200
monitoring is very important because you

516
00:19:59,200 --> 00:20:01,200
know when you begin to insert or when

517
00:20:01,200 --> 00:20:03,760
you begin to conduct chaos and cares

518
00:20:03,760 --> 00:20:06,080
experiments you got to understand and

519
00:20:06,080 --> 00:20:08,240
you got to understand how it impacts

520
00:20:08,240 --> 00:20:10,400
your environment and you need to have

521
00:20:10,400 --> 00:20:13,200
clear visibility into the environment um

522
00:20:13,200 --> 00:20:15,280
either using things like logging like

523
00:20:15,280 --> 00:20:18,080
observability like tracing um so that

524
00:20:18,080 --> 00:20:21,039
you are able to stop the experiment if

525
00:20:21,039 --> 00:20:23,120
it begins to impact your environment

526
00:20:23,120 --> 00:20:26,559
negatively and so that you can also

527
00:20:26,559 --> 00:20:28,400
recover to the steady state that i

528
00:20:28,400 --> 00:20:30,720
talked about um as part of the execute

529
00:20:30,720 --> 00:20:32,799
pillar

530
00:20:32,799 --> 00:20:35,679
right so the next part um is analyze and

531
00:20:35,679 --> 00:20:37,520
this is also another important part

532
00:20:37,520 --> 00:20:39,600
because uh at the end of the day at the

533
00:20:39,600 --> 00:20:40,960
end of the result of the of the

534
00:20:40,960 --> 00:20:43,600
experiment you want to get at results uh

535
00:20:43,600 --> 00:20:45,039
you want to analyze it you want to

536
00:20:45,039 --> 00:20:48,480
understand what field why it failed um

537
00:20:48,480 --> 00:20:49,840
you want to understand whether your

538
00:20:49,840 --> 00:20:54,080
hypothesis was proven or not

539
00:20:54,720 --> 00:20:56,480
and you know this is just an example

540
00:20:56,480 --> 00:20:58,159
this is the always risk rating

541
00:20:58,159 --> 00:21:01,039
methodology where um you know it goes

542
00:21:01,039 --> 00:21:03,120
from analyzing the threats you know the

543
00:21:03,120 --> 00:21:05,200
threat agents to the attack vectors in

544
00:21:05,200 --> 00:21:07,679
the end it also looks at the technical

545
00:21:07,679 --> 00:21:10,559
impact and also the business impacts so

546
00:21:10,559 --> 00:21:11,360
um

547
00:21:11,360 --> 00:21:13,039
it is also a framework that could be

548
00:21:13,039 --> 00:21:14,240
used for

549
00:21:14,240 --> 00:21:16,480
security cares in january just to

550
00:21:16,480 --> 00:21:19,039
analyze also you know the results of the

551
00:21:19,039 --> 00:21:21,679
experiment

552
00:21:21,760 --> 00:21:24,159
so the next part you know the next stage

553
00:21:24,159 --> 00:21:26,480
is you know it's about planning so at

554
00:21:26,480 --> 00:21:28,400
the end of the day you want to plan the

555
00:21:28,400 --> 00:21:31,360
next steps you know you want to um plan

556
00:21:31,360 --> 00:21:33,520
how you will patch your system you want

557
00:21:33,520 --> 00:21:35,280
to plan how you will carry that

558
00:21:35,280 --> 00:21:37,360
information because the value you get

559
00:21:37,360 --> 00:21:38,240
out of

560
00:21:38,240 --> 00:21:39,679
out of security cares and during

561
00:21:39,679 --> 00:21:42,159
experiments um it's very valuable that

562
00:21:42,159 --> 00:21:44,080
is a great thing about it this is

563
00:21:44,080 --> 00:21:46,720
knowledge that is very useful for um

564
00:21:46,720 --> 00:21:49,120
security operations is very useful for

565
00:21:49,120 --> 00:21:51,520
trade modeling sessions and is useful

566
00:21:51,520 --> 00:21:54,240
for also doing awareness training for

567
00:21:54,240 --> 00:21:56,880
your employees and this is cool because

568
00:21:56,880 --> 00:21:58,240
in this case you're talking about

569
00:21:58,240 --> 00:22:00,480
evidence-based knowledge and not some

570
00:22:00,480 --> 00:22:03,280
knowledge that's based on um on some

571
00:22:03,280 --> 00:22:05,200
theory or knowledge that's based on some

572
00:22:05,200 --> 00:22:07,840
assumptions

573
00:22:08,240 --> 00:22:10,320
all right and the last part of this um

574
00:22:10,320 --> 00:22:12,320
the risk driven fault rejection is the

575
00:22:12,320 --> 00:22:13,760
knowledge base so i just talked about

576
00:22:13,760 --> 00:22:16,000
the knowledge and as much as possible

577
00:22:16,000 --> 00:22:17,200
this knowledge

578
00:22:17,200 --> 00:22:19,200
has to be kept in a sort of knowledge

579
00:22:19,200 --> 00:22:21,679
base so that it can be reused

580
00:22:21,679 --> 00:22:23,200
and there are a lot of ways that you can

581
00:22:23,200 --> 00:22:25,840
use this knowledge um either by sharing

582
00:22:25,840 --> 00:22:28,000
it with the trained hunt and the threat

583
00:22:28,000 --> 00:22:30,400
hunting team or the incident response

584
00:22:30,400 --> 00:22:32,720
teams um or you could also use it as

585
00:22:32,720 --> 00:22:34,080
part of the data

586
00:22:34,080 --> 00:22:37,280
for your machine learning um

587
00:22:37,280 --> 00:22:38,840
machine learning

588
00:22:38,840 --> 00:22:41,440
models right so

589
00:22:41,440 --> 00:22:43,440
yeah so in case you're actually someone

590
00:22:43,440 --> 00:22:45,679
who is interested in learning more about

591
00:22:45,679 --> 00:22:48,080
security cares engineering i i have

592
00:22:48,080 --> 00:22:50,400
published a couple of papers and feel

593
00:22:50,400 --> 00:22:52,880
free to to most of them are publicly

594
00:22:52,880 --> 00:22:55,360
available and reading it will give you

595
00:22:55,360 --> 00:22:58,159
more insight and i was also very lucky

596
00:22:58,159 --> 00:23:00,400
to be um one of the contribute

597
00:23:00,400 --> 00:23:02,559
contributing authors for the security

598
00:23:02,559 --> 00:23:04,640
cares engineering o'reilly book the very

599
00:23:04,640 --> 00:23:06,799
first one that was published by aaron

600
00:23:06,799 --> 00:23:09,200
reinhardt and kelly shortridge it's a

601
00:23:09,200 --> 00:23:11,280
great book for you to also read to get

602
00:23:11,280 --> 00:23:13,360
more understanding about security cares

603
00:23:13,360 --> 00:23:15,200
engineering

604
00:23:15,200 --> 00:23:17,120
yeah okay so that brings me to the end

605
00:23:17,120 --> 00:23:19,280
of my talk um thank you so much for

606
00:23:19,280 --> 00:23:22,080
listening i am super excited to get to

607
00:23:22,080 --> 00:23:24,159
hear from you um i've got my twitter

608
00:23:24,159 --> 00:23:26,240
handle there uh feel free to reach out

609
00:23:26,240 --> 00:23:29,120
to me and talk to me about your your

610
00:23:29,120 --> 00:23:31,520
your understanding ask me questions um

611
00:23:31,520 --> 00:23:34,400
criticize um the things that i've said

612
00:23:34,400 --> 00:23:36,400
thank you very much enjoy the rest of

613
00:23:36,400 --> 00:23:39,559
the conference

