1
00:00:02,879 --> 00:00:05,600
so hello everyone ladies and gentlemen i

2
00:00:05,600 --> 00:00:07,520
would like to

3
00:00:07,520 --> 00:00:10,240
welcome you here at positive hack days

4
00:00:10,240 --> 00:00:13,040
and today's presentation is big data

5
00:00:13,040 --> 00:00:14,719
insecurity

6
00:00:14,719 --> 00:00:17,359
uh obviously

7
00:00:17,359 --> 00:00:20,000
in practice we are going to take a look

8
00:00:20,000 --> 00:00:21,600
at the typical

9
00:00:21,600 --> 00:00:23,519
configuration errors

10
00:00:23,519 --> 00:00:25,439
that very often are

11
00:00:25,439 --> 00:00:27,000
found at pin tests

12
00:00:27,000 --> 00:00:28,480
[Music]

13
00:00:28,480 --> 00:00:29,359
at

14
00:00:29,359 --> 00:00:31,599
hadoop environment

15
00:00:31,599 --> 00:00:33,920
especially when we perform

16
00:00:33,920 --> 00:00:37,200
hadoop ecosystem audit for big data

17
00:00:37,200 --> 00:00:40,200
analysis

18
00:00:46,239 --> 00:00:48,239
in the introduction i would like to say

19
00:00:48,239 --> 00:00:50,559
a few words about the essence of my

20
00:00:50,559 --> 00:00:52,399
presentation first of all i would like

21
00:00:52,399 --> 00:00:55,920
to discuss uh hadoop and big data

22
00:00:55,920 --> 00:00:58,640
what it's all about and uh take a look

23
00:00:58,640 --> 00:01:00,480
at hadoop at the

24
00:01:00,480 --> 00:01:02,640
integral part

25
00:01:02,640 --> 00:01:03,680
of the

26
00:01:03,680 --> 00:01:05,199
analysis

27
00:01:05,199 --> 00:01:07,680
of the big data and the second part of

28
00:01:07,680 --> 00:01:09,840
the presentation will speak about the

29
00:01:09,840 --> 00:01:12,320
typical

30
00:01:12,320 --> 00:01:15,280
hadoop cluster configuration errors

31
00:01:15,280 --> 00:01:18,640
body hue zoom keeper

32
00:01:18,640 --> 00:01:21,840
hive etc in the end i'll come up with

33
00:01:21,840 --> 00:01:24,560
conclusions uh summary recommendations

34
00:01:24,560 --> 00:01:26,880
which will help you hopefully make your

35
00:01:26,880 --> 00:01:30,720
hadoop cluster more secure

36
00:01:32,640 --> 00:01:35,439
who am i i'm vadim

37
00:01:35,439 --> 00:01:37,680
working as a pin tester

38
00:01:37,680 --> 00:01:40,920
in um

39
00:01:42,880 --> 00:01:45,759
this company and i specialize in cloud

40
00:01:45,759 --> 00:01:49,600
security kubernetes and

41
00:01:49,600 --> 00:01:51,600
co-creator of

42
00:01:51,600 --> 00:01:53,439
k8's

43
00:01:53,439 --> 00:01:54,799
telegram

44
00:01:54,799 --> 00:01:58,079
channel hadoop what it's all about so i

45
00:01:58,079 --> 00:02:00,240
think obviously we just need to start

46
00:02:00,240 --> 00:02:04,320
with big data and what we mean by it

47
00:02:04,320 --> 00:02:06,719
so it's big volume of the

48
00:02:06,719 --> 00:02:08,399
non-structured

49
00:02:08,399 --> 00:02:11,200
data that we use

50
00:02:11,200 --> 00:02:12,000
for

51
00:02:12,000 --> 00:02:15,040
an upcoming analysis

52
00:02:15,040 --> 00:02:17,680
regardless of the goal whether it's

53
00:02:17,680 --> 00:02:20,560
building a model whether it's the fraud

54
00:02:20,560 --> 00:02:23,599
transaction analysis it's all a part of

55
00:02:23,599 --> 00:02:25,200
the hadoop

56
00:02:25,200 --> 00:02:27,680
eco system

57
00:02:27,680 --> 00:02:30,160
been one of the main elements i mean

58
00:02:30,160 --> 00:02:31,840
hadoop

59
00:02:31,840 --> 00:02:32,879
what is

60
00:02:32,879 --> 00:02:36,640
hadoop hadoop as i said is an echo

61
00:02:36,640 --> 00:02:40,000
system having more than 40 components

62
00:02:40,000 --> 00:02:42,560
all intended for specific

63
00:02:42,560 --> 00:02:44,000
purposes

64
00:02:44,000 --> 00:02:47,200
here we have a huge number of them it's

65
00:02:47,200 --> 00:02:49,040
a very busy

66
00:02:49,040 --> 00:02:50,560
slide showing

67
00:02:50,560 --> 00:02:53,599
uh the great heterogenesis

68
00:02:53,599 --> 00:02:55,200
of this

69
00:02:55,200 --> 00:02:58,160
echo system

70
00:02:58,480 --> 00:03:01,120
as for the methodology

71
00:03:01,120 --> 00:03:04,959
the testing of the hadoop clusters

72
00:03:04,959 --> 00:03:06,080
it's a

73
00:03:06,080 --> 00:03:07,680
high level uh

74
00:03:07,680 --> 00:03:09,920
approach to methodology but according to

75
00:03:09,920 --> 00:03:12,800
that we assume that we split this whole

76
00:03:12,800 --> 00:03:14,159
data

77
00:03:14,159 --> 00:03:18,319
by levels by functions and we single out

78
00:03:18,319 --> 00:03:20,879
five levels cluster management is not

79
00:03:20,879 --> 00:03:23,440
the main one is actually

80
00:03:23,440 --> 00:03:25,040
managing the cluster

81
00:03:25,040 --> 00:03:27,920
just in the configuration

82
00:03:27,920 --> 00:03:30,959
and performing some administrative

83
00:03:30,959 --> 00:03:33,360
functions so we'll just take a look at

84
00:03:33,360 --> 00:03:34,480
bari

85
00:03:34,480 --> 00:03:35,360
you

86
00:03:35,360 --> 00:03:39,040
date ingestions etc so this is how our

87
00:03:39,040 --> 00:03:40,319
data goes

88
00:03:40,319 --> 00:03:41,920
to the cluster

89
00:03:41,920 --> 00:03:44,640
how do we put it in there

90
00:03:44,640 --> 00:03:48,560
for which we will speak and check it out

91
00:03:48,560 --> 00:03:49,599
then

92
00:03:49,599 --> 00:03:52,000
storage hadoop

93
00:03:52,000 --> 00:03:55,120
hydro distributed file system

94
00:03:55,120 --> 00:03:58,640
apache edge base and hive

95
00:03:58,640 --> 00:04:02,159
data storage layers as we can obviously

96
00:04:02,159 --> 00:04:03,439
define them

97
00:04:03,439 --> 00:04:06,480
data processing these are the

98
00:04:06,480 --> 00:04:07,360
tools

99
00:04:07,360 --> 00:04:09,519
responsible for data process and

100
00:04:09,519 --> 00:04:11,680
actually

101
00:04:11,680 --> 00:04:14,799
data analysis and level five is data

102
00:04:14,799 --> 00:04:16,720
access that's where we can see some of

103
00:04:16,720 --> 00:04:19,279
the tools there's a big number of them

104
00:04:19,279 --> 00:04:21,680
and what we're going to cover

105
00:04:21,680 --> 00:04:23,360
during the course of the presentation

106
00:04:23,360 --> 00:04:24,560
today

107
00:04:24,560 --> 00:04:25,360
uh

108
00:04:25,360 --> 00:04:28,720
what's this hadoop cluster all about

109
00:04:28,720 --> 00:04:31,759
if you take a look at this approximate

110
00:04:31,759 --> 00:04:34,639
slide we can see the sources of data

111
00:04:34,639 --> 00:04:36,880
imagine these are the clouds regardless

112
00:04:36,880 --> 00:04:39,919
of the provider amazon yandex cloud it

113
00:04:39,919 --> 00:04:41,840
doesn't really matter we just put them

114
00:04:41,840 --> 00:04:42,880
into the

115
00:04:42,880 --> 00:04:45,199
cluster with the use of kafka we can use

116
00:04:45,199 --> 00:04:47,360
flume for instance

117
00:04:47,360 --> 00:04:50,479
and spark is actually used here as the

118
00:04:50,479 --> 00:04:52,800
processing layer then it goes to the

119
00:04:52,800 --> 00:04:56,400
hadoop hdfs and we can analyze them with

120
00:04:56,400 --> 00:04:58,560
the hadoop yarn

121
00:04:58,560 --> 00:05:00,720
then we have the data access layer

122
00:05:00,720 --> 00:05:04,320
that's how we can interact

123
00:05:04,560 --> 00:05:08,000
with the data in cluster

124
00:05:08,000 --> 00:05:09,600
and

125
00:05:09,600 --> 00:05:12,000
i'm barry hugh and zookeeper there's a

126
00:05:12,000 --> 00:05:14,479
management layer tools responsible for

127
00:05:14,479 --> 00:05:18,160
the cluster configuration it's

128
00:05:18,160 --> 00:05:19,520
performance

129
00:05:19,520 --> 00:05:22,840
and let's start with the typical

130
00:05:22,840 --> 00:05:26,400
configuration components errors of the

131
00:05:26,400 --> 00:05:28,240
hadoop cluster

132
00:05:28,240 --> 00:05:31,360
we cannot obviously see these bugs and

133
00:05:31,360 --> 00:05:34,160
misconfig misconfigs

134
00:05:34,160 --> 00:05:37,520
misconfigurations that are very easy

135
00:05:37,520 --> 00:05:40,479
to utilize but sometimes they can lead

136
00:05:40,479 --> 00:05:42,560
to very very aggravated

137
00:05:42,560 --> 00:05:45,039
and sad consequences

138
00:05:45,039 --> 00:05:48,080
for the businesses

139
00:05:48,560 --> 00:05:50,960
and we'll start with cluster management

140
00:05:50,960 --> 00:05:53,680
apache ambari which is a tool which is

141
00:05:53,680 --> 00:05:56,319
for the monitoring and centralized

142
00:05:56,319 --> 00:05:57,440
launch

143
00:05:57,440 --> 00:06:00,080
shutdown and configuration of all of the

144
00:06:00,080 --> 00:06:02,160
hadoop services and the cluster it's a

145
00:06:02,160 --> 00:06:03,360
dashboard

146
00:06:03,360 --> 00:06:05,360
in any way in other words

147
00:06:05,360 --> 00:06:07,600
for the entire cluster you can see the

148
00:06:07,600 --> 00:06:10,720
main metrics here on the screen

149
00:06:10,720 --> 00:06:13,919
here on the main page

150
00:06:17,039 --> 00:06:20,080
and apache i'm barry the default

151
00:06:20,080 --> 00:06:22,639
configuration of the hadoop cluster of

152
00:06:22,639 --> 00:06:24,479
the cloud era

153
00:06:24,479 --> 00:06:27,840
and hotel works ambari runs by default

154
00:06:27,840 --> 00:06:30,880
at 8080 port which is the dashboard you

155
00:06:30,880 --> 00:06:31,840
could see

156
00:06:31,840 --> 00:06:35,440
at the screenshot and the

157
00:06:35,440 --> 00:06:37,680
the the wizard

158
00:06:37,680 --> 00:06:40,639
launch wizard just provides you with the

159
00:06:40,639 --> 00:06:43,039
hints that the default data

160
00:06:43,039 --> 00:06:46,160
must be changed because by default it's

161
00:06:46,160 --> 00:06:50,160
admin admin just like everywhere

162
00:06:50,400 --> 00:06:54,400
if we change it from the web interface

163
00:06:54,400 --> 00:06:56,880
the installation wizard prompts you to

164
00:06:56,880 --> 00:06:58,560
do that but unfortunately they do not

165
00:06:58,560 --> 00:07:01,759
prompt that it use post

166
00:07:01,759 --> 00:07:04,160
database

167
00:07:04,160 --> 00:07:06,319
and if we can connect to

168
00:07:06,319 --> 00:07:08,400
port 5432

169
00:07:08,400 --> 00:07:10,800
all of the hadoop projects

170
00:07:10,800 --> 00:07:13,680
basically inner ones would

171
00:07:13,680 --> 00:07:15,520
always get access

172
00:07:15,520 --> 00:07:16,639
to the

173
00:07:16,639 --> 00:07:19,199
host so we can connect to the database

174
00:07:19,199 --> 00:07:20,160
with the

175
00:07:20,160 --> 00:07:22,800
default base sql

176
00:07:22,800 --> 00:07:25,599
with the m vary

177
00:07:25,599 --> 00:07:28,400
and then we will see two charts

178
00:07:28,400 --> 00:07:30,960
user identification and user

179
00:07:30,960 --> 00:07:33,039
what we're interested is user

180
00:07:33,039 --> 00:07:36,400
identification authentication of course

181
00:07:36,400 --> 00:07:39,198
here we can see

182
00:07:39,599 --> 00:07:43,039
the authentication key

183
00:07:43,039 --> 00:07:46,319
if we just take a look at github

184
00:07:46,319 --> 00:07:49,039
with the ambari default

185
00:07:49,039 --> 00:07:52,400
admin password you can find it

186
00:07:52,400 --> 00:07:55,440
and update user authentication set

187
00:07:55,440 --> 00:07:58,800
authentication key and change it to

188
00:07:58,800 --> 00:08:01,120
admin admin and get access to the

189
00:08:01,120 --> 00:08:02,879
interface

190
00:08:02,879 --> 00:08:04,879
so as far as you can see

191
00:08:04,879 --> 00:08:08,319
the exploit here runs

192
00:08:08,319 --> 00:08:12,280
very very simply

193
00:08:12,879 --> 00:08:15,120
it's just primary school level but it

194
00:08:15,120 --> 00:08:17,759
may lead to very sad consequences for

195
00:08:17,759 --> 00:08:20,240
organizations

196
00:08:20,240 --> 00:08:21,280
because it

197
00:08:21,280 --> 00:08:22,240
gives

198
00:08:22,240 --> 00:08:24,800
admin privileges to everyone who manages

199
00:08:24,800 --> 00:08:26,960
the cluster you can

200
00:08:26,960 --> 00:08:29,759
encrypt it you can delete whatever you

201
00:08:29,759 --> 00:08:32,159
like to delete etc so it poses lots of

202
00:08:32,159 --> 00:08:33,599
threads

203
00:08:33,599 --> 00:08:36,000
we follow with hue hadoop user

204
00:08:36,000 --> 00:08:38,159
experience which is a

205
00:08:38,159 --> 00:08:41,200
web interface to administer

206
00:08:41,200 --> 00:08:42,479
hadoop

207
00:08:42,479 --> 00:08:45,120
echo system elements it's just like

208
00:08:45,120 --> 00:08:47,680
ambari with just one assumption

209
00:08:47,680 --> 00:08:51,359
in this interface we can use

210
00:08:52,720 --> 00:08:54,720
connection to different sources to

211
00:08:54,720 --> 00:08:57,519
analyze data so we can interact with

212
00:08:57,519 --> 00:08:59,519
hadoop hdfs

213
00:08:59,519 --> 00:09:01,279
hbase

214
00:09:01,279 --> 00:09:03,360
s3

215
00:09:03,360 --> 00:09:06,839
compatible storage is uh like

216
00:09:06,839 --> 00:09:09,839
azure google cloud etc

217
00:09:09,839 --> 00:09:14,640
in this monstrous tool with a very

218
00:09:14,640 --> 00:09:17,440
complicated interface which is not an

219
00:09:17,440 --> 00:09:20,480
intuitive ui

220
00:09:20,720 --> 00:09:22,399
they tried to include

221
00:09:22,399 --> 00:09:24,880
everything in there and this

222
00:09:24,880 --> 00:09:26,800
user interface

223
00:09:26,800 --> 00:09:30,000
including data access and the analysis

224
00:09:30,000 --> 00:09:30,959
tool

225
00:09:30,959 --> 00:09:33,519
you can run jobs on

226
00:09:33,519 --> 00:09:35,519
cluster workers

227
00:09:35,519 --> 00:09:39,360
and interacts and process our big data

228
00:09:39,360 --> 00:09:41,279
thus you can also have

229
00:09:41,279 --> 00:09:43,600
an ability to connect to the relational

230
00:09:43,600 --> 00:09:45,040
database

231
00:09:45,040 --> 00:09:47,680
like hive and everything works and works

232
00:09:47,680 --> 00:09:49,760
quite well as far as you can see here on

233
00:09:49,760 --> 00:09:51,440
the slide

234
00:09:51,440 --> 00:09:53,040
we move on and

235
00:09:53,040 --> 00:09:54,399
hugh

236
00:09:54,399 --> 00:09:55,920
launches

237
00:09:55,920 --> 00:09:57,839
the port

238
00:09:57,839 --> 00:10:00,240
quarter eight four eight

239
00:10:00,240 --> 00:10:01,760
and the first

240
00:10:01,760 --> 00:10:05,120
user that logs in sets the username and

241
00:10:05,120 --> 00:10:06,320
password

242
00:10:06,320 --> 00:10:09,040
for administrator and sets the super

243
00:10:09,040 --> 00:10:10,959
user with maximum

244
00:10:10,959 --> 00:10:12,560
privileges

245
00:10:12,560 --> 00:10:14,800
this screenshot shows you how it's all

246
00:10:14,800 --> 00:10:17,040
organized i was reacting like jackie

247
00:10:17,040 --> 00:10:18,959
chan in this pic

248
00:10:18,959 --> 00:10:21,360
i was very much surprised to the to this

249
00:10:21,360 --> 00:10:22,720
authentication

250
00:10:22,720 --> 00:10:25,120
approach because when we set a

251
00:10:25,120 --> 00:10:28,240
default data of

252
00:10:28,399 --> 00:10:31,279
user and administrator in such

253
00:10:31,279 --> 00:10:32,720
a fashion

254
00:10:32,720 --> 00:10:35,279
which provides us full administrative

255
00:10:35,279 --> 00:10:37,200
control over the entire hadoop cluster

256
00:10:37,200 --> 00:10:39,440
we get access to any configuration of

257
00:10:39,440 --> 00:10:41,200
any element

258
00:10:41,200 --> 00:10:44,880
and we get access to data as well

259
00:10:44,880 --> 00:10:48,160
and just one big icing on the cake we

260
00:10:48,160 --> 00:10:49,279
get a

261
00:10:49,279 --> 00:10:51,519
remote node

262
00:10:51,519 --> 00:10:54,880
locution with the arbiters this is the

263
00:10:54,880 --> 00:10:55,760
hue

264
00:10:55,760 --> 00:10:57,760
functionality and that

265
00:10:57,760 --> 00:11:00,640
helps you get rc at all of the cluster

266
00:11:00,640 --> 00:11:04,399
nodes by default this authentication you

267
00:11:04,399 --> 00:11:06,480
username password

268
00:11:06,480 --> 00:11:09,760
is used here by default but here is

269
00:11:09,760 --> 00:11:12,399
capable in terms of authentication it

270
00:11:12,399 --> 00:11:14,560
use ldap

271
00:11:14,560 --> 00:11:16,560
saml

272
00:11:16,560 --> 00:11:17,839
etc

273
00:11:17,839 --> 00:11:19,600
it's not included by default but they

274
00:11:19,600 --> 00:11:21,760
all include it

275
00:11:21,760 --> 00:11:25,200
and can be configured and this is how

276
00:11:25,200 --> 00:11:27,360
the password and

277
00:11:27,360 --> 00:11:29,279
the username

278
00:11:29,279 --> 00:11:31,839
are set here in the system

279
00:11:31,839 --> 00:11:34,079
let's just take a look uh what we can do

280
00:11:34,079 --> 00:11:36,000
with the user interface we get the

281
00:11:36,000 --> 00:11:39,040
entire admin control we can adjust this

282
00:11:39,040 --> 00:11:41,680
cluster remove the components change the

283
00:11:41,680 --> 00:11:43,200
configuration

284
00:11:43,200 --> 00:11:45,600
edit

285
00:11:45,680 --> 00:11:47,200
accounts

286
00:11:47,200 --> 00:11:49,120
let me change

287
00:11:49,120 --> 00:11:50,320
access

288
00:11:50,320 --> 00:11:52,560
by changing

289
00:11:52,560 --> 00:11:55,839
login password and we can look through

290
00:11:55,839 --> 00:11:57,440
all of the clusters

291
00:11:57,440 --> 00:12:00,079
thus we can see all of the logs uh

292
00:12:00,079 --> 00:12:04,399
from everywhere and we can use them

293
00:12:04,959 --> 00:12:06,639
we can use them further we get the

294
00:12:06,639 --> 00:12:10,000
entire control over the creation of jobs

295
00:12:10,000 --> 00:12:13,040
at all of the nodes of the cluster you

296
00:12:13,040 --> 00:12:14,480
can see this

297
00:12:14,480 --> 00:12:17,440
in the interface you can

298
00:12:17,440 --> 00:12:19,839
remove a job which was launched like for

299
00:12:19,839 --> 00:12:23,040
example 700 days ago and all of the

300
00:12:23,040 --> 00:12:24,399
analysis

301
00:12:24,399 --> 00:12:26,880
will unfortunately be lost what else can

302
00:12:26,880 --> 00:12:30,320
we do with hue we get access to

303
00:12:30,320 --> 00:12:32,000
hdfs

304
00:12:32,000 --> 00:12:35,440
data hadoop distributed file system

305
00:12:35,440 --> 00:12:36,839
read write

306
00:12:36,839 --> 00:12:38,399
delete

307
00:12:38,399 --> 00:12:40,880
encrypt

308
00:12:40,880 --> 00:12:43,040
to violate the

309
00:12:43,040 --> 00:12:45,920
operations of the company we can get

310
00:12:45,920 --> 00:12:48,320
access

311
00:12:48,320 --> 00:12:49,519
to the

312
00:12:49,519 --> 00:12:50,839
connected

313
00:12:50,839 --> 00:12:54,720
sources that are used for read and write

314
00:12:54,720 --> 00:12:56,959
we can also delete that data and we get

315
00:12:56,959 --> 00:12:59,200
an excellent opportunity

316
00:12:59,200 --> 00:13:01,440
to get access to

317
00:13:01,440 --> 00:13:03,680
the

318
00:13:04,839 --> 00:13:09,120
dbms and s3 directly from

319
00:13:09,120 --> 00:13:12,160
the web interface and we can upload

320
00:13:12,160 --> 00:13:14,480
everything from the cluster using the

321
00:13:14,480 --> 00:13:15,279
same

322
00:13:15,279 --> 00:13:18,399
web interface and we can dump

323
00:13:18,399 --> 00:13:21,839
all these petabytes of data

324
00:13:22,959 --> 00:13:26,399
the most interesting thing rce and

325
00:13:26,399 --> 00:13:27,760
running

326
00:13:27,760 --> 00:13:28,880
code on

327
00:13:28,880 --> 00:13:31,680
hadoop clusters with the so-called

328
00:13:31,680 --> 00:13:33,120
editors

329
00:13:33,120 --> 00:13:35,440
here at these screenshots you can see

330
00:13:35,440 --> 00:13:39,120
them and there's a great number of them

331
00:13:39,120 --> 00:13:41,040
starting from

332
00:13:41,040 --> 00:13:43,920
marshall and ending with

333
00:13:43,920 --> 00:13:45,519
spark or

334
00:13:45,519 --> 00:13:49,440
pi sparks kala or r those who can use

335
00:13:49,440 --> 00:13:50,480
them

336
00:13:50,480 --> 00:13:52,959
can try them

337
00:13:52,959 --> 00:13:56,880
i chose this you know they compiled the

338
00:13:56,880 --> 00:13:58,880
version

339
00:13:58,880 --> 00:14:03,279
where we put the pass and the location

340
00:14:03,279 --> 00:14:06,160
of our local file

341
00:14:06,160 --> 00:14:08,320
and we can send there the number of

342
00:14:08,320 --> 00:14:10,880
nodes where we can run this code and we

343
00:14:10,880 --> 00:14:14,000
press play and we

344
00:14:14,000 --> 00:14:17,360
we get over and take over

345
00:14:17,360 --> 00:14:19,760
hadoop

346
00:14:19,760 --> 00:14:21,760
as for hue

347
00:14:21,760 --> 00:14:23,680
according to the shortened

348
00:14:23,680 --> 00:14:26,040
statistics there are

349
00:14:26,040 --> 00:14:29,440
579 hosts in china and the united states

350
00:14:29,440 --> 00:14:30,959
mainly

351
00:14:30,959 --> 00:14:32,880
that are

352
00:14:32,880 --> 00:14:35,760
searched very simply

353
00:14:35,760 --> 00:14:38,800
by query titled hugh welcome to you

354
00:14:38,800 --> 00:14:40,560
and they are launched

355
00:14:40,560 --> 00:14:42,240
in

356
00:14:42,240 --> 00:14:45,440
cloud providers

357
00:14:45,440 --> 00:14:48,560
alibaba amazon oracle etc

358
00:14:48,560 --> 00:14:50,800
they

359
00:14:50,800 --> 00:14:53,680
deploy hue as part of the hadoop

360
00:14:53,680 --> 00:14:56,639
component in the default configuration

361
00:14:56,639 --> 00:14:58,800
so if we do not remove the

362
00:14:58,800 --> 00:15:01,440
the tick from there from the tick box

363
00:15:01,440 --> 00:15:02,959
check box

364
00:15:02,959 --> 00:15:04,320
this uh

365
00:15:04,320 --> 00:15:05,839
quarter four

366
00:15:05,839 --> 00:15:08,160
port interface will be available and the

367
00:15:08,160 --> 00:15:11,360
practice reveals that admins do not

368
00:15:11,360 --> 00:15:14,399
read any manual on deploying

369
00:15:14,399 --> 00:15:16,000
hadoop

370
00:15:16,000 --> 00:15:18,320
in amazon it's actually printed there on

371
00:15:18,320 --> 00:15:19,360
page

372
00:15:19,360 --> 00:15:22,880
18 you just need to read there

373
00:15:22,880 --> 00:15:23,920
and

374
00:15:23,920 --> 00:15:28,000
showdown does not reflect the entire

375
00:15:28,000 --> 00:15:30,720
picture but basically reflects quite a

376
00:15:30,720 --> 00:15:35,279
lot so this very very simple

377
00:15:35,519 --> 00:15:38,160
scenario helps us

378
00:15:38,160 --> 00:15:40,639
take over this big

379
00:15:40,639 --> 00:15:42,560
solution and

380
00:15:42,560 --> 00:15:45,440
take over the company's

381
00:15:45,440 --> 00:15:48,320
activities

382
00:15:48,639 --> 00:15:50,959
so very often we can see

383
00:15:50,959 --> 00:15:52,880
lazy administrators

384
00:15:52,880 --> 00:15:54,800
that

385
00:15:54,800 --> 00:15:57,519
managed to

386
00:15:57,519 --> 00:16:01,199
let this misconfig stay in the system

387
00:16:01,199 --> 00:16:03,279
and there are

388
00:16:03,279 --> 00:16:06,320
sometimes when you have to

389
00:16:06,320 --> 00:16:08,639
spend quite a lot of time which company

390
00:16:08,639 --> 00:16:10,639
owns what and what belongs to what

391
00:16:10,639 --> 00:16:11,839
company

392
00:16:11,839 --> 00:16:14,160
and we tried to contact uh some of the

393
00:16:14,160 --> 00:16:15,680
providers just

394
00:16:15,680 --> 00:16:18,639
making attempts to make this world

395
00:16:18,639 --> 00:16:20,560
a safer place

396
00:16:20,560 --> 00:16:22,480
we are done with hadoop and would like

397
00:16:22,480 --> 00:16:24,560
to say a few words about zookeeper

398
00:16:24,560 --> 00:16:26,480
management layer for cluster

399
00:16:26,480 --> 00:16:29,839
configuration here it's the console

400
00:16:29,839 --> 00:16:32,560
solution you can connect it

401
00:16:32,560 --> 00:16:35,680
connect it with the zookeeper sli here's

402
00:16:35,680 --> 00:16:37,279
the link

403
00:16:37,279 --> 00:16:40,320
by which you can download it and port 21

404
00:16:40,320 --> 00:16:42,480
nt1 that's

405
00:16:42,480 --> 00:16:44,800
where zookeeper sits and listens to this

406
00:16:44,800 --> 00:16:47,040
port that it listens to

407
00:16:47,040 --> 00:16:49,199
you change the configuration on the node

408
00:16:49,199 --> 00:16:51,440
and it changes on all of the nodes of

409
00:16:51,440 --> 00:16:53,759
the cluster with the ls get

410
00:16:53,759 --> 00:16:57,680
create and delete very simple commands

411
00:16:57,680 --> 00:17:00,079
we can delete configuration we can

412
00:17:00,079 --> 00:17:02,839
create delete

413
00:17:02,839 --> 00:17:05,839
whatever we can

414
00:17:05,839 --> 00:17:08,319
achieve the same effect as with hugh and

415
00:17:08,319 --> 00:17:12,480
mbari but with this console

416
00:17:12,480 --> 00:17:14,799
zookeeper solution

417
00:17:14,799 --> 00:17:18,000
by default they do not imply any

418
00:17:18,000 --> 00:17:20,799
authentication whatsoever

419
00:17:20,799 --> 00:17:23,280
you can configure it

420
00:17:23,280 --> 00:17:26,480
but practice reveals that very often

421
00:17:26,480 --> 00:17:28,640
it's on and it's running and it's

422
00:17:28,640 --> 00:17:31,039
included and anyone can use it

423
00:17:31,039 --> 00:17:32,720
unfortunately

424
00:17:32,720 --> 00:17:34,240
we checked this

425
00:17:34,240 --> 00:17:36,559
and now we're going to talk about data

426
00:17:36,559 --> 00:17:38,320
access

427
00:17:38,320 --> 00:17:41,679
three popular tools hbase

428
00:17:41,679 --> 00:17:44,960
which listens to 170 10 port

429
00:17:44,960 --> 00:17:47,039
for the entire hadoop it's available

430
00:17:47,039 --> 00:17:49,039
without any authentication it routes

431
00:17:49,039 --> 00:17:50,559
allows you to read

432
00:17:50,559 --> 00:17:53,679
config settings

433
00:17:53,679 --> 00:17:55,120
charts logs

434
00:17:55,120 --> 00:17:58,640
and process metrics it allows us to see

435
00:17:58,640 --> 00:18:02,160
what kind of cluster there is and we can

436
00:18:02,160 --> 00:18:03,280
use it

437
00:18:03,280 --> 00:18:05,440
for upcoming attacks

438
00:18:05,440 --> 00:18:07,520
followed by a hive

439
00:18:07,520 --> 00:18:09,280
which listens to

440
00:18:09,280 --> 00:18:11,520
102

441
00:18:11,520 --> 00:18:13,440
that's the port it

442
00:18:13,440 --> 00:18:16,240
reads the configuration of the service

443
00:18:16,240 --> 00:18:18,160
logs metrics

444
00:18:18,160 --> 00:18:19,440
and

445
00:18:19,440 --> 00:18:21,840
that's where you can get a lot of

446
00:18:21,840 --> 00:18:23,679
interesting information

447
00:18:23,679 --> 00:18:25,760
presto

448
00:18:25,760 --> 00:18:28,799
that's a funny thing and

449
00:18:28,799 --> 00:18:30,720
let me read it

450
00:18:30,720 --> 00:18:33,200
so here we have this

451
00:18:33,200 --> 00:18:35,360
chart uh login

452
00:18:35,360 --> 00:18:38,480
and we have this username and where we

453
00:18:38,480 --> 00:18:41,039
have this password

454
00:18:41,039 --> 00:18:44,000
we get this inscription password not

455
00:18:44,000 --> 00:18:47,280
allowed over http and i was looking like

456
00:18:47,280 --> 00:18:48,720
this panda

457
00:18:48,720 --> 00:18:52,640
like saying what the hell is going on

458
00:18:53,360 --> 00:18:58,479
and it runs very smoothly by default

459
00:18:59,039 --> 00:19:00,240
and

460
00:19:00,240 --> 00:19:02,160
more interesting information followers

461
00:19:02,160 --> 00:19:04,000
just take a look

462
00:19:04,000 --> 00:19:05,360
now we're going to

463
00:19:05,360 --> 00:19:06,640
take a look at

464
00:19:06,640 --> 00:19:09,120
data processing layer

465
00:19:09,120 --> 00:19:12,880
hadoop hdfs and yarn these are the main

466
00:19:12,880 --> 00:19:15,280
components by hadoop everything is

467
00:19:15,280 --> 00:19:17,600
centered around hdfs

468
00:19:17,600 --> 00:19:20,400
it has master slave architecture we have

469
00:19:20,400 --> 00:19:23,280
name nodes and data nodes

470
00:19:23,280 --> 00:19:24,960
these are the ones

471
00:19:24,960 --> 00:19:27,200
that are responsible for

472
00:19:27,200 --> 00:19:28,880
information storage

473
00:19:28,880 --> 00:19:32,080
as far as this architecture

474
00:19:32,080 --> 00:19:34,320
we don't need to know it we have master

475
00:19:34,320 --> 00:19:37,280
slave architecture and two options and

476
00:19:37,280 --> 00:19:39,039
yarn is the same

477
00:19:39,039 --> 00:19:42,400
yarn is the engine which processes

478
00:19:42,400 --> 00:19:45,760
data processing

479
00:19:45,760 --> 00:19:48,160
so that's master slave architecture we

480
00:19:48,160 --> 00:19:50,320
have a resource manager split into

481
00:19:50,320 --> 00:19:52,559
scheduler

482
00:19:52,559 --> 00:19:56,960
and app manager and we have node manager

483
00:19:57,520 --> 00:19:59,520
we have two components there

484
00:19:59,520 --> 00:20:02,400
app master

485
00:20:02,400 --> 00:20:04,000
launch that launches

486
00:20:04,000 --> 00:20:06,400
container that's how this service works

487
00:20:06,400 --> 00:20:08,720
more more or less now

488
00:20:08,720 --> 00:20:11,520
let's see how we can exploit its

489
00:20:11,520 --> 00:20:14,000
misconfigs

490
00:20:14,000 --> 00:20:17,039
with hadoop ipc rpc

491
00:20:17,039 --> 00:20:18,480
the protocol

492
00:20:18,480 --> 00:20:20,960
uh by which we interact

493
00:20:20,960 --> 00:20:26,640
name nodes of hadoop at 80 20 port

494
00:20:28,320 --> 00:20:31,679
and to get access to hdfs

495
00:20:31,679 --> 00:20:33,840
by the use of this protocol we just need

496
00:20:33,840 --> 00:20:37,280
to craft four xml files

497
00:20:37,280 --> 00:20:40,720
if this authentication does not imply

498
00:20:40,720 --> 00:20:44,159
we can interact with the file system

499
00:20:44,159 --> 00:20:46,720
directly i will be showing it to more in

500
00:20:46,720 --> 00:20:49,679
detail and we can launch these

501
00:20:49,679 --> 00:20:53,520
applications on nodes by yarn by using

502
00:20:53,520 --> 00:20:55,120
yarn

503
00:20:55,120 --> 00:20:57,760
yarn is just a skeleton of the

504
00:20:57,760 --> 00:20:59,440
any yarn app

505
00:20:59,440 --> 00:21:01,200
by very simple

506
00:21:01,200 --> 00:21:04,000
manipulations it turns into

507
00:21:04,000 --> 00:21:06,240
rc

508
00:21:06,240 --> 00:21:06,960
and

509
00:21:06,960 --> 00:21:08,799
you can find it

510
00:21:08,799 --> 00:21:11,360
find more information

511
00:21:11,360 --> 00:21:14,240
on it from this github link which i

512
00:21:14,240 --> 00:21:16,400
showed you at the previous slide a few

513
00:21:16,400 --> 00:21:21,440
words about hadoop pcr pc coresight xml

514
00:21:21,440 --> 00:21:24,880
is needed here and its value

515
00:21:24,880 --> 00:21:27,760
i hdfs

516
00:21:27,760 --> 00:21:31,440
namespace and take a look at hadoop ui

517
00:21:31,440 --> 00:21:35,360
at 500 and 570 port

518
00:21:35,360 --> 00:21:36,960
that you listen

519
00:21:36,960 --> 00:21:38,240
and you find

520
00:21:38,240 --> 00:21:40,080
all the values needed

521
00:21:40,080 --> 00:21:42,960
hdfs site xml

522
00:21:42,960 --> 00:21:45,600
so if you're interested about namespace

523
00:21:45,600 --> 00:21:47,520
name node id

524
00:21:47,520 --> 00:21:49,840
all of the name nodes there can be a

525
00:21:49,840 --> 00:21:54,080
great number of them you can enlist them

526
00:21:54,080 --> 00:21:55,360
we can

527
00:21:55,360 --> 00:21:57,039
get it

528
00:21:57,039 --> 00:21:59,840
in this magic interface

529
00:21:59,840 --> 00:22:02,799
file number three

530
00:22:03,280 --> 00:22:04,080
mob

531
00:22:04,080 --> 00:22:07,360
market site

532
00:22:07,919 --> 00:22:12,520
everything which deals with

533
00:22:13,520 --> 00:22:17,360
the jobs in the cluster

534
00:22:18,640 --> 00:22:21,120
jobs in the cluster you can find it on

535
00:22:21,120 --> 00:22:25,200
ports uh one eight nine eight eight etc

536
00:22:25,200 --> 00:22:28,960
and one lost file is the yarn side

537
00:22:28,960 --> 00:22:30,960
that's where you can find

538
00:22:30,960 --> 00:22:32,880
name

539
00:22:32,880 --> 00:22:36,880
node dns or simply name node name node

540
00:22:36,880 --> 00:22:38,960
we put this in the value fields and we

541
00:22:38,960 --> 00:22:40,640
are ready to interact with

542
00:22:40,640 --> 00:22:43,440
hadoop hdfs

543
00:22:43,440 --> 00:22:47,280
so in order not to locally run hadoop

544
00:22:47,280 --> 00:22:49,120
please use

545
00:22:49,120 --> 00:22:49,919
this

546
00:22:49,919 --> 00:22:51,520
dockerfile

547
00:22:51,520 --> 00:22:52,880
the image

548
00:22:52,880 --> 00:22:56,559
i just change the version if necessary

549
00:22:56,559 --> 00:22:59,280
when we test this cluster

550
00:22:59,280 --> 00:23:00,000
we

551
00:23:00,000 --> 00:23:01,679
assemble

552
00:23:01,679 --> 00:23:03,280
docker image

553
00:23:03,280 --> 00:23:05,280
launch the container

554
00:23:05,280 --> 00:23:07,120
copy the xml

555
00:23:07,120 --> 00:23:11,200
file into configs and these

556
00:23:11,200 --> 00:23:14,240
configs can be copied and we copy

557
00:23:14,240 --> 00:23:16,799
property

558
00:23:18,080 --> 00:23:18,710
and

559
00:23:18,710 --> 00:23:21,520
[Music]

560
00:23:21,520 --> 00:23:23,600
make a few adjustments to

561
00:23:23,600 --> 00:23:28,320
vi etc hosts so that it runs smoothly

562
00:23:28,320 --> 00:23:31,679
so we fit it to hadoop we feed our

563
00:23:31,679 --> 00:23:34,000
config files to hadoop

564
00:23:34,000 --> 00:23:38,159
with a hadoop config we the list

565
00:23:38,159 --> 00:23:39,440
this uh

566
00:23:39,440 --> 00:23:42,880
directory we try to create

567
00:23:42,880 --> 00:23:44,240
a default

568
00:23:44,240 --> 00:23:46,080
named hacked

569
00:23:46,080 --> 00:23:48,240
trivial message appears on the screen

570
00:23:48,240 --> 00:23:52,240
permission denied but it's all simple um

571
00:23:52,240 --> 00:23:54,000
to change that

572
00:23:54,000 --> 00:23:57,440
so it seems like um we can export

573
00:23:57,440 --> 00:23:59,600
it

574
00:24:01,760 --> 00:24:04,799
and voila we have the opportunity to

575
00:24:04,799 --> 00:24:06,640
work with the file system and you know

576
00:24:06,640 --> 00:24:09,600
change the data and do whatever criminal

577
00:24:09,600 --> 00:24:12,480
things we want to do

578
00:24:12,559 --> 00:24:15,520
in apache spark

579
00:24:15,600 --> 00:24:18,400
which is an alternative for yarn

580
00:24:18,400 --> 00:24:20,960
a very popular tool that

581
00:24:20,960 --> 00:24:23,279
happens and that that is often

582
00:24:23,279 --> 00:24:25,679
installed together with hadoop and it is

583
00:24:25,679 --> 00:24:27,840
responsible for data processing within

584
00:24:27,840 --> 00:24:30,480
the cluster

585
00:24:30,880 --> 00:24:33,760
and traditionally spark security

586
00:24:33,760 --> 00:24:36,640
things you need to know

587
00:24:36,720 --> 00:24:40,320
security inspect yeah so this is uh

588
00:24:40,320 --> 00:24:42,240
quite obvious and that does not require

589
00:24:42,240 --> 00:24:44,480
any comments by default this is

590
00:24:44,480 --> 00:24:49,039
this is it and let's see how we can work

591
00:24:49,039 --> 00:24:50,799
with spark

592
00:24:50,799 --> 00:24:54,000
so spark has a remote procedure called

593
00:24:54,000 --> 00:24:56,400
protocol

594
00:24:56,400 --> 00:24:58,840
we have a web

595
00:24:58,840 --> 00:25:02,320
interface same as for all uh hadoop

596
00:25:02,320 --> 00:25:04,880
tools 8080

597
00:25:04,880 --> 00:25:07,679
accessible without authentication and

598
00:25:07,679 --> 00:25:10,159
allows you to get the preliminary data

599
00:25:10,159 --> 00:25:12,960
on what cluster is in front of you and

600
00:25:12,960 --> 00:25:15,039
we see here some infor gunning the

601
00:25:15,039 --> 00:25:16,240
workers

602
00:25:16,240 --> 00:25:18,480
active workers

603
00:25:18,480 --> 00:25:21,360
inactive workers resources memory stuff

604
00:25:21,360 --> 00:25:22,799
like that

605
00:25:22,799 --> 00:25:25,120
and

606
00:25:25,840 --> 00:25:28,400
with spark rpc

607
00:25:28,400 --> 00:25:30,400
the calls are listened at

608
00:25:30,400 --> 00:25:35,200
1770 at the spark masternode

609
00:25:35,279 --> 00:25:38,159
and we can actually

610
00:25:38,799 --> 00:25:42,320
detect it with a map as is a go-to tool

611
00:25:42,320 --> 00:25:45,360
for all the pen testers

612
00:25:45,360 --> 00:25:48,640
but unfortunately the way nmap

613
00:25:48,640 --> 00:25:50,880
tries to

614
00:25:50,880 --> 00:25:53,360
identify the spark

615
00:25:53,360 --> 00:25:56,159
is not sufficient because the

616
00:25:56,159 --> 00:25:58,960
fingerprints are not written well so

617
00:25:58,960 --> 00:26:01,600
it's better to run a script like this

618
00:26:01,600 --> 00:26:03,679
that allows you to identify a bunch of

619
00:26:03,679 --> 00:26:07,440
spark on 7070 and

620
00:26:08,400 --> 00:26:10,799
the authentication not required is a

621
00:26:10,799 --> 00:26:13,679
very useful piece of information

622
00:26:13,679 --> 00:26:15,440
so apache spark

623
00:26:15,440 --> 00:26:17,919
works in two different modes we have a

624
00:26:17,919 --> 00:26:20,480
client mode so let's

625
00:26:20,480 --> 00:26:24,880
learn what it is to understand uh

626
00:26:24,880 --> 00:26:25,760
and

627
00:26:25,760 --> 00:26:28,720
we have apache spark master interface at

628
00:26:28,720 --> 00:26:33,279
8080 we have our pc at 7070

629
00:26:33,279 --> 00:26:35,120
and

630
00:26:35,120 --> 00:26:37,919
if the cluster works in a client mode

631
00:26:37,919 --> 00:26:40,240
then the driver

632
00:26:40,240 --> 00:26:42,480
which is responsible for

633
00:26:42,480 --> 00:26:45,200
slicing and chunking the tasks and

634
00:26:45,200 --> 00:26:46,480
sending them to

635
00:26:46,480 --> 00:26:48,559
the cluster manager using the rpc

636
00:26:48,559 --> 00:26:49,919
protocol

637
00:26:49,919 --> 00:26:52,960
and then the cluster manager would send

638
00:26:52,960 --> 00:26:56,559
the data to the workers so the driver

639
00:26:56,559 --> 00:27:00,960
is placed on the local workstation and

640
00:27:00,960 --> 00:27:02,720
is used to connect to

641
00:27:02,720 --> 00:27:04,640
the cluster manager

642
00:27:04,640 --> 00:27:09,200
in this case we can of course get an rce

643
00:27:09,200 --> 00:27:11,679
or the functionality that is

644
00:27:11,679 --> 00:27:14,080
uh provided by precious park so using

645
00:27:14,080 --> 00:27:16,720
this snippet

646
00:27:17,360 --> 00:27:21,279
of code by sending the ip address of

647
00:27:21,279 --> 00:27:23,039
sparc rpc

648
00:27:23,039 --> 00:27:25,440
and

649
00:27:26,640 --> 00:27:27,840
sending

650
00:27:27,840 --> 00:27:30,080
the address of the machine where we have

651
00:27:30,080 --> 00:27:32,000
the driver running our attacking

652
00:27:32,000 --> 00:27:33,760
workstation

653
00:27:33,760 --> 00:27:37,120
so by parallelizing the commands

654
00:27:37,120 --> 00:27:39,039
using this snippet

655
00:27:39,039 --> 00:27:42,159
we can run the needed id on all the

656
00:27:42,159 --> 00:27:43,360
nodes

657
00:27:43,360 --> 00:27:46,960
of the cluster this is client mode

658
00:27:46,960 --> 00:27:49,120
and there's another option of spock

659
00:27:49,120 --> 00:27:52,559
running in a cluster mode

660
00:27:53,520 --> 00:27:56,000
and obviously the driver is not on our

661
00:27:56,000 --> 00:27:57,440
laptop then

662
00:27:57,440 --> 00:27:58,960
but

663
00:27:58,960 --> 00:28:01,520
rather work with the cluster manager

664
00:28:01,520 --> 00:28:05,120
using the rpc protocol on 7077

665
00:28:05,120 --> 00:28:06,559
port and

666
00:28:06,559 --> 00:28:08,159
we say hey

667
00:28:08,159 --> 00:28:09,840
here's the code we need to execute and

668
00:28:09,840 --> 00:28:11,360
you need to decide

669
00:28:11,360 --> 00:28:14,719
where to run the driver

670
00:28:14,840 --> 00:28:17,120
accordingly it's about the same we

671
00:28:17,120 --> 00:28:20,640
cannot do anything on pi spark

672
00:28:20,640 --> 00:28:22,000
because

673
00:28:22,000 --> 00:28:24,559
those are the

674
00:28:24,559 --> 00:28:26,399
peculiarities and

675
00:28:26,399 --> 00:28:28,480
regarding the cluster mode

676
00:28:28,480 --> 00:28:30,159
when the driver registers the

677
00:28:30,159 --> 00:28:32,480
application working together with the

678
00:28:32,480 --> 00:28:33,840
cluster manager

679
00:28:33,840 --> 00:28:37,120
it assigns the workers

680
00:28:37,840 --> 00:28:39,760
and the customer manager sends this

681
00:28:39,760 --> 00:28:42,720
information to the workers

682
00:28:42,720 --> 00:28:46,159
so it would be a logical idea to

683
00:28:46,159 --> 00:28:48,080
say that the driver only initiates the

684
00:28:48,080 --> 00:28:49,919
registration

685
00:28:49,919 --> 00:28:53,200
that needs to be processed

686
00:28:53,200 --> 00:28:55,120
and then the workers

687
00:28:55,120 --> 00:28:58,320
connect using the rpc protocol

688
00:28:58,320 --> 00:28:59,600
with us

689
00:28:59,600 --> 00:29:02,480
and if this connection is lost then this

690
00:29:02,480 --> 00:29:04,559
trick will not work

691
00:29:04,559 --> 00:29:07,039
but quite often

692
00:29:07,039 --> 00:29:09,760
we still see this running and

693
00:29:09,760 --> 00:29:12,000
successfully executing

694
00:29:12,000 --> 00:29:13,600
and if the driver works in a cluster

695
00:29:13,600 --> 00:29:15,918
mode

696
00:29:16,320 --> 00:29:19,039
we can then run this color code

697
00:29:19,039 --> 00:29:21,760
the jar payload that is run on the given

698
00:29:21,760 --> 00:29:24,240
amount of worker nodes in a cluster mode

699
00:29:24,240 --> 00:29:27,120
and when the cluster is configured

700
00:29:27,120 --> 00:29:28,880
so this

701
00:29:28,880 --> 00:29:32,000
structure is

702
00:29:34,480 --> 00:29:37,919
some you know template that allows us to

703
00:29:37,919 --> 00:29:40,159
run some code we need to of course run

704
00:29:40,159 --> 00:29:42,480
install java

705
00:29:42,480 --> 00:29:44,720
create a jar file and then feed it to

706
00:29:44,720 --> 00:29:47,720
spark

707
00:29:55,360 --> 00:29:57,279
spark rest api

708
00:29:57,279 --> 00:29:59,679
has

709
00:29:59,760 --> 00:30:03,840
an option to walk through rest apis

710
00:30:04,799 --> 00:30:09,200
same as our pc and we can

711
00:30:09,200 --> 00:30:13,279
set tasks to spark using rest type apa

712
00:30:13,279 --> 00:30:15,039
and there's nothing to explain here we

713
00:30:15,039 --> 00:30:17,279
already have a metasploit module that

714
00:30:17,279 --> 00:30:18,640
allows us

715
00:30:18,640 --> 00:30:20,960
to get rc

716
00:30:20,960 --> 00:30:21,760
and

717
00:30:21,760 --> 00:30:23,919
you all can use metasploit right

718
00:30:23,919 --> 00:30:26,399
the idea is that the authentication is

719
00:30:26,399 --> 00:30:30,639
not needed and we can send a json

720
00:30:31,520 --> 00:30:33,279
to get an rc

721
00:30:33,279 --> 00:30:36,159
there's an automation tool sparky to

722
00:30:36,159 --> 00:30:38,080
avoid doing everything by hand not

723
00:30:38,080 --> 00:30:41,120
crafting the files

724
00:30:41,679 --> 00:30:43,919
you can use this link to download this

725
00:30:43,919 --> 00:30:47,120
utility from github

726
00:30:47,440 --> 00:30:48,840
get the

727
00:30:48,840 --> 00:30:50,799
dependencies and

728
00:30:50,799 --> 00:30:53,200
that's it

729
00:30:53,679 --> 00:30:55,520
so generally speaking this is a tool

730
00:30:55,520 --> 00:30:57,440
that allows you to do

731
00:30:57,440 --> 00:30:59,200
everything i told you about but in a

732
00:30:59,200 --> 00:31:01,120
more automated mode

733
00:31:01,120 --> 00:31:02,640
and

734
00:31:02,640 --> 00:31:05,760
talking about spark client mode rc

735
00:31:05,760 --> 00:31:09,039
we can use just one command to get our c

736
00:31:09,039 --> 00:31:11,600
through sparky and if we send spark

737
00:31:11,600 --> 00:31:13,279
master api

738
00:31:13,279 --> 00:31:14,320
uh to

739
00:31:14,320 --> 00:31:17,519
our driver machine then the command

740
00:31:17,519 --> 00:31:19,840
should be id and then three

741
00:31:19,840 --> 00:31:21,519
is the amount of the nodes of the

742
00:31:21,519 --> 00:31:24,880
cluster and with that we get the rc on

743
00:31:24,880 --> 00:31:26,399
the given nodes

744
00:31:26,399 --> 00:31:28,720
or cluster we can even do it for all the

745
00:31:28,720 --> 00:31:31,720
nodes

746
00:31:39,360 --> 00:31:42,158
we can do the same

747
00:31:42,320 --> 00:31:43,360
but

748
00:31:43,360 --> 00:31:45,200
automate the

749
00:31:45,200 --> 00:31:47,760
information gathering so using the

750
00:31:47,760 --> 00:31:51,200
script that is called cloud scripts

751
00:31:51,200 --> 00:31:53,679
we can get access to the internal

752
00:31:53,679 --> 00:31:55,919
infrastructure of the client

753
00:31:55,919 --> 00:31:59,840
using the credentials that we can change

754
00:31:59,840 --> 00:32:02,720
in aws and the digital option

755
00:32:02,720 --> 00:32:04,720
and the only thing we need here is just

756
00:32:04,720 --> 00:32:07,679
the access key and the token if we talk

757
00:32:07,679 --> 00:32:10,480
about amazon

758
00:32:11,120 --> 00:32:12,720
and on the screenshot below you see how

759
00:32:12,720 --> 00:32:14,640
it works

760
00:32:14,640 --> 00:32:17,760
and also this search secret script that

761
00:32:17,760 --> 00:32:19,200
allows you to

762
00:32:19,200 --> 00:32:20,559
find

763
00:32:20,559 --> 00:32:22,159
the secrets

764
00:32:22,159 --> 00:32:24,799
for the workers of spark cluster and

765
00:32:24,799 --> 00:32:26,840
using regular

766
00:32:26,840 --> 00:32:29,679
expressions you know get that beautiful

767
00:32:29,679 --> 00:32:31,519
output of this utility

768
00:32:31,519 --> 00:32:33,679
so

769
00:32:33,760 --> 00:32:37,919
with that we are close to conclusion

770
00:32:39,519 --> 00:32:42,000
and in this 40 minutes of my discussion

771
00:32:42,000 --> 00:32:42,880
of course

772
00:32:42,880 --> 00:32:45,679
it is very hard to overview

773
00:32:45,679 --> 00:32:46,960
this

774
00:32:46,960 --> 00:32:50,320
huge topic of hadoop cluster security

775
00:32:50,320 --> 00:32:52,320
and

776
00:32:52,320 --> 00:32:55,320
accordingly

777
00:32:56,240 --> 00:32:58,399
i think we've looked at some things and

778
00:32:58,399 --> 00:32:59,840
let me give you some

779
00:32:59,840 --> 00:33:03,360
advice so first of all we need to have

780
00:33:03,360 --> 00:33:06,320
layered security of hadoop cluster on

781
00:33:06,320 --> 00:33:09,120
all the abstraction layers management

782
00:33:09,120 --> 00:33:11,679
layer data storage

783
00:33:11,679 --> 00:33:14,559
you need to be

784
00:33:14,559 --> 00:33:17,279
medication wise

785
00:33:17,279 --> 00:33:18,480
you need to look through all the

786
00:33:18,480 --> 00:33:21,120
functionality of the tools

787
00:33:21,120 --> 00:33:24,640
we also need to isolate and segment the

788
00:33:24,640 --> 00:33:28,799
key infrastructure of the hadoop cluster

789
00:33:28,799 --> 00:33:31,279
according to zero trust and least

790
00:33:31,279 --> 00:33:33,440
privilege principles as you saw

791
00:33:33,440 --> 00:33:35,120
everything is turned off firewalls are

792
00:33:35,120 --> 00:33:36,640
turned off and

793
00:33:36,640 --> 00:33:39,760
some instruments some tools are

794
00:33:39,760 --> 00:33:42,480
just writing in bold red

795
00:33:42,480 --> 00:33:44,720
letters that you know to

796
00:33:44,720 --> 00:33:46,640
use it properly you need to turn the

797
00:33:46,640 --> 00:33:48,559
security off so

798
00:33:48,559 --> 00:33:50,320
you know if we are

799
00:33:50,320 --> 00:33:53,840
if we want uh security then we need to

800
00:33:53,840 --> 00:33:56,559
turn security on so everything that is

801
00:33:56,559 --> 00:33:58,960
off by default needs to be properly

802
00:33:58,960 --> 00:34:01,039
configured all those mechanisms are

803
00:34:01,039 --> 00:34:03,440
present there but they are not always

804
00:34:03,440 --> 00:34:04,799
easy

805
00:34:04,799 --> 00:34:07,840
to configure

806
00:34:08,639 --> 00:34:10,320
you will need to spend some time but of

807
00:34:10,320 --> 00:34:12,239
course this will pay back in the future

808
00:34:12,239 --> 00:34:14,639
when you know you see the intruders

809
00:34:14,639 --> 00:34:16,639
coming

810
00:34:16,639 --> 00:34:18,159
we also need to configure the

811
00:34:18,159 --> 00:34:22,239
authentication mechanisms and

812
00:34:22,239 --> 00:34:24,159
to ensure

813
00:34:24,159 --> 00:34:26,000
authorization is done properly we would

814
00:34:26,000 --> 00:34:28,159
like everything to work

815
00:34:28,159 --> 00:34:32,320
using normal protocols and

816
00:34:32,320 --> 00:34:35,839
to be able to use whatever we need

817
00:34:36,800 --> 00:34:40,000
so anything will be safer than

818
00:34:40,000 --> 00:34:41,599
you know this

819
00:34:41,599 --> 00:34:46,320
uh hue style password

820
00:34:46,800 --> 00:34:49,040
setup

821
00:34:49,040 --> 00:34:53,199
and as applicable to all the pen tests

822
00:34:53,440 --> 00:34:54,480
so

823
00:34:54,480 --> 00:34:57,440
you know password policy is a go-to

824
00:34:57,440 --> 00:35:00,640
different registries non

825
00:35:00,640 --> 00:35:03,920
dictionary puzzles uh mfa hardware

826
00:35:03,920 --> 00:35:04,960
tokens

827
00:35:04,960 --> 00:35:07,440
are the best choice

828
00:35:07,440 --> 00:35:11,200
and a strong application security

829
00:35:11,200 --> 00:35:15,200
and regular pen testing will be your

830
00:35:15,200 --> 00:35:17,280
path to success thank you indeed thank

831
00:35:17,280 --> 00:35:18,560
you indeed for being with us and for

832
00:35:18,560 --> 00:35:22,279
your attention thanks

833
00:35:33,280 --> 00:35:36,640
i think there's a question there right

834
00:35:39,520 --> 00:35:43,560
not very much

835
00:35:44,480 --> 00:35:48,480
yeah you can now ask your questions

836
00:35:52,960 --> 00:35:54,800
hi thanks for the presentation can you

837
00:35:54,800 --> 00:35:57,920
switch back to the sparky

838
00:35:57,920 --> 00:36:02,000
slide where you could upload the jar

839
00:36:06,160 --> 00:36:08,960
oh just uh simpler

840
00:36:08,960 --> 00:36:11,280
you should you just add authentication

841
00:36:11,280 --> 00:36:13,920
there yes uh there you have some options

842
00:36:13,920 --> 00:36:17,280
depending on your authentication schema

843
00:36:17,280 --> 00:36:18,560
uh

844
00:36:18,560 --> 00:36:20,720
things you need to implement will change

845
00:36:20,720 --> 00:36:23,520
but the idea that you can you know send

846
00:36:23,520 --> 00:36:27,599
a jar there uh spark does the same

847
00:36:27,599 --> 00:36:29,359
so to mitigate

848
00:36:29,359 --> 00:36:31,200
you need to base

849
00:36:31,200 --> 00:36:33,119
the mitigation on your case if you have

850
00:36:33,119 --> 00:36:36,079
such a risk then you need to implement

851
00:36:36,079 --> 00:36:38,000
that layered

852
00:36:38,000 --> 00:36:39,359
defense

853
00:36:39,359 --> 00:36:41,680
and how you do it depends on the

854
00:36:41,680 --> 00:36:43,599
infrastructure and of course you need

855
00:36:43,599 --> 00:36:45,760
authentication

856
00:36:45,760 --> 00:36:49,040
and the first case about hue

857
00:36:49,040 --> 00:36:50,640
can you explain again

858
00:36:50,640 --> 00:36:51,599
when you

859
00:36:51,599 --> 00:36:55,680
connect to this interface first it

860
00:36:55,680 --> 00:36:57,920
gives you an option to define a super

861
00:36:57,920 --> 00:36:59,839
user right yes

862
00:36:59,839 --> 00:37:01,920
and if you have a super user in the

863
00:37:01,920 --> 00:37:03,280
database

864
00:37:03,280 --> 00:37:05,119
you can create new users right yes

865
00:37:05,119 --> 00:37:06,240
absolutely

866
00:37:06,240 --> 00:37:09,920
so hue itself has its own

867
00:37:09,920 --> 00:37:12,320
roles

868
00:37:13,200 --> 00:37:16,640
an admin a super user

869
00:37:20,720 --> 00:37:22,960
so when it starts

870
00:37:22,960 --> 00:37:25,839
by default in the cloud in amazon you

871
00:37:25,839 --> 00:37:27,280
just you know

872
00:37:27,280 --> 00:37:29,680
put a

873
00:37:29,680 --> 00:37:32,720
checkbox in front of you

874
00:37:32,720 --> 00:37:36,240
so the first person finding and logging

875
00:37:36,240 --> 00:37:39,440
into hue just gets a super user

876
00:37:39,440 --> 00:37:41,040
there's no admin there

877
00:37:41,040 --> 00:37:44,320
we will create an admin

878
00:37:44,640 --> 00:37:48,640
and thus we have an admin we have a user

879
00:37:48,640 --> 00:37:51,200
with admin rights

880
00:37:51,200 --> 00:37:54,240
so we can create a lot of a lot of users

881
00:37:54,240 --> 00:37:56,400
thanks much

882
00:37:56,400 --> 00:37:58,960
my pleasure

883
00:38:00,320 --> 00:38:02,640
hello

884
00:38:02,720 --> 00:38:05,200
maybe the question is stupid but in

885
00:38:05,200 --> 00:38:08,160
terms of you know blue teaming

886
00:38:08,160 --> 00:38:11,599
all you showed was miss config

887
00:38:11,599 --> 00:38:14,960
and the question is

888
00:38:16,960 --> 00:38:19,119
what about the compliance of the given

889
00:38:19,119 --> 00:38:21,440
tools

890
00:38:21,440 --> 00:38:22,960
are there any

891
00:38:22,960 --> 00:38:26,240
ready-made modules for popular scanners

892
00:38:26,240 --> 00:38:27,280
to

893
00:38:27,280 --> 00:38:30,800
find obvious issues administering issues

894
00:38:30,800 --> 00:38:33,920
and the second question is what

895
00:38:33,920 --> 00:38:36,960
do those tools have in terms of logging

896
00:38:36,960 --> 00:38:39,440
because it's especially interesting for

897
00:38:39,440 --> 00:38:41,359
you know changing jobs

898
00:38:41,359 --> 00:38:44,720
because it changes the logic completely

899
00:38:44,720 --> 00:38:46,880
yeah i get your question thanks much

900
00:38:46,880 --> 00:38:49,839
great question and

901
00:38:49,839 --> 00:38:52,160
i will start from the last part

902
00:38:52,160 --> 00:38:54,720
regarding the jobs

903
00:38:54,720 --> 00:38:57,520
in one of our projects

904
00:38:57,520 --> 00:39:00,000
cannot name the company or any details

905
00:39:00,000 --> 00:39:02,160
but

906
00:39:02,160 --> 00:39:05,279
i will give you an overview

907
00:39:05,760 --> 00:39:07,280
randomly

908
00:39:07,280 --> 00:39:09,359
by pressing

909
00:39:09,359 --> 00:39:12,320
the wrong button

910
00:39:12,320 --> 00:39:16,079
i was able to kill the uh the job that

911
00:39:16,079 --> 00:39:19,119
well not 700 but it is 70 70 hours that

912
00:39:19,119 --> 00:39:21,359
worked for 70 hours just looking through

913
00:39:21,359 --> 00:39:22,720
the interface

914
00:39:22,720 --> 00:39:24,880
funny part right

915
00:39:24,880 --> 00:39:27,440
and regarding the blue team approach and

916
00:39:27,440 --> 00:39:28,720
logging

917
00:39:28,720 --> 00:39:32,320
yes logging can and should be

918
00:39:32,320 --> 00:39:36,320
set up and by default each tool

919
00:39:36,320 --> 00:39:39,680
provides you with locks and

920
00:39:40,720 --> 00:39:42,720
and barry can help you gather it from

921
00:39:42,720 --> 00:39:44,400
all the notes and uh

922
00:39:44,400 --> 00:39:46,160
look at all the data

923
00:39:46,160 --> 00:39:48,720
cluster wise i don't know whether we

924
00:39:48,720 --> 00:39:51,920
have some ready paper that will give us

925
00:39:51,920 --> 00:39:54,720
all the misconfigs but pen test is

926
00:39:54,720 --> 00:39:56,880
probably something that can be

927
00:39:56,880 --> 00:40:00,160
recommended and as an optimal solution

928
00:40:00,160 --> 00:40:03,520
we will look on at everything and uh

929
00:40:03,520 --> 00:40:06,400
finding those misconfigs we will

930
00:40:06,400 --> 00:40:09,040
report it to you well but it's expensive

931
00:40:09,040 --> 00:40:12,720
and i think every change every deploy

932
00:40:12,720 --> 00:40:13,599
can

933
00:40:13,599 --> 00:40:14,800
you know

934
00:40:14,800 --> 00:40:17,040
should be followed up by a pen test

935
00:40:17,040 --> 00:40:18,720
yeah i agree

936
00:40:18,720 --> 00:40:22,959
and the alternative here is

937
00:40:25,839 --> 00:40:27,760
a lot of

938
00:40:27,760 --> 00:40:30,160
work with the settings and

939
00:40:30,160 --> 00:40:32,640
reading the documents and

940
00:40:32,640 --> 00:40:34,960
each of them has very

941
00:40:34,960 --> 00:40:37,119
very much detailed

942
00:40:37,119 --> 00:40:39,920
description and manuals

943
00:40:39,920 --> 00:40:42,800
i think from my experience no one

944
00:40:42,800 --> 00:40:45,200
no one reads the manuals yeah dr house

945
00:40:45,200 --> 00:40:47,200
said everyone lies and i can add that

946
00:40:47,200 --> 00:40:49,119
everyone is mistaken also

947
00:40:49,119 --> 00:40:50,880
correct

948
00:40:50,880 --> 00:40:53,839
everyone makes mistakes

949
00:41:00,480 --> 00:41:03,440
thank you thank you for the presentation

950
00:41:03,440 --> 00:41:04,640
and uh

951
00:41:04,640 --> 00:41:07,280
yeah

952
00:41:07,280 --> 00:41:09,280
i would like to ask how long all this

953
00:41:09,280 --> 00:41:11,680
will keep happening but

954
00:41:11,680 --> 00:41:13,599
okay

955
00:41:13,599 --> 00:41:15,599
hardware keys are great i'm afraid

956
00:41:15,599 --> 00:41:17,040
upgrade

957
00:41:17,040 --> 00:41:18,480
but

958
00:41:18,480 --> 00:41:21,119
as a user of that hardware thing the

959
00:41:21,119 --> 00:41:25,119
question is it's always in in my pc and

960
00:41:25,119 --> 00:41:26,079
i never

961
00:41:26,079 --> 00:41:27,680
take it out

962
00:41:27,680 --> 00:41:31,359
and if i was hacked and here are my keys

963
00:41:31,359 --> 00:41:34,000
visible to all the world

964
00:41:34,000 --> 00:41:36,720
so the question is

965
00:41:39,280 --> 00:41:41,839
how can you how can we solve this i work

966
00:41:41,839 --> 00:41:45,280
with hadoop as a full scale ml engineer

967
00:41:45,280 --> 00:41:47,440
and

968
00:41:47,839 --> 00:41:50,160
it's not very probable that i will you

969
00:41:50,160 --> 00:41:53,599
know switch the keys always or you know

970
00:41:53,599 --> 00:41:56,240
remove it so how do you protect it

971
00:41:56,240 --> 00:41:58,240
hardware wise

972
00:41:58,240 --> 00:41:59,280
thanks much

973
00:41:59,280 --> 00:42:01,359
great question and

974
00:42:01,359 --> 00:42:04,960
cyber security related

975
00:42:06,960 --> 00:42:08,079
uh

976
00:42:08,079 --> 00:42:10,400
theory says that you know you need to

977
00:42:10,400 --> 00:42:13,839
balance the convenience and security

978
00:42:13,839 --> 00:42:15,680
because you have

979
00:42:15,680 --> 00:42:16,640
you know

980
00:42:16,640 --> 00:42:20,079
a lot of displeasure from the obvious

981
00:42:20,079 --> 00:42:21,599
ordinary users

982
00:42:21,599 --> 00:42:23,359
but you need yeah you need to find a

983
00:42:23,359 --> 00:42:24,720
balance and

984
00:42:24,720 --> 00:42:27,839
maneuver around the issues

985
00:42:27,839 --> 00:42:31,359
using hardware tokens and nfmfis is

986
00:42:31,359 --> 00:42:34,000
an obvious

987
00:42:34,800 --> 00:42:36,000
advice

988
00:42:36,000 --> 00:42:38,319
we saw hadoop clusters in serious

989
00:42:38,319 --> 00:42:40,800
companies with a lot of requirements for

990
00:42:40,800 --> 00:42:43,119
cyber security and

991
00:42:43,119 --> 00:42:45,839
high maturity

992
00:42:47,040 --> 00:42:48,000
so

993
00:42:48,000 --> 00:42:49,200
you know

994
00:42:49,200 --> 00:42:50,720
player defense

995
00:42:50,720 --> 00:42:52,400
mitigations everywhere

996
00:42:52,400 --> 00:42:55,040
this is this is how it's done

997
00:42:55,040 --> 00:42:57,520
hyper tokens jump host authentication

998
00:42:57,520 --> 00:42:59,920
all works well but in the case that i

999
00:42:59,920 --> 00:43:01,440
was

1000
00:43:01,440 --> 00:43:04,720
describing there was ambari there was a

1001
00:43:04,720 --> 00:43:07,760
password sql file and we just

1002
00:43:07,760 --> 00:43:10,000
used credential stuffing

1003
00:43:10,000 --> 00:43:13,839
a very serious password

1004
00:43:15,040 --> 00:43:17,680
so you need to find your golden

1005
00:43:17,680 --> 00:43:18,720
uh

1006
00:43:18,720 --> 00:43:20,960
ideal balance between convenience and

1007
00:43:20,960 --> 00:43:25,319
security and this is a fight here

1008
00:43:36,800 --> 00:43:38,800
thank you you've mentioned

1009
00:43:38,800 --> 00:43:41,359
the fact that the best practice is

1010
00:43:41,359 --> 00:43:43,200
isolation

1011
00:43:43,200 --> 00:43:46,000
isolating a big data cluster for example

1012
00:43:46,000 --> 00:43:48,400
and in my practice i keep seeing that

1013
00:43:48,400 --> 00:43:50,880
this is part of some internal virtual

1014
00:43:50,880 --> 00:43:52,960
network and pretty much

1015
00:43:52,960 --> 00:43:56,319
all cloud providers create their virtual

1016
00:43:56,319 --> 00:43:59,839
network and everyone you know suggests

1017
00:43:59,839 --> 00:44:01,200
jump servers

1018
00:44:01,200 --> 00:44:02,560
but there's

1019
00:44:02,560 --> 00:44:04,800
usually a check box

1020
00:44:04,800 --> 00:44:05,920
to remove it

1021
00:44:05,920 --> 00:44:08,400
and i often see it means you know just

1022
00:44:08,400 --> 00:44:10,880
putting a distributive distribution

1023
00:44:10,880 --> 00:44:12,400
software

1024
00:44:12,400 --> 00:44:13,359
and

1025
00:44:13,359 --> 00:44:15,359
direct success and no one thinks that

1026
00:44:15,359 --> 00:44:17,680
this was not thought about

1027
00:44:17,680 --> 00:44:19,520
in terms of security

1028
00:44:19,520 --> 00:44:22,640
even adding kerberos there is is very

1029
00:44:22,640 --> 00:44:24,160
hard to do

1030
00:44:24,160 --> 00:44:25,040
and

1031
00:44:25,040 --> 00:44:27,839
i see that

1032
00:44:27,839 --> 00:44:30,240
they sometimes put it in an ordinary

1033
00:44:30,240 --> 00:44:34,078
segment and yeah great question

1034
00:44:35,280 --> 00:44:36,960
regarding the

1035
00:44:36,960 --> 00:44:38,480
pen test

1036
00:44:38,480 --> 00:44:40,640
projects for hadoop usually we are hired

1037
00:44:40,640 --> 00:44:44,000
by companies that invest in

1038
00:44:44,000 --> 00:44:45,680
checking the

1039
00:44:45,680 --> 00:44:47,839
the quality of their security so the

1040
00:44:47,839 --> 00:44:50,480
default

1041
00:44:50,480 --> 00:44:53,040
settings are not used

1042
00:44:53,040 --> 00:44:56,560
but the misconcepts that you can often

1043
00:44:56,560 --> 00:44:59,680
find based on children

1044
00:44:59,680 --> 00:45:01,680
with companies that don't have enough

1045
00:45:01,680 --> 00:45:04,079
maturity or enough personnel that works

1046
00:45:04,079 --> 00:45:07,359
with security

1047
00:45:12,079 --> 00:45:15,040
so those misconfig cases are

1048
00:45:15,040 --> 00:45:16,800
more popular within the companies that

1049
00:45:16,800 --> 00:45:19,200
are just starting to think about cyber

1050
00:45:19,200 --> 00:45:21,920
security or after the incident

1051
00:45:21,920 --> 00:45:24,720
when something has happened

1052
00:45:24,720 --> 00:45:27,359
with the data

1053
00:45:31,119 --> 00:45:34,640
i may ask the next question

1054
00:45:35,200 --> 00:45:38,079
isn't it a good advice for

1055
00:45:38,079 --> 00:45:40,240
the companies not to

1056
00:45:40,240 --> 00:45:42,560
create self-hosted clusters at least the

1057
00:45:42,560 --> 00:45:44,160
cloud players

1058
00:45:44,160 --> 00:45:47,119
will have some understanding of uh

1059
00:45:47,119 --> 00:45:50,000
security and

1060
00:45:50,000 --> 00:45:51,200
well i agree

1061
00:45:51,200 --> 00:45:54,000
and this would be a great solution if

1062
00:45:54,000 --> 00:45:55,440
not for

1063
00:45:55,440 --> 00:45:59,920
for example aws case we

1064
00:46:08,800 --> 00:46:10,400
we worked with amazon

1065
00:46:10,400 --> 00:46:13,400
representatives

1066
00:46:15,839 --> 00:46:19,200
the responsibility model

1067
00:46:19,920 --> 00:46:21,760
is

1068
00:46:21,760 --> 00:46:25,520
fully put on the client of the cloud

1069
00:46:25,520 --> 00:46:28,079
everything that is above hypervisor is

1070
00:46:28,079 --> 00:46:30,480
responsibility of the cloud provider so

1071
00:46:30,480 --> 00:46:32,960
everything that is higher

1072
00:46:32,960 --> 00:46:36,079
depends on the client

1073
00:46:40,400 --> 00:46:42,480
they put the blame on you

1074
00:46:42,480 --> 00:46:47,760
does aws uh work with wbc

1075
00:46:50,800 --> 00:46:53,839
the two options are available

1076
00:46:53,839 --> 00:46:55,040
i think we're

1077
00:46:55,040 --> 00:46:57,040
no no we're not done with the questions

1078
00:46:57,040 --> 00:46:59,920
okay another question

1079
00:47:02,000 --> 00:47:04,560
hi thanks for the presentation and my

1080
00:47:04,560 --> 00:47:07,440
question is not to the hardware but more

1081
00:47:07,440 --> 00:47:09,680
to

1082
00:47:12,960 --> 00:47:16,079
because working with big data

1083
00:47:16,079 --> 00:47:18,079
means you need a lot of data from

1084
00:47:18,079 --> 00:47:20,720
everywhere and security people

1085
00:47:20,720 --> 00:47:22,720
from many companies they surround it

1086
00:47:22,720 --> 00:47:24,720
with you know three layers of security

1087
00:47:24,720 --> 00:47:26,079
and you need to

1088
00:47:26,079 --> 00:47:27,040
you know

1089
00:47:27,040 --> 00:47:30,720
go through an rdp to a specific server

1090
00:47:30,720 --> 00:47:32,480
where everything is closed and you are

1091
00:47:32,480 --> 00:47:34,720
identified and you can

1092
00:47:34,720 --> 00:47:38,240
move that data only by

1093
00:47:38,240 --> 00:47:41,200
moving the file and

1094
00:47:41,200 --> 00:47:42,240
so to

1095
00:47:42,240 --> 00:47:43,760
even to

1096
00:47:43,760 --> 00:47:46,160
run a very primitive analytics you need

1097
00:47:46,160 --> 00:47:48,720
to spend three days to just gather the

1098
00:47:48,720 --> 00:47:50,640
data and

1099
00:47:50,640 --> 00:47:52,559
understand

1100
00:47:52,559 --> 00:47:54,400
you don't have something

1101
00:47:54,400 --> 00:47:56,960
so you spend a lot of a lot of time

1102
00:47:56,960 --> 00:47:58,079
passing

1103
00:47:58,079 --> 00:48:00,319
through the security any recommendations

1104
00:48:00,319 --> 00:48:02,079
on how we can fight with that like you

1105
00:48:02,079 --> 00:48:04,160
know limiting the amount of activities

1106
00:48:04,160 --> 00:48:04,880
of

1107
00:48:04,880 --> 00:48:06,400
the security people

1108
00:48:06,400 --> 00:48:09,920
you know just saying you know enough

1109
00:48:10,240 --> 00:48:12,799
great question

1110
00:48:13,119 --> 00:48:14,079
i think

1111
00:48:14,079 --> 00:48:16,720
it's an often

1112
00:48:16,720 --> 00:48:18,079
happening

1113
00:48:18,079 --> 00:48:19,440
story

1114
00:48:19,440 --> 00:48:20,480
and

1115
00:48:20,480 --> 00:48:21,359
we

1116
00:48:21,359 --> 00:48:24,559
yeah we see this a lot

1117
00:48:24,559 --> 00:48:27,280
but i am a security guy and

1118
00:48:27,280 --> 00:48:29,920
i will not be giving you such an address

1119
00:48:29,920 --> 00:48:31,520
this is not

1120
00:48:31,520 --> 00:48:34,559
you know something that i know but how

1121
00:48:34,559 --> 00:48:36,319
we can be stopped

1122
00:48:36,319 --> 00:48:38,558
but

1123
00:48:40,160 --> 00:48:42,400
if you find the balance between the

1124
00:48:42,400 --> 00:48:45,359
security and usability

1125
00:48:45,359 --> 00:48:47,040
if this is not usable

1126
00:48:47,040 --> 00:48:48,400
then

1127
00:48:48,400 --> 00:48:50,079
you know you don't need security if you

1128
00:48:50,079 --> 00:48:51,280
cannot

1129
00:48:51,280 --> 00:48:55,760
get access to that data

1130
00:48:56,880 --> 00:48:59,119
well with people working with jupiter

1131
00:48:59,119 --> 00:49:01,200
notebooks

1132
00:49:01,200 --> 00:49:04,240
they often complain that you know you

1133
00:49:04,240 --> 00:49:07,040
have put so much security on top of this

1134
00:49:07,040 --> 00:49:07,839
that

1135
00:49:07,839 --> 00:49:10,079
this cannot be used

1136
00:49:10,079 --> 00:49:12,559
but at least this is safe and secure

1137
00:49:12,559 --> 00:49:15,440
at least that data is safe we can work

1138
00:49:15,440 --> 00:49:18,160
with it and

1139
00:49:18,480 --> 00:49:22,319
there might be petabytes of data

1140
00:49:22,640 --> 00:49:24,559
maybe the company has worked with it for

1141
00:49:24,559 --> 00:49:25,520
years

1142
00:49:25,520 --> 00:49:27,200
so that would not be

1143
00:49:27,200 --> 00:49:28,720
very

1144
00:49:28,720 --> 00:49:31,359
convenient if this gets hacked

1145
00:49:31,359 --> 00:49:33,359
any research you would advise on that

1146
00:49:33,359 --> 00:49:36,800
because the question was

1147
00:49:36,800 --> 00:49:38,640
asked many times

1148
00:49:38,640 --> 00:49:40,880
you know someone should have

1149
00:49:40,880 --> 00:49:41,680
been

1150
00:49:41,680 --> 00:49:44,680
motivated

1151
00:49:44,720 --> 00:49:46,800
say to say that you know at that point

1152
00:49:46,800 --> 00:49:50,160
you've over even over secured the system

1153
00:49:50,160 --> 00:49:51,040
and

1154
00:49:51,040 --> 00:49:53,040
this is uh i think

1155
00:49:53,040 --> 00:49:55,280
an abstract discussion but

1156
00:49:55,280 --> 00:49:58,160
the more i look the the less i uh the

1157
00:49:58,160 --> 00:49:59,200
more i

1158
00:49:59,200 --> 00:50:00,160
find

1159
00:50:00,160 --> 00:50:02,079
that the question that the more security

1160
00:50:02,079 --> 00:50:04,559
there is the less usage there is and

1161
00:50:04,559 --> 00:50:07,119
people leaving to foreign resources that

1162
00:50:07,119 --> 00:50:07,920
are

1163
00:50:07,920 --> 00:50:10,800
more required more convenient and

1164
00:50:10,800 --> 00:50:12,720
we wanted to

1165
00:50:12,720 --> 00:50:15,760
create a safe and secure resource

1166
00:50:15,760 --> 00:50:18,960
but it's not usable and we start using

1167
00:50:18,960 --> 00:50:20,400
some you know back

1168
00:50:20,400 --> 00:50:21,839
doors and

1169
00:50:21,839 --> 00:50:24,000
those backdoors are used to hack us i

1170
00:50:24,000 --> 00:50:25,520
agree i agree

1171
00:50:25,520 --> 00:50:27,839
but unfortunately there's a lot of

1172
00:50:27,839 --> 00:50:30,640
philosophy and we can keep

1173
00:50:30,640 --> 00:50:32,400
talking about this but there's no silver

1174
00:50:32,400 --> 00:50:34,319
bullet there's no solution

1175
00:50:34,319 --> 00:50:37,200
in my opinion this is just you know find

1176
00:50:37,200 --> 00:50:38,720
the balance and

1177
00:50:38,720 --> 00:50:42,880
not over overdo this security get your

1178
00:50:42,880 --> 00:50:46,240
feedback from the admins of the service

1179
00:50:46,240 --> 00:50:47,440
and

1180
00:50:47,440 --> 00:50:49,359
now analysts

1181
00:50:49,359 --> 00:50:51,520
how comfortable are they

1182
00:50:51,520 --> 00:50:53,040
working with that

1183
00:50:53,040 --> 00:50:56,640
and i think this is this is the

1184
00:50:56,640 --> 00:50:58,400
reply i can give you

1185
00:50:58,400 --> 00:51:01,839
thank you any other questions

1186
00:51:03,520 --> 00:51:06,240
i don't see any any raised hands okay

1187
00:51:06,240 --> 00:51:08,880
thanks time to choose the best question

1188
00:51:08,880 --> 00:51:09,839
and

1189
00:51:09,839 --> 00:51:11,359
give the gifts

1190
00:51:11,359 --> 00:51:13,200
thank you indeed for the questions they

1191
00:51:13,200 --> 00:51:14,800
were really interesting it's hard to

1192
00:51:14,800 --> 00:51:16,480
choose the right one but this guy i

1193
00:51:16,480 --> 00:51:18,240
think was

1194
00:51:18,240 --> 00:51:22,680
my favorite and your question also

1195
00:51:25,040 --> 00:51:28,040
thanks

1196
00:51:29,940 --> 00:51:32,619
[Applause]

