1
00:00:00,320 --> 00:00:01,599
hey everyone

2
00:00:01,599 --> 00:00:03,360
so i'm david agronovich i'm facebook's

3
00:00:03,360 --> 00:00:05,279
director for global threat disruption we

4
00:00:05,279 --> 00:00:07,919
also have mike dolianski who leads our

5
00:00:07,919 --> 00:00:10,800
cyber espionage teams among others um so

6
00:00:10,800 --> 00:00:11,920
i'm going to open this really quick and

7
00:00:11,920 --> 00:00:13,200
then pass it to mike because he's more

8
00:00:13,200 --> 00:00:15,759
interesting and knows more things

9
00:00:15,759 --> 00:00:16,720
so let's see how this goes so we're

10
00:00:16,720 --> 00:00:18,160
going to talk a bit about how we disrupt

11
00:00:18,160 --> 00:00:21,039
cyber adversaries and in in particular

12
00:00:21,039 --> 00:00:22,480
the question that we want to try to

13
00:00:22,480 --> 00:00:24,000
answer here is

14
00:00:24,000 --> 00:00:25,920
how can you deter

15
00:00:25,920 --> 00:00:27,599
a cyber threat actor

16
00:00:27,599 --> 00:00:30,160
and when you try to do it does it work

17
00:00:30,160 --> 00:00:31,359
we have 10 minutes so we'll see if that

18
00:00:31,359 --> 00:00:33,280
works um so we'll talk a bit about what

19
00:00:33,280 --> 00:00:34,880
our goals are as a private company

20
00:00:34,880 --> 00:00:36,239
trying to do this

21
00:00:36,239 --> 00:00:38,320
how we do it right what is deterrence

22
00:00:38,320 --> 00:00:39,680
how do we define it and what levers do

23
00:00:39,680 --> 00:00:41,360
we have and then mike's going to talk

24
00:00:41,360 --> 00:00:42,800
about some examples of how we've

25
00:00:42,800 --> 00:00:44,879
actually applied this uh

26
00:00:44,879 --> 00:00:46,719
in real life

27
00:00:46,719 --> 00:00:48,719
in particular

28
00:00:48,719 --> 00:00:50,719
the goals here are

29
00:00:50,719 --> 00:00:52,559
simple right protect people on our

30
00:00:52,559 --> 00:00:54,320
platform from bad actors doing bad

31
00:00:54,320 --> 00:00:56,320
things on our platform

32
00:00:56,320 --> 00:00:57,520
but those goals are a little more

33
00:00:57,520 --> 00:00:59,120
nuanced than that right how do we raise

34
00:00:59,120 --> 00:01:00,559
costs against those adversaries how do

35
00:01:00,559 --> 00:01:02,399
we make this you know doing bad things

36
00:01:02,399 --> 00:01:05,199
on facebook's platforms worse for them

37
00:01:05,199 --> 00:01:07,280
how do we increase the risk for doing

38
00:01:07,280 --> 00:01:09,680
operations on our platform and then how

39
00:01:09,680 --> 00:01:11,840
can we make them change the way they

40
00:01:11,840 --> 00:01:14,320
behave on our platforms and off of our

41
00:01:14,320 --> 00:01:16,080
platforms to move away from the bad

42
00:01:16,080 --> 00:01:18,320
things that they're doing

43
00:01:18,320 --> 00:01:20,000
so when we think about deterrence right

44
00:01:20,000 --> 00:01:21,680
falls into kind of two major buckets how

45
00:01:21,680 --> 00:01:23,680
can we maximize the pain on the

46
00:01:23,680 --> 00:01:25,600
adversary and how can we minimize the

47
00:01:25,600 --> 00:01:27,360
benefits of the operations that they're

48
00:01:27,360 --> 00:01:28,640
conducting

49
00:01:28,640 --> 00:01:30,479
and as a private company we have a bunch

50
00:01:30,479 --> 00:01:32,640
of these levers that we can pull right

51
00:01:32,640 --> 00:01:34,799
we can disrupt the network like we did

52
00:01:34,799 --> 00:01:36,320
this morning with an operation from

53
00:01:36,320 --> 00:01:38,159
pakistan targeting people in afghanistan

54
00:01:38,159 --> 00:01:39,680
and three operations in syria targeting

55
00:01:39,680 --> 00:01:41,040
people in syria

56
00:01:41,040 --> 00:01:42,640
we can blow the cover on those

57
00:01:42,640 --> 00:01:44,560
operations which we did this morning by

58
00:01:44,560 --> 00:01:46,399
releasing reports on those operations we

59
00:01:46,399 --> 00:01:48,159
can attribute those operations which we

60
00:01:48,159 --> 00:01:49,840
did this morning to side copy and the

61
00:01:49,840 --> 00:01:51,680
pakistan case the syrian air force

62
00:01:51,680 --> 00:01:54,320
intelligence and two of the syrian cases

63
00:01:54,320 --> 00:01:55,920
and then we can share information we can

64
00:01:55,920 --> 00:01:57,360
share information about the operations

65
00:01:57,360 --> 00:01:58,640
with the public we released a bunch of

66
00:01:58,640 --> 00:02:01,360
iocs websites malware hashes information

67
00:02:01,360 --> 00:02:03,200
about the applications that they were

68
00:02:03,200 --> 00:02:05,040
using we can also share information with

69
00:02:05,040 --> 00:02:06,479
law enforcement with policy makers with

70
00:02:06,479 --> 00:02:08,080
folks like who alicia was talking about

71
00:02:08,080 --> 00:02:09,598
to make other parts of society more

72
00:02:09,598 --> 00:02:10,720
effective

73
00:02:10,720 --> 00:02:12,239
and then we can share with industry so

74
00:02:12,239 --> 00:02:13,440
some of the other companies that are

75
00:02:13,440 --> 00:02:15,200
here both on the cyber security side and

76
00:02:15,200 --> 00:02:16,720
some of the platform companies will work

77
00:02:16,720 --> 00:02:18,080
with them to make sure we're sharing

78
00:02:18,080 --> 00:02:19,520
with them and vice versa so that we can

79
00:02:19,520 --> 00:02:20,879
take action on these networks wherever

80
00:02:20,879 --> 00:02:23,200
they appear and then

81
00:02:23,200 --> 00:02:25,040
when we're doing the sharing we can also

82
00:02:25,040 --> 00:02:26,480
what i have here is advocate for real

83
00:02:26,480 --> 00:02:28,400
consequences note that getting your

84
00:02:28,400 --> 00:02:30,319
facebook account taken down is certainly

85
00:02:30,319 --> 00:02:32,160
going to be annoying

86
00:02:32,160 --> 00:02:34,000
but it is not the end of the world and

87
00:02:34,000 --> 00:02:35,440
if much like as we talked about the

88
00:02:35,440 --> 00:02:37,840
ransomware uh cases this morning

89
00:02:37,840 --> 00:02:40,080
if we wanted to actually change the risk

90
00:02:40,080 --> 00:02:41,840
calculus of some of these threat actors

91
00:02:41,840 --> 00:02:43,280
the way we do it

92
00:02:43,280 --> 00:02:45,120
is to get them to think that doing this

93
00:02:45,120 --> 00:02:46,400
type of an operation isn't just gonna

94
00:02:46,400 --> 00:02:48,000
get your facebook account taken down

95
00:02:48,000 --> 00:02:49,120
it's gonna result in real world

96
00:02:49,120 --> 00:02:50,560
consequences elsewhere in the rest of

97
00:02:50,560 --> 00:02:51,920
your work

98
00:02:51,920 --> 00:02:53,360
minimize the benefits we can warn

99
00:02:53,360 --> 00:02:54,720
victims we told the people in those

100
00:02:54,720 --> 00:02:56,000
operations i mentioned that they were

101
00:02:56,000 --> 00:02:57,519
being targeted so if you were a threat

102
00:02:57,519 --> 00:02:59,519
actor now your victims know that you're

103
00:02:59,519 --> 00:03:01,599
out there looking at them we can change

104
00:03:01,599 --> 00:03:03,200
the way the platform works make it less

105
00:03:03,200 --> 00:03:05,200
likely it's going to be effective and we

106
00:03:05,200 --> 00:03:06,800
can work to catch them earlier right as

107
00:03:06,800 --> 00:03:08,000
a private company we can build things

108
00:03:08,000 --> 00:03:09,440
like automated detection to look for

109
00:03:09,440 --> 00:03:11,200
this type of stuff

110
00:03:11,200 --> 00:03:12,080
so

111
00:03:12,080 --> 00:03:13,680
some major items here right we have

112
00:03:13,680 --> 00:03:16,159
deterrent levers that we can pull

113
00:03:16,159 --> 00:03:18,480
we need to make trade-offs between the

114
00:03:18,480 --> 00:03:20,000
public and non-public approaches we can

115
00:03:20,000 --> 00:03:20,879
take

116
00:03:20,879 --> 00:03:22,480
and then we need to think about when we

117
00:03:22,480 --> 00:03:24,400
do these takedowns the effect they have

118
00:03:24,400 --> 00:03:25,840
on our adversaries and then the effect

119
00:03:25,840 --> 00:03:27,120
that they have on our ability to

120
00:03:27,120 --> 00:03:28,080
continue doing this type of

121
00:03:28,080 --> 00:03:29,840
investigative work

122
00:03:29,840 --> 00:03:31,360
and then finally when we do these public

123
00:03:31,360 --> 00:03:32,480
enforcements something that we've been

124
00:03:32,480 --> 00:03:34,080
advocating for for more people to do

125
00:03:34,080 --> 00:03:35,200
right is

126
00:03:35,200 --> 00:03:37,040
commit to making public your findings on

127
00:03:37,040 --> 00:03:39,040
these types of enforcements attribute it

128
00:03:39,040 --> 00:03:40,799
when we have it and make our attribution

129
00:03:40,799 --> 00:03:42,480
standards as public as possible we talk

130
00:03:42,480 --> 00:03:44,080
about essentially how we hold ourselves

131
00:03:44,080 --> 00:03:46,159
to attribution each of these cases and

132
00:03:46,159 --> 00:03:48,239
then actually provide usable and

133
00:03:48,239 --> 00:03:49,680
actionable information in those

134
00:03:49,680 --> 00:03:51,840
takedowns right so if we have iocs if we

135
00:03:51,840 --> 00:03:53,200
have information malware hashes for

136
00:03:53,200 --> 00:03:54,640
example we actually provide that both to

137
00:03:54,640 --> 00:03:56,799
the public and to the industry

138
00:03:56,799 --> 00:03:58,480
and so mike is going to talk through

139
00:03:58,480 --> 00:04:01,760
some examples of how this works mike

140
00:04:01,760 --> 00:04:02,640
thanks

141
00:04:02,640 --> 00:04:03,599
um

142
00:04:03,599 --> 00:04:05,200
so thanks david for and i really

143
00:04:05,200 --> 00:04:06,560
appreciate being here today to talk

144
00:04:06,560 --> 00:04:08,400
about this so these are two cases that

145
00:04:08,400 --> 00:04:10,239
we've made public in the past the first

146
00:04:10,239 --> 00:04:12,640
one tortoise shell a case from iran that

147
00:04:12,640 --> 00:04:14,159
mike scott and our team actually worked

148
00:04:14,159 --> 00:04:16,079
on and then the second one from china

149
00:04:16,079 --> 00:04:17,839
earth and pusa mike flossman from our

150
00:04:17,839 --> 00:04:19,600
team worked on so we're all named mike's

151
00:04:19,600 --> 00:04:21,519
to confuse the adversary by the way on

152
00:04:21,519 --> 00:04:22,639
our team

153
00:04:22,639 --> 00:04:25,680
so in the first case uh what we saw and

154
00:04:25,680 --> 00:04:27,840
the first one we made public in july the

155
00:04:27,840 --> 00:04:30,080
one in china we made public in march of

156
00:04:30,080 --> 00:04:31,680
uh this year i can't believe was this

157
00:04:31,680 --> 00:04:34,240
year but it was in 2021. so

158
00:04:34,240 --> 00:04:35,680
tortoiseshell is an investigation we've

159
00:04:35,680 --> 00:04:37,680
been following for some time they were

160
00:04:37,680 --> 00:04:39,520
following they were targeting uh

161
00:04:39,520 --> 00:04:41,520
typically it industry in the middle east

162
00:04:41,520 --> 00:04:44,000
what we saw in 2020 is a shift in

163
00:04:44,000 --> 00:04:45,680
targeting to the

164
00:04:45,680 --> 00:04:47,680
aerospace and defense sectors mostly in

165
00:04:47,680 --> 00:04:48,720
the us

166
00:04:48,720 --> 00:04:50,320
but also some

167
00:04:50,320 --> 00:04:53,120
across the eu and uk

168
00:04:53,120 --> 00:04:55,440
so what we saw in this case is a heavy

169
00:04:55,440 --> 00:04:56,800
reliance on

170
00:04:56,800 --> 00:04:58,639
backstop personas across multiple

171
00:04:58,639 --> 00:05:00,320
internet services and social media

172
00:05:00,320 --> 00:05:02,560
platforms um essentially like a lot of

173
00:05:02,560 --> 00:05:04,720
investment into building trust someone

174
00:05:04,720 --> 00:05:06,240
talked earlier about trust building

175
00:05:06,240 --> 00:05:08,160
trust with the adversary with the target

176
00:05:08,160 --> 00:05:09,600
but you're tar that you're trying to

177
00:05:09,600 --> 00:05:11,039
trick into clicking on malicious links

178
00:05:11,039 --> 00:05:12,880
or enter your credentials we saw a lot

179
00:05:12,880 --> 00:05:14,800
of investment from this specific group

180
00:05:14,800 --> 00:05:16,639
into that and we also saw some custom

181
00:05:16,639 --> 00:05:19,039
malware developed um by what we were

182
00:05:19,039 --> 00:05:21,600
able to link to an irgc linked company

183
00:05:21,600 --> 00:05:23,840
mahak rayana fraz

184
00:05:23,840 --> 00:05:24,800
tehran

185
00:05:24,800 --> 00:05:27,520
it was similar on the on the china side

186
00:05:27,520 --> 00:05:29,360
we saw some malware outsourcing to two

187
00:05:29,360 --> 00:05:31,039
companies which we named publicly uh

188
00:05:31,039 --> 00:05:32,960
best lh and nine rush technologies in

189
00:05:32,960 --> 00:05:34,000
china

190
00:05:34,000 --> 00:05:36,000
and we saw some sensitivity to public

191
00:05:36,000 --> 00:05:38,560
disclosures uh from from this actor um

192
00:05:38,560 --> 00:05:40,639
the china actor targeted uh uyghurs

193
00:05:40,639 --> 00:05:42,639
around the world and people sympathetic

194
00:05:42,639 --> 00:05:44,479
to uga rights uh or

195
00:05:44,479 --> 00:05:47,759
the movement um and uh the the actual

196
00:05:47,759 --> 00:05:50,320
ttps across both of these cases were

197
00:05:50,320 --> 00:05:51,600
somewhat similar so they relied on

198
00:05:51,600 --> 00:05:52,720
phishing

199
00:05:52,720 --> 00:05:54,160
they relied on social engineering and

200
00:05:54,160 --> 00:05:56,160
then driving people off of our platform

201
00:05:56,160 --> 00:05:59,039
to compromised or other attacker-owned

202
00:05:59,039 --> 00:06:00,400
infrastructure to get them to either

203
00:06:00,400 --> 00:06:02,000
enter their credentials or click on

204
00:06:02,000 --> 00:06:03,520
malicious links

205
00:06:03,520 --> 00:06:05,360
what we saw in the second case in the

206
00:06:05,360 --> 00:06:06,880
earth in fusa case

207
00:06:06,880 --> 00:06:10,160
we also saw a lot of sensitivity to

208
00:06:10,160 --> 00:06:11,520
protection of their infrastructure and

209
00:06:11,520 --> 00:06:13,120
tooling chain that they used so there

210
00:06:13,120 --> 00:06:15,280
were some server-side server-side checks

211
00:06:15,280 --> 00:06:16,639
that they would perform before infecting

212
00:06:16,639 --> 00:06:18,319
someone with ios malware that they would

213
00:06:18,319 --> 00:06:19,280
serve up

214
00:06:19,280 --> 00:06:20,720
and we generally saw them as i mentioned

215
00:06:20,720 --> 00:06:21,840
slow down

216
00:06:21,840 --> 00:06:23,440
when whenever there was any public

217
00:06:23,440 --> 00:06:24,800
reporting on them

218
00:06:24,800 --> 00:06:26,880
so why did we make these public we do

219
00:06:26,880 --> 00:06:28,560
lots of disruptions some of them are not

220
00:06:28,560 --> 00:06:30,240
public um

221
00:06:30,240 --> 00:06:31,840
the reason for these two is comes back

222
00:06:31,840 --> 00:06:33,039
to those two things that david talked

223
00:06:33,039 --> 00:06:34,800
about so effects on the adversary and

224
00:06:34,800 --> 00:06:36,800
enabling the community so on the

225
00:06:36,800 --> 00:06:38,319
adversaries side the question we want to

226
00:06:38,319 --> 00:06:40,560
ask ourselves is are we increasing costs

227
00:06:40,560 --> 00:06:43,919
are we introducing risk we ask are we

228
00:06:43,919 --> 00:06:46,000
helping them ask questions like is this

229
00:06:46,000 --> 00:06:48,400
worth it or did legal sign off on this

230
00:06:48,400 --> 00:06:49,919
or like you know what are my equities

231
00:06:49,919 --> 00:06:52,240
here that i need to worry about um will

232
00:06:52,240 --> 00:06:53,440
they slow down we know that they're

233
00:06:53,440 --> 00:06:55,039
going to come back we will continue to

234
00:06:55,039 --> 00:06:56,560
look for them if they do to try to come

235
00:06:56,560 --> 00:06:57,599
back

236
00:06:57,599 --> 00:06:58,560
but

237
00:06:58,560 --> 00:07:00,000
we're we're not the goal here isn't to

238
00:07:00,000 --> 00:07:01,039
stop them

239
00:07:01,039 --> 00:07:02,400
the goal here is to move the adversary

240
00:07:02,400 --> 00:07:03,919
into a space that's more advantageous to

241
00:07:03,919 --> 00:07:05,039
us

242
00:07:05,039 --> 00:07:06,720
on enabling the community the question

243
00:07:06,720 --> 00:07:07,840
we want to ask ourselves is are we

244
00:07:07,840 --> 00:07:09,680
helping are we adding anything new to

245
00:07:09,680 --> 00:07:11,440
the understanding of these actors and

246
00:07:11,440 --> 00:07:12,960
are we helping to harden the attack

247
00:07:12,960 --> 00:07:14,960
surface for them by making the users

248
00:07:14,960 --> 00:07:16,720
more resilient through increased

249
00:07:16,720 --> 00:07:18,960
awareness so

250
00:07:18,960 --> 00:07:20,479
the last slide that i just want to talk

251
00:07:20,479 --> 00:07:22,160
about briefly here is i mean the

252
00:07:22,160 --> 00:07:23,680
question that we always ask ourselves is

253
00:07:23,680 --> 00:07:26,639
does it work is this effective um

254
00:07:26,639 --> 00:07:28,720
and so the answer we what we try to do

255
00:07:28,720 --> 00:07:29,919
after each disruption is actually

256
00:07:29,919 --> 00:07:32,240
analyze how quickly the actors come back

257
00:07:32,240 --> 00:07:34,000
what they do differently

258
00:07:34,000 --> 00:07:36,000
we try to understand how effective this

259
00:07:36,000 --> 00:07:37,199
was or not

260
00:07:37,199 --> 00:07:38,720
and what we usually see is that they do

261
00:07:38,720 --> 00:07:41,120
come back with some changes

262
00:07:41,120 --> 00:07:42,720
they do take notice

263
00:07:42,720 --> 00:07:44,879
they do pay attention to what we do

264
00:07:44,879 --> 00:07:46,560
and we look for behavioral changes in

265
00:07:46,560 --> 00:07:47,759
time to come back and changes in

266
00:07:47,759 --> 00:07:49,680
infrastructure and ttps and we have seen

267
00:07:49,680 --> 00:07:51,120
that just speaking broadly not just

268
00:07:51,120 --> 00:07:52,960
about these two cases but generally we

269
00:07:52,960 --> 00:07:54,879
have seen all of those things

270
00:07:54,879 --> 00:07:56,960
we do see generally more caution after

271
00:07:56,960 --> 00:07:59,199
we call them out publicly in how they

272
00:07:59,199 --> 00:08:00,319
come back

273
00:08:00,319 --> 00:08:02,960
we do see some self-imposed delays

274
00:08:02,960 --> 00:08:05,120
and just essentially what i imagine

275
00:08:05,120 --> 00:08:06,160
happens is some kind of damage

276
00:08:06,160 --> 00:08:07,520
assessment on the other side to try to

277
00:08:07,520 --> 00:08:09,440
understand how we found them what we did

278
00:08:09,440 --> 00:08:11,360
what we will do next so there's a little

279
00:08:11,360 --> 00:08:12,720
bit of friction introduced and a little

280
00:08:12,720 --> 00:08:14,240
bit more risk calculus which is our goal

281
00:08:14,240 --> 00:08:15,680
here

282
00:08:15,680 --> 00:08:17,199
we see lower levels of operational

283
00:08:17,199 --> 00:08:18,560
activity generally though they tend to

284
00:08:18,560 --> 00:08:20,160
ramp up over time

285
00:08:20,160 --> 00:08:22,160
and we do see the point number seven

286
00:08:22,160 --> 00:08:24,879
here is that personal consequences do

287
00:08:24,879 --> 00:08:26,639
matter there is institutional risk to

288
00:08:26,639 --> 00:08:28,160
the operation and the campaign but

289
00:08:28,160 --> 00:08:29,759
there's also personal risk to people

290
00:08:29,759 --> 00:08:31,120
involved in these campaigns and they do

291
00:08:31,120 --> 00:08:32,240
matter

292
00:08:32,240 --> 00:08:34,640
so we do see the bad guys take notice

293
00:08:34,640 --> 00:08:35,519
and

294
00:08:35,519 --> 00:08:37,039
you know respond

295
00:08:37,039 --> 00:08:38,719
and our goal here is to do those two

296
00:08:38,719 --> 00:08:39,760
things

297
00:08:39,760 --> 00:08:41,839
are we helping slow them down over time

298
00:08:41,839 --> 00:08:43,200
and are we helping users become more

299
00:08:43,200 --> 00:08:46,240
resilient by raising awareness so last

300
00:08:46,240 --> 00:08:48,959
thing i just want to say briefly is that

301
00:08:48,959 --> 00:08:50,160
like i mentioned before these are

302
00:08:50,160 --> 00:08:51,760
persistent actors we know we're not

303
00:08:51,760 --> 00:08:53,680
going to stop them what we're hoping to

304
00:08:53,680 --> 00:08:55,760
do is build a framework in which we work

305
00:08:55,760 --> 00:08:56,959
together to

306
00:08:56,959 --> 00:08:58,880
create as broader as broad of an impact

307
00:08:58,880 --> 00:09:00,320
radius on the actor operations as

308
00:09:00,320 --> 00:09:02,240
possible by sharing information with the

309
00:09:02,240 --> 00:09:03,680
industry by sharing information with

310
00:09:03,680 --> 00:09:04,959
each other

311
00:09:04,959 --> 00:09:06,880
by making this public and raising those

312
00:09:06,880 --> 00:09:08,560
costs so that we can be more effective

313
00:09:08,560 --> 00:09:09,680
in the long run

314
00:09:09,680 --> 00:09:13,920
and with that i think that's all we have

