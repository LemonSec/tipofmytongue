1
00:00:07,790 --> 00:00:14,580
yep so then let's just start because I

2
00:00:14,580 --> 00:00:17,430
heard we have a tight schedule so my

3
00:00:17,430 --> 00:00:20,449
name is Yann I'm here to present some

4
00:00:20,449 --> 00:00:23,130
quick research I have done for the

5
00:00:23,130 --> 00:00:25,800
German Aerospace Center on generic

6
00:00:25,800 --> 00:00:28,350
polyphase filter banks on a GPU with

7
00:00:28,350 --> 00:00:31,470
CUDA so yeah I'm working for a German

8
00:00:31,470 --> 00:00:33,870
Aerospace Center in the satellite

9
00:00:33,870 --> 00:00:36,540
navigation or no communication

10
00:00:36,540 --> 00:00:38,940
navigation Institute it's the satellite

11
00:00:38,940 --> 00:00:41,510
networks department and I do mostly

12
00:00:41,510 --> 00:00:45,480
software-defined radio so short outline

13
00:00:45,480 --> 00:00:47,579
of the talk so we start with the

14
00:00:47,579 --> 00:00:50,070
mandatory motivation then I want to give

15
00:00:50,070 --> 00:00:52,649
a short introduction into the cuda

16
00:00:52,649 --> 00:00:55,140
system a short introduction into

17
00:00:55,140 --> 00:00:57,270
polyphase filter banks what they are and

18
00:00:57,270 --> 00:01:00,770
why they are so cool or not so cool

19
00:01:00,770 --> 00:01:03,629
translation of the polyphase filter bank

20
00:01:03,629 --> 00:01:06,240
from like you have the DSP how do you

21
00:01:06,240 --> 00:01:10,319
get it to CUDA and then some results and

22
00:01:10,319 --> 00:01:12,690
then some release plans for a library

23
00:01:12,690 --> 00:01:15,300
that is open source that actually does

24
00:01:15,300 --> 00:01:18,869
that so motivation once upon a time

25
00:01:18,869 --> 00:01:20,399
there was a space project that I've been

26
00:01:20,399 --> 00:01:23,759
working on it was kind of a multi

27
00:01:23,759 --> 00:01:27,509
frequency random access scheme so we

28
00:01:27,509 --> 00:01:31,380
have some several numbers of carriers in

29
00:01:31,380 --> 00:01:33,869
this project it was like this a 15 30 or

30
00:01:33,869 --> 00:01:37,830
45 carrier and on receiving end we have

31
00:01:37,830 --> 00:01:39,330
to separate them somehow

32
00:01:39,330 --> 00:01:41,789
so I remember Tom's talk in Karlsruhe

33
00:01:41,789 --> 00:01:45,060
like years ago like hey let's do the PFP

34
00:01:45,060 --> 00:01:49,050
thing that sounded cool so I did some

35
00:01:49,050 --> 00:01:51,149
calculations and if you have 45 carriers

36
00:01:51,149 --> 00:01:52,830
the problem is if you have all of them

37
00:01:52,830 --> 00:01:55,110
at once you have like 45 times the

38
00:01:55,110 --> 00:02:00,869
bandwidth so that could be a lot and

39
00:02:00,869 --> 00:02:05,090
also for the actual channels the

40
00:02:05,090 --> 00:02:07,349
restrictions were quite tight so we only

41
00:02:07,349 --> 00:02:10,220
had 12 to 15% guard bands between

42
00:02:10,220 --> 00:02:12,510
information signal and then the next

43
00:02:12,510 --> 00:02:17,189
channel so this is quite steep we needed

44
00:02:17,189 --> 00:02:18,540
over sampling here they

45
00:02:18,540 --> 00:02:20,129
it says at least three times over

46
00:02:20,129 --> 00:02:22,829
sampling was is needed this is where we

47
00:02:22,829 --> 00:02:24,840
are right now at that time we had to do

48
00:02:24,840 --> 00:02:29,310
at least a time over sampling so it's

49
00:02:29,310 --> 00:02:31,349
quite a lot so when we did the filter

50
00:02:31,349 --> 00:02:33,810
design why did the filter design we came

51
00:02:33,810 --> 00:02:36,450
up with up to 1500 tab filters so if

52
00:02:36,450 --> 00:02:39,420
anybody knows something about fi our

53
00:02:39,420 --> 00:02:43,349
filters that's that's a huge filter so I

54
00:02:43,349 --> 00:02:46,590
did some tests I wrote a generic CPU

55
00:02:46,590 --> 00:02:51,510
version of that yeah that was me when I

56
00:02:51,510 --> 00:02:54,650
when I figure out what I had to do so I

57
00:02:54,650 --> 00:02:58,799
wrote a generic CPU implementation of

58
00:02:58,799 --> 00:03:00,629
that I just used the thousand taps

59
00:03:00,629 --> 00:03:03,420
filter just used 35 DB rejection which

60
00:03:03,420 --> 00:03:07,440
is might be okay might be not okay I did

61
00:03:07,440 --> 00:03:09,180
the original nine times over sampling

62
00:03:09,180 --> 00:03:10,889
and I came up with two mega samples per

63
00:03:10,889 --> 00:03:15,329
second well I needed four so it was not

64
00:03:15,329 --> 00:03:17,760
fast enough I tried to look into how

65
00:03:17,760 --> 00:03:21,810
could optimize it for or optimize it

66
00:03:21,810 --> 00:03:25,739
even more for x86 processors but

67
00:03:25,739 --> 00:03:27,810
actually the filtering was all like

68
00:03:27,810 --> 00:03:30,389
maxed out from optimization already

69
00:03:30,389 --> 00:03:33,209
I could have optimized the FFT somehow

70
00:03:33,209 --> 00:03:35,669
because I could not use fftw which kind

71
00:03:35,669 --> 00:03:38,730
of sucked but there would be like way

72
00:03:38,730 --> 00:03:41,489
too much time so I just let's write on

73
00:03:41,489 --> 00:03:43,349
the on CUDA I had some experience with

74
00:03:43,349 --> 00:03:45,629
it so let's do it

75
00:03:45,629 --> 00:03:48,449
so CUDA what is it cooter is a Nvidia's

76
00:03:48,449 --> 00:03:49,849
framework for general-purpose

77
00:03:49,849 --> 00:03:53,609
programming on graphics processing units

78
00:03:53,609 --> 00:03:56,760
it's mostly used I think for scientific

79
00:03:56,760 --> 00:04:00,209
computing where you have a huge problem

80
00:04:00,209 --> 00:04:02,579
that you can somehow paralyze a lot and

81
00:04:02,579 --> 00:04:04,500
you don't want your simulations to take

82
00:04:04,500 --> 00:04:08,310
years or a month or whatever yes it uses

83
00:04:08,310 --> 00:04:10,260
the massive amount of available compute

84
00:04:10,260 --> 00:04:12,930
cores inside the GPU so for example the

85
00:04:12,930 --> 00:04:15,120
GPU that we are we're using has like

86
00:04:15,120 --> 00:04:18,298
2000 cuda cores which is way more than

87
00:04:18,298 --> 00:04:24,840
x86 or so has yes so how is it cheap you

88
00:04:24,840 --> 00:04:28,080
build so normally to PU has four nvidia

89
00:04:28,080 --> 00:04:30,479
in this case has several streaming multi

90
00:04:30,479 --> 00:04:31,830
processors these

91
00:04:31,830 --> 00:04:34,230
you can think of as like the CPU you

92
00:04:34,230 --> 00:04:37,200
have in your normal PC but you have

93
00:04:37,200 --> 00:04:39,870
several of them in our case it was

94
00:04:39,870 --> 00:04:42,180
seven-day I'm not sure how far they go

95
00:04:42,180 --> 00:04:44,160
up but you can get one streaming

96
00:04:44,160 --> 00:04:46,920
multiprocessor in in the low-end

97
00:04:46,920 --> 00:04:48,360
graphics card too high and one have

98
00:04:48,360 --> 00:04:50,870
seven or eight or something like that

99
00:04:50,870 --> 00:04:53,460
each of this streaming multi processors

100
00:04:53,460 --> 00:04:57,180
has lots of course like your normal CPU

101
00:04:57,180 --> 00:05:00,000
and on your PC but instead of four cores

102
00:05:00,000 --> 00:05:04,980
the CPU that we used had 109 192 course

103
00:05:04,980 --> 00:05:08,160
if I'm correct so also a lot more than

104
00:05:08,160 --> 00:05:10,370
you're normally excited six CPU

105
00:05:10,370 --> 00:05:12,690
destruction that they use or the

106
00:05:12,690 --> 00:05:15,360
structure is a single instruct single

107
00:05:15,360 --> 00:05:17,400
instruction multiple threats structure

108
00:05:17,400 --> 00:05:19,530
so basically what they do is they take

109
00:05:19,530 --> 00:05:22,920
one instruction they broadcast it over

110
00:05:22,920 --> 00:05:24,930
several threats and all the threats do

111
00:05:24,930 --> 00:05:27,210
the same an instruction at the same

112
00:05:27,210 --> 00:05:30,810
times also you have some different kind

113
00:05:30,810 --> 00:05:33,210
of memories on your GPU that are

114
00:05:33,210 --> 00:05:35,400
actually really important that you know

115
00:05:35,400 --> 00:05:37,260
what they do and how they do it you have

116
00:05:37,260 --> 00:05:39,240
the global memory which is what they

117
00:05:39,240 --> 00:05:41,340
will sell you on the box is this like

118
00:05:41,340 --> 00:05:45,240
you get the new GTX 970 with 4 gigabyte

119
00:05:45,240 --> 00:05:47,430
rams which are actually just 3.5

120
00:05:47,430 --> 00:05:51,810
gigabyte this is really slow it's way

121
00:05:51,810 --> 00:05:54,330
faster than ddr3 or something like that

122
00:05:54,330 --> 00:05:58,560
but it's for GPU it's slow then you have

123
00:05:58,560 --> 00:06:00,990
to on chip memory this is tied to a

124
00:06:00,990 --> 00:06:03,210
specific streaming multiprocessor so all

125
00:06:03,210 --> 00:06:04,890
the course in the multi process I share

126
00:06:04,890 --> 00:06:07,530
all this memory which is faster way

127
00:06:07,530 --> 00:06:11,310
faster than the gd-r gd-r 4-5 Ram and

128
00:06:11,310 --> 00:06:13,320
then of course you have the registers

129
00:06:13,320 --> 00:06:16,560
like any CPU structure did a blazingly

130
00:06:16,560 --> 00:06:19,940
fast and way faster than anything else

131
00:06:19,940 --> 00:06:24,210
so CUDA tries to use that architecture

132
00:06:24,210 --> 00:06:26,820
as best as possible so first thing what

133
00:06:26,820 --> 00:06:30,240
it will do it will it will build up a

134
00:06:30,240 --> 00:06:31,740
grid and probably I just go to the next

135
00:06:31,740 --> 00:06:34,650
slide so this is how CUDA structures the

136
00:06:34,650 --> 00:06:38,250
threats that it will run to match the

137
00:06:38,250 --> 00:06:40,740
graphics card architecture so you have

138
00:06:40,740 --> 00:06:42,690
here this grid this is what you have to

139
00:06:42,690 --> 00:06:45,630
define in your program it can be up

140
00:06:45,630 --> 00:06:47,100
three dimensional it can be two or

141
00:06:47,100 --> 00:06:49,860
one-dimensional that's up to you for

142
00:06:49,860 --> 00:06:50,970
visualization

143
00:06:50,970 --> 00:06:52,890
I took the two-dimensional case so we

144
00:06:52,890 --> 00:06:57,330
have an X dimension and Y dimension each

145
00:06:57,330 --> 00:07:00,270
position in this matrix you could call

146
00:07:00,270 --> 00:07:03,480
it consists of a thread block a thread

147
00:07:03,480 --> 00:07:05,880
block is also just a compilation of

148
00:07:05,880 --> 00:07:08,640
threats that will run on one stream

149
00:07:08,640 --> 00:07:12,390
multiprocessor and inside each of these

150
00:07:12,390 --> 00:07:13,890
thread blocks then you have the

151
00:07:13,890 --> 00:07:17,610
individual threads that execute the

152
00:07:17,610 --> 00:07:19,470
instruction that you want to want them

153
00:07:19,470 --> 00:07:25,770
to execute so the way this works is that

154
00:07:25,770 --> 00:07:29,280
each of these blocks has a unique ID

155
00:07:29,280 --> 00:07:34,040
inside this grid so you can access block

156
00:07:34,040 --> 00:07:38,120
22 or access block whatever

157
00:07:38,120 --> 00:07:41,630
two-dimensional ID that you give them

158
00:07:41,630 --> 00:07:44,820
and each threat inside the threat block

159
00:07:44,820 --> 00:07:47,310
also has a unique ID within the threat

160
00:07:47,310 --> 00:07:49,350
block so if you know the idea of your

161
00:07:49,350 --> 00:07:51,990
thread block and the local ID of your

162
00:07:51,990 --> 00:07:54,120
thread inside the thread block you can

163
00:07:54,120 --> 00:07:57,260
basically access a threat

164
00:07:57,260 --> 00:08:01,500
inside your program what is a threat

165
00:08:01,500 --> 00:08:04,260
scheduler now does and how he executes

166
00:08:04,260 --> 00:08:08,130
those threats is he will collect the

167
00:08:08,130 --> 00:08:10,670
thread blocks assign them to one string

168
00:08:10,670 --> 00:08:15,360
multiprocessor and then it will further

169
00:08:15,360 --> 00:08:19,110
group these threats inside into bundles

170
00:08:19,110 --> 00:08:21,840
of 32 threats and they are called a warp

171
00:08:21,840 --> 00:08:25,620
and these 32 threats are actually the

172
00:08:25,620 --> 00:08:27,870
threats that I'm going to be executed

173
00:08:27,870 --> 00:08:30,330
simultaneously and you have to be a bit

174
00:08:30,330 --> 00:08:33,690
careful we will come to that later how

175
00:08:33,690 --> 00:08:36,390
you do calculations or anything inside

176
00:08:36,390 --> 00:08:39,750
those warps because the interaction

177
00:08:39,750 --> 00:08:44,099
between them is kind of special so yeah

178
00:08:44,099 --> 00:08:46,620
that's that you have some performance

179
00:08:46,620 --> 00:08:49,320
bottlenecks that you can run into very

180
00:08:49,320 --> 00:08:52,170
easily while doing your GPU and and you

181
00:08:52,170 --> 00:08:53,940
put your program into the GPU and you

182
00:08:53,940 --> 00:08:57,510
think well it's not really fast so these

183
00:08:57,510 --> 00:08:59,290
are some of the problem that you have

184
00:08:59,290 --> 00:09:01,570
first one is globe with memory it's not

185
00:09:01,570 --> 00:09:05,139
really fast so you want to minimize the

186
00:09:05,139 --> 00:09:08,139
usage in any case but even if you have

187
00:09:08,139 --> 00:09:10,180
to use it and you have to use it at one

188
00:09:10,180 --> 00:09:13,570
point you have to make sure that all

189
00:09:13,570 --> 00:09:16,690
your reads and all your rights from to

190
00:09:16,690 --> 00:09:18,910
memory are coalesced what does that mean

191
00:09:18,910 --> 00:09:22,630
is that consecutive threats access

192
00:09:22,630 --> 00:09:26,199
consecutive memory because then what the

193
00:09:26,199 --> 00:09:28,269
architecture can do it is it can load

194
00:09:28,269 --> 00:09:30,399
just one cache line for all the threats

195
00:09:30,399 --> 00:09:34,149
that need data and then distribute the

196
00:09:34,149 --> 00:09:36,790
cache line to all the data inside the

197
00:09:36,790 --> 00:09:39,910
cache line to all the threats this will

198
00:09:39,910 --> 00:09:42,670
be one load for several threats if you

199
00:09:42,670 --> 00:09:44,709
cross the cache line then of course it

200
00:09:44,709 --> 00:09:47,680
has to load two cache lines which might

201
00:09:47,680 --> 00:09:49,630
be way more loads that you would

202
00:09:49,630 --> 00:09:52,510
actually need for your instruction or

203
00:09:52,510 --> 00:09:54,459
whatever and then you just waste

204
00:09:54,459 --> 00:09:59,860
bandwidth so be careful about that then

205
00:09:59,860 --> 00:10:02,649
if you're using the shared memory memory

206
00:10:02,649 --> 00:10:05,050
you have a similar problem so shared

207
00:10:05,050 --> 00:10:07,149
memory can also be accessed in parallel

208
00:10:07,149 --> 00:10:11,350
if you access several banks in parallel

209
00:10:11,350 --> 00:10:14,110
and how the graphics card will structure

210
00:10:14,110 --> 00:10:17,050
it just memories that consecutive 32-bit

211
00:10:17,050 --> 00:10:20,380
words are in a different Bank so if your

212
00:10:20,380 --> 00:10:22,779
threats or consecutive threats just acts

213
00:10:22,779 --> 00:10:26,410
as a 32-bit word that is where the

214
00:10:26,410 --> 00:10:29,110
memory is consecutive they can also load

215
00:10:29,110 --> 00:10:33,910
all the data in one go if two threats

216
00:10:33,910 --> 00:10:35,769
access the same memory bank then of

217
00:10:35,769 --> 00:10:37,120
course you have two loads and you're

218
00:10:37,120 --> 00:10:41,199
wasting memory bandwidth then branching

219
00:10:41,199 --> 00:10:45,180
is also a difficult topic because it's a

220
00:10:45,180 --> 00:10:47,500
single instruction multiple threat

221
00:10:47,500 --> 00:10:49,959
architecture so you want your threats to

222
00:10:49,959 --> 00:10:53,800
or the threats have to do one

223
00:10:53,800 --> 00:10:55,750
instruction that is the same on every

224
00:10:55,750 --> 00:10:58,360
threat inside a wall so if you have a

225
00:10:58,360 --> 00:11:00,610
branch it might be that one threat

226
00:11:00,610 --> 00:11:02,620
inside the web has another instruction

227
00:11:02,620 --> 00:11:05,949
than the others so these threats then

228
00:11:05,949 --> 00:11:07,990
would have to be executed in Syria

229
00:11:07,990 --> 00:11:11,199
because which branch which instruction

230
00:11:11,199 --> 00:11:13,290
would you execute then

231
00:11:13,290 --> 00:11:15,870
so yes these are the three main

232
00:11:15,870 --> 00:11:18,400
performance killers that can come up

233
00:11:18,400 --> 00:11:21,160
when you do GPU programming and when

234
00:11:21,160 --> 00:11:23,410
you're if you're wondering why does my

235
00:11:23,410 --> 00:11:26,410
code not run as fast as I think it

236
00:11:26,410 --> 00:11:30,880
should go to this list so now polyphase

237
00:11:30,880 --> 00:11:33,940
filter banks what are they so basically

238
00:11:33,940 --> 00:11:35,950
polyphase filter banks are used for

239
00:11:35,950 --> 00:11:38,170
example if you want to reduce company

240
00:11:38,170 --> 00:11:41,140
computational complexity within

241
00:11:41,140 --> 00:11:43,330
resampling filters in general whether

242
00:11:43,330 --> 00:11:45,550
you decimate or interpolate it really

243
00:11:45,550 --> 00:11:49,230
doesn't matter but they're used for that

244
00:11:49,230 --> 00:11:51,880
then what you can also do if you have a

245
00:11:51,880 --> 00:11:54,160
scheme like we had in our project where

246
00:11:54,160 --> 00:11:56,490
you have several channels you can

247
00:11:56,490 --> 00:11:59,080
separate one channel with a polyphase

248
00:11:59,080 --> 00:12:01,060
filter bank but you can also separate

249
00:12:01,060 --> 00:12:03,430
all channel at once in one go which is

250
00:12:03,430 --> 00:12:05,890
the cool thing about these polyphase

251
00:12:05,890 --> 00:12:08,290
filter Bank channel lasers what you can

252
00:12:08,290 --> 00:12:10,080
also do is you can take several

253
00:12:10,080 --> 00:12:15,520
separated like information signals and

254
00:12:15,520 --> 00:12:18,160
then distribute all of them into a wider

255
00:12:18,160 --> 00:12:21,250
spectrum this is what synthesizer does

256
00:12:21,250 --> 00:12:24,040
which we also have implemented but in

257
00:12:24,040 --> 00:12:25,570
this talk I'm going to concentrate on

258
00:12:25,570 --> 00:12:26,560
the channel either

259
00:12:26,560 --> 00:12:28,660
because there is already enough stuff to

260
00:12:28,660 --> 00:12:32,620
do so what you would normally do if you

261
00:12:32,620 --> 00:12:35,050
would extract a channel that has one end

262
00:12:35,050 --> 00:12:39,010
of the total bandwidth of your of you of

263
00:12:39,010 --> 00:12:42,280
the signal that you recorded this well

264
00:12:42,280 --> 00:12:44,050
you could first mix your signal to a

265
00:12:44,050 --> 00:12:46,870
baseband and then do a low-pass fyr

266
00:12:46,870 --> 00:12:50,500
filter over it because you have to do

267
00:12:50,500 --> 00:12:53,500
this to get rid of all the aliasing when

268
00:12:53,500 --> 00:12:55,240
you're down simple you can also switch

269
00:12:55,240 --> 00:12:58,060
this you can own for a first you like a

270
00:12:58,060 --> 00:13:00,940
bandpass filtering and then do the down

271
00:13:00,940 --> 00:13:03,370
conversion of course and then you can

272
00:13:03,370 --> 00:13:06,400
down sample the signal the problem as I

273
00:13:06,400 --> 00:13:09,730
said with this is if you have a small

274
00:13:09,730 --> 00:13:11,380
channel compared to the overall

275
00:13:11,380 --> 00:13:13,660
bandwidth your filters will get very

276
00:13:13,660 --> 00:13:16,560
steep and they will get very

277
00:13:16,560 --> 00:13:18,820
computational heavy polyphase filter

278
00:13:18,820 --> 00:13:23,390
Bank somehow help in that respect

279
00:13:23,390 --> 00:13:25,459
so the polyphase filter bank what it

280
00:13:25,459 --> 00:13:28,250
does is it basically takes your filter

281
00:13:28,250 --> 00:13:31,269
taps or your filter impulse response and

282
00:13:31,269 --> 00:13:34,070
then splits them into the N different

283
00:13:34,070 --> 00:13:37,310
phase shares or the face parts that

284
00:13:37,310 --> 00:13:40,040
filter has which I will show you in a

285
00:13:40,040 --> 00:13:42,250
second so this is like a tap

286
00:13:42,250 --> 00:13:44,149
representation of your filter right we

287
00:13:44,149 --> 00:13:46,970
have 16 taps from type zero to type 15

288
00:13:46,970 --> 00:13:49,550
and normally you would just like shift

289
00:13:49,550 --> 00:13:52,640
your signal through that in one go like

290
00:13:52,640 --> 00:13:57,190
serially and then you get the output so

291
00:13:57,190 --> 00:14:00,350
the P now we had the PFP will split

292
00:14:00,350 --> 00:14:04,670
these into the taps so you have like the

293
00:14:04,670 --> 00:14:09,110
first phase part is our direct taps and

294
00:14:09,110 --> 00:14:11,750
then the blue ones are the second phase

295
00:14:11,750 --> 00:14:15,290
parts and so on what you can do then is

296
00:14:15,290 --> 00:14:18,110
you can read or reorder those tabs and

297
00:14:18,110 --> 00:14:22,130
then basically serve build new filters

298
00:14:22,130 --> 00:14:24,980
that are now for four type filters so

299
00:14:24,980 --> 00:14:26,899
and totally you still have 16 taps but

300
00:14:26,899 --> 00:14:30,620
you have four yep they only have four

301
00:14:30,620 --> 00:14:34,850
taps and you have four filters this will

302
00:14:34,850 --> 00:14:37,149
help in a regard that if you know how

303
00:14:37,149 --> 00:14:39,709
computational complexity grows within a

304
00:14:39,709 --> 00:14:42,079
filter it's if you want to sample a

305
00:14:42,079 --> 00:14:46,300
signal is n square so now we have

306
00:14:46,300 --> 00:14:50,839
basically n divided by four square times

307
00:14:50,839 --> 00:14:55,790
four which is way better then the usual

308
00:14:55,790 --> 00:14:58,430
filter complexity we actually have

309
00:14:58,430 --> 00:15:00,769
divided computational complexity by four

310
00:15:00,769 --> 00:15:03,019
so what we will do now is we will get

311
00:15:03,019 --> 00:15:05,390
samples from from your source

312
00:15:05,390 --> 00:15:07,670
the first sample will go to the the

313
00:15:07,670 --> 00:15:09,560
first filter the second sampler will go

314
00:15:09,560 --> 00:15:11,390
to the second filter and so on which is

315
00:15:11,390 --> 00:15:13,490
switch through all the filters when we

316
00:15:13,490 --> 00:15:14,570
are down

317
00:15:14,570 --> 00:15:17,750
we go up again basically what you can

318
00:15:17,750 --> 00:15:20,360
think of it in a simple way or how I

319
00:15:20,360 --> 00:15:23,029
always visualize it is if you down

320
00:15:23,029 --> 00:15:24,740
sample the signal what you actually do

321
00:15:24,740 --> 00:15:27,860
is you compute all your 60 in output

322
00:15:27,860 --> 00:15:30,350
samples and then you throw away 12 of

323
00:15:30,350 --> 00:15:35,750
them and this is and if you would map

324
00:15:35,750 --> 00:15:36,720
that

325
00:15:36,720 --> 00:15:38,759
to your filter operation it's like you

326
00:15:38,759 --> 00:15:41,040
kind of just do a snapshot of your

327
00:15:41,040 --> 00:15:44,189
filter every for computations and this

328
00:15:44,189 --> 00:15:45,930
is actually what it does in the end

329
00:15:45,930 --> 00:15:49,019
everything gets added together and then

330
00:15:49,019 --> 00:15:50,810
you have your resampling filter already

331
00:15:50,810 --> 00:15:54,720
so if you want to now extract a channel

332
00:15:54,720 --> 00:15:56,430
you basically have to know where your

333
00:15:56,430 --> 00:16:00,089
channel is and then down convert the

334
00:16:00,089 --> 00:16:02,430
channel by applying a multiplication

335
00:16:02,430 --> 00:16:05,810
with the complex wave if you do an FFT

336
00:16:05,810 --> 00:16:08,699
after your filtering you get all the

337
00:16:08,699 --> 00:16:12,620
channel at once and and yeah basically

338
00:16:12,620 --> 00:16:16,199
you do - just one filter ring - one FFT

339
00:16:16,199 --> 00:16:20,279
and get all channels that you want so

340
00:16:20,279 --> 00:16:21,810
you can also do some different things

341
00:16:21,810 --> 00:16:23,579
you can over sample the output of the

342
00:16:23,579 --> 00:16:24,959
channel which is basically you

343
00:16:24,959 --> 00:16:27,870
manipulate this commutator so instead of

344
00:16:27,870 --> 00:16:30,240
for example if you want to over sample

345
00:16:30,240 --> 00:16:33,629
it by a factor of two you don't shift

346
00:16:33,629 --> 00:16:37,949
every inputs basically the the first

347
00:16:37,949 --> 00:16:40,350
sampler goes to a t0 and then gets

348
00:16:40,350 --> 00:16:42,600
shifted to t4 no then it gets shifted to

349
00:16:42,600 --> 00:16:47,730
t2 actually yeah if you want to

350
00:16:47,730 --> 00:16:49,920
synthesize instead of channelized you

351
00:16:49,920 --> 00:16:51,779
can basically do the same operations but

352
00:16:51,779 --> 00:16:53,759
you just reverse it you first to the FFT

353
00:16:53,759 --> 00:16:59,069
then do the filtering etc so how you

354
00:16:59,069 --> 00:17:01,949
could translate it into CUDA so if

355
00:17:01,949 --> 00:17:04,439
you're familiar with how CUDA works and

356
00:17:04,439 --> 00:17:08,010
you want to do all this quick basically

357
00:17:08,010 --> 00:17:10,890
consecutive memory access all you do is

358
00:17:10,890 --> 00:17:14,159
gonna shuffle so the channel as we saw

359
00:17:14,159 --> 00:17:16,049
consists of four operations we have to

360
00:17:16,049 --> 00:17:18,599
shuffle the input stream from a serial

361
00:17:18,599 --> 00:17:21,630
stream to this parallel stream we have

362
00:17:21,630 --> 00:17:23,429
to do the polyphase filtering we have to

363
00:17:23,429 --> 00:17:26,240
do the FFT and after the FFT we have to

364
00:17:26,240 --> 00:17:30,110
parallel to serialize the signal again

365
00:17:30,110 --> 00:17:34,260
so input shuffling actually I don't like

366
00:17:34,260 --> 00:17:36,150
this slide and I don't like how I

367
00:17:36,150 --> 00:17:41,429
implemented it in my library so I took

368
00:17:41,429 --> 00:17:43,590
the easy road and said okay I wanna if

369
00:17:43,590 --> 00:17:45,780
you basically shuffle stuff you either

370
00:17:45,780 --> 00:17:48,240
read a cordless or your right cordless

371
00:17:48,240 --> 00:17:49,140
there's

372
00:17:49,140 --> 00:17:52,050
nothing you can do one of the memory

373
00:17:52,050 --> 00:17:54,540
loads will be uncoolest so I decided

374
00:17:54,540 --> 00:17:57,510
that I could ask my reach because this

375
00:17:57,510 --> 00:18:00,690
is somehow the more logical or was more

376
00:18:00,690 --> 00:18:05,550
logical to me and then right leg

377
00:18:05,550 --> 00:18:08,340
scattered the problem with this is if

378
00:18:08,340 --> 00:18:10,200
you want to read them coalesced you

379
00:18:10,200 --> 00:18:12,360
basically take your thread blocks and

380
00:18:12,360 --> 00:18:14,280
then you have an X dimension in your

381
00:18:14,280 --> 00:18:16,850
thread blocks it is the number of your

382
00:18:16,850 --> 00:18:21,140
channels and if you remember that

383
00:18:21,140 --> 00:18:26,040
schedule a tries to bundle the 32

384
00:18:26,040 --> 00:18:28,350
threads to a warp and then execute them

385
00:18:28,350 --> 00:18:32,010
and it starts on the X time actually in

386
00:18:32,010 --> 00:18:33,570
the first dimension of the thread block

387
00:18:33,570 --> 00:18:36,210
if you have less than 32 channels you

388
00:18:36,210 --> 00:18:37,800
are not going to end up with the holy

389
00:18:37,800 --> 00:18:41,100
war so in my case we're at 45 channels

390
00:18:41,100 --> 00:18:42,570
it probably didn't make that much of a

391
00:18:42,570 --> 00:18:44,160
difference but if you have less than

392
00:18:44,160 --> 00:18:46,770
that 32 channels it might make a

393
00:18:46,770 --> 00:18:49,200
difference so I'm going to revisit that

394
00:18:49,200 --> 00:18:51,650
and see if it stays like that

395
00:18:51,650 --> 00:18:56,280
so filter operation yes we have a

396
00:18:56,280 --> 00:18:58,350
basically two-dimensional grid and

397
00:18:58,350 --> 00:19:01,230
two-dimensional thread locks the first

398
00:19:01,230 --> 00:19:02,640
dimension in the block computes

399
00:19:02,640 --> 00:19:04,500
basically several input samples because

400
00:19:04,500 --> 00:19:07,890
we want to maximize out our GPU and just

401
00:19:07,890 --> 00:19:11,280
calculating one sample output we would

402
00:19:11,280 --> 00:19:13,730
still have a lot of threats idle so

403
00:19:13,730 --> 00:19:16,740
these are compute several inputs a input

404
00:19:16,740 --> 00:19:19,530
samples at once process every input

405
00:19:19,530 --> 00:19:23,190
samples I want the second time mentioned

406
00:19:23,190 --> 00:19:24,960
the Y dimension takes care of if I want

407
00:19:24,960 --> 00:19:28,380
out over sample the output this is taken

408
00:19:28,380 --> 00:19:32,730
care of in that one our first dimension

409
00:19:32,730 --> 00:19:34,890
of the grid basically represents how

410
00:19:34,890 --> 00:19:39,590
many channels and want to have and the

411
00:19:39,590 --> 00:19:41,730
second dimension of the grid is just

412
00:19:41,730 --> 00:19:47,130
there if we don't have enough well don't

413
00:19:47,130 --> 00:19:49,680
have enough threats already executing

414
00:19:49,680 --> 00:19:51,060
then those will provide additional

415
00:19:51,060 --> 00:19:53,820
concurrency just one thing I want to

416
00:19:53,820 --> 00:19:57,480
show you how that the code for that

417
00:19:57,480 --> 00:20:02,049
looks like so the actual filter ring is

418
00:20:02,049 --> 00:20:08,450
 oh wait yes the actual filtering is

419
00:20:08,450 --> 00:20:13,210
just these lines the rest is just

420
00:20:13,210 --> 00:20:16,990
shuffling sorry

421
00:20:17,259 --> 00:20:23,480
this is shuffling up what them so no

422
00:20:23,480 --> 00:20:26,659
marking so this is shuffling of the

423
00:20:26,659 --> 00:20:30,200
memory and all the rest is just finding

424
00:20:30,200 --> 00:20:35,980
out in which threat I'm actually so yeah

425
00:20:35,980 --> 00:20:38,509
this is basically all what you do inside

426
00:20:38,509 --> 00:20:40,850
your code in CUDA you've tried to find

427
00:20:40,850 --> 00:20:46,940
out where the hell you are so yeah if

428
00:20:46,940 --> 00:20:49,159
you're a couple of other things for the

429
00:20:49,159 --> 00:20:50,750
filter operations we go to shared memory

430
00:20:50,750 --> 00:20:54,470
which try to avoid bank conflicts which

431
00:20:54,470 --> 00:20:56,179
is not that easy because we have

432
00:20:56,179 --> 00:20:59,480
actually complex samples which are 64

433
00:20:59,480 --> 00:21:03,019
bits so not two 32-bit words that we

434
00:21:03,019 --> 00:21:05,360
would need for the loads from shared

435
00:21:05,360 --> 00:21:09,009
memory as far as the compiler output

436
00:21:09,009 --> 00:21:11,600
concerns we don't have any registered or

437
00:21:11,600 --> 00:21:14,500
shared memory spills that's always good

438
00:21:14,500 --> 00:21:17,360
the FFT is just the qff T which is

439
00:21:17,360 --> 00:21:19,909
provided by CUDA I mean minutes faster

440
00:21:19,909 --> 00:21:22,309
it's convenient so why not use it the

441
00:21:22,309 --> 00:21:23,840
output shuffling is because I was

442
00:21:23,840 --> 00:21:27,590
actually lazy implemented on the host

443
00:21:27,590 --> 00:21:30,860
CPU for now this might change as well I

444
00:21:30,860 --> 00:21:33,139
don't expect much of a performance boost

445
00:21:33,139 --> 00:21:36,700
maybe in a 1% a one digit percentage for

446
00:21:36,700 --> 00:21:39,529
area but it would be nice to have

447
00:21:39,529 --> 00:21:41,629
everything on the GPU for me at the time

448
00:21:41,629 --> 00:21:44,809
it was plenty fast enough so we have

449
00:21:44,809 --> 00:21:47,059
some results so this is 32 channel

450
00:21:47,059 --> 00:21:49,759
separations with no oversampling the

451
00:21:49,759 --> 00:21:52,340
prototype filter was a 437 type filter

452
00:21:52,340 --> 00:21:55,820
so rather small and here we see we as

453
00:21:55,820 --> 00:21:59,360
benchmark to GTX 970 against trusty old

454
00:21:59,360 --> 00:22:02,090
GNU radio polyphase filter Bank and

455
00:22:02,090 --> 00:22:04,009
actually the polyphase filter Bank of

456
00:22:04,009 --> 00:22:08,019
Maria is doing very good this is for gtp

457
00:22:08,019 --> 00:22:11,539
really remarkable what we see we get to

458
00:22:11,539 --> 00:22:15,110
160 mega samples with with a cuda

459
00:22:15,110 --> 00:22:16,879
implementation which is roughly four

460
00:22:16,879 --> 00:22:19,929
times as fast as the GPU a cpu version

461
00:22:19,929 --> 00:22:22,850
this is the actual filter that we use in

462
00:22:22,850 --> 00:22:25,909
the projects for the 45 channel case we

463
00:22:25,909 --> 00:22:27,649
have three times over sampling 45

464
00:22:27,649 --> 00:22:31,519
channels 15 hundred and one tabs so we

465
00:22:31,519 --> 00:22:34,190
see this this time we actually have

466
00:22:34,190 --> 00:22:38,240
three GPUs there is also the GT 720 m

467
00:22:38,240 --> 00:22:40,100
which is a laptop

468
00:22:40,100 --> 00:22:44,000
early really low-level laptop GPU with

469
00:22:44,000 --> 00:22:46,549
just one screaming multi processor and

470
00:22:46,549 --> 00:22:50,149
you see we still get above 100 mega

471
00:22:50,149 --> 00:22:52,220
samples with the cuda implementation on

472
00:22:52,220 --> 00:22:58,850
the GTX 970 720 GT is a bit worse or far

473
00:22:58,850 --> 00:23:01,039
worse with 14 mega samples which which

474
00:23:01,039 --> 00:23:05,179
would still be okay in our use case and

475
00:23:05,179 --> 00:23:07,580
then the CPU version is actually not

476
00:23:07,580 --> 00:23:13,369
that much slower than the GT m 720 so

477
00:23:13,369 --> 00:23:16,129
margin also said that I should tell you

478
00:23:16,129 --> 00:23:17,840
something about the release plans and

479
00:23:17,840 --> 00:23:21,769
open source strategies at DLR well to be

480
00:23:21,769 --> 00:23:24,799
sure there is no open source release

481
00:23:24,799 --> 00:23:27,110
strategy at DLR at least no global one

482
00:23:27,110 --> 00:23:29,419
so if you work at DLR and you think I

483
00:23:29,419 --> 00:23:31,039
want to release something you just go to

484
00:23:31,039 --> 00:23:33,320
your superior and ask if you can do it

485
00:23:33,320 --> 00:23:36,769
then you have to go to whoever is

486
00:23:36,769 --> 00:23:38,809
supervising the project and ask if you

487
00:23:38,809 --> 00:23:41,360
can do it and then just put it on github

488
00:23:41,360 --> 00:23:44,779
or whatever maybe if it's like for for

489
00:23:44,779 --> 00:23:47,419
the military you have to ask for export

490
00:23:47,419 --> 00:23:50,629
code export control services but in

491
00:23:50,629 --> 00:23:53,090
principle it's your own personal choice

492
00:23:53,090 --> 00:23:56,299
so it's still not released we still have

493
00:23:56,299 --> 00:23:58,669
some bureaucratic hurdles in sight DLR

494
00:23:58,669 --> 00:24:02,659
because we do not have a formal way to

495
00:24:02,659 --> 00:24:05,659
do it it's also still dependent on some

496
00:24:05,659 --> 00:24:07,190
project code and I want to get rid of

497
00:24:07,190 --> 00:24:10,340
these dependencies but I can tell you

498
00:24:10,340 --> 00:24:12,259
the license so we decided it will be

499
00:24:12,259 --> 00:24:17,000
LGPL 3 and it will be on on github

500
00:24:17,000 --> 00:24:19,609
probably in a group kay and san which is

501
00:24:19,609 --> 00:24:22,279
our department communication navigation

502
00:24:22,279 --> 00:24:24,830
satellite networks if you want some news

503
00:24:24,830 --> 00:24:26,659
and when it's released probably it's the

504
00:24:26,659 --> 00:24:27,980
best to

505
00:24:27,980 --> 00:24:29,779
my guitar because I don't think that

506
00:24:29,779 --> 00:24:32,590
there will be a German Aerospace and

507
00:24:32,590 --> 00:24:36,799
news about that so that's it thank you

508
00:24:36,799 --> 00:24:43,279
for listening to me and we have time for

509
00:24:43,279 --> 00:24:58,630
questions yes the longest perfect sorry

510
00:24:58,630 --> 00:25:03,649
I mentioned it towards the biggest so

511
00:25:03,649 --> 00:25:05,389
the biggest that I tested was roughly

512
00:25:05,389 --> 00:25:09,309
1,700 taps and it ran I think 80 mega

513
00:25:09,309 --> 00:25:19,610
samples per second so yeah that could be

514
00:25:19,610 --> 00:25:23,149
sort of the limitation I think for the

515
00:25:23,149 --> 00:25:25,159
filter not because they go to this this

516
00:25:25,159 --> 00:25:27,909
local memory the way can store these

517
00:25:27,909 --> 00:25:32,269
like constant stuff so if this memory

518
00:25:32,269 --> 00:25:35,510
runs out then you might be in

519
00:25:35,510 --> 00:25:39,409
performance trouble but I have not come

520
00:25:39,409 --> 00:25:41,090
to that point yet so I think there is

521
00:25:41,090 --> 00:25:44,740
plenty of space for even longer filters

522
00:25:44,740 --> 00:25:56,500
yes Ben yes

523
00:25:58,399 --> 00:26:01,519
the major core concern is always that

524
00:26:01,519 --> 00:26:03,559
the GPUs are super high bandwidth but

525
00:26:03,559 --> 00:26:07,700
also also high latency yeah yeah based

526
00:26:07,700 --> 00:26:09,470
on the work that you've done what I

527
00:26:09,470 --> 00:26:12,559
guess what is your opinion of how

528
00:26:12,559 --> 00:26:14,779
feasible it would be to basically drop a

529
00:26:14,779 --> 00:26:17,769
GPU blocking

530
00:26:19,230 --> 00:26:27,480
a streaming performance fool that's a

531
00:26:27,480 --> 00:26:29,970
good question because there is also

532
00:26:29,970 --> 00:26:32,309
another problem with at least with most

533
00:26:32,309 --> 00:26:38,010
of these like these few problems on GPU

534
00:26:38,010 --> 00:26:39,960
you have to buffer first a buttload of

535
00:26:39,960 --> 00:26:44,040
samples to get to this parallelism that

536
00:26:44,040 --> 00:26:46,710
you can actually exploit a GPU so I

537
00:26:46,710 --> 00:26:48,240
would guess that the latency from

538
00:26:48,240 --> 00:26:49,830
buffering december's would be higher

539
00:26:49,830 --> 00:26:53,210
than the latency from getting them to

540
00:26:53,210 --> 00:26:56,429
because also this this 180 mega samples

541
00:26:56,429 --> 00:26:58,260
okay its throughput it's not latency

542
00:26:58,260 --> 00:27:02,730
it's measured with with the data copy

543
00:27:02,730 --> 00:27:10,260
from say a host to GPU so we have to

544
00:27:10,260 --> 00:27:13,080
stop yeah okay ten sorry but I'm really

545
00:27:13,080 --> 00:27:15,649
hanging around

