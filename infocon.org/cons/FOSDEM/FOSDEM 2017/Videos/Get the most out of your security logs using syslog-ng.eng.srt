1
00:00:00,000 --> 00:00:02,690
four or three

2
00:00:04,750 --> 00:00:09,230
e2 1 hello welcome to the final session

3
00:00:09,230 --> 00:00:14,330
of the security devrel blitz

4
00:00:14,330 --> 00:00:16,430
let's welcome Peter who will talk about

5
00:00:16,430 --> 00:00:25,689
syslog-ng thank you thank you

6
00:00:26,840 --> 00:00:30,259
first a few words about me and sorry for

7
00:00:30,259 --> 00:00:32,989
those who were there yesterday in in my

8
00:00:32,989 --> 00:00:37,070
talk the first few slides will sound

9
00:00:37,070 --> 00:00:39,199
quite familiar

10
00:00:39,199 --> 00:00:42,140
I'm Peter Tunney from Hungary community

11
00:00:42,140 --> 00:00:44,869
manager at bally beat syslog-ng is

12
00:00:44,869 --> 00:00:46,790
upstream developer I'm working on

13
00:00:46,790 --> 00:00:52,430
packaging supporting system Gangji first

14
00:00:52,430 --> 00:00:56,439
of all what is logging it's recording of

15
00:00:56,439 --> 00:01:01,299
events on a computer for example an SSH

16
00:01:01,299 --> 00:01:04,489
login message under word log messages in

17
00:01:04,489 --> 00:01:10,189
a file you can see here

18
00:01:10,189 --> 00:01:13,700
Cisco Gangji itself is an enhanced login

19
00:01:13,700 --> 00:01:15,740
teaming with a strong focus on high

20
00:01:15,740 --> 00:01:20,049
performance center log collection why

21
00:01:20,049 --> 00:01:22,999
central login first of all its ease of

22
00:01:22,999 --> 00:01:27,170
use one place to check for your log

23
00:01:27,170 --> 00:01:29,570
messages instead of money it's also

24
00:01:29,570 --> 00:01:32,689
availability so even if the standard

25
00:01:32,689 --> 00:01:37,009
machine is down you can read the locks

26
00:01:37,009 --> 00:01:39,560
at the central location and last but not

27
00:01:39,560 --> 00:01:43,729
least it's also security as the first

28
00:01:43,729 --> 00:01:47,479
thing in hacking the machine is to

29
00:01:47,479 --> 00:01:51,289
remove traces of what you have done but

30
00:01:51,289 --> 00:01:55,759
if you have center logging then all of

31
00:01:55,759 --> 00:01:58,850
your all of the traces are F or

32
00:01:58,850 --> 00:02:01,009
forwarded in real time to a central

33
00:02:01,009 --> 00:02:03,979
location where you can check it what

34
00:02:03,979 --> 00:02:07,909
happened to the Machine there are four

35
00:02:07,909 --> 00:02:11,450
being doors of Cisco Gangji first of all

36
00:02:11,450 --> 00:02:14,270
it's collecting messages it also can

37
00:02:14,270 --> 00:02:16,580
process log messages filtered them and

38
00:02:16,580 --> 00:02:18,080
at the end either

39
00:02:18,080 --> 00:02:23,160
locally or forward somewhere the main

40
00:02:23,160 --> 00:02:27,510
door the first was data collection and I

41
00:02:27,510 --> 00:02:30,390
say data and not local action as systems

42
00:02:30,390 --> 00:02:32,790
you can collect practically any kind of

43
00:02:32,790 --> 00:02:35,660
data system messages application logs

44
00:02:35,660 --> 00:02:38,670
together and they can provide quite

45
00:02:38,670 --> 00:02:43,010
useful contextual data for either side

46
00:02:43,010 --> 00:02:46,800
it can collect messages from a wide

47
00:02:46,800 --> 00:02:49,200
variety of platform specific sources

48
00:02:49,200 --> 00:02:53,070
like dev vlog or journa or sunscreens as

49
00:02:53,070 --> 00:02:55,519
many different platforms are supported

50
00:02:55,519 --> 00:02:59,940
as a central log collector it knows both

51
00:02:59,940 --> 00:03:02,819
the legacy and the new system protocol

52
00:03:02,819 --> 00:03:10,140
and can use UDP TCP TRS you know in many

53
00:03:10,140 --> 00:03:16,260
cases it can also collect logs or any

54
00:03:16,260 --> 00:03:18,480
kind of data from applications through

55
00:03:18,480 --> 00:03:22,290
feist sockets pipes and if the

56
00:03:22,290 --> 00:03:23,970
application is started by Cisco Ganges

57
00:03:23,970 --> 00:03:29,519
and even application output the next and

58
00:03:29,519 --> 00:03:33,570
in my opinion the most important role at

59
00:03:33,570 --> 00:03:36,090
least in a security environment is lock

60
00:03:36,090 --> 00:03:38,790
processing with using Cisco Gangi you

61
00:03:38,790 --> 00:03:40,920
can classify an organized and structure

62
00:03:40,920 --> 00:03:45,030
structure log messages I will talk about

63
00:03:45,030 --> 00:03:45,810
this later

64
00:03:45,810 --> 00:03:48,840
you can even rewrite rogue messages and

65
00:03:48,840 --> 00:03:51,239
you don't have to think about falsifying

66
00:03:51,239 --> 00:03:55,620
messages here but for example in many

67
00:03:55,620 --> 00:03:59,130
cases you need to anonymize log messages

68
00:03:59,130 --> 00:04:04,049
due to compliance requirements messages

69
00:04:04,049 --> 00:04:07,640
can also be reformatted using templates

70
00:04:07,640 --> 00:04:11,670
when local log analysis software needs a

71
00:04:11,670 --> 00:04:15,030
specific format like a specific date

72
00:04:15,030 --> 00:04:18,180
format or have locks in JSON for no tank

73
00:04:18,180 --> 00:04:23,310
and so on and you can also n

74
00:04:23,310 --> 00:04:28,310
data using geoip or adding

75
00:04:28,310 --> 00:04:32,960
Fields based on the message content the

76
00:04:32,960 --> 00:04:37,070
next role is filtering it has two main

77
00:04:37,070 --> 00:04:41,660
uses first of all discarding surplus

78
00:04:41,660 --> 00:04:46,640
looks like debug level messages or the

79
00:04:46,640 --> 00:04:50,690
other one is message routing so you can

80
00:04:50,690 --> 00:04:53,150
make sure that the right messages reach

81
00:04:53,150 --> 00:04:56,470
the right destinations for example to

82
00:04:56,470 --> 00:05:00,410
even send out the authentication related

83
00:05:00,410 --> 00:05:04,010
messages to assume system there are many

84
00:05:04,010 --> 00:05:07,190
possibilities for filtering it can be

85
00:05:07,190 --> 00:05:12,280
based on message content or parameters

86
00:05:12,280 --> 00:05:15,770
using comparisons wildcards and many

87
00:05:15,770 --> 00:05:17,660
different filtering functions and best

88
00:05:17,660 --> 00:05:19,730
of all any of these can be combined

89
00:05:19,730 --> 00:05:24,980
using boolean operators at the end you

90
00:05:24,980 --> 00:05:27,530
can either store your messages locally

91
00:05:27,530 --> 00:05:30,740
or for one to many different

92
00:05:30,740 --> 00:05:37,550
destinations here comes the tricky

93
00:05:37,550 --> 00:05:38,600
question

94
00:05:38,600 --> 00:05:42,260
for those who don't check my slides

95
00:05:42,260 --> 00:05:46,250
right now I mean when you're on a phone

96
00:05:46,250 --> 00:05:50,840
also which sister Gangji is the which

97
00:05:50,840 --> 00:05:52,970
this organza version is the most most

98
00:05:52,970 --> 00:05:55,790
used do you have any idea project

99
00:05:55,790 --> 00:05:59,420
started long time ago

100
00:05:59,420 --> 00:06:00,820
[Music]

101
00:06:00,820 --> 00:06:04,670
Red Hat has version 3.5 the latest

102
00:06:04,670 --> 00:06:05,390
stable version

103
00:06:05,390 --> 00:06:09,140
oh it's actually 3.9 what do you think

104
00:06:09,140 --> 00:06:12,290
which is the most useful option any

105
00:06:12,290 --> 00:06:14,530
guesses

106
00:06:17,330 --> 00:06:21,919
you were the closest as its version 1.6

107
00:06:21,919 --> 00:06:26,629
us there are over a hundred million

108
00:06:26,629 --> 00:06:28,340
Kindle eBook readers and all of those

109
00:06:28,340 --> 00:06:32,990
run syslog-ng for Rock Corrections now

110
00:06:32,990 --> 00:06:37,990
back to more serious topics bit about

111
00:06:37,990 --> 00:06:41,240
message formats if you take a look at

112
00:06:41,240 --> 00:06:43,759
under of our log messages you will see

113
00:06:43,759 --> 00:06:46,099
that most of the messages have the date

114
00:06:46,099 --> 00:06:49,699
hostname and some kind of text at the

115
00:06:49,699 --> 00:06:52,789
end the text part is an English sentence

116
00:06:52,789 --> 00:06:55,009
with some variable parts in it it's

117
00:06:55,009 --> 00:06:57,740
quite easy to be to read by a human but

118
00:06:57,740 --> 00:06:59,719
if you have a busy server with a

119
00:06:59,719 --> 00:07:03,289
thousand messages a second it's quite

120
00:07:03,289 --> 00:07:06,020
difficult to deal with it as you cannot

121
00:07:06,020 --> 00:07:07,969
read you don't have the time and the

122
00:07:07,969 --> 00:07:11,349
Machine cannot really understand it

123
00:07:11,349 --> 00:07:14,900
there is a solution for this problem

124
00:07:14,900 --> 00:07:17,990
it's called structured logging in this

125
00:07:17,990 --> 00:07:21,500
case events are represented as name

126
00:07:21,500 --> 00:07:25,460
value pairs back to my favorite example

127
00:07:25,460 --> 00:07:28,400
SSH login example that you can describe

128
00:07:28,400 --> 00:07:30,650
the event as application

129
00:07:30,650 --> 00:07:35,509
SSH the user root and as IP address the

130
00:07:35,509 --> 00:07:37,520
good news is that this token G has named

131
00:07:37,520 --> 00:07:39,620
value pairs inside right from the

132
00:07:39,620 --> 00:07:42,050
beginning facility priority and so on

133
00:07:42,050 --> 00:07:47,389
are all saved us mean value pairs so

134
00:07:47,389 --> 00:07:50,389
that this is the way how it how you

135
00:07:50,389 --> 00:07:52,370
could use them in filters or in

136
00:07:52,370 --> 00:07:57,620
templates and there are partners in

137
00:07:57,620 --> 00:08:00,830
syslog-ng which can turn unstructured

138
00:08:00,830 --> 00:08:04,669
and some structured data into name value

139
00:08:04,669 --> 00:08:08,539
pairs as well let's talk about these and

140
00:08:08,539 --> 00:08:13,969
the first one is the JSON parser if if

141
00:08:13,969 --> 00:08:17,060
you couldn't parse JSON which is the

142
00:08:17,060 --> 00:08:21,830
engi then you then you can see inside

143
00:08:21,830 --> 00:08:23,900
the message just simply store the whole

144
00:08:23,900 --> 00:08:25,600
JSON

145
00:08:25,600 --> 00:08:28,780
message somewhere but a Cisco Kenji can

146
00:08:28,780 --> 00:08:30,940
parse JSON messages you can use the

147
00:08:30,940 --> 00:08:36,520
values inside the adjacent message for

148
00:08:36,520 --> 00:08:39,039
filtering for perform a ping for other

149
00:08:39,039 --> 00:08:44,860
destinations so the in for me data is

150
00:08:44,860 --> 00:08:50,530
much more value bit this way CSV parser

151
00:08:50,530 --> 00:08:54,670
can parse columnar data into fields the

152
00:08:54,670 --> 00:08:58,180
most popular example is Apache access

153
00:08:58,180 --> 00:09:00,880
log in this configuration snippet you

154
00:09:00,880 --> 00:09:06,370
can see the the column numbers and if

155
00:09:06,370 --> 00:09:09,490
you take a look here at the bottom after

156
00:09:09,490 --> 00:09:13,480
screen you will see that the user name

157
00:09:13,480 --> 00:09:18,550
is used in a file name template so each

158
00:09:18,550 --> 00:09:25,020
user has its own log file in this case

159
00:09:25,530 --> 00:09:28,600
the key value partner was added just

160
00:09:28,600 --> 00:09:31,780
recently to assist or Gangi and it can

161
00:09:31,780 --> 00:09:39,250
parse key equals something like data in

162
00:09:39,250 --> 00:09:43,030
the most popular example for this is

163
00:09:43,030 --> 00:09:48,010
fired warlocks for example iptables but

164
00:09:48,010 --> 00:09:52,950
this one is from zorp another fire war

165
00:09:53,070 --> 00:09:56,290
the most interesting parts are in

166
00:09:56,290 --> 00:09:59,320
systole Gangi is pattern DB which can

167
00:09:59,320 --> 00:10:02,470
extract information from unstructured

168
00:10:02,470 --> 00:10:04,680
messages into name value pairs

169
00:10:04,680 --> 00:10:08,110
it can also add status fields based on

170
00:10:08,110 --> 00:10:10,990
the message content and do some message

171
00:10:10,990 --> 00:10:14,980
classification like rock chapters the

172
00:10:14,980 --> 00:10:17,320
downside of this parser is that it needs

173
00:10:17,320 --> 00:10:22,600
an XML pride XML database describing the

174
00:10:22,600 --> 00:10:26,910
log messages so it can only parse

175
00:10:26,910 --> 00:10:29,380
messages which for which you have a

176
00:10:29,380 --> 00:10:32,140
description back to my favorite SSH

177
00:10:32,140 --> 00:10:36,730
example here are a few fields the first

178
00:10:36,730 --> 00:10:38,230
line has

179
00:10:38,230 --> 00:10:41,230
some data which is directly extracted

180
00:10:41,230 --> 00:10:43,390
from a direct message the application

181
00:10:43,390 --> 00:10:48,430
name username source IP but based on the

182
00:10:48,430 --> 00:10:53,710
message content you can also add that

183
00:10:53,710 --> 00:10:57,880
the action of the log was login and the

184
00:10:57,880 --> 00:11:00,460
status was a failure and based on this

185
00:11:00,460 --> 00:11:04,560
you can state that you can classify this

186
00:11:04,560 --> 00:11:12,310
log message as a violation sister

187
00:11:12,310 --> 00:11:14,920
getting the Cisco Gangi can n log

188
00:11:14,920 --> 00:11:19,360
messages and give and create additional

189
00:11:19,360 --> 00:11:21,730
name value pair parts based on the

190
00:11:21,730 --> 00:11:24,130
message content I already mentioned

191
00:11:24,130 --> 00:11:26,680
pattern baby on the previous slide you

192
00:11:26,680 --> 00:11:32,790
can also use a geoip parts are to add

193
00:11:32,790 --> 00:11:36,460
geolocation based on IP addresses for

194
00:11:36,460 --> 00:11:40,540
example a country name or longitude

195
00:11:40,540 --> 00:11:45,240
latitude information it can be used

196
00:11:45,240 --> 00:11:48,370
security as well to detect anomalies as

197
00:11:48,370 --> 00:11:51,970
it's not real world situation that

198
00:11:51,970 --> 00:11:56,380
someone wrote rocks in from Europe and

199
00:11:56,380 --> 00:12:01,930
from Australia at the same time and you

200
00:12:01,930 --> 00:12:05,080
can also use it to display locations on

201
00:12:05,080 --> 00:12:07,230
a map

202
00:12:08,520 --> 00:12:13,300
recently we added another part R which

203
00:12:13,300 --> 00:12:19,450
can add metadata from csv files to log

204
00:12:19,450 --> 00:12:22,240
messages for example at the ho stroll or

205
00:12:22,240 --> 00:12:26,200
contact person which can considerably

206
00:12:26,200 --> 00:12:31,930
speed up log analysis and also helps to

207
00:12:31,930 --> 00:12:34,440
create more accurate alerts or

208
00:12:34,440 --> 00:12:37,440
dashboards

209
00:12:39,080 --> 00:12:41,060
next I would like to talk a few words

210
00:12:41,060 --> 00:12:44,630
about configuring Sisto Gangji my first

211
00:12:44,630 --> 00:12:47,290
advice is don't panic

212
00:12:47,290 --> 00:12:53,959
as I often get feedback that sister

213
00:12:53,959 --> 00:12:58,430
Kenji configuration is worried difficult

214
00:12:58,430 --> 00:13:00,709
yes it looks difficult at first and

215
00:13:00,709 --> 00:13:04,209
sometimes even at second side but once

216
00:13:04,209 --> 00:13:07,279
you take a deeper look at it you will

217
00:13:07,279 --> 00:13:09,170
see that it's simple and logical it

218
00:13:09,170 --> 00:13:11,420
follows a pipeline model where you have

219
00:13:11,420 --> 00:13:13,070
many different building blocks like

220
00:13:13,070 --> 00:13:15,920
sources destinations filters and so on

221
00:13:15,920 --> 00:13:21,019
and all of these can be connected into a

222
00:13:21,019 --> 00:13:29,810
pipeline using log statements as citizen

223
00:13:29,810 --> 00:13:31,850
syslog-ng configuration always starts

224
00:13:31,850 --> 00:13:35,630
with a version number where it was for

225
00:13:35,630 --> 00:13:39,110
which version it was created and some

226
00:13:39,110 --> 00:13:43,310
global options which most of this can be

227
00:13:43,310 --> 00:13:45,860
overridden later in the configuration

228
00:13:45,860 --> 00:13:53,959
you can define sources and here are as

229
00:13:53,959 --> 00:14:00,290
you can see here this is a single source

230
00:14:00,290 --> 00:14:03,640
definition but it combines two different

231
00:14:03,640 --> 00:14:07,790
sources internal messages so those

232
00:14:07,790 --> 00:14:10,910
generated by systems itself and system

233
00:14:10,910 --> 00:14:14,420
is for platform specifics Rock sources

234
00:14:14,420 --> 00:14:16,399
this helps to hide away

235
00:14:16,399 --> 00:14:19,459
platform specific differences so you can

236
00:14:19,459 --> 00:14:23,089
use the same configuration on Linux

237
00:14:23,089 --> 00:14:29,360
FreeBSD Solaris and it will find rocks

238
00:14:29,360 --> 00:14:35,709
versus the other one is a network source

239
00:14:35,709 --> 00:14:41,440
in this case UDP here are a few

240
00:14:41,440 --> 00:14:44,240
destinations the typical world log

241
00:14:44,240 --> 00:14:47,060
messages it's a flat file the other one

242
00:14:47,060 --> 00:14:48,709
is more interesting it's an elastic

243
00:14:48,709 --> 00:14:52,760
search destination where you

244
00:14:52,760 --> 00:14:56,370
specify the index name the type of the

245
00:14:56,370 --> 00:14:59,760
message crossed our name and here you

246
00:14:59,760 --> 00:15:02,730
can see that it's using JSON formatting

247
00:15:02,730 --> 00:15:08,910
and selecting the different fields what

248
00:15:08,910 --> 00:15:19,290
to forward here you can see some filter

249
00:15:19,290 --> 00:15:21,630
definitions and loading a pattern in

250
00:15:21,630 --> 00:15:24,990
database for pattern DB parsing and here

251
00:15:24,990 --> 00:15:28,230
is the part of the configuration the log

252
00:15:28,230 --> 00:15:31,860
statements where the upper one is for

253
00:15:31,860 --> 00:15:38,970
VAR log messages local sources related

254
00:15:38,970 --> 00:15:41,520
filter and the destination the other one

255
00:15:41,520 --> 00:15:44,610
is more interesting with multiple

256
00:15:44,610 --> 00:15:48,690
sources filtering pattern DB and sending

257
00:15:48,690 --> 00:15:54,210
the results to rustic search and he was

258
00:15:54,210 --> 00:15:59,040
a nice dashboard from elastic search

259
00:15:59,040 --> 00:16:06,180
it's a word map where the log horse was

260
00:16:06,180 --> 00:16:11,160
IP tables and the attack attack sources

261
00:16:11,160 --> 00:16:15,120
I are visualized on screen here is the

262
00:16:15,120 --> 00:16:18,240
configuration how you can do this first

263
00:16:18,240 --> 00:16:21,620
of all you need a key value parser to

264
00:16:21,620 --> 00:16:28,320
extract the different fields from the

265
00:16:28,320 --> 00:16:31,620
message in this case the source IP for

266
00:16:31,620 --> 00:16:35,190
the society the geo location is looked

267
00:16:35,190 --> 00:16:37,890
at as gabbana

268
00:16:37,890 --> 00:16:40,530
needs a specific format for it it's

269
00:16:40,530 --> 00:16:44,880
written to that format and here in the

270
00:16:44,880 --> 00:16:48,210
Rock statement all of this building

271
00:16:48,210 --> 00:16:51,140
blocks ID combined

272
00:16:54,439 --> 00:16:59,249
peih-gee is a software in heavy

273
00:16:59,249 --> 00:17:01,739
development it was formerly known as

274
00:17:01,739 --> 00:17:08,640
elsa its web application for security

275
00:17:08,640 --> 00:17:13,919
analysts and it's built on syslog-ng and

276
00:17:13,919 --> 00:17:17,849
packed on BB message parsing the results

277
00:17:17,849 --> 00:17:21,619
are sent to elasticsearch and it has a

278
00:17:21,619 --> 00:17:25,260
it has its own web interface it's not

279
00:17:25,260 --> 00:17:32,779
Cabana in in this case there are some

280
00:17:32,990 --> 00:17:36,510
nice graphs from coming from domain

281
00:17:36,510 --> 00:17:40,380
intrusion detection system in a few

282
00:17:40,380 --> 00:17:43,860
words what are new in Cisco Gangi 3.8 it

283
00:17:43,860 --> 00:17:47,490
has displaced buffering a new parser

284
00:17:47,490 --> 00:17:50,520
which is easier to use you can also

285
00:17:50,520 --> 00:17:57,389
write parsers in rust it has support for

286
00:17:57,389 --> 00:17:58,799
all of the latest

287
00:17:58,799 --> 00:18:01,760
elasticsearch versions and many many

288
00:18:01,760 --> 00:18:09,510
performance if - improvements fine

289
00:18:09,510 --> 00:18:12,960
finally summary what this organ G can

290
00:18:12,960 --> 00:18:16,710
help in with security rocks first of all

291
00:18:16,710 --> 00:18:18,870
it's high performance and reliable local

292
00:18:18,870 --> 00:18:21,299
action you can part and and which log

293
00:18:21,299 --> 00:18:24,510
messages so you can do basic local

294
00:18:24,510 --> 00:18:28,639
arises inside Sisto Gangji and you can

295
00:18:28,639 --> 00:18:34,260
also efficiently forward block messages

296
00:18:34,260 --> 00:18:38,159
to other organize these tools if you

297
00:18:38,159 --> 00:18:40,860
want to know more about cisco Gangji our

298
00:18:40,860 --> 00:18:43,020
central hub of information is syslog-ng

299
00:18:43,020 --> 00:18:47,850
dot org or our source code is on github

300
00:18:47,850 --> 00:18:50,159
where we also have an issue tracking

301
00:18:50,159 --> 00:18:55,860
system and we if you need help we have a

302
00:18:55,860 --> 00:18:59,549
mailing list or for near real-time have

303
00:18:59,549 --> 00:19:03,220
we have IRC or guitar channels

304
00:19:03,220 --> 00:19:10,780
you have any questions thank you Peter

305
00:19:10,780 --> 00:19:19,460
we have an apple we have five minutes

306
00:19:19,460 --> 00:19:21,050
for questions to raise your hand if you

307
00:19:21,050 --> 00:19:22,460
want to ask a question we have the first

308
00:19:22,460 --> 00:19:26,630
one here hi what about support for

309
00:19:26,630 --> 00:19:28,760
docker containers or other containers so

310
00:19:28,760 --> 00:19:31,000
instead of having log stash or fluently

311
00:19:31,000 --> 00:19:33,200
getting the container logs put into this

312
00:19:33,200 --> 00:19:35,270
and then enriching the log format with

313
00:19:35,270 --> 00:19:37,580
container relevant information because

314
00:19:37,580 --> 00:19:43,790
that supported yet yes we have a docker

315
00:19:43,790 --> 00:19:47,150
image and I just checked it and was

316
00:19:47,150 --> 00:19:50,780
quite surprised as the development

317
00:19:50,780 --> 00:19:53,390
version of the docker image had just a

318
00:19:53,390 --> 00:19:58,340
few hundred tunnels but the regular

319
00:19:58,340 --> 00:20:00,760
image had over a hundred thousand

320
00:20:00,760 --> 00:20:04,730
downloads I so people are using it in

321
00:20:04,730 --> 00:20:09,800
the car sorry I wasn't referring about

322
00:20:09,800 --> 00:20:11,870
running syslog-ng inside a container but

323
00:20:11,870 --> 00:20:13,940
rather on a host or VMware you have

324
00:20:13,940 --> 00:20:16,160
Sasaki ng and it has the darker daemon

325
00:20:16,160 --> 00:20:18,290
or it has rocket or whatever and you're

326
00:20:18,290 --> 00:20:19,730
running say ten containers and you'd

327
00:20:19,730 --> 00:20:21,980
like the logs from those containers to

328
00:20:21,980 --> 00:20:24,679
go back to the host base syslog-ng to

329
00:20:24,679 --> 00:20:26,780
enrich to then send them on to some

330
00:20:26,780 --> 00:20:30,800
other location so in order to do that it

331
00:20:30,800 --> 00:20:32,840
would be useful to get some information

332
00:20:32,840 --> 00:20:34,670
from say doc or demon to understanding

333
00:20:34,670 --> 00:20:36,020
the name of the container and some other

334
00:20:36,020 --> 00:20:39,830
attributes as far as I don't use docker

335
00:20:39,830 --> 00:20:42,740
myself but as far as I know the doctor

336
00:20:42,740 --> 00:20:44,750
is logging in JSON format and that can

337
00:20:44,750 --> 00:20:53,000
we can process that I I know that it's

338
00:20:53,000 --> 00:20:54,679
used but personally I don't have much

339
00:20:54,679 --> 00:20:58,490
experience with it okay there's one more

340
00:20:58,490 --> 00:21:00,380
question here raise your hand if you was

341
00:21:00,380 --> 00:21:03,610
want to ask a question

342
00:21:04,670 --> 00:21:08,090
hello say my question it gets born -

343
00:21:08,090 --> 00:21:09,620
like us visible eagle aspects which I

344
00:21:09,620 --> 00:21:12,020
saw mentioned up sort of to talk in your

345
00:21:12,020 --> 00:21:15,830
like your brief I suppose like are there

346
00:21:15,830 --> 00:21:16,670
ways

347
00:21:16,670 --> 00:21:18,530
which syslog-ng can support like

348
00:21:18,530 --> 00:21:20,060
compliance to like EU data protection

349
00:21:20,060 --> 00:21:23,240
law for not storing like I P addresses

350
00:21:23,240 --> 00:21:25,880
or storing in particular ways which

351
00:21:25,880 --> 00:21:29,330
better support like some like I suppose

352
00:21:29,330 --> 00:21:31,040
minimal standards in what should be

353
00:21:31,040 --> 00:21:37,820
captured and not captured what we can do

354
00:21:37,820 --> 00:21:41,410
is using pattern BB or using Tegrity

355
00:21:41,410 --> 00:21:44,510
expressions you can find IP addresses or

356
00:21:44,510 --> 00:21:48,410
credit card numbers in log messages both

357
00:21:48,410 --> 00:21:52,180
have advantages and disadvantages and

358
00:21:52,180 --> 00:21:55,430
you can either replace with a static

359
00:21:55,430 --> 00:21:59,960
text the IP address or you can use

360
00:21:59,960 --> 00:22:02,660
hashes and if you use a hash of the

361
00:22:02,660 --> 00:22:06,650
original then you can use it in further

362
00:22:06,650 --> 00:22:08,860
analysis of the message so you can

363
00:22:08,860 --> 00:22:11,810
follow sessions what they give they use

364
00:22:11,810 --> 00:22:13,910
a bit even if you don't know the name of

365
00:22:13,910 --> 00:22:16,790
the user but you can follow what is it

366
00:22:16,790 --> 00:22:22,670
coming from what it did and we have one

367
00:22:22,670 --> 00:22:24,410
more here it's also fine to just have a

368
00:22:24,410 --> 00:22:27,320
comment or reflection or criticism or

369
00:22:27,320 --> 00:22:31,940
discussion in the sample so most of the

370
00:22:31,940 --> 00:22:34,010
new assistants are running Journal d

371
00:22:34,010 --> 00:22:37,880
what is your recommendation where is the

372
00:22:37,880 --> 00:22:40,190
work split between germinal journal D

373
00:22:40,190 --> 00:22:48,920
and syslog-ng generally is for blocking

374
00:22:48,920 --> 00:22:52,520
log messages of course you can pull log

375
00:22:52,520 --> 00:22:55,130
messages from it periodically but it's

376
00:22:55,130 --> 00:22:57,080
still not something for central

377
00:22:57,080 --> 00:22:59,030
collection with syslog-ng

378
00:22:59,030 --> 00:23:01,610
you can constantly see seconds you can

379
00:23:01,610 --> 00:23:04,990
read log messages from the journa and

380
00:23:04,990 --> 00:23:07,760
forward it to a central location in real

381
00:23:07,760 --> 00:23:10,400
time so it's better so it is with it for

382
00:23:10,400 --> 00:23:16,600
security purposes I think thank you

383
00:23:16,600 --> 00:23:30,910
final question ok let's thank Peter and

384
00:23:30,910 --> 00:23:33,560
thanks for coming here this was the

385
00:23:33,560 --> 00:23:37,419
final presentation for today

386
00:23:42,630 --> 00:23:45,679
[Music]

