1
00:00:00,000 --> 00:00:02,420
cool

2
00:00:05,840 --> 00:00:07,970
so thank you for staying because you're

3
00:00:07,970 --> 00:00:09,559
all stuck here anyways

4
00:00:09,559 --> 00:00:11,990
this is extending spark ml super happy

5
00:00:11,990 --> 00:00:16,180
new pipeline stage time yay

6
00:00:16,279 --> 00:00:18,500
I'm holdin my preferred pronouns are she

7
00:00:18,500 --> 00:00:20,570
or her it's tattooed on my wrist in case

8
00:00:20,570 --> 00:00:23,270
you forget don't it up and I'm a

9
00:00:23,270 --> 00:00:25,550
principal software engineer at IBM spark

10
00:00:25,550 --> 00:00:27,619
Technology Center if anyone's looking to

11
00:00:27,619 --> 00:00:29,239
relocate to America for some reason

12
00:00:29,239 --> 00:00:33,470
still come and talk to me and I've been

13
00:00:33,470 --> 00:00:34,640
doing this had a bunch of other

14
00:00:34,640 --> 00:00:37,039
companies for a while you can follow me

15
00:00:37,039 --> 00:00:39,949
on Twitter and it's mostly just tweets

16
00:00:39,949 --> 00:00:41,800
being really sad about America right now

17
00:00:41,800 --> 00:00:44,600
so if you're too happy following me on

18
00:00:44,600 --> 00:00:46,309
Twitter and I'll fix that for you and

19
00:00:46,309 --> 00:00:49,100
then we'll talk about software will be

20
00:00:49,100 --> 00:00:52,039
worthwhile we're gonna talk about what

21
00:00:52,039 --> 00:00:54,079
spark ml pipelines look like and then

22
00:00:54,079 --> 00:00:55,370
we're gonna jump into extending them

23
00:00:55,370 --> 00:00:58,609
really quickly and the topic said it was

24
00:00:58,609 --> 00:01:00,800
going beyond word count but we've got

25
00:01:00,800 --> 00:01:03,019
ten minutes so it's sort of beyond what

26
00:01:03,019 --> 00:01:07,340
counted so yeah spark ml pipelines are

27
00:01:07,340 --> 00:01:09,920
pretty much the spark developers looking

28
00:01:09,920 --> 00:01:11,660
at scikit-learn and going you shiny

29
00:01:11,660 --> 00:01:16,010
steel unfortunately their big data

30
00:01:16,010 --> 00:01:17,480
developers and so they got kind of

31
00:01:17,480 --> 00:01:19,400
halfway through stealing I didn't bother

32
00:01:19,400 --> 00:01:21,590
stealing all of the algorithms but they

33
00:01:21,590 --> 00:01:23,450
they stole the api's so if you're

34
00:01:23,450 --> 00:01:26,330
familiar with scikit-learn spark ml

35
00:01:26,330 --> 00:01:27,680
pipelines are gonna be really familiar

36
00:01:27,680 --> 00:01:30,590
to you and they're exposed in Scala and

37
00:01:30,590 --> 00:01:32,240
Python and you can use it to do

38
00:01:32,240 --> 00:01:34,880
distributed machine learning but the

39
00:01:34,880 --> 00:01:37,190
algorithm selection isn't like 100

40
00:01:37,190 --> 00:01:39,080
percent right you might have some really

41
00:01:39,080 --> 00:01:40,490
crazy problem that you're trying to

42
00:01:40,490 --> 00:01:42,290
solve and you need an algorithm that

43
00:01:42,290 --> 00:01:44,360
isn't already in spark and the good news

44
00:01:44,360 --> 00:01:46,850
is you can implement it yourself

45
00:01:46,850 --> 00:01:49,520
and the stages in these pipelines are

46
00:01:49,520 --> 00:01:52,000
either estimators or transformers

47
00:01:52,000 --> 00:01:54,470
transformers are the little blue boxes

48
00:01:54,470 --> 00:01:55,640
and those are just things which don't

49
00:01:55,640 --> 00:01:57,740
need to be trained on data and so

50
00:01:57,740 --> 00:01:59,030
they're really simple to implement we

51
00:01:59,030 --> 00:02:00,800
can just write in a normal spark job and

52
00:02:00,800 --> 00:02:02,750
add a little bit of sugar and make a

53
00:02:02,750 --> 00:02:04,700
transformer but if you want to build

54
00:02:04,700 --> 00:02:06,440
something fancy you like a machine

55
00:02:06,440 --> 00:02:07,820
learning algorithm or something which

56
00:02:07,820 --> 00:02:09,919
needs to be trained on data you have to

57
00:02:09,919 --> 00:02:12,170
build an estimator and we'll look at how

58
00:02:12,170 --> 00:02:15,339
to do that really quickly

59
00:02:15,910 --> 00:02:17,840
yeah these tourists

60
00:02:17,840 --> 00:02:19,970
whatever just cover up this part of the

61
00:02:19,970 --> 00:02:23,060
slides no one sees this part but we have

62
00:02:23,060 --> 00:02:26,090
to provide a transform schema and a copy

63
00:02:26,090 --> 00:02:27,980
function and these are the two sort of

64
00:02:27,980 --> 00:02:29,870
like non-standard spark bits that we

65
00:02:29,870 --> 00:02:32,690
have to add if we want to turn our spark

66
00:02:32,690 --> 00:02:35,750
job into an ml pipeline component and

67
00:02:35,750 --> 00:02:37,280
then we had can add some configuration

68
00:02:37,280 --> 00:02:39,410
as well and then if you add the

69
00:02:39,410 --> 00:02:42,019
configuration with the spark way you can

70
00:02:42,019 --> 00:02:44,420
do like parameter grid searches and and

71
00:02:44,420 --> 00:02:46,040
automatically tune your models and

72
00:02:46,040 --> 00:02:48,019
because I'm really bad at statistics I

73
00:02:48,019 --> 00:02:49,730
frequently use parameter grid search

74
00:02:49,730 --> 00:02:51,890
because I don't know how to pick my

75
00:02:51,890 --> 00:02:55,160
own regularization parameter you do that

76
00:02:55,160 --> 00:02:58,519
for me so here is our hard-coded word

77
00:02:58,519 --> 00:03:00,799
count stage as a licensed Big Data

78
00:03:00,799 --> 00:03:02,390
instructor I have to put word count

79
00:03:02,390 --> 00:03:04,879
everywhere you may wonder why it's in

80
00:03:04,879 --> 00:03:07,819
every single talk ever and this is why

81
00:03:07,819 --> 00:03:10,640
but we've got a copy function and our

82
00:03:10,640 --> 00:03:12,950
constructor it's not super important you

83
00:03:12,950 --> 00:03:14,480
can pretty much just steal this and

84
00:03:14,480 --> 00:03:16,370
change the name from hard-coded word

85
00:03:16,370 --> 00:03:19,790
count to hard-coded magic algorithm and

86
00:03:19,790 --> 00:03:22,310
for copy you've just called default copy

87
00:03:22,310 --> 00:03:23,989
unless you need to do something really

88
00:03:23,989 --> 00:03:27,709
weird in my sample set of two calling

89
00:03:27,709 --> 00:03:30,680
default copy works 100% of the time if

90
00:03:30,680 --> 00:03:33,200
it doesn't work for you please don't

91
00:03:33,200 --> 00:03:35,840
tell me I'll have to change the talk and

92
00:03:35,840 --> 00:03:40,099
that that would just be sad and so now

93
00:03:40,099 --> 00:03:41,870
this is the part which is different than

94
00:03:41,870 --> 00:03:45,049
our normal spark code because these

95
00:03:45,049 --> 00:03:46,400
machine learning pipelines can take a

96
00:03:46,400 --> 00:03:48,919
really long time to run and because data

97
00:03:48,919 --> 00:03:51,280
frames aren't compile time type checked

98
00:03:51,280 --> 00:03:53,720
we want to do at least some type

99
00:03:53,720 --> 00:03:56,959
checking before we start our like 8 hour

100
00:03:56,959 --> 00:03:57,980
or 24 hour

101
00:03:57,980 --> 00:04:00,139
machine learning job and then come back

102
00:04:00,139 --> 00:04:02,750
halfway through and be like oh it failed

103
00:04:02,750 --> 00:04:05,030
because like I got the name wrong of

104
00:04:05,030 --> 00:04:07,340
this one random thing and so transform

105
00:04:07,340 --> 00:04:09,620
schema is a thing which gives us the

106
00:04:09,620 --> 00:04:11,450
ability to verify that our inputs are

107
00:04:11,450 --> 00:04:13,519
sort of what we're expecting and tell

108
00:04:13,519 --> 00:04:15,620
the downstream people what our outputs

109
00:04:15,620 --> 00:04:17,478
are going to be like I mean if this code

110
00:04:17,478 --> 00:04:19,970
looks kind of weird to you it's ok it's

111
00:04:19,970 --> 00:04:21,769
just the data frame code and it's really

112
00:04:21,769 --> 00:04:23,330
simple there's a lot of introductions to

113
00:04:23,330 --> 00:04:25,789
it and that's where like these types

114
00:04:25,789 --> 00:04:28,250
come from this string type is not the

115
00:04:28,250 --> 00:04:30,229
Scala string type it's the spark string

116
00:04:30,229 --> 00:04:31,550
type which is mildly differ

117
00:04:31,550 --> 00:04:35,810
in ways that are exciting and not for a

118
00:04:35,810 --> 00:04:37,610
10-minute talk and then we can just add

119
00:04:37,610 --> 00:04:42,110
our result here and then we can do our

120
00:04:42,110 --> 00:04:44,930
work and so this is really simple right

121
00:04:44,930 --> 00:04:46,159
we're just counting the words that are

122
00:04:46,159 --> 00:04:47,479
being put in I'm not even doing the

123
00:04:47,479 --> 00:04:49,879
proper word count but it's really simple

124
00:04:49,879 --> 00:04:53,060
and you could do something actually

125
00:04:53,060 --> 00:04:56,030
complex I find that doing this with the

126
00:04:56,030 --> 00:04:58,699
UDF even though spark has a really nice

127
00:04:58,699 --> 00:05:00,979
way to do integrated functional

128
00:05:00,979 --> 00:05:04,610
programming and relational stuff it

129
00:05:04,610 --> 00:05:06,800
doesn't work really well with this part

130
00:05:06,800 --> 00:05:08,780
because generally what we want to do is

131
00:05:08,780 --> 00:05:11,150
we want to just add things to the data

132
00:05:11,150 --> 00:05:12,440
that's coming and we don't want to like

133
00:05:12,440 --> 00:05:14,599
get rid of anything and we don't

134
00:05:14,599 --> 00:05:16,130
necessarily know all of the types that

135
00:05:16,130 --> 00:05:17,960
are coming in so it's hard to use the

136
00:05:17,960 --> 00:05:20,120
full data set API so you end up having

137
00:05:20,120 --> 00:05:23,449
to use this kind of ugly UDF syntax but

138
00:05:23,449 --> 00:05:24,770
it's not the end of the world right

139
00:05:24,770 --> 00:05:27,110
usually this is much nicer than writing

140
00:05:27,110 --> 00:05:28,400
a high view D Athens

141
00:05:28,400 --> 00:05:31,460
I promise you've never written a high

142
00:05:31,460 --> 00:05:34,699
view TF you're lucky and and this is

143
00:05:34,699 --> 00:05:36,680
where your fun can be and if you're a

144
00:05:36,680 --> 00:05:39,020
researcher you can spend like months

145
00:05:39,020 --> 00:05:40,669
working on the code that's gonna live

146
00:05:40,669 --> 00:05:42,289
inside of transform if you're in

147
00:05:42,289 --> 00:05:43,990
industry you can spend like a day or two

148
00:05:43,990 --> 00:05:46,310
or if your boss is wondering what you're

149
00:05:46,310 --> 00:05:48,110
doing just like have them email me I'll

150
00:05:48,110 --> 00:05:50,889
be like no it's super important trust me

151
00:05:50,889 --> 00:05:53,440
and you can go and do some crazy stuff

152
00:05:53,440 --> 00:05:55,759
and then we need to configure our

153
00:05:55,759 --> 00:05:58,819
pipeline stage for pipeline stages in

154
00:05:58,819 --> 00:06:01,940
SPARC we use this parameter interface

155
00:06:01,940 --> 00:06:04,340
and this just gives spark a standard way

156
00:06:04,340 --> 00:06:07,610
of being able to configure and do sort

157
00:06:07,610 --> 00:06:10,430
of parameter good searching you probably

158
00:06:10,430 --> 00:06:11,990
wouldn't do a parameter grid search on

159
00:06:11,990 --> 00:06:13,819
your output column let's be a little

160
00:06:13,819 --> 00:06:15,889
weird but you might do it on your input

161
00:06:15,889 --> 00:06:18,560
cone and you're not limited to strings

162
00:06:18,560 --> 00:06:20,180
here right so these these are string

163
00:06:20,180 --> 00:06:22,130
parameters but these could definitely be

164
00:06:22,130 --> 00:06:25,819
doubles you know floats bins whatever so

165
00:06:25,819 --> 00:06:27,229
you could do a parameter search on your

166
00:06:27,229 --> 00:06:29,509
on your tuna Graham and then you provide

167
00:06:29,509 --> 00:06:31,039
some setters and those are for like

168
00:06:31,039 --> 00:06:36,259
humans use and it's really simple and

169
00:06:36,259 --> 00:06:38,960
yeah so we do it this way so that sparks

170
00:06:38,960 --> 00:06:41,870
meta algorithms can work on it if you

171
00:06:41,870 --> 00:06:43,699
don't know what parameters you should be

172
00:06:43,699 --> 00:06:46,310
adding to your machine learning

173
00:06:46,310 --> 00:06:48,580
you can go look at shared pram Scala

174
00:06:48,580 --> 00:06:50,930
inside of Sparks codebase and just like

175
00:06:50,930 --> 00:06:52,910
steal the ones that you want you'll have

176
00:06:52,910 --> 00:06:55,430
to cut and paste the code or lie about

177
00:06:55,430 --> 00:06:57,440
being inside of package org Apache spark

178
00:06:57,440 --> 00:06:59,780
because it's all private if you lie

179
00:06:59,780 --> 00:07:01,580
about being inside a package org Apache

180
00:07:01,580 --> 00:07:04,160
spark I don't know who you are it's not

181
00:07:04,160 --> 00:07:07,040
my fault but I do it pretty often myself

182
00:07:07,040 --> 00:07:09,560
and so you know no harm no foul but your

183
00:07:09,560 --> 00:07:11,530
cause is probably gonna break me upward

184
00:07:11,530 --> 00:07:14,120
what's the future use problem though and

185
00:07:14,120 --> 00:07:14,900
if I've learned anything about

186
00:07:14,900 --> 00:07:16,669
scientists it's that they don't seem to

187
00:07:16,669 --> 00:07:18,290
think about future you when it comes to

188
00:07:18,290 --> 00:07:20,780
their software no offense

189
00:07:20,780 --> 00:07:24,380
so that's really boring we made word

190
00:07:24,380 --> 00:07:26,210
count and I promised we were gonna go

191
00:07:26,210 --> 00:07:28,820
beyond word count um so let's go beyond

192
00:07:28,820 --> 00:07:29,330
word count

193
00:07:29,330 --> 00:07:31,580
we're gonna make an estimator this is

194
00:07:31,580 --> 00:07:34,460
the fancy thing no one's excited but

195
00:07:34,460 --> 00:07:37,220
it's okay it's fancy it's gonna like

196
00:07:37,220 --> 00:07:40,910
actually train on some input data we do

197
00:07:40,910 --> 00:07:43,280
pretty much the same thing so what our

198
00:07:43,280 --> 00:07:46,040
estimator does is we write a fit

199
00:07:46,040 --> 00:07:48,320
function we have the same parameters to

200
00:07:48,320 --> 00:07:51,590
configure it and then our fit function

201
00:07:51,590 --> 00:07:53,539
is going to return our transformer and

202
00:07:53,539 --> 00:07:58,610
so our it's really simple yeah I owe

203
00:07:58,610 --> 00:08:01,100
this says November oh yeah that actually

204
00:08:01,100 --> 00:08:05,120
is old but let's let's look at a really

205
00:08:05,120 --> 00:08:08,900
simple estimate ah you know oh this is

206
00:08:08,900 --> 00:08:11,419
an old version of the slides dammit okay

207
00:08:11,419 --> 00:08:13,789
well so I don't have the code for the

208
00:08:13,789 --> 00:08:16,310
estimator but it's a fit function which

209
00:08:16,310 --> 00:08:20,620
is just gonna return our transformer yay

210
00:08:20,620 --> 00:08:23,180
so pretend that there's a fit function

211
00:08:23,180 --> 00:08:25,100
and it's gonna construct new hard-coded

212
00:08:25,100 --> 00:08:27,200
word count stage or whatever it is you

213
00:08:27,200 --> 00:08:29,660
want and if you want to see the code for

214
00:08:29,660 --> 00:08:32,839
that it's totally in this really nice

215
00:08:32,839 --> 00:08:36,679
blog post which is a lot longer than 10

216
00:08:36,679 --> 00:08:39,049
minutes unfortunately but hopefully

217
00:08:39,049 --> 00:08:42,260
maybe I trick someone into thinking that

218
00:08:42,260 --> 00:08:44,510
making their own spark machine learning

219
00:08:44,510 --> 00:08:46,370
algorithm is a good use of their time

220
00:08:46,370 --> 00:08:48,290
and you'll publish it to maven central

221
00:08:48,290 --> 00:08:50,990
and then I can use it or tell people to

222
00:08:50,990 --> 00:08:53,029
use it and we can all hang out and have

223
00:08:53,029 --> 00:08:56,390
fun if I didn't trick anyone into doing

224
00:08:56,390 --> 00:09:00,069
that that's okay too

225
00:09:00,560 --> 00:09:03,020
there's also this github repo with a

226
00:09:03,020 --> 00:09:05,960
bunch of examples they're written mostly

227
00:09:05,960 --> 00:09:09,740
by me so they're a little yeah but if

228
00:09:09,740 --> 00:09:11,000
you want to go ahead and look at the

229
00:09:11,000 --> 00:09:12,680
ones that are inside a spark itself you

230
00:09:12,680 --> 00:09:15,140
can find them here and those ones are a

231
00:09:15,140 --> 00:09:19,250
little more I want to say professional

232
00:09:19,250 --> 00:09:20,570
or production-ready

233
00:09:20,570 --> 00:09:23,450
they're not like all great but they put

234
00:09:23,450 --> 00:09:24,860
a lot more thought into them and I put

235
00:09:24,860 --> 00:09:27,350
into mine so you can definitely check

236
00:09:27,350 --> 00:09:29,300
those out and they're gonna use internal

237
00:09:29,300 --> 00:09:31,370
api's but it's okay you can just like

238
00:09:31,370 --> 00:09:33,230
lie and say you're inside a package org

239
00:09:33,230 --> 00:09:36,709
apache spark and there's api

240
00:09:36,709 --> 00:09:41,690
documentation and fun stuff as an author

241
00:09:41,690 --> 00:09:43,490
of some books i would be remiss if i

242
00:09:43,490 --> 00:09:44,839
didn't try and get you to give me your

243
00:09:44,839 --> 00:09:50,300
money and so and these aren't all my

244
00:09:50,300 --> 00:09:52,160
books to be clear i don't have that much

245
00:09:52,160 --> 00:09:55,459
time in my life don't buy this one

246
00:09:55,459 --> 00:09:58,070
that's kind of out of date authors won't

247
00:09:58,070 --> 00:10:00,200
normally tell you that but you should

248
00:10:00,200 --> 00:10:02,779
buy all of these other books even the

249
00:10:02,779 --> 00:10:05,120
ones I didn't write but if you have an

250
00:10:05,120 --> 00:10:07,010
expense account does anyone have an

251
00:10:07,010 --> 00:10:11,240
expense account no okay well and then

252
00:10:11,240 --> 00:10:13,640
don't buy several copies of this but if

253
00:10:13,640 --> 00:10:15,620
you know someone with an expense account

254
00:10:15,620 --> 00:10:16,820
maybe someone that works at Bloomberg

255
00:10:16,820 --> 00:10:19,100
you can get them to buy several copies

256
00:10:19,100 --> 00:10:21,560
of high-performance spark it is the

257
00:10:21,560 --> 00:10:23,810
holiday gift of the season for whatever

258
00:10:23,810 --> 00:10:27,470
holiday is coming up next if for some

259
00:10:27,470 --> 00:10:28,910
reason you don't want to buy a book

260
00:10:28,910 --> 00:10:31,970
which doesn't exist yet that's that's

261
00:10:31,970 --> 00:10:34,310
okay I understand you can give me your

262
00:10:34,310 --> 00:10:36,110
email address at high performance bar

263
00:10:36,110 --> 00:10:38,120
comm and they'll spend the hell out of

264
00:10:38,120 --> 00:10:41,870
you as soon as the book is finished but

265
00:10:41,870 --> 00:10:43,550
please give me your money today rather

266
00:10:43,550 --> 00:10:45,320
than tomorrow because money today is

267
00:10:45,320 --> 00:10:48,750
coffee so thank you

268
00:10:48,750 --> 00:10:56,290
[Applause]

269
00:10:56,290 --> 00:11:04,220
okay Oh doggies name is boo she comes

270
00:11:04,220 --> 00:11:05,839
with me to all of my talks where I

271
00:11:05,839 --> 00:11:08,949
remember to bring her

