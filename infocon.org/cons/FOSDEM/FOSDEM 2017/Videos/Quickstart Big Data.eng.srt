1
00:00:00,290 --> 00:00:03,410
thank you

2
00:00:05,130 --> 00:00:07,439
for letting me into this room it's very

3
00:00:07,439 --> 00:00:11,370
crowded outside it's a great honor to be

4
00:00:11,370 --> 00:00:15,960
sent inside so I will talk about a

5
00:00:15,960 --> 00:00:20,130
consulting job I did first about some

6
00:00:20,130 --> 00:00:22,350
words about me I'm indeed my PhD and

7
00:00:22,350 --> 00:00:25,130
computational physics a long time ago

8
00:00:25,130 --> 00:00:28,560
was involved in projects like MINIX for

9
00:00:28,560 --> 00:00:33,150
68k the mathematics library for linux i

10
00:00:33,150 --> 00:00:37,100
did the high-precision mass Paul Patton

11
00:00:37,100 --> 00:00:41,160
reporting to the prior 5 flight years if

12
00:00:41,160 --> 00:00:43,260
flight simulator had some computer

13
00:00:43,260 --> 00:00:45,870
contributions and I'm a maintainer for

14
00:00:45,870 --> 00:00:48,899
the MS KT util it's accepted actually

15
00:00:48,899 --> 00:00:53,460
cobbles integration - right now for the

16
00:00:53,460 --> 00:00:55,949
moment I am the pn pn c of the apache

17
00:00:55,949 --> 00:00:59,129
victor project more about that later in

18
00:00:59,129 --> 00:01:01,770
my real life the otherworld life I'm a

19
00:01:01,770 --> 00:01:04,220
software he take for connected ebikes

20
00:01:04,220 --> 00:01:09,330
and the thing I was I'm talking about

21
00:01:09,330 --> 00:01:14,070
this how to solve how to attack a

22
00:01:14,070 --> 00:01:17,729
problem when you do some have to do some

23
00:01:17,729 --> 00:01:19,530
consulting jobs and with a big tailor

24
00:01:19,530 --> 00:01:23,220
label on it and the problem I had to

25
00:01:23,220 --> 00:01:26,130
solve was from cam and fro metrics you

26
00:01:26,130 --> 00:01:31,140
have for the the development of medical

27
00:01:31,140 --> 00:01:35,070
drugs so the problem at hand is you have

28
00:01:35,070 --> 00:01:39,689
a database a large database of molecules

29
00:01:39,689 --> 00:01:43,619
which can be may produced quite cheaply

30
00:01:43,619 --> 00:01:47,070
for instance and you have this many

31
00:01:47,070 --> 00:01:51,540
medical database database of things is

32
00:01:51,540 --> 00:01:53,220
written down for instance in the

33
00:01:53,220 --> 00:01:56,810
smallest notation that's a complicated

34
00:01:56,810 --> 00:02:01,439
notation - that's the the chemical

35
00:02:01,439 --> 00:02:03,570
structure of this thing here I didn't

36
00:02:03,570 --> 00:02:05,490
remember the name of it just I just

37
00:02:05,490 --> 00:02:08,070
picked randomly one order out of it and

38
00:02:08,070 --> 00:02:12,329
the problem is to look for substructures

39
00:02:12,329 --> 00:02:16,020
into these molecules which have some

40
00:02:16,020 --> 00:02:17,600
healthy

41
00:02:17,600 --> 00:02:20,250
can make you healthy or something like

42
00:02:20,250 --> 00:02:23,630
that so there that's not a new problem

43
00:02:23,630 --> 00:02:26,370
there's a commercial solution for it you

44
00:02:26,370 --> 00:02:30,450
had me Hugh throw enterprise database in

45
00:02:30,450 --> 00:02:32,010
it and you have something like a

46
00:02:32,010 --> 00:02:34,440
cartridge in it and you can make a

47
00:02:34,440 --> 00:02:38,300
sequel query and you get results the

48
00:02:38,300 --> 00:02:44,000
problem is that is the duration is very

49
00:02:44,000 --> 00:02:47,700
long for instance it needs about a day

50
00:02:47,700 --> 00:02:50,220
or something it's not very reliable and

51
00:02:50,220 --> 00:02:54,900
it's very expensive so the customer

52
00:02:54,900 --> 00:02:57,780
looked out for a big data approach to

53
00:02:57,780 --> 00:03:00,210
this problem and fortunately there is an

54
00:03:00,210 --> 00:03:03,660
open source project card called Rd kit

55
00:03:03,660 --> 00:03:07,050
it's a beautiful library for chem

56
00:03:07,050 --> 00:03:09,090
informatics and you can do something

57
00:03:09,090 --> 00:03:11,760
like that you read in a molecule from

58
00:03:11,760 --> 00:03:14,790
smiles and you put in this mass

59
00:03:14,790 --> 00:03:16,020
notification and you know if your

60
00:03:16,020 --> 00:03:18,420
molecule object the person object and

61
00:03:18,420 --> 00:03:21,030
can say it simply say it has a

62
00:03:21,030 --> 00:03:22,890
substructure match from the other small

63
00:03:22,890 --> 00:03:25,200
notation so it gives you true or false

64
00:03:25,200 --> 00:03:32,010
that's fine and ok so this always the

65
00:03:32,010 --> 00:03:35,820
same thing we have the ingredients a

66
00:03:35,820 --> 00:03:37,590
time-consuming job

67
00:03:37,590 --> 00:03:40,200
we have a large data set and make it

68
00:03:40,200 --> 00:03:42,900
fast so and we have an eye on the

69
00:03:42,900 --> 00:03:46,680
environment we wanted to use is a big

70
00:03:46,680 --> 00:03:49,770
data cluster or an HPC cluster we have

71
00:03:49,770 --> 00:03:55,290
both so what we can be doing so now

72
00:03:55,290 --> 00:03:59,160
about talking how not to scale out you

73
00:03:59,160 --> 00:04:00,870
can simply benchmark it and you see that

74
00:04:00,870 --> 00:04:03,120
the reading in the small notation and

75
00:04:03,120 --> 00:04:05,220
constructing the molecule object is the

76
00:04:05,220 --> 00:04:08,870
most time-consuming thing in this whole

77
00:04:08,870 --> 00:04:14,370
problem and ok we can simply read it in

78
00:04:14,370 --> 00:04:20,310
one time and dumping the civilizing the

79
00:04:20,310 --> 00:04:22,710
molecules is called pickling in C

80
00:04:22,710 --> 00:04:25,800
important to him dumpling to a to file

81
00:04:25,800 --> 00:04:28,470
as though you do not have to reconstruct

82
00:04:28,470 --> 00:04:29,620
all the molecules

83
00:04:29,620 --> 00:04:33,100
anytime so that's a huge gain in run

84
00:04:33,100 --> 00:04:36,699
time but it does not scale anything it's

85
00:04:36,699 --> 00:04:40,750
we have we are looking out for scale so

86
00:04:40,750 --> 00:04:44,020
- in order to make the program faster so

87
00:04:44,020 --> 00:04:49,449
more machines in it so we simply looking

88
00:04:49,449 --> 00:04:53,139
at the problem it's simply an HP AEP

89
00:04:53,139 --> 00:04:56,110
problem it's embarrassingly parallel so

90
00:04:56,110 --> 00:04:59,169
we can simply divide the database into

91
00:04:59,169 --> 00:05:02,080
small chunks and so each chunks at

92
00:05:02,080 --> 00:05:06,370
different machines quite easy and the

93
00:05:06,370 --> 00:05:08,860
big data approach is to distribute the

94
00:05:08,860 --> 00:05:11,350
algorithm to the machines and not the

95
00:05:11,350 --> 00:05:15,760
data coming to one machine so yes and

96
00:05:15,760 --> 00:05:18,210
the beautiful a framework for SSS Park

97
00:05:18,210 --> 00:05:21,669
it's the sparkle no special ingredients

98
00:05:21,669 --> 00:05:25,240
needed and we you see the RDD power

99
00:05:25,240 --> 00:05:27,060
dignity this resident artists

100
00:05:27,060 --> 00:05:31,060
distribution ya think it's called that

101
00:05:31,060 --> 00:05:36,479
is that the files are hacked into

102
00:05:36,479 --> 00:05:39,520
different components so we can

103
00:05:39,520 --> 00:05:41,849
distribute it to all the machines and

104
00:05:41,849 --> 00:05:44,470
SPARC is beautiful because it runs or

105
00:05:44,470 --> 00:05:47,830
each on HPC and picked our environments

106
00:05:47,830 --> 00:05:50,590
it does not need it stuff is not tied to

107
00:05:50,590 --> 00:05:56,169
the HDFS for instance so all I did is

108
00:05:56,169 --> 00:05:58,979
read the instructions at spark I never

109
00:05:58,979 --> 00:06:03,820
haven't used spark before and it's quite

110
00:06:03,820 --> 00:06:10,870
easy we read in and a text file okay in

111
00:06:10,870 --> 00:06:12,870
fact I'm reading in the pickle for

112
00:06:12,870 --> 00:06:16,360
forget about it text file I have the

113
00:06:16,360 --> 00:06:20,260
input and I can this is a beauty

114
00:06:20,260 --> 00:06:22,360
algorithm that's the algorithm here the

115
00:06:22,360 --> 00:06:25,240
function to the cluster and here and do

116
00:06:25,240 --> 00:06:27,039
some aggregation in order to gets

117
00:06:27,039 --> 00:06:30,760
benchmarking results that's all all I

118
00:06:30,760 --> 00:06:34,300
have to do as its if I remember about

119
00:06:34,300 --> 00:06:37,270
construction in MPI job one thing what I

120
00:06:37,270 --> 00:06:40,700
have to do with all the initialization

121
00:06:40,700 --> 00:06:43,820
and it is a fail-safe think this is

122
00:06:43,820 --> 00:06:45,170
inherently failsafe

123
00:06:45,170 --> 00:06:47,090
because spark handles if you didn't

124
00:06:47,090 --> 00:06:49,880
notice crying or had misbehaving or

125
00:06:49,880 --> 00:06:52,070
something like that and only relies on

126
00:06:52,070 --> 00:06:56,960
that every note can read that file so if

127
00:06:56,960 --> 00:06:59,390
you have if I have some kind of shared

128
00:06:59,390 --> 00:07:02,000
file system I can distribute it and run

129
00:07:02,000 --> 00:07:03,280
it in the environment

130
00:07:03,280 --> 00:07:07,310
so if we see mode is quite so

131
00:07:07,310 --> 00:07:10,220
straightforward use a cluster for a

132
00:07:10,220 --> 00:07:15,380
filesystem dump the air the spark jar on

133
00:07:15,380 --> 00:07:18,080
it distributed data in the same

134
00:07:18,080 --> 00:07:21,470
directory and okay it does not use the

135
00:07:21,470 --> 00:07:24,710
locality of data store but this is CPU

136
00:07:24,710 --> 00:07:29,060
bound not data bound and we can use the

137
00:07:29,060 --> 00:07:34,430
standalone mode of spark and okay let's

138
00:07:34,430 --> 00:07:37,450
compare about with a big data set up

139
00:07:37,450 --> 00:07:43,520
okay I have to make some advertisement

140
00:07:43,520 --> 00:07:46,300
for the Apache Victoire distribution and

141
00:07:46,300 --> 00:07:51,740
only one minute left okay oh yes

142
00:07:51,740 --> 00:07:54,740
okay the apache big top is a debian of

143
00:07:54,740 --> 00:07:56,630
potatoes and solutions is who used by

144
00:07:56,630 --> 00:07:59,690
google cloud era canonical and the UDP i

145
00:07:59,690 --> 00:08:03,890
please turn around Roman and it contains

146
00:08:03,890 --> 00:08:06,710
all the usual stuff and it's important

147
00:08:06,710 --> 00:08:09,380
to have a comparable environment we have

148
00:08:09,380 --> 00:08:11,270
a repositories we have provisioning the

149
00:08:11,270 --> 00:08:13,970
Tucker compose for testing of course the

150
00:08:13,970 --> 00:08:15,590
OpenStack is broken oh sorry

151
00:08:15,590 --> 00:08:19,310
the deployment the templates based on

152
00:08:19,310 --> 00:08:21,140
puppet orchestration

153
00:08:21,140 --> 00:08:23,720
if one needs to like to have it through

154
00:08:23,720 --> 00:08:27,020
the charms that's the canonical thing we

155
00:08:27,020 --> 00:08:29,720
have an automotive auto Moloch testing

156
00:08:29,720 --> 00:08:31,880
environment and we have non Intel

157
00:08:31,880 --> 00:08:36,590
architectures and that's a glimpse for

158
00:08:36,590 --> 00:08:38,990
CI composites them that's the

159
00:08:38,990 --> 00:08:40,789
distributions the Linux distribution

160
00:08:40,789 --> 00:08:44,740
center has six seven six debian fedora

161
00:08:44,740 --> 00:08:49,850
fedora on PowerPC and Ubuntu on arm 64

162
00:08:49,850 --> 00:08:53,870
and that's like something like

163
00:08:53,870 --> 00:09:00,569
Hadoop she love hive and something like

164
00:09:00,569 --> 00:09:03,209
that that's all these big data ecosystem

165
00:09:03,209 --> 00:09:07,860
and it's simply a simply deploying it

166
00:09:07,860 --> 00:09:10,949
with the puppet scripts you see HDFS put

167
00:09:10,949 --> 00:09:12,779
the data into it use the yarn motor

168
00:09:12,779 --> 00:09:16,709
spark and unpack the spark to because we

169
00:09:16,709 --> 00:09:19,829
do not support it until now and run okay

170
00:09:19,829 --> 00:09:24,089
works preview of picked up 1.2 is we

171
00:09:24,089 --> 00:09:27,569
will have spark too but unfortunately

172
00:09:27,569 --> 00:09:29,459
it's not finished until now and we need

173
00:09:29,459 --> 00:09:31,439
more help please join us at picked up

174
00:09:31,439 --> 00:09:37,529
Apache or so let me conclude the problem

175
00:09:37,529 --> 00:09:40,019
runs much better on the HPC environment

176
00:09:40,019 --> 00:09:43,079
because it's compute intensive not data

177
00:09:43,079 --> 00:09:45,810
pipeline that's simply the cause the Big

178
00:09:45,810 --> 00:09:48,959
Data environment is optimized for soup

179
00:09:48,959 --> 00:09:51,180
route data to put not for HPC runtimes

180
00:09:51,180 --> 00:09:53,339
oh and the problem

181
00:09:53,339 --> 00:09:56,279
it scales really well it's over for over

182
00:09:56,279 --> 00:10:00,839
m but unfortunately t if we have that's

183
00:10:00,839 --> 00:10:04,139
the number of machines we put in and we

184
00:10:04,139 --> 00:10:06,959
have some runtime the total runtime I'm

185
00:10:06,959 --> 00:10:09,720
waiting for the job that's the

186
00:10:09,720 --> 00:10:12,660
commercial solution because it's a fixed

187
00:10:12,660 --> 00:10:17,899
environment and our n is and that one is

188
00:10:17,899 --> 00:10:24,420
too much for the customer to pay so we

189
00:10:24,420 --> 00:10:28,050
will have to investing some how someone

190
00:10:28,050 --> 00:10:32,939
has to investigate how wealthy where we

191
00:10:32,939 --> 00:10:37,399
can speed up it much better thanks

192
00:10:41,439 --> 00:10:44,858
any questions

