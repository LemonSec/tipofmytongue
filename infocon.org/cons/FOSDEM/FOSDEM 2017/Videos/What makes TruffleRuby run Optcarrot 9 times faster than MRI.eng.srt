1
00:00:08,840 --> 00:00:13,980
so the next one is about JRuby and Monet

2
00:00:13,980 --> 00:00:17,130
can make it nine times faster than ever

3
00:00:17,130 --> 00:00:19,860
ride it's presented by Peter he works

4
00:00:19,860 --> 00:00:22,650
for a local lass and is one of the

5
00:00:22,650 --> 00:00:26,070
maintainer of concurrent Ruby jet so

6
00:00:26,070 --> 00:00:27,860
please

7
00:00:27,860 --> 00:00:34,210
[Applause]

8
00:00:39,200 --> 00:00:40,910
for our collapse which is a research

9
00:00:40,910 --> 00:00:43,820
group within Morocco and we work on a

10
00:00:43,820 --> 00:00:46,940
girl compiler and Pettifer framework

11
00:00:46,940 --> 00:00:48,400
there as well

12
00:00:48,400 --> 00:00:51,500
and I'll be talking about what makes

13
00:00:51,500 --> 00:00:55,280
Java Ruby run nine times faster and MRI

14
00:00:55,280 --> 00:00:59,180
and we recently changed names from

15
00:00:59,180 --> 00:01:03,370
jeremyposter fur to just stuff for Ruby

16
00:01:03,460 --> 00:01:05,930
like to make sure at the beginning that

17
00:01:05,930 --> 00:01:07,040
you understand this is a research

18
00:01:07,040 --> 00:01:10,220
product so by any Orrico stocks based on

19
00:01:10,220 --> 00:01:13,369
anything you hear here today even if you

20
00:01:13,369 --> 00:01:15,520
like

21
00:01:18,229 --> 00:01:21,439
so I start talking a little bit about

22
00:01:21,439 --> 00:01:25,149
account what it what it is then I

23
00:01:25,149 --> 00:01:28,340
explain what stuff Aruba is and then I

24
00:01:28,340 --> 00:01:30,259
follow with explaining some of the

25
00:01:30,259 --> 00:01:32,299
optimizations we do and how we are able

26
00:01:32,299 --> 00:01:34,369
to run it around hope to correct many

27
00:01:34,369 --> 00:01:42,649
times fast so up caret is Ness emulator

28
00:01:42,649 --> 00:01:44,899
which means net bonus is short cut for

29
00:01:44,899 --> 00:01:46,909
Nintendo Entertainment System which is

30
00:01:46,909 --> 00:01:50,659
so all to konso now it's it has a bit

31
00:01:50,659 --> 00:01:55,009
CPU and picture processing unit and two

32
00:01:55,009 --> 00:01:58,700
kilobytes of RAM and gram roster east in

33
00:01:58,700 --> 00:02:01,579
1983 and so you can look up the

34
00:02:01,579 --> 00:02:03,349
benchmark or get up

35
00:02:03,349 --> 00:02:06,470
it was created to drive the improvements

36
00:02:06,470 --> 00:02:10,610
for a ruby free to make MRI free ride

37
00:02:10,610 --> 00:02:15,530
free that three times faster and the

38
00:02:15,530 --> 00:02:21,190
benchmark itself runs run master game so

39
00:02:21,190 --> 00:02:24,920
they start by that we have a look even

40
00:02:24,920 --> 00:02:26,359
though the benchmark was not developed

41
00:02:26,359 --> 00:02:29,299
primarily for being to play the games

42
00:02:29,299 --> 00:02:31,519
but you can do it anyway

43
00:02:31,519 --> 00:02:36,470
so we can play one master on you see

44
00:02:36,470 --> 00:02:40,430
some MRI 2.4 hey you can see it's a

45
00:02:40,430 --> 00:02:43,370
little bit laggy so it takes about 40

46
00:02:43,370 --> 00:02:45,950
seconds before I solve this simple the

47
00:02:45,950 --> 00:02:49,850
first level so just bear with me for a

48
00:02:49,850 --> 00:02:52,630
few more seconds

49
00:02:55,380 --> 00:03:01,600
almost there you can see it's around 14

50
00:03:01,600 --> 00:03:12,220
or 15 frames per second but if we if you

51
00:03:12,220 --> 00:03:15,520
run the same thing on a tougher ruby it

52
00:03:15,520 --> 00:03:20,800
will be much better so so I'll be able

53
00:03:20,800 --> 00:03:23,860
to solve the same level in about 20

54
00:03:23,860 --> 00:03:26,830
seconds because just the UI works much

55
00:03:26,830 --> 00:03:29,640
nicer so that's it

56
00:03:29,640 --> 00:03:33,370
this is not this is very subjective I

57
00:03:33,370 --> 00:03:36,880
have to compare the implementations but

58
00:03:36,880 --> 00:03:38,440
I wanted to show you that it's actually

59
00:03:38,440 --> 00:03:40,930
you you can actually play games on top a

60
00:03:40,930 --> 00:03:44,140
little bit of carrot so let's move on to

61
00:03:44,140 --> 00:03:46,769
results

62
00:03:49,590 --> 00:03:52,230
so these are these are the results

63
00:03:52,230 --> 00:03:56,580
published and in the carrot read me on

64
00:03:56,580 --> 00:03:58,940
github for all the different

65
00:03:58,940 --> 00:04:04,160
implementations they are run up until

66
00:04:04,160 --> 00:04:08,220
180 frames just not enough for a bit of

67
00:04:08,220 --> 00:04:11,190
fully warm-up and also the tougher B is

68
00:04:11,190 --> 00:04:13,650
not part of this benchmark of DC results

69
00:04:13,650 --> 00:04:18,329
so we run around now so I will show you

70
00:04:18,329 --> 00:04:20,339
results for these four implementations

71
00:04:20,339 --> 00:04:24,750
MRI 2.0 which is the baseline the latest

72
00:04:24,750 --> 00:04:27,450
one JRuby which I moved in a mechanical

73
00:04:27,450 --> 00:04:30,930
tandem server and of course there will

74
00:04:30,930 --> 00:04:38,130
be on growl VM 0.19 I'll be using 6,000

75
00:04:38,130 --> 00:04:43,880
frames to let it run much longer

76
00:04:47,930 --> 00:04:50,530
so

77
00:04:52,340 --> 00:04:59,880
at first I've zoomed in at the first 600

78
00:04:59,880 --> 00:05:05,280
frames the x-axis are frames and episode

79
00:05:05,280 --> 00:05:09,690
axis is frames per second and you can

80
00:05:09,690 --> 00:05:11,670
see that the MRI implementations are

81
00:05:11,670 --> 00:05:16,680
pretty stable from the beginning the 2.4

82
00:05:16,680 --> 00:05:19,410
is slightly faster the green dots

83
00:05:19,410 --> 00:05:22,860
represent samples from JRuby you can see

84
00:05:22,860 --> 00:05:24,660
that it takes a little bit to warm up

85
00:05:24,660 --> 00:05:27,060
and then it's stable around 50 frames

86
00:05:27,060 --> 00:05:28,160
per second

87
00:05:28,160 --> 00:05:30,900
preferably has longer warm up but it's

88
00:05:30,900 --> 00:05:32,700
because we didn't really looked at it

89
00:05:32,700 --> 00:05:35,850
yet so don't take this as a final state

90
00:05:35,850 --> 00:05:40,200
how fast or slow we warm up let me don't

91
00:05:40,200 --> 00:05:42,390
stop at the 50 frames per second we go

92
00:05:42,390 --> 00:05:47,580
up to 110 and if if we look at the whole

93
00:05:47,580 --> 00:05:52,860
graph for 6,000 frames you can see that

94
00:05:52,860 --> 00:05:55,800
referral base is after all the

95
00:05:55,800 --> 00:05:59,640
optimizations are done it goes up to 240

96
00:05:59,640 --> 00:06:03,270
frames per second compared to MRI which

97
00:06:03,270 --> 00:06:07,490
is down around 20 something

98
00:06:08,680 --> 00:06:12,550
so this is the comparison by taking the

99
00:06:12,550 --> 00:06:15,960
last 1,000 samples from the previous

100
00:06:15,960 --> 00:06:24,220
slide so let's have a look at the closer

101
00:06:24,220 --> 00:06:28,810
look at opt karat so if you profile the

102
00:06:28,810 --> 00:06:31,570
code you can see that there is one who

103
00:06:31,570 --> 00:06:34,830
really hot metal and our pixel in the PP

104
00:06:34,830 --> 00:06:40,449
picture processing unit class so we will

105
00:06:40,449 --> 00:06:42,639
be looking at its source code and there

106
00:06:42,639 --> 00:06:44,260
is also a group of nodes which are

107
00:06:44,260 --> 00:06:47,370
representing the memory mode access

108
00:06:47,370 --> 00:06:50,830
memory remote access and instructions in

109
00:06:50,830 --> 00:06:53,169
the CPU class so we'll be looking at

110
00:06:53,169 --> 00:06:57,400
those as well so this is the source code

111
00:06:57,400 --> 00:07:00,610
for the end our pixel method from the

112
00:07:00,610 --> 00:07:05,050
PPU as you can see and that's a lots of

113
00:07:05,050 --> 00:07:07,509
instance variable access is some integer

114
00:07:07,509 --> 00:07:09,729
operations and also access these arrays

115
00:07:09,729 --> 00:07:16,570
and appends arrays so we will be later

116
00:07:16,570 --> 00:07:18,280
looking and how we optimize instance

117
00:07:18,280 --> 00:07:20,889
variables for example the source code

118
00:07:20,889 --> 00:07:24,520
for CPU it's not just one method

119
00:07:24,520 --> 00:07:29,349
composed for many methods and there's

120
00:07:29,349 --> 00:07:33,310
also a constant The Dispatch which is an

121
00:07:33,310 --> 00:07:36,400
array of arrays which is used to map the

122
00:07:36,400 --> 00:07:39,240
opcode this is just an integer value to

123
00:07:39,240 --> 00:07:41,440
method name and the arguments of the

124
00:07:41,440 --> 00:07:42,760
method which should be called for a

125
00:07:42,760 --> 00:07:45,130
given up optical so for example if the

126
00:07:45,130 --> 00:07:48,120
opcode is one then it looks up the first

127
00:07:48,120 --> 00:07:52,810
array the array in the in the position

128
00:07:52,810 --> 00:07:56,080
one from The Dispatch and it's called

129
00:07:56,080 --> 00:07:58,180
with the sent method so it will go to

130
00:07:58,180 --> 00:08:02,229
the OP method and there there are two

131
00:08:02,229 --> 00:08:05,949
other sense right the first one prepares

132
00:08:05,949 --> 00:08:08,650
the environment from for reading from a

133
00:08:08,650 --> 00:08:11,020
memory in a given mode and the seconds

134
00:08:11,020 --> 00:08:13,300
and just executed some of the

135
00:08:13,300 --> 00:08:15,840
instructions

136
00:08:22,520 --> 00:08:26,730
so before we go to talk about some of

137
00:08:26,730 --> 00:08:28,710
the optimization specifically I also

138
00:08:28,710 --> 00:08:31,980
explain a little bit generally how

139
00:08:31,980 --> 00:08:35,570
truffle Ruby works

140
00:08:36,450 --> 00:08:38,849
I forgot to mention at the beginning if

141
00:08:38,849 --> 00:08:41,578
you have if I explain something poorly

142
00:08:41,578 --> 00:08:43,529
please ask immediately don't wait at the

143
00:08:43,529 --> 00:08:47,490
at the end so taro base pervy

144
00:08:47,490 --> 00:08:50,880
implementation we aim to be very highly

145
00:08:50,880 --> 00:08:53,160
compatible with MRI which means that we

146
00:08:53,160 --> 00:08:55,649
will be able to run the C extensions we

147
00:08:55,649 --> 00:08:57,180
will just run them but we will around

148
00:08:57,180 --> 00:09:01,800
them as fast as samurai does and of

149
00:09:01,800 --> 00:09:03,720
course they I mean I miss performances

150
00:09:03,720 --> 00:09:05,790
you've seen the results so which also

151
00:09:05,790 --> 00:09:08,130
means that there should not be any more

152
00:09:08,130 --> 00:09:11,010
need for writing C extensions or I see

153
00:09:11,010 --> 00:09:13,589
our extensions because code you write in

154
00:09:13,589 --> 00:09:15,990
a rouble should be as fast as almost as

155
00:09:15,990 --> 00:09:19,050
fastest if you would write OC extent you

156
00:09:19,050 --> 00:09:23,519
know or interest or whatever the truffle

157
00:09:23,519 --> 00:09:25,410
Ruby implementation is using truffle

158
00:09:25,410 --> 00:09:27,480
which is a language implementation

159
00:09:27,480 --> 00:09:30,420
framework which is a self optimizing

160
00:09:30,420 --> 00:09:32,310
casting interpreter and I'll be

161
00:09:32,310 --> 00:09:35,579
explaining that and its uses growl

162
00:09:35,579 --> 00:09:38,370
compiler to just-in-time compile the

163
00:09:38,370 --> 00:09:41,180
Ruby methods

164
00:09:45,700 --> 00:09:48,430
so I'll start by explaining what's

165
00:09:48,430 --> 00:09:50,770
abstract syntax to me so if you have a

166
00:09:50,770 --> 00:09:54,820
simple method foo I can express that as

167
00:09:54,820 --> 00:09:58,780
a tree at the beginning is the call to

168
00:09:58,780 --> 00:10:03,490
the two string method the left branch

169
00:10:03,490 --> 00:10:05,650
goes to the receiver which in this case

170
00:10:05,650 --> 00:10:08,080
is called to the plus method on a

171
00:10:08,080 --> 00:10:10,740
receiver 6 with first argument 7 and

172
00:10:10,740 --> 00:10:13,810
then the right branch at the top is 8

173
00:10:13,810 --> 00:10:15,580
which is the argument of the two string

174
00:10:15,580 --> 00:10:19,510
method so we can turn this into

175
00:10:19,510 --> 00:10:22,060
interpreter very easily by representing

176
00:10:22,060 --> 00:10:24,700
each of the nodes with a class so for

177
00:10:24,700 --> 00:10:28,000
example we start with with the constant

178
00:10:28,000 --> 00:10:30,760
with greater nodes with the numbers so

179
00:10:30,760 --> 00:10:33,550
we can implement it just by creating

180
00:10:33,550 --> 00:10:36,220
this literal node where it's initialized

181
00:10:36,220 --> 00:10:38,380
with the value and then you call the

182
00:10:38,380 --> 00:10:39,670
execute method where you are

183
00:10:39,670 --> 00:10:41,350
interpreting the node it will just

184
00:10:41,350 --> 00:10:43,150
return the value which was used to

185
00:10:43,150 --> 00:10:46,540
initialize the node now let's have a

186
00:10:46,540 --> 00:10:51,520
look at the method calls so now we have

187
00:10:51,520 --> 00:10:53,020
to create a node with a little bit more

188
00:10:53,020 --> 00:10:54,820
information we need the name

189
00:10:54,820 --> 00:10:57,760
we need the node which is representing

190
00:10:57,760 --> 00:11:00,580
the receiver and we need array of nodes

191
00:11:00,580 --> 00:11:02,200
which are opposing with the arguments

192
00:11:02,200 --> 00:11:06,490
for the method so those we assigned two

193
00:11:06,490 --> 00:11:08,050
instance variables and then we execute

194
00:11:08,050 --> 00:11:11,260
this node we first have to execute the

195
00:11:11,260 --> 00:11:13,540
receiver out to get the actual object

196
00:11:13,540 --> 00:11:16,120
the receiver then we look up the method

197
00:11:16,120 --> 00:11:19,500
by name and then we can call the method

198
00:11:19,500 --> 00:11:24,010
with the receiver and with the arguments

199
00:11:24,010 --> 00:11:26,440
after evaluating the nodes representing

200
00:11:26,440 --> 00:11:29,100
the arguments

201
00:11:33,520 --> 00:11:37,700
but as I said truffle is self-optimizing

202
00:11:37,700 --> 00:11:41,180
abstract syntax tree interpreter so try

203
00:11:41,180 --> 00:11:43,850
continue this simple example we can for

204
00:11:43,850 --> 00:11:46,960
example do you know the replacement so

205
00:11:46,960 --> 00:11:50,720
we had the budget called

206
00:11:50,720 --> 00:11:54,980
we had method call note so we can do one

207
00:11:54,980 --> 00:11:58,130
monomorphic cash simple monomer figure

208
00:11:58,130 --> 00:12:00,890
here by creating initialized method Co

209
00:12:00,890 --> 00:12:03,860
node which when it's first executed it

210
00:12:03,860 --> 00:12:06,020
will look up the method and then it

211
00:12:06,020 --> 00:12:08,480
replaces itself with another node cached

212
00:12:08,480 --> 00:12:12,080
method call node but there won't be just

213
00:12:12,080 --> 00:12:13,610
the name of the method it will be

214
00:12:13,610 --> 00:12:15,680
already the object representing two

215
00:12:15,680 --> 00:12:18,710
methods to be called and after it's

216
00:12:18,710 --> 00:12:20,870
replaced it will be immediately called

217
00:12:20,870 --> 00:12:25,070
and if you look at the cached method

218
00:12:25,070 --> 00:12:29,450
call note cars we see that in the

219
00:12:29,450 --> 00:12:31,790
execute method the method is immediately

220
00:12:31,790 --> 00:12:33,950
called there is no more expensive look

221
00:12:33,950 --> 00:12:36,410
lookup of the method through the classes

222
00:12:36,410 --> 00:12:39,890
and modules of firme this is of course

223
00:12:39,890 --> 00:12:42,110
very simplified example I won't be

224
00:12:42,110 --> 00:12:43,790
explaining how we do the optimizations

225
00:12:43,790 --> 00:12:45,140
and stuff like that how we deal with

226
00:12:45,140 --> 00:12:48,500
when the method is defined and stuff

227
00:12:48,500 --> 00:12:51,050
like that of course we handle that but I

228
00:12:51,050 --> 00:12:54,099
am skipping it

229
00:13:00,850 --> 00:13:04,310
but even though the notes are

230
00:13:04,310 --> 00:13:07,100
specializing for the code they are

231
00:13:07,100 --> 00:13:09,740
executing by for example doing so

232
00:13:09,740 --> 00:13:11,900
cashews and stuff like that it's not

233
00:13:11,900 --> 00:13:14,840
enough to be able to run that fast so we

234
00:13:14,840 --> 00:13:18,230
need to be able somehow to compile this

235
00:13:18,230 --> 00:13:20,150
so for that we was partial evaluation

236
00:13:20,150 --> 00:13:22,160
which basically eliminates all the

237
00:13:22,160 --> 00:13:28,760
overhead of executing the notes so we do

238
00:13:28,760 --> 00:13:31,160
that by trying to execute as much as we

239
00:13:31,160 --> 00:13:34,190
can because we use all the constant

240
00:13:34,190 --> 00:13:39,620
information from the notes so if we have

241
00:13:39,620 --> 00:13:42,200
a look again at cache method Connaught

242
00:13:42,200 --> 00:13:49,960
and later note we add in this example

243
00:13:49,960 --> 00:13:53,210
attribute final we will be just assuming

244
00:13:53,210 --> 00:13:55,220
for this example that ruby has final

245
00:13:55,220 --> 00:13:57,020
methods which means that sorry final

246
00:13:57,020 --> 00:13:59,320
instance variables which means that

247
00:13:59,320 --> 00:14:03,410
basically after you set some value to

248
00:14:03,410 --> 00:14:05,300
the instance variable it cannot be and

249
00:14:05,300 --> 00:14:08,000
it can't be ever changed which is

250
00:14:08,000 --> 00:14:11,290
important for the partial evaluation so

251
00:14:11,290 --> 00:14:14,720
if we take the we represent the code

252
00:14:14,720 --> 00:14:17,030
from the previous slides with these

253
00:14:17,030 --> 00:14:20,660
nodes and we start to partially

254
00:14:20,660 --> 00:14:23,690
evaluating it so we start by copying the

255
00:14:23,690 --> 00:14:26,360
body of the method of the top node for

256
00:14:26,360 --> 00:14:29,810
executing the to string method but now

257
00:14:29,810 --> 00:14:32,030
because we've marks at some of the

258
00:14:32,030 --> 00:14:34,430
instance variables this final you know

259
00:14:34,430 --> 00:14:36,530
that the method receiver arguments are

260
00:14:36,530 --> 00:14:39,230
final constant values during the

261
00:14:39,230 --> 00:14:43,630
compilation so we now can expand that to

262
00:14:43,630 --> 00:14:45,950
just the array which contains the one

263
00:14:45,950 --> 00:14:49,490
letter or note which contains the value

264
00:14:49,490 --> 00:14:51,830
eight I'm using the brackets here to

265
00:14:51,830 --> 00:14:53,240
represent objects which are already

266
00:14:53,240 --> 00:14:55,910
created this is not an instantiation of

267
00:14:55,910 --> 00:14:58,670
that object is just representation of

268
00:14:58,670 --> 00:15:00,260
the object which was already stored with

269
00:15:00,260 --> 00:15:03,620
the arguments instance variable so now

270
00:15:03,620 --> 00:15:07,220
we can get rid of two array we can

271
00:15:07,220 --> 00:15:10,790
execute the method exactly on the return

272
00:15:10,790 --> 00:15:13,660
you remember is just a reading of the

273
00:15:13,660 --> 00:15:16,310
value instance variable inside the

274
00:15:16,310 --> 00:15:18,500
literal node which is constant so we can

275
00:15:18,500 --> 00:15:22,930
just replace that with eight now we will

276
00:15:22,930 --> 00:15:26,660
our receiver so I do a little

277
00:15:26,660 --> 00:15:30,110
substitution here to make it easier so

278
00:15:30,110 --> 00:15:32,360
again we replace the executor with the

279
00:15:32,360 --> 00:15:34,970
Maddie body of the executive method on

280
00:15:34,970 --> 00:15:40,880
the cache method Connaught and again we

281
00:15:40,880 --> 00:15:45,250
replace the arguments with seven

282
00:15:45,250 --> 00:15:47,990
receiver is in this case a certain node

283
00:15:47,990 --> 00:15:52,070
4 6 so we replace that 4 6 and the

284
00:15:52,070 --> 00:15:55,430
method is again because it's cache cache

285
00:15:55,430 --> 00:15:57,050
method call node so the method was

286
00:15:57,050 --> 00:15:59,930
already looked up in the initialize node

287
00:15:59,930 --> 00:16:02,450
before so the method is again just the

288
00:16:02,450 --> 00:16:05,780
object representing the method itself so

289
00:16:05,780 --> 00:16:07,280
we can replace that with the direct call

290
00:16:07,280 --> 00:16:11,750
to the method on the integer class so we

291
00:16:11,750 --> 00:16:12,890
now put that back

292
00:16:12,890 --> 00:16:19,070
and there are things we have to do is

293
00:16:19,070 --> 00:16:21,590
replace the first method which is the

294
00:16:21,590 --> 00:16:27,050
instance variable from the top node to

295
00:16:27,050 --> 00:16:30,770
get just two direct calls so we've

296
00:16:30,770 --> 00:16:33,980
eliminated all the execute methods of

297
00:16:33,980 --> 00:16:36,130
the nodes and they are left but just

298
00:16:36,130 --> 00:16:40,630
with the bare minimum they have to do

299
00:16:48,110 --> 00:16:50,720
so this is the compression you need

300
00:16:50,720 --> 00:16:55,220
basically which will then is fat to girl

301
00:16:55,220 --> 00:16:58,850
compiler and compile produces highly

302
00:16:58,850 --> 00:17:01,720
optimized the machine code for this

303
00:17:01,720 --> 00:17:05,510
calculation unit so next time when you

304
00:17:05,510 --> 00:17:07,609
call this method it will not go through

305
00:17:07,609 --> 00:17:09,619
the interpreter through calling the

306
00:17:09,619 --> 00:17:11,959
executives on the notes but ago called

307
00:17:11,959 --> 00:17:20,660
the compiled code for this ok so we

308
00:17:20,660 --> 00:17:22,790
actually don't write the Ruby notes in

309
00:17:22,790 --> 00:17:25,790
Ruby with Java for that so this is a

310
00:17:25,790 --> 00:17:28,220
small example from our actual

311
00:17:28,220 --> 00:17:30,830
implementation of the boss operation of

312
00:17:30,830 --> 00:17:36,380
on fixnum use DSL a lot which means in

313
00:17:36,380 --> 00:17:39,470
Java that we use annotations heavily and

314
00:17:39,470 --> 00:17:42,170
annotation processors so for example the

315
00:17:42,170 --> 00:17:47,000
code on the left just means that for

316
00:17:47,000 --> 00:17:49,480
doing plus operation on a fixed number

317
00:17:49,480 --> 00:17:53,080
we have at least these four

318
00:17:53,080 --> 00:17:56,270
specializations where the first one is

319
00:17:56,270 --> 00:18:00,050
used for doing addition of two small

320
00:18:00,050 --> 00:18:03,380
integers without overflow if that fails

321
00:18:03,380 --> 00:18:05,660
with the arithmetic exception then the

322
00:18:05,660 --> 00:18:07,820
second specialization is used which

323
00:18:07,820 --> 00:18:10,310
causes the values to long to avoid the

324
00:18:10,310 --> 00:18:14,800
overflow if we are adding two wrongs

325
00:18:14,800 --> 00:18:18,860
then we have to check if you are getting

326
00:18:18,860 --> 00:18:20,600
again the automatic exception because it

327
00:18:20,600 --> 00:18:23,060
can again overflow if it does we have to

328
00:18:23,060 --> 00:18:25,400
create baking teacher at the very how

329
00:18:25,400 --> 00:18:27,140
this is implemented is that the

330
00:18:27,140 --> 00:18:29,270
annotation process structure generates

331
00:18:29,270 --> 00:18:31,910
notes for each of these methods for us

332
00:18:31,910 --> 00:18:35,270
so based on which of the special agents

333
00:18:35,270 --> 00:18:38,210
and specializations is used then they

334
00:18:38,210 --> 00:18:42,740
are added to chain which is represent

335
00:18:42,740 --> 00:18:46,760
which is then called the executable

336
00:18:46,760 --> 00:18:49,250
methods are caught on the chain and then

337
00:18:49,250 --> 00:18:50,840
it of course goes through the partial

338
00:18:50,840 --> 00:18:54,190
evolutions and to the computation

339
00:18:54,190 --> 00:18:57,020
and this is also a example how we do

340
00:18:57,020 --> 00:19:01,580
type specialization so for so if you use

341
00:19:01,580 --> 00:19:05,029
in your code only small integers only

342
00:19:05,029 --> 00:19:06,710
this the first method will be triggered

343
00:19:06,710 --> 00:19:09,140
for this so it will end up compiled just

344
00:19:09,140 --> 00:19:11,210
as a single instruction for integer

345
00:19:11,210 --> 00:19:14,330
addition and one jump overflow if to

346
00:19:14,330 --> 00:19:17,059
check that it didn't over fault that's

347
00:19:17,059 --> 00:19:19,240
it

348
00:19:24,490 --> 00:19:30,850
so there was the basics of truffle so a

349
00:19:30,850 --> 00:19:33,970
little bit about how we optimize how we

350
00:19:33,970 --> 00:19:35,770
do instance variable access because

351
00:19:35,770 --> 00:19:38,590
we've seen seen it a lot in the source

352
00:19:38,590 --> 00:19:40,150
code of the methods of the OP car

353
00:19:40,150 --> 00:19:44,080
benchmark so the Ruby objects can grow

354
00:19:44,080 --> 00:19:45,940
and shrink which means that a new

355
00:19:45,940 --> 00:19:47,170
instance variable can be added or

356
00:19:47,170 --> 00:19:50,110
removed from the object so because of

357
00:19:50,110 --> 00:19:52,360
that we use the following a presentation

358
00:19:52,360 --> 00:19:55,450
we have a dynamic object which is which

359
00:19:55,450 --> 00:19:58,870
is representing a ruby object and it has

360
00:19:58,870 --> 00:20:00,970
few fields to store some values of

361
00:20:00,970 --> 00:20:03,490
instance variables and it also has a way

362
00:20:03,490 --> 00:20:05,860
to store any additional instance

363
00:20:05,860 --> 00:20:07,510
variables which are not fitting in these

364
00:20:07,510 --> 00:20:11,200
two few fields and array of course then

365
00:20:11,200 --> 00:20:16,420
can be grown or shrink as needed and we

366
00:20:16,420 --> 00:20:19,800
have a companion object shape assigned

367
00:20:19,800 --> 00:20:22,750
from each dynamic object it describes

368
00:20:22,750 --> 00:20:25,300
where each instance variable is stored

369
00:20:25,300 --> 00:20:30,070
in the dynamic object so in the shape we

370
00:20:30,070 --> 00:20:32,290
can look up that for example the name

371
00:20:32,290 --> 00:20:33,760
instance whatever I store that the

372
00:20:33,760 --> 00:20:36,790
certain offset in the dynamic object on

373
00:20:36,790 --> 00:20:39,389
the fields to

374
00:20:47,100 --> 00:20:50,250
so because of that what we want to do is

375
00:20:50,250 --> 00:20:53,050
you don't want to each time we want

376
00:20:53,050 --> 00:20:55,450
dorita instance variable we don't want

377
00:20:55,450 --> 00:20:57,250
to go through shape looking in up where

378
00:20:57,250 --> 00:20:59,860
it is but it's the actual instance and

379
00:20:59,860 --> 00:21:03,390
reading it want to somehow cache where

380
00:21:03,390 --> 00:21:06,220
we should read the instances sorry the

381
00:21:06,220 --> 00:21:09,030
values of the instance variables from so

382
00:21:09,030 --> 00:21:11,800
this is again a small example how it

383
00:21:11,800 --> 00:21:14,140
looks like in our implementation or it

384
00:21:14,140 --> 00:21:18,160
basically does is that as if there is

385
00:21:18,160 --> 00:21:19,930
any code to read from instance variable

386
00:21:19,930 --> 00:21:22,120
at the beginning its initialized and

387
00:21:22,120 --> 00:21:24,400
then when its first time it with

388
00:21:24,400 --> 00:21:27,010
something it catches the shape of the

389
00:21:27,010 --> 00:21:31,660
object its seen and it catches the shape

390
00:21:31,660 --> 00:21:36,310
and also the property which stores the

391
00:21:36,310 --> 00:21:38,710
offset in the dynamic object when the

392
00:21:38,710 --> 00:21:41,770
value is stored and the shape and the

393
00:21:41,770 --> 00:21:47,440
property is final so if I switch to a

394
00:21:47,440 --> 00:21:50,560
graphic representation we start with

395
00:21:50,560 --> 00:21:56,230
initialized then when we read some for

396
00:21:56,230 --> 00:21:57,760
example instance variable name for my

397
00:21:57,760 --> 00:22:00,730
object we catch that it has a it has a

398
00:22:00,730 --> 00:22:02,320
shape with the instance variable name

399
00:22:02,320 --> 00:22:06,610
and that the property for describing the

400
00:22:06,610 --> 00:22:09,160
instance variable name is sketched as

401
00:22:09,160 --> 00:22:12,160
well and within that there is stored

402
00:22:12,160 --> 00:22:15,070
offset the final offset well of the

403
00:22:15,070 --> 00:22:16,900
value of the instance variable which

404
00:22:16,900 --> 00:22:19,360
means that next time when we are reading

405
00:22:19,360 --> 00:22:22,000
the value we first just check the shape

406
00:22:22,000 --> 00:22:23,920
of the dynamic object is equal to the

407
00:22:23,920 --> 00:22:28,360
cached shape which is very cheap and if

408
00:22:28,360 --> 00:22:30,100
it does we can immediately read the

409
00:22:30,100 --> 00:22:32,980
value from the final offset stored in

410
00:22:32,980 --> 00:22:35,350
the property so we don't have to go

411
00:22:35,350 --> 00:22:37,240
through the shape and looking up the

412
00:22:37,240 --> 00:22:39,100
property and it very store and stuff

413
00:22:39,100 --> 00:22:41,459
like that

414
00:22:47,150 --> 00:22:51,570
so if you have very simple method read

415
00:22:51,570 --> 00:22:55,170
with just reach one instance variable so

416
00:22:55,170 --> 00:23:00,810
we can then have a look at a graph of IR

417
00:23:00,810 --> 00:23:02,780
internal representation from growl this

418
00:23:02,780 --> 00:23:04,170
screenshot from the

419
00:23:04,170 --> 00:23:09,510
igv and we can verify what I'm just

420
00:23:09,510 --> 00:23:10,920
trying to explain on the previous slide

421
00:23:10,920 --> 00:23:15,570
so at the beginning these notes are just

422
00:23:15,570 --> 00:23:18,690
reading arguments from given to the

423
00:23:18,690 --> 00:23:24,150
method and this one is self so if you

424
00:23:24,150 --> 00:23:27,150
follow the blue line you can't read it

425
00:23:27,150 --> 00:23:28,770
so I have to explain it

426
00:23:28,770 --> 00:23:36,060
this one just reads the shape and blue

427
00:23:36,060 --> 00:23:38,970
one underneath is comparing the shape it

428
00:23:38,970 --> 00:23:40,650
just read from the dynamic object with

429
00:23:40,650 --> 00:23:43,530
the constant value which is part of the

430
00:23:43,530 --> 00:23:46,920
compiled code so if this succeeds it

431
00:23:46,920 --> 00:23:51,870
goes it goes first

432
00:23:51,870 --> 00:23:54,080
sorry

433
00:23:54,080 --> 00:23:57,200
it goes here where it reads the value

434
00:23:57,200 --> 00:24:01,789
from the from the self object and it

435
00:24:01,789 --> 00:24:06,080
uses this small gray rectangle is the

436
00:24:06,080 --> 00:24:10,990
final value the offset plates right from

437
00:24:20,290 --> 00:24:22,960
but the real advantage is that if you

438
00:24:22,960 --> 00:24:25,750
have a lot of instance variables in the

439
00:24:25,750 --> 00:24:28,090
method like in this one which is some

440
00:24:28,090 --> 00:24:31,000
zero page mode for accessing memory from

441
00:24:31,000 --> 00:24:34,090
the benchmark the checks for reading the

442
00:24:34,090 --> 00:24:36,040
instance variables are actually match

443
00:24:36,040 --> 00:24:39,549
together so again this is just a subset

444
00:24:39,549 --> 00:24:43,090
of of the igb graph and you can see

445
00:24:43,090 --> 00:24:46,960
there is a metro there is a many equal

446
00:24:46,960 --> 00:24:48,730
checks which is all checking like the

447
00:24:48,730 --> 00:24:50,440
shape of the method is the one we are

448
00:24:50,440 --> 00:24:54,669
expecting but this is actually after one

449
00:24:54,669 --> 00:24:57,820
more path optimizing paths in the graph

450
00:24:57,820 --> 00:25:00,490
compile this is to just three checks for

451
00:25:00,490 --> 00:25:03,059
the whole method

452
00:25:11,900 --> 00:25:15,110
so the next thing is splitting

453
00:25:15,110 --> 00:25:18,900
optimization and we will have a look at

454
00:25:18,900 --> 00:25:20,760
those again at the source code for the

455
00:25:20,760 --> 00:25:24,960
CPU code as you can notice there are two

456
00:25:24,960 --> 00:25:27,540
cents method here in the operation

457
00:25:27,540 --> 00:25:32,580
method and this cent method is in our

458
00:25:32,580 --> 00:25:34,500
representation represented as a tree of

459
00:25:34,500 --> 00:25:37,919
notes right and if we had just one tree

460
00:25:37,919 --> 00:25:44,070
for a cent method then we couldn't

461
00:25:44,070 --> 00:25:46,919
specialize for these different cases we

462
00:25:46,919 --> 00:25:48,720
are calling to send metal on different

463
00:25:48,720 --> 00:25:50,880
prices and there may be different modes

464
00:25:50,880 --> 00:25:53,400
and instructions the its calling

465
00:25:53,400 --> 00:25:56,190
different methods so we want the the

466
00:25:56,190 --> 00:25:58,679
call to send specialized different in

467
00:25:58,679 --> 00:26:03,960
these two places so for that we use two

468
00:26:03,960 --> 00:26:10,190
dimensional polymorphic wine cash and

469
00:26:11,470 --> 00:26:13,690
because actually I have the example here

470
00:26:13,690 --> 00:26:15,340
different set method actually in this

471
00:26:15,340 --> 00:26:18,340
benchmark is called with the fur with

472
00:26:18,340 --> 00:26:22,510
six different modes and second sandwich

473
00:26:22,510 --> 00:26:24,930
R which is calling the instructions is

474
00:26:24,930 --> 00:26:27,970
seven different instructions which is

475
00:26:27,970 --> 00:26:29,410
which I represent about seven different

476
00:26:29,410 --> 00:26:34,240
methods so you want to use the cache to

477
00:26:34,240 --> 00:26:39,150
specialized e to sand sense differently

478
00:26:39,150 --> 00:26:41,800
so for that are you splitting and that

479
00:26:41,800 --> 00:26:43,990
means that we just take the original

480
00:26:43,990 --> 00:26:46,630
three representing the body of the sand

481
00:26:46,630 --> 00:26:48,340
method having copied and they have two

482
00:26:48,340 --> 00:26:51,220
copies of it and the first banner having

483
00:26:51,220 --> 00:26:53,470
the cache specializes for the first and

484
00:26:53,470 --> 00:26:55,330
said note and the second one specialized

485
00:26:55,330 --> 00:26:59,170
for the second segment so let's have a

486
00:26:59,170 --> 00:27:01,030
look a little bit more how this works so

487
00:27:01,030 --> 00:27:03,640
at the beginning there is again

488
00:27:03,640 --> 00:27:07,180
initialized note inside the center tree

489
00:27:07,180 --> 00:27:11,140
and when the first method when it's

490
00:27:11,140 --> 00:27:14,110
called with the first method it in there

491
00:27:14,110 --> 00:27:17,440
it's one known which checks if it's EPS

492
00:27:17,440 --> 00:27:20,950
which exact absolute access mode then it

493
00:27:20,950 --> 00:27:22,780
checks that the receiver is Kanaan type

494
00:27:22,780 --> 00:27:25,090
which in this case is always CPU but

495
00:27:25,090 --> 00:27:26,710
this is the second dimension if it was

496
00:27:26,710 --> 00:27:29,560
some different type of receiver we would

497
00:27:29,560 --> 00:27:31,990
have another branch here so if these two

498
00:27:31,990 --> 00:27:33,520
checks are correct and it can directly

499
00:27:33,520 --> 00:27:36,760
call the abstract sorry absolute method

500
00:27:36,760 --> 00:27:41,500
on CPU as different methods are called

501
00:27:41,500 --> 00:27:44,320
the three of the send method groves

502
00:27:44,320 --> 00:27:46,930
cashing all the different methods they

503
00:27:46,930 --> 00:27:49,350
are called

504
00:27:50,930 --> 00:27:53,850
and this is again the representation

505
00:27:53,850 --> 00:27:56,370
from igv Guevara you can actually look

506
00:27:56,370 --> 00:27:59,250
at it how it was specialized for a given

507
00:27:59,250 --> 00:28:02,640
cult so in this case you can almost

508
00:28:02,640 --> 00:28:05,810
reach the names of the methods and the

509
00:28:05,810 --> 00:28:10,070
of the memory accesses

510
00:28:15,010 --> 00:28:17,570
so splitting is applied to all methods

511
00:28:17,570 --> 00:28:19,520
which is particularly important for the

512
00:28:19,520 --> 00:28:23,780
core methods like each to string equal

513
00:28:23,780 --> 00:28:26,990
sapphire which are called all over the

514
00:28:26,990 --> 00:28:29,960
source code so you have to we want these

515
00:28:29,960 --> 00:28:32,210
methods to be specialized in the places

516
00:28:32,210 --> 00:28:34,490
where you are calling them otherwise you

517
00:28:34,490 --> 00:28:36,860
would have one three for each method and

518
00:28:36,860 --> 00:28:38,390
it would get megamorph it very quickly

519
00:28:38,390 --> 00:28:40,340
which means it would not specialize for

520
00:28:40,340 --> 00:28:41,930
any particular case it would be very

521
00:28:41,930 --> 00:28:45,230
generic handling every call every place

522
00:28:45,230 --> 00:28:49,250
where you are calling it and this is

523
00:28:49,250 --> 00:28:51,020
actually part of the traffic framework

524
00:28:51,020 --> 00:28:53,840
so it's not something we write directly

525
00:28:53,840 --> 00:28:55,790
in a tougher Ruby implementation this is

526
00:28:55,790 --> 00:28:57,020
something which is handled in the

527
00:28:57,020 --> 00:29:01,550
truffle framer itself and the second

528
00:29:01,550 --> 00:29:05,919
very important optimization is in lining

529
00:29:09,500 --> 00:29:14,190
so now we have splitted trees which are

530
00:29:14,190 --> 00:29:17,280
optimized for the different places from

531
00:29:17,280 --> 00:29:18,750
which they are called

532
00:29:18,750 --> 00:29:24,570
but if these we had we looked at how the

533
00:29:24,570 --> 00:29:27,630
checks for the shapes are merged for the

534
00:29:27,630 --> 00:29:29,790
access to instance variables so if you

535
00:29:29,790 --> 00:29:32,790
have for example the IAP method and it's

536
00:29:32,790 --> 00:29:35,130
calling with some of the memory access

537
00:29:35,130 --> 00:29:36,480
mode method and then some of the

538
00:29:36,480 --> 00:29:38,760
instructions both of these methods also

539
00:29:38,760 --> 00:29:41,160
have accesses to instance variables on

540
00:29:41,160 --> 00:29:46,740
the same object so but if you but the

541
00:29:46,740 --> 00:29:48,450
methods if they are not in line with

542
00:29:48,450 --> 00:29:49,800
that means that they are part of the

543
00:29:49,800 --> 00:29:51,720
different compilation unit so the

544
00:29:51,720 --> 00:29:54,710
compiler cannot see the checks which are

545
00:29:54,710 --> 00:29:58,260
done in the memory in one of the memory

546
00:29:58,260 --> 00:30:02,220
mode access methods with the checks

547
00:30:02,220 --> 00:30:03,720
which which are in the one of the

548
00:30:03,720 --> 00:30:05,820
instructions so they cannot be matched

549
00:30:05,820 --> 00:30:08,340
together or emanated so for that you

550
00:30:08,340 --> 00:30:12,270
need to inline the methods to to the

551
00:30:12,270 --> 00:30:14,880
caller so you get a bigger computation

552
00:30:14,880 --> 00:30:16,560
you need to be able to eliminate these

553
00:30:16,560 --> 00:30:21,210
checks and guards which is done very

554
00:30:21,210 --> 00:30:24,030
simply by just taking the three for the

555
00:30:24,030 --> 00:30:26,850
right side there was so immediate memory

556
00:30:26,850 --> 00:30:28,830
remote access so you just take the tree

557
00:30:28,830 --> 00:30:30,540
which is representing the body of the

558
00:30:30,540 --> 00:30:32,490
method and you just copy it to the core

559
00:30:32,490 --> 00:30:35,390
and that's it basically

560
00:30:44,700 --> 00:30:47,489
yeah now basically already said that

561
00:30:47,489 --> 00:30:49,590
again this is part of the truffle

562
00:30:49,590 --> 00:30:52,279
framework so it's done in the therefore

563
00:30:52,279 --> 00:30:54,330
framework which means any language

564
00:30:54,330 --> 00:30:56,970
written on top of the truffle framework

565
00:30:56,970 --> 00:31:04,950
will get these optimizations so this

566
00:31:04,950 --> 00:31:06,840
means for example I already mentioned it

567
00:31:06,840 --> 00:31:10,109
if you remember I showed a little bit

568
00:31:10,109 --> 00:31:11,879
how we do the type specifications for

569
00:31:11,879 --> 00:31:13,649
which we have the plasma token fixed

570
00:31:13,649 --> 00:31:16,200
number this is reduced just due to

571
00:31:16,200 --> 00:31:18,179
instructions after compilation after

572
00:31:18,179 --> 00:31:24,179
inlining but also the other consequence

573
00:31:24,179 --> 00:31:27,509
is that we can in line box eliminate the

574
00:31:27,509 --> 00:31:30,539
overhead of have box because books are

575
00:31:30,539 --> 00:31:33,659
very good very important abstractions in

576
00:31:33,659 --> 00:31:37,190
a ruby there are loose used very often

577
00:31:37,190 --> 00:31:39,659
it's it good that we can allow

578
00:31:39,659 --> 00:31:42,149
developers to leave them in the code to

579
00:31:42,149 --> 00:31:43,739
keep the abstractions but actually not

580
00:31:43,739 --> 00:31:47,009
paying the price in performance so for

581
00:31:47,009 --> 00:31:49,739
that we have a look at this we compile

582
00:31:49,739 --> 00:31:52,139
compare these simple methods when the

583
00:31:52,139 --> 00:31:54,359
first one is the one before already seen

584
00:31:54,359 --> 00:31:56,669
just to read from instance variable the

585
00:31:56,669 --> 00:31:58,409
second one does the same thing but it's

586
00:31:58,409 --> 00:32:03,499
just wrapped interrupts in a book so

587
00:32:06,360 --> 00:32:09,460
these are the igv graphs before the

588
00:32:09,460 --> 00:32:12,150
optimization passes for the two methods

589
00:32:12,150 --> 00:32:16,900
and this is after optimizations as you

590
00:32:16,900 --> 00:32:19,330
can see it's the same the overhead of

591
00:32:19,330 --> 00:32:21,220
the block the allocation of the block

592
00:32:21,220 --> 00:32:28,570
everything was eliminated so in

593
00:32:28,570 --> 00:32:31,990
conclusion what makes a forbidden opcode

594
00:32:31,990 --> 00:32:33,669
benchmark nine times faster than MRI

595
00:32:33,669 --> 00:32:36,070
it's not the single optimization several

596
00:32:36,070 --> 00:32:38,289
things and I didn't even cover

597
00:32:38,289 --> 00:32:41,020
everything but just a major one so is

598
00:32:41,020 --> 00:32:43,840
the splitting inlining and the partial

599
00:32:43,840 --> 00:32:45,760
operations which are due to eliminate

600
00:32:45,760 --> 00:32:49,720
the overhead of having the asd

601
00:32:49,720 --> 00:32:52,870
interpreter and a high quality compare I

602
00:32:52,870 --> 00:32:55,149
like growl which allows us to produce

603
00:32:55,149 --> 00:32:58,750
high-quality machine code and of course

604
00:32:58,750 --> 00:33:02,320
we also do some optimization route array

605
00:33:02,320 --> 00:33:04,210
access which I didn't include it to do

606
00:33:04,210 --> 00:33:06,070
into this talk which I because I thought

607
00:33:06,070 --> 00:33:09,159
that I don't have the space so just in a

608
00:33:09,159 --> 00:33:11,350
short we as we are able to specialize

609
00:33:11,350 --> 00:33:14,320
for small integers we are able to

610
00:33:14,320 --> 00:33:17,020
specialize arrays that if we see that

611
00:33:17,020 --> 00:33:19,659
user or some code is storing only

612
00:33:19,659 --> 00:33:21,370
integers small integers into the array

613
00:33:21,370 --> 00:33:23,590
we don't have to allocate the array of

614
00:33:23,590 --> 00:33:27,039
objects we allocate just array of int on

615
00:33:27,039 --> 00:33:29,470
private of primitive values so it's also

616
00:33:29,470 --> 00:33:33,279
gives us some performance benefits I

617
00:33:33,279 --> 00:33:35,080
would like to acknowledge also all of

618
00:33:35,080 --> 00:33:36,730
the people which are working on the girl

619
00:33:36,730 --> 00:33:43,870
tougher and tougher Ruby as I mentioned

620
00:33:43,870 --> 00:33:47,010
this is a research project

621
00:33:47,070 --> 00:33:50,290
and that's it so I thank you for your

622
00:33:50,290 --> 00:33:50,770
attention

623
00:33:50,770 --> 00:33:58,930
[Applause]

624
00:34:22,199 --> 00:34:24,639
yeah the question was if we are able to

625
00:34:24,639 --> 00:34:28,210
use existing tooling for Java and rods

626
00:34:28,210 --> 00:34:33,370
first yes but for example the visual VM

627
00:34:33,370 --> 00:34:35,159
I think there is some ongoing work to

628
00:34:35,159 --> 00:34:38,050
improve it so it won't profile just the

629
00:34:38,050 --> 00:34:41,800
Java parts of the truffle and stuff like

630
00:34:41,800 --> 00:34:43,780
that but it will actually understand a

631
00:34:43,780 --> 00:34:47,949
little bit the languages implemented on

632
00:34:47,949 --> 00:34:49,000
top of the truffle

633
00:34:49,000 --> 00:34:50,530
so you can use it to actually inspect

634
00:34:50,530 --> 00:34:52,810
the languages implemented interfere not

635
00:34:52,810 --> 00:34:56,639
just to Java so yeah and if we also have

636
00:34:56,639 --> 00:34:59,550
debugger which is independent on the

637
00:34:59,550 --> 00:35:02,500
implementation so you can do but the bug

638
00:35:02,500 --> 00:35:05,020
any language written on top of truffle

639
00:35:05,020 --> 00:35:08,170
and because the debugger is independent

640
00:35:08,170 --> 00:35:11,830
and because the engine is particular

641
00:35:11,830 --> 00:35:13,600
which means you can easily call one

642
00:35:13,600 --> 00:35:16,510
language implementing refer to another

643
00:35:16,510 --> 00:35:19,450
language on top of truffle so we can of

644
00:35:19,450 --> 00:35:21,340
course they bug it through calling

645
00:35:21,340 --> 00:35:25,960
different languages in one runtime thank

646
00:35:25,960 --> 00:35:29,610
you any more questions

647
00:35:29,610 --> 00:35:34,770
sure so when you're generating your true

648
00:35:34,770 --> 00:35:38,880
dimensional inline cash what kind of

649
00:35:38,880 --> 00:35:41,520
restrictions are you making on whether

650
00:35:41,520 --> 00:35:43,020
or not you're actually going to generate

651
00:35:43,020 --> 00:35:48,960
specialization there do you just there

652
00:35:48,960 --> 00:35:52,560
is a limit I didn't mention it there is

653
00:35:52,560 --> 00:35:55,650
a indentation there is a sorry I didn't

654
00:35:55,650 --> 00:36:00,150
repeat the question the question was how

655
00:36:00,150 --> 00:36:02,700
do we do if there are any limits in the

656
00:36:02,700 --> 00:36:07,920
two-dimensional cash so it there is a

657
00:36:07,920 --> 00:36:09,960
limit value on the annotation for the

658
00:36:09,960 --> 00:36:12,480
cash and it says how big it can grow

659
00:36:12,480 --> 00:36:15,480
after it's exceeds the limit the whole

660
00:36:15,480 --> 00:36:17,910
cash you can configure it you either can

661
00:36:17,910 --> 00:36:20,220
add a whole cash Joey buy and replace it

662
00:36:20,220 --> 00:36:22,380
with one generic node which always knows

663
00:36:22,380 --> 00:36:25,020
how to call any method or you can keep

664
00:36:25,020 --> 00:36:27,750
the current cash at the bottom up and

665
00:36:27,750 --> 00:36:30,420
the generic node which has lost any

666
00:36:30,420 --> 00:36:45,270
other calls currently you need a JVM

667
00:36:45,270 --> 00:36:52,260
with JME CI API so growl is so you can

668
00:36:52,260 --> 00:36:56,400
use growl there is a built of Java 8 we

669
00:36:56,400 --> 00:36:59,370
did Java 9 will have it when it's

670
00:36:59,370 --> 00:37:01,830
released so it won't be any problem Java

671
00:37:01,830 --> 00:37:05,540
9 but there is also another project

672
00:37:05,540 --> 00:37:10,290
substrate vm which basically ahead of

673
00:37:10,290 --> 00:37:11,880
time pre compiles the whole

674
00:37:11,880 --> 00:37:13,890
implementation of the language including

675
00:37:13,890 --> 00:37:19,770
truffle and ghoul so on one hand you

676
00:37:19,770 --> 00:37:22,290
lose Java part on the other hand because

677
00:37:22,290 --> 00:37:23,280
it's pre-compiled

678
00:37:23,280 --> 00:37:27,330
we get the startup time to around 100

679
00:37:27,330 --> 00:37:29,910
milliseconds which is quite close to MRI

680
00:37:29,910 --> 00:37:32,520
so the hello world is just to 100

681
00:37:32,520 --> 00:37:35,000
milliseconds

682
00:37:36,230 --> 00:37:49,190
follow this were mentioning substrate

683
00:37:49,190 --> 00:37:52,020
because it's ahead of time compiled so

684
00:37:52,020 --> 00:37:55,170
during that time it analyzes all of the

685
00:37:55,170 --> 00:37:57,140
parts which are used from the Java

686
00:37:57,140 --> 00:37:59,970
standard library and it compiles ahead

687
00:37:59,970 --> 00:38:02,510
of time only the parts which are used

688
00:38:02,510 --> 00:38:05,790
and during the time also takes as

689
00:38:05,790 --> 00:38:09,300
certain assumptions that it can do it

690
00:38:09,300 --> 00:38:10,920
does a global analysis so it can see

691
00:38:10,920 --> 00:38:13,590
okay this method with with this name was

692
00:38:13,590 --> 00:38:15,690
called is always called on this

693
00:38:15,690 --> 00:38:18,720
particular receiver and because it's

694
00:38:18,720 --> 00:38:20,940
called ahead of time you cannot go back

695
00:38:20,940 --> 00:38:23,400
from this assumption so we have to

696
00:38:23,400 --> 00:38:25,800
forbid cross loading loading and other

697
00:38:25,800 --> 00:38:27,390
Java classes which could break this

698
00:38:27,390 --> 00:38:30,000
assumption so for example for on a

699
00:38:30,000 --> 00:38:32,040
substrate VM you cannot load the new

700
00:38:32,040 --> 00:38:35,430
Java classes because of this why it's

701
00:38:35,430 --> 00:38:39,120
not entirely true because there might be

702
00:38:39,120 --> 00:38:42,000
also a Java on shuffle and then it will

703
00:38:42,000 --> 00:38:51,270
be able yeah all right it's a different

704
00:38:51,270 --> 00:38:54,800
VM so it has different GC

705
00:38:56,970 --> 00:39:00,120
other questions

706
00:39:00,120 --> 00:39:01,890
thank you Peter thank you

707
00:39:01,890 --> 00:39:08,839
[Applause]

