1
00:00:00,000 --> 00:00:03,650
okay Stephen something who the

2
00:00:04,540 --> 00:00:09,029
to us abundant infrastructure monitoring

3
00:00:10,290 --> 00:00:15,070
excellent thank you very much so a lot

4
00:00:15,070 --> 00:00:16,810
of you probably don't know me as it's

5
00:00:16,810 --> 00:00:18,490
been pointed out though the last couple

6
00:00:18,490 --> 00:00:20,470
of days some haven't been particularly

7
00:00:20,470 --> 00:00:22,210
active in the post press community but

8
00:00:22,210 --> 00:00:25,840
looking to change that so this talks

9
00:00:25,840 --> 00:00:28,059
kind of be a bit of a mix of everything

10
00:00:28,059 --> 00:00:29,980
it's going to be it's nobody going to

11
00:00:29,980 --> 00:00:32,079
delve into the details of post post very

12
00:00:32,079 --> 00:00:34,660
much but more how we'd build something

13
00:00:34,660 --> 00:00:37,960
on top of post grads so I think it

14
00:00:37,960 --> 00:00:39,580
should appeal to people at most levels

15
00:00:39,580 --> 00:00:41,590
with post press so we can talk about

16
00:00:41,590 --> 00:00:43,000
monitoring so I'll give you a bit quick

17
00:00:43,000 --> 00:00:44,950
background on specifically what I'm

18
00:00:44,950 --> 00:00:48,640
trying to do then we'll go in depth a

19
00:00:48,640 --> 00:00:51,300
bit on how to use post codes for metrics

20
00:00:51,300 --> 00:00:57,880
and there's no section on using post

21
00:00:57,880 --> 00:00:59,530
players for a few other things which you

22
00:00:59,530 --> 00:01:03,900
might not ordinarily think to use it for

23
00:01:06,490 --> 00:01:08,869
so I'm actually a software developer I'm

24
00:01:08,869 --> 00:01:11,630
not a DBA so I apologize if my SQL and

25
00:01:11,630 --> 00:01:15,140
my procedures are a bit bit shaky I'll

26
00:01:15,140 --> 00:01:18,409
do my best so I don't know do C and C++

27
00:01:18,409 --> 00:01:20,720
and Python that kind of things also

28
00:01:20,720 --> 00:01:22,790
dabbled with Perl in the past but kind

29
00:01:22,790 --> 00:01:26,600
of learnt better after a while usually

30
00:01:26,600 --> 00:01:27,500
systems-level

31
00:01:27,500 --> 00:01:30,350
kind of things and based in Bristol of

32
00:01:30,350 --> 00:01:32,899
the UK which I don't think I've met

33
00:01:32,899 --> 00:01:35,330
anyone else from Bristol it's primarily

34
00:01:35,330 --> 00:01:38,380
famous for this bridge quite pretty

35
00:01:38,380 --> 00:01:42,350
probably more famous for its cider so if

36
00:01:42,350 --> 00:01:44,450
you ever go to Bristol you'll see and

37
00:01:44,450 --> 00:01:47,450
pretty much every pub more varieties of

38
00:01:47,450 --> 00:01:49,490
cider than you can ever imagine I'll

39
00:01:49,490 --> 00:01:51,140
tell you things many places else in the

40
00:01:51,140 --> 00:01:54,530
world would you like that plan so I've

41
00:01:54,530 --> 00:01:57,890
done a few bizarre things I wrote for a

42
00:01:57,890 --> 00:02:01,070
couple of startups one building 10

43
00:02:01,070 --> 00:02:04,340
Gigabit Ethernet switches and then kind

44
00:02:04,340 --> 00:02:06,500
of thought hmm maybe I'll do something

45
00:02:06,500 --> 00:02:07,220
completely different

46
00:02:07,220 --> 00:02:09,380
work for a database vendor for quite a

47
00:02:09,380 --> 00:02:12,620
long time based on postage crop so spend

48
00:02:12,620 --> 00:02:15,739
her five years working with post Reds

49
00:02:15,739 --> 00:02:19,850
but not on post players specifically and

50
00:02:19,850 --> 00:02:21,230
that database was sort of geared towards

51
00:02:21,230 --> 00:02:25,610
big data analytics that sort of thing

52
00:02:25,610 --> 00:02:27,829
all the buzz words you can think of we

53
00:02:27,829 --> 00:02:30,980
had them so I now work for a company

54
00:02:30,980 --> 00:02:34,100
called spec HPC and we're consultancy

55
00:02:34,100 --> 00:02:38,630
for HPC on OpenStack we primarily deal

56
00:02:38,630 --> 00:02:42,560
with complex kind of infrastructure and

57
00:02:42,560 --> 00:02:44,200
this is kind of why this talk came from

58
00:02:44,200 --> 00:02:48,220
because you can't need to monitor it

59
00:02:48,400 --> 00:02:49,989
I'll give you a quick background on

60
00:02:49,989 --> 00:02:53,459
OpenStack because there is a booth over

61
00:02:53,459 --> 00:02:57,220
in building K and some guys you can go

62
00:02:57,220 --> 00:02:59,970
talk to about it if you like but it's a

63
00:02:59,970 --> 00:03:02,560
the buzzword kind of title for it is

64
00:03:02,560 --> 00:03:05,410
cloud orchestration platform but what it

65
00:03:05,410 --> 00:03:09,190
really is is it's a bit like AWS but you

66
00:03:09,190 --> 00:03:11,140
can do it yourself that's probably the

67
00:03:11,140 --> 00:03:13,420
shortest way to put it and can talk to

68
00:03:13,420 --> 00:03:14,620
you more about that later if you want to

69
00:03:14,620 --> 00:03:17,440
come and find me the thing that sucks is

70
00:03:17,440 --> 00:03:19,930
like complicated so I like to think of

71
00:03:19,930 --> 00:03:22,660
it as a complex distributed application

72
00:03:22,660 --> 00:03:24,940
to run your complex distributed

73
00:03:24,940 --> 00:03:29,709
applications so it's quite subjective I

74
00:03:29,709 --> 00:03:31,870
think you hear differing opinions on it

75
00:03:31,870 --> 00:03:34,060
it's a very useful tool and it's gained

76
00:03:34,060 --> 00:03:35,980
quite a lot of traction in the past few

77
00:03:35,980 --> 00:03:39,250
years so operational visibility of this

78
00:03:39,250 --> 00:03:41,590
is critical because there's a lot of

79
00:03:41,590 --> 00:03:44,560
things to go wrong and you need to make

80
00:03:44,560 --> 00:03:47,049
sure that you notice when it does go

81
00:03:47,049 --> 00:03:52,470
wrong so monitoring

82
00:03:53,190 --> 00:03:54,510
and the context we're thinking of

83
00:03:54,510 --> 00:03:56,910
monitoring is this kind of thing so

84
00:03:56,910 --> 00:03:59,460
you've got a load of servers got a

85
00:03:59,460 --> 00:04:03,990
website even database make PostgreSQL by

86
00:04:03,990 --> 00:04:05,430
the way everything in this talk you

87
00:04:05,430 --> 00:04:07,530
could apply to using postcode well to

88
00:04:07,530 --> 00:04:10,410
monitor PostgreSQL that's fine fact I

89
00:04:10,410 --> 00:04:13,080
think you should be encouraged say it

90
00:04:13,080 --> 00:04:14,640
could be a cluster of systems could be

91
00:04:14,640 --> 00:04:17,640
disk drive anything and we do all these

92
00:04:17,640 --> 00:04:20,339
graphs and we make alerts and it emails

93
00:04:20,339 --> 00:04:23,520
us when it all goes horribly wrong and

94
00:04:23,520 --> 00:04:24,750
generally this tends to be quite

95
00:04:24,750 --> 00:04:25,520
different

96
00:04:25,520 --> 00:04:27,450
yeah I'm for everyone that's the very

97
00:04:27,450 --> 00:04:30,900
idea of what they want from a system a

98
00:04:30,900 --> 00:04:32,970
few things that we kind of think are

99
00:04:32,970 --> 00:04:37,020
quite important folk finding an alerting

100
00:04:37,020 --> 00:04:39,900
so you need to be told when something

101
00:04:39,900 --> 00:04:42,060
breaks when something goes down when you

102
00:04:42,060 --> 00:04:44,870
need to replace a disk

103
00:04:45,940 --> 00:04:50,080
full post-mortem and preemption so once

104
00:04:50,080 --> 00:04:51,850
something's gone wrong you want to

105
00:04:51,850 --> 00:04:54,240
prevent that from happening again and

106
00:04:54,240 --> 00:04:56,380
ideally you want as much information as

107
00:04:56,380 --> 00:04:57,820
you possibly can about everything that

108
00:04:57,820 --> 00:05:00,550
was going on around the fault so you can

109
00:05:00,550 --> 00:05:02,320
work out what caused it and make sure it

110
00:05:02,320 --> 00:05:08,470
doesn't happen next time you can also

111
00:05:08,470 --> 00:05:12,700
use a monitoring to measure utilization

112
00:05:12,700 --> 00:05:14,800
and efficiency of your infrastructure

113
00:05:14,800 --> 00:05:17,350
it's kind of amazing how many people if

114
00:05:17,350 --> 00:05:19,420
you ask them if they've got a huge

115
00:05:19,420 --> 00:05:20,680
cluster of servers they spent you know

116
00:05:20,680 --> 00:05:22,570
tens of millions on these servers it's

117
00:05:22,570 --> 00:05:23,650
quite often they don't really know how

118
00:05:23,650 --> 00:05:26,770
much it's being used and in my area only

119
00:05:26,770 --> 00:05:29,980
being used for a few days a week or a

120
00:05:29,980 --> 00:05:32,620
few hours of a day and it's just sat

121
00:05:32,620 --> 00:05:33,940
there wasting electricity the rest of

122
00:05:33,940 --> 00:05:35,860
the time and as soon as you kind of

123
00:05:35,860 --> 00:05:36,940
graph these things it becomes

124
00:05:36,940 --> 00:05:40,690
immediately clear and you can even take

125
00:05:40,690 --> 00:05:42,430
it a step further and use some of these

126
00:05:42,430 --> 00:05:44,520
techniques for performance monitoring

127
00:05:44,520 --> 00:05:48,790
and profiling so how fast my database

128
00:05:48,790 --> 00:05:50,650
requests how fast in my web requests

129
00:05:50,650 --> 00:05:52,720
good example of this in Postgres would

130
00:05:52,720 --> 00:05:55,390
be with statement logging so you could

131
00:05:55,390 --> 00:05:58,600
actually monitor the latency of all your

132
00:05:58,600 --> 00:06:00,840
database requesters

133
00:06:00,840 --> 00:06:03,970
and this kind of go you can taste a

134
00:06:03,970 --> 00:06:05,260
little bit further and go into the

135
00:06:05,260 --> 00:06:07,440
realms of application profiling as well

136
00:06:07,440 --> 00:06:11,110
and start tracking things like HTTP

137
00:06:11,110 --> 00:06:13,620
requests and in OpenStack specifically

138
00:06:13,620 --> 00:06:17,260
every OpenStack API request is linked

139
00:06:17,260 --> 00:06:19,990
with a unique request identifier so you

140
00:06:19,990 --> 00:06:22,300
can actually trace all of the HTTP

141
00:06:22,300 --> 00:06:25,860
requests they have around the system

142
00:06:28,810 --> 00:06:31,810
on in a sort of different direction you

143
00:06:31,810 --> 00:06:35,290
can also use it for auditing security so

144
00:06:35,290 --> 00:06:36,880
especially kind of things like tracking

145
00:06:36,880 --> 00:06:39,910
log files or tracking Network requests

146
00:06:39,910 --> 00:06:42,460
or SSH logins things like that

147
00:06:42,460 --> 00:06:43,930
that's all things that we kinda want to

148
00:06:43,930 --> 00:06:48,389
do and at a very high level of not even

149
00:06:48,389 --> 00:06:50,500
decision-making so planning what your

150
00:06:50,500 --> 00:06:52,180
next system is going to look like based

151
00:06:52,180 --> 00:06:55,990
on how much your old system is being

152
00:06:55,990 --> 00:06:57,669
used how well it worked or how well it

153
00:06:57,669 --> 00:07:01,750
didn't work it's kind of the managers

154
00:07:01,750 --> 00:07:04,060
dashboard dollars per hour that kind of

155
00:07:04,060 --> 00:07:08,350
thing so go look do a little bit of

156
00:07:08,350 --> 00:07:09,970
background on existing tools you might

157
00:07:09,970 --> 00:07:11,890
kind of use for this sort of thing and

158
00:07:11,890 --> 00:07:14,260
the first one category of tool may be

159
00:07:14,260 --> 00:07:16,000
worth pointing out I mostly work with

160
00:07:16,000 --> 00:07:18,490
open source software don't tend to buy a

161
00:07:18,490 --> 00:07:19,870
lot of proprietary software so I'm sure

162
00:07:19,870 --> 00:07:20,830
there are plenty of proprietary

163
00:07:20,830 --> 00:07:22,450
monitoring tools which I don't know

164
00:07:22,450 --> 00:07:23,830
about and we'll never mention this talk

165
00:07:23,830 --> 00:07:25,540
so I'm sorry if one of them happens to

166
00:07:25,540 --> 00:07:28,060
be your favorite but in the open source

167
00:07:28,060 --> 00:07:30,850
world one category of tools you tend to

168
00:07:30,850 --> 00:07:32,950
find are ones that do checking for you

169
00:07:32,950 --> 00:07:35,169
so they'll ping machines make sure

170
00:07:35,169 --> 00:07:37,690
they're up make sure that your web

171
00:07:37,690 --> 00:07:44,140
server is servicing requests and these

172
00:07:44,140 --> 00:07:47,370
systems usually give you a dashboard and

173
00:07:47,370 --> 00:07:49,660
they're quite often store history of the

174
00:07:49,660 --> 00:07:52,159
events as well

175
00:07:52,159 --> 00:07:55,099
and a classic example of this is Nagios

176
00:07:55,099 --> 00:07:57,499
or i ginger or someone told me the other

177
00:07:57,499 --> 00:07:58,999
day there's there's another fork as well

178
00:07:58,999 --> 00:08:00,889
with it they've got a whole category of

179
00:08:00,889 --> 00:08:03,889
things and quite like a lot of people

180
00:08:03,889 --> 00:08:05,749
tend to write their own as well

181
00:08:05,749 --> 00:08:10,489
bash scripts like this seems Lensky off

182
00:08:10,489 --> 00:08:13,009
as well and and sometimes that's all you

183
00:08:13,009 --> 00:08:14,259
need at least you know it kind of works

184
00:08:14,259 --> 00:08:20,019
the issue with these kind of systems is

185
00:08:20,019 --> 00:08:21,860
it will tell you when something goes

186
00:08:21,860 --> 00:08:23,899
wrong but it won't tell you why esse

187
00:08:23,899 --> 00:08:26,539
Sara Lee got it's gone wrong what you

188
00:08:26,539 --> 00:08:28,249
really want to know is all the

189
00:08:28,249 --> 00:08:29,659
information about what happened around

190
00:08:29,659 --> 00:08:33,919
that kind of event so post-mortem

191
00:08:33,919 --> 00:08:36,490
analysis is usually the only option

192
00:08:36,490 --> 00:08:39,919
digging around the system was in a state

193
00:08:39,919 --> 00:08:42,139
at the time it went wrong it died I'm

194
00:08:42,139 --> 00:08:43,818
fortunate now we started and it's in a

195
00:08:43,818 --> 00:08:45,709
fresh new state and you've kind of got a

196
00:08:45,709 --> 00:08:48,410
trace your trace back to try and work

197
00:08:48,410 --> 00:08:52,370
out what happened so something else

198
00:08:52,370 --> 00:08:53,810
that's kind of gaining popularity at the

199
00:08:53,810 --> 00:08:57,790
moment probably aware of this cabaña

200
00:08:57,790 --> 00:08:59,600
elasticsearch and logstash

201
00:08:59,600 --> 00:09:02,360
done a great job of advertising this is

202
00:09:02,360 --> 00:09:05,509
the elk stack and this is just this is a

203
00:09:05,509 --> 00:09:07,430
way of centralizing all your log files

204
00:09:07,430 --> 00:09:11,360
together which is hugely useful I mean

205
00:09:11,360 --> 00:09:12,680
this is kind of the this seems to be

206
00:09:12,680 --> 00:09:15,350
what people like using at the moment but

207
00:09:15,350 --> 00:09:18,199
for a long time our system or the

208
00:09:18,199 --> 00:09:20,779
systems before that were very capable of

209
00:09:20,779 --> 00:09:22,550
stop shipping all of your logs to a

210
00:09:22,550 --> 00:09:24,199
central server and grepping it however

211
00:09:24,199 --> 00:09:26,569
way you like but these systems quite

212
00:09:26,569 --> 00:09:29,180
useful unless you do kind of full-text

213
00:09:29,180 --> 00:09:32,149
searching on your log files and see

214
00:09:32,149 --> 00:09:33,800
where your connections happen and how

215
00:09:33,800 --> 00:09:36,860
often your log messages are firing so if

216
00:09:36,860 --> 00:09:39,410
you see this big peak in errors at some

217
00:09:39,410 --> 00:09:40,490
point in the middle of the night then

218
00:09:40,490 --> 00:09:42,709
maybe a batch jobs gone crazy or

219
00:09:42,709 --> 00:09:46,069
something like that the LOB stash

220
00:09:46,069 --> 00:09:48,040
component of it is useful for

221
00:09:48,040 --> 00:09:50,240
transforming your data so if you've got

222
00:09:50,240 --> 00:09:51,800
your web request classic example is

223
00:09:51,800 --> 00:09:53,509
you've got web requests you've got the

224
00:09:53,509 --> 00:09:55,699
IP address and you use log stash has a

225
00:09:55,699 --> 00:09:59,000
plug-in to determine the geolocation of

226
00:09:59,000 --> 00:10:01,069
that request based on the IP and then

227
00:10:01,069 --> 00:10:03,139
people draw pretty graphs of the world

228
00:10:03,139 --> 00:10:05,150
and they find most of their users of

229
00:10:05,150 --> 00:10:06,890
North America because the most people

230
00:10:06,890 --> 00:10:15,050
are in that say the next kind of set of

231
00:10:15,050 --> 00:10:17,890
systems are these metrics based systems

232
00:10:17,890 --> 00:10:21,770
so we collect metrics like CPU

233
00:10:21,770 --> 00:10:24,580
percentage or disk space favorite time

234
00:10:24,580 --> 00:10:26,900
and what these lets do is these let us

235
00:10:26,900 --> 00:10:28,370
get some insight into what happened

236
00:10:28,370 --> 00:10:30,470
before your system fell out though the

237
00:10:30,470 --> 00:10:33,530
system falls over and just before it

238
00:10:33,530 --> 00:10:36,500
fell over disk space was rising that's a

239
00:10:36,500 --> 00:10:38,240
good sign light of what might have gone

240
00:10:38,240 --> 00:10:40,790
wrong there or memory rising slowly and

241
00:10:40,790 --> 00:10:45,350
things like that so these are becoming

242
00:10:45,350 --> 00:10:47,750
very popular very very very popular as

243
00:10:47,750 --> 00:10:51,290
you'll see in a minute the the tool for

244
00:10:51,290 --> 00:10:53,750
this in at least HPC world and a lot of

245
00:10:53,750 --> 00:10:55,400
other world has been ganglia and this

246
00:10:55,400 --> 00:10:56,870
kind of gives you these these nice

247
00:10:56,870 --> 00:11:00,200
little graphs and it usually comprises

248
00:11:00,200 --> 00:11:01,790
of a collector component that runs on

249
00:11:01,790 --> 00:11:04,010
all your servers we've a database and

250
00:11:04,010 --> 00:11:05,660
then aggregator which gives your

251
00:11:05,660 --> 00:11:06,770
front-end and pulls all the data

252
00:11:06,770 --> 00:11:09,320
together so you get grass like CPU sends

253
00:11:09,320 --> 00:11:12,320
you over my entire cluster and this

254
00:11:12,320 --> 00:11:15,650
one's actually we could Wikipedia's so

255
00:11:15,650 --> 00:11:17,120
you can actually go there and look at

256
00:11:17,120 --> 00:11:20,210
all of wikimedia server stats which i

257
00:11:20,210 --> 00:11:22,100
great fun with the other day just on

258
00:11:22,100 --> 00:11:24,020
digging around seeing off what's going

259
00:11:24,020 --> 00:11:27,230
on there although as i checked it

260
00:11:27,230 --> 00:11:29,210
yesterday so I rate this slide quite a

261
00:11:29,210 --> 00:11:31,040
few weeks ago I checked it yesterday and

262
00:11:31,040 --> 00:11:32,480
a big banner comes across the top saying

263
00:11:32,480 --> 00:11:35,720
gangly was deprecated so think of that

264
00:11:35,720 --> 00:11:37,790
what you will and the thing that they

265
00:11:37,790 --> 00:11:40,250
link you to is actually I interesting

266
00:11:40,250 --> 00:11:41,570
the next thing on my slide next thing

267
00:11:41,570 --> 00:11:45,590
next slide and that's good father

268
00:11:45,590 --> 00:11:48,500
so this is kind of I guess you could say

269
00:11:48,500 --> 00:11:51,410
this is like the hipsters kind of tool

270
00:11:51,410 --> 00:11:53,510
of choice it's actually a really good

271
00:11:53,510 --> 00:11:57,410
tool I like it a lot it's very web 4.0

272
00:11:57,410 --> 00:11:59,840
or whatever app now very cliquey and

273
00:11:59,840 --> 00:12:02,180
draggy and really it's quite nice to use

274
00:12:02,180 --> 00:12:04,610
I don't meet a dog on it too much but it

275
00:12:04,610 --> 00:12:06,740
does look very hip Street thing we don't

276
00:12:06,740 --> 00:12:10,370
have that people and this that's the

277
00:12:10,370 --> 00:12:11,900
same thing isn't jaws class for you

278
00:12:11,900 --> 00:12:15,400
CPU usage queue depth whatever you like

279
00:12:15,400 --> 00:12:19,250
but this is only front-end this doesn't

280
00:12:19,250 --> 00:12:21,860
actually store any data for you and it

281
00:12:21,860 --> 00:12:24,500
doesn't collect any data for you any

282
00:12:24,500 --> 00:12:27,589
drawers brass it connects to a service

283
00:12:27,589 --> 00:12:30,850
which gives the numbers back to it

284
00:12:30,850 --> 00:12:34,040
and this is kind of what is interesting

285
00:12:34,040 --> 00:12:38,300
you know there's a lot of choice of what

286
00:12:38,300 --> 00:12:41,839
you can use for this and I've listed I

287
00:12:41,839 --> 00:12:44,630
think about 20 there of time-series

288
00:12:44,630 --> 00:12:47,720
metrics databases and there's more I

289
00:12:47,720 --> 00:12:51,560
haven't listed here and they're not

290
00:12:51,560 --> 00:12:54,650
insignificant projects either notice at

291
00:12:54,650 --> 00:12:55,670
the bottom there is one that actually

292
00:12:55,670 --> 00:12:59,680
uses PostgreSQL to store its er data

293
00:12:59,680 --> 00:13:04,610
which I thought was worth mentioning so

294
00:13:04,610 --> 00:13:06,560
that kind of makes the rest of us talk

295
00:13:06,560 --> 00:13:08,240
slightly invalid but well Carol anyway

296
00:13:08,240 --> 00:13:11,230
seeing as I've already written

297
00:13:11,350 --> 00:13:13,210
so interesting thing about all of these

298
00:13:13,210 --> 00:13:15,340
date places they're not insignificant

299
00:13:15,340 --> 00:13:18,970
projects so a lot going to have backing

300
00:13:18,970 --> 00:13:21,310
from quite well-known companies or quite

301
00:13:21,310 --> 00:13:23,380
significant companies some of them work

302
00:13:23,380 --> 00:13:29,380
for companies some of them built by

303
00:13:29,380 --> 00:13:31,570
people something some of them are built

304
00:13:31,570 --> 00:13:34,720
by companies with you know investment

305
00:13:34,720 --> 00:13:37,480
funding they're trying to make a startup

306
00:13:37,480 --> 00:13:38,470
companies they've got money behind

307
00:13:38,470 --> 00:13:42,850
getting funding so I kind of thought

308
00:13:42,850 --> 00:13:46,000
well when did all this start sure some

309
00:13:46,000 --> 00:13:47,170
of you kind of might see where this is

310
00:13:47,170 --> 00:13:50,529
going but so I drew this kind of chart

311
00:13:50,529 --> 00:13:53,200
of when all these databases started

312
00:13:53,200 --> 00:13:55,180
appearing and have in the world and

313
00:13:55,180 --> 00:13:56,200
their mind these are any open source

314
00:13:56,200 --> 00:13:57,640
ones as well because I'm that's kind of

315
00:13:57,640 --> 00:14:01,300
fulfill them primarily it so look in

316
00:14:01,300 --> 00:14:03,460
2000 gangly has been around a long time

317
00:14:03,460 --> 00:14:05,380
being able to draw your glass for a long

318
00:14:05,380 --> 00:14:10,500
time originally started in 2000 from

319
00:14:10,500 --> 00:14:14,200
University of California I think and

320
00:14:14,200 --> 00:14:17,350
then some graphite arrived in 2010 which

321
00:14:17,350 --> 00:14:19,120
is kind of a bit of a plate with sort of

322
00:14:19,120 --> 00:14:20,890
a placement for the internals of ganglia

323
00:14:20,890 --> 00:14:23,290
because some people thought our detour

324
00:14:23,290 --> 00:14:24,630
was getting a bit long in the tooth or

325
00:14:24,630 --> 00:14:27,430
maybe they just wanted something fun to

326
00:14:27,430 --> 00:14:31,900
do and then proving 2013 2:15 timeframe

327
00:14:31,900 --> 00:14:35,140
just an explosion of project doing this

328
00:14:35,140 --> 00:14:39,150
time series monitoring kind of stuff

329
00:14:39,150 --> 00:14:41,260
which is it's kind of interesting when

330
00:14:41,260 --> 00:14:45,430
we think about no sequel as we think

331
00:14:45,430 --> 00:14:47,770
about the document stores

332
00:14:47,770 --> 00:14:49,480
and things like that but it seems like

333
00:14:49,480 --> 00:14:50,920
time series has also been quite a big

334
00:14:50,920 --> 00:14:55,300
component of this became trendy again as

335
00:14:55,300 --> 00:14:56,440
even I think a new one that was

336
00:14:56,440 --> 00:14:59,230
announced just last year 2016 more at

337
00:14:59,230 --> 00:15:04,570
the bottom there so the system can talk

338
00:15:04,570 --> 00:15:07,330
now about the system where I'm working

339
00:15:07,330 --> 00:15:09,580
on and this system is geared around

340
00:15:09,580 --> 00:15:13,000
OpenStack but it kind of encompasses

341
00:15:13,000 --> 00:15:16,180
what a lot of people are building for

342
00:15:16,180 --> 00:15:17,710
their monitoring infrastructure now they

343
00:15:17,710 --> 00:15:19,330
want the alerting they want metrics they

344
00:15:19,330 --> 00:15:20,890
want logs this is all information we

345
00:15:20,890 --> 00:15:22,570
want we want it sensual we want it

346
00:15:22,570 --> 00:15:26,320
pretty so we start off with our servers

347
00:15:26,320 --> 00:15:29,200
our software storage network all of our

348
00:15:29,200 --> 00:15:31,390
bits that we want to monitor and we've

349
00:15:31,390 --> 00:15:33,400
got all these metrics and all these logs

350
00:15:33,400 --> 00:15:36,460
coming out of all of this we need to

351
00:15:36,460 --> 00:15:39,670
store it and present it in some way so

352
00:15:39,670 --> 00:15:41,560
the project that we're working on in the

353
00:15:41,560 --> 00:15:45,190
OpenStack world is called Nazca and it's

354
00:15:45,190 --> 00:15:48,340
a set of api's for letting you consume

355
00:15:48,340 --> 00:15:52,600
metrics and access metrics it has any

356
00:15:52,600 --> 00:15:54,070
kind of integrates with OpenStack and

357
00:15:54,070 --> 00:15:55,600
all the multi-tenancy the OpenStack

358
00:15:55,600 --> 00:15:57,430
gives you so each tenant has its own set

359
00:15:57,430 --> 00:15:59,080
of metrics its own set of logs and all

360
00:15:59,080 --> 00:16:00,060
this kind of stuff

361
00:16:00,060 --> 00:16:02,080
so it's quite nice there's actually

362
00:16:02,080 --> 00:16:04,660
quite nice system as you find out is

363
00:16:04,660 --> 00:16:06,920
there's a lot to it

364
00:16:06,920 --> 00:16:10,160
so the first bit of it it has a my

365
00:16:10,160 --> 00:16:12,799
sequel database to store configuration

366
00:16:12,799 --> 00:16:14,989
and alerts and things I like most of

367
00:16:14,989 --> 00:16:17,089
OpenStack big there's a database behind

368
00:16:17,089 --> 00:16:21,499
a lot of the components so then has a

369
00:16:21,499 --> 00:16:23,480
time series database of some sort for

370
00:16:23,480 --> 00:16:26,089
the metrics the common one the popular

371
00:16:26,089 --> 00:16:27,529
one is in flux DB at the moment

372
00:16:27,529 --> 00:16:28,910
it also supports a few other ones I

373
00:16:28,910 --> 00:16:31,129
think sports Cassandra they tried

374
00:16:31,129 --> 00:16:32,839
supporting Cassandra and there's a

375
00:16:32,839 --> 00:16:37,369
vertical back-end things like that then

376
00:16:37,369 --> 00:16:39,980
that feeds graph owner which has its own

377
00:16:39,980 --> 00:16:43,779
internal sequel like database

378
00:16:44,169 --> 00:16:46,429
it stores dashboards and things like

379
00:16:46,429 --> 00:16:50,600
that the logs are all stored in elastic

380
00:16:50,600 --> 00:16:55,609
via log stash and Cabana sits at the

381
00:16:55,609 --> 00:17:01,160
front UI for that then someone put

382
00:17:01,160 --> 00:17:04,760
caf-co in the middle because we need to

383
00:17:04,760 --> 00:17:06,769
handle peak loads so when you need a

384
00:17:06,769 --> 00:17:08,659
queue for that so everything goes to

385
00:17:08,659 --> 00:17:11,119
Cayuga goes through logs - back into

386
00:17:11,119 --> 00:17:17,059
Kafka into elastic Rana - in fact DB and

387
00:17:17,059 --> 00:17:19,490
of course because you've got caf-co and

388
00:17:19,490 --> 00:17:21,289
elastic in there you need a zookeeper as

389
00:17:21,289 --> 00:17:25,638
well another three nodes for that and so

390
00:17:25,638 --> 00:17:26,659
you can kind of see where I'm going with

391
00:17:26,659 --> 00:17:26,869
this

392
00:17:26,869 --> 00:17:31,340
about six persistent data stores to

393
00:17:31,340 --> 00:17:34,480
monitor your infrastructure

394
00:17:34,480 --> 00:17:36,490
and this is kind of quite common system

395
00:17:36,490 --> 00:17:38,590
people you know people a lot of people

396
00:17:38,590 --> 00:17:41,769
are doing this outside of OpenStack the

397
00:17:41,769 --> 00:17:43,240
nasty project really kind of encompasses

398
00:17:43,240 --> 00:17:46,539
there what people want to use at the

399
00:17:46,539 --> 00:17:53,019
moment so I mean having this many

400
00:17:53,019 --> 00:17:55,779
databases each with their own H a boat

401
00:17:55,779 --> 00:17:57,340
calls each with their own quirks

402
00:17:57,340 --> 00:18:01,360
persistence layers each of them you have

403
00:18:01,360 --> 00:18:05,139
to back up if you're doing you're doing

404
00:18:05,139 --> 00:18:08,740
it properly and it comes a lot of a yeah

405
00:18:08,740 --> 00:18:13,299
not a lot of overhead there yeah and so

406
00:18:13,299 --> 00:18:14,769
it's a commendable right tool for the

407
00:18:14,769 --> 00:18:18,610
job attitude but why why not post post

408
00:18:18,610 --> 00:18:22,990
post mr. store data so if we we just

409
00:18:22,990 --> 00:18:25,299
used Postgres to have fewer points of

410
00:18:25,299 --> 00:18:27,519
failure fewer places to back up here

411
00:18:27,519 --> 00:18:30,460
with undersea protocols more consistent

412
00:18:30,460 --> 00:18:33,880
set of data semantics and you can reuse

413
00:18:33,880 --> 00:18:37,419
your existing knowledge of Postgres as

414
00:18:37,419 --> 00:18:41,440
well so it seems like a good idea so if

415
00:18:41,440 --> 00:18:43,510
we look at these components again well

416
00:18:43,510 --> 00:18:45,669
and it turns out the Nazca team have

417
00:18:45,669 --> 00:18:48,610
already ported this to Postgres so you

418
00:18:48,610 --> 00:18:50,260
can already use a post business back

419
00:18:50,260 --> 00:18:51,639
into this as we have a lot of OpenStack

420
00:18:51,639 --> 00:18:53,380
you can use post base with it

421
00:18:53,380 --> 00:18:56,110
I'm good father actually was a support

422
00:18:56,110 --> 00:18:58,690
page press which is nice and my sequel

423
00:18:58,690 --> 00:19:02,010
but we don't care about that

424
00:19:02,330 --> 00:19:05,300
why not replace the time series database

425
00:19:05,300 --> 00:19:07,520
replacement Oh stress can do time series

426
00:19:07,520 --> 00:19:09,350
the relational database it's not a new

427
00:19:09,350 --> 00:19:11,530
concept

428
00:19:12,090 --> 00:19:13,680
why don't put the logs in there as well

429
00:19:13,680 --> 00:19:17,970
we've got full-text search we lose

430
00:19:17,970 --> 00:19:18,420
Cabana

431
00:19:18,420 --> 00:19:19,920
because Cabana an elastic search quite

432
00:19:19,920 --> 00:19:22,080
tightly coupled but the father is able

433
00:19:22,080 --> 00:19:27,240
to display lobs quite nicely if we don't

434
00:19:27,240 --> 00:19:30,600
have a huge system there's a possibility

435
00:19:30,600 --> 00:19:32,400
we could just shove the data into post

436
00:19:32,400 --> 00:19:35,490
prism as fast as we can without doing

437
00:19:35,490 --> 00:19:37,020
any of the processing and use that those

438
00:19:37,020 --> 00:19:41,910
are offering mechanism and don't need

439
00:19:41,910 --> 00:19:46,340
that no elastic no Kafka

440
00:19:46,490 --> 00:19:49,130
I'm over there why don't we use most

441
00:19:49,130 --> 00:19:51,740
British text mechanism to get rid of

442
00:19:51,740 --> 00:19:54,010
that as well

443
00:19:54,040 --> 00:20:01,280
satisfy isn't it so some of that you're

444
00:20:01,280 --> 00:20:02,630
probably thinking or some of that's a

445
00:20:02,630 --> 00:20:05,320
bit of a push and you're right

446
00:20:05,320 --> 00:20:09,260
so the something that sort of go a bit

447
00:20:09,260 --> 00:20:13,070
deeper now into the metrics part because

448
00:20:13,070 --> 00:20:14,030
that seems to be what people are most

449
00:20:14,030 --> 00:20:17,090
interested in the moment so how would we

450
00:20:17,090 --> 00:20:19,160
store our metrics and post grades so

451
00:20:19,160 --> 00:20:21,740
system we volumes quite modest it's an

452
00:20:21,740 --> 00:20:25,010
eighteen node cluster we take 200 ish

453
00:20:25,010 --> 00:20:29,450
metrics every 30 seconds so quite

454
00:20:29,450 --> 00:20:33,830
limited we want a six-month history the

455
00:20:33,830 --> 00:20:35,570
server we've been given currently to do

456
00:20:35,570 --> 00:20:38,179
this on has a terabyte of disk space so

457
00:20:38,179 --> 00:20:40,130
that's all we've got and we want curves

458
00:20:40,130 --> 00:20:41,540
to be fast because this is all user

459
00:20:41,540 --> 00:20:43,370
facing so you want to click it it comes

460
00:20:43,370 --> 00:20:46,820
up without those so what agrees to be

461
00:20:46,820 --> 00:20:49,880
less than 100 milliseconds so with the

462
00:20:49,880 --> 00:20:52,190
time series data we kind of have two

463
00:20:52,190 --> 00:20:54,110
categories of query we have one query

464
00:20:54,110 --> 00:20:57,080
which is get me all the measurements for

465
00:20:57,080 --> 00:20:59,000
this series so get me a lot of

466
00:20:59,000 --> 00:21:03,640
measurements for a particular post and

467
00:21:03,640 --> 00:21:05,630
then the other kind of cache be of

468
00:21:05,630 --> 00:21:09,710
series is I want the average CPU load of

469
00:21:09,710 --> 00:21:11,720
all my hosts so you end up sort of

470
00:21:11,720 --> 00:21:12,800
averaging them all together

471
00:21:12,800 --> 00:21:14,929
and then you get one line instead of two

472
00:21:14,929 --> 00:21:17,559
or 80

473
00:21:18,059 --> 00:21:20,440
I'll go into a bit more depth in a bit

474
00:21:20,440 --> 00:21:23,020
so I'm gonna move on from that and the

475
00:21:23,020 --> 00:21:24,070
other sort of category of queries you

476
00:21:24,070 --> 00:21:25,570
end up having to do is you want to find

477
00:21:25,570 --> 00:21:26,920
out what metrics you've got in your

478
00:21:26,920 --> 00:21:28,179
system these are all changing

479
00:21:28,179 --> 00:21:30,070
dynamically posts are coming and going

480
00:21:30,070 --> 00:21:33,520
new VMs are coming and going and

481
00:21:33,520 --> 00:21:35,440
networks coming going it's all changing

482
00:21:35,440 --> 00:21:36,880
all the time so you want to work out

483
00:21:36,880 --> 00:21:38,410
what you're actually monitoring what's

484
00:21:38,410 --> 00:21:40,929
available so we want a better list the

485
00:21:40,929 --> 00:21:43,960
metric names masca has this concept of

486
00:21:43,960 --> 00:21:46,090
dimensions so things like post name

487
00:21:46,090 --> 00:21:49,090
mount point process name and we want the

488
00:21:49,090 --> 00:21:50,860
values of those so we want to be able to

489
00:21:50,860 --> 00:21:56,260
say list me all my host names so the

490
00:21:56,260 --> 00:21:58,900
data and the queries for this is next

491
00:21:58,900 --> 00:22:02,380
thing we look at so the data comes into

492
00:22:02,380 --> 00:22:04,650
this system in JSON format because

493
00:22:04,650 --> 00:22:12,549
everything's JSON new XML and the

494
00:22:12,549 --> 00:22:15,480
structure is kind of irrelevant for this

495
00:22:15,480 --> 00:22:19,480
you get a name you get the value and you

496
00:22:19,480 --> 00:22:22,690
get a set of dimensions and some list of

497
00:22:22,690 --> 00:22:25,809
tags or senses of key value pairs so for

498
00:22:25,809 --> 00:22:28,780
a CPU percentage you get a host name and

499
00:22:28,780 --> 00:22:30,880
there's a value meta which is kind of an

500
00:22:30,880 --> 00:22:33,280
extra bit of data you couldn't store but

501
00:22:33,280 --> 00:22:37,020
never really gets processed in any way

502
00:22:37,020 --> 00:22:43,640
so fairly simple stick this in Postgres

503
00:22:43,640 --> 00:22:45,360
you probably you're thinking this is

504
00:22:45,360 --> 00:22:47,309
terrible idea but there's more to the

505
00:22:47,309 --> 00:22:51,630
top so we could just shove all the data

506
00:22:51,630 --> 00:22:54,210
in the dimensions we'll store as Jason B

507
00:22:54,210 --> 00:22:56,760
because that fits nicely we want to

508
00:22:56,760 --> 00:22:58,860
access them quite fast the value matter

509
00:22:58,860 --> 00:23:00,360
we don't really care about we just want

510
00:23:00,360 --> 00:23:01,980
to pipe it back out again so Jason's

511
00:23:01,980 --> 00:23:04,559
good fit for that all of these systems

512
00:23:04,559 --> 00:23:06,360
if used to dig into the details they're

513
00:23:06,360 --> 00:23:08,070
all double precision none of them do

514
00:23:08,070 --> 00:23:09,450
anything up in double precision so

515
00:23:09,450 --> 00:23:11,940
rotate is fine for all the values and

516
00:23:11,940 --> 00:23:14,670
the name of the time step these always

517
00:23:14,670 --> 00:23:16,580
use time time T Zed

518
00:23:16,580 --> 00:23:20,880
nothing else ever you'll thank me one

519
00:23:20,880 --> 00:23:22,940
day

520
00:23:23,990 --> 00:23:28,410
so this is this is a query we might run

521
00:23:28,410 --> 00:23:31,580
to get a single series out of the system

522
00:23:31,580 --> 00:23:34,020
so I've got a function there that rounds

523
00:23:34,020 --> 00:23:36,780
a time stamp to the nearest number of

524
00:23:36,780 --> 00:23:38,429
seconds you pass it there's not a post

525
00:23:38,429 --> 00:23:39,720
players built-in it's very easy to write

526
00:23:39,720 --> 00:23:42,780
you can find examples of it all over the

527
00:23:42,780 --> 00:23:46,530
place and so we want we often want to

528
00:23:46,530 --> 00:23:48,120
say give me these give me all the values

529
00:23:48,120 --> 00:23:49,980
between this particular time range for

530
00:23:49,980 --> 00:23:52,320
this series and we might also want to

531
00:23:52,320 --> 00:23:54,059
say make sure it matches these

532
00:23:54,059 --> 00:23:56,010
dimensions so we get that single series

533
00:23:56,010 --> 00:24:01,550
of CPU time for post-death naught one

534
00:24:01,790 --> 00:24:05,630
and then we might want to so this is

535
00:24:05,630 --> 00:24:08,120
just an example of we actually want to

536
00:24:08,120 --> 00:24:09,980
get all the series we want to get that

537
00:24:09,980 --> 00:24:12,020
individual series we want to get it for

538
00:24:12,020 --> 00:24:15,710
all the hosts so we want to so again we

539
00:24:15,710 --> 00:24:17,390
can dig into our dimensions field grab

540
00:24:17,390 --> 00:24:19,370
the host name and then grouped by the

541
00:24:19,370 --> 00:24:22,390
time window and the host name as well

542
00:24:22,390 --> 00:24:26,630
and finally we might want to do this

543
00:24:26,630 --> 00:24:28,160
combo query where we sort of roll

544
00:24:28,160 --> 00:24:30,470
everything up into one big metric so CPU

545
00:24:30,470 --> 00:24:35,800
percentage for all my hosts don't care

546
00:24:37,400 --> 00:24:41,809
and so the metric name list we could do

547
00:24:41,809 --> 00:24:44,690
that it would work a lot of you might be

548
00:24:44,690 --> 00:24:46,550
thinking that's gonna take a while yeah

549
00:24:46,550 --> 00:24:51,280
it's gonna take a while well it's good

550
00:24:51,490 --> 00:24:53,270
to mention the names bit more

551
00:24:53,270 --> 00:24:55,430
interesting post post has a nice

552
00:24:55,430 --> 00:24:58,190
function to get all of the keys out of a

553
00:24:58,190 --> 00:25:03,080
blob of JSON for you and likewise if you

554
00:25:03,080 --> 00:25:05,420
want all the values for then you can

555
00:25:05,420 --> 00:25:07,460
just dig into the JSON pick out the

556
00:25:07,460 --> 00:25:12,320
dimension so fairly straightforward so

557
00:25:12,320 --> 00:25:16,460
far not very complicated sequel and it's

558
00:25:16,460 --> 00:25:17,990
not going to be very faster if we store

559
00:25:17,990 --> 00:25:19,340
it like that and so we didn't it

560
00:25:19,340 --> 00:25:22,160
optimize it a little bit so if we stick

561
00:25:22,160 --> 00:25:24,740
with our denormalized schema we could

562
00:25:24,740 --> 00:25:28,190
just put some indexes on it we can use

563
00:25:28,190 --> 00:25:30,679
add in index for the JSON B so we can

564
00:25:30,679 --> 00:25:32,330
pick out the host names really fast

565
00:25:32,330 --> 00:25:35,000
and we can put a index we can put a

566
00:25:35,000 --> 00:25:37,370
multi column index on name and time

567
00:25:37,370 --> 00:25:38,480
stamps so when we're looking for

568
00:25:38,480 --> 00:25:41,380
particular time range a particular name

569
00:25:41,380 --> 00:25:43,370
most post does that very efficiently

570
00:25:43,370 --> 00:25:45,080
sort of walks through the B tree to find

571
00:25:45,080 --> 00:25:46,670
the right name and then walks further

572
00:25:46,670 --> 00:25:47,960
through the B tree to find the time

573
00:25:47,960 --> 00:25:49,610
stamp and then just iterate all the way

574
00:25:49,610 --> 00:25:55,330
down really good structure so

575
00:25:55,330 --> 00:25:57,370
a lot of information how I try it too

576
00:25:57,370 --> 00:25:59,500
much but the queries I decided to look

577
00:25:59,500 --> 00:26:01,870
at for the performance were some of the

578
00:26:01,870 --> 00:26:04,960
series queries of varying time window so

579
00:26:04,960 --> 00:26:07,180
over a small period of time over an hour

580
00:26:07,180 --> 00:26:10,990
over six hours and over 24 hours and

581
00:26:10,990 --> 00:26:18,280
then the listing queries as well so this

582
00:26:18,280 --> 00:26:21,130
so the the kind of interesting thing

583
00:26:21,130 --> 00:26:24,430
about this is this kind of rather naive

584
00:26:24,430 --> 00:26:25,570
schema we've put together doesn't

585
00:26:25,570 --> 00:26:28,330
actually do too bad we can pick out

586
00:26:28,330 --> 00:26:33,340
individual series really fast but doing

587
00:26:33,340 --> 00:26:35,620
these kind of queries over the big time

588
00:26:35,620 --> 00:26:37,960
windows so over the six hours and the 24

589
00:26:37,960 --> 00:26:40,600
hour time windows really starts to sort

590
00:26:40,600 --> 00:26:43,690
of grind away a bit I should mention all

591
00:26:43,690 --> 00:26:45,610
these tests I talked about is over one

592
00:26:45,610 --> 00:26:48,400
day of data and that's about 45 million

593
00:26:48,400 --> 00:26:51,040
rows table I think I mentioned that

594
00:26:51,040 --> 00:26:51,540
earlier

595
00:26:51,540 --> 00:26:54,070
so just rescale that query so we can

596
00:26:54,070 --> 00:26:58,420
look at it a bit better some of the

597
00:26:58,420 --> 00:26:59,440
queries are kind of on the edge of our

598
00:26:59,440 --> 00:27:00,850
hundred milliseconds but a lot of them

599
00:27:00,850 --> 00:27:03,280
are actually in there it's quite quite

600
00:27:03,280 --> 00:27:05,179
interesting

601
00:27:05,179 --> 00:27:07,249
and unfortunately those other queries

602
00:27:07,249 --> 00:27:08,599
where we are picking out metric names

603
00:27:08,599 --> 00:27:11,149
and dimension names as you can imagine

604
00:27:11,149 --> 00:27:13,279
they take a long time they select

605
00:27:13,279 --> 00:27:16,219
distinct over 45 million rows yep it's

606
00:27:16,219 --> 00:27:19,190
not gonna be faster afraid then we zoom

607
00:27:19,190 --> 00:27:20,450
in on that a little bit you can see we

608
00:27:20,450 --> 00:27:23,299
are well over our requirement of hundred

609
00:27:23,299 --> 00:27:25,509
milliseconds for all of those queries

610
00:27:25,509 --> 00:27:28,399
and of course you're all shouting at me

611
00:27:28,399 --> 00:27:29,539
this is stupid

612
00:27:29,539 --> 00:27:31,580
you should have two tables and you're

613
00:27:31,580 --> 00:27:34,849
probably right so first kind of thing we

614
00:27:34,849 --> 00:27:36,799
can do to improve this is normalize out

615
00:27:36,799 --> 00:27:39,349
the two tables so we've got a separate

616
00:27:39,349 --> 00:27:41,539
metrics table and a set put measurement

617
00:27:41,539 --> 00:27:43,489
values table and they're joined together

618
00:27:43,489 --> 00:27:47,419
with a with an ID has some other

619
00:27:47,419 --> 00:27:49,159
advantages as well so I'll talk about in

620
00:27:49,159 --> 00:27:52,849
a minute but it does make the queries a

621
00:27:52,849 --> 00:27:56,659
bit faster it doesn't mean we need to do

622
00:27:56,659 --> 00:28:00,619
a little bit of it doesn't even need to

623
00:28:00,619 --> 00:28:03,019
do a little bit of fiddling around when

624
00:28:03,019 --> 00:28:05,330
we insert the values so we find the ID

625
00:28:05,330 --> 00:28:09,320
of the we find the ID of the metric and

626
00:28:09,320 --> 00:28:11,179
then we tag the measurements with that

627
00:28:11,179 --> 00:28:13,389
money

628
00:28:13,620 --> 00:28:15,360
don't expect you to read that now but

629
00:28:15,360 --> 00:28:16,650
it's good of the rough than yesterday

630
00:28:16,650 --> 00:28:19,760
not tea drinking

631
00:28:21,690 --> 00:28:23,790
and the queries that the queries that we

632
00:28:23,790 --> 00:28:25,290
can do on this exactly the same as

633
00:28:25,290 --> 00:28:28,440
before it's just we can use that view to

634
00:28:28,440 --> 00:28:31,380
do the join for us just technical team

635
00:28:31,380 --> 00:28:32,970
or anything else you could write the

636
00:28:32,970 --> 00:28:34,290
codes with the join in if you wanted to

637
00:28:34,290 --> 00:28:37,260
and the index is mostly the same as well

638
00:28:37,260 --> 00:28:39,420
so we have a multi column index on the

639
00:28:39,420 --> 00:28:41,910
metric ID and time stamp and we have a

640
00:28:41,910 --> 00:28:44,370
just index or name and dimension so we

641
00:28:44,370 --> 00:28:45,350
couldn't when we're doing that

642
00:28:45,350 --> 00:28:47,430
normalization we can find the name and

643
00:28:47,430 --> 00:28:52,410
dimensions which fast and that help was

644
00:28:52,410 --> 00:28:55,430
a bit bounty how quick these are down to

645
00:28:55,430 --> 00:28:58,200
500 milliseconds for some of them for

646
00:28:58,200 --> 00:28:59,750
the 24-hour query we're still way over

647
00:28:59,750 --> 00:29:02,130
of one and a half seconds two seconds

648
00:29:02,130 --> 00:29:09,530
they we need to do a bit more work the

649
00:29:09,530 --> 00:29:11,850
listing queries however because we've

650
00:29:11,850 --> 00:29:14,340
already normalized all of those lists

651
00:29:14,340 --> 00:29:15,690
out we've already done that distinct

652
00:29:15,690 --> 00:29:18,690
operation effectively are now well in

653
00:29:18,690 --> 00:29:24,030
our requirement so that's good so the

654
00:29:24,030 --> 00:29:26,220
problem that this is at the time and

655
00:29:26,220 --> 00:29:29,250
this is the problem with all time series

656
00:29:29,250 --> 00:29:33,150
data you eventually get the actual

657
00:29:33,150 --> 00:29:34,830
detail that you need for a particular

658
00:29:34,830 --> 00:29:36,870
graph is becomes less interesting the

659
00:29:36,870 --> 00:29:38,190
bigger the time window you're looking at

660
00:29:38,190 --> 00:29:39,720
so if you're looking at a 24 hour time

661
00:29:39,720 --> 00:29:43,020
window or a 6 month time window you

662
00:29:43,020 --> 00:29:45,000
don't need to plot every point from

663
00:29:45,000 --> 00:29:49,340
every 30 seconds on that graph so you

664
00:29:49,340 --> 00:29:51,600
really don't have to store all of that

665
00:29:51,600 --> 00:29:54,080
detail and this is what a lot of these

666
00:29:54,080 --> 00:29:57,420
time series kind of databases seem to be

667
00:29:57,420 --> 00:29:59,520
doing is they're doing these roll-ups

668
00:29:59,520 --> 00:30:03,060
and as you push the data in so instead

669
00:30:03,060 --> 00:30:05,790
of having every 30 seconds you have a

670
00:30:05,790 --> 00:30:06,930
data point through each of your metrics

671
00:30:06,930 --> 00:30:10,429
every 2 minutes or every 5 minutes

672
00:30:10,429 --> 00:30:12,139
and this really shrinks down the amount

673
00:30:12,139 --> 00:30:15,019
of dates you need to query for 24 hour

674
00:30:15,019 --> 00:30:18,590
time window and so I kind of call this

675
00:30:18,590 --> 00:30:22,070
the summarized schema it's it's kind of

676
00:30:22,070 --> 00:30:25,340
conceptually similar to our Rd and tools

677
00:30:25,340 --> 00:30:27,950
like that and again a lot of the

678
00:30:27,950 --> 00:30:29,330
internals with these other databases are

679
00:30:29,330 --> 00:30:30,289
doing this thing as well they're

680
00:30:30,289 --> 00:30:32,659
bringing their building up course the

681
00:30:32,659 --> 00:30:36,200
roll-ups to query instead so we can do

682
00:30:36,200 --> 00:30:37,999
that in place because we can build these

683
00:30:37,999 --> 00:30:39,740
summary tables and depending on the

684
00:30:39,740 --> 00:30:42,830
functions you want to do you could you

685
00:30:42,830 --> 00:30:45,139
could compute so I've done some count

686
00:30:45,139 --> 00:30:47,360
min and Max here because then you can

687
00:30:47,360 --> 00:30:49,429
kind of aggregate them together high up

688
00:30:49,429 --> 00:30:55,399
and but you need constraint there just

689
00:30:55,399 --> 00:30:57,769
to make the in the creation of the

690
00:30:57,769 --> 00:31:00,440
summaries a bit easier so he attached a

691
00:31:00,440 --> 00:31:02,269
trigger so let me insert data into our

692
00:31:02,269 --> 00:31:04,159
main measurements table we want to keep

693
00:31:04,159 --> 00:31:06,220
the detail in case we want to go really

694
00:31:06,220 --> 00:31:09,919
really fine grained into it we just

695
00:31:09,919 --> 00:31:12,669
create a trigger which I'd say

696
00:31:12,669 --> 00:31:15,860
essentially updates a row the row for

697
00:31:15,860 --> 00:31:18,350
that particular time point for that

698
00:31:18,350 --> 00:31:23,360
metric ID and then if there's a image if

699
00:31:23,360 --> 00:31:25,340
there's a summary already there then we

700
00:31:25,340 --> 00:31:26,929
combine it so when we summing them we

701
00:31:26,929 --> 00:31:28,970
add them together or for milling we take

702
00:31:28,970 --> 00:31:30,320
the min of the one that's already there

703
00:31:30,320 --> 00:31:34,460
and the new one we're adding in that's

704
00:31:34,460 --> 00:31:36,350
it that's it's kind of all you put a do

705
00:31:36,350 --> 00:31:39,080
to build these summaries its own post

706
00:31:39,080 --> 00:31:44,049
goes into a time series data box

707
00:31:44,520 --> 00:31:47,330
so what I've kind of just discussed here

708
00:31:47,330 --> 00:31:49,730
isn't the most efficient way of doing it

709
00:31:49,730 --> 00:31:52,920
but it does the job as we'll see in a

710
00:31:52,920 --> 00:31:56,720
second so a few technicalities just to

711
00:31:56,720 --> 00:32:02,130
join the table together and the queries

712
00:32:02,130 --> 00:32:03,929
so the queries for the small intervals

713
00:32:03,929 --> 00:32:06,240
we still go to the raw data for the

714
00:32:06,240 --> 00:32:07,650
larger intervals we now go to our

715
00:32:07,650 --> 00:32:14,040
summaries instead and these queries of

716
00:32:14,040 --> 00:32:17,730
course a lot faster so that's good so

717
00:32:17,730 --> 00:32:19,860
those 24-hour queries that were taking

718
00:32:19,860 --> 00:32:22,440
two seconds we're just plowing through

719
00:32:22,440 --> 00:32:23,790
the data as fast as we could

720
00:32:23,790 --> 00:32:25,800
now we do something a bit smarter we're

721
00:32:25,800 --> 00:32:28,710
only querying the rolled up data days we

722
00:32:28,710 --> 00:32:31,640
pre build up even our 24-hour query

723
00:32:31,640 --> 00:32:34,850
comes back in less than hundred percent

724
00:32:34,850 --> 00:32:39,350
pretty good and of course the sum of the

725
00:32:39,350 --> 00:32:42,980
dimension listing credits the same

726
00:32:42,980 --> 00:32:46,290
so the other thing that we want to

727
00:32:46,290 --> 00:32:47,520
consider is can we actually get this one

728
00:32:47,520 --> 00:32:50,130
data in so we need to be able get a

729
00:32:50,130 --> 00:32:51,840
day's worth of data in less than a day

730
00:32:51,840 --> 00:32:53,730
otherwise we're going to start lagging

731
00:32:53,730 --> 00:32:58,680
behind quite significantly and for this

732
00:32:58,680 --> 00:33:02,490
system so we've got quite a lot of

733
00:33:02,490 --> 00:33:08,790
headroom I think this the the sunlight

734
00:33:08,790 --> 00:33:11,300
schemer equates to about 15,000

735
00:33:11,300 --> 00:33:14,100
measurements a second so you know it's

736
00:33:14,100 --> 00:33:16,680
not a lot but this is a very naive

737
00:33:16,680 --> 00:33:18,210
scheme and a very naive sort of set of

738
00:33:18,210 --> 00:33:20,190
triggers we've just drove together to

739
00:33:20,190 --> 00:33:24,840
make this work so the good result the

740
00:33:24,840 --> 00:33:26,660
other thing worth noticing is the

741
00:33:26,660 --> 00:33:28,740
normalization as you might expect really

742
00:33:28,740 --> 00:33:30,300
does reduce the amount of disk space you

743
00:33:30,300 --> 00:33:32,970
need and in fact this was necessary for

744
00:33:32,970 --> 00:33:35,610
us because the in order to get to that

745
00:33:35,610 --> 00:33:39,000
one terabyte for six months value we

746
00:33:39,000 --> 00:33:41,160
have to hit less than six gigabytes a

747
00:33:41,160 --> 00:33:46,020
day of data so we were well over that do

748
00:33:46,020 --> 00:33:51,000
you normalize data so this isn't the

749
00:33:51,000 --> 00:33:53,160
whole story I mean this is an example of

750
00:33:53,160 --> 00:33:56,160
how you could do it and to really make

751
00:33:56,160 --> 00:33:57,420
this work in production there's a few

752
00:33:57,420 --> 00:33:58,830
things we're going to do and there's a

753
00:33:58,830 --> 00:34:01,680
few things you have to do as well you

754
00:34:01,680 --> 00:34:03,240
probably gonna need Porter summaries so

755
00:34:03,240 --> 00:34:04,920
if you want to do a six-month average

756
00:34:04,920 --> 00:34:06,830
you're probably going to need maybe a

757
00:34:06,830 --> 00:34:09,960
summary for every point every hour or

758
00:34:09,960 --> 00:34:12,830
maybe a point every two hours

759
00:34:13,090 --> 00:34:14,620
you're probably gonna have to partition

760
00:34:14,620 --> 00:34:15,909
the data and that's kind of the

761
00:34:15,909 --> 00:34:17,260
assumption I made so all of these tests

762
00:34:17,260 --> 00:34:19,179
have been on a day of data so you

763
00:34:19,179 --> 00:34:20,469
probably going to want to partition it

764
00:34:20,469 --> 00:34:24,820
by day and that also makes dropping the

765
00:34:24,820 --> 00:34:30,070
data very fast and there's there's a few

766
00:34:30,070 --> 00:34:32,380
tricky ways you can optimize the

767
00:34:32,380 --> 00:34:34,210
producing of these summaries because the

768
00:34:34,210 --> 00:34:35,050
way we're doing these summaries we're

769
00:34:35,050 --> 00:34:37,290
doing an update for every measurement so

770
00:34:37,290 --> 00:34:40,330
b-tree look-up on an update of a row so

771
00:34:40,330 --> 00:34:41,800
not the most efficient way of doing it

772
00:34:41,800 --> 00:34:43,000
we really want to do take a whole batch

773
00:34:43,000 --> 00:34:46,270
of these values so for a 5-minute

774
00:34:46,270 --> 00:34:47,530
interval we want five minutes worth of

775
00:34:47,530 --> 00:34:50,530
values and shove them all into a smaller

776
00:34:50,530 --> 00:34:53,770
format and one go and there's a few ways

777
00:34:53,770 --> 00:34:55,719
to do that bamaca go into that detail

778
00:34:55,719 --> 00:34:58,260
this is coming meant to be a day review

779
00:34:58,260 --> 00:35:02,020
so we can do metrics wasn't too hard so

780
00:35:02,020 --> 00:35:04,810
this next station is kind of bit wider

781
00:35:04,810 --> 00:35:08,260
stretching perhaps so what else could we

782
00:35:08,260 --> 00:35:10,840
put into posterized well we said earlier

783
00:35:10,840 --> 00:35:15,010
we could put logs in there so let's do

784
00:35:15,010 --> 00:35:18,190
that so we want some centralized log

785
00:35:18,190 --> 00:35:21,070
storage we wanted to be searchable so we

786
00:35:21,070 --> 00:35:22,110
want a better search for things like

787
00:35:22,110 --> 00:35:25,270
connect and H a proxy and get values

788
00:35:25,270 --> 00:35:28,960
back we won't be time bounded and again

789
00:35:28,960 --> 00:35:31,000
they gotta be fast because we're going

790
00:35:31,000 --> 00:35:32,740
to produce interactive graphs and

791
00:35:32,740 --> 00:35:35,650
interactive lists of these things you

792
00:35:35,650 --> 00:35:39,330
don't keep people waiting around

793
00:35:40,050 --> 00:35:42,500
so this was the kind of the data we get

794
00:35:42,500 --> 00:35:46,590
typically comes from our syslog you get

795
00:35:46,590 --> 00:35:48,330
things like severity the program name

796
00:35:48,330 --> 00:35:52,069
host name and you get the message

797
00:35:52,220 --> 00:35:56,070
so again basic schema timestamp message

798
00:35:56,070 --> 00:35:58,850
dimensions

799
00:36:00,900 --> 00:36:03,180
and the sort of queries we want to do if

800
00:36:03,180 --> 00:36:04,500
you used to using kind of elastic and

801
00:36:04,500 --> 00:36:05,850
Cabana you might want to do things like

802
00:36:05,850 --> 00:36:08,250
this so you want to say find me Logs

803
00:36:08,250 --> 00:36:09,660
with the word connection where the

804
00:36:09,660 --> 00:36:14,790
program name is a checkbox E and we can

805
00:36:14,790 --> 00:36:17,070
do those with a repo specification has

806
00:36:17,070 --> 00:36:19,890
got full-text search this made me a bit

807
00:36:19,890 --> 00:36:23,310
longer that we can do a TS query on the

808
00:36:23,310 --> 00:36:26,100
message and then we can do it contains

809
00:36:26,100 --> 00:36:31,050
on the dimensions as long as we've got

810
00:36:31,050 --> 00:36:35,000
that indexed with some gene indexes

811
00:36:35,000 --> 00:36:38,400
it'll be nice and fast haven't dug in as

812
00:36:38,400 --> 00:36:40,770
depth in depth for these kind of

813
00:36:40,770 --> 00:36:43,290
dissection or for stuff like performance

814
00:36:43,290 --> 00:36:45,870
numbers for this I'm afraid a bit of a

815
00:36:45,870 --> 00:36:48,690
kind of a total fiddling around shows

816
00:36:48,690 --> 00:36:50,670
that you can store quite a lot of logs

817
00:36:50,670 --> 00:36:53,820
with some basic genetics is on them then

818
00:36:53,820 --> 00:36:58,050
get some really fast queries if any

819
00:36:58,050 --> 00:36:59,280
Postgres people want to tell me whether

820
00:36:59,280 --> 00:37:01,290
it's a better idea to combine those into

821
00:37:01,290 --> 00:37:02,970
one multi-column query multiple mean

822
00:37:02,970 --> 00:37:04,140
that's not that'll be really interesting

823
00:37:04,140 --> 00:37:09,000
I'm not sure haven't tried it yet so

824
00:37:09,000 --> 00:37:11,340
long pausing we're sort of stretching

825
00:37:11,340 --> 00:37:13,590
now but I think it's interesting to try

826
00:37:13,590 --> 00:37:17,490
and so this is our log message again our

827
00:37:17,490 --> 00:37:19,470
log structure bit of JSON that we've got

828
00:37:19,470 --> 00:37:23,610
out of our sister or wherever and what

829
00:37:23,610 --> 00:37:24,630
we were worried ain't don't wanna do is

830
00:37:24,630 --> 00:37:26,190
we want to notice that that puts that

831
00:37:26,190 --> 00:37:28,740
has connect from and it's from a CH a

832
00:37:28,740 --> 00:37:32,100
proxy and we want to tag it so this is

833
00:37:32,100 --> 00:37:33,510
the sort of thing that log stash will do

834
00:37:33,510 --> 00:37:36,000
for you well target connect cuz then it

835
00:37:36,000 --> 00:37:37,230
makes it really easy to search for it

836
00:37:37,230 --> 00:37:40,350
later on and draw kind of graphs with it

837
00:37:40,350 --> 00:37:43,760
we don't want to get all this data out

838
00:37:43,760 --> 00:37:46,680
and we want to store it in a structured

839
00:37:46,680 --> 00:37:49,830
way so we can search for a service name

840
00:37:49,830 --> 00:37:52,740
or protocol it's nice and reliable and

841
00:37:52,740 --> 00:37:54,119
robust and we're not doing

842
00:37:54,119 --> 00:37:55,710
that horrible regex is all over the

843
00:37:55,710 --> 00:37:59,089
place shouldn't have said that because

844
00:37:59,089 --> 00:38:01,349
we are going to use hope of regex is to

845
00:38:01,349 --> 00:38:03,230
do this

846
00:38:03,230 --> 00:38:06,450
Postgres can do regex is and if you've

847
00:38:06,450 --> 00:38:07,799
you know if you've used logstash for a

848
00:38:07,799 --> 00:38:09,269
long time you realize that the core

849
00:38:09,269 --> 00:38:10,710
thing is the Drakh I mean that's the

850
00:38:10,710 --> 00:38:13,440
really good bit of logs - and it's a

851
00:38:13,440 --> 00:38:16,410
regex and you match them match your log

852
00:38:16,410 --> 00:38:19,349
messages and it pulls out all of the all

853
00:38:19,349 --> 00:38:21,170
the field data for you

854
00:38:21,170 --> 00:38:24,749
so with a bit of a little extra JSON

855
00:38:24,749 --> 00:38:27,539
garnishing we can make this nice into a

856
00:38:27,539 --> 00:38:31,849
little JSON blob as well

857
00:38:39,830 --> 00:38:43,730
so we've got our schema for logs which

858
00:38:43,730 --> 00:38:46,760
we looked at a minute ago what we really

859
00:38:46,760 --> 00:38:49,460
want to do with this data is we want to

860
00:38:49,460 --> 00:38:50,840
pause the message against the patterns

861
00:38:50,840 --> 00:38:52,400
and then we want all those dimensions

862
00:38:52,400 --> 00:38:56,900
extracted and added on as extra field so

863
00:38:56,900 --> 00:38:58,400
this is kind of an idea this might not

864
00:38:58,400 --> 00:39:00,260
be the nicest way to do it but it's

865
00:39:00,260 --> 00:39:02,420
certainly a way you can do it we can

866
00:39:02,420 --> 00:39:04,640
have a patterns table so we can store

867
00:39:04,640 --> 00:39:06,620
our patterns in the table and we can

868
00:39:06,620 --> 00:39:10,610
store the field names alongside them so

869
00:39:10,610 --> 00:39:12,170
that part of the regex

870
00:39:12,170 --> 00:39:15,680
ends up being the source IP you should

871
00:39:15,680 --> 00:39:17,090
have matched them one-to-one to each

872
00:39:17,090 --> 00:39:19,580
other and then use our little trick

873
00:39:19,580 --> 00:39:22,520
earlier and again just keeping this

874
00:39:22,520 --> 00:39:25,490
simple let's use a trigger so as we

875
00:39:25,490 --> 00:39:29,030
insert logs into our logs table we

876
00:39:29,030 --> 00:39:30,860
pre-processed them so for those people

877
00:39:30,860 --> 00:39:32,390
not too familiar with post cards or

878
00:39:32,390 --> 00:39:34,760
sequel tree this trigger lets you

879
00:39:34,760 --> 00:39:36,860
pre-process the row before it's inserted

880
00:39:36,860 --> 00:39:39,170
into the table so we're using that so

881
00:39:39,170 --> 00:39:40,430
it's right over all of our patterns

882
00:39:40,430 --> 00:39:42,910
match all of our patterns if it matches

883
00:39:42,910 --> 00:39:47,049
then we add the dimensions on

884
00:39:50,500 --> 00:39:53,490
yeah attaching the trigger to the table

885
00:39:53,490 --> 00:39:57,460
interesting so when we insert our log

886
00:39:57,460 --> 00:40:02,410
into the table with those dimensions it

887
00:40:02,410 --> 00:40:05,040
actually grows all of this extra stuff

888
00:40:05,040 --> 00:40:08,440
because of the trigger which is really

889
00:40:08,440 --> 00:40:09,580
nice and this actually gives us a way to

890
00:40:09,580 --> 00:40:13,060
dynamically add patterns to our log

891
00:40:13,060 --> 00:40:15,130
pausing which is really cool so you

892
00:40:15,130 --> 00:40:17,080
could have a so it's not in the early

893
00:40:17,080 --> 00:40:18,250
used log stash you know you have to

894
00:40:18,250 --> 00:40:19,930
rebuild confer you have to edit config

895
00:40:19,930 --> 00:40:21,340
files and restart it before it kind of

896
00:40:21,340 --> 00:40:22,720
before you can add new Athens to

897
00:40:22,720 --> 00:40:26,470
everything interesting advantage again

898
00:40:26,470 --> 00:40:27,430
probably not the most efficient way to

899
00:40:27,430 --> 00:40:31,649
do it but good enough

900
00:40:32,090 --> 00:40:37,530
say stretching even further now what do

901
00:40:37,530 --> 00:40:39,090
you mean by queueing in these systems

902
00:40:39,090 --> 00:40:40,890
why these systems have message queues in

903
00:40:40,890 --> 00:40:42,620
them

904
00:40:42,620 --> 00:40:47,130
so the the point of the queue is really

905
00:40:47,130 --> 00:40:50,970
to handle really bursty traffic so you

906
00:40:50,970 --> 00:40:52,800
might have a system of spewing logs

907
00:40:52,800 --> 00:40:56,250
outlet quite rate and you really want to

908
00:40:56,250 --> 00:40:57,540
keep this you want to persist this as

909
00:40:57,540 --> 00:40:59,010
soon as possible so you don't lose it

910
00:40:59,010 --> 00:41:00,690
but you don't really have to query it

911
00:41:00,690 --> 00:41:01,440
straightaway

912
00:41:01,440 --> 00:41:03,360
in fact it's okay if it sits there for a

913
00:41:03,360 --> 00:41:04,980
few minutes as long as it's there and

914
00:41:04,980 --> 00:41:06,060
you can look at it eventually then

915
00:41:06,060 --> 00:41:07,350
that's kind of good enough and it's

916
00:41:07,350 --> 00:41:08,700
really the only option you have if

917
00:41:08,700 --> 00:41:10,560
you're getting gigabytes of logs you

918
00:41:10,560 --> 00:41:11,610
know there's any certain amount you can

919
00:41:11,610 --> 00:41:13,320
process unless you have an entire

920
00:41:13,320 --> 00:41:16,020
cluster just for processing logs which I

921
00:41:16,020 --> 00:41:17,970
presume some people do by the way they

922
00:41:17,970 --> 00:41:20,100
speak about it so really all we want to

923
00:41:20,100 --> 00:41:22,320
do is want to just write the data to

924
00:41:22,320 --> 00:41:23,640
some sort of persistent storage as fast

925
00:41:23,640 --> 00:41:24,390
as possible

926
00:41:24,390 --> 00:41:26,070
enough to clear it and we're worried

927
00:41:26,070 --> 00:41:27,960
about structuring it later processing it

928
00:41:27,960 --> 00:41:31,920
later so if we go back to those ingest

929
00:41:31,920 --> 00:41:33,930
rates so I've turned the numbers I had

930
00:41:33,930 --> 00:41:35,790
from earlier I'm on their head from

931
00:41:35,790 --> 00:41:39,480
ingest time to ingest rate so our

932
00:41:39,480 --> 00:41:45,030
summarized time series data about 15,000

933
00:41:45,030 --> 00:41:46,230
of them a second because we're doing a

934
00:41:46,230 --> 00:41:47,580
lot of processing on it we're not doing

935
00:41:47,580 --> 00:41:50,940
it very very efficiently but the less

936
00:41:50,940 --> 00:41:54,030
processing we do the more we can shove

937
00:41:54,030 --> 00:41:57,030
in so if we go back to the denormalized

938
00:41:57,030 --> 00:41:59,430
version we can actually put in quite a

939
00:41:59,430 --> 00:42:01,670
lot more second so we can take in

940
00:42:01,670 --> 00:42:06,170
140,000 make sure it's a second

941
00:42:07,339 --> 00:42:10,800
we could simplify this I mean if we just

942
00:42:10,800 --> 00:42:13,320
stored the raw JSON be that we got from

943
00:42:13,320 --> 00:42:15,780
the from the software doing even less

944
00:42:15,780 --> 00:42:19,109
processing now we're up to much high

945
00:42:19,109 --> 00:42:21,780
number I think I got my scales on there

946
00:42:21,780 --> 00:42:24,589
so that one's about hundred and forty

947
00:42:24,589 --> 00:42:27,450
well let's do even less processing their

948
00:42:27,450 --> 00:42:29,940
stories JSON the JSON for those if you

949
00:42:29,940 --> 00:42:33,510
don't know it's just text version of the

950
00:42:33,510 --> 00:42:35,910
JSON stored in the column the JSON B

951
00:42:35,910 --> 00:42:38,849
does some extra fiddling around for you

952
00:42:38,849 --> 00:42:40,880
to make it more efficient to to get to

953
00:42:40,880 --> 00:42:44,130
and the JSTOR the thing about the JSON

954
00:42:44,130 --> 00:42:46,410
type is it still validates your JSON for

955
00:42:46,410 --> 00:42:47,730
you which is great most of the time

956
00:42:47,730 --> 00:42:49,530
unless you really just want to shove

957
00:42:49,530 --> 00:42:52,589
data into a table really fast so if you

958
00:42:52,589 --> 00:42:55,170
start this voucher you can really press

959
00:42:55,170 --> 00:42:59,180
out even more well over 250,000

960
00:42:59,180 --> 00:43:04,380
measurements a second now anyone have

961
00:43:04,380 --> 00:43:06,800
any idea what I'm gonna put their next

962
00:43:06,800 --> 00:43:13,020
copy anything to do a copy so if you go

963
00:43:13,020 --> 00:43:14,760
to the darkest steps of postcards and

964
00:43:14,760 --> 00:43:17,910
use binary copy then you can eat even

965
00:43:17,910 --> 00:43:21,119
more performance out you know nearly up

966
00:43:21,119 --> 00:43:26,400
to 350,000 of these for 350,000 rows of

967
00:43:26,400 --> 00:43:28,710
JSON and I like these bits of JSON

968
00:43:28,710 --> 00:43:30,300
they're about 300 bytes long so the

969
00:43:30,300 --> 00:43:33,630
metrics are similar size to the logs I

970
00:43:33,630 --> 00:43:35,640
mean that's quite a big system you can

971
00:43:35,640 --> 00:43:37,770
handle pretty impressive ingest rate

972
00:43:37,770 --> 00:43:40,560
just by stripping all the processing

973
00:43:40,560 --> 00:43:42,510
away and just shoving it in then having

974
00:43:42,510 --> 00:43:44,700
a there's other background process doing

975
00:43:44,700 --> 00:43:46,859
the processing later on for you and let

976
00:43:46,859 --> 00:43:50,940
it catch up over time possible we could

977
00:43:50,940 --> 00:43:52,380
replace the queue with postcodes as well

978
00:43:52,380 --> 00:43:53,150
which be not

979
00:43:53,150 --> 00:43:55,339
I'm all of our persistent data in one

980
00:43:55,339 --> 00:44:00,500
place so what's kind of the conclusion

981
00:44:00,500 --> 00:44:08,660
of this kind of view post Prez as a as

982
00:44:08,660 --> 00:44:10,670
the hipsters might say data persistence

983
00:44:10,670 --> 00:44:13,609
toolbox there just happens to you sequel

984
00:44:13,609 --> 00:44:15,710
I think a lot of people scared off by

985
00:44:15,710 --> 00:44:18,349
sequel and if I hadn't worked for a

986
00:44:18,349 --> 00:44:20,270
database vendor I might be equally

987
00:44:20,270 --> 00:44:22,190
scared by sequel but I some think it's

988
00:44:22,190 --> 00:44:23,359
useful I still think you can do a lot of

989
00:44:23,359 --> 00:44:26,059
things with it they're kind of a no

990
00:44:26,059 --> 00:44:29,839
sequel crowd like to do I think you

991
00:44:29,839 --> 00:44:32,180
should be scared of it the batteries

992
00:44:32,180 --> 00:44:33,710
aren't always included though you have

993
00:44:33,710 --> 00:44:35,750
to think about your problems and do some

994
00:44:35,750 --> 00:44:37,700
work it's not most present the bespoke

995
00:44:37,700 --> 00:44:39,410
solution for your time series it's not a

996
00:44:39,410 --> 00:44:43,089
bespoke solution for your log searching

997
00:44:43,240 --> 00:44:47,240
it doesn't mean it's hard but reducing

998
00:44:47,240 --> 00:44:49,339
those number of systems can be a huge

999
00:44:49,339 --> 00:44:50,869
operational Vantage if you've got quite

1000
00:44:50,869 --> 00:44:54,440
a small team one bit of software one bit

1001
00:44:54,440 --> 00:44:57,670
of persistence to understand sort of six

1002
00:44:57,670 --> 00:44:59,990
and using deploy what you know and what

1003
00:44:59,990 --> 00:45:02,059
you trust you trust Postgres to store

1004
00:45:02,059 --> 00:45:05,529
your data for you then why not use it

1005
00:45:05,529 --> 00:45:08,350
good idea to me

1006
00:45:08,350 --> 00:45:12,400
so that's it thanks for listening thank

1007
00:45:12,400 --> 00:45:23,550
you very much you do have any questions

1008
00:45:25,980 --> 00:45:30,970
I'll go there that next hello can you

1009
00:45:30,970 --> 00:45:33,730
tell us what kind of hardware and main

1010
00:45:33,730 --> 00:45:36,250
settings you were running on that 45

1011
00:45:36,250 --> 00:45:39,250
million queries sorry it logs that were

1012
00:45:39,250 --> 00:45:41,860
entering Posterous and yes it was my

1013
00:45:41,860 --> 00:45:45,180
laptop oh okay

1014
00:45:45,510 --> 00:45:49,960
tuning settings and no I was I had a my

1015
00:45:49,960 --> 00:45:52,440
poster is running in an lxd container

1016
00:45:52,440 --> 00:45:56,530
stock woody fault default config yep

1017
00:45:56,530 --> 00:45:58,510
just installed it so we can make it

1018
00:45:58,510 --> 00:46:00,400
better you probably could make a lot

1019
00:46:00,400 --> 00:46:03,300
better yep definitely

1020
00:46:09,640 --> 00:46:15,830
hi you said you could replace the influx

1021
00:46:15,830 --> 00:46:18,800
TV with Postgres and said Griffin I

1022
00:46:18,800 --> 00:46:20,810
could read that but I couldn't find

1023
00:46:20,810 --> 00:46:23,210
anything about Agrafena reading from

1024
00:46:23,210 --> 00:46:26,750
sequel yes you're right so there was a

1025
00:46:26,750 --> 00:46:29,600
graph on a pull request I believe open

1026
00:46:29,600 --> 00:46:30,830
where they were actually building in

1027
00:46:30,830 --> 00:46:32,960
support for sequel databases which is

1028
00:46:32,960 --> 00:46:34,370
quite interesting but what we're

1029
00:46:34,370 --> 00:46:35,810
actually doing here so that monastic

1030
00:46:35,810 --> 00:46:39,230
component I talked about briefly has an

1031
00:46:39,230 --> 00:46:43,310
AP as a HTTP API for storing metrics and

1032
00:46:43,310 --> 00:46:45,470
for obtaining metrics as well on running

1033
00:46:45,470 --> 00:46:47,840
queries and that's a part of an

1034
00:46:47,840 --> 00:46:49,460
OpenStack project it's all been written

1035
00:46:49,460 --> 00:46:51,710
in Python so what they've done is

1036
00:46:51,710 --> 00:46:53,330
they've built a graph on a plug-in that

1037
00:46:53,330 --> 00:46:55,730
talked about API and that's how you're

1038
00:46:55,730 --> 00:46:57,380
accessing their degree so we're not

1039
00:46:57,380 --> 00:46:58,640
actually clearing post grades directly

1040
00:46:58,640 --> 00:47:00,800
but we're going through this kind of API

1041
00:47:00,800 --> 00:47:02,900
layer but if you did if obviously you

1042
00:47:02,900 --> 00:47:04,460
were outside in the OpenStack context

1043
00:47:04,460 --> 00:47:07,490
then it might be worth keeping an eye on

1044
00:47:07,490 --> 00:47:10,190
those sequel functionality pull requests

1045
00:47:10,190 --> 00:47:11,930
in graph honor and they look like

1046
00:47:11,930 --> 00:47:15,830
promising one question is this code

1047
00:47:15,830 --> 00:47:19,280
available on github Horizonte and not

1048
00:47:19,280 --> 00:47:21,320
currently though my employees more than

1049
00:47:21,320 --> 00:47:23,960
happy to open source everything we do so

1050
00:47:23,960 --> 00:47:28,310
I can if you drop me an email I can I'll

1051
00:47:28,310 --> 00:47:29,330
let you know when we've made it

1052
00:47:29,330 --> 00:47:31,820
available I only make it available in

1053
00:47:31,820 --> 00:47:34,510
the coming weeks

1054
00:47:42,480 --> 00:47:45,119
how you good all the data in database

1055
00:47:45,119 --> 00:47:48,330
first mmm how we got medics mayor how we

1056
00:47:48,330 --> 00:47:52,590
put them into so the performance test

1057
00:47:52,590 --> 00:47:57,900
will run using copy through a - a little

1058
00:47:57,900 --> 00:48:00,869
bit of a little python shim if you do a

1059
00:48:00,869 --> 00:48:04,290
lot of Python with Postgres inserting

1060
00:48:04,290 --> 00:48:05,970
individual rows or even insert many is

1061
00:48:05,970 --> 00:48:08,040
very inefficient you're much better off

1062
00:48:08,040 --> 00:48:11,280
using copy in like cyclic PG - and then

1063
00:48:11,280 --> 00:48:13,859
you get really really good insert recent

1064
00:48:13,859 --> 00:48:16,980
into post-birth tables and can you tell

1065
00:48:16,980 --> 00:48:19,140
about scale of your instruction just

1066
00:48:19,140 --> 00:48:23,280
monitor it in production so because of

1067
00:48:23,280 --> 00:48:25,410
people who's listening since L is it

1068
00:48:25,410 --> 00:48:27,000
applicable to my infrastructure with

1069
00:48:27,000 --> 00:48:30,570
just so yeah so that sort of an

1070
00:48:30,570 --> 00:48:31,800
interesting point to make really I mean

1071
00:48:31,800 --> 00:48:34,080
this this works because our system

1072
00:48:34,080 --> 00:48:37,680
structures quite small so if you haven't

1073
00:48:37,680 --> 00:48:39,720
got extreme requirements you can make

1074
00:48:39,720 --> 00:48:41,310
your life a lot simpler by doing

1075
00:48:41,310 --> 00:48:43,560
something like this I think so the the

1076
00:48:43,560 --> 00:48:44,730
system we're going to deploy this on

1077
00:48:44,730 --> 00:48:46,410
system I've been testing the scale I

1078
00:48:46,410 --> 00:48:48,990
been testing is eighty nodes with about

1079
00:48:48,990 --> 00:48:51,270
200 metrics coming from each node every

1080
00:48:51,270 --> 00:48:54,330
30 seconds and there's the system we're

1081
00:48:54,330 --> 00:48:55,770
gonna run it on is ludicrously

1082
00:48:55,770 --> 00:48:57,540
overpowered because all these tests were

1083
00:48:57,540 --> 00:49:01,770
run of my Platinum's they should be I

1084
00:49:01,770 --> 00:49:05,900
think you've got to stretch it quite way

1085
00:49:06,500 --> 00:49:10,500
my recommend that when you run a Ingres

1086
00:49:10,500 --> 00:49:14,250
system for the for the high-speed data

1087
00:49:14,250 --> 00:49:16,020
you're collecting that you use it on a

1088
00:49:16,020 --> 00:49:18,420
different Postgres than the one that you

1089
00:49:18,420 --> 00:49:21,060
actually collect the long-term data on

1090
00:49:21,060 --> 00:49:24,960
that's a very good idea but actually

1091
00:49:24,960 --> 00:49:26,940
with the I was having conversation with

1092
00:49:26,940 --> 00:49:27,930
someone Friday actually about

1093
00:49:27,930 --> 00:49:29,640
potentially using the logical

1094
00:49:29,640 --> 00:49:32,550
replication to feed a lot of the so if

1095
00:49:32,550 --> 00:49:33,960
you really want to optimize that

1096
00:49:33,960 --> 00:49:36,540
summarizing process actually feeding it

1097
00:49:36,540 --> 00:49:37,950
asynchronously through the logical

1098
00:49:37,950 --> 00:49:39,869
replication to a different post phrase

1099
00:49:39,869 --> 00:49:43,980
instance means the the summarizing and

1100
00:49:43,980 --> 00:49:45,840
all that extra work we're doing isn't

1101
00:49:45,840 --> 00:49:48,540
holding up loading the data so you

1102
00:49:48,540 --> 00:49:49,920
actually got a load date of a lot faster

1103
00:49:49,920 --> 00:49:51,540
than that so yeah then that's a really

1104
00:49:51,540 --> 00:49:53,900
good point

1105
00:49:53,900 --> 00:50:02,490
any more questions okay thank you very

1106
00:50:02,490 --> 00:50:04,819
much cute

1107
00:50:07,290 --> 00:50:12,239
[Applause]

