1
00:00:04,830 --> 00:00:07,650
thank you for your kind attention to

2
00:00:07,650 --> 00:00:10,110
these tops today without any further

3
00:00:10,110 --> 00:00:11,670
interruption I'd like to introduce

4
00:00:11,670 --> 00:00:15,540
Martin subject from Red Hat check we'll

5
00:00:15,540 --> 00:00:19,170
be talking about affinity rules in the

6
00:00:19,170 --> 00:00:21,250
ups

7
00:00:21,250 --> 00:00:25,179
so good afternoon everybody thanks Brian

8
00:00:25,179 --> 00:00:27,369
for the introduction my name is Martin

9
00:00:27,369 --> 00:00:29,829
Civic I've worked for Red Hat I've been

10
00:00:29,829 --> 00:00:32,829
there since 2007 just quite a long time

11
00:00:32,829 --> 00:00:35,800
and for the past about four and a half

12
00:00:35,800 --> 00:00:37,600
years I've been working on the overt

13
00:00:37,600 --> 00:00:40,960
project there's one assumption about the

14
00:00:40,960 --> 00:00:43,540
overt project that's very fundamental to

15
00:00:43,540 --> 00:00:45,579
all the presentations you've heard today

16
00:00:45,579 --> 00:00:50,079
and that's sorry about that does that

17
00:00:50,079 --> 00:00:52,480
our viens are actually Pat's not cattle

18
00:00:52,480 --> 00:00:54,790
which means we'll do whatever we can to

19
00:00:54,790 --> 00:00:56,470
keep them running and that's why we care

20
00:00:56,470 --> 00:00:58,600
about black migration and that's why

21
00:00:58,600 --> 00:01:01,180
some assumptions and some decisions are

22
00:01:01,180 --> 00:01:04,420
like they are so without further delay

23
00:01:04,420 --> 00:01:08,080
so what I'll be talking about today I'll

24
00:01:08,080 --> 00:01:10,990
be talking about VM affinity so first

25
00:01:10,990 --> 00:01:13,180
I'll actually tell you what we think the

26
00:01:13,180 --> 00:01:16,720
affinity is what use case is we see for

27
00:01:16,720 --> 00:01:19,869
affinity then we'll overview the actual

28
00:01:19,869 --> 00:01:21,900
affinity types we decided to implement

29
00:01:21,900 --> 00:01:25,000
I'll show you something about the finta

30
00:01:25,000 --> 00:01:27,850
conflict I'll talk about the actual

31
00:01:27,850 --> 00:01:30,159
management of affinity and overt and

32
00:01:30,159 --> 00:01:32,350
then I'll discuss some future ideas and

33
00:01:32,350 --> 00:01:36,040
we'll have time for questions so what is

34
00:01:36,040 --> 00:01:39,850
actually affinity affinity as we see it

35
00:01:39,850 --> 00:01:42,159
is basically an attraction factor

36
00:01:42,159 --> 00:01:43,390
between VMs

37
00:01:43,390 --> 00:01:47,290
it means virtual machines might want to

38
00:01:47,290 --> 00:01:49,570
run together or not want to run together

39
00:01:49,570 --> 00:01:52,900
the same applies to virtual machines and

40
00:01:52,900 --> 00:01:54,790
hosts there are certain house that might

41
00:01:54,790 --> 00:01:57,840
be better suited for the VM than others

42
00:01:57,840 --> 00:02:00,670
but that's based on something different

43
00:02:00,670 --> 00:02:03,549
than just hardware considerations it's

44
00:02:03,549 --> 00:02:08,889
just a logical attraction the difference

45
00:02:08,889 --> 00:02:11,230
between affinity which I am going to

46
00:02:11,230 --> 00:02:13,870
describe and VM pinning which you might

47
00:02:13,870 --> 00:02:17,709
know is that when you fix your virtual

48
00:02:17,709 --> 00:02:20,409
machine to a specific host it will stay

49
00:02:20,409 --> 00:02:23,170
there at least in orbit environment no

50
00:02:23,170 --> 00:02:24,790
matter what you do if you want to fix it

51
00:02:24,790 --> 00:02:26,200
to some other house you have to kill it

52
00:02:26,200 --> 00:02:29,790
and restart it currently

53
00:02:32,010 --> 00:02:34,230
Emily

54
00:02:34,230 --> 00:02:36,060
on the other hand when you use affinity

55
00:02:36,060 --> 00:02:38,879
you basically specify the logical rules

56
00:02:38,879 --> 00:02:41,640
like these BMS like to run together

57
00:02:41,640 --> 00:02:45,090
they're good neighbors and when the host

58
00:02:45,090 --> 00:02:47,640
is unsuitable they'll migrate both of

59
00:02:47,640 --> 00:02:49,799
them to the same house to a different

60
00:02:49,799 --> 00:02:52,769
host which means in affinity we support

61
00:02:52,769 --> 00:02:55,260
migrations in Pinter host functionality

62
00:02:55,260 --> 00:02:58,860
we don't now it will also automatically

63
00:02:58,860 --> 00:03:01,799
adapt to the situation on the cluster so

64
00:03:01,799 --> 00:03:03,629
when if you create new affinity rule

65
00:03:03,629 --> 00:03:06,209
we'll do whatever we can to fix that to

66
00:03:06,209 --> 00:03:08,430
migrate VMs where they belong if you

67
00:03:08,430 --> 00:03:11,150
delete one will stop using that rule and

68
00:03:11,150 --> 00:03:13,620
that's also something different when you

69
00:03:13,620 --> 00:03:15,840
change pin to host relationship and the

70
00:03:15,840 --> 00:03:18,090
VM is already running and pin it might

71
00:03:18,090 --> 00:03:21,840
not migrate so why do you actually why

72
00:03:21,840 --> 00:03:23,760
might you want to use affinity in the

73
00:03:23,760 --> 00:03:27,420
first place I listed a couple of topics

74
00:03:27,420 --> 00:03:30,060
and I'll show you all the topics

75
00:03:30,060 --> 00:03:32,640
one-by-one so for example there are

76
00:03:32,640 --> 00:03:34,379
licensing requirements that might

77
00:03:34,379 --> 00:03:36,859
require you to use affinity security

78
00:03:36,859 --> 00:03:39,389
considerations in might get better

79
00:03:39,389 --> 00:03:41,370
performance when certain VMS are

80
00:03:41,370 --> 00:03:44,040
together or are not together you might

81
00:03:44,040 --> 00:03:46,680
get high availability or you might want

82
00:03:46,680 --> 00:03:48,510
to use affinity to prevent high

83
00:03:48,510 --> 00:03:52,260
availability compromises for planning

84
00:03:52,260 --> 00:03:55,230
that's purely management functionality

85
00:03:55,230 --> 00:03:57,690
you can use affinity so your data center

86
00:03:57,690 --> 00:03:59,910
behaves in a way you want it to behave

87
00:03:59,910 --> 00:04:03,690
or customer locality that has something

88
00:04:03,690 --> 00:04:06,900
to do with latency let's start with the

89
00:04:06,900 --> 00:04:09,780
specific use cases so here you can

90
00:04:09,780 --> 00:04:13,709
actually see a affinity well actually

91
00:04:13,709 --> 00:04:15,480
it's a situation where you might want to

92
00:04:15,480 --> 00:04:17,310
use affinity let's assume we have some

93
00:04:17,310 --> 00:04:19,139
kind of software license we have

94
00:04:19,139 --> 00:04:21,539
software that runs on your server inside

95
00:04:21,539 --> 00:04:24,419
virtual machines and it's licensing

96
00:04:24,419 --> 00:04:25,800
model it's pretty benevelon

97
00:04:25,800 --> 00:04:29,370
it's only limits you the number of

98
00:04:29,370 --> 00:04:31,949
physical machines you're allowed to run

99
00:04:31,949 --> 00:04:35,160
the software on so when you run virtual

100
00:04:35,160 --> 00:04:36,720
machines on top of those physical

101
00:04:36,720 --> 00:04:38,520
machines you can actually run multiple

102
00:04:38,520 --> 00:04:39,610
copies on each

103
00:04:39,610 --> 00:04:41,710
physical machine but you still have to

104
00:04:41,710 --> 00:04:44,020
maintain that all the virtual machines

105
00:04:44,020 --> 00:04:48,250
are not violating the actual number of

106
00:04:48,250 --> 00:04:50,020
physical machines that you are allowed

107
00:04:50,020 --> 00:04:52,900
to use so here you see some kind of a

108
00:04:52,900 --> 00:04:55,599
machine that runs the software it only

109
00:04:55,599 --> 00:04:58,930
runs on two physical machines if you

110
00:04:58,930 --> 00:05:00,610
want to run them on to other physical

111
00:05:00,610 --> 00:05:02,860
machines you will have to pay money for

112
00:05:02,860 --> 00:05:05,680
that so if that's a virtual machine you

113
00:05:05,680 --> 00:05:08,979
can set affinity and in this case heart

114
00:05:08,979 --> 00:05:11,550
positive

115
00:05:13,900 --> 00:05:17,830
directly to those other machines that's

116
00:05:17,830 --> 00:05:21,970
actually use case that was requested

117
00:05:21,970 --> 00:05:23,889
that was one of the bugs and one of the

118
00:05:23,889 --> 00:05:25,419
reasons we created this in the first

119
00:05:25,419 --> 00:05:30,090
place so high availability

120
00:05:30,090 --> 00:05:33,250
considerations the first presentation

121
00:05:33,250 --> 00:05:36,310
today by Peter was talking about open

122
00:05:36,310 --> 00:05:40,060
shift running on top of overt well in

123
00:05:40,060 --> 00:05:41,979
that case you're running containers

124
00:05:41,979 --> 00:05:45,639
inside virtual machines and kubernetes

125
00:05:45,639 --> 00:05:48,250
already provides you with availability

126
00:05:48,250 --> 00:05:50,410
configuration with replication manager

127
00:05:50,410 --> 00:05:53,680
but what happens when the hosting

128
00:05:53,680 --> 00:05:56,410
virtual machine runs on the same host as

129
00:05:56,410 --> 00:05:58,240
some other hosting virtual machine and

130
00:05:58,240 --> 00:06:00,610
kubernetes plans your containers to

131
00:06:00,610 --> 00:06:01,960
those two virtual machines that are

132
00:06:01,960 --> 00:06:04,330
running together the physical host can

133
00:06:04,330 --> 00:06:07,240
go down and both two replicas will dive

134
00:06:07,240 --> 00:06:10,060
in in the same instant so you'll

135
00:06:10,060 --> 00:06:11,970
compromise high availability that way

136
00:06:11,970 --> 00:06:15,850
but if you define negative affinity

137
00:06:15,850 --> 00:06:18,160
between those two VMs that will never be

138
00:06:18,160 --> 00:06:20,530
on the same host which will maintain

139
00:06:20,530 --> 00:06:26,320
high availability in this case you might

140
00:06:26,320 --> 00:06:29,680
want to define affinity for security

141
00:06:29,680 --> 00:06:32,470
reasons basically creating sub posters

142
00:06:32,470 --> 00:06:36,099
here I have one of the examples if you

143
00:06:36,099 --> 00:06:38,200
are following security conferences or

144
00:06:38,200 --> 00:06:40,599
watching videos from our conferences it

145
00:06:40,599 --> 00:06:42,550
might sometimes see that there are very

146
00:06:42,550 --> 00:06:45,700
black magic attacks on virtual machines

147
00:06:45,700 --> 00:06:50,349
using cash pay cash based timing attacks

148
00:06:50,349 --> 00:06:53,229
they are basically able to dump bits of

149
00:06:53,229 --> 00:06:56,260
data from the actual CPU and that way

150
00:06:56,260 --> 00:06:58,090
they can actually cross virtual machine

151
00:06:58,090 --> 00:07:01,120
barriers so there are ways although they

152
00:07:01,120 --> 00:07:03,400
are very weird and mathematically

153
00:07:03,400 --> 00:07:07,030
confused and I can't replicate them to

154
00:07:07,030 --> 00:07:09,400
read data from another machine that's

155
00:07:09,400 --> 00:07:12,280
running on the same CPU so if you have

156
00:07:12,280 --> 00:07:15,099
sensitive virtual machines like I have

157
00:07:15,099 --> 00:07:16,780
here virtual machine that's processing

158
00:07:16,780 --> 00:07:19,840
my card payments you don't want to run

159
00:07:19,840 --> 00:07:22,300
them on the same physical host where

160
00:07:22,300 --> 00:07:25,030
you're running some public service where

161
00:07:25,030 --> 00:07:26,860
anybody can start their load

162
00:07:26,860 --> 00:07:29,490
like so am I going to separate them and

163
00:07:29,490 --> 00:07:32,169
again for that you might want to use

164
00:07:32,169 --> 00:07:34,090
affinity you might want to define I

165
00:07:34,090 --> 00:07:36,310
don't negative affinity between those

166
00:07:36,310 --> 00:07:38,759
two VMs you might want to define

167
00:07:38,759 --> 00:07:42,310
positive affinity of both those VMs to

168
00:07:42,310 --> 00:07:49,780
their respective subclusters now another

169
00:07:49,780 --> 00:07:54,389
case storage locality performance

170
00:07:54,389 --> 00:07:57,699
network overhead that all can be solved

171
00:07:57,699 --> 00:07:59,259
by affinity or improved by using

172
00:07:59,259 --> 00:08:02,919
affinity what happens here is you have a

173
00:08:02,919 --> 00:08:05,020
virtual machine again it provides you

174
00:08:05,020 --> 00:08:08,199
some web service here and it needs to

175
00:08:08,199 --> 00:08:10,000
talk to its database it needs to

176
00:08:10,000 --> 00:08:14,319
retrieve the data you put on there some

177
00:08:14,319 --> 00:08:16,419
user uploads the document you need to

178
00:08:16,419 --> 00:08:18,969
save it somewhere so if the other

179
00:08:18,969 --> 00:08:21,460
service your database or storage service

180
00:08:21,460 --> 00:08:24,060
runs on the same node right here

181
00:08:24,060 --> 00:08:27,159
the latency is just matter of basically

182
00:08:27,159 --> 00:08:29,169
mem copy internal somewhere because you

183
00:08:29,169 --> 00:08:30,729
are talking to a virtual machine on the

184
00:08:30,729 --> 00:08:33,099
same node and it's a virtual machine so

185
00:08:33,099 --> 00:08:35,679
all its memory based but if on the other

186
00:08:35,679 --> 00:08:38,828
hand your virtual machine with the

187
00:08:38,828 --> 00:08:40,599
service with the other service database

188
00:08:40,599 --> 00:08:42,880
is running on a different note you're

189
00:08:42,880 --> 00:08:44,649
crossing Network which means you go

190
00:08:44,649 --> 00:08:47,019
through far wall you go through the

191
00:08:47,019 --> 00:08:48,699
network itself maybe a couple of

192
00:08:48,699 --> 00:08:51,699
switches that increases the latency it

193
00:08:51,699 --> 00:08:54,040
might not matter much but if you are

194
00:08:54,040 --> 00:08:56,560
selected you will probably want to have

195
00:08:56,560 --> 00:09:00,810
every milliseconds to your favor

196
00:09:02,500 --> 00:09:06,850
now there are other things with regards

197
00:09:06,850 --> 00:09:09,250
to locality I'll be talking about

198
00:09:09,250 --> 00:09:11,860
something I have an example here

199
00:09:11,860 --> 00:09:16,660
continent locality slightly later but

200
00:09:16,660 --> 00:09:18,640
you also have hardware considerations

201
00:09:18,640 --> 00:09:20,860
and then what I call dynamic sub

202
00:09:20,860 --> 00:09:25,000
clusters now what it is is in our world

203
00:09:25,000 --> 00:09:26,170
in over the world

204
00:09:26,170 --> 00:09:28,660
not all hosts are equal which means you

205
00:09:28,660 --> 00:09:30,610
can have hosts that's very powerful you

206
00:09:30,610 --> 00:09:33,010
can have a host that has special

207
00:09:33,010 --> 00:09:35,500
hardware that accelerates something on

208
00:09:35,500 --> 00:09:36,730
the other hand you can have a host that

209
00:09:36,730 --> 00:09:38,890
has lots of memory and lots of CPU power

210
00:09:38,890 --> 00:09:43,120
but likes the devices and they are

211
00:09:43,120 --> 00:09:45,100
connected to the same cluster so when

212
00:09:45,100 --> 00:09:47,880
you decide where a VM is going to run

213
00:09:47,880 --> 00:09:51,460
you can specify it's basically a soft

214
00:09:51,460 --> 00:09:53,230
what we call soft affinity or weak

215
00:09:53,230 --> 00:09:56,260
affinity which means if the host is

216
00:09:56,260 --> 00:09:58,690
available if there is enough resources

217
00:09:58,690 --> 00:10:01,420
on that host for that VM we will try to

218
00:10:01,420 --> 00:10:04,030
start being there if the host is to load

219
00:10:04,030 --> 00:10:07,300
it then they'll just use whatever host

220
00:10:07,300 --> 00:10:09,670
is available because the service is more

221
00:10:09,670 --> 00:10:11,500
important than the performance in this

222
00:10:11,500 --> 00:10:14,080
case but there is no reason to sacrifice

223
00:10:14,080 --> 00:10:16,120
the performance if you can have it as

224
00:10:16,120 --> 00:10:20,860
well so you can prefer faster CPUs you

225
00:10:20,860 --> 00:10:25,120
can prefer faster Nix faster well faster

226
00:10:25,120 --> 00:10:27,310
Network you can have hosts with hundred

227
00:10:27,310 --> 00:10:30,880
megabits gigabit ten gigabit network on

228
00:10:30,880 --> 00:10:32,350
different level of your infrastructure

229
00:10:32,350 --> 00:10:35,140
and you can place the VM exactly where

230
00:10:35,140 --> 00:10:37,210
it's supposed to be but if the host goes

231
00:10:37,210 --> 00:10:40,270
down it will start somewhere else so the

232
00:10:40,270 --> 00:10:42,190
service is not disrupted it might be

233
00:10:42,190 --> 00:10:46,720
slower but it will be up now dynamic sub

234
00:10:46,720 --> 00:10:49,420
clusters that's something I will

235
00:10:49,420 --> 00:10:52,270
probably explain again slightly later

236
00:10:52,270 --> 00:10:56,770
but for now let's imagine current overt

237
00:10:56,770 --> 00:10:58,840
environment how many of you actually are

238
00:10:58,840 --> 00:11:00,940
familiar with overt how many of you

239
00:11:00,940 --> 00:11:04,210
actually used it okay so that's that's

240
00:11:04,210 --> 00:11:06,760
not that many so let me explain it

241
00:11:06,760 --> 00:11:10,840
slightly simply what you have when you

242
00:11:10,840 --> 00:11:12,790
install overt and when you deploy the

243
00:11:12,790 --> 00:11:13,850
environment

244
00:11:13,850 --> 00:11:15,680
it's basically a set of holes do you

245
00:11:15,680 --> 00:11:17,269
have physical hosts that run your VMs

246
00:11:17,269 --> 00:11:19,130
you have those virtual machines and

247
00:11:19,130 --> 00:11:21,399
those hosts can be grouped into clusters

248
00:11:21,399 --> 00:11:25,130
cluster is a logical entity in overt and

249
00:11:25,130 --> 00:11:28,699
it limits very VM can migrate you can

250
00:11:28,699 --> 00:11:30,680
own only migrated VMs within their

251
00:11:30,680 --> 00:11:33,079
cluster that's how we currently organize

252
00:11:33,079 --> 00:11:36,050
the data center but when you decide that

253
00:11:36,050 --> 00:11:37,940
you're going to move hosts from one

254
00:11:37,940 --> 00:11:41,300
cluster to another one department

255
00:11:41,300 --> 00:11:43,610
doesn't need that many hosts anymore

256
00:11:43,610 --> 00:11:46,370
other departments it's overloaded I need

257
00:11:46,370 --> 00:11:47,569
to get you need to give them one more

258
00:11:47,569 --> 00:11:50,089
host you need to put that host into

259
00:11:50,089 --> 00:11:51,980
maintenance because the cluster might

260
00:11:51,980 --> 00:11:53,720
use different storage it might have a

261
00:11:53,720 --> 00:11:55,819
different configuration and that means

262
00:11:55,819 --> 00:11:57,350
we need to decommission the host

263
00:11:57,350 --> 00:11:59,360
logically move it to the other cluster

264
00:11:59,360 --> 00:12:01,850
started up during the transition phase

265
00:12:01,850 --> 00:12:06,440
it can't run any VMs that's not that

266
00:12:06,440 --> 00:12:08,779
good it works for us

267
00:12:08,779 --> 00:12:12,670
but with affinity you can create

268
00:12:12,670 --> 00:12:16,519
something like LVM on top of cluster

269
00:12:16,519 --> 00:12:19,250
basically you put all your hosts into a

270
00:12:19,250 --> 00:12:22,100
single cluster and then you limit the

271
00:12:22,100 --> 00:12:26,360
migration domains using affinity so when

272
00:12:26,360 --> 00:12:29,420
the need arises when you need to move

273
00:12:29,420 --> 00:12:31,759
one host to another department

274
00:12:31,759 --> 00:12:33,769
you just redefined the affinity and

275
00:12:33,769 --> 00:12:36,920
since they are in the same cluster you

276
00:12:36,920 --> 00:12:39,019
don't need to shut the house down it

277
00:12:39,019 --> 00:12:42,110
will automatically be available for new

278
00:12:42,110 --> 00:12:45,350
VMs we will even migrate some of the VMS

279
00:12:45,350 --> 00:12:48,740
that no longer belong there if you have

280
00:12:48,740 --> 00:12:51,350
virtual machines that do not need any

281
00:12:51,350 --> 00:12:53,899
and if it and do not obey any affinity

282
00:12:53,899 --> 00:12:58,339
rules and you need to just start them to

283
00:12:58,339 --> 00:13:00,470
do some simple tasks we are not loading

284
00:13:00,470 --> 00:13:03,500
anything they can start anywhere so in

285
00:13:03,500 --> 00:13:05,660
this case your whole cluster is

286
00:13:05,660 --> 00:13:07,819
available for those VMs and you can

287
00:13:07,819 --> 00:13:10,160
easily use spare resources if there are

288
00:13:10,160 --> 00:13:12,199
a couple of cycles couple of hundred

289
00:13:12,199 --> 00:13:14,120
megabytes of memory you might use for

290
00:13:14,120 --> 00:13:17,089
something that the department that owns

291
00:13:17,089 --> 00:13:19,670
the host is not utilizing right now we

292
00:13:19,670 --> 00:13:21,240
can start being there and

293
00:13:21,240 --> 00:13:24,330
migrated later or just killed when the

294
00:13:24,330 --> 00:13:26,730
task is done so that's another way where

295
00:13:26,730 --> 00:13:28,470
you can use affinity instead of using

296
00:13:28,470 --> 00:13:35,490
the hard-coded and fixed layout now this

297
00:13:35,490 --> 00:13:38,880
is another case where affinity can be

298
00:13:38,880 --> 00:13:44,190
helpful if you have an application or a

299
00:13:44,190 --> 00:13:48,330
VM that can optimistically use some

300
00:13:48,330 --> 00:13:51,120
hardware resource using PCI pass-through

301
00:13:51,120 --> 00:13:53,790
for example or device pass-through but

302
00:13:53,790 --> 00:13:55,680
if the device is not available it can

303
00:13:55,680 --> 00:13:58,260
software emulate it then you can get

304
00:13:58,260 --> 00:14:01,140
better performance when you use the

305
00:14:01,140 --> 00:14:03,480
right host and better high availability

306
00:14:03,480 --> 00:14:06,890
when the host is not available because

307
00:14:06,890 --> 00:14:09,570
your VM might start on the house that

308
00:14:09,570 --> 00:14:12,270
doesn't have the necessary hardware when

309
00:14:12,270 --> 00:14:14,399
the host becomes available we might

310
00:14:14,399 --> 00:14:16,140
migrate it there and then it will

311
00:14:16,140 --> 00:14:17,880
connect to the device and we'll start

312
00:14:17,880 --> 00:14:20,459
utilizing the accelerators whatever it

313
00:14:20,459 --> 00:14:23,360
can be linked it can be GPU

314
00:14:23,360 --> 00:14:26,579
unfortunately this is still a redditor

315
00:14:26,579 --> 00:14:29,940
theoretical we are working on migration

316
00:14:29,940 --> 00:14:33,600
support for SRA OB for example that's a

317
00:14:33,600 --> 00:14:37,410
virtual network functioning device so

318
00:14:37,410 --> 00:14:39,750
like a network card with many virtual

319
00:14:39,750 --> 00:14:41,100
network cards inside where you can

320
00:14:41,100 --> 00:14:44,100
allocate whatever you want so that's one

321
00:14:44,100 --> 00:14:46,800
of the cases but we still don't support

322
00:14:46,800 --> 00:14:49,170
the migration and honestly I have no

323
00:14:49,170 --> 00:14:51,839
idea if anybody does that's kind of a

324
00:14:51,839 --> 00:14:55,020
the sound of the future but if you have

325
00:14:55,020 --> 00:14:57,690
affinity if you define affinity you can

326
00:14:57,690 --> 00:15:00,450
even now define that the VMS are

327
00:15:00,450 --> 00:15:02,310
supposed to be running on better hosts

328
00:15:02,310 --> 00:15:06,620
again okay

329
00:15:06,620 --> 00:15:09,260
so you can even use affinity for

330
00:15:09,260 --> 00:15:13,040
operations and planning what it means is

331
00:15:13,040 --> 00:15:16,130
let's imagine you have a host and you

332
00:15:16,130 --> 00:15:17,630
know that in half a year

333
00:15:17,630 --> 00:15:20,090
you'll have to decommission it it's too

334
00:15:20,090 --> 00:15:22,070
old you will be replacing it you'll be

335
00:15:22,070 --> 00:15:24,410
moving it to different data center but

336
00:15:24,410 --> 00:15:26,390
you don't want to kill it right now it's

337
00:15:26,390 --> 00:15:28,940
still running VMs it's still good enough

338
00:15:28,940 --> 00:15:33,140
for VMs but if you can avoid it you

339
00:15:33,140 --> 00:15:36,050
would choose to not start any new VM

340
00:15:36,050 --> 00:15:41,000
there just so it's barely empty fairly

341
00:15:41,000 --> 00:15:43,790
empty when when the time comes so you

342
00:15:43,790 --> 00:15:46,340
define soft negative affinity to that

343
00:15:46,340 --> 00:15:50,330
host and we will start the VM there if

344
00:15:50,330 --> 00:15:52,820
we have no other choice or if I don't

345
00:15:52,820 --> 00:15:55,070
hosts are to load it but if you don't

346
00:15:55,070 --> 00:15:57,200
have to we'll just start the VM

347
00:15:57,200 --> 00:16:00,340
elsewhere and so gradually over time

348
00:16:00,340 --> 00:16:04,490
your VM will basically sorry your host

349
00:16:04,490 --> 00:16:06,740
will basically become empty and then

350
00:16:06,740 --> 00:16:08,060
putting it to maintenance and

351
00:16:08,060 --> 00:16:10,460
decommission it become become sorry

352
00:16:10,460 --> 00:16:12,110
putting it to maintenance and be

353
00:16:12,110 --> 00:16:14,390
commissioning it will be much easier

354
00:16:14,390 --> 00:16:16,580
because you won't start any migrations

355
00:16:16,580 --> 00:16:18,980
term it will be basically empty so a

356
00:16:18,980 --> 00:16:21,320
couple of migration of small and

357
00:16:21,320 --> 00:16:24,020
unimportant VMs maybe and the host is

358
00:16:24,020 --> 00:16:28,910
free and disconnected what you might

359
00:16:28,910 --> 00:16:31,250
actually want to do as well is keep some

360
00:16:31,250 --> 00:16:32,840
services together not just for

361
00:16:32,840 --> 00:16:38,360
performance basically for management

362
00:16:38,360 --> 00:16:41,810
reasons because you know that this rack

363
00:16:41,810 --> 00:16:43,820
in the data center is running all your

364
00:16:43,820 --> 00:16:46,070
web services so if you need to plant

365
00:16:46,070 --> 00:16:48,350
power outage you need you know that all

366
00:16:48,350 --> 00:16:52,760
of them are here if you have all the

367
00:16:52,760 --> 00:16:54,500
databases for customers in the same rack

368
00:16:54,500 --> 00:16:56,540
you know that you need to double the

369
00:16:56,540 --> 00:16:58,670
power to the trick it's all management

370
00:16:58,670 --> 00:17:01,760
it's not it's not performance

371
00:17:01,760 --> 00:17:03,470
performance is one of the reasons but

372
00:17:03,470 --> 00:17:05,480
you might have different different

373
00:17:05,480 --> 00:17:07,550
reasons for that just logical just so

374
00:17:07,550 --> 00:17:10,400
you remember where where stuff is that's

375
00:17:10,400 --> 00:17:14,530
another way to do use infinite e for

376
00:17:17,550 --> 00:17:20,920
so I said that I will explain the

377
00:17:20,920 --> 00:17:23,500
locality aspect later later on so now is

378
00:17:23,500 --> 00:17:28,140
the time basically one of the girls you

379
00:17:28,140 --> 00:17:30,850
all have when you are exposing services

380
00:17:30,850 --> 00:17:33,700
on the web for example is to put your

381
00:17:33,700 --> 00:17:35,980
services as close to customers as

382
00:17:35,980 --> 00:17:38,380
possible customer can be internal it can

383
00:17:38,380 --> 00:17:40,000
be another service it can be somebody on

384
00:17:40,000 --> 00:17:42,000
the Internet it doesn't really matter so

385
00:17:42,000 --> 00:17:45,880
in this case I have basically a service

386
00:17:45,880 --> 00:17:47,640
with a client

387
00:17:47,640 --> 00:17:50,590
somewhere service this is the client and

388
00:17:50,590 --> 00:17:52,510
connecting to the closest server there

389
00:17:52,510 --> 00:17:55,090
is you also have some kind of slow

390
00:17:55,090 --> 00:17:58,000
Network the internet you know one

391
00:17:58,000 --> 00:18:02,070
datacenter in Europe one in the US but

392
00:18:02,070 --> 00:18:05,080
currently the user is using the closest

393
00:18:05,080 --> 00:18:06,640
datacenter the latency is better

394
00:18:06,640 --> 00:18:09,550
performance is better but what happens

395
00:18:09,550 --> 00:18:13,750
when your data center goes down well in

396
00:18:13,750 --> 00:18:16,030
this case if it goes down abruptly and

397
00:18:16,030 --> 00:18:17,710
your virtual machines are highly

398
00:18:17,710 --> 00:18:19,720
available in our case what we would do

399
00:18:19,720 --> 00:18:22,450
is we would start the VM again but the

400
00:18:22,450 --> 00:18:25,510
closest house now is the one that's

401
00:18:25,510 --> 00:18:29,500
remote that one your client will still

402
00:18:29,500 --> 00:18:32,260
connect to the service he will probably

403
00:18:32,260 --> 00:18:34,960
notice that the latency is higher the

404
00:18:34,960 --> 00:18:37,510
traceroute is longer but he will still

405
00:18:37,510 --> 00:18:41,350
be able to reach the service now you

406
00:18:41,350 --> 00:18:43,330
don't want to stay in this state for a

407
00:18:43,330 --> 00:18:46,270
while so you will probably work with sis

408
00:18:46,270 --> 00:18:46,990
admin's

409
00:18:46,990 --> 00:18:49,540
and fix it you will fix your data center

410
00:18:49,540 --> 00:18:53,320
so it becomes online again in this case

411
00:18:53,320 --> 00:18:55,510
what happens is we won't stop your

412
00:18:55,510 --> 00:18:56,950
service again and start it in the

413
00:18:56,950 --> 00:18:58,510
closest data center that would disrupt

414
00:18:58,510 --> 00:19:00,820
the service maybe briefly but it would

415
00:19:00,820 --> 00:19:03,250
disrupt the service so our goal in this

416
00:19:03,250 --> 00:19:07,210
case is to utilize as I said our VMs are

417
00:19:07,210 --> 00:19:11,530
pets so to utilize live migration maybe

418
00:19:11,530 --> 00:19:16,540
even using post copy as and explained

419
00:19:16,540 --> 00:19:21,090
before he left the stage which means

420
00:19:21,090 --> 00:19:23,690
the client will be talking to the VM

421
00:19:23,690 --> 00:19:26,730
here and the VM will be slowly migrating

422
00:19:26,730 --> 00:19:29,580
once it's here the client will start

423
00:19:29,580 --> 00:19:31,590
talking to to the closest server again

424
00:19:31,590 --> 00:19:35,669
latency will improve and your system is

425
00:19:35,669 --> 00:19:39,690
ready for all load again this is the

426
00:19:39,690 --> 00:19:43,490
most complicated thing for us because

427
00:19:43,490 --> 00:19:47,370
black migration / slow Network can be

428
00:19:47,370 --> 00:19:50,490
complicated we need to decide whether we

429
00:19:50,490 --> 00:19:52,620
should move the VM right now because we

430
00:19:52,620 --> 00:19:54,570
won't do it immediately I mean the VM is

431
00:19:54,570 --> 00:19:57,360
running on a house suddenly you start a

432
00:19:57,360 --> 00:19:59,279
new host and if we started moving all

433
00:19:59,279 --> 00:20:02,369
the VMS at once we would basically kill

434
00:20:02,369 --> 00:20:04,889
the network with migration so your

435
00:20:04,889 --> 00:20:06,419
client wouldn't be able to reach that

436
00:20:06,419 --> 00:20:08,809
because all the memory will be occupying

437
00:20:08,809 --> 00:20:12,779
all the pipes so basically the algorithm

438
00:20:12,779 --> 00:20:15,509
there is somewhat haze it will decide

439
00:20:15,509 --> 00:20:17,639
where the host is good enough or not it

440
00:20:17,639 --> 00:20:20,220
will start one migration per minute or

441
00:20:20,220 --> 00:20:23,429
not so basically it will slowly migrate

442
00:20:23,429 --> 00:20:26,519
it's not in immediate but the the VMS

443
00:20:26,519 --> 00:20:29,669
will get there eventually it might even

444
00:20:29,669 --> 00:20:31,350
happen that the VM will die before it's

445
00:20:31,350 --> 00:20:33,720
migrated then we will start it on the

446
00:20:33,720 --> 00:20:38,070
first house that depends on your load so

447
00:20:38,070 --> 00:20:40,320
I talked about a couple of different

448
00:20:40,320 --> 00:20:43,889
affinity scenarios and types so it's

449
00:20:43,889 --> 00:20:47,100
just sum them up so I can continue we

450
00:20:47,100 --> 00:20:49,980
basically see four different affinity

451
00:20:49,980 --> 00:20:53,340
types you can see my heart's there the

452
00:20:53,340 --> 00:20:55,409
red heart represents heart positive

453
00:20:55,409 --> 00:20:57,869
infinity heart positive affinity for

454
00:20:57,869 --> 00:21:00,389
virtual machine means it will only run

455
00:21:00,389 --> 00:21:04,519
together with some other virtual machine

456
00:21:04,519 --> 00:21:08,820
or on a specific host if you create a

457
00:21:08,820 --> 00:21:13,019
bigger rule let's say one VM has heart

458
00:21:13,019 --> 00:21:16,470
positive affinity on five hosts four to

459
00:21:16,470 --> 00:21:19,799
five hosts then we'll choose one of

460
00:21:19,799 --> 00:21:22,289
those hosts and we will allow migration

461
00:21:22,289 --> 00:21:24,389
within the affinity group that's the

462
00:21:24,389 --> 00:21:26,519
difference from pinning currently in

463
00:21:26,519 --> 00:21:28,799
overt if you define multiple host

464
00:21:28,799 --> 00:21:31,590
pinning which is rendering rather new

465
00:21:31,590 --> 00:21:33,270
feature as well

466
00:21:33,270 --> 00:21:35,160
we will start the VM on any of those

467
00:21:35,160 --> 00:21:37,830
hosts but we will not allow migration

468
00:21:37,830 --> 00:21:40,140
afterwards with affinity they'll pick

469
00:21:40,140 --> 00:21:42,570
one host and then will allow migration

470
00:21:42,570 --> 00:21:44,880
so if the host is below that will move

471
00:21:44,880 --> 00:21:47,130
the VM to some other house from the same

472
00:21:47,130 --> 00:21:50,910
group now we also have heart- if

473
00:21:50,910 --> 00:21:54,030
anything you might remember that I

474
00:21:54,030 --> 00:21:59,450
talked about that in the case of HH a

475
00:21:59,450 --> 00:22:02,850
system like where you need to put two

476
00:22:02,850 --> 00:22:04,710
VMs apart from each other so not

477
00:22:04,710 --> 00:22:06,840
compromising sorry compromising your

478
00:22:06,840 --> 00:22:09,690
high availability or in the case of

479
00:22:09,690 --> 00:22:13,020
secure versus unsecured hosts so some

480
00:22:13,020 --> 00:22:15,000
VMs should not run on unsecured hosts

481
00:22:15,000 --> 00:22:18,030
because they might be compromisable and

482
00:22:18,030 --> 00:22:22,050
we have the soft variants of those those

483
00:22:22,050 --> 00:22:24,120
are useful for those slow migrations

484
00:22:24,120 --> 00:22:26,190
where you don't care about the situation

485
00:22:26,190 --> 00:22:28,560
right now but you would prefer if it

486
00:22:28,560 --> 00:22:31,140
slowly went to the right host or if it

487
00:22:31,140 --> 00:22:32,850
stayed there but if the host is not

488
00:22:32,850 --> 00:22:35,970
ready or it's to load it you can use

489
00:22:35,970 --> 00:22:40,440
whatever host you want so just to sum it

490
00:22:40,440 --> 00:22:44,300
up we see hard and soft affinity

491
00:22:44,300 --> 00:22:47,910
positive and negative and we allow

492
00:22:47,910 --> 00:22:50,730
applying those rules to VM to VM

493
00:22:50,730 --> 00:22:52,950
relationships and VM to host

494
00:22:52,950 --> 00:22:55,010
relationships

495
00:22:55,010 --> 00:22:57,000
obviously house-to-house doesn't make

496
00:22:57,000 --> 00:22:59,730
any sense because host doesn't move so

497
00:22:59,730 --> 00:23:03,590
now when you create new affinity groups

498
00:23:03,590 --> 00:23:07,760
what you can get is an affinity conflict

499
00:23:07,760 --> 00:23:11,130
look at my example here I hope you liked

500
00:23:11,130 --> 00:23:13,770
my firm year 1 basically in the in the

501
00:23:13,770 --> 00:23:16,280
first case there is some object a and

502
00:23:16,280 --> 00:23:20,160
there's a hard affinity to be those are

503
00:23:20,160 --> 00:23:23,520
let's say those are VMs so there's a VM

504
00:23:23,520 --> 00:23:26,880
a that is hard affinity to be and VM see

505
00:23:26,880 --> 00:23:28,590
that is hard affinity to a and you

506
00:23:28,590 --> 00:23:31,470
create a negative affinity between B and

507
00:23:31,470 --> 00:23:35,520
C that's of obviously a conflict there

508
00:23:35,520 --> 00:23:37,710
is no way for us to solve it because you

509
00:23:37,710 --> 00:23:40,910
declared in different rules that

510
00:23:40,910 --> 00:23:44,940
basically B and C should run together

511
00:23:44,940 --> 00:23:47,629
but shouldn't be running together that's

512
00:23:47,629 --> 00:23:50,669
something we should warn you about we

513
00:23:50,669 --> 00:23:53,789
should maybe prevent you or not that

514
00:23:53,789 --> 00:23:55,549
actually depends

515
00:23:55,549 --> 00:23:59,279
we will definitely warn you because what

516
00:23:59,279 --> 00:24:02,369
might happen is that virtual machine a

517
00:24:02,369 --> 00:24:04,830
might not be running its currently

518
00:24:04,830 --> 00:24:07,379
stopped and you start B and C and in

519
00:24:07,379 --> 00:24:09,869
that case you want B and C to follow the

520
00:24:09,869 --> 00:24:12,840
road if you start a you will start

521
00:24:12,840 --> 00:24:15,690
getting the conflict but if only B and C

522
00:24:15,690 --> 00:24:17,700
is currently running you might actually

523
00:24:17,700 --> 00:24:20,999
want to obey the rule so currently we

524
00:24:20,999 --> 00:24:23,009
won't block you from creating such a

525
00:24:23,009 --> 00:24:27,299
cycle but will warning the other rule is

526
00:24:27,299 --> 00:24:30,210
basically the same thing except H 1 and

527
00:24:30,210 --> 00:24:33,989
H 2 are hosts the two VMs will always

528
00:24:33,989 --> 00:24:37,080
want to run together but virtual machine

529
00:24:37,080 --> 00:24:40,769
a wants to run on host 1 always and

530
00:24:40,769 --> 00:24:43,200
virtual machine B wants to run a host -

531
00:24:43,200 --> 00:24:48,779
and they can't satisfy that while they

532
00:24:48,779 --> 00:24:51,720
are running so if only virtual machine a

533
00:24:51,720 --> 00:24:54,179
is running the rule is fine only virtual

534
00:24:54,179 --> 00:24:56,009
machine B is running the rule is fine as

535
00:24:56,009 --> 00:24:58,080
well but if they are both running again

536
00:24:58,080 --> 00:25:01,979
you have a conflict so we will warn you

537
00:25:01,979 --> 00:25:05,639
again it's up to you as administrators

538
00:25:05,639 --> 00:25:09,139
or designers of the cluster rules to

539
00:25:09,139 --> 00:25:12,419
make sure that this doesn't happen we'll

540
00:25:12,419 --> 00:25:14,129
do whatever we can to help you with that

541
00:25:14,129 --> 00:25:16,159
but we can't fix it

542
00:25:16,159 --> 00:25:18,599
there are certain violations that we

543
00:25:18,599 --> 00:25:20,369
can't fix it if it's simple if it's not

544
00:25:20,369 --> 00:25:23,700
a cycle like this let's say you already

545
00:25:23,700 --> 00:25:25,649
have the virtual machine a running on

546
00:25:25,649 --> 00:25:29,220
host 1 and you create a new rule that

547
00:25:29,220 --> 00:25:31,889
says Virtual Machine shouldn't be

548
00:25:31,889 --> 00:25:34,679
running on host 1 they'll detect that

549
00:25:34,679 --> 00:25:38,070
that's a solvable conflict and part of

550
00:25:38,070 --> 00:25:39,989
the balancing algorithm in overt will

551
00:25:39,989 --> 00:25:43,559
try to slowly fix that up might not be

552
00:25:43,559 --> 00:25:45,929
immediate there might be more important

553
00:25:45,929 --> 00:25:48,809
rules to solve first but we'll see that

554
00:25:48,809 --> 00:25:50,669
and we'll try to migrate the VM to the

555
00:25:50,669 --> 00:25:53,059
right host

556
00:25:54,340 --> 00:26:00,140
so the issue here is this might

557
00:26:00,140 --> 00:26:04,030
conflicted balancing then imagine

558
00:26:04,030 --> 00:26:08,870
balancing based on CPU usage on free

559
00:26:08,870 --> 00:26:11,990
memory on the host and then rules like

560
00:26:11,990 --> 00:26:14,930
soft affinity you need to somehow

561
00:26:14,930 --> 00:26:17,050
specify what's more important to you

562
00:26:17,050 --> 00:26:19,880
because it might be that you care more

563
00:26:19,880 --> 00:26:22,190
about soft affinity than about memory

564
00:26:22,190 --> 00:26:25,370
load you just want the VM to be there if

565
00:26:25,370 --> 00:26:28,700
it's possible if the host is down you

566
00:26:28,700 --> 00:26:30,620
want the VM to start anywhere but if the

567
00:26:30,620 --> 00:26:32,660
host is up you want the VM to run on the

568
00:26:32,660 --> 00:26:34,070
host whatever it takes

569
00:26:34,070 --> 00:26:36,980
on the other hand you might want to run

570
00:26:36,980 --> 00:26:39,380
the VM on the house that's not CPU

571
00:26:39,380 --> 00:26:41,900
overload it and affinity is just the

572
00:26:41,900 --> 00:26:44,360
bonus if it's possible then it's cool

573
00:26:44,360 --> 00:26:46,760
but if it isn't I would rather have the

574
00:26:46,760 --> 00:26:48,800
better performance than obey some

575
00:26:48,800 --> 00:26:52,130
artificial rules and that's again that's

576
00:26:52,130 --> 00:26:54,140
up to you to decide because we can do it

577
00:26:54,140 --> 00:26:56,630
for you currently for us soft affinity

578
00:26:56,630 --> 00:26:59,240
is pretty important the default

579
00:26:59,240 --> 00:27:02,780
implementation which you can change the

580
00:27:02,780 --> 00:27:04,700
default configuration which you can

581
00:27:04,700 --> 00:27:07,310
change says that affinity is 10 times is

582
00:27:07,310 --> 00:27:10,790
important the CPU but you can change

583
00:27:10,790 --> 00:27:13,220
that but you should be aware of is that

584
00:27:13,220 --> 00:27:17,690
when you say that affinity is as

585
00:27:17,690 --> 00:27:20,690
important as the CPU you might get

586
00:27:20,690 --> 00:27:23,270
migration cycles basically the VM will

587
00:27:23,270 --> 00:27:25,550
decide oh I want to migrate here because

588
00:27:25,550 --> 00:27:28,430
soft affinity is telling me that once

589
00:27:28,430 --> 00:27:31,370
it's there it will decide oh but the CPU

590
00:27:31,370 --> 00:27:34,070
is suddenly slightly more loudly than it

591
00:27:34,070 --> 00:27:35,540
was supposed to be and there is a nice

592
00:27:35,540 --> 00:27:37,490
empty house there so it will migrate

593
00:27:37,490 --> 00:27:38,300
somewhere else

594
00:27:38,300 --> 00:27:43,880
and we have certain logic rules that are

595
00:27:43,880 --> 00:27:47,300
preventing this from happening but it's

596
00:27:47,300 --> 00:27:49,430
really just guessing we can't really

597
00:27:49,430 --> 00:27:52,490
tell what will happen in five minutes so

598
00:27:52,490 --> 00:27:54,470
it's soft affinity and balancing have

599
00:27:54,470 --> 00:27:57,670
the same priority you might get

600
00:27:57,670 --> 00:28:00,830
migration cycles so you always need to

601
00:28:00,830 --> 00:28:02,780
decide what's more important with hard

602
00:28:02,780 --> 00:28:04,470
affinity that's easy nothing will

603
00:28:04,470 --> 00:28:06,600
sorry nothing like that will happen

604
00:28:06,600 --> 00:28:08,490
there but if it's soft affinity you need

605
00:28:08,490 --> 00:28:13,470
to be aware of that so we have something

606
00:28:13,470 --> 00:28:15,179
which we call affinity rule enforcement

607
00:28:15,179 --> 00:28:19,380
manager and that's running the alongside

608
00:28:19,380 --> 00:28:21,600
the balancing they are talking to each

609
00:28:21,600 --> 00:28:25,230
others in certain way but they can't do

610
00:28:25,230 --> 00:28:28,080
everything it's not as smart as you can

611
00:28:28,080 --> 00:28:35,340
be so now I describe definitely in

612
00:28:35,340 --> 00:28:37,710
general I mean I assume other projects

613
00:28:37,710 --> 00:28:39,809
my my one who have affinity or over they

614
00:28:39,809 --> 00:28:41,490
have a finitary I know kubernetes

615
00:28:41,490 --> 00:28:45,690
supports affinity now what do we have in

616
00:28:45,690 --> 00:28:48,510
overt in overt we have two different

617
00:28:48,510 --> 00:28:51,030
kinds of affinity we have affinity

618
00:28:51,030 --> 00:28:53,909
labels and we have affinity groups we

619
00:28:53,909 --> 00:28:56,789
decided to do it like this for one

620
00:28:56,789 --> 00:28:59,850
simple reason sometimes you want a data

621
00:28:59,850 --> 00:29:02,130
center and you want rules that are very

622
00:29:02,130 --> 00:29:05,010
simple you just want to declare that

623
00:29:05,010 --> 00:29:07,230
this is a hard affinity these two VMs

624
00:29:07,230 --> 00:29:08,909
are supposed to be always together or

625
00:29:08,909 --> 00:29:11,250
this VM is always supposed to be on this

626
00:29:11,250 --> 00:29:13,500
host or on this group of hosts you don't

627
00:29:13,500 --> 00:29:16,409
want anything complicated and you can

628
00:29:16,409 --> 00:29:18,809
use affinity labels for that there are

629
00:29:18,809 --> 00:29:21,450
simple labels so if you apply the label

630
00:29:21,450 --> 00:29:23,190
to virtual machine you apply the label

631
00:29:23,190 --> 00:29:25,380
to the host and you declared an affinity

632
00:29:25,380 --> 00:29:28,350
group on the other hand you might want

633
00:29:28,350 --> 00:29:31,200
to declare that a virtual machine has

634
00:29:31,200 --> 00:29:33,059
soft positive affinity to another

635
00:29:33,059 --> 00:29:35,130
virtual machine and both of them

636
00:29:35,130 --> 00:29:39,000
together are have soft negative affinity

637
00:29:39,000 --> 00:29:41,490
to a group of hosts and that you can

638
00:29:41,490 --> 00:29:44,100
declare using affinity groups affinity

639
00:29:44,100 --> 00:29:46,320
group is basically I don't have this

640
00:29:46,320 --> 00:29:48,179
dialogue screenshot here but it's

641
00:29:48,179 --> 00:29:50,760
basically a list of virtual machines

642
00:29:50,760 --> 00:29:52,799
with a rule that declares the

643
00:29:52,799 --> 00:29:54,360
relationship between those virtual

644
00:29:54,360 --> 00:29:57,559
machines and list of hosts and

645
00:29:57,559 --> 00:29:59,580
relationship between the declared

646
00:29:59,580 --> 00:30:03,049
virtual machines and the declared host

647
00:30:03,049 --> 00:30:05,940
that supports all different types as you

648
00:30:05,940 --> 00:30:09,430
can see on my icon using my

649
00:30:09,430 --> 00:30:13,210
icons and as I said watch out for the

650
00:30:13,210 --> 00:30:13,900
conflicts

651
00:30:13,900 --> 00:30:16,720
they're totally yours to make and some

652
00:30:16,720 --> 00:30:20,230
most of the time yours to fix we'll do

653
00:30:20,230 --> 00:30:22,660
what we can now

654
00:30:22,660 --> 00:30:26,440
so how our affinity labels work here we

655
00:30:26,440 --> 00:30:28,690
actually have a virtual machine that's

656
00:30:28,690 --> 00:30:31,600
supposed to start and it has two labels

657
00:30:31,600 --> 00:30:34,660
finance and DB and now we have two

658
00:30:34,660 --> 00:30:39,670
physical nodes that can run the VM one

659
00:30:39,670 --> 00:30:42,460
the first one on the top has strong and

660
00:30:42,460 --> 00:30:45,010
finance labels the other one has weak

661
00:30:45,010 --> 00:30:48,670
finance and DB labels our Albert is

662
00:30:48,670 --> 00:30:54,060
checking for whether the the host has

663
00:30:54,060 --> 00:30:57,610
the same labels or more we don't care if

664
00:30:57,610 --> 00:30:59,140
there are more labels than are necessary

665
00:30:59,140 --> 00:31:02,350
but we'll check whether all those labels

666
00:31:02,350 --> 00:31:07,120
on the VM are present on the note as you

667
00:31:07,120 --> 00:31:09,640
can see the DB here is missing so we

668
00:31:09,640 --> 00:31:11,380
will never consider the host where the

669
00:31:11,380 --> 00:31:13,480
DB is missing if we require all the

670
00:31:13,480 --> 00:31:15,640
labels on the VM also on the host if

671
00:31:15,640 --> 00:31:17,740
there are some extra labels we don't

672
00:31:17,740 --> 00:31:21,670
care but the VM specified a requirement

673
00:31:21,670 --> 00:31:25,530
and the host has to match it

674
00:31:27,250 --> 00:31:30,130
so affinity groups as I said define a

675
00:31:30,130 --> 00:31:33,090
group of VMs and their relationship

676
00:31:33,090 --> 00:31:36,280
it also can define one specially a

677
00:31:36,280 --> 00:31:39,070
special value and that's no relationship

678
00:31:39,070 --> 00:31:41,169
at all because in an affinity group you

679
00:31:41,169 --> 00:31:44,350
might want to say that this list of VMs

680
00:31:44,350 --> 00:31:46,659
in the affinity group actually has no

681
00:31:46,659 --> 00:31:48,909
relationship to each other they only

682
00:31:48,909 --> 00:31:52,539
care about the hosts with affinity

683
00:31:52,539 --> 00:31:56,890
labels it's only vm to host or yeah it's

684
00:31:56,890 --> 00:31:58,929
only be able to host and with affinity

685
00:31:58,929 --> 00:32:00,789
groups you can define all the

686
00:32:00,789 --> 00:32:02,710
combinations so we need a way to say

687
00:32:02,710 --> 00:32:05,980
that VM to VM is not important only bm2

688
00:32:05,980 --> 00:32:07,990
host because it's basically one document

689
00:32:07,990 --> 00:32:11,710
with two lists and two rules and you can

690
00:32:11,710 --> 00:32:13,750
also define a group of hosts and their

691
00:32:13,750 --> 00:32:18,130
relationship to the VMS so the current

692
00:32:18,130 --> 00:32:22,480
supported overt we've been supporting VM

693
00:32:22,480 --> 00:32:25,450
to VM affinity since I think over 3.5

694
00:32:25,450 --> 00:32:28,210
that's like a year and a half ago

695
00:32:28,210 --> 00:32:29,530
something like that

696
00:32:29,530 --> 00:32:33,220
and that's supported both in the both in

697
00:32:33,220 --> 00:32:35,169
the web admin in the administration

698
00:32:35,169 --> 00:32:37,990
interface and both and using christie

699
00:32:37,990 --> 00:32:42,370
api and SDKs to support vm to host

700
00:32:42,370 --> 00:32:44,950
affinity since for one that was just

701
00:32:44,950 --> 00:32:46,510
released yesterday if i remember

702
00:32:46,510 --> 00:32:50,620
correctly and that only supports API and

703
00:32:50,620 --> 00:32:52,830
SDK is currently we have no UI for that

704
00:32:52,830 --> 00:32:55,690
affinity labels have been supported

705
00:32:55,690 --> 00:32:59,850
since 4.0 about a year ago or so and

706
00:32:59,850 --> 00:33:02,590
there is a link to a blog post I wrote

707
00:33:02,590 --> 00:33:05,169
about that when it was published so it

708
00:33:05,169 --> 00:33:07,510
will show you all the REST API calls you

709
00:33:07,510 --> 00:33:11,280
can make to make it happen

710
00:33:11,610 --> 00:33:16,990
now future ideas we might want and we

711
00:33:16,990 --> 00:33:18,460
actually want to do that but it's kind

712
00:33:18,460 --> 00:33:22,270
of complicated to do in the current

713
00:33:22,270 --> 00:33:24,760
infrastructure to let you use affinity

714
00:33:24,760 --> 00:33:27,010
label inside the affinity group dialog

715
00:33:27,010 --> 00:33:29,169
basically we would say all the VMS with

716
00:33:29,169 --> 00:33:31,659
this label are part of the affinity

717
00:33:31,659 --> 00:33:33,970
group so you don't have to select them

718
00:33:33,970 --> 00:33:35,950
one by one and if you add a VM to the

719
00:33:35,950 --> 00:33:37,720
label the whole group

720
00:33:37,720 --> 00:33:39,280
automatically apply to it that's

721
00:33:39,280 --> 00:33:40,900
something we are working on but we don't

722
00:33:40,900 --> 00:33:44,380
have it yet and I was thinking about

723
00:33:44,380 --> 00:33:45,880
inversion of a rule you might want to

724
00:33:45,880 --> 00:33:50,590
say run no VMs on this host except this

725
00:33:50,590 --> 00:33:53,350
group I really want to decommission it

726
00:33:53,350 --> 00:33:56,650
so only use this group of important VMs

727
00:33:56,650 --> 00:33:58,690
and run it on the host if it's necessary

728
00:33:58,690 --> 00:34:01,440
but otherwise keep it I'm dead

729
00:34:01,440 --> 00:34:04,840
summary definitely basically allows you

730
00:34:04,840 --> 00:34:06,940
to define complex relationship between

731
00:34:06,940 --> 00:34:10,389
virtual machines and between virtual

732
00:34:10,389 --> 00:34:13,179
machine and a host it's in first diamond

733
00:34:13,179 --> 00:34:17,110
it's enforced dynamically it depends on

734
00:34:17,110 --> 00:34:19,210
the current cluster situation it's not

735
00:34:19,210 --> 00:34:21,219
forcing you to use one specific host

736
00:34:21,219 --> 00:34:23,679
when you define VM to VM strong positive

737
00:34:23,679 --> 00:34:26,080
affinity we don't care if it's if the

738
00:34:26,080 --> 00:34:28,270
VMS are running on a host a or host b

739
00:34:28,270 --> 00:34:30,489
then we'll run together on one of those

740
00:34:30,489 --> 00:34:34,780
hosts so that's it

741
00:34:34,780 --> 00:34:37,949
thank you if you have any questions and

742
00:34:37,949 --> 00:34:40,480
those are good questions I think I have

743
00:34:40,480 --> 00:34:46,810
a USB key for you so yeah you don't

744
00:34:46,810 --> 00:34:52,199
count okay

745
00:34:59,050 --> 00:35:02,230
and the way I guess they solved the

746
00:35:02,230 --> 00:35:05,710
problem with the conflicting rules is to

747
00:35:05,710 --> 00:35:07,750
put them in a sequence so I want this

748
00:35:07,750 --> 00:35:09,670
rule this rule is more important than

749
00:35:09,670 --> 00:35:11,470
this one so you talked about the weights

750
00:35:11,470 --> 00:35:14,050
but if you actually relate them in

751
00:35:14,050 --> 00:35:15,490
importance to one another then you

752
00:35:15,490 --> 00:35:17,460
should be able to resolve the conflicts

753
00:35:17,460 --> 00:35:21,160
yeah summed it up so I don't miss

754
00:35:21,160 --> 00:35:23,140
actually asking better we have some kind

755
00:35:23,140 --> 00:35:25,030
of a rule priority where you would be

756
00:35:25,030 --> 00:35:27,130
able to declare that if there is a

757
00:35:27,130 --> 00:35:29,140
conflict between those two rules this

758
00:35:29,140 --> 00:35:31,810
reveals now currently we don't have any

759
00:35:31,810 --> 00:35:35,080
any rule priority it's actually a good

760
00:35:35,080 --> 00:35:36,670
question we might consider it in the

761
00:35:36,670 --> 00:35:39,100
future but we wanted to have at least

762
00:35:39,100 --> 00:35:41,110
something basic before we start verging

763
00:35:41,110 --> 00:35:42,940
into into the difficulty a difficult

764
00:35:42,940 --> 00:35:48,180
area any other questions

765
00:35:48,180 --> 00:35:52,450
okay then let me invite you to our booth

766
00:35:52,450 --> 00:35:55,780
we are in the main building close to the

767
00:35:55,780 --> 00:36:00,610
home where all the kiosks are we have

768
00:36:00,610 --> 00:36:02,350
over training there so we can take a

769
00:36:02,350 --> 00:36:04,150
look of what we actually support and

770
00:36:04,150 --> 00:36:07,030
talk to the developers thanks for

771
00:36:07,030 --> 00:36:09,420
watching

772
00:36:11,440 --> 00:36:13,500
you

