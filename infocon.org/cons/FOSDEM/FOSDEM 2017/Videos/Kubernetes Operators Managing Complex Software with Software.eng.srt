1
00:00:04,820 --> 00:00:09,270
next up we have Josh wood who started

2
00:00:09,270 --> 00:00:12,990
with our kte rocket containers as soon

3
00:00:12,990 --> 00:00:15,570
as they were to think which led him to a

4
00:00:15,570 --> 00:00:17,910
job at coral s where he manages

5
00:00:17,910 --> 00:00:20,610
documentation and also likes taking

6
00:00:20,610 --> 00:00:23,750
pictures of cats with extra toes yeah so

7
00:00:23,750 --> 00:00:25,830
it's gonna tell us about operators

8
00:00:25,830 --> 00:00:34,680
welcome Wells you who falls down how's

9
00:00:34,680 --> 00:00:40,249
it going so we all love kubernetes right

10
00:00:40,249 --> 00:00:42,899
obviously it's a hot topic in this room

11
00:00:42,899 --> 00:00:44,969
and across the conference this year I

12
00:00:44,969 --> 00:00:47,460
think also last year probably next year

13
00:00:47,460 --> 00:00:50,280
if we're all lucky today we're going to

14
00:00:50,280 --> 00:00:52,109
talk about what's really cool about

15
00:00:52,109 --> 00:00:54,989
kubernetes what makes us love it so much

16
00:00:54,989 --> 00:00:58,469
and then in what I hope is a direct

17
00:00:58,469 --> 00:01:00,239
response to a question that was asked in

18
00:01:00,239 --> 00:01:01,710
a talk one back we're going to talk

19
00:01:01,710 --> 00:01:03,659
about some of the reasons where that

20
00:01:03,659 --> 00:01:06,240
model begins to fall down where the

21
00:01:06,240 --> 00:01:07,950
things we love don't carry through to

22
00:01:07,950 --> 00:01:10,469
managing complex applications on top of

23
00:01:10,469 --> 00:01:12,390
this cluster orchestration system and

24
00:01:12,390 --> 00:01:14,729
the steps we're taking at core OS in the

25
00:01:14,729 --> 00:01:16,680
direction of improving and resolving

26
00:01:16,680 --> 00:01:18,390
that so the kubernetes can be a tool not

27
00:01:18,390 --> 00:01:21,079
only for deploying scaling and

28
00:01:21,079 --> 00:01:23,579
monitoring health and availability of

29
00:01:23,579 --> 00:01:26,850
simple stateless applications but so

30
00:01:26,850 --> 00:01:29,420
that we can also manage deploy and scale

31
00:01:29,420 --> 00:01:32,340
complex stateful applications in terms

32
00:01:32,340 --> 00:01:35,609
of the kubernetes api so to that end

33
00:01:35,609 --> 00:01:37,530
we're going to talk about a concept and

34
00:01:37,530 --> 00:01:40,229
a couple of pieces of software that we

35
00:01:40,229 --> 00:01:43,079
call operators in in the general sense

36
00:01:43,079 --> 00:01:44,310
now

37
00:01:44,310 --> 00:01:46,619
it's Kalei stateless Absalon kubernetes

38
00:01:46,619 --> 00:01:49,259
is really pretty easy if there's

39
00:01:49,259 --> 00:01:50,700
anything that made me really excited

40
00:01:50,700 --> 00:01:52,950
about kubernetes when I first saw

41
00:01:52,950 --> 00:01:54,659
demonstrations of it and started playing

42
00:01:54,659 --> 00:01:56,810
it with a plane playing with it myself

43
00:01:56,810 --> 00:01:59,700
it was how easy it is to take simple

44
00:01:59,700 --> 00:02:03,179
applications web servers anything that

45
00:02:03,179 --> 00:02:04,439
doesn't have a lot of state to carry

46
00:02:04,439 --> 00:02:05,759
around with it and doesn't need a lot of

47
00:02:05,759 --> 00:02:08,429
storage scale it up and down we have

48
00:02:08,429 --> 00:02:10,530
this idea of a replica set we even have

49
00:02:10,530 --> 00:02:12,210
a scale command and we can just point

50
00:02:12,210 --> 00:02:14,400
the scale command at an object in the

51
00:02:14,400 --> 00:02:16,830
kubernetes api with a name and tell it

52
00:02:16,830 --> 00:02:18,460
how many copies we want

53
00:02:18,460 --> 00:02:21,700
of that service that pod whatever that

54
00:02:21,700 --> 00:02:24,250
thing is running kubernetes implements a

55
00:02:24,250 --> 00:02:26,590
reconciliation loop at its heart at the

56
00:02:26,590 --> 00:02:30,490
controlled plane that asks what's our

57
00:02:30,490 --> 00:02:32,710
desired condition does that condition

58
00:02:32,710 --> 00:02:35,020
exist in the cluster and then takes

59
00:02:35,020 --> 00:02:38,170
actions to make the desired state that

60
00:02:38,170 --> 00:02:39,790
we've requested through coop cuddle or

61
00:02:39,790 --> 00:02:42,640
some other control mechanism the actual

62
00:02:42,640 --> 00:02:44,590
state in the cluster in really simple

63
00:02:44,590 --> 00:02:46,090
terms that kind of looks like this

64
00:02:46,090 --> 00:02:48,160
we had one copy that was running we

65
00:02:48,160 --> 00:02:50,290
wanted three in our most recent

66
00:02:50,290 --> 00:02:52,870
reconciliation loop we made sure there

67
00:02:52,870 --> 00:02:55,060
were three in fact it's so easy to

68
00:02:55,060 --> 00:02:56,470
interact in this way with the API that

69
00:02:56,470 --> 00:02:58,480
we can write really nifty control

70
00:02:58,480 --> 00:03:01,950
systems to give us an interface for

71
00:03:01,950 --> 00:03:05,410
adding a few extra replicas of any given

72
00:03:05,410 --> 00:03:10,300
object in the kubernetes cluster but

73
00:03:10,300 --> 00:03:12,900
what about apps that actually do things

74
00:03:12,900 --> 00:03:15,100
what about apps that aren't just static

75
00:03:15,100 --> 00:03:18,040
websites or nginx demos or all the other

76
00:03:18,040 --> 00:03:20,050
really cool things we do when we're

77
00:03:20,050 --> 00:03:21,160
trying to get you excited about

78
00:03:21,160 --> 00:03:23,920
kubernetes what about Postgres databases

79
00:03:23,920 --> 00:03:27,460
what about distributed data stores that

80
00:03:27,460 --> 00:03:31,350
require persistent storage that require

81
00:03:31,350 --> 00:03:36,220
explicit steps for deployment or for

82
00:03:36,220 --> 00:03:39,150
upgrade and lifecycle management cycles

83
00:03:39,150 --> 00:03:43,270
it's very very easy to stick complex

84
00:03:43,270 --> 00:03:45,840
applications in containers and

85
00:03:45,840 --> 00:03:48,880
instantiate them with the classic ideas

86
00:03:48,880 --> 00:03:51,970
from the kubernetes api you could run a

87
00:03:51,970 --> 00:03:55,120
database it's not hard to do but

88
00:03:55,120 --> 00:03:58,090
managing a database in the kubernetes

89
00:03:58,090 --> 00:04:02,140
api is considerably harder particularly

90
00:04:02,140 --> 00:04:05,290
if you lose your internet connection

91
00:04:05,290 --> 00:04:09,680
I actually need my slides for this talk

92
00:04:09,680 --> 00:04:13,490
here we go so for some of the reasons

93
00:04:13,490 --> 00:04:15,170
that finally popped up on the screen to

94
00:04:15,170 --> 00:04:17,149
remind me of what they are it is a

95
00:04:17,149 --> 00:04:18,500
little bit more difficult to manage

96
00:04:18,500 --> 00:04:21,500
purse with persistent storage or any

97
00:04:21,500 --> 00:04:24,110
kind of real state because what

98
00:04:24,110 --> 00:04:25,520
kubernetes would like to do is come

99
00:04:25,520 --> 00:04:26,960
along and treat every app as a discrete

100
00:04:26,960 --> 00:04:28,460
entity with no dependencies on other

101
00:04:28,460 --> 00:04:31,250
applications on other micro services and

102
00:04:31,250 --> 00:04:33,320
when we ask it to scale with that simple

103
00:04:33,320 --> 00:04:34,610
scale some command that we showed

104
00:04:34,610 --> 00:04:36,830
earlier all we get is a new raw fresh

105
00:04:36,830 --> 00:04:39,140
copy of whatever application we were

106
00:04:39,140 --> 00:04:40,940
running we just get another pod running

107
00:04:40,940 --> 00:04:43,250
somewhere else in the cluster we don't

108
00:04:43,250 --> 00:04:45,530
know that that pod was properly prepared

109
00:04:45,530 --> 00:04:50,180
with its persistent volumes where data

110
00:04:50,180 --> 00:04:52,310
is actually written and retrieved we

111
00:04:52,310 --> 00:04:55,070
don't know if that pod matches the

112
00:04:55,070 --> 00:04:57,680
version specifications in the midst of

113
00:04:57,680 --> 00:05:01,120
rolling upgrades and application scaling

114
00:05:01,120 --> 00:05:05,450
we don't know how to back up the data

115
00:05:05,450 --> 00:05:09,650
that's running in existing pods to ad

116
00:05:09,650 --> 00:05:11,990
pods to this collection these are all

117
00:05:11,990 --> 00:05:13,550
things that human administrators are

118
00:05:13,550 --> 00:05:15,320
still forced to interact with even if

119
00:05:15,320 --> 00:05:16,669
they're running their databases on top

120
00:05:16,669 --> 00:05:20,750
of kubernetes if only kubernetes knew

121
00:05:20,750 --> 00:05:25,460
about the the characteristics of complex

122
00:05:25,460 --> 00:05:27,800
applications now fortunately there are

123
00:05:27,800 --> 00:05:30,280
mechanisms for extending kubernetes

124
00:05:30,280 --> 00:05:32,570
designed around the idea of providing

125
00:05:32,570 --> 00:05:35,780
this kind of automation and in the form

126
00:05:35,780 --> 00:05:37,760
of operators these are the steps we've

127
00:05:37,760 --> 00:05:41,300
taken to try to make this work the idea

128
00:05:41,300 --> 00:05:42,680
here is that we want to be able to add

129
00:05:42,680 --> 00:05:45,830
to our current concept of a kubernetes

130
00:05:45,830 --> 00:05:48,380
object and everything has a manifest so

131
00:05:48,380 --> 00:05:51,890
the goal would be let me look at a tamil

132
00:05:51,890 --> 00:05:53,770
output of a manifest and see some

133
00:05:53,770 --> 00:05:56,780
application specific things in that

134
00:05:56,780 --> 00:05:58,970
manifest so in a simple illustrative

135
00:05:58,970 --> 00:06:01,490
case for the purpose of this talk we've

136
00:06:01,490 --> 00:06:04,610
got a database cluster we've got three

137
00:06:04,610 --> 00:06:06,290
machines in it a couple of them are just

138
00:06:06,290 --> 00:06:08,000
read replicas and there's one master

139
00:06:08,000 --> 00:06:11,060
they're all on a version of a datastore

140
00:06:11,060 --> 00:06:13,820
on an API that's spoken between

141
00:06:13,820 --> 00:06:16,400
that that master and and it's it's read

142
00:06:16,400 --> 00:06:20,900
replicas this is a way to explain this

143
00:06:20,900 --> 00:06:23,330
and store it in the kubernetes api this

144
00:06:23,330 --> 00:06:26,150
is about half of what we need to address

145
00:06:26,150 --> 00:06:29,750
complex and stateful applications the

146
00:06:29,750 --> 00:06:33,020
next thing we need is a representation

147
00:06:33,020 --> 00:06:35,690
of all of those special steps and an

148
00:06:35,690 --> 00:06:38,180
administrator may need to take to deploy

149
00:06:38,180 --> 00:06:42,410
or to backup or to upgrade complex

150
00:06:42,410 --> 00:06:46,400
applications we call how we've encoded

151
00:06:46,400 --> 00:06:48,440
that operators and what they really are

152
00:06:48,440 --> 00:06:51,260
is custom controllers in the kubernetes

153
00:06:51,260 --> 00:06:53,930
sense paired with third-party resources

154
00:06:53,930 --> 00:06:57,860
that store the metadata that describe

155
00:06:57,860 --> 00:07:00,590
the special characteristics of complex

156
00:07:00,590 --> 00:07:04,040
applications so to illustrate operators

157
00:07:04,040 --> 00:07:07,190
and their that is on a slide and in a

158
00:07:07,190 --> 00:07:09,170
simple clear sentence if you want to

159
00:07:09,170 --> 00:07:12,470
write it down or take a snapshot the the

160
00:07:12,470 --> 00:07:14,120
easiest way to probably illustrate this

161
00:07:14,120 --> 00:07:16,370
is with a distributed database we've

162
00:07:16,370 --> 00:07:18,650
created a core OS that actually lies at

163
00:07:18,650 --> 00:07:20,720
the heart and soul of kubernetes it's

164
00:07:20,720 --> 00:07:22,760
called at CD it's a fairly simple

165
00:07:22,760 --> 00:07:26,060
distributed key-value store kubernetes

166
00:07:26,060 --> 00:07:28,610
ships it and runs it in the center of

167
00:07:28,610 --> 00:07:30,620
the control plane binaries to maintain

168
00:07:30,620 --> 00:07:33,020
cluster state and do other things many

169
00:07:33,020 --> 00:07:34,910
other applications are also built on top

170
00:07:34,910 --> 00:07:39,410
of Etsy D and Etsy D needs a cluster of

171
00:07:39,410 --> 00:07:41,420
machines that can maintain some kind of

172
00:07:41,420 --> 00:07:46,430
quorum it uses the raft protocol - to

173
00:07:46,430 --> 00:07:48,470
maintain consistency in the data being

174
00:07:48,470 --> 00:07:51,020
stored into this database and it can do

175
00:07:51,020 --> 00:07:53,270
need things like have leader elections

176
00:07:53,270 --> 00:07:55,340
and the event of node failures and do a

177
00:07:55,340 --> 00:07:57,140
lot to maintain its own consistency but

178
00:07:57,140 --> 00:07:59,990
what it can't do is upgrade itself back

179
00:07:59,990 --> 00:08:02,600
itself up and kubernetes doesn't really

180
00:08:02,600 --> 00:08:04,910
know anything about the data stores that

181
00:08:04,910 --> 00:08:08,300
Etsy D is using the other nodes in a net

182
00:08:08,300 --> 00:08:11,810
CD database cluster so what we've done

183
00:08:11,810 --> 00:08:15,950
is written a set of of input

184
00:08:15,950 --> 00:08:17,690
sorry not endpoints what we've done is

185
00:08:17,690 --> 00:08:20,240
taken the third-party resources let me

186
00:08:20,240 --> 00:08:21,890
back up a little bit I apologize for my

187
00:08:21,890 --> 00:08:23,630
disorganization here let's talk about

188
00:08:23,630 --> 00:08:25,700
operators in the general sense just a

189
00:08:25,700 --> 00:08:27,440
little bit we have these comply

190
00:08:27,440 --> 00:08:29,300
applications and the first one we're

191
00:08:29,300 --> 00:08:32,110
going to look at as an example is etsy D

192
00:08:32,110 --> 00:08:34,849
what we want to do is figure out how to

193
00:08:34,849 --> 00:08:36,740
manage those complex applications in

194
00:08:36,740 --> 00:08:39,830
terms of the kubernetes API instead of

195
00:08:39,830 --> 00:08:42,470
needing a secondary API or instead of

196
00:08:42,470 --> 00:08:44,450
always devolve into that application

197
00:08:44,450 --> 00:08:48,710
zone management tools for things like

198
00:08:48,710 --> 00:08:52,310
larger DBMS systems how can we do that

199
00:08:52,310 --> 00:08:54,860
how can we encode the human operator

200
00:08:54,860 --> 00:08:56,330
knowledge that runs these complex

201
00:08:56,330 --> 00:08:58,880
systems well it's by building on two

202
00:08:58,880 --> 00:09:01,160
basic kubernetes concepts and extending

203
00:09:01,160 --> 00:09:03,230
them for our purposes the first are

204
00:09:03,230 --> 00:09:05,990
resources who want where in the cluster

205
00:09:05,990 --> 00:09:08,900
and what is our desired state and the

206
00:09:08,900 --> 00:09:10,850
third-party resources mechanism gives us

207
00:09:10,850 --> 00:09:13,370
a way to extend that for non-native

208
00:09:13,370 --> 00:09:15,440
members of the API so that we can add

209
00:09:15,440 --> 00:09:17,980
our own types to the kubernetes api

210
00:09:17,980 --> 00:09:20,990
secondly we need custom controllers that

211
00:09:20,990 --> 00:09:22,580
understand the meaning of those types

212
00:09:22,580 --> 00:09:25,520
once we've added them to the API and how

213
00:09:25,520 --> 00:09:28,190
to use the information contained in

214
00:09:28,190 --> 00:09:31,990
those custom types on a pod versus on a

215
00:09:31,990 --> 00:09:35,120
jabra services specification in its

216
00:09:35,120 --> 00:09:38,090
manifest to implement some kind of an

217
00:09:38,090 --> 00:09:41,750
observe act and reconciliation loop

218
00:09:41,750 --> 00:09:43,340
sorry observe analyze and act to

219
00:09:43,340 --> 00:09:45,590
reconcile loop in the same way that

220
00:09:45,590 --> 00:09:48,260
controllers in the standard kubernetes

221
00:09:48,260 --> 00:09:50,570
control plane do this for simple

222
00:09:50,570 --> 00:09:53,420
applications so instead of just do I

223
00:09:53,420 --> 00:09:55,780
have the number of copies that I expect

224
00:09:55,780 --> 00:09:58,820
operators can look into additional

225
00:09:58,820 --> 00:10:00,890
third-party resource values for am i

226
00:10:00,890 --> 00:10:03,080
running the version I expect am i

227
00:10:03,080 --> 00:10:07,040
running the the the datastore that's

228
00:10:07,040 --> 00:10:10,670
been agreed among the the group of nodes

229
00:10:10,670 --> 00:10:16,250
in this cluster so a little bit about

230
00:10:16,250 --> 00:10:18,260
third-party resources as I've mentioned

231
00:10:18,260 --> 00:10:19,580
they're a way to extend the kubernetes

232
00:10:19,580 --> 00:10:21,200
api with new object types they're a

233
00:10:21,200 --> 00:10:22,820
little bit like a database schema they

234
00:10:22,820 --> 00:10:24,710
they kind of tell us what the data model

235
00:10:24,710 --> 00:10:27,320
is or tell an operator what the data

236
00:10:27,320 --> 00:10:29,600
model is for a class of application that

237
00:10:29,600 --> 00:10:31,700
the operator will be responsible for for

238
00:10:31,700 --> 00:10:33,050
managing deploying and managing

239
00:10:33,050 --> 00:10:36,320
lifecycle for third party resources were

240
00:10:36,320 --> 00:10:38,540
designed in the kubernetes api for

241
00:10:38,540 --> 00:10:40,800
extending it in exactly this way and

242
00:10:40,800 --> 00:10:42,779
obviously at this URL you can dig into a

243
00:10:42,779 --> 00:10:45,209
little bit more of the specification now

244
00:10:45,209 --> 00:10:49,860
you may know in the in in in the process

245
00:10:49,860 --> 00:10:52,110
or abstract for my talk I promised I

246
00:10:52,110 --> 00:10:55,019
would teach you how to deploy the @ çd

247
00:10:55,019 --> 00:11:01,829
operator here you go so ideally these do

248
00:11:01,829 --> 00:11:04,320
summarize things by taking advantage of

249
00:11:04,320 --> 00:11:07,079
the of the kubernetes api that we can

250
00:11:07,079 --> 00:11:08,190
make some of these things very very

251
00:11:08,190 --> 00:11:08,850
simple

252
00:11:08,850 --> 00:11:10,140
now we're gonna dig into this a little

253
00:11:10,140 --> 00:11:11,640
bit more but this is actually how you

254
00:11:11,640 --> 00:11:13,560
would deploy a net CD cluster on top of

255
00:11:13,560 --> 00:11:15,480
kubernetes and then once you have this

256
00:11:15,480 --> 00:11:19,110
you can automate upgrades this operator

257
00:11:19,110 --> 00:11:20,399
knows how to do a lot of neat things

258
00:11:20,399 --> 00:11:22,470
with that ette CD cluster that you would

259
00:11:22,470 --> 00:11:25,560
formerly have been doing by hand how

260
00:11:25,560 --> 00:11:27,660
does that happen well we've added

261
00:11:27,660 --> 00:11:30,570
third-party resource values that let the

262
00:11:30,570 --> 00:11:32,790
custom controller we have written that

263
00:11:32,790 --> 00:11:35,399
does this management know the things it

264
00:11:35,399 --> 00:11:37,260
needs to know about the state of a net

265
00:11:37,260 --> 00:11:40,079
CD cluster running on kubernetes for

266
00:11:40,079 --> 00:11:42,000
purposes of illustration we can talk

267
00:11:42,000 --> 00:11:44,339
about how many nodes are desired in that

268
00:11:44,339 --> 00:11:47,070
cluster and what version of the ED CD

269
00:11:47,070 --> 00:11:48,899
software should should each of those

270
00:11:48,899 --> 00:11:53,820
nodes be running now let's take a look

271
00:11:53,820 --> 00:11:56,310
at actually walking through a net CD

272
00:11:56,310 --> 00:11:58,560
cluster that's runner that's running on

273
00:11:58,560 --> 00:12:01,680
top of kubernetes as you can see is the

274
00:12:01,680 --> 00:12:03,420
custom controller that we call an

275
00:12:03,420 --> 00:12:04,620
operator goes through this

276
00:12:04,620 --> 00:12:06,660
reconciliation loop the first thing it

277
00:12:06,660 --> 00:12:09,089
does is look at what's going on in the

278
00:12:09,089 --> 00:12:11,579
cluster so we have the set CD cluster

279
00:12:11,579 --> 00:12:13,620
with two nodes in it that we know from

280
00:12:13,620 --> 00:12:15,709
our manifest is supposed to have three

281
00:12:15,709 --> 00:12:18,600
we've got a first node that's actually

282
00:12:18,600 --> 00:12:20,250
running a little bit older version of

283
00:12:20,250 --> 00:12:21,720
the software then that's specified in

284
00:12:21,720 --> 00:12:24,149
the manifest we have a second version

285
00:12:24,149 --> 00:12:26,940
that's running the version we've

286
00:12:26,940 --> 00:12:28,770
specified so that's okay but we're

287
00:12:28,770 --> 00:12:30,870
missing a third node that we ought to

288
00:12:30,870 --> 00:12:34,949
have that forum in this cluster so the

289
00:12:34,949 --> 00:12:37,529
controller based on the information in

290
00:12:37,529 --> 00:12:39,300
the third party resources is able to

291
00:12:39,300 --> 00:12:42,390
analyze the situation that is operating

292
00:12:42,390 --> 00:12:43,980
the cluster right now and compare it to

293
00:12:43,980 --> 00:12:45,990
just like you would for a normal service

294
00:12:45,990 --> 00:12:48,300
but with this extended data compare it

295
00:12:48,300 --> 00:12:50,459
to the desired state and then take

296
00:12:50,459 --> 00:12:52,079
actions to bring that desired state

297
00:12:52,079 --> 00:12:54,240
about in the sed cluster running on top

298
00:12:54,240 --> 00:12:54,420
of

299
00:12:54,420 --> 00:12:57,420
vanetti so what are we gonna do in those

300
00:12:57,420 --> 00:12:59,459
in that scenario and what's special

301
00:12:59,459 --> 00:13:01,529
about it well if this were just a

302
00:13:01,529 --> 00:13:03,089
standard app all we would really be able

303
00:13:03,089 --> 00:13:04,649
to do is say well there's supposed to be

304
00:13:04,649 --> 00:13:05,370
three of them

305
00:13:05,370 --> 00:13:08,670
there's only to start another pod

306
00:13:08,670 --> 00:13:11,100
running but in an in a net CD cluster

307
00:13:11,100 --> 00:13:14,279
that would cause more trouble than than

308
00:13:14,279 --> 00:13:15,630
then it would help you out of your

309
00:13:15,630 --> 00:13:17,820
situation you would have inconsistency

310
00:13:17,820 --> 00:13:20,310
between the two versions the new nodes

311
00:13:20,310 --> 00:13:21,959
you would add you've just added would

312
00:13:21,959 --> 00:13:24,209
not know where the persistent volumes

313
00:13:24,209 --> 00:13:26,550
were at CDs actually storing data are

314
00:13:26,550 --> 00:13:30,510
located and there would have been no

315
00:13:30,510 --> 00:13:33,839
recovery step taken to find out what

316
00:13:33,839 --> 00:13:36,269
happened to this missing member restore

317
00:13:36,269 --> 00:13:38,250
its data and bring it back online before

318
00:13:38,250 --> 00:13:40,829
trying to perform this upgrade so all of

319
00:13:40,829 --> 00:13:42,930
those things are exactly the type of

320
00:13:42,930 --> 00:13:46,410
operations that are currently human

321
00:13:46,410 --> 00:13:49,920
administrator workloads that are encoded

322
00:13:49,920 --> 00:13:53,449
into the at CD operator for kubernetes

323
00:13:53,449 --> 00:13:56,970
the NCD operator knows how to recover

324
00:13:56,970 --> 00:13:59,579
our missing member it knows how to

325
00:13:59,579 --> 00:14:02,850
backup the cluster before attempting the

326
00:14:02,850 --> 00:14:04,920
upgrade to the requested version that's

327
00:14:04,920 --> 00:14:07,290
in our manifest and it knows how to

328
00:14:07,290 --> 00:14:10,199
perform a rolling upgrade to are now

329
00:14:10,199 --> 00:14:12,779
three running cluster nodes and bring

330
00:14:12,779 --> 00:14:17,220
them all to version 3.1 ovett CD the SCP

331
00:14:17,220 --> 00:14:20,160
operator is open source you can dig into

332
00:14:20,160 --> 00:14:23,880
the code at github here at this URL and

333
00:14:23,880 --> 00:14:25,560
I'll review these URLs as we get toward

334
00:14:25,560 --> 00:14:27,630
the end of the talk and kind of a

335
00:14:27,630 --> 00:14:30,180
blanket slide for you to pull out

336
00:14:30,180 --> 00:14:33,449
so what other neat things can we do in

337
00:14:33,449 --> 00:14:36,390
in the basis of with the the groundwork

338
00:14:36,390 --> 00:14:38,399
of operators what are our future plans

339
00:14:38,399 --> 00:14:40,079
and what are we going to continue to do

340
00:14:40,079 --> 00:14:41,130
with that CD because we've already

341
00:14:41,130 --> 00:14:42,660
talked about it being a key part of

342
00:14:42,660 --> 00:14:45,300
kubernetes itself so one of the things

343
00:14:45,300 --> 00:14:47,880
we're gonna do given this mechanism for

344
00:14:47,880 --> 00:14:50,760
managing and easily upgrading and having

345
00:14:50,760 --> 00:14:53,670
a an automated life cycle system for the

346
00:14:53,670 --> 00:14:56,790
at CD key value store is moving it

347
00:14:56,790 --> 00:15:00,420
outside of the the binaries that are

348
00:15:00,420 --> 00:15:01,889
linked and running in the control plane

349
00:15:01,889 --> 00:15:04,440
and actually having a self oded self

350
00:15:04,440 --> 00:15:06,529
hosted at CD cluster for

351
00:15:06,529 --> 00:15:08,319
kubernetes to use that runs

352
00:15:08,319 --> 00:15:11,059
independently of kubernetes but like a

353
00:15:11,059 --> 00:15:14,389
kubernetes application and through these

354
00:15:14,389 --> 00:15:18,069
operators is able to be scheduled scaled

355
00:15:18,069 --> 00:15:21,469
and automatically healed in the same way

356
00:15:21,469 --> 00:15:23,869
as simple applications simple stateless

357
00:15:23,869 --> 00:15:26,439
applications are today on kubernetes

358
00:15:26,439 --> 00:15:29,149
other goals with that are making high

359
00:15:29,149 --> 00:15:31,039
availability setups really really easy

360
00:15:31,039 --> 00:15:34,639
for this kind of software we can already

361
00:15:34,639 --> 00:15:38,269
offer you a what cannot fairly be called

362
00:15:38,269 --> 00:15:39,649
high availability because it doesn't

363
00:15:39,649 --> 00:15:41,809
take the idea of network segmentation

364
00:15:41,809 --> 00:15:44,059
into account but if you just go run the

365
00:15:44,059 --> 00:15:45,799
Yambol file that I showed you a little

366
00:15:45,799 --> 00:15:47,809
bit earlier you will have a three node

367
00:15:47,809 --> 00:15:51,139
at CD cluster with at least subnet

368
00:15:51,139 --> 00:15:53,209
failover then that kind of shows you the

369
00:15:53,209 --> 00:15:56,389
direction that that'll be the the that

370
00:15:56,389 --> 00:15:59,239
you can go there towards getting a Zha

371
00:15:59,239 --> 00:16:02,209
setups we're working on some automated

372
00:16:02,209 --> 00:16:04,449
backups to different popular cloud

373
00:16:04,449 --> 00:16:07,459
object stores right now automated

374
00:16:07,459 --> 00:16:10,489
backups are using kubernetes persistent

375
00:16:10,489 --> 00:16:13,519
volumes which is you know the immediate

376
00:16:13,519 --> 00:16:16,849
API mechanism for for doing this but we

377
00:16:16,849 --> 00:16:21,259
also want to connect that to s3 and GCP

378
00:16:21,259 --> 00:16:24,859
storage and make that very easy as a

379
00:16:24,859 --> 00:16:26,899
choice in the manifest file one of the

380
00:16:26,899 --> 00:16:28,129
other things the team is working on as

381
00:16:28,129 --> 00:16:30,409
we move towards a 1.0 version of the sed

382
00:16:30,409 --> 00:16:33,049
operator is chaos monkey testing to

383
00:16:33,049 --> 00:16:35,779
really stress the edges of the

384
00:16:35,779 --> 00:16:37,549
management of this operator and make

385
00:16:37,549 --> 00:16:39,649
sure that it can actually perform the

386
00:16:39,649 --> 00:16:42,399
functions of a human administrator in

387
00:16:42,399 --> 00:16:45,139
repairing and recovering from edge cases

388
00:16:45,139 --> 00:16:47,839
of failure scenarios that can happen in

389
00:16:47,839 --> 00:16:51,349
@cd clusters so that's a look at the sed

390
00:16:51,349 --> 00:16:54,529
operator as one one glance at how to

391
00:16:54,529 --> 00:16:56,839
introduce the concept of operators on

392
00:16:56,839 --> 00:16:59,509
top of kubernetes my goal here really is

393
00:16:59,509 --> 00:17:02,149
to get you to write operators based on

394
00:17:02,149 --> 00:17:04,279
this open source code to manage your

395
00:17:04,279 --> 00:17:06,648
complex applications and they kind of

396
00:17:06,648 --> 00:17:09,319
give you a way forward there that is a

397
00:17:09,319 --> 00:17:11,269
little bit harder to do if you're trying

398
00:17:11,269 --> 00:17:14,868
to like there there's a there's a an API

399
00:17:14,868 --> 00:17:18,919
object that exists in 1.5 and up called

400
00:17:18,919 --> 00:17:20,119
stateful sets

401
00:17:20,119 --> 00:17:22,220
formerly known as pet sets and several

402
00:17:22,220 --> 00:17:23,599
other names throughout the course of the

403
00:17:23,599 --> 00:17:26,959
project they're similar and lie along

404
00:17:26,959 --> 00:17:29,840
the same lines as this work however they

405
00:17:29,840 --> 00:17:32,090
cannot because of their generality

406
00:17:32,090 --> 00:17:34,510
express the specific conditions of

407
00:17:34,510 --> 00:17:37,010
individual applications in the way that

408
00:17:37,010 --> 00:17:39,380
operators are designed to do so they can

409
00:17:39,380 --> 00:17:41,150
provide part of the groundwork but they

410
00:17:41,150 --> 00:17:43,940
can't encode the specific administrator

411
00:17:43,940 --> 00:17:46,309
knowledge that's encoded into the custom

412
00:17:46,309 --> 00:17:51,260
controllers that we call operators hmm

413
00:17:51,260 --> 00:17:53,960
so what's another operator well we've

414
00:17:53,960 --> 00:17:56,390
written a set of open source operators

415
00:17:56,390 --> 00:17:58,700
in exercising exploring this idea at

416
00:17:58,700 --> 00:18:01,460
core OS we want to look today at two of

417
00:18:01,460 --> 00:18:02,750
them that are really important for

418
00:18:02,750 --> 00:18:04,309
kubernetes because they both kind of

419
00:18:04,309 --> 00:18:06,500
have a native space in kubernetes and

420
00:18:06,500 --> 00:18:09,140
they're both essential for building

421
00:18:09,140 --> 00:18:12,650
modern applications at scale we often

422
00:18:12,650 --> 00:18:14,300
say monitoring is the heart of

423
00:18:14,300 --> 00:18:17,990
production prometheus is a well-known

424
00:18:17,990 --> 00:18:20,120
and I think fairly well liked monitoring

425
00:18:20,120 --> 00:18:22,300
system certainly we hope so

426
00:18:22,300 --> 00:18:25,160
we've we've constructed an operator for

427
00:18:25,160 --> 00:18:27,290
Prometheus which is itself a fairly

428
00:18:27,290 --> 00:18:30,200
complex app with stateful storage of

429
00:18:30,200 --> 00:18:35,030
machine State application state memory

430
00:18:35,030 --> 00:18:37,100
thresholds all the kinds of statistics

431
00:18:37,100 --> 00:18:39,830
that it's that it gathers so much like

432
00:18:39,830 --> 00:18:42,500
at CD it needs a certain arrangement for

433
00:18:42,500 --> 00:18:45,740
deployment it needs to know where data

434
00:18:45,740 --> 00:18:48,890
is stored if you want consistent

435
00:18:48,890 --> 00:18:52,700
long-term collection of statistics and

436
00:18:52,700 --> 00:18:55,580
Prometheus you need to be able to

437
00:18:55,580 --> 00:18:57,650
maintain persistent volumes between

438
00:18:57,650 --> 00:18:59,780
upgrades and rollouts of different

439
00:18:59,780 --> 00:19:02,270
versions of it and more than that you

440
00:19:02,270 --> 00:19:05,150
want to be able to configure targets for

441
00:19:05,150 --> 00:19:07,880
monitoring very very easily and these

442
00:19:07,880 --> 00:19:09,530
are all items that we're trying to move

443
00:19:09,530 --> 00:19:12,559
into logic for the the Prometheus

444
00:19:12,559 --> 00:19:16,550
kubernetes operator so Prometheus is a

445
00:19:16,550 --> 00:19:18,920
monitoring system and this nifty

446
00:19:18,920 --> 00:19:21,050
animated slide I stole from our CTO

447
00:19:21,050 --> 00:19:22,030
Brandon Phillips

448
00:19:22,030 --> 00:19:24,260
so nobody tell him because he flew out

449
00:19:24,260 --> 00:19:25,190
this morning

450
00:19:25,190 --> 00:19:27,290
and I know that he'll never see this

451
00:19:27,290 --> 00:19:32,519
video but anyway this kind of shows

452
00:19:32,519 --> 00:19:34,559
sort of really more about what

453
00:19:34,559 --> 00:19:36,299
Prometheus does than the operator

454
00:19:36,299 --> 00:19:39,149
specifics of it but what we have here is

455
00:19:39,149 --> 00:19:41,219
we're deploying Prometheus one of the

456
00:19:41,219 --> 00:19:42,719
things for me theas has is this idea of

457
00:19:42,719 --> 00:19:46,559
a host information collector so that we

458
00:19:46,559 --> 00:19:49,979
can drill down to the node level which

459
00:19:49,979 --> 00:19:52,499
will cycle around here in just a second

460
00:19:52,499 --> 00:19:56,519
so we can drill down to the node level

461
00:19:56,519 --> 00:19:58,799
and do monitoring either on in terms of

462
00:19:58,799 --> 00:20:03,089
machines and in terms of services and so

463
00:20:03,089 --> 00:20:05,009
what this is actually showing is a

464
00:20:05,009 --> 00:20:10,799
little web service and we're we're doing

465
00:20:10,799 --> 00:20:14,249
some you know raffle hey is a kind of

466
00:20:14,249 --> 00:20:17,039
HTTP stress tester basically we're just

467
00:20:17,039 --> 00:20:18,629
hitting this web service really hard and

468
00:20:18,629 --> 00:20:20,459
showing off a few counters and

469
00:20:20,459 --> 00:20:23,190
Prometheus as we put this kubernetes

470
00:20:23,190 --> 00:20:26,029
service under load

471
00:20:40,760 --> 00:20:46,030
seemed to run a little faster my testing

472
00:20:46,030 --> 00:20:49,700
so that's an idea about Prometheus the

473
00:20:49,700 --> 00:20:52,100
the idea behind the operator is making

474
00:20:52,100 --> 00:20:54,380
the deployment of that kind of

475
00:20:54,380 --> 00:20:56,630
monitoring as simple as possible and

476
00:20:56,630 --> 00:21:00,110
again if you examine the the this is

477
00:21:00,110 --> 00:21:02,000
again open source code and much like

478
00:21:02,000 --> 00:21:05,030
with the sed operator there's a Hamel

479
00:21:05,030 --> 00:21:07,580
manifest file you can do a coop cuddle

480
00:21:07,580 --> 00:21:11,120
create a chef directly from the github

481
00:21:11,120 --> 00:21:14,380
repos and actually deploy Prometheus on

482
00:21:14,380 --> 00:21:20,600
your kubernetes cluster so what our next

483
00:21:20,600 --> 00:21:23,570
steps in terms of operators well we've

484
00:21:23,570 --> 00:21:26,120
worked on these two very closely because

485
00:21:26,120 --> 00:21:28,730
these two projects are so key to

486
00:21:28,730 --> 00:21:30,650
kubernetes and the ecosystem surrounding

487
00:21:30,650 --> 00:21:33,680
it and also key to our deployments of

488
00:21:33,680 --> 00:21:37,430
kubernetes but what we would like to see

489
00:21:37,430 --> 00:21:39,590
is that this becomes kind of a framework

490
00:21:39,590 --> 00:21:43,250
for constructing administration

491
00:21:43,250 --> 00:21:45,320
controllers or as we like to call them

492
00:21:45,320 --> 00:21:47,390
operators that is custom controllers for

493
00:21:47,390 --> 00:21:50,480
the various different kinds of complex

494
00:21:50,480 --> 00:21:53,780
applications with state that that

495
00:21:53,780 --> 00:21:55,430
currently you're deploying by hand and

496
00:21:55,430 --> 00:21:57,680
managing it upgrade at upgrade and

497
00:21:57,680 --> 00:22:01,370
failure cycles by hand because the

498
00:22:01,370 --> 00:22:04,490
default kubernetes api and the regular

499
00:22:04,490 --> 00:22:06,740
kubernetes control plane don't have

500
00:22:06,740 --> 00:22:08,030
enough information about those

501
00:22:08,030 --> 00:22:10,370
applications to manage and scale them in

502
00:22:10,370 --> 00:22:17,000
a complete in a complete way so as

503
00:22:17,000 --> 00:22:20,750
promised here's a bucket list of urls

504
00:22:20,750 --> 00:22:23,480
about the stuff that you can check out I

505
00:22:23,480 --> 00:22:26,030
am running intentionally a little bit

506
00:22:26,030 --> 00:22:29,720
short because what I'm hoping is that we

507
00:22:29,720 --> 00:22:32,600
can get into some questions and maybe I

508
00:22:32,600 --> 00:22:36,440
can draw out a little bit of what you'd

509
00:22:36,440 --> 00:22:38,030
really like to know about this stuff

510
00:22:38,030 --> 00:22:40,280
rather than trying to take a rapid guess

511
00:22:40,280 --> 00:22:41,870
at it all so these slides will be

512
00:22:41,870 --> 00:22:43,310
available for folks who are trying to

513
00:22:43,310 --> 00:22:46,670
take snapshots of the URLs so don't

514
00:22:46,670 --> 00:22:49,490
worry too much about that a few notes

515
00:22:49,490 --> 00:22:51,320
before I ask you if you have any

516
00:22:51,320 --> 00:22:54,000
questions we do would

517
00:22:54,000 --> 00:22:55,590
if you'd come and join us in San

518
00:22:55,590 --> 00:22:57,390
Francisco for our own conference course

519
00:22:57,390 --> 00:23:02,250
best at the end of May we will have some

520
00:23:02,250 --> 00:23:04,050
other detailed talks about open source

521
00:23:04,050 --> 00:23:06,570
projects that that we produce that fit

522
00:23:06,570 --> 00:23:10,800
into the platform and a number of great

523
00:23:10,800 --> 00:23:12,990
speakers from our partners in the

524
00:23:12,990 --> 00:23:15,120
ecosystem I was just trying to get Josh

525
00:23:15,120 --> 00:23:17,190
burkas to promise me that he would come

526
00:23:17,190 --> 00:23:22,770
and talk during core OS fest and I

527
00:23:22,770 --> 00:23:26,130
appreciate your time thank you very much

528
00:23:26,130 --> 00:23:39,870
does anybody have any questions how

529
00:23:39,870 --> 00:23:41,100
about you because I'll be able to hear

530
00:23:41,100 --> 00:24:04,620
you actually yeah that's a good question

531
00:24:04,620 --> 00:24:06,750
I'm one of the things I think it might

532
00:24:06,750 --> 00:24:08,550
even I may have run right past it on the

533
00:24:08,550 --> 00:24:13,680
slide but but sorry oh okay the question

534
00:24:13,680 --> 00:24:16,200
really was if I switch to using

535
00:24:16,200 --> 00:24:18,840
operators will that caused me to be

536
00:24:18,840 --> 00:24:21,660
limited in actions I can then take as an

537
00:24:21,660 --> 00:24:23,670
administrator will I need to be

538
00:24:23,670 --> 00:24:26,400
hands-off of that software because I

539
00:24:26,400 --> 00:24:29,130
could change expectations the operator

540
00:24:29,130 --> 00:24:32,940
now expects to be managing it and and

541
00:24:32,940 --> 00:24:35,610
will administrators trying to come in

542
00:24:35,610 --> 00:24:37,710
after the fact and administrate it break

543
00:24:37,710 --> 00:24:39,960
those expectations the answer really at

544
00:24:39,960 --> 00:24:41,580
least for the two that I've described

545
00:24:41,580 --> 00:24:43,200
here today and at CDs the one I'm most

546
00:24:43,200 --> 00:24:44,790
familiar with so I'll talk about it is

547
00:24:44,790 --> 00:24:49,830
yes once you've deployed at CD with the

548
00:24:49,830 --> 00:24:53,390
operator the expectation is like and

549
00:24:53,390 --> 00:24:55,950
number one we're not at 1.0 yet so I

550
00:24:55,950 --> 00:24:58,650
can't honor this guarantee yet but 1.0

551
00:24:58,650 --> 00:25:01,620
will honor this contract the operator

552
00:25:01,620 --> 00:25:03,720
will be backwards compatible so that it

553
00:25:03,720 --> 00:25:06,929
won't break your old stuff but it will

554
00:25:06,929 --> 00:25:07,740
expect to

555
00:25:07,740 --> 00:25:11,190
control upgrades failover redeployment

556
00:25:11,190 --> 00:25:14,610
recovery backups all of those things

557
00:25:14,610 --> 00:25:16,559
will then be expected to happen in terms

558
00:25:16,559 --> 00:25:19,350
of the operator instead of in terms of

559
00:25:19,350 --> 00:25:22,080
at CDs tooling or you know your own

560
00:25:22,080 --> 00:25:24,210
approaches you know muddling config

561
00:25:24,210 --> 00:25:25,650
files or anything like that behind the

562
00:25:25,650 --> 00:25:28,470
scenes so currently at least what these

563
00:25:28,470 --> 00:25:30,780
two has implemented the idea is very

564
00:25:30,780 --> 00:25:33,059
much for the admin to handover that

565
00:25:33,059 --> 00:25:37,140
control to to the operator now you could

566
00:25:37,140 --> 00:25:39,630
write an operator that you know gave you

567
00:25:39,630 --> 00:25:41,490
different guarantees or expected

568
00:25:41,490 --> 00:25:43,800
administrative interference or did

569
00:25:43,800 --> 00:25:46,290
checks for different kinds of expected

570
00:25:46,290 --> 00:25:48,270
administrative interference but but at

571
00:25:48,270 --> 00:25:49,679
least with the Exedy and the Prometheus

572
00:25:49,679 --> 00:25:51,630
operators and a few of the closed source

573
00:25:51,630 --> 00:25:53,280
ones that that we have that I know as

574
00:25:53,280 --> 00:25:55,830
they exist today they're all pretty much

575
00:25:55,830 --> 00:25:59,460
like a branch we're now on an operator

576
00:25:59,460 --> 00:26:00,750
branch and we really don't want to do

577
00:26:00,750 --> 00:26:04,740
manual human administration and sort of

578
00:26:04,740 --> 00:26:08,179
the point right it's a good answer oh

579
00:26:08,179 --> 00:26:11,070
wait let's bounce around a little how

580
00:26:11,070 --> 00:26:13,399
about here

581
00:26:16,620 --> 00:26:19,840
[Music]

582
00:26:25,590 --> 00:26:28,050
the question is will there be an

583
00:26:28,050 --> 00:26:32,330
operator for kubernetes Federation so

584
00:26:32,330 --> 00:26:33,929
probably first a little bit of

585
00:26:33,929 --> 00:26:37,950
background kubernetes Federation is what

586
00:26:37,950 --> 00:26:39,420
you might say how you deal with having

587
00:26:39,420 --> 00:26:42,210
too much success like your one cluster

588
00:26:42,210 --> 00:26:45,000
in one region is now no longer enough to

589
00:26:45,000 --> 00:26:46,470
provide availability even though it has

590
00:26:46,470 --> 00:26:47,850
a hundred thousand nodes in it so you

591
00:26:47,850 --> 00:26:50,309
want to start having that cluster or

592
00:26:50,309 --> 00:26:52,140
having clusters in more than one region

593
00:26:52,140 --> 00:26:53,940
but which have hierarchical

594
00:26:53,940 --> 00:26:56,670
relationships to one another that's what

595
00:26:56,670 --> 00:27:00,410
Federation is all about certainly

596
00:27:00,410 --> 00:27:03,090
certainly it's part of the idea behind

597
00:27:03,090 --> 00:27:05,400
some of this work right like that's a

598
00:27:05,400 --> 00:27:07,050
direction we would like to go is there

599
00:27:07,050 --> 00:27:09,300
code that I would show you today that I

600
00:27:09,300 --> 00:27:11,850
know all about inside and out no but as

601
00:27:11,850 --> 00:27:14,160
Federation matures yes I expect and

602
00:27:14,160 --> 00:27:16,200
here's why we already deployed

603
00:27:16,200 --> 00:27:18,750
kubernetes in terms of itself this is

604
00:27:18,750 --> 00:27:20,669
not what my talk is about but one other

605
00:27:20,669 --> 00:27:20,980
thing

606
00:27:20,980 --> 00:27:24,909
that that operators underlie is this

607
00:27:24,909 --> 00:27:26,769
larger concept that we call self-driving

608
00:27:26,769 --> 00:27:29,200
infrastructure we think the whole stack

609
00:27:29,200 --> 00:27:31,929
ought to do this the operating system

610
00:27:31,929 --> 00:27:33,429
ought to update itself when there are

611
00:27:33,429 --> 00:27:36,100
security updates right core OS container

612
00:27:36,100 --> 00:27:38,700
Linux does that that's kind of its thing

613
00:27:38,700 --> 00:27:42,039
we think the cluster orchestration

614
00:27:42,039 --> 00:27:44,500
system ought to manage itself in terms

615
00:27:44,500 --> 00:27:47,139
of itself or be self hosted if that

616
00:27:47,139 --> 00:27:48,539
makes any sense

617
00:27:48,539 --> 00:27:51,490
and by that I mean when you upgrade

618
00:27:51,490 --> 00:27:53,769
kubernetes we think that you should

619
00:27:53,769 --> 00:27:55,690
issue a coop cuddle rolling upgrade

620
00:27:55,690 --> 00:27:57,370
command to upgrade the kubernetes

621
00:27:57,370 --> 00:27:58,960
control plane components it should be

622
00:27:58,960 --> 00:28:03,389
self hosting when you deploy kubernetes

623
00:28:03,389 --> 00:28:06,299
federated clusters we think eventually

624
00:28:06,299 --> 00:28:08,919
you know in the in the long term how's

625
00:28:08,919 --> 00:28:10,299
this really work what's it look like

626
00:28:10,299 --> 00:28:13,000
when it's mature those federated

627
00:28:13,000 --> 00:28:15,010
clusters should also be deployed in

628
00:28:15,010 --> 00:28:17,200
terms of the kubernetes api and managed

629
00:28:17,200 --> 00:28:19,899
in terms of the kubernetes api verbs

630
00:28:19,899 --> 00:28:21,789
right i mean that would be the ideal

631
00:28:21,789 --> 00:28:24,760
world would be that the kubernetes api

632
00:28:24,760 --> 00:28:27,970
sort of becomes what POSIX has been for

633
00:28:27,970 --> 00:28:30,549
30 years as here is a basic set of

634
00:28:30,549 --> 00:28:33,279
services and a rely at a basic

635
00:28:33,279 --> 00:28:34,960
architecture that applications can

636
00:28:34,960 --> 00:28:39,940
expect to be in place and then extend on

637
00:28:39,940 --> 00:28:42,669
top of to provide the services that they

638
00:28:42,669 --> 00:28:45,580
want to provide you know so so the idea

639
00:28:45,580 --> 00:28:47,649
is that that we want to make the the

640
00:28:47,649 --> 00:28:49,929
kate's api the way to manage any

641
00:28:49,929 --> 00:28:52,830
application that's going to scale across

642
00:28:52,830 --> 00:28:56,409
computer heads or clusters fair enough

643
00:28:56,409 --> 00:28:59,559
answer it's not a promise but yeah

644
00:28:59,559 --> 00:29:01,720
probably like and if we don't like you

645
00:29:01,720 --> 00:29:02,799
should write it you could write it

646
00:29:02,799 --> 00:29:08,230
before we do you've had your hand up for

647
00:29:08,230 --> 00:29:10,350
a while

648
00:29:19,510 --> 00:29:23,030
currently absolutely yes right now this

649
00:29:23,030 --> 00:29:24,650
would be it like right now what you'd

650
00:29:24,650 --> 00:29:27,020
use the operator for the NCD up first of

651
00:29:27,020 --> 00:29:28,220
all let me repeat your question which I

652
00:29:28,220 --> 00:29:58,760
keep forgetting okay well first of all

653
00:29:58,760 --> 00:30:01,070
let me repeat his questions what was the

654
00:30:01,070 --> 00:30:09,050
first one yeah I like it it's much

655
00:30:09,050 --> 00:30:10,840
easier I'm gonna answer that one

656
00:30:10,840 --> 00:30:13,700
no it's he has two good questions one is

657
00:30:13,700 --> 00:30:15,980
is the operator about managing a

658
00:30:15,980 --> 00:30:18,470
separate etsy D cluster or is it about

659
00:30:18,470 --> 00:30:20,150
managing the etsy D that ships with

660
00:30:20,150 --> 00:30:21,920
every kubernetes cluster in the world

661
00:30:21,920 --> 00:30:24,710
the answer to that right now it's about

662
00:30:24,710 --> 00:30:26,990
managing a separate etsy D cluster on

663
00:30:26,990 --> 00:30:29,480
top of kubernetes in the future plans

664
00:30:29,480 --> 00:30:31,010
part this is a part of where we're

665
00:30:31,010 --> 00:30:33,230
headed we want to get the kubernetes

666
00:30:33,230 --> 00:30:35,210
etsy D up out of the heart of that thing

667
00:30:35,210 --> 00:30:36,890
too and manage it much more like a a

668
00:30:36,890 --> 00:30:39,250
regular application and have it not be

669
00:30:39,250 --> 00:30:43,580
if you will so then this second part of

670
00:30:43,580 --> 00:30:46,880
your question is if the controller and

671
00:30:46,880 --> 00:30:49,630
your etsy D cluster all live in the same

672
00:30:49,630 --> 00:30:54,650
subnet what happens when you and I

673
00:30:54,650 --> 00:30:56,060
should say operator what happens when

674
00:30:56,060 --> 00:30:58,490
the operator gets split from the rest of

675
00:30:58,490 --> 00:31:04,810
the @cd cluster the operator is not in

676
00:31:04,960 --> 00:31:06,890
what's the best way to put this the

677
00:31:06,890 --> 00:31:08,330
operator is not essential to the

678
00:31:08,330 --> 00:31:11,150
functioning of the sed database the

679
00:31:11,150 --> 00:31:13,310
operator is a kubernetes controller that

680
00:31:13,310 --> 00:31:16,340
runs a reconciliation loop so what would

681
00:31:16,340 --> 00:31:19,340
break in the situation you describe if

682
00:31:19,340 --> 00:31:21,080
we did no other engineering to try to

683
00:31:21,080 --> 00:31:23,720
rectify it what would break is our

684
00:31:23,720 --> 00:31:24,540
ability

685
00:31:24,540 --> 00:31:28,500
for for the operator to know the

686
00:31:28,500 --> 00:31:31,350
condition of the sed cluster to you know

687
00:31:31,350 --> 00:31:32,940
do all the things we talked about it

688
00:31:32,940 --> 00:31:35,940
doing what wouldn't break is the the

689
00:31:35,940 --> 00:31:38,340
actual operation of the sed cluster so I

690
00:31:38,340 --> 00:31:40,380
mean you know I don't want to pretend

691
00:31:40,380 --> 00:32:13,560
that there's a tie there that my

692
00:32:13,560 --> 00:32:15,540
colleague was just saying and explaining

693
00:32:15,540 --> 00:32:17,940
the situation we described is indeed a

694
00:32:17,940 --> 00:32:20,490
problem but it is no different than the

695
00:32:20,490 --> 00:32:22,740
problem with the standard kubernetes

696
00:32:22,740 --> 00:32:25,290
scheduler in the control plane in a non

697
00:32:25,290 --> 00:32:28,020
federated single subnet kubernetes

698
00:32:28,020 --> 00:32:29,700
cluster sitting in one network space

699
00:32:29,700 --> 00:32:48,120
somewhere so and a fair point I mean at

700
00:32:48,120 --> 00:32:49,740
least what the fair point with our

701
00:32:49,740 --> 00:32:51,570
choice of metaphor if nothing else I

702
00:32:51,570 --> 00:32:53,970
mean I would give you that thank you for

703
00:32:53,970 --> 00:33:00,950
the question how about you

704
00:33:01,200 --> 00:33:10,559
oh yeah actually you can deploy multiple

705
00:33:10,559 --> 00:33:14,190
instances of a net CD cluster with one

706
00:33:14,190 --> 00:33:16,080
operator by giving them different names

707
00:33:16,080 --> 00:33:18,750
much like any other kubernetes object

708
00:33:18,750 --> 00:33:21,210
I'm so sorry that I cannot seem to

709
00:33:21,210 --> 00:33:23,519
remember to repeat folks questions he

710
00:33:23,519 --> 00:33:25,380
asked if operators if you could run more

711
00:33:25,380 --> 00:33:26,820
than one operator so that you could run

712
00:33:26,820 --> 00:33:29,309
more than one copy of your complex

713
00:33:29,309 --> 00:33:31,799
application and the answer is absolutely

714
00:33:31,799 --> 00:33:36,059
yes but more than likely that operator

715
00:33:36,059 --> 00:33:38,130
would be constructed as the sed operator

716
00:33:38,130 --> 00:33:42,269
is to run many instances of whatever

717
00:33:42,269 --> 00:33:44,700
application is designed to manage just

718
00:33:44,700 --> 00:33:46,200
distinguished by name like any other

719
00:33:46,200 --> 00:33:51,169
kubernetes object or service or or pod

720
00:33:52,039 --> 00:34:09,869
how about you okay so the question is is

721
00:34:09,869 --> 00:34:11,489
there something special you have to do

722
00:34:11,489 --> 00:34:14,339
to handle really slow reconciliations

723
00:34:14,339 --> 00:34:19,829
like in how in the event of I presume

724
00:34:19,829 --> 00:34:21,750
connectivity issues are probably going

725
00:34:21,750 --> 00:34:23,969
to be the prime cause of that right of

726
00:34:23,969 --> 00:34:26,339
it and so in a way it relates to the

727
00:34:26,339 --> 00:34:28,290
question we were just asking about sort

728
00:34:28,290 --> 00:34:31,369
of net splits and stuff

729
00:34:35,619 --> 00:34:42,549
oh oh okay actually yeah you just

730
00:34:42,549 --> 00:34:44,079
clarified your question thank you okay

731
00:34:44,079 --> 00:34:48,969
so so the question is can you encode

732
00:34:48,969 --> 00:34:51,699
specific knowledge and operators to deal

733
00:34:51,699 --> 00:34:56,518
with particularly long-running recovery

734
00:34:56,518 --> 00:35:00,640
deployment scaling restoration or backup

735
00:35:00,640 --> 00:35:03,640
tasks the answer is absolutely yes I

736
00:35:03,640 --> 00:35:07,029
mean the the whole point of these custom

737
00:35:07,029 --> 00:35:11,319
controllers is to be able to encode

738
00:35:11,319 --> 00:35:13,920
knowledge of exactly that kind so

739
00:35:13,920 --> 00:35:18,069
forgive me for engaging in you know tech

740
00:35:18,069 --> 00:35:21,400
talk design but you could have a third

741
00:35:21,400 --> 00:35:24,210
party resource that knew something about

742
00:35:24,210 --> 00:35:28,960
expected timings perhaps you could you

743
00:35:28,960 --> 00:35:30,970
know I don't know I can't off the top of

744
00:35:30,970 --> 00:35:32,319
my head I'm not coming up with a dynamic

745
00:35:32,319 --> 00:35:35,440
way to do this so that you really knew

746
00:35:35,440 --> 00:35:38,009
like on a call back oh this job is done

747
00:35:38,009 --> 00:35:40,839
but I mean that would probably be the

748
00:35:40,839 --> 00:35:42,190
direction I would look to go if I were

749
00:35:42,190 --> 00:35:43,210
actually trying to solve this problem

750
00:35:43,210 --> 00:35:45,579
but yeah but the thing is is you would

751
00:35:45,579 --> 00:35:48,190
still use these two basic mechanisms the

752
00:35:48,190 --> 00:35:49,930
idea of a custom controller some little

753
00:35:49,930 --> 00:35:51,819
bit of code that one way or another

754
00:35:51,819 --> 00:35:55,539
knows to wait and a representation of

755
00:35:55,539 --> 00:35:57,519
some kind in in a TPR or third-party

756
00:35:57,519 --> 00:35:59,859
resource of what are we waiting on or

757
00:35:59,859 --> 00:36:01,450
how long are we waiting on it or how do

758
00:36:01,450 --> 00:36:04,210
I know that it's done or when do I give

759
00:36:04,210 --> 00:36:07,210
up or you know whatever it is I mean to

760
00:36:07,210 --> 00:36:09,940
to answer it like for Postgres would be

761
00:36:09,940 --> 00:36:11,710
a little bit over specific but in

762
00:36:11,710 --> 00:36:13,989
general for long-running operations

763
00:36:13,989 --> 00:36:16,119
that's exactly the kind of stuff we

764
00:36:16,119 --> 00:36:18,489
expect to see encoded into people's

765
00:36:18,489 --> 00:36:20,529
custom operators for their own complex

766
00:36:20,529 --> 00:36:23,349
applications I wish I could think of an

767
00:36:23,349 --> 00:36:25,299
example and like the sed operator or

768
00:36:25,299 --> 00:36:26,470
something that kind of matches that

769
00:36:26,470 --> 00:36:27,970
scenario because it is actually a really

770
00:36:27,970 --> 00:36:30,598
good question

771
00:36:32,200 --> 00:36:34,660
I think I've seemed like I really short

772
00:36:34,660 --> 00:36:38,020
the left side of the room so all the way

773
00:36:38,020 --> 00:36:40,450
in the back with the sort of denim me

774
00:36:40,450 --> 00:36:49,540
looking shirt okay the question is how

775
00:36:49,540 --> 00:36:51,630
much are we working with the folks

776
00:36:51,630 --> 00:36:56,350
working on helm and mountain charts and

777
00:36:56,350 --> 00:36:59,500
the answer is we we use a little bit of

778
00:36:59,500 --> 00:37:01,690
that stuff internally and we like those

779
00:37:01,690 --> 00:37:04,090
folks an awful lot and we are all part

780
00:37:04,090 --> 00:37:07,210
of the wider kubernetes community and we

781
00:37:07,210 --> 00:37:09,160
interact at the CN CF which is the

782
00:37:09,160 --> 00:37:10,720
overall copyright holder for the

783
00:37:10,720 --> 00:37:14,920
kubernetes code we are somewhat in

784
00:37:14,920 --> 00:37:17,820
pursuit of not contradictory but

785
00:37:17,820 --> 00:37:22,420
divergent goals you know like we're

786
00:37:22,420 --> 00:37:26,260
working on packaging for production

787
00:37:26,260 --> 00:37:27,910
probably a little bit more than

788
00:37:27,910 --> 00:37:30,250
development I don't want to get ahead of

789
00:37:30,250 --> 00:37:32,350
myself and like try to write policy for

790
00:37:32,350 --> 00:37:35,500
core OSX cathedra but I mean you know

791
00:37:35,500 --> 00:37:40,119
certainly I've spoken out at dais as

792
00:37:40,119 --> 00:37:42,460
offices in Boulder a couple of times so

793
00:37:42,460 --> 00:37:43,960
like they like us well enough to have us

794
00:37:43,960 --> 00:37:47,940
over was that

795
00:37:50,460 --> 00:37:51,720
[Music]

796
00:37:51,720 --> 00:37:55,090
how about unfortunately not you but

797
00:37:55,090 --> 00:38:15,940
right behind you and then maybe oh how

798
00:38:15,940 --> 00:38:22,120
do I okay partially just to make sure I

799
00:38:22,120 --> 00:38:24,460
even heard you this time the question

800
00:38:24,460 --> 00:38:27,670
here is let's say I deploy a database on

801
00:38:27,670 --> 00:38:30,520
kubernetes by using an operator how do I

802
00:38:30,520 --> 00:38:33,130
then interact with it for standard

803
00:38:33,130 --> 00:38:35,620
database operations just querying it in

804
00:38:35,620 --> 00:38:38,290
exactly as you would with that database

805
00:38:38,290 --> 00:38:41,110
as normal tools like it was with the PG

806
00:38:41,110 --> 00:38:46,810
SQL or with the my sequel client oh no

807
00:38:46,810 --> 00:38:50,410
no no it no actually one of the things

808
00:38:50,410 --> 00:38:54,550
that operators would do and this is

809
00:38:54,550 --> 00:38:56,080
something I probably did not do a very

810
00:38:56,080 --> 00:38:57,790
good job of bringing out in my talk

811
00:38:57,790 --> 00:39:00,070
trying to do everything in terms of kind

812
00:39:00,070 --> 00:39:01,720
of standard kubernetes things were

813
00:39:01,720 --> 00:39:05,680
possible so an operator if I my

814
00:39:05,680 --> 00:39:07,780
imaginary operator for a Postgres sequel

815
00:39:07,780 --> 00:39:10,840
database would create a service and a

816
00:39:10,840 --> 00:39:12,850
load balancer pointing to the Postgres

817
00:39:12,850 --> 00:39:16,060
api so that clients could access the

818
00:39:16,060 --> 00:39:18,880
database and that's how you would get

819
00:39:18,880 --> 00:39:20,010
access to the database

820
00:39:20,010 --> 00:39:22,360
just as any other service within

821
00:39:22,360 --> 00:39:24,610
kubernetes by mapping it to to a

822
00:39:24,610 --> 00:39:26,640
kubernetes service

823
00:39:26,640 --> 00:39:29,620
edwin common field repeat I work in a

824
00:39:29,620 --> 00:39:32,200
tool called Patroni and we're looking at

825
00:39:32,200 --> 00:39:34,120
implementing operators on top of

826
00:39:34,120 --> 00:39:36,640
petronia okay which would handle things

827
00:39:36,640 --> 00:39:39,250
like telling the operator to scale so

828
00:39:39,250 --> 00:39:42,430
gonna actually repeat that cool what if

829
00:39:42,430 --> 00:39:43,540
it does that does that have to do with

830
00:39:43,540 --> 00:39:45,670
his question yeah because his question

831
00:39:45,670 --> 00:39:46,990
was do you need something running inside

832
00:39:46,990 --> 00:39:50,040
the container and the answer is yes

833
00:39:50,690 --> 00:39:53,910
yeah I don't think I ever heard your

834
00:39:53,910 --> 00:39:56,520
question very well because I'm trying to

835
00:39:56,520 --> 00:39:59,190
answer a question about how do I use the

836
00:39:59,190 --> 00:40:00,960
database once I deploy it and that's not

837
00:40:00,960 --> 00:40:05,700
your question I think Josh has a much

838
00:40:05,700 --> 00:40:12,210
better yeah so the answer is yes you do

839
00:40:12,210 --> 00:40:13,290
need something running inside the

840
00:40:13,290 --> 00:40:16,440
container because at least you know

841
00:40:16,440 --> 00:40:18,360
normal databases are not designed to be

842
00:40:18,360 --> 00:40:21,300
self managing and so for example I work

843
00:40:21,300 --> 00:40:23,580
on a project called Patroni which

844
00:40:23,580 --> 00:40:25,440
supplies that thing inside the container

845
00:40:25,440 --> 00:40:28,440
and we've been actually working on

846
00:40:28,440 --> 00:40:30,750
implementing the operator pattern for

847
00:40:30,750 --> 00:40:32,820
that because it's exactly what we want

848
00:40:32,820 --> 00:40:35,490
you know in terms of you know you want

849
00:40:35,490 --> 00:40:37,890
to scale you want to back up you want to

850
00:40:37,890 --> 00:40:42,210
repeat other things yeah yes yeah and

851
00:40:42,210 --> 00:40:45,090
something with an API too which is

852
00:40:45,090 --> 00:40:48,300
important and I'm super sorry I'm deaf

853
00:40:48,300 --> 00:40:49,920
and didn't hear your question at first

854
00:40:49,920 --> 00:40:51,600
and start I tried to answer a totally

855
00:40:51,600 --> 00:40:55,170
different one I think we have about five

856
00:40:55,170 --> 00:40:57,060
minutes so you've been very patient and

857
00:40:57,060 --> 00:40:59,810
then all good so

858
00:41:01,190 --> 00:41:08,359
I really can't hear you the question is

859
00:41:08,359 --> 00:41:10,339
do we see the operators concept being up

860
00:41:10,339 --> 00:41:15,829
streamed that is a maybe a question

861
00:41:15,829 --> 00:41:17,839
above my paygrade to some extent I would

862
00:41:17,839 --> 00:41:20,780
say overall if you if you look at the

863
00:41:20,780 --> 00:41:23,890
history of our work on on kubernetes

864
00:41:23,890 --> 00:41:26,960
almost everything we can figure out how

865
00:41:26,960 --> 00:41:29,930
to abstract in a way that we can get it

866
00:41:29,930 --> 00:41:32,750
upstream we try to do that with if you

867
00:41:32,750 --> 00:41:35,599
look at our work on our back and like

868
00:41:35,599 --> 00:41:37,819
you know we did a whole bunch of work on

869
00:41:37,819 --> 00:41:40,579
our back basically that we could have

870
00:41:40,579 --> 00:41:42,500
incorporated into our open source

871
00:41:42,500 --> 00:41:45,050
project called decks but instead we we

872
00:41:45,050 --> 00:41:46,700
did kind of the support parts of it

873
00:41:46,700 --> 00:41:49,609
upstream so that decks could be as

874
00:41:49,609 --> 00:41:51,589
abstract and minimal apart from it and

875
00:41:51,589 --> 00:41:53,780
just work with it be loosely coupled in

876
00:41:53,780 --> 00:41:57,020
the in the best kind of sense so I would

877
00:41:57,020 --> 00:42:02,089
expect we would try but with projects of

878
00:42:02,089 --> 00:42:04,700
this age and this amount of dynamism

879
00:42:04,700 --> 00:42:06,890
right there's so many people involved I

880
00:42:06,890 --> 00:42:08,710
think there's a lot of room for

881
00:42:08,710 --> 00:42:12,380
exploring solutions with code so we have

882
00:42:12,380 --> 00:42:14,359
this idea of an operators pattern

883
00:42:14,359 --> 00:42:17,540
there's the stateful set spat sets thing

884
00:42:17,540 --> 00:42:20,359
that's in kubernetes I would expect and

885
00:42:20,359 --> 00:42:23,630
this is very purely me Josh would not me

886
00:42:23,630 --> 00:42:25,400
core OS or anything official but I would

887
00:42:25,400 --> 00:42:27,980
expect those efforts to learn from one

888
00:42:27,980 --> 00:42:30,410
another to kind of merge towards a

889
00:42:30,410 --> 00:42:32,630
something similar and towards like kind

890
00:42:32,630 --> 00:42:35,060
of a unified view of the universe over

891
00:42:35,060 --> 00:42:37,790
time so that's a really long way of

892
00:42:37,790 --> 00:42:39,770
saying yes I mean you know we would like

893
00:42:39,770 --> 00:42:41,480
to get the the key parts of the

894
00:42:41,480 --> 00:42:44,690
framework of operators be something that

895
00:42:44,690 --> 00:42:47,030
kubernetes makes it easy to write you

896
00:42:47,030 --> 00:42:48,950
know so that you can treat it like an

897
00:42:48,950 --> 00:42:52,310
API for writing management applications

898
00:42:52,310 --> 00:42:55,839
for these kind of complex apps

899
00:43:06,770 --> 00:43:08,869
the question is how difficult is it to

900
00:43:08,869 --> 00:43:11,930
implement an operator and the answer is

901
00:43:11,930 --> 00:43:14,869
I am think I'm singularly ill qualified

902
00:43:14,869 --> 00:43:17,090
to tell you responsible for

903
00:43:17,090 --> 00:43:21,800
documentation but I the thing is is if

904
00:43:21,800 --> 00:43:23,810
you look at the the open source code for

905
00:43:23,810 --> 00:43:25,820
the two demo kind of operator well I

906
00:43:25,820 --> 00:43:27,230
shouldn't call them demo operators what

907
00:43:27,230 --> 00:43:29,090
adds they're they're very much

908
00:43:29,090 --> 00:43:31,099
production operators for us you know and

909
00:43:31,099 --> 00:43:32,450
they're headed towards production

910
00:43:32,450 --> 00:43:35,090
versions but if they're like good

911
00:43:35,090 --> 00:43:37,010
examples for this talk if you look at

912
00:43:37,010 --> 00:43:38,720
the code they're neither one of those

913
00:43:38,720 --> 00:43:41,900
two items are very large code bases and

914
00:43:41,900 --> 00:43:43,480
I think especially in the NCD

915
00:43:43,480 --> 00:43:49,730
operator you see it's not as abstracted

916
00:43:49,730 --> 00:43:51,320
as we want it to eventually be where

917
00:43:51,320 --> 00:43:52,400
they're sort of like an operator

918
00:43:52,400 --> 00:43:54,230
framework and you build operators on top

919
00:43:54,230 --> 00:43:55,640
of that like that maybe as a vision in

920
00:43:55,640 --> 00:43:57,920
the future it's all one big piece right

921
00:43:57,920 --> 00:43:59,869
now but you can kind of see clearly

922
00:43:59,869 --> 00:44:02,210
which are these support pieces that are

923
00:44:02,210 --> 00:44:04,490
generic and deal with the API and which

924
00:44:04,490 --> 00:44:07,130
are the Etsy specific pieces and if I

925
00:44:07,130 --> 00:44:08,660
were going to try to write an operator

926
00:44:08,660 --> 00:44:11,240
tomorrow I would probably begin with

927
00:44:11,240 --> 00:44:14,839
that code and just kind of a mentally

928
00:44:14,839 --> 00:44:16,970
scrape away all the Etsy D specific

929
00:44:16,970 --> 00:44:18,260
stuff and I would be looking at what

930
00:44:18,260 --> 00:44:21,980
basically is the generic basis of like

931
00:44:21,980 --> 00:44:23,660
what operators do when they talk to the

932
00:44:23,660 --> 00:44:27,589
API which really as much functionality

933
00:44:27,589 --> 00:44:29,480
as they potentially enable their

934
00:44:29,480 --> 00:44:31,130
interaction with the API is fairly

935
00:44:31,130 --> 00:44:34,369
simple it revolves around third-party

936
00:44:34,369 --> 00:44:38,330
resources and registration with named

937
00:44:38,330 --> 00:44:40,640
services of that custom controller that

938
00:44:40,640 --> 00:44:42,320
is itself called an operator like

939
00:44:42,320 --> 00:44:43,880
basically just getting that running in

940
00:44:43,880 --> 00:44:48,589
the control plane so the I would expect

941
00:44:48,589 --> 00:44:51,920
that to be a fairly you know narrow bit

942
00:44:51,920 --> 00:44:54,530
of code so is it easy to write operators

943
00:44:54,530 --> 00:44:58,730
well is it easy to encode everything an

944
00:44:58,730 --> 00:45:00,740
experience DBA knows about running

945
00:45:00,740 --> 00:45:03,260
Postgres know it's probably not but my

946
00:45:03,260 --> 00:45:05,119
suggestion would be is that the design

947
00:45:05,119 --> 00:45:07,520
is much tougher than the coding as in so

948
00:45:07,520 --> 00:45:09,380
much software it's much harder to find

949
00:45:09,380 --> 00:45:09,619
out

950
00:45:09,619 --> 00:45:12,170
all the things that person knows than it

951
00:45:12,170 --> 00:45:14,240
is to write them down and go once you

952
00:45:14,240 --> 00:45:19,160
know them does that make any sense and

953
00:45:19,160 --> 00:45:21,079
maybe you can have one more question if

954
00:45:21,079 --> 00:45:30,619
anybody has it all right well I mean

955
00:45:30,619 --> 00:45:33,170
ideally you have some recourse to just

956
00:45:33,170 --> 00:45:35,029
the idea of a reconciliation loop in the

957
00:45:35,029 --> 00:45:36,529
first place if you have some kind of

958
00:45:36,529 --> 00:45:38,359
temporary failure on update like you

959
00:45:38,359 --> 00:45:40,220
can't retrieve a container from some

960
00:45:40,220 --> 00:45:42,890
registry you know kind of simple things

961
00:45:42,890 --> 00:45:44,749
all that's gonna happen is you're gonna

962
00:45:44,749 --> 00:45:46,460
go around the loop again you're gonna

963
00:45:46,460 --> 00:45:50,269
find that you didn't recover your node 3

964
00:45:50,269 --> 00:45:52,009
when you're you know you're you know and

965
00:45:52,009 --> 00:45:53,749
there's still only two running and

966
00:45:53,749 --> 00:45:55,130
you're just gonna try the recovery

967
00:45:55,130 --> 00:45:57,589
operation again so that's not it that

968
00:45:57,589 --> 00:45:59,779
really isn't even special code within

969
00:45:59,779 --> 00:46:01,519
the operator that's really just kind of

970
00:46:01,519 --> 00:46:04,400
that standard idea of some sort of Oda

971
00:46:04,400 --> 00:46:07,609
or reconciliation loop obviously for

972
00:46:07,609 --> 00:46:10,609
more complex failures I think this

973
00:46:10,609 --> 00:46:14,180
relates to the question about once I

974
00:46:14,180 --> 00:46:16,220
start using an operator should my admins

975
00:46:16,220 --> 00:46:17,930
all be hands-off and never touch it in

976
00:46:17,930 --> 00:46:20,450
the future and to the question about

977
00:46:20,450 --> 00:46:23,150
would you encode within an operator

978
00:46:23,150 --> 00:46:25,809
knowledge of exceptionally long-lived

979
00:46:25,809 --> 00:46:29,480
operations that might be expected during

980
00:46:29,480 --> 00:46:32,089
recovery or backup or deployment

981
00:46:32,089 --> 00:46:34,759
scenarios so for complex things yes they

982
00:46:34,759 --> 00:46:37,549
would probably need to be represented

983
00:46:37,549 --> 00:46:38,720
that knowledge would need to be

984
00:46:38,720 --> 00:46:40,999
represented within the operator and or

985
00:46:40,999 --> 00:46:42,739
within GPRS and some you know a

986
00:46:42,739 --> 00:46:45,819
combination of those two things

987
00:46:47,820 --> 00:46:52,410
oh yeah obviously and I mean and then

988
00:46:52,410 --> 00:46:56,040
it's so like I would probably if I were

989
00:46:56,040 --> 00:46:57,480
architecting the deployment I would

990
00:46:57,480 --> 00:47:01,740
probably seek to to take to maintain who

991
00:47:01,740 --> 00:47:04,110
am I trying to say here monitoring is

992
00:47:04,110 --> 00:47:06,030
always going to be a piece on top of

993
00:47:06,030 --> 00:47:11,370
this and I I sort of refused to be one

994
00:47:11,370 --> 00:47:12,900
of these people who's pitching like

995
00:47:12,900 --> 00:47:15,360
serverless admin lists there will

996
00:47:15,360 --> 00:47:17,040
probably be somebody there monitoring

997
00:47:17,040 --> 00:47:20,250
even a fully automated all operator

998
00:47:20,250 --> 00:47:23,250
driven kubernetes stack for the failures

999
00:47:23,250 --> 00:47:25,470
that aren't yet encoded in your operator

1000
00:47:25,470 --> 00:47:26,880
right so I mean I think that would be

1001
00:47:26,880 --> 00:47:30,810
good best practices and there's there's

1002
00:47:30,810 --> 00:47:32,310
some more detail on that kind of thing

1003
00:47:32,310 --> 00:47:37,710
in the the at CD repo on github there is

1004
00:47:37,710 --> 00:47:40,380
actually a best practices document for

1005
00:47:40,380 --> 00:47:42,930
the sed operator that'll give you some

1006
00:47:42,930 --> 00:47:44,760
idea of directions there and again I

1007
00:47:44,760 --> 00:47:46,500
would I would say that with the caveat

1008
00:47:46,500 --> 00:47:49,230
that the sed operator itself is not 1.0

1009
00:47:49,230 --> 00:47:53,250
so things will change but that gives you

1010
00:47:53,250 --> 00:47:54,750
some idea of what we kind of think that

1011
00:47:54,750 --> 00:47:56,550
picture looks like for an application

1012
00:47:56,550 --> 00:47:58,290
that we ourselves run in production all

1013
00:47:58,290 --> 00:48:01,110
the time that CV so because when I

1014
00:48:01,110 --> 00:48:02,670
answer questions about Postgres I am

1015
00:48:02,670 --> 00:48:04,830
speculating at the very best I don't run

1016
00:48:04,830 --> 00:48:06,590
Postgres every day in production I don't

1017
00:48:06,590 --> 00:48:11,960
have an idea well thank you thank you

1018
00:48:11,960 --> 00:48:16,360
[Applause]

