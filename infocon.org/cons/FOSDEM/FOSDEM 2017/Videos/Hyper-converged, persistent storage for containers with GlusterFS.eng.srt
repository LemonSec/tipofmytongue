1
00:00:00,000 --> 00:00:02,900
all righty

2
00:00:04,940 --> 00:00:08,300
hi there hello to everyone listening and

3
00:00:08,300 --> 00:00:10,309
watching on the Internet

4
00:00:10,309 --> 00:00:13,550
my name is Jose this is a sheikh we're

5
00:00:13,550 --> 00:00:15,440
here to talk about hyper-converged

6
00:00:15,440 --> 00:00:17,689
persistent storage for containers with

7
00:00:17,689 --> 00:00:22,489
cluster FS all right

8
00:00:22,489 --> 00:00:26,710
we just I just recently came down from

9
00:00:26,710 --> 00:00:29,390
giving a five minute version of this

10
00:00:29,390 --> 00:00:31,489
presentation a couple hours ago some say

11
00:00:31,489 --> 00:00:33,410
little jest from that's a bear with me

12
00:00:33,410 --> 00:00:36,620
or from plucking a little fast all right

13
00:00:36,620 --> 00:00:37,700
so who are we

14
00:00:37,700 --> 00:00:40,610
I'm Jose I work for Red Hat I'm a member

15
00:00:40,610 --> 00:00:43,040
of the kubernetes third sig and still of

16
00:00:43,040 --> 00:00:44,750
the Samba team they haven't kicked me

17
00:00:44,750 --> 00:00:49,760
out yet I work on in a mostly

18
00:00:49,760 --> 00:00:51,170
integration to work with container

19
00:00:51,170 --> 00:00:53,050
platforms distributed storage systems

20
00:00:53,050 --> 00:00:55,040
Network protocols and things like that

21
00:00:55,040 --> 00:00:58,460
most recently I helped develop a tool

22
00:00:58,460 --> 00:01:01,340
for deploying destra fest into

23
00:01:01,340 --> 00:01:02,930
hyper-converged scenario and kubernetes

24
00:01:02,930 --> 00:01:07,400
and we'll be demonstrating that later on

25
00:01:07,400 --> 00:01:12,409
in this presentation I am a so I

26
00:01:12,409 --> 00:01:14,030
work mostly on Leicester

27
00:01:14,030 --> 00:01:16,069
containerization and the integration

28
00:01:16,069 --> 00:01:18,649
part with Cuban it is an open shift so I

29
00:01:18,649 --> 00:01:20,990
I kind of contribute around all the

30
00:01:20,990 --> 00:01:22,729
components which is required for the

31
00:01:22,729 --> 00:01:27,249
integration and that's about it

32
00:01:27,700 --> 00:01:31,670
alrighty so in this presentation we're

33
00:01:31,670 --> 00:01:33,259
gonna go over you know a little bit of

34
00:01:33,259 --> 00:01:34,969
obviously why we're doing this and what

35
00:01:34,969 --> 00:01:37,819
problem were even trying to solve we're

36
00:01:37,819 --> 00:01:41,270
gonna go over what it took to solve this

37
00:01:41,270 --> 00:01:43,520
problem and that's gonna be a lot of a

38
00:01:43,520 --> 00:01:46,069
fair amount of technical detail as to

39
00:01:46,069 --> 00:01:47,810
how we created hyperconvergence that way

40
00:01:47,810 --> 00:01:49,759
and then we're going to have

41
00:01:49,759 --> 00:01:52,729
unfortunately not a live demo because

42
00:01:52,729 --> 00:01:55,069
you know networking at this conference

43
00:01:55,069 --> 00:01:58,130
so I recorded a video that we're gonna

44
00:01:58,130 --> 00:02:02,630
be talking over instead all right why

45
00:02:02,630 --> 00:02:08,508
are we doing this so basically we found

46
00:02:08,508 --> 00:02:11,360
we could solve a profound a problem that

47
00:02:11,360 --> 00:02:14,390
we could solve effectively containers

48
00:02:14,390 --> 00:02:17,300
being ephemeral in nature or wanting to

49
00:02:17,300 --> 00:02:18,540
be a feral

50
00:02:18,540 --> 00:02:21,750
nature conflicts with a lot of

51
00:02:21,750 --> 00:02:24,420
traditional and even just modern and

52
00:02:24,420 --> 00:02:26,549
even some modern applications that just

53
00:02:26,549 --> 00:02:28,860
cannot be ephemeral and stateless they

54
00:02:28,860 --> 00:02:30,780
need storage and they need storage to

55
00:02:30,780 --> 00:02:34,379
persist between you know service outages

56
00:02:34,379 --> 00:02:40,040
or restart of the service to do

57
00:02:40,040 --> 00:02:42,299
persistent storage especially in

58
00:02:42,299 --> 00:02:43,920
especially in kubernetes usually

59
00:02:43,920 --> 00:02:46,230
involves investment in some sort of

60
00:02:46,230 --> 00:02:48,680
external infrastructure whether it be an

61
00:02:48,680 --> 00:02:51,900
on-site storage solution like like an

62
00:02:51,900 --> 00:02:55,220
ass device or something or going to or

63
00:02:55,220 --> 00:02:58,950
going to a cloud cloud backed storage

64
00:02:58,950 --> 00:03:02,329
solution if so requires a fair amount of

65
00:03:02,329 --> 00:03:05,099
investment whether it's on one honkin

66
00:03:05,099 --> 00:03:06,389
piece of hardware that you then have to

67
00:03:06,389 --> 00:03:09,329
service or some bit of storage that you

68
00:03:09,329 --> 00:03:11,420
have to rent out in month after month

69
00:03:11,420 --> 00:03:16,260
and we wanted to do something that cuts

70
00:03:16,260 --> 00:03:19,349
that cost down as much as possible while

71
00:03:19,349 --> 00:03:21,480
at the same time being relatively

72
00:03:21,480 --> 00:03:23,970
transparent and easy to use both for

73
00:03:23,970 --> 00:03:26,669
administrators create using providing to

74
00:03:26,669 --> 00:03:29,010
storage and users wanting to make use of

75
00:03:29,010 --> 00:03:31,500
that storage and while we're at it let's

76
00:03:31,500 --> 00:03:32,849
make it free and open source with the

77
00:03:32,849 --> 00:03:34,709
support of community because we're Red

78
00:03:34,709 --> 00:03:38,099
Hat all right so our target platforms

79
00:03:38,099 --> 00:03:41,040
are kubernetes and OpenShift because Red

80
00:03:41,040 --> 00:03:45,209
Hat and the technologies we're using to

81
00:03:45,209 --> 00:03:47,819
solve this problem are ghost ifs and

82
00:03:47,819 --> 00:03:50,519
Poquette e those are their cute little

83
00:03:50,519 --> 00:03:52,650
logos up there and the URLs you can

84
00:03:52,650 --> 00:03:57,000
catch these slides online right now

85
00:03:57,000 --> 00:03:59,480
actually I just uploaded them yesterday

86
00:03:59,480 --> 00:04:02,340
all right so blister us is a distributed

87
00:04:02,340 --> 00:04:05,699
software-defined file system it creates

88
00:04:05,699 --> 00:04:08,659
what are called bricks which are just

89
00:04:08,659 --> 00:04:11,760
what what most people know as logical

90
00:04:11,760 --> 00:04:16,228
volumes on on on starch devices so you

91
00:04:16,228 --> 00:04:18,000
take a starch device you put partitions

92
00:04:18,000 --> 00:04:20,728
on it and usually those partitions can

93
00:04:20,728 --> 00:04:23,760
then become bricks those bricks are then

94
00:04:23,760 --> 00:04:27,180
put together into Gluster volumes which

95
00:04:27,180 --> 00:04:31,289
can be accessed from any node in the

96
00:04:31,289 --> 00:04:31,900
cluster

97
00:04:31,900 --> 00:04:34,120
so if you have a client that's trying to

98
00:04:34,120 --> 00:04:36,070
access your your Gloucester cluster you

99
00:04:36,070 --> 00:04:39,370
can go to any one of the nodes to any

100
00:04:39,370 --> 00:04:40,600
one of the server nodes and they will

101
00:04:40,600 --> 00:04:42,910
all have access to the volumes that they

102
00:04:42,910 --> 00:04:46,990
know about some interesting some cool

103
00:04:46,990 --> 00:04:48,910
things about this is that Gloucester was

104
00:04:48,910 --> 00:04:50,199
designed to run on commodity hardware

105
00:04:50,199 --> 00:04:52,690
there's a link up there show for a blog

106
00:04:52,690 --> 00:04:54,070
post showing it running on a Raspberry

107
00:04:54,070 --> 00:04:55,479
Pi

108
00:04:55,479 --> 00:04:57,789
it has a scale out design meaning that

109
00:04:57,789 --> 00:05:00,610
it's easy for you to expand your storage

110
00:05:00,610 --> 00:05:03,310
just by adding more nodes to it

111
00:05:03,310 --> 00:05:05,740
obviously I don't need to be talking too

112
00:05:05,740 --> 00:05:07,660
much about this here and provides useful

113
00:05:07,660 --> 00:05:09,060
features like cross node application

114
00:05:09,060 --> 00:05:11,770
usage balancing a nice cozy storage axis

115
00:05:11,770 --> 00:05:14,650
now the part that most people probably

116
00:05:14,650 --> 00:05:16,630
won't know too much about hey kitty

117
00:05:16,630 --> 00:05:19,570
hey Cuddy is the restful volume

118
00:05:19,570 --> 00:05:21,639
management interface for Gloucester FS

119
00:05:21,639 --> 00:05:24,610
it allows you a consistent and

120
00:05:24,610 --> 00:05:27,669
programmatic interface for performing

121
00:05:27,669 --> 00:05:29,650
most of the common Gluster volume

122
00:05:29,650 --> 00:05:32,620
management pass like creating volumes

123
00:05:32,620 --> 00:05:34,479
deleting volumes expanding the size of

124
00:05:34,479 --> 00:05:37,860
volumes etc it can manage multiple

125
00:05:37,860 --> 00:05:41,440
clusters from a single instance multiple

126
00:05:41,440 --> 00:05:43,180
Gluster clusters specifically from a

127
00:05:43,180 --> 00:05:45,880
single instance and it's fairly

128
00:05:45,880 --> 00:05:47,979
lightweight reliable and simple by

129
00:05:47,979 --> 00:05:53,199
design when you put it all together it

130
00:05:53,199 --> 00:05:55,449
looks something like this where you have

131
00:05:55,449 --> 00:05:57,960
your kubernetes or openshift cluster

132
00:05:57,960 --> 00:06:00,250
running various pods in it one of which

133
00:06:00,250 --> 00:06:02,979
will be your Hettie pod for your restful

134
00:06:02,979 --> 00:06:05,440
api if it goes down obviously kubernetes

135
00:06:05,440 --> 00:06:07,930
will just move it around or spin up a

136
00:06:07,930 --> 00:06:08,500
new one

137
00:06:08,500 --> 00:06:09,699
somewhere around somewhere in the

138
00:06:09,699 --> 00:06:11,409
cluster and then you have various

139
00:06:11,409 --> 00:06:13,720
Gloucester Gloucester pods that are all

140
00:06:13,720 --> 00:06:15,669
logically joined together into one

141
00:06:15,669 --> 00:06:19,210
cluster cluster on top of the kubernetes

142
00:06:19,210 --> 00:06:22,870
cluster and each node has some store

143
00:06:22,870 --> 00:06:24,909
some nodes as you can see there have

144
00:06:24,909 --> 00:06:27,070
some storage attached to it doesn't all

145
00:06:27,070 --> 00:06:29,830
have to be it doesn't have to be perfect

146
00:06:29,830 --> 00:06:31,060
mirrors of each other across the

147
00:06:31,060 --> 00:06:33,400
topology it can vary some can have three

148
00:06:33,400 --> 00:06:36,130
disks some can have two and then you

149
00:06:36,130 --> 00:06:38,740
just put your Gloucester pod on whatever

150
00:06:38,740 --> 00:06:41,500
node is running storage and now you can

151
00:06:41,500 --> 00:06:44,810
access that storage via cluster

152
00:06:44,810 --> 00:06:47,310
and you can find out and you can find

153
00:06:47,310 --> 00:06:49,650
our work that it that we put into sort

154
00:06:49,650 --> 00:06:51,000
of glue all this together on the

155
00:06:51,000 --> 00:06:53,280
glycerin eighties project on github URL

156
00:06:53,280 --> 00:06:56,850
is up there it documents how we put all

157
00:06:56,850 --> 00:06:58,949
this together and how you can put this

158
00:06:58,949 --> 00:07:01,590
together in your own setups provides an

159
00:07:01,590 --> 00:07:03,600
easy-to-use deployment tool that thing I

160
00:07:03,600 --> 00:07:05,520
mentioned I worked on earlier and has a

161
00:07:05,520 --> 00:07:07,050
QuickStart guide for those who want to

162
00:07:07,050 --> 00:07:10,290
start playing with it right away in VMs

163
00:07:10,290 --> 00:07:13,380
or on bare metal whatever you choose all

164
00:07:13,380 --> 00:07:15,889
right so that's kind of the set up of

165
00:07:15,889 --> 00:07:18,750
what we're doing and what we decided to

166
00:07:18,750 --> 00:07:21,120
what we decided to do about it now

167
00:07:21,120 --> 00:07:31,440
here's how it all happened hi so when we

168
00:07:31,440 --> 00:07:34,080
started converging the blest repairs on

169
00:07:34,080 --> 00:07:36,660
kubernetes or open ship first ask for us

170
00:07:36,660 --> 00:07:38,430
was to containerized Lister

171
00:07:38,430 --> 00:07:43,110
so Glessner was mostly system software

172
00:07:43,110 --> 00:07:46,020
kind of a thing but it was user space

173
00:07:46,020 --> 00:07:48,810
software but it it it was dependent on

174
00:07:48,810 --> 00:07:51,570
those nodes more so because of the

175
00:07:51,570 --> 00:07:54,450
devices which we need to access to

176
00:07:54,450 --> 00:07:57,240
create the volumes so this is how the

177
00:07:57,240 --> 00:07:59,910
docker command looks like if you run it

178
00:07:59,910 --> 00:08:02,789
it's pretty big and that is the

179
00:08:02,789 --> 00:08:06,539
kubernetes ml file which we have so what

180
00:08:06,539 --> 00:08:09,330
we faced when we container is Lestrade's

181
00:08:09,330 --> 00:08:11,450
what I'm going to talk about now it's

182
00:08:11,450 --> 00:08:14,280
just these are the issues which we faced

183
00:08:14,280 --> 00:08:17,220
so come in Gloucester runs more than one

184
00:08:17,220 --> 00:08:20,700
process from blister so it has its brick

185
00:08:20,700 --> 00:08:22,979
process running under it and it has its

186
00:08:22,979 --> 00:08:25,349
sponsored separately and it it has its

187
00:08:25,349 --> 00:08:29,639
own interface serving service running so

188
00:08:29,639 --> 00:08:31,830
these these processes need to be ran

189
00:08:31,830 --> 00:08:33,719
along with Lester's so we needed a

190
00:08:33,719 --> 00:08:35,339
container which can hold more than one

191
00:08:35,339 --> 00:08:39,450
process so we move to system D with Dan

192
00:08:39,450 --> 00:08:42,539
was help so we moved to system D and

193
00:08:42,539 --> 00:08:45,660
then we needed privileges because we

194
00:08:45,660 --> 00:08:47,640
were running a system D container and

195
00:08:47,640 --> 00:08:50,400
then this startup script I will explain

196
00:08:50,400 --> 00:08:52,320
about the scott startup script little

197
00:08:52,320 --> 00:08:54,300
bit later and

198
00:08:54,300 --> 00:08:56,309
the buy mounts for the glacier

199
00:08:56,309 --> 00:08:57,929
configuration so these configurations

200
00:08:57,929 --> 00:09:01,170
shouldn't be moving around along with

201
00:09:01,170 --> 00:09:03,029
the containers so it should be spawned

202
00:09:03,029 --> 00:09:05,459
on the same node with the same

203
00:09:05,459 --> 00:09:07,379
configuration when the glacier goes down

204
00:09:07,379 --> 00:09:09,689
and comes back up so we need we buy

205
00:09:09,689 --> 00:09:13,139
mounted from the host and the devices

206
00:09:13,139 --> 00:09:14,879
were buy mounted from the host and we

207
00:09:14,879 --> 00:09:18,119
use we prefer using horse networking for

208
00:09:18,119 --> 00:09:22,319
better performance so this is basically

209
00:09:22,319 --> 00:09:25,290
what I am supposed to tell yes system D

210
00:09:25,290 --> 00:09:28,110
container so we needed someone to manage

211
00:09:28,110 --> 00:09:30,149
all over the process all the glycerate

212
00:09:30,149 --> 00:09:32,429
process which we run to clean it up and

213
00:09:32,429 --> 00:09:36,720
also we need more support to run lister

214
00:09:36,720 --> 00:09:38,790
containers because we add more process

215
00:09:38,790 --> 00:09:42,050
before running before running Lester I

216
00:09:42,050 --> 00:09:44,699
mean when we wanted a containerized

217
00:09:44,699 --> 00:09:47,639
Lester so we needed system D and

218
00:09:47,639 --> 00:09:49,559
privileges we don't need privileges

219
00:09:49,559 --> 00:09:51,360
anymore for system D to run in a

220
00:09:51,360 --> 00:09:53,999
container because of the OCD OCI system

221
00:09:53,999 --> 00:09:57,149
D hooks so we don't actually need system

222
00:09:57,149 --> 00:09:59,009
D mid privileges for system D container

223
00:09:59,009 --> 00:10:02,100
but we need privileged container for

224
00:10:02,100 --> 00:10:04,139
accessing the devices and to create the

225
00:10:04,139 --> 00:10:07,319
Elvis from the container so we create

226
00:10:07,319 --> 00:10:09,629
logical volume from Gloucester container

227
00:10:09,629 --> 00:10:13,019
for Lester to use it and the startup

228
00:10:13,019 --> 00:10:16,170
script is just a initial script which we

229
00:10:16,170 --> 00:10:19,399
run which does all the things that and

230
00:10:19,399 --> 00:10:22,049
rpm installation does before running

231
00:10:22,049 --> 00:10:24,389
cluster so in case of upgrade this

232
00:10:24,389 --> 00:10:26,220
script will take care of doing

233
00:10:26,220 --> 00:10:30,569
versioning for Lester which we do in rpm

234
00:10:30,569 --> 00:10:33,059
installation or rpm upgrade so we needed

235
00:10:33,059 --> 00:10:35,819
a placeholder for these things to do so

236
00:10:35,819 --> 00:10:37,769
we have a initial setup script which

237
00:10:37,769 --> 00:10:41,149
does these things in the container and

238
00:10:41,149 --> 00:10:43,879
these are those persisting

239
00:10:43,879 --> 00:10:47,399
configurations we need from the host so

240
00:10:47,399 --> 00:10:49,829
Waddle Abdullah study is required to

241
00:10:49,829 --> 00:10:51,769
manage all the glyceryl volume

242
00:10:51,769 --> 00:10:54,029
configuration that's where that's the

243
00:10:54,029 --> 00:10:55,529
working directory of glister that's

244
00:10:55,529 --> 00:10:58,019
where we store all the context of

245
00:10:58,019 --> 00:11:00,990
glisters and the Hualapai service is

246
00:11:00,990 --> 00:11:04,139
just a log and easy Cygnus Rufus is the

247
00:11:04,139 --> 00:11:05,819
configuration file for the glossary

248
00:11:05,819 --> 00:11:07,180
which is a manage

249
00:11:07,180 --> 00:11:09,370
demon of glister so all the

250
00:11:09,370 --> 00:11:12,460
configurations for that is in a DC glass

251
00:11:12,460 --> 00:11:17,650
surface so by mount devices so we we had

252
00:11:17,650 --> 00:11:20,500
to buy mount the /dev inside the

253
00:11:20,500 --> 00:11:22,300
container but the initial plan was to

254
00:11:22,300 --> 00:11:24,760
create the LVS on the host and give the

255
00:11:24,760 --> 00:11:27,580
elvis to the container and then use it

256
00:11:27,580 --> 00:11:30,880
so that we can get rid of /div but it

257
00:11:30,880 --> 00:11:33,310
was really hard to scale because when

258
00:11:33,310 --> 00:11:35,350
you want to create one more volume when

259
00:11:35,350 --> 00:11:37,600
you create another LV it's it was tough

260
00:11:37,600 --> 00:11:40,630
to create a done on the host and then

261
00:11:40,630 --> 00:11:42,850
buy mounted again because you have to

262
00:11:42,850 --> 00:11:45,010
bring down the container and bring it

263
00:11:45,010 --> 00:11:47,320
back up with the node so we decided to

264
00:11:47,320 --> 00:11:50,350
put /dev inside the container we had lot

265
00:11:50,350 --> 00:11:54,520
of issues with judah and it is solved

266
00:11:54,520 --> 00:11:56,650
now so it is working completely fine

267
00:11:56,650 --> 00:11:59,440
with /dev I'm outing inside the

268
00:11:59,440 --> 00:12:01,890
container it does not mess up your host

269
00:12:01,890 --> 00:12:08,290
device so first Network host network we

270
00:12:08,290 --> 00:12:11,050
could have done the we could have

271
00:12:11,050 --> 00:12:13,180
maintained same host name for the

272
00:12:13,180 --> 00:12:15,880
container and still use glister which

273
00:12:15,880 --> 00:12:18,010
could have but we just thought it will

274
00:12:18,010 --> 00:12:20,560
be one more network hop instead we can

275
00:12:20,560 --> 00:12:22,480
use the horse network as we are not

276
00:12:22,480 --> 00:12:26,770
moving listed pots around so we we use

277
00:12:26,770 --> 00:12:30,910
lesser host networking for cluster

278
00:12:30,910 --> 00:12:33,520
containers basically and it gives better

279
00:12:33,520 --> 00:12:36,760
performance for because it's a network

280
00:12:36,760 --> 00:12:40,210
segment then container raising equity

281
00:12:40,210 --> 00:12:42,820
hecka tea container using was not that

282
00:12:42,820 --> 00:12:45,400
tough so before telling this what

283
00:12:45,400 --> 00:12:48,730
hickety does it it gets all these mean

284
00:12:48,730 --> 00:12:50,410
let's say if three nodes are there in

285
00:12:50,410 --> 00:12:52,420
the cluster and you install lesser on

286
00:12:52,420 --> 00:12:54,220
all these three nodes and there are

287
00:12:54,220 --> 00:12:56,920
three devices on each so you hand over

288
00:12:56,920 --> 00:13:00,340
these devices to hickety so when hickety

289
00:13:00,340 --> 00:13:02,980
starts with this topology file

290
00:13:02,980 --> 00:13:05,740
Hecate goes and peer probes with all

291
00:13:05,740 --> 00:13:08,380
these nodes that's what we call in

292
00:13:08,380 --> 00:13:10,450
cluster terms like creating a storage

293
00:13:10,450 --> 00:13:13,630
pool this is how it forms a pool we peer

294
00:13:13,630 --> 00:13:16,120
pro from one node to another and form a

295
00:13:16,120 --> 00:13:19,030
pool and then hickety goes inside these

296
00:13:19,030 --> 00:13:20,190
devices create

297
00:13:20,190 --> 00:13:22,410
the pv required and the VG required for

298
00:13:22,410 --> 00:13:24,480
those devices and when you give a

299
00:13:24,480 --> 00:13:27,720
request of volume from equity it comes

300
00:13:27,720 --> 00:13:30,300
to the Glessner nodes it has a ring

301
00:13:30,300 --> 00:13:32,220
algorithm inside which decides where the

302
00:13:32,220 --> 00:13:34,980
bricks will land so it it takes each

303
00:13:34,980 --> 00:13:37,500
devices and creates logical volumes from

304
00:13:37,500 --> 00:13:40,410
each device let's say replica three

305
00:13:40,410 --> 00:13:42,720
volume if you want it goes to three

306
00:13:42,720 --> 00:13:45,120
nodes and creates bricks on each node

307
00:13:45,120 --> 00:13:48,900
and then creates a volume out of it so

308
00:13:48,900 --> 00:13:51,030
that if one node goes down the volume

309
00:13:51,030 --> 00:13:53,100
will be still serving that's why we use

310
00:13:53,100 --> 00:13:55,050
replica three mostly in this solution we

311
00:13:55,050 --> 00:13:58,890
ask prefer replica three so hickety does

312
00:13:58,890 --> 00:14:01,650
this volume creation for you you don't

313
00:14:01,650 --> 00:14:03,210
have to actually worry about the Glasser

314
00:14:03,210 --> 00:14:06,000
commands it is really easy with Hecate

315
00:14:06,000 --> 00:14:10,170
ii on it and it needed it has its own

316
00:14:10,170 --> 00:14:11,580
database to store all these

317
00:14:11,580 --> 00:14:13,920
configurations of these are the nodes

318
00:14:13,920 --> 00:14:16,410
and these are the devices which which

319
00:14:16,410 --> 00:14:19,590
blesser can make use of so it stores

320
00:14:19,590 --> 00:14:22,710
that in the DB which was really a

321
00:14:22,710 --> 00:14:25,230
problem for us because the DB will go

322
00:14:25,230 --> 00:14:28,650
down when when a big heavy pot goes down

323
00:14:28,650 --> 00:14:30,840
so what we thought of doing was creating

324
00:14:30,840 --> 00:14:33,510
a glycerol um-- for it and putting the

325
00:14:33,510 --> 00:14:36,390
DB inside the volume when they Kathy

326
00:14:36,390 --> 00:14:38,550
comes up so that's what we do we give

327
00:14:38,550 --> 00:14:40,650
persistent volume and we use it as well

328
00:14:40,650 --> 00:14:45,870
and and it was rickety was using through

329
00:14:45,870 --> 00:14:48,660
SSH now we move the cube exit which

330
00:14:48,660 --> 00:14:53,130
needed few secrets in the equity pod so

331
00:14:53,130 --> 00:14:55,820
we also need to create a service account

332
00:14:55,820 --> 00:14:58,650
which will be used by equity to access

333
00:14:58,650 --> 00:15:02,700
the Glessner pots that's all about

334
00:15:02,700 --> 00:15:06,000
equity container raising and deployment

335
00:15:06,000 --> 00:15:11,670
and usage so persistent storage in point

336
00:15:11,670 --> 00:15:14,640
of cuban it is an open shift they have

337
00:15:14,640 --> 00:15:17,220
lot of volume plugins inside if you all

338
00:15:17,220 --> 00:15:19,520
know so volume plug-in is just a way for

339
00:15:19,520 --> 00:15:21,960
different kind of storage providers to

340
00:15:21,960 --> 00:15:24,330
use their volumes so in case of glycerol

341
00:15:24,330 --> 00:15:26,520
you what we do is we have a gloucester

342
00:15:26,520 --> 00:15:28,830
volume plugin inside cuban it is if you

343
00:15:28,830 --> 00:15:30,630
want to use a glycerol um-- inside your

344
00:15:30,630 --> 00:15:32,470
part you will mention the

345
00:15:32,470 --> 00:15:35,530
be of the node and the volume name in

346
00:15:35,530 --> 00:15:40,020
the mean in your volume mount section

347
00:15:40,020 --> 00:15:43,240
what internally the kubernetes volume

348
00:15:43,240 --> 00:15:45,430
plugin does it it will by mom mean it

349
00:15:45,430 --> 00:15:47,980
will mount the glass surface on the host

350
00:15:47,980 --> 00:15:50,440
and then by mount that mount point to

351
00:15:50,440 --> 00:15:53,650
the container wherever you specify for a

352
00:15:53,650 --> 00:15:56,200
persistent volume so that's how our

353
00:15:56,200 --> 00:15:58,090
volume plugin works in the kubernetes

354
00:15:58,090 --> 00:16:00,400
world and there are two ways to

355
00:16:00,400 --> 00:16:02,140
provision volumes one is static

356
00:16:02,140 --> 00:16:05,770
provisioning so you request for a volume

357
00:16:05,770 --> 00:16:09,610
in cuba release unix request for volume

358
00:16:09,610 --> 00:16:11,880
through persistent volume claim and

359
00:16:11,880 --> 00:16:14,710
admins will create persistent volumes

360
00:16:14,710 --> 00:16:17,920
which will be back ended by some network

361
00:16:17,920 --> 00:16:22,540
storage provider can be amazon can be

362
00:16:22,540 --> 00:16:24,280
gloucester can be self can be anything

363
00:16:24,280 --> 00:16:27,550
so so he has to create a static probe it

364
00:16:27,550 --> 00:16:29,500
so admin has to go back in and create

365
00:16:29,500 --> 00:16:31,300
the volume and give it to the customers

366
00:16:31,300 --> 00:16:33,580
or users in the kubernetes as a

367
00:16:33,580 --> 00:16:36,430
persistent volume when a user asked for

368
00:16:36,430 --> 00:16:39,160
a persistent volume claim if there was a

369
00:16:39,160 --> 00:16:41,980
persistent volume which will support the

370
00:16:41,980 --> 00:16:43,600
persistent volume claim it will get

371
00:16:43,600 --> 00:16:46,420
bound if it is not there then you have

372
00:16:46,420 --> 00:16:48,370
to request the admin and he will create

373
00:16:48,370 --> 00:16:50,620
it and give it to you that's what static

374
00:16:50,620 --> 00:16:53,050
provisioning means I mean that is static

375
00:16:53,050 --> 00:16:54,610
reasoning and dynamic provisioning is

376
00:16:54,610 --> 00:16:58,720
when you have a storage class defined in

377
00:16:58,720 --> 00:17:01,180
your kubernetes saying this is the

378
00:17:01,180 --> 00:17:03,820
storage pool and if someone requests you

379
00:17:03,820 --> 00:17:06,010
for a storage go back end and create a

380
00:17:06,010 --> 00:17:08,290
storage for you so that is what the

381
00:17:08,290 --> 00:17:10,690
storage class does so now when you

382
00:17:10,690 --> 00:17:12,369
create a persistent volume claim you

383
00:17:12,369 --> 00:17:15,069
will specify the storage class it will

384
00:17:15,069 --> 00:17:18,430
go to the crew go to the network

385
00:17:18,430 --> 00:17:21,310
management network storage and create a

386
00:17:21,310 --> 00:17:23,710
volume and mount it on the persistent

387
00:17:23,710 --> 00:17:26,170
volume claim so that is what dynamic

388
00:17:26,170 --> 00:17:28,319
provisioning means that's what we do in

389
00:17:28,319 --> 00:17:32,020
Leicester in the kubernetes so when a

390
00:17:32,020 --> 00:17:34,000
persistent volume claim comes with

391
00:17:34,000 --> 00:17:37,260
request for a volume from Leicester

392
00:17:37,260 --> 00:17:39,120
admin has

393
00:17:39,120 --> 00:17:42,100
admin does not have to do anything it

394
00:17:42,100 --> 00:17:44,080
just goes back in and creates a volume

395
00:17:44,080 --> 00:17:45,830
from the glacier pole and

396
00:17:45,830 --> 00:17:49,669
it creates a PV for it and admin the PVC

397
00:17:49,669 --> 00:17:53,750
is bound automatically to the PV so this

398
00:17:53,750 --> 00:17:55,370
is persistent volume claim and

399
00:17:55,370 --> 00:17:58,940
persistent volume and stories class so

400
00:17:58,940 --> 00:18:01,279
dynamic provisioning this is what I was

401
00:18:01,279 --> 00:18:02,840
explaining so dynamic provisioning it

402
00:18:02,840 --> 00:18:05,240
has a storage class storage class is a

403
00:18:05,240 --> 00:18:07,880
way to define your back-end storage so

404
00:18:07,880 --> 00:18:10,789
this this is your storage this is your

405
00:18:10,789 --> 00:18:13,610
URL and these are the option to create a

406
00:18:13,610 --> 00:18:15,980
volume is what you give in the storage

407
00:18:15,980 --> 00:18:19,159
class mostly I will show you how the

408
00:18:19,159 --> 00:18:21,710
cluster storage class looks like so we

409
00:18:21,710 --> 00:18:23,659
have a persistent volume claim which

410
00:18:23,659 --> 00:18:26,210
which is nothing but a user request for

411
00:18:26,210 --> 00:18:28,789
a volume and persistent volume is the

412
00:18:28,789 --> 00:18:32,360
actual volume which is back-end network

413
00:18:32,360 --> 00:18:35,899
storage and the PVC is bound with the PV

414
00:18:35,899 --> 00:18:39,860
based on the volume size and access

415
00:18:39,860 --> 00:18:45,889
modes so this is how it works

416
00:18:45,889 --> 00:18:47,630
dynamic provisioning you get a claim

417
00:18:47,630 --> 00:18:51,019
with and it points to a storage class it

418
00:18:51,019 --> 00:18:53,779
goes behind to the storage and creates a

419
00:18:53,779 --> 00:18:56,990
persistent volume for you and attaches

420
00:18:56,990 --> 00:19:02,210
it to the persistent volume claim so if

421
00:19:02,210 --> 00:19:04,279
you can see that the name of the storage

422
00:19:04,279 --> 00:19:08,600
class is Lester and provisional the API

423
00:19:08,600 --> 00:19:11,779
and the endpoint is the point where you

424
00:19:11,779 --> 00:19:15,110
have all that lester ip's mentioned for

425
00:19:15,110 --> 00:19:18,529
using those volumes and the rest URL is

426
00:19:18,529 --> 00:19:21,980
the URL where riccati is running so all

427
00:19:21,980 --> 00:19:23,960
the requests from the storage class will

428
00:19:23,960 --> 00:19:26,210
go to the equity and equity will create

429
00:19:26,210 --> 00:19:28,250
a volume for you read the rest user and

430
00:19:28,250 --> 00:19:31,880
the user key is also for equity so this

431
00:19:31,880 --> 00:19:33,679
is the name username for you at the end

432
00:19:33,679 --> 00:19:36,679
it is a user key which hickety wants to

433
00:19:36,679 --> 00:19:43,820
use to access and create volumes to use

434
00:19:43,820 --> 00:19:46,130
a glister volume inside a container

435
00:19:46,130 --> 00:19:49,010
these these two things are important in

436
00:19:49,010 --> 00:19:52,039
point and service so endpoints define

437
00:19:52,039 --> 00:19:55,279
where that lester volume is so if you if

438
00:19:55,279 --> 00:19:58,100
you if you have created a replica 3

439
00:19:58,100 --> 00:19:59,140
volume say

440
00:19:59,140 --> 00:20:01,450
so it is from three notes we specify

441
00:20:01,450 --> 00:20:04,390
that all three IP in the endpoint file

442
00:20:04,390 --> 00:20:07,510
and service is used to access those IPs

443
00:20:07,510 --> 00:20:10,330
and these are the options which you can

444
00:20:10,330 --> 00:20:14,950
specify in the storage class so as he

445
00:20:14,950 --> 00:20:17,410
already said hickety manages more than

446
00:20:17,410 --> 00:20:20,020
one cluster of a cluster so let's say

447
00:20:20,020 --> 00:20:22,299
you have two cluster clusters one has

448
00:20:22,299 --> 00:20:25,240
faster storage SSDs and one as smaller

449
00:20:25,240 --> 00:20:29,650
means slower storage devices and you can

450
00:20:29,650 --> 00:20:32,500
mention those cluster IDs here which is

451
00:20:32,500 --> 00:20:36,280
which is created from riccati so you can

452
00:20:36,280 --> 00:20:38,530
create you can create a storage class

453
00:20:38,530 --> 00:20:41,320
which will create a volume from this

454
00:20:41,320 --> 00:20:44,080
faster storage cluster of bluster and

455
00:20:44,080 --> 00:20:47,559
you can create a storage class from the

456
00:20:47,559 --> 00:20:52,030
slower accessible volumes so that idea

457
00:20:52,030 --> 00:20:54,190
is given Omega T and you can create that

458
00:20:54,190 --> 00:20:56,020
you can mention that in the storage

459
00:20:56,020 --> 00:20:58,299
class so that only that volumes are only

460
00:20:58,299 --> 00:21:00,460
that cluster is used to create this

461
00:21:00,460 --> 00:21:04,090
volumes and they user name is again the

462
00:21:04,090 --> 00:21:07,030
same hickety user names and for security

463
00:21:07,030 --> 00:21:11,890
we have GID so these are options which

464
00:21:11,890 --> 00:21:13,720
you can use if you want to secure your

465
00:21:13,720 --> 00:21:16,870
wash bin contents in a word persistent

466
00:21:16,870 --> 00:21:21,850
volume so only if you have them exact

467
00:21:21,850 --> 00:21:24,540
GID that you requested in your part

468
00:21:24,540 --> 00:21:27,130
that's when you can use this volume so

469
00:21:27,130 --> 00:21:29,590
if you don't know the GI DS which you

470
00:21:29,590 --> 00:21:32,169
are going to use in your part and the

471
00:21:32,169 --> 00:21:36,190
wall on the GID of the volume if this

472
00:21:36,190 --> 00:21:37,809
doesn't match you cannot use the volume

473
00:21:37,809 --> 00:21:39,340
or you cannot see the content of the

474
00:21:39,340 --> 00:21:43,299
volume so you have user has a user has a

475
00:21:43,299 --> 00:21:46,450
mean secure way to create a volume and

476
00:21:46,450 --> 00:21:48,880
put his data inside so that no one else

477
00:21:48,880 --> 00:21:51,250
who has access to these volumes can

478
00:21:51,250 --> 00:21:53,110
still read the data or right into the

479
00:21:53,110 --> 00:21:59,549
data right into the volume so this is it

480
00:22:03,310 --> 00:22:06,950
all righty thanks chic well thanks a

481
00:22:06,950 --> 00:22:08,930
sheik at this point we've achieved

482
00:22:08,930 --> 00:22:10,060
[Music]

483
00:22:10,060 --> 00:22:13,190
effectively full hyperconvergence as

484
00:22:13,190 --> 00:22:15,050
mentioned gloucester FS and hickety now

485
00:22:15,050 --> 00:22:18,350
running containers with with within

486
00:22:18,350 --> 00:22:21,350
kubernetes these are just some

487
00:22:21,350 --> 00:22:23,720
iterations of things we said earlier in

488
00:22:23,720 --> 00:22:25,930
the presentation

489
00:22:26,740 --> 00:22:31,280
yeah it's about right so now is where I

490
00:22:31,280 --> 00:22:32,780
would normally be showing you a live

491
00:22:32,780 --> 00:22:38,450
demo but unfortunately I destroyed my my

492
00:22:38,450 --> 00:22:41,120
demo cluster so instead I'm gonna try

493
00:22:41,120 --> 00:22:44,620
and talk over this video I recorded

494
00:22:44,620 --> 00:22:47,500
which hopefully will be visible enough

495
00:22:47,500 --> 00:22:49,670
especially for the people watching at

496
00:22:49,670 --> 00:22:52,630
home already

497
00:22:52,630 --> 00:22:55,790
so we're starting with a three node

498
00:22:55,790 --> 00:22:57,650
kubernetes cluster one master three

499
00:22:57,650 --> 00:23:00,200
nodes and we're running nothing other

500
00:23:00,200 --> 00:23:02,240
than kubernetes the kubernetes service

501
00:23:02,240 --> 00:23:04,730
so now we're going to run our GK deploy

502
00:23:04,730 --> 00:23:06,770
tool with a couple options and a

503
00:23:06,770 --> 00:23:09,710
topology file I should mention the

504
00:23:09,710 --> 00:23:12,140
topology filing question is just a

505
00:23:12,140 --> 00:23:14,300
properly formatted JSON file that

506
00:23:14,300 --> 00:23:18,320
describes the layout of or describes

507
00:23:18,320 --> 00:23:21,830
which note which IP addresses correspond

508
00:23:21,830 --> 00:23:23,000
to the servers and are going to have a

509
00:23:23,000 --> 00:23:24,410
cluster that are going to be running

510
00:23:24,410 --> 00:23:26,690
cluster and also a listing of the

511
00:23:26,690 --> 00:23:29,510
devices on their servers that to get

512
00:23:29,510 --> 00:23:31,420
that heck Hettie is going to be

513
00:23:31,420 --> 00:23:33,830
co-opting for use with Glosser FS

514
00:23:33,830 --> 00:23:37,400
alright so at this point we have started

515
00:23:37,400 --> 00:23:39,530
label we have started deploying woofster

516
00:23:39,530 --> 00:23:43,010
on the nodes that we specified here the

517
00:23:43,010 --> 00:23:45,860
containers are spinning up on those

518
00:23:45,860 --> 00:23:48,440
nodes this should take only a couple

519
00:23:48,440 --> 00:23:51,590
seconds and now we're deploying Tecate

520
00:23:51,590 --> 00:23:54,440
so as you mentioned one of the things we

521
00:23:54,440 --> 00:23:56,600
had to do is that we needed to store

522
00:23:56,600 --> 00:23:59,420
piketty's databases somewhere that was

523
00:23:59,420 --> 00:24:02,450
persistent so what we do is that we

524
00:24:02,450 --> 00:24:06,380
bring up hick heady one time and

525
00:24:06,380 --> 00:24:09,500
generate a debt and use it to generate a

526
00:24:09,500 --> 00:24:12,500
dead a database file then we go through

527
00:24:12,500 --> 00:24:13,190
heck Ettie

528
00:24:13,190 --> 00:24:17,210
to create a Gloucester volume within the

529
00:24:17,210 --> 00:24:20,330
cluster that it's managing so here in a

530
00:24:20,330 --> 00:24:22,910
couple seconds you'll see that that's

531
00:24:22,910 --> 00:24:25,340
the output from letting the topology

532
00:24:25,340 --> 00:24:28,460
file and adding all the devices so now

533
00:24:28,460 --> 00:24:30,770
we're creating a list of all um-- and

534
00:24:30,770 --> 00:24:32,390
then copying the contents of our

535
00:24:32,390 --> 00:24:35,150
database into that gloucester volume we

536
00:24:35,150 --> 00:24:40,970
just created and then killing the deploy

537
00:24:40,970 --> 00:24:43,100
hickety pod as we call it and then

538
00:24:43,100 --> 00:24:45,740
spinning up a new Acadie pod that uses

539
00:24:45,740 --> 00:24:48,200
that glister volume we just created to

540
00:24:48,200 --> 00:24:52,100
run its database and now hey katie is

541
00:24:52,100 --> 00:24:56,950
running and let's see to show you here

542
00:24:56,950 --> 00:25:00,260
come on there I go all right we are

543
00:25:00,260 --> 00:25:02,360
running several Gloucester pods and one

544
00:25:02,360 --> 00:25:05,210
Caqueta pod and an endpoint service all

545
00:25:05,210 --> 00:25:05,570
right

546
00:25:05,570 --> 00:25:07,010
so now I'm going to show you a quick

547
00:25:07,010 --> 00:25:09,680
demonstration to air-quote prove that

548
00:25:09,680 --> 00:25:11,720
we're using persistent storage

549
00:25:11,720 --> 00:25:15,590
underneath here we have a Gloucester

550
00:25:15,590 --> 00:25:18,290
storage class that is there's an example

551
00:25:18,290 --> 00:25:19,340
of what it looks like

552
00:25:19,340 --> 00:25:21,680
notice that we specified the endpoints

553
00:25:21,680 --> 00:25:25,070
at the endpoint and URL in the storage

554
00:25:25,070 --> 00:25:27,530
class this is all being done whether in

555
00:25:27,530 --> 00:25:29,720
the guise of an administrator setting

556
00:25:29,720 --> 00:25:31,520
this up so this first step would be the

557
00:25:31,520 --> 00:25:33,260
administrator studying up the storage

558
00:25:33,260 --> 00:25:35,480
class we specify the Emma file and it's

559
00:25:35,480 --> 00:25:37,160
done all right so now we're moving into

560
00:25:37,160 --> 00:25:40,070
user land we're gonna create a PVC a

561
00:25:40,070 --> 00:25:44,360
persistent volume claim as a as someone

562
00:25:44,360 --> 00:25:46,820
tried to deploy an application in

563
00:25:46,820 --> 00:25:48,260
kubernetes rather than providing

564
00:25:48,260 --> 00:25:51,590
kubernetes so we create this persistent

565
00:25:51,590 --> 00:25:54,770
volume claim llamó file and you know we

566
00:25:54,770 --> 00:25:56,570
have an access method as to how many

567
00:25:56,570 --> 00:25:58,010
people should be accessing this and we

568
00:25:58,010 --> 00:26:00,610
want to size that's all fairly standard

569
00:26:00,610 --> 00:26:03,620
persistent volume stuff or just storage

570
00:26:03,620 --> 00:26:05,330
stuff in general the only thing to

571
00:26:05,330 --> 00:26:07,190
notice there is that we're using a

572
00:26:07,190 --> 00:26:09,260
specific storage class name that

573
00:26:09,260 --> 00:26:11,210
corresponds to the storage class our

574
00:26:11,210 --> 00:26:13,970
administrator provided for us so then we

575
00:26:13,970 --> 00:26:20,000
cube control create the cluster PVC and

576
00:26:20,000 --> 00:26:22,340
it's done all right so now we're gonna

577
00:26:22,340 --> 00:26:25,100
try and roll out an application for this

578
00:26:25,100 --> 00:26:26,780
demonstration I'm just going to use

579
00:26:26,780 --> 00:26:29,420
a relatively simple and gen-x

580
00:26:29,420 --> 00:26:32,420
application you know it it listens on

581
00:26:32,420 --> 00:26:36,170
port 80 it serves on port 80 it uses the

582
00:26:36,170 --> 00:26:41,750
nginx slim container image and it mounts

583
00:26:41,750 --> 00:26:45,290
a glister volume to store its main HTML

584
00:26:45,290 --> 00:26:50,300
files so we're going to create this

585
00:26:50,300 --> 00:26:57,050
resource and it's underway so we created

586
00:26:57,050 --> 00:27:01,130
a service and a pod and now if we go

587
00:27:01,130 --> 00:27:06,500
look they're all running so now I just

588
00:27:06,500 --> 00:27:10,760
go and curl at this URL just to show you

589
00:27:10,760 --> 00:27:15,290
that it's running or that IP address and

590
00:27:15,290 --> 00:27:16,940
sure enough it's running so now I have a

591
00:27:16,940 --> 00:27:20,020
little test file where I pre wrote a a

592
00:27:20,020 --> 00:27:24,440
quick line to insert some data into the

593
00:27:24,440 --> 00:27:27,680
index.html of the nginx server we are

594
00:27:27,680 --> 00:27:30,890
now running and sure enough if we curl

595
00:27:30,890 --> 00:27:33,410
the same address again we get hello

596
00:27:33,410 --> 00:27:38,000
world from Gloucester FS now I'm going

597
00:27:38,000 --> 00:27:40,430
to I believe delete yes I'm going to

598
00:27:40,430 --> 00:27:44,110
delete the nginx service I just created

599
00:27:44,110 --> 00:27:47,710
deleted I'm going to delete the pod that

600
00:27:47,710 --> 00:27:55,780
I just created one I typed so slow okay

601
00:27:55,780 --> 00:28:00,170
and then get all to show that it's to

602
00:28:00,170 --> 00:28:01,790
show that it's not running anymore and

603
00:28:01,790 --> 00:28:04,880
then we go back and create the thing

604
00:28:04,880 --> 00:28:10,040
again and it's creating note that this

605
00:28:10,040 --> 00:28:12,800
time the service has a new IP address so

606
00:28:12,800 --> 00:28:15,350
this is a new service new pod using the

607
00:28:15,350 --> 00:28:17,690
same storage and then if we try to curl

608
00:28:17,690 --> 00:28:19,430
the same address again it's not gonna

609
00:28:19,430 --> 00:28:21,290
work because the old service is gone and

610
00:28:21,290 --> 00:28:23,360
it's been given a new IP address so we

611
00:28:23,360 --> 00:28:28,810
grabbed a new IP address curl that and

612
00:28:28,810 --> 00:28:31,820
hello world from Gloucester FS all right

613
00:28:31,820 --> 00:28:34,190
now I wish I could show you the real

614
00:28:34,190 --> 00:28:36,470
sexy thing which is where you take down

615
00:28:36,470 --> 00:28:38,510
a Gloucester node and it's all still

616
00:28:38,510 --> 00:28:40,100
running because obviously three-way

617
00:28:40,100 --> 00:28:40,919
replicate

618
00:28:40,919 --> 00:28:42,960
but trying to do that thing that's

619
00:28:42,960 --> 00:28:44,370
exactly what killed by virtual

620
00:28:44,370 --> 00:28:46,230
environment because I use libvirt

621
00:28:46,230 --> 00:28:48,480
snapshots and I forgot to take it out to

622
00:28:48,480 --> 00:28:51,000
undo the snapshot when I was taking down

623
00:28:51,000 --> 00:28:53,460
the node so things got messed up and I

624
00:28:53,460 --> 00:28:55,110
don't have the network bandwidth at this

625
00:28:55,110 --> 00:28:58,169
conference to redo my entire VM setup so

626
00:28:58,169 --> 00:29:00,919
apologies for that

627
00:29:03,030 --> 00:29:06,220
[Music]

628
00:29:06,529 --> 00:29:10,650
all right demos and with 15 minutes left

629
00:29:10,650 --> 00:29:13,320
we're done that's it for the main

630
00:29:13,320 --> 00:29:15,690
presentation you can find us on github

631
00:29:15,690 --> 00:29:17,760
and supposedly me on Twitter though I

632
00:29:17,760 --> 00:29:19,200
don't use that as often as maybe I

633
00:29:19,200 --> 00:29:22,799
should here we have a couple URLs to the

634
00:29:22,799 --> 00:29:24,750
various projects that we've mentioned

635
00:29:24,750 --> 00:29:27,659
and are working on so with that we are

636
00:29:27,659 --> 00:29:30,289
ready to take your questions

637
00:29:30,289 --> 00:29:34,399
well in the back there in the gray shirt

638
00:29:41,450 --> 00:29:43,890
that is currently being worked on the

639
00:29:43,890 --> 00:29:46,830
question was I see the question was is

640
00:29:46,830 --> 00:29:48,870
there a hump there are we considering or

641
00:29:48,870 --> 00:29:51,270
working on a helmet art to deploy all

642
00:29:51,270 --> 00:29:53,549
this instead of using a instead of you

643
00:29:53,549 --> 00:29:55,020
say a deploy script the answer is yes

644
00:29:55,020 --> 00:30:00,950
we are working on a helmet right here

645
00:30:07,799 --> 00:30:10,299
okay so can we say a little bit about

646
00:30:10,299 --> 00:30:11,769
the chicken and egg problem of the fact

647
00:30:11,769 --> 00:30:14,379
that we're using a district volume to

648
00:30:14,379 --> 00:30:15,820
store the database that manages our

649
00:30:15,820 --> 00:30:18,639
cluster volumes that is indeed a known

650
00:30:18,639 --> 00:30:20,830
chicken and egg problem the only reason

651
00:30:20,830 --> 00:30:21,879
we're doing that is because we needed

652
00:30:21,879 --> 00:30:25,269
something to persist the database

653
00:30:25,269 --> 00:30:27,489
between restart to facchetti

654
00:30:27,489 --> 00:30:29,529
that we didn't want to be bound to a

655
00:30:29,529 --> 00:30:31,509
particular host so we didn't just want

656
00:30:31,509 --> 00:30:33,399
to use local storage on any particular

657
00:30:33,399 --> 00:30:37,809
node so we figured hey we're providing

658
00:30:37,809 --> 00:30:39,639
to storage let's just throw the dip

659
00:30:39,639 --> 00:30:41,649
let's just throw the database in there

660
00:30:41,649 --> 00:30:43,989
this is kind of awkward but it works for

661
00:30:43,989 --> 00:30:46,269
now we're currently exploring other

662
00:30:46,269 --> 00:30:49,419
things to sort of distribute the

663
00:30:49,419 --> 00:30:53,019
database like using that's using sed as

664
00:30:53,019 --> 00:30:57,339
a database store for instance or just a

665
00:30:57,339 --> 00:30:59,499
slightly longer term product of getting

666
00:30:59,499 --> 00:31:01,659
rid of the database entirely and just

667
00:31:01,659 --> 00:31:03,309
trying to read information from the

668
00:31:03,309 --> 00:31:05,379
nodes directly but that requires some

669
00:31:05,379 --> 00:31:06,940
modifications on the Gluster side as

670
00:31:06,940 --> 00:31:08,580
well

671
00:31:08,580 --> 00:31:11,429
all right any other questions

672
00:31:11,429 --> 00:31:16,979
that's a backpack all right we got one

673
00:31:17,039 --> 00:31:20,039
sure

674
00:31:25,340 --> 00:31:29,620
a scaling preference excuse me

675
00:31:29,620 --> 00:31:33,110
well scheduling okay so if there's a

676
00:31:33,110 --> 00:31:35,270
skit the question was if there was in

677
00:31:35,270 --> 00:31:37,040
kubernetes if there's a scheduling

678
00:31:37,040 --> 00:31:39,920
preference when a node goes down in a

679
00:31:39,920 --> 00:31:41,390
new one needs to be spun up is that

680
00:31:41,390 --> 00:31:43,540
right

681
00:31:48,760 --> 00:31:51,350
okay if the pod gets restarted and

682
00:31:51,350 --> 00:31:53,420
there's already a volume about and

683
00:31:53,420 --> 00:31:55,520
there's already a volume mounted for

684
00:31:55,520 --> 00:31:57,920
that pod I would I don't know

685
00:31:57,920 --> 00:32:01,790
specifically but best I've seen it just

686
00:32:01,790 --> 00:32:04,520
gets it just gets remounted to the new

687
00:32:04,520 --> 00:32:08,240
pod so the vault the volume the volume

688
00:32:08,240 --> 00:32:10,520
never gets detached from the persistent

689
00:32:10,520 --> 00:32:13,880
volume claim unless the PVC itself is

690
00:32:13,880 --> 00:32:17,870
deleted so there's so there's the slight

691
00:32:17,870 --> 00:32:19,760
distinction between the PVC the PVC and

692
00:32:19,760 --> 00:32:29,440
the PV yeah again yes

693
00:32:32,870 --> 00:32:37,820
Oh like that okay so is there a

694
00:32:37,820 --> 00:32:40,279
scheduling preference on whether the pod

695
00:32:40,279 --> 00:32:43,159
will be restarted on the same node that

696
00:32:43,159 --> 00:32:46,100
already has its volume mounted on to the

697
00:32:46,100 --> 00:32:49,070
node and I don't know for certain

698
00:32:49,070 --> 00:32:51,559
my current observation of just as a

699
00:32:51,559 --> 00:32:54,500
kubernetes user indicates yes that I

700
00:32:54,500 --> 00:32:56,929
will just get started started on the on

701
00:32:56,929 --> 00:32:58,760
the node that already has the storage

702
00:32:58,760 --> 00:33:07,730
mounted right you there I couldn't tell

703
00:33:07,730 --> 00:33:09,590
you the question was what does the

704
00:33:09,590 --> 00:33:11,450
person comes between HDFS and cluster of

705
00:33:11,450 --> 00:33:15,500
us I have no idea officially all right

706
00:33:15,500 --> 00:33:19,510
there was something down here okay yes

707
00:33:19,510 --> 00:33:28,370
what same way same script yes the same

708
00:33:28,370 --> 00:33:30,890
script handles both kubernetes and

709
00:33:30,890 --> 00:33:31,789
OpenShift

710
00:33:31,789 --> 00:33:34,880
one thing I don't show in there is it

711
00:33:34,880 --> 00:33:37,970
will automatically detect whether you're

712
00:33:37,970 --> 00:33:39,679
running kubernetes or OpenShift

713
00:33:39,679 --> 00:33:41,779
and if for some reason it detects both

714
00:33:41,779 --> 00:33:43,220
it'll ask you if you want to do either

715
00:33:43,220 --> 00:33:45,350
kubernetes or openshift ideally you

716
00:33:45,350 --> 00:33:47,120
shouldn't have both but there have been

717
00:33:47,120 --> 00:33:50,480
some strange configuration cases where

718
00:33:50,480 --> 00:33:52,190
it can detect both so it just lets you

719
00:33:52,190 --> 00:33:56,570
choose but yes the same script will do

720
00:33:56,570 --> 00:33:58,039
both let's go back up there since he's

721
00:33:58,039 --> 00:34:06,580
been waiting any non containerized tools

722
00:34:07,950 --> 00:34:13,560
oh okay so the question was do you need

723
00:34:13,560 --> 00:34:15,780
any extra any non containerized tools

724
00:34:15,780 --> 00:34:19,500
for using the Gloucester volumes is that

725
00:34:19,500 --> 00:34:21,649
right

726
00:34:23,089 --> 00:34:26,790
okay best I know the let's see the other

727
00:34:26,790 --> 00:34:29,329
thing you'll need is that you need the

728
00:34:29,329 --> 00:34:32,369
what's called the hick Hettie Hettie CLI

729
00:34:32,369 --> 00:34:37,489
or hi kitty client say that again and

730
00:34:37,489 --> 00:34:39,659
yes you need Gloucester clients

731
00:34:39,659 --> 00:34:42,629
installed on all the nodes on all the

732
00:34:42,629 --> 00:34:43,918
nodes that are running Gloucester and

733
00:34:43,918 --> 00:34:46,679
you also need to open a couple firewall

734
00:34:46,679 --> 00:34:49,079
ports that Gloucester needs to be able

735
00:34:49,079 --> 00:34:51,030
to communicate with itself and its other

736
00:34:51,030 --> 00:35:00,109
member nodes the Gloucester processes

737
00:35:00,109 --> 00:35:05,190
run in containers but it needs access to

738
00:35:05,190 --> 00:35:08,250
the raw host system in order to do most

739
00:35:08,250 --> 00:35:11,520
of its actual job so the processes

740
00:35:11,520 --> 00:35:14,790
themselves are containerized but the

741
00:35:14,790 --> 00:35:16,859
tests it needs to do require actually

742
00:35:16,859 --> 00:35:18,569
require access to the actual storage

743
00:35:18,569 --> 00:35:26,119
devices I believe so

744
00:35:26,869 --> 00:35:30,359
all right anyone else this side of the

745
00:35:30,359 --> 00:35:34,730
room back over here aha

746
00:35:44,330 --> 00:35:46,970
the question was can we do storage

747
00:35:46,970 --> 00:35:54,140
tiering not automatically but you as an

748
00:35:54,140 --> 00:35:56,900
admit us an administrator can define can

749
00:35:56,900 --> 00:35:58,670
define this via storage classes of

750
00:35:58,670 --> 00:36:00,470
course you have to communicate that

751
00:36:00,470 --> 00:36:02,750
information to your user somehow so you

752
00:36:02,750 --> 00:36:04,340
would create usually the standard

753
00:36:04,340 --> 00:36:07,250
demonstration is you create a gold

754
00:36:07,250 --> 00:36:09,080
storage class a silver in a silver

755
00:36:09,080 --> 00:36:11,030
storage class and then you just tell

756
00:36:11,030 --> 00:36:13,550
your users all right gold is like super

757
00:36:13,550 --> 00:36:15,680
fast non-volatile memory access

758
00:36:15,680 --> 00:36:20,060
silver is SSDs and then like Stone is

759
00:36:20,060 --> 00:36:26,920
you know spinning rust all right

760
00:36:26,920 --> 00:36:30,470
anything else doesn't seem like it I'm

761
00:36:30,470 --> 00:36:33,030
calling a dumb thank you very much

762
00:36:33,030 --> 00:36:39,849
[Applause]

