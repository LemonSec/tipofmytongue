1
00:00:06,370 --> 00:00:08,840
all right so continuing on our spark

2
00:00:08,840 --> 00:00:11,510
theme next stop is Nicholas and

3
00:00:11,510 --> 00:00:14,299
Alexandra who actually was taking us

4
00:00:14,299 --> 00:00:16,250
through a cage match between spark and

5
00:00:16,250 --> 00:00:29,750
pipe so take it away guys yes but you

6
00:00:29,750 --> 00:00:34,660
also need to take for the recording

7
00:00:41,739 --> 00:00:45,040
ah all right first of all thank you very

8
00:00:45,040 --> 00:00:47,079
much for attending this line in talk I'm

9
00:00:47,079 --> 00:00:49,510
Alejandra Montero master student the

10
00:00:49,510 --> 00:00:51,550
personal supercomputing Center and in

11
00:00:51,550 --> 00:00:52,960
the last couple of months we've been

12
00:00:52,960 --> 00:00:54,760
working with big bench to compare the

13
00:00:54,760 --> 00:00:56,320
performance of different big data

14
00:00:56,320 --> 00:00:58,960
engines specifically we're focusing on -

15
00:00:58,960 --> 00:01:02,170
spark so big bench is an ax

16
00:01:02,170 --> 00:01:04,269
specification based benchmark with an

17
00:01:04,269 --> 00:01:06,399
open source implementation and recently

18
00:01:06,399 --> 00:01:09,190
it's been proposed to be the first big

19
00:01:09,190 --> 00:01:11,710
data benchmark on the world and that's

20
00:01:11,710 --> 00:01:14,550
because right now it's the only one that

21
00:01:14,550 --> 00:01:16,679
covers all measure big data

22
00:01:16,679 --> 00:01:19,179
characteristics and as you may know they

23
00:01:19,179 --> 00:01:22,270
are the volume variety and velocity some

24
00:01:22,270 --> 00:01:24,640
very quick characteristics of big bench

25
00:01:24,640 --> 00:01:27,130
it's an extension of TCP des that some

26
00:01:27,130 --> 00:01:30,640
new SQL queries and use cases as your

27
00:01:30,640 --> 00:01:32,200
machine learning natural language

28
00:01:32,200 --> 00:01:35,170
processing some others it comes from

29
00:01:35,170 --> 00:01:37,390
multiple implementations and genes and

30
00:01:37,390 --> 00:01:40,690
table formats for hive it can also

31
00:01:40,690 --> 00:01:42,759
execute multiple parallel streams at the

32
00:01:42,759 --> 00:01:44,890
same time in the same cluster and can

33
00:01:44,890 --> 00:01:46,990
define different scale factors we used

34
00:01:46,990 --> 00:01:48,820
scale factor of 100 which is

35
00:01:48,820 --> 00:01:53,320
approximately 100 gigs internal size so

36
00:01:53,320 --> 00:01:57,060
big bench what it's doing it's emulating

37
00:01:57,060 --> 00:01:59,619
store that it's selling items both

38
00:01:59,619 --> 00:02:02,740
physically and unbe a web page and for

39
00:02:02,740 --> 00:02:06,219
that reason it provides these these data

40
00:02:06,219 --> 00:02:09,940
structure first we have the structured

41
00:02:09,940 --> 00:02:11,380
data which is the one we're used to

42
00:02:11,380 --> 00:02:15,040
easily index and recoverable and we add

43
00:02:15,040 --> 00:02:17,590
two more which is the web block which

44
00:02:17,590 --> 00:02:19,420
contains a click streams of every user

45
00:02:19,420 --> 00:02:20,799
that it's navigating through the web

46
00:02:20,799 --> 00:02:24,250
page and the reviews of the users that

47
00:02:24,250 --> 00:02:26,109
actually have bought an item and want to

48
00:02:26,109 --> 00:02:29,350
make a review so for the workload itself

49
00:02:29,350 --> 00:02:31,060
there's three queries divided in four

50
00:02:31,060 --> 00:02:34,390
kind of use cases 14 pure pure coil

51
00:02:34,390 --> 00:02:36,160
queries which retrieve information from

52
00:02:36,160 --> 00:02:38,799
the structure section then we have four

53
00:02:38,799 --> 00:02:41,170
queries of MapReduce pre-processing of

54
00:02:41,170 --> 00:02:43,329
the data before selecting it seven

55
00:02:43,329 --> 00:02:45,010
natural language processing queries and

56
00:02:45,010 --> 00:02:49,359
five machine learning queries so don't

57
00:02:49,359 --> 00:02:51,750
be overwhelmed by this this is the

58
00:02:51,750 --> 00:02:54,400
server stack of the implementation we've

59
00:02:54,400 --> 00:02:55,569
been using

60
00:02:55,569 --> 00:02:57,430
very fast starting from the bottom to

61
00:02:57,430 --> 00:02:59,950
top all files are physically stored in

62
00:02:59,950 --> 00:03:03,099
the in distributed file system but as

63
00:03:03,099 --> 00:03:05,200
we're running queries we need to have a

64
00:03:05,200 --> 00:03:08,530
middleware emitter store to store the

65
00:03:08,530 --> 00:03:12,010
logical tables and on top of that we

66
00:03:12,010 --> 00:03:14,200
need that SQL engine that is receiving

67
00:03:14,200 --> 00:03:16,329
the the credits from a big bench

68
00:03:16,329 --> 00:03:18,609
it's parsing them and it's retrieving

69
00:03:18,609 --> 00:03:20,530
the information from the meta store once

70
00:03:20,530 --> 00:03:24,069
we have the location of the of the of

71
00:03:24,069 --> 00:03:25,870
the files we want to recover we can use

72
00:03:25,870 --> 00:03:28,299
one of these three engines and one of

73
00:03:28,299 --> 00:03:30,129
the execution engines to actually

74
00:03:30,129 --> 00:03:31,569
retrieve the physical information from

75
00:03:31,569 --> 00:03:34,150
each DFS the engines can be classic

76
00:03:34,150 --> 00:03:36,879
MapReduce tests which maybe you don't

77
00:03:36,879 --> 00:03:38,889
know about it it's a hack on top of

78
00:03:38,889 --> 00:03:41,079
MapReduce to clear create a director

79
00:03:41,079 --> 00:03:43,120
city graph to reduce latencies and

80
00:03:43,120 --> 00:03:45,159
improve overall performance of of

81
00:03:45,159 --> 00:03:47,730
mappers and reducers and spark engine

82
00:03:47,730 --> 00:03:51,519
and for the machine learning queries we

83
00:03:51,519 --> 00:03:53,889
also need a new application to perform

84
00:03:53,889 --> 00:03:56,530
the DES learning techniques and we can

85
00:03:56,530 --> 00:03:57,760
use two applications

86
00:03:57,760 --> 00:04:00,040
mahout which is based on MapReduce or

87
00:04:00,040 --> 00:04:02,919
spark Mlle a custom-built spark Emily

88
00:04:02,919 --> 00:04:07,930
library so of course John is the one

89
00:04:07,930 --> 00:04:09,579
that's managing all the containers for

90
00:04:09,579 --> 00:04:12,220
every single application and here

91
00:04:12,220 --> 00:04:14,889
so we've benchmarked all permutations of

92
00:04:14,889 --> 00:04:18,070
the engines you see in in this slide but

93
00:04:18,070 --> 00:04:20,620
we still have a few working progress

94
00:04:20,620 --> 00:04:23,590
things and we have some results for hive

95
00:04:23,590 --> 00:04:25,780
two but the they are quite odd so we're

96
00:04:25,780 --> 00:04:28,150
still working on that and also for spark

97
00:04:28,150 --> 00:04:30,760
- it was compatible with mahout but the

98
00:04:30,760 --> 00:04:33,039
custom library was not binary compatible

99
00:04:33,039 --> 00:04:36,220
with a spark - so major code refractor

100
00:04:36,220 --> 00:04:37,930
is needed and we hope to get results

101
00:04:37,930 --> 00:04:41,830
pretty soon huh twice we're using an

102
00:04:41,830 --> 00:04:44,229
hdinsight platform as a service cluster

103
00:04:44,229 --> 00:04:49,750
model dd4b39 outs featuring a hike an

104
00:04:49,750 --> 00:04:52,449
intelligent CPU with eight cores twenty

105
00:04:52,449 --> 00:04:55,120
eight gigs of ram and the HDFS is

106
00:04:55,120 --> 00:04:57,759
completely remote for the software stack

107
00:04:57,759 --> 00:05:00,009
AGI is realizing on Hortonworks that a

108
00:05:00,009 --> 00:05:01,330
platform 2.5

109
00:05:01,330 --> 00:05:03,849
we've noticed that both MapReduce and

110
00:05:03,849 --> 00:05:06,070
des are really well tuned so we decided

111
00:05:06,070 --> 00:05:09,310
not to change a bit of the configuration

112
00:05:09,310 --> 00:05:10,810
what we did notice though is that

113
00:05:10,810 --> 00:05:13,450
sparked was recently added and the

114
00:05:13,450 --> 00:05:17,050
computations what strange it's only

115
00:05:17,050 --> 00:05:19,060
using one executed per walking node and

116
00:05:19,060 --> 00:05:21,070
that executor has three out of eight

117
00:05:21,070 --> 00:05:23,950
cores available in the machine so for

118
00:05:23,950 --> 00:05:26,620
the results we decided to divide it in

119
00:05:26,620 --> 00:05:29,770
use cases starting for pure quell as

120
00:05:29,770 --> 00:05:31,780
expected mapreduces this lowest one on

121
00:05:31,780 --> 00:05:34,030
the group followed by the fastest one

122
00:05:34,030 --> 00:05:36,070
which is spark two which is very close

123
00:05:36,070 --> 00:05:37,900
to the other engine spark one and five

124
00:05:37,900 --> 00:05:41,710
tests we wanted to see a little bit more

125
00:05:41,710 --> 00:05:43,540
what was happening inside a pure core

126
00:05:43,540 --> 00:05:47,110
query so this is a trace of the CPU

127
00:05:47,110 --> 00:05:48,520
behavior of one of the queries for a

128
00:05:48,520 --> 00:05:52,360
twelve to be correct consist what we can

129
00:05:52,360 --> 00:05:55,690
see here is that test it's reaching 100%

130
00:05:55,690 --> 00:05:57,970
of the CPU usage which indicates its CPU

131
00:05:57,970 --> 00:06:02,440
bounded also in this case you don't you

132
00:06:02,440 --> 00:06:04,360
cannot see the numbers because of

133
00:06:04,360 --> 00:06:07,900
resizing reasons well it's a lot faster

134
00:06:07,900 --> 00:06:11,170
than both the other engines test is

135
00:06:11,170 --> 00:06:13,840
finishing in 100 seconds sparks is

136
00:06:13,840 --> 00:06:16,510
finishing in 200 seconds and spark 2 in

137
00:06:16,510 --> 00:06:20,080
116 moving on we see that spark one

138
00:06:20,080 --> 00:06:21,580
spark to you both are reaching at the

139
00:06:21,580 --> 00:06:25,750
top of 30 percent of CPU usage sorry you

140
00:06:25,750 --> 00:06:29,470
can't see the y-axis most interestingly

141
00:06:29,470 --> 00:06:32,110
we can see that spark a spark one has a

142
00:06:32,110 --> 00:06:33,700
lot of fire wait for some reason and

143
00:06:33,700 --> 00:06:36,640
spark do deals with that it doesn't show

144
00:06:36,640 --> 00:06:41,110
any more I wait and it ends lot faster

145
00:06:41,110 --> 00:06:44,290
in this case also it is using only 30%

146
00:06:44,290 --> 00:06:46,450
of the of the CPU and that may be

147
00:06:46,450 --> 00:06:48,310
because of the software configuration I

148
00:06:48,310 --> 00:06:53,320
just talked about you for very fast for

149
00:06:53,320 --> 00:06:55,210
the second use case custom reducers to

150
00:06:55,210 --> 00:06:57,250
pre-process data before selecting it we

151
00:06:57,250 --> 00:06:59,500
see that high test is the fastest one

152
00:06:59,500 --> 00:07:02,380
here followed by spark 2 and very close

153
00:07:02,380 --> 00:07:04,270
to spark one my previews again is the

154
00:07:04,270 --> 00:07:07,810
slowest one Mui GaN natural language

155
00:07:07,810 --> 00:07:10,360
processing here tests once again it's

156
00:07:10,360 --> 00:07:12,960
the winner by a longshot in these case

157
00:07:12,960 --> 00:07:16,420
followed by spark to spark one really

158
00:07:16,420 --> 00:07:18,130
close to spark 2 and my previews is

159
00:07:18,130 --> 00:07:20,599
really really slow

160
00:07:20,599 --> 00:07:22,369
and finally for the machine learning

161
00:07:22,369 --> 00:07:24,740
sections we can see two interesting

162
00:07:24,740 --> 00:07:26,270
things here first of all is that

163
00:07:26,270 --> 00:07:28,669
changing one execution engine for the

164
00:07:28,669 --> 00:07:30,740
other doesn't bring as any real

165
00:07:30,740 --> 00:07:33,649
difference in performance but what does

166
00:07:33,649 --> 00:07:35,300
givers are different in performance is

167
00:07:35,300 --> 00:07:37,520
changing the application that actually

168
00:07:37,520 --> 00:07:38,679
performs the machine learning and

169
00:07:38,679 --> 00:07:41,509
changing from mahout in n is any of the

170
00:07:41,509 --> 00:07:44,419
of the engines to spark ml Alip give us

171
00:07:44,419 --> 00:07:47,199
a two times improvement in performance

172
00:07:47,199 --> 00:07:50,029
as I said before unfortunately we were

173
00:07:50,029 --> 00:07:52,729
not able to test spark to with Sparky

174
00:07:52,729 --> 00:07:55,369
Mela leap but we're hoping to see two

175
00:07:55,369 --> 00:07:57,020
times improvement and well as in the

176
00:07:57,020 --> 00:08:00,139
other cases and finally for the

177
00:08:00,139 --> 00:08:02,080
aggregated results for the for use cases

178
00:08:02,080 --> 00:08:04,849
what we can see is that for the whole

179
00:08:04,849 --> 00:08:07,520
group the fastest one here is tests plus

180
00:08:07,520 --> 00:08:11,899
a spark Mlle second in line is a spark

181
00:08:11,899 --> 00:08:13,759
one with spark Emily leap followed by

182
00:08:13,759 --> 00:08:17,599
spark two but plasma mahout we're hoping

183
00:08:17,599 --> 00:08:19,909
to see spark two plus spark ml a leap to

184
00:08:19,909 --> 00:08:22,639
be lot faster when we have results but

185
00:08:22,639 --> 00:08:24,559
right now it's on the third position and

186
00:08:24,559 --> 00:08:26,990
mapreduces this law was one on the on

187
00:08:26,990 --> 00:08:31,999
the group so just to finish some

188
00:08:31,999 --> 00:08:33,979
conclusions we can gather from from

189
00:08:33,979 --> 00:08:38,078
these results fist of five plus tests is

190
00:08:38,078 --> 00:08:40,309
improving the SQL performance by a long

191
00:08:40,309 --> 00:08:40,729
shot

192
00:08:40,729 --> 00:08:44,600
by over MapReduce it's slightly faster

193
00:08:44,600 --> 00:08:47,149
than spark one but it is lightly it's

194
00:08:47,149 --> 00:08:51,230
lower than spark two and we have to make

195
00:08:51,230 --> 00:08:53,810
clear something in in that point in this

196
00:08:53,810 --> 00:08:55,880
point is that the implementation spark

197
00:08:55,880 --> 00:08:57,889
of the queries I mean the implementation

198
00:08:57,889 --> 00:09:00,319
spark is using it the same as they have

199
00:09:00,319 --> 00:09:02,600
one so they are using the same the very

200
00:09:02,600 --> 00:09:04,880
same SQL queries and in this

201
00:09:04,880 --> 00:09:06,740
implementation these words are very

202
00:09:06,740 --> 00:09:10,519
optimized for hive so maybe tweaking for

203
00:09:10,519 --> 00:09:13,180
spark may give us out different results

204
00:09:13,180 --> 00:09:15,800
second conclusion we got from these

205
00:09:15,800 --> 00:09:18,050
these studies that spark amela leap is

206
00:09:18,050 --> 00:09:20,660
way faster than Mahad we encourage you

207
00:09:20,660 --> 00:09:23,360
to use it instead of it and finally the

208
00:09:23,360 --> 00:09:26,329
best production company at the moment is

209
00:09:26,329 --> 00:09:28,939
using apache tests for the SQL sections

210
00:09:28,939 --> 00:09:30,850
of your queries and if you need to do a

211
00:09:30,850 --> 00:09:33,030
machine learning technique

212
00:09:33,030 --> 00:09:35,550
stick with Emily which is the fastest

213
00:09:35,550 --> 00:09:39,210
one so before finishing I encourage you

214
00:09:39,210 --> 00:09:41,190
to assist tomorrow to our presentation

215
00:09:41,190 --> 00:09:44,430
my colleague Nico is doing using for

216
00:09:44,430 --> 00:09:47,220
using a non-volatile memory to improve

217
00:09:47,220 --> 00:09:50,190
performance of HBase Hadoop and and all

218
00:09:50,190 --> 00:09:52,400
this stuff quite interesting building

219
00:09:52,400 --> 00:09:56,610
you at 12 o'clock so encourage you to

220
00:09:56,610 --> 00:09:59,820
attend and that would be all thank you

221
00:09:59,820 --> 00:10:00,330
very much

222
00:10:00,330 --> 00:10:14,880
we've had any question all right well

223
00:10:14,880 --> 00:10:17,900
thank you so much thank you

