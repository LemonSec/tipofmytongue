1
00:00:00,000 --> 00:00:02,480
wait speak

2
00:00:04,770 --> 00:00:06,870
see which is what we've been talking

3
00:00:06,870 --> 00:00:09,870
about so far today mainly and I might

4
00:00:09,870 --> 00:00:12,980
sneak in another buzzword serverless I

5
00:00:12,980 --> 00:00:15,450
was gonna sneak in unico NAL's as well

6
00:00:15,450 --> 00:00:16,079
but I won't

7
00:00:16,079 --> 00:00:19,470
so then anyway that's me that's where I

8
00:00:19,470 --> 00:00:21,900
work the probably interesting thing

9
00:00:21,900 --> 00:00:24,029
there is that was 650 million when the

10
00:00:24,029 --> 00:00:25,679
pound actually had some value which it

11
00:00:25,679 --> 00:00:35,519
doesn't anymore yeah okay so the first

12
00:00:35,519 --> 00:00:37,920
point to make is that I think in my

13
00:00:37,920 --> 00:00:40,140
experience the traditional model of HBC

14
00:00:40,140 --> 00:00:43,830
we've got a big cluster it's quite

15
00:00:43,830 --> 00:00:46,049
expensive you've got maybe restricted

16
00:00:46,049 --> 00:00:48,150
set of users that's becoming under

17
00:00:48,150 --> 00:00:50,879
increasing pressure from funding bodies

18
00:00:50,879 --> 00:00:53,489
so there in the past I've had to do cost

19
00:00:53,489 --> 00:00:56,010
comparisons of would it be cheaper if we

20
00:00:56,010 --> 00:00:59,159
did this on AWS or Azure or Google

21
00:00:59,159 --> 00:01:01,140
compute so funding bodies are

22
00:01:01,140 --> 00:01:04,470
complaining we also see that kind of

23
00:01:04,470 --> 00:01:07,770
complaints inside organizations again

24
00:01:07,770 --> 00:01:10,259
they're there on the golf course and

25
00:01:10,259 --> 00:01:11,490
they hear about the cloud and say why

26
00:01:11,490 --> 00:01:12,869
can't you use the cloud isn't that

27
00:01:12,869 --> 00:01:16,380
cheaper and then you get research groups

28
00:01:16,380 --> 00:01:18,630
who are they've got a three year project

29
00:01:18,630 --> 00:01:20,880
and then with two months to go they

30
00:01:20,880 --> 00:01:22,079
suddenly need to analyze all their

31
00:01:22,079 --> 00:01:24,659
patient data and they need 10,000 calls

32
00:01:24,659 --> 00:01:27,270
to do it and you're not going to procure

33
00:01:27,270 --> 00:01:29,159
a new 10 doesn't call cluster in two

34
00:01:29,159 --> 00:01:33,149
months so can we use the cloud example

35
00:01:33,149 --> 00:01:35,729
of a cloud that I I work on is e med lab

36
00:01:35,729 --> 00:01:39,450
which is a biomedical research cloud so

37
00:01:39,450 --> 00:01:41,640
that's the only sort of workload that we

38
00:01:41,640 --> 00:01:44,969
have on their 6000 cos 5 north petabytes

39
00:01:44,969 --> 00:01:47,520
of storage it's a consortium of

40
00:01:47,520 --> 00:01:49,799
organizations around London and South

41
00:01:49,799 --> 00:01:52,829
East England and one of the guiding

42
00:01:52,829 --> 00:01:55,409
principles is that the data methods and

43
00:01:55,409 --> 00:01:57,359
expertise must be shared amongst the

44
00:01:57,359 --> 00:02:03,229
users it's using OpenStack and gpfs

45
00:02:06,520 --> 00:02:09,619
so gpfs a very traditional sort of fast

46
00:02:09,619 --> 00:02:12,020
foul system that you would find in lots

47
00:02:12,020 --> 00:02:15,380
of HPC clusters along with luster but it

48
00:02:15,380 --> 00:02:16,730
assumes you've got a nice friendly

49
00:02:16,730 --> 00:02:18,410
environment where it's okay to have

50
00:02:18,410 --> 00:02:20,780
roots SSH in between all the nodes which

51
00:02:20,780 --> 00:02:22,370
is not really what you would expect on a

52
00:02:22,370 --> 00:02:23,000
cloud

53
00:02:23,000 --> 00:02:25,280
it also has complications with a

54
00:02:25,280 --> 00:02:27,380
licensing so if you wanted to get around

55
00:02:27,380 --> 00:02:30,980
that wish to isolate yourself from

56
00:02:30,980 --> 00:02:34,190
potentially meta lying cloud instances

57
00:02:34,190 --> 00:02:36,349
maybe you would try and run a server on

58
00:02:36,349 --> 00:02:37,239
the hypervisor

59
00:02:37,239 --> 00:02:40,160
but then would IBM be happy with that

60
00:02:40,160 --> 00:02:42,950
kind of licensing maybe maybe not but

61
00:02:42,950 --> 00:02:45,049
probably lawyers would be involved and

62
00:02:45,049 --> 00:02:47,530
that means a bit more money so the way

63
00:02:47,530 --> 00:02:49,040
well-rounded that we have at the moment

64
00:02:49,040 --> 00:02:51,290
is just exporting over NFS and I know

65
00:02:51,290 --> 00:02:53,480
that the client project which is a

66
00:02:53,480 --> 00:02:55,880
microbial bioinformatics project in the

67
00:02:55,880 --> 00:02:58,459
UK has also had to do the same thing so

68
00:02:58,459 --> 00:02:59,569
you're kind of losing a lot of the

69
00:02:59,569 --> 00:03:02,390
performance that you gain by having GPFS

70
00:03:02,390 --> 00:03:03,769
in the first place which is a bit of a

71
00:03:03,769 --> 00:03:08,330
shame but this access to shared data is

72
00:03:08,330 --> 00:03:10,430
a founding goal of the project and it's

73
00:03:10,430 --> 00:03:12,380
what people need it's not just when

74
00:03:12,380 --> 00:03:15,170
they're writing their data they need to

75
00:03:15,170 --> 00:03:17,600
refer to things they know these very

76
00:03:17,600 --> 00:03:20,810
large publicly curated datasets that the

77
00:03:20,810 --> 00:03:22,310
jobs need to refer to when they're

78
00:03:22,310 --> 00:03:26,060
running but the cloud person would say

79
00:03:26,060 --> 00:03:27,530
why don't you use an object store

80
00:03:27,530 --> 00:03:29,510
they're much more scalable much more

81
00:03:29,510 --> 00:03:32,090
sensible but if you can find

82
00:03:32,090 --> 00:03:34,069
bioinformatics code that supports

83
00:03:34,069 --> 00:03:36,350
objects then I'll be very happy they

84
00:03:36,350 --> 00:03:40,100
don't really exist an example I worked

85
00:03:40,100 --> 00:03:43,400
with is an 800 terabyte data set from

86
00:03:43,400 --> 00:03:45,170
TCG C which is the Cancer Genome

87
00:03:45,170 --> 00:03:48,920
consortium so this is because it become

88
00:03:48,920 --> 00:03:51,500
comes from patients you have to apply

89
00:03:51,500 --> 00:03:55,549
for access to the data so we have to be

90
00:03:55,549 --> 00:03:57,950
extra careful on who within the project

91
00:03:57,950 --> 00:04:02,180
can see it and hopefully you can only

92
00:04:02,180 --> 00:04:04,280
download it by a special client which is

93
00:04:04,280 --> 00:04:08,510
really weird and we actually had to by

94
00:04:08,510 --> 00:04:10,940
trial-and-error work out how many

95
00:04:10,940 --> 00:04:13,189
instances we needed to run off the

96
00:04:13,189 --> 00:04:15,019
client to download in a reasonable

97
00:04:15,019 --> 00:04:17,750
period to run twelve instances in

98
00:04:17,750 --> 00:04:18,410
parallel

99
00:04:18,410 --> 00:04:21,769
and it took us two weeks or something so

100
00:04:21,769 --> 00:04:23,450
it's quite a pain to deal with SS of

101
00:04:23,450 --> 00:04:27,800
this size on clouds when you've got your

102
00:04:27,800 --> 00:04:29,360
data what you're going to do with it

103
00:04:29,360 --> 00:04:32,000
what we've found is people want to run

104
00:04:32,000 --> 00:04:33,410
virtual clusters that's what they used

105
00:04:33,410 --> 00:04:35,210
to so they use things like elastic

106
00:04:35,210 --> 00:04:37,610
cluster or if they use clouds before

107
00:04:37,610 --> 00:04:39,920
they might use heat or cloud formation

108
00:04:39,920 --> 00:04:42,950
or maybe they just create a cluster

109
00:04:42,950 --> 00:04:46,190
using ansible or salt again you've got

110
00:04:46,190 --> 00:04:47,570
the problem of shared file system access

111
00:04:47,570 --> 00:04:51,020
I think the question arises to me is

112
00:04:51,020 --> 00:04:55,280
that actually the best way of using a

113
00:04:55,280 --> 00:04:57,500
cloud is it are you really getting the

114
00:04:57,500 --> 00:04:59,240
benefit from a cloud you're going to

115
00:04:59,240 --> 00:05:00,860
start upload of instances which may not

116
00:05:00,860 --> 00:05:02,450
be doing that much a lot of the time

117
00:05:02,450 --> 00:05:05,210
wouldn't it be better to get to know

118
00:05:05,210 --> 00:05:08,720
your your pipeline better and maybe

119
00:05:08,720 --> 00:05:10,310
maybe there's one step where you're

120
00:05:10,310 --> 00:05:11,960
hardly doing anything but then you need

121
00:05:11,960 --> 00:05:14,060
to spin up another ten then get rid of a

122
00:05:14,060 --> 00:05:16,190
turn get get another five but people

123
00:05:16,190 --> 00:05:17,660
don't tend to know their pipelines in

124
00:05:17,660 --> 00:05:21,890
that level of detail and I think the

125
00:05:21,890 --> 00:05:23,810
reason that people sort of rely on this

126
00:05:23,810 --> 00:05:26,660
crutch of a cluster is it goes back to

127
00:05:26,660 --> 00:05:28,100
their mindset that you have of all

128
00:05:28,100 --> 00:05:29,690
you've got a cluster it's got to be used

129
00:05:29,690 --> 00:05:31,730
all the time you've got sort of 90%

130
00:05:31,730 --> 00:05:34,610
utilization of your cluster irrespective

131
00:05:34,610 --> 00:05:35,690
of whether you're actually doing work

132
00:05:35,690 --> 00:05:41,300
that's worth doing so conversely you get

133
00:05:41,300 --> 00:05:44,480
people who get frustrated by some of the

134
00:05:44,480 --> 00:05:47,450
performance disk benefits that you get

135
00:05:47,450 --> 00:05:48,770
with clouds because of all the layers of

136
00:05:48,770 --> 00:05:51,380
indirection in the i/o so they heavily

137
00:05:51,380 --> 00:05:54,020
tuned it particularly the network stack

138
00:05:54,020 --> 00:05:55,700
but then you lose things like live

139
00:05:55,700 --> 00:05:57,920
migration again one of the benefits of

140
00:05:57,920 --> 00:06:02,600
clouds and I think you also when you're

141
00:06:02,600 --> 00:06:04,970
going down that road you lose the

142
00:06:04,970 --> 00:06:07,520
flexibility and the kinds of workloads

143
00:06:07,520 --> 00:06:08,690
we've talked about in this room today

144
00:06:08,690 --> 00:06:11,870
the big data workloads the increasing

145
00:06:11,870 --> 00:06:14,810
wish that people have to integrate say

146
00:06:14,810 --> 00:06:17,300
in my field you might have sequencing

147
00:06:17,300 --> 00:06:18,860
data and maybe you want to integrate

148
00:06:18,860 --> 00:06:21,050
that with mass spectrometry data with

149
00:06:21,050 --> 00:06:24,080
electron microscopy data so what is more

150
00:06:24,080 --> 00:06:29,630
important there I think than the the raw

151
00:06:29,630 --> 00:06:32,080
sort of single-threaded performance is

152
00:06:32,080 --> 00:06:34,090
getting the software working together

153
00:06:34,090 --> 00:06:37,460
that's that's the sort of time game that

154
00:06:37,460 --> 00:06:40,280
you're going to get I think I've also

155
00:06:40,280 --> 00:06:43,810
found that people are particularly

156
00:06:43,810 --> 00:06:46,370
focused on snapshots as soon as they've

157
00:06:46,370 --> 00:06:47,780
got something working on the cloud they

158
00:06:47,780 --> 00:06:49,340
say okay can we make a snapshot of that

159
00:06:49,340 --> 00:06:52,010
just in case it goes wrong but then what

160
00:06:52,010 --> 00:06:53,000
you're going to do with this snapshot

161
00:06:53,000 --> 00:06:55,790
what if you know there's a bug in

162
00:06:55,790 --> 00:06:57,650
OpenSSL was if that could ever happen

163
00:06:57,650 --> 00:07:00,950
and they need to grade it who's keeping

164
00:07:00,950 --> 00:07:02,450
track of which images are being used

165
00:07:02,450 --> 00:07:04,940
where who really knows what's inside the

166
00:07:04,940 --> 00:07:07,550
image wouldn't it be best if you use

167
00:07:07,550 --> 00:07:09,290
some kind of configuration management to

168
00:07:09,290 --> 00:07:13,280
build it and I've seen I I was at the

169
00:07:13,280 --> 00:07:14,600
OpenStack meetup in London

170
00:07:14,600 --> 00:07:16,430
this week and people were criticizing

171
00:07:16,430 --> 00:07:19,220
triple o because that's image centric

172
00:07:19,220 --> 00:07:20,900
they were saying we'll just use

173
00:07:20,900 --> 00:07:23,870
OpenStack ansible instead I've said

174
00:07:23,870 --> 00:07:28,940
already so this is a slide that I'm

175
00:07:28,940 --> 00:07:32,330
quite happy to Nick because it you know

176
00:07:32,330 --> 00:07:34,490
turning into micro services which is

177
00:07:34,490 --> 00:07:35,360
what you're supposed to do for

178
00:07:35,360 --> 00:07:38,930
containers if the input is not good the

179
00:07:38,930 --> 00:07:46,910
output may not be good either so I think

180
00:07:46,910 --> 00:07:49,490
they I think it's very good that we in

181
00:07:49,490 --> 00:07:51,320
this community look outside ourselves

182
00:07:51,320 --> 00:07:55,130
for fertile ideas but bear in mind that

183
00:07:55,130 --> 00:07:57,320
the mindset that people have in these

184
00:07:57,320 --> 00:07:59,390
startups in Shoreditch and the

185
00:07:59,390 --> 00:08:00,890
constraints they have is very different

186
00:08:00,890 --> 00:08:03,050
from what we have in the scientific

187
00:08:03,050 --> 00:08:07,250
community how mature is the support of

188
00:08:07,250 --> 00:08:09,050
scientific applications in containers I

189
00:08:09,050 --> 00:08:11,360
mean singularity and shift over very

190
00:08:11,360 --> 00:08:16,880
good projects but with things like the

191
00:08:16,880 --> 00:08:19,460
docker file and the singularity files

192
00:08:19,460 --> 00:08:22,250
are they really great formats for

193
00:08:22,250 --> 00:08:26,740
describing what you need maybe maybe not

194
00:08:26,740 --> 00:08:28,970
and aren't contains a bit rubbish anyway

195
00:08:28,970 --> 00:08:30,530
because you still need to run a server

196
00:08:30,530 --> 00:08:33,979
and who wants to do that you should be

197
00:08:33,979 --> 00:08:36,830
using it patchy lambda Google cloud

198
00:08:36,830 --> 00:08:40,490
functions or open whisk and fishing but

199
00:08:40,490 --> 00:08:44,059
I don't see any any input from the

200
00:08:44,059 --> 00:08:45,440
scientific community into

201
00:08:45,440 --> 00:08:47,000
those yet so I think we need to start

202
00:08:47,000 --> 00:08:49,190
engage gauging with the service

203
00:08:49,190 --> 00:08:52,640
developers there's a counterexample to

204
00:08:52,640 --> 00:08:55,760
all that doom and gloom when in my

205
00:08:55,760 --> 00:08:58,580
previous job at Imperial College when I

206
00:08:58,580 --> 00:09:01,220
was working on the CMS experiment when

207
00:09:01,220 --> 00:09:03,500
they had a cloud resources because they

208
00:09:03,500 --> 00:09:05,150
had a very mature environment that's all

209
00:09:05,150 --> 00:09:06,440
that that's nice we've got thirteen

210
00:09:06,440 --> 00:09:08,510
thousand cause we can use those because

211
00:09:08,510 --> 00:09:11,300
they've already got all the tools to

212
00:09:11,300 --> 00:09:12,920
move data around to keep track of what

213
00:09:12,920 --> 00:09:14,600
data is where they've already got a

214
00:09:14,600 --> 00:09:16,340
counting tool so you know which users

215
00:09:16,340 --> 00:09:19,910
are running what and there were some

216
00:09:19,910 --> 00:09:23,180
concerns about security as in when you

217
00:09:23,180 --> 00:09:24,740
need to ban a user how do you know what

218
00:09:24,740 --> 00:09:29,000
they've been running where but they were

219
00:09:29,000 --> 00:09:30,830
actually able to make and are still

220
00:09:30,830 --> 00:09:32,420
making very good use of cloud so it is

221
00:09:32,420 --> 00:09:35,170
possible that's it

222
00:09:35,170 --> 00:09:42,839
[Applause]

223
00:09:53,750 --> 00:09:56,840
[Music]

224
00:10:17,400 --> 00:10:20,600
what you think

