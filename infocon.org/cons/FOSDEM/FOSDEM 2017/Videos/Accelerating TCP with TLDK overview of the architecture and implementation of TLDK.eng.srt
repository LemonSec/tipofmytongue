1
00:00:26,080 --> 00:00:28,110
[Music]

2
00:00:28,110 --> 00:00:31,110
okay

3
00:00:39,320 --> 00:00:42,489
it's not about earlier

4
00:00:44,420 --> 00:00:51,829
[Music]

5
00:00:58,160 --> 00:01:07,890
okay so now I'm too loud my name is very

6
00:01:07,890 --> 00:01:11,490
cancer I've been working on data plane

7
00:01:11,490 --> 00:01:14,430
technologies for the last eight or ten

8
00:01:14,430 --> 00:01:15,510
years

9
00:01:15,510 --> 00:01:18,440
[Music]

10
00:01:18,440 --> 00:01:23,670
DPD ka VPP and i know t LD k tonight

11
00:01:23,670 --> 00:01:25,979
with you today i'm going to talk about

12
00:01:25,979 --> 00:01:29,970
CTL DK and why we'll have a while

13
00:01:29,970 --> 00:01:41,009
interested in accelerating tcp void tcp

14
00:01:41,009 --> 00:01:44,360
performance matters well I guess

15
00:01:44,360 --> 00:01:46,860
performance is really a heavily a part

16
00:01:46,860 --> 00:01:49,740
of user experience you know in the

17
00:01:49,740 --> 00:01:53,159
wireless network TCP dominates TCP makes

18
00:01:53,159 --> 00:01:55,770
up a bell I think 95 percent of traffic

19
00:01:55,770 --> 00:02:01,429
in the cellular network about 4% is UDP

20
00:02:01,610 --> 00:02:06,479
the rest of its in the noise TCP flows

21
00:02:06,479 --> 00:02:09,830
tend to be small which is problematic

22
00:02:09,830 --> 00:02:14,610
means that you go to all the effort of

23
00:02:14,610 --> 00:02:18,660
setting up your flows and then you know

24
00:02:18,660 --> 00:02:21,720
transfer about four kilobits sorry

25
00:02:21,720 --> 00:02:24,270
kilobytes and that's literally the size

26
00:02:24,270 --> 00:02:27,269
of the size of the very most of close

27
00:02:27,269 --> 00:02:30,420
and then to get torn down again so it's

28
00:02:30,420 --> 00:02:32,370
relatively extent expensive in this

29
00:02:32,370 --> 00:02:35,760
connection setup and teardown our most

30
00:02:35,760 --> 00:02:38,190
of the flows actually transfer very very

31
00:02:38,190 --> 00:02:42,450
very little they also have other

32
00:02:42,450 --> 00:02:45,100
artifacts in TCP you know

33
00:02:45,100 --> 00:02:50,560
and part of the spec that makes small

34
00:02:50,560 --> 00:02:52,960
flow is even more problematic teams like

35
00:02:52,960 --> 00:02:55,180
tcp slow-start so you may not be

36
00:02:55,180 --> 00:02:57,490
familiar with this book yo tcp starts

37
00:02:57,490 --> 00:02:59,620
off slowly it'll send one packet on wait

38
00:02:59,620 --> 00:03:01,120
for an arc and then it'll send two

39
00:03:01,120 --> 00:03:03,550
packets on wait for that that's flying

40
00:03:03,550 --> 00:03:05,470
if you've got a very very very long

41
00:03:05,470 --> 00:03:07,870
connection but if you're only having a

42
00:03:07,870 --> 00:03:10,030
short connection it can be quite a can

43
00:03:10,030 --> 00:03:11,590
be play again make it even more

44
00:03:11,590 --> 00:03:29,320
expensive pretty interesting 97 percent

45
00:03:29,320 --> 00:03:31,540
the connections don't use peer to peer 3

46
00:03:31,540 --> 00:03:44,800
percent of it so 97% of connections 97%

47
00:03:44,800 --> 00:03:47,620
connections that don't use to peer about

48
00:03:47,620 --> 00:03:51,910
70 or 70 percent of their traffic is

49
00:03:51,910 --> 00:03:58,720
again HTTP TCP so TCP dominates wire

50
00:03:58,720 --> 00:04:02,440
line network as well so ok it's a huge

51
00:04:02,440 --> 00:04:04,990
part of the equation in wireless

52
00:04:04,990 --> 00:04:09,070
networks networks this is where the

53
00:04:09,070 --> 00:04:14,890
problems start to creep in compared to

54
00:04:14,890 --> 00:04:18,160
the compared to TCP wireless is

55
00:04:18,160 --> 00:04:20,410
relatively lossy your connect your cell

56
00:04:20,410 --> 00:04:22,000
phone will be connected them they're not

57
00:04:22,000 --> 00:04:24,640
connected and that's perfectly normal

58
00:04:24,640 --> 00:04:27,340
well from TCP its point of view it looks

59
00:04:27,340 --> 00:04:29,650
like it's lost packets things like

60
00:04:29,650 --> 00:04:31,570
congestion control if they can lost

61
00:04:31,570 --> 00:04:33,850
version those kinds of things they kick

62
00:04:33,850 --> 00:04:36,160
in even though it's a perfectly normal

63
00:04:36,160 --> 00:04:38,620
thing for your pure cell phone to go

64
00:04:38,620 --> 00:04:41,140
away in the wild line Network you have

65
00:04:41,140 --> 00:04:43,600
things like impedance mismatch you might

66
00:04:43,600 --> 00:04:47,330
have hundreds coming into a box

67
00:04:47,330 --> 00:04:50,270
may only a 100 maggot DSL line so then

68
00:04:50,270 --> 00:04:51,830
you run into problems like both uploads

69
00:04:51,830 --> 00:04:55,099
so your your pork downloads are crowding

70
00:04:55,099 --> 00:04:58,250
out your clothing out your your web

71
00:04:58,250 --> 00:04:59,900
browsing so if you're doing let's say

72
00:04:59,900 --> 00:05:01,460
you're doing let's say video streaming

73
00:05:01,460 --> 00:05:02,900
at the same time as you're browsing the

74
00:05:02,900 --> 00:05:04,580
web which is not uncommon these days for

75
00:05:04,580 --> 00:05:06,349
people to be flicking around on Twitter

76
00:05:06,349 --> 00:05:08,750
commenting on the TV show while watching

77
00:05:08,750 --> 00:05:12,080
the TV show for Netflix the whole

78
00:05:12,080 --> 00:05:16,930
Twitter responds is a key part of UX

79
00:05:21,159 --> 00:05:24,560
user experience for the person flicking

80
00:05:24,560 --> 00:05:27,069
around on Twitter

81
00:05:30,790 --> 00:05:33,730
so this is giving rise to the advent of

82
00:05:33,730 --> 00:05:37,450
user space TCP stacks people working

83
00:05:37,450 --> 00:05:41,890
while you typically see is people who

84
00:05:41,890 --> 00:05:43,420
are developing applications in the

85
00:05:43,420 --> 00:05:45,760
datacenter many of them actually develop

86
00:05:45,760 --> 00:05:48,670
TCP stacks to go alongside their

87
00:05:48,670 --> 00:05:53,950
applications so was recently published

88
00:05:53,950 --> 00:05:56,470
by Gerry Chu from Google commented that

89
00:05:56,470 --> 00:05:58,570
they had something like half a dozen to

90
00:05:58,570 --> 00:06:00,790
a dozen individual TCP stacks inside

91
00:06:00,790 --> 00:06:05,880
Google just simply an application

92
00:06:11,520 --> 00:06:50,680
application that has some nice

93
00:06:50,680 --> 00:06:53,410
advantages as a design approach that has

94
00:06:53,410 --> 00:06:56,110
some nice advantages one of us is that

95
00:06:56,110 --> 00:06:59,260
you RFC compliance so typically all

96
00:06:59,260 --> 00:07:01,270
these panels have a fairly supportive

97
00:07:01,270 --> 00:07:03,130
group fairly broad set of RFC's which is

98
00:07:03,130 --> 00:07:09,490
pretty cool which is pretty nice BSD Sox

99
00:07:09,490 --> 00:07:12,430
API so if I'm taking an off-the-shelf

100
00:07:12,430 --> 00:07:14,050
application like around your necks

101
00:07:14,050 --> 00:07:15,660
everybody's favorite applications choice

102
00:07:15,660 --> 00:07:22,450
engine X and it's very easy to glue the

103
00:07:22,450 --> 00:07:25,540
two together also the total total cost

104
00:07:25,540 --> 00:07:28,660
of ownership so if I'm using a BSD stack

105
00:07:28,660 --> 00:07:31,820
or a neck PST PST stack or Linux

106
00:07:31,820 --> 00:07:35,030
top FTP BK all in that map then as

107
00:07:35,030 --> 00:07:38,000
security problems emerge upstream I saw

108
00:07:38,000 --> 00:07:40,160
get CVE patches I get performance fixes

109
00:07:40,160 --> 00:07:42,920
I got maintenance that sac is maintained

110
00:07:42,920 --> 00:07:44,710
so it's a valence of the attractive way

111
00:07:44,710 --> 00:07:49,750
to implement a user space TCP stack

112
00:07:55,100 --> 00:07:57,290
so along the come along with that

113
00:07:57,290 --> 00:08:01,400
approach comes with costs so those kind

114
00:08:01,400 --> 00:08:03,050
of stats make assumptions that they're

115
00:08:03,050 --> 00:08:05,510
actually running in the kernel so you

116
00:08:05,510 --> 00:08:07,310
have to jump through some hoops to get

117
00:08:07,310 --> 00:08:09,290
those tournament stacks to run and be

118
00:08:09,290 --> 00:08:14,930
held themselves in userspace the kernel

119
00:08:14,930 --> 00:08:16,520
threads will make assumptions like that

120
00:08:16,520 --> 00:08:18,680
they're running in the kawah and that

121
00:08:18,680 --> 00:08:19,820
are not going to be running in the same

122
00:08:19,820 --> 00:08:21,500
context as the user space thread that

123
00:08:21,500 --> 00:08:22,940
made the system call to which they're

124
00:08:22,940 --> 00:08:26,330
reacting so it's you have to don't use

125
00:08:26,330 --> 00:08:28,880
some hoops to get these stacks to behave

126
00:08:28,880 --> 00:08:34,549
in userspace typical things that typical

127
00:08:34,549 --> 00:08:37,190
things that people evaluate look for in

128
00:08:37,190 --> 00:08:39,349
the user space tcp shotgun it's very

129
00:08:39,349 --> 00:08:43,390
heavily around connections per second

130
00:08:48,950 --> 00:08:56,790
you're fine lost my train to talk so in

131
00:08:56,790 --> 00:08:59,310
userspace PCB stocks when you go back to

132
00:08:59,310 --> 00:09:02,040
the previous slide giving rise to the

133
00:09:02,040 --> 00:09:03,930
development of userspace TCC stacks is

134
00:09:03,930 --> 00:09:05,880
the prioritization of performance and

135
00:09:05,880 --> 00:09:10,140
optimization it's an optimized piece for

136
00:09:10,140 --> 00:09:12,089
TCP stack and user space in which you

137
00:09:12,089 --> 00:09:16,350
can really optimize for use cases like

138
00:09:16,350 --> 00:09:18,360
performance use cases like connections

139
00:09:18,360 --> 00:09:20,279
per second your true port your request

140
00:09:20,279 --> 00:09:27,420
response latency so the actual user

141
00:09:27,420 --> 00:09:29,670
space application that's processing the

142
00:09:29,670 --> 00:09:31,680
bitstream is running on the same core in

143
00:09:31,680 --> 00:09:34,829
which the bitstream are received so that

144
00:09:34,829 --> 00:09:36,120
you can do stuff like eliminating

145
00:09:36,120 --> 00:09:41,100
context switching so if I have I will

146
00:09:41,100 --> 00:09:43,230
typically do a select our way for user

147
00:09:43,230 --> 00:09:46,649
input that way for a packet to arrive

148
00:09:46,649 --> 00:09:48,870
that's one context switch and then I

149
00:09:48,870 --> 00:09:50,700
will do a read whenever the packet does

150
00:09:50,700 --> 00:09:52,290
arrive and that's a newer context switch

151
00:09:52,290 --> 00:09:53,700
and then I figure out it hasn't actually

152
00:09:53,700 --> 00:09:55,079
haven't actually received enough

153
00:09:55,079 --> 00:09:56,700
information to do use forum permit the

154
00:09:56,700 --> 00:09:58,800
useful work and I'll do another context

155
00:09:58,800 --> 00:10:00,390
video motor select away for more

156
00:10:00,390 --> 00:10:01,920
information to arrive so lots of context

157
00:10:01,920 --> 00:10:10,729
switching so what does TLB K T over K

158
00:10:16,730 --> 00:10:20,190
- okay is there a high-performance rare

159
00:10:20,190 --> 00:10:24,709
for implementation implemented on top of

160
00:10:26,089 --> 00:10:31,380
design so the bottom three points they

161
00:10:31,380 --> 00:10:34,230
talked about in the last slide you know

162
00:10:34,230 --> 00:10:53,759
the two possible performance that we can

163
00:10:53,759 --> 00:10:55,589
achieve on the platform so that means

164
00:10:55,589 --> 00:10:57,029
that we're going to leave some stuff on

165
00:10:57,029 --> 00:10:59,130
the table so you don't get to be a Steve

166
00:10:59,130 --> 00:11:01,290
stocks compatible API you won't get the

167
00:11:01,290 --> 00:11:07,550
same that look like or if CFC compliant

168
00:11:08,029 --> 00:11:11,430
the fastest possible TCP implementation

169
00:11:11,430 --> 00:11:13,410
that you can build on the general

170
00:11:13,410 --> 00:11:16,980
purpose CPU and that's really that's

171
00:11:16,980 --> 00:11:23,339
what we complained create so in the

172
00:11:23,339 --> 00:11:26,130
creation of TLD k we will use the PDK

173
00:11:26,130 --> 00:11:30,029
design concepts so we do processing

174
00:11:30,029 --> 00:11:34,649
improves IPC we do things like use

175
00:11:34,649 --> 00:11:38,660
vector instructions where where we can

176
00:11:38,660 --> 00:11:41,519
to keep the instruction cache warm so

177
00:11:41,519 --> 00:11:43,230
that instead of pushing one packet Rou

178
00:11:43,230 --> 00:11:46,380
the saccule processing multiple packets

179
00:11:46,380 --> 00:11:47,490
at the same time to keep your

180
00:11:47,490 --> 00:11:50,250
instruction cat cache warm will aim to

181
00:11:50,250 --> 00:11:52,589
cache coherency so that there's an

182
00:11:52,589 --> 00:11:55,920
affinity between a given network device

183
00:11:55,920 --> 00:11:58,440
between the stack that processes to

184
00:11:58,440 --> 00:12:00,360
network device and then also the

185
00:12:00,360 --> 00:12:03,389
application that needs the tcp stream

186
00:12:03,389 --> 00:12:05,399
that's received on that network device

187
00:12:05,399 --> 00:12:08,300
so you have an end

188
00:12:19,400 --> 00:13:01,560
between performance support common TCP

189
00:13:01,560 --> 00:13:11,990
options select acknowledgment features

190
00:13:11,990 --> 00:13:27,180
implementation based on 220 VAR self we

191
00:13:27,180 --> 00:13:28,230
support things like to know the

192
00:13:28,230 --> 00:13:29,490
acknowledgments work and support

193
00:13:29,490 --> 00:13:31,920
congestion control with also support hot

194
00:13:31,920 --> 00:13:33,990
the common hardware offload so you might

195
00:13:33,990 --> 00:13:35,640
choose to use or assess you might use

196
00:13:35,640 --> 00:13:37,710
teachers use TSO you might use to choose

197
00:13:37,710 --> 00:13:45,630
to use sign filtering make performs as

198
00:13:45,630 --> 00:13:47,310
fast as possible and then also we're

199
00:13:47,310 --> 00:13:48,750
going to provide call an example so one

200
00:13:48,750 --> 00:13:50,160
of the nice things you get with the BTK

201
00:13:50,160 --> 00:13:52,230
ones when they download DVD k it gets my

202
00:13:52,230 --> 00:13:54,030
sample code i've written some of of

203
00:13:54,030 --> 00:13:56,700
myself that actually shows different use

204
00:13:56,700 --> 00:13:58,499
cases like l2 forward and

205
00:13:58,499 --> 00:14:00,029
l-3 forwarding we're going to do the

206
00:14:00,029 --> 00:14:01,769
same with TL DK we will have a sample

207
00:14:01,769 --> 00:14:03,839
directory that would show up use cases

208
00:14:03,839 --> 00:14:06,029
like transfer you like transparent proxy

209
00:14:06,029 --> 00:14:07,409
and I'll talk about some of those use

210
00:14:07,409 --> 00:14:08,519
cases that we would like to show off

211
00:14:08,519 --> 00:14:13,819
later okay

212
00:14:17,250 --> 00:14:58,510
so so the application protocol typing

213
00:14:58,510 --> 00:15:00,520
application so what you said typically

214
00:15:00,520 --> 00:15:10,709
see with TCP applications is something

215
00:15:16,020 --> 00:15:23,770
next time we will continue to do useful

216
00:15:23,770 --> 00:15:26,140
work rather is useful what to do so we

217
00:15:26,140 --> 00:15:30,100
will so we will do batch processing so

218
00:15:30,100 --> 00:15:32,100
we were batch but we will not read

219
00:15:32,100 --> 00:15:34,779
packets off the network device and then

220
00:15:34,779 --> 00:15:36,910
we will batch read we will iterate

221
00:15:36,910 --> 00:15:39,310
through streams and then iterate through

222
00:15:39,310 --> 00:15:41,770
packets received on streams so we will

223
00:15:41,770 --> 00:15:43,720
continue to pole and continue to work in

224
00:15:43,720 --> 00:15:45,700
the DPD case Island the batch processing

225
00:15:45,700 --> 00:15:49,390
stuff and continue to work well what to

226
00:15:49,390 --> 00:15:52,720
do will never block so the application

227
00:15:52,720 --> 00:15:54,820
is driving is driving the protocol on a

228
00:15:54,820 --> 00:15:58,029
protocol judgment application so tree

229
00:15:58,029 --> 00:16:00,940
core design concepts the first is low

230
00:16:00,940 --> 00:16:03,100
context your context is really an

231
00:16:03,100 --> 00:16:05,589
individual instance of the stack you

232
00:16:05,589 --> 00:16:09,339
typically have one context pair core you

233
00:16:09,339 --> 00:16:11,050
may have more than one context protocol

234
00:16:11,050 --> 00:16:12,850
that's okay too but there is an affinity

235
00:16:12,850 --> 00:16:15,010
between the content between the context

236
00:16:15,010 --> 00:16:16,690
in the given core

237
00:16:16,690 --> 00:16:19,720
have devices now all we're doing is

238
00:16:19,720 --> 00:16:21,370
implementing a layer for implementation

239
00:16:21,370 --> 00:16:23,350
we're not doing a layer two we're not

240
00:16:23,350 --> 00:16:26,340
doing the layer 3 implementation

241
00:16:26,340 --> 00:16:28,540
somewhere else you might choose to you

242
00:16:28,540 --> 00:16:30,520
in many cases people have their own on

243
00:16:30,520 --> 00:16:31,930
top of DVD K that they'll want to use

244
00:16:31,930 --> 00:16:33,280
for all we're doing is a layer for

245
00:16:33,280 --> 00:16:34,030
implementation

246
00:16:34,030 --> 00:16:37,150
so we TLD K a hazard has a notion after

247
00:16:37,150 --> 00:16:38,590
being a device underneath and that

248
00:16:38,590 --> 00:16:56,730
device has capabilities advantages

249
00:16:59,730 --> 00:17:00,930
[Music]

250
00:17:00,930 --> 00:17:09,730
achieved by using is which is

251
00:17:09,730 --> 00:19:40,360
essentially on the back end on your

252
00:19:40,360 --> 00:19:44,620
application all of which ones we also

253
00:19:44,620 --> 00:19:46,240
will support the right-hand side where

254
00:19:46,240 --> 00:19:47,860
you have a background in your context on

255
00:19:47,860 --> 00:19:49,900
one core with your actual content can

256
00:19:49,900 --> 00:19:51,910
read and write this tree like the

257
00:19:51,910 --> 00:19:54,750
streams from other course

258
00:19:55,950 --> 00:19:59,280
so this was the bit where I was supposed

259
00:19:59,280 --> 00:20:03,090
to support talk about both GDP and TCP

260
00:20:03,090 --> 00:20:06,150
performance on top of Thiele on top of

261
00:20:06,150 --> 00:20:10,080
TL DK typically happen with these things

262
00:20:10,080 --> 00:20:13,070
that there was a whole drag around

263
00:20:13,070 --> 00:20:16,290
licensing costs for that the benchmark

264
00:20:16,290 --> 00:20:19,050
TCP and then there was also an unhappy

265
00:20:19,050 --> 00:20:21,060
incident involving an error on that kind

266
00:20:21,060 --> 00:20:29,970
of numbers today I will talk about it I

267
00:20:29,970 --> 00:20:34,220
will talk about TCP performance as well

268
00:20:39,800 --> 00:20:41,610
performance is about seven million

269
00:20:41,610 --> 00:20:43,170
packets per second for one thing you

270
00:20:43,170 --> 00:20:49,310
know m4 is very stable guys you add

271
00:20:53,380 --> 00:20:55,040
[Music]

272
00:20:55,040 --> 00:20:57,030
applications typically are is they took

273
00:20:57,030 --> 00:20:58,710
more codes you give you get a little

274
00:20:58,710 --> 00:21:07,650
stale when you're scaling initial try

275
00:21:07,650 --> 00:21:12,770
bits for connections per second is about

276
00:21:13,250 --> 00:21:21,570
connections per second for that we're

277
00:21:21,570 --> 00:21:23,670
trying positive for that so that means

278
00:21:23,670 --> 00:21:25,320
that you'll be able to set down I'm to

279
00:21:25,320 --> 00:21:28,230
set up and tear down half a million - 1

280
00:21:28,230 --> 00:21:30,120
million connections per second for core

281
00:21:30,120 --> 00:21:36,020
which is pretty exceptional performance

282
00:21:37,070 --> 00:21:39,850
okay

283
00:21:43,149 --> 00:21:46,239
okay so some of the news cases that were

284
00:21:46,239 --> 00:21:48,879
aiming for deepening our claims are

285
00:21:48,879 --> 00:21:50,589
typically proved now forced on network

286
00:21:50,589 --> 00:21:53,259
nodes and hopefully t LD k won't be any

287
00:21:53,259 --> 00:21:54,940
exception to this so we're going to

288
00:21:54,940 --> 00:21:57,609
start off at PCP aggregation points in

289
00:21:57,609 --> 00:21:59,109
the network and there's two I find

290
00:21:59,109 --> 00:21:59,950
interesting

291
00:21:59,950 --> 00:22:02,169
the first one is transparent and

292
00:22:02,169 --> 00:22:04,509
transparent proxies and transparent

293
00:22:04,509 --> 00:22:06,729
proxies are pretty widely deployed in

294
00:22:06,729 --> 00:22:09,700
the cellular network turn to foreign

295
00:22:09,700 --> 00:22:11,789
proxies elect okay with the fact that

296
00:22:11,789 --> 00:22:14,529
tcp going milks when your cell phone

297
00:22:14,529 --> 00:22:17,169
disappears on reappears on the cellular

298
00:22:17,169 --> 00:22:19,419
network so that typically happens in the

299
00:22:19,419 --> 00:22:21,669
transparent proxy is that what's the

300
00:22:21,669 --> 00:22:24,429
same go by between your cell phone on

301
00:22:24,429 --> 00:22:26,019
the server and then they will create a

302
00:22:26,019 --> 00:22:27,879
shadow connection once that shadow

303
00:22:27,879 --> 00:22:33,609
connection is set up so as your cell

304
00:22:33,609 --> 00:22:36,999
phone communicates with the cell as a

305
00:22:36,999 --> 00:22:38,559
consultant communicates with the server

306
00:22:38,559 --> 00:22:40,599
and send intelligence from the server

307
00:22:40,599 --> 00:22:43,599
which returns and acknowledges as the

308
00:22:43,599 --> 00:22:46,419
server returned packets that means that

309
00:22:46,419 --> 00:22:48,700
if your cell phone disappears for a few

310
00:22:48,700 --> 00:22:50,739
million for a few milliseconds and it's

311
00:22:50,739 --> 00:22:53,409
not there to send the acts that the

312
00:22:53,409 --> 00:22:55,629
server doesn't start sending those

313
00:22:55,629 --> 00:22:58,899
packets are necessarily appears on your

314
00:22:58,899 --> 00:23:00,669
network the tcp back in the network the

315
00:23:00,669 --> 00:23:03,729
tcp proxy stands on the sender's a sense

316
00:23:03,729 --> 00:23:06,869
on those pockets so such things like the

317
00:23:06,869 --> 00:23:12,539
typical last control mechanisms of tcp

318
00:23:19,979 --> 00:23:22,779
bouncer so this is more of a davis and

319
00:23:22,779 --> 00:23:24,940
reuse case so the in the datacenter you

320
00:23:24,940 --> 00:23:26,859
typically have a reverse proxy lower

321
00:23:26,859 --> 00:23:28,899
balancer that sits back and sits

322
00:23:28,899 --> 00:23:32,769
directly behind your front end it

323
00:23:32,769 --> 00:23:36,429
terminates HTTP it serves up static

324
00:23:36,429 --> 00:23:41,019
content itself and then it requests for

325
00:23:41,019 --> 00:23:43,719
dynamic content to the web service

326
00:23:43,719 --> 00:23:46,229
behind

327
00:23:54,970 --> 00:25:18,290
you know implementations that are

328
00:25:18,290 --> 00:25:33,940
interesting to you contributions

329
00:25:35,350 --> 00:25:37,190
contributing use cases that are

330
00:25:37,190 --> 00:25:39,419
contributing code

331
00:25:39,419 --> 00:25:43,190
for fellow travelers to follow us

332
00:25:51,970 --> 00:25:55,509
that's question so I have a few minutes

333
00:25:55,509 --> 00:25:59,100
for questions if there's any questions

334
00:26:07,740 --> 00:26:10,520
I'm sorry

335
00:26:19,630 --> 00:26:21,880
to replant okay so the question is to

336
00:26:21,880 --> 00:26:27,760
climb any MTC piece to this point that's

337
00:26:27,760 --> 00:26:28,960
an interesting one because that's

338
00:26:28,960 --> 00:26:32,770
actually interested them not calling

339
00:26:32,770 --> 00:26:34,900
people I'd love to hear more that's

340
00:26:34,900 --> 00:26:35,980
something that's interesting to you

341
00:26:35,980 --> 00:26:37,360
because I know it's heavily used

342
00:26:37,360 --> 00:26:39,510
particularly in cell phones right

343
00:26:39,510 --> 00:26:41,950
improve performance in culprit mobility

344
00:26:41,950 --> 00:26:42,940
so if that's something that's

345
00:26:42,940 --> 00:26:44,380
interesting I'd love to talk about

346
00:26:44,380 --> 00:26:46,710
afterwards

347
00:26:50,020 --> 00:26:53,079
[Music]

348
00:28:05,340 --> 00:28:08,949
[Music]

349
00:28:53,350 --> 00:28:56,820
those are the a specular host

350
00:29:09,360 --> 00:29:12,600
so the

351
00:29:38,799 --> 00:29:43,059
see how to get you been down here

